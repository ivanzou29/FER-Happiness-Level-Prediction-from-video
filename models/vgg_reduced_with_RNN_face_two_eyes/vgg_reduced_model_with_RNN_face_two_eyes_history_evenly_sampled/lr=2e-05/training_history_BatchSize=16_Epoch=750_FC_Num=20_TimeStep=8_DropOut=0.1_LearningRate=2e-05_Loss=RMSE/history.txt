Epoch: 1| Step: 0
Training loss: 5.6350985265070905
Validation loss: 5.796071324461539

Epoch: 6| Step: 1
Training loss: 4.89559245497718
Validation loss: 5.775052391893851

Epoch: 6| Step: 2
Training loss: 5.373050779828643
Validation loss: 5.7534907509223565

Epoch: 6| Step: 3
Training loss: 6.555811789007569
Validation loss: 5.730558232277758

Epoch: 6| Step: 4
Training loss: 6.606101088708701
Validation loss: 5.705367696779875

Epoch: 6| Step: 5
Training loss: 5.356852212923511
Validation loss: 5.677658185918213

Epoch: 6| Step: 6
Training loss: 4.581049170782491
Validation loss: 5.645615986913063

Epoch: 6| Step: 7
Training loss: 6.4448514276371345
Validation loss: 5.610526732725774

Epoch: 6| Step: 8
Training loss: 4.860768599780824
Validation loss: 5.5710530868789565

Epoch: 6| Step: 9
Training loss: 4.8144408436709485
Validation loss: 5.5276530510711614

Epoch: 6| Step: 10
Training loss: 5.814547598535484
Validation loss: 5.47994588626856

Epoch: 6| Step: 11
Training loss: 5.746081800208512
Validation loss: 5.429213927367714

Epoch: 6| Step: 12
Training loss: 5.4482195194399825
Validation loss: 5.374355480703198

Epoch: 6| Step: 13
Training loss: 6.8482057880783005
Validation loss: 5.318378760524111

Epoch: 2| Step: 0
Training loss: 4.791797846228604
Validation loss: 5.259539912247141

Epoch: 6| Step: 1
Training loss: 4.696662391424208
Validation loss: 5.201838106477714

Epoch: 6| Step: 2
Training loss: 5.210391723784614
Validation loss: 5.143252480764159

Epoch: 6| Step: 3
Training loss: 4.874118236123526
Validation loss: 5.082793246256657

Epoch: 6| Step: 4
Training loss: 5.1888747634169015
Validation loss: 5.023508971017539

Epoch: 6| Step: 5
Training loss: 4.468003857616921
Validation loss: 4.966042805088811

Epoch: 6| Step: 6
Training loss: 5.716328092434125
Validation loss: 4.909219675325056

Epoch: 6| Step: 7
Training loss: 5.254599236941781
Validation loss: 4.855013336967296

Epoch: 6| Step: 8
Training loss: 6.593811324137226
Validation loss: 4.803920808667055

Epoch: 6| Step: 9
Training loss: 4.249271105924006
Validation loss: 4.765827842630502

Epoch: 6| Step: 10
Training loss: 5.132308029397511
Validation loss: 4.736409622504416

Epoch: 6| Step: 11
Training loss: 4.5469408587638025
Validation loss: 4.706118437413018

Epoch: 6| Step: 12
Training loss: 4.71385150825417
Validation loss: 4.677659637678256

Epoch: 6| Step: 13
Training loss: 2.8186253285379705
Validation loss: 4.650161511980071

Epoch: 3| Step: 0
Training loss: 3.84119522666424
Validation loss: 4.622274587434256

Epoch: 6| Step: 1
Training loss: 4.332619877305267
Validation loss: 4.590843069483965

Epoch: 6| Step: 2
Training loss: 3.921232254430803
Validation loss: 4.558682377239968

Epoch: 6| Step: 3
Training loss: 5.4286801069179855
Validation loss: 4.529222541042778

Epoch: 6| Step: 4
Training loss: 4.103594641671409
Validation loss: 4.4955204415283445

Epoch: 6| Step: 5
Training loss: 5.372971795242888
Validation loss: 4.464661277572299

Epoch: 6| Step: 6
Training loss: 3.3501704955484226
Validation loss: 4.436802224703756

Epoch: 6| Step: 7
Training loss: 4.270735030864994
Validation loss: 4.409983048290994

Epoch: 6| Step: 8
Training loss: 4.529893553706329
Validation loss: 4.383697833892171

Epoch: 6| Step: 9
Training loss: 4.1079540044035205
Validation loss: 4.354586004895616

Epoch: 6| Step: 10
Training loss: 5.865238602541766
Validation loss: 4.332445429161862

Epoch: 6| Step: 11
Training loss: 4.514953985814092
Validation loss: 4.304778505656457

Epoch: 6| Step: 12
Training loss: 5.202917146397335
Validation loss: 4.280115556756467

Epoch: 6| Step: 13
Training loss: 3.5290409706787895
Validation loss: 4.2574844569653525

Epoch: 4| Step: 0
Training loss: 4.160214935032091
Validation loss: 4.235725065612922

Epoch: 6| Step: 1
Training loss: 5.659443496466527
Validation loss: 4.2148795460453465

Epoch: 6| Step: 2
Training loss: 4.167612934744845
Validation loss: 4.193587922232516

Epoch: 6| Step: 3
Training loss: 4.231113205111366
Validation loss: 4.176794056479064

Epoch: 6| Step: 4
Training loss: 2.9900487521990913
Validation loss: 4.159018156709259

Epoch: 6| Step: 5
Training loss: 4.2085903328456284
Validation loss: 4.147498301625529

Epoch: 6| Step: 6
Training loss: 3.519234800396567
Validation loss: 4.131299250300794

Epoch: 6| Step: 7
Training loss: 4.997074034009021
Validation loss: 4.114201912803316

Epoch: 6| Step: 8
Training loss: 4.149964132498664
Validation loss: 4.093902790443704

Epoch: 6| Step: 9
Training loss: 4.176756556691125
Validation loss: 4.072817326177074

Epoch: 6| Step: 10
Training loss: 4.208847064900631
Validation loss: 4.049202092228794

Epoch: 6| Step: 11
Training loss: 4.017423828010581
Validation loss: 4.029917373420879

Epoch: 6| Step: 12
Training loss: 4.841035340600739
Validation loss: 4.00461801192711

Epoch: 6| Step: 13
Training loss: 3.232849940972319
Validation loss: 3.9861811797662896

Epoch: 5| Step: 0
Training loss: 3.9548442253367817
Validation loss: 3.9787263158954693

Epoch: 6| Step: 1
Training loss: 4.727929893244976
Validation loss: 3.9581397630460353

Epoch: 6| Step: 2
Training loss: 3.9840880047526883
Validation loss: 3.9401110644500714

Epoch: 6| Step: 3
Training loss: 3.4335136187233184
Validation loss: 3.928989419912903

Epoch: 6| Step: 4
Training loss: 4.216070836205013
Validation loss: 3.908751278314734

Epoch: 6| Step: 5
Training loss: 3.6149105543201014
Validation loss: 3.887905416539441

Epoch: 6| Step: 6
Training loss: 3.643884861120548
Validation loss: 3.868907967956383

Epoch: 6| Step: 7
Training loss: 3.364919372091443
Validation loss: 3.852758126375909

Epoch: 6| Step: 8
Training loss: 5.060153181750363
Validation loss: 3.8358900969788303

Epoch: 6| Step: 9
Training loss: 4.490076779938857
Validation loss: 3.8164047184277723

Epoch: 6| Step: 10
Training loss: 4.030053249414359
Validation loss: 3.7986616546575105

Epoch: 6| Step: 11
Training loss: 3.358460341734646
Validation loss: 3.776208725042479

Epoch: 6| Step: 12
Training loss: 4.5949012196148
Validation loss: 3.7633246011546504

Epoch: 6| Step: 13
Training loss: 3.049670536194606
Validation loss: 3.7519261407449522

Epoch: 6| Step: 0
Training loss: 4.230464241398798
Validation loss: 3.7378653475835413

Epoch: 6| Step: 1
Training loss: 4.348247587256058
Validation loss: 3.722162127806859

Epoch: 6| Step: 2
Training loss: 2.7853255681900073
Validation loss: 3.7086661810349146

Epoch: 6| Step: 3
Training loss: 4.046685291689433
Validation loss: 3.6987902475878536

Epoch: 6| Step: 4
Training loss: 4.077378478727363
Validation loss: 3.6791330266422704

Epoch: 6| Step: 5
Training loss: 4.123369299182576
Validation loss: 3.662082729797779

Epoch: 6| Step: 6
Training loss: 2.847831396255583
Validation loss: 3.6499018966812264

Epoch: 6| Step: 7
Training loss: 4.787451817043457
Validation loss: 3.6487755548239025

Epoch: 6| Step: 8
Training loss: 2.7811326420058466
Validation loss: 3.626078824537927

Epoch: 6| Step: 9
Training loss: 3.907791809979027
Validation loss: 3.6284244036030366

Epoch: 6| Step: 10
Training loss: 4.125369893453495
Validation loss: 3.6101444601302233

Epoch: 6| Step: 11
Training loss: 4.316412657305765
Validation loss: 3.593583818742499

Epoch: 6| Step: 12
Training loss: 3.568859380592402
Validation loss: 3.58757044596632

Epoch: 6| Step: 13
Training loss: 2.5706341666835635
Validation loss: 3.5774997699240125

Epoch: 7| Step: 0
Training loss: 3.523914786955016
Validation loss: 3.5617064157197396

Epoch: 6| Step: 1
Training loss: 3.2765539079152366
Validation loss: 3.55646464068487

Epoch: 6| Step: 2
Training loss: 4.376185229382462
Validation loss: 3.5502866370745143

Epoch: 6| Step: 3
Training loss: 4.050731574023393
Validation loss: 3.5433527692712197

Epoch: 6| Step: 4
Training loss: 3.1636866216743296
Validation loss: 3.538235720344194

Epoch: 6| Step: 5
Training loss: 4.855395094787783
Validation loss: 3.5209369361421983

Epoch: 6| Step: 6
Training loss: 3.3386499602577246
Validation loss: 3.5119731703736994

Epoch: 6| Step: 7
Training loss: 3.31038742356601
Validation loss: 3.5052355503298886

Epoch: 6| Step: 8
Training loss: 3.424704718565207
Validation loss: 3.4993983804962108

Epoch: 6| Step: 9
Training loss: 2.9244055575954935
Validation loss: 3.49212593574377

Epoch: 6| Step: 10
Training loss: 3.50044710845721
Validation loss: 3.4846843308291597

Epoch: 6| Step: 11
Training loss: 4.1515329310376705
Validation loss: 3.4825000505363684

Epoch: 6| Step: 12
Training loss: 3.763850256865105
Validation loss: 3.462003445910155

Epoch: 6| Step: 13
Training loss: 4.198785406419356
Validation loss: 3.4498558637326346

Epoch: 8| Step: 0
Training loss: 4.573037924350064
Validation loss: 3.4460837189988243

Epoch: 6| Step: 1
Training loss: 3.1694922305877102
Validation loss: 3.441168657388943

Epoch: 6| Step: 2
Training loss: 4.724184860075131
Validation loss: 3.437101649437216

Epoch: 6| Step: 3
Training loss: 2.702226610779684
Validation loss: 3.4242597679595748

Epoch: 6| Step: 4
Training loss: 3.835897472662215
Validation loss: 3.4224704987131838

Epoch: 6| Step: 5
Training loss: 3.8558964052490694
Validation loss: 3.406856025732675

Epoch: 6| Step: 6
Training loss: 3.1126302423765075
Validation loss: 3.4032884065782

Epoch: 6| Step: 7
Training loss: 3.3669576544323694
Validation loss: 3.399134409141424

Epoch: 6| Step: 8
Training loss: 3.6360912990459355
Validation loss: 3.3966329964127198

Epoch: 6| Step: 9
Training loss: 4.026257165797625
Validation loss: 3.3902191815981424

Epoch: 6| Step: 10
Training loss: 2.6510731233680325
Validation loss: 3.3794342104637765

Epoch: 6| Step: 11
Training loss: 3.8764361519694104
Validation loss: 3.371287310278602

Epoch: 6| Step: 12
Training loss: 3.205042716231129
Validation loss: 3.364368721543719

Epoch: 6| Step: 13
Training loss: 3.2906954012419445
Validation loss: 3.355448118377502

Epoch: 9| Step: 0
Training loss: 3.7678299775690736
Validation loss: 3.344052993836323

Epoch: 6| Step: 1
Training loss: 3.6645356545844527
Validation loss: 3.338789896560857

Epoch: 6| Step: 2
Training loss: 3.6648906105443118
Validation loss: 3.3347549934369902

Epoch: 6| Step: 3
Training loss: 3.6589874713909447
Validation loss: 3.3210472696269773

Epoch: 6| Step: 4
Training loss: 3.3089367397114304
Validation loss: 3.315673962176541

Epoch: 6| Step: 5
Training loss: 3.8796005011892816
Validation loss: 3.3186925352050745

Epoch: 6| Step: 6
Training loss: 4.185316968647865
Validation loss: 3.3060453343389864

Epoch: 6| Step: 7
Training loss: 2.575074581806841
Validation loss: 3.2960893061892538

Epoch: 6| Step: 8
Training loss: 2.4944858775087946
Validation loss: 3.2931548093652947

Epoch: 6| Step: 9
Training loss: 4.001081320518047
Validation loss: 3.2885001141189694

Epoch: 6| Step: 10
Training loss: 2.8863652365153745
Validation loss: 3.2898224934266467

Epoch: 6| Step: 11
Training loss: 4.50946807871009
Validation loss: 3.290479091958968

Epoch: 6| Step: 12
Training loss: 3.0575384314454044
Validation loss: 3.2749988519897806

Epoch: 6| Step: 13
Training loss: 3.328582732194878
Validation loss: 3.272378942863499

Epoch: 10| Step: 0
Training loss: 4.893238868182683
Validation loss: 3.277930862858037

Epoch: 6| Step: 1
Training loss: 4.335131541085648
Validation loss: 3.265013564366696

Epoch: 6| Step: 2
Training loss: 2.94756281765561
Validation loss: 3.261014446703682

Epoch: 6| Step: 3
Training loss: 4.119838143660022
Validation loss: 3.2593138445895447

Epoch: 6| Step: 4
Training loss: 3.027250817626016
Validation loss: 3.252088881981079

Epoch: 6| Step: 5
Training loss: 3.8533234507248104
Validation loss: 3.248369970860114

Epoch: 6| Step: 6
Training loss: 3.6706842317873365
Validation loss: 3.2460255233461464

Epoch: 6| Step: 7
Training loss: 2.7821781452822503
Validation loss: 3.245540155634666

Epoch: 6| Step: 8
Training loss: 2.9209407189872736
Validation loss: 3.242226273974094

Epoch: 6| Step: 9
Training loss: 2.5390893553267273
Validation loss: 3.237470169427239

Epoch: 6| Step: 10
Training loss: 3.3801620002161257
Validation loss: 3.2302807926603436

Epoch: 6| Step: 11
Training loss: 3.687005478625447
Validation loss: 3.2228184319807767

Epoch: 6| Step: 12
Training loss: 2.7101452464069733
Validation loss: 3.219138569907862

Epoch: 6| Step: 13
Training loss: 3.0983348742873322
Validation loss: 3.219360819275968

Epoch: 11| Step: 0
Training loss: 3.155066088726345
Validation loss: 3.2180940951567933

Epoch: 6| Step: 1
Training loss: 3.1211365277888206
Validation loss: 3.2112264822251677

Epoch: 6| Step: 2
Training loss: 3.3619906865795968
Validation loss: 3.2091386985733332

Epoch: 6| Step: 3
Training loss: 3.1515567747337374
Validation loss: 3.20881445837934

Epoch: 6| Step: 4
Training loss: 3.655427106541422
Validation loss: 3.20463571846263

Epoch: 6| Step: 5
Training loss: 2.9034067006992883
Validation loss: 3.1963248409415566

Epoch: 6| Step: 6
Training loss: 3.0038433886871942
Validation loss: 3.1962062030066436

Epoch: 6| Step: 7
Training loss: 4.036649651043974
Validation loss: 3.1962873003564893

Epoch: 6| Step: 8
Training loss: 3.7101858562381467
Validation loss: 3.191708117192083

Epoch: 6| Step: 9
Training loss: 3.9166955067539977
Validation loss: 3.188246772821467

Epoch: 6| Step: 10
Training loss: 3.516203701285394
Validation loss: 3.1939946385974167

Epoch: 6| Step: 11
Training loss: 4.000274887176334
Validation loss: 3.184301131642774

Epoch: 6| Step: 12
Training loss: 3.312799548154467
Validation loss: 3.1780072387698777

Epoch: 6| Step: 13
Training loss: 3.234485126776649
Validation loss: 3.1772192557618113

Epoch: 12| Step: 0
Training loss: 4.188885587651048
Validation loss: 3.1708573271186253

Epoch: 6| Step: 1
Training loss: 2.7902636252382385
Validation loss: 3.1707634531284956

Epoch: 6| Step: 2
Training loss: 4.1568297935440075
Validation loss: 3.1702603289172475

Epoch: 6| Step: 3
Training loss: 3.493342744023506
Validation loss: 3.16652430639121

Epoch: 6| Step: 4
Training loss: 3.102098087218489
Validation loss: 3.1604144209964375

Epoch: 6| Step: 5
Training loss: 3.4122454873216657
Validation loss: 3.1544919132641223

Epoch: 6| Step: 6
Training loss: 3.8141650956922755
Validation loss: 3.1529847772012483

Epoch: 6| Step: 7
Training loss: 2.7625997775601414
Validation loss: 3.1469698518605806

Epoch: 6| Step: 8
Training loss: 3.3728319904771906
Validation loss: 3.1466014087122685

Epoch: 6| Step: 9
Training loss: 3.335737092834903
Validation loss: 3.1374921556665685

Epoch: 6| Step: 10
Training loss: 3.8270400397700857
Validation loss: 3.1308699198710888

Epoch: 6| Step: 11
Training loss: 3.240058806792273
Validation loss: 3.1374468864400358

Epoch: 6| Step: 12
Training loss: 2.544373858008132
Validation loss: 3.179081044480595

Epoch: 6| Step: 13
Training loss: 3.434011041240238
Validation loss: 3.14137464415

Epoch: 13| Step: 0
Training loss: 3.554508816765939
Validation loss: 3.128547851434542

Epoch: 6| Step: 1
Training loss: 3.5506703240889896
Validation loss: 3.1450846690596386

Epoch: 6| Step: 2
Training loss: 3.0689212665818775
Validation loss: 3.1440395999388655

Epoch: 6| Step: 3
Training loss: 3.4685627654809785
Validation loss: 3.138873798976467

Epoch: 6| Step: 4
Training loss: 3.9621450174934836
Validation loss: 3.12963900393754

Epoch: 6| Step: 5
Training loss: 2.5089270471006806
Validation loss: 3.125665510951214

Epoch: 6| Step: 6
Training loss: 3.075814401352491
Validation loss: 3.132661025453119

Epoch: 6| Step: 7
Training loss: 3.385123998266914
Validation loss: 3.1300134079933084

Epoch: 6| Step: 8
Training loss: 3.454365365111744
Validation loss: 3.1255408428151834

Epoch: 6| Step: 9
Training loss: 3.5229841054773847
Validation loss: 3.1208108285043514

Epoch: 6| Step: 10
Training loss: 3.9068407756384707
Validation loss: 3.1140260432762616

Epoch: 6| Step: 11
Training loss: 3.005452922385702
Validation loss: 3.1096252449539037

Epoch: 6| Step: 12
Training loss: 3.409916994980771
Validation loss: 3.1073078125740414

Epoch: 6| Step: 13
Training loss: 3.5512088060792766
Validation loss: 3.098939295843227

Epoch: 14| Step: 0
Training loss: 3.094863999295171
Validation loss: 3.0995528878833807

Epoch: 6| Step: 1
Training loss: 2.01820716763884
Validation loss: 3.0975490987529457

Epoch: 6| Step: 2
Training loss: 3.5446197465086247
Validation loss: 3.1032980158893935

Epoch: 6| Step: 3
Training loss: 3.760696795201258
Validation loss: 3.1098042496507916

Epoch: 6| Step: 4
Training loss: 3.078005251031651
Validation loss: 3.0946073084868813

Epoch: 6| Step: 5
Training loss: 3.116488806261499
Validation loss: 3.08172090058725

Epoch: 6| Step: 6
Training loss: 4.083902176659645
Validation loss: 3.081293090127634

Epoch: 6| Step: 7
Training loss: 2.4468023374640184
Validation loss: 3.075309085460399

Epoch: 6| Step: 8
Training loss: 3.157409152961349
Validation loss: 3.076105843398655

Epoch: 6| Step: 9
Training loss: 3.8536722776857544
Validation loss: 3.0741666731637616

Epoch: 6| Step: 10
Training loss: 4.183772007611065
Validation loss: 3.071850860510537

Epoch: 6| Step: 11
Training loss: 3.74574063320398
Validation loss: 3.065729109291345

Epoch: 6| Step: 12
Training loss: 3.090658319214593
Validation loss: 3.061716377500979

Epoch: 6| Step: 13
Training loss: 3.1315976496209292
Validation loss: 3.062410230662382

Epoch: 15| Step: 0
Training loss: 4.050242080046873
Validation loss: 3.05870451298569

Epoch: 6| Step: 1
Training loss: 3.6119703069503513
Validation loss: 3.0602542142466884

Epoch: 6| Step: 2
Training loss: 3.541596505461219
Validation loss: 3.0591503606979993

Epoch: 6| Step: 3
Training loss: 3.505850534241987
Validation loss: 3.0632720486417475

Epoch: 6| Step: 4
Training loss: 3.426083698210117
Validation loss: 3.0583261169963616

Epoch: 6| Step: 5
Training loss: 3.045735463989209
Validation loss: 3.056009645613464

Epoch: 6| Step: 6
Training loss: 3.7330959795250633
Validation loss: 3.0492749964130903

Epoch: 6| Step: 7
Training loss: 3.236415643147518
Validation loss: 3.0491113340082943

Epoch: 6| Step: 8
Training loss: 3.1528012913869454
Validation loss: 3.047297390545173

Epoch: 6| Step: 9
Training loss: 3.43720313437581
Validation loss: 3.046126041751893

Epoch: 6| Step: 10
Training loss: 2.6996065736164656
Validation loss: 3.042858838060344

Epoch: 6| Step: 11
Training loss: 3.2134545477749072
Validation loss: 3.0378164032315604

Epoch: 6| Step: 12
Training loss: 2.999524555678721
Validation loss: 3.0407023093045242

Epoch: 6| Step: 13
Training loss: 2.387233347756483
Validation loss: 3.0396668190519947

Epoch: 16| Step: 0
Training loss: 2.88827650190009
Validation loss: 3.0436158643004823

Epoch: 6| Step: 1
Training loss: 3.7143390043858346
Validation loss: 3.0376814760624797

Epoch: 6| Step: 2
Training loss: 3.7512700791093274
Validation loss: 3.031819452353882

Epoch: 6| Step: 3
Training loss: 3.400096409496659
Validation loss: 3.031043572221558

Epoch: 6| Step: 4
Training loss: 3.72125083116055
Validation loss: 3.0273967694612547

Epoch: 6| Step: 5
Training loss: 3.2526123111929324
Validation loss: 3.0286097240788084

Epoch: 6| Step: 6
Training loss: 3.613273067980601
Validation loss: 3.0265407451802586

Epoch: 6| Step: 7
Training loss: 3.3047815764904263
Validation loss: 3.0262230514162307

Epoch: 6| Step: 8
Training loss: 2.467782519089443
Validation loss: 3.022777541625779

Epoch: 6| Step: 9
Training loss: 3.472824864965783
Validation loss: 3.0225605412642436

Epoch: 6| Step: 10
Training loss: 2.943299756778428
Validation loss: 3.028826862375789

Epoch: 6| Step: 11
Training loss: 3.0081966006271768
Validation loss: 3.042426748600319

Epoch: 6| Step: 12
Training loss: 3.404108476705641
Validation loss: 3.043023301782854

Epoch: 6| Step: 13
Training loss: 3.19253277360767
Validation loss: 3.0452089081857165

Epoch: 17| Step: 0
Training loss: 3.183101087023848
Validation loss: 3.03722179932671

Epoch: 6| Step: 1
Training loss: 3.1081111006940874
Validation loss: 3.0219892067670657

Epoch: 6| Step: 2
Training loss: 3.469884188695494
Validation loss: 3.0167542874924003

Epoch: 6| Step: 3
Training loss: 3.1190880357182205
Validation loss: 3.016507620984954

Epoch: 6| Step: 4
Training loss: 3.2470568021335473
Validation loss: 3.0251012740932537

Epoch: 6| Step: 5
Training loss: 3.565382209823236
Validation loss: 3.017809328027697

Epoch: 6| Step: 6
Training loss: 4.086268453524264
Validation loss: 3.011695792460733

Epoch: 6| Step: 7
Training loss: 2.65246878372793
Validation loss: 3.006455700629841

Epoch: 6| Step: 8
Training loss: 3.083946648162211
Validation loss: 3.0089091753848214

Epoch: 6| Step: 9
Training loss: 3.497086538507805
Validation loss: 3.0313860828133974

Epoch: 6| Step: 10
Training loss: 3.8257144734415043
Validation loss: 3.0467262065558436

Epoch: 6| Step: 11
Training loss: 3.027624419953026
Validation loss: 3.049592268453401

Epoch: 6| Step: 12
Training loss: 2.9839528369397956
Validation loss: 3.04490627044946

Epoch: 6| Step: 13
Training loss: 3.081568926232081
Validation loss: 3.026534170347173

Epoch: 18| Step: 0
Training loss: 3.019677793986005
Validation loss: 3.0150875424689225

Epoch: 6| Step: 1
Training loss: 3.0986432767511616
Validation loss: 3.003148002195384

Epoch: 6| Step: 2
Training loss: 3.675983743633733
Validation loss: 3.0017562616878743

Epoch: 6| Step: 3
Training loss: 3.8154381858588486
Validation loss: 3.0057010334541636

Epoch: 6| Step: 4
Training loss: 3.1112724917048267
Validation loss: 2.999804343402823

Epoch: 6| Step: 5
Training loss: 3.56785676002364
Validation loss: 2.9991864020663184

Epoch: 6| Step: 6
Training loss: 3.6345751352220272
Validation loss: 2.995539262008572

Epoch: 6| Step: 7
Training loss: 2.888197420785266
Validation loss: 2.995345631744521

Epoch: 6| Step: 8
Training loss: 2.8820382916185325
Validation loss: 2.989963406289386

Epoch: 6| Step: 9
Training loss: 3.34758730876357
Validation loss: 2.9907383133539303

Epoch: 6| Step: 10
Training loss: 2.8496281163708588
Validation loss: 2.993211972931627

Epoch: 6| Step: 11
Training loss: 3.196594130482345
Validation loss: 3.0029427287941313

Epoch: 6| Step: 12
Training loss: 3.3799430535389225
Validation loss: 3.025242798499771

Epoch: 6| Step: 13
Training loss: 3.4612025725592854
Validation loss: 3.0020982760311927

Epoch: 19| Step: 0
Training loss: 3.750203445002184
Validation loss: 2.986337047810837

Epoch: 6| Step: 1
Training loss: 3.688589290787973
Validation loss: 2.9867599330606702

Epoch: 6| Step: 2
Training loss: 3.184620173396462
Validation loss: 2.998636619564006

Epoch: 6| Step: 3
Training loss: 3.5710320279819734
Validation loss: 3.0263033865196753

Epoch: 6| Step: 4
Training loss: 2.091323813294637
Validation loss: 3.0455864616729458

Epoch: 6| Step: 5
Training loss: 3.370907032415965
Validation loss: 3.0514240224042326

Epoch: 6| Step: 6
Training loss: 3.6553487074386806
Validation loss: 3.069604026190964

Epoch: 6| Step: 7
Training loss: 2.6499663584751043
Validation loss: 3.026134183221734

Epoch: 6| Step: 8
Training loss: 3.4986505631807
Validation loss: 2.992683550520801

Epoch: 6| Step: 9
Training loss: 3.352814269444495
Validation loss: 2.9814955230371822

Epoch: 6| Step: 10
Training loss: 2.7243297802610886
Validation loss: 2.9861394863842534

Epoch: 6| Step: 11
Training loss: 3.574424862781481
Validation loss: 3.0095962313098417

Epoch: 6| Step: 12
Training loss: 3.2951062416002035
Validation loss: 2.9997822330424917

Epoch: 6| Step: 13
Training loss: 3.453324394165409
Validation loss: 2.9925693587558433

Epoch: 20| Step: 0
Training loss: 3.691094666909519
Validation loss: 2.9837393100564094

Epoch: 6| Step: 1
Training loss: 3.3275587289673134
Validation loss: 2.9841723414877293

Epoch: 6| Step: 2
Training loss: 2.9369579383194306
Validation loss: 2.9784867239117623

Epoch: 6| Step: 3
Training loss: 3.2383445669134123
Validation loss: 2.9752356245226346

Epoch: 6| Step: 4
Training loss: 3.8664059244133777
Validation loss: 2.972274119471251

Epoch: 6| Step: 5
Training loss: 2.5354127915749025
Validation loss: 2.9684878291291783

Epoch: 6| Step: 6
Training loss: 3.326989351751442
Validation loss: 2.969029549960504

Epoch: 6| Step: 7
Training loss: 3.1964333207688056
Validation loss: 2.965657397204035

Epoch: 6| Step: 8
Training loss: 3.2178026305105942
Validation loss: 2.9684796834694884

Epoch: 6| Step: 9
Training loss: 3.0541208039119367
Validation loss: 2.9678122290924343

Epoch: 6| Step: 10
Training loss: 4.1945015746907295
Validation loss: 2.9716699856637723

Epoch: 6| Step: 11
Training loss: 3.231735405534351
Validation loss: 2.98553828622653

Epoch: 6| Step: 12
Training loss: 2.40541418843153
Validation loss: 2.9650816277175602

Epoch: 6| Step: 13
Training loss: 2.8691949702881567
Validation loss: 2.962814701814895

Epoch: 21| Step: 0
Training loss: 3.4312882218029985
Validation loss: 2.9589545934886754

Epoch: 6| Step: 1
Training loss: 3.2534885756657124
Validation loss: 2.960863235039706

Epoch: 6| Step: 2
Training loss: 2.839678857940692
Validation loss: 2.9611362493712203

Epoch: 6| Step: 3
Training loss: 2.9805420232842676
Validation loss: 2.9587859004436714

Epoch: 6| Step: 4
Training loss: 3.396557518125961
Validation loss: 2.9609648147817946

Epoch: 6| Step: 5
Training loss: 3.376345895918651
Validation loss: 2.9628269436580172

Epoch: 6| Step: 6
Training loss: 3.648415020172983
Validation loss: 2.9720843050593735

Epoch: 6| Step: 7
Training loss: 3.2334670114576043
Validation loss: 2.9631267215083796

Epoch: 6| Step: 8
Training loss: 3.081734956101943
Validation loss: 2.956866466699007

Epoch: 6| Step: 9
Training loss: 2.611386922603753
Validation loss: 2.9547556333608553

Epoch: 6| Step: 10
Training loss: 3.642880768258556
Validation loss: 2.953308205695457

Epoch: 6| Step: 11
Training loss: 3.1758204383825204
Validation loss: 2.9567893137046286

Epoch: 6| Step: 12
Training loss: 3.3765934608660513
Validation loss: 2.9542200233263127

Epoch: 6| Step: 13
Training loss: 3.3597512677634027
Validation loss: 2.954756065441576

Epoch: 22| Step: 0
Training loss: 4.084690465324119
Validation loss: 2.9530076446714837

Epoch: 6| Step: 1
Training loss: 3.036794409411704
Validation loss: 2.9498492375318603

Epoch: 6| Step: 2
Training loss: 2.632427968545867
Validation loss: 2.950339782707498

Epoch: 6| Step: 3
Training loss: 3.598640365282101
Validation loss: 2.951304916419406

Epoch: 6| Step: 4
Training loss: 2.310950404421955
Validation loss: 2.9517889282458967

Epoch: 6| Step: 5
Training loss: 3.3387370813620403
Validation loss: 2.9540906348382707

Epoch: 6| Step: 6
Training loss: 2.4289864758444426
Validation loss: 2.9493942711596715

Epoch: 6| Step: 7
Training loss: 3.2942870771688613
Validation loss: 2.9486270516616795

Epoch: 6| Step: 8
Training loss: 3.7955650298972876
Validation loss: 2.9464800957955415

Epoch: 6| Step: 9
Training loss: 2.7464244312423123
Validation loss: 2.9462591561418767

Epoch: 6| Step: 10
Training loss: 3.3850715969971557
Validation loss: 2.9531829710231294

Epoch: 6| Step: 11
Training loss: 4.148696345355586
Validation loss: 2.9493843256512347

Epoch: 6| Step: 12
Training loss: 3.1665841309348743
Validation loss: 2.940514291498323

Epoch: 6| Step: 13
Training loss: 2.3023049663568838
Validation loss: 2.941017310699778

Epoch: 23| Step: 0
Training loss: 2.540836594745181
Validation loss: 2.9408769015605376

Epoch: 6| Step: 1
Training loss: 3.426051269468306
Validation loss: 2.9403035110750677

Epoch: 6| Step: 2
Training loss: 3.4146068846049618
Validation loss: 2.9410557090444622

Epoch: 6| Step: 3
Training loss: 3.479256055829517
Validation loss: 2.9403081826933413

Epoch: 6| Step: 4
Training loss: 2.919243101498149
Validation loss: 2.939496287329237

Epoch: 6| Step: 5
Training loss: 3.420135473947816
Validation loss: 2.9395052772937333

Epoch: 6| Step: 6
Training loss: 2.8570992841122798
Validation loss: 2.936860695039751

Epoch: 6| Step: 7
Training loss: 3.165788947150133
Validation loss: 2.9366942247246284

Epoch: 6| Step: 8
Training loss: 3.508319095996471
Validation loss: 2.9340533718245134

Epoch: 6| Step: 9
Training loss: 3.522195195262505
Validation loss: 2.932312019225202

Epoch: 6| Step: 10
Training loss: 3.724028871664035
Validation loss: 2.931015691451729

Epoch: 6| Step: 11
Training loss: 2.794282617511532
Validation loss: 2.929184281203987

Epoch: 6| Step: 12
Training loss: 3.4330744605630126
Validation loss: 2.9301349589687615

Epoch: 6| Step: 13
Training loss: 2.2877758172518656
Validation loss: 2.9302817690151746

Epoch: 24| Step: 0
Training loss: 3.1365247692587777
Validation loss: 2.9334019159547955

Epoch: 6| Step: 1
Training loss: 3.233871936836309
Validation loss: 2.9495392890650884

Epoch: 6| Step: 2
Training loss: 2.821307315945624
Validation loss: 2.9626191110040705

Epoch: 6| Step: 3
Training loss: 2.9697382837959245
Validation loss: 2.9410326714925

Epoch: 6| Step: 4
Training loss: 3.234305708138346
Validation loss: 2.932146206952336

Epoch: 6| Step: 5
Training loss: 3.02951409097918
Validation loss: 2.9285174880037936

Epoch: 6| Step: 6
Training loss: 3.657640502483829
Validation loss: 2.9271321268357124

Epoch: 6| Step: 7
Training loss: 3.571404154557822
Validation loss: 2.924784187451718

Epoch: 6| Step: 8
Training loss: 3.075938421201001
Validation loss: 2.9241919134779213

Epoch: 6| Step: 9
Training loss: 3.081228947132296
Validation loss: 2.9234954199490244

Epoch: 6| Step: 10
Training loss: 3.5403052162878694
Validation loss: 2.9234648630041296

Epoch: 6| Step: 11
Training loss: 3.9970718633563447
Validation loss: 2.924114257819589

Epoch: 6| Step: 12
Training loss: 2.691796616368938
Validation loss: 2.9236927915635262

Epoch: 6| Step: 13
Training loss: 2.2009419115469973
Validation loss: 2.9258043682106663

Epoch: 25| Step: 0
Training loss: 2.966689509043103
Validation loss: 2.9235085700529186

Epoch: 6| Step: 1
Training loss: 3.8416021285080166
Validation loss: 2.9200584314663716

Epoch: 6| Step: 2
Training loss: 3.1831006376156963
Validation loss: 2.920904109121269

Epoch: 6| Step: 3
Training loss: 2.8687374073159413
Validation loss: 2.9197929904539297

Epoch: 6| Step: 4
Training loss: 3.6231728256830458
Validation loss: 2.9161578940307167

Epoch: 6| Step: 5
Training loss: 3.667881128729134
Validation loss: 2.9164415480640966

Epoch: 6| Step: 6
Training loss: 2.8520525785524424
Validation loss: 2.914631585079422

Epoch: 6| Step: 7
Training loss: 3.3009418877331673
Validation loss: 2.916723439474184

Epoch: 6| Step: 8
Training loss: 2.8463232114922903
Validation loss: 2.9193766741609375

Epoch: 6| Step: 9
Training loss: 3.1599110436292195
Validation loss: 2.9200582295398068

Epoch: 6| Step: 10
Training loss: 3.2065970606661285
Validation loss: 2.9371073191355603

Epoch: 6| Step: 11
Training loss: 2.8867207321965456
Validation loss: 2.9485656280217163

Epoch: 6| Step: 12
Training loss: 3.3321694885413935
Validation loss: 2.9506213914260537

Epoch: 6| Step: 13
Training loss: 3.131963067705413
Validation loss: 2.916140137594651

Epoch: 26| Step: 0
Training loss: 2.8927723100121865
Validation loss: 2.911298034001464

Epoch: 6| Step: 1
Training loss: 3.0902350909729295
Validation loss: 2.909573412265439

Epoch: 6| Step: 2
Training loss: 3.2602667403357732
Validation loss: 2.910042731292701

Epoch: 6| Step: 3
Training loss: 3.7081851429565056
Validation loss: 2.9118817837595254

Epoch: 6| Step: 4
Training loss: 2.519578847509468
Validation loss: 2.9144622001645915

Epoch: 6| Step: 5
Training loss: 3.7662950608134014
Validation loss: 2.920787267286708

Epoch: 6| Step: 6
Training loss: 2.866289627060791
Validation loss: 2.917870316839336

Epoch: 6| Step: 7
Training loss: 2.8754000178151164
Validation loss: 2.912238406808053

Epoch: 6| Step: 8
Training loss: 3.7003490489555775
Validation loss: 2.910045708946885

Epoch: 6| Step: 9
Training loss: 3.532629233208094
Validation loss: 2.9051001377110595

Epoch: 6| Step: 10
Training loss: 3.044938004838211
Validation loss: 2.903467381759884

Epoch: 6| Step: 11
Training loss: 2.633503627904244
Validation loss: 2.90166035120492

Epoch: 6| Step: 12
Training loss: 3.367657621980999
Validation loss: 2.8986764538517433

Epoch: 6| Step: 13
Training loss: 3.551644366185531
Validation loss: 2.901417192499319

Epoch: 27| Step: 0
Training loss: 3.8924786544929946
Validation loss: 2.905356988116519

Epoch: 6| Step: 1
Training loss: 2.9557444747102672
Validation loss: 2.9067740962939825

Epoch: 6| Step: 2
Training loss: 3.0225046379615406
Validation loss: 2.9105516007566044

Epoch: 6| Step: 3
Training loss: 3.2672696147507683
Validation loss: 2.9312401510905315

Epoch: 6| Step: 4
Training loss: 3.2665014231661353
Validation loss: 2.9783337719086034

Epoch: 6| Step: 5
Training loss: 3.6066286942697716
Validation loss: 2.9986007548089715

Epoch: 6| Step: 6
Training loss: 2.8181539713135395
Validation loss: 2.8990051175436427

Epoch: 6| Step: 7
Training loss: 2.723613291684482
Validation loss: 2.8984408522173206

Epoch: 6| Step: 8
Training loss: 2.499145934131388
Validation loss: 2.9189271365143425

Epoch: 6| Step: 9
Training loss: 2.813907017031744
Validation loss: 2.976323369283535

Epoch: 6| Step: 10
Training loss: 3.600494689861207
Validation loss: 2.977893035335357

Epoch: 6| Step: 11
Training loss: 3.410705312461719
Validation loss: 2.938625770155675

Epoch: 6| Step: 12
Training loss: 3.765697177812543
Validation loss: 2.9225783024523415

Epoch: 6| Step: 13
Training loss: 3.290530785410075
Validation loss: 2.91946938389195

Epoch: 28| Step: 0
Training loss: 2.845747696652486
Validation loss: 2.9429344573148026

Epoch: 6| Step: 1
Training loss: 3.229466053199744
Validation loss: 2.963067001795144

Epoch: 6| Step: 2
Training loss: 2.625936431975342
Validation loss: 2.950488964768495

Epoch: 6| Step: 3
Training loss: 3.637044824390602
Validation loss: 2.9258532379506366

Epoch: 6| Step: 4
Training loss: 2.9221746117694476
Validation loss: 2.8898695872436857

Epoch: 6| Step: 5
Training loss: 2.8653515334772433
Validation loss: 2.892690181697753

Epoch: 6| Step: 6
Training loss: 3.829001688317489
Validation loss: 2.9567585702080215

Epoch: 6| Step: 7
Training loss: 3.6086520176882706
Validation loss: 2.9253458234955

Epoch: 6| Step: 8
Training loss: 3.0317492516334976
Validation loss: 2.9114537962270353

Epoch: 6| Step: 9
Training loss: 2.8822351720135524
Validation loss: 2.891616529731226

Epoch: 6| Step: 10
Training loss: 2.966360154194377
Validation loss: 2.88763564501956

Epoch: 6| Step: 11
Training loss: 2.954988890496298
Validation loss: 2.889768023449702

Epoch: 6| Step: 12
Training loss: 3.9313626368750554
Validation loss: 2.8879646686313802

Epoch: 6| Step: 13
Training loss: 3.3955419372476348
Validation loss: 2.8875083930675727

Epoch: 29| Step: 0
Training loss: 3.5805487939892253
Validation loss: 2.885770975366353

Epoch: 6| Step: 1
Training loss: 2.9476131287430314
Validation loss: 2.8896964921360713

Epoch: 6| Step: 2
Training loss: 3.498916321971936
Validation loss: 2.8860359568315292

Epoch: 6| Step: 3
Training loss: 3.5301932044824573
Validation loss: 2.884291095295643

Epoch: 6| Step: 4
Training loss: 2.6562192129707096
Validation loss: 2.879913083225348

Epoch: 6| Step: 5
Training loss: 2.45565772062208
Validation loss: 2.878423468015275

Epoch: 6| Step: 6
Training loss: 3.6864839867508326
Validation loss: 2.877997967782089

Epoch: 6| Step: 7
Training loss: 2.6135684370177845
Validation loss: 2.8749608843738668

Epoch: 6| Step: 8
Training loss: 2.981471061907723
Validation loss: 2.872730657806525

Epoch: 6| Step: 9
Training loss: 3.3890900543485674
Validation loss: 2.8731999194679907

Epoch: 6| Step: 10
Training loss: 2.928210402376082
Validation loss: 2.879777654307868

Epoch: 6| Step: 11
Training loss: 3.6632610168353854
Validation loss: 2.884635042597383

Epoch: 6| Step: 12
Training loss: 2.7975314771093247
Validation loss: 2.880556510799377

Epoch: 6| Step: 13
Training loss: 3.569374812758542
Validation loss: 2.8780704686013237

Epoch: 30| Step: 0
Training loss: 2.5072392554220753
Validation loss: 2.885756326948967

Epoch: 6| Step: 1
Training loss: 3.457873915218686
Validation loss: 2.8792475372316657

Epoch: 6| Step: 2
Training loss: 3.7362710775914776
Validation loss: 2.8795108647539505

Epoch: 6| Step: 3
Training loss: 2.607918155602902
Validation loss: 2.88040680320091

Epoch: 6| Step: 4
Training loss: 2.6506600295731455
Validation loss: 2.8727287837543662

Epoch: 6| Step: 5
Training loss: 3.3567000273859056
Validation loss: 2.872168212370865

Epoch: 6| Step: 6
Training loss: 3.308629491763853
Validation loss: 2.864593823246846

Epoch: 6| Step: 7
Training loss: 3.6669693012767843
Validation loss: 2.8621141724215486

Epoch: 6| Step: 8
Training loss: 3.694874646818304
Validation loss: 2.864855055166729

Epoch: 6| Step: 9
Training loss: 2.8925253729997364
Validation loss: 2.8627560625811377

Epoch: 6| Step: 10
Training loss: 2.7672271398271584
Validation loss: 2.86298838911497

Epoch: 6| Step: 11
Training loss: 3.2030324038635944
Validation loss: 2.862687904132674

Epoch: 6| Step: 12
Training loss: 3.215351569855688
Validation loss: 2.8588482143825487

Epoch: 6| Step: 13
Training loss: 2.715536213115865
Validation loss: 2.8612898223776075

Epoch: 31| Step: 0
Training loss: 2.8391248378092726
Validation loss: 2.8610585326318216

Epoch: 6| Step: 1
Training loss: 3.165301647787202
Validation loss: 2.8628489313403436

Epoch: 6| Step: 2
Training loss: 3.0733314018767515
Validation loss: 2.85898063634798

Epoch: 6| Step: 3
Training loss: 2.924456756225122
Validation loss: 2.8604185720638333

Epoch: 6| Step: 4
Training loss: 2.687870088866652
Validation loss: 2.8558361134247368

Epoch: 6| Step: 5
Training loss: 2.932319455780197
Validation loss: 2.8559040081089138

Epoch: 6| Step: 6
Training loss: 3.225753719760217
Validation loss: 2.8549541976430137

Epoch: 6| Step: 7
Training loss: 3.3121899153766017
Validation loss: 2.8563685443758318

Epoch: 6| Step: 8
Training loss: 2.690531418221866
Validation loss: 2.8548970561515987

Epoch: 6| Step: 9
Training loss: 2.86580647566814
Validation loss: 2.85444497000958

Epoch: 6| Step: 10
Training loss: 2.9276508220128172
Validation loss: 2.8535253673933307

Epoch: 6| Step: 11
Training loss: 3.7170691017129585
Validation loss: 2.8540770736176397

Epoch: 6| Step: 12
Training loss: 3.9168318585128628
Validation loss: 2.870883687800532

Epoch: 6| Step: 13
Training loss: 3.980313254062281
Validation loss: 2.85942221497828

Epoch: 32| Step: 0
Training loss: 2.990090534281235
Validation loss: 2.850878389057774

Epoch: 6| Step: 1
Training loss: 3.5027102467333493
Validation loss: 2.854360354858841

Epoch: 6| Step: 2
Training loss: 2.8032568042604167
Validation loss: 2.8575170012152857

Epoch: 6| Step: 3
Training loss: 3.207217398107073
Validation loss: 2.8693313007537187

Epoch: 6| Step: 4
Training loss: 3.3484122314069316
Validation loss: 2.8766192111622524

Epoch: 6| Step: 5
Training loss: 3.1772478571749563
Validation loss: 2.875775188572674

Epoch: 6| Step: 6
Training loss: 3.757266950759557
Validation loss: 2.8742452953280258

Epoch: 6| Step: 7
Training loss: 3.089631238494389
Validation loss: 2.8699082347418137

Epoch: 6| Step: 8
Training loss: 3.3131931947153057
Validation loss: 2.8617514840023675

Epoch: 6| Step: 9
Training loss: 2.4397549102761933
Validation loss: 2.850599334908687

Epoch: 6| Step: 10
Training loss: 3.1169562003001974
Validation loss: 2.8507127647381942

Epoch: 6| Step: 11
Training loss: 2.8033564817521404
Validation loss: 2.8499903947329757

Epoch: 6| Step: 12
Training loss: 3.5449439350208922
Validation loss: 2.8530631312643613

Epoch: 6| Step: 13
Training loss: 3.048944171698424
Validation loss: 2.847206417679827

Epoch: 33| Step: 0
Training loss: 3.394991124721606
Validation loss: 2.842823935688754

Epoch: 6| Step: 1
Training loss: 3.0959233828386687
Validation loss: 2.857387836434595

Epoch: 6| Step: 2
Training loss: 3.4572116610763683
Validation loss: 2.864732239433711

Epoch: 6| Step: 3
Training loss: 3.5751332931745137
Validation loss: 2.8565306022622283

Epoch: 6| Step: 4
Training loss: 3.054152966338928
Validation loss: 2.8428346588970825

Epoch: 6| Step: 5
Training loss: 2.216001500690379
Validation loss: 2.837821305625469

Epoch: 6| Step: 6
Training loss: 3.268427034546032
Validation loss: 2.8416681251838494

Epoch: 6| Step: 7
Training loss: 3.2079437481711963
Validation loss: 2.838198352804884

Epoch: 6| Step: 8
Training loss: 2.6018341197592063
Validation loss: 2.837019398912558

Epoch: 6| Step: 9
Training loss: 3.5987708801532996
Validation loss: 2.8379121709891737

Epoch: 6| Step: 10
Training loss: 3.577794621969605
Validation loss: 2.8375264431319986

Epoch: 6| Step: 11
Training loss: 2.2766107914082814
Validation loss: 2.8366495344428535

Epoch: 6| Step: 12
Training loss: 3.4177059050720637
Validation loss: 2.8335844193471544

Epoch: 6| Step: 13
Training loss: 2.688245714213828
Validation loss: 2.834045614387959

Epoch: 34| Step: 0
Training loss: 2.3105139580878533
Validation loss: 2.8346433792832584

Epoch: 6| Step: 1
Training loss: 2.907330711992787
Validation loss: 2.834538106517841

Epoch: 6| Step: 2
Training loss: 3.24544381843428
Validation loss: 2.8351403529680606

Epoch: 6| Step: 3
Training loss: 3.3185326686467884
Validation loss: 2.843632786356865

Epoch: 6| Step: 4
Training loss: 2.773099980837897
Validation loss: 2.8431917706643857

Epoch: 6| Step: 5
Training loss: 3.6761288939616263
Validation loss: 2.8557366212866415

Epoch: 6| Step: 6
Training loss: 3.4588299743207624
Validation loss: 2.8491682586532545

Epoch: 6| Step: 7
Training loss: 3.151574779632203
Validation loss: 2.84012490529788

Epoch: 6| Step: 8
Training loss: 3.2285060247796618
Validation loss: 2.8301904279665795

Epoch: 6| Step: 9
Training loss: 3.252894653021709
Validation loss: 2.8327710325397004

Epoch: 6| Step: 10
Training loss: 3.0355178833586915
Validation loss: 2.8294693131283024

Epoch: 6| Step: 11
Training loss: 2.908519883899552
Validation loss: 2.8302652141234446

Epoch: 6| Step: 12
Training loss: 3.0599251646976278
Validation loss: 2.8257339713955187

Epoch: 6| Step: 13
Training loss: 3.5754144388341653
Validation loss: 2.82982811244945

Epoch: 35| Step: 0
Training loss: 3.433881485028663
Validation loss: 2.8284236116002486

Epoch: 6| Step: 1
Training loss: 3.618800814836785
Validation loss: 2.826609030538604

Epoch: 6| Step: 2
Training loss: 3.2813281821972984
Validation loss: 2.826147096353234

Epoch: 6| Step: 3
Training loss: 2.9189356742794206
Validation loss: 2.8239118101506304

Epoch: 6| Step: 4
Training loss: 1.9054491205522082
Validation loss: 2.8245470911403494

Epoch: 6| Step: 5
Training loss: 3.245339206076924
Validation loss: 2.8253144393505503

Epoch: 6| Step: 6
Training loss: 3.161332221660743
Validation loss: 2.8233934098355222

Epoch: 6| Step: 7
Training loss: 3.3602483989086527
Validation loss: 2.8188278275900793

Epoch: 6| Step: 8
Training loss: 3.1054455642314496
Validation loss: 2.821878394328568

Epoch: 6| Step: 9
Training loss: 2.497355588416988
Validation loss: 2.82196355282455

Epoch: 6| Step: 10
Training loss: 3.581892270852131
Validation loss: 2.8325940681159087

Epoch: 6| Step: 11
Training loss: 3.564662879102369
Validation loss: 2.833788947932737

Epoch: 6| Step: 12
Training loss: 2.674394457007029
Validation loss: 2.8192881257561764

Epoch: 6| Step: 13
Training loss: 3.0375913378636463
Validation loss: 2.815988524206728

Epoch: 36| Step: 0
Training loss: 2.581862174311381
Validation loss: 2.8159646318969123

Epoch: 6| Step: 1
Training loss: 3.0392087298126036
Validation loss: 2.8157331671543555

Epoch: 6| Step: 2
Training loss: 2.9999586738283135
Validation loss: 2.813463238897937

Epoch: 6| Step: 3
Training loss: 3.354504412277579
Validation loss: 2.813486875445884

Epoch: 6| Step: 4
Training loss: 3.0508495523424015
Validation loss: 2.815005938196342

Epoch: 6| Step: 5
Training loss: 3.169362543555899
Validation loss: 2.811865937691279

Epoch: 6| Step: 6
Training loss: 3.4719341887640094
Validation loss: 2.8142496698579933

Epoch: 6| Step: 7
Training loss: 3.562088256599313
Validation loss: 2.812058805910953

Epoch: 6| Step: 8
Training loss: 2.2393099832425625
Validation loss: 2.8121969317236357

Epoch: 6| Step: 9
Training loss: 2.3800367854184667
Validation loss: 2.8101067737228544

Epoch: 6| Step: 10
Training loss: 3.710960115062669
Validation loss: 2.8117749800770007

Epoch: 6| Step: 11
Training loss: 3.7006673262626526
Validation loss: 2.810370713226041

Epoch: 6| Step: 12
Training loss: 3.039853814274332
Validation loss: 2.8096419265721213

Epoch: 6| Step: 13
Training loss: 2.833666351793403
Validation loss: 2.8078027656789954

Epoch: 37| Step: 0
Training loss: 2.1247357596869385
Validation loss: 2.807895169443284

Epoch: 6| Step: 1
Training loss: 3.159630202372909
Validation loss: 2.808270963575877

Epoch: 6| Step: 2
Training loss: 3.1619612887074027
Validation loss: 2.80868419361422

Epoch: 6| Step: 3
Training loss: 3.3129760112268176
Validation loss: 2.8099733057419334

Epoch: 6| Step: 4
Training loss: 3.058056000929639
Validation loss: 2.8076929730231583

Epoch: 6| Step: 5
Training loss: 3.254542477472202
Validation loss: 2.808740810325567

Epoch: 6| Step: 6
Training loss: 2.922533583240065
Validation loss: 2.8097745143164987

Epoch: 6| Step: 7
Training loss: 3.830607702982062
Validation loss: 2.80774956772121

Epoch: 6| Step: 8
Training loss: 3.2514909112208747
Validation loss: 2.804680558652318

Epoch: 6| Step: 9
Training loss: 3.1981739019427744
Validation loss: 2.801083825459119

Epoch: 6| Step: 10
Training loss: 3.194869255530893
Validation loss: 2.8011913686076007

Epoch: 6| Step: 11
Training loss: 3.022478607076784
Validation loss: 2.7974521813422264

Epoch: 6| Step: 12
Training loss: 3.002759935496777
Validation loss: 2.7973703044476945

Epoch: 6| Step: 13
Training loss: 2.776799616781047
Validation loss: 2.800939101627345

Epoch: 38| Step: 0
Training loss: 3.2469451926081643
Validation loss: 2.8078266379623096

Epoch: 6| Step: 1
Training loss: 2.9155641015859253
Validation loss: 2.809630316611958

Epoch: 6| Step: 2
Training loss: 3.59283913388732
Validation loss: 2.8053616666879364

Epoch: 6| Step: 3
Training loss: 2.820588919917891
Validation loss: 2.7946276333959443

Epoch: 6| Step: 4
Training loss: 2.996169824144203
Validation loss: 2.7949076209067383

Epoch: 6| Step: 5
Training loss: 2.3616164720038357
Validation loss: 2.7945953334546783

Epoch: 6| Step: 6
Training loss: 3.106797419922171
Validation loss: 2.793644049741112

Epoch: 6| Step: 7
Training loss: 3.1342410970821426
Validation loss: 2.7923802685261365

Epoch: 6| Step: 8
Training loss: 3.5815775510110415
Validation loss: 2.793176033284533

Epoch: 6| Step: 9
Training loss: 3.385254152749973
Validation loss: 2.791991535569428

Epoch: 6| Step: 10
Training loss: 2.9443417677181083
Validation loss: 2.7917628032187567

Epoch: 6| Step: 11
Training loss: 3.318467002052812
Validation loss: 2.7902005851381135

Epoch: 6| Step: 12
Training loss: 3.276686483137631
Validation loss: 2.7914899795543193

Epoch: 6| Step: 13
Training loss: 2.0558902135844948
Validation loss: 2.788868426599617

Epoch: 39| Step: 0
Training loss: 2.8534232143553764
Validation loss: 2.7918903394075167

Epoch: 6| Step: 1
Training loss: 2.1853965455308706
Validation loss: 2.7968068749605104

Epoch: 6| Step: 2
Training loss: 3.5090743006539156
Validation loss: 2.8066735207017017

Epoch: 6| Step: 3
Training loss: 3.2208251189751804
Validation loss: 2.8104289707404133

Epoch: 6| Step: 4
Training loss: 3.0948401177789875
Validation loss: 2.826663235798497

Epoch: 6| Step: 5
Training loss: 3.1902038475604124
Validation loss: 2.812792012905412

Epoch: 6| Step: 6
Training loss: 3.4239891175426918
Validation loss: 2.791267986110799

Epoch: 6| Step: 7
Training loss: 3.196432127345513
Validation loss: 2.783315418211051

Epoch: 6| Step: 8
Training loss: 2.6958535356270708
Validation loss: 2.7863007224981553

Epoch: 6| Step: 9
Training loss: 2.727293774494684
Validation loss: 2.785085934742009

Epoch: 6| Step: 10
Training loss: 3.7490324679576705
Validation loss: 2.784940884929426

Epoch: 6| Step: 11
Training loss: 3.30861752984555
Validation loss: 2.7840261602005976

Epoch: 6| Step: 12
Training loss: 3.138872407252909
Validation loss: 2.783175777062748

Epoch: 6| Step: 13
Training loss: 2.7477411182736553
Validation loss: 2.7822239907740243

Epoch: 40| Step: 0
Training loss: 2.9658593811737743
Validation loss: 2.779235466974454

Epoch: 6| Step: 1
Training loss: 3.1603750334687892
Validation loss: 2.78286582850216

Epoch: 6| Step: 2
Training loss: 3.271568037642922
Validation loss: 2.782436058500053

Epoch: 6| Step: 3
Training loss: 2.1334564019507543
Validation loss: 2.7880047565604476

Epoch: 6| Step: 4
Training loss: 3.040677384398689
Validation loss: 2.792956389653617

Epoch: 6| Step: 5
Training loss: 3.0095422304140387
Validation loss: 2.810237381846608

Epoch: 6| Step: 6
Training loss: 2.5754766560086995
Validation loss: 2.8259897329058314

Epoch: 6| Step: 7
Training loss: 3.7019006177771607
Validation loss: 2.8286512890589592

Epoch: 6| Step: 8
Training loss: 3.096038280358831
Validation loss: 2.8257270454581187

Epoch: 6| Step: 9
Training loss: 2.96185803761307
Validation loss: 2.7883359379140167

Epoch: 6| Step: 10
Training loss: 3.478163858284029
Validation loss: 2.781501715306216

Epoch: 6| Step: 11
Training loss: 3.2887391862506616
Validation loss: 2.7793074107035087

Epoch: 6| Step: 12
Training loss: 3.3211617135519726
Validation loss: 2.7985458071914295

Epoch: 6| Step: 13
Training loss: 3.3215100092360217
Validation loss: 2.810316305008125

Epoch: 41| Step: 0
Training loss: 2.634869414392694
Validation loss: 2.808942281497319

Epoch: 6| Step: 1
Training loss: 2.747571306214482
Validation loss: 2.783650040551889

Epoch: 6| Step: 2
Training loss: 2.8003986687903204
Validation loss: 2.7759585767624024

Epoch: 6| Step: 3
Training loss: 3.2359379479644184
Validation loss: 2.7742957860418613

Epoch: 6| Step: 4
Training loss: 3.4217704861500713
Validation loss: 2.77221615451215

Epoch: 6| Step: 5
Training loss: 2.9900707596281073
Validation loss: 2.7718181101460564

Epoch: 6| Step: 6
Training loss: 3.0313020682041456
Validation loss: 2.7681854466548295

Epoch: 6| Step: 7
Training loss: 3.415489474694016
Validation loss: 2.767323746200819

Epoch: 6| Step: 8
Training loss: 2.981022414631538
Validation loss: 2.768185800428332

Epoch: 6| Step: 9
Training loss: 3.546912911502371
Validation loss: 2.7691523862387473

Epoch: 6| Step: 10
Training loss: 2.7159990445951374
Validation loss: 2.770062876955763

Epoch: 6| Step: 11
Training loss: 3.2491368834924295
Validation loss: 2.770833608433163

Epoch: 6| Step: 12
Training loss: 3.5140366420583202
Validation loss: 2.7888028757128156

Epoch: 6| Step: 13
Training loss: 2.612526458168205
Validation loss: 2.8103756382288525

Epoch: 42| Step: 0
Training loss: 3.267443283044123
Validation loss: 2.8370254026819945

Epoch: 6| Step: 1
Training loss: 3.034465853649992
Validation loss: 2.7962277717005164

Epoch: 6| Step: 2
Training loss: 3.567609636189945
Validation loss: 2.788451370040542

Epoch: 6| Step: 3
Training loss: 3.315958772446727
Validation loss: 2.7760739657727047

Epoch: 6| Step: 4
Training loss: 3.7422201198995833
Validation loss: 2.764162923317599

Epoch: 6| Step: 5
Training loss: 3.3671605934431064
Validation loss: 2.7614981964471372

Epoch: 6| Step: 6
Training loss: 2.4666178707073323
Validation loss: 2.7634691860444955

Epoch: 6| Step: 7
Training loss: 3.6718743506897695
Validation loss: 2.765642422273076

Epoch: 6| Step: 8
Training loss: 3.1096497994147185
Validation loss: 2.7693439847696784

Epoch: 6| Step: 9
Training loss: 2.7131669169511636
Validation loss: 2.772764952089549

Epoch: 6| Step: 10
Training loss: 1.9520959203009631
Validation loss: 2.7747015298392412

Epoch: 6| Step: 11
Training loss: 2.204127739584806
Validation loss: 2.7888940273283276

Epoch: 6| Step: 12
Training loss: 3.425559372714362
Validation loss: 2.7866771637754724

Epoch: 6| Step: 13
Training loss: 2.797176579247496
Validation loss: 2.7743504358662543

Epoch: 43| Step: 0
Training loss: 3.622146009125775
Validation loss: 2.769302823193153

Epoch: 6| Step: 1
Training loss: 2.8683461023371932
Validation loss: 2.765470497316556

Epoch: 6| Step: 2
Training loss: 3.1627194415165993
Validation loss: 2.762729232543257

Epoch: 6| Step: 3
Training loss: 2.621350066931328
Validation loss: 2.760915112589349

Epoch: 6| Step: 4
Training loss: 2.553868340333123
Validation loss: 2.760740153853003

Epoch: 6| Step: 5
Training loss: 3.916521164376092
Validation loss: 2.758065313286226

Epoch: 6| Step: 6
Training loss: 3.597717483446726
Validation loss: 2.7557366963636163

Epoch: 6| Step: 7
Training loss: 2.804753974828089
Validation loss: 2.754256300423065

Epoch: 6| Step: 8
Training loss: 2.2362903841657085
Validation loss: 2.7535484917658226

Epoch: 6| Step: 9
Training loss: 3.2548221613386064
Validation loss: 2.752538348546601

Epoch: 6| Step: 10
Training loss: 2.9834644466408706
Validation loss: 2.7550205871034374

Epoch: 6| Step: 11
Training loss: 2.5405017705594735
Validation loss: 2.753504695691447

Epoch: 6| Step: 12
Training loss: 3.349309275004162
Validation loss: 2.763939861049444

Epoch: 6| Step: 13
Training loss: 3.245491421817626
Validation loss: 2.7612461217631314

Epoch: 44| Step: 0
Training loss: 2.9138000206436154
Validation loss: 2.7672908144415027

Epoch: 6| Step: 1
Training loss: 2.5987652927992757
Validation loss: 2.7715169313321457

Epoch: 6| Step: 2
Training loss: 3.0947636956887874
Validation loss: 2.7912877272095535

Epoch: 6| Step: 3
Training loss: 3.0710524426935346
Validation loss: 2.7737772055154717

Epoch: 6| Step: 4
Training loss: 3.2869605372386594
Validation loss: 2.7610403986515943

Epoch: 6| Step: 5
Training loss: 3.0922629125033896
Validation loss: 2.7476377903865203

Epoch: 6| Step: 6
Training loss: 2.6334036777452403
Validation loss: 2.750024955763061

Epoch: 6| Step: 7
Training loss: 2.8838209750498893
Validation loss: 2.754374018005604

Epoch: 6| Step: 8
Training loss: 3.2921635377479874
Validation loss: 2.752197068498698

Epoch: 6| Step: 9
Training loss: 3.0816113242720657
Validation loss: 2.7541729876648464

Epoch: 6| Step: 10
Training loss: 3.2894629010475502
Validation loss: 2.756261995384461

Epoch: 6| Step: 11
Training loss: 3.3111811477570536
Validation loss: 2.755950534358486

Epoch: 6| Step: 12
Training loss: 3.2549491758817437
Validation loss: 2.7536214985712872

Epoch: 6| Step: 13
Training loss: 3.4682172761411483
Validation loss: 2.751350520549089

Epoch: 45| Step: 0
Training loss: 2.7577952959858654
Validation loss: 2.7515738338153115

Epoch: 6| Step: 1
Training loss: 3.592310874383353
Validation loss: 2.755039290775599

Epoch: 6| Step: 2
Training loss: 2.966156639947985
Validation loss: 2.7533604104435954

Epoch: 6| Step: 3
Training loss: 2.8036469040656673
Validation loss: 2.7516292796401207

Epoch: 6| Step: 4
Training loss: 3.182764762179585
Validation loss: 2.748573143740253

Epoch: 6| Step: 5
Training loss: 2.969737641534332
Validation loss: 2.7466271291660442

Epoch: 6| Step: 6
Training loss: 2.326873237963718
Validation loss: 2.7483180534165736

Epoch: 6| Step: 7
Training loss: 2.6916420532927847
Validation loss: 2.7538801936878605

Epoch: 6| Step: 8
Training loss: 2.8056343201847658
Validation loss: 2.747403485189767

Epoch: 6| Step: 9
Training loss: 2.58872738535907
Validation loss: 2.7447870231166194

Epoch: 6| Step: 10
Training loss: 3.4623625084195724
Validation loss: 2.7538806703185776

Epoch: 6| Step: 11
Training loss: 3.5646323799104795
Validation loss: 2.7471949701561096

Epoch: 6| Step: 12
Training loss: 3.4153832296816735
Validation loss: 2.747529058001841

Epoch: 6| Step: 13
Training loss: 3.961434177054535
Validation loss: 2.7498254674004547

Epoch: 46| Step: 0
Training loss: 2.9896143115274008
Validation loss: 2.7442989264730846

Epoch: 6| Step: 1
Training loss: 2.4555733483975493
Validation loss: 2.74110296306425

Epoch: 6| Step: 2
Training loss: 2.591616200960523
Validation loss: 2.740069395157647

Epoch: 6| Step: 3
Training loss: 3.0000133514107197
Validation loss: 2.74110715956722

Epoch: 6| Step: 4
Training loss: 2.809148359651153
Validation loss: 2.74041687423285

Epoch: 6| Step: 5
Training loss: 2.8126502102899917
Validation loss: 2.7387504407969456

Epoch: 6| Step: 6
Training loss: 3.055978799656535
Validation loss: 2.742994887681155

Epoch: 6| Step: 7
Training loss: 2.939558403689849
Validation loss: 2.7456902324032497

Epoch: 6| Step: 8
Training loss: 3.553914214481898
Validation loss: 2.7484411051636988

Epoch: 6| Step: 9
Training loss: 2.99998442327906
Validation loss: 2.7386383825040705

Epoch: 6| Step: 10
Training loss: 3.3356670475483026
Validation loss: 2.7343089162221403

Epoch: 6| Step: 11
Training loss: 2.8872334146673153
Validation loss: 2.7352924070123126

Epoch: 6| Step: 12
Training loss: 3.5462518220183488
Validation loss: 2.733819011645005

Epoch: 6| Step: 13
Training loss: 3.9986294544172143
Validation loss: 2.7286339701562676

Epoch: 47| Step: 0
Training loss: 3.1415561794884135
Validation loss: 2.732930358759164

Epoch: 6| Step: 1
Training loss: 2.8911572765320193
Validation loss: 2.7305939176956517

Epoch: 6| Step: 2
Training loss: 3.1150396686801876
Validation loss: 2.7288343979876655

Epoch: 6| Step: 3
Training loss: 3.7208920248143653
Validation loss: 2.7297179520044663

Epoch: 6| Step: 4
Training loss: 3.181896295455617
Validation loss: 2.730757368025539

Epoch: 6| Step: 5
Training loss: 2.4215900868828233
Validation loss: 2.7299896927418525

Epoch: 6| Step: 6
Training loss: 3.5777449093632443
Validation loss: 2.7256315478841135

Epoch: 6| Step: 7
Training loss: 3.133198321930538
Validation loss: 2.730125661424468

Epoch: 6| Step: 8
Training loss: 2.9108112596544378
Validation loss: 2.732758041892992

Epoch: 6| Step: 9
Training loss: 3.2294013809712387
Validation loss: 2.7305749057498403

Epoch: 6| Step: 10
Training loss: 2.273860197327656
Validation loss: 2.7274668510955675

Epoch: 6| Step: 11
Training loss: 3.126420270514785
Validation loss: 2.7251274473460674

Epoch: 6| Step: 12
Training loss: 2.699883076997144
Validation loss: 2.724826466804833

Epoch: 6| Step: 13
Training loss: 2.974469587982702
Validation loss: 2.730794382862196

Epoch: 48| Step: 0
Training loss: 3.153479238068905
Validation loss: 2.7315985271615504

Epoch: 6| Step: 1
Training loss: 3.1097019349557566
Validation loss: 2.7475572384781053

Epoch: 6| Step: 2
Training loss: 2.868483248008258
Validation loss: 2.747500267934631

Epoch: 6| Step: 3
Training loss: 3.182585873819948
Validation loss: 2.7629410401252463

Epoch: 6| Step: 4
Training loss: 3.498658740675291
Validation loss: 2.7688184640389513

Epoch: 6| Step: 5
Training loss: 2.619190690645185
Validation loss: 2.7700319944072316

Epoch: 6| Step: 6
Training loss: 2.806023154828657
Validation loss: 2.769290764542382

Epoch: 6| Step: 7
Training loss: 2.6731029165130376
Validation loss: 2.763161821794594

Epoch: 6| Step: 8
Training loss: 3.235937063824059
Validation loss: 2.763771453342417

Epoch: 6| Step: 9
Training loss: 3.2017856682090584
Validation loss: 2.745971852491119

Epoch: 6| Step: 10
Training loss: 2.8327809150563548
Validation loss: 2.7292212059910814

Epoch: 6| Step: 11
Training loss: 3.498406319864751
Validation loss: 2.7158340547147466

Epoch: 6| Step: 12
Training loss: 2.958401441909414
Validation loss: 2.720641838509299

Epoch: 6| Step: 13
Training loss: 3.0254101687958155
Validation loss: 2.7200662088117467

Epoch: 49| Step: 0
Training loss: 3.126312590547906
Validation loss: 2.7185650909837658

Epoch: 6| Step: 1
Training loss: 2.97296068835708
Validation loss: 2.717816896275995

Epoch: 6| Step: 2
Training loss: 2.782988272957145
Validation loss: 2.7184367684836626

Epoch: 6| Step: 3
Training loss: 2.9329978042942884
Validation loss: 2.719189177578746

Epoch: 6| Step: 4
Training loss: 3.2955235608566253
Validation loss: 2.721021920068577

Epoch: 6| Step: 5
Training loss: 3.298393586777645
Validation loss: 2.739724763416605

Epoch: 6| Step: 6
Training loss: 2.719417095555518
Validation loss: 2.766596449301811

Epoch: 6| Step: 7
Training loss: 2.666623492686136
Validation loss: 2.7685869208567873

Epoch: 6| Step: 8
Training loss: 3.141151953372719
Validation loss: 2.7619117061039313

Epoch: 6| Step: 9
Training loss: 2.626535057637073
Validation loss: 2.7322346353723126

Epoch: 6| Step: 10
Training loss: 3.661136980275702
Validation loss: 2.7169160221768527

Epoch: 6| Step: 11
Training loss: 2.7441730320873354
Validation loss: 2.7105670243285913

Epoch: 6| Step: 12
Training loss: 3.4480495523312933
Validation loss: 2.7081647320338176

Epoch: 6| Step: 13
Training loss: 3.154103068252706
Validation loss: 2.7101973294815815

Epoch: 50| Step: 0
Training loss: 2.97056347520626
Validation loss: 2.7070671497868286

Epoch: 6| Step: 1
Training loss: 2.6389416628016638
Validation loss: 2.7080192181825056

Epoch: 6| Step: 2
Training loss: 2.9512248712978137
Validation loss: 2.7057975395543084

Epoch: 6| Step: 3
Training loss: 2.6997251794611796
Validation loss: 2.7052846230692964

Epoch: 6| Step: 4
Training loss: 3.110030368767051
Validation loss: 2.706700356327996

Epoch: 6| Step: 5
Training loss: 2.718206504780425
Validation loss: 2.704601652003874

Epoch: 6| Step: 6
Training loss: 3.550803542198313
Validation loss: 2.7056498944010197

Epoch: 6| Step: 7
Training loss: 3.4102345530815397
Validation loss: 2.7040573258292504

Epoch: 6| Step: 8
Training loss: 2.711145134705401
Validation loss: 2.7078241316051894

Epoch: 6| Step: 9
Training loss: 3.216919017110391
Validation loss: 2.7067442827125148

Epoch: 6| Step: 10
Training loss: 3.0194785050576005
Validation loss: 2.6995155419788115

Epoch: 6| Step: 11
Training loss: 3.0722311688508075
Validation loss: 2.7032063220811366

Epoch: 6| Step: 12
Training loss: 2.87588155748216
Validation loss: 2.707605562012337

Epoch: 6| Step: 13
Training loss: 3.5115894807269745
Validation loss: 2.704048539085054

Epoch: 51| Step: 0
Training loss: 2.6277715492936404
Validation loss: 2.7140062063758315

Epoch: 6| Step: 1
Training loss: 2.98194842524609
Validation loss: 2.712928938196639

Epoch: 6| Step: 2
Training loss: 2.8437583839376757
Validation loss: 2.7199285939589832

Epoch: 6| Step: 3
Training loss: 3.016341840703004
Validation loss: 2.727727259781659

Epoch: 6| Step: 4
Training loss: 3.9268233856592842
Validation loss: 2.70941531731874

Epoch: 6| Step: 5
Training loss: 3.1895326603295024
Validation loss: 2.705849939386167

Epoch: 6| Step: 6
Training loss: 2.7570892336534705
Validation loss: 2.699455838607754

Epoch: 6| Step: 7
Training loss: 3.118644813491476
Validation loss: 2.6943457787697165

Epoch: 6| Step: 8
Training loss: 2.4292426484026075
Validation loss: 2.6961071672109673

Epoch: 6| Step: 9
Training loss: 3.511667966210249
Validation loss: 2.694531659074062

Epoch: 6| Step: 10
Training loss: 3.0484062846280295
Validation loss: 2.695210123161311

Epoch: 6| Step: 11
Training loss: 2.5489516889648973
Validation loss: 2.6933051577864684

Epoch: 6| Step: 12
Training loss: 3.1943801228409967
Validation loss: 2.69395964729142

Epoch: 6| Step: 13
Training loss: 2.6804121722501884
Validation loss: 2.6936003257096757

Epoch: 52| Step: 0
Training loss: 3.6536719207303623
Validation loss: 2.69445258891581

Epoch: 6| Step: 1
Training loss: 3.1472665582915647
Validation loss: 2.6941493128952154

Epoch: 6| Step: 2
Training loss: 3.193157037980071
Validation loss: 2.690301452371385

Epoch: 6| Step: 3
Training loss: 2.863454774435814
Validation loss: 2.691713497138375

Epoch: 6| Step: 4
Training loss: 3.4418798114333597
Validation loss: 2.702444206687055

Epoch: 6| Step: 5
Training loss: 3.303387758311563
Validation loss: 2.6928492274159073

Epoch: 6| Step: 6
Training loss: 1.8781185283327235
Validation loss: 2.690070738769022

Epoch: 6| Step: 7
Training loss: 3.2168939664973433
Validation loss: 2.690206903945947

Epoch: 6| Step: 8
Training loss: 3.0604110132575917
Validation loss: 2.6877064436013764

Epoch: 6| Step: 9
Training loss: 2.4100961043953983
Validation loss: 2.689727662191908

Epoch: 6| Step: 10
Training loss: 2.4530396659247273
Validation loss: 2.6881549682895276

Epoch: 6| Step: 11
Training loss: 3.1640350717368264
Validation loss: 2.689143539439034

Epoch: 6| Step: 12
Training loss: 2.974882838402494
Validation loss: 2.687635952028449

Epoch: 6| Step: 13
Training loss: 3.193808502437825
Validation loss: 2.691066058733921

Epoch: 53| Step: 0
Training loss: 2.9788250671737595
Validation loss: 2.691456254413946

Epoch: 6| Step: 1
Training loss: 3.163106288767889
Validation loss: 2.694822153908779

Epoch: 6| Step: 2
Training loss: 2.7343715994677518
Validation loss: 2.691206809854046

Epoch: 6| Step: 3
Training loss: 2.94532286138761
Validation loss: 2.6958481940966332

Epoch: 6| Step: 4
Training loss: 2.985919333122718
Validation loss: 2.703732535778257

Epoch: 6| Step: 5
Training loss: 2.6335996815024236
Validation loss: 2.713885860230316

Epoch: 6| Step: 6
Training loss: 3.430992764417801
Validation loss: 2.7164139339472557

Epoch: 6| Step: 7
Training loss: 3.560897198892996
Validation loss: 2.72441514892676

Epoch: 6| Step: 8
Training loss: 2.9645378346994087
Validation loss: 2.68652094592717

Epoch: 6| Step: 9
Training loss: 3.031335888461844
Validation loss: 2.6864129157487784

Epoch: 6| Step: 10
Training loss: 3.4095066845827353
Validation loss: 2.6896586161403073

Epoch: 6| Step: 11
Training loss: 3.1678079924147298
Validation loss: 2.6971864791102607

Epoch: 6| Step: 12
Training loss: 2.610069502274156
Validation loss: 2.7089229525644556

Epoch: 6| Step: 13
Training loss: 2.5521457171438398
Validation loss: 2.7277475453191986

Epoch: 54| Step: 0
Training loss: 2.55068992930305
Validation loss: 2.6995107167168313

Epoch: 6| Step: 1
Training loss: 3.0128738424614427
Validation loss: 2.690784279069616

Epoch: 6| Step: 2
Training loss: 3.0111696210230776
Validation loss: 2.689748446859487

Epoch: 6| Step: 3
Training loss: 2.741922827660669
Validation loss: 2.6862835240291973

Epoch: 6| Step: 4
Training loss: 2.742982232982296
Validation loss: 2.6845057258098346

Epoch: 6| Step: 5
Training loss: 3.7322517008890306
Validation loss: 2.6937515130495715

Epoch: 6| Step: 6
Training loss: 3.4803802444730323
Validation loss: 2.70734176437564

Epoch: 6| Step: 7
Training loss: 3.0872154197353256
Validation loss: 2.704680485173454

Epoch: 6| Step: 8
Training loss: 3.2312140752392766
Validation loss: 2.7040690799985185

Epoch: 6| Step: 9
Training loss: 2.9411762041203997
Validation loss: 2.682569159970131

Epoch: 6| Step: 10
Training loss: 3.0909267606077173
Validation loss: 2.680470491210406

Epoch: 6| Step: 11
Training loss: 3.0134304145208297
Validation loss: 2.6752206834201013

Epoch: 6| Step: 12
Training loss: 2.702671784791145
Validation loss: 2.6782709881004165

Epoch: 6| Step: 13
Training loss: 2.6737807766363364
Validation loss: 2.6808590762212083

Epoch: 55| Step: 0
Training loss: 2.8956685373815403
Validation loss: 2.680532879309937

Epoch: 6| Step: 1
Training loss: 3.3789735644035437
Validation loss: 2.679885731120448

Epoch: 6| Step: 2
Training loss: 3.0889777164661947
Validation loss: 2.6801952831786795

Epoch: 6| Step: 3
Training loss: 2.734790879367128
Validation loss: 2.6776763181386145

Epoch: 6| Step: 4
Training loss: 3.033509032083058
Validation loss: 2.6772237723077175

Epoch: 6| Step: 5
Training loss: 2.729826015196241
Validation loss: 2.676795022393707

Epoch: 6| Step: 6
Training loss: 2.9181922918891767
Validation loss: 2.6724930980032306

Epoch: 6| Step: 7
Training loss: 2.905153293209062
Validation loss: 2.6740667668594553

Epoch: 6| Step: 8
Training loss: 3.2501286701260748
Validation loss: 2.674632618927145

Epoch: 6| Step: 9
Training loss: 2.5841351362033382
Validation loss: 2.6729057342160196

Epoch: 6| Step: 10
Training loss: 3.6754338326287725
Validation loss: 2.674551087506867

Epoch: 6| Step: 11
Training loss: 2.915399076125135
Validation loss: 2.6798710985733356

Epoch: 6| Step: 12
Training loss: 3.0563451459619406
Validation loss: 2.6959622858204844

Epoch: 6| Step: 13
Training loss: 2.8644587449232337
Validation loss: 2.687267746539715

Epoch: 56| Step: 0
Training loss: 2.6319389365571118
Validation loss: 2.688282342637274

Epoch: 6| Step: 1
Training loss: 3.065644498835001
Validation loss: 2.7033417744198314

Epoch: 6| Step: 2
Training loss: 2.6224998193382585
Validation loss: 2.7084793919129866

Epoch: 6| Step: 3
Training loss: 3.0628120107721397
Validation loss: 2.7097489329368085

Epoch: 6| Step: 4
Training loss: 2.663720788603083
Validation loss: 2.697450956254798

Epoch: 6| Step: 5
Training loss: 3.5231706133331517
Validation loss: 2.685860450671903

Epoch: 6| Step: 6
Training loss: 2.671204956988739
Validation loss: 2.6874709884935886

Epoch: 6| Step: 7
Training loss: 2.8928168157763934
Validation loss: 2.673703711385735

Epoch: 6| Step: 8
Training loss: 3.080743131286151
Validation loss: 2.6684198890673083

Epoch: 6| Step: 9
Training loss: 2.7989070053325302
Validation loss: 2.6622365722333643

Epoch: 6| Step: 10
Training loss: 2.8358460298609525
Validation loss: 2.6655720827967593

Epoch: 6| Step: 11
Training loss: 3.5058744722429114
Validation loss: 2.6634902154176996

Epoch: 6| Step: 12
Training loss: 3.356072368218936
Validation loss: 2.6646685427129424

Epoch: 6| Step: 13
Training loss: 3.112236354952714
Validation loss: 2.6638190064640392

Epoch: 57| Step: 0
Training loss: 2.5871748715380583
Validation loss: 2.6656179352726697

Epoch: 6| Step: 1
Training loss: 2.835370808458739
Validation loss: 2.665395870997258

Epoch: 6| Step: 2
Training loss: 3.3949658430625664
Validation loss: 2.6648451883777278

Epoch: 6| Step: 3
Training loss: 2.8499122338416996
Validation loss: 2.6618820860318744

Epoch: 6| Step: 4
Training loss: 3.6424037533665956
Validation loss: 2.664284125979574

Epoch: 6| Step: 5
Training loss: 2.5221456049272044
Validation loss: 2.6683869145650903

Epoch: 6| Step: 6
Training loss: 3.2033048253638334
Validation loss: 2.6753700356540904

Epoch: 6| Step: 7
Training loss: 3.238295533225813
Validation loss: 2.6704672138039536

Epoch: 6| Step: 8
Training loss: 3.6007293598113455
Validation loss: 2.6870603046703128

Epoch: 6| Step: 9
Training loss: 2.8398971447654016
Validation loss: 2.701679600832219

Epoch: 6| Step: 10
Training loss: 2.920482772998391
Validation loss: 2.715439205950156

Epoch: 6| Step: 11
Training loss: 2.631205172847814
Validation loss: 2.7242689814153436

Epoch: 6| Step: 12
Training loss: 2.277564533713746
Validation loss: 2.6973324557030804

Epoch: 6| Step: 13
Training loss: 3.206529399157084
Validation loss: 2.6896162064735036

Epoch: 58| Step: 0
Training loss: 2.8860903250768075
Validation loss: 2.668205260236231

Epoch: 6| Step: 1
Training loss: 3.214862587040424
Validation loss: 2.664976867705906

Epoch: 6| Step: 2
Training loss: 3.139877002518153
Validation loss: 2.6609879301094876

Epoch: 6| Step: 3
Training loss: 3.815355326052619
Validation loss: 2.659997868821941

Epoch: 6| Step: 4
Training loss: 3.2066987733033296
Validation loss: 2.6577073666166324

Epoch: 6| Step: 5
Training loss: 2.567506412100655
Validation loss: 2.6557396656061147

Epoch: 6| Step: 6
Training loss: 2.4871609020572367
Validation loss: 2.658342897537662

Epoch: 6| Step: 7
Training loss: 3.633007019741796
Validation loss: 2.6596697080979443

Epoch: 6| Step: 8
Training loss: 3.3169515675875028
Validation loss: 2.653428001141354

Epoch: 6| Step: 9
Training loss: 3.000467264025761
Validation loss: 2.6582405666531668

Epoch: 6| Step: 10
Training loss: 1.8534791579040726
Validation loss: 2.654281662890121

Epoch: 6| Step: 11
Training loss: 2.655768317137073
Validation loss: 2.650326591987303

Epoch: 6| Step: 12
Training loss: 2.7538293706024306
Validation loss: 2.6514270909333946

Epoch: 6| Step: 13
Training loss: 2.894971559216829
Validation loss: 2.654134681408352

Epoch: 59| Step: 0
Training loss: 2.505559842410747
Validation loss: 2.6551812605451484

Epoch: 6| Step: 1
Training loss: 2.579689152495827
Validation loss: 2.666799590684359

Epoch: 6| Step: 2
Training loss: 3.510020081769657
Validation loss: 2.682172219499758

Epoch: 6| Step: 3
Training loss: 3.026201586456216
Validation loss: 2.676026541545734

Epoch: 6| Step: 4
Training loss: 2.7115901634086286
Validation loss: 2.654935698148745

Epoch: 6| Step: 5
Training loss: 2.7653165311177217
Validation loss: 2.6490300295803584

Epoch: 6| Step: 6
Training loss: 2.8989806784452745
Validation loss: 2.6486038851238303

Epoch: 6| Step: 7
Training loss: 3.4227454066990712
Validation loss: 2.6501599184054747

Epoch: 6| Step: 8
Training loss: 3.5315615086173917
Validation loss: 2.64911120936965

Epoch: 6| Step: 9
Training loss: 2.7104679987330162
Validation loss: 2.6490351248623347

Epoch: 6| Step: 10
Training loss: 3.0180797962335433
Validation loss: 2.6462890359170013

Epoch: 6| Step: 11
Training loss: 3.3504804807526183
Validation loss: 2.6491135754834367

Epoch: 6| Step: 12
Training loss: 2.5175956447278787
Validation loss: 2.649014503668314

Epoch: 6| Step: 13
Training loss: 3.072979649474826
Validation loss: 2.6489697603125033

Epoch: 60| Step: 0
Training loss: 3.0397305183429513
Validation loss: 2.6498028675093055

Epoch: 6| Step: 1
Training loss: 2.4693685794825058
Validation loss: 2.6476625332380626

Epoch: 6| Step: 2
Training loss: 2.7745522421371245
Validation loss: 2.6523199899966556

Epoch: 6| Step: 3
Training loss: 3.4662423907367375
Validation loss: 2.6562576583375503

Epoch: 6| Step: 4
Training loss: 2.994219933819986
Validation loss: 2.6579153005403438

Epoch: 6| Step: 5
Training loss: 3.2288260659692134
Validation loss: 2.6705535871813035

Epoch: 6| Step: 6
Training loss: 2.803410571467254
Validation loss: 2.664834177047138

Epoch: 6| Step: 7
Training loss: 2.928744314320899
Validation loss: 2.6799666276897818

Epoch: 6| Step: 8
Training loss: 2.6367992247557197
Validation loss: 2.681641896475829

Epoch: 6| Step: 9
Training loss: 2.933841131068387
Validation loss: 2.6865990214268543

Epoch: 6| Step: 10
Training loss: 3.1459475532326393
Validation loss: 2.686555953697247

Epoch: 6| Step: 11
Training loss: 3.4375056873621275
Validation loss: 2.689545328394673

Epoch: 6| Step: 12
Training loss: 2.993700725492359
Validation loss: 2.695683852941653

Epoch: 6| Step: 13
Training loss: 2.672477788021038
Validation loss: 2.6527979782584676

Epoch: 61| Step: 0
Training loss: 3.0576107935197436
Validation loss: 2.6403079375603173

Epoch: 6| Step: 1
Training loss: 3.6489701790943596
Validation loss: 2.6477257176262077

Epoch: 6| Step: 2
Training loss: 2.8332229106553553
Validation loss: 2.6553745658512655

Epoch: 6| Step: 3
Training loss: 2.6622930562720484
Validation loss: 2.6801677928647516

Epoch: 6| Step: 4
Training loss: 3.376895795945561
Validation loss: 2.680735152445979

Epoch: 6| Step: 5
Training loss: 2.831647333891556
Validation loss: 2.6784715168372615

Epoch: 6| Step: 6
Training loss: 2.7984290893360138
Validation loss: 2.6826774395419335

Epoch: 6| Step: 7
Training loss: 3.5352472957457497
Validation loss: 2.670995296284672

Epoch: 6| Step: 8
Training loss: 2.7775590386626954
Validation loss: 2.6643574696039463

Epoch: 6| Step: 9
Training loss: 3.1036992243816486
Validation loss: 2.658641499626172

Epoch: 6| Step: 10
Training loss: 2.2309745041481714
Validation loss: 2.654079197825017

Epoch: 6| Step: 11
Training loss: 3.3872872373761296
Validation loss: 2.650994861287187

Epoch: 6| Step: 12
Training loss: 3.2922975120757267
Validation loss: 2.6501731401558137

Epoch: 6| Step: 13
Training loss: 1.7986741056993019
Validation loss: 2.6462270999043738

Epoch: 62| Step: 0
Training loss: 3.452221091880432
Validation loss: 2.644816815635962

Epoch: 6| Step: 1
Training loss: 2.8182257966276563
Validation loss: 2.6441826942916027

Epoch: 6| Step: 2
Training loss: 3.2432483086675314
Validation loss: 2.6415656969297188

Epoch: 6| Step: 3
Training loss: 2.777294045820403
Validation loss: 2.6497117986545367

Epoch: 6| Step: 4
Training loss: 2.6289396241380825
Validation loss: 2.6661642649850013

Epoch: 6| Step: 5
Training loss: 3.5293275444416587
Validation loss: 2.7022290669995153

Epoch: 6| Step: 6
Training loss: 3.6133852392130694
Validation loss: 2.654414016915651

Epoch: 6| Step: 7
Training loss: 1.9826320893779195
Validation loss: 2.63453389167655

Epoch: 6| Step: 8
Training loss: 3.2433926835727918
Validation loss: 2.6327323279399453

Epoch: 6| Step: 9
Training loss: 2.7786569401460355
Validation loss: 2.632587095918531

Epoch: 6| Step: 10
Training loss: 2.9186656278059733
Validation loss: 2.6314925119467447

Epoch: 6| Step: 11
Training loss: 3.008009708429456
Validation loss: 2.6353123816199555

Epoch: 6| Step: 12
Training loss: 3.1761454881260027
Validation loss: 2.6401708748439683

Epoch: 6| Step: 13
Training loss: 1.3068727478124695
Validation loss: 2.6449743563605397

Epoch: 63| Step: 0
Training loss: 2.9352690970746127
Validation loss: 2.644755631272886

Epoch: 6| Step: 1
Training loss: 3.441730462345861
Validation loss: 2.6684251000812447

Epoch: 6| Step: 2
Training loss: 2.897053596398464
Validation loss: 2.675917077919119

Epoch: 6| Step: 3
Training loss: 3.1464111774248953
Validation loss: 2.6304982639114773

Epoch: 6| Step: 4
Training loss: 2.9712099825451546
Validation loss: 2.6298366060176943

Epoch: 6| Step: 5
Training loss: 2.5324373639298137
Validation loss: 2.6280601593060995

Epoch: 6| Step: 6
Training loss: 3.0286920510611726
Validation loss: 2.6296454741247293

Epoch: 6| Step: 7
Training loss: 2.722087784343144
Validation loss: 2.6304511872009297

Epoch: 6| Step: 8
Training loss: 2.9868791070667613
Validation loss: 2.6592853284095472

Epoch: 6| Step: 9
Training loss: 3.0331392987690666
Validation loss: 2.681704259235331

Epoch: 6| Step: 10
Training loss: 3.3164522596926242
Validation loss: 2.679370257793903

Epoch: 6| Step: 11
Training loss: 2.940123989059802
Validation loss: 2.662611058389799

Epoch: 6| Step: 12
Training loss: 2.987520327957776
Validation loss: 2.643928734386956

Epoch: 6| Step: 13
Training loss: 2.6800714779332013
Validation loss: 2.6321186748245533

Epoch: 64| Step: 0
Training loss: 3.0062587936177585
Validation loss: 2.627221007297165

Epoch: 6| Step: 1
Training loss: 3.2157623350661164
Validation loss: 2.6241059140587017

Epoch: 6| Step: 2
Training loss: 2.888851302057264
Validation loss: 2.6258595334363943

Epoch: 6| Step: 3
Training loss: 2.413809852588966
Validation loss: 2.6279810899526237

Epoch: 6| Step: 4
Training loss: 2.9477488511556995
Validation loss: 2.62530169923788

Epoch: 6| Step: 5
Training loss: 2.470616854039762
Validation loss: 2.62766267356925

Epoch: 6| Step: 6
Training loss: 3.258412550591701
Validation loss: 2.6263374265511046

Epoch: 6| Step: 7
Training loss: 2.632778269378272
Validation loss: 2.6339526325447657

Epoch: 6| Step: 8
Training loss: 3.593052804738834
Validation loss: 2.646204430101078

Epoch: 6| Step: 9
Training loss: 2.576624300593214
Validation loss: 2.6507992646416834

Epoch: 6| Step: 10
Training loss: 3.354985549827418
Validation loss: 2.661113684830944

Epoch: 6| Step: 11
Training loss: 3.1744416474317525
Validation loss: 2.643854932647575

Epoch: 6| Step: 12
Training loss: 3.2500413745300576
Validation loss: 2.63344524914688

Epoch: 6| Step: 13
Training loss: 2.447982938694559
Validation loss: 2.629849793469524

Epoch: 65| Step: 0
Training loss: 3.3371379755958643
Validation loss: 2.6283033771563344

Epoch: 6| Step: 1
Training loss: 3.2286989098854977
Validation loss: 2.6243160077417875

Epoch: 6| Step: 2
Training loss: 2.8627806013745527
Validation loss: 2.633856268669053

Epoch: 6| Step: 3
Training loss: 2.7157848455972506
Validation loss: 2.632570347300559

Epoch: 6| Step: 4
Training loss: 2.8500788761400493
Validation loss: 2.6255787740212773

Epoch: 6| Step: 5
Training loss: 3.1112269728142925
Validation loss: 2.6342680610033127

Epoch: 6| Step: 6
Training loss: 2.433018991555356
Validation loss: 2.627048784770959

Epoch: 6| Step: 7
Training loss: 2.9822117819542524
Validation loss: 2.6208016749827556

Epoch: 6| Step: 8
Training loss: 3.64742459402911
Validation loss: 2.6199149419561625

Epoch: 6| Step: 9
Training loss: 3.124812921646364
Validation loss: 2.618538417399444

Epoch: 6| Step: 10
Training loss: 2.6772368766797157
Validation loss: 2.6183794447104587

Epoch: 6| Step: 11
Training loss: 2.6472936089803936
Validation loss: 2.6166652216481796

Epoch: 6| Step: 12
Training loss: 2.8158192016150614
Validation loss: 2.6144686352922393

Epoch: 6| Step: 13
Training loss: 2.8342057923066437
Validation loss: 2.61939157688602

Epoch: 66| Step: 0
Training loss: 2.3352560114552934
Validation loss: 2.617995396142273

Epoch: 6| Step: 1
Training loss: 3.2240317258764697
Validation loss: 2.628744697735729

Epoch: 6| Step: 2
Training loss: 3.1213780585170863
Validation loss: 2.651007046070434

Epoch: 6| Step: 3
Training loss: 3.005984377477155
Validation loss: 2.729755757609648

Epoch: 6| Step: 4
Training loss: 2.908457584149858
Validation loss: 2.829368912853958

Epoch: 6| Step: 5
Training loss: 3.139152523286042
Validation loss: 2.896587938062289

Epoch: 6| Step: 6
Training loss: 3.2666960059684396
Validation loss: 2.7853164874132292

Epoch: 6| Step: 7
Training loss: 2.9058627619199915
Validation loss: 2.6634576775091543

Epoch: 6| Step: 8
Training loss: 2.3894700395709765
Validation loss: 2.612720275948582

Epoch: 6| Step: 9
Training loss: 3.3308011609673382
Validation loss: 2.618886829822795

Epoch: 6| Step: 10
Training loss: 2.903408014568407
Validation loss: 2.627975219283829

Epoch: 6| Step: 11
Training loss: 3.3169853504629088
Validation loss: 2.6375028848450044

Epoch: 6| Step: 12
Training loss: 2.536463325594794
Validation loss: 2.65690084225424

Epoch: 6| Step: 13
Training loss: 3.398865140119957
Validation loss: 2.673936527955419

Epoch: 67| Step: 0
Training loss: 3.1662693945663065
Validation loss: 2.6665657649895693

Epoch: 6| Step: 1
Training loss: 3.1757695384355085
Validation loss: 2.6637747456444973

Epoch: 6| Step: 2
Training loss: 2.404633412487173
Validation loss: 2.6515632218050835

Epoch: 6| Step: 3
Training loss: 2.955040043335258
Validation loss: 2.6474665160971877

Epoch: 6| Step: 4
Training loss: 3.2465370509014644
Validation loss: 2.6389536428863325

Epoch: 6| Step: 5
Training loss: 2.80948596094483
Validation loss: 2.6349987958634586

Epoch: 6| Step: 6
Training loss: 3.282202010331036
Validation loss: 2.6308559946311507

Epoch: 6| Step: 7
Training loss: 3.3655628081714757
Validation loss: 2.6302968078047804

Epoch: 6| Step: 8
Training loss: 2.8621349251836565
Validation loss: 2.623712630268696

Epoch: 6| Step: 9
Training loss: 2.7839365638597906
Validation loss: 2.6227651214809757

Epoch: 6| Step: 10
Training loss: 3.225831768797923
Validation loss: 2.6187692098235797

Epoch: 6| Step: 11
Training loss: 2.801010399120547
Validation loss: 2.617327318786612

Epoch: 6| Step: 12
Training loss: 2.6350017014847245
Validation loss: 2.615303645973052

Epoch: 6| Step: 13
Training loss: 3.3103368641905533
Validation loss: 2.6117932321318045

Epoch: 68| Step: 0
Training loss: 2.7054926034843536
Validation loss: 2.613484919196269

Epoch: 6| Step: 1
Training loss: 2.4812059643582876
Validation loss: 2.6123772314159734

Epoch: 6| Step: 2
Training loss: 2.925599035234634
Validation loss: 2.613937139886529

Epoch: 6| Step: 3
Training loss: 2.2682297039067842
Validation loss: 2.614341316417318

Epoch: 6| Step: 4
Training loss: 3.0310465950903636
Validation loss: 2.611948947614929

Epoch: 6| Step: 5
Training loss: 3.199043911917812
Validation loss: 2.613768454798483

Epoch: 6| Step: 6
Training loss: 3.042120094120747
Validation loss: 2.6260537485294786

Epoch: 6| Step: 7
Training loss: 3.2678254667201587
Validation loss: 2.6356916094909875

Epoch: 6| Step: 8
Training loss: 2.8459690365102186
Validation loss: 2.6467340157349213

Epoch: 6| Step: 9
Training loss: 2.85020502256492
Validation loss: 2.6460317844583954

Epoch: 6| Step: 10
Training loss: 3.2068061331426825
Validation loss: 2.6292163516231333

Epoch: 6| Step: 11
Training loss: 3.5407145099150052
Validation loss: 2.608463960713319

Epoch: 6| Step: 12
Training loss: 2.863355690273389
Validation loss: 2.608952592782848

Epoch: 6| Step: 13
Training loss: 3.234330476463629
Validation loss: 2.605464809293166

Epoch: 69| Step: 0
Training loss: 2.521868143935025
Validation loss: 2.6018217234117893

Epoch: 6| Step: 1
Training loss: 3.334061892680403
Validation loss: 2.603039721060275

Epoch: 6| Step: 2
Training loss: 3.132759226966782
Validation loss: 2.6042915576807375

Epoch: 6| Step: 3
Training loss: 3.22046963578106
Validation loss: 2.6058660233446105

Epoch: 6| Step: 4
Training loss: 2.6755944848141633
Validation loss: 2.605768532253835

Epoch: 6| Step: 5
Training loss: 3.2797388866046395
Validation loss: 2.6066106830027924

Epoch: 6| Step: 6
Training loss: 3.1251251195655274
Validation loss: 2.6083320241300565

Epoch: 6| Step: 7
Training loss: 2.6898103586163513
Validation loss: 2.6077295167099193

Epoch: 6| Step: 8
Training loss: 3.1633195923271304
Validation loss: 2.6047673116405714

Epoch: 6| Step: 9
Training loss: 2.8257825223388844
Validation loss: 2.6020692130267697

Epoch: 6| Step: 10
Training loss: 2.8263703693738136
Validation loss: 2.5968277727664546

Epoch: 6| Step: 11
Training loss: 2.110604274152095
Validation loss: 2.6042475058201138

Epoch: 6| Step: 12
Training loss: 3.486796269120276
Validation loss: 2.599290197301269

Epoch: 6| Step: 13
Training loss: 2.368112012153503
Validation loss: 2.6087666294122855

Epoch: 70| Step: 0
Training loss: 2.943928927351487
Validation loss: 2.6234611907444156

Epoch: 6| Step: 1
Training loss: 3.511872997863818
Validation loss: 2.617736568779916

Epoch: 6| Step: 2
Training loss: 2.961872687901345
Validation loss: 2.608717417680054

Epoch: 6| Step: 3
Training loss: 2.5319289250635544
Validation loss: 2.611088611122132

Epoch: 6| Step: 4
Training loss: 2.772537472250678
Validation loss: 2.6263256309978398

Epoch: 6| Step: 5
Training loss: 2.499842257291514
Validation loss: 2.62395517638192

Epoch: 6| Step: 6
Training loss: 2.42053520305954
Validation loss: 2.6393174319118184

Epoch: 6| Step: 7
Training loss: 2.8371665120033924
Validation loss: 2.639454857524846

Epoch: 6| Step: 8
Training loss: 3.2627754007493164
Validation loss: 2.6264333244633393

Epoch: 6| Step: 9
Training loss: 3.1289128030810747
Validation loss: 2.610934553793174

Epoch: 6| Step: 10
Training loss: 2.7091060025304987
Validation loss: 2.610259398128308

Epoch: 6| Step: 11
Training loss: 3.187191218959248
Validation loss: 2.6098984985375937

Epoch: 6| Step: 12
Training loss: 3.490740107018994
Validation loss: 2.6126406501095736

Epoch: 6| Step: 13
Training loss: 2.6594889023591057
Validation loss: 2.611400430982615

Epoch: 71| Step: 0
Training loss: 3.078495835946262
Validation loss: 2.6107126272770467

Epoch: 6| Step: 1
Training loss: 3.029909447050228
Validation loss: 2.6016764735478963

Epoch: 6| Step: 2
Training loss: 2.82112984688335
Validation loss: 2.5941623439545736

Epoch: 6| Step: 3
Training loss: 2.2488254024296315
Validation loss: 2.601323334624135

Epoch: 6| Step: 4
Training loss: 3.5098381735511115
Validation loss: 2.6040611478695808

Epoch: 6| Step: 5
Training loss: 3.1780689815959353
Validation loss: 2.599738620385871

Epoch: 6| Step: 6
Training loss: 2.2223077108575806
Validation loss: 2.601943330397348

Epoch: 6| Step: 7
Training loss: 3.043729439730594
Validation loss: 2.6023397804844426

Epoch: 6| Step: 8
Training loss: 3.2206314661903845
Validation loss: 2.601572719806293

Epoch: 6| Step: 9
Training loss: 2.1426541254965925
Validation loss: 2.6042621006040094

Epoch: 6| Step: 10
Training loss: 2.873613271891185
Validation loss: 2.594778492289211

Epoch: 6| Step: 11
Training loss: 3.1745642175252033
Validation loss: 2.5906476205607403

Epoch: 6| Step: 12
Training loss: 3.325051477937239
Validation loss: 2.5907711156125632

Epoch: 6| Step: 13
Training loss: 2.97881402193808
Validation loss: 2.5903313448958976

Epoch: 72| Step: 0
Training loss: 2.3931392836823173
Validation loss: 2.584763630791958

Epoch: 6| Step: 1
Training loss: 2.7391170689945823
Validation loss: 2.5860040681694674

Epoch: 6| Step: 2
Training loss: 3.263645137766377
Validation loss: 2.5843889475958672

Epoch: 6| Step: 3
Training loss: 3.0802561551869974
Validation loss: 2.592861578366109

Epoch: 6| Step: 4
Training loss: 3.2857649485313263
Validation loss: 2.583116400862953

Epoch: 6| Step: 5
Training loss: 3.188974824678627
Validation loss: 2.5839189672083505

Epoch: 6| Step: 6
Training loss: 2.8116304536879433
Validation loss: 2.5803131155234547

Epoch: 6| Step: 7
Training loss: 2.3660860930037213
Validation loss: 2.582876035629462

Epoch: 6| Step: 8
Training loss: 3.553098889525874
Validation loss: 2.582005613776652

Epoch: 6| Step: 9
Training loss: 2.582604048960284
Validation loss: 2.5865818062815777

Epoch: 6| Step: 10
Training loss: 2.6113383507653185
Validation loss: 2.5845107429761733

Epoch: 6| Step: 11
Training loss: 2.9957757455298424
Validation loss: 2.5930576984444347

Epoch: 6| Step: 12
Training loss: 2.7991097329215293
Validation loss: 2.6004761572220607

Epoch: 6| Step: 13
Training loss: 3.420047498451242
Validation loss: 2.5978148753749095

Epoch: 73| Step: 0
Training loss: 2.6413677908921915
Validation loss: 2.590667792972641

Epoch: 6| Step: 1
Training loss: 2.352853819684036
Validation loss: 2.5963669034397987

Epoch: 6| Step: 2
Training loss: 2.4332292752247056
Validation loss: 2.5923144215903093

Epoch: 6| Step: 3
Training loss: 3.107893854594423
Validation loss: 2.5892604416667058

Epoch: 6| Step: 4
Training loss: 2.6464665373591663
Validation loss: 2.589884736744547

Epoch: 6| Step: 5
Training loss: 2.897810958225083
Validation loss: 2.5869848013376386

Epoch: 6| Step: 6
Training loss: 3.3872179765594566
Validation loss: 2.589155606199019

Epoch: 6| Step: 7
Training loss: 3.151476886212408
Validation loss: 2.5842309028279304

Epoch: 6| Step: 8
Training loss: 3.068315239776469
Validation loss: 2.585327714988582

Epoch: 6| Step: 9
Training loss: 2.4705794111195756
Validation loss: 2.582631200971339

Epoch: 6| Step: 10
Training loss: 2.8612581316097865
Validation loss: 2.5820546103152635

Epoch: 6| Step: 11
Training loss: 3.0921216590506457
Validation loss: 2.5811603148287885

Epoch: 6| Step: 12
Training loss: 3.391917883139914
Validation loss: 2.5774639029057123

Epoch: 6| Step: 13
Training loss: 3.5582355607929204
Validation loss: 2.5788524636751755

Epoch: 74| Step: 0
Training loss: 2.9027948657865776
Validation loss: 2.5780539564062415

Epoch: 6| Step: 1
Training loss: 1.9097242744511838
Validation loss: 2.5773740189881886

Epoch: 6| Step: 2
Training loss: 3.046572939253931
Validation loss: 2.5763062984055733

Epoch: 6| Step: 3
Training loss: 2.6578829962852275
Validation loss: 2.5781438046860603

Epoch: 6| Step: 4
Training loss: 3.358777370078721
Validation loss: 2.5792023814935456

Epoch: 6| Step: 5
Training loss: 3.2353794178453
Validation loss: 2.5865201304562118

Epoch: 6| Step: 6
Training loss: 3.1989392727915766
Validation loss: 2.600003910180079

Epoch: 6| Step: 7
Training loss: 2.6546619829430003
Validation loss: 2.5969720805945102

Epoch: 6| Step: 8
Training loss: 3.134311384047994
Validation loss: 2.61235167513138

Epoch: 6| Step: 9
Training loss: 2.844559103754214
Validation loss: 2.6028104867783926

Epoch: 6| Step: 10
Training loss: 2.946770183361744
Validation loss: 2.5757451015729913

Epoch: 6| Step: 11
Training loss: 3.023490649009995
Validation loss: 2.5704648051023806

Epoch: 6| Step: 12
Training loss: 3.3566233166266484
Validation loss: 2.5751883697823716

Epoch: 6| Step: 13
Training loss: 2.144045915560347
Validation loss: 2.580830365439117

Epoch: 75| Step: 0
Training loss: 3.1275935282699656
Validation loss: 2.5809185247969313

Epoch: 6| Step: 1
Training loss: 2.990285722228149
Validation loss: 2.5817169593402327

Epoch: 6| Step: 2
Training loss: 2.2554581454602194
Validation loss: 2.5805709676306123

Epoch: 6| Step: 3
Training loss: 3.281810603616957
Validation loss: 2.576972297529076

Epoch: 6| Step: 4
Training loss: 3.3315440779919925
Validation loss: 2.579831614716954

Epoch: 6| Step: 5
Training loss: 2.201142629921628
Validation loss: 2.5815713042220447

Epoch: 6| Step: 6
Training loss: 2.3092216760844106
Validation loss: 2.581657589769795

Epoch: 6| Step: 7
Training loss: 2.943002781723113
Validation loss: 2.596898700602059

Epoch: 6| Step: 8
Training loss: 3.171828396459511
Validation loss: 2.606974161843612

Epoch: 6| Step: 9
Training loss: 3.255989717415734
Validation loss: 2.6141835967603146

Epoch: 6| Step: 10
Training loss: 3.025923778625346
Validation loss: 2.6162039252837026

Epoch: 6| Step: 11
Training loss: 2.996816535514675
Validation loss: 2.6209912197301515

Epoch: 6| Step: 12
Training loss: 2.823959233138334
Validation loss: 2.5922373890261396

Epoch: 6| Step: 13
Training loss: 3.1537429370415486
Validation loss: 2.5833118337265186

Epoch: 76| Step: 0
Training loss: 2.7115440020007746
Validation loss: 2.5814821273934583

Epoch: 6| Step: 1
Training loss: 2.491986975181182
Validation loss: 2.5848079790033878

Epoch: 6| Step: 2
Training loss: 2.8768855007327234
Validation loss: 2.584026572792633

Epoch: 6| Step: 3
Training loss: 3.1621259626456526
Validation loss: 2.5785418628659937

Epoch: 6| Step: 4
Training loss: 2.5251289108153174
Validation loss: 2.583341276637583

Epoch: 6| Step: 5
Training loss: 3.003992602790025
Validation loss: 2.580715826884652

Epoch: 6| Step: 6
Training loss: 2.677290575686576
Validation loss: 2.57938217978158

Epoch: 6| Step: 7
Training loss: 2.6482287299318346
Validation loss: 2.581475776583644

Epoch: 6| Step: 8
Training loss: 3.5380053425474136
Validation loss: 2.57515302076576

Epoch: 6| Step: 9
Training loss: 3.283391054165677
Validation loss: 2.574759393185955

Epoch: 6| Step: 10
Training loss: 3.0072360192279217
Validation loss: 2.5791531717330813

Epoch: 6| Step: 11
Training loss: 2.7962289415640016
Validation loss: 2.5763359298402673

Epoch: 6| Step: 12
Training loss: 3.204289220112306
Validation loss: 2.5754222675367986

Epoch: 6| Step: 13
Training loss: 2.887361736207525
Validation loss: 2.5745940001762975

Epoch: 77| Step: 0
Training loss: 3.3974647269758256
Validation loss: 2.5726971897393778

Epoch: 6| Step: 1
Training loss: 2.623429146276809
Validation loss: 2.5684771939304225

Epoch: 6| Step: 2
Training loss: 2.7000591554166036
Validation loss: 2.575474921018354

Epoch: 6| Step: 3
Training loss: 3.1952298253936227
Validation loss: 2.5889961235107894

Epoch: 6| Step: 4
Training loss: 2.93752110250482
Validation loss: 2.6262119403888806

Epoch: 6| Step: 5
Training loss: 2.9406536299541135
Validation loss: 2.62653471992229

Epoch: 6| Step: 6
Training loss: 2.773093446694345
Validation loss: 2.6159955609877787

Epoch: 6| Step: 7
Training loss: 2.5851453045970407
Validation loss: 2.6032472010268033

Epoch: 6| Step: 8
Training loss: 3.392587542040399
Validation loss: 2.609023962343317

Epoch: 6| Step: 9
Training loss: 2.9515431522120963
Validation loss: 2.5739267303022935

Epoch: 6| Step: 10
Training loss: 3.0014711587522025
Validation loss: 2.568143387456802

Epoch: 6| Step: 11
Training loss: 2.4995435297991593
Validation loss: 2.5609232946223113

Epoch: 6| Step: 12
Training loss: 2.980918120459089
Validation loss: 2.558499657038091

Epoch: 6| Step: 13
Training loss: 2.8489757772094126
Validation loss: 2.5650888227136375

Epoch: 78| Step: 0
Training loss: 2.291122395010458
Validation loss: 2.5643362363805213

Epoch: 6| Step: 1
Training loss: 2.7241683110741426
Validation loss: 2.5637890914519237

Epoch: 6| Step: 2
Training loss: 3.0245662031377467
Validation loss: 2.5642424601100022

Epoch: 6| Step: 3
Training loss: 2.810637132628222
Validation loss: 2.5664682603542563

Epoch: 6| Step: 4
Training loss: 2.832011045186546
Validation loss: 2.562608353919869

Epoch: 6| Step: 5
Training loss: 2.821810591291088
Validation loss: 2.5654093496122448

Epoch: 6| Step: 6
Training loss: 3.3056059298341194
Validation loss: 2.561993415554958

Epoch: 6| Step: 7
Training loss: 3.03189127322996
Validation loss: 2.557901475691742

Epoch: 6| Step: 8
Training loss: 3.0033858583904736
Validation loss: 2.5611368711070273

Epoch: 6| Step: 9
Training loss: 2.306837210809487
Validation loss: 2.561230314665135

Epoch: 6| Step: 10
Training loss: 3.335666332792899
Validation loss: 2.5595141487128683

Epoch: 6| Step: 11
Training loss: 2.9373230576487694
Validation loss: 2.5632950204534355

Epoch: 6| Step: 12
Training loss: 2.9729884359299716
Validation loss: 2.5708935719101245

Epoch: 6| Step: 13
Training loss: 3.6508910202023346
Validation loss: 2.5829657638144776

Epoch: 79| Step: 0
Training loss: 3.290529191378488
Validation loss: 2.595965902078359

Epoch: 6| Step: 1
Training loss: 3.009658841287893
Validation loss: 2.5750632821787605

Epoch: 6| Step: 2
Training loss: 2.982381904099375
Validation loss: 2.5597768891613306

Epoch: 6| Step: 3
Training loss: 2.759753357467869
Validation loss: 2.5558871077856127

Epoch: 6| Step: 4
Training loss: 2.428618070010282
Validation loss: 2.556624510950008

Epoch: 6| Step: 5
Training loss: 2.902485367822688
Validation loss: 2.5555222423145363

Epoch: 6| Step: 6
Training loss: 3.1946732830696605
Validation loss: 2.55430029550451

Epoch: 6| Step: 7
Training loss: 2.5451678774161355
Validation loss: 2.556606551736657

Epoch: 6| Step: 8
Training loss: 3.4563077180261326
Validation loss: 2.5585618469959632

Epoch: 6| Step: 9
Training loss: 3.104582193371267
Validation loss: 2.5553727334988174

Epoch: 6| Step: 10
Training loss: 3.0547109149318388
Validation loss: 2.5499006355352805

Epoch: 6| Step: 11
Training loss: 2.924881474628502
Validation loss: 2.550376424405819

Epoch: 6| Step: 12
Training loss: 2.4927779786683444
Validation loss: 2.552217706922702

Epoch: 6| Step: 13
Training loss: 2.464342262772348
Validation loss: 2.5605264552764817

Epoch: 80| Step: 0
Training loss: 3.1733115565196575
Validation loss: 2.5789757919181495

Epoch: 6| Step: 1
Training loss: 3.0101277741848342
Validation loss: 2.6100460705281927

Epoch: 6| Step: 2
Training loss: 2.36651722700376
Validation loss: 2.6558674121178942

Epoch: 6| Step: 3
Training loss: 2.659416106967614
Validation loss: 2.668272910072466

Epoch: 6| Step: 4
Training loss: 2.7853723899576743
Validation loss: 2.59505945631731

Epoch: 6| Step: 5
Training loss: 2.597705353007477
Validation loss: 2.5607113702328212

Epoch: 6| Step: 6
Training loss: 2.9503247744993115
Validation loss: 2.5507652868782604

Epoch: 6| Step: 7
Training loss: 3.0788626004938457
Validation loss: 2.5515612016426923

Epoch: 6| Step: 8
Training loss: 2.5315139067793573
Validation loss: 2.5525136283941436

Epoch: 6| Step: 9
Training loss: 3.2719038327175447
Validation loss: 2.5574500298020095

Epoch: 6| Step: 10
Training loss: 2.869916983543538
Validation loss: 2.556301054314441

Epoch: 6| Step: 11
Training loss: 3.6809054098455816
Validation loss: 2.5536687929158104

Epoch: 6| Step: 12
Training loss: 3.148849119630574
Validation loss: 2.5508196633962625

Epoch: 6| Step: 13
Training loss: 2.3571158197016526
Validation loss: 2.548352236182846

Epoch: 81| Step: 0
Training loss: 2.542372110576836
Validation loss: 2.5490612825631596

Epoch: 6| Step: 1
Training loss: 3.166301472001155
Validation loss: 2.552689710599272

Epoch: 6| Step: 2
Training loss: 3.608279107253862
Validation loss: 2.5488879529831943

Epoch: 6| Step: 3
Training loss: 2.9217039660002184
Validation loss: 2.548011295293761

Epoch: 6| Step: 4
Training loss: 2.859387173652791
Validation loss: 2.548485049783089

Epoch: 6| Step: 5
Training loss: 3.0886580052371335
Validation loss: 2.5458896365763053

Epoch: 6| Step: 6
Training loss: 3.054511413962525
Validation loss: 2.5488638290464976

Epoch: 6| Step: 7
Training loss: 2.430863172652907
Validation loss: 2.5470849282888084

Epoch: 6| Step: 8
Training loss: 2.7879841747518928
Validation loss: 2.543564966252714

Epoch: 6| Step: 9
Training loss: 2.616590744990515
Validation loss: 2.5481602510814194

Epoch: 6| Step: 10
Training loss: 2.6101585627947794
Validation loss: 2.550299168521789

Epoch: 6| Step: 11
Training loss: 2.645503847126965
Validation loss: 2.5568348700263717

Epoch: 6| Step: 12
Training loss: 2.72243136512967
Validation loss: 2.5802504602326586

Epoch: 6| Step: 13
Training loss: 3.696266099664472
Validation loss: 2.6362916686364035

Epoch: 82| Step: 0
Training loss: 2.845581135854752
Validation loss: 2.676191334969027

Epoch: 6| Step: 1
Training loss: 3.2427644147392995
Validation loss: 2.744570322952698

Epoch: 6| Step: 2
Training loss: 3.095996387923152
Validation loss: 2.78916030233879

Epoch: 6| Step: 3
Training loss: 2.478966734274809
Validation loss: 2.777021199288351

Epoch: 6| Step: 4
Training loss: 2.6753314231842293
Validation loss: 2.750866240794011

Epoch: 6| Step: 5
Training loss: 2.5691696455355966
Validation loss: 2.712212632692796

Epoch: 6| Step: 6
Training loss: 3.4311637047649715
Validation loss: 2.6659043751743794

Epoch: 6| Step: 7
Training loss: 3.414407324235563
Validation loss: 2.562616732279828

Epoch: 6| Step: 8
Training loss: 2.980046993627536
Validation loss: 2.546623475748949

Epoch: 6| Step: 9
Training loss: 2.800816832333684
Validation loss: 2.562346331022779

Epoch: 6| Step: 10
Training loss: 2.841313083013832
Validation loss: 2.566079243913246

Epoch: 6| Step: 11
Training loss: 2.9741300320651476
Validation loss: 2.5767121650940745

Epoch: 6| Step: 12
Training loss: 3.2509931367386904
Validation loss: 2.5786667031887522

Epoch: 6| Step: 13
Training loss: 2.2573219479189044
Validation loss: 2.584655337779839

Epoch: 83| Step: 0
Training loss: 3.1109570642964517
Validation loss: 2.582527396815157

Epoch: 6| Step: 1
Training loss: 3.3844604706824843
Validation loss: 2.5831589641597836

Epoch: 6| Step: 2
Training loss: 2.8784712691868544
Validation loss: 2.578319248154335

Epoch: 6| Step: 3
Training loss: 2.636087344828124
Validation loss: 2.573153990306058

Epoch: 6| Step: 4
Training loss: 2.8264593625375496
Validation loss: 2.570193122899003

Epoch: 6| Step: 5
Training loss: 2.9285349295332117
Validation loss: 2.5672761979096967

Epoch: 6| Step: 6
Training loss: 2.983333545734533
Validation loss: 2.569955359579924

Epoch: 6| Step: 7
Training loss: 3.255439900617611
Validation loss: 2.567712694742761

Epoch: 6| Step: 8
Training loss: 3.335650751087041
Validation loss: 2.566689241094549

Epoch: 6| Step: 9
Training loss: 2.509824617041375
Validation loss: 2.5651853188873806

Epoch: 6| Step: 10
Training loss: 2.485963709301655
Validation loss: 2.5651502462799463

Epoch: 6| Step: 11
Training loss: 3.1129046012458397
Validation loss: 2.5637338780546663

Epoch: 6| Step: 12
Training loss: 2.996662986026098
Validation loss: 2.561312665768519

Epoch: 6| Step: 13
Training loss: 2.7127763739216
Validation loss: 2.558558658677653

Epoch: 84| Step: 0
Training loss: 3.2744660502788405
Validation loss: 2.5581232886631122

Epoch: 6| Step: 1
Training loss: 2.6543744814813626
Validation loss: 2.5549678336967236

Epoch: 6| Step: 2
Training loss: 3.3611512212400467
Validation loss: 2.5592116649840477

Epoch: 6| Step: 3
Training loss: 2.9343756435015766
Validation loss: 2.553991912397031

Epoch: 6| Step: 4
Training loss: 3.2855783161912564
Validation loss: 2.5524131764330007

Epoch: 6| Step: 5
Training loss: 3.212674824154607
Validation loss: 2.5522296581464485

Epoch: 6| Step: 6
Training loss: 2.514537599954165
Validation loss: 2.5580644022542463

Epoch: 6| Step: 7
Training loss: 2.5076361383238566
Validation loss: 2.5663871295555265

Epoch: 6| Step: 8
Training loss: 2.5460785164484157
Validation loss: 2.585619979918131

Epoch: 6| Step: 9
Training loss: 2.8852670862604066
Validation loss: 2.594208930885399

Epoch: 6| Step: 10
Training loss: 2.6972431731618967
Validation loss: 2.621437620540292

Epoch: 6| Step: 11
Training loss: 3.1236896056297487
Validation loss: 2.656754880886693

Epoch: 6| Step: 12
Training loss: 2.933503211766577
Validation loss: 2.683881842904099

Epoch: 6| Step: 13
Training loss: 2.6462495030982445
Validation loss: 2.6151755305794495

Epoch: 85| Step: 0
Training loss: 3.0667637318992282
Validation loss: 2.584021049705982

Epoch: 6| Step: 1
Training loss: 2.9776202547658417
Validation loss: 2.551338691557096

Epoch: 6| Step: 2
Training loss: 3.0252796642821536
Validation loss: 2.5410027886829503

Epoch: 6| Step: 3
Training loss: 2.3917994388141066
Validation loss: 2.545310484026487

Epoch: 6| Step: 4
Training loss: 3.181255132225109
Validation loss: 2.5455195150865646

Epoch: 6| Step: 5
Training loss: 3.3882204310240773
Validation loss: 2.54762860061606

Epoch: 6| Step: 6
Training loss: 2.3468428486375417
Validation loss: 2.5475727089173708

Epoch: 6| Step: 7
Training loss: 2.5126643796070134
Validation loss: 2.54778553499636

Epoch: 6| Step: 8
Training loss: 2.5324158044283633
Validation loss: 2.549963531860709

Epoch: 6| Step: 9
Training loss: 3.230348301110017
Validation loss: 2.5486511986284057

Epoch: 6| Step: 10
Training loss: 3.3187687415331957
Validation loss: 2.55406369957591

Epoch: 6| Step: 11
Training loss: 2.853657995036672
Validation loss: 2.562865560584709

Epoch: 6| Step: 12
Training loss: 2.7504211450093514
Validation loss: 2.567691690020387

Epoch: 6| Step: 13
Training loss: 3.1795142874063016
Validation loss: 2.5844394950022336

Epoch: 86| Step: 0
Training loss: 3.238014421870328
Validation loss: 2.5864732642901225

Epoch: 6| Step: 1
Training loss: 2.7917734856357663
Validation loss: 2.5666571960013465

Epoch: 6| Step: 2
Training loss: 3.36179055596679
Validation loss: 2.5539004906848675

Epoch: 6| Step: 3
Training loss: 2.9236676433913744
Validation loss: 2.546624166332875

Epoch: 6| Step: 4
Training loss: 3.22975602873142
Validation loss: 2.5466121495418337

Epoch: 6| Step: 5
Training loss: 2.9442559327853446
Validation loss: 2.543542577832991

Epoch: 6| Step: 6
Training loss: 2.7924831581803145
Validation loss: 2.5463458186562953

Epoch: 6| Step: 7
Training loss: 2.5470605326282607
Validation loss: 2.5418130283453295

Epoch: 6| Step: 8
Training loss: 2.468863665704367
Validation loss: 2.5431253489508694

Epoch: 6| Step: 9
Training loss: 2.8178380535583556
Validation loss: 2.5453461286393506

Epoch: 6| Step: 10
Training loss: 3.411801634931047
Validation loss: 2.550578014501873

Epoch: 6| Step: 11
Training loss: 2.9627374095190535
Validation loss: 2.5946324973793384

Epoch: 6| Step: 12
Training loss: 2.4699970427584224
Validation loss: 2.5937390565054472

Epoch: 6| Step: 13
Training loss: 2.4915966900171354
Validation loss: 2.6049243062793663

Epoch: 87| Step: 0
Training loss: 2.8160161397644834
Validation loss: 2.6248395746746933

Epoch: 6| Step: 1
Training loss: 3.1890288033917638
Validation loss: 2.6196770028987997

Epoch: 6| Step: 2
Training loss: 3.297680797002041
Validation loss: 2.6174401112529857

Epoch: 6| Step: 3
Training loss: 2.715842786337254
Validation loss: 2.5980548916373687

Epoch: 6| Step: 4
Training loss: 3.5055209620791277
Validation loss: 2.584510757359085

Epoch: 6| Step: 5
Training loss: 3.118994932169954
Validation loss: 2.5368443353897945

Epoch: 6| Step: 6
Training loss: 2.7567088915056126
Validation loss: 2.5347766006382266

Epoch: 6| Step: 7
Training loss: 2.2641271441111535
Validation loss: 2.5379944064730164

Epoch: 6| Step: 8
Training loss: 3.2649237504967275
Validation loss: 2.5475376217643015

Epoch: 6| Step: 9
Training loss: 2.5885540496918873
Validation loss: 2.568387848432539

Epoch: 6| Step: 10
Training loss: 2.7868667635953153
Validation loss: 2.5611561178319784

Epoch: 6| Step: 11
Training loss: 2.74740339281148
Validation loss: 2.5392698545639614

Epoch: 6| Step: 12
Training loss: 2.34863849726443
Validation loss: 2.5363992697344737

Epoch: 6| Step: 13
Training loss: 3.2958198775359575
Validation loss: 2.529730820616946

Epoch: 88| Step: 0
Training loss: 2.7914310090157133
Validation loss: 2.539732570530483

Epoch: 6| Step: 1
Training loss: 2.6515827238877296
Validation loss: 2.544536032685693

Epoch: 6| Step: 2
Training loss: 3.027028713446777
Validation loss: 2.5603882326444167

Epoch: 6| Step: 3
Training loss: 2.5205424327460624
Validation loss: 2.5674549901253974

Epoch: 6| Step: 4
Training loss: 2.9262584098554933
Validation loss: 2.57800099064363

Epoch: 6| Step: 5
Training loss: 2.454893507347268
Validation loss: 2.5768996085022287

Epoch: 6| Step: 6
Training loss: 3.0423788691334304
Validation loss: 2.5847441115455534

Epoch: 6| Step: 7
Training loss: 3.7776908833352394
Validation loss: 2.5523025133959893

Epoch: 6| Step: 8
Training loss: 2.651827552689213
Validation loss: 2.547667983290611

Epoch: 6| Step: 9
Training loss: 3.0653178427648986
Validation loss: 2.5301530477339598

Epoch: 6| Step: 10
Training loss: 2.775884360221665
Validation loss: 2.5288166385415094

Epoch: 6| Step: 11
Training loss: 2.715361577329249
Validation loss: 2.527371702610055

Epoch: 6| Step: 12
Training loss: 3.095058896393339
Validation loss: 2.5349087683073375

Epoch: 6| Step: 13
Training loss: 2.7226874241624546
Validation loss: 2.5334317876609975

Epoch: 89| Step: 0
Training loss: 3.739318894978047
Validation loss: 2.5344599762107136

Epoch: 6| Step: 1
Training loss: 3.2018406223564093
Validation loss: 2.538587291033063

Epoch: 6| Step: 2
Training loss: 2.718214486535603
Validation loss: 2.5421285463443755

Epoch: 6| Step: 3
Training loss: 2.674334726763635
Validation loss: 2.5377261882318907

Epoch: 6| Step: 4
Training loss: 2.949282452230072
Validation loss: 2.5355260238571042

Epoch: 6| Step: 5
Training loss: 3.088712502054719
Validation loss: 2.5304263106706912

Epoch: 6| Step: 6
Training loss: 2.365409157907774
Validation loss: 2.5302799178369724

Epoch: 6| Step: 7
Training loss: 2.275634857298873
Validation loss: 2.5237810302410426

Epoch: 6| Step: 8
Training loss: 2.947902360393915
Validation loss: 2.5225539823893364

Epoch: 6| Step: 9
Training loss: 2.4509463020272686
Validation loss: 2.5205882628004734

Epoch: 6| Step: 10
Training loss: 3.1005150397898236
Validation loss: 2.5215289841606396

Epoch: 6| Step: 11
Training loss: 3.4032145282609223
Validation loss: 2.5227657952972513

Epoch: 6| Step: 12
Training loss: 3.061573744851823
Validation loss: 2.5307848482839694

Epoch: 6| Step: 13
Training loss: 2.1642444960982576
Validation loss: 2.52914861758559

Epoch: 90| Step: 0
Training loss: 3.1609051810708753
Validation loss: 2.543883519023178

Epoch: 6| Step: 1
Training loss: 3.17597943915719
Validation loss: 2.54660407086808

Epoch: 6| Step: 2
Training loss: 2.8692893657730956
Validation loss: 2.5448510206686046

Epoch: 6| Step: 3
Training loss: 2.551283875931563
Validation loss: 2.5673670784189437

Epoch: 6| Step: 4
Training loss: 2.366945159895686
Validation loss: 2.5614433746294103

Epoch: 6| Step: 5
Training loss: 3.1277475104515298
Validation loss: 2.5533327798990846

Epoch: 6| Step: 6
Training loss: 2.8004787819100625
Validation loss: 2.549182857071314

Epoch: 6| Step: 7
Training loss: 2.965353699505573
Validation loss: 2.5248259426406734

Epoch: 6| Step: 8
Training loss: 2.5349798155814325
Validation loss: 2.525569750326387

Epoch: 6| Step: 9
Training loss: 2.73000435434071
Validation loss: 2.519135167502229

Epoch: 6| Step: 10
Training loss: 3.515683321998876
Validation loss: 2.5143245290168803

Epoch: 6| Step: 11
Training loss: 2.8095313617444693
Validation loss: 2.514066966411855

Epoch: 6| Step: 12
Training loss: 2.7501601259256163
Validation loss: 2.5127069640154196

Epoch: 6| Step: 13
Training loss: 2.83879647234122
Validation loss: 2.5105767586858545

Epoch: 91| Step: 0
Training loss: 2.7355574312813955
Validation loss: 2.5098506933023828

Epoch: 6| Step: 1
Training loss: 3.0443198420634534
Validation loss: 2.5160288271639364

Epoch: 6| Step: 2
Training loss: 3.0666508473803744
Validation loss: 2.514459443788183

Epoch: 6| Step: 3
Training loss: 2.6680585586378265
Validation loss: 2.516719582274445

Epoch: 6| Step: 4
Training loss: 2.7039604880363575
Validation loss: 2.5224522214799627

Epoch: 6| Step: 5
Training loss: 3.368189970045693
Validation loss: 2.537472122429629

Epoch: 6| Step: 6
Training loss: 2.8335786788030584
Validation loss: 2.5366562616616926

Epoch: 6| Step: 7
Training loss: 2.7246509398431273
Validation loss: 2.5453055583025965

Epoch: 6| Step: 8
Training loss: 2.694833994974
Validation loss: 2.558290740576434

Epoch: 6| Step: 9
Training loss: 2.9329820343102044
Validation loss: 2.577531424934639

Epoch: 6| Step: 10
Training loss: 3.2541423221968633
Validation loss: 2.5765947252083885

Epoch: 6| Step: 11
Training loss: 2.8511598067544974
Validation loss: 2.53908412725358

Epoch: 6| Step: 12
Training loss: 2.7565239767979284
Validation loss: 2.537573708361317

Epoch: 6| Step: 13
Training loss: 2.5689341086983886
Validation loss: 2.5195491031142345

Epoch: 92| Step: 0
Training loss: 3.314912601199143
Validation loss: 2.508756678406431

Epoch: 6| Step: 1
Training loss: 3.411066971478445
Validation loss: 2.5121502734049503

Epoch: 6| Step: 2
Training loss: 3.0287074801380443
Validation loss: 2.5080612877532618

Epoch: 6| Step: 3
Training loss: 2.573660203831811
Validation loss: 2.509062686344744

Epoch: 6| Step: 4
Training loss: 2.2723830881460088
Validation loss: 2.5074675130426054

Epoch: 6| Step: 5
Training loss: 2.641737303005047
Validation loss: 2.5109730303439832

Epoch: 6| Step: 6
Training loss: 2.704300288664247
Validation loss: 2.5085580851099203

Epoch: 6| Step: 7
Training loss: 3.267367395513646
Validation loss: 2.51224877592179

Epoch: 6| Step: 8
Training loss: 2.6999422420399224
Validation loss: 2.5118735729833466

Epoch: 6| Step: 9
Training loss: 2.622863081388996
Validation loss: 2.5092280903333406

Epoch: 6| Step: 10
Training loss: 3.1872500153294037
Validation loss: 2.5207908367119765

Epoch: 6| Step: 11
Training loss: 3.1096741805559485
Validation loss: 2.5169226050616227

Epoch: 6| Step: 12
Training loss: 2.503897013773673
Validation loss: 2.529056366754444

Epoch: 6| Step: 13
Training loss: 2.6116650063761595
Validation loss: 2.533943526700392

Epoch: 93| Step: 0
Training loss: 2.834105349061258
Validation loss: 2.547115382779646

Epoch: 6| Step: 1
Training loss: 2.7437193849284993
Validation loss: 2.5292199979656744

Epoch: 6| Step: 2
Training loss: 2.62557949754078
Validation loss: 2.525871241843926

Epoch: 6| Step: 3
Training loss: 2.989783374504722
Validation loss: 2.5229899646662415

Epoch: 6| Step: 4
Training loss: 3.098927490764761
Validation loss: 2.512157858744202

Epoch: 6| Step: 5
Training loss: 3.0570001847725994
Validation loss: 2.5136187948478317

Epoch: 6| Step: 6
Training loss: 2.945077578133239
Validation loss: 2.5130822220694453

Epoch: 6| Step: 7
Training loss: 3.010398327904692
Validation loss: 2.512501933326114

Epoch: 6| Step: 8
Training loss: 3.154641676442903
Validation loss: 2.510879562428993

Epoch: 6| Step: 9
Training loss: 2.566003404931703
Validation loss: 2.5124424215123042

Epoch: 6| Step: 10
Training loss: 2.5043158471414206
Validation loss: 2.5085984562081034

Epoch: 6| Step: 11
Training loss: 3.1457241283602806
Validation loss: 2.5048175304245297

Epoch: 6| Step: 12
Training loss: 2.8160096205362795
Validation loss: 2.502969358667228

Epoch: 6| Step: 13
Training loss: 2.5059967598007455
Validation loss: 2.501703709311185

Epoch: 94| Step: 0
Training loss: 3.313303436154645
Validation loss: 2.508529193173071

Epoch: 6| Step: 1
Training loss: 2.669469989077047
Validation loss: 2.5133494298376022

Epoch: 6| Step: 2
Training loss: 3.299315502962082
Validation loss: 2.523002074661206

Epoch: 6| Step: 3
Training loss: 3.0849440895096283
Validation loss: 2.5388777985769684

Epoch: 6| Step: 4
Training loss: 3.169569709286863
Validation loss: 2.537403249479783

Epoch: 6| Step: 5
Training loss: 2.3752499499050463
Validation loss: 2.541843364456615

Epoch: 6| Step: 6
Training loss: 2.525398838534352
Validation loss: 2.534797288479196

Epoch: 6| Step: 7
Training loss: 3.1374675004347345
Validation loss: 2.534470924809848

Epoch: 6| Step: 8
Training loss: 2.5945841355692925
Validation loss: 2.545598139639359

Epoch: 6| Step: 9
Training loss: 2.3115790311689732
Validation loss: 2.543575111680692

Epoch: 6| Step: 10
Training loss: 2.8067294792280695
Validation loss: 2.5498655401993062

Epoch: 6| Step: 11
Training loss: 2.5501646549695676
Validation loss: 2.5694068449935696

Epoch: 6| Step: 12
Training loss: 3.249168876600888
Validation loss: 2.5862911825043913

Epoch: 6| Step: 13
Training loss: 2.930532918383614
Validation loss: 2.6268971497710765

Epoch: 95| Step: 0
Training loss: 3.2847874056742357
Validation loss: 2.579700699186967

Epoch: 6| Step: 1
Training loss: 3.1668265620235645
Validation loss: 2.532704286878271

Epoch: 6| Step: 2
Training loss: 2.7146612531399414
Validation loss: 2.517699820693042

Epoch: 6| Step: 3
Training loss: 2.48626215053867
Validation loss: 2.5094494020593348

Epoch: 6| Step: 4
Training loss: 2.905074179091293
Validation loss: 2.5012583416525938

Epoch: 6| Step: 5
Training loss: 2.6642998284821107
Validation loss: 2.5032541917205995

Epoch: 6| Step: 6
Training loss: 2.4527669268673247
Validation loss: 2.5037295885949518

Epoch: 6| Step: 7
Training loss: 3.1895169627241944
Validation loss: 2.5026745477016106

Epoch: 6| Step: 8
Training loss: 3.156861500942481
Validation loss: 2.497511069801804

Epoch: 6| Step: 9
Training loss: 2.8401580594633065
Validation loss: 2.4993109512325185

Epoch: 6| Step: 10
Training loss: 2.3894021889878116
Validation loss: 2.5015429411510866

Epoch: 6| Step: 11
Training loss: 2.4168717417905876
Validation loss: 2.507967685767359

Epoch: 6| Step: 12
Training loss: 3.2940091517957653
Validation loss: 2.521200355375635

Epoch: 6| Step: 13
Training loss: 3.185796843637501
Validation loss: 2.526689041821216

Epoch: 96| Step: 0
Training loss: 2.9108807167661834
Validation loss: 2.5547754396077855

Epoch: 6| Step: 1
Training loss: 3.555851270047681
Validation loss: 2.565440343041822

Epoch: 6| Step: 2
Training loss: 3.2096315870075194
Validation loss: 2.556602235891264

Epoch: 6| Step: 3
Training loss: 2.8551744969582953
Validation loss: 2.5359161970683983

Epoch: 6| Step: 4
Training loss: 2.233880475144963
Validation loss: 2.526139969853404

Epoch: 6| Step: 5
Training loss: 3.101912087213588
Validation loss: 2.528304860565832

Epoch: 6| Step: 6
Training loss: 2.5373151664878675
Validation loss: 2.5264672351672353

Epoch: 6| Step: 7
Training loss: 2.337033426159188
Validation loss: 2.5418358505589334

Epoch: 6| Step: 8
Training loss: 2.218154182489333
Validation loss: 2.5367148618054594

Epoch: 6| Step: 9
Training loss: 2.447044758370593
Validation loss: 2.5298728706066345

Epoch: 6| Step: 10
Training loss: 3.1780470756947623
Validation loss: 2.529119558450257

Epoch: 6| Step: 11
Training loss: 3.1469724668468717
Validation loss: 2.5259873934413597

Epoch: 6| Step: 12
Training loss: 2.626706613085212
Validation loss: 2.5224648828713696

Epoch: 6| Step: 13
Training loss: 3.8776576864914154
Validation loss: 2.5402865237522168

Epoch: 97| Step: 0
Training loss: 3.336661838625814
Validation loss: 2.540158871696469

Epoch: 6| Step: 1
Training loss: 2.8329904760220153
Validation loss: 2.544845181867807

Epoch: 6| Step: 2
Training loss: 2.950780189924022
Validation loss: 2.5471474231117215

Epoch: 6| Step: 3
Training loss: 2.992391793470548
Validation loss: 2.563155225795654

Epoch: 6| Step: 4
Training loss: 3.286056340817122
Validation loss: 2.5705428182517402

Epoch: 6| Step: 5
Training loss: 2.5853926439011983
Validation loss: 2.5519088491261495

Epoch: 6| Step: 6
Training loss: 2.357098927852281
Validation loss: 2.5231775533247944

Epoch: 6| Step: 7
Training loss: 2.7987572500621396
Validation loss: 2.5052695901431514

Epoch: 6| Step: 8
Training loss: 3.1502170124686604
Validation loss: 2.5042253636816856

Epoch: 6| Step: 9
Training loss: 2.6196468811271716
Validation loss: 2.4994954379372896

Epoch: 6| Step: 10
Training loss: 3.2572896341127
Validation loss: 2.5130995772785774

Epoch: 6| Step: 11
Training loss: 2.6915082981379257
Validation loss: 2.519698422885951

Epoch: 6| Step: 12
Training loss: 2.536497822061841
Validation loss: 2.5220277242022173

Epoch: 6| Step: 13
Training loss: 2.4580235259107397
Validation loss: 2.5182149053399834

Epoch: 98| Step: 0
Training loss: 2.959394309475349
Validation loss: 2.503701675118487

Epoch: 6| Step: 1
Training loss: 2.6853279385188946
Validation loss: 2.494819464382984

Epoch: 6| Step: 2
Training loss: 3.3613091157401183
Validation loss: 2.498611688190779

Epoch: 6| Step: 3
Training loss: 2.5315006273311447
Validation loss: 2.4940415224247827

Epoch: 6| Step: 4
Training loss: 2.8397911937945417
Validation loss: 2.4957000320743576

Epoch: 6| Step: 5
Training loss: 2.907347113147676
Validation loss: 2.5000319889031917

Epoch: 6| Step: 6
Training loss: 2.988109867940893
Validation loss: 2.5062394267207404

Epoch: 6| Step: 7
Training loss: 2.9494484919311907
Validation loss: 2.5152897663320393

Epoch: 6| Step: 8
Training loss: 2.5457338924518367
Validation loss: 2.5170211642420437

Epoch: 6| Step: 9
Training loss: 2.95723490851474
Validation loss: 2.5205822986346105

Epoch: 6| Step: 10
Training loss: 3.1053124346468683
Validation loss: 2.5221887621050687

Epoch: 6| Step: 11
Training loss: 2.473013275067663
Validation loss: 2.522635052390625

Epoch: 6| Step: 12
Training loss: 2.745171035135333
Validation loss: 2.5165716535396574

Epoch: 6| Step: 13
Training loss: 2.8343069049431984
Validation loss: 2.5250544075234975

Epoch: 99| Step: 0
Training loss: 2.8315607771927698
Validation loss: 2.5150499297383853

Epoch: 6| Step: 1
Training loss: 2.4342688638959746
Validation loss: 2.509050565267624

Epoch: 6| Step: 2
Training loss: 3.004654293898432
Validation loss: 2.5139925299371217

Epoch: 6| Step: 3
Training loss: 2.308745764876665
Validation loss: 2.514064643492003

Epoch: 6| Step: 4
Training loss: 2.805088535210369
Validation loss: 2.5224604273046944

Epoch: 6| Step: 5
Training loss: 2.8072943938082235
Validation loss: 2.5140444233935586

Epoch: 6| Step: 6
Training loss: 2.6579279368256765
Validation loss: 2.5085582486231717

Epoch: 6| Step: 7
Training loss: 2.9519208441152136
Validation loss: 2.503355045339418

Epoch: 6| Step: 8
Training loss: 3.1834432180189856
Validation loss: 2.5097700908460436

Epoch: 6| Step: 9
Training loss: 3.008899046594155
Validation loss: 2.5012793979388057

Epoch: 6| Step: 10
Training loss: 2.593566060725355
Validation loss: 2.5027192012206694

Epoch: 6| Step: 11
Training loss: 3.168720048089459
Validation loss: 2.5036742210850194

Epoch: 6| Step: 12
Training loss: 2.8493248926280765
Validation loss: 2.5067799718112376

Epoch: 6| Step: 13
Training loss: 3.337995765239939
Validation loss: 2.506196571819668

Epoch: 100| Step: 0
Training loss: 2.0237525488476313
Validation loss: 2.511201236468872

Epoch: 6| Step: 1
Training loss: 2.82751871428296
Validation loss: 2.5295030629004684

Epoch: 6| Step: 2
Training loss: 2.9199302035311825
Validation loss: 2.537289662465741

Epoch: 6| Step: 3
Training loss: 2.898883959992358
Validation loss: 2.565148834111119

Epoch: 6| Step: 4
Training loss: 2.6795157775129668
Validation loss: 2.553370516351624

Epoch: 6| Step: 5
Training loss: 2.433289142973808
Validation loss: 2.5543776732540118

Epoch: 6| Step: 6
Training loss: 2.4651224066497885
Validation loss: 2.537942143106371

Epoch: 6| Step: 7
Training loss: 2.345853141669417
Validation loss: 2.5172795061390643

Epoch: 6| Step: 8
Training loss: 3.4079242756181025
Validation loss: 2.5143357335307956

Epoch: 6| Step: 9
Training loss: 3.2639465399085292
Validation loss: 2.5155307754931653

Epoch: 6| Step: 10
Training loss: 2.9654185023232214
Validation loss: 2.498452740416477

Epoch: 6| Step: 11
Training loss: 3.1873982731163113
Validation loss: 2.4969870151559634

Epoch: 6| Step: 12
Training loss: 3.216044353577806
Validation loss: 2.5000173116925444

Epoch: 6| Step: 13
Training loss: 3.4602547482329182
Validation loss: 2.4961805690407783

Epoch: 101| Step: 0
Training loss: 2.9611267190426056
Validation loss: 2.4892953380103284

Epoch: 6| Step: 1
Training loss: 3.0535928857697985
Validation loss: 2.4928501094505506

Epoch: 6| Step: 2
Training loss: 2.8050836054944024
Validation loss: 2.494664196500314

Epoch: 6| Step: 3
Training loss: 3.253341570854181
Validation loss: 2.5056205776848204

Epoch: 6| Step: 4
Training loss: 2.3769053796817325
Validation loss: 2.526692742154101

Epoch: 6| Step: 5
Training loss: 3.023415893162054
Validation loss: 2.5526224945961924

Epoch: 6| Step: 6
Training loss: 2.906744473958736
Validation loss: 2.5720757926345486

Epoch: 6| Step: 7
Training loss: 3.0822744527381
Validation loss: 2.5729443566596473

Epoch: 6| Step: 8
Training loss: 2.409546513767281
Validation loss: 2.5565278836812655

Epoch: 6| Step: 9
Training loss: 2.408788753686735
Validation loss: 2.5531431875779615

Epoch: 6| Step: 10
Training loss: 3.118655822188153
Validation loss: 2.5457620036512956

Epoch: 6| Step: 11
Training loss: 2.7996297727778265
Validation loss: 2.530735776405894

Epoch: 6| Step: 12
Training loss: 2.982738745343553
Validation loss: 2.5189311750237797

Epoch: 6| Step: 13
Training loss: 2.465367377955783
Validation loss: 2.505309131139634

Epoch: 102| Step: 0
Training loss: 3.0417311848804487
Validation loss: 2.4998594388106596

Epoch: 6| Step: 1
Training loss: 3.0852369841277962
Validation loss: 2.495640047689853

Epoch: 6| Step: 2
Training loss: 2.697764290491892
Validation loss: 2.5110754626742633

Epoch: 6| Step: 3
Training loss: 2.680226530351083
Validation loss: 2.5399052740662875

Epoch: 6| Step: 4
Training loss: 2.956313737823317
Validation loss: 2.5729381302483865

Epoch: 6| Step: 5
Training loss: 2.863383833854705
Validation loss: 2.6306911591072617

Epoch: 6| Step: 6
Training loss: 2.885209573045866
Validation loss: 2.6586285215230565

Epoch: 6| Step: 7
Training loss: 2.69327102969911
Validation loss: 2.7092994506535395

Epoch: 6| Step: 8
Training loss: 2.6454679782553803
Validation loss: 2.759792647563185

Epoch: 6| Step: 9
Training loss: 3.0095159289674784
Validation loss: 2.721901019630737

Epoch: 6| Step: 10
Training loss: 3.2767972251776034
Validation loss: 2.6249955314484907

Epoch: 6| Step: 11
Training loss: 3.3047936965797313
Validation loss: 2.5608777239144347

Epoch: 6| Step: 12
Training loss: 2.7852510112462383
Validation loss: 2.5181479907926545

Epoch: 6| Step: 13
Training loss: 2.835116348973925
Validation loss: 2.5383619590589124

Epoch: 103| Step: 0
Training loss: 2.9747435451212803
Validation loss: 2.5313257398253923

Epoch: 6| Step: 1
Training loss: 2.3024216715425667
Validation loss: 2.526283261909959

Epoch: 6| Step: 2
Training loss: 3.051423262912466
Validation loss: 2.5335811169444495

Epoch: 6| Step: 3
Training loss: 3.186289688407912
Validation loss: 2.522728641648012

Epoch: 6| Step: 4
Training loss: 2.8601903534611512
Validation loss: 2.532643406490445

Epoch: 6| Step: 5
Training loss: 2.994872957314975
Validation loss: 2.550292742069773

Epoch: 6| Step: 6
Training loss: 3.534711238608359
Validation loss: 2.5952899926032678

Epoch: 6| Step: 7
Training loss: 3.602345942023162
Validation loss: 2.6040942517128403

Epoch: 6| Step: 8
Training loss: 2.5483105130251844
Validation loss: 2.54511264181134

Epoch: 6| Step: 9
Training loss: 2.721500978053722
Validation loss: 2.5252695405370673

Epoch: 6| Step: 10
Training loss: 2.2969835735791584
Validation loss: 2.520425534872427

Epoch: 6| Step: 11
Training loss: 2.943897180461787
Validation loss: 2.5155389988004204

Epoch: 6| Step: 12
Training loss: 2.57172705038219
Validation loss: 2.5106972110564945

Epoch: 6| Step: 13
Training loss: 2.949000147113557
Validation loss: 2.5099669989731375

Epoch: 104| Step: 0
Training loss: 2.43466530318847
Validation loss: 2.5185732112036754

Epoch: 6| Step: 1
Training loss: 3.1042680830464526
Validation loss: 2.504643461477813

Epoch: 6| Step: 2
Training loss: 3.3913472193088787
Validation loss: 2.513126190814708

Epoch: 6| Step: 3
Training loss: 2.924418112756412
Validation loss: 2.528665610558042

Epoch: 6| Step: 4
Training loss: 2.777862457468167
Validation loss: 2.5473853266281976

Epoch: 6| Step: 5
Training loss: 2.7527240786001914
Validation loss: 2.5456678774947883

Epoch: 6| Step: 6
Training loss: 3.0183290997676835
Validation loss: 2.5743131457655646

Epoch: 6| Step: 7
Training loss: 3.101097552524499
Validation loss: 2.565271559973523

Epoch: 6| Step: 8
Training loss: 2.663749967348626
Validation loss: 2.5363284936879

Epoch: 6| Step: 9
Training loss: 2.615238203939038
Validation loss: 2.5097770081929838

Epoch: 6| Step: 10
Training loss: 2.709157397761741
Validation loss: 2.5012155223524872

Epoch: 6| Step: 11
Training loss: 3.1784941662357857
Validation loss: 2.509099781810466

Epoch: 6| Step: 12
Training loss: 2.25672701709387
Validation loss: 2.4984627376040707

Epoch: 6| Step: 13
Training loss: 2.9983118393703476
Validation loss: 2.524047534001834

Epoch: 105| Step: 0
Training loss: 2.8114425366638547
Validation loss: 2.495827838977186

Epoch: 6| Step: 1
Training loss: 3.2502734729443583
Validation loss: 2.4826710954451086

Epoch: 6| Step: 2
Training loss: 3.4879859722450326
Validation loss: 2.47931129555563

Epoch: 6| Step: 3
Training loss: 2.6620138127393496
Validation loss: 2.4774014396512687

Epoch: 6| Step: 4
Training loss: 2.048906555711032
Validation loss: 2.4776816173353198

Epoch: 6| Step: 5
Training loss: 3.0544450668563137
Validation loss: 2.482367816811277

Epoch: 6| Step: 6
Training loss: 3.08580306520863
Validation loss: 2.485993882351192

Epoch: 6| Step: 7
Training loss: 2.8861539337176336
Validation loss: 2.491335173488344

Epoch: 6| Step: 8
Training loss: 3.217407390977873
Validation loss: 2.4816650606360926

Epoch: 6| Step: 9
Training loss: 2.7078841986301625
Validation loss: 2.4778445689329627

Epoch: 6| Step: 10
Training loss: 2.7948189962394205
Validation loss: 2.4774882038748256

Epoch: 6| Step: 11
Training loss: 2.7337116417725094
Validation loss: 2.476153670869302

Epoch: 6| Step: 12
Training loss: 2.560688774314709
Validation loss: 2.4768026027277488

Epoch: 6| Step: 13
Training loss: 2.448971189797514
Validation loss: 2.4722517990073523

Epoch: 106| Step: 0
Training loss: 3.01881674619695
Validation loss: 2.4836745184959597

Epoch: 6| Step: 1
Training loss: 3.1549361109725895
Validation loss: 2.490412927379508

Epoch: 6| Step: 2
Training loss: 2.5939137970094377
Validation loss: 2.4990941693377526

Epoch: 6| Step: 3
Training loss: 2.9275327362393284
Validation loss: 2.5095232020091487

Epoch: 6| Step: 4
Training loss: 2.871550771448733
Validation loss: 2.51015573754885

Epoch: 6| Step: 5
Training loss: 2.889146581388698
Validation loss: 2.582740437457851

Epoch: 6| Step: 6
Training loss: 3.0029004698781856
Validation loss: 2.594550857029911

Epoch: 6| Step: 7
Training loss: 2.7403095477037493
Validation loss: 2.6291453049512516

Epoch: 6| Step: 8
Training loss: 2.2640948159680416
Validation loss: 2.63942321023095

Epoch: 6| Step: 9
Training loss: 3.0451116692372713
Validation loss: 2.615499050690195

Epoch: 6| Step: 10
Training loss: 3.1650984210339406
Validation loss: 2.5608343467986567

Epoch: 6| Step: 11
Training loss: 2.18301848065692
Validation loss: 2.512848569481034

Epoch: 6| Step: 12
Training loss: 2.801897196395671
Validation loss: 2.4932067259994146

Epoch: 6| Step: 13
Training loss: 3.2096856640125333
Validation loss: 2.481050811680157

Epoch: 107| Step: 0
Training loss: 2.726467273000167
Validation loss: 2.4679247259594668

Epoch: 6| Step: 1
Training loss: 2.743420706694414
Validation loss: 2.4675356795288717

Epoch: 6| Step: 2
Training loss: 2.7238131327006556
Validation loss: 2.473174104510801

Epoch: 6| Step: 3
Training loss: 3.282748216365486
Validation loss: 2.474970753649102

Epoch: 6| Step: 4
Training loss: 2.8494646272245947
Validation loss: 2.4790599617693183

Epoch: 6| Step: 5
Training loss: 3.0598994521532235
Validation loss: 2.4801189558051986

Epoch: 6| Step: 6
Training loss: 3.0528902586359723
Validation loss: 2.479061399192981

Epoch: 6| Step: 7
Training loss: 3.198147362620983
Validation loss: 2.4868328669731423

Epoch: 6| Step: 8
Training loss: 2.197717401472127
Validation loss: 2.4822372130702686

Epoch: 6| Step: 9
Training loss: 3.505540821617453
Validation loss: 2.478814553410982

Epoch: 6| Step: 10
Training loss: 2.840964157957956
Validation loss: 2.4791061181643563

Epoch: 6| Step: 11
Training loss: 2.139933787774367
Validation loss: 2.46897546131452

Epoch: 6| Step: 12
Training loss: 2.592068322346775
Validation loss: 2.4673624725487504

Epoch: 6| Step: 13
Training loss: 3.1625591709798457
Validation loss: 2.476967220013139

Epoch: 108| Step: 0
Training loss: 2.5636361557464222
Validation loss: 2.4842392521968657

Epoch: 6| Step: 1
Training loss: 2.8477083261592058
Validation loss: 2.516692635947464

Epoch: 6| Step: 2
Training loss: 3.385454727350153
Validation loss: 2.5576386829148223

Epoch: 6| Step: 3
Training loss: 2.779056670048633
Validation loss: 2.56184835324371

Epoch: 6| Step: 4
Training loss: 2.3843019926760647
Validation loss: 2.6202191884087505

Epoch: 6| Step: 5
Training loss: 2.520261957237653
Validation loss: 2.697878373403614

Epoch: 6| Step: 6
Training loss: 2.7667702927390274
Validation loss: 2.746865536163422

Epoch: 6| Step: 7
Training loss: 3.26566340227682
Validation loss: 2.7975454704083877

Epoch: 6| Step: 8
Training loss: 2.725561444600627
Validation loss: 2.7473205273040207

Epoch: 6| Step: 9
Training loss: 3.136358447064315
Validation loss: 2.6835155841975107

Epoch: 6| Step: 10
Training loss: 3.3218197980368958
Validation loss: 2.591233802341409

Epoch: 6| Step: 11
Training loss: 2.3735961780657466
Validation loss: 2.5073354785738773

Epoch: 6| Step: 12
Training loss: 2.872450319927936
Validation loss: 2.48055008339954

Epoch: 6| Step: 13
Training loss: 3.074954031003658
Validation loss: 2.4696293535946165

Epoch: 109| Step: 0
Training loss: 3.2772753666323724
Validation loss: 2.474446344002626

Epoch: 6| Step: 1
Training loss: 2.3248837841890833
Validation loss: 2.4857842185452763

Epoch: 6| Step: 2
Training loss: 2.6146630709420937
Validation loss: 2.5057065254042628

Epoch: 6| Step: 3
Training loss: 2.4435965760599645
Validation loss: 2.524213132166705

Epoch: 6| Step: 4
Training loss: 2.9841100764898734
Validation loss: 2.514549859744391

Epoch: 6| Step: 5
Training loss: 2.799874684390538
Validation loss: 2.5018321932313814

Epoch: 6| Step: 6
Training loss: 2.9831559652387356
Validation loss: 2.4990470967275247

Epoch: 6| Step: 7
Training loss: 2.9729122497768157
Validation loss: 2.4945674691628383

Epoch: 6| Step: 8
Training loss: 2.787859659983739
Validation loss: 2.494467228376608

Epoch: 6| Step: 9
Training loss: 3.041943280606053
Validation loss: 2.49113717031872

Epoch: 6| Step: 10
Training loss: 3.0289115144154017
Validation loss: 2.4981686395987426

Epoch: 6| Step: 11
Training loss: 2.78305029733915
Validation loss: 2.4912788328252877

Epoch: 6| Step: 12
Training loss: 3.0562925682925854
Validation loss: 2.495427057269543

Epoch: 6| Step: 13
Training loss: 3.775438619230635
Validation loss: 2.4814927489668515

Epoch: 110| Step: 0
Training loss: 2.8536108733461703
Validation loss: 2.4852880336536995

Epoch: 6| Step: 1
Training loss: 3.245090297388966
Validation loss: 2.4787387904360916

Epoch: 6| Step: 2
Training loss: 2.309718340591816
Validation loss: 2.46307143851972

Epoch: 6| Step: 3
Training loss: 2.870429843254558
Validation loss: 2.4634122828626817

Epoch: 6| Step: 4
Training loss: 1.8462621740354341
Validation loss: 2.463676078678324

Epoch: 6| Step: 5
Training loss: 2.4447022672955936
Validation loss: 2.4662059148522197

Epoch: 6| Step: 6
Training loss: 3.2719227784611435
Validation loss: 2.464774917424881

Epoch: 6| Step: 7
Training loss: 3.2921250100670814
Validation loss: 2.474411772972823

Epoch: 6| Step: 8
Training loss: 3.199360044384426
Validation loss: 2.477866742922787

Epoch: 6| Step: 9
Training loss: 2.476518215421295
Validation loss: 2.4976792320618717

Epoch: 6| Step: 10
Training loss: 3.181640625
Validation loss: 2.4986324723136617

Epoch: 6| Step: 11
Training loss: 2.637654817927774
Validation loss: 2.4972173914965548

Epoch: 6| Step: 12
Training loss: 3.0611315414045404
Validation loss: 2.4887924479289993

Epoch: 6| Step: 13
Training loss: 2.9356077876976205
Validation loss: 2.4813053605471396

Epoch: 111| Step: 0
Training loss: 2.23856339998081
Validation loss: 2.4864792995611222

Epoch: 6| Step: 1
Training loss: 2.7011419530440057
Validation loss: 2.480252454630831

Epoch: 6| Step: 2
Training loss: 2.4840823786923085
Validation loss: 2.475990693409612

Epoch: 6| Step: 3
Training loss: 2.59359474177054
Validation loss: 2.4761366530620372

Epoch: 6| Step: 4
Training loss: 3.0555482710163866
Validation loss: 2.477132044210198

Epoch: 6| Step: 5
Training loss: 2.7385614227321358
Validation loss: 2.4649027042863874

Epoch: 6| Step: 6
Training loss: 3.0645371493021787
Validation loss: 2.463963217042167

Epoch: 6| Step: 7
Training loss: 2.6161899772279997
Validation loss: 2.471843617634697

Epoch: 6| Step: 8
Training loss: 3.093659678980638
Validation loss: 2.468503994546955

Epoch: 6| Step: 9
Training loss: 3.281783287671691
Validation loss: 2.468282528376889

Epoch: 6| Step: 10
Training loss: 3.0623527024326704
Validation loss: 2.4788242068056117

Epoch: 6| Step: 11
Training loss: 2.9342251642909583
Validation loss: 2.479660054022579

Epoch: 6| Step: 12
Training loss: 3.0340582040875574
Validation loss: 2.4831769431367925

Epoch: 6| Step: 13
Training loss: 2.361137893624589
Validation loss: 2.488248011730438

Epoch: 112| Step: 0
Training loss: 2.5216997617510946
Validation loss: 2.485495385569085

Epoch: 6| Step: 1
Training loss: 2.833487973948494
Validation loss: 2.484709954636797

Epoch: 6| Step: 2
Training loss: 2.6506649766465036
Validation loss: 2.5097722972080363

Epoch: 6| Step: 3
Training loss: 3.1004758223556923
Validation loss: 2.520583163154752

Epoch: 6| Step: 4
Training loss: 3.222978795411758
Validation loss: 2.5363937945490496

Epoch: 6| Step: 5
Training loss: 3.550854437716928
Validation loss: 2.5204138274953047

Epoch: 6| Step: 6
Training loss: 2.775924298427788
Validation loss: 2.4964775557974126

Epoch: 6| Step: 7
Training loss: 2.782964113914942
Validation loss: 2.4778892550305707

Epoch: 6| Step: 8
Training loss: 2.5048889992918237
Validation loss: 2.470438521911141

Epoch: 6| Step: 9
Training loss: 2.449178059557825
Validation loss: 2.472162219091315

Epoch: 6| Step: 10
Training loss: 3.0582198770736415
Validation loss: 2.472035481582698

Epoch: 6| Step: 11
Training loss: 2.852055420795854
Validation loss: 2.468696858986919

Epoch: 6| Step: 12
Training loss: 2.7878264779120068
Validation loss: 2.466953355408218

Epoch: 6| Step: 13
Training loss: 1.8119970478850647
Validation loss: 2.464843323566174

Epoch: 113| Step: 0
Training loss: 3.120053458122628
Validation loss: 2.463245910971981

Epoch: 6| Step: 1
Training loss: 2.788828436596108
Validation loss: 2.4654906660525953

Epoch: 6| Step: 2
Training loss: 3.1202733724602205
Validation loss: 2.4562211467375126

Epoch: 6| Step: 3
Training loss: 2.411412633431258
Validation loss: 2.453752298373302

Epoch: 6| Step: 4
Training loss: 2.5721912880180122
Validation loss: 2.4528666226245357

Epoch: 6| Step: 5
Training loss: 3.0142050448853515
Validation loss: 2.4576731063430994

Epoch: 6| Step: 6
Training loss: 2.7096624976434343
Validation loss: 2.451298860814074

Epoch: 6| Step: 7
Training loss: 3.123080465149253
Validation loss: 2.4690648225150498

Epoch: 6| Step: 8
Training loss: 2.5158497964632662
Validation loss: 2.4692570851058004

Epoch: 6| Step: 9
Training loss: 1.9652043461045576
Validation loss: 2.473782299538307

Epoch: 6| Step: 10
Training loss: 2.552417177954533
Validation loss: 2.4694905912857146

Epoch: 6| Step: 11
Training loss: 3.1953659239688847
Validation loss: 2.4776463526663943

Epoch: 6| Step: 12
Training loss: 3.402229105685454
Validation loss: 2.468315151635895

Epoch: 6| Step: 13
Training loss: 3.0114253553082238
Validation loss: 2.47683450464068

Epoch: 114| Step: 0
Training loss: 2.7623922991579275
Validation loss: 2.4534166616097117

Epoch: 6| Step: 1
Training loss: 2.7693769791306964
Validation loss: 2.4491210296255157

Epoch: 6| Step: 2
Training loss: 3.197696607807103
Validation loss: 2.451401511012476

Epoch: 6| Step: 3
Training loss: 2.489984094346809
Validation loss: 2.449208553901587

Epoch: 6| Step: 4
Training loss: 2.426647578293618
Validation loss: 2.45051411522347

Epoch: 6| Step: 5
Training loss: 3.439030531960404
Validation loss: 2.456883260043703

Epoch: 6| Step: 6
Training loss: 2.7118692253562986
Validation loss: 2.4603386596518177

Epoch: 6| Step: 7
Training loss: 3.0635146970749685
Validation loss: 2.4549717177636246

Epoch: 6| Step: 8
Training loss: 2.7275517371539113
Validation loss: 2.4558696035719327

Epoch: 6| Step: 9
Training loss: 2.5531945955649884
Validation loss: 2.452854611604432

Epoch: 6| Step: 10
Training loss: 2.566682519079358
Validation loss: 2.4555982040376336

Epoch: 6| Step: 11
Training loss: 2.889947430353625
Validation loss: 2.455086613446248

Epoch: 6| Step: 12
Training loss: 2.972275898845843
Validation loss: 2.461191002126629

Epoch: 6| Step: 13
Training loss: 2.8849785170259366
Validation loss: 2.4670658163886863

Epoch: 115| Step: 0
Training loss: 2.664295354158749
Validation loss: 2.4635829194074264

Epoch: 6| Step: 1
Training loss: 3.2678238616130066
Validation loss: 2.4682516989489307

Epoch: 6| Step: 2
Training loss: 2.421961136793575
Validation loss: 2.466417445646767

Epoch: 6| Step: 3
Training loss: 2.253124822227693
Validation loss: 2.472964561530691

Epoch: 6| Step: 4
Training loss: 3.0574490681583435
Validation loss: 2.476786896151807

Epoch: 6| Step: 5
Training loss: 3.3572037178250764
Validation loss: 2.4898016170560657

Epoch: 6| Step: 6
Training loss: 3.448311190588615
Validation loss: 2.5042369419960737

Epoch: 6| Step: 7
Training loss: 2.664157451828083
Validation loss: 2.509266139636646

Epoch: 6| Step: 8
Training loss: 2.7822739505715557
Validation loss: 2.503129452457964

Epoch: 6| Step: 9
Training loss: 2.4879730848224186
Validation loss: 2.5162084859835296

Epoch: 6| Step: 10
Training loss: 3.144939287142442
Validation loss: 2.5376300001140875

Epoch: 6| Step: 11
Training loss: 2.167720636140104
Validation loss: 2.5451522406953395

Epoch: 6| Step: 12
Training loss: 2.432995081171033
Validation loss: 2.530431334757438

Epoch: 6| Step: 13
Training loss: 2.9698455395334156
Validation loss: 2.5476341090146013

Epoch: 116| Step: 0
Training loss: 2.936306650160098
Validation loss: 2.5363319545564624

Epoch: 6| Step: 1
Training loss: 2.554149045981964
Validation loss: 2.51724045564874

Epoch: 6| Step: 2
Training loss: 2.561932570738207
Validation loss: 2.4974199312465704

Epoch: 6| Step: 3
Training loss: 3.231859048668649
Validation loss: 2.520666925613706

Epoch: 6| Step: 4
Training loss: 3.058446264304106
Validation loss: 2.510609561448598

Epoch: 6| Step: 5
Training loss: 2.6277312647184563
Validation loss: 2.5174819348884427

Epoch: 6| Step: 6
Training loss: 3.05106835961943
Validation loss: 2.520003326978309

Epoch: 6| Step: 7
Training loss: 2.673936015502697
Validation loss: 2.5185879014074724

Epoch: 6| Step: 8
Training loss: 2.9720111803689084
Validation loss: 2.5160190653494094

Epoch: 6| Step: 9
Training loss: 3.131561410003646
Validation loss: 2.492824497081086

Epoch: 6| Step: 10
Training loss: 2.7707444561540844
Validation loss: 2.4841459507556984

Epoch: 6| Step: 11
Training loss: 2.541963486980217
Validation loss: 2.4751485997288962

Epoch: 6| Step: 12
Training loss: 2.2829319227497593
Validation loss: 2.4648191581687473

Epoch: 6| Step: 13
Training loss: 2.615913741605737
Validation loss: 2.4641738438107357

Epoch: 117| Step: 0
Training loss: 3.481018502501574
Validation loss: 2.4630644920051115

Epoch: 6| Step: 1
Training loss: 2.7467883169061
Validation loss: 2.4598779478591424

Epoch: 6| Step: 2
Training loss: 2.5946334804942697
Validation loss: 2.4591733068593924

Epoch: 6| Step: 3
Training loss: 2.841141395087524
Validation loss: 2.4568742680765374

Epoch: 6| Step: 4
Training loss: 2.95965403416567
Validation loss: 2.4561598631523793

Epoch: 6| Step: 5
Training loss: 2.9916884999731477
Validation loss: 2.453474454781211

Epoch: 6| Step: 6
Training loss: 3.1514614529692064
Validation loss: 2.4514898804025713

Epoch: 6| Step: 7
Training loss: 3.330344306398021
Validation loss: 2.4509333213819935

Epoch: 6| Step: 8
Training loss: 2.6817364658196623
Validation loss: 2.460115814410739

Epoch: 6| Step: 9
Training loss: 2.222350087725728
Validation loss: 2.4558881105046737

Epoch: 6| Step: 10
Training loss: 2.383547610096078
Validation loss: 2.473151060731331

Epoch: 6| Step: 11
Training loss: 2.1351736783357262
Validation loss: 2.5031449829875414

Epoch: 6| Step: 12
Training loss: 2.360668509892618
Validation loss: 2.543269721210748

Epoch: 6| Step: 13
Training loss: 3.348170985350592
Validation loss: 2.551450120340146

Epoch: 118| Step: 0
Training loss: 2.6414224898869483
Validation loss: 2.5343536072585997

Epoch: 6| Step: 1
Training loss: 2.7829762791326202
Validation loss: 2.5031396352893585

Epoch: 6| Step: 2
Training loss: 2.720598491291552
Validation loss: 2.4945577050663976

Epoch: 6| Step: 3
Training loss: 3.136062420389243
Validation loss: 2.474802361870626

Epoch: 6| Step: 4
Training loss: 2.5006871232847208
Validation loss: 2.4631416977605083

Epoch: 6| Step: 5
Training loss: 2.6957901241214137
Validation loss: 2.4790162037122694

Epoch: 6| Step: 6
Training loss: 2.5093567273910526
Validation loss: 2.4680522536526874

Epoch: 6| Step: 7
Training loss: 2.6097352470202404
Validation loss: 2.4622653715522054

Epoch: 6| Step: 8
Training loss: 2.2018274043642974
Validation loss: 2.465098150390463

Epoch: 6| Step: 9
Training loss: 2.3155427452232566
Validation loss: 2.4727415094666454

Epoch: 6| Step: 10
Training loss: 3.187451231340309
Validation loss: 2.478195373117745

Epoch: 6| Step: 11
Training loss: 3.245610133386241
Validation loss: 2.4754273784877863

Epoch: 6| Step: 12
Training loss: 3.2527825108367105
Validation loss: 2.468254771782265

Epoch: 6| Step: 13
Training loss: 3.222012246258394
Validation loss: 2.465479122060416

Epoch: 119| Step: 0
Training loss: 3.1357967784196212
Validation loss: 2.4718264301394957

Epoch: 6| Step: 1
Training loss: 2.737630595397317
Validation loss: 2.459216241050979

Epoch: 6| Step: 2
Training loss: 2.306848889670533
Validation loss: 2.4697287402778008

Epoch: 6| Step: 3
Training loss: 3.160228676549521
Validation loss: 2.4634830090034048

Epoch: 6| Step: 4
Training loss: 2.929170201725859
Validation loss: 2.461903776318412

Epoch: 6| Step: 5
Training loss: 2.113825870643409
Validation loss: 2.469373579335871

Epoch: 6| Step: 6
Training loss: 3.029624581827181
Validation loss: 2.4661460052028277

Epoch: 6| Step: 7
Training loss: 2.503910725272668
Validation loss: 2.477010596137547

Epoch: 6| Step: 8
Training loss: 2.88749731815098
Validation loss: 2.4800124269538655

Epoch: 6| Step: 9
Training loss: 3.0078302556294108
Validation loss: 2.4797228400179816

Epoch: 6| Step: 10
Training loss: 2.7791763461819925
Validation loss: 2.5005941341292486

Epoch: 6| Step: 11
Training loss: 2.7847085087270194
Validation loss: 2.5092951559038195

Epoch: 6| Step: 12
Training loss: 2.8412206111383234
Validation loss: 2.4953293218538866

Epoch: 6| Step: 13
Training loss: 2.524588496602754
Validation loss: 2.4977376053167846

Epoch: 120| Step: 0
Training loss: 2.6851815269951973
Validation loss: 2.4966382491573347

Epoch: 6| Step: 1
Training loss: 3.264869858162016
Validation loss: 2.4944832968948796

Epoch: 6| Step: 2
Training loss: 2.5740796342459844
Validation loss: 2.4940099367243973

Epoch: 6| Step: 3
Training loss: 2.5984315102531688
Validation loss: 2.482595475978948

Epoch: 6| Step: 4
Training loss: 2.9816377079770873
Validation loss: 2.473511638285193

Epoch: 6| Step: 5
Training loss: 2.8861131252183476
Validation loss: 2.465474086234249

Epoch: 6| Step: 6
Training loss: 3.083271352471461
Validation loss: 2.4578119149592097

Epoch: 6| Step: 7
Training loss: 2.9569711011365234
Validation loss: 2.453808526948056

Epoch: 6| Step: 8
Training loss: 2.959470199133302
Validation loss: 2.455417456203749

Epoch: 6| Step: 9
Training loss: 2.7573292770866256
Validation loss: 2.456328876473745

Epoch: 6| Step: 10
Training loss: 1.9266630865787564
Validation loss: 2.4634249105238974

Epoch: 6| Step: 11
Training loss: 2.9467146796490624
Validation loss: 2.481036736187776

Epoch: 6| Step: 12
Training loss: 2.345687065736555
Validation loss: 2.4834071532902557

Epoch: 6| Step: 13
Training loss: 3.1490830736925775
Validation loss: 2.49609233470949

Epoch: 121| Step: 0
Training loss: 2.558677893266935
Validation loss: 2.482265787227826

Epoch: 6| Step: 1
Training loss: 2.6740796546969774
Validation loss: 2.494792998774661

Epoch: 6| Step: 2
Training loss: 2.7675970772772036
Validation loss: 2.4853812819060925

Epoch: 6| Step: 3
Training loss: 2.5843510212644953
Validation loss: 2.492535741444058

Epoch: 6| Step: 4
Training loss: 3.191017454036843
Validation loss: 2.486850640411332

Epoch: 6| Step: 5
Training loss: 2.219370150870996
Validation loss: 2.4772149287622796

Epoch: 6| Step: 6
Training loss: 2.5222261432536937
Validation loss: 2.4687697374877065

Epoch: 6| Step: 7
Training loss: 2.8081667261103465
Validation loss: 2.4588065264677437

Epoch: 6| Step: 8
Training loss: 3.1448184433098576
Validation loss: 2.4560276893513735

Epoch: 6| Step: 9
Training loss: 2.7225438098867993
Validation loss: 2.44912162837186

Epoch: 6| Step: 10
Training loss: 2.9688234018989066
Validation loss: 2.4478486843439473

Epoch: 6| Step: 11
Training loss: 2.557584001311998
Validation loss: 2.462854505254581

Epoch: 6| Step: 12
Training loss: 3.2613493019153905
Validation loss: 2.458499375338169

Epoch: 6| Step: 13
Training loss: 2.9196190922654446
Validation loss: 2.473980510376955

Epoch: 122| Step: 0
Training loss: 2.7164004466510754
Validation loss: 2.4736594713365045

Epoch: 6| Step: 1
Training loss: 3.4259855759690594
Validation loss: 2.5014174391104063

Epoch: 6| Step: 2
Training loss: 3.2892521239503836
Validation loss: 2.518794005134334

Epoch: 6| Step: 3
Training loss: 3.204958209689245
Validation loss: 2.5323005500533333

Epoch: 6| Step: 4
Training loss: 2.138752138904815
Validation loss: 2.5355512746499684

Epoch: 6| Step: 5
Training loss: 2.115289604614262
Validation loss: 2.5298945470325673

Epoch: 6| Step: 6
Training loss: 2.3614605913009807
Validation loss: 2.492397437734852

Epoch: 6| Step: 7
Training loss: 2.7274283971574933
Validation loss: 2.4757565820373215

Epoch: 6| Step: 8
Training loss: 2.678174183771131
Validation loss: 2.468148601277679

Epoch: 6| Step: 9
Training loss: 2.7806565583852527
Validation loss: 2.469010397118427

Epoch: 6| Step: 10
Training loss: 2.7940451515170297
Validation loss: 2.4682588993542987

Epoch: 6| Step: 11
Training loss: 2.940706167205561
Validation loss: 2.4604055866016523

Epoch: 6| Step: 12
Training loss: 2.8279294109680264
Validation loss: 2.472181923114463

Epoch: 6| Step: 13
Training loss: 2.763746151414639
Validation loss: 2.4534038580891506

Epoch: 123| Step: 0
Training loss: 2.898926233590688
Validation loss: 2.451679370982423

Epoch: 6| Step: 1
Training loss: 2.7367132162331647
Validation loss: 2.4464339837250906

Epoch: 6| Step: 2
Training loss: 2.2331978424687717
Validation loss: 2.445187975381559

Epoch: 6| Step: 3
Training loss: 2.9160337760549453
Validation loss: 2.443704368228844

Epoch: 6| Step: 4
Training loss: 2.7280628699779794
Validation loss: 2.452294724309185

Epoch: 6| Step: 5
Training loss: 2.9579497791641307
Validation loss: 2.4543251449677372

Epoch: 6| Step: 6
Training loss: 2.451325746851139
Validation loss: 2.466125648979795

Epoch: 6| Step: 7
Training loss: 2.518414958318568
Validation loss: 2.4673564711580007

Epoch: 6| Step: 8
Training loss: 2.3290505841512235
Validation loss: 2.488822301357455

Epoch: 6| Step: 9
Training loss: 3.1809189120153465
Validation loss: 2.496553649700588

Epoch: 6| Step: 10
Training loss: 2.712374875043742
Validation loss: 2.498678455942718

Epoch: 6| Step: 11
Training loss: 3.059745639875528
Validation loss: 2.523285413460361

Epoch: 6| Step: 12
Training loss: 2.8143124991975657
Validation loss: 2.535463511542763

Epoch: 6| Step: 13
Training loss: 3.1888400981979323
Validation loss: 2.536762009562156

Epoch: 124| Step: 0
Training loss: 3.0083188113833366
Validation loss: 2.5313252425572395

Epoch: 6| Step: 1
Training loss: 2.32373698394561
Validation loss: 2.498891782728289

Epoch: 6| Step: 2
Training loss: 2.2838632952436284
Validation loss: 2.469631390281152

Epoch: 6| Step: 3
Training loss: 2.8717822436606997
Validation loss: 2.4626621925214134

Epoch: 6| Step: 4
Training loss: 2.612786991837562
Validation loss: 2.4431942597832332

Epoch: 6| Step: 5
Training loss: 2.8617552142328604
Validation loss: 2.448873266921112

Epoch: 6| Step: 6
Training loss: 2.6560992029806076
Validation loss: 2.4447656259966126

Epoch: 6| Step: 7
Training loss: 2.946003718936435
Validation loss: 2.4462346879067804

Epoch: 6| Step: 8
Training loss: 2.537242248673664
Validation loss: 2.4429346694231593

Epoch: 6| Step: 9
Training loss: 2.587506973330919
Validation loss: 2.438878955885152

Epoch: 6| Step: 10
Training loss: 2.8029436305812183
Validation loss: 2.4448718723989504

Epoch: 6| Step: 11
Training loss: 2.8760974282221348
Validation loss: 2.443498779825418

Epoch: 6| Step: 12
Training loss: 3.4026451984623156
Validation loss: 2.4423338973942323

Epoch: 6| Step: 13
Training loss: 2.9479049484685014
Validation loss: 2.4670420021735926

Epoch: 125| Step: 0
Training loss: 2.8219406204789346
Validation loss: 2.489966291281069

Epoch: 6| Step: 1
Training loss: 2.6301451621951877
Validation loss: 2.509535827497085

Epoch: 6| Step: 2
Training loss: 3.1326138630819695
Validation loss: 2.5518197950482477

Epoch: 6| Step: 3
Training loss: 2.6946123623605365
Validation loss: 2.5950746224037498

Epoch: 6| Step: 4
Training loss: 2.5314607885685407
Validation loss: 2.5868524005424605

Epoch: 6| Step: 5
Training loss: 2.8239506215649572
Validation loss: 2.5961320823049574

Epoch: 6| Step: 6
Training loss: 2.3309492351841588
Validation loss: 2.535887689111181

Epoch: 6| Step: 7
Training loss: 2.731306697859286
Validation loss: 2.488867531987612

Epoch: 6| Step: 8
Training loss: 2.796602715392678
Validation loss: 2.4612750953266507

Epoch: 6| Step: 9
Training loss: 2.8123933559968064
Validation loss: 2.4441543819828553

Epoch: 6| Step: 10
Training loss: 2.9820026335368817
Validation loss: 2.446744680071528

Epoch: 6| Step: 11
Training loss: 2.739886500381566
Validation loss: 2.4421729663850513

Epoch: 6| Step: 12
Training loss: 3.0294972494276258
Validation loss: 2.43237124604017

Epoch: 6| Step: 13
Training loss: 3.0377244528897895
Validation loss: 2.4334593391608124

Epoch: 126| Step: 0
Training loss: 2.1579225107445192
Validation loss: 2.4303372899119755

Epoch: 6| Step: 1
Training loss: 2.274982150500354
Validation loss: 2.4304337497861965

Epoch: 6| Step: 2
Training loss: 2.960999983880617
Validation loss: 2.4427003238290497

Epoch: 6| Step: 3
Training loss: 3.061291358827247
Validation loss: 2.435342639101985

Epoch: 6| Step: 4
Training loss: 2.7070895542399946
Validation loss: 2.439600544011975

Epoch: 6| Step: 5
Training loss: 2.4898318455306483
Validation loss: 2.442043395943087

Epoch: 6| Step: 6
Training loss: 3.0307626234114364
Validation loss: 2.449490013853057

Epoch: 6| Step: 7
Training loss: 2.9149986583778604
Validation loss: 2.4440084796079904

Epoch: 6| Step: 8
Training loss: 2.539048227123345
Validation loss: 2.46501564362706

Epoch: 6| Step: 9
Training loss: 2.7343658447112356
Validation loss: 2.47081634911857

Epoch: 6| Step: 10
Training loss: 2.2347433146773517
Validation loss: 2.5031866580790934

Epoch: 6| Step: 11
Training loss: 3.818316665761783
Validation loss: 2.5323669033528216

Epoch: 6| Step: 12
Training loss: 2.4025977023738085
Validation loss: 2.546440904359518

Epoch: 6| Step: 13
Training loss: 3.1027611402951383
Validation loss: 2.546200270629414

Epoch: 127| Step: 0
Training loss: 2.8937209587205324
Validation loss: 2.5301037553780623

Epoch: 6| Step: 1
Training loss: 3.084096006628293
Validation loss: 2.529407833046033

Epoch: 6| Step: 2
Training loss: 2.4618640911231515
Validation loss: 2.487436324803247

Epoch: 6| Step: 3
Training loss: 2.7485359803166514
Validation loss: 2.4560641125135474

Epoch: 6| Step: 4
Training loss: 2.5586448140181077
Validation loss: 2.445380530114936

Epoch: 6| Step: 5
Training loss: 2.675079387306768
Validation loss: 2.44767324633278

Epoch: 6| Step: 6
Training loss: 2.9487422330785567
Validation loss: 2.445389395036225

Epoch: 6| Step: 7
Training loss: 2.8134019041367764
Validation loss: 2.438808818638969

Epoch: 6| Step: 8
Training loss: 2.821234301454527
Validation loss: 2.448299507011256

Epoch: 6| Step: 9
Training loss: 2.379638258586741
Validation loss: 2.4455917813794135

Epoch: 6| Step: 10
Training loss: 2.6442492290999544
Validation loss: 2.4497085649085673

Epoch: 6| Step: 11
Training loss: 2.855368052740972
Validation loss: 2.4497181624184705

Epoch: 6| Step: 12
Training loss: 2.4324097914400964
Validation loss: 2.456874100080087

Epoch: 6| Step: 13
Training loss: 3.707295576184448
Validation loss: 2.494059136562481

Epoch: 128| Step: 0
Training loss: 2.842340140834008
Validation loss: 2.4847942103606138

Epoch: 6| Step: 1
Training loss: 3.508861087661825
Validation loss: 2.4877499929100217

Epoch: 6| Step: 2
Training loss: 2.96707475477158
Validation loss: 2.4876011324181087

Epoch: 6| Step: 3
Training loss: 2.266833594664248
Validation loss: 2.4821378996418386

Epoch: 6| Step: 4
Training loss: 2.941459098027068
Validation loss: 2.4981183764516164

Epoch: 6| Step: 5
Training loss: 2.4484441527061422
Validation loss: 2.4925736814641213

Epoch: 6| Step: 6
Training loss: 2.9697018352308264
Validation loss: 2.4857462811250866

Epoch: 6| Step: 7
Training loss: 2.163479172072318
Validation loss: 2.4893772202795086

Epoch: 6| Step: 8
Training loss: 2.001644173950227
Validation loss: 2.4818542202703453

Epoch: 6| Step: 9
Training loss: 2.8798589695732235
Validation loss: 2.4883751783458536

Epoch: 6| Step: 10
Training loss: 2.3848989888359386
Validation loss: 2.46087863511201

Epoch: 6| Step: 11
Training loss: 3.0067009791793797
Validation loss: 2.455525617930956

Epoch: 6| Step: 12
Training loss: 2.5666536301946468
Validation loss: 2.4552154965955566

Epoch: 6| Step: 13
Training loss: 3.172422765779174
Validation loss: 2.450064704556253

Epoch: 129| Step: 0
Training loss: 2.661021894190708
Validation loss: 2.4543633215610274

Epoch: 6| Step: 1
Training loss: 3.3175669369991203
Validation loss: 2.4599820669374095

Epoch: 6| Step: 2
Training loss: 2.4552282562116496
Validation loss: 2.4860083649548974

Epoch: 6| Step: 3
Training loss: 2.418082337800517
Validation loss: 2.489145116192804

Epoch: 6| Step: 4
Training loss: 2.657390394561259
Validation loss: 2.5145762805360814

Epoch: 6| Step: 5
Training loss: 2.7450807094694802
Validation loss: 2.522716843336895

Epoch: 6| Step: 6
Training loss: 2.73630398964976
Validation loss: 2.5094773241349784

Epoch: 6| Step: 7
Training loss: 3.27106836207532
Validation loss: 2.5226704991180644

Epoch: 6| Step: 8
Training loss: 1.7938872334688678
Validation loss: 2.4806874829970913

Epoch: 6| Step: 9
Training loss: 3.01505950211095
Validation loss: 2.473471559952293

Epoch: 6| Step: 10
Training loss: 1.9699209454935345
Validation loss: 2.4580859165260227

Epoch: 6| Step: 11
Training loss: 2.8130899446375857
Validation loss: 2.4507610049085553

Epoch: 6| Step: 12
Training loss: 3.515238287107849
Validation loss: 2.4757452816234164

Epoch: 6| Step: 13
Training loss: 1.8612962301749882
Validation loss: 2.4574092044318143

Epoch: 130| Step: 0
Training loss: 2.242405472105918
Validation loss: 2.463080222075247

Epoch: 6| Step: 1
Training loss: 2.779551984240133
Validation loss: 2.463282112400428

Epoch: 6| Step: 2
Training loss: 3.2584602571890704
Validation loss: 2.4657556233529947

Epoch: 6| Step: 3
Training loss: 2.689118984411623
Validation loss: 2.4723753483247575

Epoch: 6| Step: 4
Training loss: 2.9363514704281815
Validation loss: 2.4612088003264083

Epoch: 6| Step: 5
Training loss: 2.6561209254600033
Validation loss: 2.4667982551354486

Epoch: 6| Step: 6
Training loss: 2.470726477471161
Validation loss: 2.4781477349100216

Epoch: 6| Step: 7
Training loss: 3.0268787445290952
Validation loss: 2.4819666335651664

Epoch: 6| Step: 8
Training loss: 2.725603869661765
Validation loss: 2.460820499105821

Epoch: 6| Step: 9
Training loss: 1.6134117387735394
Validation loss: 2.4613839422466937

Epoch: 6| Step: 10
Training loss: 2.73162598978991
Validation loss: 2.4473844303484467

Epoch: 6| Step: 11
Training loss: 2.5393225903446126
Validation loss: 2.445280564266157

Epoch: 6| Step: 12
Training loss: 3.39689639873485
Validation loss: 2.4476694988091965

Epoch: 6| Step: 13
Training loss: 2.5564874963094617
Validation loss: 2.455139226748065

Epoch: 131| Step: 0
Training loss: 2.7137700214815896
Validation loss: 2.4699969867111506

Epoch: 6| Step: 1
Training loss: 2.649617880135942
Validation loss: 2.526365127549001

Epoch: 6| Step: 2
Training loss: 2.5659055642391646
Validation loss: 2.5497575727893453

Epoch: 6| Step: 3
Training loss: 3.0631945075566924
Validation loss: 2.5851056181925998

Epoch: 6| Step: 4
Training loss: 3.343613951580258
Validation loss: 2.523217931310549

Epoch: 6| Step: 5
Training loss: 1.8681202876879315
Validation loss: 2.5273639336879827

Epoch: 6| Step: 6
Training loss: 2.885565541600649
Validation loss: 2.539886104766445

Epoch: 6| Step: 7
Training loss: 2.1843356542359076
Validation loss: 2.5034505033153733

Epoch: 6| Step: 8
Training loss: 2.6717774668956027
Validation loss: 2.4793290474308964

Epoch: 6| Step: 9
Training loss: 2.695924728078537
Validation loss: 2.473552050732634

Epoch: 6| Step: 10
Training loss: 3.0930779237646875
Validation loss: 2.4445642881328085

Epoch: 6| Step: 11
Training loss: 3.113804102013769
Validation loss: 2.457033259567377

Epoch: 6| Step: 12
Training loss: 2.8872388647328653
Validation loss: 2.455249058837995

Epoch: 6| Step: 13
Training loss: 2.045892261140737
Validation loss: 2.466469996022093

Epoch: 132| Step: 0
Training loss: 2.9156560145912898
Validation loss: 2.469840302629022

Epoch: 6| Step: 1
Training loss: 2.6918679161146852
Validation loss: 2.466959732927359

Epoch: 6| Step: 2
Training loss: 2.7963073836446672
Validation loss: 2.494891069632558

Epoch: 6| Step: 3
Training loss: 3.1781953126824414
Validation loss: 2.5249036977088486

Epoch: 6| Step: 4
Training loss: 3.105084857364698
Validation loss: 2.5538676266124045

Epoch: 6| Step: 5
Training loss: 2.5688378646191214
Validation loss: 2.5800757681107624

Epoch: 6| Step: 6
Training loss: 2.8833315002200375
Validation loss: 2.5682915509424915

Epoch: 6| Step: 7
Training loss: 2.2869628025327513
Validation loss: 2.5124857994416616

Epoch: 6| Step: 8
Training loss: 2.967775847574293
Validation loss: 2.480272162601164

Epoch: 6| Step: 9
Training loss: 2.9112789164737194
Validation loss: 2.4693748459084133

Epoch: 6| Step: 10
Training loss: 2.3456777147223815
Validation loss: 2.4402284457354626

Epoch: 6| Step: 11
Training loss: 2.5280274965324008
Validation loss: 2.4413320280216424

Epoch: 6| Step: 12
Training loss: 2.2583452803892814
Validation loss: 2.4375944232347657

Epoch: 6| Step: 13
Training loss: 2.802623446193288
Validation loss: 2.4425837004424213

Epoch: 133| Step: 0
Training loss: 2.282165134763815
Validation loss: 2.455426573052053

Epoch: 6| Step: 1
Training loss: 2.305277499956706
Validation loss: 2.4550292132678955

Epoch: 6| Step: 2
Training loss: 2.5683762698469987
Validation loss: 2.4746250337564883

Epoch: 6| Step: 3
Training loss: 2.5898833350929324
Validation loss: 2.4861497453431523

Epoch: 6| Step: 4
Training loss: 2.7551847479711555
Validation loss: 2.5004820615266867

Epoch: 6| Step: 5
Training loss: 2.900789442803371
Validation loss: 2.515754127232908

Epoch: 6| Step: 6
Training loss: 2.542411403256405
Validation loss: 2.5060427760710646

Epoch: 6| Step: 7
Training loss: 2.995225444836009
Validation loss: 2.514831986626437

Epoch: 6| Step: 8
Training loss: 2.8351316541885723
Validation loss: 2.491298598663352

Epoch: 6| Step: 9
Training loss: 2.250383132527451
Validation loss: 2.464311349199952

Epoch: 6| Step: 10
Training loss: 2.930786252294873
Validation loss: 2.452744569862054

Epoch: 6| Step: 11
Training loss: 3.1541615743524587
Validation loss: 2.4528133480973535

Epoch: 6| Step: 12
Training loss: 2.73444074279226
Validation loss: 2.4419805482125927

Epoch: 6| Step: 13
Training loss: 3.219767289371249
Validation loss: 2.4378972283338762

Epoch: 134| Step: 0
Training loss: 2.721160258757119
Validation loss: 2.4566156056731807

Epoch: 6| Step: 1
Training loss: 2.0085110766423764
Validation loss: 2.4619600259408267

Epoch: 6| Step: 2
Training loss: 2.1352053902167456
Validation loss: 2.4627300494175213

Epoch: 6| Step: 3
Training loss: 3.2337025113742097
Validation loss: 2.4931740742105433

Epoch: 6| Step: 4
Training loss: 2.5147772835619437
Validation loss: 2.4933312285818383

Epoch: 6| Step: 5
Training loss: 2.630404403982629
Validation loss: 2.504661344969002

Epoch: 6| Step: 6
Training loss: 2.855158464139369
Validation loss: 2.5242602666378593

Epoch: 6| Step: 7
Training loss: 2.7002660373027494
Validation loss: 2.56509868312458

Epoch: 6| Step: 8
Training loss: 3.3412497611568437
Validation loss: 2.5776700431005852

Epoch: 6| Step: 9
Training loss: 3.087668867551139
Validation loss: 2.5899534885078475

Epoch: 6| Step: 10
Training loss: 2.760860930386537
Validation loss: 2.5752740324896997

Epoch: 6| Step: 11
Training loss: 2.852411013259136
Validation loss: 2.559134260090043

Epoch: 6| Step: 12
Training loss: 2.3831488700209498
Validation loss: 2.5038853939566748

Epoch: 6| Step: 13
Training loss: 2.2055049513556075
Validation loss: 2.455044581305449

Epoch: 135| Step: 0
Training loss: 2.5847072844358645
Validation loss: 2.4366973773437315

Epoch: 6| Step: 1
Training loss: 2.9911648668607667
Validation loss: 2.432521782744975

Epoch: 6| Step: 2
Training loss: 2.8622448803351683
Validation loss: 2.430999688521865

Epoch: 6| Step: 3
Training loss: 2.8692157442089306
Validation loss: 2.433352131952866

Epoch: 6| Step: 4
Training loss: 2.1861128632429256
Validation loss: 2.429611548312981

Epoch: 6| Step: 5
Training loss: 3.0159949831731137
Validation loss: 2.4243976529132283

Epoch: 6| Step: 6
Training loss: 2.2409650813203275
Validation loss: 2.4352651162821806

Epoch: 6| Step: 7
Training loss: 2.2452924012072337
Validation loss: 2.4306149558579424

Epoch: 6| Step: 8
Training loss: 3.427969465317824
Validation loss: 2.451158213629437

Epoch: 6| Step: 9
Training loss: 3.114379689034904
Validation loss: 2.4840110718120365

Epoch: 6| Step: 10
Training loss: 2.291756460569174
Validation loss: 2.5248079329017212

Epoch: 6| Step: 11
Training loss: 2.619102938592123
Validation loss: 2.53749909864905

Epoch: 6| Step: 12
Training loss: 2.719942554820943
Validation loss: 2.581288151020975

Epoch: 6| Step: 13
Training loss: 2.915358513432065
Validation loss: 2.570565060272256

Epoch: 136| Step: 0
Training loss: 2.9804074742329076
Validation loss: 2.5253285592152683

Epoch: 6| Step: 1
Training loss: 2.672317735899682
Validation loss: 2.5003889345323103

Epoch: 6| Step: 2
Training loss: 3.330881329546064
Validation loss: 2.4863699004963022

Epoch: 6| Step: 3
Training loss: 2.1149133384030367
Validation loss: 2.501545596468032

Epoch: 6| Step: 4
Training loss: 2.611205595304534
Validation loss: 2.5009443242859972

Epoch: 6| Step: 5
Training loss: 3.0221591188661945
Validation loss: 2.4866572225749235

Epoch: 6| Step: 6
Training loss: 2.922287039849769
Validation loss: 2.486966006430955

Epoch: 6| Step: 7
Training loss: 2.4422614713023183
Validation loss: 2.4691407764216464

Epoch: 6| Step: 8
Training loss: 3.014330650413045
Validation loss: 2.4718864105767295

Epoch: 6| Step: 9
Training loss: 2.6021912877392084
Validation loss: 2.4607640119486525

Epoch: 6| Step: 10
Training loss: 1.9543707574957512
Validation loss: 2.456878710065475

Epoch: 6| Step: 11
Training loss: 2.433305016008852
Validation loss: 2.4576872786115667

Epoch: 6| Step: 12
Training loss: 2.960878557811253
Validation loss: 2.459020398859582

Epoch: 6| Step: 13
Training loss: 2.481730847405174
Validation loss: 2.464552501396538

Epoch: 137| Step: 0
Training loss: 2.3421737456729024
Validation loss: 2.4513655357205564

Epoch: 6| Step: 1
Training loss: 2.756886269964283
Validation loss: 2.452489331232785

Epoch: 6| Step: 2
Training loss: 2.680797291486619
Validation loss: 2.4418447638355163

Epoch: 6| Step: 3
Training loss: 2.322735584083323
Validation loss: 2.4589932732400444

Epoch: 6| Step: 4
Training loss: 2.5716310035406678
Validation loss: 2.467516045935708

Epoch: 6| Step: 5
Training loss: 3.133897246350555
Validation loss: 2.47522036699492

Epoch: 6| Step: 6
Training loss: 3.0489169589876886
Validation loss: 2.491824084209633

Epoch: 6| Step: 7
Training loss: 2.6729297006298682
Validation loss: 2.5476604805340313

Epoch: 6| Step: 8
Training loss: 2.338412093641739
Validation loss: 2.5815410347546845

Epoch: 6| Step: 9
Training loss: 2.9246395312823514
Validation loss: 2.5966557173050724

Epoch: 6| Step: 10
Training loss: 2.867829710838182
Validation loss: 2.569824031701161

Epoch: 6| Step: 11
Training loss: 2.6811213535844445
Validation loss: 2.541241302246148

Epoch: 6| Step: 12
Training loss: 2.5555035982056244
Validation loss: 2.4827000786823468

Epoch: 6| Step: 13
Training loss: 2.803290909330097
Validation loss: 2.4598937707371844

Epoch: 138| Step: 0
Training loss: 2.852354342112626
Validation loss: 2.4446799256738574

Epoch: 6| Step: 1
Training loss: 3.33821374926271
Validation loss: 2.453067704412032

Epoch: 6| Step: 2
Training loss: 2.878594183603683
Validation loss: 2.4539419213945375

Epoch: 6| Step: 3
Training loss: 3.235030840294833
Validation loss: 2.4518163558290738

Epoch: 6| Step: 4
Training loss: 2.5482583998679487
Validation loss: 2.4361712039273913

Epoch: 6| Step: 5
Training loss: 2.5389581746896672
Validation loss: 2.447050934245564

Epoch: 6| Step: 6
Training loss: 2.7171924558115026
Validation loss: 2.4640000779743607

Epoch: 6| Step: 7
Training loss: 1.9537195140097792
Validation loss: 2.482161922767554

Epoch: 6| Step: 8
Training loss: 2.9240670370931223
Validation loss: 2.4956138948522333

Epoch: 6| Step: 9
Training loss: 2.3146669699467988
Validation loss: 2.5187700764297603

Epoch: 6| Step: 10
Training loss: 2.7494390088864358
Validation loss: 2.522220121975509

Epoch: 6| Step: 11
Training loss: 2.2774392266649715
Validation loss: 2.5257981012407202

Epoch: 6| Step: 12
Training loss: 2.152881478987438
Validation loss: 2.523664760842363

Epoch: 6| Step: 13
Training loss: 3.5071096417050365
Validation loss: 2.5310157374777953

Epoch: 139| Step: 0
Training loss: 2.879392668212578
Validation loss: 2.5403904655281226

Epoch: 6| Step: 1
Training loss: 2.004544340568615
Validation loss: 2.557006114915397

Epoch: 6| Step: 2
Training loss: 3.024033283211948
Validation loss: 2.5505147433329745

Epoch: 6| Step: 3
Training loss: 2.6946699620503103
Validation loss: 2.551748126586175

Epoch: 6| Step: 4
Training loss: 2.8567007097362027
Validation loss: 2.546407473852807

Epoch: 6| Step: 5
Training loss: 2.772771535085213
Validation loss: 2.5378372474635986

Epoch: 6| Step: 6
Training loss: 2.804896014864958
Validation loss: 2.5022141936623084

Epoch: 6| Step: 7
Training loss: 2.6523005126664976
Validation loss: 2.4730425176567956

Epoch: 6| Step: 8
Training loss: 2.4050318619487197
Validation loss: 2.4547347720363644

Epoch: 6| Step: 9
Training loss: 2.7078215090980935
Validation loss: 2.445900531931638

Epoch: 6| Step: 10
Training loss: 2.735475852618478
Validation loss: 2.4488932729601776

Epoch: 6| Step: 11
Training loss: 2.6475463087950617
Validation loss: 2.4543598338939456

Epoch: 6| Step: 12
Training loss: 2.5443109816966225
Validation loss: 2.4550165706170772

Epoch: 6| Step: 13
Training loss: 3.1864348483126883
Validation loss: 2.4372807276069595

Epoch: 140| Step: 0
Training loss: 2.333473564657017
Validation loss: 2.458147700145317

Epoch: 6| Step: 1
Training loss: 2.8888011230276414
Validation loss: 2.463398947465985

Epoch: 6| Step: 2
Training loss: 3.03338846498908
Validation loss: 2.479740292236665

Epoch: 6| Step: 3
Training loss: 3.0560580639940285
Validation loss: 2.4895569246483857

Epoch: 6| Step: 4
Training loss: 2.65411605387468
Validation loss: 2.494400649035671

Epoch: 6| Step: 5
Training loss: 2.370803136471237
Validation loss: 2.5057223417798453

Epoch: 6| Step: 6
Training loss: 2.4442283493913792
Validation loss: 2.534288349422568

Epoch: 6| Step: 7
Training loss: 2.092270057650452
Validation loss: 2.526900424922957

Epoch: 6| Step: 8
Training loss: 3.0340450024922894
Validation loss: 2.5213579916490625

Epoch: 6| Step: 9
Training loss: 2.6773061597738206
Validation loss: 2.5192403645927297

Epoch: 6| Step: 10
Training loss: 2.667553893155335
Validation loss: 2.534050050454096

Epoch: 6| Step: 11
Training loss: 2.293487750037116
Validation loss: 2.5322572321329027

Epoch: 6| Step: 12
Training loss: 2.8813284178548764
Validation loss: 2.524636822296356

Epoch: 6| Step: 13
Training loss: 2.0474440387907995
Validation loss: 2.540822150217841

Epoch: 141| Step: 0
Training loss: 2.6802066933935382
Validation loss: 2.5628370197969965

Epoch: 6| Step: 1
Training loss: 2.912181420973307
Validation loss: 2.5443699395564168

Epoch: 6| Step: 2
Training loss: 1.9447437358794057
Validation loss: 2.546163544519805

Epoch: 6| Step: 3
Training loss: 2.7171267344177106
Validation loss: 2.5465687851354124

Epoch: 6| Step: 4
Training loss: 2.5675529345262267
Validation loss: 2.5341767092729612

Epoch: 6| Step: 5
Training loss: 2.3064854736863025
Validation loss: 2.5310824982057385

Epoch: 6| Step: 6
Training loss: 2.98585912740349
Validation loss: 2.52771815866327

Epoch: 6| Step: 7
Training loss: 2.455642283343133
Validation loss: 2.5498042209821645

Epoch: 6| Step: 8
Training loss: 2.6410816407243436
Validation loss: 2.5287603634945373

Epoch: 6| Step: 9
Training loss: 2.8522195973433964
Validation loss: 2.5288759515517922

Epoch: 6| Step: 10
Training loss: 2.7991029187872636
Validation loss: 2.513062821388731

Epoch: 6| Step: 11
Training loss: 2.4463415935914186
Validation loss: 2.49112687719359

Epoch: 6| Step: 12
Training loss: 3.0613206422068657
Validation loss: 2.503833054454366

Epoch: 6| Step: 13
Training loss: 2.213219533181669
Validation loss: 2.513311528033788

Epoch: 142| Step: 0
Training loss: 2.740480592722626
Validation loss: 2.520156262628606

Epoch: 6| Step: 1
Training loss: 2.8606777871220306
Validation loss: 2.5286515811199943

Epoch: 6| Step: 2
Training loss: 2.256891821875429
Validation loss: 2.555345260750275

Epoch: 6| Step: 3
Training loss: 2.7687220931530434
Validation loss: 2.558280075297572

Epoch: 6| Step: 4
Training loss: 2.712314398959625
Validation loss: 2.525697070916335

Epoch: 6| Step: 5
Training loss: 3.0015833173324826
Validation loss: 2.51426107355488

Epoch: 6| Step: 6
Training loss: 2.9514799834510823
Validation loss: 2.533222162962624

Epoch: 6| Step: 7
Training loss: 2.2198066881573464
Validation loss: 2.5575245842498697

Epoch: 6| Step: 8
Training loss: 2.9158416307768644
Validation loss: 2.558799911568411

Epoch: 6| Step: 9
Training loss: 2.214389976560641
Validation loss: 2.5919184805329714

Epoch: 6| Step: 10
Training loss: 2.1411913936898825
Validation loss: 2.617610671278863

Epoch: 6| Step: 11
Training loss: 2.6133306068127222
Validation loss: 2.6176791928399297

Epoch: 6| Step: 12
Training loss: 2.710997215294894
Validation loss: 2.5353777090466543

Epoch: 6| Step: 13
Training loss: 2.540711040846364
Validation loss: 2.4884331867476375

Epoch: 143| Step: 0
Training loss: 2.499241904711627
Validation loss: 2.4776197181032225

Epoch: 6| Step: 1
Training loss: 2.933459323286995
Validation loss: 2.479098635414224

Epoch: 6| Step: 2
Training loss: 1.944868167243673
Validation loss: 2.4626273634118685

Epoch: 6| Step: 3
Training loss: 2.8037231827710647
Validation loss: 2.4599791077849584

Epoch: 6| Step: 4
Training loss: 2.5679650065572046
Validation loss: 2.472005384980793

Epoch: 6| Step: 5
Training loss: 3.003819735983939
Validation loss: 2.473974788246202

Epoch: 6| Step: 6
Training loss: 2.351907799801491
Validation loss: 2.449509214734259

Epoch: 6| Step: 7
Training loss: 2.604565968736067
Validation loss: 2.4427538692887154

Epoch: 6| Step: 8
Training loss: 3.0121959105428737
Validation loss: 2.4279883609749615

Epoch: 6| Step: 9
Training loss: 2.617444381633043
Validation loss: 2.4501885104908623

Epoch: 6| Step: 10
Training loss: 2.806402080807409
Validation loss: 2.4822411221939067

Epoch: 6| Step: 11
Training loss: 2.4364758809862925
Validation loss: 2.575724521660346

Epoch: 6| Step: 12
Training loss: 2.6119293684822225
Validation loss: 2.658901702095008

Epoch: 6| Step: 13
Training loss: 3.2708445911254227
Validation loss: 2.7220537053844795

Epoch: 144| Step: 0
Training loss: 3.159173197201602
Validation loss: 2.745566255285421

Epoch: 6| Step: 1
Training loss: 2.576907708596303
Validation loss: 2.670720853138073

Epoch: 6| Step: 2
Training loss: 2.5070117848640083
Validation loss: 2.5811584565275707

Epoch: 6| Step: 3
Training loss: 2.135714167518813
Validation loss: 2.5133705357883587

Epoch: 6| Step: 4
Training loss: 2.1832080698358296
Validation loss: 2.477504278003607

Epoch: 6| Step: 5
Training loss: 2.6847219968969895
Validation loss: 2.4541184959765787

Epoch: 6| Step: 6
Training loss: 2.6344436437458203
Validation loss: 2.450809199511539

Epoch: 6| Step: 7
Training loss: 2.927987951045442
Validation loss: 2.448091549322065

Epoch: 6| Step: 8
Training loss: 2.9072723231303677
Validation loss: 2.4558314211650427

Epoch: 6| Step: 9
Training loss: 2.9916891375222874
Validation loss: 2.4541340838645045

Epoch: 6| Step: 10
Training loss: 2.9147035440809295
Validation loss: 2.4540501909865573

Epoch: 6| Step: 11
Training loss: 2.560701716183741
Validation loss: 2.473928992070983

Epoch: 6| Step: 12
Training loss: 2.63569768279396
Validation loss: 2.5214955741330067

Epoch: 6| Step: 13
Training loss: 3.108756765888185
Validation loss: 2.5896328380667684

Epoch: 145| Step: 0
Training loss: 2.903654847180983
Validation loss: 2.616047855490841

Epoch: 6| Step: 1
Training loss: 2.2939010362505456
Validation loss: 2.633818021925016

Epoch: 6| Step: 2
Training loss: 2.9419542995095678
Validation loss: 2.639531557149146

Epoch: 6| Step: 3
Training loss: 2.580063616981116
Validation loss: 2.6072503662482918

Epoch: 6| Step: 4
Training loss: 2.4592529344136937
Validation loss: 2.550711656972327

Epoch: 6| Step: 5
Training loss: 2.8293831908602725
Validation loss: 2.5329357374251025

Epoch: 6| Step: 6
Training loss: 2.627490723917491
Validation loss: 2.497647222263277

Epoch: 6| Step: 7
Training loss: 2.3291969647651927
Validation loss: 2.507285123635447

Epoch: 6| Step: 8
Training loss: 2.0652066590578047
Validation loss: 2.5043890081033355

Epoch: 6| Step: 9
Training loss: 2.921988255554869
Validation loss: 2.5142573008848226

Epoch: 6| Step: 10
Training loss: 2.509253257373088
Validation loss: 2.502114566599397

Epoch: 6| Step: 11
Training loss: 2.8212468932087784
Validation loss: 2.5038316844939756

Epoch: 6| Step: 12
Training loss: 2.9168296950054398
Validation loss: 2.492288768530408

Epoch: 6| Step: 13
Training loss: 3.0787208871088354
Validation loss: 2.488825890605007

Epoch: 146| Step: 0
Training loss: 2.744329414797022
Validation loss: 2.484796201601749

Epoch: 6| Step: 1
Training loss: 2.208358068747513
Validation loss: 2.491882166644043

Epoch: 6| Step: 2
Training loss: 1.98215185872787
Validation loss: 2.474673012232486

Epoch: 6| Step: 3
Training loss: 2.8157582377452393
Validation loss: 2.469822312323627

Epoch: 6| Step: 4
Training loss: 2.5449939170120177
Validation loss: 2.4722311415247744

Epoch: 6| Step: 5
Training loss: 2.928387895342483
Validation loss: 2.4857498763611976

Epoch: 6| Step: 6
Training loss: 2.8839094354533694
Validation loss: 2.4763844811246902

Epoch: 6| Step: 7
Training loss: 2.645323416365729
Validation loss: 2.4551518478835095

Epoch: 6| Step: 8
Training loss: 2.375259084122261
Validation loss: 2.470670361025799

Epoch: 6| Step: 9
Training loss: 2.6180039683778906
Validation loss: 2.4733952207937526

Epoch: 6| Step: 10
Training loss: 2.14409762308286
Validation loss: 2.4704318628083204

Epoch: 6| Step: 11
Training loss: 2.801795254520643
Validation loss: 2.475798957353479

Epoch: 6| Step: 12
Training loss: 2.884833395128975
Validation loss: 2.4782358012549075

Epoch: 6| Step: 13
Training loss: 2.553722887758846
Validation loss: 2.5113736779689093

Epoch: 147| Step: 0
Training loss: 2.867595425309225
Validation loss: 2.5188199101689603

Epoch: 6| Step: 1
Training loss: 2.5256755340663513
Validation loss: 2.5023591457065435

Epoch: 6| Step: 2
Training loss: 2.5322307052607838
Validation loss: 2.503641549655654

Epoch: 6| Step: 3
Training loss: 3.196504776176418
Validation loss: 2.4904420716905493

Epoch: 6| Step: 4
Training loss: 3.054701548980641
Validation loss: 2.5013321106474775

Epoch: 6| Step: 5
Training loss: 2.512208881877963
Validation loss: 2.503381111160766

Epoch: 6| Step: 6
Training loss: 2.6360339822619223
Validation loss: 2.468076146411189

Epoch: 6| Step: 7
Training loss: 2.5615898935217505
Validation loss: 2.459696061608193

Epoch: 6| Step: 8
Training loss: 2.12130112450966
Validation loss: 2.4642120155534686

Epoch: 6| Step: 9
Training loss: 2.819591144655987
Validation loss: 2.4676384251661725

Epoch: 6| Step: 10
Training loss: 2.779608595759064
Validation loss: 2.4993564525989442

Epoch: 6| Step: 11
Training loss: 1.594189601931953
Validation loss: 2.540650112166889

Epoch: 6| Step: 12
Training loss: 2.382156431837983
Validation loss: 2.5667757477638506

Epoch: 6| Step: 13
Training loss: 1.9506653213122602
Validation loss: 2.5811324798989745

Epoch: 148| Step: 0
Training loss: 2.5756035699209705
Validation loss: 2.566600621946139

Epoch: 6| Step: 1
Training loss: 2.5682255118988797
Validation loss: 2.525714104974996

Epoch: 6| Step: 2
Training loss: 3.066110467920107
Validation loss: 2.4873610398498576

Epoch: 6| Step: 3
Training loss: 2.5525580347470953
Validation loss: 2.462770654398124

Epoch: 6| Step: 4
Training loss: 2.5067769702355687
Validation loss: 2.4388258593486927

Epoch: 6| Step: 5
Training loss: 2.2392976327276046
Validation loss: 2.4391647966244454

Epoch: 6| Step: 6
Training loss: 2.598384898393653
Validation loss: 2.4428857863561193

Epoch: 6| Step: 7
Training loss: 2.708122792985881
Validation loss: 2.444800714811025

Epoch: 6| Step: 8
Training loss: 2.9381060685239837
Validation loss: 2.444155890281236

Epoch: 6| Step: 9
Training loss: 3.1893864453570298
Validation loss: 2.4430103590623338

Epoch: 6| Step: 10
Training loss: 2.0915568238048396
Validation loss: 2.4516764295189026

Epoch: 6| Step: 11
Training loss: 2.236108281019906
Validation loss: 2.455254643973284

Epoch: 6| Step: 12
Training loss: 2.412008850226922
Validation loss: 2.505058922843737

Epoch: 6| Step: 13
Training loss: 2.474246605926187
Validation loss: 2.5558998272229885

Epoch: 149| Step: 0
Training loss: 2.697145231461808
Validation loss: 2.656156289500351

Epoch: 6| Step: 1
Training loss: 2.792727586698108
Validation loss: 2.700406847183262

Epoch: 6| Step: 2
Training loss: 2.1510118631756687
Validation loss: 2.6308653659111187

Epoch: 6| Step: 3
Training loss: 3.015926840109856
Validation loss: 2.5808502639384225

Epoch: 6| Step: 4
Training loss: 2.6960179387070253
Validation loss: 2.5364412434050574

Epoch: 6| Step: 5
Training loss: 2.351849003064468
Validation loss: 2.501966369665063

Epoch: 6| Step: 6
Training loss: 2.9924638187321326
Validation loss: 2.4858138832759042

Epoch: 6| Step: 7
Training loss: 2.3543706709880436
Validation loss: 2.46904577267247

Epoch: 6| Step: 8
Training loss: 2.6178010591437055
Validation loss: 2.4644922987780613

Epoch: 6| Step: 9
Training loss: 2.929298802339678
Validation loss: 2.4906877630402264

Epoch: 6| Step: 10
Training loss: 2.729138575596177
Validation loss: 2.4780523212571697

Epoch: 6| Step: 11
Training loss: 2.9506483238444154
Validation loss: 2.4759695716782795

Epoch: 6| Step: 12
Training loss: 1.8236110418351485
Validation loss: 2.482187961716212

Epoch: 6| Step: 13
Training loss: 2.6721838164747465
Validation loss: 2.484810727296446

Epoch: 150| Step: 0
Training loss: 2.6470806055481737
Validation loss: 2.4926829429860167

Epoch: 6| Step: 1
Training loss: 2.7084039727804545
Validation loss: 2.5072929062048206

Epoch: 6| Step: 2
Training loss: 2.4411583858552772
Validation loss: 2.5244574083739746

Epoch: 6| Step: 3
Training loss: 2.805677318973207
Validation loss: 2.5392105692938833

Epoch: 6| Step: 4
Training loss: 2.170522364664841
Validation loss: 2.55128543745765

Epoch: 6| Step: 5
Training loss: 2.7672718554347173
Validation loss: 2.55336070201594

Epoch: 6| Step: 6
Training loss: 2.059514051729791
Validation loss: 2.5489981884724133

Epoch: 6| Step: 7
Training loss: 3.199753787582329
Validation loss: 2.551153562508261

Epoch: 6| Step: 8
Training loss: 2.476578962108881
Validation loss: 2.5334635942590746

Epoch: 6| Step: 9
Training loss: 2.6543151091341586
Validation loss: 2.520855745808988

Epoch: 6| Step: 10
Training loss: 2.287216327358916
Validation loss: 2.5014648575855527

Epoch: 6| Step: 11
Training loss: 2.4265504069128294
Validation loss: 2.4765377905863484

Epoch: 6| Step: 12
Training loss: 2.8080189929874098
Validation loss: 2.469169436725697

Epoch: 6| Step: 13
Training loss: 1.6045436746389463
Validation loss: 2.4424036038261216

Epoch: 151| Step: 0
Training loss: 2.545940016921684
Validation loss: 2.438361997560862

Epoch: 6| Step: 1
Training loss: 2.6243775855985345
Validation loss: 2.426870815692897

Epoch: 6| Step: 2
Training loss: 2.4809331504244527
Validation loss: 2.4119123815755747

Epoch: 6| Step: 3
Training loss: 2.8928918146817444
Validation loss: 2.418002284274331

Epoch: 6| Step: 4
Training loss: 2.825029396646864
Validation loss: 2.4311490215578053

Epoch: 6| Step: 5
Training loss: 2.1718328458139338
Validation loss: 2.4657792794829945

Epoch: 6| Step: 6
Training loss: 2.7873198036145888
Validation loss: 2.519535385144977

Epoch: 6| Step: 7
Training loss: 2.4305438038375375
Validation loss: 2.5611254509281407

Epoch: 6| Step: 8
Training loss: 2.181351986662303
Validation loss: 2.6352168603307478

Epoch: 6| Step: 9
Training loss: 3.1089572338305187
Validation loss: 2.711583921619149

Epoch: 6| Step: 10
Training loss: 2.4260821808483692
Validation loss: 2.7155124627158456

Epoch: 6| Step: 11
Training loss: 2.2021462721718845
Validation loss: 2.6294094456719765

Epoch: 6| Step: 12
Training loss: 2.884559329539742
Validation loss: 2.5703536381081715

Epoch: 6| Step: 13
Training loss: 2.370794890169726
Validation loss: 2.5151848952944653

Epoch: 152| Step: 0
Training loss: 2.3361130460271737
Validation loss: 2.4738876479477563

Epoch: 6| Step: 1
Training loss: 2.414244314711024
Validation loss: 2.4651248245668618

Epoch: 6| Step: 2
Training loss: 2.386498074233267
Validation loss: 2.456526671364896

Epoch: 6| Step: 3
Training loss: 2.2864517061199754
Validation loss: 2.4444269063217265

Epoch: 6| Step: 4
Training loss: 2.304345677776133
Validation loss: 2.4365396019578633

Epoch: 6| Step: 5
Training loss: 2.7000162406715513
Validation loss: 2.4364483449638468

Epoch: 6| Step: 6
Training loss: 2.9921186553764145
Validation loss: 2.4511891968641315

Epoch: 6| Step: 7
Training loss: 2.356007478005891
Validation loss: 2.4674447335618184

Epoch: 6| Step: 8
Training loss: 2.5836333644103484
Validation loss: 2.485128224419772

Epoch: 6| Step: 9
Training loss: 2.3090067072953073
Validation loss: 2.5112918442545222

Epoch: 6| Step: 10
Training loss: 2.5694823620263767
Validation loss: 2.522757253593585

Epoch: 6| Step: 11
Training loss: 2.9062818299878255
Validation loss: 2.52227884813623

Epoch: 6| Step: 12
Training loss: 2.4297182136385214
Validation loss: 2.530514523025314

Epoch: 6| Step: 13
Training loss: 2.7434781506841364
Validation loss: 2.550768190459244

Epoch: 153| Step: 0
Training loss: 2.3532183827466953
Validation loss: 2.5885350329259493

Epoch: 6| Step: 1
Training loss: 2.4513792398591256
Validation loss: 2.6135472868377225

Epoch: 6| Step: 2
Training loss: 2.860830634812474
Validation loss: 2.6118376828335133

Epoch: 6| Step: 3
Training loss: 2.423545605764962
Validation loss: 2.5966147860986593

Epoch: 6| Step: 4
Training loss: 2.774522595966478
Validation loss: 2.5555303790686397

Epoch: 6| Step: 5
Training loss: 2.2195651209233054
Validation loss: 2.511339507072236

Epoch: 6| Step: 6
Training loss: 2.658440707518572
Validation loss: 2.503283966900764

Epoch: 6| Step: 7
Training loss: 2.421923827632791
Validation loss: 2.4767913862688267

Epoch: 6| Step: 8
Training loss: 2.113447538874044
Validation loss: 2.4669998349552587

Epoch: 6| Step: 9
Training loss: 1.8972629005957637
Validation loss: 2.4714755460674724

Epoch: 6| Step: 10
Training loss: 2.5875955204678274
Validation loss: 2.487940960448997

Epoch: 6| Step: 11
Training loss: 2.9526925552460868
Validation loss: 2.477266212118934

Epoch: 6| Step: 12
Training loss: 2.808373794113269
Validation loss: 2.480955715307332

Epoch: 6| Step: 13
Training loss: 2.6559000121277467
Validation loss: 2.488691253452489

Epoch: 154| Step: 0
Training loss: 2.0932522082351888
Validation loss: 2.5013410181256153

Epoch: 6| Step: 1
Training loss: 2.690562698759464
Validation loss: 2.5172707151468234

Epoch: 6| Step: 2
Training loss: 1.935182662247685
Validation loss: 2.5206986003746574

Epoch: 6| Step: 3
Training loss: 2.536822272685767
Validation loss: 2.5313086949162837

Epoch: 6| Step: 4
Training loss: 2.1990144949830386
Validation loss: 2.5321922842354

Epoch: 6| Step: 5
Training loss: 2.1761171913705875
Validation loss: 2.5358027648485195

Epoch: 6| Step: 6
Training loss: 2.524197773918571
Validation loss: 2.573807073608363

Epoch: 6| Step: 7
Training loss: 2.7310165270567532
Validation loss: 2.5856355791309946

Epoch: 6| Step: 8
Training loss: 2.5381727332215656
Validation loss: 2.5977446396795467

Epoch: 6| Step: 9
Training loss: 1.800725576073861
Validation loss: 2.5477248439277793

Epoch: 6| Step: 10
Training loss: 1.8450050608247648
Validation loss: 2.5172929227309235

Epoch: 6| Step: 11
Training loss: 3.119984378286525
Validation loss: 2.4942036693500853

Epoch: 6| Step: 12
Training loss: 3.1091256353171906
Validation loss: 2.483895747102837

Epoch: 6| Step: 13
Training loss: 3.083876759522002
Validation loss: 2.4815427300457578

Epoch: 155| Step: 0
Training loss: 2.1996386924907556
Validation loss: 2.4673996920668477

Epoch: 6| Step: 1
Training loss: 2.2150870160992775
Validation loss: 2.465697112626794

Epoch: 6| Step: 2
Training loss: 2.325680467025638
Validation loss: 2.4857931745178052

Epoch: 6| Step: 3
Training loss: 2.6219849300868026
Validation loss: 2.4945655638258963

Epoch: 6| Step: 4
Training loss: 2.3541837258410077
Validation loss: 2.5109369079894215

Epoch: 6| Step: 5
Training loss: 3.1072012045507327
Validation loss: 2.5181401720342973

Epoch: 6| Step: 6
Training loss: 2.794930746622887
Validation loss: 2.541656666263116

Epoch: 6| Step: 7
Training loss: 2.048205343747904
Validation loss: 2.520963652911904

Epoch: 6| Step: 8
Training loss: 2.262607011319221
Validation loss: 2.5114897834739707

Epoch: 6| Step: 9
Training loss: 2.125148319229306
Validation loss: 2.531665101039269

Epoch: 6| Step: 10
Training loss: 2.5598687409486898
Validation loss: 2.5109181890951078

Epoch: 6| Step: 11
Training loss: 2.262369276453778
Validation loss: 2.529312261073049

Epoch: 6| Step: 12
Training loss: 2.8929565923910756
Validation loss: 2.5171753616647847

Epoch: 6| Step: 13
Training loss: 1.8753431006275654
Validation loss: 2.540950176559566

Epoch: 156| Step: 0
Training loss: 2.308184643947581
Validation loss: 2.579818635654919

Epoch: 6| Step: 1
Training loss: 2.0020807886124024
Validation loss: 2.598215365418311

Epoch: 6| Step: 2
Training loss: 3.147461391996942
Validation loss: 2.649318809667685

Epoch: 6| Step: 3
Training loss: 2.5267814470589203
Validation loss: 2.547851746634047

Epoch: 6| Step: 4
Training loss: 2.5111354785438325
Validation loss: 2.5046568393074877

Epoch: 6| Step: 5
Training loss: 2.494272728918798
Validation loss: 2.4681818889820777

Epoch: 6| Step: 6
Training loss: 2.475176787564821
Validation loss: 2.449731282407975

Epoch: 6| Step: 7
Training loss: 2.701802100901867
Validation loss: 2.4324019964063037

Epoch: 6| Step: 8
Training loss: 1.6258137939363508
Validation loss: 2.4500891661516877

Epoch: 6| Step: 9
Training loss: 2.394573366874459
Validation loss: 2.4452358698934527

Epoch: 6| Step: 10
Training loss: 2.5322395556815707
Validation loss: 2.446516759290812

Epoch: 6| Step: 11
Training loss: 2.7439963088997796
Validation loss: 2.4563433763864264

Epoch: 6| Step: 12
Training loss: 1.9046040918051699
Validation loss: 2.4611524064543717

Epoch: 6| Step: 13
Training loss: 2.7181285279392093
Validation loss: 2.4658531502740675

Epoch: 157| Step: 0
Training loss: 1.9603573370241618
Validation loss: 2.4784770063883195

Epoch: 6| Step: 1
Training loss: 2.3814839646149752
Validation loss: 2.4808975816680485

Epoch: 6| Step: 2
Training loss: 2.7355938619924918
Validation loss: 2.492766468484734

Epoch: 6| Step: 3
Training loss: 1.9735788133152785
Validation loss: 2.493688226613686

Epoch: 6| Step: 4
Training loss: 2.418444363310377
Validation loss: 2.4955951103322453

Epoch: 6| Step: 5
Training loss: 3.044305588540424
Validation loss: 2.4921730841650063

Epoch: 6| Step: 6
Training loss: 2.5873119930942567
Validation loss: 2.4859296160684083

Epoch: 6| Step: 7
Training loss: 2.1886974871755696
Validation loss: 2.4865143461663224

Epoch: 6| Step: 8
Training loss: 2.06108403006714
Validation loss: 2.4790057609819542

Epoch: 6| Step: 9
Training loss: 2.021378931806134
Validation loss: 2.4721901723970254

Epoch: 6| Step: 10
Training loss: 2.5409446899927866
Validation loss: 2.4972211888830107

Epoch: 6| Step: 11
Training loss: 2.5950305948677292
Validation loss: 2.5270593759646407

Epoch: 6| Step: 12
Training loss: 1.9492408888788468
Validation loss: 2.5612667586705493

Epoch: 6| Step: 13
Training loss: 2.964517728750278
Validation loss: 2.6022961014640176

Epoch: 158| Step: 0
Training loss: 1.5648703334338683
Validation loss: 2.5193992158520886

Epoch: 6| Step: 1
Training loss: 2.822547766498388
Validation loss: 2.488215172778377

Epoch: 6| Step: 2
Training loss: 2.0538599936992448
Validation loss: 2.4751453314106358

Epoch: 6| Step: 3
Training loss: 2.4892681566085586
Validation loss: 2.475257253965521

Epoch: 6| Step: 4
Training loss: 2.2133536464647596
Validation loss: 2.4774652835224065

Epoch: 6| Step: 5
Training loss: 2.688434261012784
Validation loss: 2.466407576345616

Epoch: 6| Step: 6
Training loss: 2.2188308056368267
Validation loss: 2.4653032301446265

Epoch: 6| Step: 7
Training loss: 2.4744715964629016
Validation loss: 2.485424893346196

Epoch: 6| Step: 8
Training loss: 2.4658203125
Validation loss: 2.4913205664672207

Epoch: 6| Step: 9
Training loss: 2.1431613569938723
Validation loss: 2.4929836288830147

Epoch: 6| Step: 10
Training loss: 2.1389372917852683
Validation loss: 2.4944623281516556

Epoch: 6| Step: 11
Training loss: 2.6957766810443515
Validation loss: 2.4979597144121843

Epoch: 6| Step: 12
Training loss: 2.5963577581678603
Validation loss: 2.501943487069528

Epoch: 6| Step: 13
Training loss: 2.6903354856750075
Validation loss: 2.4828589125448834

Epoch: 159| Step: 0
Training loss: 2.6483229890897024
Validation loss: 2.4868792522770238

Epoch: 6| Step: 1
Training loss: 2.37307380064457
Validation loss: 2.4707388446662106

Epoch: 6| Step: 2
Training loss: 2.5975121479649874
Validation loss: 2.4707589397994485

Epoch: 6| Step: 3
Training loss: 2.477673591206184
Validation loss: 2.4722652266414027

Epoch: 6| Step: 4
Training loss: 2.2700803949176884
Validation loss: 2.5079870594194085

Epoch: 6| Step: 5
Training loss: 2.233823267968415
Validation loss: 2.520090015084376

Epoch: 6| Step: 6
Training loss: 2.6762466805520777
Validation loss: 2.495009875927285

Epoch: 6| Step: 7
Training loss: 2.211344758931267
Validation loss: 2.462999720069595

Epoch: 6| Step: 8
Training loss: 2.4460346752088817
Validation loss: 2.44414417209994

Epoch: 6| Step: 9
Training loss: 2.6115057919763225
Validation loss: 2.45325129638262

Epoch: 6| Step: 10
Training loss: 2.030728551984056
Validation loss: 2.4520702959493095

Epoch: 6| Step: 11
Training loss: 1.8790955636499975
Validation loss: 2.4571467025105203

Epoch: 6| Step: 12
Training loss: 2.384451680681511
Validation loss: 2.4718868741689284

Epoch: 6| Step: 13
Training loss: 1.6521922373464746
Validation loss: 2.5029625925304915

Epoch: 160| Step: 0
Training loss: 2.1981406677746325
Validation loss: 2.514874299361069

Epoch: 6| Step: 1
Training loss: 2.034274387948053
Validation loss: 2.5620445308885884

Epoch: 6| Step: 2
Training loss: 2.43550047413448
Validation loss: 2.5751844613844885

Epoch: 6| Step: 3
Training loss: 2.4550736578245953
Validation loss: 2.567846223170196

Epoch: 6| Step: 4
Training loss: 2.6225610028818527
Validation loss: 2.4982864680746144

Epoch: 6| Step: 5
Training loss: 2.1023635188562135
Validation loss: 2.4634153591309293

Epoch: 6| Step: 6
Training loss: 2.498559823062599
Validation loss: 2.436085853720585

Epoch: 6| Step: 7
Training loss: 1.9065755972531961
Validation loss: 2.433966930314771

Epoch: 6| Step: 8
Training loss: 2.4504557866791807
Validation loss: 2.4269391884572333

Epoch: 6| Step: 9
Training loss: 2.237307031930788
Validation loss: 2.43294216180378

Epoch: 6| Step: 10
Training loss: 2.305656824096537
Validation loss: 2.4167042132789396

Epoch: 6| Step: 11
Training loss: 2.7735896538919143
Validation loss: 2.4294351046308345

Epoch: 6| Step: 12
Training loss: 2.156537023044746
Validation loss: 2.469280573761651

Epoch: 6| Step: 13
Training loss: 2.7457516539894393
Validation loss: 2.4774125669419065

Epoch: 161| Step: 0
Training loss: 2.575655314936586
Validation loss: 2.5286353840075604

Epoch: 6| Step: 1
Training loss: 2.0950464817981427
Validation loss: 2.5336975414155276

Epoch: 6| Step: 2
Training loss: 2.782627921647016
Validation loss: 2.587661847840961

Epoch: 6| Step: 3
Training loss: 2.017494812950453
Validation loss: 2.4898526957360936

Epoch: 6| Step: 4
Training loss: 2.5376741809914938
Validation loss: 2.4312488972942154

Epoch: 6| Step: 5
Training loss: 2.393010165073789
Validation loss: 2.3972568372371854

Epoch: 6| Step: 6
Training loss: 2.5098883572860444
Validation loss: 2.383433916737625

Epoch: 6| Step: 7
Training loss: 2.1547517961918814
Validation loss: 2.3890236012262793

Epoch: 6| Step: 8
Training loss: 1.981988748674378
Validation loss: 2.388518226358648

Epoch: 6| Step: 9
Training loss: 2.7850025022211256
Validation loss: 2.4053704591096077

Epoch: 6| Step: 10
Training loss: 2.2535426542393906
Validation loss: 2.4053939886317557

Epoch: 6| Step: 11
Training loss: 2.240271198000005
Validation loss: 2.438830175482661

Epoch: 6| Step: 12
Training loss: 2.147941726355852
Validation loss: 2.4744347008884753

Epoch: 6| Step: 13
Training loss: 2.2684476961021542
Validation loss: 2.521580490715824

Epoch: 162| Step: 0
Training loss: 2.3498717658585124
Validation loss: 2.4781748024209524

Epoch: 6| Step: 1
Training loss: 1.983719604874681
Validation loss: 2.461444817680381

Epoch: 6| Step: 2
Training loss: 2.2416891680678903
Validation loss: 2.431546195662281

Epoch: 6| Step: 3
Training loss: 2.5093498865298445
Validation loss: 2.4284456955472007

Epoch: 6| Step: 4
Training loss: 2.400714501676697
Validation loss: 2.4344724643196614

Epoch: 6| Step: 5
Training loss: 2.235050872804066
Validation loss: 2.452646271876143

Epoch: 6| Step: 6
Training loss: 2.3612638075078016
Validation loss: 2.444034253201839

Epoch: 6| Step: 7
Training loss: 2.507646977081068
Validation loss: 2.474697093838402

Epoch: 6| Step: 8
Training loss: 2.062032241954017
Validation loss: 2.522394743370712

Epoch: 6| Step: 9
Training loss: 2.087203766596222
Validation loss: 2.5540092636428504

Epoch: 6| Step: 10
Training loss: 2.4388756415901165
Validation loss: 2.6046331169194703

Epoch: 6| Step: 11
Training loss: 2.8533299651378585
Validation loss: 2.597413750135332

Epoch: 6| Step: 12
Training loss: 2.407886295561631
Validation loss: 2.5451350728270836

Epoch: 6| Step: 13
Training loss: 1.4143281971549524
Validation loss: 2.5137078203710175

Epoch: 163| Step: 0
Training loss: 2.70075346712008
Validation loss: 2.4904812520928665

Epoch: 6| Step: 1
Training loss: 2.1947003254277377
Validation loss: 2.4695064226456367

Epoch: 6| Step: 2
Training loss: 2.2795525074890057
Validation loss: 2.4382473357645047

Epoch: 6| Step: 3
Training loss: 2.5489065107079916
Validation loss: 2.4353437391541157

Epoch: 6| Step: 4
Training loss: 1.9510378252172527
Validation loss: 2.424538895552501

Epoch: 6| Step: 5
Training loss: 2.3788054246003205
Validation loss: 2.4247928821446383

Epoch: 6| Step: 6
Training loss: 2.9838227564966893
Validation loss: 2.4240548244155553

Epoch: 6| Step: 7
Training loss: 1.620739266118333
Validation loss: 2.442975022061493

Epoch: 6| Step: 8
Training loss: 2.2559034467082943
Validation loss: 2.4340002873590136

Epoch: 6| Step: 9
Training loss: 2.0198665023352063
Validation loss: 2.448740402491235

Epoch: 6| Step: 10
Training loss: 2.017384552140067
Validation loss: 2.4789154147399466

Epoch: 6| Step: 11
Training loss: 1.5110809794550877
Validation loss: 2.5028274493038434

Epoch: 6| Step: 12
Training loss: 2.6457806879848476
Validation loss: 2.5124287310651816

Epoch: 6| Step: 13
Training loss: 2.8860890033239484
Validation loss: 2.5207424220308905

Epoch: 164| Step: 0
Training loss: 2.213647374639707
Validation loss: 2.4970384427364416

Epoch: 6| Step: 1
Training loss: 2.321805223363764
Validation loss: 2.477276651833532

Epoch: 6| Step: 2
Training loss: 2.122662099662417
Validation loss: 2.4600159580717893

Epoch: 6| Step: 3
Training loss: 2.6502706209590836
Validation loss: 2.442677842152427

Epoch: 6| Step: 4
Training loss: 2.033300333328531
Validation loss: 2.4303411633170993

Epoch: 6| Step: 5
Training loss: 1.7089472652220894
Validation loss: 2.4482651699160614

Epoch: 6| Step: 6
Training loss: 2.339650752748458
Validation loss: 2.481150822666826

Epoch: 6| Step: 7
Training loss: 2.041979227339611
Validation loss: 2.461310697672347

Epoch: 6| Step: 8
Training loss: 2.756006530250154
Validation loss: 2.4489486672859653

Epoch: 6| Step: 9
Training loss: 2.0516715887254953
Validation loss: 2.426860640846257

Epoch: 6| Step: 10
Training loss: 1.9968084261546797
Validation loss: 2.4046438050546146

Epoch: 6| Step: 11
Training loss: 2.5801108370489665
Validation loss: 2.3973424908429575

Epoch: 6| Step: 12
Training loss: 2.3877540253517524
Validation loss: 2.382906298419344

Epoch: 6| Step: 13
Training loss: 2.51225092398184
Validation loss: 2.3925446619100805

Epoch: 165| Step: 0
Training loss: 2.225941675201789
Validation loss: 2.4274881299889297

Epoch: 6| Step: 1
Training loss: 2.232938931878464
Validation loss: 2.529293379165743

Epoch: 6| Step: 2
Training loss: 2.1198613360779044
Validation loss: 2.5984841740182922

Epoch: 6| Step: 3
Training loss: 2.0731647924422973
Validation loss: 2.6341079285953914

Epoch: 6| Step: 4
Training loss: 2.6984561886385987
Validation loss: 2.665884365291415

Epoch: 6| Step: 5
Training loss: 2.32742678009804
Validation loss: 2.5531227016113545

Epoch: 6| Step: 6
Training loss: 2.0894129228816136
Validation loss: 2.446055118976817

Epoch: 6| Step: 7
Training loss: 2.1539570876781835
Validation loss: 2.3958392734819545

Epoch: 6| Step: 8
Training loss: 2.4854534375608814
Validation loss: 2.386179906737132

Epoch: 6| Step: 9
Training loss: 2.442065926501552
Validation loss: 2.400990914542969

Epoch: 6| Step: 10
Training loss: 1.703276321268225
Validation loss: 2.4246969390339

Epoch: 6| Step: 11
Training loss: 2.358137703140221
Validation loss: 2.436835893476055

Epoch: 6| Step: 12
Training loss: 2.644013437262943
Validation loss: 2.462504939716724

Epoch: 6| Step: 13
Training loss: 2.4584036240523366
Validation loss: 2.477698946318558

Epoch: 166| Step: 0
Training loss: 2.1820051662198594
Validation loss: 2.458596718264917

Epoch: 6| Step: 1
Training loss: 1.8776999425776417
Validation loss: 2.477795581010863

Epoch: 6| Step: 2
Training loss: 2.658276043297495
Validation loss: 2.5025209560280874

Epoch: 6| Step: 3
Training loss: 2.32950627871304
Validation loss: 2.5056225278193276

Epoch: 6| Step: 4
Training loss: 2.0172573842797434
Validation loss: 2.4990904148046544

Epoch: 6| Step: 5
Training loss: 1.697124023149508
Validation loss: 2.495098402322929

Epoch: 6| Step: 6
Training loss: 2.3740715420555665
Validation loss: 2.5192985689870437

Epoch: 6| Step: 7
Training loss: 1.9764394608752587
Validation loss: 2.510545721061327

Epoch: 6| Step: 8
Training loss: 2.354049634697023
Validation loss: 2.506546753501581

Epoch: 6| Step: 9
Training loss: 1.8185926179204714
Validation loss: 2.5065476658193058

Epoch: 6| Step: 10
Training loss: 2.2811939807441197
Validation loss: 2.471753211854864

Epoch: 6| Step: 11
Training loss: 2.7118512902912464
Validation loss: 2.430582668272371

Epoch: 6| Step: 12
Training loss: 2.412650970320789
Validation loss: 2.4047557771090666

Epoch: 6| Step: 13
Training loss: 2.403392134999538
Validation loss: 2.398428359994124

Epoch: 167| Step: 0
Training loss: 2.3926539568658707
Validation loss: 2.384351699412696

Epoch: 6| Step: 1
Training loss: 2.0373875545997477
Validation loss: 2.389611592602074

Epoch: 6| Step: 2
Training loss: 2.5024057257364825
Validation loss: 2.389421284765792

Epoch: 6| Step: 3
Training loss: 2.0777679366061728
Validation loss: 2.405485310029719

Epoch: 6| Step: 4
Training loss: 2.3635948792731836
Validation loss: 2.422147635874225

Epoch: 6| Step: 5
Training loss: 2.0175020216467274
Validation loss: 2.4306720044376564

Epoch: 6| Step: 6
Training loss: 2.4329051211445156
Validation loss: 2.4255755249101267

Epoch: 6| Step: 7
Training loss: 1.921232534811917
Validation loss: 2.4612975404569277

Epoch: 6| Step: 8
Training loss: 2.196378944359129
Validation loss: 2.4639872899111217

Epoch: 6| Step: 9
Training loss: 2.2333117536194944
Validation loss: 2.4934277540340206

Epoch: 6| Step: 10
Training loss: 2.129434334589153
Validation loss: 2.508699733666834

Epoch: 6| Step: 11
Training loss: 2.2180226167948067
Validation loss: 2.496142500003129

Epoch: 6| Step: 12
Training loss: 1.8975155950616578
Validation loss: 2.470032598268665

Epoch: 6| Step: 13
Training loss: 2.333350953535126
Validation loss: 2.4444495292261412

Epoch: 168| Step: 0
Training loss: 1.5385956806609669
Validation loss: 2.43200644680042

Epoch: 6| Step: 1
Training loss: 1.6899389373311566
Validation loss: 2.396741948548268

Epoch: 6| Step: 2
Training loss: 1.984730846308284
Validation loss: 2.429067593217433

Epoch: 6| Step: 3
Training loss: 2.3397552014951444
Validation loss: 2.4281784650797986

Epoch: 6| Step: 4
Training loss: 2.384070092700544
Validation loss: 2.4440924465456506

Epoch: 6| Step: 5
Training loss: 2.1612531694837975
Validation loss: 2.4468694617860782

Epoch: 6| Step: 6
Training loss: 2.2347584642129856
Validation loss: 2.4745232215777233

Epoch: 6| Step: 7
Training loss: 2.6728420180741628
Validation loss: 2.4706631245865487

Epoch: 6| Step: 8
Training loss: 2.394254235926595
Validation loss: 2.464651249230372

Epoch: 6| Step: 9
Training loss: 1.526976324116465
Validation loss: 2.4524675706717134

Epoch: 6| Step: 10
Training loss: 2.2003665185275234
Validation loss: 2.4482498797432832

Epoch: 6| Step: 11
Training loss: 2.162673890283251
Validation loss: 2.425153638989848

Epoch: 6| Step: 12
Training loss: 2.3573872864721253
Validation loss: 2.4180024115020307

Epoch: 6| Step: 13
Training loss: 2.8789657110442723
Validation loss: 2.4098756927723977

Epoch: 169| Step: 0
Training loss: 1.7625902139287932
Validation loss: 2.397551066217808

Epoch: 6| Step: 1
Training loss: 2.097470067461971
Validation loss: 2.4196966377092934

Epoch: 6| Step: 2
Training loss: 2.3391222215467886
Validation loss: 2.424964496076513

Epoch: 6| Step: 3
Training loss: 1.8483410588416318
Validation loss: 2.406562580847231

Epoch: 6| Step: 4
Training loss: 2.168579015670075
Validation loss: 2.431208513471484

Epoch: 6| Step: 5
Training loss: 2.3819446421611716
Validation loss: 2.461704213495368

Epoch: 6| Step: 6
Training loss: 2.2343536589343596
Validation loss: 2.514044019581373

Epoch: 6| Step: 7
Training loss: 2.3138789627678453
Validation loss: 2.55026567047543

Epoch: 6| Step: 8
Training loss: 2.262836713657391
Validation loss: 2.515096708955031

Epoch: 6| Step: 9
Training loss: 1.89001158544229
Validation loss: 2.5018530633165867

Epoch: 6| Step: 10
Training loss: 1.743643592677914
Validation loss: 2.488021333974035

Epoch: 6| Step: 11
Training loss: 2.58262648192407
Validation loss: 2.484941362909111

Epoch: 6| Step: 12
Training loss: 2.423784352413724
Validation loss: 2.4939427828885488

Epoch: 6| Step: 13
Training loss: 2.5809351546644885
Validation loss: 2.4796819212635763

Epoch: 170| Step: 0
Training loss: 2.1141119996991002
Validation loss: 2.4028371583507586

Epoch: 6| Step: 1
Training loss: 2.419602244453064
Validation loss: 2.3523446547281037

Epoch: 6| Step: 2
Training loss: 2.697239549028779
Validation loss: 2.364376870251044

Epoch: 6| Step: 3
Training loss: 2.0355512415096615
Validation loss: 2.378684788018698

Epoch: 6| Step: 4
Training loss: 1.9648433253020479
Validation loss: 2.3966193079393614

Epoch: 6| Step: 5
Training loss: 2.3230480162657994
Validation loss: 2.3899639110197732

Epoch: 6| Step: 6
Training loss: 2.0799449322820265
Validation loss: 2.4072105851313257

Epoch: 6| Step: 7
Training loss: 1.8510092379495595
Validation loss: 2.415121875417875

Epoch: 6| Step: 8
Training loss: 1.953934768657766
Validation loss: 2.4078311229482128

Epoch: 6| Step: 9
Training loss: 2.6122470057884053
Validation loss: 2.409143395103581

Epoch: 6| Step: 10
Training loss: 2.200269431175006
Validation loss: 2.4237648128840914

Epoch: 6| Step: 11
Training loss: 2.1993577279715955
Validation loss: 2.417133093926126

Epoch: 6| Step: 12
Training loss: 2.3918209699594253
Validation loss: 2.405521749801899

Epoch: 6| Step: 13
Training loss: 1.638102454096192
Validation loss: 2.3725383784114684

Epoch: 171| Step: 0
Training loss: 2.3156541500753582
Validation loss: 2.37314034426483

Epoch: 6| Step: 1
Training loss: 2.5721099041702824
Validation loss: 2.3681577599233004

Epoch: 6| Step: 2
Training loss: 2.1691236014774096
Validation loss: 2.389296127284943

Epoch: 6| Step: 3
Training loss: 2.1462671032836744
Validation loss: 2.398732643289724

Epoch: 6| Step: 4
Training loss: 2.4899900309045226
Validation loss: 2.403434921658504

Epoch: 6| Step: 5
Training loss: 1.7529811670931401
Validation loss: 2.4632442436785658

Epoch: 6| Step: 6
Training loss: 2.0778744195142025
Validation loss: 2.454905482284421

Epoch: 6| Step: 7
Training loss: 1.9611308089945945
Validation loss: 2.454737103059352

Epoch: 6| Step: 8
Training loss: 1.9154934263860892
Validation loss: 2.4410217376135113

Epoch: 6| Step: 9
Training loss: 2.85939000860559
Validation loss: 2.4340781853889912

Epoch: 6| Step: 10
Training loss: 1.638045690334756
Validation loss: 2.4061811757189973

Epoch: 6| Step: 11
Training loss: 2.395792543368093
Validation loss: 2.4090827011790767

Epoch: 6| Step: 12
Training loss: 1.8912167214278874
Validation loss: 2.376900010592325

Epoch: 6| Step: 13
Training loss: 1.5632958483455222
Validation loss: 2.360717052191517

Epoch: 172| Step: 0
Training loss: 1.9492023597288106
Validation loss: 2.3684363011319842

Epoch: 6| Step: 1
Training loss: 1.5012770620633744
Validation loss: 2.3806783650460424

Epoch: 6| Step: 2
Training loss: 2.0137651719718166
Validation loss: 2.397959198216425

Epoch: 6| Step: 3
Training loss: 2.216769556893901
Validation loss: 2.40166790787518

Epoch: 6| Step: 4
Training loss: 2.518257233004037
Validation loss: 2.421915730515285

Epoch: 6| Step: 5
Training loss: 2.0067492092725527
Validation loss: 2.435368392297329

Epoch: 6| Step: 6
Training loss: 1.9118644705585643
Validation loss: 2.440006959970124

Epoch: 6| Step: 7
Training loss: 2.540051452536102
Validation loss: 2.460511320199409

Epoch: 6| Step: 8
Training loss: 2.0427395343748187
Validation loss: 2.4949382766563186

Epoch: 6| Step: 9
Training loss: 2.4524961017729314
Validation loss: 2.480562185617839

Epoch: 6| Step: 10
Training loss: 2.746687888585051
Validation loss: 2.47099942851933

Epoch: 6| Step: 11
Training loss: 1.8972936881465692
Validation loss: 2.433679194979798

Epoch: 6| Step: 12
Training loss: 1.651273051352959
Validation loss: 2.4273664719605934

Epoch: 6| Step: 13
Training loss: 1.7267614741912736
Validation loss: 2.4214609279733135

Epoch: 173| Step: 0
Training loss: 1.868955405693694
Validation loss: 2.4275111663231366

Epoch: 6| Step: 1
Training loss: 2.176481781371283
Validation loss: 2.417935403986903

Epoch: 6| Step: 2
Training loss: 2.03917755153148
Validation loss: 2.4516448835908458

Epoch: 6| Step: 3
Training loss: 2.514362658215073
Validation loss: 2.4443347135400177

Epoch: 6| Step: 4
Training loss: 1.7841835627438074
Validation loss: 2.4452242921348777

Epoch: 6| Step: 5
Training loss: 2.038590650663566
Validation loss: 2.4223915758557055

Epoch: 6| Step: 6
Training loss: 2.4382481527236424
Validation loss: 2.423017654498928

Epoch: 6| Step: 7
Training loss: 1.9226901178891804
Validation loss: 2.4269889472721142

Epoch: 6| Step: 8
Training loss: 1.8458936481940436
Validation loss: 2.4484598227890935

Epoch: 6| Step: 9
Training loss: 2.0407920313381616
Validation loss: 2.465986111497819

Epoch: 6| Step: 10
Training loss: 2.2967288431389217
Validation loss: 2.4804692998382785

Epoch: 6| Step: 11
Training loss: 1.8542860899909528
Validation loss: 2.521873606944614

Epoch: 6| Step: 12
Training loss: 2.0356910866775486
Validation loss: 2.543184946179201

Epoch: 6| Step: 13
Training loss: 2.6454891571705197
Validation loss: 2.5121719262069973

Epoch: 174| Step: 0
Training loss: 1.9859825891497962
Validation loss: 2.465722562821507

Epoch: 6| Step: 1
Training loss: 2.3802025681529493
Validation loss: 2.4378240825815607

Epoch: 6| Step: 2
Training loss: 1.999515295898815
Validation loss: 2.435027280510944

Epoch: 6| Step: 3
Training loss: 2.2662611495773155
Validation loss: 2.4096483551808716

Epoch: 6| Step: 4
Training loss: 2.034297945171804
Validation loss: 2.4063671175716563

Epoch: 6| Step: 5
Training loss: 2.0189980369282474
Validation loss: 2.4195671864776993

Epoch: 6| Step: 6
Training loss: 1.7982817740675352
Validation loss: 2.399773083725974

Epoch: 6| Step: 7
Training loss: 2.407181794715567
Validation loss: 2.3969698856239408

Epoch: 6| Step: 8
Training loss: 2.23576685096305
Validation loss: 2.394975548444114

Epoch: 6| Step: 9
Training loss: 2.153775329263782
Validation loss: 2.4046780859226886

Epoch: 6| Step: 10
Training loss: 1.9133191592104626
Validation loss: 2.4068172565546972

Epoch: 6| Step: 11
Training loss: 2.1866769604712
Validation loss: 2.42210238021479

Epoch: 6| Step: 12
Training loss: 2.0929497855004704
Validation loss: 2.4553841353595995

Epoch: 6| Step: 13
Training loss: 1.5152743218966542
Validation loss: 2.4761228840515255

Epoch: 175| Step: 0
Training loss: 2.1244576828015203
Validation loss: 2.4843515715033213

Epoch: 6| Step: 1
Training loss: 1.8347930587786951
Validation loss: 2.492995494897115

Epoch: 6| Step: 2
Training loss: 2.1424398038546775
Validation loss: 2.4884808995144305

Epoch: 6| Step: 3
Training loss: 2.5767072998962024
Validation loss: 2.496346726963396

Epoch: 6| Step: 4
Training loss: 2.245660836337026
Validation loss: 2.479885146804003

Epoch: 6| Step: 5
Training loss: 2.07824064234161
Validation loss: 2.4673540263351814

Epoch: 6| Step: 6
Training loss: 2.178013750297361
Validation loss: 2.4609200222568646

Epoch: 6| Step: 7
Training loss: 1.7268361698938925
Validation loss: 2.4938775865631073

Epoch: 6| Step: 8
Training loss: 2.164302881434447
Validation loss: 2.4838770741932468

Epoch: 6| Step: 9
Training loss: 2.0906856374115073
Validation loss: 2.492421034373385

Epoch: 6| Step: 10
Training loss: 1.5899282522028186
Validation loss: 2.5244532792604018

Epoch: 6| Step: 11
Training loss: 2.1906959075988417
Validation loss: 2.6283227075136

Epoch: 6| Step: 12
Training loss: 1.9408941994417197
Validation loss: 2.664919102416023

Epoch: 6| Step: 13
Training loss: 2.294912109354222
Validation loss: 2.668292164164797

Epoch: 176| Step: 0
Training loss: 2.015292591216087
Validation loss: 2.6409434697902556

Epoch: 6| Step: 1
Training loss: 2.5178779322916722
Validation loss: 2.5358484383982134

Epoch: 6| Step: 2
Training loss: 1.9308079235175908
Validation loss: 2.5021408697260985

Epoch: 6| Step: 3
Training loss: 2.446750400922428
Validation loss: 2.4558843160154744

Epoch: 6| Step: 4
Training loss: 1.9093225450068885
Validation loss: 2.385342608409765

Epoch: 6| Step: 5
Training loss: 2.158348168379811
Validation loss: 2.3511357766346537

Epoch: 6| Step: 6
Training loss: 1.858031099771612
Validation loss: 2.354850099940334

Epoch: 6| Step: 7
Training loss: 2.064881885651253
Validation loss: 2.3624718849257142

Epoch: 6| Step: 8
Training loss: 2.4413201156680637
Validation loss: 2.356031155579258

Epoch: 6| Step: 9
Training loss: 2.299269485561953
Validation loss: 2.3613664643012995

Epoch: 6| Step: 10
Training loss: 1.8396615426131049
Validation loss: 2.369265984817914

Epoch: 6| Step: 11
Training loss: 1.6040603140053047
Validation loss: 2.3555999291054914

Epoch: 6| Step: 12
Training loss: 2.079077022151437
Validation loss: 2.3899730061644684

Epoch: 6| Step: 13
Training loss: 1.7225759751350025
Validation loss: 2.456265517541199

Epoch: 177| Step: 0
Training loss: 2.1119426782155135
Validation loss: 2.5220109076819845

Epoch: 6| Step: 1
Training loss: 1.2892747646466123
Validation loss: 2.533755314549608

Epoch: 6| Step: 2
Training loss: 2.390942321860233
Validation loss: 2.5422205769420874

Epoch: 6| Step: 3
Training loss: 1.7706268489355363
Validation loss: 2.5332016403729374

Epoch: 6| Step: 4
Training loss: 2.003729442507639
Validation loss: 2.5103559752620055

Epoch: 6| Step: 5
Training loss: 1.4987267812627716
Validation loss: 2.494580607109992

Epoch: 6| Step: 6
Training loss: 1.7636221269284973
Validation loss: 2.4629713616452538

Epoch: 6| Step: 7
Training loss: 1.8293425589116596
Validation loss: 2.4449174746624935

Epoch: 6| Step: 8
Training loss: 1.9213313132299057
Validation loss: 2.4557798509555866

Epoch: 6| Step: 9
Training loss: 1.9957567740498268
Validation loss: 2.4575975136198105

Epoch: 6| Step: 10
Training loss: 2.189194812901083
Validation loss: 2.4859099508870925

Epoch: 6| Step: 11
Training loss: 2.5290973128017136
Validation loss: 2.5117781115736086

Epoch: 6| Step: 12
Training loss: 2.741879002968392
Validation loss: 2.549619131339615

Epoch: 6| Step: 13
Training loss: 2.3100257214852262
Validation loss: 2.593281792236249

Epoch: 178| Step: 0
Training loss: 1.6225499977437436
Validation loss: 2.604276904982541

Epoch: 6| Step: 1
Training loss: 2.411335414008453
Validation loss: 2.612499473592528

Epoch: 6| Step: 2
Training loss: 1.4699860099853372
Validation loss: 2.5640984638696422

Epoch: 6| Step: 3
Training loss: 1.6433592763455966
Validation loss: 2.5178752137626663

Epoch: 6| Step: 4
Training loss: 1.824647318062285
Validation loss: 2.4753000251774697

Epoch: 6| Step: 5
Training loss: 2.1525641742138344
Validation loss: 2.45476964733459

Epoch: 6| Step: 6
Training loss: 2.001285974011253
Validation loss: 2.4554887738613567

Epoch: 6| Step: 7
Training loss: 2.1078908714842015
Validation loss: 2.4373444327960234

Epoch: 6| Step: 8
Training loss: 2.52241169301404
Validation loss: 2.4777719454509137

Epoch: 6| Step: 9
Training loss: 1.9852720620918587
Validation loss: 2.5213397812363625

Epoch: 6| Step: 10
Training loss: 2.2902242687301
Validation loss: 2.5810915528197325

Epoch: 6| Step: 11
Training loss: 1.8915277012715765
Validation loss: 2.5421857355944404

Epoch: 6| Step: 12
Training loss: 2.1775946739103613
Validation loss: 2.515198921364869

Epoch: 6| Step: 13
Training loss: 2.3506655582498213
Validation loss: 2.466829251859658

Epoch: 179| Step: 0
Training loss: 1.9446649047970868
Validation loss: 2.424571852570445

Epoch: 6| Step: 1
Training loss: 1.8131522616388587
Validation loss: 2.404742977825383

Epoch: 6| Step: 2
Training loss: 1.9445706833626244
Validation loss: 2.3905657678405916

Epoch: 6| Step: 3
Training loss: 2.0211953956338666
Validation loss: 2.401927085830593

Epoch: 6| Step: 4
Training loss: 2.2428352935427918
Validation loss: 2.4127612426098337

Epoch: 6| Step: 5
Training loss: 2.0400320503110696
Validation loss: 2.453328975016658

Epoch: 6| Step: 6
Training loss: 2.455642380433241
Validation loss: 2.503381539222514

Epoch: 6| Step: 7
Training loss: 1.9531055907238721
Validation loss: 2.5410240220934863

Epoch: 6| Step: 8
Training loss: 1.9280247493754072
Validation loss: 2.583398257130092

Epoch: 6| Step: 9
Training loss: 2.2575489141122445
Validation loss: 2.6336082856888234

Epoch: 6| Step: 10
Training loss: 1.7429179896781994
Validation loss: 2.5386071278125315

Epoch: 6| Step: 11
Training loss: 2.200556129909844
Validation loss: 2.4788971407412737

Epoch: 6| Step: 12
Training loss: 1.7975642996841652
Validation loss: 2.4595244810130645

Epoch: 6| Step: 13
Training loss: 2.018370303889816
Validation loss: 2.4471041645082185

Epoch: 180| Step: 0
Training loss: 2.27587738724539
Validation loss: 2.451362168238883

Epoch: 6| Step: 1
Training loss: 2.3531682308121664
Validation loss: 2.437360743269744

Epoch: 6| Step: 2
Training loss: 1.7845047778287135
Validation loss: 2.4133343903280844

Epoch: 6| Step: 3
Training loss: 1.4195824050713675
Validation loss: 2.373385252316707

Epoch: 6| Step: 4
Training loss: 1.9129259121432594
Validation loss: 2.37539281440897

Epoch: 6| Step: 5
Training loss: 2.000862412480368
Validation loss: 2.3665790423640476

Epoch: 6| Step: 6
Training loss: 2.309033037401167
Validation loss: 2.397174480873212

Epoch: 6| Step: 7
Training loss: 1.9517650905302797
Validation loss: 2.423585186948644

Epoch: 6| Step: 8
Training loss: 2.221659619586563
Validation loss: 2.4932432070259276

Epoch: 6| Step: 9
Training loss: 2.1919429890117206
Validation loss: 2.5306026076991985

Epoch: 6| Step: 10
Training loss: 1.6422837364388894
Validation loss: 2.507269648913978

Epoch: 6| Step: 11
Training loss: 1.878125319901374
Validation loss: 2.5176469476552463

Epoch: 6| Step: 12
Training loss: 2.066261098916118
Validation loss: 2.515581495311011

Epoch: 6| Step: 13
Training loss: 2.294416604118174
Validation loss: 2.5405819368698017

Epoch: 181| Step: 0
Training loss: 2.4082551998500867
Validation loss: 2.544748464958784

Epoch: 6| Step: 1
Training loss: 1.6168738904196431
Validation loss: 2.5661212655966197

Epoch: 6| Step: 2
Training loss: 1.77675731332266
Validation loss: 2.578509243260766

Epoch: 6| Step: 3
Training loss: 2.287537467107726
Validation loss: 2.580800822361215

Epoch: 6| Step: 4
Training loss: 2.0372042903568097
Validation loss: 2.5807155815189047

Epoch: 6| Step: 5
Training loss: 2.1587739629691107
Validation loss: 2.5474517066655618

Epoch: 6| Step: 6
Training loss: 2.1340764251580886
Validation loss: 2.5312160164048096

Epoch: 6| Step: 7
Training loss: 2.0587477798310974
Validation loss: 2.499312589337113

Epoch: 6| Step: 8
Training loss: 1.955777069060509
Validation loss: 2.479082434086651

Epoch: 6| Step: 9
Training loss: 1.8989111541004209
Validation loss: 2.4821006604713216

Epoch: 6| Step: 10
Training loss: 1.7416936747572613
Validation loss: 2.4762536798308314

Epoch: 6| Step: 11
Training loss: 1.3550475947618312
Validation loss: 2.4877813515171563

Epoch: 6| Step: 12
Training loss: 1.9309378831612682
Validation loss: 2.507722232668527

Epoch: 6| Step: 13
Training loss: 1.7601086348905317
Validation loss: 2.5252574698414376

Epoch: 182| Step: 0
Training loss: 1.78651680215813
Validation loss: 2.55140615238857

Epoch: 6| Step: 1
Training loss: 2.07912013958058
Validation loss: 2.559079412091337

Epoch: 6| Step: 2
Training loss: 1.8281661461006253
Validation loss: 2.577602904633678

Epoch: 6| Step: 3
Training loss: 1.7946356045943108
Validation loss: 2.5896950891604806

Epoch: 6| Step: 4
Training loss: 2.328069699033852
Validation loss: 2.5704452899755306

Epoch: 6| Step: 5
Training loss: 2.072972614804874
Validation loss: 2.5752332437580487

Epoch: 6| Step: 6
Training loss: 1.716496950235166
Validation loss: 2.5794358437068605

Epoch: 6| Step: 7
Training loss: 1.7428779089358333
Validation loss: 2.59322698335796

Epoch: 6| Step: 8
Training loss: 2.275552192158167
Validation loss: 2.6068230260550465

Epoch: 6| Step: 9
Training loss: 1.7599843489427853
Validation loss: 2.584006741414022

Epoch: 6| Step: 10
Training loss: 1.5007248557604234
Validation loss: 2.5571305018022574

Epoch: 6| Step: 11
Training loss: 2.3241096022165637
Validation loss: 2.5290481103599505

Epoch: 6| Step: 12
Training loss: 1.977691086942011
Validation loss: 2.507538256151705

Epoch: 6| Step: 13
Training loss: 1.538820818984281
Validation loss: 2.4779115972598786

Epoch: 183| Step: 0
Training loss: 2.04941430447678
Validation loss: 2.4481924752975868

Epoch: 6| Step: 1
Training loss: 1.1902056538766304
Validation loss: 2.437378463050006

Epoch: 6| Step: 2
Training loss: 2.160412736948597
Validation loss: 2.471646009196549

Epoch: 6| Step: 3
Training loss: 1.8792900597546476
Validation loss: 2.457353288805791

Epoch: 6| Step: 4
Training loss: 1.033568233022195
Validation loss: 2.4955435174059653

Epoch: 6| Step: 5
Training loss: 2.0374216076332794
Validation loss: 2.5123516184859294

Epoch: 6| Step: 6
Training loss: 1.565151330255235
Validation loss: 2.518759221415025

Epoch: 6| Step: 7
Training loss: 2.296748981781627
Validation loss: 2.55498619574983

Epoch: 6| Step: 8
Training loss: 1.8247025234298413
Validation loss: 2.5615385199115335

Epoch: 6| Step: 9
Training loss: 2.252391815466585
Validation loss: 2.5701459370684625

Epoch: 6| Step: 10
Training loss: 1.4718569096386958
Validation loss: 2.552831933176509

Epoch: 6| Step: 11
Training loss: 2.330768287941286
Validation loss: 2.509032648690068

Epoch: 6| Step: 12
Training loss: 2.0172611663392064
Validation loss: 2.5019250277571334

Epoch: 6| Step: 13
Training loss: 2.1072460592642397
Validation loss: 2.4421436785321418

Epoch: 184| Step: 0
Training loss: 2.265385476966984
Validation loss: 2.443996265613481

Epoch: 6| Step: 1
Training loss: 1.7430757046058856
Validation loss: 2.421237759308349

Epoch: 6| Step: 2
Training loss: 1.3387743627644828
Validation loss: 2.411119072061414

Epoch: 6| Step: 3
Training loss: 2.2007320746580468
Validation loss: 2.4130001383448136

Epoch: 6| Step: 4
Training loss: 2.019878542052961
Validation loss: 2.411779769544929

Epoch: 6| Step: 5
Training loss: 2.021373977963767
Validation loss: 2.433950371695579

Epoch: 6| Step: 6
Training loss: 1.096076616083981
Validation loss: 2.4815731748272123

Epoch: 6| Step: 7
Training loss: 2.3589596414319565
Validation loss: 2.501246990412304

Epoch: 6| Step: 8
Training loss: 1.8396905725944965
Validation loss: 2.53130893494343

Epoch: 6| Step: 9
Training loss: 1.80134133588499
Validation loss: 2.550792673274425

Epoch: 6| Step: 10
Training loss: 2.1876193422732926
Validation loss: 2.527555679813654

Epoch: 6| Step: 11
Training loss: 1.8596388685700733
Validation loss: 2.51187769521949

Epoch: 6| Step: 12
Training loss: 1.8356069064263307
Validation loss: 2.4887251955426497

Epoch: 6| Step: 13
Training loss: 1.6950424612122552
Validation loss: 2.473155408699138

Epoch: 185| Step: 0
Training loss: 2.4427477759543517
Validation loss: 2.4862189316980876

Epoch: 6| Step: 1
Training loss: 2.0446863485126383
Validation loss: 2.4808023895163935

Epoch: 6| Step: 2
Training loss: 1.8119727716189615
Validation loss: 2.4958968536063604

Epoch: 6| Step: 3
Training loss: 2.183126819346642
Validation loss: 2.4947736891334857

Epoch: 6| Step: 4
Training loss: 1.8413941154355293
Validation loss: 2.511126417960729

Epoch: 6| Step: 5
Training loss: 1.8772596095132952
Validation loss: 2.5367003786487667

Epoch: 6| Step: 6
Training loss: 1.8881326436226165
Validation loss: 2.5451181506187823

Epoch: 6| Step: 7
Training loss: 1.4493052001832458
Validation loss: 2.5264991537962636

Epoch: 6| Step: 8
Training loss: 1.476859572463592
Validation loss: 2.5155488934345285

Epoch: 6| Step: 9
Training loss: 1.6054035554072101
Validation loss: 2.484689869156046

Epoch: 6| Step: 10
Training loss: 1.4253266746453483
Validation loss: 2.4491975339868937

Epoch: 6| Step: 11
Training loss: 2.3121624262028053
Validation loss: 2.4434748943508486

Epoch: 6| Step: 12
Training loss: 1.539157302957391
Validation loss: 2.45827180657859

Epoch: 6| Step: 13
Training loss: 1.5291294283927883
Validation loss: 2.4595776268538527

Epoch: 186| Step: 0
Training loss: 1.5224776936918671
Validation loss: 2.4895803093082

Epoch: 6| Step: 1
Training loss: 1.55817776819781
Validation loss: 2.514677309084962

Epoch: 6| Step: 2
Training loss: 1.675282081650904
Validation loss: 2.533240685674012

Epoch: 6| Step: 3
Training loss: 1.780239286947888
Validation loss: 2.495023687640967

Epoch: 6| Step: 4
Training loss: 1.852268905125093
Validation loss: 2.5039468128174085

Epoch: 6| Step: 5
Training loss: 1.9135088684339028
Validation loss: 2.5157817673770126

Epoch: 6| Step: 6
Training loss: 1.9989082217499363
Validation loss: 2.5033414608559217

Epoch: 6| Step: 7
Training loss: 2.413890844865462
Validation loss: 2.497382629442433

Epoch: 6| Step: 8
Training loss: 1.592535865415752
Validation loss: 2.5102682299959205

Epoch: 6| Step: 9
Training loss: 1.7419915880291392
Validation loss: 2.5390176960641946

Epoch: 6| Step: 10
Training loss: 1.6312093210811816
Validation loss: 2.5002095452546156

Epoch: 6| Step: 11
Training loss: 1.9250608261208624
Validation loss: 2.532629974042213

Epoch: 6| Step: 12
Training loss: 1.4021869029789218
Validation loss: 2.544811008093378

Epoch: 6| Step: 13
Training loss: 2.3391042824111414
Validation loss: 2.5745292101781656

Epoch: 187| Step: 0
Training loss: 1.7635111350045147
Validation loss: 2.5670630533147696

Epoch: 6| Step: 1
Training loss: 1.4656030746804598
Validation loss: 2.559027002308254

Epoch: 6| Step: 2
Training loss: 1.5533412299276093
Validation loss: 2.5336564693686747

Epoch: 6| Step: 3
Training loss: 1.6590296614043505
Validation loss: 2.515799098868283

Epoch: 6| Step: 4
Training loss: 2.1082989243826935
Validation loss: 2.538603901304205

Epoch: 6| Step: 5
Training loss: 1.7972997412193068
Validation loss: 2.5405379347142234

Epoch: 6| Step: 6
Training loss: 1.9720422979078185
Validation loss: 2.5511769020852695

Epoch: 6| Step: 7
Training loss: 2.3189570002942848
Validation loss: 2.5211570495960416

Epoch: 6| Step: 8
Training loss: 1.6054285049035006
Validation loss: 2.5229889373766974

Epoch: 6| Step: 9
Training loss: 1.6430949193059046
Validation loss: 2.535115577771819

Epoch: 6| Step: 10
Training loss: 0.9664565286840842
Validation loss: 2.5345159618564406

Epoch: 6| Step: 11
Training loss: 1.756282360824071
Validation loss: 2.5440225870013706

Epoch: 6| Step: 12
Training loss: 1.7151704446601916
Validation loss: 2.5620576400167225

Epoch: 6| Step: 13
Training loss: 2.891127753998672
Validation loss: 2.556357104169791

Epoch: 188| Step: 0
Training loss: 2.0744547161934754
Validation loss: 2.5013360970322776

Epoch: 6| Step: 1
Training loss: 1.6008071979227432
Validation loss: 2.500014743966546

Epoch: 6| Step: 2
Training loss: 1.2348897802150118
Validation loss: 2.495498936839866

Epoch: 6| Step: 3
Training loss: 1.8261293130902427
Validation loss: 2.4937294316168974

Epoch: 6| Step: 4
Training loss: 1.7271351964853465
Validation loss: 2.5247438006574816

Epoch: 6| Step: 5
Training loss: 2.271097663637194
Validation loss: 2.5448564071418636

Epoch: 6| Step: 6
Training loss: 2.0154146779652358
Validation loss: 2.5535962467049496

Epoch: 6| Step: 7
Training loss: 1.79084602310042
Validation loss: 2.5766153767727444

Epoch: 6| Step: 8
Training loss: 2.3373051852881352
Validation loss: 2.6042019273565242

Epoch: 6| Step: 9
Training loss: 2.0481171078801994
Validation loss: 2.6053755883242293

Epoch: 6| Step: 10
Training loss: 1.5380594305751651
Validation loss: 2.60208864516832

Epoch: 6| Step: 11
Training loss: 1.3215347140627909
Validation loss: 2.5971036797169074

Epoch: 6| Step: 12
Training loss: 1.6597603359483788
Validation loss: 2.5938648614063045

Epoch: 6| Step: 13
Training loss: 1.3407803478800289
Validation loss: 2.6235563485452866

Epoch: 189| Step: 0
Training loss: 1.5920146395331272
Validation loss: 2.60779736890608

Epoch: 6| Step: 1
Training loss: 1.7664506045361108
Validation loss: 2.58792242896268

Epoch: 6| Step: 2
Training loss: 1.9971926178357027
Validation loss: 2.525800155564276

Epoch: 6| Step: 3
Training loss: 1.8568327377579064
Validation loss: 2.4680357242822164

Epoch: 6| Step: 4
Training loss: 2.1897400422160005
Validation loss: 2.464840487259311

Epoch: 6| Step: 5
Training loss: 1.6689465267741705
Validation loss: 2.5050689074831345

Epoch: 6| Step: 6
Training loss: 2.205183866278329
Validation loss: 2.507281211125277

Epoch: 6| Step: 7
Training loss: 1.6157349775944896
Validation loss: 2.5454426284596847

Epoch: 6| Step: 8
Training loss: 1.4684337518988797
Validation loss: 2.576779788403445

Epoch: 6| Step: 9
Training loss: 1.9501994079944165
Validation loss: 2.5749637636653064

Epoch: 6| Step: 10
Training loss: 1.409364895668095
Validation loss: 2.5364131451376095

Epoch: 6| Step: 11
Training loss: 2.0638585095960034
Validation loss: 2.5476912149290682

Epoch: 6| Step: 12
Training loss: 1.369494600561834
Validation loss: 2.4711725849530204

Epoch: 6| Step: 13
Training loss: 1.697710863368125
Validation loss: 2.4801809094649783

Epoch: 190| Step: 0
Training loss: 1.6753560840677577
Validation loss: 2.503453984034665

Epoch: 6| Step: 1
Training loss: 1.963929648143501
Validation loss: 2.5221411487964986

Epoch: 6| Step: 2
Training loss: 2.042835005107672
Validation loss: 2.506726515613922

Epoch: 6| Step: 3
Training loss: 1.5598700706464574
Validation loss: 2.521724683344438

Epoch: 6| Step: 4
Training loss: 1.57641524051519
Validation loss: 2.5649377176189283

Epoch: 6| Step: 5
Training loss: 1.9059554325829426
Validation loss: 2.5800070874923753

Epoch: 6| Step: 6
Training loss: 2.2775176359764675
Validation loss: 2.558782815229714

Epoch: 6| Step: 7
Training loss: 2.235111568661671
Validation loss: 2.5223432107550146

Epoch: 6| Step: 8
Training loss: 1.5508401316651417
Validation loss: 2.4769709780653293

Epoch: 6| Step: 9
Training loss: 1.2500903096954272
Validation loss: 2.477908292236616

Epoch: 6| Step: 10
Training loss: 1.8047249530027007
Validation loss: 2.4832356438751386

Epoch: 6| Step: 11
Training loss: 1.8142449759510626
Validation loss: 2.4757666501625146

Epoch: 6| Step: 12
Training loss: 1.3184455447822918
Validation loss: 2.462185061557893

Epoch: 6| Step: 13
Training loss: 1.3188541642402367
Validation loss: 2.4896663134151424

Epoch: 191| Step: 0
Training loss: 1.6101515294671676
Validation loss: 2.535684574730006

Epoch: 6| Step: 1
Training loss: 2.0819302475354515
Validation loss: 2.5597190954070403

Epoch: 6| Step: 2
Training loss: 1.352356605755168
Validation loss: 2.5808088717187645

Epoch: 6| Step: 3
Training loss: 1.3620522104470756
Validation loss: 2.5942719585820275

Epoch: 6| Step: 4
Training loss: 1.748711588548817
Validation loss: 2.59473291545809

Epoch: 6| Step: 5
Training loss: 2.0248841523364494
Validation loss: 2.5924657544966725

Epoch: 6| Step: 6
Training loss: 1.6652884825100032
Validation loss: 2.622427827210365

Epoch: 6| Step: 7
Training loss: 1.6910227986247701
Validation loss: 2.590208616712318

Epoch: 6| Step: 8
Training loss: 1.5515459995218324
Validation loss: 2.607586513064092

Epoch: 6| Step: 9
Training loss: 1.6517263571188994
Validation loss: 2.596553672428666

Epoch: 6| Step: 10
Training loss: 1.3432662447954011
Validation loss: 2.5825087739452552

Epoch: 6| Step: 11
Training loss: 1.7771815634705967
Validation loss: 2.546449394305388

Epoch: 6| Step: 12
Training loss: 2.1542335701544233
Validation loss: 2.5701186905623574

Epoch: 6| Step: 13
Training loss: 1.827418264082379
Validation loss: 2.5464347852988016

Epoch: 192| Step: 0
Training loss: 1.3888975408072668
Validation loss: 2.522780478362883

Epoch: 6| Step: 1
Training loss: 1.5285000143952723
Validation loss: 2.54004095694003

Epoch: 6| Step: 2
Training loss: 1.7578877072670125
Validation loss: 2.494518195592349

Epoch: 6| Step: 3
Training loss: 1.8385517743258772
Validation loss: 2.492812373663992

Epoch: 6| Step: 4
Training loss: 1.5392689832638526
Validation loss: 2.4775646445629307

Epoch: 6| Step: 5
Training loss: 1.4850295380502827
Validation loss: 2.497279776106076

Epoch: 6| Step: 6
Training loss: 2.0124793531413108
Validation loss: 2.513337010169596

Epoch: 6| Step: 7
Training loss: 1.8054267062974707
Validation loss: 2.547298973634322

Epoch: 6| Step: 8
Training loss: 1.5321016862503312
Validation loss: 2.565461340215558

Epoch: 6| Step: 9
Training loss: 1.802668908150726
Validation loss: 2.619224523321133

Epoch: 6| Step: 10
Training loss: 1.3838934256665902
Validation loss: 2.5949831296067445

Epoch: 6| Step: 11
Training loss: 1.7707458100474667
Validation loss: 2.5772227031193524

Epoch: 6| Step: 12
Training loss: 1.6712419969342844
Validation loss: 2.565408722544796

Epoch: 6| Step: 13
Training loss: 2.2997892407589005
Validation loss: 2.540293661767779

Epoch: 193| Step: 0
Training loss: 1.6043251586828384
Validation loss: 2.5270299864292034

Epoch: 6| Step: 1
Training loss: 1.1775446243901395
Validation loss: 2.5352490615408336

Epoch: 6| Step: 2
Training loss: 1.6616052385235685
Validation loss: 2.5393833913666954

Epoch: 6| Step: 3
Training loss: 1.3863180951798
Validation loss: 2.5285628201569232

Epoch: 6| Step: 4
Training loss: 1.7769693168863434
Validation loss: 2.530421297718377

Epoch: 6| Step: 5
Training loss: 2.101641458495801
Validation loss: 2.542884270407896

Epoch: 6| Step: 6
Training loss: 1.8343228646299161
Validation loss: 2.545237784692018

Epoch: 6| Step: 7
Training loss: 1.6869863505464209
Validation loss: 2.5592818663033534

Epoch: 6| Step: 8
Training loss: 1.6571165013448936
Validation loss: 2.572251398822397

Epoch: 6| Step: 9
Training loss: 1.8622993105094112
Validation loss: 2.5871032123681448

Epoch: 6| Step: 10
Training loss: 1.1445669747984144
Validation loss: 2.5898659529660937

Epoch: 6| Step: 11
Training loss: 2.0197254434332916
Validation loss: 2.5834078680421153

Epoch: 6| Step: 12
Training loss: 1.5206486141254334
Validation loss: 2.6008144639592823

Epoch: 6| Step: 13
Training loss: 1.722089540162874
Validation loss: 2.557535820030335

Epoch: 194| Step: 0
Training loss: 2.0462053674154137
Validation loss: 2.5940910715058987

Epoch: 6| Step: 1
Training loss: 1.5384712439010835
Validation loss: 2.566190060106632

Epoch: 6| Step: 2
Training loss: 1.5418519432839668
Validation loss: 2.5821510259732166

Epoch: 6| Step: 3
Training loss: 1.365612321528541
Validation loss: 2.5657182818588615

Epoch: 6| Step: 4
Training loss: 1.347698531662357
Validation loss: 2.549619469187408

Epoch: 6| Step: 5
Training loss: 1.7214226490273887
Validation loss: 2.5451009915861333

Epoch: 6| Step: 6
Training loss: 2.263887357288719
Validation loss: 2.534708544490597

Epoch: 6| Step: 7
Training loss: 1.6366901986993612
Validation loss: 2.5685297577248183

Epoch: 6| Step: 8
Training loss: 1.4906860307079512
Validation loss: 2.566977535053868

Epoch: 6| Step: 9
Training loss: 1.3467453684014625
Validation loss: 2.572946048519153

Epoch: 6| Step: 10
Training loss: 1.96798994136969
Validation loss: 2.600308835168938

Epoch: 6| Step: 11
Training loss: 1.5994755242953311
Validation loss: 2.598911130516242

Epoch: 6| Step: 12
Training loss: 1.778224450198001
Validation loss: 2.6254894446820223

Epoch: 6| Step: 13
Training loss: 0.875719455849528
Validation loss: 2.605802828440673

Epoch: 195| Step: 0
Training loss: 1.4354717209015921
Validation loss: 2.5738375226779366

Epoch: 6| Step: 1
Training loss: 1.5946778233328174
Validation loss: 2.527495487865115

Epoch: 6| Step: 2
Training loss: 1.4803449030384455
Validation loss: 2.501871929961514

Epoch: 6| Step: 3
Training loss: 1.4555124338733463
Validation loss: 2.479981404796145

Epoch: 6| Step: 4
Training loss: 1.6197376139986082
Validation loss: 2.4944781490194825

Epoch: 6| Step: 5
Training loss: 2.166700167274689
Validation loss: 2.5275732470236894

Epoch: 6| Step: 6
Training loss: 1.5632886803491894
Validation loss: 2.5033732677867393

Epoch: 6| Step: 7
Training loss: 1.4540907409142318
Validation loss: 2.5457411410723925

Epoch: 6| Step: 8
Training loss: 1.8915938740083165
Validation loss: 2.5431412582138453

Epoch: 6| Step: 9
Training loss: 1.2622143035029865
Validation loss: 2.6032874577704557

Epoch: 6| Step: 10
Training loss: 2.0324501600172393
Validation loss: 2.6409278109129777

Epoch: 6| Step: 11
Training loss: 1.6199005515574205
Validation loss: 2.700071649538817

Epoch: 6| Step: 12
Training loss: 1.5524309353662182
Validation loss: 2.6941341431071573

Epoch: 6| Step: 13
Training loss: 1.576197892249646
Validation loss: 2.6879301354147955

Epoch: 196| Step: 0
Training loss: 1.458820134612265
Validation loss: 2.656499369604219

Epoch: 6| Step: 1
Training loss: 1.7615882842142925
Validation loss: 2.58300392387391

Epoch: 6| Step: 2
Training loss: 1.8112195194436056
Validation loss: 2.537405464144646

Epoch: 6| Step: 3
Training loss: 1.9970989644949537
Validation loss: 2.4953235449138034

Epoch: 6| Step: 4
Training loss: 1.5352370068612624
Validation loss: 2.4730609976669564

Epoch: 6| Step: 5
Training loss: 1.7414170002594798
Validation loss: 2.435535512227433

Epoch: 6| Step: 6
Training loss: 1.497042999715177
Validation loss: 2.426770463980944

Epoch: 6| Step: 7
Training loss: 1.9158023945004243
Validation loss: 2.4429726997539087

Epoch: 6| Step: 8
Training loss: 1.5717694559933333
Validation loss: 2.4563158167727996

Epoch: 6| Step: 9
Training loss: 1.6934392045683517
Validation loss: 2.5178307786336247

Epoch: 6| Step: 10
Training loss: 1.5461697752979133
Validation loss: 2.597282756484347

Epoch: 6| Step: 11
Training loss: 1.1333879784892442
Validation loss: 2.6324902915442516

Epoch: 6| Step: 12
Training loss: 1.5772204686772788
Validation loss: 2.6600213125563834

Epoch: 6| Step: 13
Training loss: 1.9445331651640643
Validation loss: 2.653435382606841

Epoch: 197| Step: 0
Training loss: 1.2209658408701851
Validation loss: 2.6240280078480684

Epoch: 6| Step: 1
Training loss: 1.6374732124525377
Validation loss: 2.5700297781928976

Epoch: 6| Step: 2
Training loss: 1.6315612379126572
Validation loss: 2.5436951141269386

Epoch: 6| Step: 3
Training loss: 1.439610052159842
Validation loss: 2.5236484342025447

Epoch: 6| Step: 4
Training loss: 1.8184839978315077
Validation loss: 2.4938738036169257

Epoch: 6| Step: 5
Training loss: 1.7875421719144644
Validation loss: 2.4927887575903496

Epoch: 6| Step: 6
Training loss: 1.3385371741233076
Validation loss: 2.4724039327680187

Epoch: 6| Step: 7
Training loss: 2.205259330879401
Validation loss: 2.5013896258932813

Epoch: 6| Step: 8
Training loss: 1.5056719038622186
Validation loss: 2.479440518506185

Epoch: 6| Step: 9
Training loss: 1.3510134248666523
Validation loss: 2.532519050878525

Epoch: 6| Step: 10
Training loss: 1.0280208894373537
Validation loss: 2.5644352875911194

Epoch: 6| Step: 11
Training loss: 1.4085046284050775
Validation loss: 2.604071407093508

Epoch: 6| Step: 12
Training loss: 2.183923358641433
Validation loss: 2.651302911198411

Epoch: 6| Step: 13
Training loss: 1.483930019137283
Validation loss: 2.6055903569878307

Epoch: 198| Step: 0
Training loss: 1.8624456359302557
Validation loss: 2.544434158480956

Epoch: 6| Step: 1
Training loss: 1.6321589425890148
Validation loss: 2.512590915775949

Epoch: 6| Step: 2
Training loss: 1.8828150958917855
Validation loss: 2.4842464067794676

Epoch: 6| Step: 3
Training loss: 1.150781276933368
Validation loss: 2.4532561827844703

Epoch: 6| Step: 4
Training loss: 1.5957553439426602
Validation loss: 2.4575230963225887

Epoch: 6| Step: 5
Training loss: 1.8400107791833684
Validation loss: 2.4901367312483487

Epoch: 6| Step: 6
Training loss: 1.1128391391872552
Validation loss: 2.5164927822325978

Epoch: 6| Step: 7
Training loss: 1.824291415676652
Validation loss: 2.523624689683576

Epoch: 6| Step: 8
Training loss: 1.7923343508486171
Validation loss: 2.547855950018304

Epoch: 6| Step: 9
Training loss: 1.152546182729076
Validation loss: 2.575376798095861

Epoch: 6| Step: 10
Training loss: 1.6636341958616927
Validation loss: 2.641099662276164

Epoch: 6| Step: 11
Training loss: 1.234408221220278
Validation loss: 2.635124653076696

Epoch: 6| Step: 12
Training loss: 1.4358424706296535
Validation loss: 2.6315425520470446

Epoch: 6| Step: 13
Training loss: 1.3894589711158245
Validation loss: 2.635486935666863

Epoch: 199| Step: 0
Training loss: 1.6487163289806
Validation loss: 2.6104886077970986

Epoch: 6| Step: 1
Training loss: 1.1844425494173105
Validation loss: 2.604730524526325

Epoch: 6| Step: 2
Training loss: 0.9754324516399905
Validation loss: 2.6049851655084018

Epoch: 6| Step: 3
Training loss: 1.199692424457019
Validation loss: 2.594754306929355

Epoch: 6| Step: 4
Training loss: 1.4559595497821383
Validation loss: 2.6012121031908677

Epoch: 6| Step: 5
Training loss: 1.640322993501662
Validation loss: 2.5937064530786365

Epoch: 6| Step: 6
Training loss: 1.9929988031876602
Validation loss: 2.558582113064652

Epoch: 6| Step: 7
Training loss: 1.4238524048962924
Validation loss: 2.5184198465481047

Epoch: 6| Step: 8
Training loss: 1.5321635421134046
Validation loss: 2.5100555759335617

Epoch: 6| Step: 9
Training loss: 1.4222858380371988
Validation loss: 2.5102689264962583

Epoch: 6| Step: 10
Training loss: 1.4745858500037805
Validation loss: 2.505023493759466

Epoch: 6| Step: 11
Training loss: 1.690724435868244
Validation loss: 2.514237401486055

Epoch: 6| Step: 12
Training loss: 2.019938149402325
Validation loss: 2.5224915906983307

Epoch: 6| Step: 13
Training loss: 1.4026310873393315
Validation loss: 2.580073884187631

Epoch: 200| Step: 0
Training loss: 1.8408287958814802
Validation loss: 2.6344640695417794

Epoch: 6| Step: 1
Training loss: 1.6673744447213745
Validation loss: 2.6277112382977332

Epoch: 6| Step: 2
Training loss: 1.454245022882447
Validation loss: 2.6366780488865675

Epoch: 6| Step: 3
Training loss: 1.5399478747476154
Validation loss: 2.602793738618725

Epoch: 6| Step: 4
Training loss: 1.6745198088163689
Validation loss: 2.6007645837571793

Epoch: 6| Step: 5
Training loss: 1.3770124273854432
Validation loss: 2.590306164927245

Epoch: 6| Step: 6
Training loss: 1.7536089332927316
Validation loss: 2.5797627974171946

Epoch: 6| Step: 7
Training loss: 1.4576671531973608
Validation loss: 2.56219357084752

Epoch: 6| Step: 8
Training loss: 1.5935131719815072
Validation loss: 2.554281821128607

Epoch: 6| Step: 9
Training loss: 0.9929866425997843
Validation loss: 2.5427911548119138

Epoch: 6| Step: 10
Training loss: 1.6148357891298089
Validation loss: 2.5776181933218254

Epoch: 6| Step: 11
Training loss: 1.1773015835506981
Validation loss: 2.535058629488448

Epoch: 6| Step: 12
Training loss: 1.5366461515126038
Validation loss: 2.566821650717527

Epoch: 6| Step: 13
Training loss: 1.3481575738316718
Validation loss: 2.577491268204716

Epoch: 201| Step: 0
Training loss: 1.3845054478894605
Validation loss: 2.5634162859336858

Epoch: 6| Step: 1
Training loss: 1.3642730165916384
Validation loss: 2.6060257013365766

Epoch: 6| Step: 2
Training loss: 1.6742902760929435
Validation loss: 2.6153004111596325

Epoch: 6| Step: 3
Training loss: 1.4363688289133645
Validation loss: 2.6222829224459754

Epoch: 6| Step: 4
Training loss: 1.603279272914166
Validation loss: 2.598966374870747

Epoch: 6| Step: 5
Training loss: 1.2407356750934198
Validation loss: 2.618123645763271

Epoch: 6| Step: 6
Training loss: 1.4834214209357584
Validation loss: 2.620572097550466

Epoch: 6| Step: 7
Training loss: 1.3747708823308429
Validation loss: 2.650869422456982

Epoch: 6| Step: 8
Training loss: 1.0712645257523639
Validation loss: 2.6966405986418436

Epoch: 6| Step: 9
Training loss: 1.7695885116373238
Validation loss: 2.6751691028950493

Epoch: 6| Step: 10
Training loss: 1.677390581817767
Validation loss: 2.6992123390357756

Epoch: 6| Step: 11
Training loss: 1.3059832140791638
Validation loss: 2.6438280263822387

Epoch: 6| Step: 12
Training loss: 1.5972649950943747
Validation loss: 2.6517478723814043

Epoch: 6| Step: 13
Training loss: 1.8609736646442012
Validation loss: 2.580074687041117

Epoch: 202| Step: 0
Training loss: 1.400741086385111
Validation loss: 2.5654076028168036

Epoch: 6| Step: 1
Training loss: 1.4055661976117793
Validation loss: 2.509448909650559

Epoch: 6| Step: 2
Training loss: 1.469476885198128
Validation loss: 2.4955882512660548

Epoch: 6| Step: 3
Training loss: 1.407219446655326
Validation loss: 2.500085142182948

Epoch: 6| Step: 4
Training loss: 1.8962463795294804
Validation loss: 2.5035584335711114

Epoch: 6| Step: 5
Training loss: 1.3334605136456146
Validation loss: 2.490344231225457

Epoch: 6| Step: 6
Training loss: 1.050060322709043
Validation loss: 2.538562994478271

Epoch: 6| Step: 7
Training loss: 1.5865913133332206
Validation loss: 2.509590218831647

Epoch: 6| Step: 8
Training loss: 1.387498663136981
Validation loss: 2.554636810974963

Epoch: 6| Step: 9
Training loss: 1.6875178018266752
Validation loss: 2.5686623174927457

Epoch: 6| Step: 10
Training loss: 0.9115945151182865
Validation loss: 2.593969105296053

Epoch: 6| Step: 11
Training loss: 1.760709012227326
Validation loss: 2.5976808336938784

Epoch: 6| Step: 12
Training loss: 1.6861782549051756
Validation loss: 2.5981442515149236

Epoch: 6| Step: 13
Training loss: 1.2765020928162132
Validation loss: 2.590581389425185

Epoch: 203| Step: 0
Training loss: 1.4501680211026275
Validation loss: 2.596031986954106

Epoch: 6| Step: 1
Training loss: 1.4042456860291819
Validation loss: 2.6125500099532433

Epoch: 6| Step: 2
Training loss: 1.58456526898541
Validation loss: 2.615747633205296

Epoch: 6| Step: 3
Training loss: 1.2227127013413095
Validation loss: 2.5979240763612252

Epoch: 6| Step: 4
Training loss: 1.4315614353151824
Validation loss: 2.5655354015472107

Epoch: 6| Step: 5
Training loss: 1.2529966673932278
Validation loss: 2.5849397754054384

Epoch: 6| Step: 6
Training loss: 1.4083977298949044
Validation loss: 2.5718739204074033

Epoch: 6| Step: 7
Training loss: 1.3547662239123979
Validation loss: 2.567445411359426

Epoch: 6| Step: 8
Training loss: 1.2522018114209381
Validation loss: 2.535386228960521

Epoch: 6| Step: 9
Training loss: 1.7772992138994321
Validation loss: 2.55697616924322

Epoch: 6| Step: 10
Training loss: 1.9880529246356455
Validation loss: 2.5441006179391503

Epoch: 6| Step: 11
Training loss: 1.2569487075780204
Validation loss: 2.5668279214290366

Epoch: 6| Step: 12
Training loss: 1.4783407332110785
Validation loss: 2.56117234800986

Epoch: 6| Step: 13
Training loss: 1.1599806835769584
Validation loss: 2.5469211906604503

Epoch: 204| Step: 0
Training loss: 0.688407429139249
Validation loss: 2.583742989150376

Epoch: 6| Step: 1
Training loss: 1.4152013081481476
Validation loss: 2.5934760696138155

Epoch: 6| Step: 2
Training loss: 1.680048775078407
Validation loss: 2.601456685051268

Epoch: 6| Step: 3
Training loss: 1.4710425482949305
Validation loss: 2.6237137490527687

Epoch: 6| Step: 4
Training loss: 1.7983861788296658
Validation loss: 2.638819639063338

Epoch: 6| Step: 5
Training loss: 1.7425253502029328
Validation loss: 2.6207211198408253

Epoch: 6| Step: 6
Training loss: 1.4381524968575234
Validation loss: 2.6388360002187046

Epoch: 6| Step: 7
Training loss: 1.6057400439406746
Validation loss: 2.6189108657385836

Epoch: 6| Step: 8
Training loss: 0.8767881514376924
Validation loss: 2.6304415737180564

Epoch: 6| Step: 9
Training loss: 1.180507299272202
Validation loss: 2.6029563529403497

Epoch: 6| Step: 10
Training loss: 1.4811177705743994
Validation loss: 2.5896635950438722

Epoch: 6| Step: 11
Training loss: 1.8111934556684444
Validation loss: 2.5825156473484814

Epoch: 6| Step: 12
Training loss: 1.052126452377566
Validation loss: 2.6201817660329136

Epoch: 6| Step: 13
Training loss: 0.9189520905555854
Validation loss: 2.653781194775919

Epoch: 205| Step: 0
Training loss: 1.3443392858722647
Validation loss: 2.6345485376251467

Epoch: 6| Step: 1
Training loss: 1.298335482449073
Validation loss: 2.6386716359950557

Epoch: 6| Step: 2
Training loss: 1.2876358460544552
Validation loss: 2.650453941671104

Epoch: 6| Step: 3
Training loss: 1.761794331826056
Validation loss: 2.6222354787628523

Epoch: 6| Step: 4
Training loss: 1.679947801868973
Validation loss: 2.6427753321756757

Epoch: 6| Step: 5
Training loss: 1.505152040196696
Validation loss: 2.625185016063453

Epoch: 6| Step: 6
Training loss: 1.0496229857288808
Validation loss: 2.610309154839884

Epoch: 6| Step: 7
Training loss: 1.3391238577994606
Validation loss: 2.5897624635447194

Epoch: 6| Step: 8
Training loss: 1.3992821470857888
Validation loss: 2.562287827818752

Epoch: 6| Step: 9
Training loss: 1.2151980358785963
Validation loss: 2.553194490637439

Epoch: 6| Step: 10
Training loss: 1.2471695802950153
Validation loss: 2.5643033390955745

Epoch: 6| Step: 11
Training loss: 1.4318104808429633
Validation loss: 2.5970335624938503

Epoch: 6| Step: 12
Training loss: 1.7483443193602646
Validation loss: 2.586934895289623

Epoch: 6| Step: 13
Training loss: 1.239154351426997
Validation loss: 2.6126040631514575

Epoch: 206| Step: 0
Training loss: 0.8586559061421173
Validation loss: 2.614010424064254

Epoch: 6| Step: 1
Training loss: 1.5803426136891474
Validation loss: 2.641557597120741

Epoch: 6| Step: 2
Training loss: 1.4908551564262127
Validation loss: 2.591741817104794

Epoch: 6| Step: 3
Training loss: 1.1479876928400812
Validation loss: 2.593799081084222

Epoch: 6| Step: 4
Training loss: 1.5229428001628127
Validation loss: 2.5919522547689624

Epoch: 6| Step: 5
Training loss: 1.9815521587444291
Validation loss: 2.5553111130283668

Epoch: 6| Step: 6
Training loss: 1.3114235414591977
Validation loss: 2.5321448159999185

Epoch: 6| Step: 7
Training loss: 1.005896469469224
Validation loss: 2.5604857605195708

Epoch: 6| Step: 8
Training loss: 1.5005341214676595
Validation loss: 2.5748377093250445

Epoch: 6| Step: 9
Training loss: 1.3104301207336424
Validation loss: 2.601713363952463

Epoch: 6| Step: 10
Training loss: 1.1870176439910218
Validation loss: 2.5983935116463193

Epoch: 6| Step: 11
Training loss: 1.744356592696961
Validation loss: 2.604114375091908

Epoch: 6| Step: 12
Training loss: 1.178704869366112
Validation loss: 2.6022711525313107

Epoch: 6| Step: 13
Training loss: 1.2163092798133854
Validation loss: 2.6198210981967285

Epoch: 207| Step: 0
Training loss: 1.0166183309060746
Validation loss: 2.613779444881739

Epoch: 6| Step: 1
Training loss: 1.5570639844669978
Validation loss: 2.600434676894164

Epoch: 6| Step: 2
Training loss: 1.614525045347719
Validation loss: 2.604650624907856

Epoch: 6| Step: 3
Training loss: 1.1761787224313403
Validation loss: 2.5666141427992697

Epoch: 6| Step: 4
Training loss: 0.9391412038716429
Validation loss: 2.552736266044198

Epoch: 6| Step: 5
Training loss: 1.699401424717404
Validation loss: 2.5684763819621517

Epoch: 6| Step: 6
Training loss: 1.4201038773917236
Validation loss: 2.5884340173539964

Epoch: 6| Step: 7
Training loss: 1.3025427452878473
Validation loss: 2.5538678584963725

Epoch: 6| Step: 8
Training loss: 1.537817126807648
Validation loss: 2.5760696178003446

Epoch: 6| Step: 9
Training loss: 1.104471572427252
Validation loss: 2.5833538430385863

Epoch: 6| Step: 10
Training loss: 1.0920424074385413
Validation loss: 2.559059548673438

Epoch: 6| Step: 11
Training loss: 1.2420725259414147
Validation loss: 2.561262540260921

Epoch: 6| Step: 12
Training loss: 1.8894293921815524
Validation loss: 2.5952775022718937

Epoch: 6| Step: 13
Training loss: 1.589248283276089
Validation loss: 2.626642923078614

Epoch: 208| Step: 0
Training loss: 1.508965560317843
Validation loss: 2.6532920702956067

Epoch: 6| Step: 1
Training loss: 1.1285517574875812
Validation loss: 2.636226375643597

Epoch: 6| Step: 2
Training loss: 1.2097297798637954
Validation loss: 2.6483520354633434

Epoch: 6| Step: 3
Training loss: 1.323710611349929
Validation loss: 2.6262197946756545

Epoch: 6| Step: 4
Training loss: 1.0475083897511852
Validation loss: 2.6007641500378105

Epoch: 6| Step: 5
Training loss: 1.2783693634950366
Validation loss: 2.5758043133154804

Epoch: 6| Step: 6
Training loss: 1.8502457842068165
Validation loss: 2.5422710965522293

Epoch: 6| Step: 7
Training loss: 1.437344584149105
Validation loss: 2.5799229750916717

Epoch: 6| Step: 8
Training loss: 1.3611705803800682
Validation loss: 2.562447550127043

Epoch: 6| Step: 9
Training loss: 0.9254273651674864
Validation loss: 2.598690898995665

Epoch: 6| Step: 10
Training loss: 1.484282641298157
Validation loss: 2.6229015699784215

Epoch: 6| Step: 11
Training loss: 1.681439714470078
Validation loss: 2.6327451444938936

Epoch: 6| Step: 12
Training loss: 1.2018935601938303
Validation loss: 2.6697757036795196

Epoch: 6| Step: 13
Training loss: 1.8993350446489594
Validation loss: 2.664365290341494

Epoch: 209| Step: 0
Training loss: 1.3401186469202966
Validation loss: 2.6809026370984395

Epoch: 6| Step: 1
Training loss: 1.375429389838526
Validation loss: 2.6744797402031897

Epoch: 6| Step: 2
Training loss: 1.3680898685745755
Validation loss: 2.634686755910641

Epoch: 6| Step: 3
Training loss: 1.3157380895871031
Validation loss: 2.604919193114288

Epoch: 6| Step: 4
Training loss: 1.0382836656850896
Validation loss: 2.5636516297267615

Epoch: 6| Step: 5
Training loss: 1.9711888662666321
Validation loss: 2.5593909825034293

Epoch: 6| Step: 6
Training loss: 1.2443925970683158
Validation loss: 2.528052476422004

Epoch: 6| Step: 7
Training loss: 0.9824287914844131
Validation loss: 2.5383898564886183

Epoch: 6| Step: 8
Training loss: 1.3729538865705024
Validation loss: 2.536142322524775

Epoch: 6| Step: 9
Training loss: 0.9178818681873738
Validation loss: 2.559251244055714

Epoch: 6| Step: 10
Training loss: 1.411757724817163
Validation loss: 2.576090726375345

Epoch: 6| Step: 11
Training loss: 1.4189110349438576
Validation loss: 2.576622203214618

Epoch: 6| Step: 12
Training loss: 1.4261238418134383
Validation loss: 2.6097918865087615

Epoch: 6| Step: 13
Training loss: 1.5892578094996237
Validation loss: 2.6468161405682693

Epoch: 210| Step: 0
Training loss: 1.6078426880963563
Validation loss: 2.6277373095904415

Epoch: 6| Step: 1
Training loss: 1.297122931622954
Validation loss: 2.614468423491496

Epoch: 6| Step: 2
Training loss: 0.8747873047764367
Validation loss: 2.6120529173389757

Epoch: 6| Step: 3
Training loss: 1.3743171730383617
Validation loss: 2.601250021202552

Epoch: 6| Step: 4
Training loss: 1.4480666853581505
Validation loss: 2.608966101974355

Epoch: 6| Step: 5
Training loss: 0.8484768740683847
Validation loss: 2.6046541928301137

Epoch: 6| Step: 6
Training loss: 1.64062747046875
Validation loss: 2.5867022902789913

Epoch: 6| Step: 7
Training loss: 1.5097809429304592
Validation loss: 2.6129778135813035

Epoch: 6| Step: 8
Training loss: 1.1744171035958153
Validation loss: 2.561808356969676

Epoch: 6| Step: 9
Training loss: 1.378959935685836
Validation loss: 2.597458149340702

Epoch: 6| Step: 10
Training loss: 0.9236256093167623
Validation loss: 2.59123812481381

Epoch: 6| Step: 11
Training loss: 1.3135582880737715
Validation loss: 2.6018048003956147

Epoch: 6| Step: 12
Training loss: 1.4777273598932255
Validation loss: 2.6319729190009467

Epoch: 6| Step: 13
Training loss: 1.5874832212507588
Validation loss: 2.6090427732703567

Epoch: 211| Step: 0
Training loss: 1.5741101551699395
Validation loss: 2.625408709185422

Epoch: 6| Step: 1
Training loss: 0.8785869103019106
Validation loss: 2.5832804880549154

Epoch: 6| Step: 2
Training loss: 1.112204690378606
Validation loss: 2.5770916620208584

Epoch: 6| Step: 3
Training loss: 0.9933941329893395
Validation loss: 2.553993753325034

Epoch: 6| Step: 4
Training loss: 1.7862195744202314
Validation loss: 2.5543974145072217

Epoch: 6| Step: 5
Training loss: 1.4631573137302394
Validation loss: 2.548764288362223

Epoch: 6| Step: 6
Training loss: 1.2319543015005538
Validation loss: 2.5960561307854415

Epoch: 6| Step: 7
Training loss: 1.5566557879888068
Validation loss: 2.5967811518648323

Epoch: 6| Step: 8
Training loss: 0.9744970222494196
Validation loss: 2.6185246834611116

Epoch: 6| Step: 9
Training loss: 1.7398862137256697
Validation loss: 2.6695170941069755

Epoch: 6| Step: 10
Training loss: 1.0392566585552288
Validation loss: 2.701892665531556

Epoch: 6| Step: 11
Training loss: 1.6525650778001895
Validation loss: 2.692353015678404

Epoch: 6| Step: 12
Training loss: 1.0264575457519913
Validation loss: 2.6820424109936605

Epoch: 6| Step: 13
Training loss: 1.0037724149678626
Validation loss: 2.676366905921357

Epoch: 212| Step: 0
Training loss: 1.1972403344723852
Validation loss: 2.648069257802727

Epoch: 6| Step: 1
Training loss: 1.04485524758376
Validation loss: 2.624270809089631

Epoch: 6| Step: 2
Training loss: 1.0020295052667105
Validation loss: 2.623526377825924

Epoch: 6| Step: 3
Training loss: 1.3755411037042993
Validation loss: 2.594473731287075

Epoch: 6| Step: 4
Training loss: 1.6176775498499991
Validation loss: 2.6083613015755502

Epoch: 6| Step: 5
Training loss: 1.0465508713621507
Validation loss: 2.5982355737968637

Epoch: 6| Step: 6
Training loss: 1.1529987607256142
Validation loss: 2.594006465049193

Epoch: 6| Step: 7
Training loss: 1.4501302890778136
Validation loss: 2.577176330380894

Epoch: 6| Step: 8
Training loss: 1.7856901276180475
Validation loss: 2.58805999430708

Epoch: 6| Step: 9
Training loss: 1.416808355015137
Validation loss: 2.6078986386132588

Epoch: 6| Step: 10
Training loss: 1.3589249666172265
Validation loss: 2.6139819022944013

Epoch: 6| Step: 11
Training loss: 1.3478640631071301
Validation loss: 2.6313258632220484

Epoch: 6| Step: 12
Training loss: 0.8903674707015375
Validation loss: 2.636070645680097

Epoch: 6| Step: 13
Training loss: 1.3771619706008977
Validation loss: 2.6248084885701912

Epoch: 213| Step: 0
Training loss: 1.0457544735259496
Validation loss: 2.6079511288977244

Epoch: 6| Step: 1
Training loss: 0.8900482585767583
Validation loss: 2.6402132407787633

Epoch: 6| Step: 2
Training loss: 1.2883332010115291
Validation loss: 2.6172126779828266

Epoch: 6| Step: 3
Training loss: 1.354218535774824
Validation loss: 2.6108461432618966

Epoch: 6| Step: 4
Training loss: 1.3546306206576986
Validation loss: 2.6013221549635768

Epoch: 6| Step: 5
Training loss: 1.2482700775139273
Validation loss: 2.58289436305042

Epoch: 6| Step: 6
Training loss: 1.2032477576311982
Validation loss: 2.6129552085153787

Epoch: 6| Step: 7
Training loss: 1.2059515410883765
Validation loss: 2.6079441229798803

Epoch: 6| Step: 8
Training loss: 1.6990731012470734
Validation loss: 2.628254312251556

Epoch: 6| Step: 9
Training loss: 1.6075547674409931
Validation loss: 2.627873058962443

Epoch: 6| Step: 10
Training loss: 1.3565873688916392
Validation loss: 2.602813132355273

Epoch: 6| Step: 11
Training loss: 1.615766407664475
Validation loss: 2.635025112707015

Epoch: 6| Step: 12
Training loss: 0.8878995117065002
Validation loss: 2.5876035603300362

Epoch: 6| Step: 13
Training loss: 1.1578067918397372
Validation loss: 2.5776323282161666

Epoch: 214| Step: 0
Training loss: 1.130415649854177
Validation loss: 2.615179959543566

Epoch: 6| Step: 1
Training loss: 1.2245758392755388
Validation loss: 2.6139763267728022

Epoch: 6| Step: 2
Training loss: 1.4637548035787962
Validation loss: 2.616430053910322

Epoch: 6| Step: 3
Training loss: 1.1286427543444402
Validation loss: 2.6448099412986137

Epoch: 6| Step: 4
Training loss: 0.8287523160876193
Validation loss: 2.605602445156526

Epoch: 6| Step: 5
Training loss: 0.8285076049243855
Validation loss: 2.6291942596222713

Epoch: 6| Step: 6
Training loss: 1.5549619806186368
Validation loss: 2.630872387771684

Epoch: 6| Step: 7
Training loss: 1.1240955531818038
Validation loss: 2.6118754043820047

Epoch: 6| Step: 8
Training loss: 1.4032978860420957
Validation loss: 2.643809575922559

Epoch: 6| Step: 9
Training loss: 1.6909429254763828
Validation loss: 2.6314167431985185

Epoch: 6| Step: 10
Training loss: 0.9390797338951303
Validation loss: 2.6298537580756514

Epoch: 6| Step: 11
Training loss: 1.3965157885452817
Validation loss: 2.63470464022074

Epoch: 6| Step: 12
Training loss: 1.5799518247092534
Validation loss: 2.608920414821465

Epoch: 6| Step: 13
Training loss: 1.3184588359472593
Validation loss: 2.631546765445328

Epoch: 215| Step: 0
Training loss: 1.2438167228245596
Validation loss: 2.5978544307821294

Epoch: 6| Step: 1
Training loss: 0.9079999142617341
Validation loss: 2.6160001257614502

Epoch: 6| Step: 2
Training loss: 0.9928649031677889
Validation loss: 2.614114138215873

Epoch: 6| Step: 3
Training loss: 1.4299838066518016
Validation loss: 2.6015788057503544

Epoch: 6| Step: 4
Training loss: 1.1990114710102384
Validation loss: 2.590770146864442

Epoch: 6| Step: 5
Training loss: 1.1009294571205115
Validation loss: 2.5986366570216726

Epoch: 6| Step: 6
Training loss: 1.3901406205353348
Validation loss: 2.6112003996968944

Epoch: 6| Step: 7
Training loss: 1.1919981939922963
Validation loss: 2.6235436786269286

Epoch: 6| Step: 8
Training loss: 1.5625430291926725
Validation loss: 2.647377591219164

Epoch: 6| Step: 9
Training loss: 1.1169530449118996
Validation loss: 2.6781163278950646

Epoch: 6| Step: 10
Training loss: 1.4681045250177398
Validation loss: 2.652737908633827

Epoch: 6| Step: 11
Training loss: 1.1688686208655952
Validation loss: 2.6624400514798583

Epoch: 6| Step: 12
Training loss: 1.0063558297748496
Validation loss: 2.636213111659617

Epoch: 6| Step: 13
Training loss: 2.0368713064239246
Validation loss: 2.6263441657278994

Epoch: 216| Step: 0
Training loss: 1.3689266369558482
Validation loss: 2.5640715320378065

Epoch: 6| Step: 1
Training loss: 1.2145815256584067
Validation loss: 2.5974894892380727

Epoch: 6| Step: 2
Training loss: 1.003898947128867
Validation loss: 2.5655807466319986

Epoch: 6| Step: 3
Training loss: 1.0018422323806992
Validation loss: 2.570328222035257

Epoch: 6| Step: 4
Training loss: 1.406688579408236
Validation loss: 2.5799177780938707

Epoch: 6| Step: 5
Training loss: 1.6305477369959704
Validation loss: 2.5619304733399253

Epoch: 6| Step: 6
Training loss: 0.9473312827096374
Validation loss: 2.572200412568157

Epoch: 6| Step: 7
Training loss: 1.2718076983366873
Validation loss: 2.5800642588690264

Epoch: 6| Step: 8
Training loss: 1.2954338062944315
Validation loss: 2.5886293131778717

Epoch: 6| Step: 9
Training loss: 1.298786179861938
Validation loss: 2.6096597326665427

Epoch: 6| Step: 10
Training loss: 1.2363451915846628
Validation loss: 2.6066138607377334

Epoch: 6| Step: 11
Training loss: 1.4045251652794475
Validation loss: 2.6121092518875866

Epoch: 6| Step: 12
Training loss: 1.2249687190830358
Validation loss: 2.638169013168003

Epoch: 6| Step: 13
Training loss: 0.8400500376875097
Validation loss: 2.651418792096106

Epoch: 217| Step: 0
Training loss: 1.1402781756131006
Validation loss: 2.647571645424556

Epoch: 6| Step: 1
Training loss: 1.1620554166175912
Validation loss: 2.6137043533956676

Epoch: 6| Step: 2
Training loss: 0.9068911356315346
Validation loss: 2.5975299970755814

Epoch: 6| Step: 3
Training loss: 1.5473986423312431
Validation loss: 2.580377837789163

Epoch: 6| Step: 4
Training loss: 1.5383862399050743
Validation loss: 2.5490468655333745

Epoch: 6| Step: 5
Training loss: 0.829968900787318
Validation loss: 2.56462497977423

Epoch: 6| Step: 6
Training loss: 1.4077815299062313
Validation loss: 2.574012058519871

Epoch: 6| Step: 7
Training loss: 0.7768096622602736
Validation loss: 2.5859437481500755

Epoch: 6| Step: 8
Training loss: 1.158839547854451
Validation loss: 2.5900747683396905

Epoch: 6| Step: 9
Training loss: 1.8257930913564846
Validation loss: 2.60404302061502

Epoch: 6| Step: 10
Training loss: 0.7950893291333543
Validation loss: 2.597260678612584

Epoch: 6| Step: 11
Training loss: 1.414962903402549
Validation loss: 2.6086295147796363

Epoch: 6| Step: 12
Training loss: 1.1741935681595272
Validation loss: 2.594647835905943

Epoch: 6| Step: 13
Training loss: 1.0190499291321649
Validation loss: 2.620980507351794

Epoch: 218| Step: 0
Training loss: 0.9744238055658295
Validation loss: 2.6105474842133165

Epoch: 6| Step: 1
Training loss: 1.2209323515245252
Validation loss: 2.5786855914111

Epoch: 6| Step: 2
Training loss: 1.645434206439798
Validation loss: 2.594555860695044

Epoch: 6| Step: 3
Training loss: 0.7419717977181891
Validation loss: 2.5481695129921604

Epoch: 6| Step: 4
Training loss: 1.2448210240603863
Validation loss: 2.5668414955169054

Epoch: 6| Step: 5
Training loss: 0.9253430516520963
Validation loss: 2.548984290555633

Epoch: 6| Step: 6
Training loss: 1.3978643681407468
Validation loss: 2.557003913216611

Epoch: 6| Step: 7
Training loss: 1.0728819140882928
Validation loss: 2.583691824836116

Epoch: 6| Step: 8
Training loss: 1.3531057554642878
Validation loss: 2.6151886184506377

Epoch: 6| Step: 9
Training loss: 0.9603141065162655
Validation loss: 2.598161799282363

Epoch: 6| Step: 10
Training loss: 1.5074025916264664
Validation loss: 2.601198007728347

Epoch: 6| Step: 11
Training loss: 1.2135111377898091
Validation loss: 2.613933334541422

Epoch: 6| Step: 12
Training loss: 1.4234926014189733
Validation loss: 2.6397399200577385

Epoch: 6| Step: 13
Training loss: 1.1731915517148406
Validation loss: 2.633125080920351

Epoch: 219| Step: 0
Training loss: 1.2688706307778
Validation loss: 2.642370425884746

Epoch: 6| Step: 1
Training loss: 1.1320474079840208
Validation loss: 2.625097966844243

Epoch: 6| Step: 2
Training loss: 1.82932783153993
Validation loss: 2.5875835131372673

Epoch: 6| Step: 3
Training loss: 1.3137824741055757
Validation loss: 2.5474970445653327

Epoch: 6| Step: 4
Training loss: 1.143879363034898
Validation loss: 2.5413306175663073

Epoch: 6| Step: 5
Training loss: 1.2691554525676858
Validation loss: 2.5489096758974705

Epoch: 6| Step: 6
Training loss: 1.1406773071836926
Validation loss: 2.5364572380531683

Epoch: 6| Step: 7
Training loss: 0.7409086352276185
Validation loss: 2.550332751069089

Epoch: 6| Step: 8
Training loss: 1.3406108295251962
Validation loss: 2.5689150444917837

Epoch: 6| Step: 9
Training loss: 1.5732077104045397
Validation loss: 2.567389506719627

Epoch: 6| Step: 10
Training loss: 0.7767973469895141
Validation loss: 2.5569480078799787

Epoch: 6| Step: 11
Training loss: 1.1807697712642051
Validation loss: 2.628391523328885

Epoch: 6| Step: 12
Training loss: 0.9757470350169143
Validation loss: 2.6436530407368153

Epoch: 6| Step: 13
Training loss: 0.5876986421419133
Validation loss: 2.6695614969191994

Epoch: 220| Step: 0
Training loss: 0.8729198115860424
Validation loss: 2.672614553128272

Epoch: 6| Step: 1
Training loss: 1.1885388999770803
Validation loss: 2.679221540957698

Epoch: 6| Step: 2
Training loss: 0.924072168871775
Validation loss: 2.648918294308643

Epoch: 6| Step: 3
Training loss: 1.9669803355775335
Validation loss: 2.644642369437519

Epoch: 6| Step: 4
Training loss: 0.6944887446472597
Validation loss: 2.654327555870153

Epoch: 6| Step: 5
Training loss: 1.3007405592593941
Validation loss: 2.601844905055633

Epoch: 6| Step: 6
Training loss: 1.1696866265430497
Validation loss: 2.5801235553085027

Epoch: 6| Step: 7
Training loss: 1.182710828153017
Validation loss: 2.593274231641708

Epoch: 6| Step: 8
Training loss: 1.0906466462793554
Validation loss: 2.6049847689045103

Epoch: 6| Step: 9
Training loss: 1.2830105293002423
Validation loss: 2.5980446935164383

Epoch: 6| Step: 10
Training loss: 1.2463153893123686
Validation loss: 2.608798442727104

Epoch: 6| Step: 11
Training loss: 1.191575735575402
Validation loss: 2.594708469822464

Epoch: 6| Step: 12
Training loss: 1.0400100632327391
Validation loss: 2.6240691543000754

Epoch: 6| Step: 13
Training loss: 1.3152420827732085
Validation loss: 2.61598606000029

Epoch: 221| Step: 0
Training loss: 0.8780132928571921
Validation loss: 2.642631425268402

Epoch: 6| Step: 1
Training loss: 1.0786225649640082
Validation loss: 2.5872323933422354

Epoch: 6| Step: 2
Training loss: 1.8615142953320192
Validation loss: 2.594051655380133

Epoch: 6| Step: 3
Training loss: 1.4259386785679147
Validation loss: 2.589655986267617

Epoch: 6| Step: 4
Training loss: 1.2479092278786867
Validation loss: 2.6035948002812535

Epoch: 6| Step: 5
Training loss: 1.2712145165936732
Validation loss: 2.639237045596733

Epoch: 6| Step: 6
Training loss: 1.1290269938908746
Validation loss: 2.6231067097739733

Epoch: 6| Step: 7
Training loss: 1.0216384683941988
Validation loss: 2.6442801981524844

Epoch: 6| Step: 8
Training loss: 1.1675747107835244
Validation loss: 2.622281076177976

Epoch: 6| Step: 9
Training loss: 1.188870191625137
Validation loss: 2.630614642219866

Epoch: 6| Step: 10
Training loss: 1.0823275163946706
Validation loss: 2.6283981089839257

Epoch: 6| Step: 11
Training loss: 0.8893198857551337
Validation loss: 2.604481033218935

Epoch: 6| Step: 12
Training loss: 1.0765948286586762
Validation loss: 2.601050986377515

Epoch: 6| Step: 13
Training loss: 0.6761426896221175
Validation loss: 2.600997249971739

Epoch: 222| Step: 0
Training loss: 0.9216415303604091
Validation loss: 2.596051808434985

Epoch: 6| Step: 1
Training loss: 0.731286065932095
Validation loss: 2.651961795831855

Epoch: 6| Step: 2
Training loss: 0.9530045167409651
Validation loss: 2.6225223284478907

Epoch: 6| Step: 3
Training loss: 1.4746299085387433
Validation loss: 2.6616583163590524

Epoch: 6| Step: 4
Training loss: 0.8298366060633602
Validation loss: 2.652969676259425

Epoch: 6| Step: 5
Training loss: 1.0799012410079476
Validation loss: 2.6299517717278738

Epoch: 6| Step: 6
Training loss: 1.5358616419208402
Validation loss: 2.6525604953512767

Epoch: 6| Step: 7
Training loss: 1.339881740732121
Validation loss: 2.669259674425108

Epoch: 6| Step: 8
Training loss: 1.3428219096364773
Validation loss: 2.6413356259024288

Epoch: 6| Step: 9
Training loss: 1.2743262249722311
Validation loss: 2.69697952734309

Epoch: 6| Step: 10
Training loss: 1.240490215676532
Validation loss: 2.615728335858776

Epoch: 6| Step: 11
Training loss: 1.3792808823480767
Validation loss: 2.646291862296682

Epoch: 6| Step: 12
Training loss: 0.9030066363110865
Validation loss: 2.6267928199332684

Epoch: 6| Step: 13
Training loss: 0.8160172772425044
Validation loss: 2.594005360136434

Epoch: 223| Step: 0
Training loss: 1.063893526303438
Validation loss: 2.596780751046235

Epoch: 6| Step: 1
Training loss: 1.257132304831594
Validation loss: 2.6107869112443263

Epoch: 6| Step: 2
Training loss: 0.7407747173685094
Validation loss: 2.624989455358653

Epoch: 6| Step: 3
Training loss: 1.2380216789750915
Validation loss: 2.631261078840415

Epoch: 6| Step: 4
Training loss: 0.9244303766548329
Validation loss: 2.6599640025009146

Epoch: 6| Step: 5
Training loss: 0.9900371648574978
Validation loss: 2.6438245045385727

Epoch: 6| Step: 6
Training loss: 0.9467333369776886
Validation loss: 2.6518763245185064

Epoch: 6| Step: 7
Training loss: 0.9217604226500051
Validation loss: 2.6221809367995754

Epoch: 6| Step: 8
Training loss: 1.2528564717166244
Validation loss: 2.603151267344284

Epoch: 6| Step: 9
Training loss: 1.0844206610748504
Validation loss: 2.5766756112149425

Epoch: 6| Step: 10
Training loss: 1.0647279717020073
Validation loss: 2.622409687119084

Epoch: 6| Step: 11
Training loss: 2.023718619241747
Validation loss: 2.5755730441840763

Epoch: 6| Step: 12
Training loss: 1.106901231451691
Validation loss: 2.612193790198355

Epoch: 6| Step: 13
Training loss: 1.4492479511619616
Validation loss: 2.601567812412273

Epoch: 224| Step: 0
Training loss: 1.0617506526283036
Validation loss: 2.620262873914402

Epoch: 6| Step: 1
Training loss: 1.8555638981566256
Validation loss: 2.6206498125348188

Epoch: 6| Step: 2
Training loss: 0.8966464226563449
Validation loss: 2.630406782050547

Epoch: 6| Step: 3
Training loss: 1.0504291611054075
Validation loss: 2.6452158028902897

Epoch: 6| Step: 4
Training loss: 0.8853328478165046
Validation loss: 2.605861934685123

Epoch: 6| Step: 5
Training loss: 0.90213816228723
Validation loss: 2.6207832614792417

Epoch: 6| Step: 6
Training loss: 1.307942607063782
Validation loss: 2.617140982931839

Epoch: 6| Step: 7
Training loss: 1.2614416520863527
Validation loss: 2.6040432244033545

Epoch: 6| Step: 8
Training loss: 1.2018678215236995
Validation loss: 2.5886741368741926

Epoch: 6| Step: 9
Training loss: 1.1109305208526163
Validation loss: 2.585326149233585

Epoch: 6| Step: 10
Training loss: 1.1168565059725293
Validation loss: 2.5597009485840503

Epoch: 6| Step: 11
Training loss: 1.3152263118812837
Validation loss: 2.561055354198013

Epoch: 6| Step: 12
Training loss: 0.8868611091241013
Validation loss: 2.553557607022807

Epoch: 6| Step: 13
Training loss: 0.8990438654151491
Validation loss: 2.5551683040502198

Epoch: 225| Step: 0
Training loss: 0.801648744698708
Validation loss: 2.589990649325029

Epoch: 6| Step: 1
Training loss: 1.2020813514961994
Validation loss: 2.590693478059187

Epoch: 6| Step: 2
Training loss: 0.9671677311616367
Validation loss: 2.630783588991383

Epoch: 6| Step: 3
Training loss: 0.7029122772562143
Validation loss: 2.6174749582322163

Epoch: 6| Step: 4
Training loss: 0.6039994901898108
Validation loss: 2.6396645070144995

Epoch: 6| Step: 5
Training loss: 1.0616182146339512
Validation loss: 2.620686293036986

Epoch: 6| Step: 6
Training loss: 1.0377386163442366
Validation loss: 2.6295262850583727

Epoch: 6| Step: 7
Training loss: 1.273352403664377
Validation loss: 2.6476348862051324

Epoch: 6| Step: 8
Training loss: 0.9765917048855679
Validation loss: 2.6518769354899456

Epoch: 6| Step: 9
Training loss: 1.3483684040282045
Validation loss: 2.6437849416551966

Epoch: 6| Step: 10
Training loss: 1.264170906312925
Validation loss: 2.6324792831639248

Epoch: 6| Step: 11
Training loss: 1.1753487028973166
Validation loss: 2.6170040148945315

Epoch: 6| Step: 12
Training loss: 1.763726285346508
Validation loss: 2.653177776638151

Epoch: 6| Step: 13
Training loss: 1.3186463446354595
Validation loss: 2.6191055686907068

Epoch: 226| Step: 0
Training loss: 1.4802830562034932
Validation loss: 2.651107593537562

Epoch: 6| Step: 1
Training loss: 1.0712559015919383
Validation loss: 2.64901136615138

Epoch: 6| Step: 2
Training loss: 1.2315852352696965
Validation loss: 2.6132248710638963

Epoch: 6| Step: 3
Training loss: 0.9594145390815463
Validation loss: 2.6162449948891413

Epoch: 6| Step: 4
Training loss: 0.963097292868535
Validation loss: 2.6641224182086436

Epoch: 6| Step: 5
Training loss: 0.7915512343793618
Validation loss: 2.644490352125396

Epoch: 6| Step: 6
Training loss: 1.1818418221176676
Validation loss: 2.6452180668499845

Epoch: 6| Step: 7
Training loss: 1.4756524243324898
Validation loss: 2.6441251631069096

Epoch: 6| Step: 8
Training loss: 0.8704989331198897
Validation loss: 2.6225670371877925

Epoch: 6| Step: 9
Training loss: 0.9352172398258168
Validation loss: 2.611341669025413

Epoch: 6| Step: 10
Training loss: 1.3122011934471198
Validation loss: 2.5993930884492604

Epoch: 6| Step: 11
Training loss: 0.8015506304778581
Validation loss: 2.5674149933232866

Epoch: 6| Step: 12
Training loss: 1.312368658851094
Validation loss: 2.605022714667903

Epoch: 6| Step: 13
Training loss: 0.9505436759538104
Validation loss: 2.5992076873432914

Epoch: 227| Step: 0
Training loss: 1.0495847675717014
Validation loss: 2.596413341215729

Epoch: 6| Step: 1
Training loss: 1.1021286611964543
Validation loss: 2.604021024179405

Epoch: 6| Step: 2
Training loss: 1.067957326497261
Validation loss: 2.6403987190741276

Epoch: 6| Step: 3
Training loss: 0.9081842892241996
Validation loss: 2.647059168189928

Epoch: 6| Step: 4
Training loss: 1.5883425061393661
Validation loss: 2.6679637648666312

Epoch: 6| Step: 5
Training loss: 1.1969532893698436
Validation loss: 2.678849329231994

Epoch: 6| Step: 6
Training loss: 1.1212847078494956
Validation loss: 2.664120101029338

Epoch: 6| Step: 7
Training loss: 0.5852957453572595
Validation loss: 2.653465887937654

Epoch: 6| Step: 8
Training loss: 1.4637273577886158
Validation loss: 2.629128080015038

Epoch: 6| Step: 9
Training loss: 0.6029894859384223
Validation loss: 2.581757564708722

Epoch: 6| Step: 10
Training loss: 1.2259003619642133
Validation loss: 2.596013059036638

Epoch: 6| Step: 11
Training loss: 1.350475248819674
Validation loss: 2.6086763897504626

Epoch: 6| Step: 12
Training loss: 0.9400256785476876
Validation loss: 2.6030653392218137

Epoch: 6| Step: 13
Training loss: 0.7874998728434142
Validation loss: 2.6273105256073808

Epoch: 228| Step: 0
Training loss: 1.070080363027657
Validation loss: 2.6371306562735457

Epoch: 6| Step: 1
Training loss: 0.91537739657482
Validation loss: 2.6345883374891916

Epoch: 6| Step: 2
Training loss: 1.310471920593145
Validation loss: 2.6663408086734113

Epoch: 6| Step: 3
Training loss: 1.0406266679263567
Validation loss: 2.6926020646130104

Epoch: 6| Step: 4
Training loss: 0.8318675421904252
Validation loss: 2.6555419547628483

Epoch: 6| Step: 5
Training loss: 1.8155381620194668
Validation loss: 2.664429742236123

Epoch: 6| Step: 6
Training loss: 0.6440170086190228
Validation loss: 2.656829728255391

Epoch: 6| Step: 7
Training loss: 1.2177979100513114
Validation loss: 2.6182129816229245

Epoch: 6| Step: 8
Training loss: 0.46262074904716427
Validation loss: 2.6059853963876773

Epoch: 6| Step: 9
Training loss: 1.0246028526177087
Validation loss: 2.609316586410517

Epoch: 6| Step: 10
Training loss: 0.9944461135802892
Validation loss: 2.5835245963383233

Epoch: 6| Step: 11
Training loss: 1.0002736670819727
Validation loss: 2.5910090802377277

Epoch: 6| Step: 12
Training loss: 1.2957903451116222
Validation loss: 2.6130821887597464

Epoch: 6| Step: 13
Training loss: 1.424930349956721
Validation loss: 2.622166877796

Epoch: 229| Step: 0
Training loss: 0.8555672993789747
Validation loss: 2.6474940942004723

Epoch: 6| Step: 1
Training loss: 0.8104525223933676
Validation loss: 2.6402249004918126

Epoch: 6| Step: 2
Training loss: 1.19283041960818
Validation loss: 2.6379965598116693

Epoch: 6| Step: 3
Training loss: 0.9139945828237621
Validation loss: 2.6468086554080648

Epoch: 6| Step: 4
Training loss: 1.9073356913623458
Validation loss: 2.6005342735226358

Epoch: 6| Step: 5
Training loss: 1.0017753577225226
Validation loss: 2.5849040509609744

Epoch: 6| Step: 6
Training loss: 1.1632834266042746
Validation loss: 2.6172583766174973

Epoch: 6| Step: 7
Training loss: 1.2101858451874108
Validation loss: 2.5709599198429927

Epoch: 6| Step: 8
Training loss: 0.9722724371763788
Validation loss: 2.555413448483889

Epoch: 6| Step: 9
Training loss: 1.1346180700073891
Validation loss: 2.5515843064042403

Epoch: 6| Step: 10
Training loss: 0.7541763138197942
Validation loss: 2.5712646651714848

Epoch: 6| Step: 11
Training loss: 1.052852248916003
Validation loss: 2.573115441067705

Epoch: 6| Step: 12
Training loss: 0.9674750521496575
Validation loss: 2.6021271720744172

Epoch: 6| Step: 13
Training loss: 1.2460848529940511
Validation loss: 2.6171299572518874

Epoch: 230| Step: 0
Training loss: 0.5730971456683275
Validation loss: 2.6532079419149492

Epoch: 6| Step: 1
Training loss: 1.086566825026472
Validation loss: 2.6872235180024813

Epoch: 6| Step: 2
Training loss: 1.6080234370682434
Validation loss: 2.6809665365158404

Epoch: 6| Step: 3
Training loss: 1.015103954760766
Validation loss: 2.6675507495736883

Epoch: 6| Step: 4
Training loss: 1.0960332743682277
Validation loss: 2.6335773624681478

Epoch: 6| Step: 5
Training loss: 0.8738097542343836
Validation loss: 2.640875474196231

Epoch: 6| Step: 6
Training loss: 1.1900032162021803
Validation loss: 2.650349206218657

Epoch: 6| Step: 7
Training loss: 0.8829847859749247
Validation loss: 2.606530157454063

Epoch: 6| Step: 8
Training loss: 0.8699142613311157
Validation loss: 2.6231313442359223

Epoch: 6| Step: 9
Training loss: 1.591597655765852
Validation loss: 2.5972992341977976

Epoch: 6| Step: 10
Training loss: 0.7616713680300313
Validation loss: 2.6221737323029175

Epoch: 6| Step: 11
Training loss: 1.078304994457402
Validation loss: 2.5944748226608096

Epoch: 6| Step: 12
Training loss: 0.9951242553340146
Validation loss: 2.6125774571658393

Epoch: 6| Step: 13
Training loss: 1.387075931593876
Validation loss: 2.613854626404758

Epoch: 231| Step: 0
Training loss: 1.7074318422311527
Validation loss: 2.6416216398639256

Epoch: 6| Step: 1
Training loss: 0.983678662283738
Validation loss: 2.62985299576434

Epoch: 6| Step: 2
Training loss: 1.0652562462660053
Validation loss: 2.618296271278871

Epoch: 6| Step: 3
Training loss: 1.2676055387991658
Validation loss: 2.6372525749213453

Epoch: 6| Step: 4
Training loss: 0.9394288565500916
Validation loss: 2.617584367885758

Epoch: 6| Step: 5
Training loss: 0.9265414307950489
Validation loss: 2.608821455264459

Epoch: 6| Step: 6
Training loss: 1.2797286142305024
Validation loss: 2.6258727594112736

Epoch: 6| Step: 7
Training loss: 1.1182823951441365
Validation loss: 2.60912264057438

Epoch: 6| Step: 8
Training loss: 1.0966720241098844
Validation loss: 2.565953895583736

Epoch: 6| Step: 9
Training loss: 1.099519173698248
Validation loss: 2.594995487492229

Epoch: 6| Step: 10
Training loss: 0.7819082919929947
Validation loss: 2.6172375109318646

Epoch: 6| Step: 11
Training loss: 0.50395894329554
Validation loss: 2.6164645591603968

Epoch: 6| Step: 12
Training loss: 0.9539692376013352
Validation loss: 2.63441735369359

Epoch: 6| Step: 13
Training loss: 1.0612196781602932
Validation loss: 2.6614420903777836

Epoch: 232| Step: 0
Training loss: 0.8503196115417196
Validation loss: 2.64590354950932

Epoch: 6| Step: 1
Training loss: 1.181965428629407
Validation loss: 2.6709264052312665

Epoch: 6| Step: 2
Training loss: 0.8806613606512806
Validation loss: 2.666215357224661

Epoch: 6| Step: 3
Training loss: 1.394177389261374
Validation loss: 2.649222616681538

Epoch: 6| Step: 4
Training loss: 1.5632901292021621
Validation loss: 2.6017068289950447

Epoch: 6| Step: 5
Training loss: 0.7848583054678502
Validation loss: 2.592963229706357

Epoch: 6| Step: 6
Training loss: 1.1285909984712994
Validation loss: 2.6144844683297594

Epoch: 6| Step: 7
Training loss: 0.9955803539182263
Validation loss: 2.6069387659011354

Epoch: 6| Step: 8
Training loss: 1.052540947124403
Validation loss: 2.6150724428010803

Epoch: 6| Step: 9
Training loss: 0.846181333452202
Validation loss: 2.6033382251479207

Epoch: 6| Step: 10
Training loss: 1.1355192272283519
Validation loss: 2.585287767611583

Epoch: 6| Step: 11
Training loss: 1.0348277596423787
Validation loss: 2.5713294277555465

Epoch: 6| Step: 12
Training loss: 0.8072303666662721
Validation loss: 2.5421187294497942

Epoch: 6| Step: 13
Training loss: 1.1478490035278606
Validation loss: 2.5815703578410676

Epoch: 233| Step: 0
Training loss: 0.7273204910378245
Validation loss: 2.580454122614581

Epoch: 6| Step: 1
Training loss: 0.9540841951224464
Validation loss: 2.5813454360439625

Epoch: 6| Step: 2
Training loss: 0.8973617083761654
Validation loss: 2.5739973240869114

Epoch: 6| Step: 3
Training loss: 1.0806077758757815
Validation loss: 2.6236958171828246

Epoch: 6| Step: 4
Training loss: 0.9363900607762572
Validation loss: 2.6385158944098643

Epoch: 6| Step: 5
Training loss: 1.1454784652970254
Validation loss: 2.677357082480429

Epoch: 6| Step: 6
Training loss: 0.9213015825796907
Validation loss: 2.702208648714891

Epoch: 6| Step: 7
Training loss: 1.3819099972562114
Validation loss: 2.7167066873752805

Epoch: 6| Step: 8
Training loss: 1.3051300212060934
Validation loss: 2.695608035865035

Epoch: 6| Step: 9
Training loss: 0.997960872639961
Validation loss: 2.6693816829127566

Epoch: 6| Step: 10
Training loss: 0.8562816084993297
Validation loss: 2.643925147711937

Epoch: 6| Step: 11
Training loss: 1.1828657372611968
Validation loss: 2.622803049478225

Epoch: 6| Step: 12
Training loss: 1.454169195586504
Validation loss: 2.610004330736263

Epoch: 6| Step: 13
Training loss: 0.9184598542433191
Validation loss: 2.605174622090014

Epoch: 234| Step: 0
Training loss: 0.9212005863886833
Validation loss: 2.6282991400260265

Epoch: 6| Step: 1
Training loss: 0.5510323134880251
Validation loss: 2.617291930626325

Epoch: 6| Step: 2
Training loss: 1.2236682250431135
Validation loss: 2.6520613418921517

Epoch: 6| Step: 3
Training loss: 1.0363075044365577
Validation loss: 2.660569268945602

Epoch: 6| Step: 4
Training loss: 1.3403014355000669
Validation loss: 2.721506989859926

Epoch: 6| Step: 5
Training loss: 1.0864588083111952
Validation loss: 2.6869508907767625

Epoch: 6| Step: 6
Training loss: 0.7760939015126642
Validation loss: 2.654587510968069

Epoch: 6| Step: 7
Training loss: 0.9685971847106518
Validation loss: 2.656039208982476

Epoch: 6| Step: 8
Training loss: 0.8421517882976491
Validation loss: 2.6502418519536226

Epoch: 6| Step: 9
Training loss: 1.5479392041926934
Validation loss: 2.646914396830492

Epoch: 6| Step: 10
Training loss: 1.4180991372935634
Validation loss: 2.595837671496879

Epoch: 6| Step: 11
Training loss: 0.7217420827195496
Validation loss: 2.610066465274011

Epoch: 6| Step: 12
Training loss: 0.8566845480342798
Validation loss: 2.6092393994750847

Epoch: 6| Step: 13
Training loss: 0.9242747801744403
Validation loss: 2.6042718963691818

Epoch: 235| Step: 0
Training loss: 0.8068635646325902
Validation loss: 2.604385878329858

Epoch: 6| Step: 1
Training loss: 1.3641328529139565
Validation loss: 2.6374565503899423

Epoch: 6| Step: 2
Training loss: 0.8190364176509908
Validation loss: 2.6457463315483496

Epoch: 6| Step: 3
Training loss: 1.3198971518272447
Validation loss: 2.6589743592343553

Epoch: 6| Step: 4
Training loss: 1.1518416005682737
Validation loss: 2.626712586140129

Epoch: 6| Step: 5
Training loss: 1.1288348640654176
Validation loss: 2.615663421458835

Epoch: 6| Step: 6
Training loss: 1.154529786856939
Validation loss: 2.6109460084525815

Epoch: 6| Step: 7
Training loss: 0.49249162814484754
Validation loss: 2.56832473352843

Epoch: 6| Step: 8
Training loss: 1.0365495625638192
Validation loss: 2.5441151879500783

Epoch: 6| Step: 9
Training loss: 1.4405745094040694
Validation loss: 2.573648093135871

Epoch: 6| Step: 10
Training loss: 1.0102697770359523
Validation loss: 2.578931607837229

Epoch: 6| Step: 11
Training loss: 0.6529429533372768
Validation loss: 2.592822957286799

Epoch: 6| Step: 12
Training loss: 0.8780337601907623
Validation loss: 2.6225485305051905

Epoch: 6| Step: 13
Training loss: 0.5774422299608059
Validation loss: 2.656628055197999

Epoch: 236| Step: 0
Training loss: 0.8352679128909699
Validation loss: 2.6473590691442883

Epoch: 6| Step: 1
Training loss: 1.168519569569356
Validation loss: 2.648516410677877

Epoch: 6| Step: 2
Training loss: 1.0661894749124963
Validation loss: 2.66729891367886

Epoch: 6| Step: 3
Training loss: 0.9504063088737477
Validation loss: 2.651513610783995

Epoch: 6| Step: 4
Training loss: 1.1343511195335794
Validation loss: 2.6247793848136682

Epoch: 6| Step: 5
Training loss: 0.505173737694917
Validation loss: 2.641815851950377

Epoch: 6| Step: 6
Training loss: 1.0315399918156183
Validation loss: 2.5908614935682173

Epoch: 6| Step: 7
Training loss: 0.6372232603147625
Validation loss: 2.608040405271979

Epoch: 6| Step: 8
Training loss: 1.595004317418297
Validation loss: 2.648374727539588

Epoch: 6| Step: 9
Training loss: 1.0681397597630746
Validation loss: 2.6361566863470336

Epoch: 6| Step: 10
Training loss: 0.7513900432080303
Validation loss: 2.6725271364989966

Epoch: 6| Step: 11
Training loss: 0.9705392250140922
Validation loss: 2.7209573925833523

Epoch: 6| Step: 12
Training loss: 1.2117544064419044
Validation loss: 2.699694156073531

Epoch: 6| Step: 13
Training loss: 1.1185092176757574
Validation loss: 2.7209890930982503

Epoch: 237| Step: 0
Training loss: 0.6589713438472079
Validation loss: 2.7071419877769074

Epoch: 6| Step: 1
Training loss: 0.9564374677614078
Validation loss: 2.714500814352538

Epoch: 6| Step: 2
Training loss: 1.0646091171894754
Validation loss: 2.634238305582335

Epoch: 6| Step: 3
Training loss: 1.1488944980368405
Validation loss: 2.6098049399838543

Epoch: 6| Step: 4
Training loss: 0.7152878262658636
Validation loss: 2.5865425066596512

Epoch: 6| Step: 5
Training loss: 0.8205695339961634
Validation loss: 2.5953740633318434

Epoch: 6| Step: 6
Training loss: 0.8165083460874722
Validation loss: 2.585572637371789

Epoch: 6| Step: 7
Training loss: 1.5033257491152345
Validation loss: 2.5920543423302025

Epoch: 6| Step: 8
Training loss: 1.284315582163279
Validation loss: 2.6375025140287387

Epoch: 6| Step: 9
Training loss: 1.1514156418716395
Validation loss: 2.6716169304510333

Epoch: 6| Step: 10
Training loss: 1.3094123215921396
Validation loss: 2.7336603686973144

Epoch: 6| Step: 11
Training loss: 0.9750157428350812
Validation loss: 2.7308146498404904

Epoch: 6| Step: 12
Training loss: 1.1306449410117652
Validation loss: 2.7331431343189108

Epoch: 6| Step: 13
Training loss: 1.0780891744217502
Validation loss: 2.724942703901603

Epoch: 238| Step: 0
Training loss: 0.857020812201423
Validation loss: 2.7061767214291326

Epoch: 6| Step: 1
Training loss: 0.6697746760189401
Validation loss: 2.6992464470899997

Epoch: 6| Step: 2
Training loss: 0.7883250501276827
Validation loss: 2.7111181482843154

Epoch: 6| Step: 3
Training loss: 1.0935699859710002
Validation loss: 2.6772801402820856

Epoch: 6| Step: 4
Training loss: 0.8819100822970226
Validation loss: 2.683208063322864

Epoch: 6| Step: 5
Training loss: 1.007624763923166
Validation loss: 2.6851467390384065

Epoch: 6| Step: 6
Training loss: 1.8935868573812884
Validation loss: 2.650391079132747

Epoch: 6| Step: 7
Training loss: 0.9186711322902426
Validation loss: 2.619572201517936

Epoch: 6| Step: 8
Training loss: 1.0800452891320034
Validation loss: 2.6192225843602177

Epoch: 6| Step: 9
Training loss: 1.1236417836667116
Validation loss: 2.609867618053419

Epoch: 6| Step: 10
Training loss: 1.181290352349091
Validation loss: 2.598739539517811

Epoch: 6| Step: 11
Training loss: 0.9762717462674619
Validation loss: 2.599627617979953

Epoch: 6| Step: 12
Training loss: 0.6603165832479938
Validation loss: 2.6309078807196005

Epoch: 6| Step: 13
Training loss: 1.2989522085935112
Validation loss: 2.6370790267788182

Epoch: 239| Step: 0
Training loss: 1.0087504199475026
Validation loss: 2.656808610311883

Epoch: 6| Step: 1
Training loss: 1.0181098471322418
Validation loss: 2.695247830683226

Epoch: 6| Step: 2
Training loss: 0.782737079573426
Validation loss: 2.6716756333117306

Epoch: 6| Step: 3
Training loss: 1.1673216797533645
Validation loss: 2.6901813494379656

Epoch: 6| Step: 4
Training loss: 0.7580563261120523
Validation loss: 2.6707150188237962

Epoch: 6| Step: 5
Training loss: 0.9806911322696785
Validation loss: 2.6491323620615774

Epoch: 6| Step: 6
Training loss: 1.039120837416767
Validation loss: 2.620664938622531

Epoch: 6| Step: 7
Training loss: 0.559083150670959
Validation loss: 2.6117475919797917

Epoch: 6| Step: 8
Training loss: 0.8315037590992473
Validation loss: 2.603751857248205

Epoch: 6| Step: 9
Training loss: 1.7131780298452872
Validation loss: 2.6000915180330075

Epoch: 6| Step: 10
Training loss: 1.1746959049282397
Validation loss: 2.549082787772488

Epoch: 6| Step: 11
Training loss: 1.057468336907402
Validation loss: 2.604488799485688

Epoch: 6| Step: 12
Training loss: 1.0597410284239892
Validation loss: 2.584727941602917

Epoch: 6| Step: 13
Training loss: 0.8241188024874831
Validation loss: 2.61500383038649

Epoch: 240| Step: 0
Training loss: 1.3580102317829108
Validation loss: 2.6130434652760104

Epoch: 6| Step: 1
Training loss: 0.8206348694021182
Validation loss: 2.6009153392421456

Epoch: 6| Step: 2
Training loss: 0.906589937580565
Validation loss: 2.6109298643004197

Epoch: 6| Step: 3
Training loss: 0.7713617927608732
Validation loss: 2.6372160441008132

Epoch: 6| Step: 4
Training loss: 0.9835912824119538
Validation loss: 2.6219395944513293

Epoch: 6| Step: 5
Training loss: 1.508144203819436
Validation loss: 2.5954061953912704

Epoch: 6| Step: 6
Training loss: 1.2275604270465799
Validation loss: 2.6363951752714843

Epoch: 6| Step: 7
Training loss: 0.9170574778427952
Validation loss: 2.60368724684107

Epoch: 6| Step: 8
Training loss: 1.15506689010074
Validation loss: 2.64519449482538

Epoch: 6| Step: 9
Training loss: 0.9116531963038992
Validation loss: 2.6185345002776685

Epoch: 6| Step: 10
Training loss: 0.9719490636344091
Validation loss: 2.627706180692601

Epoch: 6| Step: 11
Training loss: 0.8856591434936917
Validation loss: 2.618051448105894

Epoch: 6| Step: 12
Training loss: 0.5340515206125235
Validation loss: 2.5988796287234663

Epoch: 6| Step: 13
Training loss: 0.7153978961917912
Validation loss: 2.616025507247367

Epoch: 241| Step: 0
Training loss: 0.7506874033758177
Validation loss: 2.6128681556002005

Epoch: 6| Step: 1
Training loss: 1.200198143256553
Validation loss: 2.59374519641252

Epoch: 6| Step: 2
Training loss: 0.7180548499018016
Validation loss: 2.60141344156758

Epoch: 6| Step: 3
Training loss: 1.6504204561144593
Validation loss: 2.616293885222801

Epoch: 6| Step: 4
Training loss: 1.1787802131478173
Validation loss: 2.6042391796886273

Epoch: 6| Step: 5
Training loss: 1.0661505088585606
Validation loss: 2.6323537167859064

Epoch: 6| Step: 6
Training loss: 0.7886801066920818
Validation loss: 2.5978569264739497

Epoch: 6| Step: 7
Training loss: 0.9407574645898639
Validation loss: 2.630513582372901

Epoch: 6| Step: 8
Training loss: 0.6682273631816104
Validation loss: 2.585892629858387

Epoch: 6| Step: 9
Training loss: 0.8826336974971665
Validation loss: 2.6278423579962005

Epoch: 6| Step: 10
Training loss: 0.7346050632556765
Validation loss: 2.5829781146819353

Epoch: 6| Step: 11
Training loss: 0.9138269691561074
Validation loss: 2.634371510906505

Epoch: 6| Step: 12
Training loss: 1.0819096135376718
Validation loss: 2.6315785055127767

Epoch: 6| Step: 13
Training loss: 1.099780000014274
Validation loss: 2.661366803427308

Epoch: 242| Step: 0
Training loss: 0.888476876464037
Validation loss: 2.687434568417073

Epoch: 6| Step: 1
Training loss: 0.8411908014676126
Validation loss: 2.6721091056046204

Epoch: 6| Step: 2
Training loss: 1.0805893527980428
Validation loss: 2.6580231632553404

Epoch: 6| Step: 3
Training loss: 1.2734182625470096
Validation loss: 2.660408080739668

Epoch: 6| Step: 4
Training loss: 1.7690806372999313
Validation loss: 2.6027830429456693

Epoch: 6| Step: 5
Training loss: 0.8647090445130953
Validation loss: 2.6080395377956807

Epoch: 6| Step: 6
Training loss: 0.8269455265638488
Validation loss: 2.5820633326501254

Epoch: 6| Step: 7
Training loss: 0.4757630568660559
Validation loss: 2.5976374513604497

Epoch: 6| Step: 8
Training loss: 0.8813077542473646
Validation loss: 2.5800497308993706

Epoch: 6| Step: 9
Training loss: 0.7865161411353352
Validation loss: 2.604104201685421

Epoch: 6| Step: 10
Training loss: 1.1236267185161968
Validation loss: 2.6243459430679223

Epoch: 6| Step: 11
Training loss: 0.7832600865376675
Validation loss: 2.627906593529214

Epoch: 6| Step: 12
Training loss: 0.9066399688915556
Validation loss: 2.6313497933083387

Epoch: 6| Step: 13
Training loss: 0.6846708694590261
Validation loss: 2.6500849948749177

Epoch: 243| Step: 0
Training loss: 0.5167940931180441
Validation loss: 2.6664809920545722

Epoch: 6| Step: 1
Training loss: 0.8517892168252365
Validation loss: 2.682856390133799

Epoch: 6| Step: 2
Training loss: 0.8166999836048822
Validation loss: 2.6769803707572812

Epoch: 6| Step: 3
Training loss: 1.0580081234784133
Validation loss: 2.6530248549848108

Epoch: 6| Step: 4
Training loss: 0.7116182442643779
Validation loss: 2.624340775428972

Epoch: 6| Step: 5
Training loss: 1.1002062300782536
Validation loss: 2.5904922258754

Epoch: 6| Step: 6
Training loss: 1.725691631817162
Validation loss: 2.578471039550061

Epoch: 6| Step: 7
Training loss: 0.9496532434760298
Validation loss: 2.5578155528985884

Epoch: 6| Step: 8
Training loss: 0.6375374007006169
Validation loss: 2.5734131594609817

Epoch: 6| Step: 9
Training loss: 0.922267054581332
Validation loss: 2.56279099095528

Epoch: 6| Step: 10
Training loss: 0.9675803968751714
Validation loss: 2.602044112654598

Epoch: 6| Step: 11
Training loss: 0.9863051005782626
Validation loss: 2.5836852691025705

Epoch: 6| Step: 12
Training loss: 1.1019921513258897
Validation loss: 2.6180383774839826

Epoch: 6| Step: 13
Training loss: 0.9811458301527315
Validation loss: 2.648270812073514

Epoch: 244| Step: 0
Training loss: 0.7796546286952505
Validation loss: 2.629078495165872

Epoch: 6| Step: 1
Training loss: 0.7615656380946795
Validation loss: 2.6641928083055184

Epoch: 6| Step: 2
Training loss: 1.0472477491276735
Validation loss: 2.6301534082669593

Epoch: 6| Step: 3
Training loss: 1.091457525754075
Validation loss: 2.6444945923961694

Epoch: 6| Step: 4
Training loss: 0.9490195485263238
Validation loss: 2.605786386790907

Epoch: 6| Step: 5
Training loss: 0.7220008558733192
Validation loss: 2.601802941074113

Epoch: 6| Step: 6
Training loss: 1.7479467608377393
Validation loss: 2.589573016882973

Epoch: 6| Step: 7
Training loss: 0.9311951665928189
Validation loss: 2.578954149288431

Epoch: 6| Step: 8
Training loss: 0.7296265831950246
Validation loss: 2.5972820359398017

Epoch: 6| Step: 9
Training loss: 0.8194298491462304
Validation loss: 2.611332923732029

Epoch: 6| Step: 10
Training loss: 0.8887791830816566
Validation loss: 2.6153010306757243

Epoch: 6| Step: 11
Training loss: 0.8957493912750398
Validation loss: 2.598925504222899

Epoch: 6| Step: 12
Training loss: 0.7405135702658006
Validation loss: 2.627451043882213

Epoch: 6| Step: 13
Training loss: 1.232877668198196
Validation loss: 2.611767243148456

Epoch: 245| Step: 0
Training loss: 0.826623238709767
Validation loss: 2.6474449830925963

Epoch: 6| Step: 1
Training loss: 1.1885074558176654
Validation loss: 2.6399119308081773

Epoch: 6| Step: 2
Training loss: 1.2438665594183165
Validation loss: 2.655058015333535

Epoch: 6| Step: 3
Training loss: 1.6068305484138388
Validation loss: 2.6712061096265143

Epoch: 6| Step: 4
Training loss: 1.0045781836950607
Validation loss: 2.6738211258211977

Epoch: 6| Step: 5
Training loss: 0.855322768763321
Validation loss: 2.6821512499544937

Epoch: 6| Step: 6
Training loss: 0.9358245819703938
Validation loss: 2.6406649238047426

Epoch: 6| Step: 7
Training loss: 0.5064796268417684
Validation loss: 2.7083203437689303

Epoch: 6| Step: 8
Training loss: 0.2936477675999517
Validation loss: 2.700750209355136

Epoch: 6| Step: 9
Training loss: 0.841333000373724
Validation loss: 2.6936701491694257

Epoch: 6| Step: 10
Training loss: 1.1386041899205477
Validation loss: 2.667942556805974

Epoch: 6| Step: 11
Training loss: 0.9300148652026944
Validation loss: 2.6410345682314036

Epoch: 6| Step: 12
Training loss: 0.26616183896594253
Validation loss: 2.638647195196275

Epoch: 6| Step: 13
Training loss: 1.0469915979844346
Validation loss: 2.6119774101198336

Epoch: 246| Step: 0
Training loss: 0.6394387869838261
Validation loss: 2.57516215473214

Epoch: 6| Step: 1
Training loss: 1.6527181431174522
Validation loss: 2.5962882957051563

Epoch: 6| Step: 2
Training loss: 1.159269514194798
Validation loss: 2.625272179090861

Epoch: 6| Step: 3
Training loss: 0.9809864394857638
Validation loss: 2.616853435845656

Epoch: 6| Step: 4
Training loss: 0.7516670376409502
Validation loss: 2.615913360378993

Epoch: 6| Step: 5
Training loss: 1.1784065820749696
Validation loss: 2.6301130690370065

Epoch: 6| Step: 6
Training loss: 0.8400441839881987
Validation loss: 2.6575320677988707

Epoch: 6| Step: 7
Training loss: 0.9925066817512731
Validation loss: 2.6652375751405986

Epoch: 6| Step: 8
Training loss: 1.075535414676177
Validation loss: 2.6617975183606357

Epoch: 6| Step: 9
Training loss: 0.6817889120581742
Validation loss: 2.637142268371679

Epoch: 6| Step: 10
Training loss: 0.8217809703109967
Validation loss: 2.6229081601324205

Epoch: 6| Step: 11
Training loss: 0.7867280021964405
Validation loss: 2.643153037799471

Epoch: 6| Step: 12
Training loss: 0.7872041403846676
Validation loss: 2.657786080199434

Epoch: 6| Step: 13
Training loss: 0.5712732035726139
Validation loss: 2.6633098856238164

Epoch: 247| Step: 0
Training loss: 1.0386091117933733
Validation loss: 2.657622679607414

Epoch: 6| Step: 1
Training loss: 0.806323342351162
Validation loss: 2.6285557354977898

Epoch: 6| Step: 2
Training loss: 0.873236718754718
Validation loss: 2.6294350872236407

Epoch: 6| Step: 3
Training loss: 1.1064037237743234
Validation loss: 2.663519949164798

Epoch: 6| Step: 4
Training loss: 0.8651543918263792
Validation loss: 2.6440870978680793

Epoch: 6| Step: 5
Training loss: 0.6797062662975926
Validation loss: 2.6752966422578153

Epoch: 6| Step: 6
Training loss: 0.9411059015215679
Validation loss: 2.6789855659537376

Epoch: 6| Step: 7
Training loss: 1.5359911795750325
Validation loss: 2.6649588229211916

Epoch: 6| Step: 8
Training loss: 1.096062150908921
Validation loss: 2.6362351122640626

Epoch: 6| Step: 9
Training loss: 0.6329336168213948
Validation loss: 2.662293469375236

Epoch: 6| Step: 10
Training loss: 0.7870790840170194
Validation loss: 2.6563655666471275

Epoch: 6| Step: 11
Training loss: 0.9265808965648255
Validation loss: 2.6625020754071054

Epoch: 6| Step: 12
Training loss: 0.721836676963379
Validation loss: 2.6702240662028545

Epoch: 6| Step: 13
Training loss: 0.8805300822385804
Validation loss: 2.6968573034805705

Epoch: 248| Step: 0
Training loss: 0.9978563160390146
Validation loss: 2.7078252241579377

Epoch: 6| Step: 1
Training loss: 0.6896781662178462
Validation loss: 2.7066754671088407

Epoch: 6| Step: 2
Training loss: 1.530723247622632
Validation loss: 2.7031081340964733

Epoch: 6| Step: 3
Training loss: 1.059563899570167
Validation loss: 2.705634301121342

Epoch: 6| Step: 4
Training loss: 0.7277051083325569
Validation loss: 2.6733287576065425

Epoch: 6| Step: 5
Training loss: 0.8152736857230499
Validation loss: 2.687390950292537

Epoch: 6| Step: 6
Training loss: 0.6779812409920015
Validation loss: 2.6674065934905578

Epoch: 6| Step: 7
Training loss: 1.028678462158862
Validation loss: 2.6774561674149964

Epoch: 6| Step: 8
Training loss: 0.6641630208845919
Validation loss: 2.656277952101431

Epoch: 6| Step: 9
Training loss: 1.1001505900387611
Validation loss: 2.6716940779648084

Epoch: 6| Step: 10
Training loss: 0.7237520312740303
Validation loss: 2.688214412437344

Epoch: 6| Step: 11
Training loss: 0.9734253504501603
Validation loss: 2.653601872675986

Epoch: 6| Step: 12
Training loss: 0.7270366803115457
Validation loss: 2.665221360667994

Epoch: 6| Step: 13
Training loss: 0.9804991151279501
Validation loss: 2.707235151204296

Epoch: 249| Step: 0
Training loss: 0.7374273943318154
Validation loss: 2.6696897103718054

Epoch: 6| Step: 1
Training loss: 1.1905642676696038
Validation loss: 2.6931761543138877

Epoch: 6| Step: 2
Training loss: 0.9623674437660655
Validation loss: 2.6519076656249907

Epoch: 6| Step: 3
Training loss: 0.482650085093705
Validation loss: 2.635413606671002

Epoch: 6| Step: 4
Training loss: 1.0943863243854763
Validation loss: 2.6231173509204115

Epoch: 6| Step: 5
Training loss: 0.9815734475978732
Validation loss: 2.6236734363722056

Epoch: 6| Step: 6
Training loss: 0.8561808787938558
Validation loss: 2.5929819989573533

Epoch: 6| Step: 7
Training loss: 0.8499778912978798
Validation loss: 2.5947289159615603

Epoch: 6| Step: 8
Training loss: 0.6218228169692576
Validation loss: 2.6161137133458183

Epoch: 6| Step: 9
Training loss: 0.5610423274366263
Validation loss: 2.635628318499437

Epoch: 6| Step: 10
Training loss: 1.0273270406198174
Validation loss: 2.6474348541824524

Epoch: 6| Step: 11
Training loss: 0.3052322091386285
Validation loss: 2.6729424577565193

Epoch: 6| Step: 12
Training loss: 1.6493172128722715
Validation loss: 2.698836220528769

Epoch: 6| Step: 13
Training loss: 0.8222343094541572
Validation loss: 2.6869875358968627

Epoch: 250| Step: 0
Training loss: 0.8303996820877363
Validation loss: 2.7123406608156406

Epoch: 6| Step: 1
Training loss: 0.8821299792464483
Validation loss: 2.724801312244262

Epoch: 6| Step: 2
Training loss: 0.8768287689463847
Validation loss: 2.7310706949515007

Epoch: 6| Step: 3
Training loss: 0.8285538624559797
Validation loss: 2.711254569790042

Epoch: 6| Step: 4
Training loss: 0.5997051696798146
Validation loss: 2.7040683177519558

Epoch: 6| Step: 5
Training loss: 1.600822017033282
Validation loss: 2.681935100867297

Epoch: 6| Step: 6
Training loss: 0.8111536535409691
Validation loss: 2.642757682913969

Epoch: 6| Step: 7
Training loss: 0.8524844926671009
Validation loss: 2.612784324961607

Epoch: 6| Step: 8
Training loss: 0.7288415093000061
Validation loss: 2.645848707703976

Epoch: 6| Step: 9
Training loss: 0.9387384182333645
Validation loss: 2.6483031619446487

Epoch: 6| Step: 10
Training loss: 0.7954514822343577
Validation loss: 2.6723213851971397

Epoch: 6| Step: 11
Training loss: 1.0585606418513804
Validation loss: 2.6628133527496924

Epoch: 6| Step: 12
Training loss: 0.8324252704495618
Validation loss: 2.6857967736400545

Epoch: 6| Step: 13
Training loss: 1.0074338571309958
Validation loss: 2.697394433843181

Epoch: 251| Step: 0
Training loss: 1.0948295170525897
Validation loss: 2.6809289398639438

Epoch: 6| Step: 1
Training loss: 0.5875015745750591
Validation loss: 2.6423773521681806

Epoch: 6| Step: 2
Training loss: 0.9379631805635851
Validation loss: 2.6550184779019235

Epoch: 6| Step: 3
Training loss: 0.8149816321427008
Validation loss: 2.628063387193263

Epoch: 6| Step: 4
Training loss: 1.0799186823395563
Validation loss: 2.6334134030763297

Epoch: 6| Step: 5
Training loss: 0.8463777313864413
Validation loss: 2.600960318855058

Epoch: 6| Step: 6
Training loss: 0.7729095815109335
Validation loss: 2.583841979026884

Epoch: 6| Step: 7
Training loss: 0.7125908626375277
Validation loss: 2.5918698583909703

Epoch: 6| Step: 8
Training loss: 0.6377033507700692
Validation loss: 2.6131802070367924

Epoch: 6| Step: 9
Training loss: 1.0244202299996064
Validation loss: 2.6113674315391817

Epoch: 6| Step: 10
Training loss: 0.6616952777108897
Validation loss: 2.643258157802776

Epoch: 6| Step: 11
Training loss: 1.5775569988901557
Validation loss: 2.6580717350836065

Epoch: 6| Step: 12
Training loss: 0.7323971349988285
Validation loss: 2.6693316769912503

Epoch: 6| Step: 13
Training loss: 0.9786971603395234
Validation loss: 2.693022814666813

Epoch: 252| Step: 0
Training loss: 0.6835798207634985
Validation loss: 2.660572181329681

Epoch: 6| Step: 1
Training loss: 0.9280149015636058
Validation loss: 2.652418587496761

Epoch: 6| Step: 2
Training loss: 1.0391229597585825
Validation loss: 2.6834187225832125

Epoch: 6| Step: 3
Training loss: 0.9188094165299536
Validation loss: 2.6585284851153164

Epoch: 6| Step: 4
Training loss: 1.6357628117869567
Validation loss: 2.662732595517065

Epoch: 6| Step: 5
Training loss: 0.5924947922715152
Validation loss: 2.6327479479241744

Epoch: 6| Step: 6
Training loss: 0.7515149710173498
Validation loss: 2.6607640139395046

Epoch: 6| Step: 7
Training loss: 0.8328649794198888
Validation loss: 2.6367740004572005

Epoch: 6| Step: 8
Training loss: 0.9922229129749223
Validation loss: 2.6410640442095135

Epoch: 6| Step: 9
Training loss: 0.9457167714649768
Validation loss: 2.6401356627593278

Epoch: 6| Step: 10
Training loss: 0.66510253692961
Validation loss: 2.6386775401880973

Epoch: 6| Step: 11
Training loss: 0.6598914704533615
Validation loss: 2.6475097587838086

Epoch: 6| Step: 12
Training loss: 0.7946365181683855
Validation loss: 2.652627246228492

Epoch: 6| Step: 13
Training loss: 0.5931301897342456
Validation loss: 2.6273505014660157

Epoch: 253| Step: 0
Training loss: 1.007275993017462
Validation loss: 2.6516293393848156

Epoch: 6| Step: 1
Training loss: 0.6794894795968269
Validation loss: 2.673586011801722

Epoch: 6| Step: 2
Training loss: 0.8882611677572007
Validation loss: 2.6836600193892135

Epoch: 6| Step: 3
Training loss: 0.663086094807085
Validation loss: 2.6432535615420973

Epoch: 6| Step: 4
Training loss: 0.8313754367118885
Validation loss: 2.642054734380995

Epoch: 6| Step: 5
Training loss: 0.7933144027457534
Validation loss: 2.6584429264639198

Epoch: 6| Step: 6
Training loss: 1.0665276426872239
Validation loss: 2.6584208526487596

Epoch: 6| Step: 7
Training loss: 1.2030791236751122
Validation loss: 2.6411930868019327

Epoch: 6| Step: 8
Training loss: 0.38894762388475274
Validation loss: 2.664977445852709

Epoch: 6| Step: 9
Training loss: 0.5406355090580713
Validation loss: 2.6685482399888882

Epoch: 6| Step: 10
Training loss: 1.6141616598802286
Validation loss: 2.7226026199634776

Epoch: 6| Step: 11
Training loss: 0.6730132995130268
Validation loss: 2.6884215058790675

Epoch: 6| Step: 12
Training loss: 0.7879349612393847
Validation loss: 2.7690371957814954

Epoch: 6| Step: 13
Training loss: 0.8384728176371866
Validation loss: 2.7456466657912313

Epoch: 254| Step: 0
Training loss: 0.33760208422708987
Validation loss: 2.7318455992348194

Epoch: 6| Step: 1
Training loss: 0.6844524331030012
Validation loss: 2.73225154057139

Epoch: 6| Step: 2
Training loss: 0.9020968012578926
Validation loss: 2.6909205786735266

Epoch: 6| Step: 3
Training loss: 1.5779666632356981
Validation loss: 2.6376366552337127

Epoch: 6| Step: 4
Training loss: 0.8310249224665642
Validation loss: 2.644681686848617

Epoch: 6| Step: 5
Training loss: 0.591916390112776
Validation loss: 2.6788645212169766

Epoch: 6| Step: 6
Training loss: 0.6946775130061545
Validation loss: 2.669333740421518

Epoch: 6| Step: 7
Training loss: 0.8605545964805863
Validation loss: 2.6465990778259187

Epoch: 6| Step: 8
Training loss: 0.8664127015956291
Validation loss: 2.643184832961849

Epoch: 6| Step: 9
Training loss: 1.2122303613734662
Validation loss: 2.666198697739035

Epoch: 6| Step: 10
Training loss: 0.9386599676080999
Validation loss: 2.6721385765115566

Epoch: 6| Step: 11
Training loss: 0.9472683936009798
Validation loss: 2.693307011050881

Epoch: 6| Step: 12
Training loss: 0.9020588082260657
Validation loss: 2.6828534460399

Epoch: 6| Step: 13
Training loss: 0.5888375042318547
Validation loss: 2.642960434730386

Epoch: 255| Step: 0
Training loss: 0.7822620702868681
Validation loss: 2.706357064192413

Epoch: 6| Step: 1
Training loss: 0.6730105540282671
Validation loss: 2.6452985524595447

Epoch: 6| Step: 2
Training loss: 0.5036247413371376
Validation loss: 2.6193540634090677

Epoch: 6| Step: 3
Training loss: 0.6650880859948276
Validation loss: 2.627108633788661

Epoch: 6| Step: 4
Training loss: 0.7379541227404264
Validation loss: 2.629888407913424

Epoch: 6| Step: 5
Training loss: 0.9557839498314947
Validation loss: 2.5894379020696903

Epoch: 6| Step: 6
Training loss: 0.9977937739497046
Validation loss: 2.6348236076874563

Epoch: 6| Step: 7
Training loss: 0.9123848411320942
Validation loss: 2.6125227567475755

Epoch: 6| Step: 8
Training loss: 1.763702831651422
Validation loss: 2.6541124906255753

Epoch: 6| Step: 9
Training loss: 0.7216440070678976
Validation loss: 2.6575074300207855

Epoch: 6| Step: 10
Training loss: 0.7487757545588896
Validation loss: 2.6600156321078967

Epoch: 6| Step: 11
Training loss: 0.698176945125837
Validation loss: 2.6667253701865246

Epoch: 6| Step: 12
Training loss: 0.7848274719263513
Validation loss: 2.6888317033921503

Epoch: 6| Step: 13
Training loss: 0.919380239112599
Validation loss: 2.7192721225615353

Epoch: 256| Step: 0
Training loss: 0.9313574146560701
Validation loss: 2.6907974555488514

Epoch: 6| Step: 1
Training loss: 1.573802126141633
Validation loss: 2.670677071472286

Epoch: 6| Step: 2
Training loss: 0.6390317550389303
Validation loss: 2.6771640917828763

Epoch: 6| Step: 3
Training loss: 0.7218057937805997
Validation loss: 2.6385582344510485

Epoch: 6| Step: 4
Training loss: 1.0953013725640641
Validation loss: 2.64021362238078

Epoch: 6| Step: 5
Training loss: 0.9239757008660255
Validation loss: 2.6288580930361567

Epoch: 6| Step: 6
Training loss: 0.8348531374581144
Validation loss: 2.583843221238029

Epoch: 6| Step: 7
Training loss: 0.9462657882300511
Validation loss: 2.6085681430467997

Epoch: 6| Step: 8
Training loss: 0.7869320047226207
Validation loss: 2.5969437167136027

Epoch: 6| Step: 9
Training loss: 0.8512402896075189
Validation loss: 2.616449884490588

Epoch: 6| Step: 10
Training loss: 0.44073665097123293
Validation loss: 2.623793308522229

Epoch: 6| Step: 11
Training loss: 0.6685631321589076
Validation loss: 2.645680941462121

Epoch: 6| Step: 12
Training loss: 0.5335648256563762
Validation loss: 2.6549761927556386

Epoch: 6| Step: 13
Training loss: 0.7692805235159222
Validation loss: 2.630688463605129

Epoch: 257| Step: 0
Training loss: 0.7364055481536455
Validation loss: 2.648472856285666

Epoch: 6| Step: 1
Training loss: 0.8155339522716953
Validation loss: 2.5980640052798307

Epoch: 6| Step: 2
Training loss: 0.9150050919292079
Validation loss: 2.5935571754281974

Epoch: 6| Step: 3
Training loss: 0.7569176808174437
Validation loss: 2.5970817197647644

Epoch: 6| Step: 4
Training loss: 0.7990902048737724
Validation loss: 2.578394127325838

Epoch: 6| Step: 5
Training loss: 0.6806248088447575
Validation loss: 2.5995729941770285

Epoch: 6| Step: 6
Training loss: 1.050936549172381
Validation loss: 2.5765821656411827

Epoch: 6| Step: 7
Training loss: 0.8412786955565986
Validation loss: 2.602818420546122

Epoch: 6| Step: 8
Training loss: 0.5045341305903016
Validation loss: 2.6320360183496088

Epoch: 6| Step: 9
Training loss: 1.6089385098122717
Validation loss: 2.6702164728840496

Epoch: 6| Step: 10
Training loss: 0.940577541941051
Validation loss: 2.6863482669526357

Epoch: 6| Step: 11
Training loss: 0.6545803082463203
Validation loss: 2.6818761321898803

Epoch: 6| Step: 12
Training loss: 0.7887812198076551
Validation loss: 2.687303507290295

Epoch: 6| Step: 13
Training loss: 0.6559587240942664
Validation loss: 2.7099915425291567

Epoch: 258| Step: 0
Training loss: 0.49663916215115594
Validation loss: 2.64031928614846

Epoch: 6| Step: 1
Training loss: 0.8156839853640254
Validation loss: 2.644745180906898

Epoch: 6| Step: 2
Training loss: 0.46414320915002344
Validation loss: 2.6311984198145537

Epoch: 6| Step: 3
Training loss: 0.8751426989135023
Validation loss: 2.6033953509273497

Epoch: 6| Step: 4
Training loss: 0.9547128427391477
Validation loss: 2.610673946713935

Epoch: 6| Step: 5
Training loss: 1.0302684621103206
Validation loss: 2.5865035959667746

Epoch: 6| Step: 6
Training loss: 0.7947790968981324
Validation loss: 2.589304299002194

Epoch: 6| Step: 7
Training loss: 1.547176216159849
Validation loss: 2.6247868780997687

Epoch: 6| Step: 8
Training loss: 0.48328848464933
Validation loss: 2.6383407167702395

Epoch: 6| Step: 9
Training loss: 0.6602478866629992
Validation loss: 2.706445779903764

Epoch: 6| Step: 10
Training loss: 0.9018231496095517
Validation loss: 2.6881731367929347

Epoch: 6| Step: 11
Training loss: 0.7954220709426462
Validation loss: 2.66366618274114

Epoch: 6| Step: 12
Training loss: 0.8956648128416039
Validation loss: 2.6820095103014343

Epoch: 6| Step: 13
Training loss: 1.1745622468760433
Validation loss: 2.662202565870232

Epoch: 259| Step: 0
Training loss: 0.6499037423752911
Validation loss: 2.662113951224382

Epoch: 6| Step: 1
Training loss: 0.565946853071722
Validation loss: 2.646393651125808

Epoch: 6| Step: 2
Training loss: 0.8149409674111311
Validation loss: 2.6489925893607142

Epoch: 6| Step: 3
Training loss: 0.7913691731360292
Validation loss: 2.666192819875359

Epoch: 6| Step: 4
Training loss: 0.18436976037419914
Validation loss: 2.6866183178511966

Epoch: 6| Step: 5
Training loss: 0.9599554735030154
Validation loss: 2.669940347131487

Epoch: 6| Step: 6
Training loss: 1.0119847717496415
Validation loss: 2.7261743292432286

Epoch: 6| Step: 7
Training loss: 0.9709879958002989
Validation loss: 2.712466089452448

Epoch: 6| Step: 8
Training loss: 0.44354224109866297
Validation loss: 2.731025258012132

Epoch: 6| Step: 9
Training loss: 0.6746942675464452
Validation loss: 2.719996273121461

Epoch: 6| Step: 10
Training loss: 0.736322984753382
Validation loss: 2.6927967459663757

Epoch: 6| Step: 11
Training loss: 1.6884800925805348
Validation loss: 2.6604093941627287

Epoch: 6| Step: 12
Training loss: 0.9435829229439594
Validation loss: 2.6565390403655096

Epoch: 6| Step: 13
Training loss: 0.6699064825753094
Validation loss: 2.6635621217750898

Epoch: 260| Step: 0
Training loss: 0.6291004141815136
Validation loss: 2.6513896371842844

Epoch: 6| Step: 1
Training loss: 0.8070372190744018
Validation loss: 2.6689750133300056

Epoch: 6| Step: 2
Training loss: 0.40254387924370183
Validation loss: 2.6451159250619654

Epoch: 6| Step: 3
Training loss: 0.7518370303414953
Validation loss: 2.632305439309179

Epoch: 6| Step: 4
Training loss: 0.759467961464952
Validation loss: 2.66765541991292

Epoch: 6| Step: 5
Training loss: 0.9882285364137665
Validation loss: 2.6457061627203537

Epoch: 6| Step: 6
Training loss: 1.1416298607418158
Validation loss: 2.6858028310027287

Epoch: 6| Step: 7
Training loss: 0.89079186064338
Validation loss: 2.687541212532383

Epoch: 6| Step: 8
Training loss: 0.5627720228060773
Validation loss: 2.6510536977998322

Epoch: 6| Step: 9
Training loss: 0.338416555712908
Validation loss: 2.651494855580656

Epoch: 6| Step: 10
Training loss: 0.7242428657277796
Validation loss: 2.664738724047458

Epoch: 6| Step: 11
Training loss: 0.9047454973516184
Validation loss: 2.64278220986529

Epoch: 6| Step: 12
Training loss: 1.626702590464931
Validation loss: 2.654954672377956

Epoch: 6| Step: 13
Training loss: 0.562988784141349
Validation loss: 2.651771388085508

Epoch: 261| Step: 0
Training loss: 0.5781356707438735
Validation loss: 2.674367831152876

Epoch: 6| Step: 1
Training loss: 0.9442532492317368
Validation loss: 2.651079057962907

Epoch: 6| Step: 2
Training loss: 0.7492174993828766
Validation loss: 2.642200102872182

Epoch: 6| Step: 3
Training loss: 0.8368723268017513
Validation loss: 2.688073208027696

Epoch: 6| Step: 4
Training loss: 0.6403575199250093
Validation loss: 2.654708494153495

Epoch: 6| Step: 5
Training loss: 1.530687111917937
Validation loss: 2.6642943390155214

Epoch: 6| Step: 6
Training loss: 0.7094730343066138
Validation loss: 2.6798820337695584

Epoch: 6| Step: 7
Training loss: 0.925854000017689
Validation loss: 2.6240808368986177

Epoch: 6| Step: 8
Training loss: 0.6163847809547186
Validation loss: 2.619923786788572

Epoch: 6| Step: 9
Training loss: 0.8872870418096352
Validation loss: 2.659298490328881

Epoch: 6| Step: 10
Training loss: 0.6118562020209051
Validation loss: 2.626216883730947

Epoch: 6| Step: 11
Training loss: 1.1030982384393837
Validation loss: 2.6141327546244626

Epoch: 6| Step: 12
Training loss: 0.7596496650441469
Validation loss: 2.6206065756540347

Epoch: 6| Step: 13
Training loss: 0.3562094129899344
Validation loss: 2.619247002830349

Epoch: 262| Step: 0
Training loss: 0.7095938760807146
Validation loss: 2.64090500000183

Epoch: 6| Step: 1
Training loss: 0.545794127296271
Validation loss: 2.643420644400075

Epoch: 6| Step: 2
Training loss: 0.993473271160608
Validation loss: 2.6413377427473805

Epoch: 6| Step: 3
Training loss: 1.0914340977539552
Validation loss: 2.682260578635237

Epoch: 6| Step: 4
Training loss: 0.7066026094331777
Validation loss: 2.6710088266531278

Epoch: 6| Step: 5
Training loss: 0.9519531362703406
Validation loss: 2.657057313367637

Epoch: 6| Step: 6
Training loss: 0.6011345319446323
Validation loss: 2.6437830255554218

Epoch: 6| Step: 7
Training loss: 0.9418221975408632
Validation loss: 2.643969020393253

Epoch: 6| Step: 8
Training loss: 0.5702232395500675
Validation loss: 2.6540283027649343

Epoch: 6| Step: 9
Training loss: 0.5450798817371579
Validation loss: 2.6685350766178466

Epoch: 6| Step: 10
Training loss: 1.532040139133123
Validation loss: 2.7083511888342975

Epoch: 6| Step: 11
Training loss: 0.7792552659631181
Validation loss: 2.6825556525502634

Epoch: 6| Step: 12
Training loss: 0.7101270646580793
Validation loss: 2.6628882753253333

Epoch: 6| Step: 13
Training loss: 0.6345740865616889
Validation loss: 2.6670588617045623

Epoch: 263| Step: 0
Training loss: 1.5944158621665554
Validation loss: 2.645857189698462

Epoch: 6| Step: 1
Training loss: 0.7276299541457426
Validation loss: 2.632475019644032

Epoch: 6| Step: 2
Training loss: 0.598240037416685
Validation loss: 2.6615127863897383

Epoch: 6| Step: 3
Training loss: 0.7025148711548029
Validation loss: 2.6484667541996485

Epoch: 6| Step: 4
Training loss: 0.7509007210997674
Validation loss: 2.6703105357699246

Epoch: 6| Step: 5
Training loss: 0.8924044517319705
Validation loss: 2.6624347565347706

Epoch: 6| Step: 6
Training loss: 0.7144590916705129
Validation loss: 2.6551267455476175

Epoch: 6| Step: 7
Training loss: 0.9891027421282514
Validation loss: 2.7114322422851984

Epoch: 6| Step: 8
Training loss: 1.0173428019907498
Validation loss: 2.743656149984018

Epoch: 6| Step: 9
Training loss: 0.7511113595217546
Validation loss: 2.764102379227225

Epoch: 6| Step: 10
Training loss: 0.7980970100865905
Validation loss: 2.7389760992365084

Epoch: 6| Step: 11
Training loss: 0.6172765112321167
Validation loss: 2.7627516198777258

Epoch: 6| Step: 12
Training loss: 0.7211637601415491
Validation loss: 2.7208769694542503

Epoch: 6| Step: 13
Training loss: 0.6152336726108962
Validation loss: 2.6993352692333374

Epoch: 264| Step: 0
Training loss: 0.6139305710726293
Validation loss: 2.691985627752733

Epoch: 6| Step: 1
Training loss: 0.38821411012862894
Validation loss: 2.6996670352442496

Epoch: 6| Step: 2
Training loss: 0.7964732709543724
Validation loss: 2.7061070842472694

Epoch: 6| Step: 3
Training loss: 0.8181790902111544
Validation loss: 2.662362618478817

Epoch: 6| Step: 4
Training loss: 0.9515666103430859
Validation loss: 2.6575655435556067

Epoch: 6| Step: 5
Training loss: 0.623521486519355
Validation loss: 2.651228874764322

Epoch: 6| Step: 6
Training loss: 0.6917553898388018
Validation loss: 2.6841829065809737

Epoch: 6| Step: 7
Training loss: 0.5332616417602577
Validation loss: 2.6593067645761774

Epoch: 6| Step: 8
Training loss: 0.6044635920008462
Validation loss: 2.6696196198208475

Epoch: 6| Step: 9
Training loss: 1.1736112321230332
Validation loss: 2.6646877102858935

Epoch: 6| Step: 10
Training loss: 0.7465422715152704
Validation loss: 2.6521647144583467

Epoch: 6| Step: 11
Training loss: 0.678744132787591
Validation loss: 2.6379147969604757

Epoch: 6| Step: 12
Training loss: 1.639463031367125
Validation loss: 2.6897853312190043

Epoch: 6| Step: 13
Training loss: 0.7344930026433246
Validation loss: 2.632305466578787

Epoch: 265| Step: 0
Training loss: 0.5566935731567892
Validation loss: 2.6738297098799984

Epoch: 6| Step: 1
Training loss: 0.6928802554147856
Validation loss: 2.668888999506643

Epoch: 6| Step: 2
Training loss: 1.050905808791357
Validation loss: 2.6952829257982716

Epoch: 6| Step: 3
Training loss: 0.5404320609616521
Validation loss: 2.674779576245989

Epoch: 6| Step: 4
Training loss: 0.9180817879413959
Validation loss: 2.7035348043237324

Epoch: 6| Step: 5
Training loss: 0.8215821748962603
Validation loss: 2.705119060252383

Epoch: 6| Step: 6
Training loss: 0.7343637587315957
Validation loss: 2.693520708539362

Epoch: 6| Step: 7
Training loss: 0.7064823527983705
Validation loss: 2.66871706969238

Epoch: 6| Step: 8
Training loss: 1.6363504582654735
Validation loss: 2.689734012364757

Epoch: 6| Step: 9
Training loss: 0.8102487774268569
Validation loss: 2.6557326226165023

Epoch: 6| Step: 10
Training loss: 0.615905153846762
Validation loss: 2.6410651527312843

Epoch: 6| Step: 11
Training loss: 0.6911370135743276
Validation loss: 2.665746021037287

Epoch: 6| Step: 12
Training loss: 0.47040754352752345
Validation loss: 2.6284418272883054

Epoch: 6| Step: 13
Training loss: 0.7169591735538146
Validation loss: 2.662329850129719

Epoch: 266| Step: 0
Training loss: 0.8344985127558635
Validation loss: 2.6467088309082993

Epoch: 6| Step: 1
Training loss: 1.6760521872004346
Validation loss: 2.6668885764213996

Epoch: 6| Step: 2
Training loss: 0.54422984052513
Validation loss: 2.673608582716564

Epoch: 6| Step: 3
Training loss: 0.7962300551714698
Validation loss: 2.660865357539903

Epoch: 6| Step: 4
Training loss: 0.7733357680490687
Validation loss: 2.7105348647446204

Epoch: 6| Step: 5
Training loss: 0.5991116424287621
Validation loss: 2.6954070367294993

Epoch: 6| Step: 6
Training loss: 0.45290630916846963
Validation loss: 2.6726304205931313

Epoch: 6| Step: 7
Training loss: 0.33610542669012594
Validation loss: 2.662334158280687

Epoch: 6| Step: 8
Training loss: 0.8631906936583114
Validation loss: 2.6440375521235495

Epoch: 6| Step: 9
Training loss: 0.563878436714647
Validation loss: 2.6993064998482024

Epoch: 6| Step: 10
Training loss: 0.8501939888787652
Validation loss: 2.6795033042664804

Epoch: 6| Step: 11
Training loss: 0.5710262639657808
Validation loss: 2.676294540875529

Epoch: 6| Step: 12
Training loss: 1.0158031600797846
Validation loss: 2.686924964682129

Epoch: 6| Step: 13
Training loss: 1.0026528813140716
Validation loss: 2.732293204961644

Epoch: 267| Step: 0
Training loss: 0.571055620540945
Validation loss: 2.668560077552614

Epoch: 6| Step: 1
Training loss: 0.33256761200490004
Validation loss: 2.682574434286622

Epoch: 6| Step: 2
Training loss: 0.5325894020143477
Validation loss: 2.6800417250248927

Epoch: 6| Step: 3
Training loss: 1.0192542156462592
Validation loss: 2.6652232161465435

Epoch: 6| Step: 4
Training loss: 1.0857085940383926
Validation loss: 2.665738877540493

Epoch: 6| Step: 5
Training loss: 0.5426596715518848
Validation loss: 2.6375114223526626

Epoch: 6| Step: 6
Training loss: 0.5724631219338707
Validation loss: 2.656782052827928

Epoch: 6| Step: 7
Training loss: 0.4982357938409334
Validation loss: 2.657151469670557

Epoch: 6| Step: 8
Training loss: 0.5887729449164494
Validation loss: 2.663619056049743

Epoch: 6| Step: 9
Training loss: 0.9482758159547753
Validation loss: 2.6804871040774345

Epoch: 6| Step: 10
Training loss: 0.9205410568285243
Validation loss: 2.693320400776979

Epoch: 6| Step: 11
Training loss: 1.6049252817700572
Validation loss: 2.7150390498094534

Epoch: 6| Step: 12
Training loss: 0.7265743951951754
Validation loss: 2.712572840100154

Epoch: 6| Step: 13
Training loss: 0.46268384475634855
Validation loss: 2.6796497189355883

Epoch: 268| Step: 0
Training loss: 0.6703464286060334
Validation loss: 2.6670409319354826

Epoch: 6| Step: 1
Training loss: 0.5860956105848744
Validation loss: 2.627099820952711

Epoch: 6| Step: 2
Training loss: 0.6078435286812303
Validation loss: 2.6137815855150683

Epoch: 6| Step: 3
Training loss: 0.5595676495287312
Validation loss: 2.5999354503166137

Epoch: 6| Step: 4
Training loss: 0.6260774861358938
Validation loss: 2.6121613611712067

Epoch: 6| Step: 5
Training loss: 0.3473444515569537
Validation loss: 2.638925134236829

Epoch: 6| Step: 6
Training loss: 1.071007662930042
Validation loss: 2.680389280831617

Epoch: 6| Step: 7
Training loss: 0.6278538398556599
Validation loss: 2.6711249083896322

Epoch: 6| Step: 8
Training loss: 0.5652870960337147
Validation loss: 2.678300493623813

Epoch: 6| Step: 9
Training loss: 1.6664874536801395
Validation loss: 2.6383868977207774

Epoch: 6| Step: 10
Training loss: 1.120770450988334
Validation loss: 2.6588693018356317

Epoch: 6| Step: 11
Training loss: 0.8787691814776394
Validation loss: 2.633322464474104

Epoch: 6| Step: 12
Training loss: 0.483295514487927
Validation loss: 2.640890884872252

Epoch: 6| Step: 13
Training loss: 0.7496327852268203
Validation loss: 2.6434829177101715

Epoch: 269| Step: 0
Training loss: 0.44293313396245737
Validation loss: 2.646787343700517

Epoch: 6| Step: 1
Training loss: 0.6617440535246109
Validation loss: 2.6473472520179824

Epoch: 6| Step: 2
Training loss: 1.1219549294053408
Validation loss: 2.6468091493827988

Epoch: 6| Step: 3
Training loss: 0.7378679359869499
Validation loss: 2.660597700326481

Epoch: 6| Step: 4
Training loss: 0.3729588269886143
Validation loss: 2.6792017515790287

Epoch: 6| Step: 5
Training loss: 0.7208318414470545
Validation loss: 2.6898074955221025

Epoch: 6| Step: 6
Training loss: 0.5510406154004786
Validation loss: 2.7038960141767334

Epoch: 6| Step: 7
Training loss: 1.7246370928946502
Validation loss: 2.6553838341885716

Epoch: 6| Step: 8
Training loss: 0.685728174129971
Validation loss: 2.6642078158783646

Epoch: 6| Step: 9
Training loss: 0.5373951654441761
Validation loss: 2.6315612789677054

Epoch: 6| Step: 10
Training loss: 0.7332961903904769
Validation loss: 2.645627445358686

Epoch: 6| Step: 11
Training loss: 0.8975095185755332
Validation loss: 2.684188390711528

Epoch: 6| Step: 12
Training loss: 0.537834316345363
Validation loss: 2.6712883794226356

Epoch: 6| Step: 13
Training loss: 0.7955083160061628
Validation loss: 2.6653924007354726

Epoch: 270| Step: 0
Training loss: 0.5697711831641239
Validation loss: 2.631426167038937

Epoch: 6| Step: 1
Training loss: 0.856683956638466
Validation loss: 2.6552163339301704

Epoch: 6| Step: 2
Training loss: 0.6882299536166497
Validation loss: 2.666264148553448

Epoch: 6| Step: 3
Training loss: 0.47420814414317075
Validation loss: 2.6823371361664674

Epoch: 6| Step: 4
Training loss: 0.759447909022238
Validation loss: 2.6730145941770873

Epoch: 6| Step: 5
Training loss: 0.7831353517352033
Validation loss: 2.7023556802580186

Epoch: 6| Step: 6
Training loss: 0.3501453872554956
Validation loss: 2.732485489079591

Epoch: 6| Step: 7
Training loss: 0.37093811787117564
Validation loss: 2.704603007473426

Epoch: 6| Step: 8
Training loss: 0.6673610666967248
Validation loss: 2.7142143525022586

Epoch: 6| Step: 9
Training loss: 1.6366863384087564
Validation loss: 2.702433417808204

Epoch: 6| Step: 10
Training loss: 0.9911519451156717
Validation loss: 2.660319352355017

Epoch: 6| Step: 11
Training loss: 0.8332333186849282
Validation loss: 2.679682041099152

Epoch: 6| Step: 12
Training loss: 0.806630649458785
Validation loss: 2.6543660720973334

Epoch: 6| Step: 13
Training loss: 0.7117952893971876
Validation loss: 2.6419600555741893

Epoch: 271| Step: 0
Training loss: 0.5612859870740905
Validation loss: 2.66483354403374

Epoch: 6| Step: 1
Training loss: 0.7575711524707816
Validation loss: 2.660559238660802

Epoch: 6| Step: 2
Training loss: 0.6215891751510377
Validation loss: 2.6544630918024654

Epoch: 6| Step: 3
Training loss: 0.8001447055000974
Validation loss: 2.6816658670283795

Epoch: 6| Step: 4
Training loss: 0.8118556475370139
Validation loss: 2.650214935079402

Epoch: 6| Step: 5
Training loss: 0.3192166096731797
Validation loss: 2.6570099961271567

Epoch: 6| Step: 6
Training loss: 0.9435298915630008
Validation loss: 2.6851461680985613

Epoch: 6| Step: 7
Training loss: 0.8356938586399326
Validation loss: 2.6665401800470256

Epoch: 6| Step: 8
Training loss: 0.8211395091219332
Validation loss: 2.6792358258865225

Epoch: 6| Step: 9
Training loss: 0.8814819571757643
Validation loss: 2.6733841125865596

Epoch: 6| Step: 10
Training loss: 1.5948102079975162
Validation loss: 2.677182971671748

Epoch: 6| Step: 11
Training loss: 0.4320402410030373
Validation loss: 2.6908005391024448

Epoch: 6| Step: 12
Training loss: 0.38852658263816214
Validation loss: 2.6797900704498034

Epoch: 6| Step: 13
Training loss: 0.5514213954264843
Validation loss: 2.6865039877115295

Epoch: 272| Step: 0
Training loss: 0.2899481891109794
Validation loss: 2.719714596986164

Epoch: 6| Step: 1
Training loss: 0.9346042415634485
Validation loss: 2.706032052791799

Epoch: 6| Step: 2
Training loss: 0.8124608617305973
Validation loss: 2.685936927071147

Epoch: 6| Step: 3
Training loss: 0.52405938172024
Validation loss: 2.6935887504718408

Epoch: 6| Step: 4
Training loss: 0.6895215051905925
Validation loss: 2.6748088020810887

Epoch: 6| Step: 5
Training loss: 0.6691730640607549
Validation loss: 2.656123141999998

Epoch: 6| Step: 6
Training loss: 0.8389222878599703
Validation loss: 2.612237222264375

Epoch: 6| Step: 7
Training loss: 1.096740014445766
Validation loss: 2.6366969230960753

Epoch: 6| Step: 8
Training loss: 1.5877886712445302
Validation loss: 2.648491092766049

Epoch: 6| Step: 9
Training loss: 0.7017941914319935
Validation loss: 2.618009834967103

Epoch: 6| Step: 10
Training loss: 0.2999111818919886
Validation loss: 2.6564953762462515

Epoch: 6| Step: 11
Training loss: 0.7338971957679044
Validation loss: 2.654730461708885

Epoch: 6| Step: 12
Training loss: 0.6021071111434325
Validation loss: 2.688931813718501

Epoch: 6| Step: 13
Training loss: 0.5230883102585376
Validation loss: 2.6867669534995358

Epoch: 273| Step: 0
Training loss: 0.5932294169607687
Validation loss: 2.7077810842973564

Epoch: 6| Step: 1
Training loss: 1.614089800150484
Validation loss: 2.730891337425718

Epoch: 6| Step: 2
Training loss: 0.7731668403300754
Validation loss: 2.6893918065149873

Epoch: 6| Step: 3
Training loss: 0.6761725290737151
Validation loss: 2.7273643765536217

Epoch: 6| Step: 4
Training loss: 0.918057441485057
Validation loss: 2.702206465708228

Epoch: 6| Step: 5
Training loss: 0.655761627856239
Validation loss: 2.710128657368625

Epoch: 6| Step: 6
Training loss: 0.6235827589870555
Validation loss: 2.6908301258887075

Epoch: 6| Step: 7
Training loss: 0.5016660945779235
Validation loss: 2.696031156170074

Epoch: 6| Step: 8
Training loss: 0.7504425332714011
Validation loss: 2.726423505940206

Epoch: 6| Step: 9
Training loss: 0.8887546039682025
Validation loss: 2.7085087311572207

Epoch: 6| Step: 10
Training loss: 0.42357123188093726
Validation loss: 2.6754288449348103

Epoch: 6| Step: 11
Training loss: 0.8533584834157631
Validation loss: 2.6758443280198274

Epoch: 6| Step: 12
Training loss: 0.3848532175192012
Validation loss: 2.689340868604787

Epoch: 6| Step: 13
Training loss: 0.926719093920847
Validation loss: 2.632357903564551

Epoch: 274| Step: 0
Training loss: 0.7509043724572857
Validation loss: 2.6284155757153926

Epoch: 6| Step: 1
Training loss: 0.7053198149187261
Validation loss: 2.6348788414517914

Epoch: 6| Step: 2
Training loss: 0.8433892573848676
Validation loss: 2.6555559770537975

Epoch: 6| Step: 3
Training loss: 0.6551438727962154
Validation loss: 2.648576255660608

Epoch: 6| Step: 4
Training loss: 0.5383414823055087
Validation loss: 2.6482984069701097

Epoch: 6| Step: 5
Training loss: 0.6471825831294187
Validation loss: 2.667238603549977

Epoch: 6| Step: 6
Training loss: 0.823988281136576
Validation loss: 2.694411625768147

Epoch: 6| Step: 7
Training loss: 0.6923584496606272
Validation loss: 2.682014384255711

Epoch: 6| Step: 8
Training loss: 0.5959035567492282
Validation loss: 2.6832325147968676

Epoch: 6| Step: 9
Training loss: 0.6890005728299842
Validation loss: 2.712729168582898

Epoch: 6| Step: 10
Training loss: 0.8722734887417375
Validation loss: 2.6930031966753276

Epoch: 6| Step: 11
Training loss: 0.6173656785874913
Validation loss: 2.6877696175583017

Epoch: 6| Step: 12
Training loss: 0.6010184118795597
Validation loss: 2.6648164064375734

Epoch: 6| Step: 13
Training loss: 2.0172430833033013
Validation loss: 2.6719367713314677

Epoch: 275| Step: 0
Training loss: 0.4211032661112937
Validation loss: 2.6570285937238487

Epoch: 6| Step: 1
Training loss: 0.5454356188452627
Validation loss: 2.6611654963635467

Epoch: 6| Step: 2
Training loss: 1.1261264671462634
Validation loss: 2.647783005980184

Epoch: 6| Step: 3
Training loss: 0.5142916287591092
Validation loss: 2.679295919544308

Epoch: 6| Step: 4
Training loss: 0.7390507316055636
Validation loss: 2.6800825337940593

Epoch: 6| Step: 5
Training loss: 0.5169747632487541
Validation loss: 2.7046292010782076

Epoch: 6| Step: 6
Training loss: 0.914708716039271
Validation loss: 2.720605953415205

Epoch: 6| Step: 7
Training loss: 0.5601254783275889
Validation loss: 2.7052629778976525

Epoch: 6| Step: 8
Training loss: 0.590678426556419
Validation loss: 2.690359356852779

Epoch: 6| Step: 9
Training loss: 1.0229009721617666
Validation loss: 2.713594315008895

Epoch: 6| Step: 10
Training loss: 0.3009016737206152
Validation loss: 2.715545712273649

Epoch: 6| Step: 11
Training loss: 0.459778670625822
Validation loss: 2.7165002761603043

Epoch: 6| Step: 12
Training loss: 1.5847337786808207
Validation loss: 2.693704862263777

Epoch: 6| Step: 13
Training loss: 0.6863870933007841
Validation loss: 2.685488398029946

Epoch: 276| Step: 0
Training loss: 0.6301026426441817
Validation loss: 2.683561430051323

Epoch: 6| Step: 1
Training loss: 0.7550367664707025
Validation loss: 2.6678916283292007

Epoch: 6| Step: 2
Training loss: 0.4145042294446382
Validation loss: 2.6767010892109093

Epoch: 6| Step: 3
Training loss: 0.7989568256892801
Validation loss: 2.6858824354675304

Epoch: 6| Step: 4
Training loss: 0.8933982503728256
Validation loss: 2.699916386572472

Epoch: 6| Step: 5
Training loss: 0.7827702798327105
Validation loss: 2.6731088146669832

Epoch: 6| Step: 6
Training loss: 0.4697486570876062
Validation loss: 2.6558778920806128

Epoch: 6| Step: 7
Training loss: 1.7534845945553372
Validation loss: 2.691727718629958

Epoch: 6| Step: 8
Training loss: 0.7634918703197249
Validation loss: 2.702189225491082

Epoch: 6| Step: 9
Training loss: 0.6092912909893484
Validation loss: 2.683605927198221

Epoch: 6| Step: 10
Training loss: 0.44136523165895325
Validation loss: 2.671960858693393

Epoch: 6| Step: 11
Training loss: 0.4300182803282593
Validation loss: 2.6406115794740335

Epoch: 6| Step: 12
Training loss: 0.6496524918056801
Validation loss: 2.6552549907790595

Epoch: 6| Step: 13
Training loss: 0.2354072568216876
Validation loss: 2.674217139313609

Epoch: 277| Step: 0
Training loss: 0.6003590473118259
Validation loss: 2.66893295218526

Epoch: 6| Step: 1
Training loss: 0.6028924088342329
Validation loss: 2.6670389152734875

Epoch: 6| Step: 2
Training loss: 0.7157785109405305
Validation loss: 2.7132904262052193

Epoch: 6| Step: 3
Training loss: 0.9118433039426946
Validation loss: 2.7041738508298345

Epoch: 6| Step: 4
Training loss: 0.5216070595203571
Validation loss: 2.672526731692469

Epoch: 6| Step: 5
Training loss: 1.5813933416841766
Validation loss: 2.664199161124745

Epoch: 6| Step: 6
Training loss: 0.587085514763957
Validation loss: 2.676955854514462

Epoch: 6| Step: 7
Training loss: 0.4383186446775943
Validation loss: 2.63414334777673

Epoch: 6| Step: 8
Training loss: 0.6232864015126779
Validation loss: 2.6199847437904347

Epoch: 6| Step: 9
Training loss: 0.9628960104399029
Validation loss: 2.614232123579907

Epoch: 6| Step: 10
Training loss: 0.7890495828005594
Validation loss: 2.5985769533359626

Epoch: 6| Step: 11
Training loss: 0.6615404368430368
Validation loss: 2.610340048269683

Epoch: 6| Step: 12
Training loss: 0.6890778208995086
Validation loss: 2.6444362905006695

Epoch: 6| Step: 13
Training loss: 0.600965004984321
Validation loss: 2.711747056212271

Epoch: 278| Step: 0
Training loss: 1.5875830921444365
Validation loss: 2.741719998874737

Epoch: 6| Step: 1
Training loss: 0.6058143367788683
Validation loss: 2.759364788657281

Epoch: 6| Step: 2
Training loss: 0.9737626183393736
Validation loss: 2.7258825060937837

Epoch: 6| Step: 3
Training loss: 0.8151505592151935
Validation loss: 2.6916350070964965

Epoch: 6| Step: 4
Training loss: 0.4063983609652227
Validation loss: 2.6544125363394615

Epoch: 6| Step: 5
Training loss: 0.9460894646771981
Validation loss: 2.652954599556813

Epoch: 6| Step: 6
Training loss: 0.5859833254378427
Validation loss: 2.686780605772939

Epoch: 6| Step: 7
Training loss: 0.5605830802257215
Validation loss: 2.6274077091412065

Epoch: 6| Step: 8
Training loss: 0.8609618361784179
Validation loss: 2.614224441174788

Epoch: 6| Step: 9
Training loss: 0.757408348934594
Validation loss: 2.622347111101747

Epoch: 6| Step: 10
Training loss: 0.5918627409586887
Validation loss: 2.6668966113120063

Epoch: 6| Step: 11
Training loss: 0.5530847308484304
Validation loss: 2.7132439143625504

Epoch: 6| Step: 12
Training loss: 0.511191526020957
Validation loss: 2.7393529954140545

Epoch: 6| Step: 13
Training loss: 0.46669927877620127
Validation loss: 2.7626222364696664

Epoch: 279| Step: 0
Training loss: 0.99931577281546
Validation loss: 2.7439297626565673

Epoch: 6| Step: 1
Training loss: 0.7301935503701722
Validation loss: 2.7326092293885

Epoch: 6| Step: 2
Training loss: 0.5769881850575048
Validation loss: 2.73255345298369

Epoch: 6| Step: 3
Training loss: 0.7043890928129621
Validation loss: 2.6837497710069638

Epoch: 6| Step: 4
Training loss: 0.634794686459139
Validation loss: 2.656649472276241

Epoch: 6| Step: 5
Training loss: 0.43228749958772195
Validation loss: 2.6151880626267157

Epoch: 6| Step: 6
Training loss: 0.2545103076915898
Validation loss: 2.656092914759711

Epoch: 6| Step: 7
Training loss: 0.6824749756162322
Validation loss: 2.6121900205887565

Epoch: 6| Step: 8
Training loss: 0.7545519420751212
Validation loss: 2.6431097437182056

Epoch: 6| Step: 9
Training loss: 0.5649322799169662
Validation loss: 2.6626165118508456

Epoch: 6| Step: 10
Training loss: 0.665545031619662
Validation loss: 2.696021039586728

Epoch: 6| Step: 11
Training loss: 1.6530592791756593
Validation loss: 2.687645710998857

Epoch: 6| Step: 12
Training loss: 0.9102935687426614
Validation loss: 2.7324004119623755

Epoch: 6| Step: 13
Training loss: 0.2988524084259962
Validation loss: 2.754498440988211

Epoch: 280| Step: 0
Training loss: 0.6082997249655954
Validation loss: 2.7736981863434518

Epoch: 6| Step: 1
Training loss: 0.7600094127072141
Validation loss: 2.764943829622167

Epoch: 6| Step: 2
Training loss: 0.6830134299104254
Validation loss: 2.724784376111202

Epoch: 6| Step: 3
Training loss: 0.5711469685484492
Validation loss: 2.7378521572915653

Epoch: 6| Step: 4
Training loss: 0.5846448244783641
Validation loss: 2.680047980968608

Epoch: 6| Step: 5
Training loss: 0.7318024724634464
Validation loss: 2.6788346046546527

Epoch: 6| Step: 6
Training loss: 0.506669357061563
Validation loss: 2.6521419465471423

Epoch: 6| Step: 7
Training loss: 1.6647732072167292
Validation loss: 2.6670914445916023

Epoch: 6| Step: 8
Training loss: 0.36211437563442184
Validation loss: 2.6543891753841806

Epoch: 6| Step: 9
Training loss: 0.8977415291671517
Validation loss: 2.6639922281948114

Epoch: 6| Step: 10
Training loss: 0.7324498692566755
Validation loss: 2.6943320268626842

Epoch: 6| Step: 11
Training loss: 0.7688463135219048
Validation loss: 2.7104614729744143

Epoch: 6| Step: 12
Training loss: 0.5296948052636797
Validation loss: 2.6866407974096154

Epoch: 6| Step: 13
Training loss: 0.28980330316110364
Validation loss: 2.702161273943376

Epoch: 281| Step: 0
Training loss: 0.6859411426351885
Validation loss: 2.67890355837844

Epoch: 6| Step: 1
Training loss: 0.6513405813019202
Validation loss: 2.6851251769048616

Epoch: 6| Step: 2
Training loss: 0.6294412173882131
Validation loss: 2.655828638695597

Epoch: 6| Step: 3
Training loss: 0.5356360463502283
Validation loss: 2.6774879272087033

Epoch: 6| Step: 4
Training loss: 0.444998965396107
Validation loss: 2.6452568795014804

Epoch: 6| Step: 5
Training loss: 1.6218623166332555
Validation loss: 2.663045940690473

Epoch: 6| Step: 6
Training loss: 0.5343239430804002
Validation loss: 2.660320020170607

Epoch: 6| Step: 7
Training loss: 0.7470405921758804
Validation loss: 2.6786270102434253

Epoch: 6| Step: 8
Training loss: 0.5494942745885835
Validation loss: 2.7257042396198194

Epoch: 6| Step: 9
Training loss: 0.8845059179988946
Validation loss: 2.694906681250318

Epoch: 6| Step: 10
Training loss: 0.551536907434397
Validation loss: 2.6986840783504773

Epoch: 6| Step: 11
Training loss: 1.0170805844138655
Validation loss: 2.71764218253299

Epoch: 6| Step: 12
Training loss: 0.5088145127035822
Validation loss: 2.702122521550141

Epoch: 6| Step: 13
Training loss: 0.1654394529718807
Validation loss: 2.703528928928819

Epoch: 282| Step: 0
Training loss: 0.6196819790715887
Validation loss: 2.6789187857029657

Epoch: 6| Step: 1
Training loss: 0.6276629936116191
Validation loss: 2.6762893748793806

Epoch: 6| Step: 2
Training loss: 0.8460198705652819
Validation loss: 2.684484124148146

Epoch: 6| Step: 3
Training loss: 0.6496765294692364
Validation loss: 2.6672013199281994

Epoch: 6| Step: 4
Training loss: 0.38524454586517637
Validation loss: 2.66519361298164

Epoch: 6| Step: 5
Training loss: 0.5641436404887339
Validation loss: 2.6641088037890737

Epoch: 6| Step: 6
Training loss: 0.4188668771159374
Validation loss: 2.6457087828453485

Epoch: 6| Step: 7
Training loss: 0.7161853478829889
Validation loss: 2.6550405558648076

Epoch: 6| Step: 8
Training loss: 0.8352592069363328
Validation loss: 2.650408224400652

Epoch: 6| Step: 9
Training loss: 1.623271316085207
Validation loss: 2.687180564270605

Epoch: 6| Step: 10
Training loss: 0.39612209512085433
Validation loss: 2.720060165546343

Epoch: 6| Step: 11
Training loss: 0.7528177022219775
Validation loss: 2.7177038795621065

Epoch: 6| Step: 12
Training loss: 0.6856945128832848
Validation loss: 2.6820171772884702

Epoch: 6| Step: 13
Training loss: 0.6942276152551937
Validation loss: 2.713396724454413

Epoch: 283| Step: 0
Training loss: 0.6843101671070927
Validation loss: 2.674682766321624

Epoch: 6| Step: 1
Training loss: 0.702595914354398
Validation loss: 2.6568256813581064

Epoch: 6| Step: 2
Training loss: 0.665260222151821
Validation loss: 2.650479203594793

Epoch: 6| Step: 3
Training loss: 0.8017570690750969
Validation loss: 2.6489439047672647

Epoch: 6| Step: 4
Training loss: 0.7059093024915568
Validation loss: 2.6698815398626143

Epoch: 6| Step: 5
Training loss: 0.4334553334391068
Validation loss: 2.6411092500682405

Epoch: 6| Step: 6
Training loss: 0.4803769403835856
Validation loss: 2.669085721676162

Epoch: 6| Step: 7
Training loss: 0.4387362248684573
Validation loss: 2.65779310810176

Epoch: 6| Step: 8
Training loss: 0.5016727183801792
Validation loss: 2.6320626039347834

Epoch: 6| Step: 9
Training loss: 0.9137383562799488
Validation loss: 2.6729842850905374

Epoch: 6| Step: 10
Training loss: 1.6076358916893472
Validation loss: 2.681092450907933

Epoch: 6| Step: 11
Training loss: 0.5493160807290702
Validation loss: 2.6568535174025065

Epoch: 6| Step: 12
Training loss: 0.6954382879081836
Validation loss: 2.6817124347159864

Epoch: 6| Step: 13
Training loss: 0.646054335179548
Validation loss: 2.7097663627583928

Epoch: 284| Step: 0
Training loss: 0.5010188867488671
Validation loss: 2.711172854630856

Epoch: 6| Step: 1
Training loss: 0.7868964046751478
Validation loss: 2.7199100126681977

Epoch: 6| Step: 2
Training loss: 0.6763058428879568
Validation loss: 2.7161294115112202

Epoch: 6| Step: 3
Training loss: 0.5353611185027481
Validation loss: 2.715444288968856

Epoch: 6| Step: 4
Training loss: 0.7149989892378912
Validation loss: 2.696673899309192

Epoch: 6| Step: 5
Training loss: 0.7487068949727743
Validation loss: 2.6586504248678398

Epoch: 6| Step: 6
Training loss: 1.5482708576657056
Validation loss: 2.6703522425628563

Epoch: 6| Step: 7
Training loss: 0.2720380255936103
Validation loss: 2.6594964356949933

Epoch: 6| Step: 8
Training loss: 0.6961103854776457
Validation loss: 2.668980529669754

Epoch: 6| Step: 9
Training loss: 0.5155027996101911
Validation loss: 2.645819105775882

Epoch: 6| Step: 10
Training loss: 0.790866300828968
Validation loss: 2.7009837712712157

Epoch: 6| Step: 11
Training loss: 0.6464420777282054
Validation loss: 2.6841374132707854

Epoch: 6| Step: 12
Training loss: 0.7405092237414514
Validation loss: 2.685162727691637

Epoch: 6| Step: 13
Training loss: 0.2506094299388649
Validation loss: 2.6713750083925287

Epoch: 285| Step: 0
Training loss: 0.693852724597736
Validation loss: 2.6679370325546232

Epoch: 6| Step: 1
Training loss: 0.5512826950082848
Validation loss: 2.7156911456872272

Epoch: 6| Step: 2
Training loss: 0.7413924526462282
Validation loss: 2.715822730938493

Epoch: 6| Step: 3
Training loss: 0.9719442802831959
Validation loss: 2.7016295588492203

Epoch: 6| Step: 4
Training loss: 0.638626470322558
Validation loss: 2.7128998215773135

Epoch: 6| Step: 5
Training loss: 0.4876283782259149
Validation loss: 2.698949130639711

Epoch: 6| Step: 6
Training loss: 0.5996798247163729
Validation loss: 2.7244913965484727

Epoch: 6| Step: 7
Training loss: 0.6181720895833611
Validation loss: 2.714630489216651

Epoch: 6| Step: 8
Training loss: 0.5670921644896116
Validation loss: 2.64124611607008

Epoch: 6| Step: 9
Training loss: 1.5085880478959106
Validation loss: 2.6636619190923474

Epoch: 6| Step: 10
Training loss: 0.7008666327779689
Validation loss: 2.6461529592386013

Epoch: 6| Step: 11
Training loss: 0.7574584369776514
Validation loss: 2.6431167893056244

Epoch: 6| Step: 12
Training loss: 0.49136917265486396
Validation loss: 2.613164890467115

Epoch: 6| Step: 13
Training loss: 0.4107582216130726
Validation loss: 2.6388227002907283

Epoch: 286| Step: 0
Training loss: 0.7621286707497682
Validation loss: 2.6219584388474844

Epoch: 6| Step: 1
Training loss: 0.6810012923353035
Validation loss: 2.642722053241129

Epoch: 6| Step: 2
Training loss: 0.7774006808342491
Validation loss: 2.6627037031268395

Epoch: 6| Step: 3
Training loss: 0.4538711783800577
Validation loss: 2.637215321829592

Epoch: 6| Step: 4
Training loss: 0.32193987016762565
Validation loss: 2.684736601095593

Epoch: 6| Step: 5
Training loss: 0.7916697117261716
Validation loss: 2.6678741135130997

Epoch: 6| Step: 6
Training loss: 1.6411357992727669
Validation loss: 2.6588472142047843

Epoch: 6| Step: 7
Training loss: 0.559452969961647
Validation loss: 2.660599550357513

Epoch: 6| Step: 8
Training loss: 0.8706854303751743
Validation loss: 2.693803517188035

Epoch: 6| Step: 9
Training loss: 0.59525557418546
Validation loss: 2.7081050849193784

Epoch: 6| Step: 10
Training loss: 0.5143813248960442
Validation loss: 2.698206382175034

Epoch: 6| Step: 11
Training loss: 0.5018944613245174
Validation loss: 2.6951601998088535

Epoch: 6| Step: 12
Training loss: 0.48298596596123367
Validation loss: 2.734851873626813

Epoch: 6| Step: 13
Training loss: 0.714974146555608
Validation loss: 2.688515522075836

Epoch: 287| Step: 0
Training loss: 0.7733494486924641
Validation loss: 2.6880113068075837

Epoch: 6| Step: 1
Training loss: 0.665096106862518
Validation loss: 2.672502523766942

Epoch: 6| Step: 2
Training loss: 0.7498593198443926
Validation loss: 2.6393630926340665

Epoch: 6| Step: 3
Training loss: 0.6969222390624399
Validation loss: 2.7082744276457738

Epoch: 6| Step: 4
Training loss: 0.48926455860474305
Validation loss: 2.686303952655695

Epoch: 6| Step: 5
Training loss: 0.4629456370696793
Validation loss: 2.699189179656823

Epoch: 6| Step: 6
Training loss: 0.7349179878022571
Validation loss: 2.7143134586531708

Epoch: 6| Step: 7
Training loss: 0.4794911308820779
Validation loss: 2.6921722004682187

Epoch: 6| Step: 8
Training loss: 1.5939754999735696
Validation loss: 2.667366673963164

Epoch: 6| Step: 9
Training loss: 0.5427483310225738
Validation loss: 2.6851473992471226

Epoch: 6| Step: 10
Training loss: 0.6264559001090931
Validation loss: 2.678243406244204

Epoch: 6| Step: 11
Training loss: 0.45773173716732857
Validation loss: 2.6938513111171036

Epoch: 6| Step: 12
Training loss: 0.7583717563522686
Validation loss: 2.705356291317362

Epoch: 6| Step: 13
Training loss: 0.5740831954705969
Validation loss: 2.7188367856886186

Epoch: 288| Step: 0
Training loss: 0.653360453970471
Validation loss: 2.732206766007976

Epoch: 6| Step: 1
Training loss: 1.682846222010985
Validation loss: 2.703616605259682

Epoch: 6| Step: 2
Training loss: 0.7710023557228683
Validation loss: 2.7002917517601537

Epoch: 6| Step: 3
Training loss: 0.5452151039392122
Validation loss: 2.685708122297463

Epoch: 6| Step: 4
Training loss: 0.6304986353412474
Validation loss: 2.69694642864368

Epoch: 6| Step: 5
Training loss: 0.3989033313350088
Validation loss: 2.652075761514652

Epoch: 6| Step: 6
Training loss: 0.6968605296595538
Validation loss: 2.65629757784869

Epoch: 6| Step: 7
Training loss: 0.6886448864076085
Validation loss: 2.6654794290740513

Epoch: 6| Step: 8
Training loss: 0.4214346141272282
Validation loss: 2.6375177320327414

Epoch: 6| Step: 9
Training loss: 0.8136273412654665
Validation loss: 2.6743239538969474

Epoch: 6| Step: 10
Training loss: 0.45288141872649085
Validation loss: 2.6623103632185052

Epoch: 6| Step: 11
Training loss: 0.3008374496074439
Validation loss: 2.639102966308813

Epoch: 6| Step: 12
Training loss: 0.6490435238719565
Validation loss: 2.6466899699789295

Epoch: 6| Step: 13
Training loss: 0.7583950988711763
Validation loss: 2.6398397337384987

Epoch: 289| Step: 0
Training loss: 0.8568095321186479
Validation loss: 2.6707627949360107

Epoch: 6| Step: 1
Training loss: 0.6984605354418948
Validation loss: 2.6790774693318844

Epoch: 6| Step: 2
Training loss: 0.7690735825999916
Validation loss: 2.6928380126218276

Epoch: 6| Step: 3
Training loss: 0.703618469854492
Validation loss: 2.6698204267483368

Epoch: 6| Step: 4
Training loss: 1.5097348307520069
Validation loss: 2.7000865457535115

Epoch: 6| Step: 5
Training loss: 0.6526066826977119
Validation loss: 2.6558556453977515

Epoch: 6| Step: 6
Training loss: 0.4324606791025085
Validation loss: 2.661944878007242

Epoch: 6| Step: 7
Training loss: 0.5691031344809218
Validation loss: 2.674276917238916

Epoch: 6| Step: 8
Training loss: 0.5549495239330009
Validation loss: 2.639602839987069

Epoch: 6| Step: 9
Training loss: 0.3211379927994715
Validation loss: 2.6854808039587503

Epoch: 6| Step: 10
Training loss: 0.627611735339186
Validation loss: 2.6488459851025254

Epoch: 6| Step: 11
Training loss: 0.7520279091642522
Validation loss: 2.669971700876852

Epoch: 6| Step: 12
Training loss: 0.5577045646124997
Validation loss: 2.6426585561686573

Epoch: 6| Step: 13
Training loss: 0.8057360067901224
Validation loss: 2.6243867875718254

Epoch: 290| Step: 0
Training loss: 0.8766532674159477
Validation loss: 2.6641966582966825

Epoch: 6| Step: 1
Training loss: 0.32969708993713337
Validation loss: 2.652777151479849

Epoch: 6| Step: 2
Training loss: 0.6078996159509172
Validation loss: 2.635921450518893

Epoch: 6| Step: 3
Training loss: 0.49222702291536896
Validation loss: 2.6611640985385923

Epoch: 6| Step: 4
Training loss: 1.5786888701503448
Validation loss: 2.6544708644287613

Epoch: 6| Step: 5
Training loss: 0.6027151187532791
Validation loss: 2.688777082146692

Epoch: 6| Step: 6
Training loss: 0.43196111320164593
Validation loss: 2.6949356507612845

Epoch: 6| Step: 7
Training loss: 0.6591418446168629
Validation loss: 2.7081191862523344

Epoch: 6| Step: 8
Training loss: 0.3908099499595924
Validation loss: 2.718524931560379

Epoch: 6| Step: 9
Training loss: 0.7982017467644068
Validation loss: 2.7073906165717307

Epoch: 6| Step: 10
Training loss: 0.8678312232168484
Validation loss: 2.713084734960745

Epoch: 6| Step: 11
Training loss: 0.6407526865920333
Validation loss: 2.6670386230592302

Epoch: 6| Step: 12
Training loss: 0.6431129108549464
Validation loss: 2.6460216191348445

Epoch: 6| Step: 13
Training loss: 0.27555417554381173
Validation loss: 2.618132988198913

Epoch: 291| Step: 0
Training loss: 0.5898606253729922
Validation loss: 2.6663396241264268

Epoch: 6| Step: 1
Training loss: 0.44322686588872107
Validation loss: 2.66515030227408

Epoch: 6| Step: 2
Training loss: 0.5804040936981602
Validation loss: 2.636090122822423

Epoch: 6| Step: 3
Training loss: 1.6461789536841036
Validation loss: 2.6548697700971675

Epoch: 6| Step: 4
Training loss: 0.546360755010349
Validation loss: 2.6427267697453223

Epoch: 6| Step: 5
Training loss: 0.7415542712038381
Validation loss: 2.660026579055685

Epoch: 6| Step: 6
Training loss: 0.9007541477066583
Validation loss: 2.6591679971374327

Epoch: 6| Step: 7
Training loss: 0.39498471176161476
Validation loss: 2.66186947236986

Epoch: 6| Step: 8
Training loss: 0.6180869682653956
Validation loss: 2.6675956291123324

Epoch: 6| Step: 9
Training loss: 0.5345649236728722
Validation loss: 2.6836869265619776

Epoch: 6| Step: 10
Training loss: 0.5714468974342404
Validation loss: 2.726483823745503

Epoch: 6| Step: 11
Training loss: 0.5029763209379602
Validation loss: 2.7000923925594096

Epoch: 6| Step: 12
Training loss: 0.5774609128101372
Validation loss: 2.7241222781103596

Epoch: 6| Step: 13
Training loss: 0.7159233903764156
Validation loss: 2.732033602140517

Epoch: 292| Step: 0
Training loss: 0.6184322022707012
Validation loss: 2.722992506854924

Epoch: 6| Step: 1
Training loss: 1.4640015482555604
Validation loss: 2.7462226042635978

Epoch: 6| Step: 2
Training loss: 0.5851084120464375
Validation loss: 2.730779274883678

Epoch: 6| Step: 3
Training loss: 0.35112072420419616
Validation loss: 2.7157754095786526

Epoch: 6| Step: 4
Training loss: 0.5385365615642109
Validation loss: 2.6886896990040774

Epoch: 6| Step: 5
Training loss: 0.5379729108956972
Validation loss: 2.705290228364399

Epoch: 6| Step: 6
Training loss: 0.7145564434749434
Validation loss: 2.673695766467315

Epoch: 6| Step: 7
Training loss: 0.9839736483580985
Validation loss: 2.7031092527396625

Epoch: 6| Step: 8
Training loss: 0.6170026768018876
Validation loss: 2.669854862280647

Epoch: 6| Step: 9
Training loss: 0.6371561432026869
Validation loss: 2.6292665973874305

Epoch: 6| Step: 10
Training loss: 0.6064246722408456
Validation loss: 2.6240660406902303

Epoch: 6| Step: 11
Training loss: 0.5165958512392532
Validation loss: 2.62010969455726

Epoch: 6| Step: 12
Training loss: 1.0103439357314115
Validation loss: 2.6572488362963433

Epoch: 6| Step: 13
Training loss: 0.35118840765305387
Validation loss: 2.7030296633698043

Epoch: 293| Step: 0
Training loss: 0.6895152596202133
Validation loss: 2.7471571516479067

Epoch: 6| Step: 1
Training loss: 0.6736815141043337
Validation loss: 2.748426695822972

Epoch: 6| Step: 2
Training loss: 1.6131375227999658
Validation loss: 2.7353549383833773

Epoch: 6| Step: 3
Training loss: 0.41302190333929717
Validation loss: 2.7303215169189246

Epoch: 6| Step: 4
Training loss: 0.6444613332106606
Validation loss: 2.668251328798447

Epoch: 6| Step: 5
Training loss: 0.8065879749175446
Validation loss: 2.650502118782914

Epoch: 6| Step: 6
Training loss: 0.46715246407280453
Validation loss: 2.632359270913008

Epoch: 6| Step: 7
Training loss: 0.6847377686565848
Validation loss: 2.6083182620052408

Epoch: 6| Step: 8
Training loss: 0.6434313781876885
Validation loss: 2.6259416853151767

Epoch: 6| Step: 9
Training loss: 0.8219489350804482
Validation loss: 2.6359205528287477

Epoch: 6| Step: 10
Training loss: 0.8999616217377778
Validation loss: 2.6617907851533853

Epoch: 6| Step: 11
Training loss: 0.5362503117558212
Validation loss: 2.656146938923244

Epoch: 6| Step: 12
Training loss: 0.5882994285500316
Validation loss: 2.6827892255753274

Epoch: 6| Step: 13
Training loss: 0.7517458146907705
Validation loss: 2.715188123760828

Epoch: 294| Step: 0
Training loss: 1.5830298768752635
Validation loss: 2.7009850863191893

Epoch: 6| Step: 1
Training loss: 0.6759345702073881
Validation loss: 2.6834744875338745

Epoch: 6| Step: 2
Training loss: 0.6122104261933679
Validation loss: 2.7278854123016685

Epoch: 6| Step: 3
Training loss: 0.5210168292737672
Validation loss: 2.666878350249369

Epoch: 6| Step: 4
Training loss: 0.6774331778479843
Validation loss: 2.657856960266822

Epoch: 6| Step: 5
Training loss: 0.6855640898279289
Validation loss: 2.6174799038730976

Epoch: 6| Step: 6
Training loss: 0.7258026087054171
Validation loss: 2.6339634371871776

Epoch: 6| Step: 7
Training loss: 0.555750727808755
Validation loss: 2.6626504325321383

Epoch: 6| Step: 8
Training loss: 0.4729209505494925
Validation loss: 2.62329020681904

Epoch: 6| Step: 9
Training loss: 0.8433742392901084
Validation loss: 2.63969008148491

Epoch: 6| Step: 10
Training loss: 0.6955709941289495
Validation loss: 2.631754503431034

Epoch: 6| Step: 11
Training loss: 0.841130960212914
Validation loss: 2.6475022194218316

Epoch: 6| Step: 12
Training loss: 0.5916312964930663
Validation loss: 2.6428603436248763

Epoch: 6| Step: 13
Training loss: 0.5643683769200761
Validation loss: 2.627777359930698

Epoch: 295| Step: 0
Training loss: 0.5928711158678293
Validation loss: 2.5866546880507904

Epoch: 6| Step: 1
Training loss: 0.367188920363256
Validation loss: 2.6238591107103644

Epoch: 6| Step: 2
Training loss: 0.9099819687744191
Validation loss: 2.604587743043863

Epoch: 6| Step: 3
Training loss: 0.6730937770944628
Validation loss: 2.6086621596919564

Epoch: 6| Step: 4
Training loss: 0.5082916933212859
Validation loss: 2.635451495146235

Epoch: 6| Step: 5
Training loss: 0.5774751309824108
Validation loss: 2.6568081563111634

Epoch: 6| Step: 6
Training loss: 0.6722000134383804
Validation loss: 2.6833238074392756

Epoch: 6| Step: 7
Training loss: 0.6721727908913502
Validation loss: 2.7210469437487186

Epoch: 6| Step: 8
Training loss: 0.5529680870032776
Validation loss: 2.65916248647204

Epoch: 6| Step: 9
Training loss: 0.5097612987349346
Validation loss: 2.6357881465060697

Epoch: 6| Step: 10
Training loss: 0.5379835194009797
Validation loss: 2.663930959283539

Epoch: 6| Step: 11
Training loss: 0.48725627895711404
Validation loss: 2.681579785611009

Epoch: 6| Step: 12
Training loss: 1.59247433340807
Validation loss: 2.653901346294453

Epoch: 6| Step: 13
Training loss: 0.6518961575842677
Validation loss: 2.674035056551589

Epoch: 296| Step: 0
Training loss: 0.6682775798533607
Validation loss: 2.6337944082204614

Epoch: 6| Step: 1
Training loss: 0.49139502471571794
Validation loss: 2.6275431613728233

Epoch: 6| Step: 2
Training loss: 1.5007274770957764
Validation loss: 2.673203632179005

Epoch: 6| Step: 3
Training loss: 0.7577356909140572
Validation loss: 2.684000398601755

Epoch: 6| Step: 4
Training loss: 0.8040481545939931
Validation loss: 2.722918931149309

Epoch: 6| Step: 5
Training loss: 0.680637747695126
Validation loss: 2.732695447345455

Epoch: 6| Step: 6
Training loss: 0.5285948993468524
Validation loss: 2.683997163962055

Epoch: 6| Step: 7
Training loss: 0.857552277331075
Validation loss: 2.66371293613789

Epoch: 6| Step: 8
Training loss: 0.5505476652431758
Validation loss: 2.645794213583671

Epoch: 6| Step: 9
Training loss: 0.5098497752454098
Validation loss: 2.635822341929901

Epoch: 6| Step: 10
Training loss: 0.5344996078389855
Validation loss: 2.6162632188790873

Epoch: 6| Step: 11
Training loss: 0.6168454828128317
Validation loss: 2.620502241902039

Epoch: 6| Step: 12
Training loss: 0.5641929528448398
Validation loss: 2.63649321897682

Epoch: 6| Step: 13
Training loss: 0.3977743127178838
Validation loss: 2.6539521346344768

Epoch: 297| Step: 0
Training loss: 0.6344330606058165
Validation loss: 2.664374818947766

Epoch: 6| Step: 1
Training loss: 0.5500959637759946
Validation loss: 2.674728542406862

Epoch: 6| Step: 2
Training loss: 0.5957338669145645
Validation loss: 2.7202897116066382

Epoch: 6| Step: 3
Training loss: 0.5650143852343711
Validation loss: 2.6915141369087223

Epoch: 6| Step: 4
Training loss: 1.470665919832563
Validation loss: 2.7025301727713913

Epoch: 6| Step: 5
Training loss: 0.5202440806816974
Validation loss: 2.7024198019216867

Epoch: 6| Step: 6
Training loss: 0.49854652922358256
Validation loss: 2.7061489209592198

Epoch: 6| Step: 7
Training loss: 0.3530252860234862
Validation loss: 2.6690426177222424

Epoch: 6| Step: 8
Training loss: 0.6848268993967005
Validation loss: 2.666807469629475

Epoch: 6| Step: 9
Training loss: 0.685752207553271
Validation loss: 2.646088474895178

Epoch: 6| Step: 10
Training loss: 0.45821231270218676
Validation loss: 2.6260275043234635

Epoch: 6| Step: 11
Training loss: 0.8839389062802987
Validation loss: 2.632774946002691

Epoch: 6| Step: 12
Training loss: 0.5201215903553847
Validation loss: 2.6463357185067085

Epoch: 6| Step: 13
Training loss: 0.6165421407424965
Validation loss: 2.6473584716558447

Epoch: 298| Step: 0
Training loss: 0.6498233050656715
Validation loss: 2.6670983729996016

Epoch: 6| Step: 1
Training loss: 0.2964398557990396
Validation loss: 2.6713912670860247

Epoch: 6| Step: 2
Training loss: 0.7656445792672485
Validation loss: 2.649977253580015

Epoch: 6| Step: 3
Training loss: 0.5662596414178908
Validation loss: 2.6742739752034863

Epoch: 6| Step: 4
Training loss: 0.6503681030039707
Validation loss: 2.636908972535229

Epoch: 6| Step: 5
Training loss: 0.745472594526904
Validation loss: 2.617343629169552

Epoch: 6| Step: 6
Training loss: 0.5767581866063223
Validation loss: 2.613342313872953

Epoch: 6| Step: 7
Training loss: 0.4619355952786575
Validation loss: 2.6239168351459914

Epoch: 6| Step: 8
Training loss: 1.399251477206488
Validation loss: 2.5954750848698884

Epoch: 6| Step: 9
Training loss: 0.45915084417270313
Validation loss: 2.6050827144541002

Epoch: 6| Step: 10
Training loss: 0.3976018407505607
Validation loss: 2.5979428038510175

Epoch: 6| Step: 11
Training loss: 0.7357239204733507
Validation loss: 2.6190591055108507

Epoch: 6| Step: 12
Training loss: 0.5959595925487327
Validation loss: 2.6383151875215494

Epoch: 6| Step: 13
Training loss: 0.33873546139813737
Validation loss: 2.657522442307274

Epoch: 299| Step: 0
Training loss: 0.5143852067400555
Validation loss: 2.6240275916516733

Epoch: 6| Step: 1
Training loss: 1.3672643585399746
Validation loss: 2.6678798886969677

Epoch: 6| Step: 2
Training loss: 0.5825233171568612
Validation loss: 2.659093046867547

Epoch: 6| Step: 3
Training loss: 0.6461292224819123
Validation loss: 2.626864389894861

Epoch: 6| Step: 4
Training loss: 0.6382111220197907
Validation loss: 2.6223849754908306

Epoch: 6| Step: 5
Training loss: 0.6032337406937774
Validation loss: 2.6345920010977126

Epoch: 6| Step: 6
Training loss: 0.39362287285654896
Validation loss: 2.6193342254537724

Epoch: 6| Step: 7
Training loss: 0.6837397174306118
Validation loss: 2.63064898188103

Epoch: 6| Step: 8
Training loss: 0.719925375488514
Validation loss: 2.613124684841686

Epoch: 6| Step: 9
Training loss: 0.561702825668057
Validation loss: 2.6144852929747175

Epoch: 6| Step: 10
Training loss: 0.44587050161185937
Validation loss: 2.6389164055507037

Epoch: 6| Step: 11
Training loss: 0.46162658843080423
Validation loss: 2.6264019473095606

Epoch: 6| Step: 12
Training loss: 0.6469958952562759
Validation loss: 2.6375271544861443

Epoch: 6| Step: 13
Training loss: 0.6082787556747771
Validation loss: 2.668134203482497

Epoch: 300| Step: 0
Training loss: 0.7448921713785484
Validation loss: 2.6508340072281533

Epoch: 6| Step: 1
Training loss: 0.5205112764912438
Validation loss: 2.6725570363756024

Epoch: 6| Step: 2
Training loss: 1.3812916900419046
Validation loss: 2.680467755863763

Epoch: 6| Step: 3
Training loss: 0.4530248531298581
Validation loss: 2.6752290512064145

Epoch: 6| Step: 4
Training loss: 0.5860094153458307
Validation loss: 2.6666223524882593

Epoch: 6| Step: 5
Training loss: 0.2577472372970742
Validation loss: 2.6564575094955316

Epoch: 6| Step: 6
Training loss: 0.68477737407974
Validation loss: 2.6410032339915466

Epoch: 6| Step: 7
Training loss: 0.5858844478749622
Validation loss: 2.5927932621393186

Epoch: 6| Step: 8
Training loss: 0.716176234669283
Validation loss: 2.6169567728250316

Epoch: 6| Step: 9
Training loss: 0.845193546408095
Validation loss: 2.6022045941106025

Epoch: 6| Step: 10
Training loss: 0.5453938726796501
Validation loss: 2.6235273540221384

Epoch: 6| Step: 11
Training loss: 0.2943282563663422
Validation loss: 2.5977744134277256

Epoch: 6| Step: 12
Training loss: 0.5314885333233725
Validation loss: 2.5776591012062573

Epoch: 6| Step: 13
Training loss: 0.17051903708480304
Validation loss: 2.589138219186587

Epoch: 301| Step: 0
Training loss: 1.261211186880773
Validation loss: 2.60708043037136

Epoch: 6| Step: 1
Training loss: 0.38759206170475075
Validation loss: 2.6257235481575

Epoch: 6| Step: 2
Training loss: 0.5166403570193223
Validation loss: 2.6188239718843525

Epoch: 6| Step: 3
Training loss: 0.6306791727258934
Validation loss: 2.6468727880548255

Epoch: 6| Step: 4
Training loss: 0.751015809699103
Validation loss: 2.630151040691788

Epoch: 6| Step: 5
Training loss: 0.5602070379709192
Validation loss: 2.654213994505511

Epoch: 6| Step: 6
Training loss: 0.5338941295521819
Validation loss: 2.613514493028376

Epoch: 6| Step: 7
Training loss: 0.9787334877267988
Validation loss: 2.5846694525393263

Epoch: 6| Step: 8
Training loss: 0.41780536345932906
Validation loss: 2.561752853699696

Epoch: 6| Step: 9
Training loss: 0.5070790496066393
Validation loss: 2.5928054371612577

Epoch: 6| Step: 10
Training loss: 0.6080798789258153
Validation loss: 2.6137302941831777

Epoch: 6| Step: 11
Training loss: 0.6272502444689849
Validation loss: 2.594554269878384

Epoch: 6| Step: 12
Training loss: 0.44510254176752573
Validation loss: 2.6036042716530723

Epoch: 6| Step: 13
Training loss: 0.4546767335121726
Validation loss: 2.6208153989452687

Epoch: 302| Step: 0
Training loss: 0.5375356196643991
Validation loss: 2.628249909221199

Epoch: 6| Step: 1
Training loss: 0.45754617228748934
Validation loss: 2.675913520707244

Epoch: 6| Step: 2
Training loss: 0.5194338370184733
Validation loss: 2.67267147489515

Epoch: 6| Step: 3
Training loss: 0.7209675621640331
Validation loss: 2.6834961661071537

Epoch: 6| Step: 4
Training loss: 0.3584508415805591
Validation loss: 2.6821033354719237

Epoch: 6| Step: 5
Training loss: 0.313793295688442
Validation loss: 2.6538798481127257

Epoch: 6| Step: 6
Training loss: 0.5718454113585963
Validation loss: 2.6574999537508615

Epoch: 6| Step: 7
Training loss: 0.7203689668910129
Validation loss: 2.625281854958616

Epoch: 6| Step: 8
Training loss: 0.5359602686991823
Validation loss: 2.6298003362848092

Epoch: 6| Step: 9
Training loss: 1.4726665304214692
Validation loss: 2.647887702550412

Epoch: 6| Step: 10
Training loss: 0.5622427670092878
Validation loss: 2.6337328032930234

Epoch: 6| Step: 11
Training loss: 0.6097728946308655
Validation loss: 2.6464127795971217

Epoch: 6| Step: 12
Training loss: 0.42706661269168433
Validation loss: 2.667250468071426

Epoch: 6| Step: 13
Training loss: 0.782370564782327
Validation loss: 2.6679824052588326

Epoch: 303| Step: 0
Training loss: 0.46342524305869115
Validation loss: 2.679279347133323

Epoch: 6| Step: 1
Training loss: 0.3631640624671748
Validation loss: 2.660066325874832

Epoch: 6| Step: 2
Training loss: 0.5345344272174539
Validation loss: 2.6772680827334234

Epoch: 6| Step: 3
Training loss: 0.5905491230176622
Validation loss: 2.650253328252144

Epoch: 6| Step: 4
Training loss: 0.5923853802774672
Validation loss: 2.6750720262725847

Epoch: 6| Step: 5
Training loss: 0.5299967962743989
Validation loss: 2.634748233447781

Epoch: 6| Step: 6
Training loss: 0.5299159859700256
Validation loss: 2.64239754054602

Epoch: 6| Step: 7
Training loss: 0.44271056978745377
Validation loss: 2.626914890955097

Epoch: 6| Step: 8
Training loss: 0.5851796144269721
Validation loss: 2.611137871927661

Epoch: 6| Step: 9
Training loss: 1.2975143327454266
Validation loss: 2.6066009422522995

Epoch: 6| Step: 10
Training loss: 0.5314515236488442
Validation loss: 2.649439874268578

Epoch: 6| Step: 11
Training loss: 0.6446346084488157
Validation loss: 2.6432226599922313

Epoch: 6| Step: 12
Training loss: 0.627450715823445
Validation loss: 2.6381982801709873

Epoch: 6| Step: 13
Training loss: 0.6736261479730216
Validation loss: 2.6099217145273967

Epoch: 304| Step: 0
Training loss: 0.4973712152776649
Validation loss: 2.6356614839894874

Epoch: 6| Step: 1
Training loss: 0.7741379311699791
Validation loss: 2.637179542423742

Epoch: 6| Step: 2
Training loss: 0.4573675695119639
Validation loss: 2.6050799658841477

Epoch: 6| Step: 3
Training loss: 0.7881209922283258
Validation loss: 2.6206706060528626

Epoch: 6| Step: 4
Training loss: 0.6525025317263541
Validation loss: 2.6152200002541055

Epoch: 6| Step: 5
Training loss: 0.4323159368052195
Validation loss: 2.60058555895528

Epoch: 6| Step: 6
Training loss: 1.297295008288976
Validation loss: 2.575454266281606

Epoch: 6| Step: 7
Training loss: 0.340471499091889
Validation loss: 2.605775854911317

Epoch: 6| Step: 8
Training loss: 0.49013313068688635
Validation loss: 2.6359503446963686

Epoch: 6| Step: 9
Training loss: 0.5474208832104772
Validation loss: 2.627334027805377

Epoch: 6| Step: 10
Training loss: 0.6233679443412916
Validation loss: 2.6738388193263094

Epoch: 6| Step: 11
Training loss: 0.5279896489342513
Validation loss: 2.6467041786486134

Epoch: 6| Step: 12
Training loss: 0.28299599011397575
Validation loss: 2.6711693564560344

Epoch: 6| Step: 13
Training loss: 0.6695966014326891
Validation loss: 2.645271241239935

Epoch: 305| Step: 0
Training loss: 0.2599176807942307
Validation loss: 2.6166577266584548

Epoch: 6| Step: 1
Training loss: 0.3971251022583683
Validation loss: 2.643594054059575

Epoch: 6| Step: 2
Training loss: 0.5668190339881501
Validation loss: 2.6580328173150547

Epoch: 6| Step: 3
Training loss: 0.8729387254742552
Validation loss: 2.6569202482295573

Epoch: 6| Step: 4
Training loss: 0.6061361264910593
Validation loss: 2.6764561080478604

Epoch: 6| Step: 5
Training loss: 0.6141316052249911
Validation loss: 2.6628333597155773

Epoch: 6| Step: 6
Training loss: 0.5354252160227163
Validation loss: 2.6557973486870767

Epoch: 6| Step: 7
Training loss: 1.3043391967743683
Validation loss: 2.620602646949663

Epoch: 6| Step: 8
Training loss: 0.4728280850632278
Validation loss: 2.6424669274896355

Epoch: 6| Step: 9
Training loss: 0.2719996385869963
Validation loss: 2.6436675110702055

Epoch: 6| Step: 10
Training loss: 0.7339214791335442
Validation loss: 2.6352898572356125

Epoch: 6| Step: 11
Training loss: 0.5437708357403492
Validation loss: 2.6165609678426436

Epoch: 6| Step: 12
Training loss: 0.5081481997740962
Validation loss: 2.5748541594240635

Epoch: 6| Step: 13
Training loss: 0.4916044899721092
Validation loss: 2.5686225151489492

Epoch: 306| Step: 0
Training loss: 0.5311806296889366
Validation loss: 2.579329779996906

Epoch: 6| Step: 1
Training loss: 0.31212467065411087
Validation loss: 2.583937372060377

Epoch: 6| Step: 2
Training loss: 0.629946919808789
Validation loss: 2.5859092128668677

Epoch: 6| Step: 3
Training loss: 0.23184881969934648
Validation loss: 2.591162806505989

Epoch: 6| Step: 4
Training loss: 0.5553505386779926
Validation loss: 2.6114503377499183

Epoch: 6| Step: 5
Training loss: 0.6621268841164119
Validation loss: 2.6065187458440726

Epoch: 6| Step: 6
Training loss: 0.683475113519599
Validation loss: 2.6044652146695118

Epoch: 6| Step: 7
Training loss: 0.6368767010008134
Validation loss: 2.609715288303031

Epoch: 6| Step: 8
Training loss: 0.46862056852592343
Validation loss: 2.6144354882671665

Epoch: 6| Step: 9
Training loss: 0.4546902194384235
Validation loss: 2.618485119173235

Epoch: 6| Step: 10
Training loss: 0.5075933423666834
Validation loss: 2.614322972143247

Epoch: 6| Step: 11
Training loss: 1.2226697537099984
Validation loss: 2.625402951894488

Epoch: 6| Step: 12
Training loss: 0.390316593493825
Validation loss: 2.6384710779549705

Epoch: 6| Step: 13
Training loss: 0.7431818274481282
Validation loss: 2.5999703154750664

Epoch: 307| Step: 0
Training loss: 0.5491010591344947
Validation loss: 2.6138482983445686

Epoch: 6| Step: 1
Training loss: 0.6833367872926213
Validation loss: 2.5923156478742855

Epoch: 6| Step: 2
Training loss: 0.625940473590402
Validation loss: 2.6062373838180557

Epoch: 6| Step: 3
Training loss: 0.38142816179806127
Validation loss: 2.585047950387968

Epoch: 6| Step: 4
Training loss: 0.4860259040072985
Validation loss: 2.5982957431381797

Epoch: 6| Step: 5
Training loss: 0.4987474637696068
Validation loss: 2.627244765953092

Epoch: 6| Step: 6
Training loss: 0.7258214144890573
Validation loss: 2.6074613879036126

Epoch: 6| Step: 7
Training loss: 0.6450618524983353
Validation loss: 2.626057012562876

Epoch: 6| Step: 8
Training loss: 0.4571163391719819
Validation loss: 2.622046951822648

Epoch: 6| Step: 9
Training loss: 1.1934784425563285
Validation loss: 2.631685659631018

Epoch: 6| Step: 10
Training loss: 0.4710566827162546
Validation loss: 2.5899846054391222

Epoch: 6| Step: 11
Training loss: 0.2851443222895688
Validation loss: 2.6107314653153666

Epoch: 6| Step: 12
Training loss: 0.6071522350348364
Validation loss: 2.6190294269043943

Epoch: 6| Step: 13
Training loss: 0.5401545258026368
Validation loss: 2.631282121712021

Epoch: 308| Step: 0
Training loss: 0.20588867225134921
Validation loss: 2.6137412241057305

Epoch: 6| Step: 1
Training loss: 0.4068326073637073
Validation loss: 2.6420556843248773

Epoch: 6| Step: 2
Training loss: 0.5985233524183676
Validation loss: 2.600073058432635

Epoch: 6| Step: 3
Training loss: 0.5444092612538267
Validation loss: 2.634690224775708

Epoch: 6| Step: 4
Training loss: 0.4732787863968574
Validation loss: 2.6510690246507482

Epoch: 6| Step: 5
Training loss: 0.46443709850332426
Validation loss: 2.6036835732239836

Epoch: 6| Step: 6
Training loss: 0.5662835349958943
Validation loss: 2.6172255176420967

Epoch: 6| Step: 7
Training loss: 0.5076287157100732
Validation loss: 2.599191883550858

Epoch: 6| Step: 8
Training loss: 0.48649183834557336
Validation loss: 2.5979379448609445

Epoch: 6| Step: 9
Training loss: 0.7245245212935991
Validation loss: 2.5987205445088497

Epoch: 6| Step: 10
Training loss: 0.5971822916279849
Validation loss: 2.597042612101417

Epoch: 6| Step: 11
Training loss: 0.5572202375275643
Validation loss: 2.594270573135479

Epoch: 6| Step: 12
Training loss: 1.1788584341131672
Validation loss: 2.626449152724004

Epoch: 6| Step: 13
Training loss: 0.75181499054636
Validation loss: 2.6151876783533177

Epoch: 309| Step: 0
Training loss: 0.3592691265554893
Validation loss: 2.657082895066705

Epoch: 6| Step: 1
Training loss: 1.1175332234711541
Validation loss: 2.6255179840011955

Epoch: 6| Step: 2
Training loss: 0.5339114336761879
Validation loss: 2.6650983334979728

Epoch: 6| Step: 3
Training loss: 0.38421372465032877
Validation loss: 2.5941534300643867

Epoch: 6| Step: 4
Training loss: 0.4392561068232467
Validation loss: 2.5975183835708946

Epoch: 6| Step: 5
Training loss: 0.49447864535925495
Validation loss: 2.6112780971043676

Epoch: 6| Step: 6
Training loss: 0.5164003322798962
Validation loss: 2.585656999265883

Epoch: 6| Step: 7
Training loss: 0.6293954545895453
Validation loss: 2.581502677295376

Epoch: 6| Step: 8
Training loss: 0.6893851270995291
Validation loss: 2.616421563722665

Epoch: 6| Step: 9
Training loss: 0.5413850975583472
Validation loss: 2.5950313807450986

Epoch: 6| Step: 10
Training loss: 0.5815251089023236
Validation loss: 2.598049851787253

Epoch: 6| Step: 11
Training loss: 0.4928132272834709
Validation loss: 2.584687333306111

Epoch: 6| Step: 12
Training loss: 0.6803571537276711
Validation loss: 2.5566602174221638

Epoch: 6| Step: 13
Training loss: 0.8593210376790094
Validation loss: 2.566806719700743

Epoch: 310| Step: 0
Training loss: 0.4032970911319309
Validation loss: 2.526053560408888

Epoch: 6| Step: 1
Training loss: 1.0537347516894513
Validation loss: 2.5498650616277745

Epoch: 6| Step: 2
Training loss: 0.5846976832568855
Validation loss: 2.554443314589327

Epoch: 6| Step: 3
Training loss: 0.7072189671978489
Validation loss: 2.582305948695419

Epoch: 6| Step: 4
Training loss: 0.5441718460185084
Validation loss: 2.5393491824526913

Epoch: 6| Step: 5
Training loss: 0.6617097802212909
Validation loss: 2.5903528479321816

Epoch: 6| Step: 6
Training loss: 0.6361263304096986
Validation loss: 2.604106689418741

Epoch: 6| Step: 7
Training loss: 0.654460533512729
Validation loss: 2.603199149934332

Epoch: 6| Step: 8
Training loss: 0.5063672259677319
Validation loss: 2.5423418301852387

Epoch: 6| Step: 9
Training loss: 0.39145834722649164
Validation loss: 2.562705549214273

Epoch: 6| Step: 10
Training loss: 0.6321754545684977
Validation loss: 2.5812291077812146

Epoch: 6| Step: 11
Training loss: 0.542752257074893
Validation loss: 2.5437893586314795

Epoch: 6| Step: 12
Training loss: 0.524008795000115
Validation loss: 2.5599997042904445

Epoch: 6| Step: 13
Training loss: 0.4887831283034733
Validation loss: 2.5894907022115032

Epoch: 311| Step: 0
Training loss: 0.5661512919153749
Validation loss: 2.5686067567235993

Epoch: 6| Step: 1
Training loss: 0.5224358953731285
Validation loss: 2.577106941804657

Epoch: 6| Step: 2
Training loss: 0.5767815160999262
Validation loss: 2.5249845744916426

Epoch: 6| Step: 3
Training loss: 0.45042820531349637
Validation loss: 2.5352959842669525

Epoch: 6| Step: 4
Training loss: 1.219869637325182
Validation loss: 2.5691527663833393

Epoch: 6| Step: 5
Training loss: 0.6008974337499692
Validation loss: 2.5680740802504145

Epoch: 6| Step: 6
Training loss: 0.4923403820381475
Validation loss: 2.600308581546531

Epoch: 6| Step: 7
Training loss: 0.4328401391469018
Validation loss: 2.5789494876298944

Epoch: 6| Step: 8
Training loss: 0.6087552366873528
Validation loss: 2.5616069045730216

Epoch: 6| Step: 9
Training loss: 0.35242765785095065
Validation loss: 2.594901272071703

Epoch: 6| Step: 10
Training loss: 0.3577862117722152
Validation loss: 2.601312048000253

Epoch: 6| Step: 11
Training loss: 0.20265153577934641
Validation loss: 2.580977676456528

Epoch: 6| Step: 12
Training loss: 0.5040474036002381
Validation loss: 2.5848269562427997

Epoch: 6| Step: 13
Training loss: 0.5131384687247434
Validation loss: 2.5997127199525814

Epoch: 312| Step: 0
Training loss: 0.5110021334489753
Validation loss: 2.5876646495871776

Epoch: 6| Step: 1
Training loss: 0.5481078828337701
Validation loss: 2.606329538937565

Epoch: 6| Step: 2
Training loss: 0.6713227952523398
Validation loss: 2.587494779322635

Epoch: 6| Step: 3
Training loss: 0.9925152695295567
Validation loss: 2.5960135182380224

Epoch: 6| Step: 4
Training loss: 0.5706088458863378
Validation loss: 2.6221244559090007

Epoch: 6| Step: 5
Training loss: 0.4520998572334346
Validation loss: 2.605072931578774

Epoch: 6| Step: 6
Training loss: 0.4944765208304592
Validation loss: 2.597616454714085

Epoch: 6| Step: 7
Training loss: 0.534171346707406
Validation loss: 2.608581628677207

Epoch: 6| Step: 8
Training loss: 0.3808932362689277
Validation loss: 2.611098552114526

Epoch: 6| Step: 9
Training loss: 0.5167828189613584
Validation loss: 2.555956149416866

Epoch: 6| Step: 10
Training loss: 0.3432676876411941
Validation loss: 2.6081274089758515

Epoch: 6| Step: 11
Training loss: 0.835147734153445
Validation loss: 2.629706683466153

Epoch: 6| Step: 12
Training loss: 0.4351366959840697
Validation loss: 2.617076582342093

Epoch: 6| Step: 13
Training loss: 0.45581688899494477
Validation loss: 2.5870696949026835

Epoch: 313| Step: 0
Training loss: 0.6133105034138232
Validation loss: 2.573217473940082

Epoch: 6| Step: 1
Training loss: 0.41249740556421216
Validation loss: 2.593899042201493

Epoch: 6| Step: 2
Training loss: 0.6543796088448968
Validation loss: 2.5613132192710792

Epoch: 6| Step: 3
Training loss: 0.44664654927831193
Validation loss: 2.556751601619199

Epoch: 6| Step: 4
Training loss: 0.5364206788511202
Validation loss: 2.563534340546709

Epoch: 6| Step: 5
Training loss: 0.6777507329280412
Validation loss: 2.573672119234725

Epoch: 6| Step: 6
Training loss: 0.574743796366115
Validation loss: 2.575054098083286

Epoch: 6| Step: 7
Training loss: 0.43715584365615323
Validation loss: 2.5885149038119812

Epoch: 6| Step: 8
Training loss: 0.49982434405915976
Validation loss: 2.6049578331589354

Epoch: 6| Step: 9
Training loss: 0.29631829768207457
Validation loss: 2.6314956664544487

Epoch: 6| Step: 10
Training loss: 0.6454579020955069
Validation loss: 2.6124541274161546

Epoch: 6| Step: 11
Training loss: 0.9987428631008327
Validation loss: 2.5715719887988557

Epoch: 6| Step: 12
Training loss: 0.4773000731519495
Validation loss: 2.5858131921344985

Epoch: 6| Step: 13
Training loss: 0.6545717942863676
Validation loss: 2.590008599761193

Epoch: 314| Step: 0
Training loss: 0.37335747376089784
Validation loss: 2.6032847466959166

Epoch: 6| Step: 1
Training loss: 0.5345589025727173
Validation loss: 2.5235686127638943

Epoch: 6| Step: 2
Training loss: 0.754003567912314
Validation loss: 2.5494527881502087

Epoch: 6| Step: 3
Training loss: 0.4357595907896861
Validation loss: 2.5394433701864454

Epoch: 6| Step: 4
Training loss: 0.5303275289749371
Validation loss: 2.5362242095597782

Epoch: 6| Step: 5
Training loss: 0.2936691177900391
Validation loss: 2.5472534289096234

Epoch: 6| Step: 6
Training loss: 0.45160538624844904
Validation loss: 2.5398064524760007

Epoch: 6| Step: 7
Training loss: 0.3017642937121596
Validation loss: 2.5995978920834606

Epoch: 6| Step: 8
Training loss: 0.5860424456391738
Validation loss: 2.6290866431721014

Epoch: 6| Step: 9
Training loss: 0.5487677381424908
Validation loss: 2.5850052892685924

Epoch: 6| Step: 10
Training loss: 1.1151349612953028
Validation loss: 2.658823922103696

Epoch: 6| Step: 11
Training loss: 0.6937681685465695
Validation loss: 2.6081623327075802

Epoch: 6| Step: 12
Training loss: 0.3040562962901861
Validation loss: 2.576252533467392

Epoch: 6| Step: 13
Training loss: 0.5200121955175075
Validation loss: 2.5455306920668006

Epoch: 315| Step: 0
Training loss: 0.5738524222115189
Validation loss: 2.5547404027090375

Epoch: 6| Step: 1
Training loss: 0.3734636425300754
Validation loss: 2.5585770721129952

Epoch: 6| Step: 2
Training loss: 0.49842099368707704
Validation loss: 2.5669129672838107

Epoch: 6| Step: 3
Training loss: 0.7291667166210339
Validation loss: 2.545756565721828

Epoch: 6| Step: 4
Training loss: 0.6524760860138683
Validation loss: 2.5550020311587245

Epoch: 6| Step: 5
Training loss: 0.3137309150666503
Validation loss: 2.5885903655181126

Epoch: 6| Step: 6
Training loss: 0.5866179774636435
Validation loss: 2.60346717414902

Epoch: 6| Step: 7
Training loss: 0.33390209232896056
Validation loss: 2.6320314054139935

Epoch: 6| Step: 8
Training loss: 0.6444170764020861
Validation loss: 2.650783285839061

Epoch: 6| Step: 9
Training loss: 0.43420749906423106
Validation loss: 2.693381871586952

Epoch: 6| Step: 10
Training loss: 1.0226675733809283
Validation loss: 2.698197722697242

Epoch: 6| Step: 11
Training loss: 0.4098687208613171
Validation loss: 2.7015383685780834

Epoch: 6| Step: 12
Training loss: 0.4986851958668508
Validation loss: 2.694034328872106

Epoch: 6| Step: 13
Training loss: 0.3009731745544699
Validation loss: 2.6753103904370303

Epoch: 316| Step: 0
Training loss: 0.5653247109903099
Validation loss: 2.658034323844813

Epoch: 6| Step: 1
Training loss: 0.978367107031515
Validation loss: 2.5971879538072047

Epoch: 6| Step: 2
Training loss: 0.37156651147420694
Validation loss: 2.6380715642821326

Epoch: 6| Step: 3
Training loss: 0.6291793325130347
Validation loss: 2.6253364604210914

Epoch: 6| Step: 4
Training loss: 0.559796512281341
Validation loss: 2.634607564322379

Epoch: 6| Step: 5
Training loss: 0.4615782147872288
Validation loss: 2.6172171838209923

Epoch: 6| Step: 6
Training loss: 0.5221325849676679
Validation loss: 2.6057359445551587

Epoch: 6| Step: 7
Training loss: 0.6004181418134934
Validation loss: 2.5948069682632395

Epoch: 6| Step: 8
Training loss: 0.5698677837386017
Validation loss: 2.6104318336591126

Epoch: 6| Step: 9
Training loss: 0.33472182745182577
Validation loss: 2.610436501458857

Epoch: 6| Step: 10
Training loss: 0.6720568388675017
Validation loss: 2.6083891024605452

Epoch: 6| Step: 11
Training loss: 0.3955483121504906
Validation loss: 2.6152362433974763

Epoch: 6| Step: 12
Training loss: 0.5350294310950651
Validation loss: 2.650708798221932

Epoch: 6| Step: 13
Training loss: 0.5757068114900994
Validation loss: 2.615804536982261

Epoch: 317| Step: 0
Training loss: 0.3643172064827464
Validation loss: 2.624324723446642

Epoch: 6| Step: 1
Training loss: 0.9341025781440502
Validation loss: 2.6331617780260808

Epoch: 6| Step: 2
Training loss: 0.6266761952506026
Validation loss: 2.6207709987810377

Epoch: 6| Step: 3
Training loss: 0.635101886595223
Validation loss: 2.6239852662829604

Epoch: 6| Step: 4
Training loss: 0.44634224806385125
Validation loss: 2.5707917858579883

Epoch: 6| Step: 5
Training loss: 0.43461900073988735
Validation loss: 2.578598918593198

Epoch: 6| Step: 6
Training loss: 0.4545056257896435
Validation loss: 2.5852690307553035

Epoch: 6| Step: 7
Training loss: 0.34724764439447786
Validation loss: 2.5833716877588575

Epoch: 6| Step: 8
Training loss: 0.6481086632519053
Validation loss: 2.518146327272402

Epoch: 6| Step: 9
Training loss: 0.6565005414543621
Validation loss: 2.5749291025228698

Epoch: 6| Step: 10
Training loss: 0.5291043033296517
Validation loss: 2.5634528158702348

Epoch: 6| Step: 11
Training loss: 0.4494279788837211
Validation loss: 2.5650909854909836

Epoch: 6| Step: 12
Training loss: 0.49815377976716996
Validation loss: 2.584312096423543

Epoch: 6| Step: 13
Training loss: 0.5875423071217327
Validation loss: 2.592235699867712

Epoch: 318| Step: 0
Training loss: 0.8346054301873465
Validation loss: 2.6024556569161716

Epoch: 6| Step: 1
Training loss: 0.49421618943059137
Validation loss: 2.599836833588958

Epoch: 6| Step: 2
Training loss: 0.7177557495429013
Validation loss: 2.6184014017892734

Epoch: 6| Step: 3
Training loss: 0.5846220126806723
Validation loss: 2.605085891100615

Epoch: 6| Step: 4
Training loss: 0.6703153294501354
Validation loss: 2.5970913214981928

Epoch: 6| Step: 5
Training loss: 0.6256330621830591
Validation loss: 2.62542541072595

Epoch: 6| Step: 6
Training loss: 0.5807833510867074
Validation loss: 2.63091439819947

Epoch: 6| Step: 7
Training loss: 0.34796137760404916
Validation loss: 2.604245046769153

Epoch: 6| Step: 8
Training loss: 0.4906226516473052
Validation loss: 2.6137120951991895

Epoch: 6| Step: 9
Training loss: 0.39271833278900664
Validation loss: 2.5748326982069347

Epoch: 6| Step: 10
Training loss: 0.4427020539979094
Validation loss: 2.588813802261731

Epoch: 6| Step: 11
Training loss: 0.41913963026229123
Validation loss: 2.5807996512003224

Epoch: 6| Step: 12
Training loss: 0.2936954640430793
Validation loss: 2.5660661942932053

Epoch: 6| Step: 13
Training loss: 0.2138253262454795
Validation loss: 2.559668732873987

Epoch: 319| Step: 0
Training loss: 0.47415726717173123
Validation loss: 2.5965971098932448

Epoch: 6| Step: 1
Training loss: 0.6550073438698628
Validation loss: 2.5826800486591455

Epoch: 6| Step: 2
Training loss: 0.5015417409623563
Validation loss: 2.606590138277557

Epoch: 6| Step: 3
Training loss: 0.9978557187119079
Validation loss: 2.6044170615297717

Epoch: 6| Step: 4
Training loss: 0.44167579590461264
Validation loss: 2.604404774926998

Epoch: 6| Step: 5
Training loss: 0.6340949638407345
Validation loss: 2.5712001576991463

Epoch: 6| Step: 6
Training loss: 0.44262432722521555
Validation loss: 2.5316179889916883

Epoch: 6| Step: 7
Training loss: 0.5726213879141376
Validation loss: 2.5743891731340915

Epoch: 6| Step: 8
Training loss: 0.25512258717574865
Validation loss: 2.568068176453378

Epoch: 6| Step: 9
Training loss: 0.4425944817694613
Validation loss: 2.5762119209401084

Epoch: 6| Step: 10
Training loss: 0.3550349512490692
Validation loss: 2.5611210436003287

Epoch: 6| Step: 11
Training loss: 0.4082794118169025
Validation loss: 2.580867508120843

Epoch: 6| Step: 12
Training loss: 0.48939595965618365
Validation loss: 2.561548066721883

Epoch: 6| Step: 13
Training loss: 0.27413097726625646
Validation loss: 2.5946721240263857

Epoch: 320| Step: 0
Training loss: 0.513585565662541
Validation loss: 2.624541387620657

Epoch: 6| Step: 1
Training loss: 0.6126659246418762
Validation loss: 2.61089811377783

Epoch: 6| Step: 2
Training loss: 0.24144051317926402
Validation loss: 2.6024385811464623

Epoch: 6| Step: 3
Training loss: 0.4755420547073097
Validation loss: 2.613421966400275

Epoch: 6| Step: 4
Training loss: 0.26899871185235386
Validation loss: 2.5974744191703865

Epoch: 6| Step: 5
Training loss: 0.5511075399310443
Validation loss: 2.616359992135793

Epoch: 6| Step: 6
Training loss: 0.9266432921516995
Validation loss: 2.589682643615192

Epoch: 6| Step: 7
Training loss: 0.4796851366214746
Validation loss: 2.5779853790452076

Epoch: 6| Step: 8
Training loss: 0.4958396621374996
Validation loss: 2.5716162674279057

Epoch: 6| Step: 9
Training loss: 0.29041997384076945
Validation loss: 2.5776831866394696

Epoch: 6| Step: 10
Training loss: 0.6571352528234284
Validation loss: 2.5634386037896233

Epoch: 6| Step: 11
Training loss: 0.33352592859818736
Validation loss: 2.588533477529257

Epoch: 6| Step: 12
Training loss: 0.5455776083903059
Validation loss: 2.5827217049515467

Epoch: 6| Step: 13
Training loss: 0.44856634448932514
Validation loss: 2.5697840697762246

Epoch: 321| Step: 0
Training loss: 0.46572003194845873
Validation loss: 2.587461504224564

Epoch: 6| Step: 1
Training loss: 0.6158759994808424
Validation loss: 2.5968970440914076

Epoch: 6| Step: 2
Training loss: 0.4494935563466837
Validation loss: 2.569909090132642

Epoch: 6| Step: 3
Training loss: 0.3833600818416842
Validation loss: 2.5857364983011717

Epoch: 6| Step: 4
Training loss: 0.74399390989549
Validation loss: 2.615901255175939

Epoch: 6| Step: 5
Training loss: 0.3680347245797266
Validation loss: 2.5883733216335894

Epoch: 6| Step: 6
Training loss: 0.3899274319600723
Validation loss: 2.61672797885302

Epoch: 6| Step: 7
Training loss: 0.5123328680736652
Validation loss: 2.580448268998497

Epoch: 6| Step: 8
Training loss: 0.397879171935035
Validation loss: 2.5566951442849764

Epoch: 6| Step: 9
Training loss: 0.36297910697700203
Validation loss: 2.5742920983003725

Epoch: 6| Step: 10
Training loss: 0.41544542950861446
Validation loss: 2.56920017251623

Epoch: 6| Step: 11
Training loss: 0.3944948765067845
Validation loss: 2.584280299614279

Epoch: 6| Step: 12
Training loss: 0.3887744365690264
Validation loss: 2.581980009071474

Epoch: 6| Step: 13
Training loss: 1.23619177670585
Validation loss: 2.5566135449149106

Epoch: 322| Step: 0
Training loss: 0.45669830453991056
Validation loss: 2.587256430528699

Epoch: 6| Step: 1
Training loss: 0.2390925245192551
Validation loss: 2.6530567178520337

Epoch: 6| Step: 2
Training loss: 0.4284264352595339
Validation loss: 2.6349005734723283

Epoch: 6| Step: 3
Training loss: 0.29866786474139456
Validation loss: 2.6246256309870675

Epoch: 6| Step: 4
Training loss: 0.48480159678314233
Validation loss: 2.6084352554426444

Epoch: 6| Step: 5
Training loss: 0.5559722903657117
Validation loss: 2.6286566287489532

Epoch: 6| Step: 6
Training loss: 0.5551580125956278
Validation loss: 2.5887496474149407

Epoch: 6| Step: 7
Training loss: 0.8329301375278888
Validation loss: 2.557253248568026

Epoch: 6| Step: 8
Training loss: 0.4125421430272103
Validation loss: 2.5783845872104836

Epoch: 6| Step: 9
Training loss: 0.4404768823344518
Validation loss: 2.5922658672012284

Epoch: 6| Step: 10
Training loss: 0.6228439335372292
Validation loss: 2.5550656086049264

Epoch: 6| Step: 11
Training loss: 0.39724279317446365
Validation loss: 2.5818818995349075

Epoch: 6| Step: 12
Training loss: 0.6302395542282364
Validation loss: 2.6071104524837074

Epoch: 6| Step: 13
Training loss: 0.27576642739551366
Validation loss: 2.5608957562850367

Epoch: 323| Step: 0
Training loss: 0.20008324068046923
Validation loss: 2.567127029109882

Epoch: 6| Step: 1
Training loss: 0.5068088296392067
Validation loss: 2.5265642495634766

Epoch: 6| Step: 2
Training loss: 0.33555393722260946
Validation loss: 2.5754255604017815

Epoch: 6| Step: 3
Training loss: 0.49950727384347804
Validation loss: 2.5924373605954045

Epoch: 6| Step: 4
Training loss: 0.4987559039978272
Validation loss: 2.5953850858682506

Epoch: 6| Step: 5
Training loss: 0.45843537957468833
Validation loss: 2.5823093037656824

Epoch: 6| Step: 6
Training loss: 0.5112229777518721
Validation loss: 2.583447082375773

Epoch: 6| Step: 7
Training loss: 0.8493177242209613
Validation loss: 2.5786113579819028

Epoch: 6| Step: 8
Training loss: 0.36605162143288245
Validation loss: 2.5466411449744006

Epoch: 6| Step: 9
Training loss: 0.6115019919705327
Validation loss: 2.5876467641303647

Epoch: 6| Step: 10
Training loss: 0.39479962276336367
Validation loss: 2.5888133665401765

Epoch: 6| Step: 11
Training loss: 0.5211992663111906
Validation loss: 2.567955650322309

Epoch: 6| Step: 12
Training loss: 0.46304331647298164
Validation loss: 2.5833901704403304

Epoch: 6| Step: 13
Training loss: 0.48890664295389213
Validation loss: 2.607542800511148

Epoch: 324| Step: 0
Training loss: 0.4282514329764937
Validation loss: 2.555408657103002

Epoch: 6| Step: 1
Training loss: 0.4076564724191605
Validation loss: 2.6011837170472005

Epoch: 6| Step: 2
Training loss: 0.6765535825357528
Validation loss: 2.585562174857479

Epoch: 6| Step: 3
Training loss: 0.5287493023518318
Validation loss: 2.5634609114505578

Epoch: 6| Step: 4
Training loss: 0.3716372074261153
Validation loss: 2.5970756711579117

Epoch: 6| Step: 5
Training loss: 0.5642420496179794
Validation loss: 2.556191339859487

Epoch: 6| Step: 6
Training loss: 0.2551635131923462
Validation loss: 2.5638649049406963

Epoch: 6| Step: 7
Training loss: 0.5859822065464169
Validation loss: 2.557810556541038

Epoch: 6| Step: 8
Training loss: 0.5137960189665106
Validation loss: 2.5247810901612406

Epoch: 6| Step: 9
Training loss: 0.37081746306731556
Validation loss: 2.5777591767710817

Epoch: 6| Step: 10
Training loss: 0.7319690576147255
Validation loss: 2.5467675034931965

Epoch: 6| Step: 11
Training loss: 0.44806305208410285
Validation loss: 2.5906742182264115

Epoch: 6| Step: 12
Training loss: 0.26447569216929623
Validation loss: 2.583837375299859

Epoch: 6| Step: 13
Training loss: 0.37354682455350935
Validation loss: 2.580818838702309

Epoch: 325| Step: 0
Training loss: 0.3814584959284326
Validation loss: 2.589514889211598

Epoch: 6| Step: 1
Training loss: 0.598936716325405
Validation loss: 2.5716896285227144

Epoch: 6| Step: 2
Training loss: 0.3979122589359854
Validation loss: 2.5787994844893904

Epoch: 6| Step: 3
Training loss: 0.7643498291961685
Validation loss: 2.5765269171958773

Epoch: 6| Step: 4
Training loss: 0.5191230891518865
Validation loss: 2.619062508936409

Epoch: 6| Step: 5
Training loss: 0.3541825889299429
Validation loss: 2.5798738406860395

Epoch: 6| Step: 6
Training loss: 0.5150171511766266
Validation loss: 2.57909416013187

Epoch: 6| Step: 7
Training loss: 0.28250758821288585
Validation loss: 2.586151528089902

Epoch: 6| Step: 8
Training loss: 0.6828141699100562
Validation loss: 2.5654720735702305

Epoch: 6| Step: 9
Training loss: 0.3826860296796495
Validation loss: 2.5899493069236392

Epoch: 6| Step: 10
Training loss: 0.40636959516345006
Validation loss: 2.6159478861644954

Epoch: 6| Step: 11
Training loss: 0.44292894551233264
Validation loss: 2.628277940616328

Epoch: 6| Step: 12
Training loss: 0.3781269751252852
Validation loss: 2.6022461127242695

Epoch: 6| Step: 13
Training loss: 0.536669686419519
Validation loss: 2.62179639001935

Epoch: 326| Step: 0
Training loss: 0.41506272192444893
Validation loss: 2.5628327464538843

Epoch: 6| Step: 1
Training loss: 0.3053441430115584
Validation loss: 2.589002046918939

Epoch: 6| Step: 2
Training loss: 0.5484581239740443
Validation loss: 2.574112876669204

Epoch: 6| Step: 3
Training loss: 0.23603919786900052
Validation loss: 2.563833564490817

Epoch: 6| Step: 4
Training loss: 0.4787629870005325
Validation loss: 2.561813544672168

Epoch: 6| Step: 5
Training loss: 0.45375743665459767
Validation loss: 2.590332521644204

Epoch: 6| Step: 6
Training loss: 0.4837321661094083
Validation loss: 2.590878655286831

Epoch: 6| Step: 7
Training loss: 0.6540226375864525
Validation loss: 2.6042654436308146

Epoch: 6| Step: 8
Training loss: 0.8762369268642056
Validation loss: 2.636187857927123

Epoch: 6| Step: 9
Training loss: 0.6450768213581164
Validation loss: 2.607015709226529

Epoch: 6| Step: 10
Training loss: 0.4841724710669166
Validation loss: 2.610632721217643

Epoch: 6| Step: 11
Training loss: 0.47632837016165197
Validation loss: 2.6368319739821677

Epoch: 6| Step: 12
Training loss: 0.2670132040641435
Validation loss: 2.6450981203531616

Epoch: 6| Step: 13
Training loss: 0.4722767401839427
Validation loss: 2.60639638693508

Epoch: 327| Step: 0
Training loss: 0.7087545731815763
Validation loss: 2.6035907927354494

Epoch: 6| Step: 1
Training loss: 0.39710305712663146
Validation loss: 2.5726562629943026

Epoch: 6| Step: 2
Training loss: 0.5481385484019266
Validation loss: 2.623232080613007

Epoch: 6| Step: 3
Training loss: 0.36938004575791156
Validation loss: 2.64362700227691

Epoch: 6| Step: 4
Training loss: 0.7710033220721761
Validation loss: 2.6187849277762583

Epoch: 6| Step: 5
Training loss: 0.34335295548584266
Validation loss: 2.6416272628183295

Epoch: 6| Step: 6
Training loss: 0.3507486884758071
Validation loss: 2.629614879643752

Epoch: 6| Step: 7
Training loss: 0.1950514574809065
Validation loss: 2.641328656122628

Epoch: 6| Step: 8
Training loss: 0.21173432634212466
Validation loss: 2.6281764719470786

Epoch: 6| Step: 9
Training loss: 0.3634647603196869
Validation loss: 2.627329721784416

Epoch: 6| Step: 10
Training loss: 0.4686930144957572
Validation loss: 2.634870057523714

Epoch: 6| Step: 11
Training loss: 0.37291967010709315
Validation loss: 2.622100117031406

Epoch: 6| Step: 12
Training loss: 0.7007299534151656
Validation loss: 2.597788495887127

Epoch: 6| Step: 13
Training loss: 0.692469151632641
Validation loss: 2.6206302064517892

Epoch: 328| Step: 0
Training loss: 0.49132155884855777
Validation loss: 2.5829342253623184

Epoch: 6| Step: 1
Training loss: 0.5586395778397056
Validation loss: 2.6063789064112477

Epoch: 6| Step: 2
Training loss: 0.408974716815749
Validation loss: 2.59999878881756

Epoch: 6| Step: 3
Training loss: 0.36291017346243265
Validation loss: 2.6259144324633334

Epoch: 6| Step: 4
Training loss: 0.4692783398156644
Validation loss: 2.628465338877613

Epoch: 6| Step: 5
Training loss: 0.7271055427664235
Validation loss: 2.6559481165131196

Epoch: 6| Step: 6
Training loss: 0.4716151254511441
Validation loss: 2.6309799146136514

Epoch: 6| Step: 7
Training loss: 0.39951798782148223
Validation loss: 2.665862731984852

Epoch: 6| Step: 8
Training loss: 0.5807894830784699
Validation loss: 2.6427916630215957

Epoch: 6| Step: 9
Training loss: 0.5614656899653805
Validation loss: 2.65012355631718

Epoch: 6| Step: 10
Training loss: 0.3295672486648759
Validation loss: 2.614745186338827

Epoch: 6| Step: 11
Training loss: 0.45679862468156696
Validation loss: 2.572823965744092

Epoch: 6| Step: 12
Training loss: 0.4062653318593134
Validation loss: 2.5957299632041897

Epoch: 6| Step: 13
Training loss: 0.21377204276640188
Validation loss: 2.5692086391414404

Epoch: 329| Step: 0
Training loss: 0.47858280566657646
Validation loss: 2.549282287888121

Epoch: 6| Step: 1
Training loss: 0.20252196038343964
Validation loss: 2.5550848940395254

Epoch: 6| Step: 2
Training loss: 0.2368700104442083
Validation loss: 2.5645041853090715

Epoch: 6| Step: 3
Training loss: 0.5981155575332792
Validation loss: 2.541036589937058

Epoch: 6| Step: 4
Training loss: 0.6690118464217915
Validation loss: 2.5474148765756213

Epoch: 6| Step: 5
Training loss: 0.33930204780600365
Validation loss: 2.5509728167537324

Epoch: 6| Step: 6
Training loss: 0.3569868181156474
Validation loss: 2.6054633269758063

Epoch: 6| Step: 7
Training loss: 0.31665526116477555
Validation loss: 2.57779908666772

Epoch: 6| Step: 8
Training loss: 0.35577459068583056
Validation loss: 2.559787775545441

Epoch: 6| Step: 9
Training loss: 0.7191304153803424
Validation loss: 2.5366339092875827

Epoch: 6| Step: 10
Training loss: 0.6702840732335555
Validation loss: 2.5916346673803816

Epoch: 6| Step: 11
Training loss: 0.4155522662890796
Validation loss: 2.5656209768709126

Epoch: 6| Step: 12
Training loss: 0.35091544050553386
Validation loss: 2.541578022664974

Epoch: 6| Step: 13
Training loss: 0.3052443770563228
Validation loss: 2.574106458877273

Epoch: 330| Step: 0
Training loss: 0.22871624055182363
Validation loss: 2.5976463463867647

Epoch: 6| Step: 1
Training loss: 0.46920601597902406
Validation loss: 2.588168592579492

Epoch: 6| Step: 2
Training loss: 0.7000422396858352
Validation loss: 2.584641383131055

Epoch: 6| Step: 3
Training loss: 0.3672819827651906
Validation loss: 2.588279011752102

Epoch: 6| Step: 4
Training loss: 0.6072082879969037
Validation loss: 2.599793401442176

Epoch: 6| Step: 5
Training loss: 0.308814669855644
Validation loss: 2.5836585955196356

Epoch: 6| Step: 6
Training loss: 0.46613879882221554
Validation loss: 2.607112605967718

Epoch: 6| Step: 7
Training loss: 0.3860057654604946
Validation loss: 2.61396611721166

Epoch: 6| Step: 8
Training loss: 0.44677050642608024
Validation loss: 2.6117539918771304

Epoch: 6| Step: 9
Training loss: 0.5723721141488344
Validation loss: 2.5791985810600235

Epoch: 6| Step: 10
Training loss: 0.5347312854918027
Validation loss: 2.5799410084934826

Epoch: 6| Step: 11
Training loss: 0.2949933350747658
Validation loss: 2.563466001802363

Epoch: 6| Step: 12
Training loss: 0.4549317022038805
Validation loss: 2.5255617748759867

Epoch: 6| Step: 13
Training loss: 0.2900792874272627
Validation loss: 2.5507628697375377

Epoch: 331| Step: 0
Training loss: 0.5860177557341634
Validation loss: 2.5295755896444696

Epoch: 6| Step: 1
Training loss: 0.22555303952996253
Validation loss: 2.5187695843164146

Epoch: 6| Step: 2
Training loss: 0.2934052077248576
Validation loss: 2.5255529325214296

Epoch: 6| Step: 3
Training loss: 0.39496194351335284
Validation loss: 2.552230230694845

Epoch: 6| Step: 4
Training loss: 0.3340338954686949
Validation loss: 2.5648188410087585

Epoch: 6| Step: 5
Training loss: 0.43201754584487817
Validation loss: 2.55675664215922

Epoch: 6| Step: 6
Training loss: 0.46160253943851337
Validation loss: 2.559366786780888

Epoch: 6| Step: 7
Training loss: 0.3524193811550371
Validation loss: 2.571553306031248

Epoch: 6| Step: 8
Training loss: 0.48006509091194977
Validation loss: 2.5876720036612073

Epoch: 6| Step: 9
Training loss: 0.4985653142372633
Validation loss: 2.6005634810277947

Epoch: 6| Step: 10
Training loss: 0.34973551429924615
Validation loss: 2.6063633359382132

Epoch: 6| Step: 11
Training loss: 0.7644304571362966
Validation loss: 2.573481221108471

Epoch: 6| Step: 12
Training loss: 0.5341804964662664
Validation loss: 2.5936693005264466

Epoch: 6| Step: 13
Training loss: 0.44160951306062507
Validation loss: 2.597781659933363

Epoch: 332| Step: 0
Training loss: 0.5324961128451173
Validation loss: 2.5821781182145154

Epoch: 6| Step: 1
Training loss: 0.5716522887936245
Validation loss: 2.6161974382809565

Epoch: 6| Step: 2
Training loss: 0.40138188912969863
Validation loss: 2.571647843996937

Epoch: 6| Step: 3
Training loss: 0.5695585205079753
Validation loss: 2.579279475361133

Epoch: 6| Step: 4
Training loss: 0.5235181148568328
Validation loss: 2.5978324046436048

Epoch: 6| Step: 5
Training loss: 0.23292584636309685
Validation loss: 2.554856952186435

Epoch: 6| Step: 6
Training loss: 0.19603753937043014
Validation loss: 2.5686953356039504

Epoch: 6| Step: 7
Training loss: 0.4547896555554526
Validation loss: 2.5217739930928333

Epoch: 6| Step: 8
Training loss: 0.5283230765617679
Validation loss: 2.5131437793215325

Epoch: 6| Step: 9
Training loss: 0.5222920082293037
Validation loss: 2.521756583214162

Epoch: 6| Step: 10
Training loss: 0.18736629884887115
Validation loss: 2.5144284010730393

Epoch: 6| Step: 11
Training loss: 0.4527371818712197
Validation loss: 2.5064700992166613

Epoch: 6| Step: 12
Training loss: 0.3415747002170411
Validation loss: 2.542453003405239

Epoch: 6| Step: 13
Training loss: 0.8598445996448909
Validation loss: 2.536157476525961

Epoch: 333| Step: 0
Training loss: 0.2768901957912249
Validation loss: 2.5408836397875665

Epoch: 6| Step: 1
Training loss: 0.3846014805490519
Validation loss: 2.557501072049233

Epoch: 6| Step: 2
Training loss: 0.45201547204180903
Validation loss: 2.5720480527570997

Epoch: 6| Step: 3
Training loss: 0.3739210342181622
Validation loss: 2.5606382876855984

Epoch: 6| Step: 4
Training loss: 0.5190928911547967
Validation loss: 2.5688988412769134

Epoch: 6| Step: 5
Training loss: 0.3421680070385056
Validation loss: 2.596624324397071

Epoch: 6| Step: 6
Training loss: 0.5607052356711604
Validation loss: 2.578782524716705

Epoch: 6| Step: 7
Training loss: 0.5186647057788347
Validation loss: 2.574078311631255

Epoch: 6| Step: 8
Training loss: 0.7513751694662093
Validation loss: 2.5700497837566814

Epoch: 6| Step: 9
Training loss: 0.6091470047334239
Validation loss: 2.576367064470745

Epoch: 6| Step: 10
Training loss: 0.4461941106776506
Validation loss: 2.564018442911325

Epoch: 6| Step: 11
Training loss: 0.2953782497861669
Validation loss: 2.585299399367777

Epoch: 6| Step: 12
Training loss: 0.4518902166925376
Validation loss: 2.5971447014347357

Epoch: 6| Step: 13
Training loss: 0.5670356936161087
Validation loss: 2.606457725216901

Epoch: 334| Step: 0
Training loss: 0.37381967915687386
Validation loss: 2.581144146272199

Epoch: 6| Step: 1
Training loss: 0.5770241075781797
Validation loss: 2.5731480762455865

Epoch: 6| Step: 2
Training loss: 0.6777881304175211
Validation loss: 2.5665488092456408

Epoch: 6| Step: 3
Training loss: 0.30620758191058595
Validation loss: 2.592172696834699

Epoch: 6| Step: 4
Training loss: 0.3079395482208286
Validation loss: 2.486251519643833

Epoch: 6| Step: 5
Training loss: 0.6030040165022508
Validation loss: 2.503015893029979

Epoch: 6| Step: 6
Training loss: 0.2878391825498193
Validation loss: 2.4703478509303123

Epoch: 6| Step: 7
Training loss: 0.5675179981957066
Validation loss: 2.509963829105271

Epoch: 6| Step: 8
Training loss: 0.53732400940543
Validation loss: 2.4729010716031814

Epoch: 6| Step: 9
Training loss: 0.6995079678428638
Validation loss: 2.4791789031732834

Epoch: 6| Step: 10
Training loss: 0.658215576416328
Validation loss: 2.546216558382735

Epoch: 6| Step: 11
Training loss: 0.6004984474035007
Validation loss: 2.5532621961250115

Epoch: 6| Step: 12
Training loss: 0.6187019117530203
Validation loss: 2.600632020964829

Epoch: 6| Step: 13
Training loss: 0.6621562299775648
Validation loss: 2.613666834798109

Epoch: 335| Step: 0
Training loss: 0.7840028328236179
Validation loss: 2.5990204294546135

Epoch: 6| Step: 1
Training loss: 0.7467133510703334
Validation loss: 2.6223002534474453

Epoch: 6| Step: 2
Training loss: 1.0815746018582193
Validation loss: 2.581492535438213

Epoch: 6| Step: 3
Training loss: 0.9980969799028543
Validation loss: 2.5398054854857035

Epoch: 6| Step: 4
Training loss: 0.5465212631591313
Validation loss: 2.497538688584437

Epoch: 6| Step: 5
Training loss: 0.7054360239542923
Validation loss: 2.498765009738785

Epoch: 6| Step: 6
Training loss: 0.6016639524840673
Validation loss: 2.5273861357614615

Epoch: 6| Step: 7
Training loss: 0.5998848148885589
Validation loss: 2.548737209083002

Epoch: 6| Step: 8
Training loss: 0.446477336944884
Validation loss: 2.5337676877588926

Epoch: 6| Step: 9
Training loss: 0.4839582188321899
Validation loss: 2.6035773994135374

Epoch: 6| Step: 10
Training loss: 0.6119000864000504
Validation loss: 2.59138318316255

Epoch: 6| Step: 11
Training loss: 0.8037492040745902
Validation loss: 2.588754508796603

Epoch: 6| Step: 12
Training loss: 0.39117255934405326
Validation loss: 2.560855528898129

Epoch: 6| Step: 13
Training loss: 0.4500836049669832
Validation loss: 2.5317274296884653

Epoch: 336| Step: 0
Training loss: 0.6312842576957189
Validation loss: 2.5871966178148775

Epoch: 6| Step: 1
Training loss: 0.607853457093251
Validation loss: 2.541095731213348

Epoch: 6| Step: 2
Training loss: 0.7887591543739468
Validation loss: 2.554863654391128

Epoch: 6| Step: 3
Training loss: 0.9573311783388672
Validation loss: 2.576388864160007

Epoch: 6| Step: 4
Training loss: 1.1674365614129558
Validation loss: 2.622311924374053

Epoch: 6| Step: 5
Training loss: 0.8767717679434849
Validation loss: 2.7071362262740775

Epoch: 6| Step: 6
Training loss: 0.6865615508568254
Validation loss: 2.755487292317264

Epoch: 6| Step: 7
Training loss: 0.7848897453195189
Validation loss: 2.6501948792863006

Epoch: 6| Step: 8
Training loss: 0.8281479238540189
Validation loss: 2.5623357206439636

Epoch: 6| Step: 9
Training loss: 0.4184653282455786
Validation loss: 2.4531670754809043

Epoch: 6| Step: 10
Training loss: 0.6439495814294445
Validation loss: 2.4459572879313107

Epoch: 6| Step: 11
Training loss: 0.8782194378663541
Validation loss: 2.447110967757294

Epoch: 6| Step: 12
Training loss: 0.7659194146662728
Validation loss: 2.474992269228598

Epoch: 6| Step: 13
Training loss: 0.8661679985129612
Validation loss: 2.4771265125412145

Epoch: 337| Step: 0
Training loss: 0.6849239377442927
Validation loss: 2.490176676227116

Epoch: 6| Step: 1
Training loss: 0.6703063484389797
Validation loss: 2.4576346969097784

Epoch: 6| Step: 2
Training loss: 0.4105026961782847
Validation loss: 2.458730765270703

Epoch: 6| Step: 3
Training loss: 0.576974548892525
Validation loss: 2.4567664566012706

Epoch: 6| Step: 4
Training loss: 0.6441695151897319
Validation loss: 2.4986347223690197

Epoch: 6| Step: 5
Training loss: 0.5644014592268104
Validation loss: 2.5335830668064734

Epoch: 6| Step: 6
Training loss: 0.6477083909934594
Validation loss: 2.577787752240336

Epoch: 6| Step: 7
Training loss: 0.7512485919247347
Validation loss: 2.597948843038035

Epoch: 6| Step: 8
Training loss: 0.583264216233838
Validation loss: 2.615275775473562

Epoch: 6| Step: 9
Training loss: 0.46085628505252274
Validation loss: 2.673810614554285

Epoch: 6| Step: 10
Training loss: 0.6552259993685886
Validation loss: 2.655521014348717

Epoch: 6| Step: 11
Training loss: 0.5094349983780099
Validation loss: 2.619287272058775

Epoch: 6| Step: 12
Training loss: 0.5514819780744284
Validation loss: 2.6019817067390667

Epoch: 6| Step: 13
Training loss: 0.677540160392956
Validation loss: 2.5606330655645144

Epoch: 338| Step: 0
Training loss: 0.6974391347382427
Validation loss: 2.5733530618469356

Epoch: 6| Step: 1
Training loss: 0.5025298964683419
Validation loss: 2.571648405243891

Epoch: 6| Step: 2
Training loss: 0.38526763698152927
Validation loss: 2.528845610933143

Epoch: 6| Step: 3
Training loss: 0.600200399072496
Validation loss: 2.5173653124325246

Epoch: 6| Step: 4
Training loss: 0.7040130940595927
Validation loss: 2.4909645760431087

Epoch: 6| Step: 5
Training loss: 0.5619620293758063
Validation loss: 2.5508459200735483

Epoch: 6| Step: 6
Training loss: 0.6538131292070447
Validation loss: 2.53904319484493

Epoch: 6| Step: 7
Training loss: 0.5421124299157499
Validation loss: 2.509459648379563

Epoch: 6| Step: 8
Training loss: 0.4099123638395391
Validation loss: 2.5376760933606746

Epoch: 6| Step: 9
Training loss: 0.6049356882734469
Validation loss: 2.57002670784303

Epoch: 6| Step: 10
Training loss: 0.774333858305345
Validation loss: 2.5594946612714295

Epoch: 6| Step: 11
Training loss: 0.5265270549492266
Validation loss: 2.623779207350101

Epoch: 6| Step: 12
Training loss: 0.556119601363466
Validation loss: 2.599924567862173

Epoch: 6| Step: 13
Training loss: 0.39577557953915055
Validation loss: 2.602834592356072

Epoch: 339| Step: 0
Training loss: 0.6661530741600542
Validation loss: 2.6439010298868104

Epoch: 6| Step: 1
Training loss: 0.484583594414249
Validation loss: 2.6405000171037947

Epoch: 6| Step: 2
Training loss: 0.6645465208837765
Validation loss: 2.598808751992824

Epoch: 6| Step: 3
Training loss: 0.7646852291994788
Validation loss: 2.5744336522612663

Epoch: 6| Step: 4
Training loss: 0.49961668461037345
Validation loss: 2.567280168276147

Epoch: 6| Step: 5
Training loss: 0.5858732061079888
Validation loss: 2.534586376850874

Epoch: 6| Step: 6
Training loss: 0.4205529549726296
Validation loss: 2.5247349853927306

Epoch: 6| Step: 7
Training loss: 0.5382105688188601
Validation loss: 2.508085044690042

Epoch: 6| Step: 8
Training loss: 0.5737096125281652
Validation loss: 2.510567271292144

Epoch: 6| Step: 9
Training loss: 0.7645525135269644
Validation loss: 2.4748553132571525

Epoch: 6| Step: 10
Training loss: 0.7113671733564405
Validation loss: 2.473391119413464

Epoch: 6| Step: 11
Training loss: 0.531647589509684
Validation loss: 2.4795850251026725

Epoch: 6| Step: 12
Training loss: 0.637410963610059
Validation loss: 2.538653889000989

Epoch: 6| Step: 13
Training loss: 0.33494363189568194
Validation loss: 2.53223793988983

Epoch: 340| Step: 0
Training loss: 0.36775490364135166
Validation loss: 2.565947070233396

Epoch: 6| Step: 1
Training loss: 0.6949032211158789
Validation loss: 2.5949957700365287

Epoch: 6| Step: 2
Training loss: 0.6007361743620354
Validation loss: 2.6588936011030024

Epoch: 6| Step: 3
Training loss: 0.4661358738124748
Validation loss: 2.642122868457975

Epoch: 6| Step: 4
Training loss: 0.6768998166340318
Validation loss: 2.6185668954132897

Epoch: 6| Step: 5
Training loss: 0.47932885023685756
Validation loss: 2.629109329912318

Epoch: 6| Step: 6
Training loss: 0.4706015417881509
Validation loss: 2.6376507007892713

Epoch: 6| Step: 7
Training loss: 0.6931137724535481
Validation loss: 2.5924883651666137

Epoch: 6| Step: 8
Training loss: 0.5176512468616108
Validation loss: 2.6051361500928425

Epoch: 6| Step: 9
Training loss: 0.28472310966777253
Validation loss: 2.5518425438410537

Epoch: 6| Step: 10
Training loss: 0.22619474094476633
Validation loss: 2.5859267812026596

Epoch: 6| Step: 11
Training loss: 0.623873314985332
Validation loss: 2.5252594687688634

Epoch: 6| Step: 12
Training loss: 0.3501755163636536
Validation loss: 2.5507341854893864

Epoch: 6| Step: 13
Training loss: 0.4793098087322284
Validation loss: 2.5477191294443133

Epoch: 341| Step: 0
Training loss: 0.5272893524370336
Validation loss: 2.5772424693225817

Epoch: 6| Step: 1
Training loss: 0.6461601020294875
Validation loss: 2.5501877965104676

Epoch: 6| Step: 2
Training loss: 0.37385399867397956
Validation loss: 2.543348227829195

Epoch: 6| Step: 3
Training loss: 0.4391999087368761
Validation loss: 2.585696750576264

Epoch: 6| Step: 4
Training loss: 0.3795511322655873
Validation loss: 2.5562849120490823

Epoch: 6| Step: 5
Training loss: 0.3636032031461107
Validation loss: 2.566698946534755

Epoch: 6| Step: 6
Training loss: 0.7107226707418449
Validation loss: 2.5730917863825056

Epoch: 6| Step: 7
Training loss: 0.3885766492577311
Validation loss: 2.596888968833649

Epoch: 6| Step: 8
Training loss: 0.46496556392952043
Validation loss: 2.6012826400910485

Epoch: 6| Step: 9
Training loss: 0.37323776074813064
Validation loss: 2.5929200828514856

Epoch: 6| Step: 10
Training loss: 0.5986746046901849
Validation loss: 2.5820073791297045

Epoch: 6| Step: 11
Training loss: 0.2979882598874945
Validation loss: 2.6061810285817613

Epoch: 6| Step: 12
Training loss: 0.3264991351988061
Validation loss: 2.603788290448359

Epoch: 6| Step: 13
Training loss: 0.42902732766082774
Validation loss: 2.575719988025917

Epoch: 342| Step: 0
Training loss: 0.31100942843640567
Validation loss: 2.6339114701594033

Epoch: 6| Step: 1
Training loss: 0.47222686999813723
Validation loss: 2.6195833208995905

Epoch: 6| Step: 2
Training loss: 0.38851693673816606
Validation loss: 2.615406218851423

Epoch: 6| Step: 3
Training loss: 0.4793323631175112
Validation loss: 2.6214166609853815

Epoch: 6| Step: 4
Training loss: 0.25933524022365584
Validation loss: 2.5877911754096248

Epoch: 6| Step: 5
Training loss: 0.3533962322127086
Validation loss: 2.6191720534168277

Epoch: 6| Step: 6
Training loss: 0.29612891660220125
Validation loss: 2.5774983002031524

Epoch: 6| Step: 7
Training loss: 0.4492402610604162
Validation loss: 2.5908375308930496

Epoch: 6| Step: 8
Training loss: 0.5460047200421615
Validation loss: 2.6166966651005286

Epoch: 6| Step: 9
Training loss: 0.7779312214224497
Validation loss: 2.607313726650415

Epoch: 6| Step: 10
Training loss: 0.39289139352155533
Validation loss: 2.627155327371365

Epoch: 6| Step: 11
Training loss: 0.4713516200156641
Validation loss: 2.6513855404066504

Epoch: 6| Step: 12
Training loss: 0.23600205870817442
Validation loss: 2.6199429869391913

Epoch: 6| Step: 13
Training loss: 0.5717277472768851
Validation loss: 2.6268609155751617

Epoch: 343| Step: 0
Training loss: 0.4510043935667479
Validation loss: 2.6105171019368005

Epoch: 6| Step: 1
Training loss: 0.7236875855672884
Validation loss: 2.614781144287736

Epoch: 6| Step: 2
Training loss: 0.47918965104857814
Validation loss: 2.611375637752579

Epoch: 6| Step: 3
Training loss: 0.35928092637470127
Validation loss: 2.638398857976146

Epoch: 6| Step: 4
Training loss: 0.20695252091178126
Validation loss: 2.651152545462008

Epoch: 6| Step: 5
Training loss: 0.3967366097431524
Validation loss: 2.6108379520769103

Epoch: 6| Step: 6
Training loss: 0.36510693779880965
Validation loss: 2.6288261011896474

Epoch: 6| Step: 7
Training loss: 0.27933980705174677
Validation loss: 2.6066859345811983

Epoch: 6| Step: 8
Training loss: 0.3693460367275436
Validation loss: 2.553439222673157

Epoch: 6| Step: 9
Training loss: 0.5017041431202705
Validation loss: 2.5796018366106206

Epoch: 6| Step: 10
Training loss: 0.4882801208483038
Validation loss: 2.580199130285456

Epoch: 6| Step: 11
Training loss: 0.4018980724421376
Validation loss: 2.580553189972966

Epoch: 6| Step: 12
Training loss: 0.45989589676761156
Validation loss: 2.580429178090427

Epoch: 6| Step: 13
Training loss: 0.4839709657992867
Validation loss: 2.5868893110806326

Epoch: 344| Step: 0
Training loss: 0.6418772298296833
Validation loss: 2.5856499354199585

Epoch: 6| Step: 1
Training loss: 0.35833935159612107
Validation loss: 2.579376038483688

Epoch: 6| Step: 2
Training loss: 0.45407079777024084
Validation loss: 2.612198646224781

Epoch: 6| Step: 3
Training loss: 0.3127381371093857
Validation loss: 2.581632936412052

Epoch: 6| Step: 4
Training loss: 0.6104574615161233
Validation loss: 2.565831387699641

Epoch: 6| Step: 5
Training loss: 0.4323590027021502
Validation loss: 2.6030898915289233

Epoch: 6| Step: 6
Training loss: 0.36931099567891323
Validation loss: 2.600724959251386

Epoch: 6| Step: 7
Training loss: 0.4385525440066165
Validation loss: 2.563371935168825

Epoch: 6| Step: 8
Training loss: 0.3022522810147071
Validation loss: 2.573922951461351

Epoch: 6| Step: 9
Training loss: 0.3604901881926294
Validation loss: 2.5718214070194434

Epoch: 6| Step: 10
Training loss: 0.35546908535784316
Validation loss: 2.5462155404641327

Epoch: 6| Step: 11
Training loss: 0.3114470385201363
Validation loss: 2.526909089076589

Epoch: 6| Step: 12
Training loss: 0.40241448234354465
Validation loss: 2.5455645983617536

Epoch: 6| Step: 13
Training loss: 0.4405352514593565
Validation loss: 2.5628064060178115

Epoch: 345| Step: 0
Training loss: 0.5334976835888785
Validation loss: 2.6007089231710276

Epoch: 6| Step: 1
Training loss: 0.40319680084608406
Validation loss: 2.5807892011237055

Epoch: 6| Step: 2
Training loss: 0.4941356040488411
Validation loss: 2.586769972538559

Epoch: 6| Step: 3
Training loss: 0.3641870752125573
Validation loss: 2.5629946883723758

Epoch: 6| Step: 4
Training loss: 0.5416798834533183
Validation loss: 2.5528216739013025

Epoch: 6| Step: 5
Training loss: 0.3523077377557805
Validation loss: 2.532378945222748

Epoch: 6| Step: 6
Training loss: 0.4556281241164615
Validation loss: 2.539336847545158

Epoch: 6| Step: 7
Training loss: 0.4136204429114889
Validation loss: 2.5415862312950512

Epoch: 6| Step: 8
Training loss: 0.28242572765967405
Validation loss: 2.5636234516927456

Epoch: 6| Step: 9
Training loss: 0.29470387669159953
Validation loss: 2.546852968826395

Epoch: 6| Step: 10
Training loss: 0.5203462102927041
Validation loss: 2.53386596910317

Epoch: 6| Step: 11
Training loss: 0.3991933459953859
Validation loss: 2.5484941053009944

Epoch: 6| Step: 12
Training loss: 0.4409955401108575
Validation loss: 2.5948828451998978

Epoch: 6| Step: 13
Training loss: 0.3900489374170499
Validation loss: 2.5460677184544434

Epoch: 346| Step: 0
Training loss: 0.27441036995680673
Validation loss: 2.558935547090395

Epoch: 6| Step: 1
Training loss: 0.277888046008163
Validation loss: 2.6115099105755757

Epoch: 6| Step: 2
Training loss: 0.2810763246691822
Validation loss: 2.564047133522605

Epoch: 6| Step: 3
Training loss: 0.25862456077660073
Validation loss: 2.5532974395594827

Epoch: 6| Step: 4
Training loss: 0.2616225677938539
Validation loss: 2.5463075642995734

Epoch: 6| Step: 5
Training loss: 0.5521620358444577
Validation loss: 2.536748751523263

Epoch: 6| Step: 6
Training loss: 0.31038911279002246
Validation loss: 2.548142046590096

Epoch: 6| Step: 7
Training loss: 0.3821421612400905
Validation loss: 2.539167314737167

Epoch: 6| Step: 8
Training loss: 0.48486557083127124
Validation loss: 2.5704925411216752

Epoch: 6| Step: 9
Training loss: 0.36550065395907283
Validation loss: 2.5392772064427107

Epoch: 6| Step: 10
Training loss: 0.6183579368357703
Validation loss: 2.5339395425450024

Epoch: 6| Step: 11
Training loss: 0.727100255344804
Validation loss: 2.5714434562289084

Epoch: 6| Step: 12
Training loss: 0.40697877878848043
Validation loss: 2.5450076085613595

Epoch: 6| Step: 13
Training loss: 0.3771207565192786
Validation loss: 2.551932958341886

Epoch: 347| Step: 0
Training loss: 0.37843966514163335
Validation loss: 2.553600528979399

Epoch: 6| Step: 1
Training loss: 0.38403599684099854
Validation loss: 2.5524676092435103

Epoch: 6| Step: 2
Training loss: 0.5436455878497002
Validation loss: 2.5586971234208935

Epoch: 6| Step: 3
Training loss: 0.16472047607742027
Validation loss: 2.602204118761077

Epoch: 6| Step: 4
Training loss: 0.42146480893175986
Validation loss: 2.6027616731370284

Epoch: 6| Step: 5
Training loss: 0.353637126465229
Validation loss: 2.584688940114209

Epoch: 6| Step: 6
Training loss: 0.43077821148674883
Validation loss: 2.5840612230216435

Epoch: 6| Step: 7
Training loss: 0.22359938559104411
Validation loss: 2.609841560288653

Epoch: 6| Step: 8
Training loss: 0.39693110061986514
Validation loss: 2.559840273906968

Epoch: 6| Step: 9
Training loss: 0.44651841962482886
Validation loss: 2.5475650624810062

Epoch: 6| Step: 10
Training loss: 0.5282669463501763
Validation loss: 2.561894927381376

Epoch: 6| Step: 11
Training loss: 0.48004773930733585
Validation loss: 2.543431637700208

Epoch: 6| Step: 12
Training loss: 0.30040995482320265
Validation loss: 2.536276744345983

Epoch: 6| Step: 13
Training loss: 0.7190806416158959
Validation loss: 2.530772164192439

Epoch: 348| Step: 0
Training loss: 0.5333535118557449
Validation loss: 2.54740842750011

Epoch: 6| Step: 1
Training loss: 0.6215360494118876
Validation loss: 2.5612856100572228

Epoch: 6| Step: 2
Training loss: 0.48899621118158165
Validation loss: 2.5579466238663087

Epoch: 6| Step: 3
Training loss: 0.2828500058927193
Validation loss: 2.5921722725566703

Epoch: 6| Step: 4
Training loss: 0.2901638289259339
Validation loss: 2.599729280876167

Epoch: 6| Step: 5
Training loss: 0.3065017215507724
Validation loss: 2.6048877211678567

Epoch: 6| Step: 6
Training loss: 0.4683984868992294
Validation loss: 2.5723479108408918

Epoch: 6| Step: 7
Training loss: 0.4118848071283832
Validation loss: 2.555692747590999

Epoch: 6| Step: 8
Training loss: 0.4508439560882654
Validation loss: 2.5944212455002456

Epoch: 6| Step: 9
Training loss: 0.4119479690422983
Validation loss: 2.6019921919045097

Epoch: 6| Step: 10
Training loss: 0.3658858216669233
Validation loss: 2.5870185397729917

Epoch: 6| Step: 11
Training loss: 0.32566934122586866
Validation loss: 2.6286884456492743

Epoch: 6| Step: 12
Training loss: 0.2964997680849709
Validation loss: 2.609404736342607

Epoch: 6| Step: 13
Training loss: 0.20075919590513558
Validation loss: 2.611021097773235

Epoch: 349| Step: 0
Training loss: 0.46150353800862937
Validation loss: 2.619422456174798

Epoch: 6| Step: 1
Training loss: 0.24918908986066893
Validation loss: 2.6329597896169155

Epoch: 6| Step: 2
Training loss: 0.3316494934909196
Validation loss: 2.5984197661047674

Epoch: 6| Step: 3
Training loss: 0.3973019256060734
Validation loss: 2.6193677861476985

Epoch: 6| Step: 4
Training loss: 0.38148449190174305
Validation loss: 2.602508454732612

Epoch: 6| Step: 5
Training loss: 0.5463801733857283
Validation loss: 2.6071008689666257

Epoch: 6| Step: 6
Training loss: 0.4056843708007564
Validation loss: 2.5975866386911703

Epoch: 6| Step: 7
Training loss: 0.5326508397045515
Validation loss: 2.57552286325896

Epoch: 6| Step: 8
Training loss: 0.27970292512351547
Validation loss: 2.596641516151068

Epoch: 6| Step: 9
Training loss: 0.35913042370570747
Validation loss: 2.6178223218516687

Epoch: 6| Step: 10
Training loss: 0.4482164728771336
Validation loss: 2.5968733562683783

Epoch: 6| Step: 11
Training loss: 0.5020769018602851
Validation loss: 2.59055087046083

Epoch: 6| Step: 12
Training loss: 0.28307460631164866
Validation loss: 2.557555126933298

Epoch: 6| Step: 13
Training loss: 0.26349618497924265
Validation loss: 2.585234805273339

Epoch: 350| Step: 0
Training loss: 0.36938871897153297
Validation loss: 2.5909173815379143

Epoch: 6| Step: 1
Training loss: 0.3809436020272441
Validation loss: 2.5716267547797065

Epoch: 6| Step: 2
Training loss: 0.5849221396595298
Validation loss: 2.6266849499112936

Epoch: 6| Step: 3
Training loss: 0.3717961540303351
Validation loss: 2.6055012564222477

Epoch: 6| Step: 4
Training loss: 0.44358413309635175
Validation loss: 2.610972434688385

Epoch: 6| Step: 5
Training loss: 0.3993531719325855
Validation loss: 2.6036380459359174

Epoch: 6| Step: 6
Training loss: 0.5034418849647546
Validation loss: 2.5856259011457143

Epoch: 6| Step: 7
Training loss: 0.28363869155950233
Validation loss: 2.593861147192604

Epoch: 6| Step: 8
Training loss: 0.3208291376549643
Validation loss: 2.5736845824361274

Epoch: 6| Step: 9
Training loss: 0.43490436872988314
Validation loss: 2.5963022874833346

Epoch: 6| Step: 10
Training loss: 0.34718207908745224
Validation loss: 2.600900083018487

Epoch: 6| Step: 11
Training loss: 0.3559147688026771
Validation loss: 2.586490314379705

Epoch: 6| Step: 12
Training loss: 0.25509151230830324
Validation loss: 2.6048759121392133

Epoch: 6| Step: 13
Training loss: 0.42714765886149453
Validation loss: 2.644095991764206

Epoch: 351| Step: 0
Training loss: 0.4152468890280861
Validation loss: 2.59136065485462

Epoch: 6| Step: 1
Training loss: 0.23942710959170413
Validation loss: 2.638873649629445

Epoch: 6| Step: 2
Training loss: 0.5793915869880579
Validation loss: 2.6129272207396266

Epoch: 6| Step: 3
Training loss: 0.3473244487429408
Validation loss: 2.6043823946946745

Epoch: 6| Step: 4
Training loss: 0.33274257982093014
Validation loss: 2.5880923003795933

Epoch: 6| Step: 5
Training loss: 0.54127672415782
Validation loss: 2.562407406130237

Epoch: 6| Step: 6
Training loss: 0.2863131661039913
Validation loss: 2.573473675063011

Epoch: 6| Step: 7
Training loss: 0.2990915595857148
Validation loss: 2.5674234818119306

Epoch: 6| Step: 8
Training loss: 0.45293192202866894
Validation loss: 2.563126282151964

Epoch: 6| Step: 9
Training loss: 0.32682695677591744
Validation loss: 2.557158478694391

Epoch: 6| Step: 10
Training loss: 0.3845988265471428
Validation loss: 2.57140995397907

Epoch: 6| Step: 11
Training loss: 0.37081029004213695
Validation loss: 2.5735146879269775

Epoch: 6| Step: 12
Training loss: 0.34621988886860994
Validation loss: 2.5755048805440444

Epoch: 6| Step: 13
Training loss: 0.12806635392516513
Validation loss: 2.5919443935722013

Epoch: 352| Step: 0
Training loss: 0.4744717433724219
Validation loss: 2.5740536046050564

Epoch: 6| Step: 1
Training loss: 0.2030051684872602
Validation loss: 2.5866653423836636

Epoch: 6| Step: 2
Training loss: 0.4392325801565039
Validation loss: 2.625817400642236

Epoch: 6| Step: 3
Training loss: 0.3333497962263854
Validation loss: 2.5789674706805292

Epoch: 6| Step: 4
Training loss: 0.589788977498839
Validation loss: 2.5905975737959896

Epoch: 6| Step: 5
Training loss: 0.15736073639028617
Validation loss: 2.6003867394566242

Epoch: 6| Step: 6
Training loss: 0.546737217576239
Validation loss: 2.610000515728223

Epoch: 6| Step: 7
Training loss: 0.26161013669616967
Validation loss: 2.6247272762406286

Epoch: 6| Step: 8
Training loss: 0.487327773898508
Validation loss: 2.603455514260605

Epoch: 6| Step: 9
Training loss: 0.32086776661122257
Validation loss: 2.6003689592486934

Epoch: 6| Step: 10
Training loss: 0.39751469578958065
Validation loss: 2.6121520955207282

Epoch: 6| Step: 11
Training loss: 0.27184891411173456
Validation loss: 2.578478128531214

Epoch: 6| Step: 12
Training loss: 0.3426782633489608
Validation loss: 2.5622285788690116

Epoch: 6| Step: 13
Training loss: 0.29624294457705685
Validation loss: 2.597876341275774

Epoch: 353| Step: 0
Training loss: 0.324122977761324
Validation loss: 2.599646368205985

Epoch: 6| Step: 1
Training loss: 0.46906552821432895
Validation loss: 2.5873953579896507

Epoch: 6| Step: 2
Training loss: 0.44231609658243426
Validation loss: 2.589281588250581

Epoch: 6| Step: 3
Training loss: 0.4019104374201073
Validation loss: 2.589962514351943

Epoch: 6| Step: 4
Training loss: 0.4665389685244312
Validation loss: 2.595309240901653

Epoch: 6| Step: 5
Training loss: 0.41085149786115427
Validation loss: 2.599617713987639

Epoch: 6| Step: 6
Training loss: 0.4281553174164552
Validation loss: 2.6140925094562593

Epoch: 6| Step: 7
Training loss: 0.3582062582796228
Validation loss: 2.567600793043989

Epoch: 6| Step: 8
Training loss: 0.2613873162398514
Validation loss: 2.558450587166558

Epoch: 6| Step: 9
Training loss: 0.2599781142477744
Validation loss: 2.548441407409096

Epoch: 6| Step: 10
Training loss: 0.275946198755104
Validation loss: 2.5408392382583393

Epoch: 6| Step: 11
Training loss: 0.3741100798568647
Validation loss: 2.529331241915341

Epoch: 6| Step: 12
Training loss: 0.35423126286102913
Validation loss: 2.543210317495353

Epoch: 6| Step: 13
Training loss: 0.5031288419304345
Validation loss: 2.52168445936002

Epoch: 354| Step: 0
Training loss: 0.3370059565292215
Validation loss: 2.5284184628789457

Epoch: 6| Step: 1
Training loss: 0.30409160443357486
Validation loss: 2.5167839210276464

Epoch: 6| Step: 2
Training loss: 0.6457669290634058
Validation loss: 2.5295141343039487

Epoch: 6| Step: 3
Training loss: 0.23464116242232833
Validation loss: 2.5633550278409816

Epoch: 6| Step: 4
Training loss: 0.4078727736089362
Validation loss: 2.569856308647301

Epoch: 6| Step: 5
Training loss: 0.2721949136602492
Validation loss: 2.569411013614007

Epoch: 6| Step: 6
Training loss: 0.343171337052752
Validation loss: 2.603546005283601

Epoch: 6| Step: 7
Training loss: 0.252179450765773
Validation loss: 2.5904682206934586

Epoch: 6| Step: 8
Training loss: 0.2739606756876515
Validation loss: 2.5953352336815527

Epoch: 6| Step: 9
Training loss: 0.5355524420361921
Validation loss: 2.5794336919633682

Epoch: 6| Step: 10
Training loss: 0.42070703956249167
Validation loss: 2.5556391398338745

Epoch: 6| Step: 11
Training loss: 0.35798756593683434
Validation loss: 2.529736793616107

Epoch: 6| Step: 12
Training loss: 0.45341130781077177
Validation loss: 2.5125007793058183

Epoch: 6| Step: 13
Training loss: 0.4788970983729196
Validation loss: 2.5260381057726002

Epoch: 355| Step: 0
Training loss: 0.4581498696419134
Validation loss: 2.4877114367544118

Epoch: 6| Step: 1
Training loss: 0.38409776381398086
Validation loss: 2.4934781970694786

Epoch: 6| Step: 2
Training loss: 0.40289657538078866
Validation loss: 2.5218200752431543

Epoch: 6| Step: 3
Training loss: 0.4186096447258213
Validation loss: 2.527126168170019

Epoch: 6| Step: 4
Training loss: 0.34952458893282673
Validation loss: 2.5147014984671925

Epoch: 6| Step: 5
Training loss: 0.24821234612991075
Validation loss: 2.523377097046393

Epoch: 6| Step: 6
Training loss: 0.4513641872331051
Validation loss: 2.5744753434011085

Epoch: 6| Step: 7
Training loss: 0.2666902220028126
Validation loss: 2.5343456210112785

Epoch: 6| Step: 8
Training loss: 0.5466306412948985
Validation loss: 2.6077717677386216

Epoch: 6| Step: 9
Training loss: 0.6248806601075517
Validation loss: 2.6203187981258336

Epoch: 6| Step: 10
Training loss: 0.38674369885663107
Validation loss: 2.6084734532263067

Epoch: 6| Step: 11
Training loss: 0.4264258658432142
Validation loss: 2.577948055615202

Epoch: 6| Step: 12
Training loss: 0.22159062079319727
Validation loss: 2.576534736629138

Epoch: 6| Step: 13
Training loss: 0.14788330926549217
Validation loss: 2.584638021665197

Epoch: 356| Step: 0
Training loss: 0.18232393433314217
Validation loss: 2.5987516230531793

Epoch: 6| Step: 1
Training loss: 0.30464050957647776
Validation loss: 2.6053499968151166

Epoch: 6| Step: 2
Training loss: 0.286191420037372
Validation loss: 2.6044824654029486

Epoch: 6| Step: 3
Training loss: 0.39899732492142914
Validation loss: 2.568521252930215

Epoch: 6| Step: 4
Training loss: 0.31263539242315647
Validation loss: 2.5891869728266426

Epoch: 6| Step: 5
Training loss: 0.47638486459488605
Validation loss: 2.616134141144414

Epoch: 6| Step: 6
Training loss: 0.5419907028590308
Validation loss: 2.6092961671359536

Epoch: 6| Step: 7
Training loss: 0.4854545867690659
Validation loss: 2.618595363327292

Epoch: 6| Step: 8
Training loss: 0.4105595740070162
Validation loss: 2.6534109328730193

Epoch: 6| Step: 9
Training loss: 0.30179256251466086
Validation loss: 2.6437477267928107

Epoch: 6| Step: 10
Training loss: 0.2782089679921786
Validation loss: 2.617903118958646

Epoch: 6| Step: 11
Training loss: 0.2548367104180782
Validation loss: 2.6075305910679276

Epoch: 6| Step: 12
Training loss: 0.39595134966803663
Validation loss: 2.6039532842685995

Epoch: 6| Step: 13
Training loss: 0.6827856682714721
Validation loss: 2.6134729709749838

Epoch: 357| Step: 0
Training loss: 0.32175944485469704
Validation loss: 2.6016225830361224

Epoch: 6| Step: 1
Training loss: 0.4077062548800617
Validation loss: 2.5559876875079732

Epoch: 6| Step: 2
Training loss: 0.36918599490738324
Validation loss: 2.58003498822045

Epoch: 6| Step: 3
Training loss: 0.6150287102766578
Validation loss: 2.5866614275408706

Epoch: 6| Step: 4
Training loss: 0.34456959465634496
Validation loss: 2.583192581989353

Epoch: 6| Step: 5
Training loss: 0.2948343260714039
Validation loss: 2.5701423037854334

Epoch: 6| Step: 6
Training loss: 0.5167840011734748
Validation loss: 2.569573257293429

Epoch: 6| Step: 7
Training loss: 0.3681636577573621
Validation loss: 2.570973378881633

Epoch: 6| Step: 8
Training loss: 0.4398971349052717
Validation loss: 2.592563888220318

Epoch: 6| Step: 9
Training loss: 0.39591939726695974
Validation loss: 2.594018622023351

Epoch: 6| Step: 10
Training loss: 0.33123273759522953
Validation loss: 2.6337361858098363

Epoch: 6| Step: 11
Training loss: 0.3694069522263346
Validation loss: 2.622821400907454

Epoch: 6| Step: 12
Training loss: 0.32955896303538557
Validation loss: 2.6385323011714354

Epoch: 6| Step: 13
Training loss: 0.3589665123082803
Validation loss: 2.5786397371011627

Epoch: 358| Step: 0
Training loss: 0.410778119179398
Validation loss: 2.5655212099967906

Epoch: 6| Step: 1
Training loss: 0.3902101984639696
Validation loss: 2.5722231490521565

Epoch: 6| Step: 2
Training loss: 0.3503794792724586
Validation loss: 2.5910183245325125

Epoch: 6| Step: 3
Training loss: 0.3906015961311668
Validation loss: 2.5694406771740783

Epoch: 6| Step: 4
Training loss: 0.5241008370104379
Validation loss: 2.557575372912773

Epoch: 6| Step: 5
Training loss: 0.32218171385519095
Validation loss: 2.5998665676002117

Epoch: 6| Step: 6
Training loss: 0.17406705444582327
Validation loss: 2.6255083954182323

Epoch: 6| Step: 7
Training loss: 0.476354272095667
Validation loss: 2.5910844999761236

Epoch: 6| Step: 8
Training loss: 0.38210109860058383
Validation loss: 2.644728372122434

Epoch: 6| Step: 9
Training loss: 0.45252503763131996
Validation loss: 2.6430486415673116

Epoch: 6| Step: 10
Training loss: 0.30155419451883453
Validation loss: 2.6451711852378565

Epoch: 6| Step: 11
Training loss: 0.4189508788977251
Validation loss: 2.6493738389698045

Epoch: 6| Step: 12
Training loss: 0.43901127961077296
Validation loss: 2.6046279515089146

Epoch: 6| Step: 13
Training loss: 0.36265269631514624
Validation loss: 2.6147147969518727

Epoch: 359| Step: 0
Training loss: 0.36344309247372625
Validation loss: 2.6283956149811365

Epoch: 6| Step: 1
Training loss: 0.2472239683717028
Validation loss: 2.6151141409136374

Epoch: 6| Step: 2
Training loss: 0.28798779901184085
Validation loss: 2.5782914044276883

Epoch: 6| Step: 3
Training loss: 0.38362593739141176
Validation loss: 2.6166211096509886

Epoch: 6| Step: 4
Training loss: 0.46113711415295605
Validation loss: 2.573492393199833

Epoch: 6| Step: 5
Training loss: 0.30141248974390156
Validation loss: 2.5650585846166516

Epoch: 6| Step: 6
Training loss: 0.34492856339982586
Validation loss: 2.560077949221327

Epoch: 6| Step: 7
Training loss: 0.31983498125677157
Validation loss: 2.5406815670588645

Epoch: 6| Step: 8
Training loss: 0.29550976295609105
Validation loss: 2.5394156635236795

Epoch: 6| Step: 9
Training loss: 0.325210250190659
Validation loss: 2.544122882542832

Epoch: 6| Step: 10
Training loss: 0.4142543779992477
Validation loss: 2.544149037535089

Epoch: 6| Step: 11
Training loss: 0.6493208280479633
Validation loss: 2.5941039761939884

Epoch: 6| Step: 12
Training loss: 0.198487341621317
Validation loss: 2.5788985239543516

Epoch: 6| Step: 13
Training loss: 0.4569591889261947
Validation loss: 2.564205652486501

Epoch: 360| Step: 0
Training loss: 0.32961153312242414
Validation loss: 2.577768122489406

Epoch: 6| Step: 1
Training loss: 0.24886847517703997
Validation loss: 2.5874346837946804

Epoch: 6| Step: 2
Training loss: 0.44577738271186323
Validation loss: 2.5522844213169567

Epoch: 6| Step: 3
Training loss: 0.5071810978493038
Validation loss: 2.5882045938797003

Epoch: 6| Step: 4
Training loss: 0.2543376046185994
Validation loss: 2.57822138959444

Epoch: 6| Step: 5
Training loss: 0.34792090639892753
Validation loss: 2.5843683631096437

Epoch: 6| Step: 6
Training loss: 0.19312142652767142
Validation loss: 2.623722282086249

Epoch: 6| Step: 7
Training loss: 0.4277551550150447
Validation loss: 2.55202687753326

Epoch: 6| Step: 8
Training loss: 0.19845456928520233
Validation loss: 2.607081023323963

Epoch: 6| Step: 9
Training loss: 0.4316879004916637
Validation loss: 2.564656070647942

Epoch: 6| Step: 10
Training loss: 0.29888561418831894
Validation loss: 2.6209598375805476

Epoch: 6| Step: 11
Training loss: 0.5059633774056592
Validation loss: 2.6099573863012138

Epoch: 6| Step: 12
Training loss: 0.21055147381857572
Validation loss: 2.6224612779291534

Epoch: 6| Step: 13
Training loss: 0.3795324440658964
Validation loss: 2.632625553357089

Epoch: 361| Step: 0
Training loss: 0.42532600773782936
Validation loss: 2.631838431164907

Epoch: 6| Step: 1
Training loss: 0.4656977142290995
Validation loss: 2.6698546856006713

Epoch: 6| Step: 2
Training loss: 0.3933552125257865
Validation loss: 2.6632702286031926

Epoch: 6| Step: 3
Training loss: 0.3347278373338736
Validation loss: 2.6491864043031272

Epoch: 6| Step: 4
Training loss: 0.2978724613049499
Validation loss: 2.655339234845839

Epoch: 6| Step: 5
Training loss: 0.3252473967027974
Validation loss: 2.5815253253957944

Epoch: 6| Step: 6
Training loss: 0.29615306914286665
Validation loss: 2.6238351211005497

Epoch: 6| Step: 7
Training loss: 0.14841328599090822
Validation loss: 2.60728887489391

Epoch: 6| Step: 8
Training loss: 0.22860583945460491
Validation loss: 2.5880357847948123

Epoch: 6| Step: 9
Training loss: 0.26779063341392406
Validation loss: 2.587025428074144

Epoch: 6| Step: 10
Training loss: 0.45504980040062676
Validation loss: 2.5793810934517505

Epoch: 6| Step: 11
Training loss: 0.32497542911961647
Validation loss: 2.550198462458402

Epoch: 6| Step: 12
Training loss: 0.5526924252176841
Validation loss: 2.5686925480985265

Epoch: 6| Step: 13
Training loss: 0.2527966830819159
Validation loss: 2.5649260894758528

Epoch: 362| Step: 0
Training loss: 0.2451928162641415
Validation loss: 2.567908362479142

Epoch: 6| Step: 1
Training loss: 0.29650474347699385
Validation loss: 2.568905410793958

Epoch: 6| Step: 2
Training loss: 0.32173441251745555
Validation loss: 2.611834774509048

Epoch: 6| Step: 3
Training loss: 0.40028850834919055
Validation loss: 2.6063827755314994

Epoch: 6| Step: 4
Training loss: 0.39115206446385054
Validation loss: 2.5854966483334807

Epoch: 6| Step: 5
Training loss: 0.2501763079748864
Validation loss: 2.5790828453121875

Epoch: 6| Step: 6
Training loss: 0.40065756482440507
Validation loss: 2.54334256903093

Epoch: 6| Step: 7
Training loss: 0.2690169361625607
Validation loss: 2.5523457668265124

Epoch: 6| Step: 8
Training loss: 0.6306390288940897
Validation loss: 2.5487894009631478

Epoch: 6| Step: 9
Training loss: 0.2877928066868062
Validation loss: 2.5270806291437213

Epoch: 6| Step: 10
Training loss: 0.2455308319200877
Validation loss: 2.5613856239816615

Epoch: 6| Step: 11
Training loss: 0.37060054328469993
Validation loss: 2.5616785799309727

Epoch: 6| Step: 12
Training loss: 0.4009139200176086
Validation loss: 2.612645582823649

Epoch: 6| Step: 13
Training loss: 0.3724568479300447
Validation loss: 2.6102929183574277

Epoch: 363| Step: 0
Training loss: 0.5936622554794373
Validation loss: 2.6322141293383425

Epoch: 6| Step: 1
Training loss: 0.49982564091410236
Validation loss: 2.617187215933297

Epoch: 6| Step: 2
Training loss: 0.526819717565966
Validation loss: 2.643864119191392

Epoch: 6| Step: 3
Training loss: 0.22124748277040418
Validation loss: 2.5871174614204535

Epoch: 6| Step: 4
Training loss: 0.3225482279549528
Validation loss: 2.618275531360471

Epoch: 6| Step: 5
Training loss: 0.2546173701241037
Validation loss: 2.6278467636605543

Epoch: 6| Step: 6
Training loss: 0.3498085669255007
Validation loss: 2.5897589958756626

Epoch: 6| Step: 7
Training loss: 0.1713408873484322
Validation loss: 2.5866743583927447

Epoch: 6| Step: 8
Training loss: 0.31259069318801225
Validation loss: 2.6007160915122602

Epoch: 6| Step: 9
Training loss: 0.3646181180799516
Validation loss: 2.5893726874781384

Epoch: 6| Step: 10
Training loss: 0.18898997768062462
Validation loss: 2.6178869677668293

Epoch: 6| Step: 11
Training loss: 0.34996540971536855
Validation loss: 2.532816335560277

Epoch: 6| Step: 12
Training loss: 0.25544260748696174
Validation loss: 2.5919335952676508

Epoch: 6| Step: 13
Training loss: 0.24469957073444493
Validation loss: 2.5774127173893704

Epoch: 364| Step: 0
Training loss: 0.28179314936879024
Validation loss: 2.5776694642681544

Epoch: 6| Step: 1
Training loss: 0.14356766207444183
Validation loss: 2.580495119411683

Epoch: 6| Step: 2
Training loss: 0.27794016257388166
Validation loss: 2.5841481491410425

Epoch: 6| Step: 3
Training loss: 0.19430365366168154
Validation loss: 2.600067698596759

Epoch: 6| Step: 4
Training loss: 0.5259852394835974
Validation loss: 2.634858841140551

Epoch: 6| Step: 5
Training loss: 0.40122400407569486
Validation loss: 2.6158955083209423

Epoch: 6| Step: 6
Training loss: 0.5003363848673005
Validation loss: 2.5922661104847493

Epoch: 6| Step: 7
Training loss: 0.30801258410021537
Validation loss: 2.591436050511143

Epoch: 6| Step: 8
Training loss: 0.29639687434336065
Validation loss: 2.619575873160202

Epoch: 6| Step: 9
Training loss: 0.2777653565543642
Validation loss: 2.6061790228633517

Epoch: 6| Step: 10
Training loss: 0.33726530701121027
Validation loss: 2.570712527719513

Epoch: 6| Step: 11
Training loss: 0.2656191095933222
Validation loss: 2.5572758828621245

Epoch: 6| Step: 12
Training loss: 0.5402203164302191
Validation loss: 2.5852548875368826

Epoch: 6| Step: 13
Training loss: 0.41371435248098537
Validation loss: 2.549602386450904

Epoch: 365| Step: 0
Training loss: 0.21268279754278327
Validation loss: 2.5816377774319363

Epoch: 6| Step: 1
Training loss: 0.2815510674885379
Validation loss: 2.5818842354131935

Epoch: 6| Step: 2
Training loss: 0.3946533580700956
Validation loss: 2.539790946267791

Epoch: 6| Step: 3
Training loss: 0.16738495174362936
Validation loss: 2.5849657137740687

Epoch: 6| Step: 4
Training loss: 0.4306869327761201
Validation loss: 2.606678034221527

Epoch: 6| Step: 5
Training loss: 0.4648098973361272
Validation loss: 2.6090810019544053

Epoch: 6| Step: 6
Training loss: 0.3423319960038443
Validation loss: 2.591159099302293

Epoch: 6| Step: 7
Training loss: 0.366296946280141
Validation loss: 2.5949251171970453

Epoch: 6| Step: 8
Training loss: 0.3461351012591318
Validation loss: 2.5980699267620926

Epoch: 6| Step: 9
Training loss: 0.29109178097069716
Validation loss: 2.595189985290247

Epoch: 6| Step: 10
Training loss: 0.4822112639153079
Validation loss: 2.5775086343216285

Epoch: 6| Step: 11
Training loss: 0.27777082845154316
Validation loss: 2.5733269506370315

Epoch: 6| Step: 12
Training loss: 0.3776779716535893
Validation loss: 2.543452963723036

Epoch: 6| Step: 13
Training loss: 0.4864213693231441
Validation loss: 2.6095644905581445

Epoch: 366| Step: 0
Training loss: 0.17728493004927662
Validation loss: 2.5776827008006453

Epoch: 6| Step: 1
Training loss: 0.48511823422304967
Validation loss: 2.538403521547263

Epoch: 6| Step: 2
Training loss: 0.27571304872012614
Validation loss: 2.588372028112489

Epoch: 6| Step: 3
Training loss: 0.42801925021402015
Validation loss: 2.6079474050094724

Epoch: 6| Step: 4
Training loss: 0.2467181745815996
Validation loss: 2.6102219095684265

Epoch: 6| Step: 5
Training loss: 0.26659245178529006
Validation loss: 2.615467366417372

Epoch: 6| Step: 6
Training loss: 0.4781906737308386
Validation loss: 2.6600025903536664

Epoch: 6| Step: 7
Training loss: 0.5166408473403293
Validation loss: 2.6473859714785646

Epoch: 6| Step: 8
Training loss: 0.2670858128328925
Validation loss: 2.6671805489089904

Epoch: 6| Step: 9
Training loss: 0.42156427030990495
Validation loss: 2.665609128573192

Epoch: 6| Step: 10
Training loss: 0.46368211768646744
Validation loss: 2.666919732455447

Epoch: 6| Step: 11
Training loss: 0.29957288298509466
Validation loss: 2.6576739264079206

Epoch: 6| Step: 12
Training loss: 0.3289749513217169
Validation loss: 2.6439555319992616

Epoch: 6| Step: 13
Training loss: 0.43859340071112163
Validation loss: 2.6298779949759776

Epoch: 367| Step: 0
Training loss: 0.2135429624580208
Validation loss: 2.5618618706583143

Epoch: 6| Step: 1
Training loss: 0.35227861584778586
Validation loss: 2.579782836318712

Epoch: 6| Step: 2
Training loss: 0.28351490353881165
Validation loss: 2.555760990250978

Epoch: 6| Step: 3
Training loss: 0.31341195554843077
Validation loss: 2.5249427758872827

Epoch: 6| Step: 4
Training loss: 0.24083301730338705
Validation loss: 2.5335487800802783

Epoch: 6| Step: 5
Training loss: 0.29346525717074295
Validation loss: 2.573950075527955

Epoch: 6| Step: 6
Training loss: 0.39065566896206655
Validation loss: 2.5738198011042894

Epoch: 6| Step: 7
Training loss: 0.3184098981775035
Validation loss: 2.5629022154046512

Epoch: 6| Step: 8
Training loss: 0.5601996964932879
Validation loss: 2.59808569445595

Epoch: 6| Step: 9
Training loss: 0.4560231886120934
Validation loss: 2.621099207683401

Epoch: 6| Step: 10
Training loss: 0.38260691825167376
Validation loss: 2.632092556105081

Epoch: 6| Step: 11
Training loss: 0.4231513108450549
Validation loss: 2.634092682619196

Epoch: 6| Step: 12
Training loss: 0.4318462417180626
Validation loss: 2.6509847324017244

Epoch: 6| Step: 13
Training loss: 0.48153130187037363
Validation loss: 2.616303542851713

Epoch: 368| Step: 0
Training loss: 0.3095463283164864
Validation loss: 2.6237102490646755

Epoch: 6| Step: 1
Training loss: 0.2899939505176315
Validation loss: 2.5953149888904106

Epoch: 6| Step: 2
Training loss: 0.47408163297362466
Validation loss: 2.5594533926988516

Epoch: 6| Step: 3
Training loss: 0.46097996079732817
Validation loss: 2.5806783303569776

Epoch: 6| Step: 4
Training loss: 0.326548182251187
Validation loss: 2.5796375798245537

Epoch: 6| Step: 5
Training loss: 0.2456307369756108
Validation loss: 2.5525966785125727

Epoch: 6| Step: 6
Training loss: 0.27105323257858444
Validation loss: 2.508564056913528

Epoch: 6| Step: 7
Training loss: 0.31869496169540984
Validation loss: 2.522706390454607

Epoch: 6| Step: 8
Training loss: 0.2734787909802866
Validation loss: 2.5195938961084856

Epoch: 6| Step: 9
Training loss: 0.2513200509692758
Validation loss: 2.5646944911420295

Epoch: 6| Step: 10
Training loss: 0.20018930193554263
Validation loss: 2.540952026936349

Epoch: 6| Step: 11
Training loss: 0.42460143389816846
Validation loss: 2.5768756761669125

Epoch: 6| Step: 12
Training loss: 0.5306431726549709
Validation loss: 2.5631096937701026

Epoch: 6| Step: 13
Training loss: 0.46223440212157735
Validation loss: 2.5729229412888306

Epoch: 369| Step: 0
Training loss: 0.2828126517448229
Validation loss: 2.5863590945809674

Epoch: 6| Step: 1
Training loss: 0.19750512569150094
Validation loss: 2.5809726355415874

Epoch: 6| Step: 2
Training loss: 0.29078826727745194
Validation loss: 2.6007892346700605

Epoch: 6| Step: 3
Training loss: 0.6030328541862982
Validation loss: 2.555752460018131

Epoch: 6| Step: 4
Training loss: 0.3643467566993251
Validation loss: 2.5744088147079167

Epoch: 6| Step: 5
Training loss: 0.46749249903633244
Validation loss: 2.5753114912341584

Epoch: 6| Step: 6
Training loss: 0.49325467023267466
Validation loss: 2.617252209591497

Epoch: 6| Step: 7
Training loss: 0.1819537038535922
Validation loss: 2.6266086452383286

Epoch: 6| Step: 8
Training loss: 0.30135776952538484
Validation loss: 2.619049444339139

Epoch: 6| Step: 9
Training loss: 0.28138125853524204
Validation loss: 2.620637836817873

Epoch: 6| Step: 10
Training loss: 0.32575459542769425
Validation loss: 2.6074538546595867

Epoch: 6| Step: 11
Training loss: 0.34462306384406466
Validation loss: 2.6085798026864406

Epoch: 6| Step: 12
Training loss: 0.36407155037955985
Validation loss: 2.5652554126951683

Epoch: 6| Step: 13
Training loss: 0.16661872708266692
Validation loss: 2.584201348031386

Epoch: 370| Step: 0
Training loss: 0.5894543454996244
Validation loss: 2.5549611791758284

Epoch: 6| Step: 1
Training loss: 0.27225144512188804
Validation loss: 2.554381724890207

Epoch: 6| Step: 2
Training loss: 0.43933554877854747
Validation loss: 2.6384719830362737

Epoch: 6| Step: 3
Training loss: 0.38559977159869285
Validation loss: 2.616857645464276

Epoch: 6| Step: 4
Training loss: 0.3410338358697596
Validation loss: 2.622192620966959

Epoch: 6| Step: 5
Training loss: 0.30495590223394536
Validation loss: 2.676939417014049

Epoch: 6| Step: 6
Training loss: 0.32774368336567994
Validation loss: 2.661858172800926

Epoch: 6| Step: 7
Training loss: 0.2162484457809075
Validation loss: 2.6798282470209545

Epoch: 6| Step: 8
Training loss: 0.3072171713623861
Validation loss: 2.6815839289932013

Epoch: 6| Step: 9
Training loss: 0.20001421855512191
Validation loss: 2.6504760624918986

Epoch: 6| Step: 10
Training loss: 0.21085817116912783
Validation loss: 2.6625077207019014

Epoch: 6| Step: 11
Training loss: 0.5472332462205152
Validation loss: 2.648119487104264

Epoch: 6| Step: 12
Training loss: 0.3577458315379196
Validation loss: 2.66479979111828

Epoch: 6| Step: 13
Training loss: 0.3513804388171553
Validation loss: 2.6418594976542606

Epoch: 371| Step: 0
Training loss: 0.31482935841800724
Validation loss: 2.6359975780047886

Epoch: 6| Step: 1
Training loss: 0.3075911980201143
Validation loss: 2.6285397658233736

Epoch: 6| Step: 2
Training loss: 0.45836049960284375
Validation loss: 2.618008216295078

Epoch: 6| Step: 3
Training loss: 0.31045655670565564
Validation loss: 2.5795227328891914

Epoch: 6| Step: 4
Training loss: 0.40951870005043023
Validation loss: 2.5556795947804574

Epoch: 6| Step: 5
Training loss: 0.475791432439275
Validation loss: 2.542994246463642

Epoch: 6| Step: 6
Training loss: 0.2989597280095407
Validation loss: 2.549001655270978

Epoch: 6| Step: 7
Training loss: 0.2735934630152288
Validation loss: 2.5393610438161023

Epoch: 6| Step: 8
Training loss: 0.27285109719937845
Validation loss: 2.5455223873878468

Epoch: 6| Step: 9
Training loss: 0.398112931540206
Validation loss: 2.5513835735358974

Epoch: 6| Step: 10
Training loss: 0.2994135314777441
Validation loss: 2.54113581742195

Epoch: 6| Step: 11
Training loss: 0.24088229443700365
Validation loss: 2.53305186870702

Epoch: 6| Step: 12
Training loss: 0.26411158314327793
Validation loss: 2.5263655151852284

Epoch: 6| Step: 13
Training loss: 0.4216813773421281
Validation loss: 2.5553163079017622

Epoch: 372| Step: 0
Training loss: 0.3408470689824088
Validation loss: 2.5684326750331237

Epoch: 6| Step: 1
Training loss: 0.34392148855471083
Validation loss: 2.5361643931655196

Epoch: 6| Step: 2
Training loss: 0.40408100133020913
Validation loss: 2.5513253655761075

Epoch: 6| Step: 3
Training loss: 0.41824851967138615
Validation loss: 2.553516020873458

Epoch: 6| Step: 4
Training loss: 0.28970294318654577
Validation loss: 2.552144899477436

Epoch: 6| Step: 5
Training loss: 0.296979471697339
Validation loss: 2.552255897807071

Epoch: 6| Step: 6
Training loss: 0.3502497854592907
Validation loss: 2.5286074869349746

Epoch: 6| Step: 7
Training loss: 0.4140071651983561
Validation loss: 2.6073796704124157

Epoch: 6| Step: 8
Training loss: 0.22758791157677977
Validation loss: 2.575980420691946

Epoch: 6| Step: 9
Training loss: 0.23704101293445423
Validation loss: 2.5856575931654473

Epoch: 6| Step: 10
Training loss: 0.3549986445038398
Validation loss: 2.5949018154458257

Epoch: 6| Step: 11
Training loss: 0.2529990200619322
Validation loss: 2.6035635442143894

Epoch: 6| Step: 12
Training loss: 0.2044638471084074
Validation loss: 2.576804914504201

Epoch: 6| Step: 13
Training loss: 0.22884902108516275
Validation loss: 2.6233369077779662

Epoch: 373| Step: 0
Training loss: 0.3703585318432775
Validation loss: 2.584725732770783

Epoch: 6| Step: 1
Training loss: 0.07954870518186424
Validation loss: 2.5702833995685936

Epoch: 6| Step: 2
Training loss: 0.22098710349048614
Validation loss: 2.5729073733591674

Epoch: 6| Step: 3
Training loss: 0.30139308479472515
Validation loss: 2.590921779737963

Epoch: 6| Step: 4
Training loss: 0.5501954230002718
Validation loss: 2.5997004308389164

Epoch: 6| Step: 5
Training loss: 0.40922708168593297
Validation loss: 2.5821444256215886

Epoch: 6| Step: 6
Training loss: 0.12637512235182774
Validation loss: 2.585451652544844

Epoch: 6| Step: 7
Training loss: 0.15892346947132371
Validation loss: 2.603973210850325

Epoch: 6| Step: 8
Training loss: 0.2848678201412546
Validation loss: 2.5958483999842143

Epoch: 6| Step: 9
Training loss: 0.3400655220162477
Validation loss: 2.578534762129375

Epoch: 6| Step: 10
Training loss: 0.35222371757130905
Validation loss: 2.547264509715987

Epoch: 6| Step: 11
Training loss: 0.13840450784978217
Validation loss: 2.5919841315390015

Epoch: 6| Step: 12
Training loss: 0.44360640445623073
Validation loss: 2.6265797383352263

Epoch: 6| Step: 13
Training loss: 0.3877081304396246
Validation loss: 2.5892889050590786

Epoch: 374| Step: 0
Training loss: 0.3208154126318785
Validation loss: 2.5744977466205503

Epoch: 6| Step: 1
Training loss: 0.47053912776299334
Validation loss: 2.5603782529641146

Epoch: 6| Step: 2
Training loss: 0.3413446868454767
Validation loss: 2.5515258066231046

Epoch: 6| Step: 3
Training loss: 0.21425728080634857
Validation loss: 2.574463962475025

Epoch: 6| Step: 4
Training loss: 0.2542269661905657
Validation loss: 2.544561594045028

Epoch: 6| Step: 5
Training loss: 0.37186131652532917
Validation loss: 2.60734764559728

Epoch: 6| Step: 6
Training loss: 0.29916363001763696
Validation loss: 2.534209399776547

Epoch: 6| Step: 7
Training loss: 0.33267571230638887
Validation loss: 2.5777440977701596

Epoch: 6| Step: 8
Training loss: 0.219935203676846
Validation loss: 2.5936845636990506

Epoch: 6| Step: 9
Training loss: 0.3778625744118406
Validation loss: 2.580879069406508

Epoch: 6| Step: 10
Training loss: 0.23350445881166246
Validation loss: 2.5511697930130093

Epoch: 6| Step: 11
Training loss: 0.3205510623443617
Validation loss: 2.5711189713115696

Epoch: 6| Step: 12
Training loss: 0.2286609937179168
Validation loss: 2.5616165617158244

Epoch: 6| Step: 13
Training loss: 0.43404042373884033
Validation loss: 2.5772793028812306

Epoch: 375| Step: 0
Training loss: 0.1973942818660375
Validation loss: 2.5479756567743514

Epoch: 6| Step: 1
Training loss: 0.3716434823953396
Validation loss: 2.556827346041205

Epoch: 6| Step: 2
Training loss: 0.461022191429985
Validation loss: 2.5116491611599394

Epoch: 6| Step: 3
Training loss: 0.28473161407942466
Validation loss: 2.5520772251225985

Epoch: 6| Step: 4
Training loss: 0.27447286498468254
Validation loss: 2.6005865881236088

Epoch: 6| Step: 5
Training loss: 0.2664918778704461
Validation loss: 2.576009079585516

Epoch: 6| Step: 6
Training loss: 0.31289771520841714
Validation loss: 2.576896002648918

Epoch: 6| Step: 7
Training loss: 0.22559454104708496
Validation loss: 2.6033362684464025

Epoch: 6| Step: 8
Training loss: 0.333586606523203
Validation loss: 2.5906676841202145

Epoch: 6| Step: 9
Training loss: 0.24316199428184357
Validation loss: 2.5852174265992414

Epoch: 6| Step: 10
Training loss: 0.418112863669579
Validation loss: 2.5791964783200423

Epoch: 6| Step: 11
Training loss: 0.22855310051262256
Validation loss: 2.538632450963657

Epoch: 6| Step: 12
Training loss: 0.299039566432276
Validation loss: 2.555723318184745

Epoch: 6| Step: 13
Training loss: 0.41974364645774664
Validation loss: 2.6131495836182013

Epoch: 376| Step: 0
Training loss: 0.21847819574087654
Validation loss: 2.585569756020196

Epoch: 6| Step: 1
Training loss: 0.43360655138518367
Validation loss: 2.5635132513355545

Epoch: 6| Step: 2
Training loss: 0.21363551512163245
Validation loss: 2.5590088896479806

Epoch: 6| Step: 3
Training loss: 0.2769977264646674
Validation loss: 2.5885897623877954

Epoch: 6| Step: 4
Training loss: 0.19225289465011075
Validation loss: 2.589911695623576

Epoch: 6| Step: 5
Training loss: 0.40091919783625296
Validation loss: 2.5700826458901274

Epoch: 6| Step: 6
Training loss: 0.3463688276051368
Validation loss: 2.5907901501038046

Epoch: 6| Step: 7
Training loss: 0.30729109419214407
Validation loss: 2.5954247652288602

Epoch: 6| Step: 8
Training loss: 0.2477360226887044
Validation loss: 2.5338171607681863

Epoch: 6| Step: 9
Training loss: 0.30875901734161026
Validation loss: 2.563657541694591

Epoch: 6| Step: 10
Training loss: 0.35114764001578247
Validation loss: 2.5781801677132488

Epoch: 6| Step: 11
Training loss: 0.22361379650841934
Validation loss: 2.5637605029480315

Epoch: 6| Step: 12
Training loss: 0.40374906716962355
Validation loss: 2.5879321186673057

Epoch: 6| Step: 13
Training loss: 0.2602929377675691
Validation loss: 2.5943258580052495

Epoch: 377| Step: 0
Training loss: 0.4728892043902355
Validation loss: 2.580562469736783

Epoch: 6| Step: 1
Training loss: 0.38377496824519725
Validation loss: 2.5741310916977422

Epoch: 6| Step: 2
Training loss: 0.30074643267959894
Validation loss: 2.5897608856222356

Epoch: 6| Step: 3
Training loss: 0.36042371404883716
Validation loss: 2.5691565846707256

Epoch: 6| Step: 4
Training loss: 0.17420257463333189
Validation loss: 2.576159128772688

Epoch: 6| Step: 5
Training loss: 0.39800699200790374
Validation loss: 2.5734905692085595

Epoch: 6| Step: 6
Training loss: 0.2802958728702833
Validation loss: 2.588244742870933

Epoch: 6| Step: 7
Training loss: 0.2167668278810019
Validation loss: 2.57712255822706

Epoch: 6| Step: 8
Training loss: 0.15263797395840492
Validation loss: 2.6090485411151962

Epoch: 6| Step: 9
Training loss: 0.2459025927276643
Validation loss: 2.590453782246005

Epoch: 6| Step: 10
Training loss: 0.22388918311805997
Validation loss: 2.6037989224252307

Epoch: 6| Step: 11
Training loss: 0.3067663263120452
Validation loss: 2.6138959893948037

Epoch: 6| Step: 12
Training loss: 0.3399906060379629
Validation loss: 2.60678392045799

Epoch: 6| Step: 13
Training loss: 0.2756787679738363
Validation loss: 2.5692711266624486

Epoch: 378| Step: 0
Training loss: 0.20130726045577996
Validation loss: 2.5894252661902053

Epoch: 6| Step: 1
Training loss: 0.3329667991820909
Validation loss: 2.593880225227392

Epoch: 6| Step: 2
Training loss: 0.2962122848502234
Validation loss: 2.5872961354665054

Epoch: 6| Step: 3
Training loss: 0.3690159299443538
Validation loss: 2.597831377344683

Epoch: 6| Step: 4
Training loss: 0.13413731990290578
Validation loss: 2.5827279236584304

Epoch: 6| Step: 5
Training loss: 0.3065979800365544
Validation loss: 2.570300086775315

Epoch: 6| Step: 6
Training loss: 0.5429434461666528
Validation loss: 2.541816449471544

Epoch: 6| Step: 7
Training loss: 0.3632440445418987
Validation loss: 2.569088275734709

Epoch: 6| Step: 8
Training loss: 0.1706079466475503
Validation loss: 2.561711174669807

Epoch: 6| Step: 9
Training loss: 0.26611764886754097
Validation loss: 2.54683395021495

Epoch: 6| Step: 10
Training loss: 0.15038619716120533
Validation loss: 2.5543587106681485

Epoch: 6| Step: 11
Training loss: 0.5234339699697317
Validation loss: 2.548694724753274

Epoch: 6| Step: 12
Training loss: 0.19088056934615416
Validation loss: 2.5814622774609375

Epoch: 6| Step: 13
Training loss: 0.17375359383989766
Validation loss: 2.5561366523680795

Epoch: 379| Step: 0
Training loss: 0.20552571815979612
Validation loss: 2.55304397139335

Epoch: 6| Step: 1
Training loss: 0.43909572054802454
Validation loss: 2.53962124793841

Epoch: 6| Step: 2
Training loss: 0.137532523491911
Validation loss: 2.5712366622965006

Epoch: 6| Step: 3
Training loss: 0.2211535423493611
Validation loss: 2.536718699105535

Epoch: 6| Step: 4
Training loss: 0.49358242909489625
Validation loss: 2.5490339942299345

Epoch: 6| Step: 5
Training loss: 0.23967075912371996
Validation loss: 2.5630210078688576

Epoch: 6| Step: 6
Training loss: 0.2306939899432894
Validation loss: 2.6080678144254974

Epoch: 6| Step: 7
Training loss: 0.22907978094158252
Validation loss: 2.5409399399360693

Epoch: 6| Step: 8
Training loss: 0.193061145870959
Validation loss: 2.5997146271168354

Epoch: 6| Step: 9
Training loss: 0.478356549038001
Validation loss: 2.593816683945261

Epoch: 6| Step: 10
Training loss: 0.30320742164954584
Validation loss: 2.6052403552922847

Epoch: 6| Step: 11
Training loss: 0.2705015326366617
Validation loss: 2.593259240878879

Epoch: 6| Step: 12
Training loss: 0.3518614345767904
Validation loss: 2.5955100939001805

Epoch: 6| Step: 13
Training loss: 0.20984873767870313
Validation loss: 2.5696358905861496

Epoch: 380| Step: 0
Training loss: 0.2077416521499953
Validation loss: 2.593260840398589

Epoch: 6| Step: 1
Training loss: 0.12773509185776513
Validation loss: 2.600123624331585

Epoch: 6| Step: 2
Training loss: 0.41169823119483334
Validation loss: 2.5825184368093326

Epoch: 6| Step: 3
Training loss: 0.21982663736660907
Validation loss: 2.584795412729192

Epoch: 6| Step: 4
Training loss: 0.4876853205490252
Validation loss: 2.5619181871145473

Epoch: 6| Step: 5
Training loss: 0.1814531774222698
Validation loss: 2.599263494487109

Epoch: 6| Step: 6
Training loss: 0.27533610460323765
Validation loss: 2.609229442556691

Epoch: 6| Step: 7
Training loss: 0.22184041788017128
Validation loss: 2.596085169446822

Epoch: 6| Step: 8
Training loss: 0.3262150673050422
Validation loss: 2.5892340968093257

Epoch: 6| Step: 9
Training loss: 0.31896937618827625
Validation loss: 2.5506072337171997

Epoch: 6| Step: 10
Training loss: 0.3853721485545941
Validation loss: 2.57965540354379

Epoch: 6| Step: 11
Training loss: 0.4601177264216154
Validation loss: 2.5744912979229078

Epoch: 6| Step: 12
Training loss: 0.28987736160053273
Validation loss: 2.5885326020301664

Epoch: 6| Step: 13
Training loss: 0.3179976157317958
Validation loss: 2.5591586197938723

Epoch: 381| Step: 0
Training loss: 0.3297257206895556
Validation loss: 2.5718727317246532

Epoch: 6| Step: 1
Training loss: 0.3225081715916204
Validation loss: 2.577732394626435

Epoch: 6| Step: 2
Training loss: 0.37925597892629964
Validation loss: 2.5632493798941725

Epoch: 6| Step: 3
Training loss: 0.3553833072803735
Validation loss: 2.5462119047495606

Epoch: 6| Step: 4
Training loss: 0.29733435328795815
Validation loss: 2.570585046212083

Epoch: 6| Step: 5
Training loss: 0.42715017059351346
Validation loss: 2.5722686428451302

Epoch: 6| Step: 6
Training loss: 0.30311102048355587
Validation loss: 2.564929636694761

Epoch: 6| Step: 7
Training loss: 0.15885361230993214
Validation loss: 2.577833481481627

Epoch: 6| Step: 8
Training loss: 0.2683357872515084
Validation loss: 2.5840221836907857

Epoch: 6| Step: 9
Training loss: 0.39376571714730835
Validation loss: 2.564801442945576

Epoch: 6| Step: 10
Training loss: 0.26368569231916894
Validation loss: 2.5724251179482764

Epoch: 6| Step: 11
Training loss: 0.2084860252075482
Validation loss: 2.6156060764926234

Epoch: 6| Step: 12
Training loss: 0.3437905287692383
Validation loss: 2.6056749172795017

Epoch: 6| Step: 13
Training loss: 0.28035671047094046
Validation loss: 2.6187427183596217

Epoch: 382| Step: 0
Training loss: 0.2779417173418647
Validation loss: 2.6173468066068137

Epoch: 6| Step: 1
Training loss: 0.16898927502487524
Validation loss: 2.611136666265003

Epoch: 6| Step: 2
Training loss: 0.29825443475005037
Validation loss: 2.619833438732474

Epoch: 6| Step: 3
Training loss: 0.4138981834999402
Validation loss: 2.5925077974286825

Epoch: 6| Step: 4
Training loss: 0.28599651853236385
Validation loss: 2.6033226473209

Epoch: 6| Step: 5
Training loss: 0.3462906279638786
Validation loss: 2.619738421664264

Epoch: 6| Step: 6
Training loss: 0.23721098128980078
Validation loss: 2.590708668219867

Epoch: 6| Step: 7
Training loss: 0.1956906663046977
Validation loss: 2.6138999796698594

Epoch: 6| Step: 8
Training loss: 0.13279459636289428
Validation loss: 2.598498227966537

Epoch: 6| Step: 9
Training loss: 0.5618977501562956
Validation loss: 2.5458595702164017

Epoch: 6| Step: 10
Training loss: 0.4921749658350996
Validation loss: 2.5533597391547858

Epoch: 6| Step: 11
Training loss: 0.2563842166079067
Validation loss: 2.535756922650798

Epoch: 6| Step: 12
Training loss: 0.2534925171088164
Validation loss: 2.554443593590256

Epoch: 6| Step: 13
Training loss: 0.23000804468525876
Validation loss: 2.516415832395131

Epoch: 383| Step: 0
Training loss: 0.44261439579669154
Validation loss: 2.5222356833520556

Epoch: 6| Step: 1
Training loss: 0.33562967702068264
Validation loss: 2.5007038028179767

Epoch: 6| Step: 2
Training loss: 0.45018793128990053
Validation loss: 2.522513920009283

Epoch: 6| Step: 3
Training loss: 0.4966692252487913
Validation loss: 2.532534651212957

Epoch: 6| Step: 4
Training loss: 0.25851584352937684
Validation loss: 2.5581758422277603

Epoch: 6| Step: 5
Training loss: 0.25558147918017005
Validation loss: 2.568571178396787

Epoch: 6| Step: 6
Training loss: 0.3462782241149292
Validation loss: 2.6108660624040794

Epoch: 6| Step: 7
Training loss: 0.13447443975458495
Validation loss: 2.6169170721736705

Epoch: 6| Step: 8
Training loss: 0.25954722064243657
Validation loss: 2.6305892085376885

Epoch: 6| Step: 9
Training loss: 0.3144667249309391
Validation loss: 2.6263107737378713

Epoch: 6| Step: 10
Training loss: 0.25392501468277195
Validation loss: 2.634409157947769

Epoch: 6| Step: 11
Training loss: 0.15003253365404332
Validation loss: 2.6012194436028584

Epoch: 6| Step: 12
Training loss: 0.209967422385205
Validation loss: 2.579156240661224

Epoch: 6| Step: 13
Training loss: 0.3994237063859519
Validation loss: 2.576676368365058

Epoch: 384| Step: 0
Training loss: 0.3308209181845464
Validation loss: 2.6107466827452983

Epoch: 6| Step: 1
Training loss: 0.1193397569747519
Validation loss: 2.59448580652881

Epoch: 6| Step: 2
Training loss: 0.1760850188994111
Validation loss: 2.610077477820454

Epoch: 6| Step: 3
Training loss: 0.2635623987182755
Validation loss: 2.6498949795315867

Epoch: 6| Step: 4
Training loss: 0.25571733273837505
Validation loss: 2.612241189066277

Epoch: 6| Step: 5
Training loss: 0.2995240951782001
Validation loss: 2.649912716214987

Epoch: 6| Step: 6
Training loss: 0.2799533784318754
Validation loss: 2.6312307350311412

Epoch: 6| Step: 7
Training loss: 0.37377907761082113
Validation loss: 2.6380433609622362

Epoch: 6| Step: 8
Training loss: 0.20843247597743433
Validation loss: 2.6012097713639264

Epoch: 6| Step: 9
Training loss: 0.47202280647532274
Validation loss: 2.5863852248863757

Epoch: 6| Step: 10
Training loss: 0.3160136813373937
Validation loss: 2.6272637703812594

Epoch: 6| Step: 11
Training loss: 0.23125271086779253
Validation loss: 2.599916415728667

Epoch: 6| Step: 12
Training loss: 0.5045212533857721
Validation loss: 2.615296845998511

Epoch: 6| Step: 13
Training loss: 0.350858152324115
Validation loss: 2.603866788928428

Epoch: 385| Step: 0
Training loss: 0.23148033424375722
Validation loss: 2.625229803477213

Epoch: 6| Step: 1
Training loss: 0.5128893385186081
Validation loss: 2.614729375469724

Epoch: 6| Step: 2
Training loss: 0.4735441773842162
Validation loss: 2.6438496586610367

Epoch: 6| Step: 3
Training loss: 0.4190844324845571
Validation loss: 2.6180232856718475

Epoch: 6| Step: 4
Training loss: 0.20369446231569663
Validation loss: 2.6310688743599884

Epoch: 6| Step: 5
Training loss: 0.34941268161524275
Validation loss: 2.6176767082117918

Epoch: 6| Step: 6
Training loss: 0.2748462084410311
Validation loss: 2.5911973533923294

Epoch: 6| Step: 7
Training loss: 0.24602973196142047
Validation loss: 2.596026464721039

Epoch: 6| Step: 8
Training loss: 0.4008900574632808
Validation loss: 2.576803262984214

Epoch: 6| Step: 9
Training loss: 0.21519651062597756
Validation loss: 2.598740102312505

Epoch: 6| Step: 10
Training loss: 0.36422878691771615
Validation loss: 2.5865680979165444

Epoch: 6| Step: 11
Training loss: 0.22347630517281658
Validation loss: 2.6174192244886827

Epoch: 6| Step: 12
Training loss: 0.25838593087237777
Validation loss: 2.6253927086506046

Epoch: 6| Step: 13
Training loss: 0.4363172756885057
Validation loss: 2.643749388857093

Epoch: 386| Step: 0
Training loss: 0.2986125916744955
Validation loss: 2.5738659165838635

Epoch: 6| Step: 1
Training loss: 0.3751224675472799
Validation loss: 2.581184938435121

Epoch: 6| Step: 2
Training loss: 0.2641974262451133
Validation loss: 2.542437059585323

Epoch: 6| Step: 3
Training loss: 0.2992289105674772
Validation loss: 2.52346495439412

Epoch: 6| Step: 4
Training loss: 0.3974647240610669
Validation loss: 2.552106730035982

Epoch: 6| Step: 5
Training loss: 0.20331094557176427
Validation loss: 2.5341848923075316

Epoch: 6| Step: 6
Training loss: 0.27067361150593144
Validation loss: 2.531431567608784

Epoch: 6| Step: 7
Training loss: 0.4646137694437572
Validation loss: 2.5411747715835675

Epoch: 6| Step: 8
Training loss: 0.4447601305690745
Validation loss: 2.5326072591748883

Epoch: 6| Step: 9
Training loss: 0.3154435287603904
Validation loss: 2.5719777553325356

Epoch: 6| Step: 10
Training loss: 0.21881063506490184
Validation loss: 2.571816029174912

Epoch: 6| Step: 11
Training loss: 0.2054175066414915
Validation loss: 2.5610129661016727

Epoch: 6| Step: 12
Training loss: 0.38200546364846466
Validation loss: 2.605867103552422

Epoch: 6| Step: 13
Training loss: 0.241059220821102
Validation loss: 2.583833495859727

Epoch: 387| Step: 0
Training loss: 0.27966074149565656
Validation loss: 2.5469684544679008

Epoch: 6| Step: 1
Training loss: 0.21994052218425592
Validation loss: 2.528205704182652

Epoch: 6| Step: 2
Training loss: 0.2645244096614018
Validation loss: 2.53602133593453

Epoch: 6| Step: 3
Training loss: 0.3228553231742038
Validation loss: 2.522811942404156

Epoch: 6| Step: 4
Training loss: 0.46509061397045515
Validation loss: 2.5411449344391137

Epoch: 6| Step: 5
Training loss: 0.3963810264552728
Validation loss: 2.525110169205116

Epoch: 6| Step: 6
Training loss: 0.44860386437440863
Validation loss: 2.500518673241801

Epoch: 6| Step: 7
Training loss: 0.24655441280586482
Validation loss: 2.5356191272005297

Epoch: 6| Step: 8
Training loss: 0.19874017865128313
Validation loss: 2.5433849351216877

Epoch: 6| Step: 9
Training loss: 0.1444175053548022
Validation loss: 2.5568405069847584

Epoch: 6| Step: 10
Training loss: 0.3765699583715802
Validation loss: 2.5576943746945697

Epoch: 6| Step: 11
Training loss: 0.19044308737535356
Validation loss: 2.565036063973897

Epoch: 6| Step: 12
Training loss: 0.4702125303661129
Validation loss: 2.5750002761364383

Epoch: 6| Step: 13
Training loss: 0.18804505716989636
Validation loss: 2.585670126496549

Epoch: 388| Step: 0
Training loss: 0.31563707744039393
Validation loss: 2.5871834606753397

Epoch: 6| Step: 1
Training loss: 0.3685627203118007
Validation loss: 2.5959251308437685

Epoch: 6| Step: 2
Training loss: 0.351345822001184
Validation loss: 2.5979524941737036

Epoch: 6| Step: 3
Training loss: 0.2602936676741907
Validation loss: 2.591111530471207

Epoch: 6| Step: 4
Training loss: 0.34618535863761923
Validation loss: 2.5780596344766606

Epoch: 6| Step: 5
Training loss: 0.3018440814602418
Validation loss: 2.5947001723629493

Epoch: 6| Step: 6
Training loss: 0.22096387263318018
Validation loss: 2.607701888700967

Epoch: 6| Step: 7
Training loss: 0.23233331868524199
Validation loss: 2.6099977202785243

Epoch: 6| Step: 8
Training loss: 0.18546105458042847
Validation loss: 2.582244324626292

Epoch: 6| Step: 9
Training loss: 0.4356979655452296
Validation loss: 2.5840732561439985

Epoch: 6| Step: 10
Training loss: 0.2430830211485919
Validation loss: 2.564342497673978

Epoch: 6| Step: 11
Training loss: 0.3406772149163553
Validation loss: 2.579099025797214

Epoch: 6| Step: 12
Training loss: 0.24357706256252765
Validation loss: 2.5592457726819475

Epoch: 6| Step: 13
Training loss: 0.38188545705959254
Validation loss: 2.5415563823376437

Epoch: 389| Step: 0
Training loss: 0.30025520397380534
Validation loss: 2.5816673566110193

Epoch: 6| Step: 1
Training loss: 0.386546318067059
Validation loss: 2.5412323545517173

Epoch: 6| Step: 2
Training loss: 0.3298042108861472
Validation loss: 2.5531841309033823

Epoch: 6| Step: 3
Training loss: 0.22007449259822462
Validation loss: 2.5485401735681243

Epoch: 6| Step: 4
Training loss: 0.38551776006930916
Validation loss: 2.5943029560257487

Epoch: 6| Step: 5
Training loss: 0.3152279518730447
Validation loss: 2.5799628912630737

Epoch: 6| Step: 6
Training loss: 0.24675675046957032
Validation loss: 2.610360043949349

Epoch: 6| Step: 7
Training loss: 0.1535049650747552
Validation loss: 2.6233081238709843

Epoch: 6| Step: 8
Training loss: 0.31399673608432055
Validation loss: 2.643134087966545

Epoch: 6| Step: 9
Training loss: 0.3781170048144278
Validation loss: 2.602972026524041

Epoch: 6| Step: 10
Training loss: 0.16023550747378673
Validation loss: 2.645424822117602

Epoch: 6| Step: 11
Training loss: 0.22357625954207191
Validation loss: 2.5759069801375643

Epoch: 6| Step: 12
Training loss: 0.35945391825053874
Validation loss: 2.5795733975144097

Epoch: 6| Step: 13
Training loss: 0.2557576246542025
Validation loss: 2.60474670907027

Epoch: 390| Step: 0
Training loss: 0.33102957031031277
Validation loss: 2.594678226156131

Epoch: 6| Step: 1
Training loss: 0.2497882840614477
Validation loss: 2.5297276294041158

Epoch: 6| Step: 2
Training loss: 0.4701515543365019
Validation loss: 2.579285127873184

Epoch: 6| Step: 3
Training loss: 0.2380557947894536
Validation loss: 2.545566087863687

Epoch: 6| Step: 4
Training loss: 0.3124341895425419
Validation loss: 2.6006742586590637

Epoch: 6| Step: 5
Training loss: 0.21088412280607113
Validation loss: 2.5610639828850164

Epoch: 6| Step: 6
Training loss: 0.3847652958127855
Validation loss: 2.574483674179226

Epoch: 6| Step: 7
Training loss: 0.18017825199903895
Validation loss: 2.60980825773784

Epoch: 6| Step: 8
Training loss: 0.1932848006271588
Validation loss: 2.6067716332095774

Epoch: 6| Step: 9
Training loss: 0.2134617136322064
Validation loss: 2.582447795018825

Epoch: 6| Step: 10
Training loss: 0.33218259167207453
Validation loss: 2.5911792617960825

Epoch: 6| Step: 11
Training loss: 0.34671333042291097
Validation loss: 2.595459285018577

Epoch: 6| Step: 12
Training loss: 0.16536987601593608
Validation loss: 2.5547001115128216

Epoch: 6| Step: 13
Training loss: 0.24885922421750026
Validation loss: 2.5622996320205362

Epoch: 391| Step: 0
Training loss: 0.11671559765527977
Validation loss: 2.5377678308360903

Epoch: 6| Step: 1
Training loss: 0.30095022582641257
Validation loss: 2.523372130031587

Epoch: 6| Step: 2
Training loss: 0.3942129153902066
Validation loss: 2.5318385667573957

Epoch: 6| Step: 3
Training loss: 0.2991584622476554
Validation loss: 2.5555200358262034

Epoch: 6| Step: 4
Training loss: 0.270006879679134
Validation loss: 2.5500996607484074

Epoch: 6| Step: 5
Training loss: 0.33361885637420163
Validation loss: 2.5408980294820176

Epoch: 6| Step: 6
Training loss: 0.3613260423754909
Validation loss: 2.555172475833755

Epoch: 6| Step: 7
Training loss: 0.3756985515872185
Validation loss: 2.5371319727659487

Epoch: 6| Step: 8
Training loss: 0.30330689960012347
Validation loss: 2.58161204892084

Epoch: 6| Step: 9
Training loss: 0.3628861729869262
Validation loss: 2.5698160484440202

Epoch: 6| Step: 10
Training loss: 0.11687910907197778
Validation loss: 2.590116513557795

Epoch: 6| Step: 11
Training loss: 0.2564533560683322
Validation loss: 2.586770441309236

Epoch: 6| Step: 12
Training loss: 0.22267219419445117
Validation loss: 2.5724923940396027

Epoch: 6| Step: 13
Training loss: 0.13161469722069102
Validation loss: 2.5823027162282757

Epoch: 392| Step: 0
Training loss: 0.43853535077522215
Validation loss: 2.606309627420298

Epoch: 6| Step: 1
Training loss: 0.30277028024695957
Validation loss: 2.551148503863441

Epoch: 6| Step: 2
Training loss: 0.2123313960705503
Validation loss: 2.542627279817819

Epoch: 6| Step: 3
Training loss: 0.345374182547238
Validation loss: 2.508636023514867

Epoch: 6| Step: 4
Training loss: 0.3600979250932602
Validation loss: 2.5421390101269905

Epoch: 6| Step: 5
Training loss: 0.37172885555530893
Validation loss: 2.5416097222748624

Epoch: 6| Step: 6
Training loss: 0.2809110161600511
Validation loss: 2.511535682769362

Epoch: 6| Step: 7
Training loss: 0.1753483368714369
Validation loss: 2.485796634583765

Epoch: 6| Step: 8
Training loss: 0.13715064088012482
Validation loss: 2.5476690640238444

Epoch: 6| Step: 9
Training loss: 0.2238096512498947
Validation loss: 2.557956236699009

Epoch: 6| Step: 10
Training loss: 0.22657360674501173
Validation loss: 2.5877811898333762

Epoch: 6| Step: 11
Training loss: 0.40221728957794806
Validation loss: 2.5678378234359864

Epoch: 6| Step: 12
Training loss: 0.33852811443884273
Validation loss: 2.5482639436253463

Epoch: 6| Step: 13
Training loss: 0.11828941600482952
Validation loss: 2.55010478154097

Epoch: 393| Step: 0
Training loss: 0.3950025557181817
Validation loss: 2.539518899971809

Epoch: 6| Step: 1
Training loss: 0.3876622952255502
Validation loss: 2.545885823168914

Epoch: 6| Step: 2
Training loss: 0.37445706561804865
Validation loss: 2.549785051951907

Epoch: 6| Step: 3
Training loss: 0.2117344934866991
Validation loss: 2.545254596821164

Epoch: 6| Step: 4
Training loss: 0.2279964973448357
Validation loss: 2.5371463554459854

Epoch: 6| Step: 5
Training loss: 0.2753083938223143
Validation loss: 2.5298790550595593

Epoch: 6| Step: 6
Training loss: 0.27168274911325035
Validation loss: 2.5379891862454245

Epoch: 6| Step: 7
Training loss: 0.18654053295144027
Validation loss: 2.581406261256395

Epoch: 6| Step: 8
Training loss: 0.1631308396708221
Validation loss: 2.5723224043455226

Epoch: 6| Step: 9
Training loss: 0.19388640470489896
Validation loss: 2.5361733668265094

Epoch: 6| Step: 10
Training loss: 0.1654487130530353
Validation loss: 2.5599858776162527

Epoch: 6| Step: 11
Training loss: 0.2104766633090255
Validation loss: 2.57464310042128

Epoch: 6| Step: 12
Training loss: 0.30423819596847196
Validation loss: 2.592541837899437

Epoch: 6| Step: 13
Training loss: 0.4364286144793723
Validation loss: 2.556909697581052

Epoch: 394| Step: 0
Training loss: 0.24141442059760423
Validation loss: 2.5622088524277675

Epoch: 6| Step: 1
Training loss: 0.42372430681301015
Validation loss: 2.543351667049919

Epoch: 6| Step: 2
Training loss: 0.13999431299469103
Validation loss: 2.580783898587658

Epoch: 6| Step: 3
Training loss: 0.3339703874837889
Validation loss: 2.546118183881714

Epoch: 6| Step: 4
Training loss: 0.3638801355356633
Validation loss: 2.56572113154781

Epoch: 6| Step: 5
Training loss: 0.26228922260793003
Validation loss: 2.5175504597725435

Epoch: 6| Step: 6
Training loss: 0.26441683611807776
Validation loss: 2.5598816333849643

Epoch: 6| Step: 7
Training loss: 0.15074599995454122
Validation loss: 2.574226930233604

Epoch: 6| Step: 8
Training loss: 0.35942197575588675
Validation loss: 2.5594621905534582

Epoch: 6| Step: 9
Training loss: 0.2781851724832801
Validation loss: 2.5583289810928735

Epoch: 6| Step: 10
Training loss: 0.18835142656008336
Validation loss: 2.547080325057518

Epoch: 6| Step: 11
Training loss: 0.32208755659827654
Validation loss: 2.5549536787715037

Epoch: 6| Step: 12
Training loss: 0.12942519634286093
Validation loss: 2.566986781002434

Epoch: 6| Step: 13
Training loss: 0.14377622961114825
Validation loss: 2.5729389881369586

Epoch: 395| Step: 0
Training loss: 0.4148861951360571
Validation loss: 2.5678140487496206

Epoch: 6| Step: 1
Training loss: 0.2481280216638407
Validation loss: 2.5500626964892272

Epoch: 6| Step: 2
Training loss: 0.15707714966239997
Validation loss: 2.555938364795962

Epoch: 6| Step: 3
Training loss: 0.15164864736539244
Validation loss: 2.547419470899838

Epoch: 6| Step: 4
Training loss: 0.1714646903798953
Validation loss: 2.528581317181522

Epoch: 6| Step: 5
Training loss: 0.2202475326872936
Validation loss: 2.561105018800785

Epoch: 6| Step: 6
Training loss: 0.3011837903744427
Validation loss: 2.5801399120904414

Epoch: 6| Step: 7
Training loss: 0.12471166525933522
Validation loss: 2.5726721291482533

Epoch: 6| Step: 8
Training loss: 0.12910779456074187
Validation loss: 2.567813202127717

Epoch: 6| Step: 9
Training loss: 0.3193313644968341
Validation loss: 2.5734288197167086

Epoch: 6| Step: 10
Training loss: 0.3657003479941582
Validation loss: 2.5497597656636333

Epoch: 6| Step: 11
Training loss: 0.23526406145485163
Validation loss: 2.5478114591961774

Epoch: 6| Step: 12
Training loss: 0.27157454056819025
Validation loss: 2.52921059773657

Epoch: 6| Step: 13
Training loss: 0.5702641087734595
Validation loss: 2.5674020024164266

Epoch: 396| Step: 0
Training loss: 0.3355723880931609
Validation loss: 2.5654461029917948

Epoch: 6| Step: 1
Training loss: 0.3938217014544865
Validation loss: 2.529658949961206

Epoch: 6| Step: 2
Training loss: 0.14741987957839642
Validation loss: 2.5523852359153003

Epoch: 6| Step: 3
Training loss: 0.33592878374724133
Validation loss: 2.5169346546161306

Epoch: 6| Step: 4
Training loss: 0.1512716484044801
Validation loss: 2.556402268086672

Epoch: 6| Step: 5
Training loss: 0.24431271400744808
Validation loss: 2.5587729915961748

Epoch: 6| Step: 6
Training loss: 0.37546581900568216
Validation loss: 2.551965814177929

Epoch: 6| Step: 7
Training loss: 0.35440253603218386
Validation loss: 2.589456966161676

Epoch: 6| Step: 8
Training loss: 0.15041716452918605
Validation loss: 2.5803438365470868

Epoch: 6| Step: 9
Training loss: 0.15964788491396362
Validation loss: 2.582691063829019

Epoch: 6| Step: 10
Training loss: 0.3222720983606476
Validation loss: 2.555852054530177

Epoch: 6| Step: 11
Training loss: 0.20597586547918828
Validation loss: 2.53660453770376

Epoch: 6| Step: 12
Training loss: 0.24978327297735917
Validation loss: 2.5651089332744075

Epoch: 6| Step: 13
Training loss: 0.14075350188409833
Validation loss: 2.5569040988753193

Epoch: 397| Step: 0
Training loss: 0.2728648046667506
Validation loss: 2.5616925275677094

Epoch: 6| Step: 1
Training loss: 0.10644069714120834
Validation loss: 2.5509529233766175

Epoch: 6| Step: 2
Training loss: 0.4075808916076626
Validation loss: 2.527047699320963

Epoch: 6| Step: 3
Training loss: 0.32205183856417385
Validation loss: 2.522824550419149

Epoch: 6| Step: 4
Training loss: 0.41440440402990875
Validation loss: 2.518419674513532

Epoch: 6| Step: 5
Training loss: 0.2679314890499366
Validation loss: 2.5358205792280875

Epoch: 6| Step: 6
Training loss: 0.15055751829231126
Validation loss: 2.5412030108966372

Epoch: 6| Step: 7
Training loss: 0.16089186715873427
Validation loss: 2.586497441842857

Epoch: 6| Step: 8
Training loss: 0.23870767677613244
Validation loss: 2.582253266720192

Epoch: 6| Step: 9
Training loss: 0.15911753441549953
Validation loss: 2.5960462576060794

Epoch: 6| Step: 10
Training loss: 0.11335975705403804
Validation loss: 2.5882262688556072

Epoch: 6| Step: 11
Training loss: 0.2692087427760143
Validation loss: 2.6203177356160747

Epoch: 6| Step: 12
Training loss: 0.42185461913434386
Validation loss: 2.6176399732433273

Epoch: 6| Step: 13
Training loss: 0.19540292553961575
Validation loss: 2.5965505085458975

Epoch: 398| Step: 0
Training loss: 0.40723450284759094
Validation loss: 2.6099403765562332

Epoch: 6| Step: 1
Training loss: 0.3184162627336312
Validation loss: 2.5970196151285463

Epoch: 6| Step: 2
Training loss: 0.23112807281415568
Validation loss: 2.63917509368084

Epoch: 6| Step: 3
Training loss: 0.27195523272987665
Validation loss: 2.637692687330683

Epoch: 6| Step: 4
Training loss: 0.193713836217455
Validation loss: 2.604866254707486

Epoch: 6| Step: 5
Training loss: 0.2697489315538574
Validation loss: 2.5889045436386464

Epoch: 6| Step: 6
Training loss: 0.1648086598639317
Validation loss: 2.549994478776694

Epoch: 6| Step: 7
Training loss: 0.2422119328264572
Validation loss: 2.5213729686235857

Epoch: 6| Step: 8
Training loss: 0.24359161445753316
Validation loss: 2.546373583815087

Epoch: 6| Step: 9
Training loss: 0.23457545609119337
Validation loss: 2.5098629172544586

Epoch: 6| Step: 10
Training loss: 0.1912072373247465
Validation loss: 2.5115195988191648

Epoch: 6| Step: 11
Training loss: 0.2486198370964691
Validation loss: 2.5438242757708225

Epoch: 6| Step: 12
Training loss: 0.41670098958109636
Validation loss: 2.515333289825983

Epoch: 6| Step: 13
Training loss: 0.1891314735388838
Validation loss: 2.520616437801134

Epoch: 399| Step: 0
Training loss: 0.3666967602684211
Validation loss: 2.5454219531123274

Epoch: 6| Step: 1
Training loss: 0.15811485606665382
Validation loss: 2.567114028257277

Epoch: 6| Step: 2
Training loss: 0.3677730153102143
Validation loss: 2.5562882646663843

Epoch: 6| Step: 3
Training loss: 0.15847363127718994
Validation loss: 2.5509967941219207

Epoch: 6| Step: 4
Training loss: 0.2292907642544538
Validation loss: 2.557607562367027

Epoch: 6| Step: 5
Training loss: 0.1239045316545748
Validation loss: 2.5732285425677794

Epoch: 6| Step: 6
Training loss: 0.15940685094194
Validation loss: 2.5372690151544317

Epoch: 6| Step: 7
Training loss: 0.19743547586705826
Validation loss: 2.527877572459279

Epoch: 6| Step: 8
Training loss: 0.1482043128702502
Validation loss: 2.539052851479548

Epoch: 6| Step: 9
Training loss: 0.4437579409466362
Validation loss: 2.571130366046932

Epoch: 6| Step: 10
Training loss: 0.2225782860232809
Validation loss: 2.552050125746478

Epoch: 6| Step: 11
Training loss: 0.3980425766103534
Validation loss: 2.56074231240121

Epoch: 6| Step: 12
Training loss: 0.236088978538038
Validation loss: 2.575874266455187

Epoch: 6| Step: 13
Training loss: 0.13818496191203417
Validation loss: 2.5709065451739264

Epoch: 400| Step: 0
Training loss: 0.1717488356849957
Validation loss: 2.54230585303351

Epoch: 6| Step: 1
Training loss: 0.13167475277807053
Validation loss: 2.5628495636984017

Epoch: 6| Step: 2
Training loss: 0.14774144253097407
Validation loss: 2.564740606770149

Epoch: 6| Step: 3
Training loss: 0.1824183886437881
Validation loss: 2.5984949495409007

Epoch: 6| Step: 4
Training loss: 0.3859409254902779
Validation loss: 2.593495714908259

Epoch: 6| Step: 5
Training loss: 0.31458444400406027
Validation loss: 2.5625059406362722

Epoch: 6| Step: 6
Training loss: 0.31490869869753846
Validation loss: 2.571824396478111

Epoch: 6| Step: 7
Training loss: 0.4120473046587153
Validation loss: 2.5200710691648323

Epoch: 6| Step: 8
Training loss: 0.2447620722284247
Validation loss: 2.562451229836892

Epoch: 6| Step: 9
Training loss: 0.4127873633540859
Validation loss: 2.538141364403291

Epoch: 6| Step: 10
Training loss: 0.20801110779923507
Validation loss: 2.5404776790010883

Epoch: 6| Step: 11
Training loss: 0.3176043162976833
Validation loss: 2.529952421196958

Epoch: 6| Step: 12
Training loss: 0.15372894889265376
Validation loss: 2.520206204249998

Epoch: 6| Step: 13
Training loss: 0.17175416058043017
Validation loss: 2.5319209797695805

Epoch: 401| Step: 0
Training loss: 0.2753273641013901
Validation loss: 2.543054767659291

Epoch: 6| Step: 1
Training loss: 0.18054246676719868
Validation loss: 2.5488477231616997

Epoch: 6| Step: 2
Training loss: 0.24280762496924602
Validation loss: 2.5328072462576334

Epoch: 6| Step: 3
Training loss: 0.2772245419554806
Validation loss: 2.5913303642011014

Epoch: 6| Step: 4
Training loss: 0.29452069261080766
Validation loss: 2.5625781085627874

Epoch: 6| Step: 5
Training loss: 0.1844291550904969
Validation loss: 2.5495740735055996

Epoch: 6| Step: 6
Training loss: 0.23713719771920255
Validation loss: 2.5329219492460666

Epoch: 6| Step: 7
Training loss: 0.3931397553238673
Validation loss: 2.5302113020194263

Epoch: 6| Step: 8
Training loss: 0.28257810089052166
Validation loss: 2.532982230858518

Epoch: 6| Step: 9
Training loss: 0.23299678255180467
Validation loss: 2.499516231122041

Epoch: 6| Step: 10
Training loss: 0.31154150596525393
Validation loss: 2.5133095624448103

Epoch: 6| Step: 11
Training loss: 0.36467698347656247
Validation loss: 2.5186808400007945

Epoch: 6| Step: 12
Training loss: 0.12319981440545244
Validation loss: 2.4921442090399264

Epoch: 6| Step: 13
Training loss: 0.3758926892547181
Validation loss: 2.5173453866827953

Epoch: 402| Step: 0
Training loss: 0.15020790394559835
Validation loss: 2.550957626146781

Epoch: 6| Step: 1
Training loss: 0.1888039270946757
Validation loss: 2.518035506249778

Epoch: 6| Step: 2
Training loss: 0.38506752601690664
Validation loss: 2.528919318773558

Epoch: 6| Step: 3
Training loss: 0.3101250164342566
Validation loss: 2.547867625378505

Epoch: 6| Step: 4
Training loss: 0.21236945588260553
Validation loss: 2.546886089498854

Epoch: 6| Step: 5
Training loss: 0.20090902619157822
Validation loss: 2.548370734431339

Epoch: 6| Step: 6
Training loss: 0.3284734283816716
Validation loss: 2.5083170774755703

Epoch: 6| Step: 7
Training loss: 0.3562745403738405
Validation loss: 2.5327029578399562

Epoch: 6| Step: 8
Training loss: 0.24617618360898286
Validation loss: 2.542363239968981

Epoch: 6| Step: 9
Training loss: 0.3032817076650603
Validation loss: 2.5269269347045697

Epoch: 6| Step: 10
Training loss: 0.18605053455139642
Validation loss: 2.5249003288020226

Epoch: 6| Step: 11
Training loss: 0.10818250301243042
Validation loss: 2.496576373757513

Epoch: 6| Step: 12
Training loss: 0.22699627786107565
Validation loss: 2.5543352435957902

Epoch: 6| Step: 13
Training loss: 0.09658914719182071
Validation loss: 2.495556192560468

Epoch: 403| Step: 0
Training loss: 0.3870301774787442
Validation loss: 2.5016214265597037

Epoch: 6| Step: 1
Training loss: 0.16231797481824875
Validation loss: 2.526387935070449

Epoch: 6| Step: 2
Training loss: 0.1368430526238247
Validation loss: 2.4875627166910186

Epoch: 6| Step: 3
Training loss: 0.1686757091953967
Validation loss: 2.531018194747843

Epoch: 6| Step: 4
Training loss: 0.16709655712559957
Validation loss: 2.5355429858172824

Epoch: 6| Step: 5
Training loss: 0.3372292854572974
Validation loss: 2.528928660782401

Epoch: 6| Step: 6
Training loss: 0.3131327184232184
Validation loss: 2.5260263759470356

Epoch: 6| Step: 7
Training loss: 0.09584526289239303
Validation loss: 2.51942741941321

Epoch: 6| Step: 8
Training loss: 0.31390777828666705
Validation loss: 2.5199259609154487

Epoch: 6| Step: 9
Training loss: 0.21707283533403757
Validation loss: 2.5325378844413584

Epoch: 6| Step: 10
Training loss: 0.28313988604369433
Validation loss: 2.5043266879846793

Epoch: 6| Step: 11
Training loss: 0.2790440568884711
Validation loss: 2.51886654914478

Epoch: 6| Step: 12
Training loss: 0.15106952070589066
Validation loss: 2.5065916428218418

Epoch: 6| Step: 13
Training loss: 0.4262682553126934
Validation loss: 2.5018442396375447

Epoch: 404| Step: 0
Training loss: 0.19837926250342022
Validation loss: 2.5516154617326925

Epoch: 6| Step: 1
Training loss: 0.34514531969176626
Validation loss: 2.493154105247671

Epoch: 6| Step: 2
Training loss: 0.17247170666328757
Validation loss: 2.4767926718195037

Epoch: 6| Step: 3
Training loss: 0.27930490442218336
Validation loss: 2.512347737845658

Epoch: 6| Step: 4
Training loss: 0.33574462499172
Validation loss: 2.5009076080930654

Epoch: 6| Step: 5
Training loss: 0.1880626977049174
Validation loss: 2.5281829543813803

Epoch: 6| Step: 6
Training loss: 0.24612179853663632
Validation loss: 2.5238647241517485

Epoch: 6| Step: 7
Training loss: 0.3618148824271007
Validation loss: 2.524582000133294

Epoch: 6| Step: 8
Training loss: 0.10188375155327169
Validation loss: 2.546357036308208

Epoch: 6| Step: 9
Training loss: 0.3017726018053002
Validation loss: 2.559181976522067

Epoch: 6| Step: 10
Training loss: 0.32758732294024073
Validation loss: 2.559465048209522

Epoch: 6| Step: 11
Training loss: 0.2871709744552273
Validation loss: 2.5291480661665675

Epoch: 6| Step: 12
Training loss: 0.19339169126242722
Validation loss: 2.583988565741

Epoch: 6| Step: 13
Training loss: 0.15341844273329472
Validation loss: 2.5745663880028697

Epoch: 405| Step: 0
Training loss: 0.16101816896282606
Validation loss: 2.573246810182592

Epoch: 6| Step: 1
Training loss: 0.3163097140135423
Validation loss: 2.5894691860757795

Epoch: 6| Step: 2
Training loss: 0.438111729060378
Validation loss: 2.563616431636079

Epoch: 6| Step: 3
Training loss: 0.30353973076926755
Validation loss: 2.5440299130529076

Epoch: 6| Step: 4
Training loss: 0.24696871210209237
Validation loss: 2.5378631389339876

Epoch: 6| Step: 5
Training loss: 0.29764808833829864
Validation loss: 2.55918012730526

Epoch: 6| Step: 6
Training loss: 0.15942415526562434
Validation loss: 2.5175653524763826

Epoch: 6| Step: 7
Training loss: 0.27716751946963997
Validation loss: 2.5229192930797772

Epoch: 6| Step: 8
Training loss: 0.23373803368196436
Validation loss: 2.539289874804546

Epoch: 6| Step: 9
Training loss: 0.24348952638486038
Validation loss: 2.545503925846461

Epoch: 6| Step: 10
Training loss: 0.33575265811484334
Validation loss: 2.5490714292469883

Epoch: 6| Step: 11
Training loss: 0.2655872430333074
Validation loss: 2.558960838383133

Epoch: 6| Step: 12
Training loss: 0.18046841724579754
Validation loss: 2.5587575913090363

Epoch: 6| Step: 13
Training loss: 0.3174489113862765
Validation loss: 2.573419780214312

Epoch: 406| Step: 0
Training loss: 0.14160312783263979
Validation loss: 2.5713359661374944

Epoch: 6| Step: 1
Training loss: 0.17297116683677435
Validation loss: 2.5487225256807022

Epoch: 6| Step: 2
Training loss: 0.33321455860981
Validation loss: 2.54833521964741

Epoch: 6| Step: 3
Training loss: 0.25463464867256336
Validation loss: 2.535197315951261

Epoch: 6| Step: 4
Training loss: 0.26426858139933085
Validation loss: 2.5490122633234606

Epoch: 6| Step: 5
Training loss: 0.15205289512149794
Validation loss: 2.5761140370631006

Epoch: 6| Step: 6
Training loss: 0.3369643353535031
Validation loss: 2.5840690407379845

Epoch: 6| Step: 7
Training loss: 0.27822566514481983
Validation loss: 2.581764987243845

Epoch: 6| Step: 8
Training loss: 0.15332575502879928
Validation loss: 2.5835811083998816

Epoch: 6| Step: 9
Training loss: 0.17968194372459917
Validation loss: 2.5983418395951996

Epoch: 6| Step: 10
Training loss: 0.361001026458549
Validation loss: 2.613127002112091

Epoch: 6| Step: 11
Training loss: 0.38158947339268834
Validation loss: 2.5938467525875692

Epoch: 6| Step: 12
Training loss: 0.35925369703319127
Validation loss: 2.585992701300988

Epoch: 6| Step: 13
Training loss: 0.34101840058515714
Validation loss: 2.562889556727247

Epoch: 407| Step: 0
Training loss: 0.17238412574321435
Validation loss: 2.5407030211040156

Epoch: 6| Step: 1
Training loss: 0.3861528359577341
Validation loss: 2.484048551705747

Epoch: 6| Step: 2
Training loss: 0.365898344777636
Validation loss: 2.4908935837664066

Epoch: 6| Step: 3
Training loss: 0.2067491300580728
Validation loss: 2.4853848952054616

Epoch: 6| Step: 4
Training loss: 0.29020765651360153
Validation loss: 2.486410369967894

Epoch: 6| Step: 5
Training loss: 0.215604985386296
Validation loss: 2.4700833820708246

Epoch: 6| Step: 6
Training loss: 0.4155842868683588
Validation loss: 2.460591213892422

Epoch: 6| Step: 7
Training loss: 0.2951140882631021
Validation loss: 2.524852025413104

Epoch: 6| Step: 8
Training loss: 0.2349419967487921
Validation loss: 2.5086963501531536

Epoch: 6| Step: 9
Training loss: 0.2575708904413183
Validation loss: 2.5633884233439614

Epoch: 6| Step: 10
Training loss: 0.3132589184799819
Validation loss: 2.583528920793587

Epoch: 6| Step: 11
Training loss: 0.3221886051503124
Validation loss: 2.571242408264848

Epoch: 6| Step: 12
Training loss: 0.1809610760602654
Validation loss: 2.57013060293335

Epoch: 6| Step: 13
Training loss: 0.23877147369530777
Validation loss: 2.595796850102123

Epoch: 408| Step: 0
Training loss: 0.40591326843133535
Validation loss: 2.608308352680002

Epoch: 6| Step: 1
Training loss: 0.4332999015560166
Validation loss: 2.5633192886102623

Epoch: 6| Step: 2
Training loss: 0.2437899550678458
Validation loss: 2.630776518169774

Epoch: 6| Step: 3
Training loss: 0.21734871952565146
Validation loss: 2.6094950181135865

Epoch: 6| Step: 4
Training loss: 0.21630728486571407
Validation loss: 2.6295253656861055

Epoch: 6| Step: 5
Training loss: 0.256010927931926
Validation loss: 2.605646814532212

Epoch: 6| Step: 6
Training loss: 0.19994053329093867
Validation loss: 2.547979279910758

Epoch: 6| Step: 7
Training loss: 0.2866899709784247
Validation loss: 2.5561199684786997

Epoch: 6| Step: 8
Training loss: 0.22998909417761007
Validation loss: 2.5211093659591954

Epoch: 6| Step: 9
Training loss: 0.2524314598027655
Validation loss: 2.4914761209250176

Epoch: 6| Step: 10
Training loss: 0.17582805858025363
Validation loss: 2.528525107869364

Epoch: 6| Step: 11
Training loss: 0.3992269399441135
Validation loss: 2.5123318070555474

Epoch: 6| Step: 12
Training loss: 0.15559613984772785
Validation loss: 2.495306777020326

Epoch: 6| Step: 13
Training loss: 0.1710857400369134
Validation loss: 2.517081562871777

Epoch: 409| Step: 0
Training loss: 0.13256658900643686
Validation loss: 2.505089075688606

Epoch: 6| Step: 1
Training loss: 0.14324472010578718
Validation loss: 2.565475767928358

Epoch: 6| Step: 2
Training loss: 0.28118130056784424
Validation loss: 2.5606837675448584

Epoch: 6| Step: 3
Training loss: 0.15172972179816563
Validation loss: 2.54579184823641

Epoch: 6| Step: 4
Training loss: 0.3773078435395972
Validation loss: 2.5933372919404776

Epoch: 6| Step: 5
Training loss: 0.282860542136914
Validation loss: 2.556763180708463

Epoch: 6| Step: 6
Training loss: 0.18944043185785422
Validation loss: 2.5880805751861224

Epoch: 6| Step: 7
Training loss: 0.19009491275229184
Validation loss: 2.56872013458814

Epoch: 6| Step: 8
Training loss: 0.3334816389176717
Validation loss: 2.5981624288053307

Epoch: 6| Step: 9
Training loss: 0.2495474295246636
Validation loss: 2.5926411563094978

Epoch: 6| Step: 10
Training loss: 0.2971491551656972
Validation loss: 2.58445917129265

Epoch: 6| Step: 11
Training loss: 0.2153228619411664
Validation loss: 2.567177855485299

Epoch: 6| Step: 12
Training loss: 0.35121248623567264
Validation loss: 2.5968124569882876

Epoch: 6| Step: 13
Training loss: 0.33863093470797445
Validation loss: 2.5718851747387435

Epoch: 410| Step: 0
Training loss: 0.2663519252975697
Validation loss: 2.5688469332184503

Epoch: 6| Step: 1
Training loss: 0.19373927701994945
Validation loss: 2.5409103931328025

Epoch: 6| Step: 2
Training loss: 0.28826512082266886
Validation loss: 2.539877805855836

Epoch: 6| Step: 3
Training loss: 0.22565710092998767
Validation loss: 2.549513889573074

Epoch: 6| Step: 4
Training loss: 0.19739819783595422
Validation loss: 2.5515933489135465

Epoch: 6| Step: 5
Training loss: 0.2158473243897914
Validation loss: 2.542560012566816

Epoch: 6| Step: 6
Training loss: 0.2165828627966784
Validation loss: 2.529205300589704

Epoch: 6| Step: 7
Training loss: 0.24456966847881925
Validation loss: 2.555102409434526

Epoch: 6| Step: 8
Training loss: 0.3774288121104904
Validation loss: 2.5047854081735923

Epoch: 6| Step: 9
Training loss: 0.24862554588996333
Validation loss: 2.539431738371616

Epoch: 6| Step: 10
Training loss: 0.15907342558475385
Validation loss: 2.530473720469913

Epoch: 6| Step: 11
Training loss: 0.4318581287715653
Validation loss: 2.5232019045554632

Epoch: 6| Step: 12
Training loss: 0.21185727391318393
Validation loss: 2.55684833974942

Epoch: 6| Step: 13
Training loss: 0.15428447673576595
Validation loss: 2.5808798590963535

Epoch: 411| Step: 0
Training loss: 0.1648031105550153
Validation loss: 2.591317538696525

Epoch: 6| Step: 1
Training loss: 0.14692440064541498
Validation loss: 2.5626307248301856

Epoch: 6| Step: 2
Training loss: 0.33563458292260584
Validation loss: 2.6042672283486095

Epoch: 6| Step: 3
Training loss: 0.3154259790728091
Validation loss: 2.5486852032255096

Epoch: 6| Step: 4
Training loss: 0.16663246002438992
Validation loss: 2.5796499525894796

Epoch: 6| Step: 5
Training loss: 0.311759643931686
Validation loss: 2.59411836813639

Epoch: 6| Step: 6
Training loss: 0.3680423363324987
Validation loss: 2.5668345002413853

Epoch: 6| Step: 7
Training loss: 0.1458128030551454
Validation loss: 2.5070594769008214

Epoch: 6| Step: 8
Training loss: 0.22423781470084184
Validation loss: 2.544413467382318

Epoch: 6| Step: 9
Training loss: 0.1889494660500429
Validation loss: 2.5127756446218807

Epoch: 6| Step: 10
Training loss: 0.32645908433932885
Validation loss: 2.5536977323186254

Epoch: 6| Step: 11
Training loss: 0.1155859747638752
Validation loss: 2.554815294869446

Epoch: 6| Step: 12
Training loss: 0.26313348126730646
Validation loss: 2.5517206339025575

Epoch: 6| Step: 13
Training loss: 0.12805585245544293
Validation loss: 2.563756425135453

Epoch: 412| Step: 0
Training loss: 0.2614025226744551
Validation loss: 2.5424025821949687

Epoch: 6| Step: 1
Training loss: 0.29462890726152063
Validation loss: 2.584735016399197

Epoch: 6| Step: 2
Training loss: 0.15911429179383918
Validation loss: 2.554563501956419

Epoch: 6| Step: 3
Training loss: 0.14434060849282968
Validation loss: 2.5499807521737865

Epoch: 6| Step: 4
Training loss: 0.24044094663608323
Validation loss: 2.585938010559438

Epoch: 6| Step: 5
Training loss: 0.16901211162201168
Validation loss: 2.5258819891585507

Epoch: 6| Step: 6
Training loss: 0.20131289529983665
Validation loss: 2.573876024248726

Epoch: 6| Step: 7
Training loss: 0.2721862775860566
Validation loss: 2.5437125809621195

Epoch: 6| Step: 8
Training loss: 0.18748454189157995
Validation loss: 2.560778971584131

Epoch: 6| Step: 9
Training loss: 0.3628393993213771
Validation loss: 2.5542425845916332

Epoch: 6| Step: 10
Training loss: 0.30790851663962937
Validation loss: 2.580321180560295

Epoch: 6| Step: 11
Training loss: 0.13476834087123085
Validation loss: 2.5608057363205545

Epoch: 6| Step: 12
Training loss: 0.2035712603562958
Validation loss: 2.5512831022020666

Epoch: 6| Step: 13
Training loss: 0.30867888085195044
Validation loss: 2.599808993513511

Epoch: 413| Step: 0
Training loss: 0.25347971669240843
Validation loss: 2.594976116339777

Epoch: 6| Step: 1
Training loss: 0.17418369616258472
Validation loss: 2.58036180441587

Epoch: 6| Step: 2
Training loss: 0.3083295294595751
Validation loss: 2.5868375162647697

Epoch: 6| Step: 3
Training loss: 0.22075579023327638
Validation loss: 2.576341821159351

Epoch: 6| Step: 4
Training loss: 0.22876381234383045
Validation loss: 2.5667306774847494

Epoch: 6| Step: 5
Training loss: 0.31222865722136844
Validation loss: 2.5284937856410625

Epoch: 6| Step: 6
Training loss: 0.19370868226923388
Validation loss: 2.584362489591894

Epoch: 6| Step: 7
Training loss: 0.21338605541412664
Validation loss: 2.5596318564753813

Epoch: 6| Step: 8
Training loss: 0.09719422718819194
Validation loss: 2.5648339150366755

Epoch: 6| Step: 9
Training loss: 0.4345872854282895
Validation loss: 2.567517620175224

Epoch: 6| Step: 10
Training loss: 0.3109180104075745
Validation loss: 2.5969929314155604

Epoch: 6| Step: 11
Training loss: 0.11302812841343102
Validation loss: 2.563461508492344

Epoch: 6| Step: 12
Training loss: 0.22476379228042953
Validation loss: 2.578669415291083

Epoch: 6| Step: 13
Training loss: 0.19715666830659714
Validation loss: 2.578042908496085

Epoch: 414| Step: 0
Training loss: 0.20851200409336232
Validation loss: 2.5801707792473807

Epoch: 6| Step: 1
Training loss: 0.33645720535813606
Validation loss: 2.549370412941147

Epoch: 6| Step: 2
Training loss: 0.15714796245900456
Validation loss: 2.5616425871315958

Epoch: 6| Step: 3
Training loss: 0.2112043247277723
Validation loss: 2.593065341728483

Epoch: 6| Step: 4
Training loss: 0.1387105068607247
Validation loss: 2.582602569900557

Epoch: 6| Step: 5
Training loss: 0.18639884902062565
Validation loss: 2.5705948082500085

Epoch: 6| Step: 6
Training loss: 0.41013297968655626
Validation loss: 2.5863208023826205

Epoch: 6| Step: 7
Training loss: 0.3136754697258788
Validation loss: 2.5903726396333835

Epoch: 6| Step: 8
Training loss: 0.2637631011258219
Validation loss: 2.5805097630959377

Epoch: 6| Step: 9
Training loss: 0.20317764700353672
Validation loss: 2.5734806473109404

Epoch: 6| Step: 10
Training loss: 0.2792311237541463
Validation loss: 2.5540399437216217

Epoch: 6| Step: 11
Training loss: 0.29941893123841234
Validation loss: 2.574755210821862

Epoch: 6| Step: 12
Training loss: 0.11287364304002534
Validation loss: 2.542462776911367

Epoch: 6| Step: 13
Training loss: 0.17090927634608727
Validation loss: 2.552449598685453

Epoch: 415| Step: 0
Training loss: 0.2565871945158059
Validation loss: 2.539914016240442

Epoch: 6| Step: 1
Training loss: 0.18852043629469348
Validation loss: 2.535022508521652

Epoch: 6| Step: 2
Training loss: 0.2820559979514978
Validation loss: 2.5432402357470947

Epoch: 6| Step: 3
Training loss: 0.3917926312689324
Validation loss: 2.553765539407003

Epoch: 6| Step: 4
Training loss: 0.23965610128147646
Validation loss: 2.533448839536314

Epoch: 6| Step: 5
Training loss: 0.15331859952127652
Validation loss: 2.586977373959582

Epoch: 6| Step: 6
Training loss: 0.2149104794996746
Validation loss: 2.5494927228480706

Epoch: 6| Step: 7
Training loss: 0.12449217998311907
Validation loss: 2.527427552636172

Epoch: 6| Step: 8
Training loss: 0.37541535342696325
Validation loss: 2.5004142428290788

Epoch: 6| Step: 9
Training loss: 0.3453410671897281
Validation loss: 2.5251247066558133

Epoch: 6| Step: 10
Training loss: 0.1565825142888054
Validation loss: 2.512783901431286

Epoch: 6| Step: 11
Training loss: 0.30347585626216306
Validation loss: 2.54884914033881

Epoch: 6| Step: 12
Training loss: 0.21529886418475755
Validation loss: 2.5347365180347707

Epoch: 6| Step: 13
Training loss: 0.1790357878701343
Validation loss: 2.5352811931881134

Epoch: 416| Step: 0
Training loss: 0.37853824795886926
Validation loss: 2.5574313401025335

Epoch: 6| Step: 1
Training loss: 0.2735447128462336
Validation loss: 2.5332126515892837

Epoch: 6| Step: 2
Training loss: 0.31063901386080145
Validation loss: 2.5489993636844654

Epoch: 6| Step: 3
Training loss: 0.26108773868929946
Validation loss: 2.5715592900545907

Epoch: 6| Step: 4
Training loss: 0.1316093263292002
Validation loss: 2.5625962049991693

Epoch: 6| Step: 5
Training loss: 0.2922070073434409
Validation loss: 2.5462186606703114

Epoch: 6| Step: 6
Training loss: 0.1636704460755385
Validation loss: 2.5385923636000345

Epoch: 6| Step: 7
Training loss: 0.1730935186724435
Validation loss: 2.571087667436247

Epoch: 6| Step: 8
Training loss: 0.1582713627527918
Validation loss: 2.574124517092695

Epoch: 6| Step: 9
Training loss: 0.14021713660927074
Validation loss: 2.591163429814336

Epoch: 6| Step: 10
Training loss: 0.24611865023631274
Validation loss: 2.5580151987584228

Epoch: 6| Step: 11
Training loss: 0.20203473860346288
Validation loss: 2.584197621912608

Epoch: 6| Step: 12
Training loss: 0.3784544699507847
Validation loss: 2.545829431501184

Epoch: 6| Step: 13
Training loss: 0.17646143497790934
Validation loss: 2.577966429506522

Epoch: 417| Step: 0
Training loss: 0.23630745852565269
Validation loss: 2.5772534778911025

Epoch: 6| Step: 1
Training loss: 0.14586780486957684
Validation loss: 2.5626961697759705

Epoch: 6| Step: 2
Training loss: 0.24215647283355035
Validation loss: 2.559620824200414

Epoch: 6| Step: 3
Training loss: 0.2397326215078087
Validation loss: 2.5620147301616583

Epoch: 6| Step: 4
Training loss: 0.2535840264017456
Validation loss: 2.573747409394986

Epoch: 6| Step: 5
Training loss: 0.18179376360989297
Validation loss: 2.5644146359093436

Epoch: 6| Step: 6
Training loss: 0.18737302891786894
Validation loss: 2.6006495135011494

Epoch: 6| Step: 7
Training loss: 0.27252163774869187
Validation loss: 2.581519921092066

Epoch: 6| Step: 8
Training loss: 0.4212785849508508
Validation loss: 2.6295148440667093

Epoch: 6| Step: 9
Training loss: 0.11081100290301615
Validation loss: 2.626371249157118

Epoch: 6| Step: 10
Training loss: 0.12193885591448178
Validation loss: 2.6202326698432805

Epoch: 6| Step: 11
Training loss: 0.19066611065552855
Validation loss: 2.62695543202396

Epoch: 6| Step: 12
Training loss: 0.330222555309531
Validation loss: 2.5961518032864217

Epoch: 6| Step: 13
Training loss: 0.15255077063140157
Validation loss: 2.5991830194582057

Epoch: 418| Step: 0
Training loss: 0.20539201601761017
Validation loss: 2.5964949279406904

Epoch: 6| Step: 1
Training loss: 0.15317488412490005
Validation loss: 2.605763120183804

Epoch: 6| Step: 2
Training loss: 0.3306743270984268
Validation loss: 2.6045153552182816

Epoch: 6| Step: 3
Training loss: 0.2030346559471071
Validation loss: 2.599909707640039

Epoch: 6| Step: 4
Training loss: 0.3360460460863866
Validation loss: 2.571130737960352

Epoch: 6| Step: 5
Training loss: 0.3143629098694702
Validation loss: 2.602896645905733

Epoch: 6| Step: 6
Training loss: 0.19660908436611618
Validation loss: 2.5507572796511333

Epoch: 6| Step: 7
Training loss: 0.3445487495874089
Validation loss: 2.5293101913577356

Epoch: 6| Step: 8
Training loss: 0.26208771844984785
Validation loss: 2.5534253875822923

Epoch: 6| Step: 9
Training loss: 0.17556300390089055
Validation loss: 2.5770610046918216

Epoch: 6| Step: 10
Training loss: 0.22507800266748484
Validation loss: 2.5645015252037346

Epoch: 6| Step: 11
Training loss: 0.17872373608062087
Validation loss: 2.5605289072538464

Epoch: 6| Step: 12
Training loss: 0.15286104700741002
Validation loss: 2.549706569832113

Epoch: 6| Step: 13
Training loss: 0.09906990157494065
Validation loss: 2.5687580062709103

Epoch: 419| Step: 0
Training loss: 0.15504717986524666
Validation loss: 2.578832313162715

Epoch: 6| Step: 1
Training loss: 0.19047266157356835
Validation loss: 2.5939648733573866

Epoch: 6| Step: 2
Training loss: 0.39305232241970406
Validation loss: 2.5960164304616837

Epoch: 6| Step: 3
Training loss: 0.3067014718885461
Validation loss: 2.575888495514971

Epoch: 6| Step: 4
Training loss: 0.187914965315967
Validation loss: 2.583378679934067

Epoch: 6| Step: 5
Training loss: 0.19714828816214164
Validation loss: 2.5957426681438

Epoch: 6| Step: 6
Training loss: 0.12994238555644677
Validation loss: 2.5815490487848853

Epoch: 6| Step: 7
Training loss: 0.3403240624347277
Validation loss: 2.5299941502087258

Epoch: 6| Step: 8
Training loss: 0.22272579880403215
Validation loss: 2.56333203917681

Epoch: 6| Step: 9
Training loss: 0.2925247642842155
Validation loss: 2.5652621909167643

Epoch: 6| Step: 10
Training loss: 0.12859591060459521
Validation loss: 2.5410592082668533

Epoch: 6| Step: 11
Training loss: 0.21403227056637883
Validation loss: 2.540875987346748

Epoch: 6| Step: 12
Training loss: 0.2237397816791511
Validation loss: 2.5684772363503927

Epoch: 6| Step: 13
Training loss: 0.12622841344780633
Validation loss: 2.546705103283865

Epoch: 420| Step: 0
Training loss: 0.2908777383913942
Validation loss: 2.595873773088942

Epoch: 6| Step: 1
Training loss: 0.32830841750927786
Validation loss: 2.544907007399138

Epoch: 6| Step: 2
Training loss: 0.3743808522666553
Validation loss: 2.5628267695633986

Epoch: 6| Step: 3
Training loss: 0.21286644054548776
Validation loss: 2.5764212459305043

Epoch: 6| Step: 4
Training loss: 0.10534869531358587
Validation loss: 2.5704786601840204

Epoch: 6| Step: 5
Training loss: 0.23337939515901843
Validation loss: 2.61817096665339

Epoch: 6| Step: 6
Training loss: 0.20955632279516045
Validation loss: 2.598996814743176

Epoch: 6| Step: 7
Training loss: 0.16803522790531775
Validation loss: 2.6035047570180763

Epoch: 6| Step: 8
Training loss: 0.1657969605500735
Validation loss: 2.5928316493291876

Epoch: 6| Step: 9
Training loss: 0.23178969888665024
Validation loss: 2.5715694117703327

Epoch: 6| Step: 10
Training loss: 0.12572905897068995
Validation loss: 2.614446165442065

Epoch: 6| Step: 11
Training loss: 0.21830383850179388
Validation loss: 2.5879128427416633

Epoch: 6| Step: 12
Training loss: 0.1461697505692566
Validation loss: 2.597030689909344

Epoch: 6| Step: 13
Training loss: 0.2930444238204771
Validation loss: 2.596651997210502

Epoch: 421| Step: 0
Training loss: 0.21523519747762118
Validation loss: 2.598526003652551

Epoch: 6| Step: 1
Training loss: 0.2603288725046657
Validation loss: 2.5842212820803665

Epoch: 6| Step: 2
Training loss: 0.17136200294625673
Validation loss: 2.6224972776912265

Epoch: 6| Step: 3
Training loss: 0.1014583401986785
Validation loss: 2.564642583954426

Epoch: 6| Step: 4
Training loss: 0.23484273174265644
Validation loss: 2.5746975795325406

Epoch: 6| Step: 5
Training loss: 0.40122561963009923
Validation loss: 2.575626794441218

Epoch: 6| Step: 6
Training loss: 0.19819272180545391
Validation loss: 2.5346736019062277

Epoch: 6| Step: 7
Training loss: 0.23169993627083882
Validation loss: 2.558395202442831

Epoch: 6| Step: 8
Training loss: 0.13672018050399085
Validation loss: 2.5726314521273204

Epoch: 6| Step: 9
Training loss: 0.15136539088998047
Validation loss: 2.539415228412081

Epoch: 6| Step: 10
Training loss: 0.19305519299126236
Validation loss: 2.5279951662077353

Epoch: 6| Step: 11
Training loss: 0.24780895056233065
Validation loss: 2.5427167496123486

Epoch: 6| Step: 12
Training loss: 0.12248216198696862
Validation loss: 2.5386748784909545

Epoch: 6| Step: 13
Training loss: 0.37383978894252645
Validation loss: 2.5450238545890977

Epoch: 422| Step: 0
Training loss: 0.17249417940457648
Validation loss: 2.529837510607901

Epoch: 6| Step: 1
Training loss: 0.23101573625445146
Validation loss: 2.54869110967498

Epoch: 6| Step: 2
Training loss: 0.212709148296759
Validation loss: 2.557759136088019

Epoch: 6| Step: 3
Training loss: 0.2934574501682027
Validation loss: 2.5790088658634533

Epoch: 6| Step: 4
Training loss: 0.24224011557228103
Validation loss: 2.622893124196601

Epoch: 6| Step: 5
Training loss: 0.22986510799296972
Validation loss: 2.6277839207839935

Epoch: 6| Step: 6
Training loss: 0.1961887824650677
Validation loss: 2.6235068333045586

Epoch: 6| Step: 7
Training loss: 0.27037888081199674
Validation loss: 2.635208939467103

Epoch: 6| Step: 8
Training loss: 0.29329990744246265
Validation loss: 2.6157406383685435

Epoch: 6| Step: 9
Training loss: 0.2939914654462892
Validation loss: 2.5990172897820742

Epoch: 6| Step: 10
Training loss: 0.1801909877077011
Validation loss: 2.5930073091523305

Epoch: 6| Step: 11
Training loss: 0.17045209089953872
Validation loss: 2.6157099371158994

Epoch: 6| Step: 12
Training loss: 0.18421915749916518
Validation loss: 2.559711466726278

Epoch: 6| Step: 13
Training loss: 0.31184833051370114
Validation loss: 2.5692367938372973

Epoch: 423| Step: 0
Training loss: 0.18900052307954693
Validation loss: 2.5234673011701685

Epoch: 6| Step: 1
Training loss: 0.2451135323544512
Validation loss: 2.5288000836090667

Epoch: 6| Step: 2
Training loss: 0.18407618262918607
Validation loss: 2.5545668036446463

Epoch: 6| Step: 3
Training loss: 0.1853415507596299
Validation loss: 2.5384564662008477

Epoch: 6| Step: 4
Training loss: 0.3991330750983899
Validation loss: 2.5487378578544777

Epoch: 6| Step: 5
Training loss: 0.17945414400454926
Validation loss: 2.602377429875888

Epoch: 6| Step: 6
Training loss: 0.1200886087612504
Validation loss: 2.5576750918963795

Epoch: 6| Step: 7
Training loss: 0.19501793583277993
Validation loss: 2.609880857783443

Epoch: 6| Step: 8
Training loss: 0.15248181127126023
Validation loss: 2.5843058914487456

Epoch: 6| Step: 9
Training loss: 0.2607118110250015
Validation loss: 2.5932945160897733

Epoch: 6| Step: 10
Training loss: 0.15256633148476723
Validation loss: 2.5605010172494547

Epoch: 6| Step: 11
Training loss: 0.2203705991742657
Validation loss: 2.5261608055511298

Epoch: 6| Step: 12
Training loss: 0.3732568040318324
Validation loss: 2.576602359620297

Epoch: 6| Step: 13
Training loss: 0.11313307460003519
Validation loss: 2.5367918689506044

Epoch: 424| Step: 0
Training loss: 0.20586472383097465
Validation loss: 2.5378060881515694

Epoch: 6| Step: 1
Training loss: 0.39194306206896856
Validation loss: 2.525624983461149

Epoch: 6| Step: 2
Training loss: 0.15050510904045916
Validation loss: 2.5649134152995754

Epoch: 6| Step: 3
Training loss: 0.1696681342393646
Validation loss: 2.565429737465131

Epoch: 6| Step: 4
Training loss: 0.3707930501031936
Validation loss: 2.572555112716864

Epoch: 6| Step: 5
Training loss: 0.2058100219575064
Validation loss: 2.5469011126378134

Epoch: 6| Step: 6
Training loss: 0.10465193507325563
Validation loss: 2.543659020055381

Epoch: 6| Step: 7
Training loss: 0.07833886973123382
Validation loss: 2.5519888459612283

Epoch: 6| Step: 8
Training loss: 0.14608510598706412
Validation loss: 2.5541974547529165

Epoch: 6| Step: 9
Training loss: 0.22410790398375652
Validation loss: 2.5504496271096144

Epoch: 6| Step: 10
Training loss: 0.2102711005650598
Validation loss: 2.5279473985903995

Epoch: 6| Step: 11
Training loss: 0.21481988947758338
Validation loss: 2.528134666051324

Epoch: 6| Step: 12
Training loss: 0.1953406885786273
Validation loss: 2.5301017207609227

Epoch: 6| Step: 13
Training loss: 0.18589370836950625
Validation loss: 2.5191818728945345

Epoch: 425| Step: 0
Training loss: 0.22579322308007846
Validation loss: 2.5194172377981996

Epoch: 6| Step: 1
Training loss: 0.17606805080754212
Validation loss: 2.5193847013300825

Epoch: 6| Step: 2
Training loss: 0.22176621550671738
Validation loss: 2.521466002823868

Epoch: 6| Step: 3
Training loss: 0.1551739115809451
Validation loss: 2.5254214152109586

Epoch: 6| Step: 4
Training loss: 0.3136627975043483
Validation loss: 2.5707477503147875

Epoch: 6| Step: 5
Training loss: 0.2776244046395079
Validation loss: 2.572765138795759

Epoch: 6| Step: 6
Training loss: 0.28782071334849474
Validation loss: 2.557281949917629

Epoch: 6| Step: 7
Training loss: 0.11965392104213862
Validation loss: 2.56916508137507

Epoch: 6| Step: 8
Training loss: 0.3078882022656839
Validation loss: 2.5746390732018734

Epoch: 6| Step: 9
Training loss: 0.27975359833578944
Validation loss: 2.59443487976284

Epoch: 6| Step: 10
Training loss: 0.2039765152865228
Validation loss: 2.5653762252514993

Epoch: 6| Step: 11
Training loss: 0.1496347468104795
Validation loss: 2.5399659806469077

Epoch: 6| Step: 12
Training loss: 0.18688688768257572
Validation loss: 2.5710114187944106

Epoch: 6| Step: 13
Training loss: 0.25561141600576015
Validation loss: 2.551533957126449

Epoch: 426| Step: 0
Training loss: 0.2017547994944441
Validation loss: 2.537388551007242

Epoch: 6| Step: 1
Training loss: 0.20143735830341672
Validation loss: 2.573435044940749

Epoch: 6| Step: 2
Training loss: 0.1595272820957223
Validation loss: 2.5888122336637913

Epoch: 6| Step: 3
Training loss: 0.21579113931389504
Validation loss: 2.5758717325456897

Epoch: 6| Step: 4
Training loss: 0.346934469383306
Validation loss: 2.5850121748766415

Epoch: 6| Step: 5
Training loss: 0.2737855603362416
Validation loss: 2.5685120374579182

Epoch: 6| Step: 6
Training loss: 0.32747562046526635
Validation loss: 2.580298117021421

Epoch: 6| Step: 7
Training loss: 0.13825622914130759
Validation loss: 2.535113804035234

Epoch: 6| Step: 8
Training loss: 0.13878623518250208
Validation loss: 2.5709251912590965

Epoch: 6| Step: 9
Training loss: 0.22067122102221992
Validation loss: 2.540754069338694

Epoch: 6| Step: 10
Training loss: 0.1735009854773806
Validation loss: 2.5204661288405537

Epoch: 6| Step: 11
Training loss: 0.2537487128182823
Validation loss: 2.551771448669233

Epoch: 6| Step: 12
Training loss: 0.3189443234336641
Validation loss: 2.5405060552283865

Epoch: 6| Step: 13
Training loss: 0.11564160981601024
Validation loss: 2.5527980731940194

Epoch: 427| Step: 0
Training loss: 0.210465946108033
Validation loss: 2.568934561762849

Epoch: 6| Step: 1
Training loss: 0.27365003228036644
Validation loss: 2.553684657073848

Epoch: 6| Step: 2
Training loss: 0.30958066134799345
Validation loss: 2.5395501589018834

Epoch: 6| Step: 3
Training loss: 0.30200956392065303
Validation loss: 2.5550179256685897

Epoch: 6| Step: 4
Training loss: 0.19811261457244606
Validation loss: 2.5624397184703285

Epoch: 6| Step: 5
Training loss: 0.3660240408500849
Validation loss: 2.5318365416348665

Epoch: 6| Step: 6
Training loss: 0.21311653469982353
Validation loss: 2.5591632959649626

Epoch: 6| Step: 7
Training loss: 0.14827954521445313
Validation loss: 2.542503483106088

Epoch: 6| Step: 8
Training loss: 0.2177278274192231
Validation loss: 2.4998772344902545

Epoch: 6| Step: 9
Training loss: 0.19201265344362178
Validation loss: 2.5008895824366713

Epoch: 6| Step: 10
Training loss: 0.17921212796895483
Validation loss: 2.5332507925020358

Epoch: 6| Step: 11
Training loss: 0.1738425902445041
Validation loss: 2.4906324349867783

Epoch: 6| Step: 12
Training loss: 0.2519501234955134
Validation loss: 2.5076110204842847

Epoch: 6| Step: 13
Training loss: 0.21307115162600374
Validation loss: 2.5105017530744034

Epoch: 428| Step: 0
Training loss: 0.2656049159815857
Validation loss: 2.5488282497206227

Epoch: 6| Step: 1
Training loss: 0.3053225477160284
Validation loss: 2.5918002815835295

Epoch: 6| Step: 2
Training loss: 0.2107980231701362
Validation loss: 2.5530627449239414

Epoch: 6| Step: 3
Training loss: 0.15512090664595554
Validation loss: 2.5954263871200687

Epoch: 6| Step: 4
Training loss: 0.25002221664418145
Validation loss: 2.6077975242307283

Epoch: 6| Step: 5
Training loss: 0.15319417514949799
Validation loss: 2.5821734698224565

Epoch: 6| Step: 6
Training loss: 0.21738289338664754
Validation loss: 2.596072094880592

Epoch: 6| Step: 7
Training loss: 0.1421387840488087
Validation loss: 2.5771862181556386

Epoch: 6| Step: 8
Training loss: 0.15497441559419997
Validation loss: 2.5607185674463935

Epoch: 6| Step: 9
Training loss: 0.22745197905440276
Validation loss: 2.5607427258686224

Epoch: 6| Step: 10
Training loss: 0.4484528023903474
Validation loss: 2.562668613475909

Epoch: 6| Step: 11
Training loss: 0.22661035953011427
Validation loss: 2.5710573951943148

Epoch: 6| Step: 12
Training loss: 0.22038267722364518
Validation loss: 2.534356723860766

Epoch: 6| Step: 13
Training loss: 0.20335716954199312
Validation loss: 2.5236329719483237

Epoch: 429| Step: 0
Training loss: 0.24369863555817387
Validation loss: 2.514512659125326

Epoch: 6| Step: 1
Training loss: 0.16742607545767849
Validation loss: 2.5114821950961876

Epoch: 6| Step: 2
Training loss: 0.2667928994191151
Validation loss: 2.5529926326735977

Epoch: 6| Step: 3
Training loss: 0.21416120481082188
Validation loss: 2.5652484455741273

Epoch: 6| Step: 4
Training loss: 0.14147533183526576
Validation loss: 2.593319450549197

Epoch: 6| Step: 5
Training loss: 0.10956066415503178
Validation loss: 2.5729574341666455

Epoch: 6| Step: 6
Training loss: 0.18341417864601528
Validation loss: 2.571857694965034

Epoch: 6| Step: 7
Training loss: 0.36212030124743216
Validation loss: 2.552176820416822

Epoch: 6| Step: 8
Training loss: 0.3210423458561695
Validation loss: 2.5292635108203276

Epoch: 6| Step: 9
Training loss: 0.2766117052175
Validation loss: 2.565756954725592

Epoch: 6| Step: 10
Training loss: 0.23519917853497407
Validation loss: 2.527441122787424

Epoch: 6| Step: 11
Training loss: 0.21273437505603668
Validation loss: 2.509367889724004

Epoch: 6| Step: 12
Training loss: 0.15185213238648
Validation loss: 2.51919999714192

Epoch: 6| Step: 13
Training loss: 0.09991009981358355
Validation loss: 2.4975053307556654

Epoch: 430| Step: 0
Training loss: 0.345096907913059
Validation loss: 2.545177182448275

Epoch: 6| Step: 1
Training loss: 0.2019403741378762
Validation loss: 2.5040460106996445

Epoch: 6| Step: 2
Training loss: 0.11753484984633095
Validation loss: 2.5425871505769817

Epoch: 6| Step: 3
Training loss: 0.16835831776793717
Validation loss: 2.5383047886953554

Epoch: 6| Step: 4
Training loss: 0.19790348000683353
Validation loss: 2.4814949241668374

Epoch: 6| Step: 5
Training loss: 0.2964524348649087
Validation loss: 2.508720279907124

Epoch: 6| Step: 6
Training loss: 0.1450735627290531
Validation loss: 2.516774362810359

Epoch: 6| Step: 7
Training loss: 0.2738841632091864
Validation loss: 2.5293324128355867

Epoch: 6| Step: 8
Training loss: 0.10265580752029164
Validation loss: 2.5007687417320383

Epoch: 6| Step: 9
Training loss: 0.20632298796447035
Validation loss: 2.4721303455492287

Epoch: 6| Step: 10
Training loss: 0.25352449328130505
Validation loss: 2.500412825882918

Epoch: 6| Step: 11
Training loss: 0.16217395346449265
Validation loss: 2.4888322610045113

Epoch: 6| Step: 12
Training loss: 0.2875267550209653
Validation loss: 2.514309161346838

Epoch: 6| Step: 13
Training loss: 0.10191151365380449
Validation loss: 2.4999134469174895

Epoch: 431| Step: 0
Training loss: 0.2662944491987195
Validation loss: 2.5568967555686286

Epoch: 6| Step: 1
Training loss: 0.11639492312630151
Validation loss: 2.5591733184494108

Epoch: 6| Step: 2
Training loss: 0.26252508497724475
Validation loss: 2.60695298176553

Epoch: 6| Step: 3
Training loss: 0.206594438204631
Validation loss: 2.606703693337884

Epoch: 6| Step: 4
Training loss: 0.16268736280639937
Validation loss: 2.5697812899362455

Epoch: 6| Step: 5
Training loss: 0.19009967476402084
Validation loss: 2.5787149101835936

Epoch: 6| Step: 6
Training loss: 0.16691858777840232
Validation loss: 2.573468957652659

Epoch: 6| Step: 7
Training loss: 0.2143430684528341
Validation loss: 2.58087963261929

Epoch: 6| Step: 8
Training loss: 0.25661919154484075
Validation loss: 2.5640964252329024

Epoch: 6| Step: 9
Training loss: 0.15859885818260142
Validation loss: 2.5397342471659448

Epoch: 6| Step: 10
Training loss: 0.297445664793341
Validation loss: 2.5502080105047726

Epoch: 6| Step: 11
Training loss: 0.09784588997211568
Validation loss: 2.55729280481843

Epoch: 6| Step: 12
Training loss: 0.2705105254660394
Validation loss: 2.566914289595619

Epoch: 6| Step: 13
Training loss: 0.374841557250262
Validation loss: 2.5371539883175336

Epoch: 432| Step: 0
Training loss: 0.16903203601622668
Validation loss: 2.5470735724287716

Epoch: 6| Step: 1
Training loss: 0.13337085963823803
Validation loss: 2.560970569295402

Epoch: 6| Step: 2
Training loss: 0.3031027122051188
Validation loss: 2.538828061673486

Epoch: 6| Step: 3
Training loss: 0.17223778821976585
Validation loss: 2.527839085269943

Epoch: 6| Step: 4
Training loss: 0.3004435340111934
Validation loss: 2.5436524901514646

Epoch: 6| Step: 5
Training loss: 0.15746211538628968
Validation loss: 2.472533407333271

Epoch: 6| Step: 6
Training loss: 0.12216706065961806
Validation loss: 2.5491294493193335

Epoch: 6| Step: 7
Training loss: 0.25313936475330945
Validation loss: 2.536511418984626

Epoch: 6| Step: 8
Training loss: 0.20679237872439307
Validation loss: 2.5315037859280918

Epoch: 6| Step: 9
Training loss: 0.1540237314819812
Validation loss: 2.525803253793652

Epoch: 6| Step: 10
Training loss: 0.17831786238626024
Validation loss: 2.5393758964385054

Epoch: 6| Step: 11
Training loss: 0.2307793173454009
Validation loss: 2.5691683563157364

Epoch: 6| Step: 12
Training loss: 0.27285983510675715
Validation loss: 2.5804709253596956

Epoch: 6| Step: 13
Training loss: 0.0824297184850544
Validation loss: 2.5420539321539914

Epoch: 433| Step: 0
Training loss: 0.090641414660266
Validation loss: 2.6082638565739176

Epoch: 6| Step: 1
Training loss: 0.21359973889307696
Validation loss: 2.543922673222429

Epoch: 6| Step: 2
Training loss: 0.3471137325022796
Validation loss: 2.576767876426948

Epoch: 6| Step: 3
Training loss: 0.2381473383851078
Validation loss: 2.585363474234383

Epoch: 6| Step: 4
Training loss: 0.2200019975051363
Validation loss: 2.578899418629404

Epoch: 6| Step: 5
Training loss: 0.2640292677198222
Validation loss: 2.570047226648224

Epoch: 6| Step: 6
Training loss: 0.14878473951089116
Validation loss: 2.554274663990803

Epoch: 6| Step: 7
Training loss: 0.13700288810739955
Validation loss: 2.4849738840446784

Epoch: 6| Step: 8
Training loss: 0.18039769305445266
Validation loss: 2.5176459955739987

Epoch: 6| Step: 9
Training loss: 0.19338255078690197
Validation loss: 2.5388786846354727

Epoch: 6| Step: 10
Training loss: 0.14916995933519758
Validation loss: 2.545127198474211

Epoch: 6| Step: 11
Training loss: 0.2770301899940793
Validation loss: 2.537313173016569

Epoch: 6| Step: 12
Training loss: 0.18421183696908877
Validation loss: 2.550904882668257

Epoch: 6| Step: 13
Training loss: 0.08268235017619228
Validation loss: 2.5368481906841285

Epoch: 434| Step: 0
Training loss: 0.1427642574046487
Validation loss: 2.5482696692109603

Epoch: 6| Step: 1
Training loss: 0.25966963751329497
Validation loss: 2.538090319173336

Epoch: 6| Step: 2
Training loss: 0.1883015882816832
Validation loss: 2.560050609081003

Epoch: 6| Step: 3
Training loss: 0.10057454368724611
Validation loss: 2.55459864615128

Epoch: 6| Step: 4
Training loss: 0.2163714281015419
Validation loss: 2.5462992057729807

Epoch: 6| Step: 5
Training loss: 0.17818168273657
Validation loss: 2.5654674496193626

Epoch: 6| Step: 6
Training loss: 0.18611833009688172
Validation loss: 2.5754752116766

Epoch: 6| Step: 7
Training loss: 0.13820813773182294
Validation loss: 2.5619057197076813

Epoch: 6| Step: 8
Training loss: 0.2662496234998593
Validation loss: 2.597428073402206

Epoch: 6| Step: 9
Training loss: 0.12457572563398514
Validation loss: 2.6157322245950145

Epoch: 6| Step: 10
Training loss: 0.12754394527745053
Validation loss: 2.605398842648492

Epoch: 6| Step: 11
Training loss: 0.32546715357366496
Validation loss: 2.5865974403299865

Epoch: 6| Step: 12
Training loss: 0.29496858239575796
Validation loss: 2.584522061806754

Epoch: 6| Step: 13
Training loss: 0.16899458216378307
Validation loss: 2.5823046203663518

Epoch: 435| Step: 0
Training loss: 0.2991232194118213
Validation loss: 2.617321651463053

Epoch: 6| Step: 1
Training loss: 0.2016410171995668
Validation loss: 2.569812285006795

Epoch: 6| Step: 2
Training loss: 0.18319199615708254
Validation loss: 2.6223588480527975

Epoch: 6| Step: 3
Training loss: 0.2878964851849209
Validation loss: 2.595035498323703

Epoch: 6| Step: 4
Training loss: 0.17740446429406365
Validation loss: 2.5625860098253703

Epoch: 6| Step: 5
Training loss: 0.16191055560944545
Validation loss: 2.585479817765238

Epoch: 6| Step: 6
Training loss: 0.19329466844883786
Validation loss: 2.587725660128145

Epoch: 6| Step: 7
Training loss: 0.15283310374898249
Validation loss: 2.5528754261807527

Epoch: 6| Step: 8
Training loss: 0.11128401300631137
Validation loss: 2.547390642328012

Epoch: 6| Step: 9
Training loss: 0.20896134294172547
Validation loss: 2.545423943758212

Epoch: 6| Step: 10
Training loss: 0.36356715775159326
Validation loss: 2.5404941669193897

Epoch: 6| Step: 11
Training loss: 0.14300649775192723
Validation loss: 2.5263586655834414

Epoch: 6| Step: 12
Training loss: 0.24933570282100467
Validation loss: 2.5472927076850196

Epoch: 6| Step: 13
Training loss: 0.11315334021059446
Validation loss: 2.5400586376393224

Epoch: 436| Step: 0
Training loss: 0.21949140893105942
Validation loss: 2.5604779669167375

Epoch: 6| Step: 1
Training loss: 0.20336210643972444
Validation loss: 2.5805686479487866

Epoch: 6| Step: 2
Training loss: 0.10895706692595437
Validation loss: 2.561370077259423

Epoch: 6| Step: 3
Training loss: 0.13600081909332729
Validation loss: 2.604616075356541

Epoch: 6| Step: 4
Training loss: 0.12512781641721957
Validation loss: 2.576545912395084

Epoch: 6| Step: 5
Training loss: 0.23441231748404684
Validation loss: 2.555771105320857

Epoch: 6| Step: 6
Training loss: 0.19112212638678147
Validation loss: 2.5934669526994867

Epoch: 6| Step: 7
Training loss: 0.15158709886846522
Validation loss: 2.5711635698263606

Epoch: 6| Step: 8
Training loss: 0.1599261445154344
Validation loss: 2.5333783787569115

Epoch: 6| Step: 9
Training loss: 0.1613320130810266
Validation loss: 2.5408463278039997

Epoch: 6| Step: 10
Training loss: 0.17515683533045812
Validation loss: 2.5326719342638095

Epoch: 6| Step: 11
Training loss: 0.30867305171262405
Validation loss: 2.5079244719563527

Epoch: 6| Step: 12
Training loss: 0.38679064458068
Validation loss: 2.5262947289825046

Epoch: 6| Step: 13
Training loss: 0.12534219870300436
Validation loss: 2.5100255639492315

Epoch: 437| Step: 0
Training loss: 0.19793303112505584
Validation loss: 2.494823117447231

Epoch: 6| Step: 1
Training loss: 0.1558762072793267
Validation loss: 2.501540661942012

Epoch: 6| Step: 2
Training loss: 0.1615928440817376
Validation loss: 2.495573580793268

Epoch: 6| Step: 3
Training loss: 0.17617506840554192
Validation loss: 2.4856056193608698

Epoch: 6| Step: 4
Training loss: 0.2438097122608
Validation loss: 2.4935676136893257

Epoch: 6| Step: 5
Training loss: 0.16717938755532058
Validation loss: 2.5097593715764264

Epoch: 6| Step: 6
Training loss: 0.11086800507389243
Validation loss: 2.520407276019268

Epoch: 6| Step: 7
Training loss: 0.27032299131640064
Validation loss: 2.5054941625534273

Epoch: 6| Step: 8
Training loss: 0.2361780273211577
Validation loss: 2.516235873049212

Epoch: 6| Step: 9
Training loss: 0.24248577024553855
Validation loss: 2.5162875821912167

Epoch: 6| Step: 10
Training loss: 0.09959314251449022
Validation loss: 2.558443630072596

Epoch: 6| Step: 11
Training loss: 0.11395160284324232
Validation loss: 2.5580293467645747

Epoch: 6| Step: 12
Training loss: 0.32992551311534823
Validation loss: 2.568163695707163

Epoch: 6| Step: 13
Training loss: 0.2158575586828634
Validation loss: 2.536301331669243

Epoch: 438| Step: 0
Training loss: 0.1825880853648141
Validation loss: 2.530564028229403

Epoch: 6| Step: 1
Training loss: 0.25988183254582975
Validation loss: 2.5207750884401774

Epoch: 6| Step: 2
Training loss: 0.09043952113953144
Validation loss: 2.5231629741741095

Epoch: 6| Step: 3
Training loss: 0.19787019677637102
Validation loss: 2.5415189485947103

Epoch: 6| Step: 4
Training loss: 0.21912637756053915
Validation loss: 2.5269289333258933

Epoch: 6| Step: 5
Training loss: 0.1536396976366534
Validation loss: 2.537706577926993

Epoch: 6| Step: 6
Training loss: 0.15655504490659125
Validation loss: 2.5211096842395047

Epoch: 6| Step: 7
Training loss: 0.14810918588764066
Validation loss: 2.530588531255274

Epoch: 6| Step: 8
Training loss: 0.25523298332645294
Validation loss: 2.5291113032757084

Epoch: 6| Step: 9
Training loss: 0.2686534075922201
Validation loss: 2.540407758301421

Epoch: 6| Step: 10
Training loss: 0.29026144987303815
Validation loss: 2.542605114036055

Epoch: 6| Step: 11
Training loss: 0.31359156462891985
Validation loss: 2.5509528620732205

Epoch: 6| Step: 12
Training loss: 0.16874275302337416
Validation loss: 2.540218179240155

Epoch: 6| Step: 13
Training loss: 0.1537534039496609
Validation loss: 2.5399483073772493

Epoch: 439| Step: 0
Training loss: 0.13554849458765744
Validation loss: 2.5232972822641475

Epoch: 6| Step: 1
Training loss: 0.13396386748649347
Validation loss: 2.52771819416067

Epoch: 6| Step: 2
Training loss: 0.22298185065423506
Validation loss: 2.531189041082246

Epoch: 6| Step: 3
Training loss: 0.312016422910853
Validation loss: 2.493918309409789

Epoch: 6| Step: 4
Training loss: 0.3370989969187693
Validation loss: 2.530309368915402

Epoch: 6| Step: 5
Training loss: 0.28151389827686746
Validation loss: 2.5178517989100997

Epoch: 6| Step: 6
Training loss: 0.2152193860409775
Validation loss: 2.5178247218982825

Epoch: 6| Step: 7
Training loss: 0.1151704368366959
Validation loss: 2.5242387134665973

Epoch: 6| Step: 8
Training loss: 0.20358853452769451
Validation loss: 2.5414064655090955

Epoch: 6| Step: 9
Training loss: 0.1378755674704998
Validation loss: 2.5580797245363027

Epoch: 6| Step: 10
Training loss: 0.3258584395335527
Validation loss: 2.5193856242624277

Epoch: 6| Step: 11
Training loss: 0.11859273001643082
Validation loss: 2.507482688514514

Epoch: 6| Step: 12
Training loss: 0.19695022599032264
Validation loss: 2.511748744304707

Epoch: 6| Step: 13
Training loss: 0.060302830900663275
Validation loss: 2.5106593723452013

Epoch: 440| Step: 0
Training loss: 0.15985352119941243
Validation loss: 2.522553526076109

Epoch: 6| Step: 1
Training loss: 0.15715247831523504
Validation loss: 2.4961633221450796

Epoch: 6| Step: 2
Training loss: 0.2735220914510506
Validation loss: 2.492005875371117

Epoch: 6| Step: 3
Training loss: 0.27558680912044903
Validation loss: 2.4835310168171687

Epoch: 6| Step: 4
Training loss: 0.21546684421971748
Validation loss: 2.5512901180108143

Epoch: 6| Step: 5
Training loss: 0.1716960387097614
Validation loss: 2.5381366919241843

Epoch: 6| Step: 6
Training loss: 0.1354695745572842
Validation loss: 2.5586882803534032

Epoch: 6| Step: 7
Training loss: 0.2781963406908332
Validation loss: 2.5714170404930274

Epoch: 6| Step: 8
Training loss: 0.26043681861471557
Validation loss: 2.5713040467518327

Epoch: 6| Step: 9
Training loss: 0.21834888467174085
Validation loss: 2.6023381786640396

Epoch: 6| Step: 10
Training loss: 0.19512700809359426
Validation loss: 2.567742325506337

Epoch: 6| Step: 11
Training loss: 0.11858990286064126
Validation loss: 2.582345637423155

Epoch: 6| Step: 12
Training loss: 0.15574827704234365
Validation loss: 2.528511827932725

Epoch: 6| Step: 13
Training loss: 0.2188284767254281
Validation loss: 2.5285557088442996

Epoch: 441| Step: 0
Training loss: 0.20794302419416738
Validation loss: 2.551634974184769

Epoch: 6| Step: 1
Training loss: 0.10462484228300013
Validation loss: 2.509960311451178

Epoch: 6| Step: 2
Training loss: 0.28666053773506733
Validation loss: 2.4952285640602643

Epoch: 6| Step: 3
Training loss: 0.14159341328289785
Validation loss: 2.4973243854485636

Epoch: 6| Step: 4
Training loss: 0.2875952469574248
Validation loss: 2.5538070429418913

Epoch: 6| Step: 5
Training loss: 0.27413025702424965
Validation loss: 2.5136534426630104

Epoch: 6| Step: 6
Training loss: 0.15524372680286397
Validation loss: 2.547667792099395

Epoch: 6| Step: 7
Training loss: 0.31014345464569165
Validation loss: 2.558058303982503

Epoch: 6| Step: 8
Training loss: 0.1486755206973591
Validation loss: 2.5959022627250676

Epoch: 6| Step: 9
Training loss: 0.17547347357108178
Validation loss: 2.577150705548666

Epoch: 6| Step: 10
Training loss: 0.21566496734346408
Validation loss: 2.5648101809741357

Epoch: 6| Step: 11
Training loss: 0.162604569525854
Validation loss: 2.5755013707844205

Epoch: 6| Step: 12
Training loss: 0.1163869774628779
Validation loss: 2.5775011169756454

Epoch: 6| Step: 13
Training loss: 0.17879920613986847
Validation loss: 2.557390994064468

Epoch: 442| Step: 0
Training loss: 0.278940506976393
Validation loss: 2.5326940604520103

Epoch: 6| Step: 1
Training loss: 0.09727061423562096
Validation loss: 2.5635896872440784

Epoch: 6| Step: 2
Training loss: 0.16387302947514565
Validation loss: 2.591138079841842

Epoch: 6| Step: 3
Training loss: 0.09219218419992443
Validation loss: 2.561711900716145

Epoch: 6| Step: 4
Training loss: 0.2098938413356665
Validation loss: 2.578399500398718

Epoch: 6| Step: 5
Training loss: 0.15139429403444393
Validation loss: 2.5694328613448825

Epoch: 6| Step: 6
Training loss: 0.245179233069376
Validation loss: 2.5617198762040343

Epoch: 6| Step: 7
Training loss: 0.1053397749917816
Validation loss: 2.519509839527137

Epoch: 6| Step: 8
Training loss: 0.2776054705552809
Validation loss: 2.5543458902183334

Epoch: 6| Step: 9
Training loss: 0.28621423754033254
Validation loss: 2.511852003341308

Epoch: 6| Step: 10
Training loss: 0.152843194620874
Validation loss: 2.482412188090486

Epoch: 6| Step: 11
Training loss: 0.20084300520138412
Validation loss: 2.497805621904189

Epoch: 6| Step: 12
Training loss: 0.2853575479348382
Validation loss: 2.5098510947249424

Epoch: 6| Step: 13
Training loss: 0.18869761613222963
Validation loss: 2.5163262766247922

Epoch: 443| Step: 0
Training loss: 0.17764223246434713
Validation loss: 2.458641859507766

Epoch: 6| Step: 1
Training loss: 0.11095224470555663
Validation loss: 2.5020321882371337

Epoch: 6| Step: 2
Training loss: 0.21209312819331713
Validation loss: 2.5379462088591382

Epoch: 6| Step: 3
Training loss: 0.08405373448277388
Validation loss: 2.574846401346639

Epoch: 6| Step: 4
Training loss: 0.15546616403547261
Validation loss: 2.573177134317013

Epoch: 6| Step: 5
Training loss: 0.1747223484325113
Validation loss: 2.601233466018667

Epoch: 6| Step: 6
Training loss: 0.34159221516422206
Validation loss: 2.55613828614977

Epoch: 6| Step: 7
Training loss: 0.193224879411775
Validation loss: 2.5519271739189606

Epoch: 6| Step: 8
Training loss: 0.1415930252132417
Validation loss: 2.503882490273832

Epoch: 6| Step: 9
Training loss: 0.1567921412256591
Validation loss: 2.5193114286319207

Epoch: 6| Step: 10
Training loss: 0.2229095657649651
Validation loss: 2.51700768610851

Epoch: 6| Step: 11
Training loss: 0.258593546587815
Validation loss: 2.5042298885465546

Epoch: 6| Step: 12
Training loss: 0.2907614141685442
Validation loss: 2.5558798207361533

Epoch: 6| Step: 13
Training loss: 0.18805079225866717
Validation loss: 2.5364827509505736

Epoch: 444| Step: 0
Training loss: 0.1098968030862673
Validation loss: 2.5275378548534553

Epoch: 6| Step: 1
Training loss: 0.10738641847319623
Validation loss: 2.543285131616875

Epoch: 6| Step: 2
Training loss: 0.22574078418343693
Validation loss: 2.5830475460228057

Epoch: 6| Step: 3
Training loss: 0.1948573244500997
Validation loss: 2.5433822549438085

Epoch: 6| Step: 4
Training loss: 0.249438691323479
Validation loss: 2.5462259965126925

Epoch: 6| Step: 5
Training loss: 0.12942127455245436
Validation loss: 2.555861416957013

Epoch: 6| Step: 6
Training loss: 0.31430550184365075
Validation loss: 2.5211299696961857

Epoch: 6| Step: 7
Training loss: 0.11165382192466203
Validation loss: 2.5326396753744427

Epoch: 6| Step: 8
Training loss: 0.24624527701578258
Validation loss: 2.5232824691105633

Epoch: 6| Step: 9
Training loss: 0.2589441518488532
Validation loss: 2.514183585854547

Epoch: 6| Step: 10
Training loss: 0.2080021888796551
Validation loss: 2.526901887888688

Epoch: 6| Step: 11
Training loss: 0.2674275552389874
Validation loss: 2.5190999915980608

Epoch: 6| Step: 12
Training loss: 0.15588360982838292
Validation loss: 2.5353858336031765

Epoch: 6| Step: 13
Training loss: 0.21080571932537134
Validation loss: 2.5530417743108917

Epoch: 445| Step: 0
Training loss: 0.25266163293580923
Validation loss: 2.5806951435629877

Epoch: 6| Step: 1
Training loss: 0.24276839087620053
Validation loss: 2.574483062765158

Epoch: 6| Step: 2
Training loss: 0.16099131179884624
Validation loss: 2.542744180349397

Epoch: 6| Step: 3
Training loss: 0.16300872871037228
Validation loss: 2.5678718739623934

Epoch: 6| Step: 4
Training loss: 0.140509054280813
Validation loss: 2.5617340778049797

Epoch: 6| Step: 5
Training loss: 0.10609103224620352
Validation loss: 2.543526534004713

Epoch: 6| Step: 6
Training loss: 0.11438423075193067
Validation loss: 2.5442459102369703

Epoch: 6| Step: 7
Training loss: 0.15266142027190496
Validation loss: 2.537851790803016

Epoch: 6| Step: 8
Training loss: 0.253342677932754
Validation loss: 2.5172512683282

Epoch: 6| Step: 9
Training loss: 0.13797076384736806
Validation loss: 2.5083750795076476

Epoch: 6| Step: 10
Training loss: 0.34670871022126043
Validation loss: 2.51407593380049

Epoch: 6| Step: 11
Training loss: 0.18313403097544517
Validation loss: 2.523817414689974

Epoch: 6| Step: 12
Training loss: 0.17994714719292232
Validation loss: 2.5288192946197854

Epoch: 6| Step: 13
Training loss: 0.25759699513137
Validation loss: 2.5393972878176654

Epoch: 446| Step: 0
Training loss: 0.13059480453863254
Validation loss: 2.5103655400459193

Epoch: 6| Step: 1
Training loss: 0.17818938689435368
Validation loss: 2.498208839947362

Epoch: 6| Step: 2
Training loss: 0.180490492877469
Validation loss: 2.4890166118296895

Epoch: 6| Step: 3
Training loss: 0.1582925626114458
Validation loss: 2.520245835902153

Epoch: 6| Step: 4
Training loss: 0.3042597457896804
Validation loss: 2.5464210692066853

Epoch: 6| Step: 5
Training loss: 0.15793962079893512
Validation loss: 2.537772994948203

Epoch: 6| Step: 6
Training loss: 0.18882134876395384
Validation loss: 2.5442471637196435

Epoch: 6| Step: 7
Training loss: 0.19791771967925642
Validation loss: 2.5693982031664344

Epoch: 6| Step: 8
Training loss: 0.28668825574650103
Validation loss: 2.561516419694698

Epoch: 6| Step: 9
Training loss: 0.13694780100012402
Validation loss: 2.587081738309942

Epoch: 6| Step: 10
Training loss: 0.17152730495651122
Validation loss: 2.6026948489993584

Epoch: 6| Step: 11
Training loss: 0.2614219462897532
Validation loss: 2.5809165103725364

Epoch: 6| Step: 12
Training loss: 0.2522086097551494
Validation loss: 2.5834510794913172

Epoch: 6| Step: 13
Training loss: 0.1914312093381799
Validation loss: 2.5706396975894594

Epoch: 447| Step: 0
Training loss: 0.28487421484918934
Validation loss: 2.5589084442047936

Epoch: 6| Step: 1
Training loss: 0.17395553312979348
Validation loss: 2.552296018663742

Epoch: 6| Step: 2
Training loss: 0.27580199393259797
Validation loss: 2.5666999463418345

Epoch: 6| Step: 3
Training loss: 0.10028725322717752
Validation loss: 2.54597836541144

Epoch: 6| Step: 4
Training loss: 0.18273388606899393
Validation loss: 2.5401128457065045

Epoch: 6| Step: 5
Training loss: 0.2746229767991811
Validation loss: 2.5486493699355073

Epoch: 6| Step: 6
Training loss: 0.26467893924403
Validation loss: 2.555628752392112

Epoch: 6| Step: 7
Training loss: 0.18580639408342986
Validation loss: 2.558985610483673

Epoch: 6| Step: 8
Training loss: 0.1575297400234375
Validation loss: 2.5582774478021455

Epoch: 6| Step: 9
Training loss: 0.17165148897303048
Validation loss: 2.5735312007733415

Epoch: 6| Step: 10
Training loss: 0.2790401586066816
Validation loss: 2.571028738938351

Epoch: 6| Step: 11
Training loss: 0.17594775155624887
Validation loss: 2.5779624939953982

Epoch: 6| Step: 12
Training loss: 0.14318210233141349
Validation loss: 2.5524697425400955

Epoch: 6| Step: 13
Training loss: 0.17844365670494095
Validation loss: 2.533164637761042

Epoch: 448| Step: 0
Training loss: 0.3154465047882409
Validation loss: 2.53075337016507

Epoch: 6| Step: 1
Training loss: 0.2708086344876424
Validation loss: 2.5716126536679718

Epoch: 6| Step: 2
Training loss: 0.2020430727963703
Validation loss: 2.536367877971935

Epoch: 6| Step: 3
Training loss: 0.15264280017884807
Validation loss: 2.535500410839537

Epoch: 6| Step: 4
Training loss: 0.16117934508770584
Validation loss: 2.552436121568494

Epoch: 6| Step: 5
Training loss: 0.1471183219757751
Validation loss: 2.5578414626395527

Epoch: 6| Step: 6
Training loss: 0.16583003722162779
Validation loss: 2.587275967483354

Epoch: 6| Step: 7
Training loss: 0.1262011042418133
Validation loss: 2.578394409700784

Epoch: 6| Step: 8
Training loss: 0.16432087852153107
Validation loss: 2.577618424063757

Epoch: 6| Step: 9
Training loss: 0.2966826844958676
Validation loss: 2.5649515605776654

Epoch: 6| Step: 10
Training loss: 0.22908298452879697
Validation loss: 2.5649617593422107

Epoch: 6| Step: 11
Training loss: 0.20932496028021838
Validation loss: 2.5343570617200366

Epoch: 6| Step: 12
Training loss: 0.1587480883971335
Validation loss: 2.5669816966336723

Epoch: 6| Step: 13
Training loss: 0.22883869222281558
Validation loss: 2.578054527197073

Epoch: 449| Step: 0
Training loss: 0.1627059323988069
Validation loss: 2.594607719301873

Epoch: 6| Step: 1
Training loss: 0.16450990118141098
Validation loss: 2.5582868664889253

Epoch: 6| Step: 2
Training loss: 0.14286250012327925
Validation loss: 2.5913591590281895

Epoch: 6| Step: 3
Training loss: 0.1124809126423739
Validation loss: 2.5630119256576145

Epoch: 6| Step: 4
Training loss: 0.12314304499141435
Validation loss: 2.609760961540659

Epoch: 6| Step: 5
Training loss: 0.13345862743975703
Validation loss: 2.6032028232502302

Epoch: 6| Step: 6
Training loss: 0.25557080951260214
Validation loss: 2.586021412808129

Epoch: 6| Step: 7
Training loss: 0.24058449825420614
Validation loss: 2.593977393234402

Epoch: 6| Step: 8
Training loss: 0.1972705066190203
Validation loss: 2.603956846254727

Epoch: 6| Step: 9
Training loss: 0.24195759382053347
Validation loss: 2.6098568624730265

Epoch: 6| Step: 10
Training loss: 0.20028564462052945
Validation loss: 2.6158821875544827

Epoch: 6| Step: 11
Training loss: 0.2423527061829171
Validation loss: 2.6256744145406548

Epoch: 6| Step: 12
Training loss: 0.28547693536274266
Validation loss: 2.6443665834395413

Epoch: 6| Step: 13
Training loss: 0.16360257600405065
Validation loss: 2.5833605415216074

Epoch: 450| Step: 0
Training loss: 0.33818949452737174
Validation loss: 2.576453119830253

Epoch: 6| Step: 1
Training loss: 0.16523443316735942
Validation loss: 2.5536210236617674

Epoch: 6| Step: 2
Training loss: 0.15921145397162223
Validation loss: 2.527862175625554

Epoch: 6| Step: 3
Training loss: 0.23710315293973344
Validation loss: 2.563517482792318

Epoch: 6| Step: 4
Training loss: 0.19903241587444276
Validation loss: 2.5570753130614

Epoch: 6| Step: 5
Training loss: 0.1754286939261141
Validation loss: 2.54794336424935

Epoch: 6| Step: 6
Training loss: 0.13300400839139578
Validation loss: 2.5621524167875043

Epoch: 6| Step: 7
Training loss: 0.1844737289664086
Validation loss: 2.578305736482379

Epoch: 6| Step: 8
Training loss: 0.19824119154205444
Validation loss: 2.586556358875684

Epoch: 6| Step: 9
Training loss: 0.20581099938900616
Validation loss: 2.5524728048822176

Epoch: 6| Step: 10
Training loss: 0.1682467931679891
Validation loss: 2.552198334531073

Epoch: 6| Step: 11
Training loss: 0.24990929507820858
Validation loss: 2.5908956214693815

Epoch: 6| Step: 12
Training loss: 0.27997208720109956
Validation loss: 2.5793372482811083

Epoch: 6| Step: 13
Training loss: 0.11356377721728543
Validation loss: 2.577003850003049

Epoch: 451| Step: 0
Training loss: 0.11794323819028037
Validation loss: 2.5499163125091155

Epoch: 6| Step: 1
Training loss: 0.2739182469492899
Validation loss: 2.5666167542689564

Epoch: 6| Step: 2
Training loss: 0.1721129341900322
Validation loss: 2.5416174617733676

Epoch: 6| Step: 3
Training loss: 0.2011777728799475
Validation loss: 2.5771317444014543

Epoch: 6| Step: 4
Training loss: 0.13747473560490966
Validation loss: 2.5465486449382704

Epoch: 6| Step: 5
Training loss: 0.18269789029387334
Validation loss: 2.5761299635233867

Epoch: 6| Step: 6
Training loss: 0.15397282869198828
Validation loss: 2.5622403053011267

Epoch: 6| Step: 7
Training loss: 0.11087861832296923
Validation loss: 2.5798392206693688

Epoch: 6| Step: 8
Training loss: 0.1842192383873753
Validation loss: 2.5573203909760953

Epoch: 6| Step: 9
Training loss: 0.17019419388910167
Validation loss: 2.5577210298816264

Epoch: 6| Step: 10
Training loss: 0.20367494742501796
Validation loss: 2.560664811611263

Epoch: 6| Step: 11
Training loss: 0.1533591166672399
Validation loss: 2.5685297924086723

Epoch: 6| Step: 12
Training loss: 0.24192310329293717
Validation loss: 2.5542858696549415

Epoch: 6| Step: 13
Training loss: 0.39732495355343583
Validation loss: 2.553936989094958

Epoch: 452| Step: 0
Training loss: 0.15061070081497488
Validation loss: 2.5423312260639412

Epoch: 6| Step: 1
Training loss: 0.19076651104629042
Validation loss: 2.5828463740136507

Epoch: 6| Step: 2
Training loss: 0.25643354157905435
Validation loss: 2.5789815594117345

Epoch: 6| Step: 3
Training loss: 0.18445969349767746
Validation loss: 2.580132861457753

Epoch: 6| Step: 4
Training loss: 0.17980712557475426
Validation loss: 2.5983502941412997

Epoch: 6| Step: 5
Training loss: 0.2661542528441896
Validation loss: 2.5609753762974528

Epoch: 6| Step: 6
Training loss: 0.18845455258582036
Validation loss: 2.610355503195358

Epoch: 6| Step: 7
Training loss: 0.1566677469569695
Validation loss: 2.5611860426585666

Epoch: 6| Step: 8
Training loss: 0.2738081191478066
Validation loss: 2.590182875350589

Epoch: 6| Step: 9
Training loss: 0.24947173214362492
Validation loss: 2.587478709300487

Epoch: 6| Step: 10
Training loss: 0.23073629432128456
Validation loss: 2.5785538770053473

Epoch: 6| Step: 11
Training loss: 0.07315032284144554
Validation loss: 2.595062094483777

Epoch: 6| Step: 12
Training loss: 0.14949416213853342
Validation loss: 2.5493085774952235

Epoch: 6| Step: 13
Training loss: 0.1396494645301026
Validation loss: 2.546838209131971

Epoch: 453| Step: 0
Training loss: 0.17571064272716705
Validation loss: 2.546876493768476

Epoch: 6| Step: 1
Training loss: 0.28256732999153694
Validation loss: 2.539361654600615

Epoch: 6| Step: 2
Training loss: 0.15062350040892286
Validation loss: 2.5519798279583936

Epoch: 6| Step: 3
Training loss: 0.16548283296402755
Validation loss: 2.521368642290117

Epoch: 6| Step: 4
Training loss: 0.17249793177553444
Validation loss: 2.5409806334487204

Epoch: 6| Step: 5
Training loss: 0.2793800123563009
Validation loss: 2.5464416533846963

Epoch: 6| Step: 6
Training loss: 0.27875514278029895
Validation loss: 2.518089841250452

Epoch: 6| Step: 7
Training loss: 0.2944512812677414
Validation loss: 2.5312844925685947

Epoch: 6| Step: 8
Training loss: 0.22521989196936676
Validation loss: 2.4984483343765236

Epoch: 6| Step: 9
Training loss: 0.28802058884999465
Validation loss: 2.5193717181698956

Epoch: 6| Step: 10
Training loss: 0.36282520998066387
Validation loss: 2.500406716190529

Epoch: 6| Step: 11
Training loss: 0.20641931029012806
Validation loss: 2.520074413245954

Epoch: 6| Step: 12
Training loss: 0.32227681458438556
Validation loss: 2.5391767932040747

Epoch: 6| Step: 13
Training loss: 0.3085361620128428
Validation loss: 2.5321459200637486

Epoch: 454| Step: 0
Training loss: 0.19640405806939648
Validation loss: 2.5844713215949953

Epoch: 6| Step: 1
Training loss: 0.22857106180299983
Validation loss: 2.5738616655359756

Epoch: 6| Step: 2
Training loss: 0.37487143060931677
Validation loss: 2.5703349893728538

Epoch: 6| Step: 3
Training loss: 0.26102917482749344
Validation loss: 2.5640586456713588

Epoch: 6| Step: 4
Training loss: 0.2909963588609697
Validation loss: 2.544610879864564

Epoch: 6| Step: 5
Training loss: 0.14945785030426606
Validation loss: 2.5452499182629906

Epoch: 6| Step: 6
Training loss: 0.3303260098151389
Validation loss: 2.525278881835214

Epoch: 6| Step: 7
Training loss: 0.21402275837280335
Validation loss: 2.543028630647547

Epoch: 6| Step: 8
Training loss: 0.26215251164005293
Validation loss: 2.548394481768434

Epoch: 6| Step: 9
Training loss: 0.3075866078511919
Validation loss: 2.5323784598033736

Epoch: 6| Step: 10
Training loss: 0.14000584143134578
Validation loss: 2.5543963293444314

Epoch: 6| Step: 11
Training loss: 0.20175360853425856
Validation loss: 2.556248381473492

Epoch: 6| Step: 12
Training loss: 0.2852136737016067
Validation loss: 2.5957610637274087

Epoch: 6| Step: 13
Training loss: 0.30379144024835053
Validation loss: 2.5761819417732035

Epoch: 455| Step: 0
Training loss: 0.26850518897528375
Validation loss: 2.6020866481181533

Epoch: 6| Step: 1
Training loss: 0.2908549665372607
Validation loss: 2.615243664039541

Epoch: 6| Step: 2
Training loss: 0.4433819601213328
Validation loss: 2.5733910516400313

Epoch: 6| Step: 3
Training loss: 0.17249891439732046
Validation loss: 2.5211787897730282

Epoch: 6| Step: 4
Training loss: 0.4713645182222832
Validation loss: 2.5110741701723343

Epoch: 6| Step: 5
Training loss: 0.28329113875149753
Validation loss: 2.517124636788679

Epoch: 6| Step: 6
Training loss: 0.24768152890117845
Validation loss: 2.482197155817152

Epoch: 6| Step: 7
Training loss: 0.1987021236215964
Validation loss: 2.477267422912831

Epoch: 6| Step: 8
Training loss: 0.23889532071718905
Validation loss: 2.4805475151586003

Epoch: 6| Step: 9
Training loss: 0.3611913886256155
Validation loss: 2.461660562455022

Epoch: 6| Step: 10
Training loss: 0.26452805712643734
Validation loss: 2.4978432909799166

Epoch: 6| Step: 11
Training loss: 0.49076383047878885
Validation loss: 2.4998942988620523

Epoch: 6| Step: 12
Training loss: 0.3983920576323641
Validation loss: 2.5336555101495333

Epoch: 6| Step: 13
Training loss: 0.49721178840662816
Validation loss: 2.552617225946918

Epoch: 456| Step: 0
Training loss: 0.430221191503508
Validation loss: 2.5865191075847376

Epoch: 6| Step: 1
Training loss: 0.3122381663137845
Validation loss: 2.577641593631166

Epoch: 6| Step: 2
Training loss: 0.4937330381884239
Validation loss: 2.5845758441732043

Epoch: 6| Step: 3
Training loss: 0.23933892724019099
Validation loss: 2.5406517266448896

Epoch: 6| Step: 4
Training loss: 0.25542515023928924
Validation loss: 2.5614415225413425

Epoch: 6| Step: 5
Training loss: 0.18975723084706103
Validation loss: 2.5269217172302105

Epoch: 6| Step: 6
Training loss: 0.29835191817753015
Validation loss: 2.5011070005295446

Epoch: 6| Step: 7
Training loss: 0.3976862313410553
Validation loss: 2.4833319103299933

Epoch: 6| Step: 8
Training loss: 0.4460425833571361
Validation loss: 2.4588180658165495

Epoch: 6| Step: 9
Training loss: 0.3883620134017299
Validation loss: 2.4727422528237866

Epoch: 6| Step: 10
Training loss: 0.21138496974125284
Validation loss: 2.5184333629318236

Epoch: 6| Step: 11
Training loss: 0.28771488410587404
Validation loss: 2.4949256168583265

Epoch: 6| Step: 12
Training loss: 0.4880407122373578
Validation loss: 2.495560208717279

Epoch: 6| Step: 13
Training loss: 0.25893071454434374
Validation loss: 2.530953144150805

Epoch: 457| Step: 0
Training loss: 0.2604596039024961
Validation loss: 2.520871216962137

Epoch: 6| Step: 1
Training loss: 0.2521566707292243
Validation loss: 2.5177414666565268

Epoch: 6| Step: 2
Training loss: 0.3389544196079723
Validation loss: 2.5845273011259735

Epoch: 6| Step: 3
Training loss: 0.38607690509651427
Validation loss: 2.592640074052027

Epoch: 6| Step: 4
Training loss: 0.3555889764718974
Validation loss: 2.5834226639142224

Epoch: 6| Step: 5
Training loss: 0.30385468445111397
Validation loss: 2.560725597449636

Epoch: 6| Step: 6
Training loss: 0.24817591036785902
Validation loss: 2.5605385749702205

Epoch: 6| Step: 7
Training loss: 0.3900635690110577
Validation loss: 2.5299773729609454

Epoch: 6| Step: 8
Training loss: 0.23131146161924215
Validation loss: 2.54508851331586

Epoch: 6| Step: 9
Training loss: 0.3161215030707536
Validation loss: 2.556189919732561

Epoch: 6| Step: 10
Training loss: 0.253569261963317
Validation loss: 2.5447303675299935

Epoch: 6| Step: 11
Training loss: 0.3000358162798572
Validation loss: 2.5049939022342453

Epoch: 6| Step: 12
Training loss: 0.3154690130420663
Validation loss: 2.532186809065275

Epoch: 6| Step: 13
Training loss: 0.2104912116335301
Validation loss: 2.463633060396864

Epoch: 458| Step: 0
Training loss: 0.3865331146432116
Validation loss: 2.493191461062429

Epoch: 6| Step: 1
Training loss: 0.35384863243383174
Validation loss: 2.495144832266814

Epoch: 6| Step: 2
Training loss: 0.3514759381009379
Validation loss: 2.529967464837858

Epoch: 6| Step: 3
Training loss: 0.25140300101391067
Validation loss: 2.5231558364659543

Epoch: 6| Step: 4
Training loss: 0.38722026941824705
Validation loss: 2.4942572890960495

Epoch: 6| Step: 5
Training loss: 0.3241735909506149
Validation loss: 2.496958509871616

Epoch: 6| Step: 6
Training loss: 0.24396186387634453
Validation loss: 2.4902720031533456

Epoch: 6| Step: 7
Training loss: 0.23649254115925925
Validation loss: 2.468557625738162

Epoch: 6| Step: 8
Training loss: 0.34772886096608063
Validation loss: 2.522167460589305

Epoch: 6| Step: 9
Training loss: 0.16622367612836803
Validation loss: 2.5498384278745005

Epoch: 6| Step: 10
Training loss: 0.1870965491340813
Validation loss: 2.5859680798541067

Epoch: 6| Step: 11
Training loss: 0.1854509205913347
Validation loss: 2.594921521078484

Epoch: 6| Step: 12
Training loss: 0.19053532531381664
Validation loss: 2.5834440448416767

Epoch: 6| Step: 13
Training loss: 0.2691303671998421
Validation loss: 2.5769774029742227

Epoch: 459| Step: 0
Training loss: 0.26420616835061245
Validation loss: 2.5986251490895618

Epoch: 6| Step: 1
Training loss: 0.2725196146248943
Validation loss: 2.545672561327166

Epoch: 6| Step: 2
Training loss: 0.24187233630150304
Validation loss: 2.5409724808752157

Epoch: 6| Step: 3
Training loss: 0.2679474085325323
Validation loss: 2.5914397642435536

Epoch: 6| Step: 4
Training loss: 0.4345480066639755
Validation loss: 2.5792997118337913

Epoch: 6| Step: 5
Training loss: 0.211088850330157
Validation loss: 2.548521873209277

Epoch: 6| Step: 6
Training loss: 0.3764080395622357
Validation loss: 2.5817737363745668

Epoch: 6| Step: 7
Training loss: 0.15324641834246147
Validation loss: 2.5806964041765013

Epoch: 6| Step: 8
Training loss: 0.20319018785123966
Validation loss: 2.5473715643284685

Epoch: 6| Step: 9
Training loss: 0.32551538335688385
Validation loss: 2.5542715350576897

Epoch: 6| Step: 10
Training loss: 0.32166023033419655
Validation loss: 2.5504734133896725

Epoch: 6| Step: 11
Training loss: 0.17013386404852257
Validation loss: 2.5621914081258446

Epoch: 6| Step: 12
Training loss: 0.24807588903192282
Validation loss: 2.5619324636668668

Epoch: 6| Step: 13
Training loss: 0.25114356692723544
Validation loss: 2.555985719131244

Epoch: 460| Step: 0
Training loss: 0.1709834895344169
Validation loss: 2.5312201476530123

Epoch: 6| Step: 1
Training loss: 0.30036919099411075
Validation loss: 2.5289779689461453

Epoch: 6| Step: 2
Training loss: 0.26294145078617454
Validation loss: 2.544069217412663

Epoch: 6| Step: 3
Training loss: 0.27518479792134487
Validation loss: 2.5445053337290373

Epoch: 6| Step: 4
Training loss: 0.14685992102628526
Validation loss: 2.5652377492601017

Epoch: 6| Step: 5
Training loss: 0.231989940022869
Validation loss: 2.5689110152782817

Epoch: 6| Step: 6
Training loss: 0.27468024271382124
Validation loss: 2.6060207541248177

Epoch: 6| Step: 7
Training loss: 0.32404446800923903
Validation loss: 2.5911801819120326

Epoch: 6| Step: 8
Training loss: 0.24897237515985404
Validation loss: 2.6156474191366903

Epoch: 6| Step: 9
Training loss: 0.17962619523531415
Validation loss: 2.532491353493593

Epoch: 6| Step: 10
Training loss: 0.25714267066540086
Validation loss: 2.5592914065061056

Epoch: 6| Step: 11
Training loss: 0.18751660909204557
Validation loss: 2.5461487566639995

Epoch: 6| Step: 12
Training loss: 0.1337116254030453
Validation loss: 2.5624743779720043

Epoch: 6| Step: 13
Training loss: 0.20025195739268067
Validation loss: 2.5617082354559955

Epoch: 461| Step: 0
Training loss: 0.18167412356688473
Validation loss: 2.545733925683959

Epoch: 6| Step: 1
Training loss: 0.29081683441808176
Validation loss: 2.5311021659093735

Epoch: 6| Step: 2
Training loss: 0.20270655703934348
Validation loss: 2.535259377769305

Epoch: 6| Step: 3
Training loss: 0.25108796552773593
Validation loss: 2.5394499376660686

Epoch: 6| Step: 4
Training loss: 0.3009185725248317
Validation loss: 2.5557932893224335

Epoch: 6| Step: 5
Training loss: 0.19199314447049978
Validation loss: 2.5039769575539066

Epoch: 6| Step: 6
Training loss: 0.23642890924955212
Validation loss: 2.533999830300727

Epoch: 6| Step: 7
Training loss: 0.21301795056700112
Validation loss: 2.508877145610201

Epoch: 6| Step: 8
Training loss: 0.24994753495685557
Validation loss: 2.574220652150625

Epoch: 6| Step: 9
Training loss: 0.20231113244585291
Validation loss: 2.5239980259163723

Epoch: 6| Step: 10
Training loss: 0.14558061916011727
Validation loss: 2.574429516668919

Epoch: 6| Step: 11
Training loss: 0.19456616858109593
Validation loss: 2.569270508021088

Epoch: 6| Step: 12
Training loss: 0.26187698363506534
Validation loss: 2.5591239439355187

Epoch: 6| Step: 13
Training loss: 0.2926322275822912
Validation loss: 2.5615434299329154

Epoch: 462| Step: 0
Training loss: 0.13115100249217457
Validation loss: 2.5686041048592503

Epoch: 6| Step: 1
Training loss: 0.2895091703985124
Validation loss: 2.560992358896965

Epoch: 6| Step: 2
Training loss: 0.19051951710528064
Validation loss: 2.560203541680537

Epoch: 6| Step: 3
Training loss: 0.20733171827684108
Validation loss: 2.5831519654351585

Epoch: 6| Step: 4
Training loss: 0.24507671949222523
Validation loss: 2.5709772019437347

Epoch: 6| Step: 5
Training loss: 0.21297642090179358
Validation loss: 2.559835646042407

Epoch: 6| Step: 6
Training loss: 0.26157198534393816
Validation loss: 2.5378258295149823

Epoch: 6| Step: 7
Training loss: 0.17082497243851694
Validation loss: 2.5447369928923136

Epoch: 6| Step: 8
Training loss: 0.21792013419190323
Validation loss: 2.556284408604525

Epoch: 6| Step: 9
Training loss: 0.2361091040233001
Validation loss: 2.530046848302899

Epoch: 6| Step: 10
Training loss: 0.17775264059256854
Validation loss: 2.5326698440127884

Epoch: 6| Step: 11
Training loss: 0.10722169865067303
Validation loss: 2.5616764252810285

Epoch: 6| Step: 12
Training loss: 0.1498261422680411
Validation loss: 2.5237573260780124

Epoch: 6| Step: 13
Training loss: 0.14922716256838783
Validation loss: 2.5464364746362174

Epoch: 463| Step: 0
Training loss: 0.13388738708551878
Validation loss: 2.4990430066711222

Epoch: 6| Step: 1
Training loss: 0.16060186822551034
Validation loss: 2.5363190369213333

Epoch: 6| Step: 2
Training loss: 0.20961092673575785
Validation loss: 2.517981684233915

Epoch: 6| Step: 3
Training loss: 0.2632041031413644
Validation loss: 2.503095193084025

Epoch: 6| Step: 4
Training loss: 0.16221671974052151
Validation loss: 2.5050078594872165

Epoch: 6| Step: 5
Training loss: 0.15675421660515018
Validation loss: 2.545700016609047

Epoch: 6| Step: 6
Training loss: 0.2886517028574337
Validation loss: 2.4856530847263674

Epoch: 6| Step: 7
Training loss: 0.2610775508911973
Validation loss: 2.5090449364005547

Epoch: 6| Step: 8
Training loss: 0.09852625028742039
Validation loss: 2.5131249258900894

Epoch: 6| Step: 9
Training loss: 0.19797575010164084
Validation loss: 2.506411673629537

Epoch: 6| Step: 10
Training loss: 0.13485760935817687
Validation loss: 2.5100624393837907

Epoch: 6| Step: 11
Training loss: 0.2553048567637546
Validation loss: 2.542706477755071

Epoch: 6| Step: 12
Training loss: 0.28636131666704034
Validation loss: 2.5453876385237737

Epoch: 6| Step: 13
Training loss: 0.0634821522525683
Validation loss: 2.551979716451197

Epoch: 464| Step: 0
Training loss: 0.24902233796718426
Validation loss: 2.568221578929679

Epoch: 6| Step: 1
Training loss: 0.12846837668061908
Validation loss: 2.567673164227832

Epoch: 6| Step: 2
Training loss: 0.31935616525402943
Validation loss: 2.54127639814985

Epoch: 6| Step: 3
Training loss: 0.1483848503501889
Validation loss: 2.565166043928759

Epoch: 6| Step: 4
Training loss: 0.15643412946528878
Validation loss: 2.5733655823819537

Epoch: 6| Step: 5
Training loss: 0.13740072459532343
Validation loss: 2.558811563543453

Epoch: 6| Step: 6
Training loss: 0.16776621051361781
Validation loss: 2.5389435932597344

Epoch: 6| Step: 7
Training loss: 0.26305469760757105
Validation loss: 2.5213081155472463

Epoch: 6| Step: 8
Training loss: 0.26082445482727046
Validation loss: 2.518745598890585

Epoch: 6| Step: 9
Training loss: 0.2240079041261545
Validation loss: 2.5301803664393323

Epoch: 6| Step: 10
Training loss: 0.20874108208378217
Validation loss: 2.5425345268732067

Epoch: 6| Step: 11
Training loss: 0.2585315935051221
Validation loss: 2.5153093832364455

Epoch: 6| Step: 12
Training loss: 0.15946339558742134
Validation loss: 2.5133152021612157

Epoch: 6| Step: 13
Training loss: 0.3263072115694815
Validation loss: 2.562855653570342

Epoch: 465| Step: 0
Training loss: 0.2516974697198794
Validation loss: 2.557186429214821

Epoch: 6| Step: 1
Training loss: 0.2074926201817909
Validation loss: 2.5901791063693578

Epoch: 6| Step: 2
Training loss: 0.19867920272880207
Validation loss: 2.540913631846461

Epoch: 6| Step: 3
Training loss: 0.2785558406692021
Validation loss: 2.5615251899466696

Epoch: 6| Step: 4
Training loss: 0.21045057291891847
Validation loss: 2.5485786504173067

Epoch: 6| Step: 5
Training loss: 0.16433849281045382
Validation loss: 2.5200395319905

Epoch: 6| Step: 6
Training loss: 0.258392260096287
Validation loss: 2.5023496138382098

Epoch: 6| Step: 7
Training loss: 0.3453231922065056
Validation loss: 2.512552909679667

Epoch: 6| Step: 8
Training loss: 0.11111580948242379
Validation loss: 2.494856288669916

Epoch: 6| Step: 9
Training loss: 0.25741556706898094
Validation loss: 2.5150517859193777

Epoch: 6| Step: 10
Training loss: 0.22607794278663665
Validation loss: 2.5129224277318576

Epoch: 6| Step: 11
Training loss: 0.31143256509305667
Validation loss: 2.5496382156477604

Epoch: 6| Step: 12
Training loss: 0.12519567790104572
Validation loss: 2.5212974026260637

Epoch: 6| Step: 13
Training loss: 0.2961959224750288
Validation loss: 2.5658940054251036

Epoch: 466| Step: 0
Training loss: 0.2423085479330407
Validation loss: 2.563671274567246

Epoch: 6| Step: 1
Training loss: 0.27282277899535196
Validation loss: 2.5953846655725554

Epoch: 6| Step: 2
Training loss: 0.23180647729540946
Validation loss: 2.5816335044255214

Epoch: 6| Step: 3
Training loss: 0.23856480720809486
Validation loss: 2.5224228880299107

Epoch: 6| Step: 4
Training loss: 0.20790635800240567
Validation loss: 2.5112738068730183

Epoch: 6| Step: 5
Training loss: 0.3063195242108503
Validation loss: 2.512639324276313

Epoch: 6| Step: 6
Training loss: 0.27191353228889575
Validation loss: 2.4932044360848806

Epoch: 6| Step: 7
Training loss: 0.208805899302502
Validation loss: 2.4811163822523405

Epoch: 6| Step: 8
Training loss: 0.3264991466086073
Validation loss: 2.517012994666356

Epoch: 6| Step: 9
Training loss: 0.2731696860903157
Validation loss: 2.564413269321572

Epoch: 6| Step: 10
Training loss: 0.2534793198838665
Validation loss: 2.5723896427608786

Epoch: 6| Step: 11
Training loss: 0.25157401668652474
Validation loss: 2.623080189792899

Epoch: 6| Step: 12
Training loss: 0.23652063363363995
Validation loss: 2.5674008720746118

Epoch: 6| Step: 13
Training loss: 0.2562750431942329
Validation loss: 2.5743345585341633

Epoch: 467| Step: 0
Training loss: 0.21016783168318817
Validation loss: 2.5488611430631014

Epoch: 6| Step: 1
Training loss: 0.16323044365207073
Validation loss: 2.568309847683547

Epoch: 6| Step: 2
Training loss: 0.27210214706577596
Validation loss: 2.6089990423726315

Epoch: 6| Step: 3
Training loss: 0.17202711418266642
Validation loss: 2.5631466916655636

Epoch: 6| Step: 4
Training loss: 0.2298161269755796
Validation loss: 2.5543461551789615

Epoch: 6| Step: 5
Training loss: 0.282498159697961
Validation loss: 2.535024158944929

Epoch: 6| Step: 6
Training loss: 0.18122285565644117
Validation loss: 2.5352046715502956

Epoch: 6| Step: 7
Training loss: 0.2722610095602998
Validation loss: 2.5110571613566868

Epoch: 6| Step: 8
Training loss: 0.39448040927355144
Validation loss: 2.490418645711285

Epoch: 6| Step: 9
Training loss: 0.4062450481993321
Validation loss: 2.512127558070003

Epoch: 6| Step: 10
Training loss: 0.2297592394893862
Validation loss: 2.515531891434938

Epoch: 6| Step: 11
Training loss: 0.15127757096027886
Validation loss: 2.5390070669529834

Epoch: 6| Step: 12
Training loss: 0.23653155627125635
Validation loss: 2.5572928800045975

Epoch: 6| Step: 13
Training loss: 0.30286198049374224
Validation loss: 2.572670720111785

Epoch: 468| Step: 0
Training loss: 0.2732939070643548
Validation loss: 2.5725468484406844

Epoch: 6| Step: 1
Training loss: 0.24795310433202752
Validation loss: 2.5246498555541828

Epoch: 6| Step: 2
Training loss: 0.16113903149249945
Validation loss: 2.5586706534918235

Epoch: 6| Step: 3
Training loss: 0.30614338790230117
Validation loss: 2.576376504093177

Epoch: 6| Step: 4
Training loss: 0.25915510094053373
Validation loss: 2.5142935509117432

Epoch: 6| Step: 5
Training loss: 0.18446344985727697
Validation loss: 2.540005320388894

Epoch: 6| Step: 6
Training loss: 0.21630149812448504
Validation loss: 2.5171399475491794

Epoch: 6| Step: 7
Training loss: 0.3741826647281528
Validation loss: 2.5063785070264073

Epoch: 6| Step: 8
Training loss: 0.3944418399833755
Validation loss: 2.500418258872554

Epoch: 6| Step: 9
Training loss: 0.27286384898916566
Validation loss: 2.554857549231995

Epoch: 6| Step: 10
Training loss: 0.2568691652800146
Validation loss: 2.538926770642477

Epoch: 6| Step: 11
Training loss: 0.2017679180557639
Validation loss: 2.5480914044307648

Epoch: 6| Step: 12
Training loss: 0.22507787025858306
Validation loss: 2.569034409632252

Epoch: 6| Step: 13
Training loss: 0.2786417794452625
Validation loss: 2.5638101891433807

Epoch: 469| Step: 0
Training loss: 0.21107395491553102
Validation loss: 2.5713334257617317

Epoch: 6| Step: 1
Training loss: 0.22723934588149228
Validation loss: 2.600718919117776

Epoch: 6| Step: 2
Training loss: 0.15017355077910147
Validation loss: 2.5683661485234333

Epoch: 6| Step: 3
Training loss: 0.2776173061866018
Validation loss: 2.541434858602

Epoch: 6| Step: 4
Training loss: 0.26590416767732006
Validation loss: 2.5152302312958796

Epoch: 6| Step: 5
Training loss: 0.3131902462639622
Validation loss: 2.550399356955676

Epoch: 6| Step: 6
Training loss: 0.23084227148429198
Validation loss: 2.517215261528222

Epoch: 6| Step: 7
Training loss: 0.271051652041694
Validation loss: 2.5180827624647386

Epoch: 6| Step: 8
Training loss: 0.17898319954987757
Validation loss: 2.51739020157638

Epoch: 6| Step: 9
Training loss: 0.18931374879666327
Validation loss: 2.4777762247828075

Epoch: 6| Step: 10
Training loss: 0.28596707905016566
Validation loss: 2.4863005636764113

Epoch: 6| Step: 11
Training loss: 0.102741454971959
Validation loss: 2.487516228704373

Epoch: 6| Step: 12
Training loss: 0.10535872866791401
Validation loss: 2.482296270648565

Epoch: 6| Step: 13
Training loss: 0.25977365581747297
Validation loss: 2.4805306845882815

Epoch: 470| Step: 0
Training loss: 0.279729548016051
Validation loss: 2.4856258531811073

Epoch: 6| Step: 1
Training loss: 0.24705054464154716
Validation loss: 2.492408332474933

Epoch: 6| Step: 2
Training loss: 0.1970993134073427
Validation loss: 2.515201527610305

Epoch: 6| Step: 3
Training loss: 0.24812252663213175
Validation loss: 2.541679086424529

Epoch: 6| Step: 4
Training loss: 0.19958986048852806
Validation loss: 2.5494526031262317

Epoch: 6| Step: 5
Training loss: 0.30772120821178106
Validation loss: 2.5319168385270783

Epoch: 6| Step: 6
Training loss: 0.22271155624151148
Validation loss: 2.562913602659297

Epoch: 6| Step: 7
Training loss: 0.2151685167415792
Validation loss: 2.599085521321066

Epoch: 6| Step: 8
Training loss: 0.2170633276680045
Validation loss: 2.6027292635017036

Epoch: 6| Step: 9
Training loss: 0.22596390341708925
Validation loss: 2.6022270871568196

Epoch: 6| Step: 10
Training loss: 0.30043279602323414
Validation loss: 2.591646998697189

Epoch: 6| Step: 11
Training loss: 0.19507570217096148
Validation loss: 2.565375948438887

Epoch: 6| Step: 12
Training loss: 0.2561794928336828
Validation loss: 2.535176690025844

Epoch: 6| Step: 13
Training loss: 0.1773306904828293
Validation loss: 2.5221013929315865

Epoch: 471| Step: 0
Training loss: 0.23126994704228554
Validation loss: 2.5051997185479387

Epoch: 6| Step: 1
Training loss: 0.4369206338933097
Validation loss: 2.525015337164503

Epoch: 6| Step: 2
Training loss: 0.21801106783895868
Validation loss: 2.5077633001069377

Epoch: 6| Step: 3
Training loss: 0.25489674087994735
Validation loss: 2.489642066655779

Epoch: 6| Step: 4
Training loss: 0.3065206207849896
Validation loss: 2.4972296983338826

Epoch: 6| Step: 5
Training loss: 0.22533391110063533
Validation loss: 2.5145981535606645

Epoch: 6| Step: 6
Training loss: 0.20223050133367643
Validation loss: 2.5134901408179626

Epoch: 6| Step: 7
Training loss: 0.18392370888185686
Validation loss: 2.527542900910196

Epoch: 6| Step: 8
Training loss: 0.25713493435722823
Validation loss: 2.589156115133729

Epoch: 6| Step: 9
Training loss: 0.1899786473811757
Validation loss: 2.5727248199813313

Epoch: 6| Step: 10
Training loss: 0.22790095810975444
Validation loss: 2.565172547051046

Epoch: 6| Step: 11
Training loss: 0.18158922185915863
Validation loss: 2.561226879433047

Epoch: 6| Step: 12
Training loss: 0.267042710296616
Validation loss: 2.556406809906349

Epoch: 6| Step: 13
Training loss: 0.15448319979251812
Validation loss: 2.592116102576323

Epoch: 472| Step: 0
Training loss: 0.27108471770176895
Validation loss: 2.5797828780559096

Epoch: 6| Step: 1
Training loss: 0.16192656861014126
Validation loss: 2.5869436467553824

Epoch: 6| Step: 2
Training loss: 0.17979295372824583
Validation loss: 2.5878996010777713

Epoch: 6| Step: 3
Training loss: 0.16839525499834093
Validation loss: 2.5645142478997887

Epoch: 6| Step: 4
Training loss: 0.20284993547697594
Validation loss: 2.5902368420470796

Epoch: 6| Step: 5
Training loss: 0.24255787308783458
Validation loss: 2.590415416229528

Epoch: 6| Step: 6
Training loss: 0.19736000673653376
Validation loss: 2.567259335766865

Epoch: 6| Step: 7
Training loss: 0.221458046978155
Validation loss: 2.5728700801409268

Epoch: 6| Step: 8
Training loss: 0.2842269019268017
Validation loss: 2.5725704812302888

Epoch: 6| Step: 9
Training loss: 0.16285102166122406
Validation loss: 2.570458045087989

Epoch: 6| Step: 10
Training loss: 0.24219769794774218
Validation loss: 2.592908892631041

Epoch: 6| Step: 11
Training loss: 0.23549747296919268
Validation loss: 2.5960418478437544

Epoch: 6| Step: 12
Training loss: 0.1561144837173623
Validation loss: 2.588272862840065

Epoch: 6| Step: 13
Training loss: 0.22888813467895552
Validation loss: 2.6085482220820198

Epoch: 473| Step: 0
Training loss: 0.2571795670455085
Validation loss: 2.5977354380716386

Epoch: 6| Step: 1
Training loss: 0.33923516645379165
Validation loss: 2.5904821454381537

Epoch: 6| Step: 2
Training loss: 0.20011528090179892
Validation loss: 2.612794104474654

Epoch: 6| Step: 3
Training loss: 0.16933656052207513
Validation loss: 2.5681185539538314

Epoch: 6| Step: 4
Training loss: 0.28263763005811793
Validation loss: 2.575751238589157

Epoch: 6| Step: 5
Training loss: 0.2598269254016844
Validation loss: 2.5655139962783093

Epoch: 6| Step: 6
Training loss: 0.26020302910408694
Validation loss: 2.570814075584984

Epoch: 6| Step: 7
Training loss: 0.22947521552777997
Validation loss: 2.6095273186684396

Epoch: 6| Step: 8
Training loss: 0.14667883998458378
Validation loss: 2.5394457072440106

Epoch: 6| Step: 9
Training loss: 0.2104460324358193
Validation loss: 2.5573458014957198

Epoch: 6| Step: 10
Training loss: 0.19703935166355085
Validation loss: 2.569058267325823

Epoch: 6| Step: 11
Training loss: 0.14408408402548348
Validation loss: 2.5365403408817

Epoch: 6| Step: 12
Training loss: 0.19856834828424777
Validation loss: 2.550141002529529

Epoch: 6| Step: 13
Training loss: 0.40570567417647796
Validation loss: 2.556457586680333

Epoch: 474| Step: 0
Training loss: 0.24716205928977153
Validation loss: 2.5473632384784297

Epoch: 6| Step: 1
Training loss: 0.19155254417485837
Validation loss: 2.5787503604897513

Epoch: 6| Step: 2
Training loss: 0.331105366206486
Validation loss: 2.5617192282184615

Epoch: 6| Step: 3
Training loss: 0.15522646643387825
Validation loss: 2.5738891816836285

Epoch: 6| Step: 4
Training loss: 0.16945583736171196
Validation loss: 2.6011687698962813

Epoch: 6| Step: 5
Training loss: 0.2712509057034257
Validation loss: 2.553822303432541

Epoch: 6| Step: 6
Training loss: 0.1638528187832339
Validation loss: 2.5230075971979273

Epoch: 6| Step: 7
Training loss: 0.10341082972451811
Validation loss: 2.466338774941603

Epoch: 6| Step: 8
Training loss: 0.27097862118591587
Validation loss: 2.474133500448388

Epoch: 6| Step: 9
Training loss: 0.14615538209955586
Validation loss: 2.486475274407507

Epoch: 6| Step: 10
Training loss: 0.19842661655046773
Validation loss: 2.4798544007550323

Epoch: 6| Step: 11
Training loss: 0.2735075452189197
Validation loss: 2.4709174622274626

Epoch: 6| Step: 12
Training loss: 0.14353197268398146
Validation loss: 2.497217961258881

Epoch: 6| Step: 13
Training loss: 0.20984899508638064
Validation loss: 2.536046380124978

Epoch: 475| Step: 0
Training loss: 0.18831018407583242
Validation loss: 2.5908961572730043

Epoch: 6| Step: 1
Training loss: 0.1939048298423335
Validation loss: 2.5755945440233954

Epoch: 6| Step: 2
Training loss: 0.2179189888406174
Validation loss: 2.5788995806649635

Epoch: 6| Step: 3
Training loss: 0.30352771543481005
Validation loss: 2.5767311004761333

Epoch: 6| Step: 4
Training loss: 0.2645103685639903
Validation loss: 2.5634344614598343

Epoch: 6| Step: 5
Training loss: 0.28522847188557965
Validation loss: 2.526155785656523

Epoch: 6| Step: 6
Training loss: 0.19012149422640562
Validation loss: 2.5519119884906534

Epoch: 6| Step: 7
Training loss: 0.23898745462179838
Validation loss: 2.516457288217306

Epoch: 6| Step: 8
Training loss: 0.1361061472343081
Validation loss: 2.4987086560294496

Epoch: 6| Step: 9
Training loss: 0.16360390237240963
Validation loss: 2.508931720844127

Epoch: 6| Step: 10
Training loss: 0.21287322191973088
Validation loss: 2.494778322597812

Epoch: 6| Step: 11
Training loss: 0.24065859485787122
Validation loss: 2.521696526826042

Epoch: 6| Step: 12
Training loss: 0.23929073340803933
Validation loss: 2.5447199547003434

Epoch: 6| Step: 13
Training loss: 0.526281459529471
Validation loss: 2.499059564844111

Epoch: 476| Step: 0
Training loss: 0.17063919568133434
Validation loss: 2.594648812098718

Epoch: 6| Step: 1
Training loss: 0.15919166941100682
Validation loss: 2.6431578704094663

Epoch: 6| Step: 2
Training loss: 0.36315997981135595
Validation loss: 2.719543965330883

Epoch: 6| Step: 3
Training loss: 0.3200873304574505
Validation loss: 2.756652891281347

Epoch: 6| Step: 4
Training loss: 0.41874949896483554
Validation loss: 2.791777768508576

Epoch: 6| Step: 5
Training loss: 0.45539072457870516
Validation loss: 2.778622707555146

Epoch: 6| Step: 6
Training loss: 0.3579172131101606
Validation loss: 2.791243019767402

Epoch: 6| Step: 7
Training loss: 0.32609053414134076
Validation loss: 2.793783163067607

Epoch: 6| Step: 8
Training loss: 0.3361266512973863
Validation loss: 2.6879585678081

Epoch: 6| Step: 9
Training loss: 0.47660855555384973
Validation loss: 2.6672653159497117

Epoch: 6| Step: 10
Training loss: 0.38622580041969723
Validation loss: 2.613654761367385

Epoch: 6| Step: 11
Training loss: 0.1756799087858908
Validation loss: 2.5700540007107513

Epoch: 6| Step: 12
Training loss: 0.3814257396514556
Validation loss: 2.542306972348275

Epoch: 6| Step: 13
Training loss: 0.39214829024711007
Validation loss: 2.5158660942309523

Epoch: 477| Step: 0
Training loss: 0.2546298938968199
Validation loss: 2.5162908464839493

Epoch: 6| Step: 1
Training loss: 0.4207840518454424
Validation loss: 2.5576540453350347

Epoch: 6| Step: 2
Training loss: 0.2371992654106351
Validation loss: 2.560709255815976

Epoch: 6| Step: 3
Training loss: 0.17459889237515724
Validation loss: 2.5869841314375703

Epoch: 6| Step: 4
Training loss: 0.31114465531716945
Validation loss: 2.5632896877289624

Epoch: 6| Step: 5
Training loss: 0.4276414535131418
Validation loss: 2.6151265362564544

Epoch: 6| Step: 6
Training loss: 0.18941360730041573
Validation loss: 2.5875000933710104

Epoch: 6| Step: 7
Training loss: 0.21617670106894613
Validation loss: 2.5680598578066176

Epoch: 6| Step: 8
Training loss: 0.2997437952686389
Validation loss: 2.5751902114858893

Epoch: 6| Step: 9
Training loss: 0.227155747300118
Validation loss: 2.549554440706282

Epoch: 6| Step: 10
Training loss: 0.31302850854554237
Validation loss: 2.5553134646679987

Epoch: 6| Step: 11
Training loss: 0.2124603893723933
Validation loss: 2.517902647352943

Epoch: 6| Step: 12
Training loss: 0.31386822152575716
Validation loss: 2.5424048146887186

Epoch: 6| Step: 13
Training loss: 0.2800185742773964
Validation loss: 2.5423925490574812

Epoch: 478| Step: 0
Training loss: 0.2808442632989468
Validation loss: 2.5358359580697187

Epoch: 6| Step: 1
Training loss: 0.24916657466684725
Validation loss: 2.5324389421384446

Epoch: 6| Step: 2
Training loss: 0.3576748479071585
Validation loss: 2.4988149869783127

Epoch: 6| Step: 3
Training loss: 0.2316144333388507
Validation loss: 2.498204798802031

Epoch: 6| Step: 4
Training loss: 0.23571685680209203
Validation loss: 2.5112091952538678

Epoch: 6| Step: 5
Training loss: 0.30567208179033406
Validation loss: 2.507080877127952

Epoch: 6| Step: 6
Training loss: 0.1532848341403224
Validation loss: 2.500046098448166

Epoch: 6| Step: 7
Training loss: 0.20130832451887218
Validation loss: 2.4877769131809417

Epoch: 6| Step: 8
Training loss: 0.25254222103778273
Validation loss: 2.4823209062172467

Epoch: 6| Step: 9
Training loss: 0.2594094810776329
Validation loss: 2.4608683654376926

Epoch: 6| Step: 10
Training loss: 0.1703514336784731
Validation loss: 2.439582755252662

Epoch: 6| Step: 11
Training loss: 0.2547830993171614
Validation loss: 2.446127600955124

Epoch: 6| Step: 12
Training loss: 0.28131873562437687
Validation loss: 2.447661442347231

Epoch: 6| Step: 13
Training loss: 0.11880637402446485
Validation loss: 2.4433731030582577

Epoch: 479| Step: 0
Training loss: 0.17331303133919201
Validation loss: 2.4187716943810296

Epoch: 6| Step: 1
Training loss: 0.2346195058194592
Validation loss: 2.4533310910679913

Epoch: 6| Step: 2
Training loss: 0.1468389733242467
Validation loss: 2.4877523872889453

Epoch: 6| Step: 3
Training loss: 0.18416097956574615
Validation loss: 2.496135951581261

Epoch: 6| Step: 4
Training loss: 0.2931907956758025
Validation loss: 2.5158800604595615

Epoch: 6| Step: 5
Training loss: 0.3124561755922352
Validation loss: 2.4920080120752757

Epoch: 6| Step: 6
Training loss: 0.17839916320145333
Validation loss: 2.4902598060565646

Epoch: 6| Step: 7
Training loss: 0.29357133565612187
Validation loss: 2.4890170289720928

Epoch: 6| Step: 8
Training loss: 0.1695260776662446
Validation loss: 2.5310876941892633

Epoch: 6| Step: 9
Training loss: 0.15153477528248144
Validation loss: 2.5307900119567397

Epoch: 6| Step: 10
Training loss: 0.20925306712515357
Validation loss: 2.511902374402634

Epoch: 6| Step: 11
Training loss: 0.3572147790833105
Validation loss: 2.4903101449466307

Epoch: 6| Step: 12
Training loss: 0.177302958296609
Validation loss: 2.475171901972457

Epoch: 6| Step: 13
Training loss: 0.18877504856751598
Validation loss: 2.5265372179794925

Epoch: 480| Step: 0
Training loss: 0.2163819647152369
Validation loss: 2.537086956895765

Epoch: 6| Step: 1
Training loss: 0.12236651913315989
Validation loss: 2.5439427850817116

Epoch: 6| Step: 2
Training loss: 0.1851996636498087
Validation loss: 2.5181201556986617

Epoch: 6| Step: 3
Training loss: 0.150951886350357
Validation loss: 2.5383507555628047

Epoch: 6| Step: 4
Training loss: 0.14625260136809443
Validation loss: 2.507114299278954

Epoch: 6| Step: 5
Training loss: 0.22508685733601522
Validation loss: 2.5132933276614997

Epoch: 6| Step: 6
Training loss: 0.20121921982157162
Validation loss: 2.524761859593057

Epoch: 6| Step: 7
Training loss: 0.12537162642775093
Validation loss: 2.5103269110035615

Epoch: 6| Step: 8
Training loss: 0.2008018702000794
Validation loss: 2.5270453842753815

Epoch: 6| Step: 9
Training loss: 0.30002687651723875
Validation loss: 2.506251216676699

Epoch: 6| Step: 10
Training loss: 0.24125136681401757
Validation loss: 2.510192992523805

Epoch: 6| Step: 11
Training loss: 0.2591446359098017
Validation loss: 2.514533300092582

Epoch: 6| Step: 12
Training loss: 0.17773686920763418
Validation loss: 2.5019822388865314

Epoch: 6| Step: 13
Training loss: 0.21625874722159805
Validation loss: 2.527232624235613

Epoch: 481| Step: 0
Training loss: 0.24911343313392012
Validation loss: 2.5286412926807764

Epoch: 6| Step: 1
Training loss: 0.2696664857909944
Validation loss: 2.527908486527469

Epoch: 6| Step: 2
Training loss: 0.14227136507138358
Validation loss: 2.5161199065682673

Epoch: 6| Step: 3
Training loss: 0.31812301005582344
Validation loss: 2.5357566198574153

Epoch: 6| Step: 4
Training loss: 0.23681581634762627
Validation loss: 2.5114617806741606

Epoch: 6| Step: 5
Training loss: 0.1366623557811818
Validation loss: 2.5087086323575623

Epoch: 6| Step: 6
Training loss: 0.2150666900820797
Validation loss: 2.4827259070174783

Epoch: 6| Step: 7
Training loss: 0.2228293164556214
Validation loss: 2.4729689030880766

Epoch: 6| Step: 8
Training loss: 0.2209695035586849
Validation loss: 2.48288950742374

Epoch: 6| Step: 9
Training loss: 0.18837267725461107
Validation loss: 2.4815186301588517

Epoch: 6| Step: 10
Training loss: 0.1382700848247578
Validation loss: 2.4959865964761554

Epoch: 6| Step: 11
Training loss: 0.1258123051470836
Validation loss: 2.4371887609925134

Epoch: 6| Step: 12
Training loss: 0.18260761990702962
Validation loss: 2.495094187634338

Epoch: 6| Step: 13
Training loss: 0.18083151196919084
Validation loss: 2.477639135567208

Epoch: 482| Step: 0
Training loss: 0.21140927080701435
Validation loss: 2.507734530889127

Epoch: 6| Step: 1
Training loss: 0.13372327760438335
Validation loss: 2.5251267714259207

Epoch: 6| Step: 2
Training loss: 0.1890310324341122
Validation loss: 2.513270871547799

Epoch: 6| Step: 3
Training loss: 0.2207408383310833
Validation loss: 2.502959033797434

Epoch: 6| Step: 4
Training loss: 0.16217942620175546
Validation loss: 2.518476680427139

Epoch: 6| Step: 5
Training loss: 0.16655324389520398
Validation loss: 2.4868752422029106

Epoch: 6| Step: 6
Training loss: 0.2347432581296018
Validation loss: 2.51740222648865

Epoch: 6| Step: 7
Training loss: 0.24485031737458324
Validation loss: 2.5227555417942793

Epoch: 6| Step: 8
Training loss: 0.24254349724009372
Validation loss: 2.5011662480405423

Epoch: 6| Step: 9
Training loss: 0.25692324006733486
Validation loss: 2.5360809737468992

Epoch: 6| Step: 10
Training loss: 0.22468529123167663
Validation loss: 2.5188013200868293

Epoch: 6| Step: 11
Training loss: 0.14978555858088963
Validation loss: 2.517091888375661

Epoch: 6| Step: 12
Training loss: 0.12897133629028668
Validation loss: 2.519702587262273

Epoch: 6| Step: 13
Training loss: 0.2764191595483965
Validation loss: 2.5418299705402885

Epoch: 483| Step: 0
Training loss: 0.12609536830520676
Validation loss: 2.491739648478658

Epoch: 6| Step: 1
Training loss: 0.12612333545068447
Validation loss: 2.496437541169059

Epoch: 6| Step: 2
Training loss: 0.25048196052176175
Validation loss: 2.4758718789325114

Epoch: 6| Step: 3
Training loss: 0.17865487558671267
Validation loss: 2.50561940872886

Epoch: 6| Step: 4
Training loss: 0.1527638633730241
Validation loss: 2.510878918169717

Epoch: 6| Step: 5
Training loss: 0.18294721758478905
Validation loss: 2.4976375502678616

Epoch: 6| Step: 6
Training loss: 0.161371580141221
Validation loss: 2.456153403315218

Epoch: 6| Step: 7
Training loss: 0.16132345770118298
Validation loss: 2.472128225886034

Epoch: 6| Step: 8
Training loss: 0.1912962636435437
Validation loss: 2.474222348972586

Epoch: 6| Step: 9
Training loss: 0.18161245353207678
Validation loss: 2.495832364172556

Epoch: 6| Step: 10
Training loss: 0.10150711218193713
Validation loss: 2.529380106660163

Epoch: 6| Step: 11
Training loss: 0.12824260501288157
Validation loss: 2.5173756938017373

Epoch: 6| Step: 12
Training loss: 0.24323676833963076
Validation loss: 2.538412979637602

Epoch: 6| Step: 13
Training loss: 0.16859163628562152
Validation loss: 2.533786842893472

Epoch: 484| Step: 0
Training loss: 0.1374716870461793
Validation loss: 2.5414491604419767

Epoch: 6| Step: 1
Training loss: 0.12656011638045084
Validation loss: 2.540198383804635

Epoch: 6| Step: 2
Training loss: 0.13128702544039678
Validation loss: 2.547051443831216

Epoch: 6| Step: 3
Training loss: 0.12478807485035923
Validation loss: 2.571416020586552

Epoch: 6| Step: 4
Training loss: 0.21326321186738154
Validation loss: 2.5378425245729836

Epoch: 6| Step: 5
Training loss: 0.20835312312229445
Validation loss: 2.5396038387684503

Epoch: 6| Step: 6
Training loss: 0.2537429284298972
Validation loss: 2.544428340889685

Epoch: 6| Step: 7
Training loss: 0.1387593906571222
Validation loss: 2.552554720417127

Epoch: 6| Step: 8
Training loss: 0.19973911316844076
Validation loss: 2.558464932167643

Epoch: 6| Step: 9
Training loss: 0.1776133638855069
Validation loss: 2.5749860839834096

Epoch: 6| Step: 10
Training loss: 0.17114669207146407
Validation loss: 2.5610921730632845

Epoch: 6| Step: 11
Training loss: 0.15753571107356112
Validation loss: 2.580082321092163

Epoch: 6| Step: 12
Training loss: 0.1387079218904843
Validation loss: 2.583060005672248

Epoch: 6| Step: 13
Training loss: 0.11700773756716724
Validation loss: 2.5438066474472776

Epoch: 485| Step: 0
Training loss: 0.20878742420777766
Validation loss: 2.604076728170127

Epoch: 6| Step: 1
Training loss: 0.13805898702839758
Validation loss: 2.569684651591365

Epoch: 6| Step: 2
Training loss: 0.1273579378942028
Validation loss: 2.5592835819698005

Epoch: 6| Step: 3
Training loss: 0.14108216625749737
Validation loss: 2.503983630853094

Epoch: 6| Step: 4
Training loss: 0.12306268529892547
Validation loss: 2.5112574741976275

Epoch: 6| Step: 5
Training loss: 0.13673433487483655
Validation loss: 2.5310588720455467

Epoch: 6| Step: 6
Training loss: 0.17403174379435904
Validation loss: 2.5066103122058325

Epoch: 6| Step: 7
Training loss: 0.1172337917449121
Validation loss: 2.504231750700107

Epoch: 6| Step: 8
Training loss: 0.218979068437313
Validation loss: 2.509073071413892

Epoch: 6| Step: 9
Training loss: 0.13022865057425828
Validation loss: 2.537935454045036

Epoch: 6| Step: 10
Training loss: 0.18827986459499355
Validation loss: 2.5011175990317285

Epoch: 6| Step: 11
Training loss: 0.08250265682522974
Validation loss: 2.4723148757970783

Epoch: 6| Step: 12
Training loss: 0.29879301774983746
Validation loss: 2.5480604424503186

Epoch: 6| Step: 13
Training loss: 0.149486262510817
Validation loss: 2.5103582199156134

Epoch: 486| Step: 0
Training loss: 0.10387002360046692
Validation loss: 2.495034958279702

Epoch: 6| Step: 1
Training loss: 0.13811383323063914
Validation loss: 2.482059292370492

Epoch: 6| Step: 2
Training loss: 0.16547195385540953
Validation loss: 2.5028143146987643

Epoch: 6| Step: 3
Training loss: 0.18077421181248052
Validation loss: 2.4851287845746546

Epoch: 6| Step: 4
Training loss: 0.19415969140972122
Validation loss: 2.492282663609502

Epoch: 6| Step: 5
Training loss: 0.29809162908795933
Validation loss: 2.5248708846899444

Epoch: 6| Step: 6
Training loss: 0.23670470759473178
Validation loss: 2.478403770459337

Epoch: 6| Step: 7
Training loss: 0.1302208481178588
Validation loss: 2.4890247270393444

Epoch: 6| Step: 8
Training loss: 0.20497344842368426
Validation loss: 2.4876428463450826

Epoch: 6| Step: 9
Training loss: 0.08470119035746002
Validation loss: 2.4995824875391963

Epoch: 6| Step: 10
Training loss: 0.10748680493275019
Validation loss: 2.4957124039182834

Epoch: 6| Step: 11
Training loss: 0.162092822735048
Validation loss: 2.48859690540149

Epoch: 6| Step: 12
Training loss: 0.1261914438833025
Validation loss: 2.5048619661229523

Epoch: 6| Step: 13
Training loss: 0.14212819528971973
Validation loss: 2.496803951026478

Epoch: 487| Step: 0
Training loss: 0.15626116951120536
Validation loss: 2.52251167600936

Epoch: 6| Step: 1
Training loss: 0.28952434090998064
Validation loss: 2.550333979445308

Epoch: 6| Step: 2
Training loss: 0.10697719695278435
Validation loss: 2.5264394085232444

Epoch: 6| Step: 3
Training loss: 0.3651057746224179
Validation loss: 2.54039743270538

Epoch: 6| Step: 4
Training loss: 0.16811162948621275
Validation loss: 2.5184179144668435

Epoch: 6| Step: 5
Training loss: 0.20507598149223907
Validation loss: 2.530682987809827

Epoch: 6| Step: 6
Training loss: 0.1035019757610899
Validation loss: 2.5159347242623507

Epoch: 6| Step: 7
Training loss: 0.18263591323559047
Validation loss: 2.4947858944759163

Epoch: 6| Step: 8
Training loss: 0.12654446337948116
Validation loss: 2.491589362075367

Epoch: 6| Step: 9
Training loss: 0.16506159927616398
Validation loss: 2.5202645684194325

Epoch: 6| Step: 10
Training loss: 0.21586561806286933
Validation loss: 2.472341391750044

Epoch: 6| Step: 11
Training loss: 0.12671872287143177
Validation loss: 2.4775532171026526

Epoch: 6| Step: 12
Training loss: 0.24162478601324847
Validation loss: 2.4789631405768615

Epoch: 6| Step: 13
Training loss: 0.20523990426168084
Validation loss: 2.481870302275248

Epoch: 488| Step: 0
Training loss: 0.2942039897698735
Validation loss: 2.423004559677269

Epoch: 6| Step: 1
Training loss: 0.22814090686365537
Validation loss: 2.439257417074709

Epoch: 6| Step: 2
Training loss: 0.2432238034318021
Validation loss: 2.4498909184924034

Epoch: 6| Step: 3
Training loss: 0.12000718157979687
Validation loss: 2.4854105264780237

Epoch: 6| Step: 4
Training loss: 0.1518351673158701
Validation loss: 2.502692811980432

Epoch: 6| Step: 5
Training loss: 0.2877560553356866
Validation loss: 2.507933199621761

Epoch: 6| Step: 6
Training loss: 0.22638387873598245
Validation loss: 2.5056330898278536

Epoch: 6| Step: 7
Training loss: 0.16171789583726956
Validation loss: 2.59236494400975

Epoch: 6| Step: 8
Training loss: 0.24829227593476227
Validation loss: 2.567991459799168

Epoch: 6| Step: 9
Training loss: 0.19457352075572015
Validation loss: 2.550002352928397

Epoch: 6| Step: 10
Training loss: 0.22581419192962335
Validation loss: 2.52832299546287

Epoch: 6| Step: 11
Training loss: 0.14346953221354855
Validation loss: 2.4901472817266606

Epoch: 6| Step: 12
Training loss: 0.2084691657872915
Validation loss: 2.520785929180678

Epoch: 6| Step: 13
Training loss: 0.1657781304669057
Validation loss: 2.446287052490294

Epoch: 489| Step: 0
Training loss: 0.15513628174250677
Validation loss: 2.5083336050894465

Epoch: 6| Step: 1
Training loss: 0.16400370793286875
Validation loss: 2.5016751778390804

Epoch: 6| Step: 2
Training loss: 0.26700571189174843
Validation loss: 2.495373379443205

Epoch: 6| Step: 3
Training loss: 0.30392799103546825
Validation loss: 2.526883354221393

Epoch: 6| Step: 4
Training loss: 0.3269766854897615
Validation loss: 2.542650364935325

Epoch: 6| Step: 5
Training loss: 0.12098724927127412
Validation loss: 2.5128362738445573

Epoch: 6| Step: 6
Training loss: 0.12537547432941915
Validation loss: 2.522520397921773

Epoch: 6| Step: 7
Training loss: 0.1544833806514136
Validation loss: 2.511122323842581

Epoch: 6| Step: 8
Training loss: 0.15151415427423431
Validation loss: 2.528666368903827

Epoch: 6| Step: 9
Training loss: 0.1262930952066024
Validation loss: 2.4994084427427548

Epoch: 6| Step: 10
Training loss: 0.21399399294622024
Validation loss: 2.5207211957570306

Epoch: 6| Step: 11
Training loss: 0.29149513934321325
Validation loss: 2.5313019685766887

Epoch: 6| Step: 12
Training loss: 0.18872223294564594
Validation loss: 2.5233575347337145

Epoch: 6| Step: 13
Training loss: 0.2026044337279873
Validation loss: 2.5006455818443425

Epoch: 490| Step: 0
Training loss: 0.2552814508652828
Validation loss: 2.524156401042854

Epoch: 6| Step: 1
Training loss: 0.1445428225034039
Validation loss: 2.5459857130224717

Epoch: 6| Step: 2
Training loss: 0.2364653039456568
Validation loss: 2.490875750149419

Epoch: 6| Step: 3
Training loss: 0.31892858999859774
Validation loss: 2.533536486752481

Epoch: 6| Step: 4
Training loss: 0.15649946682773663
Validation loss: 2.484658175924384

Epoch: 6| Step: 5
Training loss: 0.18139770630621307
Validation loss: 2.539971342153631

Epoch: 6| Step: 6
Training loss: 0.22654046576329387
Validation loss: 2.5060273136264013

Epoch: 6| Step: 7
Training loss: 0.14161509745136117
Validation loss: 2.497217725141176

Epoch: 6| Step: 8
Training loss: 0.1711385130569541
Validation loss: 2.4779618636942007

Epoch: 6| Step: 9
Training loss: 0.30281324282182065
Validation loss: 2.494002734084341

Epoch: 6| Step: 10
Training loss: 0.140548897389932
Validation loss: 2.521785277350449

Epoch: 6| Step: 11
Training loss: 0.1708682442287468
Validation loss: 2.521931354115532

Epoch: 6| Step: 12
Training loss: 0.18999053986426043
Validation loss: 2.520705771483653

Epoch: 6| Step: 13
Training loss: 0.22991088656870065
Validation loss: 2.5481056326898384

Epoch: 491| Step: 0
Training loss: 0.13685443140101958
Validation loss: 2.5497830677270965

Epoch: 6| Step: 1
Training loss: 0.16937149184982203
Validation loss: 2.526945409209977

Epoch: 6| Step: 2
Training loss: 0.19837404197624992
Validation loss: 2.5271199110407885

Epoch: 6| Step: 3
Training loss: 0.2579246912669776
Validation loss: 2.4934619339235384

Epoch: 6| Step: 4
Training loss: 0.15924727871237554
Validation loss: 2.499432675788862

Epoch: 6| Step: 5
Training loss: 0.2627610475339143
Validation loss: 2.495130645174316

Epoch: 6| Step: 6
Training loss: 0.13629161323922226
Validation loss: 2.5095847106951497

Epoch: 6| Step: 7
Training loss: 0.21955575025691035
Validation loss: 2.5011919851082838

Epoch: 6| Step: 8
Training loss: 0.1351512836359705
Validation loss: 2.538092347386556

Epoch: 6| Step: 9
Training loss: 0.2083421983422208
Validation loss: 2.5073135488379976

Epoch: 6| Step: 10
Training loss: 0.19122064115783272
Validation loss: 2.516819942147408

Epoch: 6| Step: 11
Training loss: 0.2280148619149739
Validation loss: 2.5432566654351607

Epoch: 6| Step: 12
Training loss: 0.13427972964854748
Validation loss: 2.562351808782482

Epoch: 6| Step: 13
Training loss: 0.14629948073444596
Validation loss: 2.5308263576851373

Epoch: 492| Step: 0
Training loss: 0.12173064850102694
Validation loss: 2.5615795011875107

Epoch: 6| Step: 1
Training loss: 0.1427522928050443
Validation loss: 2.5883700452404512

Epoch: 6| Step: 2
Training loss: 0.19176133947340174
Validation loss: 2.5587522861987426

Epoch: 6| Step: 3
Training loss: 0.12140555385257457
Validation loss: 2.522044487244437

Epoch: 6| Step: 4
Training loss: 0.21431594519016736
Validation loss: 2.531245318851171

Epoch: 6| Step: 5
Training loss: 0.13317567592837445
Validation loss: 2.5171797074268305

Epoch: 6| Step: 6
Training loss: 0.10777301618183295
Validation loss: 2.565064740204607

Epoch: 6| Step: 7
Training loss: 0.2960460911343433
Validation loss: 2.5407050194832985

Epoch: 6| Step: 8
Training loss: 0.10447670474278437
Validation loss: 2.530965149191997

Epoch: 6| Step: 9
Training loss: 0.19008538837094066
Validation loss: 2.5738291340300807

Epoch: 6| Step: 10
Training loss: 0.14722070641332094
Validation loss: 2.557655270696194

Epoch: 6| Step: 11
Training loss: 0.15286409328150358
Validation loss: 2.5498771736825847

Epoch: 6| Step: 12
Training loss: 0.1380276625821048
Validation loss: 2.5585804307445814

Epoch: 6| Step: 13
Training loss: 0.09634013224109497
Validation loss: 2.5673394414423827

Epoch: 493| Step: 0
Training loss: 0.29003108620513113
Validation loss: 2.5449158046694937

Epoch: 6| Step: 1
Training loss: 0.10364589052182765
Validation loss: 2.5348947860639526

Epoch: 6| Step: 2
Training loss: 0.18418399809791966
Validation loss: 2.569505366503233

Epoch: 6| Step: 3
Training loss: 0.1434453106397092
Validation loss: 2.5189949173874098

Epoch: 6| Step: 4
Training loss: 0.08677116444592461
Validation loss: 2.5425168533082023

Epoch: 6| Step: 5
Training loss: 0.16883447903455107
Validation loss: 2.5101196187527126

Epoch: 6| Step: 6
Training loss: 0.11707098254577507
Validation loss: 2.4746880655945214

Epoch: 6| Step: 7
Training loss: 0.17090812655639503
Validation loss: 2.4873579509393084

Epoch: 6| Step: 8
Training loss: 0.15022942337985287
Validation loss: 2.480008252785428

Epoch: 6| Step: 9
Training loss: 0.10331539365889589
Validation loss: 2.5157101361413288

Epoch: 6| Step: 10
Training loss: 0.09426451105534221
Validation loss: 2.522699342915223

Epoch: 6| Step: 11
Training loss: 0.2592986793144965
Validation loss: 2.5139867469355446

Epoch: 6| Step: 12
Training loss: 0.17729564636132872
Validation loss: 2.536975449499336

Epoch: 6| Step: 13
Training loss: 0.07230776769423711
Validation loss: 2.5099048597426745

Epoch: 494| Step: 0
Training loss: 0.1131112862541563
Validation loss: 2.5562861165046824

Epoch: 6| Step: 1
Training loss: 0.1886354577121363
Validation loss: 2.532639134837919

Epoch: 6| Step: 2
Training loss: 0.09872935074683536
Validation loss: 2.5344573381819737

Epoch: 6| Step: 3
Training loss: 0.1427031778590051
Validation loss: 2.5609282899122214

Epoch: 6| Step: 4
Training loss: 0.18750942723098815
Validation loss: 2.535068946491865

Epoch: 6| Step: 5
Training loss: 0.20333072441478015
Validation loss: 2.546689415602294

Epoch: 6| Step: 6
Training loss: 0.1467195022531223
Validation loss: 2.546183087676754

Epoch: 6| Step: 7
Training loss: 0.1436007419332581
Validation loss: 2.5252996931669243

Epoch: 6| Step: 8
Training loss: 0.10436590085798844
Validation loss: 2.555855252243135

Epoch: 6| Step: 9
Training loss: 0.1666705620330338
Validation loss: 2.5535431420901222

Epoch: 6| Step: 10
Training loss: 0.19057986866490392
Validation loss: 2.567448198221845

Epoch: 6| Step: 11
Training loss: 0.14002056824359604
Validation loss: 2.5440076693015

Epoch: 6| Step: 12
Training loss: 0.2086210747298687
Validation loss: 2.529031828610202

Epoch: 6| Step: 13
Training loss: 0.12723178358553114
Validation loss: 2.5311593956469944

Epoch: 495| Step: 0
Training loss: 0.19261785372091056
Validation loss: 2.5395629793432417

Epoch: 6| Step: 1
Training loss: 0.13195110518251776
Validation loss: 2.515043274589453

Epoch: 6| Step: 2
Training loss: 0.1772549209288264
Validation loss: 2.493166800775979

Epoch: 6| Step: 3
Training loss: 0.20229318752921893
Validation loss: 2.481834961805822

Epoch: 6| Step: 4
Training loss: 0.17091746088143647
Validation loss: 2.485827564574939

Epoch: 6| Step: 5
Training loss: 0.16634487712778517
Validation loss: 2.4654651521146924

Epoch: 6| Step: 6
Training loss: 0.11231881757660622
Validation loss: 2.494157962971846

Epoch: 6| Step: 7
Training loss: 0.13369501943561152
Validation loss: 2.5011955991412744

Epoch: 6| Step: 8
Training loss: 0.12613669279904574
Validation loss: 2.484690932915738

Epoch: 6| Step: 9
Training loss: 0.14189783868262698
Validation loss: 2.4757446841383537

Epoch: 6| Step: 10
Training loss: 0.12527968736931477
Validation loss: 2.474248506705571

Epoch: 6| Step: 11
Training loss: 0.18897904729567772
Validation loss: 2.462755795199366

Epoch: 6| Step: 12
Training loss: 0.1677271691450438
Validation loss: 2.4688306675612597

Epoch: 6| Step: 13
Training loss: 0.17077219523745857
Validation loss: 2.470152554509918

Epoch: 496| Step: 0
Training loss: 0.11691768101510258
Validation loss: 2.491268960137948

Epoch: 6| Step: 1
Training loss: 0.14244268464121917
Validation loss: 2.470381872785097

Epoch: 6| Step: 2
Training loss: 0.14337517420010681
Validation loss: 2.500499667204684

Epoch: 6| Step: 3
Training loss: 0.22560837869366715
Validation loss: 2.5097662480942753

Epoch: 6| Step: 4
Training loss: 0.11519827519717542
Validation loss: 2.508053132945267

Epoch: 6| Step: 5
Training loss: 0.11568059438526566
Validation loss: 2.504070469658154

Epoch: 6| Step: 6
Training loss: 0.06762731806797755
Validation loss: 2.501994662149668

Epoch: 6| Step: 7
Training loss: 0.1540296086819625
Validation loss: 2.528512219295422

Epoch: 6| Step: 8
Training loss: 0.1221037017934585
Validation loss: 2.5330196581760664

Epoch: 6| Step: 9
Training loss: 0.1989478812959106
Validation loss: 2.5125489007881314

Epoch: 6| Step: 10
Training loss: 0.19916607590478672
Validation loss: 2.529954842007127

Epoch: 6| Step: 11
Training loss: 0.09651922144958411
Validation loss: 2.541945920383722

Epoch: 6| Step: 12
Training loss: 0.13497731265414736
Validation loss: 2.523143939563458

Epoch: 6| Step: 13
Training loss: 0.0640415394324826
Validation loss: 2.535491972197501

Epoch: 497| Step: 0
Training loss: 0.11983723309390593
Validation loss: 2.5586050599903514

Epoch: 6| Step: 1
Training loss: 0.08850523839751867
Validation loss: 2.5629084136824836

Epoch: 6| Step: 2
Training loss: 0.10221066339250919
Validation loss: 2.5525169139021773

Epoch: 6| Step: 3
Training loss: 0.11726149368760132
Validation loss: 2.520533697886597

Epoch: 6| Step: 4
Training loss: 0.16481279629444545
Validation loss: 2.5692384023256314

Epoch: 6| Step: 5
Training loss: 0.11724664864320622
Validation loss: 2.4952594177204217

Epoch: 6| Step: 6
Training loss: 0.13366683890277312
Validation loss: 2.5304794465441893

Epoch: 6| Step: 7
Training loss: 0.1314046941522215
Validation loss: 2.525383545360646

Epoch: 6| Step: 8
Training loss: 0.1912164428198945
Validation loss: 2.537047356416037

Epoch: 6| Step: 9
Training loss: 0.2761377116524331
Validation loss: 2.546604486630981

Epoch: 6| Step: 10
Training loss: 0.1541088805981197
Validation loss: 2.5309138098198622

Epoch: 6| Step: 11
Training loss: 0.1786404767822836
Validation loss: 2.5244136623776487

Epoch: 6| Step: 12
Training loss: 0.1586688275046912
Validation loss: 2.5346242963194547

Epoch: 6| Step: 13
Training loss: 0.09536237779577728
Validation loss: 2.579299512054066

Epoch: 498| Step: 0
Training loss: 0.18316782588920222
Validation loss: 2.549608571813894

Epoch: 6| Step: 1
Training loss: 0.17859193352070038
Validation loss: 2.5468815468062873

Epoch: 6| Step: 2
Training loss: 0.10965081757618138
Validation loss: 2.5350131055381455

Epoch: 6| Step: 3
Training loss: 0.20201207597323473
Validation loss: 2.5204756176244723

Epoch: 6| Step: 4
Training loss: 0.1940835915036639
Validation loss: 2.5410190653600524

Epoch: 6| Step: 5
Training loss: 0.10632932976202049
Validation loss: 2.5479805828702444

Epoch: 6| Step: 6
Training loss: 0.09666429262219418
Validation loss: 2.5489462668921976

Epoch: 6| Step: 7
Training loss: 0.1099732505585266
Validation loss: 2.564708564318232

Epoch: 6| Step: 8
Training loss: 0.06994383576303248
Validation loss: 2.566529797741648

Epoch: 6| Step: 9
Training loss: 0.1694590194929157
Validation loss: 2.567134239793655

Epoch: 6| Step: 10
Training loss: 0.13637759013561565
Validation loss: 2.499223463398964

Epoch: 6| Step: 11
Training loss: 0.12905586114762307
Validation loss: 2.5653880821969044

Epoch: 6| Step: 12
Training loss: 0.1625588058475796
Validation loss: 2.531068127660085

Epoch: 6| Step: 13
Training loss: 0.20209045315683144
Validation loss: 2.5250298751611813

Epoch: 499| Step: 0
Training loss: 0.2774902279310278
Validation loss: 2.5282132512377946

Epoch: 6| Step: 1
Training loss: 0.13062179406352323
Validation loss: 2.425589996223228

Epoch: 6| Step: 2
Training loss: 0.11282729992910207
Validation loss: 2.4733132312835506

Epoch: 6| Step: 3
Training loss: 0.10284656555983715
Validation loss: 2.5031875793025744

Epoch: 6| Step: 4
Training loss: 0.07597062840369669
Validation loss: 2.4949538299170504

Epoch: 6| Step: 5
Training loss: 0.1634030542580949
Validation loss: 2.503205258636939

Epoch: 6| Step: 6
Training loss: 0.1453980537537798
Validation loss: 2.481837037025151

Epoch: 6| Step: 7
Training loss: 0.10957814407919611
Validation loss: 2.53889041642482

Epoch: 6| Step: 8
Training loss: 0.12293508159026435
Validation loss: 2.5333549753871925

Epoch: 6| Step: 9
Training loss: 0.1430087640663463
Validation loss: 2.558429124626157

Epoch: 6| Step: 10
Training loss: 0.12670306741353526
Validation loss: 2.5437862031957588

Epoch: 6| Step: 11
Training loss: 0.23755697489272104
Validation loss: 2.547765592582877

Epoch: 6| Step: 12
Training loss: 0.14209413030391865
Validation loss: 2.5447138123600874

Epoch: 6| Step: 13
Training loss: 0.1054616236928252
Validation loss: 2.5335285783743062

Epoch: 500| Step: 0
Training loss: 0.21086691629125867
Validation loss: 2.5491099890931532

Epoch: 6| Step: 1
Training loss: 0.10447477480825758
Validation loss: 2.5081852011833243

Epoch: 6| Step: 2
Training loss: 0.3507623149119709
Validation loss: 2.4638036899753106

Epoch: 6| Step: 3
Training loss: 0.1988905465818681
Validation loss: 2.5046421984104783

Epoch: 6| Step: 4
Training loss: 0.12546403257259256
Validation loss: 2.490291603005057

Epoch: 6| Step: 5
Training loss: 0.20280899629667015
Validation loss: 2.481106842135777

Epoch: 6| Step: 6
Training loss: 0.15364934154858817
Validation loss: 2.4492711674918097

Epoch: 6| Step: 7
Training loss: 0.12604010997420423
Validation loss: 2.4731320625775353

Epoch: 6| Step: 8
Training loss: 0.12140600645072791
Validation loss: 2.4485606215560445

Epoch: 6| Step: 9
Training loss: 0.21224739298269704
Validation loss: 2.474408036935349

Epoch: 6| Step: 10
Training loss: 0.11910557622205026
Validation loss: 2.4698432971945983

Epoch: 6| Step: 11
Training loss: 0.20488711953522593
Validation loss: 2.4605911440864645

Epoch: 6| Step: 12
Training loss: 0.22733871087326357
Validation loss: 2.4824274630283707

Epoch: 6| Step: 13
Training loss: 0.14817216020818333
Validation loss: 2.488058515955411

Epoch: 501| Step: 0
Training loss: 0.1773860368433488
Validation loss: 2.479972876477518

Epoch: 6| Step: 1
Training loss: 0.13913586053075142
Validation loss: 2.5040351154034397

Epoch: 6| Step: 2
Training loss: 0.18013881934838713
Validation loss: 2.509837606687494

Epoch: 6| Step: 3
Training loss: 0.15649709832644323
Validation loss: 2.501628592660932

Epoch: 6| Step: 4
Training loss: 0.26738375544468845
Validation loss: 2.5322672892294635

Epoch: 6| Step: 5
Training loss: 0.19136471200320257
Validation loss: 2.5495261631764476

Epoch: 6| Step: 6
Training loss: 0.2501384232678111
Validation loss: 2.5511108300091205

Epoch: 6| Step: 7
Training loss: 0.10371894482234853
Validation loss: 2.5353501369288156

Epoch: 6| Step: 8
Training loss: 0.15072315781981824
Validation loss: 2.520620542179415

Epoch: 6| Step: 9
Training loss: 0.22956463907866956
Validation loss: 2.52942993609718

Epoch: 6| Step: 10
Training loss: 0.134214275460936
Validation loss: 2.5047149281472625

Epoch: 6| Step: 11
Training loss: 0.13080581593831297
Validation loss: 2.4612698404972178

Epoch: 6| Step: 12
Training loss: 0.12633767970040188
Validation loss: 2.465483431047426

Epoch: 6| Step: 13
Training loss: 0.31206045232827206
Validation loss: 2.4648103787298696

Epoch: 502| Step: 0
Training loss: 0.2537881576571276
Validation loss: 2.471880683598367

Epoch: 6| Step: 1
Training loss: 0.18380426958109317
Validation loss: 2.456816925316507

Epoch: 6| Step: 2
Training loss: 0.23148994176468646
Validation loss: 2.474532510461576

Epoch: 6| Step: 3
Training loss: 0.13716278856162462
Validation loss: 2.495845856509233

Epoch: 6| Step: 4
Training loss: 0.1143592400584576
Validation loss: 2.5300142580349054

Epoch: 6| Step: 5
Training loss: 0.13555763240418697
Validation loss: 2.5290534777796942

Epoch: 6| Step: 6
Training loss: 0.11762336497457561
Validation loss: 2.5243128483115562

Epoch: 6| Step: 7
Training loss: 0.2471434217401961
Validation loss: 2.5487430761839973

Epoch: 6| Step: 8
Training loss: 0.1489604346809578
Validation loss: 2.539240759814952

Epoch: 6| Step: 9
Training loss: 0.14715045807061042
Validation loss: 2.5386607023993144

Epoch: 6| Step: 10
Training loss: 0.1362985078726298
Validation loss: 2.5174047337082097

Epoch: 6| Step: 11
Training loss: 0.2778311999263293
Validation loss: 2.5294026893561603

Epoch: 6| Step: 12
Training loss: 0.1796072283032042
Validation loss: 2.5226777733590793

Epoch: 6| Step: 13
Training loss: 0.15253089755939203
Validation loss: 2.5069947004249586

Epoch: 503| Step: 0
Training loss: 0.19931358062520577
Validation loss: 2.520590135244588

Epoch: 6| Step: 1
Training loss: 0.15848070682243448
Validation loss: 2.5212459248593793

Epoch: 6| Step: 2
Training loss: 0.19618745327997883
Validation loss: 2.489531011688512

Epoch: 6| Step: 3
Training loss: 0.18833091524000903
Validation loss: 2.498679831806482

Epoch: 6| Step: 4
Training loss: 0.14720610521249725
Validation loss: 2.4975804941758484

Epoch: 6| Step: 5
Training loss: 0.24581425553719918
Validation loss: 2.522599641750796

Epoch: 6| Step: 6
Training loss: 0.22699331561300418
Validation loss: 2.522216682400291

Epoch: 6| Step: 7
Training loss: 0.20293839759968857
Validation loss: 2.5140100338627662

Epoch: 6| Step: 8
Training loss: 0.12338781805614821
Validation loss: 2.521974070739937

Epoch: 6| Step: 9
Training loss: 0.14744447148833645
Validation loss: 2.554406135937554

Epoch: 6| Step: 10
Training loss: 0.15211615311734913
Validation loss: 2.5386857301457386

Epoch: 6| Step: 11
Training loss: 0.1043761402199191
Validation loss: 2.520256034259683

Epoch: 6| Step: 12
Training loss: 0.20780408311591986
Validation loss: 2.529435945280141

Epoch: 6| Step: 13
Training loss: 0.10770074452927185
Validation loss: 2.50252812544389

Epoch: 504| Step: 0
Training loss: 0.10117612299598701
Validation loss: 2.494279646076394

Epoch: 6| Step: 1
Training loss: 0.17169957528561677
Validation loss: 2.510463829722526

Epoch: 6| Step: 2
Training loss: 0.08686687763840545
Validation loss: 2.5124950306238745

Epoch: 6| Step: 3
Training loss: 0.13298545122882058
Validation loss: 2.5085761716548065

Epoch: 6| Step: 4
Training loss: 0.20922773220845894
Validation loss: 2.5068639203871683

Epoch: 6| Step: 5
Training loss: 0.19944548326639133
Validation loss: 2.5098964550606375

Epoch: 6| Step: 6
Training loss: 0.1501785740249728
Validation loss: 2.5173597785362496

Epoch: 6| Step: 7
Training loss: 0.20633298151034257
Validation loss: 2.543857712007289

Epoch: 6| Step: 8
Training loss: 0.20277683056068696
Validation loss: 2.5402929270768726

Epoch: 6| Step: 9
Training loss: 0.11170805966641234
Validation loss: 2.5523335715677264

Epoch: 6| Step: 10
Training loss: 0.17445232531257063
Validation loss: 2.5545420860392025

Epoch: 6| Step: 11
Training loss: 0.14903968457490438
Validation loss: 2.54192394230079

Epoch: 6| Step: 12
Training loss: 0.1259132492295735
Validation loss: 2.5225803041039585

Epoch: 6| Step: 13
Training loss: 0.1313816650493859
Validation loss: 2.510120671735575

Epoch: 505| Step: 0
Training loss: 0.16754812981405034
Validation loss: 2.5004222718337292

Epoch: 6| Step: 1
Training loss: 0.19543245446646074
Validation loss: 2.5230421303061377

Epoch: 6| Step: 2
Training loss: 0.13182405488894242
Validation loss: 2.5208548366355275

Epoch: 6| Step: 3
Training loss: 0.15408334563946233
Validation loss: 2.530450066337158

Epoch: 6| Step: 4
Training loss: 0.12878792562957753
Validation loss: 2.5468945658818205

Epoch: 6| Step: 5
Training loss: 0.15307580074770288
Validation loss: 2.537840798199777

Epoch: 6| Step: 6
Training loss: 0.15230046782282414
Validation loss: 2.5367823254850266

Epoch: 6| Step: 7
Training loss: 0.16081410302216803
Validation loss: 2.5486107306956853

Epoch: 6| Step: 8
Training loss: 0.09209587223065849
Validation loss: 2.5606650624023644

Epoch: 6| Step: 9
Training loss: 0.1853677386831437
Validation loss: 2.583318464836444

Epoch: 6| Step: 10
Training loss: 0.16743761187140646
Validation loss: 2.55981114155541

Epoch: 6| Step: 11
Training loss: 0.23064338404050105
Validation loss: 2.5948780056729857

Epoch: 6| Step: 12
Training loss: 0.15428706632896397
Validation loss: 2.5766909770404847

Epoch: 6| Step: 13
Training loss: 0.21207546644540629
Validation loss: 2.5836152138941526

Epoch: 506| Step: 0
Training loss: 0.12108253611662964
Validation loss: 2.562608664044726

Epoch: 6| Step: 1
Training loss: 0.09413498568758939
Validation loss: 2.564151977254423

Epoch: 6| Step: 2
Training loss: 0.09128547824651181
Validation loss: 2.5169793087639443

Epoch: 6| Step: 3
Training loss: 0.17599771205304973
Validation loss: 2.4952503503459527

Epoch: 6| Step: 4
Training loss: 0.17606107373924368
Validation loss: 2.5009351140235774

Epoch: 6| Step: 5
Training loss: 0.1370579394835535
Validation loss: 2.5072588307646972

Epoch: 6| Step: 6
Training loss: 0.24480928026233859
Validation loss: 2.5031969005903574

Epoch: 6| Step: 7
Training loss: 0.12292289542994997
Validation loss: 2.496655591861326

Epoch: 6| Step: 8
Training loss: 0.13000188833020648
Validation loss: 2.489513024657004

Epoch: 6| Step: 9
Training loss: 0.226814935078798
Validation loss: 2.5045004043053867

Epoch: 6| Step: 10
Training loss: 0.1646190920343897
Validation loss: 2.4694316873542688

Epoch: 6| Step: 11
Training loss: 0.13985454581588266
Validation loss: 2.5032220504324707

Epoch: 6| Step: 12
Training loss: 0.12692734383186008
Validation loss: 2.4803951491189244

Epoch: 6| Step: 13
Training loss: 0.10767502865942614
Validation loss: 2.500513680300739

Epoch: 507| Step: 0
Training loss: 0.10220852209833947
Validation loss: 2.4819801620273383

Epoch: 6| Step: 1
Training loss: 0.12421842700988237
Validation loss: 2.506982680812687

Epoch: 6| Step: 2
Training loss: 0.11866352829199804
Validation loss: 2.5033678401862

Epoch: 6| Step: 3
Training loss: 0.11998918349845235
Validation loss: 2.506127058783239

Epoch: 6| Step: 4
Training loss: 0.11330710313372605
Validation loss: 2.485310916933732

Epoch: 6| Step: 5
Training loss: 0.2637294565127845
Validation loss: 2.5187009302544903

Epoch: 6| Step: 6
Training loss: 0.14332783219496667
Validation loss: 2.499378467536659

Epoch: 6| Step: 7
Training loss: 0.1980491224232901
Validation loss: 2.521231939547297

Epoch: 6| Step: 8
Training loss: 0.07420386616892352
Validation loss: 2.521600780518396

Epoch: 6| Step: 9
Training loss: 0.12210009020958043
Validation loss: 2.496427953829285

Epoch: 6| Step: 10
Training loss: 0.1119782762898673
Validation loss: 2.508405342726871

Epoch: 6| Step: 11
Training loss: 0.11446816081989696
Validation loss: 2.518738775386811

Epoch: 6| Step: 12
Training loss: 0.13327241253370659
Validation loss: 2.5328113303748276

Epoch: 6| Step: 13
Training loss: 0.11898366563451539
Validation loss: 2.481994167097096

Epoch: 508| Step: 0
Training loss: 0.09408434218216903
Validation loss: 2.531290081096258

Epoch: 6| Step: 1
Training loss: 0.12647693532042492
Validation loss: 2.509541435853502

Epoch: 6| Step: 2
Training loss: 0.21912607154867084
Validation loss: 2.5226899239776652

Epoch: 6| Step: 3
Training loss: 0.2269990431381006
Validation loss: 2.5400265250461325

Epoch: 6| Step: 4
Training loss: 0.10821405830644924
Validation loss: 2.5536911798971373

Epoch: 6| Step: 5
Training loss: 0.1546468026155956
Validation loss: 2.5266285765791996

Epoch: 6| Step: 6
Training loss: 0.16024718378020492
Validation loss: 2.5174349790114245

Epoch: 6| Step: 7
Training loss: 0.20077789949523406
Validation loss: 2.531264751335133

Epoch: 6| Step: 8
Training loss: 0.11275733037943463
Validation loss: 2.4824941600451673

Epoch: 6| Step: 9
Training loss: 0.14671513501183608
Validation loss: 2.5314634449106377

Epoch: 6| Step: 10
Training loss: 0.08853833692497896
Validation loss: 2.5504455365587475

Epoch: 6| Step: 11
Training loss: 0.08422208844417169
Validation loss: 2.525565864619449

Epoch: 6| Step: 12
Training loss: 0.10446823148544536
Validation loss: 2.5295816076025996

Epoch: 6| Step: 13
Training loss: 0.07709729636300104
Validation loss: 2.54050675151163

Epoch: 509| Step: 0
Training loss: 0.1496312488969548
Validation loss: 2.529375401779759

Epoch: 6| Step: 1
Training loss: 0.15448511688603703
Validation loss: 2.519316833840416

Epoch: 6| Step: 2
Training loss: 0.15368076643943923
Validation loss: 2.52170723093523

Epoch: 6| Step: 3
Training loss: 0.11348164853961316
Validation loss: 2.5479954355551566

Epoch: 6| Step: 4
Training loss: 0.12835926266025077
Validation loss: 2.5105905261159784

Epoch: 6| Step: 5
Training loss: 0.09754955184932322
Validation loss: 2.4849100184990633

Epoch: 6| Step: 6
Training loss: 0.1257843058671013
Validation loss: 2.508769568840164

Epoch: 6| Step: 7
Training loss: 0.08961498118243567
Validation loss: 2.5114813080486464

Epoch: 6| Step: 8
Training loss: 0.13959149887152
Validation loss: 2.5047050746439092

Epoch: 6| Step: 9
Training loss: 0.11333655783008267
Validation loss: 2.4863483240700837

Epoch: 6| Step: 10
Training loss: 0.28124671510261584
Validation loss: 2.4738844847006094

Epoch: 6| Step: 11
Training loss: 0.07524938001963437
Validation loss: 2.479594718921344

Epoch: 6| Step: 12
Training loss: 0.2350917347460737
Validation loss: 2.4726010140648147

Epoch: 6| Step: 13
Training loss: 0.10257106009280699
Validation loss: 2.4774451362022956

Epoch: 510| Step: 0
Training loss: 0.23718535794231974
Validation loss: 2.5029667355879304

Epoch: 6| Step: 1
Training loss: 0.1255586256285842
Validation loss: 2.5171241336595997

Epoch: 6| Step: 2
Training loss: 0.23505894685091916
Validation loss: 2.539986532355014

Epoch: 6| Step: 3
Training loss: 0.2085930734973467
Validation loss: 2.4740587184122504

Epoch: 6| Step: 4
Training loss: 0.21209174060052338
Validation loss: 2.47165745437397

Epoch: 6| Step: 5
Training loss: 0.11825300447596913
Validation loss: 2.5026756652785287

Epoch: 6| Step: 6
Training loss: 0.1723663394645865
Validation loss: 2.524439942360219

Epoch: 6| Step: 7
Training loss: 0.1405079208534805
Validation loss: 2.503775016828388

Epoch: 6| Step: 8
Training loss: 0.19192610425108442
Validation loss: 2.5085454460143297

Epoch: 6| Step: 9
Training loss: 0.1322648805686339
Validation loss: 2.495296812393772

Epoch: 6| Step: 10
Training loss: 0.1603144817713146
Validation loss: 2.537930803409701

Epoch: 6| Step: 11
Training loss: 0.14110992190048383
Validation loss: 2.471571075140079

Epoch: 6| Step: 12
Training loss: 0.12097940891798459
Validation loss: 2.4963406946109488

Epoch: 6| Step: 13
Training loss: 0.1363332763835365
Validation loss: 2.4964258188543296

Epoch: 511| Step: 0
Training loss: 0.12104688783613309
Validation loss: 2.5391283090801484

Epoch: 6| Step: 1
Training loss: 0.17911201038899333
Validation loss: 2.4759576634132547

Epoch: 6| Step: 2
Training loss: 0.12820979022565218
Validation loss: 2.4860797362292644

Epoch: 6| Step: 3
Training loss: 0.10375297075350162
Validation loss: 2.4961221480761324

Epoch: 6| Step: 4
Training loss: 0.11713575571810292
Validation loss: 2.510222606760331

Epoch: 6| Step: 5
Training loss: 0.12450923917208767
Validation loss: 2.5132906051935384

Epoch: 6| Step: 6
Training loss: 0.16772024490474918
Validation loss: 2.5226644446022926

Epoch: 6| Step: 7
Training loss: 0.17830727018728823
Validation loss: 2.5122747555899236

Epoch: 6| Step: 8
Training loss: 0.12761293027588358
Validation loss: 2.484639071263244

Epoch: 6| Step: 9
Training loss: 0.19204797021691508
Validation loss: 2.515632257926864

Epoch: 6| Step: 10
Training loss: 0.11158935950152767
Validation loss: 2.5079389332050512

Epoch: 6| Step: 11
Training loss: 0.08902362008304125
Validation loss: 2.534882646414519

Epoch: 6| Step: 12
Training loss: 0.1410728317418599
Validation loss: 2.4901000986687314

Epoch: 6| Step: 13
Training loss: 0.06847401950986555
Validation loss: 2.5177541904301384

Epoch: 512| Step: 0
Training loss: 0.08714928568038711
Validation loss: 2.5447061356732186

Epoch: 6| Step: 1
Training loss: 0.13303679571987717
Validation loss: 2.5434679854694293

Epoch: 6| Step: 2
Training loss: 0.12289781851913009
Validation loss: 2.5322541514177606

Epoch: 6| Step: 3
Training loss: 0.10056497299823655
Validation loss: 2.522511541857128

Epoch: 6| Step: 4
Training loss: 0.12079881313389075
Validation loss: 2.5109918458213656

Epoch: 6| Step: 5
Training loss: 0.23448634681627553
Validation loss: 2.4850977458205983

Epoch: 6| Step: 6
Training loss: 0.15100739079192077
Validation loss: 2.517099215404116

Epoch: 6| Step: 7
Training loss: 0.07556224446730717
Validation loss: 2.515028775701948

Epoch: 6| Step: 8
Training loss: 0.09313643863691694
Validation loss: 2.4861736322591113

Epoch: 6| Step: 9
Training loss: 0.1606242274291759
Validation loss: 2.49243380152125

Epoch: 6| Step: 10
Training loss: 0.1257579888579971
Validation loss: 2.456398060524178

Epoch: 6| Step: 11
Training loss: 0.14886298810070192
Validation loss: 2.455192232574926

Epoch: 6| Step: 12
Training loss: 0.22534680593426354
Validation loss: 2.4583340167389998

Epoch: 6| Step: 13
Training loss: 0.11967658824830978
Validation loss: 2.4926233611588486

Epoch: 513| Step: 0
Training loss: 0.12868668902319017
Validation loss: 2.4823835629487085

Epoch: 6| Step: 1
Training loss: 0.19282782346898017
Validation loss: 2.5069959794355228

Epoch: 6| Step: 2
Training loss: 0.1291798231771868
Validation loss: 2.4959266189786273

Epoch: 6| Step: 3
Training loss: 0.16396696283585357
Validation loss: 2.5057754930328415

Epoch: 6| Step: 4
Training loss: 0.08712749848621283
Validation loss: 2.497815872111919

Epoch: 6| Step: 5
Training loss: 0.1128700867948091
Validation loss: 2.5228699579568454

Epoch: 6| Step: 6
Training loss: 0.11318649242201213
Validation loss: 2.488521206397791

Epoch: 6| Step: 7
Training loss: 0.13927265104231298
Validation loss: 2.486061107050663

Epoch: 6| Step: 8
Training loss: 0.11789168736565007
Validation loss: 2.4894650559439793

Epoch: 6| Step: 9
Training loss: 0.11501905561994301
Validation loss: 2.5577468288231735

Epoch: 6| Step: 10
Training loss: 0.06012012462121137
Validation loss: 2.513455862529475

Epoch: 6| Step: 11
Training loss: 0.18727050087397404
Validation loss: 2.5101588893015148

Epoch: 6| Step: 12
Training loss: 0.21244979854447602
Validation loss: 2.5500215909503474

Epoch: 6| Step: 13
Training loss: 0.09257628925933893
Validation loss: 2.5390457243637328

Epoch: 514| Step: 0
Training loss: 0.08120441969330641
Validation loss: 2.4993066728716213

Epoch: 6| Step: 1
Training loss: 0.08234976907099434
Validation loss: 2.532769725716442

Epoch: 6| Step: 2
Training loss: 0.09050596863404115
Validation loss: 2.492232573891727

Epoch: 6| Step: 3
Training loss: 0.13258431270143936
Validation loss: 2.4882992016336036

Epoch: 6| Step: 4
Training loss: 0.18467932211815846
Validation loss: 2.487082811225448

Epoch: 6| Step: 5
Training loss: 0.11461784012989419
Validation loss: 2.49612149076446

Epoch: 6| Step: 6
Training loss: 0.11023803796096232
Validation loss: 2.4884413780357355

Epoch: 6| Step: 7
Training loss: 0.10636870663665142
Validation loss: 2.5245975657375546

Epoch: 6| Step: 8
Training loss: 0.19088606311711184
Validation loss: 2.5272442462615965

Epoch: 6| Step: 9
Training loss: 0.11696863399054491
Validation loss: 2.5462381299053023

Epoch: 6| Step: 10
Training loss: 0.19363903282691106
Validation loss: 2.546596151226205

Epoch: 6| Step: 11
Training loss: 0.1120200572281686
Validation loss: 2.5780763185838964

Epoch: 6| Step: 12
Training loss: 0.092403134616974
Validation loss: 2.5699680991682925

Epoch: 6| Step: 13
Training loss: 0.12766560385996623
Validation loss: 2.537593606608142

Epoch: 515| Step: 0
Training loss: 0.10233713430760073
Validation loss: 2.4999813335501178

Epoch: 6| Step: 1
Training loss: 0.09964246761155056
Validation loss: 2.5205844106059403

Epoch: 6| Step: 2
Training loss: 0.1433390990218555
Validation loss: 2.5319948998087387

Epoch: 6| Step: 3
Training loss: 0.2265726942202438
Validation loss: 2.5205840134354496

Epoch: 6| Step: 4
Training loss: 0.12456122143606507
Validation loss: 2.4993983180478327

Epoch: 6| Step: 5
Training loss: 0.11999059612337307
Validation loss: 2.4874251640243976

Epoch: 6| Step: 6
Training loss: 0.12392068345907888
Validation loss: 2.5016311707716974

Epoch: 6| Step: 7
Training loss: 0.16999802034291264
Validation loss: 2.472790810045537

Epoch: 6| Step: 8
Training loss: 0.22537725465147135
Validation loss: 2.518467484403223

Epoch: 6| Step: 9
Training loss: 0.10238324997396199
Validation loss: 2.4813143523159

Epoch: 6| Step: 10
Training loss: 0.12905428795631718
Validation loss: 2.493837610400437

Epoch: 6| Step: 11
Training loss: 0.06431277846094428
Validation loss: 2.488423194596521

Epoch: 6| Step: 12
Training loss: 0.13445098746693607
Validation loss: 2.499628402411162

Epoch: 6| Step: 13
Training loss: 0.23773812321451296
Validation loss: 2.504646020364303

Epoch: 516| Step: 0
Training loss: 0.28799594831431313
Validation loss: 2.4915004866867014

Epoch: 6| Step: 1
Training loss: 0.1201115273483408
Validation loss: 2.5024082203207025

Epoch: 6| Step: 2
Training loss: 0.10490888328389286
Validation loss: 2.493911350131591

Epoch: 6| Step: 3
Training loss: 0.11850750878392136
Validation loss: 2.4665422714875502

Epoch: 6| Step: 4
Training loss: 0.09679673074799289
Validation loss: 2.5078547190522706

Epoch: 6| Step: 5
Training loss: 0.14636042118849074
Validation loss: 2.5254954945285792

Epoch: 6| Step: 6
Training loss: 0.2820947860837355
Validation loss: 2.5340051750916115

Epoch: 6| Step: 7
Training loss: 0.24183859611557007
Validation loss: 2.515405171299503

Epoch: 6| Step: 8
Training loss: 0.16909489046373838
Validation loss: 2.511441042497459

Epoch: 6| Step: 9
Training loss: 0.22646967860921463
Validation loss: 2.5187861822744724

Epoch: 6| Step: 10
Training loss: 0.09073299394229506
Validation loss: 2.529615205747714

Epoch: 6| Step: 11
Training loss: 0.166839228396424
Validation loss: 2.5360363233572345

Epoch: 6| Step: 12
Training loss: 0.2133774571838758
Validation loss: 2.5368819391652155

Epoch: 6| Step: 13
Training loss: 0.1074568734809721
Validation loss: 2.5341336313159992

Epoch: 517| Step: 0
Training loss: 0.20308705122125578
Validation loss: 2.5568927269678783

Epoch: 6| Step: 1
Training loss: 0.1823579713036708
Validation loss: 2.4853406492039163

Epoch: 6| Step: 2
Training loss: 0.26170824513775254
Validation loss: 2.5374817517029196

Epoch: 6| Step: 3
Training loss: 0.15054023410302206
Validation loss: 2.5107687443392437

Epoch: 6| Step: 4
Training loss: 0.21045667099647056
Validation loss: 2.5073573539282523

Epoch: 6| Step: 5
Training loss: 0.19447398434398402
Validation loss: 2.5028972747104556

Epoch: 6| Step: 6
Training loss: 0.1731487295176436
Validation loss: 2.5248265122649833

Epoch: 6| Step: 7
Training loss: 0.134101732033351
Validation loss: 2.5065367440656354

Epoch: 6| Step: 8
Training loss: 0.12398531094938761
Validation loss: 2.525502104877323

Epoch: 6| Step: 9
Training loss: 0.21289281231517715
Validation loss: 2.517245385877847

Epoch: 6| Step: 10
Training loss: 0.1509426685893626
Validation loss: 2.5542852446241175

Epoch: 6| Step: 11
Training loss: 0.3542646828760334
Validation loss: 2.5401531371643906

Epoch: 6| Step: 12
Training loss: 0.07715963934201542
Validation loss: 2.5682555140667263

Epoch: 6| Step: 13
Training loss: 0.11394802711451939
Validation loss: 2.5060429274726315

Epoch: 518| Step: 0
Training loss: 0.14696135746814393
Validation loss: 2.5668437906502657

Epoch: 6| Step: 1
Training loss: 0.2582028497183713
Validation loss: 2.536239948832482

Epoch: 6| Step: 2
Training loss: 0.24981111603220618
Validation loss: 2.5066623556780034

Epoch: 6| Step: 3
Training loss: 0.247438284929326
Validation loss: 2.50842656743914

Epoch: 6| Step: 4
Training loss: 0.13341253437941408
Validation loss: 2.4859412754705357

Epoch: 6| Step: 5
Training loss: 0.2010650906892451
Validation loss: 2.5019706957349643

Epoch: 6| Step: 6
Training loss: 0.10636833452271013
Validation loss: 2.4776223286983305

Epoch: 6| Step: 7
Training loss: 0.1722361173897211
Validation loss: 2.499365767147578

Epoch: 6| Step: 8
Training loss: 0.20519543879962768
Validation loss: 2.515642392697033

Epoch: 6| Step: 9
Training loss: 0.17632011892306493
Validation loss: 2.4985969154243017

Epoch: 6| Step: 10
Training loss: 0.2247945851194578
Validation loss: 2.478230288601053

Epoch: 6| Step: 11
Training loss: 0.15878195893373961
Validation loss: 2.5072203197580354

Epoch: 6| Step: 12
Training loss: 0.21496959815098546
Validation loss: 2.5087987211377087

Epoch: 6| Step: 13
Training loss: 0.1308383070654344
Validation loss: 2.493301023511433

Epoch: 519| Step: 0
Training loss: 0.22298228502794368
Validation loss: 2.5088633672451217

Epoch: 6| Step: 1
Training loss: 0.1407235449313522
Validation loss: 2.504752777849572

Epoch: 6| Step: 2
Training loss: 0.22457839088686954
Validation loss: 2.5407737529863157

Epoch: 6| Step: 3
Training loss: 0.13196043564559473
Validation loss: 2.5658116664765047

Epoch: 6| Step: 4
Training loss: 0.22048726961794357
Validation loss: 2.523579381059482

Epoch: 6| Step: 5
Training loss: 0.2505925428154731
Validation loss: 2.5946838609306173

Epoch: 6| Step: 6
Training loss: 0.11013381709298002
Validation loss: 2.577844663302364

Epoch: 6| Step: 7
Training loss: 0.09741619646490135
Validation loss: 2.527197334823691

Epoch: 6| Step: 8
Training loss: 0.22820871071409632
Validation loss: 2.5478686154699326

Epoch: 6| Step: 9
Training loss: 0.2867419688206784
Validation loss: 2.4973305078146035

Epoch: 6| Step: 10
Training loss: 0.18669203682869745
Validation loss: 2.523113911040309

Epoch: 6| Step: 11
Training loss: 0.20004117661029222
Validation loss: 2.4751684767697713

Epoch: 6| Step: 12
Training loss: 0.18821888440802023
Validation loss: 2.4561683050661722

Epoch: 6| Step: 13
Training loss: 0.23651157699067357
Validation loss: 2.4363585766323466

Epoch: 520| Step: 0
Training loss: 0.24090242927204472
Validation loss: 2.4720314930599154

Epoch: 6| Step: 1
Training loss: 0.16871743461956717
Validation loss: 2.4704884941847816

Epoch: 6| Step: 2
Training loss: 0.09672400874692083
Validation loss: 2.4752291214211684

Epoch: 6| Step: 3
Training loss: 0.10354604813818499
Validation loss: 2.4615507430535066

Epoch: 6| Step: 4
Training loss: 0.06693897024244339
Validation loss: 2.5170926771984172

Epoch: 6| Step: 5
Training loss: 0.1694126500973923
Validation loss: 2.5028732165594274

Epoch: 6| Step: 6
Training loss: 0.1055892811922125
Validation loss: 2.519495219820184

Epoch: 6| Step: 7
Training loss: 0.15059371957820183
Validation loss: 2.524140520406037

Epoch: 6| Step: 8
Training loss: 0.1673819193599201
Validation loss: 2.527322195990483

Epoch: 6| Step: 9
Training loss: 0.15166424551103727
Validation loss: 2.513849060456788

Epoch: 6| Step: 10
Training loss: 0.20952362827545667
Validation loss: 2.492591967302575

Epoch: 6| Step: 11
Training loss: 0.23253925148539567
Validation loss: 2.4760134120510453

Epoch: 6| Step: 12
Training loss: 0.1347609532970131
Validation loss: 2.509626450463812

Epoch: 6| Step: 13
Training loss: 0.05162412318816872
Validation loss: 2.498769416246311

Epoch: 521| Step: 0
Training loss: 0.13003645679158468
Validation loss: 2.4790169058907154

Epoch: 6| Step: 1
Training loss: 0.1025252105802584
Validation loss: 2.4918699136429

Epoch: 6| Step: 2
Training loss: 0.12147278837778315
Validation loss: 2.47966233886932

Epoch: 6| Step: 3
Training loss: 0.13901801630111307
Validation loss: 2.5044887514612353

Epoch: 6| Step: 4
Training loss: 0.21089893447695893
Validation loss: 2.497345715115609

Epoch: 6| Step: 5
Training loss: 0.11613517182715805
Validation loss: 2.5091397960415764

Epoch: 6| Step: 6
Training loss: 0.13192967508568645
Validation loss: 2.5281217126158078

Epoch: 6| Step: 7
Training loss: 0.11065864876951072
Validation loss: 2.4848794381806254

Epoch: 6| Step: 8
Training loss: 0.1969478616158717
Validation loss: 2.5066431203402035

Epoch: 6| Step: 9
Training loss: 0.15602881750681896
Validation loss: 2.5129909555473113

Epoch: 6| Step: 10
Training loss: 0.18422506224516935
Validation loss: 2.509593405005232

Epoch: 6| Step: 11
Training loss: 0.21324369917412545
Validation loss: 2.4988881212491503

Epoch: 6| Step: 12
Training loss: 0.19803887074564433
Validation loss: 2.452823538356382

Epoch: 6| Step: 13
Training loss: 0.11803440199772375
Validation loss: 2.5358986937190378

Epoch: 522| Step: 0
Training loss: 0.20731216841260897
Validation loss: 2.5491559190112603

Epoch: 6| Step: 1
Training loss: 0.11135415559250599
Validation loss: 2.513705212576885

Epoch: 6| Step: 2
Training loss: 0.12556542722955552
Validation loss: 2.51617173067811

Epoch: 6| Step: 3
Training loss: 0.19655297221394313
Validation loss: 2.523028485690002

Epoch: 6| Step: 4
Training loss: 0.07928285310355182
Validation loss: 2.5231472955746845

Epoch: 6| Step: 5
Training loss: 0.07063610723279617
Validation loss: 2.505407709229664

Epoch: 6| Step: 6
Training loss: 0.18581194765975675
Validation loss: 2.53975723240419

Epoch: 6| Step: 7
Training loss: 0.13870406113094125
Validation loss: 2.5264633701202186

Epoch: 6| Step: 8
Training loss: 0.12043675502463551
Validation loss: 2.534747174156528

Epoch: 6| Step: 9
Training loss: 0.14338269602707915
Validation loss: 2.53227341519049

Epoch: 6| Step: 10
Training loss: 0.15105275135363017
Validation loss: 2.525458699785036

Epoch: 6| Step: 11
Training loss: 0.14594983800240022
Validation loss: 2.5115304800203253

Epoch: 6| Step: 12
Training loss: 0.0860232824560266
Validation loss: 2.4758973839965726

Epoch: 6| Step: 13
Training loss: 0.07606601695359419
Validation loss: 2.5174924736180504

Epoch: 523| Step: 0
Training loss: 0.15977192915251606
Validation loss: 2.498584732289466

Epoch: 6| Step: 1
Training loss: 0.09040812303222716
Validation loss: 2.4916318961450936

Epoch: 6| Step: 2
Training loss: 0.16806609083342228
Validation loss: 2.4922668493775326

Epoch: 6| Step: 3
Training loss: 0.08965391337639685
Validation loss: 2.5211456110151196

Epoch: 6| Step: 4
Training loss: 0.13250992472384152
Validation loss: 2.5186905574010874

Epoch: 6| Step: 5
Training loss: 0.10272709998418757
Validation loss: 2.5062454996904058

Epoch: 6| Step: 6
Training loss: 0.2106153978230494
Validation loss: 2.5240035676037302

Epoch: 6| Step: 7
Training loss: 0.09586973673711036
Validation loss: 2.5327688734535

Epoch: 6| Step: 8
Training loss: 0.09226722139338937
Validation loss: 2.500751360405527

Epoch: 6| Step: 9
Training loss: 0.21302489325020754
Validation loss: 2.4642089751314873

Epoch: 6| Step: 10
Training loss: 0.09326045050432766
Validation loss: 2.438151634519958

Epoch: 6| Step: 11
Training loss: 0.1216530113920909
Validation loss: 2.504510923960099

Epoch: 6| Step: 12
Training loss: 0.08071593944055284
Validation loss: 2.485788355169025

Epoch: 6| Step: 13
Training loss: 0.13673858498696356
Validation loss: 2.4547954363976836

Epoch: 524| Step: 0
Training loss: 0.10797390845434411
Validation loss: 2.4747023610757424

Epoch: 6| Step: 1
Training loss: 0.1270965939258239
Validation loss: 2.4993807343575143

Epoch: 6| Step: 2
Training loss: 0.18099152040245425
Validation loss: 2.474768467084798

Epoch: 6| Step: 3
Training loss: 0.09094742114556474
Validation loss: 2.5034623688719755

Epoch: 6| Step: 4
Training loss: 0.12771714003826695
Validation loss: 2.4950357823320632

Epoch: 6| Step: 5
Training loss: 0.1379283124087576
Validation loss: 2.4929624254019953

Epoch: 6| Step: 6
Training loss: 0.11403958354955572
Validation loss: 2.5293547658803894

Epoch: 6| Step: 7
Training loss: 0.17184529264513448
Validation loss: 2.4908880430340363

Epoch: 6| Step: 8
Training loss: 0.2045998218078807
Validation loss: 2.5237029048534274

Epoch: 6| Step: 9
Training loss: 0.1589473596920571
Validation loss: 2.4591963659024536

Epoch: 6| Step: 10
Training loss: 0.09574019434273254
Validation loss: 2.463723426483621

Epoch: 6| Step: 11
Training loss: 0.15960977526263045
Validation loss: 2.4708869733059777

Epoch: 6| Step: 12
Training loss: 0.09105162236124963
Validation loss: 2.4445662188083768

Epoch: 6| Step: 13
Training loss: 0.21562624530156208
Validation loss: 2.444727430606855

Epoch: 525| Step: 0
Training loss: 0.16071963656123653
Validation loss: 2.447389483493962

Epoch: 6| Step: 1
Training loss: 0.14453138531858967
Validation loss: 2.4352852514828185

Epoch: 6| Step: 2
Training loss: 0.2408263348818722
Validation loss: 2.4537240404657097

Epoch: 6| Step: 3
Training loss: 0.10382151841729122
Validation loss: 2.4487609440651315

Epoch: 6| Step: 4
Training loss: 0.10583526892875728
Validation loss: 2.4748620951211886

Epoch: 6| Step: 5
Training loss: 0.1282708227912329
Validation loss: 2.5237100323798423

Epoch: 6| Step: 6
Training loss: 0.11960545913420666
Validation loss: 2.558464664627495

Epoch: 6| Step: 7
Training loss: 0.130571682523087
Validation loss: 2.570463362940873

Epoch: 6| Step: 8
Training loss: 0.1804649080140009
Validation loss: 2.5422171351827485

Epoch: 6| Step: 9
Training loss: 0.1370198680387316
Validation loss: 2.5446208191238413

Epoch: 6| Step: 10
Training loss: 0.12998491590588868
Validation loss: 2.5398410413153183

Epoch: 6| Step: 11
Training loss: 0.13545413293704409
Validation loss: 2.51096650426344

Epoch: 6| Step: 12
Training loss: 0.18571910895284502
Validation loss: 2.492360874383947

Epoch: 6| Step: 13
Training loss: 0.06478575646689094
Validation loss: 2.5120839371932036

Epoch: 526| Step: 0
Training loss: 0.12700334435991206
Validation loss: 2.4961081062178914

Epoch: 6| Step: 1
Training loss: 0.1410624930779384
Validation loss: 2.5405667502283786

Epoch: 6| Step: 2
Training loss: 0.2005911844044602
Validation loss: 2.5088458192370577

Epoch: 6| Step: 3
Training loss: 0.12247478233450629
Validation loss: 2.521196749173535

Epoch: 6| Step: 4
Training loss: 0.07970705937649362
Validation loss: 2.541854039196015

Epoch: 6| Step: 5
Training loss: 0.12225406549427946
Validation loss: 2.520345014278201

Epoch: 6| Step: 6
Training loss: 0.11168763604420007
Validation loss: 2.5091024168693723

Epoch: 6| Step: 7
Training loss: 0.20803514041388793
Validation loss: 2.5487270530218056

Epoch: 6| Step: 8
Training loss: 0.12592210997452938
Validation loss: 2.5191724708262337

Epoch: 6| Step: 9
Training loss: 0.09073468755763793
Validation loss: 2.5108145639011057

Epoch: 6| Step: 10
Training loss: 0.11579252298845373
Validation loss: 2.508992373473231

Epoch: 6| Step: 11
Training loss: 0.1701750896557577
Validation loss: 2.4991791885116386

Epoch: 6| Step: 12
Training loss: 0.07899437223229072
Validation loss: 2.5143900546800846

Epoch: 6| Step: 13
Training loss: 0.12765282235277203
Validation loss: 2.5080324415853417

Epoch: 527| Step: 0
Training loss: 0.13015662279109988
Validation loss: 2.5322289365902813

Epoch: 6| Step: 1
Training loss: 0.09602295702447128
Validation loss: 2.527232210357819

Epoch: 6| Step: 2
Training loss: 0.19918692091446802
Validation loss: 2.5312634215409906

Epoch: 6| Step: 3
Training loss: 0.12860049486142933
Validation loss: 2.5151093604874446

Epoch: 6| Step: 4
Training loss: 0.13546627462604835
Validation loss: 2.533391976230965

Epoch: 6| Step: 5
Training loss: 0.1818418925915363
Validation loss: 2.50338963858758

Epoch: 6| Step: 6
Training loss: 0.1469440115455752
Validation loss: 2.5189306356165515

Epoch: 6| Step: 7
Training loss: 0.08953852221195555
Validation loss: 2.4977707686252497

Epoch: 6| Step: 8
Training loss: 0.19910398618387848
Validation loss: 2.503373439831243

Epoch: 6| Step: 9
Training loss: 0.10381287057271887
Validation loss: 2.491050486303885

Epoch: 6| Step: 10
Training loss: 0.14024392788792994
Validation loss: 2.5147162923350432

Epoch: 6| Step: 11
Training loss: 0.07308842731722322
Validation loss: 2.5018091557014115

Epoch: 6| Step: 12
Training loss: 0.11722556131883019
Validation loss: 2.5037771777898126

Epoch: 6| Step: 13
Training loss: 0.11335927643827522
Validation loss: 2.5044562175880056

Epoch: 528| Step: 0
Training loss: 0.1316398009322547
Validation loss: 2.515945451866215

Epoch: 6| Step: 1
Training loss: 0.09830455165690853
Validation loss: 2.47933362393638

Epoch: 6| Step: 2
Training loss: 0.18432078574692265
Validation loss: 2.4801947407059015

Epoch: 6| Step: 3
Training loss: 0.11083294515105559
Validation loss: 2.485347572654021

Epoch: 6| Step: 4
Training loss: 0.1580698488012136
Validation loss: 2.4850724965016533

Epoch: 6| Step: 5
Training loss: 0.20504480727075453
Validation loss: 2.4665699215912404

Epoch: 6| Step: 6
Training loss: 0.1412497523820445
Validation loss: 2.489876513149729

Epoch: 6| Step: 7
Training loss: 0.20239197071752754
Validation loss: 2.4925159638173873

Epoch: 6| Step: 8
Training loss: 0.11224803324826413
Validation loss: 2.473494919452659

Epoch: 6| Step: 9
Training loss: 0.14156735105602652
Validation loss: 2.4783388180758275

Epoch: 6| Step: 10
Training loss: 0.11544101985419727
Validation loss: 2.4726407363696015

Epoch: 6| Step: 11
Training loss: 0.12925486674544615
Validation loss: 2.4558784870005637

Epoch: 6| Step: 12
Training loss: 0.10163361553795935
Validation loss: 2.4949373955434453

Epoch: 6| Step: 13
Training loss: 0.1055993137361478
Validation loss: 2.478089255042421

Epoch: 529| Step: 0
Training loss: 0.13511803064582278
Validation loss: 2.516812492073191

Epoch: 6| Step: 1
Training loss: 0.17494449139594284
Validation loss: 2.4888938020662197

Epoch: 6| Step: 2
Training loss: 0.0990542764439295
Validation loss: 2.4692722150899353

Epoch: 6| Step: 3
Training loss: 0.22776051006552206
Validation loss: 2.484191094188982

Epoch: 6| Step: 4
Training loss: 0.2603975940713691
Validation loss: 2.510933573434958

Epoch: 6| Step: 5
Training loss: 0.10265764464123403
Validation loss: 2.461129932917546

Epoch: 6| Step: 6
Training loss: 0.1121999127459803
Validation loss: 2.4906061492789964

Epoch: 6| Step: 7
Training loss: 0.12610107744474708
Validation loss: 2.4611583323507036

Epoch: 6| Step: 8
Training loss: 0.12081813595078846
Validation loss: 2.4860148884926336

Epoch: 6| Step: 9
Training loss: 0.09929787323162582
Validation loss: 2.4528274637857748

Epoch: 6| Step: 10
Training loss: 0.11336439057841177
Validation loss: 2.4506620582812983

Epoch: 6| Step: 11
Training loss: 0.133151917948663
Validation loss: 2.4560403080087942

Epoch: 6| Step: 12
Training loss: 0.11369503021362466
Validation loss: 2.467139038698131

Epoch: 6| Step: 13
Training loss: 0.11517609722837381
Validation loss: 2.480391031406965

Epoch: 530| Step: 0
Training loss: 0.20111746191025248
Validation loss: 2.4876126809296055

Epoch: 6| Step: 1
Training loss: 0.1381551490865805
Validation loss: 2.4670621217036706

Epoch: 6| Step: 2
Training loss: 0.17349727090412392
Validation loss: 2.523840252345065

Epoch: 6| Step: 3
Training loss: 0.14724938583893601
Validation loss: 2.49523110177935

Epoch: 6| Step: 4
Training loss: 0.13621677480255806
Validation loss: 2.5181148779810947

Epoch: 6| Step: 5
Training loss: 0.14459575038636716
Validation loss: 2.4815923258186894

Epoch: 6| Step: 6
Training loss: 0.16663574078355012
Validation loss: 2.539748563629446

Epoch: 6| Step: 7
Training loss: 0.0593790497622209
Validation loss: 2.509666574537071

Epoch: 6| Step: 8
Training loss: 0.11471565329794436
Validation loss: 2.522374056459749

Epoch: 6| Step: 9
Training loss: 0.0825047733721335
Validation loss: 2.5454579411108313

Epoch: 6| Step: 10
Training loss: 0.15438673565539227
Validation loss: 2.5395689312363814

Epoch: 6| Step: 11
Training loss: 0.12195873501744842
Validation loss: 2.537466658146816

Epoch: 6| Step: 12
Training loss: 0.09176010044537229
Validation loss: 2.5427785926157767

Epoch: 6| Step: 13
Training loss: 0.21572014050378863
Validation loss: 2.5690749061097993

Epoch: 531| Step: 0
Training loss: 0.10785906000545858
Validation loss: 2.529056469135594

Epoch: 6| Step: 1
Training loss: 0.18705590624966478
Validation loss: 2.574062220096266

Epoch: 6| Step: 2
Training loss: 0.1450479909797827
Validation loss: 2.5435051088150087

Epoch: 6| Step: 3
Training loss: 0.1319380117787745
Validation loss: 2.4944478268003607

Epoch: 6| Step: 4
Training loss: 0.15471842678208125
Validation loss: 2.4967683190679315

Epoch: 6| Step: 5
Training loss: 0.1606475458760881
Validation loss: 2.519220891255649

Epoch: 6| Step: 6
Training loss: 0.1233457462713671
Validation loss: 2.480558159130585

Epoch: 6| Step: 7
Training loss: 0.10020416919610908
Validation loss: 2.5133236805824666

Epoch: 6| Step: 8
Training loss: 0.1141143615606751
Validation loss: 2.5031154355704475

Epoch: 6| Step: 9
Training loss: 0.21839989165147952
Validation loss: 2.4928133902500287

Epoch: 6| Step: 10
Training loss: 0.11670266629158402
Validation loss: 2.5136180962160095

Epoch: 6| Step: 11
Training loss: 0.13218229502267032
Validation loss: 2.479358301350637

Epoch: 6| Step: 12
Training loss: 0.10110301837561204
Validation loss: 2.499525754308031

Epoch: 6| Step: 13
Training loss: 0.12225326560930347
Validation loss: 2.4856283264444015

Epoch: 532| Step: 0
Training loss: 0.20684048122641974
Validation loss: 2.493255141724297

Epoch: 6| Step: 1
Training loss: 0.06649904569433193
Validation loss: 2.503003530143751

Epoch: 6| Step: 2
Training loss: 0.13915377819770902
Validation loss: 2.4861427746306988

Epoch: 6| Step: 3
Training loss: 0.1860918174021932
Validation loss: 2.483786559372037

Epoch: 6| Step: 4
Training loss: 0.18849957775263457
Validation loss: 2.4496103585901006

Epoch: 6| Step: 5
Training loss: 0.17477980495219048
Validation loss: 2.4785063458722187

Epoch: 6| Step: 6
Training loss: 0.12115244442770916
Validation loss: 2.5042585250187095

Epoch: 6| Step: 7
Training loss: 0.13646831736791967
Validation loss: 2.510389379850797

Epoch: 6| Step: 8
Training loss: 0.12889122875431536
Validation loss: 2.5150851531128438

Epoch: 6| Step: 9
Training loss: 0.11847932390365018
Validation loss: 2.5310003136476915

Epoch: 6| Step: 10
Training loss: 0.12059108169551432
Validation loss: 2.503277832468384

Epoch: 6| Step: 11
Training loss: 0.1051527694137462
Validation loss: 2.531573567737285

Epoch: 6| Step: 12
Training loss: 0.10901465405516621
Validation loss: 2.548830971444951

Epoch: 6| Step: 13
Training loss: 0.10151406196787177
Validation loss: 2.5634681529479955

Epoch: 533| Step: 0
Training loss: 0.12807428763629128
Validation loss: 2.5797096083594995

Epoch: 6| Step: 1
Training loss: 0.09842016411823586
Validation loss: 2.56731111465561

Epoch: 6| Step: 2
Training loss: 0.10010608079395474
Validation loss: 2.5379573646452043

Epoch: 6| Step: 3
Training loss: 0.1861690129785662
Validation loss: 2.5427775108121957

Epoch: 6| Step: 4
Training loss: 0.1378513696355165
Validation loss: 2.5363268269302983

Epoch: 6| Step: 5
Training loss: 0.18664719435514276
Validation loss: 2.5331061518259315

Epoch: 6| Step: 6
Training loss: 0.13209600581735323
Validation loss: 2.4987290730717064

Epoch: 6| Step: 7
Training loss: 0.14802511553528705
Validation loss: 2.499445425070783

Epoch: 6| Step: 8
Training loss: 0.08601594454959757
Validation loss: 2.5397206271205066

Epoch: 6| Step: 9
Training loss: 0.10513775154781443
Validation loss: 2.5324845224849435

Epoch: 6| Step: 10
Training loss: 0.10985749971224007
Validation loss: 2.518941122486554

Epoch: 6| Step: 11
Training loss: 0.16938016307358622
Validation loss: 2.53511429550399

Epoch: 6| Step: 12
Training loss: 0.13376841420573202
Validation loss: 2.532525386786111

Epoch: 6| Step: 13
Training loss: 0.11759680159251408
Validation loss: 2.5038069155217846

Epoch: 534| Step: 0
Training loss: 0.11643767876670207
Validation loss: 2.5138501159567155

Epoch: 6| Step: 1
Training loss: 0.12314700034174826
Validation loss: 2.4869424260694215

Epoch: 6| Step: 2
Training loss: 0.174169227164519
Validation loss: 2.4754756282786

Epoch: 6| Step: 3
Training loss: 0.1002754771906013
Validation loss: 2.4983709421568134

Epoch: 6| Step: 4
Training loss: 0.23816487331418165
Validation loss: 2.4996938733363083

Epoch: 6| Step: 5
Training loss: 0.14198628482854414
Validation loss: 2.492172343003261

Epoch: 6| Step: 6
Training loss: 0.10326171269641365
Validation loss: 2.4914162108010234

Epoch: 6| Step: 7
Training loss: 0.11020251141399923
Validation loss: 2.500695133985321

Epoch: 6| Step: 8
Training loss: 0.15931278351376532
Validation loss: 2.520669634012533

Epoch: 6| Step: 9
Training loss: 0.1369835265146274
Validation loss: 2.5171850156218967

Epoch: 6| Step: 10
Training loss: 0.12085368217001688
Validation loss: 2.5367020926600414

Epoch: 6| Step: 11
Training loss: 0.11382697460245167
Validation loss: 2.520520038165619

Epoch: 6| Step: 12
Training loss: 0.1101590731103468
Validation loss: 2.5624540551461426

Epoch: 6| Step: 13
Training loss: 0.17934137677199288
Validation loss: 2.548250717762633

Epoch: 535| Step: 0
Training loss: 0.11615990071002881
Validation loss: 2.5724490034916276

Epoch: 6| Step: 1
Training loss: 0.10545228017145568
Validation loss: 2.560498560239246

Epoch: 6| Step: 2
Training loss: 0.067916631858886
Validation loss: 2.5636465857434305

Epoch: 6| Step: 3
Training loss: 0.09511133583288625
Validation loss: 2.5283190369255735

Epoch: 6| Step: 4
Training loss: 0.21342315913288204
Validation loss: 2.526583596797836

Epoch: 6| Step: 5
Training loss: 0.12065071925035038
Validation loss: 2.508542899792217

Epoch: 6| Step: 6
Training loss: 0.10011591395901318
Validation loss: 2.5080583955490736

Epoch: 6| Step: 7
Training loss: 0.10337935781461338
Validation loss: 2.5380123751658203

Epoch: 6| Step: 8
Training loss: 0.10310529860236611
Validation loss: 2.5273717015957042

Epoch: 6| Step: 9
Training loss: 0.11969487842919072
Validation loss: 2.5533004753056256

Epoch: 6| Step: 10
Training loss: 0.17338310024340903
Validation loss: 2.5463946234382626

Epoch: 6| Step: 11
Training loss: 0.09863131115969932
Validation loss: 2.560038184652191

Epoch: 6| Step: 12
Training loss: 0.16698749714114722
Validation loss: 2.518002539587087

Epoch: 6| Step: 13
Training loss: 0.14691632480801547
Validation loss: 2.541980410018998

Epoch: 536| Step: 0
Training loss: 0.08927568928602826
Validation loss: 2.549008895101862

Epoch: 6| Step: 1
Training loss: 0.164919256707265
Validation loss: 2.525891653481562

Epoch: 6| Step: 2
Training loss: 0.12626470835385692
Validation loss: 2.529285133173973

Epoch: 6| Step: 3
Training loss: 0.08509247287988952
Validation loss: 2.517416556915454

Epoch: 6| Step: 4
Training loss: 0.06960234034920701
Validation loss: 2.5418089445715997

Epoch: 6| Step: 5
Training loss: 0.09265260858922905
Validation loss: 2.523640699531801

Epoch: 6| Step: 6
Training loss: 0.06444477258373536
Validation loss: 2.512509819627459

Epoch: 6| Step: 7
Training loss: 0.12510407853447666
Validation loss: 2.525229369972494

Epoch: 6| Step: 8
Training loss: 0.08577468469124569
Validation loss: 2.5386664034435475

Epoch: 6| Step: 9
Training loss: 0.19286868902711235
Validation loss: 2.506677011110923

Epoch: 6| Step: 10
Training loss: 0.11982509718419851
Validation loss: 2.5186096087953924

Epoch: 6| Step: 11
Training loss: 0.10404838810708575
Validation loss: 2.5497763524192063

Epoch: 6| Step: 12
Training loss: 0.09587297159720012
Validation loss: 2.535291968362336

Epoch: 6| Step: 13
Training loss: 0.20303581187105332
Validation loss: 2.5254390754319127

Epoch: 537| Step: 0
Training loss: 0.10047503718671849
Validation loss: 2.5234163797034976

Epoch: 6| Step: 1
Training loss: 0.21023086230215077
Validation loss: 2.540006362243996

Epoch: 6| Step: 2
Training loss: 0.12873851092936428
Validation loss: 2.534878713291153

Epoch: 6| Step: 3
Training loss: 0.08534059977889531
Validation loss: 2.5316541732164635

Epoch: 6| Step: 4
Training loss: 0.11708888036794501
Validation loss: 2.4995411933821186

Epoch: 6| Step: 5
Training loss: 0.13481404637071923
Validation loss: 2.5454394962235884

Epoch: 6| Step: 6
Training loss: 0.08976875160290056
Validation loss: 2.516944825902704

Epoch: 6| Step: 7
Training loss: 0.20133722787276065
Validation loss: 2.5272324457001023

Epoch: 6| Step: 8
Training loss: 0.09487694179139766
Validation loss: 2.5319961279689283

Epoch: 6| Step: 9
Training loss: 0.10993306804515426
Validation loss: 2.5311331206085006

Epoch: 6| Step: 10
Training loss: 0.10625166295657547
Validation loss: 2.5256764059783983

Epoch: 6| Step: 11
Training loss: 0.17004598272654373
Validation loss: 2.5682464723270604

Epoch: 6| Step: 12
Training loss: 0.09042530914319184
Validation loss: 2.537946061381015

Epoch: 6| Step: 13
Training loss: 0.06992572462150898
Validation loss: 2.534545583203644

Epoch: 538| Step: 0
Training loss: 0.1634841728034196
Validation loss: 2.5431427768567643

Epoch: 6| Step: 1
Training loss: 0.1222420628607312
Validation loss: 2.5291337292297915

Epoch: 6| Step: 2
Training loss: 0.10901380401387348
Validation loss: 2.549363953979916

Epoch: 6| Step: 3
Training loss: 0.1661109089892234
Validation loss: 2.5327011722915715

Epoch: 6| Step: 4
Training loss: 0.11631860874083
Validation loss: 2.5213870375443475

Epoch: 6| Step: 5
Training loss: 0.0771729032135561
Validation loss: 2.551404623089829

Epoch: 6| Step: 6
Training loss: 0.15140906339182925
Validation loss: 2.516631694195668

Epoch: 6| Step: 7
Training loss: 0.11150967284202007
Validation loss: 2.5469005026548017

Epoch: 6| Step: 8
Training loss: 0.10212996937703081
Validation loss: 2.536325593791768

Epoch: 6| Step: 9
Training loss: 0.10416185894441203
Validation loss: 2.501419359725747

Epoch: 6| Step: 10
Training loss: 0.10720000328953136
Validation loss: 2.533602303273491

Epoch: 6| Step: 11
Training loss: 0.24436547415672447
Validation loss: 2.517373008336879

Epoch: 6| Step: 12
Training loss: 0.20266512016819482
Validation loss: 2.490662922282731

Epoch: 6| Step: 13
Training loss: 0.12325251516364083
Validation loss: 2.4713618640815875

Epoch: 539| Step: 0
Training loss: 0.21086158976004785
Validation loss: 2.491687312609769

Epoch: 6| Step: 1
Training loss: 0.17654026195275482
Validation loss: 2.5251989956918908

Epoch: 6| Step: 2
Training loss: 0.13869999210978873
Validation loss: 2.4878313000296095

Epoch: 6| Step: 3
Training loss: 0.24688841415129031
Validation loss: 2.476736498221847

Epoch: 6| Step: 4
Training loss: 0.08010592792089383
Validation loss: 2.509658104191154

Epoch: 6| Step: 5
Training loss: 0.1782778928676333
Validation loss: 2.5228473919811303

Epoch: 6| Step: 6
Training loss: 0.1500581807313692
Validation loss: 2.52927707872314

Epoch: 6| Step: 7
Training loss: 0.17104598079596456
Validation loss: 2.554249598795409

Epoch: 6| Step: 8
Training loss: 0.15989558593179987
Validation loss: 2.565458780032529

Epoch: 6| Step: 9
Training loss: 0.19858516658058695
Validation loss: 2.5790969716824126

Epoch: 6| Step: 10
Training loss: 0.1470272305067879
Validation loss: 2.554734607081713

Epoch: 6| Step: 11
Training loss: 0.13346380528369703
Validation loss: 2.510596917874397

Epoch: 6| Step: 12
Training loss: 0.10964894898352733
Validation loss: 2.5036546497141146

Epoch: 6| Step: 13
Training loss: 0.13622024114903583
Validation loss: 2.4485153237703075

Epoch: 540| Step: 0
Training loss: 0.13246336092991767
Validation loss: 2.461502233849791

Epoch: 6| Step: 1
Training loss: 0.16262408777717052
Validation loss: 2.479234960423168

Epoch: 6| Step: 2
Training loss: 0.15502550015343466
Validation loss: 2.4500292976959828

Epoch: 6| Step: 3
Training loss: 0.19389634757996543
Validation loss: 2.448919091977364

Epoch: 6| Step: 4
Training loss: 0.11965433356527984
Validation loss: 2.4582996498193252

Epoch: 6| Step: 5
Training loss: 0.09657267225258782
Validation loss: 2.4946562507010404

Epoch: 6| Step: 6
Training loss: 0.12227046198311058
Validation loss: 2.4709018515648493

Epoch: 6| Step: 7
Training loss: 0.19911152628185702
Validation loss: 2.5242839381492925

Epoch: 6| Step: 8
Training loss: 0.161700445327871
Validation loss: 2.5170097781623824

Epoch: 6| Step: 9
Training loss: 0.08095327605590687
Validation loss: 2.4950071304265102

Epoch: 6| Step: 10
Training loss: 0.19823312973601925
Validation loss: 2.5296868678678956

Epoch: 6| Step: 11
Training loss: 0.10220520983792854
Validation loss: 2.502860578972431

Epoch: 6| Step: 12
Training loss: 0.13735358126001726
Validation loss: 2.5217230770812638

Epoch: 6| Step: 13
Training loss: 0.0687379741175166
Validation loss: 2.507954962431204

Epoch: 541| Step: 0
Training loss: 0.0812195027179998
Validation loss: 2.518104329639361

Epoch: 6| Step: 1
Training loss: 0.1292457733127266
Validation loss: 2.506660687347935

Epoch: 6| Step: 2
Training loss: 0.11813377354727134
Validation loss: 2.503480729806258

Epoch: 6| Step: 3
Training loss: 0.13887710562696884
Validation loss: 2.5104988682769926

Epoch: 6| Step: 4
Training loss: 0.06609990479059187
Validation loss: 2.528675424427101

Epoch: 6| Step: 5
Training loss: 0.12260320694946696
Validation loss: 2.5247949502138054

Epoch: 6| Step: 6
Training loss: 0.10830427496101704
Validation loss: 2.5434708585755765

Epoch: 6| Step: 7
Training loss: 0.1693692593639818
Validation loss: 2.5355646309578996

Epoch: 6| Step: 8
Training loss: 0.23458357113633602
Validation loss: 2.592080448849782

Epoch: 6| Step: 9
Training loss: 0.10965442302064635
Validation loss: 2.540270010265382

Epoch: 6| Step: 10
Training loss: 0.11043219447790205
Validation loss: 2.5789793615628045

Epoch: 6| Step: 11
Training loss: 0.11355445653802028
Validation loss: 2.5707182798456194

Epoch: 6| Step: 12
Training loss: 0.21348249770950553
Validation loss: 2.597815736890457

Epoch: 6| Step: 13
Training loss: 0.08353142241900081
Validation loss: 2.554658683199631

Epoch: 542| Step: 0
Training loss: 0.1689636242595086
Validation loss: 2.570599902925049

Epoch: 6| Step: 1
Training loss: 0.07226272525640068
Validation loss: 2.5794890801515336

Epoch: 6| Step: 2
Training loss: 0.16939081317028007
Validation loss: 2.568237648165363

Epoch: 6| Step: 3
Training loss: 0.14256938489488533
Validation loss: 2.532880807942488

Epoch: 6| Step: 4
Training loss: 0.10926889910211827
Validation loss: 2.5353061683460356

Epoch: 6| Step: 5
Training loss: 0.16228246066124657
Validation loss: 2.53966276861978

Epoch: 6| Step: 6
Training loss: 0.11234194510711805
Validation loss: 2.529496347975381

Epoch: 6| Step: 7
Training loss: 0.15926154787474955
Validation loss: 2.5392145603230603

Epoch: 6| Step: 8
Training loss: 0.16137082987146442
Validation loss: 2.553627402584913

Epoch: 6| Step: 9
Training loss: 0.19540969337664016
Validation loss: 2.5551469288201485

Epoch: 6| Step: 10
Training loss: 0.0799515642841681
Validation loss: 2.5344944099214417

Epoch: 6| Step: 11
Training loss: 0.09926010587820884
Validation loss: 2.5648931307900487

Epoch: 6| Step: 12
Training loss: 0.12510453264096633
Validation loss: 2.5536078039604275

Epoch: 6| Step: 13
Training loss: 0.09859055850974016
Validation loss: 2.5245095728867324

Epoch: 543| Step: 0
Training loss: 0.07721615487233802
Validation loss: 2.5171999013217974

Epoch: 6| Step: 1
Training loss: 0.14157768574372764
Validation loss: 2.507377551269915

Epoch: 6| Step: 2
Training loss: 0.10584809816831832
Validation loss: 2.4856562407320917

Epoch: 6| Step: 3
Training loss: 0.09185932956752182
Validation loss: 2.5218563995425596

Epoch: 6| Step: 4
Training loss: 0.11688430027498989
Validation loss: 2.5149055027309744

Epoch: 6| Step: 5
Training loss: 0.11216445543385492
Validation loss: 2.491552060439279

Epoch: 6| Step: 6
Training loss: 0.1949398491165381
Validation loss: 2.475049974474167

Epoch: 6| Step: 7
Training loss: 0.1669515203292624
Validation loss: 2.5318599104377904

Epoch: 6| Step: 8
Training loss: 0.12661975960511881
Validation loss: 2.4982408589688387

Epoch: 6| Step: 9
Training loss: 0.09446580627383884
Validation loss: 2.5033238833567912

Epoch: 6| Step: 10
Training loss: 0.16839191449795365
Validation loss: 2.491485843592193

Epoch: 6| Step: 11
Training loss: 0.11956083735622573
Validation loss: 2.49553210627044

Epoch: 6| Step: 12
Training loss: 0.07578055415866362
Validation loss: 2.4863355880548093

Epoch: 6| Step: 13
Training loss: 0.08388132049101958
Validation loss: 2.4632849255238805

Epoch: 544| Step: 0
Training loss: 0.1557615154587905
Validation loss: 2.5021869999393775

Epoch: 6| Step: 1
Training loss: 0.21756265472257572
Validation loss: 2.4864405262556537

Epoch: 6| Step: 2
Training loss: 0.11699941959858662
Validation loss: 2.495808703231699

Epoch: 6| Step: 3
Training loss: 0.10306275468798294
Validation loss: 2.49019203325371

Epoch: 6| Step: 4
Training loss: 0.14978982386651465
Validation loss: 2.476629394298595

Epoch: 6| Step: 5
Training loss: 0.12368594078181834
Validation loss: 2.526142949436704

Epoch: 6| Step: 6
Training loss: 0.09682240692836927
Validation loss: 2.5243785417466094

Epoch: 6| Step: 7
Training loss: 0.12743731378875642
Validation loss: 2.503149081703954

Epoch: 6| Step: 8
Training loss: 0.14656149423616097
Validation loss: 2.476638348182233

Epoch: 6| Step: 9
Training loss: 0.10187822564992031
Validation loss: 2.4984831238213956

Epoch: 6| Step: 10
Training loss: 0.14560070528954072
Validation loss: 2.5318873646326443

Epoch: 6| Step: 11
Training loss: 0.07129106453475095
Validation loss: 2.5068830428185933

Epoch: 6| Step: 12
Training loss: 0.10919126763118539
Validation loss: 2.5139584140125963

Epoch: 6| Step: 13
Training loss: 0.06055562086927692
Validation loss: 2.5115106468012494

Epoch: 545| Step: 0
Training loss: 0.04834080704779219
Validation loss: 2.5048439044445687

Epoch: 6| Step: 1
Training loss: 0.1088018300288009
Validation loss: 2.5070927122095203

Epoch: 6| Step: 2
Training loss: 0.08919078472132906
Validation loss: 2.5469063354855486

Epoch: 6| Step: 3
Training loss: 0.10577719232673813
Validation loss: 2.5006613799957034

Epoch: 6| Step: 4
Training loss: 0.08441160178580791
Validation loss: 2.5141916759129628

Epoch: 6| Step: 5
Training loss: 0.0773840066152347
Validation loss: 2.535142774742181

Epoch: 6| Step: 6
Training loss: 0.16896697550456163
Validation loss: 2.51904837224471

Epoch: 6| Step: 7
Training loss: 0.08628473248546717
Validation loss: 2.5257012365673206

Epoch: 6| Step: 8
Training loss: 0.10437350797443377
Validation loss: 2.5234551791848667

Epoch: 6| Step: 9
Training loss: 0.10648889261963486
Validation loss: 2.4995576897935496

Epoch: 6| Step: 10
Training loss: 0.17530332869409376
Validation loss: 2.493269675718094

Epoch: 6| Step: 11
Training loss: 0.19062589660808887
Validation loss: 2.4771759938903672

Epoch: 6| Step: 12
Training loss: 0.14891938367766364
Validation loss: 2.4935932909064507

Epoch: 6| Step: 13
Training loss: 0.09270549092953831
Validation loss: 2.502827546612132

Epoch: 546| Step: 0
Training loss: 0.1403533377828419
Validation loss: 2.497234518700625

Epoch: 6| Step: 1
Training loss: 0.14344746614252973
Validation loss: 2.4954268908411974

Epoch: 6| Step: 2
Training loss: 0.08533368065187961
Validation loss: 2.498225952657929

Epoch: 6| Step: 3
Training loss: 0.11430554737739887
Validation loss: 2.530691906957072

Epoch: 6| Step: 4
Training loss: 0.08429506961950363
Validation loss: 2.5091262753167056

Epoch: 6| Step: 5
Training loss: 0.0960541971340748
Validation loss: 2.4826868582459642

Epoch: 6| Step: 6
Training loss: 0.10344775692140586
Validation loss: 2.503720403937477

Epoch: 6| Step: 7
Training loss: 0.09655904949683616
Validation loss: 2.4819577118151765

Epoch: 6| Step: 8
Training loss: 0.10824154333599573
Validation loss: 2.4914669229938196

Epoch: 6| Step: 9
Training loss: 0.0873083642957689
Validation loss: 2.4948941584644007

Epoch: 6| Step: 10
Training loss: 0.08385302007771889
Validation loss: 2.5126454878883897

Epoch: 6| Step: 11
Training loss: 0.23140358045636444
Validation loss: 2.5256781142755185

Epoch: 6| Step: 12
Training loss: 0.08296623310574763
Validation loss: 2.5239081200898186

Epoch: 6| Step: 13
Training loss: 0.2078454095553095
Validation loss: 2.519146653883054

Epoch: 547| Step: 0
Training loss: 0.06505052820586092
Validation loss: 2.526895700968365

Epoch: 6| Step: 1
Training loss: 0.19050735454805423
Validation loss: 2.5390100486013805

Epoch: 6| Step: 2
Training loss: 0.17063071943485428
Validation loss: 2.5255970658247713

Epoch: 6| Step: 3
Training loss: 0.08566159694896452
Validation loss: 2.482574078442761

Epoch: 6| Step: 4
Training loss: 0.11488527825182582
Validation loss: 2.4977261641759885

Epoch: 6| Step: 5
Training loss: 0.07771467996902637
Validation loss: 2.506860181581453

Epoch: 6| Step: 6
Training loss: 0.12016586154895315
Validation loss: 2.498275350636803

Epoch: 6| Step: 7
Training loss: 0.13989740466567785
Validation loss: 2.5073364601316106

Epoch: 6| Step: 8
Training loss: 0.15055363972960292
Validation loss: 2.498809738250682

Epoch: 6| Step: 9
Training loss: 0.11307267191927917
Validation loss: 2.5053219047507116

Epoch: 6| Step: 10
Training loss: 0.09078016213997964
Validation loss: 2.4963676973363547

Epoch: 6| Step: 11
Training loss: 0.06543590388018326
Validation loss: 2.5166455958191336

Epoch: 6| Step: 12
Training loss: 0.1596965705848526
Validation loss: 2.525130428361876

Epoch: 6| Step: 13
Training loss: 0.04960547604595719
Validation loss: 2.5007602022927062

Epoch: 548| Step: 0
Training loss: 0.06091543281024659
Validation loss: 2.5161577579174805

Epoch: 6| Step: 1
Training loss: 0.15420888854733986
Validation loss: 2.507996319937469

Epoch: 6| Step: 2
Training loss: 0.09676585066652155
Validation loss: 2.491451389639024

Epoch: 6| Step: 3
Training loss: 0.11265316675916545
Validation loss: 2.513611017075891

Epoch: 6| Step: 4
Training loss: 0.09720379442126412
Validation loss: 2.4992465616908572

Epoch: 6| Step: 5
Training loss: 0.14264070757319142
Validation loss: 2.446392136685855

Epoch: 6| Step: 6
Training loss: 0.09005063534917054
Validation loss: 2.508807284819401

Epoch: 6| Step: 7
Training loss: 0.1735524981951126
Validation loss: 2.4679458407114336

Epoch: 6| Step: 8
Training loss: 0.08891647146025386
Validation loss: 2.487332757159284

Epoch: 6| Step: 9
Training loss: 0.09988708211719259
Validation loss: 2.4525596228919087

Epoch: 6| Step: 10
Training loss: 0.12354050877249886
Validation loss: 2.440281895205088

Epoch: 6| Step: 11
Training loss: 0.08518789385888562
Validation loss: 2.4843990855933646

Epoch: 6| Step: 12
Training loss: 0.19205530241027646
Validation loss: 2.495934290599393

Epoch: 6| Step: 13
Training loss: 0.06996567608916085
Validation loss: 2.49624722876933

Epoch: 549| Step: 0
Training loss: 0.08015570720317794
Validation loss: 2.4963707073200925

Epoch: 6| Step: 1
Training loss: 0.17992043945561387
Validation loss: 2.5328988797128247

Epoch: 6| Step: 2
Training loss: 0.10989108263688223
Validation loss: 2.5071442893621816

Epoch: 6| Step: 3
Training loss: 0.12679304153561108
Validation loss: 2.508483894982482

Epoch: 6| Step: 4
Training loss: 0.11324579818695964
Validation loss: 2.541174313569831

Epoch: 6| Step: 5
Training loss: 0.12037134419021661
Validation loss: 2.518571730167426

Epoch: 6| Step: 6
Training loss: 0.22074093115075585
Validation loss: 2.509806213650812

Epoch: 6| Step: 7
Training loss: 0.09195970743452195
Validation loss: 2.471826280790715

Epoch: 6| Step: 8
Training loss: 0.10866709229004672
Validation loss: 2.4828202943742714

Epoch: 6| Step: 9
Training loss: 0.07627638347679819
Validation loss: 2.500180483015022

Epoch: 6| Step: 10
Training loss: 0.07813812979993748
Validation loss: 2.483434737434438

Epoch: 6| Step: 11
Training loss: 0.10871821567270323
Validation loss: 2.458575027400632

Epoch: 6| Step: 12
Training loss: 0.09977099452732904
Validation loss: 2.481325177936586

Epoch: 6| Step: 13
Training loss: 0.13739160768254444
Validation loss: 2.497977379945367

Epoch: 550| Step: 0
Training loss: 0.13821189105372467
Validation loss: 2.5122113973419626

Epoch: 6| Step: 1
Training loss: 0.08414924595569925
Validation loss: 2.5411702852648395

Epoch: 6| Step: 2
Training loss: 0.07095627645463332
Validation loss: 2.514477866138588

Epoch: 6| Step: 3
Training loss: 0.21440058865486386
Validation loss: 2.5371494969099313

Epoch: 6| Step: 4
Training loss: 0.09293470921523826
Validation loss: 2.5255292005789474

Epoch: 6| Step: 5
Training loss: 0.08214213052755531
Validation loss: 2.5148568845318486

Epoch: 6| Step: 6
Training loss: 0.10592218784213485
Validation loss: 2.5099854435719444

Epoch: 6| Step: 7
Training loss: 0.07972859066519307
Validation loss: 2.490428834448925

Epoch: 6| Step: 8
Training loss: 0.12131212525086299
Validation loss: 2.5209586841927107

Epoch: 6| Step: 9
Training loss: 0.16765252553601592
Validation loss: 2.489111341529697

Epoch: 6| Step: 10
Training loss: 0.18640334572332198
Validation loss: 2.499521673240093

Epoch: 6| Step: 11
Training loss: 0.18240203014313733
Validation loss: 2.4992663824769803

Epoch: 6| Step: 12
Training loss: 0.1461692854480133
Validation loss: 2.502291900386603

Epoch: 6| Step: 13
Training loss: 0.07732076351484811
Validation loss: 2.4796640431981993

Epoch: 551| Step: 0
Training loss: 0.11754486114052633
Validation loss: 2.4653533096293234

Epoch: 6| Step: 1
Training loss: 0.16548704821531207
Validation loss: 2.4556095794180273

Epoch: 6| Step: 2
Training loss: 0.1208629485195666
Validation loss: 2.467837333075197

Epoch: 6| Step: 3
Training loss: 0.13031792002779477
Validation loss: 2.481613323763661

Epoch: 6| Step: 4
Training loss: 0.1699137411692008
Validation loss: 2.4761901261865966

Epoch: 6| Step: 5
Training loss: 0.1403005685491081
Validation loss: 2.488458034567587

Epoch: 6| Step: 6
Training loss: 0.09141582169913094
Validation loss: 2.493684049635781

Epoch: 6| Step: 7
Training loss: 0.0990828642386221
Validation loss: 2.485822488497953

Epoch: 6| Step: 8
Training loss: 0.119132244878499
Validation loss: 2.4878863977298673

Epoch: 6| Step: 9
Training loss: 0.0942244544287221
Validation loss: 2.4816161155905965

Epoch: 6| Step: 10
Training loss: 0.11371494178706158
Validation loss: 2.5069641589007103

Epoch: 6| Step: 11
Training loss: 0.1488398382128171
Validation loss: 2.5212630520328014

Epoch: 6| Step: 12
Training loss: 0.06479142732259162
Validation loss: 2.5311617535200823

Epoch: 6| Step: 13
Training loss: 0.21153093678714277
Validation loss: 2.4921513728178737

Epoch: 552| Step: 0
Training loss: 0.0770230179193028
Validation loss: 2.514035351879934

Epoch: 6| Step: 1
Training loss: 0.1588365214089764
Validation loss: 2.5403574842017203

Epoch: 6| Step: 2
Training loss: 0.17305023284823148
Validation loss: 2.5463725800541956

Epoch: 6| Step: 3
Training loss: 0.1846171122966447
Validation loss: 2.5299053106957934

Epoch: 6| Step: 4
Training loss: 0.055101158520293826
Validation loss: 2.5398600391112347

Epoch: 6| Step: 5
Training loss: 0.09416851861136265
Validation loss: 2.5174587951498504

Epoch: 6| Step: 6
Training loss: 0.06661675900683514
Validation loss: 2.488957845551272

Epoch: 6| Step: 7
Training loss: 0.07980710781682601
Validation loss: 2.4924735055188956

Epoch: 6| Step: 8
Training loss: 0.13227649123591867
Validation loss: 2.4903548647230584

Epoch: 6| Step: 9
Training loss: 0.11781994706302021
Validation loss: 2.511379139818106

Epoch: 6| Step: 10
Training loss: 0.07935072369464073
Validation loss: 2.4799428834401365

Epoch: 6| Step: 11
Training loss: 0.07707464636630448
Validation loss: 2.5097410458503595

Epoch: 6| Step: 12
Training loss: 0.07651543167904656
Validation loss: 2.5049256069785737

Epoch: 6| Step: 13
Training loss: 0.20369753478042152
Validation loss: 2.4778255658975423

Epoch: 553| Step: 0
Training loss: 0.06257647068061047
Validation loss: 2.484325680611126

Epoch: 6| Step: 1
Training loss: 0.11579561147024912
Validation loss: 2.486683891268842

Epoch: 6| Step: 2
Training loss: 0.17488851082528578
Validation loss: 2.522743516993844

Epoch: 6| Step: 3
Training loss: 0.10101428074543423
Validation loss: 2.5174053620402588

Epoch: 6| Step: 4
Training loss: 0.07009241309317478
Validation loss: 2.495111623781555

Epoch: 6| Step: 5
Training loss: 0.08343568925821508
Validation loss: 2.4771980093164148

Epoch: 6| Step: 6
Training loss: 0.07314946345162168
Validation loss: 2.4796350136185112

Epoch: 6| Step: 7
Training loss: 0.20158579750855984
Validation loss: 2.498235443306826

Epoch: 6| Step: 8
Training loss: 0.06342714293265105
Validation loss: 2.49525996173102

Epoch: 6| Step: 9
Training loss: 0.10074758503370611
Validation loss: 2.494087812721053

Epoch: 6| Step: 10
Training loss: 0.06471388261552999
Validation loss: 2.5221794871197214

Epoch: 6| Step: 11
Training loss: 0.10819146871614896
Validation loss: 2.4939828961360018

Epoch: 6| Step: 12
Training loss: 0.11376978501713164
Validation loss: 2.4771129787874875

Epoch: 6| Step: 13
Training loss: 0.16354332817250075
Validation loss: 2.5287645788440942

Epoch: 554| Step: 0
Training loss: 0.0882191293875833
Validation loss: 2.4745505473314133

Epoch: 6| Step: 1
Training loss: 0.16234924196053685
Validation loss: 2.5006721351888235

Epoch: 6| Step: 2
Training loss: 0.0990112711036626
Validation loss: 2.5067261269861594

Epoch: 6| Step: 3
Training loss: 0.18543719011119514
Validation loss: 2.5204815322037284

Epoch: 6| Step: 4
Training loss: 0.1480359682378492
Validation loss: 2.5280094852633015

Epoch: 6| Step: 5
Training loss: 0.09309875770582798
Validation loss: 2.5187996763363105

Epoch: 6| Step: 6
Training loss: 0.07600741176889722
Validation loss: 2.4945591366429745

Epoch: 6| Step: 7
Training loss: 0.061451953655149244
Validation loss: 2.476921712042876

Epoch: 6| Step: 8
Training loss: 0.11229581383187434
Validation loss: 2.4732452076334015

Epoch: 6| Step: 9
Training loss: 0.11040654121012847
Validation loss: 2.460905202929403

Epoch: 6| Step: 10
Training loss: 0.08646822280605891
Validation loss: 2.4419554615789827

Epoch: 6| Step: 11
Training loss: 0.19728302642817677
Validation loss: 2.445352021878569

Epoch: 6| Step: 12
Training loss: 0.09973029669446905
Validation loss: 2.4548776752148083

Epoch: 6| Step: 13
Training loss: 0.16011323583807427
Validation loss: 2.4628270374990664

Epoch: 555| Step: 0
Training loss: 0.1514619530623924
Validation loss: 2.474032837415664

Epoch: 6| Step: 1
Training loss: 0.18384247023107683
Validation loss: 2.510646849001996

Epoch: 6| Step: 2
Training loss: 0.11584388644172078
Validation loss: 2.5049533364155456

Epoch: 6| Step: 3
Training loss: 0.16187615451253753
Validation loss: 2.536664618611673

Epoch: 6| Step: 4
Training loss: 0.11530276871276277
Validation loss: 2.4948951942394917

Epoch: 6| Step: 5
Training loss: 0.08897185188101021
Validation loss: 2.5175137800674623

Epoch: 6| Step: 6
Training loss: 0.1205556125527507
Validation loss: 2.5042390129833567

Epoch: 6| Step: 7
Training loss: 0.15509283610983005
Validation loss: 2.466004198402689

Epoch: 6| Step: 8
Training loss: 0.11380660799518956
Validation loss: 2.476794454200256

Epoch: 6| Step: 9
Training loss: 0.10184103112748323
Validation loss: 2.4718204572183886

Epoch: 6| Step: 10
Training loss: 0.08213046579320406
Validation loss: 2.487872826676427

Epoch: 6| Step: 11
Training loss: 0.11384689582103483
Validation loss: 2.4691326747690847

Epoch: 6| Step: 12
Training loss: 0.16764765366329645
Validation loss: 2.477532800167765

Epoch: 6| Step: 13
Training loss: 0.12937692486441393
Validation loss: 2.492370558627485

Epoch: 556| Step: 0
Training loss: 0.12706277953369044
Validation loss: 2.499734132227139

Epoch: 6| Step: 1
Training loss: 0.17554926929615158
Validation loss: 2.4832812632571564

Epoch: 6| Step: 2
Training loss: 0.14394157849959174
Validation loss: 2.492734598203857

Epoch: 6| Step: 3
Training loss: 0.10959606734942996
Validation loss: 2.494625300687807

Epoch: 6| Step: 4
Training loss: 0.1629660902693201
Validation loss: 2.5276281001554746

Epoch: 6| Step: 5
Training loss: 0.13528636171143513
Validation loss: 2.543602780091046

Epoch: 6| Step: 6
Training loss: 0.1650698311469351
Validation loss: 2.550668662783072

Epoch: 6| Step: 7
Training loss: 0.09350062522481523
Validation loss: 2.530775067413025

Epoch: 6| Step: 8
Training loss: 0.11224154480225541
Validation loss: 2.5621229950390583

Epoch: 6| Step: 9
Training loss: 0.1710037016251837
Validation loss: 2.5262344187013936

Epoch: 6| Step: 10
Training loss: 0.10074088282515024
Validation loss: 2.527010723264863

Epoch: 6| Step: 11
Training loss: 0.1592073884509738
Validation loss: 2.550437713782861

Epoch: 6| Step: 12
Training loss: 0.14748451221304895
Validation loss: 2.5044586374520432

Epoch: 6| Step: 13
Training loss: 0.09928287964222728
Validation loss: 2.500425807007273

Epoch: 557| Step: 0
Training loss: 0.10787988039499528
Validation loss: 2.4826815093342587

Epoch: 6| Step: 1
Training loss: 0.15037652977619537
Validation loss: 2.4939211558209333

Epoch: 6| Step: 2
Training loss: 0.18043615038492228
Validation loss: 2.4732863730696057

Epoch: 6| Step: 3
Training loss: 0.11986014147122918
Validation loss: 2.4801829312848462

Epoch: 6| Step: 4
Training loss: 0.10928328108488612
Validation loss: 2.5036831048712984

Epoch: 6| Step: 5
Training loss: 0.2187261398109145
Validation loss: 2.495869370214948

Epoch: 6| Step: 6
Training loss: 0.11710010289544798
Validation loss: 2.5263825883710704

Epoch: 6| Step: 7
Training loss: 0.15702385007209163
Validation loss: 2.542998687223646

Epoch: 6| Step: 8
Training loss: 0.12504931311641784
Validation loss: 2.554581891000923

Epoch: 6| Step: 9
Training loss: 0.11923397815634806
Validation loss: 2.5333896447201694

Epoch: 6| Step: 10
Training loss: 0.11045125239327276
Validation loss: 2.5536169110850686

Epoch: 6| Step: 11
Training loss: 0.08534895873299156
Validation loss: 2.543457937887821

Epoch: 6| Step: 12
Training loss: 0.1032080218606627
Validation loss: 2.4896717786084763

Epoch: 6| Step: 13
Training loss: 0.1859029966285474
Validation loss: 2.4842570720536616

Epoch: 558| Step: 0
Training loss: 0.11521522718496066
Validation loss: 2.46470864895275

Epoch: 6| Step: 1
Training loss: 0.09522648275592509
Validation loss: 2.463472338084257

Epoch: 6| Step: 2
Training loss: 0.10153139995365452
Validation loss: 2.4436091372129547

Epoch: 6| Step: 3
Training loss: 0.19923793475956064
Validation loss: 2.463388367764028

Epoch: 6| Step: 4
Training loss: 0.11308903253434388
Validation loss: 2.476667700131477

Epoch: 6| Step: 5
Training loss: 0.16466828178020373
Validation loss: 2.4770293342641496

Epoch: 6| Step: 6
Training loss: 0.22745494351816692
Validation loss: 2.522026629431713

Epoch: 6| Step: 7
Training loss: 0.2064713789147653
Validation loss: 2.5553594019691332

Epoch: 6| Step: 8
Training loss: 0.2197214253142955
Validation loss: 2.551214227278635

Epoch: 6| Step: 9
Training loss: 0.14597652138251874
Validation loss: 2.5886906213531473

Epoch: 6| Step: 10
Training loss: 0.09856635394692333
Validation loss: 2.5791213093337952

Epoch: 6| Step: 11
Training loss: 0.11447875351118254
Validation loss: 2.550398910147862

Epoch: 6| Step: 12
Training loss: 0.15894303545911045
Validation loss: 2.502018507428586

Epoch: 6| Step: 13
Training loss: 0.11929904067666211
Validation loss: 2.5287925917822185

Epoch: 559| Step: 0
Training loss: 0.12978194916654173
Validation loss: 2.524492160294149

Epoch: 6| Step: 1
Training loss: 0.0701693229453301
Validation loss: 2.4930947367409635

Epoch: 6| Step: 2
Training loss: 0.18527624571680892
Validation loss: 2.479471113690714

Epoch: 6| Step: 3
Training loss: 0.1708662384217542
Validation loss: 2.5076500379327142

Epoch: 6| Step: 4
Training loss: 0.1801438342048531
Validation loss: 2.4790505000882304

Epoch: 6| Step: 5
Training loss: 0.14634516777143586
Validation loss: 2.5132369018955907

Epoch: 6| Step: 6
Training loss: 0.14295298145448343
Validation loss: 2.5195038280376374

Epoch: 6| Step: 7
Training loss: 0.09560466099710543
Validation loss: 2.521047145962972

Epoch: 6| Step: 8
Training loss: 0.08706677875048044
Validation loss: 2.5448245666434186

Epoch: 6| Step: 9
Training loss: 0.11015591959531756
Validation loss: 2.581123232974512

Epoch: 6| Step: 10
Training loss: 0.16515663856994767
Validation loss: 2.5598921202401286

Epoch: 6| Step: 11
Training loss: 0.1491614244104202
Validation loss: 2.53558822928912

Epoch: 6| Step: 12
Training loss: 0.15234757687579387
Validation loss: 2.5698978894952753

Epoch: 6| Step: 13
Training loss: 0.09968357968618977
Validation loss: 2.5560697917898962

Epoch: 560| Step: 0
Training loss: 0.1698531856039084
Validation loss: 2.5343091034609726

Epoch: 6| Step: 1
Training loss: 0.1148243049132012
Validation loss: 2.561486456692452

Epoch: 6| Step: 2
Training loss: 0.08791507274962852
Validation loss: 2.5666728155746714

Epoch: 6| Step: 3
Training loss: 0.16941737776228805
Validation loss: 2.578773100363391

Epoch: 6| Step: 4
Training loss: 0.1631513110496284
Validation loss: 2.5807631740902055

Epoch: 6| Step: 5
Training loss: 0.23186727278293423
Validation loss: 2.570295839305254

Epoch: 6| Step: 6
Training loss: 0.1284074815304396
Validation loss: 2.5175805628003007

Epoch: 6| Step: 7
Training loss: 0.11369066001255296
Validation loss: 2.5451109566316226

Epoch: 6| Step: 8
Training loss: 0.11601689511384165
Validation loss: 2.5317118739979234

Epoch: 6| Step: 9
Training loss: 0.10456293153417252
Validation loss: 2.5112314125444275

Epoch: 6| Step: 10
Training loss: 0.11665111012993377
Validation loss: 2.5078193102981077

Epoch: 6| Step: 11
Training loss: 0.13972671022479338
Validation loss: 2.4795488543970645

Epoch: 6| Step: 12
Training loss: 0.12875020089643044
Validation loss: 2.506133723799799

Epoch: 6| Step: 13
Training loss: 0.09345106805413772
Validation loss: 2.5271028400465614

Epoch: 561| Step: 0
Training loss: 0.17742354072652256
Validation loss: 2.5153491180321152

Epoch: 6| Step: 1
Training loss: 0.12372796839691927
Validation loss: 2.5400878915686698

Epoch: 6| Step: 2
Training loss: 0.09494837618608683
Validation loss: 2.5156855493421664

Epoch: 6| Step: 3
Training loss: 0.08525370437231118
Validation loss: 2.5281100844831004

Epoch: 6| Step: 4
Training loss: 0.2005598517433565
Validation loss: 2.503076721269044

Epoch: 6| Step: 5
Training loss: 0.1362340509634171
Validation loss: 2.481145860753411

Epoch: 6| Step: 6
Training loss: 0.08737173556777142
Validation loss: 2.490162792331117

Epoch: 6| Step: 7
Training loss: 0.14589867802489037
Validation loss: 2.476878024888235

Epoch: 6| Step: 8
Training loss: 0.13366463715730031
Validation loss: 2.4687103521679234

Epoch: 6| Step: 9
Training loss: 0.12981737969630153
Validation loss: 2.4887923449215874

Epoch: 6| Step: 10
Training loss: 0.1730856737854984
Validation loss: 2.469298535829546

Epoch: 6| Step: 11
Training loss: 0.10774710579301995
Validation loss: 2.4945226615010077

Epoch: 6| Step: 12
Training loss: 0.07784319358436932
Validation loss: 2.5027780766388856

Epoch: 6| Step: 13
Training loss: 0.1218068598727924
Validation loss: 2.5148245156266587

Epoch: 562| Step: 0
Training loss: 0.07378681190031104
Validation loss: 2.486134320037694

Epoch: 6| Step: 1
Training loss: 0.07116158073881214
Validation loss: 2.50447060673669

Epoch: 6| Step: 2
Training loss: 0.1388514524577559
Validation loss: 2.5058390958531307

Epoch: 6| Step: 3
Training loss: 0.11949218410804946
Validation loss: 2.4978864072210283

Epoch: 6| Step: 4
Training loss: 0.16179694091449245
Validation loss: 2.4969134211861697

Epoch: 6| Step: 5
Training loss: 0.07361101743679165
Validation loss: 2.4805975256176103

Epoch: 6| Step: 6
Training loss: 0.07405246754190373
Validation loss: 2.499126662226669

Epoch: 6| Step: 7
Training loss: 0.08348241772107365
Validation loss: 2.507715801891671

Epoch: 6| Step: 8
Training loss: 0.1271841075336995
Validation loss: 2.490668654193394

Epoch: 6| Step: 9
Training loss: 0.0855904257105481
Validation loss: 2.515870317938064

Epoch: 6| Step: 10
Training loss: 0.22610666194656492
Validation loss: 2.525210273781368

Epoch: 6| Step: 11
Training loss: 0.1394541662909262
Validation loss: 2.5452140048806116

Epoch: 6| Step: 12
Training loss: 0.1321003769596845
Validation loss: 2.5309293567410127

Epoch: 6| Step: 13
Training loss: 0.1407310430395525
Validation loss: 2.573765474238366

Epoch: 563| Step: 0
Training loss: 0.10333623276700987
Validation loss: 2.547780375079126

Epoch: 6| Step: 1
Training loss: 0.10883484447215992
Validation loss: 2.524789321924712

Epoch: 6| Step: 2
Training loss: 0.14500468271192038
Validation loss: 2.5324754461636774

Epoch: 6| Step: 3
Training loss: 0.11808694734939708
Validation loss: 2.539797730371705

Epoch: 6| Step: 4
Training loss: 0.13639498248980078
Validation loss: 2.550138149504466

Epoch: 6| Step: 5
Training loss: 0.09833597139615695
Validation loss: 2.5409879319497315

Epoch: 6| Step: 6
Training loss: 0.16779597955861414
Validation loss: 2.542250400958047

Epoch: 6| Step: 7
Training loss: 0.08536593602051172
Validation loss: 2.5073995561058533

Epoch: 6| Step: 8
Training loss: 0.10629424916306808
Validation loss: 2.4981977498713843

Epoch: 6| Step: 9
Training loss: 0.10021950818129802
Validation loss: 2.5424962586554956

Epoch: 6| Step: 10
Training loss: 0.09976754066462251
Validation loss: 2.5605327899637107

Epoch: 6| Step: 11
Training loss: 0.16467234255837174
Validation loss: 2.537614365437364

Epoch: 6| Step: 12
Training loss: 0.15982591475456645
Validation loss: 2.5212341318116107

Epoch: 6| Step: 13
Training loss: 0.15675498897120863
Validation loss: 2.487822023702864

Epoch: 564| Step: 0
Training loss: 0.18159928415386864
Validation loss: 2.539212685963693

Epoch: 6| Step: 1
Training loss: 0.0772614978521163
Validation loss: 2.5071381418793814

Epoch: 6| Step: 2
Training loss: 0.1454848072888328
Validation loss: 2.487556071480915

Epoch: 6| Step: 3
Training loss: 0.08146247774363541
Validation loss: 2.510264356347552

Epoch: 6| Step: 4
Training loss: 0.11064115015774503
Validation loss: 2.5020344485552517

Epoch: 6| Step: 5
Training loss: 0.17076376922364153
Validation loss: 2.5068405783264143

Epoch: 6| Step: 6
Training loss: 0.08591458166738607
Validation loss: 2.5072729392621684

Epoch: 6| Step: 7
Training loss: 0.08725507946124811
Validation loss: 2.5284015423498856

Epoch: 6| Step: 8
Training loss: 0.06871018313351084
Validation loss: 2.5175554688223887

Epoch: 6| Step: 9
Training loss: 0.1488982503489411
Validation loss: 2.5070312783868274

Epoch: 6| Step: 10
Training loss: 0.13615751876922821
Validation loss: 2.5271263223662634

Epoch: 6| Step: 11
Training loss: 0.09987102998498801
Validation loss: 2.5022782886164823

Epoch: 6| Step: 12
Training loss: 0.11273923642679855
Validation loss: 2.5451576637998024

Epoch: 6| Step: 13
Training loss: 0.12418619125052885
Validation loss: 2.511459606930113

Epoch: 565| Step: 0
Training loss: 0.16177527342874762
Validation loss: 2.5400413101918775

Epoch: 6| Step: 1
Training loss: 0.05921621100473315
Validation loss: 2.5463835010923725

Epoch: 6| Step: 2
Training loss: 0.1048749348898266
Validation loss: 2.524299605626612

Epoch: 6| Step: 3
Training loss: 0.08551525289230477
Validation loss: 2.523226532923734

Epoch: 6| Step: 4
Training loss: 0.14836097928345388
Validation loss: 2.5060248819782247

Epoch: 6| Step: 5
Training loss: 0.08557708981779219
Validation loss: 2.4892329953211485

Epoch: 6| Step: 6
Training loss: 0.10837546955818697
Validation loss: 2.4763287506755924

Epoch: 6| Step: 7
Training loss: 0.09411795252117557
Validation loss: 2.4950888612112694

Epoch: 6| Step: 8
Training loss: 0.09125731553186574
Validation loss: 2.4779978904830684

Epoch: 6| Step: 9
Training loss: 0.14458349288932543
Validation loss: 2.509091258464101

Epoch: 6| Step: 10
Training loss: 0.10315857795774204
Validation loss: 2.514608134986043

Epoch: 6| Step: 11
Training loss: 0.1001048434398703
Validation loss: 2.5384528900678687

Epoch: 6| Step: 12
Training loss: 0.10580375237647754
Validation loss: 2.5320703829661646

Epoch: 6| Step: 13
Training loss: 0.20165470660884244
Validation loss: 2.542747521581893

Epoch: 566| Step: 0
Training loss: 0.07520243375671737
Validation loss: 2.562467939034701

Epoch: 6| Step: 1
Training loss: 0.1701327747075691
Validation loss: 2.530617024449522

Epoch: 6| Step: 2
Training loss: 0.13774784249487135
Validation loss: 2.4977136267932263

Epoch: 6| Step: 3
Training loss: 0.13206198351551887
Validation loss: 2.5436430182838867

Epoch: 6| Step: 4
Training loss: 0.14381181305319635
Validation loss: 2.539895948963245

Epoch: 6| Step: 5
Training loss: 0.17617065953683353
Validation loss: 2.4854116023069763

Epoch: 6| Step: 6
Training loss: 0.1237656587690479
Validation loss: 2.491180664786209

Epoch: 6| Step: 7
Training loss: 0.11945732423675254
Validation loss: 2.4524179242590387

Epoch: 6| Step: 8
Training loss: 0.22282376596611342
Validation loss: 2.496472564016269

Epoch: 6| Step: 9
Training loss: 0.1509025086148237
Validation loss: 2.4711467904399913

Epoch: 6| Step: 10
Training loss: 0.14550282642603168
Validation loss: 2.50773223890612

Epoch: 6| Step: 11
Training loss: 0.10031965340899195
Validation loss: 2.4932619660798663

Epoch: 6| Step: 12
Training loss: 0.10750596050022547
Validation loss: 2.508649361147945

Epoch: 6| Step: 13
Training loss: 0.054219559985000255
Validation loss: 2.5014343464190283

Epoch: 567| Step: 0
Training loss: 0.11547049883704077
Validation loss: 2.4858054884116907

Epoch: 6| Step: 1
Training loss: 0.10360358657568401
Validation loss: 2.497118171821241

Epoch: 6| Step: 2
Training loss: 0.24004066224647613
Validation loss: 2.496440231183496

Epoch: 6| Step: 3
Training loss: 0.1110662844463396
Validation loss: 2.5377219150328876

Epoch: 6| Step: 4
Training loss: 0.15780674763383898
Validation loss: 2.517539483411556

Epoch: 6| Step: 5
Training loss: 0.08068109498763747
Validation loss: 2.533585385996921

Epoch: 6| Step: 6
Training loss: 0.0745519636868415
Validation loss: 2.553106527201039

Epoch: 6| Step: 7
Training loss: 0.11045683843770746
Validation loss: 2.532710731641382

Epoch: 6| Step: 8
Training loss: 0.10415585481641385
Validation loss: 2.5516498216733283

Epoch: 6| Step: 9
Training loss: 0.11799662525950004
Validation loss: 2.5585205167841685

Epoch: 6| Step: 10
Training loss: 0.16467660683322402
Validation loss: 2.5564150892548203

Epoch: 6| Step: 11
Training loss: 0.07233763663783467
Validation loss: 2.55295848059651

Epoch: 6| Step: 12
Training loss: 0.10228235718395629
Validation loss: 2.529860140901889

Epoch: 6| Step: 13
Training loss: 0.130839090056127
Validation loss: 2.5201658970288245

Epoch: 568| Step: 0
Training loss: 0.1077756950194518
Validation loss: 2.544206155169483

Epoch: 6| Step: 1
Training loss: 0.14716484329762552
Validation loss: 2.514658885137238

Epoch: 6| Step: 2
Training loss: 0.17488323343689416
Validation loss: 2.5467787225592557

Epoch: 6| Step: 3
Training loss: 0.15272738984664563
Validation loss: 2.54499787177405

Epoch: 6| Step: 4
Training loss: 0.103742256931259
Validation loss: 2.553913242100129

Epoch: 6| Step: 5
Training loss: 0.07965033520041621
Validation loss: 2.5428065751756947

Epoch: 6| Step: 6
Training loss: 0.09808777833621768
Validation loss: 2.548713986978827

Epoch: 6| Step: 7
Training loss: 0.10139634222112341
Validation loss: 2.5110419676701596

Epoch: 6| Step: 8
Training loss: 0.11069476509968497
Validation loss: 2.541280737753246

Epoch: 6| Step: 9
Training loss: 0.21367655928531423
Validation loss: 2.511548655399978

Epoch: 6| Step: 10
Training loss: 0.1183390385873756
Validation loss: 2.5212192109545883

Epoch: 6| Step: 11
Training loss: 0.14965395275757615
Validation loss: 2.4887817320450902

Epoch: 6| Step: 12
Training loss: 0.10087018450749811
Validation loss: 2.5341922154384537

Epoch: 6| Step: 13
Training loss: 0.16138588654092234
Validation loss: 2.5311316540113133

Epoch: 569| Step: 0
Training loss: 0.07264377271511888
Validation loss: 2.572298137410643

Epoch: 6| Step: 1
Training loss: 0.13369428103513897
Validation loss: 2.5493859574206494

Epoch: 6| Step: 2
Training loss: 0.11462840274005386
Validation loss: 2.576471831246627

Epoch: 6| Step: 3
Training loss: 0.14110070142804806
Validation loss: 2.5759535687997723

Epoch: 6| Step: 4
Training loss: 0.11667327911790835
Validation loss: 2.5241022281193723

Epoch: 6| Step: 5
Training loss: 0.1791985223325247
Validation loss: 2.5744691396126576

Epoch: 6| Step: 6
Training loss: 0.09571853824981871
Validation loss: 2.5590342738841687

Epoch: 6| Step: 7
Training loss: 0.1726220487577812
Validation loss: 2.5453282127262256

Epoch: 6| Step: 8
Training loss: 0.0821556414067989
Validation loss: 2.5099313748821994

Epoch: 6| Step: 9
Training loss: 0.2130529589705817
Validation loss: 2.480143834205972

Epoch: 6| Step: 10
Training loss: 0.14024249348212067
Validation loss: 2.513869894005766

Epoch: 6| Step: 11
Training loss: 0.1328340681178177
Validation loss: 2.5015554552426833

Epoch: 6| Step: 12
Training loss: 0.15095103493418155
Validation loss: 2.501565873527185

Epoch: 6| Step: 13
Training loss: 0.09273865700326628
Validation loss: 2.485011758978496

Epoch: 570| Step: 0
Training loss: 0.15356570851308637
Validation loss: 2.498833349230719

Epoch: 6| Step: 1
Training loss: 0.1290272231763608
Validation loss: 2.4902267136155336

Epoch: 6| Step: 2
Training loss: 0.13983768364732366
Validation loss: 2.4898805101531574

Epoch: 6| Step: 3
Training loss: 0.13897329131860345
Validation loss: 2.491363516730452

Epoch: 6| Step: 4
Training loss: 0.09873311447688755
Validation loss: 2.469794261634471

Epoch: 6| Step: 5
Training loss: 0.14373562238151769
Validation loss: 2.4967455230856

Epoch: 6| Step: 6
Training loss: 0.11750072501217589
Validation loss: 2.5052949944429437

Epoch: 6| Step: 7
Training loss: 0.11729522760300734
Validation loss: 2.514460805409326

Epoch: 6| Step: 8
Training loss: 0.07315682204795662
Validation loss: 2.499687374215756

Epoch: 6| Step: 9
Training loss: 0.08684995515795578
Validation loss: 2.502747439099963

Epoch: 6| Step: 10
Training loss: 0.08415459415968407
Validation loss: 2.5109234467150845

Epoch: 6| Step: 11
Training loss: 0.1620817563072978
Validation loss: 2.4828699461975896

Epoch: 6| Step: 12
Training loss: 0.197219427761315
Validation loss: 2.4980187122687103

Epoch: 6| Step: 13
Training loss: 0.20284494020086116
Validation loss: 2.5173973838918933

Epoch: 571| Step: 0
Training loss: 0.136613669203932
Validation loss: 2.5298943803383076

Epoch: 6| Step: 1
Training loss: 0.06662932960960358
Validation loss: 2.551186621319155

Epoch: 6| Step: 2
Training loss: 0.06296395416076263
Validation loss: 2.528179050382245

Epoch: 6| Step: 3
Training loss: 0.19659167065700933
Validation loss: 2.5317341311015293

Epoch: 6| Step: 4
Training loss: 0.12093699984976874
Validation loss: 2.528007004279773

Epoch: 6| Step: 5
Training loss: 0.18407968372902192
Validation loss: 2.549142429760733

Epoch: 6| Step: 6
Training loss: 0.10075241496963891
Validation loss: 2.5425760297246565

Epoch: 6| Step: 7
Training loss: 0.07411589836739778
Validation loss: 2.538627977319582

Epoch: 6| Step: 8
Training loss: 0.25816744155277016
Validation loss: 2.5570767803185337

Epoch: 6| Step: 9
Training loss: 0.12379925282944046
Validation loss: 2.516712173667655

Epoch: 6| Step: 10
Training loss: 0.1532095369225662
Validation loss: 2.5064139586374745

Epoch: 6| Step: 11
Training loss: 0.08993045624255355
Validation loss: 2.4864148860107487

Epoch: 6| Step: 12
Training loss: 0.14779642606441812
Validation loss: 2.490500808608437

Epoch: 6| Step: 13
Training loss: 0.12221216352262722
Validation loss: 2.505897051913753

Epoch: 572| Step: 0
Training loss: 0.21360061091724553
Validation loss: 2.5383098901063033

Epoch: 6| Step: 1
Training loss: 0.09811966614288514
Validation loss: 2.564647280614526

Epoch: 6| Step: 2
Training loss: 0.14138540672834896
Validation loss: 2.5397980861808507

Epoch: 6| Step: 3
Training loss: 0.09149518047730851
Validation loss: 2.5431397501546624

Epoch: 6| Step: 4
Training loss: 0.09809233572816281
Validation loss: 2.539209922126659

Epoch: 6| Step: 5
Training loss: 0.11658937080582102
Validation loss: 2.548073736206931

Epoch: 6| Step: 6
Training loss: 0.1748673204279099
Validation loss: 2.53189467213298

Epoch: 6| Step: 7
Training loss: 0.12544164273321073
Validation loss: 2.514409535862717

Epoch: 6| Step: 8
Training loss: 0.17385930949600972
Validation loss: 2.525614728877722

Epoch: 6| Step: 9
Training loss: 0.11282796440699472
Validation loss: 2.5186690257819495

Epoch: 6| Step: 10
Training loss: 0.16062452893243728
Validation loss: 2.5198673111609775

Epoch: 6| Step: 11
Training loss: 0.14717682253018702
Validation loss: 2.4988578802425088

Epoch: 6| Step: 12
Training loss: 0.1989271235994228
Validation loss: 2.4753066877548724

Epoch: 6| Step: 13
Training loss: 0.057959288553726826
Validation loss: 2.4839562916946587

Epoch: 573| Step: 0
Training loss: 0.09949730196845961
Validation loss: 2.477617671427845

Epoch: 6| Step: 1
Training loss: 0.08257557021405276
Validation loss: 2.4832082639974815

Epoch: 6| Step: 2
Training loss: 0.08823418755339986
Validation loss: 2.4493886504655227

Epoch: 6| Step: 3
Training loss: 0.1836381716454383
Validation loss: 2.4803913125361117

Epoch: 6| Step: 4
Training loss: 0.15816168772242328
Validation loss: 2.4899494713518817

Epoch: 6| Step: 5
Training loss: 0.12423132946689132
Validation loss: 2.496281471211598

Epoch: 6| Step: 6
Training loss: 0.11115412750716529
Validation loss: 2.4968302382253644

Epoch: 6| Step: 7
Training loss: 0.1635476048013096
Validation loss: 2.508594648451532

Epoch: 6| Step: 8
Training loss: 0.129650129828423
Validation loss: 2.5464352841467663

Epoch: 6| Step: 9
Training loss: 0.12240426731135132
Validation loss: 2.5438369250154036

Epoch: 6| Step: 10
Training loss: 0.1509627198934
Validation loss: 2.538694196545101

Epoch: 6| Step: 11
Training loss: 0.11876026786783947
Validation loss: 2.5313955366700807

Epoch: 6| Step: 12
Training loss: 0.13525105552561137
Validation loss: 2.4998663569179453

Epoch: 6| Step: 13
Training loss: 0.163523703219301
Validation loss: 2.4650462311680057

Epoch: 574| Step: 0
Training loss: 0.19516931053359896
Validation loss: 2.478355350104331

Epoch: 6| Step: 1
Training loss: 0.12084233040514669
Validation loss: 2.458731971637634

Epoch: 6| Step: 2
Training loss: 0.10712005957742152
Validation loss: 2.47853341360419

Epoch: 6| Step: 3
Training loss: 0.1334442023865421
Validation loss: 2.488070465219814

Epoch: 6| Step: 4
Training loss: 0.09596976775887706
Validation loss: 2.498133009403003

Epoch: 6| Step: 5
Training loss: 0.1113725916415323
Validation loss: 2.519815817913493

Epoch: 6| Step: 6
Training loss: 0.13348570073713095
Validation loss: 2.509898439665132

Epoch: 6| Step: 7
Training loss: 0.1111757758549261
Validation loss: 2.5037130592590455

Epoch: 6| Step: 8
Training loss: 0.160827972585483
Validation loss: 2.506781261413854

Epoch: 6| Step: 9
Training loss: 0.11201425398175004
Validation loss: 2.55482406931047

Epoch: 6| Step: 10
Training loss: 0.12559501027843856
Validation loss: 2.5370750555968584

Epoch: 6| Step: 11
Training loss: 0.11333475822307998
Validation loss: 2.5307870145460116

Epoch: 6| Step: 12
Training loss: 0.08381403515321517
Validation loss: 2.529246855425805

Epoch: 6| Step: 13
Training loss: 0.21060439582076645
Validation loss: 2.5296954692735394

Epoch: 575| Step: 0
Training loss: 0.1480222905563992
Validation loss: 2.4902730598959626

Epoch: 6| Step: 1
Training loss: 0.12128190067050863
Validation loss: 2.520670622582465

Epoch: 6| Step: 2
Training loss: 0.11228980919511324
Validation loss: 2.524562919354941

Epoch: 6| Step: 3
Training loss: 0.16107844967337123
Validation loss: 2.53469598876156

Epoch: 6| Step: 4
Training loss: 0.10122207294720456
Validation loss: 2.4928046209605847

Epoch: 6| Step: 5
Training loss: 0.08715102756572093
Validation loss: 2.5164698310349376

Epoch: 6| Step: 6
Training loss: 0.10252799928110927
Validation loss: 2.5283843560542247

Epoch: 6| Step: 7
Training loss: 0.15237035885761083
Validation loss: 2.533480132884646

Epoch: 6| Step: 8
Training loss: 0.08812026646934823
Validation loss: 2.5619034571755392

Epoch: 6| Step: 9
Training loss: 0.15432006927186795
Validation loss: 2.534700752542345

Epoch: 6| Step: 10
Training loss: 0.10431050611565137
Validation loss: 2.526903539050449

Epoch: 6| Step: 11
Training loss: 0.16074916365585373
Validation loss: 2.510551752979772

Epoch: 6| Step: 12
Training loss: 0.08766811603325894
Validation loss: 2.517130224671984

Epoch: 6| Step: 13
Training loss: 0.12569228337147212
Validation loss: 2.5458053304428723

Epoch: 576| Step: 0
Training loss: 0.10455521794879878
Validation loss: 2.5385957910862933

Epoch: 6| Step: 1
Training loss: 0.1391150685935898
Validation loss: 2.538723031471694

Epoch: 6| Step: 2
Training loss: 0.16289850988903745
Validation loss: 2.532366531820489

Epoch: 6| Step: 3
Training loss: 0.08327190797666056
Validation loss: 2.561908104320333

Epoch: 6| Step: 4
Training loss: 0.08407007602051854
Validation loss: 2.5503927096133414

Epoch: 6| Step: 5
Training loss: 0.0852662607354191
Validation loss: 2.561534948980981

Epoch: 6| Step: 6
Training loss: 0.09906214102520568
Validation loss: 2.5378635369358795

Epoch: 6| Step: 7
Training loss: 0.17214861137289603
Validation loss: 2.5544114350199214

Epoch: 6| Step: 8
Training loss: 0.18651407028563943
Validation loss: 2.5327190024135504

Epoch: 6| Step: 9
Training loss: 0.1015151261835113
Validation loss: 2.5020693449028766

Epoch: 6| Step: 10
Training loss: 0.09613027421250078
Validation loss: 2.4982322164799844

Epoch: 6| Step: 11
Training loss: 0.13384021699950935
Validation loss: 2.475772390932633

Epoch: 6| Step: 12
Training loss: 0.12837483221867713
Validation loss: 2.536837966814735

Epoch: 6| Step: 13
Training loss: 0.10978580285998119
Validation loss: 2.468485701632069

Epoch: 577| Step: 0
Training loss: 0.11508397616436607
Validation loss: 2.4880422503559094

Epoch: 6| Step: 1
Training loss: 0.07761463114997627
Validation loss: 2.490306733873885

Epoch: 6| Step: 2
Training loss: 0.09688004530566251
Validation loss: 2.4985934084441292

Epoch: 6| Step: 3
Training loss: 0.12190500510542597
Validation loss: 2.5030636135770266

Epoch: 6| Step: 4
Training loss: 0.08993701654878195
Validation loss: 2.4986073398886726

Epoch: 6| Step: 5
Training loss: 0.06451165186283479
Validation loss: 2.470953144038639

Epoch: 6| Step: 6
Training loss: 0.1435527996016944
Validation loss: 2.513197469308302

Epoch: 6| Step: 7
Training loss: 0.11559836638272493
Validation loss: 2.51378291032131

Epoch: 6| Step: 8
Training loss: 0.1306298363625317
Validation loss: 2.4969314611729323

Epoch: 6| Step: 9
Training loss: 0.14888440166993835
Validation loss: 2.471092758315196

Epoch: 6| Step: 10
Training loss: 0.19751406595384172
Validation loss: 2.5283853689842704

Epoch: 6| Step: 11
Training loss: 0.15653506144199303
Validation loss: 2.489305330780081

Epoch: 6| Step: 12
Training loss: 0.07103736089998723
Validation loss: 2.4800638540345763

Epoch: 6| Step: 13
Training loss: 0.08001969112820677
Validation loss: 2.4850513138524706

Epoch: 578| Step: 0
Training loss: 0.15829441591957846
Validation loss: 2.5062670664389954

Epoch: 6| Step: 1
Training loss: 0.11098980946415611
Validation loss: 2.516228905705274

Epoch: 6| Step: 2
Training loss: 0.1386645207671278
Validation loss: 2.5057014732283225

Epoch: 6| Step: 3
Training loss: 0.06297846651127113
Validation loss: 2.5160469868606157

Epoch: 6| Step: 4
Training loss: 0.10988183606605902
Validation loss: 2.495845881161146

Epoch: 6| Step: 5
Training loss: 0.10508011812496588
Validation loss: 2.5100397245601194

Epoch: 6| Step: 6
Training loss: 0.1531228050736354
Validation loss: 2.518587334443741

Epoch: 6| Step: 7
Training loss: 0.09922256349759227
Validation loss: 2.50526527693286

Epoch: 6| Step: 8
Training loss: 0.10883587561103059
Validation loss: 2.5294797746876343

Epoch: 6| Step: 9
Training loss: 0.17649616455376593
Validation loss: 2.522890986293264

Epoch: 6| Step: 10
Training loss: 0.09338939375669682
Validation loss: 2.5160990832437324

Epoch: 6| Step: 11
Training loss: 0.12672000903199085
Validation loss: 2.5101910684084787

Epoch: 6| Step: 12
Training loss: 0.08087544845839219
Validation loss: 2.490898937686117

Epoch: 6| Step: 13
Training loss: 0.0670187868133749
Validation loss: 2.4726905822314427

Epoch: 579| Step: 0
Training loss: 0.08698811751507035
Validation loss: 2.465296251442597

Epoch: 6| Step: 1
Training loss: 0.13985181550789977
Validation loss: 2.483938779306139

Epoch: 6| Step: 2
Training loss: 0.16045940016276553
Validation loss: 2.4436699760071585

Epoch: 6| Step: 3
Training loss: 0.09950586157604893
Validation loss: 2.4630293303086144

Epoch: 6| Step: 4
Training loss: 0.111286552932471
Validation loss: 2.4650809741022726

Epoch: 6| Step: 5
Training loss: 0.13110096536496613
Validation loss: 2.475665281543274

Epoch: 6| Step: 6
Training loss: 0.17986492022437522
Validation loss: 2.4490378788753318

Epoch: 6| Step: 7
Training loss: 0.11751081846785223
Validation loss: 2.4833657914682097

Epoch: 6| Step: 8
Training loss: 0.12544842840495404
Validation loss: 2.4661642198362004

Epoch: 6| Step: 9
Training loss: 0.15003393653588967
Validation loss: 2.492270010380408

Epoch: 6| Step: 10
Training loss: 0.08850874241924526
Validation loss: 2.472629641518827

Epoch: 6| Step: 11
Training loss: 0.09342540237644048
Validation loss: 2.4827608062856474

Epoch: 6| Step: 12
Training loss: 0.07931127241344213
Validation loss: 2.4715812777834127

Epoch: 6| Step: 13
Training loss: 0.09381425165781329
Validation loss: 2.462434657102182

Epoch: 580| Step: 0
Training loss: 0.14183977413425292
Validation loss: 2.473674312710595

Epoch: 6| Step: 1
Training loss: 0.0822474293497312
Validation loss: 2.487389824147856

Epoch: 6| Step: 2
Training loss: 0.08034102675872272
Validation loss: 2.4474070426745094

Epoch: 6| Step: 3
Training loss: 0.0817378735731525
Validation loss: 2.4943542309339817

Epoch: 6| Step: 4
Training loss: 0.10331444714633067
Validation loss: 2.46852788604867

Epoch: 6| Step: 5
Training loss: 0.16342048252817104
Validation loss: 2.4854671383786844

Epoch: 6| Step: 6
Training loss: 0.09445665190416919
Validation loss: 2.469220701334802

Epoch: 6| Step: 7
Training loss: 0.08241576662524777
Validation loss: 2.4913100147834677

Epoch: 6| Step: 8
Training loss: 0.10275745748979022
Validation loss: 2.485129197727484

Epoch: 6| Step: 9
Training loss: 0.15214423417441864
Validation loss: 2.5183979522549254

Epoch: 6| Step: 10
Training loss: 0.07667701377909979
Validation loss: 2.503039964660719

Epoch: 6| Step: 11
Training loss: 0.06952754262620027
Validation loss: 2.462500924305492

Epoch: 6| Step: 12
Training loss: 0.09011174224785476
Validation loss: 2.51760360264596

Epoch: 6| Step: 13
Training loss: 0.1519179016514897
Validation loss: 2.4851899789299363

Epoch: 581| Step: 0
Training loss: 0.09789163355296367
Validation loss: 2.485869354670964

Epoch: 6| Step: 1
Training loss: 0.1499059347412217
Validation loss: 2.4845599580778286

Epoch: 6| Step: 2
Training loss: 0.0905511981024251
Validation loss: 2.5125387321127013

Epoch: 6| Step: 3
Training loss: 0.1458418040426725
Validation loss: 2.510267734683979

Epoch: 6| Step: 4
Training loss: 0.12068315081461843
Validation loss: 2.504407348936539

Epoch: 6| Step: 5
Training loss: 0.0991688129582803
Validation loss: 2.4939421424775774

Epoch: 6| Step: 6
Training loss: 0.08001735463160417
Validation loss: 2.491198798512426

Epoch: 6| Step: 7
Training loss: 0.11928055316210812
Validation loss: 2.471583410103321

Epoch: 6| Step: 8
Training loss: 0.1254548796496476
Validation loss: 2.4911695333888804

Epoch: 6| Step: 9
Training loss: 0.09710016232996531
Validation loss: 2.4822825492310114

Epoch: 6| Step: 10
Training loss: 0.10740748222339029
Validation loss: 2.4649273353259415

Epoch: 6| Step: 11
Training loss: 0.08890600718982973
Validation loss: 2.446394328948381

Epoch: 6| Step: 12
Training loss: 0.13189445892155754
Validation loss: 2.455331450041455

Epoch: 6| Step: 13
Training loss: 0.1866338313300587
Validation loss: 2.4443935961234144

Epoch: 582| Step: 0
Training loss: 0.11580719254339854
Validation loss: 2.4848943306704228

Epoch: 6| Step: 1
Training loss: 0.06929007544698082
Validation loss: 2.495160689904946

Epoch: 6| Step: 2
Training loss: 0.0763262321819244
Validation loss: 2.5259734445300266

Epoch: 6| Step: 3
Training loss: 0.0783474378155312
Validation loss: 2.495852926462474

Epoch: 6| Step: 4
Training loss: 0.10855965181895927
Validation loss: 2.528491578379122

Epoch: 6| Step: 5
Training loss: 0.12924560037278301
Validation loss: 2.5141889477899215

Epoch: 6| Step: 6
Training loss: 0.11745521245387638
Validation loss: 2.5138897381855903

Epoch: 6| Step: 7
Training loss: 0.1643200737051824
Validation loss: 2.537387164812009

Epoch: 6| Step: 8
Training loss: 0.11483351035757888
Validation loss: 2.5323359490559256

Epoch: 6| Step: 9
Training loss: 0.10610243493489603
Validation loss: 2.5348776726154227

Epoch: 6| Step: 10
Training loss: 0.15185158040750715
Validation loss: 2.532486792066328

Epoch: 6| Step: 11
Training loss: 0.08720597259032682
Validation loss: 2.5250152650784115

Epoch: 6| Step: 12
Training loss: 0.08584842888492693
Validation loss: 2.5340541922571287

Epoch: 6| Step: 13
Training loss: 0.04489290038983342
Validation loss: 2.494404124911366

Epoch: 583| Step: 0
Training loss: 0.1486662682915847
Validation loss: 2.50263172190104

Epoch: 6| Step: 1
Training loss: 0.09623047475812865
Validation loss: 2.5282295463712163

Epoch: 6| Step: 2
Training loss: 0.1121967252840665
Validation loss: 2.4945451304344686

Epoch: 6| Step: 3
Training loss: 0.11195030690683956
Validation loss: 2.5079585360525054

Epoch: 6| Step: 4
Training loss: 0.07587676468702821
Validation loss: 2.48055637376999

Epoch: 6| Step: 5
Training loss: 0.10265600711033158
Validation loss: 2.504695256925481

Epoch: 6| Step: 6
Training loss: 0.19099887002116378
Validation loss: 2.4883778271090398

Epoch: 6| Step: 7
Training loss: 0.09991820462116742
Validation loss: 2.4713991883028994

Epoch: 6| Step: 8
Training loss: 0.09594240249073682
Validation loss: 2.4919124058876965

Epoch: 6| Step: 9
Training loss: 0.09627296649811765
Validation loss: 2.4636521096886197

Epoch: 6| Step: 10
Training loss: 0.07630290779876979
Validation loss: 2.483898996166511

Epoch: 6| Step: 11
Training loss: 0.07510958776449815
Validation loss: 2.5087617622391316

Epoch: 6| Step: 12
Training loss: 0.09273358040993852
Validation loss: 2.5007383773830556

Epoch: 6| Step: 13
Training loss: 0.0785708372083965
Validation loss: 2.493490568113854

Epoch: 584| Step: 0
Training loss: 0.07245549184072993
Validation loss: 2.533876771542231

Epoch: 6| Step: 1
Training loss: 0.1462918414983879
Validation loss: 2.549598243008464

Epoch: 6| Step: 2
Training loss: 0.12086515230353241
Validation loss: 2.553769238653764

Epoch: 6| Step: 3
Training loss: 0.14512584141923515
Validation loss: 2.537638538732482

Epoch: 6| Step: 4
Training loss: 0.09121343172244951
Validation loss: 2.556791300992262

Epoch: 6| Step: 5
Training loss: 0.13916290012799962
Validation loss: 2.5164258336078804

Epoch: 6| Step: 6
Training loss: 0.08371812734375893
Validation loss: 2.53952894648146

Epoch: 6| Step: 7
Training loss: 0.15045785020702965
Validation loss: 2.499049098154742

Epoch: 6| Step: 8
Training loss: 0.07015369283183039
Validation loss: 2.5114267045143865

Epoch: 6| Step: 9
Training loss: 0.05934213494186748
Validation loss: 2.4844358589868647

Epoch: 6| Step: 10
Training loss: 0.06883925528708523
Validation loss: 2.4964279599908266

Epoch: 6| Step: 11
Training loss: 0.09557450175811542
Validation loss: 2.4923761531510276

Epoch: 6| Step: 12
Training loss: 0.08739719428977567
Validation loss: 2.49466259131114

Epoch: 6| Step: 13
Training loss: 0.1348683339028083
Validation loss: 2.4857101273644604

Epoch: 585| Step: 0
Training loss: 0.10623116343783605
Validation loss: 2.495738777600374

Epoch: 6| Step: 1
Training loss: 0.0720525448304874
Validation loss: 2.523135792860657

Epoch: 6| Step: 2
Training loss: 0.07982735504250216
Validation loss: 2.494988102954512

Epoch: 6| Step: 3
Training loss: 0.2038547538537048
Validation loss: 2.5152638799785927

Epoch: 6| Step: 4
Training loss: 0.07376651324965766
Validation loss: 2.4856981430322294

Epoch: 6| Step: 5
Training loss: 0.09801129174167021
Validation loss: 2.5135933035847304

Epoch: 6| Step: 6
Training loss: 0.07589794384063996
Validation loss: 2.4915390845289

Epoch: 6| Step: 7
Training loss: 0.10816094871025964
Validation loss: 2.4888573860431595

Epoch: 6| Step: 8
Training loss: 0.0754853821724573
Validation loss: 2.4816588975566076

Epoch: 6| Step: 9
Training loss: 0.051001248740149725
Validation loss: 2.46150294519032

Epoch: 6| Step: 10
Training loss: 0.11289530401201976
Validation loss: 2.4782491530193083

Epoch: 6| Step: 11
Training loss: 0.07735438863721311
Validation loss: 2.47629078641646

Epoch: 6| Step: 12
Training loss: 0.16102975381703566
Validation loss: 2.484227954250634

Epoch: 6| Step: 13
Training loss: 0.06958234682901905
Validation loss: 2.4694483828269727

Epoch: 586| Step: 0
Training loss: 0.06978456665097475
Validation loss: 2.4949920177880722

Epoch: 6| Step: 1
Training loss: 0.08290646199958834
Validation loss: 2.4712220859276326

Epoch: 6| Step: 2
Training loss: 0.08685492260836061
Validation loss: 2.517831542788238

Epoch: 6| Step: 3
Training loss: 0.08101397663948359
Validation loss: 2.4941923939271176

Epoch: 6| Step: 4
Training loss: 0.05009568509839935
Validation loss: 2.481502748104193

Epoch: 6| Step: 5
Training loss: 0.09303283566272666
Validation loss: 2.4726919233083597

Epoch: 6| Step: 6
Training loss: 0.14461417654423978
Validation loss: 2.4437792351790453

Epoch: 6| Step: 7
Training loss: 0.07380199752166397
Validation loss: 2.4764859051911534

Epoch: 6| Step: 8
Training loss: 0.13487779399728422
Validation loss: 2.4670384150056806

Epoch: 6| Step: 9
Training loss: 0.07837786878426292
Validation loss: 2.490416373821186

Epoch: 6| Step: 10
Training loss: 0.06218547582327246
Validation loss: 2.5128181511379095

Epoch: 6| Step: 11
Training loss: 0.08741294540808386
Validation loss: 2.484117958349989

Epoch: 6| Step: 12
Training loss: 0.1485567993808384
Validation loss: 2.492791153814174

Epoch: 6| Step: 13
Training loss: 0.06368472373365631
Validation loss: 2.478161452324954

Epoch: 587| Step: 0
Training loss: 0.0632145462396859
Validation loss: 2.4893924720465748

Epoch: 6| Step: 1
Training loss: 0.052956882138234726
Validation loss: 2.5111408524112715

Epoch: 6| Step: 2
Training loss: 0.07264138808068094
Validation loss: 2.5304327490781025

Epoch: 6| Step: 3
Training loss: 0.12930618004867753
Validation loss: 2.4610794581161852

Epoch: 6| Step: 4
Training loss: 0.16822307760676833
Validation loss: 2.5399475342319766

Epoch: 6| Step: 5
Training loss: 0.0743060633646591
Validation loss: 2.5173852958172818

Epoch: 6| Step: 6
Training loss: 0.15367150631013363
Validation loss: 2.5340576319516197

Epoch: 6| Step: 7
Training loss: 0.07040375509806844
Validation loss: 2.52814339695797

Epoch: 6| Step: 8
Training loss: 0.10603622254703104
Validation loss: 2.525257502327828

Epoch: 6| Step: 9
Training loss: 0.08593582563503095
Validation loss: 2.523736979966855

Epoch: 6| Step: 10
Training loss: 0.10120623715674532
Validation loss: 2.502488994330988

Epoch: 6| Step: 11
Training loss: 0.08484259398254174
Validation loss: 2.5274036676337914

Epoch: 6| Step: 12
Training loss: 0.17208167676170638
Validation loss: 2.5115500354414038

Epoch: 6| Step: 13
Training loss: 0.10630236660522269
Validation loss: 2.5222896554791605

Epoch: 588| Step: 0
Training loss: 0.1015836116049538
Validation loss: 2.500687369326585

Epoch: 6| Step: 1
Training loss: 0.08614762042685477
Validation loss: 2.523260677970471

Epoch: 6| Step: 2
Training loss: 0.08718864059043999
Validation loss: 2.512604161503615

Epoch: 6| Step: 3
Training loss: 0.11883327832857163
Validation loss: 2.552013330125244

Epoch: 6| Step: 4
Training loss: 0.08972041849300927
Validation loss: 2.519331748156572

Epoch: 6| Step: 5
Training loss: 0.13505138976550016
Validation loss: 2.550750977974855

Epoch: 6| Step: 6
Training loss: 0.14347425140629916
Validation loss: 2.5455554991880165

Epoch: 6| Step: 7
Training loss: 0.1541741704134908
Validation loss: 2.499772957777511

Epoch: 6| Step: 8
Training loss: 0.05949235333139673
Validation loss: 2.4870988197365334

Epoch: 6| Step: 9
Training loss: 0.10465219315086637
Validation loss: 2.5146474567574297

Epoch: 6| Step: 10
Training loss: 0.09490303924079599
Validation loss: 2.4891998439134344

Epoch: 6| Step: 11
Training loss: 0.14984552878595925
Validation loss: 2.501365783330915

Epoch: 6| Step: 12
Training loss: 0.12408952379054844
Validation loss: 2.4736317305118427

Epoch: 6| Step: 13
Training loss: 0.07751766108868605
Validation loss: 2.4531237333979097

Epoch: 589| Step: 0
Training loss: 0.13273547547609982
Validation loss: 2.481783132407813

Epoch: 6| Step: 1
Training loss: 0.08561462741522222
Validation loss: 2.490595372233604

Epoch: 6| Step: 2
Training loss: 0.07966658046491966
Validation loss: 2.4866341991010033

Epoch: 6| Step: 3
Training loss: 0.10771932168957714
Validation loss: 2.477583160170271

Epoch: 6| Step: 4
Training loss: 0.15059018209489197
Validation loss: 2.4583455984547613

Epoch: 6| Step: 5
Training loss: 0.060518696595967834
Validation loss: 2.492791918959837

Epoch: 6| Step: 6
Training loss: 0.0878711413934277
Validation loss: 2.4755639294847915

Epoch: 6| Step: 7
Training loss: 0.12562127987966376
Validation loss: 2.490624145914452

Epoch: 6| Step: 8
Training loss: 0.09320778310699611
Validation loss: 2.506446978508432

Epoch: 6| Step: 9
Training loss: 0.09020476784425097
Validation loss: 2.5425428271952044

Epoch: 6| Step: 10
Training loss: 0.12811568621766498
Validation loss: 2.5041052030060658

Epoch: 6| Step: 11
Training loss: 0.1985271735587206
Validation loss: 2.5047227734611046

Epoch: 6| Step: 12
Training loss: 0.06146699723434121
Validation loss: 2.489887023545821

Epoch: 6| Step: 13
Training loss: 0.07519708358858737
Validation loss: 2.494060591038996

Epoch: 590| Step: 0
Training loss: 0.13072713888984283
Validation loss: 2.4315831816391436

Epoch: 6| Step: 1
Training loss: 0.10814939276812029
Validation loss: 2.4747883896508496

Epoch: 6| Step: 2
Training loss: 0.09185735252439235
Validation loss: 2.45580712220145

Epoch: 6| Step: 3
Training loss: 0.11509979196221229
Validation loss: 2.4784147391261326

Epoch: 6| Step: 4
Training loss: 0.15648008929176882
Validation loss: 2.484427791732902

Epoch: 6| Step: 5
Training loss: 0.08451924114456949
Validation loss: 2.487357002724423

Epoch: 6| Step: 6
Training loss: 0.11408795667090686
Validation loss: 2.5146671897952797

Epoch: 6| Step: 7
Training loss: 0.06603239864920045
Validation loss: 2.50601195389745

Epoch: 6| Step: 8
Training loss: 0.1511371710713995
Validation loss: 2.50343669764337

Epoch: 6| Step: 9
Training loss: 0.23381227650513173
Validation loss: 2.5099017817232974

Epoch: 6| Step: 10
Training loss: 0.0808258042237388
Validation loss: 2.45975485369987

Epoch: 6| Step: 11
Training loss: 0.08806945303974108
Validation loss: 2.4395295542346975

Epoch: 6| Step: 12
Training loss: 0.1428087668275276
Validation loss: 2.420557044692089

Epoch: 6| Step: 13
Training loss: 0.09216161057257638
Validation loss: 2.425122465308641

Epoch: 591| Step: 0
Training loss: 0.09049019241537874
Validation loss: 2.4442384886496966

Epoch: 6| Step: 1
Training loss: 0.13421969476707044
Validation loss: 2.430893801833003

Epoch: 6| Step: 2
Training loss: 0.1702557112569769
Validation loss: 2.440005800030837

Epoch: 6| Step: 3
Training loss: 0.11145866002572688
Validation loss: 2.4176372817947427

Epoch: 6| Step: 4
Training loss: 0.11634943426828258
Validation loss: 2.4757540212497964

Epoch: 6| Step: 5
Training loss: 0.08388964722287885
Validation loss: 2.4739376945908447

Epoch: 6| Step: 6
Training loss: 0.08284150461372213
Validation loss: 2.5385030160652793

Epoch: 6| Step: 7
Training loss: 0.12292554338038157
Validation loss: 2.5100982842647404

Epoch: 6| Step: 8
Training loss: 0.11837400748824699
Validation loss: 2.4994038455557965

Epoch: 6| Step: 9
Training loss: 0.14477696667178416
Validation loss: 2.5383036948852586

Epoch: 6| Step: 10
Training loss: 0.10477077477874429
Validation loss: 2.5127366486084783

Epoch: 6| Step: 11
Training loss: 0.11848579302863221
Validation loss: 2.4917760799940174

Epoch: 6| Step: 12
Training loss: 0.15131417853705806
Validation loss: 2.4909166357978667

Epoch: 6| Step: 13
Training loss: 0.12376396565793223
Validation loss: 2.5016227142100234

Epoch: 592| Step: 0
Training loss: 0.09265405100678435
Validation loss: 2.5173068634758646

Epoch: 6| Step: 1
Training loss: 0.0893913728465667
Validation loss: 2.496713453056247

Epoch: 6| Step: 2
Training loss: 0.17261265553872052
Validation loss: 2.4909780667011794

Epoch: 6| Step: 3
Training loss: 0.1508417917175446
Validation loss: 2.497556284216958

Epoch: 6| Step: 4
Training loss: 0.0942853997587685
Validation loss: 2.4835861934023344

Epoch: 6| Step: 5
Training loss: 0.1893006330456353
Validation loss: 2.5017491651090764

Epoch: 6| Step: 6
Training loss: 0.059896218602696706
Validation loss: 2.48674704115843

Epoch: 6| Step: 7
Training loss: 0.11690822543412907
Validation loss: 2.489206550649082

Epoch: 6| Step: 8
Training loss: 0.14584394966947178
Validation loss: 2.4911472555230483

Epoch: 6| Step: 9
Training loss: 0.09959116937653194
Validation loss: 2.479422814474501

Epoch: 6| Step: 10
Training loss: 0.1294349607248969
Validation loss: 2.4730708860276374

Epoch: 6| Step: 11
Training loss: 0.0740068636031736
Validation loss: 2.47017072922126

Epoch: 6| Step: 12
Training loss: 0.11545672221122574
Validation loss: 2.5211467549772326

Epoch: 6| Step: 13
Training loss: 0.14954226111485838
Validation loss: 2.5074384776706395

Epoch: 593| Step: 0
Training loss: 0.1394951586058399
Validation loss: 2.499331597221189

Epoch: 6| Step: 1
Training loss: 0.1106126532291787
Validation loss: 2.513652159645755

Epoch: 6| Step: 2
Training loss: 0.19146213883307808
Validation loss: 2.4981920483196856

Epoch: 6| Step: 3
Training loss: 0.1618495202815601
Validation loss: 2.485653699425836

Epoch: 6| Step: 4
Training loss: 0.14329208307070773
Validation loss: 2.4471823048763306

Epoch: 6| Step: 5
Training loss: 0.1261114906040941
Validation loss: 2.4218981331240785

Epoch: 6| Step: 6
Training loss: 0.2447721629117338
Validation loss: 2.40581939556264

Epoch: 6| Step: 7
Training loss: 0.17635596948307913
Validation loss: 2.4698093436942514

Epoch: 6| Step: 8
Training loss: 0.10250558306590629
Validation loss: 2.4520223530112792

Epoch: 6| Step: 9
Training loss: 0.08396405706150242
Validation loss: 2.4544434978899883

Epoch: 6| Step: 10
Training loss: 0.11932943189029441
Validation loss: 2.466947230397127

Epoch: 6| Step: 11
Training loss: 0.11155143727020385
Validation loss: 2.5078308638416993

Epoch: 6| Step: 12
Training loss: 0.12390456547860818
Validation loss: 2.521515313564091

Epoch: 6| Step: 13
Training loss: 0.060637920897793775
Validation loss: 2.5260682314681198

Epoch: 594| Step: 0
Training loss: 0.09235144056288422
Validation loss: 2.503578825398607

Epoch: 6| Step: 1
Training loss: 0.13767351830254732
Validation loss: 2.5116176361281055

Epoch: 6| Step: 2
Training loss: 0.15526135115697887
Validation loss: 2.512926522742914

Epoch: 6| Step: 3
Training loss: 0.10815048211045813
Validation loss: 2.5241900063997376

Epoch: 6| Step: 4
Training loss: 0.14311140739246409
Validation loss: 2.491966768320543

Epoch: 6| Step: 5
Training loss: 0.13827796517258387
Validation loss: 2.502788563584605

Epoch: 6| Step: 6
Training loss: 0.11730045993769436
Validation loss: 2.4931123544829483

Epoch: 6| Step: 7
Training loss: 0.07538596358737126
Validation loss: 2.487680782666862

Epoch: 6| Step: 8
Training loss: 0.12953400202865856
Validation loss: 2.4759834833915755

Epoch: 6| Step: 9
Training loss: 0.10220967931395099
Validation loss: 2.506686362888651

Epoch: 6| Step: 10
Training loss: 0.08553494648964963
Validation loss: 2.476315106964917

Epoch: 6| Step: 11
Training loss: 0.11303338112666401
Validation loss: 2.4708055832867855

Epoch: 6| Step: 12
Training loss: 0.15852587943564836
Validation loss: 2.4931642126271125

Epoch: 6| Step: 13
Training loss: 0.09286669009705988
Validation loss: 2.4831892390323627

Epoch: 595| Step: 0
Training loss: 0.098458589459397
Validation loss: 2.4946881113330894

Epoch: 6| Step: 1
Training loss: 0.16055164724529297
Validation loss: 2.4919031416668593

Epoch: 6| Step: 2
Training loss: 0.10733655662532984
Validation loss: 2.479067551150017

Epoch: 6| Step: 3
Training loss: 0.0687871728179387
Validation loss: 2.462762833018199

Epoch: 6| Step: 4
Training loss: 0.10797641842849534
Validation loss: 2.454632845056217

Epoch: 6| Step: 5
Training loss: 0.07247564045812073
Validation loss: 2.4900876639361185

Epoch: 6| Step: 6
Training loss: 0.16417017309886564
Validation loss: 2.4450428854140216

Epoch: 6| Step: 7
Training loss: 0.1522843293924305
Validation loss: 2.496521383638616

Epoch: 6| Step: 8
Training loss: 0.11693310543332357
Validation loss: 2.5153308855198917

Epoch: 6| Step: 9
Training loss: 0.10896057993725636
Validation loss: 2.5235419381771944

Epoch: 6| Step: 10
Training loss: 0.08458044638937294
Validation loss: 2.503668802328533

Epoch: 6| Step: 11
Training loss: 0.11552768894250397
Validation loss: 2.525977926377224

Epoch: 6| Step: 12
Training loss: 0.11749401537639333
Validation loss: 2.489408205675681

Epoch: 6| Step: 13
Training loss: 0.08809378508651348
Validation loss: 2.506112593728525

Epoch: 596| Step: 0
Training loss: 0.10178794963701755
Validation loss: 2.480958070260385

Epoch: 6| Step: 1
Training loss: 0.1060104938409467
Validation loss: 2.466839319008061

Epoch: 6| Step: 2
Training loss: 0.11898429964530297
Validation loss: 2.466192875230121

Epoch: 6| Step: 3
Training loss: 0.18583536308046805
Validation loss: 2.4776735684428566

Epoch: 6| Step: 4
Training loss: 0.10024341112885005
Validation loss: 2.4649890743513443

Epoch: 6| Step: 5
Training loss: 0.09982812460712619
Validation loss: 2.50179830497385

Epoch: 6| Step: 6
Training loss: 0.10460239908492272
Validation loss: 2.4641932548675904

Epoch: 6| Step: 7
Training loss: 0.10272866838800203
Validation loss: 2.503181417493929

Epoch: 6| Step: 8
Training loss: 0.08361789118589999
Validation loss: 2.474952081767688

Epoch: 6| Step: 9
Training loss: 0.1567576981636047
Validation loss: 2.4953782994535736

Epoch: 6| Step: 10
Training loss: 0.07222056595030792
Validation loss: 2.51552442429732

Epoch: 6| Step: 11
Training loss: 0.1416134072973148
Validation loss: 2.492284286789595

Epoch: 6| Step: 12
Training loss: 0.1330109544066447
Validation loss: 2.5065115083272045

Epoch: 6| Step: 13
Training loss: 0.055572002812879814
Validation loss: 2.5045889187023236

Epoch: 597| Step: 0
Training loss: 0.0775517682684388
Validation loss: 2.507253925120836

Epoch: 6| Step: 1
Training loss: 0.08287768542497262
Validation loss: 2.5038802480058635

Epoch: 6| Step: 2
Training loss: 0.07097045692673885
Validation loss: 2.4925759853287626

Epoch: 6| Step: 3
Training loss: 0.07326218014284261
Validation loss: 2.493236515261723

Epoch: 6| Step: 4
Training loss: 0.08885963114377395
Validation loss: 2.475916091719474

Epoch: 6| Step: 5
Training loss: 0.1599097448276101
Validation loss: 2.480797914926233

Epoch: 6| Step: 6
Training loss: 0.10796495487537694
Validation loss: 2.495975487282356

Epoch: 6| Step: 7
Training loss: 0.09592933584323242
Validation loss: 2.4826068174967495

Epoch: 6| Step: 8
Training loss: 0.09545175471331532
Validation loss: 2.470133420686899

Epoch: 6| Step: 9
Training loss: 0.14610680557503042
Validation loss: 2.522321551761002

Epoch: 6| Step: 10
Training loss: 0.12931953992159437
Validation loss: 2.4960976405041766

Epoch: 6| Step: 11
Training loss: 0.16855600186362618
Validation loss: 2.494413294540088

Epoch: 6| Step: 12
Training loss: 0.11689733901830579
Validation loss: 2.4731534609514814

Epoch: 6| Step: 13
Training loss: 0.11974308248431705
Validation loss: 2.489012109777233

Epoch: 598| Step: 0
Training loss: 0.07050783125647297
Validation loss: 2.5192950552084876

Epoch: 6| Step: 1
Training loss: 0.10253981181279649
Validation loss: 2.471130695705962

Epoch: 6| Step: 2
Training loss: 0.10425179450202428
Validation loss: 2.4632625005840616

Epoch: 6| Step: 3
Training loss: 0.15144434162347223
Validation loss: 2.4898722906515025

Epoch: 6| Step: 4
Training loss: 0.11991208483840737
Validation loss: 2.4739668050123327

Epoch: 6| Step: 5
Training loss: 0.14889651151596686
Validation loss: 2.4868805181808256

Epoch: 6| Step: 6
Training loss: 0.10711294314328072
Validation loss: 2.4524365534110237

Epoch: 6| Step: 7
Training loss: 0.10573072921681949
Validation loss: 2.5013803209307994

Epoch: 6| Step: 8
Training loss: 0.06631428998882642
Validation loss: 2.498828603250822

Epoch: 6| Step: 9
Training loss: 0.07785556346529066
Validation loss: 2.51218958772612

Epoch: 6| Step: 10
Training loss: 0.13938872990315762
Validation loss: 2.5229913384494287

Epoch: 6| Step: 11
Training loss: 0.09719548243218107
Validation loss: 2.5245743663160467

Epoch: 6| Step: 12
Training loss: 0.16000226224104663
Validation loss: 2.516076029875833

Epoch: 6| Step: 13
Training loss: 0.08179071333047502
Validation loss: 2.550916435032509

Epoch: 599| Step: 0
Training loss: 0.08932637434106862
Validation loss: 2.538623309775532

Epoch: 6| Step: 1
Training loss: 0.14507566836140873
Validation loss: 2.512967893814439

Epoch: 6| Step: 2
Training loss: 0.10695258716534403
Validation loss: 2.500270812430685

Epoch: 6| Step: 3
Training loss: 0.05147712097814494
Validation loss: 2.477701691339235

Epoch: 6| Step: 4
Training loss: 0.17319822301883608
Validation loss: 2.49300173792597

Epoch: 6| Step: 5
Training loss: 0.11044969668230153
Validation loss: 2.4535750527593176

Epoch: 6| Step: 6
Training loss: 0.10832506566258071
Validation loss: 2.4868870172671906

Epoch: 6| Step: 7
Training loss: 0.13881518789365846
Validation loss: 2.5074477141432596

Epoch: 6| Step: 8
Training loss: 0.191560614873749
Validation loss: 2.501698831458833

Epoch: 6| Step: 9
Training loss: 0.12614448208666632
Validation loss: 2.486933261623991

Epoch: 6| Step: 10
Training loss: 0.08264814883375614
Validation loss: 2.5258394857943314

Epoch: 6| Step: 11
Training loss: 0.16897670917168636
Validation loss: 2.5341836831644224

Epoch: 6| Step: 12
Training loss: 0.0947048811335105
Validation loss: 2.5510676867833784

Epoch: 6| Step: 13
Training loss: 0.19082826814495413
Validation loss: 2.5409831855050586

Epoch: 600| Step: 0
Training loss: 0.12315286506810866
Validation loss: 2.529136904973713

Epoch: 6| Step: 1
Training loss: 0.0794427395721998
Validation loss: 2.533695842572631

Epoch: 6| Step: 2
Training loss: 0.09017394899519114
Validation loss: 2.460114019946121

Epoch: 6| Step: 3
Training loss: 0.16280302761514379
Validation loss: 2.469165193871277

Epoch: 6| Step: 4
Training loss: 0.09794755403695707
Validation loss: 2.470526721938893

Epoch: 6| Step: 5
Training loss: 0.1453057236270706
Validation loss: 2.458061933961541

Epoch: 6| Step: 6
Training loss: 0.09139767040025662
Validation loss: 2.4256784858117317

Epoch: 6| Step: 7
Training loss: 0.15003613394392099
Validation loss: 2.449757422759872

Epoch: 6| Step: 8
Training loss: 0.0893539053358041
Validation loss: 2.4358950427574473

Epoch: 6| Step: 9
Training loss: 0.14008803635194417
Validation loss: 2.462286847703959

Epoch: 6| Step: 10
Training loss: 0.13593965342339706
Validation loss: 2.4771005378525235

Epoch: 6| Step: 11
Training loss: 0.13398443005174224
Validation loss: 2.4472732532696173

Epoch: 6| Step: 12
Training loss: 0.1011095998638036
Validation loss: 2.458059149278096

Epoch: 6| Step: 13
Training loss: 0.09170092986341574
Validation loss: 2.4572907236188346

Epoch: 601| Step: 0
Training loss: 0.09131387705485865
Validation loss: 2.510199215249738

Epoch: 6| Step: 1
Training loss: 0.1838271199955605
Validation loss: 2.4999471597317147

Epoch: 6| Step: 2
Training loss: 0.11217492111423048
Validation loss: 2.5145638108541704

Epoch: 6| Step: 3
Training loss: 0.07086931397615415
Validation loss: 2.514080552084933

Epoch: 6| Step: 4
Training loss: 0.14573355579401595
Validation loss: 2.4671913321147065

Epoch: 6| Step: 5
Training loss: 0.07905655333900115
Validation loss: 2.463468552155081

Epoch: 6| Step: 6
Training loss: 0.277307508008009
Validation loss: 2.466182693174973

Epoch: 6| Step: 7
Training loss: 0.20754365668586933
Validation loss: 2.4775394163854534

Epoch: 6| Step: 8
Training loss: 0.1428680216210589
Validation loss: 2.4332725586706725

Epoch: 6| Step: 9
Training loss: 0.1087932356439786
Validation loss: 2.4439451615942693

Epoch: 6| Step: 10
Training loss: 0.10956357979446388
Validation loss: 2.45320354790775

Epoch: 6| Step: 11
Training loss: 0.24859461794401383
Validation loss: 2.475582182523106

Epoch: 6| Step: 12
Training loss: 0.09641984739352291
Validation loss: 2.517432962669182

Epoch: 6| Step: 13
Training loss: 0.2042456943888091
Validation loss: 2.5092010022534192

Epoch: 602| Step: 0
Training loss: 0.1164454250213581
Validation loss: 2.5081157504172076

Epoch: 6| Step: 1
Training loss: 0.14089902035323223
Validation loss: 2.5049824461349433

Epoch: 6| Step: 2
Training loss: 0.12864922417355976
Validation loss: 2.5007048761682737

Epoch: 6| Step: 3
Training loss: 0.19630989988949699
Validation loss: 2.4934322388603314

Epoch: 6| Step: 4
Training loss: 0.21545153392093874
Validation loss: 2.4878501163782003

Epoch: 6| Step: 5
Training loss: 0.16919173201970703
Validation loss: 2.4889758829448003

Epoch: 6| Step: 6
Training loss: 0.13671287115264133
Validation loss: 2.511621561787026

Epoch: 6| Step: 7
Training loss: 0.13261272327398188
Validation loss: 2.471439828231686

Epoch: 6| Step: 8
Training loss: 0.1395073024110024
Validation loss: 2.509595976210656

Epoch: 6| Step: 9
Training loss: 0.17463554425172803
Validation loss: 2.4607067358706507

Epoch: 6| Step: 10
Training loss: 0.16037237308778451
Validation loss: 2.4754649821295924

Epoch: 6| Step: 11
Training loss: 0.12370320526328596
Validation loss: 2.5034518499313836

Epoch: 6| Step: 12
Training loss: 0.09757172741468434
Validation loss: 2.471633616201799

Epoch: 6| Step: 13
Training loss: 0.14399761843822945
Validation loss: 2.4750736463852427

Epoch: 603| Step: 0
Training loss: 0.12360224956217572
Validation loss: 2.459634188159996

Epoch: 6| Step: 1
Training loss: 0.10587486474001508
Validation loss: 2.4502508359007207

Epoch: 6| Step: 2
Training loss: 0.12583323760797427
Validation loss: 2.42528462073307

Epoch: 6| Step: 3
Training loss: 0.17317180278920788
Validation loss: 2.467853327746491

Epoch: 6| Step: 4
Training loss: 0.0984832035036176
Validation loss: 2.464196190233041

Epoch: 6| Step: 5
Training loss: 0.14069389271669808
Validation loss: 2.443201569187257

Epoch: 6| Step: 6
Training loss: 0.08680610166483863
Validation loss: 2.476170335513867

Epoch: 6| Step: 7
Training loss: 0.12175960289180648
Validation loss: 2.4857366571907846

Epoch: 6| Step: 8
Training loss: 0.11397577591267127
Validation loss: 2.5464526420822473

Epoch: 6| Step: 9
Training loss: 0.10818580874482485
Validation loss: 2.507496677921948

Epoch: 6| Step: 10
Training loss: 0.1701238954975591
Validation loss: 2.53314879740543

Epoch: 6| Step: 11
Training loss: 0.1597785391869504
Validation loss: 2.517925908245689

Epoch: 6| Step: 12
Training loss: 0.1379573439077077
Validation loss: 2.538868884457796

Epoch: 6| Step: 13
Training loss: 0.14526587091913176
Validation loss: 2.510828774687479

Epoch: 604| Step: 0
Training loss: 0.06747661502284445
Validation loss: 2.48994205722404

Epoch: 6| Step: 1
Training loss: 0.09334245153289623
Validation loss: 2.454619156993696

Epoch: 6| Step: 2
Training loss: 0.17016330098377183
Validation loss: 2.4652262363729793

Epoch: 6| Step: 3
Training loss: 0.23791171169939082
Validation loss: 2.461118007016212

Epoch: 6| Step: 4
Training loss: 0.14477246363545257
Validation loss: 2.4436772955282486

Epoch: 6| Step: 5
Training loss: 0.09804841454501655
Validation loss: 2.4897961516329032

Epoch: 6| Step: 6
Training loss: 0.16730228432143554
Validation loss: 2.4903479042369736

Epoch: 6| Step: 7
Training loss: 0.1292027329524167
Validation loss: 2.524647767800384

Epoch: 6| Step: 8
Training loss: 0.0966745047673241
Validation loss: 2.568759866556855

Epoch: 6| Step: 9
Training loss: 0.1643084090932642
Validation loss: 2.597302840842829

Epoch: 6| Step: 10
Training loss: 0.17057331221051739
Validation loss: 2.5629120642225445

Epoch: 6| Step: 11
Training loss: 0.11845419472288239
Validation loss: 2.5815912903566995

Epoch: 6| Step: 12
Training loss: 0.08055141193847248
Validation loss: 2.5659656024934634

Epoch: 6| Step: 13
Training loss: 0.06488057564445684
Validation loss: 2.5592910038229197

Epoch: 605| Step: 0
Training loss: 0.12591478030435738
Validation loss: 2.5390531998204495

Epoch: 6| Step: 1
Training loss: 0.1635555769133363
Validation loss: 2.511565003534305

Epoch: 6| Step: 2
Training loss: 0.11412492180599111
Validation loss: 2.5175312005755117

Epoch: 6| Step: 3
Training loss: 0.09218308692811232
Validation loss: 2.537371132580632

Epoch: 6| Step: 4
Training loss: 0.2001297820232933
Validation loss: 2.5042836693177275

Epoch: 6| Step: 5
Training loss: 0.1593499180280207
Validation loss: 2.501124459334198

Epoch: 6| Step: 6
Training loss: 0.09759041474390637
Validation loss: 2.536626041390987

Epoch: 6| Step: 7
Training loss: 0.0970487342276197
Validation loss: 2.580642333336788

Epoch: 6| Step: 8
Training loss: 0.13084904074785547
Validation loss: 2.562268741676137

Epoch: 6| Step: 9
Training loss: 0.11939817872007212
Validation loss: 2.551423111767858

Epoch: 6| Step: 10
Training loss: 0.16298214813450437
Validation loss: 2.5993727598703935

Epoch: 6| Step: 11
Training loss: 0.1719909190370048
Validation loss: 2.536828402805907

Epoch: 6| Step: 12
Training loss: 0.11985974519662748
Validation loss: 2.5104994125593776

Epoch: 6| Step: 13
Training loss: 0.10651162907750555
Validation loss: 2.4605815150129104

Epoch: 606| Step: 0
Training loss: 0.16647514251428483
Validation loss: 2.472038518082468

Epoch: 6| Step: 1
Training loss: 0.07591320401709635
Validation loss: 2.464924382110307

Epoch: 6| Step: 2
Training loss: 0.1572665880328206
Validation loss: 2.5028105713800315

Epoch: 6| Step: 3
Training loss: 0.12237541217754024
Validation loss: 2.4725663928683064

Epoch: 6| Step: 4
Training loss: 0.07178142432207024
Validation loss: 2.472592429185495

Epoch: 6| Step: 5
Training loss: 0.18915786544838514
Validation loss: 2.509864343676239

Epoch: 6| Step: 6
Training loss: 0.2253588239161462
Validation loss: 2.508928420409671

Epoch: 6| Step: 7
Training loss: 0.07546755504945542
Validation loss: 2.510295734463579

Epoch: 6| Step: 8
Training loss: 0.12782841962195887
Validation loss: 2.4903895515673584

Epoch: 6| Step: 9
Training loss: 0.18042934738956298
Validation loss: 2.4988890322593114

Epoch: 6| Step: 10
Training loss: 0.12214439051736908
Validation loss: 2.46350532787122

Epoch: 6| Step: 11
Training loss: 0.11898454229051297
Validation loss: 2.4693683967634206

Epoch: 6| Step: 12
Training loss: 0.135031589723922
Validation loss: 2.4659229393583453

Epoch: 6| Step: 13
Training loss: 0.1799603339703266
Validation loss: 2.463045650760625

Epoch: 607| Step: 0
Training loss: 0.18473580424212363
Validation loss: 2.433321078843874

Epoch: 6| Step: 1
Training loss: 0.13984877881006894
Validation loss: 2.4516401497843963

Epoch: 6| Step: 2
Training loss: 0.29306641540222256
Validation loss: 2.4464138726933564

Epoch: 6| Step: 3
Training loss: 0.11886127350029277
Validation loss: 2.469870571966686

Epoch: 6| Step: 4
Training loss: 0.1621257647306602
Validation loss: 2.472757406063747

Epoch: 6| Step: 5
Training loss: 0.13929817315703927
Validation loss: 2.4875843186541275

Epoch: 6| Step: 6
Training loss: 0.13988062090143585
Validation loss: 2.4620646494443523

Epoch: 6| Step: 7
Training loss: 0.3045279990150412
Validation loss: 2.4655873674802025

Epoch: 6| Step: 8
Training loss: 0.10879249087946406
Validation loss: 2.4961111986789724

Epoch: 6| Step: 9
Training loss: 0.17974750926529717
Validation loss: 2.5092433838891055

Epoch: 6| Step: 10
Training loss: 0.1354791988976186
Validation loss: 2.5497871135935326

Epoch: 6| Step: 11
Training loss: 0.12683759714679074
Validation loss: 2.553335578148726

Epoch: 6| Step: 12
Training loss: 0.10864197805860441
Validation loss: 2.5529530650252354

Epoch: 6| Step: 13
Training loss: 0.21054397184674103
Validation loss: 2.5333717373504454

Epoch: 608| Step: 0
Training loss: 0.10892402112611592
Validation loss: 2.4978174475631674

Epoch: 6| Step: 1
Training loss: 0.09197045209167021
Validation loss: 2.529666913507598

Epoch: 6| Step: 2
Training loss: 0.10294096159311515
Validation loss: 2.467081827492432

Epoch: 6| Step: 3
Training loss: 0.20081694319101795
Validation loss: 2.4683241813786743

Epoch: 6| Step: 4
Training loss: 0.160656699557474
Validation loss: 2.466473093422146

Epoch: 6| Step: 5
Training loss: 0.13184204087434645
Validation loss: 2.4767717525562722

Epoch: 6| Step: 6
Training loss: 0.16620602068145232
Validation loss: 2.4718769302527606

Epoch: 6| Step: 7
Training loss: 0.1443682150567565
Validation loss: 2.494552084604541

Epoch: 6| Step: 8
Training loss: 0.14352939668385342
Validation loss: 2.505503643576987

Epoch: 6| Step: 9
Training loss: 0.16201479577194355
Validation loss: 2.512278234287807

Epoch: 6| Step: 10
Training loss: 0.1793934032423411
Validation loss: 2.52821768044189

Epoch: 6| Step: 11
Training loss: 0.19789395494818207
Validation loss: 2.5510995166902597

Epoch: 6| Step: 12
Training loss: 0.08146388393322312
Validation loss: 2.5166579454245483

Epoch: 6| Step: 13
Training loss: 0.22140536370702368
Validation loss: 2.5046365749895076

Epoch: 609| Step: 0
Training loss: 0.1415161730370403
Validation loss: 2.530288733540782

Epoch: 6| Step: 1
Training loss: 0.1492958972884921
Validation loss: 2.529029604585196

Epoch: 6| Step: 2
Training loss: 0.16822214751663267
Validation loss: 2.5433767554800917

Epoch: 6| Step: 3
Training loss: 0.23973031390249255
Validation loss: 2.513278554488771

Epoch: 6| Step: 4
Training loss: 0.10087446385782371
Validation loss: 2.556135071740969

Epoch: 6| Step: 5
Training loss: 0.11916822363957835
Validation loss: 2.5807456833510685

Epoch: 6| Step: 6
Training loss: 0.13412721043620196
Validation loss: 2.501058613799008

Epoch: 6| Step: 7
Training loss: 0.20342058902541746
Validation loss: 2.5196283020166517

Epoch: 6| Step: 8
Training loss: 0.1559921043672033
Validation loss: 2.4931401644106344

Epoch: 6| Step: 9
Training loss: 0.16150216627919425
Validation loss: 2.5096512631299324

Epoch: 6| Step: 10
Training loss: 0.12239676502224887
Validation loss: 2.521601916140643

Epoch: 6| Step: 11
Training loss: 0.13192423936278688
Validation loss: 2.5102891754740284

Epoch: 6| Step: 12
Training loss: 0.12934706915094113
Validation loss: 2.4808058717856807

Epoch: 6| Step: 13
Training loss: 0.25438124902064974
Validation loss: 2.5015530223220717

Epoch: 610| Step: 0
Training loss: 0.13142949784299254
Validation loss: 2.4881200874887757

Epoch: 6| Step: 1
Training loss: 0.10445088613103658
Validation loss: 2.5186353152064274

Epoch: 6| Step: 2
Training loss: 0.09106570081904343
Validation loss: 2.4794497522627093

Epoch: 6| Step: 3
Training loss: 0.19448395464362825
Validation loss: 2.5173964920546736

Epoch: 6| Step: 4
Training loss: 0.11877575880428334
Validation loss: 2.5120678710407205

Epoch: 6| Step: 5
Training loss: 0.16549391394881893
Validation loss: 2.484596036743322

Epoch: 6| Step: 6
Training loss: 0.07563937956870748
Validation loss: 2.4772421296158424

Epoch: 6| Step: 7
Training loss: 0.1407285812157746
Validation loss: 2.5142042575641375

Epoch: 6| Step: 8
Training loss: 0.21069859291551898
Validation loss: 2.5180716957772735

Epoch: 6| Step: 9
Training loss: 0.15260757929617513
Validation loss: 2.5327177594207546

Epoch: 6| Step: 10
Training loss: 0.13143707266568938
Validation loss: 2.5107978024621085

Epoch: 6| Step: 11
Training loss: 0.10879428429801372
Validation loss: 2.4962001964444105

Epoch: 6| Step: 12
Training loss: 0.10182435409900416
Validation loss: 2.488965262610883

Epoch: 6| Step: 13
Training loss: 0.21711113636994886
Validation loss: 2.4891532987010594

Epoch: 611| Step: 0
Training loss: 0.2663765681
Validation loss: 2.4906092341610555

Epoch: 6| Step: 1
Training loss: 0.14492591250777062
Validation loss: 2.53110007031057

Epoch: 6| Step: 2
Training loss: 0.1088352766103862
Validation loss: 2.491451765214789

Epoch: 6| Step: 3
Training loss: 0.14039030623784546
Validation loss: 2.5246379392903133

Epoch: 6| Step: 4
Training loss: 0.21747388037511664
Validation loss: 2.5226695316566565

Epoch: 6| Step: 5
Training loss: 0.2245874145387054
Validation loss: 2.542308684596395

Epoch: 6| Step: 6
Training loss: 0.15878617024808211
Validation loss: 2.5436167169863295

Epoch: 6| Step: 7
Training loss: 0.1307044464336388
Validation loss: 2.5247596881613887

Epoch: 6| Step: 8
Training loss: 0.21750146621451058
Validation loss: 2.490372674790476

Epoch: 6| Step: 9
Training loss: 0.18556493370115099
Validation loss: 2.505649707788916

Epoch: 6| Step: 10
Training loss: 0.12983921581343588
Validation loss: 2.467967704752446

Epoch: 6| Step: 11
Training loss: 0.138715542378715
Validation loss: 2.42915988523584

Epoch: 6| Step: 12
Training loss: 0.1833833340894313
Validation loss: 2.4484921175441676

Epoch: 6| Step: 13
Training loss: 0.32175488314001954
Validation loss: 2.442576305224293

Epoch: 612| Step: 0
Training loss: 0.16265198656187363
Validation loss: 2.406332769143674

Epoch: 6| Step: 1
Training loss: 0.18457975817534006
Validation loss: 2.4375183929346806

Epoch: 6| Step: 2
Training loss: 0.21509848145337285
Validation loss: 2.425611030839457

Epoch: 6| Step: 3
Training loss: 0.2061393979487913
Validation loss: 2.4996144622988448

Epoch: 6| Step: 4
Training loss: 0.16629894427956782
Validation loss: 2.534721312553395

Epoch: 6| Step: 5
Training loss: 0.19621998724476744
Validation loss: 2.5286384498685504

Epoch: 6| Step: 6
Training loss: 0.3579065340907479
Validation loss: 2.555262026070032

Epoch: 6| Step: 7
Training loss: 0.2006550603848245
Validation loss: 2.5532470537792205

Epoch: 6| Step: 8
Training loss: 0.14175227464763246
Validation loss: 2.493994774870486

Epoch: 6| Step: 9
Training loss: 0.20646225815502658
Validation loss: 2.4548043801076487

Epoch: 6| Step: 10
Training loss: 0.1935509589920686
Validation loss: 2.421326455598226

Epoch: 6| Step: 11
Training loss: 0.25693971111187835
Validation loss: 2.4040881757480705

Epoch: 6| Step: 12
Training loss: 0.28670416023075396
Validation loss: 2.434206476041013

Epoch: 6| Step: 13
Training loss: 0.12827769113080825
Validation loss: 2.4451035983646423

Epoch: 613| Step: 0
Training loss: 0.24634239714387848
Validation loss: 2.435195723464815

Epoch: 6| Step: 1
Training loss: 0.22914990811771663
Validation loss: 2.429074690779532

Epoch: 6| Step: 2
Training loss: 0.215261175214451
Validation loss: 2.4109084581170936

Epoch: 6| Step: 3
Training loss: 0.2134754477538995
Validation loss: 2.414804432947994

Epoch: 6| Step: 4
Training loss: 0.11204355397753353
Validation loss: 2.4216229082973273

Epoch: 6| Step: 5
Training loss: 0.21392581083976145
Validation loss: 2.459443475903825

Epoch: 6| Step: 6
Training loss: 0.1388127055108663
Validation loss: 2.4310059696186612

Epoch: 6| Step: 7
Training loss: 0.20857917863335515
Validation loss: 2.465918324448752

Epoch: 6| Step: 8
Training loss: 0.1951261966981426
Validation loss: 2.476038123591548

Epoch: 6| Step: 9
Training loss: 0.19358964175221058
Validation loss: 2.463875036979162

Epoch: 6| Step: 10
Training loss: 0.12906481642641715
Validation loss: 2.48043486598091

Epoch: 6| Step: 11
Training loss: 0.24884403722838225
Validation loss: 2.473480528376496

Epoch: 6| Step: 12
Training loss: 0.13697234204434539
Validation loss: 2.468555090196046

Epoch: 6| Step: 13
Training loss: 0.17056721879212342
Validation loss: 2.491633692604251

Epoch: 614| Step: 0
Training loss: 0.14977306047029673
Validation loss: 2.46812045989605

Epoch: 6| Step: 1
Training loss: 0.19091182220789246
Validation loss: 2.477957720729913

Epoch: 6| Step: 2
Training loss: 0.13686333232079206
Validation loss: 2.4637063030449875

Epoch: 6| Step: 3
Training loss: 0.2035652305202047
Validation loss: 2.5078313003442045

Epoch: 6| Step: 4
Training loss: 0.1256266917878671
Validation loss: 2.470863450118642

Epoch: 6| Step: 5
Training loss: 0.12571263574263083
Validation loss: 2.5388793939869303

Epoch: 6| Step: 6
Training loss: 0.375373812962909
Validation loss: 2.556318647622878

Epoch: 6| Step: 7
Training loss: 0.3265412232435444
Validation loss: 2.5111531504152356

Epoch: 6| Step: 8
Training loss: 0.13561032428973993
Validation loss: 2.5461671178779466

Epoch: 6| Step: 9
Training loss: 0.15481994791445616
Validation loss: 2.527505646066977

Epoch: 6| Step: 10
Training loss: 0.1435342112359687
Validation loss: 2.500874247533469

Epoch: 6| Step: 11
Training loss: 0.29555126004415916
Validation loss: 2.5044113974754163

Epoch: 6| Step: 12
Training loss: 0.24036549657205256
Validation loss: 2.475591794672664

Epoch: 6| Step: 13
Training loss: 0.1535677037706181
Validation loss: 2.5231199728600275

Epoch: 615| Step: 0
Training loss: 0.08950908672001467
Validation loss: 2.5591182969803405

Epoch: 6| Step: 1
Training loss: 0.1500969285519196
Validation loss: 2.6399058176737586

Epoch: 6| Step: 2
Training loss: 0.30508920891197555
Validation loss: 2.665396646226962

Epoch: 6| Step: 3
Training loss: 0.21223859942779583
Validation loss: 2.6674245083075534

Epoch: 6| Step: 4
Training loss: 0.21798364902835093
Validation loss: 2.607427461587512

Epoch: 6| Step: 5
Training loss: 0.14647125185357232
Validation loss: 2.5388275830409253

Epoch: 6| Step: 6
Training loss: 0.31666775481555764
Validation loss: 2.509975268086

Epoch: 6| Step: 7
Training loss: 0.17527216200750217
Validation loss: 2.474149673048717

Epoch: 6| Step: 8
Training loss: 0.2515193843026215
Validation loss: 2.474917410074023

Epoch: 6| Step: 9
Training loss: 0.18634085181895035
Validation loss: 2.477059086247196

Epoch: 6| Step: 10
Training loss: 0.3254062323702587
Validation loss: 2.464026532022586

Epoch: 6| Step: 11
Training loss: 0.20069675448810392
Validation loss: 2.4866255420464607

Epoch: 6| Step: 12
Training loss: 0.1478232801389586
Validation loss: 2.52734183691316

Epoch: 6| Step: 13
Training loss: 0.1857654187970329
Validation loss: 2.561205681386715

Epoch: 616| Step: 0
Training loss: 0.3433191243297726
Validation loss: 2.5668554620408135

Epoch: 6| Step: 1
Training loss: 0.297149819613708
Validation loss: 2.551577488331033

Epoch: 6| Step: 2
Training loss: 0.13819534737032682
Validation loss: 2.496785449609199

Epoch: 6| Step: 3
Training loss: 0.16244909011704006
Validation loss: 2.448880174129128

Epoch: 6| Step: 4
Training loss: 0.21815233668659068
Validation loss: 2.3886798631818613

Epoch: 6| Step: 5
Training loss: 0.36065061818700156
Validation loss: 2.4428558805313045

Epoch: 6| Step: 6
Training loss: 0.13415137190694892
Validation loss: 2.458025358405372

Epoch: 6| Step: 7
Training loss: 0.20993116300739456
Validation loss: 2.408137787663272

Epoch: 6| Step: 8
Training loss: 0.23724815103334976
Validation loss: 2.4392086085064055

Epoch: 6| Step: 9
Training loss: 0.19037165613425014
Validation loss: 2.475129372985922

Epoch: 6| Step: 10
Training loss: 0.24292988205622998
Validation loss: 2.44815076251067

Epoch: 6| Step: 11
Training loss: 0.1820665308934656
Validation loss: 2.480790663592893

Epoch: 6| Step: 12
Training loss: 0.18507264418596334
Validation loss: 2.4746253867637007

Epoch: 6| Step: 13
Training loss: 0.19439314953744055
Validation loss: 2.46970358360929

Epoch: 617| Step: 0
Training loss: 0.22491650522280912
Validation loss: 2.5162972008393996

Epoch: 6| Step: 1
Training loss: 0.1820378216388116
Validation loss: 2.495192636051069

Epoch: 6| Step: 2
Training loss: 0.15209054690284576
Validation loss: 2.494350947183374

Epoch: 6| Step: 3
Training loss: 0.22295724868516525
Validation loss: 2.4888708930157257

Epoch: 6| Step: 4
Training loss: 0.19423906029822618
Validation loss: 2.4933009314865076

Epoch: 6| Step: 5
Training loss: 0.2234772386759047
Validation loss: 2.4955247950212343

Epoch: 6| Step: 6
Training loss: 0.20798381255048498
Validation loss: 2.4861454412398714

Epoch: 6| Step: 7
Training loss: 0.13944889030117594
Validation loss: 2.527367380459072

Epoch: 6| Step: 8
Training loss: 0.2366767314091025
Validation loss: 2.5473140023895153

Epoch: 6| Step: 9
Training loss: 0.17555081840537323
Validation loss: 2.531363491409171

Epoch: 6| Step: 10
Training loss: 0.2034029892393279
Validation loss: 2.5241635064681103

Epoch: 6| Step: 11
Training loss: 0.13612096754122927
Validation loss: 2.501685657110915

Epoch: 6| Step: 12
Training loss: 0.15218191231568554
Validation loss: 2.4978518147328788

Epoch: 6| Step: 13
Training loss: 0.23694401871627563
Validation loss: 2.4884133291237016

Epoch: 618| Step: 0
Training loss: 0.13746488512923158
Validation loss: 2.5038707546920147

Epoch: 6| Step: 1
Training loss: 0.1635351789204076
Validation loss: 2.507023130454269

Epoch: 6| Step: 2
Training loss: 0.13088865095009025
Validation loss: 2.5046194098641523

Epoch: 6| Step: 3
Training loss: 0.09316101429109176
Validation loss: 2.5100853215010246

Epoch: 6| Step: 4
Training loss: 0.16395863583180184
Validation loss: 2.5132816105219598

Epoch: 6| Step: 5
Training loss: 0.14240406463843108
Validation loss: 2.5210934874831854

Epoch: 6| Step: 6
Training loss: 0.16748955482325925
Validation loss: 2.510250961423546

Epoch: 6| Step: 7
Training loss: 0.15880652140488674
Validation loss: 2.4771708074609307

Epoch: 6| Step: 8
Training loss: 0.11576387017550002
Validation loss: 2.474457299648503

Epoch: 6| Step: 9
Training loss: 0.18812020366992568
Validation loss: 2.4180913801932244

Epoch: 6| Step: 10
Training loss: 0.11139210318243947
Validation loss: 2.4705232415245053

Epoch: 6| Step: 11
Training loss: 0.10966403271345264
Validation loss: 2.472658135931592

Epoch: 6| Step: 12
Training loss: 0.09071818115891771
Validation loss: 2.4507261416058284

Epoch: 6| Step: 13
Training loss: 0.14222223465434325
Validation loss: 2.4497380849017927

Epoch: 619| Step: 0
Training loss: 0.13517773545661446
Validation loss: 2.4733801968770095

Epoch: 6| Step: 1
Training loss: 0.12901750734001782
Validation loss: 2.471070483208147

Epoch: 6| Step: 2
Training loss: 0.07180549432863403
Validation loss: 2.4393372018463677

Epoch: 6| Step: 3
Training loss: 0.15443205645842864
Validation loss: 2.4635210738580664

Epoch: 6| Step: 4
Training loss: 0.10835056708498399
Validation loss: 2.468689542512724

Epoch: 6| Step: 5
Training loss: 0.16077488535377354
Validation loss: 2.463939922205168

Epoch: 6| Step: 6
Training loss: 0.22303106315405066
Validation loss: 2.4449031261367216

Epoch: 6| Step: 7
Training loss: 0.15464818772818295
Validation loss: 2.47131030065178

Epoch: 6| Step: 8
Training loss: 0.10685865833596032
Validation loss: 2.4665372523831275

Epoch: 6| Step: 9
Training loss: 0.08181326718294882
Validation loss: 2.485105507608661

Epoch: 6| Step: 10
Training loss: 0.11196277650011305
Validation loss: 2.4993291252094743

Epoch: 6| Step: 11
Training loss: 0.18683553219894228
Validation loss: 2.499217879074306

Epoch: 6| Step: 12
Training loss: 0.1092765143314415
Validation loss: 2.4950092296251665

Epoch: 6| Step: 13
Training loss: 0.0960530190867839
Validation loss: 2.5242229369404434

Epoch: 620| Step: 0
Training loss: 0.13107429477107949
Validation loss: 2.459904801617375

Epoch: 6| Step: 1
Training loss: 0.10768779439216176
Validation loss: 2.491083016189649

Epoch: 6| Step: 2
Training loss: 0.1490669831815348
Validation loss: 2.5267069285734234

Epoch: 6| Step: 3
Training loss: 0.1127842367185821
Validation loss: 2.5284361330912595

Epoch: 6| Step: 4
Training loss: 0.18547507452846954
Validation loss: 2.53821820858282

Epoch: 6| Step: 5
Training loss: 0.13238007608772723
Validation loss: 2.4935550060486036

Epoch: 6| Step: 6
Training loss: 0.11263128971029088
Validation loss: 2.5078172708907527

Epoch: 6| Step: 7
Training loss: 0.1043083811424462
Validation loss: 2.48851337799923

Epoch: 6| Step: 8
Training loss: 0.14139765823986702
Validation loss: 2.509924484517133

Epoch: 6| Step: 9
Training loss: 0.16786577705631925
Validation loss: 2.4817207043073166

Epoch: 6| Step: 10
Training loss: 0.1516171391305666
Validation loss: 2.4721860617585962

Epoch: 6| Step: 11
Training loss: 0.1689963511730491
Validation loss: 2.456618273026548

Epoch: 6| Step: 12
Training loss: 0.10726686043524494
Validation loss: 2.4446469919893548

Epoch: 6| Step: 13
Training loss: 0.10613378381828709
Validation loss: 2.4442605060191505

Epoch: 621| Step: 0
Training loss: 0.13925266871643063
Validation loss: 2.4582185052743792

Epoch: 6| Step: 1
Training loss: 0.10139596563656789
Validation loss: 2.436517162866898

Epoch: 6| Step: 2
Training loss: 0.13904302251691245
Validation loss: 2.4538273524036303

Epoch: 6| Step: 3
Training loss: 0.18659872762416443
Validation loss: 2.419352939615222

Epoch: 6| Step: 4
Training loss: 0.13743194120319072
Validation loss: 2.4593164498840334

Epoch: 6| Step: 5
Training loss: 0.14183622187378703
Validation loss: 2.4361489534939857

Epoch: 6| Step: 6
Training loss: 0.09944490804836485
Validation loss: 2.4217113597046285

Epoch: 6| Step: 7
Training loss: 0.10374926345632692
Validation loss: 2.4346223319702824

Epoch: 6| Step: 8
Training loss: 0.13906207727518016
Validation loss: 2.429557778629023

Epoch: 6| Step: 9
Training loss: 0.16775727266324184
Validation loss: 2.462306819201303

Epoch: 6| Step: 10
Training loss: 0.10277581358235902
Validation loss: 2.4503438133566218

Epoch: 6| Step: 11
Training loss: 0.12369943333415434
Validation loss: 2.4699438668184333

Epoch: 6| Step: 12
Training loss: 0.09116977195635075
Validation loss: 2.482241536343765

Epoch: 6| Step: 13
Training loss: 0.13077021165977235
Validation loss: 2.4865913743776344

Epoch: 622| Step: 0
Training loss: 0.10302386345793003
Validation loss: 2.465590280910451

Epoch: 6| Step: 1
Training loss: 0.12207955897597486
Validation loss: 2.495665805794374

Epoch: 6| Step: 2
Training loss: 0.1360648731380445
Validation loss: 2.4818568501692115

Epoch: 6| Step: 3
Training loss: 0.18974818033670213
Validation loss: 2.5129677050839994

Epoch: 6| Step: 4
Training loss: 0.11595715934459774
Validation loss: 2.525016522523537

Epoch: 6| Step: 5
Training loss: 0.11161613853849749
Validation loss: 2.4545313504244977

Epoch: 6| Step: 6
Training loss: 0.09894073689600426
Validation loss: 2.4570907276992067

Epoch: 6| Step: 7
Training loss: 0.11079681922637909
Validation loss: 2.4501731140875593

Epoch: 6| Step: 8
Training loss: 0.15456409492934653
Validation loss: 2.4417114392581625

Epoch: 6| Step: 9
Training loss: 0.2429507748740825
Validation loss: 2.408487565275808

Epoch: 6| Step: 10
Training loss: 0.1695096177921315
Validation loss: 2.4434679078631065

Epoch: 6| Step: 11
Training loss: 0.1467293344179688
Validation loss: 2.4550823039631813

Epoch: 6| Step: 12
Training loss: 0.13882065568836768
Validation loss: 2.469317647052233

Epoch: 6| Step: 13
Training loss: 0.11394690329088906
Validation loss: 2.4923351098956656

Epoch: 623| Step: 0
Training loss: 0.1373734127188142
Validation loss: 2.496251289002184

Epoch: 6| Step: 1
Training loss: 0.126425807038836
Validation loss: 2.500743541588349

Epoch: 6| Step: 2
Training loss: 0.18013533471642998
Validation loss: 2.5379298427756667

Epoch: 6| Step: 3
Training loss: 0.11962075497630018
Validation loss: 2.5039198805641973

Epoch: 6| Step: 4
Training loss: 0.1403946844839737
Validation loss: 2.450993238358127

Epoch: 6| Step: 5
Training loss: 0.10245730455817255
Validation loss: 2.463862460528255

Epoch: 6| Step: 6
Training loss: 0.12093421209533281
Validation loss: 2.4432777437118167

Epoch: 6| Step: 7
Training loss: 0.11831461166974995
Validation loss: 2.467674063488391

Epoch: 6| Step: 8
Training loss: 0.12605746576766105
Validation loss: 2.4402307233788996

Epoch: 6| Step: 9
Training loss: 0.13595169694801773
Validation loss: 2.439426340887987

Epoch: 6| Step: 10
Training loss: 0.20381578945440398
Validation loss: 2.4318166598646327

Epoch: 6| Step: 11
Training loss: 0.10111788483710588
Validation loss: 2.4403644040873815

Epoch: 6| Step: 12
Training loss: 0.1374189023883183
Validation loss: 2.4600852874923382

Epoch: 6| Step: 13
Training loss: 0.16154360570310428
Validation loss: 2.4314577757004385

Epoch: 624| Step: 0
Training loss: 0.1488086177026319
Validation loss: 2.4838295810814235

Epoch: 6| Step: 1
Training loss: 0.11848819036678038
Validation loss: 2.4823378454816782

Epoch: 6| Step: 2
Training loss: 0.17843383401154606
Validation loss: 2.503096029589622

Epoch: 6| Step: 3
Training loss: 0.17915839579994092
Validation loss: 2.5120590230300004

Epoch: 6| Step: 4
Training loss: 0.13623729128143902
Validation loss: 2.4793136045060566

Epoch: 6| Step: 5
Training loss: 0.07502079504031593
Validation loss: 2.478116807343591

Epoch: 6| Step: 6
Training loss: 0.13923487748603447
Validation loss: 2.4777475202156176

Epoch: 6| Step: 7
Training loss: 0.15115224281994794
Validation loss: 2.4623184540699525

Epoch: 6| Step: 8
Training loss: 0.16464167498438115
Validation loss: 2.4225193030675993

Epoch: 6| Step: 9
Training loss: 0.12212327189818804
Validation loss: 2.424828103504981

Epoch: 6| Step: 10
Training loss: 0.17709975073014417
Validation loss: 2.4509339186396226

Epoch: 6| Step: 11
Training loss: 0.10006296905923492
Validation loss: 2.450991733744353

Epoch: 6| Step: 12
Training loss: 0.07491015265491081
Validation loss: 2.471112634911769

Epoch: 6| Step: 13
Training loss: 0.1368356205193074
Validation loss: 2.4849334004636305

Epoch: 625| Step: 0
Training loss: 0.08418222897049792
Validation loss: 2.502828083344098

Epoch: 6| Step: 1
Training loss: 0.16610241472605078
Validation loss: 2.5378947546360333

Epoch: 6| Step: 2
Training loss: 0.15196679625019116
Validation loss: 2.521132771148753

Epoch: 6| Step: 3
Training loss: 0.13965522642906467
Validation loss: 2.5069870779890815

Epoch: 6| Step: 4
Training loss: 0.12695881757444588
Validation loss: 2.5201141611594147

Epoch: 6| Step: 5
Training loss: 0.08234819422858684
Validation loss: 2.486507996119374

Epoch: 6| Step: 6
Training loss: 0.10986791389022846
Validation loss: 2.481881246325234

Epoch: 6| Step: 7
Training loss: 0.143340340008041
Validation loss: 2.465562395228251

Epoch: 6| Step: 8
Training loss: 0.16370734875076215
Validation loss: 2.4619889697642363

Epoch: 6| Step: 9
Training loss: 0.14080314478674366
Validation loss: 2.45641022746446

Epoch: 6| Step: 10
Training loss: 0.10139028455107153
Validation loss: 2.447839738260611

Epoch: 6| Step: 11
Training loss: 0.1725254052828202
Validation loss: 2.4325923771118965

Epoch: 6| Step: 12
Training loss: 0.08360666627564978
Validation loss: 2.4396096800363156

Epoch: 6| Step: 13
Training loss: 0.08055838053638607
Validation loss: 2.4587115217091897

Epoch: 626| Step: 0
Training loss: 0.10580105882044524
Validation loss: 2.479632066546892

Epoch: 6| Step: 1
Training loss: 0.10649483954660714
Validation loss: 2.5115129863738916

Epoch: 6| Step: 2
Training loss: 0.13615014500881686
Validation loss: 2.4906201109903354

Epoch: 6| Step: 3
Training loss: 0.15879458081180514
Validation loss: 2.5323785544576283

Epoch: 6| Step: 4
Training loss: 0.16767182831500957
Validation loss: 2.527027084992946

Epoch: 6| Step: 5
Training loss: 0.1400305315768425
Validation loss: 2.5179255503639317

Epoch: 6| Step: 6
Training loss: 0.08133530585974698
Validation loss: 2.5101685038589143

Epoch: 6| Step: 7
Training loss: 0.13184634979950666
Validation loss: 2.5038505925432473

Epoch: 6| Step: 8
Training loss: 0.12709090019456476
Validation loss: 2.4784209707843563

Epoch: 6| Step: 9
Training loss: 0.18734124535929714
Validation loss: 2.4537606952862863

Epoch: 6| Step: 10
Training loss: 0.1323538180533358
Validation loss: 2.4957462299768847

Epoch: 6| Step: 11
Training loss: 0.1571950821725775
Validation loss: 2.511341701847153

Epoch: 6| Step: 12
Training loss: 0.120594811837414
Validation loss: 2.472648129798728

Epoch: 6| Step: 13
Training loss: 0.087115640692893
Validation loss: 2.4651441834174044

Epoch: 627| Step: 0
Training loss: 0.1842084799436417
Validation loss: 2.4701161278842387

Epoch: 6| Step: 1
Training loss: 0.09358054980265293
Validation loss: 2.4798470033536453

Epoch: 6| Step: 2
Training loss: 0.0810510393263885
Validation loss: 2.485045202499472

Epoch: 6| Step: 3
Training loss: 0.12306498969418682
Validation loss: 2.479858779225747

Epoch: 6| Step: 4
Training loss: 0.14178087128421954
Validation loss: 2.460773402777063

Epoch: 6| Step: 5
Training loss: 0.03745367608780938
Validation loss: 2.4864886355416704

Epoch: 6| Step: 6
Training loss: 0.10978143398297728
Validation loss: 2.4535253315823593

Epoch: 6| Step: 7
Training loss: 0.16197939338136694
Validation loss: 2.440958806864206

Epoch: 6| Step: 8
Training loss: 0.17368311137385575
Validation loss: 2.4367747909482036

Epoch: 6| Step: 9
Training loss: 0.12756908349669246
Validation loss: 2.4155697403454335

Epoch: 6| Step: 10
Training loss: 0.11613788231832008
Validation loss: 2.4524208846948703

Epoch: 6| Step: 11
Training loss: 0.14229352843945572
Validation loss: 2.4607765813153706

Epoch: 6| Step: 12
Training loss: 0.07227727435270044
Validation loss: 2.4762144151115533

Epoch: 6| Step: 13
Training loss: 0.0738414819179809
Validation loss: 2.5021640845261754

Epoch: 628| Step: 0
Training loss: 0.17747509037775344
Validation loss: 2.517980230339351

Epoch: 6| Step: 1
Training loss: 0.1110782328363792
Validation loss: 2.5047857633270656

Epoch: 6| Step: 2
Training loss: 0.12102103357314367
Validation loss: 2.5120294386072937

Epoch: 6| Step: 3
Training loss: 0.0830212245652343
Validation loss: 2.5032129089749273

Epoch: 6| Step: 4
Training loss: 0.11226392088985751
Validation loss: 2.477218053087952

Epoch: 6| Step: 5
Training loss: 0.18119094930815086
Validation loss: 2.4771434210913195

Epoch: 6| Step: 6
Training loss: 0.13593802287560236
Validation loss: 2.441686960928574

Epoch: 6| Step: 7
Training loss: 0.08320524913691199
Validation loss: 2.465389079769905

Epoch: 6| Step: 8
Training loss: 0.15895293766161808
Validation loss: 2.4723455793812397

Epoch: 6| Step: 9
Training loss: 0.1154798463256814
Validation loss: 2.432991322629439

Epoch: 6| Step: 10
Training loss: 0.1270174303784094
Validation loss: 2.4580902238720257

Epoch: 6| Step: 11
Training loss: 0.11890623612723351
Validation loss: 2.4441701466967265

Epoch: 6| Step: 12
Training loss: 0.1851016072633168
Validation loss: 2.4971734116122586

Epoch: 6| Step: 13
Training loss: 0.1615986419480216
Validation loss: 2.500167586749473

Epoch: 629| Step: 0
Training loss: 0.11306201339150934
Validation loss: 2.4775929270094434

Epoch: 6| Step: 1
Training loss: 0.12535023053472916
Validation loss: 2.4825701089167085

Epoch: 6| Step: 2
Training loss: 0.10664988903706292
Validation loss: 2.4762234222608646

Epoch: 6| Step: 3
Training loss: 0.12920315102888227
Validation loss: 2.514930775545809

Epoch: 6| Step: 4
Training loss: 0.13639554922335423
Validation loss: 2.5047174746784413

Epoch: 6| Step: 5
Training loss: 0.11311433267616842
Validation loss: 2.4737937882024856

Epoch: 6| Step: 6
Training loss: 0.09749140177313143
Validation loss: 2.483245495849563

Epoch: 6| Step: 7
Training loss: 0.09716756619317327
Validation loss: 2.457003866089674

Epoch: 6| Step: 8
Training loss: 0.09130942502382873
Validation loss: 2.4264458458988183

Epoch: 6| Step: 9
Training loss: 0.10763277678244391
Validation loss: 2.43488149559209

Epoch: 6| Step: 10
Training loss: 0.08779839338743557
Validation loss: 2.422645227253386

Epoch: 6| Step: 11
Training loss: 0.09079649315495927
Validation loss: 2.4182728729161154

Epoch: 6| Step: 12
Training loss: 0.1754187873540738
Validation loss: 2.440182023579182

Epoch: 6| Step: 13
Training loss: 0.10592479039501883
Validation loss: 2.437033190751922

Epoch: 630| Step: 0
Training loss: 0.057674183779798736
Validation loss: 2.4384219837316006

Epoch: 6| Step: 1
Training loss: 0.11964575979665712
Validation loss: 2.424635376754278

Epoch: 6| Step: 2
Training loss: 0.08438841527677829
Validation loss: 2.4481010484517416

Epoch: 6| Step: 3
Training loss: 0.14122471484962276
Validation loss: 2.4557064935176047

Epoch: 6| Step: 4
Training loss: 0.09995873277743915
Validation loss: 2.4823092153515494

Epoch: 6| Step: 5
Training loss: 0.13729326925104543
Validation loss: 2.437989279686417

Epoch: 6| Step: 6
Training loss: 0.09654862257083804
Validation loss: 2.451656591017241

Epoch: 6| Step: 7
Training loss: 0.12236781678923561
Validation loss: 2.4421925565084015

Epoch: 6| Step: 8
Training loss: 0.14697571051075956
Validation loss: 2.4470487593336117

Epoch: 6| Step: 9
Training loss: 0.09245837571076661
Validation loss: 2.459358484589796

Epoch: 6| Step: 10
Training loss: 0.11138043095076852
Validation loss: 2.47185859177429

Epoch: 6| Step: 11
Training loss: 0.1087389829004333
Validation loss: 2.5098713945698434

Epoch: 6| Step: 12
Training loss: 0.1685226589020607
Validation loss: 2.468825167135592

Epoch: 6| Step: 13
Training loss: 0.18221213558610955
Validation loss: 2.474769211904915

Epoch: 631| Step: 0
Training loss: 0.11549539422527078
Validation loss: 2.4925594468246515

Epoch: 6| Step: 1
Training loss: 0.11939630277153432
Validation loss: 2.4837141630483597

Epoch: 6| Step: 2
Training loss: 0.07838577022768466
Validation loss: 2.466405438251684

Epoch: 6| Step: 3
Training loss: 0.09849740638894561
Validation loss: 2.477119985259419

Epoch: 6| Step: 4
Training loss: 0.08585000732020684
Validation loss: 2.4498064020733756

Epoch: 6| Step: 5
Training loss: 0.14179068465158554
Validation loss: 2.4742332451258866

Epoch: 6| Step: 6
Training loss: 0.10219234248741091
Validation loss: 2.460878174654818

Epoch: 6| Step: 7
Training loss: 0.06149171208030786
Validation loss: 2.446783111149834

Epoch: 6| Step: 8
Training loss: 0.10336847462752652
Validation loss: 2.4906494885881205

Epoch: 6| Step: 9
Training loss: 0.16043439995193295
Validation loss: 2.420541608617298

Epoch: 6| Step: 10
Training loss: 0.07523800826781961
Validation loss: 2.451286938328903

Epoch: 6| Step: 11
Training loss: 0.14733421489004492
Validation loss: 2.424856773741713

Epoch: 6| Step: 12
Training loss: 0.11128734377079126
Validation loss: 2.446166819099853

Epoch: 6| Step: 13
Training loss: 0.07805362063211324
Validation loss: 2.4429449725110794

Epoch: 632| Step: 0
Training loss: 0.1075183911657219
Validation loss: 2.4568005979223484

Epoch: 6| Step: 1
Training loss: 0.14095039602601572
Validation loss: 2.442076968624849

Epoch: 6| Step: 2
Training loss: 0.08490487967846577
Validation loss: 2.4269433778452627

Epoch: 6| Step: 3
Training loss: 0.07139404288004521
Validation loss: 2.463626097255384

Epoch: 6| Step: 4
Training loss: 0.13211518136726044
Validation loss: 2.4832077736119427

Epoch: 6| Step: 5
Training loss: 0.0863979154588785
Validation loss: 2.4757623756410534

Epoch: 6| Step: 6
Training loss: 0.08715569735646239
Validation loss: 2.5015447397161337

Epoch: 6| Step: 7
Training loss: 0.13139860590225333
Validation loss: 2.50002517379884

Epoch: 6| Step: 8
Training loss: 0.1291660090270785
Validation loss: 2.4778674319769625

Epoch: 6| Step: 9
Training loss: 0.11909609884990253
Validation loss: 2.510978325114639

Epoch: 6| Step: 10
Training loss: 0.10617461475376974
Validation loss: 2.494984195307433

Epoch: 6| Step: 11
Training loss: 0.11134856437977891
Validation loss: 2.455156243911976

Epoch: 6| Step: 12
Training loss: 0.14209002727483583
Validation loss: 2.466187805517871

Epoch: 6| Step: 13
Training loss: 0.10373447334346944
Validation loss: 2.465807119046068

Epoch: 633| Step: 0
Training loss: 0.13658322701843753
Validation loss: 2.5053408885311144

Epoch: 6| Step: 1
Training loss: 0.10584349196391023
Validation loss: 2.505932718010799

Epoch: 6| Step: 2
Training loss: 0.10446202208147302
Validation loss: 2.442693221778409

Epoch: 6| Step: 3
Training loss: 0.08796004626646513
Validation loss: 2.464087196514685

Epoch: 6| Step: 4
Training loss: 0.09015567162855462
Validation loss: 2.4955166711575947

Epoch: 6| Step: 5
Training loss: 0.13281877587020052
Validation loss: 2.4890360155722964

Epoch: 6| Step: 6
Training loss: 0.14065050847442692
Validation loss: 2.501796097727825

Epoch: 6| Step: 7
Training loss: 0.12925138652941393
Validation loss: 2.492582863997663

Epoch: 6| Step: 8
Training loss: 0.130353669277287
Validation loss: 2.493242237399867

Epoch: 6| Step: 9
Training loss: 0.14429782369370972
Validation loss: 2.51090774222923

Epoch: 6| Step: 10
Training loss: 0.13747027791174216
Validation loss: 2.482145339146238

Epoch: 6| Step: 11
Training loss: 0.12796625677528195
Validation loss: 2.4919067887184845

Epoch: 6| Step: 12
Training loss: 0.061712494892322396
Validation loss: 2.484770862165456

Epoch: 6| Step: 13
Training loss: 0.035555340929906566
Validation loss: 2.5042998555323357

Epoch: 634| Step: 0
Training loss: 0.08384513956945237
Validation loss: 2.490717850041863

Epoch: 6| Step: 1
Training loss: 0.07940077117854248
Validation loss: 2.456262312291004

Epoch: 6| Step: 2
Training loss: 0.15722820920851924
Validation loss: 2.4831326799896565

Epoch: 6| Step: 3
Training loss: 0.07640889168094586
Validation loss: 2.45406428023466

Epoch: 6| Step: 4
Training loss: 0.1135757129666019
Validation loss: 2.4313173609876566

Epoch: 6| Step: 5
Training loss: 0.110607727609721
Validation loss: 2.4519884130766916

Epoch: 6| Step: 6
Training loss: 0.06649457793274757
Validation loss: 2.426182921348783

Epoch: 6| Step: 7
Training loss: 0.163046860724587
Validation loss: 2.4254010823547327

Epoch: 6| Step: 8
Training loss: 0.07992211123680484
Validation loss: 2.449505744227466

Epoch: 6| Step: 9
Training loss: 0.06523952321050745
Validation loss: 2.442374685067082

Epoch: 6| Step: 10
Training loss: 0.06239608604921823
Validation loss: 2.4578769719790112

Epoch: 6| Step: 11
Training loss: 0.09039696086811289
Validation loss: 2.4711154235592967

Epoch: 6| Step: 12
Training loss: 0.10320369037354914
Validation loss: 2.4779099181079003

Epoch: 6| Step: 13
Training loss: 0.16423931698081853
Validation loss: 2.4427703871229722

Epoch: 635| Step: 0
Training loss: 0.09542897428323346
Validation loss: 2.4527862965025498

Epoch: 6| Step: 1
Training loss: 0.1519874600155892
Validation loss: 2.4739909193983283

Epoch: 6| Step: 2
Training loss: 0.09998829147220188
Validation loss: 2.4536499398148517

Epoch: 6| Step: 3
Training loss: 0.09353425613164573
Validation loss: 2.486655995733893

Epoch: 6| Step: 4
Training loss: 0.09607822517654077
Validation loss: 2.460520578627786

Epoch: 6| Step: 5
Training loss: 0.06929696357768697
Validation loss: 2.4785074805528455

Epoch: 6| Step: 6
Training loss: 0.07775755541435185
Validation loss: 2.472868842145165

Epoch: 6| Step: 7
Training loss: 0.07083168999376149
Validation loss: 2.472775862286005

Epoch: 6| Step: 8
Training loss: 0.14752860127378034
Validation loss: 2.498540517907503

Epoch: 6| Step: 9
Training loss: 0.10962529579332565
Validation loss: 2.4870202728844744

Epoch: 6| Step: 10
Training loss: 0.09342750074792605
Validation loss: 2.492425237125111

Epoch: 6| Step: 11
Training loss: 0.07729896214348705
Validation loss: 2.519131232181009

Epoch: 6| Step: 12
Training loss: 0.0566512685673861
Validation loss: 2.5280643978866615

Epoch: 6| Step: 13
Training loss: 0.15055365210157265
Validation loss: 2.5098958079954774

Epoch: 636| Step: 0
Training loss: 0.07632860540826458
Validation loss: 2.540659149194297

Epoch: 6| Step: 1
Training loss: 0.08954022281847837
Validation loss: 2.5386535173789153

Epoch: 6| Step: 2
Training loss: 0.13200484863952688
Validation loss: 2.5203641992079318

Epoch: 6| Step: 3
Training loss: 0.10637613550962986
Validation loss: 2.5051795340923295

Epoch: 6| Step: 4
Training loss: 0.12127076178313617
Validation loss: 2.4973084306810267

Epoch: 6| Step: 5
Training loss: 0.06969535380314028
Validation loss: 2.5141946594595717

Epoch: 6| Step: 6
Training loss: 0.08450924626633192
Validation loss: 2.477175110081749

Epoch: 6| Step: 7
Training loss: 0.0687082719421363
Validation loss: 2.4636343054667145

Epoch: 6| Step: 8
Training loss: 0.07233607556830171
Validation loss: 2.4810732277340506

Epoch: 6| Step: 9
Training loss: 0.0964414763740267
Validation loss: 2.487369458837996

Epoch: 6| Step: 10
Training loss: 0.09536388176986892
Validation loss: 2.454931800415787

Epoch: 6| Step: 11
Training loss: 0.09651857495844444
Validation loss: 2.5019053038595103

Epoch: 6| Step: 12
Training loss: 0.13100438126033362
Validation loss: 2.47026827797656

Epoch: 6| Step: 13
Training loss: 0.07616241714252965
Validation loss: 2.4843611022556367

Epoch: 637| Step: 0
Training loss: 0.08120030226617433
Validation loss: 2.4787121158983587

Epoch: 6| Step: 1
Training loss: 0.059303326387732336
Validation loss: 2.4796495716149995

Epoch: 6| Step: 2
Training loss: 0.052757525219270004
Validation loss: 2.4697292561762643

Epoch: 6| Step: 3
Training loss: 0.12439278925261282
Validation loss: 2.4870383944248045

Epoch: 6| Step: 4
Training loss: 0.1289205832171053
Validation loss: 2.4933674270924944

Epoch: 6| Step: 5
Training loss: 0.0857468761257034
Validation loss: 2.515889254732194

Epoch: 6| Step: 6
Training loss: 0.08685651760098524
Validation loss: 2.497576086083917

Epoch: 6| Step: 7
Training loss: 0.08677182452834772
Validation loss: 2.4925146832906195

Epoch: 6| Step: 8
Training loss: 0.07192404669931093
Validation loss: 2.4648517128580925

Epoch: 6| Step: 9
Training loss: 0.13039079438707654
Validation loss: 2.4519924781148768

Epoch: 6| Step: 10
Training loss: 0.07472365948491516
Validation loss: 2.4775956369667895

Epoch: 6| Step: 11
Training loss: 0.0930523194242405
Validation loss: 2.4769697070970635

Epoch: 6| Step: 12
Training loss: 0.09026006460900755
Validation loss: 2.4763156836070674

Epoch: 6| Step: 13
Training loss: 0.07225001334050825
Validation loss: 2.5020087693359447

Epoch: 638| Step: 0
Training loss: 0.07608251342800833
Validation loss: 2.468924744022557

Epoch: 6| Step: 1
Training loss: 0.09050079252623137
Validation loss: 2.4565048599480788

Epoch: 6| Step: 2
Training loss: 0.1050485079977561
Validation loss: 2.4847269880125054

Epoch: 6| Step: 3
Training loss: 0.10414110903330537
Validation loss: 2.4962238978357463

Epoch: 6| Step: 4
Training loss: 0.1083561754751315
Validation loss: 2.470822176095082

Epoch: 6| Step: 5
Training loss: 0.07925692359910914
Validation loss: 2.4862551605499856

Epoch: 6| Step: 6
Training loss: 0.07940731297606818
Validation loss: 2.499204878340678

Epoch: 6| Step: 7
Training loss: 0.12747107266467722
Validation loss: 2.4925924650984275

Epoch: 6| Step: 8
Training loss: 0.06961727152132142
Validation loss: 2.495389988677143

Epoch: 6| Step: 9
Training loss: 0.09812504779000546
Validation loss: 2.5082758014025206

Epoch: 6| Step: 10
Training loss: 0.16273468704303595
Validation loss: 2.5021359087103487

Epoch: 6| Step: 11
Training loss: 0.06326704660600489
Validation loss: 2.463236879265434

Epoch: 6| Step: 12
Training loss: 0.07589872609514076
Validation loss: 2.500569959499081

Epoch: 6| Step: 13
Training loss: 0.07670946722042579
Validation loss: 2.521446603612681

Epoch: 639| Step: 0
Training loss: 0.09259968599107615
Validation loss: 2.489343039916586

Epoch: 6| Step: 1
Training loss: 0.08230714439903618
Validation loss: 2.507668293575847

Epoch: 6| Step: 2
Training loss: 0.12077981493986878
Validation loss: 2.518221906383503

Epoch: 6| Step: 3
Training loss: 0.12029421175020168
Validation loss: 2.495876670696851

Epoch: 6| Step: 4
Training loss: 0.08038428558696402
Validation loss: 2.4435655259303948

Epoch: 6| Step: 5
Training loss: 0.06310660316063955
Validation loss: 2.4312469296818633

Epoch: 6| Step: 6
Training loss: 0.12973370992698405
Validation loss: 2.4634236450549154

Epoch: 6| Step: 7
Training loss: 0.07562939641425324
Validation loss: 2.4685126985370376

Epoch: 6| Step: 8
Training loss: 0.07071795387089647
Validation loss: 2.471965435715515

Epoch: 6| Step: 9
Training loss: 0.11598329527094238
Validation loss: 2.453366184860113

Epoch: 6| Step: 10
Training loss: 0.1403494426568268
Validation loss: 2.459016435619694

Epoch: 6| Step: 11
Training loss: 0.055531626562018176
Validation loss: 2.4372585661917796

Epoch: 6| Step: 12
Training loss: 0.1033136493647197
Validation loss: 2.4795031637591247

Epoch: 6| Step: 13
Training loss: 0.06744949869499982
Validation loss: 2.414820657328678

Epoch: 640| Step: 0
Training loss: 0.12005172279149308
Validation loss: 2.434372417544361

Epoch: 6| Step: 1
Training loss: 0.06375299198361516
Validation loss: 2.4609778506891606

Epoch: 6| Step: 2
Training loss: 0.08583770180765007
Validation loss: 2.464020905384964

Epoch: 6| Step: 3
Training loss: 0.12165603147512075
Validation loss: 2.4694610896650118

Epoch: 6| Step: 4
Training loss: 0.07206119800195392
Validation loss: 2.456747815672247

Epoch: 6| Step: 5
Training loss: 0.07598093137952769
Validation loss: 2.4830666097854315

Epoch: 6| Step: 6
Training loss: 0.08125363201954998
Validation loss: 2.4817093360136306

Epoch: 6| Step: 7
Training loss: 0.07565659072055538
Validation loss: 2.500923992983716

Epoch: 6| Step: 8
Training loss: 0.12715526040986594
Validation loss: 2.4903115784502305

Epoch: 6| Step: 9
Training loss: 0.13376021944425645
Validation loss: 2.4981200122595406

Epoch: 6| Step: 10
Training loss: 0.06637214037065661
Validation loss: 2.4821843427302714

Epoch: 6| Step: 11
Training loss: 0.08861275815483541
Validation loss: 2.491053455372102

Epoch: 6| Step: 12
Training loss: 0.10814668874050785
Validation loss: 2.518791212276407

Epoch: 6| Step: 13
Training loss: 0.11361995163305252
Validation loss: 2.535066466855198

Epoch: 641| Step: 0
Training loss: 0.04584862664320239
Validation loss: 2.511860064167035

Epoch: 6| Step: 1
Training loss: 0.08983230517924913
Validation loss: 2.5213162234169

Epoch: 6| Step: 2
Training loss: 0.08176170068308437
Validation loss: 2.5003868265213143

Epoch: 6| Step: 3
Training loss: 0.06549211271291525
Validation loss: 2.5354950722338923

Epoch: 6| Step: 4
Training loss: 0.07222887664211215
Validation loss: 2.5178748747099666

Epoch: 6| Step: 5
Training loss: 0.09536473140708529
Validation loss: 2.477706497446138

Epoch: 6| Step: 6
Training loss: 0.17683331052169987
Validation loss: 2.4738238930995324

Epoch: 6| Step: 7
Training loss: 0.12102315752438934
Validation loss: 2.5127468205639896

Epoch: 6| Step: 8
Training loss: 0.11881948402031178
Validation loss: 2.466867921873114

Epoch: 6| Step: 9
Training loss: 0.15308144665258727
Validation loss: 2.4700777567756758

Epoch: 6| Step: 10
Training loss: 0.09159878399179229
Validation loss: 2.4709361604468194

Epoch: 6| Step: 11
Training loss: 0.10175868489775593
Validation loss: 2.4735023548955746

Epoch: 6| Step: 12
Training loss: 0.09305945027185424
Validation loss: 2.4941812315165235

Epoch: 6| Step: 13
Training loss: 0.07813593966662016
Validation loss: 2.44273508548201

Epoch: 642| Step: 0
Training loss: 0.07024470345632142
Validation loss: 2.5038082189424515

Epoch: 6| Step: 1
Training loss: 0.06496630456651493
Validation loss: 2.5116924022385447

Epoch: 6| Step: 2
Training loss: 0.12934652193587196
Validation loss: 2.5118510286512072

Epoch: 6| Step: 3
Training loss: 0.19827242089853447
Validation loss: 2.552459400454286

Epoch: 6| Step: 4
Training loss: 0.0884381933151405
Validation loss: 2.5260636959927343

Epoch: 6| Step: 5
Training loss: 0.12899860772593968
Validation loss: 2.507471764187903

Epoch: 6| Step: 6
Training loss: 0.10325598995045997
Validation loss: 2.489706174298371

Epoch: 6| Step: 7
Training loss: 0.06021586040835072
Validation loss: 2.4832083806576057

Epoch: 6| Step: 8
Training loss: 0.12085833277188221
Validation loss: 2.5349330776376195

Epoch: 6| Step: 9
Training loss: 0.14630218620156346
Validation loss: 2.465235210095295

Epoch: 6| Step: 10
Training loss: 0.15185833281241737
Validation loss: 2.4957619256054158

Epoch: 6| Step: 11
Training loss: 0.12923716206359293
Validation loss: 2.4996952753062867

Epoch: 6| Step: 12
Training loss: 0.09624332150134075
Validation loss: 2.5206041108956945

Epoch: 6| Step: 13
Training loss: 0.1048816082350715
Validation loss: 2.534043083023707

Epoch: 643| Step: 0
Training loss: 0.07288116807193697
Validation loss: 2.518517686508082

Epoch: 6| Step: 1
Training loss: 0.1459022845740256
Validation loss: 2.5376264197856626

Epoch: 6| Step: 2
Training loss: 0.1287389449817692
Validation loss: 2.5112975150441135

Epoch: 6| Step: 3
Training loss: 0.07740688793368425
Validation loss: 2.5041728091318585

Epoch: 6| Step: 4
Training loss: 0.11552851120914341
Validation loss: 2.529056827976423

Epoch: 6| Step: 5
Training loss: 0.15641385070441954
Validation loss: 2.5345724732407415

Epoch: 6| Step: 6
Training loss: 0.132560013144771
Validation loss: 2.5309709197353234

Epoch: 6| Step: 7
Training loss: 0.11460338808972481
Validation loss: 2.521399815110724

Epoch: 6| Step: 8
Training loss: 0.06316905731476674
Validation loss: 2.5067638900734073

Epoch: 6| Step: 9
Training loss: 0.1527334754702721
Validation loss: 2.518264274141628

Epoch: 6| Step: 10
Training loss: 0.1588365507259899
Validation loss: 2.4946230891504304

Epoch: 6| Step: 11
Training loss: 0.09877277113232523
Validation loss: 2.51274471577858

Epoch: 6| Step: 12
Training loss: 0.11409472784267469
Validation loss: 2.545675047752849

Epoch: 6| Step: 13
Training loss: 0.09463371563825873
Validation loss: 2.508911079263057

Epoch: 644| Step: 0
Training loss: 0.12863700375648887
Validation loss: 2.4876282939042635

Epoch: 6| Step: 1
Training loss: 0.08448941279567218
Validation loss: 2.528414518686164

Epoch: 6| Step: 2
Training loss: 0.1596574400717255
Validation loss: 2.495274958705474

Epoch: 6| Step: 3
Training loss: 0.07536059643809286
Validation loss: 2.4864673292465382

Epoch: 6| Step: 4
Training loss: 0.07916269765596096
Validation loss: 2.5027276366636246

Epoch: 6| Step: 5
Training loss: 0.12010237362080964
Validation loss: 2.514093200573234

Epoch: 6| Step: 6
Training loss: 0.11040166544526192
Validation loss: 2.5261042226985544

Epoch: 6| Step: 7
Training loss: 0.07231119690749657
Validation loss: 2.502995993879433

Epoch: 6| Step: 8
Training loss: 0.08634917317636814
Validation loss: 2.503103401427136

Epoch: 6| Step: 9
Training loss: 0.08540623810053051
Validation loss: 2.5080481468262383

Epoch: 6| Step: 10
Training loss: 0.09337226447505469
Validation loss: 2.490820209103002

Epoch: 6| Step: 11
Training loss: 0.08704075526820529
Validation loss: 2.456388281424872

Epoch: 6| Step: 12
Training loss: 0.07442619795480633
Validation loss: 2.492182646726201

Epoch: 6| Step: 13
Training loss: 0.11281878518589057
Validation loss: 2.4869286148318754

Epoch: 645| Step: 0
Training loss: 0.14930363233076757
Validation loss: 2.479788988456818

Epoch: 6| Step: 1
Training loss: 0.08425380492992429
Validation loss: 2.4872000640573284

Epoch: 6| Step: 2
Training loss: 0.06453002330454623
Validation loss: 2.498454510423353

Epoch: 6| Step: 3
Training loss: 0.09076705006587069
Validation loss: 2.48649521761887

Epoch: 6| Step: 4
Training loss: 0.06585314353522999
Validation loss: 2.517739291715678

Epoch: 6| Step: 5
Training loss: 0.07293993572933999
Validation loss: 2.500495123799241

Epoch: 6| Step: 6
Training loss: 0.07963325042327253
Validation loss: 2.4855945421563597

Epoch: 6| Step: 7
Training loss: 0.07735344652602157
Validation loss: 2.502126419536445

Epoch: 6| Step: 8
Training loss: 0.08888853256933169
Validation loss: 2.501853744739815

Epoch: 6| Step: 9
Training loss: 0.06772743087204812
Validation loss: 2.5156429470764454

Epoch: 6| Step: 10
Training loss: 0.07684726416819822
Validation loss: 2.492379913684156

Epoch: 6| Step: 11
Training loss: 0.08890858932896946
Validation loss: 2.5121056160798947

Epoch: 6| Step: 12
Training loss: 0.15017702365837102
Validation loss: 2.483778340346904

Epoch: 6| Step: 13
Training loss: 0.07332297955388954
Validation loss: 2.4976397067883904

Epoch: 646| Step: 0
Training loss: 0.06923517104508875
Validation loss: 2.502734710736308

Epoch: 6| Step: 1
Training loss: 0.10251095250247463
Validation loss: 2.5011288729597556

Epoch: 6| Step: 2
Training loss: 0.16334604319277662
Validation loss: 2.534889879542921

Epoch: 6| Step: 3
Training loss: 0.08374586169850688
Validation loss: 2.491661522122239

Epoch: 6| Step: 4
Training loss: 0.06680966305040097
Validation loss: 2.4806903497568356

Epoch: 6| Step: 5
Training loss: 0.07277275967653422
Validation loss: 2.4794050115718758

Epoch: 6| Step: 6
Training loss: 0.07172414533935934
Validation loss: 2.475381950952467

Epoch: 6| Step: 7
Training loss: 0.09125920862443246
Validation loss: 2.4705088113462366

Epoch: 6| Step: 8
Training loss: 0.12939952624774478
Validation loss: 2.440139855522756

Epoch: 6| Step: 9
Training loss: 0.0895243544361399
Validation loss: 2.418776985364087

Epoch: 6| Step: 10
Training loss: 0.07635073265011917
Validation loss: 2.4536642601771184

Epoch: 6| Step: 11
Training loss: 0.10387400004758283
Validation loss: 2.44469789231773

Epoch: 6| Step: 12
Training loss: 0.12245835236128151
Validation loss: 2.442662518054551

Epoch: 6| Step: 13
Training loss: 0.08116867197250648
Validation loss: 2.4589341960383093

Epoch: 647| Step: 0
Training loss: 0.13246035171599752
Validation loss: 2.4577456863964295

Epoch: 6| Step: 1
Training loss: 0.1371583411004529
Validation loss: 2.464386227288047

Epoch: 6| Step: 2
Training loss: 0.13844094053647388
Validation loss: 2.462826321076071

Epoch: 6| Step: 3
Training loss: 0.0810475978278541
Validation loss: 2.476491511789574

Epoch: 6| Step: 4
Training loss: 0.059199673201913085
Validation loss: 2.4343031109114266

Epoch: 6| Step: 5
Training loss: 0.1022636848408462
Validation loss: 2.4476984880274535

Epoch: 6| Step: 6
Training loss: 0.06598105767059335
Validation loss: 2.429216641888029

Epoch: 6| Step: 7
Training loss: 0.11528650817915972
Validation loss: 2.4030720500936513

Epoch: 6| Step: 8
Training loss: 0.14895058097095393
Validation loss: 2.406504890952955

Epoch: 6| Step: 9
Training loss: 0.14100892587319733
Validation loss: 2.4624916103376906

Epoch: 6| Step: 10
Training loss: 0.14502539446245605
Validation loss: 2.4284794113459065

Epoch: 6| Step: 11
Training loss: 0.08937988573005044
Validation loss: 2.4683010263681466

Epoch: 6| Step: 12
Training loss: 0.07460232796267809
Validation loss: 2.463989977376344

Epoch: 6| Step: 13
Training loss: 0.07643751749871304
Validation loss: 2.4725592993590615

Epoch: 648| Step: 0
Training loss: 0.07583634128975902
Validation loss: 2.516245959031166

Epoch: 6| Step: 1
Training loss: 0.10414370243937017
Validation loss: 2.4955975028341992

Epoch: 6| Step: 2
Training loss: 0.0880484567862302
Validation loss: 2.4670826717926237

Epoch: 6| Step: 3
Training loss: 0.06654068718154288
Validation loss: 2.4848482838556403

Epoch: 6| Step: 4
Training loss: 0.09945240461743346
Validation loss: 2.5034635055539143

Epoch: 6| Step: 5
Training loss: 0.08631909784958576
Validation loss: 2.501390493972056

Epoch: 6| Step: 6
Training loss: 0.07915538852074523
Validation loss: 2.484586906205669

Epoch: 6| Step: 7
Training loss: 0.08484699567097982
Validation loss: 2.4865666862668165

Epoch: 6| Step: 8
Training loss: 0.09898276142560496
Validation loss: 2.480658246819035

Epoch: 6| Step: 9
Training loss: 0.0858143091467769
Validation loss: 2.4727956930851462

Epoch: 6| Step: 10
Training loss: 0.1476875357811457
Validation loss: 2.4658196346347414

Epoch: 6| Step: 11
Training loss: 0.17585338595888544
Validation loss: 2.459215504029902

Epoch: 6| Step: 12
Training loss: 0.07519540539029812
Validation loss: 2.454610133755237

Epoch: 6| Step: 13
Training loss: 0.06644346442615591
Validation loss: 2.447100881258058

Epoch: 649| Step: 0
Training loss: 0.11317971217137479
Validation loss: 2.4521729744912206

Epoch: 6| Step: 1
Training loss: 0.10218882008671061
Validation loss: 2.441105863997016

Epoch: 6| Step: 2
Training loss: 0.08724223555143981
Validation loss: 2.496593626014624

Epoch: 6| Step: 3
Training loss: 0.06938744364650103
Validation loss: 2.4698073175343835

Epoch: 6| Step: 4
Training loss: 0.09488265950366108
Validation loss: 2.483415266184196

Epoch: 6| Step: 5
Training loss: 0.12900969660525555
Validation loss: 2.4452528112961343

Epoch: 6| Step: 6
Training loss: 0.06897620449195767
Validation loss: 2.501572115663678

Epoch: 6| Step: 7
Training loss: 0.0963180502227429
Validation loss: 2.4862266961727264

Epoch: 6| Step: 8
Training loss: 0.0997413620985229
Validation loss: 2.484974051173103

Epoch: 6| Step: 9
Training loss: 0.1584178738599062
Validation loss: 2.4493070264871646

Epoch: 6| Step: 10
Training loss: 0.05670517704202543
Validation loss: 2.487644567363189

Epoch: 6| Step: 11
Training loss: 0.06305129573407213
Validation loss: 2.4933953688658494

Epoch: 6| Step: 12
Training loss: 0.060548186287985514
Validation loss: 2.5169671524761412

Epoch: 6| Step: 13
Training loss: 0.06403213339513183
Validation loss: 2.4942478136309423

Epoch: 650| Step: 0
Training loss: 0.09103738827476575
Validation loss: 2.4849160847905685

Epoch: 6| Step: 1
Training loss: 0.10301332242751035
Validation loss: 2.508845431959423

Epoch: 6| Step: 2
Training loss: 0.0969414010440456
Validation loss: 2.5156788102732732

Epoch: 6| Step: 3
Training loss: 0.1313464579474374
Validation loss: 2.4923968606990465

Epoch: 6| Step: 4
Training loss: 0.0531106829635102
Validation loss: 2.4821898269791656

Epoch: 6| Step: 5
Training loss: 0.11392000586253356
Validation loss: 2.4965098714598266

Epoch: 6| Step: 6
Training loss: 0.08337709524547397
Validation loss: 2.495350843226628

Epoch: 6| Step: 7
Training loss: 0.0558855831413213
Validation loss: 2.491582220346708

Epoch: 6| Step: 8
Training loss: 0.07201862329522206
Validation loss: 2.4782122754096125

Epoch: 6| Step: 9
Training loss: 0.08028590182135119
Validation loss: 2.477105188592013

Epoch: 6| Step: 10
Training loss: 0.13263596695310684
Validation loss: 2.481135023759488

Epoch: 6| Step: 11
Training loss: 0.06472141606850251
Validation loss: 2.4771149270440427

Epoch: 6| Step: 12
Training loss: 0.07557546212799258
Validation loss: 2.4560416900134934

Epoch: 6| Step: 13
Training loss: 0.08548426862942592
Validation loss: 2.4776401061259996

Epoch: 651| Step: 0
Training loss: 0.09449042057216213
Validation loss: 2.4615648185318313

Epoch: 6| Step: 1
Training loss: 0.07788850035299745
Validation loss: 2.4561801944630592

Epoch: 6| Step: 2
Training loss: 0.0816996377090192
Validation loss: 2.4448282034235813

Epoch: 6| Step: 3
Training loss: 0.08817772597585531
Validation loss: 2.456728988594726

Epoch: 6| Step: 4
Training loss: 0.10791854480572126
Validation loss: 2.444624294620462

Epoch: 6| Step: 5
Training loss: 0.06019561342031726
Validation loss: 2.455993269282458

Epoch: 6| Step: 6
Training loss: 0.11539758826535948
Validation loss: 2.4791128118767833

Epoch: 6| Step: 7
Training loss: 0.09215787152829652
Validation loss: 2.4767647104241735

Epoch: 6| Step: 8
Training loss: 0.08225855103171255
Validation loss: 2.4562492334491512

Epoch: 6| Step: 9
Training loss: 0.08300971421699964
Validation loss: 2.4689369997931676

Epoch: 6| Step: 10
Training loss: 0.06288965028990783
Validation loss: 2.4669191002518365

Epoch: 6| Step: 11
Training loss: 0.1416291308697013
Validation loss: 2.4958593246347704

Epoch: 6| Step: 12
Training loss: 0.10765906936486082
Validation loss: 2.4422506929641097

Epoch: 6| Step: 13
Training loss: 0.14647743208644007
Validation loss: 2.4575756991890065

Epoch: 652| Step: 0
Training loss: 0.05517689948510145
Validation loss: 2.4613024879614773

Epoch: 6| Step: 1
Training loss: 0.1217180548257527
Validation loss: 2.454260251543895

Epoch: 6| Step: 2
Training loss: 0.05799520673476257
Validation loss: 2.473957505714438

Epoch: 6| Step: 3
Training loss: 0.0681678336447477
Validation loss: 2.4717742809380017

Epoch: 6| Step: 4
Training loss: 0.06557579594303405
Validation loss: 2.450649312550558

Epoch: 6| Step: 5
Training loss: 0.0905191236712405
Validation loss: 2.4653134043933407

Epoch: 6| Step: 6
Training loss: 0.050150242843852916
Validation loss: 2.4713486172240025

Epoch: 6| Step: 7
Training loss: 0.09981364921004983
Validation loss: 2.4791642193580956

Epoch: 6| Step: 8
Training loss: 0.12133733031605966
Validation loss: 2.481021558600881

Epoch: 6| Step: 9
Training loss: 0.11991093147619505
Validation loss: 2.4636350390846764

Epoch: 6| Step: 10
Training loss: 0.08500475411320721
Validation loss: 2.4802922497476936

Epoch: 6| Step: 11
Training loss: 0.07721155035668674
Validation loss: 2.482347263133933

Epoch: 6| Step: 12
Training loss: 0.12147785227519771
Validation loss: 2.4729181251535746

Epoch: 6| Step: 13
Training loss: 0.0638713189343252
Validation loss: 2.506444599431197

Epoch: 653| Step: 0
Training loss: 0.06652904825074804
Validation loss: 2.483473006430175

Epoch: 6| Step: 1
Training loss: 0.09140559770889334
Validation loss: 2.4997667983202776

Epoch: 6| Step: 2
Training loss: 0.08745769793740939
Validation loss: 2.497305383844699

Epoch: 6| Step: 3
Training loss: 0.11251812017397274
Validation loss: 2.473353851164044

Epoch: 6| Step: 4
Training loss: 0.11181920477017881
Validation loss: 2.5221526753593118

Epoch: 6| Step: 5
Training loss: 0.07647738567014105
Validation loss: 2.514532217861887

Epoch: 6| Step: 6
Training loss: 0.05878727663058762
Validation loss: 2.456046036955983

Epoch: 6| Step: 7
Training loss: 0.05592214418865005
Validation loss: 2.4785039699713574

Epoch: 6| Step: 8
Training loss: 0.07779688777624677
Validation loss: 2.475796718126677

Epoch: 6| Step: 9
Training loss: 0.10776134949961495
Validation loss: 2.50295342247069

Epoch: 6| Step: 10
Training loss: 0.058908700873034944
Validation loss: 2.461165736315734

Epoch: 6| Step: 11
Training loss: 0.09415922159309877
Validation loss: 2.467725518109212

Epoch: 6| Step: 12
Training loss: 0.12379211720543305
Validation loss: 2.4708534450183204

Epoch: 6| Step: 13
Training loss: 0.07851682989420092
Validation loss: 2.4518758544274633

Epoch: 654| Step: 0
Training loss: 0.07112799372578169
Validation loss: 2.421999620293859

Epoch: 6| Step: 1
Training loss: 0.07804988289670174
Validation loss: 2.4676476677626438

Epoch: 6| Step: 2
Training loss: 0.09708110242778506
Validation loss: 2.464203327583216

Epoch: 6| Step: 3
Training loss: 0.07091958831265749
Validation loss: 2.4602723149308368

Epoch: 6| Step: 4
Training loss: 0.15398670964089678
Validation loss: 2.46484567870207

Epoch: 6| Step: 5
Training loss: 0.07192564908252047
Validation loss: 2.4708068532755503

Epoch: 6| Step: 6
Training loss: 0.055541956555700926
Validation loss: 2.4789925094682137

Epoch: 6| Step: 7
Training loss: 0.057362947183765604
Validation loss: 2.480682534883438

Epoch: 6| Step: 8
Training loss: 0.04564025479362135
Validation loss: 2.494158504653042

Epoch: 6| Step: 9
Training loss: 0.05671440038869656
Validation loss: 2.480818776988082

Epoch: 6| Step: 10
Training loss: 0.10635446031030486
Validation loss: 2.4851823143733203

Epoch: 6| Step: 11
Training loss: 0.1243421784062185
Validation loss: 2.5016045404990503

Epoch: 6| Step: 12
Training loss: 0.05505327956206153
Validation loss: 2.514922665438771

Epoch: 6| Step: 13
Training loss: 0.06160520425807095
Validation loss: 2.4861686384793322

Epoch: 655| Step: 0
Training loss: 0.06059127763791845
Validation loss: 2.4945919958783445

Epoch: 6| Step: 1
Training loss: 0.1276238038724355
Validation loss: 2.469457700402657

Epoch: 6| Step: 2
Training loss: 0.09241329359650073
Validation loss: 2.4752738925384703

Epoch: 6| Step: 3
Training loss: 0.08134166345125789
Validation loss: 2.486890981448972

Epoch: 6| Step: 4
Training loss: 0.08664448861914385
Validation loss: 2.4743965677002095

Epoch: 6| Step: 5
Training loss: 0.07954880469620472
Validation loss: 2.4607332576202783

Epoch: 6| Step: 6
Training loss: 0.05856277123727346
Validation loss: 2.467352051149316

Epoch: 6| Step: 7
Training loss: 0.1051735012618427
Validation loss: 2.4538965066875544

Epoch: 6| Step: 8
Training loss: 0.093252091634881
Validation loss: 2.504223577279164

Epoch: 6| Step: 9
Training loss: 0.15431379273778129
Validation loss: 2.4659205653684224

Epoch: 6| Step: 10
Training loss: 0.07035879094819432
Validation loss: 2.4599080980009957

Epoch: 6| Step: 11
Training loss: 0.06639847990466217
Validation loss: 2.4710674828674977

Epoch: 6| Step: 12
Training loss: 0.08148989406375937
Validation loss: 2.4584904998156145

Epoch: 6| Step: 13
Training loss: 0.07134752946054475
Validation loss: 2.471061257045281

Epoch: 656| Step: 0
Training loss: 0.11728756129509094
Validation loss: 2.4670619211482574

Epoch: 6| Step: 1
Training loss: 0.0955921424875219
Validation loss: 2.4815654712067485

Epoch: 6| Step: 2
Training loss: 0.07494649344390374
Validation loss: 2.483232025383677

Epoch: 6| Step: 3
Training loss: 0.058489796692803554
Validation loss: 2.4730544472152505

Epoch: 6| Step: 4
Training loss: 0.0747644291207111
Validation loss: 2.4743870607311287

Epoch: 6| Step: 5
Training loss: 0.08217313677687112
Validation loss: 2.483445421678763

Epoch: 6| Step: 6
Training loss: 0.11680396418921278
Validation loss: 2.477704025587369

Epoch: 6| Step: 7
Training loss: 0.08335315448750596
Validation loss: 2.4820242530952163

Epoch: 6| Step: 8
Training loss: 0.06396261240437881
Validation loss: 2.466245089437393

Epoch: 6| Step: 9
Training loss: 0.08090433285284655
Validation loss: 2.466016018546461

Epoch: 6| Step: 10
Training loss: 0.12919247523879301
Validation loss: 2.491458707954126

Epoch: 6| Step: 11
Training loss: 0.1040915491537977
Validation loss: 2.450155131091565

Epoch: 6| Step: 12
Training loss: 0.0803305323094803
Validation loss: 2.470703135376158

Epoch: 6| Step: 13
Training loss: 0.08883053684063758
Validation loss: 2.4829835736539008

Epoch: 657| Step: 0
Training loss: 0.10774649209587585
Validation loss: 2.4715706394944394

Epoch: 6| Step: 1
Training loss: 0.04794654615377465
Validation loss: 2.4748939914898447

Epoch: 6| Step: 2
Training loss: 0.11514870239093795
Validation loss: 2.481051324191073

Epoch: 6| Step: 3
Training loss: 0.10166818365381464
Validation loss: 2.492733358927227

Epoch: 6| Step: 4
Training loss: 0.08235442556527421
Validation loss: 2.5029443179292907

Epoch: 6| Step: 5
Training loss: 0.057772933059538074
Validation loss: 2.493399224509872

Epoch: 6| Step: 6
Training loss: 0.1410617932431656
Validation loss: 2.512487116726397

Epoch: 6| Step: 7
Training loss: 0.14425443224403126
Validation loss: 2.5262805105658948

Epoch: 6| Step: 8
Training loss: 0.08901921044223694
Validation loss: 2.4892002187990117

Epoch: 6| Step: 9
Training loss: 0.09136853825817105
Validation loss: 2.504027259744655

Epoch: 6| Step: 10
Training loss: 0.104156494140625
Validation loss: 2.4968795036457956

Epoch: 6| Step: 11
Training loss: 0.08582467562488891
Validation loss: 2.49041800954109

Epoch: 6| Step: 12
Training loss: 0.0706047237457183
Validation loss: 2.4987444606398417

Epoch: 6| Step: 13
Training loss: 0.06376504634023487
Validation loss: 2.4651272144025675

Epoch: 658| Step: 0
Training loss: 0.07017076631522566
Validation loss: 2.456114748313347

Epoch: 6| Step: 1
Training loss: 0.06839753856754474
Validation loss: 2.459083474659337

Epoch: 6| Step: 2
Training loss: 0.11496928807843215
Validation loss: 2.498894540375608

Epoch: 6| Step: 3
Training loss: 0.08701777699334154
Validation loss: 2.473778522133459

Epoch: 6| Step: 4
Training loss: 0.09013427532682398
Validation loss: 2.4513625426361423

Epoch: 6| Step: 5
Training loss: 0.1495424728606544
Validation loss: 2.456047714876857

Epoch: 6| Step: 6
Training loss: 0.07360853128753364
Validation loss: 2.469383920570228

Epoch: 6| Step: 7
Training loss: 0.10402945083902705
Validation loss: 2.4937776757953185

Epoch: 6| Step: 8
Training loss: 0.07679521605445164
Validation loss: 2.509194426609326

Epoch: 6| Step: 9
Training loss: 0.07700063937753107
Validation loss: 2.4978248054718346

Epoch: 6| Step: 10
Training loss: 0.09311976789331267
Validation loss: 2.5288786268289463

Epoch: 6| Step: 11
Training loss: 0.06206533036904172
Validation loss: 2.506011570785354

Epoch: 6| Step: 12
Training loss: 0.0777436725289463
Validation loss: 2.5207848145478464

Epoch: 6| Step: 13
Training loss: 0.1430183694543432
Validation loss: 2.533982591426961

Epoch: 659| Step: 0
Training loss: 0.051374826842269156
Validation loss: 2.4807839423723057

Epoch: 6| Step: 1
Training loss: 0.10442936425877111
Validation loss: 2.504874841801756

Epoch: 6| Step: 2
Training loss: 0.07149061035102407
Validation loss: 2.471763784794193

Epoch: 6| Step: 3
Training loss: 0.10181171761347377
Validation loss: 2.4523929196973597

Epoch: 6| Step: 4
Training loss: 0.1004945886484181
Validation loss: 2.483013352376808

Epoch: 6| Step: 5
Training loss: 0.06673437981816523
Validation loss: 2.476627000034976

Epoch: 6| Step: 6
Training loss: 0.08527840571449737
Validation loss: 2.4816176832478223

Epoch: 6| Step: 7
Training loss: 0.07870436657533453
Validation loss: 2.463200134927741

Epoch: 6| Step: 8
Training loss: 0.09025560703090833
Validation loss: 2.4428538194222673

Epoch: 6| Step: 9
Training loss: 0.07328279641030612
Validation loss: 2.4569155531168323

Epoch: 6| Step: 10
Training loss: 0.057777698455148845
Validation loss: 2.451833482840582

Epoch: 6| Step: 11
Training loss: 0.14937181436461688
Validation loss: 2.458518466231986

Epoch: 6| Step: 12
Training loss: 0.09480730037444328
Validation loss: 2.475180957452223

Epoch: 6| Step: 13
Training loss: 0.07190213740684938
Validation loss: 2.4570259307945133

Epoch: 660| Step: 0
Training loss: 0.06007888110147615
Validation loss: 2.4882463333720173

Epoch: 6| Step: 1
Training loss: 0.09799372535684332
Validation loss: 2.4531627317972466

Epoch: 6| Step: 2
Training loss: 0.07361264635674095
Validation loss: 2.48312809241857

Epoch: 6| Step: 3
Training loss: 0.05210138494867733
Validation loss: 2.449483412926667

Epoch: 6| Step: 4
Training loss: 0.07645643097843531
Validation loss: 2.4946010075821277

Epoch: 6| Step: 5
Training loss: 0.11588623862742978
Validation loss: 2.4908920121695663

Epoch: 6| Step: 6
Training loss: 0.059942287937017814
Validation loss: 2.476493702251831

Epoch: 6| Step: 7
Training loss: 0.08056881640904037
Validation loss: 2.4881159557720083

Epoch: 6| Step: 8
Training loss: 0.05859546261509785
Validation loss: 2.478391086196945

Epoch: 6| Step: 9
Training loss: 0.06448870457117417
Validation loss: 2.4641625683072452

Epoch: 6| Step: 10
Training loss: 0.05181253662139716
Validation loss: 2.4497886497492427

Epoch: 6| Step: 11
Training loss: 0.0857871973689379
Validation loss: 2.4380779438366336

Epoch: 6| Step: 12
Training loss: 0.14682144167568426
Validation loss: 2.440830950677667

Epoch: 6| Step: 13
Training loss: 0.10066902562149456
Validation loss: 2.4097133462269245

Epoch: 661| Step: 0
Training loss: 0.1035556985553207
Validation loss: 2.4250174127238378

Epoch: 6| Step: 1
Training loss: 0.055915203239282105
Validation loss: 2.439780883267031

Epoch: 6| Step: 2
Training loss: 0.11652453368640356
Validation loss: 2.4073612617996263

Epoch: 6| Step: 3
Training loss: 0.08581214670600319
Validation loss: 2.451425559782381

Epoch: 6| Step: 4
Training loss: 0.07204037757953996
Validation loss: 2.417573645837396

Epoch: 6| Step: 5
Training loss: 0.07387223414586286
Validation loss: 2.454543482751111

Epoch: 6| Step: 6
Training loss: 0.13783520835835394
Validation loss: 2.452959597866162

Epoch: 6| Step: 7
Training loss: 0.13063072041484083
Validation loss: 2.4356753574805268

Epoch: 6| Step: 8
Training loss: 0.07863258338095139
Validation loss: 2.4633739988200354

Epoch: 6| Step: 9
Training loss: 0.058793238954060655
Validation loss: 2.4451837585394878

Epoch: 6| Step: 10
Training loss: 0.0683843260597246
Validation loss: 2.4498476984377

Epoch: 6| Step: 11
Training loss: 0.07687219222105025
Validation loss: 2.4487436657454893

Epoch: 6| Step: 12
Training loss: 0.06364031723429446
Validation loss: 2.48233862107869

Epoch: 6| Step: 13
Training loss: 0.08821565873080785
Validation loss: 2.457907039235193

Epoch: 662| Step: 0
Training loss: 0.10810152837503673
Validation loss: 2.4764282238296036

Epoch: 6| Step: 1
Training loss: 0.09994488665149275
Validation loss: 2.467238077857125

Epoch: 6| Step: 2
Training loss: 0.03978685870715912
Validation loss: 2.4625675660629183

Epoch: 6| Step: 3
Training loss: 0.058967826745063644
Validation loss: 2.4568242682780466

Epoch: 6| Step: 4
Training loss: 0.04797625837833761
Validation loss: 2.4401021477099105

Epoch: 6| Step: 5
Training loss: 0.07517252304239468
Validation loss: 2.4386225919029547

Epoch: 6| Step: 6
Training loss: 0.09010551507672214
Validation loss: 2.468086960503867

Epoch: 6| Step: 7
Training loss: 0.0786615572956775
Validation loss: 2.4411543195788465

Epoch: 6| Step: 8
Training loss: 0.11989711745113324
Validation loss: 2.4526066522128342

Epoch: 6| Step: 9
Training loss: 0.06951483294270916
Validation loss: 2.4428677539127404

Epoch: 6| Step: 10
Training loss: 0.07710069374157819
Validation loss: 2.4699867445698125

Epoch: 6| Step: 11
Training loss: 0.14544696943916316
Validation loss: 2.4408800235130825

Epoch: 6| Step: 12
Training loss: 0.1112763175548785
Validation loss: 2.4378031722749554

Epoch: 6| Step: 13
Training loss: 0.09624116840035109
Validation loss: 2.4476677900077597

Epoch: 663| Step: 0
Training loss: 0.09010254345333986
Validation loss: 2.4438753947559655

Epoch: 6| Step: 1
Training loss: 0.11703632060450526
Validation loss: 2.4753603647100983

Epoch: 6| Step: 2
Training loss: 0.08169934702513654
Validation loss: 2.4720617957160322

Epoch: 6| Step: 3
Training loss: 0.059670463781432995
Validation loss: 2.472854423581067

Epoch: 6| Step: 4
Training loss: 0.12564919689451587
Validation loss: 2.493897309189032

Epoch: 6| Step: 5
Training loss: 0.1252002750787897
Validation loss: 2.5246689194285135

Epoch: 6| Step: 6
Training loss: 0.12882793822081232
Validation loss: 2.489315433704495

Epoch: 6| Step: 7
Training loss: 0.10960817600798967
Validation loss: 2.512283393650161

Epoch: 6| Step: 8
Training loss: 0.09599633939601014
Validation loss: 2.482700476234018

Epoch: 6| Step: 9
Training loss: 0.08985045138535186
Validation loss: 2.4696068611763335

Epoch: 6| Step: 10
Training loss: 0.06660991879168965
Validation loss: 2.4650497785951515

Epoch: 6| Step: 11
Training loss: 0.05923936914249348
Validation loss: 2.434404092780955

Epoch: 6| Step: 12
Training loss: 0.06558095825065524
Validation loss: 2.461454422025694

Epoch: 6| Step: 13
Training loss: 0.07603383087857019
Validation loss: 2.436112273088796

Epoch: 664| Step: 0
Training loss: 0.11095147246363156
Validation loss: 2.435172936688114

Epoch: 6| Step: 1
Training loss: 0.06662166241817179
Validation loss: 2.460066479704132

Epoch: 6| Step: 2
Training loss: 0.123703461238341
Validation loss: 2.431023964424922

Epoch: 6| Step: 3
Training loss: 0.09193302264582201
Validation loss: 2.4422712345378157

Epoch: 6| Step: 4
Training loss: 0.10059098351423072
Validation loss: 2.4659687168392685

Epoch: 6| Step: 5
Training loss: 0.09000844993594057
Validation loss: 2.4577015279880774

Epoch: 6| Step: 6
Training loss: 0.10846423823975193
Validation loss: 2.4705977258878837

Epoch: 6| Step: 7
Training loss: 0.06182059361225062
Validation loss: 2.456541941328634

Epoch: 6| Step: 8
Training loss: 0.08368297209466714
Validation loss: 2.455880050731208

Epoch: 6| Step: 9
Training loss: 0.06921989508859244
Validation loss: 2.4679926599376896

Epoch: 6| Step: 10
Training loss: 0.11356481052309313
Validation loss: 2.481527621154833

Epoch: 6| Step: 11
Training loss: 0.07458328769636267
Validation loss: 2.4767812084515497

Epoch: 6| Step: 12
Training loss: 0.1102188291070804
Validation loss: 2.453546636602093

Epoch: 6| Step: 13
Training loss: 0.15522016655106782
Validation loss: 2.4629749380826276

Epoch: 665| Step: 0
Training loss: 0.08682044752517755
Validation loss: 2.438829829645613

Epoch: 6| Step: 1
Training loss: 0.057831883483435126
Validation loss: 2.4464142546593632

Epoch: 6| Step: 2
Training loss: 0.10453174412757396
Validation loss: 2.411441867151739

Epoch: 6| Step: 3
Training loss: 0.09265193511829034
Validation loss: 2.4468540654528246

Epoch: 6| Step: 4
Training loss: 0.10810294557571463
Validation loss: 2.4388158400228694

Epoch: 6| Step: 5
Training loss: 0.07313799122194073
Validation loss: 2.4393057180982116

Epoch: 6| Step: 6
Training loss: 0.12116754498298965
Validation loss: 2.44665413167972

Epoch: 6| Step: 7
Training loss: 0.10900379951224393
Validation loss: 2.443415222660259

Epoch: 6| Step: 8
Training loss: 0.09452318204389173
Validation loss: 2.436942350945992

Epoch: 6| Step: 9
Training loss: 0.09388913320726537
Validation loss: 2.4327999085606504

Epoch: 6| Step: 10
Training loss: 0.09017911288076606
Validation loss: 2.4563830098793096

Epoch: 6| Step: 11
Training loss: 0.08029103759080128
Validation loss: 2.463823820341679

Epoch: 6| Step: 12
Training loss: 0.0892684387626262
Validation loss: 2.488702128878211

Epoch: 6| Step: 13
Training loss: 0.10736323837021264
Validation loss: 2.4931803039389626

Epoch: 666| Step: 0
Training loss: 0.09557806329442992
Validation loss: 2.5042265368714163

Epoch: 6| Step: 1
Training loss: 0.0833740234375
Validation loss: 2.4823125780302213

Epoch: 6| Step: 2
Training loss: 0.10898591129355002
Validation loss: 2.459923662228773

Epoch: 6| Step: 3
Training loss: 0.112787948430618
Validation loss: 2.49360685858549

Epoch: 6| Step: 4
Training loss: 0.11825690680998306
Validation loss: 2.440522472136688

Epoch: 6| Step: 5
Training loss: 0.10434784679504688
Validation loss: 2.4467795581942546

Epoch: 6| Step: 6
Training loss: 0.11199188622233565
Validation loss: 2.4480033955148013

Epoch: 6| Step: 7
Training loss: 0.08259726423908839
Validation loss: 2.44199548710909

Epoch: 6| Step: 8
Training loss: 0.11095469569867378
Validation loss: 2.4691406030301555

Epoch: 6| Step: 9
Training loss: 0.07207863689822175
Validation loss: 2.4662681140650964

Epoch: 6| Step: 10
Training loss: 0.08208190682193492
Validation loss: 2.4422225575822867

Epoch: 6| Step: 11
Training loss: 0.07636271619756001
Validation loss: 2.4531839469587298

Epoch: 6| Step: 12
Training loss: 0.0624325358342886
Validation loss: 2.4326432941341185

Epoch: 6| Step: 13
Training loss: 0.059705990135542196
Validation loss: 2.4458169079775995

Epoch: 667| Step: 0
Training loss: 0.12219384237326619
Validation loss: 2.469418947143962

Epoch: 6| Step: 1
Training loss: 0.06971794991502214
Validation loss: 2.4472334471005905

Epoch: 6| Step: 2
Training loss: 0.12998426390279852
Validation loss: 2.446295873255749

Epoch: 6| Step: 3
Training loss: 0.14060552780122573
Validation loss: 2.463026172371931

Epoch: 6| Step: 4
Training loss: 0.09653201529389996
Validation loss: 2.453148809280472

Epoch: 6| Step: 5
Training loss: 0.0743265247850331
Validation loss: 2.4537160791086

Epoch: 6| Step: 6
Training loss: 0.05813698955481276
Validation loss: 2.460798451756235

Epoch: 6| Step: 7
Training loss: 0.06462141304811177
Validation loss: 2.4541637545850623

Epoch: 6| Step: 8
Training loss: 0.10995978461520009
Validation loss: 2.483438600284406

Epoch: 6| Step: 9
Training loss: 0.10626874505908858
Validation loss: 2.4599806819357015

Epoch: 6| Step: 10
Training loss: 0.10758666922935606
Validation loss: 2.4487403019867036

Epoch: 6| Step: 11
Training loss: 0.10691510654702073
Validation loss: 2.470350101841658

Epoch: 6| Step: 12
Training loss: 0.10397373352799749
Validation loss: 2.4769099108220227

Epoch: 6| Step: 13
Training loss: 0.09872983183311035
Validation loss: 2.4685887847054735

Epoch: 668| Step: 0
Training loss: 0.08980277930974806
Validation loss: 2.453714036002883

Epoch: 6| Step: 1
Training loss: 0.062240673531809614
Validation loss: 2.499280053219469

Epoch: 6| Step: 2
Training loss: 0.0919476346537799
Validation loss: 2.486205215431444

Epoch: 6| Step: 3
Training loss: 0.13796987282543427
Validation loss: 2.457509497381509

Epoch: 6| Step: 4
Training loss: 0.07912605106735135
Validation loss: 2.491409479143895

Epoch: 6| Step: 5
Training loss: 0.05395982471145447
Validation loss: 2.4942364705710305

Epoch: 6| Step: 6
Training loss: 0.08387961340889363
Validation loss: 2.4981384368320594

Epoch: 6| Step: 7
Training loss: 0.08551146011536477
Validation loss: 2.468707660495268

Epoch: 6| Step: 8
Training loss: 0.16157198502719985
Validation loss: 2.4903083017222976

Epoch: 6| Step: 9
Training loss: 0.07382578089186727
Validation loss: 2.494490311615955

Epoch: 6| Step: 10
Training loss: 0.05548555629958393
Validation loss: 2.4766336166022076

Epoch: 6| Step: 11
Training loss: 0.0687060421516733
Validation loss: 2.477650349740382

Epoch: 6| Step: 12
Training loss: 0.10618993765506751
Validation loss: 2.4928580589499774

Epoch: 6| Step: 13
Training loss: 0.0469433489831826
Validation loss: 2.452862572622154

Epoch: 669| Step: 0
Training loss: 0.0827851900467745
Validation loss: 2.477870719983588

Epoch: 6| Step: 1
Training loss: 0.07917826077719514
Validation loss: 2.473463137708994

Epoch: 6| Step: 2
Training loss: 0.08252729289102552
Validation loss: 2.4802983893493997

Epoch: 6| Step: 3
Training loss: 0.10834673774149194
Validation loss: 2.4555014182570987

Epoch: 6| Step: 4
Training loss: 0.08940477522134031
Validation loss: 2.457256501210096

Epoch: 6| Step: 5
Training loss: 0.062050313653645967
Validation loss: 2.45810562700473

Epoch: 6| Step: 6
Training loss: 0.08258502099540214
Validation loss: 2.4595194726035565

Epoch: 6| Step: 7
Training loss: 0.04294175551763558
Validation loss: 2.465160286038184

Epoch: 6| Step: 8
Training loss: 0.06158023059703532
Validation loss: 2.4747550095244275

Epoch: 6| Step: 9
Training loss: 0.09027554576001542
Validation loss: 2.4788361002656236

Epoch: 6| Step: 10
Training loss: 0.05727537241331365
Validation loss: 2.495875362620517

Epoch: 6| Step: 11
Training loss: 0.12797170051089035
Validation loss: 2.437656847690493

Epoch: 6| Step: 12
Training loss: 0.1022266351206153
Validation loss: 2.478290796779717

Epoch: 6| Step: 13
Training loss: 0.1403662367129454
Validation loss: 2.493583669241934

Epoch: 670| Step: 0
Training loss: 0.13277339359562174
Validation loss: 2.5312114303974367

Epoch: 6| Step: 1
Training loss: 0.08147116029076261
Validation loss: 2.496025550161317

Epoch: 6| Step: 2
Training loss: 0.09370127544228385
Validation loss: 2.5069986997914215

Epoch: 6| Step: 3
Training loss: 0.11990956451402232
Validation loss: 2.5122521865402687

Epoch: 6| Step: 4
Training loss: 0.11879530092797336
Validation loss: 2.482995889091663

Epoch: 6| Step: 5
Training loss: 0.18398636575905541
Validation loss: 2.4869326011105057

Epoch: 6| Step: 6
Training loss: 0.08117315528161032
Validation loss: 2.5247066603775927

Epoch: 6| Step: 7
Training loss: 0.08190612673577352
Validation loss: 2.4917358561135208

Epoch: 6| Step: 8
Training loss: 0.04346629510142949
Validation loss: 2.4549629010197918

Epoch: 6| Step: 9
Training loss: 0.07639073450334627
Validation loss: 2.4888000756160054

Epoch: 6| Step: 10
Training loss: 0.12291707655735962
Validation loss: 2.4908267066583707

Epoch: 6| Step: 11
Training loss: 0.15111746954910074
Validation loss: 2.5471041211624157

Epoch: 6| Step: 12
Training loss: 0.06679670113546488
Validation loss: 2.509683156596766

Epoch: 6| Step: 13
Training loss: 0.11233040888257093
Validation loss: 2.500011021579525

Epoch: 671| Step: 0
Training loss: 0.08545694588736574
Validation loss: 2.491726972043469

Epoch: 6| Step: 1
Training loss: 0.10886011953442853
Validation loss: 2.5229304756819104

Epoch: 6| Step: 2
Training loss: 0.13241479736588752
Validation loss: 2.475847596484024

Epoch: 6| Step: 3
Training loss: 0.11923235348175196
Validation loss: 2.4711503674943973

Epoch: 6| Step: 4
Training loss: 0.06669988645830957
Validation loss: 2.508925111796407

Epoch: 6| Step: 5
Training loss: 0.10608365364096896
Validation loss: 2.500004092592561

Epoch: 6| Step: 6
Training loss: 0.08546641040612542
Validation loss: 2.4763913902754555

Epoch: 6| Step: 7
Training loss: 0.09810254636585436
Validation loss: 2.4481226703273187

Epoch: 6| Step: 8
Training loss: 0.09438379448057063
Validation loss: 2.4711250779821223

Epoch: 6| Step: 9
Training loss: 0.0754013706119381
Validation loss: 2.462473702205717

Epoch: 6| Step: 10
Training loss: 0.07113756778749337
Validation loss: 2.4657258010015184

Epoch: 6| Step: 11
Training loss: 0.1322375502873931
Validation loss: 2.447000568194659

Epoch: 6| Step: 12
Training loss: 0.12108916612378483
Validation loss: 2.452045717155684

Epoch: 6| Step: 13
Training loss: 0.05389293267736163
Validation loss: 2.4738823432240378

Epoch: 672| Step: 0
Training loss: 0.07767912468298212
Validation loss: 2.4385704317390426

Epoch: 6| Step: 1
Training loss: 0.10225699547887082
Validation loss: 2.4656309422427967

Epoch: 6| Step: 2
Training loss: 0.05953245836318153
Validation loss: 2.475156040561598

Epoch: 6| Step: 3
Training loss: 0.12111380241858943
Validation loss: 2.4453794219975156

Epoch: 6| Step: 4
Training loss: 0.08858933871756162
Validation loss: 2.473525395920545

Epoch: 6| Step: 5
Training loss: 0.06453272571331133
Validation loss: 2.4672968834965223

Epoch: 6| Step: 6
Training loss: 0.1310265597589605
Validation loss: 2.4750395062051855

Epoch: 6| Step: 7
Training loss: 0.08242719325765294
Validation loss: 2.4694022545867322

Epoch: 6| Step: 8
Training loss: 0.10326801231084781
Validation loss: 2.484358253146525

Epoch: 6| Step: 9
Training loss: 0.059945063167154415
Validation loss: 2.5164010923260642

Epoch: 6| Step: 10
Training loss: 0.08187254528468138
Validation loss: 2.533916557144291

Epoch: 6| Step: 11
Training loss: 0.07137433921880544
Validation loss: 2.491813541859822

Epoch: 6| Step: 12
Training loss: 0.10856157347591777
Validation loss: 2.5124599117484196

Epoch: 6| Step: 13
Training loss: 0.041194515719106345
Validation loss: 2.504753121749059

Epoch: 673| Step: 0
Training loss: 0.06270090981331762
Validation loss: 2.524337330262491

Epoch: 6| Step: 1
Training loss: 0.06774845294884033
Validation loss: 2.537662042010145

Epoch: 6| Step: 2
Training loss: 0.10336263164917153
Validation loss: 2.5152533074496373

Epoch: 6| Step: 3
Training loss: 0.12929673007599699
Validation loss: 2.49742254270101

Epoch: 6| Step: 4
Training loss: 0.08124992113843171
Validation loss: 2.4679457778655403

Epoch: 6| Step: 5
Training loss: 0.08206483743698682
Validation loss: 2.5037597154684557

Epoch: 6| Step: 6
Training loss: 0.10546593750629854
Validation loss: 2.4588637123117505

Epoch: 6| Step: 7
Training loss: 0.08060772732046918
Validation loss: 2.4676841287486333

Epoch: 6| Step: 8
Training loss: 0.06180538558348728
Validation loss: 2.45214512963971

Epoch: 6| Step: 9
Training loss: 0.10707739301760028
Validation loss: 2.45359116339149

Epoch: 6| Step: 10
Training loss: 0.047180960427849826
Validation loss: 2.4561774895807464

Epoch: 6| Step: 11
Training loss: 0.12846657880926238
Validation loss: 2.4642371887509134

Epoch: 6| Step: 12
Training loss: 0.058646127020104466
Validation loss: 2.4503521542062447

Epoch: 6| Step: 13
Training loss: 0.09119560267992861
Validation loss: 2.4613947367890767

Epoch: 674| Step: 0
Training loss: 0.07626764072903214
Validation loss: 2.446742088919823

Epoch: 6| Step: 1
Training loss: 0.05111459071880217
Validation loss: 2.4755317445331944

Epoch: 6| Step: 2
Training loss: 0.05591993541969849
Validation loss: 2.453063798962271

Epoch: 6| Step: 3
Training loss: 0.10039324961099848
Validation loss: 2.4663148533982673

Epoch: 6| Step: 4
Training loss: 0.06243002781902324
Validation loss: 2.4833901438959827

Epoch: 6| Step: 5
Training loss: 0.05722974778121484
Validation loss: 2.4697719622303222

Epoch: 6| Step: 6
Training loss: 0.09396144744247484
Validation loss: 2.4745009948341115

Epoch: 6| Step: 7
Training loss: 0.06461552188236137
Validation loss: 2.450366313890212

Epoch: 6| Step: 8
Training loss: 0.12063198338686837
Validation loss: 2.4779849687791615

Epoch: 6| Step: 9
Training loss: 0.13630342751674576
Validation loss: 2.443033147242574

Epoch: 6| Step: 10
Training loss: 0.09737542783523219
Validation loss: 2.456786992895069

Epoch: 6| Step: 11
Training loss: 0.09240447510184485
Validation loss: 2.4787586945365696

Epoch: 6| Step: 12
Training loss: 0.08798684045964708
Validation loss: 2.4797366066145514

Epoch: 6| Step: 13
Training loss: 0.06387966978953093
Validation loss: 2.4917122128605005

Epoch: 675| Step: 0
Training loss: 0.056319940318934836
Validation loss: 2.4835317902351104

Epoch: 6| Step: 1
Training loss: 0.06341521893629139
Validation loss: 2.499061974546158

Epoch: 6| Step: 2
Training loss: 0.05306683925919535
Validation loss: 2.5264094039484926

Epoch: 6| Step: 3
Training loss: 0.06397175569535755
Validation loss: 2.5084477531357146

Epoch: 6| Step: 4
Training loss: 0.1340394287887009
Validation loss: 2.4893420234581134

Epoch: 6| Step: 5
Training loss: 0.06187081661796918
Validation loss: 2.4908969338270883

Epoch: 6| Step: 6
Training loss: 0.062245229673776985
Validation loss: 2.495937358624822

Epoch: 6| Step: 7
Training loss: 0.07536744566839887
Validation loss: 2.5416877349983586

Epoch: 6| Step: 8
Training loss: 0.10448066255703589
Validation loss: 2.4930756052108505

Epoch: 6| Step: 9
Training loss: 0.0897461786363136
Validation loss: 2.481329355055513

Epoch: 6| Step: 10
Training loss: 0.07947521204200908
Validation loss: 2.459471571680646

Epoch: 6| Step: 11
Training loss: 0.052192080733568604
Validation loss: 2.4962973021167034

Epoch: 6| Step: 12
Training loss: 0.11027263671470734
Validation loss: 2.4713303661122095

Epoch: 6| Step: 13
Training loss: 0.06963408198120147
Validation loss: 2.4782006458507024

Epoch: 676| Step: 0
Training loss: 0.09596623046434566
Validation loss: 2.45595034451031

Epoch: 6| Step: 1
Training loss: 0.048085952390022356
Validation loss: 2.4976944197908093

Epoch: 6| Step: 2
Training loss: 0.07005165645346398
Validation loss: 2.468615417010483

Epoch: 6| Step: 3
Training loss: 0.053056378433250936
Validation loss: 2.4982985685192793

Epoch: 6| Step: 4
Training loss: 0.1325924607316953
Validation loss: 2.4824782669339926

Epoch: 6| Step: 5
Training loss: 0.05888289989595531
Validation loss: 2.4529911336799475

Epoch: 6| Step: 6
Training loss: 0.13737432116834522
Validation loss: 2.4586538141030707

Epoch: 6| Step: 7
Training loss: 0.06886363689467745
Validation loss: 2.432554420830595

Epoch: 6| Step: 8
Training loss: 0.06911209064519547
Validation loss: 2.4861828116207256

Epoch: 6| Step: 9
Training loss: 0.07131594647417441
Validation loss: 2.448991913675007

Epoch: 6| Step: 10
Training loss: 0.08500068107675722
Validation loss: 2.473124134672955

Epoch: 6| Step: 11
Training loss: 0.07438733379292241
Validation loss: 2.4599753388856893

Epoch: 6| Step: 12
Training loss: 0.09720496331257773
Validation loss: 2.449307005553565

Epoch: 6| Step: 13
Training loss: 0.08854871843343293
Validation loss: 2.467032237208623

Epoch: 677| Step: 0
Training loss: 0.07949812700543903
Validation loss: 2.485332033029971

Epoch: 6| Step: 1
Training loss: 0.05556185440566992
Validation loss: 2.4665491811842823

Epoch: 6| Step: 2
Training loss: 0.06889540457200392
Validation loss: 2.4735425539912046

Epoch: 6| Step: 3
Training loss: 0.10434446856241875
Validation loss: 2.492702981544675

Epoch: 6| Step: 4
Training loss: 0.08312777938086169
Validation loss: 2.519306209123446

Epoch: 6| Step: 5
Training loss: 0.07194481664501838
Validation loss: 2.516928379280529

Epoch: 6| Step: 6
Training loss: 0.07002475591344283
Validation loss: 2.4584439553270476

Epoch: 6| Step: 7
Training loss: 0.14863049358709446
Validation loss: 2.5078274311097433

Epoch: 6| Step: 8
Training loss: 0.05305092341771453
Validation loss: 2.489171436897557

Epoch: 6| Step: 9
Training loss: 0.12959937669291768
Validation loss: 2.5104795589405837

Epoch: 6| Step: 10
Training loss: 0.08493903853466507
Validation loss: 2.4953706620810547

Epoch: 6| Step: 11
Training loss: 0.09768705835749004
Validation loss: 2.4913041369390814

Epoch: 6| Step: 12
Training loss: 0.05959446604983138
Validation loss: 2.481795195557969

Epoch: 6| Step: 13
Training loss: 0.10360878225440887
Validation loss: 2.468308893944531

Epoch: 678| Step: 0
Training loss: 0.06309535661893613
Validation loss: 2.468125480974408

Epoch: 6| Step: 1
Training loss: 0.05776389284002972
Validation loss: 2.436697990715879

Epoch: 6| Step: 2
Training loss: 0.0766087256257593
Validation loss: 2.454247685886299

Epoch: 6| Step: 3
Training loss: 0.042341265937657434
Validation loss: 2.4341037629099196

Epoch: 6| Step: 4
Training loss: 0.11393322444715583
Validation loss: 2.457825723184364

Epoch: 6| Step: 5
Training loss: 0.09570873497071287
Validation loss: 2.4616476075854163

Epoch: 6| Step: 6
Training loss: 0.0939852574101704
Validation loss: 2.434363301882875

Epoch: 6| Step: 7
Training loss: 0.13329910444944684
Validation loss: 2.447070539795245

Epoch: 6| Step: 8
Training loss: 0.06051546481845339
Validation loss: 2.4386626784426153

Epoch: 6| Step: 9
Training loss: 0.05131255116065213
Validation loss: 2.466594876367405

Epoch: 6| Step: 10
Training loss: 0.08660763665037093
Validation loss: 2.4416158638173675

Epoch: 6| Step: 11
Training loss: 0.057362141485843704
Validation loss: 2.4570687100063755

Epoch: 6| Step: 12
Training loss: 0.06132052277261523
Validation loss: 2.439715697029948

Epoch: 6| Step: 13
Training loss: 0.10979653344129053
Validation loss: 2.4468974033427533

Epoch: 679| Step: 0
Training loss: 0.1032194317518859
Validation loss: 2.4323476317800736

Epoch: 6| Step: 1
Training loss: 0.10150774983888787
Validation loss: 2.46198232425249

Epoch: 6| Step: 2
Training loss: 0.11876238912026758
Validation loss: 2.4750532527583715

Epoch: 6| Step: 3
Training loss: 0.06569683281823156
Validation loss: 2.461316623187575

Epoch: 6| Step: 4
Training loss: 0.05118353079406435
Validation loss: 2.4850650019288096

Epoch: 6| Step: 5
Training loss: 0.12469923447602067
Validation loss: 2.471964840428105

Epoch: 6| Step: 6
Training loss: 0.07885454603685123
Validation loss: 2.481157700979865

Epoch: 6| Step: 7
Training loss: 0.05572978957814434
Validation loss: 2.5130845805813617

Epoch: 6| Step: 8
Training loss: 0.06461069685173049
Validation loss: 2.5351863907136347

Epoch: 6| Step: 9
Training loss: 0.07097989150634419
Validation loss: 2.4853677435909742

Epoch: 6| Step: 10
Training loss: 0.10393537582817795
Validation loss: 2.5462007237116775

Epoch: 6| Step: 11
Training loss: 0.059645724247351234
Validation loss: 2.4896397961164696

Epoch: 6| Step: 12
Training loss: 0.09662520674970845
Validation loss: 2.512315152679967

Epoch: 6| Step: 13
Training loss: 0.08800162882018804
Validation loss: 2.5021185952825746

Epoch: 680| Step: 0
Training loss: 0.04080783200322118
Validation loss: 2.500384064368029

Epoch: 6| Step: 1
Training loss: 0.05733517959536658
Validation loss: 2.4766332522360113

Epoch: 6| Step: 2
Training loss: 0.06229109421491457
Validation loss: 2.511200881201842

Epoch: 6| Step: 3
Training loss: 0.07974187687981242
Validation loss: 2.4428961893457517

Epoch: 6| Step: 4
Training loss: 0.13856178265524852
Validation loss: 2.4457173011596756

Epoch: 6| Step: 5
Training loss: 0.10380694046211188
Validation loss: 2.437571489028823

Epoch: 6| Step: 6
Training loss: 0.10716240931892763
Validation loss: 2.4860690808367325

Epoch: 6| Step: 7
Training loss: 0.06488286872140193
Validation loss: 2.4615382349212465

Epoch: 6| Step: 8
Training loss: 0.12534765238026185
Validation loss: 2.4527197856449674

Epoch: 6| Step: 9
Training loss: 0.09089133346757601
Validation loss: 2.474723019166654

Epoch: 6| Step: 10
Training loss: 0.1012306201160145
Validation loss: 2.509584357242358

Epoch: 6| Step: 11
Training loss: 0.045034200756635126
Validation loss: 2.485957882753781

Epoch: 6| Step: 12
Training loss: 0.08765966746609313
Validation loss: 2.5109563087601083

Epoch: 6| Step: 13
Training loss: 0.07320578942289567
Validation loss: 2.5523172033225165

Epoch: 681| Step: 0
Training loss: 0.1467527283860855
Validation loss: 2.542399224375474

Epoch: 6| Step: 1
Training loss: 0.06264441167861994
Validation loss: 2.5364948071392597

Epoch: 6| Step: 2
Training loss: 0.07532934220637576
Validation loss: 2.5511313230872266

Epoch: 6| Step: 3
Training loss: 0.09368427277287787
Validation loss: 2.5492641371659457

Epoch: 6| Step: 4
Training loss: 0.12377758514003226
Validation loss: 2.4967781656460533

Epoch: 6| Step: 5
Training loss: 0.06450858042397226
Validation loss: 2.521860886673429

Epoch: 6| Step: 6
Training loss: 0.07567623471814516
Validation loss: 2.535348189436953

Epoch: 6| Step: 7
Training loss: 0.06209650401140466
Validation loss: 2.497172011819609

Epoch: 6| Step: 8
Training loss: 0.07703191069228713
Validation loss: 2.5398261056160347

Epoch: 6| Step: 9
Training loss: 0.07848377103533286
Validation loss: 2.5115255620498793

Epoch: 6| Step: 10
Training loss: 0.11629792171685295
Validation loss: 2.530910761402682

Epoch: 6| Step: 11
Training loss: 0.07845348204831774
Validation loss: 2.5206661699465216

Epoch: 6| Step: 12
Training loss: 0.07732979366789816
Validation loss: 2.509804476164385

Epoch: 6| Step: 13
Training loss: 0.08658006603902897
Validation loss: 2.5249386130462983

Epoch: 682| Step: 0
Training loss: 0.1330139371607355
Validation loss: 2.5179212410155984

Epoch: 6| Step: 1
Training loss: 0.05570270008831954
Validation loss: 2.5325230403054886

Epoch: 6| Step: 2
Training loss: 0.11958161801288696
Validation loss: 2.4907696206341865

Epoch: 6| Step: 3
Training loss: 0.1316541053593673
Validation loss: 2.5050587611488444

Epoch: 6| Step: 4
Training loss: 0.08499130988665084
Validation loss: 2.461758670767042

Epoch: 6| Step: 5
Training loss: 0.1151514320582018
Validation loss: 2.487641953888518

Epoch: 6| Step: 6
Training loss: 0.07621006741752953
Validation loss: 2.49866461364406

Epoch: 6| Step: 7
Training loss: 0.08734666126838267
Validation loss: 2.4664966491262166

Epoch: 6| Step: 8
Training loss: 0.09104420638833874
Validation loss: 2.4543235029504054

Epoch: 6| Step: 9
Training loss: 0.10102375816475455
Validation loss: 2.4738028590900627

Epoch: 6| Step: 10
Training loss: 0.0867386719871607
Validation loss: 2.4601200702670027

Epoch: 6| Step: 11
Training loss: 0.09321090552252974
Validation loss: 2.4869998731085636

Epoch: 6| Step: 12
Training loss: 0.10084470776699185
Validation loss: 2.493979094846783

Epoch: 6| Step: 13
Training loss: 0.06803803187719927
Validation loss: 2.5281881573381297

Epoch: 683| Step: 0
Training loss: 0.13916267258895443
Validation loss: 2.4992565792956243

Epoch: 6| Step: 1
Training loss: 0.12554350799195005
Validation loss: 2.509651913833437

Epoch: 6| Step: 2
Training loss: 0.09966963459934884
Validation loss: 2.4865251831711603

Epoch: 6| Step: 3
Training loss: 0.08215996317200777
Validation loss: 2.4897153071708145

Epoch: 6| Step: 4
Training loss: 0.1256653245572602
Validation loss: 2.47146800857712

Epoch: 6| Step: 5
Training loss: 0.10691418754729212
Validation loss: 2.461068142393666

Epoch: 6| Step: 6
Training loss: 0.09265238745005765
Validation loss: 2.4689909284067975

Epoch: 6| Step: 7
Training loss: 0.17489564117078768
Validation loss: 2.46157525557983

Epoch: 6| Step: 8
Training loss: 0.16150460554352816
Validation loss: 2.5080403962433087

Epoch: 6| Step: 9
Training loss: 0.10357502366741775
Validation loss: 2.492311787085055

Epoch: 6| Step: 10
Training loss: 0.07752596554780725
Validation loss: 2.502595620514591

Epoch: 6| Step: 11
Training loss: 0.09423627999508141
Validation loss: 2.52523945861166

Epoch: 6| Step: 12
Training loss: 0.12295144028357179
Validation loss: 2.5552663421724855

Epoch: 6| Step: 13
Training loss: 0.10732802713178392
Validation loss: 2.5666603872443186

Epoch: 684| Step: 0
Training loss: 0.11347611701339497
Validation loss: 2.529277441587015

Epoch: 6| Step: 1
Training loss: 0.09564831195546686
Validation loss: 2.521908665887865

Epoch: 6| Step: 2
Training loss: 0.06393133989520404
Validation loss: 2.4839795175055697

Epoch: 6| Step: 3
Training loss: 0.07151272711780292
Validation loss: 2.5059396060523462

Epoch: 6| Step: 4
Training loss: 0.057874738370549135
Validation loss: 2.465020437027958

Epoch: 6| Step: 5
Training loss: 0.1191111356166489
Validation loss: 2.4440014285615823

Epoch: 6| Step: 6
Training loss: 0.18455736427705813
Validation loss: 2.4032603414366163

Epoch: 6| Step: 7
Training loss: 0.14685047178192648
Validation loss: 2.441929345842448

Epoch: 6| Step: 8
Training loss: 0.09293927879593719
Validation loss: 2.4669164949574567

Epoch: 6| Step: 9
Training loss: 0.18215209976889699
Validation loss: 2.4588096277870948

Epoch: 6| Step: 10
Training loss: 0.20078234319723254
Validation loss: 2.5332153207685213

Epoch: 6| Step: 11
Training loss: 0.2538194948316096
Validation loss: 2.535270415945715

Epoch: 6| Step: 12
Training loss: 0.08210179156882096
Validation loss: 2.51526407465214

Epoch: 6| Step: 13
Training loss: 0.08874568388074525
Validation loss: 2.467021334320295

Epoch: 685| Step: 0
Training loss: 0.10920009081183053
Validation loss: 2.4810172404346393

Epoch: 6| Step: 1
Training loss: 0.1450964919333805
Validation loss: 2.502883228867251

Epoch: 6| Step: 2
Training loss: 0.09472243801458187
Validation loss: 2.467771898446727

Epoch: 6| Step: 3
Training loss: 0.13284461951347004
Validation loss: 2.453244231146653

Epoch: 6| Step: 4
Training loss: 0.107778978665056
Validation loss: 2.4700153213666134

Epoch: 6| Step: 5
Training loss: 0.13990121917933
Validation loss: 2.4469640410278752

Epoch: 6| Step: 6
Training loss: 0.11105419220547248
Validation loss: 2.5041038183498165

Epoch: 6| Step: 7
Training loss: 0.18905635461198714
Validation loss: 2.5107667747174944

Epoch: 6| Step: 8
Training loss: 0.09729611271335542
Validation loss: 2.5227712888814007

Epoch: 6| Step: 9
Training loss: 0.17096368906363887
Validation loss: 2.498799932251891

Epoch: 6| Step: 10
Training loss: 0.1501311751833836
Validation loss: 2.497922411431917

Epoch: 6| Step: 11
Training loss: 0.1607202623879518
Validation loss: 2.4586352007781893

Epoch: 6| Step: 12
Training loss: 0.08966592107091177
Validation loss: 2.4755693186291343

Epoch: 6| Step: 13
Training loss: 0.16768993480136052
Validation loss: 2.434127856193792

Epoch: 686| Step: 0
Training loss: 0.09874161771466079
Validation loss: 2.4914696806275

Epoch: 6| Step: 1
Training loss: 0.13100740259081267
Validation loss: 2.466619438023006

Epoch: 6| Step: 2
Training loss: 0.12595580913313412
Validation loss: 2.466285602243647

Epoch: 6| Step: 3
Training loss: 0.11686792907515264
Validation loss: 2.4388529601494997

Epoch: 6| Step: 4
Training loss: 0.11059135361091099
Validation loss: 2.459718082360161

Epoch: 6| Step: 5
Training loss: 0.13707974322911934
Validation loss: 2.481533081027912

Epoch: 6| Step: 6
Training loss: 0.338547151472215
Validation loss: 2.494335882986292

Epoch: 6| Step: 7
Training loss: 0.12752341777659038
Validation loss: 2.500642396572273

Epoch: 6| Step: 8
Training loss: 0.22274402093087609
Validation loss: 2.4785777200993646

Epoch: 6| Step: 9
Training loss: 0.23151815048933924
Validation loss: 2.4650050687838685

Epoch: 6| Step: 10
Training loss: 0.48180507503859565
Validation loss: 2.5407572189545427

Epoch: 6| Step: 11
Training loss: 0.2731576304726521
Validation loss: 2.499868366918845

Epoch: 6| Step: 12
Training loss: 0.1939776966913432
Validation loss: 2.462926389791973

Epoch: 6| Step: 13
Training loss: 0.27583311257876947
Validation loss: 2.46944233978898

Epoch: 687| Step: 0
Training loss: 0.1493259930823198
Validation loss: 2.4987900938971057

Epoch: 6| Step: 1
Training loss: 0.3492056790835004
Validation loss: 2.4843334159175052

Epoch: 6| Step: 2
Training loss: 0.37602407972609847
Validation loss: 2.504877263308296

Epoch: 6| Step: 3
Training loss: 0.3158656553087056
Validation loss: 2.5029388177009237

Epoch: 6| Step: 4
Training loss: 0.2616982238463642
Validation loss: 2.5326882523336653

Epoch: 6| Step: 5
Training loss: 0.19370677835069144
Validation loss: 2.5221964808997477

Epoch: 6| Step: 6
Training loss: 0.43707363606409066
Validation loss: 2.531187550209749

Epoch: 6| Step: 7
Training loss: 0.3824140460232881
Validation loss: 2.5667360981952543

Epoch: 6| Step: 8
Training loss: 0.40686416051931806
Validation loss: 2.602924146650256

Epoch: 6| Step: 9
Training loss: 0.16670485086429906
Validation loss: 2.504038500096474

Epoch: 6| Step: 10
Training loss: 0.2797980313892043
Validation loss: 2.507730096176133

Epoch: 6| Step: 11
Training loss: 0.2968707460801378
Validation loss: 2.4798198641542752

Epoch: 6| Step: 12
Training loss: 0.8315982318642862
Validation loss: 2.4778346623760856

Epoch: 6| Step: 13
Training loss: 0.5795524347279333
Validation loss: 2.5813263199903824

Epoch: 688| Step: 0
Training loss: 0.7951368561394337
Validation loss: 2.648865993039188

Epoch: 6| Step: 1
Training loss: 1.2539770754007
Validation loss: 2.608139587611452

Epoch: 6| Step: 2
Training loss: 1.5614970230626273
Validation loss: 2.6887348673863336

Epoch: 6| Step: 3
Training loss: 1.5946153273743995
Validation loss: 2.8359592262556097

Epoch: 6| Step: 4
Training loss: 1.1423720997311164
Validation loss: 3.042182902716553

Epoch: 6| Step: 5
Training loss: 1.3659062949137417
Validation loss: 2.9653697313278284

Epoch: 6| Step: 6
Training loss: 1.6626857739818757
Validation loss: 2.7642307677766764

Epoch: 6| Step: 7
Training loss: 1.7401383327436184
Validation loss: 2.541344640562727

Epoch: 6| Step: 8
Training loss: 1.3438831529516364
Validation loss: 2.4555109941693276

Epoch: 6| Step: 9
Training loss: 1.33769102069413
Validation loss: 2.41364656937783

Epoch: 6| Step: 10
Training loss: 1.011185258695586
Validation loss: 2.4347165340738877

Epoch: 6| Step: 11
Training loss: 0.7145860968518737
Validation loss: 2.4094241998619554

Epoch: 6| Step: 12
Training loss: 1.0732730656243896
Validation loss: 2.5202917573034043

Epoch: 6| Step: 13
Training loss: 1.362989509211894
Validation loss: 2.6150564947025314

Epoch: 689| Step: 0
Training loss: 1.6788072985587028
Validation loss: 2.5842238268995534

Epoch: 6| Step: 1
Training loss: 0.8294831780469157
Validation loss: 2.4928428515251526

Epoch: 6| Step: 2
Training loss: 0.723074632108777
Validation loss: 2.428722589755792

Epoch: 6| Step: 3
Training loss: 1.2381251384151561
Validation loss: 2.3994944851027653

Epoch: 6| Step: 4
Training loss: 1.0842112810620061
Validation loss: 2.422112392470534

Epoch: 6| Step: 5
Training loss: 0.5125266533410523
Validation loss: 2.4367457385808646

Epoch: 6| Step: 6
Training loss: 0.7025482355303194
Validation loss: 2.5489043145851777

Epoch: 6| Step: 7
Training loss: 0.9250997940565496
Validation loss: 2.533132662446101

Epoch: 6| Step: 8
Training loss: 1.2927742895390661
Validation loss: 2.470359811143442

Epoch: 6| Step: 9
Training loss: 0.8862840032040109
Validation loss: 2.4447475948353348

Epoch: 6| Step: 10
Training loss: 1.7631007692442782
Validation loss: 2.3849161341831198

Epoch: 6| Step: 11
Training loss: 0.8884805662040205
Validation loss: 2.3602050112317405

Epoch: 6| Step: 12
Training loss: 1.3140884959295083
Validation loss: 2.4359318106278733

Epoch: 6| Step: 13
Training loss: 1.2896055984834638
Validation loss: 2.4018226061607613

Epoch: 690| Step: 0
Training loss: 0.8196420018333819
Validation loss: 2.4035634573208386

Epoch: 6| Step: 1
Training loss: 1.10381708669209
Validation loss: 2.4470731766951213

Epoch: 6| Step: 2
Training loss: 1.2552980203626758
Validation loss: 2.427929266366503

Epoch: 6| Step: 3
Training loss: 0.8119781725773202
Validation loss: 2.425714120227796

Epoch: 6| Step: 4
Training loss: 0.9392498851305943
Validation loss: 2.455253768980036

Epoch: 6| Step: 5
Training loss: 0.9320892597317597
Validation loss: 2.4292899296709933

Epoch: 6| Step: 6
Training loss: 0.8105737153170904
Validation loss: 2.4970529577896907

Epoch: 6| Step: 7
Training loss: 0.8507264258845515
Validation loss: 2.510160015801912

Epoch: 6| Step: 8
Training loss: 0.9555611354427161
Validation loss: 2.552002527105753

Epoch: 6| Step: 9
Training loss: 1.0543783229194383
Validation loss: 2.5669574226537835

Epoch: 6| Step: 10
Training loss: 0.5895765848975495
Validation loss: 2.5633833938442234

Epoch: 6| Step: 11
Training loss: 1.0861466569983669
Validation loss: 2.5542604269378053

Epoch: 6| Step: 12
Training loss: 0.5921585689915788
Validation loss: 2.53379867464786

Epoch: 6| Step: 13
Training loss: 0.6719394919027333
Validation loss: 2.5522238081007345

Epoch: 691| Step: 0
Training loss: 0.743419949042572
Validation loss: 2.5458566227716286

Epoch: 6| Step: 1
Training loss: 0.7140911705888996
Validation loss: 2.5403192385670907

Epoch: 6| Step: 2
Training loss: 0.7573830479019431
Validation loss: 2.49389750861435

Epoch: 6| Step: 3
Training loss: 0.5846153856228721
Validation loss: 2.5215662683381845

Epoch: 6| Step: 4
Training loss: 0.822701417963622
Validation loss: 2.5179285422131272

Epoch: 6| Step: 5
Training loss: 0.5636016865449881
Validation loss: 2.5005414858319184

Epoch: 6| Step: 6
Training loss: 0.6096141052649222
Validation loss: 2.4767545500936468

Epoch: 6| Step: 7
Training loss: 0.4682458232453029
Validation loss: 2.466368932376493

Epoch: 6| Step: 8
Training loss: 0.8886161367521968
Validation loss: 2.4386664408583183

Epoch: 6| Step: 9
Training loss: 0.6606524030691522
Validation loss: 2.446108281825472

Epoch: 6| Step: 10
Training loss: 0.5293348798444979
Validation loss: 2.405053372697698

Epoch: 6| Step: 11
Training loss: 0.7726715225237745
Validation loss: 2.371036662179983

Epoch: 6| Step: 12
Training loss: 0.4971570162296355
Validation loss: 2.3784148067974322

Epoch: 6| Step: 13
Training loss: 0.51160097586872
Validation loss: 2.4198521009904894

Epoch: 692| Step: 0
Training loss: 0.5046835825387186
Validation loss: 2.4293944089032595

Epoch: 6| Step: 1
Training loss: 0.6501138459055399
Validation loss: 2.4603237644040945

Epoch: 6| Step: 2
Training loss: 0.6786978740944369
Validation loss: 2.5005770148142052

Epoch: 6| Step: 3
Training loss: 0.37500508622852785
Validation loss: 2.5119435521020437

Epoch: 6| Step: 4
Training loss: 0.42089496796985754
Validation loss: 2.529979520154932

Epoch: 6| Step: 5
Training loss: 0.44044179963164537
Validation loss: 2.526512534619877

Epoch: 6| Step: 6
Training loss: 0.4624261739163332
Validation loss: 2.5169234076880107

Epoch: 6| Step: 7
Training loss: 0.4607305870520115
Validation loss: 2.5237767720306508

Epoch: 6| Step: 8
Training loss: 0.4216527530041992
Validation loss: 2.4611472471942855

Epoch: 6| Step: 9
Training loss: 0.59376099224958
Validation loss: 2.504923710543852

Epoch: 6| Step: 10
Training loss: 0.6466221734557953
Validation loss: 2.476690653742757

Epoch: 6| Step: 11
Training loss: 0.2824224696278413
Validation loss: 2.4744087000150685

Epoch: 6| Step: 12
Training loss: 0.6003580793148287
Validation loss: 2.4085498734465167

Epoch: 6| Step: 13
Training loss: 0.8197957182173764
Validation loss: 2.4297143202481393

Epoch: 693| Step: 0
Training loss: 0.41824285485593926
Validation loss: 2.4239732727721077

Epoch: 6| Step: 1
Training loss: 0.49471313120986316
Validation loss: 2.4217973117759546

Epoch: 6| Step: 2
Training loss: 0.46724690407308517
Validation loss: 2.417132022707656

Epoch: 6| Step: 3
Training loss: 0.508520659601862
Validation loss: 2.4293088343225504

Epoch: 6| Step: 4
Training loss: 0.3915953219480154
Validation loss: 2.4437831570401887

Epoch: 6| Step: 5
Training loss: 0.44670242765427515
Validation loss: 2.4407253534292916

Epoch: 6| Step: 6
Training loss: 0.4828548110397131
Validation loss: 2.437839566703659

Epoch: 6| Step: 7
Training loss: 0.4170304756543262
Validation loss: 2.4085231421635522

Epoch: 6| Step: 8
Training loss: 0.36805399658464755
Validation loss: 2.3949272172173663

Epoch: 6| Step: 9
Training loss: 0.31443485657125414
Validation loss: 2.373999103547252

Epoch: 6| Step: 10
Training loss: 0.42306770280481104
Validation loss: 2.397567387570883

Epoch: 6| Step: 11
Training loss: 0.3581465165763017
Validation loss: 2.395718451300768

Epoch: 6| Step: 12
Training loss: 0.4417801851312502
Validation loss: 2.3958115678808865

Epoch: 6| Step: 13
Training loss: 0.3498751839251919
Validation loss: 2.3570363678973956

Epoch: 694| Step: 0
Training loss: 0.45669752146677084
Validation loss: 2.411136949608127

Epoch: 6| Step: 1
Training loss: 0.3846907954380864
Validation loss: 2.393081150746473

Epoch: 6| Step: 2
Training loss: 0.35541995206136534
Validation loss: 2.3831890183268563

Epoch: 6| Step: 3
Training loss: 0.21097044334302748
Validation loss: 2.3854776530394264

Epoch: 6| Step: 4
Training loss: 0.3448552115834035
Validation loss: 2.4387932526333884

Epoch: 6| Step: 5
Training loss: 0.38640338870422547
Validation loss: 2.4538488209152267

Epoch: 6| Step: 6
Training loss: 0.37406881271300335
Validation loss: 2.4525906391188106

Epoch: 6| Step: 7
Training loss: 0.28675987094295713
Validation loss: 2.4459767188286516

Epoch: 6| Step: 8
Training loss: 0.3236557657117205
Validation loss: 2.4580169812759003

Epoch: 6| Step: 9
Training loss: 0.38154641807213546
Validation loss: 2.467353042898545

Epoch: 6| Step: 10
Training loss: 0.2769852994837869
Validation loss: 2.477684230969285

Epoch: 6| Step: 11
Training loss: 0.3694116717496468
Validation loss: 2.4817218199571394

Epoch: 6| Step: 12
Training loss: 0.2755849707118108
Validation loss: 2.47306348142287

Epoch: 6| Step: 13
Training loss: 0.2097350835321419
Validation loss: 2.4298214790569705

Epoch: 695| Step: 0
Training loss: 0.26100907971494336
Validation loss: 2.459622127846856

Epoch: 6| Step: 1
Training loss: 0.25341426427702435
Validation loss: 2.4407273842997865

Epoch: 6| Step: 2
Training loss: 0.40839042199623055
Validation loss: 2.4214486044819092

Epoch: 6| Step: 3
Training loss: 0.29497532644375835
Validation loss: 2.424266911413978

Epoch: 6| Step: 4
Training loss: 0.3300733058058478
Validation loss: 2.4425502386336193

Epoch: 6| Step: 5
Training loss: 0.4505764553889594
Validation loss: 2.455696279466289

Epoch: 6| Step: 6
Training loss: 0.31200610709479476
Validation loss: 2.4572735005815516

Epoch: 6| Step: 7
Training loss: 0.2868489492136151
Validation loss: 2.4340982145539023

Epoch: 6| Step: 8
Training loss: 0.26871399749198055
Validation loss: 2.4788314359676726

Epoch: 6| Step: 9
Training loss: 0.2681834898021881
Validation loss: 2.4477947523294725

Epoch: 6| Step: 10
Training loss: 0.22590643339404273
Validation loss: 2.4752224550099546

Epoch: 6| Step: 11
Training loss: 0.30072620433109876
Validation loss: 2.480199451021221

Epoch: 6| Step: 12
Training loss: 0.37449679786372503
Validation loss: 2.4248965306943027

Epoch: 6| Step: 13
Training loss: 0.31794409785202826
Validation loss: 2.4638575004757333

Epoch: 696| Step: 0
Training loss: 0.2798445873152125
Validation loss: 2.4552660355633655

Epoch: 6| Step: 1
Training loss: 0.28843535876073434
Validation loss: 2.466084688094822

Epoch: 6| Step: 2
Training loss: 0.3249831667538825
Validation loss: 2.4579647362131256

Epoch: 6| Step: 3
Training loss: 0.23836843271465674
Validation loss: 2.4061169544264813

Epoch: 6| Step: 4
Training loss: 0.2569969165910186
Validation loss: 2.37752169492194

Epoch: 6| Step: 5
Training loss: 0.23981688439072357
Validation loss: 2.426206123289335

Epoch: 6| Step: 6
Training loss: 0.3565459435954517
Validation loss: 2.4041536359365785

Epoch: 6| Step: 7
Training loss: 0.2548470015233605
Validation loss: 2.400628544425281

Epoch: 6| Step: 8
Training loss: 0.2146864054789399
Validation loss: 2.403188164565481

Epoch: 6| Step: 9
Training loss: 0.21901446772278674
Validation loss: 2.4144334888672954

Epoch: 6| Step: 10
Training loss: 0.33573939892030774
Validation loss: 2.427291308428431

Epoch: 6| Step: 11
Training loss: 0.25126023347615273
Validation loss: 2.4186578654894655

Epoch: 6| Step: 12
Training loss: 0.2261216873856256
Validation loss: 2.4234365329529064

Epoch: 6| Step: 13
Training loss: 0.26247329973487094
Validation loss: 2.4315987384494866

Epoch: 697| Step: 0
Training loss: 0.19861477570239255
Validation loss: 2.4438013747029164

Epoch: 6| Step: 1
Training loss: 0.262018416493644
Validation loss: 2.4296546471930114

Epoch: 6| Step: 2
Training loss: 0.24136493570067902
Validation loss: 2.419708820736288

Epoch: 6| Step: 3
Training loss: 0.19480096587425327
Validation loss: 2.43388449527181

Epoch: 6| Step: 4
Training loss: 0.2063612623373206
Validation loss: 2.4269668408197433

Epoch: 6| Step: 5
Training loss: 0.14894101424559447
Validation loss: 2.410182321776777

Epoch: 6| Step: 6
Training loss: 0.23940585480380905
Validation loss: 2.399845320577736

Epoch: 6| Step: 7
Training loss: 0.26537496354924445
Validation loss: 2.3993568647815757

Epoch: 6| Step: 8
Training loss: 0.2510819417981611
Validation loss: 2.434101782596944

Epoch: 6| Step: 9
Training loss: 0.2685704313345015
Validation loss: 2.413158301704981

Epoch: 6| Step: 10
Training loss: 0.22578461060448402
Validation loss: 2.389244530868355

Epoch: 6| Step: 11
Training loss: 0.2687495131820883
Validation loss: 2.415627385679683

Epoch: 6| Step: 12
Training loss: 0.30463664535237284
Validation loss: 2.4275730915589055

Epoch: 6| Step: 13
Training loss: 0.23391635046067683
Validation loss: 2.421306366841807

Epoch: 698| Step: 0
Training loss: 0.24708849572379438
Validation loss: 2.466381367156711

Epoch: 6| Step: 1
Training loss: 0.17176313986724662
Validation loss: 2.425661991096678

Epoch: 6| Step: 2
Training loss: 0.18434498671954108
Validation loss: 2.414082627797114

Epoch: 6| Step: 3
Training loss: 0.1884552147985609
Validation loss: 2.4462855035870064

Epoch: 6| Step: 4
Training loss: 0.19237407916234697
Validation loss: 2.440625772004312

Epoch: 6| Step: 5
Training loss: 0.183858133242633
Validation loss: 2.4197241572354966

Epoch: 6| Step: 6
Training loss: 0.20245531533980318
Validation loss: 2.439842688059206

Epoch: 6| Step: 7
Training loss: 0.29738952571016547
Validation loss: 2.4332423113331134

Epoch: 6| Step: 8
Training loss: 0.22694813859093863
Validation loss: 2.426280369751516

Epoch: 6| Step: 9
Training loss: 0.17877996393630333
Validation loss: 2.408097558144148

Epoch: 6| Step: 10
Training loss: 0.27415687754198426
Validation loss: 2.4370441688926845

Epoch: 6| Step: 11
Training loss: 0.1996461920181848
Validation loss: 2.4492465799722973

Epoch: 6| Step: 12
Training loss: 0.18691674552434798
Validation loss: 2.423230492429752

Epoch: 6| Step: 13
Training loss: 0.08680412754897569
Validation loss: 2.4714284416918395

Epoch: 699| Step: 0
Training loss: 0.1985596712497486
Validation loss: 2.4418826925062156

Epoch: 6| Step: 1
Training loss: 0.20771358616945465
Validation loss: 2.4386940327806803

Epoch: 6| Step: 2
Training loss: 0.1417358879422415
Validation loss: 2.478873866276834

Epoch: 6| Step: 3
Training loss: 0.24361850602942128
Validation loss: 2.4796589420975317

Epoch: 6| Step: 4
Training loss: 0.16224965380115927
Validation loss: 2.4448484774470405

Epoch: 6| Step: 5
Training loss: 0.27819364911347305
Validation loss: 2.4676511145726923

Epoch: 6| Step: 6
Training loss: 0.16122407351771978
Validation loss: 2.4398409637940355

Epoch: 6| Step: 7
Training loss: 0.2725077079636482
Validation loss: 2.4722170365574785

Epoch: 6| Step: 8
Training loss: 0.2345027734240682
Validation loss: 2.485810974984632

Epoch: 6| Step: 9
Training loss: 0.14919192187816166
Validation loss: 2.455162624926465

Epoch: 6| Step: 10
Training loss: 0.1792727846903516
Validation loss: 2.4668445786013087

Epoch: 6| Step: 11
Training loss: 0.2244397891498062
Validation loss: 2.444883739659891

Epoch: 6| Step: 12
Training loss: 0.23605486937823147
Validation loss: 2.440196021653721

Epoch: 6| Step: 13
Training loss: 0.2437715181609453
Validation loss: 2.4399604526968193

Epoch: 700| Step: 0
Training loss: 0.1307982686407952
Validation loss: 2.389939162268246

Epoch: 6| Step: 1
Training loss: 0.1986645769735683
Validation loss: 2.3943524406895604

Epoch: 6| Step: 2
Training loss: 0.23625319845819812
Validation loss: 2.3949732791429823

Epoch: 6| Step: 3
Training loss: 0.23705551032109073
Validation loss: 2.3949954250751935

Epoch: 6| Step: 4
Training loss: 0.17336694210087208
Validation loss: 2.3902930090107413

Epoch: 6| Step: 5
Training loss: 0.18357764843073582
Validation loss: 2.393228353978499

Epoch: 6| Step: 6
Training loss: 0.22674143236717548
Validation loss: 2.3904207965312434

Epoch: 6| Step: 7
Training loss: 0.13895824574873344
Validation loss: 2.4201320837731077

Epoch: 6| Step: 8
Training loss: 0.19589360574409606
Validation loss: 2.3924333999321545

Epoch: 6| Step: 9
Training loss: 0.11987115116523882
Validation loss: 2.4348927403359575

Epoch: 6| Step: 10
Training loss: 0.26059015535107055
Validation loss: 2.4494014142692935

Epoch: 6| Step: 11
Training loss: 0.1888611383268212
Validation loss: 2.4396000795386943

Epoch: 6| Step: 12
Training loss: 0.17045923198593457
Validation loss: 2.4509855583855495

Epoch: 6| Step: 13
Training loss: 0.14531142147238216
Validation loss: 2.4638858683401286

Epoch: 701| Step: 0
Training loss: 0.21716817214095854
Validation loss: 2.474130915185012

Epoch: 6| Step: 1
Training loss: 0.13862261098569442
Validation loss: 2.448372351325472

Epoch: 6| Step: 2
Training loss: 0.17078916053216
Validation loss: 2.4526385160722137

Epoch: 6| Step: 3
Training loss: 0.17563852768008834
Validation loss: 2.4358076089615692

Epoch: 6| Step: 4
Training loss: 0.23410202660300572
Validation loss: 2.425932803274665

Epoch: 6| Step: 5
Training loss: 0.22172404782267877
Validation loss: 2.4463611230865254

Epoch: 6| Step: 6
Training loss: 0.1783296237950423
Validation loss: 2.5091779858911427

Epoch: 6| Step: 7
Training loss: 0.15695263712053817
Validation loss: 2.456752892864356

Epoch: 6| Step: 8
Training loss: 0.2599980741209449
Validation loss: 2.4614922458988415

Epoch: 6| Step: 9
Training loss: 0.19215807883372074
Validation loss: 2.451932720956709

Epoch: 6| Step: 10
Training loss: 0.10571982821282029
Validation loss: 2.4672993366883422

Epoch: 6| Step: 11
Training loss: 0.1711411523691559
Validation loss: 2.4699345160463313

Epoch: 6| Step: 12
Training loss: 0.21440224799660834
Validation loss: 2.4729054599231617

Epoch: 6| Step: 13
Training loss: 0.14688085940015977
Validation loss: 2.496877154468543

Epoch: 702| Step: 0
Training loss: 0.15151713542808898
Validation loss: 2.452451631411228

Epoch: 6| Step: 1
Training loss: 0.16154128809753263
Validation loss: 2.4493525064035158

Epoch: 6| Step: 2
Training loss: 0.1548686238701295
Validation loss: 2.454569159302446

Epoch: 6| Step: 3
Training loss: 0.1460745610165402
Validation loss: 2.4577445306566363

Epoch: 6| Step: 4
Training loss: 0.16916778557819215
Validation loss: 2.4127264858127813

Epoch: 6| Step: 5
Training loss: 0.11747391588132353
Validation loss: 2.43092838746422

Epoch: 6| Step: 6
Training loss: 0.14748926711635107
Validation loss: 2.4245643315707666

Epoch: 6| Step: 7
Training loss: 0.21872862643319202
Validation loss: 2.452916112590938

Epoch: 6| Step: 8
Training loss: 0.15694413378203242
Validation loss: 2.4703516948090285

Epoch: 6| Step: 9
Training loss: 0.17832931044607436
Validation loss: 2.4606129255327804

Epoch: 6| Step: 10
Training loss: 0.1930971583262992
Validation loss: 2.4426760445854137

Epoch: 6| Step: 11
Training loss: 0.19337293789238158
Validation loss: 2.494500897635957

Epoch: 6| Step: 12
Training loss: 0.1665719416270169
Validation loss: 2.4733401091586487

Epoch: 6| Step: 13
Training loss: 0.11639070231019924
Validation loss: 2.483076272718692

Epoch: 703| Step: 0
Training loss: 0.21640745190173044
Validation loss: 2.4539272965528136

Epoch: 6| Step: 1
Training loss: 0.1698941504123989
Validation loss: 2.476166773993885

Epoch: 6| Step: 2
Training loss: 0.1180063566681892
Validation loss: 2.469287822558258

Epoch: 6| Step: 3
Training loss: 0.19722932538223958
Validation loss: 2.4399024129735882

Epoch: 6| Step: 4
Training loss: 0.16534624911719362
Validation loss: 2.4639316515434406

Epoch: 6| Step: 5
Training loss: 0.15415067627390658
Validation loss: 2.4504057720428754

Epoch: 6| Step: 6
Training loss: 0.21496397469295284
Validation loss: 2.454722285569092

Epoch: 6| Step: 7
Training loss: 0.2348346335849092
Validation loss: 2.4648913353912323

Epoch: 6| Step: 8
Training loss: 0.16047357895521022
Validation loss: 2.452784256019235

Epoch: 6| Step: 9
Training loss: 0.11794277230396699
Validation loss: 2.4354633565950237

Epoch: 6| Step: 10
Training loss: 0.19955546776543173
Validation loss: 2.4580443121812094

Epoch: 6| Step: 11
Training loss: 0.13419582319898113
Validation loss: 2.4230704573412387

Epoch: 6| Step: 12
Training loss: 0.11064008112928483
Validation loss: 2.4183473838761578

Epoch: 6| Step: 13
Training loss: 0.09559237143996219
Validation loss: 2.441369888002064

Epoch: 704| Step: 0
Training loss: 0.12018819198989428
Validation loss: 2.430355551929324

Epoch: 6| Step: 1
Training loss: 0.15325468323087443
Validation loss: 2.4202577894990767

Epoch: 6| Step: 2
Training loss: 0.13794255886126194
Validation loss: 2.4167653034676193

Epoch: 6| Step: 3
Training loss: 0.17806369538004693
Validation loss: 2.4294567918564254

Epoch: 6| Step: 4
Training loss: 0.14397505112677075
Validation loss: 2.4455628793548962

Epoch: 6| Step: 5
Training loss: 0.1841629922850532
Validation loss: 2.4286088863037234

Epoch: 6| Step: 6
Training loss: 0.1508225950074794
Validation loss: 2.4365467061626633

Epoch: 6| Step: 7
Training loss: 0.1673324976716731
Validation loss: 2.4431278204321414

Epoch: 6| Step: 8
Training loss: 0.1442130813848457
Validation loss: 2.4328363549171135

Epoch: 6| Step: 9
Training loss: 0.1709989742469975
Validation loss: 2.4075097796356784

Epoch: 6| Step: 10
Training loss: 0.09672207818136455
Validation loss: 2.4217812722786136

Epoch: 6| Step: 11
Training loss: 0.09884480083134936
Validation loss: 2.399662413833105

Epoch: 6| Step: 12
Training loss: 0.14250045777339354
Validation loss: 2.4098753278868528

Epoch: 6| Step: 13
Training loss: 0.25783404346967065
Validation loss: 2.410926381885943

Epoch: 705| Step: 0
Training loss: 0.12763184535931593
Validation loss: 2.4288032504595685

Epoch: 6| Step: 1
Training loss: 0.16516434129980412
Validation loss: 2.413575853969415

Epoch: 6| Step: 2
Training loss: 0.18576254106391138
Validation loss: 2.4095539273699504

Epoch: 6| Step: 3
Training loss: 0.15808659252938764
Validation loss: 2.434001900956256

Epoch: 6| Step: 4
Training loss: 0.1603066157214764
Validation loss: 2.4296100499784723

Epoch: 6| Step: 5
Training loss: 0.11827329441941054
Validation loss: 2.4342314748178153

Epoch: 6| Step: 6
Training loss: 0.1314500459269374
Validation loss: 2.455493905336887

Epoch: 6| Step: 7
Training loss: 0.14332592831263924
Validation loss: 2.4566684001557455

Epoch: 6| Step: 8
Training loss: 0.17845059802723917
Validation loss: 2.4533810533833242

Epoch: 6| Step: 9
Training loss: 0.13884036479783812
Validation loss: 2.425151646875747

Epoch: 6| Step: 10
Training loss: 0.17997445123872052
Validation loss: 2.4243988438480373

Epoch: 6| Step: 11
Training loss: 0.18545579180486188
Validation loss: 2.4297117489188755

Epoch: 6| Step: 12
Training loss: 0.2091728679496351
Validation loss: 2.4355859743216537

Epoch: 6| Step: 13
Training loss: 0.20414642133049662
Validation loss: 2.4322544899702034

Epoch: 706| Step: 0
Training loss: 0.12212718783056825
Validation loss: 2.409649943592807

Epoch: 6| Step: 1
Training loss: 0.12779208055152863
Validation loss: 2.378453150914939

Epoch: 6| Step: 2
Training loss: 0.212007554697325
Validation loss: 2.4070235906490276

Epoch: 6| Step: 3
Training loss: 0.14054655165155355
Validation loss: 2.375900283582445

Epoch: 6| Step: 4
Training loss: 0.21506511381446086
Validation loss: 2.3696110309143084

Epoch: 6| Step: 5
Training loss: 0.2896919742514414
Validation loss: 2.36356927466937

Epoch: 6| Step: 6
Training loss: 0.18410795317658235
Validation loss: 2.375823642891094

Epoch: 6| Step: 7
Training loss: 0.20460705013345337
Validation loss: 2.3864264093264933

Epoch: 6| Step: 8
Training loss: 0.12283594353611595
Validation loss: 2.3708727055236407

Epoch: 6| Step: 9
Training loss: 0.19396259157899304
Validation loss: 2.4105871559969203

Epoch: 6| Step: 10
Training loss: 0.137091883606007
Validation loss: 2.3631920218922495

Epoch: 6| Step: 11
Training loss: 0.10872492294873454
Validation loss: 2.3626617397978826

Epoch: 6| Step: 12
Training loss: 0.09587041188959562
Validation loss: 2.4224401573424377

Epoch: 6| Step: 13
Training loss: 0.15710533989571643
Validation loss: 2.414713729936999

Epoch: 707| Step: 0
Training loss: 0.15281116477211346
Validation loss: 2.4310696508694294

Epoch: 6| Step: 1
Training loss: 0.14298101226667484
Validation loss: 2.4377044032499398

Epoch: 6| Step: 2
Training loss: 0.14783961576625188
Validation loss: 2.421591284227022

Epoch: 6| Step: 3
Training loss: 0.11190087655164531
Validation loss: 2.412512952848535

Epoch: 6| Step: 4
Training loss: 0.1633216502206246
Validation loss: 2.4294734064280115

Epoch: 6| Step: 5
Training loss: 0.17880190425841241
Validation loss: 2.412685817461347

Epoch: 6| Step: 6
Training loss: 0.16585125359279093
Validation loss: 2.4049578008232033

Epoch: 6| Step: 7
Training loss: 0.18171749744328006
Validation loss: 2.4184599712455794

Epoch: 6| Step: 8
Training loss: 0.09060721366733249
Validation loss: 2.4305319319561924

Epoch: 6| Step: 9
Training loss: 0.1305354436141837
Validation loss: 2.3950275351892456

Epoch: 6| Step: 10
Training loss: 0.14299295772871723
Validation loss: 2.4138083263905568

Epoch: 6| Step: 11
Training loss: 0.13323005784337907
Validation loss: 2.4018057864379045

Epoch: 6| Step: 12
Training loss: 0.14020119489699343
Validation loss: 2.4211206378735626

Epoch: 6| Step: 13
Training loss: 0.17159130242908083
Validation loss: 2.3978385063751393

Epoch: 708| Step: 0
Training loss: 0.14491424848945714
Validation loss: 2.406019849974778

Epoch: 6| Step: 1
Training loss: 0.11592301194645976
Validation loss: 2.4127014467105834

Epoch: 6| Step: 2
Training loss: 0.16561745410499867
Validation loss: 2.374455070479059

Epoch: 6| Step: 3
Training loss: 0.17512679126246808
Validation loss: 2.3954971186353857

Epoch: 6| Step: 4
Training loss: 0.11982185995676232
Validation loss: 2.3524622927912535

Epoch: 6| Step: 5
Training loss: 0.16968514405682225
Validation loss: 2.3901337299715584

Epoch: 6| Step: 6
Training loss: 0.18816013160228182
Validation loss: 2.3907177798729333

Epoch: 6| Step: 7
Training loss: 0.14295887730597892
Validation loss: 2.4131127032288804

Epoch: 6| Step: 8
Training loss: 0.1178573537180612
Validation loss: 2.3906609708581255

Epoch: 6| Step: 9
Training loss: 0.1401065302109391
Validation loss: 2.3900665042617737

Epoch: 6| Step: 10
Training loss: 0.13168714391871153
Validation loss: 2.3936440454371954

Epoch: 6| Step: 11
Training loss: 0.1566583899224939
Validation loss: 2.406724448082077

Epoch: 6| Step: 12
Training loss: 0.16965021143474832
Validation loss: 2.399226667655218

Epoch: 6| Step: 13
Training loss: 0.18597249855708353
Validation loss: 2.4317400852049915

Epoch: 709| Step: 0
Training loss: 0.11543428731360598
Validation loss: 2.428325994241204

Epoch: 6| Step: 1
Training loss: 0.13553944548108002
Validation loss: 2.418370913287651

Epoch: 6| Step: 2
Training loss: 0.08895467287583342
Validation loss: 2.4019881009145454

Epoch: 6| Step: 3
Training loss: 0.11661215451309273
Validation loss: 2.4068575410253907

Epoch: 6| Step: 4
Training loss: 0.11024268864481318
Validation loss: 2.42846755259707

Epoch: 6| Step: 5
Training loss: 0.13463019739680485
Validation loss: 2.4133828309436254

Epoch: 6| Step: 6
Training loss: 0.13224379006067935
Validation loss: 2.446856668534823

Epoch: 6| Step: 7
Training loss: 0.08276982129862744
Validation loss: 2.4287856275008846

Epoch: 6| Step: 8
Training loss: 0.11178000661426656
Validation loss: 2.4209495138989343

Epoch: 6| Step: 9
Training loss: 0.14148181587529385
Validation loss: 2.4122370440636325

Epoch: 6| Step: 10
Training loss: 0.09799301731372916
Validation loss: 2.4173894536123623

Epoch: 6| Step: 11
Training loss: 0.06481203300299554
Validation loss: 2.4012352988108607

Epoch: 6| Step: 12
Training loss: 0.12143714345412399
Validation loss: 2.429690902797792

Epoch: 6| Step: 13
Training loss: 0.19964162039794123
Validation loss: 2.445864344708755

Epoch: 710| Step: 0
Training loss: 0.11996098961513807
Validation loss: 2.3837998309342154

Epoch: 6| Step: 1
Training loss: 0.09904213753217743
Validation loss: 2.392659444894024

Epoch: 6| Step: 2
Training loss: 0.13353084092464765
Validation loss: 2.4181441835291286

Epoch: 6| Step: 3
Training loss: 0.1874606071257815
Validation loss: 2.3641370050587516

Epoch: 6| Step: 4
Training loss: 0.14882920682819292
Validation loss: 2.424049354586989

Epoch: 6| Step: 5
Training loss: 0.10035046542330106
Validation loss: 2.3991365890621603

Epoch: 6| Step: 6
Training loss: 0.15496835787493324
Validation loss: 2.420900110660155

Epoch: 6| Step: 7
Training loss: 0.12708955916283018
Validation loss: 2.393543847277396

Epoch: 6| Step: 8
Training loss: 0.11526103034705773
Validation loss: 2.3827612408914693

Epoch: 6| Step: 9
Training loss: 0.10512347572199071
Validation loss: 2.408732357564955

Epoch: 6| Step: 10
Training loss: 0.11791117459979496
Validation loss: 2.4123268003210416

Epoch: 6| Step: 11
Training loss: 0.1379734841287316
Validation loss: 2.4067314767878543

Epoch: 6| Step: 12
Training loss: 0.1803164049647988
Validation loss: 2.3916309215385163

Epoch: 6| Step: 13
Training loss: 0.16148164155341743
Validation loss: 2.386911198528268

Epoch: 711| Step: 0
Training loss: 0.15864667995758813
Validation loss: 2.4159772870562795

Epoch: 6| Step: 1
Training loss: 0.1160339682941532
Validation loss: 2.4098542447488183

Epoch: 6| Step: 2
Training loss: 0.13727849409323015
Validation loss: 2.405592632700285

Epoch: 6| Step: 3
Training loss: 0.14288506064783488
Validation loss: 2.4319755860189702

Epoch: 6| Step: 4
Training loss: 0.10759445112948915
Validation loss: 2.395248350943059

Epoch: 6| Step: 5
Training loss: 0.13217692605692016
Validation loss: 2.4090398078475346

Epoch: 6| Step: 6
Training loss: 0.11900207796731838
Validation loss: 2.4170861868397235

Epoch: 6| Step: 7
Training loss: 0.1837976824596686
Validation loss: 2.4171481439651403

Epoch: 6| Step: 8
Training loss: 0.1172452704765956
Validation loss: 2.4216075102469263

Epoch: 6| Step: 9
Training loss: 0.2345534281248165
Validation loss: 2.426138859451947

Epoch: 6| Step: 10
Training loss: 0.11232606435581803
Validation loss: 2.4057025401176455

Epoch: 6| Step: 11
Training loss: 0.09141254627517943
Validation loss: 2.413314759284901

Epoch: 6| Step: 12
Training loss: 0.15825455029930247
Validation loss: 2.3893664224843887

Epoch: 6| Step: 13
Training loss: 0.12417261283499774
Validation loss: 2.3891744516500375

Epoch: 712| Step: 0
Training loss: 0.20040656318265332
Validation loss: 2.425495525273884

Epoch: 6| Step: 1
Training loss: 0.15252466952011903
Validation loss: 2.394732326001151

Epoch: 6| Step: 2
Training loss: 0.21582669900273813
Validation loss: 2.4249411527493843

Epoch: 6| Step: 3
Training loss: 0.1806773412824871
Validation loss: 2.4498316924249743

Epoch: 6| Step: 4
Training loss: 0.1570805588448959
Validation loss: 2.4018707143154723

Epoch: 6| Step: 5
Training loss: 0.20102761475632416
Validation loss: 2.4367527790603356

Epoch: 6| Step: 6
Training loss: 0.14408862796557712
Validation loss: 2.4326728338914303

Epoch: 6| Step: 7
Training loss: 0.19719789305319682
Validation loss: 2.4311753153114988

Epoch: 6| Step: 8
Training loss: 0.10788385148300525
Validation loss: 2.4465467911675107

Epoch: 6| Step: 9
Training loss: 0.15925515614984978
Validation loss: 2.4766824970836105

Epoch: 6| Step: 10
Training loss: 0.1739139452188829
Validation loss: 2.4454277719329847

Epoch: 6| Step: 11
Training loss: 0.15559788162199417
Validation loss: 2.4643166610023677

Epoch: 6| Step: 12
Training loss: 0.2126072038180946
Validation loss: 2.476793762777445

Epoch: 6| Step: 13
Training loss: 0.1085229321993169
Validation loss: 2.424323953926741

Epoch: 713| Step: 0
Training loss: 0.16801770184486578
Validation loss: 2.446533034811408

Epoch: 6| Step: 1
Training loss: 0.16536952684677678
Validation loss: 2.454950854307835

Epoch: 6| Step: 2
Training loss: 0.1287181811689425
Validation loss: 2.3962557455505773

Epoch: 6| Step: 3
Training loss: 0.13455102945704386
Validation loss: 2.4087802202248474

Epoch: 6| Step: 4
Training loss: 0.11810855113278461
Validation loss: 2.426365326066462

Epoch: 6| Step: 5
Training loss: 0.15316626834424119
Validation loss: 2.433637975040943

Epoch: 6| Step: 6
Training loss: 0.15816315393241087
Validation loss: 2.38965894136739

Epoch: 6| Step: 7
Training loss: 0.14662449810547065
Validation loss: 2.4382755043996234

Epoch: 6| Step: 8
Training loss: 0.10688988998767071
Validation loss: 2.430772252030573

Epoch: 6| Step: 9
Training loss: 0.10557174069233147
Validation loss: 2.4203224665298224

Epoch: 6| Step: 10
Training loss: 0.10461201437255002
Validation loss: 2.43597613371789

Epoch: 6| Step: 11
Training loss: 0.13945258351496012
Validation loss: 2.4323470578890425

Epoch: 6| Step: 12
Training loss: 0.16000212254457463
Validation loss: 2.405993928083338

Epoch: 6| Step: 13
Training loss: 0.09607054286717291
Validation loss: 2.4232936042776245

Epoch: 714| Step: 0
Training loss: 0.1425829390144228
Validation loss: 2.4410466343008475

Epoch: 6| Step: 1
Training loss: 0.13316998335145927
Validation loss: 2.4152830034445176

Epoch: 6| Step: 2
Training loss: 0.11791430236821326
Validation loss: 2.414530588341372

Epoch: 6| Step: 3
Training loss: 0.10878801362441187
Validation loss: 2.429146839355655

Epoch: 6| Step: 4
Training loss: 0.12613197469329687
Validation loss: 2.4553714705220857

Epoch: 6| Step: 5
Training loss: 0.1980339986614304
Validation loss: 2.435043305401518

Epoch: 6| Step: 6
Training loss: 0.09144841163236388
Validation loss: 2.416979534157067

Epoch: 6| Step: 7
Training loss: 0.13310074381512996
Validation loss: 2.4138166615250203

Epoch: 6| Step: 8
Training loss: 0.06302854079347164
Validation loss: 2.4522016987682074

Epoch: 6| Step: 9
Training loss: 0.10425711420367757
Validation loss: 2.4245730304670583

Epoch: 6| Step: 10
Training loss: 0.12526643937502702
Validation loss: 2.4078177368510003

Epoch: 6| Step: 11
Training loss: 0.0985799543927795
Validation loss: 2.400996742275812

Epoch: 6| Step: 12
Training loss: 0.1141114479361392
Validation loss: 2.4161581056655232

Epoch: 6| Step: 13
Training loss: 0.12523176641478173
Validation loss: 2.425249242157905

Epoch: 715| Step: 0
Training loss: 0.12099637838950555
Validation loss: 2.4380666640997846

Epoch: 6| Step: 1
Training loss: 0.08292019090259521
Validation loss: 2.448248039669998

Epoch: 6| Step: 2
Training loss: 0.12460546517292152
Validation loss: 2.4284334993450414

Epoch: 6| Step: 3
Training loss: 0.12867032482693452
Validation loss: 2.4396308659394763

Epoch: 6| Step: 4
Training loss: 0.13283887769512887
Validation loss: 2.4486815364903847

Epoch: 6| Step: 5
Training loss: 0.15211727352040963
Validation loss: 2.474680439991903

Epoch: 6| Step: 6
Training loss: 0.1507881410042003
Validation loss: 2.4459245111091197

Epoch: 6| Step: 7
Training loss: 0.09528221290154378
Validation loss: 2.469209143633893

Epoch: 6| Step: 8
Training loss: 0.11067956940345822
Validation loss: 2.4620966647475035

Epoch: 6| Step: 9
Training loss: 0.17556553956595652
Validation loss: 2.457701131086611

Epoch: 6| Step: 10
Training loss: 0.11626693434324688
Validation loss: 2.4489208234596846

Epoch: 6| Step: 11
Training loss: 0.07739847142738715
Validation loss: 2.4587692008519526

Epoch: 6| Step: 12
Training loss: 0.12534715457487644
Validation loss: 2.4711237744401298

Epoch: 6| Step: 13
Training loss: 0.08315359665222488
Validation loss: 2.4307684130615894

Epoch: 716| Step: 0
Training loss: 0.10036902046771717
Validation loss: 2.4239278592365383

Epoch: 6| Step: 1
Training loss: 0.1474380096396014
Validation loss: 2.442822151165804

Epoch: 6| Step: 2
Training loss: 0.08935630255971967
Validation loss: 2.45952363047015

Epoch: 6| Step: 3
Training loss: 0.1252590713375859
Validation loss: 2.4501828175473017

Epoch: 6| Step: 4
Training loss: 0.13367812576260057
Validation loss: 2.447324549151202

Epoch: 6| Step: 5
Training loss: 0.12369648949318467
Validation loss: 2.449855285181088

Epoch: 6| Step: 6
Training loss: 0.13176770740565738
Validation loss: 2.4271448085251923

Epoch: 6| Step: 7
Training loss: 0.10918171015795385
Validation loss: 2.429620578396742

Epoch: 6| Step: 8
Training loss: 0.132309479965932
Validation loss: 2.420364055699983

Epoch: 6| Step: 9
Training loss: 0.08406327112546151
Validation loss: 2.469322684383777

Epoch: 6| Step: 10
Training loss: 0.1159284508199134
Validation loss: 2.448643219488154

Epoch: 6| Step: 11
Training loss: 0.12502228270049043
Validation loss: 2.4490454409108224

Epoch: 6| Step: 12
Training loss: 0.08317429732651342
Validation loss: 2.413124457363229

Epoch: 6| Step: 13
Training loss: 0.12898245639633335
Validation loss: 2.4606204988796114

Epoch: 717| Step: 0
Training loss: 0.08183726580504584
Validation loss: 2.451559190554365

Epoch: 6| Step: 1
Training loss: 0.1146046273718009
Validation loss: 2.461547559266005

Epoch: 6| Step: 2
Training loss: 0.11617701700576306
Validation loss: 2.445305387713385

Epoch: 6| Step: 3
Training loss: 0.12735327234530885
Validation loss: 2.4224276163263108

Epoch: 6| Step: 4
Training loss: 0.10517031780280822
Validation loss: 2.451326624292299

Epoch: 6| Step: 5
Training loss: 0.13712090881176958
Validation loss: 2.427708336488356

Epoch: 6| Step: 6
Training loss: 0.10194208662705952
Validation loss: 2.4175123804231835

Epoch: 6| Step: 7
Training loss: 0.1108558660009654
Validation loss: 2.4627750420318786

Epoch: 6| Step: 8
Training loss: 0.11088464478504345
Validation loss: 2.4170400085723487

Epoch: 6| Step: 9
Training loss: 0.1626359991738215
Validation loss: 2.448637173788639

Epoch: 6| Step: 10
Training loss: 0.0795228974962699
Validation loss: 2.429156202023115

Epoch: 6| Step: 11
Training loss: 0.08645817047366158
Validation loss: 2.4158470221050656

Epoch: 6| Step: 12
Training loss: 0.09508127968192837
Validation loss: 2.411304940398092

Epoch: 6| Step: 13
Training loss: 0.07755146804176502
Validation loss: 2.403533331016777

Epoch: 718| Step: 0
Training loss: 0.08651757349590002
Validation loss: 2.4085285695512506

Epoch: 6| Step: 1
Training loss: 0.09049949588029302
Validation loss: 2.4034685056522123

Epoch: 6| Step: 2
Training loss: 0.11748053946298705
Validation loss: 2.41548441998781

Epoch: 6| Step: 3
Training loss: 0.08854556834749659
Validation loss: 2.4292211713874408

Epoch: 6| Step: 4
Training loss: 0.12404498716552273
Validation loss: 2.4128484123796303

Epoch: 6| Step: 5
Training loss: 0.09782352426516461
Validation loss: 2.404912090034103

Epoch: 6| Step: 6
Training loss: 0.11100213944756414
Validation loss: 2.4407129517955557

Epoch: 6| Step: 7
Training loss: 0.13784701870882698
Validation loss: 2.398603392108061

Epoch: 6| Step: 8
Training loss: 0.0892786154096255
Validation loss: 2.392847097185628

Epoch: 6| Step: 9
Training loss: 0.1315118196305579
Validation loss: 2.3857997309616388

Epoch: 6| Step: 10
Training loss: 0.09384566631450192
Validation loss: 2.423675645220835

Epoch: 6| Step: 11
Training loss: 0.08088418250617202
Validation loss: 2.391166171608774

Epoch: 6| Step: 12
Training loss: 0.13070116870462678
Validation loss: 2.414531453671782

Epoch: 6| Step: 13
Training loss: 0.09882620462805963
Validation loss: 2.4376762101369884

Epoch: 719| Step: 0
Training loss: 0.07779839912633181
Validation loss: 2.417122827179079

Epoch: 6| Step: 1
Training loss: 0.138621005278062
Validation loss: 2.4212420549132694

Epoch: 6| Step: 2
Training loss: 0.1316303699132526
Validation loss: 2.4265688458662864

Epoch: 6| Step: 3
Training loss: 0.15213232775352212
Validation loss: 2.4219985808652718

Epoch: 6| Step: 4
Training loss: 0.13053951029204452
Validation loss: 2.451683862118815

Epoch: 6| Step: 5
Training loss: 0.09870798720950198
Validation loss: 2.440865062035081

Epoch: 6| Step: 6
Training loss: 0.09669226747606322
Validation loss: 2.4319207891412264

Epoch: 6| Step: 7
Training loss: 0.11724566764442736
Validation loss: 2.4620127151911437

Epoch: 6| Step: 8
Training loss: 0.11317140498781968
Validation loss: 2.4352962422403244

Epoch: 6| Step: 9
Training loss: 0.08333257647508402
Validation loss: 2.4039881398979936

Epoch: 6| Step: 10
Training loss: 0.14014264669075477
Validation loss: 2.42450000613922

Epoch: 6| Step: 11
Training loss: 0.13917453089306592
Validation loss: 2.410080469951523

Epoch: 6| Step: 12
Training loss: 0.12358219397132295
Validation loss: 2.384297419776276

Epoch: 6| Step: 13
Training loss: 0.1211803149943103
Validation loss: 2.4079945439202026

Epoch: 720| Step: 0
Training loss: 0.1307712870509394
Validation loss: 2.3899206284263177

Epoch: 6| Step: 1
Training loss: 0.10734929320336353
Validation loss: 2.424177505239435

Epoch: 6| Step: 2
Training loss: 0.08535984542513853
Validation loss: 2.3962798353023236

Epoch: 6| Step: 3
Training loss: 0.10715603011262527
Validation loss: 2.3904074689819534

Epoch: 6| Step: 4
Training loss: 0.11762424781003429
Validation loss: 2.415099231492959

Epoch: 6| Step: 5
Training loss: 0.06400539481440351
Validation loss: 2.4204728253008816

Epoch: 6| Step: 6
Training loss: 0.10788138683580697
Validation loss: 2.398072206133934

Epoch: 6| Step: 7
Training loss: 0.09194957936985704
Validation loss: 2.4335707438542618

Epoch: 6| Step: 8
Training loss: 0.09601243307893276
Validation loss: 2.4224552852651793

Epoch: 6| Step: 9
Training loss: 0.1333698610720812
Validation loss: 2.412882575618816

Epoch: 6| Step: 10
Training loss: 0.17409592263080276
Validation loss: 2.400330493160842

Epoch: 6| Step: 11
Training loss: 0.06949567527660012
Validation loss: 2.4521275181358533

Epoch: 6| Step: 12
Training loss: 0.13148274618444356
Validation loss: 2.430773109469795

Epoch: 6| Step: 13
Training loss: 0.14839417678648886
Validation loss: 2.405132644222646

Epoch: 721| Step: 0
Training loss: 0.08484563731892202
Validation loss: 2.4275344210447565

Epoch: 6| Step: 1
Training loss: 0.08271925643085654
Validation loss: 2.4243655331411067

Epoch: 6| Step: 2
Training loss: 0.12126739418971706
Validation loss: 2.444495570400769

Epoch: 6| Step: 3
Training loss: 0.08960148032415229
Validation loss: 2.4272438942268217

Epoch: 6| Step: 4
Training loss: 0.07836905446745988
Validation loss: 2.425037963108261

Epoch: 6| Step: 5
Training loss: 0.13581781544665109
Validation loss: 2.4102906106078197

Epoch: 6| Step: 6
Training loss: 0.10707498373915028
Validation loss: 2.410626242208832

Epoch: 6| Step: 7
Training loss: 0.158595681296179
Validation loss: 2.4273462235457655

Epoch: 6| Step: 8
Training loss: 0.13192558772532867
Validation loss: 2.388450292385759

Epoch: 6| Step: 9
Training loss: 0.11752977454322577
Validation loss: 2.4045600885983895

Epoch: 6| Step: 10
Training loss: 0.17095490748810938
Validation loss: 2.4271611812028007

Epoch: 6| Step: 11
Training loss: 0.10217103307055962
Validation loss: 2.4226313854424792

Epoch: 6| Step: 12
Training loss: 0.06409462292038176
Validation loss: 2.4278586670821523

Epoch: 6| Step: 13
Training loss: 0.07632966388002277
Validation loss: 2.410442044765524

Epoch: 722| Step: 0
Training loss: 0.10272098026053655
Validation loss: 2.4122245554820627

Epoch: 6| Step: 1
Training loss: 0.09468540792073969
Validation loss: 2.4321663007719745

Epoch: 6| Step: 2
Training loss: 0.17535473683645883
Validation loss: 2.4317958465465486

Epoch: 6| Step: 3
Training loss: 0.11967868158657423
Validation loss: 2.436633335391859

Epoch: 6| Step: 4
Training loss: 0.11602444470722102
Validation loss: 2.4535243473047847

Epoch: 6| Step: 5
Training loss: 0.11771918719038098
Validation loss: 2.4305999217010337

Epoch: 6| Step: 6
Training loss: 0.10989773527943252
Validation loss: 2.4102378585820734

Epoch: 6| Step: 7
Training loss: 0.16199350237398977
Validation loss: 2.4066990717109316

Epoch: 6| Step: 8
Training loss: 0.11113538705562195
Validation loss: 2.4062942545560455

Epoch: 6| Step: 9
Training loss: 0.11269100749554739
Validation loss: 2.395288931123933

Epoch: 6| Step: 10
Training loss: 0.1088400257392339
Validation loss: 2.408988958355093

Epoch: 6| Step: 11
Training loss: 0.08853917842996417
Validation loss: 2.3989817474906654

Epoch: 6| Step: 12
Training loss: 0.09900496873042781
Validation loss: 2.4080368926874565

Epoch: 6| Step: 13
Training loss: 0.12873728110626959
Validation loss: 2.405472676622328

Epoch: 723| Step: 0
Training loss: 0.13359147817230435
Validation loss: 2.4240730888155744

Epoch: 6| Step: 1
Training loss: 0.11552462151384298
Validation loss: 2.3924563012448634

Epoch: 6| Step: 2
Training loss: 0.0927256712167214
Validation loss: 2.4206578663330376

Epoch: 6| Step: 3
Training loss: 0.14287178941558623
Validation loss: 2.3757121416843785

Epoch: 6| Step: 4
Training loss: 0.11424270350661812
Validation loss: 2.398939461686583

Epoch: 6| Step: 5
Training loss: 0.13472741041306527
Validation loss: 2.3966967806180066

Epoch: 6| Step: 6
Training loss: 0.0972467132168615
Validation loss: 2.3809513154811204

Epoch: 6| Step: 7
Training loss: 0.11872762481802576
Validation loss: 2.4005895178262393

Epoch: 6| Step: 8
Training loss: 0.11853424521331991
Validation loss: 2.3827919568958724

Epoch: 6| Step: 9
Training loss: 0.14240068341831896
Validation loss: 2.4014416967044374

Epoch: 6| Step: 10
Training loss: 0.10949525863526595
Validation loss: 2.4017448038147613

Epoch: 6| Step: 11
Training loss: 0.11250386612262529
Validation loss: 2.3901475363483895

Epoch: 6| Step: 12
Training loss: 0.10710851741311113
Validation loss: 2.397575718218687

Epoch: 6| Step: 13
Training loss: 0.11665025585704888
Validation loss: 2.393804859042648

Epoch: 724| Step: 0
Training loss: 0.11926122330662041
Validation loss: 2.415238142450697

Epoch: 6| Step: 1
Training loss: 0.12368759731281186
Validation loss: 2.3654301380985254

Epoch: 6| Step: 2
Training loss: 0.08933804034588352
Validation loss: 2.4110692207143085

Epoch: 6| Step: 3
Training loss: 0.12004747926678372
Validation loss: 2.4095776373395976

Epoch: 6| Step: 4
Training loss: 0.1576414852960142
Validation loss: 2.41033273183955

Epoch: 6| Step: 5
Training loss: 0.04906398314235771
Validation loss: 2.4019712951582437

Epoch: 6| Step: 6
Training loss: 0.1291361333985576
Validation loss: 2.4258557691742157

Epoch: 6| Step: 7
Training loss: 0.16875385725946446
Validation loss: 2.4093024282697026

Epoch: 6| Step: 8
Training loss: 0.13907659598498848
Validation loss: 2.4223083722304484

Epoch: 6| Step: 9
Training loss: 0.08865283433938544
Validation loss: 2.4188245326794746

Epoch: 6| Step: 10
Training loss: 0.0803291236709254
Validation loss: 2.4286879764074842

Epoch: 6| Step: 11
Training loss: 0.07911369148324708
Validation loss: 2.429528744952943

Epoch: 6| Step: 12
Training loss: 0.0732706014830893
Validation loss: 2.411449102703309

Epoch: 6| Step: 13
Training loss: 0.11833964457214184
Validation loss: 2.4166489799567996

Epoch: 725| Step: 0
Training loss: 0.07962864824991954
Validation loss: 2.4301388920057474

Epoch: 6| Step: 1
Training loss: 0.12332785782977804
Validation loss: 2.395761118723874

Epoch: 6| Step: 2
Training loss: 0.1358726204134723
Validation loss: 2.414322995639738

Epoch: 6| Step: 3
Training loss: 0.1317400901789007
Validation loss: 2.4303038762622142

Epoch: 6| Step: 4
Training loss: 0.11647398213434894
Validation loss: 2.4254558563557187

Epoch: 6| Step: 5
Training loss: 0.10973476946875409
Validation loss: 2.4065721080769906

Epoch: 6| Step: 6
Training loss: 0.14666096533545678
Validation loss: 2.437240832917474

Epoch: 6| Step: 7
Training loss: 0.12831675961480715
Validation loss: 2.440559902444048

Epoch: 6| Step: 8
Training loss: 0.11289287452700422
Validation loss: 2.4140319408119675

Epoch: 6| Step: 9
Training loss: 0.1408999325107402
Validation loss: 2.407801066011844

Epoch: 6| Step: 10
Training loss: 0.1346348598021078
Validation loss: 2.4255207092198736

Epoch: 6| Step: 11
Training loss: 0.08629995551025287
Validation loss: 2.410437814732827

Epoch: 6| Step: 12
Training loss: 0.12108205538853846
Validation loss: 2.416853933182684

Epoch: 6| Step: 13
Training loss: 0.11714962506177266
Validation loss: 2.4212894394721487

Epoch: 726| Step: 0
Training loss: 0.13518308858159514
Validation loss: 2.4199926094254876

Epoch: 6| Step: 1
Training loss: 0.14004070701325172
Validation loss: 2.41136066929398

Epoch: 6| Step: 2
Training loss: 0.07890859661767576
Validation loss: 2.4301133555669447

Epoch: 6| Step: 3
Training loss: 0.07953055343997399
Validation loss: 2.4267077436382705

Epoch: 6| Step: 4
Training loss: 0.11024363903290071
Validation loss: 2.424572807364602

Epoch: 6| Step: 5
Training loss: 0.0835715421474016
Validation loss: 2.429437168946054

Epoch: 6| Step: 6
Training loss: 0.15383317539028574
Validation loss: 2.4537018734549396

Epoch: 6| Step: 7
Training loss: 0.14192112347283015
Validation loss: 2.4372191213404566

Epoch: 6| Step: 8
Training loss: 0.2052103887655138
Validation loss: 2.4544589928438603

Epoch: 6| Step: 9
Training loss: 0.10654887577258816
Validation loss: 2.433311814642727

Epoch: 6| Step: 10
Training loss: 0.11268794549699505
Validation loss: 2.4449674191227015

Epoch: 6| Step: 11
Training loss: 0.13286575483849689
Validation loss: 2.4269271864437245

Epoch: 6| Step: 12
Training loss: 0.08179321835605184
Validation loss: 2.4177711182470345

Epoch: 6| Step: 13
Training loss: 0.07640932133026722
Validation loss: 2.4081854598752055

Epoch: 727| Step: 0
Training loss: 0.11619447543447316
Validation loss: 2.387775792674845

Epoch: 6| Step: 1
Training loss: 0.1350235888835595
Validation loss: 2.428524875944395

Epoch: 6| Step: 2
Training loss: 0.09715239721157709
Validation loss: 2.4128584239885478

Epoch: 6| Step: 3
Training loss: 0.18064433840744346
Validation loss: 2.3924311432215917

Epoch: 6| Step: 4
Training loss: 0.14721438657391184
Validation loss: 2.4252273423614867

Epoch: 6| Step: 5
Training loss: 0.09547885580627513
Validation loss: 2.4128747403437996

Epoch: 6| Step: 6
Training loss: 0.09136382895531428
Validation loss: 2.4083124555496163

Epoch: 6| Step: 7
Training loss: 0.1011191374254671
Validation loss: 2.4053028161801207

Epoch: 6| Step: 8
Training loss: 0.06452441607674418
Validation loss: 2.414656775191628

Epoch: 6| Step: 9
Training loss: 0.1414430652030073
Validation loss: 2.4164487855802266

Epoch: 6| Step: 10
Training loss: 0.09881145992672684
Validation loss: 2.426761288072061

Epoch: 6| Step: 11
Training loss: 0.12371740731394545
Validation loss: 2.428702715759652

Epoch: 6| Step: 12
Training loss: 0.11817217239419128
Validation loss: 2.4187146791176684

Epoch: 6| Step: 13
Training loss: 0.14300581394310966
Validation loss: 2.449415692485764

Epoch: 728| Step: 0
Training loss: 0.10337870917994246
Validation loss: 2.4536687957421073

Epoch: 6| Step: 1
Training loss: 0.1225067006013188
Validation loss: 2.435008451840419

Epoch: 6| Step: 2
Training loss: 0.12025105374949162
Validation loss: 2.4337145015724166

Epoch: 6| Step: 3
Training loss: 0.09552141377464386
Validation loss: 2.4019539401510315

Epoch: 6| Step: 4
Training loss: 0.11737356117720488
Validation loss: 2.4561531903876737

Epoch: 6| Step: 5
Training loss: 0.16115794130376887
Validation loss: 2.4335040059444295

Epoch: 6| Step: 6
Training loss: 0.13603072066787938
Validation loss: 2.4137779275459126

Epoch: 6| Step: 7
Training loss: 0.11464759982321313
Validation loss: 2.4003634140928884

Epoch: 6| Step: 8
Training loss: 0.09250740758612189
Validation loss: 2.423096985820103

Epoch: 6| Step: 9
Training loss: 0.13790180063752597
Validation loss: 2.4134658818006938

Epoch: 6| Step: 10
Training loss: 0.12570410103949461
Validation loss: 2.425475533936732

Epoch: 6| Step: 11
Training loss: 0.1498866305984652
Validation loss: 2.471406303295043

Epoch: 6| Step: 12
Training loss: 0.07767756605124083
Validation loss: 2.4532204813128575

Epoch: 6| Step: 13
Training loss: 0.14854147055583097
Validation loss: 2.471812257522321

Epoch: 729| Step: 0
Training loss: 0.06476034292440115
Validation loss: 2.4382902077437913

Epoch: 6| Step: 1
Training loss: 0.08778665273773673
Validation loss: 2.437983775925452

Epoch: 6| Step: 2
Training loss: 0.11614752088982933
Validation loss: 2.426080825102105

Epoch: 6| Step: 3
Training loss: 0.12162244653569697
Validation loss: 2.472069442877943

Epoch: 6| Step: 4
Training loss: 0.07236547917208307
Validation loss: 2.391551577663918

Epoch: 6| Step: 5
Training loss: 0.08600442350437948
Validation loss: 2.432628786267662

Epoch: 6| Step: 6
Training loss: 0.11601404532567666
Validation loss: 2.4473985831100835

Epoch: 6| Step: 7
Training loss: 0.06018033133950635
Validation loss: 2.42285707524074

Epoch: 6| Step: 8
Training loss: 0.11491591690302756
Validation loss: 2.4308920227082496

Epoch: 6| Step: 9
Training loss: 0.13622906044946498
Validation loss: 2.416505621175271

Epoch: 6| Step: 10
Training loss: 0.12800682450472847
Validation loss: 2.4416855581996706

Epoch: 6| Step: 11
Training loss: 0.12356231225119582
Validation loss: 2.420795049049232

Epoch: 6| Step: 12
Training loss: 0.0873147056259363
Validation loss: 2.4151161284752236

Epoch: 6| Step: 13
Training loss: 0.06587354434642678
Validation loss: 2.4054923323648274

Epoch: 730| Step: 0
Training loss: 0.08019483017067996
Validation loss: 2.4272363762257068

Epoch: 6| Step: 1
Training loss: 0.10023470080226834
Validation loss: 2.4041936008902915

Epoch: 6| Step: 2
Training loss: 0.11510010348206814
Validation loss: 2.4369545166618183

Epoch: 6| Step: 3
Training loss: 0.11733509147334466
Validation loss: 2.4254725062610945

Epoch: 6| Step: 4
Training loss: 0.10525825918331201
Validation loss: 2.410700080271099

Epoch: 6| Step: 5
Training loss: 0.1029117125174308
Validation loss: 2.4150094094901275

Epoch: 6| Step: 6
Training loss: 0.1331935912716965
Validation loss: 2.431775172208163

Epoch: 6| Step: 7
Training loss: 0.0862113804064748
Validation loss: 2.431152897096759

Epoch: 6| Step: 8
Training loss: 0.08602890117479
Validation loss: 2.3980011875330587

Epoch: 6| Step: 9
Training loss: 0.09734561629825421
Validation loss: 2.428683613221193

Epoch: 6| Step: 10
Training loss: 0.12903143122016597
Validation loss: 2.437542582882215

Epoch: 6| Step: 11
Training loss: 0.1270247037545143
Validation loss: 2.4495442628095643

Epoch: 6| Step: 12
Training loss: 0.09996198904059055
Validation loss: 2.4341188133412044

Epoch: 6| Step: 13
Training loss: 0.14738269018294017
Validation loss: 2.437755437760249

Epoch: 731| Step: 0
Training loss: 0.149776505327277
Validation loss: 2.441286768329662

Epoch: 6| Step: 1
Training loss: 0.09178226943191864
Validation loss: 2.417572405677247

Epoch: 6| Step: 2
Training loss: 0.15460841199315706
Validation loss: 2.442769335542978

Epoch: 6| Step: 3
Training loss: 0.08603263054559994
Validation loss: 2.398972788555725

Epoch: 6| Step: 4
Training loss: 0.09474571761900209
Validation loss: 2.42728900174452

Epoch: 6| Step: 5
Training loss: 0.13320751210927959
Validation loss: 2.410597785578014

Epoch: 6| Step: 6
Training loss: 0.12618489744460434
Validation loss: 2.4223739843025025

Epoch: 6| Step: 7
Training loss: 0.09857084197081839
Validation loss: 2.425442253078868

Epoch: 6| Step: 8
Training loss: 0.17601406785840865
Validation loss: 2.4004708210478567

Epoch: 6| Step: 9
Training loss: 0.0999745472538501
Validation loss: 2.42904934420828

Epoch: 6| Step: 10
Training loss: 0.13090697888744884
Validation loss: 2.4368374084083393

Epoch: 6| Step: 11
Training loss: 0.08813482902714781
Validation loss: 2.4252656323890047

Epoch: 6| Step: 12
Training loss: 0.12542934740816983
Validation loss: 2.4239261786475854

Epoch: 6| Step: 13
Training loss: 0.08313956183327477
Validation loss: 2.4161764340026757

Epoch: 732| Step: 0
Training loss: 0.10856150484589784
Validation loss: 2.4250923076585273

Epoch: 6| Step: 1
Training loss: 0.08316551542737514
Validation loss: 2.4232179600001733

Epoch: 6| Step: 2
Training loss: 0.12064333950477417
Validation loss: 2.4584364295005

Epoch: 6| Step: 3
Training loss: 0.09705044237930976
Validation loss: 2.427483304718906

Epoch: 6| Step: 4
Training loss: 0.07575361335334654
Validation loss: 2.45065652649166

Epoch: 6| Step: 5
Training loss: 0.08083275492707413
Validation loss: 2.4409625006247344

Epoch: 6| Step: 6
Training loss: 0.12310519804116041
Validation loss: 2.4403171934640877

Epoch: 6| Step: 7
Training loss: 0.112282361008891
Validation loss: 2.419395478977152

Epoch: 6| Step: 8
Training loss: 0.06952517501673743
Validation loss: 2.4530441618862318

Epoch: 6| Step: 9
Training loss: 0.10966252103677285
Validation loss: 2.408217374957431

Epoch: 6| Step: 10
Training loss: 0.08566914729879707
Validation loss: 2.422439444849579

Epoch: 6| Step: 11
Training loss: 0.10711673834384301
Validation loss: 2.4205508790646357

Epoch: 6| Step: 12
Training loss: 0.12097288837464173
Validation loss: 2.4134595727148382

Epoch: 6| Step: 13
Training loss: 0.12458276778497306
Validation loss: 2.426885577173013

Epoch: 733| Step: 0
Training loss: 0.10724159197927852
Validation loss: 2.4063410209718294

Epoch: 6| Step: 1
Training loss: 0.10210830034859399
Validation loss: 2.406483950333463

Epoch: 6| Step: 2
Training loss: 0.12404553149012672
Validation loss: 2.394684821686512

Epoch: 6| Step: 3
Training loss: 0.11396921013816869
Validation loss: 2.3948732875327843

Epoch: 6| Step: 4
Training loss: 0.06354527422495253
Validation loss: 2.405315707875919

Epoch: 6| Step: 5
Training loss: 0.1174055137834573
Validation loss: 2.4235986673683025

Epoch: 6| Step: 6
Training loss: 0.05898491309722606
Validation loss: 2.4101864918946663

Epoch: 6| Step: 7
Training loss: 0.05732791424070779
Validation loss: 2.4007164697523473

Epoch: 6| Step: 8
Training loss: 0.10487494377014235
Validation loss: 2.4336874083352584

Epoch: 6| Step: 9
Training loss: 0.1072664002725989
Validation loss: 2.3939355636123616

Epoch: 6| Step: 10
Training loss: 0.09926603084320923
Validation loss: 2.4178790086201882

Epoch: 6| Step: 11
Training loss: 0.11066147236026413
Validation loss: 2.4107506062819213

Epoch: 6| Step: 12
Training loss: 0.0865796895509703
Validation loss: 2.4386180567378895

Epoch: 6| Step: 13
Training loss: 0.07273523679995084
Validation loss: 2.4315372249190466

Epoch: 734| Step: 0
Training loss: 0.08251412503743372
Validation loss: 2.4150624458081236

Epoch: 6| Step: 1
Training loss: 0.08188912591033375
Validation loss: 2.3839313018181327

Epoch: 6| Step: 2
Training loss: 0.10568356272341503
Validation loss: 2.4379712499332764

Epoch: 6| Step: 3
Training loss: 0.06401179315994862
Validation loss: 2.4220633251948995

Epoch: 6| Step: 4
Training loss: 0.12557164996375977
Validation loss: 2.4200600515088087

Epoch: 6| Step: 5
Training loss: 0.09504843622117244
Validation loss: 2.405628161818069

Epoch: 6| Step: 6
Training loss: 0.12602589255007232
Validation loss: 2.402096378140263

Epoch: 6| Step: 7
Training loss: 0.1085780348487136
Validation loss: 2.4303354818988647

Epoch: 6| Step: 8
Training loss: 0.0953970901147937
Validation loss: 2.415161872231393

Epoch: 6| Step: 9
Training loss: 0.11247485578534737
Validation loss: 2.428536397138929

Epoch: 6| Step: 10
Training loss: 0.11581334451747322
Validation loss: 2.4099814136383952

Epoch: 6| Step: 11
Training loss: 0.08153394831943853
Validation loss: 2.4390562451844415

Epoch: 6| Step: 12
Training loss: 0.08505941581109844
Validation loss: 2.427878089719009

Epoch: 6| Step: 13
Training loss: 0.11021732926460251
Validation loss: 2.452935894920236

Epoch: 735| Step: 0
Training loss: 0.11896890631756384
Validation loss: 2.3998171612780324

Epoch: 6| Step: 1
Training loss: 0.11748195450652664
Validation loss: 2.3851262524945906

Epoch: 6| Step: 2
Training loss: 0.09704341765297886
Validation loss: 2.444360087248307

Epoch: 6| Step: 3
Training loss: 0.12476988562401659
Validation loss: 2.4253803799314726

Epoch: 6| Step: 4
Training loss: 0.09314177324463663
Validation loss: 2.423344251468142

Epoch: 6| Step: 5
Training loss: 0.1072668257060575
Validation loss: 2.376802988474565

Epoch: 6| Step: 6
Training loss: 0.07702631277816954
Validation loss: 2.4083804205752073

Epoch: 6| Step: 7
Training loss: 0.13092822782921845
Validation loss: 2.423896395329738

Epoch: 6| Step: 8
Training loss: 0.09271219139250915
Validation loss: 2.458939267152133

Epoch: 6| Step: 9
Training loss: 0.11626169554779976
Validation loss: 2.4078852010651106

Epoch: 6| Step: 10
Training loss: 0.1255625345544307
Validation loss: 2.434596150207852

Epoch: 6| Step: 11
Training loss: 0.09232297253720892
Validation loss: 2.423529025659898

Epoch: 6| Step: 12
Training loss: 0.09871699262916261
Validation loss: 2.416913674078798

Epoch: 6| Step: 13
Training loss: 0.07801304484466527
Validation loss: 2.4103586107924593

Epoch: 736| Step: 0
Training loss: 0.0822476699721545
Validation loss: 2.4297241091059845

Epoch: 6| Step: 1
Training loss: 0.1160892923790559
Validation loss: 2.4134989323989613

Epoch: 6| Step: 2
Training loss: 0.08750974194330849
Validation loss: 2.4282280491087604

Epoch: 6| Step: 3
Training loss: 0.12788974342205467
Validation loss: 2.4235964158768737

Epoch: 6| Step: 4
Training loss: 0.09886280005617243
Validation loss: 2.4464255695238415

Epoch: 6| Step: 5
Training loss: 0.12015783196041602
Validation loss: 2.422284700087406

Epoch: 6| Step: 6
Training loss: 0.07247203911517679
Validation loss: 2.425416995385957

Epoch: 6| Step: 7
Training loss: 0.08009192010636217
Validation loss: 2.4067175817990996

Epoch: 6| Step: 8
Training loss: 0.07047696878713403
Validation loss: 2.41927487846236

Epoch: 6| Step: 9
Training loss: 0.10801113806462884
Validation loss: 2.3995534370304314

Epoch: 6| Step: 10
Training loss: 0.11949053176775284
Validation loss: 2.424106278484507

Epoch: 6| Step: 11
Training loss: 0.1066590054011082
Validation loss: 2.4319497594730803

Epoch: 6| Step: 12
Training loss: 0.13103861418849613
Validation loss: 2.4601655576577124

Epoch: 6| Step: 13
Training loss: 0.049784097435767546
Validation loss: 2.4435720652069275

Epoch: 737| Step: 0
Training loss: 0.14471712918239862
Validation loss: 2.4234261966450523

Epoch: 6| Step: 1
Training loss: 0.10280868413766038
Validation loss: 2.4195076742743473

Epoch: 6| Step: 2
Training loss: 0.09974802876200217
Validation loss: 2.414071981170702

Epoch: 6| Step: 3
Training loss: 0.06355524321947938
Validation loss: 2.4264308524726426

Epoch: 6| Step: 4
Training loss: 0.08373649744531825
Validation loss: 2.415438547547843

Epoch: 6| Step: 5
Training loss: 0.18589822731078326
Validation loss: 2.4335710872783394

Epoch: 6| Step: 6
Training loss: 0.09732951819475608
Validation loss: 2.4080246122816935

Epoch: 6| Step: 7
Training loss: 0.11454237446095637
Validation loss: 2.399043223786092

Epoch: 6| Step: 8
Training loss: 0.0896413430458954
Validation loss: 2.4005954989789084

Epoch: 6| Step: 9
Training loss: 0.12395694406983757
Validation loss: 2.4276903613256087

Epoch: 6| Step: 10
Training loss: 0.12108764325402493
Validation loss: 2.431943202649204

Epoch: 6| Step: 11
Training loss: 0.14170067048331464
Validation loss: 2.4111284829359105

Epoch: 6| Step: 12
Training loss: 0.060308880820913936
Validation loss: 2.4127770429685973

Epoch: 6| Step: 13
Training loss: 0.05350068076858714
Validation loss: 2.432615543476122

Epoch: 738| Step: 0
Training loss: 0.14462305710096623
Validation loss: 2.4164428900824717

Epoch: 6| Step: 1
Training loss: 0.11573338760643863
Validation loss: 2.422141958522324

Epoch: 6| Step: 2
Training loss: 0.1940989558980906
Validation loss: 2.4251134184758336

Epoch: 6| Step: 3
Training loss: 0.08561300112715071
Validation loss: 2.435425317424825

Epoch: 6| Step: 4
Training loss: 0.07913595793991161
Validation loss: 2.424530650148105

Epoch: 6| Step: 5
Training loss: 0.11962247169472569
Validation loss: 2.4241624967260536

Epoch: 6| Step: 6
Training loss: 0.11586045056986569
Validation loss: 2.4077967176800996

Epoch: 6| Step: 7
Training loss: 0.12607793647372864
Validation loss: 2.418327301115508

Epoch: 6| Step: 8
Training loss: 0.10156369208589948
Validation loss: 2.4101908728773442

Epoch: 6| Step: 9
Training loss: 0.07025747662895258
Validation loss: 2.398351921042379

Epoch: 6| Step: 10
Training loss: 0.10428154293335812
Validation loss: 2.4115809930317913

Epoch: 6| Step: 11
Training loss: 0.06846481434089123
Validation loss: 2.389492617380182

Epoch: 6| Step: 12
Training loss: 0.12419460154872992
Validation loss: 2.437900532391703

Epoch: 6| Step: 13
Training loss: 0.09208198667565703
Validation loss: 2.437154441973154

Epoch: 739| Step: 0
Training loss: 0.10507856266114937
Validation loss: 2.4221939792487364

Epoch: 6| Step: 1
Training loss: 0.09346200497266448
Validation loss: 2.433736631003613

Epoch: 6| Step: 2
Training loss: 0.1185023218859981
Validation loss: 2.438032534356541

Epoch: 6| Step: 3
Training loss: 0.08438194509021021
Validation loss: 2.40989202426941

Epoch: 6| Step: 4
Training loss: 0.13192671017368743
Validation loss: 2.425371262184058

Epoch: 6| Step: 5
Training loss: 0.11939797201616881
Validation loss: 2.417487727055585

Epoch: 6| Step: 6
Training loss: 0.08657679322737684
Validation loss: 2.4321338756705755

Epoch: 6| Step: 7
Training loss: 0.15134722670335274
Validation loss: 2.3916036039987105

Epoch: 6| Step: 8
Training loss: 0.10050205325406278
Validation loss: 2.429997624604964

Epoch: 6| Step: 9
Training loss: 0.10440617880865899
Validation loss: 2.4320910329919485

Epoch: 6| Step: 10
Training loss: 0.09359906882009844
Validation loss: 2.4076442911263762

Epoch: 6| Step: 11
Training loss: 0.07427132150017883
Validation loss: 2.4215048293723975

Epoch: 6| Step: 12
Training loss: 0.09772413755142674
Validation loss: 2.383917022294178

Epoch: 6| Step: 13
Training loss: 0.10732280324153441
Validation loss: 2.4233042500611166

Epoch: 740| Step: 0
Training loss: 0.10426722133568642
Validation loss: 2.4113126877464213

Epoch: 6| Step: 1
Training loss: 0.09241765718033897
Validation loss: 2.4230472147948166

Epoch: 6| Step: 2
Training loss: 0.11579997461468784
Validation loss: 2.420027267162096

Epoch: 6| Step: 3
Training loss: 0.09820346106909496
Validation loss: 2.4186090132610434

Epoch: 6| Step: 4
Training loss: 0.08721173402979007
Validation loss: 2.428520364147805

Epoch: 6| Step: 5
Training loss: 0.09904994666197042
Validation loss: 2.3973216423595427

Epoch: 6| Step: 6
Training loss: 0.1061871881157649
Validation loss: 2.380413421851911

Epoch: 6| Step: 7
Training loss: 0.1383623241108107
Validation loss: 2.393019270066584

Epoch: 6| Step: 8
Training loss: 0.08426603504394495
Validation loss: 2.3929103324851027

Epoch: 6| Step: 9
Training loss: 0.11064916754198074
Validation loss: 2.387716972722063

Epoch: 6| Step: 10
Training loss: 0.109307932727204
Validation loss: 2.417978128914049

Epoch: 6| Step: 11
Training loss: 0.08549302749235071
Validation loss: 2.3981193482980703

Epoch: 6| Step: 12
Training loss: 0.08643698754369018
Validation loss: 2.363689223930281

Epoch: 6| Step: 13
Training loss: 0.11371782052697263
Validation loss: 2.3869069093414383

Epoch: 741| Step: 0
Training loss: 0.10569194295428065
Validation loss: 2.424983486249976

Epoch: 6| Step: 1
Training loss: 0.08249834454566116
Validation loss: 2.4170420810873408

Epoch: 6| Step: 2
Training loss: 0.14584336856533053
Validation loss: 2.4222711477951555

Epoch: 6| Step: 3
Training loss: 0.07723562830406451
Validation loss: 2.4135622081648735

Epoch: 6| Step: 4
Training loss: 0.0900334966763871
Validation loss: 2.398047943027067

Epoch: 6| Step: 5
Training loss: 0.09552123340164459
Validation loss: 2.4417429066859473

Epoch: 6| Step: 6
Training loss: 0.12014371687529408
Validation loss: 2.4313104703136696

Epoch: 6| Step: 7
Training loss: 0.09505211055006221
Validation loss: 2.4063057713889924

Epoch: 6| Step: 8
Training loss: 0.06647671439103835
Validation loss: 2.4250360306284318

Epoch: 6| Step: 9
Training loss: 0.11309558764643596
Validation loss: 2.391280116998886

Epoch: 6| Step: 10
Training loss: 0.13625205631191772
Validation loss: 2.4182865334836605

Epoch: 6| Step: 11
Training loss: 0.08160143600680499
Validation loss: 2.387637443217837

Epoch: 6| Step: 12
Training loss: 0.09344814800428286
Validation loss: 2.415126146871378

Epoch: 6| Step: 13
Training loss: 0.08418373078285582
Validation loss: 2.393053327510462

Epoch: 742| Step: 0
Training loss: 0.08809570123054884
Validation loss: 2.40282744933788

Epoch: 6| Step: 1
Training loss: 0.11518046362617405
Validation loss: 2.4017217191466997

Epoch: 6| Step: 2
Training loss: 0.08722250567243027
Validation loss: 2.387269385290549

Epoch: 6| Step: 3
Training loss: 0.09875887661132698
Validation loss: 2.3880655452229065

Epoch: 6| Step: 4
Training loss: 0.09229085793618039
Validation loss: 2.3746302699542268

Epoch: 6| Step: 5
Training loss: 0.07101216495066734
Validation loss: 2.39982172703822

Epoch: 6| Step: 6
Training loss: 0.09558313496592497
Validation loss: 2.396718450677089

Epoch: 6| Step: 7
Training loss: 0.1464506110379817
Validation loss: 2.390499333936553

Epoch: 6| Step: 8
Training loss: 0.11046402188640858
Validation loss: 2.385092538135764

Epoch: 6| Step: 9
Training loss: 0.10038540581669514
Validation loss: 2.4220863062213804

Epoch: 6| Step: 10
Training loss: 0.0839999040396602
Validation loss: 2.4054534002637085

Epoch: 6| Step: 11
Training loss: 0.09480680920710523
Validation loss: 2.392945261401782

Epoch: 6| Step: 12
Training loss: 0.11106689237792033
Validation loss: 2.422743495434976

Epoch: 6| Step: 13
Training loss: 0.10198269630781678
Validation loss: 2.398543728234982

Epoch: 743| Step: 0
Training loss: 0.08504782815508088
Validation loss: 2.4227337730778773

Epoch: 6| Step: 1
Training loss: 0.09390006869373764
Validation loss: 2.419251264590601

Epoch: 6| Step: 2
Training loss: 0.11047937789225769
Validation loss: 2.4094130086259633

Epoch: 6| Step: 3
Training loss: 0.07981953504732048
Validation loss: 2.4120282251216065

Epoch: 6| Step: 4
Training loss: 0.09301095974022006
Validation loss: 2.4532618121664953

Epoch: 6| Step: 5
Training loss: 0.12153181701335629
Validation loss: 2.3920148390751654

Epoch: 6| Step: 6
Training loss: 0.13065924215049765
Validation loss: 2.415057277785322

Epoch: 6| Step: 7
Training loss: 0.07797217919600426
Validation loss: 2.4069842222672166

Epoch: 6| Step: 8
Training loss: 0.08875547450938111
Validation loss: 2.4029829595337633

Epoch: 6| Step: 9
Training loss: 0.14464997235379315
Validation loss: 2.419751182208554

Epoch: 6| Step: 10
Training loss: 0.08662597992973736
Validation loss: 2.420232010569785

Epoch: 6| Step: 11
Training loss: 0.10539169057190033
Validation loss: 2.4334408378502066

Epoch: 6| Step: 12
Training loss: 0.09857031286704783
Validation loss: 2.4222633021421927

Epoch: 6| Step: 13
Training loss: 0.06624604281941941
Validation loss: 2.388470220099404

Epoch: 744| Step: 0
Training loss: 0.09983685174880576
Validation loss: 2.4214841878630766

Epoch: 6| Step: 1
Training loss: 0.11207735438409666
Validation loss: 2.4412682559812593

Epoch: 6| Step: 2
Training loss: 0.09119534226430699
Validation loss: 2.4248584124536094

Epoch: 6| Step: 3
Training loss: 0.12770959981328728
Validation loss: 2.4223934342469224

Epoch: 6| Step: 4
Training loss: 0.08572619914749029
Validation loss: 2.386929606984043

Epoch: 6| Step: 5
Training loss: 0.11357833284124716
Validation loss: 2.405163695406149

Epoch: 6| Step: 6
Training loss: 0.1278507047088873
Validation loss: 2.3916380101449755

Epoch: 6| Step: 7
Training loss: 0.14233264300857745
Validation loss: 2.406484487247385

Epoch: 6| Step: 8
Training loss: 0.10801858762002606
Validation loss: 2.4082562984365374

Epoch: 6| Step: 9
Training loss: 0.05912735280508043
Validation loss: 2.4015834952316766

Epoch: 6| Step: 10
Training loss: 0.11791056641296759
Validation loss: 2.3792507180130644

Epoch: 6| Step: 11
Training loss: 0.08552940693274771
Validation loss: 2.3854329155701994

Epoch: 6| Step: 12
Training loss: 0.09986994824983672
Validation loss: 2.4181717350348437

Epoch: 6| Step: 13
Training loss: 0.0940397672019111
Validation loss: 2.4181247463191253

Epoch: 745| Step: 0
Training loss: 0.10982822282694249
Validation loss: 2.434983551321227

Epoch: 6| Step: 1
Training loss: 0.06643473140625974
Validation loss: 2.41551788845686

Epoch: 6| Step: 2
Training loss: 0.12265071218587466
Validation loss: 2.429963690383806

Epoch: 6| Step: 3
Training loss: 0.11748103889206488
Validation loss: 2.418743847636215

Epoch: 6| Step: 4
Training loss: 0.09809438648546022
Validation loss: 2.4314379725621813

Epoch: 6| Step: 5
Training loss: 0.08627206527031801
Validation loss: 2.4365226925624306

Epoch: 6| Step: 6
Training loss: 0.06079039132896878
Validation loss: 2.4336324898817003

Epoch: 6| Step: 7
Training loss: 0.07746780962813768
Validation loss: 2.4186390312804336

Epoch: 6| Step: 8
Training loss: 0.10089856239692144
Validation loss: 2.44875196153172

Epoch: 6| Step: 9
Training loss: 0.07805546407816309
Validation loss: 2.4543703877536247

Epoch: 6| Step: 10
Training loss: 0.0733991466973166
Validation loss: 2.438780260913417

Epoch: 6| Step: 11
Training loss: 0.060744903877825385
Validation loss: 2.4351951370856617

Epoch: 6| Step: 12
Training loss: 0.07024989387353164
Validation loss: 2.4397127955210047

Epoch: 6| Step: 13
Training loss: 0.09447532449723596
Validation loss: 2.4276783693617965

Epoch: 746| Step: 0
Training loss: 0.08523776457608859
Validation loss: 2.472606939480437

Epoch: 6| Step: 1
Training loss: 0.11888254072137333
Validation loss: 2.467406035703766

Epoch: 6| Step: 2
Training loss: 0.06460561558603951
Validation loss: 2.412198097138739

Epoch: 6| Step: 3
Training loss: 0.09623504268552735
Validation loss: 2.445937513095654

Epoch: 6| Step: 4
Training loss: 0.11133380507317601
Validation loss: 2.450182559109741

Epoch: 6| Step: 5
Training loss: 0.11250534789964123
Validation loss: 2.4493423558684926

Epoch: 6| Step: 6
Training loss: 0.06397796088686612
Validation loss: 2.4571753516907506

Epoch: 6| Step: 7
Training loss: 0.10970961101990237
Validation loss: 2.4315240816160335

Epoch: 6| Step: 8
Training loss: 0.07555410937294278
Validation loss: 2.4289484471193967

Epoch: 6| Step: 9
Training loss: 0.07644412099721565
Validation loss: 2.449701772013006

Epoch: 6| Step: 10
Training loss: 0.10855233376920724
Validation loss: 2.4277477669102527

Epoch: 6| Step: 11
Training loss: 0.12274815235597444
Validation loss: 2.447533718954772

Epoch: 6| Step: 12
Training loss: 0.07886896846077289
Validation loss: 2.473055324203461

Epoch: 6| Step: 13
Training loss: 0.10820529243556945
Validation loss: 2.4001714529815144

Epoch: 747| Step: 0
Training loss: 0.0833703985585164
Validation loss: 2.449990907074171

Epoch: 6| Step: 1
Training loss: 0.0885218155102697
Validation loss: 2.42810855615543

Epoch: 6| Step: 2
Training loss: 0.07857674288600888
Validation loss: 2.4489135091424155

Epoch: 6| Step: 3
Training loss: 0.05656737902579132
Validation loss: 2.444881381940931

Epoch: 6| Step: 4
Training loss: 0.09031243498347757
Validation loss: 2.4426390011864547

Epoch: 6| Step: 5
Training loss: 0.09182527285481322
Validation loss: 2.4482866798714547

Epoch: 6| Step: 6
Training loss: 0.08180886733599478
Validation loss: 2.440309296573516

Epoch: 6| Step: 7
Training loss: 0.08274850171798583
Validation loss: 2.4529993921093904

Epoch: 6| Step: 8
Training loss: 0.08511719092254842
Validation loss: 2.4597477107373997

Epoch: 6| Step: 9
Training loss: 0.0769970349837844
Validation loss: 2.411490325584401

Epoch: 6| Step: 10
Training loss: 0.07622012725260632
Validation loss: 2.4599221120112986

Epoch: 6| Step: 11
Training loss: 0.10353941913860798
Validation loss: 2.4641026318667283

Epoch: 6| Step: 12
Training loss: 0.08840446734797017
Validation loss: 2.42468260618487

Epoch: 6| Step: 13
Training loss: 0.08632839772453209
Validation loss: 2.4396865924666065

Epoch: 748| Step: 0
Training loss: 0.11115490671975771
Validation loss: 2.457490730907014

Epoch: 6| Step: 1
Training loss: 0.08853793720730918
Validation loss: 2.396359636692368

Epoch: 6| Step: 2
Training loss: 0.09965384182692365
Validation loss: 2.418029488849926

Epoch: 6| Step: 3
Training loss: 0.06552848900193556
Validation loss: 2.4656785316769327

Epoch: 6| Step: 4
Training loss: 0.08975603652519912
Validation loss: 2.43513610577375

Epoch: 6| Step: 5
Training loss: 0.10459480416353935
Validation loss: 2.435780101169188

Epoch: 6| Step: 6
Training loss: 0.1117825186073295
Validation loss: 2.431374812737558

Epoch: 6| Step: 7
Training loss: 0.07385515886184148
Validation loss: 2.4627415355098816

Epoch: 6| Step: 8
Training loss: 0.11449924457656917
Validation loss: 2.4340901258117653

Epoch: 6| Step: 9
Training loss: 0.13354458712966502
Validation loss: 2.4360199003401055

Epoch: 6| Step: 10
Training loss: 0.12229918196137307
Validation loss: 2.390547380414495

Epoch: 6| Step: 11
Training loss: 0.1259148986475269
Validation loss: 2.4215200152789147

Epoch: 6| Step: 12
Training loss: 0.11172318216348585
Validation loss: 2.442524447806023

Epoch: 6| Step: 13
Training loss: 0.08050759220602148
Validation loss: 2.404210390046062

Epoch: 749| Step: 0
Training loss: 0.09879264533928261
Validation loss: 2.394925950879228

Epoch: 6| Step: 1
Training loss: 0.08745512088142711
Validation loss: 2.4327841987285925

Epoch: 6| Step: 2
Training loss: 0.09218466802870078
Validation loss: 2.424872824612731

Epoch: 6| Step: 3
Training loss: 0.08701078251721392
Validation loss: 2.440864799460061

Epoch: 6| Step: 4
Training loss: 0.0933987773759849
Validation loss: 2.4073874815179424

Epoch: 6| Step: 5
Training loss: 0.11791805005216859
Validation loss: 2.44807338034056

Epoch: 6| Step: 6
Training loss: 0.09667445178256275
Validation loss: 2.43444396208575

Epoch: 6| Step: 7
Training loss: 0.11999171379284454
Validation loss: 2.4571371486231137

Epoch: 6| Step: 8
Training loss: 0.09770156762538047
Validation loss: 2.4014492079204404

Epoch: 6| Step: 9
Training loss: 0.07123807494647214
Validation loss: 2.4331500161210067

Epoch: 6| Step: 10
Training loss: 0.08031171364158068
Validation loss: 2.433282276847913

Epoch: 6| Step: 11
Training loss: 0.09254571170194911
Validation loss: 2.4249604142745564

Epoch: 6| Step: 12
Training loss: 0.1051603638905645
Validation loss: 2.4515129798212794

Epoch: 6| Step: 13
Training loss: 0.16780954955968602
Validation loss: 2.408413894625287

Epoch: 750| Step: 0
Training loss: 0.08809543693729768
Validation loss: 2.4156583613929676

Epoch: 6| Step: 1
Training loss: 0.11065143587229695
Validation loss: 2.4035562534940595

Epoch: 6| Step: 2
Training loss: 0.12080379735192778
Validation loss: 2.4371992535159905

Epoch: 6| Step: 3
Training loss: 0.1056517056134074
Validation loss: 2.439960636567461

Epoch: 6| Step: 4
Training loss: 0.07638559558601568
Validation loss: 2.4331141866312795

Epoch: 6| Step: 5
Training loss: 0.054952776339549925
Validation loss: 2.457563567227337

Epoch: 6| Step: 6
Training loss: 0.09726460123097852
Validation loss: 2.441825123676999

Epoch: 6| Step: 7
Training loss: 0.13606238164620604
Validation loss: 2.4314390959955148

Epoch: 6| Step: 8
Training loss: 0.10680242445200572
Validation loss: 2.4706255931298444

Epoch: 6| Step: 9
Training loss: 0.11995538808643859
Validation loss: 2.447701658931482

Epoch: 6| Step: 10
Training loss: 0.10537576108252644
Validation loss: 2.462119414758202

Epoch: 6| Step: 11
Training loss: 0.12977104827921032
Validation loss: 2.4382531617180834

Epoch: 6| Step: 12
Training loss: 0.13998025539930692
Validation loss: 2.44120171879315

Epoch: 6| Step: 13
Training loss: 0.07908538664739302
Validation loss: 2.440566723935708

Testing loss: 2.6763388106812354
