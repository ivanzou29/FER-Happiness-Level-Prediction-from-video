Epoch: 1| Step: 0
Training loss: 5.4175367781337345
Validation loss: 5.851969236195176

Epoch: 6| Step: 1
Training loss: 6.151947841924203
Validation loss: 5.83726166445047

Epoch: 6| Step: 2
Training loss: 6.771277905076222
Validation loss: 5.826678733029431

Epoch: 6| Step: 3
Training loss: 7.0138505420538815
Validation loss: 5.817268526448584

Epoch: 6| Step: 4
Training loss: 5.674279914241631
Validation loss: 5.807323495858666

Epoch: 6| Step: 5
Training loss: 5.6831440436349245
Validation loss: 5.796120522901131

Epoch: 6| Step: 6
Training loss: 4.224473475767239
Validation loss: 5.783179765301776

Epoch: 6| Step: 7
Training loss: 6.789672683669456
Validation loss: 5.769201087906861

Epoch: 6| Step: 8
Training loss: 4.322289233653892
Validation loss: 5.752442414112989

Epoch: 6| Step: 9
Training loss: 5.460125907871499
Validation loss: 5.73350928013471

Epoch: 6| Step: 10
Training loss: 6.2623693517279015
Validation loss: 5.711794163458719

Epoch: 6| Step: 11
Training loss: 6.651088378869669
Validation loss: 5.687334799528098

Epoch: 6| Step: 12
Training loss: 4.014173906026886
Validation loss: 5.658508826935442

Epoch: 6| Step: 13
Training loss: 5.641968965906837
Validation loss: 5.626066601260136

Epoch: 2| Step: 0
Training loss: 6.355276675800713
Validation loss: 5.590010195281506

Epoch: 6| Step: 1
Training loss: 5.816922382027729
Validation loss: 5.549008145216918

Epoch: 6| Step: 2
Training loss: 6.771186639419961
Validation loss: 5.504858969384356

Epoch: 6| Step: 3
Training loss: 5.078456081454742
Validation loss: 5.457388035688365

Epoch: 6| Step: 4
Training loss: 4.670607583100137
Validation loss: 5.405721306282177

Epoch: 6| Step: 5
Training loss: 5.42945108242044
Validation loss: 5.351452789846761

Epoch: 6| Step: 6
Training loss: 4.8345185942182285
Validation loss: 5.2970787815227665

Epoch: 6| Step: 7
Training loss: 6.249384735340952
Validation loss: 5.2402028337511455

Epoch: 6| Step: 8
Training loss: 5.770201647324056
Validation loss: 5.186097361804722

Epoch: 6| Step: 9
Training loss: 4.665275275479047
Validation loss: 5.133222035843676

Epoch: 6| Step: 10
Training loss: 4.5219340354160735
Validation loss: 5.083002541987044

Epoch: 6| Step: 11
Training loss: 4.210694258251792
Validation loss: 5.036951748448077

Epoch: 6| Step: 12
Training loss: 4.2317861828647905
Validation loss: 4.992492527809253

Epoch: 6| Step: 13
Training loss: 5.619997130966811
Validation loss: 4.949978612540967

Epoch: 3| Step: 0
Training loss: 4.463517974232749
Validation loss: 4.911160425494043

Epoch: 6| Step: 1
Training loss: 4.175567021954501
Validation loss: 4.883182298664703

Epoch: 6| Step: 2
Training loss: 4.947680444265217
Validation loss: 4.861312736787104

Epoch: 6| Step: 3
Training loss: 5.286208855014896
Validation loss: 4.83966248500483

Epoch: 6| Step: 4
Training loss: 4.976526856107635
Validation loss: 4.818249801986759

Epoch: 6| Step: 5
Training loss: 4.560949819926513
Validation loss: 4.79791434490847

Epoch: 6| Step: 6
Training loss: 4.9980045151340935
Validation loss: 4.774945152400231

Epoch: 6| Step: 7
Training loss: 4.500456257048439
Validation loss: 4.745917227395348

Epoch: 6| Step: 8
Training loss: 5.678386051137414
Validation loss: 4.71269042040891

Epoch: 6| Step: 9
Training loss: 4.742186695582716
Validation loss: 4.684580569086407

Epoch: 6| Step: 10
Training loss: 3.9168661891898418
Validation loss: 4.661973420768352

Epoch: 6| Step: 11
Training loss: 4.70238522005721
Validation loss: 4.645657862406551

Epoch: 6| Step: 12
Training loss: 5.411351966240883
Validation loss: 4.631494278903459

Epoch: 6| Step: 13
Training loss: 5.422425871465922
Validation loss: 4.609057592910672

Epoch: 4| Step: 0
Training loss: 4.534221227497902
Validation loss: 4.59092316253791

Epoch: 6| Step: 1
Training loss: 5.227638578616791
Validation loss: 4.578766884737044

Epoch: 6| Step: 2
Training loss: 4.646461797838171
Validation loss: 4.563153993060195

Epoch: 6| Step: 3
Training loss: 4.676621287518385
Validation loss: 4.5467772430149065

Epoch: 6| Step: 4
Training loss: 3.492098745289226
Validation loss: 4.528479286079799

Epoch: 6| Step: 5
Training loss: 5.263887837638292
Validation loss: 4.517444299602286

Epoch: 6| Step: 6
Training loss: 5.140124821316204
Validation loss: 4.497874271736181

Epoch: 6| Step: 7
Training loss: 4.418100640093117
Validation loss: 4.483864115033063

Epoch: 6| Step: 8
Training loss: 4.473846517045601
Validation loss: 4.4721172005959255

Epoch: 6| Step: 9
Training loss: 3.4231551053442115
Validation loss: 4.464449888524302

Epoch: 6| Step: 10
Training loss: 5.239151417984253
Validation loss: 4.462521935081556

Epoch: 6| Step: 11
Training loss: 4.837074257107742
Validation loss: 4.442272700658952

Epoch: 6| Step: 12
Training loss: 4.31662961632184
Validation loss: 4.427107727253812

Epoch: 6| Step: 13
Training loss: 4.220888175244049
Validation loss: 4.412549510865004

Epoch: 5| Step: 0
Training loss: 4.714506148266847
Validation loss: 4.400913329806892

Epoch: 6| Step: 1
Training loss: 3.3712643329342553
Validation loss: 4.38797604633634

Epoch: 6| Step: 2
Training loss: 4.0510592829637675
Validation loss: 4.376825730454757

Epoch: 6| Step: 3
Training loss: 4.2942698956595144
Validation loss: 4.3649289756444745

Epoch: 6| Step: 4
Training loss: 4.268487549696504
Validation loss: 4.3529140230623735

Epoch: 6| Step: 5
Training loss: 3.801875961431519
Validation loss: 4.342040799751606

Epoch: 6| Step: 6
Training loss: 5.010292331900269
Validation loss: 4.333271065604576

Epoch: 6| Step: 7
Training loss: 4.736986302528927
Validation loss: 4.3190783998313895

Epoch: 6| Step: 8
Training loss: 5.285405978486598
Validation loss: 4.309446344251512

Epoch: 6| Step: 9
Training loss: 4.729175091482492
Validation loss: 4.288436620736011

Epoch: 6| Step: 10
Training loss: 4.265013263140647
Validation loss: 4.265782273993291

Epoch: 6| Step: 11
Training loss: 5.352976190443871
Validation loss: 4.258164573459016

Epoch: 6| Step: 12
Training loss: 4.373380524760619
Validation loss: 4.2506433684010005

Epoch: 6| Step: 13
Training loss: 2.3946197642757827
Validation loss: 4.253450959067165

Epoch: 6| Step: 0
Training loss: 4.418571397336403
Validation loss: 4.236556267621549

Epoch: 6| Step: 1
Training loss: 3.314038189444073
Validation loss: 4.219261591134223

Epoch: 6| Step: 2
Training loss: 3.6659704905735873
Validation loss: 4.208184064867594

Epoch: 6| Step: 3
Training loss: 4.524295916497843
Validation loss: 4.183777260171121

Epoch: 6| Step: 4
Training loss: 3.7526609516634526
Validation loss: 4.164957632870041

Epoch: 6| Step: 5
Training loss: 4.435932581066751
Validation loss: 4.160443956000519

Epoch: 6| Step: 6
Training loss: 4.24719594566567
Validation loss: 4.13660912857152

Epoch: 6| Step: 7
Training loss: 4.202900139561953
Validation loss: 4.1404725393226345

Epoch: 6| Step: 8
Training loss: 3.7077234745389873
Validation loss: 4.127825460741573

Epoch: 6| Step: 9
Training loss: 4.650098385334028
Validation loss: 4.1167104215481665

Epoch: 6| Step: 10
Training loss: 3.678861424077221
Validation loss: 4.097663765130894

Epoch: 6| Step: 11
Training loss: 4.717076693304612
Validation loss: 4.0800611172939645

Epoch: 6| Step: 12
Training loss: 5.5950140350683935
Validation loss: 4.067883245256757

Epoch: 6| Step: 13
Training loss: 4.629278523730081
Validation loss: 4.064210961490152

Epoch: 7| Step: 0
Training loss: 5.206368566584875
Validation loss: 4.043790836067491

Epoch: 6| Step: 1
Training loss: 4.9221718350470525
Validation loss: 4.035202770860201

Epoch: 6| Step: 2
Training loss: 4.054292104622519
Validation loss: 4.023313715052344

Epoch: 6| Step: 3
Training loss: 4.718545669274827
Validation loss: 4.008871495125533

Epoch: 6| Step: 4
Training loss: 4.688658304154317
Validation loss: 4.01336304499659

Epoch: 6| Step: 5
Training loss: 4.2799462331086335
Validation loss: 3.9903028048206837

Epoch: 6| Step: 6
Training loss: 3.754012186736871
Validation loss: 3.990176428139393

Epoch: 6| Step: 7
Training loss: 3.213538682504481
Validation loss: 3.9846223127486637

Epoch: 6| Step: 8
Training loss: 3.163369185228114
Validation loss: 3.9803350574027627

Epoch: 6| Step: 9
Training loss: 3.185708683285134
Validation loss: 3.9668614618795837

Epoch: 6| Step: 10
Training loss: 2.836517694986613
Validation loss: 3.960968359842988

Epoch: 6| Step: 11
Training loss: 4.545768052473602
Validation loss: 3.950646720852852

Epoch: 6| Step: 12
Training loss: 4.044128664379106
Validation loss: 3.9449720088138767

Epoch: 6| Step: 13
Training loss: 4.911645340283688
Validation loss: 3.9363089285325996

Epoch: 8| Step: 0
Training loss: 3.300640107697965
Validation loss: 3.935058029236228

Epoch: 6| Step: 1
Training loss: 4.416027286721666
Validation loss: 3.9285921355949505

Epoch: 6| Step: 2
Training loss: 3.5355182609879554
Validation loss: 3.9195897529787285

Epoch: 6| Step: 3
Training loss: 4.607124011739417
Validation loss: 3.9058378216259264

Epoch: 6| Step: 4
Training loss: 3.710875050872567
Validation loss: 3.894954416205559

Epoch: 6| Step: 5
Training loss: 4.37004331728768
Validation loss: 3.957326203714163

Epoch: 6| Step: 6
Training loss: 2.8442276773541604
Validation loss: 3.88946499305088

Epoch: 6| Step: 7
Training loss: 3.720331320620903
Validation loss: 3.8995664362923086

Epoch: 6| Step: 8
Training loss: 4.0516800209828565
Validation loss: 3.9071449222681953

Epoch: 6| Step: 9
Training loss: 4.479055619157006
Validation loss: 3.911177434202387

Epoch: 6| Step: 10
Training loss: 4.455705290001534
Validation loss: 3.8948363565606625

Epoch: 6| Step: 11
Training loss: 3.349824895125554
Validation loss: 3.877159691785625

Epoch: 6| Step: 12
Training loss: 5.23580721718974
Validation loss: 3.8618964738741046

Epoch: 6| Step: 13
Training loss: 4.318048860246101
Validation loss: 3.8260074225797034

Epoch: 9| Step: 0
Training loss: 4.817848701150518
Validation loss: 3.8287607454905204

Epoch: 6| Step: 1
Training loss: 4.953377413410229
Validation loss: 3.8539312107275863

Epoch: 6| Step: 2
Training loss: 3.947313220658744
Validation loss: 3.8002152872007304

Epoch: 6| Step: 3
Training loss: 3.956029254847588
Validation loss: 3.800929613614156

Epoch: 6| Step: 4
Training loss: 4.5453895685580195
Validation loss: 3.8048707533368447

Epoch: 6| Step: 5
Training loss: 3.4344896486564807
Validation loss: 3.8034438619300657

Epoch: 6| Step: 6
Training loss: 4.317630977267438
Validation loss: 3.795006891390511

Epoch: 6| Step: 7
Training loss: 3.174433385796876
Validation loss: 3.7816407623732147

Epoch: 6| Step: 8
Training loss: 4.280495235989877
Validation loss: 3.7663259104529425

Epoch: 6| Step: 9
Training loss: 2.486943770284893
Validation loss: 3.7525239237501036

Epoch: 6| Step: 10
Training loss: 3.6677058799076008
Validation loss: 3.7436389679352686

Epoch: 6| Step: 11
Training loss: 3.7829976732578126
Validation loss: 3.742884176114622

Epoch: 6| Step: 12
Training loss: 3.9330485779657214
Validation loss: 3.7349545624669895

Epoch: 6| Step: 13
Training loss: 3.065444776115701
Validation loss: 3.7234510814466266

Epoch: 10| Step: 0
Training loss: 2.7238057800715656
Validation loss: 3.712126786870117

Epoch: 6| Step: 1
Training loss: 4.3043332378188826
Validation loss: 3.7038692157319524

Epoch: 6| Step: 2
Training loss: 3.128183193218075
Validation loss: 3.697224512393793

Epoch: 6| Step: 3
Training loss: 4.159190120357014
Validation loss: 3.6908139034559033

Epoch: 6| Step: 4
Training loss: 3.9197670184207034
Validation loss: 3.683073196408628

Epoch: 6| Step: 5
Training loss: 3.3924452997800145
Validation loss: 3.6733285010385903

Epoch: 6| Step: 6
Training loss: 3.5891097919701367
Validation loss: 3.6626250630974773

Epoch: 6| Step: 7
Training loss: 4.007969070558883
Validation loss: 3.658949706587314

Epoch: 6| Step: 8
Training loss: 4.104390068880444
Validation loss: 3.657590900848422

Epoch: 6| Step: 9
Training loss: 3.713061814874169
Validation loss: 3.6403647300753206

Epoch: 6| Step: 10
Training loss: 3.329097122274466
Validation loss: 3.636767686073362

Epoch: 6| Step: 11
Training loss: 4.549666658703939
Validation loss: 3.6397233093108516

Epoch: 6| Step: 12
Training loss: 5.063085263177201
Validation loss: 3.6211916926461125

Epoch: 6| Step: 13
Training loss: 2.8818576130686875
Validation loss: 3.6195161745460833

Epoch: 11| Step: 0
Training loss: 3.010882349305981
Validation loss: 3.6242227028591483

Epoch: 6| Step: 1
Training loss: 3.843307841851382
Validation loss: 3.629370459654486

Epoch: 6| Step: 2
Training loss: 3.3154491036342364
Validation loss: 3.623560692206806

Epoch: 6| Step: 3
Training loss: 4.355171391895295
Validation loss: 3.628529969597313

Epoch: 6| Step: 4
Training loss: 3.6544435391132266
Validation loss: 3.61325269373524

Epoch: 6| Step: 5
Training loss: 4.117698912734817
Validation loss: 3.6079079432067527

Epoch: 6| Step: 6
Training loss: 4.187777837389661
Validation loss: 3.5953150440504458

Epoch: 6| Step: 7
Training loss: 3.651256574907557
Validation loss: 3.582325950918205

Epoch: 6| Step: 8
Training loss: 3.562744132260009
Validation loss: 3.5766677221016394

Epoch: 6| Step: 9
Training loss: 4.078854550404976
Validation loss: 3.5717393182670807

Epoch: 6| Step: 10
Training loss: 3.405470732696859
Validation loss: 3.5656932860400876

Epoch: 6| Step: 11
Training loss: 3.469753085979049
Validation loss: 3.55565836513822

Epoch: 6| Step: 12
Training loss: 4.533786668736982
Validation loss: 3.5452363778720595

Epoch: 6| Step: 13
Training loss: 3.32244287698636
Validation loss: 3.5362619950858902

Epoch: 12| Step: 0
Training loss: 4.660460955370008
Validation loss: 3.5298568615737214

Epoch: 6| Step: 1
Training loss: 3.8702596156450118
Validation loss: 3.524538626666675

Epoch: 6| Step: 2
Training loss: 4.401819477156311
Validation loss: 3.5202352869380036

Epoch: 6| Step: 3
Training loss: 3.809231842580573
Validation loss: 3.5129913054206456

Epoch: 6| Step: 4
Training loss: 3.2090748677232246
Validation loss: 3.509899690807002

Epoch: 6| Step: 5
Training loss: 3.9668141847849805
Validation loss: 3.505607816379865

Epoch: 6| Step: 6
Training loss: 3.424499341472574
Validation loss: 3.498232160636553

Epoch: 6| Step: 7
Training loss: 3.278144747635497
Validation loss: 3.4934402659312473

Epoch: 6| Step: 8
Training loss: 3.0961624141744064
Validation loss: 3.4894914776915957

Epoch: 6| Step: 9
Training loss: 3.092332149011812
Validation loss: 3.48325752781865

Epoch: 6| Step: 10
Training loss: 3.4959939100618374
Validation loss: 3.480650181651566

Epoch: 6| Step: 11
Training loss: 3.267940156881322
Validation loss: 3.4723952559695754

Epoch: 6| Step: 12
Training loss: 3.6159920416297093
Validation loss: 3.4707956635239934

Epoch: 6| Step: 13
Training loss: 4.789174811335994
Validation loss: 3.4659373431621257

Epoch: 13| Step: 0
Training loss: 3.340584513291333
Validation loss: 3.461010520974177

Epoch: 6| Step: 1
Training loss: 3.889706177585811
Validation loss: 3.4577748593580107

Epoch: 6| Step: 2
Training loss: 3.304949955179018
Validation loss: 3.4602643796861794

Epoch: 6| Step: 3
Training loss: 3.4940371809904307
Validation loss: 3.452836759964565

Epoch: 6| Step: 4
Training loss: 4.266727067599328
Validation loss: 3.453027638748222

Epoch: 6| Step: 5
Training loss: 4.216215601581997
Validation loss: 3.452073920540578

Epoch: 6| Step: 6
Training loss: 3.863144612764749
Validation loss: 3.450493546337569

Epoch: 6| Step: 7
Training loss: 4.456588736523027
Validation loss: 3.444717505784975

Epoch: 6| Step: 8
Training loss: 3.331368598472946
Validation loss: 3.4403445372626895

Epoch: 6| Step: 9
Training loss: 3.1948317933317094
Validation loss: 3.4337088552668598

Epoch: 6| Step: 10
Training loss: 3.4046572539906097
Validation loss: 3.430019300103902

Epoch: 6| Step: 11
Training loss: 2.8534756865895177
Validation loss: 3.4233182818079126

Epoch: 6| Step: 12
Training loss: 3.68751474151251
Validation loss: 3.421472811713296

Epoch: 6| Step: 13
Training loss: 3.6538417090261506
Validation loss: 3.4224424372589666

Epoch: 14| Step: 0
Training loss: 4.282869798290212
Validation loss: 3.4171464859750094

Epoch: 6| Step: 1
Training loss: 3.4662319357037097
Validation loss: 3.413911166523187

Epoch: 6| Step: 2
Training loss: 3.1414807420620265
Validation loss: 3.4102018939387904

Epoch: 6| Step: 3
Training loss: 4.260752595499263
Validation loss: 3.407162767837152

Epoch: 6| Step: 4
Training loss: 3.1680641771424334
Validation loss: 3.4072363498707188

Epoch: 6| Step: 5
Training loss: 3.2708539212949703
Validation loss: 3.405761510618394

Epoch: 6| Step: 6
Training loss: 4.095060182532068
Validation loss: 3.4045831463459297

Epoch: 6| Step: 7
Training loss: 2.8233655640685145
Validation loss: 3.4022040345444884

Epoch: 6| Step: 8
Training loss: 3.4521115572199013
Validation loss: 3.397377098604964

Epoch: 6| Step: 9
Training loss: 3.8503302098143966
Validation loss: 3.395609178561629

Epoch: 6| Step: 10
Training loss: 3.1576676914510475
Validation loss: 3.391713894851871

Epoch: 6| Step: 11
Training loss: 4.1227612055375875
Validation loss: 3.3880099139485655

Epoch: 6| Step: 12
Training loss: 4.3166779997884275
Validation loss: 3.3857186419250613

Epoch: 6| Step: 13
Training loss: 2.1782902440092773
Validation loss: 3.381820711036423

Epoch: 15| Step: 0
Training loss: 3.672230545037079
Validation loss: 3.378734095290394

Epoch: 6| Step: 1
Training loss: 4.104404242492571
Validation loss: 3.3786912798375406

Epoch: 6| Step: 2
Training loss: 4.170890091780751
Validation loss: 3.370646743683441

Epoch: 6| Step: 3
Training loss: 3.766491675461503
Validation loss: 3.3709138284116436

Epoch: 6| Step: 4
Training loss: 4.285273311271397
Validation loss: 3.3695824916969626

Epoch: 6| Step: 5
Training loss: 3.4445999342848785
Validation loss: 3.3660014856819607

Epoch: 6| Step: 6
Training loss: 3.6116378758621837
Validation loss: 3.364885496007529

Epoch: 6| Step: 7
Training loss: 3.0414737657666358
Validation loss: 3.361118977566103

Epoch: 6| Step: 8
Training loss: 4.276898253769395
Validation loss: 3.3580257666284647

Epoch: 6| Step: 9
Training loss: 3.95879623651078
Validation loss: 3.3542741668988416

Epoch: 6| Step: 10
Training loss: 2.9704345742253637
Validation loss: 3.35012117171925

Epoch: 6| Step: 11
Training loss: 3.180568263784134
Validation loss: 3.346488678287118

Epoch: 6| Step: 12
Training loss: 2.3005188564032664
Validation loss: 3.345158590497892

Epoch: 6| Step: 13
Training loss: 2.284294291895706
Validation loss: 3.3426214734000923

Epoch: 16| Step: 0
Training loss: 3.6085811914562806
Validation loss: 3.3405578974286394

Epoch: 6| Step: 1
Training loss: 3.032120412544164
Validation loss: 3.3375481312972703

Epoch: 6| Step: 2
Training loss: 3.7181776872583536
Validation loss: 3.335044412954445

Epoch: 6| Step: 3
Training loss: 3.855164489799132
Validation loss: 3.3335580186079516

Epoch: 6| Step: 4
Training loss: 3.0021519889808053
Validation loss: 3.3316335379314332

Epoch: 6| Step: 5
Training loss: 3.578874134784826
Validation loss: 3.330253992755573

Epoch: 6| Step: 6
Training loss: 2.9174735633417233
Validation loss: 3.327569673633341

Epoch: 6| Step: 7
Training loss: 2.5628585564575572
Validation loss: 3.326888763037461

Epoch: 6| Step: 8
Training loss: 3.141850322613576
Validation loss: 3.327122053185517

Epoch: 6| Step: 9
Training loss: 3.468975987676503
Validation loss: 3.3233347343765822

Epoch: 6| Step: 10
Training loss: 4.61501409559484
Validation loss: 3.3210349703254116

Epoch: 6| Step: 11
Training loss: 3.510283757230235
Validation loss: 3.3208860990793525

Epoch: 6| Step: 12
Training loss: 4.037186384273977
Validation loss: 3.317410603461603

Epoch: 6| Step: 13
Training loss: 4.77256115050428
Validation loss: 3.316494552179034

Epoch: 17| Step: 0
Training loss: 3.6999779056198694
Validation loss: 3.31464570185446

Epoch: 6| Step: 1
Training loss: 3.6643256314599038
Validation loss: 3.313650797739691

Epoch: 6| Step: 2
Training loss: 3.370329274015108
Validation loss: 3.311606898366055

Epoch: 6| Step: 3
Training loss: 3.839373322054462
Validation loss: 3.310549538886231

Epoch: 6| Step: 4
Training loss: 3.9420810269293014
Validation loss: 3.307521940661791

Epoch: 6| Step: 5
Training loss: 4.085175598180419
Validation loss: 3.3067462874871807

Epoch: 6| Step: 6
Training loss: 3.5524541189625496
Validation loss: 3.3047946833131556

Epoch: 6| Step: 7
Training loss: 2.6993038975580483
Validation loss: 3.304260763178961

Epoch: 6| Step: 8
Training loss: 3.070566414387348
Validation loss: 3.3041236970753194

Epoch: 6| Step: 9
Training loss: 3.785585424384194
Validation loss: 3.303296883060163

Epoch: 6| Step: 10
Training loss: 3.5350647972459486
Validation loss: 3.2996057172286557

Epoch: 6| Step: 11
Training loss: 3.5974590235027346
Validation loss: 3.298284605166717

Epoch: 6| Step: 12
Training loss: 2.768949934584296
Validation loss: 3.295935740342966

Epoch: 6| Step: 13
Training loss: 3.919201794731257
Validation loss: 3.2953652433606915

Epoch: 18| Step: 0
Training loss: 3.7373488328657456
Validation loss: 3.294581732459376

Epoch: 6| Step: 1
Training loss: 3.7131835565089713
Validation loss: 3.2937804979474232

Epoch: 6| Step: 2
Training loss: 3.512867842449474
Validation loss: 3.293322348620146

Epoch: 6| Step: 3
Training loss: 3.4521013356493166
Validation loss: 3.2909139538662773

Epoch: 6| Step: 4
Training loss: 2.821300808943832
Validation loss: 3.2891967128734376

Epoch: 6| Step: 5
Training loss: 3.2135266633922623
Validation loss: 3.2885409637252616

Epoch: 6| Step: 6
Training loss: 2.7014017069386362
Validation loss: 3.287036398262782

Epoch: 6| Step: 7
Training loss: 3.962514469348952
Validation loss: 3.2861782061392346

Epoch: 6| Step: 8
Training loss: 2.9690509844340744
Validation loss: 3.2845713629416813

Epoch: 6| Step: 9
Training loss: 4.420453062010443
Validation loss: 3.283951289160478

Epoch: 6| Step: 10
Training loss: 4.128901399521157
Validation loss: 3.2816317491015257

Epoch: 6| Step: 11
Training loss: 3.808124470287332
Validation loss: 3.281458589532621

Epoch: 6| Step: 12
Training loss: 3.2793108341721955
Validation loss: 3.280019962616206

Epoch: 6| Step: 13
Training loss: 3.0698855348303216
Validation loss: 3.2790404303061362

Epoch: 19| Step: 0
Training loss: 3.4691791440794493
Validation loss: 3.27696524556198

Epoch: 6| Step: 1
Training loss: 3.1544536350849857
Validation loss: 3.27548515003457

Epoch: 6| Step: 2
Training loss: 3.6989648040969842
Validation loss: 3.2745269921017366

Epoch: 6| Step: 3
Training loss: 3.5456513970419743
Validation loss: 3.2743842671381294

Epoch: 6| Step: 4
Training loss: 3.3373803049404915
Validation loss: 3.2727525758920057

Epoch: 6| Step: 5
Training loss: 3.64586462098275
Validation loss: 3.2714790870453574

Epoch: 6| Step: 6
Training loss: 4.20744379795955
Validation loss: 3.270868189254795

Epoch: 6| Step: 7
Training loss: 3.874490396769072
Validation loss: 3.2702191363166784

Epoch: 6| Step: 8
Training loss: 3.2082090642733134
Validation loss: 3.2694668402254576

Epoch: 6| Step: 9
Training loss: 3.344773323122039
Validation loss: 3.269960027553689

Epoch: 6| Step: 10
Training loss: 3.493458356609919
Validation loss: 3.269011974367757

Epoch: 6| Step: 11
Training loss: 3.2893317105624686
Validation loss: 3.2693200175165007

Epoch: 6| Step: 12
Training loss: 3.4155602563304344
Validation loss: 3.266309469088441

Epoch: 6| Step: 13
Training loss: 3.419377639314877
Validation loss: 3.2666263292378255

Epoch: 20| Step: 0
Training loss: 3.7213474466713876
Validation loss: 3.2648148750343724

Epoch: 6| Step: 1
Training loss: 3.444053921728213
Validation loss: 3.265288742942011

Epoch: 6| Step: 2
Training loss: 3.4279221703363962
Validation loss: 3.264252290296638

Epoch: 6| Step: 3
Training loss: 3.0584255284298916
Validation loss: 3.26041413742534

Epoch: 6| Step: 4
Training loss: 4.206401469661997
Validation loss: 3.2593476994597466

Epoch: 6| Step: 5
Training loss: 4.280493899217733
Validation loss: 3.2568962363032057

Epoch: 6| Step: 6
Training loss: 3.584068060373458
Validation loss: 3.2566015562703075

Epoch: 6| Step: 7
Training loss: 3.636002516154981
Validation loss: 3.2554162820004025

Epoch: 6| Step: 8
Training loss: 3.501885042736135
Validation loss: 3.254870108016756

Epoch: 6| Step: 9
Training loss: 3.2202645599483857
Validation loss: 3.253999131719716

Epoch: 6| Step: 10
Training loss: 3.5203237371692877
Validation loss: 3.2513155140309986

Epoch: 6| Step: 11
Training loss: 3.115370600959578
Validation loss: 3.2506889752019545

Epoch: 6| Step: 12
Training loss: 2.83262049365671
Validation loss: 3.2498078601036857

Epoch: 6| Step: 13
Training loss: 3.103584303195029
Validation loss: 3.249529300424962

Epoch: 21| Step: 0
Training loss: 2.811379781791464
Validation loss: 3.248491582430294

Epoch: 6| Step: 1
Training loss: 3.055508944608655
Validation loss: 3.2479121472574586

Epoch: 6| Step: 2
Training loss: 4.789230567758493
Validation loss: 3.2464428864672077

Epoch: 6| Step: 3
Training loss: 2.7085133908401846
Validation loss: 3.2449467122113984

Epoch: 6| Step: 4
Training loss: 3.810763104129016
Validation loss: 3.2439134206850917

Epoch: 6| Step: 5
Training loss: 3.379098734582439
Validation loss: 3.2433138714735192

Epoch: 6| Step: 6
Training loss: 3.3805184635943992
Validation loss: 3.242814492382249

Epoch: 6| Step: 7
Training loss: 3.6089633194942667
Validation loss: 3.2426132964313963

Epoch: 6| Step: 8
Training loss: 3.1881261472357827
Validation loss: 3.2409196501955018

Epoch: 6| Step: 9
Training loss: 3.4436767570336206
Validation loss: 3.2399066950555953

Epoch: 6| Step: 10
Training loss: 3.737832356350687
Validation loss: 3.2403232323166753

Epoch: 6| Step: 11
Training loss: 3.661539538999176
Validation loss: 3.2404633958047238

Epoch: 6| Step: 12
Training loss: 3.873715464661759
Validation loss: 3.237351319334125

Epoch: 6| Step: 13
Training loss: 2.5734111810020464
Validation loss: 3.235965224684952

Epoch: 22| Step: 0
Training loss: 3.2108846321301563
Validation loss: 3.234519590261215

Epoch: 6| Step: 1
Training loss: 3.782914985235917
Validation loss: 3.235470267361207

Epoch: 6| Step: 2
Training loss: 4.2472581433732275
Validation loss: 3.2334671922264344

Epoch: 6| Step: 3
Training loss: 2.7222208252295546
Validation loss: 3.2331577011866437

Epoch: 6| Step: 4
Training loss: 3.723790063146311
Validation loss: 3.2340668815924363

Epoch: 6| Step: 5
Training loss: 3.492469042324739
Validation loss: 3.2363691388315243

Epoch: 6| Step: 6
Training loss: 3.4296656718678245
Validation loss: 3.23019334956592

Epoch: 6| Step: 7
Training loss: 3.47866970023036
Validation loss: 3.228505996193355

Epoch: 6| Step: 8
Training loss: 3.5456713007757124
Validation loss: 3.2285582944180393

Epoch: 6| Step: 9
Training loss: 3.9729899188474755
Validation loss: 3.2301541589265885

Epoch: 6| Step: 10
Training loss: 3.0311339051342636
Validation loss: 3.23518943192813

Epoch: 6| Step: 11
Training loss: 3.6673030878939583
Validation loss: 3.237814432822127

Epoch: 6| Step: 12
Training loss: 2.898809116117688
Validation loss: 3.223671541646971

Epoch: 6| Step: 13
Training loss: 3.1508278682257442
Validation loss: 3.2261226582391775

Epoch: 23| Step: 0
Training loss: 3.795570180727287
Validation loss: 3.242025462990412

Epoch: 6| Step: 1
Training loss: 4.200892426273734
Validation loss: 3.2427522572913468

Epoch: 6| Step: 2
Training loss: 3.961871215799248
Validation loss: 3.243285253515967

Epoch: 6| Step: 3
Training loss: 3.5982908006150662
Validation loss: 3.239116239485056

Epoch: 6| Step: 4
Training loss: 3.2734994085826137
Validation loss: 3.230599956533979

Epoch: 6| Step: 5
Training loss: 2.8826100348109818
Validation loss: 3.2274179768363482

Epoch: 6| Step: 6
Training loss: 3.4800089351495496
Validation loss: 3.2287543230367377

Epoch: 6| Step: 7
Training loss: 4.394714839915091
Validation loss: 3.223617007375206

Epoch: 6| Step: 8
Training loss: 2.881700751075656
Validation loss: 3.2194001755469124

Epoch: 6| Step: 9
Training loss: 3.421025418933947
Validation loss: 3.2180473189045293

Epoch: 6| Step: 10
Training loss: 3.3345990321110657
Validation loss: 3.215770345430795

Epoch: 6| Step: 11
Training loss: 2.5241202266430545
Validation loss: 3.215950618002334

Epoch: 6| Step: 12
Training loss: 3.0754168840370433
Validation loss: 3.217190552792279

Epoch: 6| Step: 13
Training loss: 3.480309685048906
Validation loss: 3.2156543000197835

Epoch: 24| Step: 0
Training loss: 3.0067734546122424
Validation loss: 3.2163536262052577

Epoch: 6| Step: 1
Training loss: 3.6894585532153026
Validation loss: 3.214302112754326

Epoch: 6| Step: 2
Training loss: 4.453241928974723
Validation loss: 3.2104811146823358

Epoch: 6| Step: 3
Training loss: 4.439906797375905
Validation loss: 3.208224801469311

Epoch: 6| Step: 4
Training loss: 2.9836591091623554
Validation loss: 3.206853114133427

Epoch: 6| Step: 5
Training loss: 3.362467065812951
Validation loss: 3.206266550669306

Epoch: 6| Step: 6
Training loss: 3.125071715485696
Validation loss: 3.2059215328229786

Epoch: 6| Step: 7
Training loss: 2.878184006673224
Validation loss: 3.207767130305717

Epoch: 6| Step: 8
Training loss: 3.3825658131221243
Validation loss: 3.2092678950004947

Epoch: 6| Step: 9
Training loss: 3.4201760450863232
Validation loss: 3.205978629491368

Epoch: 6| Step: 10
Training loss: 3.142635480074028
Validation loss: 3.202582065239445

Epoch: 6| Step: 11
Training loss: 2.745526055685637
Validation loss: 3.201060842402256

Epoch: 6| Step: 12
Training loss: 3.2738035448028
Validation loss: 3.19918097332081

Epoch: 6| Step: 13
Training loss: 4.492906277414092
Validation loss: 3.197799445315295

Epoch: 25| Step: 0
Training loss: 2.9463788841648886
Validation loss: 3.197182080382106

Epoch: 6| Step: 1
Training loss: 4.760945608634792
Validation loss: 3.1975219783354567

Epoch: 6| Step: 2
Training loss: 2.4924478903080156
Validation loss: 3.196691460266973

Epoch: 6| Step: 3
Training loss: 3.84325287868417
Validation loss: 3.194705425181344

Epoch: 6| Step: 4
Training loss: 3.5251537803491444
Validation loss: 3.1938874533243458

Epoch: 6| Step: 5
Training loss: 3.7124670470345436
Validation loss: 3.193536911702765

Epoch: 6| Step: 6
Training loss: 3.3868679906924264
Validation loss: 3.1919974364181662

Epoch: 6| Step: 7
Training loss: 3.4188188117039404
Validation loss: 3.192815779266621

Epoch: 6| Step: 8
Training loss: 2.813584182306926
Validation loss: 3.193617027655859

Epoch: 6| Step: 9
Training loss: 2.8211406643647394
Validation loss: 3.1901032821456488

Epoch: 6| Step: 10
Training loss: 3.8452610674305037
Validation loss: 3.18940340717767

Epoch: 6| Step: 11
Training loss: 3.4608848688330247
Validation loss: 3.1872471245211593

Epoch: 6| Step: 12
Training loss: 3.3992767350080504
Validation loss: 3.1862203951919223

Epoch: 6| Step: 13
Training loss: 3.276520290293884
Validation loss: 3.1855710889040205

Epoch: 26| Step: 0
Training loss: 3.2815149109487236
Validation loss: 3.184587623588461

Epoch: 6| Step: 1
Training loss: 3.5053386843488017
Validation loss: 3.1838892061969717

Epoch: 6| Step: 2
Training loss: 2.7062421697278642
Validation loss: 3.1836613175644093

Epoch: 6| Step: 3
Training loss: 4.2353636090804585
Validation loss: 3.1833433571041168

Epoch: 6| Step: 4
Training loss: 3.5508477233103344
Validation loss: 3.181856547008359

Epoch: 6| Step: 5
Training loss: 3.5164125365747934
Validation loss: 3.180696367136031

Epoch: 6| Step: 6
Training loss: 3.47048631805594
Validation loss: 3.179996209125887

Epoch: 6| Step: 7
Training loss: 2.5170858181496665
Validation loss: 3.1791790458967064

Epoch: 6| Step: 8
Training loss: 3.915426720837717
Validation loss: 3.178311833678364

Epoch: 6| Step: 9
Training loss: 3.6061942216866756
Validation loss: 3.178230988294069

Epoch: 6| Step: 10
Training loss: 2.681378601120171
Validation loss: 3.177508049060094

Epoch: 6| Step: 11
Training loss: 3.1446161673316744
Validation loss: 3.176147045934117

Epoch: 6| Step: 12
Training loss: 3.2731404681857295
Validation loss: 3.1752241165841064

Epoch: 6| Step: 13
Training loss: 4.850193586123751
Validation loss: 3.174996069480266

Epoch: 27| Step: 0
Training loss: 3.8287815076009206
Validation loss: 3.1742623013225244

Epoch: 6| Step: 1
Training loss: 4.235953962124504
Validation loss: 3.1735417135166006

Epoch: 6| Step: 2
Training loss: 3.543077629123942
Validation loss: 3.1727566623479673

Epoch: 6| Step: 3
Training loss: 3.771115933501797
Validation loss: 3.172734897533214

Epoch: 6| Step: 4
Training loss: 3.6694199166515733
Validation loss: 3.173448320430339

Epoch: 6| Step: 5
Training loss: 3.65974780626099
Validation loss: 3.1693714283044514

Epoch: 6| Step: 6
Training loss: 3.233506532991911
Validation loss: 3.1672730348354596

Epoch: 6| Step: 7
Training loss: 3.659883177513577
Validation loss: 3.1666853104859127

Epoch: 6| Step: 8
Training loss: 3.612309043615581
Validation loss: 3.164269233329452

Epoch: 6| Step: 9
Training loss: 2.6537760264934764
Validation loss: 3.1643482220530275

Epoch: 6| Step: 10
Training loss: 2.776441467772823
Validation loss: 3.163582770894823

Epoch: 6| Step: 11
Training loss: 2.124261391125091
Validation loss: 3.1627383312423762

Epoch: 6| Step: 12
Training loss: 2.801928510016653
Validation loss: 3.1627608684246535

Epoch: 6| Step: 13
Training loss: 4.195373875685826
Validation loss: 3.161294616675793

Epoch: 28| Step: 0
Training loss: 3.093241640189866
Validation loss: 3.161769886393325

Epoch: 6| Step: 1
Training loss: 3.391939110713241
Validation loss: 3.1598913938452884

Epoch: 6| Step: 2
Training loss: 3.586016352831632
Validation loss: 3.1591193721676376

Epoch: 6| Step: 3
Training loss: 2.892876155730241
Validation loss: 3.158299800162198

Epoch: 6| Step: 4
Training loss: 2.4456496326230615
Validation loss: 3.157954826621629

Epoch: 6| Step: 5
Training loss: 3.3187470459431
Validation loss: 3.157250806032437

Epoch: 6| Step: 6
Training loss: 3.9227228350098375
Validation loss: 3.157934155586503

Epoch: 6| Step: 7
Training loss: 3.8030050893544387
Validation loss: 3.1574717094087967

Epoch: 6| Step: 8
Training loss: 3.715719575055311
Validation loss: 3.1542858899125026

Epoch: 6| Step: 9
Training loss: 3.6447008099624068
Validation loss: 3.1530617443942455

Epoch: 6| Step: 10
Training loss: 3.4368504690851167
Validation loss: 3.1522965112603467

Epoch: 6| Step: 11
Training loss: 3.2050379553584207
Validation loss: 3.1525087636771643

Epoch: 6| Step: 12
Training loss: 3.7477886037415398
Validation loss: 3.150963263204491

Epoch: 6| Step: 13
Training loss: 3.4669759526812016
Validation loss: 3.150882246594508

Epoch: 29| Step: 0
Training loss: 3.9199356208107896
Validation loss: 3.1490292015645496

Epoch: 6| Step: 1
Training loss: 3.5151431961519184
Validation loss: 3.1482611446770323

Epoch: 6| Step: 2
Training loss: 2.3623428373185535
Validation loss: 3.148116776724734

Epoch: 6| Step: 3
Training loss: 3.46005534001013
Validation loss: 3.1462693026749706

Epoch: 6| Step: 4
Training loss: 3.448940451639117
Validation loss: 3.146463506393161

Epoch: 6| Step: 5
Training loss: 3.498259247723391
Validation loss: 3.1452179515815755

Epoch: 6| Step: 6
Training loss: 3.2016258639334207
Validation loss: 3.1449277476626296

Epoch: 6| Step: 7
Training loss: 3.738202164948465
Validation loss: 3.143287255584479

Epoch: 6| Step: 8
Training loss: 3.2107281024901684
Validation loss: 3.1417991807603

Epoch: 6| Step: 9
Training loss: 3.2099500933894256
Validation loss: 3.1418354866986533

Epoch: 6| Step: 10
Training loss: 3.7492663619525155
Validation loss: 3.1394974070943755

Epoch: 6| Step: 11
Training loss: 3.7607392712514662
Validation loss: 3.13908535828302

Epoch: 6| Step: 12
Training loss: 3.511897981035215
Validation loss: 3.1378787853817

Epoch: 6| Step: 13
Training loss: 2.487145947893989
Validation loss: 3.1369252079292043

Epoch: 30| Step: 0
Training loss: 3.3784917500005496
Validation loss: 3.137264238961713

Epoch: 6| Step: 1
Training loss: 3.703517973446149
Validation loss: 3.140043332652827

Epoch: 6| Step: 2
Training loss: 2.4136006428890617
Validation loss: 3.1455329442470967

Epoch: 6| Step: 3
Training loss: 3.2009955049797227
Validation loss: 3.149118722541903

Epoch: 6| Step: 4
Training loss: 3.424051507081126
Validation loss: 3.147100609917856

Epoch: 6| Step: 5
Training loss: 2.6135879587508515
Validation loss: 3.147319914843867

Epoch: 6| Step: 6
Training loss: 3.4921663356199413
Validation loss: 3.1639462401921117

Epoch: 6| Step: 7
Training loss: 3.7195728577704585
Validation loss: 3.1752468671063947

Epoch: 6| Step: 8
Training loss: 3.6353396577885584
Validation loss: 3.15029106234312

Epoch: 6| Step: 9
Training loss: 4.060954107916213
Validation loss: 3.135157569975803

Epoch: 6| Step: 10
Training loss: 3.2217946883366024
Validation loss: 3.1404075100336843

Epoch: 6| Step: 11
Training loss: 3.815647639426911
Validation loss: 3.2058888330433892

Epoch: 6| Step: 12
Training loss: 3.028765574630512
Validation loss: 3.1423623333489723

Epoch: 6| Step: 13
Training loss: 3.900494417004403
Validation loss: 3.1273569337194185

Epoch: 31| Step: 0
Training loss: 2.8737242812258166
Validation loss: 3.1234545604593618

Epoch: 6| Step: 1
Training loss: 3.0692102526068545
Validation loss: 3.1310187070166022

Epoch: 6| Step: 2
Training loss: 3.391159929541013
Validation loss: 3.133412020207337

Epoch: 6| Step: 3
Training loss: 2.926507714487372
Validation loss: 3.1298713796881383

Epoch: 6| Step: 4
Training loss: 4.208903031769081
Validation loss: 3.129649931366017

Epoch: 6| Step: 5
Training loss: 3.204133558825688
Validation loss: 3.1263024616374055

Epoch: 6| Step: 6
Training loss: 2.7597438544125383
Validation loss: 3.123065392312203

Epoch: 6| Step: 7
Training loss: 3.5227332923367882
Validation loss: 3.1228319059077436

Epoch: 6| Step: 8
Training loss: 3.6726722663379228
Validation loss: 3.1209795383167793

Epoch: 6| Step: 9
Training loss: 3.818828645636178
Validation loss: 3.1221505026752783

Epoch: 6| Step: 10
Training loss: 3.8870956161511594
Validation loss: 3.122297745422338

Epoch: 6| Step: 11
Training loss: 2.693762468986241
Validation loss: 3.1216226781785243

Epoch: 6| Step: 12
Training loss: 3.6956487587330056
Validation loss: 3.1202361024690526

Epoch: 6| Step: 13
Training loss: 3.4953788495235787
Validation loss: 3.1198032246157688

Epoch: 32| Step: 0
Training loss: 3.826760558816258
Validation loss: 3.118467536228523

Epoch: 6| Step: 1
Training loss: 3.5006743190228664
Validation loss: 3.11792766509351

Epoch: 6| Step: 2
Training loss: 2.322966114652605
Validation loss: 3.1168773940054404

Epoch: 6| Step: 3
Training loss: 3.197681695877408
Validation loss: 3.115811376285606

Epoch: 6| Step: 4
Training loss: 3.952412416668836
Validation loss: 3.113047359166141

Epoch: 6| Step: 5
Training loss: 3.716336917932152
Validation loss: 3.113577430291429

Epoch: 6| Step: 6
Training loss: 3.4960801108323336
Validation loss: 3.1134092613641324

Epoch: 6| Step: 7
Training loss: 2.183917572631873
Validation loss: 3.109385510548128

Epoch: 6| Step: 8
Training loss: 3.50736075638119
Validation loss: 3.110406482425646

Epoch: 6| Step: 9
Training loss: 4.286509158581323
Validation loss: 3.107572203895143

Epoch: 6| Step: 10
Training loss: 3.02481418385705
Validation loss: 3.1080802686680893

Epoch: 6| Step: 11
Training loss: 3.332551403522037
Validation loss: 3.1069942748463317

Epoch: 6| Step: 12
Training loss: 3.4275263970469454
Validation loss: 3.107240818933169

Epoch: 6| Step: 13
Training loss: 2.6835744709949325
Validation loss: 3.1075634526461395

Epoch: 33| Step: 0
Training loss: 3.6003209288917044
Validation loss: 3.105515851596002

Epoch: 6| Step: 1
Training loss: 2.702395566745146
Validation loss: 3.103200683027718

Epoch: 6| Step: 2
Training loss: 3.761167048068533
Validation loss: 3.102802867035599

Epoch: 6| Step: 3
Training loss: 3.8703686509507973
Validation loss: 3.1039019681914226

Epoch: 6| Step: 4
Training loss: 2.4077157844660757
Validation loss: 3.1004880754799498

Epoch: 6| Step: 5
Training loss: 3.7924190794748984
Validation loss: 3.099731633958

Epoch: 6| Step: 6
Training loss: 3.5096251428305667
Validation loss: 3.0976717295144356

Epoch: 6| Step: 7
Training loss: 3.8259896687249992
Validation loss: 3.098010561209795

Epoch: 6| Step: 8
Training loss: 3.4776897531676267
Validation loss: 3.0977991280119848

Epoch: 6| Step: 9
Training loss: 3.303703432133804
Validation loss: 3.0964564433115815

Epoch: 6| Step: 10
Training loss: 2.569387251987814
Validation loss: 3.0952655804313136

Epoch: 6| Step: 11
Training loss: 3.8247952674477395
Validation loss: 3.094343557520053

Epoch: 6| Step: 12
Training loss: 3.267482393621571
Validation loss: 3.093134910383241

Epoch: 6| Step: 13
Training loss: 2.3582484100831422
Validation loss: 3.0926706091117913

Epoch: 34| Step: 0
Training loss: 3.4110476802377696
Validation loss: 3.0946760667452597

Epoch: 6| Step: 1
Training loss: 4.290404841032041
Validation loss: 3.092397615275148

Epoch: 6| Step: 2
Training loss: 3.341869502836222
Validation loss: 3.090034667825249

Epoch: 6| Step: 3
Training loss: 3.7240711257321224
Validation loss: 3.088588190834195

Epoch: 6| Step: 4
Training loss: 3.399696976116981
Validation loss: 3.0881201526255886

Epoch: 6| Step: 5
Training loss: 2.6183362574796742
Validation loss: 3.0868253403459796

Epoch: 6| Step: 6
Training loss: 3.7895245771727217
Validation loss: 3.089132199416143

Epoch: 6| Step: 7
Training loss: 3.3068909570038247
Validation loss: 3.0873360013921722

Epoch: 6| Step: 8
Training loss: 3.0460567060215453
Validation loss: 3.0863249604432323

Epoch: 6| Step: 9
Training loss: 2.918614490965705
Validation loss: 3.085815902480441

Epoch: 6| Step: 10
Training loss: 3.148209102098701
Validation loss: 3.084483061738515

Epoch: 6| Step: 11
Training loss: 3.190957531614436
Validation loss: 3.0847894417007895

Epoch: 6| Step: 12
Training loss: 3.60307363058297
Validation loss: 3.088801928603125

Epoch: 6| Step: 13
Training loss: 2.6022178580514197
Validation loss: 3.0879694089233434

Epoch: 35| Step: 0
Training loss: 3.3498569230228505
Validation loss: 3.0980303899867163

Epoch: 6| Step: 1
Training loss: 3.6992610296554287
Validation loss: 3.1083556691528806

Epoch: 6| Step: 2
Training loss: 3.2505800756552774
Validation loss: 3.0949663290498646

Epoch: 6| Step: 3
Training loss: 2.8705007758193504
Validation loss: 3.0835852804128723

Epoch: 6| Step: 4
Training loss: 3.6725865750011812
Validation loss: 3.0833704368888695

Epoch: 6| Step: 5
Training loss: 2.604571735667692
Validation loss: 3.081225742193931

Epoch: 6| Step: 6
Training loss: 3.550271445628698
Validation loss: 3.0796046594516917

Epoch: 6| Step: 7
Training loss: 3.4188344327832225
Validation loss: 3.0817752023028118

Epoch: 6| Step: 8
Training loss: 2.9683108356300805
Validation loss: 3.0807126261775806

Epoch: 6| Step: 9
Training loss: 3.341010281475909
Validation loss: 3.0760441808440713

Epoch: 6| Step: 10
Training loss: 3.568089166442259
Validation loss: 3.075337893582011

Epoch: 6| Step: 11
Training loss: 3.6751781135007033
Validation loss: 3.0757474518930468

Epoch: 6| Step: 12
Training loss: 4.0435121917371
Validation loss: 3.07344124336452

Epoch: 6| Step: 13
Training loss: 2.115648900042139
Validation loss: 3.0713520358370414

Epoch: 36| Step: 0
Training loss: 2.4682279590143033
Validation loss: 3.0704205725242724

Epoch: 6| Step: 1
Training loss: 3.4788975107086224
Validation loss: 3.0771323273741014

Epoch: 6| Step: 2
Training loss: 3.746317390393263
Validation loss: 3.079424521157189

Epoch: 6| Step: 3
Training loss: 2.786766496296884
Validation loss: 3.07545275992844

Epoch: 6| Step: 4
Training loss: 3.7124525330459957
Validation loss: 3.0727559665869553

Epoch: 6| Step: 5
Training loss: 3.694226224249817
Validation loss: 3.0681502267020364

Epoch: 6| Step: 6
Training loss: 3.71623208850967
Validation loss: 3.0662840969945497

Epoch: 6| Step: 7
Training loss: 3.195453370213832
Validation loss: 3.0645164512953618

Epoch: 6| Step: 8
Training loss: 3.7395282766102174
Validation loss: 3.066269838554149

Epoch: 6| Step: 9
Training loss: 3.0935426893037103
Validation loss: 3.064342282010537

Epoch: 6| Step: 10
Training loss: 3.669693838752522
Validation loss: 3.0627889465476814

Epoch: 6| Step: 11
Training loss: 3.0829374385676513
Validation loss: 3.0620390608139596

Epoch: 6| Step: 12
Training loss: 3.280525054775495
Validation loss: 3.063234143706041

Epoch: 6| Step: 13
Training loss: 2.442330684357245
Validation loss: 3.062174981763371

Epoch: 37| Step: 0
Training loss: 3.2800795147724666
Validation loss: 3.06532313343213

Epoch: 6| Step: 1
Training loss: 4.064351760208864
Validation loss: 3.064445903688028

Epoch: 6| Step: 2
Training loss: 4.009453331649685
Validation loss: 3.0667388850554693

Epoch: 6| Step: 3
Training loss: 3.2299765934996594
Validation loss: 3.0646953235688814

Epoch: 6| Step: 4
Training loss: 2.8862679301118406
Validation loss: 3.0691329016437545

Epoch: 6| Step: 5
Training loss: 3.001740586470109
Validation loss: 3.074276699954259

Epoch: 6| Step: 6
Training loss: 3.1923024519558267
Validation loss: 3.055708917390509

Epoch: 6| Step: 7
Training loss: 3.267116224404496
Validation loss: 3.0573794022569727

Epoch: 6| Step: 8
Training loss: 3.1906045492714297
Validation loss: 3.0567436539789927

Epoch: 6| Step: 9
Training loss: 2.909015939028267
Validation loss: 3.059378797441267

Epoch: 6| Step: 10
Training loss: 3.2376400596928514
Validation loss: 3.0584602071683724

Epoch: 6| Step: 11
Training loss: 3.7931236290469594
Validation loss: 3.0633472277756804

Epoch: 6| Step: 12
Training loss: 3.4992183084864505
Validation loss: 3.057474878450256

Epoch: 6| Step: 13
Training loss: 2.49349223934394
Validation loss: 3.0571182625819024

Epoch: 38| Step: 0
Training loss: 3.8477184619811906
Validation loss: 3.057366933600333

Epoch: 6| Step: 1
Training loss: 3.5586572635145743
Validation loss: 3.0577494827090006

Epoch: 6| Step: 2
Training loss: 2.881500359040899
Validation loss: 3.0626542255743874

Epoch: 6| Step: 3
Training loss: 3.0692268762440627
Validation loss: 3.0731293941314237

Epoch: 6| Step: 4
Training loss: 3.4690992849640363
Validation loss: 3.081543358511095

Epoch: 6| Step: 5
Training loss: 3.127997524777577
Validation loss: 3.0874015860507735

Epoch: 6| Step: 6
Training loss: 2.6226221849980873
Validation loss: 3.0702718380157994

Epoch: 6| Step: 7
Training loss: 3.8462749344764773
Validation loss: 3.058436192276045

Epoch: 6| Step: 8
Training loss: 3.2758634404562073
Validation loss: 3.0536724983173253

Epoch: 6| Step: 9
Training loss: 3.324532302431009
Validation loss: 3.0475825638531067

Epoch: 6| Step: 10
Training loss: 3.1406702446406705
Validation loss: 3.04787716219653

Epoch: 6| Step: 11
Training loss: 3.5498684925919815
Validation loss: 3.0467631413888334

Epoch: 6| Step: 12
Training loss: 3.120212702714458
Validation loss: 3.0467169372266403

Epoch: 6| Step: 13
Training loss: 3.681987327218198
Validation loss: 3.0514079638179186

Epoch: 39| Step: 0
Training loss: 3.230961717034629
Validation loss: 3.0474104333782095

Epoch: 6| Step: 1
Training loss: 2.671260919329934
Validation loss: 3.040815580449296

Epoch: 6| Step: 2
Training loss: 4.26594022487391
Validation loss: 3.045050544243166

Epoch: 6| Step: 3
Training loss: 3.4092774542430195
Validation loss: 3.0424246858409094

Epoch: 6| Step: 4
Training loss: 3.682712356442323
Validation loss: 3.063866493546539

Epoch: 6| Step: 5
Training loss: 2.908373969230481
Validation loss: 3.039441988545237

Epoch: 6| Step: 6
Training loss: 3.271166612366202
Validation loss: 3.040151098524707

Epoch: 6| Step: 7
Training loss: 2.87460092179675
Validation loss: 3.0566379100886185

Epoch: 6| Step: 8
Training loss: 3.001428264136236
Validation loss: 3.1236250791686326

Epoch: 6| Step: 9
Training loss: 3.3279312865426203
Validation loss: 3.1770501974076746

Epoch: 6| Step: 10
Training loss: 3.592511569052951
Validation loss: 3.1790405745704544

Epoch: 6| Step: 11
Training loss: 3.6634513166297715
Validation loss: 3.1665149311268403

Epoch: 6| Step: 12
Training loss: 3.5381550751853106
Validation loss: 3.0845273728766753

Epoch: 6| Step: 13
Training loss: 3.198410360559397
Validation loss: 3.0375233366276695

Epoch: 40| Step: 0
Training loss: 3.2344796721249693
Validation loss: 3.0345735790811204

Epoch: 6| Step: 1
Training loss: 4.085109298532541
Validation loss: 3.048337274927617

Epoch: 6| Step: 2
Training loss: 3.7419694745415653
Validation loss: 3.1259571242226967

Epoch: 6| Step: 3
Training loss: 3.27596955252857
Validation loss: 3.041515490429756

Epoch: 6| Step: 4
Training loss: 3.2721627969604463
Validation loss: 3.0351135527103126

Epoch: 6| Step: 5
Training loss: 2.699046415135521
Validation loss: 3.040579510664799

Epoch: 6| Step: 6
Training loss: 2.3156477665779445
Validation loss: 3.063683147972184

Epoch: 6| Step: 7
Training loss: 3.6111592428146024
Validation loss: 3.1041546414138184

Epoch: 6| Step: 8
Training loss: 3.3642925376927026
Validation loss: 3.1270000972818033

Epoch: 6| Step: 9
Training loss: 3.570286055786231
Validation loss: 3.096011965165586

Epoch: 6| Step: 10
Training loss: 3.275341854744615
Validation loss: 3.0574703389000533

Epoch: 6| Step: 11
Training loss: 3.29127207133263
Validation loss: 3.0505740513265405

Epoch: 6| Step: 12
Training loss: 3.3798838000666716
Validation loss: 3.0566821745013915

Epoch: 6| Step: 13
Training loss: 3.2519355292316754
Validation loss: 3.029318234246241

Epoch: 41| Step: 0
Training loss: 3.6992328003049564
Validation loss: 3.0251268781771232

Epoch: 6| Step: 1
Training loss: 2.6060435334534215
Validation loss: 3.0234477708676044

Epoch: 6| Step: 2
Training loss: 3.45909217567407
Validation loss: 3.0866816221537676

Epoch: 6| Step: 3
Training loss: 3.250649167297218
Validation loss: 3.1619372102059513

Epoch: 6| Step: 4
Training loss: 3.301202907378029
Validation loss: 3.022547855181391

Epoch: 6| Step: 5
Training loss: 3.6524573323749228
Validation loss: 3.028111058808646

Epoch: 6| Step: 6
Training loss: 3.50277844908914
Validation loss: 3.036525834410673

Epoch: 6| Step: 7
Training loss: 2.991585374611406
Validation loss: 3.162545494132713

Epoch: 6| Step: 8
Training loss: 3.6479546760453925
Validation loss: 3.260139739519785

Epoch: 6| Step: 9
Training loss: 3.6678639682351277
Validation loss: 3.2475421736792582

Epoch: 6| Step: 10
Training loss: 3.6702551332605062
Validation loss: 3.1641900643890977

Epoch: 6| Step: 11
Training loss: 2.5771571336652257
Validation loss: 3.0553914020131168

Epoch: 6| Step: 12
Training loss: 3.162356672695507
Validation loss: 3.061741420006917

Epoch: 6| Step: 13
Training loss: 4.070351159320368
Validation loss: 3.0577432415958965

Epoch: 42| Step: 0
Training loss: 2.6740826861052156
Validation loss: 3.05774719888564

Epoch: 6| Step: 1
Training loss: 3.434344837726186
Validation loss: 3.1049285243361093

Epoch: 6| Step: 2
Training loss: 3.272733407785464
Validation loss: 3.078911788559966

Epoch: 6| Step: 3
Training loss: 3.0227070401623397
Validation loss: 3.0661888031351783

Epoch: 6| Step: 4
Training loss: 2.9812981687609055
Validation loss: 3.0598951993831203

Epoch: 6| Step: 5
Training loss: 3.346697497536138
Validation loss: 3.0511193569377557

Epoch: 6| Step: 6
Training loss: 3.5764134740550264
Validation loss: 3.0397547586053384

Epoch: 6| Step: 7
Training loss: 3.514502587754212
Validation loss: 3.0206028840137837

Epoch: 6| Step: 8
Training loss: 3.056068361965716
Validation loss: 3.020885493952995

Epoch: 6| Step: 9
Training loss: 4.148389223324321
Validation loss: 3.014650895989674

Epoch: 6| Step: 10
Training loss: 3.553267444717806
Validation loss: 3.009329427092647

Epoch: 6| Step: 11
Training loss: 2.977522087111335
Validation loss: 3.008330201650796

Epoch: 6| Step: 12
Training loss: 3.2607942470200304
Validation loss: 3.0096917173508517

Epoch: 6| Step: 13
Training loss: 3.3846713766721823
Validation loss: 3.0093420683751693

Epoch: 43| Step: 0
Training loss: 3.0284656439349185
Validation loss: 3.022583655463781

Epoch: 6| Step: 1
Training loss: 3.256231642541374
Validation loss: 3.023408935052417

Epoch: 6| Step: 2
Training loss: 2.5485077287550393
Validation loss: 3.0092764130355767

Epoch: 6| Step: 3
Training loss: 3.586914195437991
Validation loss: 3.011026107788948

Epoch: 6| Step: 4
Training loss: 2.9510565078170057
Validation loss: 3.009238860491776

Epoch: 6| Step: 5
Training loss: 3.554244263231615
Validation loss: 3.016735214499763

Epoch: 6| Step: 6
Training loss: 4.365669109364673
Validation loss: 3.023846228668713

Epoch: 6| Step: 7
Training loss: 3.368613523079057
Validation loss: 3.013854377346985

Epoch: 6| Step: 8
Training loss: 3.006183767877879
Validation loss: 3.0080570363923287

Epoch: 6| Step: 9
Training loss: 3.281788373104257
Validation loss: 3.0010582260687144

Epoch: 6| Step: 10
Training loss: 2.6046481691902486
Validation loss: 3.0007387383117794

Epoch: 6| Step: 11
Training loss: 3.678416038543262
Validation loss: 2.997166137726615

Epoch: 6| Step: 12
Training loss: 3.512225054097109
Validation loss: 3.0004151033187396

Epoch: 6| Step: 13
Training loss: 2.475808206244758
Validation loss: 2.996442247310799

Epoch: 44| Step: 0
Training loss: 2.9602053096810477
Validation loss: 2.998626021765905

Epoch: 6| Step: 1
Training loss: 3.5250730249943714
Validation loss: 2.9999770519103555

Epoch: 6| Step: 2
Training loss: 3.0716515647060194
Validation loss: 2.9979605082937457

Epoch: 6| Step: 3
Training loss: 3.2330402070980946
Validation loss: 2.99592337620136

Epoch: 6| Step: 4
Training loss: 3.141768973090389
Validation loss: 2.996526869704242

Epoch: 6| Step: 5
Training loss: 2.728189589532202
Validation loss: 2.9974092795916247

Epoch: 6| Step: 6
Training loss: 3.3453174375437933
Validation loss: 3.0010965694895306

Epoch: 6| Step: 7
Training loss: 3.328261108480761
Validation loss: 3.0081341783871487

Epoch: 6| Step: 8
Training loss: 4.2870679988037494
Validation loss: 3.008856454690346

Epoch: 6| Step: 9
Training loss: 3.729125351206334
Validation loss: 3.0106639253112704

Epoch: 6| Step: 10
Training loss: 3.0268473950453907
Validation loss: 3.00330518342249

Epoch: 6| Step: 11
Training loss: 3.0319548111922474
Validation loss: 2.994693284026024

Epoch: 6| Step: 12
Training loss: 2.7206339830758095
Validation loss: 2.9920523299247916

Epoch: 6| Step: 13
Training loss: 3.5992622891196615
Validation loss: 2.993467734068166

Epoch: 45| Step: 0
Training loss: 3.9785060367459324
Validation loss: 2.9957820489913356

Epoch: 6| Step: 1
Training loss: 3.432761515680219
Validation loss: 2.9916286468717885

Epoch: 6| Step: 2
Training loss: 3.062641529783336
Validation loss: 2.9902982133977276

Epoch: 6| Step: 3
Training loss: 2.761980230532753
Validation loss: 2.9900783183212263

Epoch: 6| Step: 4
Training loss: 3.3240358546649498
Validation loss: 2.98962876320133

Epoch: 6| Step: 5
Training loss: 3.022604184307412
Validation loss: 2.9905339069285737

Epoch: 6| Step: 6
Training loss: 3.270809311181235
Validation loss: 2.9893943112591392

Epoch: 6| Step: 7
Training loss: 3.5501562057299685
Validation loss: 2.9873284486516214

Epoch: 6| Step: 8
Training loss: 3.85175859985065
Validation loss: 2.9888294343160684

Epoch: 6| Step: 9
Training loss: 2.6772273478877047
Validation loss: 2.9850582789565516

Epoch: 6| Step: 10
Training loss: 2.465780669545192
Validation loss: 2.985221111899827

Epoch: 6| Step: 11
Training loss: 3.4737046057119105
Validation loss: 2.9855470722911757

Epoch: 6| Step: 12
Training loss: 3.2396103509264935
Validation loss: 2.9855393355409268

Epoch: 6| Step: 13
Training loss: 3.2691540791073668
Validation loss: 2.9831751772967587

Epoch: 46| Step: 0
Training loss: 4.11758774145661
Validation loss: 2.9860312765415795

Epoch: 6| Step: 1
Training loss: 2.594434073448101
Validation loss: 2.984382561092788

Epoch: 6| Step: 2
Training loss: 3.7555634237679767
Validation loss: 2.981658186851097

Epoch: 6| Step: 3
Training loss: 2.8368809499466
Validation loss: 2.982955944861961

Epoch: 6| Step: 4
Training loss: 2.980293078763756
Validation loss: 2.9837873666653842

Epoch: 6| Step: 5
Training loss: 3.2891155610142455
Validation loss: 2.980470331809532

Epoch: 6| Step: 6
Training loss: 2.9895883132591816
Validation loss: 2.980986740435784

Epoch: 6| Step: 7
Training loss: 3.0601632681779045
Validation loss: 2.979943173753058

Epoch: 6| Step: 8
Training loss: 3.7382567593241656
Validation loss: 2.9804021859370127

Epoch: 6| Step: 9
Training loss: 2.3150767842158464
Validation loss: 2.980525716977651

Epoch: 6| Step: 10
Training loss: 3.927226636516593
Validation loss: 2.9819993546226886

Epoch: 6| Step: 11
Training loss: 3.2756673642501277
Validation loss: 2.9804680567216044

Epoch: 6| Step: 12
Training loss: 2.6551164789026727
Validation loss: 2.9828648009604

Epoch: 6| Step: 13
Training loss: 3.707124120033346
Validation loss: 2.98475248233076

Epoch: 47| Step: 0
Training loss: 2.7658775774604587
Validation loss: 2.988024345677486

Epoch: 6| Step: 1
Training loss: 3.7573361164224397
Validation loss: 2.9763268026018985

Epoch: 6| Step: 2
Training loss: 3.046879695008402
Validation loss: 2.9728476827471604

Epoch: 6| Step: 3
Training loss: 3.2530415314474954
Validation loss: 2.9711597034561694

Epoch: 6| Step: 4
Training loss: 3.6006215618576007
Validation loss: 2.970696169418495

Epoch: 6| Step: 5
Training loss: 3.1792621749857184
Validation loss: 2.971366217451825

Epoch: 6| Step: 6
Training loss: 3.2824337231931677
Validation loss: 2.9703938499564946

Epoch: 6| Step: 7
Training loss: 2.2896550684189148
Validation loss: 2.971819560889486

Epoch: 6| Step: 8
Training loss: 3.8602980772366773
Validation loss: 2.967849669188575

Epoch: 6| Step: 9
Training loss: 3.0117493070049224
Validation loss: 2.9663552435910145

Epoch: 6| Step: 10
Training loss: 3.3512918856549105
Validation loss: 2.968186995742334

Epoch: 6| Step: 11
Training loss: 3.2888560468162313
Validation loss: 2.9723636250911865

Epoch: 6| Step: 12
Training loss: 3.3467080410328687
Validation loss: 2.9716498969130343

Epoch: 6| Step: 13
Training loss: 3.0939890451268157
Validation loss: 2.9790402173388575

Epoch: 48| Step: 0
Training loss: 3.829732378381922
Validation loss: 2.9730234748687248

Epoch: 6| Step: 1
Training loss: 3.0709890925649397
Validation loss: 2.9779710189657727

Epoch: 6| Step: 2
Training loss: 3.5080373305419066
Validation loss: 2.976551103579522

Epoch: 6| Step: 3
Training loss: 2.8257086109868657
Validation loss: 2.9786340426839164

Epoch: 6| Step: 4
Training loss: 3.730754294127317
Validation loss: 2.971025668321241

Epoch: 6| Step: 5
Training loss: 3.042166647033853
Validation loss: 2.9635216173972005

Epoch: 6| Step: 6
Training loss: 3.0608690551146736
Validation loss: 2.963690138632372

Epoch: 6| Step: 7
Training loss: 3.4832989181448974
Validation loss: 2.961587214943737

Epoch: 6| Step: 8
Training loss: 2.806728205047738
Validation loss: 2.96043377988148

Epoch: 6| Step: 9
Training loss: 2.8578303599855395
Validation loss: 2.961187046682724

Epoch: 6| Step: 10
Training loss: 2.9025839376346463
Validation loss: 2.9613891780010664

Epoch: 6| Step: 11
Training loss: 3.902637245360126
Validation loss: 2.961086891841406

Epoch: 6| Step: 12
Training loss: 2.8752149418633146
Validation loss: 2.9588044233580697

Epoch: 6| Step: 13
Training loss: 3.180490753165184
Validation loss: 2.9594746135392787

Epoch: 49| Step: 0
Training loss: 2.623267283094864
Validation loss: 2.959354583704114

Epoch: 6| Step: 1
Training loss: 2.695006068405085
Validation loss: 2.95778625007556

Epoch: 6| Step: 2
Training loss: 3.88622356691693
Validation loss: 2.9574513623448055

Epoch: 6| Step: 3
Training loss: 3.991849463198834
Validation loss: 2.9550480143603695

Epoch: 6| Step: 4
Training loss: 2.8532916953117775
Validation loss: 2.9525588817312864

Epoch: 6| Step: 5
Training loss: 3.0114726993970686
Validation loss: 2.951340373487199

Epoch: 6| Step: 6
Training loss: 3.7815493630689456
Validation loss: 2.950058903148671

Epoch: 6| Step: 7
Training loss: 2.9098554007663577
Validation loss: 2.9522054108248157

Epoch: 6| Step: 8
Training loss: 3.3745082920892204
Validation loss: 2.9536241599018997

Epoch: 6| Step: 9
Training loss: 3.373403242113063
Validation loss: 2.957490768682419

Epoch: 6| Step: 10
Training loss: 3.7359580032634785
Validation loss: 2.9611681334998368

Epoch: 6| Step: 11
Training loss: 2.9739668133954917
Validation loss: 2.9511463216325193

Epoch: 6| Step: 12
Training loss: 2.917774771047791
Validation loss: 2.948568785875051

Epoch: 6| Step: 13
Training loss: 2.322459040384285
Validation loss: 2.948033557955582

Epoch: 50| Step: 0
Training loss: 3.710040496029354
Validation loss: 2.9476042356950307

Epoch: 6| Step: 1
Training loss: 2.9796610246431294
Validation loss: 2.950077121957761

Epoch: 6| Step: 2
Training loss: 3.7707135653926733
Validation loss: 2.9466305755860898

Epoch: 6| Step: 3
Training loss: 2.9494088825301343
Validation loss: 2.9426404719577843

Epoch: 6| Step: 4
Training loss: 2.7455584464200977
Validation loss: 2.9434457360120527

Epoch: 6| Step: 5
Training loss: 2.462220841283828
Validation loss: 2.9436632220784706

Epoch: 6| Step: 6
Training loss: 3.454245545177261
Validation loss: 2.945254505498587

Epoch: 6| Step: 7
Training loss: 3.1390796104561045
Validation loss: 2.9426067892695813

Epoch: 6| Step: 8
Training loss: 3.866193177292499
Validation loss: 2.9402535195866046

Epoch: 6| Step: 9
Training loss: 3.0498611293508424
Validation loss: 2.9391695321241675

Epoch: 6| Step: 10
Training loss: 2.492155738556426
Validation loss: 2.9396328964154583

Epoch: 6| Step: 11
Training loss: 3.2506554749535828
Validation loss: 2.940718213398459

Epoch: 6| Step: 12
Training loss: 3.530010579771446
Validation loss: 2.941294579752388

Epoch: 6| Step: 13
Training loss: 3.471377915198366
Validation loss: 2.938703618110294

Epoch: 51| Step: 0
Training loss: 3.541207242600521
Validation loss: 2.9380079226067615

Epoch: 6| Step: 1
Training loss: 2.9135815425503937
Validation loss: 2.939741171183052

Epoch: 6| Step: 2
Training loss: 3.1571357919309406
Validation loss: 2.93700333522144

Epoch: 6| Step: 3
Training loss: 3.5947353173283774
Validation loss: 2.9406625100220753

Epoch: 6| Step: 4
Training loss: 3.7936760884206997
Validation loss: 2.9450383103730604

Epoch: 6| Step: 5
Training loss: 3.0924807940960646
Validation loss: 2.9329029785792695

Epoch: 6| Step: 6
Training loss: 2.5562956528445997
Validation loss: 2.936082391867524

Epoch: 6| Step: 7
Training loss: 2.4906617280365193
Validation loss: 2.93464027566949

Epoch: 6| Step: 8
Training loss: 3.299347009498533
Validation loss: 2.9351528235842728

Epoch: 6| Step: 9
Training loss: 3.302128226920688
Validation loss: 2.9356773908060916

Epoch: 6| Step: 10
Training loss: 2.9896573756460594
Validation loss: 2.9410026419482396

Epoch: 6| Step: 11
Training loss: 3.18439167531208
Validation loss: 2.9469877233379225

Epoch: 6| Step: 12
Training loss: 3.3673085768454274
Validation loss: 2.935734277718932

Epoch: 6| Step: 13
Training loss: 3.7820796844463698
Validation loss: 2.932641056063328

Epoch: 52| Step: 0
Training loss: 2.595370510309638
Validation loss: 2.933348179024058

Epoch: 6| Step: 1
Training loss: 3.0137174433528338
Validation loss: 2.934343899841597

Epoch: 6| Step: 2
Training loss: 3.1796023195746557
Validation loss: 2.9364607610539952

Epoch: 6| Step: 3
Training loss: 3.0198584375612967
Validation loss: 2.9568240469337375

Epoch: 6| Step: 4
Training loss: 3.3013032940538887
Validation loss: 2.9823370466554526

Epoch: 6| Step: 5
Training loss: 3.570555830996169
Validation loss: 2.985016246939766

Epoch: 6| Step: 6
Training loss: 3.8376213775227015
Validation loss: 2.946288724891367

Epoch: 6| Step: 7
Training loss: 2.6875707927517456
Validation loss: 2.9335681239137896

Epoch: 6| Step: 8
Training loss: 3.311271295648212
Validation loss: 2.9296043790011783

Epoch: 6| Step: 9
Training loss: 3.4713946733832435
Validation loss: 2.9274319379226417

Epoch: 6| Step: 10
Training loss: 3.3713204847979465
Validation loss: 2.9292347565439782

Epoch: 6| Step: 11
Training loss: 3.241201374882323
Validation loss: 2.9275160506025566

Epoch: 6| Step: 12
Training loss: 3.39182495822547
Validation loss: 2.925038429430609

Epoch: 6| Step: 13
Training loss: 2.5718603604202497
Validation loss: 2.9258698840030144

Epoch: 53| Step: 0
Training loss: 3.6455712505781577
Validation loss: 2.925065068034015

Epoch: 6| Step: 1
Training loss: 3.157413079521957
Validation loss: 2.9251359456607315

Epoch: 6| Step: 2
Training loss: 2.9972071363155663
Validation loss: 2.926654974532189

Epoch: 6| Step: 3
Training loss: 3.218505553805668
Validation loss: 2.9281902396012156

Epoch: 6| Step: 4
Training loss: 3.490069060421124
Validation loss: 2.929122166276687

Epoch: 6| Step: 5
Training loss: 3.1131051084307604
Validation loss: 2.927477637547833

Epoch: 6| Step: 6
Training loss: 2.5143333578395053
Validation loss: 2.923632695139958

Epoch: 6| Step: 7
Training loss: 3.308145648107011
Validation loss: 2.921422116401045

Epoch: 6| Step: 8
Training loss: 2.7864543784045144
Validation loss: 2.9203536103473358

Epoch: 6| Step: 9
Training loss: 3.3679808635666375
Validation loss: 2.91894251957987

Epoch: 6| Step: 10
Training loss: 3.659899593706191
Validation loss: 2.9173537545204904

Epoch: 6| Step: 11
Training loss: 2.973086432510946
Validation loss: 2.9165697623707296

Epoch: 6| Step: 12
Training loss: 2.9216515766747135
Validation loss: 2.916533718214047

Epoch: 6| Step: 13
Training loss: 3.825021287447466
Validation loss: 2.9176604486715476

Epoch: 54| Step: 0
Training loss: 3.2772628537766297
Validation loss: 2.9163412595251703

Epoch: 6| Step: 1
Training loss: 3.428823583844526
Validation loss: 2.9182480104089885

Epoch: 6| Step: 2
Training loss: 2.686636408958088
Validation loss: 2.921408296998505

Epoch: 6| Step: 3
Training loss: 3.23664739273676
Validation loss: 2.924675152092701

Epoch: 6| Step: 4
Training loss: 3.14988277762147
Validation loss: 2.9291372516141028

Epoch: 6| Step: 5
Training loss: 3.2695207493110945
Validation loss: 2.9229751769689156

Epoch: 6| Step: 6
Training loss: 2.8665097134523885
Validation loss: 2.9233282551909765

Epoch: 6| Step: 7
Training loss: 3.233838317868301
Validation loss: 2.9202761791911893

Epoch: 6| Step: 8
Training loss: 3.7428990844281893
Validation loss: 2.9138836558209316

Epoch: 6| Step: 9
Training loss: 3.419330086040932
Validation loss: 2.911003594300987

Epoch: 6| Step: 10
Training loss: 3.3687117593891407
Validation loss: 2.9112092575159783

Epoch: 6| Step: 11
Training loss: 2.7527711084436675
Validation loss: 2.9100181611245715

Epoch: 6| Step: 12
Training loss: 3.2065677656385687
Validation loss: 2.9109263565420607

Epoch: 6| Step: 13
Training loss: 2.9598768443184786
Validation loss: 2.910789662297798

Epoch: 55| Step: 0
Training loss: 3.495371892132029
Validation loss: 2.91141320146139

Epoch: 6| Step: 1
Training loss: 2.9981222634047535
Validation loss: 2.917678037696884

Epoch: 6| Step: 2
Training loss: 3.3479379826935136
Validation loss: 2.9170150730396185

Epoch: 6| Step: 3
Training loss: 3.9092271369762694
Validation loss: 2.92265773570016

Epoch: 6| Step: 4
Training loss: 3.0726069062570334
Validation loss: 2.9075966461887073

Epoch: 6| Step: 5
Training loss: 3.0527899816992456
Validation loss: 2.906509165566033

Epoch: 6| Step: 6
Training loss: 3.1172240596912295
Validation loss: 2.9046749752102774

Epoch: 6| Step: 7
Training loss: 3.2900670345631173
Validation loss: 2.9050059104146113

Epoch: 6| Step: 8
Training loss: 2.817278892147552
Validation loss: 2.904326193053201

Epoch: 6| Step: 9
Training loss: 2.8492137694465653
Validation loss: 2.9022732882926574

Epoch: 6| Step: 10
Training loss: 2.881303924916505
Validation loss: 2.9031901637661566

Epoch: 6| Step: 11
Training loss: 3.1579407044461507
Validation loss: 2.9040048849695332

Epoch: 6| Step: 12
Training loss: 3.663562992754442
Validation loss: 2.906181217314257

Epoch: 6| Step: 13
Training loss: 2.6380354242903548
Validation loss: 2.9059688517248845

Epoch: 56| Step: 0
Training loss: 3.0273024820775944
Validation loss: 2.9005586945235455

Epoch: 6| Step: 1
Training loss: 3.4888769241365423
Validation loss: 2.9011614504451093

Epoch: 6| Step: 2
Training loss: 3.4172474127228103
Validation loss: 2.90137635392542

Epoch: 6| Step: 3
Training loss: 2.908051291473858
Validation loss: 2.8972378232507814

Epoch: 6| Step: 4
Training loss: 3.6466222000432995
Validation loss: 2.8952207793136933

Epoch: 6| Step: 5
Training loss: 3.0551108142590087
Validation loss: 2.8971503848050646

Epoch: 6| Step: 6
Training loss: 3.968492033977475
Validation loss: 2.8965994800460413

Epoch: 6| Step: 7
Training loss: 3.2615007704576433
Validation loss: 2.895284766447604

Epoch: 6| Step: 8
Training loss: 3.441086164260954
Validation loss: 2.89559331999836

Epoch: 6| Step: 9
Training loss: 1.812129410314104
Validation loss: 2.89406492626821

Epoch: 6| Step: 10
Training loss: 2.79417425428984
Validation loss: 2.8935625780549867

Epoch: 6| Step: 11
Training loss: 2.7139217430251015
Validation loss: 2.8929258706147105

Epoch: 6| Step: 12
Training loss: 2.8875016117504293
Validation loss: 2.8923194360060767

Epoch: 6| Step: 13
Training loss: 3.9476400931046767
Validation loss: 2.89238907304651

Epoch: 57| Step: 0
Training loss: 3.83719193405565
Validation loss: 2.891255617184459

Epoch: 6| Step: 1
Training loss: 3.038639303911358
Validation loss: 2.8909401014307923

Epoch: 6| Step: 2
Training loss: 3.760880389728869
Validation loss: 2.89064921796033

Epoch: 6| Step: 3
Training loss: 2.6816527164239417
Validation loss: 2.8894136834712696

Epoch: 6| Step: 4
Training loss: 2.2626976306230033
Validation loss: 2.8881639819253033

Epoch: 6| Step: 5
Training loss: 3.1280531654912993
Validation loss: 2.8871759210878

Epoch: 6| Step: 6
Training loss: 3.4121736587032667
Validation loss: 2.887445993339683

Epoch: 6| Step: 7
Training loss: 1.9421547995136865
Validation loss: 2.886476400230622

Epoch: 6| Step: 8
Training loss: 3.227922573186781
Validation loss: 2.8855468106412707

Epoch: 6| Step: 9
Training loss: 3.7295134115002266
Validation loss: 2.8836618817288544

Epoch: 6| Step: 10
Training loss: 2.9918394359405753
Validation loss: 2.8840462090442402

Epoch: 6| Step: 11
Training loss: 3.4550350654467743
Validation loss: 2.8826712043391405

Epoch: 6| Step: 12
Training loss: 3.5889866317283223
Validation loss: 2.8839537704205807

Epoch: 6| Step: 13
Training loss: 2.369073399834566
Validation loss: 2.885475657119093

Epoch: 58| Step: 0
Training loss: 3.023331830053436
Validation loss: 2.8855707895880003

Epoch: 6| Step: 1
Training loss: 3.264224395462215
Validation loss: 2.8880440774573604

Epoch: 6| Step: 2
Training loss: 3.5578927481291425
Validation loss: 2.9000998796993582

Epoch: 6| Step: 3
Training loss: 3.063847148200148
Validation loss: 2.8995154457947643

Epoch: 6| Step: 4
Training loss: 3.0090507039456837
Validation loss: 2.8842129484197927

Epoch: 6| Step: 5
Training loss: 2.56522921856042
Validation loss: 2.880482422486205

Epoch: 6| Step: 6
Training loss: 3.4766224373783414
Validation loss: 2.879986050344396

Epoch: 6| Step: 7
Training loss: 3.4693781653382754
Validation loss: 2.878998982477427

Epoch: 6| Step: 8
Training loss: 3.8524872016075284
Validation loss: 2.879695756305364

Epoch: 6| Step: 9
Training loss: 3.171567855020066
Validation loss: 2.8747998088104336

Epoch: 6| Step: 10
Training loss: 3.243626874817686
Validation loss: 2.8744846477758443

Epoch: 6| Step: 11
Training loss: 2.7848588482410497
Validation loss: 2.87490991181076

Epoch: 6| Step: 12
Training loss: 2.440761633649407
Validation loss: 2.87454879059224

Epoch: 6| Step: 13
Training loss: 3.2478909618509735
Validation loss: 2.8741169411987797

Epoch: 59| Step: 0
Training loss: 3.2441664941021564
Validation loss: 2.87314052201488

Epoch: 6| Step: 1
Training loss: 3.406768759325558
Validation loss: 2.873507216921647

Epoch: 6| Step: 2
Training loss: 3.6164676617368876
Validation loss: 2.87324356134533

Epoch: 6| Step: 3
Training loss: 3.379574254325969
Validation loss: 2.8763147052655498

Epoch: 6| Step: 4
Training loss: 3.847670377908707
Validation loss: 2.872232959412772

Epoch: 6| Step: 5
Training loss: 2.6752747439177784
Validation loss: 2.871605119333518

Epoch: 6| Step: 6
Training loss: 3.518473916207941
Validation loss: 2.872619416414886

Epoch: 6| Step: 7
Training loss: 3.3843314128404263
Validation loss: 2.873346592519678

Epoch: 6| Step: 8
Training loss: 2.4018119409459207
Validation loss: 2.8712401770662197

Epoch: 6| Step: 9
Training loss: 2.5788228333210403
Validation loss: 2.875775587947051

Epoch: 6| Step: 10
Training loss: 3.1986129615709507
Validation loss: 2.8832371945784145

Epoch: 6| Step: 11
Training loss: 2.9142190926948253
Validation loss: 2.881970916546078

Epoch: 6| Step: 12
Training loss: 2.61466398279395
Validation loss: 2.8781219178487305

Epoch: 6| Step: 13
Training loss: 3.0837431626694443
Validation loss: 2.8655851489854345

Epoch: 60| Step: 0
Training loss: 2.7132270225424358
Validation loss: 2.863983144819324

Epoch: 6| Step: 1
Training loss: 2.914182604239908
Validation loss: 2.8642893904209137

Epoch: 6| Step: 2
Training loss: 2.7037657050083586
Validation loss: 2.862258731016897

Epoch: 6| Step: 3
Training loss: 3.032059708825151
Validation loss: 2.863550225761589

Epoch: 6| Step: 4
Training loss: 3.857058675543699
Validation loss: 2.861366326763291

Epoch: 6| Step: 5
Training loss: 3.438825594460442
Validation loss: 2.86086084815338

Epoch: 6| Step: 6
Training loss: 2.6378413770414872
Validation loss: 2.8627351970085257

Epoch: 6| Step: 7
Training loss: 2.8675590087353218
Validation loss: 2.860442724017279

Epoch: 6| Step: 8
Training loss: 4.20927959920254
Validation loss: 2.861129791610823

Epoch: 6| Step: 9
Training loss: 3.737229664699699
Validation loss: 2.860365954730066

Epoch: 6| Step: 10
Training loss: 3.6466012781709503
Validation loss: 2.8610428275869126

Epoch: 6| Step: 11
Training loss: 2.23821861618845
Validation loss: 2.859910629351049

Epoch: 6| Step: 12
Training loss: 2.8829825333070467
Validation loss: 2.8614675350484666

Epoch: 6| Step: 13
Training loss: 2.169250219521155
Validation loss: 2.8589138603027218

Epoch: 61| Step: 0
Training loss: 3.1015832549585003
Validation loss: 2.85887376056851

Epoch: 6| Step: 1
Training loss: 3.409437455567668
Validation loss: 2.858057687063699

Epoch: 6| Step: 2
Training loss: 3.284717435253079
Validation loss: 2.8560833098562024

Epoch: 6| Step: 3
Training loss: 2.798996786504811
Validation loss: 2.857763830671488

Epoch: 6| Step: 4
Training loss: 2.897202056232646
Validation loss: 2.854915592195864

Epoch: 6| Step: 5
Training loss: 3.4299302417123143
Validation loss: 2.8541866089516614

Epoch: 6| Step: 6
Training loss: 2.9996158035950615
Validation loss: 2.854332195057226

Epoch: 6| Step: 7
Training loss: 3.9552608946967314
Validation loss: 2.8539654815261817

Epoch: 6| Step: 8
Training loss: 3.515286984618541
Validation loss: 2.852755729042458

Epoch: 6| Step: 9
Training loss: 2.1833444633879657
Validation loss: 2.851531329555631

Epoch: 6| Step: 10
Training loss: 3.4853886382957264
Validation loss: 2.8507618183308066

Epoch: 6| Step: 11
Training loss: 2.7278035572057058
Validation loss: 2.8496195805697693

Epoch: 6| Step: 12
Training loss: 2.9556068607966757
Validation loss: 2.8503332986257246

Epoch: 6| Step: 13
Training loss: 2.8451754173007333
Validation loss: 2.8520617506648986

Epoch: 62| Step: 0
Training loss: 2.991162953877704
Validation loss: 2.849298684992702

Epoch: 6| Step: 1
Training loss: 3.289307211428015
Validation loss: 2.8579341764587816

Epoch: 6| Step: 2
Training loss: 3.4246306449931887
Validation loss: 2.852033006366729

Epoch: 6| Step: 3
Training loss: 3.1308939474366126
Validation loss: 2.8516071544774504

Epoch: 6| Step: 4
Training loss: 3.1116324812883027
Validation loss: 2.8491185531621053

Epoch: 6| Step: 5
Training loss: 3.1131381931726128
Validation loss: 2.848036482361789

Epoch: 6| Step: 6
Training loss: 3.495729020342823
Validation loss: 2.846079621617677

Epoch: 6| Step: 7
Training loss: 3.362396017402507
Validation loss: 2.8462037565375566

Epoch: 6| Step: 8
Training loss: 3.2422883902788944
Validation loss: 2.8455810403572426

Epoch: 6| Step: 9
Training loss: 3.1749709480938932
Validation loss: 2.8469259401226465

Epoch: 6| Step: 10
Training loss: 2.685439806104295
Validation loss: 2.84577301270871

Epoch: 6| Step: 11
Training loss: 2.9397428350795187
Validation loss: 2.846751215450224

Epoch: 6| Step: 12
Training loss: 3.0270230424884215
Validation loss: 2.845693209883507

Epoch: 6| Step: 13
Training loss: 2.888261643400706
Validation loss: 2.846301160836588

Epoch: 63| Step: 0
Training loss: 1.6507240094119378
Validation loss: 2.8498526307860432

Epoch: 6| Step: 1
Training loss: 2.7816185010606893
Validation loss: 2.847472966682625

Epoch: 6| Step: 2
Training loss: 3.2455487212604273
Validation loss: 2.845902987499319

Epoch: 6| Step: 3
Training loss: 3.5277230533016475
Validation loss: 2.8461940521334954

Epoch: 6| Step: 4
Training loss: 3.5703376084661427
Validation loss: 2.8450096457041574

Epoch: 6| Step: 5
Training loss: 3.6541402875991333
Validation loss: 2.84405684503173

Epoch: 6| Step: 6
Training loss: 3.359697335326139
Validation loss: 2.8443856712634306

Epoch: 6| Step: 7
Training loss: 3.588908774206332
Validation loss: 2.843599373390218

Epoch: 6| Step: 8
Training loss: 2.7928748481810888
Validation loss: 2.841789531737039

Epoch: 6| Step: 9
Training loss: 2.9989119781978455
Validation loss: 2.840180218289378

Epoch: 6| Step: 10
Training loss: 3.1134282822871175
Validation loss: 2.8389885837988116

Epoch: 6| Step: 11
Training loss: 3.10282169023717
Validation loss: 2.8388144849794577

Epoch: 6| Step: 12
Training loss: 3.0581341199584915
Validation loss: 2.8371692372352073

Epoch: 6| Step: 13
Training loss: 3.0025042572118354
Validation loss: 2.8360164012920355

Epoch: 64| Step: 0
Training loss: 3.5447079932894936
Validation loss: 2.8359816529211486

Epoch: 6| Step: 1
Training loss: 3.199659305555962
Validation loss: 2.8347295036228495

Epoch: 6| Step: 2
Training loss: 2.8751784559509437
Validation loss: 2.8342034947847523

Epoch: 6| Step: 3
Training loss: 3.104106791556739
Validation loss: 2.832539442362108

Epoch: 6| Step: 4
Training loss: 3.1404728639107775
Validation loss: 2.8330829504903474

Epoch: 6| Step: 5
Training loss: 3.1250067138599755
Validation loss: 2.831916165727471

Epoch: 6| Step: 6
Training loss: 2.637444832753681
Validation loss: 2.8332377447209685

Epoch: 6| Step: 7
Training loss: 3.7052361631094533
Validation loss: 2.82865911505234

Epoch: 6| Step: 8
Training loss: 3.620346502507429
Validation loss: 2.830196264153227

Epoch: 6| Step: 9
Training loss: 2.920137266041933
Validation loss: 2.8290606686656163

Epoch: 6| Step: 10
Training loss: 2.9379999262924654
Validation loss: 2.8302973388735655

Epoch: 6| Step: 11
Training loss: 3.322622702738886
Validation loss: 2.8305400498389726

Epoch: 6| Step: 12
Training loss: 2.321097501265744
Validation loss: 2.8274756713713

Epoch: 6| Step: 13
Training loss: 3.232222720923075
Validation loss: 2.8296101895216967

Epoch: 65| Step: 0
Training loss: 2.7805651560933207
Validation loss: 2.828027696691348

Epoch: 6| Step: 1
Training loss: 3.1507175415468978
Validation loss: 2.826774236067831

Epoch: 6| Step: 2
Training loss: 3.5009350208919634
Validation loss: 2.824588123838304

Epoch: 6| Step: 3
Training loss: 3.0941534838886633
Validation loss: 2.825171640517697

Epoch: 6| Step: 4
Training loss: 2.5809705347435874
Validation loss: 2.824600021747959

Epoch: 6| Step: 5
Training loss: 3.672693818692794
Validation loss: 2.8289123519684525

Epoch: 6| Step: 6
Training loss: 2.8594295308901154
Validation loss: 2.8355431925114476

Epoch: 6| Step: 7
Training loss: 3.147613190304102
Validation loss: 2.8393652981023925

Epoch: 6| Step: 8
Training loss: 3.225219447040369
Validation loss: 2.838572678401748

Epoch: 6| Step: 9
Training loss: 2.942698160789709
Validation loss: 2.8319305467646716

Epoch: 6| Step: 10
Training loss: 3.0672470980901076
Validation loss: 2.8230701978886494

Epoch: 6| Step: 11
Training loss: 2.850183273579642
Validation loss: 2.8230564310022195

Epoch: 6| Step: 12
Training loss: 3.5834393744340285
Validation loss: 2.8207821514476223

Epoch: 6| Step: 13
Training loss: 3.3067904515579962
Validation loss: 2.8213538985888778

Epoch: 66| Step: 0
Training loss: 3.1835622961444647
Validation loss: 2.821887153949355

Epoch: 6| Step: 1
Training loss: 3.0201071206098793
Validation loss: 2.8230381489091574

Epoch: 6| Step: 2
Training loss: 2.5152604686025164
Validation loss: 2.8225373921984387

Epoch: 6| Step: 3
Training loss: 3.5092137178231817
Validation loss: 2.822432678844573

Epoch: 6| Step: 4
Training loss: 2.9738282789307724
Validation loss: 2.8217619220382275

Epoch: 6| Step: 5
Training loss: 3.1877943912766216
Validation loss: 2.821826757255926

Epoch: 6| Step: 6
Training loss: 2.818065308094984
Validation loss: 2.8229557381715464

Epoch: 6| Step: 7
Training loss: 3.6613876893059776
Validation loss: 2.820662438274212

Epoch: 6| Step: 8
Training loss: 2.859433533116316
Validation loss: 2.8184974903826228

Epoch: 6| Step: 9
Training loss: 2.772588723554301
Validation loss: 2.8188492127973097

Epoch: 6| Step: 10
Training loss: 2.7806531287099783
Validation loss: 2.817504805101566

Epoch: 6| Step: 11
Training loss: 3.9400225839112846
Validation loss: 2.8166842364759384

Epoch: 6| Step: 12
Training loss: 3.3692651697994664
Validation loss: 2.817134046602268

Epoch: 6| Step: 13
Training loss: 2.7125033822456053
Validation loss: 2.8163106190765417

Epoch: 67| Step: 0
Training loss: 2.6175136078314125
Validation loss: 2.8154656201115054

Epoch: 6| Step: 1
Training loss: 2.9462013421230457
Validation loss: 2.8131894067683345

Epoch: 6| Step: 2
Training loss: 3.934912785262783
Validation loss: 2.8129877294224053

Epoch: 6| Step: 3
Training loss: 3.456983938809383
Validation loss: 2.8128351301288257

Epoch: 6| Step: 4
Training loss: 2.5023016824559687
Validation loss: 2.811630668872398

Epoch: 6| Step: 5
Training loss: 2.728284931192394
Validation loss: 2.811934243089848

Epoch: 6| Step: 6
Training loss: 2.791255313306194
Validation loss: 2.8090432557952227

Epoch: 6| Step: 7
Training loss: 3.12747338641192
Validation loss: 2.809221414493893

Epoch: 6| Step: 8
Training loss: 2.9382602438344443
Validation loss: 2.808012854161954

Epoch: 6| Step: 9
Training loss: 3.445230426805531
Validation loss: 2.8074066931816954

Epoch: 6| Step: 10
Training loss: 2.9616356985190104
Validation loss: 2.807725154247121

Epoch: 6| Step: 11
Training loss: 3.36924026120788
Validation loss: 2.8068635745686663

Epoch: 6| Step: 12
Training loss: 3.4163324766395884
Validation loss: 2.803632145691957

Epoch: 6| Step: 13
Training loss: 3.0465195668586214
Validation loss: 2.8051745808465465

Epoch: 68| Step: 0
Training loss: 3.0590498816771308
Validation loss: 2.810137326248103

Epoch: 6| Step: 1
Training loss: 2.6711253402818995
Validation loss: 2.8231252066455235

Epoch: 6| Step: 2
Training loss: 3.0175692758769923
Validation loss: 2.834976934431136

Epoch: 6| Step: 3
Training loss: 4.162195986164766
Validation loss: 2.8442365412024824

Epoch: 6| Step: 4
Training loss: 3.355378652657545
Validation loss: 2.8438405812777394

Epoch: 6| Step: 5
Training loss: 2.7993415739563945
Validation loss: 2.811956888716605

Epoch: 6| Step: 6
Training loss: 3.317206152613302
Validation loss: 2.8017590367851275

Epoch: 6| Step: 7
Training loss: 3.5196865102581456
Validation loss: 2.801011177087754

Epoch: 6| Step: 8
Training loss: 3.310730947592787
Validation loss: 2.803420241992591

Epoch: 6| Step: 9
Training loss: 2.8115128374181473
Validation loss: 2.807527755960829

Epoch: 6| Step: 10
Training loss: 2.6373326469950205
Validation loss: 2.8115712135105686

Epoch: 6| Step: 11
Training loss: 2.9928454280849004
Validation loss: 2.8140936544206894

Epoch: 6| Step: 12
Training loss: 3.0212113417968225
Validation loss: 2.8047096913568343

Epoch: 6| Step: 13
Training loss: 2.306673700546095
Validation loss: 2.804218542900317

Epoch: 69| Step: 0
Training loss: 3.3185869827032675
Validation loss: 2.8014806207575895

Epoch: 6| Step: 1
Training loss: 2.7414506318877305
Validation loss: 2.8008349574202724

Epoch: 6| Step: 2
Training loss: 2.638153183313647
Validation loss: 2.7986132486734325

Epoch: 6| Step: 3
Training loss: 3.449873277852354
Validation loss: 2.797410605815128

Epoch: 6| Step: 4
Training loss: 3.4617699855421207
Validation loss: 2.7978204433196145

Epoch: 6| Step: 5
Training loss: 3.4341103227031153
Validation loss: 2.796461982179543

Epoch: 6| Step: 6
Training loss: 3.412764872237927
Validation loss: 2.7965868234677758

Epoch: 6| Step: 7
Training loss: 2.3228005578370343
Validation loss: 2.7927190578241756

Epoch: 6| Step: 8
Training loss: 2.860979140940643
Validation loss: 2.794182206206846

Epoch: 6| Step: 9
Training loss: 2.5221000410260017
Validation loss: 2.795124865945377

Epoch: 6| Step: 10
Training loss: 2.805408778196283
Validation loss: 2.793487008296108

Epoch: 6| Step: 11
Training loss: 3.585369389229869
Validation loss: 2.7967515997154937

Epoch: 6| Step: 12
Training loss: 3.317411991380727
Validation loss: 2.799544401942161

Epoch: 6| Step: 13
Training loss: 3.3370788194163277
Validation loss: 2.806281018797704

Epoch: 70| Step: 0
Training loss: 3.1593549205168365
Validation loss: 2.847305248086096

Epoch: 6| Step: 1
Training loss: 3.6454530063436508
Validation loss: 2.829781861366436

Epoch: 6| Step: 2
Training loss: 3.5627200410046496
Validation loss: 2.7960968575839984

Epoch: 6| Step: 3
Training loss: 3.3114350244390334
Validation loss: 2.7910467768811125

Epoch: 6| Step: 4
Training loss: 3.2008048237553304
Validation loss: 2.787543823002188

Epoch: 6| Step: 5
Training loss: 3.291101688878374
Validation loss: 2.7884196384502795

Epoch: 6| Step: 6
Training loss: 2.511139561155326
Validation loss: 2.789685924272378

Epoch: 6| Step: 7
Training loss: 2.9499669218633437
Validation loss: 2.7895640219355777

Epoch: 6| Step: 8
Training loss: 3.010563689516914
Validation loss: 2.790044430444265

Epoch: 6| Step: 9
Training loss: 2.802767805903624
Validation loss: 2.7898780450987815

Epoch: 6| Step: 10
Training loss: 2.68002824312957
Validation loss: 2.790366061904005

Epoch: 6| Step: 11
Training loss: 3.0597289647263612
Validation loss: 2.791738962539208

Epoch: 6| Step: 12
Training loss: 2.525294515222104
Validation loss: 2.792513943916994

Epoch: 6| Step: 13
Training loss: 3.896703667074793
Validation loss: 2.7926325760866524

Epoch: 71| Step: 0
Training loss: 3.843126944310194
Validation loss: 2.7890990452980158

Epoch: 6| Step: 1
Training loss: 3.2894753674954575
Validation loss: 2.787189880216067

Epoch: 6| Step: 2
Training loss: 2.757523475609297
Validation loss: 2.7858470455923974

Epoch: 6| Step: 3
Training loss: 3.273093412609988
Validation loss: 2.7855429715185824

Epoch: 6| Step: 4
Training loss: 3.0297608798005053
Validation loss: 2.783546927085978

Epoch: 6| Step: 5
Training loss: 3.3227352144611104
Validation loss: 2.781663010208968

Epoch: 6| Step: 6
Training loss: 3.198276777007611
Validation loss: 2.782052030806913

Epoch: 6| Step: 7
Training loss: 3.320295553725137
Validation loss: 2.7820999010193033

Epoch: 6| Step: 8
Training loss: 2.909523545682079
Validation loss: 2.780347692709691

Epoch: 6| Step: 9
Training loss: 3.3953918138799803
Validation loss: 2.777044195160274

Epoch: 6| Step: 10
Training loss: 2.6561918364495973
Validation loss: 2.780369997192828

Epoch: 6| Step: 11
Training loss: 2.41066020723268
Validation loss: 2.77980655084889

Epoch: 6| Step: 12
Training loss: 2.980129877626882
Validation loss: 2.7826028694905904

Epoch: 6| Step: 13
Training loss: 2.3841720954684766
Validation loss: 2.781819977287922

Epoch: 72| Step: 0
Training loss: 3.6219751299757825
Validation loss: 2.786548456101802

Epoch: 6| Step: 1
Training loss: 3.3160372866937373
Validation loss: 2.7892906026979825

Epoch: 6| Step: 2
Training loss: 3.1976663365171207
Validation loss: 2.77673747308834

Epoch: 6| Step: 3
Training loss: 3.3362019275504893
Validation loss: 2.774708191394221

Epoch: 6| Step: 4
Training loss: 2.772957085922213
Validation loss: 2.7741843235282695

Epoch: 6| Step: 5
Training loss: 2.1568348409340237
Validation loss: 2.7738015887535488

Epoch: 6| Step: 6
Training loss: 3.6286402872801617
Validation loss: 2.774954546824344

Epoch: 6| Step: 7
Training loss: 2.84956051298924
Validation loss: 2.77424836611359

Epoch: 6| Step: 8
Training loss: 2.8722167433344787
Validation loss: 2.7737418197709887

Epoch: 6| Step: 9
Training loss: 2.969408785355411
Validation loss: 2.7717848812451935

Epoch: 6| Step: 10
Training loss: 3.203572758338532
Validation loss: 2.7726725924918427

Epoch: 6| Step: 11
Training loss: 2.991064433595982
Validation loss: 2.7713542735037504

Epoch: 6| Step: 12
Training loss: 2.890005674257615
Validation loss: 2.770684661935338

Epoch: 6| Step: 13
Training loss: 3.3108764124334518
Validation loss: 2.7693139431000224

Epoch: 73| Step: 0
Training loss: 2.705328776180715
Validation loss: 2.766419791674743

Epoch: 6| Step: 1
Training loss: 3.5556789482745943
Validation loss: 2.7701594612483453

Epoch: 6| Step: 2
Training loss: 3.304819668049995
Validation loss: 2.771586804609945

Epoch: 6| Step: 3
Training loss: 3.4108467932263964
Validation loss: 2.770944764416859

Epoch: 6| Step: 4
Training loss: 3.334623627478591
Validation loss: 2.766941983129158

Epoch: 6| Step: 5
Training loss: 2.874548503419405
Validation loss: 2.768640987974548

Epoch: 6| Step: 6
Training loss: 3.1035395934017824
Validation loss: 2.7701299133627835

Epoch: 6| Step: 7
Training loss: 3.480544101229086
Validation loss: 2.7653930170026344

Epoch: 6| Step: 8
Training loss: 2.6167628612776253
Validation loss: 2.764513575129286

Epoch: 6| Step: 9
Training loss: 2.4679139085589257
Validation loss: 2.766910503340189

Epoch: 6| Step: 10
Training loss: 3.2680567398281704
Validation loss: 2.768612622083166

Epoch: 6| Step: 11
Training loss: 1.665502793515009
Validation loss: 2.7634940238846504

Epoch: 6| Step: 12
Training loss: 3.4443214011689998
Validation loss: 2.762530155821881

Epoch: 6| Step: 13
Training loss: 3.5948696880040685
Validation loss: 2.7615186563072

Epoch: 74| Step: 0
Training loss: 2.455859852641068
Validation loss: 2.7631196959857514

Epoch: 6| Step: 1
Training loss: 2.9632787783406513
Validation loss: 2.763876801189505

Epoch: 6| Step: 2
Training loss: 2.8010304870798497
Validation loss: 2.7649761421607217

Epoch: 6| Step: 3
Training loss: 3.01257707805877
Validation loss: 2.7662943989379567

Epoch: 6| Step: 4
Training loss: 3.3791966660779345
Validation loss: 2.7739442858270733

Epoch: 6| Step: 5
Training loss: 2.9932687265040845
Validation loss: 2.7802459832891593

Epoch: 6| Step: 6
Training loss: 3.3268868735698316
Validation loss: 2.7899481513679585

Epoch: 6| Step: 7
Training loss: 3.290701777041609
Validation loss: 2.7880419786921307

Epoch: 6| Step: 8
Training loss: 2.9994010327356664
Validation loss: 2.772530838767775

Epoch: 6| Step: 9
Training loss: 2.8422730351726813
Validation loss: 2.766027907985927

Epoch: 6| Step: 10
Training loss: 2.850591123078959
Validation loss: 2.756032923653177

Epoch: 6| Step: 11
Training loss: 2.803675391896323
Validation loss: 2.7589319738742057

Epoch: 6| Step: 12
Training loss: 3.379793789233192
Validation loss: 2.753288087605923

Epoch: 6| Step: 13
Training loss: 4.197536681641458
Validation loss: 2.7541938770589462

Epoch: 75| Step: 0
Training loss: 2.961999546707809
Validation loss: 2.756178177726592

Epoch: 6| Step: 1
Training loss: 3.1441460604531226
Validation loss: 2.7570093772573654

Epoch: 6| Step: 2
Training loss: 3.8067969519593854
Validation loss: 2.7574445605755216

Epoch: 6| Step: 3
Training loss: 2.7256644882424212
Validation loss: 2.7577944017125686

Epoch: 6| Step: 4
Training loss: 3.7484436620269665
Validation loss: 2.7587144230851335

Epoch: 6| Step: 5
Training loss: 2.9480809322101944
Validation loss: 2.7588048896622315

Epoch: 6| Step: 6
Training loss: 2.8718483277121045
Validation loss: 2.761008878502358

Epoch: 6| Step: 7
Training loss: 2.7751387415388873
Validation loss: 2.7581720632244937

Epoch: 6| Step: 8
Training loss: 3.1452302333573603
Validation loss: 2.75914296820359

Epoch: 6| Step: 9
Training loss: 2.9248773989292425
Validation loss: 2.7582284694474737

Epoch: 6| Step: 10
Training loss: 3.21328211663084
Validation loss: 2.756911550229026

Epoch: 6| Step: 11
Training loss: 2.8840641932968705
Validation loss: 2.756700080080541

Epoch: 6| Step: 12
Training loss: 2.748730800088022
Validation loss: 2.7547386394509883

Epoch: 6| Step: 13
Training loss: 3.0349981986076626
Validation loss: 2.7543440894948232

Epoch: 76| Step: 0
Training loss: 3.2393144861921175
Validation loss: 2.7535617915199926

Epoch: 6| Step: 1
Training loss: 3.194416545432806
Validation loss: 2.7504606355240644

Epoch: 6| Step: 2
Training loss: 3.0475851160669576
Validation loss: 2.747643224373616

Epoch: 6| Step: 3
Training loss: 3.206064354948492
Validation loss: 2.7499200281650826

Epoch: 6| Step: 4
Training loss: 2.8198306023331425
Validation loss: 2.749172436692765

Epoch: 6| Step: 5
Training loss: 3.462939920951295
Validation loss: 2.750700564005713

Epoch: 6| Step: 6
Training loss: 2.797631869919601
Validation loss: 2.754203554709122

Epoch: 6| Step: 7
Training loss: 3.1552750998622208
Validation loss: 2.7693697085929068

Epoch: 6| Step: 8
Training loss: 2.8713709275750396
Validation loss: 2.794949322638654

Epoch: 6| Step: 9
Training loss: 3.408387799437943
Validation loss: 2.77610830874881

Epoch: 6| Step: 10
Training loss: 2.628043907629023
Validation loss: 2.7460935828929274

Epoch: 6| Step: 11
Training loss: 2.908133603937345
Validation loss: 2.742215783982694

Epoch: 6| Step: 12
Training loss: 2.753831275298118
Validation loss: 2.7452815035309923

Epoch: 6| Step: 13
Training loss: 3.6413578720169224
Validation loss: 2.745707593496176

Epoch: 77| Step: 0
Training loss: 2.5676142202672607
Validation loss: 2.745291496483801

Epoch: 6| Step: 1
Training loss: 2.9182419655391145
Validation loss: 2.745638790860929

Epoch: 6| Step: 2
Training loss: 3.468671093292413
Validation loss: 2.742861376732326

Epoch: 6| Step: 3
Training loss: 3.1346127481706016
Validation loss: 2.741526458550794

Epoch: 6| Step: 4
Training loss: 3.57784540008497
Validation loss: 2.7414450079489234

Epoch: 6| Step: 5
Training loss: 3.405745022640527
Validation loss: 2.742045458651761

Epoch: 6| Step: 6
Training loss: 2.741617431507735
Validation loss: 2.7464239691861905

Epoch: 6| Step: 7
Training loss: 2.4817287338758285
Validation loss: 2.7456538478872465

Epoch: 6| Step: 8
Training loss: 3.0558132429028593
Validation loss: 2.7457599151365053

Epoch: 6| Step: 9
Training loss: 3.158277408101359
Validation loss: 2.7447432469583566

Epoch: 6| Step: 10
Training loss: 3.18965913535918
Validation loss: 2.7453634463511234

Epoch: 6| Step: 11
Training loss: 2.880058813554204
Validation loss: 2.743592427688845

Epoch: 6| Step: 12
Training loss: 3.0855378870018795
Validation loss: 2.746598506988368

Epoch: 6| Step: 13
Training loss: 3.120541405531299
Validation loss: 2.746468262746049

Epoch: 78| Step: 0
Training loss: 3.287903932769047
Validation loss: 2.7397334273201577

Epoch: 6| Step: 1
Training loss: 2.659986224461501
Validation loss: 2.73700099781148

Epoch: 6| Step: 2
Training loss: 3.165810486009103
Validation loss: 2.7366141859043616

Epoch: 6| Step: 3
Training loss: 3.309987969045297
Validation loss: 2.736896033626745

Epoch: 6| Step: 4
Training loss: 3.3584147655625904
Validation loss: 2.7374569636133117

Epoch: 6| Step: 5
Training loss: 3.031975256292991
Validation loss: 2.735915374736674

Epoch: 6| Step: 6
Training loss: 2.9191081772793517
Validation loss: 2.735859543918113

Epoch: 6| Step: 7
Training loss: 3.11729794261195
Validation loss: 2.740466560618883

Epoch: 6| Step: 8
Training loss: 2.7086904045840567
Validation loss: 2.749868317077367

Epoch: 6| Step: 9
Training loss: 2.30831055429101
Validation loss: 2.7694828061550636

Epoch: 6| Step: 10
Training loss: 2.7577201676514043
Validation loss: 2.772207084429918

Epoch: 6| Step: 11
Training loss: 2.9655436015238528
Validation loss: 2.777453343986885

Epoch: 6| Step: 12
Training loss: 3.7659828364243992
Validation loss: 2.7553485324715585

Epoch: 6| Step: 13
Training loss: 3.4750523405455707
Validation loss: 2.7293683810173666

Epoch: 79| Step: 0
Training loss: 2.9011507316282197
Validation loss: 2.732432318420045

Epoch: 6| Step: 1
Training loss: 2.7245518832139997
Validation loss: 2.7310062640885673

Epoch: 6| Step: 2
Training loss: 3.3459421262872104
Validation loss: 2.735794879120486

Epoch: 6| Step: 3
Training loss: 3.0035015969625425
Validation loss: 2.740693054315881

Epoch: 6| Step: 4
Training loss: 2.912323870265356
Validation loss: 2.7384300079765413

Epoch: 6| Step: 5
Training loss: 2.7916094266422675
Validation loss: 2.7390437645026857

Epoch: 6| Step: 6
Training loss: 3.2519808381420496
Validation loss: 2.7368806998638804

Epoch: 6| Step: 7
Training loss: 3.254121661068341
Validation loss: 2.7369502322166386

Epoch: 6| Step: 8
Training loss: 2.6472685718337035
Validation loss: 2.7369170530130305

Epoch: 6| Step: 9
Training loss: 3.1251957641318966
Validation loss: 2.7351356950671932

Epoch: 6| Step: 10
Training loss: 2.9024554676513503
Validation loss: 2.7413914462268965

Epoch: 6| Step: 11
Training loss: 3.2102180658823753
Validation loss: 2.7351914235009636

Epoch: 6| Step: 12
Training loss: 3.758550813279424
Validation loss: 2.732318108525994

Epoch: 6| Step: 13
Training loss: 2.8128818676577416
Validation loss: 2.733737290140607

Epoch: 80| Step: 0
Training loss: 3.159657668873743
Validation loss: 2.7316090535026945

Epoch: 6| Step: 1
Training loss: 3.1861581408854254
Validation loss: 2.7311991043813455

Epoch: 6| Step: 2
Training loss: 3.3298656228019126
Validation loss: 2.7297725710981156

Epoch: 6| Step: 3
Training loss: 2.7693715553890734
Validation loss: 2.7288344365056734

Epoch: 6| Step: 4
Training loss: 2.641698133921005
Validation loss: 2.7269768642597794

Epoch: 6| Step: 5
Training loss: 2.537737597536955
Validation loss: 2.727539502377741

Epoch: 6| Step: 6
Training loss: 3.604948161224678
Validation loss: 2.7270914219322577

Epoch: 6| Step: 7
Training loss: 3.635253611116929
Validation loss: 2.727930112127988

Epoch: 6| Step: 8
Training loss: 3.5105508086310997
Validation loss: 2.722555331699718

Epoch: 6| Step: 9
Training loss: 2.740520611887845
Validation loss: 2.724382103126862

Epoch: 6| Step: 10
Training loss: 2.360599629470601
Validation loss: 2.723512581104657

Epoch: 6| Step: 11
Training loss: 2.8720714746788705
Validation loss: 2.7237085742280587

Epoch: 6| Step: 12
Training loss: 2.570051927895399
Validation loss: 2.727609942995125

Epoch: 6| Step: 13
Training loss: 3.679079301141708
Validation loss: 2.7367056116133344

Epoch: 81| Step: 0
Training loss: 2.8274811069656685
Validation loss: 2.7247291534202533

Epoch: 6| Step: 1
Training loss: 2.8507752886537596
Validation loss: 2.7209938293944345

Epoch: 6| Step: 2
Training loss: 3.2132229062122852
Validation loss: 2.7247338239399608

Epoch: 6| Step: 3
Training loss: 2.847344945314821
Validation loss: 2.7209666259640986

Epoch: 6| Step: 4
Training loss: 3.130658177165533
Validation loss: 2.7248785524530366

Epoch: 6| Step: 5
Training loss: 2.732889872917516
Validation loss: 2.7258638939117583

Epoch: 6| Step: 6
Training loss: 2.8482725630323293
Validation loss: 2.722753978317127

Epoch: 6| Step: 7
Training loss: 3.327287308840535
Validation loss: 2.732515768647324

Epoch: 6| Step: 8
Training loss: 3.5280712302666113
Validation loss: 2.735478664165122

Epoch: 6| Step: 9
Training loss: 2.6613218467836557
Validation loss: 2.7307305726057507

Epoch: 6| Step: 10
Training loss: 3.426079662031509
Validation loss: 2.719131843664945

Epoch: 6| Step: 11
Training loss: 3.2771502359249935
Validation loss: 2.713350526226066

Epoch: 6| Step: 12
Training loss: 2.6195638771198224
Validation loss: 2.7161536591165345

Epoch: 6| Step: 13
Training loss: 3.3321882347342955
Validation loss: 2.714610681734538

Epoch: 82| Step: 0
Training loss: 2.9291742714520455
Validation loss: 2.7132002552527092

Epoch: 6| Step: 1
Training loss: 3.626388546947585
Validation loss: 2.7122709162906498

Epoch: 6| Step: 2
Training loss: 3.1193919406034185
Validation loss: 2.7134838783437982

Epoch: 6| Step: 3
Training loss: 3.055020599545519
Validation loss: 2.714285904920338

Epoch: 6| Step: 4
Training loss: 3.2247785388698955
Validation loss: 2.710334896443748

Epoch: 6| Step: 5
Training loss: 3.346843108836447
Validation loss: 2.7086935714046496

Epoch: 6| Step: 6
Training loss: 2.856486377909942
Validation loss: 2.710416681320996

Epoch: 6| Step: 7
Training loss: 3.0280852166584915
Validation loss: 2.7108069968821855

Epoch: 6| Step: 8
Training loss: 2.562175637162001
Validation loss: 2.7108630854896223

Epoch: 6| Step: 9
Training loss: 2.965401135950198
Validation loss: 2.7065667268187834

Epoch: 6| Step: 10
Training loss: 2.4861230997924815
Validation loss: 2.7087326547389208

Epoch: 6| Step: 11
Training loss: 2.9342137886589232
Validation loss: 2.7085965094158952

Epoch: 6| Step: 12
Training loss: 2.825215650446369
Validation loss: 2.708930750633578

Epoch: 6| Step: 13
Training loss: 3.6808604579965643
Validation loss: 2.706945983730486

Epoch: 83| Step: 0
Training loss: 2.5102755136233306
Validation loss: 2.7070704046848713

Epoch: 6| Step: 1
Training loss: 2.6662613640179544
Validation loss: 2.7066969020840337

Epoch: 6| Step: 2
Training loss: 2.819512673874627
Validation loss: 2.7131619997461534

Epoch: 6| Step: 3
Training loss: 3.0478607930511457
Validation loss: 2.7146184011356667

Epoch: 6| Step: 4
Training loss: 3.4365801881059355
Validation loss: 2.7374092632799276

Epoch: 6| Step: 5
Training loss: 3.187262731958911
Validation loss: 2.740064624470086

Epoch: 6| Step: 6
Training loss: 2.893781104033953
Validation loss: 2.768323907556518

Epoch: 6| Step: 7
Training loss: 2.6099123829718023
Validation loss: 2.745156655323879

Epoch: 6| Step: 8
Training loss: 3.21813396002907
Validation loss: 2.7285763621052688

Epoch: 6| Step: 9
Training loss: 2.8060712455791483
Validation loss: 2.7055894631904795

Epoch: 6| Step: 10
Training loss: 3.7405476013181613
Validation loss: 2.7011491709027196

Epoch: 6| Step: 11
Training loss: 2.8812125710395966
Validation loss: 2.70416790003271

Epoch: 6| Step: 12
Training loss: 3.208958816658718
Validation loss: 2.702133647526702

Epoch: 6| Step: 13
Training loss: 3.494151132993213
Validation loss: 2.703294488734927

Epoch: 84| Step: 0
Training loss: 2.099738822317729
Validation loss: 2.7050048761344887

Epoch: 6| Step: 1
Training loss: 2.802574785852797
Validation loss: 2.706558446446275

Epoch: 6| Step: 2
Training loss: 3.1054598442285823
Validation loss: 2.7055561154391707

Epoch: 6| Step: 3
Training loss: 3.4968109588622376
Validation loss: 2.7027382892634324

Epoch: 6| Step: 4
Training loss: 3.006977867154111
Validation loss: 2.7023706473649005

Epoch: 6| Step: 5
Training loss: 2.9903624225012786
Validation loss: 2.6998387066371827

Epoch: 6| Step: 6
Training loss: 3.2558057719980145
Validation loss: 2.6964183135091764

Epoch: 6| Step: 7
Training loss: 3.3906420166713684
Validation loss: 2.696808784267142

Epoch: 6| Step: 8
Training loss: 2.5270688410063267
Validation loss: 2.6963913822103773

Epoch: 6| Step: 9
Training loss: 3.1725404539302144
Validation loss: 2.6972757179062095

Epoch: 6| Step: 10
Training loss: 2.755996149184993
Validation loss: 2.697635817669041

Epoch: 6| Step: 11
Training loss: 2.968437098025094
Validation loss: 2.6975733404386983

Epoch: 6| Step: 12
Training loss: 3.1119432433966514
Validation loss: 2.6962273613131384

Epoch: 6| Step: 13
Training loss: 3.8079283773755095
Validation loss: 2.6981694856136245

Epoch: 85| Step: 0
Training loss: 2.780181593830092
Validation loss: 2.7064359049590743

Epoch: 6| Step: 1
Training loss: 3.1023338761529162
Validation loss: 2.7188849815813296

Epoch: 6| Step: 2
Training loss: 2.9787479097436638
Validation loss: 2.7235504229584238

Epoch: 6| Step: 3
Training loss: 2.8980416492868035
Validation loss: 2.7360321826695966

Epoch: 6| Step: 4
Training loss: 2.2873011768422593
Validation loss: 2.734859827424739

Epoch: 6| Step: 5
Training loss: 3.0717254571226817
Validation loss: 2.732920011048218

Epoch: 6| Step: 6
Training loss: 2.5565467158614723
Validation loss: 2.715337707857145

Epoch: 6| Step: 7
Training loss: 3.3471115185452254
Validation loss: 2.7060676655188898

Epoch: 6| Step: 8
Training loss: 2.4845878461913746
Validation loss: 2.6958495996134126

Epoch: 6| Step: 9
Training loss: 3.1921675671642724
Validation loss: 2.696234047506912

Epoch: 6| Step: 10
Training loss: 3.87814953694047
Validation loss: 2.691441462836056

Epoch: 6| Step: 11
Training loss: 3.399360057968402
Validation loss: 2.6869776438245396

Epoch: 6| Step: 12
Training loss: 2.639490007789517
Validation loss: 2.689802144844455

Epoch: 6| Step: 13
Training loss: 3.5494773157590247
Validation loss: 2.694111651850312

Epoch: 86| Step: 0
Training loss: 3.473948801343081
Validation loss: 2.6979612124353407

Epoch: 6| Step: 1
Training loss: 3.678457001746288
Validation loss: 2.699558681204054

Epoch: 6| Step: 2
Training loss: 3.2562790882180557
Validation loss: 2.703879492040538

Epoch: 6| Step: 3
Training loss: 2.8447428217330573
Validation loss: 2.7100991871460995

Epoch: 6| Step: 4
Training loss: 2.676155810348988
Validation loss: 2.7090405723180186

Epoch: 6| Step: 5
Training loss: 2.756262151643777
Validation loss: 2.7027543203982463

Epoch: 6| Step: 6
Training loss: 3.201814560208993
Validation loss: 2.698822755578068

Epoch: 6| Step: 7
Training loss: 2.8368513668308806
Validation loss: 2.698269320750492

Epoch: 6| Step: 8
Training loss: 3.4098147716163996
Validation loss: 2.6949682110050004

Epoch: 6| Step: 9
Training loss: 2.6436596649824975
Validation loss: 2.6917404342865394

Epoch: 6| Step: 10
Training loss: 2.7395828788573224
Validation loss: 2.691176127421305

Epoch: 6| Step: 11
Training loss: 2.7215602863621204
Validation loss: 2.6894986923451265

Epoch: 6| Step: 12
Training loss: 2.7623211798465186
Validation loss: 2.6874930650450355

Epoch: 6| Step: 13
Training loss: 3.5220996152100654
Validation loss: 2.6868005783476314

Epoch: 87| Step: 0
Training loss: 3.034868106395692
Validation loss: 2.6894612197324617

Epoch: 6| Step: 1
Training loss: 3.027485505753715
Validation loss: 2.6953193339884947

Epoch: 6| Step: 2
Training loss: 3.44969262122123
Validation loss: 2.6987276127442823

Epoch: 6| Step: 3
Training loss: 2.7146041654625237
Validation loss: 2.697012872778835

Epoch: 6| Step: 4
Training loss: 3.409967196578038
Validation loss: 2.697444504974042

Epoch: 6| Step: 5
Training loss: 2.5443233509298526
Validation loss: 2.691067372436185

Epoch: 6| Step: 6
Training loss: 3.3003713861194344
Validation loss: 2.6838359786432693

Epoch: 6| Step: 7
Training loss: 3.0172892509383527
Validation loss: 2.6842623804893977

Epoch: 6| Step: 8
Training loss: 3.3322759540676725
Validation loss: 2.6815727564737153

Epoch: 6| Step: 9
Training loss: 2.9886367486662735
Validation loss: 2.68400672364116

Epoch: 6| Step: 10
Training loss: 2.9997420200051326
Validation loss: 2.683840388867733

Epoch: 6| Step: 11
Training loss: 2.6079746531910564
Validation loss: 2.6819681085750533

Epoch: 6| Step: 12
Training loss: 2.5991169200106214
Validation loss: 2.680903566583245

Epoch: 6| Step: 13
Training loss: 3.1134890842347476
Validation loss: 2.679005558364667

Epoch: 88| Step: 0
Training loss: 2.4128093738533187
Validation loss: 2.684028403646512

Epoch: 6| Step: 1
Training loss: 2.981317841659632
Validation loss: 2.690206837239239

Epoch: 6| Step: 2
Training loss: 2.926311857342922
Validation loss: 2.698974121504519

Epoch: 6| Step: 3
Training loss: 2.6105585212453444
Validation loss: 2.7177325890882655

Epoch: 6| Step: 4
Training loss: 2.941476443644937
Validation loss: 2.7700189273641147

Epoch: 6| Step: 5
Training loss: 3.018509666084912
Validation loss: 2.763024783453723

Epoch: 6| Step: 6
Training loss: 2.9696596057171476
Validation loss: 2.7234229773450847

Epoch: 6| Step: 7
Training loss: 3.315557256612378
Validation loss: 2.69220067281098

Epoch: 6| Step: 8
Training loss: 2.9118788159065603
Validation loss: 2.675532311174891

Epoch: 6| Step: 9
Training loss: 2.6280864553992935
Validation loss: 2.6733730539568565

Epoch: 6| Step: 10
Training loss: 3.517944113560193
Validation loss: 2.677279312955196

Epoch: 6| Step: 11
Training loss: 3.5507807128368682
Validation loss: 2.679630689958431

Epoch: 6| Step: 12
Training loss: 3.2222185427180654
Validation loss: 2.6844602699626994

Epoch: 6| Step: 13
Training loss: 2.942953850060586
Validation loss: 2.691249975574232

Epoch: 89| Step: 0
Training loss: 3.6827022569977457
Validation loss: 2.6879296823786887

Epoch: 6| Step: 1
Training loss: 3.1505017198909973
Validation loss: 2.689670772552493

Epoch: 6| Step: 2
Training loss: 2.458490517542708
Validation loss: 2.6869245305588847

Epoch: 6| Step: 3
Training loss: 2.6589863763283015
Validation loss: 2.6838955060325285

Epoch: 6| Step: 4
Training loss: 2.7910352723569307
Validation loss: 2.685048912261868

Epoch: 6| Step: 5
Training loss: 2.509640891690068
Validation loss: 2.6833436805873614

Epoch: 6| Step: 6
Training loss: 2.8740760313634044
Validation loss: 2.6805336884175843

Epoch: 6| Step: 7
Training loss: 2.921943541350156
Validation loss: 2.6801715931257095

Epoch: 6| Step: 8
Training loss: 3.0347224530632886
Validation loss: 2.6810268792017635

Epoch: 6| Step: 9
Training loss: 3.435376707962367
Validation loss: 2.679086889154319

Epoch: 6| Step: 10
Training loss: 3.2980781276278917
Validation loss: 2.6763233832926896

Epoch: 6| Step: 11
Training loss: 2.8517275409752143
Validation loss: 2.675494227095147

Epoch: 6| Step: 12
Training loss: 3.243601736454623
Validation loss: 2.6721315479629024

Epoch: 6| Step: 13
Training loss: 3.241404243444712
Validation loss: 2.6729095927579425

Epoch: 90| Step: 0
Training loss: 2.668021473845348
Validation loss: 2.6679787663616312

Epoch: 6| Step: 1
Training loss: 3.291091691674702
Validation loss: 2.6663360349073915

Epoch: 6| Step: 2
Training loss: 3.4541378693402143
Validation loss: 2.6754852660564237

Epoch: 6| Step: 3
Training loss: 1.6292705174328264
Validation loss: 2.7136574776894395

Epoch: 6| Step: 4
Training loss: 3.13130376164317
Validation loss: 2.754329117205956

Epoch: 6| Step: 5
Training loss: 3.3780836923280995
Validation loss: 2.806650784034716

Epoch: 6| Step: 6
Training loss: 2.8433014232936356
Validation loss: 2.7094721968810407

Epoch: 6| Step: 7
Training loss: 2.9338957406354687
Validation loss: 2.6736831797735494

Epoch: 6| Step: 8
Training loss: 3.0593410470576687
Validation loss: 2.662542396202856

Epoch: 6| Step: 9
Training loss: 3.3541713422343835
Validation loss: 2.6617784262883726

Epoch: 6| Step: 10
Training loss: 3.0080263532437814
Validation loss: 2.6618433877012095

Epoch: 6| Step: 11
Training loss: 3.0108074387796115
Validation loss: 2.662817521481703

Epoch: 6| Step: 12
Training loss: 2.9794148873023225
Validation loss: 2.6626726729918007

Epoch: 6| Step: 13
Training loss: 3.4720819639911804
Validation loss: 2.664274022117424

Epoch: 91| Step: 0
Training loss: 3.231633743136786
Validation loss: 2.6649521842797577

Epoch: 6| Step: 1
Training loss: 3.5152717921527885
Validation loss: 2.667033845736075

Epoch: 6| Step: 2
Training loss: 3.2467729245865233
Validation loss: 2.664820323832021

Epoch: 6| Step: 3
Training loss: 3.1216195705572667
Validation loss: 2.6658349438527007

Epoch: 6| Step: 4
Training loss: 2.924666269940443
Validation loss: 2.6614041745644488

Epoch: 6| Step: 5
Training loss: 2.9600662922523897
Validation loss: 2.6627321680402183

Epoch: 6| Step: 6
Training loss: 2.2385615893921598
Validation loss: 2.662776146768132

Epoch: 6| Step: 7
Training loss: 2.595447398520403
Validation loss: 2.6579851113837303

Epoch: 6| Step: 8
Training loss: 3.3525136029382105
Validation loss: 2.661755656817071

Epoch: 6| Step: 9
Training loss: 2.2129553762660854
Validation loss: 2.6596487356017353

Epoch: 6| Step: 10
Training loss: 2.868721948956079
Validation loss: 2.659593060041648

Epoch: 6| Step: 11
Training loss: 3.1575079195794635
Validation loss: 2.6633992536163014

Epoch: 6| Step: 12
Training loss: 3.30738868070475
Validation loss: 2.6629731491528905

Epoch: 6| Step: 13
Training loss: 3.0803022865481355
Validation loss: 2.6732471960097595

Epoch: 92| Step: 0
Training loss: 2.98035243696086
Validation loss: 2.679913971442624

Epoch: 6| Step: 1
Training loss: 2.9986473848913975
Validation loss: 2.6766230051477793

Epoch: 6| Step: 2
Training loss: 3.535430863815932
Validation loss: 2.66835790373723

Epoch: 6| Step: 3
Training loss: 3.2030952266146753
Validation loss: 2.6595744572431976

Epoch: 6| Step: 4
Training loss: 3.190024479500051
Validation loss: 2.656775293400493

Epoch: 6| Step: 5
Training loss: 3.450683835575996
Validation loss: 2.65163100424337

Epoch: 6| Step: 6
Training loss: 1.5017611178727523
Validation loss: 2.6573999221299527

Epoch: 6| Step: 7
Training loss: 3.1418138977143593
Validation loss: 2.653819901510325

Epoch: 6| Step: 8
Training loss: 2.60830300976694
Validation loss: 2.6499736402643577

Epoch: 6| Step: 9
Training loss: 2.6700736772180016
Validation loss: 2.6485369234682605

Epoch: 6| Step: 10
Training loss: 3.1097825899824585
Validation loss: 2.65341828733336

Epoch: 6| Step: 11
Training loss: 2.6017510972954025
Validation loss: 2.657326577492945

Epoch: 6| Step: 12
Training loss: 3.2810485778021423
Validation loss: 2.659718354437603

Epoch: 6| Step: 13
Training loss: 3.2873987624676935
Validation loss: 2.664425521182665

Epoch: 93| Step: 0
Training loss: 3.4310190314151723
Validation loss: 2.660313103019187

Epoch: 6| Step: 1
Training loss: 3.1023500148966425
Validation loss: 2.6612207238302927

Epoch: 6| Step: 2
Training loss: 2.8308571111312872
Validation loss: 2.6556897039948426

Epoch: 6| Step: 3
Training loss: 2.812586126068451
Validation loss: 2.6537334124135525

Epoch: 6| Step: 4
Training loss: 2.4775317488559767
Validation loss: 2.6515508800481147

Epoch: 6| Step: 5
Training loss: 2.891800594984437
Validation loss: 2.6467536192652967

Epoch: 6| Step: 6
Training loss: 2.9299576698344096
Validation loss: 2.650915571793954

Epoch: 6| Step: 7
Training loss: 3.150359445075865
Validation loss: 2.645410290895367

Epoch: 6| Step: 8
Training loss: 3.2586583930668582
Validation loss: 2.6479616900839837

Epoch: 6| Step: 9
Training loss: 2.596521666138342
Validation loss: 2.6460810516202997

Epoch: 6| Step: 10
Training loss: 2.923741035463992
Validation loss: 2.645916083290727

Epoch: 6| Step: 11
Training loss: 3.2337988003888682
Validation loss: 2.64572447059568

Epoch: 6| Step: 12
Training loss: 3.0426581521724465
Validation loss: 2.6465624624249773

Epoch: 6| Step: 13
Training loss: 3.1703104003177343
Validation loss: 2.6486607828099245

Epoch: 94| Step: 0
Training loss: 2.6606506694821603
Validation loss: 2.650533834976055

Epoch: 6| Step: 1
Training loss: 3.2654325437644514
Validation loss: 2.6508602553545226

Epoch: 6| Step: 2
Training loss: 3.4536321621430908
Validation loss: 2.659003800246747

Epoch: 6| Step: 3
Training loss: 3.1996777849099263
Validation loss: 2.6490455399172443

Epoch: 6| Step: 4
Training loss: 3.00981457947087
Validation loss: 2.653625629896432

Epoch: 6| Step: 5
Training loss: 2.720119087753788
Validation loss: 2.6493333903329703

Epoch: 6| Step: 6
Training loss: 2.9579283387825757
Validation loss: 2.6596245521554547

Epoch: 6| Step: 7
Training loss: 3.0501093985527223
Validation loss: 2.6722541160636717

Epoch: 6| Step: 8
Training loss: 3.0706861428777645
Validation loss: 2.6914367297806674

Epoch: 6| Step: 9
Training loss: 3.342855743901632
Validation loss: 2.699034362690453

Epoch: 6| Step: 10
Training loss: 3.298288629841571
Validation loss: 2.6870906772816907

Epoch: 6| Step: 11
Training loss: 2.7207325689361537
Validation loss: 2.64684187258216

Epoch: 6| Step: 12
Training loss: 2.487515270243792
Validation loss: 2.6417727596377736

Epoch: 6| Step: 13
Training loss: 2.1092316755416882
Validation loss: 2.646318623869603

Epoch: 95| Step: 0
Training loss: 3.079537004870647
Validation loss: 2.644255452412679

Epoch: 6| Step: 1
Training loss: 3.2238968374440033
Validation loss: 2.6429451825907258

Epoch: 6| Step: 2
Training loss: 2.5130639159836528
Validation loss: 2.641975030058791

Epoch: 6| Step: 3
Training loss: 2.55784351327745
Validation loss: 2.642189723901373

Epoch: 6| Step: 4
Training loss: 2.766817428510371
Validation loss: 2.667068017346191

Epoch: 6| Step: 5
Training loss: 3.534276155123398
Validation loss: 2.6698866654460427

Epoch: 6| Step: 6
Training loss: 2.9140039187518223
Validation loss: 2.659002772477834

Epoch: 6| Step: 7
Training loss: 3.4851081658410985
Validation loss: 2.64177820177197

Epoch: 6| Step: 8
Training loss: 3.1296004955065126
Validation loss: 2.637528711607965

Epoch: 6| Step: 9
Training loss: 3.277971355375919
Validation loss: 2.6384983507409774

Epoch: 6| Step: 10
Training loss: 2.8844960163556443
Validation loss: 2.6418165312362603

Epoch: 6| Step: 11
Training loss: 2.6614148359731864
Validation loss: 2.656593110462292

Epoch: 6| Step: 12
Training loss: 2.678510312790962
Validation loss: 2.7094207896435427

Epoch: 6| Step: 13
Training loss: 2.9869108760424874
Validation loss: 2.734813778504218

Epoch: 96| Step: 0
Training loss: 3.0515576496857255
Validation loss: 2.65046273682323

Epoch: 6| Step: 1
Training loss: 2.38921189773512
Validation loss: 2.639377406795579

Epoch: 6| Step: 2
Training loss: 2.7713309010976848
Validation loss: 2.6519291962284846

Epoch: 6| Step: 3
Training loss: 3.1129321736643205
Validation loss: 2.695848264467586

Epoch: 6| Step: 4
Training loss: 3.4977544665525873
Validation loss: 2.7185918724044744

Epoch: 6| Step: 5
Training loss: 2.951046489725549
Validation loss: 2.735726640583763

Epoch: 6| Step: 6
Training loss: 3.135301015417083
Validation loss: 2.7157934414456

Epoch: 6| Step: 7
Training loss: 3.629107680135175
Validation loss: 2.7006021601048427

Epoch: 6| Step: 8
Training loss: 2.47969987622197
Validation loss: 2.662969407621988

Epoch: 6| Step: 9
Training loss: 3.0143274866101066
Validation loss: 2.6458486766982343

Epoch: 6| Step: 10
Training loss: 2.4437783398167916
Validation loss: 2.6348615985382704

Epoch: 6| Step: 11
Training loss: 2.4408514994731796
Validation loss: 2.637512885686574

Epoch: 6| Step: 12
Training loss: 3.333052305454932
Validation loss: 2.6404866702162137

Epoch: 6| Step: 13
Training loss: 3.5460452819187824
Validation loss: 2.6527428218734195

Epoch: 97| Step: 0
Training loss: 3.1035331403887425
Validation loss: 2.6850880394856267

Epoch: 6| Step: 1
Training loss: 2.601866375012916
Validation loss: 2.6906766115734095

Epoch: 6| Step: 2
Training loss: 3.319379177187843
Validation loss: 2.659851661032197

Epoch: 6| Step: 3
Training loss: 3.317789999986254
Validation loss: 2.654701544032287

Epoch: 6| Step: 4
Training loss: 3.3239401712920618
Validation loss: 2.637407742276562

Epoch: 6| Step: 5
Training loss: 3.1168296818931536
Validation loss: 2.6353532653079776

Epoch: 6| Step: 6
Training loss: 2.5037188526792935
Validation loss: 2.6296656885927203

Epoch: 6| Step: 7
Training loss: 2.9478053059566487
Validation loss: 2.6335132146337847

Epoch: 6| Step: 8
Training loss: 3.020593848546338
Validation loss: 2.6354053488478675

Epoch: 6| Step: 9
Training loss: 2.484832145809185
Validation loss: 2.6369881465355403

Epoch: 6| Step: 10
Training loss: 3.14230043880745
Validation loss: 2.646018808452808

Epoch: 6| Step: 11
Training loss: 2.510405628818501
Validation loss: 2.66790796398426

Epoch: 6| Step: 12
Training loss: 3.288714827694172
Validation loss: 2.708210701134164

Epoch: 6| Step: 13
Training loss: 2.6617726975805436
Validation loss: 2.7085443236247424

Epoch: 98| Step: 0
Training loss: 2.8298744144140002
Validation loss: 2.7288138152016415

Epoch: 6| Step: 1
Training loss: 3.1767719220406
Validation loss: 2.69762619367352

Epoch: 6| Step: 2
Training loss: 2.6892759088819833
Validation loss: 2.7019639683225702

Epoch: 6| Step: 3
Training loss: 2.437333027916158
Validation loss: 2.6682175931761427

Epoch: 6| Step: 4
Training loss: 2.7999701396167356
Validation loss: 2.6509272956477914

Epoch: 6| Step: 5
Training loss: 3.2065218150308215
Validation loss: 2.6346398494006706

Epoch: 6| Step: 6
Training loss: 3.454820863797099
Validation loss: 2.6333719324180533

Epoch: 6| Step: 7
Training loss: 3.229130275070057
Validation loss: 2.627595370452837

Epoch: 6| Step: 8
Training loss: 3.3544408713778684
Validation loss: 2.627820748086063

Epoch: 6| Step: 9
Training loss: 2.5908073370328584
Validation loss: 2.6291689691871034

Epoch: 6| Step: 10
Training loss: 3.010311050058287
Validation loss: 2.6297088535415214

Epoch: 6| Step: 11
Training loss: 3.3213991787923973
Validation loss: 2.6292148071294834

Epoch: 6| Step: 12
Training loss: 2.343921299078622
Validation loss: 2.629719111169137

Epoch: 6| Step: 13
Training loss: 3.165930076728231
Validation loss: 2.629622305530828

Epoch: 99| Step: 0
Training loss: 2.9268723453670162
Validation loss: 2.626336077542317

Epoch: 6| Step: 1
Training loss: 2.816826692433146
Validation loss: 2.629976970804634

Epoch: 6| Step: 2
Training loss: 2.9774117447259183
Validation loss: 2.6276586441920973

Epoch: 6| Step: 3
Training loss: 3.106680004053042
Validation loss: 2.6331432012268494

Epoch: 6| Step: 4
Training loss: 2.8395962403961024
Validation loss: 2.639716360784568

Epoch: 6| Step: 5
Training loss: 2.8577354191333115
Validation loss: 2.6401263938134214

Epoch: 6| Step: 6
Training loss: 2.9669434521888562
Validation loss: 2.6352552628539834

Epoch: 6| Step: 7
Training loss: 2.9475717151773053
Validation loss: 2.635928666069204

Epoch: 6| Step: 8
Training loss: 2.7762811401214647
Validation loss: 2.63824496599511

Epoch: 6| Step: 9
Training loss: 2.5751705002122818
Validation loss: 2.6441175714333864

Epoch: 6| Step: 10
Training loss: 2.9903778898855586
Validation loss: 2.659877225494472

Epoch: 6| Step: 11
Training loss: 2.9342914670971925
Validation loss: 2.6689446939092956

Epoch: 6| Step: 12
Training loss: 3.499712251006324
Validation loss: 2.672938631871759

Epoch: 6| Step: 13
Training loss: 3.5890837519692824
Validation loss: 2.6368026859804448

Epoch: 100| Step: 0
Training loss: 2.5896302562420352
Validation loss: 2.620956914925122

Epoch: 6| Step: 1
Training loss: 2.308433669167006
Validation loss: 2.6205632597976045

Epoch: 6| Step: 2
Training loss: 3.1364274703253265
Validation loss: 2.6187845890620296

Epoch: 6| Step: 3
Training loss: 3.1373896849186873
Validation loss: 2.6192691474101175

Epoch: 6| Step: 4
Training loss: 2.6201091798936527
Validation loss: 2.618892096324804

Epoch: 6| Step: 5
Training loss: 3.170700231524721
Validation loss: 2.615586988341696

Epoch: 6| Step: 6
Training loss: 3.0742255747621194
Validation loss: 2.6160262422288114

Epoch: 6| Step: 7
Training loss: 2.8330914637232043
Validation loss: 2.616544485038389

Epoch: 6| Step: 8
Training loss: 2.8947157498554046
Validation loss: 2.6167141149072712

Epoch: 6| Step: 9
Training loss: 3.38021137411787
Validation loss: 2.6157188177291646

Epoch: 6| Step: 10
Training loss: 3.4335168129001166
Validation loss: 2.61434203716315

Epoch: 6| Step: 11
Training loss: 3.3475904424869363
Validation loss: 2.614457532399605

Epoch: 6| Step: 12
Training loss: 2.91115132159287
Validation loss: 2.6135736092809263

Epoch: 6| Step: 13
Training loss: 2.000764223955036
Validation loss: 2.6134238253030238

Epoch: 101| Step: 0
Training loss: 2.9846648230303785
Validation loss: 2.615075490653201

Epoch: 6| Step: 1
Training loss: 2.9063600908982887
Validation loss: 2.617612455712162

Epoch: 6| Step: 2
Training loss: 2.6686808807213054
Validation loss: 2.618931157189338

Epoch: 6| Step: 3
Training loss: 2.654010771320623
Validation loss: 2.632468071202

Epoch: 6| Step: 4
Training loss: 2.8162774044621877
Validation loss: 2.651273346960722

Epoch: 6| Step: 5
Training loss: 3.3390736902359137
Validation loss: 2.6274950501642467

Epoch: 6| Step: 6
Training loss: 2.849773357816016
Validation loss: 2.634193648950071

Epoch: 6| Step: 7
Training loss: 3.3126584860837016
Validation loss: 2.62941205424902

Epoch: 6| Step: 8
Training loss: 3.4275362745462052
Validation loss: 2.6169772880862343

Epoch: 6| Step: 9
Training loss: 3.0883696038026898
Validation loss: 2.6153352665536356

Epoch: 6| Step: 10
Training loss: 2.787040511779572
Validation loss: 2.6100973586297096

Epoch: 6| Step: 11
Training loss: 2.6793387049785427
Validation loss: 2.613031939361111

Epoch: 6| Step: 12
Training loss: 3.248365431330636
Validation loss: 2.609935901374787

Epoch: 6| Step: 13
Training loss: 2.3021448624847634
Validation loss: 2.6109147765662133

Epoch: 102| Step: 0
Training loss: 2.69878926151865
Validation loss: 2.6098065932130887

Epoch: 6| Step: 1
Training loss: 3.174181771162741
Validation loss: 2.611706731406643

Epoch: 6| Step: 2
Training loss: 2.5682006322734723
Validation loss: 2.6114095471354295

Epoch: 6| Step: 3
Training loss: 3.227669366696417
Validation loss: 2.617670449132189

Epoch: 6| Step: 4
Training loss: 2.9919857425248
Validation loss: 2.6153831152600073

Epoch: 6| Step: 5
Training loss: 2.5803259500229454
Validation loss: 2.6169986299784243

Epoch: 6| Step: 6
Training loss: 2.4399337356199466
Validation loss: 2.624454199345471

Epoch: 6| Step: 7
Training loss: 3.413310721094016
Validation loss: 2.632072703367339

Epoch: 6| Step: 8
Training loss: 3.3229358317780164
Validation loss: 2.646706917893907

Epoch: 6| Step: 9
Training loss: 2.7963932410953927
Validation loss: 2.673524373506712

Epoch: 6| Step: 10
Training loss: 2.8010996021782666
Validation loss: 2.6961602312749506

Epoch: 6| Step: 11
Training loss: 3.3189956028177314
Validation loss: 2.6901798256512746

Epoch: 6| Step: 12
Training loss: 2.6581355863423592
Validation loss: 2.6496515487644317

Epoch: 6| Step: 13
Training loss: 3.51178202503131
Validation loss: 2.6288808661020715

Epoch: 103| Step: 0
Training loss: 2.733030064746517
Validation loss: 2.612367750634705

Epoch: 6| Step: 1
Training loss: 3.259802926080398
Validation loss: 2.611215616357569

Epoch: 6| Step: 2
Training loss: 2.828581883740059
Validation loss: 2.6080954375751797

Epoch: 6| Step: 3
Training loss: 3.3514108334528254
Validation loss: 2.6077136377434273

Epoch: 6| Step: 4
Training loss: 3.1325062437977103
Validation loss: 2.609101716703118

Epoch: 6| Step: 5
Training loss: 2.4463878862898145
Validation loss: 2.606693368745657

Epoch: 6| Step: 6
Training loss: 2.6655093204848397
Validation loss: 2.6085108887818786

Epoch: 6| Step: 7
Training loss: 2.9538904237562846
Validation loss: 2.606641635018739

Epoch: 6| Step: 8
Training loss: 3.0002568452876353
Validation loss: 2.6046622577927883

Epoch: 6| Step: 9
Training loss: 3.3080097209967483
Validation loss: 2.6046570442116432

Epoch: 6| Step: 10
Training loss: 2.695376718834142
Validation loss: 2.6151134350853606

Epoch: 6| Step: 11
Training loss: 3.015107105434029
Validation loss: 2.6159102341215874

Epoch: 6| Step: 12
Training loss: 2.939824260208117
Validation loss: 2.6283216258054667

Epoch: 6| Step: 13
Training loss: 3.0132906877262595
Validation loss: 2.6547868437540063

Epoch: 104| Step: 0
Training loss: 3.497152532587282
Validation loss: 2.6564616167873183

Epoch: 6| Step: 1
Training loss: 2.699289765369172
Validation loss: 2.6687794309221275

Epoch: 6| Step: 2
Training loss: 2.8851708997224876
Validation loss: 2.648955070220646

Epoch: 6| Step: 3
Training loss: 2.3878512778176924
Validation loss: 2.6204352293657465

Epoch: 6| Step: 4
Training loss: 2.8728493649181717
Validation loss: 2.6139563567946946

Epoch: 6| Step: 5
Training loss: 2.813906678117072
Validation loss: 2.601399758143302

Epoch: 6| Step: 6
Training loss: 3.2155953660791354
Validation loss: 2.6010863372700244

Epoch: 6| Step: 7
Training loss: 2.6717704172468837
Validation loss: 2.6031223951576172

Epoch: 6| Step: 8
Training loss: 3.3521312595605863
Validation loss: 2.6053986547097505

Epoch: 6| Step: 9
Training loss: 2.8350056780400004
Validation loss: 2.61057271543433

Epoch: 6| Step: 10
Training loss: 3.102795257412875
Validation loss: 2.607488966352089

Epoch: 6| Step: 11
Training loss: 2.6221117751610032
Validation loss: 2.61241879983435

Epoch: 6| Step: 12
Training loss: 3.668569432352709
Validation loss: 2.624985421878085

Epoch: 6| Step: 13
Training loss: 2.3934611532175887
Validation loss: 2.6196124672152905

Epoch: 105| Step: 0
Training loss: 2.651733687836789
Validation loss: 2.613806873299371

Epoch: 6| Step: 1
Training loss: 2.68993825976343
Validation loss: 2.6193990297983065

Epoch: 6| Step: 2
Training loss: 3.173397506845021
Validation loss: 2.621307838183619

Epoch: 6| Step: 3
Training loss: 3.4123685986158976
Validation loss: 2.619696479111405

Epoch: 6| Step: 4
Training loss: 2.6975456385247365
Validation loss: 2.611928049329444

Epoch: 6| Step: 5
Training loss: 2.604964497739818
Validation loss: 2.6072342650922335

Epoch: 6| Step: 6
Training loss: 3.4397592229635623
Validation loss: 2.6065992869898893

Epoch: 6| Step: 7
Training loss: 3.4253646266671463
Validation loss: 2.607078224743827

Epoch: 6| Step: 8
Training loss: 2.9972761822418494
Validation loss: 2.6167353374618987

Epoch: 6| Step: 9
Training loss: 3.145892986885683
Validation loss: 2.614765670910046

Epoch: 6| Step: 10
Training loss: 2.1866571164891795
Validation loss: 2.6305784241456096

Epoch: 6| Step: 11
Training loss: 2.781621929545682
Validation loss: 2.639254790281611

Epoch: 6| Step: 12
Training loss: 2.7063840062042352
Validation loss: 2.6585068662034192

Epoch: 6| Step: 13
Training loss: 3.2045067760855983
Validation loss: 2.661183612147073

Epoch: 106| Step: 0
Training loss: 3.203550580292998
Validation loss: 2.646432765243596

Epoch: 6| Step: 1
Training loss: 2.6425324722936643
Validation loss: 2.6267644759951927

Epoch: 6| Step: 2
Training loss: 3.2830053084926347
Validation loss: 2.6288623648599985

Epoch: 6| Step: 3
Training loss: 3.182202593383538
Validation loss: 2.6194618369918268

Epoch: 6| Step: 4
Training loss: 2.783609739349206
Validation loss: 2.6125194291934295

Epoch: 6| Step: 5
Training loss: 3.2252138288714067
Validation loss: 2.6129515763810818

Epoch: 6| Step: 6
Training loss: 2.8783208492548016
Validation loss: 2.605227779329252

Epoch: 6| Step: 7
Training loss: 3.632678876490757
Validation loss: 2.613437221135133

Epoch: 6| Step: 8
Training loss: 2.367501719553725
Validation loss: 2.6165979050938546

Epoch: 6| Step: 9
Training loss: 2.1045364835462923
Validation loss: 2.6081118332142252

Epoch: 6| Step: 10
Training loss: 2.9798969005184937
Validation loss: 2.600504494897202

Epoch: 6| Step: 11
Training loss: 2.4006993069677813
Validation loss: 2.602212281953516

Epoch: 6| Step: 12
Training loss: 3.247519059686915
Validation loss: 2.5979430791672016

Epoch: 6| Step: 13
Training loss: 2.964704145881579
Validation loss: 2.5988724276963926

Epoch: 107| Step: 0
Training loss: 3.1917772205883512
Validation loss: 2.5947684324557305

Epoch: 6| Step: 1
Training loss: 3.0270810117841735
Validation loss: 2.5952870677107813

Epoch: 6| Step: 2
Training loss: 3.448539070738812
Validation loss: 2.59289177796651

Epoch: 6| Step: 3
Training loss: 2.8528887447214446
Validation loss: 2.5980566618731507

Epoch: 6| Step: 4
Training loss: 2.9041622415414934
Validation loss: 2.5957505079612377

Epoch: 6| Step: 5
Training loss: 3.0165315362441136
Validation loss: 2.5947200702152506

Epoch: 6| Step: 6
Training loss: 2.6177064295765735
Validation loss: 2.5939035578991656

Epoch: 6| Step: 7
Training loss: 2.909418163532525
Validation loss: 2.609054807122303

Epoch: 6| Step: 8
Training loss: 2.9531957224294474
Validation loss: 2.6200184057416305

Epoch: 6| Step: 9
Training loss: 3.319655840396959
Validation loss: 2.6400816216907117

Epoch: 6| Step: 10
Training loss: 2.7589706280131026
Validation loss: 2.647100785657609

Epoch: 6| Step: 11
Training loss: 3.021329396174874
Validation loss: 2.6265196525280907

Epoch: 6| Step: 12
Training loss: 2.5219884910714163
Validation loss: 2.614994271875872

Epoch: 6| Step: 13
Training loss: 2.2732071907344555
Validation loss: 2.598866453788106

Epoch: 108| Step: 0
Training loss: 3.1943992298261907
Validation loss: 2.598559000921766

Epoch: 6| Step: 1
Training loss: 2.8089517887767963
Validation loss: 2.608491265170058

Epoch: 6| Step: 2
Training loss: 2.99618780791693
Validation loss: 2.604349308295162

Epoch: 6| Step: 3
Training loss: 2.344151373509456
Validation loss: 2.603206959909824

Epoch: 6| Step: 4
Training loss: 2.7415920382684353
Validation loss: 2.605326045383017

Epoch: 6| Step: 5
Training loss: 2.818433309895173
Validation loss: 2.601537545017435

Epoch: 6| Step: 6
Training loss: 3.020438192547565
Validation loss: 2.6157982401008715

Epoch: 6| Step: 7
Training loss: 2.8324191544687665
Validation loss: 2.605447831223404

Epoch: 6| Step: 8
Training loss: 1.9261312727631992
Validation loss: 2.5995013276635497

Epoch: 6| Step: 9
Training loss: 2.7322821755243787
Validation loss: 2.6114357556520824

Epoch: 6| Step: 10
Training loss: 3.760400463854823
Validation loss: 2.606652376819588

Epoch: 6| Step: 11
Training loss: 3.0751171616975026
Validation loss: 2.624785738285601

Epoch: 6| Step: 12
Training loss: 3.5133336717097525
Validation loss: 2.6167297188215195

Epoch: 6| Step: 13
Training loss: 2.7947120187855377
Validation loss: 2.614876251291762

Epoch: 109| Step: 0
Training loss: 3.0099986665032055
Validation loss: 2.606591827969051

Epoch: 6| Step: 1
Training loss: 2.529094956044928
Validation loss: 2.613429858144524

Epoch: 6| Step: 2
Training loss: 2.399113761669226
Validation loss: 2.606143348557481

Epoch: 6| Step: 3
Training loss: 2.587551477629681
Validation loss: 2.59427677305244

Epoch: 6| Step: 4
Training loss: 2.7083527393134883
Validation loss: 2.6020745150448543

Epoch: 6| Step: 5
Training loss: 3.3170526276750003
Validation loss: 2.5933590547524172

Epoch: 6| Step: 6
Training loss: 3.174203403294029
Validation loss: 2.6043546081322817

Epoch: 6| Step: 7
Training loss: 3.1733566356519294
Validation loss: 2.5979346193486905

Epoch: 6| Step: 8
Training loss: 3.1230928323404834
Validation loss: 2.589847634295456

Epoch: 6| Step: 9
Training loss: 2.9673039176966736
Validation loss: 2.5856296886619403

Epoch: 6| Step: 10
Training loss: 3.347941116088644
Validation loss: 2.5845552939084624

Epoch: 6| Step: 11
Training loss: 2.912585500354453
Validation loss: 2.584798181877104

Epoch: 6| Step: 12
Training loss: 2.5721453129489578
Validation loss: 2.590943048318788

Epoch: 6| Step: 13
Training loss: 2.9555066712558595
Validation loss: 2.5864596445557884

Epoch: 110| Step: 0
Training loss: 3.345567156004631
Validation loss: 2.588668948532193

Epoch: 6| Step: 1
Training loss: 3.080312193864434
Validation loss: 2.5890332985642828

Epoch: 6| Step: 2
Training loss: 3.0497813912514826
Validation loss: 2.5862467769563726

Epoch: 6| Step: 3
Training loss: 2.980610015441126
Validation loss: 2.587859302098239

Epoch: 6| Step: 4
Training loss: 2.5419931254200154
Validation loss: 2.586788564731138

Epoch: 6| Step: 5
Training loss: 2.2763612175154986
Validation loss: 2.583889210411156

Epoch: 6| Step: 6
Training loss: 3.0849286325567973
Validation loss: 2.5915883348957354

Epoch: 6| Step: 7
Training loss: 3.093126638785495
Validation loss: 2.600960636234846

Epoch: 6| Step: 8
Training loss: 2.7628610021232016
Validation loss: 2.6193149124448234

Epoch: 6| Step: 9
Training loss: 2.8872102930626973
Validation loss: 2.6158575046704198

Epoch: 6| Step: 10
Training loss: 2.395236087384006
Validation loss: 2.6230872393353137

Epoch: 6| Step: 11
Training loss: 3.3773312464528265
Validation loss: 2.65349086371084

Epoch: 6| Step: 12
Training loss: 2.9468274659806286
Validation loss: 2.6281545009403167

Epoch: 6| Step: 13
Training loss: 2.7322190859121918
Validation loss: 2.5943056873563246

Epoch: 111| Step: 0
Training loss: 2.918750091487385
Validation loss: 2.5984852622277406

Epoch: 6| Step: 1
Training loss: 3.4513561845061864
Validation loss: 2.598235195896397

Epoch: 6| Step: 2
Training loss: 3.403076093057809
Validation loss: 2.6077549216754927

Epoch: 6| Step: 3
Training loss: 2.3736747256492485
Validation loss: 2.5975671615207587

Epoch: 6| Step: 4
Training loss: 3.077188727025198
Validation loss: 2.584441711022665

Epoch: 6| Step: 5
Training loss: 2.986562516349273
Validation loss: 2.580328962415186

Epoch: 6| Step: 6
Training loss: 2.7742213901001236
Validation loss: 2.580672289496803

Epoch: 6| Step: 7
Training loss: 2.7453500275063383
Validation loss: 2.5815639407134747

Epoch: 6| Step: 8
Training loss: 2.5081642355798
Validation loss: 2.580209042245179

Epoch: 6| Step: 9
Training loss: 2.9183388594032773
Validation loss: 2.5799031966334405

Epoch: 6| Step: 10
Training loss: 2.9000440396878298
Validation loss: 2.576286888228047

Epoch: 6| Step: 11
Training loss: 2.8892050064780808
Validation loss: 2.5776811224454304

Epoch: 6| Step: 12
Training loss: 2.7177208015698824
Validation loss: 2.573958020565422

Epoch: 6| Step: 13
Training loss: 3.252460282103029
Validation loss: 2.578922774508872

Epoch: 112| Step: 0
Training loss: 3.1309574561602007
Validation loss: 2.602973086265265

Epoch: 6| Step: 1
Training loss: 2.446234970865294
Validation loss: 2.6431853635003377

Epoch: 6| Step: 2
Training loss: 2.6967449417668004
Validation loss: 2.7047338563769854

Epoch: 6| Step: 3
Training loss: 3.2291645337169537
Validation loss: 2.6468438891354817

Epoch: 6| Step: 4
Training loss: 3.5295058812888023
Validation loss: 2.5886570268930624

Epoch: 6| Step: 5
Training loss: 2.559498773919192
Validation loss: 2.576423904176874

Epoch: 6| Step: 6
Training loss: 3.0838903662840815
Validation loss: 2.5814049622579205

Epoch: 6| Step: 7
Training loss: 2.8874786574330464
Validation loss: 2.6026655422870104

Epoch: 6| Step: 8
Training loss: 3.368119467077561
Validation loss: 2.6141973299691084

Epoch: 6| Step: 9
Training loss: 3.6296563333133105
Validation loss: 2.6077419075846615

Epoch: 6| Step: 10
Training loss: 2.080990071146063
Validation loss: 2.592749669485732

Epoch: 6| Step: 11
Training loss: 3.1091549282692488
Validation loss: 2.589218192536301

Epoch: 6| Step: 12
Training loss: 2.7971441895924145
Validation loss: 2.5843918074486263

Epoch: 6| Step: 13
Training loss: 2.5352053409754887
Validation loss: 2.5832905261343138

Epoch: 113| Step: 0
Training loss: 3.1380489279516897
Validation loss: 2.5965254199890326

Epoch: 6| Step: 1
Training loss: 3.057430508963151
Validation loss: 2.657602539844006

Epoch: 6| Step: 2
Training loss: 2.631975623902025
Validation loss: 2.5915298992696205

Epoch: 6| Step: 3
Training loss: 2.6093562690839227
Validation loss: 2.588894223321498

Epoch: 6| Step: 4
Training loss: 3.166495586257863
Validation loss: 2.5962470516120333

Epoch: 6| Step: 5
Training loss: 3.0937170161791285
Validation loss: 2.618829036609227

Epoch: 6| Step: 6
Training loss: 3.1231082530905745
Validation loss: 2.6073783528907066

Epoch: 6| Step: 7
Training loss: 3.1654697632454942
Validation loss: 2.606747713525621

Epoch: 6| Step: 8
Training loss: 2.798502187657485
Validation loss: 2.6014586145881045

Epoch: 6| Step: 9
Training loss: 2.811457885953216
Validation loss: 2.600035263268857

Epoch: 6| Step: 10
Training loss: 2.8955349848535317
Validation loss: 2.6086890689816724

Epoch: 6| Step: 11
Training loss: 2.696744322898394
Validation loss: 2.6001390832896356

Epoch: 6| Step: 12
Training loss: 2.9263349958913984
Validation loss: 2.5904954520820582

Epoch: 6| Step: 13
Training loss: 3.145622263179008
Validation loss: 2.6048085399129994

Epoch: 114| Step: 0
Training loss: 3.1950229802745427
Validation loss: 2.621063998579081

Epoch: 6| Step: 1
Training loss: 2.5397080759815793
Validation loss: 2.6326388456410172

Epoch: 6| Step: 2
Training loss: 2.391917359331135
Validation loss: 2.627792745959482

Epoch: 6| Step: 3
Training loss: 2.812702765043335
Validation loss: 2.639878230218472

Epoch: 6| Step: 4
Training loss: 3.1749865674312923
Validation loss: 2.6212623030582387

Epoch: 6| Step: 5
Training loss: 3.2425292788604976
Validation loss: 2.6079375151641564

Epoch: 6| Step: 6
Training loss: 2.903713965650116
Validation loss: 2.588404593745605

Epoch: 6| Step: 7
Training loss: 2.810217121600808
Validation loss: 2.5768091925329797

Epoch: 6| Step: 8
Training loss: 2.9878846946335282
Validation loss: 2.5779786646067735

Epoch: 6| Step: 9
Training loss: 3.5368096800234414
Validation loss: 2.5743583730839807

Epoch: 6| Step: 10
Training loss: 3.03527517588959
Validation loss: 2.572734151896981

Epoch: 6| Step: 11
Training loss: 2.967009345276158
Validation loss: 2.5748820044768475

Epoch: 6| Step: 12
Training loss: 2.3495106410767668
Validation loss: 2.57395033349057

Epoch: 6| Step: 13
Training loss: 2.4480168315333746
Validation loss: 2.57180949699756

Epoch: 115| Step: 0
Training loss: 2.6730820455750117
Validation loss: 2.5741204457390614

Epoch: 6| Step: 1
Training loss: 3.0427860307986876
Validation loss: 2.572844802020871

Epoch: 6| Step: 2
Training loss: 2.706381627641382
Validation loss: 2.5882804400250046

Epoch: 6| Step: 3
Training loss: 3.429406921449501
Validation loss: 2.5937471089530457

Epoch: 6| Step: 4
Training loss: 2.5847425206411283
Validation loss: 2.614692483396835

Epoch: 6| Step: 5
Training loss: 2.987183692180251
Validation loss: 2.6337075321047645

Epoch: 6| Step: 6
Training loss: 3.076336801134374
Validation loss: 2.617725868545536

Epoch: 6| Step: 7
Training loss: 2.5698003287621027
Validation loss: 2.588813266522264

Epoch: 6| Step: 8
Training loss: 2.5696133761389146
Validation loss: 2.576352373358295

Epoch: 6| Step: 9
Training loss: 2.7251949870491368
Validation loss: 2.5837684275532404

Epoch: 6| Step: 10
Training loss: 2.4794941106235155
Validation loss: 2.5822603443253516

Epoch: 6| Step: 11
Training loss: 3.4117910130707183
Validation loss: 2.5825569409881477

Epoch: 6| Step: 12
Training loss: 2.93511119053532
Validation loss: 2.580351659564887

Epoch: 6| Step: 13
Training loss: 3.7902704260176145
Validation loss: 2.576075114147193

Epoch: 116| Step: 0
Training loss: 2.8542369267709833
Validation loss: 2.580863411644624

Epoch: 6| Step: 1
Training loss: 2.5289606172776704
Validation loss: 2.5841228226122515

Epoch: 6| Step: 2
Training loss: 3.3046993318530804
Validation loss: 2.581321240030266

Epoch: 6| Step: 3
Training loss: 2.071678660944464
Validation loss: 2.579396974892344

Epoch: 6| Step: 4
Training loss: 3.450622756700248
Validation loss: 2.5775683684940582

Epoch: 6| Step: 5
Training loss: 3.3793462389651077
Validation loss: 2.5922815559747017

Epoch: 6| Step: 6
Training loss: 3.6115585261903407
Validation loss: 2.5892871545714575

Epoch: 6| Step: 7
Training loss: 2.6447329197764873
Validation loss: 2.5821822086337543

Epoch: 6| Step: 8
Training loss: 2.57331204690513
Validation loss: 2.5792385606246198

Epoch: 6| Step: 9
Training loss: 2.873665209527755
Validation loss: 2.581350077981996

Epoch: 6| Step: 10
Training loss: 2.6839750371644797
Validation loss: 2.5788973728053275

Epoch: 6| Step: 11
Training loss: 2.3393909863295974
Validation loss: 2.5658418727182553

Epoch: 6| Step: 12
Training loss: 3.218103436464279
Validation loss: 2.585289036893575

Epoch: 6| Step: 13
Training loss: 2.320165558859975
Validation loss: 2.5790936193913754

Epoch: 117| Step: 0
Training loss: 2.9573819596248887
Validation loss: 2.5810749686558885

Epoch: 6| Step: 1
Training loss: 2.9172417936498145
Validation loss: 2.5960039767078387

Epoch: 6| Step: 2
Training loss: 2.9855354010393804
Validation loss: 2.5900798222232595

Epoch: 6| Step: 3
Training loss: 3.249621589345133
Validation loss: 2.5856357189315613

Epoch: 6| Step: 4
Training loss: 2.8748167228330175
Validation loss: 2.570258574773039

Epoch: 6| Step: 5
Training loss: 2.835597666826659
Validation loss: 2.5704387503253403

Epoch: 6| Step: 6
Training loss: 2.8381876780181923
Validation loss: 2.5672594476089925

Epoch: 6| Step: 7
Training loss: 2.7634796614915658
Validation loss: 2.561905652662308

Epoch: 6| Step: 8
Training loss: 2.903235071434086
Validation loss: 2.5607455820956773

Epoch: 6| Step: 9
Training loss: 3.0203608351627396
Validation loss: 2.5682460051663187

Epoch: 6| Step: 10
Training loss: 2.8083596165122335
Validation loss: 2.5666790601811744

Epoch: 6| Step: 11
Training loss: 2.031832450109054
Validation loss: 2.5658403750038112

Epoch: 6| Step: 12
Training loss: 3.2130054951919687
Validation loss: 2.5643894603865856

Epoch: 6| Step: 13
Training loss: 3.0463459827202075
Validation loss: 2.5674714635621974

Epoch: 118| Step: 0
Training loss: 2.473374007971072
Validation loss: 2.591162017971246

Epoch: 6| Step: 1
Training loss: 2.7285586157806794
Validation loss: 2.6033701062752246

Epoch: 6| Step: 2
Training loss: 2.657344099120927
Validation loss: 2.637359580644099

Epoch: 6| Step: 3
Training loss: 3.192108413231946
Validation loss: 2.6756530084276626

Epoch: 6| Step: 4
Training loss: 3.4997527171381297
Validation loss: 2.642139751550382

Epoch: 6| Step: 5
Training loss: 3.1629850837290676
Validation loss: 2.6007543312033827

Epoch: 6| Step: 6
Training loss: 2.9969097751990454
Validation loss: 2.5685991354756665

Epoch: 6| Step: 7
Training loss: 2.466346633185785
Validation loss: 2.5564869297285098

Epoch: 6| Step: 8
Training loss: 2.861716057320259
Validation loss: 2.5566812556197718

Epoch: 6| Step: 9
Training loss: 3.176439430566037
Validation loss: 2.5574558333095836

Epoch: 6| Step: 10
Training loss: 2.3331182812180895
Validation loss: 2.556446897708686

Epoch: 6| Step: 11
Training loss: 2.8413773584247393
Validation loss: 2.562739135244752

Epoch: 6| Step: 12
Training loss: 3.216263190018924
Validation loss: 2.55685206160768

Epoch: 6| Step: 13
Training loss: 3.19764083683373
Validation loss: 2.5608869868806736

Epoch: 119| Step: 0
Training loss: 3.4795213773596694
Validation loss: 2.5567263155455744

Epoch: 6| Step: 1
Training loss: 2.9978181534293027
Validation loss: 2.555975647036634

Epoch: 6| Step: 2
Training loss: 2.5823718609551904
Validation loss: 2.55492318827241

Epoch: 6| Step: 3
Training loss: 2.824453425912944
Validation loss: 2.5497415308662044

Epoch: 6| Step: 4
Training loss: 2.963144571866884
Validation loss: 2.553033473981397

Epoch: 6| Step: 5
Training loss: 2.8284773633434455
Validation loss: 2.5597924105070704

Epoch: 6| Step: 6
Training loss: 2.5776385224024048
Validation loss: 2.569982547466931

Epoch: 6| Step: 7
Training loss: 3.4686097812664465
Validation loss: 2.5965548799260505

Epoch: 6| Step: 8
Training loss: 2.307352471393587
Validation loss: 2.5931686064073762

Epoch: 6| Step: 9
Training loss: 2.2619135481202464
Validation loss: 2.636940839097202

Epoch: 6| Step: 10
Training loss: 3.0102063449836596
Validation loss: 2.6537150718803906

Epoch: 6| Step: 11
Training loss: 2.754187776501003
Validation loss: 2.645600626889605

Epoch: 6| Step: 12
Training loss: 2.780833952570926
Validation loss: 2.613550873022591

Epoch: 6| Step: 13
Training loss: 3.8707325725492017
Validation loss: 2.597655845368809

Epoch: 120| Step: 0
Training loss: 2.8666585907341804
Validation loss: 2.573554598398171

Epoch: 6| Step: 1
Training loss: 2.8344132291493174
Validation loss: 2.549653042588563

Epoch: 6| Step: 2
Training loss: 3.25408942358451
Validation loss: 2.5468174852210628

Epoch: 6| Step: 3
Training loss: 2.6043326261408675
Validation loss: 2.5457992048194553

Epoch: 6| Step: 4
Training loss: 2.9418883314898365
Validation loss: 2.543908295850123

Epoch: 6| Step: 5
Training loss: 2.801027422824183
Validation loss: 2.5470047834696974

Epoch: 6| Step: 6
Training loss: 2.809456937993175
Validation loss: 2.546080692353444

Epoch: 6| Step: 7
Training loss: 2.801528809616646
Validation loss: 2.5677699212061467

Epoch: 6| Step: 8
Training loss: 2.6948634561404425
Validation loss: 2.563530605389119

Epoch: 6| Step: 9
Training loss: 3.532516657418125
Validation loss: 2.570835278169385

Epoch: 6| Step: 10
Training loss: 2.7088001631390273
Validation loss: 2.568076432182011

Epoch: 6| Step: 11
Training loss: 2.290047183154578
Validation loss: 2.560024929992359

Epoch: 6| Step: 12
Training loss: 2.9356664251272044
Validation loss: 2.5507936793161146

Epoch: 6| Step: 13
Training loss: 3.423814755036645
Validation loss: 2.548211552347625

Epoch: 121| Step: 0
Training loss: 3.028639623100406
Validation loss: 2.545182713275571

Epoch: 6| Step: 1
Training loss: 3.229466053199744
Validation loss: 2.5482570417184847

Epoch: 6| Step: 2
Training loss: 3.106336019080991
Validation loss: 2.5461642312010206

Epoch: 6| Step: 3
Training loss: 2.6270050384043344
Validation loss: 2.5476242383665286

Epoch: 6| Step: 4
Training loss: 3.0779093555490817
Validation loss: 2.5443723990430143

Epoch: 6| Step: 5
Training loss: 2.5855310587407168
Validation loss: 2.5455094640207987

Epoch: 6| Step: 6
Training loss: 3.218123143459132
Validation loss: 2.555685981605928

Epoch: 6| Step: 7
Training loss: 2.6944976901881357
Validation loss: 2.5612116840810657

Epoch: 6| Step: 8
Training loss: 2.9486029986342155
Validation loss: 2.5649363123295537

Epoch: 6| Step: 9
Training loss: 2.8052410121468117
Validation loss: 2.579776662187268

Epoch: 6| Step: 10
Training loss: 2.8417284141238186
Validation loss: 2.588725016538297

Epoch: 6| Step: 11
Training loss: 2.635722377571211
Validation loss: 2.5744120172541125

Epoch: 6| Step: 12
Training loss: 2.716412032271806
Validation loss: 2.582281168991329

Epoch: 6| Step: 13
Training loss: 2.938021998998912
Validation loss: 2.5908970972790923

Epoch: 122| Step: 0
Training loss: 3.416936507075276
Validation loss: 2.594671240718203

Epoch: 6| Step: 1
Training loss: 3.4689414856441085
Validation loss: 2.5846829165624077

Epoch: 6| Step: 2
Training loss: 2.2378230666172274
Validation loss: 2.584842213112284

Epoch: 6| Step: 3
Training loss: 2.8730926821212353
Validation loss: 2.572919128092631

Epoch: 6| Step: 4
Training loss: 2.7193796590643715
Validation loss: 2.5582282704504626

Epoch: 6| Step: 5
Training loss: 2.5658714631400468
Validation loss: 2.5469178921462152

Epoch: 6| Step: 6
Training loss: 2.7519628282298774
Validation loss: 2.5419403088905246

Epoch: 6| Step: 7
Training loss: 3.0462649003557862
Validation loss: 2.542215766746815

Epoch: 6| Step: 8
Training loss: 3.021119799130488
Validation loss: 2.5418654087930905

Epoch: 6| Step: 9
Training loss: 2.953830372366257
Validation loss: 2.542819089848738

Epoch: 6| Step: 10
Training loss: 2.66903312306952
Validation loss: 2.5353983707488954

Epoch: 6| Step: 11
Training loss: 2.9478090264356425
Validation loss: 2.5421821082347966

Epoch: 6| Step: 12
Training loss: 2.4117847548517575
Validation loss: 2.556635139014669

Epoch: 6| Step: 13
Training loss: 3.3129300971885027
Validation loss: 2.581431059289993

Epoch: 123| Step: 0
Training loss: 2.3344882309503205
Validation loss: 2.57060245000946

Epoch: 6| Step: 1
Training loss: 2.707265516220635
Validation loss: 2.5666393519358324

Epoch: 6| Step: 2
Training loss: 3.358363367392857
Validation loss: 2.5709673506171016

Epoch: 6| Step: 3
Training loss: 2.097318199381192
Validation loss: 2.564140890941719

Epoch: 6| Step: 4
Training loss: 2.7119429864601328
Validation loss: 2.5539284678269105

Epoch: 6| Step: 5
Training loss: 3.513819387667492
Validation loss: 2.5544943301050713

Epoch: 6| Step: 6
Training loss: 3.374527509605743
Validation loss: 2.5483308133371234

Epoch: 6| Step: 7
Training loss: 3.313244717933326
Validation loss: 2.5460156741797095

Epoch: 6| Step: 8
Training loss: 2.781809718356571
Validation loss: 2.5394846646168747

Epoch: 6| Step: 9
Training loss: 2.3257115290515986
Validation loss: 2.544271293140739

Epoch: 6| Step: 10
Training loss: 3.058669516841732
Validation loss: 2.5462399462342633

Epoch: 6| Step: 11
Training loss: 2.26886134018936
Validation loss: 2.54153696398645

Epoch: 6| Step: 12
Training loss: 3.0939468167054924
Validation loss: 2.555418979227079

Epoch: 6| Step: 13
Training loss: 2.609146747770966
Validation loss: 2.5579954072532174

Epoch: 124| Step: 0
Training loss: 3.0015183421217437
Validation loss: 2.6036631048492715

Epoch: 6| Step: 1
Training loss: 2.0087083532340007
Validation loss: 2.6568320961795564

Epoch: 6| Step: 2
Training loss: 2.1391598776142535
Validation loss: 2.693938834210204

Epoch: 6| Step: 3
Training loss: 2.8633688461831097
Validation loss: 2.7669176524783934

Epoch: 6| Step: 4
Training loss: 3.489502696154179
Validation loss: 2.8327640269729

Epoch: 6| Step: 5
Training loss: 2.9457188333563726
Validation loss: 2.832911028023919

Epoch: 6| Step: 6
Training loss: 3.3326994929087412
Validation loss: 2.701204251878094

Epoch: 6| Step: 7
Training loss: 3.4380675800953555
Validation loss: 2.5657624007240636

Epoch: 6| Step: 8
Training loss: 3.2940708185121106
Validation loss: 2.537489946305937

Epoch: 6| Step: 9
Training loss: 2.666220677353602
Validation loss: 2.5494135346104954

Epoch: 6| Step: 10
Training loss: 2.5643088306701154
Validation loss: 2.626249450595135

Epoch: 6| Step: 11
Training loss: 2.875216931990673
Validation loss: 2.7269143287945874

Epoch: 6| Step: 12
Training loss: 3.464529821028871
Validation loss: 2.7736704137978117

Epoch: 6| Step: 13
Training loss: 3.4230518842950195
Validation loss: 2.604663738105412

Epoch: 125| Step: 0
Training loss: 3.0816431997866034
Validation loss: 2.5398113076096105

Epoch: 6| Step: 1
Training loss: 3.3088422049201056
Validation loss: 2.5437073724694352

Epoch: 6| Step: 2
Training loss: 2.8331655190829403
Validation loss: 2.543397581007495

Epoch: 6| Step: 3
Training loss: 2.548564982076186
Validation loss: 2.5938550050891185

Epoch: 6| Step: 4
Training loss: 3.083307386409424
Validation loss: 2.651305075200637

Epoch: 6| Step: 5
Training loss: 3.264695030562292
Validation loss: 2.7329367834944365

Epoch: 6| Step: 6
Training loss: 2.8092860189737476
Validation loss: 2.6656821905027632

Epoch: 6| Step: 7
Training loss: 3.116651598916035
Validation loss: 2.5970006865120485

Epoch: 6| Step: 8
Training loss: 2.65326487034342
Validation loss: 2.56152747383025

Epoch: 6| Step: 9
Training loss: 2.3336566519393176
Validation loss: 2.5912973861825903

Epoch: 6| Step: 10
Training loss: 2.573467694993052
Validation loss: 2.6215225953838632

Epoch: 6| Step: 11
Training loss: 3.4360265174704
Validation loss: 2.684414405556923

Epoch: 6| Step: 12
Training loss: 2.6023220293827194
Validation loss: 2.71506141208492

Epoch: 6| Step: 13
Training loss: 3.2351609901332696
Validation loss: 2.857768877634895

Epoch: 126| Step: 0
Training loss: 3.0108886841487448
Validation loss: 2.7771539726683425

Epoch: 6| Step: 1
Training loss: 3.094758148850719
Validation loss: 2.620188804783507

Epoch: 6| Step: 2
Training loss: 2.7943763867031164
Validation loss: 2.5950911259924725

Epoch: 6| Step: 3
Training loss: 2.6082020938831834
Validation loss: 2.576684750728279

Epoch: 6| Step: 4
Training loss: 2.6528537355458757
Validation loss: 2.57879703298401

Epoch: 6| Step: 5
Training loss: 2.2095750041039537
Validation loss: 2.5819130362960947

Epoch: 6| Step: 6
Training loss: 3.3102286846994913
Validation loss: 2.5961178950739225

Epoch: 6| Step: 7
Training loss: 2.822397407174163
Validation loss: 2.6026224853576476

Epoch: 6| Step: 8
Training loss: 3.223358114858027
Validation loss: 2.5988376977504455

Epoch: 6| Step: 9
Training loss: 3.3947263602317124
Validation loss: 2.6143609245555464

Epoch: 6| Step: 10
Training loss: 2.887528529170734
Validation loss: 2.6519477385859465

Epoch: 6| Step: 11
Training loss: 2.724781405579339
Validation loss: 2.6798682765182518

Epoch: 6| Step: 12
Training loss: 3.510444180676014
Validation loss: 2.681041493966345

Epoch: 6| Step: 13
Training loss: 2.724403466541738
Validation loss: 2.6485287065621943

Epoch: 127| Step: 0
Training loss: 2.4276127926740676
Validation loss: 2.614641202090044

Epoch: 6| Step: 1
Training loss: 3.1652703134529543
Validation loss: 2.5897448945016217

Epoch: 6| Step: 2
Training loss: 3.0579045909021665
Validation loss: 2.568448540328112

Epoch: 6| Step: 3
Training loss: 3.0493698469721653
Validation loss: 2.5529383496359643

Epoch: 6| Step: 4
Training loss: 2.9864359025985454
Validation loss: 2.5508924152015795

Epoch: 6| Step: 5
Training loss: 2.5056517612382194
Validation loss: 2.5479258227822523

Epoch: 6| Step: 6
Training loss: 3.6196695796585856
Validation loss: 2.539818638742836

Epoch: 6| Step: 7
Training loss: 2.859481392637285
Validation loss: 2.548991403208836

Epoch: 6| Step: 8
Training loss: 2.784877083632447
Validation loss: 2.5452787156845083

Epoch: 6| Step: 9
Training loss: 3.150938191041622
Validation loss: 2.5336302303445577

Epoch: 6| Step: 10
Training loss: 2.382232795613976
Validation loss: 2.522873885413872

Epoch: 6| Step: 11
Training loss: 2.5707303435121225
Validation loss: 2.5305504317690812

Epoch: 6| Step: 12
Training loss: 2.8966318763016194
Validation loss: 2.5337500997534685

Epoch: 6| Step: 13
Training loss: 2.3321299060803256
Validation loss: 2.5325127068567572

Epoch: 128| Step: 0
Training loss: 2.954438739796768
Validation loss: 2.5500009492103892

Epoch: 6| Step: 1
Training loss: 2.964431030335866
Validation loss: 2.5820825345902585

Epoch: 6| Step: 2
Training loss: 2.855835772304497
Validation loss: 2.624193258002072

Epoch: 6| Step: 3
Training loss: 2.330566048197516
Validation loss: 2.6460422588087855

Epoch: 6| Step: 4
Training loss: 2.8081108601305615
Validation loss: 2.6667936949187183

Epoch: 6| Step: 5
Training loss: 3.361258613005101
Validation loss: 2.7032708673943

Epoch: 6| Step: 6
Training loss: 3.2857919411338146
Validation loss: 2.6698328165622867

Epoch: 6| Step: 7
Training loss: 2.530877921932446
Validation loss: 2.5926597548508514

Epoch: 6| Step: 8
Training loss: 2.731306959732368
Validation loss: 2.541943439387179

Epoch: 6| Step: 9
Training loss: 3.752281003860664
Validation loss: 2.5222285938406825

Epoch: 6| Step: 10
Training loss: 2.230476980645114
Validation loss: 2.5176441117758164

Epoch: 6| Step: 11
Training loss: 2.491103364004354
Validation loss: 2.5254837456872936

Epoch: 6| Step: 12
Training loss: 2.5764498730548318
Validation loss: 2.5412063813938572

Epoch: 6| Step: 13
Training loss: 2.9663662626210057
Validation loss: 2.5472429418532085

Epoch: 129| Step: 0
Training loss: 2.290544570405936
Validation loss: 2.5369431028481646

Epoch: 6| Step: 1
Training loss: 3.058420383416776
Validation loss: 2.528671975383659

Epoch: 6| Step: 2
Training loss: 3.294305315201617
Validation loss: 2.5191939467514315

Epoch: 6| Step: 3
Training loss: 2.5203946785438833
Validation loss: 2.515311128131636

Epoch: 6| Step: 4
Training loss: 3.129930497637918
Validation loss: 2.518494973635449

Epoch: 6| Step: 5
Training loss: 2.7038809540630884
Validation loss: 2.528594169918161

Epoch: 6| Step: 6
Training loss: 2.901757654746075
Validation loss: 2.544077471412294

Epoch: 6| Step: 7
Training loss: 2.733043499055716
Validation loss: 2.546766274655049

Epoch: 6| Step: 8
Training loss: 2.7743849304667734
Validation loss: 2.5532158842212644

Epoch: 6| Step: 9
Training loss: 2.040256545260251
Validation loss: 2.541553646770889

Epoch: 6| Step: 10
Training loss: 3.054447096318577
Validation loss: 2.5558920838304364

Epoch: 6| Step: 11
Training loss: 2.875219253804184
Validation loss: 2.569677581749412

Epoch: 6| Step: 12
Training loss: 3.1112432186900345
Validation loss: 2.585471657270005

Epoch: 6| Step: 13
Training loss: 3.2557520216535942
Validation loss: 2.616005664630271

Epoch: 130| Step: 0
Training loss: 2.680392959310407
Validation loss: 2.656501712731716

Epoch: 6| Step: 1
Training loss: 2.4975799291152496
Validation loss: 2.6699164767887797

Epoch: 6| Step: 2
Training loss: 3.007050494486516
Validation loss: 2.599001010376114

Epoch: 6| Step: 3
Training loss: 2.668510058156228
Validation loss: 2.5574742416537606

Epoch: 6| Step: 4
Training loss: 3.0619560848602636
Validation loss: 2.531682909092014

Epoch: 6| Step: 5
Training loss: 2.6926250826118094
Validation loss: 2.5218890347491594

Epoch: 6| Step: 6
Training loss: 3.0027392914742825
Validation loss: 2.5142348380861788

Epoch: 6| Step: 7
Training loss: 2.7296184913196746
Validation loss: 2.5216078179114096

Epoch: 6| Step: 8
Training loss: 2.8303188856031154
Validation loss: 2.5142537046073117

Epoch: 6| Step: 9
Training loss: 3.40060362786881
Validation loss: 2.517705567673327

Epoch: 6| Step: 10
Training loss: 2.840638858773949
Validation loss: 2.520587176558492

Epoch: 6| Step: 11
Training loss: 2.455833737576437
Validation loss: 2.5185081028062735

Epoch: 6| Step: 12
Training loss: 3.2242921688223602
Validation loss: 2.514888537666825

Epoch: 6| Step: 13
Training loss: 3.208697872176829
Validation loss: 2.5167790051738512

Epoch: 131| Step: 0
Training loss: 3.086990833383784
Validation loss: 2.525421776598565

Epoch: 6| Step: 1
Training loss: 3.2463007194190867
Validation loss: 2.541153561627348

Epoch: 6| Step: 2
Training loss: 2.4137654044530454
Validation loss: 2.5622987655671605

Epoch: 6| Step: 3
Training loss: 2.9081886962368726
Validation loss: 2.568423117879848

Epoch: 6| Step: 4
Training loss: 3.0175746485619133
Validation loss: 2.5623588513133213

Epoch: 6| Step: 5
Training loss: 2.3384092388308577
Validation loss: 2.5601008779828454

Epoch: 6| Step: 6
Training loss: 2.047272272359402
Validation loss: 2.583329847441302

Epoch: 6| Step: 7
Training loss: 3.014993710234551
Validation loss: 2.566029019196455

Epoch: 6| Step: 8
Training loss: 3.3042560412973745
Validation loss: 2.5497619856829994

Epoch: 6| Step: 9
Training loss: 3.1946582077670103
Validation loss: 2.5378145418277684

Epoch: 6| Step: 10
Training loss: 2.858810285658992
Validation loss: 2.5344677921639467

Epoch: 6| Step: 11
Training loss: 2.431438440703399
Validation loss: 2.529700034213851

Epoch: 6| Step: 12
Training loss: 2.6609303248650877
Validation loss: 2.5345029560689993

Epoch: 6| Step: 13
Training loss: 3.0473249054350386
Validation loss: 2.5262423818801913

Epoch: 132| Step: 0
Training loss: 2.879443508001413
Validation loss: 2.532965739587483

Epoch: 6| Step: 1
Training loss: 2.836289060886047
Validation loss: 2.524083464666527

Epoch: 6| Step: 2
Training loss: 2.8044991177594745
Validation loss: 2.5227091464588858

Epoch: 6| Step: 3
Training loss: 2.433087585616224
Validation loss: 2.526962294850648

Epoch: 6| Step: 4
Training loss: 2.9657474794008114
Validation loss: 2.528626730838186

Epoch: 6| Step: 5
Training loss: 2.8389147218780106
Validation loss: 2.5277939911282226

Epoch: 6| Step: 6
Training loss: 2.694272755749322
Validation loss: 2.534986683352081

Epoch: 6| Step: 7
Training loss: 2.7146926947634338
Validation loss: 2.546827266388486

Epoch: 6| Step: 8
Training loss: 2.5317096057470794
Validation loss: 2.5653000666797734

Epoch: 6| Step: 9
Training loss: 2.6870964989379322
Validation loss: 2.588402355366661

Epoch: 6| Step: 10
Training loss: 3.1020830231703345
Validation loss: 2.6283176442573573

Epoch: 6| Step: 11
Training loss: 2.9139202993433595
Validation loss: 2.646366249490224

Epoch: 6| Step: 12
Training loss: 3.5652463265556498
Validation loss: 2.628433253006253

Epoch: 6| Step: 13
Training loss: 2.786127592523808
Validation loss: 2.5566102358424114

Epoch: 133| Step: 0
Training loss: 2.4276026769073002
Validation loss: 2.5290991201539246

Epoch: 6| Step: 1
Training loss: 2.9429008668463434
Validation loss: 2.5238110813001953

Epoch: 6| Step: 2
Training loss: 3.1019872571534655
Validation loss: 2.52167894510864

Epoch: 6| Step: 3
Training loss: 3.0203699918545266
Validation loss: 2.5212004402812194

Epoch: 6| Step: 4
Training loss: 2.694512201442618
Validation loss: 2.5200470681506237

Epoch: 6| Step: 5
Training loss: 2.8793754454095493
Validation loss: 2.519901119199238

Epoch: 6| Step: 6
Training loss: 2.6590916412044248
Validation loss: 2.5202082773730057

Epoch: 6| Step: 7
Training loss: 2.2845426860585967
Validation loss: 2.5168705641759743

Epoch: 6| Step: 8
Training loss: 2.5837813778445136
Validation loss: 2.519399910845681

Epoch: 6| Step: 9
Training loss: 2.746867910469289
Validation loss: 2.515519071832915

Epoch: 6| Step: 10
Training loss: 2.7131424876899297
Validation loss: 2.5128221713324623

Epoch: 6| Step: 11
Training loss: 2.8608924716341453
Validation loss: 2.5162238542797057

Epoch: 6| Step: 12
Training loss: 3.8663134271035973
Validation loss: 2.5104916200174023

Epoch: 6| Step: 13
Training loss: 3.201843154096568
Validation loss: 2.519505386874816

Epoch: 134| Step: 0
Training loss: 3.40002488519874
Validation loss: 2.528197392027628

Epoch: 6| Step: 1
Training loss: 2.570918327752485
Validation loss: 2.549962528507592

Epoch: 6| Step: 2
Training loss: 2.983407547807285
Validation loss: 2.541624554695912

Epoch: 6| Step: 3
Training loss: 2.523579218519513
Validation loss: 2.5295012507693957

Epoch: 6| Step: 4
Training loss: 3.0338230813634586
Validation loss: 2.5159943103876916

Epoch: 6| Step: 5
Training loss: 2.8182557444510943
Validation loss: 2.517359945551332

Epoch: 6| Step: 6
Training loss: 3.18641823756587
Validation loss: 2.511863400553401

Epoch: 6| Step: 7
Training loss: 2.8052756880190968
Validation loss: 2.5206468042449317

Epoch: 6| Step: 8
Training loss: 2.4780398033091937
Validation loss: 2.513135789939653

Epoch: 6| Step: 9
Training loss: 3.1694473973880006
Validation loss: 2.5219276711933976

Epoch: 6| Step: 10
Training loss: 2.189274313547413
Validation loss: 2.515248106275008

Epoch: 6| Step: 11
Training loss: 2.5632354797350856
Validation loss: 2.5219749307169024

Epoch: 6| Step: 12
Training loss: 3.0120493191636517
Validation loss: 2.526154985456087

Epoch: 6| Step: 13
Training loss: 2.4928369901500678
Validation loss: 2.532688778688613

Epoch: 135| Step: 0
Training loss: 3.2273947171296307
Validation loss: 2.553491122671806

Epoch: 6| Step: 1
Training loss: 2.738806049812803
Validation loss: 2.571112098351308

Epoch: 6| Step: 2
Training loss: 2.24549244668625
Validation loss: 2.5732838770220923

Epoch: 6| Step: 3
Training loss: 3.1950762598431637
Validation loss: 2.609666427481312

Epoch: 6| Step: 4
Training loss: 2.7057665668407904
Validation loss: 2.61750480676409

Epoch: 6| Step: 5
Training loss: 2.8515897566655384
Validation loss: 2.609462926909848

Epoch: 6| Step: 6
Training loss: 2.9706289669614727
Validation loss: 2.5951523807928214

Epoch: 6| Step: 7
Training loss: 2.602515060571779
Validation loss: 2.556573669303383

Epoch: 6| Step: 8
Training loss: 3.458083239478499
Validation loss: 2.553621890047763

Epoch: 6| Step: 9
Training loss: 2.498021105528244
Validation loss: 2.5334175640161756

Epoch: 6| Step: 10
Training loss: 3.1465152902345297
Validation loss: 2.5248667897593364

Epoch: 6| Step: 11
Training loss: 2.938348850404731
Validation loss: 2.542642456168671

Epoch: 6| Step: 12
Training loss: 1.9951520814985773
Validation loss: 2.5407555949580067

Epoch: 6| Step: 13
Training loss: 2.0946653272663758
Validation loss: 2.534035450898504

Epoch: 136| Step: 0
Training loss: 2.169607831615053
Validation loss: 2.5246176728812686

Epoch: 6| Step: 1
Training loss: 2.571608938219015
Validation loss: 2.5213508274789445

Epoch: 6| Step: 2
Training loss: 3.1778769247183294
Validation loss: 2.5243774236223193

Epoch: 6| Step: 3
Training loss: 3.0733013020112976
Validation loss: 2.5229168360506953

Epoch: 6| Step: 4
Training loss: 2.392468906945945
Validation loss: 2.526666243105578

Epoch: 6| Step: 5
Training loss: 3.135335082622313
Validation loss: 2.5354498190107777

Epoch: 6| Step: 6
Training loss: 2.9786877191574272
Validation loss: 2.534868391468078

Epoch: 6| Step: 7
Training loss: 2.9584273918851958
Validation loss: 2.5396024002807285

Epoch: 6| Step: 8
Training loss: 2.7993508574187174
Validation loss: 2.5402602886226444

Epoch: 6| Step: 9
Training loss: 2.6985104372629523
Validation loss: 2.534183594394429

Epoch: 6| Step: 10
Training loss: 2.963262043092908
Validation loss: 2.5513988083299397

Epoch: 6| Step: 11
Training loss: 2.194788860167773
Validation loss: 2.5476170907013804

Epoch: 6| Step: 12
Training loss: 3.019977018508879
Validation loss: 2.5492844057488857

Epoch: 6| Step: 13
Training loss: 2.8660993044167746
Validation loss: 2.5457720627831697

Epoch: 137| Step: 0
Training loss: 2.9967614813696306
Validation loss: 2.5372811105486193

Epoch: 6| Step: 1
Training loss: 3.209089280942729
Validation loss: 2.537805148179022

Epoch: 6| Step: 2
Training loss: 2.8517855622301505
Validation loss: 2.539353657854893

Epoch: 6| Step: 3
Training loss: 2.92932321953999
Validation loss: 2.53343055817294

Epoch: 6| Step: 4
Training loss: 2.6944044269679437
Validation loss: 2.539216106050105

Epoch: 6| Step: 5
Training loss: 2.842106270743446
Validation loss: 2.5326031332261434

Epoch: 6| Step: 6
Training loss: 2.8620606197652307
Validation loss: 2.546437519648909

Epoch: 6| Step: 7
Training loss: 2.131487312416939
Validation loss: 2.547704472374592

Epoch: 6| Step: 8
Training loss: 2.4519250935910133
Validation loss: 2.542703672849257

Epoch: 6| Step: 9
Training loss: 2.7073438940016805
Validation loss: 2.542211894381744

Epoch: 6| Step: 10
Training loss: 2.584208483791781
Validation loss: 2.5406551775881763

Epoch: 6| Step: 11
Training loss: 2.883756818891449
Validation loss: 2.538807404658295

Epoch: 6| Step: 12
Training loss: 3.028319210284788
Validation loss: 2.5399311144279846

Epoch: 6| Step: 13
Training loss: 2.8997671362680277
Validation loss: 2.5431992885793337

Epoch: 138| Step: 0
Training loss: 3.140143665987592
Validation loss: 2.5429540605093837

Epoch: 6| Step: 1
Training loss: 3.049740426946682
Validation loss: 2.5454026493562263

Epoch: 6| Step: 2
Training loss: 2.6186506593931047
Validation loss: 2.541204238641877

Epoch: 6| Step: 3
Training loss: 2.622190334194426
Validation loss: 2.5348697628591026

Epoch: 6| Step: 4
Training loss: 2.8587062032703203
Validation loss: 2.536110002649191

Epoch: 6| Step: 5
Training loss: 2.626295859777553
Validation loss: 2.528844742141315

Epoch: 6| Step: 6
Training loss: 2.5895171959293717
Validation loss: 2.52053751608576

Epoch: 6| Step: 7
Training loss: 2.928106507005787
Validation loss: 2.519194195565186

Epoch: 6| Step: 8
Training loss: 2.3335503976764875
Validation loss: 2.522785353052676

Epoch: 6| Step: 9
Training loss: 2.4949006526027087
Validation loss: 2.5149529038948772

Epoch: 6| Step: 10
Training loss: 2.4736567156119085
Validation loss: 2.5210711832161206

Epoch: 6| Step: 11
Training loss: 3.104166393578707
Validation loss: 2.515853872443577

Epoch: 6| Step: 12
Training loss: 2.941378690836199
Validation loss: 2.514497296683241

Epoch: 6| Step: 13
Training loss: 3.4947728224282764
Validation loss: 2.522880189655524

Epoch: 139| Step: 0
Training loss: 2.6341755674992804
Validation loss: 2.5145257540343793

Epoch: 6| Step: 1
Training loss: 2.9317331725169713
Validation loss: 2.5235581867750545

Epoch: 6| Step: 2
Training loss: 2.5516985752428685
Validation loss: 2.522159518087556

Epoch: 6| Step: 3
Training loss: 1.8934322984557566
Validation loss: 2.52116611582173

Epoch: 6| Step: 4
Training loss: 3.09231256556866
Validation loss: 2.5270531663505102

Epoch: 6| Step: 5
Training loss: 3.123159858611372
Validation loss: 2.521261065189036

Epoch: 6| Step: 6
Training loss: 2.843232998644768
Validation loss: 2.5200088672771663

Epoch: 6| Step: 7
Training loss: 3.2721760579429104
Validation loss: 2.5125358425116926

Epoch: 6| Step: 8
Training loss: 3.0889639777457014
Validation loss: 2.5150869705342522

Epoch: 6| Step: 9
Training loss: 2.811596195383248
Validation loss: 2.5057673665942826

Epoch: 6| Step: 10
Training loss: 2.6314668470900378
Validation loss: 2.5043488977470307

Epoch: 6| Step: 11
Training loss: 2.3697842999577863
Validation loss: 2.5074095206892504

Epoch: 6| Step: 12
Training loss: 2.9381060685239837
Validation loss: 2.5091041436028663

Epoch: 6| Step: 13
Training loss: 2.385772067806895
Validation loss: 2.5046443652768198

Epoch: 140| Step: 0
Training loss: 2.638054493836542
Validation loss: 2.5013408408167868

Epoch: 6| Step: 1
Training loss: 2.58466070180419
Validation loss: 2.507591608144648

Epoch: 6| Step: 2
Training loss: 3.3287206842017576
Validation loss: 2.493443347047391

Epoch: 6| Step: 3
Training loss: 2.7796028488847244
Validation loss: 2.499157363643468

Epoch: 6| Step: 4
Training loss: 2.8054856038789038
Validation loss: 2.5038568658434768

Epoch: 6| Step: 5
Training loss: 3.0549832954511946
Validation loss: 2.495154091643761

Epoch: 6| Step: 6
Training loss: 2.7681867728421756
Validation loss: 2.5029163875010974

Epoch: 6| Step: 7
Training loss: 2.659715075326939
Validation loss: 2.503814112484145

Epoch: 6| Step: 8
Training loss: 3.485574148161818
Validation loss: 2.5030648257187957

Epoch: 6| Step: 9
Training loss: 1.7761663875994242
Validation loss: 2.514093549313303

Epoch: 6| Step: 10
Training loss: 2.9288102527758837
Validation loss: 2.525940104452426

Epoch: 6| Step: 11
Training loss: 2.536187524980208
Validation loss: 2.5277889263032387

Epoch: 6| Step: 12
Training loss: 2.4281014420435576
Validation loss: 2.5359745898913544

Epoch: 6| Step: 13
Training loss: 2.9678484702282777
Validation loss: 2.544840716123097

Epoch: 141| Step: 0
Training loss: 2.7188904824629185
Validation loss: 2.5444765829689158

Epoch: 6| Step: 1
Training loss: 2.620807114688825
Validation loss: 2.561061063949604

Epoch: 6| Step: 2
Training loss: 2.507848436329845
Validation loss: 2.5593341146048654

Epoch: 6| Step: 3
Training loss: 3.0060245104188303
Validation loss: 2.5561352201755363

Epoch: 6| Step: 4
Training loss: 2.693868410557059
Validation loss: 2.5372354890594777

Epoch: 6| Step: 5
Training loss: 3.1021432789240464
Validation loss: 2.5054787049087324

Epoch: 6| Step: 6
Training loss: 2.7580793646056714
Validation loss: 2.5004006290396346

Epoch: 6| Step: 7
Training loss: 2.8585068682457466
Validation loss: 2.5016108973162052

Epoch: 6| Step: 8
Training loss: 2.6475158708220965
Validation loss: 2.5025739360763883

Epoch: 6| Step: 9
Training loss: 2.9828768659773752
Validation loss: 2.5070482858836183

Epoch: 6| Step: 10
Training loss: 2.972579734509259
Validation loss: 2.510517810868435

Epoch: 6| Step: 11
Training loss: 2.52003121553494
Validation loss: 2.5188233737207013

Epoch: 6| Step: 12
Training loss: 2.8314929108488003
Validation loss: 2.5283775083728446

Epoch: 6| Step: 13
Training loss: 2.7192164053904357
Validation loss: 2.530209295858729

Epoch: 142| Step: 0
Training loss: 2.015923647971188
Validation loss: 2.53162947544418

Epoch: 6| Step: 1
Training loss: 3.12009411058563
Validation loss: 2.535571373793975

Epoch: 6| Step: 2
Training loss: 3.1863558342568146
Validation loss: 2.560379856003575

Epoch: 6| Step: 3
Training loss: 2.4889398059670005
Validation loss: 2.6044472413222617

Epoch: 6| Step: 4
Training loss: 2.930460509998246
Validation loss: 2.6394997670283877

Epoch: 6| Step: 5
Training loss: 3.395497982262158
Validation loss: 2.679751542236536

Epoch: 6| Step: 6
Training loss: 2.5594018955703923
Validation loss: 2.626942233945825

Epoch: 6| Step: 7
Training loss: 2.4809221949587545
Validation loss: 2.5704313060548203

Epoch: 6| Step: 8
Training loss: 2.8668660079785098
Validation loss: 2.5418584224424263

Epoch: 6| Step: 9
Training loss: 2.945357183223722
Validation loss: 2.524370055770041

Epoch: 6| Step: 10
Training loss: 2.9950052644049685
Validation loss: 2.5128412994330818

Epoch: 6| Step: 11
Training loss: 2.832286155015344
Validation loss: 2.498530989940211

Epoch: 6| Step: 12
Training loss: 2.4982882361469745
Validation loss: 2.4923488592866345

Epoch: 6| Step: 13
Training loss: 3.4590779770561664
Validation loss: 2.500861324092384

Epoch: 143| Step: 0
Training loss: 2.4603944209485036
Validation loss: 2.493884395851774

Epoch: 6| Step: 1
Training loss: 3.1099511001029803
Validation loss: 2.4985783780336193

Epoch: 6| Step: 2
Training loss: 3.1186379330363194
Validation loss: 2.4992051470956795

Epoch: 6| Step: 3
Training loss: 2.4853839864658065
Validation loss: 2.500283066300947

Epoch: 6| Step: 4
Training loss: 2.8076789225549676
Validation loss: 2.512104789462876

Epoch: 6| Step: 5
Training loss: 3.16842659347618
Validation loss: 2.5241959011037167

Epoch: 6| Step: 6
Training loss: 2.9901077572596635
Validation loss: 2.546291924509435

Epoch: 6| Step: 7
Training loss: 2.834439977807427
Validation loss: 2.5764199643194456

Epoch: 6| Step: 8
Training loss: 2.679561333980978
Validation loss: 2.613201873759347

Epoch: 6| Step: 9
Training loss: 2.700170324392741
Validation loss: 2.6212652556916742

Epoch: 6| Step: 10
Training loss: 2.4566390993632465
Validation loss: 2.6286370940892456

Epoch: 6| Step: 11
Training loss: 3.1439124973535164
Validation loss: 2.588571723873579

Epoch: 6| Step: 12
Training loss: 2.4557220901166157
Validation loss: 2.533500234799139

Epoch: 6| Step: 13
Training loss: 2.77652519170955
Validation loss: 2.5096777794164926

Epoch: 144| Step: 0
Training loss: 2.7009030068307025
Validation loss: 2.495154804692447

Epoch: 6| Step: 1
Training loss: 2.4725895250426397
Validation loss: 2.486969539084878

Epoch: 6| Step: 2
Training loss: 2.865569195885217
Validation loss: 2.486750221548784

Epoch: 6| Step: 3
Training loss: 3.0003204174590876
Validation loss: 2.489280020766168

Epoch: 6| Step: 4
Training loss: 2.8046329248585606
Validation loss: 2.49143543533404

Epoch: 6| Step: 5
Training loss: 2.4956040834868243
Validation loss: 2.501127009521025

Epoch: 6| Step: 6
Training loss: 2.9193522124073845
Validation loss: 2.491256719556637

Epoch: 6| Step: 7
Training loss: 2.832752804092987
Validation loss: 2.5229960582831565

Epoch: 6| Step: 8
Training loss: 2.646325723882747
Validation loss: 2.5498744389993853

Epoch: 6| Step: 9
Training loss: 3.030309629577618
Validation loss: 2.557007571685

Epoch: 6| Step: 10
Training loss: 3.1931658484936745
Validation loss: 2.5541930414928564

Epoch: 6| Step: 11
Training loss: 2.6708537152048746
Validation loss: 2.516348341762356

Epoch: 6| Step: 12
Training loss: 2.7854316222180007
Validation loss: 2.5140220035612706

Epoch: 6| Step: 13
Training loss: 2.6933048455774435
Validation loss: 2.5156576492961755

Epoch: 145| Step: 0
Training loss: 3.3500065248340434
Validation loss: 2.5125810298996507

Epoch: 6| Step: 1
Training loss: 2.6565448372961256
Validation loss: 2.518409927565144

Epoch: 6| Step: 2
Training loss: 2.953928197392266
Validation loss: 2.527370789694481

Epoch: 6| Step: 3
Training loss: 2.340061387781095
Validation loss: 2.5429777757632452

Epoch: 6| Step: 4
Training loss: 2.9438259106869142
Validation loss: 2.561615352761032

Epoch: 6| Step: 5
Training loss: 2.6592123230645166
Validation loss: 2.578558927619876

Epoch: 6| Step: 6
Training loss: 3.2974254275226973
Validation loss: 2.5815063060099157

Epoch: 6| Step: 7
Training loss: 2.6605047818266208
Validation loss: 2.569806708425663

Epoch: 6| Step: 8
Training loss: 2.363709062678718
Validation loss: 2.5578083515255745

Epoch: 6| Step: 9
Training loss: 2.6076105971028434
Validation loss: 2.5498772199308783

Epoch: 6| Step: 10
Training loss: 2.9665644581650743
Validation loss: 2.5430982892655414

Epoch: 6| Step: 11
Training loss: 3.0513660686065767
Validation loss: 2.5270099410888247

Epoch: 6| Step: 12
Training loss: 2.69383318566838
Validation loss: 2.5134547640253757

Epoch: 6| Step: 13
Training loss: 1.5635095767956035
Validation loss: 2.5085354302459306

Epoch: 146| Step: 0
Training loss: 2.156188079387187
Validation loss: 2.499706081832687

Epoch: 6| Step: 1
Training loss: 3.666703108404151
Validation loss: 2.494744349825275

Epoch: 6| Step: 2
Training loss: 2.931526441084964
Validation loss: 2.500579967701294

Epoch: 6| Step: 3
Training loss: 3.1145883685595446
Validation loss: 2.4924027380236216

Epoch: 6| Step: 4
Training loss: 2.9964955842513747
Validation loss: 2.4896766012519227

Epoch: 6| Step: 5
Training loss: 2.6320815161108504
Validation loss: 2.505203912909442

Epoch: 6| Step: 6
Training loss: 2.4395718694515813
Validation loss: 2.513829718724578

Epoch: 6| Step: 7
Training loss: 2.670955566687921
Validation loss: 2.517852155020514

Epoch: 6| Step: 8
Training loss: 2.915916855117277
Validation loss: 2.547107202033423

Epoch: 6| Step: 9
Training loss: 2.612778049256016
Validation loss: 2.530457414460237

Epoch: 6| Step: 10
Training loss: 2.8934597652545597
Validation loss: 2.524867874160154

Epoch: 6| Step: 11
Training loss: 2.546037032931588
Validation loss: 2.5050305196453455

Epoch: 6| Step: 12
Training loss: 2.4663421864205253
Validation loss: 2.4962466459479598

Epoch: 6| Step: 13
Training loss: 2.7191979927069045
Validation loss: 2.490384688613216

Epoch: 147| Step: 0
Training loss: 2.325458817689222
Validation loss: 2.4839115537370136

Epoch: 6| Step: 1
Training loss: 2.3462781368106977
Validation loss: 2.4844905067711394

Epoch: 6| Step: 2
Training loss: 3.1198608866268858
Validation loss: 2.483156453971856

Epoch: 6| Step: 3
Training loss: 3.0249177527477786
Validation loss: 2.484302652040425

Epoch: 6| Step: 4
Training loss: 2.986031756467899
Validation loss: 2.482627738707495

Epoch: 6| Step: 5
Training loss: 2.617463510107754
Validation loss: 2.487912001170266

Epoch: 6| Step: 6
Training loss: 2.9004960063452434
Validation loss: 2.4859615457461803

Epoch: 6| Step: 7
Training loss: 3.2027374777492135
Validation loss: 2.4866445860833215

Epoch: 6| Step: 8
Training loss: 2.17470273145891
Validation loss: 2.485195782520606

Epoch: 6| Step: 9
Training loss: 1.961933445395635
Validation loss: 2.4906886147777647

Epoch: 6| Step: 10
Training loss: 2.0415629405966107
Validation loss: 2.504674194555253

Epoch: 6| Step: 11
Training loss: 3.305397624740721
Validation loss: 2.504893499418477

Epoch: 6| Step: 12
Training loss: 3.2390225692768286
Validation loss: 2.550917497807193

Epoch: 6| Step: 13
Training loss: 2.9325749117623823
Validation loss: 2.5602620394415525

Epoch: 148| Step: 0
Training loss: 2.9089867616564
Validation loss: 2.579802955557116

Epoch: 6| Step: 1
Training loss: 2.8702869760939023
Validation loss: 2.5914565076300615

Epoch: 6| Step: 2
Training loss: 3.0241597419407906
Validation loss: 2.6495583828170624

Epoch: 6| Step: 3
Training loss: 2.6824568515517657
Validation loss: 2.630199482473522

Epoch: 6| Step: 4
Training loss: 2.6910004995084065
Validation loss: 2.5792378509424316

Epoch: 6| Step: 5
Training loss: 2.72803411692879
Validation loss: 2.522658613137901

Epoch: 6| Step: 6
Training loss: 2.9972381594515736
Validation loss: 2.503611178677645

Epoch: 6| Step: 7
Training loss: 2.961335731640491
Validation loss: 2.4858203041934512

Epoch: 6| Step: 8
Training loss: 2.7880587441208884
Validation loss: 2.478910471879629

Epoch: 6| Step: 9
Training loss: 2.793962891252372
Validation loss: 2.4819497274027533

Epoch: 6| Step: 10
Training loss: 2.574894308495138
Validation loss: 2.476603490996752

Epoch: 6| Step: 11
Training loss: 2.821668642257056
Validation loss: 2.478511265231325

Epoch: 6| Step: 12
Training loss: 3.0256667482127364
Validation loss: 2.4747548903939767

Epoch: 6| Step: 13
Training loss: 2.1160383308126205
Validation loss: 2.4715470066406735

Epoch: 149| Step: 0
Training loss: 2.6769176882150783
Validation loss: 2.478825811908937

Epoch: 6| Step: 1
Training loss: 3.1559375570523684
Validation loss: 2.4785020450452193

Epoch: 6| Step: 2
Training loss: 2.9019604271912267
Validation loss: 2.4901722730452867

Epoch: 6| Step: 3
Training loss: 2.7561980538868673
Validation loss: 2.49925804818535

Epoch: 6| Step: 4
Training loss: 3.0252733595737236
Validation loss: 2.531501199504337

Epoch: 6| Step: 5
Training loss: 2.940898957904373
Validation loss: 2.567834871766755

Epoch: 6| Step: 6
Training loss: 3.337697478320513
Validation loss: 2.613845213752949

Epoch: 6| Step: 7
Training loss: 2.613246581071416
Validation loss: 2.650930504394593

Epoch: 6| Step: 8
Training loss: 2.7582486161728395
Validation loss: 2.611988043606173

Epoch: 6| Step: 9
Training loss: 2.8822108522222103
Validation loss: 2.5994772483761124

Epoch: 6| Step: 10
Training loss: 1.9910998797537494
Validation loss: 2.5556407578835323

Epoch: 6| Step: 11
Training loss: 2.930105764413533
Validation loss: 2.544925190204258

Epoch: 6| Step: 12
Training loss: 2.7872912341574985
Validation loss: 2.528418923203358

Epoch: 6| Step: 13
Training loss: 2.679527077724726
Validation loss: 2.503407864879336

Epoch: 150| Step: 0
Training loss: 2.945713977113348
Validation loss: 2.502835112063911

Epoch: 6| Step: 1
Training loss: 1.8385597494675174
Validation loss: 2.471886066253161

Epoch: 6| Step: 2
Training loss: 3.239491861080279
Validation loss: 2.4887463681677255

Epoch: 6| Step: 3
Training loss: 2.502649048168916
Validation loss: 2.4844878693414834

Epoch: 6| Step: 4
Training loss: 3.3290752075262167
Validation loss: 2.494612502107448

Epoch: 6| Step: 5
Training loss: 2.9948263061289273
Validation loss: 2.4932711008366604

Epoch: 6| Step: 6
Training loss: 3.2655741856468197
Validation loss: 2.5022626686963085

Epoch: 6| Step: 7
Training loss: 2.052737162521894
Validation loss: 2.501041056131891

Epoch: 6| Step: 8
Training loss: 2.607676244322258
Validation loss: 2.5200333712035485

Epoch: 6| Step: 9
Training loss: 3.0973020257252943
Validation loss: 2.5216117930842787

Epoch: 6| Step: 10
Training loss: 2.3978880212455422
Validation loss: 2.5286902394446797

Epoch: 6| Step: 11
Training loss: 2.7926749975274934
Validation loss: 2.5344531333122364

Epoch: 6| Step: 12
Training loss: 2.4172542668832713
Validation loss: 2.5421907727449953

Epoch: 6| Step: 13
Training loss: 3.094206034639944
Validation loss: 2.5817536255432874

Epoch: 151| Step: 0
Training loss: 2.6146020673306105
Validation loss: 2.521492657177961

Epoch: 6| Step: 1
Training loss: 2.7889712877077897
Validation loss: 2.478572773979801

Epoch: 6| Step: 2
Training loss: 2.98728984269154
Validation loss: 2.4763493211785357

Epoch: 6| Step: 3
Training loss: 2.031107618770384
Validation loss: 2.474875263092497

Epoch: 6| Step: 4
Training loss: 2.933235806953532
Validation loss: 2.476688130149815

Epoch: 6| Step: 5
Training loss: 2.6621010459047527
Validation loss: 2.4726257866660206

Epoch: 6| Step: 6
Training loss: 2.5801734877815448
Validation loss: 2.477880860218207

Epoch: 6| Step: 7
Training loss: 2.428093292147127
Validation loss: 2.471832888428471

Epoch: 6| Step: 8
Training loss: 2.718119317928365
Validation loss: 2.4818049354914504

Epoch: 6| Step: 9
Training loss: 3.0515182718489062
Validation loss: 2.504742545794733

Epoch: 6| Step: 10
Training loss: 3.0885601246857455
Validation loss: 2.526324541097989

Epoch: 6| Step: 11
Training loss: 2.832601976436008
Validation loss: 2.554920018491875

Epoch: 6| Step: 12
Training loss: 2.7924409807844732
Validation loss: 2.570037679488996

Epoch: 6| Step: 13
Training loss: 3.5240821671535425
Validation loss: 2.5742646143439134

Epoch: 152| Step: 0
Training loss: 2.38878605742017
Validation loss: 2.575430326487897

Epoch: 6| Step: 1
Training loss: 3.310185037379248
Validation loss: 2.551670679144296

Epoch: 6| Step: 2
Training loss: 2.668198761303546
Validation loss: 2.506843640162672

Epoch: 6| Step: 3
Training loss: 2.3067067756179243
Validation loss: 2.498803325062062

Epoch: 6| Step: 4
Training loss: 2.8928174751159013
Validation loss: 2.4939836249384917

Epoch: 6| Step: 5
Training loss: 3.017284351850902
Validation loss: 2.4902565179363547

Epoch: 6| Step: 6
Training loss: 2.807145510651122
Validation loss: 2.4862893452125423

Epoch: 6| Step: 7
Training loss: 2.909808533652111
Validation loss: 2.4929593711973776

Epoch: 6| Step: 8
Training loss: 2.914518837059508
Validation loss: 2.4838623799637833

Epoch: 6| Step: 9
Training loss: 2.689851486190498
Validation loss: 2.494455939756683

Epoch: 6| Step: 10
Training loss: 2.711075924903849
Validation loss: 2.480777026853888

Epoch: 6| Step: 11
Training loss: 2.7750936372097397
Validation loss: 2.477044978757711

Epoch: 6| Step: 12
Training loss: 2.900322560754389
Validation loss: 2.48034351598917

Epoch: 6| Step: 13
Training loss: 3.0097502572510813
Validation loss: 2.47421506697026

Epoch: 153| Step: 0
Training loss: 3.1786605338745777
Validation loss: 2.482367622656142

Epoch: 6| Step: 1
Training loss: 2.264412180431863
Validation loss: 2.50190152485405

Epoch: 6| Step: 2
Training loss: 2.7453304874219526
Validation loss: 2.5093382950280025

Epoch: 6| Step: 3
Training loss: 2.0814390216942447
Validation loss: 2.523086419295973

Epoch: 6| Step: 4
Training loss: 3.2693415031839237
Validation loss: 2.5355543837135475

Epoch: 6| Step: 5
Training loss: 2.425037116327081
Validation loss: 2.56427805650648

Epoch: 6| Step: 6
Training loss: 2.663951972167642
Validation loss: 2.5713378913577998

Epoch: 6| Step: 7
Training loss: 2.569855994409168
Validation loss: 2.5512986611537665

Epoch: 6| Step: 8
Training loss: 2.840295223150382
Validation loss: 2.531376879940565

Epoch: 6| Step: 9
Training loss: 2.811514024629302
Validation loss: 2.5213729787912236

Epoch: 6| Step: 10
Training loss: 2.866303934021565
Validation loss: 2.4894050801721197

Epoch: 6| Step: 11
Training loss: 2.988828681219643
Validation loss: 2.4894032542995244

Epoch: 6| Step: 12
Training loss: 3.06703628579271
Validation loss: 2.478751220045871

Epoch: 6| Step: 13
Training loss: 2.4457323975236194
Validation loss: 2.476796745830767

Epoch: 154| Step: 0
Training loss: 2.4359940987814594
Validation loss: 2.489133939902346

Epoch: 6| Step: 1
Training loss: 3.367796097207811
Validation loss: 2.4829508612500946

Epoch: 6| Step: 2
Training loss: 2.7228740238352036
Validation loss: 2.4745885890520203

Epoch: 6| Step: 3
Training loss: 3.09143164496298
Validation loss: 2.4791637136955873

Epoch: 6| Step: 4
Training loss: 2.4968196667017355
Validation loss: 2.4735126135728467

Epoch: 6| Step: 5
Training loss: 1.9156419115424617
Validation loss: 2.475315290148355

Epoch: 6| Step: 6
Training loss: 2.7054538286873306
Validation loss: 2.4784600614239936

Epoch: 6| Step: 7
Training loss: 3.039788245304917
Validation loss: 2.510891148857607

Epoch: 6| Step: 8
Training loss: 2.8566973713575257
Validation loss: 2.5052241890114115

Epoch: 6| Step: 9
Training loss: 3.005942181790687
Validation loss: 2.5082072255082632

Epoch: 6| Step: 10
Training loss: 2.5160107050366234
Validation loss: 2.480412949049158

Epoch: 6| Step: 11
Training loss: 2.328768545211032
Validation loss: 2.4840781752418786

Epoch: 6| Step: 12
Training loss: 2.677994440695453
Validation loss: 2.4727041847714712

Epoch: 6| Step: 13
Training loss: 3.328404231289775
Validation loss: 2.4693844386170705

Epoch: 155| Step: 0
Training loss: 2.761986532003063
Validation loss: 2.4663800533117928

Epoch: 6| Step: 1
Training loss: 3.164586605416055
Validation loss: 2.473790937286016

Epoch: 6| Step: 2
Training loss: 2.900875248864152
Validation loss: 2.4744590438238783

Epoch: 6| Step: 3
Training loss: 2.407716576647749
Validation loss: 2.4783806672099162

Epoch: 6| Step: 4
Training loss: 2.808231420582686
Validation loss: 2.491701707076735

Epoch: 6| Step: 5
Training loss: 2.5754806366275704
Validation loss: 2.5063658359711853

Epoch: 6| Step: 6
Training loss: 2.854100433100868
Validation loss: 2.513949326892116

Epoch: 6| Step: 7
Training loss: 2.594515216505619
Validation loss: 2.5133446398677903

Epoch: 6| Step: 8
Training loss: 2.7294490367228663
Validation loss: 2.4956723914030685

Epoch: 6| Step: 9
Training loss: 2.8836708341727215
Validation loss: 2.4855809317730593

Epoch: 6| Step: 10
Training loss: 2.6643196943870917
Validation loss: 2.4805862906630587

Epoch: 6| Step: 11
Training loss: 2.7829673694009402
Validation loss: 2.4756990874221994

Epoch: 6| Step: 12
Training loss: 2.4486692746123686
Validation loss: 2.471663317225831

Epoch: 6| Step: 13
Training loss: 2.8817472479787174
Validation loss: 2.4636534481413417

Epoch: 156| Step: 0
Training loss: 2.632405507129797
Validation loss: 2.461625033383877

Epoch: 6| Step: 1
Training loss: 2.429547566496415
Validation loss: 2.4581886118203076

Epoch: 6| Step: 2
Training loss: 2.7308525721602077
Validation loss: 2.4640652865967887

Epoch: 6| Step: 3
Training loss: 2.8538053706207416
Validation loss: 2.4577187443750166

Epoch: 6| Step: 4
Training loss: 2.7986069756270386
Validation loss: 2.4552527436295564

Epoch: 6| Step: 5
Training loss: 2.2099656843740445
Validation loss: 2.4734285197698296

Epoch: 6| Step: 6
Training loss: 2.8012495726721665
Validation loss: 2.486702520421073

Epoch: 6| Step: 7
Training loss: 2.8592719387804757
Validation loss: 2.4939124716354906

Epoch: 6| Step: 8
Training loss: 2.941053311069394
Validation loss: 2.4934409720134063

Epoch: 6| Step: 9
Training loss: 3.2760338876669284
Validation loss: 2.5095443186868414

Epoch: 6| Step: 10
Training loss: 2.948464566234406
Validation loss: 2.5076332512521593

Epoch: 6| Step: 11
Training loss: 2.3059137735052158
Validation loss: 2.5042323925745946

Epoch: 6| Step: 12
Training loss: 2.8056618530817095
Validation loss: 2.500739048858491

Epoch: 6| Step: 13
Training loss: 2.608664501563965
Validation loss: 2.494397590425495

Epoch: 157| Step: 0
Training loss: 3.272832773656309
Validation loss: 2.4812288336247406

Epoch: 6| Step: 1
Training loss: 2.6992822576137367
Validation loss: 2.4818816925563567

Epoch: 6| Step: 2
Training loss: 2.73076936870587
Validation loss: 2.485019201227324

Epoch: 6| Step: 3
Training loss: 3.151269438947305
Validation loss: 2.477144820817694

Epoch: 6| Step: 4
Training loss: 2.7186147721959526
Validation loss: 2.475790204424436

Epoch: 6| Step: 5
Training loss: 2.317674157965792
Validation loss: 2.4738390946379454

Epoch: 6| Step: 6
Training loss: 2.461052301544752
Validation loss: 2.474286255187474

Epoch: 6| Step: 7
Training loss: 3.352656401556744
Validation loss: 2.4690253889600897

Epoch: 6| Step: 8
Training loss: 2.5757674101439494
Validation loss: 2.4698728471861844

Epoch: 6| Step: 9
Training loss: 2.577875483605088
Validation loss: 2.474318505036588

Epoch: 6| Step: 10
Training loss: 2.5156371311819297
Validation loss: 2.476250816217077

Epoch: 6| Step: 11
Training loss: 2.550581312303171
Validation loss: 2.475079018470936

Epoch: 6| Step: 12
Training loss: 2.265484404312164
Validation loss: 2.474615815148265

Epoch: 6| Step: 13
Training loss: 2.976151725880081
Validation loss: 2.4738813836263853

Epoch: 158| Step: 0
Training loss: 2.3476646791329023
Validation loss: 2.471350637970845

Epoch: 6| Step: 1
Training loss: 2.334330436556944
Validation loss: 2.4687591221304532

Epoch: 6| Step: 2
Training loss: 2.7481032679559365
Validation loss: 2.4735616241324405

Epoch: 6| Step: 3
Training loss: 2.1555470965679366
Validation loss: 2.4688391871221915

Epoch: 6| Step: 4
Training loss: 3.057734927917117
Validation loss: 2.4697057344184477

Epoch: 6| Step: 5
Training loss: 2.8474492755287115
Validation loss: 2.4613616072674693

Epoch: 6| Step: 6
Training loss: 2.6323114025813723
Validation loss: 2.465574583490576

Epoch: 6| Step: 7
Training loss: 2.8764654653947086
Validation loss: 2.469635432507253

Epoch: 6| Step: 8
Training loss: 2.420687279642448
Validation loss: 2.4792136310841975

Epoch: 6| Step: 9
Training loss: 2.881418444163605
Validation loss: 2.4767541572805207

Epoch: 6| Step: 10
Training loss: 2.6707022251397126
Validation loss: 2.488396034575246

Epoch: 6| Step: 11
Training loss: 2.9256857434970946
Validation loss: 2.503361083319123

Epoch: 6| Step: 12
Training loss: 3.2742359580532354
Validation loss: 2.4914770675722346

Epoch: 6| Step: 13
Training loss: 2.971470439663081
Validation loss: 2.5010731526718213

Epoch: 159| Step: 0
Training loss: 2.3004948125232296
Validation loss: 2.504585950326079

Epoch: 6| Step: 1
Training loss: 2.7840894285067157
Validation loss: 2.4910309016855323

Epoch: 6| Step: 2
Training loss: 2.3611405190026438
Validation loss: 2.477237623240318

Epoch: 6| Step: 3
Training loss: 3.036154799996775
Validation loss: 2.4678587264570466

Epoch: 6| Step: 4
Training loss: 2.4249042885366077
Validation loss: 2.4600392087810916

Epoch: 6| Step: 5
Training loss: 2.8314503040994663
Validation loss: 2.4608816582926125

Epoch: 6| Step: 6
Training loss: 2.8241118731398154
Validation loss: 2.4610418086319616

Epoch: 6| Step: 7
Training loss: 2.6171953343516137
Validation loss: 2.4656813035963068

Epoch: 6| Step: 8
Training loss: 3.3289454348840053
Validation loss: 2.4827463006076282

Epoch: 6| Step: 9
Training loss: 2.815213907357174
Validation loss: 2.487446674425245

Epoch: 6| Step: 10
Training loss: 2.7101390003437245
Validation loss: 2.5078504644671487

Epoch: 6| Step: 11
Training loss: 2.364329409864372
Validation loss: 2.52237827435111

Epoch: 6| Step: 12
Training loss: 2.805318862280611
Validation loss: 2.5223991675465585

Epoch: 6| Step: 13
Training loss: 2.979329422637542
Validation loss: 2.5062776298228444

Epoch: 160| Step: 0
Training loss: 3.123896900033837
Validation loss: 2.474642256720238

Epoch: 6| Step: 1
Training loss: 2.6548735698762735
Validation loss: 2.455534479635469

Epoch: 6| Step: 2
Training loss: 1.9243382121401527
Validation loss: 2.453966107195904

Epoch: 6| Step: 3
Training loss: 3.1540214300207716
Validation loss: 2.457056645969461

Epoch: 6| Step: 4
Training loss: 2.242167509302217
Validation loss: 2.4528405154079276

Epoch: 6| Step: 5
Training loss: 3.2979919566373903
Validation loss: 2.4476930563718993

Epoch: 6| Step: 6
Training loss: 2.6721719498728933
Validation loss: 2.4575701360191773

Epoch: 6| Step: 7
Training loss: 2.9099412672270444
Validation loss: 2.4508325365180594

Epoch: 6| Step: 8
Training loss: 2.585212075629902
Validation loss: 2.4550865173783776

Epoch: 6| Step: 9
Training loss: 2.3316069301599742
Validation loss: 2.452057096470408

Epoch: 6| Step: 10
Training loss: 3.1229677840399455
Validation loss: 2.4510908814763828

Epoch: 6| Step: 11
Training loss: 2.9093839094146445
Validation loss: 2.4597217823441047

Epoch: 6| Step: 12
Training loss: 2.5573914942838534
Validation loss: 2.476582994030455

Epoch: 6| Step: 13
Training loss: 2.4110633960618086
Validation loss: 2.5065771114114965

Epoch: 161| Step: 0
Training loss: 2.7472602895172047
Validation loss: 2.5334736151976274

Epoch: 6| Step: 1
Training loss: 2.729578487007809
Validation loss: 2.540473189433099

Epoch: 6| Step: 2
Training loss: 2.6608706507906876
Validation loss: 2.5260125832912674

Epoch: 6| Step: 3
Training loss: 3.156842317806613
Validation loss: 2.4840583488542545

Epoch: 6| Step: 4
Training loss: 2.383178982927373
Validation loss: 2.473115327703133

Epoch: 6| Step: 5
Training loss: 2.679615520255707
Validation loss: 2.465537930140732

Epoch: 6| Step: 6
Training loss: 2.8863421079560467
Validation loss: 2.476104913508841

Epoch: 6| Step: 7
Training loss: 2.4167657919537753
Validation loss: 2.473078445066503

Epoch: 6| Step: 8
Training loss: 3.2478582220750774
Validation loss: 2.4862432530863345

Epoch: 6| Step: 9
Training loss: 2.376857232171092
Validation loss: 2.487950382652319

Epoch: 6| Step: 10
Training loss: 2.635581351903219
Validation loss: 2.5018116406333415

Epoch: 6| Step: 11
Training loss: 2.8568727978731463
Validation loss: 2.503330282916177

Epoch: 6| Step: 12
Training loss: 2.6834790512071867
Validation loss: 2.4993482150256874

Epoch: 6| Step: 13
Training loss: 2.8603080519586714
Validation loss: 2.4924538014547717

Epoch: 162| Step: 0
Training loss: 2.841406894418404
Validation loss: 2.482766496808599

Epoch: 6| Step: 1
Training loss: 2.884267052379748
Validation loss: 2.4767268460059064

Epoch: 6| Step: 2
Training loss: 2.8666007041734933
Validation loss: 2.472003584628014

Epoch: 6| Step: 3
Training loss: 2.2806689423801845
Validation loss: 2.471659524135998

Epoch: 6| Step: 4
Training loss: 2.5260518706335198
Validation loss: 2.471068346036412

Epoch: 6| Step: 5
Training loss: 2.796408758248119
Validation loss: 2.4793389562887556

Epoch: 6| Step: 6
Training loss: 2.8815465282183297
Validation loss: 2.476735296484197

Epoch: 6| Step: 7
Training loss: 2.644374916042398
Validation loss: 2.4846961908328025

Epoch: 6| Step: 8
Training loss: 3.179296071096624
Validation loss: 2.5111803379024558

Epoch: 6| Step: 9
Training loss: 2.739589318872061
Validation loss: 2.5259760224050654

Epoch: 6| Step: 10
Training loss: 2.275396807093265
Validation loss: 2.5573777066379537

Epoch: 6| Step: 11
Training loss: 2.4529471363291724
Validation loss: 2.5907072071461026

Epoch: 6| Step: 12
Training loss: 2.6638328475635067
Validation loss: 2.6015060090032676

Epoch: 6| Step: 13
Training loss: 3.25316568398664
Validation loss: 2.5625873783880015

Epoch: 163| Step: 0
Training loss: 2.3275830963084747
Validation loss: 2.5475943937378847

Epoch: 6| Step: 1
Training loss: 2.7564324662411894
Validation loss: 2.4927908956803018

Epoch: 6| Step: 2
Training loss: 2.9164754169068314
Validation loss: 2.493586481336904

Epoch: 6| Step: 3
Training loss: 2.648084678892133
Validation loss: 2.478700777245358

Epoch: 6| Step: 4
Training loss: 2.90554866737277
Validation loss: 2.4744453980923

Epoch: 6| Step: 5
Training loss: 2.3345658475797575
Validation loss: 2.478344604608673

Epoch: 6| Step: 6
Training loss: 2.6814364850831645
Validation loss: 2.4726717479812197

Epoch: 6| Step: 7
Training loss: 2.5898187098148457
Validation loss: 2.4650142292132107

Epoch: 6| Step: 8
Training loss: 2.641792355344167
Validation loss: 2.4698602846684192

Epoch: 6| Step: 9
Training loss: 2.8267605688434445
Validation loss: 2.4734089811496056

Epoch: 6| Step: 10
Training loss: 3.137161242674119
Validation loss: 2.4806668378886543

Epoch: 6| Step: 11
Training loss: 2.5850767794925518
Validation loss: 2.50376152268025

Epoch: 6| Step: 12
Training loss: 2.73364736412306
Validation loss: 2.5069183011767797

Epoch: 6| Step: 13
Training loss: 3.2869643090390386
Validation loss: 2.5102643839216583

Epoch: 164| Step: 0
Training loss: 2.9262189754127133
Validation loss: 2.5246674724312754

Epoch: 6| Step: 1
Training loss: 2.411207764187914
Validation loss: 2.5252147326178647

Epoch: 6| Step: 2
Training loss: 3.07985301818893
Validation loss: 2.5468791149072696

Epoch: 6| Step: 3
Training loss: 3.0630751089264536
Validation loss: 2.568791467259917

Epoch: 6| Step: 4
Training loss: 2.0772288978965685
Validation loss: 2.537094103913184

Epoch: 6| Step: 5
Training loss: 2.482956391300716
Validation loss: 2.4880700056734124

Epoch: 6| Step: 6
Training loss: 2.547842204850581
Validation loss: 2.475883645754212

Epoch: 6| Step: 7
Training loss: 2.8241983204547227
Validation loss: 2.4502963966472318

Epoch: 6| Step: 8
Training loss: 2.5569004192035214
Validation loss: 2.4477180821062503

Epoch: 6| Step: 9
Training loss: 3.0683475642277465
Validation loss: 2.448073764665657

Epoch: 6| Step: 10
Training loss: 2.692261757825592
Validation loss: 2.442365627613204

Epoch: 6| Step: 11
Training loss: 2.89075366584422
Validation loss: 2.4421919119746387

Epoch: 6| Step: 12
Training loss: 2.375538313241747
Validation loss: 2.4450280448237427

Epoch: 6| Step: 13
Training loss: 3.6135701161981313
Validation loss: 2.4459339610080084

Epoch: 165| Step: 0
Training loss: 2.3213555146343885
Validation loss: 2.463249058219397

Epoch: 6| Step: 1
Training loss: 2.912217443291575
Validation loss: 2.481839527492647

Epoch: 6| Step: 2
Training loss: 2.7132566354801027
Validation loss: 2.5006565472687576

Epoch: 6| Step: 3
Training loss: 2.6956063373007195
Validation loss: 2.5106043639282256

Epoch: 6| Step: 4
Training loss: 2.3911977842206444
Validation loss: 2.4862925859927363

Epoch: 6| Step: 5
Training loss: 2.467690735530517
Validation loss: 2.468677413245084

Epoch: 6| Step: 6
Training loss: 2.292015488404141
Validation loss: 2.4434786462092757

Epoch: 6| Step: 7
Training loss: 3.052677830070527
Validation loss: 2.447528457666377

Epoch: 6| Step: 8
Training loss: 2.7282827464987074
Validation loss: 2.437571338107119

Epoch: 6| Step: 9
Training loss: 3.1583059432184903
Validation loss: 2.443154847805027

Epoch: 6| Step: 10
Training loss: 2.6942191297396683
Validation loss: 2.4410081559675887

Epoch: 6| Step: 11
Training loss: 3.0958719394034286
Validation loss: 2.4419202961853546

Epoch: 6| Step: 12
Training loss: 2.6032282448177106
Validation loss: 2.4376561788204385

Epoch: 6| Step: 13
Training loss: 2.807517491436461
Validation loss: 2.43348404879325

Epoch: 166| Step: 0
Training loss: 3.2359777340305667
Validation loss: 2.4327848257328215

Epoch: 6| Step: 1
Training loss: 2.4210928361465682
Validation loss: 2.439560544341793

Epoch: 6| Step: 2
Training loss: 2.0931913854779296
Validation loss: 2.4353580534713726

Epoch: 6| Step: 3
Training loss: 2.6511069379064702
Validation loss: 2.4409072900326025

Epoch: 6| Step: 4
Training loss: 2.797917518038039
Validation loss: 2.429021815818311

Epoch: 6| Step: 5
Training loss: 3.2248060419471294
Validation loss: 2.4545960972504743

Epoch: 6| Step: 6
Training loss: 2.103209463523506
Validation loss: 2.4779626903205325

Epoch: 6| Step: 7
Training loss: 2.517512685370661
Validation loss: 2.505165311726944

Epoch: 6| Step: 8
Training loss: 2.947667159629791
Validation loss: 2.5252682969230684

Epoch: 6| Step: 9
Training loss: 2.5962292874887054
Validation loss: 2.518739641557542

Epoch: 6| Step: 10
Training loss: 3.123887741514095
Validation loss: 2.4948304030080544

Epoch: 6| Step: 11
Training loss: 2.85161667863771
Validation loss: 2.4878671200108897

Epoch: 6| Step: 12
Training loss: 2.585029650136288
Validation loss: 2.467620869695681

Epoch: 6| Step: 13
Training loss: 2.7272585442203137
Validation loss: 2.47376272329539

Epoch: 167| Step: 0
Training loss: 2.3515047085273024
Validation loss: 2.461815078867891

Epoch: 6| Step: 1
Training loss: 2.2599162823860435
Validation loss: 2.4569820766470443

Epoch: 6| Step: 2
Training loss: 2.8710719931679898
Validation loss: 2.4448467630038153

Epoch: 6| Step: 3
Training loss: 3.0949784739397446
Validation loss: 2.4391000910735676

Epoch: 6| Step: 4
Training loss: 2.686605526423288
Validation loss: 2.450407731594655

Epoch: 6| Step: 5
Training loss: 2.866084663689905
Validation loss: 2.4439327432563918

Epoch: 6| Step: 6
Training loss: 2.842039495119885
Validation loss: 2.4379736159122154

Epoch: 6| Step: 7
Training loss: 3.210181376956982
Validation loss: 2.4285946715464513

Epoch: 6| Step: 8
Training loss: 2.381704404232529
Validation loss: 2.4334109558044905

Epoch: 6| Step: 9
Training loss: 2.5847054395951305
Validation loss: 2.4370859508065443

Epoch: 6| Step: 10
Training loss: 2.6664026447565723
Validation loss: 2.436581859676927

Epoch: 6| Step: 11
Training loss: 2.644096575446303
Validation loss: 2.446972379516186

Epoch: 6| Step: 12
Training loss: 2.035035113282442
Validation loss: 2.451284833062998

Epoch: 6| Step: 13
Training loss: 3.4268790109747638
Validation loss: 2.4578424036192454

Epoch: 168| Step: 0
Training loss: 2.672054976263231
Validation loss: 2.4534260189106836

Epoch: 6| Step: 1
Training loss: 2.7002037889785577
Validation loss: 2.4713484740704157

Epoch: 6| Step: 2
Training loss: 2.352823723989065
Validation loss: 2.4734557975026075

Epoch: 6| Step: 3
Training loss: 2.538584596701113
Validation loss: 2.4720421405139605

Epoch: 6| Step: 4
Training loss: 3.309383293624154
Validation loss: 2.4821783327645086

Epoch: 6| Step: 5
Training loss: 2.9215743782307135
Validation loss: 2.453546978275007

Epoch: 6| Step: 6
Training loss: 3.0218866200110255
Validation loss: 2.4490973423908784

Epoch: 6| Step: 7
Training loss: 2.409681969073437
Validation loss: 2.4314367389463794

Epoch: 6| Step: 8
Training loss: 2.8170300770305983
Validation loss: 2.432222793326679

Epoch: 6| Step: 9
Training loss: 2.1676105375164365
Validation loss: 2.426222468488956

Epoch: 6| Step: 10
Training loss: 2.940389145768336
Validation loss: 2.4283650208554475

Epoch: 6| Step: 11
Training loss: 2.1948897745528186
Validation loss: 2.4266234577527563

Epoch: 6| Step: 12
Training loss: 2.8128861903910676
Validation loss: 2.4355703129850976

Epoch: 6| Step: 13
Training loss: 2.989509679084162
Validation loss: 2.4494085408282933

Epoch: 169| Step: 0
Training loss: 2.8124691431684035
Validation loss: 2.467568975501634

Epoch: 6| Step: 1
Training loss: 1.8627298046917231
Validation loss: 2.523507927479738

Epoch: 6| Step: 2
Training loss: 2.7844057503146438
Validation loss: 2.548647124805798

Epoch: 6| Step: 3
Training loss: 3.3970936189855503
Validation loss: 2.5542887584445535

Epoch: 6| Step: 4
Training loss: 2.6072485019607474
Validation loss: 2.564731567632601

Epoch: 6| Step: 5
Training loss: 3.4956763673688185
Validation loss: 2.5221824103954966

Epoch: 6| Step: 6
Training loss: 2.9748188829186617
Validation loss: 2.4685425843221225

Epoch: 6| Step: 7
Training loss: 2.218809529969989
Validation loss: 2.4418138909093527

Epoch: 6| Step: 8
Training loss: 2.762812072940272
Validation loss: 2.430021237437067

Epoch: 6| Step: 9
Training loss: 2.4069775558965736
Validation loss: 2.4400248627855956

Epoch: 6| Step: 10
Training loss: 3.085089690204556
Validation loss: 2.4343837404626663

Epoch: 6| Step: 11
Training loss: 2.1740221346559188
Validation loss: 2.4271990647112407

Epoch: 6| Step: 12
Training loss: 2.197656106796287
Validation loss: 2.4312703237093496

Epoch: 6| Step: 13
Training loss: 3.2200930857975476
Validation loss: 2.425600731277526

Epoch: 170| Step: 0
Training loss: 2.299446690388733
Validation loss: 2.436042852836858

Epoch: 6| Step: 1
Training loss: 2.4384572032546505
Validation loss: 2.449618591788052

Epoch: 6| Step: 2
Training loss: 2.2916244387348437
Validation loss: 2.46654113130258

Epoch: 6| Step: 3
Training loss: 2.589792012291943
Validation loss: 2.4805269019574365

Epoch: 6| Step: 4
Training loss: 3.079911076884544
Validation loss: 2.5046109142606774

Epoch: 6| Step: 5
Training loss: 2.5692663411683014
Validation loss: 2.5281327981809696

Epoch: 6| Step: 6
Training loss: 2.908440041611134
Validation loss: 2.5188890866643963

Epoch: 6| Step: 7
Training loss: 3.5546837439884
Validation loss: 2.518714219169993

Epoch: 6| Step: 8
Training loss: 2.1470796490319377
Validation loss: 2.50545821803628

Epoch: 6| Step: 9
Training loss: 3.4470004490342165
Validation loss: 2.5091624411065605

Epoch: 6| Step: 10
Training loss: 2.7781104037026916
Validation loss: 2.496346507194598

Epoch: 6| Step: 11
Training loss: 2.475667990504087
Validation loss: 2.4646402047480067

Epoch: 6| Step: 12
Training loss: 2.3991489411423936
Validation loss: 2.4525644709508123

Epoch: 6| Step: 13
Training loss: 2.1540567051499515
Validation loss: 2.44141816403343

Epoch: 171| Step: 0
Training loss: 2.8076796868043634
Validation loss: 2.4298675763704196

Epoch: 6| Step: 1
Training loss: 2.5109377962502744
Validation loss: 2.4326124999212917

Epoch: 6| Step: 2
Training loss: 2.9810750402138053
Validation loss: 2.4396441746824262

Epoch: 6| Step: 3
Training loss: 3.0495168334476315
Validation loss: 2.436672298391838

Epoch: 6| Step: 4
Training loss: 2.6238895065490326
Validation loss: 2.445662240884551

Epoch: 6| Step: 5
Training loss: 2.777898247543645
Validation loss: 2.4583595786163217

Epoch: 6| Step: 6
Training loss: 2.6948271825863617
Validation loss: 2.451658459641129

Epoch: 6| Step: 7
Training loss: 2.6194057799751524
Validation loss: 2.4549451880721476

Epoch: 6| Step: 8
Training loss: 1.748339069176433
Validation loss: 2.455323622322521

Epoch: 6| Step: 9
Training loss: 3.109843003213936
Validation loss: 2.4778959768606863

Epoch: 6| Step: 10
Training loss: 2.660126225194223
Validation loss: 2.479752533838712

Epoch: 6| Step: 11
Training loss: 2.2817593358654373
Validation loss: 2.5000696880102953

Epoch: 6| Step: 12
Training loss: 3.086464675105456
Validation loss: 2.4981381507731055

Epoch: 6| Step: 13
Training loss: 2.3467993672015215
Validation loss: 2.498376608412091

Epoch: 172| Step: 0
Training loss: 3.5126074832205147
Validation loss: 2.4797223985675783

Epoch: 6| Step: 1
Training loss: 2.8561206078801735
Validation loss: 2.4969181097163653

Epoch: 6| Step: 2
Training loss: 2.414131040124799
Validation loss: 2.509504702423511

Epoch: 6| Step: 3
Training loss: 2.5678445858556462
Validation loss: 2.5001851977180634

Epoch: 6| Step: 4
Training loss: 2.2787317459622476
Validation loss: 2.479060226503523

Epoch: 6| Step: 5
Training loss: 2.6541109335740445
Validation loss: 2.4691593375469663

Epoch: 6| Step: 6
Training loss: 3.162540022404546
Validation loss: 2.4593409945826976

Epoch: 6| Step: 7
Training loss: 2.35631752220969
Validation loss: 2.45397914414345

Epoch: 6| Step: 8
Training loss: 3.0808118528016735
Validation loss: 2.451268793031853

Epoch: 6| Step: 9
Training loss: 2.616219230430819
Validation loss: 2.4419714588519312

Epoch: 6| Step: 10
Training loss: 1.9845292639656722
Validation loss: 2.433275871115324

Epoch: 6| Step: 11
Training loss: 2.8186295578762546
Validation loss: 2.4389976357934247

Epoch: 6| Step: 12
Training loss: 2.685767213972374
Validation loss: 2.4406873122394743

Epoch: 6| Step: 13
Training loss: 2.2359327741422366
Validation loss: 2.4445005749836115

Epoch: 173| Step: 0
Training loss: 2.4886637203602078
Validation loss: 2.4534093941335806

Epoch: 6| Step: 1
Training loss: 2.867315887154486
Validation loss: 2.458786532795134

Epoch: 6| Step: 2
Training loss: 2.767743694599733
Validation loss: 2.4781245382368766

Epoch: 6| Step: 3
Training loss: 2.7243524464432656
Validation loss: 2.4840402963938675

Epoch: 6| Step: 4
Training loss: 2.7776652175562004
Validation loss: 2.481933180065217

Epoch: 6| Step: 5
Training loss: 2.7024468249260214
Validation loss: 2.485942041693261

Epoch: 6| Step: 6
Training loss: 2.7832298518453564
Validation loss: 2.480277245902874

Epoch: 6| Step: 7
Training loss: 2.0423536377554283
Validation loss: 2.474574238523933

Epoch: 6| Step: 8
Training loss: 2.5284990974592123
Validation loss: 2.464608022770569

Epoch: 6| Step: 9
Training loss: 2.288369969099952
Validation loss: 2.44152253377305

Epoch: 6| Step: 10
Training loss: 2.9087113653026186
Validation loss: 2.4354214131578082

Epoch: 6| Step: 11
Training loss: 3.1340436157424447
Validation loss: 2.4292699927762516

Epoch: 6| Step: 12
Training loss: 2.633455282920584
Validation loss: 2.4347137816547395

Epoch: 6| Step: 13
Training loss: 2.7023519832930103
Validation loss: 2.447295922142551

Epoch: 174| Step: 0
Training loss: 1.8720732416757861
Validation loss: 2.4629740252380756

Epoch: 6| Step: 1
Training loss: 2.7008284145625483
Validation loss: 2.4768101281239607

Epoch: 6| Step: 2
Training loss: 3.026887723969633
Validation loss: 2.486889947494484

Epoch: 6| Step: 3
Training loss: 2.747184525931784
Validation loss: 2.478909925315225

Epoch: 6| Step: 4
Training loss: 2.653262623878294
Validation loss: 2.4727254852449874

Epoch: 6| Step: 5
Training loss: 3.154490972162867
Validation loss: 2.4602381454589595

Epoch: 6| Step: 6
Training loss: 2.56861705575229
Validation loss: 2.4541925704672307

Epoch: 6| Step: 7
Training loss: 3.674663248008869
Validation loss: 2.4504728395055104

Epoch: 6| Step: 8
Training loss: 2.2686072354546796
Validation loss: 2.4507438191447894

Epoch: 6| Step: 9
Training loss: 2.3485451029620386
Validation loss: 2.4543377514878766

Epoch: 6| Step: 10
Training loss: 2.7511955610103573
Validation loss: 2.4523060345174565

Epoch: 6| Step: 11
Training loss: 2.067016280761146
Validation loss: 2.4496153610957774

Epoch: 6| Step: 12
Training loss: 2.411550257820909
Validation loss: 2.4494045029009492

Epoch: 6| Step: 13
Training loss: 2.648745358558898
Validation loss: 2.456967283129949

Epoch: 175| Step: 0
Training loss: 2.3735167238374753
Validation loss: 2.454006545874916

Epoch: 6| Step: 1
Training loss: 2.671154438142742
Validation loss: 2.457291210308597

Epoch: 6| Step: 2
Training loss: 2.6919830545739476
Validation loss: 2.4648798218743044

Epoch: 6| Step: 3
Training loss: 2.411266695541239
Validation loss: 2.442661625956309

Epoch: 6| Step: 4
Training loss: 2.778574138504147
Validation loss: 2.4435430238869924

Epoch: 6| Step: 5
Training loss: 2.6279888394494746
Validation loss: 2.431175375417207

Epoch: 6| Step: 6
Training loss: 2.6909585034967565
Validation loss: 2.435094373574331

Epoch: 6| Step: 7
Training loss: 2.522937831480132
Validation loss: 2.4418757718039767

Epoch: 6| Step: 8
Training loss: 2.970988343320286
Validation loss: 2.4538451904316685

Epoch: 6| Step: 9
Training loss: 2.7473816978247636
Validation loss: 2.4725875177501897

Epoch: 6| Step: 10
Training loss: 2.1518038922476506
Validation loss: 2.4727578767499274

Epoch: 6| Step: 11
Training loss: 3.4339009257150903
Validation loss: 2.501958137610868

Epoch: 6| Step: 12
Training loss: 2.4728201620483863
Validation loss: 2.4956041194410137

Epoch: 6| Step: 13
Training loss: 2.8061241784382376
Validation loss: 2.4710282311874754

Epoch: 176| Step: 0
Training loss: 2.164699419400989
Validation loss: 2.4396018575671548

Epoch: 6| Step: 1
Training loss: 2.807644616034499
Validation loss: 2.429928924855129

Epoch: 6| Step: 2
Training loss: 2.466431313533268
Validation loss: 2.4268914631482037

Epoch: 6| Step: 3
Training loss: 2.715897916681599
Validation loss: 2.4244631145993565

Epoch: 6| Step: 4
Training loss: 2.71415198864324
Validation loss: 2.421033066011617

Epoch: 6| Step: 5
Training loss: 2.156504408713561
Validation loss: 2.4263337722600595

Epoch: 6| Step: 6
Training loss: 2.817838730441969
Validation loss: 2.4375241785609303

Epoch: 6| Step: 7
Training loss: 2.2233539150072743
Validation loss: 2.439124421941043

Epoch: 6| Step: 8
Training loss: 2.259543629707287
Validation loss: 2.4389160393124256

Epoch: 6| Step: 9
Training loss: 2.872139710356741
Validation loss: 2.437030187428638

Epoch: 6| Step: 10
Training loss: 3.395245054499386
Validation loss: 2.4613953158851496

Epoch: 6| Step: 11
Training loss: 2.709058654690899
Validation loss: 2.455876877338206

Epoch: 6| Step: 12
Training loss: 2.5094063230770973
Validation loss: 2.4600739619863883

Epoch: 6| Step: 13
Training loss: 3.4451954101595703
Validation loss: 2.483577197471909

Epoch: 177| Step: 0
Training loss: 2.0606275208226092
Validation loss: 2.4406546032955934

Epoch: 6| Step: 1
Training loss: 2.7249661994727647
Validation loss: 2.412053681470835

Epoch: 6| Step: 2
Training loss: 2.7046437489691484
Validation loss: 2.413168413748706

Epoch: 6| Step: 3
Training loss: 3.0132773951455607
Validation loss: 2.399718039196385

Epoch: 6| Step: 4
Training loss: 3.149219803844248
Validation loss: 2.408945181650681

Epoch: 6| Step: 5
Training loss: 2.120529521273411
Validation loss: 2.4122903517573095

Epoch: 6| Step: 6
Training loss: 3.405412763540991
Validation loss: 2.4005549850083034

Epoch: 6| Step: 7
Training loss: 2.245319159915314
Validation loss: 2.4091348559810117

Epoch: 6| Step: 8
Training loss: 2.813571217304181
Validation loss: 2.420437911271474

Epoch: 6| Step: 9
Training loss: 2.912426527676496
Validation loss: 2.4318812556033773

Epoch: 6| Step: 10
Training loss: 2.3907573389062167
Validation loss: 2.4467437768883498

Epoch: 6| Step: 11
Training loss: 2.4821131744648652
Validation loss: 2.4635384119140613

Epoch: 6| Step: 12
Training loss: 2.819820963539788
Validation loss: 2.4843882594364537

Epoch: 6| Step: 13
Training loss: 1.8207020486019465
Validation loss: 2.4857297951579693

Epoch: 178| Step: 0
Training loss: 2.425970146945265
Validation loss: 2.469554399870404

Epoch: 6| Step: 1
Training loss: 2.6651077681002655
Validation loss: 2.4464503850206794

Epoch: 6| Step: 2
Training loss: 1.6306046886648526
Validation loss: 2.4298691964047463

Epoch: 6| Step: 3
Training loss: 2.8640508723296088
Validation loss: 2.4168576956054486

Epoch: 6| Step: 4
Training loss: 2.5634693080254496
Validation loss: 2.4185983171316923

Epoch: 6| Step: 5
Training loss: 2.887747327112284
Validation loss: 2.418604553984643

Epoch: 6| Step: 6
Training loss: 1.7732763007082581
Validation loss: 2.4204643287951337

Epoch: 6| Step: 7
Training loss: 2.5293929269587543
Validation loss: 2.4360149330587895

Epoch: 6| Step: 8
Training loss: 2.7336691681084058
Validation loss: 2.4439641348800576

Epoch: 6| Step: 9
Training loss: 2.8065843888437882
Validation loss: 2.4584350279861247

Epoch: 6| Step: 10
Training loss: 3.0879696878714484
Validation loss: 2.4600476259192883

Epoch: 6| Step: 11
Training loss: 3.304092678349689
Validation loss: 2.439802594113072

Epoch: 6| Step: 12
Training loss: 2.960086267348309
Validation loss: 2.4330211031433144

Epoch: 6| Step: 13
Training loss: 2.354451885218632
Validation loss: 2.4267120232220334

Epoch: 179| Step: 0
Training loss: 2.800247971589762
Validation loss: 2.4157404654081884

Epoch: 6| Step: 1
Training loss: 2.441778291965062
Validation loss: 2.415081582841348

Epoch: 6| Step: 2
Training loss: 2.8810424332729525
Validation loss: 2.3980063500856743

Epoch: 6| Step: 3
Training loss: 2.9315043194703367
Validation loss: 2.4003926905300035

Epoch: 6| Step: 4
Training loss: 1.954336050320673
Validation loss: 2.410300986228279

Epoch: 6| Step: 5
Training loss: 2.38541887663582
Validation loss: 2.416093676329598

Epoch: 6| Step: 6
Training loss: 2.096911420662188
Validation loss: 2.4285601445193823

Epoch: 6| Step: 7
Training loss: 2.984001096300839
Validation loss: 2.447708426480544

Epoch: 6| Step: 8
Training loss: 2.889890175286896
Validation loss: 2.4437146502373124

Epoch: 6| Step: 9
Training loss: 2.4257103852810826
Validation loss: 2.450346686583607

Epoch: 6| Step: 10
Training loss: 2.808697057954203
Validation loss: 2.4555964281956855

Epoch: 6| Step: 11
Training loss: 3.2155787576774064
Validation loss: 2.448611722952252

Epoch: 6| Step: 12
Training loss: 2.3075021916107317
Validation loss: 2.447727469570894

Epoch: 6| Step: 13
Training loss: 2.639305733221896
Validation loss: 2.4278124508452574

Epoch: 180| Step: 0
Training loss: 2.1685700003821915
Validation loss: 2.4324519638682345

Epoch: 6| Step: 1
Training loss: 2.718785603608021
Validation loss: 2.4230850885622193

Epoch: 6| Step: 2
Training loss: 1.602549774301494
Validation loss: 2.419075627332194

Epoch: 6| Step: 3
Training loss: 3.3047362700486698
Validation loss: 2.4209412859200055

Epoch: 6| Step: 4
Training loss: 2.6993738508034353
Validation loss: 2.4021479226263556

Epoch: 6| Step: 5
Training loss: 2.583331405474856
Validation loss: 2.4020737352286097

Epoch: 6| Step: 6
Training loss: 3.027406438363041
Validation loss: 2.4112736743266265

Epoch: 6| Step: 7
Training loss: 2.55700541109386
Validation loss: 2.405970411887112

Epoch: 6| Step: 8
Training loss: 2.4868424356365275
Validation loss: 2.412041756313756

Epoch: 6| Step: 9
Training loss: 2.6129524240757616
Validation loss: 2.411408181046484

Epoch: 6| Step: 10
Training loss: 2.452184314533691
Validation loss: 2.4235414136768902

Epoch: 6| Step: 11
Training loss: 2.2943314981973737
Validation loss: 2.4291035082517136

Epoch: 6| Step: 12
Training loss: 2.9114892147021014
Validation loss: 2.424023089296641

Epoch: 6| Step: 13
Training loss: 3.3140389088641267
Validation loss: 2.4365660132496814

Epoch: 181| Step: 0
Training loss: 2.742067687631406
Validation loss: 2.4330450638483483

Epoch: 6| Step: 1
Training loss: 3.1744779983697775
Validation loss: 2.4458681212019604

Epoch: 6| Step: 2
Training loss: 2.474419469855318
Validation loss: 2.4394307899515026

Epoch: 6| Step: 3
Training loss: 2.1533244091868626
Validation loss: 2.4460840120410356

Epoch: 6| Step: 4
Training loss: 3.050902848989087
Validation loss: 2.4448039251261253

Epoch: 6| Step: 5
Training loss: 2.958581797593529
Validation loss: 2.439481352223707

Epoch: 6| Step: 6
Training loss: 2.4119138568912373
Validation loss: 2.446228497395105

Epoch: 6| Step: 7
Training loss: 2.5829873212207053
Validation loss: 2.4534021809724327

Epoch: 6| Step: 8
Training loss: 2.578231624363569
Validation loss: 2.463698742305537

Epoch: 6| Step: 9
Training loss: 1.9085769833715611
Validation loss: 2.473398965616467

Epoch: 6| Step: 10
Training loss: 3.2937526290275025
Validation loss: 2.453939771394697

Epoch: 6| Step: 11
Training loss: 2.7359982277379236
Validation loss: 2.4736081546600426

Epoch: 6| Step: 12
Training loss: 2.173258608292079
Validation loss: 2.4563875894764555

Epoch: 6| Step: 13
Training loss: 1.3979432921662052
Validation loss: 2.436174685011623

Epoch: 182| Step: 0
Training loss: 3.193175405633486
Validation loss: 2.437575610186862

Epoch: 6| Step: 1
Training loss: 1.5244057732698237
Validation loss: 2.4344172055285083

Epoch: 6| Step: 2
Training loss: 1.5449851465591438
Validation loss: 2.410310006759602

Epoch: 6| Step: 3
Training loss: 2.335328497967772
Validation loss: 2.4197421407210578

Epoch: 6| Step: 4
Training loss: 2.404944523986395
Validation loss: 2.4068213142706463

Epoch: 6| Step: 5
Training loss: 2.659876961408009
Validation loss: 2.4160040769920212

Epoch: 6| Step: 6
Training loss: 2.426059971029617
Validation loss: 2.4095960933972496

Epoch: 6| Step: 7
Training loss: 2.8885053131387455
Validation loss: 2.4169493751384397

Epoch: 6| Step: 8
Training loss: 2.7891098574082545
Validation loss: 2.430115438558775

Epoch: 6| Step: 9
Training loss: 2.625738494170832
Validation loss: 2.454072383578871

Epoch: 6| Step: 10
Training loss: 2.712365733396605
Validation loss: 2.4632068791497557

Epoch: 6| Step: 11
Training loss: 3.075281834286173
Validation loss: 2.4957081419872766

Epoch: 6| Step: 12
Training loss: 2.9411431305061533
Validation loss: 2.4919468987326883

Epoch: 6| Step: 13
Training loss: 3.292822204442317
Validation loss: 2.50020319717897

Epoch: 183| Step: 0
Training loss: 2.734692538761017
Validation loss: 2.4594544869140385

Epoch: 6| Step: 1
Training loss: 2.7442227280033036
Validation loss: 2.434361566891451

Epoch: 6| Step: 2
Training loss: 3.3427961183224855
Validation loss: 2.4209211161344437

Epoch: 6| Step: 3
Training loss: 2.440810278821299
Validation loss: 2.3989975680748286

Epoch: 6| Step: 4
Training loss: 2.26312085901117
Validation loss: 2.390572104638617

Epoch: 6| Step: 5
Training loss: 1.7901348248644924
Validation loss: 2.3913418464974407

Epoch: 6| Step: 6
Training loss: 2.1213314702984687
Validation loss: 2.4088440773089412

Epoch: 6| Step: 7
Training loss: 2.516190648902089
Validation loss: 2.4121974514986086

Epoch: 6| Step: 8
Training loss: 2.9324719840530205
Validation loss: 2.4184346321506536

Epoch: 6| Step: 9
Training loss: 2.2816122107164336
Validation loss: 2.432993803562578

Epoch: 6| Step: 10
Training loss: 2.999473366607836
Validation loss: 2.4552308123035296

Epoch: 6| Step: 11
Training loss: 2.281453371780774
Validation loss: 2.4368342165290797

Epoch: 6| Step: 12
Training loss: 3.0783003548957293
Validation loss: 2.4350402964655182

Epoch: 6| Step: 13
Training loss: 2.892121953236934
Validation loss: 2.433468923852117

Epoch: 184| Step: 0
Training loss: 2.844229521512798
Validation loss: 2.4286524906557037

Epoch: 6| Step: 1
Training loss: 3.262514522125546
Validation loss: 2.425357749336069

Epoch: 6| Step: 2
Training loss: 1.9994216321090348
Validation loss: 2.41915753800862

Epoch: 6| Step: 3
Training loss: 2.8432893484752535
Validation loss: 2.4272288265152864

Epoch: 6| Step: 4
Training loss: 2.423617419137795
Validation loss: 2.4259234424331235

Epoch: 6| Step: 5
Training loss: 2.506466418123707
Validation loss: 2.4281486138225663

Epoch: 6| Step: 6
Training loss: 2.3111867526505603
Validation loss: 2.427230127754124

Epoch: 6| Step: 7
Training loss: 2.67427330128615
Validation loss: 2.420754728318419

Epoch: 6| Step: 8
Training loss: 2.3897764407827284
Validation loss: 2.429245255054099

Epoch: 6| Step: 9
Training loss: 1.7439030296419678
Validation loss: 2.4305672215085568

Epoch: 6| Step: 10
Training loss: 3.1613347858418646
Validation loss: 2.431610603013755

Epoch: 6| Step: 11
Training loss: 2.7615459123669917
Validation loss: 2.4314817750068403

Epoch: 6| Step: 12
Training loss: 2.6292577454700514
Validation loss: 2.414221827148248

Epoch: 6| Step: 13
Training loss: 2.614258177297322
Validation loss: 2.4446632026187793

Epoch: 185| Step: 0
Training loss: 2.171705280506178
Validation loss: 2.479580248484398

Epoch: 6| Step: 1
Training loss: 1.9001553145723853
Validation loss: 2.502345134236858

Epoch: 6| Step: 2
Training loss: 2.627653506483356
Validation loss: 2.5123368234489813

Epoch: 6| Step: 3
Training loss: 2.625381260386791
Validation loss: 2.5351795871912572

Epoch: 6| Step: 4
Training loss: 2.114859677252317
Validation loss: 2.50669565735933

Epoch: 6| Step: 5
Training loss: 2.9893318274281793
Validation loss: 2.5036599717372785

Epoch: 6| Step: 6
Training loss: 2.928939520401943
Validation loss: 2.4880833716385675

Epoch: 6| Step: 7
Training loss: 1.8449306264100742
Validation loss: 2.457160353539523

Epoch: 6| Step: 8
Training loss: 2.7007391659583684
Validation loss: 2.4376661498029613

Epoch: 6| Step: 9
Training loss: 2.9645547235912986
Validation loss: 2.4246408590060815

Epoch: 6| Step: 10
Training loss: 2.602437556650897
Validation loss: 2.410871748852789

Epoch: 6| Step: 11
Training loss: 2.5952486970834094
Validation loss: 2.3970833497936797

Epoch: 6| Step: 12
Training loss: 2.9594855057286837
Validation loss: 2.39512024352928

Epoch: 6| Step: 13
Training loss: 3.3994480077664555
Validation loss: 2.391574909767812

Epoch: 186| Step: 0
Training loss: 2.4637222277635464
Validation loss: 2.394047404706928

Epoch: 6| Step: 1
Training loss: 2.296946206578536
Validation loss: 2.4153240128253595

Epoch: 6| Step: 2
Training loss: 2.6987062180162678
Validation loss: 2.431264550616573

Epoch: 6| Step: 3
Training loss: 2.809414081916921
Validation loss: 2.447232122975733

Epoch: 6| Step: 4
Training loss: 2.5594653326728323
Validation loss: 2.4470129358669905

Epoch: 6| Step: 5
Training loss: 2.8128382161548555
Validation loss: 2.44058103703132

Epoch: 6| Step: 6
Training loss: 2.8674293021123125
Validation loss: 2.4365079947292605

Epoch: 6| Step: 7
Training loss: 2.339200805570774
Validation loss: 2.438103950464447

Epoch: 6| Step: 8
Training loss: 2.3487871083672376
Validation loss: 2.4369766224573075

Epoch: 6| Step: 9
Training loss: 2.1870714040227277
Validation loss: 2.4505391717789755

Epoch: 6| Step: 10
Training loss: 2.848287462728598
Validation loss: 2.4462857446207353

Epoch: 6| Step: 11
Training loss: 2.932942852848683
Validation loss: 2.4712974859698984

Epoch: 6| Step: 12
Training loss: 2.671616480406139
Validation loss: 2.48357927329994

Epoch: 6| Step: 13
Training loss: 2.4606403474181353
Validation loss: 2.4708212277597417

Epoch: 187| Step: 0
Training loss: 2.255148190114122
Validation loss: 2.4653162557543666

Epoch: 6| Step: 1
Training loss: 2.1442294994191267
Validation loss: 2.4557670670633645

Epoch: 6| Step: 2
Training loss: 2.836047125765111
Validation loss: 2.463494600853541

Epoch: 6| Step: 3
Training loss: 2.765603275537027
Validation loss: 2.4681626889864536

Epoch: 6| Step: 4
Training loss: 2.827401843268673
Validation loss: 2.450960057670695

Epoch: 6| Step: 5
Training loss: 2.037973632057927
Validation loss: 2.4599497698285995

Epoch: 6| Step: 6
Training loss: 2.797015479624973
Validation loss: 2.4772692246144485

Epoch: 6| Step: 7
Training loss: 3.259544442765773
Validation loss: 2.4780725908879244

Epoch: 6| Step: 8
Training loss: 3.027908213505499
Validation loss: 2.5011728878398785

Epoch: 6| Step: 9
Training loss: 2.1714090629647806
Validation loss: 2.4809354857655355

Epoch: 6| Step: 10
Training loss: 2.290289956605309
Validation loss: 2.464937982785583

Epoch: 6| Step: 11
Training loss: 2.418548268030324
Validation loss: 2.445552155401967

Epoch: 6| Step: 12
Training loss: 2.539338739480356
Validation loss: 2.4219308027017212

Epoch: 6| Step: 13
Training loss: 2.6764697449084225
Validation loss: 2.4308286177329146

Epoch: 188| Step: 0
Training loss: 2.37680005573541
Validation loss: 2.41004852954604

Epoch: 6| Step: 1
Training loss: 2.39955714431446
Validation loss: 2.4066038645269607

Epoch: 6| Step: 2
Training loss: 2.841747039672566
Validation loss: 2.398955693445033

Epoch: 6| Step: 3
Training loss: 2.8298648098308417
Validation loss: 2.4249661199150077

Epoch: 6| Step: 4
Training loss: 2.6269881575847145
Validation loss: 2.4276337231694525

Epoch: 6| Step: 5
Training loss: 2.308089819319038
Validation loss: 2.44041069566441

Epoch: 6| Step: 6
Training loss: 2.0852759523074464
Validation loss: 2.4591291928517087

Epoch: 6| Step: 7
Training loss: 2.1874005976299173
Validation loss: 2.442645497813432

Epoch: 6| Step: 8
Training loss: 2.7823989723695037
Validation loss: 2.4630966223332034

Epoch: 6| Step: 9
Training loss: 2.8064078577581903
Validation loss: 2.4652091725095313

Epoch: 6| Step: 10
Training loss: 2.386283972265049
Validation loss: 2.4730318558503024

Epoch: 6| Step: 11
Training loss: 2.869338390371884
Validation loss: 2.47544658116798

Epoch: 6| Step: 12
Training loss: 2.4260873893162556
Validation loss: 2.493361751510043

Epoch: 6| Step: 13
Training loss: 3.5494771814189163
Validation loss: 2.50971996504766

Epoch: 189| Step: 0
Training loss: 2.8002115305970845
Validation loss: 2.480864993663341

Epoch: 6| Step: 1
Training loss: 2.6681534576149417
Validation loss: 2.4699597409418947

Epoch: 6| Step: 2
Training loss: 2.7867216657233485
Validation loss: 2.4421565347881016

Epoch: 6| Step: 3
Training loss: 2.3142472960295697
Validation loss: 2.4197199447536692

Epoch: 6| Step: 4
Training loss: 2.4125926657159726
Validation loss: 2.416370782854168

Epoch: 6| Step: 5
Training loss: 2.5660224523060053
Validation loss: 2.4049827094850054

Epoch: 6| Step: 6
Training loss: 1.7166587591760725
Validation loss: 2.3989867962608153

Epoch: 6| Step: 7
Training loss: 3.046917254815173
Validation loss: 2.4196861619945866

Epoch: 6| Step: 8
Training loss: 2.8293024636339426
Validation loss: 2.429694316142107

Epoch: 6| Step: 9
Training loss: 2.9979768925056858
Validation loss: 2.4511839204126264

Epoch: 6| Step: 10
Training loss: 2.696849086455745
Validation loss: 2.4762102335054665

Epoch: 6| Step: 11
Training loss: 1.8409482714147354
Validation loss: 2.5174008975186997

Epoch: 6| Step: 12
Training loss: 2.5356426977264457
Validation loss: 2.5364879586125655

Epoch: 6| Step: 13
Training loss: 2.9509493771085475
Validation loss: 2.5322915247040343

Epoch: 190| Step: 0
Training loss: 2.595337990596005
Validation loss: 2.5556190129358884

Epoch: 6| Step: 1
Training loss: 2.106269981221583
Validation loss: 2.5271249985100415

Epoch: 6| Step: 2
Training loss: 3.3290870959369605
Validation loss: 2.5286860969664695

Epoch: 6| Step: 3
Training loss: 2.908634970980233
Validation loss: 2.5090057761382836

Epoch: 6| Step: 4
Training loss: 2.5492724035089855
Validation loss: 2.4958736739838594

Epoch: 6| Step: 5
Training loss: 2.15263494885988
Validation loss: 2.4847362191474627

Epoch: 6| Step: 6
Training loss: 2.2936025130333655
Validation loss: 2.4650391113384

Epoch: 6| Step: 7
Training loss: 2.018343607621486
Validation loss: 2.4779720263164315

Epoch: 6| Step: 8
Training loss: 2.4368762660995524
Validation loss: 2.4627558394403444

Epoch: 6| Step: 9
Training loss: 2.5454972173780113
Validation loss: 2.4357633091174398

Epoch: 6| Step: 10
Training loss: 2.746954966000643
Validation loss: 2.4354081718669804

Epoch: 6| Step: 11
Training loss: 2.3541268089318677
Validation loss: 2.4392258955115453

Epoch: 6| Step: 12
Training loss: 2.9183558522620454
Validation loss: 2.449927775591043

Epoch: 6| Step: 13
Training loss: 3.0482451659296976
Validation loss: 2.4127791345519944

Epoch: 191| Step: 0
Training loss: 2.549795898048332
Validation loss: 2.434934449143274

Epoch: 6| Step: 1
Training loss: 3.061677627696139
Validation loss: 2.4218736630693094

Epoch: 6| Step: 2
Training loss: 3.2763855252840024
Validation loss: 2.4606456327638746

Epoch: 6| Step: 3
Training loss: 2.4853276759350664
Validation loss: 2.450717681991655

Epoch: 6| Step: 4
Training loss: 1.7604702672378802
Validation loss: 2.485440651575605

Epoch: 6| Step: 5
Training loss: 2.4726093884407168
Validation loss: 2.517480434880149

Epoch: 6| Step: 6
Training loss: 3.125078429191599
Validation loss: 2.5569645991393513

Epoch: 6| Step: 7
Training loss: 2.585983414256757
Validation loss: 2.585853206741671

Epoch: 6| Step: 8
Training loss: 2.813909050518919
Validation loss: 2.5500284182102857

Epoch: 6| Step: 9
Training loss: 2.378011701293595
Validation loss: 2.5153695324999066

Epoch: 6| Step: 10
Training loss: 1.7529700144429896
Validation loss: 2.503961138344204

Epoch: 6| Step: 11
Training loss: 2.1627346330484145
Validation loss: 2.481135073872266

Epoch: 6| Step: 12
Training loss: 2.604430671025478
Validation loss: 2.462767586693202

Epoch: 6| Step: 13
Training loss: 2.8524850685471046
Validation loss: 2.420890842609114

Epoch: 192| Step: 0
Training loss: 2.255561947722165
Validation loss: 2.3928500448089687

Epoch: 6| Step: 1
Training loss: 2.6434847001956445
Validation loss: 2.376637832627659

Epoch: 6| Step: 2
Training loss: 2.73383679134007
Validation loss: 2.3935570079503217

Epoch: 6| Step: 3
Training loss: 2.1879895343704567
Validation loss: 2.4045088197188664

Epoch: 6| Step: 4
Training loss: 2.5380474232961823
Validation loss: 2.4105500164362437

Epoch: 6| Step: 5
Training loss: 2.2633765277289624
Validation loss: 2.4330178114255596

Epoch: 6| Step: 6
Training loss: 3.0586015450291795
Validation loss: 2.457164422019778

Epoch: 6| Step: 7
Training loss: 3.4084387230532096
Validation loss: 2.495667436019202

Epoch: 6| Step: 8
Training loss: 2.228595755605003
Validation loss: 2.5097121139036997

Epoch: 6| Step: 9
Training loss: 2.3913104502030866
Validation loss: 2.489506471154244

Epoch: 6| Step: 10
Training loss: 2.9029827826314922
Validation loss: 2.487173707029205

Epoch: 6| Step: 11
Training loss: 1.9912290174740115
Validation loss: 2.496708419647608

Epoch: 6| Step: 12
Training loss: 2.4543538508464495
Validation loss: 2.4775804626161047

Epoch: 6| Step: 13
Training loss: 3.5900706156211584
Validation loss: 2.459579241390429

Epoch: 193| Step: 0
Training loss: 2.827694854902814
Validation loss: 2.469529582963769

Epoch: 6| Step: 1
Training loss: 2.796395372577517
Validation loss: 2.4648690072319153

Epoch: 6| Step: 2
Training loss: 2.529615086160513
Validation loss: 2.459818757459826

Epoch: 6| Step: 3
Training loss: 2.7720612025805007
Validation loss: 2.4781778412258593

Epoch: 6| Step: 4
Training loss: 2.840868485594046
Validation loss: 2.496516580892337

Epoch: 6| Step: 5
Training loss: 2.919392719611111
Validation loss: 2.5011643436305024

Epoch: 6| Step: 6
Training loss: 2.795368662696959
Validation loss: 2.5474612911720778

Epoch: 6| Step: 7
Training loss: 1.8118300679673107
Validation loss: 2.5285079229205265

Epoch: 6| Step: 8
Training loss: 2.115143299343525
Validation loss: 2.532435570095589

Epoch: 6| Step: 9
Training loss: 2.198511907840673
Validation loss: 2.515001138495118

Epoch: 6| Step: 10
Training loss: 2.547998660232455
Validation loss: 2.505666433069178

Epoch: 6| Step: 11
Training loss: 2.7153875670767174
Validation loss: 2.4968117144140285

Epoch: 6| Step: 12
Training loss: 2.3416808086072307
Validation loss: 2.4915883856321868

Epoch: 6| Step: 13
Training loss: 2.5998568055261666
Validation loss: 2.507695442171364

Epoch: 194| Step: 0
Training loss: 2.768868134262461
Validation loss: 2.4871662475200242

Epoch: 6| Step: 1
Training loss: 2.7995839559178988
Validation loss: 2.502787501371064

Epoch: 6| Step: 2
Training loss: 1.992656039322691
Validation loss: 2.4983089531825207

Epoch: 6| Step: 3
Training loss: 2.5915470189711174
Validation loss: 2.4891389438257217

Epoch: 6| Step: 4
Training loss: 2.5650265031601647
Validation loss: 2.5176756718281155

Epoch: 6| Step: 5
Training loss: 2.7358411073724325
Validation loss: 2.5214849057271715

Epoch: 6| Step: 6
Training loss: 2.6991694621155755
Validation loss: 2.5393044870575014

Epoch: 6| Step: 7
Training loss: 2.3097094633028212
Validation loss: 2.520316889137127

Epoch: 6| Step: 8
Training loss: 2.880011627120813
Validation loss: 2.503185953463239

Epoch: 6| Step: 9
Training loss: 2.6471692314683923
Validation loss: 2.509710450920797

Epoch: 6| Step: 10
Training loss: 2.398368511388201
Validation loss: 2.4931422302198403

Epoch: 6| Step: 11
Training loss: 2.5436950677662447
Validation loss: 2.4844434185310784

Epoch: 6| Step: 12
Training loss: 2.341666554443067
Validation loss: 2.4902551147703975

Epoch: 6| Step: 13
Training loss: 2.241203384552905
Validation loss: 2.494324365602654

Epoch: 195| Step: 0
Training loss: 2.09054194400864
Validation loss: 2.505253894729215

Epoch: 6| Step: 1
Training loss: 2.227121169289573
Validation loss: 2.4858748349152475

Epoch: 6| Step: 2
Training loss: 2.8182187749167835
Validation loss: 2.4989425063323982

Epoch: 6| Step: 3
Training loss: 2.620148671714956
Validation loss: 2.4929328267109434

Epoch: 6| Step: 4
Training loss: 2.739172427228722
Validation loss: 2.503604617023479

Epoch: 6| Step: 5
Training loss: 1.8051403187659874
Validation loss: 2.506085894969919

Epoch: 6| Step: 6
Training loss: 2.924207765934153
Validation loss: 2.495635034715775

Epoch: 6| Step: 7
Training loss: 1.9636022691624597
Validation loss: 2.4689146905694375

Epoch: 6| Step: 8
Training loss: 3.0700944429961785
Validation loss: 2.472514459905367

Epoch: 6| Step: 9
Training loss: 2.3012678217987763
Validation loss: 2.4611155695377813

Epoch: 6| Step: 10
Training loss: 2.60807740618503
Validation loss: 2.4505355860845257

Epoch: 6| Step: 11
Training loss: 2.968341518207327
Validation loss: 2.4734066469940013

Epoch: 6| Step: 12
Training loss: 2.8783064363596442
Validation loss: 2.4926377620479063

Epoch: 6| Step: 13
Training loss: 2.1013853998260994
Validation loss: 2.5222881684939735

Epoch: 196| Step: 0
Training loss: 3.009322622126609
Validation loss: 2.5772543771160916

Epoch: 6| Step: 1
Training loss: 2.5859702301259024
Validation loss: 2.6417819631263577

Epoch: 6| Step: 2
Training loss: 2.242210786811511
Validation loss: 2.6809173089593625

Epoch: 6| Step: 3
Training loss: 2.810073823332427
Validation loss: 2.6612960433308057

Epoch: 6| Step: 4
Training loss: 3.023233411736649
Validation loss: 2.621246591158597

Epoch: 6| Step: 5
Training loss: 2.65977567171375
Validation loss: 2.5672929840498986

Epoch: 6| Step: 6
Training loss: 2.3444347144352355
Validation loss: 2.488496714626439

Epoch: 6| Step: 7
Training loss: 2.703233044179469
Validation loss: 2.440648038345559

Epoch: 6| Step: 8
Training loss: 2.7495748017786625
Validation loss: 2.458941045792786

Epoch: 6| Step: 9
Training loss: 2.3659811943512836
Validation loss: 2.4259141407347515

Epoch: 6| Step: 10
Training loss: 1.9253780414884434
Validation loss: 2.421037005129814

Epoch: 6| Step: 11
Training loss: 2.547429872694993
Validation loss: 2.4355710676872064

Epoch: 6| Step: 12
Training loss: 2.350768807639108
Validation loss: 2.4595843559934907

Epoch: 6| Step: 13
Training loss: 2.578292563801801
Validation loss: 2.497290009993914

Epoch: 197| Step: 0
Training loss: 2.9309801835607456
Validation loss: 2.531942346043198

Epoch: 6| Step: 1
Training loss: 2.29978136184429
Validation loss: 2.5804481160015644

Epoch: 6| Step: 2
Training loss: 2.5105881586237278
Validation loss: 2.6255392262005444

Epoch: 6| Step: 3
Training loss: 2.4710925613289505
Validation loss: 2.6106633397897676

Epoch: 6| Step: 4
Training loss: 2.7807666487143523
Validation loss: 2.572596594139055

Epoch: 6| Step: 5
Training loss: 2.871496968922185
Validation loss: 2.52483563842089

Epoch: 6| Step: 6
Training loss: 2.321641329562938
Validation loss: 2.5008445656511507

Epoch: 6| Step: 7
Training loss: 3.007804890412452
Validation loss: 2.498201254328399

Epoch: 6| Step: 8
Training loss: 2.209433107812488
Validation loss: 2.469876781068968

Epoch: 6| Step: 9
Training loss: 2.8690327623423966
Validation loss: 2.4480064115565665

Epoch: 6| Step: 10
Training loss: 2.5004035623981813
Validation loss: 2.446911856469424

Epoch: 6| Step: 11
Training loss: 2.5524889150111667
Validation loss: 2.4684022497822347

Epoch: 6| Step: 12
Training loss: 1.9341020012459929
Validation loss: 2.4764256583017055

Epoch: 6| Step: 13
Training loss: 2.6061088542087707
Validation loss: 2.5338662432875916

Epoch: 198| Step: 0
Training loss: 2.6834745200155625
Validation loss: 2.561797786392908

Epoch: 6| Step: 1
Training loss: 2.335486531183879
Validation loss: 2.5982152706957913

Epoch: 6| Step: 2
Training loss: 2.3464510802740253
Validation loss: 2.5561551604759964

Epoch: 6| Step: 3
Training loss: 2.385144102913406
Validation loss: 2.543571117414602

Epoch: 6| Step: 4
Training loss: 3.15632795483094
Validation loss: 2.5088596917073303

Epoch: 6| Step: 5
Training loss: 2.1313010648723414
Validation loss: 2.481772835608494

Epoch: 6| Step: 6
Training loss: 2.883701094471877
Validation loss: 2.480714978538232

Epoch: 6| Step: 7
Training loss: 2.4123005285467345
Validation loss: 2.4550984287214535

Epoch: 6| Step: 8
Training loss: 2.8581163314731257
Validation loss: 2.4633176867794213

Epoch: 6| Step: 9
Training loss: 2.6279685174574596
Validation loss: 2.4614498773726874

Epoch: 6| Step: 10
Training loss: 1.9945667495287807
Validation loss: 2.4848713930007547

Epoch: 6| Step: 11
Training loss: 1.8053702512025067
Validation loss: 2.505822779931639

Epoch: 6| Step: 12
Training loss: 2.7393886269733736
Validation loss: 2.5077568178100322

Epoch: 6| Step: 13
Training loss: 2.990215239161501
Validation loss: 2.5415916569650876

Epoch: 199| Step: 0
Training loss: 2.8522085633706458
Validation loss: 2.573696190929566

Epoch: 6| Step: 1
Training loss: 2.088311491068329
Validation loss: 2.582104219505149

Epoch: 6| Step: 2
Training loss: 3.3246785976557134
Validation loss: 2.623413850456038

Epoch: 6| Step: 3
Training loss: 2.8383785282582967
Validation loss: 2.6203292353534913

Epoch: 6| Step: 4
Training loss: 2.2000014435156507
Validation loss: 2.634400984558668

Epoch: 6| Step: 5
Training loss: 3.2574164060580366
Validation loss: 2.6231771352216433

Epoch: 6| Step: 6
Training loss: 2.528159244338435
Validation loss: 2.567708400559998

Epoch: 6| Step: 7
Training loss: 2.303679061352167
Validation loss: 2.51438861604173

Epoch: 6| Step: 8
Training loss: 2.6650465772612995
Validation loss: 2.50628729813902

Epoch: 6| Step: 9
Training loss: 2.231911855461164
Validation loss: 2.4677638634614887

Epoch: 6| Step: 10
Training loss: 2.2803981706048186
Validation loss: 2.439577869836407

Epoch: 6| Step: 11
Training loss: 2.235933733816327
Validation loss: 2.4276834540208228

Epoch: 6| Step: 12
Training loss: 2.2779942102132607
Validation loss: 2.4215417829198422

Epoch: 6| Step: 13
Training loss: 2.0223353856716972
Validation loss: 2.4206873378904645

Epoch: 200| Step: 0
Training loss: 2.6710094812382725
Validation loss: 2.426632980173491

Epoch: 6| Step: 1
Training loss: 2.329317542724424
Validation loss: 2.4612444838345375

Epoch: 6| Step: 2
Training loss: 2.6255370907594533
Validation loss: 2.510606932056041

Epoch: 6| Step: 3
Training loss: 1.6567941887256745
Validation loss: 2.551919735923425

Epoch: 6| Step: 4
Training loss: 2.3739322470659663
Validation loss: 2.5467100539836434

Epoch: 6| Step: 5
Training loss: 2.5352388200993934
Validation loss: 2.553702586139239

Epoch: 6| Step: 6
Training loss: 2.370955285643788
Validation loss: 2.537686089077771

Epoch: 6| Step: 7
Training loss: 2.803575895824813
Validation loss: 2.5374703634743856

Epoch: 6| Step: 8
Training loss: 2.7229555422501486
Validation loss: 2.5039412108711705

Epoch: 6| Step: 9
Training loss: 2.7066851858466996
Validation loss: 2.4964789400624587

Epoch: 6| Step: 10
Training loss: 2.8053817527324965
Validation loss: 2.489221781319089

Epoch: 6| Step: 11
Training loss: 2.235590677400468
Validation loss: 2.4585702245615204

Epoch: 6| Step: 12
Training loss: 2.8149667730453958
Validation loss: 2.4533422439345607

Epoch: 6| Step: 13
Training loss: 2.6957924235884074
Validation loss: 2.45385137426505

Epoch: 201| Step: 0
Training loss: 2.5264098433294957
Validation loss: 2.450951712875461

Epoch: 6| Step: 1
Training loss: 1.801434776893577
Validation loss: 2.4973707627161223

Epoch: 6| Step: 2
Training loss: 2.6769902748726406
Validation loss: 2.519540354636015

Epoch: 6| Step: 3
Training loss: 2.4142738422608163
Validation loss: 2.5633888163825986

Epoch: 6| Step: 4
Training loss: 2.5690868667284077
Validation loss: 2.577589595086465

Epoch: 6| Step: 5
Training loss: 2.883885791162633
Validation loss: 2.584024719529019

Epoch: 6| Step: 6
Training loss: 2.251758841663992
Validation loss: 2.5785236824755184

Epoch: 6| Step: 7
Training loss: 2.8678594732079965
Validation loss: 2.6106298469028415

Epoch: 6| Step: 8
Training loss: 2.428786524695809
Validation loss: 2.5769136239768464

Epoch: 6| Step: 9
Training loss: 2.915275096442779
Validation loss: 2.520478023125707

Epoch: 6| Step: 10
Training loss: 2.908585133259295
Validation loss: 2.471079508588496

Epoch: 6| Step: 11
Training loss: 1.84529831095125
Validation loss: 2.4586458728799103

Epoch: 6| Step: 12
Training loss: 2.565763024207969
Validation loss: 2.4590617703656523

Epoch: 6| Step: 13
Training loss: 3.0136696598541763
Validation loss: 2.4931511361104137

Epoch: 202| Step: 0
Training loss: 2.644092878467657
Validation loss: 2.4863114026441586

Epoch: 6| Step: 1
Training loss: 2.9772184355085427
Validation loss: 2.5326740508310035

Epoch: 6| Step: 2
Training loss: 2.543780172483064
Validation loss: 2.4999817047680257

Epoch: 6| Step: 3
Training loss: 2.459578656655226
Validation loss: 2.4872596294378737

Epoch: 6| Step: 4
Training loss: 2.958723302220328
Validation loss: 2.5018442232423395

Epoch: 6| Step: 5
Training loss: 2.523205631338837
Validation loss: 2.5002377755906027

Epoch: 6| Step: 6
Training loss: 2.246242033997911
Validation loss: 2.4857847599885674

Epoch: 6| Step: 7
Training loss: 1.9059184051773055
Validation loss: 2.4981302006300763

Epoch: 6| Step: 8
Training loss: 2.4175917619649416
Validation loss: 2.5008485512754417

Epoch: 6| Step: 9
Training loss: 2.483736639961208
Validation loss: 2.4891452511133885

Epoch: 6| Step: 10
Training loss: 2.740620657244279
Validation loss: 2.486133572435392

Epoch: 6| Step: 11
Training loss: 2.6966649297450083
Validation loss: 2.5195759303703738

Epoch: 6| Step: 12
Training loss: 2.8407251388642294
Validation loss: 2.5576815238553587

Epoch: 6| Step: 13
Training loss: 1.9924154712164395
Validation loss: 2.6250623753212983

Epoch: 203| Step: 0
Training loss: 2.740582814430216
Validation loss: 2.67102064947271

Epoch: 6| Step: 1
Training loss: 3.028463439609881
Validation loss: 2.680205778971202

Epoch: 6| Step: 2
Training loss: 3.0588830881663838
Validation loss: 2.75761479656756

Epoch: 6| Step: 3
Training loss: 2.370398028143926
Validation loss: 2.660545934587643

Epoch: 6| Step: 4
Training loss: 2.709968327692626
Validation loss: 2.6512784021544764

Epoch: 6| Step: 5
Training loss: 2.672789924532486
Validation loss: 2.602038864762931

Epoch: 6| Step: 6
Training loss: 2.619515365884635
Validation loss: 2.5476425808962375

Epoch: 6| Step: 7
Training loss: 2.208466243942788
Validation loss: 2.525846646367736

Epoch: 6| Step: 8
Training loss: 2.3148708047100124
Validation loss: 2.4874722308606554

Epoch: 6| Step: 9
Training loss: 2.21904784876364
Validation loss: 2.4609956176166508

Epoch: 6| Step: 10
Training loss: 2.376828443506098
Validation loss: 2.4481559041312333

Epoch: 6| Step: 11
Training loss: 2.199711095740557
Validation loss: 2.444289304925694

Epoch: 6| Step: 12
Training loss: 2.6706236647395665
Validation loss: 2.4547888654027124

Epoch: 6| Step: 13
Training loss: 2.549363774983093
Validation loss: 2.461996109868665

Epoch: 204| Step: 0
Training loss: 2.4148838658180196
Validation loss: 2.4656839122752725

Epoch: 6| Step: 1
Training loss: 2.7332239834691623
Validation loss: 2.50932613952461

Epoch: 6| Step: 2
Training loss: 2.0243386872424547
Validation loss: 2.5338818080106744

Epoch: 6| Step: 3
Training loss: 2.3444841379518673
Validation loss: 2.567812277632254

Epoch: 6| Step: 4
Training loss: 2.801695181092395
Validation loss: 2.608969761274882

Epoch: 6| Step: 5
Training loss: 2.3282957078446294
Validation loss: 2.604352490758084

Epoch: 6| Step: 6
Training loss: 2.963240158395557
Validation loss: 2.610808975381931

Epoch: 6| Step: 7
Training loss: 2.5329254633512344
Validation loss: 2.5854021769969497

Epoch: 6| Step: 8
Training loss: 2.6333575038364
Validation loss: 2.5699013131366724

Epoch: 6| Step: 9
Training loss: 2.1168717152356322
Validation loss: 2.5542312575427784

Epoch: 6| Step: 10
Training loss: 2.492846171713697
Validation loss: 2.521905509505058

Epoch: 6| Step: 11
Training loss: 2.3607101199655607
Validation loss: 2.4891913718962893

Epoch: 6| Step: 12
Training loss: 1.9352411823631144
Validation loss: 2.483288648750739

Epoch: 6| Step: 13
Training loss: 3.310539241095549
Validation loss: 2.4657308472305384

Epoch: 205| Step: 0
Training loss: 2.8697504962568785
Validation loss: 2.4571618935010426

Epoch: 6| Step: 1
Training loss: 1.956841800375175
Validation loss: 2.4723856521177994

Epoch: 6| Step: 2
Training loss: 2.378113061621798
Validation loss: 2.491458570843636

Epoch: 6| Step: 3
Training loss: 2.9988897176412173
Validation loss: 2.5199287001223802

Epoch: 6| Step: 4
Training loss: 2.4377070607978957
Validation loss: 2.5190276446222413

Epoch: 6| Step: 5
Training loss: 2.2525932414648056
Validation loss: 2.5517672974464705

Epoch: 6| Step: 6
Training loss: 2.7381242606399954
Validation loss: 2.578102234522049

Epoch: 6| Step: 7
Training loss: 2.491313434258336
Validation loss: 2.6113471853780554

Epoch: 6| Step: 8
Training loss: 2.1219593059438115
Validation loss: 2.6327092838877606

Epoch: 6| Step: 9
Training loss: 2.3481706763366925
Validation loss: 2.5881365321215206

Epoch: 6| Step: 10
Training loss: 2.4258630219711885
Validation loss: 2.578252825608782

Epoch: 6| Step: 11
Training loss: 2.4340744401053893
Validation loss: 2.5474196761988375

Epoch: 6| Step: 12
Training loss: 2.6406408907620973
Validation loss: 2.5259597452113702

Epoch: 6| Step: 13
Training loss: 2.6396758952743204
Validation loss: 2.502892920538221

Epoch: 206| Step: 0
Training loss: 2.784417909233763
Validation loss: 2.468085932175126

Epoch: 6| Step: 1
Training loss: 2.2768468298309466
Validation loss: 2.438621757197732

Epoch: 6| Step: 2
Training loss: 2.3192217282735688
Validation loss: 2.4228136946052135

Epoch: 6| Step: 3
Training loss: 2.7737044944657727
Validation loss: 2.431661276233992

Epoch: 6| Step: 4
Training loss: 2.810402151362038
Validation loss: 2.4376921902706963

Epoch: 6| Step: 5
Training loss: 2.9903762953135584
Validation loss: 2.4501296206873735

Epoch: 6| Step: 6
Training loss: 2.5417774885020736
Validation loss: 2.494998613395341

Epoch: 6| Step: 7
Training loss: 1.700526924375537
Validation loss: 2.5286896179719984

Epoch: 6| Step: 8
Training loss: 1.710633969490751
Validation loss: 2.567791746958247

Epoch: 6| Step: 9
Training loss: 3.1513839829987047
Validation loss: 2.5898175833175867

Epoch: 6| Step: 10
Training loss: 2.64418917856653
Validation loss: 2.631069226108366

Epoch: 6| Step: 11
Training loss: 2.222518085281714
Validation loss: 2.641374084080946

Epoch: 6| Step: 12
Training loss: 1.5655677434688857
Validation loss: 2.6624576598167105

Epoch: 6| Step: 13
Training loss: 2.7102891657926715
Validation loss: 2.61310837755721

Epoch: 207| Step: 0
Training loss: 1.5717712004044668
Validation loss: 2.5740699018572437

Epoch: 6| Step: 1
Training loss: 2.3633686144104913
Validation loss: 2.5261470991297967

Epoch: 6| Step: 2
Training loss: 2.0671616094904084
Validation loss: 2.5141607145251315

Epoch: 6| Step: 3
Training loss: 2.6489242961545374
Validation loss: 2.5004116632072484

Epoch: 6| Step: 4
Training loss: 2.7474922536891766
Validation loss: 2.4695696744040028

Epoch: 6| Step: 5
Training loss: 2.109189738862463
Validation loss: 2.4638620630585026

Epoch: 6| Step: 6
Training loss: 2.972812162263134
Validation loss: 2.466614472081727

Epoch: 6| Step: 7
Training loss: 2.5091967223652114
Validation loss: 2.494939927393476

Epoch: 6| Step: 8
Training loss: 2.7394052503213686
Validation loss: 2.5143552457223555

Epoch: 6| Step: 9
Training loss: 2.1523515039986236
Validation loss: 2.5196107404614265

Epoch: 6| Step: 10
Training loss: 2.7457353295610996
Validation loss: 2.524474442673224

Epoch: 6| Step: 11
Training loss: 3.0585502533724673
Validation loss: 2.555927386288332

Epoch: 6| Step: 12
Training loss: 2.0074548068725586
Validation loss: 2.5137980237020376

Epoch: 6| Step: 13
Training loss: 2.3427749640144566
Validation loss: 2.518568588942644

Epoch: 208| Step: 0
Training loss: 2.830832518393199
Validation loss: 2.506645879176016

Epoch: 6| Step: 1
Training loss: 2.7536501501598014
Validation loss: 2.507740346709934

Epoch: 6| Step: 2
Training loss: 2.827412552429904
Validation loss: 2.5148961820262548

Epoch: 6| Step: 3
Training loss: 2.752122233537253
Validation loss: 2.5214713802831903

Epoch: 6| Step: 4
Training loss: 2.2778968728210693
Validation loss: 2.501469250113428

Epoch: 6| Step: 5
Training loss: 1.943418875698731
Validation loss: 2.527026173981853

Epoch: 6| Step: 6
Training loss: 2.1341424505351148
Validation loss: 2.538787026176961

Epoch: 6| Step: 7
Training loss: 2.820052792751627
Validation loss: 2.5702289720204874

Epoch: 6| Step: 8
Training loss: 2.8646771409829612
Validation loss: 2.6141206097938983

Epoch: 6| Step: 9
Training loss: 2.176051234371419
Validation loss: 2.6505353322271112

Epoch: 6| Step: 10
Training loss: 1.9330000148838318
Validation loss: 2.641483610728238

Epoch: 6| Step: 11
Training loss: 2.375764824039936
Validation loss: 2.636228138237713

Epoch: 6| Step: 12
Training loss: 1.8673823426549978
Validation loss: 2.625759388961028

Epoch: 6| Step: 13
Training loss: 3.086049833546807
Validation loss: 2.606696869945546

Epoch: 209| Step: 0
Training loss: 2.2364926206900666
Validation loss: 2.5520955477018967

Epoch: 6| Step: 1
Training loss: 2.379117007385884
Validation loss: 2.533850167531667

Epoch: 6| Step: 2
Training loss: 1.6914422645875276
Validation loss: 2.5000942796957353

Epoch: 6| Step: 3
Training loss: 2.724349821026415
Validation loss: 2.4747654070009073

Epoch: 6| Step: 4
Training loss: 2.800418420590627
Validation loss: 2.467429088460411

Epoch: 6| Step: 5
Training loss: 2.4245734164025388
Validation loss: 2.4861250466597244

Epoch: 6| Step: 6
Training loss: 2.170626494156982
Validation loss: 2.4835781099693777

Epoch: 6| Step: 7
Training loss: 2.4526243245599386
Validation loss: 2.4894447706864002

Epoch: 6| Step: 8
Training loss: 2.3884241282882224
Validation loss: 2.5023912909066843

Epoch: 6| Step: 9
Training loss: 2.489997786708599
Validation loss: 2.5217783136478857

Epoch: 6| Step: 10
Training loss: 2.5797873946129375
Validation loss: 2.5266325012376827

Epoch: 6| Step: 11
Training loss: 2.9781550755137975
Validation loss: 2.577997879071362

Epoch: 6| Step: 12
Training loss: 2.148885895147192
Validation loss: 2.5949655099600353

Epoch: 6| Step: 13
Training loss: 2.59034008488675
Validation loss: 2.6141739107055564

Epoch: 210| Step: 0
Training loss: 2.5153565826325637
Validation loss: 2.592046756396479

Epoch: 6| Step: 1
Training loss: 2.5354304701701804
Validation loss: 2.5690156969345552

Epoch: 6| Step: 2
Training loss: 2.2992142164293883
Validation loss: 2.5658632522718277

Epoch: 6| Step: 3
Training loss: 2.755295682987526
Validation loss: 2.5411439563563443

Epoch: 6| Step: 4
Training loss: 2.7523854053559975
Validation loss: 2.5575950654272384

Epoch: 6| Step: 5
Training loss: 2.5703442232441076
Validation loss: 2.5554223831412526

Epoch: 6| Step: 6
Training loss: 2.5794775911508734
Validation loss: 2.5564327890801595

Epoch: 6| Step: 7
Training loss: 2.338921213820168
Validation loss: 2.566062282990855

Epoch: 6| Step: 8
Training loss: 2.307781870644534
Validation loss: 2.601060516292932

Epoch: 6| Step: 9
Training loss: 1.6492307661622592
Validation loss: 2.619405981589562

Epoch: 6| Step: 10
Training loss: 2.272110699334277
Validation loss: 2.6127187717453726

Epoch: 6| Step: 11
Training loss: 2.3130830596774508
Validation loss: 2.6029256535589544

Epoch: 6| Step: 12
Training loss: 2.2384369747720965
Validation loss: 2.5779431271159226

Epoch: 6| Step: 13
Training loss: 2.5386320248064798
Validation loss: 2.5609424338375537

Epoch: 211| Step: 0
Training loss: 2.4063044950581403
Validation loss: 2.554679319417474

Epoch: 6| Step: 1
Training loss: 2.622588275918302
Validation loss: 2.5416581469600987

Epoch: 6| Step: 2
Training loss: 2.226467304537079
Validation loss: 2.504166120980555

Epoch: 6| Step: 3
Training loss: 2.1136970604527745
Validation loss: 2.4863550611813148

Epoch: 6| Step: 4
Training loss: 2.5169417447792766
Validation loss: 2.4847106727462167

Epoch: 6| Step: 5
Training loss: 2.4880646951243097
Validation loss: 2.482901004541231

Epoch: 6| Step: 6
Training loss: 2.512478204888851
Validation loss: 2.4831725275429797

Epoch: 6| Step: 7
Training loss: 2.8826675998899143
Validation loss: 2.4967944657174024

Epoch: 6| Step: 8
Training loss: 1.9256923569905897
Validation loss: 2.4835973951739945

Epoch: 6| Step: 9
Training loss: 2.6226079123289288
Validation loss: 2.5224356349407326

Epoch: 6| Step: 10
Training loss: 2.061616650619442
Validation loss: 2.520215139621788

Epoch: 6| Step: 11
Training loss: 1.8340564587679313
Validation loss: 2.519647385570218

Epoch: 6| Step: 12
Training loss: 2.9654185023232214
Validation loss: 2.5334382953364094

Epoch: 6| Step: 13
Training loss: 2.0431009691096538
Validation loss: 2.5413767264127296

Epoch: 212| Step: 0
Training loss: 2.7096229906116496
Validation loss: 2.552225045611523

Epoch: 6| Step: 1
Training loss: 2.686223281294348
Validation loss: 2.546633415710029

Epoch: 6| Step: 2
Training loss: 2.1470192406853386
Validation loss: 2.5876980672110266

Epoch: 6| Step: 3
Training loss: 2.1193367159779353
Validation loss: 2.592900265114098

Epoch: 6| Step: 4
Training loss: 1.7315441776800882
Validation loss: 2.615492374725756

Epoch: 6| Step: 5
Training loss: 2.0434519559188766
Validation loss: 2.6331515542552513

Epoch: 6| Step: 6
Training loss: 2.1062777916407613
Validation loss: 2.620730344434951

Epoch: 6| Step: 7
Training loss: 2.6764857791698864
Validation loss: 2.619584320095367

Epoch: 6| Step: 8
Training loss: 2.672083974775028
Validation loss: 2.591387678511991

Epoch: 6| Step: 9
Training loss: 2.5195535821442454
Validation loss: 2.5747261765345972

Epoch: 6| Step: 10
Training loss: 2.9727204124153057
Validation loss: 2.566822525132387

Epoch: 6| Step: 11
Training loss: 1.6332922417798064
Validation loss: 2.5400936696466623

Epoch: 6| Step: 12
Training loss: 2.6534991212868193
Validation loss: 2.554908603637082

Epoch: 6| Step: 13
Training loss: 1.8640307952154316
Validation loss: 2.5542659320748635

Epoch: 213| Step: 0
Training loss: 2.0502694208764742
Validation loss: 2.525225063443757

Epoch: 6| Step: 1
Training loss: 2.5457826858036023
Validation loss: 2.5317857226797793

Epoch: 6| Step: 2
Training loss: 2.635415349867018
Validation loss: 2.5302555800127515

Epoch: 6| Step: 3
Training loss: 2.2735666978967553
Validation loss: 2.531992387292859

Epoch: 6| Step: 4
Training loss: 2.500840522614259
Validation loss: 2.5406501293207233

Epoch: 6| Step: 5
Training loss: 2.350633710273523
Validation loss: 2.5111354193311137

Epoch: 6| Step: 6
Training loss: 2.241842954527295
Validation loss: 2.5206183092072503

Epoch: 6| Step: 7
Training loss: 2.113576025861371
Validation loss: 2.4949022689417837

Epoch: 6| Step: 8
Training loss: 2.3181736396876476
Validation loss: 2.5011853720088717

Epoch: 6| Step: 9
Training loss: 2.071624110064289
Validation loss: 2.4856102740411075

Epoch: 6| Step: 10
Training loss: 2.8276626461884407
Validation loss: 2.5141331238589752

Epoch: 6| Step: 11
Training loss: 2.790802057849792
Validation loss: 2.5356254947926797

Epoch: 6| Step: 12
Training loss: 2.2741356266075177
Validation loss: 2.5602000620129566

Epoch: 6| Step: 13
Training loss: 2.0506427827137865
Validation loss: 2.6034200960815364

Epoch: 214| Step: 0
Training loss: 2.4036036219391343
Validation loss: 2.630146217810783

Epoch: 6| Step: 1
Training loss: 2.2666198650839027
Validation loss: 2.6295388939777187

Epoch: 6| Step: 2
Training loss: 2.4985133519208103
Validation loss: 2.6133563663961037

Epoch: 6| Step: 3
Training loss: 2.065030250974296
Validation loss: 2.594385105168051

Epoch: 6| Step: 4
Training loss: 3.009560609601709
Validation loss: 2.5770114287369936

Epoch: 6| Step: 5
Training loss: 2.122322190456138
Validation loss: 2.5621296484691647

Epoch: 6| Step: 6
Training loss: 2.1848411750246304
Validation loss: 2.553533022210655

Epoch: 6| Step: 7
Training loss: 1.8115293600391729
Validation loss: 2.550818538771678

Epoch: 6| Step: 8
Training loss: 2.4767149869261993
Validation loss: 2.575217471530469

Epoch: 6| Step: 9
Training loss: 2.4406944274796216
Validation loss: 2.5993492563555707

Epoch: 6| Step: 10
Training loss: 2.120156096703648
Validation loss: 2.6201985625308892

Epoch: 6| Step: 11
Training loss: 2.5231908908014353
Validation loss: 2.662987989111114

Epoch: 6| Step: 12
Training loss: 2.8472553489019186
Validation loss: 2.6783276259749234

Epoch: 6| Step: 13
Training loss: 1.8656146076366615
Validation loss: 2.6460964222910235

Epoch: 215| Step: 0
Training loss: 1.9139001271410512
Validation loss: 2.6248522031774018

Epoch: 6| Step: 1
Training loss: 1.9711314738651917
Validation loss: 2.6750468197760804

Epoch: 6| Step: 2
Training loss: 2.743575828776575
Validation loss: 2.7376591755512334

Epoch: 6| Step: 3
Training loss: 1.9844219772905805
Validation loss: 2.7634058436247697

Epoch: 6| Step: 4
Training loss: 2.4784836883531467
Validation loss: 2.7610311860066674

Epoch: 6| Step: 5
Training loss: 2.506619654004921
Validation loss: 2.6950624411473134

Epoch: 6| Step: 6
Training loss: 1.9058890704550475
Validation loss: 2.643644068256362

Epoch: 6| Step: 7
Training loss: 2.163402250080714
Validation loss: 2.616697409690695

Epoch: 6| Step: 8
Training loss: 2.4808881750463807
Validation loss: 2.5819638982717836

Epoch: 6| Step: 9
Training loss: 1.9529700866299105
Validation loss: 2.563473159279935

Epoch: 6| Step: 10
Training loss: 2.2070032708749183
Validation loss: 2.5530767225592466

Epoch: 6| Step: 11
Training loss: 2.928539814263345
Validation loss: 2.5539007115239007

Epoch: 6| Step: 12
Training loss: 2.3555154115726973
Validation loss: 2.539732080964833

Epoch: 6| Step: 13
Training loss: 2.8066671286587854
Validation loss: 2.5502185738313305

Epoch: 216| Step: 0
Training loss: 2.4448676634003172
Validation loss: 2.5743669372656517

Epoch: 6| Step: 1
Training loss: 2.064703602243772
Validation loss: 2.5890996118783556

Epoch: 6| Step: 2
Training loss: 2.4179502125955405
Validation loss: 2.593043039114257

Epoch: 6| Step: 3
Training loss: 2.691745332526958
Validation loss: 2.6021750183381074

Epoch: 6| Step: 4
Training loss: 2.7529417256243978
Validation loss: 2.6247431301728024

Epoch: 6| Step: 5
Training loss: 2.332313916632792
Validation loss: 2.634945060507645

Epoch: 6| Step: 6
Training loss: 2.0843245881946113
Validation loss: 2.6745797282654604

Epoch: 6| Step: 7
Training loss: 2.2879042054643257
Validation loss: 2.6701124598122905

Epoch: 6| Step: 8
Training loss: 2.6290643199541184
Validation loss: 2.7071630639391993

Epoch: 6| Step: 9
Training loss: 2.262225105910013
Validation loss: 2.7292689817992324

Epoch: 6| Step: 10
Training loss: 1.8564074260090517
Validation loss: 2.665882738183602

Epoch: 6| Step: 11
Training loss: 2.1551990988822247
Validation loss: 2.6239421771800084

Epoch: 6| Step: 12
Training loss: 2.672600184847497
Validation loss: 2.5650639086663922

Epoch: 6| Step: 13
Training loss: 1.7573467400526168
Validation loss: 2.566409435561488

Epoch: 217| Step: 0
Training loss: 2.1052008123954002
Validation loss: 2.5120885673039544

Epoch: 6| Step: 1
Training loss: 2.4313692117604195
Validation loss: 2.4872672607948587

Epoch: 6| Step: 2
Training loss: 2.08646137645523
Validation loss: 2.4889840271271044

Epoch: 6| Step: 3
Training loss: 2.6019146655117695
Validation loss: 2.478723308669048

Epoch: 6| Step: 4
Training loss: 1.5568621584294904
Validation loss: 2.5026912969620367

Epoch: 6| Step: 5
Training loss: 2.276652576389899
Validation loss: 2.496656564269061

Epoch: 6| Step: 6
Training loss: 2.468945266147852
Validation loss: 2.533510750914213

Epoch: 6| Step: 7
Training loss: 1.9517473779218282
Validation loss: 2.5221199749528895

Epoch: 6| Step: 8
Training loss: 2.6782679231446864
Validation loss: 2.571926853363587

Epoch: 6| Step: 9
Training loss: 2.629676739947767
Validation loss: 2.6267702498213086

Epoch: 6| Step: 10
Training loss: 2.4938897803576374
Validation loss: 2.6736267033632677

Epoch: 6| Step: 11
Training loss: 2.6202064524546738
Validation loss: 2.626798538067573

Epoch: 6| Step: 12
Training loss: 2.3517566486701402
Validation loss: 2.5993174649764827

Epoch: 6| Step: 13
Training loss: 1.7407828514530714
Validation loss: 2.5411478323665113

Epoch: 218| Step: 0
Training loss: 2.2698898688669167
Validation loss: 2.5078405374145443

Epoch: 6| Step: 1
Training loss: 2.75061479111961
Validation loss: 2.48979856103344

Epoch: 6| Step: 2
Training loss: 2.391459001659073
Validation loss: 2.48306929105508

Epoch: 6| Step: 3
Training loss: 1.5193883049028116
Validation loss: 2.520097076024508

Epoch: 6| Step: 4
Training loss: 2.5144095949983325
Validation loss: 2.500375108367479

Epoch: 6| Step: 5
Training loss: 1.988556069078306
Validation loss: 2.5215810265061656

Epoch: 6| Step: 6
Training loss: 1.8643619114630245
Validation loss: 2.5298262784810293

Epoch: 6| Step: 7
Training loss: 2.718452174218031
Validation loss: 2.5381250046284665

Epoch: 6| Step: 8
Training loss: 2.0937427122074657
Validation loss: 2.5599846073049664

Epoch: 6| Step: 9
Training loss: 3.2201943721510964
Validation loss: 2.543708678624949

Epoch: 6| Step: 10
Training loss: 2.1963616847222514
Validation loss: 2.5379337428869784

Epoch: 6| Step: 11
Training loss: 2.371059763129051
Validation loss: 2.5163768454199302

Epoch: 6| Step: 12
Training loss: 2.425995895545802
Validation loss: 2.5027607164372023

Epoch: 6| Step: 13
Training loss: 2.3293637046202336
Validation loss: 2.493537311755278

Epoch: 219| Step: 0
Training loss: 2.174489923934064
Validation loss: 2.47821306419421

Epoch: 6| Step: 1
Training loss: 2.793744770360912
Validation loss: 2.5128365513438204

Epoch: 6| Step: 2
Training loss: 2.005234068337969
Validation loss: 2.5575852171842235

Epoch: 6| Step: 3
Training loss: 2.2179830595699017
Validation loss: 2.6044950656353665

Epoch: 6| Step: 4
Training loss: 2.25569174668049
Validation loss: 2.6313055251081594

Epoch: 6| Step: 5
Training loss: 2.5711924429364057
Validation loss: 2.6635273315372974

Epoch: 6| Step: 6
Training loss: 2.0352616822798106
Validation loss: 2.614879223391174

Epoch: 6| Step: 7
Training loss: 2.4269185371826154
Validation loss: 2.647880640612055

Epoch: 6| Step: 8
Training loss: 1.9270627476048041
Validation loss: 2.63477527427483

Epoch: 6| Step: 9
Training loss: 1.6280034991889858
Validation loss: 2.616986297626533

Epoch: 6| Step: 10
Training loss: 2.2123582137199684
Validation loss: 2.615342730044912

Epoch: 6| Step: 11
Training loss: 2.8398103357839055
Validation loss: 2.6011847164118698

Epoch: 6| Step: 12
Training loss: 3.042716137019442
Validation loss: 2.5565716046109928

Epoch: 6| Step: 13
Training loss: 1.672473622044221
Validation loss: 2.5191978214250055

Epoch: 220| Step: 0
Training loss: 2.687001736605232
Validation loss: 2.5145930137304875

Epoch: 6| Step: 1
Training loss: 2.3371617607967083
Validation loss: 2.4900713467300433

Epoch: 6| Step: 2
Training loss: 2.042994891085144
Validation loss: 2.510410575534227

Epoch: 6| Step: 3
Training loss: 2.5770281683759353
Validation loss: 2.482095438370182

Epoch: 6| Step: 4
Training loss: 2.4317060224325866
Validation loss: 2.495255893206959

Epoch: 6| Step: 5
Training loss: 2.722375491319091
Validation loss: 2.480547844844407

Epoch: 6| Step: 6
Training loss: 2.2925681912962075
Validation loss: 2.502108853481103

Epoch: 6| Step: 7
Training loss: 2.0817503319148263
Validation loss: 2.5094383473568977

Epoch: 6| Step: 8
Training loss: 2.2094153026913808
Validation loss: 2.541915184094747

Epoch: 6| Step: 9
Training loss: 2.5557508209743633
Validation loss: 2.5104653134996266

Epoch: 6| Step: 10
Training loss: 2.031992263155949
Validation loss: 2.4851190473523763

Epoch: 6| Step: 11
Training loss: 2.4379817779961583
Validation loss: 2.4831601871710083

Epoch: 6| Step: 12
Training loss: 1.9453007341511652
Validation loss: 2.4429217039253506

Epoch: 6| Step: 13
Training loss: 2.4403790807953176
Validation loss: 2.448809474301615

Epoch: 221| Step: 0
Training loss: 2.3516920694033123
Validation loss: 2.4256786369449514

Epoch: 6| Step: 1
Training loss: 2.418027516576859
Validation loss: 2.455448655062661

Epoch: 6| Step: 2
Training loss: 2.965777384598365
Validation loss: 2.4785383287722302

Epoch: 6| Step: 3
Training loss: 2.534961005217562
Validation loss: 2.4957114670953167

Epoch: 6| Step: 4
Training loss: 1.8998461861841467
Validation loss: 2.528420687441518

Epoch: 6| Step: 5
Training loss: 2.262794778915405
Validation loss: 2.5276405418996837

Epoch: 6| Step: 6
Training loss: 2.179344013454391
Validation loss: 2.554652613928192

Epoch: 6| Step: 7
Training loss: 2.2617564881755503
Validation loss: 2.581684151459869

Epoch: 6| Step: 8
Training loss: 1.982881840304319
Validation loss: 2.635588944820038

Epoch: 6| Step: 9
Training loss: 2.1718576554079236
Validation loss: 2.649663909043558

Epoch: 6| Step: 10
Training loss: 2.093409838017498
Validation loss: 2.6709844590790883

Epoch: 6| Step: 11
Training loss: 1.986515782736917
Validation loss: 2.603511583853009

Epoch: 6| Step: 12
Training loss: 1.8064863479313789
Validation loss: 2.656734379439801

Epoch: 6| Step: 13
Training loss: 2.278602840926265
Validation loss: 2.590987445114716

Epoch: 222| Step: 0
Training loss: 1.9639025153383243
Validation loss: 2.6128037514912914

Epoch: 6| Step: 1
Training loss: 2.053801951294029
Validation loss: 2.639849425647537

Epoch: 6| Step: 2
Training loss: 1.8438771090901134
Validation loss: 2.672722902192362

Epoch: 6| Step: 3
Training loss: 2.476013892989861
Validation loss: 2.690318771627014

Epoch: 6| Step: 4
Training loss: 2.2390210059314857
Validation loss: 2.6651156251130645

Epoch: 6| Step: 5
Training loss: 2.3165645448785535
Validation loss: 2.6578387321049655

Epoch: 6| Step: 6
Training loss: 1.9603742421255828
Validation loss: 2.583143729106891

Epoch: 6| Step: 7
Training loss: 2.1531243267528883
Validation loss: 2.5567310503111997

Epoch: 6| Step: 8
Training loss: 2.5549816463878767
Validation loss: 2.539865714752792

Epoch: 6| Step: 9
Training loss: 2.562882929777161
Validation loss: 2.5332506265346235

Epoch: 6| Step: 10
Training loss: 2.077464177893546
Validation loss: 2.5398813234586934

Epoch: 6| Step: 11
Training loss: 2.09026764465557
Validation loss: 2.506209304082689

Epoch: 6| Step: 12
Training loss: 2.419573077541465
Validation loss: 2.5331723635923895

Epoch: 6| Step: 13
Training loss: 2.616867455798914
Validation loss: 2.568905798996703

Epoch: 223| Step: 0
Training loss: 2.020635601739183
Validation loss: 2.565802899885544

Epoch: 6| Step: 1
Training loss: 2.1059728241966664
Validation loss: 2.553784035587222

Epoch: 6| Step: 2
Training loss: 2.4204700948140045
Validation loss: 2.548878313493831

Epoch: 6| Step: 3
Training loss: 2.1521893288383174
Validation loss: 2.566979227849923

Epoch: 6| Step: 4
Training loss: 2.314849793770323
Validation loss: 2.586110057401542

Epoch: 6| Step: 5
Training loss: 2.1670026396421544
Validation loss: 2.587669407000785

Epoch: 6| Step: 6
Training loss: 1.9377780837798582
Validation loss: 2.6061676082403267

Epoch: 6| Step: 7
Training loss: 2.506923244547534
Validation loss: 2.5880790754827965

Epoch: 6| Step: 8
Training loss: 2.1776837946059917
Validation loss: 2.575874190816134

Epoch: 6| Step: 9
Training loss: 1.8241222936055599
Validation loss: 2.547210607832732

Epoch: 6| Step: 10
Training loss: 2.2003108238513978
Validation loss: 2.5469717207072264

Epoch: 6| Step: 11
Training loss: 2.673869944232182
Validation loss: 2.559034283401269

Epoch: 6| Step: 12
Training loss: 1.9232965189927118
Validation loss: 2.559933327161073

Epoch: 6| Step: 13
Training loss: 2.4287416634880388
Validation loss: 2.563109681767617

Epoch: 224| Step: 0
Training loss: 1.548779326893236
Validation loss: 2.563826475014539

Epoch: 6| Step: 1
Training loss: 2.663948123747545
Validation loss: 2.6026519343964107

Epoch: 6| Step: 2
Training loss: 2.1920352243948527
Validation loss: 2.598890111607624

Epoch: 6| Step: 3
Training loss: 2.1060787867112096
Validation loss: 2.600375623267124

Epoch: 6| Step: 4
Training loss: 3.062714549743088
Validation loss: 2.5754828583656604

Epoch: 6| Step: 5
Training loss: 1.9881130064884651
Validation loss: 2.598717625450501

Epoch: 6| Step: 6
Training loss: 1.7771869296801963
Validation loss: 2.6035274185356534

Epoch: 6| Step: 7
Training loss: 1.6124812398602866
Validation loss: 2.5747661110411646

Epoch: 6| Step: 8
Training loss: 1.997382716434651
Validation loss: 2.6047244666150315

Epoch: 6| Step: 9
Training loss: 2.2172994035650775
Validation loss: 2.56583277851075

Epoch: 6| Step: 10
Training loss: 2.0481875339119378
Validation loss: 2.561767100150736

Epoch: 6| Step: 11
Training loss: 2.0111322529467754
Validation loss: 2.562574873219825

Epoch: 6| Step: 12
Training loss: 2.50573007037418
Validation loss: 2.544457083127057

Epoch: 6| Step: 13
Training loss: 2.064503130492121
Validation loss: 2.530462460773682

Epoch: 225| Step: 0
Training loss: 2.3205686485626
Validation loss: 2.5144659771160085

Epoch: 6| Step: 1
Training loss: 2.3934849604796935
Validation loss: 2.4976522938103742

Epoch: 6| Step: 2
Training loss: 1.5722095171471597
Validation loss: 2.488906338555952

Epoch: 6| Step: 3
Training loss: 2.471499300447859
Validation loss: 2.499329362153442

Epoch: 6| Step: 4
Training loss: 1.8735751778327356
Validation loss: 2.513752372744128

Epoch: 6| Step: 5
Training loss: 2.0467226393974514
Validation loss: 2.5151584594912477

Epoch: 6| Step: 6
Training loss: 2.3975759940887005
Validation loss: 2.531044904491374

Epoch: 6| Step: 7
Training loss: 1.7594169245818356
Validation loss: 2.560191520535506

Epoch: 6| Step: 8
Training loss: 1.8857460436788964
Validation loss: 2.601533515579268

Epoch: 6| Step: 9
Training loss: 2.042001528105131
Validation loss: 2.6142566121987736

Epoch: 6| Step: 10
Training loss: 2.040289381857081
Validation loss: 2.6040245181429436

Epoch: 6| Step: 11
Training loss: 2.1490152587845937
Validation loss: 2.5896891227901637

Epoch: 6| Step: 12
Training loss: 2.934616621670797
Validation loss: 2.5726829310712165

Epoch: 6| Step: 13
Training loss: 2.076809803952204
Validation loss: 2.581377916524228

Epoch: 226| Step: 0
Training loss: 2.174867612821705
Validation loss: 2.5326319894201115

Epoch: 6| Step: 1
Training loss: 2.4090019441931685
Validation loss: 2.5770175726855666

Epoch: 6| Step: 2
Training loss: 1.9595647619612346
Validation loss: 2.595130476936955

Epoch: 6| Step: 3
Training loss: 1.8280406182532276
Validation loss: 2.6179809650717565

Epoch: 6| Step: 4
Training loss: 2.2311123589127604
Validation loss: 2.640977888707102

Epoch: 6| Step: 5
Training loss: 2.4556162630558296
Validation loss: 2.6281235067206676

Epoch: 6| Step: 6
Training loss: 2.044285657954475
Validation loss: 2.5945870286477986

Epoch: 6| Step: 7
Training loss: 1.9979820203649938
Validation loss: 2.6367846253376097

Epoch: 6| Step: 8
Training loss: 1.4337730191685174
Validation loss: 2.682138832931931

Epoch: 6| Step: 9
Training loss: 2.6261185578939017
Validation loss: 2.670829076493053

Epoch: 6| Step: 10
Training loss: 2.098307872412721
Validation loss: 2.6126454640932226

Epoch: 6| Step: 11
Training loss: 2.048444073722528
Validation loss: 2.538165147855255

Epoch: 6| Step: 12
Training loss: 2.623639889715153
Validation loss: 2.484207369524689

Epoch: 6| Step: 13
Training loss: 2.2245315658720233
Validation loss: 2.455451021950076

Epoch: 227| Step: 0
Training loss: 2.1206570170419927
Validation loss: 2.4590901634505538

Epoch: 6| Step: 1
Training loss: 1.8725831031438716
Validation loss: 2.4566854359462753

Epoch: 6| Step: 2
Training loss: 1.827507632092196
Validation loss: 2.4239971420619555

Epoch: 6| Step: 3
Training loss: 1.8589924651224599
Validation loss: 2.4459168052639244

Epoch: 6| Step: 4
Training loss: 2.4678369113139356
Validation loss: 2.467711743722311

Epoch: 6| Step: 5
Training loss: 2.9187239521179444
Validation loss: 2.5060476147787734

Epoch: 6| Step: 6
Training loss: 1.842871634530914
Validation loss: 2.539022129643456

Epoch: 6| Step: 7
Training loss: 2.2860168401543413
Validation loss: 2.6255869411876773

Epoch: 6| Step: 8
Training loss: 2.177213077846639
Validation loss: 2.667376199536539

Epoch: 6| Step: 9
Training loss: 2.3890197949681187
Validation loss: 2.7212954571025603

Epoch: 6| Step: 10
Training loss: 2.0336730589846157
Validation loss: 2.741428599896574

Epoch: 6| Step: 11
Training loss: 2.3018284537181914
Validation loss: 2.701124758233058

Epoch: 6| Step: 12
Training loss: 2.0815253868854877
Validation loss: 2.6077526861428297

Epoch: 6| Step: 13
Training loss: 2.1802085335760726
Validation loss: 2.5580878802141864

Epoch: 228| Step: 0
Training loss: 2.450506963633178
Validation loss: 2.547705305553684

Epoch: 6| Step: 1
Training loss: 1.6117053151090786
Validation loss: 2.5586756859931037

Epoch: 6| Step: 2
Training loss: 2.384516872519889
Validation loss: 2.536427463164154

Epoch: 6| Step: 3
Training loss: 1.7658492089434465
Validation loss: 2.531265457249942

Epoch: 6| Step: 4
Training loss: 2.069377875341908
Validation loss: 2.4877262370631366

Epoch: 6| Step: 5
Training loss: 1.7085060714600402
Validation loss: 2.49597806019083

Epoch: 6| Step: 6
Training loss: 2.1593093177533245
Validation loss: 2.48952075723259

Epoch: 6| Step: 7
Training loss: 2.420141965942275
Validation loss: 2.504044443262375

Epoch: 6| Step: 8
Training loss: 2.1467195057536177
Validation loss: 2.4971872534506865

Epoch: 6| Step: 9
Training loss: 2.1754399961711006
Validation loss: 2.5080953908770844

Epoch: 6| Step: 10
Training loss: 2.347139882506315
Validation loss: 2.5097084263295586

Epoch: 6| Step: 11
Training loss: 2.133759229089212
Validation loss: 2.524745000867384

Epoch: 6| Step: 12
Training loss: 2.090468839050469
Validation loss: 2.5113597805945416

Epoch: 6| Step: 13
Training loss: 1.7597097373157546
Validation loss: 2.5368620292729878

Epoch: 229| Step: 0
Training loss: 2.205426251998223
Validation loss: 2.564317534386777

Epoch: 6| Step: 1
Training loss: 2.233317304904793
Validation loss: 2.5748244173452437

Epoch: 6| Step: 2
Training loss: 1.6920602428317095
Validation loss: 2.5994128172362947

Epoch: 6| Step: 3
Training loss: 2.191513086118451
Validation loss: 2.554900641504851

Epoch: 6| Step: 4
Training loss: 2.4140498583811394
Validation loss: 2.5650606454759624

Epoch: 6| Step: 5
Training loss: 1.79562108614024
Validation loss: 2.5507249690734883

Epoch: 6| Step: 6
Training loss: 2.6765625641350144
Validation loss: 2.5492418923238174

Epoch: 6| Step: 7
Training loss: 2.300836481490348
Validation loss: 2.5570697157208526

Epoch: 6| Step: 8
Training loss: 1.6950989338181766
Validation loss: 2.559627934339315

Epoch: 6| Step: 9
Training loss: 1.842031745053088
Validation loss: 2.53267946522655

Epoch: 6| Step: 10
Training loss: 1.8910932985526034
Validation loss: 2.5291334160138486

Epoch: 6| Step: 11
Training loss: 2.0612719954872243
Validation loss: 2.5002726703554674

Epoch: 6| Step: 12
Training loss: 1.9449536095899642
Validation loss: 2.543423865420092

Epoch: 6| Step: 13
Training loss: 2.197221462229798
Validation loss: 2.532289092966731

Epoch: 230| Step: 0
Training loss: 1.6802280709450863
Validation loss: 2.5163007320487516

Epoch: 6| Step: 1
Training loss: 1.5940299442738135
Validation loss: 2.562108223752102

Epoch: 6| Step: 2
Training loss: 2.040212022197698
Validation loss: 2.5600251022352807

Epoch: 6| Step: 3
Training loss: 1.6481633252116963
Validation loss: 2.575604264678869

Epoch: 6| Step: 4
Training loss: 2.7855619801117233
Validation loss: 2.5877188084891243

Epoch: 6| Step: 5
Training loss: 2.1032526530143993
Validation loss: 2.569472224107444

Epoch: 6| Step: 6
Training loss: 1.9879976381330065
Validation loss: 2.565022829143653

Epoch: 6| Step: 7
Training loss: 2.3011115829554885
Validation loss: 2.5522074743083616

Epoch: 6| Step: 8
Training loss: 1.782721731297466
Validation loss: 2.550847724578907

Epoch: 6| Step: 9
Training loss: 1.6204194286529212
Validation loss: 2.5565071951981495

Epoch: 6| Step: 10
Training loss: 1.7178172961996159
Validation loss: 2.556900593662195

Epoch: 6| Step: 11
Training loss: 2.562605134621557
Validation loss: 2.559238216216722

Epoch: 6| Step: 12
Training loss: 2.2594619586508493
Validation loss: 2.544782161053091

Epoch: 6| Step: 13
Training loss: 2.1852112922378084
Validation loss: 2.573260902339376

Epoch: 231| Step: 0
Training loss: 2.1553371542745214
Validation loss: 2.5363739697710344

Epoch: 6| Step: 1
Training loss: 1.9846516213637502
Validation loss: 2.557987440698201

Epoch: 6| Step: 2
Training loss: 1.4764567342349137
Validation loss: 2.577702469443813

Epoch: 6| Step: 3
Training loss: 1.8745584603811958
Validation loss: 2.5430727222707823

Epoch: 6| Step: 4
Training loss: 2.176987483152013
Validation loss: 2.569925792239282

Epoch: 6| Step: 5
Training loss: 2.394449204599714
Validation loss: 2.5787825619965155

Epoch: 6| Step: 6
Training loss: 1.8856988207484304
Validation loss: 2.538990868251353

Epoch: 6| Step: 7
Training loss: 2.067304736768217
Validation loss: 2.5219046464547716

Epoch: 6| Step: 8
Training loss: 1.945554603310398
Validation loss: 2.4819789308086357

Epoch: 6| Step: 9
Training loss: 2.5707054881288047
Validation loss: 2.514636013033366

Epoch: 6| Step: 10
Training loss: 2.118989634957916
Validation loss: 2.4991440897302666

Epoch: 6| Step: 11
Training loss: 1.7452634334924246
Validation loss: 2.5117635152479676

Epoch: 6| Step: 12
Training loss: 2.196389148105816
Validation loss: 2.5321974703485517

Epoch: 6| Step: 13
Training loss: 2.0228010082345707
Validation loss: 2.5943081321121504

Epoch: 232| Step: 0
Training loss: 2.397383964841245
Validation loss: 2.6299381207868113

Epoch: 6| Step: 1
Training loss: 1.8508978185823126
Validation loss: 2.6286226034326092

Epoch: 6| Step: 2
Training loss: 2.1121455329691194
Validation loss: 2.6345742687958995

Epoch: 6| Step: 3
Training loss: 1.9171153731951647
Validation loss: 2.6191336157333036

Epoch: 6| Step: 4
Training loss: 2.206218522579429
Validation loss: 2.585389055346895

Epoch: 6| Step: 5
Training loss: 1.9398255696483695
Validation loss: 2.6198626522311974

Epoch: 6| Step: 6
Training loss: 1.9238213088791054
Validation loss: 2.6163950700447876

Epoch: 6| Step: 7
Training loss: 2.208418526595636
Validation loss: 2.6147479218075333

Epoch: 6| Step: 8
Training loss: 1.8340714731547778
Validation loss: 2.6022765147248657

Epoch: 6| Step: 9
Training loss: 1.7571136441721027
Validation loss: 2.5669016976440524

Epoch: 6| Step: 10
Training loss: 2.368097010970864
Validation loss: 2.5673286110455398

Epoch: 6| Step: 11
Training loss: 2.195629599262636
Validation loss: 2.5444044789538265

Epoch: 6| Step: 12
Training loss: 1.952206021595514
Validation loss: 2.546247485395169

Epoch: 6| Step: 13
Training loss: 2.0696366268531086
Validation loss: 2.52421821432267

Epoch: 233| Step: 0
Training loss: 2.354326518435307
Validation loss: 2.5551645436199744

Epoch: 6| Step: 1
Training loss: 2.2184147111318944
Validation loss: 2.569744624997099

Epoch: 6| Step: 2
Training loss: 1.548868917190199
Validation loss: 2.5677551060263206

Epoch: 6| Step: 3
Training loss: 2.314543980613849
Validation loss: 2.5567018985750014

Epoch: 6| Step: 4
Training loss: 1.846087315855304
Validation loss: 2.6132000686556367

Epoch: 6| Step: 5
Training loss: 2.1795608319629554
Validation loss: 2.6200106385406503

Epoch: 6| Step: 6
Training loss: 1.9615708502372502
Validation loss: 2.629978877467438

Epoch: 6| Step: 7
Training loss: 1.3301568589174948
Validation loss: 2.6426907254284675

Epoch: 6| Step: 8
Training loss: 2.0676238253321264
Validation loss: 2.644573315365402

Epoch: 6| Step: 9
Training loss: 2.0988364992839053
Validation loss: 2.6355669538986533

Epoch: 6| Step: 10
Training loss: 1.9031020891285648
Validation loss: 2.611282740811002

Epoch: 6| Step: 11
Training loss: 2.0001031133773695
Validation loss: 2.595999254318821

Epoch: 6| Step: 12
Training loss: 2.0741811630377973
Validation loss: 2.5801659811804316

Epoch: 6| Step: 13
Training loss: 2.0058227654582703
Validation loss: 2.568261187846923

Epoch: 234| Step: 0
Training loss: 2.3783280996449054
Validation loss: 2.570254916214855

Epoch: 6| Step: 1
Training loss: 2.029196890019087
Validation loss: 2.593962902667104

Epoch: 6| Step: 2
Training loss: 1.663175319525393
Validation loss: 2.5774804526155024

Epoch: 6| Step: 3
Training loss: 2.2193235273953387
Validation loss: 2.6257463830696173

Epoch: 6| Step: 4
Training loss: 1.6264593467287398
Validation loss: 2.578611656240166

Epoch: 6| Step: 5
Training loss: 1.8308676987856176
Validation loss: 2.606891696439915

Epoch: 6| Step: 6
Training loss: 1.7389078104020905
Validation loss: 2.5839962844649214

Epoch: 6| Step: 7
Training loss: 1.9197958267451098
Validation loss: 2.5849313350156637

Epoch: 6| Step: 8
Training loss: 2.1703524295437626
Validation loss: 2.5588388908736786

Epoch: 6| Step: 9
Training loss: 1.9230100179918135
Validation loss: 2.583789425606213

Epoch: 6| Step: 10
Training loss: 2.4167584917008673
Validation loss: 2.5999455907333227

Epoch: 6| Step: 11
Training loss: 2.431941811166622
Validation loss: 2.59356525018666

Epoch: 6| Step: 12
Training loss: 1.5406177234284375
Validation loss: 2.58346796991551

Epoch: 6| Step: 13
Training loss: 0.931035835166475
Validation loss: 2.5661455419913506

Epoch: 235| Step: 0
Training loss: 2.2563127334622926
Validation loss: 2.539663715475598

Epoch: 6| Step: 1
Training loss: 2.032803454954416
Validation loss: 2.5220884501846927

Epoch: 6| Step: 2
Training loss: 1.86892995573901
Validation loss: 2.472057857013971

Epoch: 6| Step: 3
Training loss: 2.3930746256203217
Validation loss: 2.477828693591782

Epoch: 6| Step: 4
Training loss: 1.8235756763709539
Validation loss: 2.486050750629231

Epoch: 6| Step: 5
Training loss: 2.128449501246837
Validation loss: 2.481894255169068

Epoch: 6| Step: 6
Training loss: 1.6899976966210193
Validation loss: 2.4950325354408815

Epoch: 6| Step: 7
Training loss: 1.917723039787908
Validation loss: 2.5173056711766546

Epoch: 6| Step: 8
Training loss: 1.7501565999399467
Validation loss: 2.565034854631875

Epoch: 6| Step: 9
Training loss: 1.8494929727182077
Validation loss: 2.5974379196153765

Epoch: 6| Step: 10
Training loss: 2.149873454783335
Validation loss: 2.6566404418828484

Epoch: 6| Step: 11
Training loss: 2.0262565858370327
Validation loss: 2.695645894740811

Epoch: 6| Step: 12
Training loss: 2.5498489148129546
Validation loss: 2.690521793587788

Epoch: 6| Step: 13
Training loss: 1.968346206187964
Validation loss: 2.6181377049363257

Epoch: 236| Step: 0
Training loss: 2.012682637522256
Validation loss: 2.5411068323134636

Epoch: 6| Step: 1
Training loss: 2.185665560338633
Validation loss: 2.460561657664665

Epoch: 6| Step: 2
Training loss: 2.1985229692471657
Validation loss: 2.4596440742164987

Epoch: 6| Step: 3
Training loss: 1.9530879513087693
Validation loss: 2.4256825473816273

Epoch: 6| Step: 4
Training loss: 1.878537591943393
Validation loss: 2.4490923691834787

Epoch: 6| Step: 5
Training loss: 2.332557503828575
Validation loss: 2.449744907783333

Epoch: 6| Step: 6
Training loss: 2.4111073995914207
Validation loss: 2.4636861410215576

Epoch: 6| Step: 7
Training loss: 1.8750813784423463
Validation loss: 2.4273940386617316

Epoch: 6| Step: 8
Training loss: 1.793942388657797
Validation loss: 2.478398838474138

Epoch: 6| Step: 9
Training loss: 1.6231643138497251
Validation loss: 2.487441654214655

Epoch: 6| Step: 10
Training loss: 1.837084927032234
Validation loss: 2.532385241999523

Epoch: 6| Step: 11
Training loss: 1.947698026684171
Validation loss: 2.584735595633027

Epoch: 6| Step: 12
Training loss: 1.821177199459307
Validation loss: 2.639814387965687

Epoch: 6| Step: 13
Training loss: 2.0142443756066655
Validation loss: 2.6931841379068313

Epoch: 237| Step: 0
Training loss: 1.3321386389079346
Validation loss: 2.726679387989461

Epoch: 6| Step: 1
Training loss: 2.1125502811745624
Validation loss: 2.7495787718375744

Epoch: 6| Step: 2
Training loss: 1.8736501921371895
Validation loss: 2.7479760150738297

Epoch: 6| Step: 3
Training loss: 1.6036177682810908
Validation loss: 2.73516351303017

Epoch: 6| Step: 4
Training loss: 2.0083558056261315
Validation loss: 2.7056659149170614

Epoch: 6| Step: 5
Training loss: 2.14054346973501
Validation loss: 2.693383989407017

Epoch: 6| Step: 6
Training loss: 2.1424273400466003
Validation loss: 2.617554055534393

Epoch: 6| Step: 7
Training loss: 2.659990078613594
Validation loss: 2.619786252578239

Epoch: 6| Step: 8
Training loss: 1.4408621239125319
Validation loss: 2.559847339371133

Epoch: 6| Step: 9
Training loss: 1.9836536207625328
Validation loss: 2.521360358688022

Epoch: 6| Step: 10
Training loss: 1.8714311968390833
Validation loss: 2.4839070326267483

Epoch: 6| Step: 11
Training loss: 1.9517859789860987
Validation loss: 2.4927456632199245

Epoch: 6| Step: 12
Training loss: 2.1500131828436233
Validation loss: 2.468393249405472

Epoch: 6| Step: 13
Training loss: 2.0167628189158067
Validation loss: 2.470160247020556

Epoch: 238| Step: 0
Training loss: 1.9997808217113804
Validation loss: 2.4801393181146145

Epoch: 6| Step: 1
Training loss: 2.5866947045068405
Validation loss: 2.4861434088013525

Epoch: 6| Step: 2
Training loss: 1.946530738139078
Validation loss: 2.498016803406547

Epoch: 6| Step: 3
Training loss: 1.5995884336188366
Validation loss: 2.551907758133293

Epoch: 6| Step: 4
Training loss: 1.6114598075927355
Validation loss: 2.613346659617677

Epoch: 6| Step: 5
Training loss: 1.7489634577585396
Validation loss: 2.6146524267639975

Epoch: 6| Step: 6
Training loss: 2.3094313597867346
Validation loss: 2.630213707124737

Epoch: 6| Step: 7
Training loss: 1.8897382059386567
Validation loss: 2.6454503353289

Epoch: 6| Step: 8
Training loss: 2.7043945330131938
Validation loss: 2.6662636004924796

Epoch: 6| Step: 9
Training loss: 2.2095525602782295
Validation loss: 2.611536154897265

Epoch: 6| Step: 10
Training loss: 1.7808753171668672
Validation loss: 2.563886716939774

Epoch: 6| Step: 11
Training loss: 1.8593835910630705
Validation loss: 2.560332308084865

Epoch: 6| Step: 12
Training loss: 1.3831906852173557
Validation loss: 2.522239096474583

Epoch: 6| Step: 13
Training loss: 1.3472296882807044
Validation loss: 2.5062471353083207

Epoch: 239| Step: 0
Training loss: 1.8300964940797035
Validation loss: 2.524448878994948

Epoch: 6| Step: 1
Training loss: 1.2646051701394327
Validation loss: 2.5441931399706563

Epoch: 6| Step: 2
Training loss: 2.003141677477559
Validation loss: 2.579408620292339

Epoch: 6| Step: 3
Training loss: 1.8036280573219456
Validation loss: 2.6105377257451163

Epoch: 6| Step: 4
Training loss: 2.2253928877029043
Validation loss: 2.6447717967377447

Epoch: 6| Step: 5
Training loss: 1.8051665359767983
Validation loss: 2.6249663374735213

Epoch: 6| Step: 6
Training loss: 1.9933776292482757
Validation loss: 2.6002374627772076

Epoch: 6| Step: 7
Training loss: 1.6396419668155153
Validation loss: 2.5970492984751448

Epoch: 6| Step: 8
Training loss: 2.1516065494679504
Validation loss: 2.561210562017708

Epoch: 6| Step: 9
Training loss: 2.2959178565148024
Validation loss: 2.545238374928909

Epoch: 6| Step: 10
Training loss: 1.8031564799028466
Validation loss: 2.540881532076916

Epoch: 6| Step: 11
Training loss: 2.281554110388437
Validation loss: 2.5480299288261365

Epoch: 6| Step: 12
Training loss: 1.8959707552670428
Validation loss: 2.5423625603280895

Epoch: 6| Step: 13
Training loss: 2.1673189306250933
Validation loss: 2.566816811217904

Epoch: 240| Step: 0
Training loss: 2.285425832122071
Validation loss: 2.5374263831350503

Epoch: 6| Step: 1
Training loss: 2.0513266573848865
Validation loss: 2.5584213087256464

Epoch: 6| Step: 2
Training loss: 2.3101772293206384
Validation loss: 2.555085695714864

Epoch: 6| Step: 3
Training loss: 1.2496921160136445
Validation loss: 2.5450500557239906

Epoch: 6| Step: 4
Training loss: 1.793738372446049
Validation loss: 2.561545174359363

Epoch: 6| Step: 5
Training loss: 2.0614734753834387
Validation loss: 2.5530100991606153

Epoch: 6| Step: 6
Training loss: 2.0269892682175796
Validation loss: 2.5636052185056912

Epoch: 6| Step: 7
Training loss: 1.7390429938662761
Validation loss: 2.61089661539813

Epoch: 6| Step: 8
Training loss: 2.170922818478138
Validation loss: 2.6031992346274646

Epoch: 6| Step: 9
Training loss: 1.550151860581097
Validation loss: 2.569239142708881

Epoch: 6| Step: 10
Training loss: 2.0645725356460227
Validation loss: 2.5966577530870523

Epoch: 6| Step: 11
Training loss: 1.1128984830611701
Validation loss: 2.6047553490205257

Epoch: 6| Step: 12
Training loss: 2.020681264078057
Validation loss: 2.5820099109893992

Epoch: 6| Step: 13
Training loss: 1.7111346684247584
Validation loss: 2.586324660497519

Epoch: 241| Step: 0
Training loss: 2.6040952342091037
Validation loss: 2.5456358668800885

Epoch: 6| Step: 1
Training loss: 1.8716529854636503
Validation loss: 2.5613308271960693

Epoch: 6| Step: 2
Training loss: 2.238873202087795
Validation loss: 2.5370960278346937

Epoch: 6| Step: 3
Training loss: 1.7523376655217875
Validation loss: 2.5193547572325157

Epoch: 6| Step: 4
Training loss: 1.103236124206874
Validation loss: 2.4892416474270744

Epoch: 6| Step: 5
Training loss: 1.585799187703381
Validation loss: 2.511582859686932

Epoch: 6| Step: 6
Training loss: 1.6970856706150643
Validation loss: 2.496130958089929

Epoch: 6| Step: 7
Training loss: 1.3363400572216475
Validation loss: 2.5019291315461003

Epoch: 6| Step: 8
Training loss: 1.9602888637913531
Validation loss: 2.4723607578646773

Epoch: 6| Step: 9
Training loss: 2.552057247936814
Validation loss: 2.47931421560722

Epoch: 6| Step: 10
Training loss: 2.106861453628106
Validation loss: 2.503668331309842

Epoch: 6| Step: 11
Training loss: 1.4443176144565444
Validation loss: 2.504057709627294

Epoch: 6| Step: 12
Training loss: 1.9032245453355343
Validation loss: 2.5023829239945434

Epoch: 6| Step: 13
Training loss: 1.6335424954269921
Validation loss: 2.520059999001371

Epoch: 242| Step: 0
Training loss: 1.9160270107292632
Validation loss: 2.538500288317062

Epoch: 6| Step: 1
Training loss: 1.4946733310481695
Validation loss: 2.540410811973366

Epoch: 6| Step: 2
Training loss: 2.521935833997281
Validation loss: 2.5513680362030313

Epoch: 6| Step: 3
Training loss: 1.8005164359247476
Validation loss: 2.5868920234814725

Epoch: 6| Step: 4
Training loss: 1.7172884188597455
Validation loss: 2.5693252901317423

Epoch: 6| Step: 5
Training loss: 1.7603918521494053
Validation loss: 2.571405488508149

Epoch: 6| Step: 6
Training loss: 1.935329205603977
Validation loss: 2.5954808749638603

Epoch: 6| Step: 7
Training loss: 1.768842752673426
Validation loss: 2.5890823056841197

Epoch: 6| Step: 8
Training loss: 1.7889906689745418
Validation loss: 2.565077091313802

Epoch: 6| Step: 9
Training loss: 1.8868165553550806
Validation loss: 2.5496192258565613

Epoch: 6| Step: 10
Training loss: 1.8001176848616889
Validation loss: 2.5435231434000816

Epoch: 6| Step: 11
Training loss: 1.5762600596361782
Validation loss: 2.5435560423548362

Epoch: 6| Step: 12
Training loss: 2.0808971529782996
Validation loss: 2.5318008495969977

Epoch: 6| Step: 13
Training loss: 1.9686014634063096
Validation loss: 2.5463153328116124

Epoch: 243| Step: 0
Training loss: 2.218389992318758
Validation loss: 2.578592209729176

Epoch: 6| Step: 1
Training loss: 2.0172649483915785
Validation loss: 2.570045758317193

Epoch: 6| Step: 2
Training loss: 1.6802597135794588
Validation loss: 2.5695796894005674

Epoch: 6| Step: 3
Training loss: 1.5398006315111856
Validation loss: 2.6029378200911464

Epoch: 6| Step: 4
Training loss: 1.7590767616104521
Validation loss: 2.574512288991834

Epoch: 6| Step: 5
Training loss: 2.198014737754056
Validation loss: 2.557030943048623

Epoch: 6| Step: 6
Training loss: 1.5925738913073018
Validation loss: 2.589080573870125

Epoch: 6| Step: 7
Training loss: 1.732551784869895
Validation loss: 2.583239803413972

Epoch: 6| Step: 8
Training loss: 2.2350270846985136
Validation loss: 2.6207517418467274

Epoch: 6| Step: 9
Training loss: 1.9701298918720507
Validation loss: 2.576242751571028

Epoch: 6| Step: 10
Training loss: 1.479956706934576
Validation loss: 2.6054379552590814

Epoch: 6| Step: 11
Training loss: 2.0042047408433588
Validation loss: 2.564022255346646

Epoch: 6| Step: 12
Training loss: 1.9883773570637597
Validation loss: 2.5481891936861607

Epoch: 6| Step: 13
Training loss: 1.6724037688985864
Validation loss: 2.5193556638945838

Epoch: 244| Step: 0
Training loss: 1.605243305053913
Validation loss: 2.5351783898988667

Epoch: 6| Step: 1
Training loss: 2.118188375119804
Validation loss: 2.513923376766846

Epoch: 6| Step: 2
Training loss: 1.6344046245391892
Validation loss: 2.5337249853108847

Epoch: 6| Step: 3
Training loss: 1.3312337954972169
Validation loss: 2.518235983746396

Epoch: 6| Step: 4
Training loss: 2.058146766619319
Validation loss: 2.52668201655133

Epoch: 6| Step: 5
Training loss: 1.6579124456509933
Validation loss: 2.527072922223973

Epoch: 6| Step: 6
Training loss: 1.756397474620118
Validation loss: 2.559308559548943

Epoch: 6| Step: 7
Training loss: 1.6447710238468547
Validation loss: 2.589560737069416

Epoch: 6| Step: 8
Training loss: 2.0231308870462645
Validation loss: 2.5743823218502118

Epoch: 6| Step: 9
Training loss: 1.9817252302165358
Validation loss: 2.5776576329843484

Epoch: 6| Step: 10
Training loss: 1.6430793206216097
Validation loss: 2.5311794648444907

Epoch: 6| Step: 11
Training loss: 1.89713779746914
Validation loss: 2.5289254928867906

Epoch: 6| Step: 12
Training loss: 2.534979251272547
Validation loss: 2.497249989905363

Epoch: 6| Step: 13
Training loss: 1.8027394667664076
Validation loss: 2.4979945229773963

Epoch: 245| Step: 0
Training loss: 2.1611250900082313
Validation loss: 2.4978700434584242

Epoch: 6| Step: 1
Training loss: 1.815344321638051
Validation loss: 2.458547124713799

Epoch: 6| Step: 2
Training loss: 1.2815490466706774
Validation loss: 2.4765216009732023

Epoch: 6| Step: 3
Training loss: 1.596619808462446
Validation loss: 2.534974108774498

Epoch: 6| Step: 4
Training loss: 1.6673783769534025
Validation loss: 2.5266105888213684

Epoch: 6| Step: 5
Training loss: 1.7515280727845035
Validation loss: 2.5540068947420043

Epoch: 6| Step: 6
Training loss: 1.8853581105055992
Validation loss: 2.6060817195665167

Epoch: 6| Step: 7
Training loss: 2.194623845918303
Validation loss: 2.6107100456774894

Epoch: 6| Step: 8
Training loss: 2.1932823052118087
Validation loss: 2.5945442901988236

Epoch: 6| Step: 9
Training loss: 2.084983007238287
Validation loss: 2.558077593913786

Epoch: 6| Step: 10
Training loss: 1.7947017630186841
Validation loss: 2.5364325471256155

Epoch: 6| Step: 11
Training loss: 1.9713048555026305
Validation loss: 2.5184131819812445

Epoch: 6| Step: 12
Training loss: 1.3280393685055187
Validation loss: 2.509020001256492

Epoch: 6| Step: 13
Training loss: 1.542204771553883
Validation loss: 2.5032643858219457

Epoch: 246| Step: 0
Training loss: 2.164895678819397
Validation loss: 2.4798590066584216

Epoch: 6| Step: 1
Training loss: 1.6953321183295678
Validation loss: 2.5110898659603835

Epoch: 6| Step: 2
Training loss: 1.4969409904189233
Validation loss: 2.488818666266912

Epoch: 6| Step: 3
Training loss: 1.4643910433272596
Validation loss: 2.5264854877693392

Epoch: 6| Step: 4
Training loss: 1.986209532011593
Validation loss: 2.5302159891341294

Epoch: 6| Step: 5
Training loss: 1.4322599187858072
Validation loss: 2.5414174981704

Epoch: 6| Step: 6
Training loss: 1.6389548383615458
Validation loss: 2.56413743961287

Epoch: 6| Step: 7
Training loss: 1.3422732999686677
Validation loss: 2.5547465435208387

Epoch: 6| Step: 8
Training loss: 2.4158963148529105
Validation loss: 2.56356159553189

Epoch: 6| Step: 9
Training loss: 1.7344029054888357
Validation loss: 2.554585073243552

Epoch: 6| Step: 10
Training loss: 1.8230626365711005
Validation loss: 2.5513680522799946

Epoch: 6| Step: 11
Training loss: 1.8799746959079073
Validation loss: 2.576100024204411

Epoch: 6| Step: 12
Training loss: 2.218521106357347
Validation loss: 2.5790111939065

Epoch: 6| Step: 13
Training loss: 2.174689904392655
Validation loss: 2.5872116476691778

Epoch: 247| Step: 0
Training loss: 1.7729978310474397
Validation loss: 2.59577176759392

Epoch: 6| Step: 1
Training loss: 1.8322564415711118
Validation loss: 2.585970353055172

Epoch: 6| Step: 2
Training loss: 1.7157034489495988
Validation loss: 2.5981693387472564

Epoch: 6| Step: 3
Training loss: 1.2411543670416416
Validation loss: 2.5679027113803734

Epoch: 6| Step: 4
Training loss: 1.7068100006790354
Validation loss: 2.594237079097685

Epoch: 6| Step: 5
Training loss: 1.8103349843564083
Validation loss: 2.616844047695772

Epoch: 6| Step: 6
Training loss: 1.8897007976838147
Validation loss: 2.5871925680231436

Epoch: 6| Step: 7
Training loss: 1.5748410947050426
Validation loss: 2.5527691386561218

Epoch: 6| Step: 8
Training loss: 1.5121125095328045
Validation loss: 2.54726943316144

Epoch: 6| Step: 9
Training loss: 2.1870794709483357
Validation loss: 2.588307333404807

Epoch: 6| Step: 10
Training loss: 2.0049991118697865
Validation loss: 2.5493400909779673

Epoch: 6| Step: 11
Training loss: 2.3358224693732517
Validation loss: 2.525769175091478

Epoch: 6| Step: 12
Training loss: 1.6072311195478597
Validation loss: 2.555359720498046

Epoch: 6| Step: 13
Training loss: 2.079820213984266
Validation loss: 2.552127629980342

Epoch: 248| Step: 0
Training loss: 1.386969831060185
Validation loss: 2.5543524389530865

Epoch: 6| Step: 1
Training loss: 1.8252392024217343
Validation loss: 2.596622191833652

Epoch: 6| Step: 2
Training loss: 1.823712493113386
Validation loss: 2.609125250765191

Epoch: 6| Step: 3
Training loss: 2.756721777989697
Validation loss: 2.6110771148695133

Epoch: 6| Step: 4
Training loss: 1.9414196973369477
Validation loss: 2.581594069892834

Epoch: 6| Step: 5
Training loss: 1.6047571094722126
Validation loss: 2.5841401858301563

Epoch: 6| Step: 6
Training loss: 1.7234098209153959
Validation loss: 2.524098778920901

Epoch: 6| Step: 7
Training loss: 2.1882421052176477
Validation loss: 2.457698486292154

Epoch: 6| Step: 8
Training loss: 2.0733219945337913
Validation loss: 2.4560269211027865

Epoch: 6| Step: 9
Training loss: 1.71025162278851
Validation loss: 2.452099813386286

Epoch: 6| Step: 10
Training loss: 1.709578231083676
Validation loss: 2.480449218259689

Epoch: 6| Step: 11
Training loss: 1.3162998416806933
Validation loss: 2.5463391305281617

Epoch: 6| Step: 12
Training loss: 2.06329134007348
Validation loss: 2.5269848575589684

Epoch: 6| Step: 13
Training loss: 1.707310634070891
Validation loss: 2.5956721067459902

Epoch: 249| Step: 0
Training loss: 1.9788005356350882
Validation loss: 2.5708452581420023

Epoch: 6| Step: 1
Training loss: 1.7350274997917379
Validation loss: 2.5842290189578256

Epoch: 6| Step: 2
Training loss: 1.899239327598956
Validation loss: 2.640698711436574

Epoch: 6| Step: 3
Training loss: 1.8826101360551104
Validation loss: 2.6992529795424085

Epoch: 6| Step: 4
Training loss: 1.926959004558484
Validation loss: 2.7205594455536395

Epoch: 6| Step: 5
Training loss: 1.4951527477298732
Validation loss: 2.73250654896072

Epoch: 6| Step: 6
Training loss: 2.3729496186346064
Validation loss: 2.7225550275531094

Epoch: 6| Step: 7
Training loss: 1.6960574855643866
Validation loss: 2.6316196245073162

Epoch: 6| Step: 8
Training loss: 1.728323957086118
Validation loss: 2.570615091648695

Epoch: 6| Step: 9
Training loss: 2.1165835937458186
Validation loss: 2.508034611272328

Epoch: 6| Step: 10
Training loss: 1.938039704493811
Validation loss: 2.448505571821362

Epoch: 6| Step: 11
Training loss: 1.8262161331117537
Validation loss: 2.422898634130325

Epoch: 6| Step: 12
Training loss: 1.4468761336979226
Validation loss: 2.452269976316868

Epoch: 6| Step: 13
Training loss: 1.6059916960239098
Validation loss: 2.437277658322408

Epoch: 250| Step: 0
Training loss: 1.9869560217019737
Validation loss: 2.425136234231639

Epoch: 6| Step: 1
Training loss: 1.6251840487203182
Validation loss: 2.4382750459824263

Epoch: 6| Step: 2
Training loss: 1.8705712466892113
Validation loss: 2.434351632396259

Epoch: 6| Step: 3
Training loss: 1.7952387782166996
Validation loss: 2.4624428130658016

Epoch: 6| Step: 4
Training loss: 1.4950317119182166
Validation loss: 2.464820047447922

Epoch: 6| Step: 5
Training loss: 1.495332927823419
Validation loss: 2.527492180228119

Epoch: 6| Step: 6
Training loss: 1.131708067154014
Validation loss: 2.5197828648775116

Epoch: 6| Step: 7
Training loss: 2.0970753694814226
Validation loss: 2.549134559238336

Epoch: 6| Step: 8
Training loss: 1.632014759614062
Validation loss: 2.561968818632662

Epoch: 6| Step: 9
Training loss: 1.9549707465166117
Validation loss: 2.565957939431645

Epoch: 6| Step: 10
Training loss: 1.8800553517613905
Validation loss: 2.6177134230778756

Epoch: 6| Step: 11
Training loss: 2.2367656163226584
Validation loss: 2.620023673882982

Epoch: 6| Step: 12
Training loss: 1.5437475629161794
Validation loss: 2.622613867348338

Epoch: 6| Step: 13
Training loss: 1.5109198773371213
Validation loss: 2.630221871107983

Epoch: 251| Step: 0
Training loss: 1.7072021957454844
Validation loss: 2.6202003794462474

Epoch: 6| Step: 1
Training loss: 1.538485423691275
Validation loss: 2.644161678461128

Epoch: 6| Step: 2
Training loss: 1.88921158346663
Validation loss: 2.641178065175722

Epoch: 6| Step: 3
Training loss: 1.4971473907913737
Validation loss: 2.6124383772616153

Epoch: 6| Step: 4
Training loss: 1.9869587815131882
Validation loss: 2.628380354402555

Epoch: 6| Step: 5
Training loss: 1.5779078116956273
Validation loss: 2.600035274114882

Epoch: 6| Step: 6
Training loss: 1.5859023217119113
Validation loss: 2.5408441837394062

Epoch: 6| Step: 7
Training loss: 1.6864632141281415
Validation loss: 2.548426433589076

Epoch: 6| Step: 8
Training loss: 2.0387535591959804
Validation loss: 2.5389686313439026

Epoch: 6| Step: 9
Training loss: 1.8527463194759461
Validation loss: 2.5183000557248563

Epoch: 6| Step: 10
Training loss: 1.678479847250402
Validation loss: 2.496535632655738

Epoch: 6| Step: 11
Training loss: 2.02801914026983
Validation loss: 2.457335472070326

Epoch: 6| Step: 12
Training loss: 1.5218966786056642
Validation loss: 2.444211981957431

Epoch: 6| Step: 13
Training loss: 1.5815786962427945
Validation loss: 2.4357227917443587

Epoch: 252| Step: 0
Training loss: 1.684023844221662
Validation loss: 2.4604697777046325

Epoch: 6| Step: 1
Training loss: 2.2221913044156234
Validation loss: 2.46550804432765

Epoch: 6| Step: 2
Training loss: 2.19561874045618
Validation loss: 2.4795962738989688

Epoch: 6| Step: 3
Training loss: 1.0372389660347454
Validation loss: 2.4747283081033054

Epoch: 6| Step: 4
Training loss: 1.251409213124155
Validation loss: 2.5093767594830982

Epoch: 6| Step: 5
Training loss: 1.386799210913967
Validation loss: 2.520688477797339

Epoch: 6| Step: 6
Training loss: 1.384650049376808
Validation loss: 2.5739111427966512

Epoch: 6| Step: 7
Training loss: 1.4976506909191134
Validation loss: 2.5486176059944112

Epoch: 6| Step: 8
Training loss: 1.6397902045156385
Validation loss: 2.5721136547769974

Epoch: 6| Step: 9
Training loss: 2.0048920881574275
Validation loss: 2.5713459730799273

Epoch: 6| Step: 10
Training loss: 2.244078685944893
Validation loss: 2.5599651710130384

Epoch: 6| Step: 11
Training loss: 2.1614338578519807
Validation loss: 2.5284476517421437

Epoch: 6| Step: 12
Training loss: 1.3910215005426494
Validation loss: 2.4992676513383882

Epoch: 6| Step: 13
Training loss: 1.2613870757578405
Validation loss: 2.4912576976733947

Epoch: 253| Step: 0
Training loss: 1.8279862962580575
Validation loss: 2.4833492360167115

Epoch: 6| Step: 1
Training loss: 1.9552899378346207
Validation loss: 2.4460672503742416

Epoch: 6| Step: 2
Training loss: 1.9492833923751756
Validation loss: 2.4682368415873994

Epoch: 6| Step: 3
Training loss: 1.4825523027582597
Validation loss: 2.46113425316495

Epoch: 6| Step: 4
Training loss: 1.835430578495897
Validation loss: 2.442087324145889

Epoch: 6| Step: 5
Training loss: 1.7842801738601946
Validation loss: 2.495973447441657

Epoch: 6| Step: 6
Training loss: 1.782333178531908
Validation loss: 2.52494519642386

Epoch: 6| Step: 7
Training loss: 1.5960255253980646
Validation loss: 2.5317383485879636

Epoch: 6| Step: 8
Training loss: 1.9656076936915128
Validation loss: 2.5203309039392416

Epoch: 6| Step: 9
Training loss: 1.6348112001982307
Validation loss: 2.548510410584198

Epoch: 6| Step: 10
Training loss: 1.3412205598129647
Validation loss: 2.56379967681709

Epoch: 6| Step: 11
Training loss: 1.7022559372205497
Validation loss: 2.546591348289155

Epoch: 6| Step: 12
Training loss: 1.613122595127919
Validation loss: 2.56310417562133

Epoch: 6| Step: 13
Training loss: 0.9190957476307001
Validation loss: 2.5712254694363352

Epoch: 254| Step: 0
Training loss: 1.7508224189680774
Validation loss: 2.5980400804200423

Epoch: 6| Step: 1
Training loss: 1.7333555920100934
Validation loss: 2.613539653426741

Epoch: 6| Step: 2
Training loss: 1.9430554636344073
Validation loss: 2.615828758028001

Epoch: 6| Step: 3
Training loss: 2.117864296482239
Validation loss: 2.631448692345625

Epoch: 6| Step: 4
Training loss: 1.858664176411559
Validation loss: 2.5964194066698614

Epoch: 6| Step: 5
Training loss: 1.3603803052419337
Validation loss: 2.569345987154312

Epoch: 6| Step: 6
Training loss: 1.6177277330691542
Validation loss: 2.5381642620526774

Epoch: 6| Step: 7
Training loss: 1.2363986075078452
Validation loss: 2.5456766293358446

Epoch: 6| Step: 8
Training loss: 2.1418470249848096
Validation loss: 2.5045281594339297

Epoch: 6| Step: 9
Training loss: 2.0591458877673956
Validation loss: 2.499614657165577

Epoch: 6| Step: 10
Training loss: 1.5182340522630797
Validation loss: 2.493794012954771

Epoch: 6| Step: 11
Training loss: 1.544253816130241
Validation loss: 2.498636879054926

Epoch: 6| Step: 12
Training loss: 1.8515661698317074
Validation loss: 2.471848610407487

Epoch: 6| Step: 13
Training loss: 1.1762155130095988
Validation loss: 2.4757052024303774

Epoch: 255| Step: 0
Training loss: 1.903779977924367
Validation loss: 2.496744938840358

Epoch: 6| Step: 1
Training loss: 2.43270078781102
Validation loss: 2.4908630161843313

Epoch: 6| Step: 2
Training loss: 1.3795853798422022
Validation loss: 2.53643318994785

Epoch: 6| Step: 3
Training loss: 1.6084184489021502
Validation loss: 2.5474378622028917

Epoch: 6| Step: 4
Training loss: 1.7687584408400279
Validation loss: 2.5230809924428717

Epoch: 6| Step: 5
Training loss: 1.1826931891995711
Validation loss: 2.5840952636462693

Epoch: 6| Step: 6
Training loss: 1.3106416534399055
Validation loss: 2.6060234180849116

Epoch: 6| Step: 7
Training loss: 1.8035115295456194
Validation loss: 2.6239235101938854

Epoch: 6| Step: 8
Training loss: 1.4452484941486248
Validation loss: 2.6662158764497135

Epoch: 6| Step: 9
Training loss: 1.8383299477835104
Validation loss: 2.7007742514160347

Epoch: 6| Step: 10
Training loss: 1.7156267398901839
Validation loss: 2.675377029822482

Epoch: 6| Step: 11
Training loss: 1.9070444796555333
Validation loss: 2.632305355552524

Epoch: 6| Step: 12
Training loss: 1.979133411596557
Validation loss: 2.5917585318328897

Epoch: 6| Step: 13
Training loss: 1.0656807356323241
Validation loss: 2.6011348048720144

Epoch: 256| Step: 0
Training loss: 1.507900018079221
Validation loss: 2.5861127934198294

Epoch: 6| Step: 1
Training loss: 1.4680588902139138
Validation loss: 2.582780904647181

Epoch: 6| Step: 2
Training loss: 1.4935022124665829
Validation loss: 2.514791189574794

Epoch: 6| Step: 3
Training loss: 1.6523879025018529
Validation loss: 2.4791044946287255

Epoch: 6| Step: 4
Training loss: 1.8187865709121551
Validation loss: 2.430208902869824

Epoch: 6| Step: 5
Training loss: 0.9174959304261969
Validation loss: 2.4351765992202195

Epoch: 6| Step: 6
Training loss: 2.0975841886336197
Validation loss: 2.408223985733792

Epoch: 6| Step: 7
Training loss: 2.104184241898161
Validation loss: 2.4127848711232116

Epoch: 6| Step: 8
Training loss: 1.954085945246189
Validation loss: 2.4344625055300537

Epoch: 6| Step: 9
Training loss: 1.9890907303574037
Validation loss: 2.4633085575073643

Epoch: 6| Step: 10
Training loss: 1.9652585753935687
Validation loss: 2.4585394772013824

Epoch: 6| Step: 11
Training loss: 1.6195424206022289
Validation loss: 2.4889799617342607

Epoch: 6| Step: 12
Training loss: 1.3664391785760384
Validation loss: 2.513048206001532

Epoch: 6| Step: 13
Training loss: 1.5315550675413205
Validation loss: 2.5746504961700225

Epoch: 257| Step: 0
Training loss: 1.9798289211615914
Validation loss: 2.5785814812768275

Epoch: 6| Step: 1
Training loss: 1.8416193272762127
Validation loss: 2.632067661934927

Epoch: 6| Step: 2
Training loss: 1.5656153330247495
Validation loss: 2.6363633774761017

Epoch: 6| Step: 3
Training loss: 1.6087574190503704
Validation loss: 2.6370716296668033

Epoch: 6| Step: 4
Training loss: 1.9986255810764382
Validation loss: 2.651614153544861

Epoch: 6| Step: 5
Training loss: 1.9821691793611187
Validation loss: 2.6264339862536525

Epoch: 6| Step: 6
Training loss: 1.166438909279093
Validation loss: 2.568020688028528

Epoch: 6| Step: 7
Training loss: 1.2970704540361173
Validation loss: 2.576924710553253

Epoch: 6| Step: 8
Training loss: 1.603949800504889
Validation loss: 2.53020461582413

Epoch: 6| Step: 9
Training loss: 1.6293685586360829
Validation loss: 2.5243738569954797

Epoch: 6| Step: 10
Training loss: 1.701277404385053
Validation loss: 2.5227071699000754

Epoch: 6| Step: 11
Training loss: 2.045241075030686
Validation loss: 2.4726328162209557

Epoch: 6| Step: 12
Training loss: 1.5324793960157006
Validation loss: 2.4566968709913537

Epoch: 6| Step: 13
Training loss: 1.7792679316389068
Validation loss: 2.448359189500071

Epoch: 258| Step: 0
Training loss: 1.9663081087424905
Validation loss: 2.486161125298585

Epoch: 6| Step: 1
Training loss: 1.233279502613198
Validation loss: 2.4734851809993312

Epoch: 6| Step: 2
Training loss: 1.8441464272738894
Validation loss: 2.4812819464607014

Epoch: 6| Step: 3
Training loss: 1.5725136886995486
Validation loss: 2.520732945438544

Epoch: 6| Step: 4
Training loss: 1.1644149349160364
Validation loss: 2.5452589580958493

Epoch: 6| Step: 5
Training loss: 1.5813999753250307
Validation loss: 2.5675153915446054

Epoch: 6| Step: 6
Training loss: 1.4895877260085564
Validation loss: 2.585816463835939

Epoch: 6| Step: 7
Training loss: 1.2058382527361535
Validation loss: 2.635055105872983

Epoch: 6| Step: 8
Training loss: 1.4060668826087686
Validation loss: 2.6396489231026212

Epoch: 6| Step: 9
Training loss: 2.2119528659675836
Validation loss: 2.6443018044337805

Epoch: 6| Step: 10
Training loss: 1.7180614826316365
Validation loss: 2.6496730541616946

Epoch: 6| Step: 11
Training loss: 1.5768372975792744
Validation loss: 2.609818034159369

Epoch: 6| Step: 12
Training loss: 2.0349235767757645
Validation loss: 2.636450839938253

Epoch: 6| Step: 13
Training loss: 1.4804780904429955
Validation loss: 2.5881836346187437

Epoch: 259| Step: 0
Training loss: 1.6424272356797311
Validation loss: 2.5524604600755705

Epoch: 6| Step: 1
Training loss: 1.2959870665311077
Validation loss: 2.5606800832928456

Epoch: 6| Step: 2
Training loss: 1.8265535822667787
Validation loss: 2.5651260753991276

Epoch: 6| Step: 3
Training loss: 1.6742504036777437
Validation loss: 2.5469210970499434

Epoch: 6| Step: 4
Training loss: 1.966637219461793
Validation loss: 2.5054805835287475

Epoch: 6| Step: 5
Training loss: 1.7494405124577452
Validation loss: 2.513154293399149

Epoch: 6| Step: 6
Training loss: 1.3032244399663468
Validation loss: 2.5119415701339083

Epoch: 6| Step: 7
Training loss: 1.436169713683827
Validation loss: 2.52021738007178

Epoch: 6| Step: 8
Training loss: 1.1759626178963238
Validation loss: 2.5020468269882996

Epoch: 6| Step: 9
Training loss: 1.8229683423665117
Validation loss: 2.5037717188116457

Epoch: 6| Step: 10
Training loss: 1.3839249958044877
Validation loss: 2.4998671342552194

Epoch: 6| Step: 11
Training loss: 1.6357598238321627
Validation loss: 2.5191709423126256

Epoch: 6| Step: 12
Training loss: 1.7083012027355065
Validation loss: 2.531548229673178

Epoch: 6| Step: 13
Training loss: 1.564869724006696
Validation loss: 2.51211552015525

Epoch: 260| Step: 0
Training loss: 2.096225357047299
Validation loss: 2.5511956099697284

Epoch: 6| Step: 1
Training loss: 1.609138249140263
Validation loss: 2.5544155267470243

Epoch: 6| Step: 2
Training loss: 1.8890531957758487
Validation loss: 2.5422672918347198

Epoch: 6| Step: 3
Training loss: 1.542776361374065
Validation loss: 2.540763009131941

Epoch: 6| Step: 4
Training loss: 1.993855096325107
Validation loss: 2.554894218599761

Epoch: 6| Step: 5
Training loss: 1.6431414968214575
Validation loss: 2.5633297609015524

Epoch: 6| Step: 6
Training loss: 1.14542226642689
Validation loss: 2.5631053068577994

Epoch: 6| Step: 7
Training loss: 1.452912181733917
Validation loss: 2.562800740167837

Epoch: 6| Step: 8
Training loss: 1.3707210110192898
Validation loss: 2.558638145013401

Epoch: 6| Step: 9
Training loss: 1.408230806414606
Validation loss: 2.5614958425620395

Epoch: 6| Step: 10
Training loss: 1.5808805071693426
Validation loss: 2.5774705490607257

Epoch: 6| Step: 11
Training loss: 1.3083109080261623
Validation loss: 2.54838844133845

Epoch: 6| Step: 12
Training loss: 1.1315705956836044
Validation loss: 2.566947370139817

Epoch: 6| Step: 13
Training loss: 1.8360567094775369
Validation loss: 2.5738063066497188

Epoch: 261| Step: 0
Training loss: 1.3554590318314943
Validation loss: 2.5588216294846773

Epoch: 6| Step: 1
Training loss: 1.4697026349017788
Validation loss: 2.5374765768949765

Epoch: 6| Step: 2
Training loss: 1.958168963034068
Validation loss: 2.5448299048178677

Epoch: 6| Step: 3
Training loss: 1.605982491745768
Validation loss: 2.5518915649717724

Epoch: 6| Step: 4
Training loss: 1.673182466451295
Validation loss: 2.5361443704910043

Epoch: 6| Step: 5
Training loss: 1.3887752703711798
Validation loss: 2.523731398585293

Epoch: 6| Step: 6
Training loss: 1.5206689963539626
Validation loss: 2.546734091618291

Epoch: 6| Step: 7
Training loss: 1.7317286742009572
Validation loss: 2.5632391623144324

Epoch: 6| Step: 8
Training loss: 1.4514087673612643
Validation loss: 2.5922131077624178

Epoch: 6| Step: 9
Training loss: 1.302785800908229
Validation loss: 2.568809323321577

Epoch: 6| Step: 10
Training loss: 1.4562386409987766
Validation loss: 2.5422796407592703

Epoch: 6| Step: 11
Training loss: 1.5595395844166793
Validation loss: 2.4945522716451647

Epoch: 6| Step: 12
Training loss: 1.6441711611459937
Validation loss: 2.460195869960393

Epoch: 6| Step: 13
Training loss: 2.0233742251131637
Validation loss: 2.4570557632709

Epoch: 262| Step: 0
Training loss: 1.5794650893789626
Validation loss: 2.4426533588139248

Epoch: 6| Step: 1
Training loss: 1.852905558930336
Validation loss: 2.4477223134347232

Epoch: 6| Step: 2
Training loss: 1.1437883797965287
Validation loss: 2.461712654620598

Epoch: 6| Step: 3
Training loss: 1.796335155828508
Validation loss: 2.4365705816944287

Epoch: 6| Step: 4
Training loss: 1.3474099639084771
Validation loss: 2.4668514573134313

Epoch: 6| Step: 5
Training loss: 1.7784892991210302
Validation loss: 2.4747403756005144

Epoch: 6| Step: 6
Training loss: 1.423731168734609
Validation loss: 2.497409432022468

Epoch: 6| Step: 7
Training loss: 0.9336195427432102
Validation loss: 2.5204689951100585

Epoch: 6| Step: 8
Training loss: 1.406964269014913
Validation loss: 2.5464379505403367

Epoch: 6| Step: 9
Training loss: 1.8032641061315458
Validation loss: 2.5948302975416553

Epoch: 6| Step: 10
Training loss: 1.5254020348584958
Validation loss: 2.6286771385225194

Epoch: 6| Step: 11
Training loss: 1.4871544765229456
Validation loss: 2.616290682009884

Epoch: 6| Step: 12
Training loss: 1.8342235600153092
Validation loss: 2.6423983739433132

Epoch: 6| Step: 13
Training loss: 1.6282121748476215
Validation loss: 2.639756857722969

Epoch: 263| Step: 0
Training loss: 1.943183070481022
Validation loss: 2.630926509843222

Epoch: 6| Step: 1
Training loss: 1.3668359358952347
Validation loss: 2.5996417416802813

Epoch: 6| Step: 2
Training loss: 1.592554279641971
Validation loss: 2.589803127879134

Epoch: 6| Step: 3
Training loss: 1.7236611685433108
Validation loss: 2.562259086491128

Epoch: 6| Step: 4
Training loss: 1.3126930367339809
Validation loss: 2.5739953410970986

Epoch: 6| Step: 5
Training loss: 1.2424827560671197
Validation loss: 2.5295994434978124

Epoch: 6| Step: 6
Training loss: 0.983788694132103
Validation loss: 2.508416569592354

Epoch: 6| Step: 7
Training loss: 1.627924927702812
Validation loss: 2.462218901024804

Epoch: 6| Step: 8
Training loss: 1.6774207855714276
Validation loss: 2.4915895771191767

Epoch: 6| Step: 9
Training loss: 1.6188828432224354
Validation loss: 2.5051821742980573

Epoch: 6| Step: 10
Training loss: 1.6786548367680112
Validation loss: 2.513111153472052

Epoch: 6| Step: 11
Training loss: 0.9984942364877349
Validation loss: 2.5111881589338756

Epoch: 6| Step: 12
Training loss: 1.6821127482442388
Validation loss: 2.5210395690657648

Epoch: 6| Step: 13
Training loss: 1.8366557562769976
Validation loss: 2.5282122230285915

Epoch: 264| Step: 0
Training loss: 1.3989311497770025
Validation loss: 2.543592089509333

Epoch: 6| Step: 1
Training loss: 1.5503833942624359
Validation loss: 2.5858121521291433

Epoch: 6| Step: 2
Training loss: 1.8562032109281597
Validation loss: 2.5838555440989928

Epoch: 6| Step: 3
Training loss: 1.5674176458843503
Validation loss: 2.617274099725403

Epoch: 6| Step: 4
Training loss: 1.6188692940016502
Validation loss: 2.564200586597999

Epoch: 6| Step: 5
Training loss: 0.8422402544077711
Validation loss: 2.5154280516971292

Epoch: 6| Step: 6
Training loss: 1.7686667109313414
Validation loss: 2.5580185395870787

Epoch: 6| Step: 7
Training loss: 1.5465111352696628
Validation loss: 2.564418079867249

Epoch: 6| Step: 8
Training loss: 1.5862768402113465
Validation loss: 2.55422480434938

Epoch: 6| Step: 9
Training loss: 1.605566091440575
Validation loss: 2.5825110075055027

Epoch: 6| Step: 10
Training loss: 1.6623202951008054
Validation loss: 2.5559444460594607

Epoch: 6| Step: 11
Training loss: 1.9001662934461876
Validation loss: 2.570412563631964

Epoch: 6| Step: 12
Training loss: 1.2566878699142148
Validation loss: 2.5829008959778075

Epoch: 6| Step: 13
Training loss: 1.802677438814286
Validation loss: 2.5853093998597165

Epoch: 265| Step: 0
Training loss: 1.2467247492388547
Validation loss: 2.5585221290035958

Epoch: 6| Step: 1
Training loss: 1.555066623180469
Validation loss: 2.5426802595284035

Epoch: 6| Step: 2
Training loss: 1.9762248478349926
Validation loss: 2.463942171687176

Epoch: 6| Step: 3
Training loss: 1.5654743114448417
Validation loss: 2.476049177802663

Epoch: 6| Step: 4
Training loss: 1.6883916971425015
Validation loss: 2.410746895208793

Epoch: 6| Step: 5
Training loss: 1.8806013364054244
Validation loss: 2.4114774047066234

Epoch: 6| Step: 6
Training loss: 1.5306839967310402
Validation loss: 2.4362281781696087

Epoch: 6| Step: 7
Training loss: 1.5724596365886667
Validation loss: 2.445930718112039

Epoch: 6| Step: 8
Training loss: 1.3373417751807104
Validation loss: 2.4608837897264633

Epoch: 6| Step: 9
Training loss: 1.2412932433925188
Validation loss: 2.461882992435662

Epoch: 6| Step: 10
Training loss: 1.7622453870903703
Validation loss: 2.4879905379022142

Epoch: 6| Step: 11
Training loss: 1.4024980295476823
Validation loss: 2.535988152216046

Epoch: 6| Step: 12
Training loss: 1.8140951569317747
Validation loss: 2.6042075779480274

Epoch: 6| Step: 13
Training loss: 0.7646240776147497
Validation loss: 2.6073017909540748

Epoch: 266| Step: 0
Training loss: 1.0022060974698392
Validation loss: 2.591509225095895

Epoch: 6| Step: 1
Training loss: 1.6607962059290038
Validation loss: 2.6033656335858666

Epoch: 6| Step: 2
Training loss: 1.8036714806653138
Validation loss: 2.592049564282488

Epoch: 6| Step: 3
Training loss: 0.9724456681713205
Validation loss: 2.6082082547863443

Epoch: 6| Step: 4
Training loss: 1.6013944212012976
Validation loss: 2.576820661594625

Epoch: 6| Step: 5
Training loss: 1.1991613914863257
Validation loss: 2.5657702042536927

Epoch: 6| Step: 6
Training loss: 2.090265705613106
Validation loss: 2.544266644010463

Epoch: 6| Step: 7
Training loss: 1.1964138168368685
Validation loss: 2.500753566010803

Epoch: 6| Step: 8
Training loss: 1.3482879042939218
Validation loss: 2.5356858941173592

Epoch: 6| Step: 9
Training loss: 1.6577259900444488
Validation loss: 2.5244265891410334

Epoch: 6| Step: 10
Training loss: 1.8711235028093423
Validation loss: 2.50280982414964

Epoch: 6| Step: 11
Training loss: 1.753104997544577
Validation loss: 2.501166324913899

Epoch: 6| Step: 12
Training loss: 1.0929522193383907
Validation loss: 2.50066434482908

Epoch: 6| Step: 13
Training loss: 1.7259750402464784
Validation loss: 2.53171646416183

Epoch: 267| Step: 0
Training loss: 1.7911722328996635
Validation loss: 2.5177577501427426

Epoch: 6| Step: 1
Training loss: 1.834508266514566
Validation loss: 2.5433439287967494

Epoch: 6| Step: 2
Training loss: 1.7745879218794622
Validation loss: 2.530423603596625

Epoch: 6| Step: 3
Training loss: 1.6311125598754361
Validation loss: 2.5045097590924614

Epoch: 6| Step: 4
Training loss: 1.2279737578393182
Validation loss: 2.525900877283194

Epoch: 6| Step: 5
Training loss: 1.2834955401935675
Validation loss: 2.5085386412644493

Epoch: 6| Step: 6
Training loss: 1.2924567646638672
Validation loss: 2.541804780104054

Epoch: 6| Step: 7
Training loss: 0.6547616019908816
Validation loss: 2.490461755642672

Epoch: 6| Step: 8
Training loss: 1.5784239533031308
Validation loss: 2.57128981625113

Epoch: 6| Step: 9
Training loss: 1.2869233849402437
Validation loss: 2.5337882917652865

Epoch: 6| Step: 10
Training loss: 1.1413579179895312
Validation loss: 2.4978593808863354

Epoch: 6| Step: 11
Training loss: 1.3579714314429123
Validation loss: 2.4959920473171238

Epoch: 6| Step: 12
Training loss: 1.8629633154418277
Validation loss: 2.5477917876589733

Epoch: 6| Step: 13
Training loss: 1.735115786599763
Validation loss: 2.525742036035284

Epoch: 268| Step: 0
Training loss: 1.1792173143344993
Validation loss: 2.532224480993001

Epoch: 6| Step: 1
Training loss: 1.5559579077227181
Validation loss: 2.507515565491829

Epoch: 6| Step: 2
Training loss: 1.1675931907235704
Validation loss: 2.5092764748238356

Epoch: 6| Step: 3
Training loss: 1.8688839025590933
Validation loss: 2.518266155439859

Epoch: 6| Step: 4
Training loss: 1.3479185871816137
Validation loss: 2.4856167027043554

Epoch: 6| Step: 5
Training loss: 1.6837259404446572
Validation loss: 2.5106801818179596

Epoch: 6| Step: 6
Training loss: 1.291092632265056
Validation loss: 2.501481086123666

Epoch: 6| Step: 7
Training loss: 1.2742840813892686
Validation loss: 2.561871622405952

Epoch: 6| Step: 8
Training loss: 1.3261629758825588
Validation loss: 2.5455598085849234

Epoch: 6| Step: 9
Training loss: 1.6759675462580501
Validation loss: 2.5340031183146254

Epoch: 6| Step: 10
Training loss: 1.1807136872293098
Validation loss: 2.5420783193865737

Epoch: 6| Step: 11
Training loss: 1.6402011142092
Validation loss: 2.53860926114325

Epoch: 6| Step: 12
Training loss: 1.6369448121030512
Validation loss: 2.5223643878065034

Epoch: 6| Step: 13
Training loss: 1.4532240146825182
Validation loss: 2.5236094761702357

Epoch: 269| Step: 0
Training loss: 1.3082235695217286
Validation loss: 2.5645903958199323

Epoch: 6| Step: 1
Training loss: 1.5693784754269127
Validation loss: 2.5361859238336018

Epoch: 6| Step: 2
Training loss: 1.6392944753622287
Validation loss: 2.5085599910605927

Epoch: 6| Step: 3
Training loss: 1.8974293359155936
Validation loss: 2.5277508779262874

Epoch: 6| Step: 4
Training loss: 1.1132390599872952
Validation loss: 2.5263645247846966

Epoch: 6| Step: 5
Training loss: 1.161540942255015
Validation loss: 2.492243822178657

Epoch: 6| Step: 6
Training loss: 1.2029874648711878
Validation loss: 2.478947583682748

Epoch: 6| Step: 7
Training loss: 1.2662998801948222
Validation loss: 2.48055679181836

Epoch: 6| Step: 8
Training loss: 1.4586114164160107
Validation loss: 2.4894972041588432

Epoch: 6| Step: 9
Training loss: 1.3463365367962425
Validation loss: 2.4832141222904958

Epoch: 6| Step: 10
Training loss: 1.1775916473294583
Validation loss: 2.5080648203367115

Epoch: 6| Step: 11
Training loss: 1.7613120275638732
Validation loss: 2.509816596664853

Epoch: 6| Step: 12
Training loss: 1.7618298548408264
Validation loss: 2.5592865642866833

Epoch: 6| Step: 13
Training loss: 1.404443852528281
Validation loss: 2.5536623970296297

Epoch: 270| Step: 0
Training loss: 1.4069779948863743
Validation loss: 2.5598926119590653

Epoch: 6| Step: 1
Training loss: 1.3133906112967335
Validation loss: 2.5860145685498868

Epoch: 6| Step: 2
Training loss: 1.3095916131866672
Validation loss: 2.582172735133497

Epoch: 6| Step: 3
Training loss: 1.3159855473139268
Validation loss: 2.568125838220034

Epoch: 6| Step: 4
Training loss: 1.1780797853571354
Validation loss: 2.4919056765997816

Epoch: 6| Step: 5
Training loss: 1.3847435867428275
Validation loss: 2.48275897759187

Epoch: 6| Step: 6
Training loss: 1.410538344250482
Validation loss: 2.4978516720718704

Epoch: 6| Step: 7
Training loss: 1.5192743785434493
Validation loss: 2.4703106156400674

Epoch: 6| Step: 8
Training loss: 1.5248064199686744
Validation loss: 2.484259301074704

Epoch: 6| Step: 9
Training loss: 1.5761086452427342
Validation loss: 2.482741612678189

Epoch: 6| Step: 10
Training loss: 1.8668966665373963
Validation loss: 2.484805002249416

Epoch: 6| Step: 11
Training loss: 1.3336354549168705
Validation loss: 2.5061023743863333

Epoch: 6| Step: 12
Training loss: 1.3834356423351084
Validation loss: 2.475668736089111

Epoch: 6| Step: 13
Training loss: 1.7328282925683285
Validation loss: 2.5067109863084442

Epoch: 271| Step: 0
Training loss: 1.589750394962392
Validation loss: 2.5063783863305105

Epoch: 6| Step: 1
Training loss: 1.1106028679234843
Validation loss: 2.540083496183508

Epoch: 6| Step: 2
Training loss: 1.319875340066182
Validation loss: 2.566651914210833

Epoch: 6| Step: 3
Training loss: 1.586994288837466
Validation loss: 2.6149643530216227

Epoch: 6| Step: 4
Training loss: 1.3970955744949507
Validation loss: 2.6381979779600844

Epoch: 6| Step: 5
Training loss: 1.640375318147407
Validation loss: 2.617369521644745

Epoch: 6| Step: 6
Training loss: 1.5890572966993994
Validation loss: 2.5989191008482506

Epoch: 6| Step: 7
Training loss: 0.928121899429434
Validation loss: 2.6036954418143554

Epoch: 6| Step: 8
Training loss: 1.2377972062920561
Validation loss: 2.5707609546746757

Epoch: 6| Step: 9
Training loss: 1.8915662077837945
Validation loss: 2.559715668162174

Epoch: 6| Step: 10
Training loss: 1.123056799803292
Validation loss: 2.5191008138843145

Epoch: 6| Step: 11
Training loss: 1.100877643639639
Validation loss: 2.4978247931556434

Epoch: 6| Step: 12
Training loss: 1.8783659286965393
Validation loss: 2.4571074131237123

Epoch: 6| Step: 13
Training loss: 1.352089310658805
Validation loss: 2.453199890343778

Epoch: 272| Step: 0
Training loss: 1.7262882342789858
Validation loss: 2.4330667473454337

Epoch: 6| Step: 1
Training loss: 1.240285316682643
Validation loss: 2.449465065879118

Epoch: 6| Step: 2
Training loss: 1.1461288186749308
Validation loss: 2.4737521257368424

Epoch: 6| Step: 3
Training loss: 1.757754854740562
Validation loss: 2.4762959337957833

Epoch: 6| Step: 4
Training loss: 1.2612559884177763
Validation loss: 2.512407800873172

Epoch: 6| Step: 5
Training loss: 1.275121266077156
Validation loss: 2.540130401262357

Epoch: 6| Step: 6
Training loss: 1.4480736828018677
Validation loss: 2.52162020192675

Epoch: 6| Step: 7
Training loss: 1.089017383839527
Validation loss: 2.5387508108258587

Epoch: 6| Step: 8
Training loss: 1.5768564999251522
Validation loss: 2.5563738145911246

Epoch: 6| Step: 9
Training loss: 1.494310396809083
Validation loss: 2.5422622457600945

Epoch: 6| Step: 10
Training loss: 1.6570176558811482
Validation loss: 2.530152978833952

Epoch: 6| Step: 11
Training loss: 1.4849446057092994
Validation loss: 2.534192865910311

Epoch: 6| Step: 12
Training loss: 1.0976787849909582
Validation loss: 2.5357939622483863

Epoch: 6| Step: 13
Training loss: 1.2248699878286817
Validation loss: 2.529422915399325

Epoch: 273| Step: 0
Training loss: 1.8881160387611313
Validation loss: 2.538668199438977

Epoch: 6| Step: 1
Training loss: 1.5655733020036249
Validation loss: 2.5383983122604596

Epoch: 6| Step: 2
Training loss: 1.1010659363428794
Validation loss: 2.5469101929122036

Epoch: 6| Step: 3
Training loss: 1.7199859336898846
Validation loss: 2.5964419108323225

Epoch: 6| Step: 4
Training loss: 1.068657256446889
Validation loss: 2.5840049069864484

Epoch: 6| Step: 5
Training loss: 0.6877714834847931
Validation loss: 2.5265725937264865

Epoch: 6| Step: 6
Training loss: 1.4077194166158817
Validation loss: 2.5314334451977483

Epoch: 6| Step: 7
Training loss: 1.42348581812031
Validation loss: 2.499716329375352

Epoch: 6| Step: 8
Training loss: 1.556830840891482
Validation loss: 2.4919820330438642

Epoch: 6| Step: 9
Training loss: 1.3838471674380206
Validation loss: 2.518070384468305

Epoch: 6| Step: 10
Training loss: 1.2549361043219636
Validation loss: 2.494215941721527

Epoch: 6| Step: 11
Training loss: 1.2801218415921545
Validation loss: 2.4582833004659355

Epoch: 6| Step: 12
Training loss: 1.2476136794498245
Validation loss: 2.463309596156301

Epoch: 6| Step: 13
Training loss: 1.8230689793487642
Validation loss: 2.493303235707365

Epoch: 274| Step: 0
Training loss: 1.3278254451645888
Validation loss: 2.479079133209583

Epoch: 6| Step: 1
Training loss: 2.112345546515944
Validation loss: 2.514547111109718

Epoch: 6| Step: 2
Training loss: 1.6940822092530703
Validation loss: 2.4992848614256977

Epoch: 6| Step: 3
Training loss: 1.1513164531734532
Validation loss: 2.5253220072923255

Epoch: 6| Step: 4
Training loss: 1.2006559923372826
Validation loss: 2.529170235346519

Epoch: 6| Step: 5
Training loss: 1.3367984964203612
Validation loss: 2.5846301709540818

Epoch: 6| Step: 6
Training loss: 1.1837868108131633
Validation loss: 2.5883819810771076

Epoch: 6| Step: 7
Training loss: 1.28071364364535
Validation loss: 2.5942982147294478

Epoch: 6| Step: 8
Training loss: 1.3205040787067277
Validation loss: 2.576815299158034

Epoch: 6| Step: 9
Training loss: 1.2952829723420791
Validation loss: 2.545519506022495

Epoch: 6| Step: 10
Training loss: 1.6191134571331627
Validation loss: 2.5118997504457545

Epoch: 6| Step: 11
Training loss: 1.4821236653488827
Validation loss: 2.484360459374728

Epoch: 6| Step: 12
Training loss: 1.2253325302950193
Validation loss: 2.4531004882072787

Epoch: 6| Step: 13
Training loss: 1.1875031621790495
Validation loss: 2.5092778612232283

Epoch: 275| Step: 0
Training loss: 1.3531125832355788
Validation loss: 2.440682165389119

Epoch: 6| Step: 1
Training loss: 1.2867186999711824
Validation loss: 2.4839212017722194

Epoch: 6| Step: 2
Training loss: 1.0203885971597104
Validation loss: 2.4617546166486064

Epoch: 6| Step: 3
Training loss: 1.3101292952583685
Validation loss: 2.489828090415834

Epoch: 6| Step: 4
Training loss: 1.4046156817143511
Validation loss: 2.4995929848150173

Epoch: 6| Step: 5
Training loss: 1.3990251382692005
Validation loss: 2.5139625211028997

Epoch: 6| Step: 6
Training loss: 1.711363020982808
Validation loss: 2.5209234569537755

Epoch: 6| Step: 7
Training loss: 1.7839113398019324
Validation loss: 2.5433128424936022

Epoch: 6| Step: 8
Training loss: 0.9650575346916875
Validation loss: 2.567552468237774

Epoch: 6| Step: 9
Training loss: 1.236633937913288
Validation loss: 2.5465803752906213

Epoch: 6| Step: 10
Training loss: 1.4387814159261063
Validation loss: 2.5233076910432968

Epoch: 6| Step: 11
Training loss: 1.2654708014849694
Validation loss: 2.530128169642874

Epoch: 6| Step: 12
Training loss: 1.6862935592646904
Validation loss: 2.521866154010002

Epoch: 6| Step: 13
Training loss: 1.4504470760785313
Validation loss: 2.5122175354717395

Epoch: 276| Step: 0
Training loss: 1.7824920205770967
Validation loss: 2.504110564510694

Epoch: 6| Step: 1
Training loss: 0.9920475778514286
Validation loss: 2.497395689961927

Epoch: 6| Step: 2
Training loss: 1.579932961792153
Validation loss: 2.513266911743506

Epoch: 6| Step: 3
Training loss: 1.1791740967659117
Validation loss: 2.494213290935522

Epoch: 6| Step: 4
Training loss: 1.6046264369381964
Validation loss: 2.490080761901749

Epoch: 6| Step: 5
Training loss: 1.5194347517660203
Validation loss: 2.5312466704299723

Epoch: 6| Step: 6
Training loss: 1.2622257312444556
Validation loss: 2.524824127152712

Epoch: 6| Step: 7
Training loss: 1.011804937867065
Validation loss: 2.548141500790385

Epoch: 6| Step: 8
Training loss: 0.947575595124873
Validation loss: 2.5897905205089997

Epoch: 6| Step: 9
Training loss: 1.187144577644181
Validation loss: 2.561048703482529

Epoch: 6| Step: 10
Training loss: 1.3807835753704993
Validation loss: 2.598307631405877

Epoch: 6| Step: 11
Training loss: 1.6229121660685133
Validation loss: 2.5517562994865304

Epoch: 6| Step: 12
Training loss: 1.4494067787282454
Validation loss: 2.5324467086517726

Epoch: 6| Step: 13
Training loss: 1.3974317205055267
Validation loss: 2.547817877819877

Epoch: 277| Step: 0
Training loss: 1.0770685299434666
Validation loss: 2.5036302716827508

Epoch: 6| Step: 1
Training loss: 1.2641317718725824
Validation loss: 2.513294607801841

Epoch: 6| Step: 2
Training loss: 1.019442616552596
Validation loss: 2.517915879391994

Epoch: 6| Step: 3
Training loss: 0.9918533122835093
Validation loss: 2.48644091908508

Epoch: 6| Step: 4
Training loss: 1.2519105139278597
Validation loss: 2.474908600162903

Epoch: 6| Step: 5
Training loss: 1.606548011534887
Validation loss: 2.517793017092141

Epoch: 6| Step: 6
Training loss: 1.552822124952679
Validation loss: 2.5086985574594847

Epoch: 6| Step: 7
Training loss: 1.4753013755542148
Validation loss: 2.503989453338179

Epoch: 6| Step: 8
Training loss: 1.3176244877411738
Validation loss: 2.5314935455379004

Epoch: 6| Step: 9
Training loss: 1.26644023494315
Validation loss: 2.502233338308589

Epoch: 6| Step: 10
Training loss: 1.6868469952820093
Validation loss: 2.510497932887103

Epoch: 6| Step: 11
Training loss: 1.85886741570044
Validation loss: 2.522059808797296

Epoch: 6| Step: 12
Training loss: 0.9033539306983304
Validation loss: 2.5051690924607493

Epoch: 6| Step: 13
Training loss: 1.1211174620137723
Validation loss: 2.5187009862358223

Epoch: 278| Step: 0
Training loss: 1.3722649161371996
Validation loss: 2.5147523267603105

Epoch: 6| Step: 1
Training loss: 1.5139014285362493
Validation loss: 2.5174916508064658

Epoch: 6| Step: 2
Training loss: 1.499955574013538
Validation loss: 2.537165049069532

Epoch: 6| Step: 3
Training loss: 1.5669367550646576
Validation loss: 2.5520103385553345

Epoch: 6| Step: 4
Training loss: 1.141401731885549
Validation loss: 2.555084427482423

Epoch: 6| Step: 5
Training loss: 0.9415898440822096
Validation loss: 2.541098189329077

Epoch: 6| Step: 6
Training loss: 1.2619275372070209
Validation loss: 2.5699568090092995

Epoch: 6| Step: 7
Training loss: 1.5338269562134628
Validation loss: 2.570561374225663

Epoch: 6| Step: 8
Training loss: 1.461829744301457
Validation loss: 2.5311559115006106

Epoch: 6| Step: 9
Training loss: 1.0233704639640413
Validation loss: 2.508048581246597

Epoch: 6| Step: 10
Training loss: 1.1872481028769994
Validation loss: 2.496291618817917

Epoch: 6| Step: 11
Training loss: 1.4227366090103128
Validation loss: 2.484450309397779

Epoch: 6| Step: 12
Training loss: 1.3533215404256633
Validation loss: 2.5253409341209667

Epoch: 6| Step: 13
Training loss: 1.3477420503144475
Validation loss: 2.4867597668191057

Epoch: 279| Step: 0
Training loss: 1.2307848327592321
Validation loss: 2.5067854308858135

Epoch: 6| Step: 1
Training loss: 1.7523440602098617
Validation loss: 2.556028454380596

Epoch: 6| Step: 2
Training loss: 1.2776045226842936
Validation loss: 2.563195932179984

Epoch: 6| Step: 3
Training loss: 1.2212936559896073
Validation loss: 2.5863265329288816

Epoch: 6| Step: 4
Training loss: 1.371529751654169
Validation loss: 2.631495202728414

Epoch: 6| Step: 5
Training loss: 1.6165471675137577
Validation loss: 2.564816661009722

Epoch: 6| Step: 6
Training loss: 1.2987164212714988
Validation loss: 2.4766170730807087

Epoch: 6| Step: 7
Training loss: 1.5967483739048778
Validation loss: 2.4374339881206195

Epoch: 6| Step: 8
Training loss: 1.2834655400499568
Validation loss: 2.434605619858659

Epoch: 6| Step: 9
Training loss: 1.0527295057647712
Validation loss: 2.4333397917746775

Epoch: 6| Step: 10
Training loss: 1.3986473991529416
Validation loss: 2.423377757903911

Epoch: 6| Step: 11
Training loss: 1.3668243797916655
Validation loss: 2.4195267899227466

Epoch: 6| Step: 12
Training loss: 1.3100256985043777
Validation loss: 2.4364754559006534

Epoch: 6| Step: 13
Training loss: 1.5314824453375877
Validation loss: 2.5115755405527493

Epoch: 280| Step: 0
Training loss: 1.7717412827509975
Validation loss: 2.5176033465470047

Epoch: 6| Step: 1
Training loss: 1.6239995811302133
Validation loss: 2.540798802296042

Epoch: 6| Step: 2
Training loss: 0.971483250990441
Validation loss: 2.590995825703787

Epoch: 6| Step: 3
Training loss: 1.1662680194603392
Validation loss: 2.5831374260501323

Epoch: 6| Step: 4
Training loss: 1.0909778887556163
Validation loss: 2.565306821298645

Epoch: 6| Step: 5
Training loss: 1.4304144006776551
Validation loss: 2.5568410022985444

Epoch: 6| Step: 6
Training loss: 1.138942365760627
Validation loss: 2.582162172467361

Epoch: 6| Step: 7
Training loss: 1.7647852293108848
Validation loss: 2.620547472781124

Epoch: 6| Step: 8
Training loss: 1.3493546550536857
Validation loss: 2.6302143172800436

Epoch: 6| Step: 9
Training loss: 1.2281117465248061
Validation loss: 2.6065826870987436

Epoch: 6| Step: 10
Training loss: 1.2344113115208974
Validation loss: 2.563449912155856

Epoch: 6| Step: 11
Training loss: 1.0371564434168226
Validation loss: 2.51652523384401

Epoch: 6| Step: 12
Training loss: 1.40170494554998
Validation loss: 2.470944224023219

Epoch: 6| Step: 13
Training loss: 1.5026080981577232
Validation loss: 2.500062002418094

Epoch: 281| Step: 0
Training loss: 1.516513681905312
Validation loss: 2.470191464128642

Epoch: 6| Step: 1
Training loss: 0.988708132497623
Validation loss: 2.4538477113982315

Epoch: 6| Step: 2
Training loss: 1.103871300016502
Validation loss: 2.4662823559631004

Epoch: 6| Step: 3
Training loss: 0.9508473432101084
Validation loss: 2.4446127139654483

Epoch: 6| Step: 4
Training loss: 1.8421855690309403
Validation loss: 2.5183848499950443

Epoch: 6| Step: 5
Training loss: 1.3738195814399055
Validation loss: 2.49847476485624

Epoch: 6| Step: 6
Training loss: 1.7362103073603374
Validation loss: 2.52408115096489

Epoch: 6| Step: 7
Training loss: 1.0624409827502856
Validation loss: 2.5388772452320136

Epoch: 6| Step: 8
Training loss: 1.275093546408853
Validation loss: 2.5454146637999826

Epoch: 6| Step: 9
Training loss: 1.3521083545377894
Validation loss: 2.539595387010499

Epoch: 6| Step: 10
Training loss: 1.275406047266298
Validation loss: 2.5215353812342083

Epoch: 6| Step: 11
Training loss: 1.418921872790096
Validation loss: 2.580984162584815

Epoch: 6| Step: 12
Training loss: 0.8752077741529577
Validation loss: 2.5580248900057607

Epoch: 6| Step: 13
Training loss: 1.2067095380266242
Validation loss: 2.5362792698010437

Epoch: 282| Step: 0
Training loss: 1.3991970791142263
Validation loss: 2.5642791322387852

Epoch: 6| Step: 1
Training loss: 1.4728364303007795
Validation loss: 2.5681159415156536

Epoch: 6| Step: 2
Training loss: 1.4077331351244002
Validation loss: 2.55821273059558

Epoch: 6| Step: 3
Training loss: 1.4134139792058023
Validation loss: 2.5722296697141

Epoch: 6| Step: 4
Training loss: 1.0849541802114337
Validation loss: 2.551735307085559

Epoch: 6| Step: 5
Training loss: 1.0519295696535076
Validation loss: 2.554114671483817

Epoch: 6| Step: 6
Training loss: 1.045536267060658
Validation loss: 2.580921711319095

Epoch: 6| Step: 7
Training loss: 1.493216594123757
Validation loss: 2.560024132867987

Epoch: 6| Step: 8
Training loss: 1.7241128658248517
Validation loss: 2.571777879549377

Epoch: 6| Step: 9
Training loss: 1.030540337725823
Validation loss: 2.5654108665652156

Epoch: 6| Step: 10
Training loss: 1.2821846785898985
Validation loss: 2.5333353838672124

Epoch: 6| Step: 11
Training loss: 1.1222351856133426
Validation loss: 2.473563095843751

Epoch: 6| Step: 12
Training loss: 1.4061970594825433
Validation loss: 2.48221143542157

Epoch: 6| Step: 13
Training loss: 0.9908826462869434
Validation loss: 2.479653622322777

Epoch: 283| Step: 0
Training loss: 1.8292040126640574
Validation loss: 2.51081823555616

Epoch: 6| Step: 1
Training loss: 1.2823250145169263
Validation loss: 2.4716152118688965

Epoch: 6| Step: 2
Training loss: 0.9772145650181844
Validation loss: 2.4955902143764854

Epoch: 6| Step: 3
Training loss: 1.0001841018009747
Validation loss: 2.4971864475606913

Epoch: 6| Step: 4
Training loss: 1.4056695375896395
Validation loss: 2.515276238151662

Epoch: 6| Step: 5
Training loss: 1.536924784917801
Validation loss: 2.4695728862587036

Epoch: 6| Step: 6
Training loss: 1.2919917722947887
Validation loss: 2.4481495624485934

Epoch: 6| Step: 7
Training loss: 0.9148182801073617
Validation loss: 2.5007941840651875

Epoch: 6| Step: 8
Training loss: 1.3625317893563185
Validation loss: 2.5437489322755753

Epoch: 6| Step: 9
Training loss: 1.2521182232574637
Validation loss: 2.5002276470765317

Epoch: 6| Step: 10
Training loss: 1.0440030345178402
Validation loss: 2.534565065233414

Epoch: 6| Step: 11
Training loss: 1.1160770045549884
Validation loss: 2.5334596164323266

Epoch: 6| Step: 12
Training loss: 1.416173044859653
Validation loss: 2.527200292871967

Epoch: 6| Step: 13
Training loss: 0.9801837157273877
Validation loss: 2.52345963959865

Epoch: 284| Step: 0
Training loss: 1.2981536720279483
Validation loss: 2.522618412175397

Epoch: 6| Step: 1
Training loss: 1.235157247949495
Validation loss: 2.556467963734735

Epoch: 6| Step: 2
Training loss: 0.988854765809302
Validation loss: 2.525902027211208

Epoch: 6| Step: 3
Training loss: 1.5456486474251616
Validation loss: 2.6009485678904327

Epoch: 6| Step: 4
Training loss: 1.8758161040296795
Validation loss: 2.565148734169913

Epoch: 6| Step: 5
Training loss: 1.188504647367424
Validation loss: 2.5469317676189993

Epoch: 6| Step: 6
Training loss: 0.9287656493171305
Validation loss: 2.523442979930679

Epoch: 6| Step: 7
Training loss: 1.1174771126914507
Validation loss: 2.484644553189302

Epoch: 6| Step: 8
Training loss: 1.2150047171073364
Validation loss: 2.475281605382744

Epoch: 6| Step: 9
Training loss: 0.44399063610714645
Validation loss: 2.482813499141387

Epoch: 6| Step: 10
Training loss: 1.103713620408226
Validation loss: 2.4673236544307677

Epoch: 6| Step: 11
Training loss: 1.2359292590690016
Validation loss: 2.4695385314462626

Epoch: 6| Step: 12
Training loss: 1.5328150944585746
Validation loss: 2.47919575739733

Epoch: 6| Step: 13
Training loss: 1.4878899968617405
Validation loss: 2.485783519309767

Epoch: 285| Step: 0
Training loss: 1.1126656419689502
Validation loss: 2.444395627616974

Epoch: 6| Step: 1
Training loss: 1.707894043925764
Validation loss: 2.4577787415761687

Epoch: 6| Step: 2
Training loss: 1.2996826114548845
Validation loss: 2.4601192803706327

Epoch: 6| Step: 3
Training loss: 0.7733385812715615
Validation loss: 2.461213067833731

Epoch: 6| Step: 4
Training loss: 1.2689742994058195
Validation loss: 2.4470355861984245

Epoch: 6| Step: 5
Training loss: 1.3579213053805606
Validation loss: 2.4304262121175024

Epoch: 6| Step: 6
Training loss: 1.2885453082531493
Validation loss: 2.4285734938739156

Epoch: 6| Step: 7
Training loss: 0.9746400144114521
Validation loss: 2.4631927578933794

Epoch: 6| Step: 8
Training loss: 0.4299356264344451
Validation loss: 2.5092477152924135

Epoch: 6| Step: 9
Training loss: 1.52069259236194
Validation loss: 2.477913307448617

Epoch: 6| Step: 10
Training loss: 1.4968388945300621
Validation loss: 2.5201856021159634

Epoch: 6| Step: 11
Training loss: 1.362541675805173
Validation loss: 2.4982853423772826

Epoch: 6| Step: 12
Training loss: 1.199191065167383
Validation loss: 2.5028096377261217

Epoch: 6| Step: 13
Training loss: 0.9514534159556168
Validation loss: 2.547255570598753

Epoch: 286| Step: 0
Training loss: 1.8670415462127306
Validation loss: 2.5581159187914277

Epoch: 6| Step: 1
Training loss: 0.978778704761886
Validation loss: 2.5820179424290775

Epoch: 6| Step: 2
Training loss: 1.414112659218075
Validation loss: 2.588133521882947

Epoch: 6| Step: 3
Training loss: 1.4038658276376226
Validation loss: 2.621410251427711

Epoch: 6| Step: 4
Training loss: 1.399835580298889
Validation loss: 2.5751056590128165

Epoch: 6| Step: 5
Training loss: 0.8669124545124249
Validation loss: 2.5599515980176477

Epoch: 6| Step: 6
Training loss: 1.0986433918761458
Validation loss: 2.5261355106203336

Epoch: 6| Step: 7
Training loss: 1.249264453006583
Validation loss: 2.48889217461489

Epoch: 6| Step: 8
Training loss: 1.186822798526612
Validation loss: 2.47537512494377

Epoch: 6| Step: 9
Training loss: 1.2073332276101139
Validation loss: 2.492732778883845

Epoch: 6| Step: 10
Training loss: 1.1374744642975578
Validation loss: 2.446173552380419

Epoch: 6| Step: 11
Training loss: 1.0119340586495102
Validation loss: 2.4732307954096795

Epoch: 6| Step: 12
Training loss: 1.3573228100092067
Validation loss: 2.416163833153189

Epoch: 6| Step: 13
Training loss: 1.4453614097773806
Validation loss: 2.453303560313826

Epoch: 287| Step: 0
Training loss: 1.2106066836427383
Validation loss: 2.4330813858884346

Epoch: 6| Step: 1
Training loss: 1.3693333815253033
Validation loss: 2.4693411517430213

Epoch: 6| Step: 2
Training loss: 1.0261912680580607
Validation loss: 2.5022106394998778

Epoch: 6| Step: 3
Training loss: 1.365269301681277
Validation loss: 2.531155434455776

Epoch: 6| Step: 4
Training loss: 1.3024534182721463
Validation loss: 2.5785633061367492

Epoch: 6| Step: 5
Training loss: 1.05595186529128
Validation loss: 2.5745758695766585

Epoch: 6| Step: 6
Training loss: 1.3424000723817189
Validation loss: 2.5920805052243883

Epoch: 6| Step: 7
Training loss: 1.2194125013191448
Validation loss: 2.5359166368240893

Epoch: 6| Step: 8
Training loss: 1.0488927952667635
Validation loss: 2.4972031207044227

Epoch: 6| Step: 9
Training loss: 1.4154456523943977
Validation loss: 2.4365512294007505

Epoch: 6| Step: 10
Training loss: 0.7566589542309555
Validation loss: 2.4363932235828445

Epoch: 6| Step: 11
Training loss: 1.159313576605824
Validation loss: 2.412286755437998

Epoch: 6| Step: 12
Training loss: 1.6539412907855824
Validation loss: 2.4492052954536305

Epoch: 6| Step: 13
Training loss: 1.4121239372547247
Validation loss: 2.4390190782246544

Epoch: 288| Step: 0
Training loss: 0.9788112536442458
Validation loss: 2.4807262325450146

Epoch: 6| Step: 1
Training loss: 0.9440240196914131
Validation loss: 2.522217160119352

Epoch: 6| Step: 2
Training loss: 1.5263353223641216
Validation loss: 2.534612562484228

Epoch: 6| Step: 3
Training loss: 0.991955016525615
Validation loss: 2.548192948313104

Epoch: 6| Step: 4
Training loss: 1.5437156704317265
Validation loss: 2.5491381032895073

Epoch: 6| Step: 5
Training loss: 1.4158570088964186
Validation loss: 2.584603539855055

Epoch: 6| Step: 6
Training loss: 0.9386371709319263
Validation loss: 2.550535053239659

Epoch: 6| Step: 7
Training loss: 1.555550723787403
Validation loss: 2.5732578642382937

Epoch: 6| Step: 8
Training loss: 1.2180130515565943
Validation loss: 2.5545459768450063

Epoch: 6| Step: 9
Training loss: 1.438997069620273
Validation loss: 2.4998535000525344

Epoch: 6| Step: 10
Training loss: 1.0091674922075577
Validation loss: 2.4520639853003803

Epoch: 6| Step: 11
Training loss: 1.1050998355247121
Validation loss: 2.4503088292918815

Epoch: 6| Step: 12
Training loss: 1.4138454460351573
Validation loss: 2.415162784040624

Epoch: 6| Step: 13
Training loss: 1.3834221999031295
Validation loss: 2.4070413303343567

Epoch: 289| Step: 0
Training loss: 1.4109233344329088
Validation loss: 2.4134982756880685

Epoch: 6| Step: 1
Training loss: 1.4573333672462128
Validation loss: 2.4525509950376345

Epoch: 6| Step: 2
Training loss: 0.8758815003593888
Validation loss: 2.503671671444823

Epoch: 6| Step: 3
Training loss: 1.313218510460628
Validation loss: 2.5659257053657356

Epoch: 6| Step: 4
Training loss: 0.8483156021815782
Validation loss: 2.541501039494306

Epoch: 6| Step: 5
Training loss: 1.1326806353410637
Validation loss: 2.5617301498808067

Epoch: 6| Step: 6
Training loss: 1.1040687997499516
Validation loss: 2.605109373365574

Epoch: 6| Step: 7
Training loss: 0.7806846862160788
Validation loss: 2.574090523880883

Epoch: 6| Step: 8
Training loss: 1.4010016094092328
Validation loss: 2.5755301873022622

Epoch: 6| Step: 9
Training loss: 1.84887364869658
Validation loss: 2.5511296398734142

Epoch: 6| Step: 10
Training loss: 1.1563193326215928
Validation loss: 2.5308907356567523

Epoch: 6| Step: 11
Training loss: 0.8131957010059836
Validation loss: 2.5460364005894425

Epoch: 6| Step: 12
Training loss: 0.9704397907398336
Validation loss: 2.4844089061249566

Epoch: 6| Step: 13
Training loss: 1.384932665307013
Validation loss: 2.4649238626060814

Epoch: 290| Step: 0
Training loss: 1.1095732390894448
Validation loss: 2.4568095009412945

Epoch: 6| Step: 1
Training loss: 0.8629119911846946
Validation loss: 2.4947576543415493

Epoch: 6| Step: 2
Training loss: 1.433473254552712
Validation loss: 2.50507132010335

Epoch: 6| Step: 3
Training loss: 1.3545296793770274
Validation loss: 2.511656110587188

Epoch: 6| Step: 4
Training loss: 1.2069770282307097
Validation loss: 2.548860691962448

Epoch: 6| Step: 5
Training loss: 1.0012788939384747
Validation loss: 2.514075869558452

Epoch: 6| Step: 6
Training loss: 1.0192344496595485
Validation loss: 2.5162016036380193

Epoch: 6| Step: 7
Training loss: 0.7999844191941298
Validation loss: 2.5314516275595076

Epoch: 6| Step: 8
Training loss: 1.070612844385909
Validation loss: 2.5025567168513847

Epoch: 6| Step: 9
Training loss: 1.4231084985660074
Validation loss: 2.553497837246168

Epoch: 6| Step: 10
Training loss: 1.2463171109999511
Validation loss: 2.5334388104043915

Epoch: 6| Step: 11
Training loss: 1.4712648977920657
Validation loss: 2.528863130659852

Epoch: 6| Step: 12
Training loss: 1.1806782989022273
Validation loss: 2.510950293128269

Epoch: 6| Step: 13
Training loss: 1.0024146491268868
Validation loss: 2.514734604742373

Epoch: 291| Step: 0
Training loss: 1.1883985232056102
Validation loss: 2.496002465199956

Epoch: 6| Step: 1
Training loss: 0.9502941680013114
Validation loss: 2.4835657158716065

Epoch: 6| Step: 2
Training loss: 1.195257846355715
Validation loss: 2.52387136213411

Epoch: 6| Step: 3
Training loss: 1.1142160874226488
Validation loss: 2.542019451584294

Epoch: 6| Step: 4
Training loss: 1.195625264256992
Validation loss: 2.5369190330746227

Epoch: 6| Step: 5
Training loss: 1.6059590354436035
Validation loss: 2.534549617991743

Epoch: 6| Step: 6
Training loss: 1.2305363712197928
Validation loss: 2.542999440287059

Epoch: 6| Step: 7
Training loss: 1.3575390223168677
Validation loss: 2.5443040353120043

Epoch: 6| Step: 8
Training loss: 1.1977400718664457
Validation loss: 2.552229899219473

Epoch: 6| Step: 9
Training loss: 1.5063864333542134
Validation loss: 2.5532616398730648

Epoch: 6| Step: 10
Training loss: 1.0431149269563893
Validation loss: 2.531839364655227

Epoch: 6| Step: 11
Training loss: 0.6435863851749596
Validation loss: 2.5059110706338514

Epoch: 6| Step: 12
Training loss: 0.7893966873584612
Validation loss: 2.576768519135847

Epoch: 6| Step: 13
Training loss: 0.9341297606075454
Validation loss: 2.5230200190509775

Epoch: 292| Step: 0
Training loss: 1.0836756911096106
Validation loss: 2.5141103989074316

Epoch: 6| Step: 1
Training loss: 1.5839227365714075
Validation loss: 2.499664277946028

Epoch: 6| Step: 2
Training loss: 1.2279500220283504
Validation loss: 2.4423545421844346

Epoch: 6| Step: 3
Training loss: 0.988279139098073
Validation loss: 2.4318155497833303

Epoch: 6| Step: 4
Training loss: 1.409502548908312
Validation loss: 2.4152145050330556

Epoch: 6| Step: 5
Training loss: 0.993055969777647
Validation loss: 2.400656302291422

Epoch: 6| Step: 6
Training loss: 1.40893434118954
Validation loss: 2.37936287602767

Epoch: 6| Step: 7
Training loss: 1.2701138612063356
Validation loss: 2.4010684025869744

Epoch: 6| Step: 8
Training loss: 1.219909019048244
Validation loss: 2.461230763796243

Epoch: 6| Step: 9
Training loss: 1.232001908653812
Validation loss: 2.4895523514898423

Epoch: 6| Step: 10
Training loss: 0.8231596085116497
Validation loss: 2.4813232758625405

Epoch: 6| Step: 11
Training loss: 0.8269000080043596
Validation loss: 2.5125791198569347

Epoch: 6| Step: 12
Training loss: 1.2349569662990425
Validation loss: 2.472875764228647

Epoch: 6| Step: 13
Training loss: 0.46477631472453496
Validation loss: 2.5199255987396763

Epoch: 293| Step: 0
Training loss: 0.9177522444566399
Validation loss: 2.5018377522513005

Epoch: 6| Step: 1
Training loss: 1.4564191335274619
Validation loss: 2.5326862592694215

Epoch: 6| Step: 2
Training loss: 1.402867254020151
Validation loss: 2.5101619103231996

Epoch: 6| Step: 3
Training loss: 1.2003116163326508
Validation loss: 2.5206038383198766

Epoch: 6| Step: 4
Training loss: 0.5719067486564422
Validation loss: 2.4694388900288278

Epoch: 6| Step: 5
Training loss: 0.9894198165449726
Validation loss: 2.4797159132695685

Epoch: 6| Step: 6
Training loss: 1.270253841458154
Validation loss: 2.460250495561166

Epoch: 6| Step: 7
Training loss: 1.063873637239204
Validation loss: 2.5024734505103132

Epoch: 6| Step: 8
Training loss: 1.0033341495747166
Validation loss: 2.514351802015588

Epoch: 6| Step: 9
Training loss: 0.9692236450012665
Validation loss: 2.4761712631647423

Epoch: 6| Step: 10
Training loss: 1.1911266561659397
Validation loss: 2.5074809177237647

Epoch: 6| Step: 11
Training loss: 1.4573656777308603
Validation loss: 2.5138099056854633

Epoch: 6| Step: 12
Training loss: 1.0364638796455063
Validation loss: 2.483690112358613

Epoch: 6| Step: 13
Training loss: 1.255229596265245
Validation loss: 2.5531075222897073

Epoch: 294| Step: 0
Training loss: 0.7094882404167403
Validation loss: 2.547799966207056

Epoch: 6| Step: 1
Training loss: 0.7470524804474135
Validation loss: 2.5026593481962265

Epoch: 6| Step: 2
Training loss: 1.145413888396197
Validation loss: 2.5263462692791223

Epoch: 6| Step: 3
Training loss: 0.984874719601555
Validation loss: 2.481182268294385

Epoch: 6| Step: 4
Training loss: 0.7820864205425654
Validation loss: 2.525234586121228

Epoch: 6| Step: 5
Training loss: 1.1871927767418184
Validation loss: 2.54377704727021

Epoch: 6| Step: 6
Training loss: 1.7424082936875074
Validation loss: 2.4902379658154588

Epoch: 6| Step: 7
Training loss: 1.362664987916404
Validation loss: 2.507297840657234

Epoch: 6| Step: 8
Training loss: 1.2368338034362956
Validation loss: 2.4727127557847504

Epoch: 6| Step: 9
Training loss: 0.9445873032463885
Validation loss: 2.473232714072905

Epoch: 6| Step: 10
Training loss: 1.1118749469930755
Validation loss: 2.4987916179494905

Epoch: 6| Step: 11
Training loss: 1.2632696581740992
Validation loss: 2.5142822738160335

Epoch: 6| Step: 12
Training loss: 1.0839398349168667
Validation loss: 2.5475982488648494

Epoch: 6| Step: 13
Training loss: 0.8091651998075108
Validation loss: 2.5498865419611065

Epoch: 295| Step: 0
Training loss: 0.8835881294591147
Validation loss: 2.5825939675135667

Epoch: 6| Step: 1
Training loss: 0.6001817288957969
Validation loss: 2.5607454249181756

Epoch: 6| Step: 2
Training loss: 1.6517168303159073
Validation loss: 2.5686207575638322

Epoch: 6| Step: 3
Training loss: 0.6504110384650141
Validation loss: 2.5869600605049414

Epoch: 6| Step: 4
Training loss: 1.7048953593073517
Validation loss: 2.564009288244116

Epoch: 6| Step: 5
Training loss: 0.8925143496644715
Validation loss: 2.549625917446375

Epoch: 6| Step: 6
Training loss: 0.9817848035929774
Validation loss: 2.5675406432541226

Epoch: 6| Step: 7
Training loss: 0.8595320471402959
Validation loss: 2.5475871705163957

Epoch: 6| Step: 8
Training loss: 0.7309856116161255
Validation loss: 2.523219042328501

Epoch: 6| Step: 9
Training loss: 1.0395902283056995
Validation loss: 2.522167543937668

Epoch: 6| Step: 10
Training loss: 1.5059815195223825
Validation loss: 2.5105110650757076

Epoch: 6| Step: 11
Training loss: 1.0584018434792493
Validation loss: 2.507006153464539

Epoch: 6| Step: 12
Training loss: 1.19101991486895
Validation loss: 2.4508921332661626

Epoch: 6| Step: 13
Training loss: 0.9769720210673514
Validation loss: 2.4367691766074517

Epoch: 296| Step: 0
Training loss: 0.5703358580104048
Validation loss: 2.414637694778136

Epoch: 6| Step: 1
Training loss: 1.2120167014825112
Validation loss: 2.4139841174975034

Epoch: 6| Step: 2
Training loss: 1.0943132312712736
Validation loss: 2.4652985659800333

Epoch: 6| Step: 3
Training loss: 1.136591428986922
Validation loss: 2.470235987703971

Epoch: 6| Step: 4
Training loss: 1.4311427646760198
Validation loss: 2.5228866737406346

Epoch: 6| Step: 5
Training loss: 1.1219217784766742
Validation loss: 2.510185935384475

Epoch: 6| Step: 6
Training loss: 1.0045066848767898
Validation loss: 2.5379901680692356

Epoch: 6| Step: 7
Training loss: 0.923122144318892
Validation loss: 2.566607596883369

Epoch: 6| Step: 8
Training loss: 0.6847077801694299
Validation loss: 2.5611146988567497

Epoch: 6| Step: 9
Training loss: 1.0836024805884767
Validation loss: 2.604900135401935

Epoch: 6| Step: 10
Training loss: 1.2302163485858912
Validation loss: 2.5934397757419347

Epoch: 6| Step: 11
Training loss: 1.7324721749453407
Validation loss: 2.559058354539307

Epoch: 6| Step: 12
Training loss: 0.9477229322101635
Validation loss: 2.4774793027319957

Epoch: 6| Step: 13
Training loss: 0.9826336854153649
Validation loss: 2.475797859744294

Epoch: 297| Step: 0
Training loss: 1.4645955193321474
Validation loss: 2.420887406262617

Epoch: 6| Step: 1
Training loss: 1.4094996310528247
Validation loss: 2.450446231813633

Epoch: 6| Step: 2
Training loss: 1.1465292926677941
Validation loss: 2.4461254750041777

Epoch: 6| Step: 3
Training loss: 0.8808111613203966
Validation loss: 2.448514449509774

Epoch: 6| Step: 4
Training loss: 0.7736352995129726
Validation loss: 2.478192718643661

Epoch: 6| Step: 5
Training loss: 0.7166364942527467
Validation loss: 2.5056268844102405

Epoch: 6| Step: 6
Training loss: 0.8512657418384956
Validation loss: 2.494334495476356

Epoch: 6| Step: 7
Training loss: 1.079643727807813
Validation loss: 2.5019753619800915

Epoch: 6| Step: 8
Training loss: 0.9995116591162354
Validation loss: 2.528035200542052

Epoch: 6| Step: 9
Training loss: 0.9404208459171114
Validation loss: 2.5085386341106886

Epoch: 6| Step: 10
Training loss: 1.0253179615250834
Validation loss: 2.482634510698356

Epoch: 6| Step: 11
Training loss: 1.4248236798072345
Validation loss: 2.462956140910887

Epoch: 6| Step: 12
Training loss: 1.028483929346735
Validation loss: 2.5238256125207785

Epoch: 6| Step: 13
Training loss: 1.3018337264823263
Validation loss: 2.4853907519781515

Epoch: 298| Step: 0
Training loss: 0.9343781946440214
Validation loss: 2.5168380986824594

Epoch: 6| Step: 1
Training loss: 1.0476597364169944
Validation loss: 2.448154284678997

Epoch: 6| Step: 2
Training loss: 0.9863079408903214
Validation loss: 2.508111078730729

Epoch: 6| Step: 3
Training loss: 1.1395037640136578
Validation loss: 2.503131902281481

Epoch: 6| Step: 4
Training loss: 0.8697955803392879
Validation loss: 2.4828022453026994

Epoch: 6| Step: 5
Training loss: 1.5261559123563329
Validation loss: 2.506550153213029

Epoch: 6| Step: 6
Training loss: 1.1552242678112872
Validation loss: 2.5544141357411947

Epoch: 6| Step: 7
Training loss: 1.289124828334543
Validation loss: 2.5056756269635376

Epoch: 6| Step: 8
Training loss: 1.0221379306381637
Validation loss: 2.492910781589347

Epoch: 6| Step: 9
Training loss: 0.8641160406870211
Validation loss: 2.494184118741512

Epoch: 6| Step: 10
Training loss: 1.2825368141259408
Validation loss: 2.519813622889142

Epoch: 6| Step: 11
Training loss: 0.9561770617025441
Validation loss: 2.5133746841292863

Epoch: 6| Step: 12
Training loss: 0.8010041089589506
Validation loss: 2.5412419191360343

Epoch: 6| Step: 13
Training loss: 1.1253675813973818
Validation loss: 2.492451025367237

Epoch: 299| Step: 0
Training loss: 1.4444240829467239
Validation loss: 2.4699863044930677

Epoch: 6| Step: 1
Training loss: 1.1814338440101173
Validation loss: 2.457154934453168

Epoch: 6| Step: 2
Training loss: 0.8223699653008668
Validation loss: 2.5113822017354708

Epoch: 6| Step: 3
Training loss: 1.1785786450978415
Validation loss: 2.47205657107513

Epoch: 6| Step: 4
Training loss: 1.2170906997992306
Validation loss: 2.48128961686619

Epoch: 6| Step: 5
Training loss: 0.8271955636571424
Validation loss: 2.4907581166085566

Epoch: 6| Step: 6
Training loss: 0.74434620978525
Validation loss: 2.5193559640800456

Epoch: 6| Step: 7
Training loss: 0.9584635079471123
Validation loss: 2.5925339013597317

Epoch: 6| Step: 8
Training loss: 1.3049864740511143
Validation loss: 2.56369127075028

Epoch: 6| Step: 9
Training loss: 0.9428515597690074
Validation loss: 2.5524753670423186

Epoch: 6| Step: 10
Training loss: 1.0597795552323495
Validation loss: 2.5772791514369158

Epoch: 6| Step: 11
Training loss: 0.9609065787449937
Validation loss: 2.5363691575845078

Epoch: 6| Step: 12
Training loss: 1.1451352969863127
Validation loss: 2.548177163148098

Epoch: 6| Step: 13
Training loss: 0.8060078575186695
Validation loss: 2.4660230393939555

Epoch: 300| Step: 0
Training loss: 0.8985742216155626
Validation loss: 2.488038681100793

Epoch: 6| Step: 1
Training loss: 1.2851982689571269
Validation loss: 2.514943703140992

Epoch: 6| Step: 2
Training loss: 1.1381408604831793
Validation loss: 2.5362105241671076

Epoch: 6| Step: 3
Training loss: 1.051864406103957
Validation loss: 2.5118605346702445

Epoch: 6| Step: 4
Training loss: 1.358497292427114
Validation loss: 2.5244120710274665

Epoch: 6| Step: 5
Training loss: 0.9622169908375722
Validation loss: 2.5179281695685005

Epoch: 6| Step: 6
Training loss: 1.1000338289087532
Validation loss: 2.5439233617682113

Epoch: 6| Step: 7
Training loss: 0.7012587257087174
Validation loss: 2.513750293277004

Epoch: 6| Step: 8
Training loss: 0.9508766170371117
Validation loss: 2.5615372808952745

Epoch: 6| Step: 9
Training loss: 1.0638094294406062
Validation loss: 2.5503324374410234

Epoch: 6| Step: 10
Training loss: 0.9775460135320422
Validation loss: 2.5067509090443725

Epoch: 6| Step: 11
Training loss: 1.1060200317493343
Validation loss: 2.5101539022587773

Epoch: 6| Step: 12
Training loss: 0.7360647119937636
Validation loss: 2.514566349450301

Epoch: 6| Step: 13
Training loss: 1.4959117489860136
Validation loss: 2.540394666625271

Epoch: 301| Step: 0
Training loss: 1.1009254507314459
Validation loss: 2.490939447815609

Epoch: 6| Step: 1
Training loss: 0.9857529275489346
Validation loss: 2.534464304473545

Epoch: 6| Step: 2
Training loss: 0.9700013354380745
Validation loss: 2.5298981119564146

Epoch: 6| Step: 3
Training loss: 0.9184066052868862
Validation loss: 2.5547012238919278

Epoch: 6| Step: 4
Training loss: 0.6941365788759926
Validation loss: 2.5275589437537147

Epoch: 6| Step: 5
Training loss: 0.9990197682243375
Validation loss: 2.544171848870302

Epoch: 6| Step: 6
Training loss: 1.598955367724457
Validation loss: 2.5647473868520803

Epoch: 6| Step: 7
Training loss: 1.0246532877253587
Validation loss: 2.5127065110153044

Epoch: 6| Step: 8
Training loss: 0.9443861150182148
Validation loss: 2.564275333182158

Epoch: 6| Step: 9
Training loss: 0.9877189272832934
Validation loss: 2.5014929302766546

Epoch: 6| Step: 10
Training loss: 1.1640576356107728
Validation loss: 2.5331195341828274

Epoch: 6| Step: 11
Training loss: 0.9083795847768529
Validation loss: 2.5322049379278644

Epoch: 6| Step: 12
Training loss: 0.6702786043573665
Validation loss: 2.5618119535376827

Epoch: 6| Step: 13
Training loss: 0.9772880910367386
Validation loss: 2.52239368331548

Epoch: 302| Step: 0
Training loss: 1.1219991822435251
Validation loss: 2.517273902801636

Epoch: 6| Step: 1
Training loss: 0.8355623990150931
Validation loss: 2.5122949838088373

Epoch: 6| Step: 2
Training loss: 1.0751924852547128
Validation loss: 2.4789348985833546

Epoch: 6| Step: 3
Training loss: 1.4507154771298563
Validation loss: 2.463211986740791

Epoch: 6| Step: 4
Training loss: 1.0368640559229971
Validation loss: 2.5215817229317707

Epoch: 6| Step: 5
Training loss: 1.0550000328136275
Validation loss: 2.544623661207872

Epoch: 6| Step: 6
Training loss: 1.2294425924053245
Validation loss: 2.56382767692713

Epoch: 6| Step: 7
Training loss: 0.9914190665785124
Validation loss: 2.5575083434529233

Epoch: 6| Step: 8
Training loss: 0.8042021092986531
Validation loss: 2.5410625971147494

Epoch: 6| Step: 9
Training loss: 0.7127290307408797
Validation loss: 2.5802207167679896

Epoch: 6| Step: 10
Training loss: 0.7928635475766534
Validation loss: 2.5386380490667566

Epoch: 6| Step: 11
Training loss: 1.1074344694844342
Validation loss: 2.556543593218821

Epoch: 6| Step: 12
Training loss: 0.8094270623153927
Validation loss: 2.5541846194418647

Epoch: 6| Step: 13
Training loss: 0.8217884047110072
Validation loss: 2.5581888709674105

Epoch: 303| Step: 0
Training loss: 0.9524147639346683
Validation loss: 2.578302666044733

Epoch: 6| Step: 1
Training loss: 1.1168185605228345
Validation loss: 2.5444253353640782

Epoch: 6| Step: 2
Training loss: 0.8069424930300145
Validation loss: 2.5636615351651457

Epoch: 6| Step: 3
Training loss: 1.025267152164198
Validation loss: 2.5242743316535465

Epoch: 6| Step: 4
Training loss: 0.8262545857612444
Validation loss: 2.506702885913715

Epoch: 6| Step: 5
Training loss: 1.0075570899179707
Validation loss: 2.503343079937696

Epoch: 6| Step: 6
Training loss: 0.9844953675323348
Validation loss: 2.5219366380777783

Epoch: 6| Step: 7
Training loss: 0.9161825129698986
Validation loss: 2.5214462945255085

Epoch: 6| Step: 8
Training loss: 1.2972637191432241
Validation loss: 2.5638704769471974

Epoch: 6| Step: 9
Training loss: 1.1116529905020336
Validation loss: 2.4740108502982263

Epoch: 6| Step: 10
Training loss: 0.611620628896406
Validation loss: 2.4985217287129724

Epoch: 6| Step: 11
Training loss: 1.0492533526818075
Validation loss: 2.538918478188616

Epoch: 6| Step: 12
Training loss: 1.0927712011783137
Validation loss: 2.5176633264511405

Epoch: 6| Step: 13
Training loss: 1.2602495550341388
Validation loss: 2.513882185606502

Epoch: 304| Step: 0
Training loss: 1.202817258243163
Validation loss: 2.4745095855242316

Epoch: 6| Step: 1
Training loss: 0.8043913805641602
Validation loss: 2.495195622280245

Epoch: 6| Step: 2
Training loss: 0.8360627695502238
Validation loss: 2.565433582778697

Epoch: 6| Step: 3
Training loss: 0.7399803671938854
Validation loss: 2.546881240805876

Epoch: 6| Step: 4
Training loss: 0.6349095342804356
Validation loss: 2.5454186440944366

Epoch: 6| Step: 5
Training loss: 0.9033604628429281
Validation loss: 2.558661175850549

Epoch: 6| Step: 6
Training loss: 0.8406369743770609
Validation loss: 2.5505559173139516

Epoch: 6| Step: 7
Training loss: 0.6610840366689497
Validation loss: 2.566965168121152

Epoch: 6| Step: 8
Training loss: 1.3340760586287046
Validation loss: 2.552883734053612

Epoch: 6| Step: 9
Training loss: 1.2595477721637036
Validation loss: 2.517134946838736

Epoch: 6| Step: 10
Training loss: 1.0898626729217984
Validation loss: 2.589106446001011

Epoch: 6| Step: 11
Training loss: 1.0676603104871312
Validation loss: 2.4970967642385817

Epoch: 6| Step: 12
Training loss: 1.145052950438477
Validation loss: 2.563125638022649

Epoch: 6| Step: 13
Training loss: 1.362441845623957
Validation loss: 2.505020771770271

Epoch: 305| Step: 0
Training loss: 0.5825128802729592
Validation loss: 2.5377698683987955

Epoch: 6| Step: 1
Training loss: 0.9562054866827245
Validation loss: 2.5626775838613987

Epoch: 6| Step: 2
Training loss: 1.2842158903523375
Validation loss: 2.571884006495489

Epoch: 6| Step: 3
Training loss: 1.1529374484408923
Validation loss: 2.550522947827022

Epoch: 6| Step: 4
Training loss: 1.079143374914627
Validation loss: 2.5707340781812333

Epoch: 6| Step: 5
Training loss: 1.4654201339985806
Validation loss: 2.558616485657509

Epoch: 6| Step: 6
Training loss: 0.9853172334072775
Validation loss: 2.546724206408845

Epoch: 6| Step: 7
Training loss: 0.8346856271257886
Validation loss: 2.535644586351735

Epoch: 6| Step: 8
Training loss: 0.7820199986581156
Validation loss: 2.5010211807326783

Epoch: 6| Step: 9
Training loss: 0.8986160100979902
Validation loss: 2.5059847026657556

Epoch: 6| Step: 10
Training loss: 0.8207627287059798
Validation loss: 2.4562053779590785

Epoch: 6| Step: 11
Training loss: 0.8710025346151935
Validation loss: 2.5140491523761312

Epoch: 6| Step: 12
Training loss: 0.8001877236652367
Validation loss: 2.514552783733764

Epoch: 6| Step: 13
Training loss: 0.9830723271989213
Validation loss: 2.5324422423021278

Epoch: 306| Step: 0
Training loss: 0.9395223104336164
Validation loss: 2.535319562347353

Epoch: 6| Step: 1
Training loss: 1.3134109423954583
Validation loss: 2.5103165117178947

Epoch: 6| Step: 2
Training loss: 1.0355580251950334
Validation loss: 2.5149398713524396

Epoch: 6| Step: 3
Training loss: 0.593927306755626
Validation loss: 2.537325687504312

Epoch: 6| Step: 4
Training loss: 0.898626191600477
Validation loss: 2.5336530068691783

Epoch: 6| Step: 5
Training loss: 1.352501118812874
Validation loss: 2.5247442626672836

Epoch: 6| Step: 6
Training loss: 0.5716989986388888
Validation loss: 2.5239874879417603

Epoch: 6| Step: 7
Training loss: 1.1583311579475741
Validation loss: 2.4861624142536454

Epoch: 6| Step: 8
Training loss: 1.2522315133882227
Validation loss: 2.497235158780569

Epoch: 6| Step: 9
Training loss: 0.8820916330027846
Validation loss: 2.4525557699430482

Epoch: 6| Step: 10
Training loss: 0.7100127357361499
Validation loss: 2.5027803997910327

Epoch: 6| Step: 11
Training loss: 0.8101688836491218
Validation loss: 2.516489019020696

Epoch: 6| Step: 12
Training loss: 0.7005748491603497
Validation loss: 2.5286313276163246

Epoch: 6| Step: 13
Training loss: 0.8926615936851177
Validation loss: 2.5088104627906125

Epoch: 307| Step: 0
Training loss: 0.7504398724958569
Validation loss: 2.502589939226337

Epoch: 6| Step: 1
Training loss: 1.144755579084875
Validation loss: 2.5517689109186565

Epoch: 6| Step: 2
Training loss: 0.8628798712513193
Validation loss: 2.5532848306569345

Epoch: 6| Step: 3
Training loss: 1.142176891856892
Validation loss: 2.5589119526786397

Epoch: 6| Step: 4
Training loss: 0.8098338104409415
Validation loss: 2.561332096339237

Epoch: 6| Step: 5
Training loss: 0.9099794142354405
Validation loss: 2.557656770196658

Epoch: 6| Step: 6
Training loss: 1.0695904711871653
Validation loss: 2.5371238244979426

Epoch: 6| Step: 7
Training loss: 0.5234139849946291
Validation loss: 2.560786745249699

Epoch: 6| Step: 8
Training loss: 0.5808984370074831
Validation loss: 2.5365989558313795

Epoch: 6| Step: 9
Training loss: 0.8148650813030838
Validation loss: 2.548253870688177

Epoch: 6| Step: 10
Training loss: 1.037011323306027
Validation loss: 2.5401622980782532

Epoch: 6| Step: 11
Training loss: 1.3063766144346585
Validation loss: 2.5546373292953164

Epoch: 6| Step: 12
Training loss: 1.1201394302567615
Validation loss: 2.5361198028739103

Epoch: 6| Step: 13
Training loss: 0.8844081333275542
Validation loss: 2.535497703621886

Epoch: 308| Step: 0
Training loss: 1.1664514797304815
Validation loss: 2.5257589449459252

Epoch: 6| Step: 1
Training loss: 0.813307177801856
Validation loss: 2.5172913981681053

Epoch: 6| Step: 2
Training loss: 0.8770390321925574
Validation loss: 2.4604256473478188

Epoch: 6| Step: 3
Training loss: 0.8698521819544558
Validation loss: 2.470864136975645

Epoch: 6| Step: 4
Training loss: 1.3557890148144918
Validation loss: 2.4966249233440547

Epoch: 6| Step: 5
Training loss: 1.0987752728815936
Validation loss: 2.48698249038829

Epoch: 6| Step: 6
Training loss: 0.900700778460153
Validation loss: 2.491500402312431

Epoch: 6| Step: 7
Training loss: 0.6219895817997285
Validation loss: 2.4645761992403172

Epoch: 6| Step: 8
Training loss: 0.9983239731697452
Validation loss: 2.507398104254772

Epoch: 6| Step: 9
Training loss: 1.1805631911585595
Validation loss: 2.471596583095652

Epoch: 6| Step: 10
Training loss: 0.2706288917120722
Validation loss: 2.478647101263232

Epoch: 6| Step: 11
Training loss: 0.9304221320144801
Validation loss: 2.4873406490527787

Epoch: 6| Step: 12
Training loss: 1.0162623826289545
Validation loss: 2.4979261051158295

Epoch: 6| Step: 13
Training loss: 0.45470963650331453
Validation loss: 2.497496667244831

Epoch: 309| Step: 0
Training loss: 0.8479168750534614
Validation loss: 2.5389534587810605

Epoch: 6| Step: 1
Training loss: 0.9980098769763699
Validation loss: 2.5700437902335924

Epoch: 6| Step: 2
Training loss: 0.7467523434209179
Validation loss: 2.5395983311226273

Epoch: 6| Step: 3
Training loss: 1.0074023809540031
Validation loss: 2.6271418336455166

Epoch: 6| Step: 4
Training loss: 0.6026844362447865
Validation loss: 2.597245222756857

Epoch: 6| Step: 5
Training loss: 0.8608051191348799
Validation loss: 2.564877390431855

Epoch: 6| Step: 6
Training loss: 0.8938441407034411
Validation loss: 2.575622236746415

Epoch: 6| Step: 7
Training loss: 0.8893510507775684
Validation loss: 2.5334858354675687

Epoch: 6| Step: 8
Training loss: 0.6938792039650746
Validation loss: 2.55419434429364

Epoch: 6| Step: 9
Training loss: 0.8668405680841962
Validation loss: 2.50795728181014

Epoch: 6| Step: 10
Training loss: 0.8093170395648035
Validation loss: 2.4610759544457177

Epoch: 6| Step: 11
Training loss: 1.4545326388130437
Validation loss: 2.4977872305428814

Epoch: 6| Step: 12
Training loss: 1.0536853126047465
Validation loss: 2.4626074954937165

Epoch: 6| Step: 13
Training loss: 1.1638761537644693
Validation loss: 2.535439770493575

Epoch: 310| Step: 0
Training loss: 0.8545903612688233
Validation loss: 2.499985237488178

Epoch: 6| Step: 1
Training loss: 0.9472742453900608
Validation loss: 2.5167426666729

Epoch: 6| Step: 2
Training loss: 0.9300019830251902
Validation loss: 2.524962203572334

Epoch: 6| Step: 3
Training loss: 0.8177971923235104
Validation loss: 2.4989987901386628

Epoch: 6| Step: 4
Training loss: 0.9437726302307309
Validation loss: 2.544566757466875

Epoch: 6| Step: 5
Training loss: 1.1733027089973895
Validation loss: 2.606302169537741

Epoch: 6| Step: 6
Training loss: 0.6110008753225546
Validation loss: 2.5926761848192448

Epoch: 6| Step: 7
Training loss: 0.7114817872842829
Validation loss: 2.5769722776325437

Epoch: 6| Step: 8
Training loss: 1.0262221098628515
Validation loss: 2.533737350067961

Epoch: 6| Step: 9
Training loss: 1.1039718360072714
Validation loss: 2.5121362884815843

Epoch: 6| Step: 10
Training loss: 1.004730242684665
Validation loss: 2.5528158764285114

Epoch: 6| Step: 11
Training loss: 1.0991691399219405
Validation loss: 2.549160015151414

Epoch: 6| Step: 12
Training loss: 0.8252188955695398
Validation loss: 2.5129767886129746

Epoch: 6| Step: 13
Training loss: 0.5839277259117261
Validation loss: 2.5403289912687073

Epoch: 311| Step: 0
Training loss: 1.128658122213039
Validation loss: 2.490310308113868

Epoch: 6| Step: 1
Training loss: 1.1704114803327408
Validation loss: 2.552758117897277

Epoch: 6| Step: 2
Training loss: 1.119115592849685
Validation loss: 2.5370098862044212

Epoch: 6| Step: 3
Training loss: 0.7364769742154194
Validation loss: 2.5109669391998737

Epoch: 6| Step: 4
Training loss: 1.0488393204018702
Validation loss: 2.5805918089096886

Epoch: 6| Step: 5
Training loss: 0.4453984562416713
Validation loss: 2.519150650239826

Epoch: 6| Step: 6
Training loss: 0.7626239582049025
Validation loss: 2.526887315007782

Epoch: 6| Step: 7
Training loss: 0.558587881204146
Validation loss: 2.508341611810978

Epoch: 6| Step: 8
Training loss: 0.9683111488856324
Validation loss: 2.4769883906788936

Epoch: 6| Step: 9
Training loss: 0.728134914870967
Validation loss: 2.464206286344577

Epoch: 6| Step: 10
Training loss: 0.7276790202655127
Validation loss: 2.4558994072958544

Epoch: 6| Step: 11
Training loss: 0.9847942246759671
Validation loss: 2.465296227005146

Epoch: 6| Step: 12
Training loss: 1.2865238970936252
Validation loss: 2.4589268103760316

Epoch: 6| Step: 13
Training loss: 0.7569931162391421
Validation loss: 2.501119520902314

Epoch: 312| Step: 0
Training loss: 0.6498494230601981
Validation loss: 2.499832345611771

Epoch: 6| Step: 1
Training loss: 0.8658231363867883
Validation loss: 2.5287926475401457

Epoch: 6| Step: 2
Training loss: 1.073373191273117
Validation loss: 2.584689369588056

Epoch: 6| Step: 3
Training loss: 0.9702163488936016
Validation loss: 2.5681287441343614

Epoch: 6| Step: 4
Training loss: 0.6716949975835936
Validation loss: 2.564398123841401

Epoch: 6| Step: 5
Training loss: 0.9997077753336833
Validation loss: 2.5723048198351584

Epoch: 6| Step: 6
Training loss: 1.1035388505230106
Validation loss: 2.559911082896898

Epoch: 6| Step: 7
Training loss: 0.9508982427330681
Validation loss: 2.4742754166426377

Epoch: 6| Step: 8
Training loss: 0.6127680435278843
Validation loss: 2.5295487792542017

Epoch: 6| Step: 9
Training loss: 0.9877017889400764
Validation loss: 2.4898204288108454

Epoch: 6| Step: 10
Training loss: 0.8064761606064343
Validation loss: 2.4935571095540467

Epoch: 6| Step: 11
Training loss: 1.1663901591740085
Validation loss: 2.484864911855887

Epoch: 6| Step: 12
Training loss: 0.8636492812066727
Validation loss: 2.491546889015647

Epoch: 6| Step: 13
Training loss: 0.7115268151168802
Validation loss: 2.500490048278107

Epoch: 313| Step: 0
Training loss: 0.839796907759822
Validation loss: 2.4873763823096744

Epoch: 6| Step: 1
Training loss: 0.5452706919385844
Validation loss: 2.559817777960094

Epoch: 6| Step: 2
Training loss: 0.6944014763784535
Validation loss: 2.568119071050565

Epoch: 6| Step: 3
Training loss: 0.9781454455886558
Validation loss: 2.617046652028087

Epoch: 6| Step: 4
Training loss: 0.787526968842371
Validation loss: 2.611317771568166

Epoch: 6| Step: 5
Training loss: 1.1499020327427922
Validation loss: 2.597453242562335

Epoch: 6| Step: 6
Training loss: 1.1397962302747198
Validation loss: 2.6347599737797784

Epoch: 6| Step: 7
Training loss: 1.246320363070007
Validation loss: 2.59565184976728

Epoch: 6| Step: 8
Training loss: 0.5721694813448068
Validation loss: 2.597595444081005

Epoch: 6| Step: 9
Training loss: 0.9230008766442926
Validation loss: 2.5803502517413612

Epoch: 6| Step: 10
Training loss: 1.1088938677148736
Validation loss: 2.530075272615747

Epoch: 6| Step: 11
Training loss: 0.6738580227176076
Validation loss: 2.506714782097056

Epoch: 6| Step: 12
Training loss: 1.0002260548672315
Validation loss: 2.5002934406711477

Epoch: 6| Step: 13
Training loss: 0.6894548108131612
Validation loss: 2.453180853157755

Epoch: 314| Step: 0
Training loss: 1.2353632387355804
Validation loss: 2.447178394748222

Epoch: 6| Step: 1
Training loss: 0.7004475797525473
Validation loss: 2.4035300586449226

Epoch: 6| Step: 2
Training loss: 0.7963653879682803
Validation loss: 2.4091133050569353

Epoch: 6| Step: 3
Training loss: 0.9879261932063885
Validation loss: 2.430527277800044

Epoch: 6| Step: 4
Training loss: 0.7910148338031344
Validation loss: 2.4188321939408586

Epoch: 6| Step: 5
Training loss: 0.9115912131677343
Validation loss: 2.5142170094351863

Epoch: 6| Step: 6
Training loss: 0.7054570624818628
Validation loss: 2.4987669139255284

Epoch: 6| Step: 7
Training loss: 0.9176947001997223
Validation loss: 2.532155289147245

Epoch: 6| Step: 8
Training loss: 0.8631046166247123
Validation loss: 2.5862550192626004

Epoch: 6| Step: 9
Training loss: 0.9816219948922145
Validation loss: 2.571706762296015

Epoch: 6| Step: 10
Training loss: 0.9652485480941053
Validation loss: 2.633644048392918

Epoch: 6| Step: 11
Training loss: 0.9082179570781477
Validation loss: 2.622181177307604

Epoch: 6| Step: 12
Training loss: 0.9174622782091073
Validation loss: 2.6788649566463856

Epoch: 6| Step: 13
Training loss: 1.0195524717731155
Validation loss: 2.609891370150988

Epoch: 315| Step: 0
Training loss: 0.98412943607834
Validation loss: 2.5864614078599812

Epoch: 6| Step: 1
Training loss: 0.7631537980153158
Validation loss: 2.5922687910522733

Epoch: 6| Step: 2
Training loss: 0.8630309281404351
Validation loss: 2.5388484004446012

Epoch: 6| Step: 3
Training loss: 0.7687673892403738
Validation loss: 2.5348985710012872

Epoch: 6| Step: 4
Training loss: 0.8568600006237572
Validation loss: 2.487947635543793

Epoch: 6| Step: 5
Training loss: 1.3564456640343316
Validation loss: 2.4518649834729946

Epoch: 6| Step: 6
Training loss: 0.45178855926602274
Validation loss: 2.482000655738219

Epoch: 6| Step: 7
Training loss: 0.9211468164430887
Validation loss: 2.4877944438930397

Epoch: 6| Step: 8
Training loss: 0.6720984331371249
Validation loss: 2.4970351111820412

Epoch: 6| Step: 9
Training loss: 1.161417471447717
Validation loss: 2.5780367431251

Epoch: 6| Step: 10
Training loss: 0.6611177563889848
Validation loss: 2.5691235126154957

Epoch: 6| Step: 11
Training loss: 0.6728599558889474
Validation loss: 2.562424063088889

Epoch: 6| Step: 12
Training loss: 0.9620366207218857
Validation loss: 2.5744420454120682

Epoch: 6| Step: 13
Training loss: 1.161827348098219
Validation loss: 2.5743419008958575

Epoch: 316| Step: 0
Training loss: 1.114065436189482
Validation loss: 2.58573337819131

Epoch: 6| Step: 1
Training loss: 0.831469924057095
Validation loss: 2.6074907223175763

Epoch: 6| Step: 2
Training loss: 0.929955868494282
Validation loss: 2.5625035235653115

Epoch: 6| Step: 3
Training loss: 0.6298514661455877
Validation loss: 2.582244304770381

Epoch: 6| Step: 4
Training loss: 0.6068724573084073
Validation loss: 2.563899538676964

Epoch: 6| Step: 5
Training loss: 0.7350642439603653
Validation loss: 2.563072444785058

Epoch: 6| Step: 6
Training loss: 0.8423421204695722
Validation loss: 2.513205281002256

Epoch: 6| Step: 7
Training loss: 1.076797552705679
Validation loss: 2.5146588402801844

Epoch: 6| Step: 8
Training loss: 0.7513229702184343
Validation loss: 2.5135482738702404

Epoch: 6| Step: 9
Training loss: 1.1051575994517047
Validation loss: 2.476856156698558

Epoch: 6| Step: 10
Training loss: 0.9225651372227455
Validation loss: 2.4439092973547574

Epoch: 6| Step: 11
Training loss: 0.8914781466216267
Validation loss: 2.489821143387015

Epoch: 6| Step: 12
Training loss: 0.9829221630926481
Validation loss: 2.4843779110041746

Epoch: 6| Step: 13
Training loss: 0.6685108193825176
Validation loss: 2.5163546195632582

Epoch: 317| Step: 0
Training loss: 1.0626620000866798
Validation loss: 2.526565276921327

Epoch: 6| Step: 1
Training loss: 0.8312992224783389
Validation loss: 2.5994781369546986

Epoch: 6| Step: 2
Training loss: 1.3016656841578829
Validation loss: 2.5623529253435713

Epoch: 6| Step: 3
Training loss: 0.710375301540243
Validation loss: 2.5737806661942635

Epoch: 6| Step: 4
Training loss: 0.6379512489416647
Validation loss: 2.5767766793361297

Epoch: 6| Step: 5
Training loss: 0.65076639586643
Validation loss: 2.557875883270871

Epoch: 6| Step: 6
Training loss: 0.508110839064601
Validation loss: 2.5731043694626785

Epoch: 6| Step: 7
Training loss: 0.7863815009036844
Validation loss: 2.576379424085333

Epoch: 6| Step: 8
Training loss: 1.1124816700143239
Validation loss: 2.5725605139296857

Epoch: 6| Step: 9
Training loss: 1.0839127800469675
Validation loss: 2.5757784498988894

Epoch: 6| Step: 10
Training loss: 0.8171668639048272
Validation loss: 2.5432497816920328

Epoch: 6| Step: 11
Training loss: 0.96065262704509
Validation loss: 2.504355353036478

Epoch: 6| Step: 12
Training loss: 0.4677898268725335
Validation loss: 2.5172065706286144

Epoch: 6| Step: 13
Training loss: 0.785415189186818
Validation loss: 2.5155149514874586

Epoch: 318| Step: 0
Training loss: 1.0315805541188872
Validation loss: 2.5174068386708752

Epoch: 6| Step: 1
Training loss: 1.2229215194025322
Validation loss: 2.541745992707308

Epoch: 6| Step: 2
Training loss: 1.1882532641885468
Validation loss: 2.444945423847392

Epoch: 6| Step: 3
Training loss: 0.5370987769728568
Validation loss: 2.4655838291446894

Epoch: 6| Step: 4
Training loss: 1.087758410653397
Validation loss: 2.502509477851529

Epoch: 6| Step: 5
Training loss: 0.5930921272920125
Validation loss: 2.5446405282715268

Epoch: 6| Step: 6
Training loss: 0.8967479908295609
Validation loss: 2.539438019679385

Epoch: 6| Step: 7
Training loss: 0.8015611897656773
Validation loss: 2.573015719184311

Epoch: 6| Step: 8
Training loss: 0.20205971249605428
Validation loss: 2.588665740846186

Epoch: 6| Step: 9
Training loss: 0.8070522486566577
Validation loss: 2.56348484301658

Epoch: 6| Step: 10
Training loss: 0.739210643800465
Validation loss: 2.560407546073952

Epoch: 6| Step: 11
Training loss: 0.9070265829802446
Validation loss: 2.5774295290208227

Epoch: 6| Step: 12
Training loss: 0.6186534999002614
Validation loss: 2.5899731491384643

Epoch: 6| Step: 13
Training loss: 0.6861501576972818
Validation loss: 2.570140474922973

Epoch: 319| Step: 0
Training loss: 0.646888905988485
Validation loss: 2.5668960687980094

Epoch: 6| Step: 1
Training loss: 0.6978113298965805
Validation loss: 2.6077508222143955

Epoch: 6| Step: 2
Training loss: 0.8441604040000807
Validation loss: 2.583428438349972

Epoch: 6| Step: 3
Training loss: 0.5759022744677182
Validation loss: 2.610859298494721

Epoch: 6| Step: 4
Training loss: 0.7294061449162861
Validation loss: 2.593691178173878

Epoch: 6| Step: 5
Training loss: 0.7081917359435251
Validation loss: 2.6173991211267054

Epoch: 6| Step: 6
Training loss: 0.6600483461937082
Validation loss: 2.6098710123460624

Epoch: 6| Step: 7
Training loss: 1.2648442061613696
Validation loss: 2.5662655359382955

Epoch: 6| Step: 8
Training loss: 0.9442519867593085
Validation loss: 2.6155246301307584

Epoch: 6| Step: 9
Training loss: 0.7238176241101153
Validation loss: 2.531699980847563

Epoch: 6| Step: 10
Training loss: 0.8817217342063243
Validation loss: 2.5413308435327644

Epoch: 6| Step: 11
Training loss: 0.6577636428775233
Validation loss: 2.507644732045221

Epoch: 6| Step: 12
Training loss: 1.2672263011330638
Validation loss: 2.4969883488306186

Epoch: 6| Step: 13
Training loss: 0.8317482337118829
Validation loss: 2.5060209623855476

Epoch: 320| Step: 0
Training loss: 1.0327159403621542
Validation loss: 2.5355543897800095

Epoch: 6| Step: 1
Training loss: 0.5832202211341113
Validation loss: 2.4861631505044763

Epoch: 6| Step: 2
Training loss: 0.552682126005404
Validation loss: 2.5061626801781216

Epoch: 6| Step: 3
Training loss: 0.6155324788933201
Validation loss: 2.5505277589401074

Epoch: 6| Step: 4
Training loss: 0.883695481546317
Validation loss: 2.5422601165031784

Epoch: 6| Step: 5
Training loss: 0.9380739044872738
Validation loss: 2.5414506725305244

Epoch: 6| Step: 6
Training loss: 0.5502171163737826
Validation loss: 2.5443474242113715

Epoch: 6| Step: 7
Training loss: 0.8166821757290681
Validation loss: 2.6158651371978436

Epoch: 6| Step: 8
Training loss: 0.9010054667409665
Validation loss: 2.593291331919404

Epoch: 6| Step: 9
Training loss: 0.6529969012200055
Validation loss: 2.5811713891241745

Epoch: 6| Step: 10
Training loss: 0.5327208017773057
Validation loss: 2.5973473401528437

Epoch: 6| Step: 11
Training loss: 0.5904688270409305
Validation loss: 2.57219214715235

Epoch: 6| Step: 12
Training loss: 1.45064193064857
Validation loss: 2.6011757802646507

Epoch: 6| Step: 13
Training loss: 1.0627508428332912
Validation loss: 2.5885162438100155

Epoch: 321| Step: 0
Training loss: 0.46803448427138183
Validation loss: 2.5413575528282446

Epoch: 6| Step: 1
Training loss: 0.7710015439885137
Validation loss: 2.5277556395828067

Epoch: 6| Step: 2
Training loss: 0.7735381012812224
Validation loss: 2.512330412137204

Epoch: 6| Step: 3
Training loss: 0.9037932606390313
Validation loss: 2.4722881345414547

Epoch: 6| Step: 4
Training loss: 0.9526724444503998
Validation loss: 2.5347230981958346

Epoch: 6| Step: 5
Training loss: 0.9408448947627495
Validation loss: 2.5261988281507284

Epoch: 6| Step: 6
Training loss: 0.5501843186953523
Validation loss: 2.491886272569068

Epoch: 6| Step: 7
Training loss: 0.8788596585958085
Validation loss: 2.548660534195852

Epoch: 6| Step: 8
Training loss: 0.8915696070481745
Validation loss: 2.5487809168001396

Epoch: 6| Step: 9
Training loss: 0.556026829730863
Validation loss: 2.5705334793781187

Epoch: 6| Step: 10
Training loss: 1.012176174608064
Validation loss: 2.532173414185791

Epoch: 6| Step: 11
Training loss: 0.992574421088684
Validation loss: 2.5451504256046746

Epoch: 6| Step: 12
Training loss: 0.7670169555301896
Validation loss: 2.5508414238798305

Epoch: 6| Step: 13
Training loss: 0.8085842408436553
Validation loss: 2.5462514090121453

Epoch: 322| Step: 0
Training loss: 0.7814544410239128
Validation loss: 2.521832958372726

Epoch: 6| Step: 1
Training loss: 0.6735634546583747
Validation loss: 2.5423720823425984

Epoch: 6| Step: 2
Training loss: 0.7175306259823093
Validation loss: 2.554658384151872

Epoch: 6| Step: 3
Training loss: 0.6802632535073035
Validation loss: 2.5531647558035604

Epoch: 6| Step: 4
Training loss: 0.8964231050451676
Validation loss: 2.5956459375836705

Epoch: 6| Step: 5
Training loss: 0.8680349453492663
Validation loss: 2.61235034343425

Epoch: 6| Step: 6
Training loss: 0.5645108836892783
Validation loss: 2.581205109316122

Epoch: 6| Step: 7
Training loss: 0.5039373580438489
Validation loss: 2.5951529991915168

Epoch: 6| Step: 8
Training loss: 1.1720577860377215
Validation loss: 2.5541347088603024

Epoch: 6| Step: 9
Training loss: 0.8515097925515703
Validation loss: 2.546098449924411

Epoch: 6| Step: 10
Training loss: 1.0483624722828528
Validation loss: 2.5122243348488627

Epoch: 6| Step: 11
Training loss: 0.7320541883068594
Validation loss: 2.5007238775702807

Epoch: 6| Step: 12
Training loss: 0.7934695762229441
Validation loss: 2.495330163274419

Epoch: 6| Step: 13
Training loss: 0.6568059156114855
Validation loss: 2.5557817760542774

Epoch: 323| Step: 0
Training loss: 0.8580252017163572
Validation loss: 2.5049251054930073

Epoch: 6| Step: 1
Training loss: 0.9080687720894576
Validation loss: 2.481784736630425

Epoch: 6| Step: 2
Training loss: 0.8136545194989918
Validation loss: 2.4716509940707683

Epoch: 6| Step: 3
Training loss: 0.8737380259707089
Validation loss: 2.4807785562887905

Epoch: 6| Step: 4
Training loss: 0.9426630265675056
Validation loss: 2.4688471947246318

Epoch: 6| Step: 5
Training loss: 0.5320396445084037
Validation loss: 2.5261154409295385

Epoch: 6| Step: 6
Training loss: 0.7173428236370216
Validation loss: 2.521981829835915

Epoch: 6| Step: 7
Training loss: 0.5360274914961295
Validation loss: 2.5929009656189224

Epoch: 6| Step: 8
Training loss: 0.8975479366071154
Validation loss: 2.5781453439774342

Epoch: 6| Step: 9
Training loss: 0.8253390756912116
Validation loss: 2.6218450927436656

Epoch: 6| Step: 10
Training loss: 0.895819989186342
Validation loss: 2.6074279187786744

Epoch: 6| Step: 11
Training loss: 0.9390565983083807
Validation loss: 2.5861519141995104

Epoch: 6| Step: 12
Training loss: 0.6401034069341295
Validation loss: 2.572482060697821

Epoch: 6| Step: 13
Training loss: 0.7918501984190556
Validation loss: 2.5687383953419487

Epoch: 324| Step: 0
Training loss: 1.0091051195582774
Validation loss: 2.533958024602506

Epoch: 6| Step: 1
Training loss: 1.000977157964762
Validation loss: 2.535475948204674

Epoch: 6| Step: 2
Training loss: 0.7716186406602551
Validation loss: 2.5123629420028335

Epoch: 6| Step: 3
Training loss: 1.0086916851597663
Validation loss: 2.571118292292231

Epoch: 6| Step: 4
Training loss: 0.871161625018169
Validation loss: 2.568470171169927

Epoch: 6| Step: 5
Training loss: 0.5414671132940361
Validation loss: 2.5435830094843546

Epoch: 6| Step: 6
Training loss: 0.4652532809089041
Validation loss: 2.5442779705828196

Epoch: 6| Step: 7
Training loss: 0.5297342442954912
Validation loss: 2.52560597298863

Epoch: 6| Step: 8
Training loss: 0.6583955749431384
Validation loss: 2.514864125306992

Epoch: 6| Step: 9
Training loss: 1.0146357486875024
Validation loss: 2.5319095290656533

Epoch: 6| Step: 10
Training loss: 0.5448066562270475
Validation loss: 2.4779815916926364

Epoch: 6| Step: 11
Training loss: 1.1663396694959374
Validation loss: 2.485998365119985

Epoch: 6| Step: 12
Training loss: 0.9079495311797822
Validation loss: 2.5052884494783947

Epoch: 6| Step: 13
Training loss: 0.3030052695807571
Validation loss: 2.476230945276039

Epoch: 325| Step: 0
Training loss: 0.831606581937661
Validation loss: 2.482027167889307

Epoch: 6| Step: 1
Training loss: 0.5582384967208147
Validation loss: 2.555358561754883

Epoch: 6| Step: 2
Training loss: 1.025419572694069
Validation loss: 2.558126454474468

Epoch: 6| Step: 3
Training loss: 0.40379606548095776
Validation loss: 2.5408573412046933

Epoch: 6| Step: 4
Training loss: 0.8288387965046509
Validation loss: 2.5701628251588895

Epoch: 6| Step: 5
Training loss: 0.7517223846341334
Validation loss: 2.5501654813131753

Epoch: 6| Step: 6
Training loss: 0.7930653330045611
Validation loss: 2.5368320085142306

Epoch: 6| Step: 7
Training loss: 0.5073332358945852
Validation loss: 2.572609560807812

Epoch: 6| Step: 8
Training loss: 0.8607431098823981
Validation loss: 2.5522446016175264

Epoch: 6| Step: 9
Training loss: 0.8659225723593369
Validation loss: 2.5402376762990198

Epoch: 6| Step: 10
Training loss: 0.5481305287603189
Validation loss: 2.5421612172854626

Epoch: 6| Step: 11
Training loss: 1.0276992820858246
Validation loss: 2.564793483537212

Epoch: 6| Step: 12
Training loss: 0.5124303805353012
Validation loss: 2.5289251036155043

Epoch: 6| Step: 13
Training loss: 1.1272134728079346
Validation loss: 2.5087643608656167

Epoch: 326| Step: 0
Training loss: 0.5050078187469422
Validation loss: 2.4466230192382126

Epoch: 6| Step: 1
Training loss: 0.621612619994352
Validation loss: 2.5040613748091

Epoch: 6| Step: 2
Training loss: 0.7090279221625393
Validation loss: 2.457910698138688

Epoch: 6| Step: 3
Training loss: 0.35274575638601
Validation loss: 2.491659686585374

Epoch: 6| Step: 4
Training loss: 0.9039510968028479
Validation loss: 2.5345401222205024

Epoch: 6| Step: 5
Training loss: 0.7545200675535432
Validation loss: 2.518119466460325

Epoch: 6| Step: 6
Training loss: 0.6604850221230826
Validation loss: 2.5231531515648133

Epoch: 6| Step: 7
Training loss: 1.0362832897623242
Validation loss: 2.519321248157498

Epoch: 6| Step: 8
Training loss: 0.6023855647553656
Validation loss: 2.5437222208783576

Epoch: 6| Step: 9
Training loss: 1.074304251302563
Validation loss: 2.533184746733227

Epoch: 6| Step: 10
Training loss: 0.9225248212498911
Validation loss: 2.522816097830353

Epoch: 6| Step: 11
Training loss: 0.7865603972305726
Validation loss: 2.5389493204264673

Epoch: 6| Step: 12
Training loss: 0.762289566957373
Validation loss: 2.5273385549413505

Epoch: 6| Step: 13
Training loss: 0.7472408723296038
Validation loss: 2.5428462452575062

Epoch: 327| Step: 0
Training loss: 0.7142158210141869
Validation loss: 2.5165225729396843

Epoch: 6| Step: 1
Training loss: 0.8248166631957898
Validation loss: 2.512626243002837

Epoch: 6| Step: 2
Training loss: 0.8508706738544279
Validation loss: 2.511313564687389

Epoch: 6| Step: 3
Training loss: 0.3814251927129965
Validation loss: 2.4936073978161883

Epoch: 6| Step: 4
Training loss: 0.890531233820768
Validation loss: 2.506587543598062

Epoch: 6| Step: 5
Training loss: 0.5062273962367031
Validation loss: 2.47099887138639

Epoch: 6| Step: 6
Training loss: 0.7230205133332339
Validation loss: 2.5155739992760684

Epoch: 6| Step: 7
Training loss: 0.6207638230123245
Validation loss: 2.5545877175828022

Epoch: 6| Step: 8
Training loss: 0.8828405865277735
Validation loss: 2.5997187353056104

Epoch: 6| Step: 9
Training loss: 0.986962233560021
Validation loss: 2.6014040183917926

Epoch: 6| Step: 10
Training loss: 0.9246902475577295
Validation loss: 2.599741886395917

Epoch: 6| Step: 11
Training loss: 0.8181521351323473
Validation loss: 2.5894968264513794

Epoch: 6| Step: 12
Training loss: 0.9201247847973604
Validation loss: 2.5972522644436955

Epoch: 6| Step: 13
Training loss: 0.3247294826920042
Validation loss: 2.582647843634213

Epoch: 328| Step: 0
Training loss: 0.6701696176901147
Validation loss: 2.5923396671002403

Epoch: 6| Step: 1
Training loss: 1.1670471433843586
Validation loss: 2.5368905379024533

Epoch: 6| Step: 2
Training loss: 0.6465993358357326
Validation loss: 2.4867792623967113

Epoch: 6| Step: 3
Training loss: 0.9013103826773194
Validation loss: 2.5240644014487437

Epoch: 6| Step: 4
Training loss: 0.8193634355952516
Validation loss: 2.5087863351441304

Epoch: 6| Step: 5
Training loss: 0.8358467979779197
Validation loss: 2.5571873134407905

Epoch: 6| Step: 6
Training loss: 1.017643492607138
Validation loss: 2.5913341621765826

Epoch: 6| Step: 7
Training loss: 0.8811681506516792
Validation loss: 2.612147946528251

Epoch: 6| Step: 8
Training loss: 0.6680005160803715
Validation loss: 2.5374980984497864

Epoch: 6| Step: 9
Training loss: 0.9191285942772062
Validation loss: 2.5369486081742445

Epoch: 6| Step: 10
Training loss: 0.6853798339439515
Validation loss: 2.5069641123720636

Epoch: 6| Step: 11
Training loss: 0.7286866833513505
Validation loss: 2.4623768118675997

Epoch: 6| Step: 12
Training loss: 0.912407575133175
Validation loss: 2.43786385704623

Epoch: 6| Step: 13
Training loss: 0.9599322511688554
Validation loss: 2.3774878743428807

Epoch: 329| Step: 0
Training loss: 0.678600779863028
Validation loss: 2.339826449684419

Epoch: 6| Step: 1
Training loss: 0.8794152714360888
Validation loss: 2.3935375044230645

Epoch: 6| Step: 2
Training loss: 1.068168720759036
Validation loss: 2.379837556198354

Epoch: 6| Step: 3
Training loss: 1.1927559633475728
Validation loss: 2.4545000250146316

Epoch: 6| Step: 4
Training loss: 0.8399680821848861
Validation loss: 2.4918730710340955

Epoch: 6| Step: 5
Training loss: 0.7989782364880734
Validation loss: 2.509177338640704

Epoch: 6| Step: 6
Training loss: 0.5948402283636669
Validation loss: 2.5819190618418135

Epoch: 6| Step: 7
Training loss: 0.8081135083861786
Validation loss: 2.656899478851779

Epoch: 6| Step: 8
Training loss: 0.8725911771030539
Validation loss: 2.631258356641657

Epoch: 6| Step: 9
Training loss: 0.655719951739617
Validation loss: 2.6775516831153108

Epoch: 6| Step: 10
Training loss: 0.980925373878644
Validation loss: 2.6241903702094658

Epoch: 6| Step: 11
Training loss: 0.6876184188120082
Validation loss: 2.5595055849141044

Epoch: 6| Step: 12
Training loss: 0.8341223359181904
Validation loss: 2.5431287814165464

Epoch: 6| Step: 13
Training loss: 0.7603897629947258
Validation loss: 2.5231853859384596

Epoch: 330| Step: 0
Training loss: 0.8561079171908001
Validation loss: 2.5646874520259897

Epoch: 6| Step: 1
Training loss: 0.9379015380529516
Validation loss: 2.547697601655459

Epoch: 6| Step: 2
Training loss: 0.9903960387558979
Validation loss: 2.5450051859522316

Epoch: 6| Step: 3
Training loss: 1.096149754741822
Validation loss: 2.5162742397072293

Epoch: 6| Step: 4
Training loss: 0.7603929376601298
Validation loss: 2.515713932108927

Epoch: 6| Step: 5
Training loss: 0.899051357037145
Validation loss: 2.547509114543198

Epoch: 6| Step: 6
Training loss: 0.8396149079575415
Validation loss: 2.5210255582032377

Epoch: 6| Step: 7
Training loss: 0.5323836628445751
Validation loss: 2.5669585646760034

Epoch: 6| Step: 8
Training loss: 0.8365482701604318
Validation loss: 2.583802491879273

Epoch: 6| Step: 9
Training loss: 0.7955620364846282
Validation loss: 2.6017133728207593

Epoch: 6| Step: 10
Training loss: 0.760890177483089
Validation loss: 2.594391066667812

Epoch: 6| Step: 11
Training loss: 0.933803774141915
Validation loss: 2.6103463853257045

Epoch: 6| Step: 12
Training loss: 0.3276047442279004
Validation loss: 2.612072430769347

Epoch: 6| Step: 13
Training loss: 0.27026429215026637
Validation loss: 2.605577630208843

Epoch: 331| Step: 0
Training loss: 0.6218997116546404
Validation loss: 2.590393927568037

Epoch: 6| Step: 1
Training loss: 0.8550737418336436
Validation loss: 2.6068559787820305

Epoch: 6| Step: 2
Training loss: 0.9366557452446402
Validation loss: 2.6300578623912965

Epoch: 6| Step: 3
Training loss: 0.7962802088350311
Validation loss: 2.5795119516576954

Epoch: 6| Step: 4
Training loss: 0.5175747853297324
Validation loss: 2.571761742718457

Epoch: 6| Step: 5
Training loss: 0.7806244825570657
Validation loss: 2.518949476635475

Epoch: 6| Step: 6
Training loss: 0.6568872672767558
Validation loss: 2.5057664713851

Epoch: 6| Step: 7
Training loss: 0.5001241112691376
Validation loss: 2.5227110498479886

Epoch: 6| Step: 8
Training loss: 0.9666645306256689
Validation loss: 2.5354799001181685

Epoch: 6| Step: 9
Training loss: 0.8334797174312052
Validation loss: 2.4925250488530675

Epoch: 6| Step: 10
Training loss: 0.7591718299877173
Validation loss: 2.489030167377036

Epoch: 6| Step: 11
Training loss: 0.7249873735709546
Validation loss: 2.4887569523525404

Epoch: 6| Step: 12
Training loss: 0.4688361247733684
Validation loss: 2.4865103633412398

Epoch: 6| Step: 13
Training loss: 1.1409107007212544
Validation loss: 2.4731394462450975

Epoch: 332| Step: 0
Training loss: 0.719039029596707
Validation loss: 2.488112586511611

Epoch: 6| Step: 1
Training loss: 0.6086154263006474
Validation loss: 2.502279346948095

Epoch: 6| Step: 2
Training loss: 0.5544627365562783
Validation loss: 2.57369573671114

Epoch: 6| Step: 3
Training loss: 0.7451234669751986
Validation loss: 2.528367091060532

Epoch: 6| Step: 4
Training loss: 0.6186564866117698
Validation loss: 2.5565710761537606

Epoch: 6| Step: 5
Training loss: 0.8067032833563588
Validation loss: 2.6078197611196723

Epoch: 6| Step: 6
Training loss: 0.6876309226827602
Validation loss: 2.653567996217872

Epoch: 6| Step: 7
Training loss: 0.741529152655289
Validation loss: 2.6237241786378425

Epoch: 6| Step: 8
Training loss: 0.9682276147943173
Validation loss: 2.6253811002435454

Epoch: 6| Step: 9
Training loss: 0.8401045283493963
Validation loss: 2.6120363511250146

Epoch: 6| Step: 10
Training loss: 0.8449518333340676
Validation loss: 2.5898928397806067

Epoch: 6| Step: 11
Training loss: 0.9232339379684688
Validation loss: 2.5313580519182826

Epoch: 6| Step: 12
Training loss: 0.5991932173440555
Validation loss: 2.542825109734374

Epoch: 6| Step: 13
Training loss: 0.6978619587270934
Validation loss: 2.5317112056742253

Epoch: 333| Step: 0
Training loss: 0.5936720194554747
Validation loss: 2.5198941167169275

Epoch: 6| Step: 1
Training loss: 0.512529124618672
Validation loss: 2.4956170269614946

Epoch: 6| Step: 2
Training loss: 0.5577162405780393
Validation loss: 2.5556627534265832

Epoch: 6| Step: 3
Training loss: 0.5075964835018822
Validation loss: 2.552694199771425

Epoch: 6| Step: 4
Training loss: 0.8898773066462262
Validation loss: 2.5775792861573885

Epoch: 6| Step: 5
Training loss: 0.8217851771017028
Validation loss: 2.5854159133586254

Epoch: 6| Step: 6
Training loss: 0.5746402102040853
Validation loss: 2.5781824547414867

Epoch: 6| Step: 7
Training loss: 0.5887988099844196
Validation loss: 2.591958270823479

Epoch: 6| Step: 8
Training loss: 0.9599198325778024
Validation loss: 2.576974937300155

Epoch: 6| Step: 9
Training loss: 0.6285088035540498
Validation loss: 2.5923448985309245

Epoch: 6| Step: 10
Training loss: 0.84866146833811
Validation loss: 2.633387136811844

Epoch: 6| Step: 11
Training loss: 0.6473705061737967
Validation loss: 2.6199148392115017

Epoch: 6| Step: 12
Training loss: 0.9526527673258166
Validation loss: 2.6117706128869527

Epoch: 6| Step: 13
Training loss: 0.783842439447591
Validation loss: 2.5757396104937484

Epoch: 334| Step: 0
Training loss: 0.6112159406694065
Validation loss: 2.590686042512086

Epoch: 6| Step: 1
Training loss: 0.7701956886723577
Validation loss: 2.557528067557595

Epoch: 6| Step: 2
Training loss: 0.6325700554480832
Validation loss: 2.528289617924557

Epoch: 6| Step: 3
Training loss: 0.7858907575718868
Validation loss: 2.552467103037279

Epoch: 6| Step: 4
Training loss: 0.7493851843771024
Validation loss: 2.5304881906357983

Epoch: 6| Step: 5
Training loss: 0.5428175681431572
Validation loss: 2.552164937251408

Epoch: 6| Step: 6
Training loss: 0.6698464220446181
Validation loss: 2.577200435993012

Epoch: 6| Step: 7
Training loss: 0.8127094145644355
Validation loss: 2.5662787024233786

Epoch: 6| Step: 8
Training loss: 0.672619695257236
Validation loss: 2.5361954432620273

Epoch: 6| Step: 9
Training loss: 0.6227219071944965
Validation loss: 2.5360157093100986

Epoch: 6| Step: 10
Training loss: 0.4403276684803588
Validation loss: 2.548646084722637

Epoch: 6| Step: 11
Training loss: 0.6775246551292647
Validation loss: 2.5300404970688564

Epoch: 6| Step: 12
Training loss: 0.7874886330283728
Validation loss: 2.5149319121411744

Epoch: 6| Step: 13
Training loss: 1.1396134999598642
Validation loss: 2.544218749614681

Epoch: 335| Step: 0
Training loss: 0.734961012111136
Validation loss: 2.5186671671774725

Epoch: 6| Step: 1
Training loss: 0.6740628704340611
Validation loss: 2.540581337478499

Epoch: 6| Step: 2
Training loss: 0.9054305548260337
Validation loss: 2.53593843749051

Epoch: 6| Step: 3
Training loss: 0.5765922176900389
Validation loss: 2.547905657089639

Epoch: 6| Step: 4
Training loss: 0.5436069388021821
Validation loss: 2.540236684242544

Epoch: 6| Step: 5
Training loss: 0.7470806445236314
Validation loss: 2.5385590478693376

Epoch: 6| Step: 6
Training loss: 0.7220212053476543
Validation loss: 2.5286274750017776

Epoch: 6| Step: 7
Training loss: 0.6723192653501792
Validation loss: 2.578540445727755

Epoch: 6| Step: 8
Training loss: 0.640582153003939
Validation loss: 2.566211875819071

Epoch: 6| Step: 9
Training loss: 0.5925436312871338
Validation loss: 2.5781936362916444

Epoch: 6| Step: 10
Training loss: 0.6006042229574761
Validation loss: 2.6149207544872923

Epoch: 6| Step: 11
Training loss: 0.7231813739506926
Validation loss: 2.6265909810444956

Epoch: 6| Step: 12
Training loss: 0.9016341023960754
Validation loss: 2.6151409887152623

Epoch: 6| Step: 13
Training loss: 0.6303074078408557
Validation loss: 2.611926382720293

Epoch: 336| Step: 0
Training loss: 0.6345653981082788
Validation loss: 2.636337143519977

Epoch: 6| Step: 1
Training loss: 0.5996726434486483
Validation loss: 2.550321862020804

Epoch: 6| Step: 2
Training loss: 0.6426755605180492
Validation loss: 2.520612785504

Epoch: 6| Step: 3
Training loss: 0.7599245900462198
Validation loss: 2.5294967021930654

Epoch: 6| Step: 4
Training loss: 0.7216151806156509
Validation loss: 2.541685631484743

Epoch: 6| Step: 5
Training loss: 0.5893620425081285
Validation loss: 2.5160980136585374

Epoch: 6| Step: 6
Training loss: 0.95541831356749
Validation loss: 2.530862942454542

Epoch: 6| Step: 7
Training loss: 0.4991857783453967
Validation loss: 2.5042435767248685

Epoch: 6| Step: 8
Training loss: 0.5346785313507884
Validation loss: 2.5486510487520846

Epoch: 6| Step: 9
Training loss: 0.6037913806626702
Validation loss: 2.5649468949591974

Epoch: 6| Step: 10
Training loss: 0.40164586994075935
Validation loss: 2.562954352391809

Epoch: 6| Step: 11
Training loss: 0.695794677707605
Validation loss: 2.541065369529971

Epoch: 6| Step: 12
Training loss: 0.9462290962359362
Validation loss: 2.570905710539325

Epoch: 6| Step: 13
Training loss: 0.7710060278437946
Validation loss: 2.5402646140669534

Epoch: 337| Step: 0
Training loss: 0.9717452904106467
Validation loss: 2.5702288104357414

Epoch: 6| Step: 1
Training loss: 0.48574156414094755
Validation loss: 2.558217925589492

Epoch: 6| Step: 2
Training loss: 0.5962832518368492
Validation loss: 2.534654447404533

Epoch: 6| Step: 3
Training loss: 0.7437978841289429
Validation loss: 2.541607202620713

Epoch: 6| Step: 4
Training loss: 0.49646393788650994
Validation loss: 2.5772594939390387

Epoch: 6| Step: 5
Training loss: 0.893243253872986
Validation loss: 2.546796207503897

Epoch: 6| Step: 6
Training loss: 0.6607537810108832
Validation loss: 2.5247392815879204

Epoch: 6| Step: 7
Training loss: 0.6467224558585606
Validation loss: 2.557476573260978

Epoch: 6| Step: 8
Training loss: 0.7950092614432156
Validation loss: 2.5235964360155085

Epoch: 6| Step: 9
Training loss: 0.6162880246267981
Validation loss: 2.5535249915356997

Epoch: 6| Step: 10
Training loss: 0.5753512729672795
Validation loss: 2.5789413019975598

Epoch: 6| Step: 11
Training loss: 0.5364654009702218
Validation loss: 2.555712189792666

Epoch: 6| Step: 12
Training loss: 0.6586958854641763
Validation loss: 2.5282593934698663

Epoch: 6| Step: 13
Training loss: 0.5101748464562716
Validation loss: 2.556912531018787

Epoch: 338| Step: 0
Training loss: 0.4004943713246261
Validation loss: 2.5686665162647153

Epoch: 6| Step: 1
Training loss: 0.8502982317629197
Validation loss: 2.6331952384242596

Epoch: 6| Step: 2
Training loss: 0.525459568647879
Validation loss: 2.599661366021309

Epoch: 6| Step: 3
Training loss: 0.39846354754706614
Validation loss: 2.6087788478111404

Epoch: 6| Step: 4
Training loss: 0.6431445144569445
Validation loss: 2.5810236392138046

Epoch: 6| Step: 5
Training loss: 0.6395208100399483
Validation loss: 2.6041409789428425

Epoch: 6| Step: 6
Training loss: 0.6065564383941384
Validation loss: 2.617571822826278

Epoch: 6| Step: 7
Training loss: 0.765352901453091
Validation loss: 2.584576698198915

Epoch: 6| Step: 8
Training loss: 0.5833414423469768
Validation loss: 2.5475854527592605

Epoch: 6| Step: 9
Training loss: 0.8807859538197848
Validation loss: 2.546716634433254

Epoch: 6| Step: 10
Training loss: 0.5878009410899943
Validation loss: 2.5256208709747114

Epoch: 6| Step: 11
Training loss: 0.7331510449114109
Validation loss: 2.5608638669429156

Epoch: 6| Step: 12
Training loss: 0.8675097992093479
Validation loss: 2.533273056324595

Epoch: 6| Step: 13
Training loss: 0.9436420151529079
Validation loss: 2.5327721934310397

Epoch: 339| Step: 0
Training loss: 0.6108792884587145
Validation loss: 2.5351766728349747

Epoch: 6| Step: 1
Training loss: 0.6526241956003342
Validation loss: 2.540986436232923

Epoch: 6| Step: 2
Training loss: 0.4861800952812876
Validation loss: 2.506358445856529

Epoch: 6| Step: 3
Training loss: 0.862696592067869
Validation loss: 2.4891468691299052

Epoch: 6| Step: 4
Training loss: 0.7423168671946747
Validation loss: 2.4852325265892286

Epoch: 6| Step: 5
Training loss: 0.9802894580335327
Validation loss: 2.4846777075955644

Epoch: 6| Step: 6
Training loss: 0.6939961263152746
Validation loss: 2.421398030926686

Epoch: 6| Step: 7
Training loss: 0.8110646260308557
Validation loss: 2.4964207704887773

Epoch: 6| Step: 8
Training loss: 0.7607223253509681
Validation loss: 2.5230171170677154

Epoch: 6| Step: 9
Training loss: 0.566333213569639
Validation loss: 2.5597349626296495

Epoch: 6| Step: 10
Training loss: 0.5363233328519749
Validation loss: 2.5594718703120978

Epoch: 6| Step: 11
Training loss: 0.6313958735983363
Validation loss: 2.56400967118902

Epoch: 6| Step: 12
Training loss: 0.6468754763762705
Validation loss: 2.568099142785886

Epoch: 6| Step: 13
Training loss: 0.651051068555973
Validation loss: 2.580951805284042

Epoch: 340| Step: 0
Training loss: 0.8785151310737412
Validation loss: 2.624847440881428

Epoch: 6| Step: 1
Training loss: 0.6625901898586791
Validation loss: 2.604515387700386

Epoch: 6| Step: 2
Training loss: 0.7288503823739322
Validation loss: 2.619284036292593

Epoch: 6| Step: 3
Training loss: 0.5112304978976383
Validation loss: 2.6159438916632043

Epoch: 6| Step: 4
Training loss: 0.6791236336264441
Validation loss: 2.5928209303588354

Epoch: 6| Step: 5
Training loss: 0.7165581412168242
Validation loss: 2.55331667107832

Epoch: 6| Step: 6
Training loss: 0.5183734181851182
Validation loss: 2.5790241388859263

Epoch: 6| Step: 7
Training loss: 0.5300597995185048
Validation loss: 2.5629720045564968

Epoch: 6| Step: 8
Training loss: 0.38722369433575776
Validation loss: 2.579688263063563

Epoch: 6| Step: 9
Training loss: 0.6710902221729069
Validation loss: 2.53831756997785

Epoch: 6| Step: 10
Training loss: 0.48834273904827713
Validation loss: 2.5967354581462656

Epoch: 6| Step: 11
Training loss: 0.6216338586289184
Validation loss: 2.5603011506875246

Epoch: 6| Step: 12
Training loss: 0.9761487465782659
Validation loss: 2.583127296069818

Epoch: 6| Step: 13
Training loss: 0.701813364524217
Validation loss: 2.571398832659

Epoch: 341| Step: 0
Training loss: 0.7051102269015976
Validation loss: 2.55990168220365

Epoch: 6| Step: 1
Training loss: 0.2986504020026564
Validation loss: 2.5330927868563626

Epoch: 6| Step: 2
Training loss: 0.6355501227597732
Validation loss: 2.514954092467542

Epoch: 6| Step: 3
Training loss: 0.6030792337555612
Validation loss: 2.5206182644562505

Epoch: 6| Step: 4
Training loss: 0.5212739384137672
Validation loss: 2.529754293363452

Epoch: 6| Step: 5
Training loss: 0.7025048806234763
Validation loss: 2.5384140461322833

Epoch: 6| Step: 6
Training loss: 0.8070540211687919
Validation loss: 2.5328488432146066

Epoch: 6| Step: 7
Training loss: 0.7405150191015808
Validation loss: 2.513028294988274

Epoch: 6| Step: 8
Training loss: 0.5586908962898881
Validation loss: 2.5307795245491054

Epoch: 6| Step: 9
Training loss: 0.7534204607840146
Validation loss: 2.540449206085029

Epoch: 6| Step: 10
Training loss: 0.48504730451090694
Validation loss: 2.552903551128424

Epoch: 6| Step: 11
Training loss: 0.8315756539928274
Validation loss: 2.5473166623280448

Epoch: 6| Step: 12
Training loss: 0.6251903959186438
Validation loss: 2.535116516213478

Epoch: 6| Step: 13
Training loss: 0.4831303633457566
Validation loss: 2.529634972522241

Epoch: 342| Step: 0
Training loss: 0.3976256195742287
Validation loss: 2.532935127115308

Epoch: 6| Step: 1
Training loss: 0.6167468175693849
Validation loss: 2.540916380714052

Epoch: 6| Step: 2
Training loss: 0.9243365898689418
Validation loss: 2.520665061363029

Epoch: 6| Step: 3
Training loss: 0.6159804649212478
Validation loss: 2.5117189561757063

Epoch: 6| Step: 4
Training loss: 0.785923862528555
Validation loss: 2.5489204085459773

Epoch: 6| Step: 5
Training loss: 0.30824199378235095
Validation loss: 2.509963994059022

Epoch: 6| Step: 6
Training loss: 0.5613011193731018
Validation loss: 2.5017932223616977

Epoch: 6| Step: 7
Training loss: 0.8932679096564975
Validation loss: 2.5046448514652786

Epoch: 6| Step: 8
Training loss: 0.3995929867543319
Validation loss: 2.5526139167154036

Epoch: 6| Step: 9
Training loss: 0.6203739625859469
Validation loss: 2.5534942359956365

Epoch: 6| Step: 10
Training loss: 0.45590517913903866
Validation loss: 2.583997294445343

Epoch: 6| Step: 11
Training loss: 0.761198443215643
Validation loss: 2.5879318685373707

Epoch: 6| Step: 12
Training loss: 0.7568227459157819
Validation loss: 2.667263847312922

Epoch: 6| Step: 13
Training loss: 0.5903680000043646
Validation loss: 2.6244390135317373

Epoch: 343| Step: 0
Training loss: 0.5360783339095885
Validation loss: 2.5748301602854595

Epoch: 6| Step: 1
Training loss: 0.9009556517954006
Validation loss: 2.568520595681391

Epoch: 6| Step: 2
Training loss: 0.5386530108672307
Validation loss: 2.54189866606023

Epoch: 6| Step: 3
Training loss: 0.7364941316255577
Validation loss: 2.5510434829655266

Epoch: 6| Step: 4
Training loss: 0.6209679962102947
Validation loss: 2.541121915849857

Epoch: 6| Step: 5
Training loss: 0.5941755125297724
Validation loss: 2.5309781215007976

Epoch: 6| Step: 6
Training loss: 0.7298962802884688
Validation loss: 2.537553262386475

Epoch: 6| Step: 7
Training loss: 0.8905492047633212
Validation loss: 2.5383876073344114

Epoch: 6| Step: 8
Training loss: 0.5637763166523121
Validation loss: 2.5365695424052572

Epoch: 6| Step: 9
Training loss: 0.5058555455596787
Validation loss: 2.577759842106843

Epoch: 6| Step: 10
Training loss: 0.6078195527361344
Validation loss: 2.600717858950895

Epoch: 6| Step: 11
Training loss: 0.453215573565182
Validation loss: 2.5909591097168407

Epoch: 6| Step: 12
Training loss: 0.8184689104797293
Validation loss: 2.5776573475450046

Epoch: 6| Step: 13
Training loss: 0.6951544935736285
Validation loss: 2.5466124699198627

Epoch: 344| Step: 0
Training loss: 0.5640501015692728
Validation loss: 2.563966216076083

Epoch: 6| Step: 1
Training loss: 0.819483637994949
Validation loss: 2.5304755243062806

Epoch: 6| Step: 2
Training loss: 0.827536463784051
Validation loss: 2.5285859262085792

Epoch: 6| Step: 3
Training loss: 0.8345782200362568
Validation loss: 2.493247184236832

Epoch: 6| Step: 4
Training loss: 0.5000188943153987
Validation loss: 2.498404000604032

Epoch: 6| Step: 5
Training loss: 0.495377271009308
Validation loss: 2.4994241163993887

Epoch: 6| Step: 6
Training loss: 0.5878361267987509
Validation loss: 2.480201934863946

Epoch: 6| Step: 7
Training loss: 0.41268728512901803
Validation loss: 2.5360443133783064

Epoch: 6| Step: 8
Training loss: 0.4662733454139416
Validation loss: 2.552201673431417

Epoch: 6| Step: 9
Training loss: 0.819818656861624
Validation loss: 2.5724082222866915

Epoch: 6| Step: 10
Training loss: 0.5561964973693317
Validation loss: 2.622209211006905

Epoch: 6| Step: 11
Training loss: 0.4918234553588817
Validation loss: 2.5990353455599298

Epoch: 6| Step: 12
Training loss: 0.7319002862824715
Validation loss: 2.6029270363685213

Epoch: 6| Step: 13
Training loss: 0.5754887038248279
Validation loss: 2.6195467115128035

Epoch: 345| Step: 0
Training loss: 0.5105538248816403
Validation loss: 2.5834873449943943

Epoch: 6| Step: 1
Training loss: 0.7830525393805894
Validation loss: 2.561864340370718

Epoch: 6| Step: 2
Training loss: 0.49954150456942337
Validation loss: 2.525564629271973

Epoch: 6| Step: 3
Training loss: 0.8233881376407602
Validation loss: 2.5795627755070845

Epoch: 6| Step: 4
Training loss: 0.648283377106276
Validation loss: 2.6040571804206443

Epoch: 6| Step: 5
Training loss: 0.7643210147311945
Validation loss: 2.5781055070594463

Epoch: 6| Step: 6
Training loss: 0.6288258281963923
Validation loss: 2.6396502080067252

Epoch: 6| Step: 7
Training loss: 0.6538550408113244
Validation loss: 2.6398632671469153

Epoch: 6| Step: 8
Training loss: 0.7219596185671847
Validation loss: 2.6042602814286093

Epoch: 6| Step: 9
Training loss: 0.5132704642220796
Validation loss: 2.593274565779328

Epoch: 6| Step: 10
Training loss: 0.6344522260066018
Validation loss: 2.547767219657831

Epoch: 6| Step: 11
Training loss: 0.3198195245995267
Validation loss: 2.5266646653497333

Epoch: 6| Step: 12
Training loss: 0.7723135439834892
Validation loss: 2.485447403524719

Epoch: 6| Step: 13
Training loss: 0.7262177418489598
Validation loss: 2.47660083171102

Epoch: 346| Step: 0
Training loss: 0.7739599755852905
Validation loss: 2.495014406202459

Epoch: 6| Step: 1
Training loss: 0.5950420776683459
Validation loss: 2.509103656235012

Epoch: 6| Step: 2
Training loss: 0.622250517370209
Validation loss: 2.4688845984975374

Epoch: 6| Step: 3
Training loss: 0.5087902047113348
Validation loss: 2.5254858378255505

Epoch: 6| Step: 4
Training loss: 0.46300363569500597
Validation loss: 2.5722800225212423

Epoch: 6| Step: 5
Training loss: 0.62455158837104
Validation loss: 2.5490618125772806

Epoch: 6| Step: 6
Training loss: 0.8727361138800892
Validation loss: 2.5920477573058247

Epoch: 6| Step: 7
Training loss: 0.6106940201374279
Validation loss: 2.5834796639465742

Epoch: 6| Step: 8
Training loss: 0.729786396063843
Validation loss: 2.6140085950006

Epoch: 6| Step: 9
Training loss: 0.4963011871141913
Validation loss: 2.589506118715261

Epoch: 6| Step: 10
Training loss: 0.8280264237951348
Validation loss: 2.579505266039165

Epoch: 6| Step: 11
Training loss: 0.6882078255016398
Validation loss: 2.5356617911780446

Epoch: 6| Step: 12
Training loss: 0.5503405708635754
Validation loss: 2.54820974144822

Epoch: 6| Step: 13
Training loss: 0.7384051264423739
Validation loss: 2.550424568047737

Epoch: 347| Step: 0
Training loss: 0.36310811172581425
Validation loss: 2.5452074623466174

Epoch: 6| Step: 1
Training loss: 0.5517015816721699
Validation loss: 2.5266685818350982

Epoch: 6| Step: 2
Training loss: 0.5879370585509174
Validation loss: 2.5113585607170363

Epoch: 6| Step: 3
Training loss: 0.5202835773757587
Validation loss: 2.4891808832807762

Epoch: 6| Step: 4
Training loss: 0.6760587618585967
Validation loss: 2.530678284845146

Epoch: 6| Step: 5
Training loss: 0.47927960502271083
Validation loss: 2.531670842139897

Epoch: 6| Step: 6
Training loss: 0.8938499754895721
Validation loss: 2.5579778034285265

Epoch: 6| Step: 7
Training loss: 0.8901478677240803
Validation loss: 2.5254976871523165

Epoch: 6| Step: 8
Training loss: 0.7478288776088414
Validation loss: 2.56821344245575

Epoch: 6| Step: 9
Training loss: 0.6224337344154824
Validation loss: 2.6240167148337474

Epoch: 6| Step: 10
Training loss: 0.6809684477833386
Validation loss: 2.5992245981725963

Epoch: 6| Step: 11
Training loss: 0.5378822730474924
Validation loss: 2.595906512244313

Epoch: 6| Step: 12
Training loss: 0.3679961168029882
Validation loss: 2.586976596536323

Epoch: 6| Step: 13
Training loss: 0.9483442006105832
Validation loss: 2.5698185479219466

Epoch: 348| Step: 0
Training loss: 0.5482564643656187
Validation loss: 2.5436958679920147

Epoch: 6| Step: 1
Training loss: 0.732670408678724
Validation loss: 2.5144081563711578

Epoch: 6| Step: 2
Training loss: 0.8050021324958752
Validation loss: 2.5104519788767004

Epoch: 6| Step: 3
Training loss: 0.4914252266911612
Validation loss: 2.4845640946762306

Epoch: 6| Step: 4
Training loss: 0.7596446826061498
Validation loss: 2.4918141529819327

Epoch: 6| Step: 5
Training loss: 0.4560940090438771
Validation loss: 2.4969942030276453

Epoch: 6| Step: 6
Training loss: 0.5530304941164765
Validation loss: 2.5120798234596973

Epoch: 6| Step: 7
Training loss: 0.7846856676062819
Validation loss: 2.5085393178057007

Epoch: 6| Step: 8
Training loss: 0.6521167474377716
Validation loss: 2.5655642460661894

Epoch: 6| Step: 9
Training loss: 0.5639539048756498
Validation loss: 2.5011431869518956

Epoch: 6| Step: 10
Training loss: 0.7781935221211022
Validation loss: 2.525324050836276

Epoch: 6| Step: 11
Training loss: 0.688154256061901
Validation loss: 2.5304348553607787

Epoch: 6| Step: 12
Training loss: 0.3648893593291789
Validation loss: 2.6038256894913427

Epoch: 6| Step: 13
Training loss: 0.7616185048970698
Validation loss: 2.6408903985272523

Epoch: 349| Step: 0
Training loss: 0.7121551063739664
Validation loss: 2.667081084146588

Epoch: 6| Step: 1
Training loss: 0.6858731658936051
Validation loss: 2.719907758096939

Epoch: 6| Step: 2
Training loss: 0.9397475956842669
Validation loss: 2.6687695501294

Epoch: 6| Step: 3
Training loss: 0.4952970851340688
Validation loss: 2.6119818356733577

Epoch: 6| Step: 4
Training loss: 0.4218756711036148
Validation loss: 2.6007652303931947

Epoch: 6| Step: 5
Training loss: 0.980209498686846
Validation loss: 2.5512701105453823

Epoch: 6| Step: 6
Training loss: 0.6970177217772788
Validation loss: 2.5503031220935615

Epoch: 6| Step: 7
Training loss: 0.7611733856233166
Validation loss: 2.485793814965549

Epoch: 6| Step: 8
Training loss: 0.4950795356835133
Validation loss: 2.4596877130985293

Epoch: 6| Step: 9
Training loss: 0.32297943130791046
Validation loss: 2.4238103230801586

Epoch: 6| Step: 10
Training loss: 0.8918102475607795
Validation loss: 2.425020961884425

Epoch: 6| Step: 11
Training loss: 0.6063420058761432
Validation loss: 2.443117117270587

Epoch: 6| Step: 12
Training loss: 0.489737848153496
Validation loss: 2.494670152236396

Epoch: 6| Step: 13
Training loss: 0.28466111137283606
Validation loss: 2.4845985275407396

Epoch: 350| Step: 0
Training loss: 0.45844808861401326
Validation loss: 2.488539964475664

Epoch: 6| Step: 1
Training loss: 0.48601140199343307
Validation loss: 2.575169731668659

Epoch: 6| Step: 2
Training loss: 0.5558049940046181
Validation loss: 2.5543708837130095

Epoch: 6| Step: 3
Training loss: 0.6104909996975139
Validation loss: 2.6468624768031894

Epoch: 6| Step: 4
Training loss: 0.7066582386021085
Validation loss: 2.6528495835300814

Epoch: 6| Step: 5
Training loss: 0.6761495655947848
Validation loss: 2.6332168937969205

Epoch: 6| Step: 6
Training loss: 0.7264265117744668
Validation loss: 2.584825532012463

Epoch: 6| Step: 7
Training loss: 0.504602764090468
Validation loss: 2.603566769978377

Epoch: 6| Step: 8
Training loss: 0.625403798314251
Validation loss: 2.5835494256385068

Epoch: 6| Step: 9
Training loss: 0.780521740035725
Validation loss: 2.539291332651502

Epoch: 6| Step: 10
Training loss: 0.7182358270953658
Validation loss: 2.486619955204383

Epoch: 6| Step: 11
Training loss: 0.7020084841153039
Validation loss: 2.503465807589269

Epoch: 6| Step: 12
Training loss: 0.7845200955362076
Validation loss: 2.471318061006691

Epoch: 6| Step: 13
Training loss: 0.7270245877191664
Validation loss: 2.514657598555058

Epoch: 351| Step: 0
Training loss: 0.30754346418240897
Validation loss: 2.558175215892554

Epoch: 6| Step: 1
Training loss: 0.8156916580146829
Validation loss: 2.570211601602124

Epoch: 6| Step: 2
Training loss: 0.7275934186253995
Validation loss: 2.5610474221867734

Epoch: 6| Step: 3
Training loss: 0.8325423698984253
Validation loss: 2.5709582022462167

Epoch: 6| Step: 4
Training loss: 0.8618729094659073
Validation loss: 2.544865143137093

Epoch: 6| Step: 5
Training loss: 0.564389895161268
Validation loss: 2.5946047279338758

Epoch: 6| Step: 6
Training loss: 0.5657877998636623
Validation loss: 2.5200745930515436

Epoch: 6| Step: 7
Training loss: 0.6025920084191384
Validation loss: 2.553124463840706

Epoch: 6| Step: 8
Training loss: 0.6790519900327139
Validation loss: 2.4924408055533602

Epoch: 6| Step: 9
Training loss: 0.5855945346362269
Validation loss: 2.515457519711968

Epoch: 6| Step: 10
Training loss: 0.5068114170030432
Validation loss: 2.5383080236637325

Epoch: 6| Step: 11
Training loss: 0.6412527451261243
Validation loss: 2.5603406798748245

Epoch: 6| Step: 12
Training loss: 0.6239645009274675
Validation loss: 2.558556544485759

Epoch: 6| Step: 13
Training loss: 0.5226255923917671
Validation loss: 2.545910647976011

Epoch: 352| Step: 0
Training loss: 0.4865194044095306
Validation loss: 2.5909129882777693

Epoch: 6| Step: 1
Training loss: 0.8240086436836798
Validation loss: 2.5665415744425357

Epoch: 6| Step: 2
Training loss: 0.8338730891930198
Validation loss: 2.588031321265083

Epoch: 6| Step: 3
Training loss: 0.3719800504198404
Validation loss: 2.4877222716360405

Epoch: 6| Step: 4
Training loss: 0.7566973159341155
Validation loss: 2.478755816234601

Epoch: 6| Step: 5
Training loss: 0.5494299470332227
Validation loss: 2.4549494957073628

Epoch: 6| Step: 6
Training loss: 0.5882108709580488
Validation loss: 2.4323241880367883

Epoch: 6| Step: 7
Training loss: 0.7505479638735132
Validation loss: 2.4315779891605533

Epoch: 6| Step: 8
Training loss: 0.35498603071344387
Validation loss: 2.471231917328102

Epoch: 6| Step: 9
Training loss: 0.5123506386524433
Validation loss: 2.5128705774182754

Epoch: 6| Step: 10
Training loss: 0.7751763189386449
Validation loss: 2.540442611923873

Epoch: 6| Step: 11
Training loss: 0.7453759220417621
Validation loss: 2.5767255667265996

Epoch: 6| Step: 12
Training loss: 0.6967583956477813
Validation loss: 2.5687842038431854

Epoch: 6| Step: 13
Training loss: 0.33884797055505106
Validation loss: 2.6679184322038045

Epoch: 353| Step: 0
Training loss: 0.5747355516433753
Validation loss: 2.6618431132156326

Epoch: 6| Step: 1
Training loss: 0.9246059635229958
Validation loss: 2.6366540767344775

Epoch: 6| Step: 2
Training loss: 0.7040040349411208
Validation loss: 2.5947951726362466

Epoch: 6| Step: 3
Training loss: 0.36887507499608746
Validation loss: 2.529248934822124

Epoch: 6| Step: 4
Training loss: 0.5709285805125021
Validation loss: 2.5232438457912036

Epoch: 6| Step: 5
Training loss: 0.9844492929670268
Validation loss: 2.4713245164747626

Epoch: 6| Step: 6
Training loss: 0.537530186271247
Validation loss: 2.481834841982254

Epoch: 6| Step: 7
Training loss: 0.793523960518555
Validation loss: 2.485706538258975

Epoch: 6| Step: 8
Training loss: 0.6282047126255627
Validation loss: 2.4799849856474907

Epoch: 6| Step: 9
Training loss: 0.45623243245831846
Validation loss: 2.5462273829301587

Epoch: 6| Step: 10
Training loss: 0.6082764039335291
Validation loss: 2.5366381216594416

Epoch: 6| Step: 11
Training loss: 0.543301212974218
Validation loss: 2.594181986028434

Epoch: 6| Step: 12
Training loss: 0.6233036385142194
Validation loss: 2.5669665403412876

Epoch: 6| Step: 13
Training loss: 0.4638797316611845
Validation loss: 2.536463595960948

Epoch: 354| Step: 0
Training loss: 0.6314674257936712
Validation loss: 2.591332090059626

Epoch: 6| Step: 1
Training loss: 0.9589256377402343
Validation loss: 2.5789199901054896

Epoch: 6| Step: 2
Training loss: 0.5981944285230554
Validation loss: 2.5785111710790773

Epoch: 6| Step: 3
Training loss: 0.7040374557368586
Validation loss: 2.5943364709527414

Epoch: 6| Step: 4
Training loss: 0.5704857027600958
Validation loss: 2.5393239391385753

Epoch: 6| Step: 5
Training loss: 0.6928609211492822
Validation loss: 2.5293629553930197

Epoch: 6| Step: 6
Training loss: 0.474931113367704
Validation loss: 2.5495354809598387

Epoch: 6| Step: 7
Training loss: 0.4135465105991788
Validation loss: 2.532734725005102

Epoch: 6| Step: 8
Training loss: 0.3108361774004246
Validation loss: 2.5123476674369307

Epoch: 6| Step: 9
Training loss: 0.7179459760206564
Validation loss: 2.5116707044749265

Epoch: 6| Step: 10
Training loss: 0.5206565143531187
Validation loss: 2.4928558000812115

Epoch: 6| Step: 11
Training loss: 0.5841652070307034
Validation loss: 2.509051597753125

Epoch: 6| Step: 12
Training loss: 0.5390665358240285
Validation loss: 2.5316917047211183

Epoch: 6| Step: 13
Training loss: 0.5206222837727593
Validation loss: 2.5311436642828786

Epoch: 355| Step: 0
Training loss: 0.5767220924960632
Validation loss: 2.53643359423848

Epoch: 6| Step: 1
Training loss: 0.5862957431459102
Validation loss: 2.546818579401069

Epoch: 6| Step: 2
Training loss: 0.597229150490409
Validation loss: 2.520615888583858

Epoch: 6| Step: 3
Training loss: 0.5254390935273575
Validation loss: 2.5514497551033615

Epoch: 6| Step: 4
Training loss: 0.6504647152601688
Validation loss: 2.5531296641674106

Epoch: 6| Step: 5
Training loss: 0.3903846955245089
Validation loss: 2.607428220623118

Epoch: 6| Step: 6
Training loss: 0.6025480396461395
Validation loss: 2.598848787472038

Epoch: 6| Step: 7
Training loss: 0.36115563889402513
Validation loss: 2.558998637104143

Epoch: 6| Step: 8
Training loss: 0.6578916950531961
Validation loss: 2.6129705591817163

Epoch: 6| Step: 9
Training loss: 0.5172086440544125
Validation loss: 2.5833527841804953

Epoch: 6| Step: 10
Training loss: 0.7235534047819367
Validation loss: 2.560234068426243

Epoch: 6| Step: 11
Training loss: 0.6523143967289042
Validation loss: 2.5844672298390123

Epoch: 6| Step: 12
Training loss: 0.8270267185337122
Validation loss: 2.543669202398728

Epoch: 6| Step: 13
Training loss: 0.6504033405332539
Validation loss: 2.5066870419752636

Epoch: 356| Step: 0
Training loss: 0.6441197324271287
Validation loss: 2.4910926292458235

Epoch: 6| Step: 1
Training loss: 0.6581119734587974
Validation loss: 2.505818458465864

Epoch: 6| Step: 2
Training loss: 0.6560691402622931
Validation loss: 2.4797095292716205

Epoch: 6| Step: 3
Training loss: 0.5302047825552626
Validation loss: 2.4636108202111497

Epoch: 6| Step: 4
Training loss: 0.6205421733618056
Validation loss: 2.4965368299966553

Epoch: 6| Step: 5
Training loss: 0.6509125365306646
Validation loss: 2.529337255640418

Epoch: 6| Step: 6
Training loss: 0.6757297385985501
Validation loss: 2.5610493120977886

Epoch: 6| Step: 7
Training loss: 0.46128560515477857
Validation loss: 2.58832589524035

Epoch: 6| Step: 8
Training loss: 0.7362020774231658
Validation loss: 2.602109527403503

Epoch: 6| Step: 9
Training loss: 0.49378656058820214
Validation loss: 2.584193771782636

Epoch: 6| Step: 10
Training loss: 0.564603211403692
Validation loss: 2.592565857007506

Epoch: 6| Step: 11
Training loss: 0.7624020763742206
Validation loss: 2.6045976980211547

Epoch: 6| Step: 12
Training loss: 0.43537697664393177
Validation loss: 2.5718125991110155

Epoch: 6| Step: 13
Training loss: 0.5958664466975442
Validation loss: 2.5658348754668063

Epoch: 357| Step: 0
Training loss: 0.7388455288178318
Validation loss: 2.579771095220737

Epoch: 6| Step: 1
Training loss: 0.764779421913457
Validation loss: 2.582753582490177

Epoch: 6| Step: 2
Training loss: 0.7558879994731346
Validation loss: 2.5644572856779884

Epoch: 6| Step: 3
Training loss: 0.7332241293124495
Validation loss: 2.618610541911114

Epoch: 6| Step: 4
Training loss: 0.6247903233719653
Validation loss: 2.5439577097123527

Epoch: 6| Step: 5
Training loss: 0.6860561815617094
Validation loss: 2.5264399483567614

Epoch: 6| Step: 6
Training loss: 0.5095354342413119
Validation loss: 2.5659164555937206

Epoch: 6| Step: 7
Training loss: 0.5333705820795098
Validation loss: 2.5384617945387484

Epoch: 6| Step: 8
Training loss: 0.8287149882796355
Validation loss: 2.4997257471910186

Epoch: 6| Step: 9
Training loss: 0.42544750817627525
Validation loss: 2.4750007800095513

Epoch: 6| Step: 10
Training loss: 0.4673526599561424
Validation loss: 2.4522735542482375

Epoch: 6| Step: 11
Training loss: 0.6515624798744986
Validation loss: 2.414917029973305

Epoch: 6| Step: 12
Training loss: 0.7458830530937923
Validation loss: 2.385036575966668

Epoch: 6| Step: 13
Training loss: 0.6457936033723638
Validation loss: 2.422692099193348

Epoch: 358| Step: 0
Training loss: 0.7039009898472907
Validation loss: 2.4641876535792817

Epoch: 6| Step: 1
Training loss: 0.4891492376710141
Validation loss: 2.5028865639043203

Epoch: 6| Step: 2
Training loss: 0.5706302071424642
Validation loss: 2.5652310943973546

Epoch: 6| Step: 3
Training loss: 0.9347002821966259
Validation loss: 2.5953981708097014

Epoch: 6| Step: 4
Training loss: 0.6371741976993467
Validation loss: 2.6065576247805375

Epoch: 6| Step: 5
Training loss: 0.6223224985074781
Validation loss: 2.5666776473552653

Epoch: 6| Step: 6
Training loss: 0.4669210197053593
Validation loss: 2.5771123563573455

Epoch: 6| Step: 7
Training loss: 0.5180181108663104
Validation loss: 2.6087476057029075

Epoch: 6| Step: 8
Training loss: 0.6160555732850814
Validation loss: 2.548317821216473

Epoch: 6| Step: 9
Training loss: 0.5542656812432578
Validation loss: 2.4994751307479413

Epoch: 6| Step: 10
Training loss: 0.9080301755898861
Validation loss: 2.469511391595482

Epoch: 6| Step: 11
Training loss: 0.6815855774608339
Validation loss: 2.500765085563894

Epoch: 6| Step: 12
Training loss: 0.46833216800522093
Validation loss: 2.4256832174396035

Epoch: 6| Step: 13
Training loss: 0.5413379466470192
Validation loss: 2.4523242353859533

Epoch: 359| Step: 0
Training loss: 0.6026539994332045
Validation loss: 2.4820410528802177

Epoch: 6| Step: 1
Training loss: 0.8266856803040533
Validation loss: 2.458868520311955

Epoch: 6| Step: 2
Training loss: 0.4667375917976735
Validation loss: 2.496867962059209

Epoch: 6| Step: 3
Training loss: 0.6269048511779888
Validation loss: 2.5135920682176254

Epoch: 6| Step: 4
Training loss: 0.3902658337197985
Validation loss: 2.509757739779652

Epoch: 6| Step: 5
Training loss: 0.4566399129661315
Validation loss: 2.5449585666463275

Epoch: 6| Step: 6
Training loss: 0.5076985157907162
Validation loss: 2.562750313151077

Epoch: 6| Step: 7
Training loss: 0.49567493271375346
Validation loss: 2.584171168894137

Epoch: 6| Step: 8
Training loss: 0.5409144503190968
Validation loss: 2.5538467981262665

Epoch: 6| Step: 9
Training loss: 0.6647551570547396
Validation loss: 2.5865147009070752

Epoch: 6| Step: 10
Training loss: 0.6751222870575686
Validation loss: 2.554605854565303

Epoch: 6| Step: 11
Training loss: 0.9739988322006212
Validation loss: 2.5114180379877022

Epoch: 6| Step: 12
Training loss: 0.539722260027797
Validation loss: 2.4191147136306137

Epoch: 6| Step: 13
Training loss: 0.5297402921041863
Validation loss: 2.419619949130926

Epoch: 360| Step: 0
Training loss: 0.4433211087421309
Validation loss: 2.4370298108295203

Epoch: 6| Step: 1
Training loss: 0.3932026123613502
Validation loss: 2.4350199728900015

Epoch: 6| Step: 2
Training loss: 0.5727463613600189
Validation loss: 2.4611226986345676

Epoch: 6| Step: 3
Training loss: 0.7295435794156937
Validation loss: 2.4629186481447713

Epoch: 6| Step: 4
Training loss: 0.3571195105176501
Validation loss: 2.4472220862117227

Epoch: 6| Step: 5
Training loss: 0.7476759506388422
Validation loss: 2.5102354462621173

Epoch: 6| Step: 6
Training loss: 0.5011379881631773
Validation loss: 2.5157606490462374

Epoch: 6| Step: 7
Training loss: 0.49560799433623726
Validation loss: 2.542007542114772

Epoch: 6| Step: 8
Training loss: 0.7330142461269251
Validation loss: 2.570857273347405

Epoch: 6| Step: 9
Training loss: 0.7424491822548503
Validation loss: 2.5990656006665644

Epoch: 6| Step: 10
Training loss: 0.5944351459481028
Validation loss: 2.6262232893669166

Epoch: 6| Step: 11
Training loss: 0.5211614115880818
Validation loss: 2.6496761696094593

Epoch: 6| Step: 12
Training loss: 0.5862605412395653
Validation loss: 2.5972712622944347

Epoch: 6| Step: 13
Training loss: 0.35910341117729105
Validation loss: 2.5757376806010552

Epoch: 361| Step: 0
Training loss: 0.5182503707100499
Validation loss: 2.569857472824432

Epoch: 6| Step: 1
Training loss: 0.49046118303570285
Validation loss: 2.5807962300962486

Epoch: 6| Step: 2
Training loss: 0.6474841129533784
Validation loss: 2.511286424580639

Epoch: 6| Step: 3
Training loss: 0.5090012062317021
Validation loss: 2.5245953337443514

Epoch: 6| Step: 4
Training loss: 0.7893812083576314
Validation loss: 2.5077127769008762

Epoch: 6| Step: 5
Training loss: 0.5437888942707558
Validation loss: 2.5216453418703377

Epoch: 6| Step: 6
Training loss: 0.4670854578244944
Validation loss: 2.4807106288354293

Epoch: 6| Step: 7
Training loss: 0.6184254556170217
Validation loss: 2.4904582186779067

Epoch: 6| Step: 8
Training loss: 0.5579784445666867
Validation loss: 2.4665474111479897

Epoch: 6| Step: 9
Training loss: 0.5720697008978172
Validation loss: 2.5017565616662574

Epoch: 6| Step: 10
Training loss: 0.43037290527294886
Validation loss: 2.502736023934394

Epoch: 6| Step: 11
Training loss: 0.7048314896880644
Validation loss: 2.4777223694315524

Epoch: 6| Step: 12
Training loss: 0.4573302798670873
Validation loss: 2.5267543665613337

Epoch: 6| Step: 13
Training loss: 0.6489059410765013
Validation loss: 2.503497906835017

Epoch: 362| Step: 0
Training loss: 0.5521267088159117
Validation loss: 2.5549323062611595

Epoch: 6| Step: 1
Training loss: 0.6453906716204845
Validation loss: 2.5702476649132064

Epoch: 6| Step: 2
Training loss: 0.2505742570588418
Validation loss: 2.5376681963677994

Epoch: 6| Step: 3
Training loss: 0.6121968687001716
Validation loss: 2.6158250152177875

Epoch: 6| Step: 4
Training loss: 0.5063285272234976
Validation loss: 2.6256731647814404

Epoch: 6| Step: 5
Training loss: 0.5789973404811729
Validation loss: 2.647294888721435

Epoch: 6| Step: 6
Training loss: 0.6806583705319307
Validation loss: 2.6039279337738552

Epoch: 6| Step: 7
Training loss: 0.6388898005225638
Validation loss: 2.5731920388303178

Epoch: 6| Step: 8
Training loss: 0.6618939164496042
Validation loss: 2.5122477952628857

Epoch: 6| Step: 9
Training loss: 0.3519570785452825
Validation loss: 2.465846357148133

Epoch: 6| Step: 10
Training loss: 0.6747641654759026
Validation loss: 2.46875564285865

Epoch: 6| Step: 11
Training loss: 0.5039199117538476
Validation loss: 2.471565705024272

Epoch: 6| Step: 12
Training loss: 0.7454162237579355
Validation loss: 2.4198286998702474

Epoch: 6| Step: 13
Training loss: 0.45546538938980513
Validation loss: 2.460624778867759

Epoch: 363| Step: 0
Training loss: 0.5944692371324101
Validation loss: 2.4356404961231277

Epoch: 6| Step: 1
Training loss: 0.7000415585306661
Validation loss: 2.4794350069798976

Epoch: 6| Step: 2
Training loss: 0.4770031908206461
Validation loss: 2.464368463999584

Epoch: 6| Step: 3
Training loss: 0.5447622632856107
Validation loss: 2.4926875505111994

Epoch: 6| Step: 4
Training loss: 0.6068971090483312
Validation loss: 2.4572067016809993

Epoch: 6| Step: 5
Training loss: 0.445160371326825
Validation loss: 2.5419336121965923

Epoch: 6| Step: 6
Training loss: 0.5608885252248274
Validation loss: 2.553654148912924

Epoch: 6| Step: 7
Training loss: 0.3650762450261429
Validation loss: 2.510399840617699

Epoch: 6| Step: 8
Training loss: 0.6076149587611809
Validation loss: 2.50594785878713

Epoch: 6| Step: 9
Training loss: 0.6170755115745689
Validation loss: 2.514742705261466

Epoch: 6| Step: 10
Training loss: 0.5242632146360452
Validation loss: 2.565784906498652

Epoch: 6| Step: 11
Training loss: 0.4819019156483027
Validation loss: 2.539996716299624

Epoch: 6| Step: 12
Training loss: 0.7512992096333058
Validation loss: 2.545744484413624

Epoch: 6| Step: 13
Training loss: 0.29384871254778966
Validation loss: 2.563475591437668

Epoch: 364| Step: 0
Training loss: 0.6975945303379871
Validation loss: 2.5766472631953183

Epoch: 6| Step: 1
Training loss: 0.2011816429803686
Validation loss: 2.568684002923415

Epoch: 6| Step: 2
Training loss: 0.6978829266567569
Validation loss: 2.506571465739484

Epoch: 6| Step: 3
Training loss: 0.45389287932198324
Validation loss: 2.5396522542568243

Epoch: 6| Step: 4
Training loss: 0.5137622594182797
Validation loss: 2.4887210977937855

Epoch: 6| Step: 5
Training loss: 0.6648609970491474
Validation loss: 2.529147571511166

Epoch: 6| Step: 6
Training loss: 0.5224858643476833
Validation loss: 2.5251358921818468

Epoch: 6| Step: 7
Training loss: 0.49130320962144375
Validation loss: 2.487008237140007

Epoch: 6| Step: 8
Training loss: 0.5465852787425022
Validation loss: 2.5177741893108614

Epoch: 6| Step: 9
Training loss: 0.5947455542527714
Validation loss: 2.5022359421781744

Epoch: 6| Step: 10
Training loss: 0.3652295198984831
Validation loss: 2.486937393501673

Epoch: 6| Step: 11
Training loss: 0.6267472639233364
Validation loss: 2.51575871288467

Epoch: 6| Step: 12
Training loss: 0.5404280629080179
Validation loss: 2.491926018725834

Epoch: 6| Step: 13
Training loss: 0.20686070597382009
Validation loss: 2.517911765005029

Epoch: 365| Step: 0
Training loss: 0.6720027580332357
Validation loss: 2.4948253812140355

Epoch: 6| Step: 1
Training loss: 0.43523731264250415
Validation loss: 2.5483099828548035

Epoch: 6| Step: 2
Training loss: 0.4569185558175446
Validation loss: 2.5560139131623267

Epoch: 6| Step: 3
Training loss: 0.6833950298842527
Validation loss: 2.511454851635155

Epoch: 6| Step: 4
Training loss: 0.3423370452600376
Validation loss: 2.556462367320722

Epoch: 6| Step: 5
Training loss: 0.5059214668018979
Validation loss: 2.5577082217749165

Epoch: 6| Step: 6
Training loss: 0.5781031424024741
Validation loss: 2.558023419784768

Epoch: 6| Step: 7
Training loss: 0.1947091702238427
Validation loss: 2.5420504942030004

Epoch: 6| Step: 8
Training loss: 0.58625667779694
Validation loss: 2.5075882343816476

Epoch: 6| Step: 9
Training loss: 0.36796679891081185
Validation loss: 2.5617820220123613

Epoch: 6| Step: 10
Training loss: 0.4813457022294674
Validation loss: 2.547977639388233

Epoch: 6| Step: 11
Training loss: 0.5647625982256471
Validation loss: 2.534195111706109

Epoch: 6| Step: 12
Training loss: 0.5758527744956721
Validation loss: 2.5067203006306125

Epoch: 6| Step: 13
Training loss: 0.6714540537966956
Validation loss: 2.5302966201299064

Epoch: 366| Step: 0
Training loss: 0.5014704896187467
Validation loss: 2.546025425199165

Epoch: 6| Step: 1
Training loss: 0.3906115911089694
Validation loss: 2.5473105654992585

Epoch: 6| Step: 2
Training loss: 0.30715845205472597
Validation loss: 2.5457742550624163

Epoch: 6| Step: 3
Training loss: 0.6152283683362533
Validation loss: 2.5084848117056207

Epoch: 6| Step: 4
Training loss: 0.4679290257885594
Validation loss: 2.524176149119282

Epoch: 6| Step: 5
Training loss: 0.5249617006319183
Validation loss: 2.553008828892937

Epoch: 6| Step: 6
Training loss: 0.615075033231698
Validation loss: 2.5535232481560586

Epoch: 6| Step: 7
Training loss: 0.4071066700478197
Validation loss: 2.5538889116660783

Epoch: 6| Step: 8
Training loss: 0.42575195631696633
Validation loss: 2.53795568380553

Epoch: 6| Step: 9
Training loss: 0.5456909713538582
Validation loss: 2.5798246695704505

Epoch: 6| Step: 10
Training loss: 0.4288285773982551
Validation loss: 2.546403031990118

Epoch: 6| Step: 11
Training loss: 0.6301361284323272
Validation loss: 2.493781851588391

Epoch: 6| Step: 12
Training loss: 0.808701733736397
Validation loss: 2.5152559798890914

Epoch: 6| Step: 13
Training loss: 0.5255383989204337
Validation loss: 2.4909156601201725

Epoch: 367| Step: 0
Training loss: 0.5535805631138822
Validation loss: 2.476204525327403

Epoch: 6| Step: 1
Training loss: 0.5527091677683735
Validation loss: 2.536863165137452

Epoch: 6| Step: 2
Training loss: 0.4934571858610979
Validation loss: 2.523276612912555

Epoch: 6| Step: 3
Training loss: 0.536694675222117
Validation loss: 2.459758073159211

Epoch: 6| Step: 4
Training loss: 0.5908394298140295
Validation loss: 2.512254494553602

Epoch: 6| Step: 5
Training loss: 0.7304452494548594
Validation loss: 2.54887840904404

Epoch: 6| Step: 6
Training loss: 0.3147277935601037
Validation loss: 2.539534181714809

Epoch: 6| Step: 7
Training loss: 0.4962660722988457
Validation loss: 2.5431386886659446

Epoch: 6| Step: 8
Training loss: 0.27440576778378617
Validation loss: 2.55960331268239

Epoch: 6| Step: 9
Training loss: 0.6658495027427251
Validation loss: 2.5454269999732118

Epoch: 6| Step: 10
Training loss: 0.5802548328808154
Validation loss: 2.5547605972391763

Epoch: 6| Step: 11
Training loss: 0.35821308051432105
Validation loss: 2.524118339551453

Epoch: 6| Step: 12
Training loss: 0.2598224950505403
Validation loss: 2.518724408207113

Epoch: 6| Step: 13
Training loss: 0.5878508037881888
Validation loss: 2.5546555642702757

Epoch: 368| Step: 0
Training loss: 0.3685870788604414
Validation loss: 2.521129163324688

Epoch: 6| Step: 1
Training loss: 0.6525698972220105
Validation loss: 2.488097773045639

Epoch: 6| Step: 2
Training loss: 0.619700951442262
Validation loss: 2.513814619301987

Epoch: 6| Step: 3
Training loss: 0.5880276339745595
Validation loss: 2.5263862028993898

Epoch: 6| Step: 4
Training loss: 0.7739795365302169
Validation loss: 2.5275308228142648

Epoch: 6| Step: 5
Training loss: 0.27047842258587157
Validation loss: 2.5626221974567627

Epoch: 6| Step: 6
Training loss: 0.5693844599518946
Validation loss: 2.526755600312542

Epoch: 6| Step: 7
Training loss: 0.4806117953605976
Validation loss: 2.5690630696727315

Epoch: 6| Step: 8
Training loss: 0.46223470837525255
Validation loss: 2.572737814901283

Epoch: 6| Step: 9
Training loss: 0.5886349449395021
Validation loss: 2.564383504119458

Epoch: 6| Step: 10
Training loss: 0.48132239082139233
Validation loss: 2.6002288871823485

Epoch: 6| Step: 11
Training loss: 0.49674686483114716
Validation loss: 2.583373648665992

Epoch: 6| Step: 12
Training loss: 0.40706722883947755
Validation loss: 2.5683624154019116

Epoch: 6| Step: 13
Training loss: 0.2736644212000101
Validation loss: 2.567108590119464

Epoch: 369| Step: 0
Training loss: 0.4981371330305635
Validation loss: 2.5282213856355096

Epoch: 6| Step: 1
Training loss: 0.45332240047080813
Validation loss: 2.547267694055057

Epoch: 6| Step: 2
Training loss: 0.37217104291684744
Validation loss: 2.546282480079537

Epoch: 6| Step: 3
Training loss: 0.6065404451852389
Validation loss: 2.5314996379269297

Epoch: 6| Step: 4
Training loss: 0.5807798104092601
Validation loss: 2.484979209968095

Epoch: 6| Step: 5
Training loss: 0.6146829707527176
Validation loss: 2.4845516773795797

Epoch: 6| Step: 6
Training loss: 0.49685067531136334
Validation loss: 2.537428563428497

Epoch: 6| Step: 7
Training loss: 0.20249389762867148
Validation loss: 2.576212609563225

Epoch: 6| Step: 8
Training loss: 0.4982198676564732
Validation loss: 2.597445730628425

Epoch: 6| Step: 9
Training loss: 0.5897609324135294
Validation loss: 2.577827020244235

Epoch: 6| Step: 10
Training loss: 0.6366872955229069
Validation loss: 2.5640946435490486

Epoch: 6| Step: 11
Training loss: 0.5173601663255136
Validation loss: 2.57044182018303

Epoch: 6| Step: 12
Training loss: 0.6935934611863654
Validation loss: 2.553926099854926

Epoch: 6| Step: 13
Training loss: 0.3208597787985015
Validation loss: 2.512221167319021

Epoch: 370| Step: 0
Training loss: 0.7486437614868364
Validation loss: 2.4548029096820927

Epoch: 6| Step: 1
Training loss: 0.5817577052079475
Validation loss: 2.495319957307077

Epoch: 6| Step: 2
Training loss: 0.3377029471033562
Validation loss: 2.440336457063474

Epoch: 6| Step: 3
Training loss: 0.7134327120793642
Validation loss: 2.42741105230823

Epoch: 6| Step: 4
Training loss: 0.39384466804337465
Validation loss: 2.4825008435895337

Epoch: 6| Step: 5
Training loss: 0.5675016925383212
Validation loss: 2.471533156048622

Epoch: 6| Step: 6
Training loss: 0.6778847035721692
Validation loss: 2.481127442769377

Epoch: 6| Step: 7
Training loss: 0.4910932669180552
Validation loss: 2.525040307256807

Epoch: 6| Step: 8
Training loss: 0.5192682848389231
Validation loss: 2.5152549382291998

Epoch: 6| Step: 9
Training loss: 0.441642326757937
Validation loss: 2.529916222259446

Epoch: 6| Step: 10
Training loss: 0.4096799355397046
Validation loss: 2.5524710904130075

Epoch: 6| Step: 11
Training loss: 0.5137556464634441
Validation loss: 2.5408727460627047

Epoch: 6| Step: 12
Training loss: 0.4934799240361375
Validation loss: 2.5580675300556908

Epoch: 6| Step: 13
Training loss: 0.1972202777673417
Validation loss: 2.537917342378509

Epoch: 371| Step: 0
Training loss: 0.5131287695203779
Validation loss: 2.556113938782962

Epoch: 6| Step: 1
Training loss: 0.6223846551590974
Validation loss: 2.5505957065880214

Epoch: 6| Step: 2
Training loss: 0.5704242126582459
Validation loss: 2.508645850337027

Epoch: 6| Step: 3
Training loss: 0.6166479915506078
Validation loss: 2.527278125526725

Epoch: 6| Step: 4
Training loss: 0.33210865689211005
Validation loss: 2.4783734656963348

Epoch: 6| Step: 5
Training loss: 0.48190891933178065
Validation loss: 2.5219854659191867

Epoch: 6| Step: 6
Training loss: 0.2744591563903396
Validation loss: 2.5190394836195207

Epoch: 6| Step: 7
Training loss: 0.39537786538927694
Validation loss: 2.537711655285052

Epoch: 6| Step: 8
Training loss: 0.36976260308329084
Validation loss: 2.557327658883653

Epoch: 6| Step: 9
Training loss: 0.4746284951962163
Validation loss: 2.615072764350137

Epoch: 6| Step: 10
Training loss: 0.568199423603919
Validation loss: 2.565675614082956

Epoch: 6| Step: 11
Training loss: 0.6726751663791342
Validation loss: 2.582607454765067

Epoch: 6| Step: 12
Training loss: 0.6178008303507334
Validation loss: 2.6047415261690037

Epoch: 6| Step: 13
Training loss: 0.5715274150543895
Validation loss: 2.606311723531957

Epoch: 372| Step: 0
Training loss: 0.6142031307170481
Validation loss: 2.6250117272868523

Epoch: 6| Step: 1
Training loss: 0.48549280088019553
Validation loss: 2.595156294681121

Epoch: 6| Step: 2
Training loss: 0.4064295262025742
Validation loss: 2.6659877211450578

Epoch: 6| Step: 3
Training loss: 0.34655115673120906
Validation loss: 2.5865620262105726

Epoch: 6| Step: 4
Training loss: 0.30086950765984377
Validation loss: 2.5620804204819794

Epoch: 6| Step: 5
Training loss: 0.5720247666659192
Validation loss: 2.6000764314951326

Epoch: 6| Step: 6
Training loss: 0.6653032716296526
Validation loss: 2.5718727725934194

Epoch: 6| Step: 7
Training loss: 0.5365937410834144
Validation loss: 2.5256996744490063

Epoch: 6| Step: 8
Training loss: 0.7557960503441926
Validation loss: 2.5782594110646677

Epoch: 6| Step: 9
Training loss: 0.25288390698965485
Validation loss: 2.5438374636764163

Epoch: 6| Step: 10
Training loss: 0.295112901677961
Validation loss: 2.5410834870073735

Epoch: 6| Step: 11
Training loss: 0.4564664072721049
Validation loss: 2.5503931418469246

Epoch: 6| Step: 12
Training loss: 0.5300110225610924
Validation loss: 2.5206041434420587

Epoch: 6| Step: 13
Training loss: 0.589918094017169
Validation loss: 2.5042130195630534

Epoch: 373| Step: 0
Training loss: 0.4521247577439836
Validation loss: 2.5188974801697745

Epoch: 6| Step: 1
Training loss: 0.38567000087886505
Validation loss: 2.5477570063995687

Epoch: 6| Step: 2
Training loss: 0.4014405046683454
Validation loss: 2.5170791877350824

Epoch: 6| Step: 3
Training loss: 0.6629570230331964
Validation loss: 2.496625954807156

Epoch: 6| Step: 4
Training loss: 0.720560323322313
Validation loss: 2.542668928863627

Epoch: 6| Step: 5
Training loss: 0.22180961800705187
Validation loss: 2.4923349535469517

Epoch: 6| Step: 6
Training loss: 0.4347105335794307
Validation loss: 2.5282824485533406

Epoch: 6| Step: 7
Training loss: 0.7328649376040643
Validation loss: 2.5289066455998936

Epoch: 6| Step: 8
Training loss: 0.6070068511576249
Validation loss: 2.5142629231807803

Epoch: 6| Step: 9
Training loss: 0.5397603590246397
Validation loss: 2.554536160000405

Epoch: 6| Step: 10
Training loss: 0.31649025637798417
Validation loss: 2.5225075050911574

Epoch: 6| Step: 11
Training loss: 0.5228772082645806
Validation loss: 2.5447611922178526

Epoch: 6| Step: 12
Training loss: 0.4196812849798902
Validation loss: 2.530906065445324

Epoch: 6| Step: 13
Training loss: 0.3227681259277768
Validation loss: 2.528977715519584

Epoch: 374| Step: 0
Training loss: 0.49925719159428444
Validation loss: 2.4873968964920703

Epoch: 6| Step: 1
Training loss: 0.5341602719420603
Validation loss: 2.5301876748168075

Epoch: 6| Step: 2
Training loss: 0.5646322949377173
Validation loss: 2.537460767498351

Epoch: 6| Step: 3
Training loss: 0.3604786966486835
Validation loss: 2.5444808030116426

Epoch: 6| Step: 4
Training loss: 0.3423147256788243
Validation loss: 2.5489042949724396

Epoch: 6| Step: 5
Training loss: 0.404618398002665
Validation loss: 2.5338484728381307

Epoch: 6| Step: 6
Training loss: 0.6349605319756088
Validation loss: 2.5313223592102387

Epoch: 6| Step: 7
Training loss: 0.3460510787319263
Validation loss: 2.5603253731260582

Epoch: 6| Step: 8
Training loss: 0.5130663301332135
Validation loss: 2.578986410378772

Epoch: 6| Step: 9
Training loss: 0.42041657162688245
Validation loss: 2.5783804659095035

Epoch: 6| Step: 10
Training loss: 0.667746479018
Validation loss: 2.536678069109823

Epoch: 6| Step: 11
Training loss: 0.2694148489559111
Validation loss: 2.5369801008754576

Epoch: 6| Step: 12
Training loss: 0.617682825583596
Validation loss: 2.5400449416180186

Epoch: 6| Step: 13
Training loss: 0.36069028075089377
Validation loss: 2.5127048102236014

Epoch: 375| Step: 0
Training loss: 0.23728047157088572
Validation loss: 2.494946397779384

Epoch: 6| Step: 1
Training loss: 0.4716330874467734
Validation loss: 2.527898508432879

Epoch: 6| Step: 2
Training loss: 0.5308804067862265
Validation loss: 2.4722253883835914

Epoch: 6| Step: 3
Training loss: 0.4909366425786583
Validation loss: 2.513201909674793

Epoch: 6| Step: 4
Training loss: 0.5686371376904018
Validation loss: 2.5279374206494003

Epoch: 6| Step: 5
Training loss: 0.46202245815505305
Validation loss: 2.514688991176219

Epoch: 6| Step: 6
Training loss: 0.5697166256304488
Validation loss: 2.569869863746459

Epoch: 6| Step: 7
Training loss: 0.3764412918343194
Validation loss: 2.497637157146594

Epoch: 6| Step: 8
Training loss: 0.3717391976260181
Validation loss: 2.5084975103817055

Epoch: 6| Step: 9
Training loss: 0.5009881923582331
Validation loss: 2.5326007443027967

Epoch: 6| Step: 10
Training loss: 0.4960659950482156
Validation loss: 2.534763888480501

Epoch: 6| Step: 11
Training loss: 0.34685075864198867
Validation loss: 2.5168274614643775

Epoch: 6| Step: 12
Training loss: 0.5118763222403676
Validation loss: 2.4804884128438784

Epoch: 6| Step: 13
Training loss: 0.8519343692861104
Validation loss: 2.527156635947874

Epoch: 376| Step: 0
Training loss: 0.5213740942999052
Validation loss: 2.5356783073779474

Epoch: 6| Step: 1
Training loss: 0.4801751456994472
Validation loss: 2.5173700662372775

Epoch: 6| Step: 2
Training loss: 0.6178036282278153
Validation loss: 2.5089187520531593

Epoch: 6| Step: 3
Training loss: 0.43364570924951246
Validation loss: 2.536332143569884

Epoch: 6| Step: 4
Training loss: 0.36876536272666033
Validation loss: 2.5133329199074184

Epoch: 6| Step: 5
Training loss: 0.23119324425839005
Validation loss: 2.553119272540498

Epoch: 6| Step: 6
Training loss: 0.4084335844732212
Validation loss: 2.543243011836572

Epoch: 6| Step: 7
Training loss: 0.5760004855491658
Validation loss: 2.556347075658282

Epoch: 6| Step: 8
Training loss: 0.44301178200082514
Validation loss: 2.6018558134713974

Epoch: 6| Step: 9
Training loss: 0.30374275359783864
Validation loss: 2.6324418753619367

Epoch: 6| Step: 10
Training loss: 0.5539809011238267
Validation loss: 2.6561548412633487

Epoch: 6| Step: 11
Training loss: 0.7108391494632291
Validation loss: 2.624988875241006

Epoch: 6| Step: 12
Training loss: 0.6546426115830093
Validation loss: 2.610244864377461

Epoch: 6| Step: 13
Training loss: 0.44227073209610684
Validation loss: 2.5818823627389946

Epoch: 377| Step: 0
Training loss: 0.6035862359772375
Validation loss: 2.5401046630976234

Epoch: 6| Step: 1
Training loss: 0.48144111863605826
Validation loss: 2.5238497457114915

Epoch: 6| Step: 2
Training loss: 0.518862760307105
Validation loss: 2.4819688713571084

Epoch: 6| Step: 3
Training loss: 0.5711966154500453
Validation loss: 2.4985412505108497

Epoch: 6| Step: 4
Training loss: 0.5514934615459182
Validation loss: 2.5155426513303043

Epoch: 6| Step: 5
Training loss: 0.4885339617036873
Validation loss: 2.479076723473478

Epoch: 6| Step: 6
Training loss: 0.29079728608596583
Validation loss: 2.533870574588113

Epoch: 6| Step: 7
Training loss: 0.33020960429495533
Validation loss: 2.510783087100691

Epoch: 6| Step: 8
Training loss: 0.6834912468489963
Validation loss: 2.5504380213669213

Epoch: 6| Step: 9
Training loss: 0.6927528414852109
Validation loss: 2.5318254054571345

Epoch: 6| Step: 10
Training loss: 0.5769885982695946
Validation loss: 2.528785103988309

Epoch: 6| Step: 11
Training loss: 0.3631294302415694
Validation loss: 2.5102890702849554

Epoch: 6| Step: 12
Training loss: 0.44069102245822545
Validation loss: 2.5169611002831456

Epoch: 6| Step: 13
Training loss: 0.25866759706564185
Validation loss: 2.530176662594608

Epoch: 378| Step: 0
Training loss: 0.6054531710681604
Validation loss: 2.5522870399152806

Epoch: 6| Step: 1
Training loss: 0.6472982947439205
Validation loss: 2.569508878466659

Epoch: 6| Step: 2
Training loss: 0.5269983644061974
Validation loss: 2.590069310609462

Epoch: 6| Step: 3
Training loss: 0.6029031849662969
Validation loss: 2.6435719920233347

Epoch: 6| Step: 4
Training loss: 0.43116691106809735
Validation loss: 2.6296862616628793

Epoch: 6| Step: 5
Training loss: 0.7029117472766104
Validation loss: 2.6478932250621563

Epoch: 6| Step: 6
Training loss: 0.4628218909630279
Validation loss: 2.6440095520649978

Epoch: 6| Step: 7
Training loss: 0.4206540489085347
Validation loss: 2.633804442610725

Epoch: 6| Step: 8
Training loss: 0.2832665734084507
Validation loss: 2.6062087986224447

Epoch: 6| Step: 9
Training loss: 0.6195778250775441
Validation loss: 2.599749309847934

Epoch: 6| Step: 10
Training loss: 0.3583105743558739
Validation loss: 2.5471199783989342

Epoch: 6| Step: 11
Training loss: 0.41545346384380044
Validation loss: 2.5159466888799042

Epoch: 6| Step: 12
Training loss: 0.4591438178846678
Validation loss: 2.5064339354914744

Epoch: 6| Step: 13
Training loss: 0.23961867541710977
Validation loss: 2.5193588336477357

Epoch: 379| Step: 0
Training loss: 0.3146815566114412
Validation loss: 2.513005222376421

Epoch: 6| Step: 1
Training loss: 0.28491728711755687
Validation loss: 2.55396902816597

Epoch: 6| Step: 2
Training loss: 0.36173394585281166
Validation loss: 2.4923443244235104

Epoch: 6| Step: 3
Training loss: 0.34473184684182906
Validation loss: 2.5218733029925864

Epoch: 6| Step: 4
Training loss: 0.36927796891836906
Validation loss: 2.517173589544994

Epoch: 6| Step: 5
Training loss: 0.6275595230960438
Validation loss: 2.517241628883231

Epoch: 6| Step: 6
Training loss: 0.6164603960166664
Validation loss: 2.5405721074400254

Epoch: 6| Step: 7
Training loss: 0.6437060998558567
Validation loss: 2.5323802744311106

Epoch: 6| Step: 8
Training loss: 0.36011954594262
Validation loss: 2.535637099582085

Epoch: 6| Step: 9
Training loss: 0.4030761349063997
Validation loss: 2.4971454258764663

Epoch: 6| Step: 10
Training loss: 0.6346290089238489
Validation loss: 2.480383846065909

Epoch: 6| Step: 11
Training loss: 0.5600345144109126
Validation loss: 2.4818013138810255

Epoch: 6| Step: 12
Training loss: 0.4763482503344933
Validation loss: 2.490765625572169

Epoch: 6| Step: 13
Training loss: 0.6053759103784326
Validation loss: 2.5023683548255895

Epoch: 380| Step: 0
Training loss: 0.3016824226892583
Validation loss: 2.535218405854743

Epoch: 6| Step: 1
Training loss: 0.6518099079568855
Validation loss: 2.531617380389516

Epoch: 6| Step: 2
Training loss: 0.3812310190635097
Validation loss: 2.5589469229434307

Epoch: 6| Step: 3
Training loss: 0.5192246643886705
Validation loss: 2.566182266844833

Epoch: 6| Step: 4
Training loss: 0.39844677484226443
Validation loss: 2.5178051973931885

Epoch: 6| Step: 5
Training loss: 0.3437815890102901
Validation loss: 2.559694990420891

Epoch: 6| Step: 6
Training loss: 0.5686933447318112
Validation loss: 2.578659303549007

Epoch: 6| Step: 7
Training loss: 0.6167859328340018
Validation loss: 2.566707491826355

Epoch: 6| Step: 8
Training loss: 0.5694437595559734
Validation loss: 2.565628718878736

Epoch: 6| Step: 9
Training loss: 0.44165621068861577
Validation loss: 2.5625164902839535

Epoch: 6| Step: 10
Training loss: 0.5336982747549498
Validation loss: 2.5756871848778027

Epoch: 6| Step: 11
Training loss: 0.37571187796642275
Validation loss: 2.5692977410714137

Epoch: 6| Step: 12
Training loss: 0.4855143928250706
Validation loss: 2.583172183480144

Epoch: 6| Step: 13
Training loss: 0.19343477763354056
Validation loss: 2.587865871033213

Epoch: 381| Step: 0
Training loss: 0.4461624333139611
Validation loss: 2.577866180245956

Epoch: 6| Step: 1
Training loss: 0.5095797963720151
Validation loss: 2.580995362788792

Epoch: 6| Step: 2
Training loss: 0.5600510374721838
Validation loss: 2.5713874271494612

Epoch: 6| Step: 3
Training loss: 0.5906522401451877
Validation loss: 2.5524226740100273

Epoch: 6| Step: 4
Training loss: 0.41038381530584583
Validation loss: 2.5337326775618036

Epoch: 6| Step: 5
Training loss: 0.5292263758256072
Validation loss: 2.5586523942787176

Epoch: 6| Step: 6
Training loss: 0.505206802863985
Validation loss: 2.547144949697791

Epoch: 6| Step: 7
Training loss: 0.18890576091983863
Validation loss: 2.559567051820907

Epoch: 6| Step: 8
Training loss: 0.5149349450252768
Validation loss: 2.535961772538259

Epoch: 6| Step: 9
Training loss: 0.4030891291605387
Validation loss: 2.525611335542902

Epoch: 6| Step: 10
Training loss: 0.18406920046826825
Validation loss: 2.551071339695877

Epoch: 6| Step: 11
Training loss: 0.3892752980823538
Validation loss: 2.5419326308873997

Epoch: 6| Step: 12
Training loss: 0.5457001191085789
Validation loss: 2.5519518862121284

Epoch: 6| Step: 13
Training loss: 0.3631000066681559
Validation loss: 2.563045214605301

Epoch: 382| Step: 0
Training loss: 0.25517268158891054
Validation loss: 2.523889266823656

Epoch: 6| Step: 1
Training loss: 0.5234933510205977
Validation loss: 2.529094755340377

Epoch: 6| Step: 2
Training loss: 0.403344548492457
Validation loss: 2.5185265230254643

Epoch: 6| Step: 3
Training loss: 0.2664605910290316
Validation loss: 2.5453952718614032

Epoch: 6| Step: 4
Training loss: 0.4476664883173438
Validation loss: 2.516227459458106

Epoch: 6| Step: 5
Training loss: 0.5539308141687743
Validation loss: 2.5373190943189026

Epoch: 6| Step: 6
Training loss: 0.24202236575424968
Validation loss: 2.555659321745118

Epoch: 6| Step: 7
Training loss: 0.3620509366941985
Validation loss: 2.5700798414357298

Epoch: 6| Step: 8
Training loss: 0.6610662745205443
Validation loss: 2.553213237457135

Epoch: 6| Step: 9
Training loss: 0.3248957264957006
Validation loss: 2.5635875722011727

Epoch: 6| Step: 10
Training loss: 0.20535563811201069
Validation loss: 2.551745588310073

Epoch: 6| Step: 11
Training loss: 0.7156435551798996
Validation loss: 2.5656315027183783

Epoch: 6| Step: 12
Training loss: 0.5222023011808853
Validation loss: 2.565210507086868

Epoch: 6| Step: 13
Training loss: 0.31835178061946384
Validation loss: 2.5377245860356608

Epoch: 383| Step: 0
Training loss: 0.7401201869690204
Validation loss: 2.56943931675157

Epoch: 6| Step: 1
Training loss: 0.27707734543680956
Validation loss: 2.6004863320060756

Epoch: 6| Step: 2
Training loss: 0.23656393534478112
Validation loss: 2.546915121068855

Epoch: 6| Step: 3
Training loss: 0.39706048310624903
Validation loss: 2.5532674624393317

Epoch: 6| Step: 4
Training loss: 0.44559416312464684
Validation loss: 2.539947581670401

Epoch: 6| Step: 5
Training loss: 0.5688632684619928
Validation loss: 2.52218870213541

Epoch: 6| Step: 6
Training loss: 0.21416223979863563
Validation loss: 2.521762784013611

Epoch: 6| Step: 7
Training loss: 0.471655550826865
Validation loss: 2.489926772787227

Epoch: 6| Step: 8
Training loss: 0.25763644362663346
Validation loss: 2.5341695995510567

Epoch: 6| Step: 9
Training loss: 0.47846779097652237
Validation loss: 2.5073191826144505

Epoch: 6| Step: 10
Training loss: 0.33952813455597997
Validation loss: 2.5287485831874736

Epoch: 6| Step: 11
Training loss: 0.4748885350197526
Validation loss: 2.5574211534094977

Epoch: 6| Step: 12
Training loss: 0.5715670178434541
Validation loss: 2.5237295208531854

Epoch: 6| Step: 13
Training loss: 0.4188740987651331
Validation loss: 2.547543828744737

Epoch: 384| Step: 0
Training loss: 0.5407395191949366
Validation loss: 2.5423448308632075

Epoch: 6| Step: 1
Training loss: 0.3576955112624608
Validation loss: 2.5160199701567323

Epoch: 6| Step: 2
Training loss: 0.30642929813317576
Validation loss: 2.5286403001300806

Epoch: 6| Step: 3
Training loss: 0.4039166639154989
Validation loss: 2.5111635431735033

Epoch: 6| Step: 4
Training loss: 0.5008337698546849
Validation loss: 2.5375543201499613

Epoch: 6| Step: 5
Training loss: 0.2717671739578737
Validation loss: 2.519639626407686

Epoch: 6| Step: 6
Training loss: 0.43942816769409343
Validation loss: 2.5584516623430096

Epoch: 6| Step: 7
Training loss: 0.25756293557770554
Validation loss: 2.5612841627272602

Epoch: 6| Step: 8
Training loss: 0.5266860816893918
Validation loss: 2.5444617958880023

Epoch: 6| Step: 9
Training loss: 0.33529172973439436
Validation loss: 2.583109491840911

Epoch: 6| Step: 10
Training loss: 0.5985114268564116
Validation loss: 2.532107598997203

Epoch: 6| Step: 11
Training loss: 0.6375521488925636
Validation loss: 2.574584170157014

Epoch: 6| Step: 12
Training loss: 0.5548307207060738
Validation loss: 2.5595735311082026

Epoch: 6| Step: 13
Training loss: 0.289715904769118
Validation loss: 2.575428365505329

Epoch: 385| Step: 0
Training loss: 0.5364830110176226
Validation loss: 2.545421000341219

Epoch: 6| Step: 1
Training loss: 0.5943729746369874
Validation loss: 2.5628015144213796

Epoch: 6| Step: 2
Training loss: 0.4906138588922063
Validation loss: 2.561603861657277

Epoch: 6| Step: 3
Training loss: 0.47809005809086297
Validation loss: 2.5575573707586545

Epoch: 6| Step: 4
Training loss: 0.2894408353392196
Validation loss: 2.5316107910717722

Epoch: 6| Step: 5
Training loss: 0.3168131013940915
Validation loss: 2.5514241235896904

Epoch: 6| Step: 6
Training loss: 0.19419054122669835
Validation loss: 2.5442121365058985

Epoch: 6| Step: 7
Training loss: 0.33446768875331506
Validation loss: 2.5487061976138685

Epoch: 6| Step: 8
Training loss: 0.48418881314238565
Validation loss: 2.5733548570451465

Epoch: 6| Step: 9
Training loss: 0.4604951546369567
Validation loss: 2.558366855285344

Epoch: 6| Step: 10
Training loss: 0.3868890445175171
Validation loss: 2.5542002013686154

Epoch: 6| Step: 11
Training loss: 0.3299240113680822
Validation loss: 2.5935063480570344

Epoch: 6| Step: 12
Training loss: 0.5192137300040301
Validation loss: 2.603083730329939

Epoch: 6| Step: 13
Training loss: 0.6150841908087354
Validation loss: 2.5814370953952417

Epoch: 386| Step: 0
Training loss: 0.5412850105203907
Validation loss: 2.5796021496615493

Epoch: 6| Step: 1
Training loss: 0.5542622937846592
Validation loss: 2.5772020778084723

Epoch: 6| Step: 2
Training loss: 0.34103472067382007
Validation loss: 2.5990457153689746

Epoch: 6| Step: 3
Training loss: 0.5003255439978358
Validation loss: 2.55325571688679

Epoch: 6| Step: 4
Training loss: 0.32185292260832893
Validation loss: 2.5805162027142265

Epoch: 6| Step: 5
Training loss: 0.44252203967278386
Validation loss: 2.563005081470003

Epoch: 6| Step: 6
Training loss: 0.5047434276853889
Validation loss: 2.561865638269678

Epoch: 6| Step: 7
Training loss: 0.3547744257947764
Validation loss: 2.529166384566507

Epoch: 6| Step: 8
Training loss: 0.39068427589805876
Validation loss: 2.5469640447865296

Epoch: 6| Step: 9
Training loss: 0.5004422496933765
Validation loss: 2.5326413698645944

Epoch: 6| Step: 10
Training loss: 0.4735044797093286
Validation loss: 2.5391383026141434

Epoch: 6| Step: 11
Training loss: 0.4159911958927403
Validation loss: 2.5296605299032384

Epoch: 6| Step: 12
Training loss: 0.3167116786730086
Validation loss: 2.5648532729531985

Epoch: 6| Step: 13
Training loss: 0.3962527194967722
Validation loss: 2.530286142835471

Epoch: 387| Step: 0
Training loss: 0.5094084090995677
Validation loss: 2.5422898104761193

Epoch: 6| Step: 1
Training loss: 0.40575973565343465
Validation loss: 2.5732372161144106

Epoch: 6| Step: 2
Training loss: 0.4664489215391427
Validation loss: 2.6202885721965865

Epoch: 6| Step: 3
Training loss: 0.5998412935644373
Validation loss: 2.552275547995256

Epoch: 6| Step: 4
Training loss: 0.4888269655550143
Validation loss: 2.602542067896989

Epoch: 6| Step: 5
Training loss: 0.3525196397666969
Validation loss: 2.578344053009412

Epoch: 6| Step: 6
Training loss: 0.48892249153836864
Validation loss: 2.625977445040529

Epoch: 6| Step: 7
Training loss: 0.31598697952187804
Validation loss: 2.5667948872864135

Epoch: 6| Step: 8
Training loss: 0.44254069426750314
Validation loss: 2.570941056130156

Epoch: 6| Step: 9
Training loss: 0.2570173253980584
Validation loss: 2.5762282965867986

Epoch: 6| Step: 10
Training loss: 0.3752636181573241
Validation loss: 2.5831168643419002

Epoch: 6| Step: 11
Training loss: 0.3628696242580455
Validation loss: 2.5459957934229482

Epoch: 6| Step: 12
Training loss: 0.4981589097814146
Validation loss: 2.510627627598527

Epoch: 6| Step: 13
Training loss: 0.588296743647388
Validation loss: 2.5399342504289932

Epoch: 388| Step: 0
Training loss: 0.6241440156545397
Validation loss: 2.5480381227078213

Epoch: 6| Step: 1
Training loss: 0.413829035888499
Validation loss: 2.540076636137783

Epoch: 6| Step: 2
Training loss: 0.580164482290482
Validation loss: 2.5511824580910596

Epoch: 6| Step: 3
Training loss: 0.3997776829293455
Validation loss: 2.5694064678418416

Epoch: 6| Step: 4
Training loss: 0.25587077515808254
Validation loss: 2.5711165603434147

Epoch: 6| Step: 5
Training loss: 0.46551572490298365
Validation loss: 2.547420846604092

Epoch: 6| Step: 6
Training loss: 0.3328623188144512
Validation loss: 2.5467050207385653

Epoch: 6| Step: 7
Training loss: 0.46993994674116696
Validation loss: 2.5319833324950194

Epoch: 6| Step: 8
Training loss: 0.44286392693992666
Validation loss: 2.5815383981631017

Epoch: 6| Step: 9
Training loss: 0.2699090824877369
Validation loss: 2.578164825678759

Epoch: 6| Step: 10
Training loss: 0.2563730572422765
Validation loss: 2.5692393702120473

Epoch: 6| Step: 11
Training loss: 0.39717476029752896
Validation loss: 2.565914287517469

Epoch: 6| Step: 12
Training loss: 0.5305855466555734
Validation loss: 2.5865246045230026

Epoch: 6| Step: 13
Training loss: 0.6963834765439969
Validation loss: 2.573093942433075

Epoch: 389| Step: 0
Training loss: 0.44802354121622323
Validation loss: 2.5826421786291336

Epoch: 6| Step: 1
Training loss: 0.3482732227336501
Validation loss: 2.5615074332328245

Epoch: 6| Step: 2
Training loss: 0.546116248064382
Validation loss: 2.5710522979359087

Epoch: 6| Step: 3
Training loss: 0.3219088342161282
Validation loss: 2.556433611893422

Epoch: 6| Step: 4
Training loss: 0.5499681734500076
Validation loss: 2.596172265707697

Epoch: 6| Step: 5
Training loss: 0.37349703725152955
Validation loss: 2.5756897373823113

Epoch: 6| Step: 6
Training loss: 0.4353499715852142
Validation loss: 2.5495292883807803

Epoch: 6| Step: 7
Training loss: 0.3927859614958674
Validation loss: 2.5444811924219417

Epoch: 6| Step: 8
Training loss: 0.5329747531880457
Validation loss: 2.529551527043434

Epoch: 6| Step: 9
Training loss: 0.37249741358147115
Validation loss: 2.5621984460947513

Epoch: 6| Step: 10
Training loss: 0.3616526615416703
Validation loss: 2.5628485473845926

Epoch: 6| Step: 11
Training loss: 0.37390509344193873
Validation loss: 2.542801931432964

Epoch: 6| Step: 12
Training loss: 0.6502623560434391
Validation loss: 2.568209692142501

Epoch: 6| Step: 13
Training loss: 0.23434672979883542
Validation loss: 2.5594239434296564

Epoch: 390| Step: 0
Training loss: 0.20707361219763845
Validation loss: 2.588529100030844

Epoch: 6| Step: 1
Training loss: 0.3881435733534382
Validation loss: 2.5765868271053782

Epoch: 6| Step: 2
Training loss: 0.39039555486773
Validation loss: 2.560064138992081

Epoch: 6| Step: 3
Training loss: 0.34446576765586767
Validation loss: 2.55187291342457

Epoch: 6| Step: 4
Training loss: 0.23223759855158138
Validation loss: 2.61782416881603

Epoch: 6| Step: 5
Training loss: 0.31864752337649893
Validation loss: 2.5551399381495297

Epoch: 6| Step: 6
Training loss: 0.49783164965141913
Validation loss: 2.5407106745703087

Epoch: 6| Step: 7
Training loss: 0.45152310328236483
Validation loss: 2.5304010127885164

Epoch: 6| Step: 8
Training loss: 0.5065052519259565
Validation loss: 2.565259987309644

Epoch: 6| Step: 9
Training loss: 0.435889806155189
Validation loss: 2.5472475961188437

Epoch: 6| Step: 10
Training loss: 0.5264592700593156
Validation loss: 2.519314306136696

Epoch: 6| Step: 11
Training loss: 0.45260842244115873
Validation loss: 2.4987475467602476

Epoch: 6| Step: 12
Training loss: 0.4089841534778829
Validation loss: 2.5342302839469832

Epoch: 6| Step: 13
Training loss: 0.783733198055761
Validation loss: 2.543290334926272

Epoch: 391| Step: 0
Training loss: 0.3344875582974191
Validation loss: 2.5468884056347987

Epoch: 6| Step: 1
Training loss: 0.3766159961420541
Validation loss: 2.556489787701943

Epoch: 6| Step: 2
Training loss: 0.4900041320684945
Validation loss: 2.547997252895244

Epoch: 6| Step: 3
Training loss: 0.5243011296178802
Validation loss: 2.5391526466692094

Epoch: 6| Step: 4
Training loss: 0.5268159556310027
Validation loss: 2.571944233129669

Epoch: 6| Step: 5
Training loss: 0.2993578983192613
Validation loss: 2.5595834813745575

Epoch: 6| Step: 6
Training loss: 0.4071193343492427
Validation loss: 2.5565023376772866

Epoch: 6| Step: 7
Training loss: 0.2994761453006205
Validation loss: 2.5902317538291846

Epoch: 6| Step: 8
Training loss: 0.504348413033748
Validation loss: 2.5677955033730138

Epoch: 6| Step: 9
Training loss: 0.33958646747492377
Validation loss: 2.5779875300086794

Epoch: 6| Step: 10
Training loss: 0.37208727299839056
Validation loss: 2.557306220501902

Epoch: 6| Step: 11
Training loss: 0.42664651707043805
Validation loss: 2.5522859762042027

Epoch: 6| Step: 12
Training loss: 0.2974247610494733
Validation loss: 2.53284798186887

Epoch: 6| Step: 13
Training loss: 0.5086860772166993
Validation loss: 2.5438070687063767

Epoch: 392| Step: 0
Training loss: 0.4974008896122989
Validation loss: 2.52054802373186

Epoch: 6| Step: 1
Training loss: 0.435329485641965
Validation loss: 2.522746163206853

Epoch: 6| Step: 2
Training loss: 0.5377103737614181
Validation loss: 2.513734557498833

Epoch: 6| Step: 3
Training loss: 0.5229331761169214
Validation loss: 2.491222277098889

Epoch: 6| Step: 4
Training loss: 0.25927432645777004
Validation loss: 2.5104748257869103

Epoch: 6| Step: 5
Training loss: 0.3857408547680201
Validation loss: 2.5133274515938937

Epoch: 6| Step: 6
Training loss: 0.32843375438873684
Validation loss: 2.5398834431022523

Epoch: 6| Step: 7
Training loss: 0.4643704224434034
Validation loss: 2.568162867168829

Epoch: 6| Step: 8
Training loss: 0.29762219211642904
Validation loss: 2.558502238212932

Epoch: 6| Step: 9
Training loss: 0.3990471047259951
Validation loss: 2.549161471376429

Epoch: 6| Step: 10
Training loss: 0.5039606582484945
Validation loss: 2.5295372134231506

Epoch: 6| Step: 11
Training loss: 0.17981381744734817
Validation loss: 2.541881177683476

Epoch: 6| Step: 12
Training loss: 0.3302584499791272
Validation loss: 2.584167133210133

Epoch: 6| Step: 13
Training loss: 0.4029020306428347
Validation loss: 2.5763768110681426

Epoch: 393| Step: 0
Training loss: 0.5519464761019025
Validation loss: 2.5664897355777305

Epoch: 6| Step: 1
Training loss: 0.31092736788396547
Validation loss: 2.6114896846617612

Epoch: 6| Step: 2
Training loss: 0.3974267818387227
Validation loss: 2.5929403947875445

Epoch: 6| Step: 3
Training loss: 0.5778838763140116
Validation loss: 2.5796820578985398

Epoch: 6| Step: 4
Training loss: 0.6157007538713875
Validation loss: 2.569878711233243

Epoch: 6| Step: 5
Training loss: 0.2568583170492343
Validation loss: 2.530354572229404

Epoch: 6| Step: 6
Training loss: 0.32661322468956777
Validation loss: 2.550710851912113

Epoch: 6| Step: 7
Training loss: 0.31442611293991574
Validation loss: 2.5508809396112073

Epoch: 6| Step: 8
Training loss: 0.4855365669218149
Validation loss: 2.5266954694593227

Epoch: 6| Step: 9
Training loss: 0.2497757412481854
Validation loss: 2.5260966660441015

Epoch: 6| Step: 10
Training loss: 0.20046681857349372
Validation loss: 2.5163289132854474

Epoch: 6| Step: 11
Training loss: 0.5580228542480942
Validation loss: 2.5236849302730278

Epoch: 6| Step: 12
Training loss: 0.4164604352154088
Validation loss: 2.5063278433899363

Epoch: 6| Step: 13
Training loss: 0.15258106674194583
Validation loss: 2.513875408049968

Epoch: 394| Step: 0
Training loss: 0.462431974176666
Validation loss: 2.463163457693389

Epoch: 6| Step: 1
Training loss: 0.31428665588287397
Validation loss: 2.5010391475264035

Epoch: 6| Step: 2
Training loss: 0.4764161119600734
Validation loss: 2.5205586747441635

Epoch: 6| Step: 3
Training loss: 0.37843137655808745
Validation loss: 2.505806130379787

Epoch: 6| Step: 4
Training loss: 0.497859874849003
Validation loss: 2.4925920536969035

Epoch: 6| Step: 5
Training loss: 0.22394974917587046
Validation loss: 2.5070877200901696

Epoch: 6| Step: 6
Training loss: 0.521119064791364
Validation loss: 2.5326902241397136

Epoch: 6| Step: 7
Training loss: 0.15991311109389258
Validation loss: 2.5364725392527845

Epoch: 6| Step: 8
Training loss: 0.4013545273317917
Validation loss: 2.5662303237500774

Epoch: 6| Step: 9
Training loss: 0.256746341757263
Validation loss: 2.5768722001100333

Epoch: 6| Step: 10
Training loss: 0.523690176940916
Validation loss: 2.5853379900462943

Epoch: 6| Step: 11
Training loss: 0.5500170770074757
Validation loss: 2.542151082854277

Epoch: 6| Step: 12
Training loss: 0.44258877504872773
Validation loss: 2.5580014285051584

Epoch: 6| Step: 13
Training loss: 0.4323765621548588
Validation loss: 2.576906846059862

Epoch: 395| Step: 0
Training loss: 0.3548388926863548
Validation loss: 2.553453392017617

Epoch: 6| Step: 1
Training loss: 0.4655916304439898
Validation loss: 2.531810210844294

Epoch: 6| Step: 2
Training loss: 0.4698748285171995
Validation loss: 2.532268361349642

Epoch: 6| Step: 3
Training loss: 0.48275127825180075
Validation loss: 2.5200078906554095

Epoch: 6| Step: 4
Training loss: 0.352708580282132
Validation loss: 2.486374091823746

Epoch: 6| Step: 5
Training loss: 0.34700365644707937
Validation loss: 2.506184882876276

Epoch: 6| Step: 6
Training loss: 0.5900933451276142
Validation loss: 2.5164687888587585

Epoch: 6| Step: 7
Training loss: 0.4281579276460551
Validation loss: 2.5060970345332962

Epoch: 6| Step: 8
Training loss: 0.14966549629997777
Validation loss: 2.4940748058040447

Epoch: 6| Step: 9
Training loss: 0.4861110064718346
Validation loss: 2.515902960993784

Epoch: 6| Step: 10
Training loss: 0.6484167486340354
Validation loss: 2.5545445648354344

Epoch: 6| Step: 11
Training loss: 0.33789915834797907
Validation loss: 2.562200137045447

Epoch: 6| Step: 12
Training loss: 0.3648509496595192
Validation loss: 2.6193164123706745

Epoch: 6| Step: 13
Training loss: 0.3887795150689916
Validation loss: 2.588472173060069

Epoch: 396| Step: 0
Training loss: 0.3147923553016615
Validation loss: 2.5978528528405125

Epoch: 6| Step: 1
Training loss: 0.42804697885109966
Validation loss: 2.55473193278989

Epoch: 6| Step: 2
Training loss: 0.5185768137088865
Validation loss: 2.5935254375980277

Epoch: 6| Step: 3
Training loss: 0.2737588764955014
Validation loss: 2.5365253655332642

Epoch: 6| Step: 4
Training loss: 0.5688539692933623
Validation loss: 2.5045754105148323

Epoch: 6| Step: 5
Training loss: 0.6476422454461039
Validation loss: 2.5278312924301525

Epoch: 6| Step: 6
Training loss: 0.4202814026854356
Validation loss: 2.5325377133658202

Epoch: 6| Step: 7
Training loss: 0.4902778393448505
Validation loss: 2.577332743766646

Epoch: 6| Step: 8
Training loss: 0.29829382658592646
Validation loss: 2.5873757872575696

Epoch: 6| Step: 9
Training loss: 0.3336556026641463
Validation loss: 2.582127237623135

Epoch: 6| Step: 10
Training loss: 0.17340343544621892
Validation loss: 2.600051050103052

Epoch: 6| Step: 11
Training loss: 0.3305877047598235
Validation loss: 2.5737867810009263

Epoch: 6| Step: 12
Training loss: 0.4382320988475916
Validation loss: 2.5683370060755477

Epoch: 6| Step: 13
Training loss: 0.5089271929012358
Validation loss: 2.587188583624355

Epoch: 397| Step: 0
Training loss: 0.34827367198464443
Validation loss: 2.566192116061254

Epoch: 6| Step: 1
Training loss: 0.3263372013691949
Validation loss: 2.5303732435885404

Epoch: 6| Step: 2
Training loss: 0.6783389602149696
Validation loss: 2.538786676789749

Epoch: 6| Step: 3
Training loss: 0.3574351532350954
Validation loss: 2.556621544830671

Epoch: 6| Step: 4
Training loss: 0.45594792882902985
Validation loss: 2.5402263761170287

Epoch: 6| Step: 5
Training loss: 0.4146178497949175
Validation loss: 2.547454647233029

Epoch: 6| Step: 6
Training loss: 0.36547378608329273
Validation loss: 2.519111346859001

Epoch: 6| Step: 7
Training loss: 0.19940917880572664
Validation loss: 2.5459942231144606

Epoch: 6| Step: 8
Training loss: 0.5796800525526196
Validation loss: 2.5156549171580096

Epoch: 6| Step: 9
Training loss: 0.325595929702447
Validation loss: 2.5494903175729986

Epoch: 6| Step: 10
Training loss: 0.48328014429152766
Validation loss: 2.5528378466015966

Epoch: 6| Step: 11
Training loss: 0.32520704276891654
Validation loss: 2.564511516829002

Epoch: 6| Step: 12
Training loss: 0.28026732328438114
Validation loss: 2.541205556172263

Epoch: 6| Step: 13
Training loss: 0.392624012556902
Validation loss: 2.5313438166211197

Epoch: 398| Step: 0
Training loss: 0.48584018113014354
Validation loss: 2.561665120594679

Epoch: 6| Step: 1
Training loss: 0.17468582139718541
Validation loss: 2.5421799622714696

Epoch: 6| Step: 2
Training loss: 0.5127704093066627
Validation loss: 2.4966241295946583

Epoch: 6| Step: 3
Training loss: 0.47932054978825006
Validation loss: 2.47654404922361

Epoch: 6| Step: 4
Training loss: 0.22987045604908998
Validation loss: 2.49810049230101

Epoch: 6| Step: 5
Training loss: 0.3821911537638299
Validation loss: 2.4889801193237195

Epoch: 6| Step: 6
Training loss: 0.19540235359898483
Validation loss: 2.5212533953880016

Epoch: 6| Step: 7
Training loss: 0.32743274234694575
Validation loss: 2.5336894873318974

Epoch: 6| Step: 8
Training loss: 0.49042911385183996
Validation loss: 2.529176786423128

Epoch: 6| Step: 9
Training loss: 0.4329054756694597
Validation loss: 2.533309972347174

Epoch: 6| Step: 10
Training loss: 0.4148873444548422
Validation loss: 2.5386807536993494

Epoch: 6| Step: 11
Training loss: 0.5839220607006297
Validation loss: 2.5792271003267446

Epoch: 6| Step: 12
Training loss: 0.318689327449463
Validation loss: 2.5414535887708056

Epoch: 6| Step: 13
Training loss: 0.41918874217324686
Validation loss: 2.5698733592505714

Epoch: 399| Step: 0
Training loss: 0.2922610700263059
Validation loss: 2.5649435706508865

Epoch: 6| Step: 1
Training loss: 0.18979535211976092
Validation loss: 2.580174914579763

Epoch: 6| Step: 2
Training loss: 0.21861290893413923
Validation loss: 2.5825192259978875

Epoch: 6| Step: 3
Training loss: 0.4038846775691249
Validation loss: 2.5789654746133253

Epoch: 6| Step: 4
Training loss: 0.7053919381773637
Validation loss: 2.5405911275187374

Epoch: 6| Step: 5
Training loss: 0.18711382117991587
Validation loss: 2.5845657704177394

Epoch: 6| Step: 6
Training loss: 0.5287025465086277
Validation loss: 2.570368145578691

Epoch: 6| Step: 7
Training loss: 0.47910936849201174
Validation loss: 2.5889173197025404

Epoch: 6| Step: 8
Training loss: 0.6831746369709933
Validation loss: 2.543106291373613

Epoch: 6| Step: 9
Training loss: 0.2709586727664829
Validation loss: 2.54894397374724

Epoch: 6| Step: 10
Training loss: 0.1865454056670199
Validation loss: 2.529571505370355

Epoch: 6| Step: 11
Training loss: 0.5114714046550854
Validation loss: 2.5171994888497715

Epoch: 6| Step: 12
Training loss: 0.4355516647280778
Validation loss: 2.4735712969908143

Epoch: 6| Step: 13
Training loss: 0.3254942908592084
Validation loss: 2.52431029869768

Epoch: 400| Step: 0
Training loss: 0.5069902659164566
Validation loss: 2.5132952840828895

Epoch: 6| Step: 1
Training loss: 0.4028265195527291
Validation loss: 2.4975528717496718

Epoch: 6| Step: 2
Training loss: 0.5558512394216572
Validation loss: 2.541505106614724

Epoch: 6| Step: 3
Training loss: 0.4229416960401979
Validation loss: 2.559740308768848

Epoch: 6| Step: 4
Training loss: 0.5443542148900987
Validation loss: 2.5858494373982395

Epoch: 6| Step: 5
Training loss: 0.5500977516004932
Validation loss: 2.6344539306207406

Epoch: 6| Step: 6
Training loss: 0.3549256000327519
Validation loss: 2.644311147452462

Epoch: 6| Step: 7
Training loss: 0.38105491118079915
Validation loss: 2.650772806044282

Epoch: 6| Step: 8
Training loss: 0.3021525298262504
Validation loss: 2.6631297361475883

Epoch: 6| Step: 9
Training loss: 0.432165818873887
Validation loss: 2.618138186695201

Epoch: 6| Step: 10
Training loss: 0.25230439413608496
Validation loss: 2.627644655473526

Epoch: 6| Step: 11
Training loss: 0.4446630929346233
Validation loss: 2.5386575113035166

Epoch: 6| Step: 12
Training loss: 0.4130172131232612
Validation loss: 2.5805374368492577

Epoch: 6| Step: 13
Training loss: 0.2626757135844266
Validation loss: 2.5634685849770262

Epoch: 401| Step: 0
Training loss: 0.34668598437970843
Validation loss: 2.5506299988527643

Epoch: 6| Step: 1
Training loss: 0.4316962538555534
Validation loss: 2.5404145922244306

Epoch: 6| Step: 2
Training loss: 0.5441165565485859
Validation loss: 2.5417073392984313

Epoch: 6| Step: 3
Training loss: 0.4843904431250049
Validation loss: 2.5331416660757644

Epoch: 6| Step: 4
Training loss: 0.4114702520776917
Validation loss: 2.5942127137762374

Epoch: 6| Step: 5
Training loss: 0.4173442953114034
Validation loss: 2.5769361850698105

Epoch: 6| Step: 6
Training loss: 0.3624039177332306
Validation loss: 2.5585501407782307

Epoch: 6| Step: 7
Training loss: 0.4106146657563599
Validation loss: 2.5744424183407775

Epoch: 6| Step: 8
Training loss: 0.22940100623777315
Validation loss: 2.5800131030813978

Epoch: 6| Step: 9
Training loss: 0.32898655814825906
Validation loss: 2.598198884634649

Epoch: 6| Step: 10
Training loss: 0.5241098214009312
Validation loss: 2.5751369269866005

Epoch: 6| Step: 11
Training loss: 0.397977638399983
Validation loss: 2.587662722643942

Epoch: 6| Step: 12
Training loss: 0.20991609671178263
Validation loss: 2.5972112083965597

Epoch: 6| Step: 13
Training loss: 0.56124913689222
Validation loss: 2.5618597651965893

Epoch: 402| Step: 0
Training loss: 0.2297758338032572
Validation loss: 2.520736834527329

Epoch: 6| Step: 1
Training loss: 0.5754384691038202
Validation loss: 2.5464635028757057

Epoch: 6| Step: 2
Training loss: 0.21939259898678706
Validation loss: 2.5053229239353314

Epoch: 6| Step: 3
Training loss: 0.5652356383039993
Validation loss: 2.53466028034896

Epoch: 6| Step: 4
Training loss: 0.4972497132925259
Validation loss: 2.5091150424311737

Epoch: 6| Step: 5
Training loss: 0.3403087263187063
Validation loss: 2.5326192184159693

Epoch: 6| Step: 6
Training loss: 0.3485742407571283
Validation loss: 2.526603396929287

Epoch: 6| Step: 7
Training loss: 0.4577019815202442
Validation loss: 2.524962170574485

Epoch: 6| Step: 8
Training loss: 0.412998145042715
Validation loss: 2.52780323030024

Epoch: 6| Step: 9
Training loss: 0.4733485991351161
Validation loss: 2.5165698708077033

Epoch: 6| Step: 10
Training loss: 0.41221205168999087
Validation loss: 2.5545024485564305

Epoch: 6| Step: 11
Training loss: 0.3447418101453444
Validation loss: 2.5073296377861913

Epoch: 6| Step: 12
Training loss: 0.14166140114124035
Validation loss: 2.5369009970158776

Epoch: 6| Step: 13
Training loss: 0.3876457278735218
Validation loss: 2.540929642735049

Epoch: 403| Step: 0
Training loss: 0.3350033079880752
Validation loss: 2.5612616083963315

Epoch: 6| Step: 1
Training loss: 0.4873903921592273
Validation loss: 2.5562456821886874

Epoch: 6| Step: 2
Training loss: 0.4127798186193689
Validation loss: 2.607761631211225

Epoch: 6| Step: 3
Training loss: 0.2204189665541579
Validation loss: 2.6124880659778067

Epoch: 6| Step: 4
Training loss: 0.19314337717043806
Validation loss: 2.598506392935186

Epoch: 6| Step: 5
Training loss: 0.3276000478492662
Validation loss: 2.5705244062569053

Epoch: 6| Step: 6
Training loss: 0.36048415311090826
Validation loss: 2.572429718679442

Epoch: 6| Step: 7
Training loss: 0.6689426171464289
Validation loss: 2.5808483507806685

Epoch: 6| Step: 8
Training loss: 0.260260576516963
Validation loss: 2.545961039988939

Epoch: 6| Step: 9
Training loss: 0.5750052845753518
Validation loss: 2.5521206887989245

Epoch: 6| Step: 10
Training loss: 0.2994415992172776
Validation loss: 2.545893938358828

Epoch: 6| Step: 11
Training loss: 0.42664663931228136
Validation loss: 2.5431522954459758

Epoch: 6| Step: 12
Training loss: 0.15855123344619493
Validation loss: 2.537921343017365

Epoch: 6| Step: 13
Training loss: 0.4787038938765999
Validation loss: 2.5611886251298888

Epoch: 404| Step: 0
Training loss: 0.4094997055905021
Validation loss: 2.5208272460142624

Epoch: 6| Step: 1
Training loss: 0.3849376545624098
Validation loss: 2.5374890491542894

Epoch: 6| Step: 2
Training loss: 0.6015228407035823
Validation loss: 2.5019765833585823

Epoch: 6| Step: 3
Training loss: 0.39872768530994096
Validation loss: 2.516836948687575

Epoch: 6| Step: 4
Training loss: 0.3049330822045463
Validation loss: 2.5422938864186415

Epoch: 6| Step: 5
Training loss: 0.25444318778310965
Validation loss: 2.5268300696779757

Epoch: 6| Step: 6
Training loss: 0.5035547020829089
Validation loss: 2.5492265108875043

Epoch: 6| Step: 7
Training loss: 0.5991734215254378
Validation loss: 2.5468176976148262

Epoch: 6| Step: 8
Training loss: 0.42141645731036614
Validation loss: 2.5650893454183112

Epoch: 6| Step: 9
Training loss: 0.36186872714046264
Validation loss: 2.5752017216052794

Epoch: 6| Step: 10
Training loss: 0.39336400109822023
Validation loss: 2.598311387609618

Epoch: 6| Step: 11
Training loss: 0.3642706574739652
Validation loss: 2.565113194830105

Epoch: 6| Step: 12
Training loss: 0.2854476902568767
Validation loss: 2.57876993603957

Epoch: 6| Step: 13
Training loss: 0.2601823404191371
Validation loss: 2.5066914734199828

Epoch: 405| Step: 0
Training loss: 0.3053367983423283
Validation loss: 2.521222937618237

Epoch: 6| Step: 1
Training loss: 0.4235278529372427
Validation loss: 2.523434670120126

Epoch: 6| Step: 2
Training loss: 0.36656733146273723
Validation loss: 2.5212163252014355

Epoch: 6| Step: 3
Training loss: 0.6983012567890411
Validation loss: 2.5799232056274692

Epoch: 6| Step: 4
Training loss: 0.3446023733551581
Validation loss: 2.5818883769375764

Epoch: 6| Step: 5
Training loss: 0.404783205181799
Validation loss: 2.5687270019721713

Epoch: 6| Step: 6
Training loss: 0.40044376671919896
Validation loss: 2.5194707991850693

Epoch: 6| Step: 7
Training loss: 0.4042521650130143
Validation loss: 2.6053619286612024

Epoch: 6| Step: 8
Training loss: 0.44745362174665293
Validation loss: 2.5528043457151033

Epoch: 6| Step: 9
Training loss: 0.3286481388190524
Validation loss: 2.5657676064103567

Epoch: 6| Step: 10
Training loss: 0.3748136892027927
Validation loss: 2.5715143285388766

Epoch: 6| Step: 11
Training loss: 0.5138205251527547
Validation loss: 2.5655301034575113

Epoch: 6| Step: 12
Training loss: 0.25433712126617947
Validation loss: 2.5428792376555736

Epoch: 6| Step: 13
Training loss: 0.307857226012427
Validation loss: 2.55109565831249

Epoch: 406| Step: 0
Training loss: 0.36560623088166044
Validation loss: 2.544794481655441

Epoch: 6| Step: 1
Training loss: 0.3714907881286479
Validation loss: 2.5708229577161

Epoch: 6| Step: 2
Training loss: 0.581352965146288
Validation loss: 2.5301444190065796

Epoch: 6| Step: 3
Training loss: 0.4002192060525023
Validation loss: 2.541051188614457

Epoch: 6| Step: 4
Training loss: 0.40994935039776337
Validation loss: 2.5085334885077217

Epoch: 6| Step: 5
Training loss: 0.38297799484070055
Validation loss: 2.520382877444421

Epoch: 6| Step: 6
Training loss: 0.48170431726087826
Validation loss: 2.500994072442593

Epoch: 6| Step: 7
Training loss: 0.29860071492518353
Validation loss: 2.4804777148292034

Epoch: 6| Step: 8
Training loss: 0.407349602203999
Validation loss: 2.4881565874567015

Epoch: 6| Step: 9
Training loss: 0.41555812914404705
Validation loss: 2.5071806217820685

Epoch: 6| Step: 10
Training loss: 0.43209942216020125
Validation loss: 2.5189719976382707

Epoch: 6| Step: 11
Training loss: 0.44305480040496176
Validation loss: 2.56886899731525

Epoch: 6| Step: 12
Training loss: 0.4794508844366458
Validation loss: 2.611421128314471

Epoch: 6| Step: 13
Training loss: 0.21143368360450654
Validation loss: 2.65066324734801

Epoch: 407| Step: 0
Training loss: 0.3626354589259082
Validation loss: 2.6541224337110183

Epoch: 6| Step: 1
Training loss: 0.3091729318214461
Validation loss: 2.676269611235961

Epoch: 6| Step: 2
Training loss: 0.4175608061293761
Validation loss: 2.666106547537949

Epoch: 6| Step: 3
Training loss: 0.37922951584392495
Validation loss: 2.624897886009936

Epoch: 6| Step: 4
Training loss: 0.44603763902185917
Validation loss: 2.6694183483325546

Epoch: 6| Step: 5
Training loss: 0.39006276677077756
Validation loss: 2.619612699640747

Epoch: 6| Step: 6
Training loss: 0.27214528329049925
Validation loss: 2.5556893891769272

Epoch: 6| Step: 7
Training loss: 0.49510499837644856
Validation loss: 2.5429113696722623

Epoch: 6| Step: 8
Training loss: 0.6436727412630409
Validation loss: 2.5613086275983905

Epoch: 6| Step: 9
Training loss: 0.3430482572363935
Validation loss: 2.5511085991045936

Epoch: 6| Step: 10
Training loss: 0.44721974633138994
Validation loss: 2.5592201586437064

Epoch: 6| Step: 11
Training loss: 0.2804895026729763
Validation loss: 2.537850720031406

Epoch: 6| Step: 12
Training loss: 0.5242270876907881
Validation loss: 2.524373050644636

Epoch: 6| Step: 13
Training loss: 0.3740692110662676
Validation loss: 2.527676276455501

Epoch: 408| Step: 0
Training loss: 0.5583441917113228
Validation loss: 2.5342386686231473

Epoch: 6| Step: 1
Training loss: 0.3636645479211938
Validation loss: 2.521676720698512

Epoch: 6| Step: 2
Training loss: 0.27362559524809466
Validation loss: 2.490133076456698

Epoch: 6| Step: 3
Training loss: 0.3357902692148872
Validation loss: 2.513105033846632

Epoch: 6| Step: 4
Training loss: 0.27294306330146245
Validation loss: 2.51473679859306

Epoch: 6| Step: 5
Training loss: 0.5673480392541855
Validation loss: 2.4849377494806464

Epoch: 6| Step: 6
Training loss: 0.3047658134954672
Validation loss: 2.4871746955129903

Epoch: 6| Step: 7
Training loss: 0.41840826081956545
Validation loss: 2.467119883062383

Epoch: 6| Step: 8
Training loss: 0.3425107095777324
Validation loss: 2.5055132657662442

Epoch: 6| Step: 9
Training loss: 0.5231830490883602
Validation loss: 2.4980307360142704

Epoch: 6| Step: 10
Training loss: 0.4151055136945528
Validation loss: 2.5191148344342476

Epoch: 6| Step: 11
Training loss: 0.3291409975416935
Validation loss: 2.5401873433253335

Epoch: 6| Step: 12
Training loss: 0.314089606429598
Validation loss: 2.5187337910824694

Epoch: 6| Step: 13
Training loss: 0.15715319538807818
Validation loss: 2.5274747230143246

Epoch: 409| Step: 0
Training loss: 0.346259945647421
Validation loss: 2.5183011668764563

Epoch: 6| Step: 1
Training loss: 0.18475832773520923
Validation loss: 2.5454337262518925

Epoch: 6| Step: 2
Training loss: 0.41543298315580174
Validation loss: 2.585961342522509

Epoch: 6| Step: 3
Training loss: 0.3849007035370163
Validation loss: 2.521908229788833

Epoch: 6| Step: 4
Training loss: 0.3900347637308293
Validation loss: 2.569920518164058

Epoch: 6| Step: 5
Training loss: 0.5256550346892493
Validation loss: 2.525118561321443

Epoch: 6| Step: 6
Training loss: 0.32741249018230634
Validation loss: 2.505693644279424

Epoch: 6| Step: 7
Training loss: 0.5149454204562743
Validation loss: 2.5032511480246673

Epoch: 6| Step: 8
Training loss: 0.44232539463261694
Validation loss: 2.529031818473356

Epoch: 6| Step: 9
Training loss: 0.43989342566531425
Validation loss: 2.5347380280593046

Epoch: 6| Step: 10
Training loss: 0.3948401007051526
Validation loss: 2.5356703798985087

Epoch: 6| Step: 11
Training loss: 0.2451997822975068
Validation loss: 2.526880604798911

Epoch: 6| Step: 12
Training loss: 0.30503857999830153
Validation loss: 2.5428103548896903

Epoch: 6| Step: 13
Training loss: 0.604059042607422
Validation loss: 2.5934979192366314

Epoch: 410| Step: 0
Training loss: 0.22915719113845281
Validation loss: 2.523905564480503

Epoch: 6| Step: 1
Training loss: 0.42564711951588824
Validation loss: 2.523055994322963

Epoch: 6| Step: 2
Training loss: 0.3978046927094265
Validation loss: 2.5564950212948347

Epoch: 6| Step: 3
Training loss: 0.17739796502995447
Validation loss: 2.523592099779612

Epoch: 6| Step: 4
Training loss: 0.3361608849284203
Validation loss: 2.539470022610373

Epoch: 6| Step: 5
Training loss: 0.3022142926620012
Validation loss: 2.526022338962393

Epoch: 6| Step: 6
Training loss: 0.3692561781126845
Validation loss: 2.547896263416436

Epoch: 6| Step: 7
Training loss: 0.5210087925687041
Validation loss: 2.5343363146495275

Epoch: 6| Step: 8
Training loss: 0.5452152679239461
Validation loss: 2.5138081087570625

Epoch: 6| Step: 9
Training loss: 0.15444234437033091
Validation loss: 2.5371639734611335

Epoch: 6| Step: 10
Training loss: 0.34885085524161263
Validation loss: 2.536370894056145

Epoch: 6| Step: 11
Training loss: 0.35970840330390924
Validation loss: 2.4998018350304796

Epoch: 6| Step: 12
Training loss: 0.39753163901556576
Validation loss: 2.5030418389658333

Epoch: 6| Step: 13
Training loss: 0.4894924705138639
Validation loss: 2.5420251345065172

Epoch: 411| Step: 0
Training loss: 0.4093603313526168
Validation loss: 2.527436898637452

Epoch: 6| Step: 1
Training loss: 0.4159772971679894
Validation loss: 2.542619528269094

Epoch: 6| Step: 2
Training loss: 0.3897217989819048
Validation loss: 2.5398536907149927

Epoch: 6| Step: 3
Training loss: 0.29890609172890636
Validation loss: 2.55035375803037

Epoch: 6| Step: 4
Training loss: 0.4773095014057623
Validation loss: 2.5159789325378488

Epoch: 6| Step: 5
Training loss: 0.36100176944985873
Validation loss: 2.556533865270044

Epoch: 6| Step: 6
Training loss: 0.33879408473846057
Validation loss: 2.5763112454598853

Epoch: 6| Step: 7
Training loss: 0.334154398065478
Validation loss: 2.575101474722239

Epoch: 6| Step: 8
Training loss: 0.40750716168013834
Validation loss: 2.577881638422516

Epoch: 6| Step: 9
Training loss: 0.4983326409993205
Validation loss: 2.578500270286536

Epoch: 6| Step: 10
Training loss: 0.4189601619907548
Validation loss: 2.560177598767397

Epoch: 6| Step: 11
Training loss: 0.2535017753309425
Validation loss: 2.5530321264053955

Epoch: 6| Step: 12
Training loss: 0.23426274154334725
Validation loss: 2.491698301510058

Epoch: 6| Step: 13
Training loss: 0.3299653803121072
Validation loss: 2.517746305282238

Epoch: 412| Step: 0
Training loss: 0.19473398360915736
Validation loss: 2.4723983594133716

Epoch: 6| Step: 1
Training loss: 0.31038614828173283
Validation loss: 2.505451454527972

Epoch: 6| Step: 2
Training loss: 0.3631781154792781
Validation loss: 2.530972578878047

Epoch: 6| Step: 3
Training loss: 0.5119318045372798
Validation loss: 2.5221259588611367

Epoch: 6| Step: 4
Training loss: 0.22242972077070688
Validation loss: 2.5233846212068776

Epoch: 6| Step: 5
Training loss: 0.47971581179790246
Validation loss: 2.5153692532417047

Epoch: 6| Step: 6
Training loss: 0.24684925518520415
Validation loss: 2.5251770210898528

Epoch: 6| Step: 7
Training loss: 0.5232654687387498
Validation loss: 2.536665139088358

Epoch: 6| Step: 8
Training loss: 0.25819459690432406
Validation loss: 2.542307632340399

Epoch: 6| Step: 9
Training loss: 0.3494337269349559
Validation loss: 2.545684637941435

Epoch: 6| Step: 10
Training loss: 0.471641554781781
Validation loss: 2.552227133909618

Epoch: 6| Step: 11
Training loss: 0.3895946455994398
Validation loss: 2.5715284640854925

Epoch: 6| Step: 12
Training loss: 0.24536669521250215
Validation loss: 2.5851607450310543

Epoch: 6| Step: 13
Training loss: 0.13511162721343367
Validation loss: 2.580883117185236

Epoch: 413| Step: 0
Training loss: 0.29007503658903655
Validation loss: 2.559719008273753

Epoch: 6| Step: 1
Training loss: 0.5791288372647941
Validation loss: 2.551748868025541

Epoch: 6| Step: 2
Training loss: 0.3276551720415465
Validation loss: 2.5458593889592205

Epoch: 6| Step: 3
Training loss: 0.3420572978139392
Validation loss: 2.585510181175133

Epoch: 6| Step: 4
Training loss: 0.43662440009284775
Validation loss: 2.5035078531553077

Epoch: 6| Step: 5
Training loss: 0.19302495300115521
Validation loss: 2.543131302083325

Epoch: 6| Step: 6
Training loss: 0.3844740096560864
Validation loss: 2.495764064229882

Epoch: 6| Step: 7
Training loss: 0.4314748005354701
Validation loss: 2.566848839337184

Epoch: 6| Step: 8
Training loss: 0.19687165681331617
Validation loss: 2.532020198472149

Epoch: 6| Step: 9
Training loss: 0.2652365986389524
Validation loss: 2.517171382541188

Epoch: 6| Step: 10
Training loss: 0.24634177712436003
Validation loss: 2.54606909287528

Epoch: 6| Step: 11
Training loss: 0.40157526196339033
Validation loss: 2.551655691119535

Epoch: 6| Step: 12
Training loss: 0.41028743644104637
Validation loss: 2.5328606257066033

Epoch: 6| Step: 13
Training loss: 0.5040988406226461
Validation loss: 2.5539791182118865

Epoch: 414| Step: 0
Training loss: 0.3126775594767133
Validation loss: 2.545467257168308

Epoch: 6| Step: 1
Training loss: 0.379992922635427
Validation loss: 2.576216505952553

Epoch: 6| Step: 2
Training loss: 0.2369554956721927
Validation loss: 2.5585043158764256

Epoch: 6| Step: 3
Training loss: 0.3579785956798322
Validation loss: 2.5801623009010406

Epoch: 6| Step: 4
Training loss: 0.4024797598565579
Validation loss: 2.585480440460536

Epoch: 6| Step: 5
Training loss: 0.3333356256207484
Validation loss: 2.5924665347238185

Epoch: 6| Step: 6
Training loss: 0.5519140511819937
Validation loss: 2.5315539928113555

Epoch: 6| Step: 7
Training loss: 0.40866816191389366
Validation loss: 2.5557513666536784

Epoch: 6| Step: 8
Training loss: 0.4113387183467273
Validation loss: 2.5723260958416136

Epoch: 6| Step: 9
Training loss: 0.2753489307197159
Validation loss: 2.56489188239966

Epoch: 6| Step: 10
Training loss: 0.38612126905738764
Validation loss: 2.5041947346359317

Epoch: 6| Step: 11
Training loss: 0.3948718574159778
Validation loss: 2.5435701201069634

Epoch: 6| Step: 12
Training loss: 0.4188305535341231
Validation loss: 2.556516595337207

Epoch: 6| Step: 13
Training loss: 0.19459343150039124
Validation loss: 2.593657935621676

Epoch: 415| Step: 0
Training loss: 0.4860764124006075
Validation loss: 2.597286939833713

Epoch: 6| Step: 1
Training loss: 0.35489585319245043
Validation loss: 2.5600619148883026

Epoch: 6| Step: 2
Training loss: 0.4632505152576461
Validation loss: 2.5333104914891367

Epoch: 6| Step: 3
Training loss: 0.2862004925881218
Validation loss: 2.5452323894571593

Epoch: 6| Step: 4
Training loss: 0.3892622829243717
Validation loss: 2.539741499787626

Epoch: 6| Step: 5
Training loss: 0.48338071231904617
Validation loss: 2.50869833775084

Epoch: 6| Step: 6
Training loss: 0.3733821979578548
Validation loss: 2.544712149079898

Epoch: 6| Step: 7
Training loss: 0.4345707925515256
Validation loss: 2.4853877482951146

Epoch: 6| Step: 8
Training loss: 0.4648507542443103
Validation loss: 2.548206044191273

Epoch: 6| Step: 9
Training loss: 0.4970793058110184
Validation loss: 2.519841748814846

Epoch: 6| Step: 10
Training loss: 0.15952136807748357
Validation loss: 2.5334101303692296

Epoch: 6| Step: 11
Training loss: 0.271130351583164
Validation loss: 2.5340845013691173

Epoch: 6| Step: 12
Training loss: 0.39183881997215825
Validation loss: 2.5774812025667795

Epoch: 6| Step: 13
Training loss: 0.40610219027124195
Validation loss: 2.564734853232341

Epoch: 416| Step: 0
Training loss: 0.35611722295509995
Validation loss: 2.537886626999714

Epoch: 6| Step: 1
Training loss: 0.42681097053100736
Validation loss: 2.5228127251196093

Epoch: 6| Step: 2
Training loss: 0.4483618150702159
Validation loss: 2.510445047050557

Epoch: 6| Step: 3
Training loss: 0.39233466802892364
Validation loss: 2.5185346418856644

Epoch: 6| Step: 4
Training loss: 0.32950078820726186
Validation loss: 2.533354426907651

Epoch: 6| Step: 5
Training loss: 0.20343613637300176
Validation loss: 2.527427106331795

Epoch: 6| Step: 6
Training loss: 0.3151723325575795
Validation loss: 2.508346770072087

Epoch: 6| Step: 7
Training loss: 0.4820005608037005
Validation loss: 2.517911507410175

Epoch: 6| Step: 8
Training loss: 0.2684207096555308
Validation loss: 2.5357922274036393

Epoch: 6| Step: 9
Training loss: 0.4385894426189353
Validation loss: 2.550298271855281

Epoch: 6| Step: 10
Training loss: 0.3338790415137561
Validation loss: 2.5665018530823134

Epoch: 6| Step: 11
Training loss: 0.6004166279152358
Validation loss: 2.564672104247038

Epoch: 6| Step: 12
Training loss: 0.4196370067884318
Validation loss: 2.5792366581988184

Epoch: 6| Step: 13
Training loss: 0.1952965348394343
Validation loss: 2.5799667645992868

Epoch: 417| Step: 0
Training loss: 0.43851796997574205
Validation loss: 2.5655822674806004

Epoch: 6| Step: 1
Training loss: 0.36412156243998256
Validation loss: 2.535946958553282

Epoch: 6| Step: 2
Training loss: 0.3625392514386469
Validation loss: 2.5188376584040455

Epoch: 6| Step: 3
Training loss: 0.38983685137621094
Validation loss: 2.478142199301241

Epoch: 6| Step: 4
Training loss: 0.23403817451492726
Validation loss: 2.4985637723156517

Epoch: 6| Step: 5
Training loss: 0.5269220149285475
Validation loss: 2.5012834884380193

Epoch: 6| Step: 6
Training loss: 0.3275012832172385
Validation loss: 2.551914514043806

Epoch: 6| Step: 7
Training loss: 0.2711300630461654
Validation loss: 2.509091166507437

Epoch: 6| Step: 8
Training loss: 0.29715704068872917
Validation loss: 2.561236962907155

Epoch: 6| Step: 9
Training loss: 0.43877022134203186
Validation loss: 2.5498519551674694

Epoch: 6| Step: 10
Training loss: 0.3181311134245606
Validation loss: 2.520323400160634

Epoch: 6| Step: 11
Training loss: 0.42407676329832805
Validation loss: 2.5305226925752318

Epoch: 6| Step: 12
Training loss: 0.3608113072407162
Validation loss: 2.5058238239778277

Epoch: 6| Step: 13
Training loss: 0.3123215881317025
Validation loss: 2.5327289767000996

Epoch: 418| Step: 0
Training loss: 0.29803766158875966
Validation loss: 2.519933742595247

Epoch: 6| Step: 1
Training loss: 0.6398386432224997
Validation loss: 2.5665787610935316

Epoch: 6| Step: 2
Training loss: 0.1846006459332817
Validation loss: 2.5175705977420693

Epoch: 6| Step: 3
Training loss: 0.41200884275298366
Validation loss: 2.5425456413531324

Epoch: 6| Step: 4
Training loss: 0.14272599195136307
Validation loss: 2.555280911723439

Epoch: 6| Step: 5
Training loss: 0.4468944625350948
Validation loss: 2.5537909100085505

Epoch: 6| Step: 6
Training loss: 0.36967461931969164
Validation loss: 2.5417561574990444

Epoch: 6| Step: 7
Training loss: 0.27603246415591465
Validation loss: 2.5483717187943453

Epoch: 6| Step: 8
Training loss: 0.3495418227587176
Validation loss: 2.596186002357997

Epoch: 6| Step: 9
Training loss: 0.32644532214058936
Validation loss: 2.5863943023352856

Epoch: 6| Step: 10
Training loss: 0.2895353419286997
Validation loss: 2.539302137250155

Epoch: 6| Step: 11
Training loss: 0.5153327460443984
Validation loss: 2.5198277727506735

Epoch: 6| Step: 12
Training loss: 0.27767062736558507
Validation loss: 2.512869649032456

Epoch: 6| Step: 13
Training loss: 0.5035647928337935
Validation loss: 2.487624075834368

Epoch: 419| Step: 0
Training loss: 0.36710878299487615
Validation loss: 2.5003370673079193

Epoch: 6| Step: 1
Training loss: 0.2384379762617282
Validation loss: 2.4994690208148027

Epoch: 6| Step: 2
Training loss: 0.3390871482890609
Validation loss: 2.4851498506392597

Epoch: 6| Step: 3
Training loss: 0.3494152297229153
Validation loss: 2.4765650382131956

Epoch: 6| Step: 4
Training loss: 0.4710777817735355
Validation loss: 2.5148902614469306

Epoch: 6| Step: 5
Training loss: 0.4929637993323666
Validation loss: 2.50127190465166

Epoch: 6| Step: 6
Training loss: 0.3750280330034603
Validation loss: 2.4904312383477323

Epoch: 6| Step: 7
Training loss: 0.2316580249626265
Validation loss: 2.4904083835868045

Epoch: 6| Step: 8
Training loss: 0.4403410355016801
Validation loss: 2.544736943024601

Epoch: 6| Step: 9
Training loss: 0.356734067410055
Validation loss: 2.5553613868801497

Epoch: 6| Step: 10
Training loss: 0.2771024997913334
Validation loss: 2.5673795013312146

Epoch: 6| Step: 11
Training loss: 0.3719104613698834
Validation loss: 2.5686798391113665

Epoch: 6| Step: 12
Training loss: 0.6270159871087667
Validation loss: 2.63523099174611

Epoch: 6| Step: 13
Training loss: 0.250309246246869
Validation loss: 2.6235625496105905

Epoch: 420| Step: 0
Training loss: 0.2025453384442362
Validation loss: 2.5652002393538575

Epoch: 6| Step: 1
Training loss: 0.31604171286884153
Validation loss: 2.60338460455032

Epoch: 6| Step: 2
Training loss: 0.5374348989140498
Validation loss: 2.586351357136938

Epoch: 6| Step: 3
Training loss: 0.28539466036354033
Validation loss: 2.583685670960486

Epoch: 6| Step: 4
Training loss: 0.2570642826919085
Validation loss: 2.5670428542006776

Epoch: 6| Step: 5
Training loss: 0.4970222854645278
Validation loss: 2.543485903902499

Epoch: 6| Step: 6
Training loss: 0.355044289667022
Validation loss: 2.5107171916101523

Epoch: 6| Step: 7
Training loss: 0.46608373203439
Validation loss: 2.5738523496606986

Epoch: 6| Step: 8
Training loss: 0.3757941658195489
Validation loss: 2.538251179326268

Epoch: 6| Step: 9
Training loss: 0.2372725979179487
Validation loss: 2.513944767513153

Epoch: 6| Step: 10
Training loss: 0.37401513073015985
Validation loss: 2.523826099585162

Epoch: 6| Step: 11
Training loss: 0.3955845699473124
Validation loss: 2.5216199711439975

Epoch: 6| Step: 12
Training loss: 0.21235021192586342
Validation loss: 2.530917515624604

Epoch: 6| Step: 13
Training loss: 0.2462198222132515
Validation loss: 2.564599108577283

Epoch: 421| Step: 0
Training loss: 0.5854947260970115
Validation loss: 2.569163732281906

Epoch: 6| Step: 1
Training loss: 0.4634578625507062
Validation loss: 2.5305284453854493

Epoch: 6| Step: 2
Training loss: 0.46489808221857576
Validation loss: 2.5216528991559684

Epoch: 6| Step: 3
Training loss: 0.23178915244295556
Validation loss: 2.5141830138189296

Epoch: 6| Step: 4
Training loss: 0.3670003292201798
Validation loss: 2.5283418988125548

Epoch: 6| Step: 5
Training loss: 0.4772413609103954
Validation loss: 2.5155346746629013

Epoch: 6| Step: 6
Training loss: 0.1960151621272193
Validation loss: 2.554077774115222

Epoch: 6| Step: 7
Training loss: 0.44404369427177265
Validation loss: 2.548513989705138

Epoch: 6| Step: 8
Training loss: 0.30486936521230146
Validation loss: 2.567668960836193

Epoch: 6| Step: 9
Training loss: 0.22402418447434827
Validation loss: 2.502735995253008

Epoch: 6| Step: 10
Training loss: 0.30345390703687725
Validation loss: 2.5595115395117185

Epoch: 6| Step: 11
Training loss: 0.22098092513003484
Validation loss: 2.528830501820112

Epoch: 6| Step: 12
Training loss: 0.3191691788561252
Validation loss: 2.5066806908718955

Epoch: 6| Step: 13
Training loss: 0.2775714637908341
Validation loss: 2.4837485584097734

Epoch: 422| Step: 0
Training loss: 0.3706770514914816
Validation loss: 2.492130251752295

Epoch: 6| Step: 1
Training loss: 0.20117391196395543
Validation loss: 2.537723173758448

Epoch: 6| Step: 2
Training loss: 0.4006210036532224
Validation loss: 2.5192270703116035

Epoch: 6| Step: 3
Training loss: 0.20275858695923288
Validation loss: 2.475374050966784

Epoch: 6| Step: 4
Training loss: 0.5044693277447033
Validation loss: 2.5016455566988416

Epoch: 6| Step: 5
Training loss: 0.2685202559159757
Validation loss: 2.502548918016522

Epoch: 6| Step: 6
Training loss: 0.20982104231848137
Validation loss: 2.5129635040427605

Epoch: 6| Step: 7
Training loss: 0.14469751898020003
Validation loss: 2.534090786320424

Epoch: 6| Step: 8
Training loss: 0.3184501073997617
Validation loss: 2.538016494341176

Epoch: 6| Step: 9
Training loss: 0.27321148114274263
Validation loss: 2.5260009992391916

Epoch: 6| Step: 10
Training loss: 0.36894885132659005
Validation loss: 2.5176553799227537

Epoch: 6| Step: 11
Training loss: 0.4485265623432537
Validation loss: 2.5436184616125495

Epoch: 6| Step: 12
Training loss: 0.29593602813548037
Validation loss: 2.5480762907171157

Epoch: 6| Step: 13
Training loss: 0.5519062213987336
Validation loss: 2.518244137138192

Epoch: 423| Step: 0
Training loss: 0.3693774840953969
Validation loss: 2.5345346157088247

Epoch: 6| Step: 1
Training loss: 0.48432094518466245
Validation loss: 2.516660828255271

Epoch: 6| Step: 2
Training loss: 0.24454490757543748
Validation loss: 2.5559587434411144

Epoch: 6| Step: 3
Training loss: 0.31890092904166983
Validation loss: 2.5606631056304265

Epoch: 6| Step: 4
Training loss: 0.41410964121664434
Validation loss: 2.5333544481587054

Epoch: 6| Step: 5
Training loss: 0.5213841831383547
Validation loss: 2.5713479740649396

Epoch: 6| Step: 6
Training loss: 0.2790037364111341
Validation loss: 2.5114875760688893

Epoch: 6| Step: 7
Training loss: 0.25341220621308275
Validation loss: 2.5467751742181863

Epoch: 6| Step: 8
Training loss: 0.40985443272922384
Validation loss: 2.5331907743336535

Epoch: 6| Step: 9
Training loss: 0.18786869952144278
Validation loss: 2.526060039392978

Epoch: 6| Step: 10
Training loss: 0.2826640160813268
Validation loss: 2.5624225463686825

Epoch: 6| Step: 11
Training loss: 0.3618650210689667
Validation loss: 2.5412964323423344

Epoch: 6| Step: 12
Training loss: 0.27682270212724375
Validation loss: 2.553317328726633

Epoch: 6| Step: 13
Training loss: 0.2900644927002628
Validation loss: 2.5005219724733605

Epoch: 424| Step: 0
Training loss: 0.17840825698052412
Validation loss: 2.530165736955673

Epoch: 6| Step: 1
Training loss: 0.2872568128207846
Validation loss: 2.512712718334103

Epoch: 6| Step: 2
Training loss: 0.34278202317834283
Validation loss: 2.52414879996259

Epoch: 6| Step: 3
Training loss: 0.2671640352352372
Validation loss: 2.4769578212352337

Epoch: 6| Step: 4
Training loss: 0.4774324106893236
Validation loss: 2.508108950634365

Epoch: 6| Step: 5
Training loss: 0.39090646140290847
Validation loss: 2.5186536581556354

Epoch: 6| Step: 6
Training loss: 0.2560680353917855
Validation loss: 2.5090440454260654

Epoch: 6| Step: 7
Training loss: 0.2637237215284327
Validation loss: 2.501859760725404

Epoch: 6| Step: 8
Training loss: 0.31990103927412483
Validation loss: 2.5168945488814973

Epoch: 6| Step: 9
Training loss: 0.3948091340373674
Validation loss: 2.5247866321606187

Epoch: 6| Step: 10
Training loss: 0.44602773348257885
Validation loss: 2.5045699015854477

Epoch: 6| Step: 11
Training loss: 0.18438373197471186
Validation loss: 2.468726130378318

Epoch: 6| Step: 12
Training loss: 0.47169805771337037
Validation loss: 2.5064698598793007

Epoch: 6| Step: 13
Training loss: 0.2808253738556367
Validation loss: 2.495783496661588

Epoch: 425| Step: 0
Training loss: 0.3759733323788295
Validation loss: 2.5381113022132284

Epoch: 6| Step: 1
Training loss: 0.3406137097088697
Validation loss: 2.51556720793371

Epoch: 6| Step: 2
Training loss: 0.2838268908540253
Validation loss: 2.5527708900827064

Epoch: 6| Step: 3
Training loss: 0.1886831248623685
Validation loss: 2.558258504101552

Epoch: 6| Step: 4
Training loss: 0.34655935858772374
Validation loss: 2.5409435408188767

Epoch: 6| Step: 5
Training loss: 0.4159906585795364
Validation loss: 2.544743756254729

Epoch: 6| Step: 6
Training loss: 0.26298917762442103
Validation loss: 2.5658709041264283

Epoch: 6| Step: 7
Training loss: 0.3048976271437223
Validation loss: 2.5495448952399355

Epoch: 6| Step: 8
Training loss: 0.4407996338881722
Validation loss: 2.543531065050903

Epoch: 6| Step: 9
Training loss: 0.37605792069464294
Validation loss: 2.51406514009533

Epoch: 6| Step: 10
Training loss: 0.3270617014217122
Validation loss: 2.537561271877816

Epoch: 6| Step: 11
Training loss: 0.3826000441507313
Validation loss: 2.5480600279310983

Epoch: 6| Step: 12
Training loss: 0.2540280123502083
Validation loss: 2.515413145320058

Epoch: 6| Step: 13
Training loss: 0.38619049675626543
Validation loss: 2.4927626005492365

Epoch: 426| Step: 0
Training loss: 0.2654400069116352
Validation loss: 2.5579158588506217

Epoch: 6| Step: 1
Training loss: 0.2712314305563467
Validation loss: 2.557451805589515

Epoch: 6| Step: 2
Training loss: 0.4838509647467384
Validation loss: 2.5776854756004766

Epoch: 6| Step: 3
Training loss: 0.16905026676284707
Validation loss: 2.6003289146401203

Epoch: 6| Step: 4
Training loss: 0.3672894275501105
Validation loss: 2.5826933667152243

Epoch: 6| Step: 5
Training loss: 0.41629251927360483
Validation loss: 2.542296922699138

Epoch: 6| Step: 6
Training loss: 0.31707764259316346
Validation loss: 2.596358584620557

Epoch: 6| Step: 7
Training loss: 0.17403500279829145
Validation loss: 2.5610647096153323

Epoch: 6| Step: 8
Training loss: 0.24934802125733124
Validation loss: 2.5544142371060032

Epoch: 6| Step: 9
Training loss: 0.2928507630865333
Validation loss: 2.572692453466798

Epoch: 6| Step: 10
Training loss: 0.3818588835316888
Validation loss: 2.5418921144886615

Epoch: 6| Step: 11
Training loss: 0.2380392142960819
Validation loss: 2.5480330206512383

Epoch: 6| Step: 12
Training loss: 0.40893281394842385
Validation loss: 2.530875332843198

Epoch: 6| Step: 13
Training loss: 0.5730029879187528
Validation loss: 2.5525349006341043

Epoch: 427| Step: 0
Training loss: 0.2832921513029018
Validation loss: 2.5349445606988183

Epoch: 6| Step: 1
Training loss: 0.34063138343359206
Validation loss: 2.5308434521856005

Epoch: 6| Step: 2
Training loss: 0.2972413863978563
Validation loss: 2.5486705838995087

Epoch: 6| Step: 3
Training loss: 0.29132908062664337
Validation loss: 2.5231981716704155

Epoch: 6| Step: 4
Training loss: 0.3672847821843079
Validation loss: 2.5250410961346943

Epoch: 6| Step: 5
Training loss: 0.43293970628046546
Validation loss: 2.5067233810224887

Epoch: 6| Step: 6
Training loss: 0.27595759257069763
Validation loss: 2.5066116376920355

Epoch: 6| Step: 7
Training loss: 0.32359863634900804
Validation loss: 2.463236859490977

Epoch: 6| Step: 8
Training loss: 0.2292496718734007
Validation loss: 2.5594996593495556

Epoch: 6| Step: 9
Training loss: 0.43335722580784775
Validation loss: 2.553662439193741

Epoch: 6| Step: 10
Training loss: 0.33672836272288015
Validation loss: 2.5678457224914975

Epoch: 6| Step: 11
Training loss: 0.1751616472200501
Validation loss: 2.575857677563305

Epoch: 6| Step: 12
Training loss: 0.42157512179313383
Validation loss: 2.59130233479184

Epoch: 6| Step: 13
Training loss: 0.4400650680449724
Validation loss: 2.607900380540503

Epoch: 428| Step: 0
Training loss: 0.2831487274543139
Validation loss: 2.6151603908765435

Epoch: 6| Step: 1
Training loss: 0.4070196380716139
Validation loss: 2.6020329971414955

Epoch: 6| Step: 2
Training loss: 0.3947965655194848
Validation loss: 2.601605992284848

Epoch: 6| Step: 3
Training loss: 0.27752941257094926
Validation loss: 2.6056468991457864

Epoch: 6| Step: 4
Training loss: 0.28273483232059055
Validation loss: 2.6049938327153463

Epoch: 6| Step: 5
Training loss: 0.32555246072348015
Validation loss: 2.5920151068897797

Epoch: 6| Step: 6
Training loss: 0.19685323496505977
Validation loss: 2.5646557812625486

Epoch: 6| Step: 7
Training loss: 0.5040409292582682
Validation loss: 2.5539247848716546

Epoch: 6| Step: 8
Training loss: 0.4403656703665604
Validation loss: 2.5361089058707833

Epoch: 6| Step: 9
Training loss: 0.2226493734000551
Validation loss: 2.52244970098348

Epoch: 6| Step: 10
Training loss: 0.33695504865267517
Validation loss: 2.5771121330308984

Epoch: 6| Step: 11
Training loss: 0.14107145857853767
Validation loss: 2.5504383128681205

Epoch: 6| Step: 12
Training loss: 0.33904948539191343
Validation loss: 2.5285005473331954

Epoch: 6| Step: 13
Training loss: 0.28485190467231164
Validation loss: 2.550619492510893

Epoch: 429| Step: 0
Training loss: 0.32502827062892653
Validation loss: 2.549699394069903

Epoch: 6| Step: 1
Training loss: 0.5189553417403913
Validation loss: 2.5225057214727156

Epoch: 6| Step: 2
Training loss: 0.3248860604207664
Validation loss: 2.540075880693922

Epoch: 6| Step: 3
Training loss: 0.361905826942217
Validation loss: 2.5705742653925867

Epoch: 6| Step: 4
Training loss: 0.31236383332515166
Validation loss: 2.530270106138324

Epoch: 6| Step: 5
Training loss: 0.2781523616061705
Validation loss: 2.5638064668868603

Epoch: 6| Step: 6
Training loss: 0.3443135929917794
Validation loss: 2.614617304394747

Epoch: 6| Step: 7
Training loss: 0.39223584868759015
Validation loss: 2.5696491465518636

Epoch: 6| Step: 8
Training loss: 0.16194060744193858
Validation loss: 2.591996165464219

Epoch: 6| Step: 9
Training loss: 0.3236651462570948
Validation loss: 2.6118951429263046

Epoch: 6| Step: 10
Training loss: 0.25282665495978224
Validation loss: 2.6393166587353067

Epoch: 6| Step: 11
Training loss: 0.5268303526653546
Validation loss: 2.568012949238789

Epoch: 6| Step: 12
Training loss: 0.32249828378826934
Validation loss: 2.52638522062494

Epoch: 6| Step: 13
Training loss: 0.40248766427062366
Validation loss: 2.5138092815538373

Epoch: 430| Step: 0
Training loss: 0.302445871026424
Validation loss: 2.45560284982619

Epoch: 6| Step: 1
Training loss: 0.33955162471724626
Validation loss: 2.517495254678483

Epoch: 6| Step: 2
Training loss: 0.3779735293328658
Validation loss: 2.5032934009934777

Epoch: 6| Step: 3
Training loss: 0.2393249339716378
Validation loss: 2.5418969656385664

Epoch: 6| Step: 4
Training loss: 0.3604729507393331
Validation loss: 2.613265575463277

Epoch: 6| Step: 5
Training loss: 0.3849944000951566
Validation loss: 2.581124726787109

Epoch: 6| Step: 6
Training loss: 0.41744771907021966
Validation loss: 2.6414202333501597

Epoch: 6| Step: 7
Training loss: 0.541114770501357
Validation loss: 2.5969428001204804

Epoch: 6| Step: 8
Training loss: 0.4536002396432388
Validation loss: 2.594266914841536

Epoch: 6| Step: 9
Training loss: 0.2083746849188113
Validation loss: 2.523364703366134

Epoch: 6| Step: 10
Training loss: 0.2962169129368705
Validation loss: 2.5127997615097053

Epoch: 6| Step: 11
Training loss: 0.43776621552786393
Validation loss: 2.446549561710068

Epoch: 6| Step: 12
Training loss: 0.5177714724451259
Validation loss: 2.434423694610374

Epoch: 6| Step: 13
Training loss: 0.44079632100138116
Validation loss: 2.494178193194273

Epoch: 431| Step: 0
Training loss: 0.3617755491017275
Validation loss: 2.5081752499027212

Epoch: 6| Step: 1
Training loss: 0.32718371300751004
Validation loss: 2.530295437751012

Epoch: 6| Step: 2
Training loss: 0.5852135318277595
Validation loss: 2.5971989311364405

Epoch: 6| Step: 3
Training loss: 0.6961606671057516
Validation loss: 2.605057196827775

Epoch: 6| Step: 4
Training loss: 0.5044144426165814
Validation loss: 2.566822718891893

Epoch: 6| Step: 5
Training loss: 0.38839027133011966
Validation loss: 2.539152203435385

Epoch: 6| Step: 6
Training loss: 0.20930357647142056
Validation loss: 2.5265909318138933

Epoch: 6| Step: 7
Training loss: 0.5443774275610631
Validation loss: 2.455082502364555

Epoch: 6| Step: 8
Training loss: 0.5729904011759558
Validation loss: 2.459824941909132

Epoch: 6| Step: 9
Training loss: 0.40338322700643353
Validation loss: 2.463726562715503

Epoch: 6| Step: 10
Training loss: 0.49751085346210444
Validation loss: 2.5292429682728486

Epoch: 6| Step: 11
Training loss: 0.4198717309155045
Validation loss: 2.5936260230823907

Epoch: 6| Step: 12
Training loss: 0.5964561330808225
Validation loss: 2.6099384410117317

Epoch: 6| Step: 13
Training loss: 0.34339554892323015
Validation loss: 2.6314926346978873

Epoch: 432| Step: 0
Training loss: 0.5417436459445512
Validation loss: 2.663439819750587

Epoch: 6| Step: 1
Training loss: 0.5089317897704432
Validation loss: 2.6283044656997583

Epoch: 6| Step: 2
Training loss: 0.5838188523687241
Validation loss: 2.5462999367172587

Epoch: 6| Step: 3
Training loss: 0.4410916785726309
Validation loss: 2.6146653201760977

Epoch: 6| Step: 4
Training loss: 0.7759464299352188
Validation loss: 2.5690648514035193

Epoch: 6| Step: 5
Training loss: 0.40741973978801593
Validation loss: 2.574561566546473

Epoch: 6| Step: 6
Training loss: 0.6290584877519148
Validation loss: 2.567956400060271

Epoch: 6| Step: 7
Training loss: 0.5525172855296903
Validation loss: 2.6376044126689817

Epoch: 6| Step: 8
Training loss: 0.47288280763566065
Validation loss: 2.6450952752522277

Epoch: 6| Step: 9
Training loss: 0.3910777138909768
Validation loss: 2.634114550567395

Epoch: 6| Step: 10
Training loss: 0.5383990531208787
Validation loss: 2.651300579914323

Epoch: 6| Step: 11
Training loss: 0.45881027815716924
Validation loss: 2.618665535149316

Epoch: 6| Step: 12
Training loss: 0.482214709445642
Validation loss: 2.6191445588338227

Epoch: 6| Step: 13
Training loss: 0.11093712625306262
Validation loss: 2.607614749873749

Epoch: 433| Step: 0
Training loss: 0.3508240149072933
Validation loss: 2.5984448235454285

Epoch: 6| Step: 1
Training loss: 0.41362595487906895
Validation loss: 2.572977340744749

Epoch: 6| Step: 2
Training loss: 0.5350676414475322
Validation loss: 2.558460522260742

Epoch: 6| Step: 3
Training loss: 0.4381676756227025
Validation loss: 2.55724402757707

Epoch: 6| Step: 4
Training loss: 0.34345108821045073
Validation loss: 2.490435518059061

Epoch: 6| Step: 5
Training loss: 0.46807609435062913
Validation loss: 2.4776971138888144

Epoch: 6| Step: 6
Training loss: 0.4133037957602107
Validation loss: 2.4777739495780136

Epoch: 6| Step: 7
Training loss: 0.5553607347413425
Validation loss: 2.4924715152684076

Epoch: 6| Step: 8
Training loss: 0.35294143665645394
Validation loss: 2.527690376217027

Epoch: 6| Step: 9
Training loss: 0.39054041900457176
Validation loss: 2.489901797022763

Epoch: 6| Step: 10
Training loss: 0.25137712745012847
Validation loss: 2.571760512614887

Epoch: 6| Step: 11
Training loss: 0.355505008734656
Validation loss: 2.5888064009270026

Epoch: 6| Step: 12
Training loss: 0.5762991813061427
Validation loss: 2.6362346369728153

Epoch: 6| Step: 13
Training loss: 0.36479860716745227
Validation loss: 2.6420082051487883

Epoch: 434| Step: 0
Training loss: 0.4189194535675645
Validation loss: 2.601072327366766

Epoch: 6| Step: 1
Training loss: 0.29432768680422233
Validation loss: 2.56994902018719

Epoch: 6| Step: 2
Training loss: 0.38957561682472536
Validation loss: 2.621635783324247

Epoch: 6| Step: 3
Training loss: 0.3511578880639166
Validation loss: 2.572452870701432

Epoch: 6| Step: 4
Training loss: 0.1988640788308708
Validation loss: 2.6080589170982633

Epoch: 6| Step: 5
Training loss: 0.39471038679514087
Validation loss: 2.5425105039834306

Epoch: 6| Step: 6
Training loss: 0.4111806882406253
Validation loss: 2.5150777661935795

Epoch: 6| Step: 7
Training loss: 0.3259748903372213
Validation loss: 2.523555736463329

Epoch: 6| Step: 8
Training loss: 0.521266534575069
Validation loss: 2.522294224167057

Epoch: 6| Step: 9
Training loss: 0.4101747962754921
Validation loss: 2.512007280933389

Epoch: 6| Step: 10
Training loss: 0.4644449109761974
Validation loss: 2.5056248882371857

Epoch: 6| Step: 11
Training loss: 0.3257833439601868
Validation loss: 2.5019563918565364

Epoch: 6| Step: 12
Training loss: 0.2862460852859207
Validation loss: 2.5136622024509263

Epoch: 6| Step: 13
Training loss: 0.6040278116243096
Validation loss: 2.586391104713873

Epoch: 435| Step: 0
Training loss: 0.2480763845837378
Validation loss: 2.540326041443722

Epoch: 6| Step: 1
Training loss: 0.4048387149216475
Validation loss: 2.5695584954119797

Epoch: 6| Step: 2
Training loss: 0.4036780149695359
Validation loss: 2.5507072829092765

Epoch: 6| Step: 3
Training loss: 0.4392254557550578
Validation loss: 2.4983418103010324

Epoch: 6| Step: 4
Training loss: 0.2953549041780994
Validation loss: 2.4718715911373366

Epoch: 6| Step: 5
Training loss: 0.3263477034263113
Validation loss: 2.468625413527001

Epoch: 6| Step: 6
Training loss: 0.25923879160788055
Validation loss: 2.4900759601171503

Epoch: 6| Step: 7
Training loss: 0.3486409119592143
Validation loss: 2.4680553293311625

Epoch: 6| Step: 8
Training loss: 0.3518515352383429
Validation loss: 2.4658327531658117

Epoch: 6| Step: 9
Training loss: 0.4180782923248466
Validation loss: 2.502935410011475

Epoch: 6| Step: 10
Training loss: 0.4387795266108822
Validation loss: 2.525666147036095

Epoch: 6| Step: 11
Training loss: 0.3577731131652035
Validation loss: 2.5270508259479563

Epoch: 6| Step: 12
Training loss: 0.3566145612671076
Validation loss: 2.5591204417629037

Epoch: 6| Step: 13
Training loss: 0.22554602827303663
Validation loss: 2.5700464845027535

Epoch: 436| Step: 0
Training loss: 0.2584448198252842
Validation loss: 2.6315076346495667

Epoch: 6| Step: 1
Training loss: 0.32763636627405707
Validation loss: 2.6133969755561095

Epoch: 6| Step: 2
Training loss: 0.2803167914377831
Validation loss: 2.6246519976303317

Epoch: 6| Step: 3
Training loss: 0.38583297626830376
Validation loss: 2.6028497988283807

Epoch: 6| Step: 4
Training loss: 0.20811253808203523
Validation loss: 2.5690618138286974

Epoch: 6| Step: 5
Training loss: 0.43081627748671447
Validation loss: 2.5807437567052545

Epoch: 6| Step: 6
Training loss: 0.4298062593895392
Validation loss: 2.5877380913089008

Epoch: 6| Step: 7
Training loss: 0.4469860152418729
Validation loss: 2.5153050872422518

Epoch: 6| Step: 8
Training loss: 0.3041915035340966
Validation loss: 2.489657601002056

Epoch: 6| Step: 9
Training loss: 0.24345691312135967
Validation loss: 2.4604418616001538

Epoch: 6| Step: 10
Training loss: 0.489481937446337
Validation loss: 2.44076489181597

Epoch: 6| Step: 11
Training loss: 0.4804963825002327
Validation loss: 2.505241385808889

Epoch: 6| Step: 12
Training loss: 0.4730718850187517
Validation loss: 2.4527933149787464

Epoch: 6| Step: 13
Training loss: 0.3907145778943083
Validation loss: 2.499601686700181

Epoch: 437| Step: 0
Training loss: 0.3759434276693773
Validation loss: 2.530555996591007

Epoch: 6| Step: 1
Training loss: 0.313603265653121
Validation loss: 2.5482041427427538

Epoch: 6| Step: 2
Training loss: 0.255559352242444
Validation loss: 2.5304174133826938

Epoch: 6| Step: 3
Training loss: 0.4370434286025242
Validation loss: 2.5646884376233494

Epoch: 6| Step: 4
Training loss: 0.2546973156353969
Validation loss: 2.526493060257119

Epoch: 6| Step: 5
Training loss: 0.25459960754893185
Validation loss: 2.552360945154142

Epoch: 6| Step: 6
Training loss: 0.3106346486164638
Validation loss: 2.5400905853153115

Epoch: 6| Step: 7
Training loss: 0.26621220701031095
Validation loss: 2.566207981222255

Epoch: 6| Step: 8
Training loss: 0.43110848330090673
Validation loss: 2.5505551388405365

Epoch: 6| Step: 9
Training loss: 0.4128832669355858
Validation loss: 2.56844675367821

Epoch: 6| Step: 10
Training loss: 0.3828017564161259
Validation loss: 2.6021230410873417

Epoch: 6| Step: 11
Training loss: 0.38833996963901835
Validation loss: 2.62154924553733

Epoch: 6| Step: 12
Training loss: 0.333823193032265
Validation loss: 2.603477758694678

Epoch: 6| Step: 13
Training loss: 0.29403976494428796
Validation loss: 2.5736619310805606

Epoch: 438| Step: 0
Training loss: 0.43435313766679384
Validation loss: 2.591966426226999

Epoch: 6| Step: 1
Training loss: 0.4152385636097757
Validation loss: 2.5683158826847703

Epoch: 6| Step: 2
Training loss: 0.24871268985802586
Validation loss: 2.5649203803321594

Epoch: 6| Step: 3
Training loss: 0.36333200653880915
Validation loss: 2.5255628838477833

Epoch: 6| Step: 4
Training loss: 0.17474553370020948
Validation loss: 2.5114409128577964

Epoch: 6| Step: 5
Training loss: 0.27227679904244967
Validation loss: 2.524063084112003

Epoch: 6| Step: 6
Training loss: 0.3048455488659269
Validation loss: 2.49375912828132

Epoch: 6| Step: 7
Training loss: 0.3560772393262604
Validation loss: 2.541064242606099

Epoch: 6| Step: 8
Training loss: 0.45284104493536076
Validation loss: 2.5488895119539468

Epoch: 6| Step: 9
Training loss: 0.26109574310893463
Validation loss: 2.5795996323334807

Epoch: 6| Step: 10
Training loss: 0.22829287831627257
Validation loss: 2.5836433009006843

Epoch: 6| Step: 11
Training loss: 0.25245222293545977
Validation loss: 2.611848196158963

Epoch: 6| Step: 12
Training loss: 0.3378315692075172
Validation loss: 2.601906666914835

Epoch: 6| Step: 13
Training loss: 0.2170891381242398
Validation loss: 2.5992624874797006

Epoch: 439| Step: 0
Training loss: 0.447846713998521
Validation loss: 2.5753564790345402

Epoch: 6| Step: 1
Training loss: 0.4048262737452252
Validation loss: 2.594884180427588

Epoch: 6| Step: 2
Training loss: 0.23489624712048363
Validation loss: 2.5515074578478334

Epoch: 6| Step: 3
Training loss: 0.19798843228741841
Validation loss: 2.5465888597380366

Epoch: 6| Step: 4
Training loss: 0.3031852932576223
Validation loss: 2.4893900612231707

Epoch: 6| Step: 5
Training loss: 0.3332498515415648
Validation loss: 2.536066154392978

Epoch: 6| Step: 6
Training loss: 0.3349903416308852
Validation loss: 2.512874270554071

Epoch: 6| Step: 7
Training loss: 0.3858599133052342
Validation loss: 2.4991337536729876

Epoch: 6| Step: 8
Training loss: 0.3277152318444612
Validation loss: 2.5173468821888054

Epoch: 6| Step: 9
Training loss: 0.33905525375568907
Validation loss: 2.467238884177693

Epoch: 6| Step: 10
Training loss: 0.4212637110666277
Validation loss: 2.4979327247913097

Epoch: 6| Step: 11
Training loss: 0.21325725518258018
Validation loss: 2.4693957982461647

Epoch: 6| Step: 12
Training loss: 0.3717014356495634
Validation loss: 2.443299345840438

Epoch: 6| Step: 13
Training loss: 0.37646971228156667
Validation loss: 2.5001283838265445

Epoch: 440| Step: 0
Training loss: 0.28074701685352366
Validation loss: 2.5047832189123094

Epoch: 6| Step: 1
Training loss: 0.26421108918276026
Validation loss: 2.5001019231467208

Epoch: 6| Step: 2
Training loss: 0.36389600360182295
Validation loss: 2.5396512761039096

Epoch: 6| Step: 3
Training loss: 0.2725125882539632
Validation loss: 2.4868332009801124

Epoch: 6| Step: 4
Training loss: 0.39323933274557354
Validation loss: 2.560859189872751

Epoch: 6| Step: 5
Training loss: 0.2507698306041738
Validation loss: 2.5672312013255834

Epoch: 6| Step: 6
Training loss: 0.4236114229225442
Validation loss: 2.578062448895633

Epoch: 6| Step: 7
Training loss: 0.16428206714900742
Validation loss: 2.598782926142702

Epoch: 6| Step: 8
Training loss: 0.3317336375506947
Validation loss: 2.5584639687223736

Epoch: 6| Step: 9
Training loss: 0.3623334353986969
Validation loss: 2.5828533289010682

Epoch: 6| Step: 10
Training loss: 0.29307835118256104
Validation loss: 2.5732327299039004

Epoch: 6| Step: 11
Training loss: 0.43827087743660137
Validation loss: 2.6078067109790544

Epoch: 6| Step: 12
Training loss: 0.17573444485063064
Validation loss: 2.555990942723335

Epoch: 6| Step: 13
Training loss: 0.3141431287444207
Validation loss: 2.58937926643468

Epoch: 441| Step: 0
Training loss: 0.31076378114912745
Validation loss: 2.575721474023767

Epoch: 6| Step: 1
Training loss: 0.3736459605111568
Validation loss: 2.579653734966657

Epoch: 6| Step: 2
Training loss: 0.21286693056170652
Validation loss: 2.5719634298797796

Epoch: 6| Step: 3
Training loss: 0.22165805862379426
Validation loss: 2.5651197360644646

Epoch: 6| Step: 4
Training loss: 0.2105184560644993
Validation loss: 2.5650898981059282

Epoch: 6| Step: 5
Training loss: 0.362638807851116
Validation loss: 2.5690505276700226

Epoch: 6| Step: 6
Training loss: 0.38943071903526283
Validation loss: 2.5823022396971504

Epoch: 6| Step: 7
Training loss: 0.2574361597476828
Validation loss: 2.569231943420659

Epoch: 6| Step: 8
Training loss: 0.24493842426465376
Validation loss: 2.594610876661117

Epoch: 6| Step: 9
Training loss: 0.24536365868519638
Validation loss: 2.597691107260167

Epoch: 6| Step: 10
Training loss: 0.4389328653231297
Validation loss: 2.5688085418969284

Epoch: 6| Step: 11
Training loss: 0.3363668448282857
Validation loss: 2.5590284439022004

Epoch: 6| Step: 12
Training loss: 0.5459856158202775
Validation loss: 2.5624471254293595

Epoch: 6| Step: 13
Training loss: 0.29483176111490733
Validation loss: 2.5294806108291983

Epoch: 442| Step: 0
Training loss: 0.3189814054830672
Validation loss: 2.558345620514399

Epoch: 6| Step: 1
Training loss: 0.22849288240382437
Validation loss: 2.564107151303475

Epoch: 6| Step: 2
Training loss: 0.33281426944172743
Validation loss: 2.56431160394578

Epoch: 6| Step: 3
Training loss: 0.2922298523098546
Validation loss: 2.5533791770322716

Epoch: 6| Step: 4
Training loss: 0.2928651117755035
Validation loss: 2.570432407137992

Epoch: 6| Step: 5
Training loss: 0.35814123253375324
Validation loss: 2.5702945546399194

Epoch: 6| Step: 6
Training loss: 0.38578726589600076
Validation loss: 2.60145865203569

Epoch: 6| Step: 7
Training loss: 0.29390746725297784
Validation loss: 2.569697675353579

Epoch: 6| Step: 8
Training loss: 0.37305086942601323
Validation loss: 2.564894607068372

Epoch: 6| Step: 9
Training loss: 0.3629829453555155
Validation loss: 2.5583720559786483

Epoch: 6| Step: 10
Training loss: 0.36737443345536624
Validation loss: 2.5465124644649477

Epoch: 6| Step: 11
Training loss: 0.4083186811945359
Validation loss: 2.5406323356872154

Epoch: 6| Step: 12
Training loss: 0.5068316744292504
Validation loss: 2.5583968287699226

Epoch: 6| Step: 13
Training loss: 0.16619246544939204
Validation loss: 2.60667373440162

Epoch: 443| Step: 0
Training loss: 0.20817547519728555
Validation loss: 2.574335337285576

Epoch: 6| Step: 1
Training loss: 0.5222389105938349
Validation loss: 2.605375955349196

Epoch: 6| Step: 2
Training loss: 0.5535919223015546
Validation loss: 2.601041262259871

Epoch: 6| Step: 3
Training loss: 0.29011796590881167
Validation loss: 2.5776193390746616

Epoch: 6| Step: 4
Training loss: 0.4324730316474992
Validation loss: 2.5735495459317983

Epoch: 6| Step: 5
Training loss: 0.2888753130261959
Validation loss: 2.5483210278806165

Epoch: 6| Step: 6
Training loss: 0.27416767992443075
Validation loss: 2.540110762083223

Epoch: 6| Step: 7
Training loss: 0.22255627579463239
Validation loss: 2.558631079716991

Epoch: 6| Step: 8
Training loss: 0.32639654496639803
Validation loss: 2.5159129031070715

Epoch: 6| Step: 9
Training loss: 0.25441374312652687
Validation loss: 2.536855634467831

Epoch: 6| Step: 10
Training loss: 0.32822766287429
Validation loss: 2.5376113003182144

Epoch: 6| Step: 11
Training loss: 0.2330537189625793
Validation loss: 2.500934959237575

Epoch: 6| Step: 12
Training loss: 0.3338069890868526
Validation loss: 2.5054367517644

Epoch: 6| Step: 13
Training loss: 0.28826870051001585
Validation loss: 2.4980234526034413

Epoch: 444| Step: 0
Training loss: 0.20036515265485455
Validation loss: 2.5012025504515343

Epoch: 6| Step: 1
Training loss: 0.24370102023481308
Validation loss: 2.4698397083863743

Epoch: 6| Step: 2
Training loss: 0.2877328551659074
Validation loss: 2.5157978108311756

Epoch: 6| Step: 3
Training loss: 0.294227084843528
Validation loss: 2.5739491422807514

Epoch: 6| Step: 4
Training loss: 0.25089125909087884
Validation loss: 2.550783085204848

Epoch: 6| Step: 5
Training loss: 0.3440249275633516
Validation loss: 2.5548575221391743

Epoch: 6| Step: 6
Training loss: 0.3276834582491166
Validation loss: 2.5998459350684593

Epoch: 6| Step: 7
Training loss: 0.3347413146585211
Validation loss: 2.565006576354868

Epoch: 6| Step: 8
Training loss: 0.21204251909493793
Validation loss: 2.594628249725721

Epoch: 6| Step: 9
Training loss: 0.21861468966727426
Validation loss: 2.5665967733868067

Epoch: 6| Step: 10
Training loss: 0.4831008457497024
Validation loss: 2.570512254357829

Epoch: 6| Step: 11
Training loss: 0.316462700129138
Validation loss: 2.5540710359718255

Epoch: 6| Step: 12
Training loss: 0.4534434482071272
Validation loss: 2.5234136661252418

Epoch: 6| Step: 13
Training loss: 0.20522636323878718
Validation loss: 2.5246790433087942

Epoch: 445| Step: 0
Training loss: 0.3121328462027764
Validation loss: 2.516107285589389

Epoch: 6| Step: 1
Training loss: 0.3171962718032578
Validation loss: 2.5344419762629786

Epoch: 6| Step: 2
Training loss: 0.4178567361917019
Validation loss: 2.482405467645711

Epoch: 6| Step: 3
Training loss: 0.3530086021672001
Validation loss: 2.518924211572913

Epoch: 6| Step: 4
Training loss: 0.39011236885863343
Validation loss: 2.53996872599815

Epoch: 6| Step: 5
Training loss: 0.3222036128635412
Validation loss: 2.5335055093054204

Epoch: 6| Step: 6
Training loss: 0.218535045187698
Validation loss: 2.536812654046696

Epoch: 6| Step: 7
Training loss: 0.23448396375051558
Validation loss: 2.5180563978088846

Epoch: 6| Step: 8
Training loss: 0.3021356013998409
Validation loss: 2.5246992858704473

Epoch: 6| Step: 9
Training loss: 0.3171394706404731
Validation loss: 2.5720589659442537

Epoch: 6| Step: 10
Training loss: 0.4013392120784375
Validation loss: 2.5556695580932303

Epoch: 6| Step: 11
Training loss: 0.20715071272459254
Validation loss: 2.5157088042393942

Epoch: 6| Step: 12
Training loss: 0.27611933671126565
Validation loss: 2.525360915557262

Epoch: 6| Step: 13
Training loss: 0.18396464887998104
Validation loss: 2.4969434336848915

Epoch: 446| Step: 0
Training loss: 0.29360530363598225
Validation loss: 2.542843220722895

Epoch: 6| Step: 1
Training loss: 0.19947695361537432
Validation loss: 2.5211003269850165

Epoch: 6| Step: 2
Training loss: 0.5099816869271414
Validation loss: 2.5410427996818896

Epoch: 6| Step: 3
Training loss: 0.2910152281688058
Validation loss: 2.477248217789116

Epoch: 6| Step: 4
Training loss: 0.2526079289002141
Validation loss: 2.4750342987259426

Epoch: 6| Step: 5
Training loss: 0.26740671501016705
Validation loss: 2.451933105722438

Epoch: 6| Step: 6
Training loss: 0.33400955997565174
Validation loss: 2.4465486516437682

Epoch: 6| Step: 7
Training loss: 0.36831841913655605
Validation loss: 2.4317376783710936

Epoch: 6| Step: 8
Training loss: 0.36858705864654556
Validation loss: 2.462716086779054

Epoch: 6| Step: 9
Training loss: 0.36920783021513254
Validation loss: 2.4790023090180524

Epoch: 6| Step: 10
Training loss: 0.39537013919072306
Validation loss: 2.4644066941035483

Epoch: 6| Step: 11
Training loss: 0.29173756345165275
Validation loss: 2.491702170068824

Epoch: 6| Step: 12
Training loss: 0.30834947647973804
Validation loss: 2.5545810881639355

Epoch: 6| Step: 13
Training loss: 0.5388315231174056
Validation loss: 2.561181492297723

Epoch: 447| Step: 0
Training loss: 0.3730364293738096
Validation loss: 2.5585091320211713

Epoch: 6| Step: 1
Training loss: 0.3355117695111273
Validation loss: 2.5555177678912795

Epoch: 6| Step: 2
Training loss: 0.20843228831202587
Validation loss: 2.560571250299841

Epoch: 6| Step: 3
Training loss: 0.30222256373205203
Validation loss: 2.540580703273911

Epoch: 6| Step: 4
Training loss: 0.4851209372724082
Validation loss: 2.53084999791815

Epoch: 6| Step: 5
Training loss: 0.20442313091239545
Validation loss: 2.51567632069585

Epoch: 6| Step: 6
Training loss: 0.26526478577605955
Validation loss: 2.539655271487744

Epoch: 6| Step: 7
Training loss: 0.2896130705505807
Validation loss: 2.5006535978039595

Epoch: 6| Step: 8
Training loss: 0.48647485380962036
Validation loss: 2.483373556604855

Epoch: 6| Step: 9
Training loss: 0.484599630506007
Validation loss: 2.491173799997327

Epoch: 6| Step: 10
Training loss: 0.40267275348988035
Validation loss: 2.5287355893032006

Epoch: 6| Step: 11
Training loss: 0.29790881497811394
Validation loss: 2.54076582223419

Epoch: 6| Step: 12
Training loss: 0.1550149385306146
Validation loss: 2.5354423387438616

Epoch: 6| Step: 13
Training loss: 0.5083986567387967
Validation loss: 2.5941722381391665

Epoch: 448| Step: 0
Training loss: 0.3922119710514373
Validation loss: 2.5951740394772207

Epoch: 6| Step: 1
Training loss: 0.4497232009681218
Validation loss: 2.657026683315246

Epoch: 6| Step: 2
Training loss: 0.5814661700755837
Validation loss: 2.6833643264932165

Epoch: 6| Step: 3
Training loss: 0.48558620560584725
Validation loss: 2.6461324938478867

Epoch: 6| Step: 4
Training loss: 0.4574717819391698
Validation loss: 2.620989026787014

Epoch: 6| Step: 5
Training loss: 0.39248409378720217
Validation loss: 2.5694502978898894

Epoch: 6| Step: 6
Training loss: 0.393175875187359
Validation loss: 2.560137474752773

Epoch: 6| Step: 7
Training loss: 0.2620823881807453
Validation loss: 2.5246330316213594

Epoch: 6| Step: 8
Training loss: 0.33217756749947575
Validation loss: 2.524057103780513

Epoch: 6| Step: 9
Training loss: 0.4395420916888517
Validation loss: 2.5393090357331713

Epoch: 6| Step: 10
Training loss: 0.49638658426370397
Validation loss: 2.492673856468872

Epoch: 6| Step: 11
Training loss: 0.5221508781699686
Validation loss: 2.498057850805393

Epoch: 6| Step: 12
Training loss: 0.4194024000014588
Validation loss: 2.5215383438911982

Epoch: 6| Step: 13
Training loss: 0.253018117049614
Validation loss: 2.560274664048309

Epoch: 449| Step: 0
Training loss: 0.4470747827895533
Validation loss: 2.565120483882899

Epoch: 6| Step: 1
Training loss: 0.3336378943830391
Validation loss: 2.5808246110172233

Epoch: 6| Step: 2
Training loss: 0.25107054676173535
Validation loss: 2.5667092112688272

Epoch: 6| Step: 3
Training loss: 0.5177048150242992
Validation loss: 2.5733111283701664

Epoch: 6| Step: 4
Training loss: 0.43696467823051244
Validation loss: 2.56785667100949

Epoch: 6| Step: 5
Training loss: 0.36123387937645013
Validation loss: 2.5779319812740864

Epoch: 6| Step: 6
Training loss: 0.32773642010783854
Validation loss: 2.6679173108167284

Epoch: 6| Step: 7
Training loss: 0.3458886268469434
Validation loss: 2.685516993739552

Epoch: 6| Step: 8
Training loss: 0.5259637932373006
Validation loss: 2.6201520111055823

Epoch: 6| Step: 9
Training loss: 0.35053824522730026
Validation loss: 2.6508258119491326

Epoch: 6| Step: 10
Training loss: 0.7258306529597455
Validation loss: 2.631813082366611

Epoch: 6| Step: 11
Training loss: 0.38479902635622665
Validation loss: 2.6123870310984474

Epoch: 6| Step: 12
Training loss: 0.41410287624208675
Validation loss: 2.559281999529865

Epoch: 6| Step: 13
Training loss: 0.23083831768530394
Validation loss: 2.5086788045534987

Epoch: 450| Step: 0
Training loss: 0.5449401414879166
Validation loss: 2.4886704295707833

Epoch: 6| Step: 1
Training loss: 0.37056031284983265
Validation loss: 2.4702448495650353

Epoch: 6| Step: 2
Training loss: 0.49285939691948244
Validation loss: 2.4659975865825183

Epoch: 6| Step: 3
Training loss: 0.419701558358383
Validation loss: 2.450647680623582

Epoch: 6| Step: 4
Training loss: 0.286586232965377
Validation loss: 2.4752563073293743

Epoch: 6| Step: 5
Training loss: 0.18856359853920787
Validation loss: 2.5112047054241815

Epoch: 6| Step: 6
Training loss: 0.3825392818537944
Validation loss: 2.5739728299223135

Epoch: 6| Step: 7
Training loss: 0.35730952180265496
Validation loss: 2.5767671630795776

Epoch: 6| Step: 8
Training loss: 0.4794299207607212
Validation loss: 2.56546114135678

Epoch: 6| Step: 9
Training loss: 0.42162888023384654
Validation loss: 2.57909858346438

Epoch: 6| Step: 10
Training loss: 0.3890531768600976
Validation loss: 2.5587599798574643

Epoch: 6| Step: 11
Training loss: 0.377149738169264
Validation loss: 2.537839705199867

Epoch: 6| Step: 12
Training loss: 0.277854529678288
Validation loss: 2.5151344350413614

Epoch: 6| Step: 13
Training loss: 0.4622856081404708
Validation loss: 2.502180375125847

Epoch: 451| Step: 0
Training loss: 0.4727094478462343
Validation loss: 2.5155928516773187

Epoch: 6| Step: 1
Training loss: 0.3747565750960185
Validation loss: 2.464276287479757

Epoch: 6| Step: 2
Training loss: 0.29331874286649734
Validation loss: 2.4679065830114135

Epoch: 6| Step: 3
Training loss: 0.26784413056329315
Validation loss: 2.489272887860134

Epoch: 6| Step: 4
Training loss: 0.3753684935461593
Validation loss: 2.4683624914658835

Epoch: 6| Step: 5
Training loss: 0.26144770921092775
Validation loss: 2.5154869863624567

Epoch: 6| Step: 6
Training loss: 0.42627019543503164
Validation loss: 2.5367879514196794

Epoch: 6| Step: 7
Training loss: 0.28064166612136254
Validation loss: 2.5190530597758864

Epoch: 6| Step: 8
Training loss: 0.44309717567153256
Validation loss: 2.5408525102671855

Epoch: 6| Step: 9
Training loss: 0.28216631289139044
Validation loss: 2.5228946312277323

Epoch: 6| Step: 10
Training loss: 0.18237370053012042
Validation loss: 2.54109679809539

Epoch: 6| Step: 11
Training loss: 0.25195565333317627
Validation loss: 2.4996909781171044

Epoch: 6| Step: 12
Training loss: 0.2992347867368382
Validation loss: 2.512403809096785

Epoch: 6| Step: 13
Training loss: 0.4121050179056825
Validation loss: 2.466724327425617

Epoch: 452| Step: 0
Training loss: 0.4481267842851814
Validation loss: 2.4994487072567293

Epoch: 6| Step: 1
Training loss: 0.29349346220380557
Validation loss: 2.5090046460543243

Epoch: 6| Step: 2
Training loss: 0.24670640433783098
Validation loss: 2.5563568123406615

Epoch: 6| Step: 3
Training loss: 0.20301301326699744
Validation loss: 2.5687883076063027

Epoch: 6| Step: 4
Training loss: 0.32872253460976075
Validation loss: 2.5858581826234945

Epoch: 6| Step: 5
Training loss: 0.4595651239636437
Validation loss: 2.6053073158611055

Epoch: 6| Step: 6
Training loss: 0.3719590388634945
Validation loss: 2.5861556018159697

Epoch: 6| Step: 7
Training loss: 0.3789669853377604
Validation loss: 2.5970508117540616

Epoch: 6| Step: 8
Training loss: 0.30065193121067957
Validation loss: 2.5753491868494716

Epoch: 6| Step: 9
Training loss: 0.21185150629506994
Validation loss: 2.557018208183396

Epoch: 6| Step: 10
Training loss: 0.45614874643791015
Validation loss: 2.506629028497013

Epoch: 6| Step: 11
Training loss: 0.34748424604094363
Validation loss: 2.519721044533646

Epoch: 6| Step: 12
Training loss: 0.4533816301456846
Validation loss: 2.505346577906885

Epoch: 6| Step: 13
Training loss: 0.46875754986087115
Validation loss: 2.4991213490142625

Epoch: 453| Step: 0
Training loss: 0.2714609643735951
Validation loss: 2.4623027087218134

Epoch: 6| Step: 1
Training loss: 0.33192819230122705
Validation loss: 2.468484242471842

Epoch: 6| Step: 2
Training loss: 0.22611677786733275
Validation loss: 2.4960718560438537

Epoch: 6| Step: 3
Training loss: 0.20682819773427846
Validation loss: 2.501680573245131

Epoch: 6| Step: 4
Training loss: 0.24272341807534847
Validation loss: 2.507904307641581

Epoch: 6| Step: 5
Training loss: 0.2561790129564935
Validation loss: 2.5307198104295607

Epoch: 6| Step: 6
Training loss: 0.21553031286727536
Validation loss: 2.481484918024494

Epoch: 6| Step: 7
Training loss: 0.3782979270287352
Validation loss: 2.5314826812811844

Epoch: 6| Step: 8
Training loss: 0.24329752495828127
Validation loss: 2.503186991952234

Epoch: 6| Step: 9
Training loss: 0.5005368092898573
Validation loss: 2.5007655520036995

Epoch: 6| Step: 10
Training loss: 0.220716315693929
Validation loss: 2.4860079163708164

Epoch: 6| Step: 11
Training loss: 0.40125358440307424
Validation loss: 2.4978013337803753

Epoch: 6| Step: 12
Training loss: 0.37400666440799046
Validation loss: 2.459662269251103

Epoch: 6| Step: 13
Training loss: 0.460366962808081
Validation loss: 2.4865400080677906

Epoch: 454| Step: 0
Training loss: 0.24299966854594823
Validation loss: 2.479370419726107

Epoch: 6| Step: 1
Training loss: 0.2552821805079893
Validation loss: 2.5127281998345867

Epoch: 6| Step: 2
Training loss: 0.2918620760586564
Validation loss: 2.4954300950985684

Epoch: 6| Step: 3
Training loss: 0.2518597954877246
Validation loss: 2.487466376927589

Epoch: 6| Step: 4
Training loss: 0.378001085580044
Validation loss: 2.5301862735310388

Epoch: 6| Step: 5
Training loss: 0.14362320594729505
Validation loss: 2.5118576698044337

Epoch: 6| Step: 6
Training loss: 0.20631407732159818
Validation loss: 2.498908861010798

Epoch: 6| Step: 7
Training loss: 0.2512909667697353
Validation loss: 2.5082225993904723

Epoch: 6| Step: 8
Training loss: 0.33734483684242805
Validation loss: 2.465197196666833

Epoch: 6| Step: 9
Training loss: 0.38479645116640726
Validation loss: 2.4713184105961856

Epoch: 6| Step: 10
Training loss: 0.3258205623371926
Validation loss: 2.4723319022829426

Epoch: 6| Step: 11
Training loss: 0.33871741379186493
Validation loss: 2.4647004224763136

Epoch: 6| Step: 12
Training loss: 0.4468893108877436
Validation loss: 2.4294942723539767

Epoch: 6| Step: 13
Training loss: 0.2216390076673391
Validation loss: 2.443032276267037

Epoch: 455| Step: 0
Training loss: 0.3648198268978724
Validation loss: 2.4836162322450233

Epoch: 6| Step: 1
Training loss: 0.2413982173978304
Validation loss: 2.5013380110481753

Epoch: 6| Step: 2
Training loss: 0.3411428461113908
Validation loss: 2.509527448650541

Epoch: 6| Step: 3
Training loss: 0.3901646762804193
Validation loss: 2.4879087666213016

Epoch: 6| Step: 4
Training loss: 0.32158589202945037
Validation loss: 2.5344662951280514

Epoch: 6| Step: 5
Training loss: 0.376493697786208
Validation loss: 2.4942073870421813

Epoch: 6| Step: 6
Training loss: 0.3424707907904717
Validation loss: 2.5403324133843346

Epoch: 6| Step: 7
Training loss: 0.3655200188055971
Validation loss: 2.512395807157843

Epoch: 6| Step: 8
Training loss: 0.24292349501239108
Validation loss: 2.507309419097998

Epoch: 6| Step: 9
Training loss: 0.15843227650611086
Validation loss: 2.478245146566529

Epoch: 6| Step: 10
Training loss: 0.24420146184149033
Validation loss: 2.502024366506309

Epoch: 6| Step: 11
Training loss: 0.4038932001304151
Validation loss: 2.485186219895971

Epoch: 6| Step: 12
Training loss: 0.18335197640223197
Validation loss: 2.4752943594351335

Epoch: 6| Step: 13
Training loss: 0.15591721262289146
Validation loss: 2.450238744049757

Epoch: 456| Step: 0
Training loss: 0.31776154442531657
Validation loss: 2.4997748027401854

Epoch: 6| Step: 1
Training loss: 0.35862412999267995
Validation loss: 2.53170417915121

Epoch: 6| Step: 2
Training loss: 0.17624422139982324
Validation loss: 2.511703370469405

Epoch: 6| Step: 3
Training loss: 0.24430737713478118
Validation loss: 2.542980276921277

Epoch: 6| Step: 4
Training loss: 0.2352031540589038
Validation loss: 2.6025135726340736

Epoch: 6| Step: 5
Training loss: 0.39336905822654555
Validation loss: 2.580966026216717

Epoch: 6| Step: 6
Training loss: 0.37228313376850614
Validation loss: 2.5843801854952004

Epoch: 6| Step: 7
Training loss: 0.4336079603736189
Validation loss: 2.5968561986271212

Epoch: 6| Step: 8
Training loss: 0.28212667631361993
Validation loss: 2.5750584765862223

Epoch: 6| Step: 9
Training loss: 0.30862451955248804
Validation loss: 2.6007846422132372

Epoch: 6| Step: 10
Training loss: 0.2531560672721208
Validation loss: 2.5421437377740927

Epoch: 6| Step: 11
Training loss: 0.2564093815195612
Validation loss: 2.567419928053308

Epoch: 6| Step: 12
Training loss: 0.1975654174712365
Validation loss: 2.495545109187423

Epoch: 6| Step: 13
Training loss: 0.4275210122750235
Validation loss: 2.493237355332063

Epoch: 457| Step: 0
Training loss: 0.3273985404908932
Validation loss: 2.493633402065366

Epoch: 6| Step: 1
Training loss: 0.31538823094473967
Validation loss: 2.523896941819324

Epoch: 6| Step: 2
Training loss: 0.22174504866765277
Validation loss: 2.5426534048231533

Epoch: 6| Step: 3
Training loss: 0.4276056836372754
Validation loss: 2.4809202667421846

Epoch: 6| Step: 4
Training loss: 0.26696023812668057
Validation loss: 2.520293186468921

Epoch: 6| Step: 5
Training loss: 0.2651922543639166
Validation loss: 2.5073253940683724

Epoch: 6| Step: 6
Training loss: 0.35803645092786807
Validation loss: 2.5132324743416374

Epoch: 6| Step: 7
Training loss: 0.2066896607568943
Validation loss: 2.520197052174807

Epoch: 6| Step: 8
Training loss: 0.35900775140108454
Validation loss: 2.5324402470196294

Epoch: 6| Step: 9
Training loss: 0.35279184086662674
Validation loss: 2.5716324844246135

Epoch: 6| Step: 10
Training loss: 0.2209750247609832
Validation loss: 2.6034793233801192

Epoch: 6| Step: 11
Training loss: 0.2698106009173722
Validation loss: 2.58077259415634

Epoch: 6| Step: 12
Training loss: 0.17727404497508284
Validation loss: 2.5819562519116697

Epoch: 6| Step: 13
Training loss: 0.3037950577106929
Validation loss: 2.5953029426955405

Epoch: 458| Step: 0
Training loss: 0.559872903280384
Validation loss: 2.5950984669241364

Epoch: 6| Step: 1
Training loss: 0.39069747252514525
Validation loss: 2.5772628600549714

Epoch: 6| Step: 2
Training loss: 0.22251404018787319
Validation loss: 2.5381404220297927

Epoch: 6| Step: 3
Training loss: 0.37994096011860834
Validation loss: 2.551427455967297

Epoch: 6| Step: 4
Training loss: 0.30100338647369485
Validation loss: 2.495614211247837

Epoch: 6| Step: 5
Training loss: 0.26152484030201334
Validation loss: 2.537692283281002

Epoch: 6| Step: 6
Training loss: 0.3156593478747297
Validation loss: 2.4974491354459625

Epoch: 6| Step: 7
Training loss: 0.2789680572754139
Validation loss: 2.5336266180559597

Epoch: 6| Step: 8
Training loss: 0.21670689304923005
Validation loss: 2.529600553233145

Epoch: 6| Step: 9
Training loss: 0.26719719160918315
Validation loss: 2.5193380719464997

Epoch: 6| Step: 10
Training loss: 0.18827387925912223
Validation loss: 2.5774738313518517

Epoch: 6| Step: 11
Training loss: 0.2723448858275723
Validation loss: 2.5424424945313735

Epoch: 6| Step: 12
Training loss: 0.16063061685797658
Validation loss: 2.580502242571052

Epoch: 6| Step: 13
Training loss: 0.39431507495638574
Validation loss: 2.5768210237327973

Epoch: 459| Step: 0
Training loss: 0.27549848405780947
Validation loss: 2.5751601915543065

Epoch: 6| Step: 1
Training loss: 0.18744542400493683
Validation loss: 2.5514888959309454

Epoch: 6| Step: 2
Training loss: 0.17381665374109329
Validation loss: 2.5771141937015942

Epoch: 6| Step: 3
Training loss: 0.36871201998493836
Validation loss: 2.5600996878392737

Epoch: 6| Step: 4
Training loss: 0.2855127796947158
Validation loss: 2.528343226087443

Epoch: 6| Step: 5
Training loss: 0.4171082382058048
Validation loss: 2.5480612131339324

Epoch: 6| Step: 6
Training loss: 0.2788443333689055
Validation loss: 2.521849588522132

Epoch: 6| Step: 7
Training loss: 0.391840265063998
Validation loss: 2.5295035797832544

Epoch: 6| Step: 8
Training loss: 0.3629669757919532
Validation loss: 2.5132913651183877

Epoch: 6| Step: 9
Training loss: 0.2535183070295145
Validation loss: 2.503883041113784

Epoch: 6| Step: 10
Training loss: 0.2655244805369977
Validation loss: 2.4860685116128907

Epoch: 6| Step: 11
Training loss: 0.28804176121169445
Validation loss: 2.5457050901088967

Epoch: 6| Step: 12
Training loss: 0.21359877094208088
Validation loss: 2.5517298643039683

Epoch: 6| Step: 13
Training loss: 0.23929238361573613
Validation loss: 2.5654426464237843

Epoch: 460| Step: 0
Training loss: 0.25962406976686536
Validation loss: 2.568419363880201

Epoch: 6| Step: 1
Training loss: 0.28561815971514354
Validation loss: 2.571808648700459

Epoch: 6| Step: 2
Training loss: 0.3181237360886084
Validation loss: 2.548760748317534

Epoch: 6| Step: 3
Training loss: 0.41797593369059377
Validation loss: 2.5771340830930685

Epoch: 6| Step: 4
Training loss: 0.33334738234875
Validation loss: 2.5461403341830553

Epoch: 6| Step: 5
Training loss: 0.3220730292747567
Validation loss: 2.5537779802989005

Epoch: 6| Step: 6
Training loss: 0.42155069672594037
Validation loss: 2.525332375240646

Epoch: 6| Step: 7
Training loss: 0.286816142325301
Validation loss: 2.516042122550733

Epoch: 6| Step: 8
Training loss: 0.346285969848937
Validation loss: 2.5258136969047413

Epoch: 6| Step: 9
Training loss: 0.2794227049888362
Validation loss: 2.5079640032948047

Epoch: 6| Step: 10
Training loss: 0.44816086640203745
Validation loss: 2.562660454369344

Epoch: 6| Step: 11
Training loss: 0.3715723665562074
Validation loss: 2.5040642987603468

Epoch: 6| Step: 12
Training loss: 0.32535433389392704
Validation loss: 2.526388389676365

Epoch: 6| Step: 13
Training loss: 0.24666679360707555
Validation loss: 2.51593655431655

Epoch: 461| Step: 0
Training loss: 0.23493148384448959
Validation loss: 2.480219199724478

Epoch: 6| Step: 1
Training loss: 0.3628871174325596
Validation loss: 2.4787543377810324

Epoch: 6| Step: 2
Training loss: 0.310634600646405
Validation loss: 2.4933103334345343

Epoch: 6| Step: 3
Training loss: 0.22622477912483135
Validation loss: 2.4956275635166647

Epoch: 6| Step: 4
Training loss: 0.26796994445356626
Validation loss: 2.5150108191461062

Epoch: 6| Step: 5
Training loss: 0.34766483296289924
Validation loss: 2.567326461137431

Epoch: 6| Step: 6
Training loss: 0.28234575651940974
Validation loss: 2.5154203049987243

Epoch: 6| Step: 7
Training loss: 0.4096737885090197
Validation loss: 2.5264485816184683

Epoch: 6| Step: 8
Training loss: 0.26530920217596454
Validation loss: 2.5570085893177814

Epoch: 6| Step: 9
Training loss: 0.17114778040054857
Validation loss: 2.5513831133355853

Epoch: 6| Step: 10
Training loss: 0.44281838302096377
Validation loss: 2.524324572643034

Epoch: 6| Step: 11
Training loss: 0.28517472194257776
Validation loss: 2.553460029384199

Epoch: 6| Step: 12
Training loss: 0.18441129828225514
Validation loss: 2.5718707740103146

Epoch: 6| Step: 13
Training loss: 0.089318950674392
Validation loss: 2.538364729878976

Epoch: 462| Step: 0
Training loss: 0.2538765376385808
Validation loss: 2.539755752617768

Epoch: 6| Step: 1
Training loss: 0.2636818777942054
Validation loss: 2.5129395499142007

Epoch: 6| Step: 2
Training loss: 0.41112208409027773
Validation loss: 2.5635731743627304

Epoch: 6| Step: 3
Training loss: 0.22839211117376454
Validation loss: 2.5292104370789112

Epoch: 6| Step: 4
Training loss: 0.18827113880216972
Validation loss: 2.5038389632958618

Epoch: 6| Step: 5
Training loss: 0.2839577453804973
Validation loss: 2.5033479320563115

Epoch: 6| Step: 6
Training loss: 0.2975200872291484
Validation loss: 2.4993023539865726

Epoch: 6| Step: 7
Training loss: 0.22382582951245752
Validation loss: 2.530270533703846

Epoch: 6| Step: 8
Training loss: 0.20553893134478224
Validation loss: 2.491241839374274

Epoch: 6| Step: 9
Training loss: 0.23462208598150827
Validation loss: 2.561522202229547

Epoch: 6| Step: 10
Training loss: 0.30272641325294763
Validation loss: 2.572165284616718

Epoch: 6| Step: 11
Training loss: 0.3434974653117185
Validation loss: 2.5438939604706396

Epoch: 6| Step: 12
Training loss: 0.41791990476033963
Validation loss: 2.5867652273456154

Epoch: 6| Step: 13
Training loss: 0.26401306965023585
Validation loss: 2.5743234936660704

Epoch: 463| Step: 0
Training loss: 0.3588832310098384
Validation loss: 2.584102036597688

Epoch: 6| Step: 1
Training loss: 0.22674216348697693
Validation loss: 2.5650826581885338

Epoch: 6| Step: 2
Training loss: 0.36876720129723306
Validation loss: 2.578563675983883

Epoch: 6| Step: 3
Training loss: 0.3082406522775226
Validation loss: 2.5504072728291725

Epoch: 6| Step: 4
Training loss: 0.18371819276006562
Validation loss: 2.5377187126544496

Epoch: 6| Step: 5
Training loss: 0.2675593571450473
Validation loss: 2.5630010589696264

Epoch: 6| Step: 6
Training loss: 0.16264954160109152
Validation loss: 2.5201450799236085

Epoch: 6| Step: 7
Training loss: 0.32260606296923433
Validation loss: 2.5001084622061094

Epoch: 6| Step: 8
Training loss: 0.38561292969470967
Validation loss: 2.542576857022159

Epoch: 6| Step: 9
Training loss: 0.19555244965175986
Validation loss: 2.528448943474378

Epoch: 6| Step: 10
Training loss: 0.2485445541673488
Validation loss: 2.560770721361544

Epoch: 6| Step: 11
Training loss: 0.24914991121638855
Validation loss: 2.5360516382160943

Epoch: 6| Step: 12
Training loss: 0.21094573852557075
Validation loss: 2.546959319040999

Epoch: 6| Step: 13
Training loss: 0.21449810313784357
Validation loss: 2.514641637541046

Epoch: 464| Step: 0
Training loss: 0.17650249123942682
Validation loss: 2.534736676825069

Epoch: 6| Step: 1
Training loss: 0.19419007122583123
Validation loss: 2.5190669167427933

Epoch: 6| Step: 2
Training loss: 0.24820617006311302
Validation loss: 2.5072154608184327

Epoch: 6| Step: 3
Training loss: 0.33748037316509566
Validation loss: 2.5039444651514344

Epoch: 6| Step: 4
Training loss: 0.29808065640451986
Validation loss: 2.5223482885476276

Epoch: 6| Step: 5
Training loss: 0.18607251850919784
Validation loss: 2.510792882035495

Epoch: 6| Step: 6
Training loss: 0.3189452578374625
Validation loss: 2.5230415460536917

Epoch: 6| Step: 7
Training loss: 0.35484128634539486
Validation loss: 2.5182713040613547

Epoch: 6| Step: 8
Training loss: 0.22093954336254729
Validation loss: 2.569448013066684

Epoch: 6| Step: 9
Training loss: 0.184536491807332
Validation loss: 2.5287902377827858

Epoch: 6| Step: 10
Training loss: 0.3587000562547629
Validation loss: 2.497211893026775

Epoch: 6| Step: 11
Training loss: 0.2572163857175366
Validation loss: 2.514331872266601

Epoch: 6| Step: 12
Training loss: 0.2776636776765164
Validation loss: 2.5105023821129735

Epoch: 6| Step: 13
Training loss: 0.13212342176875216
Validation loss: 2.4567597304392446

Epoch: 465| Step: 0
Training loss: 0.2526376135138971
Validation loss: 2.512262510208509

Epoch: 6| Step: 1
Training loss: 0.23222431634148744
Validation loss: 2.491788070074637

Epoch: 6| Step: 2
Training loss: 0.3299794472810956
Validation loss: 2.50807031034585

Epoch: 6| Step: 3
Training loss: 0.19109566460661673
Validation loss: 2.472703774208096

Epoch: 6| Step: 4
Training loss: 0.21594784278500959
Validation loss: 2.522585812319912

Epoch: 6| Step: 5
Training loss: 0.1881074007806668
Validation loss: 2.513818688384002

Epoch: 6| Step: 6
Training loss: 0.5358039389250849
Validation loss: 2.4877515824646106

Epoch: 6| Step: 7
Training loss: 0.2091532942561495
Validation loss: 2.535219235047594

Epoch: 6| Step: 8
Training loss: 0.21360515410557396
Validation loss: 2.5571454602442287

Epoch: 6| Step: 9
Training loss: 0.27947682805646284
Validation loss: 2.568598084009159

Epoch: 6| Step: 10
Training loss: 0.20435627644483262
Validation loss: 2.5893432289927922

Epoch: 6| Step: 11
Training loss: 0.28516050884254135
Validation loss: 2.576028732692545

Epoch: 6| Step: 12
Training loss: 0.20479694345266022
Validation loss: 2.5614600383575037

Epoch: 6| Step: 13
Training loss: 0.2649869407953818
Validation loss: 2.602268406902665

Epoch: 466| Step: 0
Training loss: 0.21031047203650644
Validation loss: 2.569099256377738

Epoch: 6| Step: 1
Training loss: 0.3202900413455238
Validation loss: 2.618171467989588

Epoch: 6| Step: 2
Training loss: 0.20452634058015104
Validation loss: 2.5797156117232145

Epoch: 6| Step: 3
Training loss: 0.335966752131613
Validation loss: 2.535427266919782

Epoch: 6| Step: 4
Training loss: 0.1601146085614739
Validation loss: 2.5326084779278437

Epoch: 6| Step: 5
Training loss: 0.19099207266801257
Validation loss: 2.5552265438598774

Epoch: 6| Step: 6
Training loss: 0.20925820316963978
Validation loss: 2.5158060821782375

Epoch: 6| Step: 7
Training loss: 0.21383273051789672
Validation loss: 2.579816047983262

Epoch: 6| Step: 8
Training loss: 0.20959471767561044
Validation loss: 2.4996850753670334

Epoch: 6| Step: 9
Training loss: 0.2951096574793385
Validation loss: 2.483857183241047

Epoch: 6| Step: 10
Training loss: 0.21316234501948422
Validation loss: 2.510242519602609

Epoch: 6| Step: 11
Training loss: 0.3538682769883263
Validation loss: 2.546958438813307

Epoch: 6| Step: 12
Training loss: 0.2047280548047137
Validation loss: 2.5483005192446457

Epoch: 6| Step: 13
Training loss: 0.39788226166958757
Validation loss: 2.525666171904463

Epoch: 467| Step: 0
Training loss: 0.203023224789304
Validation loss: 2.5269224819329015

Epoch: 6| Step: 1
Training loss: 0.3125554035664949
Validation loss: 2.5144163160578272

Epoch: 6| Step: 2
Training loss: 0.16255584385388588
Validation loss: 2.569339588386707

Epoch: 6| Step: 3
Training loss: 0.22850369153285835
Validation loss: 2.5007055907097158

Epoch: 6| Step: 4
Training loss: 0.21440889392251775
Validation loss: 2.534003162829246

Epoch: 6| Step: 5
Training loss: 0.39325416771777344
Validation loss: 2.5419200402433497

Epoch: 6| Step: 6
Training loss: 0.3162177784340563
Validation loss: 2.5265828276802416

Epoch: 6| Step: 7
Training loss: 0.2805970081990296
Validation loss: 2.519381422729757

Epoch: 6| Step: 8
Training loss: 0.1719871718493861
Validation loss: 2.5320084181442515

Epoch: 6| Step: 9
Training loss: 0.19462636590918114
Validation loss: 2.502662438708336

Epoch: 6| Step: 10
Training loss: 0.3828891755212646
Validation loss: 2.5020077365057145

Epoch: 6| Step: 11
Training loss: 0.1919514617723658
Validation loss: 2.5706376038049

Epoch: 6| Step: 12
Training loss: 0.28743681109587016
Validation loss: 2.5596071567332714

Epoch: 6| Step: 13
Training loss: 0.36221771018792537
Validation loss: 2.590186544361451

Epoch: 468| Step: 0
Training loss: 0.27398622495332897
Validation loss: 2.598440368029987

Epoch: 6| Step: 1
Training loss: 0.27087792921924964
Validation loss: 2.6018678864754685

Epoch: 6| Step: 2
Training loss: 0.4496385023026728
Validation loss: 2.621442459443212

Epoch: 6| Step: 3
Training loss: 0.3409514297940391
Validation loss: 2.5921164393357676

Epoch: 6| Step: 4
Training loss: 0.3199047424051338
Validation loss: 2.5765187718758398

Epoch: 6| Step: 5
Training loss: 0.2590579525326424
Validation loss: 2.544870391569991

Epoch: 6| Step: 6
Training loss: 0.16156479122780262
Validation loss: 2.493822694217959

Epoch: 6| Step: 7
Training loss: 0.2102773721501503
Validation loss: 2.479747407074295

Epoch: 6| Step: 8
Training loss: 0.3282747835069837
Validation loss: 2.457254511647888

Epoch: 6| Step: 9
Training loss: 0.35515702381376996
Validation loss: 2.5137583877894216

Epoch: 6| Step: 10
Training loss: 0.46091160459031344
Validation loss: 2.4787832370187592

Epoch: 6| Step: 11
Training loss: 0.36565201895886834
Validation loss: 2.4676254897324843

Epoch: 6| Step: 12
Training loss: 0.17688007236257314
Validation loss: 2.5405978792138506

Epoch: 6| Step: 13
Training loss: 0.26537409320196614
Validation loss: 2.5668505721680908

Epoch: 469| Step: 0
Training loss: 0.2206518231747283
Validation loss: 2.590356180703736

Epoch: 6| Step: 1
Training loss: 0.48600320034582456
Validation loss: 2.602257824334153

Epoch: 6| Step: 2
Training loss: 0.26433729342494366
Validation loss: 2.591477733241238

Epoch: 6| Step: 3
Training loss: 0.21247013807846238
Validation loss: 2.525404179195366

Epoch: 6| Step: 4
Training loss: 0.18351427346515842
Validation loss: 2.5230550256122544

Epoch: 6| Step: 5
Training loss: 0.24547455106372304
Validation loss: 2.5268834993015363

Epoch: 6| Step: 6
Training loss: 0.30657895190844503
Validation loss: 2.517472767817689

Epoch: 6| Step: 7
Training loss: 0.3936081464253936
Validation loss: 2.4734714293590274

Epoch: 6| Step: 8
Training loss: 0.23029632098747735
Validation loss: 2.479574123646982

Epoch: 6| Step: 9
Training loss: 0.2410482483459546
Validation loss: 2.4837164784855625

Epoch: 6| Step: 10
Training loss: 0.3281948832616905
Validation loss: 2.436058180690529

Epoch: 6| Step: 11
Training loss: 0.1713073253138837
Validation loss: 2.4479657156242745

Epoch: 6| Step: 12
Training loss: 0.3884911428470441
Validation loss: 2.4692872494659754

Epoch: 6| Step: 13
Training loss: 0.332690929989975
Validation loss: 2.4997632950324697

Epoch: 470| Step: 0
Training loss: 0.3209422944666319
Validation loss: 2.532258178214405

Epoch: 6| Step: 1
Training loss: 0.19517340475510087
Validation loss: 2.518163400191179

Epoch: 6| Step: 2
Training loss: 0.3252447279767464
Validation loss: 2.558730270123962

Epoch: 6| Step: 3
Training loss: 0.23615934319140636
Validation loss: 2.5126735580986663

Epoch: 6| Step: 4
Training loss: 0.3978048800018084
Validation loss: 2.5307550416063496

Epoch: 6| Step: 5
Training loss: 0.3232964184955879
Validation loss: 2.580727768320613

Epoch: 6| Step: 6
Training loss: 0.35335363185617114
Validation loss: 2.575397454947058

Epoch: 6| Step: 7
Training loss: 0.36037680684806717
Validation loss: 2.607026431785624

Epoch: 6| Step: 8
Training loss: 0.21619289912208864
Validation loss: 2.603361816727313

Epoch: 6| Step: 9
Training loss: 0.22625652567267449
Validation loss: 2.5551218972648346

Epoch: 6| Step: 10
Training loss: 0.20300437940491636
Validation loss: 2.564120189897634

Epoch: 6| Step: 11
Training loss: 0.2173743161497278
Validation loss: 2.5458749437994017

Epoch: 6| Step: 12
Training loss: 0.24772728584128847
Validation loss: 2.5705193692770254

Epoch: 6| Step: 13
Training loss: 0.2598827212866906
Validation loss: 2.5326524356469573

Epoch: 471| Step: 0
Training loss: 0.2099103289979235
Validation loss: 2.519247330222582

Epoch: 6| Step: 1
Training loss: 0.2732270111821141
Validation loss: 2.520508316987874

Epoch: 6| Step: 2
Training loss: 0.3590865636253704
Validation loss: 2.4896218999723647

Epoch: 6| Step: 3
Training loss: 0.2322230089331214
Validation loss: 2.532982617482094

Epoch: 6| Step: 4
Training loss: 0.2106961883319639
Validation loss: 2.514444227328626

Epoch: 6| Step: 5
Training loss: 0.2484637234601212
Validation loss: 2.535328007630245

Epoch: 6| Step: 6
Training loss: 0.3028179299504478
Validation loss: 2.5347204022848873

Epoch: 6| Step: 7
Training loss: 0.30918786043508917
Validation loss: 2.5641758578799867

Epoch: 6| Step: 8
Training loss: 0.2212682089613307
Validation loss: 2.529946706596331

Epoch: 6| Step: 9
Training loss: 0.38691964374119636
Validation loss: 2.552841946374132

Epoch: 6| Step: 10
Training loss: 0.3468453132538487
Validation loss: 2.519446514663774

Epoch: 6| Step: 11
Training loss: 0.2351071366638165
Validation loss: 2.502892125703798

Epoch: 6| Step: 12
Training loss: 0.15249386751633262
Validation loss: 2.4983366642193494

Epoch: 6| Step: 13
Training loss: 0.29321047665176425
Validation loss: 2.465563151147655

Epoch: 472| Step: 0
Training loss: 0.2534673271548435
Validation loss: 2.48354421521165

Epoch: 6| Step: 1
Training loss: 0.375493440232968
Validation loss: 2.4624645578321904

Epoch: 6| Step: 2
Training loss: 0.37541557173546336
Validation loss: 2.473094366449771

Epoch: 6| Step: 3
Training loss: 0.2809520839007626
Validation loss: 2.489193540883731

Epoch: 6| Step: 4
Training loss: 0.44422874415288893
Validation loss: 2.5341146452194225

Epoch: 6| Step: 5
Training loss: 0.2488243129683754
Validation loss: 2.509964568077564

Epoch: 6| Step: 6
Training loss: 0.2581356797306586
Validation loss: 2.512240628583748

Epoch: 6| Step: 7
Training loss: 0.22652569833657743
Validation loss: 2.524782219276062

Epoch: 6| Step: 8
Training loss: 0.22688641084658961
Validation loss: 2.564557843672965

Epoch: 6| Step: 9
Training loss: 0.26551411221511617
Validation loss: 2.529627290106573

Epoch: 6| Step: 10
Training loss: 0.26465644683542294
Validation loss: 2.556389316485473

Epoch: 6| Step: 11
Training loss: 0.2424008906014058
Validation loss: 2.5475050207802257

Epoch: 6| Step: 12
Training loss: 0.21590868836347116
Validation loss: 2.5048639183832653

Epoch: 6| Step: 13
Training loss: 0.1575610175371319
Validation loss: 2.5698277607042463

Epoch: 473| Step: 0
Training loss: 0.4068643253291448
Validation loss: 2.5173415738258633

Epoch: 6| Step: 1
Training loss: 0.237813020522642
Validation loss: 2.541988358160605

Epoch: 6| Step: 2
Training loss: 0.14477748129558973
Validation loss: 2.549557958532939

Epoch: 6| Step: 3
Training loss: 0.30064942827723895
Validation loss: 2.5692849472711687

Epoch: 6| Step: 4
Training loss: 0.15468175785889646
Validation loss: 2.542025990725641

Epoch: 6| Step: 5
Training loss: 0.27325183832277894
Validation loss: 2.5585519052813104

Epoch: 6| Step: 6
Training loss: 0.16686679080530387
Validation loss: 2.536047842363658

Epoch: 6| Step: 7
Training loss: 0.18768910964417862
Validation loss: 2.575455054648574

Epoch: 6| Step: 8
Training loss: 0.27733567723090324
Validation loss: 2.5482926048750314

Epoch: 6| Step: 9
Training loss: 0.2889155452505889
Validation loss: 2.5296912235524296

Epoch: 6| Step: 10
Training loss: 0.41553387037232625
Validation loss: 2.4893997961570085

Epoch: 6| Step: 11
Training loss: 0.230814093136241
Validation loss: 2.5095228240301344

Epoch: 6| Step: 12
Training loss: 0.20291730459284005
Validation loss: 2.469091567012502

Epoch: 6| Step: 13
Training loss: 0.2622391238898325
Validation loss: 2.490585017168026

Epoch: 474| Step: 0
Training loss: 0.31828242817184527
Validation loss: 2.472808590069086

Epoch: 6| Step: 1
Training loss: 0.25113537880682063
Validation loss: 2.4781673023758732

Epoch: 6| Step: 2
Training loss: 0.2731940957230777
Validation loss: 2.513680721413076

Epoch: 6| Step: 3
Training loss: 0.3029969952870252
Validation loss: 2.509000056232505

Epoch: 6| Step: 4
Training loss: 0.36249337848009
Validation loss: 2.5237418792201773

Epoch: 6| Step: 5
Training loss: 0.15552851280684188
Validation loss: 2.541056086769734

Epoch: 6| Step: 6
Training loss: 0.32604927911291176
Validation loss: 2.516673401637017

Epoch: 6| Step: 7
Training loss: 0.20722062069125147
Validation loss: 2.5245550641048946

Epoch: 6| Step: 8
Training loss: 0.19701503662752448
Validation loss: 2.512257437541774

Epoch: 6| Step: 9
Training loss: 0.1620946096107366
Validation loss: 2.513293492906744

Epoch: 6| Step: 10
Training loss: 0.2736364322180606
Validation loss: 2.535028501413785

Epoch: 6| Step: 11
Training loss: 0.19116357093924624
Validation loss: 2.538193469133889

Epoch: 6| Step: 12
Training loss: 0.24556678785899586
Validation loss: 2.545467988351484

Epoch: 6| Step: 13
Training loss: 0.09704653181913002
Validation loss: 2.490396950980635

Epoch: 475| Step: 0
Training loss: 0.36800103663474737
Validation loss: 2.5403065188242433

Epoch: 6| Step: 1
Training loss: 0.17334703242479835
Validation loss: 2.5401704365995528

Epoch: 6| Step: 2
Training loss: 0.2638927664736798
Validation loss: 2.49415118012657

Epoch: 6| Step: 3
Training loss: 0.14879387188522405
Validation loss: 2.54028592101133

Epoch: 6| Step: 4
Training loss: 0.21128792265776578
Validation loss: 2.484597652563307

Epoch: 6| Step: 5
Training loss: 0.2399189126102925
Validation loss: 2.494912532105323

Epoch: 6| Step: 6
Training loss: 0.37088504744992895
Validation loss: 2.4858481936368992

Epoch: 6| Step: 7
Training loss: 0.21892029230521626
Validation loss: 2.448896846403341

Epoch: 6| Step: 8
Training loss: 0.332537735988248
Validation loss: 2.4640916702381563

Epoch: 6| Step: 9
Training loss: 0.2280405681949461
Validation loss: 2.3985128569574976

Epoch: 6| Step: 10
Training loss: 0.3944812780779889
Validation loss: 2.457281763397918

Epoch: 6| Step: 11
Training loss: 0.33021136421874414
Validation loss: 2.434157430068293

Epoch: 6| Step: 12
Training loss: 0.2918519924252657
Validation loss: 2.482616755610155

Epoch: 6| Step: 13
Training loss: 0.2131485208134306
Validation loss: 2.515150501990985

Epoch: 476| Step: 0
Training loss: 0.19996849795440513
Validation loss: 2.520228398174053

Epoch: 6| Step: 1
Training loss: 0.1836261619202615
Validation loss: 2.506111139085964

Epoch: 6| Step: 2
Training loss: 0.15831374786568875
Validation loss: 2.5454164122296894

Epoch: 6| Step: 3
Training loss: 0.23997959334570146
Validation loss: 2.5609158116798163

Epoch: 6| Step: 4
Training loss: 0.22170102861163218
Validation loss: 2.581545593420144

Epoch: 6| Step: 5
Training loss: 0.24901778270808447
Validation loss: 2.570779005476382

Epoch: 6| Step: 6
Training loss: 0.2629217993743583
Validation loss: 2.588902532457444

Epoch: 6| Step: 7
Training loss: 0.2517065571650371
Validation loss: 2.5173061783430755

Epoch: 6| Step: 8
Training loss: 0.34116086368598164
Validation loss: 2.507597781096836

Epoch: 6| Step: 9
Training loss: 0.33219870664151296
Validation loss: 2.4966603460792802

Epoch: 6| Step: 10
Training loss: 0.1654081055796366
Validation loss: 2.4936513336743813

Epoch: 6| Step: 11
Training loss: 0.2505494873938401
Validation loss: 2.486127938084744

Epoch: 6| Step: 12
Training loss: 0.45611142248747605
Validation loss: 2.4846808648401986

Epoch: 6| Step: 13
Training loss: 0.26605961809754897
Validation loss: 2.468397038167195

Epoch: 477| Step: 0
Training loss: 0.2263585274120205
Validation loss: 2.490362394461629

Epoch: 6| Step: 1
Training loss: 0.16046894182121305
Validation loss: 2.469428437942467

Epoch: 6| Step: 2
Training loss: 0.24937352274454774
Validation loss: 2.4897579757088057

Epoch: 6| Step: 3
Training loss: 0.14773677769507051
Validation loss: 2.5103037466711577

Epoch: 6| Step: 4
Training loss: 0.2124567422594652
Validation loss: 2.5199466546980673

Epoch: 6| Step: 5
Training loss: 0.4355416575576916
Validation loss: 2.5222422636204795

Epoch: 6| Step: 6
Training loss: 0.1840375446830726
Validation loss: 2.5122647868335206

Epoch: 6| Step: 7
Training loss: 0.18988230356957703
Validation loss: 2.5558233812577336

Epoch: 6| Step: 8
Training loss: 0.23368697905501531
Validation loss: 2.508469084287527

Epoch: 6| Step: 9
Training loss: 0.3848718796616251
Validation loss: 2.5331714183583283

Epoch: 6| Step: 10
Training loss: 0.175500932342547
Validation loss: 2.52693254098556

Epoch: 6| Step: 11
Training loss: 0.2271900037289098
Validation loss: 2.5519599112893747

Epoch: 6| Step: 12
Training loss: 0.25529000214680087
Validation loss: 2.5899430649723834

Epoch: 6| Step: 13
Training loss: 0.41655763948070273
Validation loss: 2.5708307169659625

Epoch: 478| Step: 0
Training loss: 0.32261377660036206
Validation loss: 2.593646923536944

Epoch: 6| Step: 1
Training loss: 0.21054922679373242
Validation loss: 2.5415821501829443

Epoch: 6| Step: 2
Training loss: 0.22859464404021917
Validation loss: 2.5311120837705565

Epoch: 6| Step: 3
Training loss: 0.33192442129087124
Validation loss: 2.4744847416475264

Epoch: 6| Step: 4
Training loss: 0.38727885442427024
Validation loss: 2.461326406662161

Epoch: 6| Step: 5
Training loss: 0.3535911100106124
Validation loss: 2.44446503404328

Epoch: 6| Step: 6
Training loss: 0.3532189024920093
Validation loss: 2.448552510179248

Epoch: 6| Step: 7
Training loss: 0.5109114940686139
Validation loss: 2.422129338432637

Epoch: 6| Step: 8
Training loss: 0.37548258644418714
Validation loss: 2.3765915512502698

Epoch: 6| Step: 9
Training loss: 0.4037402093958046
Validation loss: 2.4252857232331855

Epoch: 6| Step: 10
Training loss: 0.2374610542689904
Validation loss: 2.4934977048908014

Epoch: 6| Step: 11
Training loss: 0.3591409418595522
Validation loss: 2.515607316740907

Epoch: 6| Step: 12
Training loss: 0.2881470179057798
Validation loss: 2.4853174763421255

Epoch: 6| Step: 13
Training loss: 0.30957141960258955
Validation loss: 2.5315770102959076

Epoch: 479| Step: 0
Training loss: 0.3262086036698225
Validation loss: 2.5625235543717926

Epoch: 6| Step: 1
Training loss: 0.33435718185865687
Validation loss: 2.595050841877517

Epoch: 6| Step: 2
Training loss: 0.23802123970536837
Validation loss: 2.624316687649865

Epoch: 6| Step: 3
Training loss: 0.4080010785633211
Validation loss: 2.61005776629204

Epoch: 6| Step: 4
Training loss: 0.30558583291398317
Validation loss: 2.614724791809713

Epoch: 6| Step: 5
Training loss: 0.27170114987775523
Validation loss: 2.6064262044723177

Epoch: 6| Step: 6
Training loss: 0.2140552791017982
Validation loss: 2.562322218235565

Epoch: 6| Step: 7
Training loss: 0.3195720814403092
Validation loss: 2.5514604750575467

Epoch: 6| Step: 8
Training loss: 0.3244074077256658
Validation loss: 2.543927953076413

Epoch: 6| Step: 9
Training loss: 0.2662305940800287
Validation loss: 2.557990451335319

Epoch: 6| Step: 10
Training loss: 0.40499281762076905
Validation loss: 2.498924499842678

Epoch: 6| Step: 11
Training loss: 0.24067538959958631
Validation loss: 2.487020944971263

Epoch: 6| Step: 12
Training loss: 0.3407311090507099
Validation loss: 2.4512440325899307

Epoch: 6| Step: 13
Training loss: 0.18893375190224898
Validation loss: 2.4602543343754455

Epoch: 480| Step: 0
Training loss: 0.4045911261786582
Validation loss: 2.45491412379387

Epoch: 6| Step: 1
Training loss: 0.2532869121382224
Validation loss: 2.435805271926928

Epoch: 6| Step: 2
Training loss: 0.23889348063950633
Validation loss: 2.5019140981200487

Epoch: 6| Step: 3
Training loss: 0.3335922906740953
Validation loss: 2.4867184669469955

Epoch: 6| Step: 4
Training loss: 0.2691914448144593
Validation loss: 2.5326883555802215

Epoch: 6| Step: 5
Training loss: 0.167064740219823
Validation loss: 2.5369755465083537

Epoch: 6| Step: 6
Training loss: 0.35048641184140605
Validation loss: 2.5504472971197787

Epoch: 6| Step: 7
Training loss: 0.3583384783323699
Validation loss: 2.5525010075847936

Epoch: 6| Step: 8
Training loss: 0.3253950931567438
Validation loss: 2.573614207189498

Epoch: 6| Step: 9
Training loss: 0.299870163915516
Validation loss: 2.609268224608392

Epoch: 6| Step: 10
Training loss: 0.3632292351350245
Validation loss: 2.5900639716435188

Epoch: 6| Step: 11
Training loss: 0.35673697048711894
Validation loss: 2.5703137667030975

Epoch: 6| Step: 12
Training loss: 0.38983558997900536
Validation loss: 2.620522827236221

Epoch: 6| Step: 13
Training loss: 0.2086950777522549
Validation loss: 2.581645913179856

Epoch: 481| Step: 0
Training loss: 0.26766345480392867
Validation loss: 2.562492142491933

Epoch: 6| Step: 1
Training loss: 0.33264176954912617
Validation loss: 2.5282044404650934

Epoch: 6| Step: 2
Training loss: 0.3209514061088919
Validation loss: 2.5154826957673

Epoch: 6| Step: 3
Training loss: 0.23561905661152452
Validation loss: 2.515670756588403

Epoch: 6| Step: 4
Training loss: 0.2583802214622257
Validation loss: 2.5441196620220334

Epoch: 6| Step: 5
Training loss: 0.32146731826197883
Validation loss: 2.527866137920734

Epoch: 6| Step: 6
Training loss: 0.3280885085749903
Validation loss: 2.520155206718075

Epoch: 6| Step: 7
Training loss: 0.2563143753972867
Validation loss: 2.5347780560240047

Epoch: 6| Step: 8
Training loss: 0.20919078366495017
Validation loss: 2.534113071089351

Epoch: 6| Step: 9
Training loss: 0.2357936284688119
Validation loss: 2.5688758732829844

Epoch: 6| Step: 10
Training loss: 0.3589819334194101
Validation loss: 2.562156163960036

Epoch: 6| Step: 11
Training loss: 0.3370353812016248
Validation loss: 2.5580436620578766

Epoch: 6| Step: 12
Training loss: 0.31951982995403616
Validation loss: 2.563278218133183

Epoch: 6| Step: 13
Training loss: 0.16135855958026474
Validation loss: 2.576370852662598

Epoch: 482| Step: 0
Training loss: 0.20549807466175843
Validation loss: 2.5546116690501135

Epoch: 6| Step: 1
Training loss: 0.35054922310110964
Validation loss: 2.5856082187256058

Epoch: 6| Step: 2
Training loss: 0.470588591004423
Validation loss: 2.5524284322002107

Epoch: 6| Step: 3
Training loss: 0.21885275130530674
Validation loss: 2.5705292048674044

Epoch: 6| Step: 4
Training loss: 0.29750548722311676
Validation loss: 2.5873086187490286

Epoch: 6| Step: 5
Training loss: 0.23231141486849677
Validation loss: 2.576722813776297

Epoch: 6| Step: 6
Training loss: 0.35622953389591683
Validation loss: 2.5677650725114103

Epoch: 6| Step: 7
Training loss: 0.1952437470542365
Validation loss: 2.5468250850816854

Epoch: 6| Step: 8
Training loss: 0.28621313120023545
Validation loss: 2.569021045714447

Epoch: 6| Step: 9
Training loss: 0.30861050524071765
Validation loss: 2.520021105536467

Epoch: 6| Step: 10
Training loss: 0.3306554789817624
Validation loss: 2.5079142875972154

Epoch: 6| Step: 11
Training loss: 0.3148375110623341
Validation loss: 2.4667954335474684

Epoch: 6| Step: 12
Training loss: 0.3193214249885863
Validation loss: 2.4148916834275327

Epoch: 6| Step: 13
Training loss: 0.17614121667232474
Validation loss: 2.4187067909257305

Epoch: 483| Step: 0
Training loss: 0.3610664038411606
Validation loss: 2.401861038753407

Epoch: 6| Step: 1
Training loss: 0.30186151987784154
Validation loss: 2.4161164425057877

Epoch: 6| Step: 2
Training loss: 0.3449847629540964
Validation loss: 2.446603283838066

Epoch: 6| Step: 3
Training loss: 0.38437030060539296
Validation loss: 2.480692859977409

Epoch: 6| Step: 4
Training loss: 0.1608247760322846
Validation loss: 2.4897034414835306

Epoch: 6| Step: 5
Training loss: 0.3525037457219767
Validation loss: 2.5268055860071965

Epoch: 6| Step: 6
Training loss: 0.25664413020093246
Validation loss: 2.555571990371202

Epoch: 6| Step: 7
Training loss: 0.27928308306166416
Validation loss: 2.6013076846143064

Epoch: 6| Step: 8
Training loss: 0.23506294059458557
Validation loss: 2.5973701225095644

Epoch: 6| Step: 9
Training loss: 0.4327938158429908
Validation loss: 2.5629857801123306

Epoch: 6| Step: 10
Training loss: 0.2642346204912535
Validation loss: 2.5454768410898034

Epoch: 6| Step: 11
Training loss: 0.3632116353594287
Validation loss: 2.604860818372814

Epoch: 6| Step: 12
Training loss: 0.21676838318153302
Validation loss: 2.5661106858120006

Epoch: 6| Step: 13
Training loss: 0.4272496860898083
Validation loss: 2.5225224417027605

Epoch: 484| Step: 0
Training loss: 0.33236713250049493
Validation loss: 2.522442012437319

Epoch: 6| Step: 1
Training loss: 0.16464749558836647
Validation loss: 2.5275860551873928

Epoch: 6| Step: 2
Training loss: 0.30357347916463484
Validation loss: 2.5079224520566337

Epoch: 6| Step: 3
Training loss: 0.35898550321881123
Validation loss: 2.485041883752021

Epoch: 6| Step: 4
Training loss: 0.2823758769796397
Validation loss: 2.4643142087424814

Epoch: 6| Step: 5
Training loss: 0.4535267791559224
Validation loss: 2.4465989814169196

Epoch: 6| Step: 6
Training loss: 0.3463614494112581
Validation loss: 2.4764001514318723

Epoch: 6| Step: 7
Training loss: 0.3499237437282435
Validation loss: 2.516399331886291

Epoch: 6| Step: 8
Training loss: 0.5281981716592352
Validation loss: 2.513383394908951

Epoch: 6| Step: 9
Training loss: 0.18630571290546333
Validation loss: 2.5365585331277356

Epoch: 6| Step: 10
Training loss: 0.2519391226019499
Validation loss: 2.481334870122861

Epoch: 6| Step: 11
Training loss: 0.22661043350644808
Validation loss: 2.51305850829245

Epoch: 6| Step: 12
Training loss: 0.2227642734227314
Validation loss: 2.4867893797072407

Epoch: 6| Step: 13
Training loss: 0.21201034854707954
Validation loss: 2.480681168156488

Epoch: 485| Step: 0
Training loss: 0.3465835437972749
Validation loss: 2.4851351505248607

Epoch: 6| Step: 1
Training loss: 0.24579454580043303
Validation loss: 2.497500504496095

Epoch: 6| Step: 2
Training loss: 0.2110101433458253
Validation loss: 2.5165829234324915

Epoch: 6| Step: 3
Training loss: 0.17565906834814216
Validation loss: 2.5330412803472964

Epoch: 6| Step: 4
Training loss: 0.30039280418131376
Validation loss: 2.528702486379239

Epoch: 6| Step: 5
Training loss: 0.21665981187125072
Validation loss: 2.527782930446047

Epoch: 6| Step: 6
Training loss: 0.2685718322829862
Validation loss: 2.5481841834840346

Epoch: 6| Step: 7
Training loss: 0.3123009286049514
Validation loss: 2.5304087285680725

Epoch: 6| Step: 8
Training loss: 0.44591448066178935
Validation loss: 2.533061388274623

Epoch: 6| Step: 9
Training loss: 0.29530231619739405
Validation loss: 2.5073037515581267

Epoch: 6| Step: 10
Training loss: 0.30049175103000175
Validation loss: 2.52275369636256

Epoch: 6| Step: 11
Training loss: 0.31766078806880316
Validation loss: 2.5063745396571706

Epoch: 6| Step: 12
Training loss: 0.3408902268717544
Validation loss: 2.554709085292568

Epoch: 6| Step: 13
Training loss: 0.18556863757551462
Validation loss: 2.4843082182954404

Epoch: 486| Step: 0
Training loss: 0.2929578651949313
Validation loss: 2.498686934780888

Epoch: 6| Step: 1
Training loss: 0.2320397385094538
Validation loss: 2.531040709145691

Epoch: 6| Step: 2
Training loss: 0.31649005627717913
Validation loss: 2.5676507878275743

Epoch: 6| Step: 3
Training loss: 0.26205647442124885
Validation loss: 2.554657268743563

Epoch: 6| Step: 4
Training loss: 0.2836248480610211
Validation loss: 2.5714458439603813

Epoch: 6| Step: 5
Training loss: 0.23683998541099396
Validation loss: 2.574916484054658

Epoch: 6| Step: 6
Training loss: 0.2634341545842842
Validation loss: 2.5695193494768485

Epoch: 6| Step: 7
Training loss: 0.23238970429702258
Validation loss: 2.6239285467563995

Epoch: 6| Step: 8
Training loss: 0.3085909251796022
Validation loss: 2.5936739362229995

Epoch: 6| Step: 9
Training loss: 0.4052839162919581
Validation loss: 2.5693021777772347

Epoch: 6| Step: 10
Training loss: 0.1847210929223806
Validation loss: 2.575035392294196

Epoch: 6| Step: 11
Training loss: 0.15699212146652286
Validation loss: 2.5665388824872584

Epoch: 6| Step: 12
Training loss: 0.31381290728419714
Validation loss: 2.575400061492154

Epoch: 6| Step: 13
Training loss: 0.24138136491626347
Validation loss: 2.5333714276943176

Epoch: 487| Step: 0
Training loss: 0.3205100822484593
Validation loss: 2.4954561070644843

Epoch: 6| Step: 1
Training loss: 0.26839197951902943
Validation loss: 2.528607159459879

Epoch: 6| Step: 2
Training loss: 0.22197012004083086
Validation loss: 2.525864538070358

Epoch: 6| Step: 3
Training loss: 0.20030694035865182
Validation loss: 2.542104082445535

Epoch: 6| Step: 4
Training loss: 0.37661558069958634
Validation loss: 2.547572959487839

Epoch: 6| Step: 5
Training loss: 0.17996029256908394
Validation loss: 2.516201049381692

Epoch: 6| Step: 6
Training loss: 0.25756186526821306
Validation loss: 2.5351679155887887

Epoch: 6| Step: 7
Training loss: 0.14790994607630162
Validation loss: 2.565221266475668

Epoch: 6| Step: 8
Training loss: 0.16754209313349824
Validation loss: 2.542784410956872

Epoch: 6| Step: 9
Training loss: 0.1709359373094447
Validation loss: 2.581613934700615

Epoch: 6| Step: 10
Training loss: 0.1749491600710932
Validation loss: 2.619946775972129

Epoch: 6| Step: 11
Training loss: 0.16267030828335408
Validation loss: 2.5765413563261266

Epoch: 6| Step: 12
Training loss: 0.3728962739060625
Validation loss: 2.5767960659263234

Epoch: 6| Step: 13
Training loss: 0.20306351538087564
Validation loss: 2.5528207048114093

Epoch: 488| Step: 0
Training loss: 0.27192210852609616
Validation loss: 2.551358219188457

Epoch: 6| Step: 1
Training loss: 0.21948107251186383
Validation loss: 2.5867366459962327

Epoch: 6| Step: 2
Training loss: 0.2784342081023057
Validation loss: 2.5356702787954353

Epoch: 6| Step: 3
Training loss: 0.24423948193864703
Validation loss: 2.5223022353590925

Epoch: 6| Step: 4
Training loss: 0.17082909948541566
Validation loss: 2.5293970409138327

Epoch: 6| Step: 5
Training loss: 0.25266677860458414
Validation loss: 2.512960831205679

Epoch: 6| Step: 6
Training loss: 0.2297643549137234
Validation loss: 2.5049332530858686

Epoch: 6| Step: 7
Training loss: 0.19899505322983704
Validation loss: 2.5175207738958845

Epoch: 6| Step: 8
Training loss: 0.29962993088772005
Validation loss: 2.5459337728016456

Epoch: 6| Step: 9
Training loss: 0.228455209489166
Validation loss: 2.562919696380197

Epoch: 6| Step: 10
Training loss: 0.18855633801515712
Validation loss: 2.5504657108165927

Epoch: 6| Step: 11
Training loss: 0.19989322106697205
Validation loss: 2.546181927777963

Epoch: 6| Step: 12
Training loss: 0.31185421975727196
Validation loss: 2.5317797393257067

Epoch: 6| Step: 13
Training loss: 0.18834563139904142
Validation loss: 2.543342286796273

Epoch: 489| Step: 0
Training loss: 0.3368297084306261
Validation loss: 2.5475936219067523

Epoch: 6| Step: 1
Training loss: 0.244728540167463
Validation loss: 2.5263588624463296

Epoch: 6| Step: 2
Training loss: 0.3237600873973678
Validation loss: 2.5709386444965756

Epoch: 6| Step: 3
Training loss: 0.12705763403248332
Validation loss: 2.535158420110994

Epoch: 6| Step: 4
Training loss: 0.21374988387199503
Validation loss: 2.5492235582847314

Epoch: 6| Step: 5
Training loss: 0.17350117335108273
Validation loss: 2.5265041613395987

Epoch: 6| Step: 6
Training loss: 0.15719176434520934
Validation loss: 2.541018179543452

Epoch: 6| Step: 7
Training loss: 0.17222527552586928
Validation loss: 2.5217367790832506

Epoch: 6| Step: 8
Training loss: 0.1285065102750967
Validation loss: 2.5349203248000727

Epoch: 6| Step: 9
Training loss: 0.23184981589808754
Validation loss: 2.5522736475696175

Epoch: 6| Step: 10
Training loss: 0.17615249425685164
Validation loss: 2.5750640920700527

Epoch: 6| Step: 11
Training loss: 0.2990733742206813
Validation loss: 2.5499315299296574

Epoch: 6| Step: 12
Training loss: 0.3331312694639517
Validation loss: 2.5560172977290354

Epoch: 6| Step: 13
Training loss: 0.19719896039894272
Validation loss: 2.5430165953539676

Epoch: 490| Step: 0
Training loss: 0.17633265265963333
Validation loss: 2.5675268042696997

Epoch: 6| Step: 1
Training loss: 0.299425264013371
Validation loss: 2.553421819361647

Epoch: 6| Step: 2
Training loss: 0.17843422024881048
Validation loss: 2.544274715999537

Epoch: 6| Step: 3
Training loss: 0.31993587961623055
Validation loss: 2.5818928669740075

Epoch: 6| Step: 4
Training loss: 0.2602197506590911
Validation loss: 2.5741008985706753

Epoch: 6| Step: 5
Training loss: 0.19468536782972362
Validation loss: 2.558744219805055

Epoch: 6| Step: 6
Training loss: 0.2566849007002358
Validation loss: 2.571441402229737

Epoch: 6| Step: 7
Training loss: 0.16150031518167263
Validation loss: 2.543655189193887

Epoch: 6| Step: 8
Training loss: 0.18679957894825605
Validation loss: 2.5461712314120826

Epoch: 6| Step: 9
Training loss: 0.21142771942448443
Validation loss: 2.5735735430664466

Epoch: 6| Step: 10
Training loss: 0.32551453647881057
Validation loss: 2.556098180469056

Epoch: 6| Step: 11
Training loss: 0.22254082548980875
Validation loss: 2.5822796341508756

Epoch: 6| Step: 12
Training loss: 0.3008602212058435
Validation loss: 2.5419392610204543

Epoch: 6| Step: 13
Training loss: 0.2337696045033948
Validation loss: 2.558871799300533

Epoch: 491| Step: 0
Training loss: 0.17209797181159553
Validation loss: 2.5638692595560526

Epoch: 6| Step: 1
Training loss: 0.15049879716870926
Validation loss: 2.5792792243920935

Epoch: 6| Step: 2
Training loss: 0.28412501802289164
Validation loss: 2.535970015522043

Epoch: 6| Step: 3
Training loss: 0.33151542762671005
Validation loss: 2.5353646368990774

Epoch: 6| Step: 4
Training loss: 0.12301949166062377
Validation loss: 2.5027615891620405

Epoch: 6| Step: 5
Training loss: 0.14411836364368735
Validation loss: 2.546693053655125

Epoch: 6| Step: 6
Training loss: 0.17864405313240622
Validation loss: 2.4998159320298177

Epoch: 6| Step: 7
Training loss: 0.2855551033556566
Validation loss: 2.473344519502838

Epoch: 6| Step: 8
Training loss: 0.24533739874760874
Validation loss: 2.4997713189490463

Epoch: 6| Step: 9
Training loss: 0.32387822434319513
Validation loss: 2.489322622100773

Epoch: 6| Step: 10
Training loss: 0.2273850472292438
Validation loss: 2.4802987769500073

Epoch: 6| Step: 11
Training loss: 0.31005856972041
Validation loss: 2.511146383869347

Epoch: 6| Step: 12
Training loss: 0.19705842722353886
Validation loss: 2.5229958987539365

Epoch: 6| Step: 13
Training loss: 0.21435791917933986
Validation loss: 2.5454592287430766

Epoch: 492| Step: 0
Training loss: 0.24621676594709102
Validation loss: 2.5723469790056535

Epoch: 6| Step: 1
Training loss: 0.26747130607741204
Validation loss: 2.565395239308433

Epoch: 6| Step: 2
Training loss: 0.18391886798285642
Validation loss: 2.5613205539193906

Epoch: 6| Step: 3
Training loss: 0.23868820740154686
Validation loss: 2.5759351929912553

Epoch: 6| Step: 4
Training loss: 0.21618868602185834
Validation loss: 2.5926650805609666

Epoch: 6| Step: 5
Training loss: 0.25604941321206864
Validation loss: 2.5918959548995564

Epoch: 6| Step: 6
Training loss: 0.2982013212233875
Validation loss: 2.5443804026856287

Epoch: 6| Step: 7
Training loss: 0.25930159575695494
Validation loss: 2.5530227997943165

Epoch: 6| Step: 8
Training loss: 0.20737559993098365
Validation loss: 2.5250762207489794

Epoch: 6| Step: 9
Training loss: 0.14282538255730104
Validation loss: 2.51077263354634

Epoch: 6| Step: 10
Training loss: 0.1835808546529108
Validation loss: 2.543312620735211

Epoch: 6| Step: 11
Training loss: 0.19899633558112714
Validation loss: 2.5511775889244053

Epoch: 6| Step: 12
Training loss: 0.2538983857330774
Validation loss: 2.5543266263026294

Epoch: 6| Step: 13
Training loss: 0.37256761292505813
Validation loss: 2.5358778369365544

Epoch: 493| Step: 0
Training loss: 0.30765802021592575
Validation loss: 2.5687955460615997

Epoch: 6| Step: 1
Training loss: 0.13811298359087024
Validation loss: 2.5172706000652805

Epoch: 6| Step: 2
Training loss: 0.28207115989930737
Validation loss: 2.5486219725790407

Epoch: 6| Step: 3
Training loss: 0.1660643506070824
Validation loss: 2.522840064372045

Epoch: 6| Step: 4
Training loss: 0.20182004229231765
Validation loss: 2.5203008078236593

Epoch: 6| Step: 5
Training loss: 0.16597863514522507
Validation loss: 2.5415057153709038

Epoch: 6| Step: 6
Training loss: 0.31321522404591834
Validation loss: 2.515563513655896

Epoch: 6| Step: 7
Training loss: 0.19665339804666176
Validation loss: 2.491783553996042

Epoch: 6| Step: 8
Training loss: 0.21405187670946038
Validation loss: 2.513090430946306

Epoch: 6| Step: 9
Training loss: 0.193929333138996
Validation loss: 2.546608074470725

Epoch: 6| Step: 10
Training loss: 0.2385909147662449
Validation loss: 2.5295489637070903

Epoch: 6| Step: 11
Training loss: 0.2754565085743632
Validation loss: 2.5543821173074415

Epoch: 6| Step: 12
Training loss: 0.24151895139162768
Validation loss: 2.5387400988027964

Epoch: 6| Step: 13
Training loss: 0.10901660613495619
Validation loss: 2.552089192072104

Epoch: 494| Step: 0
Training loss: 0.15291071807021392
Validation loss: 2.536761980254882

Epoch: 6| Step: 1
Training loss: 0.12131970996622317
Validation loss: 2.5461913005908365

Epoch: 6| Step: 2
Training loss: 0.30772875019248724
Validation loss: 2.5598509046440174

Epoch: 6| Step: 3
Training loss: 0.1165250212280088
Validation loss: 2.556570622903827

Epoch: 6| Step: 4
Training loss: 0.2847498519150212
Validation loss: 2.55582297200979

Epoch: 6| Step: 5
Training loss: 0.22416414001227386
Validation loss: 2.5572465458592655

Epoch: 6| Step: 6
Training loss: 0.2204039918023131
Validation loss: 2.5589066809494168

Epoch: 6| Step: 7
Training loss: 0.24594934707618138
Validation loss: 2.5753552914614772

Epoch: 6| Step: 8
Training loss: 0.25579681796524806
Validation loss: 2.5299548349139234

Epoch: 6| Step: 9
Training loss: 0.2195944494863574
Validation loss: 2.5515376395137137

Epoch: 6| Step: 10
Training loss: 0.1466846114753139
Validation loss: 2.5509581813936744

Epoch: 6| Step: 11
Training loss: 0.19113260287474693
Validation loss: 2.5521050293841285

Epoch: 6| Step: 12
Training loss: 0.28329358464870197
Validation loss: 2.5368203960535443

Epoch: 6| Step: 13
Training loss: 0.2541561950548451
Validation loss: 2.5401957542583853

Epoch: 495| Step: 0
Training loss: 0.24680478449527918
Validation loss: 2.5622817010784114

Epoch: 6| Step: 1
Training loss: 0.17273421533819625
Validation loss: 2.5346443997798653

Epoch: 6| Step: 2
Training loss: 0.16270000226610484
Validation loss: 2.518530424682586

Epoch: 6| Step: 3
Training loss: 0.21579835529743588
Validation loss: 2.5421568295188823

Epoch: 6| Step: 4
Training loss: 0.3865392634470695
Validation loss: 2.5398432694997317

Epoch: 6| Step: 5
Training loss: 0.2132081629688009
Validation loss: 2.526052745967748

Epoch: 6| Step: 6
Training loss: 0.1849976190046503
Validation loss: 2.5203822529061575

Epoch: 6| Step: 7
Training loss: 0.1866016922811145
Validation loss: 2.531064556281204

Epoch: 6| Step: 8
Training loss: 0.19719254679198991
Validation loss: 2.4974852896690765

Epoch: 6| Step: 9
Training loss: 0.1912140757348984
Validation loss: 2.51853008368227

Epoch: 6| Step: 10
Training loss: 0.17303996405998934
Validation loss: 2.5252709552106962

Epoch: 6| Step: 11
Training loss: 0.1422163999447571
Validation loss: 2.5052428844471475

Epoch: 6| Step: 12
Training loss: 0.2774727212540277
Validation loss: 2.5413289712386535

Epoch: 6| Step: 13
Training loss: 0.3570355062418857
Validation loss: 2.518342163090438

Epoch: 496| Step: 0
Training loss: 0.15610616739578403
Validation loss: 2.4955128937780002

Epoch: 6| Step: 1
Training loss: 0.308797153605767
Validation loss: 2.489001285660342

Epoch: 6| Step: 2
Training loss: 0.16224290909172484
Validation loss: 2.48674037830477

Epoch: 6| Step: 3
Training loss: 0.3279515330142276
Validation loss: 2.529067052384477

Epoch: 6| Step: 4
Training loss: 0.25898171217802335
Validation loss: 2.5185226630967916

Epoch: 6| Step: 5
Training loss: 0.239101646995436
Validation loss: 2.5382904459089084

Epoch: 6| Step: 6
Training loss: 0.15205955284067643
Validation loss: 2.557723408873763

Epoch: 6| Step: 7
Training loss: 0.1501158085942622
Validation loss: 2.55334031869992

Epoch: 6| Step: 8
Training loss: 0.2881123158937702
Validation loss: 2.6025923277466694

Epoch: 6| Step: 9
Training loss: 0.22035766672904356
Validation loss: 2.5752595153252

Epoch: 6| Step: 10
Training loss: 0.15663291384202646
Validation loss: 2.557731951577236

Epoch: 6| Step: 11
Training loss: 0.21789239619408157
Validation loss: 2.548579513487902

Epoch: 6| Step: 12
Training loss: 0.2913828331587067
Validation loss: 2.53358900137989

Epoch: 6| Step: 13
Training loss: 0.12867265545875275
Validation loss: 2.545716959118473

Epoch: 497| Step: 0
Training loss: 0.11749855324052329
Validation loss: 2.5466715252458463

Epoch: 6| Step: 1
Training loss: 0.12885593385982813
Validation loss: 2.5295082844252472

Epoch: 6| Step: 2
Training loss: 0.33840955455088456
Validation loss: 2.5178762013933937

Epoch: 6| Step: 3
Training loss: 0.1864385561515109
Validation loss: 2.5130690885247815

Epoch: 6| Step: 4
Training loss: 0.28432103210866316
Validation loss: 2.506783067981351

Epoch: 6| Step: 5
Training loss: 0.22177124653358601
Validation loss: 2.554104191520999

Epoch: 6| Step: 6
Training loss: 0.4270371454741293
Validation loss: 2.556506349845781

Epoch: 6| Step: 7
Training loss: 0.27888077638270037
Validation loss: 2.557798364786285

Epoch: 6| Step: 8
Training loss: 0.16632936788070402
Validation loss: 2.5354075407535572

Epoch: 6| Step: 9
Training loss: 0.2246937634705253
Validation loss: 2.5672812507391742

Epoch: 6| Step: 10
Training loss: 0.15851361218448756
Validation loss: 2.549441035078744

Epoch: 6| Step: 11
Training loss: 0.1214852618218831
Validation loss: 2.595906795677025

Epoch: 6| Step: 12
Training loss: 0.16533718608068768
Validation loss: 2.584210153396158

Epoch: 6| Step: 13
Training loss: 0.2122268916744865
Validation loss: 2.587644685593105

Epoch: 498| Step: 0
Training loss: 0.2819188298111311
Validation loss: 2.57325180047868

Epoch: 6| Step: 1
Training loss: 0.31503337138380944
Validation loss: 2.576541977201689

Epoch: 6| Step: 2
Training loss: 0.2390663003307785
Validation loss: 2.540082318360291

Epoch: 6| Step: 3
Training loss: 0.2340211899824087
Validation loss: 2.517824620078618

Epoch: 6| Step: 4
Training loss: 0.22538495709517156
Validation loss: 2.488655969669739

Epoch: 6| Step: 5
Training loss: 0.22994264263240932
Validation loss: 2.5309424133055773

Epoch: 6| Step: 6
Training loss: 0.23715866368425562
Validation loss: 2.5286179093400163

Epoch: 6| Step: 7
Training loss: 0.31764996362443065
Validation loss: 2.5105642007223197

Epoch: 6| Step: 8
Training loss: 0.24464128657096412
Validation loss: 2.5246234416857765

Epoch: 6| Step: 9
Training loss: 0.11675560359199025
Validation loss: 2.5198271012750024

Epoch: 6| Step: 10
Training loss: 0.21433650738873436
Validation loss: 2.4992083495862576

Epoch: 6| Step: 11
Training loss: 0.24006837831891342
Validation loss: 2.5403621329174446

Epoch: 6| Step: 12
Training loss: 0.08103866303846612
Validation loss: 2.5346961364287846

Epoch: 6| Step: 13
Training loss: 0.36680560848088534
Validation loss: 2.5461035951262434

Epoch: 499| Step: 0
Training loss: 0.313815685098785
Validation loss: 2.5372817854883056

Epoch: 6| Step: 1
Training loss: 0.21600737599079692
Validation loss: 2.5196736623572784

Epoch: 6| Step: 2
Training loss: 0.3070473858424949
Validation loss: 2.497412105143176

Epoch: 6| Step: 3
Training loss: 0.28159590483808217
Validation loss: 2.5016447993850357

Epoch: 6| Step: 4
Training loss: 0.22559752991850984
Validation loss: 2.499268768387227

Epoch: 6| Step: 5
Training loss: 0.21545893417860607
Validation loss: 2.4739052154244363

Epoch: 6| Step: 6
Training loss: 0.2621532221587557
Validation loss: 2.476603559316239

Epoch: 6| Step: 7
Training loss: 0.16814669343256294
Validation loss: 2.4948392730725684

Epoch: 6| Step: 8
Training loss: 0.21144213183745286
Validation loss: 2.474199215485714

Epoch: 6| Step: 9
Training loss: 0.2963650238291984
Validation loss: 2.51645146554546

Epoch: 6| Step: 10
Training loss: 0.27432483023246534
Validation loss: 2.5116638382746332

Epoch: 6| Step: 11
Training loss: 0.22713378701561726
Validation loss: 2.4696181310272123

Epoch: 6| Step: 12
Training loss: 0.16601230393622118
Validation loss: 2.5160460841008416

Epoch: 6| Step: 13
Training loss: 0.39051458705662967
Validation loss: 2.5638360703010155

Epoch: 500| Step: 0
Training loss: 0.20701939170992925
Validation loss: 2.5059421298554927

Epoch: 6| Step: 1
Training loss: 0.19848522078051542
Validation loss: 2.5188612892755575

Epoch: 6| Step: 2
Training loss: 0.24693605295779278
Validation loss: 2.5349043477604805

Epoch: 6| Step: 3
Training loss: 0.2225528694544849
Validation loss: 2.4863786172121607

Epoch: 6| Step: 4
Training loss: 0.22626747456399154
Validation loss: 2.4877213812690044

Epoch: 6| Step: 5
Training loss: 0.17533691195485027
Validation loss: 2.474353120885085

Epoch: 6| Step: 6
Training loss: 0.20368582990487827
Validation loss: 2.513692852799339

Epoch: 6| Step: 7
Training loss: 0.2539251907326509
Validation loss: 2.476656592266926

Epoch: 6| Step: 8
Training loss: 0.14582921062046175
Validation loss: 2.5200179152528204

Epoch: 6| Step: 9
Training loss: 0.34518899780382234
Validation loss: 2.4993443808676505

Epoch: 6| Step: 10
Training loss: 0.27191798484197094
Validation loss: 2.4994039112006496

Epoch: 6| Step: 11
Training loss: 0.1975020134799063
Validation loss: 2.54138569629589

Epoch: 6| Step: 12
Training loss: 0.3014747378273746
Validation loss: 2.5864245041007394

Epoch: 6| Step: 13
Training loss: 0.24731077020130335
Validation loss: 2.561149892791507

Epoch: 501| Step: 0
Training loss: 0.17497993720376587
Validation loss: 2.5445730240838036

Epoch: 6| Step: 1
Training loss: 0.2355669231328472
Validation loss: 2.5871972004611727

Epoch: 6| Step: 2
Training loss: 0.3137175801043789
Validation loss: 2.5577722872256015

Epoch: 6| Step: 3
Training loss: 0.2404687482525266
Validation loss: 2.5289990529334183

Epoch: 6| Step: 4
Training loss: 0.27992303722927103
Validation loss: 2.557515817319704

Epoch: 6| Step: 5
Training loss: 0.1589572381893878
Validation loss: 2.5579101536040856

Epoch: 6| Step: 6
Training loss: 0.2869805806166103
Validation loss: 2.577509380286229

Epoch: 6| Step: 7
Training loss: 0.2123467909852718
Validation loss: 2.5902852375168295

Epoch: 6| Step: 8
Training loss: 0.2666620737787935
Validation loss: 2.582567029528104

Epoch: 6| Step: 9
Training loss: 0.22873835834990658
Validation loss: 2.536582819572835

Epoch: 6| Step: 10
Training loss: 0.1829620613550014
Validation loss: 2.566914704066325

Epoch: 6| Step: 11
Training loss: 0.2449513820657481
Validation loss: 2.5861602519721325

Epoch: 6| Step: 12
Training loss: 0.15516446446227974
Validation loss: 2.53862580916464

Epoch: 6| Step: 13
Training loss: 0.21910655390888686
Validation loss: 2.543093669241316

Epoch: 502| Step: 0
Training loss: 0.3636567011206985
Validation loss: 2.570109944148721

Epoch: 6| Step: 1
Training loss: 0.22065828087205314
Validation loss: 2.560996844526759

Epoch: 6| Step: 2
Training loss: 0.17055963447535827
Validation loss: 2.5454529527257144

Epoch: 6| Step: 3
Training loss: 0.19068597029588472
Validation loss: 2.552424047017657

Epoch: 6| Step: 4
Training loss: 0.13220284585953723
Validation loss: 2.4982809206496737

Epoch: 6| Step: 5
Training loss: 0.1935124706339255
Validation loss: 2.5479176003666346

Epoch: 6| Step: 6
Training loss: 0.19849633148248189
Validation loss: 2.549330249561518

Epoch: 6| Step: 7
Training loss: 0.2980879424113586
Validation loss: 2.533799044958419

Epoch: 6| Step: 8
Training loss: 0.2585801919108483
Validation loss: 2.529872082222068

Epoch: 6| Step: 9
Training loss: 0.24368973103050104
Validation loss: 2.5286326861684754

Epoch: 6| Step: 10
Training loss: 0.33729941403187946
Validation loss: 2.5359947983958624

Epoch: 6| Step: 11
Training loss: 0.19153903714813986
Validation loss: 2.5280023825351114

Epoch: 6| Step: 12
Training loss: 0.2484548247792409
Validation loss: 2.509004704806441

Epoch: 6| Step: 13
Training loss: 0.19203659312463603
Validation loss: 2.5024087048946795

Epoch: 503| Step: 0
Training loss: 0.14948283588633451
Validation loss: 2.496324174886777

Epoch: 6| Step: 1
Training loss: 0.19634337172106753
Validation loss: 2.521842964532979

Epoch: 6| Step: 2
Training loss: 0.32862237291385127
Validation loss: 2.518641090079186

Epoch: 6| Step: 3
Training loss: 0.20224785318166522
Validation loss: 2.503581336733757

Epoch: 6| Step: 4
Training loss: 0.17826019309862126
Validation loss: 2.4858946127833184

Epoch: 6| Step: 5
Training loss: 0.3041051777433051
Validation loss: 2.53932105780689

Epoch: 6| Step: 6
Training loss: 0.2528556214514645
Validation loss: 2.5543068022026856

Epoch: 6| Step: 7
Training loss: 0.29130699625322143
Validation loss: 2.555530860591927

Epoch: 6| Step: 8
Training loss: 0.13704491265540042
Validation loss: 2.5209377775333195

Epoch: 6| Step: 9
Training loss: 0.12144722416484517
Validation loss: 2.5208980993013745

Epoch: 6| Step: 10
Training loss: 0.29680444481322055
Validation loss: 2.549902720710063

Epoch: 6| Step: 11
Training loss: 0.19922826781630748
Validation loss: 2.5315631149684585

Epoch: 6| Step: 12
Training loss: 0.16883763978017097
Validation loss: 2.5368295169581994

Epoch: 6| Step: 13
Training loss: 0.3655684264340664
Validation loss: 2.5284722533484763

Epoch: 504| Step: 0
Training loss: 0.1466593523825199
Validation loss: 2.5057640057215824

Epoch: 6| Step: 1
Training loss: 0.2807853091736735
Validation loss: 2.515594540325426

Epoch: 6| Step: 2
Training loss: 0.15138631515242426
Validation loss: 2.516368140927392

Epoch: 6| Step: 3
Training loss: 0.34070894668038404
Validation loss: 2.568647946602294

Epoch: 6| Step: 4
Training loss: 0.16801607219416936
Validation loss: 2.5336849452626398

Epoch: 6| Step: 5
Training loss: 0.2746672904312665
Validation loss: 2.538060286681027

Epoch: 6| Step: 6
Training loss: 0.22693557277439988
Validation loss: 2.5569915251165143

Epoch: 6| Step: 7
Training loss: 0.29117779405625155
Validation loss: 2.539570346525065

Epoch: 6| Step: 8
Training loss: 0.15944309322680522
Validation loss: 2.5530330562529957

Epoch: 6| Step: 9
Training loss: 0.2657649709256265
Validation loss: 2.5384303656668874

Epoch: 6| Step: 10
Training loss: 0.2815685322800174
Validation loss: 2.555424918266841

Epoch: 6| Step: 11
Training loss: 0.2012669607088094
Validation loss: 2.528308868810073

Epoch: 6| Step: 12
Training loss: 0.2417985037901317
Validation loss: 2.492615850335052

Epoch: 6| Step: 13
Training loss: 0.23049112793207235
Validation loss: 2.4779990191891526

Epoch: 505| Step: 0
Training loss: 0.2171411444229641
Validation loss: 2.4974130520424906

Epoch: 6| Step: 1
Training loss: 0.14286824325878172
Validation loss: 2.5227063386270645

Epoch: 6| Step: 2
Training loss: 0.3081074879333784
Validation loss: 2.5109695549427515

Epoch: 6| Step: 3
Training loss: 0.1731972121011029
Validation loss: 2.5122761005373446

Epoch: 6| Step: 4
Training loss: 0.29271526814908067
Validation loss: 2.5488243169948226

Epoch: 6| Step: 5
Training loss: 0.1416399344707811
Validation loss: 2.5501499757651382

Epoch: 6| Step: 6
Training loss: 0.27878333944395667
Validation loss: 2.5289760418899334

Epoch: 6| Step: 7
Training loss: 0.13851225087746136
Validation loss: 2.5375839080507894

Epoch: 6| Step: 8
Training loss: 0.29881896210628417
Validation loss: 2.533260240482635

Epoch: 6| Step: 9
Training loss: 0.19455195167418451
Validation loss: 2.536379818976013

Epoch: 6| Step: 10
Training loss: 0.190522586952789
Validation loss: 2.511119082692884

Epoch: 6| Step: 11
Training loss: 0.24097917982941108
Validation loss: 2.5442150054968837

Epoch: 6| Step: 12
Training loss: 0.3635956419013178
Validation loss: 2.5168670398776114

Epoch: 6| Step: 13
Training loss: 0.3783370589851468
Validation loss: 2.535079211878705

Epoch: 506| Step: 0
Training loss: 0.17318945795079224
Validation loss: 2.4856964763597627

Epoch: 6| Step: 1
Training loss: 0.26621066770029145
Validation loss: 2.4825020807454945

Epoch: 6| Step: 2
Training loss: 0.23009739877640906
Validation loss: 2.482241161440031

Epoch: 6| Step: 3
Training loss: 0.22767407582490135
Validation loss: 2.4720415724676896

Epoch: 6| Step: 4
Training loss: 0.23584758358846272
Validation loss: 2.4682630144557307

Epoch: 6| Step: 5
Training loss: 0.26170165447368804
Validation loss: 2.480237875365977

Epoch: 6| Step: 6
Training loss: 0.1880257705364307
Validation loss: 2.4922299991738246

Epoch: 6| Step: 7
Training loss: 0.19496490064814542
Validation loss: 2.477982205450069

Epoch: 6| Step: 8
Training loss: 0.24203225513000812
Validation loss: 2.5477778685710977

Epoch: 6| Step: 9
Training loss: 0.30451800449194666
Validation loss: 2.5313561985794877

Epoch: 6| Step: 10
Training loss: 0.2762138021927752
Validation loss: 2.5101874070703056

Epoch: 6| Step: 11
Training loss: 0.17629436201789356
Validation loss: 2.5173250259191207

Epoch: 6| Step: 12
Training loss: 0.09713169839490536
Validation loss: 2.549883927935361

Epoch: 6| Step: 13
Training loss: 0.44048322534067763
Validation loss: 2.5481074859192625

Epoch: 507| Step: 0
Training loss: 0.22233075895444224
Validation loss: 2.5283959454097897

Epoch: 6| Step: 1
Training loss: 0.2705349133959421
Validation loss: 2.567060481746481

Epoch: 6| Step: 2
Training loss: 0.16990472992088487
Validation loss: 2.6036215054440173

Epoch: 6| Step: 3
Training loss: 0.20994457802136388
Validation loss: 2.6295702556359832

Epoch: 6| Step: 4
Training loss: 0.24565919474278147
Validation loss: 2.6007369803323486

Epoch: 6| Step: 5
Training loss: 0.2146839414465438
Validation loss: 2.66300252573993

Epoch: 6| Step: 6
Training loss: 0.21982141778518033
Validation loss: 2.643376678241557

Epoch: 6| Step: 7
Training loss: 0.17883669488119977
Validation loss: 2.6193747654261004

Epoch: 6| Step: 8
Training loss: 0.28273700633831245
Validation loss: 2.587400737140734

Epoch: 6| Step: 9
Training loss: 0.23076943809587078
Validation loss: 2.559113902724977

Epoch: 6| Step: 10
Training loss: 0.21026945291422142
Validation loss: 2.545331436753852

Epoch: 6| Step: 11
Training loss: 0.2885967833189696
Validation loss: 2.5309297153163

Epoch: 6| Step: 12
Training loss: 0.33775370916423586
Validation loss: 2.478571958934476

Epoch: 6| Step: 13
Training loss: 0.15834118858623625
Validation loss: 2.4938178410424525

Epoch: 508| Step: 0
Training loss: 0.1893957287078922
Validation loss: 2.4362901620052564

Epoch: 6| Step: 1
Training loss: 0.33781813797670257
Validation loss: 2.4294027918673415

Epoch: 6| Step: 2
Training loss: 0.20830818660286476
Validation loss: 2.4103921100177677

Epoch: 6| Step: 3
Training loss: 0.18184934949734932
Validation loss: 2.395571248047771

Epoch: 6| Step: 4
Training loss: 0.20592322834096113
Validation loss: 2.4070194283648254

Epoch: 6| Step: 5
Training loss: 0.1751529697720188
Validation loss: 2.439559353715245

Epoch: 6| Step: 6
Training loss: 0.17964343899091204
Validation loss: 2.397005988539585

Epoch: 6| Step: 7
Training loss: 0.1951384245471777
Validation loss: 2.465768777574158

Epoch: 6| Step: 8
Training loss: 0.1596611383126189
Validation loss: 2.4489900733741448

Epoch: 6| Step: 9
Training loss: 0.30986312351649586
Validation loss: 2.4903174051062793

Epoch: 6| Step: 10
Training loss: 0.19901216304691347
Validation loss: 2.463930633966083

Epoch: 6| Step: 11
Training loss: 0.24521027275513338
Validation loss: 2.538406628127325

Epoch: 6| Step: 12
Training loss: 0.3572148833704222
Validation loss: 2.5407448268105735

Epoch: 6| Step: 13
Training loss: 0.11244502214319932
Validation loss: 2.5727613831600573

Epoch: 509| Step: 0
Training loss: 0.20092786415809713
Validation loss: 2.529561774028632

Epoch: 6| Step: 1
Training loss: 0.1807490174845878
Validation loss: 2.583995345420884

Epoch: 6| Step: 2
Training loss: 0.14464998523070585
Validation loss: 2.543257565088308

Epoch: 6| Step: 3
Training loss: 0.18269330238735595
Validation loss: 2.5693246325897015

Epoch: 6| Step: 4
Training loss: 0.15434624690847357
Validation loss: 2.583409756480409

Epoch: 6| Step: 5
Training loss: 0.3318435362719882
Validation loss: 2.5930424256500073

Epoch: 6| Step: 6
Training loss: 0.3367492936303222
Validation loss: 2.5703348447504974

Epoch: 6| Step: 7
Training loss: 0.1327879476292278
Validation loss: 2.5816947783929467

Epoch: 6| Step: 8
Training loss: 0.11766611748107711
Validation loss: 2.573878007330464

Epoch: 6| Step: 9
Training loss: 0.17798411461247896
Validation loss: 2.5807397037410733

Epoch: 6| Step: 10
Training loss: 0.2610159590398437
Validation loss: 2.573933124140325

Epoch: 6| Step: 11
Training loss: 0.19283495214308127
Validation loss: 2.5649283273527654

Epoch: 6| Step: 12
Training loss: 0.18380027680028552
Validation loss: 2.558230206537203

Epoch: 6| Step: 13
Training loss: 0.29492264551731534
Validation loss: 2.586292462197592

Epoch: 510| Step: 0
Training loss: 0.3087213831740117
Validation loss: 2.5194618286123265

Epoch: 6| Step: 1
Training loss: 0.15853029141887298
Validation loss: 2.517951909771903

Epoch: 6| Step: 2
Training loss: 0.40312138193562086
Validation loss: 2.517189433677482

Epoch: 6| Step: 3
Training loss: 0.23347689694474308
Validation loss: 2.5134360802024656

Epoch: 6| Step: 4
Training loss: 0.14298759737490835
Validation loss: 2.5326482642211388

Epoch: 6| Step: 5
Training loss: 0.20602798288868676
Validation loss: 2.512321433416033

Epoch: 6| Step: 6
Training loss: 0.23011143512882481
Validation loss: 2.557278983057107

Epoch: 6| Step: 7
Training loss: 0.21175354710336136
Validation loss: 2.5932287094371227

Epoch: 6| Step: 8
Training loss: 0.28080475850474923
Validation loss: 2.539878852557683

Epoch: 6| Step: 9
Training loss: 0.2230343953798499
Validation loss: 2.5504178938824253

Epoch: 6| Step: 10
Training loss: 0.17848481010404682
Validation loss: 2.566413168527068

Epoch: 6| Step: 11
Training loss: 0.11912473979173002
Validation loss: 2.5601547588128115

Epoch: 6| Step: 12
Training loss: 0.10506540455453955
Validation loss: 2.543256058610113

Epoch: 6| Step: 13
Training loss: 0.24719012977609423
Validation loss: 2.566219727432159

Epoch: 511| Step: 0
Training loss: 0.2701494894069836
Validation loss: 2.572859478287078

Epoch: 6| Step: 1
Training loss: 0.15479957200559202
Validation loss: 2.534498177755465

Epoch: 6| Step: 2
Training loss: 0.26372523297729816
Validation loss: 2.549026451241784

Epoch: 6| Step: 3
Training loss: 0.41225754302522666
Validation loss: 2.5127684284359506

Epoch: 6| Step: 4
Training loss: 0.22686094325895242
Validation loss: 2.5384431947935555

Epoch: 6| Step: 5
Training loss: 0.16221235060998387
Validation loss: 2.57375199145181

Epoch: 6| Step: 6
Training loss: 0.18061234017327504
Validation loss: 2.585038355738761

Epoch: 6| Step: 7
Training loss: 0.3314442663226816
Validation loss: 2.59644175087889

Epoch: 6| Step: 8
Training loss: 0.45541498707702693
Validation loss: 2.574450690473179

Epoch: 6| Step: 9
Training loss: 0.26315027142763864
Validation loss: 2.576510949160363

Epoch: 6| Step: 10
Training loss: 0.20859125185838595
Validation loss: 2.56160934100468

Epoch: 6| Step: 11
Training loss: 0.2144775738007762
Validation loss: 2.542604043249674

Epoch: 6| Step: 12
Training loss: 0.15800669331384104
Validation loss: 2.523135443338272

Epoch: 6| Step: 13
Training loss: 0.24889347200467477
Validation loss: 2.507080877127952

Epoch: 512| Step: 0
Training loss: 0.2492921837628605
Validation loss: 2.498428702572861

Epoch: 6| Step: 1
Training loss: 0.23976030327045317
Validation loss: 2.530621078670886

Epoch: 6| Step: 2
Training loss: 0.26963886932015446
Validation loss: 2.5642055974986198

Epoch: 6| Step: 3
Training loss: 0.27269011945688226
Validation loss: 2.561781411569724

Epoch: 6| Step: 4
Training loss: 0.22709884955099252
Validation loss: 2.5524185710530523

Epoch: 6| Step: 5
Training loss: 0.19520234816511214
Validation loss: 2.5582761831561687

Epoch: 6| Step: 6
Training loss: 0.11558488298085295
Validation loss: 2.558708515362859

Epoch: 6| Step: 7
Training loss: 0.16353604454857162
Validation loss: 2.5518031396970122

Epoch: 6| Step: 8
Training loss: 0.1745653431907039
Validation loss: 2.542160894581674

Epoch: 6| Step: 9
Training loss: 0.13100313005366163
Validation loss: 2.60583878680932

Epoch: 6| Step: 10
Training loss: 0.17403453187867107
Validation loss: 2.582623541697158

Epoch: 6| Step: 11
Training loss: 0.2500635900685817
Validation loss: 2.5646818063250936

Epoch: 6| Step: 12
Training loss: 0.1775633020084131
Validation loss: 2.5831545557197386

Epoch: 6| Step: 13
Training loss: 0.513723450598881
Validation loss: 2.546826259786595

Epoch: 513| Step: 0
Training loss: 0.19459675295037948
Validation loss: 2.6005371284356746

Epoch: 6| Step: 1
Training loss: 0.14063152324593514
Validation loss: 2.589135885397044

Epoch: 6| Step: 2
Training loss: 0.22038801873906397
Validation loss: 2.6267849946868016

Epoch: 6| Step: 3
Training loss: 0.20771209758024667
Validation loss: 2.6209563671713996

Epoch: 6| Step: 4
Training loss: 0.23498924351231115
Validation loss: 2.6393074621912906

Epoch: 6| Step: 5
Training loss: 0.1779454413766625
Validation loss: 2.656904271502631

Epoch: 6| Step: 6
Training loss: 0.29631002524243044
Validation loss: 2.6227857633407647

Epoch: 6| Step: 7
Training loss: 0.2200133338458368
Validation loss: 2.618660921177506

Epoch: 6| Step: 8
Training loss: 0.19958651014187542
Validation loss: 2.5752367922097363

Epoch: 6| Step: 9
Training loss: 0.3205028294112575
Validation loss: 2.517336954904502

Epoch: 6| Step: 10
Training loss: 0.25170574315645494
Validation loss: 2.5343202277133994

Epoch: 6| Step: 11
Training loss: 0.16930080784206675
Validation loss: 2.5594245980062245

Epoch: 6| Step: 12
Training loss: 0.13285898348846947
Validation loss: 2.5185620326666314

Epoch: 6| Step: 13
Training loss: 0.18435176646405654
Validation loss: 2.509328698744161

Epoch: 514| Step: 0
Training loss: 0.1456278235648821
Validation loss: 2.559627802132377

Epoch: 6| Step: 1
Training loss: 0.2900171496401214
Validation loss: 2.528990366542529

Epoch: 6| Step: 2
Training loss: 0.23361810219176177
Validation loss: 2.527341319588262

Epoch: 6| Step: 3
Training loss: 0.21686548573569617
Validation loss: 2.5558567036504254

Epoch: 6| Step: 4
Training loss: 0.2763867320775831
Validation loss: 2.48233069779128

Epoch: 6| Step: 5
Training loss: 0.36508318377760735
Validation loss: 2.545910708393857

Epoch: 6| Step: 6
Training loss: 0.1555787270187495
Validation loss: 2.5349309144129935

Epoch: 6| Step: 7
Training loss: 0.17829657289016237
Validation loss: 2.54009650367557

Epoch: 6| Step: 8
Training loss: 0.16564400536879084
Validation loss: 2.558503722186885

Epoch: 6| Step: 9
Training loss: 0.21706807297214978
Validation loss: 2.530710697388842

Epoch: 6| Step: 10
Training loss: 0.1484073118833336
Validation loss: 2.547039659548622

Epoch: 6| Step: 11
Training loss: 0.24516158442774852
Validation loss: 2.5373292207697125

Epoch: 6| Step: 12
Training loss: 0.19850231824140932
Validation loss: 2.5551285543771534

Epoch: 6| Step: 13
Training loss: 0.24926168974703633
Validation loss: 2.581082077302861

Epoch: 515| Step: 0
Training loss: 0.3711744120420202
Validation loss: 2.567144125802424

Epoch: 6| Step: 1
Training loss: 0.14302436028493995
Validation loss: 2.5953980147429996

Epoch: 6| Step: 2
Training loss: 0.25159416947136165
Validation loss: 2.5774677113674835

Epoch: 6| Step: 3
Training loss: 0.17315075191332613
Validation loss: 2.607827784834727

Epoch: 6| Step: 4
Training loss: 0.30732720649074236
Validation loss: 2.6138686781352134

Epoch: 6| Step: 5
Training loss: 0.23264991568453777
Validation loss: 2.6001761838223985

Epoch: 6| Step: 6
Training loss: 0.3246016481951167
Validation loss: 2.580276141713739

Epoch: 6| Step: 7
Training loss: 0.31548182526047847
Validation loss: 2.5976813133252548

Epoch: 6| Step: 8
Training loss: 0.13657200976590905
Validation loss: 2.5599748068096693

Epoch: 6| Step: 9
Training loss: 0.2650748895593284
Validation loss: 2.5323344188703305

Epoch: 6| Step: 10
Training loss: 0.13822728736690398
Validation loss: 2.5687744254434595

Epoch: 6| Step: 11
Training loss: 0.34640038213031515
Validation loss: 2.5252207711206784

Epoch: 6| Step: 12
Training loss: 0.13567189928524895
Validation loss: 2.5279432330913103

Epoch: 6| Step: 13
Training loss: 0.22372634464294203
Validation loss: 2.5165163638124075

Epoch: 516| Step: 0
Training loss: 0.32728374586753595
Validation loss: 2.4853907622929907

Epoch: 6| Step: 1
Training loss: 0.18266436533525318
Validation loss: 2.501867206140784

Epoch: 6| Step: 2
Training loss: 0.2714828930272332
Validation loss: 2.459525596307862

Epoch: 6| Step: 3
Training loss: 0.19875506124709855
Validation loss: 2.54815747431257

Epoch: 6| Step: 4
Training loss: 0.31911045244665703
Validation loss: 2.563142469348561

Epoch: 6| Step: 5
Training loss: 0.2938603249807981
Validation loss: 2.5884756672131646

Epoch: 6| Step: 6
Training loss: 0.4032570740859125
Validation loss: 2.5977818395414443

Epoch: 6| Step: 7
Training loss: 0.16514007592017463
Validation loss: 2.5699355832165085

Epoch: 6| Step: 8
Training loss: 0.2464366673216755
Validation loss: 2.6269489169206213

Epoch: 6| Step: 9
Training loss: 0.21473638279266336
Validation loss: 2.5809090059325124

Epoch: 6| Step: 10
Training loss: 0.2667638263926638
Validation loss: 2.599852748831282

Epoch: 6| Step: 11
Training loss: 0.17618432984235238
Validation loss: 2.56073599625271

Epoch: 6| Step: 12
Training loss: 0.3701362303009522
Validation loss: 2.55002395852673

Epoch: 6| Step: 13
Training loss: 0.24093303038017397
Validation loss: 2.5362937685025893

Epoch: 517| Step: 0
Training loss: 0.29246536241345195
Validation loss: 2.5344584144332942

Epoch: 6| Step: 1
Training loss: 0.22752351666828227
Validation loss: 2.506232852001014

Epoch: 6| Step: 2
Training loss: 0.19338177059985398
Validation loss: 2.5050730925974003

Epoch: 6| Step: 3
Training loss: 0.30504657909517885
Validation loss: 2.547005044161352

Epoch: 6| Step: 4
Training loss: 0.3163788277316487
Validation loss: 2.5308346070122143

Epoch: 6| Step: 5
Training loss: 0.2231496397139034
Validation loss: 2.523791976409212

Epoch: 6| Step: 6
Training loss: 0.13691932406906535
Validation loss: 2.52677534227912

Epoch: 6| Step: 7
Training loss: 0.12737297179186186
Validation loss: 2.5262688640641064

Epoch: 6| Step: 8
Training loss: 0.3572884399149726
Validation loss: 2.529490624743142

Epoch: 6| Step: 9
Training loss: 0.2085842419718333
Validation loss: 2.516006613007466

Epoch: 6| Step: 10
Training loss: 0.19267285939788728
Validation loss: 2.5197323959783646

Epoch: 6| Step: 11
Training loss: 0.23301668749756127
Validation loss: 2.4944526741253594

Epoch: 6| Step: 12
Training loss: 0.19727374522803917
Validation loss: 2.4997894341997338

Epoch: 6| Step: 13
Training loss: 0.16718904703975332
Validation loss: 2.477862690845819

Epoch: 518| Step: 0
Training loss: 0.28661737650811675
Validation loss: 2.453053613620367

Epoch: 6| Step: 1
Training loss: 0.3555712290171976
Validation loss: 2.519368307395412

Epoch: 6| Step: 2
Training loss: 0.2642759115332405
Validation loss: 2.5212978367971597

Epoch: 6| Step: 3
Training loss: 0.19331886368041168
Validation loss: 2.522201344012867

Epoch: 6| Step: 4
Training loss: 0.17951511323815877
Validation loss: 2.5347010114652053

Epoch: 6| Step: 5
Training loss: 0.1513230905596392
Validation loss: 2.5179790630487444

Epoch: 6| Step: 6
Training loss: 0.17218698016882658
Validation loss: 2.541839090614852

Epoch: 6| Step: 7
Training loss: 0.20549153031230788
Validation loss: 2.555963479127118

Epoch: 6| Step: 8
Training loss: 0.35456103452382665
Validation loss: 2.545477723340536

Epoch: 6| Step: 9
Training loss: 0.1900509711961587
Validation loss: 2.553462066221982

Epoch: 6| Step: 10
Training loss: 0.24048052946690085
Validation loss: 2.5352316769526344

Epoch: 6| Step: 11
Training loss: 0.2754218307021572
Validation loss: 2.5152059369188815

Epoch: 6| Step: 12
Training loss: 0.24105100696593149
Validation loss: 2.4765765615855764

Epoch: 6| Step: 13
Training loss: 0.2636386426540155
Validation loss: 2.4801183914177756

Epoch: 519| Step: 0
Training loss: 0.26927357948324493
Validation loss: 2.4762525969172704

Epoch: 6| Step: 1
Training loss: 0.22371506323656007
Validation loss: 2.4534384262919127

Epoch: 6| Step: 2
Training loss: 0.2803480733457941
Validation loss: 2.4749814184971917

Epoch: 6| Step: 3
Training loss: 0.3580865152262175
Validation loss: 2.467335456824134

Epoch: 6| Step: 4
Training loss: 0.1726841951427463
Validation loss: 2.5022411401761073

Epoch: 6| Step: 5
Training loss: 0.18590236540233937
Validation loss: 2.512231152575929

Epoch: 6| Step: 6
Training loss: 0.22060157330009034
Validation loss: 2.54525820670818

Epoch: 6| Step: 7
Training loss: 0.1680532509034484
Validation loss: 2.5610846956192064

Epoch: 6| Step: 8
Training loss: 0.1612429040449024
Validation loss: 2.56539318571313

Epoch: 6| Step: 9
Training loss: 0.2518881780617819
Validation loss: 2.543114791443699

Epoch: 6| Step: 10
Training loss: 0.14255989951086973
Validation loss: 2.6100353603743915

Epoch: 6| Step: 11
Training loss: 0.26882788893432363
Validation loss: 2.5798352288886726

Epoch: 6| Step: 12
Training loss: 0.12493387350751146
Validation loss: 2.5647718674166717

Epoch: 6| Step: 13
Training loss: 0.15755797341005798
Validation loss: 2.586156034020135

Epoch: 520| Step: 0
Training loss: 0.18932208218886915
Validation loss: 2.5916200103875626

Epoch: 6| Step: 1
Training loss: 0.20606570643752561
Validation loss: 2.586950906753089

Epoch: 6| Step: 2
Training loss: 0.2640766709943747
Validation loss: 2.5328838261547135

Epoch: 6| Step: 3
Training loss: 0.22073802840797518
Validation loss: 2.5490262963588597

Epoch: 6| Step: 4
Training loss: 0.3985184605940098
Validation loss: 2.5117360197084144

Epoch: 6| Step: 5
Training loss: 0.14969381932276948
Validation loss: 2.530200624768085

Epoch: 6| Step: 6
Training loss: 0.23836311122350412
Validation loss: 2.5242761404277667

Epoch: 6| Step: 7
Training loss: 0.2520914806804324
Validation loss: 2.523056366718275

Epoch: 6| Step: 8
Training loss: 0.12676492092144395
Validation loss: 2.5044809412410705

Epoch: 6| Step: 9
Training loss: 0.20164567281146012
Validation loss: 2.4898664289760375

Epoch: 6| Step: 10
Training loss: 0.16233293216412276
Validation loss: 2.506630587158893

Epoch: 6| Step: 11
Training loss: 0.20013264861611865
Validation loss: 2.445509273796265

Epoch: 6| Step: 12
Training loss: 0.21809295342372734
Validation loss: 2.4438808044753615

Epoch: 6| Step: 13
Training loss: 0.2958262138226385
Validation loss: 2.503468274492244

Epoch: 521| Step: 0
Training loss: 0.17498062379891693
Validation loss: 2.4939140711397214

Epoch: 6| Step: 1
Training loss: 0.19637228496818743
Validation loss: 2.5039409062781024

Epoch: 6| Step: 2
Training loss: 0.15494720207712073
Validation loss: 2.5298949204479357

Epoch: 6| Step: 3
Training loss: 0.23467774706155475
Validation loss: 2.5173390044214203

Epoch: 6| Step: 4
Training loss: 0.1978125497025462
Validation loss: 2.535705926478237

Epoch: 6| Step: 5
Training loss: 0.23651790880188178
Validation loss: 2.5304137544627068

Epoch: 6| Step: 6
Training loss: 0.24362352158698258
Validation loss: 2.5740882770384568

Epoch: 6| Step: 7
Training loss: 0.2863868392968017
Validation loss: 2.5781929193613373

Epoch: 6| Step: 8
Training loss: 0.21702029769759096
Validation loss: 2.5295384883832854

Epoch: 6| Step: 9
Training loss: 0.2423720502654227
Validation loss: 2.538755132783151

Epoch: 6| Step: 10
Training loss: 0.15790677276364748
Validation loss: 2.567573173560123

Epoch: 6| Step: 11
Training loss: 0.299610783500295
Validation loss: 2.5580065557784275

Epoch: 6| Step: 12
Training loss: 0.2664504408891595
Validation loss: 2.5328755437749995

Epoch: 6| Step: 13
Training loss: 0.1710084615490569
Validation loss: 2.5420162193220643

Epoch: 522| Step: 0
Training loss: 0.21985966359815537
Validation loss: 2.54530388684786

Epoch: 6| Step: 1
Training loss: 0.1530181312344102
Validation loss: 2.5025279707564185

Epoch: 6| Step: 2
Training loss: 0.18889783316730574
Validation loss: 2.500655092527952

Epoch: 6| Step: 3
Training loss: 0.17045281212460037
Validation loss: 2.4923908619873587

Epoch: 6| Step: 4
Training loss: 0.11174202823207503
Validation loss: 2.500650728300458

Epoch: 6| Step: 5
Training loss: 0.129392299992739
Validation loss: 2.511808393498985

Epoch: 6| Step: 6
Training loss: 0.16014881814600376
Validation loss: 2.531576450798171

Epoch: 6| Step: 7
Training loss: 0.2365218306596326
Validation loss: 2.5439508520519554

Epoch: 6| Step: 8
Training loss: 0.2928058171196671
Validation loss: 2.4823506309248002

Epoch: 6| Step: 9
Training loss: 0.3103726936190113
Validation loss: 2.502396727796639

Epoch: 6| Step: 10
Training loss: 0.15661748943565204
Validation loss: 2.5066791639456105

Epoch: 6| Step: 11
Training loss: 0.2920243108423992
Validation loss: 2.513047411318658

Epoch: 6| Step: 12
Training loss: 0.16838153308288004
Validation loss: 2.5099453261282263

Epoch: 6| Step: 13
Training loss: 0.14383087707779174
Validation loss: 2.5346598666725737

Epoch: 523| Step: 0
Training loss: 0.23740052222899063
Validation loss: 2.531884037419601

Epoch: 6| Step: 1
Training loss: 0.2175487847809111
Validation loss: 2.5144445316689152

Epoch: 6| Step: 2
Training loss: 0.12394324285616871
Validation loss: 2.5834828750947234

Epoch: 6| Step: 3
Training loss: 0.1843296075968088
Validation loss: 2.570392758870295

Epoch: 6| Step: 4
Training loss: 0.11984179491440262
Validation loss: 2.5912495685964045

Epoch: 6| Step: 5
Training loss: 0.20107698517388206
Validation loss: 2.610890478512928

Epoch: 6| Step: 6
Training loss: 0.18741019402978723
Validation loss: 2.5790545560577574

Epoch: 6| Step: 7
Training loss: 0.27014904813505236
Validation loss: 2.54513061627875

Epoch: 6| Step: 8
Training loss: 0.22767437852877512
Validation loss: 2.5970795668473183

Epoch: 6| Step: 9
Training loss: 0.32781773894844773
Validation loss: 2.595651140622011

Epoch: 6| Step: 10
Training loss: 0.29556043601328774
Validation loss: 2.5621376551757433

Epoch: 6| Step: 11
Training loss: 0.3312905408234566
Validation loss: 2.5300438469718873

Epoch: 6| Step: 12
Training loss: 0.5986966819357754
Validation loss: 2.4734405324569058

Epoch: 6| Step: 13
Training loss: 0.26101371828380143
Validation loss: 2.4951135913768456

Epoch: 524| Step: 0
Training loss: 0.31575222472783626
Validation loss: 2.5334130285429173

Epoch: 6| Step: 1
Training loss: 0.272978424529692
Validation loss: 2.547921930922661

Epoch: 6| Step: 2
Training loss: 0.381081012889911
Validation loss: 2.5814464762573537

Epoch: 6| Step: 3
Training loss: 0.2609632890486452
Validation loss: 2.536973556812238

Epoch: 6| Step: 4
Training loss: 0.3321126501495747
Validation loss: 2.584551148722313

Epoch: 6| Step: 5
Training loss: 0.4587711407054522
Validation loss: 2.5330716167601595

Epoch: 6| Step: 6
Training loss: 0.22547385498791978
Validation loss: 2.5157981124601774

Epoch: 6| Step: 7
Training loss: 0.4639899161759914
Validation loss: 2.5658570736211286

Epoch: 6| Step: 8
Training loss: 0.41329049170388243
Validation loss: 2.5387924618683466

Epoch: 6| Step: 9
Training loss: 0.23663365499584577
Validation loss: 2.501307254403341

Epoch: 6| Step: 10
Training loss: 0.5544551846424434
Validation loss: 2.4782602568491634

Epoch: 6| Step: 11
Training loss: 0.2529969733447319
Validation loss: 2.4559136550412757

Epoch: 6| Step: 12
Training loss: 0.24676326474544252
Validation loss: 2.5293146561430633

Epoch: 6| Step: 13
Training loss: 0.3252879059625768
Validation loss: 2.541626992883465

Epoch: 525| Step: 0
Training loss: 0.3773669012640509
Validation loss: 2.595011744606492

Epoch: 6| Step: 1
Training loss: 0.3914062507614166
Validation loss: 2.6174794905532353

Epoch: 6| Step: 2
Training loss: 0.31826610017881757
Validation loss: 2.6114481043990265

Epoch: 6| Step: 3
Training loss: 0.27609708817454953
Validation loss: 2.55271761313675

Epoch: 6| Step: 4
Training loss: 0.30386597579790964
Validation loss: 2.509386497588399

Epoch: 6| Step: 5
Training loss: 0.360164935158294
Validation loss: 2.5690766973122763

Epoch: 6| Step: 6
Training loss: 0.4085772866602967
Validation loss: 2.518850883495728

Epoch: 6| Step: 7
Training loss: 0.33402392504570283
Validation loss: 2.5760741926167454

Epoch: 6| Step: 8
Training loss: 0.3011757876368385
Validation loss: 2.5496188347172595

Epoch: 6| Step: 9
Training loss: 0.399542267982751
Validation loss: 2.557614952247147

Epoch: 6| Step: 10
Training loss: 0.30814072396662834
Validation loss: 2.616521564430608

Epoch: 6| Step: 11
Training loss: 0.28842276586176674
Validation loss: 2.5756366055511464

Epoch: 6| Step: 12
Training loss: 0.3692530506230132
Validation loss: 2.5223486320808655

Epoch: 6| Step: 13
Training loss: 0.3895470814829242
Validation loss: 2.5256895353742905

Epoch: 526| Step: 0
Training loss: 0.33478697327032336
Validation loss: 2.500786019911785

Epoch: 6| Step: 1
Training loss: 0.2688057575493348
Validation loss: 2.472436190579467

Epoch: 6| Step: 2
Training loss: 0.30268445987817
Validation loss: 2.4644875397178536

Epoch: 6| Step: 3
Training loss: 0.5140944218797254
Validation loss: 2.4507398691950786

Epoch: 6| Step: 4
Training loss: 0.16469000973680195
Validation loss: 2.461971846237057

Epoch: 6| Step: 5
Training loss: 0.18384080861728014
Validation loss: 2.4896192087691653

Epoch: 6| Step: 6
Training loss: 0.38257242966210814
Validation loss: 2.5237954808795227

Epoch: 6| Step: 7
Training loss: 0.3568213791322951
Validation loss: 2.530759653765561

Epoch: 6| Step: 8
Training loss: 0.18334854267892
Validation loss: 2.552597145524379

Epoch: 6| Step: 9
Training loss: 0.25008460937692656
Validation loss: 2.586707712001256

Epoch: 6| Step: 10
Training loss: 0.2873357801384828
Validation loss: 2.6246319643191924

Epoch: 6| Step: 11
Training loss: 0.18538377520111787
Validation loss: 2.6355162995721426

Epoch: 6| Step: 12
Training loss: 0.19908081215988843
Validation loss: 2.624450342825259

Epoch: 6| Step: 13
Training loss: 0.23201949285653348
Validation loss: 2.5981619245949408

Epoch: 527| Step: 0
Training loss: 0.36051996942809933
Validation loss: 2.5824383875160755

Epoch: 6| Step: 1
Training loss: 0.3038688322827711
Validation loss: 2.611362720244111

Epoch: 6| Step: 2
Training loss: 0.24715123717167986
Validation loss: 2.580367270756215

Epoch: 6| Step: 3
Training loss: 0.2477364211778399
Validation loss: 2.5642583893210698

Epoch: 6| Step: 4
Training loss: 0.3232770019407017
Validation loss: 2.568232752938604

Epoch: 6| Step: 5
Training loss: 0.2501967073471651
Validation loss: 2.5816268193359946

Epoch: 6| Step: 6
Training loss: 0.25392030530320797
Validation loss: 2.5904573449808446

Epoch: 6| Step: 7
Training loss: 0.2860936603514751
Validation loss: 2.571107593476337

Epoch: 6| Step: 8
Training loss: 0.2923681588026939
Validation loss: 2.573879706544439

Epoch: 6| Step: 9
Training loss: 0.255505222085227
Validation loss: 2.5097363965973303

Epoch: 6| Step: 10
Training loss: 0.20368429359002835
Validation loss: 2.4792054144779354

Epoch: 6| Step: 11
Training loss: 0.20374573714822727
Validation loss: 2.500357048625531

Epoch: 6| Step: 12
Training loss: 0.2978095603469555
Validation loss: 2.4721737909852126

Epoch: 6| Step: 13
Training loss: 0.21109079159824354
Validation loss: 2.4494531784260576

Epoch: 528| Step: 0
Training loss: 0.2647857872655128
Validation loss: 2.493171524115027

Epoch: 6| Step: 1
Training loss: 0.34790745778183824
Validation loss: 2.4580759657978373

Epoch: 6| Step: 2
Training loss: 0.21000421654634724
Validation loss: 2.5129891202875476

Epoch: 6| Step: 3
Training loss: 0.2286016840154341
Validation loss: 2.5518439794474346

Epoch: 6| Step: 4
Training loss: 0.2644214853492268
Validation loss: 2.564931074971191

Epoch: 6| Step: 5
Training loss: 0.1858031360417252
Validation loss: 2.5604789601418503

Epoch: 6| Step: 6
Training loss: 0.32250750163321074
Validation loss: 2.574541772790087

Epoch: 6| Step: 7
Training loss: 0.3272519303782904
Validation loss: 2.5613002834946226

Epoch: 6| Step: 8
Training loss: 0.19921373847193
Validation loss: 2.5340566303939998

Epoch: 6| Step: 9
Training loss: 0.14912009148301492
Validation loss: 2.523438098383814

Epoch: 6| Step: 10
Training loss: 0.2239202293243423
Validation loss: 2.5305798726077984

Epoch: 6| Step: 11
Training loss: 0.1967995680760668
Validation loss: 2.499065077713741

Epoch: 6| Step: 12
Training loss: 0.25731548895314854
Validation loss: 2.490997714513823

Epoch: 6| Step: 13
Training loss: 0.12117659903294288
Validation loss: 2.5224132612339627

Epoch: 529| Step: 0
Training loss: 0.16293404981452342
Validation loss: 2.5380958851400495

Epoch: 6| Step: 1
Training loss: 0.16512662494655464
Validation loss: 2.5533048122947215

Epoch: 6| Step: 2
Training loss: 0.23793443079172083
Validation loss: 2.538532433345823

Epoch: 6| Step: 3
Training loss: 0.27988385495126816
Validation loss: 2.562755186839019

Epoch: 6| Step: 4
Training loss: 0.14934862486567319
Validation loss: 2.5807359984520737

Epoch: 6| Step: 5
Training loss: 0.30172946636305614
Validation loss: 2.5540323472620474

Epoch: 6| Step: 6
Training loss: 0.3259725018448929
Validation loss: 2.5358382044322845

Epoch: 6| Step: 7
Training loss: 0.1798338190679233
Validation loss: 2.5669833325012084

Epoch: 6| Step: 8
Training loss: 0.15456554103733428
Validation loss: 2.5252312338992033

Epoch: 6| Step: 9
Training loss: 0.2601388530241242
Validation loss: 2.5531899024376554

Epoch: 6| Step: 10
Training loss: 0.25597735589526016
Validation loss: 2.5491241965814475

Epoch: 6| Step: 11
Training loss: 0.18142392963602516
Validation loss: 2.566755707193416

Epoch: 6| Step: 12
Training loss: 0.2128426821559655
Validation loss: 2.545053397958468

Epoch: 6| Step: 13
Training loss: 0.09341052302238
Validation loss: 2.558071013626267

Epoch: 530| Step: 0
Training loss: 0.21868010664557608
Validation loss: 2.597325765722319

Epoch: 6| Step: 1
Training loss: 0.16656224635464534
Validation loss: 2.6272778304080795

Epoch: 6| Step: 2
Training loss: 0.24647410835370265
Validation loss: 2.582560956853185

Epoch: 6| Step: 3
Training loss: 0.18126304924786132
Validation loss: 2.5679559238618834

Epoch: 6| Step: 4
Training loss: 0.22748829516754954
Validation loss: 2.5568691056840924

Epoch: 6| Step: 5
Training loss: 0.13205490295450353
Validation loss: 2.5456934828769975

Epoch: 6| Step: 6
Training loss: 0.2688634311469601
Validation loss: 2.556153668118084

Epoch: 6| Step: 7
Training loss: 0.20198440346430285
Validation loss: 2.58422308560125

Epoch: 6| Step: 8
Training loss: 0.24580303307806323
Validation loss: 2.5408098537397015

Epoch: 6| Step: 9
Training loss: 0.26586300341035524
Validation loss: 2.5653782608725715

Epoch: 6| Step: 10
Training loss: 0.19221950512624386
Validation loss: 2.524463660931769

Epoch: 6| Step: 11
Training loss: 0.24991408004123883
Validation loss: 2.529700869775904

Epoch: 6| Step: 12
Training loss: 0.20433833793757225
Validation loss: 2.5660099009364554

Epoch: 6| Step: 13
Training loss: 0.21711407902396127
Validation loss: 2.566705363871122

Epoch: 531| Step: 0
Training loss: 0.22608686539476588
Validation loss: 2.5972862698764283

Epoch: 6| Step: 1
Training loss: 0.1719023346839067
Validation loss: 2.562233945319243

Epoch: 6| Step: 2
Training loss: 0.1910024880258426
Validation loss: 2.584238289490194

Epoch: 6| Step: 3
Training loss: 0.20556056179699825
Validation loss: 2.5711652434147148

Epoch: 6| Step: 4
Training loss: 0.16911305385642422
Validation loss: 2.541760441062034

Epoch: 6| Step: 5
Training loss: 0.19332317051882064
Validation loss: 2.5400506269392906

Epoch: 6| Step: 6
Training loss: 0.2229105016414407
Validation loss: 2.5201544712425594

Epoch: 6| Step: 7
Training loss: 0.2232491396191113
Validation loss: 2.5057285444032793

Epoch: 6| Step: 8
Training loss: 0.1887230718742836
Validation loss: 2.5032886245532384

Epoch: 6| Step: 9
Training loss: 0.33985876729824155
Validation loss: 2.5260561453063186

Epoch: 6| Step: 10
Training loss: 0.2041738829180829
Validation loss: 2.4977156795822686

Epoch: 6| Step: 11
Training loss: 0.26721715595232526
Validation loss: 2.5426681535208653

Epoch: 6| Step: 12
Training loss: 0.1457033571543135
Validation loss: 2.558504922591924

Epoch: 6| Step: 13
Training loss: 0.12412386680284554
Validation loss: 2.5379051378909487

Epoch: 532| Step: 0
Training loss: 0.14632758332420576
Validation loss: 2.5228106815737865

Epoch: 6| Step: 1
Training loss: 0.22200010896048578
Validation loss: 2.5270478230875817

Epoch: 6| Step: 2
Training loss: 0.2188704533684783
Validation loss: 2.525405041557267

Epoch: 6| Step: 3
Training loss: 0.1408605721708975
Validation loss: 2.5615315431813115

Epoch: 6| Step: 4
Training loss: 0.22603321733519102
Validation loss: 2.5362472685566595

Epoch: 6| Step: 5
Training loss: 0.2589625802514074
Validation loss: 2.554545227185437

Epoch: 6| Step: 6
Training loss: 0.23833297730854983
Validation loss: 2.5631285596078874

Epoch: 6| Step: 7
Training loss: 0.2927514860081278
Validation loss: 2.5449247026448627

Epoch: 6| Step: 8
Training loss: 0.1597642171000258
Validation loss: 2.585386503989838

Epoch: 6| Step: 9
Training loss: 0.31907293005623594
Validation loss: 2.557378058497516

Epoch: 6| Step: 10
Training loss: 0.3075358813177139
Validation loss: 2.57926429989033

Epoch: 6| Step: 11
Training loss: 0.19404277062369965
Validation loss: 2.5373112916955383

Epoch: 6| Step: 12
Training loss: 0.18457030240820801
Validation loss: 2.5371861928412422

Epoch: 6| Step: 13
Training loss: 0.1505850241468861
Validation loss: 2.5642812926997935

Epoch: 533| Step: 0
Training loss: 0.19808108732122767
Validation loss: 2.5592185128052645

Epoch: 6| Step: 1
Training loss: 0.31306100794870145
Validation loss: 2.523993232793905

Epoch: 6| Step: 2
Training loss: 0.21854086654093569
Validation loss: 2.543272008383806

Epoch: 6| Step: 3
Training loss: 0.2200932473649917
Validation loss: 2.5769285849741506

Epoch: 6| Step: 4
Training loss: 0.22254757152947338
Validation loss: 2.563570613794071

Epoch: 6| Step: 5
Training loss: 0.20330885672566468
Validation loss: 2.5895587937172544

Epoch: 6| Step: 6
Training loss: 0.24990858701514992
Validation loss: 2.5832450383869823

Epoch: 6| Step: 7
Training loss: 0.18582290395806542
Validation loss: 2.5762137877850098

Epoch: 6| Step: 8
Training loss: 0.10866058714688258
Validation loss: 2.5621763245547204

Epoch: 6| Step: 9
Training loss: 0.19710476614772185
Validation loss: 2.5715849566463236

Epoch: 6| Step: 10
Training loss: 0.22229908019296846
Validation loss: 2.540664112684174

Epoch: 6| Step: 11
Training loss: 0.26651757003629967
Validation loss: 2.54889406112573

Epoch: 6| Step: 12
Training loss: 0.24781328000334354
Validation loss: 2.5035303753369105

Epoch: 6| Step: 13
Training loss: 0.07228653192950435
Validation loss: 2.5373054931360683

Epoch: 534| Step: 0
Training loss: 0.19840854561193128
Validation loss: 2.527888546525192

Epoch: 6| Step: 1
Training loss: 0.21777059784136912
Validation loss: 2.5329776743636554

Epoch: 6| Step: 2
Training loss: 0.17156173594709404
Validation loss: 2.5391319034452575

Epoch: 6| Step: 3
Training loss: 0.1819699695892841
Validation loss: 2.512688968420988

Epoch: 6| Step: 4
Training loss: 0.10950405732214064
Validation loss: 2.5289473730806753

Epoch: 6| Step: 5
Training loss: 0.15253435340089197
Validation loss: 2.556832537833977

Epoch: 6| Step: 6
Training loss: 0.27403867574508367
Validation loss: 2.546602322247098

Epoch: 6| Step: 7
Training loss: 0.2430712051500271
Validation loss: 2.5603860123266142

Epoch: 6| Step: 8
Training loss: 0.26901796089714053
Validation loss: 2.5536140724846916

Epoch: 6| Step: 9
Training loss: 0.18803286333423788
Validation loss: 2.5541893629338976

Epoch: 6| Step: 10
Training loss: 0.2033833731150972
Validation loss: 2.5880378659896865

Epoch: 6| Step: 11
Training loss: 0.13347091576898565
Validation loss: 2.55398819038587

Epoch: 6| Step: 12
Training loss: 0.1205908500058762
Validation loss: 2.5772102172386537

Epoch: 6| Step: 13
Training loss: 0.17675273318922483
Validation loss: 2.555229925957987

Epoch: 535| Step: 0
Training loss: 0.20346460929410498
Validation loss: 2.566710823338737

Epoch: 6| Step: 1
Training loss: 0.25138990155842117
Validation loss: 2.6027833837422656

Epoch: 6| Step: 2
Training loss: 0.17253213667749687
Validation loss: 2.5555279814825873

Epoch: 6| Step: 3
Training loss: 0.26842542832112926
Validation loss: 2.553999306716219

Epoch: 6| Step: 4
Training loss: 0.2391999778134358
Validation loss: 2.5873779740108502

Epoch: 6| Step: 5
Training loss: 0.10879062466552776
Validation loss: 2.569463103837367

Epoch: 6| Step: 6
Training loss: 0.11709432076365195
Validation loss: 2.5648136853730166

Epoch: 6| Step: 7
Training loss: 0.2463257770565564
Validation loss: 2.5979239697864425

Epoch: 6| Step: 8
Training loss: 0.24094975188011586
Validation loss: 2.6015267899807513

Epoch: 6| Step: 9
Training loss: 0.270755186482997
Validation loss: 2.5609768728528923

Epoch: 6| Step: 10
Training loss: 0.1698797820560607
Validation loss: 2.5876035068301118

Epoch: 6| Step: 11
Training loss: 0.27377110974687563
Validation loss: 2.549907417374019

Epoch: 6| Step: 12
Training loss: 0.19443120490330562
Validation loss: 2.5552678410682845

Epoch: 6| Step: 13
Training loss: 0.14575026621393458
Validation loss: 2.564227160655956

Epoch: 536| Step: 0
Training loss: 0.2171493362954388
Validation loss: 2.5364982788986072

Epoch: 6| Step: 1
Training loss: 0.2806095141957389
Validation loss: 2.509434168501194

Epoch: 6| Step: 2
Training loss: 0.15358267040785759
Validation loss: 2.5242643006008394

Epoch: 6| Step: 3
Training loss: 0.22234949932854797
Validation loss: 2.478889514642226

Epoch: 6| Step: 4
Training loss: 0.2115824693639884
Validation loss: 2.521465550889016

Epoch: 6| Step: 5
Training loss: 0.15820999483804674
Validation loss: 2.490420740542412

Epoch: 6| Step: 6
Training loss: 0.19661268439649565
Validation loss: 2.513381198856924

Epoch: 6| Step: 7
Training loss: 0.13108307663134963
Validation loss: 2.526376916940441

Epoch: 6| Step: 8
Training loss: 0.11015160767262527
Validation loss: 2.5335039125351813

Epoch: 6| Step: 9
Training loss: 0.26740923654132953
Validation loss: 2.5133504977874637

Epoch: 6| Step: 10
Training loss: 0.16045822192592446
Validation loss: 2.5525135751631036

Epoch: 6| Step: 11
Training loss: 0.1440877941665367
Validation loss: 2.5442997132083196

Epoch: 6| Step: 12
Training loss: 0.09831126838708064
Validation loss: 2.5297979162267015

Epoch: 6| Step: 13
Training loss: 0.29432744632210744
Validation loss: 2.5608547004980315

Epoch: 537| Step: 0
Training loss: 0.15708664775719502
Validation loss: 2.540603553207092

Epoch: 6| Step: 1
Training loss: 0.20486563618739648
Validation loss: 2.565002053260841

Epoch: 6| Step: 2
Training loss: 0.1785877824855986
Validation loss: 2.5770891422405184

Epoch: 6| Step: 3
Training loss: 0.15607318410481538
Validation loss: 2.5310161684624712

Epoch: 6| Step: 4
Training loss: 0.20586498622014895
Validation loss: 2.6032662201236874

Epoch: 6| Step: 5
Training loss: 0.2606988363624857
Validation loss: 2.5940573933079176

Epoch: 6| Step: 6
Training loss: 0.19717526963175488
Validation loss: 2.5809789190529644

Epoch: 6| Step: 7
Training loss: 0.24826056369623536
Validation loss: 2.6148006648103763

Epoch: 6| Step: 8
Training loss: 0.17644908456779743
Validation loss: 2.5309860140449945

Epoch: 6| Step: 9
Training loss: 0.16296320425748823
Validation loss: 2.5291686115121252

Epoch: 6| Step: 10
Training loss: 0.2506925408163969
Validation loss: 2.5294882333870015

Epoch: 6| Step: 11
Training loss: 0.10667242093167954
Validation loss: 2.495788071755918

Epoch: 6| Step: 12
Training loss: 0.1997866669971681
Validation loss: 2.5067432214372247

Epoch: 6| Step: 13
Training loss: 0.34713917759057306
Validation loss: 2.5150084242154387

Epoch: 538| Step: 0
Training loss: 0.13883147659077189
Validation loss: 2.509850229572425

Epoch: 6| Step: 1
Training loss: 0.15195106980569167
Validation loss: 2.529751438247787

Epoch: 6| Step: 2
Training loss: 0.24141850980472715
Validation loss: 2.5490475876439564

Epoch: 6| Step: 3
Training loss: 0.13929781880810477
Validation loss: 2.5580992387913013

Epoch: 6| Step: 4
Training loss: 0.2745002258348491
Validation loss: 2.5556728097013295

Epoch: 6| Step: 5
Training loss: 0.21441935323705463
Validation loss: 2.5784355088454065

Epoch: 6| Step: 6
Training loss: 0.21332463811747354
Validation loss: 2.5877587678720055

Epoch: 6| Step: 7
Training loss: 0.24476150908602948
Validation loss: 2.5760346928846065

Epoch: 6| Step: 8
Training loss: 0.2154375885857294
Validation loss: 2.588295309071681

Epoch: 6| Step: 9
Training loss: 0.24244129050296695
Validation loss: 2.547452235001856

Epoch: 6| Step: 10
Training loss: 0.1714407246154628
Validation loss: 2.5163738960429307

Epoch: 6| Step: 11
Training loss: 0.2238465666039206
Validation loss: 2.516108549014684

Epoch: 6| Step: 12
Training loss: 0.13355029163339466
Validation loss: 2.5421750783829533

Epoch: 6| Step: 13
Training loss: 0.20606481156630535
Validation loss: 2.539734077584564

Epoch: 539| Step: 0
Training loss: 0.1597599674426306
Validation loss: 2.5484040949205116

Epoch: 6| Step: 1
Training loss: 0.20179761399840093
Validation loss: 2.5187094348224237

Epoch: 6| Step: 2
Training loss: 0.21406906215327212
Validation loss: 2.546620135575073

Epoch: 6| Step: 3
Training loss: 0.18249025880604502
Validation loss: 2.5298929500099083

Epoch: 6| Step: 4
Training loss: 0.15580339980223326
Validation loss: 2.565282938709402

Epoch: 6| Step: 5
Training loss: 0.25915515843953524
Validation loss: 2.55109730788401

Epoch: 6| Step: 6
Training loss: 0.27755790823643167
Validation loss: 2.581590943783388

Epoch: 6| Step: 7
Training loss: 0.22276929027075637
Validation loss: 2.6085922180225727

Epoch: 6| Step: 8
Training loss: 0.2516690360335631
Validation loss: 2.595636427295482

Epoch: 6| Step: 9
Training loss: 0.22282095723199155
Validation loss: 2.5777153159472266

Epoch: 6| Step: 10
Training loss: 0.2217071364965565
Validation loss: 2.5780588170739485

Epoch: 6| Step: 11
Training loss: 0.17296356408771332
Validation loss: 2.56808865101099

Epoch: 6| Step: 12
Training loss: 0.1637228674650269
Validation loss: 2.552641755303455

Epoch: 6| Step: 13
Training loss: 0.20173524470005536
Validation loss: 2.530226751429931

Epoch: 540| Step: 0
Training loss: 0.22333142323501518
Validation loss: 2.494188793387059

Epoch: 6| Step: 1
Training loss: 0.17323674641766024
Validation loss: 2.5286003270828057

Epoch: 6| Step: 2
Training loss: 0.2424193933318731
Validation loss: 2.495628895863312

Epoch: 6| Step: 3
Training loss: 0.1357151800499037
Validation loss: 2.451721816336862

Epoch: 6| Step: 4
Training loss: 0.1715760285874992
Validation loss: 2.500414340231282

Epoch: 6| Step: 5
Training loss: 0.17595914739707558
Validation loss: 2.4909823305500685

Epoch: 6| Step: 6
Training loss: 0.16799104343002205
Validation loss: 2.5190105068296385

Epoch: 6| Step: 7
Training loss: 0.3564981499793803
Validation loss: 2.478714057209557

Epoch: 6| Step: 8
Training loss: 0.18190586044566023
Validation loss: 2.4843643940509406

Epoch: 6| Step: 9
Training loss: 0.09715640895458726
Validation loss: 2.497526696856837

Epoch: 6| Step: 10
Training loss: 0.13888757344126293
Validation loss: 2.5431438995833977

Epoch: 6| Step: 11
Training loss: 0.2500005960457372
Validation loss: 2.5378319029144207

Epoch: 6| Step: 12
Training loss: 0.21720716812764745
Validation loss: 2.54168954297978

Epoch: 6| Step: 13
Training loss: 0.11681107224259797
Validation loss: 2.553480471481369

Epoch: 541| Step: 0
Training loss: 0.18310793048475388
Validation loss: 2.547357655021144

Epoch: 6| Step: 1
Training loss: 0.21159619341977395
Validation loss: 2.5389137344384483

Epoch: 6| Step: 2
Training loss: 0.14334642783175877
Validation loss: 2.5181212246794606

Epoch: 6| Step: 3
Training loss: 0.17873498098259183
Validation loss: 2.5487827484161443

Epoch: 6| Step: 4
Training loss: 0.13291511358227698
Validation loss: 2.5593796747340165

Epoch: 6| Step: 5
Training loss: 0.22563641466447454
Validation loss: 2.5673727431785345

Epoch: 6| Step: 6
Training loss: 0.15063988477518908
Validation loss: 2.5172721969485243

Epoch: 6| Step: 7
Training loss: 0.13518093908969872
Validation loss: 2.553880136270705

Epoch: 6| Step: 8
Training loss: 0.2015749217796718
Validation loss: 2.5527393441349178

Epoch: 6| Step: 9
Training loss: 0.11021121138583752
Validation loss: 2.5618485123549424

Epoch: 6| Step: 10
Training loss: 0.21985930777499849
Validation loss: 2.5721755375031923

Epoch: 6| Step: 11
Training loss: 0.28030984090524075
Validation loss: 2.5541176229491596

Epoch: 6| Step: 12
Training loss: 0.09823716475006895
Validation loss: 2.5720529427158967

Epoch: 6| Step: 13
Training loss: 0.16196346035599232
Validation loss: 2.5667234212206984

Epoch: 542| Step: 0
Training loss: 0.24676423847526582
Validation loss: 2.5655734521419427

Epoch: 6| Step: 1
Training loss: 0.2449330249785431
Validation loss: 2.5356347034067106

Epoch: 6| Step: 2
Training loss: 0.13352395682903223
Validation loss: 2.5711076034472953

Epoch: 6| Step: 3
Training loss: 0.09922861741027628
Validation loss: 2.5650022881361

Epoch: 6| Step: 4
Training loss: 0.15363355091808872
Validation loss: 2.536189809442682

Epoch: 6| Step: 5
Training loss: 0.15189657237646123
Validation loss: 2.5584682516170902

Epoch: 6| Step: 6
Training loss: 0.16311158760880312
Validation loss: 2.5471326802207668

Epoch: 6| Step: 7
Training loss: 0.19691023586969078
Validation loss: 2.5533607451890594

Epoch: 6| Step: 8
Training loss: 0.17701967347989123
Validation loss: 2.602542006823732

Epoch: 6| Step: 9
Training loss: 0.13258586508029818
Validation loss: 2.536697255830437

Epoch: 6| Step: 10
Training loss: 0.14518214911438196
Validation loss: 2.537098705559157

Epoch: 6| Step: 11
Training loss: 0.26772678728485755
Validation loss: 2.5477282339718714

Epoch: 6| Step: 12
Training loss: 0.12006229991911063
Validation loss: 2.5787859683747674

Epoch: 6| Step: 13
Training loss: 0.2093117458247907
Validation loss: 2.545294984154817

Epoch: 543| Step: 0
Training loss: 0.11316875100422584
Validation loss: 2.5452290217732614

Epoch: 6| Step: 1
Training loss: 0.1299986788563354
Validation loss: 2.5224843575893563

Epoch: 6| Step: 2
Training loss: 0.1810743878787274
Validation loss: 2.5242876176336453

Epoch: 6| Step: 3
Training loss: 0.18810258833246649
Validation loss: 2.549264445897244

Epoch: 6| Step: 4
Training loss: 0.22388708659526788
Validation loss: 2.512330979173645

Epoch: 6| Step: 5
Training loss: 0.1797349908515244
Validation loss: 2.492458183120543

Epoch: 6| Step: 6
Training loss: 0.29306140705994177
Validation loss: 2.4996011733774877

Epoch: 6| Step: 7
Training loss: 0.31280131118992294
Validation loss: 2.5190820192844265

Epoch: 6| Step: 8
Training loss: 0.2215425428406419
Validation loss: 2.5104499140359704

Epoch: 6| Step: 9
Training loss: 0.18978967956259246
Validation loss: 2.4960112088750157

Epoch: 6| Step: 10
Training loss: 0.15642218639116823
Validation loss: 2.489374417074883

Epoch: 6| Step: 11
Training loss: 0.20102896753204663
Validation loss: 2.5270333768445536

Epoch: 6| Step: 12
Training loss: 0.23835876642310147
Validation loss: 2.4862872417449315

Epoch: 6| Step: 13
Training loss: 0.14400778518558124
Validation loss: 2.531251682254096

Epoch: 544| Step: 0
Training loss: 0.12124107612505089
Validation loss: 2.5168086519251465

Epoch: 6| Step: 1
Training loss: 0.18252906100895835
Validation loss: 2.5721933022988788

Epoch: 6| Step: 2
Training loss: 0.13616022739725367
Validation loss: 2.5352067809469063

Epoch: 6| Step: 3
Training loss: 0.12470670653728848
Validation loss: 2.5892853149740285

Epoch: 6| Step: 4
Training loss: 0.28130786353500314
Validation loss: 2.5236015717304983

Epoch: 6| Step: 5
Training loss: 0.14006798417616195
Validation loss: 2.555845930918757

Epoch: 6| Step: 6
Training loss: 0.1412779431427532
Validation loss: 2.5389324690698034

Epoch: 6| Step: 7
Training loss: 0.21500729491643947
Validation loss: 2.531438737682124

Epoch: 6| Step: 8
Training loss: 0.1257768793116756
Validation loss: 2.5736262911496546

Epoch: 6| Step: 9
Training loss: 0.1651508471887325
Validation loss: 2.5551690545302996

Epoch: 6| Step: 10
Training loss: 0.12906954998915374
Validation loss: 2.53871245111283

Epoch: 6| Step: 11
Training loss: 0.13230432733892766
Validation loss: 2.54706906932432

Epoch: 6| Step: 12
Training loss: 0.24167676108478164
Validation loss: 2.5439748663790995

Epoch: 6| Step: 13
Training loss: 0.30506376117882483
Validation loss: 2.565109242097514

Epoch: 545| Step: 0
Training loss: 0.18007967486924767
Validation loss: 2.5505193107139896

Epoch: 6| Step: 1
Training loss: 0.24639536524541888
Validation loss: 2.539313268906871

Epoch: 6| Step: 2
Training loss: 0.15061881353407902
Validation loss: 2.5513911869250854

Epoch: 6| Step: 3
Training loss: 0.2072481332926092
Validation loss: 2.5492955712506937

Epoch: 6| Step: 4
Training loss: 0.12516450488028588
Validation loss: 2.5776422908234546

Epoch: 6| Step: 5
Training loss: 0.15838110296222166
Validation loss: 2.5557023423189538

Epoch: 6| Step: 6
Training loss: 0.1680266369276335
Validation loss: 2.5099166278844915

Epoch: 6| Step: 7
Training loss: 0.281714149115934
Validation loss: 2.583565621810672

Epoch: 6| Step: 8
Training loss: 0.3078821766605813
Validation loss: 2.5447958204973524

Epoch: 6| Step: 9
Training loss: 0.2446597340664985
Validation loss: 2.571904652026776

Epoch: 6| Step: 10
Training loss: 0.15316105729462437
Validation loss: 2.5543192625386295

Epoch: 6| Step: 11
Training loss: 0.1196448140369391
Validation loss: 2.5235540737141644

Epoch: 6| Step: 12
Training loss: 0.17714799840971543
Validation loss: 2.5480392968534926

Epoch: 6| Step: 13
Training loss: 0.195845429997157
Validation loss: 2.508399484500917

Epoch: 546| Step: 0
Training loss: 0.16868225190301403
Validation loss: 2.517454451906273

Epoch: 6| Step: 1
Training loss: 0.2678315848691263
Validation loss: 2.494150726839844

Epoch: 6| Step: 2
Training loss: 0.21566349909038082
Validation loss: 2.4855652698385793

Epoch: 6| Step: 3
Training loss: 0.16704804339618887
Validation loss: 2.4524657800188767

Epoch: 6| Step: 4
Training loss: 0.1518816296774855
Validation loss: 2.4783878273266327

Epoch: 6| Step: 5
Training loss: 0.2992219013416685
Validation loss: 2.497962959551158

Epoch: 6| Step: 6
Training loss: 0.16981008294245312
Validation loss: 2.490880803063412

Epoch: 6| Step: 7
Training loss: 0.15567786252488416
Validation loss: 2.5640106790437414

Epoch: 6| Step: 8
Training loss: 0.2790741198898253
Validation loss: 2.5913018401292054

Epoch: 6| Step: 9
Training loss: 0.1574802129668418
Validation loss: 2.6128563482990756

Epoch: 6| Step: 10
Training loss: 0.23437298138067064
Validation loss: 2.62208502806531

Epoch: 6| Step: 11
Training loss: 0.36959042468501835
Validation loss: 2.5945164536065968

Epoch: 6| Step: 12
Training loss: 0.19294191822582388
Validation loss: 2.5990525923849344

Epoch: 6| Step: 13
Training loss: 0.09675690909631164
Validation loss: 2.5782641440710408

Epoch: 547| Step: 0
Training loss: 0.18075921929196118
Validation loss: 2.532259758053301

Epoch: 6| Step: 1
Training loss: 0.25082520548324355
Validation loss: 2.510140531256879

Epoch: 6| Step: 2
Training loss: 0.21305550306339716
Validation loss: 2.4799218020894163

Epoch: 6| Step: 3
Training loss: 0.2845372313656842
Validation loss: 2.490023689663056

Epoch: 6| Step: 4
Training loss: 0.26318291432252283
Validation loss: 2.4922454505272817

Epoch: 6| Step: 5
Training loss: 0.207318646306219
Validation loss: 2.508807261827633

Epoch: 6| Step: 6
Training loss: 0.14825331403669148
Validation loss: 2.511582807119487

Epoch: 6| Step: 7
Training loss: 0.2648738731425116
Validation loss: 2.5102903534892183

Epoch: 6| Step: 8
Training loss: 0.28273325120629306
Validation loss: 2.5538141612363066

Epoch: 6| Step: 9
Training loss: 0.20056439314662283
Validation loss: 2.568735568960606

Epoch: 6| Step: 10
Training loss: 0.23777814031656377
Validation loss: 2.553996367661349

Epoch: 6| Step: 11
Training loss: 0.2801443194664298
Validation loss: 2.591257867211666

Epoch: 6| Step: 12
Training loss: 0.19386876565451147
Validation loss: 2.550679194049448

Epoch: 6| Step: 13
Training loss: 0.24000591176421118
Validation loss: 2.5491232049663033

Epoch: 548| Step: 0
Training loss: 0.13981177374677162
Validation loss: 2.5149959785920024

Epoch: 6| Step: 1
Training loss: 0.22879959459960808
Validation loss: 2.5172269410071495

Epoch: 6| Step: 2
Training loss: 0.14713719178425855
Validation loss: 2.495442572041017

Epoch: 6| Step: 3
Training loss: 0.2237900177237256
Validation loss: 2.5027758907433175

Epoch: 6| Step: 4
Training loss: 0.3500028771895268
Validation loss: 2.4544521754940023

Epoch: 6| Step: 5
Training loss: 0.1685018728531349
Validation loss: 2.4789484854743966

Epoch: 6| Step: 6
Training loss: 0.12809325092327334
Validation loss: 2.4294673177731765

Epoch: 6| Step: 7
Training loss: 0.2674131093439936
Validation loss: 2.447255518187044

Epoch: 6| Step: 8
Training loss: 0.1720289061453352
Validation loss: 2.471371509761678

Epoch: 6| Step: 9
Training loss: 0.2042598931590867
Validation loss: 2.5092944785446947

Epoch: 6| Step: 10
Training loss: 0.17764234780341773
Validation loss: 2.525363323511171

Epoch: 6| Step: 11
Training loss: 0.19102397034558166
Validation loss: 2.5593435905054043

Epoch: 6| Step: 12
Training loss: 0.2847980444184012
Validation loss: 2.565840991474772

Epoch: 6| Step: 13
Training loss: 0.1669223817965634
Validation loss: 2.5725558959930797

Epoch: 549| Step: 0
Training loss: 0.2491923638130576
Validation loss: 2.6107751735773834

Epoch: 6| Step: 1
Training loss: 0.12730807787678405
Validation loss: 2.614848727225966

Epoch: 6| Step: 2
Training loss: 0.17322288113161277
Validation loss: 2.6335986963850475

Epoch: 6| Step: 3
Training loss: 0.20523851571264165
Validation loss: 2.61365723020165

Epoch: 6| Step: 4
Training loss: 0.2636755907715248
Validation loss: 2.608671733542349

Epoch: 6| Step: 5
Training loss: 0.14623673168948648
Validation loss: 2.5786576333331483

Epoch: 6| Step: 6
Training loss: 0.26620635758488403
Validation loss: 2.5858136660357514

Epoch: 6| Step: 7
Training loss: 0.28861003982593764
Validation loss: 2.5361616295444644

Epoch: 6| Step: 8
Training loss: 0.12555643746706074
Validation loss: 2.5365980103582073

Epoch: 6| Step: 9
Training loss: 0.16900843064170393
Validation loss: 2.5161191755170886

Epoch: 6| Step: 10
Training loss: 0.13663870648170848
Validation loss: 2.5064753830433335

Epoch: 6| Step: 11
Training loss: 0.1278452121126035
Validation loss: 2.499766942410318

Epoch: 6| Step: 12
Training loss: 0.14406381229953133
Validation loss: 2.500805883853326

Epoch: 6| Step: 13
Training loss: 0.24199124044336157
Validation loss: 2.492218869120168

Epoch: 550| Step: 0
Training loss: 0.11337679911124943
Validation loss: 2.4768279631336956

Epoch: 6| Step: 1
Training loss: 0.16363149750327538
Validation loss: 2.486459394370588

Epoch: 6| Step: 2
Training loss: 0.18573418248011675
Validation loss: 2.51757350804008

Epoch: 6| Step: 3
Training loss: 0.25041166327254877
Validation loss: 2.494730064886417

Epoch: 6| Step: 4
Training loss: 0.13788856985705747
Validation loss: 2.5274962678622916

Epoch: 6| Step: 5
Training loss: 0.23417841296131509
Validation loss: 2.523554237017667

Epoch: 6| Step: 6
Training loss: 0.20824138082341948
Validation loss: 2.5107652962238447

Epoch: 6| Step: 7
Training loss: 0.2198825706200041
Validation loss: 2.4973474664027315

Epoch: 6| Step: 8
Training loss: 0.2285668486869136
Validation loss: 2.511871050036769

Epoch: 6| Step: 9
Training loss: 0.20815783897426823
Validation loss: 2.5110849532525696

Epoch: 6| Step: 10
Training loss: 0.175711337067671
Validation loss: 2.5399257245749127

Epoch: 6| Step: 11
Training loss: 0.2019982909086603
Validation loss: 2.560851327330156

Epoch: 6| Step: 12
Training loss: 0.19963417496375085
Validation loss: 2.5615528015823346

Epoch: 6| Step: 13
Training loss: 0.17812188840122595
Validation loss: 2.6102325968584092

Epoch: 551| Step: 0
Training loss: 0.1749730178774426
Validation loss: 2.556198600948103

Epoch: 6| Step: 1
Training loss: 0.1996475168355076
Validation loss: 2.570324662318764

Epoch: 6| Step: 2
Training loss: 0.1419049072147491
Validation loss: 2.5624860597596957

Epoch: 6| Step: 3
Training loss: 0.12252604671712035
Validation loss: 2.528198895817619

Epoch: 6| Step: 4
Training loss: 0.16057470363555149
Validation loss: 2.513607421913536

Epoch: 6| Step: 5
Training loss: 0.2868332735478481
Validation loss: 2.509194934904368

Epoch: 6| Step: 6
Training loss: 0.19923572841923837
Validation loss: 2.489811787983059

Epoch: 6| Step: 7
Training loss: 0.12625018426673965
Validation loss: 2.47815795418446

Epoch: 6| Step: 8
Training loss: 0.23520014470434117
Validation loss: 2.486949745025236

Epoch: 6| Step: 9
Training loss: 0.26260799956459435
Validation loss: 2.4740825179342543

Epoch: 6| Step: 10
Training loss: 0.209573316952517
Validation loss: 2.504246755880848

Epoch: 6| Step: 11
Training loss: 0.13959788361076747
Validation loss: 2.4781575315934434

Epoch: 6| Step: 12
Training loss: 0.20608908922016858
Validation loss: 2.4740255470838655

Epoch: 6| Step: 13
Training loss: 0.32091567770396867
Validation loss: 2.482227647310319

Epoch: 552| Step: 0
Training loss: 0.2599117900381325
Validation loss: 2.520522838261886

Epoch: 6| Step: 1
Training loss: 0.157663212878567
Validation loss: 2.5730528436534987

Epoch: 6| Step: 2
Training loss: 0.1305734157463957
Validation loss: 2.5246063281704085

Epoch: 6| Step: 3
Training loss: 0.13627905304031673
Validation loss: 2.5681319934438083

Epoch: 6| Step: 4
Training loss: 0.09971816535976769
Validation loss: 2.5368301965655933

Epoch: 6| Step: 5
Training loss: 0.1072140113071919
Validation loss: 2.5505307733569063

Epoch: 6| Step: 6
Training loss: 0.12588630074503757
Validation loss: 2.531678338107143

Epoch: 6| Step: 7
Training loss: 0.145438299280158
Validation loss: 2.534100506339975

Epoch: 6| Step: 8
Training loss: 0.1220053156428508
Validation loss: 2.4988288156197647

Epoch: 6| Step: 9
Training loss: 0.3365490913022369
Validation loss: 2.5245159484444524

Epoch: 6| Step: 10
Training loss: 0.2412867716451534
Validation loss: 2.5174045575307997

Epoch: 6| Step: 11
Training loss: 0.22824441677913146
Validation loss: 2.5035255850126212

Epoch: 6| Step: 12
Training loss: 0.12899930080882296
Validation loss: 2.468415949692686

Epoch: 6| Step: 13
Training loss: 0.22200255052125958
Validation loss: 2.478009503406071

Epoch: 553| Step: 0
Training loss: 0.19318970065558852
Validation loss: 2.488995156196169

Epoch: 6| Step: 1
Training loss: 0.15779288991573653
Validation loss: 2.48043953811592

Epoch: 6| Step: 2
Training loss: 0.1857775709623709
Validation loss: 2.5132560350001247

Epoch: 6| Step: 3
Training loss: 0.17818206952041143
Validation loss: 2.517548697081561

Epoch: 6| Step: 4
Training loss: 0.2048200891303431
Validation loss: 2.510697642976318

Epoch: 6| Step: 5
Training loss: 0.16186859449578486
Validation loss: 2.5456833035951916

Epoch: 6| Step: 6
Training loss: 0.2044107386054374
Validation loss: 2.519647076262334

Epoch: 6| Step: 7
Training loss: 0.14737874702611437
Validation loss: 2.5346000871963352

Epoch: 6| Step: 8
Training loss: 0.07716977753832939
Validation loss: 2.5388261325009793

Epoch: 6| Step: 9
Training loss: 0.17317575559370021
Validation loss: 2.5247958493376643

Epoch: 6| Step: 10
Training loss: 0.3404518912466907
Validation loss: 2.518808506775418

Epoch: 6| Step: 11
Training loss: 0.17523211429683624
Validation loss: 2.5665325506377212

Epoch: 6| Step: 12
Training loss: 0.24494891070705563
Validation loss: 2.5669131450568883

Epoch: 6| Step: 13
Training loss: 0.11932030011878034
Validation loss: 2.598742429943254

Epoch: 554| Step: 0
Training loss: 0.20603975359417803
Validation loss: 2.620668507730642

Epoch: 6| Step: 1
Training loss: 0.25170220588858694
Validation loss: 2.6300220260663196

Epoch: 6| Step: 2
Training loss: 0.1924769466548207
Validation loss: 2.6112747787634896

Epoch: 6| Step: 3
Training loss: 0.1611472845803299
Validation loss: 2.595330914081648

Epoch: 6| Step: 4
Training loss: 0.21775789590298236
Validation loss: 2.601793843977184

Epoch: 6| Step: 5
Training loss: 0.1813823750939973
Validation loss: 2.636082617417127

Epoch: 6| Step: 6
Training loss: 0.120507586678366
Validation loss: 2.594354750022532

Epoch: 6| Step: 7
Training loss: 0.131626966656468
Validation loss: 2.575212062948727

Epoch: 6| Step: 8
Training loss: 0.15692327402553435
Validation loss: 2.5967666236320235

Epoch: 6| Step: 9
Training loss: 0.24171719725047836
Validation loss: 2.5473294751315096

Epoch: 6| Step: 10
Training loss: 0.35618985571871276
Validation loss: 2.551077859654347

Epoch: 6| Step: 11
Training loss: 0.20862573528445924
Validation loss: 2.544349594543741

Epoch: 6| Step: 12
Training loss: 0.20093350037173044
Validation loss: 2.5357492036829945

Epoch: 6| Step: 13
Training loss: 0.2685652990845603
Validation loss: 2.5152073924171034

Epoch: 555| Step: 0
Training loss: 0.2260560590729765
Validation loss: 2.5206549457703966

Epoch: 6| Step: 1
Training loss: 0.2959780192606795
Validation loss: 2.513353750594704

Epoch: 6| Step: 2
Training loss: 0.218780983706071
Validation loss: 2.50578684933617

Epoch: 6| Step: 3
Training loss: 0.241329827912393
Validation loss: 2.517995525716109

Epoch: 6| Step: 4
Training loss: 0.23507057130898176
Validation loss: 2.5020791637034847

Epoch: 6| Step: 5
Training loss: 0.20066189242528645
Validation loss: 2.4760186288603205

Epoch: 6| Step: 6
Training loss: 0.2394116821643757
Validation loss: 2.4873169650516944

Epoch: 6| Step: 7
Training loss: 0.2267816568828043
Validation loss: 2.4963588819963336

Epoch: 6| Step: 8
Training loss: 0.13906502399940052
Validation loss: 2.5484957852257946

Epoch: 6| Step: 9
Training loss: 0.21990650861865035
Validation loss: 2.540330582739745

Epoch: 6| Step: 10
Training loss: 0.23335377413474848
Validation loss: 2.556614053308397

Epoch: 6| Step: 11
Training loss: 0.14102756312339793
Validation loss: 2.6095850875112534

Epoch: 6| Step: 12
Training loss: 0.22945894041085577
Validation loss: 2.597713384278313

Epoch: 6| Step: 13
Training loss: 0.28863097534751453
Validation loss: 2.631215899134962

Epoch: 556| Step: 0
Training loss: 0.21973264050024613
Validation loss: 2.6330296234061157

Epoch: 6| Step: 1
Training loss: 0.1983214816407806
Validation loss: 2.6164805662829855

Epoch: 6| Step: 2
Training loss: 0.1857174540998758
Validation loss: 2.6162161672527695

Epoch: 6| Step: 3
Training loss: 0.2645304652707695
Validation loss: 2.585494197228909

Epoch: 6| Step: 4
Training loss: 0.23737252604042566
Validation loss: 2.5677513800036285

Epoch: 6| Step: 5
Training loss: 0.1484858471788309
Validation loss: 2.572551105149137

Epoch: 6| Step: 6
Training loss: 0.1511365671842551
Validation loss: 2.5611172934118334

Epoch: 6| Step: 7
Training loss: 0.19933149475971565
Validation loss: 2.528027257207781

Epoch: 6| Step: 8
Training loss: 0.15837047697012596
Validation loss: 2.5613281487814517

Epoch: 6| Step: 9
Training loss: 0.09790519455232163
Validation loss: 2.5370036334944985

Epoch: 6| Step: 10
Training loss: 0.22111811486776772
Validation loss: 2.5512620868153273

Epoch: 6| Step: 11
Training loss: 0.20016290355823457
Validation loss: 2.516164073892027

Epoch: 6| Step: 12
Training loss: 0.12547140341930407
Validation loss: 2.55506076339378

Epoch: 6| Step: 13
Training loss: 0.15887540274043024
Validation loss: 2.5304219653696327

Epoch: 557| Step: 0
Training loss: 0.15478409727678955
Validation loss: 2.5246002973371064

Epoch: 6| Step: 1
Training loss: 0.10129790501774759
Validation loss: 2.508010509893946

Epoch: 6| Step: 2
Training loss: 0.1190310349401132
Validation loss: 2.5129741382335866

Epoch: 6| Step: 3
Training loss: 0.25340316523420714
Validation loss: 2.5398729518586993

Epoch: 6| Step: 4
Training loss: 0.22229646592797353
Validation loss: 2.54566057227009

Epoch: 6| Step: 5
Training loss: 0.1791112200380651
Validation loss: 2.538383833659214

Epoch: 6| Step: 6
Training loss: 0.12156325505519837
Validation loss: 2.514661401208885

Epoch: 6| Step: 7
Training loss: 0.16545546780050724
Validation loss: 2.5471809913536325

Epoch: 6| Step: 8
Training loss: 0.24488444125896003
Validation loss: 2.541955122237559

Epoch: 6| Step: 9
Training loss: 0.21801371640398126
Validation loss: 2.5633182589809933

Epoch: 6| Step: 10
Training loss: 0.11046231881053742
Validation loss: 2.5478309228001415

Epoch: 6| Step: 11
Training loss: 0.15476476974289505
Validation loss: 2.5612948955703154

Epoch: 6| Step: 12
Training loss: 0.1339671974737296
Validation loss: 2.5482677076994635

Epoch: 6| Step: 13
Training loss: 0.13660643596426203
Validation loss: 2.509038572363101

Epoch: 558| Step: 0
Training loss: 0.12731724387157184
Validation loss: 2.5361487949415222

Epoch: 6| Step: 1
Training loss: 0.1472526114504254
Validation loss: 2.533405515951767

Epoch: 6| Step: 2
Training loss: 0.154474626837979
Validation loss: 2.507244237014774

Epoch: 6| Step: 3
Training loss: 0.21801051249059905
Validation loss: 2.5184044651857205

Epoch: 6| Step: 4
Training loss: 0.27296181583167695
Validation loss: 2.5104337077344705

Epoch: 6| Step: 5
Training loss: 0.14111366403917183
Validation loss: 2.511308234894189

Epoch: 6| Step: 6
Training loss: 0.18614353817501605
Validation loss: 2.496574893021361

Epoch: 6| Step: 7
Training loss: 0.13066921366529363
Validation loss: 2.526394283309943

Epoch: 6| Step: 8
Training loss: 0.24246996128208928
Validation loss: 2.5338845204958598

Epoch: 6| Step: 9
Training loss: 0.21344648639700603
Validation loss: 2.558532831349316

Epoch: 6| Step: 10
Training loss: 0.11897320788272789
Validation loss: 2.5852521957302983

Epoch: 6| Step: 11
Training loss: 0.1601951482102715
Validation loss: 2.5708305494358186

Epoch: 6| Step: 12
Training loss: 0.22147287476838987
Validation loss: 2.6111338062502987

Epoch: 6| Step: 13
Training loss: 0.26239414748866435
Validation loss: 2.6402807252182705

Epoch: 559| Step: 0
Training loss: 0.1429028927400133
Validation loss: 2.6000429728090673

Epoch: 6| Step: 1
Training loss: 0.12874716999823207
Validation loss: 2.615276369508831

Epoch: 6| Step: 2
Training loss: 0.164178988563925
Validation loss: 2.5669593886095154

Epoch: 6| Step: 3
Training loss: 0.20360912803603895
Validation loss: 2.569308844545679

Epoch: 6| Step: 4
Training loss: 0.2750535349322107
Validation loss: 2.526177884179822

Epoch: 6| Step: 5
Training loss: 0.19683819911268435
Validation loss: 2.5507828841967144

Epoch: 6| Step: 6
Training loss: 0.24689656960142578
Validation loss: 2.4873115539488215

Epoch: 6| Step: 7
Training loss: 0.1297298907892836
Validation loss: 2.4603175176469225

Epoch: 6| Step: 8
Training loss: 0.15378409902107532
Validation loss: 2.513119534651814

Epoch: 6| Step: 9
Training loss: 0.2145980036374928
Validation loss: 2.515712136540538

Epoch: 6| Step: 10
Training loss: 0.20978124159039088
Validation loss: 2.4980899692549903

Epoch: 6| Step: 11
Training loss: 0.14256270207637864
Validation loss: 2.5286098532707837

Epoch: 6| Step: 12
Training loss: 0.2125288312651236
Validation loss: 2.4861335198454286

Epoch: 6| Step: 13
Training loss: 0.13552605279400273
Validation loss: 2.4894395459694003

Epoch: 560| Step: 0
Training loss: 0.11394884852041613
Validation loss: 2.548052787919474

Epoch: 6| Step: 1
Training loss: 0.14340006357433327
Validation loss: 2.5533471406001977

Epoch: 6| Step: 2
Training loss: 0.13558458880932692
Validation loss: 2.5332905671895647

Epoch: 6| Step: 3
Training loss: 0.1458125922803264
Validation loss: 2.483812275259555

Epoch: 6| Step: 4
Training loss: 0.11689124807847734
Validation loss: 2.530812452411674

Epoch: 6| Step: 5
Training loss: 0.13578198213237222
Validation loss: 2.507176211652344

Epoch: 6| Step: 6
Training loss: 0.29270359756104947
Validation loss: 2.503882174923025

Epoch: 6| Step: 7
Training loss: 0.1822845571130634
Validation loss: 2.5368253539168153

Epoch: 6| Step: 8
Training loss: 0.2183059289179761
Validation loss: 2.5401821588906426

Epoch: 6| Step: 9
Training loss: 0.18046448483732072
Validation loss: 2.5749331606505232

Epoch: 6| Step: 10
Training loss: 0.12667827197238882
Validation loss: 2.5809137032873997

Epoch: 6| Step: 11
Training loss: 0.09701504486784182
Validation loss: 2.553401479705946

Epoch: 6| Step: 12
Training loss: 0.30459160396046525
Validation loss: 2.63944305066057

Epoch: 6| Step: 13
Training loss: 0.203764239732193
Validation loss: 2.610845427442512

Epoch: 561| Step: 0
Training loss: 0.22690331376948197
Validation loss: 2.593226623510842

Epoch: 6| Step: 1
Training loss: 0.16134429116336577
Validation loss: 2.6228996063683403

Epoch: 6| Step: 2
Training loss: 0.24300947982542315
Validation loss: 2.602750569553159

Epoch: 6| Step: 3
Training loss: 0.12487920870456894
Validation loss: 2.5829781821728517

Epoch: 6| Step: 4
Training loss: 0.2780549641627885
Validation loss: 2.537772721690969

Epoch: 6| Step: 5
Training loss: 0.18918701044277017
Validation loss: 2.5289355794526167

Epoch: 6| Step: 6
Training loss: 0.11168935795931953
Validation loss: 2.4898292652412315

Epoch: 6| Step: 7
Training loss: 0.1701359770216422
Validation loss: 2.4969671808965077

Epoch: 6| Step: 8
Training loss: 0.11120540564271224
Validation loss: 2.4818215931785863

Epoch: 6| Step: 9
Training loss: 0.1961115133743225
Validation loss: 2.5071366050063264

Epoch: 6| Step: 10
Training loss: 0.22280668731266018
Validation loss: 2.4588499320712853

Epoch: 6| Step: 11
Training loss: 0.18729626991681503
Validation loss: 2.4896548640150296

Epoch: 6| Step: 12
Training loss: 0.1456951880658271
Validation loss: 2.496177667692577

Epoch: 6| Step: 13
Training loss: 0.14566726396663351
Validation loss: 2.5322584024594605

Epoch: 562| Step: 0
Training loss: 0.1352781762888413
Validation loss: 2.496414763988474

Epoch: 6| Step: 1
Training loss: 0.19584576287459418
Validation loss: 2.5638506491481685

Epoch: 6| Step: 2
Training loss: 0.17482639156692167
Validation loss: 2.5425972636086756

Epoch: 6| Step: 3
Training loss: 0.18962276375318887
Validation loss: 2.5788014926145273

Epoch: 6| Step: 4
Training loss: 0.25161463155859837
Validation loss: 2.5736322847967488

Epoch: 6| Step: 5
Training loss: 0.18689220982346763
Validation loss: 2.540346546844599

Epoch: 6| Step: 6
Training loss: 0.18276923270789075
Validation loss: 2.500698366348031

Epoch: 6| Step: 7
Training loss: 0.2564417057989438
Validation loss: 2.517210891894102

Epoch: 6| Step: 8
Training loss: 0.18431418676759004
Validation loss: 2.4740423048154074

Epoch: 6| Step: 9
Training loss: 0.1290082961092857
Validation loss: 2.4970543170957744

Epoch: 6| Step: 10
Training loss: 0.18965577564126754
Validation loss: 2.447521149662516

Epoch: 6| Step: 11
Training loss: 0.20502985431607174
Validation loss: 2.49911142473004

Epoch: 6| Step: 12
Training loss: 0.24825808026262458
Validation loss: 2.5237246195442395

Epoch: 6| Step: 13
Training loss: 0.1470649657474385
Validation loss: 2.487999918701695

Epoch: 563| Step: 0
Training loss: 0.16538333536191832
Validation loss: 2.4722796828612386

Epoch: 6| Step: 1
Training loss: 0.16849676023072668
Validation loss: 2.479037153673906

Epoch: 6| Step: 2
Training loss: 0.1263583261251285
Validation loss: 2.4681143024653687

Epoch: 6| Step: 3
Training loss: 0.13601749960074794
Validation loss: 2.481132396711905

Epoch: 6| Step: 4
Training loss: 0.160580677455754
Validation loss: 2.510670015274307

Epoch: 6| Step: 5
Training loss: 0.2146822756058025
Validation loss: 2.5286851672904227

Epoch: 6| Step: 6
Training loss: 0.16364688682540812
Validation loss: 2.508846984135125

Epoch: 6| Step: 7
Training loss: 0.16919660897142877
Validation loss: 2.5126081090883474

Epoch: 6| Step: 8
Training loss: 0.1413540880933453
Validation loss: 2.5201583581722797

Epoch: 6| Step: 9
Training loss: 0.15856368573865257
Validation loss: 2.5397515494543623

Epoch: 6| Step: 10
Training loss: 0.2278451293633585
Validation loss: 2.5412990657936416

Epoch: 6| Step: 11
Training loss: 0.25323542964685325
Validation loss: 2.5767719734447048

Epoch: 6| Step: 12
Training loss: 0.11004531614403813
Validation loss: 2.5644657299741427

Epoch: 6| Step: 13
Training loss: 0.21105821122569757
Validation loss: 2.558943482642352

Epoch: 564| Step: 0
Training loss: 0.13633228585306972
Validation loss: 2.5794479843765195

Epoch: 6| Step: 1
Training loss: 0.1140994988489596
Validation loss: 2.61144602713556

Epoch: 6| Step: 2
Training loss: 0.10527499822333712
Validation loss: 2.6009883890748

Epoch: 6| Step: 3
Training loss: 0.2186804643874552
Validation loss: 2.57661969192984

Epoch: 6| Step: 4
Training loss: 0.12474005836112323
Validation loss: 2.566153176520364

Epoch: 6| Step: 5
Training loss: 0.15892146527188114
Validation loss: 2.5988715537073657

Epoch: 6| Step: 6
Training loss: 0.21517192744674857
Validation loss: 2.596582472519883

Epoch: 6| Step: 7
Training loss: 0.14698923213926607
Validation loss: 2.533880335922199

Epoch: 6| Step: 8
Training loss: 0.18144020180131104
Validation loss: 2.5521894267575185

Epoch: 6| Step: 9
Training loss: 0.14908344490523487
Validation loss: 2.529436716570764

Epoch: 6| Step: 10
Training loss: 0.17323047787595783
Validation loss: 2.56488089973649

Epoch: 6| Step: 11
Training loss: 0.19064098275517416
Validation loss: 2.5438125853801035

Epoch: 6| Step: 12
Training loss: 0.14235553611006602
Validation loss: 2.575964666474627

Epoch: 6| Step: 13
Training loss: 0.17280723520643987
Validation loss: 2.5151543258140627

Epoch: 565| Step: 0
Training loss: 0.10330965585682268
Validation loss: 2.556937370086938

Epoch: 6| Step: 1
Training loss: 0.1390928005039544
Validation loss: 2.540432770854532

Epoch: 6| Step: 2
Training loss: 0.12569052729714392
Validation loss: 2.5601880358448446

Epoch: 6| Step: 3
Training loss: 0.1695205289553477
Validation loss: 2.593052639489543

Epoch: 6| Step: 4
Training loss: 0.16796716423173258
Validation loss: 2.55116967694841

Epoch: 6| Step: 5
Training loss: 0.14672964543115488
Validation loss: 2.599525785427042

Epoch: 6| Step: 6
Training loss: 0.19599301041637776
Validation loss: 2.593698893721976

Epoch: 6| Step: 7
Training loss: 0.16853366711893966
Validation loss: 2.5716231270779666

Epoch: 6| Step: 8
Training loss: 0.2692206431281888
Validation loss: 2.581050664821707

Epoch: 6| Step: 9
Training loss: 0.11989060407360207
Validation loss: 2.5967779191524873

Epoch: 6| Step: 10
Training loss: 0.10768708954869588
Validation loss: 2.5630422069049805

Epoch: 6| Step: 11
Training loss: 0.19527452099616457
Validation loss: 2.5836111971871354

Epoch: 6| Step: 12
Training loss: 0.1624155714711856
Validation loss: 2.5810266478119597

Epoch: 6| Step: 13
Training loss: 0.15579518643237825
Validation loss: 2.558967183958809

Epoch: 566| Step: 0
Training loss: 0.1298088207155072
Validation loss: 2.564047242505322

Epoch: 6| Step: 1
Training loss: 0.14574756967160662
Validation loss: 2.583848216865479

Epoch: 6| Step: 2
Training loss: 0.17286797353997058
Validation loss: 2.58284102905034

Epoch: 6| Step: 3
Training loss: 0.1438239809068116
Validation loss: 2.5272220825036045

Epoch: 6| Step: 4
Training loss: 0.12516764485353268
Validation loss: 2.5494013147665027

Epoch: 6| Step: 5
Training loss: 0.07523706131790751
Validation loss: 2.5329634846048004

Epoch: 6| Step: 6
Training loss: 0.20014292333877887
Validation loss: 2.5354779117761246

Epoch: 6| Step: 7
Training loss: 0.2328595440332879
Validation loss: 2.5533375852157407

Epoch: 6| Step: 8
Training loss: 0.23134514294825512
Validation loss: 2.5313605372130934

Epoch: 6| Step: 9
Training loss: 0.155898378028562
Validation loss: 2.5746328976883985

Epoch: 6| Step: 10
Training loss: 0.23028189956608627
Validation loss: 2.574216395713196

Epoch: 6| Step: 11
Training loss: 0.14233984697939103
Validation loss: 2.605483717744031

Epoch: 6| Step: 12
Training loss: 0.17768246028742496
Validation loss: 2.5663439317205303

Epoch: 6| Step: 13
Training loss: 0.2920147941284018
Validation loss: 2.5770587703871803

Epoch: 567| Step: 0
Training loss: 0.11538636157734956
Validation loss: 2.5754237975051213

Epoch: 6| Step: 1
Training loss: 0.19163079617189244
Validation loss: 2.54592982855602

Epoch: 6| Step: 2
Training loss: 0.14766588558062382
Validation loss: 2.5170275778649183

Epoch: 6| Step: 3
Training loss: 0.2646771939690893
Validation loss: 2.538788966991755

Epoch: 6| Step: 4
Training loss: 0.15490087160943597
Validation loss: 2.518717013131129

Epoch: 6| Step: 5
Training loss: 0.15589964449192326
Validation loss: 2.4927572033242393

Epoch: 6| Step: 6
Training loss: 0.23181519548140284
Validation loss: 2.5165126658343304

Epoch: 6| Step: 7
Training loss: 0.16346649494413312
Validation loss: 2.525898206971727

Epoch: 6| Step: 8
Training loss: 0.12027639212576757
Validation loss: 2.5149805553929583

Epoch: 6| Step: 9
Training loss: 0.12397723952001628
Validation loss: 2.536584240570287

Epoch: 6| Step: 10
Training loss: 0.11484027811887783
Validation loss: 2.540479097819981

Epoch: 6| Step: 11
Training loss: 0.1615420491060137
Validation loss: 2.498695605450718

Epoch: 6| Step: 12
Training loss: 0.15218703450047544
Validation loss: 2.520510830271726

Epoch: 6| Step: 13
Training loss: 0.20404695391768463
Validation loss: 2.5353382638788617

Epoch: 568| Step: 0
Training loss: 0.16786977713059154
Validation loss: 2.5747042607080237

Epoch: 6| Step: 1
Training loss: 0.18979540118958502
Validation loss: 2.5055108540831896

Epoch: 6| Step: 2
Training loss: 0.12154225384310252
Validation loss: 2.5060052732120446

Epoch: 6| Step: 3
Training loss: 0.1144591334787081
Validation loss: 2.523474248020848

Epoch: 6| Step: 4
Training loss: 0.23022521616591812
Validation loss: 2.5336026037946984

Epoch: 6| Step: 5
Training loss: 0.17735059405661033
Validation loss: 2.5025266308142124

Epoch: 6| Step: 6
Training loss: 0.18782515941741568
Validation loss: 2.51442835417273

Epoch: 6| Step: 7
Training loss: 0.10508361007952469
Validation loss: 2.521574737316732

Epoch: 6| Step: 8
Training loss: 0.1483338960682003
Validation loss: 2.520298131578795

Epoch: 6| Step: 9
Training loss: 0.20903113546153035
Validation loss: 2.5031527835498775

Epoch: 6| Step: 10
Training loss: 0.11533406358393054
Validation loss: 2.552339682010856

Epoch: 6| Step: 11
Training loss: 0.10613196299286297
Validation loss: 2.5452952289062694

Epoch: 6| Step: 12
Training loss: 0.16549696967139646
Validation loss: 2.5809135940235852

Epoch: 6| Step: 13
Training loss: 0.2967583150935967
Validation loss: 2.583448519274029

Epoch: 569| Step: 0
Training loss: 0.23581481390079925
Validation loss: 2.5844946548956758

Epoch: 6| Step: 1
Training loss: 0.12971938040131464
Validation loss: 2.5527664236412626

Epoch: 6| Step: 2
Training loss: 0.12337301567814371
Validation loss: 2.578495794227219

Epoch: 6| Step: 3
Training loss: 0.22816230488501676
Validation loss: 2.569321241106912

Epoch: 6| Step: 4
Training loss: 0.1969273754872036
Validation loss: 2.590565311335985

Epoch: 6| Step: 5
Training loss: 0.1902045949228707
Validation loss: 2.6224818772126435

Epoch: 6| Step: 6
Training loss: 0.1619086861724405
Validation loss: 2.5470387657607003

Epoch: 6| Step: 7
Training loss: 0.13125814344483497
Validation loss: 2.5450454261478255

Epoch: 6| Step: 8
Training loss: 0.1419742153080547
Validation loss: 2.5474793128449758

Epoch: 6| Step: 9
Training loss: 0.11071979222249921
Validation loss: 2.55599797068456

Epoch: 6| Step: 10
Training loss: 0.11378254631810629
Validation loss: 2.5542688939039486

Epoch: 6| Step: 11
Training loss: 0.20031129222214153
Validation loss: 2.5059896018429093

Epoch: 6| Step: 12
Training loss: 0.1038266134905531
Validation loss: 2.54738834677631

Epoch: 6| Step: 13
Training loss: 0.15750101670058148
Validation loss: 2.557501381289803

Epoch: 570| Step: 0
Training loss: 0.25507439614998134
Validation loss: 2.5945560672047128

Epoch: 6| Step: 1
Training loss: 0.2209580223879304
Validation loss: 2.5485935992013062

Epoch: 6| Step: 2
Training loss: 0.15594778636649786
Validation loss: 2.577051683470417

Epoch: 6| Step: 3
Training loss: 0.16004736618313717
Validation loss: 2.5913416542332808

Epoch: 6| Step: 4
Training loss: 0.1550477444944304
Validation loss: 2.55584396393743

Epoch: 6| Step: 5
Training loss: 0.24246571311961373
Validation loss: 2.5884452704983256

Epoch: 6| Step: 6
Training loss: 0.1978836575805253
Validation loss: 2.552151703980784

Epoch: 6| Step: 7
Training loss: 0.2366817760233723
Validation loss: 2.5332488535162265

Epoch: 6| Step: 8
Training loss: 0.10564754483901491
Validation loss: 2.5356726612882894

Epoch: 6| Step: 9
Training loss: 0.23251792782195008
Validation loss: 2.4996042758756754

Epoch: 6| Step: 10
Training loss: 0.17237381727312184
Validation loss: 2.5138765420631075

Epoch: 6| Step: 11
Training loss: 0.23700875404996524
Validation loss: 2.5546516144237748

Epoch: 6| Step: 12
Training loss: 0.1415216088657234
Validation loss: 2.5733405073791578

Epoch: 6| Step: 13
Training loss: 0.12899058646455588
Validation loss: 2.5657327381023567

Epoch: 571| Step: 0
Training loss: 0.11169798798140666
Validation loss: 2.601325197737736

Epoch: 6| Step: 1
Training loss: 0.12288590907792894
Validation loss: 2.6147526863204766

Epoch: 6| Step: 2
Training loss: 0.17008911321607667
Validation loss: 2.6639302235649462

Epoch: 6| Step: 3
Training loss: 0.23466099138558802
Validation loss: 2.6353885665835812

Epoch: 6| Step: 4
Training loss: 0.17580775484956318
Validation loss: 2.602214038031574

Epoch: 6| Step: 5
Training loss: 0.10445526397614933
Validation loss: 2.5781542784121245

Epoch: 6| Step: 6
Training loss: 0.14444293081604145
Validation loss: 2.570104720325638

Epoch: 6| Step: 7
Training loss: 0.1284096356143086
Validation loss: 2.5674637141303998

Epoch: 6| Step: 8
Training loss: 0.23059236314943016
Validation loss: 2.494089767247567

Epoch: 6| Step: 9
Training loss: 0.3004971314156853
Validation loss: 2.4930040280266894

Epoch: 6| Step: 10
Training loss: 0.28662512287381814
Validation loss: 2.484725368149587

Epoch: 6| Step: 11
Training loss: 0.13867069297609125
Validation loss: 2.469257097564482

Epoch: 6| Step: 12
Training loss: 0.26714409481199736
Validation loss: 2.471749151311407

Epoch: 6| Step: 13
Training loss: 0.1589459300128813
Validation loss: 2.503942543401417

Epoch: 572| Step: 0
Training loss: 0.20647285840655555
Validation loss: 2.5169340546861676

Epoch: 6| Step: 1
Training loss: 0.17378411110846653
Validation loss: 2.550480879726968

Epoch: 6| Step: 2
Training loss: 0.15396901801650992
Validation loss: 2.5160877156618824

Epoch: 6| Step: 3
Training loss: 0.1815099759053188
Validation loss: 2.548682390817307

Epoch: 6| Step: 4
Training loss: 0.14501457334321444
Validation loss: 2.581078024869931

Epoch: 6| Step: 5
Training loss: 0.1423353649877262
Validation loss: 2.583115715072753

Epoch: 6| Step: 6
Training loss: 0.2506739502713716
Validation loss: 2.557037307449705

Epoch: 6| Step: 7
Training loss: 0.15713951710400237
Validation loss: 2.5529108677616335

Epoch: 6| Step: 8
Training loss: 0.1483355849899706
Validation loss: 2.523465099670796

Epoch: 6| Step: 9
Training loss: 0.2326660796702758
Validation loss: 2.524031457159189

Epoch: 6| Step: 10
Training loss: 0.28339980300584866
Validation loss: 2.494924773246275

Epoch: 6| Step: 11
Training loss: 0.13887386654701156
Validation loss: 2.4944338721248847

Epoch: 6| Step: 12
Training loss: 0.21158393072337187
Validation loss: 2.510147414901032

Epoch: 6| Step: 13
Training loss: 0.22909767654908758
Validation loss: 2.548694237914982

Epoch: 573| Step: 0
Training loss: 0.16735020122862174
Validation loss: 2.5074406584791205

Epoch: 6| Step: 1
Training loss: 0.15910201722849734
Validation loss: 2.557207859076946

Epoch: 6| Step: 2
Training loss: 0.18772572599466977
Validation loss: 2.566445136754663

Epoch: 6| Step: 3
Training loss: 0.2550930018855047
Validation loss: 2.552347778187362

Epoch: 6| Step: 4
Training loss: 0.1510410795255189
Validation loss: 2.598742731810026

Epoch: 6| Step: 5
Training loss: 0.24752473317455462
Validation loss: 2.542778856765323

Epoch: 6| Step: 6
Training loss: 0.224178124113426
Validation loss: 2.5508276915330472

Epoch: 6| Step: 7
Training loss: 0.16710759240867615
Validation loss: 2.4939763985799877

Epoch: 6| Step: 8
Training loss: 0.17858598854107266
Validation loss: 2.542362447894898

Epoch: 6| Step: 9
Training loss: 0.21236745613602354
Validation loss: 2.5188425509021886

Epoch: 6| Step: 10
Training loss: 0.22068582315059065
Validation loss: 2.5234304783769548

Epoch: 6| Step: 11
Training loss: 0.19792186997918737
Validation loss: 2.508321229063795

Epoch: 6| Step: 12
Training loss: 0.16872784504449576
Validation loss: 2.4998899553546687

Epoch: 6| Step: 13
Training loss: 0.2582814834972141
Validation loss: 2.50211463729608

Epoch: 574| Step: 0
Training loss: 0.15077294638109148
Validation loss: 2.5051289869194284

Epoch: 6| Step: 1
Training loss: 0.2133864744053265
Validation loss: 2.506563203807412

Epoch: 6| Step: 2
Training loss: 0.16767025084753606
Validation loss: 2.47573280378584

Epoch: 6| Step: 3
Training loss: 0.22755188967195283
Validation loss: 2.4927265392951763

Epoch: 6| Step: 4
Training loss: 0.2874644153797725
Validation loss: 2.485246718608196

Epoch: 6| Step: 5
Training loss: 0.2918296284913366
Validation loss: 2.5305857873779742

Epoch: 6| Step: 6
Training loss: 0.1509245028931976
Validation loss: 2.5872271287836326

Epoch: 6| Step: 7
Training loss: 0.10513601534241589
Validation loss: 2.571630859988089

Epoch: 6| Step: 8
Training loss: 0.2635231304937633
Validation loss: 2.6049158435453124

Epoch: 6| Step: 9
Training loss: 0.19371668236889492
Validation loss: 2.595232681495416

Epoch: 6| Step: 10
Training loss: 0.2138857463291703
Validation loss: 2.5434914817481236

Epoch: 6| Step: 11
Training loss: 0.20104007662669776
Validation loss: 2.5548446660616135

Epoch: 6| Step: 12
Training loss: 0.2564912230512517
Validation loss: 2.504252406281908

Epoch: 6| Step: 13
Training loss: 0.12281578555820352
Validation loss: 2.5469186722346486

Epoch: 575| Step: 0
Training loss: 0.17706185215266965
Validation loss: 2.492747531895641

Epoch: 6| Step: 1
Training loss: 0.12515945992419403
Validation loss: 2.566424512233948

Epoch: 6| Step: 2
Training loss: 0.14025168405038563
Validation loss: 2.5319822769604565

Epoch: 6| Step: 3
Training loss: 0.25467588714148515
Validation loss: 2.5404830495190636

Epoch: 6| Step: 4
Training loss: 0.16256617335796827
Validation loss: 2.5800322765599484

Epoch: 6| Step: 5
Training loss: 0.14257783759101222
Validation loss: 2.567807846838362

Epoch: 6| Step: 6
Training loss: 0.20593827018825317
Validation loss: 2.5575348757816148

Epoch: 6| Step: 7
Training loss: 0.20254157716814125
Validation loss: 2.597784690571357

Epoch: 6| Step: 8
Training loss: 0.15779101891250794
Validation loss: 2.6014547821205345

Epoch: 6| Step: 9
Training loss: 0.16766160783978978
Validation loss: 2.582780314056492

Epoch: 6| Step: 10
Training loss: 0.13721812871941327
Validation loss: 2.5678295369891506

Epoch: 6| Step: 11
Training loss: 0.1530585514616951
Validation loss: 2.5574796145717547

Epoch: 6| Step: 12
Training loss: 0.17561164196807272
Validation loss: 2.535853677186088

Epoch: 6| Step: 13
Training loss: 0.17329816720178254
Validation loss: 2.5611031899913144

Epoch: 576| Step: 0
Training loss: 0.1178501349132888
Validation loss: 2.5520346326536347

Epoch: 6| Step: 1
Training loss: 0.13909097256798197
Validation loss: 2.577103873917835

Epoch: 6| Step: 2
Training loss: 0.22088566548385105
Validation loss: 2.539088872704744

Epoch: 6| Step: 3
Training loss: 0.24567650436991978
Validation loss: 2.5289233873744568

Epoch: 6| Step: 4
Training loss: 0.174916274401481
Validation loss: 2.548796741476416

Epoch: 6| Step: 5
Training loss: 0.12030052521797882
Validation loss: 2.546345499503207

Epoch: 6| Step: 6
Training loss: 0.14303765642763808
Validation loss: 2.5574050422726895

Epoch: 6| Step: 7
Training loss: 0.24100505675851472
Validation loss: 2.6057231909394463

Epoch: 6| Step: 8
Training loss: 0.14331466694876763
Validation loss: 2.595389790607191

Epoch: 6| Step: 9
Training loss: 0.10091456644337435
Validation loss: 2.5712722849994982

Epoch: 6| Step: 10
Training loss: 0.08914478144370919
Validation loss: 2.574047293730733

Epoch: 6| Step: 11
Training loss: 0.1836669045655613
Validation loss: 2.5671893560913768

Epoch: 6| Step: 12
Training loss: 0.1196280732417785
Validation loss: 2.5588034292080843

Epoch: 6| Step: 13
Training loss: 0.14221013931673243
Validation loss: 2.563551802211245

Epoch: 577| Step: 0
Training loss: 0.16656507559855122
Validation loss: 2.567022309383472

Epoch: 6| Step: 1
Training loss: 0.10250527869855736
Validation loss: 2.534595722752839

Epoch: 6| Step: 2
Training loss: 0.1204171273842526
Validation loss: 2.547172421819319

Epoch: 6| Step: 3
Training loss: 0.12195130459870446
Validation loss: 2.5447101886040926

Epoch: 6| Step: 4
Training loss: 0.10587630294923595
Validation loss: 2.5342900675941187

Epoch: 6| Step: 5
Training loss: 0.18471466958668617
Validation loss: 2.5646795082573774

Epoch: 6| Step: 6
Training loss: 0.22929894448017432
Validation loss: 2.5632620928028595

Epoch: 6| Step: 7
Training loss: 0.19143662892815028
Validation loss: 2.5837149210876817

Epoch: 6| Step: 8
Training loss: 0.11240936459539178
Validation loss: 2.587933871557397

Epoch: 6| Step: 9
Training loss: 0.14599713991740818
Validation loss: 2.568277236870888

Epoch: 6| Step: 10
Training loss: 0.17167791532745352
Validation loss: 2.5540985916841437

Epoch: 6| Step: 11
Training loss: 0.09712056580385332
Validation loss: 2.569660336301562

Epoch: 6| Step: 12
Training loss: 0.19207683183654745
Validation loss: 2.565465086552162

Epoch: 6| Step: 13
Training loss: 0.12355317297268645
Validation loss: 2.549712902996717

Epoch: 578| Step: 0
Training loss: 0.15774740113371052
Validation loss: 2.589511922155715

Epoch: 6| Step: 1
Training loss: 0.2357636322659304
Validation loss: 2.572010178684729

Epoch: 6| Step: 2
Training loss: 0.17023685464020324
Validation loss: 2.5380530635979635

Epoch: 6| Step: 3
Training loss: 0.2051919167304988
Validation loss: 2.5859508716671384

Epoch: 6| Step: 4
Training loss: 0.22689648379391794
Validation loss: 2.540651402235799

Epoch: 6| Step: 5
Training loss: 0.12621554543086233
Validation loss: 2.5567197859264144

Epoch: 6| Step: 6
Training loss: 0.12459358441145939
Validation loss: 2.5560264383937628

Epoch: 6| Step: 7
Training loss: 0.12191811801431561
Validation loss: 2.578480065818115

Epoch: 6| Step: 8
Training loss: 0.1171081115114994
Validation loss: 2.544479230760658

Epoch: 6| Step: 9
Training loss: 0.15267032685284024
Validation loss: 2.542151713641734

Epoch: 6| Step: 10
Training loss: 0.20030518284851764
Validation loss: 2.5296837404452917

Epoch: 6| Step: 11
Training loss: 0.11290480283785852
Validation loss: 2.495286171702636

Epoch: 6| Step: 12
Training loss: 0.09553183095622461
Validation loss: 2.4882688855103723

Epoch: 6| Step: 13
Training loss: 0.12974841112200358
Validation loss: 2.472544080620703

Epoch: 579| Step: 0
Training loss: 0.1547160249958216
Validation loss: 2.5080719529509774

Epoch: 6| Step: 1
Training loss: 0.11283876884620113
Validation loss: 2.4946967013588646

Epoch: 6| Step: 2
Training loss: 0.15799600677333167
Validation loss: 2.4953051784088274

Epoch: 6| Step: 3
Training loss: 0.21940647971246233
Validation loss: 2.5054263976681823

Epoch: 6| Step: 4
Training loss: 0.21628878741723084
Validation loss: 2.4809073705928344

Epoch: 6| Step: 5
Training loss: 0.12288178616437766
Validation loss: 2.5026846663129287

Epoch: 6| Step: 6
Training loss: 0.21183358699191634
Validation loss: 2.5161524557062496

Epoch: 6| Step: 7
Training loss: 0.19831087773354117
Validation loss: 2.5366098658891487

Epoch: 6| Step: 8
Training loss: 0.16623289812652675
Validation loss: 2.5628953244105372

Epoch: 6| Step: 9
Training loss: 0.10807438690457047
Validation loss: 2.55984407203453

Epoch: 6| Step: 10
Training loss: 0.15017559110540388
Validation loss: 2.55538197629074

Epoch: 6| Step: 11
Training loss: 0.12052046525459935
Validation loss: 2.5452012280127243

Epoch: 6| Step: 12
Training loss: 0.16355026411329954
Validation loss: 2.536722953782267

Epoch: 6| Step: 13
Training loss: 0.13484496393464013
Validation loss: 2.5554311371891223

Epoch: 580| Step: 0
Training loss: 0.3005434929598179
Validation loss: 2.5594454902795007

Epoch: 6| Step: 1
Training loss: 0.12630114768032355
Validation loss: 2.518595865351319

Epoch: 6| Step: 2
Training loss: 0.14095017137256555
Validation loss: 2.500435003766539

Epoch: 6| Step: 3
Training loss: 0.17779705493400622
Validation loss: 2.519600313357282

Epoch: 6| Step: 4
Training loss: 0.2450313189739592
Validation loss: 2.4760055622259216

Epoch: 6| Step: 5
Training loss: 0.17169660825527264
Validation loss: 2.480022979154189

Epoch: 6| Step: 6
Training loss: 0.17043535980710595
Validation loss: 2.4853084351024224

Epoch: 6| Step: 7
Training loss: 0.21788209505232173
Validation loss: 2.4597099444604

Epoch: 6| Step: 8
Training loss: 0.132264641162708
Validation loss: 2.446212110331874

Epoch: 6| Step: 9
Training loss: 0.20860668170862684
Validation loss: 2.4193144908398203

Epoch: 6| Step: 10
Training loss: 0.17566900908410704
Validation loss: 2.4554325681026565

Epoch: 6| Step: 11
Training loss: 0.30436001809316277
Validation loss: 2.4682747349789875

Epoch: 6| Step: 12
Training loss: 0.20366969802096854
Validation loss: 2.5166857488140075

Epoch: 6| Step: 13
Training loss: 0.30012851336725316
Validation loss: 2.5103631003452636

Epoch: 581| Step: 0
Training loss: 0.20119952965436358
Validation loss: 2.6122674304573605

Epoch: 6| Step: 1
Training loss: 0.28433887702899246
Validation loss: 2.5995228258526573

Epoch: 6| Step: 2
Training loss: 0.2478878457616607
Validation loss: 2.5853072520131484

Epoch: 6| Step: 3
Training loss: 0.1899405040572444
Validation loss: 2.637765284302661

Epoch: 6| Step: 4
Training loss: 0.18491190630043147
Validation loss: 2.6307814003129657

Epoch: 6| Step: 5
Training loss: 0.22895283729463814
Validation loss: 2.574160649078105

Epoch: 6| Step: 6
Training loss: 0.21884280177685428
Validation loss: 2.5802398092184418

Epoch: 6| Step: 7
Training loss: 0.3404774621914107
Validation loss: 2.551842655354245

Epoch: 6| Step: 8
Training loss: 0.13877781327168434
Validation loss: 2.543084133799296

Epoch: 6| Step: 9
Training loss: 0.17243787323986334
Validation loss: 2.5475820786260264

Epoch: 6| Step: 10
Training loss: 0.17574013653075843
Validation loss: 2.5613020400976265

Epoch: 6| Step: 11
Training loss: 0.14318806679903606
Validation loss: 2.557393087166175

Epoch: 6| Step: 12
Training loss: 0.1597443669080417
Validation loss: 2.5987995482338073

Epoch: 6| Step: 13
Training loss: 0.09356790481091638
Validation loss: 2.58819932040299

Epoch: 582| Step: 0
Training loss: 0.11532543916136959
Validation loss: 2.622694596018784

Epoch: 6| Step: 1
Training loss: 0.14141309626745335
Validation loss: 2.581431059289993

Epoch: 6| Step: 2
Training loss: 0.13823981876720695
Validation loss: 2.5739117822348416

Epoch: 6| Step: 3
Training loss: 0.1775778930467869
Validation loss: 2.588021325347569

Epoch: 6| Step: 4
Training loss: 0.27173501389951354
Validation loss: 2.5631086137962074

Epoch: 6| Step: 5
Training loss: 0.19728890838695579
Validation loss: 2.5845616867465266

Epoch: 6| Step: 6
Training loss: 0.1770037315542391
Validation loss: 2.5923424756579125

Epoch: 6| Step: 7
Training loss: 0.22976304161437952
Validation loss: 2.592206807967604

Epoch: 6| Step: 8
Training loss: 0.17106977865304193
Validation loss: 2.5562613643768004

Epoch: 6| Step: 9
Training loss: 0.0936799184799369
Validation loss: 2.537162844804391

Epoch: 6| Step: 10
Training loss: 0.22886250732188926
Validation loss: 2.5520740156441

Epoch: 6| Step: 11
Training loss: 0.14751945370349237
Validation loss: 2.5163374212855905

Epoch: 6| Step: 12
Training loss: 0.27459968452122924
Validation loss: 2.5152992853452085

Epoch: 6| Step: 13
Training loss: 0.1338685627875855
Validation loss: 2.5171334527345226

Epoch: 583| Step: 0
Training loss: 0.1414213283150196
Validation loss: 2.5514975288366624

Epoch: 6| Step: 1
Training loss: 0.15348980883113716
Validation loss: 2.5461654867598904

Epoch: 6| Step: 2
Training loss: 0.2054223033494053
Validation loss: 2.5608797090531086

Epoch: 6| Step: 3
Training loss: 0.17898045212947838
Validation loss: 2.5361203972545527

Epoch: 6| Step: 4
Training loss: 0.17964089867387775
Validation loss: 2.546248433829696

Epoch: 6| Step: 5
Training loss: 0.25548619435331965
Validation loss: 2.521233907602848

Epoch: 6| Step: 6
Training loss: 0.18154691514378282
Validation loss: 2.535583885756729

Epoch: 6| Step: 7
Training loss: 0.22165963842667777
Validation loss: 2.537545963604344

Epoch: 6| Step: 8
Training loss: 0.31219708543482483
Validation loss: 2.5354677612479986

Epoch: 6| Step: 9
Training loss: 0.14913770886623115
Validation loss: 2.540687413410074

Epoch: 6| Step: 10
Training loss: 0.3154075071490636
Validation loss: 2.555476900327105

Epoch: 6| Step: 11
Training loss: 0.1446222135037173
Validation loss: 2.526449850019501

Epoch: 6| Step: 12
Training loss: 0.16627440199097054
Validation loss: 2.5158680404997664

Epoch: 6| Step: 13
Training loss: 0.09511982015299378
Validation loss: 2.5462626975577254

Epoch: 584| Step: 0
Training loss: 0.3105398933057687
Validation loss: 2.5274587787855647

Epoch: 6| Step: 1
Training loss: 0.2543937111985943
Validation loss: 2.5643460017122632

Epoch: 6| Step: 2
Training loss: 0.23085517330832073
Validation loss: 2.56910529900438

Epoch: 6| Step: 3
Training loss: 0.22487971580855431
Validation loss: 2.581389966127285

Epoch: 6| Step: 4
Training loss: 0.17171503338944
Validation loss: 2.5641185751991706

Epoch: 6| Step: 5
Training loss: 0.20599736867307408
Validation loss: 2.5988881180182495

Epoch: 6| Step: 6
Training loss: 0.18256793658484827
Validation loss: 2.602171181507093

Epoch: 6| Step: 7
Training loss: 0.2185910618216605
Validation loss: 2.5988451671891917

Epoch: 6| Step: 8
Training loss: 0.22695475362695633
Validation loss: 2.5856114430942814

Epoch: 6| Step: 9
Training loss: 0.23089948102482594
Validation loss: 2.6009313779924925

Epoch: 6| Step: 10
Training loss: 0.25213047557534196
Validation loss: 2.55757934230079

Epoch: 6| Step: 11
Training loss: 0.22609666914726134
Validation loss: 2.552605861053774

Epoch: 6| Step: 12
Training loss: 0.14052517314663374
Validation loss: 2.505756369310964

Epoch: 6| Step: 13
Training loss: 0.12153833055848991
Validation loss: 2.485143594074883

Epoch: 585| Step: 0
Training loss: 0.16441372333690113
Validation loss: 2.485458729450112

Epoch: 6| Step: 1
Training loss: 0.1628684632573465
Validation loss: 2.4816287120887237

Epoch: 6| Step: 2
Training loss: 0.20110556055760453
Validation loss: 2.5278188982766707

Epoch: 6| Step: 3
Training loss: 0.11275506311560252
Validation loss: 2.528677022218706

Epoch: 6| Step: 4
Training loss: 0.23430832073293129
Validation loss: 2.5550182276843905

Epoch: 6| Step: 5
Training loss: 0.12711702184295318
Validation loss: 2.54850027172612

Epoch: 6| Step: 6
Training loss: 0.06539090273853965
Validation loss: 2.589133930834306

Epoch: 6| Step: 7
Training loss: 0.20923348312979786
Validation loss: 2.609493118097392

Epoch: 6| Step: 8
Training loss: 0.20873844971367933
Validation loss: 2.600005808256617

Epoch: 6| Step: 9
Training loss: 0.2969084269125924
Validation loss: 2.6062423276676427

Epoch: 6| Step: 10
Training loss: 0.1313660619382935
Validation loss: 2.58746817523015

Epoch: 6| Step: 11
Training loss: 0.27389354822158213
Validation loss: 2.569838733199595

Epoch: 6| Step: 12
Training loss: 0.21066657080590304
Validation loss: 2.5554072114605644

Epoch: 6| Step: 13
Training loss: 0.11508164548700804
Validation loss: 2.557615560677153

Epoch: 586| Step: 0
Training loss: 0.13379220889213378
Validation loss: 2.510678099295748

Epoch: 6| Step: 1
Training loss: 0.18822739491757398
Validation loss: 2.4821559328876557

Epoch: 6| Step: 2
Training loss: 0.09160757329777126
Validation loss: 2.4990428107339655

Epoch: 6| Step: 3
Training loss: 0.1753771853236034
Validation loss: 2.4712109286878876

Epoch: 6| Step: 4
Training loss: 0.20932843950314467
Validation loss: 2.472766187352835

Epoch: 6| Step: 5
Training loss: 0.21096029864834906
Validation loss: 2.523872247366399

Epoch: 6| Step: 6
Training loss: 0.16533243187159014
Validation loss: 2.4859643857990723

Epoch: 6| Step: 7
Training loss: 0.1503750433838513
Validation loss: 2.514722472264956

Epoch: 6| Step: 8
Training loss: 0.15427120212452466
Validation loss: 2.5064688483207176

Epoch: 6| Step: 9
Training loss: 0.21300423066992602
Validation loss: 2.544239187367593

Epoch: 6| Step: 10
Training loss: 0.14140788019410316
Validation loss: 2.56436794258151

Epoch: 6| Step: 11
Training loss: 0.14041879555982517
Validation loss: 2.538479197402205

Epoch: 6| Step: 12
Training loss: 0.18075500467568592
Validation loss: 2.5428217010552774

Epoch: 6| Step: 13
Training loss: 0.09905036507478569
Validation loss: 2.5465998749810583

Epoch: 587| Step: 0
Training loss: 0.16679294032117145
Validation loss: 2.5264776339306945

Epoch: 6| Step: 1
Training loss: 0.21937194182228728
Validation loss: 2.5665074758007664

Epoch: 6| Step: 2
Training loss: 0.1366337511962948
Validation loss: 2.5455502974874777

Epoch: 6| Step: 3
Training loss: 0.20847663520581566
Validation loss: 2.5630342580371592

Epoch: 6| Step: 4
Training loss: 0.11093419634238522
Validation loss: 2.568648432652892

Epoch: 6| Step: 5
Training loss: 0.2493246911626372
Validation loss: 2.5830357056279487

Epoch: 6| Step: 6
Training loss: 0.1883652511559808
Validation loss: 2.5210626789886565

Epoch: 6| Step: 7
Training loss: 0.1788390487327608
Validation loss: 2.518809494040199

Epoch: 6| Step: 8
Training loss: 0.13420081992506472
Validation loss: 2.5222346466075507

Epoch: 6| Step: 9
Training loss: 0.098425817931766
Validation loss: 2.5497340090748186

Epoch: 6| Step: 10
Training loss: 0.17642932739207548
Validation loss: 2.5404517849125465

Epoch: 6| Step: 11
Training loss: 0.2395164026534806
Validation loss: 2.543758325643027

Epoch: 6| Step: 12
Training loss: 0.13754202379344804
Validation loss: 2.545072500386181

Epoch: 6| Step: 13
Training loss: 0.16822202571873413
Validation loss: 2.52925602847494

Epoch: 588| Step: 0
Training loss: 0.12001202018954969
Validation loss: 2.5791560642290166

Epoch: 6| Step: 1
Training loss: 0.13480090633142122
Validation loss: 2.556817207075215

Epoch: 6| Step: 2
Training loss: 0.13172036509355162
Validation loss: 2.5692447015633655

Epoch: 6| Step: 3
Training loss: 0.19992350292549238
Validation loss: 2.5582793257301204

Epoch: 6| Step: 4
Training loss: 0.1607917470535986
Validation loss: 2.5259535958190265

Epoch: 6| Step: 5
Training loss: 0.14351626290650446
Validation loss: 2.5350144272975594

Epoch: 6| Step: 6
Training loss: 0.06167541382801153
Validation loss: 2.5418706896424923

Epoch: 6| Step: 7
Training loss: 0.09331131659828555
Validation loss: 2.5296748638543707

Epoch: 6| Step: 8
Training loss: 0.1560650923486519
Validation loss: 2.5547390229184246

Epoch: 6| Step: 9
Training loss: 0.09700315961871868
Validation loss: 2.5247965352303527

Epoch: 6| Step: 10
Training loss: 0.1737636221461625
Validation loss: 2.517176399474589

Epoch: 6| Step: 11
Training loss: 0.12694530462973627
Validation loss: 2.53928466935526

Epoch: 6| Step: 12
Training loss: 0.2033758814909248
Validation loss: 2.4985680114198994

Epoch: 6| Step: 13
Training loss: 0.2394909870775284
Validation loss: 2.495536819482544

Epoch: 589| Step: 0
Training loss: 0.16992596369241797
Validation loss: 2.4752247770960354

Epoch: 6| Step: 1
Training loss: 0.10030934813856894
Validation loss: 2.4973212488080345

Epoch: 6| Step: 2
Training loss: 0.13978405349592818
Validation loss: 2.511920471567738

Epoch: 6| Step: 3
Training loss: 0.21401795424977463
Validation loss: 2.51710352259507

Epoch: 6| Step: 4
Training loss: 0.07778084171252378
Validation loss: 2.538056106971924

Epoch: 6| Step: 5
Training loss: 0.15329500463291673
Validation loss: 2.5605084613552327

Epoch: 6| Step: 6
Training loss: 0.2052487798630136
Validation loss: 2.535645691419306

Epoch: 6| Step: 7
Training loss: 0.07983808186132989
Validation loss: 2.5758308691786245

Epoch: 6| Step: 8
Training loss: 0.13526043376939637
Validation loss: 2.5707437723397386

Epoch: 6| Step: 9
Training loss: 0.2181366598461424
Validation loss: 2.606111031145604

Epoch: 6| Step: 10
Training loss: 0.22989682176760906
Validation loss: 2.5340807971607364

Epoch: 6| Step: 11
Training loss: 0.11261873287843531
Validation loss: 2.5510206139905343

Epoch: 6| Step: 12
Training loss: 0.18751498003564962
Validation loss: 2.534748586069072

Epoch: 6| Step: 13
Training loss: 0.1111158304362937
Validation loss: 2.497297092283754

Epoch: 590| Step: 0
Training loss: 0.10778153638284606
Validation loss: 2.510665483636402

Epoch: 6| Step: 1
Training loss: 0.11956506699549786
Validation loss: 2.5098492632978324

Epoch: 6| Step: 2
Training loss: 0.13206524157442837
Validation loss: 2.503491005931283

Epoch: 6| Step: 3
Training loss: 0.22688512193678675
Validation loss: 2.5300706136118736

Epoch: 6| Step: 4
Training loss: 0.10989256150752252
Validation loss: 2.5085792528336266

Epoch: 6| Step: 5
Training loss: 0.17086744844944246
Validation loss: 2.480848632331252

Epoch: 6| Step: 6
Training loss: 0.22746449996566676
Validation loss: 2.5052183740009695

Epoch: 6| Step: 7
Training loss: 0.1286805300763455
Validation loss: 2.488142977693579

Epoch: 6| Step: 8
Training loss: 0.2035649011158194
Validation loss: 2.4746420272541703

Epoch: 6| Step: 9
Training loss: 0.14645403865764045
Validation loss: 2.4739435121430158

Epoch: 6| Step: 10
Training loss: 0.10707341376499518
Validation loss: 2.5258268479163464

Epoch: 6| Step: 11
Training loss: 0.1718003533563294
Validation loss: 2.5154077090465172

Epoch: 6| Step: 12
Training loss: 0.10358484221259937
Validation loss: 2.547849088763439

Epoch: 6| Step: 13
Training loss: 0.239032764081415
Validation loss: 2.5544126574203165

Epoch: 591| Step: 0
Training loss: 0.1308598376023955
Validation loss: 2.579558419557115

Epoch: 6| Step: 1
Training loss: 0.14641766618658145
Validation loss: 2.5862251877388367

Epoch: 6| Step: 2
Training loss: 0.19389482015694312
Validation loss: 2.606902950547689

Epoch: 6| Step: 3
Training loss: 0.15155165107478022
Validation loss: 2.5874104936973352

Epoch: 6| Step: 4
Training loss: 0.19865267868996403
Validation loss: 2.591416731893991

Epoch: 6| Step: 5
Training loss: 0.1817550401375757
Validation loss: 2.5818508080737708

Epoch: 6| Step: 6
Training loss: 0.20651105990476035
Validation loss: 2.5557188142713074

Epoch: 6| Step: 7
Training loss: 0.13671558240218307
Validation loss: 2.5681353495618766

Epoch: 6| Step: 8
Training loss: 0.12891353962256283
Validation loss: 2.513013136682589

Epoch: 6| Step: 9
Training loss: 0.26362297169740284
Validation loss: 2.541274677135793

Epoch: 6| Step: 10
Training loss: 0.20731298602199308
Validation loss: 2.5107415758796847

Epoch: 6| Step: 11
Training loss: 0.10591237933594227
Validation loss: 2.5438613964363874

Epoch: 6| Step: 12
Training loss: 0.1861404661544395
Validation loss: 2.5280324929357016

Epoch: 6| Step: 13
Training loss: 0.24400997480734463
Validation loss: 2.515659386816293

Epoch: 592| Step: 0
Training loss: 0.1386771805513925
Validation loss: 2.508464154183083

Epoch: 6| Step: 1
Training loss: 0.2177758836822658
Validation loss: 2.553152194442931

Epoch: 6| Step: 2
Training loss: 0.11048650508516392
Validation loss: 2.554005798622734

Epoch: 6| Step: 3
Training loss: 0.19480274435833164
Validation loss: 2.5337480306278506

Epoch: 6| Step: 4
Training loss: 0.1408064122422712
Validation loss: 2.5222397703573707

Epoch: 6| Step: 5
Training loss: 0.24043395893135938
Validation loss: 2.5471589864787014

Epoch: 6| Step: 6
Training loss: 0.15657050520595395
Validation loss: 2.52796146337398

Epoch: 6| Step: 7
Training loss: 0.12172407256157185
Validation loss: 2.5236190201818802

Epoch: 6| Step: 8
Training loss: 0.11937627001531195
Validation loss: 2.545132423703093

Epoch: 6| Step: 9
Training loss: 0.1592561210652911
Validation loss: 2.5553812639960136

Epoch: 6| Step: 10
Training loss: 0.15220971201921366
Validation loss: 2.5613940528819747

Epoch: 6| Step: 11
Training loss: 0.177018158269496
Validation loss: 2.54904713305626

Epoch: 6| Step: 12
Training loss: 0.3200571158592596
Validation loss: 2.585589285889298

Epoch: 6| Step: 13
Training loss: 0.1239570980918737
Validation loss: 2.567971661323251

Epoch: 593| Step: 0
Training loss: 0.14766813714755178
Validation loss: 2.5480110608645425

Epoch: 6| Step: 1
Training loss: 0.19804166414527188
Validation loss: 2.5604138750478116

Epoch: 6| Step: 2
Training loss: 0.19541055125473492
Validation loss: 2.5911063163383594

Epoch: 6| Step: 3
Training loss: 0.21593398125813731
Validation loss: 2.5675270678701

Epoch: 6| Step: 4
Training loss: 0.23898407204375904
Validation loss: 2.5582186295784997

Epoch: 6| Step: 5
Training loss: 0.21344684418404858
Validation loss: 2.5857473368613686

Epoch: 6| Step: 6
Training loss: 0.2542349961288298
Validation loss: 2.6282439562421986

Epoch: 6| Step: 7
Training loss: 0.1553530339091493
Validation loss: 2.6580983737173987

Epoch: 6| Step: 8
Training loss: 0.1793483975917144
Validation loss: 2.6663982422256254

Epoch: 6| Step: 9
Training loss: 0.16993894162466214
Validation loss: 2.629111941224877

Epoch: 6| Step: 10
Training loss: 0.12598377768975677
Validation loss: 2.6463642965098195

Epoch: 6| Step: 11
Training loss: 0.18404109712199798
Validation loss: 2.6193633946051156

Epoch: 6| Step: 12
Training loss: 0.2520645545764125
Validation loss: 2.6059999519262327

Epoch: 6| Step: 13
Training loss: 0.07878640168481481
Validation loss: 2.572984571400712

Epoch: 594| Step: 0
Training loss: 0.1689033290758689
Validation loss: 2.5032693937588775

Epoch: 6| Step: 1
Training loss: 0.21427221571464478
Validation loss: 2.447736555362312

Epoch: 6| Step: 2
Training loss: 0.19721517767622815
Validation loss: 2.4635405587400663

Epoch: 6| Step: 3
Training loss: 0.3515290880220695
Validation loss: 2.457023407871917

Epoch: 6| Step: 4
Training loss: 0.1588403149855721
Validation loss: 2.5220012727061385

Epoch: 6| Step: 5
Training loss: 0.13476190009014116
Validation loss: 2.5728527703998414

Epoch: 6| Step: 6
Training loss: 0.23608712447720234
Validation loss: 2.5811460373599124

Epoch: 6| Step: 7
Training loss: 0.15469965694321025
Validation loss: 2.58177425868015

Epoch: 6| Step: 8
Training loss: 0.2385390325606278
Validation loss: 2.6260212260980422

Epoch: 6| Step: 9
Training loss: 0.1918605356946342
Validation loss: 2.6465682763645355

Epoch: 6| Step: 10
Training loss: 0.17590391859155338
Validation loss: 2.6435057737766483

Epoch: 6| Step: 11
Training loss: 0.13022430957692455
Validation loss: 2.652589808458737

Epoch: 6| Step: 12
Training loss: 0.1645227063053765
Validation loss: 2.6385407891965995

Epoch: 6| Step: 13
Training loss: 0.22804480736982102
Validation loss: 2.6122323044815614

Epoch: 595| Step: 0
Training loss: 0.15668726771260996
Validation loss: 2.5864279645939288

Epoch: 6| Step: 1
Training loss: 0.22971789035732276
Validation loss: 2.579975776194567

Epoch: 6| Step: 2
Training loss: 0.16790782577638558
Validation loss: 2.5830079822178504

Epoch: 6| Step: 3
Training loss: 0.18761432659025773
Validation loss: 2.5468149485737936

Epoch: 6| Step: 4
Training loss: 0.2103743453160127
Validation loss: 2.532746652772276

Epoch: 6| Step: 5
Training loss: 0.10583806280850597
Validation loss: 2.5088215677757675

Epoch: 6| Step: 6
Training loss: 0.2049427766571426
Validation loss: 2.534746466177163

Epoch: 6| Step: 7
Training loss: 0.2723863287605347
Validation loss: 2.5109103090257534

Epoch: 6| Step: 8
Training loss: 0.160524903485531
Validation loss: 2.5603211206232572

Epoch: 6| Step: 9
Training loss: 0.2075341253197773
Validation loss: 2.529564474930708

Epoch: 6| Step: 10
Training loss: 0.11750535772668709
Validation loss: 2.5698901314192066

Epoch: 6| Step: 11
Training loss: 0.12672069252914742
Validation loss: 2.5778387687050106

Epoch: 6| Step: 12
Training loss: 0.19460362539599646
Validation loss: 2.584151580688523

Epoch: 6| Step: 13
Training loss: 0.08254239651508402
Validation loss: 2.5754300676781003

Epoch: 596| Step: 0
Training loss: 0.10999502548029032
Validation loss: 2.5288963115663776

Epoch: 6| Step: 1
Training loss: 0.14792066241853583
Validation loss: 2.558324192166135

Epoch: 6| Step: 2
Training loss: 0.11089037277012391
Validation loss: 2.594141748078335

Epoch: 6| Step: 3
Training loss: 0.19475218509616146
Validation loss: 2.569888948303066

Epoch: 6| Step: 4
Training loss: 0.1737256712570073
Validation loss: 2.589492298118925

Epoch: 6| Step: 5
Training loss: 0.13278068133282017
Validation loss: 2.5773026483262638

Epoch: 6| Step: 6
Training loss: 0.20678422693903106
Validation loss: 2.556519437232908

Epoch: 6| Step: 7
Training loss: 0.19970669548174325
Validation loss: 2.5619244933437946

Epoch: 6| Step: 8
Training loss: 0.1566589606343744
Validation loss: 2.5472453950432588

Epoch: 6| Step: 9
Training loss: 0.14991921693354884
Validation loss: 2.5206811011965016

Epoch: 6| Step: 10
Training loss: 0.19780785095633432
Validation loss: 2.49313804307267

Epoch: 6| Step: 11
Training loss: 0.23091318629682248
Validation loss: 2.5014616615708634

Epoch: 6| Step: 12
Training loss: 0.2397182549436826
Validation loss: 2.5339674927096456

Epoch: 6| Step: 13
Training loss: 0.10848607567271817
Validation loss: 2.4906007556154983

Epoch: 597| Step: 0
Training loss: 0.15744059666703597
Validation loss: 2.5241340933713836

Epoch: 6| Step: 1
Training loss: 0.15079298319649886
Validation loss: 2.529647998777185

Epoch: 6| Step: 2
Training loss: 0.1292890586680145
Validation loss: 2.530462156333656

Epoch: 6| Step: 3
Training loss: 0.2701106133422958
Validation loss: 2.546774757476528

Epoch: 6| Step: 4
Training loss: 0.1613378780455729
Validation loss: 2.569526645735331

Epoch: 6| Step: 5
Training loss: 0.16616955521026502
Validation loss: 2.559915385152155

Epoch: 6| Step: 6
Training loss: 0.21013626053199339
Validation loss: 2.566291507214866

Epoch: 6| Step: 7
Training loss: 0.14742326571036504
Validation loss: 2.5653454239190276

Epoch: 6| Step: 8
Training loss: 0.16341554147753473
Validation loss: 2.581040299195119

Epoch: 6| Step: 9
Training loss: 0.10382385967038545
Validation loss: 2.6037738810646722

Epoch: 6| Step: 10
Training loss: 0.17164382777049597
Validation loss: 2.5937664116959076

Epoch: 6| Step: 11
Training loss: 0.15024469156694237
Validation loss: 2.5973075450690795

Epoch: 6| Step: 12
Training loss: 0.14660929122055638
Validation loss: 2.598951863785479

Epoch: 6| Step: 13
Training loss: 0.23098758713133125
Validation loss: 2.6024890006063246

Epoch: 598| Step: 0
Training loss: 0.09050423472235095
Validation loss: 2.6247875051438556

Epoch: 6| Step: 1
Training loss: 0.14172064279429947
Validation loss: 2.583734336980301

Epoch: 6| Step: 2
Training loss: 0.10656622485113962
Validation loss: 2.613141869089335

Epoch: 6| Step: 3
Training loss: 0.1300805171826776
Validation loss: 2.600092239770943

Epoch: 6| Step: 4
Training loss: 0.14181774343142048
Validation loss: 2.5754066980416948

Epoch: 6| Step: 5
Training loss: 0.18693124419100762
Validation loss: 2.549859721929656

Epoch: 6| Step: 6
Training loss: 0.14147254064430767
Validation loss: 2.5321682887691113

Epoch: 6| Step: 7
Training loss: 0.1979464594268062
Validation loss: 2.5282341489415283

Epoch: 6| Step: 8
Training loss: 0.10399493326513201
Validation loss: 2.5687430800222537

Epoch: 6| Step: 9
Training loss: 0.2200801970601335
Validation loss: 2.545665132247381

Epoch: 6| Step: 10
Training loss: 0.1052587856365808
Validation loss: 2.5681883840303983

Epoch: 6| Step: 11
Training loss: 0.13979615888138222
Validation loss: 2.5104132592561865

Epoch: 6| Step: 12
Training loss: 0.22602315536122242
Validation loss: 2.527599392729489

Epoch: 6| Step: 13
Training loss: 0.0854689411835912
Validation loss: 2.5538100715572414

Epoch: 599| Step: 0
Training loss: 0.16536144506425213
Validation loss: 2.568030173804263

Epoch: 6| Step: 1
Training loss: 0.10948342245691184
Validation loss: 2.5652304877736265

Epoch: 6| Step: 2
Training loss: 0.19301793749558924
Validation loss: 2.610584529135929

Epoch: 6| Step: 3
Training loss: 0.087830008690679
Validation loss: 2.587093259438571

Epoch: 6| Step: 4
Training loss: 0.1653232047107107
Validation loss: 2.5559775346797733

Epoch: 6| Step: 5
Training loss: 0.12692089405265414
Validation loss: 2.5602244356080512

Epoch: 6| Step: 6
Training loss: 0.13359752225848223
Validation loss: 2.5674791930005063

Epoch: 6| Step: 7
Training loss: 0.15447378278015972
Validation loss: 2.544506498422173

Epoch: 6| Step: 8
Training loss: 0.2178566093879395
Validation loss: 2.5331396364287757

Epoch: 6| Step: 9
Training loss: 0.14902421793602086
Validation loss: 2.5162000407163716

Epoch: 6| Step: 10
Training loss: 0.11805298999572962
Validation loss: 2.5406380772101143

Epoch: 6| Step: 11
Training loss: 0.13689367139744624
Validation loss: 2.491032283831541

Epoch: 6| Step: 12
Training loss: 0.1062352093050727
Validation loss: 2.5456927014060735

Epoch: 6| Step: 13
Training loss: 0.20608641393762533
Validation loss: 2.538287026090245

Epoch: 600| Step: 0
Training loss: 0.17592439121581724
Validation loss: 2.541881269966749

Epoch: 6| Step: 1
Training loss: 0.23387602301811694
Validation loss: 2.569030864089448

Epoch: 6| Step: 2
Training loss: 0.19755072811381624
Validation loss: 2.5007926812232806

Epoch: 6| Step: 3
Training loss: 0.09588557485335668
Validation loss: 2.5405770630273303

Epoch: 6| Step: 4
Training loss: 0.1495835209710725
Validation loss: 2.561070640567846

Epoch: 6| Step: 5
Training loss: 0.18815477602903558
Validation loss: 2.61452486680198

Epoch: 6| Step: 6
Training loss: 0.1381332454011178
Validation loss: 2.5958058921698632

Epoch: 6| Step: 7
Training loss: 0.16802859903478812
Validation loss: 2.5787384516510543

Epoch: 6| Step: 8
Training loss: 0.07585867657521624
Validation loss: 2.6104024016784204

Epoch: 6| Step: 9
Training loss: 0.25985684621613925
Validation loss: 2.6273718786261395

Epoch: 6| Step: 10
Training loss: 0.15734650201294348
Validation loss: 2.58920012077537

Epoch: 6| Step: 11
Training loss: 0.10904378211858962
Validation loss: 2.572168100252585

Epoch: 6| Step: 12
Training loss: 0.16888443175137502
Validation loss: 2.538920285617702

Epoch: 6| Step: 13
Training loss: 0.12286766944301253
Validation loss: 2.557346017024927

Testing loss: 2.6285456109786436
