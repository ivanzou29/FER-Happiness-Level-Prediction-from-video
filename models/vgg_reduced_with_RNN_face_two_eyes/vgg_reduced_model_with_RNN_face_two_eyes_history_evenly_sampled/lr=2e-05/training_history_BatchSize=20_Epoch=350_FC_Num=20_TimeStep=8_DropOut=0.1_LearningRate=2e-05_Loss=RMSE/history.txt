Epoch: 1| Step: 0
Training loss: 6.178550953283805
Validation loss: 5.7818708153541145

Epoch: 5| Step: 1
Training loss: 5.723907313120926
Validation loss: 5.761238436359681

Epoch: 5| Step: 2
Training loss: 5.222536826070086
Validation loss: 5.739933052468642

Epoch: 5| Step: 3
Training loss: 6.0180430915179715
Validation loss: 5.716879972129764

Epoch: 5| Step: 4
Training loss: 5.4188229108258925
Validation loss: 5.691268125208135

Epoch: 5| Step: 5
Training loss: 5.702125608068917
Validation loss: 5.6620388545249645

Epoch: 5| Step: 6
Training loss: 5.510863585878188
Validation loss: 5.628864247155115

Epoch: 5| Step: 7
Training loss: 5.3914716415076915
Validation loss: 5.592010234829324

Epoch: 5| Step: 8
Training loss: 5.938008818658722
Validation loss: 5.55040971255658

Epoch: 5| Step: 9
Training loss: 6.241523182148792
Validation loss: 5.504463217633355

Epoch: 5| Step: 10
Training loss: 4.893483262082266
Validation loss: 5.454586605234997

Epoch: 2| Step: 0
Training loss: 5.969066032311563
Validation loss: 5.402272416330318

Epoch: 5| Step: 1
Training loss: 4.8305188019251055
Validation loss: 5.347839630853119

Epoch: 5| Step: 2
Training loss: 5.613783270381171
Validation loss: 5.294050324958525

Epoch: 5| Step: 3
Training loss: 5.630801621007581
Validation loss: 5.23966223521694

Epoch: 5| Step: 4
Training loss: 5.256549383067373
Validation loss: 5.1870832576064405

Epoch: 5| Step: 5
Training loss: 4.958979567187016
Validation loss: 5.131738526107147

Epoch: 5| Step: 6
Training loss: 5.608540167355307
Validation loss: 5.078012619352669

Epoch: 5| Step: 7
Training loss: 4.914894215560136
Validation loss: 5.018324902647355

Epoch: 5| Step: 8
Training loss: 4.428482995270987
Validation loss: 4.959392110210152

Epoch: 5| Step: 9
Training loss: 4.908066140087523
Validation loss: 4.90193742408953

Epoch: 5| Step: 10
Training loss: 4.785656064458159
Validation loss: 4.8467469300535955

Epoch: 3| Step: 0
Training loss: 4.842428507043258
Validation loss: 4.795516351553539

Epoch: 5| Step: 1
Training loss: 4.166805087015556
Validation loss: 4.748781420317068

Epoch: 5| Step: 2
Training loss: 4.9570795392028355
Validation loss: 4.709563169921173

Epoch: 5| Step: 3
Training loss: 4.929153534373796
Validation loss: 4.674769744721546

Epoch: 5| Step: 4
Training loss: 4.865090887587037
Validation loss: 4.641575268769241

Epoch: 5| Step: 5
Training loss: 3.688297767335526
Validation loss: 4.6067246158982575

Epoch: 5| Step: 6
Training loss: 4.666006427562618
Validation loss: 4.573962886482011

Epoch: 5| Step: 7
Training loss: 4.769950129730111
Validation loss: 4.536579464683904

Epoch: 5| Step: 8
Training loss: 5.463128737660138
Validation loss: 4.4954883377418255

Epoch: 5| Step: 9
Training loss: 5.116759956495182
Validation loss: 4.460791975506458

Epoch: 5| Step: 10
Training loss: 3.8720906318429655
Validation loss: 4.4385515971960645

Epoch: 4| Step: 0
Training loss: 5.070228235047092
Validation loss: 4.420479987835297

Epoch: 5| Step: 1
Training loss: 4.563055971316074
Validation loss: 4.399660867988019

Epoch: 5| Step: 2
Training loss: 4.643027765681112
Validation loss: 4.379123943847117

Epoch: 5| Step: 3
Training loss: 3.6652522971625663
Validation loss: 4.351337245799859

Epoch: 5| Step: 4
Training loss: 4.739704820801616
Validation loss: 4.329245057857428

Epoch: 5| Step: 5
Training loss: 3.870961699942519
Validation loss: 4.309441172286652

Epoch: 5| Step: 6
Training loss: 4.1413861420853335
Validation loss: 4.290372058084417

Epoch: 5| Step: 7
Training loss: 5.214120055999288
Validation loss: 4.271039484882714

Epoch: 5| Step: 8
Training loss: 4.218938300557515
Validation loss: 4.253937804932791

Epoch: 5| Step: 9
Training loss: 4.359265616627254
Validation loss: 4.234873125391586

Epoch: 5| Step: 10
Training loss: 4.087812237960822
Validation loss: 4.218372053674594

Epoch: 5| Step: 0
Training loss: 4.320836509671541
Validation loss: 4.198032604829182

Epoch: 5| Step: 1
Training loss: 4.10120627173284
Validation loss: 4.181619783002312

Epoch: 5| Step: 2
Training loss: 4.431455551997129
Validation loss: 4.165986714821595

Epoch: 5| Step: 3
Training loss: 4.8572732483167425
Validation loss: 4.150079427770246

Epoch: 5| Step: 4
Training loss: 4.721595159048186
Validation loss: 4.133404782802708

Epoch: 5| Step: 5
Training loss: 4.436831141823485
Validation loss: 4.119492648846884

Epoch: 5| Step: 6
Training loss: 4.395081779752
Validation loss: 4.104592808338154

Epoch: 5| Step: 7
Training loss: 2.4161092729235727
Validation loss: 4.093495637615274

Epoch: 5| Step: 8
Training loss: 4.475759064640535
Validation loss: 4.087352531738041

Epoch: 5| Step: 9
Training loss: 4.231986522948758
Validation loss: 4.07396032006349

Epoch: 5| Step: 10
Training loss: 4.049718616270972
Validation loss: 4.061489795570664

Epoch: 6| Step: 0
Training loss: 3.4668473532856745
Validation loss: 4.051173206340411

Epoch: 5| Step: 1
Training loss: 3.6745582678391586
Validation loss: 4.041052905005173

Epoch: 5| Step: 2
Training loss: 4.220919581012531
Validation loss: 4.027692828745923

Epoch: 5| Step: 3
Training loss: 4.011360011269825
Validation loss: 4.020216592582001

Epoch: 5| Step: 4
Training loss: 3.4638298813451294
Validation loss: 4.008944012845048

Epoch: 5| Step: 5
Training loss: 4.446312334354593
Validation loss: 3.9945135098217177

Epoch: 5| Step: 6
Training loss: 4.6841516361335875
Validation loss: 3.9813974371834773

Epoch: 5| Step: 7
Training loss: 4.907426243605276
Validation loss: 3.9707384090123874

Epoch: 5| Step: 8
Training loss: 4.048501177706223
Validation loss: 3.9586373700839377

Epoch: 5| Step: 9
Training loss: 4.460546473052022
Validation loss: 3.946751435273558

Epoch: 5| Step: 10
Training loss: 3.917374783616255
Validation loss: 3.93548849552057

Epoch: 7| Step: 0
Training loss: 3.6977198302128063
Validation loss: 3.9248328895021927

Epoch: 5| Step: 1
Training loss: 3.749770856850034
Validation loss: 3.9142161033736915

Epoch: 5| Step: 2
Training loss: 3.751549591334583
Validation loss: 3.90114266510593

Epoch: 5| Step: 3
Training loss: 4.937455575477561
Validation loss: 3.889665766338461

Epoch: 5| Step: 4
Training loss: 4.118134767836581
Validation loss: 3.881704042855904

Epoch: 5| Step: 5
Training loss: 4.003041303297197
Validation loss: 3.867162486575827

Epoch: 5| Step: 6
Training loss: 3.375774577230662
Validation loss: 3.8527876848386318

Epoch: 5| Step: 7
Training loss: 4.560090147097775
Validation loss: 3.837483070408074

Epoch: 5| Step: 8
Training loss: 3.9427975334179117
Validation loss: 3.8170674750930713

Epoch: 5| Step: 9
Training loss: 3.919224181378111
Validation loss: 3.8039026676602945

Epoch: 5| Step: 10
Training loss: 4.047143640033846
Validation loss: 3.786063147741051

Epoch: 8| Step: 0
Training loss: 3.210442794967433
Validation loss: 3.767667138782276

Epoch: 5| Step: 1
Training loss: 4.4458470886265555
Validation loss: 3.7540531527294374

Epoch: 5| Step: 2
Training loss: 3.931577679148687
Validation loss: 3.735168855946564

Epoch: 5| Step: 3
Training loss: 4.282165429473838
Validation loss: 3.7268439326998375

Epoch: 5| Step: 4
Training loss: 4.433448123640859
Validation loss: 3.7091945428441435

Epoch: 5| Step: 5
Training loss: 3.3745631182441485
Validation loss: 3.6929638752480525

Epoch: 5| Step: 6
Training loss: 3.7882862043043497
Validation loss: 3.678376985918323

Epoch: 5| Step: 7
Training loss: 4.194423133734207
Validation loss: 3.6590552396690534

Epoch: 5| Step: 8
Training loss: 4.111448279865358
Validation loss: 3.6354618724933356

Epoch: 5| Step: 9
Training loss: 3.6326011678282044
Validation loss: 3.613018147502016

Epoch: 5| Step: 10
Training loss: 2.713827653825491
Validation loss: 3.6071486908383843

Epoch: 9| Step: 0
Training loss: 3.3737640943653293
Validation loss: 3.664999672876922

Epoch: 5| Step: 1
Training loss: 3.597846441387974
Validation loss: 3.6130582343855995

Epoch: 5| Step: 2
Training loss: 2.975362380580955
Validation loss: 3.611478345659774

Epoch: 5| Step: 3
Training loss: 4.589522512029736
Validation loss: 3.6194689473650863

Epoch: 5| Step: 4
Training loss: 3.4929541102686805
Validation loss: 3.5937060253133297

Epoch: 5| Step: 5
Training loss: 3.755746380499326
Validation loss: 3.588292181067492

Epoch: 5| Step: 6
Training loss: 4.410450765880054
Validation loss: 3.5592932625885885

Epoch: 5| Step: 7
Training loss: 3.6758607699704187
Validation loss: 3.5492608785825794

Epoch: 5| Step: 8
Training loss: 3.9955209450170965
Validation loss: 3.545858655606606

Epoch: 5| Step: 9
Training loss: 3.5782902442056517
Validation loss: 3.535710649264011

Epoch: 5| Step: 10
Training loss: 3.865626411160186
Validation loss: 3.5221946901324284

Epoch: 10| Step: 0
Training loss: 4.496692713687263
Validation loss: 3.476532891518309

Epoch: 5| Step: 1
Training loss: 2.9583329393270166
Validation loss: 3.455092468419299

Epoch: 5| Step: 2
Training loss: 3.2675642616356386
Validation loss: 3.4620789161638656

Epoch: 5| Step: 3
Training loss: 3.4486196825017648
Validation loss: 3.4667290917598255

Epoch: 5| Step: 4
Training loss: 3.233555049438847
Validation loss: 3.452083145575197

Epoch: 5| Step: 5
Training loss: 3.060529736809865
Validation loss: 3.443993393725112

Epoch: 5| Step: 6
Training loss: 4.192900861343688
Validation loss: 3.4318487106942617

Epoch: 5| Step: 7
Training loss: 3.863858232910566
Validation loss: 3.416707263488251

Epoch: 5| Step: 8
Training loss: 3.932204181969539
Validation loss: 3.403463291889935

Epoch: 5| Step: 9
Training loss: 4.082259731195389
Validation loss: 3.390687555845899

Epoch: 5| Step: 10
Training loss: 3.264690356680094
Validation loss: 3.3745850961652812

Epoch: 11| Step: 0
Training loss: 3.8157552361034095
Validation loss: 3.366142307734504

Epoch: 5| Step: 1
Training loss: 4.18199684304219
Validation loss: 3.3654747886841947

Epoch: 5| Step: 2
Training loss: 3.064344512395663
Validation loss: 3.357200389950939

Epoch: 5| Step: 3
Training loss: 3.0585288945869773
Validation loss: 3.3459699221561046

Epoch: 5| Step: 4
Training loss: 4.101161159679783
Validation loss: 3.3351466266453453

Epoch: 5| Step: 5
Training loss: 4.311049728896044
Validation loss: 3.324293057465173

Epoch: 5| Step: 6
Training loss: 2.8882872329909968
Validation loss: 3.3187228319335937

Epoch: 5| Step: 7
Training loss: 3.3045615314256183
Validation loss: 3.31814024426469

Epoch: 5| Step: 8
Training loss: 3.668925167756448
Validation loss: 3.3221346834839327

Epoch: 5| Step: 9
Training loss: 3.054268654598893
Validation loss: 3.3054439769083186

Epoch: 5| Step: 10
Training loss: 3.4795972972564253
Validation loss: 3.2940074987420473

Epoch: 12| Step: 0
Training loss: 4.379939751058271
Validation loss: 3.2985284210243444

Epoch: 5| Step: 1
Training loss: 2.647734242019679
Validation loss: 3.286719006651191

Epoch: 5| Step: 2
Training loss: 3.9113127592031267
Validation loss: 3.29028243283279

Epoch: 5| Step: 3
Training loss: 3.5806060584897845
Validation loss: 3.2772696124143224

Epoch: 5| Step: 4
Training loss: 2.8486214298495587
Validation loss: 3.266160561011758

Epoch: 5| Step: 5
Training loss: 3.5998252932223855
Validation loss: 3.2557003949123167

Epoch: 5| Step: 6
Training loss: 4.086604747666143
Validation loss: 3.2559511506510317

Epoch: 5| Step: 7
Training loss: 3.007652377535788
Validation loss: 3.25054217029323

Epoch: 5| Step: 8
Training loss: 3.0889048542399884
Validation loss: 3.2514360456200624

Epoch: 5| Step: 9
Training loss: 3.381942531438065
Validation loss: 3.2388984508316154

Epoch: 5| Step: 10
Training loss: 3.7613929615381054
Validation loss: 3.232820668144753

Epoch: 13| Step: 0
Training loss: 3.88066978356252
Validation loss: 3.219876638671158

Epoch: 5| Step: 1
Training loss: 3.3661450677574045
Validation loss: 3.211670165633465

Epoch: 5| Step: 2
Training loss: 2.8885895031887325
Validation loss: 3.204406328331545

Epoch: 5| Step: 3
Training loss: 3.595283778082933
Validation loss: 3.2007371839737253

Epoch: 5| Step: 4
Training loss: 4.043650870899051
Validation loss: 3.1951331379033516

Epoch: 5| Step: 5
Training loss: 3.25514723249948
Validation loss: 3.186362858129616

Epoch: 5| Step: 6
Training loss: 3.5969688264091446
Validation loss: 3.178099128179907

Epoch: 5| Step: 7
Training loss: 3.4215346911794327
Validation loss: 3.1771542760929323

Epoch: 5| Step: 8
Training loss: 3.6500371330149086
Validation loss: 3.171441423222725

Epoch: 5| Step: 9
Training loss: 2.764723291330348
Validation loss: 3.164216308420398

Epoch: 5| Step: 10
Training loss: 3.268328847796137
Validation loss: 3.158687714618009

Epoch: 14| Step: 0
Training loss: 3.362172793666354
Validation loss: 3.1547258600505867

Epoch: 5| Step: 1
Training loss: 3.897109178054768
Validation loss: 3.148707447547142

Epoch: 5| Step: 2
Training loss: 3.3538287132714255
Validation loss: 3.136689335230478

Epoch: 5| Step: 3
Training loss: 3.0921580524786876
Validation loss: 3.137062369921204

Epoch: 5| Step: 4
Training loss: 3.554955373878287
Validation loss: 3.137036021306243

Epoch: 5| Step: 5
Training loss: 3.2587334591263204
Validation loss: 3.1333543310288747

Epoch: 5| Step: 6
Training loss: 3.307253875917007
Validation loss: 3.12988467837549

Epoch: 5| Step: 7
Training loss: 2.9701448075156716
Validation loss: 3.127355348328831

Epoch: 5| Step: 8
Training loss: 4.186784142184437
Validation loss: 3.1215994070790645

Epoch: 5| Step: 9
Training loss: 3.025898249910435
Validation loss: 3.117843374296286

Epoch: 5| Step: 10
Training loss: 3.206858324785581
Validation loss: 3.1141526163144646

Epoch: 15| Step: 0
Training loss: 3.0705072472230093
Validation loss: 3.1107338607268975

Epoch: 5| Step: 1
Training loss: 3.163662958232665
Validation loss: 3.107998223305547

Epoch: 5| Step: 2
Training loss: 3.5535921861599578
Validation loss: 3.102579713088414

Epoch: 5| Step: 3
Training loss: 3.324848406784975
Validation loss: 3.1006556496031346

Epoch: 5| Step: 4
Training loss: 3.0839253106479854
Validation loss: 3.0985393607355607

Epoch: 5| Step: 5
Training loss: 3.6326815017543828
Validation loss: 3.0928804698899968

Epoch: 5| Step: 6
Training loss: 3.6460541285913686
Validation loss: 3.092547019868769

Epoch: 5| Step: 7
Training loss: 3.4611153653769953
Validation loss: 3.0878070203202306

Epoch: 5| Step: 8
Training loss: 3.255317299608499
Validation loss: 3.0860268557701054

Epoch: 5| Step: 9
Training loss: 3.4724074318551295
Validation loss: 3.0832883576026013

Epoch: 5| Step: 10
Training loss: 3.405745022640527
Validation loss: 3.08607721558932

Epoch: 16| Step: 0
Training loss: 2.699173348648109
Validation loss: 3.081031472773081

Epoch: 5| Step: 1
Training loss: 3.3310044418209146
Validation loss: 3.083914562031257

Epoch: 5| Step: 2
Training loss: 3.724737908276442
Validation loss: 3.0782413030731313

Epoch: 5| Step: 3
Training loss: 3.1051244772809317
Validation loss: 3.0753538989036437

Epoch: 5| Step: 4
Training loss: 3.6112628970075984
Validation loss: 3.072140816002987

Epoch: 5| Step: 5
Training loss: 3.1770518483754127
Validation loss: 3.072426430272904

Epoch: 5| Step: 6
Training loss: 3.6621809888831156
Validation loss: 3.0747960601349456

Epoch: 5| Step: 7
Training loss: 3.5278361875516175
Validation loss: 3.0688672169264217

Epoch: 5| Step: 8
Training loss: 3.128961417370243
Validation loss: 3.0641189792797907

Epoch: 5| Step: 9
Training loss: 3.767531422849153
Validation loss: 3.061108999673002

Epoch: 5| Step: 10
Training loss: 2.972313599256347
Validation loss: 3.0640656113111344

Epoch: 17| Step: 0
Training loss: 3.264263982840605
Validation loss: 3.062577161890456

Epoch: 5| Step: 1
Training loss: 3.78594024066141
Validation loss: 3.066975905363335

Epoch: 5| Step: 2
Training loss: 2.5267557819255386
Validation loss: 3.0662450738249283

Epoch: 5| Step: 3
Training loss: 3.0726173039540114
Validation loss: 3.06721245601203

Epoch: 5| Step: 4
Training loss: 3.5003273674589814
Validation loss: 3.0628438207860844

Epoch: 5| Step: 5
Training loss: 2.8448494263610846
Validation loss: 3.0666068497486725

Epoch: 5| Step: 6
Training loss: 3.5202454446703935
Validation loss: 3.0596096704951123

Epoch: 5| Step: 7
Training loss: 3.488943620186326
Validation loss: 3.054898216177007

Epoch: 5| Step: 8
Training loss: 3.7449693633228245
Validation loss: 3.0540567399413345

Epoch: 5| Step: 9
Training loss: 3.7187800045566073
Validation loss: 3.0500366282033022

Epoch: 5| Step: 10
Training loss: 3.021073395409191
Validation loss: 3.04913725187147

Epoch: 18| Step: 0
Training loss: 2.752636425992574
Validation loss: 3.0475151994399132

Epoch: 5| Step: 1
Training loss: 3.296908554701875
Validation loss: 3.048913296301736

Epoch: 5| Step: 2
Training loss: 3.728884823056433
Validation loss: 3.0469404332928605

Epoch: 5| Step: 3
Training loss: 3.7951753053646557
Validation loss: 3.0420364383248293

Epoch: 5| Step: 4
Training loss: 3.2494033852739017
Validation loss: 3.0381161145466558

Epoch: 5| Step: 5
Training loss: 3.6665495218001607
Validation loss: 3.0351274490336126

Epoch: 5| Step: 6
Training loss: 3.484063515190396
Validation loss: 3.0312911499058486

Epoch: 5| Step: 7
Training loss: 2.7688794142399566
Validation loss: 3.0319304426166487

Epoch: 5| Step: 8
Training loss: 3.494379981059067
Validation loss: 3.033900458841664

Epoch: 5| Step: 9
Training loss: 2.98713851720942
Validation loss: 3.0321097102579686

Epoch: 5| Step: 10
Training loss: 3.1707188796558663
Validation loss: 3.0273947777551062

Epoch: 19| Step: 0
Training loss: 3.6753297826495066
Validation loss: 3.0286099018384296

Epoch: 5| Step: 1
Training loss: 3.134196368192275
Validation loss: 3.0226683432543013

Epoch: 5| Step: 2
Training loss: 3.0984409103336312
Validation loss: 3.0203615829433006

Epoch: 5| Step: 3
Training loss: 2.7347591457282014
Validation loss: 3.0199454938135055

Epoch: 5| Step: 4
Training loss: 3.856508866436308
Validation loss: 3.0174793380558826

Epoch: 5| Step: 5
Training loss: 2.802495923681638
Validation loss: 3.0197405718758445

Epoch: 5| Step: 6
Training loss: 3.526257792413182
Validation loss: 3.014362790040171

Epoch: 5| Step: 7
Training loss: 2.77249146565946
Validation loss: 3.0161959301983736

Epoch: 5| Step: 8
Training loss: 3.858218000320937
Validation loss: 3.015147400932957

Epoch: 5| Step: 9
Training loss: 4.030169201652123
Validation loss: 3.012377043634923

Epoch: 5| Step: 10
Training loss: 2.3605863985435938
Validation loss: 3.008930022455342

Epoch: 20| Step: 0
Training loss: 3.515560437775233
Validation loss: 3.0086523308275535

Epoch: 5| Step: 1
Training loss: 3.166917054834583
Validation loss: 3.00591478873261

Epoch: 5| Step: 2
Training loss: 3.182013333516265
Validation loss: 3.00725735528861

Epoch: 5| Step: 3
Training loss: 2.9246716502506374
Validation loss: 3.006057496160672

Epoch: 5| Step: 4
Training loss: 3.268578758641197
Validation loss: 3.004922864601429

Epoch: 5| Step: 5
Training loss: 2.967640880399704
Validation loss: 3.006381432767202

Epoch: 5| Step: 6
Training loss: 3.7659724538224144
Validation loss: 3.002584473857581

Epoch: 5| Step: 7
Training loss: 3.6128785934850076
Validation loss: 3.001040946339978

Epoch: 5| Step: 8
Training loss: 3.5260982236547704
Validation loss: 2.99959961123252

Epoch: 5| Step: 9
Training loss: 2.968573956540281
Validation loss: 3.0018962759958274

Epoch: 5| Step: 10
Training loss: 3.302601112821922
Validation loss: 2.997586167936391

Epoch: 21| Step: 0
Training loss: 3.2159705151587006
Validation loss: 2.9988600246738013

Epoch: 5| Step: 1
Training loss: 3.0607799448587625
Validation loss: 2.993413198990481

Epoch: 5| Step: 2
Training loss: 3.8987718947108596
Validation loss: 2.994325958180551

Epoch: 5| Step: 3
Training loss: 3.4029497029647975
Validation loss: 2.9936514030396713

Epoch: 5| Step: 4
Training loss: 2.872694666867304
Validation loss: 2.9906666254249097

Epoch: 5| Step: 5
Training loss: 3.907324315159033
Validation loss: 2.993346107440671

Epoch: 5| Step: 6
Training loss: 3.0669764286276027
Validation loss: 2.995775019852186

Epoch: 5| Step: 7
Training loss: 2.9727526535062117
Validation loss: 2.9939700903939857

Epoch: 5| Step: 8
Training loss: 3.310295955184836
Validation loss: 2.9942190639242128

Epoch: 5| Step: 9
Training loss: 3.102666009953977
Validation loss: 2.987519775330667

Epoch: 5| Step: 10
Training loss: 3.176022828920891
Validation loss: 2.985296386231184

Epoch: 22| Step: 0
Training loss: 3.0343949825049266
Validation loss: 2.9879210037606616

Epoch: 5| Step: 1
Training loss: 3.1677252020862885
Validation loss: 2.9898741685937336

Epoch: 5| Step: 2
Training loss: 3.727556587879616
Validation loss: 2.9894540470159425

Epoch: 5| Step: 3
Training loss: 2.8338373147362574
Validation loss: 2.9823287402522625

Epoch: 5| Step: 4
Training loss: 3.613043040078605
Validation loss: 2.993428952071875

Epoch: 5| Step: 5
Training loss: 3.6089012198349746
Validation loss: 2.9955092268759005

Epoch: 5| Step: 6
Training loss: 3.058103090882538
Validation loss: 2.9948897641644536

Epoch: 5| Step: 7
Training loss: 2.9035265888082553
Validation loss: 2.9866345525748614

Epoch: 5| Step: 8
Training loss: 3.0227390635867337
Validation loss: 2.9832012314547476

Epoch: 5| Step: 9
Training loss: 3.8369793069583222
Validation loss: 2.9854844109072523

Epoch: 5| Step: 10
Training loss: 3.038291696112153
Validation loss: 2.986042547492092

Epoch: 23| Step: 0
Training loss: 3.553010045912133
Validation loss: 2.9840263107591114

Epoch: 5| Step: 1
Training loss: 2.781575558928223
Validation loss: 2.98150620580157

Epoch: 5| Step: 2
Training loss: 3.240696134310732
Validation loss: 2.987396816689675

Epoch: 5| Step: 3
Training loss: 3.6987725928397492
Validation loss: 2.9889893840941233

Epoch: 5| Step: 4
Training loss: 3.439797483293779
Validation loss: 2.9891720083253297

Epoch: 5| Step: 5
Training loss: 3.0488178025730126
Validation loss: 2.9876551813624346

Epoch: 5| Step: 6
Training loss: 3.201402601174543
Validation loss: 2.9788853444875945

Epoch: 5| Step: 7
Training loss: 3.251484898489455
Validation loss: 2.9716192519463087

Epoch: 5| Step: 8
Training loss: 3.4176202389285706
Validation loss: 2.9687602968582483

Epoch: 5| Step: 9
Training loss: 3.351773342089701
Validation loss: 2.9712275634591094

Epoch: 5| Step: 10
Training loss: 2.7234902985751765
Validation loss: 2.9666441654441056

Epoch: 24| Step: 0
Training loss: 3.3772218243211958
Validation loss: 2.963188331264752

Epoch: 5| Step: 1
Training loss: 2.741938218309027
Validation loss: 2.965882947638537

Epoch: 5| Step: 2
Training loss: 2.6095898933780943
Validation loss: 2.967447902267983

Epoch: 5| Step: 3
Training loss: 2.8561823797255808
Validation loss: 2.97225363976766

Epoch: 5| Step: 4
Training loss: 3.7559366917500197
Validation loss: 2.973562066613516

Epoch: 5| Step: 5
Training loss: 3.526281321432784
Validation loss: 2.963215684129026

Epoch: 5| Step: 6
Training loss: 3.1942775701160175
Validation loss: 2.9612471324208802

Epoch: 5| Step: 7
Training loss: 2.4222359665160886
Validation loss: 2.9588923064129724

Epoch: 5| Step: 8
Training loss: 3.355890782630789
Validation loss: 2.9581249885270227

Epoch: 5| Step: 9
Training loss: 4.103593944472138
Validation loss: 2.955642761525856

Epoch: 5| Step: 10
Training loss: 3.501631220390474
Validation loss: 2.951994006193994

Epoch: 25| Step: 0
Training loss: 2.8696049365836807
Validation loss: 2.950237338351117

Epoch: 5| Step: 1
Training loss: 3.493331824100935
Validation loss: 2.950528201693436

Epoch: 5| Step: 2
Training loss: 2.640157082537172
Validation loss: 2.9501245164046592

Epoch: 5| Step: 3
Training loss: 3.4049171849961533
Validation loss: 2.9525863122286906

Epoch: 5| Step: 4
Training loss: 4.046196958084023
Validation loss: 2.955807314687972

Epoch: 5| Step: 5
Training loss: 2.9942608614454884
Validation loss: 2.9485749694150685

Epoch: 5| Step: 6
Training loss: 3.192319629565556
Validation loss: 2.9507057101537266

Epoch: 5| Step: 7
Training loss: 3.36423683547524
Validation loss: 2.9464515469571593

Epoch: 5| Step: 8
Training loss: 3.0378982157328496
Validation loss: 2.950320363781649

Epoch: 5| Step: 9
Training loss: 3.6374935713773464
Validation loss: 2.9565788784891196

Epoch: 5| Step: 10
Training loss: 2.558955742075013
Validation loss: 2.9489437899501483

Epoch: 26| Step: 0
Training loss: 2.8680523391800015
Validation loss: 2.946707128912734

Epoch: 5| Step: 1
Training loss: 3.6069088391871706
Validation loss: 2.94359135615348

Epoch: 5| Step: 2
Training loss: 3.144483028065813
Validation loss: 2.940778447109806

Epoch: 5| Step: 3
Training loss: 3.1423834437542095
Validation loss: 2.939921475223251

Epoch: 5| Step: 4
Training loss: 2.5152536437980086
Validation loss: 2.936246296775745

Epoch: 5| Step: 5
Training loss: 3.425914592170488
Validation loss: 2.934865370045469

Epoch: 5| Step: 6
Training loss: 3.283956229156328
Validation loss: 2.9357831891209485

Epoch: 5| Step: 7
Training loss: 3.5521869961256733
Validation loss: 2.9367897896161326

Epoch: 5| Step: 8
Training loss: 3.717164799675852
Validation loss: 2.9387508234858344

Epoch: 5| Step: 9
Training loss: 3.288413665635808
Validation loss: 2.937623205766988

Epoch: 5| Step: 10
Training loss: 2.655607617061658
Validation loss: 2.935919082935646

Epoch: 27| Step: 0
Training loss: 3.078660947353535
Validation loss: 2.9322302456015863

Epoch: 5| Step: 1
Training loss: 3.4986460655505276
Validation loss: 2.933635294475216

Epoch: 5| Step: 2
Training loss: 3.5879461775265176
Validation loss: 2.9311893070895016

Epoch: 5| Step: 3
Training loss: 2.929532385216575
Validation loss: 2.929410752217732

Epoch: 5| Step: 4
Training loss: 3.3479952379053812
Validation loss: 2.92766655766615

Epoch: 5| Step: 5
Training loss: 3.2807724378103837
Validation loss: 2.9301899044536284

Epoch: 5| Step: 6
Training loss: 3.3840741278282778
Validation loss: 2.92915477522425

Epoch: 5| Step: 7
Training loss: 3.261932475688629
Validation loss: 2.9250651697009187

Epoch: 5| Step: 8
Training loss: 2.8226367957159817
Validation loss: 2.9269599539673905

Epoch: 5| Step: 9
Training loss: 2.766652148181861
Validation loss: 2.9275264381976176

Epoch: 5| Step: 10
Training loss: 3.399256254641123
Validation loss: 2.9223488079194477

Epoch: 28| Step: 0
Training loss: 3.0620823789511933
Validation loss: 2.9215138977591493

Epoch: 5| Step: 1
Training loss: 3.3462245733002582
Validation loss: 2.9227786103370095

Epoch: 5| Step: 2
Training loss: 3.028140646123472
Validation loss: 2.9200317823068547

Epoch: 5| Step: 3
Training loss: 3.0001401868491198
Validation loss: 2.9212839633124794

Epoch: 5| Step: 4
Training loss: 2.671726066498577
Validation loss: 2.9168797522083487

Epoch: 5| Step: 5
Training loss: 3.5038259575701507
Validation loss: 2.918450098285926

Epoch: 5| Step: 6
Training loss: 2.7313217118754443
Validation loss: 2.9256514046966875

Epoch: 5| Step: 7
Training loss: 3.0512716800305486
Validation loss: 2.9306198235800847

Epoch: 5| Step: 8
Training loss: 3.395156714933424
Validation loss: 2.9284962575900053

Epoch: 5| Step: 9
Training loss: 3.7693041797298097
Validation loss: 2.9305618514937946

Epoch: 5| Step: 10
Training loss: 3.672808719173145
Validation loss: 2.9212164402918033

Epoch: 29| Step: 0
Training loss: 3.3039854489853515
Validation loss: 2.9167949003751654

Epoch: 5| Step: 1
Training loss: 3.4250765938095333
Validation loss: 2.913020445730278

Epoch: 5| Step: 2
Training loss: 3.4188896638840918
Validation loss: 2.912768009928836

Epoch: 5| Step: 3
Training loss: 3.016408077418266
Validation loss: 2.9150612035314385

Epoch: 5| Step: 4
Training loss: 3.28062970792462
Validation loss: 2.9162971373828324

Epoch: 5| Step: 5
Training loss: 2.647328732636001
Validation loss: 2.911249974886757

Epoch: 5| Step: 6
Training loss: 3.036816392118311
Validation loss: 2.907249487877511

Epoch: 5| Step: 7
Training loss: 3.242244857832247
Validation loss: 2.9058442385502556

Epoch: 5| Step: 8
Training loss: 2.7655445669083685
Validation loss: 2.905280677660232

Epoch: 5| Step: 9
Training loss: 3.6380080612202357
Validation loss: 2.907768942867799

Epoch: 5| Step: 10
Training loss: 3.373943446048886
Validation loss: 2.9131232968422003

Epoch: 30| Step: 0
Training loss: 2.808568622757905
Validation loss: 2.9153080150451602

Epoch: 5| Step: 1
Training loss: 3.4917442501313287
Validation loss: 2.935329318584102

Epoch: 5| Step: 2
Training loss: 2.3049620384019605
Validation loss: 2.9433623381111738

Epoch: 5| Step: 3
Training loss: 3.4623833041030063
Validation loss: 2.936171860448873

Epoch: 5| Step: 4
Training loss: 2.9216408049212617
Validation loss: 2.9089859693828575

Epoch: 5| Step: 5
Training loss: 2.949363290642648
Validation loss: 2.8995887560232187

Epoch: 5| Step: 6
Training loss: 3.3553405666181138
Validation loss: 2.9012098498727292

Epoch: 5| Step: 7
Training loss: 3.4893064626296333
Validation loss: 2.9047155494105468

Epoch: 5| Step: 8
Training loss: 3.749624869339145
Validation loss: 2.9122449579860423

Epoch: 5| Step: 9
Training loss: 3.1285645563855127
Validation loss: 2.9035863455927955

Epoch: 5| Step: 10
Training loss: 3.329609141508547
Validation loss: 2.9045931331384653

Epoch: 31| Step: 0
Training loss: 3.142146107511506
Validation loss: 2.9004403560392897

Epoch: 5| Step: 1
Training loss: 4.328407911838894
Validation loss: 2.896695734912362

Epoch: 5| Step: 2
Training loss: 3.953873755670665
Validation loss: 2.8953297444903026

Epoch: 5| Step: 3
Training loss: 3.0619364628693595
Validation loss: 2.893960575746784

Epoch: 5| Step: 4
Training loss: 2.987405406779121
Validation loss: 2.8916259327513334

Epoch: 5| Step: 5
Training loss: 2.8828242438679323
Validation loss: 2.897695582804422

Epoch: 5| Step: 6
Training loss: 2.999435371670496
Validation loss: 2.9125060283033926

Epoch: 5| Step: 7
Training loss: 2.6156799529397587
Validation loss: 2.9515932061066956

Epoch: 5| Step: 8
Training loss: 3.5262523834209643
Validation loss: 3.089799800525131

Epoch: 5| Step: 9
Training loss: 3.0228616328699287
Validation loss: 2.975880577559691

Epoch: 5| Step: 10
Training loss: 2.157920080067946
Validation loss: 2.9425995808349796

Epoch: 32| Step: 0
Training loss: 2.6893748463837412
Validation loss: 2.9362992254493556

Epoch: 5| Step: 1
Training loss: 3.36885585300125
Validation loss: 2.9372606932717393

Epoch: 5| Step: 2
Training loss: 3.6749453430263364
Validation loss: 2.942695526318782

Epoch: 5| Step: 3
Training loss: 2.8486639471644444
Validation loss: 2.924201862258748

Epoch: 5| Step: 4
Training loss: 2.280120151767038
Validation loss: 2.9176461369715336

Epoch: 5| Step: 5
Training loss: 3.034871248785375
Validation loss: 2.9066196664805584

Epoch: 5| Step: 6
Training loss: 3.6630195483519996
Validation loss: 2.8967082756527414

Epoch: 5| Step: 7
Training loss: 3.6220922975960574
Validation loss: 2.9090904586184294

Epoch: 5| Step: 8
Training loss: 3.3090132590357086
Validation loss: 2.9085750076643633

Epoch: 5| Step: 9
Training loss: 2.874886054393222
Validation loss: 2.9086476691325904

Epoch: 5| Step: 10
Training loss: 3.637966642565519
Validation loss: 2.902630507173489

Epoch: 33| Step: 0
Training loss: 2.8235127475424417
Validation loss: 2.8902358298940714

Epoch: 5| Step: 1
Training loss: 3.2418952534419665
Validation loss: 2.887941559095306

Epoch: 5| Step: 2
Training loss: 2.840152686944181
Validation loss: 2.8933912225393663

Epoch: 5| Step: 3
Training loss: 2.948941613117025
Validation loss: 2.909774181928538

Epoch: 5| Step: 4
Training loss: 3.1766396801640524
Validation loss: 2.9517083099936623

Epoch: 5| Step: 5
Training loss: 4.197494649696234
Validation loss: 2.9815448832106157

Epoch: 5| Step: 6
Training loss: 3.339674703324178
Validation loss: 2.9026493981522

Epoch: 5| Step: 7
Training loss: 2.8755515854834472
Validation loss: 2.88436926671838

Epoch: 5| Step: 8
Training loss: 3.3973135657172056
Validation loss: 2.8808257993504287

Epoch: 5| Step: 9
Training loss: 2.3573057688112713
Validation loss: 2.915317612496852

Epoch: 5| Step: 10
Training loss: 3.8223089138692643
Validation loss: 2.955552281138279

Epoch: 34| Step: 0
Training loss: 2.8846687605394536
Validation loss: 2.918342169434395

Epoch: 5| Step: 1
Training loss: 3.167689526314034
Validation loss: 2.8947142124051988

Epoch: 5| Step: 2
Training loss: 3.3748688848952897
Validation loss: 2.886417781355368

Epoch: 5| Step: 3
Training loss: 3.6701340464296677
Validation loss: 2.8737688643166197

Epoch: 5| Step: 4
Training loss: 2.820150439395738
Validation loss: 2.8766618520526035

Epoch: 5| Step: 5
Training loss: 2.3958372254270923
Validation loss: 2.8790933476945058

Epoch: 5| Step: 6
Training loss: 3.2559987972547852
Validation loss: 2.8717188523185606

Epoch: 5| Step: 7
Training loss: 2.989254143608905
Validation loss: 2.8764084339467275

Epoch: 5| Step: 8
Training loss: 3.8703967409048436
Validation loss: 2.886685786014014

Epoch: 5| Step: 9
Training loss: 3.2645732153220646
Validation loss: 2.893607810560759

Epoch: 5| Step: 10
Training loss: 3.1519645075179437
Validation loss: 2.8817606295106795

Epoch: 35| Step: 0
Training loss: 2.9241249275290677
Validation loss: 2.876802937588255

Epoch: 5| Step: 1
Training loss: 2.776281397752327
Validation loss: 2.874584503253736

Epoch: 5| Step: 2
Training loss: 3.006031172752548
Validation loss: 2.868276596605991

Epoch: 5| Step: 3
Training loss: 2.8670354901589645
Validation loss: 2.869872910535986

Epoch: 5| Step: 4
Training loss: 3.696362465214033
Validation loss: 2.8670005651340866

Epoch: 5| Step: 5
Training loss: 3.1831604083428937
Validation loss: 2.8636965551254825

Epoch: 5| Step: 6
Training loss: 2.8784414508822698
Validation loss: 2.863609921510679

Epoch: 5| Step: 7
Training loss: 3.3353012157110977
Validation loss: 2.862351169882528

Epoch: 5| Step: 8
Training loss: 2.919561602460466
Validation loss: 2.8629273228871135

Epoch: 5| Step: 9
Training loss: 3.4803116031880887
Validation loss: 2.8599854961882

Epoch: 5| Step: 10
Training loss: 3.6971093097899006
Validation loss: 2.863341162655106

Epoch: 36| Step: 0
Training loss: 3.504459945495528
Validation loss: 2.856024488160105

Epoch: 5| Step: 1
Training loss: 2.5690976318362715
Validation loss: 2.85816488755945

Epoch: 5| Step: 2
Training loss: 3.4407573179047852
Validation loss: 2.855413870532885

Epoch: 5| Step: 3
Training loss: 2.9802460393528123
Validation loss: 2.8546827182244447

Epoch: 5| Step: 4
Training loss: 3.300380921775667
Validation loss: 2.854366694884941

Epoch: 5| Step: 5
Training loss: 3.416983814561762
Validation loss: 2.8575079367777927

Epoch: 5| Step: 6
Training loss: 2.865713629397203
Validation loss: 2.8542107902860576

Epoch: 5| Step: 7
Training loss: 3.754160670968256
Validation loss: 2.852580777292004

Epoch: 5| Step: 8
Training loss: 2.635478766593007
Validation loss: 2.850249701907563

Epoch: 5| Step: 9
Training loss: 2.9386425636996925
Validation loss: 2.8535043894025405

Epoch: 5| Step: 10
Training loss: 3.1020654995937034
Validation loss: 2.8459117362302813

Epoch: 37| Step: 0
Training loss: 2.4104362832086923
Validation loss: 2.851181102312157

Epoch: 5| Step: 1
Training loss: 3.492988375116111
Validation loss: 2.8498208042875968

Epoch: 5| Step: 2
Training loss: 3.19456894857693
Validation loss: 2.8488342170534726

Epoch: 5| Step: 3
Training loss: 3.054093481195742
Validation loss: 2.849649218258419

Epoch: 5| Step: 4
Training loss: 3.409412001313738
Validation loss: 2.850909365212193

Epoch: 5| Step: 5
Training loss: 2.9528621173088814
Validation loss: 2.8500345377330634

Epoch: 5| Step: 6
Training loss: 2.9951581028648935
Validation loss: 2.853842111818342

Epoch: 5| Step: 7
Training loss: 3.3164462209568577
Validation loss: 2.8671261852193344

Epoch: 5| Step: 8
Training loss: 3.129585868567954
Validation loss: 2.857944179175756

Epoch: 5| Step: 9
Training loss: 3.4971468058776645
Validation loss: 2.857305245538449

Epoch: 5| Step: 10
Training loss: 3.0393447548775154
Validation loss: 2.8477367540143943

Epoch: 38| Step: 0
Training loss: 3.187577340178836
Validation loss: 2.843861168103059

Epoch: 5| Step: 1
Training loss: 2.8044737838033944
Validation loss: 2.838060074265213

Epoch: 5| Step: 2
Training loss: 3.2304731781824243
Validation loss: 2.839102635530043

Epoch: 5| Step: 3
Training loss: 3.8809552116060533
Validation loss: 2.8445424712552843

Epoch: 5| Step: 4
Training loss: 2.4774008694707037
Validation loss: 2.841709801083054

Epoch: 5| Step: 5
Training loss: 2.9517993676461036
Validation loss: 2.839563977083133

Epoch: 5| Step: 6
Training loss: 3.2155227036882463
Validation loss: 2.8402526076377344

Epoch: 5| Step: 7
Training loss: 3.3683137006028616
Validation loss: 2.837385943517731

Epoch: 5| Step: 8
Training loss: 3.06887589641193
Validation loss: 2.8342787747434377

Epoch: 5| Step: 9
Training loss: 3.553010851151237
Validation loss: 2.835212539148747

Epoch: 5| Step: 10
Training loss: 2.5666242765253675
Validation loss: 2.834539581642405

Epoch: 39| Step: 0
Training loss: 3.1909361624983426
Validation loss: 2.8339655102736367

Epoch: 5| Step: 1
Training loss: 3.0687209801943003
Validation loss: 2.8297556185935764

Epoch: 5| Step: 2
Training loss: 3.39630551166117
Validation loss: 2.8333859526243836

Epoch: 5| Step: 3
Training loss: 2.9094240637226396
Validation loss: 2.841011520992801

Epoch: 5| Step: 4
Training loss: 3.3311816582459706
Validation loss: 2.8373219273580275

Epoch: 5| Step: 5
Training loss: 2.3767497995219413
Validation loss: 2.837696670309061

Epoch: 5| Step: 6
Training loss: 3.1363982800566923
Validation loss: 2.844695071123851

Epoch: 5| Step: 7
Training loss: 3.5989922808505814
Validation loss: 2.8423740899226

Epoch: 5| Step: 8
Training loss: 2.9676555021400857
Validation loss: 2.851078043427049

Epoch: 5| Step: 9
Training loss: 3.494026263238192
Validation loss: 2.860837671119087

Epoch: 5| Step: 10
Training loss: 2.805169109339868
Validation loss: 2.8453529173892487

Epoch: 40| Step: 0
Training loss: 2.7346030875852643
Validation loss: 2.8347136228639975

Epoch: 5| Step: 1
Training loss: 2.878088246130519
Validation loss: 2.8355326636884244

Epoch: 5| Step: 2
Training loss: 3.227897312521057
Validation loss: 2.8332491412191705

Epoch: 5| Step: 3
Training loss: 2.1236121189383104
Validation loss: 2.8295005290963235

Epoch: 5| Step: 4
Training loss: 3.478250089659779
Validation loss: 2.8374034275181734

Epoch: 5| Step: 5
Training loss: 3.7984653486002213
Validation loss: 2.835211246121542

Epoch: 5| Step: 6
Training loss: 3.2868761058050406
Validation loss: 2.8249734103931337

Epoch: 5| Step: 7
Training loss: 2.486270685124259
Validation loss: 2.8227567539269227

Epoch: 5| Step: 8
Training loss: 3.788030173079814
Validation loss: 2.8207969800477835

Epoch: 5| Step: 9
Training loss: 3.164739993053586
Validation loss: 2.8207022650673923

Epoch: 5| Step: 10
Training loss: 3.1172280368702734
Validation loss: 2.820151120269559

Epoch: 41| Step: 0
Training loss: 3.5678687883293665
Validation loss: 2.8205937870871765

Epoch: 5| Step: 1
Training loss: 3.2313232767735505
Validation loss: 2.819725028384637

Epoch: 5| Step: 2
Training loss: 2.731558259027425
Validation loss: 2.821382591078947

Epoch: 5| Step: 3
Training loss: 2.475294588840728
Validation loss: 2.825873691344444

Epoch: 5| Step: 4
Training loss: 3.2623832710985914
Validation loss: 2.8310437313188266

Epoch: 5| Step: 5
Training loss: 3.0663501126927497
Validation loss: 2.8290556719799302

Epoch: 5| Step: 6
Training loss: 3.32636411405897
Validation loss: 2.828869761633043

Epoch: 5| Step: 7
Training loss: 3.2478978621203765
Validation loss: 2.8223176773323364

Epoch: 5| Step: 8
Training loss: 3.2685104836699472
Validation loss: 2.813361799951158

Epoch: 5| Step: 9
Training loss: 2.479866303101057
Validation loss: 2.810289443504034

Epoch: 5| Step: 10
Training loss: 3.65969855541963
Validation loss: 2.8098257971626843

Epoch: 42| Step: 0
Training loss: 2.695177511621977
Validation loss: 2.8111764010587157

Epoch: 5| Step: 1
Training loss: 3.1032495018453035
Validation loss: 2.8112950148962867

Epoch: 5| Step: 2
Training loss: 3.046227019438157
Validation loss: 2.809151739935134

Epoch: 5| Step: 3
Training loss: 2.9230481408899105
Validation loss: 2.815695273137098

Epoch: 5| Step: 4
Training loss: 3.1586708378354325
Validation loss: 2.8143680894954257

Epoch: 5| Step: 5
Training loss: 3.457848817519965
Validation loss: 2.8160412023739023

Epoch: 5| Step: 6
Training loss: 2.7927966511662867
Validation loss: 2.817412274283514

Epoch: 5| Step: 7
Training loss: 3.738575890867064
Validation loss: 2.8324106980472745

Epoch: 5| Step: 8
Training loss: 3.36521907189643
Validation loss: 2.824361516680262

Epoch: 5| Step: 9
Training loss: 2.7220471438292098
Validation loss: 2.8135233595348614

Epoch: 5| Step: 10
Training loss: 3.162407185394979
Validation loss: 2.8131799912702853

Epoch: 43| Step: 0
Training loss: 3.241882751114336
Validation loss: 2.809740379368814

Epoch: 5| Step: 1
Training loss: 3.1387040825587706
Validation loss: 2.810432292016324

Epoch: 5| Step: 2
Training loss: 3.1875373987734013
Validation loss: 2.8032288700400296

Epoch: 5| Step: 3
Training loss: 2.7013914690656415
Validation loss: 2.8020614847018446

Epoch: 5| Step: 4
Training loss: 3.333706469314202
Validation loss: 2.802169566701797

Epoch: 5| Step: 5
Training loss: 3.3510078735987623
Validation loss: 2.8008877119032736

Epoch: 5| Step: 6
Training loss: 2.450923831137475
Validation loss: 2.8024475419663175

Epoch: 5| Step: 7
Training loss: 3.463419624798087
Validation loss: 2.803657171788019

Epoch: 5| Step: 8
Training loss: 3.021930644362299
Validation loss: 2.8048977925705945

Epoch: 5| Step: 9
Training loss: 2.8992663738067637
Validation loss: 2.8029025105958354

Epoch: 5| Step: 10
Training loss: 3.336998942621079
Validation loss: 2.801111871678095

Epoch: 44| Step: 0
Training loss: 3.0680236827030773
Validation loss: 2.8050811095596373

Epoch: 5| Step: 1
Training loss: 3.9627203606304566
Validation loss: 2.806741842857507

Epoch: 5| Step: 2
Training loss: 2.547358273952214
Validation loss: 2.8056385051440347

Epoch: 5| Step: 3
Training loss: 2.6236985022810035
Validation loss: 2.808150892325221

Epoch: 5| Step: 4
Training loss: 3.5262706387364466
Validation loss: 2.8215414380812684

Epoch: 5| Step: 5
Training loss: 3.0970815580060074
Validation loss: 2.811716219800808

Epoch: 5| Step: 6
Training loss: 2.8981416864924583
Validation loss: 2.8050647657473715

Epoch: 5| Step: 7
Training loss: 3.180267206157916
Validation loss: 2.79710200182505

Epoch: 5| Step: 8
Training loss: 2.8914193376493857
Validation loss: 2.7952699522546482

Epoch: 5| Step: 9
Training loss: 3.235905087252037
Validation loss: 2.7975701532443336

Epoch: 5| Step: 10
Training loss: 2.9129359954496814
Validation loss: 2.793264748627092

Epoch: 45| Step: 0
Training loss: 3.4968124588597145
Validation loss: 2.795833222908045

Epoch: 5| Step: 1
Training loss: 3.001334370448395
Validation loss: 2.7952488250469485

Epoch: 5| Step: 2
Training loss: 3.1119556548482015
Validation loss: 2.7998404864318296

Epoch: 5| Step: 3
Training loss: 3.0940255707052153
Validation loss: 2.800812231021698

Epoch: 5| Step: 4
Training loss: 2.9737958891552134
Validation loss: 2.8049154854787046

Epoch: 5| Step: 5
Training loss: 2.7970509393858975
Validation loss: 2.816533336577098

Epoch: 5| Step: 6
Training loss: 2.993870672609136
Validation loss: 2.7980356169170335

Epoch: 5| Step: 7
Training loss: 2.7481799605189523
Validation loss: 2.7899511891990816

Epoch: 5| Step: 8
Training loss: 3.2452322393933004
Validation loss: 2.7931202272654283

Epoch: 5| Step: 9
Training loss: 3.204889323306812
Validation loss: 2.7898532510189393

Epoch: 5| Step: 10
Training loss: 3.442865519126195
Validation loss: 2.7862537497920563

Epoch: 46| Step: 0
Training loss: 2.8690394103892505
Validation loss: 2.7872359146077295

Epoch: 5| Step: 1
Training loss: 2.481727004623207
Validation loss: 2.7844609879876407

Epoch: 5| Step: 2
Training loss: 2.7874026875979667
Validation loss: 2.784653979326641

Epoch: 5| Step: 3
Training loss: 3.257334136604692
Validation loss: 2.78681133902811

Epoch: 5| Step: 4
Training loss: 2.951245875664705
Validation loss: 2.787557968522069

Epoch: 5| Step: 5
Training loss: 3.036817648268168
Validation loss: 2.7865822431085743

Epoch: 5| Step: 6
Training loss: 3.2897314990552746
Validation loss: 2.784770416544296

Epoch: 5| Step: 7
Training loss: 3.397212928169397
Validation loss: 2.7864446499181583

Epoch: 5| Step: 8
Training loss: 3.706355878530208
Validation loss: 2.7824581555214865

Epoch: 5| Step: 9
Training loss: 2.795889142574272
Validation loss: 2.7822853162541636

Epoch: 5| Step: 10
Training loss: 3.279453330655769
Validation loss: 2.781968587470121

Epoch: 47| Step: 0
Training loss: 3.545283695808369
Validation loss: 2.7787850409435495

Epoch: 5| Step: 1
Training loss: 3.3601084773400083
Validation loss: 2.7788494350858737

Epoch: 5| Step: 2
Training loss: 3.2343251689813215
Validation loss: 2.7765632260575575

Epoch: 5| Step: 3
Training loss: 3.2228204858718508
Validation loss: 2.774218510622518

Epoch: 5| Step: 4
Training loss: 2.92358478968217
Validation loss: 2.773537387692749

Epoch: 5| Step: 5
Training loss: 3.669911610425041
Validation loss: 2.7748450915848473

Epoch: 5| Step: 6
Training loss: 2.835238620195356
Validation loss: 2.773989763726019

Epoch: 5| Step: 7
Training loss: 2.8371465118301247
Validation loss: 2.7722321907666125

Epoch: 5| Step: 8
Training loss: 3.043427850175462
Validation loss: 2.7725229819443125

Epoch: 5| Step: 9
Training loss: 2.511478584637207
Validation loss: 2.7738408924332774

Epoch: 5| Step: 10
Training loss: 2.4560627446127783
Validation loss: 2.7858753445891176

Epoch: 48| Step: 0
Training loss: 3.515699868994459
Validation loss: 2.7967914351807943

Epoch: 5| Step: 1
Training loss: 2.6965671438737955
Validation loss: 2.7902609699604737

Epoch: 5| Step: 2
Training loss: 3.7756538279632155
Validation loss: 2.8007494713737597

Epoch: 5| Step: 3
Training loss: 3.070772481148912
Validation loss: 2.77271939400272

Epoch: 5| Step: 4
Training loss: 3.33052313283948
Validation loss: 2.771855696698013

Epoch: 5| Step: 5
Training loss: 3.1563784129392576
Validation loss: 2.7699004586033245

Epoch: 5| Step: 6
Training loss: 2.383559813331318
Validation loss: 2.7681976249574944

Epoch: 5| Step: 7
Training loss: 2.255391443114925
Validation loss: 2.7663615229584964

Epoch: 5| Step: 8
Training loss: 3.3697794344570458
Validation loss: 2.767115810417089

Epoch: 5| Step: 9
Training loss: 3.2996447169625265
Validation loss: 2.768052250496584

Epoch: 5| Step: 10
Training loss: 2.838592883473336
Validation loss: 2.7693010754048624

Epoch: 49| Step: 0
Training loss: 3.0307456314645744
Validation loss: 2.7656419180066454

Epoch: 5| Step: 1
Training loss: 3.5632374318144167
Validation loss: 2.767603362253476

Epoch: 5| Step: 2
Training loss: 3.2635761751472523
Validation loss: 2.7676555080168295

Epoch: 5| Step: 3
Training loss: 2.569947097916626
Validation loss: 2.764533120579577

Epoch: 5| Step: 4
Training loss: 3.114438941355825
Validation loss: 2.7689758722349285

Epoch: 5| Step: 5
Training loss: 3.0867070650899593
Validation loss: 2.7638651511064656

Epoch: 5| Step: 6
Training loss: 3.5207739529690447
Validation loss: 2.763393400215727

Epoch: 5| Step: 7
Training loss: 2.869734378711366
Validation loss: 2.762030073851118

Epoch: 5| Step: 8
Training loss: 2.584573345576037
Validation loss: 2.762476766274508

Epoch: 5| Step: 9
Training loss: 2.803439571969637
Validation loss: 2.761446650184555

Epoch: 5| Step: 10
Training loss: 3.4234109854008734
Validation loss: 2.7710685210732304

Epoch: 50| Step: 0
Training loss: 3.2206809168617285
Validation loss: 2.7613644521248997

Epoch: 5| Step: 1
Training loss: 3.073286872589819
Validation loss: 2.7665600932450394

Epoch: 5| Step: 2
Training loss: 3.4709820138898833
Validation loss: 2.780435346730819

Epoch: 5| Step: 3
Training loss: 2.8083739639044647
Validation loss: 2.7756175551234854

Epoch: 5| Step: 4
Training loss: 2.635690808016264
Validation loss: 2.766233936715785

Epoch: 5| Step: 5
Training loss: 3.1294034831870907
Validation loss: 2.7677465345007586

Epoch: 5| Step: 6
Training loss: 3.2122639610170616
Validation loss: 2.761584648743622

Epoch: 5| Step: 7
Training loss: 3.1613041663667225
Validation loss: 2.7609751053870766

Epoch: 5| Step: 8
Training loss: 2.8835764133838606
Validation loss: 2.7637220495755295

Epoch: 5| Step: 9
Training loss: 3.245406940024604
Validation loss: 2.7576372812016388

Epoch: 5| Step: 10
Training loss: 2.9151326277906917
Validation loss: 2.753198299205308

Epoch: 51| Step: 0
Training loss: 3.083020959100494
Validation loss: 2.7539270837013654

Epoch: 5| Step: 1
Training loss: 3.498785216824439
Validation loss: 2.754008616617114

Epoch: 5| Step: 2
Training loss: 2.9908669050034344
Validation loss: 2.7538233828115124

Epoch: 5| Step: 3
Training loss: 2.8708396332057564
Validation loss: 2.7548891962758555

Epoch: 5| Step: 4
Training loss: 2.6787242882118085
Validation loss: 2.7546334511989183

Epoch: 5| Step: 5
Training loss: 3.3764927706387557
Validation loss: 2.7586373951731953

Epoch: 5| Step: 6
Training loss: 3.0974927669068153
Validation loss: 2.7522388966836258

Epoch: 5| Step: 7
Training loss: 3.2501068097683103
Validation loss: 2.75173900431526

Epoch: 5| Step: 8
Training loss: 2.955678007828646
Validation loss: 2.7545381168913

Epoch: 5| Step: 9
Training loss: 3.2544032858682885
Validation loss: 2.753368513753113

Epoch: 5| Step: 10
Training loss: 2.443414018173953
Validation loss: 2.7511016041360272

Epoch: 52| Step: 0
Training loss: 2.002789221366584
Validation loss: 2.7561129311231496

Epoch: 5| Step: 1
Training loss: 2.9324084044686107
Validation loss: 2.755740848255033

Epoch: 5| Step: 2
Training loss: 2.476465746797693
Validation loss: 2.7606898897948797

Epoch: 5| Step: 3
Training loss: 3.352405362084209
Validation loss: 2.757557277053158

Epoch: 5| Step: 4
Training loss: 2.853352191482449
Validation loss: 2.753151779488734

Epoch: 5| Step: 5
Training loss: 3.4262662955240706
Validation loss: 2.7495318104659288

Epoch: 5| Step: 6
Training loss: 3.177946246586214
Validation loss: 2.7443247953757735

Epoch: 5| Step: 7
Training loss: 3.3910948256449736
Validation loss: 2.742864263893093

Epoch: 5| Step: 8
Training loss: 3.586099458914049
Validation loss: 2.74331188379322

Epoch: 5| Step: 9
Training loss: 3.5148352520075363
Validation loss: 2.7437657179241977

Epoch: 5| Step: 10
Training loss: 2.5383109051353716
Validation loss: 2.743641522093735

Epoch: 53| Step: 0
Training loss: 2.830676197912216
Validation loss: 2.7396122331115333

Epoch: 5| Step: 1
Training loss: 2.9484432186036886
Validation loss: 2.7429161976855254

Epoch: 5| Step: 2
Training loss: 3.422215832323106
Validation loss: 2.739070999922921

Epoch: 5| Step: 3
Training loss: 2.5346348113108887
Validation loss: 2.7401703354953395

Epoch: 5| Step: 4
Training loss: 3.0829006269477395
Validation loss: 2.739872209327043

Epoch: 5| Step: 5
Training loss: 2.577358987467745
Validation loss: 2.744630168628136

Epoch: 5| Step: 6
Training loss: 2.9323623856485748
Validation loss: 2.749180536493803

Epoch: 5| Step: 7
Training loss: 3.3848686048511447
Validation loss: 2.749888282661972

Epoch: 5| Step: 8
Training loss: 3.185063945900857
Validation loss: 2.7463072877258505

Epoch: 5| Step: 9
Training loss: 3.4884674261802284
Validation loss: 2.7455843884252205

Epoch: 5| Step: 10
Training loss: 3.1610180183145706
Validation loss: 2.73932387609191

Epoch: 54| Step: 0
Training loss: 2.6845030819553157
Validation loss: 2.7355533883928245

Epoch: 5| Step: 1
Training loss: 3.1509811689806253
Validation loss: 2.739735579489813

Epoch: 5| Step: 2
Training loss: 2.5681308195002246
Validation loss: 2.748059777381286

Epoch: 5| Step: 3
Training loss: 3.4686734302764455
Validation loss: 2.7449127408421554

Epoch: 5| Step: 4
Training loss: 3.4462115786309377
Validation loss: 2.737513640276069

Epoch: 5| Step: 5
Training loss: 3.2918476264239906
Validation loss: 2.7354123521306604

Epoch: 5| Step: 6
Training loss: 3.0171672454896927
Validation loss: 2.7352173991597764

Epoch: 5| Step: 7
Training loss: 3.2081995519183653
Validation loss: 2.73328360297971

Epoch: 5| Step: 8
Training loss: 2.699794327001887
Validation loss: 2.7330790477840776

Epoch: 5| Step: 9
Training loss: 3.1806610641488784
Validation loss: 2.732436570459608

Epoch: 5| Step: 10
Training loss: 2.763699480869192
Validation loss: 2.7406185104467835

Epoch: 55| Step: 0
Training loss: 3.121012470585905
Validation loss: 2.7402561639949727

Epoch: 5| Step: 1
Training loss: 3.167802422951427
Validation loss: 2.7468621277616325

Epoch: 5| Step: 2
Training loss: 3.0240206685848428
Validation loss: 2.7761548454862077

Epoch: 5| Step: 3
Training loss: 3.116977464679497
Validation loss: 2.7958369879042095

Epoch: 5| Step: 4
Training loss: 3.4978869735490483
Validation loss: 2.7486150876994278

Epoch: 5| Step: 5
Training loss: 2.807122663649238
Validation loss: 2.737444820869647

Epoch: 5| Step: 6
Training loss: 2.882568679878047
Validation loss: 2.7329514883799386

Epoch: 5| Step: 7
Training loss: 2.338303608378008
Validation loss: 2.729071688664757

Epoch: 5| Step: 8
Training loss: 3.216435461349468
Validation loss: 2.730234192054772

Epoch: 5| Step: 9
Training loss: 3.097701506506572
Validation loss: 2.7276976939796196

Epoch: 5| Step: 10
Training loss: 3.1793791600345056
Validation loss: 2.727139000979501

Epoch: 56| Step: 0
Training loss: 2.869337725637163
Validation loss: 2.7306019130008297

Epoch: 5| Step: 1
Training loss: 3.1883584156900953
Validation loss: 2.7324796787492533

Epoch: 5| Step: 2
Training loss: 3.252168665435786
Validation loss: 2.7293012151090092

Epoch: 5| Step: 3
Training loss: 3.543288110305087
Validation loss: 2.7265853742190087

Epoch: 5| Step: 4
Training loss: 3.2588500787946
Validation loss: 2.7270010389154575

Epoch: 5| Step: 5
Training loss: 2.812868899417906
Validation loss: 2.7253535094544508

Epoch: 5| Step: 6
Training loss: 3.1076726039049745
Validation loss: 2.7252037676990555

Epoch: 5| Step: 7
Training loss: 3.009479486824293
Validation loss: 2.7234300420200084

Epoch: 5| Step: 8
Training loss: 2.9180364026419467
Validation loss: 2.7383812854239147

Epoch: 5| Step: 9
Training loss: 2.801986115954225
Validation loss: 2.7299435588542402

Epoch: 5| Step: 10
Training loss: 2.6149163711625327
Validation loss: 2.7271353742732187

Epoch: 57| Step: 0
Training loss: 3.1979101390130005
Validation loss: 2.7316175751542944

Epoch: 5| Step: 1
Training loss: 2.7881724756710002
Validation loss: 2.7402086153008725

Epoch: 5| Step: 2
Training loss: 2.5777287034135496
Validation loss: 2.741354634326986

Epoch: 5| Step: 3
Training loss: 3.0294231140080985
Validation loss: 2.7638624927287254

Epoch: 5| Step: 4
Training loss: 2.986886291035561
Validation loss: 2.733421045364669

Epoch: 5| Step: 5
Training loss: 3.3495196894881145
Validation loss: 2.725328489571201

Epoch: 5| Step: 6
Training loss: 3.6827399355537396
Validation loss: 2.7217588822128973

Epoch: 5| Step: 7
Training loss: 3.097226896030642
Validation loss: 2.7173922190118494

Epoch: 5| Step: 8
Training loss: 2.958401280728729
Validation loss: 2.7168837046773646

Epoch: 5| Step: 9
Training loss: 2.5311047547665924
Validation loss: 2.717290231570081

Epoch: 5| Step: 10
Training loss: 3.1342176677432514
Validation loss: 2.715529570671737

Epoch: 58| Step: 0
Training loss: 3.369506603763764
Validation loss: 2.714583510665643

Epoch: 5| Step: 1
Training loss: 3.2053250828455373
Validation loss: 2.712000458172848

Epoch: 5| Step: 2
Training loss: 2.84117781460551
Validation loss: 2.707142480212478

Epoch: 5| Step: 3
Training loss: 2.76476968588988
Validation loss: 2.708787891934889

Epoch: 5| Step: 4
Training loss: 2.9334281133020195
Validation loss: 2.709494149047778

Epoch: 5| Step: 5
Training loss: 2.9063615674989847
Validation loss: 2.7280438394533677

Epoch: 5| Step: 6
Training loss: 3.0222623054177515
Validation loss: 2.7854558160011753

Epoch: 5| Step: 7
Training loss: 3.0498612856980087
Validation loss: 2.801857241376045

Epoch: 5| Step: 8
Training loss: 3.2481994042564586
Validation loss: 2.7902929277603117

Epoch: 5| Step: 9
Training loss: 3.31037849290627
Validation loss: 2.748174727223511

Epoch: 5| Step: 10
Training loss: 2.8601385045692846
Validation loss: 2.717493513955603

Epoch: 59| Step: 0
Training loss: 3.4968380950807556
Validation loss: 2.714635919391759

Epoch: 5| Step: 1
Training loss: 2.9435754809310524
Validation loss: 2.7094086101930284

Epoch: 5| Step: 2
Training loss: 2.6100579013467438
Validation loss: 2.710349591532902

Epoch: 5| Step: 3
Training loss: 2.857750436349808
Validation loss: 2.711151834225552

Epoch: 5| Step: 4
Training loss: 2.9927380406442916
Validation loss: 2.719545090882198

Epoch: 5| Step: 5
Training loss: 3.3180245448901013
Validation loss: 2.7104396359949225

Epoch: 5| Step: 6
Training loss: 2.6155269991838113
Validation loss: 2.7101837904378856

Epoch: 5| Step: 7
Training loss: 3.0815868758384606
Validation loss: 2.712869564985107

Epoch: 5| Step: 8
Training loss: 3.104683254874504
Validation loss: 2.710542945227704

Epoch: 5| Step: 9
Training loss: 3.3847073012322126
Validation loss: 2.712191502192567

Epoch: 5| Step: 10
Training loss: 3.065371354524227
Validation loss: 2.711079367894708

Epoch: 60| Step: 0
Training loss: 2.874223023619071
Validation loss: 2.7131306783395037

Epoch: 5| Step: 1
Training loss: 3.7347784742156853
Validation loss: 2.712301334572172

Epoch: 5| Step: 2
Training loss: 2.655383338912615
Validation loss: 2.7101516371846395

Epoch: 5| Step: 3
Training loss: 2.4731882496290143
Validation loss: 2.7115891858254635

Epoch: 5| Step: 4
Training loss: 3.2565757544591603
Validation loss: 2.7106964353097798

Epoch: 5| Step: 5
Training loss: 2.7471860880886627
Validation loss: 2.7046232484393387

Epoch: 5| Step: 6
Training loss: 2.692299040057354
Validation loss: 2.7034932656904633

Epoch: 5| Step: 7
Training loss: 2.701931375678241
Validation loss: 2.7148981074311327

Epoch: 5| Step: 8
Training loss: 3.1556036258970193
Validation loss: 2.7158459618090074

Epoch: 5| Step: 9
Training loss: 3.63444734929398
Validation loss: 2.7266419073552717

Epoch: 5| Step: 10
Training loss: 3.263167775532606
Validation loss: 2.741511216145092

Epoch: 61| Step: 0
Training loss: 2.752903705757139
Validation loss: 2.7231963539364084

Epoch: 5| Step: 1
Training loss: 2.891748488383518
Validation loss: 2.7048573706372667

Epoch: 5| Step: 2
Training loss: 2.9823289818027594
Validation loss: 2.704827721663254

Epoch: 5| Step: 3
Training loss: 2.435938995537045
Validation loss: 2.7042919312008173

Epoch: 5| Step: 4
Training loss: 2.8347917244109087
Validation loss: 2.7074956859083508

Epoch: 5| Step: 5
Training loss: 3.432478965700385
Validation loss: 2.7035318277493707

Epoch: 5| Step: 6
Training loss: 3.247476184690104
Validation loss: 2.6998944638286453

Epoch: 5| Step: 7
Training loss: 3.7071560194525772
Validation loss: 2.6948391025886265

Epoch: 5| Step: 8
Training loss: 3.160059980475085
Validation loss: 2.6926118517614217

Epoch: 5| Step: 9
Training loss: 2.666807041844497
Validation loss: 2.69381624207972

Epoch: 5| Step: 10
Training loss: 2.967648914331908
Validation loss: 2.694507427160988

Epoch: 62| Step: 0
Training loss: 3.526363942206344
Validation loss: 2.690031113640388

Epoch: 5| Step: 1
Training loss: 2.906081656225676
Validation loss: 2.690726432323774

Epoch: 5| Step: 2
Training loss: 3.1220154815622325
Validation loss: 2.6947308579008586

Epoch: 5| Step: 3
Training loss: 2.916040316947953
Validation loss: 2.695250462571134

Epoch: 5| Step: 4
Training loss: 3.5905173980287124
Validation loss: 2.693765904603486

Epoch: 5| Step: 5
Training loss: 3.3106589329301848
Validation loss: 2.6933230659594156

Epoch: 5| Step: 6
Training loss: 2.5931625620194123
Validation loss: 2.6976783283860977

Epoch: 5| Step: 7
Training loss: 2.003518109720749
Validation loss: 2.68999699547859

Epoch: 5| Step: 8
Training loss: 2.8636552636649912
Validation loss: 2.6940191593881875

Epoch: 5| Step: 9
Training loss: 3.0961610280922796
Validation loss: 2.686544997953664

Epoch: 5| Step: 10
Training loss: 2.9600885225926055
Validation loss: 2.6906502649892015

Epoch: 63| Step: 0
Training loss: 2.905361244734008
Validation loss: 2.685211601979177

Epoch: 5| Step: 1
Training loss: 2.7853329296169593
Validation loss: 2.687176548771371

Epoch: 5| Step: 2
Training loss: 2.701392439900091
Validation loss: 2.68825386789341

Epoch: 5| Step: 3
Training loss: 3.1823115288363804
Validation loss: 2.683577142035266

Epoch: 5| Step: 4
Training loss: 3.004603827031056
Validation loss: 2.6814202758255723

Epoch: 5| Step: 5
Training loss: 2.6015173189289467
Validation loss: 2.6863742072017702

Epoch: 5| Step: 6
Training loss: 2.938709740405556
Validation loss: 2.688857069552963

Epoch: 5| Step: 7
Training loss: 2.6824692948175866
Validation loss: 2.6835616497732624

Epoch: 5| Step: 8
Training loss: 3.351033629191472
Validation loss: 2.689950391085756

Epoch: 5| Step: 9
Training loss: 3.3866966449231746
Validation loss: 2.689215302287813

Epoch: 5| Step: 10
Training loss: 3.5079537344114153
Validation loss: 2.6858932746032753

Epoch: 64| Step: 0
Training loss: 3.472485155110936
Validation loss: 2.6939210224396493

Epoch: 5| Step: 1
Training loss: 2.874638907934905
Validation loss: 2.6870906849141556

Epoch: 5| Step: 2
Training loss: 3.0562683853813373
Validation loss: 2.676509044003667

Epoch: 5| Step: 3
Training loss: 2.3877277645097834
Validation loss: 2.681622061384242

Epoch: 5| Step: 4
Training loss: 3.089243371170883
Validation loss: 2.675398912951889

Epoch: 5| Step: 5
Training loss: 3.035004011776832
Validation loss: 2.6780176895511163

Epoch: 5| Step: 6
Training loss: 2.920760977624757
Validation loss: 2.6747609400927104

Epoch: 5| Step: 7
Training loss: 3.3510579616414087
Validation loss: 2.6742198053203996

Epoch: 5| Step: 8
Training loss: 3.000932707436638
Validation loss: 2.6787451955799204

Epoch: 5| Step: 9
Training loss: 2.2077570709160206
Validation loss: 2.67337961894494

Epoch: 5| Step: 10
Training loss: 3.524281470472765
Validation loss: 2.6761391150324485

Epoch: 65| Step: 0
Training loss: 3.0951607310229785
Validation loss: 2.679253269299378

Epoch: 5| Step: 1
Training loss: 2.8212397100001514
Validation loss: 2.6828822179453264

Epoch: 5| Step: 2
Training loss: 2.6024084233745444
Validation loss: 2.6889820376636107

Epoch: 5| Step: 3
Training loss: 2.3332216940012698
Validation loss: 2.69226576002692

Epoch: 5| Step: 4
Training loss: 3.0557948298161564
Validation loss: 2.6894868621055377

Epoch: 5| Step: 5
Training loss: 2.73664805075679
Validation loss: 2.6786951749610473

Epoch: 5| Step: 6
Training loss: 3.3781388839168174
Validation loss: 2.6792435936254835

Epoch: 5| Step: 7
Training loss: 2.9386596014153668
Validation loss: 2.6781449027659736

Epoch: 5| Step: 8
Training loss: 3.207344513809084
Validation loss: 2.6759229909470865

Epoch: 5| Step: 9
Training loss: 3.308334754796207
Validation loss: 2.671654147653977

Epoch: 5| Step: 10
Training loss: 3.404985105507157
Validation loss: 2.6736021573270543

Epoch: 66| Step: 0
Training loss: 2.8080449742033045
Validation loss: 2.670873564037258

Epoch: 5| Step: 1
Training loss: 2.8750888976575304
Validation loss: 2.6694094797418413

Epoch: 5| Step: 2
Training loss: 3.7393468217076546
Validation loss: 2.671900422558737

Epoch: 5| Step: 3
Training loss: 2.6746100988285404
Validation loss: 2.6744771645599346

Epoch: 5| Step: 4
Training loss: 3.545959354466753
Validation loss: 2.675553530937455

Epoch: 5| Step: 5
Training loss: 2.9063518875474266
Validation loss: 2.671071309057409

Epoch: 5| Step: 6
Training loss: 3.16533087280015
Validation loss: 2.670918119948585

Epoch: 5| Step: 7
Training loss: 2.0385394247592092
Validation loss: 2.665184361444225

Epoch: 5| Step: 8
Training loss: 3.4901862842937574
Validation loss: 2.6662001092705387

Epoch: 5| Step: 9
Training loss: 2.610328728447174
Validation loss: 2.664049901473291

Epoch: 5| Step: 10
Training loss: 2.68752404135663
Validation loss: 2.6586402595783403

Epoch: 67| Step: 0
Training loss: 2.725000146988331
Validation loss: 2.6702506824917362

Epoch: 5| Step: 1
Training loss: 2.9273436262030432
Validation loss: 2.661461551859291

Epoch: 5| Step: 2
Training loss: 3.363425009177163
Validation loss: 2.6606005428215465

Epoch: 5| Step: 3
Training loss: 3.3748515061100774
Validation loss: 2.667253416892774

Epoch: 5| Step: 4
Training loss: 2.4994916399033578
Validation loss: 2.669419835951848

Epoch: 5| Step: 5
Training loss: 3.1487624992192185
Validation loss: 2.663839014538357

Epoch: 5| Step: 6
Training loss: 2.609593547874347
Validation loss: 2.6717715821145807

Epoch: 5| Step: 7
Training loss: 2.977430642550918
Validation loss: 2.680895097932

Epoch: 5| Step: 8
Training loss: 3.0372908657589344
Validation loss: 2.702766580106727

Epoch: 5| Step: 9
Training loss: 3.241510306724863
Validation loss: 2.674507922582016

Epoch: 5| Step: 10
Training loss: 2.945637247410984
Validation loss: 2.667613515751155

Epoch: 68| Step: 0
Training loss: 2.926607267462005
Validation loss: 2.662366206314112

Epoch: 5| Step: 1
Training loss: 2.436913933356122
Validation loss: 2.6605720396852686

Epoch: 5| Step: 2
Training loss: 3.0337407212337504
Validation loss: 2.666550525769009

Epoch: 5| Step: 3
Training loss: 2.5657353329834467
Validation loss: 2.6677799402171662

Epoch: 5| Step: 4
Training loss: 2.910876785275807
Validation loss: 2.665584210562908

Epoch: 5| Step: 5
Training loss: 2.9704600980268574
Validation loss: 2.666895557265704

Epoch: 5| Step: 6
Training loss: 3.4494348201275096
Validation loss: 2.660577721836497

Epoch: 5| Step: 7
Training loss: 3.138933172072995
Validation loss: 2.654184130428649

Epoch: 5| Step: 8
Training loss: 3.4087688686966313
Validation loss: 2.6560282784178906

Epoch: 5| Step: 9
Training loss: 3.0220669737689985
Validation loss: 2.6602306499216843

Epoch: 5| Step: 10
Training loss: 2.932296527070285
Validation loss: 2.660358143200817

Epoch: 69| Step: 0
Training loss: 2.368048483004283
Validation loss: 2.661223656213062

Epoch: 5| Step: 1
Training loss: 2.726340473393148
Validation loss: 2.662953189447135

Epoch: 5| Step: 2
Training loss: 3.3138442281005354
Validation loss: 2.661794243737581

Epoch: 5| Step: 3
Training loss: 3.2694277000664678
Validation loss: 2.660329881272205

Epoch: 5| Step: 4
Training loss: 2.6967795097622798
Validation loss: 2.6645602230827397

Epoch: 5| Step: 5
Training loss: 3.396357739606613
Validation loss: 2.6663495744970365

Epoch: 5| Step: 6
Training loss: 3.3400751758726863
Validation loss: 2.664445798919975

Epoch: 5| Step: 7
Training loss: 3.1313199033567622
Validation loss: 2.65776998135231

Epoch: 5| Step: 8
Training loss: 3.002667512691417
Validation loss: 2.6738006286686233

Epoch: 5| Step: 9
Training loss: 2.7831254272323545
Validation loss: 2.6646077930161916

Epoch: 5| Step: 10
Training loss: 2.541757790438083
Validation loss: 2.671122824748402

Epoch: 70| Step: 0
Training loss: 2.6438863804768715
Validation loss: 2.696090166122205

Epoch: 5| Step: 1
Training loss: 3.4338337160173924
Validation loss: 2.7027156362664777

Epoch: 5| Step: 2
Training loss: 2.954608524422952
Validation loss: 2.68871292784428

Epoch: 5| Step: 3
Training loss: 2.6043040633513646
Validation loss: 2.6794824793550793

Epoch: 5| Step: 4
Training loss: 3.116796330357375
Validation loss: 2.6864404919798135

Epoch: 5| Step: 5
Training loss: 3.317699885494829
Validation loss: 2.6653993701091956

Epoch: 5| Step: 6
Training loss: 3.046892840993439
Validation loss: 2.6603704306089377

Epoch: 5| Step: 7
Training loss: 2.591122134817559
Validation loss: 2.657541820591539

Epoch: 5| Step: 8
Training loss: 3.1689135627743084
Validation loss: 2.652528827553074

Epoch: 5| Step: 9
Training loss: 3.4724557687841195
Validation loss: 2.648830750398991

Epoch: 5| Step: 10
Training loss: 2.0200520476632664
Validation loss: 2.6449435146548606

Epoch: 71| Step: 0
Training loss: 3.151243261188594
Validation loss: 2.6492005899064504

Epoch: 5| Step: 1
Training loss: 2.492458316833227
Validation loss: 2.6437560448613437

Epoch: 5| Step: 2
Training loss: 2.9570199621027946
Validation loss: 2.6441874062513375

Epoch: 5| Step: 3
Training loss: 3.122267634814582
Validation loss: 2.641284027160738

Epoch: 5| Step: 4
Training loss: 2.9516749783152454
Validation loss: 2.640186364400286

Epoch: 5| Step: 5
Training loss: 2.696531070071163
Validation loss: 2.6494623901153673

Epoch: 5| Step: 6
Training loss: 3.1674149448985216
Validation loss: 2.6619519421201265

Epoch: 5| Step: 7
Training loss: 3.329919608809686
Validation loss: 2.6563749396168115

Epoch: 5| Step: 8
Training loss: 2.9228704868039217
Validation loss: 2.6647688854445146

Epoch: 5| Step: 9
Training loss: 3.030713063300138
Validation loss: 2.700006973625241

Epoch: 5| Step: 10
Training loss: 2.902720122750891
Validation loss: 2.7276707181246596

Epoch: 72| Step: 0
Training loss: 2.932443202672791
Validation loss: 2.718505697526963

Epoch: 5| Step: 1
Training loss: 3.343424986257791
Validation loss: 2.6915792083424512

Epoch: 5| Step: 2
Training loss: 2.4718996068450676
Validation loss: 2.6699852450739945

Epoch: 5| Step: 3
Training loss: 2.704815374620773
Validation loss: 2.6610497181324315

Epoch: 5| Step: 4
Training loss: 2.8406969386560825
Validation loss: 2.6586431890216646

Epoch: 5| Step: 5
Training loss: 2.9519108289571108
Validation loss: 2.648036690149502

Epoch: 5| Step: 6
Training loss: 2.932361084752707
Validation loss: 2.6429830760997426

Epoch: 5| Step: 7
Training loss: 3.0421185266701984
Validation loss: 2.640447086448068

Epoch: 5| Step: 8
Training loss: 3.200619047606702
Validation loss: 2.635772606787057

Epoch: 5| Step: 9
Training loss: 3.087850166263252
Validation loss: 2.6352117203330834

Epoch: 5| Step: 10
Training loss: 3.2042731483601328
Validation loss: 2.6358607210427074

Epoch: 73| Step: 0
Training loss: 2.735727640465848
Validation loss: 2.6359319027997374

Epoch: 5| Step: 1
Training loss: 2.9565319612331216
Validation loss: 2.641563142571361

Epoch: 5| Step: 2
Training loss: 2.873842752825692
Validation loss: 2.65471097599034

Epoch: 5| Step: 3
Training loss: 1.9240007507021386
Validation loss: 2.6787110370324347

Epoch: 5| Step: 4
Training loss: 2.9309391857386
Validation loss: 2.7043394743574907

Epoch: 5| Step: 5
Training loss: 3.187104593323184
Validation loss: 2.750110433827792

Epoch: 5| Step: 6
Training loss: 3.7226436971030488
Validation loss: 2.727880041394009

Epoch: 5| Step: 7
Training loss: 2.8645163418421378
Validation loss: 2.6803175179226937

Epoch: 5| Step: 8
Training loss: 2.7114428837898177
Validation loss: 2.654938238675542

Epoch: 5| Step: 9
Training loss: 3.3811593542446925
Validation loss: 2.6377849350491624

Epoch: 5| Step: 10
Training loss: 3.17273223267446
Validation loss: 2.6331203627952076

Epoch: 74| Step: 0
Training loss: 2.635184286575162
Validation loss: 2.630988426029723

Epoch: 5| Step: 1
Training loss: 3.0712513349729686
Validation loss: 2.631658692266176

Epoch: 5| Step: 2
Training loss: 3.2888650359185165
Validation loss: 2.6303831123820283

Epoch: 5| Step: 3
Training loss: 2.8620882762674285
Validation loss: 2.6358977010165376

Epoch: 5| Step: 4
Training loss: 3.042237337132311
Validation loss: 2.6360937313417168

Epoch: 5| Step: 5
Training loss: 2.524168304345435
Validation loss: 2.6348037276078484

Epoch: 5| Step: 6
Training loss: 3.5054359456604565
Validation loss: 2.63625452303675

Epoch: 5| Step: 7
Training loss: 3.0329190407955204
Validation loss: 2.629512976065388

Epoch: 5| Step: 8
Training loss: 3.3229635269225155
Validation loss: 2.6265921991339485

Epoch: 5| Step: 9
Training loss: 2.4701390282117863
Validation loss: 2.6313953828232717

Epoch: 5| Step: 10
Training loss: 2.798928982394217
Validation loss: 2.6336164542373304

Epoch: 75| Step: 0
Training loss: 2.6667524165035896
Validation loss: 2.6365269346360836

Epoch: 5| Step: 1
Training loss: 2.7057070004556025
Validation loss: 2.647572664558922

Epoch: 5| Step: 2
Training loss: 2.6811723960191918
Validation loss: 2.6461954047526897

Epoch: 5| Step: 3
Training loss: 2.7026533476086216
Validation loss: 2.6455623251171296

Epoch: 5| Step: 4
Training loss: 2.832544067255501
Validation loss: 2.640561364150966

Epoch: 5| Step: 5
Training loss: 2.9023874518286195
Validation loss: 2.6551670199967945

Epoch: 5| Step: 6
Training loss: 3.373359140013439
Validation loss: 2.6578181637823737

Epoch: 5| Step: 7
Training loss: 3.402411021148964
Validation loss: 2.646763927066642

Epoch: 5| Step: 8
Training loss: 2.912370860629908
Validation loss: 2.631729666215541

Epoch: 5| Step: 9
Training loss: 3.045300355576814
Validation loss: 2.6227708112531287

Epoch: 5| Step: 10
Training loss: 3.3066775415098144
Validation loss: 2.6246388289932

Epoch: 76| Step: 0
Training loss: 2.5966785856992773
Validation loss: 2.6254158921107518

Epoch: 5| Step: 1
Training loss: 2.880505142416566
Validation loss: 2.6297817011331794

Epoch: 5| Step: 2
Training loss: 3.2774058757799844
Validation loss: 2.6249491759427754

Epoch: 5| Step: 3
Training loss: 2.6433844960742454
Validation loss: 2.623657924565426

Epoch: 5| Step: 4
Training loss: 3.4202429655002873
Validation loss: 2.6226768780934138

Epoch: 5| Step: 5
Training loss: 3.0476315855012435
Validation loss: 2.6187848328188057

Epoch: 5| Step: 6
Training loss: 2.5114069102869143
Validation loss: 2.618840107752886

Epoch: 5| Step: 7
Training loss: 3.4709270621867736
Validation loss: 2.62386620798945

Epoch: 5| Step: 8
Training loss: 2.83142066424353
Validation loss: 2.629331681977958

Epoch: 5| Step: 9
Training loss: 3.015700581448404
Validation loss: 2.634314486574294

Epoch: 5| Step: 10
Training loss: 2.726863986510463
Validation loss: 2.635891302356906

Epoch: 77| Step: 0
Training loss: 3.1671767744156543
Validation loss: 2.6302604742414384

Epoch: 5| Step: 1
Training loss: 3.1766600947063575
Validation loss: 2.6257767482743057

Epoch: 5| Step: 2
Training loss: 2.3771755894893754
Validation loss: 2.6268935535045803

Epoch: 5| Step: 3
Training loss: 2.697933614277479
Validation loss: 2.6219426763646396

Epoch: 5| Step: 4
Training loss: 3.0593959102364128
Validation loss: 2.6237272584549234

Epoch: 5| Step: 5
Training loss: 3.532838177324034
Validation loss: 2.6188699270207336

Epoch: 5| Step: 6
Training loss: 2.5190128236620644
Validation loss: 2.6204907013458567

Epoch: 5| Step: 7
Training loss: 3.323546649842484
Validation loss: 2.618863068761137

Epoch: 5| Step: 8
Training loss: 2.6400376970316253
Validation loss: 2.614048987097112

Epoch: 5| Step: 9
Training loss: 2.839163634493901
Validation loss: 2.615877928589605

Epoch: 5| Step: 10
Training loss: 2.9661482804544796
Validation loss: 2.615936845410778

Epoch: 78| Step: 0
Training loss: 2.886037124046063
Validation loss: 2.6145526021489687

Epoch: 5| Step: 1
Training loss: 3.2182581257210447
Validation loss: 2.6115232872660146

Epoch: 5| Step: 2
Training loss: 2.948881137546732
Validation loss: 2.6162334629908024

Epoch: 5| Step: 3
Training loss: 2.6743606694660618
Validation loss: 2.616571011495377

Epoch: 5| Step: 4
Training loss: 3.0333930236756306
Validation loss: 2.6121377332558886

Epoch: 5| Step: 5
Training loss: 3.355656610809999
Validation loss: 2.6170743317519

Epoch: 5| Step: 6
Training loss: 2.7090860250113624
Validation loss: 2.6103309863265007

Epoch: 5| Step: 7
Training loss: 3.027752618558764
Validation loss: 2.6131593907052824

Epoch: 5| Step: 8
Training loss: 2.323940433539844
Validation loss: 2.614701771420096

Epoch: 5| Step: 9
Training loss: 3.355160220508947
Validation loss: 2.6230461654422066

Epoch: 5| Step: 10
Training loss: 2.733169725995558
Validation loss: 2.631925503396586

Epoch: 79| Step: 0
Training loss: 3.0924704631853523
Validation loss: 2.638006422728311

Epoch: 5| Step: 1
Training loss: 2.551787524044879
Validation loss: 2.6415261458297463

Epoch: 5| Step: 2
Training loss: 3.210514681188585
Validation loss: 2.6578835316061618

Epoch: 5| Step: 3
Training loss: 3.0842012953615816
Validation loss: 2.630217897309848

Epoch: 5| Step: 4
Training loss: 2.5822726092161736
Validation loss: 2.6202140889468226

Epoch: 5| Step: 5
Training loss: 2.9673011858445797
Validation loss: 2.610410115955508

Epoch: 5| Step: 6
Training loss: 2.9914224707382107
Validation loss: 2.606797071604755

Epoch: 5| Step: 7
Training loss: 2.6668578218452623
Validation loss: 2.610990793665845

Epoch: 5| Step: 8
Training loss: 3.0129047042812487
Validation loss: 2.6079703171718283

Epoch: 5| Step: 9
Training loss: 3.5568693402744187
Validation loss: 2.6074528685128753

Epoch: 5| Step: 10
Training loss: 2.5740635178204934
Validation loss: 2.6097965903252547

Epoch: 80| Step: 0
Training loss: 2.760081192840268
Validation loss: 2.610125235313973

Epoch: 5| Step: 1
Training loss: 3.081553761827973
Validation loss: 2.6090252446428495

Epoch: 5| Step: 2
Training loss: 2.5998142542880474
Validation loss: 2.6105103444886186

Epoch: 5| Step: 3
Training loss: 3.0819958200098365
Validation loss: 2.6018133392657434

Epoch: 5| Step: 4
Training loss: 2.954994054230003
Validation loss: 2.6031032725865275

Epoch: 5| Step: 5
Training loss: 3.290084426399559
Validation loss: 2.604982851820827

Epoch: 5| Step: 6
Training loss: 2.746860185568031
Validation loss: 2.605043744125847

Epoch: 5| Step: 7
Training loss: 3.2300828843953022
Validation loss: 2.6152249084976242

Epoch: 5| Step: 8
Training loss: 3.2179279944387473
Validation loss: 2.6254273490117463

Epoch: 5| Step: 9
Training loss: 2.5403544264290057
Validation loss: 2.631580922461191

Epoch: 5| Step: 10
Training loss: 2.7694926830883104
Validation loss: 2.649507313832269

Epoch: 81| Step: 0
Training loss: 2.9262978437668594
Validation loss: 2.6640787263373134

Epoch: 5| Step: 1
Training loss: 2.7624546133602346
Validation loss: 2.6813502003011487

Epoch: 5| Step: 2
Training loss: 3.117702202621501
Validation loss: 2.6708436050001234

Epoch: 5| Step: 3
Training loss: 2.9041266118867224
Validation loss: 2.642691506348606

Epoch: 5| Step: 4
Training loss: 2.826210849495859
Validation loss: 2.61301732586425

Epoch: 5| Step: 5
Training loss: 2.4218258760453972
Validation loss: 2.598321164369781

Epoch: 5| Step: 6
Training loss: 3.135462679266607
Validation loss: 2.5969186438017076

Epoch: 5| Step: 7
Training loss: 3.495349928510978
Validation loss: 2.6025661276937

Epoch: 5| Step: 8
Training loss: 3.175994002569575
Validation loss: 2.5988324054053225

Epoch: 5| Step: 9
Training loss: 2.8721627872629516
Validation loss: 2.6031702900965166

Epoch: 5| Step: 10
Training loss: 2.684032953961113
Validation loss: 2.5988510770270605

Epoch: 82| Step: 0
Training loss: 3.1295803834483698
Validation loss: 2.6006203562512407

Epoch: 5| Step: 1
Training loss: 2.7800887180141025
Validation loss: 2.5956060136952748

Epoch: 5| Step: 2
Training loss: 2.6620458761857813
Validation loss: 2.5922122631754303

Epoch: 5| Step: 3
Training loss: 3.0994403026214523
Validation loss: 2.594291842919521

Epoch: 5| Step: 4
Training loss: 2.885023143020971
Validation loss: 2.593298483198768

Epoch: 5| Step: 5
Training loss: 3.0552459752629333
Validation loss: 2.6026806039670047

Epoch: 5| Step: 6
Training loss: 2.6427289718124767
Validation loss: 2.6120549028435573

Epoch: 5| Step: 7
Training loss: 3.21934755574672
Validation loss: 2.6141266155295013

Epoch: 5| Step: 8
Training loss: 2.829782579784627
Validation loss: 2.643655309913753

Epoch: 5| Step: 9
Training loss: 3.181516379125226
Validation loss: 2.6538484095460046

Epoch: 5| Step: 10
Training loss: 2.9068228864540218
Validation loss: 2.6471779106678324

Epoch: 83| Step: 0
Training loss: 3.23980640162642
Validation loss: 2.6133479172336505

Epoch: 5| Step: 1
Training loss: 2.7147409982241335
Validation loss: 2.5967538605183567

Epoch: 5| Step: 2
Training loss: 3.0277006468052683
Validation loss: 2.5886723017927844

Epoch: 5| Step: 3
Training loss: 2.9591113576301025
Validation loss: 2.5876948365260266

Epoch: 5| Step: 4
Training loss: 2.972963094226255
Validation loss: 2.5876157463951857

Epoch: 5| Step: 5
Training loss: 2.8554485440354687
Validation loss: 2.588130595836569

Epoch: 5| Step: 6
Training loss: 2.764847813258617
Validation loss: 2.595851814089541

Epoch: 5| Step: 7
Training loss: 2.39088777581401
Validation loss: 2.5915813797087357

Epoch: 5| Step: 8
Training loss: 2.8754786217388486
Validation loss: 2.588546774382888

Epoch: 5| Step: 9
Training loss: 3.5026421791859637
Validation loss: 2.588508553420143

Epoch: 5| Step: 10
Training loss: 2.864219022761975
Validation loss: 2.5839641836487117

Epoch: 84| Step: 0
Training loss: 3.0653570433312636
Validation loss: 2.5848887250318873

Epoch: 5| Step: 1
Training loss: 3.3973841646165517
Validation loss: 2.5874952662914446

Epoch: 5| Step: 2
Training loss: 2.942358341615384
Validation loss: 2.5953974062803256

Epoch: 5| Step: 3
Training loss: 2.505476960328427
Validation loss: 2.611056422665454

Epoch: 5| Step: 4
Training loss: 3.0628890744061725
Validation loss: 2.6098730898808373

Epoch: 5| Step: 5
Training loss: 2.476274154676221
Validation loss: 2.639678285870294

Epoch: 5| Step: 6
Training loss: 2.185924725771288
Validation loss: 2.657021541607693

Epoch: 5| Step: 7
Training loss: 3.0359474829854682
Validation loss: 2.6758521927879046

Epoch: 5| Step: 8
Training loss: 3.2779329518227653
Validation loss: 2.6293202567148612

Epoch: 5| Step: 9
Training loss: 3.167371136122262
Validation loss: 2.5906311767374657

Epoch: 5| Step: 10
Training loss: 3.0856292184326066
Validation loss: 2.5842997757395834

Epoch: 85| Step: 0
Training loss: 2.8917728928578033
Validation loss: 2.594945242525721

Epoch: 5| Step: 1
Training loss: 2.9374798713156767
Validation loss: 2.60490299045089

Epoch: 5| Step: 2
Training loss: 2.96134635900558
Validation loss: 2.608758568785259

Epoch: 5| Step: 3
Training loss: 2.683084364609336
Validation loss: 2.608020240428213

Epoch: 5| Step: 4
Training loss: 3.1021103843464246
Validation loss: 2.60583539169154

Epoch: 5| Step: 5
Training loss: 3.1775630067690717
Validation loss: 2.6067119968452857

Epoch: 5| Step: 6
Training loss: 3.36703427136492
Validation loss: 2.605615226912189

Epoch: 5| Step: 7
Training loss: 2.9900283393665092
Validation loss: 2.606591421774397

Epoch: 5| Step: 8
Training loss: 3.028752507402781
Validation loss: 2.607026069909807

Epoch: 5| Step: 9
Training loss: 2.6531359201662594
Validation loss: 2.6015334505405963

Epoch: 5| Step: 10
Training loss: 2.7301175351395166
Validation loss: 2.6042578184520977

Epoch: 86| Step: 0
Training loss: 3.0466249020953304
Validation loss: 2.601123218303576

Epoch: 5| Step: 1
Training loss: 3.074078994152961
Validation loss: 2.601028458520028

Epoch: 5| Step: 2
Training loss: 2.6773798044903296
Validation loss: 2.6105629698267836

Epoch: 5| Step: 3
Training loss: 2.519755319493777
Validation loss: 2.6335932276140976

Epoch: 5| Step: 4
Training loss: 3.024498726162017
Validation loss: 2.655487945322852

Epoch: 5| Step: 5
Training loss: 3.1030574241878957
Validation loss: 2.6372765110127614

Epoch: 5| Step: 6
Training loss: 2.818847529379761
Validation loss: 2.6059332491950418

Epoch: 5| Step: 7
Training loss: 3.4223844244803625
Validation loss: 2.595248695107768

Epoch: 5| Step: 8
Training loss: 2.9526623560286227
Validation loss: 2.5878066588772897

Epoch: 5| Step: 9
Training loss: 2.578180670859635
Validation loss: 2.5978282461034827

Epoch: 5| Step: 10
Training loss: 3.040888926390848
Validation loss: 2.5914576561680014

Epoch: 87| Step: 0
Training loss: 2.949643944411547
Validation loss: 2.578195611080613

Epoch: 5| Step: 1
Training loss: 3.059615197264923
Validation loss: 2.5804753969995

Epoch: 5| Step: 2
Training loss: 2.2388693684288863
Validation loss: 2.5765528345399047

Epoch: 5| Step: 3
Training loss: 2.9751859270227135
Validation loss: 2.5804623248078555

Epoch: 5| Step: 4
Training loss: 3.2525838704184777
Validation loss: 2.581370712358189

Epoch: 5| Step: 5
Training loss: 2.5510695850926175
Validation loss: 2.5798388023127568

Epoch: 5| Step: 6
Training loss: 3.1116381512891413
Validation loss: 2.582541895956601

Epoch: 5| Step: 7
Training loss: 3.015163564215004
Validation loss: 2.595487491774984

Epoch: 5| Step: 8
Training loss: 2.8554570606164638
Validation loss: 2.5964510893782107

Epoch: 5| Step: 9
Training loss: 2.756310072609689
Validation loss: 2.605580401867513

Epoch: 5| Step: 10
Training loss: 3.3728601241639553
Validation loss: 2.591972903649458

Epoch: 88| Step: 0
Training loss: 2.4255560679815504
Validation loss: 2.5838081325120807

Epoch: 5| Step: 1
Training loss: 2.98278158900219
Validation loss: 2.5843105002931597

Epoch: 5| Step: 2
Training loss: 2.382383814537554
Validation loss: 2.5753298894112877

Epoch: 5| Step: 3
Training loss: 3.4528739458193045
Validation loss: 2.5766015745892807

Epoch: 5| Step: 4
Training loss: 2.4539068640435198
Validation loss: 2.5746770509896497

Epoch: 5| Step: 5
Training loss: 3.488157400429473
Validation loss: 2.576586248029602

Epoch: 5| Step: 6
Training loss: 2.80675232943048
Validation loss: 2.575615691329156

Epoch: 5| Step: 7
Training loss: 3.666590747625277
Validation loss: 2.576494445958709

Epoch: 5| Step: 8
Training loss: 2.26627335314914
Validation loss: 2.571782370291393

Epoch: 5| Step: 9
Training loss: 3.114119241047288
Validation loss: 2.5739861352635103

Epoch: 5| Step: 10
Training loss: 2.6624921270263036
Validation loss: 2.5730672925647218

Epoch: 89| Step: 0
Training loss: 3.0105768356921163
Validation loss: 2.573149054617041

Epoch: 5| Step: 1
Training loss: 3.19138189560972
Validation loss: 2.5775897243829498

Epoch: 5| Step: 2
Training loss: 3.1233671881741802
Validation loss: 2.5817034490660706

Epoch: 5| Step: 3
Training loss: 2.9782943693436126
Validation loss: 2.5803039729652206

Epoch: 5| Step: 4
Training loss: 3.0176250565221796
Validation loss: 2.581888975675747

Epoch: 5| Step: 5
Training loss: 2.6790427274696293
Validation loss: 2.581253948236956

Epoch: 5| Step: 6
Training loss: 2.651425546808232
Validation loss: 2.577484013390183

Epoch: 5| Step: 7
Training loss: 2.6786493453546045
Validation loss: 2.5722608729830534

Epoch: 5| Step: 8
Training loss: 2.831543768658815
Validation loss: 2.57056524676852

Epoch: 5| Step: 9
Training loss: 2.758934938068072
Validation loss: 2.5709218228282413

Epoch: 5| Step: 10
Training loss: 3.151936671409915
Validation loss: 2.564697645843261

Epoch: 90| Step: 0
Training loss: 2.989144393827993
Validation loss: 2.569954546582359

Epoch: 5| Step: 1
Training loss: 2.9588604488797414
Validation loss: 2.564192474357042

Epoch: 5| Step: 2
Training loss: 2.5398303000763724
Validation loss: 2.5640668873142833

Epoch: 5| Step: 3
Training loss: 3.2946428453280765
Validation loss: 2.5679104280397436

Epoch: 5| Step: 4
Training loss: 2.840342565749439
Validation loss: 2.560942210602592

Epoch: 5| Step: 5
Training loss: 3.034495395900158
Validation loss: 2.5704283638465673

Epoch: 5| Step: 6
Training loss: 2.817302249173099
Validation loss: 2.56918578567531

Epoch: 5| Step: 7
Training loss: 3.024226438117892
Validation loss: 2.587941559692568

Epoch: 5| Step: 8
Training loss: 3.3128440246435105
Validation loss: 2.608719950150097

Epoch: 5| Step: 9
Training loss: 2.3957127305787886
Validation loss: 2.592750300322772

Epoch: 5| Step: 10
Training loss: 2.8165053774760165
Validation loss: 2.5802322531317903

Epoch: 91| Step: 0
Training loss: 3.0855949115116807
Validation loss: 2.568343817588389

Epoch: 5| Step: 1
Training loss: 2.939139050911968
Validation loss: 2.568832671142516

Epoch: 5| Step: 2
Training loss: 3.258454696333316
Validation loss: 2.564149260294906

Epoch: 5| Step: 3
Training loss: 2.349835239884288
Validation loss: 2.5621764936513003

Epoch: 5| Step: 4
Training loss: 3.0168581007884625
Validation loss: 2.5628536419535997

Epoch: 5| Step: 5
Training loss: 2.879249086502247
Validation loss: 2.559594745175625

Epoch: 5| Step: 6
Training loss: 2.666782277303225
Validation loss: 2.5602924513407017

Epoch: 5| Step: 7
Training loss: 2.7237824966151734
Validation loss: 2.560665107955236

Epoch: 5| Step: 8
Training loss: 2.794033205155886
Validation loss: 2.5628412161089655

Epoch: 5| Step: 9
Training loss: 3.0552144486350605
Validation loss: 2.573022152151257

Epoch: 5| Step: 10
Training loss: 3.264530272175343
Validation loss: 2.5781163936109635

Epoch: 92| Step: 0
Training loss: 3.283144158917988
Validation loss: 2.5942800736078646

Epoch: 5| Step: 1
Training loss: 3.5722118308979285
Validation loss: 2.596448593322472

Epoch: 5| Step: 2
Training loss: 2.7625813951195437
Validation loss: 2.6124409110312037

Epoch: 5| Step: 3
Training loss: 2.4289852979771833
Validation loss: 2.590960306463876

Epoch: 5| Step: 4
Training loss: 2.8359220309925908
Validation loss: 2.5729450232404685

Epoch: 5| Step: 5
Training loss: 2.8147221581599697
Validation loss: 2.562569752085741

Epoch: 5| Step: 6
Training loss: 3.067378459782808
Validation loss: 2.558354110034835

Epoch: 5| Step: 7
Training loss: 2.169070841777739
Validation loss: 2.560211736654507

Epoch: 5| Step: 8
Training loss: 2.8345425961036423
Validation loss: 2.5566524773353563

Epoch: 5| Step: 9
Training loss: 3.074614406073177
Validation loss: 2.557932327573456

Epoch: 5| Step: 10
Training loss: 3.052263551844269
Validation loss: 2.555778380643371

Epoch: 93| Step: 0
Training loss: 3.214447108258587
Validation loss: 2.5551120013625765

Epoch: 5| Step: 1
Training loss: 2.926563438500917
Validation loss: 2.5556854228721866

Epoch: 5| Step: 2
Training loss: 3.299058670109655
Validation loss: 2.553110050676729

Epoch: 5| Step: 3
Training loss: 3.075193141671193
Validation loss: 2.5609543923959044

Epoch: 5| Step: 4
Training loss: 2.881233092814921
Validation loss: 2.5624122394507305

Epoch: 5| Step: 5
Training loss: 2.5671815673610983
Validation loss: 2.573451457185104

Epoch: 5| Step: 6
Training loss: 2.5449028570675147
Validation loss: 2.5898621805540247

Epoch: 5| Step: 7
Training loss: 3.329890539529644
Validation loss: 2.6142711609108082

Epoch: 5| Step: 8
Training loss: 2.5907301270583085
Validation loss: 2.6003937046116756

Epoch: 5| Step: 9
Training loss: 2.867585780782162
Validation loss: 2.6017022647629386

Epoch: 5| Step: 10
Training loss: 2.5741430801129357
Validation loss: 2.599196265776662

Epoch: 94| Step: 0
Training loss: 3.135939409818956
Validation loss: 2.579665000574282

Epoch: 5| Step: 1
Training loss: 3.433340712110374
Validation loss: 2.563223980892029

Epoch: 5| Step: 2
Training loss: 2.3136000207798113
Validation loss: 2.559315620470864

Epoch: 5| Step: 3
Training loss: 2.5258591313955043
Validation loss: 2.5550647748158806

Epoch: 5| Step: 4
Training loss: 2.6799122351894047
Validation loss: 2.552801562951087

Epoch: 5| Step: 5
Training loss: 2.91383291367922
Validation loss: 2.551245327839771

Epoch: 5| Step: 6
Training loss: 3.0693059538087657
Validation loss: 2.5542272493282203

Epoch: 5| Step: 7
Training loss: 2.9943963804459055
Validation loss: 2.5513058768818384

Epoch: 5| Step: 8
Training loss: 3.1801583506186866
Validation loss: 2.55594150272171

Epoch: 5| Step: 9
Training loss: 2.230490235126655
Validation loss: 2.5520350987637457

Epoch: 5| Step: 10
Training loss: 3.301033904208037
Validation loss: 2.551509861221374

Epoch: 95| Step: 0
Training loss: 3.056973199758704
Validation loss: 2.5516599691154704

Epoch: 5| Step: 1
Training loss: 3.1020836380308747
Validation loss: 2.554235780639996

Epoch: 5| Step: 2
Training loss: 2.300540412771725
Validation loss: 2.556881924511341

Epoch: 5| Step: 3
Training loss: 2.814169409466929
Validation loss: 2.567522252166096

Epoch: 5| Step: 4
Training loss: 3.018135251462095
Validation loss: 2.5658960935888144

Epoch: 5| Step: 5
Training loss: 2.810405035727724
Validation loss: 2.568407142631965

Epoch: 5| Step: 6
Training loss: 2.916062555874436
Validation loss: 2.589761415226188

Epoch: 5| Step: 7
Training loss: 3.2989660203750004
Validation loss: 2.620496050226073

Epoch: 5| Step: 8
Training loss: 2.8925857080209516
Validation loss: 2.6192042918915175

Epoch: 5| Step: 9
Training loss: 2.8508997316795153
Validation loss: 2.603262984139485

Epoch: 5| Step: 10
Training loss: 2.8545326128252775
Validation loss: 2.5707416562020957

Epoch: 96| Step: 0
Training loss: 3.279627516926316
Validation loss: 2.564642461502281

Epoch: 5| Step: 1
Training loss: 2.898098249708905
Validation loss: 2.5664541958284603

Epoch: 5| Step: 2
Training loss: 2.5775564780647438
Validation loss: 2.5628347930980335

Epoch: 5| Step: 3
Training loss: 3.014081648967975
Validation loss: 2.5593640987983393

Epoch: 5| Step: 4
Training loss: 2.699048623494001
Validation loss: 2.555808543971781

Epoch: 5| Step: 5
Training loss: 3.3935875672867586
Validation loss: 2.5629922867661303

Epoch: 5| Step: 6
Training loss: 2.8905398794477364
Validation loss: 2.555485499696777

Epoch: 5| Step: 7
Training loss: 3.009519414714573
Validation loss: 2.5517362745783307

Epoch: 5| Step: 8
Training loss: 2.3444869853655277
Validation loss: 2.551601649908878

Epoch: 5| Step: 9
Training loss: 2.8159942960572995
Validation loss: 2.544668832891483

Epoch: 5| Step: 10
Training loss: 2.884765459705056
Validation loss: 2.5454903165299863

Epoch: 97| Step: 0
Training loss: 3.0278953000591216
Validation loss: 2.5456598149585825

Epoch: 5| Step: 1
Training loss: 3.0254502016608193
Validation loss: 2.5440270299971792

Epoch: 5| Step: 2
Training loss: 3.1792440269193927
Validation loss: 2.548779064060371

Epoch: 5| Step: 3
Training loss: 2.5566736369263863
Validation loss: 2.5446955796872377

Epoch: 5| Step: 4
Training loss: 3.283319892145777
Validation loss: 2.547769375002274

Epoch: 5| Step: 5
Training loss: 2.707085943288799
Validation loss: 2.551072029075751

Epoch: 5| Step: 6
Training loss: 2.364701076270476
Validation loss: 2.5676700651007915

Epoch: 5| Step: 7
Training loss: 3.1736332572388757
Validation loss: 2.566334200713171

Epoch: 5| Step: 8
Training loss: 2.8766028870208515
Validation loss: 2.5782520251709773

Epoch: 5| Step: 9
Training loss: 2.7845935226300433
Validation loss: 2.5993119625450034

Epoch: 5| Step: 10
Training loss: 2.7683354258964785
Validation loss: 2.5811032114320684

Epoch: 98| Step: 0
Training loss: 2.858598447317813
Validation loss: 2.5831421808846433

Epoch: 5| Step: 1
Training loss: 2.9434662959594458
Validation loss: 2.5821012866263438

Epoch: 5| Step: 2
Training loss: 2.6479419706042466
Validation loss: 2.581790569257235

Epoch: 5| Step: 3
Training loss: 2.9712476964804417
Validation loss: 2.5801971143058284

Epoch: 5| Step: 4
Training loss: 3.122250071801466
Validation loss: 2.588391325874711

Epoch: 5| Step: 5
Training loss: 3.3459278750492722
Validation loss: 2.592523037773718

Epoch: 5| Step: 6
Training loss: 2.561534141317466
Validation loss: 2.5691399773493764

Epoch: 5| Step: 7
Training loss: 2.8113432306729527
Validation loss: 2.5610894943990803

Epoch: 5| Step: 8
Training loss: 2.5475577159030047
Validation loss: 2.552646418305059

Epoch: 5| Step: 9
Training loss: 2.8298270651882724
Validation loss: 2.549296337538406

Epoch: 5| Step: 10
Training loss: 3.117242874762695
Validation loss: 2.5469129639949255

Epoch: 99| Step: 0
Training loss: 2.836675542630012
Validation loss: 2.550661330672246

Epoch: 5| Step: 1
Training loss: 2.6203635004365644
Validation loss: 2.545596957318097

Epoch: 5| Step: 2
Training loss: 3.071323994982184
Validation loss: 2.54315378938494

Epoch: 5| Step: 3
Training loss: 2.714348134420182
Validation loss: 2.549874754694581

Epoch: 5| Step: 4
Training loss: 2.3952024430822476
Validation loss: 2.5467291500250044

Epoch: 5| Step: 5
Training loss: 2.686957548532307
Validation loss: 2.5497233190639084

Epoch: 5| Step: 6
Training loss: 3.31935719828069
Validation loss: 2.5642672151791333

Epoch: 5| Step: 7
Training loss: 3.0592794806713774
Validation loss: 2.590379270482556

Epoch: 5| Step: 8
Training loss: 3.0341515565862824
Validation loss: 2.623585229398413

Epoch: 5| Step: 9
Training loss: 3.050133317628929
Validation loss: 2.6511499722977243

Epoch: 5| Step: 10
Training loss: 3.0336759632257224
Validation loss: 2.6321474753644307

Epoch: 100| Step: 0
Training loss: 2.422940419792148
Validation loss: 2.6030281666078228

Epoch: 5| Step: 1
Training loss: 2.962025948111386
Validation loss: 2.5768851920227336

Epoch: 5| Step: 2
Training loss: 3.2874956544332465
Validation loss: 2.5466859617626025

Epoch: 5| Step: 3
Training loss: 3.180243366213845
Validation loss: 2.5413424510193225

Epoch: 5| Step: 4
Training loss: 2.7612052990536085
Validation loss: 2.545493652143627

Epoch: 5| Step: 5
Training loss: 3.0213985221319306
Validation loss: 2.5451890670138937

Epoch: 5| Step: 6
Training loss: 2.570999100182345
Validation loss: 2.5529808999150965

Epoch: 5| Step: 7
Training loss: 2.9164701849742523
Validation loss: 2.5497021782087157

Epoch: 5| Step: 8
Training loss: 2.5534639840858695
Validation loss: 2.5586434303212946

Epoch: 5| Step: 9
Training loss: 2.6583494977150677
Validation loss: 2.546204807489513

Epoch: 5| Step: 10
Training loss: 3.5317405427482216
Validation loss: 2.541347097933313

Epoch: 101| Step: 0
Training loss: 2.3741636309387286
Validation loss: 2.542519439617464

Epoch: 5| Step: 1
Training loss: 2.889622694947012
Validation loss: 2.549339797339974

Epoch: 5| Step: 2
Training loss: 2.4181457356155227
Validation loss: 2.560907427755062

Epoch: 5| Step: 3
Training loss: 3.1424254765015847
Validation loss: 2.56913593900896

Epoch: 5| Step: 4
Training loss: 3.0968592268987667
Validation loss: 2.577812932661799

Epoch: 5| Step: 5
Training loss: 3.1769394305215575
Validation loss: 2.5749410668126496

Epoch: 5| Step: 6
Training loss: 2.7848473761495915
Validation loss: 2.5966987497632217

Epoch: 5| Step: 7
Training loss: 2.8134667324541915
Validation loss: 2.6188527744856436

Epoch: 5| Step: 8
Training loss: 2.687682212152871
Validation loss: 2.593920856634997

Epoch: 5| Step: 9
Training loss: 3.4364569728849013
Validation loss: 2.590558357360787

Epoch: 5| Step: 10
Training loss: 2.7596709389719365
Validation loss: 2.598307255489207

Epoch: 102| Step: 0
Training loss: 3.1671706016176295
Validation loss: 2.607378510206767

Epoch: 5| Step: 1
Training loss: 3.2193256344914154
Validation loss: 2.602540900609485

Epoch: 5| Step: 2
Training loss: 2.8215689356898754
Validation loss: 2.603356576907991

Epoch: 5| Step: 3
Training loss: 2.3568625304085202
Validation loss: 2.569994281412744

Epoch: 5| Step: 4
Training loss: 2.7805739877779856
Validation loss: 2.5385643886154003

Epoch: 5| Step: 5
Training loss: 2.232920993867888
Validation loss: 2.5289286030000206

Epoch: 5| Step: 6
Training loss: 2.487942898680745
Validation loss: 2.5297366020830983

Epoch: 5| Step: 7
Training loss: 3.089611329260293
Validation loss: 2.5374025705310435

Epoch: 5| Step: 8
Training loss: 2.737041807803822
Validation loss: 2.536609758759583

Epoch: 5| Step: 9
Training loss: 3.693750676447101
Validation loss: 2.5446475402302062

Epoch: 5| Step: 10
Training loss: 3.105487175652885
Validation loss: 2.544043775053635

Epoch: 103| Step: 0
Training loss: 2.498169610391319
Validation loss: 2.5508000653097525

Epoch: 5| Step: 1
Training loss: 2.8427125484611895
Validation loss: 2.542836134224211

Epoch: 5| Step: 2
Training loss: 3.193144494156048
Validation loss: 2.5498269234105995

Epoch: 5| Step: 3
Training loss: 2.731678095947462
Validation loss: 2.5463785281119558

Epoch: 5| Step: 4
Training loss: 2.8331751124765554
Validation loss: 2.5472112746059046

Epoch: 5| Step: 5
Training loss: 2.9479531509424244
Validation loss: 2.5448333924056947

Epoch: 5| Step: 6
Training loss: 2.9560364595676027
Validation loss: 2.5424601595382965

Epoch: 5| Step: 7
Training loss: 3.135144210248577
Validation loss: 2.540497894572727

Epoch: 5| Step: 8
Training loss: 2.8182688570984693
Validation loss: 2.5464170864520623

Epoch: 5| Step: 9
Training loss: 2.8704756921384504
Validation loss: 2.5642619344643545

Epoch: 5| Step: 10
Training loss: 3.0384720177177234
Validation loss: 2.561606528774874

Epoch: 104| Step: 0
Training loss: 2.9413743137687747
Validation loss: 2.598871191682479

Epoch: 5| Step: 1
Training loss: 2.716297402668278
Validation loss: 2.626378166875724

Epoch: 5| Step: 2
Training loss: 3.0360311967857716
Validation loss: 2.6579916545793973

Epoch: 5| Step: 3
Training loss: 2.5934789125266584
Validation loss: 2.6781231894911586

Epoch: 5| Step: 4
Training loss: 3.2185825933976684
Validation loss: 2.679943390958396

Epoch: 5| Step: 5
Training loss: 2.8726556590694083
Validation loss: 2.6374355023480995

Epoch: 5| Step: 6
Training loss: 2.9153205671760034
Validation loss: 2.5783021221552995

Epoch: 5| Step: 7
Training loss: 2.5578476145483116
Validation loss: 2.526479132656052

Epoch: 5| Step: 8
Training loss: 3.208728188001074
Validation loss: 2.5274263440640232

Epoch: 5| Step: 9
Training loss: 3.0896639572671085
Validation loss: 2.5266698374427867

Epoch: 5| Step: 10
Training loss: 2.9391935620448706
Validation loss: 2.5290200921425883

Epoch: 105| Step: 0
Training loss: 3.1147241634990825
Validation loss: 2.5316494669927407

Epoch: 5| Step: 1
Training loss: 2.875207976406711
Validation loss: 2.531394135040201

Epoch: 5| Step: 2
Training loss: 2.662764605057958
Validation loss: 2.529872463240861

Epoch: 5| Step: 3
Training loss: 2.7536606266515924
Validation loss: 2.53443845515682

Epoch: 5| Step: 4
Training loss: 3.0634158575034207
Validation loss: 2.5350738708691556

Epoch: 5| Step: 5
Training loss: 1.9335449212584677
Validation loss: 2.5368499551235657

Epoch: 5| Step: 6
Training loss: 2.4751582933148604
Validation loss: 2.5321599838003173

Epoch: 5| Step: 7
Training loss: 3.3684190237202305
Validation loss: 2.5342400282157276

Epoch: 5| Step: 8
Training loss: 3.1823074831572136
Validation loss: 2.5338730452775957

Epoch: 5| Step: 9
Training loss: 3.0479504374582045
Validation loss: 2.5327170782037602

Epoch: 5| Step: 10
Training loss: 3.0398142848257144
Validation loss: 2.53325978103795

Epoch: 106| Step: 0
Training loss: 3.4591802609430107
Validation loss: 2.531836950709748

Epoch: 5| Step: 1
Training loss: 2.3296943853776733
Validation loss: 2.5347986123739035

Epoch: 5| Step: 2
Training loss: 2.822065743624753
Validation loss: 2.5359367532908252

Epoch: 5| Step: 3
Training loss: 2.736422398949254
Validation loss: 2.5313328544965197

Epoch: 5| Step: 4
Training loss: 3.1397658354314855
Validation loss: 2.541385283714239

Epoch: 5| Step: 5
Training loss: 3.000711038885884
Validation loss: 2.5401744341945256

Epoch: 5| Step: 6
Training loss: 2.538485323521082
Validation loss: 2.5358888896069867

Epoch: 5| Step: 7
Training loss: 2.8549339952204553
Validation loss: 2.5426672450890586

Epoch: 5| Step: 8
Training loss: 2.7921004646283123
Validation loss: 2.533998078040501

Epoch: 5| Step: 9
Training loss: 2.419675554327069
Validation loss: 2.528102066343869

Epoch: 5| Step: 10
Training loss: 3.4236437263164654
Validation loss: 2.5309146034510457

Epoch: 107| Step: 0
Training loss: 2.6648384821114743
Validation loss: 2.535865101992582

Epoch: 5| Step: 1
Training loss: 2.971491140450922
Validation loss: 2.52735438454541

Epoch: 5| Step: 2
Training loss: 3.0556417472319555
Validation loss: 2.534126995429652

Epoch: 5| Step: 3
Training loss: 3.003066561921262
Validation loss: 2.5360534749820647

Epoch: 5| Step: 4
Training loss: 2.3401198693897696
Validation loss: 2.5394229907514174

Epoch: 5| Step: 5
Training loss: 2.6003853365646803
Validation loss: 2.540641209311337

Epoch: 5| Step: 6
Training loss: 3.337526465607482
Validation loss: 2.5677594320796464

Epoch: 5| Step: 7
Training loss: 2.5690007442415377
Validation loss: 2.5872174949010067

Epoch: 5| Step: 8
Training loss: 2.650749974919346
Validation loss: 2.6369192293762445

Epoch: 5| Step: 9
Training loss: 3.2218325770311136
Validation loss: 2.6715277126063492

Epoch: 5| Step: 10
Training loss: 3.1103908087202146
Validation loss: 2.6427276777344684

Epoch: 108| Step: 0
Training loss: 2.971776924961872
Validation loss: 2.577004910723725

Epoch: 5| Step: 1
Training loss: 3.0519735861218953
Validation loss: 2.5385012103589015

Epoch: 5| Step: 2
Training loss: 2.88561478541737
Validation loss: 2.520636077325448

Epoch: 5| Step: 3
Training loss: 3.031524173882421
Validation loss: 2.5161533146163215

Epoch: 5| Step: 4
Training loss: 2.8417126410411258
Validation loss: 2.5300722064693173

Epoch: 5| Step: 5
Training loss: 2.7540847612245485
Validation loss: 2.5344801163772024

Epoch: 5| Step: 6
Training loss: 2.862044125699954
Validation loss: 2.5353709768181774

Epoch: 5| Step: 7
Training loss: 3.0937287300997056
Validation loss: 2.5267621150365214

Epoch: 5| Step: 8
Training loss: 2.8718249161994884
Validation loss: 2.5239508804535538

Epoch: 5| Step: 9
Training loss: 2.7768988702346102
Validation loss: 2.5207299492902155

Epoch: 5| Step: 10
Training loss: 2.738318253945987
Validation loss: 2.5356759370227406

Epoch: 109| Step: 0
Training loss: 2.3722470038273773
Validation loss: 2.559909044430552

Epoch: 5| Step: 1
Training loss: 2.912738734599304
Validation loss: 2.577870374966181

Epoch: 5| Step: 2
Training loss: 3.1438387848771527
Validation loss: 2.6116087240876706

Epoch: 5| Step: 3
Training loss: 3.249791358706289
Validation loss: 2.5521475453405036

Epoch: 5| Step: 4
Training loss: 2.863026439783164
Validation loss: 2.514611935675675

Epoch: 5| Step: 5
Training loss: 2.809605613807596
Validation loss: 2.517674964139468

Epoch: 5| Step: 6
Training loss: 2.5643559689504776
Validation loss: 2.515191832404392

Epoch: 5| Step: 7
Training loss: 2.7575609994817953
Validation loss: 2.53547112824709

Epoch: 5| Step: 8
Training loss: 2.832160557392812
Validation loss: 2.58901557703343

Epoch: 5| Step: 9
Training loss: 3.273590594150831
Validation loss: 2.600251049782164

Epoch: 5| Step: 10
Training loss: 3.1974408585818157
Validation loss: 2.5390963836251714

Epoch: 110| Step: 0
Training loss: 2.5659608497992785
Validation loss: 2.5203362624596206

Epoch: 5| Step: 1
Training loss: 3.120727823169023
Validation loss: 2.518313251063824

Epoch: 5| Step: 2
Training loss: 2.8730588247542106
Validation loss: 2.5164397707516355

Epoch: 5| Step: 3
Training loss: 2.6004673941192182
Validation loss: 2.5123592098499534

Epoch: 5| Step: 4
Training loss: 2.7604529516366445
Validation loss: 2.5131637465446053

Epoch: 5| Step: 5
Training loss: 2.960405689481338
Validation loss: 2.516810762479386

Epoch: 5| Step: 6
Training loss: 3.0333782472184776
Validation loss: 2.5481136774262496

Epoch: 5| Step: 7
Training loss: 3.2787966321100686
Validation loss: 2.5925979675078388

Epoch: 5| Step: 8
Training loss: 2.3069120371782343
Validation loss: 2.6131754504482876

Epoch: 5| Step: 9
Training loss: 3.1439780181038657
Validation loss: 2.619257218233901

Epoch: 5| Step: 10
Training loss: 3.0428194099967594
Validation loss: 2.60427885211776

Epoch: 111| Step: 0
Training loss: 2.9395603502556993
Validation loss: 2.5865574917489713

Epoch: 5| Step: 1
Training loss: 3.060878869547197
Validation loss: 2.548536192616266

Epoch: 5| Step: 2
Training loss: 2.5049772307984854
Validation loss: 2.528050101451846

Epoch: 5| Step: 3
Training loss: 2.539276395738092
Validation loss: 2.5284259542934615

Epoch: 5| Step: 4
Training loss: 3.3340334316012292
Validation loss: 2.5203889905876546

Epoch: 5| Step: 5
Training loss: 2.3217788327249433
Validation loss: 2.536016332020136

Epoch: 5| Step: 6
Training loss: 2.7792867524960605
Validation loss: 2.5283741040437047

Epoch: 5| Step: 7
Training loss: 2.7486909004578464
Validation loss: 2.514040676911346

Epoch: 5| Step: 8
Training loss: 2.669966880792953
Validation loss: 2.5207970719223987

Epoch: 5| Step: 9
Training loss: 3.4564091181903756
Validation loss: 2.5268035117022083

Epoch: 5| Step: 10
Training loss: 3.237052362197045
Validation loss: 2.5229137154780514

Epoch: 112| Step: 0
Training loss: 3.1045401090395424
Validation loss: 2.52009046980911

Epoch: 5| Step: 1
Training loss: 2.6630208504433908
Validation loss: 2.516001736392314

Epoch: 5| Step: 2
Training loss: 3.084728303441761
Validation loss: 2.5144710636792436

Epoch: 5| Step: 3
Training loss: 2.6215237806232174
Validation loss: 2.5155793057638576

Epoch: 5| Step: 4
Training loss: 3.2406917200972742
Validation loss: 2.507116279950498

Epoch: 5| Step: 5
Training loss: 2.978636332082806
Validation loss: 2.507687758482104

Epoch: 5| Step: 6
Training loss: 3.1191935191390203
Validation loss: 2.501925237301577

Epoch: 5| Step: 7
Training loss: 2.8391423047805184
Validation loss: 2.509574127520622

Epoch: 5| Step: 8
Training loss: 2.5080769717316036
Validation loss: 2.511310124465913

Epoch: 5| Step: 9
Training loss: 2.7459273091174112
Validation loss: 2.531599836179141

Epoch: 5| Step: 10
Training loss: 2.6828116397489703
Validation loss: 2.530601676701115

Epoch: 113| Step: 0
Training loss: 3.182533583782244
Validation loss: 2.5235258388114774

Epoch: 5| Step: 1
Training loss: 2.775359527392194
Validation loss: 2.5156075144451595

Epoch: 5| Step: 2
Training loss: 2.592930675846559
Validation loss: 2.5095224286844555

Epoch: 5| Step: 3
Training loss: 2.8228543733337212
Validation loss: 2.5027071641477376

Epoch: 5| Step: 4
Training loss: 3.067467222901366
Validation loss: 2.502388234891938

Epoch: 5| Step: 5
Training loss: 2.7554763538589886
Validation loss: 2.501056907136441

Epoch: 5| Step: 6
Training loss: 3.349752724474526
Validation loss: 2.5001001348232825

Epoch: 5| Step: 7
Training loss: 2.893455150899373
Validation loss: 2.505056877095561

Epoch: 5| Step: 8
Training loss: 2.9980630979813516
Validation loss: 2.502998356774207

Epoch: 5| Step: 9
Training loss: 2.7064700735352036
Validation loss: 2.5046431490375936

Epoch: 5| Step: 10
Training loss: 2.3525824378525164
Validation loss: 2.504379681527773

Epoch: 114| Step: 0
Training loss: 2.9316324923896193
Validation loss: 2.5015904146363424

Epoch: 5| Step: 1
Training loss: 2.8015911043390798
Validation loss: 2.5036672285113846

Epoch: 5| Step: 2
Training loss: 2.295852848900053
Validation loss: 2.509447541734387

Epoch: 5| Step: 3
Training loss: 3.1902294066880774
Validation loss: 2.5256332860651574

Epoch: 5| Step: 4
Training loss: 2.9295198519740997
Validation loss: 2.533295911958897

Epoch: 5| Step: 5
Training loss: 2.8484389664504417
Validation loss: 2.5362091100359794

Epoch: 5| Step: 6
Training loss: 2.4825740020263463
Validation loss: 2.532391057899211

Epoch: 5| Step: 7
Training loss: 3.484092119306404
Validation loss: 2.5510217179246277

Epoch: 5| Step: 8
Training loss: 2.8249093842953585
Validation loss: 2.547724605447215

Epoch: 5| Step: 9
Training loss: 2.8671088350818827
Validation loss: 2.5354093982088366

Epoch: 5| Step: 10
Training loss: 2.6427243707511314
Validation loss: 2.5329045770255063

Epoch: 115| Step: 0
Training loss: 3.2063270009333205
Validation loss: 2.5218709689650933

Epoch: 5| Step: 1
Training loss: 2.6025847754838503
Validation loss: 2.514019711192004

Epoch: 5| Step: 2
Training loss: 2.7897501292846987
Validation loss: 2.5121063130913184

Epoch: 5| Step: 3
Training loss: 2.8597178436026747
Validation loss: 2.50619652476531

Epoch: 5| Step: 4
Training loss: 3.4111206508783347
Validation loss: 2.513055015372724

Epoch: 5| Step: 5
Training loss: 2.1967884681557353
Validation loss: 2.50508567297092

Epoch: 5| Step: 6
Training loss: 3.131385383039631
Validation loss: 2.5097670550522055

Epoch: 5| Step: 7
Training loss: 2.769213487395949
Validation loss: 2.5171541134589046

Epoch: 5| Step: 8
Training loss: 2.810100464297638
Validation loss: 2.5104117780013278

Epoch: 5| Step: 9
Training loss: 2.9181784027239512
Validation loss: 2.5158940368004212

Epoch: 5| Step: 10
Training loss: 2.5314400683968907
Validation loss: 2.517355933112756

Epoch: 116| Step: 0
Training loss: 3.0077042200984696
Validation loss: 2.52611496191798

Epoch: 5| Step: 1
Training loss: 2.7572644259139167
Validation loss: 2.552535802541022

Epoch: 5| Step: 2
Training loss: 3.0929647662933744
Validation loss: 2.56237037204764

Epoch: 5| Step: 3
Training loss: 2.7616035836688293
Validation loss: 2.5891906066138617

Epoch: 5| Step: 4
Training loss: 3.321875780882434
Validation loss: 2.6226002984474173

Epoch: 5| Step: 5
Training loss: 2.4626926521034584
Validation loss: 2.5519312324595167

Epoch: 5| Step: 6
Training loss: 2.5169634368265617
Validation loss: 2.5272969778576275

Epoch: 5| Step: 7
Training loss: 2.9852146744969668
Validation loss: 2.5023360930501846

Epoch: 5| Step: 8
Training loss: 2.8474574811137194
Validation loss: 2.491910107582264

Epoch: 5| Step: 9
Training loss: 3.0652061495132217
Validation loss: 2.485525713860894

Epoch: 5| Step: 10
Training loss: 2.6518673813112796
Validation loss: 2.4924710801901826

Epoch: 117| Step: 0
Training loss: 2.9320553582183995
Validation loss: 2.4988174492392345

Epoch: 5| Step: 1
Training loss: 3.0154513768631035
Validation loss: 2.502054396849966

Epoch: 5| Step: 2
Training loss: 3.0259822417227897
Validation loss: 2.505722104417291

Epoch: 5| Step: 3
Training loss: 2.393197663729058
Validation loss: 2.503450977447177

Epoch: 5| Step: 4
Training loss: 2.9333717069138805
Validation loss: 2.4969129904754648

Epoch: 5| Step: 5
Training loss: 3.4241099962409827
Validation loss: 2.4903337217295634

Epoch: 5| Step: 6
Training loss: 2.6495758580918576
Validation loss: 2.4947257221501395

Epoch: 5| Step: 7
Training loss: 2.8567698132986346
Validation loss: 2.5232613749484916

Epoch: 5| Step: 8
Training loss: 2.4769488974864373
Validation loss: 2.514549051262768

Epoch: 5| Step: 9
Training loss: 3.1501826520976763
Validation loss: 2.5158724730958966

Epoch: 5| Step: 10
Training loss: 2.6822636180016084
Validation loss: 2.5464335469875885

Epoch: 118| Step: 0
Training loss: 3.1413624974609506
Validation loss: 2.5183035484956644

Epoch: 5| Step: 1
Training loss: 3.437949827412859
Validation loss: 2.5194348434391514

Epoch: 5| Step: 2
Training loss: 2.882857490333213
Validation loss: 2.5063343779687597

Epoch: 5| Step: 3
Training loss: 3.112539090443456
Validation loss: 2.5021035686301483

Epoch: 5| Step: 4
Training loss: 2.4274711681032706
Validation loss: 2.4935258066189476

Epoch: 5| Step: 5
Training loss: 3.2108232983702067
Validation loss: 2.493763770826866

Epoch: 5| Step: 6
Training loss: 2.158333366227119
Validation loss: 2.497367065131229

Epoch: 5| Step: 7
Training loss: 2.2386376328546143
Validation loss: 2.4995819008801754

Epoch: 5| Step: 8
Training loss: 2.8727464551252293
Validation loss: 2.497442934329757

Epoch: 5| Step: 9
Training loss: 2.869058523438148
Validation loss: 2.4967320145613514

Epoch: 5| Step: 10
Training loss: 2.7190193832060117
Validation loss: 2.508153474694956

Epoch: 119| Step: 0
Training loss: 2.585532810779801
Validation loss: 2.5155034495425617

Epoch: 5| Step: 1
Training loss: 2.5120657626248466
Validation loss: 2.5112823524163947

Epoch: 5| Step: 2
Training loss: 3.212828290618719
Validation loss: 2.502300243014772

Epoch: 5| Step: 3
Training loss: 2.7862049498580546
Validation loss: 2.4973081812265745

Epoch: 5| Step: 4
Training loss: 2.6872118418372146
Validation loss: 2.496258489262291

Epoch: 5| Step: 5
Training loss: 3.3988556001791457
Validation loss: 2.494205347811151

Epoch: 5| Step: 6
Training loss: 2.8592189058315984
Validation loss: 2.496398006505342

Epoch: 5| Step: 7
Training loss: 2.864982900784846
Validation loss: 2.498944759186269

Epoch: 5| Step: 8
Training loss: 2.7050042648422834
Validation loss: 2.508925954788156

Epoch: 5| Step: 9
Training loss: 2.7623952336532875
Validation loss: 2.51770620305801

Epoch: 5| Step: 10
Training loss: 2.981022894504266
Validation loss: 2.5511932796563155

Epoch: 120| Step: 0
Training loss: 2.713220783573696
Validation loss: 2.529546379338472

Epoch: 5| Step: 1
Training loss: 3.180771101783484
Validation loss: 2.521104051790654

Epoch: 5| Step: 2
Training loss: 2.4046417410439744
Validation loss: 2.5222042108515197

Epoch: 5| Step: 3
Training loss: 2.6545479201724618
Validation loss: 2.5122628724685656

Epoch: 5| Step: 4
Training loss: 2.1051850702836705
Validation loss: 2.5090161798348714

Epoch: 5| Step: 5
Training loss: 2.915379285526843
Validation loss: 2.50456665477115

Epoch: 5| Step: 6
Training loss: 2.979567085157442
Validation loss: 2.510242689133771

Epoch: 5| Step: 7
Training loss: 2.987514901223788
Validation loss: 2.5113176684469036

Epoch: 5| Step: 8
Training loss: 2.8728659629266353
Validation loss: 2.510545492323996

Epoch: 5| Step: 9
Training loss: 3.2018565573934654
Validation loss: 2.5148717605660975

Epoch: 5| Step: 10
Training loss: 3.1115943234463606
Validation loss: 2.5132313425880275

Epoch: 121| Step: 0
Training loss: 2.496179618015155
Validation loss: 2.5079152689284117

Epoch: 5| Step: 1
Training loss: 2.339174611189447
Validation loss: 2.5163414771189054

Epoch: 5| Step: 2
Training loss: 3.559007907388107
Validation loss: 2.5258047300821196

Epoch: 5| Step: 3
Training loss: 2.240608430213259
Validation loss: 2.5189035134615643

Epoch: 5| Step: 4
Training loss: 3.025691333304439
Validation loss: 2.5148845916228804

Epoch: 5| Step: 5
Training loss: 2.744392052260615
Validation loss: 2.5129321316934172

Epoch: 5| Step: 6
Training loss: 3.2164811220829232
Validation loss: 2.509289217000772

Epoch: 5| Step: 7
Training loss: 2.883532922558457
Validation loss: 2.5186045723234822

Epoch: 5| Step: 8
Training loss: 3.2296624244045
Validation loss: 2.5087219190210055

Epoch: 5| Step: 9
Training loss: 2.8959153710323857
Validation loss: 2.50627130427714

Epoch: 5| Step: 10
Training loss: 2.3107183655584684
Validation loss: 2.5042693139010024

Epoch: 122| Step: 0
Training loss: 2.9242410310899745
Validation loss: 2.495626684188033

Epoch: 5| Step: 1
Training loss: 3.062725136714283
Validation loss: 2.5049158750703326

Epoch: 5| Step: 2
Training loss: 2.7508923209945064
Validation loss: 2.507134513916724

Epoch: 5| Step: 3
Training loss: 2.5941129683261184
Validation loss: 2.4991685335765434

Epoch: 5| Step: 4
Training loss: 3.0919130054094373
Validation loss: 2.5028753593503117

Epoch: 5| Step: 5
Training loss: 3.0454342296652537
Validation loss: 2.507335667728262

Epoch: 5| Step: 6
Training loss: 2.9254406067343552
Validation loss: 2.496415578343012

Epoch: 5| Step: 7
Training loss: 2.8791560112571535
Validation loss: 2.498997754012679

Epoch: 5| Step: 8
Training loss: 2.4201033480306013
Validation loss: 2.5143739685968565

Epoch: 5| Step: 9
Training loss: 2.745700335911631
Validation loss: 2.5027164283250762

Epoch: 5| Step: 10
Training loss: 2.6855031068876594
Validation loss: 2.50828531483871

Epoch: 123| Step: 0
Training loss: 3.602014343648307
Validation loss: 2.5368322520610485

Epoch: 5| Step: 1
Training loss: 2.9273615441291816
Validation loss: 2.5379585212319538

Epoch: 5| Step: 2
Training loss: 2.5480826855332723
Validation loss: 2.544202874295693

Epoch: 5| Step: 3
Training loss: 2.814453633273289
Validation loss: 2.5232036358644545

Epoch: 5| Step: 4
Training loss: 3.0695063573731365
Validation loss: 2.51942514315526

Epoch: 5| Step: 5
Training loss: 2.947052540290372
Validation loss: 2.4950643609571763

Epoch: 5| Step: 6
Training loss: 3.016363182046933
Validation loss: 2.4837538936697245

Epoch: 5| Step: 7
Training loss: 2.972000430696233
Validation loss: 2.487608044424069

Epoch: 5| Step: 8
Training loss: 2.5696725715427178
Validation loss: 2.488038591457195

Epoch: 5| Step: 9
Training loss: 2.557582416567529
Validation loss: 2.4822925671332814

Epoch: 5| Step: 10
Training loss: 1.7819800637539627
Validation loss: 2.491447662689598

Epoch: 124| Step: 0
Training loss: 2.7009649742253576
Validation loss: 2.5019572707536972

Epoch: 5| Step: 1
Training loss: 3.1653887194528347
Validation loss: 2.5139884621562327

Epoch: 5| Step: 2
Training loss: 3.4161007730418533
Validation loss: 2.5148609035061256

Epoch: 5| Step: 3
Training loss: 2.721272493198498
Validation loss: 2.518393990332548

Epoch: 5| Step: 4
Training loss: 2.729053310534758
Validation loss: 2.4951993138360917

Epoch: 5| Step: 5
Training loss: 2.969920680467174
Validation loss: 2.52227949659844

Epoch: 5| Step: 6
Training loss: 2.5027341196945105
Validation loss: 2.5219616152723567

Epoch: 5| Step: 7
Training loss: 2.5341917298605976
Validation loss: 2.5543021141298246

Epoch: 5| Step: 8
Training loss: 2.996623682457091
Validation loss: 2.5496517847251705

Epoch: 5| Step: 9
Training loss: 2.68997628325604
Validation loss: 2.5534817033632398

Epoch: 5| Step: 10
Training loss: 2.6413391772704133
Validation loss: 2.5116680996691763

Epoch: 125| Step: 0
Training loss: 2.8776622553467193
Validation loss: 2.507953722497909

Epoch: 5| Step: 1
Training loss: 3.2461122588032794
Validation loss: 2.4967254081311956

Epoch: 5| Step: 2
Training loss: 2.3804964410105853
Validation loss: 2.49314530270941

Epoch: 5| Step: 3
Training loss: 2.9753393027812485
Validation loss: 2.4854018331853736

Epoch: 5| Step: 4
Training loss: 3.0328364988907506
Validation loss: 2.4878073527742375

Epoch: 5| Step: 5
Training loss: 2.692811640535332
Validation loss: 2.484349588161139

Epoch: 5| Step: 6
Training loss: 2.6960478290990224
Validation loss: 2.48596467042293

Epoch: 5| Step: 7
Training loss: 2.8765820006828995
Validation loss: 2.4869251336621976

Epoch: 5| Step: 8
Training loss: 3.057199055418722
Validation loss: 2.4852263950508022

Epoch: 5| Step: 9
Training loss: 2.5851838549341624
Validation loss: 2.4880590476303768

Epoch: 5| Step: 10
Training loss: 2.561753978527736
Validation loss: 2.4823883806457547

Epoch: 126| Step: 0
Training loss: 2.944407356876344
Validation loss: 2.4895807860815324

Epoch: 5| Step: 1
Training loss: 3.12249441789261
Validation loss: 2.4965716799646516

Epoch: 5| Step: 2
Training loss: 2.880525338155331
Validation loss: 2.4964714570122277

Epoch: 5| Step: 3
Training loss: 3.1600234636811835
Validation loss: 2.5065609915523477

Epoch: 5| Step: 4
Training loss: 2.7128468586169965
Validation loss: 2.5340115356107633

Epoch: 5| Step: 5
Training loss: 2.373817751913427
Validation loss: 2.5542071926038354

Epoch: 5| Step: 6
Training loss: 2.7158796570736605
Validation loss: 2.5242008553256703

Epoch: 5| Step: 7
Training loss: 2.432675796225427
Validation loss: 2.513823757390367

Epoch: 5| Step: 8
Training loss: 2.8637220347856895
Validation loss: 2.4939345829430213

Epoch: 5| Step: 9
Training loss: 3.1327373086557935
Validation loss: 2.4948475995189363

Epoch: 5| Step: 10
Training loss: 2.6599888237739906
Validation loss: 2.4830892925951815

Epoch: 127| Step: 0
Training loss: 2.734348057205431
Validation loss: 2.488030639954166

Epoch: 5| Step: 1
Training loss: 2.5575881029990053
Validation loss: 2.491761314028603

Epoch: 5| Step: 2
Training loss: 3.0465806085242253
Validation loss: 2.487232233044443

Epoch: 5| Step: 3
Training loss: 2.530811413102803
Validation loss: 2.4896049407613075

Epoch: 5| Step: 4
Training loss: 2.5741252042823746
Validation loss: 2.486814364566364

Epoch: 5| Step: 5
Training loss: 2.484312332610514
Validation loss: 2.4867239494437285

Epoch: 5| Step: 6
Training loss: 3.0689563813899383
Validation loss: 2.495362739078565

Epoch: 5| Step: 7
Training loss: 2.7266948853628215
Validation loss: 2.5072572328719587

Epoch: 5| Step: 8
Training loss: 2.991829873169635
Validation loss: 2.5139480185316985

Epoch: 5| Step: 9
Training loss: 3.0473582349166075
Validation loss: 2.544398220989851

Epoch: 5| Step: 10
Training loss: 3.2520620700125566
Validation loss: 2.5242856677005685

Epoch: 128| Step: 0
Training loss: 2.201821448838647
Validation loss: 2.5160425606854395

Epoch: 5| Step: 1
Training loss: 2.6390390543011963
Validation loss: 2.5185888521147715

Epoch: 5| Step: 2
Training loss: 2.344720868251103
Validation loss: 2.4997837762746307

Epoch: 5| Step: 3
Training loss: 3.1825767343624225
Validation loss: 2.508914514599601

Epoch: 5| Step: 4
Training loss: 2.8663861144828
Validation loss: 2.5340096983763956

Epoch: 5| Step: 5
Training loss: 3.103675718121472
Validation loss: 2.538158863397447

Epoch: 5| Step: 6
Training loss: 2.863227458620318
Validation loss: 2.5475852424421093

Epoch: 5| Step: 7
Training loss: 3.4603111096350667
Validation loss: 2.522677966444263

Epoch: 5| Step: 8
Training loss: 2.9241166109453873
Validation loss: 2.502918674675752

Epoch: 5| Step: 9
Training loss: 2.8106253416176985
Validation loss: 2.4924985084838203

Epoch: 5| Step: 10
Training loss: 2.6607388434003703
Validation loss: 2.4896133475275657

Epoch: 129| Step: 0
Training loss: 2.6121966245172206
Validation loss: 2.488960925266251

Epoch: 5| Step: 1
Training loss: 2.4646974934321775
Validation loss: 2.485445342665935

Epoch: 5| Step: 2
Training loss: 3.0810234249602533
Validation loss: 2.4946011247371453

Epoch: 5| Step: 3
Training loss: 3.2680546971089544
Validation loss: 2.516990922114515

Epoch: 5| Step: 4
Training loss: 2.745176072440741
Validation loss: 2.530146065519184

Epoch: 5| Step: 5
Training loss: 2.978082063731675
Validation loss: 2.5285940604212724

Epoch: 5| Step: 6
Training loss: 2.6995039484200425
Validation loss: 2.5036691299936575

Epoch: 5| Step: 7
Training loss: 2.8198074353531917
Validation loss: 2.4980418627508105

Epoch: 5| Step: 8
Training loss: 2.7637698745875596
Validation loss: 2.4845418762433265

Epoch: 5| Step: 9
Training loss: 2.790011289977061
Validation loss: 2.4878838720975103

Epoch: 5| Step: 10
Training loss: 2.685224590036742
Validation loss: 2.500154648376297

Epoch: 130| Step: 0
Training loss: 2.971094911962779
Validation loss: 2.497696362770622

Epoch: 5| Step: 1
Training loss: 2.7897490182740343
Validation loss: 2.494811179973866

Epoch: 5| Step: 2
Training loss: 3.0525737971602545
Validation loss: 2.5170065005426414

Epoch: 5| Step: 3
Training loss: 2.861024474608968
Validation loss: 2.53793341661527

Epoch: 5| Step: 4
Training loss: 2.935796365395983
Validation loss: 2.501929846762565

Epoch: 5| Step: 5
Training loss: 2.9428308692108476
Validation loss: 2.491599744863215

Epoch: 5| Step: 6
Training loss: 2.852134668089323
Validation loss: 2.4848232049438015

Epoch: 5| Step: 7
Training loss: 2.6410960843779434
Validation loss: 2.4794434637375624

Epoch: 5| Step: 8
Training loss: 2.7391448352927483
Validation loss: 2.487924810519907

Epoch: 5| Step: 9
Training loss: 2.8168635955979187
Validation loss: 2.4879555986467308

Epoch: 5| Step: 10
Training loss: 2.362693322562349
Validation loss: 2.4900947697993683

Epoch: 131| Step: 0
Training loss: 2.421067133877527
Validation loss: 2.488283111725597

Epoch: 5| Step: 1
Training loss: 2.7052130600089015
Validation loss: 2.5035189678373144

Epoch: 5| Step: 2
Training loss: 2.6410169141315167
Validation loss: 2.5110847531503855

Epoch: 5| Step: 3
Training loss: 3.1145262101632643
Validation loss: 2.5448790418905713

Epoch: 5| Step: 4
Training loss: 2.3419768683433806
Validation loss: 2.5597560747066908

Epoch: 5| Step: 5
Training loss: 2.8873017874719085
Validation loss: 2.561986134866548

Epoch: 5| Step: 6
Training loss: 2.6603484007327407
Validation loss: 2.5522072523183352

Epoch: 5| Step: 7
Training loss: 2.6663202020959487
Validation loss: 2.566679799305059

Epoch: 5| Step: 8
Training loss: 3.630675247062699
Validation loss: 2.5274643597969075

Epoch: 5| Step: 9
Training loss: 2.982610530419933
Validation loss: 2.4988531938129612

Epoch: 5| Step: 10
Training loss: 2.6737407394184607
Validation loss: 2.48743709984116

Epoch: 132| Step: 0
Training loss: 2.8937463352517967
Validation loss: 2.4846398224106125

Epoch: 5| Step: 1
Training loss: 3.061608009447915
Validation loss: 2.4780837751673794

Epoch: 5| Step: 2
Training loss: 2.7501830993732264
Validation loss: 2.4967906307180625

Epoch: 5| Step: 3
Training loss: 3.110806236390922
Validation loss: 2.488675202133488

Epoch: 5| Step: 4
Training loss: 2.516661057455452
Validation loss: 2.485422185736583

Epoch: 5| Step: 5
Training loss: 2.648259609853543
Validation loss: 2.5013209575505044

Epoch: 5| Step: 6
Training loss: 2.3354282398146973
Validation loss: 2.5060905970286758

Epoch: 5| Step: 7
Training loss: 2.4873599947534246
Validation loss: 2.516551657326997

Epoch: 5| Step: 8
Training loss: 2.9208367282849514
Validation loss: 2.5144346408455522

Epoch: 5| Step: 9
Training loss: 3.0696895054668225
Validation loss: 2.5068948144080796

Epoch: 5| Step: 10
Training loss: 2.9751859270227135
Validation loss: 2.502206425520988

Epoch: 133| Step: 0
Training loss: 2.851078525389045
Validation loss: 2.4977758583961442

Epoch: 5| Step: 1
Training loss: 3.177339854072713
Validation loss: 2.493710842622374

Epoch: 5| Step: 2
Training loss: 2.1835682002502335
Validation loss: 2.4891594280332927

Epoch: 5| Step: 3
Training loss: 2.946415621246018
Validation loss: 2.48902927644788

Epoch: 5| Step: 4
Training loss: 2.432693437371321
Validation loss: 2.475623095516424

Epoch: 5| Step: 5
Training loss: 2.518620952016989
Validation loss: 2.4921478001896595

Epoch: 5| Step: 6
Training loss: 2.8748777612324337
Validation loss: 2.483718369437246

Epoch: 5| Step: 7
Training loss: 2.483770812839645
Validation loss: 2.4877691628191023

Epoch: 5| Step: 8
Training loss: 3.094642587463151
Validation loss: 2.507027372127284

Epoch: 5| Step: 9
Training loss: 3.276726065479218
Validation loss: 2.527144036611683

Epoch: 5| Step: 10
Training loss: 2.7281809378326107
Validation loss: 2.572114156119973

Epoch: 134| Step: 0
Training loss: 3.0163840489927782
Validation loss: 2.601577239921871

Epoch: 5| Step: 1
Training loss: 2.887507556723743
Validation loss: 2.5918751629746914

Epoch: 5| Step: 2
Training loss: 2.84417453154147
Validation loss: 2.566250629157943

Epoch: 5| Step: 3
Training loss: 2.5282995665912087
Validation loss: 2.538946974834179

Epoch: 5| Step: 4
Training loss: 3.105289708380465
Validation loss: 2.543259971721912

Epoch: 5| Step: 5
Training loss: 2.775690501453139
Validation loss: 2.540513900008559

Epoch: 5| Step: 6
Training loss: 2.558847196416655
Validation loss: 2.559709536767597

Epoch: 5| Step: 7
Training loss: 2.851662495571217
Validation loss: 2.5527926181167233

Epoch: 5| Step: 8
Training loss: 3.0021713663959972
Validation loss: 2.5230487318413317

Epoch: 5| Step: 9
Training loss: 2.833080355252284
Validation loss: 2.511902090676585

Epoch: 5| Step: 10
Training loss: 2.495339531892413
Validation loss: 2.49808530190968

Epoch: 135| Step: 0
Training loss: 3.1216993066724568
Validation loss: 2.5083479515546125

Epoch: 5| Step: 1
Training loss: 2.8124853345700545
Validation loss: 2.5292354443089664

Epoch: 5| Step: 2
Training loss: 3.028515870620637
Validation loss: 2.612162330818992

Epoch: 5| Step: 3
Training loss: 2.727459691603843
Validation loss: 2.639083667799603

Epoch: 5| Step: 4
Training loss: 2.8146087370506554
Validation loss: 2.64010771065405

Epoch: 5| Step: 5
Training loss: 2.857581070945559
Validation loss: 2.6400985819252543

Epoch: 5| Step: 6
Training loss: 2.629437737211758
Validation loss: 2.5872010411671407

Epoch: 5| Step: 7
Training loss: 3.29676594486027
Validation loss: 2.552423693470774

Epoch: 5| Step: 8
Training loss: 2.599333211788081
Validation loss: 2.5087313265329585

Epoch: 5| Step: 9
Training loss: 2.5413829353264545
Validation loss: 2.496691337608242

Epoch: 5| Step: 10
Training loss: 2.9795416393696037
Validation loss: 2.497959927881291

Epoch: 136| Step: 0
Training loss: 2.5457328622558255
Validation loss: 2.4767712966063837

Epoch: 5| Step: 1
Training loss: 3.1040026388845336
Validation loss: 2.4748918172213403

Epoch: 5| Step: 2
Training loss: 2.704966276314689
Validation loss: 2.4757834178543447

Epoch: 5| Step: 3
Training loss: 3.3868170243274753
Validation loss: 2.4748264681150647

Epoch: 5| Step: 4
Training loss: 3.0281951297792147
Validation loss: 2.490632530712896

Epoch: 5| Step: 5
Training loss: 2.7329640263054307
Validation loss: 2.517113445707589

Epoch: 5| Step: 6
Training loss: 2.345785655682809
Validation loss: 2.556722199440845

Epoch: 5| Step: 7
Training loss: 2.5986226284855407
Validation loss: 2.6832224225716095

Epoch: 5| Step: 8
Training loss: 3.0715689769602457
Validation loss: 2.8658008587098904

Epoch: 5| Step: 9
Training loss: 3.1916720444224764
Validation loss: 2.8880509400542165

Epoch: 5| Step: 10
Training loss: 2.961070357187969
Validation loss: 2.5758121441486517

Epoch: 137| Step: 0
Training loss: 2.4980478294197748
Validation loss: 2.486354309521049

Epoch: 5| Step: 1
Training loss: 2.865395133846515
Validation loss: 2.4943396554677375

Epoch: 5| Step: 2
Training loss: 2.516030888954582
Validation loss: 2.519746380456561

Epoch: 5| Step: 3
Training loss: 2.667233188374153
Validation loss: 2.547596718286557

Epoch: 5| Step: 4
Training loss: 2.9013246207644037
Validation loss: 2.5575495917881277

Epoch: 5| Step: 5
Training loss: 3.7459094307496152
Validation loss: 2.585436740371698

Epoch: 5| Step: 6
Training loss: 2.472534658808157
Validation loss: 2.5435434456361214

Epoch: 5| Step: 7
Training loss: 2.8406872028049284
Validation loss: 2.525114893708103

Epoch: 5| Step: 8
Training loss: 3.342330203369274
Validation loss: 2.5183135249055684

Epoch: 5| Step: 9
Training loss: 3.098351495561998
Validation loss: 2.51172311847174

Epoch: 5| Step: 10
Training loss: 2.9233564405350863
Validation loss: 2.508930418041571

Epoch: 138| Step: 0
Training loss: 2.5595070642998676
Validation loss: 2.5036477989045824

Epoch: 5| Step: 1
Training loss: 2.539742528376275
Validation loss: 2.4998492554367604

Epoch: 5| Step: 2
Training loss: 2.414818111543977
Validation loss: 2.49477254335422

Epoch: 5| Step: 3
Training loss: 3.158060593181372
Validation loss: 2.491426987382709

Epoch: 5| Step: 4
Training loss: 2.6959313608198925
Validation loss: 2.4810717356788587

Epoch: 5| Step: 5
Training loss: 3.3245581197031555
Validation loss: 2.485015830863171

Epoch: 5| Step: 6
Training loss: 3.073801014691335
Validation loss: 2.492065561974618

Epoch: 5| Step: 7
Training loss: 2.598748595515794
Validation loss: 2.492240694059331

Epoch: 5| Step: 8
Training loss: 2.9293264751513206
Validation loss: 2.513187116583251

Epoch: 5| Step: 9
Training loss: 2.826874598811558
Validation loss: 2.5318577587631883

Epoch: 5| Step: 10
Training loss: 3.0546803193849428
Validation loss: 2.5634295140571783

Epoch: 139| Step: 0
Training loss: 2.6522565554864044
Validation loss: 2.5981611135165736

Epoch: 5| Step: 1
Training loss: 3.1042852869773965
Validation loss: 2.6018748358418637

Epoch: 5| Step: 2
Training loss: 2.5667902689645437
Validation loss: 2.549135613201855

Epoch: 5| Step: 3
Training loss: 2.8879302790037573
Validation loss: 2.526664817544874

Epoch: 5| Step: 4
Training loss: 3.1469100389547084
Validation loss: 2.5028337599945973

Epoch: 5| Step: 5
Training loss: 2.400081009292347
Validation loss: 2.489082258883888

Epoch: 5| Step: 6
Training loss: 2.773801709828148
Validation loss: 2.4915435542339908

Epoch: 5| Step: 7
Training loss: 2.538086031436368
Validation loss: 2.48268057688766

Epoch: 5| Step: 8
Training loss: 3.2001614887497705
Validation loss: 2.470465602285236

Epoch: 5| Step: 9
Training loss: 2.7400872428258776
Validation loss: 2.475804095400571

Epoch: 5| Step: 10
Training loss: 2.9267482000071543
Validation loss: 2.471887235086285

Epoch: 140| Step: 0
Training loss: 3.311344449002025
Validation loss: 2.4819773845540807

Epoch: 5| Step: 1
Training loss: 2.895158501537254
Validation loss: 2.498034898540217

Epoch: 5| Step: 2
Training loss: 2.7897287636174317
Validation loss: 2.516278000183876

Epoch: 5| Step: 3
Training loss: 3.1196554639291576
Validation loss: 2.5179388347173752

Epoch: 5| Step: 4
Training loss: 2.740763759253852
Validation loss: 2.525358239599044

Epoch: 5| Step: 5
Training loss: 2.3351893422962045
Validation loss: 2.535924498834231

Epoch: 5| Step: 6
Training loss: 2.6263968974322593
Validation loss: 2.561026006434531

Epoch: 5| Step: 7
Training loss: 2.8386869527516865
Validation loss: 2.6007454280780182

Epoch: 5| Step: 8
Training loss: 2.456956240626453
Validation loss: 2.571093492508576

Epoch: 5| Step: 9
Training loss: 2.901789369685627
Validation loss: 2.5299338440111057

Epoch: 5| Step: 10
Training loss: 2.5051031480518224
Validation loss: 2.543101704630444

Epoch: 141| Step: 0
Training loss: 2.813670444660281
Validation loss: 2.504846395577127

Epoch: 5| Step: 1
Training loss: 2.916049801216754
Validation loss: 2.4817380970244147

Epoch: 5| Step: 2
Training loss: 2.7874280911737177
Validation loss: 2.4826581237156455

Epoch: 5| Step: 3
Training loss: 2.656893573661067
Validation loss: 2.484976030921912

Epoch: 5| Step: 4
Training loss: 2.97307472441504
Validation loss: 2.486024304590027

Epoch: 5| Step: 5
Training loss: 2.0609509980263647
Validation loss: 2.4771683324803506

Epoch: 5| Step: 6
Training loss: 2.945588035748172
Validation loss: 2.4885685368304067

Epoch: 5| Step: 7
Training loss: 3.0763519912546875
Validation loss: 2.487267568975855

Epoch: 5| Step: 8
Training loss: 2.9559559649644784
Validation loss: 2.488437708391452

Epoch: 5| Step: 9
Training loss: 3.055492558456046
Validation loss: 2.4891682925581646

Epoch: 5| Step: 10
Training loss: 2.72384788235767
Validation loss: 2.487397999289487

Epoch: 142| Step: 0
Training loss: 2.404324144817681
Validation loss: 2.4812002630237417

Epoch: 5| Step: 1
Training loss: 2.984032895916795
Validation loss: 2.479191576683565

Epoch: 5| Step: 2
Training loss: 2.386978659705027
Validation loss: 2.496738735975149

Epoch: 5| Step: 3
Training loss: 2.224866575891143
Validation loss: 2.504445089663681

Epoch: 5| Step: 4
Training loss: 2.7292565095590966
Validation loss: 2.5108325142203896

Epoch: 5| Step: 5
Training loss: 2.948307366423029
Validation loss: 2.520832401100203

Epoch: 5| Step: 6
Training loss: 2.8662142647978985
Validation loss: 2.522584315346545

Epoch: 5| Step: 7
Training loss: 3.6812488134929513
Validation loss: 2.547359454449594

Epoch: 5| Step: 8
Training loss: 3.1613776224424197
Validation loss: 2.5418816204414427

Epoch: 5| Step: 9
Training loss: 2.3815516403465216
Validation loss: 2.5420212447064667

Epoch: 5| Step: 10
Training loss: 2.6793290056926287
Validation loss: 2.5405544888412175

Epoch: 143| Step: 0
Training loss: 2.976793495486462
Validation loss: 2.530174685283407

Epoch: 5| Step: 1
Training loss: 2.732309313208231
Validation loss: 2.5487759962744048

Epoch: 5| Step: 2
Training loss: 2.9410653087702183
Validation loss: 2.5581022492968444

Epoch: 5| Step: 3
Training loss: 3.0017888775618617
Validation loss: 2.535483903591863

Epoch: 5| Step: 4
Training loss: 2.395316314196551
Validation loss: 2.5190107658386847

Epoch: 5| Step: 5
Training loss: 3.291588327626481
Validation loss: 2.5199445396488827

Epoch: 5| Step: 6
Training loss: 2.293461657286558
Validation loss: 2.5168862594667627

Epoch: 5| Step: 7
Training loss: 2.8458264493696097
Validation loss: 2.513712793223977

Epoch: 5| Step: 8
Training loss: 2.745782739600564
Validation loss: 2.51461961655827

Epoch: 5| Step: 9
Training loss: 2.832532619951767
Validation loss: 2.511119183253068

Epoch: 5| Step: 10
Training loss: 2.43896557690492
Validation loss: 2.497954167287889

Epoch: 144| Step: 0
Training loss: 2.824252264264538
Validation loss: 2.4964132071636738

Epoch: 5| Step: 1
Training loss: 2.821710044796293
Validation loss: 2.4932978447937404

Epoch: 5| Step: 2
Training loss: 2.457541020187814
Validation loss: 2.4819817268723754

Epoch: 5| Step: 3
Training loss: 2.669098599467468
Validation loss: 2.4716848092171895

Epoch: 5| Step: 4
Training loss: 2.821587947807173
Validation loss: 2.4767754948614344

Epoch: 5| Step: 5
Training loss: 2.5767931648118734
Validation loss: 2.4660929000778005

Epoch: 5| Step: 6
Training loss: 2.518261588097318
Validation loss: 2.4829311218838206

Epoch: 5| Step: 7
Training loss: 3.176923670691415
Validation loss: 2.4915884741191507

Epoch: 5| Step: 8
Training loss: 2.528694086894501
Validation loss: 2.5061500683851308

Epoch: 5| Step: 9
Training loss: 3.075674252905426
Validation loss: 2.5344044303578652

Epoch: 5| Step: 10
Training loss: 3.0223699059898035
Validation loss: 2.546302850424182

Epoch: 145| Step: 0
Training loss: 2.400691858545932
Validation loss: 2.5305483610403035

Epoch: 5| Step: 1
Training loss: 3.0728277333639555
Validation loss: 2.53823548888527

Epoch: 5| Step: 2
Training loss: 2.4181449468504304
Validation loss: 2.5316139120631966

Epoch: 5| Step: 3
Training loss: 2.4606907312103052
Validation loss: 2.5451054387430654

Epoch: 5| Step: 4
Training loss: 2.6379930369854265
Validation loss: 2.5408956392768807

Epoch: 5| Step: 5
Training loss: 2.682288506268365
Validation loss: 2.5343685519431016

Epoch: 5| Step: 6
Training loss: 2.8641168017944536
Validation loss: 2.5480774366741805

Epoch: 5| Step: 7
Training loss: 3.0223579154998776
Validation loss: 2.5538487806994943

Epoch: 5| Step: 8
Training loss: 3.0442324402897842
Validation loss: 2.5556631015097717

Epoch: 5| Step: 9
Training loss: 3.081135163865788
Validation loss: 2.494417074612594

Epoch: 5| Step: 10
Training loss: 2.831432116042832
Validation loss: 2.4817072947770096

Epoch: 146| Step: 0
Training loss: 2.634346263362227
Validation loss: 2.4700653406037882

Epoch: 5| Step: 1
Training loss: 2.870453100026315
Validation loss: 2.4701177635548284

Epoch: 5| Step: 2
Training loss: 3.076163039421835
Validation loss: 2.4737843224424547

Epoch: 5| Step: 3
Training loss: 2.892559497059786
Validation loss: 2.4732724998263844

Epoch: 5| Step: 4
Training loss: 2.631020771108459
Validation loss: 2.474811957367032

Epoch: 5| Step: 5
Training loss: 2.9444920538006243
Validation loss: 2.485278411555248

Epoch: 5| Step: 6
Training loss: 2.354190409942894
Validation loss: 2.504392942022225

Epoch: 5| Step: 7
Training loss: 2.8608584698814417
Validation loss: 2.5039465988348617

Epoch: 5| Step: 8
Training loss: 3.2650995881342686
Validation loss: 2.508780050667276

Epoch: 5| Step: 9
Training loss: 2.3663883685862355
Validation loss: 2.5037453816217354

Epoch: 5| Step: 10
Training loss: 2.3260211014909773
Validation loss: 2.508967922135718

Epoch: 147| Step: 0
Training loss: 2.2996407808829304
Validation loss: 2.5038678704457666

Epoch: 5| Step: 1
Training loss: 3.0761216513757224
Validation loss: 2.4943941042630864

Epoch: 5| Step: 2
Training loss: 2.480910470634856
Validation loss: 2.507650320095203

Epoch: 5| Step: 3
Training loss: 2.648750939290275
Validation loss: 2.4890313559687316

Epoch: 5| Step: 4
Training loss: 2.2746541022296203
Validation loss: 2.4806684107962895

Epoch: 5| Step: 5
Training loss: 2.758724764184337
Validation loss: 2.4676301762507475

Epoch: 5| Step: 6
Training loss: 2.9033876495302557
Validation loss: 2.472432810320669

Epoch: 5| Step: 7
Training loss: 3.3311245434810943
Validation loss: 2.458413800785292

Epoch: 5| Step: 8
Training loss: 2.7429666743519188
Validation loss: 2.4694044108491497

Epoch: 5| Step: 9
Training loss: 2.571303898195902
Validation loss: 2.4623937040534085

Epoch: 5| Step: 10
Training loss: 3.1361820811720498
Validation loss: 2.4794650330435224

Epoch: 148| Step: 0
Training loss: 2.072958813211679
Validation loss: 2.491839780880289

Epoch: 5| Step: 1
Training loss: 2.889541340371313
Validation loss: 2.538349193149385

Epoch: 5| Step: 2
Training loss: 2.5346455346152488
Validation loss: 2.562518430133835

Epoch: 5| Step: 3
Training loss: 2.5343500627638447
Validation loss: 2.608988809895089

Epoch: 5| Step: 4
Training loss: 2.662432756604599
Validation loss: 2.635686195641211

Epoch: 5| Step: 5
Training loss: 2.8143451995593423
Validation loss: 2.6156015904221266

Epoch: 5| Step: 6
Training loss: 3.156902132553989
Validation loss: 2.5968221298100955

Epoch: 5| Step: 7
Training loss: 2.774864581816239
Validation loss: 2.5616998741398356

Epoch: 5| Step: 8
Training loss: 3.031135635578186
Validation loss: 2.5107130940167237

Epoch: 5| Step: 9
Training loss: 2.7552675602585825
Validation loss: 2.492357980932454

Epoch: 5| Step: 10
Training loss: 2.8617165571991157
Validation loss: 2.4866957595085775

Epoch: 149| Step: 0
Training loss: 2.2449008593513993
Validation loss: 2.4751887037296227

Epoch: 5| Step: 1
Training loss: 2.981488334677722
Validation loss: 2.471569146888916

Epoch: 5| Step: 2
Training loss: 2.7971363478300537
Validation loss: 2.4834624957283795

Epoch: 5| Step: 3
Training loss: 2.8510893964877946
Validation loss: 2.4875772890964356

Epoch: 5| Step: 4
Training loss: 2.624510219839688
Validation loss: 2.4945067710309106

Epoch: 5| Step: 5
Training loss: 2.488399005780422
Validation loss: 2.496373534503833

Epoch: 5| Step: 6
Training loss: 2.4015352703032486
Validation loss: 2.508485910342163

Epoch: 5| Step: 7
Training loss: 2.550859014894235
Validation loss: 2.5170251537883193

Epoch: 5| Step: 8
Training loss: 2.7121511595412464
Validation loss: 2.520112922122267

Epoch: 5| Step: 9
Training loss: 3.1537320508230677
Validation loss: 2.5350585253271523

Epoch: 5| Step: 10
Training loss: 3.1906046987218364
Validation loss: 2.5460897231952986

Epoch: 150| Step: 0
Training loss: 2.8380497404098692
Validation loss: 2.5265525356251

Epoch: 5| Step: 1
Training loss: 2.7233897990143623
Validation loss: 2.5023020315587536

Epoch: 5| Step: 2
Training loss: 2.9629379399443914
Validation loss: 2.5029416221019254

Epoch: 5| Step: 3
Training loss: 2.259868596400695
Validation loss: 2.4774944766675007

Epoch: 5| Step: 4
Training loss: 2.4190681189178704
Validation loss: 2.47726954438789

Epoch: 5| Step: 5
Training loss: 2.554496921348546
Validation loss: 2.485209204174736

Epoch: 5| Step: 6
Training loss: 3.165997702226028
Validation loss: 2.4981380543083747

Epoch: 5| Step: 7
Training loss: 2.85287687762403
Validation loss: 2.493415436656618

Epoch: 5| Step: 8
Training loss: 2.558273178867895
Validation loss: 2.5025516357795454

Epoch: 5| Step: 9
Training loss: 2.8151914645953164
Validation loss: 2.490748415288422

Epoch: 5| Step: 10
Training loss: 2.8255227272039063
Validation loss: 2.483026802863447

Epoch: 151| Step: 0
Training loss: 3.1348588685996055
Validation loss: 2.481669227885656

Epoch: 5| Step: 1
Training loss: 2.867366774772515
Validation loss: 2.4716710610438772

Epoch: 5| Step: 2
Training loss: 2.313662468786278
Validation loss: 2.479979889341911

Epoch: 5| Step: 3
Training loss: 3.0841634165689955
Validation loss: 2.4805459504422935

Epoch: 5| Step: 4
Training loss: 2.3102791922154964
Validation loss: 2.4925836641765144

Epoch: 5| Step: 5
Training loss: 2.660659809597237
Validation loss: 2.491635275051164

Epoch: 5| Step: 6
Training loss: 2.7717628258475226
Validation loss: 2.518842712221135

Epoch: 5| Step: 7
Training loss: 3.207689410568812
Validation loss: 2.5465785894054687

Epoch: 5| Step: 8
Training loss: 2.495337334343878
Validation loss: 2.6080590050739723

Epoch: 5| Step: 9
Training loss: 2.560786162601018
Validation loss: 2.5477739090682445

Epoch: 5| Step: 10
Training loss: 2.6276209326298345
Validation loss: 2.5337295247788516

Epoch: 152| Step: 0
Training loss: 3.0331819021412234
Validation loss: 2.4983702567052855

Epoch: 5| Step: 1
Training loss: 2.419796353118164
Validation loss: 2.4919691632772527

Epoch: 5| Step: 2
Training loss: 2.6303165728263416
Validation loss: 2.4848191802026456

Epoch: 5| Step: 3
Training loss: 2.748775816584111
Validation loss: 2.498441805337498

Epoch: 5| Step: 4
Training loss: 1.9437616133266287
Validation loss: 2.4992528465475274

Epoch: 5| Step: 5
Training loss: 2.4493576570146547
Validation loss: 2.5015923750862163

Epoch: 5| Step: 6
Training loss: 3.1173585161225827
Validation loss: 2.5031915647807996

Epoch: 5| Step: 7
Training loss: 3.3025712255497384
Validation loss: 2.5186333364684486

Epoch: 5| Step: 8
Training loss: 2.3845784631715277
Validation loss: 2.5424244492557273

Epoch: 5| Step: 9
Training loss: 2.785988018713914
Validation loss: 2.54957497444887

Epoch: 5| Step: 10
Training loss: 2.804356547516625
Validation loss: 2.54252560036694

Epoch: 153| Step: 0
Training loss: 2.782186886152028
Validation loss: 2.5144348875813365

Epoch: 5| Step: 1
Training loss: 2.8637398512555126
Validation loss: 2.49119435700304

Epoch: 5| Step: 2
Training loss: 2.989712241624556
Validation loss: 2.4760942980201204

Epoch: 5| Step: 3
Training loss: 2.6702635964278807
Validation loss: 2.4720805506133003

Epoch: 5| Step: 4
Training loss: 2.533128018173878
Validation loss: 2.4680323255316017

Epoch: 5| Step: 5
Training loss: 2.7465882378402093
Validation loss: 2.486287023149176

Epoch: 5| Step: 6
Training loss: 3.101350483986601
Validation loss: 2.4988076083885535

Epoch: 5| Step: 7
Training loss: 2.1936663228565907
Validation loss: 2.5412352791130672

Epoch: 5| Step: 8
Training loss: 2.7653891252697433
Validation loss: 2.563420751320572

Epoch: 5| Step: 9
Training loss: 2.627700415752349
Validation loss: 2.5964841845992863

Epoch: 5| Step: 10
Training loss: 2.4398517512014077
Validation loss: 2.6024746451035683

Epoch: 154| Step: 0
Training loss: 2.9858811657121245
Validation loss: 2.635843639196912

Epoch: 5| Step: 1
Training loss: 2.5240590183413043
Validation loss: 2.590327570192508

Epoch: 5| Step: 2
Training loss: 2.5813269873861593
Validation loss: 2.561166169553763

Epoch: 5| Step: 3
Training loss: 2.788556905274238
Validation loss: 2.5352600936949927

Epoch: 5| Step: 4
Training loss: 2.4873004699120114
Validation loss: 2.5215814799453407

Epoch: 5| Step: 5
Training loss: 2.9017098351922384
Validation loss: 2.5245410524431353

Epoch: 5| Step: 6
Training loss: 3.1130060052712683
Validation loss: 2.5349088866334686

Epoch: 5| Step: 7
Training loss: 2.4644838968200924
Validation loss: 2.5168981054809856

Epoch: 5| Step: 8
Training loss: 2.6968620821576033
Validation loss: 2.509433305758941

Epoch: 5| Step: 9
Training loss: 2.5226381529829065
Validation loss: 2.501524480932636

Epoch: 5| Step: 10
Training loss: 2.5304428509113808
Validation loss: 2.496620409340242

Epoch: 155| Step: 0
Training loss: 2.181973041832929
Validation loss: 2.469775541275935

Epoch: 5| Step: 1
Training loss: 2.858395101104134
Validation loss: 2.485803923911135

Epoch: 5| Step: 2
Training loss: 2.1743283034812335
Validation loss: 2.488965806452185

Epoch: 5| Step: 3
Training loss: 2.8671241358269963
Validation loss: 2.4854710444852297

Epoch: 5| Step: 4
Training loss: 2.796734001825224
Validation loss: 2.5245010439378266

Epoch: 5| Step: 5
Training loss: 2.391393101782858
Validation loss: 2.575858303579943

Epoch: 5| Step: 6
Training loss: 2.786892685356069
Validation loss: 2.5511849451760034

Epoch: 5| Step: 7
Training loss: 2.4142412533056006
Validation loss: 2.51681361865132

Epoch: 5| Step: 8
Training loss: 3.1449585428825917
Validation loss: 2.4950509450524425

Epoch: 5| Step: 9
Training loss: 2.681226371892221
Validation loss: 2.491078494201781

Epoch: 5| Step: 10
Training loss: 3.082844944670565
Validation loss: 2.503497692814101

Epoch: 156| Step: 0
Training loss: 2.816864949833301
Validation loss: 2.5000893325637077

Epoch: 5| Step: 1
Training loss: 2.3383138045757317
Validation loss: 2.509969406374543

Epoch: 5| Step: 2
Training loss: 2.637625169721753
Validation loss: 2.5441347105657766

Epoch: 5| Step: 3
Training loss: 2.6769665842289876
Validation loss: 2.5774587457083684

Epoch: 5| Step: 4
Training loss: 2.923625890634551
Validation loss: 2.5670316370624504

Epoch: 5| Step: 5
Training loss: 2.6988196512680873
Validation loss: 2.5352891046943755

Epoch: 5| Step: 6
Training loss: 2.3170626194460264
Validation loss: 2.5156340290942683

Epoch: 5| Step: 7
Training loss: 2.8486865446916454
Validation loss: 2.489596768747692

Epoch: 5| Step: 8
Training loss: 2.4523284979689577
Validation loss: 2.4786699331162834

Epoch: 5| Step: 9
Training loss: 3.276922078337402
Validation loss: 2.486322331270134

Epoch: 5| Step: 10
Training loss: 2.6482288199612842
Validation loss: 2.490397088921631

Epoch: 157| Step: 0
Training loss: 2.5531169018097546
Validation loss: 2.50764022765485

Epoch: 5| Step: 1
Training loss: 2.628098793216636
Validation loss: 2.514127064843696

Epoch: 5| Step: 2
Training loss: 2.7459089887169252
Validation loss: 2.522197342833742

Epoch: 5| Step: 3
Training loss: 2.3406088570011367
Validation loss: 2.5384502571986007

Epoch: 5| Step: 4
Training loss: 2.470954104254721
Validation loss: 2.5511239621589294

Epoch: 5| Step: 5
Training loss: 3.447305738523695
Validation loss: 2.5317936228321707

Epoch: 5| Step: 6
Training loss: 2.5035119185090657
Validation loss: 2.524614781873594

Epoch: 5| Step: 7
Training loss: 2.548464881473887
Validation loss: 2.530607177587979

Epoch: 5| Step: 8
Training loss: 2.638793310029537
Validation loss: 2.5124680247032525

Epoch: 5| Step: 9
Training loss: 2.630776180999471
Validation loss: 2.525872670897369

Epoch: 5| Step: 10
Training loss: 2.583291073935448
Validation loss: 2.5316855581126987

Epoch: 158| Step: 0
Training loss: 2.7231788079052426
Validation loss: 2.5561208941942013

Epoch: 5| Step: 1
Training loss: 3.190488723101263
Validation loss: 2.586108910453884

Epoch: 5| Step: 2
Training loss: 2.8385408080680086
Validation loss: 2.5718470181644095

Epoch: 5| Step: 3
Training loss: 2.592121394293467
Validation loss: 2.4961498494975514

Epoch: 5| Step: 4
Training loss: 2.6046269327958296
Validation loss: 2.4983486402586768

Epoch: 5| Step: 5
Training loss: 2.473058393659747
Validation loss: 2.4710105068275747

Epoch: 5| Step: 6
Training loss: 2.612595632162548
Validation loss: 2.481311494542529

Epoch: 5| Step: 7
Training loss: 2.0056794112763563
Validation loss: 2.4795491071890603

Epoch: 5| Step: 8
Training loss: 2.6170633315053
Validation loss: 2.4974613261734726

Epoch: 5| Step: 9
Training loss: 2.3945304534562295
Validation loss: 2.552479562310282

Epoch: 5| Step: 10
Training loss: 3.0879721585535633
Validation loss: 2.5852510880676847

Epoch: 159| Step: 0
Training loss: 2.5887771182111137
Validation loss: 2.603870808848602

Epoch: 5| Step: 1
Training loss: 2.9151103817699306
Validation loss: 2.604320965205297

Epoch: 5| Step: 2
Training loss: 2.7057381936670177
Validation loss: 2.5316422843519133

Epoch: 5| Step: 3
Training loss: 2.8286688687383905
Validation loss: 2.4696851106558246

Epoch: 5| Step: 4
Training loss: 2.4581889956068386
Validation loss: 2.452157952278062

Epoch: 5| Step: 5
Training loss: 2.5151509851292877
Validation loss: 2.451547462794086

Epoch: 5| Step: 6
Training loss: 2.756752220988017
Validation loss: 2.4542635048473955

Epoch: 5| Step: 7
Training loss: 2.965238401661243
Validation loss: 2.468188105448518

Epoch: 5| Step: 8
Training loss: 2.7286677499031597
Validation loss: 2.4522303589373666

Epoch: 5| Step: 9
Training loss: 2.4149707455966007
Validation loss: 2.4550952939982134

Epoch: 5| Step: 10
Training loss: 2.7125166545303894
Validation loss: 2.488297269861068

Epoch: 160| Step: 0
Training loss: 2.6275941655120207
Validation loss: 2.6232722896447216

Epoch: 5| Step: 1
Training loss: 2.817238609286198
Validation loss: 2.8500256829219075

Epoch: 5| Step: 2
Training loss: 2.665717721021895
Validation loss: 2.89620311610261

Epoch: 5| Step: 3
Training loss: 2.156228106843679
Validation loss: 2.6114161304583905

Epoch: 5| Step: 4
Training loss: 2.488471342817401
Validation loss: 2.4974434085755726

Epoch: 5| Step: 5
Training loss: 2.931435676338766
Validation loss: 2.4642394733330355

Epoch: 5| Step: 6
Training loss: 2.911372438823151
Validation loss: 2.4955785908089716

Epoch: 5| Step: 7
Training loss: 3.253710316120356
Validation loss: 2.5374227691783484

Epoch: 5| Step: 8
Training loss: 2.4822919257821927
Validation loss: 2.5347969830427326

Epoch: 5| Step: 9
Training loss: 3.0067774193010615
Validation loss: 2.541183184292568

Epoch: 5| Step: 10
Training loss: 2.7518696064996897
Validation loss: 2.535222897649844

Epoch: 161| Step: 0
Training loss: 2.71716279802287
Validation loss: 2.5086317365312016

Epoch: 5| Step: 1
Training loss: 2.803189868665485
Validation loss: 2.505324372895885

Epoch: 5| Step: 2
Training loss: 2.892483994976264
Validation loss: 2.5016739798831478

Epoch: 5| Step: 3
Training loss: 2.2798210789931916
Validation loss: 2.5056951395778135

Epoch: 5| Step: 4
Training loss: 2.357546167012631
Validation loss: 2.523621270816088

Epoch: 5| Step: 5
Training loss: 2.888136003477842
Validation loss: 2.55479146597767

Epoch: 5| Step: 6
Training loss: 2.648414274130736
Validation loss: 2.6180690886417546

Epoch: 5| Step: 7
Training loss: 3.2299165080708954
Validation loss: 2.686981402014871

Epoch: 5| Step: 8
Training loss: 2.7448601807663695
Validation loss: 2.698337602071636

Epoch: 5| Step: 9
Training loss: 3.0239292109645697
Validation loss: 2.6976497380473567

Epoch: 5| Step: 10
Training loss: 2.401026120966457
Validation loss: 2.625144075579729

Epoch: 162| Step: 0
Training loss: 3.0920365337666147
Validation loss: 2.563022163147826

Epoch: 5| Step: 1
Training loss: 2.8329379609946854
Validation loss: 2.5262125901062698

Epoch: 5| Step: 2
Training loss: 2.570574251430349
Validation loss: 2.496802749706581

Epoch: 5| Step: 3
Training loss: 2.775654682910359
Validation loss: 2.5141909988533624

Epoch: 5| Step: 4
Training loss: 2.2879200450691877
Validation loss: 2.4945910062229513

Epoch: 5| Step: 5
Training loss: 2.723969283850828
Validation loss: 2.478581867716066

Epoch: 5| Step: 6
Training loss: 2.2132371999744693
Validation loss: 2.480422125957827

Epoch: 5| Step: 7
Training loss: 2.06193627254011
Validation loss: 2.5121953840490097

Epoch: 5| Step: 8
Training loss: 2.8404867711443225
Validation loss: 2.5417963694523804

Epoch: 5| Step: 9
Training loss: 2.6536513238961743
Validation loss: 2.5538573915743683

Epoch: 5| Step: 10
Training loss: 2.9359875295618467
Validation loss: 2.5525019295909637

Epoch: 163| Step: 0
Training loss: 2.7809978756586142
Validation loss: 2.551618682839796

Epoch: 5| Step: 1
Training loss: 2.46156850324235
Validation loss: 2.550278488818941

Epoch: 5| Step: 2
Training loss: 2.4887524312887384
Validation loss: 2.5189877653244905

Epoch: 5| Step: 3
Training loss: 2.9032759677491335
Validation loss: 2.5273908484023675

Epoch: 5| Step: 4
Training loss: 2.4533754451737892
Validation loss: 2.5130451486643746

Epoch: 5| Step: 5
Training loss: 2.918214187615399
Validation loss: 2.519427171131263

Epoch: 5| Step: 6
Training loss: 2.4326727580151655
Validation loss: 2.51045745345362

Epoch: 5| Step: 7
Training loss: 2.5315611848167334
Validation loss: 2.50971641334272

Epoch: 5| Step: 8
Training loss: 2.3209363310700404
Validation loss: 2.5275464884221983

Epoch: 5| Step: 9
Training loss: 2.8670087129735258
Validation loss: 2.5020391126322403

Epoch: 5| Step: 10
Training loss: 2.6328701839297026
Validation loss: 2.4944246172686997

Epoch: 164| Step: 0
Training loss: 2.5539331284792195
Validation loss: 2.511347581792826

Epoch: 5| Step: 1
Training loss: 2.6587674945350783
Validation loss: 2.514865217079107

Epoch: 5| Step: 2
Training loss: 2.026369070029246
Validation loss: 2.53327560653178

Epoch: 5| Step: 3
Training loss: 3.0548627954318297
Validation loss: 2.5454279401526363

Epoch: 5| Step: 4
Training loss: 3.088818559676902
Validation loss: 2.588136869894041

Epoch: 5| Step: 5
Training loss: 2.53171092416813
Validation loss: 2.584948655611871

Epoch: 5| Step: 6
Training loss: 2.432633162928023
Validation loss: 2.590406034198722

Epoch: 5| Step: 7
Training loss: 2.8952760960719015
Validation loss: 2.582961243882455

Epoch: 5| Step: 8
Training loss: 2.180585231970523
Validation loss: 2.564618001444156

Epoch: 5| Step: 9
Training loss: 2.520496083128462
Validation loss: 2.556649218449978

Epoch: 5| Step: 10
Training loss: 2.287171086912946
Validation loss: 2.519394552368893

Epoch: 165| Step: 0
Training loss: 2.99329994976003
Validation loss: 2.4863533227732773

Epoch: 5| Step: 1
Training loss: 3.0050215021211493
Validation loss: 2.482832205863595

Epoch: 5| Step: 2
Training loss: 3.0105095203339722
Validation loss: 2.4921440321054606

Epoch: 5| Step: 3
Training loss: 2.2819324674451313
Validation loss: 2.488231935915703

Epoch: 5| Step: 4
Training loss: 2.765782066238634
Validation loss: 2.501279127356813

Epoch: 5| Step: 5
Training loss: 2.576829249429013
Validation loss: 2.500923366661353

Epoch: 5| Step: 6
Training loss: 2.145394795861275
Validation loss: 2.517231220481764

Epoch: 5| Step: 7
Training loss: 2.874784212721775
Validation loss: 2.539642280915328

Epoch: 5| Step: 8
Training loss: 2.352975515858327
Validation loss: 2.5538939578561

Epoch: 5| Step: 9
Training loss: 2.346573210105174
Validation loss: 2.568819193402998

Epoch: 5| Step: 10
Training loss: 1.996275413891252
Validation loss: 2.577615745168551

Epoch: 166| Step: 0
Training loss: 2.6889072548507897
Validation loss: 2.589517522631723

Epoch: 5| Step: 1
Training loss: 2.9646510688583585
Validation loss: 2.5487696665653305

Epoch: 5| Step: 2
Training loss: 2.1219005420254273
Validation loss: 2.509149172101565

Epoch: 5| Step: 3
Training loss: 2.5135568208602557
Validation loss: 2.5159655048632334

Epoch: 5| Step: 4
Training loss: 2.4563796691058135
Validation loss: 2.5015578246222345

Epoch: 5| Step: 5
Training loss: 2.80092766244751
Validation loss: 2.5067553618527363

Epoch: 5| Step: 6
Training loss: 2.9325950741132636
Validation loss: 2.515195217372771

Epoch: 5| Step: 7
Training loss: 2.3598512080535103
Validation loss: 2.4994570860424945

Epoch: 5| Step: 8
Training loss: 2.26616351863688
Validation loss: 2.5184250879981804

Epoch: 5| Step: 9
Training loss: 2.6064063448403108
Validation loss: 2.5145215423422473

Epoch: 5| Step: 10
Training loss: 2.5504395984885293
Validation loss: 2.536446379896412

Epoch: 167| Step: 0
Training loss: 2.3151233330452814
Validation loss: 2.5481213357985446

Epoch: 5| Step: 1
Training loss: 2.288904178078624
Validation loss: 2.553437916475112

Epoch: 5| Step: 2
Training loss: 2.5037628466028505
Validation loss: 2.6237093511049454

Epoch: 5| Step: 3
Training loss: 2.674603948062535
Validation loss: 2.7091846563701525

Epoch: 5| Step: 4
Training loss: 2.8626385184676306
Validation loss: 2.644848095002313

Epoch: 5| Step: 5
Training loss: 2.226517847516898
Validation loss: 2.5457397251861984

Epoch: 5| Step: 6
Training loss: 2.9372436736257335
Validation loss: 2.4980161814866237

Epoch: 5| Step: 7
Training loss: 2.5742826555160416
Validation loss: 2.4678049341208923

Epoch: 5| Step: 8
Training loss: 2.411150611264804
Validation loss: 2.4550836948608934

Epoch: 5| Step: 9
Training loss: 2.5938389774365604
Validation loss: 2.476372922695572

Epoch: 5| Step: 10
Training loss: 2.6145000267182006
Validation loss: 2.465503823766995

Epoch: 168| Step: 0
Training loss: 2.8442311980196133
Validation loss: 2.471924136533608

Epoch: 5| Step: 1
Training loss: 2.501782163545709
Validation loss: 2.4873327200548543

Epoch: 5| Step: 2
Training loss: 2.340416024712634
Validation loss: 2.4830979981137506

Epoch: 5| Step: 3
Training loss: 1.9028055934620909
Validation loss: 2.5146017529138147

Epoch: 5| Step: 4
Training loss: 2.749842119019729
Validation loss: 2.6069262728694245

Epoch: 5| Step: 5
Training loss: 2.9578627270254225
Validation loss: 2.6832327058828453

Epoch: 5| Step: 6
Training loss: 2.4992601253498643
Validation loss: 2.666606290643938

Epoch: 5| Step: 7
Training loss: 2.0192503743040873
Validation loss: 2.668922136382629

Epoch: 5| Step: 8
Training loss: 2.2893540128411902
Validation loss: 2.672181620452231

Epoch: 5| Step: 9
Training loss: 3.2119091633532872
Validation loss: 2.574141298411398

Epoch: 5| Step: 10
Training loss: 2.377238774434286
Validation loss: 2.4979291306689078

Epoch: 169| Step: 0
Training loss: 2.8992254209326043
Validation loss: 2.471813822581513

Epoch: 5| Step: 1
Training loss: 3.114375555109981
Validation loss: 2.467622971413518

Epoch: 5| Step: 2
Training loss: 2.2906262781574176
Validation loss: 2.4814828022194684

Epoch: 5| Step: 3
Training loss: 2.3871460577359644
Validation loss: 2.4660828090911378

Epoch: 5| Step: 4
Training loss: 2.500138660400264
Validation loss: 2.476676357834243

Epoch: 5| Step: 5
Training loss: 2.2331187311186453
Validation loss: 2.4844063831487584

Epoch: 5| Step: 6
Training loss: 1.7947923615628265
Validation loss: 2.5004026611674526

Epoch: 5| Step: 7
Training loss: 2.5338872663656336
Validation loss: 2.523737082563798

Epoch: 5| Step: 8
Training loss: 3.0474172256406487
Validation loss: 2.5633065299792466

Epoch: 5| Step: 9
Training loss: 3.0965415613411813
Validation loss: 2.5994361594210105

Epoch: 5| Step: 10
Training loss: 2.6411080003326988
Validation loss: 2.588417485185953

Epoch: 170| Step: 0
Training loss: 2.566179378706549
Validation loss: 2.585329264876857

Epoch: 5| Step: 1
Training loss: 2.354917547155345
Validation loss: 2.6006650915678646

Epoch: 5| Step: 2
Training loss: 3.0296730580214386
Validation loss: 2.567100918485757

Epoch: 5| Step: 3
Training loss: 2.2147320108635826
Validation loss: 2.5872706653604767

Epoch: 5| Step: 4
Training loss: 2.8543963003480997
Validation loss: 2.580524491140957

Epoch: 5| Step: 5
Training loss: 2.2168481762029235
Validation loss: 2.532668014915201

Epoch: 5| Step: 6
Training loss: 2.7618548023860505
Validation loss: 2.4833014540750296

Epoch: 5| Step: 7
Training loss: 2.729609407422579
Validation loss: 2.461776679386604

Epoch: 5| Step: 8
Training loss: 2.022506204979883
Validation loss: 2.4475262182373854

Epoch: 5| Step: 9
Training loss: 2.0626220667003112
Validation loss: 2.444076254420169

Epoch: 5| Step: 10
Training loss: 2.6979308747809747
Validation loss: 2.447271300635989

Epoch: 171| Step: 0
Training loss: 2.5324988404522695
Validation loss: 2.462407036565202

Epoch: 5| Step: 1
Training loss: 2.88820352942454
Validation loss: 2.49563141828017

Epoch: 5| Step: 2
Training loss: 2.46237595918655
Validation loss: 2.5741552801043066

Epoch: 5| Step: 3
Training loss: 2.380677213889909
Validation loss: 2.6067603824687047

Epoch: 5| Step: 4
Training loss: 1.8397823898547494
Validation loss: 2.5896848967266157

Epoch: 5| Step: 5
Training loss: 2.709588410487476
Validation loss: 2.5731121671654336

Epoch: 5| Step: 6
Training loss: 2.369414336517719
Validation loss: 2.504458282252181

Epoch: 5| Step: 7
Training loss: 2.704243334921126
Validation loss: 2.481097103594897

Epoch: 5| Step: 8
Training loss: 2.416940103605487
Validation loss: 2.457576379328163

Epoch: 5| Step: 9
Training loss: 2.591274780949902
Validation loss: 2.471944224105463

Epoch: 5| Step: 10
Training loss: 2.556946481895798
Validation loss: 2.4488183875294003

Epoch: 172| Step: 0
Training loss: 2.7586840584275705
Validation loss: 2.4649201990321323

Epoch: 5| Step: 1
Training loss: 2.524110875470791
Validation loss: 2.499920733025812

Epoch: 5| Step: 2
Training loss: 2.6282326910972413
Validation loss: 2.536842737689429

Epoch: 5| Step: 3
Training loss: 2.8978298815071533
Validation loss: 2.5510506531883594

Epoch: 5| Step: 4
Training loss: 2.4325106492941493
Validation loss: 2.6026868025652052

Epoch: 5| Step: 5
Training loss: 2.359247570512367
Validation loss: 2.6524908094589144

Epoch: 5| Step: 6
Training loss: 2.3780341593452134
Validation loss: 2.7014657421128443

Epoch: 5| Step: 7
Training loss: 2.1044910545965627
Validation loss: 2.6114707706130917

Epoch: 5| Step: 8
Training loss: 2.2589461176754604
Validation loss: 2.5708226126827256

Epoch: 5| Step: 9
Training loss: 2.916566483729818
Validation loss: 2.5361824243543563

Epoch: 5| Step: 10
Training loss: 2.139412752487605
Validation loss: 2.4776876630410527

Epoch: 173| Step: 0
Training loss: 2.030217656648646
Validation loss: 2.4954233896793534

Epoch: 5| Step: 1
Training loss: 2.9683840877499708
Validation loss: 2.476692073909599

Epoch: 5| Step: 2
Training loss: 2.6498868234326447
Validation loss: 2.4813364777347893

Epoch: 5| Step: 3
Training loss: 2.246839847210128
Validation loss: 2.499190544014874

Epoch: 5| Step: 4
Training loss: 2.6595375809241997
Validation loss: 2.528757110229337

Epoch: 5| Step: 5
Training loss: 2.1544637606767343
Validation loss: 2.5949126295551523

Epoch: 5| Step: 6
Training loss: 2.0523167846906336
Validation loss: 2.6168150816661564

Epoch: 5| Step: 7
Training loss: 2.7429889257738034
Validation loss: 2.660286084711676

Epoch: 5| Step: 8
Training loss: 2.2410207231372854
Validation loss: 2.706261523129231

Epoch: 5| Step: 9
Training loss: 3.006759974631155
Validation loss: 2.6283033859349123

Epoch: 5| Step: 10
Training loss: 2.3559815716824226
Validation loss: 2.5435537912175317

Epoch: 174| Step: 0
Training loss: 2.2913005420793886
Validation loss: 2.4720098142993576

Epoch: 5| Step: 1
Training loss: 1.8546757017176534
Validation loss: 2.4406865874795707

Epoch: 5| Step: 2
Training loss: 2.6707340057359756
Validation loss: 2.4622455340308904

Epoch: 5| Step: 3
Training loss: 2.201652088603122
Validation loss: 2.459407418109526

Epoch: 5| Step: 4
Training loss: 2.7064595905573436
Validation loss: 2.484438735867718

Epoch: 5| Step: 5
Training loss: 2.196886469022894
Validation loss: 2.5521418980166937

Epoch: 5| Step: 6
Training loss: 2.7833956896103373
Validation loss: 2.5682975250973152

Epoch: 5| Step: 7
Training loss: 2.9777954431582345
Validation loss: 2.6011969285382697

Epoch: 5| Step: 8
Training loss: 2.638120739103526
Validation loss: 2.658495187347017

Epoch: 5| Step: 9
Training loss: 2.7684254234318395
Validation loss: 2.6457945769396596

Epoch: 5| Step: 10
Training loss: 2.917253235462999
Validation loss: 2.6047801033995035

Epoch: 175| Step: 0
Training loss: 2.3329358670625004
Validation loss: 2.55879950980977

Epoch: 5| Step: 1
Training loss: 2.546118220129467
Validation loss: 2.519823564833515

Epoch: 5| Step: 2
Training loss: 1.9617293989165183
Validation loss: 2.519824420457472

Epoch: 5| Step: 3
Training loss: 2.8725603782211224
Validation loss: 2.5045715208966803

Epoch: 5| Step: 4
Training loss: 2.3275772576872567
Validation loss: 2.488848073368806

Epoch: 5| Step: 5
Training loss: 2.3539312351849295
Validation loss: 2.47239791872898

Epoch: 5| Step: 6
Training loss: 2.4729588038757346
Validation loss: 2.473044572265074

Epoch: 5| Step: 7
Training loss: 2.7399053831540376
Validation loss: 2.466988524565917

Epoch: 5| Step: 8
Training loss: 3.1178110976042532
Validation loss: 2.4516098645001994

Epoch: 5| Step: 9
Training loss: 2.258204020308809
Validation loss: 2.4874346087942434

Epoch: 5| Step: 10
Training loss: 2.373746340298355
Validation loss: 2.469022377308516

Epoch: 176| Step: 0
Training loss: 2.329362681084789
Validation loss: 2.499613621294879

Epoch: 5| Step: 1
Training loss: 2.278222779738332
Validation loss: 2.5258492933895904

Epoch: 5| Step: 2
Training loss: 2.1462499960897685
Validation loss: 2.542066909393804

Epoch: 5| Step: 3
Training loss: 2.237226893630591
Validation loss: 2.5770365098027783

Epoch: 5| Step: 4
Training loss: 2.5769931042437944
Validation loss: 2.5652303838380806

Epoch: 5| Step: 5
Training loss: 2.249220713130602
Validation loss: 2.5797986447308396

Epoch: 5| Step: 6
Training loss: 2.62167965839883
Validation loss: 2.5016206820484927

Epoch: 5| Step: 7
Training loss: 2.2471076600818516
Validation loss: 2.4955846434944537

Epoch: 5| Step: 8
Training loss: 2.6764317967736
Validation loss: 2.5001942723172053

Epoch: 5| Step: 9
Training loss: 2.541563521830223
Validation loss: 2.4892786386771064

Epoch: 5| Step: 10
Training loss: 2.9829208266429097
Validation loss: 2.504706078726579

Epoch: 177| Step: 0
Training loss: 2.5779101657944743
Validation loss: 2.489617810392679

Epoch: 5| Step: 1
Training loss: 2.540973871168049
Validation loss: 2.5446834328948427

Epoch: 5| Step: 2
Training loss: 2.5383467853946953
Validation loss: 2.56493357171321

Epoch: 5| Step: 3
Training loss: 2.0610391471731973
Validation loss: 2.5645180595980417

Epoch: 5| Step: 4
Training loss: 2.462641631570049
Validation loss: 2.5318589100358966

Epoch: 5| Step: 5
Training loss: 2.069356676099478
Validation loss: 2.518700649329968

Epoch: 5| Step: 6
Training loss: 2.2642559255846963
Validation loss: 2.4892277068211683

Epoch: 5| Step: 7
Training loss: 2.4013952848536686
Validation loss: 2.48945243911143

Epoch: 5| Step: 8
Training loss: 2.7074544996839536
Validation loss: 2.456392808829156

Epoch: 5| Step: 9
Training loss: 2.7386186204160667
Validation loss: 2.4444465507462203

Epoch: 5| Step: 10
Training loss: 2.3345513457213416
Validation loss: 2.4409501296032383

Epoch: 178| Step: 0
Training loss: 2.5569600954071214
Validation loss: 2.4581418681542453

Epoch: 5| Step: 1
Training loss: 1.9817131391658034
Validation loss: 2.505838846224834

Epoch: 5| Step: 2
Training loss: 2.6241510017374066
Validation loss: 2.5689513670048885

Epoch: 5| Step: 3
Training loss: 2.1250236734305763
Validation loss: 2.637048170506026

Epoch: 5| Step: 4
Training loss: 2.307317235616972
Validation loss: 2.710530627056703

Epoch: 5| Step: 5
Training loss: 2.8291994867307912
Validation loss: 2.732761504472352

Epoch: 5| Step: 6
Training loss: 2.8097273829432603
Validation loss: 2.5968600368941113

Epoch: 5| Step: 7
Training loss: 2.3436646509524923
Validation loss: 2.487067400984154

Epoch: 5| Step: 8
Training loss: 2.453019060896706
Validation loss: 2.4379462377150385

Epoch: 5| Step: 9
Training loss: 2.8720231608463727
Validation loss: 2.4305711789271167

Epoch: 5| Step: 10
Training loss: 2.2704412372631966
Validation loss: 2.426097109857678

Epoch: 179| Step: 0
Training loss: 2.0910460819254655
Validation loss: 2.4353756120277366

Epoch: 5| Step: 1
Training loss: 2.47163502604973
Validation loss: 2.4602960477498166

Epoch: 5| Step: 2
Training loss: 2.7242313245784495
Validation loss: 2.494998793209908

Epoch: 5| Step: 3
Training loss: 2.525599353776184
Validation loss: 2.5511921813232963

Epoch: 5| Step: 4
Training loss: 2.388259215747739
Validation loss: 2.57500536906432

Epoch: 5| Step: 5
Training loss: 2.6463601396404797
Validation loss: 2.5764067033887166

Epoch: 5| Step: 6
Training loss: 2.803077511932703
Validation loss: 2.5669106003040243

Epoch: 5| Step: 7
Training loss: 2.5435157574299945
Validation loss: 2.5139643276086514

Epoch: 5| Step: 8
Training loss: 2.0846727515996863
Validation loss: 2.472754140287123

Epoch: 5| Step: 9
Training loss: 2.029388278815527
Validation loss: 2.479347933475052

Epoch: 5| Step: 10
Training loss: 2.1382208919124994
Validation loss: 2.468618264557541

Epoch: 180| Step: 0
Training loss: 2.3090158970526375
Validation loss: 2.489887404505661

Epoch: 5| Step: 1
Training loss: 2.4764757592447193
Validation loss: 2.4678110829739914

Epoch: 5| Step: 2
Training loss: 2.6093854161585703
Validation loss: 2.4911298379378994

Epoch: 5| Step: 3
Training loss: 2.592473278882772
Validation loss: 2.47176268331881

Epoch: 5| Step: 4
Training loss: 1.8332641617412515
Validation loss: 2.469223432939465

Epoch: 5| Step: 5
Training loss: 2.7939517978778277
Validation loss: 2.4942490228622227

Epoch: 5| Step: 6
Training loss: 2.1398045436335615
Validation loss: 2.5206197900580616

Epoch: 5| Step: 7
Training loss: 2.2894051461365983
Validation loss: 2.5848141847565156

Epoch: 5| Step: 8
Training loss: 2.3072778659749393
Validation loss: 2.663609174401251

Epoch: 5| Step: 9
Training loss: 2.32534706232556
Validation loss: 2.7681279384114084

Epoch: 5| Step: 10
Training loss: 2.8259787661597686
Validation loss: 2.887242300985916

Epoch: 181| Step: 0
Training loss: 2.6252871764997896
Validation loss: 2.734708608501228

Epoch: 5| Step: 1
Training loss: 2.3877610148807964
Validation loss: 2.5222862993432025

Epoch: 5| Step: 2
Training loss: 2.3241237588913086
Validation loss: 2.4458670688575066

Epoch: 5| Step: 3
Training loss: 2.5227205657557406
Validation loss: 2.4422885303060258

Epoch: 5| Step: 4
Training loss: 2.249517601010461
Validation loss: 2.457700592322757

Epoch: 5| Step: 5
Training loss: 2.351749653513378
Validation loss: 2.4651284498780814

Epoch: 5| Step: 6
Training loss: 2.720818971028376
Validation loss: 2.457815441796893

Epoch: 5| Step: 7
Training loss: 3.172316346680761
Validation loss: 2.463455520938216

Epoch: 5| Step: 8
Training loss: 3.063693689757219
Validation loss: 2.462400044449481

Epoch: 5| Step: 9
Training loss: 2.3043139138750126
Validation loss: 2.4555098138869176

Epoch: 5| Step: 10
Training loss: 2.3620173329582212
Validation loss: 2.500933419577615

Epoch: 182| Step: 0
Training loss: 2.6222343407726254
Validation loss: 2.511881266321787

Epoch: 5| Step: 1
Training loss: 2.7648734240678983
Validation loss: 2.560432360247811

Epoch: 5| Step: 2
Training loss: 2.3171562537403574
Validation loss: 2.6052104188899294

Epoch: 5| Step: 3
Training loss: 2.060362662085587
Validation loss: 2.6247923847528467

Epoch: 5| Step: 4
Training loss: 2.229244397195601
Validation loss: 2.6645224747938143

Epoch: 5| Step: 5
Training loss: 2.0409894585643267
Validation loss: 2.705767554107426

Epoch: 5| Step: 6
Training loss: 2.8783831386384007
Validation loss: 2.775318225949311

Epoch: 5| Step: 7
Training loss: 2.53780073065695
Validation loss: 2.58541846766139

Epoch: 5| Step: 8
Training loss: 2.7216765339056
Validation loss: 2.4750367939669906

Epoch: 5| Step: 9
Training loss: 2.431180440108661
Validation loss: 2.4591030989540235

Epoch: 5| Step: 10
Training loss: 2.3942155987786604
Validation loss: 2.454776033531401

Epoch: 183| Step: 0
Training loss: 2.4571113997882224
Validation loss: 2.463419931898756

Epoch: 5| Step: 1
Training loss: 2.8079194810087795
Validation loss: 2.4606776061026063

Epoch: 5| Step: 2
Training loss: 2.765780600788059
Validation loss: 2.476806295303467

Epoch: 5| Step: 3
Training loss: 2.5235873434734057
Validation loss: 2.448727849862147

Epoch: 5| Step: 4
Training loss: 1.9202488788591034
Validation loss: 2.458220585830234

Epoch: 5| Step: 5
Training loss: 2.4567659413721192
Validation loss: 2.4849075837248384

Epoch: 5| Step: 6
Training loss: 2.330775141484556
Validation loss: 2.4993120739035666

Epoch: 5| Step: 7
Training loss: 2.23224949609249
Validation loss: 2.5864215899976206

Epoch: 5| Step: 8
Training loss: 2.3721972541874883
Validation loss: 2.6085323716862185

Epoch: 5| Step: 9
Training loss: 2.5226298359480106
Validation loss: 2.6232269303255005

Epoch: 5| Step: 10
Training loss: 2.402611098881436
Validation loss: 2.604864393388474

Epoch: 184| Step: 0
Training loss: 1.9801050337473594
Validation loss: 2.596629294447797

Epoch: 5| Step: 1
Training loss: 2.1695335445865838
Validation loss: 2.592606031410199

Epoch: 5| Step: 2
Training loss: 2.1659081916548852
Validation loss: 2.5662315595014724

Epoch: 5| Step: 3
Training loss: 2.379025110241313
Validation loss: 2.562991702618332

Epoch: 5| Step: 4
Training loss: 2.1900059106825402
Validation loss: 2.584304627635906

Epoch: 5| Step: 5
Training loss: 2.7277509400117275
Validation loss: 2.553222864596659

Epoch: 5| Step: 6
Training loss: 2.662567703747376
Validation loss: 2.4875774096739742

Epoch: 5| Step: 7
Training loss: 2.589612211116016
Validation loss: 2.4394543125256725

Epoch: 5| Step: 8
Training loss: 2.3917750166785576
Validation loss: 2.4321116483838097

Epoch: 5| Step: 9
Training loss: 2.6225906395681053
Validation loss: 2.4303517645168746

Epoch: 5| Step: 10
Training loss: 2.4542595250470516
Validation loss: 2.4399107840009693

Epoch: 185| Step: 0
Training loss: 2.9950525496367253
Validation loss: 2.479396831789054

Epoch: 5| Step: 1
Training loss: 2.0964566855310562
Validation loss: 2.5241763420898486

Epoch: 5| Step: 2
Training loss: 2.27993768021257
Validation loss: 2.545585788685555

Epoch: 5| Step: 3
Training loss: 2.4185069629883627
Validation loss: 2.603454923436392

Epoch: 5| Step: 4
Training loss: 2.586074134005966
Validation loss: 2.6937734296368068

Epoch: 5| Step: 5
Training loss: 2.5660700236672276
Validation loss: 2.6916464488222194

Epoch: 5| Step: 6
Training loss: 2.332197480531141
Validation loss: 2.593378451822921

Epoch: 5| Step: 7
Training loss: 2.447202007322308
Validation loss: 2.523951075472794

Epoch: 5| Step: 8
Training loss: 2.1475984911820443
Validation loss: 2.4960544440646366

Epoch: 5| Step: 9
Training loss: 1.9139037397288612
Validation loss: 2.4532048750796145

Epoch: 5| Step: 10
Training loss: 1.7662941668928294
Validation loss: 2.458647140808018

Epoch: 186| Step: 0
Training loss: 2.254560616902297
Validation loss: 2.4607330909291045

Epoch: 5| Step: 1
Training loss: 2.4920441876285544
Validation loss: 2.45081230310563

Epoch: 5| Step: 2
Training loss: 2.2476719362137834
Validation loss: 2.475476964222081

Epoch: 5| Step: 3
Training loss: 2.121455995878762
Validation loss: 2.5379160221309474

Epoch: 5| Step: 4
Training loss: 2.353787912153597
Validation loss: 2.605060157987437

Epoch: 5| Step: 5
Training loss: 3.086032991501191
Validation loss: 2.6283854516758427

Epoch: 5| Step: 6
Training loss: 2.7176326341030075
Validation loss: 2.6732523113040307

Epoch: 5| Step: 7
Training loss: 2.4305354659446134
Validation loss: 2.6319346448884517

Epoch: 5| Step: 8
Training loss: 2.1829340557530266
Validation loss: 2.604225369355798

Epoch: 5| Step: 9
Training loss: 1.7379250836616313
Validation loss: 2.5516095158355987

Epoch: 5| Step: 10
Training loss: 2.0623677529216304
Validation loss: 2.5054880857162005

Epoch: 187| Step: 0
Training loss: 2.2844084730709566
Validation loss: 2.4922725552265397

Epoch: 5| Step: 1
Training loss: 2.674705835015044
Validation loss: 2.486174612891249

Epoch: 5| Step: 2
Training loss: 2.669574483332148
Validation loss: 2.4682168136872082

Epoch: 5| Step: 3
Training loss: 2.0329679999959587
Validation loss: 2.4887634923776694

Epoch: 5| Step: 4
Training loss: 2.0485382311370057
Validation loss: 2.4862503895285757

Epoch: 5| Step: 5
Training loss: 2.1237105777128398
Validation loss: 2.5256161179816123

Epoch: 5| Step: 6
Training loss: 2.0742036923079272
Validation loss: 2.5501443481447046

Epoch: 5| Step: 7
Training loss: 2.2356849511788854
Validation loss: 2.5797876162171822

Epoch: 5| Step: 8
Training loss: 2.637216930656874
Validation loss: 2.561102799604887

Epoch: 5| Step: 9
Training loss: 2.5060426164856193
Validation loss: 2.527162883856267

Epoch: 5| Step: 10
Training loss: 2.134840116745552
Validation loss: 2.5064963003825675

Epoch: 188| Step: 0
Training loss: 2.1133911329883195
Validation loss: 2.5041431509913568

Epoch: 5| Step: 1
Training loss: 2.326995985485855
Validation loss: 2.505155919477359

Epoch: 5| Step: 2
Training loss: 1.731947979196495
Validation loss: 2.4875625425224315

Epoch: 5| Step: 3
Training loss: 2.6312319938424134
Validation loss: 2.492410315575822

Epoch: 5| Step: 4
Training loss: 2.5699713112383917
Validation loss: 2.4723483376041773

Epoch: 5| Step: 5
Training loss: 2.135512993353469
Validation loss: 2.4924517607890233

Epoch: 5| Step: 6
Training loss: 1.7999912606133124
Validation loss: 2.5324896548538627

Epoch: 5| Step: 7
Training loss: 2.901261344732993
Validation loss: 2.580434039251477

Epoch: 5| Step: 8
Training loss: 2.3958032910218736
Validation loss: 2.5884717768972885

Epoch: 5| Step: 9
Training loss: 1.8847725191138485
Validation loss: 2.623938764451389

Epoch: 5| Step: 10
Training loss: 2.660037045041601
Validation loss: 2.6087516515141194

Epoch: 189| Step: 0
Training loss: 2.663267492436141
Validation loss: 2.539324296528472

Epoch: 5| Step: 1
Training loss: 2.508127923541215
Validation loss: 2.527233979482035

Epoch: 5| Step: 2
Training loss: 2.541808911288161
Validation loss: 2.496854179028869

Epoch: 5| Step: 3
Training loss: 1.6162558558004676
Validation loss: 2.5237277350509455

Epoch: 5| Step: 4
Training loss: 2.27320184174476
Validation loss: 2.5130582665221697

Epoch: 5| Step: 5
Training loss: 2.167295609179412
Validation loss: 2.527092359401762

Epoch: 5| Step: 6
Training loss: 2.4633718893142134
Validation loss: 2.517096359556251

Epoch: 5| Step: 7
Training loss: 1.9805157597547263
Validation loss: 2.5208622310334325

Epoch: 5| Step: 8
Training loss: 2.1385396559443053
Validation loss: 2.5100311523162677

Epoch: 5| Step: 9
Training loss: 2.4766629075355118
Validation loss: 2.501845570722929

Epoch: 5| Step: 10
Training loss: 2.115449424231053
Validation loss: 2.460256131863786

Epoch: 190| Step: 0
Training loss: 2.247972422542636
Validation loss: 2.444711226957367

Epoch: 5| Step: 1
Training loss: 2.250530816088195
Validation loss: 2.4440447037497437

Epoch: 5| Step: 2
Training loss: 2.584932529594564
Validation loss: 2.440888855415878

Epoch: 5| Step: 3
Training loss: 2.546591900964619
Validation loss: 2.453310525061629

Epoch: 5| Step: 4
Training loss: 2.195357895785646
Validation loss: 2.449377778938715

Epoch: 5| Step: 5
Training loss: 1.9412017653172104
Validation loss: 2.4993009553862877

Epoch: 5| Step: 6
Training loss: 2.064117490972965
Validation loss: 2.535189052253092

Epoch: 5| Step: 7
Training loss: 2.450157946730827
Validation loss: 2.6188468314711644

Epoch: 5| Step: 8
Training loss: 2.2475120776640125
Validation loss: 2.652635543218002

Epoch: 5| Step: 9
Training loss: 2.6646244653346116
Validation loss: 2.63950201646567

Epoch: 5| Step: 10
Training loss: 1.908278089942524
Validation loss: 2.568070077170036

Epoch: 191| Step: 0
Training loss: 1.8975274059140934
Validation loss: 2.532694484571667

Epoch: 5| Step: 1
Training loss: 2.300378320511752
Validation loss: 2.5045795519279404

Epoch: 5| Step: 2
Training loss: 1.9755184145073768
Validation loss: 2.4910450586116264

Epoch: 5| Step: 3
Training loss: 3.0578838513548
Validation loss: 2.483467262815103

Epoch: 5| Step: 4
Training loss: 2.3151406341415357
Validation loss: 2.5111944062472435

Epoch: 5| Step: 5
Training loss: 2.1349667579153464
Validation loss: 2.511814717858455

Epoch: 5| Step: 6
Training loss: 1.9999347914555772
Validation loss: 2.4944591925370556

Epoch: 5| Step: 7
Training loss: 2.5659545315098393
Validation loss: 2.494845677954735

Epoch: 5| Step: 8
Training loss: 2.3983879954047187
Validation loss: 2.478378259122096

Epoch: 5| Step: 9
Training loss: 1.8208519132293237
Validation loss: 2.467445199027521

Epoch: 5| Step: 10
Training loss: 2.0205511177920235
Validation loss: 2.4242450286522867

Epoch: 192| Step: 0
Training loss: 2.1712625861365877
Validation loss: 2.438007285121006

Epoch: 5| Step: 1
Training loss: 2.0195412847686502
Validation loss: 2.4428049210942775

Epoch: 5| Step: 2
Training loss: 2.5472080504414802
Validation loss: 2.4542055286509155

Epoch: 5| Step: 3
Training loss: 2.17608322705258
Validation loss: 2.46749305944631

Epoch: 5| Step: 4
Training loss: 2.394693341144147
Validation loss: 2.5228460811221027

Epoch: 5| Step: 5
Training loss: 2.074581710754524
Validation loss: 2.5248587806122846

Epoch: 5| Step: 6
Training loss: 2.107017046887961
Validation loss: 2.5435633808369573

Epoch: 5| Step: 7
Training loss: 2.202416488674974
Validation loss: 2.6284461051530696

Epoch: 5| Step: 8
Training loss: 2.5391977127459104
Validation loss: 2.635601366185606

Epoch: 5| Step: 9
Training loss: 2.3918342274663784
Validation loss: 2.6110233511264247

Epoch: 5| Step: 10
Training loss: 2.266844533037696
Validation loss: 2.5198160544571384

Epoch: 193| Step: 0
Training loss: 2.65929668952226
Validation loss: 2.485028539598399

Epoch: 5| Step: 1
Training loss: 2.4017605205395607
Validation loss: 2.4504552792773153

Epoch: 5| Step: 2
Training loss: 1.5308094558694898
Validation loss: 2.431371218286657

Epoch: 5| Step: 3
Training loss: 1.8959720127679793
Validation loss: 2.3957324801739475

Epoch: 5| Step: 4
Training loss: 2.3057480263195425
Validation loss: 2.4073038125534554

Epoch: 5| Step: 5
Training loss: 2.3163677553320188
Validation loss: 2.4014169552162223

Epoch: 5| Step: 6
Training loss: 2.1287640165359205
Validation loss: 2.425556316359861

Epoch: 5| Step: 7
Training loss: 1.9026036016500119
Validation loss: 2.444225612927675

Epoch: 5| Step: 8
Training loss: 2.473419601944384
Validation loss: 2.478405607538563

Epoch: 5| Step: 9
Training loss: 2.5580259202623674
Validation loss: 2.531872069136898

Epoch: 5| Step: 10
Training loss: 2.26236811722435
Validation loss: 2.6022702205744417

Epoch: 194| Step: 0
Training loss: 1.9522102349992283
Validation loss: 2.6781081232486432

Epoch: 5| Step: 1
Training loss: 2.5798018117678128
Validation loss: 2.7040795371653648

Epoch: 5| Step: 2
Training loss: 2.134187248316432
Validation loss: 2.7334262872112545

Epoch: 5| Step: 3
Training loss: 2.2407126011875342
Validation loss: 2.697053042645112

Epoch: 5| Step: 4
Training loss: 1.9089626335215786
Validation loss: 2.6304231779906315

Epoch: 5| Step: 5
Training loss: 2.8378860883157992
Validation loss: 2.499132994572217

Epoch: 5| Step: 6
Training loss: 1.7354412753347483
Validation loss: 2.430932715511009

Epoch: 5| Step: 7
Training loss: 2.290531038904635
Validation loss: 2.4105261299150915

Epoch: 5| Step: 8
Training loss: 2.040776727009992
Validation loss: 2.386026884651765

Epoch: 5| Step: 9
Training loss: 2.2799374710677394
Validation loss: 2.3992747546687188

Epoch: 5| Step: 10
Training loss: 2.3409977329639147
Validation loss: 2.4136858152858944

Epoch: 195| Step: 0
Training loss: 2.0001614028653307
Validation loss: 2.402657988737414

Epoch: 5| Step: 1
Training loss: 2.5570489544230792
Validation loss: 2.4284127372628497

Epoch: 5| Step: 2
Training loss: 2.193136093446424
Validation loss: 2.617955830710225

Epoch: 5| Step: 3
Training loss: 2.8504220014311348
Validation loss: 2.728697415117276

Epoch: 5| Step: 4
Training loss: 1.9143906915303666
Validation loss: 2.7170352084754144

Epoch: 5| Step: 5
Training loss: 2.1172076572711447
Validation loss: 2.5698097501079986

Epoch: 5| Step: 6
Training loss: 1.728146685003772
Validation loss: 2.45785207575803

Epoch: 5| Step: 7
Training loss: 2.53406904563383
Validation loss: 2.4163818644171577

Epoch: 5| Step: 8
Training loss: 2.6827456981982416
Validation loss: 2.401405943378512

Epoch: 5| Step: 9
Training loss: 2.112314958763458
Validation loss: 2.433953011223494

Epoch: 5| Step: 10
Training loss: 2.3529628500220703
Validation loss: 2.439741925778653

Epoch: 196| Step: 0
Training loss: 1.9492032159404187
Validation loss: 2.4324157789281324

Epoch: 5| Step: 1
Training loss: 2.245040726324136
Validation loss: 2.4536631599800627

Epoch: 5| Step: 2
Training loss: 2.2874737847498863
Validation loss: 2.434890840946537

Epoch: 5| Step: 3
Training loss: 2.2979330104363096
Validation loss: 2.509703308662285

Epoch: 5| Step: 4
Training loss: 1.9714537326221975
Validation loss: 2.5942238825612556

Epoch: 5| Step: 5
Training loss: 2.4661942785728637
Validation loss: 2.611269813025388

Epoch: 5| Step: 6
Training loss: 2.4859831781224826
Validation loss: 2.6765876375897197

Epoch: 5| Step: 7
Training loss: 2.2284144145372693
Validation loss: 2.672369823296898

Epoch: 5| Step: 8
Training loss: 2.6124290821725866
Validation loss: 2.6764365324175663

Epoch: 5| Step: 9
Training loss: 1.9950681914719224
Validation loss: 2.680843617022187

Epoch: 5| Step: 10
Training loss: 2.1802301859288287
Validation loss: 2.5791191324779255

Epoch: 197| Step: 0
Training loss: 1.9359461183025164
Validation loss: 2.546856353991472

Epoch: 5| Step: 1
Training loss: 2.2544957915482757
Validation loss: 2.490474365560575

Epoch: 5| Step: 2
Training loss: 1.7796039002353272
Validation loss: 2.4936335624449653

Epoch: 5| Step: 3
Training loss: 2.3999337862735537
Validation loss: 2.4260319067762137

Epoch: 5| Step: 4
Training loss: 1.9510236498613016
Validation loss: 2.426943461294926

Epoch: 5| Step: 5
Training loss: 1.7470463622633439
Validation loss: 2.4299274219686957

Epoch: 5| Step: 6
Training loss: 2.5110840180809992
Validation loss: 2.4260843122109965

Epoch: 5| Step: 7
Training loss: 2.3524450122597056
Validation loss: 2.4579562900392533

Epoch: 5| Step: 8
Training loss: 2.2216247417656065
Validation loss: 2.5001163865756846

Epoch: 5| Step: 9
Training loss: 2.4477949612711267
Validation loss: 2.5724792324502563

Epoch: 5| Step: 10
Training loss: 2.427064909203363
Validation loss: 2.6037980230139492

Epoch: 198| Step: 0
Training loss: 2.114285327476849
Validation loss: 2.580860300543404

Epoch: 5| Step: 1
Training loss: 1.7652823866890641
Validation loss: 2.5100427058924453

Epoch: 5| Step: 2
Training loss: 2.6914107678379624
Validation loss: 2.463917902248212

Epoch: 5| Step: 3
Training loss: 2.306778092127806
Validation loss: 2.4270104429843045

Epoch: 5| Step: 4
Training loss: 1.83972886814153
Validation loss: 2.422079361765983

Epoch: 5| Step: 5
Training loss: 2.423335662413907
Validation loss: 2.382589295394676

Epoch: 5| Step: 6
Training loss: 2.2454659023987538
Validation loss: 2.4063443284069828

Epoch: 5| Step: 7
Training loss: 2.188029197986223
Validation loss: 2.4281535019102303

Epoch: 5| Step: 8
Training loss: 2.4590286844759333
Validation loss: 2.450362562115506

Epoch: 5| Step: 9
Training loss: 2.005782589283094
Validation loss: 2.444405088670314

Epoch: 5| Step: 10
Training loss: 1.6882535170466653
Validation loss: 2.4947084980807177

Epoch: 199| Step: 0
Training loss: 2.1268851949810066
Validation loss: 2.6045368267854183

Epoch: 5| Step: 1
Training loss: 2.283857762425607
Validation loss: 2.71802286229327

Epoch: 5| Step: 2
Training loss: 1.9483159789831785
Validation loss: 2.844695865982586

Epoch: 5| Step: 3
Training loss: 1.7517975703046968
Validation loss: 2.8251253331657544

Epoch: 5| Step: 4
Training loss: 2.2318683782483024
Validation loss: 2.783883288320846

Epoch: 5| Step: 5
Training loss: 2.276725253202625
Validation loss: 2.635517631236509

Epoch: 5| Step: 6
Training loss: 2.166002306196371
Validation loss: 2.4883039924230195

Epoch: 5| Step: 7
Training loss: 2.380295922290617
Validation loss: 2.4354647250130212

Epoch: 5| Step: 8
Training loss: 2.1360850955000097
Validation loss: 2.396806648331089

Epoch: 5| Step: 9
Training loss: 2.541751318183738
Validation loss: 2.3866399560645775

Epoch: 5| Step: 10
Training loss: 2.345940545332794
Validation loss: 2.385637937146385

Epoch: 200| Step: 0
Training loss: 2.481151961304311
Validation loss: 2.4073096164842047

Epoch: 5| Step: 1
Training loss: 2.5240618520917457
Validation loss: 2.4079906175349057

Epoch: 5| Step: 2
Training loss: 1.6789931170542298
Validation loss: 2.460153678142647

Epoch: 5| Step: 3
Training loss: 1.6484883377407795
Validation loss: 2.507581474573758

Epoch: 5| Step: 4
Training loss: 1.8435501378243004
Validation loss: 2.625336390601352

Epoch: 5| Step: 5
Training loss: 2.547304269386074
Validation loss: 2.75313550452569

Epoch: 5| Step: 6
Training loss: 2.4258978135365044
Validation loss: 2.7813993388307057

Epoch: 5| Step: 7
Training loss: 2.8409754034452597
Validation loss: 2.747702284700927

Epoch: 5| Step: 8
Training loss: 1.801368071626084
Validation loss: 2.680463935937942

Epoch: 5| Step: 9
Training loss: 2.204617366851312
Validation loss: 2.547638338418113

Epoch: 5| Step: 10
Training loss: 1.7927465363472899
Validation loss: 2.4581172609000768

Epoch: 201| Step: 0
Training loss: 2.192808521968978
Validation loss: 2.4558733218805178

Epoch: 5| Step: 1
Training loss: 2.1607825145735666
Validation loss: 2.4362704965351374

Epoch: 5| Step: 2
Training loss: 2.229081826660365
Validation loss: 2.410084146150467

Epoch: 5| Step: 3
Training loss: 2.3772504083045565
Validation loss: 2.4454601539040257

Epoch: 5| Step: 4
Training loss: 2.2033195680235425
Validation loss: 2.480046227328959

Epoch: 5| Step: 5
Training loss: 2.0748026972347016
Validation loss: 2.48135900588879

Epoch: 5| Step: 6
Training loss: 2.2356702344934285
Validation loss: 2.5133134171194103

Epoch: 5| Step: 7
Training loss: 2.22931765701556
Validation loss: 2.5682453373658802

Epoch: 5| Step: 8
Training loss: 1.9390791948385169
Validation loss: 2.6710556789955096

Epoch: 5| Step: 9
Training loss: 2.332386187917825
Validation loss: 2.720770645443324

Epoch: 5| Step: 10
Training loss: 1.9113544848207218
Validation loss: 2.791372639712101

Epoch: 202| Step: 0
Training loss: 1.9357384087482667
Validation loss: 2.756871424930689

Epoch: 5| Step: 1
Training loss: 1.8086329676287636
Validation loss: 2.75097486364208

Epoch: 5| Step: 2
Training loss: 1.9579064397659125
Validation loss: 2.652866559256642

Epoch: 5| Step: 3
Training loss: 1.948484355054171
Validation loss: 2.565437943725049

Epoch: 5| Step: 4
Training loss: 2.568218085170262
Validation loss: 2.5123548297290785

Epoch: 5| Step: 5
Training loss: 2.105506344602905
Validation loss: 2.4474092764513458

Epoch: 5| Step: 6
Training loss: 2.208553363227032
Validation loss: 2.4283447205911104

Epoch: 5| Step: 7
Training loss: 2.560572666995625
Validation loss: 2.4335137969404896

Epoch: 5| Step: 8
Training loss: 2.7902726825646282
Validation loss: 2.4406818324190387

Epoch: 5| Step: 9
Training loss: 1.6959942971709476
Validation loss: 2.4625105365040327

Epoch: 5| Step: 10
Training loss: 1.8219173707827925
Validation loss: 2.4696530203698375

Epoch: 203| Step: 0
Training loss: 1.8879040771863866
Validation loss: 2.4799881509338375

Epoch: 5| Step: 1
Training loss: 2.239654705477625
Validation loss: 2.5101761993592553

Epoch: 5| Step: 2
Training loss: 1.9845395357898918
Validation loss: 2.556176638097705

Epoch: 5| Step: 3
Training loss: 1.9782339273988405
Validation loss: 2.5464128107224586

Epoch: 5| Step: 4
Training loss: 2.088073551168716
Validation loss: 2.53037424559095

Epoch: 5| Step: 5
Training loss: 2.7892318374987495
Validation loss: 2.5260118819978783

Epoch: 5| Step: 6
Training loss: 1.9593170279120449
Validation loss: 2.5172927852453366

Epoch: 5| Step: 7
Training loss: 2.187967958805001
Validation loss: 2.517906738337047

Epoch: 5| Step: 8
Training loss: 2.278033562644901
Validation loss: 2.5348489471671174

Epoch: 5| Step: 9
Training loss: 1.7544935300962663
Validation loss: 2.5162798809295026

Epoch: 5| Step: 10
Training loss: 1.7670684585478924
Validation loss: 2.553563675885003

Epoch: 204| Step: 0
Training loss: 1.999994635574776
Validation loss: 2.5592904348575147

Epoch: 5| Step: 1
Training loss: 1.9018184242019618
Validation loss: 2.597402788519003

Epoch: 5| Step: 2
Training loss: 2.5023578968535483
Validation loss: 2.6381902973215396

Epoch: 5| Step: 3
Training loss: 1.917862153053082
Validation loss: 2.6183977909169385

Epoch: 5| Step: 4
Training loss: 1.8558516257928617
Validation loss: 2.5878839560740303

Epoch: 5| Step: 5
Training loss: 1.8478208956438202
Validation loss: 2.582665048020637

Epoch: 5| Step: 6
Training loss: 1.9838417718496286
Validation loss: 2.5674136772605416

Epoch: 5| Step: 7
Training loss: 2.0647299300369717
Validation loss: 2.524884588901104

Epoch: 5| Step: 8
Training loss: 2.3391406701734763
Validation loss: 2.4756504008455784

Epoch: 5| Step: 9
Training loss: 1.8237561572613488
Validation loss: 2.46296323241293

Epoch: 5| Step: 10
Training loss: 2.623628984907271
Validation loss: 2.4526953607379687

Epoch: 205| Step: 0
Training loss: 2.7989467002097834
Validation loss: 2.469411144355585

Epoch: 5| Step: 1
Training loss: 1.7718470495532332
Validation loss: 2.4932793081053632

Epoch: 5| Step: 2
Training loss: 2.286245546164536
Validation loss: 2.4868546525868696

Epoch: 5| Step: 3
Training loss: 1.7416637642697816
Validation loss: 2.518223548475086

Epoch: 5| Step: 4
Training loss: 2.1139242213010663
Validation loss: 2.5090579403007016

Epoch: 5| Step: 5
Training loss: 2.0620701659850957
Validation loss: 2.5603604172050254

Epoch: 5| Step: 6
Training loss: 2.0862066545320523
Validation loss: 2.581392911731741

Epoch: 5| Step: 7
Training loss: 1.5611842910218663
Validation loss: 2.582163811624418

Epoch: 5| Step: 8
Training loss: 2.375611276765089
Validation loss: 2.585112530309155

Epoch: 5| Step: 9
Training loss: 1.8620630276519547
Validation loss: 2.542891870933839

Epoch: 5| Step: 10
Training loss: 1.6683312765839837
Validation loss: 2.5836130001416255

Epoch: 206| Step: 0
Training loss: 1.5986190170783428
Validation loss: 2.5833064778176142

Epoch: 5| Step: 1
Training loss: 1.782013712675036
Validation loss: 2.593358537745648

Epoch: 5| Step: 2
Training loss: 1.7436146728069775
Validation loss: 2.5468553755856145

Epoch: 5| Step: 3
Training loss: 2.090799558733406
Validation loss: 2.5143577126472203

Epoch: 5| Step: 4
Training loss: 2.373258855951258
Validation loss: 2.466103325758676

Epoch: 5| Step: 5
Training loss: 1.9195427117570272
Validation loss: 2.4800573851349976

Epoch: 5| Step: 6
Training loss: 2.221714135206841
Validation loss: 2.47140943288927

Epoch: 5| Step: 7
Training loss: 2.1216696278845335
Validation loss: 2.4689094727675203

Epoch: 5| Step: 8
Training loss: 2.3474094559470506
Validation loss: 2.4965402720918743

Epoch: 5| Step: 9
Training loss: 2.338138831657769
Validation loss: 2.5309195343919946

Epoch: 5| Step: 10
Training loss: 1.6837720311910518
Validation loss: 2.577475039830713

Epoch: 207| Step: 0
Training loss: 2.4836410301966385
Validation loss: 2.6376970060778566

Epoch: 5| Step: 1
Training loss: 1.8849017316464716
Validation loss: 2.6334017083369843

Epoch: 5| Step: 2
Training loss: 1.8699931370002347
Validation loss: 2.706934035593423

Epoch: 5| Step: 3
Training loss: 2.2282117658202605
Validation loss: 2.7346530024108824

Epoch: 5| Step: 4
Training loss: 2.179477476440741
Validation loss: 2.7207650795788334

Epoch: 5| Step: 5
Training loss: 1.9186007513096688
Validation loss: 2.7519365560224274

Epoch: 5| Step: 6
Training loss: 1.8461555047669662
Validation loss: 2.7106175170139313

Epoch: 5| Step: 7
Training loss: 1.9429842332837353
Validation loss: 2.605019291915411

Epoch: 5| Step: 8
Training loss: 1.588617175032611
Validation loss: 2.564376266206578

Epoch: 5| Step: 9
Training loss: 2.164106788595204
Validation loss: 2.4591282243696027

Epoch: 5| Step: 10
Training loss: 2.1970501196400707
Validation loss: 2.4307333347290245

Epoch: 208| Step: 0
Training loss: 2.045193862679918
Validation loss: 2.405579032195431

Epoch: 5| Step: 1
Training loss: 1.9387996990393297
Validation loss: 2.4125435897219107

Epoch: 5| Step: 2
Training loss: 1.9413762848228215
Validation loss: 2.403748059482327

Epoch: 5| Step: 3
Training loss: 2.4409700782251567
Validation loss: 2.428998770591441

Epoch: 5| Step: 4
Training loss: 2.0041978411982733
Validation loss: 2.45654758822735

Epoch: 5| Step: 5
Training loss: 1.8126290374073226
Validation loss: 2.482752221429209

Epoch: 5| Step: 6
Training loss: 2.2961676929323263
Validation loss: 2.4740124108579056

Epoch: 5| Step: 7
Training loss: 1.7838621561655785
Validation loss: 2.5772345324208845

Epoch: 5| Step: 8
Training loss: 2.234732005802116
Validation loss: 2.629713280450725

Epoch: 5| Step: 9
Training loss: 1.8034713412493932
Validation loss: 2.707832615445583

Epoch: 5| Step: 10
Training loss: 1.9727728176612607
Validation loss: 2.719173557290023

Epoch: 209| Step: 0
Training loss: 2.069531793763495
Validation loss: 2.7963947986818445

Epoch: 5| Step: 1
Training loss: 2.433108849382435
Validation loss: 2.719519584870113

Epoch: 5| Step: 2
Training loss: 2.3996039421396356
Validation loss: 2.5988210305260497

Epoch: 5| Step: 3
Training loss: 2.0946048870183005
Validation loss: 2.51138750380992

Epoch: 5| Step: 4
Training loss: 1.8512436475522445
Validation loss: 2.4487854050744526

Epoch: 5| Step: 5
Training loss: 1.385920507075266
Validation loss: 2.410071371973254

Epoch: 5| Step: 6
Training loss: 1.929258352892585
Validation loss: 2.3967887232588794

Epoch: 5| Step: 7
Training loss: 1.9435057311801596
Validation loss: 2.3917739040908015

Epoch: 5| Step: 8
Training loss: 2.1205916960934577
Validation loss: 2.4081741947508584

Epoch: 5| Step: 9
Training loss: 2.183875323380451
Validation loss: 2.4416531860165334

Epoch: 5| Step: 10
Training loss: 2.2296476706761457
Validation loss: 2.443516394242847

Epoch: 210| Step: 0
Training loss: 2.120140353181246
Validation loss: 2.522446653008764

Epoch: 5| Step: 1
Training loss: 1.694189446792275
Validation loss: 2.6296812897467263

Epoch: 5| Step: 2
Training loss: 2.2034801440399283
Validation loss: 2.6786269422912667

Epoch: 5| Step: 3
Training loss: 2.415932434179353
Validation loss: 2.744461564318169

Epoch: 5| Step: 4
Training loss: 2.1715789153998815
Validation loss: 2.743730120783425

Epoch: 5| Step: 5
Training loss: 2.3369721127675596
Validation loss: 2.6922040704269556

Epoch: 5| Step: 6
Training loss: 1.780453687991633
Validation loss: 2.5787458659758227

Epoch: 5| Step: 7
Training loss: 1.5566129023860606
Validation loss: 2.50607612716014

Epoch: 5| Step: 8
Training loss: 1.5564567428592315
Validation loss: 2.489912524045194

Epoch: 5| Step: 9
Training loss: 2.0984309238265464
Validation loss: 2.448782744892642

Epoch: 5| Step: 10
Training loss: 2.230642335353538
Validation loss: 2.4698375249975326

Epoch: 211| Step: 0
Training loss: 1.7120843814572155
Validation loss: 2.4990010696143137

Epoch: 5| Step: 1
Training loss: 1.7720974468019286
Validation loss: 2.5123175598721366

Epoch: 5| Step: 2
Training loss: 1.8157796455745832
Validation loss: 2.568850332313241

Epoch: 5| Step: 3
Training loss: 1.5255255059504642
Validation loss: 2.631609984119336

Epoch: 5| Step: 4
Training loss: 2.18681880698845
Validation loss: 2.6499804499333193

Epoch: 5| Step: 5
Training loss: 1.76691585378843
Validation loss: 2.63857792981524

Epoch: 5| Step: 6
Training loss: 2.157358520395361
Validation loss: 2.6242746600123086

Epoch: 5| Step: 7
Training loss: 2.4970253413346315
Validation loss: 2.612699543772085

Epoch: 5| Step: 8
Training loss: 2.296057107846553
Validation loss: 2.5899099554554614

Epoch: 5| Step: 9
Training loss: 1.8101064728670615
Validation loss: 2.5773923213772396

Epoch: 5| Step: 10
Training loss: 2.0668059973766857
Validation loss: 2.5282968308765534

Epoch: 212| Step: 0
Training loss: 2.298112185735304
Validation loss: 2.484296833464078

Epoch: 5| Step: 1
Training loss: 2.14009867413923
Validation loss: 2.450403881539487

Epoch: 5| Step: 2
Training loss: 1.7063190013082148
Validation loss: 2.474862926926358

Epoch: 5| Step: 3
Training loss: 1.812121318852607
Validation loss: 2.487121744594334

Epoch: 5| Step: 4
Training loss: 2.0768950988917414
Validation loss: 2.498271452236104

Epoch: 5| Step: 5
Training loss: 2.037608713631482
Validation loss: 2.4807684005133583

Epoch: 5| Step: 6
Training loss: 1.8630383091221485
Validation loss: 2.489034120420705

Epoch: 5| Step: 7
Training loss: 1.5227264309832913
Validation loss: 2.48542171796449

Epoch: 5| Step: 8
Training loss: 2.1464694910340425
Validation loss: 2.5003248639431392

Epoch: 5| Step: 9
Training loss: 2.2706181718811305
Validation loss: 2.520261805673065

Epoch: 5| Step: 10
Training loss: 1.356584161472558
Validation loss: 2.552474202470063

Epoch: 213| Step: 0
Training loss: 1.5917604032679489
Validation loss: 2.609630929540487

Epoch: 5| Step: 1
Training loss: 2.2990611565126966
Validation loss: 2.6682092764226737

Epoch: 5| Step: 2
Training loss: 2.012232446359608
Validation loss: 2.693500728687844

Epoch: 5| Step: 3
Training loss: 2.3409910111937093
Validation loss: 2.7250954356043757

Epoch: 5| Step: 4
Training loss: 1.7880235345473545
Validation loss: 2.707869325429525

Epoch: 5| Step: 5
Training loss: 1.9512720702815234
Validation loss: 2.6552401973933484

Epoch: 5| Step: 6
Training loss: 2.2146365221824826
Validation loss: 2.586763883467335

Epoch: 5| Step: 7
Training loss: 1.4742495874718393
Validation loss: 2.5400877452241657

Epoch: 5| Step: 8
Training loss: 1.941591434358329
Validation loss: 2.4735593719978737

Epoch: 5| Step: 9
Training loss: 1.845776624073938
Validation loss: 2.459794609402206

Epoch: 5| Step: 10
Training loss: 1.9546074086223635
Validation loss: 2.4897024921025412

Epoch: 214| Step: 0
Training loss: 2.384236594966529
Validation loss: 2.5283924219674145

Epoch: 5| Step: 1
Training loss: 2.122526412098599
Validation loss: 2.538976187047464

Epoch: 5| Step: 2
Training loss: 1.6167593126525754
Validation loss: 2.5642508266322763

Epoch: 5| Step: 3
Training loss: 2.1151859070076116
Validation loss: 2.617539522130997

Epoch: 5| Step: 4
Training loss: 1.9494028864483701
Validation loss: 2.595932436827484

Epoch: 5| Step: 5
Training loss: 1.8477788969145996
Validation loss: 2.6081483082266375

Epoch: 5| Step: 6
Training loss: 2.0534917448707803
Validation loss: 2.609077223917091

Epoch: 5| Step: 7
Training loss: 1.5076646485254372
Validation loss: 2.579632036409098

Epoch: 5| Step: 8
Training loss: 1.762361058379228
Validation loss: 2.560075123292582

Epoch: 5| Step: 9
Training loss: 1.9712744377135718
Validation loss: 2.528336734702789

Epoch: 5| Step: 10
Training loss: 1.5941018108941767
Validation loss: 2.5456591291483663

Epoch: 215| Step: 0
Training loss: 1.8084990309759343
Validation loss: 2.53792745684603

Epoch: 5| Step: 1
Training loss: 1.7205538214036786
Validation loss: 2.5492350649687388

Epoch: 5| Step: 2
Training loss: 2.5835336074311708
Validation loss: 2.5307240782307003

Epoch: 5| Step: 3
Training loss: 1.6878392620256897
Validation loss: 2.5678465396509975

Epoch: 5| Step: 4
Training loss: 1.7119417770414205
Validation loss: 2.599428763675435

Epoch: 5| Step: 5
Training loss: 1.873146539767281
Validation loss: 2.636263323745795

Epoch: 5| Step: 6
Training loss: 1.962281272021762
Validation loss: 2.643464295611067

Epoch: 5| Step: 7
Training loss: 1.7869477412604229
Validation loss: 2.6815715475845265

Epoch: 5| Step: 8
Training loss: 1.9594567167773076
Validation loss: 2.707243732532966

Epoch: 5| Step: 9
Training loss: 1.685141646207402
Validation loss: 2.7201886616844884

Epoch: 5| Step: 10
Training loss: 1.967438457743142
Validation loss: 2.6081040197417824

Epoch: 216| Step: 0
Training loss: 1.7236290777668462
Validation loss: 2.577212022681645

Epoch: 5| Step: 1
Training loss: 2.69814914207447
Validation loss: 2.534609254020396

Epoch: 5| Step: 2
Training loss: 1.518400345100629
Validation loss: 2.5121764939059403

Epoch: 5| Step: 3
Training loss: 1.6202307184782245
Validation loss: 2.491646198846165

Epoch: 5| Step: 4
Training loss: 1.999498900580861
Validation loss: 2.4910800203993326

Epoch: 5| Step: 5
Training loss: 1.7827052813827011
Validation loss: 2.5371056251902666

Epoch: 5| Step: 6
Training loss: 1.96286712176927
Validation loss: 2.5414452445420372

Epoch: 5| Step: 7
Training loss: 1.7082365830479482
Validation loss: 2.5584941630148035

Epoch: 5| Step: 8
Training loss: 1.891385327506678
Validation loss: 2.5624344580007063

Epoch: 5| Step: 9
Training loss: 1.591903963757827
Validation loss: 2.558009978297769

Epoch: 5| Step: 10
Training loss: 2.0560273997859695
Validation loss: 2.5171910112616107

Epoch: 217| Step: 0
Training loss: 2.064487309023985
Validation loss: 2.5320655545009174

Epoch: 5| Step: 1
Training loss: 1.561106938205329
Validation loss: 2.5280932977742316

Epoch: 5| Step: 2
Training loss: 2.0520936091080233
Validation loss: 2.5586499600411083

Epoch: 5| Step: 3
Training loss: 2.0832327119052025
Validation loss: 2.5890115845479835

Epoch: 5| Step: 4
Training loss: 1.7706619927783163
Validation loss: 2.6013157885322835

Epoch: 5| Step: 5
Training loss: 1.8810288460855427
Validation loss: 2.603322682772158

Epoch: 5| Step: 6
Training loss: 2.000033020700614
Validation loss: 2.6166382062733375

Epoch: 5| Step: 7
Training loss: 1.7660320791698498
Validation loss: 2.5545741702075113

Epoch: 5| Step: 8
Training loss: 1.5317948598143654
Validation loss: 2.5619316791440134

Epoch: 5| Step: 9
Training loss: 2.0908006990556003
Validation loss: 2.6103824465890666

Epoch: 5| Step: 10
Training loss: 1.4958499082250905
Validation loss: 2.6223914862913413

Epoch: 218| Step: 0
Training loss: 1.6852201673387948
Validation loss: 2.660718722406553

Epoch: 5| Step: 1
Training loss: 1.6924983985025557
Validation loss: 2.67748073078077

Epoch: 5| Step: 2
Training loss: 1.6671796088849757
Validation loss: 2.649239284215298

Epoch: 5| Step: 3
Training loss: 2.162127900496515
Validation loss: 2.6808131334696808

Epoch: 5| Step: 4
Training loss: 1.9706575144545342
Validation loss: 2.6215869006901076

Epoch: 5| Step: 5
Training loss: 1.77137858654292
Validation loss: 2.5505539226324014

Epoch: 5| Step: 6
Training loss: 1.7624670499061834
Validation loss: 2.452929854052576

Epoch: 5| Step: 7
Training loss: 2.378698681324397
Validation loss: 2.444850936386448

Epoch: 5| Step: 8
Training loss: 1.8273968020627953
Validation loss: 2.4525482887659686

Epoch: 5| Step: 9
Training loss: 1.723444267529423
Validation loss: 2.477950241236704

Epoch: 5| Step: 10
Training loss: 1.5903368286022976
Validation loss: 2.5091351694295287

Epoch: 219| Step: 0
Training loss: 1.5724758599980126
Validation loss: 2.5805539251230134

Epoch: 5| Step: 1
Training loss: 2.1646125177123867
Validation loss: 2.5859919617489444

Epoch: 5| Step: 2
Training loss: 1.6850145191053836
Validation loss: 2.6860830048914277

Epoch: 5| Step: 3
Training loss: 1.5915326419878089
Validation loss: 2.74582208395248

Epoch: 5| Step: 4
Training loss: 1.9654895487148176
Validation loss: 2.7529236688836822

Epoch: 5| Step: 5
Training loss: 1.8748217815895938
Validation loss: 2.6560877635229967

Epoch: 5| Step: 6
Training loss: 1.4786419631819574
Validation loss: 2.5560053576959008

Epoch: 5| Step: 7
Training loss: 1.7603146525362554
Validation loss: 2.4682539689095004

Epoch: 5| Step: 8
Training loss: 2.3041936830266994
Validation loss: 2.4350427789959084

Epoch: 5| Step: 9
Training loss: 2.0364005884697565
Validation loss: 2.4249326512843963

Epoch: 5| Step: 10
Training loss: 1.7747225369935966
Validation loss: 2.4341287988139255

Epoch: 220| Step: 0
Training loss: 1.3613535633747924
Validation loss: 2.4671937038427774

Epoch: 5| Step: 1
Training loss: 1.7404997994615394
Validation loss: 2.5128838492171717

Epoch: 5| Step: 2
Training loss: 1.7524475284617216
Validation loss: 2.5613397802470232

Epoch: 5| Step: 3
Training loss: 1.57842297148754
Validation loss: 2.6108179197983046

Epoch: 5| Step: 4
Training loss: 1.4777881036762561
Validation loss: 2.6853280798121792

Epoch: 5| Step: 5
Training loss: 1.9943658624940022
Validation loss: 2.7231851718613647

Epoch: 5| Step: 6
Training loss: 2.143316984791597
Validation loss: 2.691600220637065

Epoch: 5| Step: 7
Training loss: 1.9087142025651653
Validation loss: 2.651710289746445

Epoch: 5| Step: 8
Training loss: 1.8029091400043449
Validation loss: 2.5946603208700623

Epoch: 5| Step: 9
Training loss: 1.7918129646837964
Validation loss: 2.5694502230594676

Epoch: 5| Step: 10
Training loss: 2.3178273259738322
Validation loss: 2.528609839076831

Epoch: 221| Step: 0
Training loss: 1.5294658621114294
Validation loss: 2.510133503588234

Epoch: 5| Step: 1
Training loss: 2.0089743254764567
Validation loss: 2.5819766471194785

Epoch: 5| Step: 2
Training loss: 1.517970521683378
Validation loss: 2.600063690544499

Epoch: 5| Step: 3
Training loss: 1.627748805422221
Validation loss: 2.6706975906778054

Epoch: 5| Step: 4
Training loss: 2.0014789596621942
Validation loss: 2.691874992176914

Epoch: 5| Step: 5
Training loss: 1.6696133869621488
Validation loss: 2.7036144982998045

Epoch: 5| Step: 6
Training loss: 2.061411368008704
Validation loss: 2.698924691420831

Epoch: 5| Step: 7
Training loss: 1.8851047981535038
Validation loss: 2.6815520714393783

Epoch: 5| Step: 8
Training loss: 1.7553707541941606
Validation loss: 2.6871467094839656

Epoch: 5| Step: 9
Training loss: 1.965516962863697
Validation loss: 2.630846609675437

Epoch: 5| Step: 10
Training loss: 1.5353655878660692
Validation loss: 2.5670134101069766

Epoch: 222| Step: 0
Training loss: 1.6335140345647463
Validation loss: 2.521129376865715

Epoch: 5| Step: 1
Training loss: 1.5070704081793793
Validation loss: 2.4834486486212

Epoch: 5| Step: 2
Training loss: 2.287299509069473
Validation loss: 2.4353535206484334

Epoch: 5| Step: 3
Training loss: 1.8971522497836733
Validation loss: 2.4478243281312397

Epoch: 5| Step: 4
Training loss: 1.7152999236427156
Validation loss: 2.4923293301297837

Epoch: 5| Step: 5
Training loss: 1.8013089745190134
Validation loss: 2.513616527608378

Epoch: 5| Step: 6
Training loss: 1.654831044542078
Validation loss: 2.5261507210989493

Epoch: 5| Step: 7
Training loss: 1.6785768607379243
Validation loss: 2.5878728783080827

Epoch: 5| Step: 8
Training loss: 1.8989945210663561
Validation loss: 2.6334719898915777

Epoch: 5| Step: 9
Training loss: 1.5842388056918955
Validation loss: 2.6766757730664117

Epoch: 5| Step: 10
Training loss: 1.7119749921193264
Validation loss: 2.7143495936374675

Epoch: 223| Step: 0
Training loss: 1.3509925125501898
Validation loss: 2.7743700395339195

Epoch: 5| Step: 1
Training loss: 1.6347552701378296
Validation loss: 2.7799772627546866

Epoch: 5| Step: 2
Training loss: 1.612894081043653
Validation loss: 2.761054841513715

Epoch: 5| Step: 3
Training loss: 2.0171497107998775
Validation loss: 2.703789505970058

Epoch: 5| Step: 4
Training loss: 1.6777338065700433
Validation loss: 2.6589724752915638

Epoch: 5| Step: 5
Training loss: 1.9391261014259606
Validation loss: 2.616478664480868

Epoch: 5| Step: 6
Training loss: 1.6141675680404508
Validation loss: 2.582165934286582

Epoch: 5| Step: 7
Training loss: 1.4124325795245132
Validation loss: 2.5634887012481418

Epoch: 5| Step: 8
Training loss: 1.530324851062765
Validation loss: 2.543884412408039

Epoch: 5| Step: 9
Training loss: 2.1656783368476966
Validation loss: 2.5289665333006983

Epoch: 5| Step: 10
Training loss: 2.1545022709202213
Validation loss: 2.535879555042104

Epoch: 224| Step: 0
Training loss: 1.5074998600644984
Validation loss: 2.5266722294371218

Epoch: 5| Step: 1
Training loss: 2.1464471648915895
Validation loss: 2.572498450121961

Epoch: 5| Step: 2
Training loss: 1.585898488133366
Validation loss: 2.6101833400846637

Epoch: 5| Step: 3
Training loss: 1.6119237180508703
Validation loss: 2.636930071931863

Epoch: 5| Step: 4
Training loss: 1.5060002796633842
Validation loss: 2.6833902296672196

Epoch: 5| Step: 5
Training loss: 1.7245338224665043
Validation loss: 2.7060442019655953

Epoch: 5| Step: 6
Training loss: 2.14021297304189
Validation loss: 2.7354660515442806

Epoch: 5| Step: 7
Training loss: 1.609977387216172
Validation loss: 2.7079963991959133

Epoch: 5| Step: 8
Training loss: 1.8021960875529979
Validation loss: 2.6213278401755535

Epoch: 5| Step: 9
Training loss: 1.5318204634572015
Validation loss: 2.5748540299902123

Epoch: 5| Step: 10
Training loss: 1.7032381772574872
Validation loss: 2.520600111757975

Epoch: 225| Step: 0
Training loss: 1.6077773673294224
Validation loss: 2.4873712908414953

Epoch: 5| Step: 1
Training loss: 2.054846927854146
Validation loss: 2.4696391716124086

Epoch: 5| Step: 2
Training loss: 1.793470590874074
Validation loss: 2.4874808993971507

Epoch: 5| Step: 3
Training loss: 1.209272359588069
Validation loss: 2.506943426979536

Epoch: 5| Step: 4
Training loss: 1.3649317415518492
Validation loss: 2.5679206889295005

Epoch: 5| Step: 5
Training loss: 1.8161013111389344
Validation loss: 2.610882485812014

Epoch: 5| Step: 6
Training loss: 1.8424826970316666
Validation loss: 2.615750831202753

Epoch: 5| Step: 7
Training loss: 2.089102754511776
Validation loss: 2.6420439502137323

Epoch: 5| Step: 8
Training loss: 2.035307133622301
Validation loss: 2.70100626984569

Epoch: 5| Step: 9
Training loss: 1.6597599768323672
Validation loss: 2.6833613533397025

Epoch: 5| Step: 10
Training loss: 1.7869828976761122
Validation loss: 2.6225957451617132

Epoch: 226| Step: 0
Training loss: 1.6082912610864553
Validation loss: 2.5522183276886015

Epoch: 5| Step: 1
Training loss: 1.8109085725805845
Validation loss: 2.5465933888589896

Epoch: 5| Step: 2
Training loss: 2.0821876681833142
Validation loss: 2.509827919361651

Epoch: 5| Step: 3
Training loss: 1.2702358227400175
Validation loss: 2.501412221465449

Epoch: 5| Step: 4
Training loss: 1.3902216122655866
Validation loss: 2.5066169437208354

Epoch: 5| Step: 5
Training loss: 2.0455829531890624
Validation loss: 2.5583244476960365

Epoch: 5| Step: 6
Training loss: 1.609038530750187
Validation loss: 2.625290945857229

Epoch: 5| Step: 7
Training loss: 1.5305173249882646
Validation loss: 2.6392570399276862

Epoch: 5| Step: 8
Training loss: 1.6163124260054034
Validation loss: 2.675651540562241

Epoch: 5| Step: 9
Training loss: 2.019456400858474
Validation loss: 2.6783586597122606

Epoch: 5| Step: 10
Training loss: 1.7728829882329573
Validation loss: 2.680911358177767

Epoch: 227| Step: 0
Training loss: 1.9061464375364785
Validation loss: 2.6709846112091498

Epoch: 5| Step: 1
Training loss: 1.7363658853722397
Validation loss: 2.671081133346711

Epoch: 5| Step: 2
Training loss: 1.525303797869955
Validation loss: 2.680286912652666

Epoch: 5| Step: 3
Training loss: 1.5564473222395734
Validation loss: 2.6480199269459286

Epoch: 5| Step: 4
Training loss: 1.9058015639850445
Validation loss: 2.645007761340948

Epoch: 5| Step: 5
Training loss: 1.4837511859943693
Validation loss: 2.6646403746064613

Epoch: 5| Step: 6
Training loss: 1.5158706151408616
Validation loss: 2.6546852034019066

Epoch: 5| Step: 7
Training loss: 1.71698135929731
Validation loss: 2.686578411829969

Epoch: 5| Step: 8
Training loss: 1.7842231832880642
Validation loss: 2.5965043620210375

Epoch: 5| Step: 9
Training loss: 1.691962593327958
Validation loss: 2.566614990316115

Epoch: 5| Step: 10
Training loss: 1.6836412604547442
Validation loss: 2.4625380819651355

Epoch: 228| Step: 0
Training loss: 1.960545352464728
Validation loss: 2.4501545399220035

Epoch: 5| Step: 1
Training loss: 1.6715946853799672
Validation loss: 2.43072681470174

Epoch: 5| Step: 2
Training loss: 1.9957909998322962
Validation loss: 2.443541642157414

Epoch: 5| Step: 3
Training loss: 1.3621316779421837
Validation loss: 2.4821093777201075

Epoch: 5| Step: 4
Training loss: 1.6670492527853393
Validation loss: 2.5214248342258054

Epoch: 5| Step: 5
Training loss: 1.5292701377821165
Validation loss: 2.579942568573565

Epoch: 5| Step: 6
Training loss: 1.6405977519361157
Validation loss: 2.5878171043919163

Epoch: 5| Step: 7
Training loss: 1.3391571955097668
Validation loss: 2.631759957514622

Epoch: 5| Step: 8
Training loss: 2.0968293277411236
Validation loss: 2.6226783462831054

Epoch: 5| Step: 9
Training loss: 1.323857801188611
Validation loss: 2.6280308096406326

Epoch: 5| Step: 10
Training loss: 1.9491175317571665
Validation loss: 2.653332088531179

Epoch: 229| Step: 0
Training loss: 1.4084849082292628
Validation loss: 2.551790544006031

Epoch: 5| Step: 1
Training loss: 1.3440557176445007
Validation loss: 2.5477776854379375

Epoch: 5| Step: 2
Training loss: 1.3234831080408969
Validation loss: 2.531046421782716

Epoch: 5| Step: 3
Training loss: 2.0086209936679476
Validation loss: 2.5265411437945735

Epoch: 5| Step: 4
Training loss: 1.4726083277182818
Validation loss: 2.563463413624752

Epoch: 5| Step: 5
Training loss: 1.6618544565733677
Validation loss: 2.568647330804997

Epoch: 5| Step: 6
Training loss: 1.6969545208755006
Validation loss: 2.5689722606373655

Epoch: 5| Step: 7
Training loss: 1.769499788994088
Validation loss: 2.55396543761773

Epoch: 5| Step: 8
Training loss: 1.8913177608193572
Validation loss: 2.556415517461673

Epoch: 5| Step: 9
Training loss: 1.4797840799878947
Validation loss: 2.5680883415479014

Epoch: 5| Step: 10
Training loss: 1.8619230746554618
Validation loss: 2.608167719157649

Epoch: 230| Step: 0
Training loss: 1.7858698313951944
Validation loss: 2.6199706348403953

Epoch: 5| Step: 1
Training loss: 1.5676600891327859
Validation loss: 2.5733686756460603

Epoch: 5| Step: 2
Training loss: 1.3215407126942902
Validation loss: 2.6133414810194706

Epoch: 5| Step: 3
Training loss: 1.5620680402670384
Validation loss: 2.626098611915367

Epoch: 5| Step: 4
Training loss: 1.6325435143085283
Validation loss: 2.6376586979069963

Epoch: 5| Step: 5
Training loss: 1.6382017859459317
Validation loss: 2.6329700248427197

Epoch: 5| Step: 6
Training loss: 1.6407036898679075
Validation loss: 2.65100726365534

Epoch: 5| Step: 7
Training loss: 1.3935735069025332
Validation loss: 2.638682511669672

Epoch: 5| Step: 8
Training loss: 1.4939965272120057
Validation loss: 2.6354187613527595

Epoch: 5| Step: 9
Training loss: 1.7338095078160434
Validation loss: 2.641206868845583

Epoch: 5| Step: 10
Training loss: 2.0416805370664117
Validation loss: 2.6003266510336096

Epoch: 231| Step: 0
Training loss: 1.699299356587576
Validation loss: 2.5498887357298754

Epoch: 5| Step: 1
Training loss: 1.7710285378369501
Validation loss: 2.5249934046222684

Epoch: 5| Step: 2
Training loss: 2.1359241409832785
Validation loss: 2.5296192109022324

Epoch: 5| Step: 3
Training loss: 1.5722835942538762
Validation loss: 2.5359448710016976

Epoch: 5| Step: 4
Training loss: 1.4680557233332538
Validation loss: 2.539310188170736

Epoch: 5| Step: 5
Training loss: 1.2122059731035923
Validation loss: 2.527293309348082

Epoch: 5| Step: 6
Training loss: 1.0399948182343726
Validation loss: 2.5615919031285146

Epoch: 5| Step: 7
Training loss: 2.0682675032343623
Validation loss: 2.593452576912259

Epoch: 5| Step: 8
Training loss: 1.4411207293644777
Validation loss: 2.605876299073832

Epoch: 5| Step: 9
Training loss: 1.3748823462348185
Validation loss: 2.647157827991371

Epoch: 5| Step: 10
Training loss: 1.442144189516965
Validation loss: 2.6503002766682973

Epoch: 232| Step: 0
Training loss: 1.7667015642042292
Validation loss: 2.6349824736357608

Epoch: 5| Step: 1
Training loss: 1.8643431126946044
Validation loss: 2.632428954101357

Epoch: 5| Step: 2
Training loss: 1.1545902402229082
Validation loss: 2.5693854570107777

Epoch: 5| Step: 3
Training loss: 1.7077415961146878
Validation loss: 2.5440291613022357

Epoch: 5| Step: 4
Training loss: 1.5382875921875194
Validation loss: 2.501718243410238

Epoch: 5| Step: 5
Training loss: 1.4403390629595627
Validation loss: 2.4888525314258696

Epoch: 5| Step: 6
Training loss: 1.521074232418038
Validation loss: 2.5167268910326315

Epoch: 5| Step: 7
Training loss: 1.6530634618024613
Validation loss: 2.54198166966142

Epoch: 5| Step: 8
Training loss: 1.8691892228938904
Validation loss: 2.644033498251582

Epoch: 5| Step: 9
Training loss: 1.722876709824902
Validation loss: 2.6212114671670954

Epoch: 5| Step: 10
Training loss: 1.0606830994176049
Validation loss: 2.671931509598017

Epoch: 233| Step: 0
Training loss: 1.8396214960387216
Validation loss: 2.645883358330751

Epoch: 5| Step: 1
Training loss: 1.3517047608758137
Validation loss: 2.641592669910362

Epoch: 5| Step: 2
Training loss: 1.799738186763162
Validation loss: 2.608833990319825

Epoch: 5| Step: 3
Training loss: 1.4477149585033025
Validation loss: 2.5504954926970496

Epoch: 5| Step: 4
Training loss: 1.5830371060917383
Validation loss: 2.533402093586721

Epoch: 5| Step: 5
Training loss: 1.4633520236519793
Validation loss: 2.562251732517515

Epoch: 5| Step: 6
Training loss: 1.9326793011075494
Validation loss: 2.564970253950601

Epoch: 5| Step: 7
Training loss: 1.3260802741572288
Validation loss: 2.5314902745184593

Epoch: 5| Step: 8
Training loss: 1.5136353322201859
Validation loss: 2.5454116584318274

Epoch: 5| Step: 9
Training loss: 1.5891221867007352
Validation loss: 2.521286795406408

Epoch: 5| Step: 10
Training loss: 1.3212758449166815
Validation loss: 2.574381710412072

Epoch: 234| Step: 0
Training loss: 1.4053762476507625
Validation loss: 2.580745513981128

Epoch: 5| Step: 1
Training loss: 1.4857929083173906
Validation loss: 2.614494042431896

Epoch: 5| Step: 2
Training loss: 1.6864161366144894
Validation loss: 2.622230908223512

Epoch: 5| Step: 3
Training loss: 1.5686260675968822
Validation loss: 2.6553058275696126

Epoch: 5| Step: 4
Training loss: 1.689530599063574
Validation loss: 2.635696204348657

Epoch: 5| Step: 5
Training loss: 1.5262078551676024
Validation loss: 2.6648399136039522

Epoch: 5| Step: 6
Training loss: 1.1724584525744637
Validation loss: 2.625650912133206

Epoch: 5| Step: 7
Training loss: 1.6768792385597988
Validation loss: 2.607969856143742

Epoch: 5| Step: 8
Training loss: 1.6507409801707573
Validation loss: 2.588099905828547

Epoch: 5| Step: 9
Training loss: 1.5147474442274862
Validation loss: 2.6015415803619493

Epoch: 5| Step: 10
Training loss: 1.571878288371778
Validation loss: 2.554171944659461

Epoch: 235| Step: 0
Training loss: 1.1840918471725868
Validation loss: 2.5642637560222528

Epoch: 5| Step: 1
Training loss: 1.3296820096934703
Validation loss: 2.5359692027492624

Epoch: 5| Step: 2
Training loss: 1.5709086183405174
Validation loss: 2.542032013497947

Epoch: 5| Step: 3
Training loss: 1.5279395460932028
Validation loss: 2.5412680079431103

Epoch: 5| Step: 4
Training loss: 1.71070051947111
Validation loss: 2.551487569643959

Epoch: 5| Step: 5
Training loss: 1.453399796293157
Validation loss: 2.5670514617630937

Epoch: 5| Step: 6
Training loss: 1.1530049124527868
Validation loss: 2.6099956094468135

Epoch: 5| Step: 7
Training loss: 1.6446679572688063
Validation loss: 2.602589136236165

Epoch: 5| Step: 8
Training loss: 1.5245706110059696
Validation loss: 2.6145571547340256

Epoch: 5| Step: 9
Training loss: 1.7790011213533878
Validation loss: 2.646183554334382

Epoch: 5| Step: 10
Training loss: 1.8093614699627036
Validation loss: 2.634844754432087

Epoch: 236| Step: 0
Training loss: 1.350053286383817
Validation loss: 2.625766759360645

Epoch: 5| Step: 1
Training loss: 1.0529086335004942
Validation loss: 2.6130433004522535

Epoch: 5| Step: 2
Training loss: 1.6348036165733646
Validation loss: 2.61263675652642

Epoch: 5| Step: 3
Training loss: 1.356434986138362
Validation loss: 2.6110981755847877

Epoch: 5| Step: 4
Training loss: 1.8313602609606952
Validation loss: 2.591866481572183

Epoch: 5| Step: 5
Training loss: 1.4573341034424454
Validation loss: 2.5709104800187093

Epoch: 5| Step: 6
Training loss: 1.5839833966309786
Validation loss: 2.608866325099522

Epoch: 5| Step: 7
Training loss: 1.1021084345727494
Validation loss: 2.594983862644683

Epoch: 5| Step: 8
Training loss: 1.8087642581064007
Validation loss: 2.5558261316429487

Epoch: 5| Step: 9
Training loss: 1.7706776793642056
Validation loss: 2.595520371120086

Epoch: 5| Step: 10
Training loss: 1.4780302473026485
Validation loss: 2.5976652416783272

Epoch: 237| Step: 0
Training loss: 1.7066117039537434
Validation loss: 2.561310491793472

Epoch: 5| Step: 1
Training loss: 1.2091911767639583
Validation loss: 2.5786795727252354

Epoch: 5| Step: 2
Training loss: 1.7745118101129524
Validation loss: 2.5965752424138837

Epoch: 5| Step: 3
Training loss: 1.3723189919353758
Validation loss: 2.606338075770803

Epoch: 5| Step: 4
Training loss: 1.411724623819364
Validation loss: 2.6115963319265223

Epoch: 5| Step: 5
Training loss: 1.131328689620364
Validation loss: 2.655390589434453

Epoch: 5| Step: 6
Training loss: 1.5582236708680077
Validation loss: 2.6062013276636544

Epoch: 5| Step: 7
Training loss: 1.6745168900183316
Validation loss: 2.646721968194592

Epoch: 5| Step: 8
Training loss: 1.1520378611985582
Validation loss: 2.62301439934004

Epoch: 5| Step: 9
Training loss: 1.6181393830392068
Validation loss: 2.6526235437429118

Epoch: 5| Step: 10
Training loss: 1.7593371751422189
Validation loss: 2.639058403164907

Epoch: 238| Step: 0
Training loss: 1.1675696568263347
Validation loss: 2.6173363839321224

Epoch: 5| Step: 1
Training loss: 1.6769469859297206
Validation loss: 2.5794812406036876

Epoch: 5| Step: 2
Training loss: 1.5224345500389243
Validation loss: 2.614221300639516

Epoch: 5| Step: 3
Training loss: 1.7139327773017392
Validation loss: 2.6324384902081515

Epoch: 5| Step: 4
Training loss: 1.5846256787625976
Validation loss: 2.616012628378995

Epoch: 5| Step: 5
Training loss: 1.6119155830164433
Validation loss: 2.6266544985808165

Epoch: 5| Step: 6
Training loss: 1.3054625441964725
Validation loss: 2.6289834085235966

Epoch: 5| Step: 7
Training loss: 1.5959884033690077
Validation loss: 2.586461397948213

Epoch: 5| Step: 8
Training loss: 1.5720579401117765
Validation loss: 2.587556931753762

Epoch: 5| Step: 9
Training loss: 1.5441902058113284
Validation loss: 2.556795864179768

Epoch: 5| Step: 10
Training loss: 0.8756132361134393
Validation loss: 2.5604728666196164

Epoch: 239| Step: 0
Training loss: 1.69868253819543
Validation loss: 2.564782831305302

Epoch: 5| Step: 1
Training loss: 1.685297765258908
Validation loss: 2.497182160426868

Epoch: 5| Step: 2
Training loss: 1.3874069870023749
Validation loss: 2.5758297932942797

Epoch: 5| Step: 3
Training loss: 1.5606249430468897
Validation loss: 2.582757855132392

Epoch: 5| Step: 4
Training loss: 1.5780151631118715
Validation loss: 2.6105220209866835

Epoch: 5| Step: 5
Training loss: 1.207445536504725
Validation loss: 2.643733330596035

Epoch: 5| Step: 6
Training loss: 1.5651062401003017
Validation loss: 2.669586199186985

Epoch: 5| Step: 7
Training loss: 1.6647502212352407
Validation loss: 2.7227142686079673

Epoch: 5| Step: 8
Training loss: 1.1497395199710516
Validation loss: 2.6946449341217154

Epoch: 5| Step: 9
Training loss: 1.4235328818229327
Validation loss: 2.640154148118475

Epoch: 5| Step: 10
Training loss: 1.3332440177487135
Validation loss: 2.596916365376391

Epoch: 240| Step: 0
Training loss: 0.7923250639466152
Validation loss: 2.5567310422895795

Epoch: 5| Step: 1
Training loss: 1.204728383361325
Validation loss: 2.539416115797373

Epoch: 5| Step: 2
Training loss: 1.7234624589373373
Validation loss: 2.520043294986878

Epoch: 5| Step: 3
Training loss: 1.4168149178667861
Validation loss: 2.5340457108610717

Epoch: 5| Step: 4
Training loss: 1.3236826934129196
Validation loss: 2.520642540231252

Epoch: 5| Step: 5
Training loss: 1.4569302848626462
Validation loss: 2.5666572709131987

Epoch: 5| Step: 6
Training loss: 1.6061176557234185
Validation loss: 2.6189465335190194

Epoch: 5| Step: 7
Training loss: 1.8652667137657997
Validation loss: 2.6930437462054995

Epoch: 5| Step: 8
Training loss: 1.7300674972156072
Validation loss: 2.745365692156944

Epoch: 5| Step: 9
Training loss: 1.4167955657809896
Validation loss: 2.65815215073093

Epoch: 5| Step: 10
Training loss: 1.5682649690900918
Validation loss: 2.5803927801913784

Epoch: 241| Step: 0
Training loss: 1.0708194840620426
Validation loss: 2.54081692470117

Epoch: 5| Step: 1
Training loss: 1.4050352147803802
Validation loss: 2.4940271049713596

Epoch: 5| Step: 2
Training loss: 1.4948253384119492
Validation loss: 2.5161097227769704

Epoch: 5| Step: 3
Training loss: 1.741465123697237
Validation loss: 2.5190221937594335

Epoch: 5| Step: 4
Training loss: 1.645359003147052
Validation loss: 2.531353451989664

Epoch: 5| Step: 5
Training loss: 1.6600874583633487
Validation loss: 2.5509749854691743

Epoch: 5| Step: 6
Training loss: 1.2464567988927826
Validation loss: 2.5976080017272207

Epoch: 5| Step: 7
Training loss: 1.2693441869394575
Validation loss: 2.6146734483857275

Epoch: 5| Step: 8
Training loss: 1.8124782297865862
Validation loss: 2.6448623518538614

Epoch: 5| Step: 9
Training loss: 1.340269816193243
Validation loss: 2.6802594232785437

Epoch: 5| Step: 10
Training loss: 1.2588638271623462
Validation loss: 2.635284074836908

Epoch: 242| Step: 0
Training loss: 1.4893771564629712
Validation loss: 2.665050452953641

Epoch: 5| Step: 1
Training loss: 1.3282055549875342
Validation loss: 2.627555400271011

Epoch: 5| Step: 2
Training loss: 1.2472608117579085
Validation loss: 2.5466228958999104

Epoch: 5| Step: 3
Training loss: 1.6522247055133104
Validation loss: 2.513496735312413

Epoch: 5| Step: 4
Training loss: 1.2512707449977774
Validation loss: 2.486708875125971

Epoch: 5| Step: 5
Training loss: 1.4441206683306305
Validation loss: 2.490561292994638

Epoch: 5| Step: 6
Training loss: 1.4999738532012734
Validation loss: 2.486739683461816

Epoch: 5| Step: 7
Training loss: 1.7447584538121739
Validation loss: 2.5194989286834377

Epoch: 5| Step: 8
Training loss: 1.3156434517696838
Validation loss: 2.570307468090586

Epoch: 5| Step: 9
Training loss: 1.6002950724073866
Validation loss: 2.5976667136420213

Epoch: 5| Step: 10
Training loss: 1.2613908087594385
Validation loss: 2.614151901447201

Epoch: 243| Step: 0
Training loss: 1.4273307010448784
Validation loss: 2.6785217426260473

Epoch: 5| Step: 1
Training loss: 1.6655362905386717
Validation loss: 2.672954904072741

Epoch: 5| Step: 2
Training loss: 1.4461744882558873
Validation loss: 2.7132247671422465

Epoch: 5| Step: 3
Training loss: 1.2218959991914065
Validation loss: 2.6328786571028386

Epoch: 5| Step: 4
Training loss: 1.4001748571871864
Validation loss: 2.5862288341132804

Epoch: 5| Step: 5
Training loss: 1.3230172166633996
Validation loss: 2.5260110142612158

Epoch: 5| Step: 6
Training loss: 1.6083244672672545
Validation loss: 2.4660605769643165

Epoch: 5| Step: 7
Training loss: 0.979997620482378
Validation loss: 2.4653851319672864

Epoch: 5| Step: 8
Training loss: 1.6760659142781726
Validation loss: 2.457823502525134

Epoch: 5| Step: 9
Training loss: 1.4975425139746448
Validation loss: 2.4957162796086845

Epoch: 5| Step: 10
Training loss: 1.6093233711331498
Validation loss: 2.5223422970358427

Epoch: 244| Step: 0
Training loss: 1.2914569233242919
Validation loss: 2.577202812422322

Epoch: 5| Step: 1
Training loss: 1.472081970435918
Validation loss: 2.6237780592815447

Epoch: 5| Step: 2
Training loss: 1.3339002367688209
Validation loss: 2.67986549081215

Epoch: 5| Step: 3
Training loss: 1.3986713064793763
Validation loss: 2.682598387905511

Epoch: 5| Step: 4
Training loss: 1.2745856509395967
Validation loss: 2.671112128185958

Epoch: 5| Step: 5
Training loss: 1.5879566136686232
Validation loss: 2.6790734215922414

Epoch: 5| Step: 6
Training loss: 1.266668666453205
Validation loss: 2.646724738416953

Epoch: 5| Step: 7
Training loss: 0.8797337684185474
Validation loss: 2.5925662060690664

Epoch: 5| Step: 8
Training loss: 1.4488344736955217
Validation loss: 2.5850004545551637

Epoch: 5| Step: 9
Training loss: 2.0598115449645005
Validation loss: 2.558297084807948

Epoch: 5| Step: 10
Training loss: 1.2972072037955857
Validation loss: 2.5133786554937596

Epoch: 245| Step: 0
Training loss: 1.2497275055465118
Validation loss: 2.5111286364028595

Epoch: 5| Step: 1
Training loss: 1.4256462973910788
Validation loss: 2.514779771990536

Epoch: 5| Step: 2
Training loss: 1.4841592732323352
Validation loss: 2.5093572964403457

Epoch: 5| Step: 3
Training loss: 1.282972108899032
Validation loss: 2.486009289965953

Epoch: 5| Step: 4
Training loss: 1.4963307006284776
Validation loss: 2.4983082338510134

Epoch: 5| Step: 5
Training loss: 1.244240222339869
Validation loss: 2.4912019701322157

Epoch: 5| Step: 6
Training loss: 1.8186256549710007
Validation loss: 2.508830913603259

Epoch: 5| Step: 7
Training loss: 1.519735366723228
Validation loss: 2.509644524201609

Epoch: 5| Step: 8
Training loss: 1.5293512834051497
Validation loss: 2.470753464418421

Epoch: 5| Step: 9
Training loss: 1.2522531230306493
Validation loss: 2.5608416657999524

Epoch: 5| Step: 10
Training loss: 0.9864551726750163
Validation loss: 2.583426733508452

Epoch: 246| Step: 0
Training loss: 1.3110809829630392
Validation loss: 2.6862793239545755

Epoch: 5| Step: 1
Training loss: 1.3587737233495718
Validation loss: 2.682290614687726

Epoch: 5| Step: 2
Training loss: 1.4563380988326757
Validation loss: 2.690845300965167

Epoch: 5| Step: 3
Training loss: 1.8438122625667925
Validation loss: 2.736625473298278

Epoch: 5| Step: 4
Training loss: 1.1083715494398374
Validation loss: 2.723555424949102

Epoch: 5| Step: 5
Training loss: 1.6289976538025954
Validation loss: 2.6863162960287403

Epoch: 5| Step: 6
Training loss: 0.6201797573932962
Validation loss: 2.6276272967927192

Epoch: 5| Step: 7
Training loss: 1.3765774694661517
Validation loss: 2.601985890169473

Epoch: 5| Step: 8
Training loss: 0.9868726379288955
Validation loss: 2.5790894187085978

Epoch: 5| Step: 9
Training loss: 1.50320457834721
Validation loss: 2.55230155716673

Epoch: 5| Step: 10
Training loss: 1.8113969537632504
Validation loss: 2.494805485068884

Epoch: 247| Step: 0
Training loss: 1.558299713316086
Validation loss: 2.5009267852929633

Epoch: 5| Step: 1
Training loss: 1.3868943224158707
Validation loss: 2.470383268559458

Epoch: 5| Step: 2
Training loss: 1.1496379572652575
Validation loss: 2.496413879289012

Epoch: 5| Step: 3
Training loss: 1.711378136596079
Validation loss: 2.5183622193986763

Epoch: 5| Step: 4
Training loss: 1.706530464792353
Validation loss: 2.518262355684273

Epoch: 5| Step: 5
Training loss: 1.2927575529545865
Validation loss: 2.5720638140198475

Epoch: 5| Step: 6
Training loss: 1.6358098895737458
Validation loss: 2.5923729661135457

Epoch: 5| Step: 7
Training loss: 1.0957926613303113
Validation loss: 2.6148896436048346

Epoch: 5| Step: 8
Training loss: 1.132375751357414
Validation loss: 2.6291552781036063

Epoch: 5| Step: 9
Training loss: 1.0502403029711749
Validation loss: 2.649926291346362

Epoch: 5| Step: 10
Training loss: 1.370273703501134
Validation loss: 2.655574176477221

Epoch: 248| Step: 0
Training loss: 1.625871937911144
Validation loss: 2.6285830419142844

Epoch: 5| Step: 1
Training loss: 1.3526859355188297
Validation loss: 2.645366020555962

Epoch: 5| Step: 2
Training loss: 1.411798086718403
Validation loss: 2.623697749906609

Epoch: 5| Step: 3
Training loss: 1.1086551856235762
Validation loss: 2.631768486864332

Epoch: 5| Step: 4
Training loss: 0.8765024501202684
Validation loss: 2.605774770730357

Epoch: 5| Step: 5
Training loss: 1.3750987450949101
Validation loss: 2.586747218724017

Epoch: 5| Step: 6
Training loss: 1.3918175459447426
Validation loss: 2.524892159336603

Epoch: 5| Step: 7
Training loss: 1.4656548047644526
Validation loss: 2.514865200259092

Epoch: 5| Step: 8
Training loss: 1.3039991196003382
Validation loss: 2.5076305267285464

Epoch: 5| Step: 9
Training loss: 1.781874363209033
Validation loss: 2.5071303884832474

Epoch: 5| Step: 10
Training loss: 1.2371243629234225
Validation loss: 2.574997884731776

Epoch: 249| Step: 0
Training loss: 1.5175133179483984
Validation loss: 2.5937055674647698

Epoch: 5| Step: 1
Training loss: 1.5663534331513964
Validation loss: 2.6146581645853555

Epoch: 5| Step: 2
Training loss: 1.7249830106921382
Validation loss: 2.6432410995155045

Epoch: 5| Step: 3
Training loss: 1.2471576322545828
Validation loss: 2.650990064722229

Epoch: 5| Step: 4
Training loss: 1.0772625334447241
Validation loss: 2.666843743623357

Epoch: 5| Step: 5
Training loss: 1.2634700749623307
Validation loss: 2.627198356944269

Epoch: 5| Step: 6
Training loss: 1.2893984732476673
Validation loss: 2.6141694702302654

Epoch: 5| Step: 7
Training loss: 1.2561781791539737
Validation loss: 2.6231564715201556

Epoch: 5| Step: 8
Training loss: 1.3277890397547016
Validation loss: 2.579726563031068

Epoch: 5| Step: 9
Training loss: 1.3868329068329066
Validation loss: 2.5597204004029295

Epoch: 5| Step: 10
Training loss: 1.038551147376851
Validation loss: 2.536230771729405

Epoch: 250| Step: 0
Training loss: 1.0245945337858975
Validation loss: 2.616598708987649

Epoch: 5| Step: 1
Training loss: 1.3922280062724208
Validation loss: 2.604254141702252

Epoch: 5| Step: 2
Training loss: 1.0872212239007835
Validation loss: 2.6210165020214657

Epoch: 5| Step: 3
Training loss: 1.7591368708879869
Validation loss: 2.6377755455891156

Epoch: 5| Step: 4
Training loss: 1.1935186950919778
Validation loss: 2.6373892561366707

Epoch: 5| Step: 5
Training loss: 1.1546255505453038
Validation loss: 2.615557571733652

Epoch: 5| Step: 6
Training loss: 1.224960641812572
Validation loss: 2.6142014497215462

Epoch: 5| Step: 7
Training loss: 1.0032126557742822
Validation loss: 2.5993687655404107

Epoch: 5| Step: 8
Training loss: 1.6981567571911664
Validation loss: 2.553588446130294

Epoch: 5| Step: 9
Training loss: 1.2046159201011926
Validation loss: 2.5593048352528696

Epoch: 5| Step: 10
Training loss: 1.8381885769461421
Validation loss: 2.5694963381411333

Epoch: 251| Step: 0
Training loss: 1.1882373127034258
Validation loss: 2.547527443813263

Epoch: 5| Step: 1
Training loss: 1.1419298729451062
Validation loss: 2.5632251940889166

Epoch: 5| Step: 2
Training loss: 1.1710332263171153
Validation loss: 2.5595740243907263

Epoch: 5| Step: 3
Training loss: 1.6098512852146318
Validation loss: 2.6203155812441357

Epoch: 5| Step: 4
Training loss: 1.4161803682453173
Validation loss: 2.6425875332904836

Epoch: 5| Step: 5
Training loss: 1.319217250181089
Validation loss: 2.7009763697839206

Epoch: 5| Step: 6
Training loss: 1.376576560183542
Validation loss: 2.664451539199459

Epoch: 5| Step: 7
Training loss: 1.563680965445761
Validation loss: 2.6143438777607884

Epoch: 5| Step: 8
Training loss: 1.1552959320638632
Validation loss: 2.5947364821975714

Epoch: 5| Step: 9
Training loss: 1.2625620949459715
Validation loss: 2.5724622359921603

Epoch: 5| Step: 10
Training loss: 1.455611286156056
Validation loss: 2.495199660593423

Epoch: 252| Step: 0
Training loss: 1.5025293165193556
Validation loss: 2.522406497452799

Epoch: 5| Step: 1
Training loss: 1.6805368094891868
Validation loss: 2.508153162947509

Epoch: 5| Step: 2
Training loss: 1.5045740007512334
Validation loss: 2.5593851878913645

Epoch: 5| Step: 3
Training loss: 0.7686104469478734
Validation loss: 2.5712358078281348

Epoch: 5| Step: 4
Training loss: 1.155044958717597
Validation loss: 2.632577883656235

Epoch: 5| Step: 5
Training loss: 1.5875311300274249
Validation loss: 2.6461078991294538

Epoch: 5| Step: 6
Training loss: 1.3020895487319104
Validation loss: 2.644898156242846

Epoch: 5| Step: 7
Training loss: 1.187912216918561
Validation loss: 2.618208789849977

Epoch: 5| Step: 8
Training loss: 1.151428790462626
Validation loss: 2.5952536865614575

Epoch: 5| Step: 9
Training loss: 1.304981906590051
Validation loss: 2.6041664139942333

Epoch: 5| Step: 10
Training loss: 1.1153236259916628
Validation loss: 2.5868790550679703

Epoch: 253| Step: 0
Training loss: 1.185912325746427
Validation loss: 2.54384754276381

Epoch: 5| Step: 1
Training loss: 1.4026964429476694
Validation loss: 2.5605661912377555

Epoch: 5| Step: 2
Training loss: 1.2106713771651407
Validation loss: 2.527255925040363

Epoch: 5| Step: 3
Training loss: 1.559800448125664
Validation loss: 2.551384985787647

Epoch: 5| Step: 4
Training loss: 1.2926012882706108
Validation loss: 2.525338238853398

Epoch: 5| Step: 5
Training loss: 0.9291606981288194
Validation loss: 2.550351202785734

Epoch: 5| Step: 6
Training loss: 1.3005384613826392
Validation loss: 2.536107405760193

Epoch: 5| Step: 7
Training loss: 1.3838554802504184
Validation loss: 2.5303291621818635

Epoch: 5| Step: 8
Training loss: 1.3790442205895026
Validation loss: 2.6264065510985857

Epoch: 5| Step: 9
Training loss: 1.563244985362846
Validation loss: 2.597571487271298

Epoch: 5| Step: 10
Training loss: 1.0674843281794884
Validation loss: 2.613248239971487

Epoch: 254| Step: 0
Training loss: 1.1217630229523017
Validation loss: 2.6211309710774606

Epoch: 5| Step: 1
Training loss: 1.4857346581801956
Validation loss: 2.6505910065396368

Epoch: 5| Step: 2
Training loss: 1.3149751757320147
Validation loss: 2.6257285138988293

Epoch: 5| Step: 3
Training loss: 1.1667820952851962
Validation loss: 2.627876017825941

Epoch: 5| Step: 4
Training loss: 1.17524473806898
Validation loss: 2.615773648306207

Epoch: 5| Step: 5
Training loss: 1.1968938801125413
Validation loss: 2.5903261242441045

Epoch: 5| Step: 6
Training loss: 1.6271770272852921
Validation loss: 2.5377013586226496

Epoch: 5| Step: 7
Training loss: 1.0065875038279328
Validation loss: 2.54355921319451

Epoch: 5| Step: 8
Training loss: 1.0616042905615866
Validation loss: 2.538318286050959

Epoch: 5| Step: 9
Training loss: 1.2047095824913
Validation loss: 2.474351772937879

Epoch: 5| Step: 10
Training loss: 1.7464324144838772
Validation loss: 2.5017109902054577

Epoch: 255| Step: 0
Training loss: 1.155737118767429
Validation loss: 2.5487358109547653

Epoch: 5| Step: 1
Training loss: 1.4726267035072704
Validation loss: 2.5666172446995708

Epoch: 5| Step: 2
Training loss: 0.8871843233283433
Validation loss: 2.603956076362063

Epoch: 5| Step: 3
Training loss: 1.2153528747365145
Validation loss: 2.6574933668984597

Epoch: 5| Step: 4
Training loss: 1.2704543762932758
Validation loss: 2.6506974133574124

Epoch: 5| Step: 5
Training loss: 1.6246924476085947
Validation loss: 2.6343315325968235

Epoch: 5| Step: 6
Training loss: 1.4154981206829567
Validation loss: 2.5316307564391343

Epoch: 5| Step: 7
Training loss: 1.2667542588331937
Validation loss: 2.465899743086483

Epoch: 5| Step: 8
Training loss: 1.6386691105924984
Validation loss: 2.465887362018251

Epoch: 5| Step: 9
Training loss: 1.1036157613236446
Validation loss: 2.4769479763367954

Epoch: 5| Step: 10
Training loss: 1.0691804119563533
Validation loss: 2.49957733170424

Epoch: 256| Step: 0
Training loss: 1.511973435980957
Validation loss: 2.533604903742019

Epoch: 5| Step: 1
Training loss: 1.3737253002553034
Validation loss: 2.582242881101181

Epoch: 5| Step: 2
Training loss: 1.2846779904469423
Validation loss: 2.5927646290823168

Epoch: 5| Step: 3
Training loss: 1.5795244111978985
Validation loss: 2.608017368149101

Epoch: 5| Step: 4
Training loss: 1.382098385316118
Validation loss: 2.6529788805239565

Epoch: 5| Step: 5
Training loss: 1.1018926247557377
Validation loss: 2.6574590557704454

Epoch: 5| Step: 6
Training loss: 1.3153655242564113
Validation loss: 2.662485392687036

Epoch: 5| Step: 7
Training loss: 1.091654541346257
Validation loss: 2.6325374992887816

Epoch: 5| Step: 8
Training loss: 1.096385722789752
Validation loss: 2.619038051549927

Epoch: 5| Step: 9
Training loss: 0.8183246322941006
Validation loss: 2.5145181921507302

Epoch: 5| Step: 10
Training loss: 1.2992512178751126
Validation loss: 2.509102064370377

Epoch: 257| Step: 0
Training loss: 1.1964546182477236
Validation loss: 2.491474575419766

Epoch: 5| Step: 1
Training loss: 1.4292239078517488
Validation loss: 2.512071056112845

Epoch: 5| Step: 2
Training loss: 1.2723765253743125
Validation loss: 2.5340227360344203

Epoch: 5| Step: 3
Training loss: 1.1796811337330806
Validation loss: 2.525660994710973

Epoch: 5| Step: 4
Training loss: 1.1262442807339197
Validation loss: 2.5316907893128366

Epoch: 5| Step: 5
Training loss: 1.3172567093700576
Validation loss: 2.575405674738036

Epoch: 5| Step: 6
Training loss: 1.21996129803165
Validation loss: 2.607747694036149

Epoch: 5| Step: 7
Training loss: 1.3525919439120728
Validation loss: 2.6166985598861414

Epoch: 5| Step: 8
Training loss: 1.1292942000904684
Validation loss: 2.641131670951386

Epoch: 5| Step: 9
Training loss: 1.271555627563835
Validation loss: 2.601269739848205

Epoch: 5| Step: 10
Training loss: 1.3711865602908502
Validation loss: 2.608603862813154

Epoch: 258| Step: 0
Training loss: 1.3013293053960087
Validation loss: 2.549694719645825

Epoch: 5| Step: 1
Training loss: 1.4348370308663154
Validation loss: 2.513257474286791

Epoch: 5| Step: 2
Training loss: 1.1409148279140464
Validation loss: 2.5198895762331075

Epoch: 5| Step: 3
Training loss: 1.2519750250985278
Validation loss: 2.496909774773648

Epoch: 5| Step: 4
Training loss: 1.324118281241251
Validation loss: 2.520187718997322

Epoch: 5| Step: 5
Training loss: 1.1067398904701031
Validation loss: 2.582153015606589

Epoch: 5| Step: 6
Training loss: 1.368989334781028
Validation loss: 2.57858131772997

Epoch: 5| Step: 7
Training loss: 1.371844268315582
Validation loss: 2.6812781581064136

Epoch: 5| Step: 8
Training loss: 0.9998259989037099
Validation loss: 2.618674082674595

Epoch: 5| Step: 9
Training loss: 1.4197796484069343
Validation loss: 2.578173944003088

Epoch: 5| Step: 10
Training loss: 1.0503270752430922
Validation loss: 2.4986839378473054

Epoch: 259| Step: 0
Training loss: 1.4906584410045236
Validation loss: 2.444601254904175

Epoch: 5| Step: 1
Training loss: 1.3488148007810525
Validation loss: 2.3946971089443756

Epoch: 5| Step: 2
Training loss: 1.3709068496996006
Validation loss: 2.4466864921808473

Epoch: 5| Step: 3
Training loss: 0.7334996139691773
Validation loss: 2.457209706948049

Epoch: 5| Step: 4
Training loss: 1.5651474458504533
Validation loss: 2.537762141410892

Epoch: 5| Step: 5
Training loss: 1.1402795346848373
Validation loss: 2.622306536670964

Epoch: 5| Step: 6
Training loss: 1.2744581192995361
Validation loss: 2.678653857910694

Epoch: 5| Step: 7
Training loss: 1.2056225701402035
Validation loss: 2.6785195489284384

Epoch: 5| Step: 8
Training loss: 1.0312639871284517
Validation loss: 2.6796175657213888

Epoch: 5| Step: 9
Training loss: 1.2945027543352101
Validation loss: 2.6158982092659615

Epoch: 5| Step: 10
Training loss: 1.362846020848527
Validation loss: 2.605268533888579

Epoch: 260| Step: 0
Training loss: 1.229383735024508
Validation loss: 2.5540195854000034

Epoch: 5| Step: 1
Training loss: 1.4060372509559427
Validation loss: 2.490755450306046

Epoch: 5| Step: 2
Training loss: 1.270714827259965
Validation loss: 2.468447185744259

Epoch: 5| Step: 3
Training loss: 1.1558413427763434
Validation loss: 2.4582546879233447

Epoch: 5| Step: 4
Training loss: 1.4596391916580682
Validation loss: 2.4538338162747357

Epoch: 5| Step: 5
Training loss: 1.2004751774621918
Validation loss: 2.443305859598107

Epoch: 5| Step: 6
Training loss: 1.3655485520253527
Validation loss: 2.44262793693964

Epoch: 5| Step: 7
Training loss: 1.2637972408411253
Validation loss: 2.497647558929746

Epoch: 5| Step: 8
Training loss: 0.783275382116784
Validation loss: 2.4809324487883617

Epoch: 5| Step: 9
Training loss: 1.3107056386550289
Validation loss: 2.5549989246890874

Epoch: 5| Step: 10
Training loss: 0.9648898959225125
Validation loss: 2.6316227106709453

Epoch: 261| Step: 0
Training loss: 1.1557675979135957
Validation loss: 2.6872508512309246

Epoch: 5| Step: 1
Training loss: 1.2010575899169782
Validation loss: 2.622721230353353

Epoch: 5| Step: 2
Training loss: 1.3826759400260615
Validation loss: 2.5598501184817435

Epoch: 5| Step: 3
Training loss: 1.2861994535636898
Validation loss: 2.550394820018248

Epoch: 5| Step: 4
Training loss: 1.1514918912568113
Validation loss: 2.4906068028996384

Epoch: 5| Step: 5
Training loss: 1.3560433612687284
Validation loss: 2.4190594246006643

Epoch: 5| Step: 6
Training loss: 1.1690117507193876
Validation loss: 2.4372670998698855

Epoch: 5| Step: 7
Training loss: 1.1058946200312278
Validation loss: 2.465807687748808

Epoch: 5| Step: 8
Training loss: 0.8840044802319154
Validation loss: 2.487716258560804

Epoch: 5| Step: 9
Training loss: 1.346228509446296
Validation loss: 2.5373603268318683

Epoch: 5| Step: 10
Training loss: 1.3821036035758882
Validation loss: 2.5951432994033152

Epoch: 262| Step: 0
Training loss: 1.4170132194446212
Validation loss: 2.6161536339329277

Epoch: 5| Step: 1
Training loss: 0.9729428462740946
Validation loss: 2.6461449180369274

Epoch: 5| Step: 2
Training loss: 1.0798967150467502
Validation loss: 2.6462702180124165

Epoch: 5| Step: 3
Training loss: 1.0616618384686147
Validation loss: 2.613531623705649

Epoch: 5| Step: 4
Training loss: 1.6148510700681862
Validation loss: 2.571383407293483

Epoch: 5| Step: 5
Training loss: 0.9805199051236643
Validation loss: 2.5554010968153924

Epoch: 5| Step: 6
Training loss: 1.163088551093175
Validation loss: 2.525294287820696

Epoch: 5| Step: 7
Training loss: 1.0347766684104514
Validation loss: 2.507532713858897

Epoch: 5| Step: 8
Training loss: 1.1069657935670105
Validation loss: 2.5335082677286964

Epoch: 5| Step: 9
Training loss: 1.0715491397321817
Validation loss: 2.4892867653909736

Epoch: 5| Step: 10
Training loss: 1.5021233629597266
Validation loss: 2.4620386095659663

Epoch: 263| Step: 0
Training loss: 1.2415750781251942
Validation loss: 2.4240551776484534

Epoch: 5| Step: 1
Training loss: 1.244878193975006
Validation loss: 2.418197940372856

Epoch: 5| Step: 2
Training loss: 1.1696863717540749
Validation loss: 2.401023338468046

Epoch: 5| Step: 3
Training loss: 1.1925499101506731
Validation loss: 2.4237858881959893

Epoch: 5| Step: 4
Training loss: 0.9749278310818043
Validation loss: 2.4382163594581145

Epoch: 5| Step: 5
Training loss: 1.2135543113126137
Validation loss: 2.5252957121247124

Epoch: 5| Step: 6
Training loss: 1.4502076427821768
Validation loss: 2.6007638474199353

Epoch: 5| Step: 7
Training loss: 1.2285338674867745
Validation loss: 2.6962231386955873

Epoch: 5| Step: 8
Training loss: 1.159469246953686
Validation loss: 2.738066678110647

Epoch: 5| Step: 9
Training loss: 1.088719269836717
Validation loss: 2.7416732395154546

Epoch: 5| Step: 10
Training loss: 1.3566655748458205
Validation loss: 2.703851387300338

Epoch: 264| Step: 0
Training loss: 1.1085359866125737
Validation loss: 2.5018149084431616

Epoch: 5| Step: 1
Training loss: 1.1559054918232812
Validation loss: 2.388901573669583

Epoch: 5| Step: 2
Training loss: 1.387366345128457
Validation loss: 2.292130798778889

Epoch: 5| Step: 3
Training loss: 1.4519704518529981
Validation loss: 2.317485476088574

Epoch: 5| Step: 4
Training loss: 1.4240179994924285
Validation loss: 2.28689401701574

Epoch: 5| Step: 5
Training loss: 1.2184362252114518
Validation loss: 2.4049939037482204

Epoch: 5| Step: 6
Training loss: 0.7936844625975887
Validation loss: 2.5528384275495566

Epoch: 5| Step: 7
Training loss: 1.0163759243170067
Validation loss: 2.6497488494507047

Epoch: 5| Step: 8
Training loss: 1.1489268706997864
Validation loss: 2.7034673237529536

Epoch: 5| Step: 9
Training loss: 1.299058156688735
Validation loss: 2.7115812573671585

Epoch: 5| Step: 10
Training loss: 1.6869346943342556
Validation loss: 2.6522606750833115

Epoch: 265| Step: 0
Training loss: 1.5133482359405872
Validation loss: 2.603015530713364

Epoch: 5| Step: 1
Training loss: 0.9412363619278623
Validation loss: 2.4918575072892564

Epoch: 5| Step: 2
Training loss: 1.1288737784074838
Validation loss: 2.4079072631123166

Epoch: 5| Step: 3
Training loss: 1.171568919581675
Validation loss: 2.329473441519545

Epoch: 5| Step: 4
Training loss: 1.4717908183198538
Validation loss: 2.3510092985119244

Epoch: 5| Step: 5
Training loss: 0.8437192699346421
Validation loss: 2.333867551001402

Epoch: 5| Step: 6
Training loss: 1.3337354302079754
Validation loss: 2.3875401143949393

Epoch: 5| Step: 7
Training loss: 0.8750981888856173
Validation loss: 2.391686224545726

Epoch: 5| Step: 8
Training loss: 1.3398253770463813
Validation loss: 2.445511890889355

Epoch: 5| Step: 9
Training loss: 1.2977387642621125
Validation loss: 2.49327228432195

Epoch: 5| Step: 10
Training loss: 0.969545345526691
Validation loss: 2.6009841872840873

Epoch: 266| Step: 0
Training loss: 1.0425586822972246
Validation loss: 2.647258891592372

Epoch: 5| Step: 1
Training loss: 1.1881797752215548
Validation loss: 2.6164142894764963

Epoch: 5| Step: 2
Training loss: 1.2009480089437061
Validation loss: 2.5656374870640817

Epoch: 5| Step: 3
Training loss: 1.160646071892383
Validation loss: 2.5140037858981676

Epoch: 5| Step: 4
Training loss: 1.268545008292798
Validation loss: 2.4740932301313303

Epoch: 5| Step: 5
Training loss: 1.324342029875833
Validation loss: 2.4622837096383

Epoch: 5| Step: 6
Training loss: 0.9164226091490597
Validation loss: 2.430016800158005

Epoch: 5| Step: 7
Training loss: 1.0416272855308084
Validation loss: 2.4510098392544144

Epoch: 5| Step: 8
Training loss: 1.027914548628694
Validation loss: 2.3992499758753705

Epoch: 5| Step: 9
Training loss: 1.4242113641577723
Validation loss: 2.4205702279508685

Epoch: 5| Step: 10
Training loss: 0.9495253832951116
Validation loss: 2.4617800513669956

Epoch: 267| Step: 0
Training loss: 1.12971356838007
Validation loss: 2.450632557002458

Epoch: 5| Step: 1
Training loss: 1.410887594597216
Validation loss: 2.5184611691156356

Epoch: 5| Step: 2
Training loss: 0.642782949715134
Validation loss: 2.5916601786792577

Epoch: 5| Step: 3
Training loss: 1.3109189456176802
Validation loss: 2.592650701316311

Epoch: 5| Step: 4
Training loss: 1.1450991214509305
Validation loss: 2.6059713838013296

Epoch: 5| Step: 5
Training loss: 1.136716705005812
Validation loss: 2.6203919458972393

Epoch: 5| Step: 6
Training loss: 1.2739497365632888
Validation loss: 2.5594923440228783

Epoch: 5| Step: 7
Training loss: 1.0907055035367024
Validation loss: 2.514135864788724

Epoch: 5| Step: 8
Training loss: 1.1697434430983185
Validation loss: 2.545003172314033

Epoch: 5| Step: 9
Training loss: 1.0065513230762917
Validation loss: 2.5505874565951614

Epoch: 5| Step: 10
Training loss: 0.9902701286768342
Validation loss: 2.534870123911041

Epoch: 268| Step: 0
Training loss: 1.250739260462529
Validation loss: 2.487981590869931

Epoch: 5| Step: 1
Training loss: 1.1275927019600969
Validation loss: 2.4858884622524045

Epoch: 5| Step: 2
Training loss: 1.3313257580902815
Validation loss: 2.475615546318502

Epoch: 5| Step: 3
Training loss: 1.2616210994193386
Validation loss: 2.4723815376567333

Epoch: 5| Step: 4
Training loss: 0.8509256623923065
Validation loss: 2.4530705250688305

Epoch: 5| Step: 5
Training loss: 0.8129835157283377
Validation loss: 2.4611746006283637

Epoch: 5| Step: 6
Training loss: 1.029414769176298
Validation loss: 2.5003701787086112

Epoch: 5| Step: 7
Training loss: 0.8845951008624158
Validation loss: 2.528042392417197

Epoch: 5| Step: 8
Training loss: 1.257176872434175
Validation loss: 2.514082209118021

Epoch: 5| Step: 9
Training loss: 1.2503610566351497
Validation loss: 2.5429272349074057

Epoch: 5| Step: 10
Training loss: 0.9302144841029603
Validation loss: 2.462208110616229

Epoch: 269| Step: 0
Training loss: 0.9718698900094573
Validation loss: 2.425188007853829

Epoch: 5| Step: 1
Training loss: 0.9226513196278885
Validation loss: 2.3939473144548153

Epoch: 5| Step: 2
Training loss: 1.148526454257167
Validation loss: 2.4268606915515787

Epoch: 5| Step: 3
Training loss: 1.328082858146325
Validation loss: 2.3947330400467375

Epoch: 5| Step: 4
Training loss: 1.2216358741081899
Validation loss: 2.4450575717848624

Epoch: 5| Step: 5
Training loss: 1.1749108219799973
Validation loss: 2.469548208643389

Epoch: 5| Step: 6
Training loss: 1.0365394419974014
Validation loss: 2.5235310087025993

Epoch: 5| Step: 7
Training loss: 0.9198260733252318
Validation loss: 2.534645350533251

Epoch: 5| Step: 8
Training loss: 1.0429913236196815
Validation loss: 2.5114951281933373

Epoch: 5| Step: 9
Training loss: 1.1887486568728138
Validation loss: 2.5688713814518653

Epoch: 5| Step: 10
Training loss: 1.0691261677989292
Validation loss: 2.5915341153998317

Epoch: 270| Step: 0
Training loss: 1.5290893569792439
Validation loss: 2.586834194320939

Epoch: 5| Step: 1
Training loss: 1.0424226052442427
Validation loss: 2.6378853479910673

Epoch: 5| Step: 2
Training loss: 0.8585613907607406
Validation loss: 2.6068182229547694

Epoch: 5| Step: 3
Training loss: 1.0559209322299943
Validation loss: 2.563656600700624

Epoch: 5| Step: 4
Training loss: 1.1107500178311123
Validation loss: 2.5278503201416616

Epoch: 5| Step: 5
Training loss: 0.8125179362151307
Validation loss: 2.5149638176415587

Epoch: 5| Step: 6
Training loss: 1.0072125563906138
Validation loss: 2.5110508608680466

Epoch: 5| Step: 7
Training loss: 0.8196391657352283
Validation loss: 2.4782746460310974

Epoch: 5| Step: 8
Training loss: 1.18014416476708
Validation loss: 2.458022850067184

Epoch: 5| Step: 9
Training loss: 1.0906929344726932
Validation loss: 2.4561113560297314

Epoch: 5| Step: 10
Training loss: 1.258256964018688
Validation loss: 2.4502526396812825

Epoch: 271| Step: 0
Training loss: 1.0661762814008997
Validation loss: 2.41933264373525

Epoch: 5| Step: 1
Training loss: 1.2733005379819111
Validation loss: 2.450855263473492

Epoch: 5| Step: 2
Training loss: 0.9897497371838002
Validation loss: 2.4572119427683647

Epoch: 5| Step: 3
Training loss: 1.1639605483910331
Validation loss: 2.4973873658518784

Epoch: 5| Step: 4
Training loss: 1.1323504854078015
Validation loss: 2.508857323092689

Epoch: 5| Step: 5
Training loss: 1.10844963056338
Validation loss: 2.562341486572386

Epoch: 5| Step: 6
Training loss: 0.9084821375013026
Validation loss: 2.5757832412094706

Epoch: 5| Step: 7
Training loss: 1.0901519449003294
Validation loss: 2.5116968748655486

Epoch: 5| Step: 8
Training loss: 1.1390435739208598
Validation loss: 2.5342329591356294

Epoch: 5| Step: 9
Training loss: 1.1390916106346376
Validation loss: 2.575738537557195

Epoch: 5| Step: 10
Training loss: 0.466380056926883
Validation loss: 2.5161638599296063

Epoch: 272| Step: 0
Training loss: 0.9563201753884101
Validation loss: 2.565078249664495

Epoch: 5| Step: 1
Training loss: 1.1896829617942064
Validation loss: 2.5407583888973497

Epoch: 5| Step: 2
Training loss: 1.3133469528292436
Validation loss: 2.5081840308673478

Epoch: 5| Step: 3
Training loss: 1.2685200111636135
Validation loss: 2.496607196898648

Epoch: 5| Step: 4
Training loss: 1.1352643018677258
Validation loss: 2.492436757627371

Epoch: 5| Step: 5
Training loss: 0.999948351241505
Validation loss: 2.457649358626394

Epoch: 5| Step: 6
Training loss: 1.0199270247552572
Validation loss: 2.474752168002631

Epoch: 5| Step: 7
Training loss: 0.866724835944037
Validation loss: 2.5048648927217885

Epoch: 5| Step: 8
Training loss: 0.5858026730864864
Validation loss: 2.503899719834865

Epoch: 5| Step: 9
Training loss: 0.9190723359775921
Validation loss: 2.550914326064131

Epoch: 5| Step: 10
Training loss: 1.156541581375693
Validation loss: 2.5775405176506867

Epoch: 273| Step: 0
Training loss: 1.1861605870402543
Validation loss: 2.58091767452726

Epoch: 5| Step: 1
Training loss: 1.289391169407355
Validation loss: 2.5743851041906605

Epoch: 5| Step: 2
Training loss: 0.933790816572912
Validation loss: 2.5388625451954177

Epoch: 5| Step: 3
Training loss: 1.0745878937826507
Validation loss: 2.577846573965491

Epoch: 5| Step: 4
Training loss: 1.1173843530471923
Validation loss: 2.522832494891914

Epoch: 5| Step: 5
Training loss: 0.6723573195470874
Validation loss: 2.489897937507347

Epoch: 5| Step: 6
Training loss: 1.2426970774206634
Validation loss: 2.451416567142906

Epoch: 5| Step: 7
Training loss: 0.9409617724117969
Validation loss: 2.485936932849794

Epoch: 5| Step: 8
Training loss: 1.1139721784319272
Validation loss: 2.4562370657113872

Epoch: 5| Step: 9
Training loss: 0.9805297832566187
Validation loss: 2.4752919001851095

Epoch: 5| Step: 10
Training loss: 0.7180248417076711
Validation loss: 2.4971918454787785

Epoch: 274| Step: 0
Training loss: 0.977451652101938
Validation loss: 2.4750304704060193

Epoch: 5| Step: 1
Training loss: 0.7784237284382047
Validation loss: 2.5141645424027863

Epoch: 5| Step: 2
Training loss: 1.024377289467488
Validation loss: 2.6104994845129066

Epoch: 5| Step: 3
Training loss: 0.9168334758589463
Validation loss: 2.5699764385717843

Epoch: 5| Step: 4
Training loss: 0.965429892473394
Validation loss: 2.568338518304827

Epoch: 5| Step: 5
Training loss: 1.135060414878384
Validation loss: 2.4883288538962627

Epoch: 5| Step: 6
Training loss: 1.2698319768518294
Validation loss: 2.5122524021114057

Epoch: 5| Step: 7
Training loss: 1.010697722263172
Validation loss: 2.481823246958738

Epoch: 5| Step: 8
Training loss: 0.75456710866094
Validation loss: 2.4172408624415973

Epoch: 5| Step: 9
Training loss: 1.2815567207717722
Validation loss: 2.4583658762328713

Epoch: 5| Step: 10
Training loss: 1.2073958256804624
Validation loss: 2.456422561328173

Epoch: 275| Step: 0
Training loss: 1.2158994350195795
Validation loss: 2.4652534870932787

Epoch: 5| Step: 1
Training loss: 0.9894280395460353
Validation loss: 2.442328864229223

Epoch: 5| Step: 2
Training loss: 1.0605353535681439
Validation loss: 2.488298231111269

Epoch: 5| Step: 3
Training loss: 1.1079834820896732
Validation loss: 2.4951738714770944

Epoch: 5| Step: 4
Training loss: 0.8637307149166761
Validation loss: 2.539016767142029

Epoch: 5| Step: 5
Training loss: 0.8370247659722265
Validation loss: 2.5447372986468526

Epoch: 5| Step: 6
Training loss: 0.9163565905970646
Validation loss: 2.610571442733112

Epoch: 5| Step: 7
Training loss: 0.8783154345600246
Validation loss: 2.5906029992411486

Epoch: 5| Step: 8
Training loss: 1.1682491922667584
Validation loss: 2.5992464394177017

Epoch: 5| Step: 9
Training loss: 1.0188119623730267
Validation loss: 2.5591814235603016

Epoch: 5| Step: 10
Training loss: 1.120469294898864
Validation loss: 2.523753262354249

Epoch: 276| Step: 0
Training loss: 0.7369503154881042
Validation loss: 2.5938047266638975

Epoch: 5| Step: 1
Training loss: 0.6750969923058359
Validation loss: 2.5237702160791358

Epoch: 5| Step: 2
Training loss: 0.9580559985751315
Validation loss: 2.528075573955204

Epoch: 5| Step: 3
Training loss: 0.9782598469562991
Validation loss: 2.513041772021417

Epoch: 5| Step: 4
Training loss: 1.3383773029906487
Validation loss: 2.5287546852311764

Epoch: 5| Step: 5
Training loss: 0.9958564326002765
Validation loss: 2.5338514554979965

Epoch: 5| Step: 6
Training loss: 1.1444263605481164
Validation loss: 2.490593544145633

Epoch: 5| Step: 7
Training loss: 0.966815185373483
Validation loss: 2.510836052604695

Epoch: 5| Step: 8
Training loss: 1.1950174603323869
Validation loss: 2.512042109159457

Epoch: 5| Step: 9
Training loss: 0.8991711482118131
Validation loss: 2.501922874930317

Epoch: 5| Step: 10
Training loss: 1.0711123408534307
Validation loss: 2.498122673267256

Epoch: 277| Step: 0
Training loss: 1.1429791129966382
Validation loss: 2.4836919455277613

Epoch: 5| Step: 1
Training loss: 0.972784133531872
Validation loss: 2.502782421792072

Epoch: 5| Step: 2
Training loss: 1.176786784848219
Validation loss: 2.4806084267096766

Epoch: 5| Step: 3
Training loss: 0.7869416619046042
Validation loss: 2.5274994771069204

Epoch: 5| Step: 4
Training loss: 0.8409429409796604
Validation loss: 2.5049885027071017

Epoch: 5| Step: 5
Training loss: 1.0202805261436156
Validation loss: 2.4993962430495738

Epoch: 5| Step: 6
Training loss: 1.1277488398375788
Validation loss: 2.4743151584323266

Epoch: 5| Step: 7
Training loss: 1.1073528719063817
Validation loss: 2.4373244218929058

Epoch: 5| Step: 8
Training loss: 1.1126935511891998
Validation loss: 2.474956620272182

Epoch: 5| Step: 9
Training loss: 0.7865320554289088
Validation loss: 2.496877989207042

Epoch: 5| Step: 10
Training loss: 0.9226676636586655
Validation loss: 2.496173071744719

Epoch: 278| Step: 0
Training loss: 0.631331984228823
Validation loss: 2.525767126325196

Epoch: 5| Step: 1
Training loss: 0.8649790023173515
Validation loss: 2.593607234769324

Epoch: 5| Step: 2
Training loss: 1.1511350855597287
Validation loss: 2.606873599685537

Epoch: 5| Step: 3
Training loss: 0.8260228087945294
Validation loss: 2.598790303010262

Epoch: 5| Step: 4
Training loss: 1.1634003464890912
Validation loss: 2.590083254820107

Epoch: 5| Step: 5
Training loss: 1.3396683736636665
Validation loss: 2.5570552741647283

Epoch: 5| Step: 6
Training loss: 0.6789208615819096
Validation loss: 2.5213929113489164

Epoch: 5| Step: 7
Training loss: 0.6293031376077755
Validation loss: 2.529708889434771

Epoch: 5| Step: 8
Training loss: 0.8864868465788182
Validation loss: 2.548712892606675

Epoch: 5| Step: 9
Training loss: 1.1868413805305547
Validation loss: 2.50717460808308

Epoch: 5| Step: 10
Training loss: 1.4302066214880687
Validation loss: 2.4872356179274493

Epoch: 279| Step: 0
Training loss: 1.2298621241510719
Validation loss: 2.53789147873504

Epoch: 5| Step: 1
Training loss: 0.652403457558882
Validation loss: 2.5264020724643563

Epoch: 5| Step: 2
Training loss: 0.6546863592315422
Validation loss: 2.517855691176383

Epoch: 5| Step: 3
Training loss: 0.9367840258178652
Validation loss: 2.5416237639046177

Epoch: 5| Step: 4
Training loss: 1.2609419188014321
Validation loss: 2.5592162719389284

Epoch: 5| Step: 5
Training loss: 0.6870914025311927
Validation loss: 2.5608662315029624

Epoch: 5| Step: 6
Training loss: 1.119328188532384
Validation loss: 2.5395563965089565

Epoch: 5| Step: 7
Training loss: 1.150820070687971
Validation loss: 2.5237426695197396

Epoch: 5| Step: 8
Training loss: 0.7725560724098899
Validation loss: 2.5162241640083907

Epoch: 5| Step: 9
Training loss: 0.9272103847640449
Validation loss: 2.479336198604753

Epoch: 5| Step: 10
Training loss: 1.2514601285788318
Validation loss: 2.5028641035320045

Epoch: 280| Step: 0
Training loss: 0.7055955715817365
Validation loss: 2.532586299366587

Epoch: 5| Step: 1
Training loss: 1.0373922131171314
Validation loss: 2.51363053285331

Epoch: 5| Step: 2
Training loss: 1.3143284187279833
Validation loss: 2.549266284708129

Epoch: 5| Step: 3
Training loss: 0.9863887050644844
Validation loss: 2.545398381994251

Epoch: 5| Step: 4
Training loss: 1.0467132898949338
Validation loss: 2.5683654637855073

Epoch: 5| Step: 5
Training loss: 0.7970133268685187
Validation loss: 2.521010317818937

Epoch: 5| Step: 6
Training loss: 1.1819952314477509
Validation loss: 2.537152587847985

Epoch: 5| Step: 7
Training loss: 1.2573214692020906
Validation loss: 2.57343487010869

Epoch: 5| Step: 8
Training loss: 1.0099560320131424
Validation loss: 2.5559920871379185

Epoch: 5| Step: 9
Training loss: 0.5638343825276478
Validation loss: 2.531275855544703

Epoch: 5| Step: 10
Training loss: 0.4949788308433555
Validation loss: 2.569757737742316

Epoch: 281| Step: 0
Training loss: 1.167242430348055
Validation loss: 2.5466330945796263

Epoch: 5| Step: 1
Training loss: 0.5955831938539224
Validation loss: 2.5413048895397052

Epoch: 5| Step: 2
Training loss: 0.9018969399789952
Validation loss: 2.529529203861595

Epoch: 5| Step: 3
Training loss: 1.0417815462979314
Validation loss: 2.5101349354734865

Epoch: 5| Step: 4
Training loss: 0.8198840521039229
Validation loss: 2.5335686466964145

Epoch: 5| Step: 5
Training loss: 0.7834374512473458
Validation loss: 2.497271804752007

Epoch: 5| Step: 6
Training loss: 1.2804809681447373
Validation loss: 2.5037900774773854

Epoch: 5| Step: 7
Training loss: 1.1508977578536648
Validation loss: 2.459328603949904

Epoch: 5| Step: 8
Training loss: 0.9965000296409438
Validation loss: 2.4818107945145798

Epoch: 5| Step: 9
Training loss: 0.7566600176719345
Validation loss: 2.4323489439821984

Epoch: 5| Step: 10
Training loss: 0.98995555435943
Validation loss: 2.4764811960941566

Epoch: 282| Step: 0
Training loss: 1.028666004353341
Validation loss: 2.4776404289557052

Epoch: 5| Step: 1
Training loss: 0.7651186845378863
Validation loss: 2.4626593162263073

Epoch: 5| Step: 2
Training loss: 0.6747311498207428
Validation loss: 2.5096293628236213

Epoch: 5| Step: 3
Training loss: 1.0708531594327384
Validation loss: 2.5155284029687373

Epoch: 5| Step: 4
Training loss: 1.173806899604012
Validation loss: 2.5249120326371317

Epoch: 5| Step: 5
Training loss: 0.9384422018090243
Validation loss: 2.527139646103604

Epoch: 5| Step: 6
Training loss: 1.0660624526303912
Validation loss: 2.486095408328193

Epoch: 5| Step: 7
Training loss: 1.1237288817393416
Validation loss: 2.497361386320005

Epoch: 5| Step: 8
Training loss: 0.9778963668811926
Validation loss: 2.457734370971165

Epoch: 5| Step: 9
Training loss: 0.7811675981934255
Validation loss: 2.469740242608104

Epoch: 5| Step: 10
Training loss: 0.8448989251309525
Validation loss: 2.500818901891993

Epoch: 283| Step: 0
Training loss: 0.7843820731159473
Validation loss: 2.509386217664372

Epoch: 5| Step: 1
Training loss: 1.1216314534918135
Validation loss: 2.554789492163703

Epoch: 5| Step: 2
Training loss: 0.7392420899345645
Validation loss: 2.5395267225639886

Epoch: 5| Step: 3
Training loss: 0.9597702690760499
Validation loss: 2.5851530555676083

Epoch: 5| Step: 4
Training loss: 0.8579869938822747
Validation loss: 2.5746910795585918

Epoch: 5| Step: 5
Training loss: 1.1118703367533254
Validation loss: 2.592643469145101

Epoch: 5| Step: 6
Training loss: 0.728671509783647
Validation loss: 2.6141074155640585

Epoch: 5| Step: 7
Training loss: 1.2866889139502014
Validation loss: 2.5776743072616104

Epoch: 5| Step: 8
Training loss: 1.00797861785387
Validation loss: 2.5996950337479303

Epoch: 5| Step: 9
Training loss: 1.0304454207942801
Validation loss: 2.5445526716273803

Epoch: 5| Step: 10
Training loss: 0.7265117996738302
Validation loss: 2.5386357915487183

Epoch: 284| Step: 0
Training loss: 0.5855223138402864
Validation loss: 2.514325007215828

Epoch: 5| Step: 1
Training loss: 0.9689900808328596
Validation loss: 2.496043840496993

Epoch: 5| Step: 2
Training loss: 1.1296108911056786
Validation loss: 2.4902837235517254

Epoch: 5| Step: 3
Training loss: 0.9760424030074548
Validation loss: 2.5148303759607855

Epoch: 5| Step: 4
Training loss: 0.8412872683699949
Validation loss: 2.528704358897863

Epoch: 5| Step: 5
Training loss: 0.9913096111022942
Validation loss: 2.5385378099989273

Epoch: 5| Step: 6
Training loss: 0.8734348808890775
Validation loss: 2.5258472908690948

Epoch: 5| Step: 7
Training loss: 0.8855421014832952
Validation loss: 2.4960504261353553

Epoch: 5| Step: 8
Training loss: 0.8042287166816114
Validation loss: 2.5121504223974394

Epoch: 5| Step: 9
Training loss: 0.851406188057547
Validation loss: 2.5096763963025306

Epoch: 5| Step: 10
Training loss: 1.4144675164806129
Validation loss: 2.4893053699148315

Epoch: 285| Step: 0
Training loss: 1.1875630412183076
Validation loss: 2.519309281376746

Epoch: 5| Step: 1
Training loss: 0.7257540727501737
Validation loss: 2.504421944118783

Epoch: 5| Step: 2
Training loss: 0.9441096953004211
Validation loss: 2.5152154394316364

Epoch: 5| Step: 3
Training loss: 1.0941389209825292
Validation loss: 2.540937980585533

Epoch: 5| Step: 4
Training loss: 1.0219800632607534
Validation loss: 2.580745471266127

Epoch: 5| Step: 5
Training loss: 0.8359100123369311
Validation loss: 2.624620780371037

Epoch: 5| Step: 6
Training loss: 0.964963835992287
Validation loss: 2.5905446522253763

Epoch: 5| Step: 7
Training loss: 0.7159725927563052
Validation loss: 2.5738126704074453

Epoch: 5| Step: 8
Training loss: 0.9000003324614017
Validation loss: 2.521650185204987

Epoch: 5| Step: 9
Training loss: 0.8638192481121071
Validation loss: 2.499332286511986

Epoch: 5| Step: 10
Training loss: 0.9810798533950437
Validation loss: 2.490444856193799

Epoch: 286| Step: 0
Training loss: 0.9677455370718069
Validation loss: 2.438931924078648

Epoch: 5| Step: 1
Training loss: 1.2969230734865773
Validation loss: 2.469284407881442

Epoch: 5| Step: 2
Training loss: 0.9486184125172149
Validation loss: 2.504614600639628

Epoch: 5| Step: 3
Training loss: 0.7529710097792565
Validation loss: 2.499746588712481

Epoch: 5| Step: 4
Training loss: 0.612688616496237
Validation loss: 2.5099704144795787

Epoch: 5| Step: 5
Training loss: 0.575796722866735
Validation loss: 2.550493880429594

Epoch: 5| Step: 6
Training loss: 1.0061369577731136
Validation loss: 2.5770105652404562

Epoch: 5| Step: 7
Training loss: 0.7959086598869025
Validation loss: 2.6060772721890166

Epoch: 5| Step: 8
Training loss: 1.3407496734482174
Validation loss: 2.6198443749956417

Epoch: 5| Step: 9
Training loss: 0.9393681668193559
Validation loss: 2.597911038680342

Epoch: 5| Step: 10
Training loss: 0.8080062574814699
Validation loss: 2.5741513063991808

Epoch: 287| Step: 0
Training loss: 1.282381349098142
Validation loss: 2.4561881614018364

Epoch: 5| Step: 1
Training loss: 0.8527267965975196
Validation loss: 2.4565335215708655

Epoch: 5| Step: 2
Training loss: 0.5622315295939635
Validation loss: 2.465815017452462

Epoch: 5| Step: 3
Training loss: 0.9379601938549139
Validation loss: 2.427957267509256

Epoch: 5| Step: 4
Training loss: 0.8724015344841504
Validation loss: 2.446778194008819

Epoch: 5| Step: 5
Training loss: 1.1983526625066918
Validation loss: 2.5105679952802915

Epoch: 5| Step: 6
Training loss: 0.9186038153989604
Validation loss: 2.582576172016253

Epoch: 5| Step: 7
Training loss: 0.5861866739065716
Validation loss: 2.6137461086437703

Epoch: 5| Step: 8
Training loss: 1.0652960283478066
Validation loss: 2.620853354179994

Epoch: 5| Step: 9
Training loss: 1.0567435674532497
Validation loss: 2.6116423202522068

Epoch: 5| Step: 10
Training loss: 0.635188598559795
Validation loss: 2.605352185209914

Epoch: 288| Step: 0
Training loss: 0.8609597938821947
Validation loss: 2.5448108015765287

Epoch: 5| Step: 1
Training loss: 0.9000896687343087
Validation loss: 2.527816988591945

Epoch: 5| Step: 2
Training loss: 0.9663365973471969
Validation loss: 2.511823867815366

Epoch: 5| Step: 3
Training loss: 1.0724420454465942
Validation loss: 2.4629948842241065

Epoch: 5| Step: 4
Training loss: 0.93925001205026
Validation loss: 2.4984523361364697

Epoch: 5| Step: 5
Training loss: 0.756261989403888
Validation loss: 2.492747932987109

Epoch: 5| Step: 6
Training loss: 0.8499500863061804
Validation loss: 2.465410359216621

Epoch: 5| Step: 7
Training loss: 0.8612731431639254
Validation loss: 2.5208255283279293

Epoch: 5| Step: 8
Training loss: 1.069473661846557
Validation loss: 2.569372386267478

Epoch: 5| Step: 9
Training loss: 0.9684080320185114
Validation loss: 2.5266843507004313

Epoch: 5| Step: 10
Training loss: 0.8419862255433097
Validation loss: 2.5966318451246853

Epoch: 289| Step: 0
Training loss: 1.038437275181946
Validation loss: 2.619875560610994

Epoch: 5| Step: 1
Training loss: 1.0305347852393227
Validation loss: 2.573273484094458

Epoch: 5| Step: 2
Training loss: 0.7310605023677954
Validation loss: 2.5613312205504464

Epoch: 5| Step: 3
Training loss: 0.752485052448233
Validation loss: 2.5203316861537277

Epoch: 5| Step: 4
Training loss: 0.9693871525507528
Validation loss: 2.542819302576475

Epoch: 5| Step: 5
Training loss: 0.9976556836203548
Validation loss: 2.505655039386983

Epoch: 5| Step: 6
Training loss: 0.6398414844663799
Validation loss: 2.483633724199159

Epoch: 5| Step: 7
Training loss: 0.9978847483957153
Validation loss: 2.471388499697693

Epoch: 5| Step: 8
Training loss: 0.8218513586901175
Validation loss: 2.477641857890532

Epoch: 5| Step: 9
Training loss: 0.8253282067545893
Validation loss: 2.466361424495474

Epoch: 5| Step: 10
Training loss: 1.1589415899440219
Validation loss: 2.4974155336496686

Epoch: 290| Step: 0
Training loss: 0.7956747477906396
Validation loss: 2.5011185102548197

Epoch: 5| Step: 1
Training loss: 0.7142468237507515
Validation loss: 2.5055247176478694

Epoch: 5| Step: 2
Training loss: 0.9449099479638509
Validation loss: 2.5084954975863027

Epoch: 5| Step: 3
Training loss: 1.0086487841494856
Validation loss: 2.5446854890989097

Epoch: 5| Step: 4
Training loss: 1.0131860057388458
Validation loss: 2.570890203437841

Epoch: 5| Step: 5
Training loss: 0.8946639716292076
Validation loss: 2.5749762773640645

Epoch: 5| Step: 6
Training loss: 0.7240125558064746
Validation loss: 2.572584236280869

Epoch: 5| Step: 7
Training loss: 1.1224732103103308
Validation loss: 2.5563882334217727

Epoch: 5| Step: 8
Training loss: 0.5998138675465426
Validation loss: 2.5768405860826884

Epoch: 5| Step: 9
Training loss: 1.0774248586417927
Validation loss: 2.5742367397076054

Epoch: 5| Step: 10
Training loss: 0.9307028731332421
Validation loss: 2.5178044322123743

Epoch: 291| Step: 0
Training loss: 0.5132354797208313
Validation loss: 2.503755225591014

Epoch: 5| Step: 1
Training loss: 0.7944777839248153
Validation loss: 2.5267550493858844

Epoch: 5| Step: 2
Training loss: 0.7737082961002656
Validation loss: 2.49981098588524

Epoch: 5| Step: 3
Training loss: 0.9872878740126066
Validation loss: 2.4473101644564226

Epoch: 5| Step: 4
Training loss: 1.0347683161653378
Validation loss: 2.461411528436807

Epoch: 5| Step: 5
Training loss: 1.010376854076145
Validation loss: 2.477666623031603

Epoch: 5| Step: 6
Training loss: 1.067931262058077
Validation loss: 2.5027875956079635

Epoch: 5| Step: 7
Training loss: 1.0804839380704192
Validation loss: 2.5331291658331363

Epoch: 5| Step: 8
Training loss: 0.4545580630558593
Validation loss: 2.5464599470481684

Epoch: 5| Step: 9
Training loss: 0.8697019671635982
Validation loss: 2.528869058062188

Epoch: 5| Step: 10
Training loss: 1.0403190987980147
Validation loss: 2.5739961488344694

Epoch: 292| Step: 0
Training loss: 0.8106762886145585
Validation loss: 2.5478741454857103

Epoch: 5| Step: 1
Training loss: 0.5996294049325259
Validation loss: 2.556966990365283

Epoch: 5| Step: 2
Training loss: 0.8859575676369253
Validation loss: 2.5488735530773003

Epoch: 5| Step: 3
Training loss: 0.637048811288025
Validation loss: 2.509521265632272

Epoch: 5| Step: 4
Training loss: 1.2896605982561684
Validation loss: 2.5355807827957233

Epoch: 5| Step: 5
Training loss: 0.7142688962114501
Validation loss: 2.54731892171368

Epoch: 5| Step: 6
Training loss: 0.8182675257739775
Validation loss: 2.5512195731855942

Epoch: 5| Step: 7
Training loss: 1.104303237578256
Validation loss: 2.539893694077282

Epoch: 5| Step: 8
Training loss: 0.9325616470495612
Validation loss: 2.556309896614276

Epoch: 5| Step: 9
Training loss: 1.0211863329125614
Validation loss: 2.557545796768599

Epoch: 5| Step: 10
Training loss: 0.6761405739241522
Validation loss: 2.5472362641321196

Epoch: 293| Step: 0
Training loss: 0.6911185576617634
Validation loss: 2.53543787868235

Epoch: 5| Step: 1
Training loss: 0.8969528536617153
Validation loss: 2.5406214247398395

Epoch: 5| Step: 2
Training loss: 0.8863410313264676
Validation loss: 2.5123869337716225

Epoch: 5| Step: 3
Training loss: 0.8019841904901318
Validation loss: 2.4949348256719355

Epoch: 5| Step: 4
Training loss: 0.7520946815317892
Validation loss: 2.497969400554546

Epoch: 5| Step: 5
Training loss: 1.133748056227123
Validation loss: 2.5076134229911164

Epoch: 5| Step: 6
Training loss: 0.6732529770197104
Validation loss: 2.525313655443997

Epoch: 5| Step: 7
Training loss: 1.076676764327688
Validation loss: 2.5460047752265282

Epoch: 5| Step: 8
Training loss: 1.0778414588371443
Validation loss: 2.5757886266956227

Epoch: 5| Step: 9
Training loss: 0.8761172654731257
Validation loss: 2.5995945233308886

Epoch: 5| Step: 10
Training loss: 0.6451817091327479
Validation loss: 2.5609659609916497

Epoch: 294| Step: 0
Training loss: 0.9782894885903294
Validation loss: 2.5589475430787476

Epoch: 5| Step: 1
Training loss: 0.965178705676465
Validation loss: 2.5078981640662286

Epoch: 5| Step: 2
Training loss: 0.7321972311743301
Validation loss: 2.503006226928664

Epoch: 5| Step: 3
Training loss: 0.6995512528719714
Validation loss: 2.468663299396393

Epoch: 5| Step: 4
Training loss: 1.0744008412784627
Validation loss: 2.4829960501583517

Epoch: 5| Step: 5
Training loss: 0.9747604528230133
Validation loss: 2.469165444871127

Epoch: 5| Step: 6
Training loss: 1.0015541159625565
Validation loss: 2.4786466627241093

Epoch: 5| Step: 7
Training loss: 0.9163180179511765
Validation loss: 2.492036381613033

Epoch: 5| Step: 8
Training loss: 0.5682789853847755
Validation loss: 2.4917962945740095

Epoch: 5| Step: 9
Training loss: 0.8666115300050439
Validation loss: 2.5888837029328293

Epoch: 5| Step: 10
Training loss: 0.7469394943291118
Validation loss: 2.546677959829214

Epoch: 295| Step: 0
Training loss: 1.2292946193930143
Validation loss: 2.5819284205980093

Epoch: 5| Step: 1
Training loss: 0.7251927990899373
Validation loss: 2.5772511781018714

Epoch: 5| Step: 2
Training loss: 0.2925691040441118
Validation loss: 2.5612452016185427

Epoch: 5| Step: 3
Training loss: 0.9920765371675966
Validation loss: 2.5353392608855354

Epoch: 5| Step: 4
Training loss: 1.2512646000302816
Validation loss: 2.4663909881389956

Epoch: 5| Step: 5
Training loss: 0.748000658963163
Validation loss: 2.4764279885765257

Epoch: 5| Step: 6
Training loss: 0.9303883707607148
Validation loss: 2.450613445474187

Epoch: 5| Step: 7
Training loss: 0.7734791522899969
Validation loss: 2.452107004241381

Epoch: 5| Step: 8
Training loss: 0.6028983159580017
Validation loss: 2.460740232593968

Epoch: 5| Step: 9
Training loss: 0.7993306489023921
Validation loss: 2.5338815560863157

Epoch: 5| Step: 10
Training loss: 0.8247497439122445
Validation loss: 2.514884476432148

Epoch: 296| Step: 0
Training loss: 1.1637908823471992
Validation loss: 2.576147600540189

Epoch: 5| Step: 1
Training loss: 0.5892915983443009
Validation loss: 2.5484733113616795

Epoch: 5| Step: 2
Training loss: 0.7317464333445038
Validation loss: 2.60213505915781

Epoch: 5| Step: 3
Training loss: 0.8841954429778246
Validation loss: 2.5837872070419348

Epoch: 5| Step: 4
Training loss: 0.9657084802386958
Validation loss: 2.600751927007675

Epoch: 5| Step: 5
Training loss: 0.9651280652192561
Validation loss: 2.5934704277669467

Epoch: 5| Step: 6
Training loss: 1.008237941160006
Validation loss: 2.517632030995483

Epoch: 5| Step: 7
Training loss: 0.8823828537863414
Validation loss: 2.477016709201719

Epoch: 5| Step: 8
Training loss: 0.4612008651676483
Validation loss: 2.467552911456038

Epoch: 5| Step: 9
Training loss: 0.7637485553459328
Validation loss: 2.491873720207221

Epoch: 5| Step: 10
Training loss: 0.9472633912364932
Validation loss: 2.436000115872075

Epoch: 297| Step: 0
Training loss: 0.8741479880813551
Validation loss: 2.473639578024413

Epoch: 5| Step: 1
Training loss: 0.3499517416041237
Validation loss: 2.532582333321332

Epoch: 5| Step: 2
Training loss: 0.8323471830629158
Validation loss: 2.5687750751423297

Epoch: 5| Step: 3
Training loss: 0.6709828330628248
Validation loss: 2.6000073158707093

Epoch: 5| Step: 4
Training loss: 0.7892748858467922
Validation loss: 2.578044433428715

Epoch: 5| Step: 5
Training loss: 1.0713520987785434
Validation loss: 2.568183498692048

Epoch: 5| Step: 6
Training loss: 1.0393872434774667
Validation loss: 2.5444283781690613

Epoch: 5| Step: 7
Training loss: 1.0036313166588826
Validation loss: 2.5676369259733813

Epoch: 5| Step: 8
Training loss: 0.7049993328334817
Validation loss: 2.5573885922080986

Epoch: 5| Step: 9
Training loss: 1.0009519694959055
Validation loss: 2.5236029268951676

Epoch: 5| Step: 10
Training loss: 0.9353457814115822
Validation loss: 2.5261507901081184

Epoch: 298| Step: 0
Training loss: 0.7061126600765076
Validation loss: 2.5289699783944357

Epoch: 5| Step: 1
Training loss: 0.9527752343957268
Validation loss: 2.5154359400354154

Epoch: 5| Step: 2
Training loss: 1.0476386857462798
Validation loss: 2.532953205582903

Epoch: 5| Step: 3
Training loss: 0.6318914751646258
Validation loss: 2.5763106857262676

Epoch: 5| Step: 4
Training loss: 0.747127675366155
Validation loss: 2.5234304565343577

Epoch: 5| Step: 5
Training loss: 0.7935704546335411
Validation loss: 2.504821718517508

Epoch: 5| Step: 6
Training loss: 1.0848935824825814
Validation loss: 2.515818483543294

Epoch: 5| Step: 7
Training loss: 0.7334920160604061
Validation loss: 2.5319767147669814

Epoch: 5| Step: 8
Training loss: 0.9116596036029521
Validation loss: 2.554565818156388

Epoch: 5| Step: 9
Training loss: 0.9170294318389938
Validation loss: 2.5415878260135476

Epoch: 5| Step: 10
Training loss: 0.7408795526917177
Validation loss: 2.6245418633201

Epoch: 299| Step: 0
Training loss: 0.8692726635023217
Validation loss: 2.631553782565115

Epoch: 5| Step: 1
Training loss: 0.5582830725532546
Validation loss: 2.6193320272084213

Epoch: 5| Step: 2
Training loss: 1.112710585647548
Validation loss: 2.575871138380376

Epoch: 5| Step: 3
Training loss: 1.0565166294867099
Validation loss: 2.502424578994532

Epoch: 5| Step: 4
Training loss: 0.4385738817042515
Validation loss: 2.5007678677991607

Epoch: 5| Step: 5
Training loss: 0.7842222513355166
Validation loss: 2.467292380257075

Epoch: 5| Step: 6
Training loss: 0.8539420662197856
Validation loss: 2.473022713716326

Epoch: 5| Step: 7
Training loss: 0.6888162627079741
Validation loss: 2.477353801699077

Epoch: 5| Step: 8
Training loss: 1.0409287636538305
Validation loss: 2.460450460221282

Epoch: 5| Step: 9
Training loss: 0.6682762419803069
Validation loss: 2.479506100127668

Epoch: 5| Step: 10
Training loss: 1.0848246848513325
Validation loss: 2.529760151413789

Epoch: 300| Step: 0
Training loss: 0.7540061765868067
Validation loss: 2.5518533917410586

Epoch: 5| Step: 1
Training loss: 1.011386713752432
Validation loss: 2.5821565868159375

Epoch: 5| Step: 2
Training loss: 0.9877658751652287
Validation loss: 2.565979072242355

Epoch: 5| Step: 3
Training loss: 0.7176276026381059
Validation loss: 2.6008928501296635

Epoch: 5| Step: 4
Training loss: 0.960709893788384
Validation loss: 2.56719885242848

Epoch: 5| Step: 5
Training loss: 1.0013287775907067
Validation loss: 2.5687895471171225

Epoch: 5| Step: 6
Training loss: 0.4434307897918958
Validation loss: 2.528162500401042

Epoch: 5| Step: 7
Training loss: 0.8415391354835766
Validation loss: 2.5384022288210195

Epoch: 5| Step: 8
Training loss: 0.9460730527571638
Validation loss: 2.4933248126119243

Epoch: 5| Step: 9
Training loss: 0.8421073040263015
Validation loss: 2.4535931047264965

Epoch: 5| Step: 10
Training loss: 0.4974855438604965
Validation loss: 2.5212906561873627

Epoch: 301| Step: 0
Training loss: 0.8456110034131077
Validation loss: 2.5313412391487526

Epoch: 5| Step: 1
Training loss: 0.7194566984209056
Validation loss: 2.544901010570712

Epoch: 5| Step: 2
Training loss: 0.8657406946530918
Validation loss: 2.49777179397013

Epoch: 5| Step: 3
Training loss: 0.7178203956658011
Validation loss: 2.5957269272042844

Epoch: 5| Step: 4
Training loss: 0.6495721380832195
Validation loss: 2.5092230166406315

Epoch: 5| Step: 5
Training loss: 1.015334161050083
Validation loss: 2.5610981530008434

Epoch: 5| Step: 6
Training loss: 0.7770387060596623
Validation loss: 2.541268010969522

Epoch: 5| Step: 7
Training loss: 0.7532414484814203
Validation loss: 2.5063924391806873

Epoch: 5| Step: 8
Training loss: 0.996353354938108
Validation loss: 2.533655304747075

Epoch: 5| Step: 9
Training loss: 1.049877870359788
Validation loss: 2.4994298238589328

Epoch: 5| Step: 10
Training loss: 0.6466477755199266
Validation loss: 2.4730799232850615

Epoch: 302| Step: 0
Training loss: 0.6064882616446557
Validation loss: 2.487823363321172

Epoch: 5| Step: 1
Training loss: 0.9129760676085327
Validation loss: 2.4638096537168943

Epoch: 5| Step: 2
Training loss: 0.837054246448063
Validation loss: 2.52076151240511

Epoch: 5| Step: 3
Training loss: 0.9569972752359918
Validation loss: 2.520317609307403

Epoch: 5| Step: 4
Training loss: 1.0267011714272836
Validation loss: 2.5831955761522227

Epoch: 5| Step: 5
Training loss: 0.8657736722886142
Validation loss: 2.5664502781250924

Epoch: 5| Step: 6
Training loss: 0.6495363736954249
Validation loss: 2.5959879825676095

Epoch: 5| Step: 7
Training loss: 0.5229076436646071
Validation loss: 2.5825903284153156

Epoch: 5| Step: 8
Training loss: 1.0838649924582517
Validation loss: 2.6056164184035757

Epoch: 5| Step: 9
Training loss: 0.8736570815858699
Validation loss: 2.529964747139717

Epoch: 5| Step: 10
Training loss: 0.6509035396278664
Validation loss: 2.5310912067896267

Epoch: 303| Step: 0
Training loss: 1.0479320484546724
Validation loss: 2.4646220058960724

Epoch: 5| Step: 1
Training loss: 0.8159466777798163
Validation loss: 2.4360385549167374

Epoch: 5| Step: 2
Training loss: 0.6572572834152557
Validation loss: 2.458282869244076

Epoch: 5| Step: 3
Training loss: 0.8526352241528354
Validation loss: 2.4958724146956808

Epoch: 5| Step: 4
Training loss: 1.0280522561354626
Validation loss: 2.4841013457321903

Epoch: 5| Step: 5
Training loss: 0.7777908802821053
Validation loss: 2.4733140045279547

Epoch: 5| Step: 6
Training loss: 0.990591552843615
Validation loss: 2.560315680573469

Epoch: 5| Step: 7
Training loss: 0.7846030188825971
Validation loss: 2.576759867424905

Epoch: 5| Step: 8
Training loss: 0.9141642196005865
Validation loss: 2.578984510749119

Epoch: 5| Step: 9
Training loss: 0.6060338736232282
Validation loss: 2.5938161897621343

Epoch: 5| Step: 10
Training loss: 0.5744839010680497
Validation loss: 2.5794710947741755

Epoch: 304| Step: 0
Training loss: 1.09109239591547
Validation loss: 2.5626939769671844

Epoch: 5| Step: 1
Training loss: 0.5558888495238076
Validation loss: 2.488310303887641

Epoch: 5| Step: 2
Training loss: 0.8411750355346973
Validation loss: 2.4942576508876906

Epoch: 5| Step: 3
Training loss: 1.1530340680914704
Validation loss: 2.4588193623282084

Epoch: 5| Step: 4
Training loss: 0.6423967795449835
Validation loss: 2.493439226207762

Epoch: 5| Step: 5
Training loss: 0.8099412240967823
Validation loss: 2.481605298987011

Epoch: 5| Step: 6
Training loss: 0.7516818659599735
Validation loss: 2.49893825503978

Epoch: 5| Step: 7
Training loss: 0.6699992766305235
Validation loss: 2.5286869212045984

Epoch: 5| Step: 8
Training loss: 0.7876521811203309
Validation loss: 2.570870063311803

Epoch: 5| Step: 9
Training loss: 0.5100051200366598
Validation loss: 2.6525388693575236

Epoch: 5| Step: 10
Training loss: 0.8744037504016269
Validation loss: 2.620162696539928

Epoch: 305| Step: 0
Training loss: 0.6899055315046703
Validation loss: 2.612713424605033

Epoch: 5| Step: 1
Training loss: 0.8003042521679211
Validation loss: 2.5747855366658485

Epoch: 5| Step: 2
Training loss: 0.9758334681127788
Validation loss: 2.5681771219838727

Epoch: 5| Step: 3
Training loss: 0.5328236162027287
Validation loss: 2.5419494684062776

Epoch: 5| Step: 4
Training loss: 0.774917996590392
Validation loss: 2.564417713978182

Epoch: 5| Step: 5
Training loss: 0.7585718342279926
Validation loss: 2.5731096773629565

Epoch: 5| Step: 6
Training loss: 0.7027874030164838
Validation loss: 2.5552340886113063

Epoch: 5| Step: 7
Training loss: 0.8950021495473611
Validation loss: 2.5483896580770593

Epoch: 5| Step: 8
Training loss: 0.8730830925378021
Validation loss: 2.5323663850297704

Epoch: 5| Step: 9
Training loss: 0.6707383676999666
Validation loss: 2.504488136266533

Epoch: 5| Step: 10
Training loss: 0.9242995109968698
Validation loss: 2.497436225076276

Epoch: 306| Step: 0
Training loss: 0.6301972779704598
Validation loss: 2.5055483745744924

Epoch: 5| Step: 1
Training loss: 0.9878338792581746
Validation loss: 2.4695583321842642

Epoch: 5| Step: 2
Training loss: 0.7473932901974962
Validation loss: 2.5006062387852217

Epoch: 5| Step: 3
Training loss: 0.6545226205861163
Validation loss: 2.5061823603405156

Epoch: 5| Step: 4
Training loss: 0.610368115009926
Validation loss: 2.582200559842652

Epoch: 5| Step: 5
Training loss: 0.6976454098533181
Validation loss: 2.6000045974318478

Epoch: 5| Step: 6
Training loss: 0.8660712403646947
Validation loss: 2.60431276432528

Epoch: 5| Step: 7
Training loss: 0.8934181651064393
Validation loss: 2.5221861874741998

Epoch: 5| Step: 8
Training loss: 1.1701781130793534
Validation loss: 2.537358903237974

Epoch: 5| Step: 9
Training loss: 0.6400495130787557
Validation loss: 2.5242574666250213

Epoch: 5| Step: 10
Training loss: 0.5294295422718484
Validation loss: 2.4936396794796822

Epoch: 307| Step: 0
Training loss: 0.6366054223430407
Validation loss: 2.490846690677566

Epoch: 5| Step: 1
Training loss: 0.6802114681348863
Validation loss: 2.4996824965310966

Epoch: 5| Step: 2
Training loss: 0.7467926506707573
Validation loss: 2.496129247031161

Epoch: 5| Step: 3
Training loss: 0.8946935514777717
Validation loss: 2.4821954000377566

Epoch: 5| Step: 4
Training loss: 0.9554824441347965
Validation loss: 2.499605820456808

Epoch: 5| Step: 5
Training loss: 0.6669739124480972
Validation loss: 2.5169898241347073

Epoch: 5| Step: 6
Training loss: 1.1070893610937467
Validation loss: 2.586123413306869

Epoch: 5| Step: 7
Training loss: 0.647945608144789
Validation loss: 2.612423291370356

Epoch: 5| Step: 8
Training loss: 0.6796134382214821
Validation loss: 2.605174662436356

Epoch: 5| Step: 9
Training loss: 0.3717272521077305
Validation loss: 2.569589309097065

Epoch: 5| Step: 10
Training loss: 1.011260529075478
Validation loss: 2.561988137157988

Epoch: 308| Step: 0
Training loss: 0.6292845257731943
Validation loss: 2.5546041535700925

Epoch: 5| Step: 1
Training loss: 0.9360370029039231
Validation loss: 2.521933400406957

Epoch: 5| Step: 2
Training loss: 0.43501206137389326
Validation loss: 2.5306922047848324

Epoch: 5| Step: 3
Training loss: 0.5325803927954836
Validation loss: 2.47815131220398

Epoch: 5| Step: 4
Training loss: 0.8774725176645658
Validation loss: 2.5089696550925162

Epoch: 5| Step: 5
Training loss: 0.8532866426139275
Validation loss: 2.5187772438690743

Epoch: 5| Step: 6
Training loss: 0.5845340196206872
Validation loss: 2.4920898401906593

Epoch: 5| Step: 7
Training loss: 0.8887642613271372
Validation loss: 2.5389499585725956

Epoch: 5| Step: 8
Training loss: 0.9946931154390408
Validation loss: 2.5333174067940036

Epoch: 5| Step: 9
Training loss: 0.8369496003020371
Validation loss: 2.5628547963077066

Epoch: 5| Step: 10
Training loss: 0.7265476102226175
Validation loss: 2.5478652125321335

Epoch: 309| Step: 0
Training loss: 0.8697820803785954
Validation loss: 2.554339681701192

Epoch: 5| Step: 1
Training loss: 0.6742231676082937
Validation loss: 2.5740541708052076

Epoch: 5| Step: 2
Training loss: 0.5369437777392349
Validation loss: 2.5791418954408916

Epoch: 5| Step: 3
Training loss: 1.127689220342374
Validation loss: 2.526544041730146

Epoch: 5| Step: 4
Training loss: 0.7557924226191752
Validation loss: 2.5319949479024095

Epoch: 5| Step: 5
Training loss: 0.994914564892888
Validation loss: 2.517786575890941

Epoch: 5| Step: 6
Training loss: 0.5469396008074212
Validation loss: 2.532973271700904

Epoch: 5| Step: 7
Training loss: 0.4611529154033009
Validation loss: 2.507502374675017

Epoch: 5| Step: 8
Training loss: 0.3696341873255288
Validation loss: 2.4939084399756735

Epoch: 5| Step: 9
Training loss: 0.8026251428541916
Validation loss: 2.554949780559356

Epoch: 5| Step: 10
Training loss: 0.9275416445058589
Validation loss: 2.5533943798393164

Epoch: 310| Step: 0
Training loss: 0.8856175512674966
Validation loss: 2.5782330790836014

Epoch: 5| Step: 1
Training loss: 0.8486618546234357
Validation loss: 2.526025722103628

Epoch: 5| Step: 2
Training loss: 0.7502344877526388
Validation loss: 2.566386037725

Epoch: 5| Step: 3
Training loss: 0.8756235149079608
Validation loss: 2.5271232333673335

Epoch: 5| Step: 4
Training loss: 0.4951338304359646
Validation loss: 2.537733017253658

Epoch: 5| Step: 5
Training loss: 0.7834492437017331
Validation loss: 2.516750147512755

Epoch: 5| Step: 6
Training loss: 0.8441961309921364
Validation loss: 2.5140018881536017

Epoch: 5| Step: 7
Training loss: 0.6598887155375278
Validation loss: 2.508807126942591

Epoch: 5| Step: 8
Training loss: 0.8038608415863755
Validation loss: 2.497179731458413

Epoch: 5| Step: 9
Training loss: 0.6343131697641133
Validation loss: 2.542136538395025

Epoch: 5| Step: 10
Training loss: 0.6746854331694727
Validation loss: 2.55397065931915

Epoch: 311| Step: 0
Training loss: 0.43049438317164723
Validation loss: 2.564778392279208

Epoch: 5| Step: 1
Training loss: 1.0639731908841055
Validation loss: 2.5844638403722415

Epoch: 5| Step: 2
Training loss: 0.7535275708997307
Validation loss: 2.5994452169369997

Epoch: 5| Step: 3
Training loss: 0.9135999242692372
Validation loss: 2.6165296462127006

Epoch: 5| Step: 4
Training loss: 0.40988787999206633
Validation loss: 2.5379779184768596

Epoch: 5| Step: 5
Training loss: 0.7025103107388075
Validation loss: 2.504659486205488

Epoch: 5| Step: 6
Training loss: 0.6147825246958737
Validation loss: 2.492594422340248

Epoch: 5| Step: 7
Training loss: 0.8742863946810959
Validation loss: 2.5059295553161385

Epoch: 5| Step: 8
Training loss: 0.7861458155344453
Validation loss: 2.533889001502884

Epoch: 5| Step: 9
Training loss: 0.829741142535998
Validation loss: 2.4975588662747583

Epoch: 5| Step: 10
Training loss: 0.6406251860827664
Validation loss: 2.5083369420782304

Epoch: 312| Step: 0
Training loss: 0.7519155121350894
Validation loss: 2.565910246098554

Epoch: 5| Step: 1
Training loss: 0.671912857585949
Validation loss: 2.5630957018341256

Epoch: 5| Step: 2
Training loss: 0.7654639872745216
Validation loss: 2.577712605824677

Epoch: 5| Step: 3
Training loss: 0.5439112051606861
Validation loss: 2.5467639010303094

Epoch: 5| Step: 4
Training loss: 0.7764545895303947
Validation loss: 2.558669822630947

Epoch: 5| Step: 5
Training loss: 0.5752490136769314
Validation loss: 2.5669442351815537

Epoch: 5| Step: 6
Training loss: 0.6910904416327017
Validation loss: 2.5570188398149565

Epoch: 5| Step: 7
Training loss: 1.1333876629504127
Validation loss: 2.5435452026593803

Epoch: 5| Step: 8
Training loss: 0.6190467305993597
Validation loss: 2.571639091818324

Epoch: 5| Step: 9
Training loss: 0.8668955749732332
Validation loss: 2.5203211216603356

Epoch: 5| Step: 10
Training loss: 0.6950419681899754
Validation loss: 2.5285859262085792

Epoch: 313| Step: 0
Training loss: 0.8321659892414539
Validation loss: 2.5048267755383327

Epoch: 5| Step: 1
Training loss: 0.48554023437378224
Validation loss: 2.535365083828503

Epoch: 5| Step: 2
Training loss: 0.8308653206695467
Validation loss: 2.499002739723867

Epoch: 5| Step: 3
Training loss: 0.7671890243235437
Validation loss: 2.5117612223484644

Epoch: 5| Step: 4
Training loss: 0.6895423809772151
Validation loss: 2.5195022020432605

Epoch: 5| Step: 5
Training loss: 0.9659816811564146
Validation loss: 2.548320532922838

Epoch: 5| Step: 6
Training loss: 0.6008486041545884
Validation loss: 2.5389145593952125

Epoch: 5| Step: 7
Training loss: 0.660370966737075
Validation loss: 2.5725329586568457

Epoch: 5| Step: 8
Training loss: 0.848424220815471
Validation loss: 2.6060302924272554

Epoch: 5| Step: 9
Training loss: 0.8299710552499981
Validation loss: 2.5854502673296444

Epoch: 5| Step: 10
Training loss: 0.4756581684382375
Validation loss: 2.5716681694324266

Epoch: 314| Step: 0
Training loss: 1.103917519632684
Validation loss: 2.5498106717901816

Epoch: 5| Step: 1
Training loss: 0.4108043636292234
Validation loss: 2.579989636839111

Epoch: 5| Step: 2
Training loss: 0.8077858468534086
Validation loss: 2.529198514427633

Epoch: 5| Step: 3
Training loss: 0.6917936672866525
Validation loss: 2.5161761107771965

Epoch: 5| Step: 4
Training loss: 0.5584648357034534
Validation loss: 2.5229649813943023

Epoch: 5| Step: 5
Training loss: 0.7475544476534274
Validation loss: 2.576670413637052

Epoch: 5| Step: 6
Training loss: 0.5358074708909716
Validation loss: 2.54342247848238

Epoch: 5| Step: 7
Training loss: 0.6541552262206858
Validation loss: 2.591556221777901

Epoch: 5| Step: 8
Training loss: 0.8591013732862769
Validation loss: 2.579495522317921

Epoch: 5| Step: 9
Training loss: 0.6918833320481247
Validation loss: 2.587859392246607

Epoch: 5| Step: 10
Training loss: 0.863325195574855
Validation loss: 2.6013654472686647

Epoch: 315| Step: 0
Training loss: 0.5313334960396796
Validation loss: 2.571645551157307

Epoch: 5| Step: 1
Training loss: 0.8739811210404662
Validation loss: 2.554887330088855

Epoch: 5| Step: 2
Training loss: 0.6269739925916561
Validation loss: 2.5723515714053566

Epoch: 5| Step: 3
Training loss: 0.9585294557382432
Validation loss: 2.5682582092137025

Epoch: 5| Step: 4
Training loss: 0.5261894308105306
Validation loss: 2.544758700365872

Epoch: 5| Step: 5
Training loss: 0.8218216229645435
Validation loss: 2.5311365703496396

Epoch: 5| Step: 6
Training loss: 0.43318123998647046
Validation loss: 2.5469345869930935

Epoch: 5| Step: 7
Training loss: 0.7651157631892231
Validation loss: 2.5774577749406555

Epoch: 5| Step: 8
Training loss: 0.7053790731452724
Validation loss: 2.494525862295196

Epoch: 5| Step: 9
Training loss: 0.8953960519520842
Validation loss: 2.539527014308153

Epoch: 5| Step: 10
Training loss: 0.604086029218097
Validation loss: 2.530098754959004

Epoch: 316| Step: 0
Training loss: 0.7690792014654138
Validation loss: 2.515320067642858

Epoch: 5| Step: 1
Training loss: 0.8091592700029581
Validation loss: 2.4902471157828194

Epoch: 5| Step: 2
Training loss: 0.8987121825558391
Validation loss: 2.4985905211840844

Epoch: 5| Step: 3
Training loss: 0.6420946708468744
Validation loss: 2.5003781842728303

Epoch: 5| Step: 4
Training loss: 0.780223591803423
Validation loss: 2.4886416714161133

Epoch: 5| Step: 5
Training loss: 0.5010290880534314
Validation loss: 2.5099166411627527

Epoch: 5| Step: 6
Training loss: 0.578031790152796
Validation loss: 2.5505240439353773

Epoch: 5| Step: 7
Training loss: 0.7280366360987919
Validation loss: 2.5548989417093244

Epoch: 5| Step: 8
Training loss: 0.8958533233068251
Validation loss: 2.564356647760979

Epoch: 5| Step: 9
Training loss: 0.5037269569029915
Validation loss: 2.539322885140959

Epoch: 5| Step: 10
Training loss: 0.7070777414116144
Validation loss: 2.57655681100868

Epoch: 317| Step: 0
Training loss: 0.5779946927830135
Validation loss: 2.5497175175625513

Epoch: 5| Step: 1
Training loss: 0.8372433525384251
Validation loss: 2.5099228390387753

Epoch: 5| Step: 2
Training loss: 0.7488479110181266
Validation loss: 2.5209150752787246

Epoch: 5| Step: 3
Training loss: 0.43043484285990397
Validation loss: 2.5229194658236676

Epoch: 5| Step: 4
Training loss: 0.8619061733967927
Validation loss: 2.5285277977121368

Epoch: 5| Step: 5
Training loss: 0.6266388625417535
Validation loss: 2.5079911328453846

Epoch: 5| Step: 6
Training loss: 0.8044809983844411
Validation loss: 2.4973629712968157

Epoch: 5| Step: 7
Training loss: 0.44008216765307817
Validation loss: 2.5266260622782397

Epoch: 5| Step: 8
Training loss: 0.8080868813949961
Validation loss: 2.5276550039430954

Epoch: 5| Step: 9
Training loss: 0.4661942586484314
Validation loss: 2.5110671461375804

Epoch: 5| Step: 10
Training loss: 1.054270004715883
Validation loss: 2.579836516752873

Epoch: 318| Step: 0
Training loss: 0.9338782926309162
Validation loss: 2.561128999407093

Epoch: 5| Step: 1
Training loss: 0.5827900593300617
Validation loss: 2.5099712785692874

Epoch: 5| Step: 2
Training loss: 0.7660885789242712
Validation loss: 2.515421945861712

Epoch: 5| Step: 3
Training loss: 0.8395915162766021
Validation loss: 2.485836578144042

Epoch: 5| Step: 4
Training loss: 0.7169749275276917
Validation loss: 2.4700740883913386

Epoch: 5| Step: 5
Training loss: 0.8636097347794836
Validation loss: 2.4982407029897273

Epoch: 5| Step: 6
Training loss: 0.47510079268138666
Validation loss: 2.4498967000142216

Epoch: 5| Step: 7
Training loss: 0.5976074797234989
Validation loss: 2.496491122177905

Epoch: 5| Step: 8
Training loss: 0.7038462013093885
Validation loss: 2.5637065589027337

Epoch: 5| Step: 9
Training loss: 0.42741976450707764
Validation loss: 2.586677699868177

Epoch: 5| Step: 10
Training loss: 0.791696627367841
Validation loss: 2.5161271498220557

Epoch: 319| Step: 0
Training loss: 0.7723240785372165
Validation loss: 2.552671880373133

Epoch: 5| Step: 1
Training loss: 0.43889976417907167
Validation loss: 2.541887048506643

Epoch: 5| Step: 2
Training loss: 0.8079544341132747
Validation loss: 2.5179075508313566

Epoch: 5| Step: 3
Training loss: 0.6107577017877426
Validation loss: 2.5376083453135516

Epoch: 5| Step: 4
Training loss: 0.6168206247174769
Validation loss: 2.537965853676647

Epoch: 5| Step: 5
Training loss: 0.705427954794314
Validation loss: 2.5385566958571557

Epoch: 5| Step: 6
Training loss: 0.688423013971954
Validation loss: 2.523529722580154

Epoch: 5| Step: 7
Training loss: 0.8485879304560237
Validation loss: 2.528367583333751

Epoch: 5| Step: 8
Training loss: 0.5650983244656936
Validation loss: 2.5621926448246524

Epoch: 5| Step: 9
Training loss: 0.8156380940990322
Validation loss: 2.5499159927975357

Epoch: 5| Step: 10
Training loss: 0.829862966140809
Validation loss: 2.5561720025973313

Epoch: 320| Step: 0
Training loss: 0.7132735804535084
Validation loss: 2.545069323373499

Epoch: 5| Step: 1
Training loss: 0.44342944561967124
Validation loss: 2.557623978446797

Epoch: 5| Step: 2
Training loss: 0.625108852444134
Validation loss: 2.5509609872729593

Epoch: 5| Step: 3
Training loss: 0.9397967814365012
Validation loss: 2.5424630564707504

Epoch: 5| Step: 4
Training loss: 0.39085112702357383
Validation loss: 2.5426677532462914

Epoch: 5| Step: 5
Training loss: 0.6941634123437014
Validation loss: 2.4947773319887303

Epoch: 5| Step: 6
Training loss: 0.9329227286535564
Validation loss: 2.4598636490798973

Epoch: 5| Step: 7
Training loss: 0.8100302647011101
Validation loss: 2.5267745224903817

Epoch: 5| Step: 8
Training loss: 0.5808330209239556
Validation loss: 2.4879004818701467

Epoch: 5| Step: 9
Training loss: 0.65529181146231
Validation loss: 2.5180009390945153

Epoch: 5| Step: 10
Training loss: 0.7479292575410382
Validation loss: 2.5064764610817085

Epoch: 321| Step: 0
Training loss: 0.8862178244621405
Validation loss: 2.4890028254914327

Epoch: 5| Step: 1
Training loss: 0.5757772613759908
Validation loss: 2.5517745269191185

Epoch: 5| Step: 2
Training loss: 0.7429052395957161
Validation loss: 2.527943784266082

Epoch: 5| Step: 3
Training loss: 0.732092618049303
Validation loss: 2.5059054306225623

Epoch: 5| Step: 4
Training loss: 0.5211718476435134
Validation loss: 2.4940663652509985

Epoch: 5| Step: 5
Training loss: 0.5038445604991303
Validation loss: 2.4969089266983406

Epoch: 5| Step: 6
Training loss: 0.7403435538506913
Validation loss: 2.5255731295060615

Epoch: 5| Step: 7
Training loss: 0.7740160772073286
Validation loss: 2.4979257053689734

Epoch: 5| Step: 8
Training loss: 0.7942353454332959
Validation loss: 2.4991008741402054

Epoch: 5| Step: 9
Training loss: 0.6543873738573616
Validation loss: 2.504111093801248

Epoch: 5| Step: 10
Training loss: 0.5932351942372963
Validation loss: 2.5077828143671894

Epoch: 322| Step: 0
Training loss: 0.6693745815941851
Validation loss: 2.496462860770261

Epoch: 5| Step: 1
Training loss: 0.6427258492735823
Validation loss: 2.5737485231290123

Epoch: 5| Step: 2
Training loss: 0.638821109053489
Validation loss: 2.5415899341471526

Epoch: 5| Step: 3
Training loss: 0.6667849664233677
Validation loss: 2.5790243937316744

Epoch: 5| Step: 4
Training loss: 0.7019130434237647
Validation loss: 2.583921140020541

Epoch: 5| Step: 5
Training loss: 0.3639706868326254
Validation loss: 2.5603828117613974

Epoch: 5| Step: 6
Training loss: 0.9862605005631161
Validation loss: 2.505817928512872

Epoch: 5| Step: 7
Training loss: 0.566354420362337
Validation loss: 2.524227632127807

Epoch: 5| Step: 8
Training loss: 0.6652024526323188
Validation loss: 2.4823566187857784

Epoch: 5| Step: 9
Training loss: 0.7298765178650918
Validation loss: 2.510894584548095

Epoch: 5| Step: 10
Training loss: 0.8184537628294273
Validation loss: 2.484503910566378

Epoch: 323| Step: 0
Training loss: 0.6432578019989612
Validation loss: 2.5077137445098527

Epoch: 5| Step: 1
Training loss: 0.5997018898037091
Validation loss: 2.519867205354362

Epoch: 5| Step: 2
Training loss: 0.9311664582229453
Validation loss: 2.5839530394712047

Epoch: 5| Step: 3
Training loss: 0.5172261030651594
Validation loss: 2.5692992746867738

Epoch: 5| Step: 4
Training loss: 0.4205054021288744
Validation loss: 2.5599756700438894

Epoch: 5| Step: 5
Training loss: 0.8057309394591707
Validation loss: 2.585041670816938

Epoch: 5| Step: 6
Training loss: 0.6719478079802023
Validation loss: 2.582897576911324

Epoch: 5| Step: 7
Training loss: 0.7869911957045941
Validation loss: 2.5791336408397143

Epoch: 5| Step: 8
Training loss: 0.7004142642353467
Validation loss: 2.5736839748166145

Epoch: 5| Step: 9
Training loss: 0.5838026191308973
Validation loss: 2.53219701324208

Epoch: 5| Step: 10
Training loss: 0.7741137929037701
Validation loss: 2.5357819507494312

Epoch: 324| Step: 0
Training loss: 0.7573253993130306
Validation loss: 2.4630228073017872

Epoch: 5| Step: 1
Training loss: 1.0135317431777933
Validation loss: 2.4949408141569007

Epoch: 5| Step: 2
Training loss: 0.45213942384901407
Validation loss: 2.4725811599309115

Epoch: 5| Step: 3
Training loss: 0.6269593520761384
Validation loss: 2.5146745952516487

Epoch: 5| Step: 4
Training loss: 0.46705481453515085
Validation loss: 2.52077179435913

Epoch: 5| Step: 5
Training loss: 0.5460755635781898
Validation loss: 2.5089468951232083

Epoch: 5| Step: 6
Training loss: 0.5805036223706789
Validation loss: 2.5600594824916385

Epoch: 5| Step: 7
Training loss: 0.7763935972316268
Validation loss: 2.5424236627466117

Epoch: 5| Step: 8
Training loss: 0.9633439488359545
Validation loss: 2.5464532753277798

Epoch: 5| Step: 9
Training loss: 0.5531755445845826
Validation loss: 2.5362135960332237

Epoch: 5| Step: 10
Training loss: 0.4495208885157596
Validation loss: 2.474083566566931

Epoch: 325| Step: 0
Training loss: 0.558444129806297
Validation loss: 2.50479737077929

Epoch: 5| Step: 1
Training loss: 0.5228438070788668
Validation loss: 2.4872814360504685

Epoch: 5| Step: 2
Training loss: 0.8550738115406635
Validation loss: 2.482907983322371

Epoch: 5| Step: 3
Training loss: 0.9008787739244483
Validation loss: 2.565927551719346

Epoch: 5| Step: 4
Training loss: 0.7577581877761633
Validation loss: 2.5795230499250916

Epoch: 5| Step: 5
Training loss: 0.5285326236717603
Validation loss: 2.5694761142554583

Epoch: 5| Step: 6
Training loss: 0.770647623699962
Validation loss: 2.570580497529556

Epoch: 5| Step: 7
Training loss: 0.46297856392888626
Validation loss: 2.5335077192823414

Epoch: 5| Step: 8
Training loss: 0.8411635563324722
Validation loss: 2.5558443410844003

Epoch: 5| Step: 9
Training loss: 0.5154515755050845
Validation loss: 2.4923061769877006

Epoch: 5| Step: 10
Training loss: 0.5191831928651749
Validation loss: 2.554197061303614

Epoch: 326| Step: 0
Training loss: 0.36336003751495466
Validation loss: 2.559346491366039

Epoch: 5| Step: 1
Training loss: 0.7188065548083669
Validation loss: 2.6119802765720235

Epoch: 5| Step: 2
Training loss: 0.9754342237084976
Validation loss: 2.5742614514493085

Epoch: 5| Step: 3
Training loss: 0.5729549799737241
Validation loss: 2.5454462753445086

Epoch: 5| Step: 4
Training loss: 0.6184095524992681
Validation loss: 2.581255428069444

Epoch: 5| Step: 5
Training loss: 0.6511708525596422
Validation loss: 2.5230950670806425

Epoch: 5| Step: 6
Training loss: 0.5238958032000507
Validation loss: 2.5077871048466047

Epoch: 5| Step: 7
Training loss: 0.5538224472979617
Validation loss: 2.5061124725083435

Epoch: 5| Step: 8
Training loss: 0.6469522494570563
Validation loss: 2.5229642284476665

Epoch: 5| Step: 9
Training loss: 0.7420015604100438
Validation loss: 2.5053605945908446

Epoch: 5| Step: 10
Training loss: 0.85987173809548
Validation loss: 2.5235052231430664

Epoch: 327| Step: 0
Training loss: 0.8295940827906337
Validation loss: 2.515246788397777

Epoch: 5| Step: 1
Training loss: 0.667752771986646
Validation loss: 2.5402415304801664

Epoch: 5| Step: 2
Training loss: 0.5928043313436406
Validation loss: 2.540018175120008

Epoch: 5| Step: 3
Training loss: 0.7435002011656088
Validation loss: 2.54232501240746

Epoch: 5| Step: 4
Training loss: 0.540676933616581
Validation loss: 2.559517963350146

Epoch: 5| Step: 5
Training loss: 0.7725924489647943
Validation loss: 2.526886076248157

Epoch: 5| Step: 6
Training loss: 0.8298034931718915
Validation loss: 2.567713594313734

Epoch: 5| Step: 7
Training loss: 0.5216236857094423
Validation loss: 2.563359601346423

Epoch: 5| Step: 8
Training loss: 0.6068761158470322
Validation loss: 2.5256754934650845

Epoch: 5| Step: 9
Training loss: 0.4274623301846855
Validation loss: 2.5508287141437993

Epoch: 5| Step: 10
Training loss: 0.6787173483566381
Validation loss: 2.5869951778297016

Epoch: 328| Step: 0
Training loss: 0.3180861207253426
Validation loss: 2.525915198061634

Epoch: 5| Step: 1
Training loss: 0.6629813649750527
Validation loss: 2.556909863015401

Epoch: 5| Step: 2
Training loss: 0.9498019526491478
Validation loss: 2.5182157299513266

Epoch: 5| Step: 3
Training loss: 0.8323542008442962
Validation loss: 2.5604188853491983

Epoch: 5| Step: 4
Training loss: 0.5252396320498111
Validation loss: 2.550061505179356

Epoch: 5| Step: 5
Training loss: 0.42385245398382193
Validation loss: 2.539907634166088

Epoch: 5| Step: 6
Training loss: 0.702169998962671
Validation loss: 2.500814649688689

Epoch: 5| Step: 7
Training loss: 0.6160200158774879
Validation loss: 2.49395915957007

Epoch: 5| Step: 8
Training loss: 0.5155196804800174
Validation loss: 2.5046200966761383

Epoch: 5| Step: 9
Training loss: 0.758711370273481
Validation loss: 2.496983713307101

Epoch: 5| Step: 10
Training loss: 0.6851866772984343
Validation loss: 2.545617209781061

Epoch: 329| Step: 0
Training loss: 0.9060490484076579
Validation loss: 2.5501410045401163

Epoch: 5| Step: 1
Training loss: 0.49677711638289257
Validation loss: 2.545691472804393

Epoch: 5| Step: 2
Training loss: 0.40618116455842646
Validation loss: 2.564578779597115

Epoch: 5| Step: 3
Training loss: 0.5434965683092641
Validation loss: 2.5519975776319477

Epoch: 5| Step: 4
Training loss: 0.5680898964825326
Validation loss: 2.575916825013525

Epoch: 5| Step: 5
Training loss: 0.6793079193252802
Validation loss: 2.6014540218347695

Epoch: 5| Step: 6
Training loss: 0.7428011716268499
Validation loss: 2.5692792108944067

Epoch: 5| Step: 7
Training loss: 0.4385816282548086
Validation loss: 2.5624908003903295

Epoch: 5| Step: 8
Training loss: 0.7160919215399355
Validation loss: 2.5663373983514832

Epoch: 5| Step: 9
Training loss: 0.5764934353698673
Validation loss: 2.5153189689336943

Epoch: 5| Step: 10
Training loss: 0.9079783828111458
Validation loss: 2.5147527345365197

Epoch: 330| Step: 0
Training loss: 0.6785191765902546
Validation loss: 2.5356648920178526

Epoch: 5| Step: 1
Training loss: 0.8068292134101052
Validation loss: 2.5451121235658136

Epoch: 5| Step: 2
Training loss: 0.5563059553655607
Validation loss: 2.533431664206257

Epoch: 5| Step: 3
Training loss: 0.68320750632607
Validation loss: 2.532233786004451

Epoch: 5| Step: 4
Training loss: 0.5739625891396741
Validation loss: 2.5276438878837024

Epoch: 5| Step: 5
Training loss: 0.5907696662822518
Validation loss: 2.5138658923134414

Epoch: 5| Step: 6
Training loss: 0.6008750653775748
Validation loss: 2.5854922617272167

Epoch: 5| Step: 7
Training loss: 0.5263611292446178
Validation loss: 2.5297242780689366

Epoch: 5| Step: 8
Training loss: 0.7276127515508025
Validation loss: 2.5376924125898213

Epoch: 5| Step: 9
Training loss: 0.7306416760736862
Validation loss: 2.5596198827239975

Epoch: 5| Step: 10
Training loss: 0.6053398979654843
Validation loss: 2.5313792092542267

Epoch: 331| Step: 0
Training loss: 0.6715397996647123
Validation loss: 2.579231642705888

Epoch: 5| Step: 1
Training loss: 0.5851318160737612
Validation loss: 2.52453885695756

Epoch: 5| Step: 2
Training loss: 0.5262963808239313
Validation loss: 2.568893390451142

Epoch: 5| Step: 3
Training loss: 0.5864585085970773
Validation loss: 2.5996385307689733

Epoch: 5| Step: 4
Training loss: 0.398631815182505
Validation loss: 2.547795884231384

Epoch: 5| Step: 5
Training loss: 0.5787077878878549
Validation loss: 2.5502233634028846

Epoch: 5| Step: 6
Training loss: 0.6013141961830608
Validation loss: 2.5364230139314676

Epoch: 5| Step: 7
Training loss: 1.016561047482325
Validation loss: 2.510063915227408

Epoch: 5| Step: 8
Training loss: 0.5781519084544933
Validation loss: 2.5550174330115083

Epoch: 5| Step: 9
Training loss: 0.618760217717124
Validation loss: 2.5629835285361997

Epoch: 5| Step: 10
Training loss: 0.7729520333793708
Validation loss: 2.5727157052628624

Epoch: 332| Step: 0
Training loss: 0.7232826610987363
Validation loss: 2.553815019526001

Epoch: 5| Step: 1
Training loss: 0.47722351632789606
Validation loss: 2.5580293547821236

Epoch: 5| Step: 2
Training loss: 0.49669516145915776
Validation loss: 2.537563100479131

Epoch: 5| Step: 3
Training loss: 0.7937834364689472
Validation loss: 2.5200619013394823

Epoch: 5| Step: 4
Training loss: 0.6886757636866533
Validation loss: 2.503985677478109

Epoch: 5| Step: 5
Training loss: 0.45888805596221127
Validation loss: 2.4928317355202285

Epoch: 5| Step: 6
Training loss: 0.6258555993192555
Validation loss: 2.5041680968177142

Epoch: 5| Step: 7
Training loss: 0.4785615392961508
Validation loss: 2.5329435601059473

Epoch: 5| Step: 8
Training loss: 0.8202522255687988
Validation loss: 2.577668689507704

Epoch: 5| Step: 9
Training loss: 0.8652043046741918
Validation loss: 2.6285623656052763

Epoch: 5| Step: 10
Training loss: 0.49149473573226904
Validation loss: 2.597935008147672

Epoch: 333| Step: 0
Training loss: 0.5905295168680688
Validation loss: 2.605141180662272

Epoch: 5| Step: 1
Training loss: 0.5331965575320273
Validation loss: 2.631595387086321

Epoch: 5| Step: 2
Training loss: 0.8838057205569264
Validation loss: 2.574904178151081

Epoch: 5| Step: 3
Training loss: 0.5757986638038081
Validation loss: 2.5500855232863167

Epoch: 5| Step: 4
Training loss: 0.5654651321080364
Validation loss: 2.4971421506727816

Epoch: 5| Step: 5
Training loss: 0.9274658456976235
Validation loss: 2.502899259743414

Epoch: 5| Step: 6
Training loss: 0.6448806740292499
Validation loss: 2.466737434909673

Epoch: 5| Step: 7
Training loss: 0.4394210125528415
Validation loss: 2.446211423365006

Epoch: 5| Step: 8
Training loss: 0.22490641813442852
Validation loss: 2.476911365018649

Epoch: 5| Step: 9
Training loss: 0.7226195042521116
Validation loss: 2.4956391632293795

Epoch: 5| Step: 10
Training loss: 0.6816914493008857
Validation loss: 2.525459684957651

Epoch: 334| Step: 0
Training loss: 0.5812243814872914
Validation loss: 2.5463880824275145

Epoch: 5| Step: 1
Training loss: 0.6169379973395547
Validation loss: 2.6068985173554946

Epoch: 5| Step: 2
Training loss: 0.6511534378746029
Validation loss: 2.5950770842171322

Epoch: 5| Step: 3
Training loss: 0.602034742601146
Validation loss: 2.5924314845923226

Epoch: 5| Step: 4
Training loss: 0.5510935337724903
Validation loss: 2.6290307777267747

Epoch: 5| Step: 5
Training loss: 0.9068973136801499
Validation loss: 2.5978167760376953

Epoch: 5| Step: 6
Training loss: 0.744379080465745
Validation loss: 2.57739628163089

Epoch: 5| Step: 7
Training loss: 0.46496375322070216
Validation loss: 2.5445808119961955

Epoch: 5| Step: 8
Training loss: 0.6946172131096264
Validation loss: 2.4909510909724726

Epoch: 5| Step: 9
Training loss: 0.640242229643906
Validation loss: 2.548646533346567

Epoch: 5| Step: 10
Training loss: 0.3511173609088989
Validation loss: 2.522943016802004

Epoch: 335| Step: 0
Training loss: 0.6735964390597715
Validation loss: 2.5127365271977276

Epoch: 5| Step: 1
Training loss: 0.38908582717026574
Validation loss: 2.5198044515836315

Epoch: 5| Step: 2
Training loss: 0.6526151081293423
Validation loss: 2.552401542455622

Epoch: 5| Step: 3
Training loss: 0.5855140681934373
Validation loss: 2.5561181511467512

Epoch: 5| Step: 4
Training loss: 0.2882929688426241
Validation loss: 2.495495709042824

Epoch: 5| Step: 5
Training loss: 0.723957436833181
Validation loss: 2.550717936634291

Epoch: 5| Step: 6
Training loss: 0.6561609843599665
Validation loss: 2.543283388274006

Epoch: 5| Step: 7
Training loss: 0.6873138132272711
Validation loss: 2.5527430117278884

Epoch: 5| Step: 8
Training loss: 0.814454991180697
Validation loss: 2.5554933998154823

Epoch: 5| Step: 9
Training loss: 0.5212949773196337
Validation loss: 2.5542961202891767

Epoch: 5| Step: 10
Training loss: 0.7445791559328098
Validation loss: 2.5352343495678

Epoch: 336| Step: 0
Training loss: 0.8090304609771751
Validation loss: 2.525668481616516

Epoch: 5| Step: 1
Training loss: 0.2989001093910186
Validation loss: 2.5177373255105127

Epoch: 5| Step: 2
Training loss: 0.6529862671761919
Validation loss: 2.530570162365928

Epoch: 5| Step: 3
Training loss: 0.43672783011344296
Validation loss: 2.479930805077232

Epoch: 5| Step: 4
Training loss: 0.7691634795211386
Validation loss: 2.523374991984245

Epoch: 5| Step: 5
Training loss: 0.6023788857509833
Validation loss: 2.50810533378633

Epoch: 5| Step: 6
Training loss: 0.5778556660300354
Validation loss: 2.5349838860853513

Epoch: 5| Step: 7
Training loss: 0.5361101322900844
Validation loss: 2.518751972498684

Epoch: 5| Step: 8
Training loss: 0.5770896713881969
Validation loss: 2.57176416205334

Epoch: 5| Step: 9
Training loss: 0.6044172940056575
Validation loss: 2.5643421907579858

Epoch: 5| Step: 10
Training loss: 0.8235995963737125
Validation loss: 2.518086131329859

Epoch: 337| Step: 0
Training loss: 0.5963762076578923
Validation loss: 2.5027397709497943

Epoch: 5| Step: 1
Training loss: 0.6025978443030596
Validation loss: 2.533760821743114

Epoch: 5| Step: 2
Training loss: 0.6124979106711739
Validation loss: 2.542094444965173

Epoch: 5| Step: 3
Training loss: 0.581084665759297
Validation loss: 2.526425989767314

Epoch: 5| Step: 4
Training loss: 0.5897335934881548
Validation loss: 2.5001733278875924

Epoch: 5| Step: 5
Training loss: 0.7978517866192694
Validation loss: 2.510359972337145

Epoch: 5| Step: 6
Training loss: 0.5160535996214601
Validation loss: 2.522180318566375

Epoch: 5| Step: 7
Training loss: 0.6312188461849808
Validation loss: 2.5665288358255243

Epoch: 5| Step: 8
Training loss: 0.6392388116918907
Validation loss: 2.5566220231402084

Epoch: 5| Step: 9
Training loss: 0.5854167404265261
Validation loss: 2.5836925412328102

Epoch: 5| Step: 10
Training loss: 0.587809433510796
Validation loss: 2.5693146521983814

Epoch: 338| Step: 0
Training loss: 0.8022644449504495
Validation loss: 2.5377454198113214

Epoch: 5| Step: 1
Training loss: 0.5685028209767267
Validation loss: 2.5575392020818066

Epoch: 5| Step: 2
Training loss: 0.7257845415547838
Validation loss: 2.5244580131169227

Epoch: 5| Step: 3
Training loss: 0.5152012789076575
Validation loss: 2.514851014830039

Epoch: 5| Step: 4
Training loss: 0.5373901188337006
Validation loss: 2.498682245978728

Epoch: 5| Step: 5
Training loss: 0.5437757409240185
Validation loss: 2.511563491826299

Epoch: 5| Step: 6
Training loss: 0.4180800387809216
Validation loss: 2.509018702586856

Epoch: 5| Step: 7
Training loss: 0.5847181985157391
Validation loss: 2.5225659501651387

Epoch: 5| Step: 8
Training loss: 0.8297384487105471
Validation loss: 2.545888261051615

Epoch: 5| Step: 9
Training loss: 0.5065535271218777
Validation loss: 2.5377462287320647

Epoch: 5| Step: 10
Training loss: 0.5414854137678726
Validation loss: 2.5794548873039354

Epoch: 339| Step: 0
Training loss: 0.567869912931046
Validation loss: 2.5344252031704855

Epoch: 5| Step: 1
Training loss: 0.5717988177142841
Validation loss: 2.587222610846435

Epoch: 5| Step: 2
Training loss: 0.8655961358942207
Validation loss: 2.513101376753816

Epoch: 5| Step: 3
Training loss: 0.43113414687122736
Validation loss: 2.5245520491365543

Epoch: 5| Step: 4
Training loss: 0.6252226909635845
Validation loss: 2.475927972745649

Epoch: 5| Step: 5
Training loss: 0.4717020065050228
Validation loss: 2.439171607303309

Epoch: 5| Step: 6
Training loss: 0.46639381149293835
Validation loss: 2.4550497116209544

Epoch: 5| Step: 7
Training loss: 0.8024168105694954
Validation loss: 2.468728985066793

Epoch: 5| Step: 8
Training loss: 0.6265335580510353
Validation loss: 2.457959025818434

Epoch: 5| Step: 9
Training loss: 0.5347242351868408
Validation loss: 2.5085881458200623

Epoch: 5| Step: 10
Training loss: 0.6973749069785429
Validation loss: 2.5292073268054396

Epoch: 340| Step: 0
Training loss: 0.8729859059868589
Validation loss: 2.562310995939652

Epoch: 5| Step: 1
Training loss: 0.3231703802372153
Validation loss: 2.5878015421051663

Epoch: 5| Step: 2
Training loss: 0.6200929171400836
Validation loss: 2.5507060597381885

Epoch: 5| Step: 3
Training loss: 0.6612661613191229
Validation loss: 2.5922814689469713

Epoch: 5| Step: 4
Training loss: 0.7956162777502755
Validation loss: 2.536942852238323

Epoch: 5| Step: 5
Training loss: 0.6363523868551096
Validation loss: 2.543341967266284

Epoch: 5| Step: 6
Training loss: 0.5834841419735685
Validation loss: 2.5760168590412436

Epoch: 5| Step: 7
Training loss: 0.5635020813873899
Validation loss: 2.562914678964305

Epoch: 5| Step: 8
Training loss: 0.38030548901078604
Validation loss: 2.5599416051185515

Epoch: 5| Step: 9
Training loss: 0.24605913524298917
Validation loss: 2.5148053330354143

Epoch: 5| Step: 10
Training loss: 0.6870883446143042
Validation loss: 2.555168099373796

Epoch: 341| Step: 0
Training loss: 0.6026050401668652
Validation loss: 2.55612749880853

Epoch: 5| Step: 1
Training loss: 0.605580104309386
Validation loss: 2.5054071986314077

Epoch: 5| Step: 2
Training loss: 0.7184000407206178
Validation loss: 2.502360144583593

Epoch: 5| Step: 3
Training loss: 0.7253467684189898
Validation loss: 2.4960512827189807

Epoch: 5| Step: 4
Training loss: 0.5750673213193195
Validation loss: 2.516710928881038

Epoch: 5| Step: 5
Training loss: 0.8235561726884278
Validation loss: 2.5770665436898086

Epoch: 5| Step: 6
Training loss: 0.6069698307577851
Validation loss: 2.5672704700261515

Epoch: 5| Step: 7
Training loss: 0.5831371017050746
Validation loss: 2.5756806779456243

Epoch: 5| Step: 8
Training loss: 0.4281254552574243
Validation loss: 2.5331504915550167

Epoch: 5| Step: 9
Training loss: 0.6345940930344972
Validation loss: 2.516911027045648

Epoch: 5| Step: 10
Training loss: 0.25679903526778547
Validation loss: 2.494217345742752

Epoch: 342| Step: 0
Training loss: 0.5835400935865357
Validation loss: 2.497699926435953

Epoch: 5| Step: 1
Training loss: 0.5019775265948351
Validation loss: 2.554021722419101

Epoch: 5| Step: 2
Training loss: 0.40005533089015105
Validation loss: 2.560565716668585

Epoch: 5| Step: 3
Training loss: 0.7935398093839706
Validation loss: 2.5818860614181696

Epoch: 5| Step: 4
Training loss: 0.5465824707203963
Validation loss: 2.615888078747706

Epoch: 5| Step: 5
Training loss: 0.5207932138885695
Validation loss: 2.635263621834434

Epoch: 5| Step: 6
Training loss: 0.6577316316021119
Validation loss: 2.618806647489971

Epoch: 5| Step: 7
Training loss: 0.7473992714265616
Validation loss: 2.5871585364422907

Epoch: 5| Step: 8
Training loss: 0.6306730296329441
Validation loss: 2.5409407450652544

Epoch: 5| Step: 9
Training loss: 0.3914533415464767
Validation loss: 2.5079461275097747

Epoch: 5| Step: 10
Training loss: 0.7334223310334703
Validation loss: 2.4917928922231076

Epoch: 343| Step: 0
Training loss: 0.5327333329975563
Validation loss: 2.5018511993925534

Epoch: 5| Step: 1
Training loss: 0.8575002856017768
Validation loss: 2.4679268144337474

Epoch: 5| Step: 2
Training loss: 0.5951648218604711
Validation loss: 2.467115182585709

Epoch: 5| Step: 3
Training loss: 0.6164166429076225
Validation loss: 2.4716308149142923

Epoch: 5| Step: 4
Training loss: 0.5274870783683097
Validation loss: 2.494677935109835

Epoch: 5| Step: 5
Training loss: 0.490406416534977
Validation loss: 2.5164068188406725

Epoch: 5| Step: 6
Training loss: 0.5244344923987654
Validation loss: 2.595082466215141

Epoch: 5| Step: 7
Training loss: 0.7526118576202416
Validation loss: 2.5791011142035685

Epoch: 5| Step: 8
Training loss: 0.4432759815719173
Validation loss: 2.5739800000147928

Epoch: 5| Step: 9
Training loss: 0.6602175306058944
Validation loss: 2.592840996875869

Epoch: 5| Step: 10
Training loss: 0.5047537013235132
Validation loss: 2.5464175817798216

Epoch: 344| Step: 0
Training loss: 0.6200989487736759
Validation loss: 2.5706620185532434

Epoch: 5| Step: 1
Training loss: 0.5922229856865292
Validation loss: 2.4935657641340185

Epoch: 5| Step: 2
Training loss: 0.7743223504001768
Validation loss: 2.4721872579301962

Epoch: 5| Step: 3
Training loss: 0.4856124882700292
Validation loss: 2.447516099931177

Epoch: 5| Step: 4
Training loss: 0.4279476139382708
Validation loss: 2.4599942067722793

Epoch: 5| Step: 5
Training loss: 0.5272386516816675
Validation loss: 2.499769097606621

Epoch: 5| Step: 6
Training loss: 0.6343703227504942
Validation loss: 2.5328587167867

Epoch: 5| Step: 7
Training loss: 0.6078253629446211
Validation loss: 2.5588363881848766

Epoch: 5| Step: 8
Training loss: 0.41019786441954764
Validation loss: 2.5825435646530597

Epoch: 5| Step: 9
Training loss: 0.7038008091203484
Validation loss: 2.607920843183366

Epoch: 5| Step: 10
Training loss: 0.676676801756733
Validation loss: 2.553456880879074

Epoch: 345| Step: 0
Training loss: 0.6264047095797699
Validation loss: 2.5726464604484516

Epoch: 5| Step: 1
Training loss: 0.4921754653912575
Validation loss: 2.504511493086796

Epoch: 5| Step: 2
Training loss: 0.6416911116398359
Validation loss: 2.521929516213025

Epoch: 5| Step: 3
Training loss: 0.5014421704895093
Validation loss: 2.4755266214547387

Epoch: 5| Step: 4
Training loss: 0.6990962853621258
Validation loss: 2.4704946560750902

Epoch: 5| Step: 5
Training loss: 0.39513943317750533
Validation loss: 2.4818780669261624

Epoch: 5| Step: 6
Training loss: 0.8361332031477203
Validation loss: 2.473201217125636

Epoch: 5| Step: 7
Training loss: 0.514036332134008
Validation loss: 2.5161784989927

Epoch: 5| Step: 8
Training loss: 0.6277694379014368
Validation loss: 2.54944948486686

Epoch: 5| Step: 9
Training loss: 0.4982945742519761
Validation loss: 2.5568175560039053

Epoch: 5| Step: 10
Training loss: 0.5436072677418395
Validation loss: 2.569791055027454

Epoch: 346| Step: 0
Training loss: 0.5492187141863403
Validation loss: 2.5969647943174583

Epoch: 5| Step: 1
Training loss: 0.6056219091818785
Validation loss: 2.5959316053013124

Epoch: 5| Step: 2
Training loss: 0.7001203978403772
Validation loss: 2.567969226435604

Epoch: 5| Step: 3
Training loss: 0.5609200063118727
Validation loss: 2.561722464642066

Epoch: 5| Step: 4
Training loss: 0.6837960734003871
Validation loss: 2.503086286215235

Epoch: 5| Step: 5
Training loss: 0.6082445565421871
Validation loss: 2.5255260819653107

Epoch: 5| Step: 6
Training loss: 0.6122870435104287
Validation loss: 2.559322885717475

Epoch: 5| Step: 7
Training loss: 0.49869132141320527
Validation loss: 2.5413150260844177

Epoch: 5| Step: 8
Training loss: 0.24482681735606945
Validation loss: 2.542184465968732

Epoch: 5| Step: 9
Training loss: 0.7436181183902326
Validation loss: 2.571558789600361

Epoch: 5| Step: 10
Training loss: 0.3344205384128159
Validation loss: 2.5946217473143776

Epoch: 347| Step: 0
Training loss: 0.660001160952963
Validation loss: 2.618118559845188

Epoch: 5| Step: 1
Training loss: 0.5648325664420881
Validation loss: 2.618645372825629

Epoch: 5| Step: 2
Training loss: 0.4471995875486338
Validation loss: 2.6173812762640014

Epoch: 5| Step: 3
Training loss: 0.827214478217448
Validation loss: 2.6071410426064143

Epoch: 5| Step: 4
Training loss: 0.593318531471456
Validation loss: 2.5745616312707513

Epoch: 5| Step: 5
Training loss: 0.17540644317356702
Validation loss: 2.5459214607336027

Epoch: 5| Step: 6
Training loss: 0.5361977904364233
Validation loss: 2.51378248046135

Epoch: 5| Step: 7
Training loss: 0.43624505504767697
Validation loss: 2.5052107077857584

Epoch: 5| Step: 8
Training loss: 0.5665959270819021
Validation loss: 2.535229323370355

Epoch: 5| Step: 9
Training loss: 0.6758460305977521
Validation loss: 2.5575788130494104

Epoch: 5| Step: 10
Training loss: 0.5665596063774603
Validation loss: 2.5978372278115476

Epoch: 348| Step: 0
Training loss: 0.3090102487526446
Validation loss: 2.60292936074762

Epoch: 5| Step: 1
Training loss: 0.5672203264641702
Validation loss: 2.585540043010065

Epoch: 5| Step: 2
Training loss: 0.4376027633685657
Validation loss: 2.6126581701807203

Epoch: 5| Step: 3
Training loss: 0.6552790088672545
Validation loss: 2.5643000219509133

Epoch: 5| Step: 4
Training loss: 0.7808413390404324
Validation loss: 2.5479611264464403

Epoch: 5| Step: 5
Training loss: 0.5556187133519229
Validation loss: 2.5677284576566572

Epoch: 5| Step: 6
Training loss: 0.6714209863413998
Validation loss: 2.5108703651271846

Epoch: 5| Step: 7
Training loss: 0.543034391757754
Validation loss: 2.48349290820139

Epoch: 5| Step: 8
Training loss: 0.4046981589191317
Validation loss: 2.4486880458768554

Epoch: 5| Step: 9
Training loss: 0.5940379649096879
Validation loss: 2.4439239978806127

Epoch: 5| Step: 10
Training loss: 0.4681055566343011
Validation loss: 2.4566759981850934

Epoch: 349| Step: 0
Training loss: 0.7287606653051398
Validation loss: 2.5036460684079156

Epoch: 5| Step: 1
Training loss: 0.4209716096013088
Validation loss: 2.5321561750270227

Epoch: 5| Step: 2
Training loss: 0.535223768666763
Validation loss: 2.4862746745199913

Epoch: 5| Step: 3
Training loss: 0.5471943331672496
Validation loss: 2.5452963428776036

Epoch: 5| Step: 4
Training loss: 0.7399695332802242
Validation loss: 2.5903542968347293

Epoch: 5| Step: 5
Training loss: 0.45532499829001527
Validation loss: 2.5572187323374513

Epoch: 5| Step: 6
Training loss: 0.4123770581171226
Validation loss: 2.557197306576526

Epoch: 5| Step: 7
Training loss: 0.5390753260759
Validation loss: 2.5501416087215465

Epoch: 5| Step: 8
Training loss: 0.563660325575085
Validation loss: 2.532136871889584

Epoch: 5| Step: 9
Training loss: 0.7295001947456293
Validation loss: 2.540808294856422

Epoch: 5| Step: 10
Training loss: 0.44667675782958033
Validation loss: 2.5657161226078697

Epoch: 350| Step: 0
Training loss: 0.29239379413701355
Validation loss: 2.5727789655463367

Epoch: 5| Step: 1
Training loss: 0.788205502881091
Validation loss: 2.5690156769764005

Epoch: 5| Step: 2
Training loss: 0.7589063713288834
Validation loss: 2.6002613841795843

Epoch: 5| Step: 3
Training loss: 0.49332245653100226
Validation loss: 2.5698557400258886

Epoch: 5| Step: 4
Training loss: 0.5140391730027762
Validation loss: 2.5856788406010076

Epoch: 5| Step: 5
Training loss: 0.7485248044885154
Validation loss: 2.5864149361165247

Epoch: 5| Step: 6
Training loss: 0.5739545408932472
Validation loss: 2.506084276125719

Epoch: 5| Step: 7
Training loss: 0.25388060220146613
Validation loss: 2.5182290825092624

Epoch: 5| Step: 8
Training loss: 0.4531710371110921
Validation loss: 2.541337495411354

Epoch: 5| Step: 9
Training loss: 0.499779891203607
Validation loss: 2.568816211424864

Epoch: 5| Step: 10
Training loss: 0.560034674056349
Validation loss: 2.567613800917209

Testing loss: 2.732471600433714
