Epoch: 1| Step: 0
Training loss: 5.849563399756724
Validation loss: 5.812140686664888

Epoch: 6| Step: 1
Training loss: 6.299499419170456
Validation loss: 5.792685118700921

Epoch: 6| Step: 2
Training loss: 5.553081296320532
Validation loss: 5.773302902621385

Epoch: 6| Step: 3
Training loss: 6.268131658421406
Validation loss: 5.754451517718501

Epoch: 6| Step: 4
Training loss: 5.932869802363514
Validation loss: 5.7355397463673015

Epoch: 6| Step: 5
Training loss: 6.084967755096686
Validation loss: 5.714623267521381

Epoch: 6| Step: 6
Training loss: 5.976536968899715
Validation loss: 5.691138251332785

Epoch: 6| Step: 7
Training loss: 4.6200904563206295
Validation loss: 5.665339136462573

Epoch: 6| Step: 8
Training loss: 5.997605163746219
Validation loss: 5.636411416859234

Epoch: 6| Step: 9
Training loss: 5.366321743766132
Validation loss: 5.6038466920031444

Epoch: 6| Step: 10
Training loss: 4.517741515770941
Validation loss: 5.5661537344275756

Epoch: 6| Step: 11
Training loss: 5.6693752023963695
Validation loss: 5.525759036350023

Epoch: 6| Step: 12
Training loss: 5.0746993027474705
Validation loss: 5.481257377555283

Epoch: 6| Step: 13
Training loss: 6.579321528185124
Validation loss: 5.432256910765676

Epoch: 2| Step: 0
Training loss: 5.7245264115661785
Validation loss: 5.378918363506723

Epoch: 6| Step: 1
Training loss: 5.918891094584422
Validation loss: 5.3225650649155005

Epoch: 6| Step: 2
Training loss: 4.379170201400265
Validation loss: 5.263909656276147

Epoch: 6| Step: 3
Training loss: 5.4837766141573905
Validation loss: 5.206519610537109

Epoch: 6| Step: 4
Training loss: 4.603865301473462
Validation loss: 5.150464250630653

Epoch: 6| Step: 5
Training loss: 5.952148677835311
Validation loss: 5.098991163246284

Epoch: 6| Step: 6
Training loss: 4.334757986385989
Validation loss: 5.05228054252473

Epoch: 6| Step: 7
Training loss: 4.954156906507592
Validation loss: 5.008604613540294

Epoch: 6| Step: 8
Training loss: 4.427716282495016
Validation loss: 4.967795317120251

Epoch: 6| Step: 9
Training loss: 5.087670378210379
Validation loss: 4.92816147954591

Epoch: 6| Step: 10
Training loss: 5.667294336599808
Validation loss: 4.88673767173791

Epoch: 6| Step: 11
Training loss: 4.9357955501633874
Validation loss: 4.845710982509812

Epoch: 6| Step: 12
Training loss: 4.562904444496344
Validation loss: 4.805699318894515

Epoch: 6| Step: 13
Training loss: 5.39900930995036
Validation loss: 4.771853197388325

Epoch: 3| Step: 0
Training loss: 5.3267433858669175
Validation loss: 4.737329791854018

Epoch: 6| Step: 1
Training loss: 4.3292627044295715
Validation loss: 4.706547327142387

Epoch: 6| Step: 2
Training loss: 4.418046459860328
Validation loss: 4.673031408010264

Epoch: 6| Step: 3
Training loss: 5.633294834855631
Validation loss: 4.642331982192129

Epoch: 6| Step: 4
Training loss: 4.5910387407154385
Validation loss: 4.6117834785486425

Epoch: 6| Step: 5
Training loss: 4.450864197900707
Validation loss: 4.5848300596841

Epoch: 6| Step: 6
Training loss: 4.401728697954419
Validation loss: 4.557072563377422

Epoch: 6| Step: 7
Training loss: 5.261334672148183
Validation loss: 4.527640628874431

Epoch: 6| Step: 8
Training loss: 5.3809253058574225
Validation loss: 4.496375300146948

Epoch: 6| Step: 9
Training loss: 3.8888450135677535
Validation loss: 4.46081997965672

Epoch: 6| Step: 10
Training loss: 3.9396173748372605
Validation loss: 4.425043028491403

Epoch: 6| Step: 11
Training loss: 4.381888497880945
Validation loss: 4.391045037152173

Epoch: 6| Step: 12
Training loss: 4.523148443444087
Validation loss: 4.357908597032284

Epoch: 6| Step: 13
Training loss: 3.7205174197012294
Validation loss: 4.329170640642409

Epoch: 4| Step: 0
Training loss: 4.056790609438466
Validation loss: 4.309012897304872

Epoch: 6| Step: 1
Training loss: 4.804908809372123
Validation loss: 4.2900451613949855

Epoch: 6| Step: 2
Training loss: 4.797426074056291
Validation loss: 4.261976671569339

Epoch: 6| Step: 3
Training loss: 5.072452510876534
Validation loss: 4.242485436437788

Epoch: 6| Step: 4
Training loss: 4.235189774730114
Validation loss: 4.230891184616363

Epoch: 6| Step: 5
Training loss: 4.122420920775421
Validation loss: 4.216391988751879

Epoch: 6| Step: 6
Training loss: 5.241114590453881
Validation loss: 4.200662377224653

Epoch: 6| Step: 7
Training loss: 4.925936521764676
Validation loss: 4.182952586307946

Epoch: 6| Step: 8
Training loss: 4.719424168003875
Validation loss: 4.162327514462598

Epoch: 6| Step: 9
Training loss: 3.0421851426063027
Validation loss: 4.141970596027922

Epoch: 6| Step: 10
Training loss: 3.346388301848434
Validation loss: 4.1221317587606805

Epoch: 6| Step: 11
Training loss: 3.7518618729956046
Validation loss: 4.10354562252653

Epoch: 6| Step: 12
Training loss: 3.935534031849391
Validation loss: 4.090094429564948

Epoch: 6| Step: 13
Training loss: 3.723650996546211
Validation loss: 4.076276331952086

Epoch: 5| Step: 0
Training loss: 4.178713562053686
Validation loss: 4.066171327242848

Epoch: 6| Step: 1
Training loss: 3.9012631742627155
Validation loss: 4.053392359483796

Epoch: 6| Step: 2
Training loss: 3.5428271617587703
Validation loss: 4.043505666466627

Epoch: 6| Step: 3
Training loss: 4.371466163131687
Validation loss: 4.025313405343533

Epoch: 6| Step: 4
Training loss: 3.584044511586757
Validation loss: 4.013927237599797

Epoch: 6| Step: 5
Training loss: 4.723929083024566
Validation loss: 4.0044254361540235

Epoch: 6| Step: 6
Training loss: 3.3154272424972575
Validation loss: 3.991487525689528

Epoch: 6| Step: 7
Training loss: 4.578595134043766
Validation loss: 3.978975441002692

Epoch: 6| Step: 8
Training loss: 4.178538740353938
Validation loss: 3.9636378903249065

Epoch: 6| Step: 9
Training loss: 4.861044839074233
Validation loss: 3.9470270197620323

Epoch: 6| Step: 10
Training loss: 3.9593207616786827
Validation loss: 3.941542961903987

Epoch: 6| Step: 11
Training loss: 4.266809320051887
Validation loss: 3.93171471715856

Epoch: 6| Step: 12
Training loss: 3.9434053249242114
Validation loss: 3.9048674993882018

Epoch: 6| Step: 13
Training loss: 4.2799181572050005
Validation loss: 3.9005891494287415

Epoch: 6| Step: 0
Training loss: 4.433064137558251
Validation loss: 3.8968521574977997

Epoch: 6| Step: 1
Training loss: 3.264579788202837
Validation loss: 3.879984977962878

Epoch: 6| Step: 2
Training loss: 3.461218140118991
Validation loss: 3.8729763906494967

Epoch: 6| Step: 3
Training loss: 4.443337482775739
Validation loss: 3.8693922671980565

Epoch: 6| Step: 4
Training loss: 4.764684365417166
Validation loss: 3.8514739368356135

Epoch: 6| Step: 5
Training loss: 4.431431448897669
Validation loss: 3.836474734290242

Epoch: 6| Step: 6
Training loss: 3.759467825056722
Validation loss: 3.8268118961258177

Epoch: 6| Step: 7
Training loss: 4.562845922446572
Validation loss: 3.826147946900677

Epoch: 6| Step: 8
Training loss: 3.5783592713802848
Validation loss: 3.807197031056689

Epoch: 6| Step: 9
Training loss: 4.609965658328886
Validation loss: 3.7970308215901865

Epoch: 6| Step: 10
Training loss: 3.751251393374801
Validation loss: 3.789693834139578

Epoch: 6| Step: 11
Training loss: 3.832718067273293
Validation loss: 3.783607357593269

Epoch: 6| Step: 12
Training loss: 2.1698506753057916
Validation loss: 3.7693337369776754

Epoch: 6| Step: 13
Training loss: 4.308601275633727
Validation loss: 3.7594914029046462

Epoch: 7| Step: 0
Training loss: 3.5142939103370994
Validation loss: 3.7531816692117244

Epoch: 6| Step: 1
Training loss: 2.945287243964991
Validation loss: 3.74604383725776

Epoch: 6| Step: 2
Training loss: 3.5538579958065166
Validation loss: 3.736323393382105

Epoch: 6| Step: 3
Training loss: 4.4895714614368964
Validation loss: 3.7312764226402133

Epoch: 6| Step: 4
Training loss: 4.27071448680232
Validation loss: 3.726357689990807

Epoch: 6| Step: 5
Training loss: 4.46050435383446
Validation loss: 3.7187829178617955

Epoch: 6| Step: 6
Training loss: 4.544963841394129
Validation loss: 3.709734399107367

Epoch: 6| Step: 7
Training loss: 4.24795146264977
Validation loss: 3.7045391735433633

Epoch: 6| Step: 8
Training loss: 3.2089883870467157
Validation loss: 3.6966222752802786

Epoch: 6| Step: 9
Training loss: 3.7965424317443306
Validation loss: 3.6877730602001018

Epoch: 6| Step: 10
Training loss: 3.5322261575113814
Validation loss: 3.6846808155961583

Epoch: 6| Step: 11
Training loss: 3.4977494224628023
Validation loss: 3.679963906990812

Epoch: 6| Step: 12
Training loss: 3.735227351897248
Validation loss: 3.6701458974019343

Epoch: 6| Step: 13
Training loss: 4.558455673519422
Validation loss: 3.65990291111866

Epoch: 8| Step: 0
Training loss: 3.3657384883409187
Validation loss: 3.6576162449514364

Epoch: 6| Step: 1
Training loss: 3.2513222572190665
Validation loss: 3.655344716814435

Epoch: 6| Step: 2
Training loss: 3.464327080188918
Validation loss: 3.6455125129049484

Epoch: 6| Step: 3
Training loss: 4.284360994389831
Validation loss: 3.631292472236421

Epoch: 6| Step: 4
Training loss: 3.3756631270375914
Validation loss: 3.629960936715786

Epoch: 6| Step: 5
Training loss: 3.6859670782580185
Validation loss: 3.628656808078975

Epoch: 6| Step: 6
Training loss: 4.968838289064265
Validation loss: 3.6167332621314645

Epoch: 6| Step: 7
Training loss: 3.4085072728723396
Validation loss: 3.60589368362988

Epoch: 6| Step: 8
Training loss: 3.9972722766514823
Validation loss: 3.60684661175538

Epoch: 6| Step: 9
Training loss: 4.464491515729261
Validation loss: 3.596930478883026

Epoch: 6| Step: 10
Training loss: 3.320389044384241
Validation loss: 3.5838303680337686

Epoch: 6| Step: 11
Training loss: 3.8305910225169053
Validation loss: 3.58498373083674

Epoch: 6| Step: 12
Training loss: 3.1684997339379475
Validation loss: 3.5802157567768074

Epoch: 6| Step: 13
Training loss: 4.594853897843684
Validation loss: 3.574050785508837

Epoch: 9| Step: 0
Training loss: 3.212992435222023
Validation loss: 3.560124590315737

Epoch: 6| Step: 1
Training loss: 4.1604459992993466
Validation loss: 3.560898838921252

Epoch: 6| Step: 2
Training loss: 3.242336628253317
Validation loss: 3.5566122684592973

Epoch: 6| Step: 3
Training loss: 4.0893111296570135
Validation loss: 3.5457549562599713

Epoch: 6| Step: 4
Training loss: 3.9812334428619605
Validation loss: 3.5392585752053174

Epoch: 6| Step: 5
Training loss: 3.936066260508923
Validation loss: 3.539376732568742

Epoch: 6| Step: 6
Training loss: 3.6326271584104917
Validation loss: 3.5328584275440975

Epoch: 6| Step: 7
Training loss: 3.9698556876677777
Validation loss: 3.5217803884718717

Epoch: 6| Step: 8
Training loss: 3.0008473789006795
Validation loss: 3.5137556108788965

Epoch: 6| Step: 9
Training loss: 4.041876456462597
Validation loss: 3.5184628804683324

Epoch: 6| Step: 10
Training loss: 3.6759348400430314
Validation loss: 3.508251667794301

Epoch: 6| Step: 11
Training loss: 4.239916339264826
Validation loss: 3.494179974418106

Epoch: 6| Step: 12
Training loss: 3.5533348108781198
Validation loss: 3.490824617696506

Epoch: 6| Step: 13
Training loss: 2.92846002931755
Validation loss: 3.485322359682124

Epoch: 10| Step: 0
Training loss: 3.3393437239909893
Validation loss: 3.48148152858459

Epoch: 6| Step: 1
Training loss: 4.238702456028518
Validation loss: 3.474265336266288

Epoch: 6| Step: 2
Training loss: 4.400046452363768
Validation loss: 3.469882959288822

Epoch: 6| Step: 3
Training loss: 3.5101570161656883
Validation loss: 3.465496102031139

Epoch: 6| Step: 4
Training loss: 3.877356151320398
Validation loss: 3.4582507042935258

Epoch: 6| Step: 5
Training loss: 3.492510684631213
Validation loss: 3.4569319816284536

Epoch: 6| Step: 6
Training loss: 3.933246798021389
Validation loss: 3.4543209147818255

Epoch: 6| Step: 7
Training loss: 4.173117920391207
Validation loss: 3.449943425382098

Epoch: 6| Step: 8
Training loss: 4.015974096419851
Validation loss: 3.4390293362512483

Epoch: 6| Step: 9
Training loss: 3.061165343640947
Validation loss: 3.438757824962315

Epoch: 6| Step: 10
Training loss: 2.951072504376405
Validation loss: 3.4433828316822566

Epoch: 6| Step: 11
Training loss: 2.6930357231663304
Validation loss: 3.444676658077158

Epoch: 6| Step: 12
Training loss: 3.4769435030867593
Validation loss: 3.4327792525103247

Epoch: 6| Step: 13
Training loss: 3.9560090050358587
Validation loss: 3.4196135755253296

Epoch: 11| Step: 0
Training loss: 4.622751668925523
Validation loss: 3.42090508921813

Epoch: 6| Step: 1
Training loss: 3.7411257963915445
Validation loss: 3.427597461152889

Epoch: 6| Step: 2
Training loss: 3.959132518734795
Validation loss: 3.41697161224299

Epoch: 6| Step: 3
Training loss: 3.7155298989255314
Validation loss: 3.4020018001619468

Epoch: 6| Step: 4
Training loss: 3.60874147346105
Validation loss: 3.4019817710117475

Epoch: 6| Step: 5
Training loss: 3.6586481038596723
Validation loss: 3.3989937456838035

Epoch: 6| Step: 6
Training loss: 3.785678508620335
Validation loss: 3.3917056514977397

Epoch: 6| Step: 7
Training loss: 2.7480761994815097
Validation loss: 3.3864008217809665

Epoch: 6| Step: 8
Training loss: 3.685696694341609
Validation loss: 3.3890003530859505

Epoch: 6| Step: 9
Training loss: 3.4327737395399365
Validation loss: 3.3866286543677457

Epoch: 6| Step: 10
Training loss: 3.21169715675513
Validation loss: 3.3776693934669964

Epoch: 6| Step: 11
Training loss: 3.857529171767228
Validation loss: 3.370531049378179

Epoch: 6| Step: 12
Training loss: 2.9634857083061767
Validation loss: 3.36445864671772

Epoch: 6| Step: 13
Training loss: 3.268975833947031
Validation loss: 3.3700462516862273

Epoch: 12| Step: 0
Training loss: 4.184356648388506
Validation loss: 3.3593546426761516

Epoch: 6| Step: 1
Training loss: 3.350933309330268
Validation loss: 3.353538647506824

Epoch: 6| Step: 2
Training loss: 3.2810982805325524
Validation loss: 3.367318583781731

Epoch: 6| Step: 3
Training loss: 3.8173082392706403
Validation loss: 3.375345603600022

Epoch: 6| Step: 4
Training loss: 3.2671727067492986
Validation loss: 3.3580232350708945

Epoch: 6| Step: 5
Training loss: 3.3960324250505365
Validation loss: 3.336594915312395

Epoch: 6| Step: 6
Training loss: 3.5962037044193145
Validation loss: 3.3277722397592915

Epoch: 6| Step: 7
Training loss: 3.9391077785772195
Validation loss: 3.3293283141568795

Epoch: 6| Step: 8
Training loss: 2.2882115992621936
Validation loss: 3.3199467383583774

Epoch: 6| Step: 9
Training loss: 4.011489341587597
Validation loss: 3.3156802018010327

Epoch: 6| Step: 10
Training loss: 4.212335527871116
Validation loss: 3.3042576054310953

Epoch: 6| Step: 11
Training loss: 2.7254188565660113
Validation loss: 3.2920517473586597

Epoch: 6| Step: 12
Training loss: 3.4542016469720376
Validation loss: 3.3055329426454185

Epoch: 6| Step: 13
Training loss: 4.161057982525063
Validation loss: 3.3149223394092706

Epoch: 13| Step: 0
Training loss: 3.19769138863962
Validation loss: 3.3020345150438013

Epoch: 6| Step: 1
Training loss: 3.9106113348123577
Validation loss: 3.283482344486713

Epoch: 6| Step: 2
Training loss: 3.2146991312493873
Validation loss: 3.2903052433010758

Epoch: 6| Step: 3
Training loss: 2.3971821733618692
Validation loss: 3.272447757578916

Epoch: 6| Step: 4
Training loss: 4.35687709328384
Validation loss: 3.2829791535177204

Epoch: 6| Step: 5
Training loss: 2.4162427815478984
Validation loss: 3.289193835281675

Epoch: 6| Step: 6
Training loss: 3.5972498561692876
Validation loss: 3.292803740198577

Epoch: 6| Step: 7
Training loss: 4.284812614412093
Validation loss: 3.284303991497486

Epoch: 6| Step: 8
Training loss: 3.3395189272325196
Validation loss: 3.2685450119336683

Epoch: 6| Step: 9
Training loss: 4.256410364387282
Validation loss: 3.2716197211611053

Epoch: 6| Step: 10
Training loss: 3.0441195034575377
Validation loss: 3.262275918687675

Epoch: 6| Step: 11
Training loss: 3.5037788699672396
Validation loss: 3.2688295154283704

Epoch: 6| Step: 12
Training loss: 3.6799041619467867
Validation loss: 3.2729777899936194

Epoch: 6| Step: 13
Training loss: 3.411018183999421
Validation loss: 3.251513188033686

Epoch: 14| Step: 0
Training loss: 2.9860892440428954
Validation loss: 3.247857101222478

Epoch: 6| Step: 1
Training loss: 4.181593643915203
Validation loss: 3.2454721732749126

Epoch: 6| Step: 2
Training loss: 2.9838531197610276
Validation loss: 3.248126536743288

Epoch: 6| Step: 3
Training loss: 3.436503179110507
Validation loss: 3.2436744021204564

Epoch: 6| Step: 4
Training loss: 3.133372268705395
Validation loss: 3.2415763570562617

Epoch: 6| Step: 5
Training loss: 4.600738814357912
Validation loss: 3.238616130022679

Epoch: 6| Step: 6
Training loss: 2.898340105338043
Validation loss: 3.231521291537487

Epoch: 6| Step: 7
Training loss: 3.3058892267757423
Validation loss: 3.2315970593562153

Epoch: 6| Step: 8
Training loss: 4.230717166500252
Validation loss: 3.2303364937408032

Epoch: 6| Step: 9
Training loss: 3.1278287672995124
Validation loss: 3.2310283019702966

Epoch: 6| Step: 10
Training loss: 3.5447900500626885
Validation loss: 3.228428867828219

Epoch: 6| Step: 11
Training loss: 3.4929734952037355
Validation loss: 3.232390813799411

Epoch: 6| Step: 12
Training loss: 2.7172584388427086
Validation loss: 3.223711157822356

Epoch: 6| Step: 13
Training loss: 3.7250302921573986
Validation loss: 3.2241095128539947

Epoch: 15| Step: 0
Training loss: 2.6813043548836575
Validation loss: 3.218201315421148

Epoch: 6| Step: 1
Training loss: 3.8488718039456717
Validation loss: 3.2182067498672673

Epoch: 6| Step: 2
Training loss: 3.078298496062293
Validation loss: 3.2130504514666

Epoch: 6| Step: 3
Training loss: 3.762118404465919
Validation loss: 3.2096302818765294

Epoch: 6| Step: 4
Training loss: 3.2568425259959595
Validation loss: 3.2092353291719404

Epoch: 6| Step: 5
Training loss: 3.3161209756574492
Validation loss: 3.2087094995085557

Epoch: 6| Step: 6
Training loss: 3.7297586294422493
Validation loss: 3.209078847701958

Epoch: 6| Step: 7
Training loss: 3.5989390187313366
Validation loss: 3.2234440986705297

Epoch: 6| Step: 8
Training loss: 3.4426865723692144
Validation loss: 3.287222272443663

Epoch: 6| Step: 9
Training loss: 2.1958501300012516
Validation loss: 3.2144289371232824

Epoch: 6| Step: 10
Training loss: 3.6865813840644512
Validation loss: 3.2010366159265646

Epoch: 6| Step: 11
Training loss: 3.8188577390166247
Validation loss: 3.200875228481772

Epoch: 6| Step: 12
Training loss: 4.164041887701095
Validation loss: 3.205692633758912

Epoch: 6| Step: 13
Training loss: 3.4655575194466564
Validation loss: 3.204899998961253

Epoch: 16| Step: 0
Training loss: 3.2455889771870208
Validation loss: 3.2012398859899514

Epoch: 6| Step: 1
Training loss: 4.199025477020238
Validation loss: 3.195385293025861

Epoch: 6| Step: 2
Training loss: 2.2822131906165812
Validation loss: 3.1900166889759256

Epoch: 6| Step: 3
Training loss: 3.364795375004164
Validation loss: 3.1877517520349192

Epoch: 6| Step: 4
Training loss: 3.672318062531155
Validation loss: 3.189287674840012

Epoch: 6| Step: 5
Training loss: 4.100722337685874
Validation loss: 3.2158270854741673

Epoch: 6| Step: 6
Training loss: 3.5265003771839187
Validation loss: 3.215665676580739

Epoch: 6| Step: 7
Training loss: 3.5648175113405394
Validation loss: 3.185073867015722

Epoch: 6| Step: 8
Training loss: 3.4859672979417544
Validation loss: 3.1822744408346977

Epoch: 6| Step: 9
Training loss: 3.8504386949165346
Validation loss: 3.180941499305166

Epoch: 6| Step: 10
Training loss: 2.7985885741212746
Validation loss: 3.1817175548682854

Epoch: 6| Step: 11
Training loss: 3.2578938791919194
Validation loss: 3.1814893430751714

Epoch: 6| Step: 12
Training loss: 2.922763628135561
Validation loss: 3.180815884988859

Epoch: 6| Step: 13
Training loss: 3.3790770030012505
Validation loss: 3.1749403083247287

Epoch: 17| Step: 0
Training loss: 3.2927306825643043
Validation loss: 3.175408105490002

Epoch: 6| Step: 1
Training loss: 2.7115928011796275
Validation loss: 3.1717614820829527

Epoch: 6| Step: 2
Training loss: 3.0278225427831695
Validation loss: 3.171404035111206

Epoch: 6| Step: 3
Training loss: 2.688113652630865
Validation loss: 3.1896626171372326

Epoch: 6| Step: 4
Training loss: 4.17790192584186
Validation loss: 3.2280746651240664

Epoch: 6| Step: 5
Training loss: 4.4000109065527555
Validation loss: 3.182781565975577

Epoch: 6| Step: 6
Training loss: 3.046609720272469
Validation loss: 3.165987316460839

Epoch: 6| Step: 7
Training loss: 3.1521809853813294
Validation loss: 3.1672211889049637

Epoch: 6| Step: 8
Training loss: 3.484126197587822
Validation loss: 3.1810399188929726

Epoch: 6| Step: 9
Training loss: 3.4243038388854834
Validation loss: 3.1780176675352223

Epoch: 6| Step: 10
Training loss: 2.8690438978121686
Validation loss: 3.170318263525899

Epoch: 6| Step: 11
Training loss: 4.044481431235335
Validation loss: 3.1610962643055336

Epoch: 6| Step: 12
Training loss: 3.560637137586688
Validation loss: 3.157560440558168

Epoch: 6| Step: 13
Training loss: 3.6914829791132733
Validation loss: 3.1549882554793403

Epoch: 18| Step: 0
Training loss: 3.5845024212618726
Validation loss: 3.1576305445708046

Epoch: 6| Step: 1
Training loss: 4.13228403329044
Validation loss: 3.160347419076552

Epoch: 6| Step: 2
Training loss: 2.5561248748673306
Validation loss: 3.159357179577042

Epoch: 6| Step: 3
Training loss: 3.5315246475225925
Validation loss: 3.1578052213853183

Epoch: 6| Step: 4
Training loss: 3.5164677266864186
Validation loss: 3.1545197300749424

Epoch: 6| Step: 5
Training loss: 3.079122313996042
Validation loss: 3.153995799374177

Epoch: 6| Step: 6
Training loss: 3.4311474449521207
Validation loss: 3.1520945297287546

Epoch: 6| Step: 7
Training loss: 3.160540242672021
Validation loss: 3.159674968784593

Epoch: 6| Step: 8
Training loss: 3.1417622950509028
Validation loss: 3.1567764874663267

Epoch: 6| Step: 9
Training loss: 3.9728751783333425
Validation loss: 3.159935036969306

Epoch: 6| Step: 10
Training loss: 2.866249866643637
Validation loss: 3.141747967899233

Epoch: 6| Step: 11
Training loss: 3.922469743717708
Validation loss: 3.1416854516961026

Epoch: 6| Step: 12
Training loss: 3.264808954371591
Validation loss: 3.1482204911176352

Epoch: 6| Step: 13
Training loss: 2.962949527162536
Validation loss: 3.1700827777023735

Epoch: 19| Step: 0
Training loss: 3.8085566905248247
Validation loss: 3.1635882983549104

Epoch: 6| Step: 1
Training loss: 3.1114202319327062
Validation loss: 3.143852633619406

Epoch: 6| Step: 2
Training loss: 3.6131366102807103
Validation loss: 3.1365644808072513

Epoch: 6| Step: 3
Training loss: 2.2433013807555824
Validation loss: 3.1345006288496373

Epoch: 6| Step: 4
Training loss: 3.3708037674923217
Validation loss: 3.1327935362133386

Epoch: 6| Step: 5
Training loss: 3.1484829352723467
Validation loss: 3.130313400534444

Epoch: 6| Step: 6
Training loss: 2.929272594318209
Validation loss: 3.132253587225184

Epoch: 6| Step: 7
Training loss: 3.568408015712548
Validation loss: 3.1427868442147133

Epoch: 6| Step: 8
Training loss: 3.4635099404777354
Validation loss: 3.1366928120558994

Epoch: 6| Step: 9
Training loss: 3.6174311051204513
Validation loss: 3.1284529955146976

Epoch: 6| Step: 10
Training loss: 4.048245584524495
Validation loss: 3.124565954110909

Epoch: 6| Step: 11
Training loss: 3.3971688544412886
Validation loss: 3.1246015873091104

Epoch: 6| Step: 12
Training loss: 3.1088987973030835
Validation loss: 3.1248659412793223

Epoch: 6| Step: 13
Training loss: 3.983127174203262
Validation loss: 3.1246782723803563

Epoch: 20| Step: 0
Training loss: 2.8288512588292933
Validation loss: 3.120939738533872

Epoch: 6| Step: 1
Training loss: 3.4952032734665894
Validation loss: 3.121370421902956

Epoch: 6| Step: 2
Training loss: 2.6803265134986116
Validation loss: 3.1204406752378127

Epoch: 6| Step: 3
Training loss: 3.4646996572437248
Validation loss: 3.1202459766527344

Epoch: 6| Step: 4
Training loss: 3.2411595932680024
Validation loss: 3.118581180621832

Epoch: 6| Step: 5
Training loss: 3.1861189299929733
Validation loss: 3.1180076617063412

Epoch: 6| Step: 6
Training loss: 4.228081449635399
Validation loss: 3.1168511198626767

Epoch: 6| Step: 7
Training loss: 3.07639415119564
Validation loss: 3.1141342863873813

Epoch: 6| Step: 8
Training loss: 3.1258717656109862
Validation loss: 3.112476821110031

Epoch: 6| Step: 9
Training loss: 3.271645868215525
Validation loss: 3.113572745286313

Epoch: 6| Step: 10
Training loss: 3.5421755406430635
Validation loss: 3.1123720301149835

Epoch: 6| Step: 11
Training loss: 3.5596189393540714
Validation loss: 3.1112092527156467

Epoch: 6| Step: 12
Training loss: 3.598886948285612
Validation loss: 3.110426958719291

Epoch: 6| Step: 13
Training loss: 4.049893818158013
Validation loss: 3.109666628968428

Epoch: 21| Step: 0
Training loss: 3.5076019291875378
Validation loss: 3.1100017995716707

Epoch: 6| Step: 1
Training loss: 3.4815543351618228
Validation loss: 3.1080772448365503

Epoch: 6| Step: 2
Training loss: 3.360357664236323
Validation loss: 3.1049496217373713

Epoch: 6| Step: 3
Training loss: 3.9249007874602704
Validation loss: 3.106052063684486

Epoch: 6| Step: 4
Training loss: 2.9340359980501267
Validation loss: 3.101079385172238

Epoch: 6| Step: 5
Training loss: 4.312762266283468
Validation loss: 3.1022565428877855

Epoch: 6| Step: 6
Training loss: 2.9426808223732457
Validation loss: 3.1022625159517205

Epoch: 6| Step: 7
Training loss: 2.659262351531428
Validation loss: 3.1019695917119035

Epoch: 6| Step: 8
Training loss: 3.198282889769628
Validation loss: 3.1008689400204528

Epoch: 6| Step: 9
Training loss: 2.3796457729075144
Validation loss: 3.0980577058595924

Epoch: 6| Step: 10
Training loss: 3.3475205027812045
Validation loss: 3.0990096356405905

Epoch: 6| Step: 11
Training loss: 3.8334970577492897
Validation loss: 3.096538036121893

Epoch: 6| Step: 12
Training loss: 3.7036580535053343
Validation loss: 3.0974039206898287

Epoch: 6| Step: 13
Training loss: 2.8748465787337807
Validation loss: 3.0949051466407105

Epoch: 22| Step: 0
Training loss: 2.550988462014538
Validation loss: 3.0948699965668514

Epoch: 6| Step: 1
Training loss: 3.463062469297914
Validation loss: 3.0940709424596022

Epoch: 6| Step: 2
Training loss: 3.5155748151800057
Validation loss: 3.0946497813890317

Epoch: 6| Step: 3
Training loss: 3.736847892697365
Validation loss: 3.0919768952574076

Epoch: 6| Step: 4
Training loss: 3.4158391803344905
Validation loss: 3.0914995981586326

Epoch: 6| Step: 5
Training loss: 3.349087599439325
Validation loss: 3.088328141931725

Epoch: 6| Step: 6
Training loss: 3.59758918360059
Validation loss: 3.0905538891803

Epoch: 6| Step: 7
Training loss: 2.751977469645913
Validation loss: 3.088603122322975

Epoch: 6| Step: 8
Training loss: 3.6332779124754864
Validation loss: 3.090942041590404

Epoch: 6| Step: 9
Training loss: 3.7951665103454366
Validation loss: 3.087873497018074

Epoch: 6| Step: 10
Training loss: 3.180357466465358
Validation loss: 3.0877436751918137

Epoch: 6| Step: 11
Training loss: 2.8317709336179364
Validation loss: 3.086957707582041

Epoch: 6| Step: 12
Training loss: 3.4799072634738315
Validation loss: 3.087660983168583

Epoch: 6| Step: 13
Training loss: 3.490337248632558
Validation loss: 3.0881406476020987

Epoch: 23| Step: 0
Training loss: 3.7625638937356745
Validation loss: 3.084143787906557

Epoch: 6| Step: 1
Training loss: 3.5528114146917873
Validation loss: 3.084669568317719

Epoch: 6| Step: 2
Training loss: 3.533134970105159
Validation loss: 3.0845268201757365

Epoch: 6| Step: 3
Training loss: 3.2871237361818637
Validation loss: 3.082755972349689

Epoch: 6| Step: 4
Training loss: 2.1402954070580718
Validation loss: 3.0816348307905383

Epoch: 6| Step: 5
Training loss: 3.2505604187414625
Validation loss: 3.0812609114675547

Epoch: 6| Step: 6
Training loss: 2.9325380012931324
Validation loss: 3.0796757055677024

Epoch: 6| Step: 7
Training loss: 3.7113251493663078
Validation loss: 3.085705529442134

Epoch: 6| Step: 8
Training loss: 3.3958856933551202
Validation loss: 3.076132390552942

Epoch: 6| Step: 9
Training loss: 3.4684288632314306
Validation loss: 3.076564998374981

Epoch: 6| Step: 10
Training loss: 3.4390169437897296
Validation loss: 3.1027339385405868

Epoch: 6| Step: 11
Training loss: 3.6206333563174975
Validation loss: 3.075668885022243

Epoch: 6| Step: 12
Training loss: 2.6763912647207957
Validation loss: 3.077771759710957

Epoch: 6| Step: 13
Training loss: 4.046975859927984
Validation loss: 3.08608751972079

Epoch: 24| Step: 0
Training loss: 3.813121557379536
Validation loss: 3.091618945511337

Epoch: 6| Step: 1
Training loss: 2.7779371268872737
Validation loss: 3.088782845667756

Epoch: 6| Step: 2
Training loss: 3.504832201762619
Validation loss: 3.094034646932186

Epoch: 6| Step: 3
Training loss: 3.186065949623699
Validation loss: 3.0851659065347885

Epoch: 6| Step: 4
Training loss: 3.2987834595388716
Validation loss: 3.0776945922691503

Epoch: 6| Step: 5
Training loss: 3.5708972944468442
Validation loss: 3.078860829429038

Epoch: 6| Step: 6
Training loss: 3.6697910320026255
Validation loss: 3.0717197217940724

Epoch: 6| Step: 7
Training loss: 3.2838798519927948
Validation loss: 3.0720826638664605

Epoch: 6| Step: 8
Training loss: 3.1760905397899726
Validation loss: 3.071051312406728

Epoch: 6| Step: 9
Training loss: 3.0388583627113332
Validation loss: 3.069160489742762

Epoch: 6| Step: 10
Training loss: 2.9303736175740833
Validation loss: 3.0659468964682572

Epoch: 6| Step: 11
Training loss: 2.7455609647185635
Validation loss: 3.064376637792786

Epoch: 6| Step: 12
Training loss: 3.8945492482893416
Validation loss: 3.0633345457361596

Epoch: 6| Step: 13
Training loss: 3.8993952306707804
Validation loss: 3.065642446680478

Epoch: 25| Step: 0
Training loss: 3.1983878485436867
Validation loss: 3.062788697950304

Epoch: 6| Step: 1
Training loss: 3.747444935420179
Validation loss: 3.0632326272310464

Epoch: 6| Step: 2
Training loss: 3.3513886377726476
Validation loss: 3.0659514050721595

Epoch: 6| Step: 3
Training loss: 3.2261324173296897
Validation loss: 3.063305777045379

Epoch: 6| Step: 4
Training loss: 2.655325515533797
Validation loss: 3.0573575590153164

Epoch: 6| Step: 5
Training loss: 3.391725563706402
Validation loss: 3.055576837551945

Epoch: 6| Step: 6
Training loss: 3.7511654632205302
Validation loss: 3.056831427662328

Epoch: 6| Step: 7
Training loss: 2.214517128625578
Validation loss: 3.0573869605692017

Epoch: 6| Step: 8
Training loss: 3.7313971357872022
Validation loss: 3.056761004615143

Epoch: 6| Step: 9
Training loss: 2.787497030350681
Validation loss: 3.0554292397913385

Epoch: 6| Step: 10
Training loss: 3.9865824250556634
Validation loss: 3.055217442554296

Epoch: 6| Step: 11
Training loss: 3.893255363384725
Validation loss: 3.0554118488696367

Epoch: 6| Step: 12
Training loss: 2.7303460657065592
Validation loss: 3.053354918107228

Epoch: 6| Step: 13
Training loss: 3.5271999122804774
Validation loss: 3.0518324671648243

Epoch: 26| Step: 0
Training loss: 2.7019499942661582
Validation loss: 3.0513404872585776

Epoch: 6| Step: 1
Training loss: 2.936303077500593
Validation loss: 3.050332677992278

Epoch: 6| Step: 2
Training loss: 3.161631010179912
Validation loss: 3.0513968965008846

Epoch: 6| Step: 3
Training loss: 3.2602892638513494
Validation loss: 3.0506122295393365

Epoch: 6| Step: 4
Training loss: 3.7952823516791585
Validation loss: 3.070505799464202

Epoch: 6| Step: 5
Training loss: 3.5774647465854255
Validation loss: 3.0976478034359247

Epoch: 6| Step: 6
Training loss: 3.6520193027266155
Validation loss: 3.05005654360443

Epoch: 6| Step: 7
Training loss: 3.2300849511280516
Validation loss: 3.0455949044737847

Epoch: 6| Step: 8
Training loss: 2.9830138612604817
Validation loss: 3.045588108988965

Epoch: 6| Step: 9
Training loss: 2.93885706944618
Validation loss: 3.0578880448828376

Epoch: 6| Step: 10
Training loss: 3.636388974751711
Validation loss: 3.0874638022946774

Epoch: 6| Step: 11
Training loss: 3.6204041911875473
Validation loss: 3.120798406267639

Epoch: 6| Step: 12
Training loss: 3.033751409315765
Validation loss: 3.0873615261240777

Epoch: 6| Step: 13
Training loss: 4.150346277336598
Validation loss: 3.047521284842816

Epoch: 27| Step: 0
Training loss: 3.453565060292246
Validation loss: 3.0444955618206957

Epoch: 6| Step: 1
Training loss: 3.6407266365238864
Validation loss: 3.046452712461591

Epoch: 6| Step: 2
Training loss: 2.6786940265028534
Validation loss: 3.094827957435631

Epoch: 6| Step: 3
Training loss: 3.3890517843595003
Validation loss: 3.0501952434458266

Epoch: 6| Step: 4
Training loss: 3.024109915940789
Validation loss: 3.0435148168279347

Epoch: 6| Step: 5
Training loss: 3.0308689782479323
Validation loss: 3.0444735528815707

Epoch: 6| Step: 6
Training loss: 3.479878213878016
Validation loss: 3.0463026680335834

Epoch: 6| Step: 7
Training loss: 3.5766187937561376
Validation loss: 3.052120471563061

Epoch: 6| Step: 8
Training loss: 3.6493190705040752
Validation loss: 3.0542796468792535

Epoch: 6| Step: 9
Training loss: 3.679588235540749
Validation loss: 3.0508338226540164

Epoch: 6| Step: 10
Training loss: 3.085939508751324
Validation loss: 3.0416539442397816

Epoch: 6| Step: 11
Training loss: 3.4240735102632542
Validation loss: 3.035964074271666

Epoch: 6| Step: 12
Training loss: 3.1291185323684716
Validation loss: 3.033233495151284

Epoch: 6| Step: 13
Training loss: 2.757344581740928
Validation loss: 3.035666366471937

Epoch: 28| Step: 0
Training loss: 3.0113045374205916
Validation loss: 3.036099199355371

Epoch: 6| Step: 1
Training loss: 3.7366133489783477
Validation loss: 3.0419998885449173

Epoch: 6| Step: 2
Training loss: 2.7601450276625807
Validation loss: 3.03969072752725

Epoch: 6| Step: 3
Training loss: 3.4506426558192285
Validation loss: 3.0346712275046785

Epoch: 6| Step: 4
Training loss: 2.7641732236293537
Validation loss: 3.0342290262317735

Epoch: 6| Step: 5
Training loss: 3.6965420312626773
Validation loss: 3.027267017060242

Epoch: 6| Step: 6
Training loss: 2.946971476685754
Validation loss: 3.0264382381638892

Epoch: 6| Step: 7
Training loss: 3.1632383427026394
Validation loss: 3.025568221131277

Epoch: 6| Step: 8
Training loss: 3.669788563221985
Validation loss: 3.030731388539664

Epoch: 6| Step: 9
Training loss: 2.985290706414811
Validation loss: 3.030454857151327

Epoch: 6| Step: 10
Training loss: 3.111607042779
Validation loss: 3.0285266397826858

Epoch: 6| Step: 11
Training loss: 3.246012221872163
Validation loss: 3.0259142659593286

Epoch: 6| Step: 12
Training loss: 4.203634578630057
Validation loss: 3.020104392380583

Epoch: 6| Step: 13
Training loss: 3.0761597842024293
Validation loss: 3.0201749367733317

Epoch: 29| Step: 0
Training loss: 3.0858410783986936
Validation loss: 3.0220919071061405

Epoch: 6| Step: 1
Training loss: 3.849792940591066
Validation loss: 3.0242522182994667

Epoch: 6| Step: 2
Training loss: 3.7708493789134763
Validation loss: 3.0249735233155333

Epoch: 6| Step: 3
Training loss: 2.8276815330183225
Validation loss: 3.0228395334158393

Epoch: 6| Step: 4
Training loss: 3.912621512674134
Validation loss: 3.0181469767241005

Epoch: 6| Step: 5
Training loss: 3.2150663759964564
Validation loss: 3.018478941407541

Epoch: 6| Step: 6
Training loss: 3.3613902589950193
Validation loss: 3.015942822408521

Epoch: 6| Step: 7
Training loss: 3.639808661493782
Validation loss: 3.018497854752826

Epoch: 6| Step: 8
Training loss: 3.051503583160602
Validation loss: 3.015180093015612

Epoch: 6| Step: 9
Training loss: 2.775000161523213
Validation loss: 3.012811862599555

Epoch: 6| Step: 10
Training loss: 2.6663402317837117
Validation loss: 3.0115659194639472

Epoch: 6| Step: 11
Training loss: 3.65212205836207
Validation loss: 3.012882073161861

Epoch: 6| Step: 12
Training loss: 2.3383770200092884
Validation loss: 3.009523495043897

Epoch: 6| Step: 13
Training loss: 3.646042881347798
Validation loss: 3.0085744318099024

Epoch: 30| Step: 0
Training loss: 3.252990520530325
Validation loss: 3.0101193971303473

Epoch: 6| Step: 1
Training loss: 2.6540671860413103
Validation loss: 3.0087171860579938

Epoch: 6| Step: 2
Training loss: 3.4160519178675264
Validation loss: 3.0079138843254802

Epoch: 6| Step: 3
Training loss: 3.5534142529957795
Validation loss: 3.008245543134452

Epoch: 6| Step: 4
Training loss: 3.5377177195054488
Validation loss: 3.007217126270444

Epoch: 6| Step: 5
Training loss: 2.671706344903196
Validation loss: 3.0085186179940826

Epoch: 6| Step: 6
Training loss: 3.442215199820104
Validation loss: 3.0088136116827857

Epoch: 6| Step: 7
Training loss: 3.141360675943198
Validation loss: 3.0124347892630046

Epoch: 6| Step: 8
Training loss: 3.055052284255327
Validation loss: 3.0231316982495966

Epoch: 6| Step: 9
Training loss: 3.854491568952636
Validation loss: 3.051488744858841

Epoch: 6| Step: 10
Training loss: 2.9962344379044783
Validation loss: 3.0529411264327857

Epoch: 6| Step: 11
Training loss: 3.527016862189206
Validation loss: 3.003038325658577

Epoch: 6| Step: 12
Training loss: 3.682195824972488
Validation loss: 3.000094578048584

Epoch: 6| Step: 13
Training loss: 2.861257464997839
Validation loss: 2.9998979807498967

Epoch: 31| Step: 0
Training loss: 2.437897087422335
Validation loss: 3.0051868064235756

Epoch: 6| Step: 1
Training loss: 3.7772178905075897
Validation loss: 3.0265907886620163

Epoch: 6| Step: 2
Training loss: 4.0018396915353875
Validation loss: 3.034680182198155

Epoch: 6| Step: 3
Training loss: 2.9319486716696908
Validation loss: 3.006567090883545

Epoch: 6| Step: 4
Training loss: 3.9412695385575347
Validation loss: 3.003931521829694

Epoch: 6| Step: 5
Training loss: 3.4058850294097023
Validation loss: 3.0045653287087504

Epoch: 6| Step: 6
Training loss: 2.992061761749013
Validation loss: 3.0124854091773794

Epoch: 6| Step: 7
Training loss: 3.3948104971805977
Validation loss: 3.021284470412585

Epoch: 6| Step: 8
Training loss: 3.462631052339603
Validation loss: 3.0294387830795553

Epoch: 6| Step: 9
Training loss: 3.239440195206621
Validation loss: 3.0232467538201937

Epoch: 6| Step: 10
Training loss: 3.780998410769141
Validation loss: 3.000580357231406

Epoch: 6| Step: 11
Training loss: 2.987766755137601
Validation loss: 2.9911820785108802

Epoch: 6| Step: 12
Training loss: 2.6073966378694386
Validation loss: 2.9893293206724385

Epoch: 6| Step: 13
Training loss: 1.96422322904607
Validation loss: 2.988391010891396

Epoch: 32| Step: 0
Training loss: 3.2764588753936765
Validation loss: 2.984627484782332

Epoch: 6| Step: 1
Training loss: 3.2816500465304137
Validation loss: 2.9905035103390483

Epoch: 6| Step: 2
Training loss: 2.5381349718113566
Validation loss: 3.018583317067771

Epoch: 6| Step: 3
Training loss: 3.415573239785007
Validation loss: 3.038206200049062

Epoch: 6| Step: 4
Training loss: 3.502145926789644
Validation loss: 3.028091720394286

Epoch: 6| Step: 5
Training loss: 3.6979844351276396
Validation loss: 2.983046381267892

Epoch: 6| Step: 6
Training loss: 3.823079922522434
Validation loss: 2.980272502768689

Epoch: 6| Step: 7
Training loss: 2.7029552957702827
Validation loss: 2.9785461094999346

Epoch: 6| Step: 8
Training loss: 3.2106137448930983
Validation loss: 2.979643218166255

Epoch: 6| Step: 9
Training loss: 2.129614699890338
Validation loss: 2.981713586925744

Epoch: 6| Step: 10
Training loss: 3.6542013574836236
Validation loss: 3.0018313639248246

Epoch: 6| Step: 11
Training loss: 3.2411997565903867
Validation loss: 3.0036510789761612

Epoch: 6| Step: 12
Training loss: 3.478770037369586
Validation loss: 2.999609982525146

Epoch: 6| Step: 13
Training loss: 3.60287498010317
Validation loss: 2.977449506676232

Epoch: 33| Step: 0
Training loss: 2.628995488594976
Validation loss: 2.9741464173980265

Epoch: 6| Step: 1
Training loss: 3.73964864661402
Validation loss: 2.9733859054135086

Epoch: 6| Step: 2
Training loss: 2.8260038229666065
Validation loss: 2.9703652927504844

Epoch: 6| Step: 3
Training loss: 3.5012177664904924
Validation loss: 2.9695360543091143

Epoch: 6| Step: 4
Training loss: 2.7611520231590143
Validation loss: 2.967013933371329

Epoch: 6| Step: 5
Training loss: 2.8502257675962324
Validation loss: 2.966849509238132

Epoch: 6| Step: 6
Training loss: 3.5441035395409677
Validation loss: 2.9672048782433897

Epoch: 6| Step: 7
Training loss: 2.857000647139217
Validation loss: 2.976010882828995

Epoch: 6| Step: 8
Training loss: 4.140642965025886
Validation loss: 2.9789633090258834

Epoch: 6| Step: 9
Training loss: 3.9796526280924573
Validation loss: 2.965109568338035

Epoch: 6| Step: 10
Training loss: 2.2856761895138487
Validation loss: 2.9644737641311942

Epoch: 6| Step: 11
Training loss: 2.8957395103862016
Validation loss: 2.965580529106083

Epoch: 6| Step: 12
Training loss: 3.3105143227566254
Validation loss: 2.9642658713760337

Epoch: 6| Step: 13
Training loss: 3.874245600944838
Validation loss: 2.9651053767429865

Epoch: 34| Step: 0
Training loss: 2.8200434928948965
Validation loss: 2.964384968988189

Epoch: 6| Step: 1
Training loss: 3.2407511643337967
Validation loss: 2.9631184408504416

Epoch: 6| Step: 2
Training loss: 2.876417888464677
Validation loss: 2.9639478962617676

Epoch: 6| Step: 3
Training loss: 2.4068394719198265
Validation loss: 2.9618871667396514

Epoch: 6| Step: 4
Training loss: 3.2711835216141694
Validation loss: 2.96184836246272

Epoch: 6| Step: 5
Training loss: 3.34260610818601
Validation loss: 2.960713448325494

Epoch: 6| Step: 6
Training loss: 3.5082371376120944
Validation loss: 2.961396285295345

Epoch: 6| Step: 7
Training loss: 2.5553555329683237
Validation loss: 2.960477558565172

Epoch: 6| Step: 8
Training loss: 3.6920016984202073
Validation loss: 2.958629755065845

Epoch: 6| Step: 9
Training loss: 3.940581553958557
Validation loss: 2.9581290184178766

Epoch: 6| Step: 10
Training loss: 2.734493231260872
Validation loss: 2.959615446612459

Epoch: 6| Step: 11
Training loss: 3.456842001352456
Validation loss: 2.956230366466977

Epoch: 6| Step: 12
Training loss: 3.653885427256188
Validation loss: 2.956242822890172

Epoch: 6| Step: 13
Training loss: 3.7514831153258834
Validation loss: 2.9553285533348514

Epoch: 35| Step: 0
Training loss: 3.084517449178576
Validation loss: 2.9546641540290466

Epoch: 6| Step: 1
Training loss: 3.4713356072897215
Validation loss: 2.9808803912689936

Epoch: 6| Step: 2
Training loss: 2.9849838514546145
Validation loss: 3.0058344537110906

Epoch: 6| Step: 3
Training loss: 2.717433128200931
Validation loss: 2.9553083517680565

Epoch: 6| Step: 4
Training loss: 3.4504768263211814
Validation loss: 2.952245041754828

Epoch: 6| Step: 5
Training loss: 2.5801103750172643
Validation loss: 2.955880534951029

Epoch: 6| Step: 6
Training loss: 3.483964425432008
Validation loss: 2.9657863329327747

Epoch: 6| Step: 7
Training loss: 3.2897684603672563
Validation loss: 2.9764352765405713

Epoch: 6| Step: 8
Training loss: 3.4755679647522797
Validation loss: 2.991635497227296

Epoch: 6| Step: 9
Training loss: 3.383651805477397
Validation loss: 2.9636082005492788

Epoch: 6| Step: 10
Training loss: 3.5757030302647523
Validation loss: 2.956031164097146

Epoch: 6| Step: 11
Training loss: 3.4834234880039125
Validation loss: 2.953516202252203

Epoch: 6| Step: 12
Training loss: 3.2482431504981735
Validation loss: 2.9547793456491545

Epoch: 6| Step: 13
Training loss: 3.0168751709540684
Validation loss: 2.955969552604484

Epoch: 36| Step: 0
Training loss: 3.981542201076135
Validation loss: 2.9607695970434342

Epoch: 6| Step: 1
Training loss: 3.9837532306295365
Validation loss: 2.956897479578914

Epoch: 6| Step: 2
Training loss: 3.497899378782488
Validation loss: 2.951472332856767

Epoch: 6| Step: 3
Training loss: 3.492059419403894
Validation loss: 2.9526999387349866

Epoch: 6| Step: 4
Training loss: 2.6146977210890854
Validation loss: 2.950649170094238

Epoch: 6| Step: 5
Training loss: 2.8562605108489247
Validation loss: 2.975159766482233

Epoch: 6| Step: 6
Training loss: 3.4584406334344147
Validation loss: 3.0410780778981223

Epoch: 6| Step: 7
Training loss: 3.424212489121301
Validation loss: 3.067150640574145

Epoch: 6| Step: 8
Training loss: 2.3486810310473847
Validation loss: 2.95720613234243

Epoch: 6| Step: 9
Training loss: 3.47134879422565
Validation loss: 2.9381970599838136

Epoch: 6| Step: 10
Training loss: 3.0636065294095807
Validation loss: 2.9402557708610417

Epoch: 6| Step: 11
Training loss: 2.926107187285588
Validation loss: 2.9415844588209517

Epoch: 6| Step: 12
Training loss: 3.2758844011379797
Validation loss: 2.941339664805662

Epoch: 6| Step: 13
Training loss: 2.1516235032641244
Validation loss: 2.94266725613674

Epoch: 37| Step: 0
Training loss: 4.178567725658523
Validation loss: 2.941494147364996

Epoch: 6| Step: 1
Training loss: 3.4498489512672954
Validation loss: 2.9392727276867823

Epoch: 6| Step: 2
Training loss: 2.449906686056786
Validation loss: 2.940039112237455

Epoch: 6| Step: 3
Training loss: 2.6827405436691034
Validation loss: 2.936841117153773

Epoch: 6| Step: 4
Training loss: 3.2882603915425994
Validation loss: 2.935744462458434

Epoch: 6| Step: 5
Training loss: 3.4564609897773386
Validation loss: 2.935347080339669

Epoch: 6| Step: 6
Training loss: 3.162909252841666
Validation loss: 2.933370553290459

Epoch: 6| Step: 7
Training loss: 3.806603922307348
Validation loss: 2.932275073972534

Epoch: 6| Step: 8
Training loss: 2.9370400900671445
Validation loss: 2.9324540046843426

Epoch: 6| Step: 9
Training loss: 3.2463132047320653
Validation loss: 2.9294818791249484

Epoch: 6| Step: 10
Training loss: 3.058591879190041
Validation loss: 2.9317279048530493

Epoch: 6| Step: 11
Training loss: 3.021855060941603
Validation loss: 2.9318137218244247

Epoch: 6| Step: 12
Training loss: 3.287606757573638
Validation loss: 2.938088004965234

Epoch: 6| Step: 13
Training loss: 2.38429099318679
Validation loss: 2.939537661171543

Epoch: 38| Step: 0
Training loss: 3.5866283673743364
Validation loss: 2.938443758622245

Epoch: 6| Step: 1
Training loss: 3.1588447405031626
Validation loss: 2.9440920514677402

Epoch: 6| Step: 2
Training loss: 3.098762228181078
Validation loss: 2.9390413136943154

Epoch: 6| Step: 3
Training loss: 4.010542328422231
Validation loss: 2.936659029928273

Epoch: 6| Step: 4
Training loss: 2.7651994453225446
Validation loss: 2.932805525674147

Epoch: 6| Step: 5
Training loss: 2.6269923324211684
Validation loss: 2.922098248323203

Epoch: 6| Step: 6
Training loss: 2.4154506013399297
Validation loss: 2.9243007292779564

Epoch: 6| Step: 7
Training loss: 3.2087543425996863
Validation loss: 2.9203383304012767

Epoch: 6| Step: 8
Training loss: 3.0929866581162546
Validation loss: 2.9216486038291625

Epoch: 6| Step: 9
Training loss: 2.944177383531475
Validation loss: 2.921483269192958

Epoch: 6| Step: 10
Training loss: 3.530325034201091
Validation loss: 2.9208930414626084

Epoch: 6| Step: 11
Training loss: 3.876545874588052
Validation loss: 2.917625880102261

Epoch: 6| Step: 12
Training loss: 3.4964951268809523
Validation loss: 2.9210862376146562

Epoch: 6| Step: 13
Training loss: 2.3456399037197424
Validation loss: 2.9169003587849405

Epoch: 39| Step: 0
Training loss: 3.5648082817498508
Validation loss: 2.9175048192235535

Epoch: 6| Step: 1
Training loss: 2.912595650735374
Validation loss: 2.925971142673444

Epoch: 6| Step: 2
Training loss: 3.270695304792917
Validation loss: 2.954318442882343

Epoch: 6| Step: 3
Training loss: 2.9171245942078516
Validation loss: 2.9386473723061544

Epoch: 6| Step: 4
Training loss: 3.4931708877833794
Validation loss: 2.9180169277609784

Epoch: 6| Step: 5
Training loss: 3.159991775212268
Validation loss: 2.9171389752569286

Epoch: 6| Step: 6
Training loss: 3.818031425734407
Validation loss: 2.9416487786812

Epoch: 6| Step: 7
Training loss: 3.2648691279074695
Validation loss: 2.9906727819279237

Epoch: 6| Step: 8
Training loss: 2.4460239533244184
Validation loss: 2.9971703819944473

Epoch: 6| Step: 9
Training loss: 4.129333531728791
Validation loss: 2.9643274842663763

Epoch: 6| Step: 10
Training loss: 3.1680969889657957
Validation loss: 2.9220307414871827

Epoch: 6| Step: 11
Training loss: 3.326865087591494
Validation loss: 2.9131526369489027

Epoch: 6| Step: 12
Training loss: 2.2070098605849586
Validation loss: 2.9112527610972023

Epoch: 6| Step: 13
Training loss: 3.05518338990632
Validation loss: 2.9126230993640516

Epoch: 40| Step: 0
Training loss: 3.287312311536819
Validation loss: 2.960858920544378

Epoch: 6| Step: 1
Training loss: 3.7646726298266127
Validation loss: 2.9679520662122765

Epoch: 6| Step: 2
Training loss: 2.7470611995216334
Validation loss: 2.9120828969526436

Epoch: 6| Step: 3
Training loss: 3.521505363177541
Validation loss: 2.9093297544122576

Epoch: 6| Step: 4
Training loss: 3.2768430634287795
Validation loss: 2.9088969830885776

Epoch: 6| Step: 5
Training loss: 3.127573403305893
Validation loss: 2.9089870366166886

Epoch: 6| Step: 6
Training loss: 3.374320491626781
Validation loss: 2.909703235833652

Epoch: 6| Step: 7
Training loss: 3.24833607260711
Validation loss: 2.9094024261090916

Epoch: 6| Step: 8
Training loss: 3.339477947346775
Validation loss: 2.911176181608079

Epoch: 6| Step: 9
Training loss: 2.5738921587804993
Validation loss: 2.9117730506044435

Epoch: 6| Step: 10
Training loss: 3.503925846517107
Validation loss: 2.915516306240762

Epoch: 6| Step: 11
Training loss: 2.2005711897706877
Validation loss: 2.916612696404673

Epoch: 6| Step: 12
Training loss: 2.9234629513210155
Validation loss: 2.9128622026386655

Epoch: 6| Step: 13
Training loss: 4.146522094152511
Validation loss: 2.91136141065798

Epoch: 41| Step: 0
Training loss: 3.5598734492407695
Validation loss: 2.9104646186672736

Epoch: 6| Step: 1
Training loss: 3.212617977365758
Validation loss: 2.909589045675272

Epoch: 6| Step: 2
Training loss: 3.452715128743451
Validation loss: 2.9047198969909225

Epoch: 6| Step: 3
Training loss: 3.2790938786559716
Validation loss: 2.903448497869224

Epoch: 6| Step: 4
Training loss: 2.970186227425132
Validation loss: 2.9051698381402775

Epoch: 6| Step: 5
Training loss: 3.7981650590188623
Validation loss: 2.9014140902404963

Epoch: 6| Step: 6
Training loss: 2.2889648000027996
Validation loss: 2.902479128488249

Epoch: 6| Step: 7
Training loss: 3.2584886466731855
Validation loss: 2.902437876469611

Epoch: 6| Step: 8
Training loss: 2.920181681324112
Validation loss: 2.904239568270388

Epoch: 6| Step: 9
Training loss: 3.527284809688907
Validation loss: 2.903321309410251

Epoch: 6| Step: 10
Training loss: 3.16711549757049
Validation loss: 2.900807352416642

Epoch: 6| Step: 11
Training loss: 3.1044353565103373
Validation loss: 2.898315421809674

Epoch: 6| Step: 12
Training loss: 3.2470275784311986
Validation loss: 2.89681553172344

Epoch: 6| Step: 13
Training loss: 2.3411557908459915
Validation loss: 2.8965405774785635

Epoch: 42| Step: 0
Training loss: 2.428456868747456
Validation loss: 2.8945626278502647

Epoch: 6| Step: 1
Training loss: 3.0964670291711713
Validation loss: 2.8974233762075334

Epoch: 6| Step: 2
Training loss: 3.748843078170071
Validation loss: 2.894762737340671

Epoch: 6| Step: 3
Training loss: 3.1493223097099814
Validation loss: 2.8925515381830187

Epoch: 6| Step: 4
Training loss: 3.3518484567149254
Validation loss: 2.8932574071694996

Epoch: 6| Step: 5
Training loss: 3.2902429777356965
Validation loss: 2.891312702458209

Epoch: 6| Step: 6
Training loss: 2.3588393658082194
Validation loss: 2.8937106269605284

Epoch: 6| Step: 7
Training loss: 3.2797644749259556
Validation loss: 2.8923000742603504

Epoch: 6| Step: 8
Training loss: 3.450042591661347
Validation loss: 2.89139388040318

Epoch: 6| Step: 9
Training loss: 3.732725154067155
Validation loss: 2.894326686916799

Epoch: 6| Step: 10
Training loss: 3.148946640458998
Validation loss: 2.893059807655608

Epoch: 6| Step: 11
Training loss: 3.2207182264465546
Validation loss: 2.8902365359463857

Epoch: 6| Step: 12
Training loss: 2.867369102942585
Validation loss: 2.8858413442999447

Epoch: 6| Step: 13
Training loss: 3.2333139346874655
Validation loss: 2.888493196527707

Epoch: 43| Step: 0
Training loss: 2.670607595282114
Validation loss: 2.891442214578076

Epoch: 6| Step: 1
Training loss: 4.009457375207213
Validation loss: 2.8820797039746004

Epoch: 6| Step: 2
Training loss: 3.33839801036886
Validation loss: 2.8821090941466454

Epoch: 6| Step: 3
Training loss: 3.092219735276805
Validation loss: 2.8804087559201026

Epoch: 6| Step: 4
Training loss: 3.0102592523903255
Validation loss: 2.878988995032688

Epoch: 6| Step: 5
Training loss: 3.353000999070544
Validation loss: 2.8807450204118212

Epoch: 6| Step: 6
Training loss: 2.903237370840578
Validation loss: 2.8797145689444537

Epoch: 6| Step: 7
Training loss: 3.0155411940872745
Validation loss: 2.8773188733784267

Epoch: 6| Step: 8
Training loss: 2.5503064775483453
Validation loss: 2.8788737611363184

Epoch: 6| Step: 9
Training loss: 3.050645265955432
Validation loss: 2.878156247417558

Epoch: 6| Step: 10
Training loss: 3.760778323435517
Validation loss: 2.8769179336323294

Epoch: 6| Step: 11
Training loss: 3.362032101207295
Validation loss: 2.875732852791204

Epoch: 6| Step: 12
Training loss: 3.2572837784763844
Validation loss: 2.882123327026519

Epoch: 6| Step: 13
Training loss: 2.516518949337654
Validation loss: 2.897448619445826

Epoch: 44| Step: 0
Training loss: 3.3742734338913674
Validation loss: 2.9388653390824557

Epoch: 6| Step: 1
Training loss: 3.176069971452457
Validation loss: 2.8977748735988604

Epoch: 6| Step: 2
Training loss: 3.15434524924207
Validation loss: 2.8751923771822536

Epoch: 6| Step: 3
Training loss: 3.5443662938424914
Validation loss: 2.8726323755077217

Epoch: 6| Step: 4
Training loss: 2.7163408501393453
Validation loss: 2.8706875934938387

Epoch: 6| Step: 5
Training loss: 3.1165287402091777
Validation loss: 2.873516901349109

Epoch: 6| Step: 6
Training loss: 2.8529447366982588
Validation loss: 2.8753347607679327

Epoch: 6| Step: 7
Training loss: 3.786670928961634
Validation loss: 2.8744229829558248

Epoch: 6| Step: 8
Training loss: 3.413367159149332
Validation loss: 2.8742221084862893

Epoch: 6| Step: 9
Training loss: 3.250233421746414
Validation loss: 2.87278753247697

Epoch: 6| Step: 10
Training loss: 2.9556933340625804
Validation loss: 2.8738111755065465

Epoch: 6| Step: 11
Training loss: 3.0650963190324525
Validation loss: 2.870368815660653

Epoch: 6| Step: 12
Training loss: 3.165618287933253
Validation loss: 2.8691227866687923

Epoch: 6| Step: 13
Training loss: 2.538616528592285
Validation loss: 2.8683653513891327

Epoch: 45| Step: 0
Training loss: 2.466195728692859
Validation loss: 2.8670584686582794

Epoch: 6| Step: 1
Training loss: 3.9847733840739696
Validation loss: 2.868363866847355

Epoch: 6| Step: 2
Training loss: 3.315891616844653
Validation loss: 2.8688460477990914

Epoch: 6| Step: 3
Training loss: 3.0860836718743663
Validation loss: 2.865542661760776

Epoch: 6| Step: 4
Training loss: 3.1102235489257026
Validation loss: 2.8675702724076064

Epoch: 6| Step: 5
Training loss: 3.392383312897582
Validation loss: 2.862868293469364

Epoch: 6| Step: 6
Training loss: 3.0441801233322274
Validation loss: 2.8653210802853786

Epoch: 6| Step: 7
Training loss: 2.3755089064013397
Validation loss: 2.8659769293257815

Epoch: 6| Step: 8
Training loss: 3.695147456219517
Validation loss: 2.8626933937642907

Epoch: 6| Step: 9
Training loss: 3.081695190209656
Validation loss: 2.8622207632936667

Epoch: 6| Step: 10
Training loss: 3.1150513024185043
Validation loss: 2.863115950969677

Epoch: 6| Step: 11
Training loss: 3.50714417613773
Validation loss: 2.861510440245923

Epoch: 6| Step: 12
Training loss: 3.050156298525466
Validation loss: 2.8620867015845253

Epoch: 6| Step: 13
Training loss: 2.3938202292396547
Validation loss: 2.8617084785010958

Epoch: 46| Step: 0
Training loss: 3.5738897453597116
Validation loss: 2.8617399492819238

Epoch: 6| Step: 1
Training loss: 3.617611030187583
Validation loss: 2.87589289463798

Epoch: 6| Step: 2
Training loss: 3.0798485282708765
Validation loss: 2.8869871129985696

Epoch: 6| Step: 3
Training loss: 2.595960663131544
Validation loss: 2.9019673779063964

Epoch: 6| Step: 4
Training loss: 2.5152501365996
Validation loss: 2.8914736809205914

Epoch: 6| Step: 5
Training loss: 3.1869875926125455
Validation loss: 2.8755090270902675

Epoch: 6| Step: 6
Training loss: 3.306123750580185
Validation loss: 2.863485699595673

Epoch: 6| Step: 7
Training loss: 3.2769610757852945
Validation loss: 2.8754904240888393

Epoch: 6| Step: 8
Training loss: 3.6800565433304655
Validation loss: 2.8548740264620416

Epoch: 6| Step: 9
Training loss: 3.161298736281057
Validation loss: 2.8544985838139327

Epoch: 6| Step: 10
Training loss: 2.7232679339446695
Validation loss: 2.855282008618491

Epoch: 6| Step: 11
Training loss: 2.9261505342091576
Validation loss: 2.8553541381076766

Epoch: 6| Step: 12
Training loss: 3.437316057312223
Validation loss: 2.851414582330647

Epoch: 6| Step: 13
Training loss: 2.839676507068177
Validation loss: 2.8546212031050286

Epoch: 47| Step: 0
Training loss: 3.5556074691664827
Validation loss: 2.8545402618876636

Epoch: 6| Step: 1
Training loss: 3.060900835067863
Validation loss: 2.851583359221031

Epoch: 6| Step: 2
Training loss: 3.173482102531907
Validation loss: 2.8513278093123264

Epoch: 6| Step: 3
Training loss: 3.274556480835107
Validation loss: 2.850207022959533

Epoch: 6| Step: 4
Training loss: 2.680471767066941
Validation loss: 2.8506298842184585

Epoch: 6| Step: 5
Training loss: 3.608154090382145
Validation loss: 2.8509066027575374

Epoch: 6| Step: 6
Training loss: 2.7090326042255075
Validation loss: 2.850745955840055

Epoch: 6| Step: 7
Training loss: 3.3801195380838
Validation loss: 2.854727993827409

Epoch: 6| Step: 8
Training loss: 3.060456353110502
Validation loss: 2.8542480588882144

Epoch: 6| Step: 9
Training loss: 2.829637997392787
Validation loss: 2.8575017997510592

Epoch: 6| Step: 10
Training loss: 3.601113512762312
Validation loss: 2.864486143788449

Epoch: 6| Step: 11
Training loss: 2.5902528281511668
Validation loss: 2.8749094766469594

Epoch: 6| Step: 12
Training loss: 3.2087379960005364
Validation loss: 2.8583817393377915

Epoch: 6| Step: 13
Training loss: 3.2057973739263903
Validation loss: 2.8432737670870156

Epoch: 48| Step: 0
Training loss: 3.8058114085698067
Validation loss: 2.8473131533619873

Epoch: 6| Step: 1
Training loss: 3.243988639858689
Validation loss: 2.8470819338827393

Epoch: 6| Step: 2
Training loss: 3.1700163408213244
Validation loss: 2.850836856185191

Epoch: 6| Step: 3
Training loss: 3.3437344559637974
Validation loss: 2.8605583849207723

Epoch: 6| Step: 4
Training loss: 2.8168968588160994
Validation loss: 2.8658058020631207

Epoch: 6| Step: 5
Training loss: 3.5696951501445917
Validation loss: 2.8830494285731993

Epoch: 6| Step: 6
Training loss: 3.1730720253219684
Validation loss: 2.8608128056014737

Epoch: 6| Step: 7
Training loss: 2.746572091995905
Validation loss: 2.8524435788410583

Epoch: 6| Step: 8
Training loss: 2.4292668901535275
Validation loss: 2.848646746465342

Epoch: 6| Step: 9
Training loss: 3.5386633911098486
Validation loss: 2.845264897203925

Epoch: 6| Step: 10
Training loss: 3.62690185116221
Validation loss: 2.842703113510458

Epoch: 6| Step: 11
Training loss: 2.9610653650862684
Validation loss: 2.8423960429696398

Epoch: 6| Step: 12
Training loss: 2.83224810592153
Validation loss: 2.8407689385172463

Epoch: 6| Step: 13
Training loss: 2.2492828285812436
Validation loss: 2.8407103222383108

Epoch: 49| Step: 0
Training loss: 2.7026451434630436
Validation loss: 2.837920028355447

Epoch: 6| Step: 1
Training loss: 3.036916568437853
Validation loss: 2.838547202393996

Epoch: 6| Step: 2
Training loss: 3.139187763880098
Validation loss: 2.8386397396838454

Epoch: 6| Step: 3
Training loss: 3.1445239712648676
Validation loss: 2.837440119986953

Epoch: 6| Step: 4
Training loss: 3.5778713886053644
Validation loss: 2.8374504876850555

Epoch: 6| Step: 5
Training loss: 2.8025524970930342
Validation loss: 2.8384402599135403

Epoch: 6| Step: 6
Training loss: 3.574933090117341
Validation loss: 2.832255917450516

Epoch: 6| Step: 7
Training loss: 3.952746105506546
Validation loss: 2.8350303666014414

Epoch: 6| Step: 8
Training loss: 2.9947871376777346
Validation loss: 2.832405176876517

Epoch: 6| Step: 9
Training loss: 2.6515076433215827
Validation loss: 2.8350167283273966

Epoch: 6| Step: 10
Training loss: 3.378345667912669
Validation loss: 2.830118458815706

Epoch: 6| Step: 11
Training loss: 2.837127519938448
Validation loss: 2.834417021587866

Epoch: 6| Step: 12
Training loss: 2.9188038398302334
Validation loss: 2.840355534010735

Epoch: 6| Step: 13
Training loss: 2.9039014946070156
Validation loss: 2.8329611291897083

Epoch: 50| Step: 0
Training loss: 3.320639345126235
Validation loss: 2.8290170266586823

Epoch: 6| Step: 1
Training loss: 3.378210165836422
Validation loss: 2.828715885709893

Epoch: 6| Step: 2
Training loss: 1.968733711780804
Validation loss: 2.831884767268078

Epoch: 6| Step: 3
Training loss: 2.1086832678365792
Validation loss: 2.8404420465395512

Epoch: 6| Step: 4
Training loss: 2.554700378945461
Validation loss: 2.8714805915558026

Epoch: 6| Step: 5
Training loss: 3.9376772886054563
Validation loss: 2.923674830985527

Epoch: 6| Step: 6
Training loss: 2.877531347029465
Validation loss: 2.848849194802025

Epoch: 6| Step: 7
Training loss: 3.62043474737631
Validation loss: 2.8353901122976177

Epoch: 6| Step: 8
Training loss: 3.4531992908616247
Validation loss: 2.8328182710198377

Epoch: 6| Step: 9
Training loss: 3.1148079033121983
Validation loss: 2.8239230545491205

Epoch: 6| Step: 10
Training loss: 2.8747488824391185
Validation loss: 2.8267036074575147

Epoch: 6| Step: 11
Training loss: 3.6923159169753488
Validation loss: 2.82263682659625

Epoch: 6| Step: 12
Training loss: 3.107584068529918
Validation loss: 2.8233667798919684

Epoch: 6| Step: 13
Training loss: 3.315536259102712
Validation loss: 2.8268324548013206

Epoch: 51| Step: 0
Training loss: 2.81008179867971
Validation loss: 2.822505235441069

Epoch: 6| Step: 1
Training loss: 3.5894370030211182
Validation loss: 2.821671678645619

Epoch: 6| Step: 2
Training loss: 3.2644012932738264
Validation loss: 2.819774644686973

Epoch: 6| Step: 3
Training loss: 2.4791560987573202
Validation loss: 2.8188002141127804

Epoch: 6| Step: 4
Training loss: 3.0954135314073823
Validation loss: 2.823213611071289

Epoch: 6| Step: 5
Training loss: 3.283382921441463
Validation loss: 2.8206093301610906

Epoch: 6| Step: 6
Training loss: 3.217100442946997
Validation loss: 2.8295157061315184

Epoch: 6| Step: 7
Training loss: 3.087921509175091
Validation loss: 2.8253471661762126

Epoch: 6| Step: 8
Training loss: 2.660881761380403
Validation loss: 2.831265354148816

Epoch: 6| Step: 9
Training loss: 3.3806379345988287
Validation loss: 2.839668236567645

Epoch: 6| Step: 10
Training loss: 3.7075063804936828
Validation loss: 2.8178585546896606

Epoch: 6| Step: 11
Training loss: 2.7365271246116585
Validation loss: 2.8193976414579716

Epoch: 6| Step: 12
Training loss: 3.2194435335395175
Validation loss: 2.818809457136437

Epoch: 6| Step: 13
Training loss: 3.021248905053846
Validation loss: 2.8526390328259907

Epoch: 52| Step: 0
Training loss: 2.8574125298890247
Validation loss: 2.851111230276532

Epoch: 6| Step: 1
Training loss: 2.846346162655051
Validation loss: 2.8611823662253424

Epoch: 6| Step: 2
Training loss: 3.4526123771084554
Validation loss: 2.8367735235185965

Epoch: 6| Step: 3
Training loss: 2.832614770165055
Validation loss: 2.8184119597356005

Epoch: 6| Step: 4
Training loss: 3.4938222314673104
Validation loss: 2.8175575422682817

Epoch: 6| Step: 5
Training loss: 2.4257766305876407
Validation loss: 2.81865806981744

Epoch: 6| Step: 6
Training loss: 3.1829867855064973
Validation loss: 2.8173991712984336

Epoch: 6| Step: 7
Training loss: 3.1713417243849182
Validation loss: 2.8169509224251517

Epoch: 6| Step: 8
Training loss: 3.6221086217726715
Validation loss: 2.8185757429387506

Epoch: 6| Step: 9
Training loss: 2.8945571136348716
Validation loss: 2.814957518314856

Epoch: 6| Step: 10
Training loss: 3.52876585959189
Validation loss: 2.8138917202777987

Epoch: 6| Step: 11
Training loss: 3.101413675192003
Validation loss: 2.817950033734464

Epoch: 6| Step: 12
Training loss: 2.927396239438006
Validation loss: 2.82548357082381

Epoch: 6| Step: 13
Training loss: 3.550718132775798
Validation loss: 2.8719778329741765

Epoch: 53| Step: 0
Training loss: 3.0933107006406972
Validation loss: 2.869179449167287

Epoch: 6| Step: 1
Training loss: 2.748478295054376
Validation loss: 2.820881727691754

Epoch: 6| Step: 2
Training loss: 3.098164039351998
Validation loss: 2.811757559183183

Epoch: 6| Step: 3
Training loss: 3.222208775751697
Validation loss: 2.808844832080885

Epoch: 6| Step: 4
Training loss: 3.4425940482618524
Validation loss: 2.805830255475164

Epoch: 6| Step: 5
Training loss: 3.50106931427868
Validation loss: 2.804544121212074

Epoch: 6| Step: 6
Training loss: 2.6742997794951693
Validation loss: 2.8049913759851908

Epoch: 6| Step: 7
Training loss: 2.9991571513967745
Validation loss: 2.8012813254914213

Epoch: 6| Step: 8
Training loss: 3.735551848184366
Validation loss: 2.803387279767172

Epoch: 6| Step: 9
Training loss: 3.1024897267973044
Validation loss: 2.8042728408786806

Epoch: 6| Step: 10
Training loss: 3.12362655975817
Validation loss: 2.802937456859721

Epoch: 6| Step: 11
Training loss: 3.2500306641525905
Validation loss: 2.8034280186253624

Epoch: 6| Step: 12
Training loss: 2.4246883664017154
Validation loss: 2.8016450204213297

Epoch: 6| Step: 13
Training loss: 3.0315399031292887
Validation loss: 2.7998252382689564

Epoch: 54| Step: 0
Training loss: 3.0797765338633183
Validation loss: 2.7995567533478356

Epoch: 6| Step: 1
Training loss: 2.7446133135203534
Validation loss: 2.800397480528703

Epoch: 6| Step: 2
Training loss: 3.5540420784678424
Validation loss: 2.797660784624017

Epoch: 6| Step: 3
Training loss: 3.0373126878793095
Validation loss: 2.795482883692176

Epoch: 6| Step: 4
Training loss: 2.997501604526781
Validation loss: 2.7970632669735283

Epoch: 6| Step: 5
Training loss: 3.549179739950775
Validation loss: 2.7944769350615988

Epoch: 6| Step: 6
Training loss: 3.4017320821086523
Validation loss: 2.7951442477865043

Epoch: 6| Step: 7
Training loss: 3.651081181129602
Validation loss: 2.794258124910132

Epoch: 6| Step: 8
Training loss: 3.0591056853260463
Validation loss: 2.7972541543376686

Epoch: 6| Step: 9
Training loss: 2.9076045991511434
Validation loss: 2.795832663568192

Epoch: 6| Step: 10
Training loss: 2.8540297612307275
Validation loss: 2.799945863406959

Epoch: 6| Step: 11
Training loss: 2.992763214900475
Validation loss: 2.8042565746333077

Epoch: 6| Step: 12
Training loss: 2.9067464424991467
Validation loss: 2.8048382968578314

Epoch: 6| Step: 13
Training loss: 2.1612505219228897
Validation loss: 2.8012186596353423

Epoch: 55| Step: 0
Training loss: 3.478871194014791
Validation loss: 2.8002788175252196

Epoch: 6| Step: 1
Training loss: 3.292108498065808
Validation loss: 2.828042782821413

Epoch: 6| Step: 2
Training loss: 2.7489105147211204
Validation loss: 2.7905850899585416

Epoch: 6| Step: 3
Training loss: 2.607368657286967
Validation loss: 2.7905211577173166

Epoch: 6| Step: 4
Training loss: 2.9409237652094005
Validation loss: 2.7912370249829

Epoch: 6| Step: 5
Training loss: 3.1766267709004725
Validation loss: 2.7980450769627367

Epoch: 6| Step: 6
Training loss: 3.3418028679263916
Validation loss: 2.8084495500912166

Epoch: 6| Step: 7
Training loss: 3.079248833151495
Validation loss: 2.8119743494014435

Epoch: 6| Step: 8
Training loss: 3.088421172203374
Validation loss: 2.805373781386346

Epoch: 6| Step: 9
Training loss: 3.5003591080770624
Validation loss: 2.7971698208937243

Epoch: 6| Step: 10
Training loss: 3.5543521261778825
Validation loss: 2.7944276649831763

Epoch: 6| Step: 11
Training loss: 2.247131426401663
Validation loss: 2.7925104975911825

Epoch: 6| Step: 12
Training loss: 3.1228653292585413
Validation loss: 2.791661722738718

Epoch: 6| Step: 13
Training loss: 3.3540524923348904
Validation loss: 2.7876999881018403

Epoch: 56| Step: 0
Training loss: 3.122624371680617
Validation loss: 2.7894767953789117

Epoch: 6| Step: 1
Training loss: 3.129021003133299
Validation loss: 2.787210785216572

Epoch: 6| Step: 2
Training loss: 3.5065320233022734
Validation loss: 2.7844659882802825

Epoch: 6| Step: 3
Training loss: 3.123289479368833
Validation loss: 2.782579617364533

Epoch: 6| Step: 4
Training loss: 3.359384935940975
Validation loss: 2.7837746842115716

Epoch: 6| Step: 5
Training loss: 3.2864643626855514
Validation loss: 2.782808230266345

Epoch: 6| Step: 6
Training loss: 2.5352243376112895
Validation loss: 2.780689033143837

Epoch: 6| Step: 7
Training loss: 2.7945029999817033
Validation loss: 2.7797073421929723

Epoch: 6| Step: 8
Training loss: 2.798233554720534
Validation loss: 2.781904775140876

Epoch: 6| Step: 9
Training loss: 2.651483814913048
Validation loss: 2.782319416709032

Epoch: 6| Step: 10
Training loss: 2.632052439204928
Validation loss: 2.7858487489512997

Epoch: 6| Step: 11
Training loss: 3.694694870673075
Validation loss: 2.7955971752169035

Epoch: 6| Step: 12
Training loss: 3.5032978869337854
Validation loss: 2.8127845784260037

Epoch: 6| Step: 13
Training loss: 2.807090728494843
Validation loss: 2.830928077135147

Epoch: 57| Step: 0
Training loss: 2.651143090207207
Validation loss: 2.7814116108973104

Epoch: 6| Step: 1
Training loss: 2.659875616879806
Validation loss: 2.776942541073455

Epoch: 6| Step: 2
Training loss: 3.5866125464580985
Validation loss: 2.774907437485894

Epoch: 6| Step: 3
Training loss: 2.6743797474440347
Validation loss: 2.775848046385765

Epoch: 6| Step: 4
Training loss: 3.1338035176610366
Validation loss: 2.775593682907847

Epoch: 6| Step: 5
Training loss: 2.58796709055664
Validation loss: 2.7751998965727602

Epoch: 6| Step: 6
Training loss: 2.824260283991792
Validation loss: 2.7755877550001453

Epoch: 6| Step: 7
Training loss: 3.396475951506231
Validation loss: 2.774543635216989

Epoch: 6| Step: 8
Training loss: 2.851776198649294
Validation loss: 2.776576648245639

Epoch: 6| Step: 9
Training loss: 3.313310919774755
Validation loss: 2.7746792296824996

Epoch: 6| Step: 10
Training loss: 3.7163642475159566
Validation loss: 2.773939236994042

Epoch: 6| Step: 11
Training loss: 3.175997605877798
Validation loss: 2.774385439612366

Epoch: 6| Step: 12
Training loss: 3.163361497625689
Validation loss: 2.77559492427551

Epoch: 6| Step: 13
Training loss: 3.4841828571251487
Validation loss: 2.7756508813019867

Epoch: 58| Step: 0
Training loss: 3.5912870508892443
Validation loss: 2.777074287985153

Epoch: 6| Step: 1
Training loss: 3.2831377684415535
Validation loss: 2.777440080180321

Epoch: 6| Step: 2
Training loss: 3.279296002549765
Validation loss: 2.7740823345328254

Epoch: 6| Step: 3
Training loss: 3.0301790213497655
Validation loss: 2.7743396309196493

Epoch: 6| Step: 4
Training loss: 2.622544002545636
Validation loss: 2.771665798881668

Epoch: 6| Step: 5
Training loss: 3.5358484085868076
Validation loss: 2.7712818300592605

Epoch: 6| Step: 6
Training loss: 2.161485039113226
Validation loss: 2.772537622969439

Epoch: 6| Step: 7
Training loss: 2.6326904268574745
Validation loss: 2.7667599465006956

Epoch: 6| Step: 8
Training loss: 2.4575256917547708
Validation loss: 2.769099871031251

Epoch: 6| Step: 9
Training loss: 3.573801685451849
Validation loss: 2.7659228700788323

Epoch: 6| Step: 10
Training loss: 3.424797169046495
Validation loss: 2.766024846661173

Epoch: 6| Step: 11
Training loss: 3.1941378423271174
Validation loss: 2.7660118422493154

Epoch: 6| Step: 12
Training loss: 3.0112225115049114
Validation loss: 2.766975302616882

Epoch: 6| Step: 13
Training loss: 3.188427509672446
Validation loss: 2.76390070318465

Epoch: 59| Step: 0
Training loss: 2.9171224692093767
Validation loss: 2.763930559750269

Epoch: 6| Step: 1
Training loss: 3.209711068005294
Validation loss: 2.764349255088021

Epoch: 6| Step: 2
Training loss: 3.311166458890499
Validation loss: 2.764288663143532

Epoch: 6| Step: 3
Training loss: 2.6043777583716192
Validation loss: 2.7637273721642477

Epoch: 6| Step: 4
Training loss: 3.592538115127323
Validation loss: 2.761318843349918

Epoch: 6| Step: 5
Training loss: 2.766227699600153
Validation loss: 2.761528110551328

Epoch: 6| Step: 6
Training loss: 3.586061030900923
Validation loss: 2.76129542406626

Epoch: 6| Step: 7
Training loss: 2.77937716745404
Validation loss: 2.759118875399166

Epoch: 6| Step: 8
Training loss: 2.9286892830664106
Validation loss: 2.7588353301174235

Epoch: 6| Step: 9
Training loss: 2.919917629073
Validation loss: 2.761133554016552

Epoch: 6| Step: 10
Training loss: 3.1442749677201953
Validation loss: 2.769357655787676

Epoch: 6| Step: 11
Training loss: 2.6408714766279133
Validation loss: 2.809097658553805

Epoch: 6| Step: 12
Training loss: 3.0094458962840873
Validation loss: 2.8401353074250983

Epoch: 6| Step: 13
Training loss: 3.905759490687654
Validation loss: 2.8562702187484272

Epoch: 60| Step: 0
Training loss: 2.712396674231811
Validation loss: 2.8923484730635325

Epoch: 6| Step: 1
Training loss: 3.477690575846708
Validation loss: 2.877024190788668

Epoch: 6| Step: 2
Training loss: 3.012423065596075
Validation loss: 2.84186159773516

Epoch: 6| Step: 3
Training loss: 3.306066635614154
Validation loss: 2.7996345326188683

Epoch: 6| Step: 4
Training loss: 3.3580739895346934
Validation loss: 2.7659870603849233

Epoch: 6| Step: 5
Training loss: 3.1932052715110344
Validation loss: 2.7542546975982085

Epoch: 6| Step: 6
Training loss: 2.982761126436029
Validation loss: 2.7541360533911816

Epoch: 6| Step: 7
Training loss: 3.25149589737996
Validation loss: 2.7574353349871106

Epoch: 6| Step: 8
Training loss: 2.7438247879019757
Validation loss: 2.7645521883189237

Epoch: 6| Step: 9
Training loss: 3.067927630648972
Validation loss: 2.7678087170434678

Epoch: 6| Step: 10
Training loss: 3.509550280112843
Validation loss: 2.7570986259102157

Epoch: 6| Step: 11
Training loss: 2.808804776006043
Validation loss: 2.752114606289322

Epoch: 6| Step: 12
Training loss: 2.469316634808978
Validation loss: 2.7529184064249943

Epoch: 6| Step: 13
Training loss: 3.644368485948828
Validation loss: 2.7571782937602314

Epoch: 61| Step: 0
Training loss: 3.130872929877473
Validation loss: 2.7631877145045594

Epoch: 6| Step: 1
Training loss: 3.218358284530705
Validation loss: 2.768331643870858

Epoch: 6| Step: 2
Training loss: 2.8331470054244807
Validation loss: 2.7734132124677804

Epoch: 6| Step: 3
Training loss: 3.194384153230197
Validation loss: 2.7846136120973424

Epoch: 6| Step: 4
Training loss: 3.241085444288338
Validation loss: 2.782593426044172

Epoch: 6| Step: 5
Training loss: 2.509731236084926
Validation loss: 2.7631389107932147

Epoch: 6| Step: 6
Training loss: 3.0995207631473676
Validation loss: 2.7516655432195463

Epoch: 6| Step: 7
Training loss: 3.5448725084802972
Validation loss: 2.749558206348218

Epoch: 6| Step: 8
Training loss: 3.1547557957565235
Validation loss: 2.750012050016819

Epoch: 6| Step: 9
Training loss: 3.003904662609301
Validation loss: 2.7464526491890373

Epoch: 6| Step: 10
Training loss: 3.1052098580175063
Validation loss: 2.751905926533767

Epoch: 6| Step: 11
Training loss: 2.8863672189546934
Validation loss: 2.750322796548268

Epoch: 6| Step: 12
Training loss: 2.786820993561048
Validation loss: 2.7497713417160092

Epoch: 6| Step: 13
Training loss: 3.3399930864822194
Validation loss: 2.75060486876788

Epoch: 62| Step: 0
Training loss: 3.1108387324520264
Validation loss: 2.7480374452758425

Epoch: 6| Step: 1
Training loss: 2.8560568312218413
Validation loss: 2.744574015357491

Epoch: 6| Step: 2
Training loss: 2.6557004472299734
Validation loss: 2.745067131412102

Epoch: 6| Step: 3
Training loss: 2.894046552387797
Validation loss: 2.7438444097177404

Epoch: 6| Step: 4
Training loss: 2.8399199799560746
Validation loss: 2.7420247235334547

Epoch: 6| Step: 5
Training loss: 2.5419935005879246
Validation loss: 2.743882383199395

Epoch: 6| Step: 6
Training loss: 2.185296611076251
Validation loss: 2.7457463264327258

Epoch: 6| Step: 7
Training loss: 3.185441493122031
Validation loss: 2.743245554579162

Epoch: 6| Step: 8
Training loss: 3.0617721626935466
Validation loss: 2.7427851177622964

Epoch: 6| Step: 9
Training loss: 4.02124485156649
Validation loss: 2.746379491019977

Epoch: 6| Step: 10
Training loss: 3.38370042384807
Validation loss: 2.742595642117002

Epoch: 6| Step: 11
Training loss: 3.295503882633747
Validation loss: 2.7390240287387337

Epoch: 6| Step: 12
Training loss: 2.887356616667142
Validation loss: 2.7413715422013527

Epoch: 6| Step: 13
Training loss: 3.8794633325101833
Validation loss: 2.748914498795829

Epoch: 63| Step: 0
Training loss: 3.197134230796994
Validation loss: 2.7481664453498618

Epoch: 6| Step: 1
Training loss: 3.455725885699664
Validation loss: 2.7352609575570956

Epoch: 6| Step: 2
Training loss: 3.109537551694848
Validation loss: 2.734801814319578

Epoch: 6| Step: 3
Training loss: 2.6875860510955656
Validation loss: 2.7332929363486955

Epoch: 6| Step: 4
Training loss: 3.144153036746374
Validation loss: 2.732154712157416

Epoch: 6| Step: 5
Training loss: 3.4471113910698983
Validation loss: 2.7346222468337733

Epoch: 6| Step: 6
Training loss: 2.658782559488255
Validation loss: 2.7358112703594646

Epoch: 6| Step: 7
Training loss: 2.6312955113912655
Validation loss: 2.7321138291657974

Epoch: 6| Step: 8
Training loss: 2.8337516662835065
Validation loss: 2.732222908542923

Epoch: 6| Step: 9
Training loss: 2.8479172910081747
Validation loss: 2.729969480209381

Epoch: 6| Step: 10
Training loss: 3.152622669081017
Validation loss: 2.733812884375199

Epoch: 6| Step: 11
Training loss: 3.1687892693187423
Validation loss: 2.7306778559665

Epoch: 6| Step: 12
Training loss: 3.6307264676118454
Validation loss: 2.7309445427813843

Epoch: 6| Step: 13
Training loss: 2.6047782383281537
Validation loss: 2.736624899046562

Epoch: 64| Step: 0
Training loss: 2.898614677504587
Validation loss: 2.739959854371999

Epoch: 6| Step: 1
Training loss: 2.605652123536755
Validation loss: 2.7389782856966733

Epoch: 6| Step: 2
Training loss: 2.9785338754563813
Validation loss: 2.7328285525025158

Epoch: 6| Step: 3
Training loss: 2.7940598284050813
Validation loss: 2.7308725124867146

Epoch: 6| Step: 4
Training loss: 3.7984676082144357
Validation loss: 2.729741985930257

Epoch: 6| Step: 5
Training loss: 3.228828724231114
Validation loss: 2.7304646028698465

Epoch: 6| Step: 6
Training loss: 3.323151072940992
Validation loss: 2.7281146730040207

Epoch: 6| Step: 7
Training loss: 2.8454908135989263
Validation loss: 2.728468287003561

Epoch: 6| Step: 8
Training loss: 3.290312106045259
Validation loss: 2.7263337801658634

Epoch: 6| Step: 9
Training loss: 2.950997045098599
Validation loss: 2.734542778715794

Epoch: 6| Step: 10
Training loss: 2.7568911993830287
Validation loss: 2.738436989936069

Epoch: 6| Step: 11
Training loss: 2.5761850167287053
Validation loss: 2.76372971714257

Epoch: 6| Step: 12
Training loss: 3.071162215435001
Validation loss: 2.822372450965768

Epoch: 6| Step: 13
Training loss: 3.9782471451507875
Validation loss: 2.8465456593864404

Epoch: 65| Step: 0
Training loss: 2.683283492231601
Validation loss: 2.7755588246338387

Epoch: 6| Step: 1
Training loss: 3.4294909027686384
Validation loss: 2.73113175821382

Epoch: 6| Step: 2
Training loss: 2.823042966450136
Validation loss: 2.722498828586322

Epoch: 6| Step: 3
Training loss: 2.6398397327673635
Validation loss: 2.724715998958204

Epoch: 6| Step: 4
Training loss: 2.8814808320694234
Validation loss: 2.723498310969053

Epoch: 6| Step: 5
Training loss: 2.380715169443329
Validation loss: 2.723687315487712

Epoch: 6| Step: 6
Training loss: 3.1317426038965186
Validation loss: 2.7235104857714876

Epoch: 6| Step: 7
Training loss: 3.653923272465761
Validation loss: 2.726056429334738

Epoch: 6| Step: 8
Training loss: 3.4177688278584837
Validation loss: 2.725722892394534

Epoch: 6| Step: 9
Training loss: 3.4208217724423933
Validation loss: 2.7255910091204747

Epoch: 6| Step: 10
Training loss: 3.0920260471564505
Validation loss: 2.727374733123186

Epoch: 6| Step: 11
Training loss: 2.9677552815440853
Validation loss: 2.7300467169321365

Epoch: 6| Step: 12
Training loss: 3.180617737659657
Validation loss: 2.7275707241170255

Epoch: 6| Step: 13
Training loss: 2.644021733164377
Validation loss: 2.72810888531497

Epoch: 66| Step: 0
Training loss: 2.9954195022375023
Validation loss: 2.726584177295092

Epoch: 6| Step: 1
Training loss: 3.5523871387913366
Validation loss: 2.7248912479495444

Epoch: 6| Step: 2
Training loss: 2.585001335217483
Validation loss: 2.725387677902096

Epoch: 6| Step: 3
Training loss: 2.5445264976112743
Validation loss: 2.720797439074858

Epoch: 6| Step: 4
Training loss: 2.9481752279991422
Validation loss: 2.719662828141056

Epoch: 6| Step: 5
Training loss: 2.835845189129079
Validation loss: 2.718517953156454

Epoch: 6| Step: 6
Training loss: 3.103910772712537
Validation loss: 2.7166022951461866

Epoch: 6| Step: 7
Training loss: 3.229011843671724
Validation loss: 2.714040333486511

Epoch: 6| Step: 8
Training loss: 2.8674467629610016
Validation loss: 2.712020853782367

Epoch: 6| Step: 9
Training loss: 3.031488468189129
Validation loss: 2.7120233947151884

Epoch: 6| Step: 10
Training loss: 2.6722280704049215
Validation loss: 2.7173119583048564

Epoch: 6| Step: 11
Training loss: 3.677882956786858
Validation loss: 2.7380292147823515

Epoch: 6| Step: 12
Training loss: 3.497069903440007
Validation loss: 2.7427024894119842

Epoch: 6| Step: 13
Training loss: 3.0768033206082666
Validation loss: 2.711491968430227

Epoch: 67| Step: 0
Training loss: 3.3148065849484607
Validation loss: 2.7198414910583515

Epoch: 6| Step: 1
Training loss: 3.6811106009392947
Validation loss: 2.749531199749298

Epoch: 6| Step: 2
Training loss: 3.0677634959072853
Validation loss: 2.8548502054533986

Epoch: 6| Step: 3
Training loss: 3.6389428701756703
Validation loss: 2.9488103916220516

Epoch: 6| Step: 4
Training loss: 2.9774950223764214
Validation loss: 2.8238571008740823

Epoch: 6| Step: 5
Training loss: 3.1551620572360264
Validation loss: 2.733127468089041

Epoch: 6| Step: 6
Training loss: 3.153107844779583
Validation loss: 2.7215931243402007

Epoch: 6| Step: 7
Training loss: 2.775867182321878
Validation loss: 2.724067593721632

Epoch: 6| Step: 8
Training loss: 2.8289562710793534
Validation loss: 2.7343241734622503

Epoch: 6| Step: 9
Training loss: 3.3747862288979547
Validation loss: 2.7460051743572214

Epoch: 6| Step: 10
Training loss: 2.71396637056187
Validation loss: 2.7350210028516813

Epoch: 6| Step: 11
Training loss: 2.674801300369798
Validation loss: 2.723096687060331

Epoch: 6| Step: 12
Training loss: 2.999105161089379
Validation loss: 2.741408903745073

Epoch: 6| Step: 13
Training loss: 2.8642796210919657
Validation loss: 2.7431477880922586

Epoch: 68| Step: 0
Training loss: 2.8286068331992147
Validation loss: 2.751145452443405

Epoch: 6| Step: 1
Training loss: 3.399386148576503
Validation loss: 2.758784359495884

Epoch: 6| Step: 2
Training loss: 2.8156414713150206
Validation loss: 2.7708148688910774

Epoch: 6| Step: 3
Training loss: 2.7031765089474624
Validation loss: 2.7807445170471627

Epoch: 6| Step: 4
Training loss: 3.281600206850697
Validation loss: 2.7347996010849815

Epoch: 6| Step: 5
Training loss: 3.538110870349287
Validation loss: 2.717114184740727

Epoch: 6| Step: 6
Training loss: 3.2299066167506587
Validation loss: 2.71304017985553

Epoch: 6| Step: 7
Training loss: 3.1033478410042314
Validation loss: 2.7123387525036287

Epoch: 6| Step: 8
Training loss: 2.2926950632555068
Validation loss: 2.715376891937008

Epoch: 6| Step: 9
Training loss: 3.6908339606811604
Validation loss: 2.715731429143479

Epoch: 6| Step: 10
Training loss: 2.8811233658175865
Validation loss: 2.7149464790016644

Epoch: 6| Step: 11
Training loss: 2.7778405712235794
Validation loss: 2.715738527986971

Epoch: 6| Step: 12
Training loss: 2.591449866676765
Validation loss: 2.7154840313516777

Epoch: 6| Step: 13
Training loss: 3.5406793601971462
Validation loss: 2.715326576503222

Epoch: 69| Step: 0
Training loss: 2.9026368353868404
Validation loss: 2.714713731191476

Epoch: 6| Step: 1
Training loss: 3.07645491009421
Validation loss: 2.7130408309141467

Epoch: 6| Step: 2
Training loss: 2.559352989241863
Validation loss: 2.714335032597216

Epoch: 6| Step: 3
Training loss: 2.587241774495539
Validation loss: 2.7127332015429166

Epoch: 6| Step: 4
Training loss: 3.327786423918358
Validation loss: 2.711630244014961

Epoch: 6| Step: 5
Training loss: 3.1847336676613236
Validation loss: 2.7117582835622156

Epoch: 6| Step: 6
Training loss: 2.804062542581085
Validation loss: 2.7071463780262564

Epoch: 6| Step: 7
Training loss: 2.7545513290356367
Validation loss: 2.7096666794494246

Epoch: 6| Step: 8
Training loss: 2.9084229908178876
Validation loss: 2.7083451591845633

Epoch: 6| Step: 9
Training loss: 3.3829971509758536
Validation loss: 2.7093765111365165

Epoch: 6| Step: 10
Training loss: 3.0821743582606156
Validation loss: 2.7065392779781696

Epoch: 6| Step: 11
Training loss: 3.546840314653504
Validation loss: 2.7030660032574594

Epoch: 6| Step: 12
Training loss: 3.1815787274807006
Validation loss: 2.7026174053175653

Epoch: 6| Step: 13
Training loss: 3.3384751399052868
Validation loss: 2.7013432514646873

Epoch: 70| Step: 0
Training loss: 2.6326340974306683
Validation loss: 2.7008638747412226

Epoch: 6| Step: 1
Training loss: 2.7759147648436984
Validation loss: 2.7076847143756373

Epoch: 6| Step: 2
Training loss: 3.7158385347779213
Validation loss: 2.714714150482962

Epoch: 6| Step: 3
Training loss: 2.2187523640364826
Validation loss: 2.7318373814077144

Epoch: 6| Step: 4
Training loss: 2.8501468018318263
Validation loss: 2.7843414855953106

Epoch: 6| Step: 5
Training loss: 2.6771211930701333
Validation loss: 2.7762683093355514

Epoch: 6| Step: 6
Training loss: 2.886589739114384
Validation loss: 2.7814880717175057

Epoch: 6| Step: 7
Training loss: 2.9969770778101448
Validation loss: 2.79349909373284

Epoch: 6| Step: 8
Training loss: 3.1935346736097685
Validation loss: 2.767631418917476

Epoch: 6| Step: 9
Training loss: 3.12386179222901
Validation loss: 2.7004658118334453

Epoch: 6| Step: 10
Training loss: 3.221477353026026
Validation loss: 2.7009111469782394

Epoch: 6| Step: 11
Training loss: 3.2501333649488315
Validation loss: 2.6999004933605684

Epoch: 6| Step: 12
Training loss: 3.7960338524212385
Validation loss: 2.703606304182582

Epoch: 6| Step: 13
Training loss: 2.5637237604026923
Validation loss: 2.704577547281527

Epoch: 71| Step: 0
Training loss: 2.8290407163050375
Validation loss: 2.7080871798315935

Epoch: 6| Step: 1
Training loss: 3.0476051433847777
Validation loss: 2.7174533952999895

Epoch: 6| Step: 2
Training loss: 3.171302480658085
Validation loss: 2.7333988370432265

Epoch: 6| Step: 3
Training loss: 3.376063285333909
Validation loss: 2.7273254229795487

Epoch: 6| Step: 4
Training loss: 3.1939754160183957
Validation loss: 2.7204350054339037

Epoch: 6| Step: 5
Training loss: 2.935890406078106
Validation loss: 2.7078121097088363

Epoch: 6| Step: 6
Training loss: 3.007353670868222
Validation loss: 2.702837504155877

Epoch: 6| Step: 7
Training loss: 3.6493337049204153
Validation loss: 2.7026755002898315

Epoch: 6| Step: 8
Training loss: 3.038368596974222
Validation loss: 2.6997397480805363

Epoch: 6| Step: 9
Training loss: 2.240796445195607
Validation loss: 2.6958138119610053

Epoch: 6| Step: 10
Training loss: 2.421417783832915
Validation loss: 2.695181801510125

Epoch: 6| Step: 11
Training loss: 3.6771353194728698
Validation loss: 2.693085208030431

Epoch: 6| Step: 12
Training loss: 2.688466275407126
Validation loss: 2.695912869932536

Epoch: 6| Step: 13
Training loss: 3.0771932208241544
Validation loss: 2.6926838853931803

Epoch: 72| Step: 0
Training loss: 2.7273401064207796
Validation loss: 2.6954260247118995

Epoch: 6| Step: 1
Training loss: 2.9053625577192386
Validation loss: 2.6988894422855383

Epoch: 6| Step: 2
Training loss: 3.087520608562926
Validation loss: 2.7026477216675633

Epoch: 6| Step: 3
Training loss: 3.1168194316884925
Validation loss: 2.715890091420069

Epoch: 6| Step: 4
Training loss: 2.9794942680159076
Validation loss: 2.7001395368353514

Epoch: 6| Step: 5
Training loss: 2.5836412082277955
Validation loss: 2.688392571068717

Epoch: 6| Step: 6
Training loss: 3.4326498320371632
Validation loss: 2.6897398173389178

Epoch: 6| Step: 7
Training loss: 2.999105002096231
Validation loss: 2.686967558033137

Epoch: 6| Step: 8
Training loss: 3.2466720267949385
Validation loss: 2.690228130889414

Epoch: 6| Step: 9
Training loss: 3.388839603197704
Validation loss: 2.6882412454147375

Epoch: 6| Step: 10
Training loss: 2.8978093127164546
Validation loss: 2.688339587794438

Epoch: 6| Step: 11
Training loss: 2.7813208067378126
Validation loss: 2.685389935006809

Epoch: 6| Step: 12
Training loss: 3.2845622465727953
Validation loss: 2.6881268221732992

Epoch: 6| Step: 13
Training loss: 2.7362375945554587
Validation loss: 2.685513588617944

Epoch: 73| Step: 0
Training loss: 2.8737360622338475
Validation loss: 2.686117075418228

Epoch: 6| Step: 1
Training loss: 3.2320927478305155
Validation loss: 2.68691689379478

Epoch: 6| Step: 2
Training loss: 3.1752794157815676
Validation loss: 2.686507713165185

Epoch: 6| Step: 3
Training loss: 3.646700132961471
Validation loss: 2.6879785173239976

Epoch: 6| Step: 4
Training loss: 2.6091526873333977
Validation loss: 2.7044343268661795

Epoch: 6| Step: 5
Training loss: 3.5114020861467434
Validation loss: 2.762505518118435

Epoch: 6| Step: 6
Training loss: 2.6947198630903078
Validation loss: 2.7762705846228193

Epoch: 6| Step: 7
Training loss: 2.7505596631764524
Validation loss: 2.7756581215326896

Epoch: 6| Step: 8
Training loss: 3.237445645262677
Validation loss: 2.7493809537421203

Epoch: 6| Step: 9
Training loss: 3.548387112715377
Validation loss: 2.742258516045385

Epoch: 6| Step: 10
Training loss: 2.6835066824258185
Validation loss: 2.7238676480802693

Epoch: 6| Step: 11
Training loss: 2.9440585029428337
Validation loss: 2.7210108779196727

Epoch: 6| Step: 12
Training loss: 2.790230984440751
Validation loss: 2.6889932561455523

Epoch: 6| Step: 13
Training loss: 2.6776706234433254
Validation loss: 2.6828798997686927

Epoch: 74| Step: 0
Training loss: 3.696869665224252
Validation loss: 2.6878614437776704

Epoch: 6| Step: 1
Training loss: 2.1339747577236152
Validation loss: 2.685012524735362

Epoch: 6| Step: 2
Training loss: 2.5576000351419883
Validation loss: 2.6882721101122398

Epoch: 6| Step: 3
Training loss: 3.528806668190373
Validation loss: 2.6946194217019332

Epoch: 6| Step: 4
Training loss: 2.708493408950017
Validation loss: 2.689121496457374

Epoch: 6| Step: 5
Training loss: 2.9670016310391314
Validation loss: 2.692145274306101

Epoch: 6| Step: 6
Training loss: 3.19206120880258
Validation loss: 2.6931790309611694

Epoch: 6| Step: 7
Training loss: 3.7044162993673586
Validation loss: 2.6970312144938458

Epoch: 6| Step: 8
Training loss: 3.0030649740867124
Validation loss: 2.691772290309312

Epoch: 6| Step: 9
Training loss: 2.052029242665988
Validation loss: 2.687119814058203

Epoch: 6| Step: 10
Training loss: 3.323379643792581
Validation loss: 2.6849148797381455

Epoch: 6| Step: 11
Training loss: 3.0780382483016373
Validation loss: 2.6872203392361476

Epoch: 6| Step: 12
Training loss: 2.7766290058850176
Validation loss: 2.680776282497245

Epoch: 6| Step: 13
Training loss: 3.1272190607559103
Validation loss: 2.679177357570613

Epoch: 75| Step: 0
Training loss: 3.243903383954077
Validation loss: 2.682400437533171

Epoch: 6| Step: 1
Training loss: 2.592667595091294
Validation loss: 2.6784627179432188

Epoch: 6| Step: 2
Training loss: 3.233428964151051
Validation loss: 2.686847112382235

Epoch: 6| Step: 3
Training loss: 3.460854281766157
Validation loss: 2.695745461008078

Epoch: 6| Step: 4
Training loss: 3.5948874622286673
Validation loss: 2.6905091198140663

Epoch: 6| Step: 5
Training loss: 3.142171602289548
Validation loss: 2.6907957434676697

Epoch: 6| Step: 6
Training loss: 2.361813832096876
Validation loss: 2.695799098498236

Epoch: 6| Step: 7
Training loss: 2.2870163870133884
Validation loss: 2.6982424259788784

Epoch: 6| Step: 8
Training loss: 2.951375776274231
Validation loss: 2.7103103328795055

Epoch: 6| Step: 9
Training loss: 2.7604527788979016
Validation loss: 2.7465234560099527

Epoch: 6| Step: 10
Training loss: 3.042711435586527
Validation loss: 2.741650720270603

Epoch: 6| Step: 11
Training loss: 3.1410007536704136
Validation loss: 2.7243520512193853

Epoch: 6| Step: 12
Training loss: 3.141364470770658
Validation loss: 2.7013949709008704

Epoch: 6| Step: 13
Training loss: 2.8969296545903593
Validation loss: 2.683193837759395

Epoch: 76| Step: 0
Training loss: 2.851786732675596
Validation loss: 2.673277512664344

Epoch: 6| Step: 1
Training loss: 3.425251588143218
Validation loss: 2.6706893632402218

Epoch: 6| Step: 2
Training loss: 3.19588698466864
Validation loss: 2.6728741789412873

Epoch: 6| Step: 3
Training loss: 3.0438586832495607
Validation loss: 2.666823457202666

Epoch: 6| Step: 4
Training loss: 2.7875183275928896
Validation loss: 2.672725655057176

Epoch: 6| Step: 5
Training loss: 3.1877767405333377
Validation loss: 2.6711776160061618

Epoch: 6| Step: 6
Training loss: 3.606109066329886
Validation loss: 2.6683068717381353

Epoch: 6| Step: 7
Training loss: 3.000381445476454
Validation loss: 2.6726630501817494

Epoch: 6| Step: 8
Training loss: 3.126024612300579
Validation loss: 2.6730183288404454

Epoch: 6| Step: 9
Training loss: 2.6335096030653196
Validation loss: 2.67237060130009

Epoch: 6| Step: 10
Training loss: 2.4788682474853547
Validation loss: 2.6687513840149597

Epoch: 6| Step: 11
Training loss: 3.053366607195974
Validation loss: 2.670611735528517

Epoch: 6| Step: 12
Training loss: 2.9192947173467285
Validation loss: 2.6710088458491756

Epoch: 6| Step: 13
Training loss: 2.3329483350387252
Validation loss: 2.667826545125419

Epoch: 77| Step: 0
Training loss: 2.9933598465230284
Validation loss: 2.6714872241828753

Epoch: 6| Step: 1
Training loss: 2.9319551770581898
Validation loss: 2.6735474320586086

Epoch: 6| Step: 2
Training loss: 3.2678670533124508
Validation loss: 2.680350481467861

Epoch: 6| Step: 3
Training loss: 3.3707906115967816
Validation loss: 2.698045066571435

Epoch: 6| Step: 4
Training loss: 3.1035251509254373
Validation loss: 2.734118851297099

Epoch: 6| Step: 5
Training loss: 3.4027062977313522
Validation loss: 2.71582311607604

Epoch: 6| Step: 6
Training loss: 2.712327056856251
Validation loss: 2.700838448593096

Epoch: 6| Step: 7
Training loss: 3.1127374765274247
Validation loss: 2.6857579120786257

Epoch: 6| Step: 8
Training loss: 3.017831736156996
Validation loss: 2.6802519827345384

Epoch: 6| Step: 9
Training loss: 2.991589200036071
Validation loss: 2.676222651881307

Epoch: 6| Step: 10
Training loss: 2.894438007206835
Validation loss: 2.675459147408558

Epoch: 6| Step: 11
Training loss: 3.12628315331086
Validation loss: 2.6736746307215813

Epoch: 6| Step: 12
Training loss: 2.7782943107581604
Validation loss: 2.6697423166880663

Epoch: 6| Step: 13
Training loss: 1.8704280425595603
Validation loss: 2.6690247252923838

Epoch: 78| Step: 0
Training loss: 3.105511743020006
Validation loss: 2.678700678940106

Epoch: 6| Step: 1
Training loss: 3.232835486188822
Validation loss: 2.6703632133788844

Epoch: 6| Step: 2
Training loss: 3.1216094888344457
Validation loss: 2.6707419997807644

Epoch: 6| Step: 3
Training loss: 2.8784407882497707
Validation loss: 2.688348877894555

Epoch: 6| Step: 4
Training loss: 2.3106517106922455
Validation loss: 2.663636647930493

Epoch: 6| Step: 5
Training loss: 3.3949171051107756
Validation loss: 2.6594808976241144

Epoch: 6| Step: 6
Training loss: 2.935637999926723
Validation loss: 2.6600710704150226

Epoch: 6| Step: 7
Training loss: 3.387921499232374
Validation loss: 2.663736697497641

Epoch: 6| Step: 8
Training loss: 2.9725659390539896
Validation loss: 2.6685924706303115

Epoch: 6| Step: 9
Training loss: 2.7346998621195096
Validation loss: 2.688159139684247

Epoch: 6| Step: 10
Training loss: 3.9380418919262294
Validation loss: 2.707522191450506

Epoch: 6| Step: 11
Training loss: 2.496565366794202
Validation loss: 2.74604645455837

Epoch: 6| Step: 12
Training loss: 2.2991815520585086
Validation loss: 2.8370701928950743

Epoch: 6| Step: 13
Training loss: 3.251226193855303
Validation loss: 2.9437497170001867

Epoch: 79| Step: 0
Training loss: 3.319027497207831
Validation loss: 2.941459810958207

Epoch: 6| Step: 1
Training loss: 2.54380969603129
Validation loss: 2.8822364750760916

Epoch: 6| Step: 2
Training loss: 3.4695940794964835
Validation loss: 2.8641294610160877

Epoch: 6| Step: 3
Training loss: 3.467534720117058
Validation loss: 2.822058319949782

Epoch: 6| Step: 4
Training loss: 3.118907635513945
Validation loss: 2.743687035086228

Epoch: 6| Step: 5
Training loss: 3.596934358983621
Validation loss: 2.7296465561631305

Epoch: 6| Step: 6
Training loss: 2.4626485053657627
Validation loss: 2.719544891978272

Epoch: 6| Step: 7
Training loss: 2.708002618013635
Validation loss: 2.673061241608609

Epoch: 6| Step: 8
Training loss: 2.9643300130294974
Validation loss: 2.6948626884361335

Epoch: 6| Step: 9
Training loss: 3.6049760707108653
Validation loss: 2.736014218597416

Epoch: 6| Step: 10
Training loss: 2.629424498944245
Validation loss: 2.7439233122743483

Epoch: 6| Step: 11
Training loss: 3.2506809988334378
Validation loss: 2.7302423095416932

Epoch: 6| Step: 12
Training loss: 2.5027764162188557
Validation loss: 2.71070486760196

Epoch: 6| Step: 13
Training loss: 2.9900860690484117
Validation loss: 2.700844667755932

Epoch: 80| Step: 0
Training loss: 3.030046204318537
Validation loss: 2.6918755178809297

Epoch: 6| Step: 1
Training loss: 2.548731776495531
Validation loss: 2.6801964702105887

Epoch: 6| Step: 2
Training loss: 3.101244239909409
Validation loss: 2.6633919373045587

Epoch: 6| Step: 3
Training loss: 3.1254845815695376
Validation loss: 2.670761881119813

Epoch: 6| Step: 4
Training loss: 3.402863665338053
Validation loss: 2.65443856075013

Epoch: 6| Step: 5
Training loss: 3.2816667564576774
Validation loss: 2.6537632216681004

Epoch: 6| Step: 6
Training loss: 3.0938261388792205
Validation loss: 2.6498746509125675

Epoch: 6| Step: 7
Training loss: 2.683991737227932
Validation loss: 2.652825107620051

Epoch: 6| Step: 8
Training loss: 2.9117134178118937
Validation loss: 2.651640841099713

Epoch: 6| Step: 9
Training loss: 3.5620752717192885
Validation loss: 2.6533092813606984

Epoch: 6| Step: 10
Training loss: 2.278371170202297
Validation loss: 2.6509341193072227

Epoch: 6| Step: 11
Training loss: 2.4290096404511328
Validation loss: 2.6555493457985486

Epoch: 6| Step: 12
Training loss: 3.3550590291636246
Validation loss: 2.6496376916377433

Epoch: 6| Step: 13
Training loss: 2.77302285976734
Validation loss: 2.6443918157794535

Epoch: 81| Step: 0
Training loss: 3.022310426381699
Validation loss: 2.6499734366221905

Epoch: 6| Step: 1
Training loss: 2.656796836663453
Validation loss: 2.6442823010061574

Epoch: 6| Step: 2
Training loss: 3.4149679907978387
Validation loss: 2.650692437329827

Epoch: 6| Step: 3
Training loss: 3.4769478916479826
Validation loss: 2.6397916990244363

Epoch: 6| Step: 4
Training loss: 2.6851196393116252
Validation loss: 2.639724573072757

Epoch: 6| Step: 5
Training loss: 2.7496152088413925
Validation loss: 2.6385014123411312

Epoch: 6| Step: 6
Training loss: 3.6175602829977893
Validation loss: 2.6396307032310755

Epoch: 6| Step: 7
Training loss: 3.0219486326223364
Validation loss: 2.6423538954825934

Epoch: 6| Step: 8
Training loss: 3.220934080560849
Validation loss: 2.6382924662532976

Epoch: 6| Step: 9
Training loss: 2.6433755668098
Validation loss: 2.6421662704014546

Epoch: 6| Step: 10
Training loss: 2.4835921679621022
Validation loss: 2.6457858001829173

Epoch: 6| Step: 11
Training loss: 3.269020760811889
Validation loss: 2.6408502131128024

Epoch: 6| Step: 12
Training loss: 2.223779592247451
Validation loss: 2.644701764094041

Epoch: 6| Step: 13
Training loss: 3.0863348982649383
Validation loss: 2.6391031134768284

Epoch: 82| Step: 0
Training loss: 2.4202820492153196
Validation loss: 2.638450001083881

Epoch: 6| Step: 1
Training loss: 3.0040222859882975
Validation loss: 2.6382222606415024

Epoch: 6| Step: 2
Training loss: 2.8081976302174474
Validation loss: 2.635818841485798

Epoch: 6| Step: 3
Training loss: 3.4246937190195266
Validation loss: 2.6403590446605927

Epoch: 6| Step: 4
Training loss: 3.2695283331453537
Validation loss: 2.6399442044272674

Epoch: 6| Step: 5
Training loss: 2.5806914531109038
Validation loss: 2.6423813755941357

Epoch: 6| Step: 6
Training loss: 2.7451458484696434
Validation loss: 2.644337947006307

Epoch: 6| Step: 7
Training loss: 2.702803840742421
Validation loss: 2.6468941717154135

Epoch: 6| Step: 8
Training loss: 2.972151564315765
Validation loss: 2.6531213700611374

Epoch: 6| Step: 9
Training loss: 3.4588217026612953
Validation loss: 2.6585415167434636

Epoch: 6| Step: 10
Training loss: 2.778155716510625
Validation loss: 2.645877525445643

Epoch: 6| Step: 11
Training loss: 3.7046953565626044
Validation loss: 2.637003691729776

Epoch: 6| Step: 12
Training loss: 2.5945510546472
Validation loss: 2.6367352685748937

Epoch: 6| Step: 13
Training loss: 2.9275964217102475
Validation loss: 2.6349341966491244

Epoch: 83| Step: 0
Training loss: 2.617630013021474
Validation loss: 2.6348894642446106

Epoch: 6| Step: 1
Training loss: 2.7749608114413795
Validation loss: 2.6345942012065167

Epoch: 6| Step: 2
Training loss: 2.7156417442305996
Validation loss: 2.634677620075573

Epoch: 6| Step: 3
Training loss: 2.8570860993333587
Validation loss: 2.635215134514537

Epoch: 6| Step: 4
Training loss: 3.6265915632418753
Validation loss: 2.6340274572636964

Epoch: 6| Step: 5
Training loss: 3.218094990572399
Validation loss: 2.6358472183891646

Epoch: 6| Step: 6
Training loss: 2.340813182808813
Validation loss: 2.6353227516829496

Epoch: 6| Step: 7
Training loss: 2.8482739023340584
Validation loss: 2.6349993236720133

Epoch: 6| Step: 8
Training loss: 3.0447621380086134
Validation loss: 2.6339256786571

Epoch: 6| Step: 9
Training loss: 3.410234692906863
Validation loss: 2.6310567092936763

Epoch: 6| Step: 10
Training loss: 3.2272330781110465
Validation loss: 2.6360944646179076

Epoch: 6| Step: 11
Training loss: 2.9507591822422437
Validation loss: 2.637269901840591

Epoch: 6| Step: 12
Training loss: 2.854679776219368
Validation loss: 2.644095739675553

Epoch: 6| Step: 13
Training loss: 3.032849548522341
Validation loss: 2.6548752462192784

Epoch: 84| Step: 0
Training loss: 3.0163630239634593
Validation loss: 2.6696526031044225

Epoch: 6| Step: 1
Training loss: 3.13597225365723
Validation loss: 2.689340442497606

Epoch: 6| Step: 2
Training loss: 3.0583304222432623
Validation loss: 2.6828994044965935

Epoch: 6| Step: 3
Training loss: 3.0278693155184078
Validation loss: 2.6899362288170927

Epoch: 6| Step: 4
Training loss: 2.9976016630442484
Validation loss: 2.7034532028970926

Epoch: 6| Step: 5
Training loss: 2.6377803671553743
Validation loss: 2.6807136408976353

Epoch: 6| Step: 6
Training loss: 3.406647825195206
Validation loss: 2.703705665009042

Epoch: 6| Step: 7
Training loss: 3.095143014195033
Validation loss: 2.6701004035005727

Epoch: 6| Step: 8
Training loss: 2.981100312959585
Validation loss: 2.6478383334558795

Epoch: 6| Step: 9
Training loss: 3.047598728398865
Validation loss: 2.634480431472954

Epoch: 6| Step: 10
Training loss: 2.721911729461883
Validation loss: 2.6286813545631347

Epoch: 6| Step: 11
Training loss: 2.392292214262637
Validation loss: 2.6256042640496937

Epoch: 6| Step: 12
Training loss: 2.796102065366844
Validation loss: 2.6250111002963257

Epoch: 6| Step: 13
Training loss: 3.647275163650909
Validation loss: 2.624394400177784

Epoch: 85| Step: 0
Training loss: 2.89127651811009
Validation loss: 2.623713176469888

Epoch: 6| Step: 1
Training loss: 2.5925840032021465
Validation loss: 2.621973815023485

Epoch: 6| Step: 2
Training loss: 2.6035847636813334
Validation loss: 2.6245675382637708

Epoch: 6| Step: 3
Training loss: 3.5471761298381774
Validation loss: 2.623919840482888

Epoch: 6| Step: 4
Training loss: 2.9830220136402454
Validation loss: 2.624694173550544

Epoch: 6| Step: 5
Training loss: 2.8178603906317483
Validation loss: 2.6234358323376474

Epoch: 6| Step: 6
Training loss: 2.4988020887952063
Validation loss: 2.627643636903022

Epoch: 6| Step: 7
Training loss: 2.9884977773371233
Validation loss: 2.6256931198500713

Epoch: 6| Step: 8
Training loss: 2.7802952188403034
Validation loss: 2.6326838032509308

Epoch: 6| Step: 9
Training loss: 2.855268353946241
Validation loss: 2.635932035069891

Epoch: 6| Step: 10
Training loss: 2.8189483471292904
Validation loss: 2.6457225772180255

Epoch: 6| Step: 11
Training loss: 3.4004248409751825
Validation loss: 2.6553226606335634

Epoch: 6| Step: 12
Training loss: 3.1339130703981724
Validation loss: 2.6619723855668176

Epoch: 6| Step: 13
Training loss: 3.805635620042226
Validation loss: 2.6560621519701058

Epoch: 86| Step: 0
Training loss: 2.8906545276680222
Validation loss: 2.624524595472756

Epoch: 6| Step: 1
Training loss: 2.330019800650488
Validation loss: 2.6199862095747704

Epoch: 6| Step: 2
Training loss: 2.939104656462683
Validation loss: 2.639096926584674

Epoch: 6| Step: 3
Training loss: 3.3708535613846835
Validation loss: 2.6343608256895004

Epoch: 6| Step: 4
Training loss: 2.814561385138091
Validation loss: 2.640615186668802

Epoch: 6| Step: 5
Training loss: 2.4501285597099685
Validation loss: 2.655574015258603

Epoch: 6| Step: 6
Training loss: 3.881661135018648
Validation loss: 2.671953830636717

Epoch: 6| Step: 7
Training loss: 2.866367482681934
Validation loss: 2.7143592253963527

Epoch: 6| Step: 8
Training loss: 3.0891694347066307
Validation loss: 2.7586890087956166

Epoch: 6| Step: 9
Training loss: 3.4276968146980575
Validation loss: 2.7868410347743837

Epoch: 6| Step: 10
Training loss: 3.7413385180788374
Validation loss: 2.7765624532433493

Epoch: 6| Step: 11
Training loss: 2.9267364694646383
Validation loss: 2.756850119694244

Epoch: 6| Step: 12
Training loss: 2.7554290240814567
Validation loss: 2.7441486611787056

Epoch: 6| Step: 13
Training loss: 2.526175699250285
Validation loss: 2.74265887534024

Epoch: 87| Step: 0
Training loss: 2.5434480792550995
Validation loss: 2.74085662821222

Epoch: 6| Step: 1
Training loss: 3.175269504432852
Validation loss: 2.7253142966727024

Epoch: 6| Step: 2
Training loss: 2.846421213340514
Validation loss: 2.7828429618053017

Epoch: 6| Step: 3
Training loss: 3.4248127628576026
Validation loss: 2.7866888380849124

Epoch: 6| Step: 4
Training loss: 1.8895665508339519
Validation loss: 2.737245996618014

Epoch: 6| Step: 5
Training loss: 3.2595447353447793
Validation loss: 2.6796894382611027

Epoch: 6| Step: 6
Training loss: 3.3806631823580515
Validation loss: 2.629186189955155

Epoch: 6| Step: 7
Training loss: 3.328012957052537
Validation loss: 2.6193494976292238

Epoch: 6| Step: 8
Training loss: 3.220001421862934
Validation loss: 2.6237370108594638

Epoch: 6| Step: 9
Training loss: 2.3440883137988173
Validation loss: 2.6394870784567956

Epoch: 6| Step: 10
Training loss: 3.4825504469657895
Validation loss: 2.6590004170922317

Epoch: 6| Step: 11
Training loss: 3.168307096990417
Validation loss: 2.6808744827362188

Epoch: 6| Step: 12
Training loss: 2.4761192334235207
Validation loss: 2.6538797930508817

Epoch: 6| Step: 13
Training loss: 3.0920127846279573
Validation loss: 2.6515886612093813

Epoch: 88| Step: 0
Training loss: 2.8140405462362863
Validation loss: 2.640168213295585

Epoch: 6| Step: 1
Training loss: 3.1620784614281834
Validation loss: 2.644348006342584

Epoch: 6| Step: 2
Training loss: 2.8321521391224276
Validation loss: 2.627416904405036

Epoch: 6| Step: 3
Training loss: 2.9404677962180954
Validation loss: 2.6391174266199253

Epoch: 6| Step: 4
Training loss: 3.0934690097399056
Validation loss: 2.630167958719199

Epoch: 6| Step: 5
Training loss: 2.3937539959667506
Validation loss: 2.621275709689052

Epoch: 6| Step: 6
Training loss: 3.3809428697806627
Validation loss: 2.6149532885077256

Epoch: 6| Step: 7
Training loss: 3.205376703557094
Validation loss: 2.617248233732692

Epoch: 6| Step: 8
Training loss: 2.8273598494734107
Validation loss: 2.6212361976827836

Epoch: 6| Step: 9
Training loss: 3.0481478648827003
Validation loss: 2.6192933863344137

Epoch: 6| Step: 10
Training loss: 3.2002766668404985
Validation loss: 2.6209213977499557

Epoch: 6| Step: 11
Training loss: 2.300862905092832
Validation loss: 2.6288112575739886

Epoch: 6| Step: 12
Training loss: 2.9198928066069816
Validation loss: 2.6278221216976667

Epoch: 6| Step: 13
Training loss: 3.3440742691955134
Validation loss: 2.635296178558037

Epoch: 89| Step: 0
Training loss: 2.971312370753005
Validation loss: 2.624883008460344

Epoch: 6| Step: 1
Training loss: 2.6124866686029096
Validation loss: 2.6388183119798434

Epoch: 6| Step: 2
Training loss: 3.093966235686149
Validation loss: 2.6503028090636023

Epoch: 6| Step: 3
Training loss: 2.8582834964185126
Validation loss: 2.635548543364362

Epoch: 6| Step: 4
Training loss: 2.900543352723388
Validation loss: 2.632331273240449

Epoch: 6| Step: 5
Training loss: 3.2978493936456443
Validation loss: 2.6375649197770055

Epoch: 6| Step: 6
Training loss: 2.313095222370118
Validation loss: 2.618411542165241

Epoch: 6| Step: 7
Training loss: 3.332453102875017
Validation loss: 2.6097655234667823

Epoch: 6| Step: 8
Training loss: 2.89756971668699
Validation loss: 2.604874052057315

Epoch: 6| Step: 9
Training loss: 2.5648696921341196
Validation loss: 2.6065094566927227

Epoch: 6| Step: 10
Training loss: 3.1971036558890336
Validation loss: 2.6011515577996636

Epoch: 6| Step: 11
Training loss: 2.822203955587043
Validation loss: 2.605434749523051

Epoch: 6| Step: 12
Training loss: 3.3457062604881687
Validation loss: 2.6092649312218583

Epoch: 6| Step: 13
Training loss: 2.956472769926834
Validation loss: 2.6018228634328517

Epoch: 90| Step: 0
Training loss: 2.9273757155021825
Validation loss: 2.601345553928498

Epoch: 6| Step: 1
Training loss: 2.87363268638916
Validation loss: 2.5998551548445685

Epoch: 6| Step: 2
Training loss: 2.739957592907488
Validation loss: 2.6013428930619917

Epoch: 6| Step: 3
Training loss: 3.183448909904963
Validation loss: 2.6002802535672522

Epoch: 6| Step: 4
Training loss: 2.831602203491578
Validation loss: 2.600644331306402

Epoch: 6| Step: 5
Training loss: 2.912198122285361
Validation loss: 2.5997072262466956

Epoch: 6| Step: 6
Training loss: 2.748743637237193
Validation loss: 2.596250802897464

Epoch: 6| Step: 7
Training loss: 3.422273795522292
Validation loss: 2.5983368303943877

Epoch: 6| Step: 8
Training loss: 2.992928754259976
Validation loss: 2.5933519372505534

Epoch: 6| Step: 9
Training loss: 3.218932507720193
Validation loss: 2.59149768551336

Epoch: 6| Step: 10
Training loss: 2.4761481194139705
Validation loss: 2.594642198089066

Epoch: 6| Step: 11
Training loss: 2.4053577899274563
Validation loss: 2.593340303058571

Epoch: 6| Step: 12
Training loss: 3.4320450936847333
Validation loss: 2.5945443040320693

Epoch: 6| Step: 13
Training loss: 3.085881717998606
Validation loss: 2.593407967278507

Epoch: 91| Step: 0
Training loss: 3.3480805492031753
Validation loss: 2.5913360695713905

Epoch: 6| Step: 1
Training loss: 2.908996924594422
Validation loss: 2.59190912916475

Epoch: 6| Step: 2
Training loss: 2.8201341229190575
Validation loss: 2.592772050263953

Epoch: 6| Step: 3
Training loss: 2.9317430939578806
Validation loss: 2.5920404799344015

Epoch: 6| Step: 4
Training loss: 2.8074279827552004
Validation loss: 2.5935492815342567

Epoch: 6| Step: 5
Training loss: 2.5454619062304893
Validation loss: 2.5901704479851912

Epoch: 6| Step: 6
Training loss: 2.8103490445706805
Validation loss: 2.5902221761548088

Epoch: 6| Step: 7
Training loss: 2.2725603961367793
Validation loss: 2.5932527775438223

Epoch: 6| Step: 8
Training loss: 3.1251559409334067
Validation loss: 2.594737738953362

Epoch: 6| Step: 9
Training loss: 2.9031762717064926
Validation loss: 2.6044075891764136

Epoch: 6| Step: 10
Training loss: 2.9978366044951446
Validation loss: 2.6281908138703933

Epoch: 6| Step: 11
Training loss: 3.199960624929412
Validation loss: 2.628676403177246

Epoch: 6| Step: 12
Training loss: 2.9633487757082695
Validation loss: 2.6247673644519844

Epoch: 6| Step: 13
Training loss: 3.917337536002186
Validation loss: 2.628103784709615

Epoch: 92| Step: 0
Training loss: 2.8127079356998785
Validation loss: 2.6204669797743074

Epoch: 6| Step: 1
Training loss: 3.2103968998232184
Validation loss: 2.5908975979558804

Epoch: 6| Step: 2
Training loss: 2.9407656758597653
Validation loss: 2.5890833988354105

Epoch: 6| Step: 3
Training loss: 3.1554822837877476
Validation loss: 2.5895849501448724

Epoch: 6| Step: 4
Training loss: 3.4498145343851854
Validation loss: 2.6010984453847965

Epoch: 6| Step: 5
Training loss: 3.113703030262993
Validation loss: 2.6203303242744544

Epoch: 6| Step: 6
Training loss: 2.9886297284556003
Validation loss: 2.644875970838602

Epoch: 6| Step: 7
Training loss: 3.1813471631274175
Validation loss: 2.6695231490357534

Epoch: 6| Step: 8
Training loss: 2.648174261553734
Validation loss: 2.6731839982061776

Epoch: 6| Step: 9
Training loss: 3.1372702221870346
Validation loss: 2.673798682303465

Epoch: 6| Step: 10
Training loss: 3.066383857402315
Validation loss: 2.6794384457018054

Epoch: 6| Step: 11
Training loss: 2.6067105698201347
Validation loss: 2.672511339406356

Epoch: 6| Step: 12
Training loss: 3.0336013011853127
Validation loss: 2.668300243348088

Epoch: 6| Step: 13
Training loss: 2.080929348275584
Validation loss: 2.669594060304693

Epoch: 93| Step: 0
Training loss: 3.0800778153733197
Validation loss: 2.6682810594512576

Epoch: 6| Step: 1
Training loss: 3.7554370882760137
Validation loss: 2.6664836811790265

Epoch: 6| Step: 2
Training loss: 2.7623623498652607
Validation loss: 2.656736551562372

Epoch: 6| Step: 3
Training loss: 3.085947389224661
Validation loss: 2.652739280940058

Epoch: 6| Step: 4
Training loss: 2.6699138381714262
Validation loss: 2.6364939968708008

Epoch: 6| Step: 5
Training loss: 2.8191131831489664
Validation loss: 2.6264668051826634

Epoch: 6| Step: 6
Training loss: 2.210730553097699
Validation loss: 2.6150564809777923

Epoch: 6| Step: 7
Training loss: 3.236436859311722
Validation loss: 2.6078136926895255

Epoch: 6| Step: 8
Training loss: 3.0129971295839066
Validation loss: 2.591184558889238

Epoch: 6| Step: 9
Training loss: 3.3648608460356266
Validation loss: 2.585094970323515

Epoch: 6| Step: 10
Training loss: 2.5695838707105323
Validation loss: 2.5837859856401257

Epoch: 6| Step: 11
Training loss: 2.8879431578518644
Validation loss: 2.5864515714023533

Epoch: 6| Step: 12
Training loss: 2.9521426226993674
Validation loss: 2.584404867700259

Epoch: 6| Step: 13
Training loss: 3.009567422547934
Validation loss: 2.6013085439875665

Epoch: 94| Step: 0
Training loss: 3.7438462947121876
Validation loss: 2.6202083926443462

Epoch: 6| Step: 1
Training loss: 2.6707200794538264
Validation loss: 2.654542661635978

Epoch: 6| Step: 2
Training loss: 2.6989850220464278
Validation loss: 2.6978662729793013

Epoch: 6| Step: 3
Training loss: 2.8564538261091075
Validation loss: 2.7991599188757617

Epoch: 6| Step: 4
Training loss: 2.4273513405849694
Validation loss: 2.8784306171780214

Epoch: 6| Step: 5
Training loss: 3.2690540179634966
Validation loss: 2.9235228916378575

Epoch: 6| Step: 6
Training loss: 2.73957025986563
Validation loss: 2.7503683052396055

Epoch: 6| Step: 7
Training loss: 2.5152324109544475
Validation loss: 2.624634577156108

Epoch: 6| Step: 8
Training loss: 2.7632530946513203
Validation loss: 2.5889631236806476

Epoch: 6| Step: 9
Training loss: 3.1242769549271503
Validation loss: 2.5704177459375215

Epoch: 6| Step: 10
Training loss: 2.7654182658541235
Validation loss: 2.574812239441946

Epoch: 6| Step: 11
Training loss: 3.7321798983735017
Validation loss: 2.574448890064297

Epoch: 6| Step: 12
Training loss: 3.0543549885961694
Validation loss: 2.583316477093067

Epoch: 6| Step: 13
Training loss: 2.93207113318656
Validation loss: 2.5858454082991322

Epoch: 95| Step: 0
Training loss: 3.0130427081413873
Validation loss: 2.6031009276810577

Epoch: 6| Step: 1
Training loss: 2.9922451880250036
Validation loss: 2.6274849985082622

Epoch: 6| Step: 2
Training loss: 2.1871417160899718
Validation loss: 2.6520842216602407

Epoch: 6| Step: 3
Training loss: 2.9171394691538346
Validation loss: 2.7425582013943006

Epoch: 6| Step: 4
Training loss: 3.345617895605168
Validation loss: 2.724514728051475

Epoch: 6| Step: 5
Training loss: 3.4781701646256176
Validation loss: 2.7094273278436942

Epoch: 6| Step: 6
Training loss: 3.437685042515979
Validation loss: 2.700652796380997

Epoch: 6| Step: 7
Training loss: 3.1076100002961167
Validation loss: 2.7000455066684994

Epoch: 6| Step: 8
Training loss: 3.5813288441978073
Validation loss: 2.69781853497414

Epoch: 6| Step: 9
Training loss: 2.955892245237316
Validation loss: 2.6823921227015055

Epoch: 6| Step: 10
Training loss: 3.186281607146723
Validation loss: 2.6757075699088007

Epoch: 6| Step: 11
Training loss: 2.9836822824260927
Validation loss: 2.670683794754783

Epoch: 6| Step: 12
Training loss: 2.7066476613428256
Validation loss: 2.641707678296942

Epoch: 6| Step: 13
Training loss: 2.202908985559146
Validation loss: 2.6316007450563235

Epoch: 96| Step: 0
Training loss: 2.804663187840744
Validation loss: 2.649092925867811

Epoch: 6| Step: 1
Training loss: 3.0963273535172537
Validation loss: 2.617701079403252

Epoch: 6| Step: 2
Training loss: 2.434724352232959
Validation loss: 2.6448747446918217

Epoch: 6| Step: 3
Training loss: 3.0974755252490054
Validation loss: 2.729495889031347

Epoch: 6| Step: 4
Training loss: 3.162032769107581
Validation loss: 2.707596103169793

Epoch: 6| Step: 5
Training loss: 3.2616050106478864
Validation loss: 2.6544585352249275

Epoch: 6| Step: 6
Training loss: 3.237743153517495
Validation loss: 2.617272238659747

Epoch: 6| Step: 7
Training loss: 3.1104118113768373
Validation loss: 2.5998256327103753

Epoch: 6| Step: 8
Training loss: 2.740347829306699
Validation loss: 2.603447765590397

Epoch: 6| Step: 9
Training loss: 3.281366546014291
Validation loss: 2.590465784684269

Epoch: 6| Step: 10
Training loss: 2.9127248194290964
Validation loss: 2.57626590763792

Epoch: 6| Step: 11
Training loss: 2.9825347499309873
Validation loss: 2.577035242424935

Epoch: 6| Step: 12
Training loss: 2.4596981742665074
Validation loss: 2.5814685428978885

Epoch: 6| Step: 13
Training loss: 2.545154950234489
Validation loss: 2.5893241046585476

Epoch: 97| Step: 0
Training loss: 3.136333817251031
Validation loss: 2.604400254797052

Epoch: 6| Step: 1
Training loss: 2.9595159575619734
Validation loss: 2.603087583050705

Epoch: 6| Step: 2
Training loss: 2.8924165689607086
Validation loss: 2.6138313188240425

Epoch: 6| Step: 3
Training loss: 3.128279224294303
Validation loss: 2.6049128310454877

Epoch: 6| Step: 4
Training loss: 2.904648041931683
Validation loss: 2.5877549210590374

Epoch: 6| Step: 5
Training loss: 3.216734319841824
Validation loss: 2.5778896966464826

Epoch: 6| Step: 6
Training loss: 3.326957963664733
Validation loss: 2.5734188816418078

Epoch: 6| Step: 7
Training loss: 2.001154089779205
Validation loss: 2.5716171875651415

Epoch: 6| Step: 8
Training loss: 2.9792682834892332
Validation loss: 2.575317837335968

Epoch: 6| Step: 9
Training loss: 3.196075870573004
Validation loss: 2.5880973234651474

Epoch: 6| Step: 10
Training loss: 2.817781871651618
Validation loss: 2.5909570610469044

Epoch: 6| Step: 11
Training loss: 3.01889193183422
Validation loss: 2.585942125763966

Epoch: 6| Step: 12
Training loss: 2.7489123360930696
Validation loss: 2.580403671995598

Epoch: 6| Step: 13
Training loss: 2.802445899924417
Validation loss: 2.568798902310733

Epoch: 98| Step: 0
Training loss: 3.161806258151646
Validation loss: 2.570758242206916

Epoch: 6| Step: 1
Training loss: 2.8270479121808516
Validation loss: 2.5733822949298872

Epoch: 6| Step: 2
Training loss: 2.8594250283789435
Validation loss: 2.5701813399882267

Epoch: 6| Step: 3
Training loss: 2.8580048827442615
Validation loss: 2.5647731266107305

Epoch: 6| Step: 4
Training loss: 3.452644142053344
Validation loss: 2.569481604751854

Epoch: 6| Step: 5
Training loss: 3.3183884015983276
Validation loss: 2.5711907210081724

Epoch: 6| Step: 6
Training loss: 2.6208309490959185
Validation loss: 2.571260020978677

Epoch: 6| Step: 7
Training loss: 2.8319276988072937
Validation loss: 2.5696566729009986

Epoch: 6| Step: 8
Training loss: 3.2286887194599556
Validation loss: 2.5698475618394467

Epoch: 6| Step: 9
Training loss: 3.060486111892826
Validation loss: 2.567856055521617

Epoch: 6| Step: 10
Training loss: 2.2630324690811934
Validation loss: 2.561928023704644

Epoch: 6| Step: 11
Training loss: 2.361931028930524
Validation loss: 2.5633906385609384

Epoch: 6| Step: 12
Training loss: 2.843482874805819
Validation loss: 2.562353914840402

Epoch: 6| Step: 13
Training loss: 3.3933392748627673
Validation loss: 2.559601300512756

Epoch: 99| Step: 0
Training loss: 3.0015088101876826
Validation loss: 2.5585664430971073

Epoch: 6| Step: 1
Training loss: 2.904851433374104
Validation loss: 2.558505885520768

Epoch: 6| Step: 2
Training loss: 3.359895887578395
Validation loss: 2.555618629736831

Epoch: 6| Step: 3
Training loss: 3.301943963576401
Validation loss: 2.5595921170265816

Epoch: 6| Step: 4
Training loss: 3.0047772834999766
Validation loss: 2.5572853343098187

Epoch: 6| Step: 5
Training loss: 2.596586859149556
Validation loss: 2.5567545585634157

Epoch: 6| Step: 6
Training loss: 3.0142825602500083
Validation loss: 2.558204902008439

Epoch: 6| Step: 7
Training loss: 2.811952580053491
Validation loss: 2.553733312065318

Epoch: 6| Step: 8
Training loss: 2.977634987641854
Validation loss: 2.5542197537945466

Epoch: 6| Step: 9
Training loss: 2.9445887316333184
Validation loss: 2.557971205846622

Epoch: 6| Step: 10
Training loss: 2.723421577586532
Validation loss: 2.558524909553671

Epoch: 6| Step: 11
Training loss: 1.9651279736844502
Validation loss: 2.5723347754210275

Epoch: 6| Step: 12
Training loss: 3.2094911905296457
Validation loss: 2.580146523531493

Epoch: 6| Step: 13
Training loss: 2.8445857570070348
Validation loss: 2.588597150476911

Epoch: 100| Step: 0
Training loss: 3.296620580610156
Validation loss: 2.599815065836761

Epoch: 6| Step: 1
Training loss: 2.6965405306494206
Validation loss: 2.617821138364011

Epoch: 6| Step: 2
Training loss: 2.2066034223054394
Validation loss: 2.648467668932665

Epoch: 6| Step: 3
Training loss: 2.816540168615271
Validation loss: 2.7142582914037456

Epoch: 6| Step: 4
Training loss: 2.726607620171975
Validation loss: 2.7311327147218107

Epoch: 6| Step: 5
Training loss: 3.3496334330859794
Validation loss: 2.725535437114387

Epoch: 6| Step: 6
Training loss: 3.2117918785193496
Validation loss: 2.5985163455592297

Epoch: 6| Step: 7
Training loss: 2.777828898489291
Validation loss: 2.552896969554914

Epoch: 6| Step: 8
Training loss: 3.229569850895621
Validation loss: 2.5576249046202837

Epoch: 6| Step: 9
Training loss: 3.169386314893959
Validation loss: 2.647249784618331

Epoch: 6| Step: 10
Training loss: 3.167291646486216
Validation loss: 2.7043262775940287

Epoch: 6| Step: 11
Training loss: 3.194685373112462
Validation loss: 2.73531093535683

Epoch: 6| Step: 12
Training loss: 2.992104631277409
Validation loss: 2.752066025403131

Epoch: 6| Step: 13
Training loss: 2.7255467487553537
Validation loss: 2.709896829665895

Epoch: 101| Step: 0
Training loss: 3.142090261084374
Validation loss: 2.706939947162439

Epoch: 6| Step: 1
Training loss: 3.2914037639718092
Validation loss: 2.694505589945137

Epoch: 6| Step: 2
Training loss: 2.9895962882121223
Validation loss: 2.682453911797894

Epoch: 6| Step: 3
Training loss: 2.7472510036001854
Validation loss: 2.665875572935194

Epoch: 6| Step: 4
Training loss: 3.696734100520178
Validation loss: 2.678258721556021

Epoch: 6| Step: 5
Training loss: 2.327270350942699
Validation loss: 2.6640525151047196

Epoch: 6| Step: 6
Training loss: 3.427356249175835
Validation loss: 2.661003437222078

Epoch: 6| Step: 7
Training loss: 3.4338800964039926
Validation loss: 2.6549315469748707

Epoch: 6| Step: 8
Training loss: 3.0963841793230236
Validation loss: 2.634581272986665

Epoch: 6| Step: 9
Training loss: 3.1052161539860754
Validation loss: 2.631735326865228

Epoch: 6| Step: 10
Training loss: 2.662228576722979
Validation loss: 2.625297539290182

Epoch: 6| Step: 11
Training loss: 2.8348881064641467
Validation loss: 2.6141144216358247

Epoch: 6| Step: 12
Training loss: 2.4085001147465976
Validation loss: 2.6160785233791444

Epoch: 6| Step: 13
Training loss: 2.622714728191229
Validation loss: 2.61907384191031

Epoch: 102| Step: 0
Training loss: 3.158428686576361
Validation loss: 2.6429797859256485

Epoch: 6| Step: 1
Training loss: 2.655547643815531
Validation loss: 2.66961625300047

Epoch: 6| Step: 2
Training loss: 2.837643281117121
Validation loss: 2.699890812869306

Epoch: 6| Step: 3
Training loss: 3.3777033963574494
Validation loss: 2.796982373176887

Epoch: 6| Step: 4
Training loss: 2.497946945231749
Validation loss: 2.693263093005447

Epoch: 6| Step: 5
Training loss: 2.404453548281756
Validation loss: 2.608263455554114

Epoch: 6| Step: 6
Training loss: 2.902679218604454
Validation loss: 2.571730076834157

Epoch: 6| Step: 7
Training loss: 2.8816249644797787
Validation loss: 2.555435205212851

Epoch: 6| Step: 8
Training loss: 2.5676567479975025
Validation loss: 2.551614336454143

Epoch: 6| Step: 9
Training loss: 3.226018605792886
Validation loss: 2.5499620620186336

Epoch: 6| Step: 10
Training loss: 3.1357181611116287
Validation loss: 2.5515650146058837

Epoch: 6| Step: 11
Training loss: 3.094976933259314
Validation loss: 2.558691510591434

Epoch: 6| Step: 12
Training loss: 3.5717919954949826
Validation loss: 2.556862899283163

Epoch: 6| Step: 13
Training loss: 3.1721906833747324
Validation loss: 2.563502518029761

Epoch: 103| Step: 0
Training loss: 2.7473420389462215
Validation loss: 2.5615128157059233

Epoch: 6| Step: 1
Training loss: 3.3722718126427362
Validation loss: 2.5616032681857037

Epoch: 6| Step: 2
Training loss: 2.90595366905334
Validation loss: 2.55640698038739

Epoch: 6| Step: 3
Training loss: 2.798411538638912
Validation loss: 2.5574060447107434

Epoch: 6| Step: 4
Training loss: 2.8992655514655845
Validation loss: 2.5591240431102453

Epoch: 6| Step: 5
Training loss: 3.165175103380316
Validation loss: 2.553677315050357

Epoch: 6| Step: 6
Training loss: 3.1058624209990096
Validation loss: 2.5528690945853736

Epoch: 6| Step: 7
Training loss: 2.5844339569267514
Validation loss: 2.5551014432163464

Epoch: 6| Step: 8
Training loss: 3.3760960529909387
Validation loss: 2.551732642711047

Epoch: 6| Step: 9
Training loss: 2.815327558143733
Validation loss: 2.5516450322675586

Epoch: 6| Step: 10
Training loss: 3.551122735014686
Validation loss: 2.547520234490536

Epoch: 6| Step: 11
Training loss: 2.3177736308868524
Validation loss: 2.5501505377222666

Epoch: 6| Step: 12
Training loss: 2.339497077237297
Validation loss: 2.5483584250831925

Epoch: 6| Step: 13
Training loss: 2.6191796762853556
Validation loss: 2.5462193825761332

Epoch: 104| Step: 0
Training loss: 2.4059099229549403
Validation loss: 2.549394700017432

Epoch: 6| Step: 1
Training loss: 2.7166716425407413
Validation loss: 2.554888897439946

Epoch: 6| Step: 2
Training loss: 3.275917297493123
Validation loss: 2.570098061107856

Epoch: 6| Step: 3
Training loss: 3.303615242803761
Validation loss: 2.5744811627999926

Epoch: 6| Step: 4
Training loss: 2.420752579025507
Validation loss: 2.570438216740215

Epoch: 6| Step: 5
Training loss: 2.702392302421868
Validation loss: 2.561367866300273

Epoch: 6| Step: 6
Training loss: 2.8111732744506512
Validation loss: 2.551161816699786

Epoch: 6| Step: 7
Training loss: 2.9779229046517983
Validation loss: 2.5479473244950293

Epoch: 6| Step: 8
Training loss: 2.9296375321259647
Validation loss: 2.551936999795278

Epoch: 6| Step: 9
Training loss: 3.1936436704489792
Validation loss: 2.5579947367767164

Epoch: 6| Step: 10
Training loss: 2.590055845387617
Validation loss: 2.5525059992699926

Epoch: 6| Step: 11
Training loss: 3.0827707000698226
Validation loss: 2.5636071385314976

Epoch: 6| Step: 12
Training loss: 3.33304887193615
Validation loss: 2.5739298985882226

Epoch: 6| Step: 13
Training loss: 2.9115663530013682
Validation loss: 2.5719446437994824

Epoch: 105| Step: 0
Training loss: 2.3908230568616307
Validation loss: 2.5759171773264233

Epoch: 6| Step: 1
Training loss: 2.949793152103678
Validation loss: 2.567782681621041

Epoch: 6| Step: 2
Training loss: 2.695345051886765
Validation loss: 2.5677164168279387

Epoch: 6| Step: 3
Training loss: 3.6452667377344827
Validation loss: 2.5611540298075477

Epoch: 6| Step: 4
Training loss: 2.3394018911884493
Validation loss: 2.5413259610387646

Epoch: 6| Step: 5
Training loss: 3.1310972621922204
Validation loss: 2.5385232938173248

Epoch: 6| Step: 6
Training loss: 2.8475520948244752
Validation loss: 2.5355855418809905

Epoch: 6| Step: 7
Training loss: 2.378238076768699
Validation loss: 2.5403122878268984

Epoch: 6| Step: 8
Training loss: 3.6424960456989006
Validation loss: 2.5434596816150172

Epoch: 6| Step: 9
Training loss: 2.5352965611450866
Validation loss: 2.546485993470532

Epoch: 6| Step: 10
Training loss: 2.8728659629266353
Validation loss: 2.556893557654242

Epoch: 6| Step: 11
Training loss: 3.280754415234559
Validation loss: 2.564606434827736

Epoch: 6| Step: 12
Training loss: 3.220427437128124
Validation loss: 2.566999331590285

Epoch: 6| Step: 13
Training loss: 2.399842090180163
Validation loss: 2.5564074095984304

Epoch: 106| Step: 0
Training loss: 3.0304488863666483
Validation loss: 2.5559484686322884

Epoch: 6| Step: 1
Training loss: 3.1043425815242034
Validation loss: 2.5539134488847375

Epoch: 6| Step: 2
Training loss: 2.724424294369049
Validation loss: 2.551858876955402

Epoch: 6| Step: 3
Training loss: 3.284760259650452
Validation loss: 2.547372149039022

Epoch: 6| Step: 4
Training loss: 3.0494463120972912
Validation loss: 2.547269898130654

Epoch: 6| Step: 5
Training loss: 3.2538721053036705
Validation loss: 2.546208200564241

Epoch: 6| Step: 6
Training loss: 2.161278321150663
Validation loss: 2.541687795012267

Epoch: 6| Step: 7
Training loss: 2.600063040776035
Validation loss: 2.5387844744374592

Epoch: 6| Step: 8
Training loss: 3.1281714558843587
Validation loss: 2.543217674111583

Epoch: 6| Step: 9
Training loss: 2.296246708684316
Validation loss: 2.547375580814266

Epoch: 6| Step: 10
Training loss: 3.2997526654119196
Validation loss: 2.5522109980207683

Epoch: 6| Step: 11
Training loss: 2.95365230958933
Validation loss: 2.5499584065116867

Epoch: 6| Step: 12
Training loss: 2.7275375765022356
Validation loss: 2.5500766448265635

Epoch: 6| Step: 13
Training loss: 3.1185050608251528
Validation loss: 2.546676035093215

Epoch: 107| Step: 0
Training loss: 2.252798988575871
Validation loss: 2.543906446112023

Epoch: 6| Step: 1
Training loss: 2.7964869395155163
Validation loss: 2.5413825610771696

Epoch: 6| Step: 2
Training loss: 3.04263934603881
Validation loss: 2.548402682525807

Epoch: 6| Step: 3
Training loss: 2.908136063437259
Validation loss: 2.546406325130674

Epoch: 6| Step: 4
Training loss: 2.846930266094068
Validation loss: 2.5555833290327343

Epoch: 6| Step: 5
Training loss: 3.110918591612866
Validation loss: 2.5759224600236545

Epoch: 6| Step: 6
Training loss: 2.4815965386450785
Validation loss: 2.59360017033631

Epoch: 6| Step: 7
Training loss: 3.3872434568213143
Validation loss: 2.615268727421047

Epoch: 6| Step: 8
Training loss: 3.005945830313286
Validation loss: 2.6277671054549163

Epoch: 6| Step: 9
Training loss: 3.2005461941928144
Validation loss: 2.605207246331436

Epoch: 6| Step: 10
Training loss: 3.3022755146760696
Validation loss: 2.5597839568034626

Epoch: 6| Step: 11
Training loss: 2.4272860222745574
Validation loss: 2.5411702459199805

Epoch: 6| Step: 12
Training loss: 3.101076025490046
Validation loss: 2.5458060766340327

Epoch: 6| Step: 13
Training loss: 2.6837553505917477
Validation loss: 2.5792341087074955

Epoch: 108| Step: 0
Training loss: 2.9357773619907293
Validation loss: 2.591203940577838

Epoch: 6| Step: 1
Training loss: 2.8058620533060097
Validation loss: 2.604086157425911

Epoch: 6| Step: 2
Training loss: 2.757588147771656
Validation loss: 2.616885655860977

Epoch: 6| Step: 3
Training loss: 2.7579549693192904
Validation loss: 2.610635933336794

Epoch: 6| Step: 4
Training loss: 3.3761097531670514
Validation loss: 2.6072251461399594

Epoch: 6| Step: 5
Training loss: 2.8592435879553304
Validation loss: 2.6099748870590056

Epoch: 6| Step: 6
Training loss: 3.174071805549179
Validation loss: 2.6027364804524478

Epoch: 6| Step: 7
Training loss: 2.5297707839083388
Validation loss: 2.5733182435207222

Epoch: 6| Step: 8
Training loss: 3.006778212238198
Validation loss: 2.5595848415267395

Epoch: 6| Step: 9
Training loss: 2.5275069453807153
Validation loss: 2.5612446701218636

Epoch: 6| Step: 10
Training loss: 3.3273684219266095
Validation loss: 2.5579178031917245

Epoch: 6| Step: 11
Training loss: 3.424275988605851
Validation loss: 2.5399009694586407

Epoch: 6| Step: 12
Training loss: 2.942299837549771
Validation loss: 2.5356219389322203

Epoch: 6| Step: 13
Training loss: 2.4302247854744983
Validation loss: 2.5435959345761865

Epoch: 109| Step: 0
Training loss: 3.394291315060353
Validation loss: 2.5409576668441853

Epoch: 6| Step: 1
Training loss: 3.303429330251492
Validation loss: 2.5459695687918042

Epoch: 6| Step: 2
Training loss: 3.4667729422589404
Validation loss: 2.5557313931099013

Epoch: 6| Step: 3
Training loss: 2.0124626487914656
Validation loss: 2.574117321508582

Epoch: 6| Step: 4
Training loss: 2.7526398905755
Validation loss: 2.542149451680549

Epoch: 6| Step: 5
Training loss: 2.555237690419624
Validation loss: 2.5301112990513355

Epoch: 6| Step: 6
Training loss: 2.823722827471612
Validation loss: 2.528309372755333

Epoch: 6| Step: 7
Training loss: 2.761351737707828
Validation loss: 2.5236297933416525

Epoch: 6| Step: 8
Training loss: 2.7724131237071106
Validation loss: 2.5226173532304172

Epoch: 6| Step: 9
Training loss: 2.672216382442164
Validation loss: 2.5237752818584753

Epoch: 6| Step: 10
Training loss: 2.350064938236436
Validation loss: 2.524034812498199

Epoch: 6| Step: 11
Training loss: 2.8442546690112653
Validation loss: 2.5249380068954657

Epoch: 6| Step: 12
Training loss: 3.5793843947337747
Validation loss: 2.5295811241800856

Epoch: 6| Step: 13
Training loss: 2.8847264498334417
Validation loss: 2.526562347555174

Epoch: 110| Step: 0
Training loss: 2.790919607231337
Validation loss: 2.528661847213027

Epoch: 6| Step: 1
Training loss: 2.888438454586252
Validation loss: 2.5422269037972307

Epoch: 6| Step: 2
Training loss: 2.9619979368585154
Validation loss: 2.568934390117292

Epoch: 6| Step: 3
Training loss: 3.4107064309097495
Validation loss: 2.577127746437544

Epoch: 6| Step: 4
Training loss: 2.634349702507725
Validation loss: 2.59906951753934

Epoch: 6| Step: 5
Training loss: 3.413928834581273
Validation loss: 2.6332535321828727

Epoch: 6| Step: 6
Training loss: 3.152669556525327
Validation loss: 2.6097552247402445

Epoch: 6| Step: 7
Training loss: 2.885632962452803
Validation loss: 2.5889129973162555

Epoch: 6| Step: 8
Training loss: 2.2394697885044725
Validation loss: 2.5670169609329827

Epoch: 6| Step: 9
Training loss: 3.292952531840252
Validation loss: 2.554401690922294

Epoch: 6| Step: 10
Training loss: 2.533242465782124
Validation loss: 2.5357160376345074

Epoch: 6| Step: 11
Training loss: 2.8721254324658063
Validation loss: 2.5296991809167206

Epoch: 6| Step: 12
Training loss: 2.6716970641020557
Validation loss: 2.5188527480713314

Epoch: 6| Step: 13
Training loss: 2.5627704570676824
Validation loss: 2.517535037457492

Epoch: 111| Step: 0
Training loss: 2.8198464132649277
Validation loss: 2.51973235629876

Epoch: 6| Step: 1
Training loss: 2.6984060032723196
Validation loss: 2.516757036507241

Epoch: 6| Step: 2
Training loss: 2.764916884292307
Validation loss: 2.518082468236051

Epoch: 6| Step: 3
Training loss: 3.566930993407492
Validation loss: 2.5174987913356652

Epoch: 6| Step: 4
Training loss: 2.1709230381253453
Validation loss: 2.5181403552867243

Epoch: 6| Step: 5
Training loss: 2.755080991132601
Validation loss: 2.5203280619251385

Epoch: 6| Step: 6
Training loss: 2.561210493953189
Validation loss: 2.5153948266416113

Epoch: 6| Step: 7
Training loss: 3.3225980185351096
Validation loss: 2.519752207214785

Epoch: 6| Step: 8
Training loss: 2.6579751190903975
Validation loss: 2.5161714759617153

Epoch: 6| Step: 9
Training loss: 2.8354557353254073
Validation loss: 2.5176101603996

Epoch: 6| Step: 10
Training loss: 2.7077723778043086
Validation loss: 2.51660849468615

Epoch: 6| Step: 11
Training loss: 3.612037766395404
Validation loss: 2.515954283661909

Epoch: 6| Step: 12
Training loss: 2.997561735483062
Validation loss: 2.51428371965265

Epoch: 6| Step: 13
Training loss: 2.5207425776346533
Validation loss: 2.5138415159139673

Epoch: 112| Step: 0
Training loss: 3.4957936760187907
Validation loss: 2.514550245633699

Epoch: 6| Step: 1
Training loss: 2.92731740067705
Validation loss: 2.516723088443739

Epoch: 6| Step: 2
Training loss: 2.845604260572451
Validation loss: 2.5182180984168485

Epoch: 6| Step: 3
Training loss: 3.1768234063221166
Validation loss: 2.5288011004276982

Epoch: 6| Step: 4
Training loss: 2.9243466943690497
Validation loss: 2.5455523016289248

Epoch: 6| Step: 5
Training loss: 2.946787335901141
Validation loss: 2.559702881553822

Epoch: 6| Step: 6
Training loss: 3.0371701347921456
Validation loss: 2.564272272937977

Epoch: 6| Step: 7
Training loss: 2.425345020722507
Validation loss: 2.5539636629193914

Epoch: 6| Step: 8
Training loss: 2.9730379959793836
Validation loss: 2.5565361465931757

Epoch: 6| Step: 9
Training loss: 2.92817506533623
Validation loss: 2.532518462738672

Epoch: 6| Step: 10
Training loss: 2.63644050542882
Validation loss: 2.526932570406835

Epoch: 6| Step: 11
Training loss: 2.5520479991309264
Validation loss: 2.5220140014178067

Epoch: 6| Step: 12
Training loss: 2.5735930404490723
Validation loss: 2.5231750284726853

Epoch: 6| Step: 13
Training loss: 2.8338278918505058
Validation loss: 2.518125740354771

Epoch: 113| Step: 0
Training loss: 2.396413937305309
Validation loss: 2.5192687866837886

Epoch: 6| Step: 1
Training loss: 3.039098587410258
Validation loss: 2.5152969844574313

Epoch: 6| Step: 2
Training loss: 2.829606653382447
Validation loss: 2.5170690679165704

Epoch: 6| Step: 3
Training loss: 3.4653225022876066
Validation loss: 2.514132170447071

Epoch: 6| Step: 4
Training loss: 2.6576571159534073
Validation loss: 2.515796184479583

Epoch: 6| Step: 5
Training loss: 3.4411651492232274
Validation loss: 2.5197496066936593

Epoch: 6| Step: 6
Training loss: 2.2308621836200255
Validation loss: 2.5191583152486214

Epoch: 6| Step: 7
Training loss: 3.286566215151045
Validation loss: 2.5212662875140266

Epoch: 6| Step: 8
Training loss: 2.540438329166224
Validation loss: 2.5290873931215447

Epoch: 6| Step: 9
Training loss: 3.219927229917906
Validation loss: 2.5316443906409165

Epoch: 6| Step: 10
Training loss: 2.609313964129905
Validation loss: 2.5380451869696206

Epoch: 6| Step: 11
Training loss: 2.991896811924356
Validation loss: 2.555185796800662

Epoch: 6| Step: 12
Training loss: 2.558674818312538
Validation loss: 2.551277404732185

Epoch: 6| Step: 13
Training loss: 2.951108051975738
Validation loss: 2.530837100924743

Epoch: 114| Step: 0
Training loss: 2.8190137244976743
Validation loss: 2.5280361375557088

Epoch: 6| Step: 1
Training loss: 2.8127115805832057
Validation loss: 2.5363172609940516

Epoch: 6| Step: 2
Training loss: 3.210292185144752
Validation loss: 2.531779144432309

Epoch: 6| Step: 3
Training loss: 2.879300260043713
Validation loss: 2.5318258773129036

Epoch: 6| Step: 4
Training loss: 2.427225122416822
Validation loss: 2.53686197571353

Epoch: 6| Step: 5
Training loss: 2.810838674914746
Validation loss: 2.5404196000897423

Epoch: 6| Step: 6
Training loss: 3.0839788087742677
Validation loss: 2.5653213548116898

Epoch: 6| Step: 7
Training loss: 3.373373134011346
Validation loss: 2.5869113570592988

Epoch: 6| Step: 8
Training loss: 2.327550420327663
Validation loss: 2.5981356986127544

Epoch: 6| Step: 9
Training loss: 3.1244935197474564
Validation loss: 2.597509552258844

Epoch: 6| Step: 10
Training loss: 3.0037827484974504
Validation loss: 2.596646309444143

Epoch: 6| Step: 11
Training loss: 2.876441759914696
Validation loss: 2.579894552453582

Epoch: 6| Step: 12
Training loss: 2.498542646971256
Validation loss: 2.5660815557131533

Epoch: 6| Step: 13
Training loss: 3.3195916324545416
Validation loss: 2.550875369381129

Epoch: 115| Step: 0
Training loss: 2.8983930805432205
Validation loss: 2.5321895911983194

Epoch: 6| Step: 1
Training loss: 2.7208798714630644
Validation loss: 2.5178226376489277

Epoch: 6| Step: 2
Training loss: 2.9200530057825302
Validation loss: 2.511824100518799

Epoch: 6| Step: 3
Training loss: 2.9313022893540452
Validation loss: 2.5132691537972955

Epoch: 6| Step: 4
Training loss: 2.8429346278051546
Validation loss: 2.513732814058909

Epoch: 6| Step: 5
Training loss: 2.5798731570150153
Validation loss: 2.5167575743430715

Epoch: 6| Step: 6
Training loss: 2.5837353321797787
Validation loss: 2.513343132290224

Epoch: 6| Step: 7
Training loss: 2.8975779449011108
Validation loss: 2.512747666354625

Epoch: 6| Step: 8
Training loss: 2.854309765275139
Validation loss: 2.5172651199372105

Epoch: 6| Step: 9
Training loss: 3.4371590185108216
Validation loss: 2.5186910052535545

Epoch: 6| Step: 10
Training loss: 2.396904769374392
Validation loss: 2.5116212800706776

Epoch: 6| Step: 11
Training loss: 2.738897975195548
Validation loss: 2.507902508526231

Epoch: 6| Step: 12
Training loss: 3.22610063918773
Validation loss: 2.508297648114877

Epoch: 6| Step: 13
Training loss: 3.4895868709413427
Validation loss: 2.5210302471426016

Epoch: 116| Step: 0
Training loss: 2.726840204562912
Validation loss: 2.5461225748904432

Epoch: 6| Step: 1
Training loss: 3.3472866001155306
Validation loss: 2.572052886400688

Epoch: 6| Step: 2
Training loss: 3.1606367993035542
Validation loss: 2.669847571341278

Epoch: 6| Step: 3
Training loss: 3.0219331690368336
Validation loss: 2.750637349750392

Epoch: 6| Step: 4
Training loss: 3.3989648870151075
Validation loss: 2.830421702221748

Epoch: 6| Step: 5
Training loss: 2.768099954388011
Validation loss: 2.834132346665281

Epoch: 6| Step: 6
Training loss: 3.0471300849751626
Validation loss: 2.7404306352994303

Epoch: 6| Step: 7
Training loss: 2.2966193232018983
Validation loss: 2.6062769776323664

Epoch: 6| Step: 8
Training loss: 2.8478513213899834
Validation loss: 2.536733543954955

Epoch: 6| Step: 9
Training loss: 2.7961072667219655
Validation loss: 2.511337849250283

Epoch: 6| Step: 10
Training loss: 2.601649469061769
Validation loss: 2.509252823161291

Epoch: 6| Step: 11
Training loss: 3.292579636939459
Validation loss: 2.517358688864405

Epoch: 6| Step: 12
Training loss: 2.3973046028458054
Validation loss: 2.532135021145714

Epoch: 6| Step: 13
Training loss: 3.4898926706943736
Validation loss: 2.548279588917921

Epoch: 117| Step: 0
Training loss: 3.1255160096435413
Validation loss: 2.5805463689626746

Epoch: 6| Step: 1
Training loss: 3.028871212437598
Validation loss: 2.6219098878283416

Epoch: 6| Step: 2
Training loss: 2.8713478443046854
Validation loss: 2.6916746943326264

Epoch: 6| Step: 3
Training loss: 2.6822033518847554
Validation loss: 2.8024028515545587

Epoch: 6| Step: 4
Training loss: 3.110409051911797
Validation loss: 2.8239327138384085

Epoch: 6| Step: 5
Training loss: 3.5215121335307087
Validation loss: 2.832921885583898

Epoch: 6| Step: 6
Training loss: 2.828969249850829
Validation loss: 2.8172472886954023

Epoch: 6| Step: 7
Training loss: 2.5385418636889114
Validation loss: 2.7701147339487395

Epoch: 6| Step: 8
Training loss: 3.1807454666528745
Validation loss: 2.7163629421591904

Epoch: 6| Step: 9
Training loss: 3.374307066814214
Validation loss: 2.6895549231616154

Epoch: 6| Step: 10
Training loss: 3.0170787410405238
Validation loss: 2.682665940450233

Epoch: 6| Step: 11
Training loss: 3.3818056224727755
Validation loss: 2.6755325641343095

Epoch: 6| Step: 12
Training loss: 2.993363669679974
Validation loss: 2.670351396288892

Epoch: 6| Step: 13
Training loss: 3.3908983814759317
Validation loss: 2.66559611707108

Epoch: 118| Step: 0
Training loss: 2.803136710288127
Validation loss: 2.653974523814461

Epoch: 6| Step: 1
Training loss: 2.4977203465918785
Validation loss: 2.601944743287333

Epoch: 6| Step: 2
Training loss: 3.1238593499322564
Validation loss: 2.5779261378423914

Epoch: 6| Step: 3
Training loss: 2.777490625374233
Validation loss: 2.5706761069288273

Epoch: 6| Step: 4
Training loss: 2.9142699794184224
Validation loss: 2.556407752566079

Epoch: 6| Step: 5
Training loss: 2.732749935631389
Validation loss: 2.5532032437892314

Epoch: 6| Step: 6
Training loss: 3.3456389893699505
Validation loss: 2.5534623666648297

Epoch: 6| Step: 7
Training loss: 3.201610523494829
Validation loss: 2.602979425005811

Epoch: 6| Step: 8
Training loss: 2.4356336050490914
Validation loss: 2.6383514781787087

Epoch: 6| Step: 9
Training loss: 3.5432255324876323
Validation loss: 2.6857997154620823

Epoch: 6| Step: 10
Training loss: 2.5538422939149394
Validation loss: 2.6908025841639245

Epoch: 6| Step: 11
Training loss: 2.9740533941589873
Validation loss: 2.698610147688015

Epoch: 6| Step: 12
Training loss: 2.898973605606546
Validation loss: 2.6504560841198455

Epoch: 6| Step: 13
Training loss: 3.3206433658677126
Validation loss: 2.5748238458383566

Epoch: 119| Step: 0
Training loss: 3.134041789970928
Validation loss: 2.555326413696093

Epoch: 6| Step: 1
Training loss: 2.9891753411218125
Validation loss: 2.5417146457989808

Epoch: 6| Step: 2
Training loss: 3.250657528606502
Validation loss: 2.5361761359943347

Epoch: 6| Step: 3
Training loss: 3.0744422530829074
Validation loss: 2.5351392227552356

Epoch: 6| Step: 4
Training loss: 2.8705964572516534
Validation loss: 2.524089510954076

Epoch: 6| Step: 5
Training loss: 2.7745673658586827
Validation loss: 2.525766199127227

Epoch: 6| Step: 6
Training loss: 3.0512216716546825
Validation loss: 2.529179388401037

Epoch: 6| Step: 7
Training loss: 2.9505646116819677
Validation loss: 2.5237185510502957

Epoch: 6| Step: 8
Training loss: 2.9183922885391347
Validation loss: 2.520839455892975

Epoch: 6| Step: 9
Training loss: 2.835602375332912
Validation loss: 2.5236669550566866

Epoch: 6| Step: 10
Training loss: 3.095552786175993
Validation loss: 2.5204295607328984

Epoch: 6| Step: 11
Training loss: 2.3831428674027575
Validation loss: 2.518288381222889

Epoch: 6| Step: 12
Training loss: 2.6560875338067556
Validation loss: 2.5146576046719322

Epoch: 6| Step: 13
Training loss: 2.581271938572497
Validation loss: 2.5155043738989282

Epoch: 120| Step: 0
Training loss: 3.14600545315473
Validation loss: 2.5077129542703256

Epoch: 6| Step: 1
Training loss: 2.6821017497458945
Validation loss: 2.510272942092679

Epoch: 6| Step: 2
Training loss: 2.3020211005681372
Validation loss: 2.5014549502854257

Epoch: 6| Step: 3
Training loss: 2.584917956586854
Validation loss: 2.4986410959758434

Epoch: 6| Step: 4
Training loss: 3.2650730086338013
Validation loss: 2.493686436774884

Epoch: 6| Step: 5
Training loss: 2.5665482898348038
Validation loss: 2.4977834217005848

Epoch: 6| Step: 6
Training loss: 3.0124317715464786
Validation loss: 2.5024094553182534

Epoch: 6| Step: 7
Training loss: 2.8255878680784168
Validation loss: 2.5033403896601936

Epoch: 6| Step: 8
Training loss: 3.0459336611761807
Validation loss: 2.5089473564656317

Epoch: 6| Step: 9
Training loss: 3.322128409681082
Validation loss: 2.511542273719264

Epoch: 6| Step: 10
Training loss: 2.9394923819014798
Validation loss: 2.516704651968933

Epoch: 6| Step: 11
Training loss: 2.903170523065866
Validation loss: 2.531464397365064

Epoch: 6| Step: 12
Training loss: 2.5744519511569677
Validation loss: 2.525713051388001

Epoch: 6| Step: 13
Training loss: 3.608717292872625
Validation loss: 2.5148320396356687

Epoch: 121| Step: 0
Training loss: 3.172841342992929
Validation loss: 2.506713016900103

Epoch: 6| Step: 1
Training loss: 3.0938665194677037
Validation loss: 2.5057355649871473

Epoch: 6| Step: 2
Training loss: 2.901282875173902
Validation loss: 2.496552447746812

Epoch: 6| Step: 3
Training loss: 2.9286902599616003
Validation loss: 2.4986087824833674

Epoch: 6| Step: 4
Training loss: 3.4183069029154667
Validation loss: 2.501301092574778

Epoch: 6| Step: 5
Training loss: 2.4963527777864467
Validation loss: 2.505864052418918

Epoch: 6| Step: 6
Training loss: 2.7055376344261757
Validation loss: 2.50659401766848

Epoch: 6| Step: 7
Training loss: 2.969059335754912
Validation loss: 2.5131432203104502

Epoch: 6| Step: 8
Training loss: 2.6515891078857043
Validation loss: 2.5104147011938935

Epoch: 6| Step: 9
Training loss: 2.6074141941600355
Validation loss: 2.510092689408499

Epoch: 6| Step: 10
Training loss: 2.725672885515246
Validation loss: 2.5103153852877247

Epoch: 6| Step: 11
Training loss: 2.666490717884777
Validation loss: 2.510519320142619

Epoch: 6| Step: 12
Training loss: 3.333888262015318
Validation loss: 2.5080533649763948

Epoch: 6| Step: 13
Training loss: 2.8288448534615775
Validation loss: 2.5081021871191864

Epoch: 122| Step: 0
Training loss: 3.145586488314818
Validation loss: 2.504836820464717

Epoch: 6| Step: 1
Training loss: 2.2729962631913168
Validation loss: 2.5032595570961735

Epoch: 6| Step: 2
Training loss: 3.378704298742683
Validation loss: 2.5026395419897343

Epoch: 6| Step: 3
Training loss: 3.2891622424009337
Validation loss: 2.502984874826656

Epoch: 6| Step: 4
Training loss: 3.295172084314654
Validation loss: 2.497168838029408

Epoch: 6| Step: 5
Training loss: 2.4702439435582138
Validation loss: 2.5021941277929303

Epoch: 6| Step: 6
Training loss: 2.36955419894663
Validation loss: 2.504240817801822

Epoch: 6| Step: 7
Training loss: 2.4979340600136486
Validation loss: 2.5049817891013957

Epoch: 6| Step: 8
Training loss: 3.0129909574345755
Validation loss: 2.502885530412043

Epoch: 6| Step: 9
Training loss: 3.3875679262677707
Validation loss: 2.509869663257082

Epoch: 6| Step: 10
Training loss: 2.783249211515361
Validation loss: 2.512483914835575

Epoch: 6| Step: 11
Training loss: 2.6648379453015973
Validation loss: 2.5126665436363567

Epoch: 6| Step: 12
Training loss: 2.559371434024101
Validation loss: 2.5160824846261667

Epoch: 6| Step: 13
Training loss: 2.856369523567211
Validation loss: 2.5305080443022314

Epoch: 123| Step: 0
Training loss: 2.8900607821398654
Validation loss: 2.5267781181954465

Epoch: 6| Step: 1
Training loss: 2.5950038590889464
Validation loss: 2.530055954615276

Epoch: 6| Step: 2
Training loss: 2.8063159348658053
Validation loss: 2.52507046617747

Epoch: 6| Step: 3
Training loss: 2.339495854314762
Validation loss: 2.528952644411172

Epoch: 6| Step: 4
Training loss: 3.06281310057442
Validation loss: 2.544913902777368

Epoch: 6| Step: 5
Training loss: 3.565612771550706
Validation loss: 2.5280598406406476

Epoch: 6| Step: 6
Training loss: 2.9132648429705266
Validation loss: 2.5190745229802673

Epoch: 6| Step: 7
Training loss: 2.838901116713309
Validation loss: 2.504555629696609

Epoch: 6| Step: 8
Training loss: 2.8103626182869443
Validation loss: 2.500123907935841

Epoch: 6| Step: 9
Training loss: 2.86434121698163
Validation loss: 2.4924438557648783

Epoch: 6| Step: 10
Training loss: 2.3627004871373236
Validation loss: 2.490422805519185

Epoch: 6| Step: 11
Training loss: 2.670147074959824
Validation loss: 2.491851432176068

Epoch: 6| Step: 12
Training loss: 3.3086248799450515
Validation loss: 2.489767053303842

Epoch: 6| Step: 13
Training loss: 3.05213685146102
Validation loss: 2.4910874620140517

Epoch: 124| Step: 0
Training loss: 2.8930231817050505
Validation loss: 2.488995535232536

Epoch: 6| Step: 1
Training loss: 2.793518097744627
Validation loss: 2.488534271187077

Epoch: 6| Step: 2
Training loss: 2.9121319714289315
Validation loss: 2.490375145913114

Epoch: 6| Step: 3
Training loss: 3.3934776857271114
Validation loss: 2.49054927230369

Epoch: 6| Step: 4
Training loss: 2.8035354160706794
Validation loss: 2.4932304404239636

Epoch: 6| Step: 5
Training loss: 2.7789956718430338
Validation loss: 2.49126013704655

Epoch: 6| Step: 6
Training loss: 2.284132299302686
Validation loss: 2.4979248437834265

Epoch: 6| Step: 7
Training loss: 2.598052718804509
Validation loss: 2.4974417102208233

Epoch: 6| Step: 8
Training loss: 3.1280037748796947
Validation loss: 2.5058962518939376

Epoch: 6| Step: 9
Training loss: 3.4039936116625933
Validation loss: 2.5069330034322626

Epoch: 6| Step: 10
Training loss: 2.7396107274608923
Validation loss: 2.5030696563565265

Epoch: 6| Step: 11
Training loss: 2.6270720160712213
Validation loss: 2.5043715556782744

Epoch: 6| Step: 12
Training loss: 2.798040136669736
Validation loss: 2.4985695817796985

Epoch: 6| Step: 13
Training loss: 2.8034287712310815
Validation loss: 2.4999031796729247

Epoch: 125| Step: 0
Training loss: 2.230893176528582
Validation loss: 2.4997791510626137

Epoch: 6| Step: 1
Training loss: 2.7055935034765826
Validation loss: 2.4975752136000184

Epoch: 6| Step: 2
Training loss: 2.7844715105963562
Validation loss: 2.49238581573483

Epoch: 6| Step: 3
Training loss: 2.6085503468611404
Validation loss: 2.496297054615164

Epoch: 6| Step: 4
Training loss: 3.2139910729408316
Validation loss: 2.4910550772948747

Epoch: 6| Step: 5
Training loss: 2.879386872088444
Validation loss: 2.491196736751582

Epoch: 6| Step: 6
Training loss: 2.9563329318069917
Validation loss: 2.487608229925679

Epoch: 6| Step: 7
Training loss: 2.668546868126947
Validation loss: 2.487518676384289

Epoch: 6| Step: 8
Training loss: 3.0531593656606892
Validation loss: 2.4863992262361854

Epoch: 6| Step: 9
Training loss: 2.6802945797848095
Validation loss: 2.485327924528992

Epoch: 6| Step: 10
Training loss: 3.2645299800431586
Validation loss: 2.484077949743539

Epoch: 6| Step: 11
Training loss: 2.64245704435516
Validation loss: 2.4874503630522717

Epoch: 6| Step: 12
Training loss: 3.4176417254268925
Validation loss: 2.4845471107436454

Epoch: 6| Step: 13
Training loss: 2.731198891307738
Validation loss: 2.4876619320601026

Epoch: 126| Step: 0
Training loss: 2.673899101390878
Validation loss: 2.4859057108230234

Epoch: 6| Step: 1
Training loss: 2.584432388646369
Validation loss: 2.4887422869352402

Epoch: 6| Step: 2
Training loss: 3.436992815921968
Validation loss: 2.4893927006678953

Epoch: 6| Step: 3
Training loss: 3.303170074472938
Validation loss: 2.490162794390131

Epoch: 6| Step: 4
Training loss: 2.1719239593037227
Validation loss: 2.4978179556074953

Epoch: 6| Step: 5
Training loss: 2.961422520672669
Validation loss: 2.503804381375184

Epoch: 6| Step: 6
Training loss: 2.5947619382997305
Validation loss: 2.516291539789024

Epoch: 6| Step: 7
Training loss: 2.7309026850847014
Validation loss: 2.5192932102947037

Epoch: 6| Step: 8
Training loss: 2.6423894641461754
Validation loss: 2.5178086353584073

Epoch: 6| Step: 9
Training loss: 3.2837268019119263
Validation loss: 2.528666843376743

Epoch: 6| Step: 10
Training loss: 3.1699895657629376
Validation loss: 2.5254874822998197

Epoch: 6| Step: 11
Training loss: 2.5271490337472247
Validation loss: 2.545199156613004

Epoch: 6| Step: 12
Training loss: 2.9319421662667575
Validation loss: 2.5338963153715643

Epoch: 6| Step: 13
Training loss: 2.8164782045355037
Validation loss: 2.534801582790606

Epoch: 127| Step: 0
Training loss: 2.965005541019505
Validation loss: 2.5089979084545853

Epoch: 6| Step: 1
Training loss: 2.402065651776982
Validation loss: 2.4924594636763384

Epoch: 6| Step: 2
Training loss: 2.9329369999713224
Validation loss: 2.49276840502131

Epoch: 6| Step: 3
Training loss: 2.4949616206395553
Validation loss: 2.4874641755153926

Epoch: 6| Step: 4
Training loss: 3.1501803815753795
Validation loss: 2.486353455783188

Epoch: 6| Step: 5
Training loss: 2.8057588958911914
Validation loss: 2.486273778478964

Epoch: 6| Step: 6
Training loss: 2.5248717020507017
Validation loss: 2.4892127485960276

Epoch: 6| Step: 7
Training loss: 3.0665605056742216
Validation loss: 2.4916551069973125

Epoch: 6| Step: 8
Training loss: 3.0388403176333925
Validation loss: 2.491914401728654

Epoch: 6| Step: 9
Training loss: 2.5730757773516215
Validation loss: 2.490870510937315

Epoch: 6| Step: 10
Training loss: 2.7811141248794966
Validation loss: 2.489329364550451

Epoch: 6| Step: 11
Training loss: 3.112264392928284
Validation loss: 2.493710603088469

Epoch: 6| Step: 12
Training loss: 3.095415379963038
Validation loss: 2.4881322085255086

Epoch: 6| Step: 13
Training loss: 3.321242401952814
Validation loss: 2.4869183084113247

Epoch: 128| Step: 0
Training loss: 2.201710781412998
Validation loss: 2.489370093830995

Epoch: 6| Step: 1
Training loss: 3.2330670499447542
Validation loss: 2.4869723398460355

Epoch: 6| Step: 2
Training loss: 3.4954665660369613
Validation loss: 2.4873286220733175

Epoch: 6| Step: 3
Training loss: 2.6179025157266924
Validation loss: 2.4874454891988584

Epoch: 6| Step: 4
Training loss: 2.492190752655107
Validation loss: 2.489650971680667

Epoch: 6| Step: 5
Training loss: 3.10808624703668
Validation loss: 2.4881833626890457

Epoch: 6| Step: 6
Training loss: 2.5802297612577307
Validation loss: 2.4905456953186027

Epoch: 6| Step: 7
Training loss: 3.223854535742417
Validation loss: 2.491724067438643

Epoch: 6| Step: 8
Training loss: 2.6808610576239165
Validation loss: 2.4976889562425386

Epoch: 6| Step: 9
Training loss: 2.7799608478945195
Validation loss: 2.4960254371815136

Epoch: 6| Step: 10
Training loss: 2.8725082546079004
Validation loss: 2.504547362138347

Epoch: 6| Step: 11
Training loss: 3.1473545834110053
Validation loss: 2.529830963268987

Epoch: 6| Step: 12
Training loss: 2.8400522861234507
Validation loss: 2.5313817836497017

Epoch: 6| Step: 13
Training loss: 1.8500524874278008
Validation loss: 2.5531992585610093

Epoch: 129| Step: 0
Training loss: 3.127617769532025
Validation loss: 2.5615537693703203

Epoch: 6| Step: 1
Training loss: 3.369540001238491
Validation loss: 2.5973958972648856

Epoch: 6| Step: 2
Training loss: 2.987823570956309
Validation loss: 2.593561728294244

Epoch: 6| Step: 3
Training loss: 3.3875362549140244
Validation loss: 2.534551833127126

Epoch: 6| Step: 4
Training loss: 2.609938417928599
Validation loss: 2.50565028381896

Epoch: 6| Step: 5
Training loss: 2.6274858239514667
Validation loss: 2.4904819675088063

Epoch: 6| Step: 6
Training loss: 3.2064309528292094
Validation loss: 2.4813557204381165

Epoch: 6| Step: 7
Training loss: 2.467437781696424
Validation loss: 2.483900593862083

Epoch: 6| Step: 8
Training loss: 1.7966802076821455
Validation loss: 2.4849172474947494

Epoch: 6| Step: 9
Training loss: 3.3155618587885107
Validation loss: 2.4880231005828053

Epoch: 6| Step: 10
Training loss: 2.440389143602039
Validation loss: 2.4849568183164292

Epoch: 6| Step: 11
Training loss: 2.978887656069035
Validation loss: 2.4867561848985997

Epoch: 6| Step: 12
Training loss: 2.591017237144738
Validation loss: 2.4848332373642834

Epoch: 6| Step: 13
Training loss: 3.032031243709337
Validation loss: 2.48120499209466

Epoch: 130| Step: 0
Training loss: 2.604659611141327
Validation loss: 2.4871626744309094

Epoch: 6| Step: 1
Training loss: 3.106630887601834
Validation loss: 2.4928558180781253

Epoch: 6| Step: 2
Training loss: 2.7638507906419494
Validation loss: 2.498564865054092

Epoch: 6| Step: 3
Training loss: 2.9621653564990535
Validation loss: 2.521212544636105

Epoch: 6| Step: 4
Training loss: 1.98502837710912
Validation loss: 2.5344215100811147

Epoch: 6| Step: 5
Training loss: 2.6292318111355284
Validation loss: 2.542228316597767

Epoch: 6| Step: 6
Training loss: 2.951766413061066
Validation loss: 2.5379882135122

Epoch: 6| Step: 7
Training loss: 2.7872270801179044
Validation loss: 2.540663664668816

Epoch: 6| Step: 8
Training loss: 2.657818140632793
Validation loss: 2.5396126907496965

Epoch: 6| Step: 9
Training loss: 2.4987702205998144
Validation loss: 2.522789831417924

Epoch: 6| Step: 10
Training loss: 3.4886486718590715
Validation loss: 2.5123956316495875

Epoch: 6| Step: 11
Training loss: 3.2338521783623664
Validation loss: 2.494577069819075

Epoch: 6| Step: 12
Training loss: 3.2222055200896618
Validation loss: 2.4978669244375706

Epoch: 6| Step: 13
Training loss: 2.745392754672979
Validation loss: 2.501087318356344

Epoch: 131| Step: 0
Training loss: 2.2765129759460803
Validation loss: 2.4969090016493176

Epoch: 6| Step: 1
Training loss: 2.8558199101683504
Validation loss: 2.49085573394291

Epoch: 6| Step: 2
Training loss: 2.886728660969116
Validation loss: 2.4888711443458713

Epoch: 6| Step: 3
Training loss: 3.2264286041187376
Validation loss: 2.4849198731202007

Epoch: 6| Step: 4
Training loss: 2.3322794668728446
Validation loss: 2.4856272486464794

Epoch: 6| Step: 5
Training loss: 2.5438162567732516
Validation loss: 2.4863397103570493

Epoch: 6| Step: 6
Training loss: 2.4027604400754057
Validation loss: 2.481140899346698

Epoch: 6| Step: 7
Training loss: 3.20505521348834
Validation loss: 2.4791758671465147

Epoch: 6| Step: 8
Training loss: 3.0834224447484195
Validation loss: 2.4813582134550165

Epoch: 6| Step: 9
Training loss: 3.2060485895559583
Validation loss: 2.48227622244015

Epoch: 6| Step: 10
Training loss: 2.5128500661329762
Validation loss: 2.480050038602981

Epoch: 6| Step: 11
Training loss: 3.226983659426866
Validation loss: 2.479117492707896

Epoch: 6| Step: 12
Training loss: 3.0917509151471885
Validation loss: 2.4813926815073897

Epoch: 6| Step: 13
Training loss: 2.5079497778090962
Validation loss: 2.4838261574963623

Epoch: 132| Step: 0
Training loss: 2.993360165119627
Validation loss: 2.484597481282311

Epoch: 6| Step: 1
Training loss: 2.1701113998367494
Validation loss: 2.4857633527779903

Epoch: 6| Step: 2
Training loss: 2.9117404389347668
Validation loss: 2.4911985643969183

Epoch: 6| Step: 3
Training loss: 2.965889928337969
Validation loss: 2.4918108617686614

Epoch: 6| Step: 4
Training loss: 2.929045176982375
Validation loss: 2.5019690081382397

Epoch: 6| Step: 5
Training loss: 3.1448396709190334
Validation loss: 2.5123069096364916

Epoch: 6| Step: 6
Training loss: 3.129619083808956
Validation loss: 2.5146660969177135

Epoch: 6| Step: 7
Training loss: 2.1092663772307105
Validation loss: 2.5209643774735966

Epoch: 6| Step: 8
Training loss: 2.3703616173017448
Validation loss: 2.519068422930255

Epoch: 6| Step: 9
Training loss: 3.230022358064066
Validation loss: 2.536964928040938

Epoch: 6| Step: 10
Training loss: 2.527089030947844
Validation loss: 2.507444914270799

Epoch: 6| Step: 11
Training loss: 2.842351213115855
Validation loss: 2.4912660304305185

Epoch: 6| Step: 12
Training loss: 3.322019465867713
Validation loss: 2.4809700237568117

Epoch: 6| Step: 13
Training loss: 2.974198170804412
Validation loss: 2.4833135821139316

Epoch: 133| Step: 0
Training loss: 2.104029572304437
Validation loss: 2.4856380472322943

Epoch: 6| Step: 1
Training loss: 3.2606351411561945
Validation loss: 2.4848569460703107

Epoch: 6| Step: 2
Training loss: 3.3903181227233827
Validation loss: 2.481862718366336

Epoch: 6| Step: 3
Training loss: 3.5164896940082744
Validation loss: 2.47759306980223

Epoch: 6| Step: 4
Training loss: 2.8125159369123125
Validation loss: 2.4908028535585647

Epoch: 6| Step: 5
Training loss: 2.578708189691456
Validation loss: 2.482989220302087

Epoch: 6| Step: 6
Training loss: 3.042036547880807
Validation loss: 2.4843252337870627

Epoch: 6| Step: 7
Training loss: 2.5325737776558492
Validation loss: 2.472605986645532

Epoch: 6| Step: 8
Training loss: 2.7746860326536886
Validation loss: 2.480037402558355

Epoch: 6| Step: 9
Training loss: 2.7781043962673646
Validation loss: 2.478806618859199

Epoch: 6| Step: 10
Training loss: 2.3837662585963746
Validation loss: 2.485518142136946

Epoch: 6| Step: 11
Training loss: 3.339788068340664
Validation loss: 2.4866631902715874

Epoch: 6| Step: 12
Training loss: 2.391148927410043
Validation loss: 2.491285047226616

Epoch: 6| Step: 13
Training loss: 2.747182182694801
Validation loss: 2.49641959876537

Epoch: 134| Step: 0
Training loss: 2.8613101268631898
Validation loss: 2.4999000139648615

Epoch: 6| Step: 1
Training loss: 3.31165130107395
Validation loss: 2.5203114786987664

Epoch: 6| Step: 2
Training loss: 3.102672464770495
Validation loss: 2.5330598762385272

Epoch: 6| Step: 3
Training loss: 2.980822780875906
Validation loss: 2.51034873782335

Epoch: 6| Step: 4
Training loss: 2.7126942859455183
Validation loss: 2.5380776892672916

Epoch: 6| Step: 5
Training loss: 3.009221685669472
Validation loss: 2.5580862065886265

Epoch: 6| Step: 6
Training loss: 2.398549627112331
Validation loss: 2.5479039596707485

Epoch: 6| Step: 7
Training loss: 2.717653689280446
Validation loss: 2.550766959276988

Epoch: 6| Step: 8
Training loss: 3.1361676369742404
Validation loss: 2.5336849169315965

Epoch: 6| Step: 9
Training loss: 3.055156232769188
Validation loss: 2.523038105566109

Epoch: 6| Step: 10
Training loss: 2.024471180943182
Validation loss: 2.510148447446027

Epoch: 6| Step: 11
Training loss: 2.7514346455335947
Validation loss: 2.499601108763435

Epoch: 6| Step: 12
Training loss: 2.579168120236416
Validation loss: 2.4824147513041224

Epoch: 6| Step: 13
Training loss: 3.3629972579450316
Validation loss: 2.4864103256322725

Epoch: 135| Step: 0
Training loss: 2.373920195204692
Validation loss: 2.490420372016966

Epoch: 6| Step: 1
Training loss: 3.106753063337609
Validation loss: 2.5643437073425153

Epoch: 6| Step: 2
Training loss: 3.003791320745165
Validation loss: 2.639709759663536

Epoch: 6| Step: 3
Training loss: 2.695651356501676
Validation loss: 2.7732442476247443

Epoch: 6| Step: 4
Training loss: 3.8045012567512804
Validation loss: 2.808965061677323

Epoch: 6| Step: 5
Training loss: 3.065933949246157
Validation loss: 2.758208697146769

Epoch: 6| Step: 6
Training loss: 3.146755630668754
Validation loss: 2.6362660563356646

Epoch: 6| Step: 7
Training loss: 2.885944267723521
Validation loss: 2.5625065519067545

Epoch: 6| Step: 8
Training loss: 2.5724749063615495
Validation loss: 2.512610855762926

Epoch: 6| Step: 9
Training loss: 2.9816012449498874
Validation loss: 2.4745731538394278

Epoch: 6| Step: 10
Training loss: 2.8385485354465825
Validation loss: 2.473516374800803

Epoch: 6| Step: 11
Training loss: 2.4625591445248993
Validation loss: 2.474501682753473

Epoch: 6| Step: 12
Training loss: 2.9884112959345863
Validation loss: 2.479647587613549

Epoch: 6| Step: 13
Training loss: 2.801513916547511
Validation loss: 2.4957087059308427

Epoch: 136| Step: 0
Training loss: 2.7089395773772096
Validation loss: 2.5098533735372883

Epoch: 6| Step: 1
Training loss: 2.8445119989671457
Validation loss: 2.537018466571748

Epoch: 6| Step: 2
Training loss: 2.7220563405503513
Validation loss: 2.5759742513797876

Epoch: 6| Step: 3
Training loss: 2.4970621967444866
Validation loss: 2.5665366530067613

Epoch: 6| Step: 4
Training loss: 2.545374703393642
Validation loss: 2.5794032860954195

Epoch: 6| Step: 5
Training loss: 3.060905820128621
Validation loss: 2.5870846927933964

Epoch: 6| Step: 6
Training loss: 3.0889917638588
Validation loss: 2.570741349052849

Epoch: 6| Step: 7
Training loss: 3.3225891206957594
Validation loss: 2.556236107552276

Epoch: 6| Step: 8
Training loss: 2.691024420994207
Validation loss: 2.5370586919775624

Epoch: 6| Step: 9
Training loss: 3.703187579821305
Validation loss: 2.503895083796348

Epoch: 6| Step: 10
Training loss: 2.2527963427703606
Validation loss: 2.5044865742240647

Epoch: 6| Step: 11
Training loss: 2.992638138185612
Validation loss: 2.510568313875856

Epoch: 6| Step: 12
Training loss: 3.387972308238242
Validation loss: 2.5377082023594073

Epoch: 6| Step: 13
Training loss: 2.758218189690529
Validation loss: 2.54785387473969

Epoch: 137| Step: 0
Training loss: 3.0866967148550684
Validation loss: 2.517053895242074

Epoch: 6| Step: 1
Training loss: 3.0303031779780496
Validation loss: 2.501165204612616

Epoch: 6| Step: 2
Training loss: 2.647822575932104
Validation loss: 2.487102501148659

Epoch: 6| Step: 3
Training loss: 2.3123146189023567
Validation loss: 2.477764237254654

Epoch: 6| Step: 4
Training loss: 2.981163653836708
Validation loss: 2.464973800554227

Epoch: 6| Step: 5
Training loss: 2.667514298748387
Validation loss: 2.474611109226405

Epoch: 6| Step: 6
Training loss: 2.987191833180081
Validation loss: 2.4648127085449167

Epoch: 6| Step: 7
Training loss: 3.000449782668497
Validation loss: 2.466462174549948

Epoch: 6| Step: 8
Training loss: 2.741500377153381
Validation loss: 2.470755596674556

Epoch: 6| Step: 9
Training loss: 2.782054141945886
Validation loss: 2.4765371301470247

Epoch: 6| Step: 10
Training loss: 3.026291714884588
Validation loss: 2.5025442139131266

Epoch: 6| Step: 11
Training loss: 3.4912818229254774
Validation loss: 2.5219918902972807

Epoch: 6| Step: 12
Training loss: 2.2617446818866362
Validation loss: 2.5168919701081807

Epoch: 6| Step: 13
Training loss: 2.260961007059953
Validation loss: 2.4732244801880907

Epoch: 138| Step: 0
Training loss: 2.7468598383809475
Validation loss: 2.4758354070213544

Epoch: 6| Step: 1
Training loss: 3.124044806409411
Validation loss: 2.4754038839478296

Epoch: 6| Step: 2
Training loss: 2.827109728928659
Validation loss: 2.4730072034214707

Epoch: 6| Step: 3
Training loss: 3.0758433914399075
Validation loss: 2.477097975349549

Epoch: 6| Step: 4
Training loss: 2.8145499494047166
Validation loss: 2.4797054786551693

Epoch: 6| Step: 5
Training loss: 1.997316765909193
Validation loss: 2.480099010937294

Epoch: 6| Step: 6
Training loss: 3.2961484280192375
Validation loss: 2.5000097192554844

Epoch: 6| Step: 7
Training loss: 3.0329775262711265
Validation loss: 2.5265901900944656

Epoch: 6| Step: 8
Training loss: 3.030504587290517
Validation loss: 2.5396737432425183

Epoch: 6| Step: 9
Training loss: 2.819585394715986
Validation loss: 2.528194893483145

Epoch: 6| Step: 10
Training loss: 2.8745538116530134
Validation loss: 2.526702143633568

Epoch: 6| Step: 11
Training loss: 3.182867835663579
Validation loss: 2.5161666872886985

Epoch: 6| Step: 12
Training loss: 2.6856258866217884
Validation loss: 2.509566098171176

Epoch: 6| Step: 13
Training loss: 2.04732164940605
Validation loss: 2.5025672487740924

Epoch: 139| Step: 0
Training loss: 2.9627932568357624
Validation loss: 2.5103339228122397

Epoch: 6| Step: 1
Training loss: 3.0485508149328964
Validation loss: 2.5140608378961056

Epoch: 6| Step: 2
Training loss: 2.80070548706585
Validation loss: 2.5053745180800506

Epoch: 6| Step: 3
Training loss: 2.527292430893188
Validation loss: 2.497760418673984

Epoch: 6| Step: 4
Training loss: 2.966176413271543
Validation loss: 2.4924030352838065

Epoch: 6| Step: 5
Training loss: 2.617969817340921
Validation loss: 2.4991027555029004

Epoch: 6| Step: 6
Training loss: 2.6049939685246497
Validation loss: 2.4975175581619973

Epoch: 6| Step: 7
Training loss: 2.897870525008306
Validation loss: 2.506990008753995

Epoch: 6| Step: 8
Training loss: 2.4379761059711256
Validation loss: 2.508317589525597

Epoch: 6| Step: 9
Training loss: 3.2827169862893686
Validation loss: 2.5105136006217847

Epoch: 6| Step: 10
Training loss: 2.992935764386883
Validation loss: 2.523141316120753

Epoch: 6| Step: 11
Training loss: 2.9125372037025827
Validation loss: 2.5172132063091097

Epoch: 6| Step: 12
Training loss: 3.0524607003046405
Validation loss: 2.509078693065623

Epoch: 6| Step: 13
Training loss: 2.207033410535447
Validation loss: 2.498658870578396

Epoch: 140| Step: 0
Training loss: 2.7149508887357556
Validation loss: 2.5149164391095877

Epoch: 6| Step: 1
Training loss: 3.233478514043545
Validation loss: 2.512630895581193

Epoch: 6| Step: 2
Training loss: 2.6556284457763666
Validation loss: 2.510679631958745

Epoch: 6| Step: 3
Training loss: 3.19815168645809
Validation loss: 2.500398585631944

Epoch: 6| Step: 4
Training loss: 3.054371224735332
Validation loss: 2.503125617946776

Epoch: 6| Step: 5
Training loss: 2.8420042611183476
Validation loss: 2.499226360185532

Epoch: 6| Step: 6
Training loss: 2.4279623990988797
Validation loss: 2.5041277976212997

Epoch: 6| Step: 7
Training loss: 2.3408565717362775
Validation loss: 2.521727209648689

Epoch: 6| Step: 8
Training loss: 2.7529519449980424
Validation loss: 2.5360706709692273

Epoch: 6| Step: 9
Training loss: 2.676675510637329
Validation loss: 2.5509877293988015

Epoch: 6| Step: 10
Training loss: 2.678073942216314
Validation loss: 2.5135115143423903

Epoch: 6| Step: 11
Training loss: 3.023518563694439
Validation loss: 2.4976584861954465

Epoch: 6| Step: 12
Training loss: 3.4221599582138253
Validation loss: 2.486037704240457

Epoch: 6| Step: 13
Training loss: 2.0041026712564545
Validation loss: 2.483889827974959

Epoch: 141| Step: 0
Training loss: 2.5502557140114686
Validation loss: 2.478284216704549

Epoch: 6| Step: 1
Training loss: 3.259853391568628
Validation loss: 2.475568781165035

Epoch: 6| Step: 2
Training loss: 2.94106287680779
Validation loss: 2.4751316796229395

Epoch: 6| Step: 3
Training loss: 3.262985842254068
Validation loss: 2.475830721538297

Epoch: 6| Step: 4
Training loss: 2.404776679474273
Validation loss: 2.4718714148260243

Epoch: 6| Step: 5
Training loss: 2.9102394860160214
Validation loss: 2.475957063908615

Epoch: 6| Step: 6
Training loss: 2.1431513448115553
Validation loss: 2.471852288603923

Epoch: 6| Step: 7
Training loss: 2.9011550050211348
Validation loss: 2.4775711924027783

Epoch: 6| Step: 8
Training loss: 2.9194877786643514
Validation loss: 2.4764067427245573

Epoch: 6| Step: 9
Training loss: 3.167741459266963
Validation loss: 2.4774351121510203

Epoch: 6| Step: 10
Training loss: 3.2392137977017943
Validation loss: 2.480096423622905

Epoch: 6| Step: 11
Training loss: 2.1729367083036397
Validation loss: 2.492505368852823

Epoch: 6| Step: 12
Training loss: 2.321832948614515
Validation loss: 2.507638190146516

Epoch: 6| Step: 13
Training loss: 3.41074599577287
Validation loss: 2.521062592553099

Epoch: 142| Step: 0
Training loss: 2.287150029994663
Validation loss: 2.530194266827516

Epoch: 6| Step: 1
Training loss: 2.7495480079268098
Validation loss: 2.536702873868805

Epoch: 6| Step: 2
Training loss: 2.782698436286403
Validation loss: 2.5347898588784963

Epoch: 6| Step: 3
Training loss: 2.7417967428252745
Validation loss: 2.572041184272979

Epoch: 6| Step: 4
Training loss: 2.600895426688441
Validation loss: 2.6056797929566837

Epoch: 6| Step: 5
Training loss: 3.3292188682489887
Validation loss: 2.6153908001429356

Epoch: 6| Step: 6
Training loss: 3.1603115123806456
Validation loss: 2.60809720640223

Epoch: 6| Step: 7
Training loss: 2.1134424624059758
Validation loss: 2.6224155682919785

Epoch: 6| Step: 8
Training loss: 2.9682976629079842
Validation loss: 2.5772959977594723

Epoch: 6| Step: 9
Training loss: 3.304018787155125
Validation loss: 2.5332563220442297

Epoch: 6| Step: 10
Training loss: 3.1543437375582344
Validation loss: 2.4963081459463434

Epoch: 6| Step: 11
Training loss: 2.399849441892137
Validation loss: 2.474878809897209

Epoch: 6| Step: 12
Training loss: 2.9783997159824036
Validation loss: 2.477862904494368

Epoch: 6| Step: 13
Training loss: 2.809965220606053
Validation loss: 2.4765506691179575

Epoch: 143| Step: 0
Training loss: 2.6673197145324914
Validation loss: 2.482196432849316

Epoch: 6| Step: 1
Training loss: 2.7805444915564914
Validation loss: 2.4817861869376765

Epoch: 6| Step: 2
Training loss: 2.5323177958220144
Validation loss: 2.4772797657327477

Epoch: 6| Step: 3
Training loss: 2.6403684773642
Validation loss: 2.4751454665764743

Epoch: 6| Step: 4
Training loss: 3.293350577701822
Validation loss: 2.476207409183223

Epoch: 6| Step: 5
Training loss: 3.0053313884080057
Validation loss: 2.4768210158687527

Epoch: 6| Step: 6
Training loss: 2.072372160536118
Validation loss: 2.4841141019745105

Epoch: 6| Step: 7
Training loss: 2.723029615943727
Validation loss: 2.4888981951494653

Epoch: 6| Step: 8
Training loss: 3.0026354340080226
Validation loss: 2.4973629394741046

Epoch: 6| Step: 9
Training loss: 3.0712637556091718
Validation loss: 2.4995077838154423

Epoch: 6| Step: 10
Training loss: 2.708531788132947
Validation loss: 2.4943876478609934

Epoch: 6| Step: 11
Training loss: 2.8786153866380713
Validation loss: 2.490528508219619

Epoch: 6| Step: 12
Training loss: 3.3774530891193235
Validation loss: 2.483531580429066

Epoch: 6| Step: 13
Training loss: 3.000248580806407
Validation loss: 2.5065596215487527

Epoch: 144| Step: 0
Training loss: 3.156586279753544
Validation loss: 2.511610479899449

Epoch: 6| Step: 1
Training loss: 3.413979116857535
Validation loss: 2.5111658095649765

Epoch: 6| Step: 2
Training loss: 3.0647481335056184
Validation loss: 2.519239902591179

Epoch: 6| Step: 3
Training loss: 3.2637460952437385
Validation loss: 2.5442155947115075

Epoch: 6| Step: 4
Training loss: 2.139593836663555
Validation loss: 2.5523402982271657

Epoch: 6| Step: 5
Training loss: 2.7090898973173307
Validation loss: 2.564300454839535

Epoch: 6| Step: 6
Training loss: 2.8911323720684714
Validation loss: 2.5890798777776096

Epoch: 6| Step: 7
Training loss: 2.889495463961638
Validation loss: 2.5995566995136077

Epoch: 6| Step: 8
Training loss: 2.993054615403156
Validation loss: 2.5822122015341593

Epoch: 6| Step: 9
Training loss: 2.238720063606292
Validation loss: 2.55053180965609

Epoch: 6| Step: 10
Training loss: 2.688404995443422
Validation loss: 2.532084653664631

Epoch: 6| Step: 11
Training loss: 2.8935110170620355
Validation loss: 2.5101833494639103

Epoch: 6| Step: 12
Training loss: 2.8088866016154626
Validation loss: 2.5074182440125345

Epoch: 6| Step: 13
Training loss: 2.1231668082212067
Validation loss: 2.5102491262030937

Epoch: 145| Step: 0
Training loss: 3.016071662041346
Validation loss: 2.5109912842892723

Epoch: 6| Step: 1
Training loss: 2.5479947302507795
Validation loss: 2.517230868102644

Epoch: 6| Step: 2
Training loss: 3.0926195641782055
Validation loss: 2.516812752836347

Epoch: 6| Step: 3
Training loss: 3.0029866928024234
Validation loss: 2.511555941438524

Epoch: 6| Step: 4
Training loss: 2.562439894552807
Validation loss: 2.5125410544026283

Epoch: 6| Step: 5
Training loss: 2.684947997855859
Validation loss: 2.516735461861534

Epoch: 6| Step: 6
Training loss: 2.598953359187583
Validation loss: 2.5247703066831018

Epoch: 6| Step: 7
Training loss: 2.8651917707296035
Validation loss: 2.510199010991787

Epoch: 6| Step: 8
Training loss: 2.9709588115742704
Validation loss: 2.5338440878765804

Epoch: 6| Step: 9
Training loss: 2.6806300871594666
Validation loss: 2.558918748204106

Epoch: 6| Step: 10
Training loss: 2.691615214215298
Validation loss: 2.564671868341942

Epoch: 6| Step: 11
Training loss: 3.4532346405989016
Validation loss: 2.5753772321089436

Epoch: 6| Step: 12
Training loss: 2.6869032441221115
Validation loss: 2.64625236003677

Epoch: 6| Step: 13
Training loss: 2.5155109829860973
Validation loss: 2.684147461941359

Epoch: 146| Step: 0
Training loss: 3.6886249701246467
Validation loss: 2.714296287779253

Epoch: 6| Step: 1
Training loss: 3.4840974568905687
Validation loss: 2.689128932480379

Epoch: 6| Step: 2
Training loss: 3.092429755977377
Validation loss: 2.645834456651788

Epoch: 6| Step: 3
Training loss: 3.198826729740049
Validation loss: 2.6038057804875705

Epoch: 6| Step: 4
Training loss: 2.713749463306657
Validation loss: 2.5913802469353775

Epoch: 6| Step: 5
Training loss: 2.696409494265773
Validation loss: 2.5655014014509447

Epoch: 6| Step: 6
Training loss: 2.847077654964978
Validation loss: 2.537992730708402

Epoch: 6| Step: 7
Training loss: 2.1965081159518585
Validation loss: 2.5087087192187654

Epoch: 6| Step: 8
Training loss: 2.254970147385678
Validation loss: 2.4801008746702773

Epoch: 6| Step: 9
Training loss: 2.714902237735537
Validation loss: 2.47110703374601

Epoch: 6| Step: 10
Training loss: 2.860074984227734
Validation loss: 2.4763552769646253

Epoch: 6| Step: 11
Training loss: 3.1077441055036963
Validation loss: 2.4866099650458113

Epoch: 6| Step: 12
Training loss: 2.7708146708918817
Validation loss: 2.499747940400472

Epoch: 6| Step: 13
Training loss: 3.160262475037922
Validation loss: 2.5157094931191364

Epoch: 147| Step: 0
Training loss: 2.7542982322982756
Validation loss: 2.510749409509582

Epoch: 6| Step: 1
Training loss: 2.2648147712740556
Validation loss: 2.492985320505601

Epoch: 6| Step: 2
Training loss: 2.8431472978034105
Validation loss: 2.4863719688373704

Epoch: 6| Step: 3
Training loss: 3.1601565517807333
Validation loss: 2.4811451894000034

Epoch: 6| Step: 4
Training loss: 3.4410098104073787
Validation loss: 2.4703858276500306

Epoch: 6| Step: 5
Training loss: 2.67763340465405
Validation loss: 2.477284875871932

Epoch: 6| Step: 6
Training loss: 2.365810585553097
Validation loss: 2.4817431628614828

Epoch: 6| Step: 7
Training loss: 2.973514147365457
Validation loss: 2.497835361451647

Epoch: 6| Step: 8
Training loss: 2.4898023522307606
Validation loss: 2.5204640121930253

Epoch: 6| Step: 9
Training loss: 2.7314561360171683
Validation loss: 2.50583545884823

Epoch: 6| Step: 10
Training loss: 3.254228482084631
Validation loss: 2.5295114971981425

Epoch: 6| Step: 11
Training loss: 3.4767602757122194
Validation loss: 2.5440897057433887

Epoch: 6| Step: 12
Training loss: 2.73472871944839
Validation loss: 2.5516234295948648

Epoch: 6| Step: 13
Training loss: 2.437631065561807
Validation loss: 2.537920414198983

Epoch: 148| Step: 0
Training loss: 2.75716386034552
Validation loss: 2.53649197616109

Epoch: 6| Step: 1
Training loss: 2.7948090152626195
Validation loss: 2.5313622953500845

Epoch: 6| Step: 2
Training loss: 2.4752039507439223
Validation loss: 2.5047395735064897

Epoch: 6| Step: 3
Training loss: 3.1001745236399785
Validation loss: 2.489007059764524

Epoch: 6| Step: 4
Training loss: 2.80961053558929
Validation loss: 2.4817350290063174

Epoch: 6| Step: 5
Training loss: 2.594781877174323
Validation loss: 2.4780688355408884

Epoch: 6| Step: 6
Training loss: 3.217053753452077
Validation loss: 2.4753014000540356

Epoch: 6| Step: 7
Training loss: 2.5849483015546375
Validation loss: 2.47327520000609

Epoch: 6| Step: 8
Training loss: 2.396999064471174
Validation loss: 2.47725334765595

Epoch: 6| Step: 9
Training loss: 3.56183631470331
Validation loss: 2.471803222890213

Epoch: 6| Step: 10
Training loss: 2.4846396635140726
Validation loss: 2.479291303863594

Epoch: 6| Step: 11
Training loss: 2.6181082401208178
Validation loss: 2.4683998870047588

Epoch: 6| Step: 12
Training loss: 2.8555545820077044
Validation loss: 2.4842941803497216

Epoch: 6| Step: 13
Training loss: 3.2587211677262014
Validation loss: 2.4903743656130417

Epoch: 149| Step: 0
Training loss: 3.035701668336437
Validation loss: 2.500931754857657

Epoch: 6| Step: 1
Training loss: 2.7523419205039334
Validation loss: 2.5033824680548107

Epoch: 6| Step: 2
Training loss: 3.236139820355364
Validation loss: 2.4941013869608732

Epoch: 6| Step: 3
Training loss: 3.3308667275557995
Validation loss: 2.492214545667252

Epoch: 6| Step: 4
Training loss: 3.012801830319149
Validation loss: 2.486719912314927

Epoch: 6| Step: 5
Training loss: 2.5778289624956874
Validation loss: 2.489785690277037

Epoch: 6| Step: 6
Training loss: 2.5269633600909587
Validation loss: 2.493220222776697

Epoch: 6| Step: 7
Training loss: 2.512367840987166
Validation loss: 2.4900525317231246

Epoch: 6| Step: 8
Training loss: 3.0356790492473116
Validation loss: 2.489504392030263

Epoch: 6| Step: 9
Training loss: 2.660815186749792
Validation loss: 2.504582079148739

Epoch: 6| Step: 10
Training loss: 2.2400937821987843
Validation loss: 2.51303007411177

Epoch: 6| Step: 11
Training loss: 2.5333096636954693
Validation loss: 2.513784945398721

Epoch: 6| Step: 12
Training loss: 2.7943827004391637
Validation loss: 2.5177154385191964

Epoch: 6| Step: 13
Training loss: 2.80498704931088
Validation loss: 2.527365832557157

Epoch: 150| Step: 0
Training loss: 2.68599623371238
Validation loss: 2.5142171287351296

Epoch: 6| Step: 1
Training loss: 3.137132211230854
Validation loss: 2.494185465221229

Epoch: 6| Step: 2
Training loss: 3.109422539582404
Validation loss: 2.4871290578686467

Epoch: 6| Step: 3
Training loss: 2.04408015113048
Validation loss: 2.4812706670780944

Epoch: 6| Step: 4
Training loss: 3.169354118228728
Validation loss: 2.4777801688800296

Epoch: 6| Step: 5
Training loss: 2.878540678377284
Validation loss: 2.4771292944185728

Epoch: 6| Step: 6
Training loss: 2.267771473608496
Validation loss: 2.480704290801513

Epoch: 6| Step: 7
Training loss: 2.910192952788687
Validation loss: 2.477662480608337

Epoch: 6| Step: 8
Training loss: 1.7862254473825394
Validation loss: 2.4806697914818017

Epoch: 6| Step: 9
Training loss: 3.4237009689647455
Validation loss: 2.478322819700725

Epoch: 6| Step: 10
Training loss: 2.9038151211277947
Validation loss: 2.479416736810766

Epoch: 6| Step: 11
Training loss: 3.3732538297831196
Validation loss: 2.4802669428518853

Epoch: 6| Step: 12
Training loss: 2.868080935444169
Validation loss: 2.4796625384056097

Epoch: 6| Step: 13
Training loss: 2.670802921909564
Validation loss: 2.485581228817686

Epoch: 151| Step: 0
Training loss: 3.016731177917067
Validation loss: 2.5002892819052622

Epoch: 6| Step: 1
Training loss: 2.6096268035550616
Validation loss: 2.5119247815151424

Epoch: 6| Step: 2
Training loss: 2.825203245160398
Validation loss: 2.5211436383147894

Epoch: 6| Step: 3
Training loss: 3.379326202226516
Validation loss: 2.5431305183129784

Epoch: 6| Step: 4
Training loss: 2.2858013579268848
Validation loss: 2.544277799289066

Epoch: 6| Step: 5
Training loss: 2.755490111356631
Validation loss: 2.542864938817932

Epoch: 6| Step: 6
Training loss: 2.5004348376715213
Validation loss: 2.5060581596510727

Epoch: 6| Step: 7
Training loss: 2.8287971498720994
Validation loss: 2.494680165096165

Epoch: 6| Step: 8
Training loss: 3.241663731930801
Validation loss: 2.498352118850721

Epoch: 6| Step: 9
Training loss: 2.7105067018004902
Validation loss: 2.4680405066238715

Epoch: 6| Step: 10
Training loss: 2.5821539637596778
Validation loss: 2.479764992483382

Epoch: 6| Step: 11
Training loss: 2.630503017926293
Validation loss: 2.474258837408217

Epoch: 6| Step: 12
Training loss: 3.2020291570590436
Validation loss: 2.4772057130652247

Epoch: 6| Step: 13
Training loss: 2.7016042499835264
Validation loss: 2.4747058423462303

Epoch: 152| Step: 0
Training loss: 2.7520601185453137
Validation loss: 2.475329047080278

Epoch: 6| Step: 1
Training loss: 2.445113396384552
Validation loss: 2.4736449889796863

Epoch: 6| Step: 2
Training loss: 2.3439983999227327
Validation loss: 2.475274377245922

Epoch: 6| Step: 3
Training loss: 3.7049374551165752
Validation loss: 2.4791792258026124

Epoch: 6| Step: 4
Training loss: 3.156464522219329
Validation loss: 2.4772782434515

Epoch: 6| Step: 5
Training loss: 2.6200193656322166
Validation loss: 2.4686308022411674

Epoch: 6| Step: 6
Training loss: 2.908830379068937
Validation loss: 2.4842371067468343

Epoch: 6| Step: 7
Training loss: 2.4096700960128654
Validation loss: 2.4865262863551902

Epoch: 6| Step: 8
Training loss: 2.7317185931791284
Validation loss: 2.499688953102601

Epoch: 6| Step: 9
Training loss: 3.064013048985834
Validation loss: 2.5133916191220447

Epoch: 6| Step: 10
Training loss: 2.323643409619548
Validation loss: 2.525351793329934

Epoch: 6| Step: 11
Training loss: 3.0388768784190554
Validation loss: 2.514555882057705

Epoch: 6| Step: 12
Training loss: 2.837824086238186
Validation loss: 2.508571929534756

Epoch: 6| Step: 13
Training loss: 2.9037254607682303
Validation loss: 2.5085147036459

Epoch: 153| Step: 0
Training loss: 2.9153922066764877
Validation loss: 2.494115890326447

Epoch: 6| Step: 1
Training loss: 3.466852304794549
Validation loss: 2.49608727129057

Epoch: 6| Step: 2
Training loss: 2.528721335187793
Validation loss: 2.5062738389980503

Epoch: 6| Step: 3
Training loss: 2.799586170132833
Validation loss: 2.5020133740322015

Epoch: 6| Step: 4
Training loss: 2.518596339685626
Validation loss: 2.4898052702749567

Epoch: 6| Step: 5
Training loss: 2.361389108884762
Validation loss: 2.479092356339471

Epoch: 6| Step: 6
Training loss: 3.3765961440147665
Validation loss: 2.478197882762102

Epoch: 6| Step: 7
Training loss: 2.7231338060265973
Validation loss: 2.4730139395580006

Epoch: 6| Step: 8
Training loss: 2.162760539153431
Validation loss: 2.48227462783018

Epoch: 6| Step: 9
Training loss: 3.4667718418990567
Validation loss: 2.475776200501992

Epoch: 6| Step: 10
Training loss: 2.6490636214856584
Validation loss: 2.4723837307234007

Epoch: 6| Step: 11
Training loss: 2.523547474262848
Validation loss: 2.4767209946227977

Epoch: 6| Step: 12
Training loss: 2.2103870367089065
Validation loss: 2.483015696086112

Epoch: 6| Step: 13
Training loss: 3.278375438218755
Validation loss: 2.4874123752912687

Epoch: 154| Step: 0
Training loss: 2.814266667222042
Validation loss: 2.477558615112925

Epoch: 6| Step: 1
Training loss: 2.2850421061903843
Validation loss: 2.4865887216495097

Epoch: 6| Step: 2
Training loss: 3.070651513716424
Validation loss: 2.4861842542066017

Epoch: 6| Step: 3
Training loss: 3.261375326933765
Validation loss: 2.4863223127103797

Epoch: 6| Step: 4
Training loss: 3.008519315034076
Validation loss: 2.484807118320778

Epoch: 6| Step: 5
Training loss: 3.030455337656015
Validation loss: 2.495677899428066

Epoch: 6| Step: 6
Training loss: 2.3344544260589437
Validation loss: 2.498465684524772

Epoch: 6| Step: 7
Training loss: 1.9920699739383891
Validation loss: 2.4923595433761054

Epoch: 6| Step: 8
Training loss: 2.8554089666493114
Validation loss: 2.4959629678108173

Epoch: 6| Step: 9
Training loss: 1.9703463183169665
Validation loss: 2.4786046205283045

Epoch: 6| Step: 10
Training loss: 3.2785198661152273
Validation loss: 2.485941218751482

Epoch: 6| Step: 11
Training loss: 2.892521416560934
Validation loss: 2.4992770944370863

Epoch: 6| Step: 12
Training loss: 3.0463138943977333
Validation loss: 2.5012247746304324

Epoch: 6| Step: 13
Training loss: 2.838647309650141
Validation loss: 2.5067095509332926

Epoch: 155| Step: 0
Training loss: 2.4114128311730845
Validation loss: 2.507574484716945

Epoch: 6| Step: 1
Training loss: 2.946021847086464
Validation loss: 2.5008586285823933

Epoch: 6| Step: 2
Training loss: 2.8627919277271903
Validation loss: 2.4916103056090866

Epoch: 6| Step: 3
Training loss: 2.1944049303169786
Validation loss: 2.4827676254119457

Epoch: 6| Step: 4
Training loss: 3.1100087502408584
Validation loss: 2.503553970468705

Epoch: 6| Step: 5
Training loss: 3.0629535261384055
Validation loss: 2.4986093406421155

Epoch: 6| Step: 6
Training loss: 2.6634860044254527
Validation loss: 2.49469047952774

Epoch: 6| Step: 7
Training loss: 2.683640036815386
Validation loss: 2.485620789068853

Epoch: 6| Step: 8
Training loss: 2.7447906050176334
Validation loss: 2.4718674478181772

Epoch: 6| Step: 9
Training loss: 2.5550088942759284
Validation loss: 2.4812000481127234

Epoch: 6| Step: 10
Training loss: 2.94907145353403
Validation loss: 2.4760858878039724

Epoch: 6| Step: 11
Training loss: 3.038933209412397
Validation loss: 2.469404544771982

Epoch: 6| Step: 12
Training loss: 2.2399266770828183
Validation loss: 2.470936332674794

Epoch: 6| Step: 13
Training loss: 3.6490360398022093
Validation loss: 2.4676090936014283

Epoch: 156| Step: 0
Training loss: 2.6461266983274014
Validation loss: 2.4649575006687297

Epoch: 6| Step: 1
Training loss: 2.9464533288749513
Validation loss: 2.4655203545149083

Epoch: 6| Step: 2
Training loss: 2.531831745125695
Validation loss: 2.4690362554834353

Epoch: 6| Step: 3
Training loss: 3.1842292011040243
Validation loss: 2.4721532863278575

Epoch: 6| Step: 4
Training loss: 2.353187886445184
Validation loss: 2.470666881851386

Epoch: 6| Step: 5
Training loss: 2.8662879634560663
Validation loss: 2.475758366717235

Epoch: 6| Step: 6
Training loss: 3.2331369582905785
Validation loss: 2.4750420692856743

Epoch: 6| Step: 7
Training loss: 2.732147181175365
Validation loss: 2.4757228820479478

Epoch: 6| Step: 8
Training loss: 2.9325497086288412
Validation loss: 2.4787779851755394

Epoch: 6| Step: 9
Training loss: 2.9122552662462144
Validation loss: 2.4829716226236624

Epoch: 6| Step: 10
Training loss: 2.458159510614896
Validation loss: 2.4865140183026293

Epoch: 6| Step: 11
Training loss: 2.5380996521729307
Validation loss: 2.4853389296849366

Epoch: 6| Step: 12
Training loss: 2.5726318098726644
Validation loss: 2.4743904621498296

Epoch: 6| Step: 13
Training loss: 3.1101189878215596
Validation loss: 2.4875367077238804

Epoch: 157| Step: 0
Training loss: 2.627460325832621
Validation loss: 2.474940983812478

Epoch: 6| Step: 1
Training loss: 2.3986118514219297
Validation loss: 2.483653623134218

Epoch: 6| Step: 2
Training loss: 3.2447797959765223
Validation loss: 2.47672260522954

Epoch: 6| Step: 3
Training loss: 2.51495399766717
Validation loss: 2.469448163778783

Epoch: 6| Step: 4
Training loss: 2.8889851635597843
Validation loss: 2.488240526593449

Epoch: 6| Step: 5
Training loss: 2.8259785130595763
Validation loss: 2.5074251545561657

Epoch: 6| Step: 6
Training loss: 3.260348350776064
Validation loss: 2.5050442842967313

Epoch: 6| Step: 7
Training loss: 2.9072355834697965
Validation loss: 2.504645852501429

Epoch: 6| Step: 8
Training loss: 2.625867518625476
Validation loss: 2.4883712046806634

Epoch: 6| Step: 9
Training loss: 2.828703088847601
Validation loss: 2.4802946208347327

Epoch: 6| Step: 10
Training loss: 2.2172537043058047
Validation loss: 2.4783158331801958

Epoch: 6| Step: 11
Training loss: 2.9936946728398093
Validation loss: 2.4732783376008394

Epoch: 6| Step: 12
Training loss: 2.87969835582556
Validation loss: 2.4682839980426903

Epoch: 6| Step: 13
Training loss: 2.6528825844593067
Validation loss: 2.462927721613062

Epoch: 158| Step: 0
Training loss: 3.027903331599319
Validation loss: 2.4683574059570303

Epoch: 6| Step: 1
Training loss: 2.848603853608803
Validation loss: 2.466343338131418

Epoch: 6| Step: 2
Training loss: 3.1765385061578453
Validation loss: 2.4671485787924663

Epoch: 6| Step: 3
Training loss: 3.036564209511521
Validation loss: 2.4700328089618466

Epoch: 6| Step: 4
Training loss: 2.9120270111696662
Validation loss: 2.4715505333273677

Epoch: 6| Step: 5
Training loss: 2.852498274592848
Validation loss: 2.4673385074203678

Epoch: 6| Step: 6
Training loss: 2.5922035294968993
Validation loss: 2.4630490938625798

Epoch: 6| Step: 7
Training loss: 2.45096128250601
Validation loss: 2.4712145129112613

Epoch: 6| Step: 8
Training loss: 2.6630495892160972
Validation loss: 2.4688572692204334

Epoch: 6| Step: 9
Training loss: 2.9540820311854334
Validation loss: 2.471314126306085

Epoch: 6| Step: 10
Training loss: 2.559972307234231
Validation loss: 2.469210596136288

Epoch: 6| Step: 11
Training loss: 2.268663355326172
Validation loss: 2.4757731447701445

Epoch: 6| Step: 12
Training loss: 3.212514077241089
Validation loss: 2.4812698653173353

Epoch: 6| Step: 13
Training loss: 1.91272530070133
Validation loss: 2.479659427498625

Epoch: 159| Step: 0
Training loss: 3.16359347411035
Validation loss: 2.4688217040521665

Epoch: 6| Step: 1
Training loss: 2.4757394475949868
Validation loss: 2.469263858466366

Epoch: 6| Step: 2
Training loss: 2.47733340614587
Validation loss: 2.4576230529065337

Epoch: 6| Step: 3
Training loss: 2.3424986486929757
Validation loss: 2.4713710035420537

Epoch: 6| Step: 4
Training loss: 2.2927665036378775
Validation loss: 2.4778474513973214

Epoch: 6| Step: 5
Training loss: 2.8068777049256948
Validation loss: 2.476908799214916

Epoch: 6| Step: 6
Training loss: 3.2936103168669724
Validation loss: 2.4962722735277247

Epoch: 6| Step: 7
Training loss: 2.1195775579222977
Validation loss: 2.4876165733615663

Epoch: 6| Step: 8
Training loss: 3.2185968158899363
Validation loss: 2.4770132373888294

Epoch: 6| Step: 9
Training loss: 2.9922188938974004
Validation loss: 2.486394559629036

Epoch: 6| Step: 10
Training loss: 2.566460502898779
Validation loss: 2.485851740254862

Epoch: 6| Step: 11
Training loss: 2.553690024412456
Validation loss: 2.4864287856793044

Epoch: 6| Step: 12
Training loss: 3.1586216240576905
Validation loss: 2.4747977707703384

Epoch: 6| Step: 13
Training loss: 3.2433365222043564
Validation loss: 2.47376568616815

Epoch: 160| Step: 0
Training loss: 2.000522664440151
Validation loss: 2.479908932794484

Epoch: 6| Step: 1
Training loss: 2.8838715714259044
Validation loss: 2.4655215294852235

Epoch: 6| Step: 2
Training loss: 2.7041522593376484
Validation loss: 2.475501025579917

Epoch: 6| Step: 3
Training loss: 3.4057588835673682
Validation loss: 2.4677682515670836

Epoch: 6| Step: 4
Training loss: 2.3392541107405793
Validation loss: 2.4687795646354145

Epoch: 6| Step: 5
Training loss: 2.8852360160455044
Validation loss: 2.4613393564521955

Epoch: 6| Step: 6
Training loss: 3.1600077703839147
Validation loss: 2.471937354379601

Epoch: 6| Step: 7
Training loss: 2.508602790257866
Validation loss: 2.472316006060736

Epoch: 6| Step: 8
Training loss: 2.975654042900859
Validation loss: 2.4887447509209233

Epoch: 6| Step: 9
Training loss: 2.4955154250441534
Validation loss: 2.4820348504520857

Epoch: 6| Step: 10
Training loss: 3.0109118062117255
Validation loss: 2.496376837159752

Epoch: 6| Step: 11
Training loss: 2.9295457322470084
Validation loss: 2.497118437720908

Epoch: 6| Step: 12
Training loss: 2.654358762759241
Validation loss: 2.501072874892401

Epoch: 6| Step: 13
Training loss: 2.453266115442577
Validation loss: 2.5030864285779018

Epoch: 161| Step: 0
Training loss: 2.902663448177172
Validation loss: 2.5062071978985494

Epoch: 6| Step: 1
Training loss: 2.6903663253938546
Validation loss: 2.501817287824108

Epoch: 6| Step: 2
Training loss: 3.0453199281792744
Validation loss: 2.5156797508702424

Epoch: 6| Step: 3
Training loss: 2.8225834123096876
Validation loss: 2.513970906072761

Epoch: 6| Step: 4
Training loss: 2.8333530051352556
Validation loss: 2.4993839099546755

Epoch: 6| Step: 5
Training loss: 2.2328006559876012
Validation loss: 2.495357348504789

Epoch: 6| Step: 6
Training loss: 3.21106758689496
Validation loss: 2.4913308567340597

Epoch: 6| Step: 7
Training loss: 2.368015660620789
Validation loss: 2.4774969316616295

Epoch: 6| Step: 8
Training loss: 2.4335313424670098
Validation loss: 2.4717648468566207

Epoch: 6| Step: 9
Training loss: 2.3468873451609187
Validation loss: 2.4712297346506116

Epoch: 6| Step: 10
Training loss: 2.983987992842911
Validation loss: 2.478122418528271

Epoch: 6| Step: 11
Training loss: 2.883196880073849
Validation loss: 2.483916389112359

Epoch: 6| Step: 12
Training loss: 3.3123629559652397
Validation loss: 2.4736474949495992

Epoch: 6| Step: 13
Training loss: 2.3069700156099957
Validation loss: 2.4657770971773356

Epoch: 162| Step: 0
Training loss: 2.990692003988329
Validation loss: 2.462408200527744

Epoch: 6| Step: 1
Training loss: 3.260263815192464
Validation loss: 2.466374889395553

Epoch: 6| Step: 2
Training loss: 2.508500429673108
Validation loss: 2.4601767827046768

Epoch: 6| Step: 3
Training loss: 2.722435218453647
Validation loss: 2.4645527094375943

Epoch: 6| Step: 4
Training loss: 3.1530571831025442
Validation loss: 2.4666403909008205

Epoch: 6| Step: 5
Training loss: 3.2048153766653615
Validation loss: 2.4585222780321443

Epoch: 6| Step: 6
Training loss: 2.0940417186148217
Validation loss: 2.4642802240547526

Epoch: 6| Step: 7
Training loss: 2.741380099902663
Validation loss: 2.468036528264715

Epoch: 6| Step: 8
Training loss: 2.913844368878077
Validation loss: 2.45986659742828

Epoch: 6| Step: 9
Training loss: 2.6886350319657604
Validation loss: 2.4643020145065098

Epoch: 6| Step: 10
Training loss: 2.252793802794147
Validation loss: 2.460811866877842

Epoch: 6| Step: 11
Training loss: 3.011933909052049
Validation loss: 2.4713072237078157

Epoch: 6| Step: 12
Training loss: 2.8139030347817697
Validation loss: 2.4796295857519124

Epoch: 6| Step: 13
Training loss: 1.7963724511656498
Validation loss: 2.484062211766509

Epoch: 163| Step: 0
Training loss: 3.0038941858096493
Validation loss: 2.482338670650795

Epoch: 6| Step: 1
Training loss: 2.779077946182336
Validation loss: 2.4866205686338643

Epoch: 6| Step: 2
Training loss: 3.2406046117216643
Validation loss: 2.4822415693931275

Epoch: 6| Step: 3
Training loss: 2.565500317237669
Validation loss: 2.5049624198387277

Epoch: 6| Step: 4
Training loss: 2.7562987411929614
Validation loss: 2.505494102184179

Epoch: 6| Step: 5
Training loss: 2.773420478876026
Validation loss: 2.5152464204520384

Epoch: 6| Step: 6
Training loss: 3.061091507858336
Validation loss: 2.500932728677964

Epoch: 6| Step: 7
Training loss: 2.0954429272957915
Validation loss: 2.4893916945279617

Epoch: 6| Step: 8
Training loss: 2.79460554911975
Validation loss: 2.48013811285744

Epoch: 6| Step: 9
Training loss: 2.4979809237103767
Validation loss: 2.4541056762695828

Epoch: 6| Step: 10
Training loss: 2.542219341620271
Validation loss: 2.457579440995195

Epoch: 6| Step: 11
Training loss: 3.10605279000956
Validation loss: 2.4559920010280964

Epoch: 6| Step: 12
Training loss: 2.8891584645534385
Validation loss: 2.4669285476684086

Epoch: 6| Step: 13
Training loss: 2.885017027647652
Validation loss: 2.468518843550093

Epoch: 164| Step: 0
Training loss: 3.0518912470828634
Validation loss: 2.4694337937598267

Epoch: 6| Step: 1
Training loss: 2.6365366328888626
Validation loss: 2.4688196116620755

Epoch: 6| Step: 2
Training loss: 3.239940922045451
Validation loss: 2.4697133878375794

Epoch: 6| Step: 3
Training loss: 3.52515851469277
Validation loss: 2.479934922519603

Epoch: 6| Step: 4
Training loss: 3.2045332627399636
Validation loss: 2.476589617961302

Epoch: 6| Step: 5
Training loss: 2.7716098834942406
Validation loss: 2.4933099211232523

Epoch: 6| Step: 6
Training loss: 2.421642366126792
Validation loss: 2.506672838390444

Epoch: 6| Step: 7
Training loss: 2.0196629966395676
Validation loss: 2.516286047849911

Epoch: 6| Step: 8
Training loss: 2.717809317074741
Validation loss: 2.5477697563632153

Epoch: 6| Step: 9
Training loss: 3.242785883457264
Validation loss: 2.565334036466248

Epoch: 6| Step: 10
Training loss: 2.216205588647209
Validation loss: 2.577038506369277

Epoch: 6| Step: 11
Training loss: 3.060723860150684
Validation loss: 2.56610687348232

Epoch: 6| Step: 12
Training loss: 1.956191074836697
Validation loss: 2.5409600620356048

Epoch: 6| Step: 13
Training loss: 3.143250539855013
Validation loss: 2.507817034748741

Epoch: 165| Step: 0
Training loss: 2.4433668885088813
Validation loss: 2.507193433916467

Epoch: 6| Step: 1
Training loss: 2.620042661217626
Validation loss: 2.4949789035852254

Epoch: 6| Step: 2
Training loss: 2.695097718457743
Validation loss: 2.487918171429134

Epoch: 6| Step: 3
Training loss: 2.4770311940969862
Validation loss: 2.488623277230688

Epoch: 6| Step: 4
Training loss: 2.597085761045605
Validation loss: 2.492506042546212

Epoch: 6| Step: 5
Training loss: 3.153140661013588
Validation loss: 2.4913570555615716

Epoch: 6| Step: 6
Training loss: 2.9999446863797155
Validation loss: 2.4945919804631544

Epoch: 6| Step: 7
Training loss: 2.8371764280034055
Validation loss: 2.49259678481033

Epoch: 6| Step: 8
Training loss: 3.1425593098799713
Validation loss: 2.500208117938737

Epoch: 6| Step: 9
Training loss: 3.0977373725880653
Validation loss: 2.4984807043263477

Epoch: 6| Step: 10
Training loss: 2.7925915016476117
Validation loss: 2.4733802124244004

Epoch: 6| Step: 11
Training loss: 2.588989577247736
Validation loss: 2.480222751290774

Epoch: 6| Step: 12
Training loss: 3.1413338084336564
Validation loss: 2.4738392438652097

Epoch: 6| Step: 13
Training loss: 2.485205841289184
Validation loss: 2.481528986899046

Epoch: 166| Step: 0
Training loss: 2.3114260680009804
Validation loss: 2.4874270480341663

Epoch: 6| Step: 1
Training loss: 2.8585729255762224
Validation loss: 2.4966413250458

Epoch: 6| Step: 2
Training loss: 2.3761793521209724
Validation loss: 2.5018358719205995

Epoch: 6| Step: 3
Training loss: 2.8318731434853253
Validation loss: 2.4985703646506305

Epoch: 6| Step: 4
Training loss: 3.2267779631638076
Validation loss: 2.514677792314178

Epoch: 6| Step: 5
Training loss: 2.96271165824031
Validation loss: 2.5004511016023105

Epoch: 6| Step: 6
Training loss: 2.8604154101038146
Validation loss: 2.506619267406087

Epoch: 6| Step: 7
Training loss: 2.5604561819488683
Validation loss: 2.505437442445252

Epoch: 6| Step: 8
Training loss: 3.0827433219220475
Validation loss: 2.508368000901166

Epoch: 6| Step: 9
Training loss: 3.0275332286973664
Validation loss: 2.500956657886457

Epoch: 6| Step: 10
Training loss: 2.5406654345308293
Validation loss: 2.480256945709332

Epoch: 6| Step: 11
Training loss: 2.2454240679646946
Validation loss: 2.475191954901001

Epoch: 6| Step: 12
Training loss: 3.014339034474772
Validation loss: 2.466690324757451

Epoch: 6| Step: 13
Training loss: 3.0122142735389716
Validation loss: 2.468595429048514

Epoch: 167| Step: 0
Training loss: 2.858010555389325
Validation loss: 2.4559460887353715

Epoch: 6| Step: 1
Training loss: 2.4161557501553554
Validation loss: 2.459735940203103

Epoch: 6| Step: 2
Training loss: 2.8773787236114394
Validation loss: 2.4560523410266373

Epoch: 6| Step: 3
Training loss: 2.724485289233098
Validation loss: 2.4530947278220676

Epoch: 6| Step: 4
Training loss: 2.5476790955006723
Validation loss: 2.462580962698299

Epoch: 6| Step: 5
Training loss: 2.569529683758359
Validation loss: 2.456444949564286

Epoch: 6| Step: 6
Training loss: 2.089220756294144
Validation loss: 2.45719675104394

Epoch: 6| Step: 7
Training loss: 3.2240326132816812
Validation loss: 2.454876364089733

Epoch: 6| Step: 8
Training loss: 3.4104859497514646
Validation loss: 2.459615639580295

Epoch: 6| Step: 9
Training loss: 2.496662009540012
Validation loss: 2.4546898722584123

Epoch: 6| Step: 10
Training loss: 2.4329170768081085
Validation loss: 2.4587745590347647

Epoch: 6| Step: 11
Training loss: 2.9161390826490132
Validation loss: 2.4632404990291903

Epoch: 6| Step: 12
Training loss: 2.933825528148233
Validation loss: 2.4753758711348346

Epoch: 6| Step: 13
Training loss: 2.9451172457867725
Validation loss: 2.4848398114459056

Epoch: 168| Step: 0
Training loss: 2.6255379988347523
Validation loss: 2.503792038252747

Epoch: 6| Step: 1
Training loss: 2.7858480100010232
Validation loss: 2.507512817325517

Epoch: 6| Step: 2
Training loss: 2.553552124453508
Validation loss: 2.5147282015826513

Epoch: 6| Step: 3
Training loss: 2.587899929965583
Validation loss: 2.517941961455561

Epoch: 6| Step: 4
Training loss: 2.122263324244105
Validation loss: 2.4989789672301166

Epoch: 6| Step: 5
Training loss: 2.660308250980396
Validation loss: 2.510704672129143

Epoch: 6| Step: 6
Training loss: 2.488422192185498
Validation loss: 2.484618907824151

Epoch: 6| Step: 7
Training loss: 3.2488178157149767
Validation loss: 2.4747660171533457

Epoch: 6| Step: 8
Training loss: 3.0235728152253465
Validation loss: 2.4584580246087193

Epoch: 6| Step: 9
Training loss: 2.9918021409610596
Validation loss: 2.458349011640434

Epoch: 6| Step: 10
Training loss: 2.9091246139676255
Validation loss: 2.4574050763710513

Epoch: 6| Step: 11
Training loss: 2.7634302256047443
Validation loss: 2.4536504956629543

Epoch: 6| Step: 12
Training loss: 2.98036683634532
Validation loss: 2.45640064253387

Epoch: 6| Step: 13
Training loss: 3.176064116207932
Validation loss: 2.4477462014509315

Epoch: 169| Step: 0
Training loss: 3.2412724318134516
Validation loss: 2.450935677986118

Epoch: 6| Step: 1
Training loss: 2.6035942872763487
Validation loss: 2.4588809966715415

Epoch: 6| Step: 2
Training loss: 2.494066253724289
Validation loss: 2.4511782371021056

Epoch: 6| Step: 3
Training loss: 2.8780347314982926
Validation loss: 2.45845680350838

Epoch: 6| Step: 4
Training loss: 2.0705867945505423
Validation loss: 2.4575679224311298

Epoch: 6| Step: 5
Training loss: 2.6311450058383414
Validation loss: 2.459651871509366

Epoch: 6| Step: 6
Training loss: 2.9842797708546733
Validation loss: 2.4594040689356924

Epoch: 6| Step: 7
Training loss: 3.163397372943834
Validation loss: 2.4630921384758464

Epoch: 6| Step: 8
Training loss: 2.5102348631140403
Validation loss: 2.465651268758481

Epoch: 6| Step: 9
Training loss: 2.9191284326446505
Validation loss: 2.476665515516259

Epoch: 6| Step: 10
Training loss: 1.7921111272687498
Validation loss: 2.487018448353473

Epoch: 6| Step: 11
Training loss: 3.0900371119668644
Validation loss: 2.495305789703191

Epoch: 6| Step: 12
Training loss: 3.18856913270101
Validation loss: 2.494552458685775

Epoch: 6| Step: 13
Training loss: 2.5712626362046413
Validation loss: 2.5015685944078374

Epoch: 170| Step: 0
Training loss: 3.1054249886362393
Validation loss: 2.507557016635047

Epoch: 6| Step: 1
Training loss: 2.388608992490472
Validation loss: 2.5053423743189827

Epoch: 6| Step: 2
Training loss: 3.30071537471247
Validation loss: 2.5084807452132467

Epoch: 6| Step: 3
Training loss: 2.402069224977597
Validation loss: 2.492633971563428

Epoch: 6| Step: 4
Training loss: 2.8248796758092714
Validation loss: 2.4909747393913886

Epoch: 6| Step: 5
Training loss: 2.5850103738897596
Validation loss: 2.4979549000632013

Epoch: 6| Step: 6
Training loss: 2.793582278002516
Validation loss: 2.5039417591385993

Epoch: 6| Step: 7
Training loss: 2.8067660054849424
Validation loss: 2.49131220662315

Epoch: 6| Step: 8
Training loss: 2.7509397288257844
Validation loss: 2.4832495375945043

Epoch: 6| Step: 9
Training loss: 2.398951273510365
Validation loss: 2.472289153345198

Epoch: 6| Step: 10
Training loss: 2.6193933101916103
Validation loss: 2.461013558900822

Epoch: 6| Step: 11
Training loss: 3.1909020911641126
Validation loss: 2.4622761203234584

Epoch: 6| Step: 12
Training loss: 2.355240590952859
Validation loss: 2.461414819677991

Epoch: 6| Step: 13
Training loss: 3.0768984756953435
Validation loss: 2.457378028377543

Epoch: 171| Step: 0
Training loss: 3.1301029502829643
Validation loss: 2.4673694880064123

Epoch: 6| Step: 1
Training loss: 3.228286098068361
Validation loss: 2.4695667210303665

Epoch: 6| Step: 2
Training loss: 3.0009090317918408
Validation loss: 2.4760331283951476

Epoch: 6| Step: 3
Training loss: 2.5766387354466573
Validation loss: 2.4796957542539015

Epoch: 6| Step: 4
Training loss: 2.089676267383496
Validation loss: 2.4917993100798004

Epoch: 6| Step: 5
Training loss: 1.8416388111107997
Validation loss: 2.5298995843353778

Epoch: 6| Step: 6
Training loss: 3.1562439569094374
Validation loss: 2.531066972989075

Epoch: 6| Step: 7
Training loss: 2.7329072337146023
Validation loss: 2.5304795954705765

Epoch: 6| Step: 8
Training loss: 2.8838998454846902
Validation loss: 2.5410519039172272

Epoch: 6| Step: 9
Training loss: 2.859406351219862
Validation loss: 2.5288684518397035

Epoch: 6| Step: 10
Training loss: 2.688901225456683
Validation loss: 2.550286786052155

Epoch: 6| Step: 11
Training loss: 2.1777621827680873
Validation loss: 2.5406195922853745

Epoch: 6| Step: 12
Training loss: 3.2123552519846887
Validation loss: 2.5112192243487597

Epoch: 6| Step: 13
Training loss: 2.8395470381553767
Validation loss: 2.516610082821332

Epoch: 172| Step: 0
Training loss: 2.575825353400479
Validation loss: 2.475919936790048

Epoch: 6| Step: 1
Training loss: 2.4594175458667022
Validation loss: 2.4660913261901496

Epoch: 6| Step: 2
Training loss: 2.1650603159548263
Validation loss: 2.45929170687862

Epoch: 6| Step: 3
Training loss: 2.725571941584452
Validation loss: 2.455811956542058

Epoch: 6| Step: 4
Training loss: 2.609559195407519
Validation loss: 2.4667560172367833

Epoch: 6| Step: 5
Training loss: 2.9558167476814297
Validation loss: 2.481996073821478

Epoch: 6| Step: 6
Training loss: 3.4281811719133133
Validation loss: 2.479202249226299

Epoch: 6| Step: 7
Training loss: 2.9247755046019064
Validation loss: 2.467835300102147

Epoch: 6| Step: 8
Training loss: 3.1665945212193503
Validation loss: 2.478586282179284

Epoch: 6| Step: 9
Training loss: 2.7383766756286385
Validation loss: 2.4778567898966544

Epoch: 6| Step: 10
Training loss: 2.7893348368548883
Validation loss: 2.4715339526698146

Epoch: 6| Step: 11
Training loss: 2.956734686509544
Validation loss: 2.471316848335329

Epoch: 6| Step: 12
Training loss: 3.052798416334817
Validation loss: 2.474797389559462

Epoch: 6| Step: 13
Training loss: 1.9195352593870292
Validation loss: 2.4704084151933805

Epoch: 173| Step: 0
Training loss: 2.566143515970154
Validation loss: 2.4710736236022903

Epoch: 6| Step: 1
Training loss: 2.667083548702912
Validation loss: 2.4924027688810817

Epoch: 6| Step: 2
Training loss: 2.3588011593266445
Validation loss: 2.5082097296539962

Epoch: 6| Step: 3
Training loss: 2.818916207634211
Validation loss: 2.5368019196913627

Epoch: 6| Step: 4
Training loss: 3.2712257943516887
Validation loss: 2.5382175500523965

Epoch: 6| Step: 5
Training loss: 3.0424542561385866
Validation loss: 2.545144894707214

Epoch: 6| Step: 6
Training loss: 3.3945224002419883
Validation loss: 2.514481417235278

Epoch: 6| Step: 7
Training loss: 2.603770559067672
Validation loss: 2.5187263446335115

Epoch: 6| Step: 8
Training loss: 2.7291594546467857
Validation loss: 2.5082660589850474

Epoch: 6| Step: 9
Training loss: 2.947446176750943
Validation loss: 2.4843684504861137

Epoch: 6| Step: 10
Training loss: 2.2023213320778923
Validation loss: 2.471469958690363

Epoch: 6| Step: 11
Training loss: 3.0093853689868744
Validation loss: 2.473346734518798

Epoch: 6| Step: 12
Training loss: 2.1579334487552186
Validation loss: 2.474059124605943

Epoch: 6| Step: 13
Training loss: 2.8159168257296754
Validation loss: 2.469274597797028

Epoch: 174| Step: 0
Training loss: 2.83758816351023
Validation loss: 2.4674640596654847

Epoch: 6| Step: 1
Training loss: 2.8156550195175414
Validation loss: 2.47337476150307

Epoch: 6| Step: 2
Training loss: 2.5607230375375596
Validation loss: 2.470201199999629

Epoch: 6| Step: 3
Training loss: 2.8549583803473606
Validation loss: 2.4681165574911073

Epoch: 6| Step: 4
Training loss: 1.7139378546684612
Validation loss: 2.46646872483967

Epoch: 6| Step: 5
Training loss: 2.713964701434926
Validation loss: 2.480371996202372

Epoch: 6| Step: 6
Training loss: 2.5636401547502907
Validation loss: 2.4896236530886293

Epoch: 6| Step: 7
Training loss: 3.4447408534938435
Validation loss: 2.5112018653322266

Epoch: 6| Step: 8
Training loss: 2.8583749158260936
Validation loss: 2.5173661383405497

Epoch: 6| Step: 9
Training loss: 2.377199258967051
Validation loss: 2.5145943915913778

Epoch: 6| Step: 10
Training loss: 2.8933618734273505
Validation loss: 2.5243889156009462

Epoch: 6| Step: 11
Training loss: 2.865371336780635
Validation loss: 2.5368728907034668

Epoch: 6| Step: 12
Training loss: 3.103165296463876
Validation loss: 2.500355850038064

Epoch: 6| Step: 13
Training loss: 2.676742581501952
Validation loss: 2.489644317628307

Epoch: 175| Step: 0
Training loss: 3.3654763814969884
Validation loss: 2.471433385512523

Epoch: 6| Step: 1
Training loss: 2.805042467526812
Validation loss: 2.4651943358086874

Epoch: 6| Step: 2
Training loss: 1.9976501966018472
Validation loss: 2.4527830083160262

Epoch: 6| Step: 3
Training loss: 2.9681421561115835
Validation loss: 2.4664139022655687

Epoch: 6| Step: 4
Training loss: 2.80969081032878
Validation loss: 2.462381982086052

Epoch: 6| Step: 5
Training loss: 2.782089621004643
Validation loss: 2.4628872940946414

Epoch: 6| Step: 6
Training loss: 2.4165485506679967
Validation loss: 2.456145388250469

Epoch: 6| Step: 7
Training loss: 2.839218721516255
Validation loss: 2.4482378230364894

Epoch: 6| Step: 8
Training loss: 2.306735612559181
Validation loss: 2.4583096288417985

Epoch: 6| Step: 9
Training loss: 2.1808360365531514
Validation loss: 2.4613889833163767

Epoch: 6| Step: 10
Training loss: 3.2751300232680114
Validation loss: 2.4639349956034944

Epoch: 6| Step: 11
Training loss: 2.5780475026822964
Validation loss: 2.4666868576375274

Epoch: 6| Step: 12
Training loss: 2.8468470215076866
Validation loss: 2.469871455794217

Epoch: 6| Step: 13
Training loss: 2.806188665114794
Validation loss: 2.4763867638174784

Epoch: 176| Step: 0
Training loss: 3.239055840006494
Validation loss: 2.474106704761807

Epoch: 6| Step: 1
Training loss: 2.7974382398127053
Validation loss: 2.4953981170625914

Epoch: 6| Step: 2
Training loss: 2.497668705188193
Validation loss: 2.494017685167099

Epoch: 6| Step: 3
Training loss: 2.6126161649877733
Validation loss: 2.4960418530933572

Epoch: 6| Step: 4
Training loss: 2.989744777950164
Validation loss: 2.4891514569374102

Epoch: 6| Step: 5
Training loss: 2.835045708450985
Validation loss: 2.4592216024296145

Epoch: 6| Step: 6
Training loss: 2.1283800507239827
Validation loss: 2.444315489841347

Epoch: 6| Step: 7
Training loss: 2.9408324797807337
Validation loss: 2.435182742029019

Epoch: 6| Step: 8
Training loss: 2.727401647988555
Validation loss: 2.4320169437620494

Epoch: 6| Step: 9
Training loss: 2.7068778210600812
Validation loss: 2.4439428753492805

Epoch: 6| Step: 10
Training loss: 2.937360557330715
Validation loss: 2.433984526291575

Epoch: 6| Step: 11
Training loss: 2.848861962361606
Validation loss: 2.4479015788859377

Epoch: 6| Step: 12
Training loss: 2.5983028668307244
Validation loss: 2.456751494041845

Epoch: 6| Step: 13
Training loss: 2.8188737491078637
Validation loss: 2.4595522673378394

Epoch: 177| Step: 0
Training loss: 2.454329371172689
Validation loss: 2.470976014302675

Epoch: 6| Step: 1
Training loss: 3.0248144991406374
Validation loss: 2.4962174605445093

Epoch: 6| Step: 2
Training loss: 2.1954605215541636
Validation loss: 2.498305424248935

Epoch: 6| Step: 3
Training loss: 2.8697775801758882
Validation loss: 2.499297981755358

Epoch: 6| Step: 4
Training loss: 2.546931728363144
Validation loss: 2.5185451024121317

Epoch: 6| Step: 5
Training loss: 3.3840225557517956
Validation loss: 2.5094829857443655

Epoch: 6| Step: 6
Training loss: 2.42012699172314
Validation loss: 2.5357211766058874

Epoch: 6| Step: 7
Training loss: 2.549389773637218
Validation loss: 2.555797800627644

Epoch: 6| Step: 8
Training loss: 2.8723317908960637
Validation loss: 2.5682434148183573

Epoch: 6| Step: 9
Training loss: 2.7639700037961275
Validation loss: 2.5427725322917403

Epoch: 6| Step: 10
Training loss: 2.7504761023635256
Validation loss: 2.500613633597038

Epoch: 6| Step: 11
Training loss: 3.640301604089666
Validation loss: 2.46123122054184

Epoch: 6| Step: 12
Training loss: 2.456232908543728
Validation loss: 2.444855577431231

Epoch: 6| Step: 13
Training loss: 2.3596150863462646
Validation loss: 2.4404887630448506

Epoch: 178| Step: 0
Training loss: 3.0520732649462414
Validation loss: 2.450395559959362

Epoch: 6| Step: 1
Training loss: 2.9965807184518267
Validation loss: 2.4417483767756583

Epoch: 6| Step: 2
Training loss: 3.1356314821045124
Validation loss: 2.4424582022570416

Epoch: 6| Step: 3
Training loss: 3.335873605442331
Validation loss: 2.4511735421380023

Epoch: 6| Step: 4
Training loss: 2.905149518103015
Validation loss: 2.441584749649032

Epoch: 6| Step: 5
Training loss: 3.416027629606551
Validation loss: 2.4577866000694266

Epoch: 6| Step: 6
Training loss: 2.2417836107950726
Validation loss: 2.4589697019559904

Epoch: 6| Step: 7
Training loss: 2.573222359684046
Validation loss: 2.472015745280344

Epoch: 6| Step: 8
Training loss: 2.770797203421169
Validation loss: 2.506004501870756

Epoch: 6| Step: 9
Training loss: 3.0193835934244464
Validation loss: 2.5220414652088565

Epoch: 6| Step: 10
Training loss: 1.6360701775876918
Validation loss: 2.5075056268895133

Epoch: 6| Step: 11
Training loss: 2.4192869078420722
Validation loss: 2.4865937528609585

Epoch: 6| Step: 12
Training loss: 2.1683678062136233
Validation loss: 2.5006012039854038

Epoch: 6| Step: 13
Training loss: 2.9063110345153533
Validation loss: 2.496388491926461

Epoch: 179| Step: 0
Training loss: 2.239293267443094
Validation loss: 2.4983237214948733

Epoch: 6| Step: 1
Training loss: 3.161238552207024
Validation loss: 2.5027184437195737

Epoch: 6| Step: 2
Training loss: 2.362617538192524
Validation loss: 2.4821812174259525

Epoch: 6| Step: 3
Training loss: 2.8621219302048218
Validation loss: 2.473199999158223

Epoch: 6| Step: 4
Training loss: 3.227367679356715
Validation loss: 2.4688794502036355

Epoch: 6| Step: 5
Training loss: 2.8196936269137827
Validation loss: 2.458529833835753

Epoch: 6| Step: 6
Training loss: 2.5765327854420965
Validation loss: 2.44709683952287

Epoch: 6| Step: 7
Training loss: 3.0006017081515357
Validation loss: 2.448457200994148

Epoch: 6| Step: 8
Training loss: 2.394227548478641
Validation loss: 2.444211862911611

Epoch: 6| Step: 9
Training loss: 2.740350178387647
Validation loss: 2.4504215310633444

Epoch: 6| Step: 10
Training loss: 3.274063378272303
Validation loss: 2.437610514333386

Epoch: 6| Step: 11
Training loss: 2.606436622579416
Validation loss: 2.4453395734678227

Epoch: 6| Step: 12
Training loss: 2.1423159415417206
Validation loss: 2.4554325117229387

Epoch: 6| Step: 13
Training loss: 3.127513332567224
Validation loss: 2.4550268585047124

Epoch: 180| Step: 0
Training loss: 2.9093657168722737
Validation loss: 2.4595823120296956

Epoch: 6| Step: 1
Training loss: 2.7615857989347226
Validation loss: 2.455906047346334

Epoch: 6| Step: 2
Training loss: 2.7863704394206974
Validation loss: 2.4496212542018068

Epoch: 6| Step: 3
Training loss: 2.849824893323697
Validation loss: 2.4483000347549972

Epoch: 6| Step: 4
Training loss: 2.840482070734656
Validation loss: 2.4394712604507474

Epoch: 6| Step: 5
Training loss: 2.8166876240990817
Validation loss: 2.4526585274597124

Epoch: 6| Step: 6
Training loss: 2.497490768033703
Validation loss: 2.450300174679641

Epoch: 6| Step: 7
Training loss: 3.155371515372542
Validation loss: 2.4438438488355274

Epoch: 6| Step: 8
Training loss: 2.997729077720848
Validation loss: 2.4634964011808798

Epoch: 6| Step: 9
Training loss: 2.6148240078698546
Validation loss: 2.4569776442356948

Epoch: 6| Step: 10
Training loss: 1.7141001833700242
Validation loss: 2.4728808575510266

Epoch: 6| Step: 11
Training loss: 2.2964275728777395
Validation loss: 2.4589888673902407

Epoch: 6| Step: 12
Training loss: 3.3015228341315455
Validation loss: 2.45650593486933

Epoch: 6| Step: 13
Training loss: 2.1821256830887754
Validation loss: 2.452167453428238

Epoch: 181| Step: 0
Training loss: 2.839708075765255
Validation loss: 2.440422981179229

Epoch: 6| Step: 1
Training loss: 2.8860420807052627
Validation loss: 2.451890097322855

Epoch: 6| Step: 2
Training loss: 2.9158555310728924
Validation loss: 2.4589976947202814

Epoch: 6| Step: 3
Training loss: 1.861440841288069
Validation loss: 2.467505192457838

Epoch: 6| Step: 4
Training loss: 2.5913942968709853
Validation loss: 2.4508270061592405

Epoch: 6| Step: 5
Training loss: 2.9112643391643833
Validation loss: 2.4719998356172996

Epoch: 6| Step: 6
Training loss: 2.8463129923018804
Validation loss: 2.4623136210511003

Epoch: 6| Step: 7
Training loss: 2.701255019226071
Validation loss: 2.4685732382437062

Epoch: 6| Step: 8
Training loss: 2.333060646017764
Validation loss: 2.473997929530901

Epoch: 6| Step: 9
Training loss: 2.4609255835835
Validation loss: 2.4738336395462164

Epoch: 6| Step: 10
Training loss: 2.9945436767511366
Validation loss: 2.4618639911543894

Epoch: 6| Step: 11
Training loss: 2.748308008037574
Validation loss: 2.4585203124349344

Epoch: 6| Step: 12
Training loss: 3.22685332754077
Validation loss: 2.460056027397086

Epoch: 6| Step: 13
Training loss: 2.2583043179870956
Validation loss: 2.4482637856158966

Epoch: 182| Step: 0
Training loss: 2.3306277347138438
Validation loss: 2.4484432710908512

Epoch: 6| Step: 1
Training loss: 2.7905803578598296
Validation loss: 2.451227034284105

Epoch: 6| Step: 2
Training loss: 3.131689617187252
Validation loss: 2.455525310464315

Epoch: 6| Step: 3
Training loss: 2.572197869059454
Validation loss: 2.4445757169548985

Epoch: 6| Step: 4
Training loss: 2.460498395225096
Validation loss: 2.441307839918487

Epoch: 6| Step: 5
Training loss: 2.2065503702126086
Validation loss: 2.4410080120849162

Epoch: 6| Step: 6
Training loss: 2.9910867523907005
Validation loss: 2.4368517044833613

Epoch: 6| Step: 7
Training loss: 2.5746862424043386
Validation loss: 2.4584270881418346

Epoch: 6| Step: 8
Training loss: 3.011730624520608
Validation loss: 2.4577134840279613

Epoch: 6| Step: 9
Training loss: 2.8348591753717596
Validation loss: 2.454347378944154

Epoch: 6| Step: 10
Training loss: 2.7069938183683253
Validation loss: 2.4585191591448057

Epoch: 6| Step: 11
Training loss: 2.938933002675268
Validation loss: 2.4509403749748424

Epoch: 6| Step: 12
Training loss: 2.6093457614379845
Validation loss: 2.4547922104298454

Epoch: 6| Step: 13
Training loss: 3.1484670330016082
Validation loss: 2.4528864748556134

Epoch: 183| Step: 0
Training loss: 2.4909499393181727
Validation loss: 2.4493278563769225

Epoch: 6| Step: 1
Training loss: 2.5591403988734656
Validation loss: 2.4532199274573436

Epoch: 6| Step: 2
Training loss: 2.4695226691488257
Validation loss: 2.457619366453158

Epoch: 6| Step: 3
Training loss: 2.685509765368604
Validation loss: 2.448062254259926

Epoch: 6| Step: 4
Training loss: 2.8652272188582244
Validation loss: 2.4441604482106376

Epoch: 6| Step: 5
Training loss: 2.971387314117028
Validation loss: 2.4486968302494527

Epoch: 6| Step: 6
Training loss: 2.629640383193465
Validation loss: 2.4472536242025265

Epoch: 6| Step: 7
Training loss: 2.9555855647533895
Validation loss: 2.4565737311851095

Epoch: 6| Step: 8
Training loss: 2.3248117924469267
Validation loss: 2.4484532792904377

Epoch: 6| Step: 9
Training loss: 3.313608236082885
Validation loss: 2.453009159636343

Epoch: 6| Step: 10
Training loss: 2.61974617303641
Validation loss: 2.4613565473937102

Epoch: 6| Step: 11
Training loss: 2.9378807957346207
Validation loss: 2.4525373716629244

Epoch: 6| Step: 12
Training loss: 2.698492501763526
Validation loss: 2.4632511740749403

Epoch: 6| Step: 13
Training loss: 2.0946275380877215
Validation loss: 2.4610281218397034

Epoch: 184| Step: 0
Training loss: 3.4654935380167906
Validation loss: 2.46361597951507

Epoch: 6| Step: 1
Training loss: 2.7579318012660448
Validation loss: 2.477673317011549

Epoch: 6| Step: 2
Training loss: 2.796354106794842
Validation loss: 2.466665584006345

Epoch: 6| Step: 3
Training loss: 2.6279990003865517
Validation loss: 2.462016479409645

Epoch: 6| Step: 4
Training loss: 2.2968409529258027
Validation loss: 2.464621208080959

Epoch: 6| Step: 5
Training loss: 2.9673109883610023
Validation loss: 2.462845796881663

Epoch: 6| Step: 6
Training loss: 2.6018542793396344
Validation loss: 2.4533854546746183

Epoch: 6| Step: 7
Training loss: 2.741614387809951
Validation loss: 2.4482526661597785

Epoch: 6| Step: 8
Training loss: 2.042870251120966
Validation loss: 2.4469107354253206

Epoch: 6| Step: 9
Training loss: 3.0401019596268077
Validation loss: 2.447250140021427

Epoch: 6| Step: 10
Training loss: 2.4547617123444163
Validation loss: 2.455003830785795

Epoch: 6| Step: 11
Training loss: 2.5110027425820136
Validation loss: 2.462892978490102

Epoch: 6| Step: 12
Training loss: 2.8212444424690672
Validation loss: 2.463454368917884

Epoch: 6| Step: 13
Training loss: 2.579777875549853
Validation loss: 2.460235188177564

Epoch: 185| Step: 0
Training loss: 2.6896842242247883
Validation loss: 2.4637199156473097

Epoch: 6| Step: 1
Training loss: 2.9124419177898657
Validation loss: 2.44611467596231

Epoch: 6| Step: 2
Training loss: 2.7777889018365856
Validation loss: 2.437605644946777

Epoch: 6| Step: 3
Training loss: 2.4233807220792833
Validation loss: 2.4329183607792393

Epoch: 6| Step: 4
Training loss: 2.9871656541996265
Validation loss: 2.4385288445206923

Epoch: 6| Step: 5
Training loss: 2.7786864564042038
Validation loss: 2.432803841271715

Epoch: 6| Step: 6
Training loss: 2.958110818867207
Validation loss: 2.430935695784362

Epoch: 6| Step: 7
Training loss: 2.6607369616704353
Validation loss: 2.429372121728158

Epoch: 6| Step: 8
Training loss: 3.1728350309280007
Validation loss: 2.4376520383424496

Epoch: 6| Step: 9
Training loss: 2.466009719674786
Validation loss: 2.4518108130508236

Epoch: 6| Step: 10
Training loss: 2.2626925728970253
Validation loss: 2.452298143825848

Epoch: 6| Step: 11
Training loss: 2.1539429194857584
Validation loss: 2.4795455246743225

Epoch: 6| Step: 12
Training loss: 3.024426044838227
Validation loss: 2.5009664831055973

Epoch: 6| Step: 13
Training loss: 3.3078435162084325
Validation loss: 2.547722838476598

Epoch: 186| Step: 0
Training loss: 2.2551270456325425
Validation loss: 2.4557942382353453

Epoch: 6| Step: 1
Training loss: 2.843388796493097
Validation loss: 2.4367954423316642

Epoch: 6| Step: 2
Training loss: 2.88625091354468
Validation loss: 2.4384006049139155

Epoch: 6| Step: 3
Training loss: 1.882279949929342
Validation loss: 2.435197347850133

Epoch: 6| Step: 4
Training loss: 2.9028566300077383
Validation loss: 2.4355155369868338

Epoch: 6| Step: 5
Training loss: 2.849118039375505
Validation loss: 2.4391759701217057

Epoch: 6| Step: 6
Training loss: 2.7927712110540814
Validation loss: 2.437773505916655

Epoch: 6| Step: 7
Training loss: 2.403695968044464
Validation loss: 2.438311745370835

Epoch: 6| Step: 8
Training loss: 2.941912320031799
Validation loss: 2.439477520654718

Epoch: 6| Step: 9
Training loss: 3.0242474084795563
Validation loss: 2.433005857310664

Epoch: 6| Step: 10
Training loss: 2.6529899787469127
Validation loss: 2.4412623424489066

Epoch: 6| Step: 11
Training loss: 1.974848067801586
Validation loss: 2.447692071843764

Epoch: 6| Step: 12
Training loss: 3.1390088226301316
Validation loss: 2.4512055082963013

Epoch: 6| Step: 13
Training loss: 3.7990922144708117
Validation loss: 2.4710588231501776

Epoch: 187| Step: 0
Training loss: 2.8430758505091007
Validation loss: 2.4673045111383116

Epoch: 6| Step: 1
Training loss: 2.7931768593249267
Validation loss: 2.473806140063257

Epoch: 6| Step: 2
Training loss: 2.523506659631802
Validation loss: 2.4726724415934416

Epoch: 6| Step: 3
Training loss: 3.243358869252791
Validation loss: 2.463968444278029

Epoch: 6| Step: 4
Training loss: 2.4659507429922467
Validation loss: 2.457029234170637

Epoch: 6| Step: 5
Training loss: 2.819071827044131
Validation loss: 2.44815076251067

Epoch: 6| Step: 6
Training loss: 2.637142797209422
Validation loss: 2.447705717996854

Epoch: 6| Step: 7
Training loss: 2.9549138539726356
Validation loss: 2.443912327889979

Epoch: 6| Step: 8
Training loss: 2.6488443697887063
Validation loss: 2.4545489483363014

Epoch: 6| Step: 9
Training loss: 2.802000581070093
Validation loss: 2.451098289704008

Epoch: 6| Step: 10
Training loss: 2.509109209362083
Validation loss: 2.4587724862462235

Epoch: 6| Step: 11
Training loss: 2.8213758498193044
Validation loss: 2.4461470310236044

Epoch: 6| Step: 12
Training loss: 2.1497866191990216
Validation loss: 2.4433826792880193

Epoch: 6| Step: 13
Training loss: 2.771427253419453
Validation loss: 2.4393033407996634

Epoch: 188| Step: 0
Training loss: 3.0036641632273975
Validation loss: 2.4294862801366945

Epoch: 6| Step: 1
Training loss: 2.8556233793418127
Validation loss: 2.446988662483057

Epoch: 6| Step: 2
Training loss: 2.9123237065345373
Validation loss: 2.4479024229942197

Epoch: 6| Step: 3
Training loss: 2.9498516692030963
Validation loss: 2.4515335033922

Epoch: 6| Step: 4
Training loss: 2.3050166525415063
Validation loss: 2.4499205322972255

Epoch: 6| Step: 5
Training loss: 2.956980292865101
Validation loss: 2.4481394603320332

Epoch: 6| Step: 6
Training loss: 2.8704363219456246
Validation loss: 2.451236095599561

Epoch: 6| Step: 7
Training loss: 2.485861471513286
Validation loss: 2.452730318340698

Epoch: 6| Step: 8
Training loss: 2.3652481847307936
Validation loss: 2.4560885858570494

Epoch: 6| Step: 9
Training loss: 2.488116248392574
Validation loss: 2.4505381591019795

Epoch: 6| Step: 10
Training loss: 2.8913226961000738
Validation loss: 2.44971160710665

Epoch: 6| Step: 11
Training loss: 2.454117300921977
Validation loss: 2.440995238000405

Epoch: 6| Step: 12
Training loss: 3.094326851750847
Validation loss: 2.445013027992336

Epoch: 6| Step: 13
Training loss: 1.3579753817544602
Validation loss: 2.443124958390348

Epoch: 189| Step: 0
Training loss: 2.7924864879475915
Validation loss: 2.436296772370834

Epoch: 6| Step: 1
Training loss: 2.3920895945760483
Validation loss: 2.436434875663521

Epoch: 6| Step: 2
Training loss: 2.056443772852971
Validation loss: 2.438988606791716

Epoch: 6| Step: 3
Training loss: 2.4815774197112512
Validation loss: 2.4290775519618975

Epoch: 6| Step: 4
Training loss: 2.752536470897453
Validation loss: 2.436506001902904

Epoch: 6| Step: 5
Training loss: 2.77336984471288
Validation loss: 2.450320784784889

Epoch: 6| Step: 6
Training loss: 2.6083092254727074
Validation loss: 2.4424980631586033

Epoch: 6| Step: 7
Training loss: 2.840337025698828
Validation loss: 2.4468252265345867

Epoch: 6| Step: 8
Training loss: 2.7046915266953526
Validation loss: 2.4504476127885106

Epoch: 6| Step: 9
Training loss: 3.079969134485728
Validation loss: 2.453074959314513

Epoch: 6| Step: 10
Training loss: 3.1212917451278286
Validation loss: 2.4479844153111436

Epoch: 6| Step: 11
Training loss: 2.5051392184192296
Validation loss: 2.472097182567381

Epoch: 6| Step: 12
Training loss: 3.252580645160314
Validation loss: 2.4822954113839386

Epoch: 6| Step: 13
Training loss: 2.0464129909320765
Validation loss: 2.471403339668351

Epoch: 190| Step: 0
Training loss: 2.5281622621032356
Validation loss: 2.4587223988860023

Epoch: 6| Step: 1
Training loss: 2.0395864931523047
Validation loss: 2.457814770068346

Epoch: 6| Step: 2
Training loss: 2.957927371543654
Validation loss: 2.459967312304254

Epoch: 6| Step: 3
Training loss: 2.9212430382752945
Validation loss: 2.452696139437191

Epoch: 6| Step: 4
Training loss: 2.3264418284401014
Validation loss: 2.4520594519945047

Epoch: 6| Step: 5
Training loss: 2.649273855659372
Validation loss: 2.459565967554384

Epoch: 6| Step: 6
Training loss: 2.8973050848608852
Validation loss: 2.455556238074706

Epoch: 6| Step: 7
Training loss: 2.2987878839670337
Validation loss: 2.469111197422182

Epoch: 6| Step: 8
Training loss: 2.8022029997693787
Validation loss: 2.4606107178076697

Epoch: 6| Step: 9
Training loss: 2.6804591366343384
Validation loss: 2.476437992894508

Epoch: 6| Step: 10
Training loss: 2.694993859958201
Validation loss: 2.465517142579924

Epoch: 6| Step: 11
Training loss: 3.239272091419765
Validation loss: 2.465607254016654

Epoch: 6| Step: 12
Training loss: 2.462550721396503
Validation loss: 2.440053691195958

Epoch: 6| Step: 13
Training loss: 3.147738622902218
Validation loss: 2.4384463776120326

Epoch: 191| Step: 0
Training loss: 2.6868098947606054
Validation loss: 2.461481285143567

Epoch: 6| Step: 1
Training loss: 2.3059304199440915
Validation loss: 2.462909855685825

Epoch: 6| Step: 2
Training loss: 2.6480272363547015
Validation loss: 2.499626394268521

Epoch: 6| Step: 3
Training loss: 2.7974854554317257
Validation loss: 2.5072446603269976

Epoch: 6| Step: 4
Training loss: 2.3517292761990047
Validation loss: 2.5067243791831877

Epoch: 6| Step: 5
Training loss: 2.519649910904876
Validation loss: 2.4911756626485055

Epoch: 6| Step: 6
Training loss: 3.224398203450384
Validation loss: 2.4776469300334214

Epoch: 6| Step: 7
Training loss: 2.6895480669005902
Validation loss: 2.4657192295034944

Epoch: 6| Step: 8
Training loss: 2.7030706675807696
Validation loss: 2.457833946594498

Epoch: 6| Step: 9
Training loss: 3.0859396632706027
Validation loss: 2.4520581430217843

Epoch: 6| Step: 10
Training loss: 2.9938150864695463
Validation loss: 2.432145674380398

Epoch: 6| Step: 11
Training loss: 2.167598328433507
Validation loss: 2.4209176417085714

Epoch: 6| Step: 12
Training loss: 2.9323688901192595
Validation loss: 2.426658460798028

Epoch: 6| Step: 13
Training loss: 2.7710571389889282
Validation loss: 2.417728748325384

Epoch: 192| Step: 0
Training loss: 2.5902576144618017
Validation loss: 2.4273316063919035

Epoch: 6| Step: 1
Training loss: 3.5960628862069663
Validation loss: 2.4337388725874765

Epoch: 6| Step: 2
Training loss: 2.45357008862791
Validation loss: 2.4305659747938058

Epoch: 6| Step: 3
Training loss: 2.5784488358997986
Validation loss: 2.4347119853152392

Epoch: 6| Step: 4
Training loss: 2.6035764305071183
Validation loss: 2.432272585288309

Epoch: 6| Step: 5
Training loss: 2.4277436063656954
Validation loss: 2.4288228460346306

Epoch: 6| Step: 6
Training loss: 2.279875563354523
Validation loss: 2.429825224565569

Epoch: 6| Step: 7
Training loss: 3.202125653938846
Validation loss: 2.4280483774810264

Epoch: 6| Step: 8
Training loss: 3.0422716627739192
Validation loss: 2.430665204748408

Epoch: 6| Step: 9
Training loss: 3.068733721843362
Validation loss: 2.4401886748808415

Epoch: 6| Step: 10
Training loss: 2.394634499743044
Validation loss: 2.43460400982055

Epoch: 6| Step: 11
Training loss: 2.4235519018169964
Validation loss: 2.4426065776168002

Epoch: 6| Step: 12
Training loss: 2.5900724146083327
Validation loss: 2.4504637575825288

Epoch: 6| Step: 13
Training loss: 2.8779049999471322
Validation loss: 2.4578474519526594

Epoch: 193| Step: 0
Training loss: 2.34776115500459
Validation loss: 2.455933891311596

Epoch: 6| Step: 1
Training loss: 2.6404288856769806
Validation loss: 2.4568353896351596

Epoch: 6| Step: 2
Training loss: 2.8890264266440444
Validation loss: 2.4483671640878546

Epoch: 6| Step: 3
Training loss: 2.6472727146872748
Validation loss: 2.445663904440637

Epoch: 6| Step: 4
Training loss: 2.5303500424106713
Validation loss: 2.4433077660860723

Epoch: 6| Step: 5
Training loss: 2.5914892432350043
Validation loss: 2.4420707408041626

Epoch: 6| Step: 6
Training loss: 3.6112166821298564
Validation loss: 2.4490966724582455

Epoch: 6| Step: 7
Training loss: 2.7713402783904306
Validation loss: 2.4620225828460294

Epoch: 6| Step: 8
Training loss: 1.973254907999927
Validation loss: 2.449339593718303

Epoch: 6| Step: 9
Training loss: 2.850294693551509
Validation loss: 2.4340309191924754

Epoch: 6| Step: 10
Training loss: 2.6052157209114433
Validation loss: 2.433112586669549

Epoch: 6| Step: 11
Training loss: 2.791170237418436
Validation loss: 2.4448848097290536

Epoch: 6| Step: 12
Training loss: 2.6596255228133794
Validation loss: 2.442057673614235

Epoch: 6| Step: 13
Training loss: 2.4178579178708457
Validation loss: 2.431253707709563

Epoch: 194| Step: 0
Training loss: 2.951066687455747
Validation loss: 2.4407018136945724

Epoch: 6| Step: 1
Training loss: 2.9914572200582237
Validation loss: 2.4421510010531713

Epoch: 6| Step: 2
Training loss: 2.1895376252092658
Validation loss: 2.4473180104735963

Epoch: 6| Step: 3
Training loss: 2.4656483928310444
Validation loss: 2.446246534408556

Epoch: 6| Step: 4
Training loss: 2.7755938676352128
Validation loss: 2.4532959497498457

Epoch: 6| Step: 5
Training loss: 2.6290932485382252
Validation loss: 2.4800778151400173

Epoch: 6| Step: 6
Training loss: 2.1693708954653848
Validation loss: 2.482610414181413

Epoch: 6| Step: 7
Training loss: 2.549766817838035
Validation loss: 2.478820757174425

Epoch: 6| Step: 8
Training loss: 2.922810124372147
Validation loss: 2.4760312657418635

Epoch: 6| Step: 9
Training loss: 3.1934715134649334
Validation loss: 2.45510430135675

Epoch: 6| Step: 10
Training loss: 2.576426646003637
Validation loss: 2.454062792651225

Epoch: 6| Step: 11
Training loss: 2.445672834373594
Validation loss: 2.45945798872496

Epoch: 6| Step: 12
Training loss: 2.6785023017319403
Validation loss: 2.465037458777872

Epoch: 6| Step: 13
Training loss: 2.7208541970575175
Validation loss: 2.4628093787695233

Epoch: 195| Step: 0
Training loss: 2.6984493853953926
Validation loss: 2.4553857516095134

Epoch: 6| Step: 1
Training loss: 2.445159419816604
Validation loss: 2.4610634506713076

Epoch: 6| Step: 2
Training loss: 2.8149018098770813
Validation loss: 2.459387378244779

Epoch: 6| Step: 3
Training loss: 2.188092287805712
Validation loss: 2.4760440972099116

Epoch: 6| Step: 4
Training loss: 2.771061440928262
Validation loss: 2.4745763011843693

Epoch: 6| Step: 5
Training loss: 2.3826949293804613
Validation loss: 2.4678093148816305

Epoch: 6| Step: 6
Training loss: 2.744973183311562
Validation loss: 2.460528678421655

Epoch: 6| Step: 7
Training loss: 2.1908727530261527
Validation loss: 2.465453818047718

Epoch: 6| Step: 8
Training loss: 2.959170979573931
Validation loss: 2.468120864989635

Epoch: 6| Step: 9
Training loss: 3.059278077878519
Validation loss: 2.4868795017467167

Epoch: 6| Step: 10
Training loss: 3.176185122401195
Validation loss: 2.5024611991701837

Epoch: 6| Step: 11
Training loss: 2.675472759646389
Validation loss: 2.4838746719501863

Epoch: 6| Step: 12
Training loss: 2.8890683493340936
Validation loss: 2.5067575371193573

Epoch: 6| Step: 13
Training loss: 2.4557894675388017
Validation loss: 2.4895188403098785

Epoch: 196| Step: 0
Training loss: 2.7006332290690014
Validation loss: 2.475070278014757

Epoch: 6| Step: 1
Training loss: 2.948899571408117
Validation loss: 2.454162077465335

Epoch: 6| Step: 2
Training loss: 2.947760012792354
Validation loss: 2.460195768881796

Epoch: 6| Step: 3
Training loss: 2.6616763170609192
Validation loss: 2.4448247131644565

Epoch: 6| Step: 4
Training loss: 2.5553495616634727
Validation loss: 2.4458274337139216

Epoch: 6| Step: 5
Training loss: 2.7175281453714937
Validation loss: 2.449696586543926

Epoch: 6| Step: 6
Training loss: 2.085231704461522
Validation loss: 2.4635656191270585

Epoch: 6| Step: 7
Training loss: 2.748529908240793
Validation loss: 2.471992792336014

Epoch: 6| Step: 8
Training loss: 2.332205045476385
Validation loss: 2.4785829413374127

Epoch: 6| Step: 9
Training loss: 2.5290342452331505
Validation loss: 2.4780820288878704

Epoch: 6| Step: 10
Training loss: 2.9944559367975137
Validation loss: 2.4751455318289453

Epoch: 6| Step: 11
Training loss: 2.981938990664123
Validation loss: 2.4673101978255305

Epoch: 6| Step: 12
Training loss: 2.5126955022711743
Validation loss: 2.4680601240995528

Epoch: 6| Step: 13
Training loss: 2.880547023586029
Validation loss: 2.4594752657813195

Epoch: 197| Step: 0
Training loss: 2.4361496143592003
Validation loss: 2.456291774133698

Epoch: 6| Step: 1
Training loss: 3.1798098678849396
Validation loss: 2.4502439984722084

Epoch: 6| Step: 2
Training loss: 2.5900324641958408
Validation loss: 2.452560258429284

Epoch: 6| Step: 3
Training loss: 2.543593275786149
Validation loss: 2.4407129234356875

Epoch: 6| Step: 4
Training loss: 2.466072562128566
Validation loss: 2.4411465377654498

Epoch: 6| Step: 5
Training loss: 2.872292612157319
Validation loss: 2.444919051694975

Epoch: 6| Step: 6
Training loss: 2.7377859584609063
Validation loss: 2.4494725910110793

Epoch: 6| Step: 7
Training loss: 2.946928759637715
Validation loss: 2.4495257906274057

Epoch: 6| Step: 8
Training loss: 3.051585151365624
Validation loss: 2.458110017750725

Epoch: 6| Step: 9
Training loss: 2.585676566152181
Validation loss: 2.4509455154502366

Epoch: 6| Step: 10
Training loss: 2.3286938068451204
Validation loss: 2.4587252808293103

Epoch: 6| Step: 11
Training loss: 2.838762877824365
Validation loss: 2.460635895550004

Epoch: 6| Step: 12
Training loss: 2.511368841356527
Validation loss: 2.477290638995193

Epoch: 6| Step: 13
Training loss: 2.007263821097105
Validation loss: 2.476906827508345

Epoch: 198| Step: 0
Training loss: 2.4869820213634357
Validation loss: 2.476337890439275

Epoch: 6| Step: 1
Training loss: 2.7088178543583954
Validation loss: 2.447806580284222

Epoch: 6| Step: 2
Training loss: 2.4616256478348055
Validation loss: 2.450143735619198

Epoch: 6| Step: 3
Training loss: 2.6267564437582407
Validation loss: 2.460049372495303

Epoch: 6| Step: 4
Training loss: 2.5885448391829047
Validation loss: 2.4585372811701047

Epoch: 6| Step: 5
Training loss: 2.713328601479993
Validation loss: 2.474526526460092

Epoch: 6| Step: 6
Training loss: 2.7718908161112066
Validation loss: 2.4804070867241474

Epoch: 6| Step: 7
Training loss: 2.935401816473805
Validation loss: 2.4932474001658873

Epoch: 6| Step: 8
Training loss: 2.923805292788273
Validation loss: 2.4842086976765403

Epoch: 6| Step: 9
Training loss: 2.513120933212561
Validation loss: 2.4779510968351754

Epoch: 6| Step: 10
Training loss: 2.7294993501135894
Validation loss: 2.480661076408345

Epoch: 6| Step: 11
Training loss: 2.9082178816155166
Validation loss: 2.476704944393246

Epoch: 6| Step: 12
Training loss: 2.5634761904761634
Validation loss: 2.465649833914409

Epoch: 6| Step: 13
Training loss: 2.5187808316523235
Validation loss: 2.449876784314555

Epoch: 199| Step: 0
Training loss: 2.6189623835346754
Validation loss: 2.436379979155765

Epoch: 6| Step: 1
Training loss: 2.2531196371959084
Validation loss: 2.445123656740844

Epoch: 6| Step: 2
Training loss: 2.2454616552836346
Validation loss: 2.452239793945029

Epoch: 6| Step: 3
Training loss: 2.6058396014008154
Validation loss: 2.460591616058047

Epoch: 6| Step: 4
Training loss: 2.644092698127103
Validation loss: 2.47821079094218

Epoch: 6| Step: 5
Training loss: 3.5209341693109772
Validation loss: 2.4934356328053706

Epoch: 6| Step: 6
Training loss: 2.515762609663064
Validation loss: 2.4898752075841073

Epoch: 6| Step: 7
Training loss: 2.4088577407947867
Validation loss: 2.4856922560430483

Epoch: 6| Step: 8
Training loss: 2.85511253629514
Validation loss: 2.491608512219797

Epoch: 6| Step: 9
Training loss: 2.7778834852662277
Validation loss: 2.45221399368674

Epoch: 6| Step: 10
Training loss: 2.4618900453757107
Validation loss: 2.4323728206673474

Epoch: 6| Step: 11
Training loss: 3.0670815277059744
Validation loss: 2.4144686447429344

Epoch: 6| Step: 12
Training loss: 2.6369254476274477
Validation loss: 2.4220587569066545

Epoch: 6| Step: 13
Training loss: 3.0401041555129633
Validation loss: 2.413882978346904

Epoch: 200| Step: 0
Training loss: 1.9335713703131956
Validation loss: 2.4232380545971672

Epoch: 6| Step: 1
Training loss: 3.0371723327980202
Validation loss: 2.432389630328624

Epoch: 6| Step: 2
Training loss: 2.868104045007482
Validation loss: 2.4452979241934387

Epoch: 6| Step: 3
Training loss: 2.801816953644498
Validation loss: 2.4395224229864825

Epoch: 6| Step: 4
Training loss: 1.9038199272513066
Validation loss: 2.453249721571396

Epoch: 6| Step: 5
Training loss: 2.4422373585361616
Validation loss: 2.460318826393358

Epoch: 6| Step: 6
Training loss: 2.566916962181454
Validation loss: 2.466554032407599

Epoch: 6| Step: 7
Training loss: 2.9547931460612844
Validation loss: 2.46633887057118

Epoch: 6| Step: 8
Training loss: 2.599206722725874
Validation loss: 2.4839601238032865

Epoch: 6| Step: 9
Training loss: 2.991290323995516
Validation loss: 2.5093199595860773

Epoch: 6| Step: 10
Training loss: 2.224363934756542
Validation loss: 2.5242164176943627

Epoch: 6| Step: 11
Training loss: 3.117540841404832
Validation loss: 2.539800101422348

Epoch: 6| Step: 12
Training loss: 2.673964726126241
Validation loss: 2.569708286261533

Epoch: 6| Step: 13
Training loss: 3.7185385507686006
Validation loss: 2.5672948114458065

Epoch: 201| Step: 0
Training loss: 2.607986354803886
Validation loss: 2.54021488716027

Epoch: 6| Step: 1
Training loss: 2.9783209465066705
Validation loss: 2.5176201762152055

Epoch: 6| Step: 2
Training loss: 2.770780682362319
Validation loss: 2.4924939088375373

Epoch: 6| Step: 3
Training loss: 2.489048526626512
Validation loss: 2.4807436994064953

Epoch: 6| Step: 4
Training loss: 2.932496374832085
Validation loss: 2.464454067921555

Epoch: 6| Step: 5
Training loss: 1.8558372372587768
Validation loss: 2.4577121749372655

Epoch: 6| Step: 6
Training loss: 2.617475715823321
Validation loss: 2.4572718626209675

Epoch: 6| Step: 7
Training loss: 2.711965052860566
Validation loss: 2.4470040653030933

Epoch: 6| Step: 8
Training loss: 2.8756373155177184
Validation loss: 2.4479128496973304

Epoch: 6| Step: 9
Training loss: 2.668839989603386
Validation loss: 2.4522264751535827

Epoch: 6| Step: 10
Training loss: 3.2334742374458583
Validation loss: 2.469750262598234

Epoch: 6| Step: 11
Training loss: 2.272760349379778
Validation loss: 2.4620157057408627

Epoch: 6| Step: 12
Training loss: 2.4627237286086614
Validation loss: 2.462285862764073

Epoch: 6| Step: 13
Training loss: 2.287610006553508
Validation loss: 2.4484831685765984

Epoch: 202| Step: 0
Training loss: 2.293768722083579
Validation loss: 2.476829379081609

Epoch: 6| Step: 1
Training loss: 2.8806822641532053
Validation loss: 2.498334345144179

Epoch: 6| Step: 2
Training loss: 2.6762240523782443
Validation loss: 2.5030544397905006

Epoch: 6| Step: 3
Training loss: 3.3136367286941666
Validation loss: 2.5198917930645677

Epoch: 6| Step: 4
Training loss: 2.071538598093483
Validation loss: 2.538455563331263

Epoch: 6| Step: 5
Training loss: 2.2508893904283958
Validation loss: 2.4943874289473538

Epoch: 6| Step: 6
Training loss: 2.6285135279077494
Validation loss: 2.4769337202086614

Epoch: 6| Step: 7
Training loss: 2.625947871961156
Validation loss: 2.4689164786375275

Epoch: 6| Step: 8
Training loss: 2.6792233790856375
Validation loss: 2.4594958292290325

Epoch: 6| Step: 9
Training loss: 2.9523001028379205
Validation loss: 2.462578777558333

Epoch: 6| Step: 10
Training loss: 2.656278542757952
Validation loss: 2.4610075399442617

Epoch: 6| Step: 11
Training loss: 2.658295326399683
Validation loss: 2.448334723185387

Epoch: 6| Step: 12
Training loss: 2.5577823662774257
Validation loss: 2.443530191712302

Epoch: 6| Step: 13
Training loss: 2.5926748598256535
Validation loss: 2.4421402972846433

Epoch: 203| Step: 0
Training loss: 2.416635962543338
Validation loss: 2.442330921582597

Epoch: 6| Step: 1
Training loss: 2.837837696566388
Validation loss: 2.4473846377538786

Epoch: 6| Step: 2
Training loss: 2.720249069675076
Validation loss: 2.4542755967156205

Epoch: 6| Step: 3
Training loss: 3.041039772403325
Validation loss: 2.4456568026101313

Epoch: 6| Step: 4
Training loss: 2.979469301729133
Validation loss: 2.425846095221844

Epoch: 6| Step: 5
Training loss: 2.7934502460015262
Validation loss: 2.4204917914022666

Epoch: 6| Step: 6
Training loss: 2.557365390520311
Validation loss: 2.4276292561818003

Epoch: 6| Step: 7
Training loss: 2.320004426688871
Validation loss: 2.4393380510201808

Epoch: 6| Step: 8
Training loss: 3.0212376992571435
Validation loss: 2.47734323605977

Epoch: 6| Step: 9
Training loss: 2.9871603864502223
Validation loss: 2.52298003113478

Epoch: 6| Step: 10
Training loss: 2.400014352755545
Validation loss: 2.544516159511033

Epoch: 6| Step: 11
Training loss: 2.3893580850755334
Validation loss: 2.5208974626872878

Epoch: 6| Step: 12
Training loss: 2.2579134486245245
Validation loss: 2.507504088196918

Epoch: 6| Step: 13
Training loss: 2.4716409102178454
Validation loss: 2.4687864737816763

Epoch: 204| Step: 0
Training loss: 2.916713132942273
Validation loss: 2.4565439752990073

Epoch: 6| Step: 1
Training loss: 3.243078049757114
Validation loss: 2.444962911454761

Epoch: 6| Step: 2
Training loss: 2.3648307323570106
Validation loss: 2.4322389326109914

Epoch: 6| Step: 3
Training loss: 2.1700058173176364
Validation loss: 2.4307401832700704

Epoch: 6| Step: 4
Training loss: 2.716076819230978
Validation loss: 2.4396664878118903

Epoch: 6| Step: 5
Training loss: 2.179739783969149
Validation loss: 2.4344189873423887

Epoch: 6| Step: 6
Training loss: 2.628873963745836
Validation loss: 2.4388577324409364

Epoch: 6| Step: 7
Training loss: 2.520916792904043
Validation loss: 2.4343589888867356

Epoch: 6| Step: 8
Training loss: 2.3688732225883355
Validation loss: 2.442028747084356

Epoch: 6| Step: 9
Training loss: 2.463664647931419
Validation loss: 2.4433720874112215

Epoch: 6| Step: 10
Training loss: 3.1735467122836534
Validation loss: 2.4545825113372106

Epoch: 6| Step: 11
Training loss: 2.8740163032425046
Validation loss: 2.4455607293266555

Epoch: 6| Step: 12
Training loss: 2.4130570870391894
Validation loss: 2.4814578050036133

Epoch: 6| Step: 13
Training loss: 2.3216089807351135
Validation loss: 2.4952179364345675

Epoch: 205| Step: 0
Training loss: 2.63215515805243
Validation loss: 2.501879422476232

Epoch: 6| Step: 1
Training loss: 2.5387120401163727
Validation loss: 2.5141387862005127

Epoch: 6| Step: 2
Training loss: 2.8363228528218456
Validation loss: 2.51227566786845

Epoch: 6| Step: 3
Training loss: 2.8165625159816896
Validation loss: 2.4943207477806473

Epoch: 6| Step: 4
Training loss: 2.207430049008269
Validation loss: 2.4986127778301874

Epoch: 6| Step: 5
Training loss: 2.6039973598121113
Validation loss: 2.4835374782173183

Epoch: 6| Step: 6
Training loss: 2.653293804644225
Validation loss: 2.4698583685752387

Epoch: 6| Step: 7
Training loss: 3.185963877615026
Validation loss: 2.4480321912313787

Epoch: 6| Step: 8
Training loss: 2.681900045206388
Validation loss: 2.438165825628769

Epoch: 6| Step: 9
Training loss: 3.1207719811256176
Validation loss: 2.4317557764806925

Epoch: 6| Step: 10
Training loss: 2.3733054691279167
Validation loss: 2.427474123055826

Epoch: 6| Step: 11
Training loss: 1.8669545814453248
Validation loss: 2.42255089914991

Epoch: 6| Step: 12
Training loss: 1.9977800446524445
Validation loss: 2.4244246628007797

Epoch: 6| Step: 13
Training loss: 2.857058060613881
Validation loss: 2.4356080699079645

Epoch: 206| Step: 0
Training loss: 2.3704623995351337
Validation loss: 2.4407900957195814

Epoch: 6| Step: 1
Training loss: 2.5171221903989736
Validation loss: 2.459002080745758

Epoch: 6| Step: 2
Training loss: 2.3905105064750045
Validation loss: 2.482185480893656

Epoch: 6| Step: 3
Training loss: 2.155659027937063
Validation loss: 2.515486875275881

Epoch: 6| Step: 4
Training loss: 2.464963689385755
Validation loss: 2.5403398035640476

Epoch: 6| Step: 5
Training loss: 2.6813182261929946
Validation loss: 2.5211931190706243

Epoch: 6| Step: 6
Training loss: 2.972705013561933
Validation loss: 2.4953387644458096

Epoch: 6| Step: 7
Training loss: 2.359617814459825
Validation loss: 2.4681954228897878

Epoch: 6| Step: 8
Training loss: 2.6661409118054475
Validation loss: 2.43420642417224

Epoch: 6| Step: 9
Training loss: 2.9111719599116404
Validation loss: 2.416393042474591

Epoch: 6| Step: 10
Training loss: 3.1392612817769203
Validation loss: 2.409993459620924

Epoch: 6| Step: 11
Training loss: 2.420220480561643
Validation loss: 2.4320911443301068

Epoch: 6| Step: 12
Training loss: 2.7605673023125017
Validation loss: 2.4424179407950857

Epoch: 6| Step: 13
Training loss: 2.824183040408968
Validation loss: 2.4494336882368724

Epoch: 207| Step: 0
Training loss: 2.4931238024008957
Validation loss: 2.474035015029616

Epoch: 6| Step: 1
Training loss: 2.767839827241659
Validation loss: 2.4918786687321455

Epoch: 6| Step: 2
Training loss: 2.496459743072036
Validation loss: 2.4997864211536656

Epoch: 6| Step: 3
Training loss: 2.948530710563357
Validation loss: 2.515420667823179

Epoch: 6| Step: 4
Training loss: 2.370641222133191
Validation loss: 2.4907907887465037

Epoch: 6| Step: 5
Training loss: 2.589059195922143
Validation loss: 2.484895031187835

Epoch: 6| Step: 6
Training loss: 2.512354839933213
Validation loss: 2.50276428620765

Epoch: 6| Step: 7
Training loss: 2.2574647417831994
Validation loss: 2.5033704741100444

Epoch: 6| Step: 8
Training loss: 2.5085593564251676
Validation loss: 2.5303420648036816

Epoch: 6| Step: 9
Training loss: 2.8261377086037305
Validation loss: 2.5389538046112903

Epoch: 6| Step: 10
Training loss: 3.063277788070283
Validation loss: 2.5319353844567902

Epoch: 6| Step: 11
Training loss: 2.341229825887611
Validation loss: 2.541816381391984

Epoch: 6| Step: 12
Training loss: 2.6033531647666415
Validation loss: 2.5260921022035694

Epoch: 6| Step: 13
Training loss: 2.303892871485402
Validation loss: 2.455372772507982

Epoch: 208| Step: 0
Training loss: 2.363907861789101
Validation loss: 2.473281499031893

Epoch: 6| Step: 1
Training loss: 2.2676421558102726
Validation loss: 2.4790404685675735

Epoch: 6| Step: 2
Training loss: 3.0772558234098706
Validation loss: 2.4869213092149143

Epoch: 6| Step: 3
Training loss: 2.449324561454143
Validation loss: 2.458981280677697

Epoch: 6| Step: 4
Training loss: 2.146864769701619
Validation loss: 2.4533305664964233

Epoch: 6| Step: 5
Training loss: 3.0292219476146274
Validation loss: 2.4617457200585986

Epoch: 6| Step: 6
Training loss: 2.5067059223503345
Validation loss: 2.4398814931599104

Epoch: 6| Step: 7
Training loss: 2.4048276388220895
Validation loss: 2.4323885911241416

Epoch: 6| Step: 8
Training loss: 1.9713475484665541
Validation loss: 2.4260348486877286

Epoch: 6| Step: 9
Training loss: 2.829834479354224
Validation loss: 2.4201432408016577

Epoch: 6| Step: 10
Training loss: 2.1950857242189703
Validation loss: 2.4411301444174587

Epoch: 6| Step: 11
Training loss: 3.1456058916814817
Validation loss: 2.447346717882792

Epoch: 6| Step: 12
Training loss: 2.8054156619992296
Validation loss: 2.4482418367096743

Epoch: 6| Step: 13
Training loss: 2.842912320014381
Validation loss: 2.4772848013620803

Epoch: 209| Step: 0
Training loss: 2.488147294826895
Validation loss: 2.495677155198245

Epoch: 6| Step: 1
Training loss: 2.997729873051384
Validation loss: 2.518178881777204

Epoch: 6| Step: 2
Training loss: 3.300941309913604
Validation loss: 2.552157816366095

Epoch: 6| Step: 3
Training loss: 2.6588142135462873
Validation loss: 2.5495515508258992

Epoch: 6| Step: 4
Training loss: 1.9160679490219457
Validation loss: 2.526096460027017

Epoch: 6| Step: 5
Training loss: 2.3422205703161705
Validation loss: 2.5237176855725685

Epoch: 6| Step: 6
Training loss: 1.6989849762861342
Validation loss: 2.5125974570233196

Epoch: 6| Step: 7
Training loss: 2.7420013451492937
Validation loss: 2.4811983164251847

Epoch: 6| Step: 8
Training loss: 2.47727402535119
Validation loss: 2.4898364387686804

Epoch: 6| Step: 9
Training loss: 2.047122387095853
Validation loss: 2.4871191419087175

Epoch: 6| Step: 10
Training loss: 2.6314081357431935
Validation loss: 2.4732328565991524

Epoch: 6| Step: 11
Training loss: 2.1515309760195143
Validation loss: 2.4702540953819767

Epoch: 6| Step: 12
Training loss: 2.4327179387506153
Validation loss: 2.479637918814609

Epoch: 6| Step: 13
Training loss: 3.335327378522808
Validation loss: 2.473997222819249

Epoch: 210| Step: 0
Training loss: 2.469539950535577
Validation loss: 2.5001193735889093

Epoch: 6| Step: 1
Training loss: 2.6444147667524027
Validation loss: 2.518592685476965

Epoch: 6| Step: 2
Training loss: 2.5702687175697365
Validation loss: 2.5295634756479495

Epoch: 6| Step: 3
Training loss: 2.0992727746176714
Validation loss: 2.527740677099234

Epoch: 6| Step: 4
Training loss: 2.8744197757532235
Validation loss: 2.550984125609686

Epoch: 6| Step: 5
Training loss: 2.230198832145264
Validation loss: 2.546564882141541

Epoch: 6| Step: 6
Training loss: 1.8818325167408583
Validation loss: 2.5643444341430888

Epoch: 6| Step: 7
Training loss: 2.8168176358486416
Validation loss: 2.585636741161009

Epoch: 6| Step: 8
Training loss: 2.7204616025918757
Validation loss: 2.6631136397614332

Epoch: 6| Step: 9
Training loss: 2.828436902798143
Validation loss: 2.657371950958899

Epoch: 6| Step: 10
Training loss: 3.2330714745684124
Validation loss: 2.6552605800351086

Epoch: 6| Step: 11
Training loss: 2.0852987047102416
Validation loss: 2.580925468986529

Epoch: 6| Step: 12
Training loss: 2.5665115032937815
Validation loss: 2.528193883518846

Epoch: 6| Step: 13
Training loss: 1.9308468197200794
Validation loss: 2.491987122807323

Epoch: 211| Step: 0
Training loss: 2.4974116277477014
Validation loss: 2.497461946178569

Epoch: 6| Step: 1
Training loss: 2.217533369017544
Validation loss: 2.4890815523352314

Epoch: 6| Step: 2
Training loss: 2.5949129002530897
Validation loss: 2.473136172680197

Epoch: 6| Step: 3
Training loss: 2.482807360596376
Validation loss: 2.4635585751465223

Epoch: 6| Step: 4
Training loss: 2.7231789830083764
Validation loss: 2.4750246844112604

Epoch: 6| Step: 5
Training loss: 2.442636701649244
Validation loss: 2.4748904840695785

Epoch: 6| Step: 6
Training loss: 2.719169145918696
Validation loss: 2.4561172262430953

Epoch: 6| Step: 7
Training loss: 2.482590232200402
Validation loss: 2.4463432116237662

Epoch: 6| Step: 8
Training loss: 2.521110950242253
Validation loss: 2.45007493685313

Epoch: 6| Step: 9
Training loss: 2.7810627734998152
Validation loss: 2.4269951963646332

Epoch: 6| Step: 10
Training loss: 2.979953866383902
Validation loss: 2.4455142962223926

Epoch: 6| Step: 11
Training loss: 2.417480518061376
Validation loss: 2.4360160549075314

Epoch: 6| Step: 12
Training loss: 2.468280506156862
Validation loss: 2.4462161477648325

Epoch: 6| Step: 13
Training loss: 2.1017492275170824
Validation loss: 2.435444802876349

Epoch: 212| Step: 0
Training loss: 2.3059976248418748
Validation loss: 2.4369985550038074

Epoch: 6| Step: 1
Training loss: 3.0024683652254667
Validation loss: 2.4390520235222537

Epoch: 6| Step: 2
Training loss: 2.144385827975841
Validation loss: 2.4837968013767218

Epoch: 6| Step: 3
Training loss: 2.4171042429832754
Validation loss: 2.509081659191949

Epoch: 6| Step: 4
Training loss: 2.380261866484348
Validation loss: 2.5394270571618773

Epoch: 6| Step: 5
Training loss: 2.795941074378007
Validation loss: 2.5521515291974883

Epoch: 6| Step: 6
Training loss: 2.0601302896425593
Validation loss: 2.543617929456325

Epoch: 6| Step: 7
Training loss: 2.5142501960140597
Validation loss: 2.537448368853554

Epoch: 6| Step: 8
Training loss: 2.3881082688648774
Validation loss: 2.503013303286654

Epoch: 6| Step: 9
Training loss: 2.2640502718745976
Validation loss: 2.462739124621637

Epoch: 6| Step: 10
Training loss: 2.752790768931974
Validation loss: 2.4718456182712862

Epoch: 6| Step: 11
Training loss: 2.574507794049634
Validation loss: 2.478718705180218

Epoch: 6| Step: 12
Training loss: 2.4252683432065942
Validation loss: 2.477288536165634

Epoch: 6| Step: 13
Training loss: 2.703917987911535
Validation loss: 2.5173277175455526

Epoch: 213| Step: 0
Training loss: 2.5090698702750625
Validation loss: 2.487749504965508

Epoch: 6| Step: 1
Training loss: 2.5378631106495866
Validation loss: 2.4830908908117415

Epoch: 6| Step: 2
Training loss: 2.3153380428536883
Validation loss: 2.4616442416722073

Epoch: 6| Step: 3
Training loss: 2.59438748166678
Validation loss: 2.4565630928684596

Epoch: 6| Step: 4
Training loss: 2.6047451953413425
Validation loss: 2.4408682759510416

Epoch: 6| Step: 5
Training loss: 2.5853905228966454
Validation loss: 2.459828735530604

Epoch: 6| Step: 6
Training loss: 2.4185508310884423
Validation loss: 2.4876869091863565

Epoch: 6| Step: 7
Training loss: 1.7545901454097879
Validation loss: 2.492105882889595

Epoch: 6| Step: 8
Training loss: 2.802001517045606
Validation loss: 2.522183136131725

Epoch: 6| Step: 9
Training loss: 2.869501744260655
Validation loss: 2.520817297858466

Epoch: 6| Step: 10
Training loss: 2.1943428912050478
Validation loss: 2.557349512104165

Epoch: 6| Step: 11
Training loss: 2.503255060176903
Validation loss: 2.5777292384731614

Epoch: 6| Step: 12
Training loss: 2.8674830146692245
Validation loss: 2.604331883921807

Epoch: 6| Step: 13
Training loss: 2.093783022492034
Validation loss: 2.60664832037381

Epoch: 214| Step: 0
Training loss: 2.6410245875203824
Validation loss: 2.5805307573646377

Epoch: 6| Step: 1
Training loss: 1.790197686941668
Validation loss: 2.558579436782471

Epoch: 6| Step: 2
Training loss: 2.4093101166178483
Validation loss: 2.534938208083034

Epoch: 6| Step: 3
Training loss: 2.5721763647489824
Validation loss: 2.508198372055426

Epoch: 6| Step: 4
Training loss: 2.826705829451031
Validation loss: 2.503453614355676

Epoch: 6| Step: 5
Training loss: 2.1244787811131807
Validation loss: 2.4957689516270425

Epoch: 6| Step: 6
Training loss: 2.488095071435811
Validation loss: 2.5032302824267285

Epoch: 6| Step: 7
Training loss: 2.567689061173133
Validation loss: 2.4983731832125917

Epoch: 6| Step: 8
Training loss: 2.2665796833551948
Validation loss: 2.5188827927892192

Epoch: 6| Step: 9
Training loss: 2.6861064757875064
Validation loss: 2.534170146842538

Epoch: 6| Step: 10
Training loss: 1.891212309104377
Validation loss: 2.5683615370195887

Epoch: 6| Step: 11
Training loss: 2.9701480183820186
Validation loss: 2.564105948522068

Epoch: 6| Step: 12
Training loss: 2.1008040750724044
Validation loss: 2.529045975553011

Epoch: 6| Step: 13
Training loss: 3.030330243132964
Validation loss: 2.5172221889689834

Epoch: 215| Step: 0
Training loss: 2.505257704493506
Validation loss: 2.5001345454691606

Epoch: 6| Step: 1
Training loss: 2.0589104830387233
Validation loss: 2.5212246407982897

Epoch: 6| Step: 2
Training loss: 2.7816324721105596
Validation loss: 2.5444854744200027

Epoch: 6| Step: 3
Training loss: 2.546572240140729
Validation loss: 2.553512122725495

Epoch: 6| Step: 4
Training loss: 2.5870076987347734
Validation loss: 2.582602776373375

Epoch: 6| Step: 5
Training loss: 2.5892115953482517
Validation loss: 2.5679737887283207

Epoch: 6| Step: 6
Training loss: 2.5710160704162037
Validation loss: 2.5435755722857905

Epoch: 6| Step: 7
Training loss: 2.1511386606240532
Validation loss: 2.49339634768591

Epoch: 6| Step: 8
Training loss: 2.219344368424869
Validation loss: 2.4758083864176217

Epoch: 6| Step: 9
Training loss: 2.2853507195563996
Validation loss: 2.4710055061364273

Epoch: 6| Step: 10
Training loss: 2.4733399806314615
Validation loss: 2.440021307869192

Epoch: 6| Step: 11
Training loss: 2.9961052089904725
Validation loss: 2.4608159913072254

Epoch: 6| Step: 12
Training loss: 2.479267844905719
Validation loss: 2.452229970036549

Epoch: 6| Step: 13
Training loss: 1.9831001812535693
Validation loss: 2.4906359449420346

Epoch: 216| Step: 0
Training loss: 2.362098385214533
Validation loss: 2.5058464220233487

Epoch: 6| Step: 1
Training loss: 2.7069949633435564
Validation loss: 2.530028553503712

Epoch: 6| Step: 2
Training loss: 2.4045736245004665
Validation loss: 2.5630416847830486

Epoch: 6| Step: 3
Training loss: 2.8468644410993815
Validation loss: 2.5492114380961004

Epoch: 6| Step: 4
Training loss: 2.1378646093451814
Validation loss: 2.526940622692655

Epoch: 6| Step: 5
Training loss: 2.375395591315366
Validation loss: 2.508225373864579

Epoch: 6| Step: 6
Training loss: 2.2071897196633654
Validation loss: 2.501441360607482

Epoch: 6| Step: 7
Training loss: 2.441723807472405
Validation loss: 2.5361831986474073

Epoch: 6| Step: 8
Training loss: 2.617252178246982
Validation loss: 2.5439330401878513

Epoch: 6| Step: 9
Training loss: 2.1539512211723126
Validation loss: 2.570560435758952

Epoch: 6| Step: 10
Training loss: 2.7724967113093553
Validation loss: 2.5870924567812916

Epoch: 6| Step: 11
Training loss: 2.21375367589179
Validation loss: 2.601040577253254

Epoch: 6| Step: 12
Training loss: 2.358022339964981
Validation loss: 2.5696223292643916

Epoch: 6| Step: 13
Training loss: 1.7485273840933102
Validation loss: 2.5625501238114814

Epoch: 217| Step: 0
Training loss: 2.7482231642104202
Validation loss: 2.51116907847376

Epoch: 6| Step: 1
Training loss: 2.753505293423171
Validation loss: 2.5055126712870983

Epoch: 6| Step: 2
Training loss: 2.1476864143437444
Validation loss: 2.49822341952032

Epoch: 6| Step: 3
Training loss: 2.023383651664941
Validation loss: 2.486940786001862

Epoch: 6| Step: 4
Training loss: 2.612242259768083
Validation loss: 2.480584970906526

Epoch: 6| Step: 5
Training loss: 2.804586084599029
Validation loss: 2.475842654229507

Epoch: 6| Step: 6
Training loss: 1.938342372756221
Validation loss: 2.467616508339757

Epoch: 6| Step: 7
Training loss: 2.024464939212358
Validation loss: 2.488098071850512

Epoch: 6| Step: 8
Training loss: 1.7132924216515473
Validation loss: 2.5094217922844937

Epoch: 6| Step: 9
Training loss: 2.3067296178125436
Validation loss: 2.514158198972098

Epoch: 6| Step: 10
Training loss: 2.1165575730252226
Validation loss: 2.536628212265857

Epoch: 6| Step: 11
Training loss: 2.8562793755220643
Validation loss: 2.55524904561384

Epoch: 6| Step: 12
Training loss: 2.3303053713906006
Validation loss: 2.565545667938847

Epoch: 6| Step: 13
Training loss: 2.667309524614205
Validation loss: 2.5385884453130796

Epoch: 218| Step: 0
Training loss: 2.616697897593084
Validation loss: 2.536837321063372

Epoch: 6| Step: 1
Training loss: 1.9941977736516034
Validation loss: 2.50535546701903

Epoch: 6| Step: 2
Training loss: 2.2407334560816494
Validation loss: 2.4948218956494044

Epoch: 6| Step: 3
Training loss: 2.88534393402498
Validation loss: 2.481448742469214

Epoch: 6| Step: 4
Training loss: 2.16996648349456
Validation loss: 2.4958292246297553

Epoch: 6| Step: 5
Training loss: 2.6224649086232685
Validation loss: 2.4881913188556344

Epoch: 6| Step: 6
Training loss: 2.388347762819169
Validation loss: 2.505856788706876

Epoch: 6| Step: 7
Training loss: 1.790577476097165
Validation loss: 2.495254513400449

Epoch: 6| Step: 8
Training loss: 2.190187819278479
Validation loss: 2.5028681904170136

Epoch: 6| Step: 9
Training loss: 1.8284564247644988
Validation loss: 2.5208334994402914

Epoch: 6| Step: 10
Training loss: 2.712710633427917
Validation loss: 2.5201767063120566

Epoch: 6| Step: 11
Training loss: 2.464629198702549
Validation loss: 2.553849033665689

Epoch: 6| Step: 12
Training loss: 2.4662040426977057
Validation loss: 2.5424590755825616

Epoch: 6| Step: 13
Training loss: 2.31954676262206
Validation loss: 2.5351854563427367

Epoch: 219| Step: 0
Training loss: 2.309018271927798
Validation loss: 2.5547241447143416

Epoch: 6| Step: 1
Training loss: 1.9409557410829268
Validation loss: 2.5976205060191124

Epoch: 6| Step: 2
Training loss: 2.55299083119056
Validation loss: 2.644161542724459

Epoch: 6| Step: 3
Training loss: 2.29684282137589
Validation loss: 2.648176513303428

Epoch: 6| Step: 4
Training loss: 2.5995880974429753
Validation loss: 2.671285534864576

Epoch: 6| Step: 5
Training loss: 2.6602608412292366
Validation loss: 2.638359543133257

Epoch: 6| Step: 6
Training loss: 2.1083525263499485
Validation loss: 2.6433363948458197

Epoch: 6| Step: 7
Training loss: 2.4682259305176237
Validation loss: 2.6039272633100246

Epoch: 6| Step: 8
Training loss: 2.837806275092797
Validation loss: 2.571058484043979

Epoch: 6| Step: 9
Training loss: 2.425936240928448
Validation loss: 2.521592174376147

Epoch: 6| Step: 10
Training loss: 2.00528757178227
Validation loss: 2.5000664507330446

Epoch: 6| Step: 11
Training loss: 2.003825582029484
Validation loss: 2.4711167255495314

Epoch: 6| Step: 12
Training loss: 1.8842781029329256
Validation loss: 2.4967372327457698

Epoch: 6| Step: 13
Training loss: 2.2616811166112885
Validation loss: 2.4749805307974286

Epoch: 220| Step: 0
Training loss: 2.0014846774717143
Validation loss: 2.488106304425836

Epoch: 6| Step: 1
Training loss: 2.5188982974333243
Validation loss: 2.493840220466201

Epoch: 6| Step: 2
Training loss: 2.1951310160819313
Validation loss: 2.489652649092174

Epoch: 6| Step: 3
Training loss: 2.7858214794397034
Validation loss: 2.5003873822325566

Epoch: 6| Step: 4
Training loss: 2.61424632135829
Validation loss: 2.4839918827049554

Epoch: 6| Step: 5
Training loss: 1.9539157334882684
Validation loss: 2.5021532875910464

Epoch: 6| Step: 6
Training loss: 1.9505435821741317
Validation loss: 2.5160759830062354

Epoch: 6| Step: 7
Training loss: 2.1109453925402395
Validation loss: 2.536923584511588

Epoch: 6| Step: 8
Training loss: 2.7054228084495864
Validation loss: 2.5413417403378165

Epoch: 6| Step: 9
Training loss: 2.283162504149721
Validation loss: 2.5857777761971814

Epoch: 6| Step: 10
Training loss: 2.4393546066975986
Validation loss: 2.620267310912138

Epoch: 6| Step: 11
Training loss: 2.469608785250218
Validation loss: 2.6293198725568336

Epoch: 6| Step: 12
Training loss: 1.234056455820042
Validation loss: 2.612096100005522

Epoch: 6| Step: 13
Training loss: 2.793516988232522
Validation loss: 2.664483712823328

Epoch: 221| Step: 0
Training loss: 2.376085635565411
Validation loss: 2.6508190344323075

Epoch: 6| Step: 1
Training loss: 2.0289832745760923
Validation loss: 2.6499409596078394

Epoch: 6| Step: 2
Training loss: 2.242358902284662
Validation loss: 2.6305679476696158

Epoch: 6| Step: 3
Training loss: 2.5825803233503497
Validation loss: 2.6068484300205452

Epoch: 6| Step: 4
Training loss: 1.953419594482026
Validation loss: 2.5855169432314145

Epoch: 6| Step: 5
Training loss: 1.840198782259009
Validation loss: 2.549191427389724

Epoch: 6| Step: 6
Training loss: 2.6211012088311345
Validation loss: 2.53946295092711

Epoch: 6| Step: 7
Training loss: 2.181156770741394
Validation loss: 2.4919883732569668

Epoch: 6| Step: 8
Training loss: 2.2112411452267593
Validation loss: 2.494834179365835

Epoch: 6| Step: 9
Training loss: 2.4527880200289447
Validation loss: 2.4991227056565966

Epoch: 6| Step: 10
Training loss: 2.2806097726060033
Validation loss: 2.508685212423668

Epoch: 6| Step: 11
Training loss: 2.7411382248995344
Validation loss: 2.4967449840192564

Epoch: 6| Step: 12
Training loss: 2.2094041879066744
Validation loss: 2.51189412388098

Epoch: 6| Step: 13
Training loss: 1.8560553015124142
Validation loss: 2.5378184996962463

Epoch: 222| Step: 0
Training loss: 2.2312823680592206
Validation loss: 2.5510473288605033

Epoch: 6| Step: 1
Training loss: 2.2971958273688826
Validation loss: 2.5423984136580304

Epoch: 6| Step: 2
Training loss: 1.7797566227136619
Validation loss: 2.5229326288733045

Epoch: 6| Step: 3
Training loss: 2.130119440016299
Validation loss: 2.529655011756309

Epoch: 6| Step: 4
Training loss: 2.336281741494563
Validation loss: 2.5331801501216513

Epoch: 6| Step: 5
Training loss: 2.226779539003789
Validation loss: 2.549715656454207

Epoch: 6| Step: 6
Training loss: 2.816376451818786
Validation loss: 2.577083299882071

Epoch: 6| Step: 7
Training loss: 1.6089885951480223
Validation loss: 2.5632702139891563

Epoch: 6| Step: 8
Training loss: 2.293226393305857
Validation loss: 2.560047309458211

Epoch: 6| Step: 9
Training loss: 2.0789736972262407
Validation loss: 2.6090401467841455

Epoch: 6| Step: 10
Training loss: 2.6439094657691276
Validation loss: 2.6564606131263777

Epoch: 6| Step: 11
Training loss: 2.078843759703528
Validation loss: 2.677740617186535

Epoch: 6| Step: 12
Training loss: 2.5347701661846265
Validation loss: 2.6737385278952996

Epoch: 6| Step: 13
Training loss: 1.864595729282312
Validation loss: 2.6621461868043155

Epoch: 223| Step: 0
Training loss: 2.5844259310112374
Validation loss: 2.575499717433151

Epoch: 6| Step: 1
Training loss: 2.363523764029015
Validation loss: 2.5213758663986092

Epoch: 6| Step: 2
Training loss: 1.9117072114023332
Validation loss: 2.49963832823245

Epoch: 6| Step: 3
Training loss: 2.285815543247947
Validation loss: 2.4806210577786265

Epoch: 6| Step: 4
Training loss: 1.9466786930069824
Validation loss: 2.4949793988497992

Epoch: 6| Step: 5
Training loss: 2.202266552922986
Validation loss: 2.4998151208340627

Epoch: 6| Step: 6
Training loss: 2.527499116016388
Validation loss: 2.484900721981762

Epoch: 6| Step: 7
Training loss: 2.087192686382623
Validation loss: 2.476158439602978

Epoch: 6| Step: 8
Training loss: 2.2825102786849056
Validation loss: 2.497884961130169

Epoch: 6| Step: 9
Training loss: 2.148449041162183
Validation loss: 2.5182226709284463

Epoch: 6| Step: 10
Training loss: 2.031943334945801
Validation loss: 2.5016699033444625

Epoch: 6| Step: 11
Training loss: 2.2008296832577146
Validation loss: 2.5342844037436616

Epoch: 6| Step: 12
Training loss: 2.3823362781354693
Validation loss: 2.5391741883455827

Epoch: 6| Step: 13
Training loss: 1.935546197515806
Validation loss: 2.5305073189273557

Epoch: 224| Step: 0
Training loss: 2.0758221709468003
Validation loss: 2.516963800447116

Epoch: 6| Step: 1
Training loss: 1.616105238117486
Validation loss: 2.529297395979235

Epoch: 6| Step: 2
Training loss: 2.2855128344248694
Validation loss: 2.504212516911055

Epoch: 6| Step: 3
Training loss: 2.5507475075235204
Validation loss: 2.556760547643412

Epoch: 6| Step: 4
Training loss: 2.3552978858529796
Validation loss: 2.56508936440758

Epoch: 6| Step: 5
Training loss: 2.303368556318722
Validation loss: 2.625138666345149

Epoch: 6| Step: 6
Training loss: 2.082300336958706
Validation loss: 2.631819545003729

Epoch: 6| Step: 7
Training loss: 2.380807301778774
Validation loss: 2.5974385157561946

Epoch: 6| Step: 8
Training loss: 2.433079942373749
Validation loss: 2.6127330974550778

Epoch: 6| Step: 9
Training loss: 2.4169299431694764
Validation loss: 2.607357289167786

Epoch: 6| Step: 10
Training loss: 1.6064627510214209
Validation loss: 2.58249188518918

Epoch: 6| Step: 11
Training loss: 1.976709955919723
Validation loss: 2.54949273793131

Epoch: 6| Step: 12
Training loss: 2.125584465880911
Validation loss: 2.522987722105836

Epoch: 6| Step: 13
Training loss: 2.5027678426568176
Validation loss: 2.5363184870612265

Epoch: 225| Step: 0
Training loss: 2.4807026910473633
Validation loss: 2.495688984265844

Epoch: 6| Step: 1
Training loss: 2.01277159759605
Validation loss: 2.5031217690912304

Epoch: 6| Step: 2
Training loss: 1.810801664035404
Validation loss: 2.530289326251636

Epoch: 6| Step: 3
Training loss: 2.033271136140363
Validation loss: 2.4969681557496526

Epoch: 6| Step: 4
Training loss: 1.8259343773121322
Validation loss: 2.5118119621482253

Epoch: 6| Step: 5
Training loss: 2.181567622016038
Validation loss: 2.512996917326867

Epoch: 6| Step: 6
Training loss: 2.3115234375
Validation loss: 2.517202014603338

Epoch: 6| Step: 7
Training loss: 1.9452119977489661
Validation loss: 2.5259067395762322

Epoch: 6| Step: 8
Training loss: 2.1690117054223745
Validation loss: 2.5230039818937455

Epoch: 6| Step: 9
Training loss: 2.4522721089632213
Validation loss: 2.538026754876911

Epoch: 6| Step: 10
Training loss: 2.110286939373814
Validation loss: 2.5328443183627867

Epoch: 6| Step: 11
Training loss: 2.092849309972634
Validation loss: 2.539244458010475

Epoch: 6| Step: 12
Training loss: 2.247368439249203
Validation loss: 2.56767518205306

Epoch: 6| Step: 13
Training loss: 2.2047845528461494
Validation loss: 2.5895902821785817

Epoch: 226| Step: 0
Training loss: 1.9392904806944118
Validation loss: 2.6167928359844677

Epoch: 6| Step: 1
Training loss: 2.292202095136092
Validation loss: 2.6907050073227805

Epoch: 6| Step: 2
Training loss: 2.5134730642046716
Validation loss: 2.709396582080335

Epoch: 6| Step: 3
Training loss: 2.173248954180285
Validation loss: 2.7111712698322505

Epoch: 6| Step: 4
Training loss: 2.3899828478465044
Validation loss: 2.737362693451906

Epoch: 6| Step: 5
Training loss: 1.8512173101512654
Validation loss: 2.7240688322189133

Epoch: 6| Step: 6
Training loss: 2.4381675784166057
Validation loss: 2.717038562770127

Epoch: 6| Step: 7
Training loss: 1.9620363112889645
Validation loss: 2.657671146376818

Epoch: 6| Step: 8
Training loss: 1.8962444935506837
Validation loss: 2.6155012570578995

Epoch: 6| Step: 9
Training loss: 2.3034628507724877
Validation loss: 2.5869092026147538

Epoch: 6| Step: 10
Training loss: 2.064147984411557
Validation loss: 2.517096936022236

Epoch: 6| Step: 11
Training loss: 2.0518800534741826
Validation loss: 2.5075734950735113

Epoch: 6| Step: 12
Training loss: 1.9277904622151978
Validation loss: 2.4827383414481736

Epoch: 6| Step: 13
Training loss: 1.61686319978741
Validation loss: 2.4832565061048157

Epoch: 227| Step: 0
Training loss: 2.0180635117667665
Validation loss: 2.4946066525979176

Epoch: 6| Step: 1
Training loss: 1.3494458686060637
Validation loss: 2.477054552112356

Epoch: 6| Step: 2
Training loss: 2.199707518989263
Validation loss: 2.478021626308523

Epoch: 6| Step: 3
Training loss: 2.1564176190227706
Validation loss: 2.5019113771028025

Epoch: 6| Step: 4
Training loss: 2.136529387568561
Validation loss: 2.491862720249257

Epoch: 6| Step: 5
Training loss: 2.1451081714164526
Validation loss: 2.4894695780306377

Epoch: 6| Step: 6
Training loss: 2.207207326701421
Validation loss: 2.5076752760149548

Epoch: 6| Step: 7
Training loss: 2.1730102206822344
Validation loss: 2.5446171035551033

Epoch: 6| Step: 8
Training loss: 1.8064729519953775
Validation loss: 2.562748836637876

Epoch: 6| Step: 9
Training loss: 2.2440965347673294
Validation loss: 2.6142541959044374

Epoch: 6| Step: 10
Training loss: 2.198689100540079
Validation loss: 2.6505486584980162

Epoch: 6| Step: 11
Training loss: 2.3908178712919486
Validation loss: 2.670625807326588

Epoch: 6| Step: 12
Training loss: 1.9049236498573607
Validation loss: 2.688588248539602

Epoch: 6| Step: 13
Training loss: 2.397086493003067
Validation loss: 2.702574650718089

Epoch: 228| Step: 0
Training loss: 2.3445570509907285
Validation loss: 2.6547944222995445

Epoch: 6| Step: 1
Training loss: 2.1143491518231867
Validation loss: 2.651712536559883

Epoch: 6| Step: 2
Training loss: 2.4438735579452797
Validation loss: 2.61693523564418

Epoch: 6| Step: 3
Training loss: 1.6790632640468408
Validation loss: 2.598690101893573

Epoch: 6| Step: 4
Training loss: 1.7579181554618777
Validation loss: 2.580483500771329

Epoch: 6| Step: 5
Training loss: 2.216574771190468
Validation loss: 2.569744579106364

Epoch: 6| Step: 6
Training loss: 1.9856211436579128
Validation loss: 2.5702032340357004

Epoch: 6| Step: 7
Training loss: 1.884125817367993
Validation loss: 2.5836913922197335

Epoch: 6| Step: 8
Training loss: 2.210820387040169
Validation loss: 2.5633024814484267

Epoch: 6| Step: 9
Training loss: 2.3021712710700593
Validation loss: 2.543919252157398

Epoch: 6| Step: 10
Training loss: 2.004205811475812
Validation loss: 2.510963848699215

Epoch: 6| Step: 11
Training loss: 1.808373324513096
Validation loss: 2.5278584977946905

Epoch: 6| Step: 12
Training loss: 2.1292645914012924
Validation loss: 2.5658415689790393

Epoch: 6| Step: 13
Training loss: 2.260764439516569
Validation loss: 2.556837726608224

Epoch: 229| Step: 0
Training loss: 2.112748225148044
Validation loss: 2.6297102788101734

Epoch: 6| Step: 1
Training loss: 2.2959102758494234
Validation loss: 2.676753680802248

Epoch: 6| Step: 2
Training loss: 2.477241302749068
Validation loss: 2.7685267679797896

Epoch: 6| Step: 3
Training loss: 1.7113354363858881
Validation loss: 2.777389207310494

Epoch: 6| Step: 4
Training loss: 2.1425811294631965
Validation loss: 2.7629149140626157

Epoch: 6| Step: 5
Training loss: 2.2336400030256565
Validation loss: 2.73593866738243

Epoch: 6| Step: 6
Training loss: 1.781164602273767
Validation loss: 2.6984570626750246

Epoch: 6| Step: 7
Training loss: 2.2191762380456836
Validation loss: 2.6548218982083855

Epoch: 6| Step: 8
Training loss: 1.9935076957957854
Validation loss: 2.634342319141447

Epoch: 6| Step: 9
Training loss: 1.7483936157719169
Validation loss: 2.604366034638918

Epoch: 6| Step: 10
Training loss: 2.4250004443925275
Validation loss: 2.6234599291816876

Epoch: 6| Step: 11
Training loss: 1.9171748800569643
Validation loss: 2.5910123335050286

Epoch: 6| Step: 12
Training loss: 2.178937010276106
Validation loss: 2.5717118243639483

Epoch: 6| Step: 13
Training loss: 3.0659863615784015
Validation loss: 2.537377396761743

Epoch: 230| Step: 0
Training loss: 1.8987149008444424
Validation loss: 2.472211499075889

Epoch: 6| Step: 1
Training loss: 2.185600109662211
Validation loss: 2.455450744229836

Epoch: 6| Step: 2
Training loss: 2.1085035996672072
Validation loss: 2.455024078732584

Epoch: 6| Step: 3
Training loss: 1.8933988667393742
Validation loss: 2.4836275298773116

Epoch: 6| Step: 4
Training loss: 2.157884945437115
Validation loss: 2.496906692542157

Epoch: 6| Step: 5
Training loss: 2.052053757920764
Validation loss: 2.565849416230017

Epoch: 6| Step: 6
Training loss: 2.250043232820327
Validation loss: 2.6009726296140987

Epoch: 6| Step: 7
Training loss: 2.5623790433295257
Validation loss: 2.630790102394031

Epoch: 6| Step: 8
Training loss: 2.6257768117361517
Validation loss: 2.583349581801978

Epoch: 6| Step: 9
Training loss: 1.8510650095186045
Validation loss: 2.5583060935696245

Epoch: 6| Step: 10
Training loss: 1.7024849205077484
Validation loss: 2.558257143244194

Epoch: 6| Step: 11
Training loss: 1.9594982078059304
Validation loss: 2.5587827871765563

Epoch: 6| Step: 12
Training loss: 2.0374829250626556
Validation loss: 2.54034723005236

Epoch: 6| Step: 13
Training loss: 2.073542770323614
Validation loss: 2.5576472108661354

Epoch: 231| Step: 0
Training loss: 2.234616353264438
Validation loss: 2.580810391292008

Epoch: 6| Step: 1
Training loss: 2.2394781989918466
Validation loss: 2.572069547176397

Epoch: 6| Step: 2
Training loss: 1.9231988332694097
Validation loss: 2.6150576652264728

Epoch: 6| Step: 3
Training loss: 2.0418761269175416
Validation loss: 2.6030696489415757

Epoch: 6| Step: 4
Training loss: 2.2069694577909478
Validation loss: 2.566448977550138

Epoch: 6| Step: 5
Training loss: 2.0631422718969565
Validation loss: 2.520372122955287

Epoch: 6| Step: 6
Training loss: 1.742237586426189
Validation loss: 2.4978934775566892

Epoch: 6| Step: 7
Training loss: 1.6874059015105514
Validation loss: 2.4764606691299624

Epoch: 6| Step: 8
Training loss: 1.6821918359509607
Validation loss: 2.477605898355353

Epoch: 6| Step: 9
Training loss: 2.1670114414069714
Validation loss: 2.466060897151611

Epoch: 6| Step: 10
Training loss: 1.8993987487332546
Validation loss: 2.4827911845024646

Epoch: 6| Step: 11
Training loss: 2.19678510370726
Validation loss: 2.5167722191203663

Epoch: 6| Step: 12
Training loss: 2.2856617947068885
Validation loss: 2.5246650272579183

Epoch: 6| Step: 13
Training loss: 2.05754453497299
Validation loss: 2.5422554006692346

Epoch: 232| Step: 0
Training loss: 1.9123323055373398
Validation loss: 2.587440505257036

Epoch: 6| Step: 1
Training loss: 1.8382556970249415
Validation loss: 2.596979760728926

Epoch: 6| Step: 2
Training loss: 2.186832217059381
Validation loss: 2.6126546043577843

Epoch: 6| Step: 3
Training loss: 1.4536865953967204
Validation loss: 2.597231800660579

Epoch: 6| Step: 4
Training loss: 2.096947463214724
Validation loss: 2.589319249296702

Epoch: 6| Step: 5
Training loss: 2.522067521887734
Validation loss: 2.569162658594828

Epoch: 6| Step: 6
Training loss: 1.4606886055008406
Validation loss: 2.534808464192024

Epoch: 6| Step: 7
Training loss: 1.6388538791487568
Validation loss: 2.547435468070329

Epoch: 6| Step: 8
Training loss: 1.965868460856271
Validation loss: 2.525224916237907

Epoch: 6| Step: 9
Training loss: 2.0281389327077646
Validation loss: 2.53941119933571

Epoch: 6| Step: 10
Training loss: 2.17105745804781
Validation loss: 2.5512687449555367

Epoch: 6| Step: 11
Training loss: 1.9867583252523682
Validation loss: 2.5497081245318465

Epoch: 6| Step: 12
Training loss: 2.1934450290766474
Validation loss: 2.5558455597903205

Epoch: 6| Step: 13
Training loss: 2.1480722567731756
Validation loss: 2.5851688301489553

Epoch: 233| Step: 0
Training loss: 2.0003711832834035
Validation loss: 2.5662632053235424

Epoch: 6| Step: 1
Training loss: 2.4465195476812114
Validation loss: 2.5877130406551676

Epoch: 6| Step: 2
Training loss: 2.432803593633344
Validation loss: 2.6087612997216065

Epoch: 6| Step: 3
Training loss: 1.8972906722452978
Validation loss: 2.6188873838827984

Epoch: 6| Step: 4
Training loss: 1.4602773062058787
Validation loss: 2.615215455684887

Epoch: 6| Step: 5
Training loss: 2.072284723565973
Validation loss: 2.6365796824325134

Epoch: 6| Step: 6
Training loss: 2.2525869967884895
Validation loss: 2.6241405699409515

Epoch: 6| Step: 7
Training loss: 1.5793342112265956
Validation loss: 2.6049416292596597

Epoch: 6| Step: 8
Training loss: 1.7805085897905326
Validation loss: 2.616443574465046

Epoch: 6| Step: 9
Training loss: 1.4299726358209717
Validation loss: 2.636043754295793

Epoch: 6| Step: 10
Training loss: 1.8845815618105932
Validation loss: 2.587854369689866

Epoch: 6| Step: 11
Training loss: 1.2847496711387592
Validation loss: 2.590357050143212

Epoch: 6| Step: 12
Training loss: 2.225544372143672
Validation loss: 2.5561551384115715

Epoch: 6| Step: 13
Training loss: 1.6673422715655344
Validation loss: 2.555891473987125

Epoch: 234| Step: 0
Training loss: 1.6258279451834619
Validation loss: 2.5494567058286566

Epoch: 6| Step: 1
Training loss: 1.3087674609224547
Validation loss: 2.5342620183104825

Epoch: 6| Step: 2
Training loss: 1.8331192137207106
Validation loss: 2.5225400561602673

Epoch: 6| Step: 3
Training loss: 2.1950792073272503
Validation loss: 2.527531677857721

Epoch: 6| Step: 4
Training loss: 2.083923281745674
Validation loss: 2.533927288546856

Epoch: 6| Step: 5
Training loss: 2.0497756090868635
Validation loss: 2.5468974245534812

Epoch: 6| Step: 6
Training loss: 2.0965787084148815
Validation loss: 2.549579799919739

Epoch: 6| Step: 7
Training loss: 2.004423732753942
Validation loss: 2.5420290797682092

Epoch: 6| Step: 8
Training loss: 1.7213372611073172
Validation loss: 2.585738172867638

Epoch: 6| Step: 9
Training loss: 2.349758939350818
Validation loss: 2.5772728827783875

Epoch: 6| Step: 10
Training loss: 1.3554025243581698
Validation loss: 2.5767264561866035

Epoch: 6| Step: 11
Training loss: 1.749691799817369
Validation loss: 2.577833431756913

Epoch: 6| Step: 12
Training loss: 2.2881509573828325
Validation loss: 2.5981679040699794

Epoch: 6| Step: 13
Training loss: 1.6175881594374528
Validation loss: 2.5915994932281468

Epoch: 235| Step: 0
Training loss: 1.6245603700306195
Validation loss: 2.5887288569581743

Epoch: 6| Step: 1
Training loss: 1.8021767064712761
Validation loss: 2.5885274678756947

Epoch: 6| Step: 2
Training loss: 2.2717748900635044
Validation loss: 2.6043355014994476

Epoch: 6| Step: 3
Training loss: 1.6842661353549115
Validation loss: 2.5980555665769063

Epoch: 6| Step: 4
Training loss: 2.120838128804579
Validation loss: 2.5896467470092523

Epoch: 6| Step: 5
Training loss: 1.8431519653789996
Validation loss: 2.5797855084917343

Epoch: 6| Step: 6
Training loss: 1.9212676538513824
Validation loss: 2.5792897645737516

Epoch: 6| Step: 7
Training loss: 2.3861452902774962
Validation loss: 2.5737549318527724

Epoch: 6| Step: 8
Training loss: 1.6659979511857457
Validation loss: 2.5512470039432524

Epoch: 6| Step: 9
Training loss: 1.818988498636703
Validation loss: 2.526480060099735

Epoch: 6| Step: 10
Training loss: 1.388547309621728
Validation loss: 2.506385431688057

Epoch: 6| Step: 11
Training loss: 1.9237925569760923
Validation loss: 2.504115305598692

Epoch: 6| Step: 12
Training loss: 2.020742145591497
Validation loss: 2.4983708662235693

Epoch: 6| Step: 13
Training loss: 1.67656890213767
Validation loss: 2.501211368194626

Epoch: 236| Step: 0
Training loss: 1.8705980126001558
Validation loss: 2.5306868935178475

Epoch: 6| Step: 1
Training loss: 2.197057498823644
Validation loss: 2.5447743526012103

Epoch: 6| Step: 2
Training loss: 1.8146328051801852
Validation loss: 2.526775822180077

Epoch: 6| Step: 3
Training loss: 1.9546899858027447
Validation loss: 2.5301261786149523

Epoch: 6| Step: 4
Training loss: 1.8006319658541243
Validation loss: 2.537371929749055

Epoch: 6| Step: 5
Training loss: 1.6087018429203352
Validation loss: 2.526296576901449

Epoch: 6| Step: 6
Training loss: 1.44160472464851
Validation loss: 2.5402666915088314

Epoch: 6| Step: 7
Training loss: 1.8775737899319442
Validation loss: 2.556678137152336

Epoch: 6| Step: 8
Training loss: 1.6242578719190395
Validation loss: 2.5523377319137626

Epoch: 6| Step: 9
Training loss: 1.9769833082884694
Validation loss: 2.5624074241388994

Epoch: 6| Step: 10
Training loss: 1.7009198673307824
Validation loss: 2.586027480826685

Epoch: 6| Step: 11
Training loss: 2.355270453309692
Validation loss: 2.5725904745103874

Epoch: 6| Step: 12
Training loss: 1.6715804936925145
Validation loss: 2.58127688157251

Epoch: 6| Step: 13
Training loss: 2.002297631371507
Validation loss: 2.572881297731578

Epoch: 237| Step: 0
Training loss: 1.1818094432447717
Validation loss: 2.552614284296415

Epoch: 6| Step: 1
Training loss: 2.0399612258517354
Validation loss: 2.5395596056554206

Epoch: 6| Step: 2
Training loss: 1.681560377095883
Validation loss: 2.5393991312496182

Epoch: 6| Step: 3
Training loss: 2.0478257162621456
Validation loss: 2.5186628942141143

Epoch: 6| Step: 4
Training loss: 1.8845265291188227
Validation loss: 2.5324917867578947

Epoch: 6| Step: 5
Training loss: 1.665008777331795
Validation loss: 2.5286832288590047

Epoch: 6| Step: 6
Training loss: 2.0598193000500413
Validation loss: 2.5269052774613736

Epoch: 6| Step: 7
Training loss: 1.8654039875025936
Validation loss: 2.5254931608033533

Epoch: 6| Step: 8
Training loss: 1.5116323204863236
Validation loss: 2.519054814290306

Epoch: 6| Step: 9
Training loss: 1.8826041838450815
Validation loss: 2.5287651485949865

Epoch: 6| Step: 10
Training loss: 1.401302535529549
Validation loss: 2.5467657189975474

Epoch: 6| Step: 11
Training loss: 2.169516181275316
Validation loss: 2.5679001122002165

Epoch: 6| Step: 12
Training loss: 2.1147646395623814
Validation loss: 2.5866778643897685

Epoch: 6| Step: 13
Training loss: 2.015704959200117
Validation loss: 2.6015578645640676

Epoch: 238| Step: 0
Training loss: 1.9441553067386286
Validation loss: 2.584445022154397

Epoch: 6| Step: 1
Training loss: 1.2903551960387787
Validation loss: 2.5862828669612647

Epoch: 6| Step: 2
Training loss: 1.674075238605033
Validation loss: 2.5836141958262155

Epoch: 6| Step: 3
Training loss: 2.21060383034563
Validation loss: 2.5532904332825717

Epoch: 6| Step: 4
Training loss: 2.0014832480208655
Validation loss: 2.5291287167564063

Epoch: 6| Step: 5
Training loss: 2.0699547800478326
Validation loss: 2.5197767472115533

Epoch: 6| Step: 6
Training loss: 2.2587271029183147
Validation loss: 2.517339797749509

Epoch: 6| Step: 7
Training loss: 1.8401318626216239
Validation loss: 2.5114720690573002

Epoch: 6| Step: 8
Training loss: 1.4522329073711238
Validation loss: 2.531389762031007

Epoch: 6| Step: 9
Training loss: 1.6569979436351698
Validation loss: 2.5279512035637275

Epoch: 6| Step: 10
Training loss: 1.7436912444685777
Validation loss: 2.5514039257614525

Epoch: 6| Step: 11
Training loss: 1.8012024227638563
Validation loss: 2.599056194624127

Epoch: 6| Step: 12
Training loss: 1.2739051007149007
Validation loss: 2.6217995522820057

Epoch: 6| Step: 13
Training loss: 1.6527161956270544
Validation loss: 2.6152028286813738

Epoch: 239| Step: 0
Training loss: 1.7737968853701107
Validation loss: 2.60623820664604

Epoch: 6| Step: 1
Training loss: 1.761820720419722
Validation loss: 2.570323948180594

Epoch: 6| Step: 2
Training loss: 1.7148483380579995
Validation loss: 2.5310900217433363

Epoch: 6| Step: 3
Training loss: 2.0913852603672747
Validation loss: 2.5188299456011123

Epoch: 6| Step: 4
Training loss: 1.3364849641941008
Validation loss: 2.513857100601587

Epoch: 6| Step: 5
Training loss: 1.5647939246516094
Validation loss: 2.5564255396877598

Epoch: 6| Step: 6
Training loss: 1.6559518509743456
Validation loss: 2.559707867206941

Epoch: 6| Step: 7
Training loss: 1.6640138574215781
Validation loss: 2.549370519534485

Epoch: 6| Step: 8
Training loss: 1.7295062486194352
Validation loss: 2.573607908187358

Epoch: 6| Step: 9
Training loss: 1.76435293099374
Validation loss: 2.558659956481831

Epoch: 6| Step: 10
Training loss: 1.9997820735457164
Validation loss: 2.554947673415178

Epoch: 6| Step: 11
Training loss: 1.686776465258512
Validation loss: 2.5288793628084476

Epoch: 6| Step: 12
Training loss: 2.19366088860089
Validation loss: 2.5231955462520386

Epoch: 6| Step: 13
Training loss: 1.7419592874676912
Validation loss: 2.4979145827334266

Epoch: 240| Step: 0
Training loss: 1.740450964399388
Validation loss: 2.4916740601198386

Epoch: 6| Step: 1
Training loss: 1.9875713647469764
Validation loss: 2.4797740342918555

Epoch: 6| Step: 2
Training loss: 1.9005677629738102
Validation loss: 2.468218360772338

Epoch: 6| Step: 3
Training loss: 1.8253413469033248
Validation loss: 2.4601964232874844

Epoch: 6| Step: 4
Training loss: 1.7062082641862886
Validation loss: 2.4809485708682892

Epoch: 6| Step: 5
Training loss: 1.5344321215032937
Validation loss: 2.510055880295294

Epoch: 6| Step: 6
Training loss: 1.971899389729748
Validation loss: 2.491038992837645

Epoch: 6| Step: 7
Training loss: 1.7209191246291629
Validation loss: 2.4925247968628264

Epoch: 6| Step: 8
Training loss: 1.2079793915917
Validation loss: 2.515741778540669

Epoch: 6| Step: 9
Training loss: 1.595240699878456
Validation loss: 2.5102138696930503

Epoch: 6| Step: 10
Training loss: 1.7955969204219142
Validation loss: 2.4877963080439076

Epoch: 6| Step: 11
Training loss: 2.308637744465003
Validation loss: 2.4780059776352905

Epoch: 6| Step: 12
Training loss: 1.1565733792469208
Validation loss: 2.5191911080340748

Epoch: 6| Step: 13
Training loss: 1.6740040992631935
Validation loss: 2.5530602646889933

Epoch: 241| Step: 0
Training loss: 1.2220500381638908
Validation loss: 2.5648786028466737

Epoch: 6| Step: 1
Training loss: 1.431234221392283
Validation loss: 2.611373965882268

Epoch: 6| Step: 2
Training loss: 1.7489778394522035
Validation loss: 2.6228607160298663

Epoch: 6| Step: 3
Training loss: 1.6540553109124305
Validation loss: 2.586007060068458

Epoch: 6| Step: 4
Training loss: 1.9294113394006127
Validation loss: 2.6080279823940784

Epoch: 6| Step: 5
Training loss: 1.9244880590031224
Validation loss: 2.556645617627488

Epoch: 6| Step: 6
Training loss: 1.8815024475844067
Validation loss: 2.532553447205601

Epoch: 6| Step: 7
Training loss: 1.3198406572690675
Validation loss: 2.5059742137499947

Epoch: 6| Step: 8
Training loss: 1.6965916462009178
Validation loss: 2.5344094313855803

Epoch: 6| Step: 9
Training loss: 1.4635530609375136
Validation loss: 2.5428399965650375

Epoch: 6| Step: 10
Training loss: 1.9118127797412865
Validation loss: 2.5504389581913465

Epoch: 6| Step: 11
Training loss: 2.0714720735538945
Validation loss: 2.574438909124299

Epoch: 6| Step: 12
Training loss: 1.8536819367315143
Validation loss: 2.556330941706406

Epoch: 6| Step: 13
Training loss: 2.136766617986726
Validation loss: 2.573347343504662

Epoch: 242| Step: 0
Training loss: 0.9219071980688709
Validation loss: 2.5613620741587666

Epoch: 6| Step: 1
Training loss: 2.108200537478725
Validation loss: 2.5761759779412774

Epoch: 6| Step: 2
Training loss: 1.2599933743681107
Validation loss: 2.5858316434850392

Epoch: 6| Step: 3
Training loss: 2.027421835863743
Validation loss: 2.578705693362179

Epoch: 6| Step: 4
Training loss: 2.3663395033169894
Validation loss: 2.569346158772372

Epoch: 6| Step: 5
Training loss: 1.962544728638027
Validation loss: 2.5902629797511127

Epoch: 6| Step: 6
Training loss: 1.6537620283339598
Validation loss: 2.5562531542312894

Epoch: 6| Step: 7
Training loss: 1.8373144951428129
Validation loss: 2.522661889511485

Epoch: 6| Step: 8
Training loss: 1.763191436521951
Validation loss: 2.4922028508078267

Epoch: 6| Step: 9
Training loss: 1.624982393609548
Validation loss: 2.4428530580498284

Epoch: 6| Step: 10
Training loss: 1.4481727135856495
Validation loss: 2.444264283941516

Epoch: 6| Step: 11
Training loss: 1.5714977592867376
Validation loss: 2.417920154216592

Epoch: 6| Step: 12
Training loss: 1.5291352753011382
Validation loss: 2.4403675545813366

Epoch: 6| Step: 13
Training loss: 1.3852143629936078
Validation loss: 2.4345272669457927

Epoch: 243| Step: 0
Training loss: 1.9229782163523839
Validation loss: 2.4761720427639258

Epoch: 6| Step: 1
Training loss: 1.5716823088163179
Validation loss: 2.502437592710345

Epoch: 6| Step: 2
Training loss: 1.3589535640898172
Validation loss: 2.5116081353140385

Epoch: 6| Step: 3
Training loss: 1.5209834751934432
Validation loss: 2.5424410213495565

Epoch: 6| Step: 4
Training loss: 2.130847291011795
Validation loss: 2.595369774417581

Epoch: 6| Step: 5
Training loss: 1.421662786388282
Validation loss: 2.633107151805106

Epoch: 6| Step: 6
Training loss: 1.2458766640535013
Validation loss: 2.6472672049230206

Epoch: 6| Step: 7
Training loss: 1.51812019633212
Validation loss: 2.6250437895466865

Epoch: 6| Step: 8
Training loss: 1.9747118824236627
Validation loss: 2.6333424920306654

Epoch: 6| Step: 9
Training loss: 1.3516880925209376
Validation loss: 2.587556580530314

Epoch: 6| Step: 10
Training loss: 1.9572859729672527
Validation loss: 2.511497388161015

Epoch: 6| Step: 11
Training loss: 1.8954222167006427
Validation loss: 2.500000595790013

Epoch: 6| Step: 12
Training loss: 1.9167694257749661
Validation loss: 2.491406473456201

Epoch: 6| Step: 13
Training loss: 1.259047949946662
Validation loss: 2.468561579890903

Epoch: 244| Step: 0
Training loss: 1.5320877586109254
Validation loss: 2.479287763371281

Epoch: 6| Step: 1
Training loss: 1.010264408136268
Validation loss: 2.50272367246993

Epoch: 6| Step: 2
Training loss: 1.7328700504085075
Validation loss: 2.5287305344745987

Epoch: 6| Step: 3
Training loss: 1.8468983811707382
Validation loss: 2.551923865801797

Epoch: 6| Step: 4
Training loss: 1.3952760390487011
Validation loss: 2.5792462945574877

Epoch: 6| Step: 5
Training loss: 1.7830739637813517
Validation loss: 2.5531399784353406

Epoch: 6| Step: 6
Training loss: 1.785923031458815
Validation loss: 2.5427342060284466

Epoch: 6| Step: 7
Training loss: 1.8691354590078493
Validation loss: 2.540596543205062

Epoch: 6| Step: 8
Training loss: 1.8337612158517491
Validation loss: 2.5304720417510596

Epoch: 6| Step: 9
Training loss: 1.2205745537759578
Validation loss: 2.5218840155004694

Epoch: 6| Step: 10
Training loss: 1.992981038341673
Validation loss: 2.497523532242382

Epoch: 6| Step: 11
Training loss: 1.4308506970841477
Validation loss: 2.5055296563499923

Epoch: 6| Step: 12
Training loss: 1.9415060896501668
Validation loss: 2.5336609264950463

Epoch: 6| Step: 13
Training loss: 1.8983292411422943
Validation loss: 2.5320267624248016

Epoch: 245| Step: 0
Training loss: 1.1856554663508685
Validation loss: 2.572889330763866

Epoch: 6| Step: 1
Training loss: 1.4774528927078854
Validation loss: 2.5705386873701346

Epoch: 6| Step: 2
Training loss: 2.3207822381997745
Validation loss: 2.5491985133176844

Epoch: 6| Step: 3
Training loss: 1.382148971417359
Validation loss: 2.577706032895436

Epoch: 6| Step: 4
Training loss: 1.889707610709495
Validation loss: 2.5580766719128993

Epoch: 6| Step: 5
Training loss: 1.206641767062273
Validation loss: 2.530624178595883

Epoch: 6| Step: 6
Training loss: 1.923638008134673
Validation loss: 2.532252404023937

Epoch: 6| Step: 7
Training loss: 0.975076139362625
Validation loss: 2.4915869780716924

Epoch: 6| Step: 8
Training loss: 1.3702480827336225
Validation loss: 2.469941314535499

Epoch: 6| Step: 9
Training loss: 2.1122367378836193
Validation loss: 2.5016892550592718

Epoch: 6| Step: 10
Training loss: 1.6987545387819356
Validation loss: 2.5067372938740964

Epoch: 6| Step: 11
Training loss: 1.8040137416290853
Validation loss: 2.505693169548856

Epoch: 6| Step: 12
Training loss: 1.305822826425186
Validation loss: 2.4599203288691838

Epoch: 6| Step: 13
Training loss: 1.4766386305140276
Validation loss: 2.504990877026764

Epoch: 246| Step: 0
Training loss: 1.9642175241499436
Validation loss: 2.4798778411128177

Epoch: 6| Step: 1
Training loss: 2.17736441031332
Validation loss: 2.504116594526052

Epoch: 6| Step: 2
Training loss: 1.7208628758934204
Validation loss: 2.5008623425320824

Epoch: 6| Step: 3
Training loss: 1.4227302410527978
Validation loss: 2.4977542275679983

Epoch: 6| Step: 4
Training loss: 1.7645588584502652
Validation loss: 2.4967897774684125

Epoch: 6| Step: 5
Training loss: 1.5909072355779754
Validation loss: 2.496251141114724

Epoch: 6| Step: 6
Training loss: 1.4473012901781688
Validation loss: 2.5132804808305513

Epoch: 6| Step: 7
Training loss: 1.0858493467268981
Validation loss: 2.5270923360691224

Epoch: 6| Step: 8
Training loss: 1.3444142141612798
Validation loss: 2.496508939813841

Epoch: 6| Step: 9
Training loss: 1.2658873392119407
Validation loss: 2.513982202410864

Epoch: 6| Step: 10
Training loss: 1.392367011248274
Validation loss: 2.4962098822252066

Epoch: 6| Step: 11
Training loss: 2.222738415317296
Validation loss: 2.5284095504140063

Epoch: 6| Step: 12
Training loss: 0.9949255881448029
Validation loss: 2.5109398923404425

Epoch: 6| Step: 13
Training loss: 1.517891045199772
Validation loss: 2.51965345369484

Epoch: 247| Step: 0
Training loss: 1.819180902252673
Validation loss: 2.529659345200165

Epoch: 6| Step: 1
Training loss: 1.4804136723964882
Validation loss: 2.550108343344584

Epoch: 6| Step: 2
Training loss: 1.1277470428421261
Validation loss: 2.5145837968768996

Epoch: 6| Step: 3
Training loss: 1.5784900356409597
Validation loss: 2.5392583663274007

Epoch: 6| Step: 4
Training loss: 1.3375656735705341
Validation loss: 2.5311228696030508

Epoch: 6| Step: 5
Training loss: 2.3330715804648503
Validation loss: 2.5171430060236033

Epoch: 6| Step: 6
Training loss: 1.283555956311404
Validation loss: 2.5308298936931566

Epoch: 6| Step: 7
Training loss: 1.4863172172316574
Validation loss: 2.5198206642559664

Epoch: 6| Step: 8
Training loss: 1.6658434583245876
Validation loss: 2.50972555051998

Epoch: 6| Step: 9
Training loss: 1.749516692861161
Validation loss: 2.5378903665641763

Epoch: 6| Step: 10
Training loss: 1.266368129751878
Validation loss: 2.490755514120306

Epoch: 6| Step: 11
Training loss: 1.2728571125007273
Validation loss: 2.4899019303579224

Epoch: 6| Step: 12
Training loss: 1.609022824169984
Validation loss: 2.537706285973545

Epoch: 6| Step: 13
Training loss: 1.91772167222583
Validation loss: 2.5908845694436207

Epoch: 248| Step: 0
Training loss: 1.3318697028768558
Validation loss: 2.598582098218304

Epoch: 6| Step: 1
Training loss: 1.4727413243983813
Validation loss: 2.6352310092571103

Epoch: 6| Step: 2
Training loss: 2.017977738665013
Validation loss: 2.6671464498688655

Epoch: 6| Step: 3
Training loss: 1.7817526660191114
Validation loss: 2.6441645395945765

Epoch: 6| Step: 4
Training loss: 1.6455191863711143
Validation loss: 2.6286151981281205

Epoch: 6| Step: 5
Training loss: 1.8228004055187652
Validation loss: 2.5877202667920667

Epoch: 6| Step: 6
Training loss: 1.4751804887937687
Validation loss: 2.566441909283332

Epoch: 6| Step: 7
Training loss: 1.4973392730203308
Validation loss: 2.5300125678649805

Epoch: 6| Step: 8
Training loss: 1.7129759468220414
Validation loss: 2.5154051407242224

Epoch: 6| Step: 9
Training loss: 1.6587855525975097
Validation loss: 2.50276160862421

Epoch: 6| Step: 10
Training loss: 1.296696570197887
Validation loss: 2.4756262746642155

Epoch: 6| Step: 11
Training loss: 1.5718674433926603
Validation loss: 2.4786909599550566

Epoch: 6| Step: 12
Training loss: 1.459073351249615
Validation loss: 2.4763881510311156

Epoch: 6| Step: 13
Training loss: 1.0537154062369039
Validation loss: 2.500477027502094

Epoch: 249| Step: 0
Training loss: 1.9022115861230415
Validation loss: 2.490797993469829

Epoch: 6| Step: 1
Training loss: 1.3077838270172972
Validation loss: 2.518688290655676

Epoch: 6| Step: 2
Training loss: 1.3522691588212643
Validation loss: 2.5409123948802987

Epoch: 6| Step: 3
Training loss: 1.9056318562835632
Validation loss: 2.5639949492659673

Epoch: 6| Step: 4
Training loss: 1.683057376538586
Validation loss: 2.575575115542149

Epoch: 6| Step: 5
Training loss: 1.6690475941449352
Validation loss: 2.552791113750573

Epoch: 6| Step: 6
Training loss: 1.0901552801030838
Validation loss: 2.552220704276393

Epoch: 6| Step: 7
Training loss: 1.4567700681205906
Validation loss: 2.5655937152847836

Epoch: 6| Step: 8
Training loss: 1.349710728418282
Validation loss: 2.5576286073061762

Epoch: 6| Step: 9
Training loss: 1.6285427794888423
Validation loss: 2.516529611290372

Epoch: 6| Step: 10
Training loss: 1.680795845038586
Validation loss: 2.5465345962359915

Epoch: 6| Step: 11
Training loss: 1.5907404290006826
Validation loss: 2.5145331497119905

Epoch: 6| Step: 12
Training loss: 1.0701887518633655
Validation loss: 2.5237034346061367

Epoch: 6| Step: 13
Training loss: 1.9733946976055858
Validation loss: 2.5038572928000127

Epoch: 250| Step: 0
Training loss: 1.3042463367652744
Validation loss: 2.5225093232627325

Epoch: 6| Step: 1
Training loss: 1.4082422343628636
Validation loss: 2.5318991404610927

Epoch: 6| Step: 2
Training loss: 1.2111814191710768
Validation loss: 2.5048831379594048

Epoch: 6| Step: 3
Training loss: 1.3774176064442927
Validation loss: 2.508757627729943

Epoch: 6| Step: 4
Training loss: 1.5219430489179877
Validation loss: 2.530938257293924

Epoch: 6| Step: 5
Training loss: 1.45526637965298
Validation loss: 2.526081191374162

Epoch: 6| Step: 6
Training loss: 1.1383776538164918
Validation loss: 2.5409849379929432

Epoch: 6| Step: 7
Training loss: 1.2316482461438856
Validation loss: 2.523730435085925

Epoch: 6| Step: 8
Training loss: 1.6460270184214885
Validation loss: 2.5523954738434242

Epoch: 6| Step: 9
Training loss: 1.9114354380831076
Validation loss: 2.5189883179499266

Epoch: 6| Step: 10
Training loss: 1.720953205480998
Validation loss: 2.548078636205947

Epoch: 6| Step: 11
Training loss: 2.1093783908392885
Validation loss: 2.560913038731025

Epoch: 6| Step: 12
Training loss: 2.037497669054816
Validation loss: 2.5647028656857627

Epoch: 6| Step: 13
Training loss: 0.6644087169413563
Validation loss: 2.582341223623607

Epoch: 251| Step: 0
Training loss: 1.4074564526937408
Validation loss: 2.5631841981176744

Epoch: 6| Step: 1
Training loss: 1.3555390177605604
Validation loss: 2.562207801340524

Epoch: 6| Step: 2
Training loss: 0.90713990026492
Validation loss: 2.5706668692633703

Epoch: 6| Step: 3
Training loss: 1.6932677845896023
Validation loss: 2.6187017339382375

Epoch: 6| Step: 4
Training loss: 1.5449372301652766
Validation loss: 2.5608569334236027

Epoch: 6| Step: 5
Training loss: 1.56999286795776
Validation loss: 2.5642986513030874

Epoch: 6| Step: 6
Training loss: 1.2302265231569383
Validation loss: 2.524458037997192

Epoch: 6| Step: 7
Training loss: 1.6817660224052635
Validation loss: 2.5350746844346235

Epoch: 6| Step: 8
Training loss: 1.277661391960845
Validation loss: 2.485461847023085

Epoch: 6| Step: 9
Training loss: 1.7430720115313747
Validation loss: 2.4994964307791268

Epoch: 6| Step: 10
Training loss: 1.4138916924096379
Validation loss: 2.4894659546980935

Epoch: 6| Step: 11
Training loss: 1.858950398153267
Validation loss: 2.472063806546497

Epoch: 6| Step: 12
Training loss: 1.6289645031362798
Validation loss: 2.4873393720457218

Epoch: 6| Step: 13
Training loss: 2.2278774728556363
Validation loss: 2.514353182047867

Epoch: 252| Step: 0
Training loss: 1.4135958075316024
Validation loss: 2.483199560930267

Epoch: 6| Step: 1
Training loss: 1.3950093195203992
Validation loss: 2.515176966417358

Epoch: 6| Step: 2
Training loss: 1.712307734033662
Validation loss: 2.5391559764734586

Epoch: 6| Step: 3
Training loss: 1.9165972683270578
Validation loss: 2.549881696962807

Epoch: 6| Step: 4
Training loss: 1.3476005653265801
Validation loss: 2.5911044879264815

Epoch: 6| Step: 5
Training loss: 1.5446989378446827
Validation loss: 2.5978244280170015

Epoch: 6| Step: 6
Training loss: 1.1530066700830934
Validation loss: 2.58542118656319

Epoch: 6| Step: 7
Training loss: 1.3701778297843474
Validation loss: 2.6206627693732774

Epoch: 6| Step: 8
Training loss: 1.7359298747090064
Validation loss: 2.593786050343605

Epoch: 6| Step: 9
Training loss: 1.6461176888164983
Validation loss: 2.5476795634139147

Epoch: 6| Step: 10
Training loss: 1.559467577431809
Validation loss: 2.5444107777084968

Epoch: 6| Step: 11
Training loss: 1.576205757845229
Validation loss: 2.4947238189893124

Epoch: 6| Step: 12
Training loss: 1.1102310960788477
Validation loss: 2.469528575997932

Epoch: 6| Step: 13
Training loss: 1.4218345887865695
Validation loss: 2.4484351470224173

Epoch: 253| Step: 0
Training loss: 1.8163135792052458
Validation loss: 2.453353919227209

Epoch: 6| Step: 1
Training loss: 1.9337976829799777
Validation loss: 2.476220036042454

Epoch: 6| Step: 2
Training loss: 1.0263316459563425
Validation loss: 2.517964080650137

Epoch: 6| Step: 3
Training loss: 1.3638649376844227
Validation loss: 2.502980952009772

Epoch: 6| Step: 4
Training loss: 1.570463790058338
Validation loss: 2.46795170147347

Epoch: 6| Step: 5
Training loss: 1.570852158464845
Validation loss: 2.4710716773261128

Epoch: 6| Step: 6
Training loss: 1.283566822552
Validation loss: 2.4669623173922917

Epoch: 6| Step: 7
Training loss: 1.268269542805956
Validation loss: 2.461987762910647

Epoch: 6| Step: 8
Training loss: 1.55073282084527
Validation loss: 2.4953778849155928

Epoch: 6| Step: 9
Training loss: 1.5760998715353387
Validation loss: 2.517406877368769

Epoch: 6| Step: 10
Training loss: 1.747738057567865
Validation loss: 2.5193552110723796

Epoch: 6| Step: 11
Training loss: 1.5269370549786732
Validation loss: 2.5416284259385185

Epoch: 6| Step: 12
Training loss: 1.5693017544017493
Validation loss: 2.5610588557267078

Epoch: 6| Step: 13
Training loss: 0.6435896034783216
Validation loss: 2.598340824337434

Epoch: 254| Step: 0
Training loss: 1.544092083299955
Validation loss: 2.593981906819072

Epoch: 6| Step: 1
Training loss: 1.6659261806935695
Validation loss: 2.6400984207326528

Epoch: 6| Step: 2
Training loss: 1.2842045190535296
Validation loss: 2.6482854962805855

Epoch: 6| Step: 3
Training loss: 1.2922423013231612
Validation loss: 2.5697649540134173

Epoch: 6| Step: 4
Training loss: 1.500939631209408
Validation loss: 2.551784990328873

Epoch: 6| Step: 5
Training loss: 1.302730348686619
Validation loss: 2.5012974289853807

Epoch: 6| Step: 6
Training loss: 1.7931007885154304
Validation loss: 2.489091456357574

Epoch: 6| Step: 7
Training loss: 1.6993142989030308
Validation loss: 2.486485410482447

Epoch: 6| Step: 8
Training loss: 1.2235072285353275
Validation loss: 2.461455477600481

Epoch: 6| Step: 9
Training loss: 1.3905096970665498
Validation loss: 2.4522956317203692

Epoch: 6| Step: 10
Training loss: 1.30413605691659
Validation loss: 2.4233779811163867

Epoch: 6| Step: 11
Training loss: 1.4689884398065902
Validation loss: 2.4300781095342536

Epoch: 6| Step: 12
Training loss: 2.030149308337159
Validation loss: 2.4543114457882145

Epoch: 6| Step: 13
Training loss: 1.3736107483698246
Validation loss: 2.4709084762001035

Epoch: 255| Step: 0
Training loss: 2.1255532834686264
Validation loss: 2.4837989286284694

Epoch: 6| Step: 1
Training loss: 1.5427023355838352
Validation loss: 2.4708830597072415

Epoch: 6| Step: 2
Training loss: 1.002447827853275
Validation loss: 2.486517985656613

Epoch: 6| Step: 3
Training loss: 1.6719239129727954
Validation loss: 2.476418593963396

Epoch: 6| Step: 4
Training loss: 1.0812180971940635
Validation loss: 2.4855176279685045

Epoch: 6| Step: 5
Training loss: 1.7163850639747753
Validation loss: 2.4913496126940897

Epoch: 6| Step: 6
Training loss: 1.5678701053261055
Validation loss: 2.538712710636357

Epoch: 6| Step: 7
Training loss: 1.1816917723628253
Validation loss: 2.523800303835344

Epoch: 6| Step: 8
Training loss: 1.62744360373389
Validation loss: 2.5295553779972435

Epoch: 6| Step: 9
Training loss: 1.6416242190584058
Validation loss: 2.520821575305853

Epoch: 6| Step: 10
Training loss: 1.0301151967674027
Validation loss: 2.5388019881847916

Epoch: 6| Step: 11
Training loss: 1.0656332491110734
Validation loss: 2.5735977710797497

Epoch: 6| Step: 12
Training loss: 1.4302704670026252
Validation loss: 2.598202286771097

Epoch: 6| Step: 13
Training loss: 1.4890375893781784
Validation loss: 2.5704578351462715

Epoch: 256| Step: 0
Training loss: 1.876017548700661
Validation loss: 2.6279627130962107

Epoch: 6| Step: 1
Training loss: 1.587895204506965
Validation loss: 2.598420968295203

Epoch: 6| Step: 2
Training loss: 1.2792957567981755
Validation loss: 2.5853806486505797

Epoch: 6| Step: 3
Training loss: 1.180660831519566
Validation loss: 2.552697895549286

Epoch: 6| Step: 4
Training loss: 1.6065855573755556
Validation loss: 2.521343044072073

Epoch: 6| Step: 5
Training loss: 1.4345629998962703
Validation loss: 2.5034843200546333

Epoch: 6| Step: 6
Training loss: 1.2469450813809824
Validation loss: 2.485332813881636

Epoch: 6| Step: 7
Training loss: 1.2908843604227096
Validation loss: 2.486032737901607

Epoch: 6| Step: 8
Training loss: 1.8261189988584927
Validation loss: 2.461494342434555

Epoch: 6| Step: 9
Training loss: 1.778736147581997
Validation loss: 2.4465653329952453

Epoch: 6| Step: 10
Training loss: 1.0101268129713672
Validation loss: 2.4312314417965597

Epoch: 6| Step: 11
Training loss: 1.2757152010002508
Validation loss: 2.4815357794508146

Epoch: 6| Step: 12
Training loss: 1.423006215589276
Validation loss: 2.4942445138089844

Epoch: 6| Step: 13
Training loss: 1.3489782952951348
Validation loss: 2.5008683532142966

Epoch: 257| Step: 0
Training loss: 1.5383552436604595
Validation loss: 2.5335250114756818

Epoch: 6| Step: 1
Training loss: 1.6739451346344896
Validation loss: 2.5479113661238917

Epoch: 6| Step: 2
Training loss: 0.7466792660172431
Validation loss: 2.5883683050263273

Epoch: 6| Step: 3
Training loss: 1.3666050133328322
Validation loss: 2.5883333796620334

Epoch: 6| Step: 4
Training loss: 1.2630966268653094
Validation loss: 2.567129066338567

Epoch: 6| Step: 5
Training loss: 1.4357411778580997
Validation loss: 2.566941555633116

Epoch: 6| Step: 6
Training loss: 1.979981131030253
Validation loss: 2.5616882503138605

Epoch: 6| Step: 7
Training loss: 1.420393874519953
Validation loss: 2.542514796358607

Epoch: 6| Step: 8
Training loss: 1.3992798894648164
Validation loss: 2.5199466384206395

Epoch: 6| Step: 9
Training loss: 1.2152662125294498
Validation loss: 2.523341222361598

Epoch: 6| Step: 10
Training loss: 1.550555234336721
Validation loss: 2.540727737126079

Epoch: 6| Step: 11
Training loss: 1.394875491953993
Validation loss: 2.5451699443086557

Epoch: 6| Step: 12
Training loss: 1.2216937386781879
Validation loss: 2.5617207898884327

Epoch: 6| Step: 13
Training loss: 1.5412657018698548
Validation loss: 2.560810049086026

Epoch: 258| Step: 0
Training loss: 1.3651558303614055
Validation loss: 2.5612445209824743

Epoch: 6| Step: 1
Training loss: 1.1532737987418695
Validation loss: 2.5926604470158

Epoch: 6| Step: 2
Training loss: 0.9337054070136291
Validation loss: 2.5885060615902686

Epoch: 6| Step: 3
Training loss: 1.3794181241068648
Validation loss: 2.5797564185246853

Epoch: 6| Step: 4
Training loss: 1.6728998768471837
Validation loss: 2.5554252683888556

Epoch: 6| Step: 5
Training loss: 1.505639996610312
Validation loss: 2.509456805546436

Epoch: 6| Step: 6
Training loss: 1.099629647591489
Validation loss: 2.495553587884908

Epoch: 6| Step: 7
Training loss: 1.6676361681517953
Validation loss: 2.5033641535074245

Epoch: 6| Step: 8
Training loss: 1.5584805478548625
Validation loss: 2.492133286913512

Epoch: 6| Step: 9
Training loss: 1.040285294447191
Validation loss: 2.5009709257115738

Epoch: 6| Step: 10
Training loss: 1.6050804392541953
Validation loss: 2.52621940864492

Epoch: 6| Step: 11
Training loss: 1.8205208720514443
Validation loss: 2.518645518812856

Epoch: 6| Step: 12
Training loss: 1.6898531577967866
Validation loss: 2.5603579860932273

Epoch: 6| Step: 13
Training loss: 1.1105772139745453
Validation loss: 2.5408891557458424

Epoch: 259| Step: 0
Training loss: 1.5421219059097655
Validation loss: 2.5428714525972045

Epoch: 6| Step: 1
Training loss: 1.1903369545120825
Validation loss: 2.5640913941224466

Epoch: 6| Step: 2
Training loss: 1.486069605397261
Validation loss: 2.5742155442256873

Epoch: 6| Step: 3
Training loss: 1.5282524508196542
Validation loss: 2.5833974324853815

Epoch: 6| Step: 4
Training loss: 1.5860023673185404
Validation loss: 2.609154934439762

Epoch: 6| Step: 5
Training loss: 1.226164735090912
Validation loss: 2.581045299254383

Epoch: 6| Step: 6
Training loss: 1.052951769065666
Validation loss: 2.5329852853855805

Epoch: 6| Step: 7
Training loss: 1.227739826011876
Validation loss: 2.521489477906628

Epoch: 6| Step: 8
Training loss: 2.260726368397678
Validation loss: 2.484426013796586

Epoch: 6| Step: 9
Training loss: 1.2046214618716007
Validation loss: 2.4926727179521646

Epoch: 6| Step: 10
Training loss: 1.5092061771730478
Validation loss: 2.5124884942116332

Epoch: 6| Step: 11
Training loss: 1.0793440188239658
Validation loss: 2.5216907808081426

Epoch: 6| Step: 12
Training loss: 1.295137827545813
Validation loss: 2.5434163471200466

Epoch: 6| Step: 13
Training loss: 1.2671016979214282
Validation loss: 2.5334576330821363

Epoch: 260| Step: 0
Training loss: 1.6924621246472484
Validation loss: 2.554088406754917

Epoch: 6| Step: 1
Training loss: 1.140137555205796
Validation loss: 2.5344483498471777

Epoch: 6| Step: 2
Training loss: 1.1167087195909238
Validation loss: 2.5924093075546097

Epoch: 6| Step: 3
Training loss: 1.3179846563097324
Validation loss: 2.568091099761144

Epoch: 6| Step: 4
Training loss: 1.5116678076546655
Validation loss: 2.585722026987699

Epoch: 6| Step: 5
Training loss: 1.6964290475486146
Validation loss: 2.572521298076576

Epoch: 6| Step: 6
Training loss: 1.4112443186913364
Validation loss: 2.566735595552121

Epoch: 6| Step: 7
Training loss: 1.1758120206437421
Validation loss: 2.556605751540966

Epoch: 6| Step: 8
Training loss: 0.9771173045604558
Validation loss: 2.569102409661683

Epoch: 6| Step: 9
Training loss: 1.72041240405516
Validation loss: 2.5193486100347346

Epoch: 6| Step: 10
Training loss: 1.0959596384649788
Validation loss: 2.508669145965055

Epoch: 6| Step: 11
Training loss: 1.267595052973446
Validation loss: 2.5251581844042006

Epoch: 6| Step: 12
Training loss: 1.2362655455071854
Validation loss: 2.4826145715830323

Epoch: 6| Step: 13
Training loss: 2.083550276587037
Validation loss: 2.543048507886076

Epoch: 261| Step: 0
Training loss: 1.2753065002644264
Validation loss: 2.50627484245223

Epoch: 6| Step: 1
Training loss: 1.3011382475109023
Validation loss: 2.4718987813025253

Epoch: 6| Step: 2
Training loss: 1.5873778619113366
Validation loss: 2.490637293339953

Epoch: 6| Step: 3
Training loss: 1.5110136847239253
Validation loss: 2.483868757416608

Epoch: 6| Step: 4
Training loss: 1.6652895562811758
Validation loss: 2.460058717072764

Epoch: 6| Step: 5
Training loss: 1.4221871002069295
Validation loss: 2.479869566748033

Epoch: 6| Step: 6
Training loss: 1.1251544316577349
Validation loss: 2.4663861490681653

Epoch: 6| Step: 7
Training loss: 1.5637020827650638
Validation loss: 2.4870562797814695

Epoch: 6| Step: 8
Training loss: 0.9848592263527396
Validation loss: 2.502550776298833

Epoch: 6| Step: 9
Training loss: 1.214389188549105
Validation loss: 2.499429167417129

Epoch: 6| Step: 10
Training loss: 0.7057049361194828
Validation loss: 2.564506735448801

Epoch: 6| Step: 11
Training loss: 1.7586452291877335
Validation loss: 2.5698311215908336

Epoch: 6| Step: 12
Training loss: 1.4555944154047833
Validation loss: 2.5766063763088405

Epoch: 6| Step: 13
Training loss: 1.62720193597534
Validation loss: 2.5768679828727383

Epoch: 262| Step: 0
Training loss: 1.3172401028556513
Validation loss: 2.577542397457813

Epoch: 6| Step: 1
Training loss: 1.1635350818271257
Validation loss: 2.5276965548533865

Epoch: 6| Step: 2
Training loss: 1.2342628717800204
Validation loss: 2.5212249397444007

Epoch: 6| Step: 3
Training loss: 1.1767749326101629
Validation loss: 2.5320833637871396

Epoch: 6| Step: 4
Training loss: 1.3951756460435325
Validation loss: 2.533294796758502

Epoch: 6| Step: 5
Training loss: 1.3094889297629173
Validation loss: 2.5233212554113087

Epoch: 6| Step: 6
Training loss: 0.9068198221300039
Validation loss: 2.5342568166961343

Epoch: 6| Step: 7
Training loss: 1.2479697906615892
Validation loss: 2.525271586153864

Epoch: 6| Step: 8
Training loss: 1.7541203357561397
Validation loss: 2.5248605026622735

Epoch: 6| Step: 9
Training loss: 1.2847764865767548
Validation loss: 2.5595152404699495

Epoch: 6| Step: 10
Training loss: 1.3498240850768985
Validation loss: 2.550018859438049

Epoch: 6| Step: 11
Training loss: 1.4453398006025893
Validation loss: 2.5875506216135227

Epoch: 6| Step: 12
Training loss: 1.7065442959803494
Validation loss: 2.6062119306151246

Epoch: 6| Step: 13
Training loss: 1.8741165623031886
Validation loss: 2.568897252535041

Epoch: 263| Step: 0
Training loss: 1.3129273581707603
Validation loss: 2.5802538959702166

Epoch: 6| Step: 1
Training loss: 2.179258023955205
Validation loss: 2.5226868158272584

Epoch: 6| Step: 2
Training loss: 1.6789621605667562
Validation loss: 2.530556470709622

Epoch: 6| Step: 3
Training loss: 1.3613547455252295
Validation loss: 2.5169714379944406

Epoch: 6| Step: 4
Training loss: 0.8195350232323841
Validation loss: 2.509270374453073

Epoch: 6| Step: 5
Training loss: 1.0981373665840086
Validation loss: 2.5239702878412644

Epoch: 6| Step: 6
Training loss: 1.2239589393560113
Validation loss: 2.5435040409273078

Epoch: 6| Step: 7
Training loss: 1.2596466718003545
Validation loss: 2.5897704293658155

Epoch: 6| Step: 8
Training loss: 1.4285651632580287
Validation loss: 2.6246650822009268

Epoch: 6| Step: 9
Training loss: 0.6031487840696657
Validation loss: 2.60882459689539

Epoch: 6| Step: 10
Training loss: 1.0365776236175204
Validation loss: 2.627003613619727

Epoch: 6| Step: 11
Training loss: 1.340780125604062
Validation loss: 2.6327698591753346

Epoch: 6| Step: 12
Training loss: 1.7521173746776262
Validation loss: 2.5656193141547754

Epoch: 6| Step: 13
Training loss: 1.233658594766957
Validation loss: 2.5509738548832726

Epoch: 264| Step: 0
Training loss: 1.3712784949708987
Validation loss: 2.5224711942331406

Epoch: 6| Step: 1
Training loss: 1.329079587868259
Validation loss: 2.512268815056719

Epoch: 6| Step: 2
Training loss: 0.988378286309675
Validation loss: 2.4873927347157325

Epoch: 6| Step: 3
Training loss: 1.4047230801940018
Validation loss: 2.5213244786940656

Epoch: 6| Step: 4
Training loss: 1.3819067623468475
Validation loss: 2.475763061138936

Epoch: 6| Step: 5
Training loss: 1.1348068045992006
Validation loss: 2.5223168164357523

Epoch: 6| Step: 6
Training loss: 1.7134935629294923
Validation loss: 2.5612433789147833

Epoch: 6| Step: 7
Training loss: 1.1680149847467265
Validation loss: 2.559670986364377

Epoch: 6| Step: 8
Training loss: 0.8237854600605387
Validation loss: 2.614558874575639

Epoch: 6| Step: 9
Training loss: 1.5373556674108035
Validation loss: 2.620815923252034

Epoch: 6| Step: 10
Training loss: 1.8444769767716203
Validation loss: 2.6260440369444766

Epoch: 6| Step: 11
Training loss: 1.5338974467865512
Validation loss: 2.599489273254572

Epoch: 6| Step: 12
Training loss: 1.3508213193917313
Validation loss: 2.64166669303739

Epoch: 6| Step: 13
Training loss: 0.6971350368593245
Validation loss: 2.574047869393863

Epoch: 265| Step: 0
Training loss: 1.2333876125316736
Validation loss: 2.5477472650261266

Epoch: 6| Step: 1
Training loss: 1.4675846752582062
Validation loss: 2.5279161675747766

Epoch: 6| Step: 2
Training loss: 1.0218096884291497
Validation loss: 2.5304421842787552

Epoch: 6| Step: 3
Training loss: 1.7131861711204464
Validation loss: 2.50146726189598

Epoch: 6| Step: 4
Training loss: 0.7766936761296338
Validation loss: 2.5224746365102724

Epoch: 6| Step: 5
Training loss: 1.4144443396859347
Validation loss: 2.5279245949975064

Epoch: 6| Step: 6
Training loss: 0.9071848421389666
Validation loss: 2.4958750000362215

Epoch: 6| Step: 7
Training loss: 1.1619265628923936
Validation loss: 2.5189282398328645

Epoch: 6| Step: 8
Training loss: 1.5926253146416844
Validation loss: 2.540105181355533

Epoch: 6| Step: 9
Training loss: 1.6514147588644374
Validation loss: 2.5360026394402766

Epoch: 6| Step: 10
Training loss: 1.19289922505396
Validation loss: 2.5440876510731645

Epoch: 6| Step: 11
Training loss: 1.207595002206428
Validation loss: 2.529076337082277

Epoch: 6| Step: 12
Training loss: 1.773281544285265
Validation loss: 2.549611744929952

Epoch: 6| Step: 13
Training loss: 1.369946774402473
Validation loss: 2.524024835341145

Epoch: 266| Step: 0
Training loss: 1.1978119790593345
Validation loss: 2.5255944388398475

Epoch: 6| Step: 1
Training loss: 1.193964678249874
Validation loss: 2.503186428669302

Epoch: 6| Step: 2
Training loss: 1.455293247782809
Validation loss: 2.54828767133411

Epoch: 6| Step: 3
Training loss: 1.2454632446488987
Validation loss: 2.5182875861576104

Epoch: 6| Step: 4
Training loss: 2.0752621772316013
Validation loss: 2.5557512171937304

Epoch: 6| Step: 5
Training loss: 0.9931351949121681
Validation loss: 2.5387129590518485

Epoch: 6| Step: 6
Training loss: 1.1875848739810686
Validation loss: 2.513415817307953

Epoch: 6| Step: 7
Training loss: 0.8327268459796758
Validation loss: 2.5028866796472347

Epoch: 6| Step: 8
Training loss: 1.4985696807891657
Validation loss: 2.581297941606132

Epoch: 6| Step: 9
Training loss: 1.6094791415694758
Validation loss: 2.544892441921532

Epoch: 6| Step: 10
Training loss: 1.1315472607454256
Validation loss: 2.582475005257017

Epoch: 6| Step: 11
Training loss: 1.248887807060111
Validation loss: 2.5845839519506306

Epoch: 6| Step: 12
Training loss: 1.4669806191347976
Validation loss: 2.572780760148685

Epoch: 6| Step: 13
Training loss: 0.9826202495650833
Validation loss: 2.5616191897894227

Epoch: 267| Step: 0
Training loss: 1.3151214850264263
Validation loss: 2.5235998528849084

Epoch: 6| Step: 1
Training loss: 1.7355751490345115
Validation loss: 2.4953280848932726

Epoch: 6| Step: 2
Training loss: 1.44300170926887
Validation loss: 2.4981136121805907

Epoch: 6| Step: 3
Training loss: 1.3922672647045171
Validation loss: 2.433000455021931

Epoch: 6| Step: 4
Training loss: 1.419867639148599
Validation loss: 2.4885236386666287

Epoch: 6| Step: 5
Training loss: 1.3920523358459813
Validation loss: 2.4942100604468687

Epoch: 6| Step: 6
Training loss: 1.3795222994615233
Validation loss: 2.4747197228341467

Epoch: 6| Step: 7
Training loss: 1.3734345628101592
Validation loss: 2.5220863328657366

Epoch: 6| Step: 8
Training loss: 1.2265671650986125
Validation loss: 2.5514421810753976

Epoch: 6| Step: 9
Training loss: 1.0672789415808062
Validation loss: 2.643539611893914

Epoch: 6| Step: 10
Training loss: 1.2920757333006496
Validation loss: 2.6562038082230006

Epoch: 6| Step: 11
Training loss: 1.2375667207244339
Validation loss: 2.6543691269851837

Epoch: 6| Step: 12
Training loss: 1.0305518474723503
Validation loss: 2.6613124488514854

Epoch: 6| Step: 13
Training loss: 1.2259677975985324
Validation loss: 2.6477712614264175

Epoch: 268| Step: 0
Training loss: 1.1766653190763572
Validation loss: 2.611866579899018

Epoch: 6| Step: 1
Training loss: 1.1224566957238615
Validation loss: 2.5682229245248953

Epoch: 6| Step: 2
Training loss: 1.1853809523384236
Validation loss: 2.5762343468723197

Epoch: 6| Step: 3
Training loss: 1.3574327207722063
Validation loss: 2.5423459110862416

Epoch: 6| Step: 4
Training loss: 1.4549725999906777
Validation loss: 2.5044685236573967

Epoch: 6| Step: 5
Training loss: 1.2628846819401802
Validation loss: 2.505555395663198

Epoch: 6| Step: 6
Training loss: 1.8027501792669571
Validation loss: 2.4867414442800815

Epoch: 6| Step: 7
Training loss: 1.1267783626137795
Validation loss: 2.4933245925767658

Epoch: 6| Step: 8
Training loss: 1.3985695377010319
Validation loss: 2.49332924210061

Epoch: 6| Step: 9
Training loss: 1.159556738086655
Validation loss: 2.5212463468375628

Epoch: 6| Step: 10
Training loss: 1.0884815850476544
Validation loss: 2.510249514285438

Epoch: 6| Step: 11
Training loss: 1.0694333106172862
Validation loss: 2.5680350664223144

Epoch: 6| Step: 12
Training loss: 1.5982720790073717
Validation loss: 2.5955466077248066

Epoch: 6| Step: 13
Training loss: 1.3530043039387367
Validation loss: 2.624080959996469

Epoch: 269| Step: 0
Training loss: 0.9040500641859872
Validation loss: 2.6205646411264505

Epoch: 6| Step: 1
Training loss: 1.7747395982600038
Validation loss: 2.59831501850274

Epoch: 6| Step: 2
Training loss: 0.9564586872944101
Validation loss: 2.6296123799706006

Epoch: 6| Step: 3
Training loss: 1.596533271072507
Validation loss: 2.5618544815207622

Epoch: 6| Step: 4
Training loss: 1.0445865271242667
Validation loss: 2.556998274613261

Epoch: 6| Step: 5
Training loss: 1.7383068982921706
Validation loss: 2.5331258604921016

Epoch: 6| Step: 6
Training loss: 1.606362495490649
Validation loss: 2.510825801435768

Epoch: 6| Step: 7
Training loss: 1.0319799671816234
Validation loss: 2.4481643045316575

Epoch: 6| Step: 8
Training loss: 1.1857198120881343
Validation loss: 2.4746004179188246

Epoch: 6| Step: 9
Training loss: 0.9441158507651405
Validation loss: 2.483574479590019

Epoch: 6| Step: 10
Training loss: 1.363959813048958
Validation loss: 2.4707368576598534

Epoch: 6| Step: 11
Training loss: 0.9476040894194283
Validation loss: 2.474806037230873

Epoch: 6| Step: 12
Training loss: 0.9448832017886009
Validation loss: 2.4672514330271036

Epoch: 6| Step: 13
Training loss: 1.6588867359966444
Validation loss: 2.478775713992945

Epoch: 270| Step: 0
Training loss: 1.1532438222147832
Validation loss: 2.5397744123989874

Epoch: 6| Step: 1
Training loss: 1.4736276352211903
Validation loss: 2.588668255299987

Epoch: 6| Step: 2
Training loss: 1.4184734192523625
Validation loss: 2.597173294593008

Epoch: 6| Step: 3
Training loss: 0.9797338033682115
Validation loss: 2.591095906839863

Epoch: 6| Step: 4
Training loss: 1.3434290391718129
Validation loss: 2.592970425392915

Epoch: 6| Step: 5
Training loss: 1.7598245591806756
Validation loss: 2.5740707563807743

Epoch: 6| Step: 6
Training loss: 1.4784751493489607
Validation loss: 2.4878974843084856

Epoch: 6| Step: 7
Training loss: 0.8188197768668147
Validation loss: 2.5038922446280623

Epoch: 6| Step: 8
Training loss: 1.1269287952990075
Validation loss: 2.518787630105885

Epoch: 6| Step: 9
Training loss: 1.2813762509551365
Validation loss: 2.519068010764181

Epoch: 6| Step: 10
Training loss: 1.0789441852681774
Validation loss: 2.5081495344088003

Epoch: 6| Step: 11
Training loss: 1.3891681369223745
Validation loss: 2.542422384164607

Epoch: 6| Step: 12
Training loss: 1.262198247823646
Validation loss: 2.5045250947669464

Epoch: 6| Step: 13
Training loss: 1.2307602794372139
Validation loss: 2.542035859916062

Epoch: 271| Step: 0
Training loss: 1.0069742191048858
Validation loss: 2.56857634844823

Epoch: 6| Step: 1
Training loss: 1.0104079426392099
Validation loss: 2.6099908033447905

Epoch: 6| Step: 2
Training loss: 1.623269994206317
Validation loss: 2.6159732642372866

Epoch: 6| Step: 3
Training loss: 1.651896603371219
Validation loss: 2.569390381969785

Epoch: 6| Step: 4
Training loss: 1.2465488475741444
Validation loss: 2.546024460570859

Epoch: 6| Step: 5
Training loss: 1.796102141982522
Validation loss: 2.511242406268636

Epoch: 6| Step: 6
Training loss: 0.9605602981727807
Validation loss: 2.4497460735761383

Epoch: 6| Step: 7
Training loss: 1.472775320404956
Validation loss: 2.433559601507508

Epoch: 6| Step: 8
Training loss: 0.9524690841303249
Validation loss: 2.414179424402957

Epoch: 6| Step: 9
Training loss: 1.097165469755443
Validation loss: 2.435619561807163

Epoch: 6| Step: 10
Training loss: 1.1356058342281588
Validation loss: 2.4310653014484833

Epoch: 6| Step: 11
Training loss: 1.0777486614235794
Validation loss: 2.459629266483736

Epoch: 6| Step: 12
Training loss: 1.4308034575062505
Validation loss: 2.481032890264134

Epoch: 6| Step: 13
Training loss: 0.9422967268606697
Validation loss: 2.518505991638594

Epoch: 272| Step: 0
Training loss: 0.9221892063870958
Validation loss: 2.520656357440094

Epoch: 6| Step: 1
Training loss: 1.361481623704551
Validation loss: 2.5521654535625347

Epoch: 6| Step: 2
Training loss: 1.6217239074301588
Validation loss: 2.5637316221357245

Epoch: 6| Step: 3
Training loss: 1.5144654390327896
Validation loss: 2.569362446471461

Epoch: 6| Step: 4
Training loss: 0.9447536866034607
Validation loss: 2.5655391387823263

Epoch: 6| Step: 5
Training loss: 1.2101641739055762
Validation loss: 2.5747592189416637

Epoch: 6| Step: 6
Training loss: 0.791996703035062
Validation loss: 2.577967143019266

Epoch: 6| Step: 7
Training loss: 1.098864016470521
Validation loss: 2.5046023940626596

Epoch: 6| Step: 8
Training loss: 1.3401240731204
Validation loss: 2.5243176525062876

Epoch: 6| Step: 9
Training loss: 0.8938223015944193
Validation loss: 2.50537045574865

Epoch: 6| Step: 10
Training loss: 1.2390364020005558
Validation loss: 2.4454745002098255

Epoch: 6| Step: 11
Training loss: 1.3051880201914003
Validation loss: 2.4527361098930283

Epoch: 6| Step: 12
Training loss: 1.8438835742216546
Validation loss: 2.400686417712785

Epoch: 6| Step: 13
Training loss: 1.0255944040443354
Validation loss: 2.4399733708890543

Epoch: 273| Step: 0
Training loss: 1.342951914630174
Validation loss: 2.4532614255191736

Epoch: 6| Step: 1
Training loss: 0.7960442345131938
Validation loss: 2.4472832856336

Epoch: 6| Step: 2
Training loss: 1.772053047936124
Validation loss: 2.4687864717048336

Epoch: 6| Step: 3
Training loss: 1.5070583058287288
Validation loss: 2.5088912396426752

Epoch: 6| Step: 4
Training loss: 0.8657382849645057
Validation loss: 2.5414127136912703

Epoch: 6| Step: 5
Training loss: 1.104099679510379
Validation loss: 2.56253770649938

Epoch: 6| Step: 6
Training loss: 1.5170687062264587
Validation loss: 2.587377045606987

Epoch: 6| Step: 7
Training loss: 0.8504010250242378
Validation loss: 2.5901679933854203

Epoch: 6| Step: 8
Training loss: 1.2222433642283137
Validation loss: 2.603044235673858

Epoch: 6| Step: 9
Training loss: 1.1293844510365383
Validation loss: 2.5632968967056944

Epoch: 6| Step: 10
Training loss: 1.1835087912506566
Validation loss: 2.562062670117772

Epoch: 6| Step: 11
Training loss: 1.5005786892101316
Validation loss: 2.5548209465692095

Epoch: 6| Step: 12
Training loss: 1.2687456253051503
Validation loss: 2.5581159268087053

Epoch: 6| Step: 13
Training loss: 1.0705817781844214
Validation loss: 2.569183268119543

Epoch: 274| Step: 0
Training loss: 0.9231121038570472
Validation loss: 2.5411825971491337

Epoch: 6| Step: 1
Training loss: 0.886627226151915
Validation loss: 2.517571955134807

Epoch: 6| Step: 2
Training loss: 1.2704005624950039
Validation loss: 2.501705222878143

Epoch: 6| Step: 3
Training loss: 1.0275517242295407
Validation loss: 2.482455646699582

Epoch: 6| Step: 4
Training loss: 1.6851353502104964
Validation loss: 2.4903641578655673

Epoch: 6| Step: 5
Training loss: 1.6943558485636627
Validation loss: 2.5251999022860563

Epoch: 6| Step: 6
Training loss: 1.0374279502761434
Validation loss: 2.541709406987769

Epoch: 6| Step: 7
Training loss: 1.0338993719228735
Validation loss: 2.5628593156890607

Epoch: 6| Step: 8
Training loss: 1.500134859380561
Validation loss: 2.5756519497057644

Epoch: 6| Step: 9
Training loss: 1.329461715301954
Validation loss: 2.5612580425848224

Epoch: 6| Step: 10
Training loss: 1.2178875732775167
Validation loss: 2.5177983820320016

Epoch: 6| Step: 11
Training loss: 1.3302165896229936
Validation loss: 2.4890442893340534

Epoch: 6| Step: 12
Training loss: 1.2056485747172654
Validation loss: 2.459629354557021

Epoch: 6| Step: 13
Training loss: 0.7521536027269857
Validation loss: 2.4618125285710706

Epoch: 275| Step: 0
Training loss: 1.1690637055293691
Validation loss: 2.4549308584734097

Epoch: 6| Step: 1
Training loss: 1.3479965443750794
Validation loss: 2.464016032007232

Epoch: 6| Step: 2
Training loss: 0.9933975830410454
Validation loss: 2.459985144368811

Epoch: 6| Step: 3
Training loss: 1.9089019339198003
Validation loss: 2.479601036011879

Epoch: 6| Step: 4
Training loss: 1.0239214153496872
Validation loss: 2.4827567038555487

Epoch: 6| Step: 5
Training loss: 1.1198232010533768
Validation loss: 2.506440562359027

Epoch: 6| Step: 6
Training loss: 0.48511700555927145
Validation loss: 2.565657618304567

Epoch: 6| Step: 7
Training loss: 0.9598911139706311
Validation loss: 2.567369336136189

Epoch: 6| Step: 8
Training loss: 1.1884508843261326
Validation loss: 2.546326086463155

Epoch: 6| Step: 9
Training loss: 1.467666307348074
Validation loss: 2.577007784739849

Epoch: 6| Step: 10
Training loss: 1.048033571389893
Validation loss: 2.5545517232241677

Epoch: 6| Step: 11
Training loss: 1.2637666315933187
Validation loss: 2.550343556135528

Epoch: 6| Step: 12
Training loss: 1.5964768960477498
Validation loss: 2.511906002623209

Epoch: 6| Step: 13
Training loss: 1.1784398131346578
Validation loss: 2.510999463247046

Epoch: 276| Step: 0
Training loss: 1.2557725179249277
Validation loss: 2.46508825084784

Epoch: 6| Step: 1
Training loss: 1.0012143034173517
Validation loss: 2.478663305436278

Epoch: 6| Step: 2
Training loss: 0.8695337670796199
Validation loss: 2.470586571016834

Epoch: 6| Step: 3
Training loss: 1.2477835077346882
Validation loss: 2.4586214849479715

Epoch: 6| Step: 4
Training loss: 1.226924964171118
Validation loss: 2.451264300089139

Epoch: 6| Step: 5
Training loss: 0.9200351264716203
Validation loss: 2.4924798341963195

Epoch: 6| Step: 6
Training loss: 1.2934193819873354
Validation loss: 2.50169840310916

Epoch: 6| Step: 7
Training loss: 1.7309711493385813
Validation loss: 2.547720164874651

Epoch: 6| Step: 8
Training loss: 0.9597580968043777
Validation loss: 2.535457081360186

Epoch: 6| Step: 9
Training loss: 1.246258285326568
Validation loss: 2.54005738208967

Epoch: 6| Step: 10
Training loss: 1.5116312952890791
Validation loss: 2.5594046511249626

Epoch: 6| Step: 11
Training loss: 1.1550061004444538
Validation loss: 2.537528270954127

Epoch: 6| Step: 12
Training loss: 1.139228069898807
Validation loss: 2.485731315357449

Epoch: 6| Step: 13
Training loss: 1.4249678290232453
Validation loss: 2.492434867632995

Epoch: 277| Step: 0
Training loss: 0.9199796362882986
Validation loss: 2.4726111852419534

Epoch: 6| Step: 1
Training loss: 1.3329609509849063
Validation loss: 2.4338148418883283

Epoch: 6| Step: 2
Training loss: 1.4897921044650382
Validation loss: 2.4450243624477017

Epoch: 6| Step: 3
Training loss: 0.9832764808470023
Validation loss: 2.4577132326408777

Epoch: 6| Step: 4
Training loss: 0.8430695085524773
Validation loss: 2.461784019530099

Epoch: 6| Step: 5
Training loss: 1.3632530930898679
Validation loss: 2.478674145738261

Epoch: 6| Step: 6
Training loss: 1.5877788358894978
Validation loss: 2.5185091868912073

Epoch: 6| Step: 7
Training loss: 0.7598860382919935
Validation loss: 2.5597212597168197

Epoch: 6| Step: 8
Training loss: 1.1405085151451484
Validation loss: 2.595415873454056

Epoch: 6| Step: 9
Training loss: 1.1479980769888958
Validation loss: 2.6229949135555892

Epoch: 6| Step: 10
Training loss: 1.5873877748485552
Validation loss: 2.6275478739017544

Epoch: 6| Step: 11
Training loss: 1.423646180049182
Validation loss: 2.576637892719292

Epoch: 6| Step: 12
Training loss: 1.204120867869113
Validation loss: 2.5744471523897072

Epoch: 6| Step: 13
Training loss: 0.3915096374838223
Validation loss: 2.569119260705561

Epoch: 278| Step: 0
Training loss: 1.3731409423208245
Validation loss: 2.517969450316209

Epoch: 6| Step: 1
Training loss: 1.3669778281606473
Validation loss: 2.5520486108972253

Epoch: 6| Step: 2
Training loss: 1.234951995040176
Validation loss: 2.5523247476341444

Epoch: 6| Step: 3
Training loss: 1.176499258421321
Validation loss: 2.52180438016192

Epoch: 6| Step: 4
Training loss: 1.0080917917683876
Validation loss: 2.5426763112441133

Epoch: 6| Step: 5
Training loss: 1.1156776736350664
Validation loss: 2.524969172200694

Epoch: 6| Step: 6
Training loss: 0.9816200821924691
Validation loss: 2.53682603908346

Epoch: 6| Step: 7
Training loss: 0.9043196475496401
Validation loss: 2.5461950017801875

Epoch: 6| Step: 8
Training loss: 1.056714236926547
Validation loss: 2.507786591154853

Epoch: 6| Step: 9
Training loss: 0.6624039076446828
Validation loss: 2.5213793366069126

Epoch: 6| Step: 10
Training loss: 1.3494032441540806
Validation loss: 2.5225995380913226

Epoch: 6| Step: 11
Training loss: 1.5942599658747294
Validation loss: 2.5135952931746863

Epoch: 6| Step: 12
Training loss: 1.5295253305323557
Validation loss: 2.4827422177726626

Epoch: 6| Step: 13
Training loss: 1.2708179702247073
Validation loss: 2.4838236494102506

Epoch: 279| Step: 0
Training loss: 1.3351710837105462
Validation loss: 2.475788555933686

Epoch: 6| Step: 1
Training loss: 1.214423005573204
Validation loss: 2.4728486594493777

Epoch: 6| Step: 2
Training loss: 1.2259781532830307
Validation loss: 2.4678233931001476

Epoch: 6| Step: 3
Training loss: 0.5989864232207516
Validation loss: 2.482756927925024

Epoch: 6| Step: 4
Training loss: 1.0436567116352642
Validation loss: 2.50719408423535

Epoch: 6| Step: 5
Training loss: 1.1260930685097115
Validation loss: 2.5022433209038666

Epoch: 6| Step: 6
Training loss: 0.9682914202237425
Validation loss: 2.5163903605519753

Epoch: 6| Step: 7
Training loss: 0.892834582724975
Validation loss: 2.5391440000619196

Epoch: 6| Step: 8
Training loss: 1.4525013887855076
Validation loss: 2.5146034779100144

Epoch: 6| Step: 9
Training loss: 1.2569572431686666
Validation loss: 2.5337587232842407

Epoch: 6| Step: 10
Training loss: 1.0192409993780824
Validation loss: 2.5438066922942424

Epoch: 6| Step: 11
Training loss: 1.3676532932817402
Validation loss: 2.519166217347585

Epoch: 6| Step: 12
Training loss: 1.339821773604618
Validation loss: 2.522908658130211

Epoch: 6| Step: 13
Training loss: 1.862364089410521
Validation loss: 2.5195195649227347

Epoch: 280| Step: 0
Training loss: 1.1618547433089734
Validation loss: 2.5522006337923377

Epoch: 6| Step: 1
Training loss: 1.3451186019338341
Validation loss: 2.5479070435993094

Epoch: 6| Step: 2
Training loss: 1.1234836425643047
Validation loss: 2.5706940556089255

Epoch: 6| Step: 3
Training loss: 0.8632789024907986
Validation loss: 2.524728514685516

Epoch: 6| Step: 4
Training loss: 0.8638528510880642
Validation loss: 2.5499811859852337

Epoch: 6| Step: 5
Training loss: 1.1617528544834794
Validation loss: 2.562451422926469

Epoch: 6| Step: 6
Training loss: 1.2483056506069903
Validation loss: 2.540963021213798

Epoch: 6| Step: 7
Training loss: 1.0020753068397619
Validation loss: 2.5304079973392097

Epoch: 6| Step: 8
Training loss: 1.2255169731281452
Validation loss: 2.514452632102941

Epoch: 6| Step: 9
Training loss: 1.856687767735305
Validation loss: 2.5165256902316053

Epoch: 6| Step: 10
Training loss: 0.9539614899657997
Validation loss: 2.506802823553131

Epoch: 6| Step: 11
Training loss: 1.0546323408608558
Validation loss: 2.518259943994498

Epoch: 6| Step: 12
Training loss: 1.1632008788024175
Validation loss: 2.5057949961732406

Epoch: 6| Step: 13
Training loss: 1.5980665057908392
Validation loss: 2.503974218813668

Epoch: 281| Step: 0
Training loss: 1.30548811235571
Validation loss: 2.4721675046920124

Epoch: 6| Step: 1
Training loss: 1.0343760879372583
Validation loss: 2.5042351525306454

Epoch: 6| Step: 2
Training loss: 1.555804823968551
Validation loss: 2.503307843678727

Epoch: 6| Step: 3
Training loss: 1.3578139363271406
Validation loss: 2.5113210616997055

Epoch: 6| Step: 4
Training loss: 1.2287267069971157
Validation loss: 2.4858396627572668

Epoch: 6| Step: 5
Training loss: 0.7851272501737881
Validation loss: 2.5004919326966095

Epoch: 6| Step: 6
Training loss: 0.8567838271681412
Validation loss: 2.491035463896512

Epoch: 6| Step: 7
Training loss: 1.2617189389633179
Validation loss: 2.4765518885430082

Epoch: 6| Step: 8
Training loss: 0.8683204467119846
Validation loss: 2.487535294778979

Epoch: 6| Step: 9
Training loss: 1.0571096229115953
Validation loss: 2.473601545546088

Epoch: 6| Step: 10
Training loss: 1.201500377859754
Validation loss: 2.4961892340383227

Epoch: 6| Step: 11
Training loss: 1.1280098494410837
Validation loss: 2.4935718402110623

Epoch: 6| Step: 12
Training loss: 1.3367002663150995
Validation loss: 2.4878505311400314

Epoch: 6| Step: 13
Training loss: 1.4176584960489171
Validation loss: 2.5284908382311406

Epoch: 282| Step: 0
Training loss: 1.2039181955624914
Validation loss: 2.494376648197641

Epoch: 6| Step: 1
Training loss: 1.0518368662077349
Validation loss: 2.5379244759460295

Epoch: 6| Step: 2
Training loss: 1.6032326526449865
Validation loss: 2.513780325551358

Epoch: 6| Step: 3
Training loss: 1.0983060494962165
Validation loss: 2.499517894733453

Epoch: 6| Step: 4
Training loss: 1.3721190094366575
Validation loss: 2.4838610536909904

Epoch: 6| Step: 5
Training loss: 1.032885497221637
Validation loss: 2.4825080754699442

Epoch: 6| Step: 6
Training loss: 1.318743433642198
Validation loss: 2.4441770525114146

Epoch: 6| Step: 7
Training loss: 1.0014981729735508
Validation loss: 2.4818657903583827

Epoch: 6| Step: 8
Training loss: 0.755775861044633
Validation loss: 2.489287796290178

Epoch: 6| Step: 9
Training loss: 1.3947182751644278
Validation loss: 2.484506606794513

Epoch: 6| Step: 10
Training loss: 1.3030798138072888
Validation loss: 2.458926768672624

Epoch: 6| Step: 11
Training loss: 1.0222767078234731
Validation loss: 2.4835907042582224

Epoch: 6| Step: 12
Training loss: 0.8607658921369296
Validation loss: 2.474136469094184

Epoch: 6| Step: 13
Training loss: 1.1195569287674025
Validation loss: 2.4689085512142945

Epoch: 283| Step: 0
Training loss: 1.1089758356349415
Validation loss: 2.509662861358317

Epoch: 6| Step: 1
Training loss: 1.518499107202312
Validation loss: 2.510260906518057

Epoch: 6| Step: 2
Training loss: 1.0108838263152626
Validation loss: 2.4987404162568634

Epoch: 6| Step: 3
Training loss: 1.3893918774360918
Validation loss: 2.5020028346548386

Epoch: 6| Step: 4
Training loss: 1.7201741647146966
Validation loss: 2.52337406035145

Epoch: 6| Step: 5
Training loss: 1.1741362054761832
Validation loss: 2.4864752816247453

Epoch: 6| Step: 6
Training loss: 1.2847032299298968
Validation loss: 2.506711587151023

Epoch: 6| Step: 7
Training loss: 0.7995089961315787
Validation loss: 2.4673907794657968

Epoch: 6| Step: 8
Training loss: 0.5640428365307465
Validation loss: 2.4855413801703103

Epoch: 6| Step: 9
Training loss: 1.3710512768723027
Validation loss: 2.4822617965530847

Epoch: 6| Step: 10
Training loss: 1.068583407440536
Validation loss: 2.517760228498031

Epoch: 6| Step: 11
Training loss: 0.969977308971418
Validation loss: 2.5191377635693137

Epoch: 6| Step: 12
Training loss: 0.9169483113379884
Validation loss: 2.5044371708015776

Epoch: 6| Step: 13
Training loss: 1.0677703405223344
Validation loss: 2.5372126315281447

Epoch: 284| Step: 0
Training loss: 1.0916477162897895
Validation loss: 2.51763123775948

Epoch: 6| Step: 1
Training loss: 1.0379383631801593
Validation loss: 2.5253807455780923

Epoch: 6| Step: 2
Training loss: 1.1006591014355611
Validation loss: 2.5471192295732292

Epoch: 6| Step: 3
Training loss: 1.332895619348549
Validation loss: 2.57884396807131

Epoch: 6| Step: 4
Training loss: 1.1577915534674268
Validation loss: 2.5659676416433466

Epoch: 6| Step: 5
Training loss: 1.7596390791937644
Validation loss: 2.5357042583003953

Epoch: 6| Step: 6
Training loss: 0.7153185325624828
Validation loss: 2.5311430292328407

Epoch: 6| Step: 7
Training loss: 1.433696524862508
Validation loss: 2.575385670463447

Epoch: 6| Step: 8
Training loss: 1.0192011741001128
Validation loss: 2.5366983200145907

Epoch: 6| Step: 9
Training loss: 0.8661484206561091
Validation loss: 2.5377680732829035

Epoch: 6| Step: 10
Training loss: 0.7017977797914219
Validation loss: 2.4747354492634743

Epoch: 6| Step: 11
Training loss: 0.995293299371514
Validation loss: 2.4852015984764724

Epoch: 6| Step: 12
Training loss: 1.1763282593365187
Validation loss: 2.486138670563042

Epoch: 6| Step: 13
Training loss: 1.519942593243367
Validation loss: 2.512422551615556

Epoch: 285| Step: 0
Training loss: 1.2858128131474276
Validation loss: 2.4888051301689793

Epoch: 6| Step: 1
Training loss: 0.8896121573561704
Validation loss: 2.4708744968726943

Epoch: 6| Step: 2
Training loss: 0.9204443806323536
Validation loss: 2.480436850902964

Epoch: 6| Step: 3
Training loss: 1.6113917482704332
Validation loss: 2.522108458405301

Epoch: 6| Step: 4
Training loss: 1.025020336321549
Validation loss: 2.539782231176001

Epoch: 6| Step: 5
Training loss: 1.155109461596984
Validation loss: 2.5594606861009286

Epoch: 6| Step: 6
Training loss: 1.1494869186400394
Validation loss: 2.5636212926773645

Epoch: 6| Step: 7
Training loss: 0.9890554659866015
Validation loss: 2.5804736802722266

Epoch: 6| Step: 8
Training loss: 1.3839735770928088
Validation loss: 2.6052521351162086

Epoch: 6| Step: 9
Training loss: 1.1952515630211151
Validation loss: 2.593715380860021

Epoch: 6| Step: 10
Training loss: 0.9290984395271181
Validation loss: 2.618399839167258

Epoch: 6| Step: 11
Training loss: 0.8051155211209466
Validation loss: 2.588923027419902

Epoch: 6| Step: 12
Training loss: 1.5165802609629682
Validation loss: 2.5704175325017404

Epoch: 6| Step: 13
Training loss: 0.675833264592736
Validation loss: 2.5461935257352426

Epoch: 286| Step: 0
Training loss: 1.0864867872618853
Validation loss: 2.474144476648746

Epoch: 6| Step: 1
Training loss: 1.6984284766553228
Validation loss: 2.474954367335353

Epoch: 6| Step: 2
Training loss: 1.1667219671131215
Validation loss: 2.482328496988373

Epoch: 6| Step: 3
Training loss: 1.0318666406266297
Validation loss: 2.5088130996861775

Epoch: 6| Step: 4
Training loss: 0.9551972547004457
Validation loss: 2.5027196416877326

Epoch: 6| Step: 5
Training loss: 0.731421191399672
Validation loss: 2.510541856010317

Epoch: 6| Step: 6
Training loss: 0.9833302782032808
Validation loss: 2.5364919044011596

Epoch: 6| Step: 7
Training loss: 1.3293675612657159
Validation loss: 2.568986971001891

Epoch: 6| Step: 8
Training loss: 0.9892557036818898
Validation loss: 2.561906327118668

Epoch: 6| Step: 9
Training loss: 1.3208304749146027
Validation loss: 2.5705060629459013

Epoch: 6| Step: 10
Training loss: 0.9949221733461254
Validation loss: 2.5532961644145

Epoch: 6| Step: 11
Training loss: 1.2700381162134984
Validation loss: 2.5354761484040984

Epoch: 6| Step: 12
Training loss: 1.0983764891956775
Validation loss: 2.525932490471002

Epoch: 6| Step: 13
Training loss: 1.1295743766907056
Validation loss: 2.5198116460938493

Epoch: 287| Step: 0
Training loss: 0.9509411792514715
Validation loss: 2.513280634346208

Epoch: 6| Step: 1
Training loss: 1.2080942059819004
Validation loss: 2.5066269216428005

Epoch: 6| Step: 2
Training loss: 1.1339636379951639
Validation loss: 2.5260877027630966

Epoch: 6| Step: 3
Training loss: 1.0869766313309737
Validation loss: 2.4880359732444775

Epoch: 6| Step: 4
Training loss: 1.520411689870726
Validation loss: 2.5044319215730844

Epoch: 6| Step: 5
Training loss: 1.0101368441270298
Validation loss: 2.513345337555614

Epoch: 6| Step: 6
Training loss: 1.26918212785193
Validation loss: 2.4983886489053573

Epoch: 6| Step: 7
Training loss: 1.0888894117336791
Validation loss: 2.5233285511437686

Epoch: 6| Step: 8
Training loss: 1.3208623339400505
Validation loss: 2.573477731501024

Epoch: 6| Step: 9
Training loss: 1.3731939418815768
Validation loss: 2.5317421883678217

Epoch: 6| Step: 10
Training loss: 0.9546369848294483
Validation loss: 2.537670693666911

Epoch: 6| Step: 11
Training loss: 1.3142632946773665
Validation loss: 2.5218732120102834

Epoch: 6| Step: 12
Training loss: 0.5791237169116088
Validation loss: 2.4925597173247

Epoch: 6| Step: 13
Training loss: 0.5273069015627132
Validation loss: 2.5121254425606776

Epoch: 288| Step: 0
Training loss: 0.7108336991208184
Validation loss: 2.499164737097406

Epoch: 6| Step: 1
Training loss: 0.7222001156928605
Validation loss: 2.495475136104629

Epoch: 6| Step: 2
Training loss: 0.912887731244745
Validation loss: 2.5164897586236963

Epoch: 6| Step: 3
Training loss: 1.1273443908055123
Validation loss: 2.516054026541697

Epoch: 6| Step: 4
Training loss: 1.3051854628101451
Validation loss: 2.5140729062651928

Epoch: 6| Step: 5
Training loss: 1.133765405215881
Validation loss: 2.5532320438817444

Epoch: 6| Step: 6
Training loss: 1.5910767219214426
Validation loss: 2.5611958190004183

Epoch: 6| Step: 7
Training loss: 1.1006287750058095
Validation loss: 2.532466642121215

Epoch: 6| Step: 8
Training loss: 1.1936153755371233
Validation loss: 2.5299862413973817

Epoch: 6| Step: 9
Training loss: 1.56832418247895
Validation loss: 2.517355080723332

Epoch: 6| Step: 10
Training loss: 0.9509571310844511
Validation loss: 2.537298220416331

Epoch: 6| Step: 11
Training loss: 0.6638658793459801
Validation loss: 2.521140045759141

Epoch: 6| Step: 12
Training loss: 0.981699805215795
Validation loss: 2.49016962361707

Epoch: 6| Step: 13
Training loss: 1.391304235986389
Validation loss: 2.51475183538989

Epoch: 289| Step: 0
Training loss: 0.9668364853884559
Validation loss: 2.4619464025664097

Epoch: 6| Step: 1
Training loss: 1.4887652874088824
Validation loss: 2.469464535241607

Epoch: 6| Step: 2
Training loss: 1.0350418891354178
Validation loss: 2.464395265185091

Epoch: 6| Step: 3
Training loss: 0.8938474081883669
Validation loss: 2.482144307862668

Epoch: 6| Step: 4
Training loss: 1.1427519315587695
Validation loss: 2.4991149002087036

Epoch: 6| Step: 5
Training loss: 0.8446503533180766
Validation loss: 2.5201335340058364

Epoch: 6| Step: 6
Training loss: 1.4420969892309174
Validation loss: 2.517843917886088

Epoch: 6| Step: 7
Training loss: 1.3337617970510658
Validation loss: 2.49880039392878

Epoch: 6| Step: 8
Training loss: 0.937570918897602
Validation loss: 2.5206143507748484

Epoch: 6| Step: 9
Training loss: 0.9107036008929315
Validation loss: 2.5160847251899328

Epoch: 6| Step: 10
Training loss: 1.2150647124964988
Validation loss: 2.5075284086309235

Epoch: 6| Step: 11
Training loss: 0.6450190692123156
Validation loss: 2.534606316756316

Epoch: 6| Step: 12
Training loss: 1.2571161842458114
Validation loss: 2.5130835349610834

Epoch: 6| Step: 13
Training loss: 1.312379604448881
Validation loss: 2.5220857402600645

Epoch: 290| Step: 0
Training loss: 1.0229536470667873
Validation loss: 2.5254933090086733

Epoch: 6| Step: 1
Training loss: 1.3743306177874068
Validation loss: 2.491884280820765

Epoch: 6| Step: 2
Training loss: 1.0411206849066377
Validation loss: 2.470090564163354

Epoch: 6| Step: 3
Training loss: 1.2082058521416341
Validation loss: 2.4847943290097416

Epoch: 6| Step: 4
Training loss: 1.0190715703528401
Validation loss: 2.529974794096481

Epoch: 6| Step: 5
Training loss: 1.4686930219271388
Validation loss: 2.4836960557027696

Epoch: 6| Step: 6
Training loss: 1.1361661006725936
Validation loss: 2.4716827814831195

Epoch: 6| Step: 7
Training loss: 0.9629587145518734
Validation loss: 2.4685103857150805

Epoch: 6| Step: 8
Training loss: 1.052793143760537
Validation loss: 2.4797735845800015

Epoch: 6| Step: 9
Training loss: 1.2486484373258615
Validation loss: 2.4837459222565945

Epoch: 6| Step: 10
Training loss: 0.976913999241521
Validation loss: 2.5142449458605807

Epoch: 6| Step: 11
Training loss: 1.0625186806326845
Validation loss: 2.503224198045426

Epoch: 6| Step: 12
Training loss: 0.9389928693551398
Validation loss: 2.5387739705741637

Epoch: 6| Step: 13
Training loss: 0.8288087721017983
Validation loss: 2.5423012456867333

Epoch: 291| Step: 0
Training loss: 0.8659419832419862
Validation loss: 2.5316970645109755

Epoch: 6| Step: 1
Training loss: 1.0818874662971352
Validation loss: 2.5164306406348245

Epoch: 6| Step: 2
Training loss: 1.35787113357214
Validation loss: 2.5046132147296443

Epoch: 6| Step: 3
Training loss: 1.0188338426596701
Validation loss: 2.5254311533707177

Epoch: 6| Step: 4
Training loss: 1.226308808544893
Validation loss: 2.4828957115888373

Epoch: 6| Step: 5
Training loss: 1.8112509797635268
Validation loss: 2.502833505969372

Epoch: 6| Step: 6
Training loss: 1.0382789009015998
Validation loss: 2.528957078402585

Epoch: 6| Step: 7
Training loss: 0.4688989402661396
Validation loss: 2.5217361924951374

Epoch: 6| Step: 8
Training loss: 1.03339215516261
Validation loss: 2.522318861143984

Epoch: 6| Step: 9
Training loss: 0.8960663396339718
Validation loss: 2.5723102803746807

Epoch: 6| Step: 10
Training loss: 0.9685677695386087
Validation loss: 2.575505851052455

Epoch: 6| Step: 11
Training loss: 0.5805244141865299
Validation loss: 2.5646070595922925

Epoch: 6| Step: 12
Training loss: 1.2896961388785044
Validation loss: 2.5533488434368388

Epoch: 6| Step: 13
Training loss: 1.1253340013394324
Validation loss: 2.5357833347892025

Epoch: 292| Step: 0
Training loss: 1.449705468880726
Validation loss: 2.4942879959748088

Epoch: 6| Step: 1
Training loss: 1.0154634200456787
Validation loss: 2.50841611275138

Epoch: 6| Step: 2
Training loss: 1.1035714194447257
Validation loss: 2.47559528453027

Epoch: 6| Step: 3
Training loss: 1.3487478064942575
Validation loss: 2.4605745875161067

Epoch: 6| Step: 4
Training loss: 1.26364564942116
Validation loss: 2.4566590927725676

Epoch: 6| Step: 5
Training loss: 1.032617529213699
Validation loss: 2.4382455199482993

Epoch: 6| Step: 6
Training loss: 0.8725914161797643
Validation loss: 2.443358003658852

Epoch: 6| Step: 7
Training loss: 1.5877616426416132
Validation loss: 2.421820182060819

Epoch: 6| Step: 8
Training loss: 0.7806788836559444
Validation loss: 2.383149777942528

Epoch: 6| Step: 9
Training loss: 0.6648083257146944
Validation loss: 2.4303842249975287

Epoch: 6| Step: 10
Training loss: 0.5365368097428168
Validation loss: 2.424890607102989

Epoch: 6| Step: 11
Training loss: 0.8993879515329694
Validation loss: 2.445637968770238

Epoch: 6| Step: 12
Training loss: 0.7608966792944225
Validation loss: 2.4670313788625093

Epoch: 6| Step: 13
Training loss: 1.532050410126077
Validation loss: 2.523173246342151

Epoch: 293| Step: 0
Training loss: 1.034144241546857
Validation loss: 2.543996403500579

Epoch: 6| Step: 1
Training loss: 1.6838741909747545
Validation loss: 2.588867564787416

Epoch: 6| Step: 2
Training loss: 1.207583945932159
Validation loss: 2.5197260909830725

Epoch: 6| Step: 3
Training loss: 0.6779757682681439
Validation loss: 2.4788820798452904

Epoch: 6| Step: 4
Training loss: 0.8453171622382187
Validation loss: 2.476185624626116

Epoch: 6| Step: 5
Training loss: 1.1981020023882905
Validation loss: 2.4385053403533994

Epoch: 6| Step: 6
Training loss: 0.9693079848893023
Validation loss: 2.45847145041576

Epoch: 6| Step: 7
Training loss: 0.7087908183728079
Validation loss: 2.427123460293148

Epoch: 6| Step: 8
Training loss: 1.026934408000614
Validation loss: 2.4561513460586144

Epoch: 6| Step: 9
Training loss: 0.9995601700079586
Validation loss: 2.4709986804879236

Epoch: 6| Step: 10
Training loss: 1.4473567218398948
Validation loss: 2.537764180998558

Epoch: 6| Step: 11
Training loss: 1.0946805537659816
Validation loss: 2.492176034408325

Epoch: 6| Step: 12
Training loss: 0.8154789161669724
Validation loss: 2.541010146645786

Epoch: 6| Step: 13
Training loss: 0.7723189077485807
Validation loss: 2.541897699865854

Epoch: 294| Step: 0
Training loss: 1.1795302532564258
Validation loss: 2.5175559688103504

Epoch: 6| Step: 1
Training loss: 1.0199730745202429
Validation loss: 2.5110709777101365

Epoch: 6| Step: 2
Training loss: 1.1954916028246774
Validation loss: 2.5299023233835713

Epoch: 6| Step: 3
Training loss: 0.8598747880849177
Validation loss: 2.4681056760121027

Epoch: 6| Step: 4
Training loss: 0.8793884311021767
Validation loss: 2.4473957716287558

Epoch: 6| Step: 5
Training loss: 1.2390585785042472
Validation loss: 2.454070359051137

Epoch: 6| Step: 6
Training loss: 0.9926521534882496
Validation loss: 2.4395573801952923

Epoch: 6| Step: 7
Training loss: 0.6899724414753814
Validation loss: 2.4534083460687475

Epoch: 6| Step: 8
Training loss: 1.2168776973621978
Validation loss: 2.4376524442925964

Epoch: 6| Step: 9
Training loss: 0.7308426170527919
Validation loss: 2.493323381354845

Epoch: 6| Step: 10
Training loss: 0.9435016216816028
Validation loss: 2.4988639157516763

Epoch: 6| Step: 11
Training loss: 1.5979651266787842
Validation loss: 2.4873294239424695

Epoch: 6| Step: 12
Training loss: 0.8046872407486878
Validation loss: 2.4897567040603064

Epoch: 6| Step: 13
Training loss: 1.3790931466935366
Validation loss: 2.5239147417062107

Epoch: 295| Step: 0
Training loss: 1.2316458748252768
Validation loss: 2.552257895929651

Epoch: 6| Step: 1
Training loss: 1.382319993066881
Validation loss: 2.5292154326657585

Epoch: 6| Step: 2
Training loss: 1.1372878495125698
Validation loss: 2.5559071011760737

Epoch: 6| Step: 3
Training loss: 0.9970460117229522
Validation loss: 2.5253847340998705

Epoch: 6| Step: 4
Training loss: 1.0381175168276984
Validation loss: 2.48880846115189

Epoch: 6| Step: 5
Training loss: 0.9401978140530698
Validation loss: 2.5347333098617777

Epoch: 6| Step: 6
Training loss: 1.2571431149909758
Validation loss: 2.489548570209422

Epoch: 6| Step: 7
Training loss: 0.7955211657951778
Validation loss: 2.507328902127154

Epoch: 6| Step: 8
Training loss: 1.4607100692219157
Validation loss: 2.4886229960013275

Epoch: 6| Step: 9
Training loss: 0.5526751968462124
Validation loss: 2.4829245303584266

Epoch: 6| Step: 10
Training loss: 0.950144030293705
Validation loss: 2.457749215154548

Epoch: 6| Step: 11
Training loss: 0.9449817930213501
Validation loss: 2.439049066830306

Epoch: 6| Step: 12
Training loss: 0.7254701832665329
Validation loss: 2.462696219576682

Epoch: 6| Step: 13
Training loss: 1.048612490745013
Validation loss: 2.4482172917334295

Epoch: 296| Step: 0
Training loss: 0.599688645879099
Validation loss: 2.445235370844227

Epoch: 6| Step: 1
Training loss: 1.2709358778474922
Validation loss: 2.4585106700368935

Epoch: 6| Step: 2
Training loss: 1.3865126335732274
Validation loss: 2.423633472398901

Epoch: 6| Step: 3
Training loss: 1.0369828716360696
Validation loss: 2.4209509339372555

Epoch: 6| Step: 4
Training loss: 0.6270523230488122
Validation loss: 2.469437886659525

Epoch: 6| Step: 5
Training loss: 1.2671876843848606
Validation loss: 2.4585967213930924

Epoch: 6| Step: 6
Training loss: 0.8781488164203819
Validation loss: 2.5269532971029087

Epoch: 6| Step: 7
Training loss: 1.091026675956748
Validation loss: 2.516553946371163

Epoch: 6| Step: 8
Training loss: 0.8913928620171404
Validation loss: 2.5214272530558506

Epoch: 6| Step: 9
Training loss: 0.7803228980896629
Validation loss: 2.5571590571569667

Epoch: 6| Step: 10
Training loss: 1.6564405079805558
Validation loss: 2.534704679873358

Epoch: 6| Step: 11
Training loss: 1.0832325570599144
Validation loss: 2.5042615091387295

Epoch: 6| Step: 12
Training loss: 0.7633833864687394
Validation loss: 2.491109257759211

Epoch: 6| Step: 13
Training loss: 0.4802803662681851
Validation loss: 2.4458619412921965

Epoch: 297| Step: 0
Training loss: 1.1810422280665152
Validation loss: 2.46592223968912

Epoch: 6| Step: 1
Training loss: 1.0333077101965906
Validation loss: 2.4508343618370794

Epoch: 6| Step: 2
Training loss: 1.7216344038730653
Validation loss: 2.458944340340654

Epoch: 6| Step: 3
Training loss: 1.0007387055429857
Validation loss: 2.4831026038080397

Epoch: 6| Step: 4
Training loss: 0.9687101909702719
Validation loss: 2.4514760513920355

Epoch: 6| Step: 5
Training loss: 1.0109486834277455
Validation loss: 2.489498113456618

Epoch: 6| Step: 6
Training loss: 0.9643612168539133
Validation loss: 2.4683289299258058

Epoch: 6| Step: 7
Training loss: 1.1855676891127471
Validation loss: 2.503072136964498

Epoch: 6| Step: 8
Training loss: 0.6780533273677566
Validation loss: 2.4716481484618416

Epoch: 6| Step: 9
Training loss: 1.064709553760277
Validation loss: 2.490169560817299

Epoch: 6| Step: 10
Training loss: 0.6649203649680098
Validation loss: 2.5174807678759574

Epoch: 6| Step: 11
Training loss: 0.7212885931257781
Validation loss: 2.521946616380292

Epoch: 6| Step: 12
Training loss: 1.0228298217723932
Validation loss: 2.5285890843909886

Epoch: 6| Step: 13
Training loss: 1.0674919777597778
Validation loss: 2.526790222210163

Epoch: 298| Step: 0
Training loss: 1.298929815685459
Validation loss: 2.535037974118709

Epoch: 6| Step: 1
Training loss: 0.8753336542767617
Validation loss: 2.54887818978145

Epoch: 6| Step: 2
Training loss: 0.5764780039499217
Validation loss: 2.51449944995925

Epoch: 6| Step: 3
Training loss: 1.0866343505906413
Validation loss: 2.499219641358857

Epoch: 6| Step: 4
Training loss: 0.6012498612909296
Validation loss: 2.476413819519351

Epoch: 6| Step: 5
Training loss: 0.9041415054289315
Validation loss: 2.4411856083093415

Epoch: 6| Step: 6
Training loss: 1.1536942666294119
Validation loss: 2.433691520796271

Epoch: 6| Step: 7
Training loss: 1.3576489594788752
Validation loss: 2.447200664323983

Epoch: 6| Step: 8
Training loss: 1.1910337772656352
Validation loss: 2.419838545139031

Epoch: 6| Step: 9
Training loss: 0.7521370798985468
Validation loss: 2.4229108275089204

Epoch: 6| Step: 10
Training loss: 1.0346938918045032
Validation loss: 2.4161300993497976

Epoch: 6| Step: 11
Training loss: 1.2691412223892005
Validation loss: 2.46287039488508

Epoch: 6| Step: 12
Training loss: 1.1651920752116045
Validation loss: 2.4628027640975008

Epoch: 6| Step: 13
Training loss: 0.602400654085217
Validation loss: 2.453151468907909

Epoch: 299| Step: 0
Training loss: 0.8125663876921341
Validation loss: 2.482696527562126

Epoch: 6| Step: 1
Training loss: 1.1659664482340788
Validation loss: 2.541511267301226

Epoch: 6| Step: 2
Training loss: 0.888014732779899
Validation loss: 2.5514245581605133

Epoch: 6| Step: 3
Training loss: 0.9390780201675103
Validation loss: 2.5326428841750253

Epoch: 6| Step: 4
Training loss: 0.5067037362207317
Validation loss: 2.5605250035125415

Epoch: 6| Step: 5
Training loss: 1.0483147129978636
Validation loss: 2.4918002843826654

Epoch: 6| Step: 6
Training loss: 1.179412809816076
Validation loss: 2.521928940851677

Epoch: 6| Step: 7
Training loss: 1.3314066118701648
Validation loss: 2.537618760048011

Epoch: 6| Step: 8
Training loss: 0.5953323711372893
Validation loss: 2.5249608029401847

Epoch: 6| Step: 9
Training loss: 0.810686398183162
Validation loss: 2.5373055305200976

Epoch: 6| Step: 10
Training loss: 1.0993287726177168
Validation loss: 2.50770016421406

Epoch: 6| Step: 11
Training loss: 1.3116737217129726
Validation loss: 2.513338585071762

Epoch: 6| Step: 12
Training loss: 1.0867759157525876
Validation loss: 2.5322551385023826

Epoch: 6| Step: 13
Training loss: 1.1250180137039794
Validation loss: 2.50656694510164

Epoch: 300| Step: 0
Training loss: 0.6873662991997154
Validation loss: 2.470616459731953

Epoch: 6| Step: 1
Training loss: 0.9508900939778452
Validation loss: 2.482622185206846

Epoch: 6| Step: 2
Training loss: 1.4085985282017153
Validation loss: 2.451799515196707

Epoch: 6| Step: 3
Training loss: 0.874323583458618
Validation loss: 2.4327652968462377

Epoch: 6| Step: 4
Training loss: 0.9315950074613651
Validation loss: 2.3888280765120466

Epoch: 6| Step: 5
Training loss: 1.2743547564625022
Validation loss: 2.402646901495105

Epoch: 6| Step: 6
Training loss: 1.0898248814415863
Validation loss: 2.45158886263534

Epoch: 6| Step: 7
Training loss: 1.0312999366460622
Validation loss: 2.5002914453666825

Epoch: 6| Step: 8
Training loss: 1.316183280739166
Validation loss: 2.4795311800887094

Epoch: 6| Step: 9
Training loss: 0.9596663340225341
Validation loss: 2.5401897296554012

Epoch: 6| Step: 10
Training loss: 0.5882857252865158
Validation loss: 2.5534217490815054

Epoch: 6| Step: 11
Training loss: 1.1272606388790498
Validation loss: 2.5793085418834036

Epoch: 6| Step: 12
Training loss: 0.5520282723902307
Validation loss: 2.5825467988041013

Epoch: 6| Step: 13
Training loss: 1.0807335298136072
Validation loss: 2.567455707058596

Epoch: 301| Step: 0
Training loss: 0.5272896067763594
Validation loss: 2.590038172425161

Epoch: 6| Step: 1
Training loss: 0.7836963118640272
Validation loss: 2.5327260180235007

Epoch: 6| Step: 2
Training loss: 0.8410443263420917
Validation loss: 2.5080057909910223

Epoch: 6| Step: 3
Training loss: 1.1082121436229786
Validation loss: 2.519491898627715

Epoch: 6| Step: 4
Training loss: 1.1902278387918712
Validation loss: 2.470168342189367

Epoch: 6| Step: 5
Training loss: 1.011621360068052
Validation loss: 2.4548303672276104

Epoch: 6| Step: 6
Training loss: 1.1499702449763884
Validation loss: 2.379582572151704

Epoch: 6| Step: 7
Training loss: 0.9407192588546011
Validation loss: 2.4222339577142993

Epoch: 6| Step: 8
Training loss: 0.7159045327304321
Validation loss: 2.3899943617585486

Epoch: 6| Step: 9
Training loss: 1.4940119270298011
Validation loss: 2.410606576881481

Epoch: 6| Step: 10
Training loss: 1.1800057695538695
Validation loss: 2.420542856258685

Epoch: 6| Step: 11
Training loss: 0.6580082183139147
Validation loss: 2.4180241275819125

Epoch: 6| Step: 12
Training loss: 0.968318196937281
Validation loss: 2.4843923792944156

Epoch: 6| Step: 13
Training loss: 1.1179414885773895
Validation loss: 2.4768267459146664

Epoch: 302| Step: 0
Training loss: 0.5672492232773407
Validation loss: 2.496167535028475

Epoch: 6| Step: 1
Training loss: 1.3744826644076236
Validation loss: 2.5830863211992

Epoch: 6| Step: 2
Training loss: 0.850446407116438
Validation loss: 2.5650098800924654

Epoch: 6| Step: 3
Training loss: 0.8160615037992499
Validation loss: 2.5343814319771596

Epoch: 6| Step: 4
Training loss: 0.9814784106087244
Validation loss: 2.567467575369345

Epoch: 6| Step: 5
Training loss: 1.201609065191561
Validation loss: 2.5174857342944525

Epoch: 6| Step: 6
Training loss: 1.0476270792496365
Validation loss: 2.474101087578185

Epoch: 6| Step: 7
Training loss: 1.1654761007076897
Validation loss: 2.4612028568440323

Epoch: 6| Step: 8
Training loss: 1.027124417755493
Validation loss: 2.409413027778151

Epoch: 6| Step: 9
Training loss: 0.7354872377015793
Validation loss: 2.4247412259024594

Epoch: 6| Step: 10
Training loss: 0.9520206619993697
Validation loss: 2.440624897018455

Epoch: 6| Step: 11
Training loss: 0.98613176562986
Validation loss: 2.448653402759687

Epoch: 6| Step: 12
Training loss: 1.2017202226676642
Validation loss: 2.4956729111836418

Epoch: 6| Step: 13
Training loss: 0.7082912114652791
Validation loss: 2.4881064744349266

Epoch: 303| Step: 0
Training loss: 0.884266828519755
Validation loss: 2.5708500845736943

Epoch: 6| Step: 1
Training loss: 1.0507110231891064
Validation loss: 2.5361181005993276

Epoch: 6| Step: 2
Training loss: 1.2755676427092015
Validation loss: 2.523955846329409

Epoch: 6| Step: 3
Training loss: 0.5626774878758879
Validation loss: 2.544785543935785

Epoch: 6| Step: 4
Training loss: 0.9356285489613224
Validation loss: 2.5648177065298947

Epoch: 6| Step: 5
Training loss: 1.2648356295461032
Validation loss: 2.5240648290498044

Epoch: 6| Step: 6
Training loss: 0.7922560773130678
Validation loss: 2.4889849324923796

Epoch: 6| Step: 7
Training loss: 0.9165795385973092
Validation loss: 2.49181580630312

Epoch: 6| Step: 8
Training loss: 0.9677152029121461
Validation loss: 2.4405862492209818

Epoch: 6| Step: 9
Training loss: 0.7784105581233037
Validation loss: 2.469075167119174

Epoch: 6| Step: 10
Training loss: 1.1518878616881685
Validation loss: 2.40451672010407

Epoch: 6| Step: 11
Training loss: 0.9109233848564369
Validation loss: 2.4295426123620647

Epoch: 6| Step: 12
Training loss: 0.9061637048084134
Validation loss: 2.39065416621079

Epoch: 6| Step: 13
Training loss: 1.2933918240600368
Validation loss: 2.4481897956226666

Epoch: 304| Step: 0
Training loss: 1.088250092267822
Validation loss: 2.4503350806614432

Epoch: 6| Step: 1
Training loss: 0.9657116897335293
Validation loss: 2.4666427293806077

Epoch: 6| Step: 2
Training loss: 1.110313770520004
Validation loss: 2.5095732193677556

Epoch: 6| Step: 3
Training loss: 1.0740409010268428
Validation loss: 2.5212062230057266

Epoch: 6| Step: 4
Training loss: 0.7443420457952183
Validation loss: 2.510399472982759

Epoch: 6| Step: 5
Training loss: 0.8374054399883539
Validation loss: 2.498305512497989

Epoch: 6| Step: 6
Training loss: 1.0129422481752983
Validation loss: 2.4617054303813473

Epoch: 6| Step: 7
Training loss: 0.9171044684133505
Validation loss: 2.4310789302056715

Epoch: 6| Step: 8
Training loss: 1.1625605372591823
Validation loss: 2.4792720637499697

Epoch: 6| Step: 9
Training loss: 0.6013627649623482
Validation loss: 2.5029395715504426

Epoch: 6| Step: 10
Training loss: 1.0825051051629537
Validation loss: 2.4869659136562006

Epoch: 6| Step: 11
Training loss: 1.3094521511172807
Validation loss: 2.521105592351574

Epoch: 6| Step: 12
Training loss: 0.6122134199978948
Validation loss: 2.543781389914185

Epoch: 6| Step: 13
Training loss: 0.9363514540419373
Validation loss: 2.5286589496768688

Epoch: 305| Step: 0
Training loss: 1.251020682373573
Validation loss: 2.5720938531463564

Epoch: 6| Step: 1
Training loss: 0.8164610045839455
Validation loss: 2.542610048520386

Epoch: 6| Step: 2
Training loss: 0.9698898930832549
Validation loss: 2.5428260775927347

Epoch: 6| Step: 3
Training loss: 0.5838477954182252
Validation loss: 2.4948121633763876

Epoch: 6| Step: 4
Training loss: 0.7962850743208626
Validation loss: 2.484750773050053

Epoch: 6| Step: 5
Training loss: 1.2617365124281827
Validation loss: 2.4615059196954876

Epoch: 6| Step: 6
Training loss: 1.0794884173826251
Validation loss: 2.443524556697119

Epoch: 6| Step: 7
Training loss: 1.1555147668678167
Validation loss: 2.4905566280099722

Epoch: 6| Step: 8
Training loss: 0.9109084005271886
Validation loss: 2.5097402639102406

Epoch: 6| Step: 9
Training loss: 0.6818568370438546
Validation loss: 2.4885042474119334

Epoch: 6| Step: 10
Training loss: 0.8190726947404664
Validation loss: 2.4664464556545713

Epoch: 6| Step: 11
Training loss: 0.9053455311731121
Validation loss: 2.5041595413292

Epoch: 6| Step: 12
Training loss: 0.6822590905097945
Validation loss: 2.4876399113366072

Epoch: 6| Step: 13
Training loss: 1.6944800939440343
Validation loss: 2.5274915341175967

Epoch: 306| Step: 0
Training loss: 0.933904939126902
Validation loss: 2.508730032823326

Epoch: 6| Step: 1
Training loss: 1.0443485576722502
Validation loss: 2.5238831926310796

Epoch: 6| Step: 2
Training loss: 1.108544159439363
Validation loss: 2.530518592607234

Epoch: 6| Step: 3
Training loss: 0.9975636127810595
Validation loss: 2.4907313520716907

Epoch: 6| Step: 4
Training loss: 0.8671922082171774
Validation loss: 2.4564149447728383

Epoch: 6| Step: 5
Training loss: 1.1888006014638846
Validation loss: 2.437450417897013

Epoch: 6| Step: 6
Training loss: 0.8424534195607724
Validation loss: 2.4478932508938374

Epoch: 6| Step: 7
Training loss: 0.8167841278643133
Validation loss: 2.406625546577425

Epoch: 6| Step: 8
Training loss: 1.2255895363804232
Validation loss: 2.4482119073034245

Epoch: 6| Step: 9
Training loss: 0.919549660186431
Validation loss: 2.4733181101821944

Epoch: 6| Step: 10
Training loss: 1.091619869617186
Validation loss: 2.4563623567085258

Epoch: 6| Step: 11
Training loss: 0.7827681477482796
Validation loss: 2.446058553504682

Epoch: 6| Step: 12
Training loss: 0.9917754872236964
Validation loss: 2.523476281886059

Epoch: 6| Step: 13
Training loss: 0.3196263756959242
Validation loss: 2.4736211588200825

Epoch: 307| Step: 0
Training loss: 0.9479483434952691
Validation loss: 2.470675644629943

Epoch: 6| Step: 1
Training loss: 0.6179031616976455
Validation loss: 2.4957873979212675

Epoch: 6| Step: 2
Training loss: 0.7886980933809505
Validation loss: 2.5125911953429454

Epoch: 6| Step: 3
Training loss: 0.98273309893305
Validation loss: 2.4967201888952606

Epoch: 6| Step: 4
Training loss: 0.8974668151862241
Validation loss: 2.4922216485522717

Epoch: 6| Step: 5
Training loss: 0.5544832955158374
Validation loss: 2.490832166217966

Epoch: 6| Step: 6
Training loss: 1.3890724945566997
Validation loss: 2.524750482021768

Epoch: 6| Step: 7
Training loss: 1.1819644704891075
Validation loss: 2.5021453758198597

Epoch: 6| Step: 8
Training loss: 0.9438461090564627
Validation loss: 2.5072401097168466

Epoch: 6| Step: 9
Training loss: 1.2941821532951197
Validation loss: 2.5256350837156614

Epoch: 6| Step: 10
Training loss: 0.6589075049319856
Validation loss: 2.5283038597712486

Epoch: 6| Step: 11
Training loss: 1.1343543247829346
Validation loss: 2.512368047109605

Epoch: 6| Step: 12
Training loss: 0.5782531647766694
Validation loss: 2.5011876433419493

Epoch: 6| Step: 13
Training loss: 1.0923997446320388
Validation loss: 2.489924650770765

Epoch: 308| Step: 0
Training loss: 0.7749791050216869
Validation loss: 2.4800534818726314

Epoch: 6| Step: 1
Training loss: 0.8291850952196376
Validation loss: 2.476906969305668

Epoch: 6| Step: 2
Training loss: 1.0760322383284147
Validation loss: 2.454631614742107

Epoch: 6| Step: 3
Training loss: 1.0092192302300516
Validation loss: 2.4647223839555794

Epoch: 6| Step: 4
Training loss: 0.8240611210371392
Validation loss: 2.462726626689046

Epoch: 6| Step: 5
Training loss: 1.3396548480002712
Validation loss: 2.5060735001718646

Epoch: 6| Step: 6
Training loss: 0.8993575982377958
Validation loss: 2.5015436902971406

Epoch: 6| Step: 7
Training loss: 1.1727196764582348
Validation loss: 2.5031579816922447

Epoch: 6| Step: 8
Training loss: 0.7357762947814858
Validation loss: 2.497090779897332

Epoch: 6| Step: 9
Training loss: 1.0645401945288477
Validation loss: 2.5079170087459017

Epoch: 6| Step: 10
Training loss: 0.4804779920231873
Validation loss: 2.5087365861812834

Epoch: 6| Step: 11
Training loss: 1.0959051425356836
Validation loss: 2.525167174335033

Epoch: 6| Step: 12
Training loss: 0.8524290103384715
Validation loss: 2.492676095447366

Epoch: 6| Step: 13
Training loss: 0.9956330075274226
Validation loss: 2.4952794212049287

Epoch: 309| Step: 0
Training loss: 1.158418014687673
Validation loss: 2.5120507362835087

Epoch: 6| Step: 1
Training loss: 0.880006703112822
Validation loss: 2.4757928024519136

Epoch: 6| Step: 2
Training loss: 0.9780733551918749
Validation loss: 2.5047944732711236

Epoch: 6| Step: 3
Training loss: 0.9254194429869201
Validation loss: 2.4987010057515286

Epoch: 6| Step: 4
Training loss: 0.9384668450939091
Validation loss: 2.464541019583416

Epoch: 6| Step: 5
Training loss: 1.3784783323437075
Validation loss: 2.504969536724599

Epoch: 6| Step: 6
Training loss: 1.0105862557103737
Validation loss: 2.5052640766004184

Epoch: 6| Step: 7
Training loss: 0.6099792321375119
Validation loss: 2.508596987677872

Epoch: 6| Step: 8
Training loss: 0.8897605180539367
Validation loss: 2.499622125678039

Epoch: 6| Step: 9
Training loss: 0.7235758935368014
Validation loss: 2.525448140497077

Epoch: 6| Step: 10
Training loss: 0.8855801300548962
Validation loss: 2.5029445821857683

Epoch: 6| Step: 11
Training loss: 0.6483460327349485
Validation loss: 2.52301466064195

Epoch: 6| Step: 12
Training loss: 0.9803701100371565
Validation loss: 2.5163090506455403

Epoch: 6| Step: 13
Training loss: 0.7876869524704361
Validation loss: 2.504545164480222

Epoch: 310| Step: 0
Training loss: 0.6902742979877482
Validation loss: 2.466847151755271

Epoch: 6| Step: 1
Training loss: 1.2170253190202045
Validation loss: 2.4450929908760326

Epoch: 6| Step: 2
Training loss: 0.566457759225079
Validation loss: 2.4527252626105835

Epoch: 6| Step: 3
Training loss: 0.5328023892782956
Validation loss: 2.4458352781985666

Epoch: 6| Step: 4
Training loss: 1.1355353943697462
Validation loss: 2.442128151628661

Epoch: 6| Step: 5
Training loss: 0.7550201488484156
Validation loss: 2.425674239809911

Epoch: 6| Step: 6
Training loss: 0.8493268124101991
Validation loss: 2.469426590032251

Epoch: 6| Step: 7
Training loss: 1.219655116533663
Validation loss: 2.484116158777645

Epoch: 6| Step: 8
Training loss: 1.2231278652494824
Validation loss: 2.5179948547699587

Epoch: 6| Step: 9
Training loss: 1.2812727484195512
Validation loss: 2.4737500136813173

Epoch: 6| Step: 10
Training loss: 0.915482550987576
Validation loss: 2.484730624962025

Epoch: 6| Step: 11
Training loss: 0.3889619138062822
Validation loss: 2.4599067786143416

Epoch: 6| Step: 12
Training loss: 0.7633680046389416
Validation loss: 2.4523130909570483

Epoch: 6| Step: 13
Training loss: 0.6137586788410714
Validation loss: 2.431294784599492

Epoch: 311| Step: 0
Training loss: 1.217412214384664
Validation loss: 2.4584908699990087

Epoch: 6| Step: 1
Training loss: 1.0442660831841224
Validation loss: 2.4564267140002856

Epoch: 6| Step: 2
Training loss: 1.2188360721810005
Validation loss: 2.4392765172075426

Epoch: 6| Step: 3
Training loss: 0.5872557243841176
Validation loss: 2.431523076834691

Epoch: 6| Step: 4
Training loss: 0.82555595507754
Validation loss: 2.4539162132069623

Epoch: 6| Step: 5
Training loss: 0.7411295930356906
Validation loss: 2.4373637535483774

Epoch: 6| Step: 6
Training loss: 0.8408443788635327
Validation loss: 2.49752673380982

Epoch: 6| Step: 7
Training loss: 0.7989505217036432
Validation loss: 2.502224697314913

Epoch: 6| Step: 8
Training loss: 1.0985117120756531
Validation loss: 2.55885428766591

Epoch: 6| Step: 9
Training loss: 0.8625364931651448
Validation loss: 2.5323864163162892

Epoch: 6| Step: 10
Training loss: 0.9030734987985074
Validation loss: 2.529071074118944

Epoch: 6| Step: 11
Training loss: 0.8602967953868023
Validation loss: 2.499201866641435

Epoch: 6| Step: 12
Training loss: 0.7384269610931075
Validation loss: 2.46177937863749

Epoch: 6| Step: 13
Training loss: 0.9779700244822732
Validation loss: 2.464072649574454

Epoch: 312| Step: 0
Training loss: 0.8411685165008024
Validation loss: 2.447154090529854

Epoch: 6| Step: 1
Training loss: 0.9806419614707181
Validation loss: 2.4637616457858256

Epoch: 6| Step: 2
Training loss: 1.0357793120468086
Validation loss: 2.4589977541459227

Epoch: 6| Step: 3
Training loss: 0.9213096372123717
Validation loss: 2.478985004658021

Epoch: 6| Step: 4
Training loss: 1.1092174041993514
Validation loss: 2.4822853459855274

Epoch: 6| Step: 5
Training loss: 0.46590354063953027
Validation loss: 2.480810389505455

Epoch: 6| Step: 6
Training loss: 0.8864684570905864
Validation loss: 2.4657679702530104

Epoch: 6| Step: 7
Training loss: 0.9451112769474785
Validation loss: 2.505460838507133

Epoch: 6| Step: 8
Training loss: 0.9175531298666483
Validation loss: 2.509382502538336

Epoch: 6| Step: 9
Training loss: 0.641027254490778
Validation loss: 2.4809040804106646

Epoch: 6| Step: 10
Training loss: 1.1408434619458587
Validation loss: 2.4863681105447166

Epoch: 6| Step: 11
Training loss: 0.7119768531015717
Validation loss: 2.5035253955703647

Epoch: 6| Step: 12
Training loss: 0.7130773012489302
Validation loss: 2.5177852155592717

Epoch: 6| Step: 13
Training loss: 1.233979656793716
Validation loss: 2.4431723587219656

Epoch: 313| Step: 0
Training loss: 0.8378450963737737
Validation loss: 2.4457962421002217

Epoch: 6| Step: 1
Training loss: 1.0699261155867896
Validation loss: 2.4104908484735104

Epoch: 6| Step: 2
Training loss: 1.1290561880045593
Validation loss: 2.432934288392679

Epoch: 6| Step: 3
Training loss: 1.0274593157730614
Validation loss: 2.4223987977507093

Epoch: 6| Step: 4
Training loss: 0.91910378916896
Validation loss: 2.4182073676945546

Epoch: 6| Step: 5
Training loss: 0.575688796468817
Validation loss: 2.4667556306260345

Epoch: 6| Step: 6
Training loss: 0.9634326082662847
Validation loss: 2.489968549682399

Epoch: 6| Step: 7
Training loss: 0.8945543710977196
Validation loss: 2.472691384700439

Epoch: 6| Step: 8
Training loss: 0.666908716924284
Validation loss: 2.479570349895937

Epoch: 6| Step: 9
Training loss: 1.1329512938613402
Validation loss: 2.4789316843802447

Epoch: 6| Step: 10
Training loss: 0.7654171486363134
Validation loss: 2.4913756477124096

Epoch: 6| Step: 11
Training loss: 0.7627343083570834
Validation loss: 2.502053877370478

Epoch: 6| Step: 12
Training loss: 0.877991331522561
Validation loss: 2.4585576470430373

Epoch: 6| Step: 13
Training loss: 0.5041981228822616
Validation loss: 2.4768745916945956

Epoch: 314| Step: 0
Training loss: 0.6966133593016711
Validation loss: 2.4958257733365317

Epoch: 6| Step: 1
Training loss: 0.620044613894274
Validation loss: 2.483069422176009

Epoch: 6| Step: 2
Training loss: 0.7580899782574823
Validation loss: 2.5082071089887683

Epoch: 6| Step: 3
Training loss: 0.8129831491485913
Validation loss: 2.4985103732482346

Epoch: 6| Step: 4
Training loss: 0.8227769435294787
Validation loss: 2.487414191803486

Epoch: 6| Step: 5
Training loss: 0.9870693933853351
Validation loss: 2.4816304971943697

Epoch: 6| Step: 6
Training loss: 0.6743652414459036
Validation loss: 2.4877298510786354

Epoch: 6| Step: 7
Training loss: 0.6330216144680192
Validation loss: 2.4772912764667936

Epoch: 6| Step: 8
Training loss: 1.0484206333310242
Validation loss: 2.4715042254557713

Epoch: 6| Step: 9
Training loss: 0.9292849783278215
Validation loss: 2.4713067651936917

Epoch: 6| Step: 10
Training loss: 1.1884502323340267
Validation loss: 2.4508977544800827

Epoch: 6| Step: 11
Training loss: 0.896024432240889
Validation loss: 2.45025172837468

Epoch: 6| Step: 12
Training loss: 1.3097213214283705
Validation loss: 2.4359418886488737

Epoch: 6| Step: 13
Training loss: 0.21614131099305545
Validation loss: 2.4413397483382298

Epoch: 315| Step: 0
Training loss: 0.9207751615340153
Validation loss: 2.463651199436295

Epoch: 6| Step: 1
Training loss: 0.8859626134041174
Validation loss: 2.439271777790508

Epoch: 6| Step: 2
Training loss: 0.7857546068348378
Validation loss: 2.4360048742831015

Epoch: 6| Step: 3
Training loss: 0.6573540619153995
Validation loss: 2.4698895853469574

Epoch: 6| Step: 4
Training loss: 0.671517676326023
Validation loss: 2.4911998666963107

Epoch: 6| Step: 5
Training loss: 1.3568742923743513
Validation loss: 2.486750538041216

Epoch: 6| Step: 6
Training loss: 0.9687015152149985
Validation loss: 2.5323353593550038

Epoch: 6| Step: 7
Training loss: 0.42822462231522906
Validation loss: 2.523298486210052

Epoch: 6| Step: 8
Training loss: 0.9214474607983788
Validation loss: 2.5568994195751458

Epoch: 6| Step: 9
Training loss: 1.2445344166975807
Validation loss: 2.5654514262373236

Epoch: 6| Step: 10
Training loss: 0.8232161222519557
Validation loss: 2.597435889379809

Epoch: 6| Step: 11
Training loss: 0.4493731357816989
Validation loss: 2.5849443692350453

Epoch: 6| Step: 12
Training loss: 1.0710854071605929
Validation loss: 2.5967559949481385

Epoch: 6| Step: 13
Training loss: 0.6027664423265915
Validation loss: 2.5110272455719986

Epoch: 316| Step: 0
Training loss: 0.6857007063290265
Validation loss: 2.4889367128357027

Epoch: 6| Step: 1
Training loss: 1.0211291306312071
Validation loss: 2.471060096121189

Epoch: 6| Step: 2
Training loss: 0.8380292230964147
Validation loss: 2.406644994637401

Epoch: 6| Step: 3
Training loss: 1.068542520561529
Validation loss: 2.4269722977351043

Epoch: 6| Step: 4
Training loss: 0.6008523737720607
Validation loss: 2.447743923992937

Epoch: 6| Step: 5
Training loss: 0.5567087232193734
Validation loss: 2.434460922776933

Epoch: 6| Step: 6
Training loss: 1.1615517183860018
Validation loss: 2.450325016850127

Epoch: 6| Step: 7
Training loss: 0.9287355501942798
Validation loss: 2.4691303646044096

Epoch: 6| Step: 8
Training loss: 1.1700160732143363
Validation loss: 2.424521415008119

Epoch: 6| Step: 9
Training loss: 0.7319868499742029
Validation loss: 2.477701777735426

Epoch: 6| Step: 10
Training loss: 0.9550278227183424
Validation loss: 2.471949214600866

Epoch: 6| Step: 11
Training loss: 0.5351593128868497
Validation loss: 2.483346126114915

Epoch: 6| Step: 12
Training loss: 0.7091522438414571
Validation loss: 2.4835750225472926

Epoch: 6| Step: 13
Training loss: 0.7646788765218776
Validation loss: 2.5167350493133904

Epoch: 317| Step: 0
Training loss: 0.7878131607095262
Validation loss: 2.4866968378743217

Epoch: 6| Step: 1
Training loss: 0.7592141864181754
Validation loss: 2.518972044962849

Epoch: 6| Step: 2
Training loss: 0.9622257250595304
Validation loss: 2.5159076895399064

Epoch: 6| Step: 3
Training loss: 1.1243960560835666
Validation loss: 2.4901431564620182

Epoch: 6| Step: 4
Training loss: 0.5970021576770532
Validation loss: 2.4917154784824302

Epoch: 6| Step: 5
Training loss: 0.8392757890572421
Validation loss: 2.507029300715872

Epoch: 6| Step: 6
Training loss: 0.6376927888361721
Validation loss: 2.468883801021492

Epoch: 6| Step: 7
Training loss: 1.025145408737007
Validation loss: 2.4483343116767626

Epoch: 6| Step: 8
Training loss: 0.8378393339806413
Validation loss: 2.367087555231415

Epoch: 6| Step: 9
Training loss: 0.7002668995886389
Validation loss: 2.3761660914237335

Epoch: 6| Step: 10
Training loss: 1.21234846052987
Validation loss: 2.3727663014145466

Epoch: 6| Step: 11
Training loss: 0.7703726182115024
Validation loss: 2.4059111771183703

Epoch: 6| Step: 12
Training loss: 0.8173238899386541
Validation loss: 2.409891885975541

Epoch: 6| Step: 13
Training loss: 1.1766720562470139
Validation loss: 2.4400311105373107

Epoch: 318| Step: 0
Training loss: 0.9771719289819388
Validation loss: 2.4184371529275945

Epoch: 6| Step: 1
Training loss: 0.3651510337355815
Validation loss: 2.521202280748872

Epoch: 6| Step: 2
Training loss: 1.1449698691588954
Validation loss: 2.540942613609698

Epoch: 6| Step: 3
Training loss: 0.6232755474557454
Validation loss: 2.4980468534485816

Epoch: 6| Step: 4
Training loss: 1.0904760679848582
Validation loss: 2.495644600447749

Epoch: 6| Step: 5
Training loss: 0.4412833523775526
Validation loss: 2.490552221382495

Epoch: 6| Step: 6
Training loss: 0.9025891783552654
Validation loss: 2.4423451839272774

Epoch: 6| Step: 7
Training loss: 1.3592687981873592
Validation loss: 2.425627113710835

Epoch: 6| Step: 8
Training loss: 0.6970760183830307
Validation loss: 2.438498815875144

Epoch: 6| Step: 9
Training loss: 1.1812478665933064
Validation loss: 2.4189250863278726

Epoch: 6| Step: 10
Training loss: 0.7201110972019422
Validation loss: 2.406413596528538

Epoch: 6| Step: 11
Training loss: 0.7930728486983969
Validation loss: 2.407268439156652

Epoch: 6| Step: 12
Training loss: 0.8281731861418566
Validation loss: 2.461607403784125

Epoch: 6| Step: 13
Training loss: 0.25280688040279226
Validation loss: 2.486389355825892

Epoch: 319| Step: 0
Training loss: 1.0000001192092824
Validation loss: 2.5419084510268397

Epoch: 6| Step: 1
Training loss: 0.9369966745287042
Validation loss: 2.552747121193271

Epoch: 6| Step: 2
Training loss: 1.1312832737871348
Validation loss: 2.5589555417088485

Epoch: 6| Step: 3
Training loss: 0.850769618771916
Validation loss: 2.532483435271731

Epoch: 6| Step: 4
Training loss: 0.9760141282622423
Validation loss: 2.5538268307675094

Epoch: 6| Step: 5
Training loss: 0.38201806293342944
Validation loss: 2.5061080845384285

Epoch: 6| Step: 6
Training loss: 1.2200429367107979
Validation loss: 2.4693431990491352

Epoch: 6| Step: 7
Training loss: 0.7917500042133916
Validation loss: 2.4668912857084138

Epoch: 6| Step: 8
Training loss: 0.6183786607290422
Validation loss: 2.414368675847812

Epoch: 6| Step: 9
Training loss: 0.8060233130147987
Validation loss: 2.410844431871939

Epoch: 6| Step: 10
Training loss: 0.9111491341881981
Validation loss: 2.4056823033096357

Epoch: 6| Step: 11
Training loss: 0.9126281569901366
Validation loss: 2.4106341358387646

Epoch: 6| Step: 12
Training loss: 0.5341948623872909
Validation loss: 2.4400436406643182

Epoch: 6| Step: 13
Training loss: 0.9320127755546043
Validation loss: 2.43898372333868

Epoch: 320| Step: 0
Training loss: 0.5508185840696168
Validation loss: 2.450536222669905

Epoch: 6| Step: 1
Training loss: 0.7937753267828244
Validation loss: 2.4957236770964624

Epoch: 6| Step: 2
Training loss: 0.4446438906444766
Validation loss: 2.484288934481083

Epoch: 6| Step: 3
Training loss: 0.7186512257250697
Validation loss: 2.5116348087991724

Epoch: 6| Step: 4
Training loss: 0.8238961912916036
Validation loss: 2.56360903455557

Epoch: 6| Step: 5
Training loss: 1.126132342239785
Validation loss: 2.5281161819836195

Epoch: 6| Step: 6
Training loss: 0.854991867015594
Validation loss: 2.4525757710302076

Epoch: 6| Step: 7
Training loss: 1.1048754390573692
Validation loss: 2.4250211278588942

Epoch: 6| Step: 8
Training loss: 0.8975857221421499
Validation loss: 2.4142690150031223

Epoch: 6| Step: 9
Training loss: 0.9779601814417578
Validation loss: 2.4147639742342704

Epoch: 6| Step: 10
Training loss: 0.4853471107201991
Validation loss: 2.406823351913587

Epoch: 6| Step: 11
Training loss: 0.8903997035918038
Validation loss: 2.390186618409447

Epoch: 6| Step: 12
Training loss: 1.147529502605744
Validation loss: 2.395164768481223

Epoch: 6| Step: 13
Training loss: 0.659206180746537
Validation loss: 2.412644408865093

Epoch: 321| Step: 0
Training loss: 0.9313849972157783
Validation loss: 2.4197050272540257

Epoch: 6| Step: 1
Training loss: 1.024778870245931
Validation loss: 2.4164956254724625

Epoch: 6| Step: 2
Training loss: 1.1161314234275854
Validation loss: 2.442220082350182

Epoch: 6| Step: 3
Training loss: 0.7151165634455109
Validation loss: 2.4635383151351427

Epoch: 6| Step: 4
Training loss: 0.6848060756993717
Validation loss: 2.465250158860529

Epoch: 6| Step: 5
Training loss: 0.839031873886409
Validation loss: 2.469021496811172

Epoch: 6| Step: 6
Training loss: 0.5910021541494881
Validation loss: 2.4761707351492195

Epoch: 6| Step: 7
Training loss: 0.8060469024112175
Validation loss: 2.491506320337405

Epoch: 6| Step: 8
Training loss: 0.8466342795052285
Validation loss: 2.4920709874442366

Epoch: 6| Step: 9
Training loss: 0.551462685304001
Validation loss: 2.5328406113285125

Epoch: 6| Step: 10
Training loss: 0.9010394689867565
Validation loss: 2.540249995731034

Epoch: 6| Step: 11
Training loss: 0.8132891490600316
Validation loss: 2.5169089603738706

Epoch: 6| Step: 12
Training loss: 1.1829416222183315
Validation loss: 2.5026335616830777

Epoch: 6| Step: 13
Training loss: 0.598462402582582
Validation loss: 2.489720466438646

Epoch: 322| Step: 0
Training loss: 0.7402445206160759
Validation loss: 2.4748077910014685

Epoch: 6| Step: 1
Training loss: 0.7863781279703463
Validation loss: 2.4181426081180133

Epoch: 6| Step: 2
Training loss: 0.32450555272634224
Validation loss: 2.4081343650557523

Epoch: 6| Step: 3
Training loss: 0.9443130253691818
Validation loss: 2.4233798080727027

Epoch: 6| Step: 4
Training loss: 1.0865250788540317
Validation loss: 2.409195986471384

Epoch: 6| Step: 5
Training loss: 0.9291789162402834
Validation loss: 2.464791737009896

Epoch: 6| Step: 6
Training loss: 0.7167025303923311
Validation loss: 2.430931278102562

Epoch: 6| Step: 7
Training loss: 0.6465945423680545
Validation loss: 2.4524319810706805

Epoch: 6| Step: 8
Training loss: 1.1061087329559418
Validation loss: 2.5116338256039574

Epoch: 6| Step: 9
Training loss: 1.1917427963445637
Validation loss: 2.558933461261393

Epoch: 6| Step: 10
Training loss: 0.6355921133080233
Validation loss: 2.532702518538486

Epoch: 6| Step: 11
Training loss: 0.8166484199808062
Validation loss: 2.5671370155095423

Epoch: 6| Step: 12
Training loss: 0.5255832815227218
Validation loss: 2.5530913568204148

Epoch: 6| Step: 13
Training loss: 0.8828909509960491
Validation loss: 2.556585126861839

Epoch: 323| Step: 0
Training loss: 0.7276777506496872
Validation loss: 2.4866929450336386

Epoch: 6| Step: 1
Training loss: 0.5747667668880742
Validation loss: 2.4784666896474947

Epoch: 6| Step: 2
Training loss: 0.6421780021689082
Validation loss: 2.3921313911339763

Epoch: 6| Step: 3
Training loss: 0.9686063229242823
Validation loss: 2.4158735200732036

Epoch: 6| Step: 4
Training loss: 0.7415653632840558
Validation loss: 2.3804480882786665

Epoch: 6| Step: 5
Training loss: 0.8824320285545629
Validation loss: 2.3763450231421746

Epoch: 6| Step: 6
Training loss: 1.1960643822012862
Validation loss: 2.4241871953682077

Epoch: 6| Step: 7
Training loss: 1.0567224157129627
Validation loss: 2.435816565556342

Epoch: 6| Step: 8
Training loss: 0.9192370155461115
Validation loss: 2.499485707451016

Epoch: 6| Step: 9
Training loss: 0.7880015653047652
Validation loss: 2.506518774233073

Epoch: 6| Step: 10
Training loss: 0.594373099988915
Validation loss: 2.5224333674954313

Epoch: 6| Step: 11
Training loss: 0.8398656088180085
Validation loss: 2.584321655329184

Epoch: 6| Step: 12
Training loss: 0.4704852727841099
Validation loss: 2.594732233726163

Epoch: 6| Step: 13
Training loss: 0.9293597629429391
Validation loss: 2.5768830709798167

Epoch: 324| Step: 0
Training loss: 0.721560332838978
Validation loss: 2.516894255787122

Epoch: 6| Step: 1
Training loss: 0.9950173040543487
Validation loss: 2.4419762806895378

Epoch: 6| Step: 2
Training loss: 0.6707971488086794
Validation loss: 2.4337203331099886

Epoch: 6| Step: 3
Training loss: 0.5608005813493586
Validation loss: 2.393618833493717

Epoch: 6| Step: 4
Training loss: 0.8840867695017246
Validation loss: 2.373551262554282

Epoch: 6| Step: 5
Training loss: 0.5280792758266671
Validation loss: 2.4210840712725186

Epoch: 6| Step: 6
Training loss: 0.940418500823831
Validation loss: 2.421178436405038

Epoch: 6| Step: 7
Training loss: 1.3242098377569287
Validation loss: 2.475107773147274

Epoch: 6| Step: 8
Training loss: 0.5517498724712161
Validation loss: 2.50930599362495

Epoch: 6| Step: 9
Training loss: 0.9348725056549309
Validation loss: 2.5152446999737434

Epoch: 6| Step: 10
Training loss: 0.9274172913620666
Validation loss: 2.5359280835873546

Epoch: 6| Step: 11
Training loss: 0.96194987738687
Validation loss: 2.538260511734391

Epoch: 6| Step: 12
Training loss: 0.8797494192335592
Validation loss: 2.491839031903297

Epoch: 6| Step: 13
Training loss: 0.7587952681082714
Validation loss: 2.495683368406171

Epoch: 325| Step: 0
Training loss: 0.781219138489564
Validation loss: 2.4723059415113036

Epoch: 6| Step: 1
Training loss: 0.8041087912122702
Validation loss: 2.4446381456116604

Epoch: 6| Step: 2
Training loss: 0.8008817656165614
Validation loss: 2.4068393781867865

Epoch: 6| Step: 3
Training loss: 0.8693268994230279
Validation loss: 2.3955270158534345

Epoch: 6| Step: 4
Training loss: 0.7871974015531259
Validation loss: 2.386957931208398

Epoch: 6| Step: 5
Training loss: 0.9298672862880999
Validation loss: 2.3986673472439763

Epoch: 6| Step: 6
Training loss: 1.0613142577758201
Validation loss: 2.404741717722306

Epoch: 6| Step: 7
Training loss: 0.9179275178780173
Validation loss: 2.3937192437829515

Epoch: 6| Step: 8
Training loss: 0.6650787207252274
Validation loss: 2.4533997044802294

Epoch: 6| Step: 9
Training loss: 0.6978425062452991
Validation loss: 2.5194821161438212

Epoch: 6| Step: 10
Training loss: 0.9055807338976959
Validation loss: 2.552402258595103

Epoch: 6| Step: 11
Training loss: 1.054347230628105
Validation loss: 2.5225127776834846

Epoch: 6| Step: 12
Training loss: 0.38492166675943695
Validation loss: 2.5536412245343136

Epoch: 6| Step: 13
Training loss: 0.6291296662783443
Validation loss: 2.5089657436765362

Epoch: 326| Step: 0
Training loss: 0.6702271147011356
Validation loss: 2.448505838812107

Epoch: 6| Step: 1
Training loss: 1.007510531822419
Validation loss: 2.4768110948673776

Epoch: 6| Step: 2
Training loss: 1.210933463797457
Validation loss: 2.416298216722806

Epoch: 6| Step: 3
Training loss: 0.8204407364656555
Validation loss: 2.3932910733407113

Epoch: 6| Step: 4
Training loss: 0.8367544442620969
Validation loss: 2.3895446858615212

Epoch: 6| Step: 5
Training loss: 0.5336925510069636
Validation loss: 2.394749026261982

Epoch: 6| Step: 6
Training loss: 0.9842988847641932
Validation loss: 2.4509952146985556

Epoch: 6| Step: 7
Training loss: 0.7132429532553036
Validation loss: 2.42794366240896

Epoch: 6| Step: 8
Training loss: 0.32022530834413365
Validation loss: 2.4543327377168045

Epoch: 6| Step: 9
Training loss: 0.9940906204808017
Validation loss: 2.511107115491749

Epoch: 6| Step: 10
Training loss: 0.724058821219762
Validation loss: 2.5013656536815247

Epoch: 6| Step: 11
Training loss: 0.5672892297988239
Validation loss: 2.478202543080103

Epoch: 6| Step: 12
Training loss: 0.7843552484343175
Validation loss: 2.4694801726383293

Epoch: 6| Step: 13
Training loss: 0.8404952959590535
Validation loss: 2.4037693630854933

Epoch: 327| Step: 0
Training loss: 0.5716511939858512
Validation loss: 2.410265064905993

Epoch: 6| Step: 1
Training loss: 0.6172285187043667
Validation loss: 2.372392416253988

Epoch: 6| Step: 2
Training loss: 1.0388402486034753
Validation loss: 2.339136238044753

Epoch: 6| Step: 3
Training loss: 0.7091923348263779
Validation loss: 2.3222831201664933

Epoch: 6| Step: 4
Training loss: 0.6460574028003745
Validation loss: 2.3252789552872914

Epoch: 6| Step: 5
Training loss: 1.0043689537222418
Validation loss: 2.368917732773226

Epoch: 6| Step: 6
Training loss: 0.6795974540256928
Validation loss: 2.38186850485983

Epoch: 6| Step: 7
Training loss: 0.8310826584874982
Validation loss: 2.4267981489012547

Epoch: 6| Step: 8
Training loss: 1.2103717589897833
Validation loss: 2.443894719473243

Epoch: 6| Step: 9
Training loss: 0.9546059219294152
Validation loss: 2.505710597422009

Epoch: 6| Step: 10
Training loss: 0.757561199561316
Validation loss: 2.518480939455397

Epoch: 6| Step: 11
Training loss: 0.3528121883536247
Validation loss: 2.5340216221655827

Epoch: 6| Step: 12
Training loss: 0.8674900111522049
Validation loss: 2.5394226040988426

Epoch: 6| Step: 13
Training loss: 0.9255876298427304
Validation loss: 2.566862311442457

Epoch: 328| Step: 0
Training loss: 1.0437191895831472
Validation loss: 2.5282723507629354

Epoch: 6| Step: 1
Training loss: 0.6299070368403858
Validation loss: 2.4205528400144156

Epoch: 6| Step: 2
Training loss: 0.8625125137748159
Validation loss: 2.3991400464114987

Epoch: 6| Step: 3
Training loss: 0.5544001412523594
Validation loss: 2.400392800534912

Epoch: 6| Step: 4
Training loss: 0.829990840137448
Validation loss: 2.3946018554864406

Epoch: 6| Step: 5
Training loss: 0.7309266149681588
Validation loss: 2.384510922801042

Epoch: 6| Step: 6
Training loss: 0.8034488069739456
Validation loss: 2.389628070636705

Epoch: 6| Step: 7
Training loss: 0.982171392645525
Validation loss: 2.441003132671888

Epoch: 6| Step: 8
Training loss: 1.1063977439196762
Validation loss: 2.4697443023023635

Epoch: 6| Step: 9
Training loss: 0.6696978491954947
Validation loss: 2.512084868930966

Epoch: 6| Step: 10
Training loss: 0.7156766614632075
Validation loss: 2.509753302768192

Epoch: 6| Step: 11
Training loss: 0.9567927783546014
Validation loss: 2.479856170984996

Epoch: 6| Step: 12
Training loss: 0.7309305699718368
Validation loss: 2.4226719545659323

Epoch: 6| Step: 13
Training loss: 0.5550001096295772
Validation loss: 2.4302159876045524

Epoch: 329| Step: 0
Training loss: 0.8615137017079826
Validation loss: 2.448225083533478

Epoch: 6| Step: 1
Training loss: 0.9527588125225214
Validation loss: 2.4485699000440126

Epoch: 6| Step: 2
Training loss: 0.3084259301192532
Validation loss: 2.4246593547739903

Epoch: 6| Step: 3
Training loss: 1.1834929772713785
Validation loss: 2.4640640360224464

Epoch: 6| Step: 4
Training loss: 0.8333888909575602
Validation loss: 2.4579416390190216

Epoch: 6| Step: 5
Training loss: 0.719603529291261
Validation loss: 2.4776755674760516

Epoch: 6| Step: 6
Training loss: 0.5240020269853393
Validation loss: 2.478923618863164

Epoch: 6| Step: 7
Training loss: 1.1039954298622796
Validation loss: 2.5033923329084233

Epoch: 6| Step: 8
Training loss: 0.744979345688197
Validation loss: 2.4918440730902462

Epoch: 6| Step: 9
Training loss: 0.5393224172499288
Validation loss: 2.498253983755218

Epoch: 6| Step: 10
Training loss: 0.8007770073010702
Validation loss: 2.500202862907378

Epoch: 6| Step: 11
Training loss: 0.5705967025174857
Validation loss: 2.4793717194493787

Epoch: 6| Step: 12
Training loss: 0.9139270519094251
Validation loss: 2.4509462528662116

Epoch: 6| Step: 13
Training loss: 0.24796486798031836
Validation loss: 2.5016558188419333

Epoch: 330| Step: 0
Training loss: 0.9522465268985849
Validation loss: 2.473678064883561

Epoch: 6| Step: 1
Training loss: 0.9618297249472878
Validation loss: 2.4725017086214636

Epoch: 6| Step: 2
Training loss: 0.8372324601617404
Validation loss: 2.4590703138673917

Epoch: 6| Step: 3
Training loss: 0.5573095217782734
Validation loss: 2.4258535002268657

Epoch: 6| Step: 4
Training loss: 0.6314059272657673
Validation loss: 2.415727335914938

Epoch: 6| Step: 5
Training loss: 0.7120300951930131
Validation loss: 2.4536419332895836

Epoch: 6| Step: 6
Training loss: 0.9129647730437619
Validation loss: 2.404716579487416

Epoch: 6| Step: 7
Training loss: 0.654799538723941
Validation loss: 2.412322749474616

Epoch: 6| Step: 8
Training loss: 0.8965218396970609
Validation loss: 2.4425351493663214

Epoch: 6| Step: 9
Training loss: 0.7504095707596181
Validation loss: 2.4697927399294497

Epoch: 6| Step: 10
Training loss: 0.7190473190356315
Validation loss: 2.4778730664878514

Epoch: 6| Step: 11
Training loss: 0.7289322794266366
Validation loss: 2.4702766747896967

Epoch: 6| Step: 12
Training loss: 0.5759679918502033
Validation loss: 2.5151118618383164

Epoch: 6| Step: 13
Training loss: 0.7494790334129259
Validation loss: 2.482890915784774

Epoch: 331| Step: 0
Training loss: 0.671620586930996
Validation loss: 2.5150181756820174

Epoch: 6| Step: 1
Training loss: 0.8477721244964606
Validation loss: 2.4763944731956635

Epoch: 6| Step: 2
Training loss: 0.6931595850262744
Validation loss: 2.445366768246424

Epoch: 6| Step: 3
Training loss: 0.7708720420878387
Validation loss: 2.4895644568003426

Epoch: 6| Step: 4
Training loss: 0.5546473099023902
Validation loss: 2.472343564632239

Epoch: 6| Step: 5
Training loss: 0.9982232163846466
Validation loss: 2.4190801556842882

Epoch: 6| Step: 6
Training loss: 0.8978969108609124
Validation loss: 2.4116609365509123

Epoch: 6| Step: 7
Training loss: 0.7659529937086003
Validation loss: 2.4216825998277542

Epoch: 6| Step: 8
Training loss: 0.7730989967728504
Validation loss: 2.39497039648519

Epoch: 6| Step: 9
Training loss: 0.7146605793728686
Validation loss: 2.387720484990626

Epoch: 6| Step: 10
Training loss: 0.509862488645746
Validation loss: 2.3830284651522464

Epoch: 6| Step: 11
Training loss: 0.49670254155605664
Validation loss: 2.44567841622028

Epoch: 6| Step: 12
Training loss: 0.8800312556329808
Validation loss: 2.4365663120611614

Epoch: 6| Step: 13
Training loss: 1.2472073831409431
Validation loss: 2.463477859307264

Epoch: 332| Step: 0
Training loss: 0.9856979623226851
Validation loss: 2.446851606954846

Epoch: 6| Step: 1
Training loss: 0.8718617222913181
Validation loss: 2.4546961625796206

Epoch: 6| Step: 2
Training loss: 0.7375941232651966
Validation loss: 2.4243003056948047

Epoch: 6| Step: 3
Training loss: 0.6041471763185577
Validation loss: 2.4283527609054

Epoch: 6| Step: 4
Training loss: 0.9774180822365167
Validation loss: 2.431496642396122

Epoch: 6| Step: 5
Training loss: 0.8519312209051227
Validation loss: 2.4249654285151565

Epoch: 6| Step: 6
Training loss: 0.5218636779927559
Validation loss: 2.4461727139636773

Epoch: 6| Step: 7
Training loss: 0.6193825041684918
Validation loss: 2.4140612436996096

Epoch: 6| Step: 8
Training loss: 0.8959161291377775
Validation loss: 2.4204228917501487

Epoch: 6| Step: 9
Training loss: 0.8957176503443978
Validation loss: 2.4587595036478636

Epoch: 6| Step: 10
Training loss: 0.6686887820023234
Validation loss: 2.4333043559514134

Epoch: 6| Step: 11
Training loss: 0.46712326067446797
Validation loss: 2.471407903880189

Epoch: 6| Step: 12
Training loss: 0.6820467637996999
Validation loss: 2.475578349872587

Epoch: 6| Step: 13
Training loss: 0.36555409844393777
Validation loss: 2.4689801961489777

Epoch: 333| Step: 0
Training loss: 0.5163377979057635
Validation loss: 2.464098516579942

Epoch: 6| Step: 1
Training loss: 0.8483206961864045
Validation loss: 2.496384816506302

Epoch: 6| Step: 2
Training loss: 0.6401981699623329
Validation loss: 2.5141092140147068

Epoch: 6| Step: 3
Training loss: 0.9739961395813813
Validation loss: 2.4863278445421293

Epoch: 6| Step: 4
Training loss: 0.6914612053189616
Validation loss: 2.491806724854536

Epoch: 6| Step: 5
Training loss: 1.0438828480859115
Validation loss: 2.5125991027907224

Epoch: 6| Step: 6
Training loss: 0.7570009113291164
Validation loss: 2.5367903556009903

Epoch: 6| Step: 7
Training loss: 0.921534459207156
Validation loss: 2.494244600659984

Epoch: 6| Step: 8
Training loss: 0.7678785828039985
Validation loss: 2.434688248975548

Epoch: 6| Step: 9
Training loss: 0.6458533396749789
Validation loss: 2.4402819508842915

Epoch: 6| Step: 10
Training loss: 0.3407268669325258
Validation loss: 2.425485931270585

Epoch: 6| Step: 11
Training loss: 0.7737128027878399
Validation loss: 2.4264583236213726

Epoch: 6| Step: 12
Training loss: 0.7495185578372829
Validation loss: 2.3984368191236727

Epoch: 6| Step: 13
Training loss: 0.4326500460371731
Validation loss: 2.3823612732006207

Epoch: 334| Step: 0
Training loss: 0.5731240041842696
Validation loss: 2.421739315237345

Epoch: 6| Step: 1
Training loss: 0.7748926134466084
Validation loss: 2.408126161423649

Epoch: 6| Step: 2
Training loss: 0.39408804294167515
Validation loss: 2.452161049983248

Epoch: 6| Step: 3
Training loss: 0.7426068777490675
Validation loss: 2.525366505519255

Epoch: 6| Step: 4
Training loss: 0.8362078719653812
Validation loss: 2.5014464101140828

Epoch: 6| Step: 5
Training loss: 0.7864474786341968
Validation loss: 2.507079843319573

Epoch: 6| Step: 6
Training loss: 0.7635462821068074
Validation loss: 2.4744034772214034

Epoch: 6| Step: 7
Training loss: 0.6598879477720495
Validation loss: 2.4951151911385576

Epoch: 6| Step: 8
Training loss: 0.628485023222979
Validation loss: 2.5078478781829006

Epoch: 6| Step: 9
Training loss: 0.9883237384815013
Validation loss: 2.510830957656446

Epoch: 6| Step: 10
Training loss: 0.8737234954197562
Validation loss: 2.491887165563141

Epoch: 6| Step: 11
Training loss: 0.6959773324873425
Validation loss: 2.4985775602798364

Epoch: 6| Step: 12
Training loss: 0.8258790563660146
Validation loss: 2.504364426344538

Epoch: 6| Step: 13
Training loss: 1.1171494590845041
Validation loss: 2.502522479857199

Epoch: 335| Step: 0
Training loss: 0.8475853675000503
Validation loss: 2.4600299412462356

Epoch: 6| Step: 1
Training loss: 0.6449180829348525
Validation loss: 2.431054990194697

Epoch: 6| Step: 2
Training loss: 0.5672490656623526
Validation loss: 2.423802901256054

Epoch: 6| Step: 3
Training loss: 0.38218021725868767
Validation loss: 2.4707346257777

Epoch: 6| Step: 4
Training loss: 0.9446629586219923
Validation loss: 2.4508493513682104

Epoch: 6| Step: 5
Training loss: 0.5371669669052328
Validation loss: 2.4889802985430918

Epoch: 6| Step: 6
Training loss: 0.7789293153766386
Validation loss: 2.507647069090691

Epoch: 6| Step: 7
Training loss: 1.033578036672532
Validation loss: 2.547342755342438

Epoch: 6| Step: 8
Training loss: 0.6766424920276887
Validation loss: 2.500744294561908

Epoch: 6| Step: 9
Training loss: 0.8564922880993555
Validation loss: 2.5267011838035747

Epoch: 6| Step: 10
Training loss: 0.7443275116859227
Validation loss: 2.505841924631071

Epoch: 6| Step: 11
Training loss: 0.8445271339280911
Validation loss: 2.4784288253718327

Epoch: 6| Step: 12
Training loss: 0.7343271118133696
Validation loss: 2.443466014090274

Epoch: 6| Step: 13
Training loss: 0.8154271291361438
Validation loss: 2.431594272947136

Epoch: 336| Step: 0
Training loss: 0.8623662388781332
Validation loss: 2.4152833531838764

Epoch: 6| Step: 1
Training loss: 0.8063033832945081
Validation loss: 2.4443387231341442

Epoch: 6| Step: 2
Training loss: 0.31776971562790324
Validation loss: 2.4340547014387464

Epoch: 6| Step: 3
Training loss: 0.6485309073951341
Validation loss: 2.448992756360663

Epoch: 6| Step: 4
Training loss: 0.9475978937130469
Validation loss: 2.4867888663170925

Epoch: 6| Step: 5
Training loss: 0.7379844512981413
Validation loss: 2.509607039412521

Epoch: 6| Step: 6
Training loss: 0.9382117113045618
Validation loss: 2.4644847893409443

Epoch: 6| Step: 7
Training loss: 0.9052908195135461
Validation loss: 2.4080270843371987

Epoch: 6| Step: 8
Training loss: 0.6947754489620644
Validation loss: 2.4133142855034224

Epoch: 6| Step: 9
Training loss: 0.9385828122777632
Validation loss: 2.356323265681142

Epoch: 6| Step: 10
Training loss: 1.018957100628752
Validation loss: 2.352114942489349

Epoch: 6| Step: 11
Training loss: 0.8255640413707582
Validation loss: 2.3552412592816627

Epoch: 6| Step: 12
Training loss: 0.5393952987139997
Validation loss: 2.423098573880076

Epoch: 6| Step: 13
Training loss: 0.4998488942937211
Validation loss: 2.5008627746128154

Epoch: 337| Step: 0
Training loss: 0.7115094326168764
Validation loss: 2.583743429695875

Epoch: 6| Step: 1
Training loss: 0.6931141164353436
Validation loss: 2.6381313264918376

Epoch: 6| Step: 2
Training loss: 0.6066673965589443
Validation loss: 2.6498187874029897

Epoch: 6| Step: 3
Training loss: 0.8078347297133281
Validation loss: 2.683175067046901

Epoch: 6| Step: 4
Training loss: 0.7980016709575511
Validation loss: 2.6103385338558773

Epoch: 6| Step: 5
Training loss: 0.6493623641237721
Validation loss: 2.5569187037111765

Epoch: 6| Step: 6
Training loss: 1.1772513086875112
Validation loss: 2.523664576975243

Epoch: 6| Step: 7
Training loss: 0.6470806679442517
Validation loss: 2.4887069389791225

Epoch: 6| Step: 8
Training loss: 0.6411447045207578
Validation loss: 2.46943148180055

Epoch: 6| Step: 9
Training loss: 1.0214961618359757
Validation loss: 2.428773168595697

Epoch: 6| Step: 10
Training loss: 0.8778167074828521
Validation loss: 2.40178273411085

Epoch: 6| Step: 11
Training loss: 0.873099886588357
Validation loss: 2.4029306626719427

Epoch: 6| Step: 12
Training loss: 0.28987840255099095
Validation loss: 2.3846652139722013

Epoch: 6| Step: 13
Training loss: 0.5433237027073404
Validation loss: 2.4349851937463023

Epoch: 338| Step: 0
Training loss: 0.9957157988731269
Validation loss: 2.4252110031399647

Epoch: 6| Step: 1
Training loss: 0.5996836762259165
Validation loss: 2.471084182850056

Epoch: 6| Step: 2
Training loss: 0.2904174083789638
Validation loss: 2.4909891786280864

Epoch: 6| Step: 3
Training loss: 0.9136108195375703
Validation loss: 2.4734645685388372

Epoch: 6| Step: 4
Training loss: 0.7088498494962522
Validation loss: 2.496391955278449

Epoch: 6| Step: 5
Training loss: 0.8447463898729785
Validation loss: 2.4520710523687796

Epoch: 6| Step: 6
Training loss: 0.6552694806634679
Validation loss: 2.484895515050262

Epoch: 6| Step: 7
Training loss: 0.7215111810633388
Validation loss: 2.4845802158909853

Epoch: 6| Step: 8
Training loss: 0.593429177593995
Validation loss: 2.4872747952423855

Epoch: 6| Step: 9
Training loss: 0.5063697567331419
Validation loss: 2.4602685298084683

Epoch: 6| Step: 10
Training loss: 1.162096808870479
Validation loss: 2.4618759977902367

Epoch: 6| Step: 11
Training loss: 0.7791913183327863
Validation loss: 2.450613301109347

Epoch: 6| Step: 12
Training loss: 0.4379170507646516
Validation loss: 2.4541127693197837

Epoch: 6| Step: 13
Training loss: 0.8096566332547063
Validation loss: 2.453065839474328

Epoch: 339| Step: 0
Training loss: 0.6839646995063019
Validation loss: 2.466523316493567

Epoch: 6| Step: 1
Training loss: 0.7518275961197899
Validation loss: 2.4571399093112234

Epoch: 6| Step: 2
Training loss: 0.9404588102622551
Validation loss: 2.415936112085057

Epoch: 6| Step: 3
Training loss: 0.7016911615942305
Validation loss: 2.4371667060342452

Epoch: 6| Step: 4
Training loss: 0.4778384964671415
Validation loss: 2.4576681880414504

Epoch: 6| Step: 5
Training loss: 0.845851118780854
Validation loss: 2.4425241077399806

Epoch: 6| Step: 6
Training loss: 0.6748257756560969
Validation loss: 2.4562001383769845

Epoch: 6| Step: 7
Training loss: 0.6393368260462561
Validation loss: 2.454359627077952

Epoch: 6| Step: 8
Training loss: 0.5551083002874891
Validation loss: 2.4947497622758856

Epoch: 6| Step: 9
Training loss: 1.097002533891476
Validation loss: 2.464290386922385

Epoch: 6| Step: 10
Training loss: 0.6474132951840241
Validation loss: 2.509428843399959

Epoch: 6| Step: 11
Training loss: 0.6756418999561784
Validation loss: 2.498611416293866

Epoch: 6| Step: 12
Training loss: 0.5991953560491319
Validation loss: 2.4952670590293358

Epoch: 6| Step: 13
Training loss: 0.7840493974012783
Validation loss: 2.4973301782912602

Epoch: 340| Step: 0
Training loss: 0.4015169258825487
Validation loss: 2.532487686940856

Epoch: 6| Step: 1
Training loss: 0.8069772826002437
Validation loss: 2.519182048947649

Epoch: 6| Step: 2
Training loss: 0.6465671636119152
Validation loss: 2.49014895056774

Epoch: 6| Step: 3
Training loss: 0.6203889746812737
Validation loss: 2.4810005499643046

Epoch: 6| Step: 4
Training loss: 0.8018402168775598
Validation loss: 2.50948013399883

Epoch: 6| Step: 5
Training loss: 0.9980241806525714
Validation loss: 2.487289952708856

Epoch: 6| Step: 6
Training loss: 0.8278609520631637
Validation loss: 2.4797180765882216

Epoch: 6| Step: 7
Training loss: 0.464505304817483
Validation loss: 2.4986606599333654

Epoch: 6| Step: 8
Training loss: 0.8033697208167577
Validation loss: 2.4979662334220682

Epoch: 6| Step: 9
Training loss: 0.7163227394543092
Validation loss: 2.456810074857255

Epoch: 6| Step: 10
Training loss: 0.9145435469423231
Validation loss: 2.4795972560984287

Epoch: 6| Step: 11
Training loss: 0.6129580818626779
Validation loss: 2.4603534745768574

Epoch: 6| Step: 12
Training loss: 0.7410371398215542
Validation loss: 2.4812911883458533

Epoch: 6| Step: 13
Training loss: 0.5858022915288374
Validation loss: 2.4849659908246413

Epoch: 341| Step: 0
Training loss: 0.6232467139548027
Validation loss: 2.455269241070019

Epoch: 6| Step: 1
Training loss: 1.001966866739191
Validation loss: 2.4585223395547904

Epoch: 6| Step: 2
Training loss: 0.2110540103566125
Validation loss: 2.476390397487372

Epoch: 6| Step: 3
Training loss: 0.8432743003096586
Validation loss: 2.459084111638212

Epoch: 6| Step: 4
Training loss: 0.7536777683777767
Validation loss: 2.4641448798742314

Epoch: 6| Step: 5
Training loss: 0.974283871160529
Validation loss: 2.47008467318842

Epoch: 6| Step: 6
Training loss: 0.6890908388983942
Validation loss: 2.444893693224881

Epoch: 6| Step: 7
Training loss: 0.6775334744787941
Validation loss: 2.487228998642187

Epoch: 6| Step: 8
Training loss: 0.49480146766458805
Validation loss: 2.496912263554727

Epoch: 6| Step: 9
Training loss: 0.504026945578358
Validation loss: 2.4847803438496014

Epoch: 6| Step: 10
Training loss: 0.6024856420048709
Validation loss: 2.4786679876334

Epoch: 6| Step: 11
Training loss: 0.6132954152409054
Validation loss: 2.497003061298979

Epoch: 6| Step: 12
Training loss: 0.9130662232580995
Validation loss: 2.5043856003398233

Epoch: 6| Step: 13
Training loss: 0.5496225817733221
Validation loss: 2.4765526328267637

Epoch: 342| Step: 0
Training loss: 0.7371451704251945
Validation loss: 2.4784095444278598

Epoch: 6| Step: 1
Training loss: 0.7145920190385234
Validation loss: 2.4320144391687726

Epoch: 6| Step: 2
Training loss: 0.3200551138667915
Validation loss: 2.4309300178648168

Epoch: 6| Step: 3
Training loss: 0.5853213822097689
Validation loss: 2.4472655186733605

Epoch: 6| Step: 4
Training loss: 1.2094815268901586
Validation loss: 2.4311316328313683

Epoch: 6| Step: 5
Training loss: 0.8560696934110018
Validation loss: 2.416475197912587

Epoch: 6| Step: 6
Training loss: 0.8040928170944945
Validation loss: 2.400249833687357

Epoch: 6| Step: 7
Training loss: 0.49996395279167083
Validation loss: 2.369326717864309

Epoch: 6| Step: 8
Training loss: 0.6954416305132719
Validation loss: 2.3792188873976383

Epoch: 6| Step: 9
Training loss: 0.4166540163821882
Validation loss: 2.3695168544194773

Epoch: 6| Step: 10
Training loss: 0.7291240452616782
Validation loss: 2.3707191041695106

Epoch: 6| Step: 11
Training loss: 0.589241023041001
Validation loss: 2.4485048498991824

Epoch: 6| Step: 12
Training loss: 0.7709923442727662
Validation loss: 2.434167603376997

Epoch: 6| Step: 13
Training loss: 0.28601196653500477
Validation loss: 2.4826303672706427

Epoch: 343| Step: 0
Training loss: 0.897131792051009
Validation loss: 2.4759976973626547

Epoch: 6| Step: 1
Training loss: 0.44804796985336137
Validation loss: 2.5166650052979556

Epoch: 6| Step: 2
Training loss: 0.6285343847800211
Validation loss: 2.5181632566447596

Epoch: 6| Step: 3
Training loss: 0.798218510824733
Validation loss: 2.5200098866257212

Epoch: 6| Step: 4
Training loss: 0.6550023616864674
Validation loss: 2.5146701034534855

Epoch: 6| Step: 5
Training loss: 0.8747712244956898
Validation loss: 2.488708058707886

Epoch: 6| Step: 6
Training loss: 0.2969450115168309
Validation loss: 2.4550309341754364

Epoch: 6| Step: 7
Training loss: 0.7346822623419488
Validation loss: 2.483758503308579

Epoch: 6| Step: 8
Training loss: 0.736817215197949
Validation loss: 2.4212903045046357

Epoch: 6| Step: 9
Training loss: 0.2581324326181715
Validation loss: 2.4551625612312624

Epoch: 6| Step: 10
Training loss: 0.7254268014788908
Validation loss: 2.4269645697421773

Epoch: 6| Step: 11
Training loss: 0.7443122966118071
Validation loss: 2.3934531595712385

Epoch: 6| Step: 12
Training loss: 0.7386799295955581
Validation loss: 2.395744013536912

Epoch: 6| Step: 13
Training loss: 0.9591657851541303
Validation loss: 2.3772759361896605

Epoch: 344| Step: 0
Training loss: 0.6177623582558647
Validation loss: 2.386226746670333

Epoch: 6| Step: 1
Training loss: 0.6119553148748399
Validation loss: 2.413625355610142

Epoch: 6| Step: 2
Training loss: 0.768107845403502
Validation loss: 2.403322967534364

Epoch: 6| Step: 3
Training loss: 0.49693157005970007
Validation loss: 2.4162141724959176

Epoch: 6| Step: 4
Training loss: 0.861807899325047
Validation loss: 2.4345238867034498

Epoch: 6| Step: 5
Training loss: 0.6757423301470378
Validation loss: 2.445097294898655

Epoch: 6| Step: 6
Training loss: 0.6373669420022096
Validation loss: 2.500959279486263

Epoch: 6| Step: 7
Training loss: 0.47987844288955483
Validation loss: 2.4853881949281584

Epoch: 6| Step: 8
Training loss: 0.35599022646410805
Validation loss: 2.514165580435733

Epoch: 6| Step: 9
Training loss: 0.8439098136161285
Validation loss: 2.521640992621094

Epoch: 6| Step: 10
Training loss: 0.8879351905550527
Validation loss: 2.55757381322226

Epoch: 6| Step: 11
Training loss: 0.7127130992841189
Validation loss: 2.5542042156477853

Epoch: 6| Step: 12
Training loss: 0.8088533657354126
Validation loss: 2.5330345257157996

Epoch: 6| Step: 13
Training loss: 0.6319123919070466
Validation loss: 2.511344195721626

Epoch: 345| Step: 0
Training loss: 0.5524158705874764
Validation loss: 2.460357036064034

Epoch: 6| Step: 1
Training loss: 0.6299916491257769
Validation loss: 2.447031520259364

Epoch: 6| Step: 2
Training loss: 0.5346708950850997
Validation loss: 2.435230481705386

Epoch: 6| Step: 3
Training loss: 0.9141736737321493
Validation loss: 2.4101089433274208

Epoch: 6| Step: 4
Training loss: 0.9490504488464069
Validation loss: 2.3963263344606665

Epoch: 6| Step: 5
Training loss: 0.51294813915889
Validation loss: 2.3821332550085477

Epoch: 6| Step: 6
Training loss: 0.5372113495171037
Validation loss: 2.4039374432263987

Epoch: 6| Step: 7
Training loss: 0.4124191349413278
Validation loss: 2.4300886037484344

Epoch: 6| Step: 8
Training loss: 0.4784164637370439
Validation loss: 2.4308239889288186

Epoch: 6| Step: 9
Training loss: 0.6947821834284957
Validation loss: 2.4643318681321063

Epoch: 6| Step: 10
Training loss: 0.8114961511681669
Validation loss: 2.4291209336593043

Epoch: 6| Step: 11
Training loss: 0.6052471862989128
Validation loss: 2.4663838654350507

Epoch: 6| Step: 12
Training loss: 1.0765257321129138
Validation loss: 2.4435743019649143

Epoch: 6| Step: 13
Training loss: 0.2574064640879276
Validation loss: 2.430653250665075

Epoch: 346| Step: 0
Training loss: 0.8551815717988337
Validation loss: 2.4495010858283806

Epoch: 6| Step: 1
Training loss: 0.4461980514048232
Validation loss: 2.436150868739815

Epoch: 6| Step: 2
Training loss: 0.5772573300569883
Validation loss: 2.4360489782018293

Epoch: 6| Step: 3
Training loss: 0.4540524856135143
Validation loss: 2.4209990897922182

Epoch: 6| Step: 4
Training loss: 0.6704526972488063
Validation loss: 2.376856873002529

Epoch: 6| Step: 5
Training loss: 0.6004293594324711
Validation loss: 2.4190788055516466

Epoch: 6| Step: 6
Training loss: 0.8468314522107508
Validation loss: 2.4010029276865663

Epoch: 6| Step: 7
Training loss: 0.6847272793641332
Validation loss: 2.439715305083446

Epoch: 6| Step: 8
Training loss: 0.793138307380112
Validation loss: 2.451624477023993

Epoch: 6| Step: 9
Training loss: 0.6247837169260604
Validation loss: 2.4538242087433373

Epoch: 6| Step: 10
Training loss: 0.8088802254027146
Validation loss: 2.4514486305257304

Epoch: 6| Step: 11
Training loss: 0.504481851824112
Validation loss: 2.434506574734514

Epoch: 6| Step: 12
Training loss: 0.80251637860991
Validation loss: 2.4778092683015163

Epoch: 6| Step: 13
Training loss: 0.3193292412945317
Validation loss: 2.4832945125320696

Epoch: 347| Step: 0
Training loss: 0.9186504348989716
Validation loss: 2.4803684334804776

Epoch: 6| Step: 1
Training loss: 0.50683520249036
Validation loss: 2.4512539158797395

Epoch: 6| Step: 2
Training loss: 0.5160976324533058
Validation loss: 2.4477777452568654

Epoch: 6| Step: 3
Training loss: 0.3254154708736948
Validation loss: 2.443650249804396

Epoch: 6| Step: 4
Training loss: 0.786844327236403
Validation loss: 2.4676695074343513

Epoch: 6| Step: 5
Training loss: 0.21647312287872447
Validation loss: 2.45415844326674

Epoch: 6| Step: 6
Training loss: 0.6673304759719274
Validation loss: 2.452406027076036

Epoch: 6| Step: 7
Training loss: 0.48557656980691977
Validation loss: 2.450408394891592

Epoch: 6| Step: 8
Training loss: 0.7871280412377423
Validation loss: 2.4169082580956407

Epoch: 6| Step: 9
Training loss: 1.0181702631752967
Validation loss: 2.4455085955425617

Epoch: 6| Step: 10
Training loss: 0.6945648030778633
Validation loss: 2.4201711768433385

Epoch: 6| Step: 11
Training loss: 0.622976221365577
Validation loss: 2.4499784497955464

Epoch: 6| Step: 12
Training loss: 0.8016042062717568
Validation loss: 2.416524227479264

Epoch: 6| Step: 13
Training loss: 0.5055896231272269
Validation loss: 2.4303658550748084

Epoch: 348| Step: 0
Training loss: 0.6090933564591767
Validation loss: 2.441571676183114

Epoch: 6| Step: 1
Training loss: 0.4315862837196664
Validation loss: 2.4813229152845153

Epoch: 6| Step: 2
Training loss: 0.7249916076174417
Validation loss: 2.456159567768372

Epoch: 6| Step: 3
Training loss: 0.6276861641108157
Validation loss: 2.5346630132411416

Epoch: 6| Step: 4
Training loss: 0.7099898593473918
Validation loss: 2.5079347186290577

Epoch: 6| Step: 5
Training loss: 0.39985833490625566
Validation loss: 2.52808637274267

Epoch: 6| Step: 6
Training loss: 0.5459613252014492
Validation loss: 2.5121538237098675

Epoch: 6| Step: 7
Training loss: 0.7084179341525849
Validation loss: 2.55331381256529

Epoch: 6| Step: 8
Training loss: 0.8649044053500837
Validation loss: 2.557671781190291

Epoch: 6| Step: 9
Training loss: 0.5138288192895134
Validation loss: 2.502255921139307

Epoch: 6| Step: 10
Training loss: 0.5677488528382417
Validation loss: 2.4669794203091167

Epoch: 6| Step: 11
Training loss: 0.9159700427070802
Validation loss: 2.460196531660384

Epoch: 6| Step: 12
Training loss: 0.795510451408222
Validation loss: 2.4330485241171225

Epoch: 6| Step: 13
Training loss: 0.7724472797020703
Validation loss: 2.388553662777101

Epoch: 349| Step: 0
Training loss: 0.659177562568913
Validation loss: 2.386527789315182

Epoch: 6| Step: 1
Training loss: 0.7739388738541607
Validation loss: 2.393839103432416

Epoch: 6| Step: 2
Training loss: 1.0233876456428397
Validation loss: 2.3773570149550673

Epoch: 6| Step: 3
Training loss: 0.6757295180789729
Validation loss: 2.3854179642043234

Epoch: 6| Step: 4
Training loss: 0.37189038749723463
Validation loss: 2.413080304696666

Epoch: 6| Step: 5
Training loss: 0.9328039491603379
Validation loss: 2.4299609958818924

Epoch: 6| Step: 6
Training loss: 0.30432729948483883
Validation loss: 2.4569403064871116

Epoch: 6| Step: 7
Training loss: 0.6140401724524769
Validation loss: 2.4849452915071732

Epoch: 6| Step: 8
Training loss: 0.5028351630111312
Validation loss: 2.4892704166731505

Epoch: 6| Step: 9
Training loss: 0.6017952010671112
Validation loss: 2.4955414751576

Epoch: 6| Step: 10
Training loss: 0.6925553939368023
Validation loss: 2.5198537444784184

Epoch: 6| Step: 11
Training loss: 0.6560190339321849
Validation loss: 2.5162121716730335

Epoch: 6| Step: 12
Training loss: 0.5825804864754479
Validation loss: 2.4818370401240335

Epoch: 6| Step: 13
Training loss: 0.48202708534655025
Validation loss: 2.4611759214186293

Epoch: 350| Step: 0
Training loss: 0.2996561011491947
Validation loss: 2.483790218857649

Epoch: 6| Step: 1
Training loss: 0.7095704401815706
Validation loss: 2.4451304812274355

Epoch: 6| Step: 2
Training loss: 0.540120179083969
Validation loss: 2.4879303181799344

Epoch: 6| Step: 3
Training loss: 0.7805597689444366
Validation loss: 2.4674791216821794

Epoch: 6| Step: 4
Training loss: 0.6705092588165179
Validation loss: 2.41422482380303

Epoch: 6| Step: 5
Training loss: 0.4997633284479794
Validation loss: 2.4891398501645803

Epoch: 6| Step: 6
Training loss: 0.6700438452366306
Validation loss: 2.461178490082841

Epoch: 6| Step: 7
Training loss: 0.33287271572766053
Validation loss: 2.479101811139157

Epoch: 6| Step: 8
Training loss: 0.48123916638553327
Validation loss: 2.4897109644398285

Epoch: 6| Step: 9
Training loss: 0.8552154793171661
Validation loss: 2.4143876548600383

Epoch: 6| Step: 10
Training loss: 0.48159246149745344
Validation loss: 2.4499427099772717

Epoch: 6| Step: 11
Training loss: 1.0428178656659792
Validation loss: 2.394324064211896

Epoch: 6| Step: 12
Training loss: 0.5744131369066093
Validation loss: 2.3994386109540784

Epoch: 6| Step: 13
Training loss: 0.8085604306050262
Validation loss: 2.4036868427011573

Epoch: 351| Step: 0
Training loss: 0.6552437151607833
Validation loss: 2.389028394720669

Epoch: 6| Step: 1
Training loss: 0.549977873227053
Validation loss: 2.4038138536786873

Epoch: 6| Step: 2
Training loss: 0.7081408145549339
Validation loss: 2.3827637951044145

Epoch: 6| Step: 3
Training loss: 0.3819453285187787
Validation loss: 2.365216393831439

Epoch: 6| Step: 4
Training loss: 0.36486291610399735
Validation loss: 2.4284521330227857

Epoch: 6| Step: 5
Training loss: 0.7090193894832768
Validation loss: 2.4462538839477443

Epoch: 6| Step: 6
Training loss: 0.7787009807607437
Validation loss: 2.5280586009344526

Epoch: 6| Step: 7
Training loss: 0.7938048366317587
Validation loss: 2.4946505718848617

Epoch: 6| Step: 8
Training loss: 0.6750242370210094
Validation loss: 2.5314420897857155

Epoch: 6| Step: 9
Training loss: 0.685666261368562
Validation loss: 2.494529476222757

Epoch: 6| Step: 10
Training loss: 0.5623391504250653
Validation loss: 2.4574864770172566

Epoch: 6| Step: 11
Training loss: 0.41283923418455426
Validation loss: 2.4550025338254926

Epoch: 6| Step: 12
Training loss: 0.940747042117815
Validation loss: 2.4572467401332965

Epoch: 6| Step: 13
Training loss: 0.8526559511435476
Validation loss: 2.4176624023252673

Epoch: 352| Step: 0
Training loss: 0.800327228141016
Validation loss: 2.4371047707900986

Epoch: 6| Step: 1
Training loss: 0.5311237634010131
Validation loss: 2.407063771019407

Epoch: 6| Step: 2
Training loss: 0.7485318118504054
Validation loss: 2.389554707401232

Epoch: 6| Step: 3
Training loss: 0.45095324482861177
Validation loss: 2.407828817851074

Epoch: 6| Step: 4
Training loss: 0.916094420730629
Validation loss: 2.444736964829327

Epoch: 6| Step: 5
Training loss: 0.2997494749242783
Validation loss: 2.437145039028698

Epoch: 6| Step: 6
Training loss: 0.7806745317075402
Validation loss: 2.427838696259545

Epoch: 6| Step: 7
Training loss: 0.24970117233140188
Validation loss: 2.466091725379715

Epoch: 6| Step: 8
Training loss: 0.3399091964492969
Validation loss: 2.489583738367068

Epoch: 6| Step: 9
Training loss: 0.8254511509957487
Validation loss: 2.46588057418479

Epoch: 6| Step: 10
Training loss: 0.7103160195823571
Validation loss: 2.457040906550952

Epoch: 6| Step: 11
Training loss: 0.5894088152087397
Validation loss: 2.4394550208371704

Epoch: 6| Step: 12
Training loss: 0.6581343210181562
Validation loss: 2.435754713335602

Epoch: 6| Step: 13
Training loss: 0.6609152995319758
Validation loss: 2.449508236692357

Epoch: 353| Step: 0
Training loss: 0.8890504470839518
Validation loss: 2.4107744807423703

Epoch: 6| Step: 1
Training loss: 0.45738402225491753
Validation loss: 2.4125096413841955

Epoch: 6| Step: 2
Training loss: 0.545173176890521
Validation loss: 2.4152615466522622

Epoch: 6| Step: 3
Training loss: 0.4113282307826646
Validation loss: 2.403052199728232

Epoch: 6| Step: 4
Training loss: 0.3942772075720681
Validation loss: 2.458454632430103

Epoch: 6| Step: 5
Training loss: 0.7968168424439673
Validation loss: 2.49009689681853

Epoch: 6| Step: 6
Training loss: 0.5251261673051463
Validation loss: 2.5000619880620625

Epoch: 6| Step: 7
Training loss: 0.6079650608991012
Validation loss: 2.4947001840155116

Epoch: 6| Step: 8
Training loss: 0.469883406817344
Validation loss: 2.5029721681552037

Epoch: 6| Step: 9
Training loss: 0.7166854397584533
Validation loss: 2.469539010012684

Epoch: 6| Step: 10
Training loss: 0.47250078339991136
Validation loss: 2.4514328613756065

Epoch: 6| Step: 11
Training loss: 0.6143016951128204
Validation loss: 2.4374612332383117

Epoch: 6| Step: 12
Training loss: 0.8853734772564209
Validation loss: 2.4215891875509605

Epoch: 6| Step: 13
Training loss: 1.028670697776855
Validation loss: 2.365520049081456

Epoch: 354| Step: 0
Training loss: 0.6171403214977161
Validation loss: 2.337904039745498

Epoch: 6| Step: 1
Training loss: 0.7823278621083517
Validation loss: 2.377704777049175

Epoch: 6| Step: 2
Training loss: 0.6552320942009523
Validation loss: 2.4023052280184425

Epoch: 6| Step: 3
Training loss: 0.4804815895411925
Validation loss: 2.4056350749034623

Epoch: 6| Step: 4
Training loss: 0.46749363058514504
Validation loss: 2.4433910688192637

Epoch: 6| Step: 5
Training loss: 0.6579717801182133
Validation loss: 2.500356007935847

Epoch: 6| Step: 6
Training loss: 0.7635574059904661
Validation loss: 2.5166736613959224

Epoch: 6| Step: 7
Training loss: 0.6385516132204424
Validation loss: 2.5609333792917606

Epoch: 6| Step: 8
Training loss: 0.8569594680922797
Validation loss: 2.5967377949783197

Epoch: 6| Step: 9
Training loss: 0.5766882183020453
Validation loss: 2.6087106339501656

Epoch: 6| Step: 10
Training loss: 0.7371955841384455
Validation loss: 2.5523613097583278

Epoch: 6| Step: 11
Training loss: 0.7131886316607544
Validation loss: 2.5181644457382575

Epoch: 6| Step: 12
Training loss: 0.5236097024088606
Validation loss: 2.482990043189771

Epoch: 6| Step: 13
Training loss: 0.3762872774407914
Validation loss: 2.464777709082456

Epoch: 355| Step: 0
Training loss: 0.6790359048423572
Validation loss: 2.4833110384103065

Epoch: 6| Step: 1
Training loss: 0.7483091765995601
Validation loss: 2.45356104011165

Epoch: 6| Step: 2
Training loss: 0.5167928820951014
Validation loss: 2.4533177687963574

Epoch: 6| Step: 3
Training loss: 0.34339743653864163
Validation loss: 2.4305398337172637

Epoch: 6| Step: 4
Training loss: 0.3150433042823647
Validation loss: 2.475259947319448

Epoch: 6| Step: 5
Training loss: 0.5712759163150898
Validation loss: 2.4446883574185474

Epoch: 6| Step: 6
Training loss: 0.7864590743779276
Validation loss: 2.439938539419852

Epoch: 6| Step: 7
Training loss: 0.3763269946378521
Validation loss: 2.4862885058879347

Epoch: 6| Step: 8
Training loss: 0.33971583491241353
Validation loss: 2.5077328676171

Epoch: 6| Step: 9
Training loss: 0.7144281398602879
Validation loss: 2.544841255075333

Epoch: 6| Step: 10
Training loss: 0.8493510938905384
Validation loss: 2.519385642578612

Epoch: 6| Step: 11
Training loss: 0.7305627038273171
Validation loss: 2.520762883334736

Epoch: 6| Step: 12
Training loss: 0.854736851133891
Validation loss: 2.4844527528751215

Epoch: 6| Step: 13
Training loss: 0.645816815585491
Validation loss: 2.487480951958628

Epoch: 356| Step: 0
Training loss: 0.4113213294935994
Validation loss: 2.441283790716565

Epoch: 6| Step: 1
Training loss: 0.6898125854226692
Validation loss: 2.4390357275118326

Epoch: 6| Step: 2
Training loss: 0.6315937786860094
Validation loss: 2.464080641974932

Epoch: 6| Step: 3
Training loss: 0.5434641327783848
Validation loss: 2.4401867607030083

Epoch: 6| Step: 4
Training loss: 0.4401633055490134
Validation loss: 2.438253020564256

Epoch: 6| Step: 5
Training loss: 0.7095890881642333
Validation loss: 2.4579994269669014

Epoch: 6| Step: 6
Training loss: 0.3152021762707115
Validation loss: 2.4824783629745415

Epoch: 6| Step: 7
Training loss: 0.6373983863180541
Validation loss: 2.479096279728952

Epoch: 6| Step: 8
Training loss: 0.8917357227881867
Validation loss: 2.50829620598221

Epoch: 6| Step: 9
Training loss: 0.6855978661508415
Validation loss: 2.501772796509977

Epoch: 6| Step: 10
Training loss: 0.8303125745997971
Validation loss: 2.4739209340781665

Epoch: 6| Step: 11
Training loss: 0.486464270719553
Validation loss: 2.502501202508927

Epoch: 6| Step: 12
Training loss: 0.6604160497363686
Validation loss: 2.4958510518945185

Epoch: 6| Step: 13
Training loss: 0.18215766250185733
Validation loss: 2.515325055654122

Epoch: 357| Step: 0
Training loss: 0.7168959047683426
Validation loss: 2.4794748110808658

Epoch: 6| Step: 1
Training loss: 0.5197609415191641
Validation loss: 2.5027803752074234

Epoch: 6| Step: 2
Training loss: 0.6968056580124382
Validation loss: 2.503146781425654

Epoch: 6| Step: 3
Training loss: 0.3072564568256292
Validation loss: 2.4926638376068477

Epoch: 6| Step: 4
Training loss: 0.8655677308235713
Validation loss: 2.494109350973898

Epoch: 6| Step: 5
Training loss: 0.4054395955506304
Validation loss: 2.4718481120640834

Epoch: 6| Step: 6
Training loss: 0.4505305169742472
Validation loss: 2.46092502833688

Epoch: 6| Step: 7
Training loss: 0.5442595199309578
Validation loss: 2.46146451480191

Epoch: 6| Step: 8
Training loss: 0.739044521508294
Validation loss: 2.4588985644962764

Epoch: 6| Step: 9
Training loss: 0.637123751405028
Validation loss: 2.4437217283379886

Epoch: 6| Step: 10
Training loss: 0.7720110290757428
Validation loss: 2.4172559955937336

Epoch: 6| Step: 11
Training loss: 0.7067325867490288
Validation loss: 2.457052866327116

Epoch: 6| Step: 12
Training loss: 0.6929023203355782
Validation loss: 2.4394892507435317

Epoch: 6| Step: 13
Training loss: 0.4627158724402389
Validation loss: 2.4637782745870767

Epoch: 358| Step: 0
Training loss: 0.4273595343260297
Validation loss: 2.4847526508336295

Epoch: 6| Step: 1
Training loss: 0.5999758218821064
Validation loss: 2.4951051075880564

Epoch: 6| Step: 2
Training loss: 0.5203869878014429
Validation loss: 2.506570687413052

Epoch: 6| Step: 3
Training loss: 0.37824986815718165
Validation loss: 2.5091165969944176

Epoch: 6| Step: 4
Training loss: 0.7224295595671435
Validation loss: 2.5008577167520585

Epoch: 6| Step: 5
Training loss: 0.8114533285069081
Validation loss: 2.485271178452425

Epoch: 6| Step: 6
Training loss: 0.8569127267758513
Validation loss: 2.444712977149636

Epoch: 6| Step: 7
Training loss: 0.6043346982534782
Validation loss: 2.4984282700711766

Epoch: 6| Step: 8
Training loss: 0.5312294395058409
Validation loss: 2.483112854828392

Epoch: 6| Step: 9
Training loss: 0.4877070904074562
Validation loss: 2.4819606483785113

Epoch: 6| Step: 10
Training loss: 0.501164540499554
Validation loss: 2.5217723980436975

Epoch: 6| Step: 11
Training loss: 0.6414944865672925
Validation loss: 2.5236283965413535

Epoch: 6| Step: 12
Training loss: 0.7057528239621707
Validation loss: 2.4668244526203265

Epoch: 6| Step: 13
Training loss: 0.513535891326969
Validation loss: 2.515897041764704

Epoch: 359| Step: 0
Training loss: 0.44072388763560005
Validation loss: 2.4406305492324853

Epoch: 6| Step: 1
Training loss: 0.36751663390941064
Validation loss: 2.450710184742717

Epoch: 6| Step: 2
Training loss: 0.6720840439395573
Validation loss: 2.451710897644967

Epoch: 6| Step: 3
Training loss: 0.5530627188667574
Validation loss: 2.426730077467887

Epoch: 6| Step: 4
Training loss: 0.8742884058470126
Validation loss: 2.4027485978971104

Epoch: 6| Step: 5
Training loss: 0.48976488162939796
Validation loss: 2.3951245816939775

Epoch: 6| Step: 6
Training loss: 0.6907016159298293
Validation loss: 2.4298195155641

Epoch: 6| Step: 7
Training loss: 0.5864280681581397
Validation loss: 2.403205561864031

Epoch: 6| Step: 8
Training loss: 0.8331837440379166
Validation loss: 2.391215559832528

Epoch: 6| Step: 9
Training loss: 0.6698087368733344
Validation loss: 2.4656775241780835

Epoch: 6| Step: 10
Training loss: 0.5462224336647576
Validation loss: 2.4601006307186

Epoch: 6| Step: 11
Training loss: 0.6023393544235845
Validation loss: 2.446063330603165

Epoch: 6| Step: 12
Training loss: 0.46519868587302543
Validation loss: 2.5159214522537297

Epoch: 6| Step: 13
Training loss: 0.7522123608286334
Validation loss: 2.558483648886278

Epoch: 360| Step: 0
Training loss: 0.8237220750165112
Validation loss: 2.585709334282286

Epoch: 6| Step: 1
Training loss: 0.650870710179665
Validation loss: 2.59088841358882

Epoch: 6| Step: 2
Training loss: 0.5468753814695935
Validation loss: 2.57013399733802

Epoch: 6| Step: 3
Training loss: 0.7217237900407037
Validation loss: 2.554211867802929

Epoch: 6| Step: 4
Training loss: 0.20474849731175684
Validation loss: 2.4936608823423576

Epoch: 6| Step: 5
Training loss: 0.4149686327248307
Validation loss: 2.5334978310372858

Epoch: 6| Step: 6
Training loss: 0.6418737243595095
Validation loss: 2.434376509892378

Epoch: 6| Step: 7
Training loss: 0.6124224146536313
Validation loss: 2.4277665557984305

Epoch: 6| Step: 8
Training loss: 0.567292670805798
Validation loss: 2.4032097371542727

Epoch: 6| Step: 9
Training loss: 0.5705330565919641
Validation loss: 2.3717033733886943

Epoch: 6| Step: 10
Training loss: 0.4157178287526005
Validation loss: 2.4110454562988846

Epoch: 6| Step: 11
Training loss: 0.5312696902048113
Validation loss: 2.490757619989988

Epoch: 6| Step: 12
Training loss: 0.8303568293604574
Validation loss: 2.44678907813381

Epoch: 6| Step: 13
Training loss: 0.8472659007696791
Validation loss: 2.4942313412010217

Epoch: 361| Step: 0
Training loss: 0.848122253301076
Validation loss: 2.4669123100612036

Epoch: 6| Step: 1
Training loss: 0.5541193026424671
Validation loss: 2.4900895315179055

Epoch: 6| Step: 2
Training loss: 0.39129883820892347
Validation loss: 2.4739871464569654

Epoch: 6| Step: 3
Training loss: 0.3540501636669059
Validation loss: 2.4808896940792087

Epoch: 6| Step: 4
Training loss: 0.5999606218926438
Validation loss: 2.462164222782771

Epoch: 6| Step: 5
Training loss: 0.5760516024992144
Validation loss: 2.4407549408448737

Epoch: 6| Step: 6
Training loss: 0.7800908453930478
Validation loss: 2.4764458630883177

Epoch: 6| Step: 7
Training loss: 0.19602073054622302
Validation loss: 2.474788116172451

Epoch: 6| Step: 8
Training loss: 0.5082533463359952
Validation loss: 2.4503036880039146

Epoch: 6| Step: 9
Training loss: 0.4384817620119926
Validation loss: 2.4395158528878906

Epoch: 6| Step: 10
Training loss: 0.8469683057333968
Validation loss: 2.4657916226256678

Epoch: 6| Step: 11
Training loss: 0.5310327983468389
Validation loss: 2.4432407396023343

Epoch: 6| Step: 12
Training loss: 0.7067642761653438
Validation loss: 2.445073327529902

Epoch: 6| Step: 13
Training loss: 0.18855230756276736
Validation loss: 2.4455698902578415

Epoch: 362| Step: 0
Training loss: 0.6779020470314953
Validation loss: 2.508609491107144

Epoch: 6| Step: 1
Training loss: 0.3642375827929683
Validation loss: 2.479771695789326

Epoch: 6| Step: 2
Training loss: 0.6626956111098926
Validation loss: 2.478150973406118

Epoch: 6| Step: 3
Training loss: 0.27085498882182907
Validation loss: 2.4864542824659397

Epoch: 6| Step: 4
Training loss: 0.5972205175577523
Validation loss: 2.452505596386522

Epoch: 6| Step: 5
Training loss: 0.5631489189563649
Validation loss: 2.4152407557250233

Epoch: 6| Step: 6
Training loss: 0.4249218483202632
Validation loss: 2.4137457421315163

Epoch: 6| Step: 7
Training loss: 0.5119609987354022
Validation loss: 2.4175002435915536

Epoch: 6| Step: 8
Training loss: 0.7208965424476836
Validation loss: 2.4615430324900642

Epoch: 6| Step: 9
Training loss: 0.4997705886973585
Validation loss: 2.462848552211686

Epoch: 6| Step: 10
Training loss: 0.569214456203286
Validation loss: 2.4132262136471665

Epoch: 6| Step: 11
Training loss: 0.8794663064779921
Validation loss: 2.4401876705154915

Epoch: 6| Step: 12
Training loss: 0.41136163066095316
Validation loss: 2.469590935216151

Epoch: 6| Step: 13
Training loss: 0.8371648957837975
Validation loss: 2.4834294035534263

Epoch: 363| Step: 0
Training loss: 0.3530714500806824
Validation loss: 2.5291344864215706

Epoch: 6| Step: 1
Training loss: 0.6753056346397822
Validation loss: 2.4921484143158645

Epoch: 6| Step: 2
Training loss: 0.5686620581411457
Validation loss: 2.4909281576168327

Epoch: 6| Step: 3
Training loss: 0.7726502313176977
Validation loss: 2.5286558838407336

Epoch: 6| Step: 4
Training loss: 0.5035135971987357
Validation loss: 2.5436751285582155

Epoch: 6| Step: 5
Training loss: 0.6263797312694662
Validation loss: 2.5242741823610624

Epoch: 6| Step: 6
Training loss: 0.1853486960282879
Validation loss: 2.4902812240282666

Epoch: 6| Step: 7
Training loss: 0.39833639769525964
Validation loss: 2.463646748846494

Epoch: 6| Step: 8
Training loss: 0.5473944240833826
Validation loss: 2.443092396985501

Epoch: 6| Step: 9
Training loss: 0.5476712832924766
Validation loss: 2.3948666126061635

Epoch: 6| Step: 10
Training loss: 0.5860638545808763
Validation loss: 2.4210573354310925

Epoch: 6| Step: 11
Training loss: 0.6226082336980532
Validation loss: 2.405882782996519

Epoch: 6| Step: 12
Training loss: 0.5377111497036962
Validation loss: 2.3777392856591377

Epoch: 6| Step: 13
Training loss: 1.1104333691417358
Validation loss: 2.3884400891087587

Epoch: 364| Step: 0
Training loss: 0.4034392617894124
Validation loss: 2.399448327268815

Epoch: 6| Step: 1
Training loss: 0.3174129882552459
Validation loss: 2.428759792366976

Epoch: 6| Step: 2
Training loss: 0.5787915948952839
Validation loss: 2.477060397532762

Epoch: 6| Step: 3
Training loss: 0.5593278769138678
Validation loss: 2.4866010058292196

Epoch: 6| Step: 4
Training loss: 0.7545914377556324
Validation loss: 2.485338499547129

Epoch: 6| Step: 5
Training loss: 0.6860410642539201
Validation loss: 2.451407664407789

Epoch: 6| Step: 6
Training loss: 0.5291193139924008
Validation loss: 2.475690212983567

Epoch: 6| Step: 7
Training loss: 0.7544928526770504
Validation loss: 2.4279057229407583

Epoch: 6| Step: 8
Training loss: 0.6677166870316696
Validation loss: 2.4325805381501615

Epoch: 6| Step: 9
Training loss: 0.4805933937970848
Validation loss: 2.416753787152472

Epoch: 6| Step: 10
Training loss: 0.3884270054818153
Validation loss: 2.428612068936997

Epoch: 6| Step: 11
Training loss: 0.521879525079354
Validation loss: 2.3984156712438596

Epoch: 6| Step: 12
Training loss: 0.5914069171937029
Validation loss: 2.384572427598799

Epoch: 6| Step: 13
Training loss: 0.558055004331423
Validation loss: 2.4460793335006894

Epoch: 365| Step: 0
Training loss: 0.41150606659163674
Validation loss: 2.512975599105096

Epoch: 6| Step: 1
Training loss: 0.7882988889023179
Validation loss: 2.509853238708467

Epoch: 6| Step: 2
Training loss: 0.8145971742577717
Validation loss: 2.502049486893574

Epoch: 6| Step: 3
Training loss: 0.8454206316425515
Validation loss: 2.5175404477528236

Epoch: 6| Step: 4
Training loss: 0.4822334044949494
Validation loss: 2.561127536973909

Epoch: 6| Step: 5
Training loss: 0.42101872046432187
Validation loss: 2.519754172865122

Epoch: 6| Step: 6
Training loss: 0.431686053755102
Validation loss: 2.5265629035972266

Epoch: 6| Step: 7
Training loss: 0.36782720317638373
Validation loss: 2.466477471351426

Epoch: 6| Step: 8
Training loss: 0.38173605937023264
Validation loss: 2.4180622364054063

Epoch: 6| Step: 9
Training loss: 0.5839600573934018
Validation loss: 2.4407554576157455

Epoch: 6| Step: 10
Training loss: 0.521284600900171
Validation loss: 2.430329840551761

Epoch: 6| Step: 11
Training loss: 0.6908871269756092
Validation loss: 2.4238525816694887

Epoch: 6| Step: 12
Training loss: 0.4933382538709028
Validation loss: 2.400885252666697

Epoch: 6| Step: 13
Training loss: 0.4611796211937572
Validation loss: 2.4334913157267266

Epoch: 366| Step: 0
Training loss: 0.803015926390792
Validation loss: 2.479670508471533

Epoch: 6| Step: 1
Training loss: 0.49634875854662797
Validation loss: 2.5199675904354915

Epoch: 6| Step: 2
Training loss: 0.5431553362241771
Validation loss: 2.5002558033828364

Epoch: 6| Step: 3
Training loss: 0.6756036558140981
Validation loss: 2.4470832046412063

Epoch: 6| Step: 4
Training loss: 0.8406777432710533
Validation loss: 2.448826396215913

Epoch: 6| Step: 5
Training loss: 0.558425931463828
Validation loss: 2.454851272435731

Epoch: 6| Step: 6
Training loss: 0.3060708310093923
Validation loss: 2.42240020741469

Epoch: 6| Step: 7
Training loss: 0.6801237701225413
Validation loss: 2.3850475752420652

Epoch: 6| Step: 8
Training loss: 0.6920591601361196
Validation loss: 2.418716952376981

Epoch: 6| Step: 9
Training loss: 0.35563433636576247
Validation loss: 2.4078014557003486

Epoch: 6| Step: 10
Training loss: 0.5564110533483663
Validation loss: 2.4296274654221732

Epoch: 6| Step: 11
Training loss: 0.42252755030131006
Validation loss: 2.4554393649814044

Epoch: 6| Step: 12
Training loss: 0.45112312350750916
Validation loss: 2.454657098202202

Epoch: 6| Step: 13
Training loss: 0.45042999174937964
Validation loss: 2.460634707828149

Epoch: 367| Step: 0
Training loss: 0.6507476880416806
Validation loss: 2.4706383623977666

Epoch: 6| Step: 1
Training loss: 0.5173327458120645
Validation loss: 2.5196491366184106

Epoch: 6| Step: 2
Training loss: 0.48757213217828743
Validation loss: 2.4811133113989383

Epoch: 6| Step: 3
Training loss: 0.600482416923054
Validation loss: 2.44944181213331

Epoch: 6| Step: 4
Training loss: 0.36416450921400895
Validation loss: 2.4488818480615717

Epoch: 6| Step: 5
Training loss: 0.6782663769289741
Validation loss: 2.4412884957741428

Epoch: 6| Step: 6
Training loss: 0.6193177363988247
Validation loss: 2.431536237012409

Epoch: 6| Step: 7
Training loss: 0.40924262971597275
Validation loss: 2.4351616090173023

Epoch: 6| Step: 8
Training loss: 0.5294779506501528
Validation loss: 2.406292392254477

Epoch: 6| Step: 9
Training loss: 0.5649282706142245
Validation loss: 2.4611978497666853

Epoch: 6| Step: 10
Training loss: 0.5822684041689747
Validation loss: 2.4355180506109866

Epoch: 6| Step: 11
Training loss: 0.7248471427783805
Validation loss: 2.424894507445372

Epoch: 6| Step: 12
Training loss: 0.42144493858949467
Validation loss: 2.391403405022861

Epoch: 6| Step: 13
Training loss: 0.8184198252490696
Validation loss: 2.3986754987927625

Epoch: 368| Step: 0
Training loss: 0.7475592714751378
Validation loss: 2.407642968654217

Epoch: 6| Step: 1
Training loss: 0.3348243813157445
Validation loss: 2.404469601012153

Epoch: 6| Step: 2
Training loss: 0.535992407696956
Validation loss: 2.397533127998766

Epoch: 6| Step: 3
Training loss: 0.7737299048505849
Validation loss: 2.4080675598928187

Epoch: 6| Step: 4
Training loss: 0.46432235070188915
Validation loss: 2.4452216668707587

Epoch: 6| Step: 5
Training loss: 0.544155634928407
Validation loss: 2.4886926863434082

Epoch: 6| Step: 6
Training loss: 0.5861342799045355
Validation loss: 2.454529762856661

Epoch: 6| Step: 7
Training loss: 0.7259573518532252
Validation loss: 2.483349952454947

Epoch: 6| Step: 8
Training loss: 0.46861301645813536
Validation loss: 2.4785723892122444

Epoch: 6| Step: 9
Training loss: 0.7361417580068866
Validation loss: 2.459299956659605

Epoch: 6| Step: 10
Training loss: 0.3942711038559154
Validation loss: 2.493030985654975

Epoch: 6| Step: 11
Training loss: 0.261050509919277
Validation loss: 2.4305223900035737

Epoch: 6| Step: 12
Training loss: 0.3562874640458307
Validation loss: 2.4010212393132346

Epoch: 6| Step: 13
Training loss: 0.3304988842835689
Validation loss: 2.4213381036866313

Epoch: 369| Step: 0
Training loss: 0.5822814301311522
Validation loss: 2.4028727335457964

Epoch: 6| Step: 1
Training loss: 0.6504454489389286
Validation loss: 2.3766721161863558

Epoch: 6| Step: 2
Training loss: 0.5262470851464087
Validation loss: 2.3650248075064044

Epoch: 6| Step: 3
Training loss: 0.5961979046341688
Validation loss: 2.3743901562699956

Epoch: 6| Step: 4
Training loss: 0.7624145069034045
Validation loss: 2.4084304393436273

Epoch: 6| Step: 5
Training loss: 0.5219253789832476
Validation loss: 2.443555407485426

Epoch: 6| Step: 6
Training loss: 0.40727551941274487
Validation loss: 2.486614925076926

Epoch: 6| Step: 7
Training loss: 0.5293309387281786
Validation loss: 2.48937193105609

Epoch: 6| Step: 8
Training loss: 0.5897190644307502
Validation loss: 2.508551531285646

Epoch: 6| Step: 9
Training loss: 0.31503363153514635
Validation loss: 2.490083504597888

Epoch: 6| Step: 10
Training loss: 0.5209613420217067
Validation loss: 2.492830609930696

Epoch: 6| Step: 11
Training loss: 0.4215781438991587
Validation loss: 2.514314234972281

Epoch: 6| Step: 12
Training loss: 0.7277330792712943
Validation loss: 2.4852946385095374

Epoch: 6| Step: 13
Training loss: 0.7744692461669229
Validation loss: 2.4439291630793503

Epoch: 370| Step: 0
Training loss: 0.4705375443467175
Validation loss: 2.446025844068748

Epoch: 6| Step: 1
Training loss: 0.4064752797742918
Validation loss: 2.427594900231134

Epoch: 6| Step: 2
Training loss: 0.6369215753387689
Validation loss: 2.4019889462155795

Epoch: 6| Step: 3
Training loss: 0.5969576523759788
Validation loss: 2.3825480028707173

Epoch: 6| Step: 4
Training loss: 0.6146011727109297
Validation loss: 2.351770683069872

Epoch: 6| Step: 5
Training loss: 0.41944458917098815
Validation loss: 2.3706171703196617

Epoch: 6| Step: 6
Training loss: 0.5002130114288807
Validation loss: 2.393784958603344

Epoch: 6| Step: 7
Training loss: 0.47566847506018756
Validation loss: 2.4199115538725238

Epoch: 6| Step: 8
Training loss: 0.42987840053126264
Validation loss: 2.4404539095182467

Epoch: 6| Step: 9
Training loss: 0.4869191511846916
Validation loss: 2.4168576956054486

Epoch: 6| Step: 10
Training loss: 0.9247465508142206
Validation loss: 2.425403263994681

Epoch: 6| Step: 11
Training loss: 0.4627062917415551
Validation loss: 2.4476712940182472

Epoch: 6| Step: 12
Training loss: 0.3258038689059
Validation loss: 2.442372085867811

Epoch: 6| Step: 13
Training loss: 0.7138618020247225
Validation loss: 2.4478861728113768

Epoch: 371| Step: 0
Training loss: 0.34848288509917746
Validation loss: 2.4222277990012753

Epoch: 6| Step: 1
Training loss: 0.4029845902523448
Validation loss: 2.4180965804283763

Epoch: 6| Step: 2
Training loss: 0.5025900870082193
Validation loss: 2.4203121375776493

Epoch: 6| Step: 3
Training loss: 0.4673347885257242
Validation loss: 2.4232381921293724

Epoch: 6| Step: 4
Training loss: 0.6893969288690353
Validation loss: 2.3907849309739175

Epoch: 6| Step: 5
Training loss: 0.3711089683223075
Validation loss: 2.4180028430159286

Epoch: 6| Step: 6
Training loss: 0.5394840527175911
Validation loss: 2.42505809759588

Epoch: 6| Step: 7
Training loss: 0.41228244636574296
Validation loss: 2.4269829643530434

Epoch: 6| Step: 8
Training loss: 0.5249787882652338
Validation loss: 2.4471122657572404

Epoch: 6| Step: 9
Training loss: 0.5395007632447254
Validation loss: 2.4803400607191404

Epoch: 6| Step: 10
Training loss: 0.8498948242528116
Validation loss: 2.4455968696769754

Epoch: 6| Step: 11
Training loss: 0.5420051641886838
Validation loss: 2.453056709149437

Epoch: 6| Step: 12
Training loss: 0.5591474336574973
Validation loss: 2.4674578112444623

Epoch: 6| Step: 13
Training loss: 0.6240518530642768
Validation loss: 2.424070948281545

Epoch: 372| Step: 0
Training loss: 0.4667880803640425
Validation loss: 2.446817945767212

Epoch: 6| Step: 1
Training loss: 0.4144832704386768
Validation loss: 2.4023370504765236

Epoch: 6| Step: 2
Training loss: 0.6201879025486527
Validation loss: 2.4309915272504856

Epoch: 6| Step: 3
Training loss: 0.7178037883543784
Validation loss: 2.4391499123871525

Epoch: 6| Step: 4
Training loss: 0.4787506149327883
Validation loss: 2.3919771624975827

Epoch: 6| Step: 5
Training loss: 0.6842698160102875
Validation loss: 2.39359004614195

Epoch: 6| Step: 6
Training loss: 0.45528377748691545
Validation loss: 2.4046938077297306

Epoch: 6| Step: 7
Training loss: 0.6303684934862375
Validation loss: 2.3958918267841067

Epoch: 6| Step: 8
Training loss: 0.4036562908007501
Validation loss: 2.398754339844076

Epoch: 6| Step: 9
Training loss: 0.4150790924514763
Validation loss: 2.457548328647546

Epoch: 6| Step: 10
Training loss: 0.6123284878280348
Validation loss: 2.4289389021125163

Epoch: 6| Step: 11
Training loss: 0.5884540937193957
Validation loss: 2.4650303545229835

Epoch: 6| Step: 12
Training loss: 0.37635661151400535
Validation loss: 2.5076590793844975

Epoch: 6| Step: 13
Training loss: 0.2990912980232335
Validation loss: 2.4944197791389318

Epoch: 373| Step: 0
Training loss: 0.41992868817147283
Validation loss: 2.4408133179307394

Epoch: 6| Step: 1
Training loss: 0.7078995404820325
Validation loss: 2.437109708500244

Epoch: 6| Step: 2
Training loss: 0.44726769059549637
Validation loss: 2.39349874752568

Epoch: 6| Step: 3
Training loss: 0.42805707420511835
Validation loss: 2.329636377153167

Epoch: 6| Step: 4
Training loss: 0.9483115802363953
Validation loss: 2.4083593983316094

Epoch: 6| Step: 5
Training loss: 0.5894338939606195
Validation loss: 2.4253988291012387

Epoch: 6| Step: 6
Training loss: 0.545382042196947
Validation loss: 2.4698283404191494

Epoch: 6| Step: 7
Training loss: 0.6180689348303813
Validation loss: 2.528234295972167

Epoch: 6| Step: 8
Training loss: 0.44528485931811984
Validation loss: 2.610249484386504

Epoch: 6| Step: 9
Training loss: 0.46723972845140815
Validation loss: 2.5909032419420686

Epoch: 6| Step: 10
Training loss: 0.5520593679972593
Validation loss: 2.5455478905014437

Epoch: 6| Step: 11
Training loss: 0.4389559837185486
Validation loss: 2.4843680139888282

Epoch: 6| Step: 12
Training loss: 0.6033157462073525
Validation loss: 2.467100644147428

Epoch: 6| Step: 13
Training loss: 0.4135063503024538
Validation loss: 2.4261011242323196

Epoch: 374| Step: 0
Training loss: 0.661107523447163
Validation loss: 2.3356986666426276

Epoch: 6| Step: 1
Training loss: 0.813704624698169
Validation loss: 2.349981475648849

Epoch: 6| Step: 2
Training loss: 0.68299340180272
Validation loss: 2.3280282279531974

Epoch: 6| Step: 3
Training loss: 0.7348440579659694
Validation loss: 2.325880242652692

Epoch: 6| Step: 4
Training loss: 0.2696284796004355
Validation loss: 2.393000238353149

Epoch: 6| Step: 5
Training loss: 0.48354422172365497
Validation loss: 2.40925772087173

Epoch: 6| Step: 6
Training loss: 0.6001702583662446
Validation loss: 2.4697649899273246

Epoch: 6| Step: 7
Training loss: 0.292654721123184
Validation loss: 2.488489402280853

Epoch: 6| Step: 8
Training loss: 0.6383188887929776
Validation loss: 2.47550109185862

Epoch: 6| Step: 9
Training loss: 0.4276787011828682
Validation loss: 2.449625995049324

Epoch: 6| Step: 10
Training loss: 0.5581374271884616
Validation loss: 2.458815073984262

Epoch: 6| Step: 11
Training loss: 0.6668669330284189
Validation loss: 2.4890278571404267

Epoch: 6| Step: 12
Training loss: 0.4079123013152092
Validation loss: 2.408853865836584

Epoch: 6| Step: 13
Training loss: 0.27281819100577964
Validation loss: 2.4057707035532276

Epoch: 375| Step: 0
Training loss: 0.5932486575851331
Validation loss: 2.3894757258859234

Epoch: 6| Step: 1
Training loss: 0.252036827437193
Validation loss: 2.354782046567527

Epoch: 6| Step: 2
Training loss: 0.5484015819818897
Validation loss: 2.3683449940755468

Epoch: 6| Step: 3
Training loss: 0.815978928576747
Validation loss: 2.366480086421779

Epoch: 6| Step: 4
Training loss: 0.5422919466846206
Validation loss: 2.35032797141305

Epoch: 6| Step: 5
Training loss: 0.5381497104744299
Validation loss: 2.3583410901978

Epoch: 6| Step: 6
Training loss: 0.5628527224166919
Validation loss: 2.3480384953229794

Epoch: 6| Step: 7
Training loss: 0.6151380917730177
Validation loss: 2.4029067654896292

Epoch: 6| Step: 8
Training loss: 0.3549488163705993
Validation loss: 2.3771075033779345

Epoch: 6| Step: 9
Training loss: 0.4966184589599491
Validation loss: 2.3994589420893497

Epoch: 6| Step: 10
Training loss: 0.5455387684431333
Validation loss: 2.4179819378284555

Epoch: 6| Step: 11
Training loss: 0.48883638486853753
Validation loss: 2.504292070827373

Epoch: 6| Step: 12
Training loss: 0.48570876917290856
Validation loss: 2.464551549608482

Epoch: 6| Step: 13
Training loss: 0.38385715802639
Validation loss: 2.505717405247954

Epoch: 376| Step: 0
Training loss: 0.6403170985461197
Validation loss: 2.4883202954618144

Epoch: 6| Step: 1
Training loss: 0.6447814455798856
Validation loss: 2.4887875334406266

Epoch: 6| Step: 2
Training loss: 0.4484460238400926
Validation loss: 2.4756660644084008

Epoch: 6| Step: 3
Training loss: 0.4650301839917402
Validation loss: 2.4587601477485954

Epoch: 6| Step: 4
Training loss: 0.5218653055535527
Validation loss: 2.429176949308113

Epoch: 6| Step: 5
Training loss: 0.5690872670062502
Validation loss: 2.3873934892921875

Epoch: 6| Step: 6
Training loss: 0.2911156092169635
Validation loss: 2.391889904120294

Epoch: 6| Step: 7
Training loss: 0.44621581764093876
Validation loss: 2.4068629711038203

Epoch: 6| Step: 8
Training loss: 0.6970354229122973
Validation loss: 2.3732290114576213

Epoch: 6| Step: 9
Training loss: 0.38709702919559386
Validation loss: 2.3404492965882207

Epoch: 6| Step: 10
Training loss: 0.6425489517592818
Validation loss: 2.379278144518449

Epoch: 6| Step: 11
Training loss: 0.3839357013452232
Validation loss: 2.413480413508141

Epoch: 6| Step: 12
Training loss: 0.5502974637786411
Validation loss: 2.4341115767178754

Epoch: 6| Step: 13
Training loss: 0.41691127590669624
Validation loss: 2.504126044421591

Epoch: 377| Step: 0
Training loss: 0.536270429671098
Validation loss: 2.5285585294443145

Epoch: 6| Step: 1
Training loss: 0.4139387557621068
Validation loss: 2.524263705967477

Epoch: 6| Step: 2
Training loss: 0.6530612950992485
Validation loss: 2.5238897625096293

Epoch: 6| Step: 3
Training loss: 0.3932640194973594
Validation loss: 2.4610464399777197

Epoch: 6| Step: 4
Training loss: 0.5325239558047465
Validation loss: 2.4251961093737733

Epoch: 6| Step: 5
Training loss: 0.3995061642287001
Validation loss: 2.3642866327871896

Epoch: 6| Step: 6
Training loss: 0.5196532772997031
Validation loss: 2.346068909598648

Epoch: 6| Step: 7
Training loss: 0.7333531270462524
Validation loss: 2.3359562679004213

Epoch: 6| Step: 8
Training loss: 0.4088631728166446
Validation loss: 2.333759461955644

Epoch: 6| Step: 9
Training loss: 0.6062296362534153
Validation loss: 2.32278679428977

Epoch: 6| Step: 10
Training loss: 0.5779355744026277
Validation loss: 2.319087593811112

Epoch: 6| Step: 11
Training loss: 0.6344345403081189
Validation loss: 2.3487695694021125

Epoch: 6| Step: 12
Training loss: 0.5982951072030557
Validation loss: 2.3544337988365736

Epoch: 6| Step: 13
Training loss: 0.38419863756430717
Validation loss: 2.414717400143878

Epoch: 378| Step: 0
Training loss: 0.7265482255087189
Validation loss: 2.4281893222469777

Epoch: 6| Step: 1
Training loss: 0.5389685894531322
Validation loss: 2.469941538729632

Epoch: 6| Step: 2
Training loss: 0.3413421985416694
Validation loss: 2.466628613243589

Epoch: 6| Step: 3
Training loss: 0.7115219564367478
Validation loss: 2.4409979990903548

Epoch: 6| Step: 4
Training loss: 0.3523118721525138
Validation loss: 2.4597792512392944

Epoch: 6| Step: 5
Training loss: 0.4736925225128132
Validation loss: 2.4778094928183907

Epoch: 6| Step: 6
Training loss: 0.5317295378499479
Validation loss: 2.488013652894956

Epoch: 6| Step: 7
Training loss: 0.35338565903245134
Validation loss: 2.441589948146146

Epoch: 6| Step: 8
Training loss: 0.5242763743444726
Validation loss: 2.473725723876818

Epoch: 6| Step: 9
Training loss: 0.5813162847891363
Validation loss: 2.412447419279769

Epoch: 6| Step: 10
Training loss: 0.5670949497850301
Validation loss: 2.4419500964115723

Epoch: 6| Step: 11
Training loss: 0.28622859354228103
Validation loss: 2.4485734074750147

Epoch: 6| Step: 12
Training loss: 0.5644636318192483
Validation loss: 2.442528764751397

Epoch: 6| Step: 13
Training loss: 0.5117412882493365
Validation loss: 2.4294862178787593

Epoch: 379| Step: 0
Training loss: 0.6334784029987821
Validation loss: 2.423244039356749

Epoch: 6| Step: 1
Training loss: 0.5373242312627504
Validation loss: 2.443186838082039

Epoch: 6| Step: 2
Training loss: 0.531770199044572
Validation loss: 2.4299355604384156

Epoch: 6| Step: 3
Training loss: 0.6443161114073335
Validation loss: 2.440116294905731

Epoch: 6| Step: 4
Training loss: 0.5788110322677248
Validation loss: 2.40377323770802

Epoch: 6| Step: 5
Training loss: 0.4180226157586337
Validation loss: 2.4260501763694267

Epoch: 6| Step: 6
Training loss: 0.3094202755059969
Validation loss: 2.3936101184963525

Epoch: 6| Step: 7
Training loss: 0.41301465152124545
Validation loss: 2.4186846055957694

Epoch: 6| Step: 8
Training loss: 0.494039668449
Validation loss: 2.4243606181175306

Epoch: 6| Step: 9
Training loss: 0.6354085160863548
Validation loss: 2.4278025608279745

Epoch: 6| Step: 10
Training loss: 0.25554515384384846
Validation loss: 2.418619259919925

Epoch: 6| Step: 11
Training loss: 0.43151940071853945
Validation loss: 2.4629489723631175

Epoch: 6| Step: 12
Training loss: 0.5274629246306264
Validation loss: 2.4552872993753967

Epoch: 6| Step: 13
Training loss: 0.37998368755262546
Validation loss: 2.4637280756806166

Epoch: 380| Step: 0
Training loss: 0.5375337623372038
Validation loss: 2.4182513451213445

Epoch: 6| Step: 1
Training loss: 0.3516145773569177
Validation loss: 2.4159576329207675

Epoch: 6| Step: 2
Training loss: 0.43980769793941
Validation loss: 2.4569798087935073

Epoch: 6| Step: 3
Training loss: 0.35040890785242823
Validation loss: 2.462634715073518

Epoch: 6| Step: 4
Training loss: 0.5216494523987317
Validation loss: 2.4505471560110506

Epoch: 6| Step: 5
Training loss: 0.40177662702910677
Validation loss: 2.411294883798891

Epoch: 6| Step: 6
Training loss: 0.5925760458983308
Validation loss: 2.4409560047697494

Epoch: 6| Step: 7
Training loss: 0.5525442274869611
Validation loss: 2.434404127269572

Epoch: 6| Step: 8
Training loss: 0.7581399426477539
Validation loss: 2.4098180688945456

Epoch: 6| Step: 9
Training loss: 0.3971009369771139
Validation loss: 2.4301186835705977

Epoch: 6| Step: 10
Training loss: 0.5790299215277342
Validation loss: 2.44069090977639

Epoch: 6| Step: 11
Training loss: 0.48900803454649744
Validation loss: 2.4081355792037047

Epoch: 6| Step: 12
Training loss: 0.35308769839261617
Validation loss: 2.4248489634141506

Epoch: 6| Step: 13
Training loss: 0.2848127726389702
Validation loss: 2.451221177460355

Epoch: 381| Step: 0
Training loss: 0.42224985705498036
Validation loss: 2.4671849131108696

Epoch: 6| Step: 1
Training loss: 0.46980782993477627
Validation loss: 2.4735414014866537

Epoch: 6| Step: 2
Training loss: 0.5195091070748223
Validation loss: 2.455619957736273

Epoch: 6| Step: 3
Training loss: 0.5465095934117448
Validation loss: 2.479640530386559

Epoch: 6| Step: 4
Training loss: 0.35529335641412546
Validation loss: 2.427587485753378

Epoch: 6| Step: 5
Training loss: 0.40418568063364535
Validation loss: 2.3752039250797283

Epoch: 6| Step: 6
Training loss: 0.33740625227390864
Validation loss: 2.4021335939742756

Epoch: 6| Step: 7
Training loss: 0.6610855468803665
Validation loss: 2.3754420816209745

Epoch: 6| Step: 8
Training loss: 0.4613674066342974
Validation loss: 2.3696555391411342

Epoch: 6| Step: 9
Training loss: 0.6744369410156444
Validation loss: 2.3516642154292944

Epoch: 6| Step: 10
Training loss: 0.33786766988584127
Validation loss: 2.3490216970350097

Epoch: 6| Step: 11
Training loss: 0.6069662218844993
Validation loss: 2.338925713765032

Epoch: 6| Step: 12
Training loss: 0.6366985762506967
Validation loss: 2.3706152594439263

Epoch: 6| Step: 13
Training loss: 0.430770687821958
Validation loss: 2.4024722624096055

Epoch: 382| Step: 0
Training loss: 0.37770136755053624
Validation loss: 2.4327147393587074

Epoch: 6| Step: 1
Training loss: 0.4847022765985836
Validation loss: 2.4262835942696745

Epoch: 6| Step: 2
Training loss: 0.47708357792921613
Validation loss: 2.490296745637171

Epoch: 6| Step: 3
Training loss: 0.6081255060254586
Validation loss: 2.529960377739717

Epoch: 6| Step: 4
Training loss: 0.6725560440407305
Validation loss: 2.5227938291168774

Epoch: 6| Step: 5
Training loss: 0.7823093480035013
Validation loss: 2.51787682248056

Epoch: 6| Step: 6
Training loss: 0.4454522666437164
Validation loss: 2.4607879671371875

Epoch: 6| Step: 7
Training loss: 0.3727061128345841
Validation loss: 2.4585049178962293

Epoch: 6| Step: 8
Training loss: 0.44773656713760807
Validation loss: 2.457058357109978

Epoch: 6| Step: 9
Training loss: 0.5456358904368932
Validation loss: 2.4063914757763545

Epoch: 6| Step: 10
Training loss: 0.299790981613147
Validation loss: 2.3902055765317956

Epoch: 6| Step: 11
Training loss: 0.4981821811360029
Validation loss: 2.429555592278143

Epoch: 6| Step: 12
Training loss: 0.5518453612960483
Validation loss: 2.38841486302054

Epoch: 6| Step: 13
Training loss: 0.5568766311124981
Validation loss: 2.359308917858622

Epoch: 383| Step: 0
Training loss: 0.6432736467639942
Validation loss: 2.3506777135233468

Epoch: 6| Step: 1
Training loss: 0.6286726808122088
Validation loss: 2.407241312384608

Epoch: 6| Step: 2
Training loss: 0.5456008509462187
Validation loss: 2.4107265236843367

Epoch: 6| Step: 3
Training loss: 0.7107541193619651
Validation loss: 2.452842190818338

Epoch: 6| Step: 4
Training loss: 0.23541478142925906
Validation loss: 2.4164581088609753

Epoch: 6| Step: 5
Training loss: 0.44670716448474607
Validation loss: 2.447873075922278

Epoch: 6| Step: 6
Training loss: 0.29230552625300016
Validation loss: 2.448965019550222

Epoch: 6| Step: 7
Training loss: 0.4817607534917775
Validation loss: 2.4524104290718345

Epoch: 6| Step: 8
Training loss: 0.3138655866049179
Validation loss: 2.417229170746676

Epoch: 6| Step: 9
Training loss: 0.3906474107035688
Validation loss: 2.4284940078676525

Epoch: 6| Step: 10
Training loss: 0.524793150433902
Validation loss: 2.4335371249307425

Epoch: 6| Step: 11
Training loss: 0.5071581806538888
Validation loss: 2.4558865165067614

Epoch: 6| Step: 12
Training loss: 0.40631911716843894
Validation loss: 2.373341901777995

Epoch: 6| Step: 13
Training loss: 0.4180806446925491
Validation loss: 2.4068895046043246

Epoch: 384| Step: 0
Training loss: 0.5715642021992293
Validation loss: 2.4278431021456783

Epoch: 6| Step: 1
Training loss: 0.45617024103398934
Validation loss: 2.429235103344398

Epoch: 6| Step: 2
Training loss: 0.29147249241035
Validation loss: 2.404644321056998

Epoch: 6| Step: 3
Training loss: 0.37988183185676366
Validation loss: 2.4429546490628433

Epoch: 6| Step: 4
Training loss: 0.45914688479959725
Validation loss: 2.4579052233406435

Epoch: 6| Step: 5
Training loss: 0.5704276086311831
Validation loss: 2.4000013866514553

Epoch: 6| Step: 6
Training loss: 0.48422089555627523
Validation loss: 2.4455990878107947

Epoch: 6| Step: 7
Training loss: 0.45011078543704736
Validation loss: 2.44471380872647

Epoch: 6| Step: 8
Training loss: 0.2542188187677048
Validation loss: 2.3958848738153478

Epoch: 6| Step: 9
Training loss: 0.4551618769121414
Validation loss: 2.422541700909033

Epoch: 6| Step: 10
Training loss: 0.8391319629750233
Validation loss: 2.3924296323173184

Epoch: 6| Step: 11
Training loss: 0.3114230553264585
Validation loss: 2.4370972537541244

Epoch: 6| Step: 12
Training loss: 0.44815539681252536
Validation loss: 2.3912984178494208

Epoch: 6| Step: 13
Training loss: 0.44461359424563124
Validation loss: 2.4036058462951067

Epoch: 385| Step: 0
Training loss: 0.485895630973821
Validation loss: 2.3905485163617346

Epoch: 6| Step: 1
Training loss: 0.3075581327398441
Validation loss: 2.3743563191577004

Epoch: 6| Step: 2
Training loss: 0.48098040683696774
Validation loss: 2.4204330491743704

Epoch: 6| Step: 3
Training loss: 0.4458181288019023
Validation loss: 2.433259736601634

Epoch: 6| Step: 4
Training loss: 0.737418381975406
Validation loss: 2.4410327923369532

Epoch: 6| Step: 5
Training loss: 0.1878818160944348
Validation loss: 2.4578946585834847

Epoch: 6| Step: 6
Training loss: 0.5993348527654978
Validation loss: 2.5073712550825515

Epoch: 6| Step: 7
Training loss: 0.3654437969181311
Validation loss: 2.482886436698304

Epoch: 6| Step: 8
Training loss: 0.49868513610505233
Validation loss: 2.448775189374273

Epoch: 6| Step: 9
Training loss: 0.5783892362749876
Validation loss: 2.381542448452774

Epoch: 6| Step: 10
Training loss: 0.4832765830228111
Validation loss: 2.4074511822688436

Epoch: 6| Step: 11
Training loss: 0.4662973612286298
Validation loss: 2.4427818148927414

Epoch: 6| Step: 12
Training loss: 0.47806096177932766
Validation loss: 2.443209310877865

Epoch: 6| Step: 13
Training loss: 0.3772514625303562
Validation loss: 2.435752263105959

Epoch: 386| Step: 0
Training loss: 0.4343964303857043
Validation loss: 2.3792224970653573

Epoch: 6| Step: 1
Training loss: 0.5591514577611739
Validation loss: 2.416926060999748

Epoch: 6| Step: 2
Training loss: 0.44644646404377186
Validation loss: 2.441930468123571

Epoch: 6| Step: 3
Training loss: 0.49977552322143537
Validation loss: 2.393516563887466

Epoch: 6| Step: 4
Training loss: 0.2045514382525102
Validation loss: 2.4313314870718825

Epoch: 6| Step: 5
Training loss: 0.38965750088583856
Validation loss: 2.4451301153121374

Epoch: 6| Step: 6
Training loss: 0.4287652956622577
Validation loss: 2.4470168897373603

Epoch: 6| Step: 7
Training loss: 0.5211161481398771
Validation loss: 2.4258191957458903

Epoch: 6| Step: 8
Training loss: 0.5287387622153078
Validation loss: 2.4714078706859515

Epoch: 6| Step: 9
Training loss: 0.8022408186308995
Validation loss: 2.4634474203610606

Epoch: 6| Step: 10
Training loss: 0.5044945232767047
Validation loss: 2.4767023411119786

Epoch: 6| Step: 11
Training loss: 0.4786204476278242
Validation loss: 2.439747353069554

Epoch: 6| Step: 12
Training loss: 0.43108566995579
Validation loss: 2.392127355118725

Epoch: 6| Step: 13
Training loss: 0.17653817287733606
Validation loss: 2.3954469052594005

Epoch: 387| Step: 0
Training loss: 0.4095658912838459
Validation loss: 2.3606176523217544

Epoch: 6| Step: 1
Training loss: 0.2578852001915072
Validation loss: 2.365379132002655

Epoch: 6| Step: 2
Training loss: 0.6135801328076234
Validation loss: 2.3455778015740396

Epoch: 6| Step: 3
Training loss: 0.32206209865110513
Validation loss: 2.3888544556480467

Epoch: 6| Step: 4
Training loss: 0.5578360053060087
Validation loss: 2.409499048295308

Epoch: 6| Step: 5
Training loss: 0.4057961643255808
Validation loss: 2.42859356949288

Epoch: 6| Step: 6
Training loss: 0.4716811881031626
Validation loss: 2.472973414650618

Epoch: 6| Step: 7
Training loss: 0.3429156168836251
Validation loss: 2.4951812767375743

Epoch: 6| Step: 8
Training loss: 0.4928078450797683
Validation loss: 2.49838185189294

Epoch: 6| Step: 9
Training loss: 0.525652398337698
Validation loss: 2.499026585340159

Epoch: 6| Step: 10
Training loss: 0.33194072835807165
Validation loss: 2.4939325948864783

Epoch: 6| Step: 11
Training loss: 0.5470703048733292
Validation loss: 2.4976846135188655

Epoch: 6| Step: 12
Training loss: 0.6201194222477572
Validation loss: 2.4572651970490846

Epoch: 6| Step: 13
Training loss: 0.5701404207415284
Validation loss: 2.4203465111089977

Epoch: 388| Step: 0
Training loss: 0.6264478364510526
Validation loss: 2.423324678239714

Epoch: 6| Step: 1
Training loss: 0.6199995515037268
Validation loss: 2.3929783075037117

Epoch: 6| Step: 2
Training loss: 0.35822181611295095
Validation loss: 2.3937728289142095

Epoch: 6| Step: 3
Training loss: 0.3963564022601019
Validation loss: 2.455786573798877

Epoch: 6| Step: 4
Training loss: 0.5927066419696866
Validation loss: 2.4123515967621825

Epoch: 6| Step: 5
Training loss: 0.2742723798339993
Validation loss: 2.4415981149407093

Epoch: 6| Step: 6
Training loss: 0.48070214968141745
Validation loss: 2.4091680173389523

Epoch: 6| Step: 7
Training loss: 0.4141130236624807
Validation loss: 2.4064037091186377

Epoch: 6| Step: 8
Training loss: 0.5188903297065773
Validation loss: 2.4369952223719227

Epoch: 6| Step: 9
Training loss: 0.5031362757396642
Validation loss: 2.430799824930743

Epoch: 6| Step: 10
Training loss: 0.6133786749752042
Validation loss: 2.460655731462101

Epoch: 6| Step: 11
Training loss: 0.442170165702821
Validation loss: 2.4742523232838054

Epoch: 6| Step: 12
Training loss: 0.25950834971337083
Validation loss: 2.5151762804495688

Epoch: 6| Step: 13
Training loss: 0.22224732543217818
Validation loss: 2.517291601850566

Epoch: 389| Step: 0
Training loss: 0.3024412766709757
Validation loss: 2.482104426243925

Epoch: 6| Step: 1
Training loss: 0.5764384025029804
Validation loss: 2.5322037544152036

Epoch: 6| Step: 2
Training loss: 0.5042903825857584
Validation loss: 2.493127522731547

Epoch: 6| Step: 3
Training loss: 0.5518456853250143
Validation loss: 2.4616736599312428

Epoch: 6| Step: 4
Training loss: 0.4829620857976099
Validation loss: 2.442897412977049

Epoch: 6| Step: 5
Training loss: 0.4580904432641003
Validation loss: 2.426464220670038

Epoch: 6| Step: 6
Training loss: 0.5397096702028824
Validation loss: 2.4217008847655532

Epoch: 6| Step: 7
Training loss: 0.6212674263979638
Validation loss: 2.403416336155422

Epoch: 6| Step: 8
Training loss: 0.5690261233422135
Validation loss: 2.4095945528266793

Epoch: 6| Step: 9
Training loss: 0.5121281856803703
Validation loss: 2.398419734088311

Epoch: 6| Step: 10
Training loss: 0.21185038088786115
Validation loss: 2.383248206315796

Epoch: 6| Step: 11
Training loss: 0.36315856420641124
Validation loss: 2.410878626698525

Epoch: 6| Step: 12
Training loss: 0.24434929131989955
Validation loss: 2.4520938300518487

Epoch: 6| Step: 13
Training loss: 0.29122131554310304
Validation loss: 2.383839132402651

Epoch: 390| Step: 0
Training loss: 0.6790263149909548
Validation loss: 2.444326911436231

Epoch: 6| Step: 1
Training loss: 0.38764690029642357
Validation loss: 2.433920722627701

Epoch: 6| Step: 2
Training loss: 0.6054106653716365
Validation loss: 2.452149229963971

Epoch: 6| Step: 3
Training loss: 0.32106144503582934
Validation loss: 2.398717752378082

Epoch: 6| Step: 4
Training loss: 0.4199987474207138
Validation loss: 2.430670078546526

Epoch: 6| Step: 5
Training loss: 0.4619239177015446
Validation loss: 2.4553916277339565

Epoch: 6| Step: 6
Training loss: 0.12167008210503921
Validation loss: 2.460305249157232

Epoch: 6| Step: 7
Training loss: 0.5120642856793515
Validation loss: 2.453469735998743

Epoch: 6| Step: 8
Training loss: 0.2936948678853473
Validation loss: 2.4266738574352957

Epoch: 6| Step: 9
Training loss: 0.5893221690102517
Validation loss: 2.45800352169721

Epoch: 6| Step: 10
Training loss: 0.31850020681251745
Validation loss: 2.4520397085969203

Epoch: 6| Step: 11
Training loss: 0.2522749213487251
Validation loss: 2.452058927150894

Epoch: 6| Step: 12
Training loss: 0.45557391292360894
Validation loss: 2.4140129175857754

Epoch: 6| Step: 13
Training loss: 0.5428146582754356
Validation loss: 2.411221437138701

Epoch: 391| Step: 0
Training loss: 0.5500025012219516
Validation loss: 2.460985985437968

Epoch: 6| Step: 1
Training loss: 0.559564081127362
Validation loss: 2.4287621161258657

Epoch: 6| Step: 2
Training loss: 0.47349390568884797
Validation loss: 2.489357172456783

Epoch: 6| Step: 3
Training loss: 0.1971414760798895
Validation loss: 2.4690916511142382

Epoch: 6| Step: 4
Training loss: 0.5473718838181598
Validation loss: 2.4742166118589988

Epoch: 6| Step: 5
Training loss: 0.48292323944296967
Validation loss: 2.421333682787613

Epoch: 6| Step: 6
Training loss: 0.4314964364303599
Validation loss: 2.420518382035002

Epoch: 6| Step: 7
Training loss: 0.12033577932208579
Validation loss: 2.4203568785752605

Epoch: 6| Step: 8
Training loss: 0.578845425806872
Validation loss: 2.418465967829053

Epoch: 6| Step: 9
Training loss: 0.15644933383454807
Validation loss: 2.473884351538438

Epoch: 6| Step: 10
Training loss: 0.5175537391531948
Validation loss: 2.4268641775398967

Epoch: 6| Step: 11
Training loss: 0.45912814222175025
Validation loss: 2.4000898343111308

Epoch: 6| Step: 12
Training loss: 0.48838653955136935
Validation loss: 2.4024249591602373

Epoch: 6| Step: 13
Training loss: 0.4469535105102989
Validation loss: 2.4389025783846825

Epoch: 392| Step: 0
Training loss: 0.6052467185195022
Validation loss: 2.420372133117435

Epoch: 6| Step: 1
Training loss: 0.4064840596183332
Validation loss: 2.431793175159085

Epoch: 6| Step: 2
Training loss: 0.3291202279522572
Validation loss: 2.4543047084587597

Epoch: 6| Step: 3
Training loss: 0.23972316562383583
Validation loss: 2.4128565829563673

Epoch: 6| Step: 4
Training loss: 0.4256004509589129
Validation loss: 2.3934990356475314

Epoch: 6| Step: 5
Training loss: 0.2524938916185118
Validation loss: 2.4067607268910525

Epoch: 6| Step: 6
Training loss: 0.4554903349170292
Validation loss: 2.4499767431277455

Epoch: 6| Step: 7
Training loss: 0.7419335985059444
Validation loss: 2.432913209611524

Epoch: 6| Step: 8
Training loss: 0.3605306950303917
Validation loss: 2.4578837089037475

Epoch: 6| Step: 9
Training loss: 0.5379712212711049
Validation loss: 2.4382810127591563

Epoch: 6| Step: 10
Training loss: 0.4357837665713614
Validation loss: 2.423072319443833

Epoch: 6| Step: 11
Training loss: 0.46246463150674405
Validation loss: 2.4070865107711823

Epoch: 6| Step: 12
Training loss: 0.3113989865441206
Validation loss: 2.393417368316248

Epoch: 6| Step: 13
Training loss: 0.425352160323493
Validation loss: 2.4263156379336297

Epoch: 393| Step: 0
Training loss: 0.2397190552670879
Validation loss: 2.4170200289699957

Epoch: 6| Step: 1
Training loss: 0.49520042667755704
Validation loss: 2.404880189718432

Epoch: 6| Step: 2
Training loss: 0.5123850728478275
Validation loss: 2.413219512465367

Epoch: 6| Step: 3
Training loss: 0.5388877143005907
Validation loss: 2.383157734074646

Epoch: 6| Step: 4
Training loss: 0.4304107820835472
Validation loss: 2.364762181318939

Epoch: 6| Step: 5
Training loss: 0.42517750483288863
Validation loss: 2.4085468739886733

Epoch: 6| Step: 6
Training loss: 0.4317663018418693
Validation loss: 2.390342135889313

Epoch: 6| Step: 7
Training loss: 0.25247766171684216
Validation loss: 2.398085434426914

Epoch: 6| Step: 8
Training loss: 0.5643985022280317
Validation loss: 2.406192855039211

Epoch: 6| Step: 9
Training loss: 0.3910732367847641
Validation loss: 2.4217995654692537

Epoch: 6| Step: 10
Training loss: 0.17441540532807312
Validation loss: 2.3897819450737274

Epoch: 6| Step: 11
Training loss: 0.4820848438263454
Validation loss: 2.4227515755009366

Epoch: 6| Step: 12
Training loss: 0.5287630549413168
Validation loss: 2.420587438363418

Epoch: 6| Step: 13
Training loss: 0.44193302218737035
Validation loss: 2.4448027679870674

Epoch: 394| Step: 0
Training loss: 0.4923293953670066
Validation loss: 2.475600050197308

Epoch: 6| Step: 1
Training loss: 0.4292846525220841
Validation loss: 2.496583499146174

Epoch: 6| Step: 2
Training loss: 0.5105516067203894
Validation loss: 2.44792272968017

Epoch: 6| Step: 3
Training loss: 0.4201878259950616
Validation loss: 2.4521949430969205

Epoch: 6| Step: 4
Training loss: 0.2275662712888951
Validation loss: 2.454736798104858

Epoch: 6| Step: 5
Training loss: 0.6306992318704094
Validation loss: 2.433203674814384

Epoch: 6| Step: 6
Training loss: 0.4552699000132369
Validation loss: 2.4325284078301492

Epoch: 6| Step: 7
Training loss: 0.33297966533296486
Validation loss: 2.468109154642099

Epoch: 6| Step: 8
Training loss: 0.23492453840983113
Validation loss: 2.4582464648778157

Epoch: 6| Step: 9
Training loss: 0.5761174321719397
Validation loss: 2.4465142155760167

Epoch: 6| Step: 10
Training loss: 0.4635038699767307
Validation loss: 2.419548493910264

Epoch: 6| Step: 11
Training loss: 0.33831434198142696
Validation loss: 2.4645550197323427

Epoch: 6| Step: 12
Training loss: 0.5099140988729083
Validation loss: 2.4945772583993535

Epoch: 6| Step: 13
Training loss: 0.3935555204851219
Validation loss: 2.4662134564708094

Epoch: 395| Step: 0
Training loss: 0.5526227804698952
Validation loss: 2.494843633079976

Epoch: 6| Step: 1
Training loss: 0.377863718036666
Validation loss: 2.4855881701629072

Epoch: 6| Step: 2
Training loss: 0.29581111462976123
Validation loss: 2.4572901868515573

Epoch: 6| Step: 3
Training loss: 0.5238201393924015
Validation loss: 2.4571947833430743

Epoch: 6| Step: 4
Training loss: 0.4031856395150449
Validation loss: 2.466717027445531

Epoch: 6| Step: 5
Training loss: 0.20137826276748919
Validation loss: 2.4793704972752475

Epoch: 6| Step: 6
Training loss: 0.4062014330663528
Validation loss: 2.4953274926108344

Epoch: 6| Step: 7
Training loss: 0.5057009887178731
Validation loss: 2.4888051425298054

Epoch: 6| Step: 8
Training loss: 0.6446038407571427
Validation loss: 2.424807533632959

Epoch: 6| Step: 9
Training loss: 0.43636839842139563
Validation loss: 2.4539988215317505

Epoch: 6| Step: 10
Training loss: 0.5439007670655744
Validation loss: 2.454921582096964

Epoch: 6| Step: 11
Training loss: 0.307046936935101
Validation loss: 2.376604617565193

Epoch: 6| Step: 12
Training loss: 0.4299765914821887
Validation loss: 2.4151599318492516

Epoch: 6| Step: 13
Training loss: 0.4592772989761749
Validation loss: 2.410227196567751

Epoch: 396| Step: 0
Training loss: 0.39840840252112203
Validation loss: 2.3914103442208745

Epoch: 6| Step: 1
Training loss: 0.5572034165809587
Validation loss: 2.3971911892522653

Epoch: 6| Step: 2
Training loss: 0.3229299460521128
Validation loss: 2.3882715022512477

Epoch: 6| Step: 3
Training loss: 0.4571459699582233
Validation loss: 2.482615526772436

Epoch: 6| Step: 4
Training loss: 0.43726015328450707
Validation loss: 2.4704276537728753

Epoch: 6| Step: 5
Training loss: 0.3431741920326622
Validation loss: 2.4823911679864645

Epoch: 6| Step: 6
Training loss: 0.440059176144903
Validation loss: 2.497040949869364

Epoch: 6| Step: 7
Training loss: 0.4410899556638978
Validation loss: 2.4614228165425045

Epoch: 6| Step: 8
Training loss: 0.2866870082986564
Validation loss: 2.4768661510068535

Epoch: 6| Step: 9
Training loss: 0.6094037073660474
Validation loss: 2.4652760098713045

Epoch: 6| Step: 10
Training loss: 0.6106853091425409
Validation loss: 2.4608285057150225

Epoch: 6| Step: 11
Training loss: 0.4190703341088183
Validation loss: 2.412574959411352

Epoch: 6| Step: 12
Training loss: 0.376081357941165
Validation loss: 2.3866467705457195

Epoch: 6| Step: 13
Training loss: 0.41456019881731404
Validation loss: 2.3666773068635

Epoch: 397| Step: 0
Training loss: 0.5397140325000281
Validation loss: 2.360274761238089

Epoch: 6| Step: 1
Training loss: 0.5695798949933402
Validation loss: 2.314411133561391

Epoch: 6| Step: 2
Training loss: 0.5515864553463561
Validation loss: 2.3521235431112424

Epoch: 6| Step: 3
Training loss: 0.4555816484295353
Validation loss: 2.304660128011507

Epoch: 6| Step: 4
Training loss: 0.497712819883048
Validation loss: 2.323294835922421

Epoch: 6| Step: 5
Training loss: 0.27057191109982914
Validation loss: 2.399354584131449

Epoch: 6| Step: 6
Training loss: 0.35984932653733276
Validation loss: 2.499867549074286

Epoch: 6| Step: 7
Training loss: 0.5944711421703253
Validation loss: 2.5227253938152447

Epoch: 6| Step: 8
Training loss: 0.5413164755192185
Validation loss: 2.5525136806208235

Epoch: 6| Step: 9
Training loss: 0.6252222142960838
Validation loss: 2.581726452386838

Epoch: 6| Step: 10
Training loss: 0.5396777525763166
Validation loss: 2.5910714021553036

Epoch: 6| Step: 11
Training loss: 0.36135010523569555
Validation loss: 2.5082984555452783

Epoch: 6| Step: 12
Training loss: 0.3137737541021419
Validation loss: 2.5306482565768276

Epoch: 6| Step: 13
Training loss: 0.394800377634751
Validation loss: 2.4792168924881945

Epoch: 398| Step: 0
Training loss: 0.4368583708505685
Validation loss: 2.421585830007099

Epoch: 6| Step: 1
Training loss: 0.5400006520302686
Validation loss: 2.3533280617984516

Epoch: 6| Step: 2
Training loss: 0.41944542402962887
Validation loss: 2.3383067434394507

Epoch: 6| Step: 3
Training loss: 0.5374844715181865
Validation loss: 2.3631740240987864

Epoch: 6| Step: 4
Training loss: 0.4145362231390863
Validation loss: 2.346158156253733

Epoch: 6| Step: 5
Training loss: 0.3922933617992651
Validation loss: 2.3696304214144854

Epoch: 6| Step: 6
Training loss: 0.4266347118359786
Validation loss: 2.377654586322265

Epoch: 6| Step: 7
Training loss: 0.3736712837254438
Validation loss: 2.4641098490779005

Epoch: 6| Step: 8
Training loss: 0.614052330301729
Validation loss: 2.4468030226933544

Epoch: 6| Step: 9
Training loss: 0.3895075646156792
Validation loss: 2.5104946467657103

Epoch: 6| Step: 10
Training loss: 0.5534182250825185
Validation loss: 2.542986886176692

Epoch: 6| Step: 11
Training loss: 0.5717809401740278
Validation loss: 2.5021399096955244

Epoch: 6| Step: 12
Training loss: 0.5916403887738299
Validation loss: 2.5422462362052385

Epoch: 6| Step: 13
Training loss: 0.47793564194499794
Validation loss: 2.4603178260776737

Epoch: 399| Step: 0
Training loss: 0.5490563077800005
Validation loss: 2.4182136097963616

Epoch: 6| Step: 1
Training loss: 0.446148055023046
Validation loss: 2.432505789722915

Epoch: 6| Step: 2
Training loss: 0.31739480802902276
Validation loss: 2.354354430473533

Epoch: 6| Step: 3
Training loss: 0.324560881112783
Validation loss: 2.356004705450946

Epoch: 6| Step: 4
Training loss: 0.3266053317696222
Validation loss: 2.351667154441926

Epoch: 6| Step: 5
Training loss: 0.4097167794176793
Validation loss: 2.356629341232428

Epoch: 6| Step: 6
Training loss: 0.3701741116917367
Validation loss: 2.3586792202783924

Epoch: 6| Step: 7
Training loss: 0.44074233095937076
Validation loss: 2.3511419503802813

Epoch: 6| Step: 8
Training loss: 0.5263636488078957
Validation loss: 2.36760245893934

Epoch: 6| Step: 9
Training loss: 0.358093693448332
Validation loss: 2.4133119399650447

Epoch: 6| Step: 10
Training loss: 0.6469207858039218
Validation loss: 2.4301750211801396

Epoch: 6| Step: 11
Training loss: 0.48824339147666973
Validation loss: 2.4240429138797555

Epoch: 6| Step: 12
Training loss: 0.5553391886294056
Validation loss: 2.4228683906044144

Epoch: 6| Step: 13
Training loss: 0.6464457428329301
Validation loss: 2.4423383931197136

Epoch: 400| Step: 0
Training loss: 0.2711318217431034
Validation loss: 2.4280887647670095

Epoch: 6| Step: 1
Training loss: 0.5028279025585651
Validation loss: 2.4298006465382933

Epoch: 6| Step: 2
Training loss: 0.4827205027117939
Validation loss: 2.4074199944665717

Epoch: 6| Step: 3
Training loss: 0.3258789025919145
Validation loss: 2.42705465964665

Epoch: 6| Step: 4
Training loss: 0.6467805397246174
Validation loss: 2.422350496155928

Epoch: 6| Step: 5
Training loss: 0.4408293135387018
Validation loss: 2.436925510095036

Epoch: 6| Step: 6
Training loss: 0.4652457382390271
Validation loss: 2.401236668584993

Epoch: 6| Step: 7
Training loss: 0.4994637623845607
Validation loss: 2.42513674164535

Epoch: 6| Step: 8
Training loss: 0.32861188687032944
Validation loss: 2.467872208119078

Epoch: 6| Step: 9
Training loss: 0.3319675159993399
Validation loss: 2.4934927503257853

Epoch: 6| Step: 10
Training loss: 0.29618826291271194
Validation loss: 2.4889979948475602

Epoch: 6| Step: 11
Training loss: 0.5691497131753102
Validation loss: 2.5019443836465958

Epoch: 6| Step: 12
Training loss: 0.4456840437499782
Validation loss: 2.5340547987565407

Epoch: 6| Step: 13
Training loss: 0.4568694716822269
Validation loss: 2.5000207477139336

Epoch: 401| Step: 0
Training loss: 0.3966936395427571
Validation loss: 2.4281635763178726

Epoch: 6| Step: 1
Training loss: 0.475487998575286
Validation loss: 2.4841417928209517

Epoch: 6| Step: 2
Training loss: 0.4977636541767083
Validation loss: 2.4560005593837175

Epoch: 6| Step: 3
Training loss: 0.2822226157786933
Validation loss: 2.42450802589595

Epoch: 6| Step: 4
Training loss: 0.3525527993693355
Validation loss: 2.438763322903187

Epoch: 6| Step: 5
Training loss: 0.2860708592755997
Validation loss: 2.4083141289378305

Epoch: 6| Step: 6
Training loss: 0.48257102668362406
Validation loss: 2.4035400730700367

Epoch: 6| Step: 7
Training loss: 0.36816928364013735
Validation loss: 2.427781530416005

Epoch: 6| Step: 8
Training loss: 0.642149785366021
Validation loss: 2.399575616546339

Epoch: 6| Step: 9
Training loss: 0.2920114899956478
Validation loss: 2.3691970070080743

Epoch: 6| Step: 10
Training loss: 0.22672086968407068
Validation loss: 2.381235475985449

Epoch: 6| Step: 11
Training loss: 0.2384416868684673
Validation loss: 2.3751383073535695

Epoch: 6| Step: 12
Training loss: 0.6425952851111518
Validation loss: 2.4033180665455793

Epoch: 6| Step: 13
Training loss: 0.6036636516671989
Validation loss: 2.4053379328458897

Epoch: 402| Step: 0
Training loss: 0.5287835704346082
Validation loss: 2.398982119910628

Epoch: 6| Step: 1
Training loss: 0.4302491072513023
Validation loss: 2.4106343267318864

Epoch: 6| Step: 2
Training loss: 0.5183108631192365
Validation loss: 2.3929087040349937

Epoch: 6| Step: 3
Training loss: 0.536779795011152
Validation loss: 2.426488146808782

Epoch: 6| Step: 4
Training loss: 0.4224522844152352
Validation loss: 2.457635344173917

Epoch: 6| Step: 5
Training loss: 0.28205371302284266
Validation loss: 2.4222527343366353

Epoch: 6| Step: 6
Training loss: 0.3079356407123333
Validation loss: 2.4418446614723477

Epoch: 6| Step: 7
Training loss: 0.2604344012261694
Validation loss: 2.436170525178526

Epoch: 6| Step: 8
Training loss: 0.32274137117683804
Validation loss: 2.4478497892489512

Epoch: 6| Step: 9
Training loss: 0.3068230444750792
Validation loss: 2.4528282837275652

Epoch: 6| Step: 10
Training loss: 0.4735522801470909
Validation loss: 2.4448488161411865

Epoch: 6| Step: 11
Training loss: 0.5905136195121417
Validation loss: 2.4605110529485117

Epoch: 6| Step: 12
Training loss: 0.31317397395157964
Validation loss: 2.460857372734147

Epoch: 6| Step: 13
Training loss: 0.3401258109285276
Validation loss: 2.4760868123804065

Epoch: 403| Step: 0
Training loss: 0.45334228699037143
Validation loss: 2.423314295964768

Epoch: 6| Step: 1
Training loss: 0.27941966525443784
Validation loss: 2.3702383250374077

Epoch: 6| Step: 2
Training loss: 0.35381310944672323
Validation loss: 2.3621920424253546

Epoch: 6| Step: 3
Training loss: 0.337183438295184
Validation loss: 2.364221411191223

Epoch: 6| Step: 4
Training loss: 0.5218085663592719
Validation loss: 2.3723865868742005

Epoch: 6| Step: 5
Training loss: 0.22257826091779614
Validation loss: 2.405988209417351

Epoch: 6| Step: 6
Training loss: 0.4173059288262824
Validation loss: 2.4515124600893663

Epoch: 6| Step: 7
Training loss: 0.6347205043308523
Validation loss: 2.5434489803524487

Epoch: 6| Step: 8
Training loss: 0.7641938905917497
Validation loss: 2.5741065275967316

Epoch: 6| Step: 9
Training loss: 0.4079883685849909
Validation loss: 2.569834334829733

Epoch: 6| Step: 10
Training loss: 0.4737606701869679
Validation loss: 2.503665499052102

Epoch: 6| Step: 11
Training loss: 0.44147612432203515
Validation loss: 2.4594827175493426

Epoch: 6| Step: 12
Training loss: 0.4077686023105742
Validation loss: 2.39838159427927

Epoch: 6| Step: 13
Training loss: 0.4089625472079865
Validation loss: 2.41069053479338

Epoch: 404| Step: 0
Training loss: 0.6147796888314652
Validation loss: 2.417842251973847

Epoch: 6| Step: 1
Training loss: 0.26248127609413757
Validation loss: 2.3554764230532053

Epoch: 6| Step: 2
Training loss: 0.43387901956998187
Validation loss: 2.360170950113005

Epoch: 6| Step: 3
Training loss: 0.32700367471835007
Validation loss: 2.3878864433866984

Epoch: 6| Step: 4
Training loss: 0.45951546318593284
Validation loss: 2.4380541650841154

Epoch: 6| Step: 5
Training loss: 0.3525351949463776
Validation loss: 2.453280182546531

Epoch: 6| Step: 6
Training loss: 0.5930969260579091
Validation loss: 2.495730084331399

Epoch: 6| Step: 7
Training loss: 0.36020175538787036
Validation loss: 2.5131064048725253

Epoch: 6| Step: 8
Training loss: 0.45200093378333467
Validation loss: 2.502968966383385

Epoch: 6| Step: 9
Training loss: 0.48644086764210337
Validation loss: 2.513004602125542

Epoch: 6| Step: 10
Training loss: 0.42064198693469834
Validation loss: 2.435927349385339

Epoch: 6| Step: 11
Training loss: 0.31230281330665155
Validation loss: 2.385825694964739

Epoch: 6| Step: 12
Training loss: 0.4146121174038935
Validation loss: 2.3477707952760607

Epoch: 6| Step: 13
Training loss: 0.5257935804533819
Validation loss: 2.33510895122164

Epoch: 405| Step: 0
Training loss: 0.2410566477432378
Validation loss: 2.324552622021483

Epoch: 6| Step: 1
Training loss: 0.5491005435241332
Validation loss: 2.352448979589788

Epoch: 6| Step: 2
Training loss: 0.36469469640278573
Validation loss: 2.3603012895084565

Epoch: 6| Step: 3
Training loss: 0.2615014497888175
Validation loss: 2.410167590954408

Epoch: 6| Step: 4
Training loss: 0.4753317653104931
Validation loss: 2.4468722015793585

Epoch: 6| Step: 5
Training loss: 0.5137074099241129
Validation loss: 2.436064703286546

Epoch: 6| Step: 6
Training loss: 0.42417181819730326
Validation loss: 2.455871067095523

Epoch: 6| Step: 7
Training loss: 0.7063250729655564
Validation loss: 2.4392900380794633

Epoch: 6| Step: 8
Training loss: 0.43467140307812724
Validation loss: 2.5186968598993866

Epoch: 6| Step: 9
Training loss: 0.2222898463374585
Validation loss: 2.4495126883759117

Epoch: 6| Step: 10
Training loss: 0.296722862512454
Validation loss: 2.435193082652021

Epoch: 6| Step: 11
Training loss: 0.4466694685980942
Validation loss: 2.4062119006691303

Epoch: 6| Step: 12
Training loss: 0.5057114786288763
Validation loss: 2.395659017619402

Epoch: 6| Step: 13
Training loss: 0.4730570173869404
Validation loss: 2.4168740265950412

Epoch: 406| Step: 0
Training loss: 0.3130235339707818
Validation loss: 2.4247758020217804

Epoch: 6| Step: 1
Training loss: 0.38187550683620053
Validation loss: 2.442138706910482

Epoch: 6| Step: 2
Training loss: 0.4430569865297642
Validation loss: 2.444022682338314

Epoch: 6| Step: 3
Training loss: 0.5554713768232984
Validation loss: 2.477131986254516

Epoch: 6| Step: 4
Training loss: 0.4438910971891505
Validation loss: 2.486875262820275

Epoch: 6| Step: 5
Training loss: 0.2960143287249745
Validation loss: 2.501034942849025

Epoch: 6| Step: 6
Training loss: 0.45887060175663263
Validation loss: 2.555184756870782

Epoch: 6| Step: 7
Training loss: 0.49096914904470584
Validation loss: 2.48391786707366

Epoch: 6| Step: 8
Training loss: 0.464888530465571
Validation loss: 2.4700019074491966

Epoch: 6| Step: 9
Training loss: 0.5569354431025318
Validation loss: 2.401056050238007

Epoch: 6| Step: 10
Training loss: 0.2836780643444538
Validation loss: 2.3819764987754715

Epoch: 6| Step: 11
Training loss: 0.4885817861723907
Validation loss: 2.3905950870528505

Epoch: 6| Step: 12
Training loss: 0.296496174694364
Validation loss: 2.443584540457162

Epoch: 6| Step: 13
Training loss: 0.3189041531618629
Validation loss: 2.35733186612313

Epoch: 407| Step: 0
Training loss: 0.4508064077884046
Validation loss: 2.4127476825139773

Epoch: 6| Step: 1
Training loss: 0.2036178734716612
Validation loss: 2.4569542372566144

Epoch: 6| Step: 2
Training loss: 0.5888293303155577
Validation loss: 2.490502984175736

Epoch: 6| Step: 3
Training loss: 0.49803528117728807
Validation loss: 2.480923271700689

Epoch: 6| Step: 4
Training loss: 0.341825157085336
Validation loss: 2.4824595503157436

Epoch: 6| Step: 5
Training loss: 0.6003980637376811
Validation loss: 2.546549617421708

Epoch: 6| Step: 6
Training loss: 0.3758705881555684
Validation loss: 2.553805718862657

Epoch: 6| Step: 7
Training loss: 0.48750395895499726
Validation loss: 2.542528743250898

Epoch: 6| Step: 8
Training loss: 0.2810388938384326
Validation loss: 2.55331384168258

Epoch: 6| Step: 9
Training loss: 0.4365524521301489
Validation loss: 2.4979864892483468

Epoch: 6| Step: 10
Training loss: 0.2522118888227075
Validation loss: 2.510881381873472

Epoch: 6| Step: 11
Training loss: 0.3997584865544779
Validation loss: 2.499130235136392

Epoch: 6| Step: 12
Training loss: 0.2810349171824575
Validation loss: 2.4631221696521006

Epoch: 6| Step: 13
Training loss: 0.6094744429999922
Validation loss: 2.522009409350868

Epoch: 408| Step: 0
Training loss: 0.4958882394277661
Validation loss: 2.5037460604821034

Epoch: 6| Step: 1
Training loss: 0.35794117208988163
Validation loss: 2.4706604692832634

Epoch: 6| Step: 2
Training loss: 0.3356232837015095
Validation loss: 2.4861980417381697

Epoch: 6| Step: 3
Training loss: 0.5845031985251673
Validation loss: 2.491061780064776

Epoch: 6| Step: 4
Training loss: 0.6728638314289854
Validation loss: 2.4931011450766243

Epoch: 6| Step: 5
Training loss: 0.47594388302525925
Validation loss: 2.4744637593592853

Epoch: 6| Step: 6
Training loss: 0.3467757938042059
Validation loss: 2.487560082518666

Epoch: 6| Step: 7
Training loss: 0.35402831947069385
Validation loss: 2.4624422685722633

Epoch: 6| Step: 8
Training loss: 0.5008650687261065
Validation loss: 2.4511604988969267

Epoch: 6| Step: 9
Training loss: 0.2762505382860558
Validation loss: 2.467944066482961

Epoch: 6| Step: 10
Training loss: 0.3034965641708651
Validation loss: 2.402191694602961

Epoch: 6| Step: 11
Training loss: 0.3534708890481742
Validation loss: 2.420532792498031

Epoch: 6| Step: 12
Training loss: 0.39291039444996345
Validation loss: 2.406977773174323

Epoch: 6| Step: 13
Training loss: 0.41093652166678
Validation loss: 2.43040904711526

Epoch: 409| Step: 0
Training loss: 0.35377720381127364
Validation loss: 2.446079212973658

Epoch: 6| Step: 1
Training loss: 0.46565713963539784
Validation loss: 2.4236624904889505

Epoch: 6| Step: 2
Training loss: 0.6742189462601784
Validation loss: 2.426471692991419

Epoch: 6| Step: 3
Training loss: 0.327148676630189
Validation loss: 2.404798140269278

Epoch: 6| Step: 4
Training loss: 0.5727432913418538
Validation loss: 2.416553642832225

Epoch: 6| Step: 5
Training loss: 0.40495565433612346
Validation loss: 2.4067128437754706

Epoch: 6| Step: 6
Training loss: 0.5447387934666049
Validation loss: 2.4280097871271176

Epoch: 6| Step: 7
Training loss: 0.24862559833234057
Validation loss: 2.4277071965447004

Epoch: 6| Step: 8
Training loss: 0.2412661902277331
Validation loss: 2.4298444120297726

Epoch: 6| Step: 9
Training loss: 0.13719532193757938
Validation loss: 2.490310190756992

Epoch: 6| Step: 10
Training loss: 0.33620811252907434
Validation loss: 2.4824150022551943

Epoch: 6| Step: 11
Training loss: 0.25921621517990795
Validation loss: 2.4779181710823703

Epoch: 6| Step: 12
Training loss: 0.21396274260930448
Validation loss: 2.473063231596115

Epoch: 6| Step: 13
Training loss: 0.48903826205608597
Validation loss: 2.482505720954574

Epoch: 410| Step: 0
Training loss: 0.3936602164645017
Validation loss: 2.4979743349512593

Epoch: 6| Step: 1
Training loss: 0.2910645846971491
Validation loss: 2.4541926634363054

Epoch: 6| Step: 2
Training loss: 0.4298679666412443
Validation loss: 2.483364438089742

Epoch: 6| Step: 3
Training loss: 0.2409823257095987
Validation loss: 2.4565982260627646

Epoch: 6| Step: 4
Training loss: 0.3445106240670413
Validation loss: 2.4388813010115857

Epoch: 6| Step: 5
Training loss: 0.3467260195437193
Validation loss: 2.427369977289197

Epoch: 6| Step: 6
Training loss: 0.4260220677811855
Validation loss: 2.4687711699992834

Epoch: 6| Step: 7
Training loss: 0.48213027913726986
Validation loss: 2.448780266869441

Epoch: 6| Step: 8
Training loss: 0.5377509983768178
Validation loss: 2.432083906943945

Epoch: 6| Step: 9
Training loss: 0.3669279276736824
Validation loss: 2.4713759853403046

Epoch: 6| Step: 10
Training loss: 0.4582251580055702
Validation loss: 2.4465269487937173

Epoch: 6| Step: 11
Training loss: 0.15716743542151815
Validation loss: 2.4654688913055414

Epoch: 6| Step: 12
Training loss: 0.45344489414277744
Validation loss: 2.4613851358562746

Epoch: 6| Step: 13
Training loss: 0.5664673870897525
Validation loss: 2.462680403774093

Epoch: 411| Step: 0
Training loss: 0.38589063274894647
Validation loss: 2.440929555906366

Epoch: 6| Step: 1
Training loss: 0.28535827900360083
Validation loss: 2.5085853201388675

Epoch: 6| Step: 2
Training loss: 0.21719742621921892
Validation loss: 2.508322603215499

Epoch: 6| Step: 3
Training loss: 0.43905742207913345
Validation loss: 2.490330457384021

Epoch: 6| Step: 4
Training loss: 0.33864365166405597
Validation loss: 2.47846487330087

Epoch: 6| Step: 5
Training loss: 0.42275141704035335
Validation loss: 2.472033042424444

Epoch: 6| Step: 6
Training loss: 0.39835141691887416
Validation loss: 2.481779360466271

Epoch: 6| Step: 7
Training loss: 0.26377785989774494
Validation loss: 2.4808537971213935

Epoch: 6| Step: 8
Training loss: 0.4798290056393658
Validation loss: 2.5335876019753396

Epoch: 6| Step: 9
Training loss: 0.4538699964532754
Validation loss: 2.5288067603388904

Epoch: 6| Step: 10
Training loss: 0.28933781323108815
Validation loss: 2.5305056128772474

Epoch: 6| Step: 11
Training loss: 0.420915590011986
Validation loss: 2.5035835505977615

Epoch: 6| Step: 12
Training loss: 0.46134187450155617
Validation loss: 2.515571650231904

Epoch: 6| Step: 13
Training loss: 0.5161793358865353
Validation loss: 2.4873434102304457

Epoch: 412| Step: 0
Training loss: 0.36265230596617337
Validation loss: 2.4409258831014604

Epoch: 6| Step: 1
Training loss: 0.39341415281461584
Validation loss: 2.4756336747103327

Epoch: 6| Step: 2
Training loss: 0.3847849110063825
Validation loss: 2.3743632563502723

Epoch: 6| Step: 3
Training loss: 0.5193783527913308
Validation loss: 2.3929264947923534

Epoch: 6| Step: 4
Training loss: 0.4727235856445949
Validation loss: 2.383706075203617

Epoch: 6| Step: 5
Training loss: 0.45339438224866085
Validation loss: 2.406154027100175

Epoch: 6| Step: 6
Training loss: 0.36959056579812827
Validation loss: 2.398360025829335

Epoch: 6| Step: 7
Training loss: 0.52118711535907
Validation loss: 2.4344926682060706

Epoch: 6| Step: 8
Training loss: 0.40760887733400136
Validation loss: 2.4104202840410998

Epoch: 6| Step: 9
Training loss: 0.369049323361134
Validation loss: 2.453612729050418

Epoch: 6| Step: 10
Training loss: 0.3252017504538807
Validation loss: 2.55450456259111

Epoch: 6| Step: 11
Training loss: 0.400075220694538
Validation loss: 2.5415670754300317

Epoch: 6| Step: 12
Training loss: 0.36574852804799074
Validation loss: 2.5549743276575825

Epoch: 6| Step: 13
Training loss: 0.14663467326048854
Validation loss: 2.51923664619018

Epoch: 413| Step: 0
Training loss: 0.4693104254828769
Validation loss: 2.49097023161539

Epoch: 6| Step: 1
Training loss: 0.583353243783211
Validation loss: 2.447979344543235

Epoch: 6| Step: 2
Training loss: 0.40268598278730233
Validation loss: 2.4960174515506264

Epoch: 6| Step: 3
Training loss: 0.17408977062064515
Validation loss: 2.421492172613046

Epoch: 6| Step: 4
Training loss: 0.4200450450436054
Validation loss: 2.4037112659286106

Epoch: 6| Step: 5
Training loss: 0.6074361032861815
Validation loss: 2.3774856713788606

Epoch: 6| Step: 6
Training loss: 0.5289477784209399
Validation loss: 2.3928505879962265

Epoch: 6| Step: 7
Training loss: 0.34492867140160105
Validation loss: 2.381680816125211

Epoch: 6| Step: 8
Training loss: 0.4178745484482325
Validation loss: 2.423086963349642

Epoch: 6| Step: 9
Training loss: 0.32620762155149596
Validation loss: 2.445771270336698

Epoch: 6| Step: 10
Training loss: 0.21616999747698634
Validation loss: 2.5203686757722394

Epoch: 6| Step: 11
Training loss: 0.28206463560702844
Validation loss: 2.502361931291906

Epoch: 6| Step: 12
Training loss: 0.43020205466220046
Validation loss: 2.5453862254624564

Epoch: 6| Step: 13
Training loss: 0.2629632965583195
Validation loss: 2.5493818797441956

Epoch: 414| Step: 0
Training loss: 0.3965675755289469
Validation loss: 2.478063394932981

Epoch: 6| Step: 1
Training loss: 0.4520686101786635
Validation loss: 2.4643311721723418

Epoch: 6| Step: 2
Training loss: 0.2700553166714889
Validation loss: 2.4131262655230663

Epoch: 6| Step: 3
Training loss: 0.3933487724989119
Validation loss: 2.380421690835118

Epoch: 6| Step: 4
Training loss: 0.34245624701323957
Validation loss: 2.3967072054608556

Epoch: 6| Step: 5
Training loss: 0.33903011395881777
Validation loss: 2.342990717800126

Epoch: 6| Step: 6
Training loss: 0.3982747998618852
Validation loss: 2.390897250237696

Epoch: 6| Step: 7
Training loss: 0.54356614874196
Validation loss: 2.37575344619171

Epoch: 6| Step: 8
Training loss: 0.4199432545032176
Validation loss: 2.4054847377230915

Epoch: 6| Step: 9
Training loss: 0.49435661329952496
Validation loss: 2.4196672563270125

Epoch: 6| Step: 10
Training loss: 0.31606633565746645
Validation loss: 2.447217519842361

Epoch: 6| Step: 11
Training loss: 0.25881815332973707
Validation loss: 2.455343089772646

Epoch: 6| Step: 12
Training loss: 0.46649485757575376
Validation loss: 2.4955152391030175

Epoch: 6| Step: 13
Training loss: 0.3602113321678483
Validation loss: 2.497304837713266

Epoch: 415| Step: 0
Training loss: 0.16762860367070972
Validation loss: 2.494988081376672

Epoch: 6| Step: 1
Training loss: 0.507387306028429
Validation loss: 2.5012813391587603

Epoch: 6| Step: 2
Training loss: 0.3393168146087819
Validation loss: 2.5264237127118205

Epoch: 6| Step: 3
Training loss: 0.4881824851285797
Validation loss: 2.477401150939166

Epoch: 6| Step: 4
Training loss: 0.23556151463198013
Validation loss: 2.465617585053743

Epoch: 6| Step: 5
Training loss: 0.21861019946546717
Validation loss: 2.426319792474033

Epoch: 6| Step: 6
Training loss: 0.46088994314263104
Validation loss: 2.4132950409735208

Epoch: 6| Step: 7
Training loss: 0.41292868432469926
Validation loss: 2.372657114654291

Epoch: 6| Step: 8
Training loss: 0.44926643118532106
Validation loss: 2.364388960998502

Epoch: 6| Step: 9
Training loss: 0.29649635059561724
Validation loss: 2.4168236702345394

Epoch: 6| Step: 10
Training loss: 0.30943032839236273
Validation loss: 2.4162424982601034

Epoch: 6| Step: 11
Training loss: 0.45773958269950366
Validation loss: 2.4534393019325833

Epoch: 6| Step: 12
Training loss: 0.4504013748407978
Validation loss: 2.4437185706284965

Epoch: 6| Step: 13
Training loss: 0.551181377326274
Validation loss: 2.457427868771619

Epoch: 416| Step: 0
Training loss: 0.39557667827345416
Validation loss: 2.5137572251673435

Epoch: 6| Step: 1
Training loss: 0.5738746234707272
Validation loss: 2.4745520536786385

Epoch: 6| Step: 2
Training loss: 0.39546557542362465
Validation loss: 2.4524408644072344

Epoch: 6| Step: 3
Training loss: 0.3387675729817599
Validation loss: 2.4395894922561046

Epoch: 6| Step: 4
Training loss: 0.3036456513227088
Validation loss: 2.4336956185028176

Epoch: 6| Step: 5
Training loss: 0.3845613004869402
Validation loss: 2.422091551859902

Epoch: 6| Step: 6
Training loss: 0.3322841242329843
Validation loss: 2.374681534542617

Epoch: 6| Step: 7
Training loss: 0.38605913106601086
Validation loss: 2.375425953601685

Epoch: 6| Step: 8
Training loss: 0.34893356301752965
Validation loss: 2.3700647289886048

Epoch: 6| Step: 9
Training loss: 0.4028901399258513
Validation loss: 2.354923660909577

Epoch: 6| Step: 10
Training loss: 0.36736439441222435
Validation loss: 2.3264606498025775

Epoch: 6| Step: 11
Training loss: 0.28684124785438575
Validation loss: 2.382099109239045

Epoch: 6| Step: 12
Training loss: 0.45135058542088746
Validation loss: 2.38768472590942

Epoch: 6| Step: 13
Training loss: 0.3031349485278872
Validation loss: 2.460644517976737

Epoch: 417| Step: 0
Training loss: 0.4813098213865282
Validation loss: 2.4524958738933913

Epoch: 6| Step: 1
Training loss: 0.37110997214748503
Validation loss: 2.485099800778011

Epoch: 6| Step: 2
Training loss: 0.2387974416572184
Validation loss: 2.523052929299162

Epoch: 6| Step: 3
Training loss: 0.5354111614265868
Validation loss: 2.52884204604622

Epoch: 6| Step: 4
Training loss: 0.35244683197825677
Validation loss: 2.5393439771249815

Epoch: 6| Step: 5
Training loss: 0.21187332746245063
Validation loss: 2.538517181928637

Epoch: 6| Step: 6
Training loss: 0.26480953479409497
Validation loss: 2.5240757617991227

Epoch: 6| Step: 7
Training loss: 0.4277697161005007
Validation loss: 2.4911289076244603

Epoch: 6| Step: 8
Training loss: 0.25575501737958745
Validation loss: 2.461409003239441

Epoch: 6| Step: 9
Training loss: 0.34562035555762805
Validation loss: 2.406687744237965

Epoch: 6| Step: 10
Training loss: 0.42003855304089355
Validation loss: 2.4178789964269116

Epoch: 6| Step: 11
Training loss: 0.31393615211867293
Validation loss: 2.359791760768984

Epoch: 6| Step: 12
Training loss: 0.6457420766612396
Validation loss: 2.3367894585897577

Epoch: 6| Step: 13
Training loss: 0.3096094076699012
Validation loss: 2.3273011361890052

Epoch: 418| Step: 0
Training loss: 0.45910857123298837
Validation loss: 2.349240358800423

Epoch: 6| Step: 1
Training loss: 0.44473557159452626
Validation loss: 2.375136855607497

Epoch: 6| Step: 2
Training loss: 0.31180993421978087
Validation loss: 2.3853774342685075

Epoch: 6| Step: 3
Training loss: 0.4428352248903152
Validation loss: 2.4241455136858354

Epoch: 6| Step: 4
Training loss: 0.25566687877435684
Validation loss: 2.458580569527461

Epoch: 6| Step: 5
Training loss: 0.27926772972572633
Validation loss: 2.489764954318866

Epoch: 6| Step: 6
Training loss: 0.4517538932237763
Validation loss: 2.4212612129854865

Epoch: 6| Step: 7
Training loss: 0.37916328128239585
Validation loss: 2.4875041768086428

Epoch: 6| Step: 8
Training loss: 0.3274151412391582
Validation loss: 2.4529099473025955

Epoch: 6| Step: 9
Training loss: 0.4674954793068897
Validation loss: 2.430266971556804

Epoch: 6| Step: 10
Training loss: 0.19388501170100433
Validation loss: 2.4440622376610825

Epoch: 6| Step: 11
Training loss: 0.39396133428096675
Validation loss: 2.413413696842164

Epoch: 6| Step: 12
Training loss: 0.42041283228927456
Validation loss: 2.4009097134694146

Epoch: 6| Step: 13
Training loss: 0.15933534114732592
Validation loss: 2.4019150751744953

Epoch: 419| Step: 0
Training loss: 0.3826179009781904
Validation loss: 2.3749578808998795

Epoch: 6| Step: 1
Training loss: 0.39662038415218004
Validation loss: 2.3847810561434453

Epoch: 6| Step: 2
Training loss: 0.4383468266079527
Validation loss: 2.371277251657862

Epoch: 6| Step: 3
Training loss: 0.16355932367175668
Validation loss: 2.3624042225712873

Epoch: 6| Step: 4
Training loss: 0.38432771190266424
Validation loss: 2.4049680523458856

Epoch: 6| Step: 5
Training loss: 0.26830713132813805
Validation loss: 2.407035181741848

Epoch: 6| Step: 6
Training loss: 0.36651724657174134
Validation loss: 2.3901219164033947

Epoch: 6| Step: 7
Training loss: 0.317395418356931
Validation loss: 2.4066854955673915

Epoch: 6| Step: 8
Training loss: 0.4230393836149776
Validation loss: 2.4388213508411223

Epoch: 6| Step: 9
Training loss: 0.3017123289921479
Validation loss: 2.4339140120652525

Epoch: 6| Step: 10
Training loss: 0.43343895219533457
Validation loss: 2.4543248765209587

Epoch: 6| Step: 11
Training loss: 0.4398996754625376
Validation loss: 2.4381248213896454

Epoch: 6| Step: 12
Training loss: 0.49139787518228595
Validation loss: 2.440657225594299

Epoch: 6| Step: 13
Training loss: 0.22472615730491802
Validation loss: 2.4409532929946147

Epoch: 420| Step: 0
Training loss: 0.35811951305187145
Validation loss: 2.4248050004479182

Epoch: 6| Step: 1
Training loss: 0.47446241576031734
Validation loss: 2.4147555446973086

Epoch: 6| Step: 2
Training loss: 0.3521330971320069
Validation loss: 2.3776725429717165

Epoch: 6| Step: 3
Training loss: 0.2584178349256223
Validation loss: 2.399668753317921

Epoch: 6| Step: 4
Training loss: 0.2586910566051823
Validation loss: 2.390843408719968

Epoch: 6| Step: 5
Training loss: 0.4634672991071647
Validation loss: 2.400592021833359

Epoch: 6| Step: 6
Training loss: 0.3211536411945202
Validation loss: 2.4328367769504258

Epoch: 6| Step: 7
Training loss: 0.3161628870420576
Validation loss: 2.4419138154764357

Epoch: 6| Step: 8
Training loss: 0.4078876608795852
Validation loss: 2.445280843665666

Epoch: 6| Step: 9
Training loss: 0.35714923904030266
Validation loss: 2.4658944669230136

Epoch: 6| Step: 10
Training loss: 0.3057996187262906
Validation loss: 2.4972772461150003

Epoch: 6| Step: 11
Training loss: 0.335982807563972
Validation loss: 2.4737976088502935

Epoch: 6| Step: 12
Training loss: 0.540018201980409
Validation loss: 2.4592516011237278

Epoch: 6| Step: 13
Training loss: 0.42358882142748827
Validation loss: 2.4418604111764846

Epoch: 421| Step: 0
Training loss: 0.24612512085796856
Validation loss: 2.419856981735264

Epoch: 6| Step: 1
Training loss: 0.3647732194774573
Validation loss: 2.4354094629460046

Epoch: 6| Step: 2
Training loss: 0.33859707183335047
Validation loss: 2.4502872774511255

Epoch: 6| Step: 3
Training loss: 0.4334403617285859
Validation loss: 2.430718822318327

Epoch: 6| Step: 4
Training loss: 0.4650929528308822
Validation loss: 2.452841611793285

Epoch: 6| Step: 5
Training loss: 0.22930488247512357
Validation loss: 2.3972853495680653

Epoch: 6| Step: 6
Training loss: 0.19779493118296507
Validation loss: 2.430785538613235

Epoch: 6| Step: 7
Training loss: 0.4766683304642048
Validation loss: 2.394280354516673

Epoch: 6| Step: 8
Training loss: 0.274737266181226
Validation loss: 2.3395418690741763

Epoch: 6| Step: 9
Training loss: 0.34004386403277875
Validation loss: 2.38379999332609

Epoch: 6| Step: 10
Training loss: 0.3757050760194313
Validation loss: 2.3674657741957015

Epoch: 6| Step: 11
Training loss: 0.5040811929943732
Validation loss: 2.4009534471576255

Epoch: 6| Step: 12
Training loss: 0.3623003895137061
Validation loss: 2.365193231474307

Epoch: 6| Step: 13
Training loss: 0.29685356665086654
Validation loss: 2.3420213763140483

Epoch: 422| Step: 0
Training loss: 0.2115364049598119
Validation loss: 2.4534368819034285

Epoch: 6| Step: 1
Training loss: 0.3220521508828047
Validation loss: 2.4239428343008718

Epoch: 6| Step: 2
Training loss: 0.34680786986774037
Validation loss: 2.435256965094645

Epoch: 6| Step: 3
Training loss: 0.3317779809230759
Validation loss: 2.471026072192112

Epoch: 6| Step: 4
Training loss: 0.5735484772026219
Validation loss: 2.4784165482687928

Epoch: 6| Step: 5
Training loss: 0.30654468371837296
Validation loss: 2.510562185499278

Epoch: 6| Step: 6
Training loss: 0.2978187668051936
Validation loss: 2.544174930269194

Epoch: 6| Step: 7
Training loss: 0.3211615289029876
Validation loss: 2.4676409735975664

Epoch: 6| Step: 8
Training loss: 0.3669198663821695
Validation loss: 2.4543429125277756

Epoch: 6| Step: 9
Training loss: 0.4117374097442922
Validation loss: 2.448281928053545

Epoch: 6| Step: 10
Training loss: 0.5057600652944256
Validation loss: 2.4147004833846033

Epoch: 6| Step: 11
Training loss: 0.426056029521465
Validation loss: 2.3925763227411196

Epoch: 6| Step: 12
Training loss: 0.19750926580000397
Validation loss: 2.4212927238411

Epoch: 6| Step: 13
Training loss: 0.36448416950767704
Validation loss: 2.418758488600687

Epoch: 423| Step: 0
Training loss: 0.31358333207308764
Validation loss: 2.406350650288423

Epoch: 6| Step: 1
Training loss: 0.45704272655195266
Validation loss: 2.465692395921402

Epoch: 6| Step: 2
Training loss: 0.2639177941642633
Validation loss: 2.451364046499418

Epoch: 6| Step: 3
Training loss: 0.3820718490153158
Validation loss: 2.4716059545478495

Epoch: 6| Step: 4
Training loss: 0.278609316503833
Validation loss: 2.4617065540607204

Epoch: 6| Step: 5
Training loss: 0.2988420869644772
Validation loss: 2.4749354462104667

Epoch: 6| Step: 6
Training loss: 0.3137315918928978
Validation loss: 2.4883413618092995

Epoch: 6| Step: 7
Training loss: 0.28893278407564477
Validation loss: 2.470274283708996

Epoch: 6| Step: 8
Training loss: 0.41611001461728053
Validation loss: 2.4194552980437467

Epoch: 6| Step: 9
Training loss: 0.6134987706558359
Validation loss: 2.3938580974198813

Epoch: 6| Step: 10
Training loss: 0.5467054649236883
Validation loss: 2.4282135370337237

Epoch: 6| Step: 11
Training loss: 0.2648146835626066
Validation loss: 2.434323838552099

Epoch: 6| Step: 12
Training loss: 0.4836708919396236
Validation loss: 2.4340367636641687

Epoch: 6| Step: 13
Training loss: 0.3650233020921424
Validation loss: 2.4763811844156773

Epoch: 424| Step: 0
Training loss: 0.406001712046147
Validation loss: 2.393948528301881

Epoch: 6| Step: 1
Training loss: 0.48605590310021757
Validation loss: 2.4689579838820452

Epoch: 6| Step: 2
Training loss: 0.2062658881801339
Validation loss: 2.4915827204021403

Epoch: 6| Step: 3
Training loss: 0.2697880668596358
Validation loss: 2.5199806727669087

Epoch: 6| Step: 4
Training loss: 0.41789269869538226
Validation loss: 2.559603575095635

Epoch: 6| Step: 5
Training loss: 0.4894138627923824
Validation loss: 2.5770416101467126

Epoch: 6| Step: 6
Training loss: 0.4496319404726025
Validation loss: 2.561078599534185

Epoch: 6| Step: 7
Training loss: 0.20113557654737677
Validation loss: 2.5330137571858833

Epoch: 6| Step: 8
Training loss: 0.26762409233035556
Validation loss: 2.554153253054723

Epoch: 6| Step: 9
Training loss: 0.38659639060392376
Validation loss: 2.4860750357662007

Epoch: 6| Step: 10
Training loss: 0.45641756834461483
Validation loss: 2.4266734591565586

Epoch: 6| Step: 11
Training loss: 0.19361915861914317
Validation loss: 2.462452707627218

Epoch: 6| Step: 12
Training loss: 0.5997802789032607
Validation loss: 2.45030797973507

Epoch: 6| Step: 13
Training loss: 0.462120542286512
Validation loss: 2.433916911797301

Epoch: 425| Step: 0
Training loss: 0.5899695963218766
Validation loss: 2.4302845626762215

Epoch: 6| Step: 1
Training loss: 0.5007663456786258
Validation loss: 2.3787227807525038

Epoch: 6| Step: 2
Training loss: 0.39135089185838995
Validation loss: 2.3665735198545628

Epoch: 6| Step: 3
Training loss: 0.4816222726461025
Validation loss: 2.381100800688854

Epoch: 6| Step: 4
Training loss: 0.3056522525541166
Validation loss: 2.4131625644170285

Epoch: 6| Step: 5
Training loss: 0.29246880152999727
Validation loss: 2.447022546044782

Epoch: 6| Step: 6
Training loss: 0.34352159497970924
Validation loss: 2.4623928045279144

Epoch: 6| Step: 7
Training loss: 0.33753796734768515
Validation loss: 2.4955136074946402

Epoch: 6| Step: 8
Training loss: 0.4160551670248269
Validation loss: 2.5078079989777553

Epoch: 6| Step: 9
Training loss: 0.24299178857528064
Validation loss: 2.505662151236175

Epoch: 6| Step: 10
Training loss: 0.38014159422445176
Validation loss: 2.44184008767162

Epoch: 6| Step: 11
Training loss: 0.21747412019258497
Validation loss: 2.431189739584402

Epoch: 6| Step: 12
Training loss: 0.3081122637934957
Validation loss: 2.4242285453339902

Epoch: 6| Step: 13
Training loss: 0.3209702321477851
Validation loss: 2.4110318259452495

Epoch: 426| Step: 0
Training loss: 0.47129022224242473
Validation loss: 2.4053853999618573

Epoch: 6| Step: 1
Training loss: 0.3584206181868382
Validation loss: 2.395321278114209

Epoch: 6| Step: 2
Training loss: 0.3880719870146311
Validation loss: 2.3960402878613114

Epoch: 6| Step: 3
Training loss: 0.353051444638404
Validation loss: 2.4162479051255445

Epoch: 6| Step: 4
Training loss: 0.3794884878342422
Validation loss: 2.3780684605049065

Epoch: 6| Step: 5
Training loss: 0.19764124168741903
Validation loss: 2.392546448120141

Epoch: 6| Step: 6
Training loss: 0.4279183640890557
Validation loss: 2.40098488819534

Epoch: 6| Step: 7
Training loss: 0.27504386443649065
Validation loss: 2.42814006367073

Epoch: 6| Step: 8
Training loss: 0.2386167774817025
Validation loss: 2.460478834155395

Epoch: 6| Step: 9
Training loss: 0.4946292075093172
Validation loss: 2.4683834118917396

Epoch: 6| Step: 10
Training loss: 0.46362298259363033
Validation loss: 2.479447746388285

Epoch: 6| Step: 11
Training loss: 0.2540432487035185
Validation loss: 2.476704982174445

Epoch: 6| Step: 12
Training loss: 0.470032891456726
Validation loss: 2.4914470802889355

Epoch: 6| Step: 13
Training loss: 0.15202912829997492
Validation loss: 2.492919085939713

Epoch: 427| Step: 0
Training loss: 0.4139542348140768
Validation loss: 2.5115169040303553

Epoch: 6| Step: 1
Training loss: 0.25832848499475825
Validation loss: 2.477919606064596

Epoch: 6| Step: 2
Training loss: 0.39423670963317103
Validation loss: 2.452927830672124

Epoch: 6| Step: 3
Training loss: 0.3264718189915007
Validation loss: 2.441425590061166

Epoch: 6| Step: 4
Training loss: 0.43439627602155073
Validation loss: 2.4186948455748447

Epoch: 6| Step: 5
Training loss: 0.17355110833604867
Validation loss: 2.39848937750467

Epoch: 6| Step: 6
Training loss: 0.5030643023727457
Validation loss: 2.3934133425029653

Epoch: 6| Step: 7
Training loss: 0.4507900290072333
Validation loss: 2.3925633511517206

Epoch: 6| Step: 8
Training loss: 0.31016466624181804
Validation loss: 2.4047970667543526

Epoch: 6| Step: 9
Training loss: 0.33799184264406673
Validation loss: 2.391805654976843

Epoch: 6| Step: 10
Training loss: 0.2783417275204218
Validation loss: 2.44584424838414

Epoch: 6| Step: 11
Training loss: 0.20039055770367242
Validation loss: 2.443584180605155

Epoch: 6| Step: 12
Training loss: 0.3788540401079192
Validation loss: 2.446774633711756

Epoch: 6| Step: 13
Training loss: 0.08002441628768185
Validation loss: 2.4793437499158903

Epoch: 428| Step: 0
Training loss: 0.36350618597352674
Validation loss: 2.4566154971423098

Epoch: 6| Step: 1
Training loss: 0.43529003422171975
Validation loss: 2.4909209295985337

Epoch: 6| Step: 2
Training loss: 0.37689303378708966
Validation loss: 2.486568575051013

Epoch: 6| Step: 3
Training loss: 0.19972129155289084
Validation loss: 2.4957506972833

Epoch: 6| Step: 4
Training loss: 0.2470493156949973
Validation loss: 2.451012333850603

Epoch: 6| Step: 5
Training loss: 0.2517310353933011
Validation loss: 2.447743855391617

Epoch: 6| Step: 6
Training loss: 0.3231056593487573
Validation loss: 2.436448737172847

Epoch: 6| Step: 7
Training loss: 0.3753697440128443
Validation loss: 2.410001500525416

Epoch: 6| Step: 8
Training loss: 0.48359106060013607
Validation loss: 2.4236981080046545

Epoch: 6| Step: 9
Training loss: 0.3328010163094518
Validation loss: 2.494406260588944

Epoch: 6| Step: 10
Training loss: 0.43192608055085124
Validation loss: 2.480297287529741

Epoch: 6| Step: 11
Training loss: 0.13030581322215795
Validation loss: 2.459150260891864

Epoch: 6| Step: 12
Training loss: 0.35420953500520885
Validation loss: 2.4915468519739745

Epoch: 6| Step: 13
Training loss: 0.3977985120113539
Validation loss: 2.4488433619821612

Epoch: 429| Step: 0
Training loss: 0.2574586318174271
Validation loss: 2.4639028392711166

Epoch: 6| Step: 1
Training loss: 0.41390234170971535
Validation loss: 2.4228703718986297

Epoch: 6| Step: 2
Training loss: 0.2944288743686281
Validation loss: 2.4413439151148397

Epoch: 6| Step: 3
Training loss: 0.4421747320373969
Validation loss: 2.368359486016504

Epoch: 6| Step: 4
Training loss: 0.26404423735177196
Validation loss: 2.3671322971847824

Epoch: 6| Step: 5
Training loss: 0.21830906023864416
Validation loss: 2.3818066116418843

Epoch: 6| Step: 6
Training loss: 0.38941537488528155
Validation loss: 2.3845619007880385

Epoch: 6| Step: 7
Training loss: 0.34009126441087223
Validation loss: 2.4049158039815333

Epoch: 6| Step: 8
Training loss: 0.3683431983866598
Validation loss: 2.441166234841815

Epoch: 6| Step: 9
Training loss: 0.15669340162571335
Validation loss: 2.3992788235379647

Epoch: 6| Step: 10
Training loss: 0.16622297577346198
Validation loss: 2.3972544845430233

Epoch: 6| Step: 11
Training loss: 0.48836446434472863
Validation loss: 2.4675379517065488

Epoch: 6| Step: 12
Training loss: 0.3475635812245594
Validation loss: 2.450617166527311

Epoch: 6| Step: 13
Training loss: 0.3527550286786886
Validation loss: 2.4610622938853686

Epoch: 430| Step: 0
Training loss: 0.20589715802731093
Validation loss: 2.4488928432254133

Epoch: 6| Step: 1
Training loss: 0.23755256046134898
Validation loss: 2.4701531377799126

Epoch: 6| Step: 2
Training loss: 0.18919086984859979
Validation loss: 2.4625422399402463

Epoch: 6| Step: 3
Training loss: 0.3604822929626104
Validation loss: 2.417137372431599

Epoch: 6| Step: 4
Training loss: 0.36384905259566147
Validation loss: 2.390861663052899

Epoch: 6| Step: 5
Training loss: 0.35451896293131646
Validation loss: 2.3950860115698958

Epoch: 6| Step: 6
Training loss: 0.3241475957901066
Validation loss: 2.3933464692030917

Epoch: 6| Step: 7
Training loss: 0.3129128589897945
Validation loss: 2.3865693207375624

Epoch: 6| Step: 8
Training loss: 0.2965132366300726
Validation loss: 2.385704361355209

Epoch: 6| Step: 9
Training loss: 0.4433751376538726
Validation loss: 2.4015466605089437

Epoch: 6| Step: 10
Training loss: 0.1546374076114644
Validation loss: 2.4385964951400245

Epoch: 6| Step: 11
Training loss: 0.5189736607984741
Validation loss: 2.3932956504797325

Epoch: 6| Step: 12
Training loss: 0.4424257741786928
Validation loss: 2.428180094159469

Epoch: 6| Step: 13
Training loss: 0.4863418209491375
Validation loss: 2.4481133152702155

Epoch: 431| Step: 0
Training loss: 0.37997423655610635
Validation loss: 2.4664135353501817

Epoch: 6| Step: 1
Training loss: 0.285094960040479
Validation loss: 2.482765019710763

Epoch: 6| Step: 2
Training loss: 0.34303373794230313
Validation loss: 2.4140477540931458

Epoch: 6| Step: 3
Training loss: 0.30818255105625825
Validation loss: 2.4146738339930414

Epoch: 6| Step: 4
Training loss: 0.2840851826524133
Validation loss: 2.439462668276251

Epoch: 6| Step: 5
Training loss: 0.37060609196747457
Validation loss: 2.442321216317761

Epoch: 6| Step: 6
Training loss: 0.31543320692242527
Validation loss: 2.5003051971449843

Epoch: 6| Step: 7
Training loss: 0.4433759274522767
Validation loss: 2.4765317627770234

Epoch: 6| Step: 8
Training loss: 0.40755343411580286
Validation loss: 2.455787334815227

Epoch: 6| Step: 9
Training loss: 0.26686110107446165
Validation loss: 2.4394514582594526

Epoch: 6| Step: 10
Training loss: 0.3084884294823965
Validation loss: 2.44767404495885

Epoch: 6| Step: 11
Training loss: 0.15782429820988894
Validation loss: 2.4326833448389373

Epoch: 6| Step: 12
Training loss: 0.4815589352871246
Validation loss: 2.387555127097192

Epoch: 6| Step: 13
Training loss: 0.144284837320838
Validation loss: 2.3914243109976616

Epoch: 432| Step: 0
Training loss: 0.4215631391946006
Validation loss: 2.4213408887800485

Epoch: 6| Step: 1
Training loss: 0.18103713616130004
Validation loss: 2.4475071301120157

Epoch: 6| Step: 2
Training loss: 0.21452592402749193
Validation loss: 2.4165540735439572

Epoch: 6| Step: 3
Training loss: 0.41948686290331
Validation loss: 2.419571295390235

Epoch: 6| Step: 4
Training loss: 0.15413633275810887
Validation loss: 2.450816437040829

Epoch: 6| Step: 5
Training loss: 0.274801327183939
Validation loss: 2.4103533561053316

Epoch: 6| Step: 6
Training loss: 0.44979844215287823
Validation loss: 2.4427903502652972

Epoch: 6| Step: 7
Training loss: 0.3293763663211113
Validation loss: 2.419608805052572

Epoch: 6| Step: 8
Training loss: 0.19876143380631175
Validation loss: 2.4681723113345506

Epoch: 6| Step: 9
Training loss: 0.2777532858117719
Validation loss: 2.4464951719489156

Epoch: 6| Step: 10
Training loss: 0.47233447637107845
Validation loss: 2.4241046096524306

Epoch: 6| Step: 11
Training loss: 0.2687734371877543
Validation loss: 2.4887519440558084

Epoch: 6| Step: 12
Training loss: 0.41174674689925017
Validation loss: 2.482930870984913

Epoch: 6| Step: 13
Training loss: 0.26494486068683915
Validation loss: 2.4461872237728697

Epoch: 433| Step: 0
Training loss: 0.4145067279175324
Validation loss: 2.4719959237804177

Epoch: 6| Step: 1
Training loss: 0.3807919173532892
Validation loss: 2.483203112363514

Epoch: 6| Step: 2
Training loss: 0.3557978144472423
Validation loss: 2.445801760774462

Epoch: 6| Step: 3
Training loss: 0.3079098595915096
Validation loss: 2.4155223619220845

Epoch: 6| Step: 4
Training loss: 0.35174080247858197
Validation loss: 2.4286632448962004

Epoch: 6| Step: 5
Training loss: 0.2782700878134371
Validation loss: 2.4572873898174534

Epoch: 6| Step: 6
Training loss: 0.25180396758579016
Validation loss: 2.391890428233102

Epoch: 6| Step: 7
Training loss: 0.46436918701702523
Validation loss: 2.455114704783408

Epoch: 6| Step: 8
Training loss: 0.2640636923723556
Validation loss: 2.455111160752418

Epoch: 6| Step: 9
Training loss: 0.23600501837536958
Validation loss: 2.412452172076185

Epoch: 6| Step: 10
Training loss: 0.32207519222192493
Validation loss: 2.439207910633489

Epoch: 6| Step: 11
Training loss: 0.3252614844645475
Validation loss: 2.448655879864315

Epoch: 6| Step: 12
Training loss: 0.40687439691408056
Validation loss: 2.4381578323955555

Epoch: 6| Step: 13
Training loss: 0.3033939191202572
Validation loss: 2.4195050115704717

Epoch: 434| Step: 0
Training loss: 0.2245466227568174
Validation loss: 2.4211044906532937

Epoch: 6| Step: 1
Training loss: 0.47247651521155276
Validation loss: 2.368799752818376

Epoch: 6| Step: 2
Training loss: 0.37162766445833006
Validation loss: 2.3894355222759773

Epoch: 6| Step: 3
Training loss: 0.33871480720253133
Validation loss: 2.3792457297255023

Epoch: 6| Step: 4
Training loss: 0.26754930438459373
Validation loss: 2.382191019091424

Epoch: 6| Step: 5
Training loss: 0.335825690802911
Validation loss: 2.402185001058685

Epoch: 6| Step: 6
Training loss: 0.20432583109533653
Validation loss: 2.4499678717844895

Epoch: 6| Step: 7
Training loss: 0.5164851614583008
Validation loss: 2.4424702759479304

Epoch: 6| Step: 8
Training loss: 0.28783076995616746
Validation loss: 2.4515995016228262

Epoch: 6| Step: 9
Training loss: 0.44143322212385677
Validation loss: 2.461629523037887

Epoch: 6| Step: 10
Training loss: 0.34353635390973664
Validation loss: 2.4639134120818666

Epoch: 6| Step: 11
Training loss: 0.2811570941275958
Validation loss: 2.4784586929542933

Epoch: 6| Step: 12
Training loss: 0.204932424467895
Validation loss: 2.458582749357742

Epoch: 6| Step: 13
Training loss: 0.17669870642365038
Validation loss: 2.453243641766487

Epoch: 435| Step: 0
Training loss: 0.4383945515832683
Validation loss: 2.462753789781003

Epoch: 6| Step: 1
Training loss: 0.19556035527619547
Validation loss: 2.4290183329265114

Epoch: 6| Step: 2
Training loss: 0.12065583694691612
Validation loss: 2.4867142669215774

Epoch: 6| Step: 3
Training loss: 0.26431410951771533
Validation loss: 2.4611499242193426

Epoch: 6| Step: 4
Training loss: 0.4506315488511394
Validation loss: 2.3828455241695514

Epoch: 6| Step: 5
Training loss: 0.4366627072046792
Validation loss: 2.368061689560285

Epoch: 6| Step: 6
Training loss: 0.3915088001458223
Validation loss: 2.421478120938857

Epoch: 6| Step: 7
Training loss: 0.45949368727709317
Validation loss: 2.429176232195237

Epoch: 6| Step: 8
Training loss: 0.33682800520747774
Validation loss: 2.423766627385169

Epoch: 6| Step: 9
Training loss: 0.12038413677023169
Validation loss: 2.4554874145144656

Epoch: 6| Step: 10
Training loss: 0.3395230106103633
Validation loss: 2.4655549930286083

Epoch: 6| Step: 11
Training loss: 0.2729743986849988
Validation loss: 2.471098757504982

Epoch: 6| Step: 12
Training loss: 0.3526167638642393
Validation loss: 2.5097468846012743

Epoch: 6| Step: 13
Training loss: 0.23282408173446678
Validation loss: 2.5188960395258477

Epoch: 436| Step: 0
Training loss: 0.46110972726791705
Validation loss: 2.48460998527988

Epoch: 6| Step: 1
Training loss: 0.4607058120605189
Validation loss: 2.4263443328567433

Epoch: 6| Step: 2
Training loss: 0.3328847461961115
Validation loss: 2.413266194074842

Epoch: 6| Step: 3
Training loss: 0.2121563330810447
Validation loss: 2.420497094512422

Epoch: 6| Step: 4
Training loss: 0.3283802356759993
Validation loss: 2.4184372398508907

Epoch: 6| Step: 5
Training loss: 0.22344702286867765
Validation loss: 2.4112431127533562

Epoch: 6| Step: 6
Training loss: 0.40019159720219616
Validation loss: 2.3801698121276726

Epoch: 6| Step: 7
Training loss: 0.3642141198347136
Validation loss: 2.404593518278752

Epoch: 6| Step: 8
Training loss: 0.38244112646257195
Validation loss: 2.3909456736495827

Epoch: 6| Step: 9
Training loss: 0.28969364597998243
Validation loss: 2.4151325391765983

Epoch: 6| Step: 10
Training loss: 0.28840490237578487
Validation loss: 2.4090089018705214

Epoch: 6| Step: 11
Training loss: 0.35974388263954243
Validation loss: 2.4572034804437934

Epoch: 6| Step: 12
Training loss: 0.23666361176059345
Validation loss: 2.478132596009655

Epoch: 6| Step: 13
Training loss: 0.2897031360714894
Validation loss: 2.5034959140845343

Epoch: 437| Step: 0
Training loss: 0.45482353325393804
Validation loss: 2.4290169265756045

Epoch: 6| Step: 1
Training loss: 0.42987025449262656
Validation loss: 2.364672119553922

Epoch: 6| Step: 2
Training loss: 0.2522118592817486
Validation loss: 2.385601434368668

Epoch: 6| Step: 3
Training loss: 0.2526701549320272
Validation loss: 2.38722136089787

Epoch: 6| Step: 4
Training loss: 0.4049386353568817
Validation loss: 2.362734400032105

Epoch: 6| Step: 5
Training loss: 0.3544766971787219
Validation loss: 2.359681263124829

Epoch: 6| Step: 6
Training loss: 0.41912428938716967
Validation loss: 2.366842469946741

Epoch: 6| Step: 7
Training loss: 0.2250752799937748
Validation loss: 2.4195041066955065

Epoch: 6| Step: 8
Training loss: 0.1787058720105298
Validation loss: 2.47659903262859

Epoch: 6| Step: 9
Training loss: 0.23610553820584268
Validation loss: 2.4701562440535603

Epoch: 6| Step: 10
Training loss: 0.4868208598982509
Validation loss: 2.4921840899537973

Epoch: 6| Step: 11
Training loss: 0.405722312069514
Validation loss: 2.5179013041382583

Epoch: 6| Step: 12
Training loss: 0.6157364749189698
Validation loss: 2.5282272303798132

Epoch: 6| Step: 13
Training loss: 0.36884382719113284
Validation loss: 2.5006971094894466

Epoch: 438| Step: 0
Training loss: 0.3200143845685319
Validation loss: 2.4232455278742933

Epoch: 6| Step: 1
Training loss: 0.2938070130313608
Validation loss: 2.392991850531363

Epoch: 6| Step: 2
Training loss: 0.2407588351223923
Validation loss: 2.3912825977878622

Epoch: 6| Step: 3
Training loss: 0.3563912964743917
Validation loss: 2.3712339371798015

Epoch: 6| Step: 4
Training loss: 0.331187950026708
Validation loss: 2.356665459489392

Epoch: 6| Step: 5
Training loss: 0.3072239739271995
Validation loss: 2.3196803693388555

Epoch: 6| Step: 6
Training loss: 0.4441204177164826
Validation loss: 2.303528650818023

Epoch: 6| Step: 7
Training loss: 0.42237506475163056
Validation loss: 2.3441038973388135

Epoch: 6| Step: 8
Training loss: 0.2498873143746936
Validation loss: 2.3533866129740457

Epoch: 6| Step: 9
Training loss: 0.45460264390733784
Validation loss: 2.4156078231513476

Epoch: 6| Step: 10
Training loss: 0.19073694334803287
Validation loss: 2.4611488028899404

Epoch: 6| Step: 11
Training loss: 0.4846780966923221
Validation loss: 2.4798915510252835

Epoch: 6| Step: 12
Training loss: 0.558115000405606
Validation loss: 2.501441405189125

Epoch: 6| Step: 13
Training loss: 0.2690632945723548
Validation loss: 2.499191205648296

Epoch: 439| Step: 0
Training loss: 0.2942318707668941
Validation loss: 2.495478378310681

Epoch: 6| Step: 1
Training loss: 0.4843180222993338
Validation loss: 2.492496351629274

Epoch: 6| Step: 2
Training loss: 0.44002204520095656
Validation loss: 2.4759373422993964

Epoch: 6| Step: 3
Training loss: 0.34807352676844244
Validation loss: 2.431102211961861

Epoch: 6| Step: 4
Training loss: 0.3673914484999521
Validation loss: 2.408910300618745

Epoch: 6| Step: 5
Training loss: 0.23585101115006152
Validation loss: 2.421699376243561

Epoch: 6| Step: 6
Training loss: 0.16663178933313416
Validation loss: 2.4128160326113073

Epoch: 6| Step: 7
Training loss: 0.4016977883815779
Validation loss: 2.3868866409901064

Epoch: 6| Step: 8
Training loss: 0.45735994566407145
Validation loss: 2.384788914921062

Epoch: 6| Step: 9
Training loss: 0.2550037871575089
Validation loss: 2.3361167382124113

Epoch: 6| Step: 10
Training loss: 0.27273118210920266
Validation loss: 2.320542062680154

Epoch: 6| Step: 11
Training loss: 0.247680257963296
Validation loss: 2.3268161928774416

Epoch: 6| Step: 12
Training loss: 0.3142934832293916
Validation loss: 2.375291869013408

Epoch: 6| Step: 13
Training loss: 0.395086162591741
Validation loss: 2.3674217878998296

Epoch: 440| Step: 0
Training loss: 0.2544397178540122
Validation loss: 2.4577500266743213

Epoch: 6| Step: 1
Training loss: 0.2793359529060207
Validation loss: 2.4392825566797263

Epoch: 6| Step: 2
Training loss: 0.2565881527425057
Validation loss: 2.5145325869316633

Epoch: 6| Step: 3
Training loss: 0.42783730718498153
Validation loss: 2.470192645179742

Epoch: 6| Step: 4
Training loss: 0.53750135510296
Validation loss: 2.48778392362572

Epoch: 6| Step: 5
Training loss: 0.2101507171980305
Validation loss: 2.4576478752992172

Epoch: 6| Step: 6
Training loss: 0.26671775270173903
Validation loss: 2.392115675713868

Epoch: 6| Step: 7
Training loss: 0.20924663131433738
Validation loss: 2.4046797117330914

Epoch: 6| Step: 8
Training loss: 0.20761270563091425
Validation loss: 2.3697622505389755

Epoch: 6| Step: 9
Training loss: 0.2709319305067473
Validation loss: 2.3248747597054407

Epoch: 6| Step: 10
Training loss: 0.349271387148512
Validation loss: 2.357904847740064

Epoch: 6| Step: 11
Training loss: 0.5076834294542111
Validation loss: 2.382388753749384

Epoch: 6| Step: 12
Training loss: 0.3214340114890035
Validation loss: 2.3452862272291064

Epoch: 6| Step: 13
Training loss: 0.4273923263976163
Validation loss: 2.3753582285394677

Epoch: 441| Step: 0
Training loss: 0.4612606984476884
Validation loss: 2.3300380451832488

Epoch: 6| Step: 1
Training loss: 0.2837299970684751
Validation loss: 2.3678352842040926

Epoch: 6| Step: 2
Training loss: 0.2730689835227255
Validation loss: 2.385903240365951

Epoch: 6| Step: 3
Training loss: 0.15431877174008038
Validation loss: 2.3741870626544466

Epoch: 6| Step: 4
Training loss: 0.3569214449587965
Validation loss: 2.3943589698283017

Epoch: 6| Step: 5
Training loss: 0.4399574099052722
Validation loss: 2.4201789996187175

Epoch: 6| Step: 6
Training loss: 0.16024819502803372
Validation loss: 2.455720801887224

Epoch: 6| Step: 7
Training loss: 0.4227517871446694
Validation loss: 2.463128338001113

Epoch: 6| Step: 8
Training loss: 0.3772231207322525
Validation loss: 2.4640399503777943

Epoch: 6| Step: 9
Training loss: 0.36184920807077475
Validation loss: 2.452434877723497

Epoch: 6| Step: 10
Training loss: 0.3824541010151624
Validation loss: 2.444886389928323

Epoch: 6| Step: 11
Training loss: 0.3372585691412478
Validation loss: 2.4065653755833227

Epoch: 6| Step: 12
Training loss: 0.2841637072707386
Validation loss: 2.3653309807273497

Epoch: 6| Step: 13
Training loss: 0.3364410618383205
Validation loss: 2.3802407585328846

Epoch: 442| Step: 0
Training loss: 0.20478333675684066
Validation loss: 2.3831673338936703

Epoch: 6| Step: 1
Training loss: 0.3784647857254291
Validation loss: 2.3700342720596006

Epoch: 6| Step: 2
Training loss: 0.39637318823240025
Validation loss: 2.374051164122886

Epoch: 6| Step: 3
Training loss: 0.24234982403608513
Validation loss: 2.407898282821213

Epoch: 6| Step: 4
Training loss: 0.27187786813297354
Validation loss: 2.4404021225549686

Epoch: 6| Step: 5
Training loss: 0.43886156744896054
Validation loss: 2.43603656696826

Epoch: 6| Step: 6
Training loss: 0.22149396670393404
Validation loss: 2.449687449417208

Epoch: 6| Step: 7
Training loss: 0.23474782854056986
Validation loss: 2.452086992534896

Epoch: 6| Step: 8
Training loss: 0.3275092455417949
Validation loss: 2.4583332419112995

Epoch: 6| Step: 9
Training loss: 0.18967904061020516
Validation loss: 2.482638991271969

Epoch: 6| Step: 10
Training loss: 0.35786735414044807
Validation loss: 2.4852976474627178

Epoch: 6| Step: 11
Training loss: 0.1976328538158045
Validation loss: 2.512926287081024

Epoch: 6| Step: 12
Training loss: 0.44746835769901466
Validation loss: 2.487467544623436

Epoch: 6| Step: 13
Training loss: 0.1842925388396903
Validation loss: 2.4744339331745384

Epoch: 443| Step: 0
Training loss: 0.32832779748158064
Validation loss: 2.4544947107683326

Epoch: 6| Step: 1
Training loss: 0.19265944058266074
Validation loss: 2.426765623550718

Epoch: 6| Step: 2
Training loss: 0.38633547198307333
Validation loss: 2.471930647459439

Epoch: 6| Step: 3
Training loss: 0.3367599134663952
Validation loss: 2.4705870358906057

Epoch: 6| Step: 4
Training loss: 0.5222430764283085
Validation loss: 2.4704599373894114

Epoch: 6| Step: 5
Training loss: 0.2790602501952587
Validation loss: 2.389323639124239

Epoch: 6| Step: 6
Training loss: 0.21806870530621025
Validation loss: 2.3817841622522233

Epoch: 6| Step: 7
Training loss: 0.5387060949840785
Validation loss: 2.3830737114174307

Epoch: 6| Step: 8
Training loss: 0.3409333574443725
Validation loss: 2.4520948316314772

Epoch: 6| Step: 9
Training loss: 0.722199909362745
Validation loss: 2.4360696567856

Epoch: 6| Step: 10
Training loss: 0.37503395324221017
Validation loss: 2.41123382486086

Epoch: 6| Step: 11
Training loss: 0.3967845701084904
Validation loss: 2.439559508191979

Epoch: 6| Step: 12
Training loss: 0.23558262605890418
Validation loss: 2.433536375918634

Epoch: 6| Step: 13
Training loss: 0.330789499211509
Validation loss: 2.4342612212031014

Epoch: 444| Step: 0
Training loss: 0.26009975541641195
Validation loss: 2.427839170374458

Epoch: 6| Step: 1
Training loss: 0.3792058212723243
Validation loss: 2.4620827005995665

Epoch: 6| Step: 2
Training loss: 0.5395895551325264
Validation loss: 2.4714650024952878

Epoch: 6| Step: 3
Training loss: 0.36294201424407263
Validation loss: 2.4589304862679597

Epoch: 6| Step: 4
Training loss: 0.32113680956883855
Validation loss: 2.3886393553220846

Epoch: 6| Step: 5
Training loss: 0.4447840851518042
Validation loss: 2.42358026981363

Epoch: 6| Step: 6
Training loss: 0.31036638016854645
Validation loss: 2.403707117639672

Epoch: 6| Step: 7
Training loss: 0.4995256050991286
Validation loss: 2.4301276611327465

Epoch: 6| Step: 8
Training loss: 0.3994626339803295
Validation loss: 2.4379009782603984

Epoch: 6| Step: 9
Training loss: 0.2426702702163237
Validation loss: 2.4537592242352977

Epoch: 6| Step: 10
Training loss: 0.2985829612982651
Validation loss: 2.4677701485061494

Epoch: 6| Step: 11
Training loss: 0.41629144542434815
Validation loss: 2.503815643205439

Epoch: 6| Step: 12
Training loss: 0.22582243210504338
Validation loss: 2.4800833577990593

Epoch: 6| Step: 13
Training loss: 0.38463040217094796
Validation loss: 2.4345260685925023

Epoch: 445| Step: 0
Training loss: 0.3190239598519963
Validation loss: 2.438026335636653

Epoch: 6| Step: 1
Training loss: 0.3014324372238346
Validation loss: 2.46217506544417

Epoch: 6| Step: 2
Training loss: 0.33413456445513084
Validation loss: 2.5206063281158055

Epoch: 6| Step: 3
Training loss: 0.5401017771722901
Validation loss: 2.5158995484463036

Epoch: 6| Step: 4
Training loss: 0.3984022498899819
Validation loss: 2.5447640850197084

Epoch: 6| Step: 5
Training loss: 0.5245390730596338
Validation loss: 2.5301663383077955

Epoch: 6| Step: 6
Training loss: 0.2729792979254489
Validation loss: 2.5037517637210627

Epoch: 6| Step: 7
Training loss: 0.24712029053383386
Validation loss: 2.4581206973471996

Epoch: 6| Step: 8
Training loss: 0.364702050998277
Validation loss: 2.422892563870289

Epoch: 6| Step: 9
Training loss: 0.2563041577445469
Validation loss: 2.346860483383358

Epoch: 6| Step: 10
Training loss: 0.3105239499825173
Validation loss: 2.3393791148683354

Epoch: 6| Step: 11
Training loss: 0.29363494151659086
Validation loss: 2.3664640917804998

Epoch: 6| Step: 12
Training loss: 0.407939405901761
Validation loss: 2.3594233477976

Epoch: 6| Step: 13
Training loss: 0.5416993595918782
Validation loss: 2.3590284377009967

Epoch: 446| Step: 0
Training loss: 0.49093740139091563
Validation loss: 2.3703298717304047

Epoch: 6| Step: 1
Training loss: 0.2797781259342512
Validation loss: 2.38941214084912

Epoch: 6| Step: 2
Training loss: 0.35530193313144676
Validation loss: 2.4525701897246632

Epoch: 6| Step: 3
Training loss: 0.4191848141430758
Validation loss: 2.4650397519783063

Epoch: 6| Step: 4
Training loss: 0.3403200122785252
Validation loss: 2.5029739062874548

Epoch: 6| Step: 5
Training loss: 0.2182981729466812
Validation loss: 2.5089843371531124

Epoch: 6| Step: 6
Training loss: 0.4619359662465731
Validation loss: 2.5026181662715357

Epoch: 6| Step: 7
Training loss: 0.2788609123245316
Validation loss: 2.4624787691536905

Epoch: 6| Step: 8
Training loss: 0.22820338901189768
Validation loss: 2.405037050981492

Epoch: 6| Step: 9
Training loss: 0.4255361814155025
Validation loss: 2.4232379752516606

Epoch: 6| Step: 10
Training loss: 0.2618239461801288
Validation loss: 2.3601454153566905

Epoch: 6| Step: 11
Training loss: 0.21471206790995856
Validation loss: 2.386035945379693

Epoch: 6| Step: 12
Training loss: 0.29024882068854446
Validation loss: 2.385203147266903

Epoch: 6| Step: 13
Training loss: 0.45573454899107263
Validation loss: 2.349747446488276

Epoch: 447| Step: 0
Training loss: 0.4334531676438607
Validation loss: 2.375875488684291

Epoch: 6| Step: 1
Training loss: 0.1964188711136816
Validation loss: 2.443247285519166

Epoch: 6| Step: 2
Training loss: 0.39179346800033066
Validation loss: 2.512034749521075

Epoch: 6| Step: 3
Training loss: 0.28563932756428
Validation loss: 2.523084029490541

Epoch: 6| Step: 4
Training loss: 0.35324780978666487
Validation loss: 2.570423549588714

Epoch: 6| Step: 5
Training loss: 0.29010173492964825
Validation loss: 2.5281482217596483

Epoch: 6| Step: 6
Training loss: 0.4895088632909232
Validation loss: 2.5628745422844457

Epoch: 6| Step: 7
Training loss: 0.36760726229469604
Validation loss: 2.5179922646514292

Epoch: 6| Step: 8
Training loss: 0.29391838026389944
Validation loss: 2.4950942667497187

Epoch: 6| Step: 9
Training loss: 0.298930368821323
Validation loss: 2.4692137970374053

Epoch: 6| Step: 10
Training loss: 0.1982052021571846
Validation loss: 2.438490669189019

Epoch: 6| Step: 11
Training loss: 0.29321052747245824
Validation loss: 2.3918689523755905

Epoch: 6| Step: 12
Training loss: 0.43113822525081535
Validation loss: 2.3950227274768907

Epoch: 6| Step: 13
Training loss: 0.35939295350715195
Validation loss: 2.3636911973463044

Epoch: 448| Step: 0
Training loss: 0.265270248706241
Validation loss: 2.40511578049549

Epoch: 6| Step: 1
Training loss: 0.1759351215828534
Validation loss: 2.380415932274309

Epoch: 6| Step: 2
Training loss: 0.4388939584903356
Validation loss: 2.4147307198585177

Epoch: 6| Step: 3
Training loss: 0.4457196332062502
Validation loss: 2.4277169818796476

Epoch: 6| Step: 4
Training loss: 0.31035980252081546
Validation loss: 2.4351502378672465

Epoch: 6| Step: 5
Training loss: 0.428484150679105
Validation loss: 2.4576123054295396

Epoch: 6| Step: 6
Training loss: 0.22981372790181048
Validation loss: 2.4479405960732175

Epoch: 6| Step: 7
Training loss: 0.23316375553457921
Validation loss: 2.4799182728348446

Epoch: 6| Step: 8
Training loss: 0.4201071042349817
Validation loss: 2.4769650310046223

Epoch: 6| Step: 9
Training loss: 0.2920703336831249
Validation loss: 2.4628820229277055

Epoch: 6| Step: 10
Training loss: 0.3107642846249997
Validation loss: 2.4683439378504444

Epoch: 6| Step: 11
Training loss: 0.18703479475073786
Validation loss: 2.4226478955005692

Epoch: 6| Step: 12
Training loss: 0.2783450333173922
Validation loss: 2.4349346623470445

Epoch: 6| Step: 13
Training loss: 0.4054698789724167
Validation loss: 2.461783102599133

Epoch: 449| Step: 0
Training loss: 0.30704102828201507
Validation loss: 2.4336883669269453

Epoch: 6| Step: 1
Training loss: 0.21352074489603462
Validation loss: 2.465952531130273

Epoch: 6| Step: 2
Training loss: 0.27957266416009663
Validation loss: 2.5012958767369744

Epoch: 6| Step: 3
Training loss: 0.3345510237835048
Validation loss: 2.4537119312522075

Epoch: 6| Step: 4
Training loss: 0.29988767984923975
Validation loss: 2.5188016554525157

Epoch: 6| Step: 5
Training loss: 0.48757327825053226
Validation loss: 2.545610486504907

Epoch: 6| Step: 6
Training loss: 0.4054619591939936
Validation loss: 2.5181241088892

Epoch: 6| Step: 7
Training loss: 0.29338710161173687
Validation loss: 2.4681196455538723

Epoch: 6| Step: 8
Training loss: 0.21805400480001078
Validation loss: 2.4646203873817

Epoch: 6| Step: 9
Training loss: 0.34814840477798875
Validation loss: 2.4763697600349444

Epoch: 6| Step: 10
Training loss: 0.2511354529757761
Validation loss: 2.4560772951549734

Epoch: 6| Step: 11
Training loss: 0.305062014927368
Validation loss: 2.454884952442293

Epoch: 6| Step: 12
Training loss: 0.2670805823134341
Validation loss: 2.4161252365417645

Epoch: 6| Step: 13
Training loss: 0.13959245293157474
Validation loss: 2.4410258455949165

Epoch: 450| Step: 0
Training loss: 0.249352271686316
Validation loss: 2.49704665096938

Epoch: 6| Step: 1
Training loss: 0.3501147235450412
Validation loss: 2.4944815158483546

Epoch: 6| Step: 2
Training loss: 0.28853351286557816
Validation loss: 2.4779148727927494

Epoch: 6| Step: 3
Training loss: 0.4327681990443385
Validation loss: 2.5171257265618454

Epoch: 6| Step: 4
Training loss: 0.20471420696250564
Validation loss: 2.488585276726732

Epoch: 6| Step: 5
Training loss: 0.43700356928722955
Validation loss: 2.423110629771109

Epoch: 6| Step: 6
Training loss: 0.24179553030006803
Validation loss: 2.4346438898035743

Epoch: 6| Step: 7
Training loss: 0.24893704580063966
Validation loss: 2.3694125783121094

Epoch: 6| Step: 8
Training loss: 0.26589343587879544
Validation loss: 2.3974522439543287

Epoch: 6| Step: 9
Training loss: 0.23502269893956643
Validation loss: 2.4243645423120697

Epoch: 6| Step: 10
Training loss: 0.2781736824205341
Validation loss: 2.408122326806896

Epoch: 6| Step: 11
Training loss: 0.34546805326062857
Validation loss: 2.3929552226329895

Epoch: 6| Step: 12
Training loss: 0.38111770867379197
Validation loss: 2.4397449993185454

Epoch: 6| Step: 13
Training loss: 0.20411948531457644
Validation loss: 2.378704525951207

Epoch: 451| Step: 0
Training loss: 0.2822165569920977
Validation loss: 2.4235430469313437

Epoch: 6| Step: 1
Training loss: 0.4457181789253052
Validation loss: 2.4292314461013023

Epoch: 6| Step: 2
Training loss: 0.29727479717525856
Validation loss: 2.4130565632741376

Epoch: 6| Step: 3
Training loss: 0.29638602745314896
Validation loss: 2.4679951716469026

Epoch: 6| Step: 4
Training loss: 0.4241333666559998
Validation loss: 2.431107902133427

Epoch: 6| Step: 5
Training loss: 0.4394681461733983
Validation loss: 2.450374563903316

Epoch: 6| Step: 6
Training loss: 0.35256665193168435
Validation loss: 2.448575137107796

Epoch: 6| Step: 7
Training loss: 0.21899645409696353
Validation loss: 2.4055946713839718

Epoch: 6| Step: 8
Training loss: 0.21549867163600553
Validation loss: 2.4118922377930887

Epoch: 6| Step: 9
Training loss: 0.19809708194003642
Validation loss: 2.4332783370082947

Epoch: 6| Step: 10
Training loss: 0.14816100318781478
Validation loss: 2.459021279289094

Epoch: 6| Step: 11
Training loss: 0.33910438524997605
Validation loss: 2.4364678001376845

Epoch: 6| Step: 12
Training loss: 0.23406571007884136
Validation loss: 2.4055694077829366

Epoch: 6| Step: 13
Training loss: 0.2275163696499036
Validation loss: 2.386272739113468

Epoch: 452| Step: 0
Training loss: 0.30919287262476874
Validation loss: 2.3997887901289476

Epoch: 6| Step: 1
Training loss: 0.3252732467055262
Validation loss: 2.4144910153355057

Epoch: 6| Step: 2
Training loss: 0.47895725656924587
Validation loss: 2.39509213196739

Epoch: 6| Step: 3
Training loss: 0.19032717170598729
Validation loss: 2.440322144634407

Epoch: 6| Step: 4
Training loss: 0.22171892331461351
Validation loss: 2.4550321747318233

Epoch: 6| Step: 5
Training loss: 0.247531046642022
Validation loss: 2.473681153258088

Epoch: 6| Step: 6
Training loss: 0.3326450060748943
Validation loss: 2.468726704639306

Epoch: 6| Step: 7
Training loss: 0.28855246576466304
Validation loss: 2.4558212295552915

Epoch: 6| Step: 8
Training loss: 0.2543423941520213
Validation loss: 2.4868049937272634

Epoch: 6| Step: 9
Training loss: 0.2721573153115874
Validation loss: 2.4796808377794606

Epoch: 6| Step: 10
Training loss: 0.4359540532842147
Validation loss: 2.460875635888163

Epoch: 6| Step: 11
Training loss: 0.21767027083379406
Validation loss: 2.448903879167128

Epoch: 6| Step: 12
Training loss: 0.32980888717346807
Validation loss: 2.430354349936791

Epoch: 6| Step: 13
Training loss: 0.3874282878230371
Validation loss: 2.4619835217371286

Epoch: 453| Step: 0
Training loss: 0.27102834148819044
Validation loss: 2.405500326901978

Epoch: 6| Step: 1
Training loss: 0.4276370978674958
Validation loss: 2.4329320861090507

Epoch: 6| Step: 2
Training loss: 0.17750172531941555
Validation loss: 2.428032760968148

Epoch: 6| Step: 3
Training loss: 0.36117546361963565
Validation loss: 2.3850960991443833

Epoch: 6| Step: 4
Training loss: 0.2868098688468355
Validation loss: 2.388825074291311

Epoch: 6| Step: 5
Training loss: 0.29852189473504276
Validation loss: 2.4189392853102234

Epoch: 6| Step: 6
Training loss: 0.2555643375299882
Validation loss: 2.3626337948786955

Epoch: 6| Step: 7
Training loss: 0.1724111150228369
Validation loss: 2.3733260770624356

Epoch: 6| Step: 8
Training loss: 0.32010811588637245
Validation loss: 2.399802309678171

Epoch: 6| Step: 9
Training loss: 0.4013066118477051
Validation loss: 2.3864997339133844

Epoch: 6| Step: 10
Training loss: 0.2726017987769527
Validation loss: 2.42246545639138

Epoch: 6| Step: 11
Training loss: 0.1646487343492468
Validation loss: 2.4183190848866754

Epoch: 6| Step: 12
Training loss: 0.3556311309835707
Validation loss: 2.434439249591593

Epoch: 6| Step: 13
Training loss: 0.17994796492543289
Validation loss: 2.474154347208938

Epoch: 454| Step: 0
Training loss: 0.25839416315835395
Validation loss: 2.442146259866339

Epoch: 6| Step: 1
Training loss: 0.22336241354114741
Validation loss: 2.4367874267182943

Epoch: 6| Step: 2
Training loss: 0.22074827221942733
Validation loss: 2.432228053994661

Epoch: 6| Step: 3
Training loss: 0.21339744644451636
Validation loss: 2.4295872189920895

Epoch: 6| Step: 4
Training loss: 0.2913909642196449
Validation loss: 2.4435737506441275

Epoch: 6| Step: 5
Training loss: 0.34114025805433545
Validation loss: 2.4524259389617695

Epoch: 6| Step: 6
Training loss: 0.16566870850405557
Validation loss: 2.4321510527432224

Epoch: 6| Step: 7
Training loss: 0.31487536070523986
Validation loss: 2.457059808448348

Epoch: 6| Step: 8
Training loss: 0.45429391376189543
Validation loss: 2.4714913818277893

Epoch: 6| Step: 9
Training loss: 0.3674052587017039
Validation loss: 2.4635795738288486

Epoch: 6| Step: 10
Training loss: 0.2570495587353127
Validation loss: 2.436318242781841

Epoch: 6| Step: 11
Training loss: 0.29757230831599546
Validation loss: 2.4355157369821505

Epoch: 6| Step: 12
Training loss: 0.22267602531554237
Validation loss: 2.4328685077447503

Epoch: 6| Step: 13
Training loss: 0.21185484731250184
Validation loss: 2.4302766817101253

Epoch: 455| Step: 0
Training loss: 0.34677279659245275
Validation loss: 2.407104289398954

Epoch: 6| Step: 1
Training loss: 0.34777165758332373
Validation loss: 2.4702314576502875

Epoch: 6| Step: 2
Training loss: 0.2511074303850857
Validation loss: 2.472699569558293

Epoch: 6| Step: 3
Training loss: 0.3003007096944344
Validation loss: 2.45372671252958

Epoch: 6| Step: 4
Training loss: 0.17663294243587385
Validation loss: 2.44264759688146

Epoch: 6| Step: 5
Training loss: 0.39467871147996625
Validation loss: 2.455690150388732

Epoch: 6| Step: 6
Training loss: 0.2485060909040953
Validation loss: 2.428132343617671

Epoch: 6| Step: 7
Training loss: 0.324142803351235
Validation loss: 2.407886086883345

Epoch: 6| Step: 8
Training loss: 0.24700444364990742
Validation loss: 2.383771092775452

Epoch: 6| Step: 9
Training loss: 0.3774354842931695
Validation loss: 2.420484667613477

Epoch: 6| Step: 10
Training loss: 0.22026962985938472
Validation loss: 2.4190247119310473

Epoch: 6| Step: 11
Training loss: 0.2621365955163825
Validation loss: 2.4434492145298417

Epoch: 6| Step: 12
Training loss: 0.3100674845704871
Validation loss: 2.433439088768894

Epoch: 6| Step: 13
Training loss: 0.3291327238187123
Validation loss: 2.477826044932675

Epoch: 456| Step: 0
Training loss: 0.11499889608428654
Validation loss: 2.4572135150402286

Epoch: 6| Step: 1
Training loss: 0.2920105076787004
Validation loss: 2.4906451387368724

Epoch: 6| Step: 2
Training loss: 0.13202356479782432
Validation loss: 2.4936270321083174

Epoch: 6| Step: 3
Training loss: 0.2915188707251861
Validation loss: 2.49424100327876

Epoch: 6| Step: 4
Training loss: 0.2027457621762984
Validation loss: 2.490975124301564

Epoch: 6| Step: 5
Training loss: 0.23546289050653132
Validation loss: 2.4842112992835084

Epoch: 6| Step: 6
Training loss: 0.271105412608872
Validation loss: 2.4825014177621596

Epoch: 6| Step: 7
Training loss: 0.1950316221474763
Validation loss: 2.5292803303059506

Epoch: 6| Step: 8
Training loss: 0.4378814396843417
Validation loss: 2.504454032133492

Epoch: 6| Step: 9
Training loss: 0.3427720246462491
Validation loss: 2.4930195517073996

Epoch: 6| Step: 10
Training loss: 0.2885148298726202
Validation loss: 2.4615310612027246

Epoch: 6| Step: 11
Training loss: 0.2749637379363465
Validation loss: 2.465833583338377

Epoch: 6| Step: 12
Training loss: 0.3709735876588501
Validation loss: 2.488119855659463

Epoch: 6| Step: 13
Training loss: 0.10488208774053402
Validation loss: 2.4815063445811676

Epoch: 457| Step: 0
Training loss: 0.24976641948670242
Validation loss: 2.4765788254685486

Epoch: 6| Step: 1
Training loss: 0.18451096322276545
Validation loss: 2.4307140519771973

Epoch: 6| Step: 2
Training loss: 0.1903911355927093
Validation loss: 2.407586354025997

Epoch: 6| Step: 3
Training loss: 0.20295879092902694
Validation loss: 2.4613056314444646

Epoch: 6| Step: 4
Training loss: 0.2757327342382046
Validation loss: 2.411053732934401

Epoch: 6| Step: 5
Training loss: 0.4031793749902281
Validation loss: 2.3806884336002856

Epoch: 6| Step: 6
Training loss: 0.3110678758882902
Validation loss: 2.432561260556026

Epoch: 6| Step: 7
Training loss: 0.19486014434072832
Validation loss: 2.4599423658512793

Epoch: 6| Step: 8
Training loss: 0.4146667605792999
Validation loss: 2.44382051118015

Epoch: 6| Step: 9
Training loss: 0.2110903680503655
Validation loss: 2.4808790360292456

Epoch: 6| Step: 10
Training loss: 0.2089975299438277
Validation loss: 2.4806394823644267

Epoch: 6| Step: 11
Training loss: 0.3467141362657303
Validation loss: 2.5179633333350657

Epoch: 6| Step: 12
Training loss: 0.40725653009817037
Validation loss: 2.4832113095476056

Epoch: 6| Step: 13
Training loss: 0.2759336569141518
Validation loss: 2.5074872386844307

Epoch: 458| Step: 0
Training loss: 0.24976095304394286
Validation loss: 2.461504635534559

Epoch: 6| Step: 1
Training loss: 0.22982368065239467
Validation loss: 2.445491325693243

Epoch: 6| Step: 2
Training loss: 0.20008390164331005
Validation loss: 2.4744749242069726

Epoch: 6| Step: 3
Training loss: 0.2250151824464718
Validation loss: 2.4414962842521555

Epoch: 6| Step: 4
Training loss: 0.3954932127718628
Validation loss: 2.429405533947187

Epoch: 6| Step: 5
Training loss: 0.22945862382606372
Validation loss: 2.3765797609779207

Epoch: 6| Step: 6
Training loss: 0.21939326120649294
Validation loss: 2.421448624597625

Epoch: 6| Step: 7
Training loss: 0.28475623618975904
Validation loss: 2.384566988689661

Epoch: 6| Step: 8
Training loss: 0.20802572110590575
Validation loss: 2.4353504499876917

Epoch: 6| Step: 9
Training loss: 0.3091553033212519
Validation loss: 2.4231633692249925

Epoch: 6| Step: 10
Training loss: 0.22728485839068963
Validation loss: 2.4666363188227267

Epoch: 6| Step: 11
Training loss: 0.45863910431278865
Validation loss: 2.4538237856182645

Epoch: 6| Step: 12
Training loss: 0.40307761364776595
Validation loss: 2.459275061813595

Epoch: 6| Step: 13
Training loss: 0.28362777705491127
Validation loss: 2.511879043441331

Epoch: 459| Step: 0
Training loss: 0.14996408688258173
Validation loss: 2.47165608058208

Epoch: 6| Step: 1
Training loss: 0.1273435677486122
Validation loss: 2.4595843997703617

Epoch: 6| Step: 2
Training loss: 0.17944300645028005
Validation loss: 2.437191812507007

Epoch: 6| Step: 3
Training loss: 0.27354249300883965
Validation loss: 2.4823395175074254

Epoch: 6| Step: 4
Training loss: 0.31623390590290457
Validation loss: 2.437934347988354

Epoch: 6| Step: 5
Training loss: 0.43418936158804294
Validation loss: 2.4688149279209064

Epoch: 6| Step: 6
Training loss: 0.1637423889196775
Validation loss: 2.481041893353298

Epoch: 6| Step: 7
Training loss: 0.20381123824841774
Validation loss: 2.4926606735037296

Epoch: 6| Step: 8
Training loss: 0.24137763776626905
Validation loss: 2.467448888463499

Epoch: 6| Step: 9
Training loss: 0.16119451786293368
Validation loss: 2.4449264052246256

Epoch: 6| Step: 10
Training loss: 0.44265287463311415
Validation loss: 2.432620335381082

Epoch: 6| Step: 11
Training loss: 0.3584633750189983
Validation loss: 2.456193160948019

Epoch: 6| Step: 12
Training loss: 0.3079854305168544
Validation loss: 2.4592656386814364

Epoch: 6| Step: 13
Training loss: 0.3406040412684361
Validation loss: 2.481601247332711

Epoch: 460| Step: 0
Training loss: 0.2123064548169706
Validation loss: 2.443639926609766

Epoch: 6| Step: 1
Training loss: 0.30405714167532166
Validation loss: 2.470409601329456

Epoch: 6| Step: 2
Training loss: 0.28660086929218737
Validation loss: 2.519333986339406

Epoch: 6| Step: 3
Training loss: 0.15107768276117128
Validation loss: 2.4879904905035333

Epoch: 6| Step: 4
Training loss: 0.2884785320857846
Validation loss: 2.5236836513398537

Epoch: 6| Step: 5
Training loss: 0.30786809225615214
Validation loss: 2.4898554891355404

Epoch: 6| Step: 6
Training loss: 0.4524875958992387
Validation loss: 2.5162140422793797

Epoch: 6| Step: 7
Training loss: 0.20744492928929237
Validation loss: 2.5079241489360617

Epoch: 6| Step: 8
Training loss: 0.344682652862167
Validation loss: 2.466277001617838

Epoch: 6| Step: 9
Training loss: 0.2813656357300449
Validation loss: 2.4564867886772856

Epoch: 6| Step: 10
Training loss: 0.36043989964760104
Validation loss: 2.4593753980281416

Epoch: 6| Step: 11
Training loss: 0.1814693135298277
Validation loss: 2.4423461417450487

Epoch: 6| Step: 12
Training loss: 0.18710611615299624
Validation loss: 2.465110223431552

Epoch: 6| Step: 13
Training loss: 0.21814168919492996
Validation loss: 2.428483623412608

Epoch: 461| Step: 0
Training loss: 0.2917228911340371
Validation loss: 2.4648953562689364

Epoch: 6| Step: 1
Training loss: 0.20914050535783563
Validation loss: 2.4748720296327784

Epoch: 6| Step: 2
Training loss: 0.2530054987698106
Validation loss: 2.476265981115881

Epoch: 6| Step: 3
Training loss: 0.2887563372820701
Validation loss: 2.4859364491900684

Epoch: 6| Step: 4
Training loss: 0.19635242179749665
Validation loss: 2.4984128877383975

Epoch: 6| Step: 5
Training loss: 0.35911882640977427
Validation loss: 2.530932787007885

Epoch: 6| Step: 6
Training loss: 0.23621733093945718
Validation loss: 2.4386511388598406

Epoch: 6| Step: 7
Training loss: 0.3531813120882986
Validation loss: 2.459796639640779

Epoch: 6| Step: 8
Training loss: 0.3766571226781643
Validation loss: 2.4845117980314884

Epoch: 6| Step: 9
Training loss: 0.2577254552994615
Validation loss: 2.41595310402161

Epoch: 6| Step: 10
Training loss: 0.41408553149389093
Validation loss: 2.399228361805607

Epoch: 6| Step: 11
Training loss: 0.3639690492068214
Validation loss: 2.4338172124344934

Epoch: 6| Step: 12
Training loss: 0.32909822320800414
Validation loss: 2.391402961205093

Epoch: 6| Step: 13
Training loss: 0.21230063798651783
Validation loss: 2.3885122474308442

Epoch: 462| Step: 0
Training loss: 0.3699920362182532
Validation loss: 2.3946393440991005

Epoch: 6| Step: 1
Training loss: 0.35526437438511177
Validation loss: 2.4465452329979094

Epoch: 6| Step: 2
Training loss: 0.15429743633892465
Validation loss: 2.440312031125585

Epoch: 6| Step: 3
Training loss: 0.1850040727888742
Validation loss: 2.5033967374152715

Epoch: 6| Step: 4
Training loss: 0.18438719692943636
Validation loss: 2.4883884386174513

Epoch: 6| Step: 5
Training loss: 0.13933012102936204
Validation loss: 2.5478326982485373

Epoch: 6| Step: 6
Training loss: 0.24052806672929655
Validation loss: 2.5572245900041763

Epoch: 6| Step: 7
Training loss: 0.3972061990497637
Validation loss: 2.509197333340389

Epoch: 6| Step: 8
Training loss: 0.3372470923610189
Validation loss: 2.542596102074079

Epoch: 6| Step: 9
Training loss: 0.2846578920128359
Validation loss: 2.51721841258935

Epoch: 6| Step: 10
Training loss: 0.4126163997568594
Validation loss: 2.483124111389059

Epoch: 6| Step: 11
Training loss: 0.20801732216171837
Validation loss: 2.482476919267839

Epoch: 6| Step: 12
Training loss: 0.20666965360046807
Validation loss: 2.4377862500857748

Epoch: 6| Step: 13
Training loss: 0.17102155882507672
Validation loss: 2.4369367575051393

Epoch: 463| Step: 0
Training loss: 0.2505302171013757
Validation loss: 2.4248786520400754

Epoch: 6| Step: 1
Training loss: 0.1404214087262365
Validation loss: 2.4283328395422434

Epoch: 6| Step: 2
Training loss: 0.27221161020580803
Validation loss: 2.4238503357022823

Epoch: 6| Step: 3
Training loss: 0.27705396368695223
Validation loss: 2.4487139560472855

Epoch: 6| Step: 4
Training loss: 0.3262071190712087
Validation loss: 2.4793985559460014

Epoch: 6| Step: 5
Training loss: 0.1762336736753565
Validation loss: 2.479205696258553

Epoch: 6| Step: 6
Training loss: 0.1876596129066067
Validation loss: 2.47995359616691

Epoch: 6| Step: 7
Training loss: 0.3871551902289084
Validation loss: 2.507128611819695

Epoch: 6| Step: 8
Training loss: 0.32140039990358094
Validation loss: 2.5541730939038856

Epoch: 6| Step: 9
Training loss: 0.4007350463706876
Validation loss: 2.5069306104995666

Epoch: 6| Step: 10
Training loss: 0.2748936436633265
Validation loss: 2.5103032488131056

Epoch: 6| Step: 11
Training loss: 0.2101338140572512
Validation loss: 2.497506461680351

Epoch: 6| Step: 12
Training loss: 0.15541703403964696
Validation loss: 2.534643284667062

Epoch: 6| Step: 13
Training loss: 0.39120724200647267
Validation loss: 2.4831734907769967

Epoch: 464| Step: 0
Training loss: 0.1733663189508557
Validation loss: 2.489163114122234

Epoch: 6| Step: 1
Training loss: 0.2068890317036314
Validation loss: 2.4656406706477556

Epoch: 6| Step: 2
Training loss: 0.35867776821432507
Validation loss: 2.4310884504651957

Epoch: 6| Step: 3
Training loss: 0.2322482654770589
Validation loss: 2.4679917084375846

Epoch: 6| Step: 4
Training loss: 0.3191901291140826
Validation loss: 2.4570934957430146

Epoch: 6| Step: 5
Training loss: 0.24583610793072735
Validation loss: 2.4070745215990548

Epoch: 6| Step: 6
Training loss: 0.298694505924262
Validation loss: 2.443015591254033

Epoch: 6| Step: 7
Training loss: 0.25565098145477644
Validation loss: 2.508031035715079

Epoch: 6| Step: 8
Training loss: 0.40432274777098776
Validation loss: 2.4752681153983342

Epoch: 6| Step: 9
Training loss: 0.3314611027676021
Validation loss: 2.5118312336850734

Epoch: 6| Step: 10
Training loss: 0.18559977128794777
Validation loss: 2.4970801232376734

Epoch: 6| Step: 11
Training loss: 0.32719986924087807
Validation loss: 2.459755467575738

Epoch: 6| Step: 12
Training loss: 0.31410202422936523
Validation loss: 2.4746908989023724

Epoch: 6| Step: 13
Training loss: 0.3914100197555312
Validation loss: 2.5030790216117276

Epoch: 465| Step: 0
Training loss: 0.36345063639259856
Validation loss: 2.4742946539067727

Epoch: 6| Step: 1
Training loss: 0.29898586971566216
Validation loss: 2.467660596327257

Epoch: 6| Step: 2
Training loss: 0.3025480866240717
Validation loss: 2.4629419713770577

Epoch: 6| Step: 3
Training loss: 0.18582725422122
Validation loss: 2.483199282183838

Epoch: 6| Step: 4
Training loss: 0.4136804041284897
Validation loss: 2.50436209544877

Epoch: 6| Step: 5
Training loss: 0.19587462595238722
Validation loss: 2.4563696540637587

Epoch: 6| Step: 6
Training loss: 0.20071297683383596
Validation loss: 2.476487961601003

Epoch: 6| Step: 7
Training loss: 0.1566392401446153
Validation loss: 2.472713373701095

Epoch: 6| Step: 8
Training loss: 0.2425448334926293
Validation loss: 2.4370689326447534

Epoch: 6| Step: 9
Training loss: 0.21941370413412908
Validation loss: 2.461482165213614

Epoch: 6| Step: 10
Training loss: 0.3206195522611451
Validation loss: 2.4808003036143402

Epoch: 6| Step: 11
Training loss: 0.25185633434015264
Validation loss: 2.4793827407031044

Epoch: 6| Step: 12
Training loss: 0.22598427946453584
Validation loss: 2.4778947674085288

Epoch: 6| Step: 13
Training loss: 0.37196881369130563
Validation loss: 2.453212972902466

Epoch: 466| Step: 0
Training loss: 0.23381166309052934
Validation loss: 2.4398753747897435

Epoch: 6| Step: 1
Training loss: 0.17719057753243345
Validation loss: 2.4288210252835776

Epoch: 6| Step: 2
Training loss: 0.27340921528165574
Validation loss: 2.4745610855267417

Epoch: 6| Step: 3
Training loss: 0.3056030090588015
Validation loss: 2.455859621941989

Epoch: 6| Step: 4
Training loss: 0.39699273803516616
Validation loss: 2.475590535423134

Epoch: 6| Step: 5
Training loss: 0.22271065298311102
Validation loss: 2.4148704386642916

Epoch: 6| Step: 6
Training loss: 0.4728072532115606
Validation loss: 2.4381754980157657

Epoch: 6| Step: 7
Training loss: 0.18752237027552776
Validation loss: 2.4440029631781455

Epoch: 6| Step: 8
Training loss: 0.29245647147289305
Validation loss: 2.4474705953171454

Epoch: 6| Step: 9
Training loss: 0.33473583921304473
Validation loss: 2.481038769709743

Epoch: 6| Step: 10
Training loss: 0.19596334734090673
Validation loss: 2.4460354172495866

Epoch: 6| Step: 11
Training loss: 0.20503641340129097
Validation loss: 2.4476019418522457

Epoch: 6| Step: 12
Training loss: 0.173433407529025
Validation loss: 2.4392618396460777

Epoch: 6| Step: 13
Training loss: 0.2945258026226412
Validation loss: 2.4352748107172806

Epoch: 467| Step: 0
Training loss: 0.22563750433152308
Validation loss: 2.4337701281413646

Epoch: 6| Step: 1
Training loss: 0.20453159531869436
Validation loss: 2.3927960575943445

Epoch: 6| Step: 2
Training loss: 0.3556190005501989
Validation loss: 2.4168980550971444

Epoch: 6| Step: 3
Training loss: 0.3316434165917975
Validation loss: 2.406792073425129

Epoch: 6| Step: 4
Training loss: 0.2970556286876502
Validation loss: 2.3603887164265784

Epoch: 6| Step: 5
Training loss: 0.3121254225748278
Validation loss: 2.4235122640252174

Epoch: 6| Step: 6
Training loss: 0.2217924024743012
Validation loss: 2.4306839879603386

Epoch: 6| Step: 7
Training loss: 0.3158545216638738
Validation loss: 2.4344565841536543

Epoch: 6| Step: 8
Training loss: 0.24789295527255276
Validation loss: 2.496068906296939

Epoch: 6| Step: 9
Training loss: 0.30847780246492656
Validation loss: 2.5382588492754556

Epoch: 6| Step: 10
Training loss: 0.3511950798133183
Validation loss: 2.5480965727730647

Epoch: 6| Step: 11
Training loss: 0.2700556753294284
Validation loss: 2.601758716025877

Epoch: 6| Step: 12
Training loss: 0.38586035741266594
Validation loss: 2.555091623489157

Epoch: 6| Step: 13
Training loss: 0.20101882149222705
Validation loss: 2.52264480638783

Epoch: 468| Step: 0
Training loss: 0.18336519258922324
Validation loss: 2.468503080631409

Epoch: 6| Step: 1
Training loss: 0.23268145002665808
Validation loss: 2.4248306937571282

Epoch: 6| Step: 2
Training loss: 0.22874963630063688
Validation loss: 2.3568626511470443

Epoch: 6| Step: 3
Training loss: 0.4272089478829896
Validation loss: 2.342943759737848

Epoch: 6| Step: 4
Training loss: 0.3589334470469267
Validation loss: 2.359715280250197

Epoch: 6| Step: 5
Training loss: 0.28292783313919323
Validation loss: 2.347728185490192

Epoch: 6| Step: 6
Training loss: 0.32680328153111865
Validation loss: 2.3944366168187248

Epoch: 6| Step: 7
Training loss: 0.24002816103335878
Validation loss: 2.4055322664187178

Epoch: 6| Step: 8
Training loss: 0.294202660228539
Validation loss: 2.508746719173859

Epoch: 6| Step: 9
Training loss: 0.3697759418994719
Validation loss: 2.5276457561153505

Epoch: 6| Step: 10
Training loss: 0.41921476222191484
Validation loss: 2.583408767357686

Epoch: 6| Step: 11
Training loss: 0.2528182855894204
Validation loss: 2.5475536785717536

Epoch: 6| Step: 12
Training loss: 0.18583923195413984
Validation loss: 2.5324813560004698

Epoch: 6| Step: 13
Training loss: 0.3304089237286433
Validation loss: 2.5068466135354854

Epoch: 469| Step: 0
Training loss: 0.2908437208358243
Validation loss: 2.507588649456977

Epoch: 6| Step: 1
Training loss: 0.3477559107546198
Validation loss: 2.4652560905054535

Epoch: 6| Step: 2
Training loss: 0.353716671927197
Validation loss: 2.4557296858541346

Epoch: 6| Step: 3
Training loss: 0.3351010844039788
Validation loss: 2.418954232967664

Epoch: 6| Step: 4
Training loss: 0.3851708925880041
Validation loss: 2.4162881262650124

Epoch: 6| Step: 5
Training loss: 0.3966973958648048
Validation loss: 2.4456647398870914

Epoch: 6| Step: 6
Training loss: 0.349827064637614
Validation loss: 2.456828292967138

Epoch: 6| Step: 7
Training loss: 0.2475616259266929
Validation loss: 2.4858821240133113

Epoch: 6| Step: 8
Training loss: 0.33752573851175494
Validation loss: 2.474050815237515

Epoch: 6| Step: 9
Training loss: 0.35835556896476395
Validation loss: 2.509224763724861

Epoch: 6| Step: 10
Training loss: 0.15890695458277534
Validation loss: 2.485558588345818

Epoch: 6| Step: 11
Training loss: 0.16254636167360667
Validation loss: 2.4376320078789604

Epoch: 6| Step: 12
Training loss: 0.22268080994189596
Validation loss: 2.4840903067127735

Epoch: 6| Step: 13
Training loss: 0.20278709990231436
Validation loss: 2.503860201631453

Epoch: 470| Step: 0
Training loss: 0.26116383495958223
Validation loss: 2.506019332246477

Epoch: 6| Step: 1
Training loss: 0.24475717893432802
Validation loss: 2.516306150092012

Epoch: 6| Step: 2
Training loss: 0.28575733272442233
Validation loss: 2.5000377816247394

Epoch: 6| Step: 3
Training loss: 0.3711669046674998
Validation loss: 2.4744831244040366

Epoch: 6| Step: 4
Training loss: 0.1557112944010671
Validation loss: 2.4658756943458124

Epoch: 6| Step: 5
Training loss: 0.18980271245160824
Validation loss: 2.4231822999851333

Epoch: 6| Step: 6
Training loss: 0.18126426180272773
Validation loss: 2.4458531891883903

Epoch: 6| Step: 7
Training loss: 0.26815281710346117
Validation loss: 2.444624818962866

Epoch: 6| Step: 8
Training loss: 0.42139403866170894
Validation loss: 2.4411806247599497

Epoch: 6| Step: 9
Training loss: 0.37494160276935296
Validation loss: 2.445912942899031

Epoch: 6| Step: 10
Training loss: 0.27578933747187817
Validation loss: 2.410700472681306

Epoch: 6| Step: 11
Training loss: 0.28569682368067356
Validation loss: 2.4251936971025274

Epoch: 6| Step: 12
Training loss: 0.25269451033317036
Validation loss: 2.4006348664081694

Epoch: 6| Step: 13
Training loss: 0.2971035554382622
Validation loss: 2.4342857257589605

Epoch: 471| Step: 0
Training loss: 0.17264907097023804
Validation loss: 2.4202268784783185

Epoch: 6| Step: 1
Training loss: 0.2552001848022844
Validation loss: 2.4719679765748

Epoch: 6| Step: 2
Training loss: 0.2554543470703103
Validation loss: 2.486299301601753

Epoch: 6| Step: 3
Training loss: 0.3361737285671955
Validation loss: 2.473820130266514

Epoch: 6| Step: 4
Training loss: 0.32629201583777045
Validation loss: 2.466255823202544

Epoch: 6| Step: 5
Training loss: 0.19476888344032434
Validation loss: 2.448691834242825

Epoch: 6| Step: 6
Training loss: 0.2818618979231956
Validation loss: 2.4517797697059347

Epoch: 6| Step: 7
Training loss: 0.21517480139999648
Validation loss: 2.5126431463093537

Epoch: 6| Step: 8
Training loss: 0.30187495899002714
Validation loss: 2.504477546909747

Epoch: 6| Step: 9
Training loss: 0.35833172086234616
Validation loss: 2.4498518601617754

Epoch: 6| Step: 10
Training loss: 0.2354372272262026
Validation loss: 2.536000754114336

Epoch: 6| Step: 11
Training loss: 0.36142069687522876
Validation loss: 2.5216343274176536

Epoch: 6| Step: 12
Training loss: 0.33338574528907644
Validation loss: 2.4466233896454592

Epoch: 6| Step: 13
Training loss: 0.3038831633401441
Validation loss: 2.5467889337009786

Epoch: 472| Step: 0
Training loss: 0.3801996238790916
Validation loss: 2.5312871470701337

Epoch: 6| Step: 1
Training loss: 0.2758776099250517
Validation loss: 2.4931200419615362

Epoch: 6| Step: 2
Training loss: 0.22706198715941656
Validation loss: 2.4770597258482927

Epoch: 6| Step: 3
Training loss: 0.23358798609993442
Validation loss: 2.4647842383660965

Epoch: 6| Step: 4
Training loss: 0.310490417146772
Validation loss: 2.500899181374989

Epoch: 6| Step: 5
Training loss: 0.24436673184527394
Validation loss: 2.520266920209978

Epoch: 6| Step: 6
Training loss: 0.3251445375502518
Validation loss: 2.4998785132966734

Epoch: 6| Step: 7
Training loss: 0.2045615729780955
Validation loss: 2.4772696996177013

Epoch: 6| Step: 8
Training loss: 0.3112582809235221
Validation loss: 2.514584708827472

Epoch: 6| Step: 9
Training loss: 0.13809871425627473
Validation loss: 2.511027950029425

Epoch: 6| Step: 10
Training loss: 0.19954696433576322
Validation loss: 2.544141659428038

Epoch: 6| Step: 11
Training loss: 0.2184527796202398
Validation loss: 2.492042740205014

Epoch: 6| Step: 12
Training loss: 0.22427158663585237
Validation loss: 2.4874861658455414

Epoch: 6| Step: 13
Training loss: 0.396046438909143
Validation loss: 2.5053442202966227

Epoch: 473| Step: 0
Training loss: 0.30389435556077327
Validation loss: 2.495997455007961

Epoch: 6| Step: 1
Training loss: 0.18748236613004496
Validation loss: 2.5284392422855446

Epoch: 6| Step: 2
Training loss: 0.20275081501713452
Validation loss: 2.5004904050669206

Epoch: 6| Step: 3
Training loss: 0.20652905320349713
Validation loss: 2.4528610498195285

Epoch: 6| Step: 4
Training loss: 0.29955281167586756
Validation loss: 2.45651682963929

Epoch: 6| Step: 5
Training loss: 0.38247689308233096
Validation loss: 2.4260648086409162

Epoch: 6| Step: 6
Training loss: 0.23010092008714272
Validation loss: 2.458024186109589

Epoch: 6| Step: 7
Training loss: 0.2881779152114548
Validation loss: 2.470869778118764

Epoch: 6| Step: 8
Training loss: 0.26916711508021685
Validation loss: 2.468616375539637

Epoch: 6| Step: 9
Training loss: 0.3850048502703235
Validation loss: 2.4701110693377553

Epoch: 6| Step: 10
Training loss: 0.13733342142728222
Validation loss: 2.486546368858536

Epoch: 6| Step: 11
Training loss: 0.17203180248057445
Validation loss: 2.457177501728649

Epoch: 6| Step: 12
Training loss: 0.2634623790229034
Validation loss: 2.491924360848262

Epoch: 6| Step: 13
Training loss: 0.27177469935554505
Validation loss: 2.4740503665577673

Epoch: 474| Step: 0
Training loss: 0.38384807414478217
Validation loss: 2.4806955975514176

Epoch: 6| Step: 1
Training loss: 0.37391230672736236
Validation loss: 2.5163206752399354

Epoch: 6| Step: 2
Training loss: 0.12364821857807323
Validation loss: 2.498639236837864

Epoch: 6| Step: 3
Training loss: 0.36885162424099893
Validation loss: 2.574115776820706

Epoch: 6| Step: 4
Training loss: 0.1877600932195649
Validation loss: 2.57203317550364

Epoch: 6| Step: 5
Training loss: 0.2489469971862419
Validation loss: 2.552873462935967

Epoch: 6| Step: 6
Training loss: 0.14853379614493847
Validation loss: 2.549455845568928

Epoch: 6| Step: 7
Training loss: 0.3701678319417746
Validation loss: 2.5409942664141596

Epoch: 6| Step: 8
Training loss: 0.28204220885227826
Validation loss: 2.5201441196307903

Epoch: 6| Step: 9
Training loss: 0.2945442561103542
Validation loss: 2.491554064800347

Epoch: 6| Step: 10
Training loss: 0.25748139128989583
Validation loss: 2.4347847202110726

Epoch: 6| Step: 11
Training loss: 0.24151576622742074
Validation loss: 2.4241769341731234

Epoch: 6| Step: 12
Training loss: 0.2066130643179267
Validation loss: 2.409679195506191

Epoch: 6| Step: 13
Training loss: 0.2016822488796878
Validation loss: 2.4201681504764663

Epoch: 475| Step: 0
Training loss: 0.25732517423217116
Validation loss: 2.44019380806382

Epoch: 6| Step: 1
Training loss: 0.24011927848117726
Validation loss: 2.3698965008650825

Epoch: 6| Step: 2
Training loss: 0.17378169950671643
Validation loss: 2.443662650169559

Epoch: 6| Step: 3
Training loss: 0.17642725811824447
Validation loss: 2.4596211449667726

Epoch: 6| Step: 4
Training loss: 0.38424011593021296
Validation loss: 2.4672953799931725

Epoch: 6| Step: 5
Training loss: 0.32259836070143233
Validation loss: 2.5048686979604144

Epoch: 6| Step: 6
Training loss: 0.3407088045391681
Validation loss: 2.4995846259717007

Epoch: 6| Step: 7
Training loss: 0.1606543285779578
Validation loss: 2.5119526750546703

Epoch: 6| Step: 8
Training loss: 0.28410647783101395
Validation loss: 2.5382061105840705

Epoch: 6| Step: 9
Training loss: 0.3523414565221064
Validation loss: 2.505615025522835

Epoch: 6| Step: 10
Training loss: 0.21716572769042067
Validation loss: 2.522922801810708

Epoch: 6| Step: 11
Training loss: 0.22752394237134177
Validation loss: 2.5077019297384564

Epoch: 6| Step: 12
Training loss: 0.3013560017990178
Validation loss: 2.5001692432624587

Epoch: 6| Step: 13
Training loss: 0.23191774012942795
Validation loss: 2.5179150363555687

Epoch: 476| Step: 0
Training loss: 0.1616982682015036
Validation loss: 2.4858658524234647

Epoch: 6| Step: 1
Training loss: 0.21134890949472407
Validation loss: 2.502692213758268

Epoch: 6| Step: 2
Training loss: 0.2892412844204532
Validation loss: 2.4980162266425308

Epoch: 6| Step: 3
Training loss: 0.12447849653241867
Validation loss: 2.5088060621679893

Epoch: 6| Step: 4
Training loss: 0.1059203545865991
Validation loss: 2.5244230022729517

Epoch: 6| Step: 5
Training loss: 0.3030803303397172
Validation loss: 2.534076803610336

Epoch: 6| Step: 6
Training loss: 0.18399547697292326
Validation loss: 2.518483478683803

Epoch: 6| Step: 7
Training loss: 0.23909709748634717
Validation loss: 2.5010179241862467

Epoch: 6| Step: 8
Training loss: 0.2138090010966948
Validation loss: 2.5002897853459776

Epoch: 6| Step: 9
Training loss: 0.2470258363640877
Validation loss: 2.495513333462403

Epoch: 6| Step: 10
Training loss: 0.11776443560914363
Validation loss: 2.5341133331072134

Epoch: 6| Step: 11
Training loss: 0.30354747482368566
Validation loss: 2.563408667255638

Epoch: 6| Step: 12
Training loss: 0.30839149269174826
Validation loss: 2.5397779321638367

Epoch: 6| Step: 13
Training loss: 0.45493402778316083
Validation loss: 2.5371373018645755

Epoch: 477| Step: 0
Training loss: 0.23273091646911176
Validation loss: 2.526439364890079

Epoch: 6| Step: 1
Training loss: 0.2550875838718079
Validation loss: 2.5270810308727363

Epoch: 6| Step: 2
Training loss: 0.21360396817705754
Validation loss: 2.4905087980316116

Epoch: 6| Step: 3
Training loss: 0.2330181263434024
Validation loss: 2.464505390047092

Epoch: 6| Step: 4
Training loss: 0.25763557605607124
Validation loss: 2.4440549140481815

Epoch: 6| Step: 5
Training loss: 0.2263585274120205
Validation loss: 2.4174434409249828

Epoch: 6| Step: 6
Training loss: 0.3827656503152502
Validation loss: 2.408846549055609

Epoch: 6| Step: 7
Training loss: 0.2385446780790677
Validation loss: 2.3965631715349303

Epoch: 6| Step: 8
Training loss: 0.26302226541462925
Validation loss: 2.441930017216484

Epoch: 6| Step: 9
Training loss: 0.3101031894602236
Validation loss: 2.466412544782306

Epoch: 6| Step: 10
Training loss: 0.2760220856589328
Validation loss: 2.471808828701304

Epoch: 6| Step: 11
Training loss: 0.3999471115373781
Validation loss: 2.4894725953249948

Epoch: 6| Step: 12
Training loss: 0.1786506634569914
Validation loss: 2.4927154608243307

Epoch: 6| Step: 13
Training loss: 0.13461618845694392
Validation loss: 2.544890592395069

Epoch: 478| Step: 0
Training loss: 0.19418554381228417
Validation loss: 2.526816124403937

Epoch: 6| Step: 1
Training loss: 0.33065411574696374
Validation loss: 2.5727135329517385

Epoch: 6| Step: 2
Training loss: 0.44219766409687034
Validation loss: 2.500766485908192

Epoch: 6| Step: 3
Training loss: 0.35679795053084823
Validation loss: 2.505251088823365

Epoch: 6| Step: 4
Training loss: 0.3005655927508876
Validation loss: 2.476757580290309

Epoch: 6| Step: 5
Training loss: 0.23813871904837763
Validation loss: 2.4479060884734567

Epoch: 6| Step: 6
Training loss: 0.23539416137378605
Validation loss: 2.4297835952868905

Epoch: 6| Step: 7
Training loss: 0.24764078795965444
Validation loss: 2.4357284627015425

Epoch: 6| Step: 8
Training loss: 0.20963011116912003
Validation loss: 2.4566514706892657

Epoch: 6| Step: 9
Training loss: 0.21074749194832826
Validation loss: 2.4497445352318348

Epoch: 6| Step: 10
Training loss: 0.18177943924331044
Validation loss: 2.4786560933667245

Epoch: 6| Step: 11
Training loss: 0.3594421241103297
Validation loss: 2.485931024769642

Epoch: 6| Step: 12
Training loss: 0.2391378919612884
Validation loss: 2.488805387686178

Epoch: 6| Step: 13
Training loss: 0.1877841782756587
Validation loss: 2.5309122362313228

Epoch: 479| Step: 0
Training loss: 0.14240575848834242
Validation loss: 2.532852788599441

Epoch: 6| Step: 1
Training loss: 0.2436434298855197
Validation loss: 2.519153643178192

Epoch: 6| Step: 2
Training loss: 0.2643729884384499
Validation loss: 2.496931670623082

Epoch: 6| Step: 3
Training loss: 0.32138661813748876
Validation loss: 2.529191985706953

Epoch: 6| Step: 4
Training loss: 0.26699261054875445
Validation loss: 2.5350248140069334

Epoch: 6| Step: 5
Training loss: 0.36838751368890066
Validation loss: 2.485531742549818

Epoch: 6| Step: 6
Training loss: 0.21356398283644873
Validation loss: 2.499726571748166

Epoch: 6| Step: 7
Training loss: 0.20538846104389905
Validation loss: 2.4785729208534226

Epoch: 6| Step: 8
Training loss: 0.2751095466901389
Validation loss: 2.4532021026481234

Epoch: 6| Step: 9
Training loss: 0.17216725860466556
Validation loss: 2.432148315339857

Epoch: 6| Step: 10
Training loss: 0.2843956798328286
Validation loss: 2.4492042100011644

Epoch: 6| Step: 11
Training loss: 0.2729459704374719
Validation loss: 2.4443593824557666

Epoch: 6| Step: 12
Training loss: 0.17899527104886742
Validation loss: 2.432055144814558

Epoch: 6| Step: 13
Training loss: 0.19699598523166256
Validation loss: 2.4590145548638733

Epoch: 480| Step: 0
Training loss: 0.1773805134852555
Validation loss: 2.4779686629203663

Epoch: 6| Step: 1
Training loss: 0.37498062799008164
Validation loss: 2.4463274829206916

Epoch: 6| Step: 2
Training loss: 0.17043654557217197
Validation loss: 2.4625402650591024

Epoch: 6| Step: 3
Training loss: 0.12650503896913184
Validation loss: 2.526875897293695

Epoch: 6| Step: 4
Training loss: 0.2594159145717051
Validation loss: 2.458769611656808

Epoch: 6| Step: 5
Training loss: 0.3510348280665995
Validation loss: 2.4959002174943397

Epoch: 6| Step: 6
Training loss: 0.21291309203141331
Validation loss: 2.4905350065360063

Epoch: 6| Step: 7
Training loss: 0.3138953171986555
Validation loss: 2.4316743766246747

Epoch: 6| Step: 8
Training loss: 0.30530913834297596
Validation loss: 2.450191248665401

Epoch: 6| Step: 9
Training loss: 0.20277653661838688
Validation loss: 2.4585269495778275

Epoch: 6| Step: 10
Training loss: 0.24093463068489263
Validation loss: 2.4530547882915474

Epoch: 6| Step: 11
Training loss: 0.25120009030967655
Validation loss: 2.424909074535692

Epoch: 6| Step: 12
Training loss: 0.29346067454889896
Validation loss: 2.420779974821719

Epoch: 6| Step: 13
Training loss: 0.1680301509677218
Validation loss: 2.4270400634468876

Epoch: 481| Step: 0
Training loss: 0.27670256952403094
Validation loss: 2.4254914179416542

Epoch: 6| Step: 1
Training loss: 0.28163390978295416
Validation loss: 2.4280612867250086

Epoch: 6| Step: 2
Training loss: 0.1334262648527151
Validation loss: 2.4523871635303287

Epoch: 6| Step: 3
Training loss: 0.1531481535592269
Validation loss: 2.415654175781464

Epoch: 6| Step: 4
Training loss: 0.1895373147527208
Validation loss: 2.4275248303472075

Epoch: 6| Step: 5
Training loss: 0.23986852126543856
Validation loss: 2.4361860837387215

Epoch: 6| Step: 6
Training loss: 0.20276445705844384
Validation loss: 2.4178077961859956

Epoch: 6| Step: 7
Training loss: 0.15974085716081285
Validation loss: 2.4011105307833445

Epoch: 6| Step: 8
Training loss: 0.26169969005358645
Validation loss: 2.4536011772365343

Epoch: 6| Step: 9
Training loss: 0.38821687375766545
Validation loss: 2.4040602890192186

Epoch: 6| Step: 10
Training loss: 0.29826392723446415
Validation loss: 2.4226668964254743

Epoch: 6| Step: 11
Training loss: 0.3601455099362161
Validation loss: 2.435747818374676

Epoch: 6| Step: 12
Training loss: 0.2147081293858599
Validation loss: 2.4141056916982953

Epoch: 6| Step: 13
Training loss: 0.22083131055235386
Validation loss: 2.4259670242510456

Epoch: 482| Step: 0
Training loss: 0.1776960457354613
Validation loss: 2.440662128282199

Epoch: 6| Step: 1
Training loss: 0.20428109372456726
Validation loss: 2.456057267783067

Epoch: 6| Step: 2
Training loss: 0.18426573311960973
Validation loss: 2.466059158991512

Epoch: 6| Step: 3
Training loss: 0.24020453787256424
Validation loss: 2.4492552498212112

Epoch: 6| Step: 4
Training loss: 0.20212134580546887
Validation loss: 2.450351376854593

Epoch: 6| Step: 5
Training loss: 0.25741746287985834
Validation loss: 2.4827944004207576

Epoch: 6| Step: 6
Training loss: 0.3686495547157536
Validation loss: 2.5067257690394826

Epoch: 6| Step: 7
Training loss: 0.16565116819550696
Validation loss: 2.442739439312174

Epoch: 6| Step: 8
Training loss: 0.218293343456804
Validation loss: 2.4710079016969972

Epoch: 6| Step: 9
Training loss: 0.41946563775932083
Validation loss: 2.4583836656871556

Epoch: 6| Step: 10
Training loss: 0.16082719082562416
Validation loss: 2.4612842769293466

Epoch: 6| Step: 11
Training loss: 0.18943963543560818
Validation loss: 2.4339217053533124

Epoch: 6| Step: 12
Training loss: 0.34208102812476254
Validation loss: 2.4673434282651994

Epoch: 6| Step: 13
Training loss: 0.2403366289935174
Validation loss: 2.462365994040528

Epoch: 483| Step: 0
Training loss: 0.45902495509190483
Validation loss: 2.501059475842541

Epoch: 6| Step: 1
Training loss: 0.22173184356846562
Validation loss: 2.485201464373351

Epoch: 6| Step: 2
Training loss: 0.19408980074641785
Validation loss: 2.517197222798548

Epoch: 6| Step: 3
Training loss: 0.16724779409933913
Validation loss: 2.4967093725254204

Epoch: 6| Step: 4
Training loss: 0.1999958812766363
Validation loss: 2.500051052843793

Epoch: 6| Step: 5
Training loss: 0.17286579698475832
Validation loss: 2.506029825065352

Epoch: 6| Step: 6
Training loss: 0.3204711428161893
Validation loss: 2.5051640223158156

Epoch: 6| Step: 7
Training loss: 0.2502899425738907
Validation loss: 2.5073565845365775

Epoch: 6| Step: 8
Training loss: 0.16151824859808786
Validation loss: 2.5030299857547273

Epoch: 6| Step: 9
Training loss: 0.1793188168931126
Validation loss: 2.4870113512243894

Epoch: 6| Step: 10
Training loss: 0.1853744006381953
Validation loss: 2.5226812001107803

Epoch: 6| Step: 11
Training loss: 0.27610784163294005
Validation loss: 2.5029181902005067

Epoch: 6| Step: 12
Training loss: 0.19588476268318006
Validation loss: 2.47099929675792

Epoch: 6| Step: 13
Training loss: 0.18322073805028266
Validation loss: 2.4164818115595486

Epoch: 484| Step: 0
Training loss: 0.2865158485702555
Validation loss: 2.4454984080864093

Epoch: 6| Step: 1
Training loss: 0.1452545419596756
Validation loss: 2.4587897530010414

Epoch: 6| Step: 2
Training loss: 0.19479138472905555
Validation loss: 2.4551234343134656

Epoch: 6| Step: 3
Training loss: 0.3481781503246833
Validation loss: 2.434646684947533

Epoch: 6| Step: 4
Training loss: 0.18635581508552077
Validation loss: 2.4371638191099025

Epoch: 6| Step: 5
Training loss: 0.23644803685752525
Validation loss: 2.4618468620718454

Epoch: 6| Step: 6
Training loss: 0.30031527304584715
Validation loss: 2.459475104216649

Epoch: 6| Step: 7
Training loss: 0.3405502035980781
Validation loss: 2.465988471390047

Epoch: 6| Step: 8
Training loss: 0.2605494526245174
Validation loss: 2.461710127128608

Epoch: 6| Step: 9
Training loss: 0.3510967772641497
Validation loss: 2.463948607982817

Epoch: 6| Step: 10
Training loss: 0.2769049544739453
Validation loss: 2.427361207885374

Epoch: 6| Step: 11
Training loss: 0.2199332727219501
Validation loss: 2.408837809331155

Epoch: 6| Step: 12
Training loss: 0.1865232277913937
Validation loss: 2.440428359683566

Epoch: 6| Step: 13
Training loss: 0.13141718871075037
Validation loss: 2.435395573152455

Epoch: 485| Step: 0
Training loss: 0.16600070213117676
Validation loss: 2.4566966946345192

Epoch: 6| Step: 1
Training loss: 0.13488602443022674
Validation loss: 2.4745291144181882

Epoch: 6| Step: 2
Training loss: 0.23606516655579113
Validation loss: 2.4691580563281654

Epoch: 6| Step: 3
Training loss: 0.333276455715515
Validation loss: 2.4416992767697505

Epoch: 6| Step: 4
Training loss: 0.19830119377641123
Validation loss: 2.4671596411408196

Epoch: 6| Step: 5
Training loss: 0.253751737090681
Validation loss: 2.5097202122469535

Epoch: 6| Step: 6
Training loss: 0.1452409486067851
Validation loss: 2.5004623006151343

Epoch: 6| Step: 7
Training loss: 0.19023783874491584
Validation loss: 2.498027480700684

Epoch: 6| Step: 8
Training loss: 0.14768279356768335
Validation loss: 2.4939393094537134

Epoch: 6| Step: 9
Training loss: 0.3291393903504962
Validation loss: 2.4733508639583235

Epoch: 6| Step: 10
Training loss: 0.22587706205981595
Validation loss: 2.5257002682367835

Epoch: 6| Step: 11
Training loss: 0.38597675386409996
Validation loss: 2.4842411922847654

Epoch: 6| Step: 12
Training loss: 0.1563497105975167
Validation loss: 2.4479220196297335

Epoch: 6| Step: 13
Training loss: 0.2152757376442568
Validation loss: 2.4196576625236026

Epoch: 486| Step: 0
Training loss: 0.18794753388544855
Validation loss: 2.4200084012366334

Epoch: 6| Step: 1
Training loss: 0.16087732578958702
Validation loss: 2.3970853304759516

Epoch: 6| Step: 2
Training loss: 0.14416701584380462
Validation loss: 2.400718954672473

Epoch: 6| Step: 3
Training loss: 0.26451938199201963
Validation loss: 2.3973421785875675

Epoch: 6| Step: 4
Training loss: 0.3090412420323313
Validation loss: 2.4415060442473813

Epoch: 6| Step: 5
Training loss: 0.20635238042678056
Validation loss: 2.4216477254715643

Epoch: 6| Step: 6
Training loss: 0.27060576500492683
Validation loss: 2.4240061179709667

Epoch: 6| Step: 7
Training loss: 0.36597774965108165
Validation loss: 2.4339479143831

Epoch: 6| Step: 8
Training loss: 0.19079952029099428
Validation loss: 2.4285909030278603

Epoch: 6| Step: 9
Training loss: 0.1738540276505326
Validation loss: 2.4313372262644126

Epoch: 6| Step: 10
Training loss: 0.14435700274460028
Validation loss: 2.446063248329828

Epoch: 6| Step: 11
Training loss: 0.2273368100290142
Validation loss: 2.4096903312476536

Epoch: 6| Step: 12
Training loss: 0.11955420828352244
Validation loss: 2.4500444961937187

Epoch: 6| Step: 13
Training loss: 0.32624701816467744
Validation loss: 2.456381406809558

Epoch: 487| Step: 0
Training loss: 0.1762038079309688
Validation loss: 2.481655567049356

Epoch: 6| Step: 1
Training loss: 0.3285545194555353
Validation loss: 2.4953763803527504

Epoch: 6| Step: 2
Training loss: 0.2556680735833683
Validation loss: 2.52515400770495

Epoch: 6| Step: 3
Training loss: 0.1106642874632278
Validation loss: 2.5452967351847526

Epoch: 6| Step: 4
Training loss: 0.2013804826315687
Validation loss: 2.5812422932849906

Epoch: 6| Step: 5
Training loss: 0.12618749539553373
Validation loss: 2.4902982594456824

Epoch: 6| Step: 6
Training loss: 0.13959753002260633
Validation loss: 2.4891787441498185

Epoch: 6| Step: 7
Training loss: 0.14024254660852337
Validation loss: 2.432018847504204

Epoch: 6| Step: 8
Training loss: 0.39075955934357354
Validation loss: 2.4518071241320385

Epoch: 6| Step: 9
Training loss: 0.27023369020638294
Validation loss: 2.4171666069153135

Epoch: 6| Step: 10
Training loss: 0.18769631440116555
Validation loss: 2.435431395921369

Epoch: 6| Step: 11
Training loss: 0.2329845189796419
Validation loss: 2.458787762072875

Epoch: 6| Step: 12
Training loss: 0.33787828764690203
Validation loss: 2.4622048537537498

Epoch: 6| Step: 13
Training loss: 0.2703064399657358
Validation loss: 2.4715004870976722

Epoch: 488| Step: 0
Training loss: 0.33714950738144195
Validation loss: 2.4133076828283113

Epoch: 6| Step: 1
Training loss: 0.294812314733593
Validation loss: 2.487639072467678

Epoch: 6| Step: 2
Training loss: 0.15467204585086655
Validation loss: 2.4599248445620487

Epoch: 6| Step: 3
Training loss: 0.1857137431638516
Validation loss: 2.4729657723573952

Epoch: 6| Step: 4
Training loss: 0.32216783831716017
Validation loss: 2.433841448121371

Epoch: 6| Step: 5
Training loss: 0.17163183610836275
Validation loss: 2.4960975521770634

Epoch: 6| Step: 6
Training loss: 0.22101079543801433
Validation loss: 2.523563877746922

Epoch: 6| Step: 7
Training loss: 0.3190994320155187
Validation loss: 2.5482943825168194

Epoch: 6| Step: 8
Training loss: 0.21885679396992502
Validation loss: 2.5513243220630457

Epoch: 6| Step: 9
Training loss: 0.19497637435953533
Validation loss: 2.557911142313949

Epoch: 6| Step: 10
Training loss: 0.23090373224684185
Validation loss: 2.5647688994745876

Epoch: 6| Step: 11
Training loss: 0.2024282279097964
Validation loss: 2.5538219892291734

Epoch: 6| Step: 12
Training loss: 0.19087111344468224
Validation loss: 2.537372338941874

Epoch: 6| Step: 13
Training loss: 0.1705097464924794
Validation loss: 2.452118293360417

Epoch: 489| Step: 0
Training loss: 0.14136706041012542
Validation loss: 2.453887629665308

Epoch: 6| Step: 1
Training loss: 0.23436806191665588
Validation loss: 2.4424574932420424

Epoch: 6| Step: 2
Training loss: 0.3364986899869056
Validation loss: 2.419053977919303

Epoch: 6| Step: 3
Training loss: 0.30650206186882967
Validation loss: 2.4264601075817973

Epoch: 6| Step: 4
Training loss: 0.32729317039898664
Validation loss: 2.4204767589759406

Epoch: 6| Step: 5
Training loss: 0.24821564797378498
Validation loss: 2.4686509809967565

Epoch: 6| Step: 6
Training loss: 0.243466989043493
Validation loss: 2.458774976094622

Epoch: 6| Step: 7
Training loss: 0.31864410960261313
Validation loss: 2.4539099041709744

Epoch: 6| Step: 8
Training loss: 0.23408007344432577
Validation loss: 2.4480252020414133

Epoch: 6| Step: 9
Training loss: 0.13249011742876377
Validation loss: 2.4985056605151317

Epoch: 6| Step: 10
Training loss: 0.2859445154132001
Validation loss: 2.5171829766733893

Epoch: 6| Step: 11
Training loss: 0.09292495802092508
Validation loss: 2.4853847136638545

Epoch: 6| Step: 12
Training loss: 0.16513442495276842
Validation loss: 2.487486150386316

Epoch: 6| Step: 13
Training loss: 0.24669535837059176
Validation loss: 2.4981156964540734

Epoch: 490| Step: 0
Training loss: 0.166654088370215
Validation loss: 2.5248992261389565

Epoch: 6| Step: 1
Training loss: 0.27214795255610963
Validation loss: 2.5261182723731253

Epoch: 6| Step: 2
Training loss: 0.10775491500003405
Validation loss: 2.493187124900474

Epoch: 6| Step: 3
Training loss: 0.3073339217708551
Validation loss: 2.4989732643831775

Epoch: 6| Step: 4
Training loss: 0.25678521007090044
Validation loss: 2.5055791865916106

Epoch: 6| Step: 5
Training loss: 0.22874879759852926
Validation loss: 2.5139997120170166

Epoch: 6| Step: 6
Training loss: 0.3662933867147311
Validation loss: 2.4842524922347065

Epoch: 6| Step: 7
Training loss: 0.15974699625286654
Validation loss: 2.4751923080862936

Epoch: 6| Step: 8
Training loss: 0.31913203691298975
Validation loss: 2.488810991253828

Epoch: 6| Step: 9
Training loss: 0.3111072378908514
Validation loss: 2.4305828043342452

Epoch: 6| Step: 10
Training loss: 0.29618660268589286
Validation loss: 2.4023826395217354

Epoch: 6| Step: 11
Training loss: 0.14094985421414397
Validation loss: 2.4176172763767663

Epoch: 6| Step: 12
Training loss: 0.19084866722072308
Validation loss: 2.3903778755939316

Epoch: 6| Step: 13
Training loss: 0.22000743292584823
Validation loss: 2.3818378829650437

Epoch: 491| Step: 0
Training loss: 0.2761805143178576
Validation loss: 2.3928591643388586

Epoch: 6| Step: 1
Training loss: 0.20356055475804138
Validation loss: 2.3971947312190265

Epoch: 6| Step: 2
Training loss: 0.3349235447067167
Validation loss: 2.4334326897701417

Epoch: 6| Step: 3
Training loss: 0.2965883200954974
Validation loss: 2.46085794987314

Epoch: 6| Step: 4
Training loss: 0.1875802901340457
Validation loss: 2.492427313812592

Epoch: 6| Step: 5
Training loss: 0.13064216264883563
Validation loss: 2.4991666286700074

Epoch: 6| Step: 6
Training loss: 0.2667707109258615
Validation loss: 2.512794369063667

Epoch: 6| Step: 7
Training loss: 0.33535644269979253
Validation loss: 2.474439112389854

Epoch: 6| Step: 8
Training loss: 0.3165397480153357
Validation loss: 2.5140298422654723

Epoch: 6| Step: 9
Training loss: 0.24934217960051028
Validation loss: 2.4756401862355557

Epoch: 6| Step: 10
Training loss: 0.20253412797999346
Validation loss: 2.4700077270058802

Epoch: 6| Step: 11
Training loss: 0.3717244861444017
Validation loss: 2.467068732229571

Epoch: 6| Step: 12
Training loss: 0.26352641013745
Validation loss: 2.4354684939480005

Epoch: 6| Step: 13
Training loss: 0.13755811118967867
Validation loss: 2.3893331959298134

Epoch: 492| Step: 0
Training loss: 0.24149123211408471
Validation loss: 2.3796803514051117

Epoch: 6| Step: 1
Training loss: 0.24737667042986028
Validation loss: 2.355174420019933

Epoch: 6| Step: 2
Training loss: 0.1738275142187468
Validation loss: 2.3539574221844815

Epoch: 6| Step: 3
Training loss: 0.28153956924275586
Validation loss: 2.381819388874178

Epoch: 6| Step: 4
Training loss: 0.29979159050084025
Validation loss: 2.409481459702337

Epoch: 6| Step: 5
Training loss: 0.42671812732808945
Validation loss: 2.3910575945534744

Epoch: 6| Step: 6
Training loss: 0.1761506702239128
Validation loss: 2.426183105206912

Epoch: 6| Step: 7
Training loss: 0.343292962032056
Validation loss: 2.4091979178235507

Epoch: 6| Step: 8
Training loss: 0.20317778451702895
Validation loss: 2.4604857108674865

Epoch: 6| Step: 9
Training loss: 0.29817929607164473
Validation loss: 2.4659456306776844

Epoch: 6| Step: 10
Training loss: 0.29991431204622415
Validation loss: 2.4967316449138717

Epoch: 6| Step: 11
Training loss: 0.31427863119050253
Validation loss: 2.478846988419678

Epoch: 6| Step: 12
Training loss: 0.2386449789323058
Validation loss: 2.4197207563138674

Epoch: 6| Step: 13
Training loss: 0.33846626420156484
Validation loss: 2.4364413393797038

Epoch: 493| Step: 0
Training loss: 0.1785840589876009
Validation loss: 2.3985730407774173

Epoch: 6| Step: 1
Training loss: 0.17407068195665915
Validation loss: 2.409269022428675

Epoch: 6| Step: 2
Training loss: 0.25463696019300514
Validation loss: 2.4136610856585685

Epoch: 6| Step: 3
Training loss: 0.2837581063679678
Validation loss: 2.4691949840268284

Epoch: 6| Step: 4
Training loss: 0.2403325833806807
Validation loss: 2.405680226336401

Epoch: 6| Step: 5
Training loss: 0.3585408107267836
Validation loss: 2.4289377089180526

Epoch: 6| Step: 6
Training loss: 0.22356190452677677
Validation loss: 2.4431149233790097

Epoch: 6| Step: 7
Training loss: 0.2218089126163536
Validation loss: 2.494438733351524

Epoch: 6| Step: 8
Training loss: 0.2386786321005038
Validation loss: 2.5279572725451795

Epoch: 6| Step: 9
Training loss: 0.3735306882902722
Validation loss: 2.501032894834421

Epoch: 6| Step: 10
Training loss: 0.17159556301300574
Validation loss: 2.478767186697281

Epoch: 6| Step: 11
Training loss: 0.43944520731257053
Validation loss: 2.4514691765962735

Epoch: 6| Step: 12
Training loss: 0.35640419500779497
Validation loss: 2.408855256820649

Epoch: 6| Step: 13
Training loss: 0.24869746396221615
Validation loss: 2.3531087165590185

Epoch: 494| Step: 0
Training loss: 0.35856927858846865
Validation loss: 2.3429037665179653

Epoch: 6| Step: 1
Training loss: 0.20939557451248555
Validation loss: 2.3760343575736855

Epoch: 6| Step: 2
Training loss: 0.27930071634705406
Validation loss: 2.358774946761778

Epoch: 6| Step: 3
Training loss: 0.26331222872626153
Validation loss: 2.3737667986070052

Epoch: 6| Step: 4
Training loss: 0.27651190591309177
Validation loss: 2.3959086120535114

Epoch: 6| Step: 5
Training loss: 0.1487636747005013
Validation loss: 2.4436206334492283

Epoch: 6| Step: 6
Training loss: 0.3147061437711369
Validation loss: 2.461453773682791

Epoch: 6| Step: 7
Training loss: 0.21960908928428147
Validation loss: 2.454167565836687

Epoch: 6| Step: 8
Training loss: 0.18839302583562934
Validation loss: 2.5129771762740827

Epoch: 6| Step: 9
Training loss: 0.1797420999252604
Validation loss: 2.5270956279980816

Epoch: 6| Step: 10
Training loss: 0.32895094370781264
Validation loss: 2.5188500982769315

Epoch: 6| Step: 11
Training loss: 0.27045084770099403
Validation loss: 2.5234043783710636

Epoch: 6| Step: 12
Training loss: 0.27503394979376944
Validation loss: 2.4703044574418245

Epoch: 6| Step: 13
Training loss: 0.23040482070823076
Validation loss: 2.4237865630091013

Epoch: 495| Step: 0
Training loss: 0.22430518740481728
Validation loss: 2.457996017467714

Epoch: 6| Step: 1
Training loss: 0.2156946152801503
Validation loss: 2.4481152955063634

Epoch: 6| Step: 2
Training loss: 0.31052342212335393
Validation loss: 2.4302357574496902

Epoch: 6| Step: 3
Training loss: 0.2230848069680834
Validation loss: 2.4506609148923686

Epoch: 6| Step: 4
Training loss: 0.2963173799304033
Validation loss: 2.4525234973388077

Epoch: 6| Step: 5
Training loss: 0.23128516857681483
Validation loss: 2.4942082632737526

Epoch: 6| Step: 6
Training loss: 0.23984555048064848
Validation loss: 2.4259831111028496

Epoch: 6| Step: 7
Training loss: 0.2866788737660664
Validation loss: 2.4601598752968297

Epoch: 6| Step: 8
Training loss: 0.2525419112632669
Validation loss: 2.4776729046848422

Epoch: 6| Step: 9
Training loss: 0.23891259024710212
Validation loss: 2.4784843193117427

Epoch: 6| Step: 10
Training loss: 0.19756079770120819
Validation loss: 2.5064583849557094

Epoch: 6| Step: 11
Training loss: 0.24183673222010257
Validation loss: 2.491167429925587

Epoch: 6| Step: 12
Training loss: 0.22315683477026232
Validation loss: 2.492108515343122

Epoch: 6| Step: 13
Training loss: 0.4243140006573333
Validation loss: 2.460244835279022

Epoch: 496| Step: 0
Training loss: 0.1361631069654319
Validation loss: 2.489612361556633

Epoch: 6| Step: 1
Training loss: 0.1748058169877201
Validation loss: 2.463971940193914

Epoch: 6| Step: 2
Training loss: 0.1768571669245834
Validation loss: 2.4455687172328666

Epoch: 6| Step: 3
Training loss: 0.1776474960438423
Validation loss: 2.45565922707482

Epoch: 6| Step: 4
Training loss: 0.29910913356940044
Validation loss: 2.4447358168341498

Epoch: 6| Step: 5
Training loss: 0.2203128621930331
Validation loss: 2.411687364910876

Epoch: 6| Step: 6
Training loss: 0.26331466213762905
Validation loss: 2.434266925053327

Epoch: 6| Step: 7
Training loss: 0.22424734212422992
Validation loss: 2.4420287460345564

Epoch: 6| Step: 8
Training loss: 0.3163774971789947
Validation loss: 2.42309807661957

Epoch: 6| Step: 9
Training loss: 0.2269946449368647
Validation loss: 2.43749978649474

Epoch: 6| Step: 10
Training loss: 0.30778646504243223
Validation loss: 2.465612802171583

Epoch: 6| Step: 11
Training loss: 0.3610373899614132
Validation loss: 2.489473066969994

Epoch: 6| Step: 12
Training loss: 0.1774642904385968
Validation loss: 2.4943011626306775

Epoch: 6| Step: 13
Training loss: 0.14860157306226482
Validation loss: 2.52730607632666

Epoch: 497| Step: 0
Training loss: 0.35098071172827056
Validation loss: 2.5290861676034835

Epoch: 6| Step: 1
Training loss: 0.1939894688368022
Validation loss: 2.4624903199237917

Epoch: 6| Step: 2
Training loss: 0.4294564579651664
Validation loss: 2.5188024045544637

Epoch: 6| Step: 3
Training loss: 0.3550752620770452
Validation loss: 2.4436081699235883

Epoch: 6| Step: 4
Training loss: 0.2463343140840579
Validation loss: 2.4641853179714617

Epoch: 6| Step: 5
Training loss: 0.16417425187030335
Validation loss: 2.445952439353867

Epoch: 6| Step: 6
Training loss: 0.22741345389004694
Validation loss: 2.401139663583823

Epoch: 6| Step: 7
Training loss: 0.3032170047939777
Validation loss: 2.421072217596849

Epoch: 6| Step: 8
Training loss: 0.239146327300007
Validation loss: 2.4523333402124456

Epoch: 6| Step: 9
Training loss: 0.2899212067950234
Validation loss: 2.463426885736519

Epoch: 6| Step: 10
Training loss: 0.30697982396233514
Validation loss: 2.4584456738442757

Epoch: 6| Step: 11
Training loss: 0.21360982799502926
Validation loss: 2.43330283355169

Epoch: 6| Step: 12
Training loss: 0.35328944225842984
Validation loss: 2.474394215826995

Epoch: 6| Step: 13
Training loss: 0.24825561931296913
Validation loss: 2.4523088675497173

Epoch: 498| Step: 0
Training loss: 0.24750995346245833
Validation loss: 2.4347455732751495

Epoch: 6| Step: 1
Training loss: 0.2760349878666795
Validation loss: 2.3831679513616564

Epoch: 6| Step: 2
Training loss: 0.4072449860647625
Validation loss: 2.3800194207282637

Epoch: 6| Step: 3
Training loss: 0.32307958979246204
Validation loss: 2.372239946974435

Epoch: 6| Step: 4
Training loss: 0.18607755363121017
Validation loss: 2.4081804415679575

Epoch: 6| Step: 5
Training loss: 0.15788949089265872
Validation loss: 2.40962905051944

Epoch: 6| Step: 6
Training loss: 0.23016342045736626
Validation loss: 2.412483597149802

Epoch: 6| Step: 7
Training loss: 0.24608876208139985
Validation loss: 2.4442200770595766

Epoch: 6| Step: 8
Training loss: 0.1907685224206969
Validation loss: 2.4861549764581667

Epoch: 6| Step: 9
Training loss: 0.27569807759802256
Validation loss: 2.505139176973451

Epoch: 6| Step: 10
Training loss: 0.25289087476414557
Validation loss: 2.522017564266417

Epoch: 6| Step: 11
Training loss: 0.26242147588174264
Validation loss: 2.515599820273359

Epoch: 6| Step: 12
Training loss: 0.16696048457945648
Validation loss: 2.5002683157139156

Epoch: 6| Step: 13
Training loss: 0.3645982557603438
Validation loss: 2.5226527178904723

Epoch: 499| Step: 0
Training loss: 0.29350218211326257
Validation loss: 2.5140038542210243

Epoch: 6| Step: 1
Training loss: 0.14951037126627845
Validation loss: 2.482967080700844

Epoch: 6| Step: 2
Training loss: 0.1817684544149849
Validation loss: 2.464109741397307

Epoch: 6| Step: 3
Training loss: 0.28539989461602805
Validation loss: 2.4679844179194217

Epoch: 6| Step: 4
Training loss: 0.1999502589539122
Validation loss: 2.449873421065141

Epoch: 6| Step: 5
Training loss: 0.2195991146495826
Validation loss: 2.4217204552390275

Epoch: 6| Step: 6
Training loss: 0.4163123133987813
Validation loss: 2.413216848134903

Epoch: 6| Step: 7
Training loss: 0.2625241909914817
Validation loss: 2.406512744304094

Epoch: 6| Step: 8
Training loss: 0.24252168610045519
Validation loss: 2.4282836329692903

Epoch: 6| Step: 9
Training loss: 0.1785403098938029
Validation loss: 2.436152364103781

Epoch: 6| Step: 10
Training loss: 0.21494824729199527
Validation loss: 2.4480262325135884

Epoch: 6| Step: 11
Training loss: 0.17566982552488936
Validation loss: 2.462103514554297

Epoch: 6| Step: 12
Training loss: 0.22630015344239485
Validation loss: 2.482899433564195

Epoch: 6| Step: 13
Training loss: 0.25622228553976273
Validation loss: 2.5128821016163276

Epoch: 500| Step: 0
Training loss: 0.3121527411324481
Validation loss: 2.456447301924442

Epoch: 6| Step: 1
Training loss: 0.20278909308635412
Validation loss: 2.409573378392978

Epoch: 6| Step: 2
Training loss: 0.20403124314300997
Validation loss: 2.419012634881749

Epoch: 6| Step: 3
Training loss: 0.26648381186464654
Validation loss: 2.4490430165398607

Epoch: 6| Step: 4
Training loss: 0.20132300801522712
Validation loss: 2.398524777766207

Epoch: 6| Step: 5
Training loss: 0.1652970977307164
Validation loss: 2.4153664262571812

Epoch: 6| Step: 6
Training loss: 0.2739487772654082
Validation loss: 2.412878066447448

Epoch: 6| Step: 7
Training loss: 0.22339115662573877
Validation loss: 2.4012696763821033

Epoch: 6| Step: 8
Training loss: 0.22833635357062385
Validation loss: 2.442268802392595

Epoch: 6| Step: 9
Training loss: 0.36881875835694783
Validation loss: 2.4795167981987194

Epoch: 6| Step: 10
Training loss: 0.22459015971379753
Validation loss: 2.508768657841374

Epoch: 6| Step: 11
Training loss: 0.30930374654337855
Validation loss: 2.5197224455348333

Epoch: 6| Step: 12
Training loss: 0.22777585981661225
Validation loss: 2.5258833867425206

Epoch: 6| Step: 13
Training loss: 0.18760423941631132
Validation loss: 2.5101894501691553

Epoch: 501| Step: 0
Training loss: 0.26212882184401815
Validation loss: 2.5038962192579888

Epoch: 6| Step: 1
Training loss: 0.2725387926880839
Validation loss: 2.5194940415299745

Epoch: 6| Step: 2
Training loss: 0.1219362514584439
Validation loss: 2.436334217091032

Epoch: 6| Step: 3
Training loss: 0.12793364773510071
Validation loss: 2.4504379543175987

Epoch: 6| Step: 4
Training loss: 0.29111818132240347
Validation loss: 2.415277972817702

Epoch: 6| Step: 5
Training loss: 0.28062703758468555
Validation loss: 2.394598563415003

Epoch: 6| Step: 6
Training loss: 0.20390541288415948
Validation loss: 2.3932849012053814

Epoch: 6| Step: 7
Training loss: 0.3637787273703903
Validation loss: 2.3865687691384085

Epoch: 6| Step: 8
Training loss: 0.3349587243009803
Validation loss: 2.3964604573963837

Epoch: 6| Step: 9
Training loss: 0.16787177990589527
Validation loss: 2.404029024701421

Epoch: 6| Step: 10
Training loss: 0.27357066862649243
Validation loss: 2.4037661758225073

Epoch: 6| Step: 11
Training loss: 0.29427159852235046
Validation loss: 2.4717322929837855

Epoch: 6| Step: 12
Training loss: 0.31001394355855894
Validation loss: 2.475846761644426

Epoch: 6| Step: 13
Training loss: 0.31461763521258135
Validation loss: 2.4849813212486684

Epoch: 502| Step: 0
Training loss: 0.21233844015010228
Validation loss: 2.5114840957654683

Epoch: 6| Step: 1
Training loss: 0.35129200808039784
Validation loss: 2.4626900943874936

Epoch: 6| Step: 2
Training loss: 0.19371731697804154
Validation loss: 2.4402476060294234

Epoch: 6| Step: 3
Training loss: 0.22099799316776714
Validation loss: 2.448441798939195

Epoch: 6| Step: 4
Training loss: 0.15653287791987588
Validation loss: 2.436348732881585

Epoch: 6| Step: 5
Training loss: 0.22508168525885694
Validation loss: 2.423884610405564

Epoch: 6| Step: 6
Training loss: 0.34738506498714294
Validation loss: 2.4448721502722974

Epoch: 6| Step: 7
Training loss: 0.2742871299757498
Validation loss: 2.3939669758101423

Epoch: 6| Step: 8
Training loss: 0.35970548278240005
Validation loss: 2.4657028664441025

Epoch: 6| Step: 9
Training loss: 0.2210326477647312
Validation loss: 2.3791318658103444

Epoch: 6| Step: 10
Training loss: 0.2090217966818386
Validation loss: 2.438601469778157

Epoch: 6| Step: 11
Training loss: 0.30065469432587333
Validation loss: 2.4636347071355833

Epoch: 6| Step: 12
Training loss: 0.2217457290617654
Validation loss: 2.4403851044075413

Epoch: 6| Step: 13
Training loss: 0.2802528878896051
Validation loss: 2.488365966891911

Epoch: 503| Step: 0
Training loss: 0.26689047058343984
Validation loss: 2.465244571412661

Epoch: 6| Step: 1
Training loss: 0.2269332417430293
Validation loss: 2.496545624170837

Epoch: 6| Step: 2
Training loss: 0.2164513007414611
Validation loss: 2.453445560194233

Epoch: 6| Step: 3
Training loss: 0.30275616721196247
Validation loss: 2.42138328575411

Epoch: 6| Step: 4
Training loss: 0.25448634564713
Validation loss: 2.438854763425038

Epoch: 6| Step: 5
Training loss: 0.2759510452341604
Validation loss: 2.427197856402594

Epoch: 6| Step: 6
Training loss: 0.15151371785297488
Validation loss: 2.4110170163122744

Epoch: 6| Step: 7
Training loss: 0.11309639465658179
Validation loss: 2.4573519085819835

Epoch: 6| Step: 8
Training loss: 0.14661369972798408
Validation loss: 2.45146821868283

Epoch: 6| Step: 9
Training loss: 0.31047351138529583
Validation loss: 2.4572200477303685

Epoch: 6| Step: 10
Training loss: 0.19141856951868685
Validation loss: 2.464802248282159

Epoch: 6| Step: 11
Training loss: 0.20873846756036807
Validation loss: 2.480889307604278

Epoch: 6| Step: 12
Training loss: 0.31942549450040314
Validation loss: 2.4792799182261707

Epoch: 6| Step: 13
Training loss: 0.2878455888985337
Validation loss: 2.459231478677687

Epoch: 504| Step: 0
Training loss: 0.20578696046753978
Validation loss: 2.4915526633940615

Epoch: 6| Step: 1
Training loss: 0.2895917557902617
Validation loss: 2.504095433100919

Epoch: 6| Step: 2
Training loss: 0.301131329608868
Validation loss: 2.4904665855061183

Epoch: 6| Step: 3
Training loss: 0.2261970713520058
Validation loss: 2.4743827009405894

Epoch: 6| Step: 4
Training loss: 0.2745554142512416
Validation loss: 2.486136653586605

Epoch: 6| Step: 5
Training loss: 0.29392144749483434
Validation loss: 2.4438830073826794

Epoch: 6| Step: 6
Training loss: 0.2784390112753462
Validation loss: 2.502089745792524

Epoch: 6| Step: 7
Training loss: 0.23136434466682723
Validation loss: 2.4832174687741704

Epoch: 6| Step: 8
Training loss: 0.1666574972332432
Validation loss: 2.511977811735609

Epoch: 6| Step: 9
Training loss: 0.30031436750881263
Validation loss: 2.4990485226548196

Epoch: 6| Step: 10
Training loss: 0.22857177892140804
Validation loss: 2.51702963934671

Epoch: 6| Step: 11
Training loss: 0.19577140302319107
Validation loss: 2.5277394215163635

Epoch: 6| Step: 12
Training loss: 0.2282284537979918
Validation loss: 2.5436857835163624

Epoch: 6| Step: 13
Training loss: 0.2687367879591878
Validation loss: 2.5178390937026345

Epoch: 505| Step: 0
Training loss: 0.17935633203347937
Validation loss: 2.492208094934004

Epoch: 6| Step: 1
Training loss: 0.3966587416106958
Validation loss: 2.5084812827795933

Epoch: 6| Step: 2
Training loss: 0.42691782520111426
Validation loss: 2.4355608323488696

Epoch: 6| Step: 3
Training loss: 0.17692719031588877
Validation loss: 2.4572861295339825

Epoch: 6| Step: 4
Training loss: 0.14223563197051012
Validation loss: 2.4709178129111606

Epoch: 6| Step: 5
Training loss: 0.2708651939627461
Validation loss: 2.4712917451783363

Epoch: 6| Step: 6
Training loss: 0.27825439743378433
Validation loss: 2.4599038417780004

Epoch: 6| Step: 7
Training loss: 0.17526209779890073
Validation loss: 2.471262058620747

Epoch: 6| Step: 8
Training loss: 0.20608144288122138
Validation loss: 2.492514003428349

Epoch: 6| Step: 9
Training loss: 0.21567121162580605
Validation loss: 2.5237142998452273

Epoch: 6| Step: 10
Training loss: 0.1704082871473931
Validation loss: 2.530193923346288

Epoch: 6| Step: 11
Training loss: 0.2787124013561576
Validation loss: 2.535988313960685

Epoch: 6| Step: 12
Training loss: 0.16113396846472194
Validation loss: 2.518584436514021

Epoch: 6| Step: 13
Training loss: 0.21746206047216296
Validation loss: 2.4974073646104085

Epoch: 506| Step: 0
Training loss: 0.2986216486259366
Validation loss: 2.5159034174942607

Epoch: 6| Step: 1
Training loss: 0.18252834668207332
Validation loss: 2.4567499506925485

Epoch: 6| Step: 2
Training loss: 0.12337489532381234
Validation loss: 2.455943388814482

Epoch: 6| Step: 3
Training loss: 0.11120540145531421
Validation loss: 2.526505889370993

Epoch: 6| Step: 4
Training loss: 0.21990132481452193
Validation loss: 2.492387072670272

Epoch: 6| Step: 5
Training loss: 0.20352141505697882
Validation loss: 2.5216358788378432

Epoch: 6| Step: 6
Training loss: 0.20838234543453932
Validation loss: 2.5056119585402152

Epoch: 6| Step: 7
Training loss: 0.24407446918615425
Validation loss: 2.5159721300611677

Epoch: 6| Step: 8
Training loss: 0.28904082242770823
Validation loss: 2.488867320828784

Epoch: 6| Step: 9
Training loss: 0.18471618216621796
Validation loss: 2.483114442705491

Epoch: 6| Step: 10
Training loss: 0.21563974654869617
Validation loss: 2.461110119577275

Epoch: 6| Step: 11
Training loss: 0.15878194720290298
Validation loss: 2.430994569143764

Epoch: 6| Step: 12
Training loss: 0.17645419373117258
Validation loss: 2.442152902406647

Epoch: 6| Step: 13
Training loss: 0.3860709033166986
Validation loss: 2.4721169835519863

Epoch: 507| Step: 0
Training loss: 0.22528523471952547
Validation loss: 2.4644430995341278

Epoch: 6| Step: 1
Training loss: 0.21543028270262238
Validation loss: 2.466726017309727

Epoch: 6| Step: 2
Training loss: 0.14446406478265422
Validation loss: 2.496104511522348

Epoch: 6| Step: 3
Training loss: 0.30547525589202695
Validation loss: 2.4580418111630866

Epoch: 6| Step: 4
Training loss: 0.3069426513073377
Validation loss: 2.466410373431185

Epoch: 6| Step: 5
Training loss: 0.16790722673928282
Validation loss: 2.4284926788034538

Epoch: 6| Step: 6
Training loss: 0.23649316337242712
Validation loss: 2.456309605745453

Epoch: 6| Step: 7
Training loss: 0.1410343120799563
Validation loss: 2.4267643379088537

Epoch: 6| Step: 8
Training loss: 0.11806793085696252
Validation loss: 2.436671364120405

Epoch: 6| Step: 9
Training loss: 0.19909269421282094
Validation loss: 2.436905653026871

Epoch: 6| Step: 10
Training loss: 0.27364743212051446
Validation loss: 2.4705772154135923

Epoch: 6| Step: 11
Training loss: 0.16497832089030026
Validation loss: 2.451968217432135

Epoch: 6| Step: 12
Training loss: 0.28553760842291726
Validation loss: 2.4545862765059754

Epoch: 6| Step: 13
Training loss: 0.1407522182399905
Validation loss: 2.4437505241523354

Epoch: 508| Step: 0
Training loss: 0.1576199437955723
Validation loss: 2.448114643630812

Epoch: 6| Step: 1
Training loss: 0.1969406453695296
Validation loss: 2.4542576009522876

Epoch: 6| Step: 2
Training loss: 0.27557366963636165
Validation loss: 2.439681937385546

Epoch: 6| Step: 3
Training loss: 0.21899392798848286
Validation loss: 2.4259306136568046

Epoch: 6| Step: 4
Training loss: 0.25941271220509043
Validation loss: 2.4381356324250087

Epoch: 6| Step: 5
Training loss: 0.17185118900436586
Validation loss: 2.439884980508461

Epoch: 6| Step: 6
Training loss: 0.162012663109012
Validation loss: 2.468031762535174

Epoch: 6| Step: 7
Training loss: 0.17673785797786795
Validation loss: 2.461836181978053

Epoch: 6| Step: 8
Training loss: 0.23102846714326689
Validation loss: 2.4277713340430407

Epoch: 6| Step: 9
Training loss: 0.1485397714353074
Validation loss: 2.4861469977917383

Epoch: 6| Step: 10
Training loss: 0.16971712821490423
Validation loss: 2.456777956226934

Epoch: 6| Step: 11
Training loss: 0.2992689334628945
Validation loss: 2.4636616656267796

Epoch: 6| Step: 12
Training loss: 0.1352515650797914
Validation loss: 2.4736174055244042

Epoch: 6| Step: 13
Training loss: 0.13842803040057358
Validation loss: 2.47949410235202

Epoch: 509| Step: 0
Training loss: 0.0776270884412977
Validation loss: 2.424213783008679

Epoch: 6| Step: 1
Training loss: 0.11267281610214623
Validation loss: 2.4600476050770848

Epoch: 6| Step: 2
Training loss: 0.2312863363251252
Validation loss: 2.468866990623398

Epoch: 6| Step: 3
Training loss: 0.09493001738111015
Validation loss: 2.466888010087516

Epoch: 6| Step: 4
Training loss: 0.24842656729292942
Validation loss: 2.454772306250277

Epoch: 6| Step: 5
Training loss: 0.24511208851894656
Validation loss: 2.452684515365783

Epoch: 6| Step: 6
Training loss: 0.33945746775703645
Validation loss: 2.449853331989329

Epoch: 6| Step: 7
Training loss: 0.09751077306663491
Validation loss: 2.46964273216536

Epoch: 6| Step: 8
Training loss: 0.18156497159184964
Validation loss: 2.4774864639015592

Epoch: 6| Step: 9
Training loss: 0.28187481036465306
Validation loss: 2.4861566428232638

Epoch: 6| Step: 10
Training loss: 0.159377764696563
Validation loss: 2.4913778796255506

Epoch: 6| Step: 11
Training loss: 0.18056706066848563
Validation loss: 2.4976390006076703

Epoch: 6| Step: 12
Training loss: 0.12579408633441647
Validation loss: 2.4533763835335725

Epoch: 6| Step: 13
Training loss: 0.3238568296698261
Validation loss: 2.4873781519531577

Epoch: 510| Step: 0
Training loss: 0.14773262964969686
Validation loss: 2.5044840745446413

Epoch: 6| Step: 1
Training loss: 0.16263751094254567
Validation loss: 2.470004143107158

Epoch: 6| Step: 2
Training loss: 0.26809631069679907
Validation loss: 2.5012462647511278

Epoch: 6| Step: 3
Training loss: 0.25820231589047715
Validation loss: 2.461701272554926

Epoch: 6| Step: 4
Training loss: 0.17634720821156816
Validation loss: 2.4492699674553466

Epoch: 6| Step: 5
Training loss: 0.15632307012984317
Validation loss: 2.418712147765788

Epoch: 6| Step: 6
Training loss: 0.19108967974017146
Validation loss: 2.465166142503247

Epoch: 6| Step: 7
Training loss: 0.15600541760974596
Validation loss: 2.4559498126693273

Epoch: 6| Step: 8
Training loss: 0.3742523488867367
Validation loss: 2.4255564072557467

Epoch: 6| Step: 9
Training loss: 0.09370603126381276
Validation loss: 2.4168199470065383

Epoch: 6| Step: 10
Training loss: 0.2284914639733747
Validation loss: 2.44361019157891

Epoch: 6| Step: 11
Training loss: 0.21777121367409608
Validation loss: 2.435482036486932

Epoch: 6| Step: 12
Training loss: 0.27074836198851954
Validation loss: 2.485170178948931

Epoch: 6| Step: 13
Training loss: 0.16269544576247896
Validation loss: 2.4610208560065057

Epoch: 511| Step: 0
Training loss: 0.15073332197775088
Validation loss: 2.4806040943891006

Epoch: 6| Step: 1
Training loss: 0.19566494613085428
Validation loss: 2.478175513113702

Epoch: 6| Step: 2
Training loss: 0.15057080485977414
Validation loss: 2.47515113421326

Epoch: 6| Step: 3
Training loss: 0.1493435238151809
Validation loss: 2.5277055327137083

Epoch: 6| Step: 4
Training loss: 0.23969091802146866
Validation loss: 2.5289106792473874

Epoch: 6| Step: 5
Training loss: 0.2504211097763194
Validation loss: 2.509235915406353

Epoch: 6| Step: 6
Training loss: 0.32689442808426883
Validation loss: 2.502773468996198

Epoch: 6| Step: 7
Training loss: 0.151263847761468
Validation loss: 2.550759042509621

Epoch: 6| Step: 8
Training loss: 0.19601026824953932
Validation loss: 2.5363668525631318

Epoch: 6| Step: 9
Training loss: 0.15787095059142112
Validation loss: 2.4780541089391255

Epoch: 6| Step: 10
Training loss: 0.17615010450551172
Validation loss: 2.45898438855329

Epoch: 6| Step: 11
Training loss: 0.31072565846386835
Validation loss: 2.4876286659350053

Epoch: 6| Step: 12
Training loss: 0.19117757215845985
Validation loss: 2.4783189799098246

Epoch: 6| Step: 13
Training loss: 0.2690670051153239
Validation loss: 2.4550851191727485

Epoch: 512| Step: 0
Training loss: 0.17587997525158747
Validation loss: 2.4298324243664435

Epoch: 6| Step: 1
Training loss: 0.18435456518304807
Validation loss: 2.4661631075436463

Epoch: 6| Step: 2
Training loss: 0.22975628043599194
Validation loss: 2.4463241168875487

Epoch: 6| Step: 3
Training loss: 0.19585515929570674
Validation loss: 2.4703738551098096

Epoch: 6| Step: 4
Training loss: 0.20620328959471249
Validation loss: 2.4894254519998906

Epoch: 6| Step: 5
Training loss: 0.1759630587579991
Validation loss: 2.5114692149768674

Epoch: 6| Step: 6
Training loss: 0.24827198266942405
Validation loss: 2.4993307325302325

Epoch: 6| Step: 7
Training loss: 0.3735266790487723
Validation loss: 2.4920570960992547

Epoch: 6| Step: 8
Training loss: 0.32424745087956147
Validation loss: 2.4852602694452797

Epoch: 6| Step: 9
Training loss: 0.16873741036712336
Validation loss: 2.4763176671722174

Epoch: 6| Step: 10
Training loss: 0.17701565393499327
Validation loss: 2.456388352393929

Epoch: 6| Step: 11
Training loss: 0.21362775524945166
Validation loss: 2.470941933189985

Epoch: 6| Step: 12
Training loss: 0.183497099089495
Validation loss: 2.4416387385103473

Epoch: 6| Step: 13
Training loss: 0.17945246251689373
Validation loss: 2.498442970469004

Epoch: 513| Step: 0
Training loss: 0.28088146807239267
Validation loss: 2.4671482878414364

Epoch: 6| Step: 1
Training loss: 0.17647448641635702
Validation loss: 2.4606157786941765

Epoch: 6| Step: 2
Training loss: 0.29276614494988096
Validation loss: 2.4625437744540744

Epoch: 6| Step: 3
Training loss: 0.1941183875720775
Validation loss: 2.457966826631464

Epoch: 6| Step: 4
Training loss: 0.2654750905842981
Validation loss: 2.4678744353182918

Epoch: 6| Step: 5
Training loss: 0.1444541300114052
Validation loss: 2.4850110017537035

Epoch: 6| Step: 6
Training loss: 0.14871597519987464
Validation loss: 2.486285047537606

Epoch: 6| Step: 7
Training loss: 0.10757701248502351
Validation loss: 2.52274534718985

Epoch: 6| Step: 8
Training loss: 0.26824896316559027
Validation loss: 2.527533663829425

Epoch: 6| Step: 9
Training loss: 0.28721160106791366
Validation loss: 2.5284702731835305

Epoch: 6| Step: 10
Training loss: 0.06427316395311997
Validation loss: 2.503629074662307

Epoch: 6| Step: 11
Training loss: 0.1289987521185141
Validation loss: 2.498369435291942

Epoch: 6| Step: 12
Training loss: 0.162364282466133
Validation loss: 2.532867428878959

Epoch: 6| Step: 13
Training loss: 0.17962824839705555
Validation loss: 2.5207044513746366

Epoch: 514| Step: 0
Training loss: 0.2504151295113844
Validation loss: 2.5485207898198894

Epoch: 6| Step: 1
Training loss: 0.2844662614202492
Validation loss: 2.522576404645652

Epoch: 6| Step: 2
Training loss: 0.21797020751028295
Validation loss: 2.520241572227292

Epoch: 6| Step: 3
Training loss: 0.10454182025398435
Validation loss: 2.524742667463852

Epoch: 6| Step: 4
Training loss: 0.17819165521926222
Validation loss: 2.5005754106012787

Epoch: 6| Step: 5
Training loss: 0.1518965662451669
Validation loss: 2.4679296773182755

Epoch: 6| Step: 6
Training loss: 0.24098112765196128
Validation loss: 2.4430342212704135

Epoch: 6| Step: 7
Training loss: 0.20000977641291365
Validation loss: 2.433089528559615

Epoch: 6| Step: 8
Training loss: 0.16348779017678391
Validation loss: 2.4207827324934126

Epoch: 6| Step: 9
Training loss: 0.13723508880561633
Validation loss: 2.4252594734466895

Epoch: 6| Step: 10
Training loss: 0.15335295262931725
Validation loss: 2.4374134141947783

Epoch: 6| Step: 11
Training loss: 0.15523440992165852
Validation loss: 2.466672259512594

Epoch: 6| Step: 12
Training loss: 0.28908427903893147
Validation loss: 2.4739656744666165

Epoch: 6| Step: 13
Training loss: 0.2865939021818809
Validation loss: 2.474137865858932

Epoch: 515| Step: 0
Training loss: 0.13207690504849418
Validation loss: 2.475800377514075

Epoch: 6| Step: 1
Training loss: 0.11814035225059649
Validation loss: 2.4217926201916313

Epoch: 6| Step: 2
Training loss: 0.29432054819884346
Validation loss: 2.435702612797056

Epoch: 6| Step: 3
Training loss: 0.24411498888840846
Validation loss: 2.454499109540436

Epoch: 6| Step: 4
Training loss: 0.1416947485693858
Validation loss: 2.4187077766530267

Epoch: 6| Step: 5
Training loss: 0.18898076229419208
Validation loss: 2.4755227597215206

Epoch: 6| Step: 6
Training loss: 0.14624827112904024
Validation loss: 2.4341014100209284

Epoch: 6| Step: 7
Training loss: 0.18342081000518262
Validation loss: 2.4694473114631297

Epoch: 6| Step: 8
Training loss: 0.14484927911709072
Validation loss: 2.430587876061533

Epoch: 6| Step: 9
Training loss: 0.3160462155996482
Validation loss: 2.44231283990633

Epoch: 6| Step: 10
Training loss: 0.2239029265035302
Validation loss: 2.4388215721145374

Epoch: 6| Step: 11
Training loss: 0.20248800128839628
Validation loss: 2.463947571684169

Epoch: 6| Step: 12
Training loss: 0.29615826419758423
Validation loss: 2.4574592413598815

Epoch: 6| Step: 13
Training loss: 0.32493452549692076
Validation loss: 2.479036270011751

Epoch: 516| Step: 0
Training loss: 0.19157682331048378
Validation loss: 2.506391610679442

Epoch: 6| Step: 1
Training loss: 0.11717040414086657
Validation loss: 2.496660517559543

Epoch: 6| Step: 2
Training loss: 0.23865855159501345
Validation loss: 2.5162628741902098

Epoch: 6| Step: 3
Training loss: 0.19746166346083555
Validation loss: 2.4361528366007197

Epoch: 6| Step: 4
Training loss: 0.22005938436972705
Validation loss: 2.4363820625772066

Epoch: 6| Step: 5
Training loss: 0.2643534152596248
Validation loss: 2.4402692391841243

Epoch: 6| Step: 6
Training loss: 0.1692682388302453
Validation loss: 2.4228747180430164

Epoch: 6| Step: 7
Training loss: 0.1373760838144779
Validation loss: 2.4242554344361142

Epoch: 6| Step: 8
Training loss: 0.1779835180932241
Validation loss: 2.445324975282372

Epoch: 6| Step: 9
Training loss: 0.170573716246694
Validation loss: 2.428284917806772

Epoch: 6| Step: 10
Training loss: 0.25019509928185746
Validation loss: 2.424170507024017

Epoch: 6| Step: 11
Training loss: 0.31385329001517703
Validation loss: 2.426755682785299

Epoch: 6| Step: 12
Training loss: 0.1426546205133003
Validation loss: 2.454791100817073

Epoch: 6| Step: 13
Training loss: 0.1342327529388279
Validation loss: 2.4263665728264368

Epoch: 517| Step: 0
Training loss: 0.1635868864705539
Validation loss: 2.4447943730762294

Epoch: 6| Step: 1
Training loss: 0.15908761667430296
Validation loss: 2.4503151067961397

Epoch: 6| Step: 2
Training loss: 0.16833100511357957
Validation loss: 2.4878015233308726

Epoch: 6| Step: 3
Training loss: 0.21172396312080916
Validation loss: 2.4266842369575787

Epoch: 6| Step: 4
Training loss: 0.21337268217947555
Validation loss: 2.444368174518403

Epoch: 6| Step: 5
Training loss: 0.2164789566578925
Validation loss: 2.4194088990314095

Epoch: 6| Step: 6
Training loss: 0.1498025692587327
Validation loss: 2.407073090179293

Epoch: 6| Step: 7
Training loss: 0.12364334902226645
Validation loss: 2.3894791580532453

Epoch: 6| Step: 8
Training loss: 0.28763832620770047
Validation loss: 2.4315897083317837

Epoch: 6| Step: 9
Training loss: 0.36862720125872833
Validation loss: 2.4479190390912886

Epoch: 6| Step: 10
Training loss: 0.1736291968673989
Validation loss: 2.4549214661811973

Epoch: 6| Step: 11
Training loss: 0.21731256033573185
Validation loss: 2.426140233129249

Epoch: 6| Step: 12
Training loss: 0.18560510022972698
Validation loss: 2.439681216004808

Epoch: 6| Step: 13
Training loss: 0.1060812305724056
Validation loss: 2.444571171859909

Epoch: 518| Step: 0
Training loss: 0.19172952561070442
Validation loss: 2.4293167036543477

Epoch: 6| Step: 1
Training loss: 0.16522112515940943
Validation loss: 2.442018652191192

Epoch: 6| Step: 2
Training loss: 0.19463503646575267
Validation loss: 2.4899473308220306

Epoch: 6| Step: 3
Training loss: 0.21766840535909704
Validation loss: 2.4553667219742494

Epoch: 6| Step: 4
Training loss: 0.23901834765839472
Validation loss: 2.496677593648852

Epoch: 6| Step: 5
Training loss: 0.18073479582258628
Validation loss: 2.4805039011640093

Epoch: 6| Step: 6
Training loss: 0.3098706494311019
Validation loss: 2.4620182964369866

Epoch: 6| Step: 7
Training loss: 0.20010671748677328
Validation loss: 2.4764815967145397

Epoch: 6| Step: 8
Training loss: 0.15395631508371121
Validation loss: 2.4974117478504287

Epoch: 6| Step: 9
Training loss: 0.22792250124235386
Validation loss: 2.4853905033905104

Epoch: 6| Step: 10
Training loss: 0.14859124428233883
Validation loss: 2.501136529648878

Epoch: 6| Step: 11
Training loss: 0.12174139341075683
Validation loss: 2.478258285183362

Epoch: 6| Step: 12
Training loss: 0.35623392604235893
Validation loss: 2.5112925517002593

Epoch: 6| Step: 13
Training loss: 0.2048193252283012
Validation loss: 2.4967724854954008

Epoch: 519| Step: 0
Training loss: 0.25680482335058175
Validation loss: 2.4774328531897134

Epoch: 6| Step: 1
Training loss: 0.26176060868491663
Validation loss: 2.4607532938171417

Epoch: 6| Step: 2
Training loss: 0.22690771374100963
Validation loss: 2.4730497232911386

Epoch: 6| Step: 3
Training loss: 0.146009973995284
Validation loss: 2.4531221893338335

Epoch: 6| Step: 4
Training loss: 0.2213474506406503
Validation loss: 2.4420696721263826

Epoch: 6| Step: 5
Training loss: 0.17852337693092402
Validation loss: 2.469686918926981

Epoch: 6| Step: 6
Training loss: 0.23343388435903467
Validation loss: 2.4323036826127806

Epoch: 6| Step: 7
Training loss: 0.1654383552379285
Validation loss: 2.4308186097390507

Epoch: 6| Step: 8
Training loss: 0.20695213389636363
Validation loss: 2.45718083724411

Epoch: 6| Step: 9
Training loss: 0.17264431312344078
Validation loss: 2.4903241088322035

Epoch: 6| Step: 10
Training loss: 0.12084399123570977
Validation loss: 2.497626786113041

Epoch: 6| Step: 11
Training loss: 0.14169546499610608
Validation loss: 2.5192170000810066

Epoch: 6| Step: 12
Training loss: 0.4005559998423975
Validation loss: 2.502087240644776

Epoch: 6| Step: 13
Training loss: 0.1464458033323775
Validation loss: 2.4754623858293052

Epoch: 520| Step: 0
Training loss: 0.1673919065446525
Validation loss: 2.4320551869787437

Epoch: 6| Step: 1
Training loss: 0.3116174155520006
Validation loss: 2.4522586277844542

Epoch: 6| Step: 2
Training loss: 0.22359857755257181
Validation loss: 2.405526931383544

Epoch: 6| Step: 3
Training loss: 0.19687853499675154
Validation loss: 2.437645043579431

Epoch: 6| Step: 4
Training loss: 0.2648006297204505
Validation loss: 2.4648921060773015

Epoch: 6| Step: 5
Training loss: 0.26515852415225694
Validation loss: 2.4630592737796113

Epoch: 6| Step: 6
Training loss: 0.3118947844259728
Validation loss: 2.487769151483626

Epoch: 6| Step: 7
Training loss: 0.16574496477053685
Validation loss: 2.508103306366195

Epoch: 6| Step: 8
Training loss: 0.24385568393972332
Validation loss: 2.5108261761555286

Epoch: 6| Step: 9
Training loss: 0.34880427143348
Validation loss: 2.508708532211701

Epoch: 6| Step: 10
Training loss: 0.22375917820779914
Validation loss: 2.5134468205106946

Epoch: 6| Step: 11
Training loss: 0.15227588340098766
Validation loss: 2.495336469296191

Epoch: 6| Step: 12
Training loss: 0.23416369767756076
Validation loss: 2.511714453478152

Epoch: 6| Step: 13
Training loss: 0.1775486887891464
Validation loss: 2.4929667897202146

Epoch: 521| Step: 0
Training loss: 0.15182608905921738
Validation loss: 2.4696461380422567

Epoch: 6| Step: 1
Training loss: 0.2513243051036463
Validation loss: 2.492423225236035

Epoch: 6| Step: 2
Training loss: 0.24815479694196124
Validation loss: 2.437924611813485

Epoch: 6| Step: 3
Training loss: 0.20937946442925912
Validation loss: 2.4518661712606895

Epoch: 6| Step: 4
Training loss: 0.23030009806975024
Validation loss: 2.440705227395579

Epoch: 6| Step: 5
Training loss: 0.27307699143821135
Validation loss: 2.441471491903805

Epoch: 6| Step: 6
Training loss: 0.18571355260027034
Validation loss: 2.418070167252692

Epoch: 6| Step: 7
Training loss: 0.23976081600941254
Validation loss: 2.4848939556510787

Epoch: 6| Step: 8
Training loss: 0.15028779118216287
Validation loss: 2.4625005443142016

Epoch: 6| Step: 9
Training loss: 0.16607696297648453
Validation loss: 2.504401659474382

Epoch: 6| Step: 10
Training loss: 0.24891778537244286
Validation loss: 2.516834948163778

Epoch: 6| Step: 11
Training loss: 0.2938231661154217
Validation loss: 2.5049601355535573

Epoch: 6| Step: 12
Training loss: 0.21761747514619786
Validation loss: 2.4912988461469503

Epoch: 6| Step: 13
Training loss: 0.15412268282354274
Validation loss: 2.4760746608508244

Epoch: 522| Step: 0
Training loss: 0.22439101011966903
Validation loss: 2.515490071306043

Epoch: 6| Step: 1
Training loss: 0.17358622703766743
Validation loss: 2.4411763747415045

Epoch: 6| Step: 2
Training loss: 0.1496594414963134
Validation loss: 2.453190549945667

Epoch: 6| Step: 3
Training loss: 0.2127877433033724
Validation loss: 2.45231686666659

Epoch: 6| Step: 4
Training loss: 0.162962644193825
Validation loss: 2.426405078375857

Epoch: 6| Step: 5
Training loss: 0.20320202210804247
Validation loss: 2.4153088691604774

Epoch: 6| Step: 6
Training loss: 0.2859728760019896
Validation loss: 2.4430777082453043

Epoch: 6| Step: 7
Training loss: 0.2214413003899554
Validation loss: 2.4382619316392793

Epoch: 6| Step: 8
Training loss: 0.17261964789745804
Validation loss: 2.492848832180621

Epoch: 6| Step: 9
Training loss: 0.16925348718725966
Validation loss: 2.473527548588673

Epoch: 6| Step: 10
Training loss: 0.2810424727807008
Validation loss: 2.4475855456547104

Epoch: 6| Step: 11
Training loss: 0.23104640529876597
Validation loss: 2.4589049279797477

Epoch: 6| Step: 12
Training loss: 0.2030859322757944
Validation loss: 2.4258131121862214

Epoch: 6| Step: 13
Training loss: 0.1702785530293298
Validation loss: 2.419468575251582

Epoch: 523| Step: 0
Training loss: 0.22697263623933348
Validation loss: 2.467339133955844

Epoch: 6| Step: 1
Training loss: 0.226099890287441
Validation loss: 2.4262945956900546

Epoch: 6| Step: 2
Training loss: 0.21454749054918032
Validation loss: 2.495646899422971

Epoch: 6| Step: 3
Training loss: 0.23702389780509905
Validation loss: 2.4840350907549196

Epoch: 6| Step: 4
Training loss: 0.20282108238764415
Validation loss: 2.488676265734872

Epoch: 6| Step: 5
Training loss: 0.16442094542383684
Validation loss: 2.4432524794296357

Epoch: 6| Step: 6
Training loss: 0.14129651854407999
Validation loss: 2.405350953849069

Epoch: 6| Step: 7
Training loss: 0.30067806207834674
Validation loss: 2.440833439397087

Epoch: 6| Step: 8
Training loss: 0.0933814852561257
Validation loss: 2.422682061291521

Epoch: 6| Step: 9
Training loss: 0.29255575952749374
Validation loss: 2.412248415620259

Epoch: 6| Step: 10
Training loss: 0.15223818569431413
Validation loss: 2.3892580376554116

Epoch: 6| Step: 11
Training loss: 0.11151483839991495
Validation loss: 2.4437949986413137

Epoch: 6| Step: 12
Training loss: 0.14398880279571574
Validation loss: 2.4455234290234347

Epoch: 6| Step: 13
Training loss: 0.37543918799625264
Validation loss: 2.4621490212671433

Epoch: 524| Step: 0
Training loss: 0.21078287744706808
Validation loss: 2.4750882322465997

Epoch: 6| Step: 1
Training loss: 0.24521704079917211
Validation loss: 2.420213048788191

Epoch: 6| Step: 2
Training loss: 0.24055276876516102
Validation loss: 2.455629961220101

Epoch: 6| Step: 3
Training loss: 0.24329824460549146
Validation loss: 2.4366194115418423

Epoch: 6| Step: 4
Training loss: 0.2015466901951481
Validation loss: 2.447582682017274

Epoch: 6| Step: 5
Training loss: 0.17704534590679177
Validation loss: 2.469442396886986

Epoch: 6| Step: 6
Training loss: 0.19880757253729162
Validation loss: 2.416381078259122

Epoch: 6| Step: 7
Training loss: 0.20944964231322585
Validation loss: 2.439510935811165

Epoch: 6| Step: 8
Training loss: 0.14613015261923656
Validation loss: 2.4144743911031696

Epoch: 6| Step: 9
Training loss: 0.27987704008209907
Validation loss: 2.41296122020472

Epoch: 6| Step: 10
Training loss: 0.1765896856427226
Validation loss: 2.442056746127159

Epoch: 6| Step: 11
Training loss: 0.19784609682567844
Validation loss: 2.4290390317846637

Epoch: 6| Step: 12
Training loss: 0.17312359282544867
Validation loss: 2.42771491530974

Epoch: 6| Step: 13
Training loss: 0.16909891103109628
Validation loss: 2.4449531956667565

Epoch: 525| Step: 0
Training loss: 0.2136676414809577
Validation loss: 2.4377991046084744

Epoch: 6| Step: 1
Training loss: 0.27146432651618985
Validation loss: 2.4559164703417307

Epoch: 6| Step: 2
Training loss: 0.1587664734748549
Validation loss: 2.4413187179789033

Epoch: 6| Step: 3
Training loss: 0.0966943094004719
Validation loss: 2.4578411290177233

Epoch: 6| Step: 4
Training loss: 0.15990117159411843
Validation loss: 2.4493671428608814

Epoch: 6| Step: 5
Training loss: 0.15510455730223371
Validation loss: 2.4476159446249315

Epoch: 6| Step: 6
Training loss: 0.1510423435546791
Validation loss: 2.4700064773644024

Epoch: 6| Step: 7
Training loss: 0.13742225031018038
Validation loss: 2.4433361932505293

Epoch: 6| Step: 8
Training loss: 0.12453815703101452
Validation loss: 2.4515744747273396

Epoch: 6| Step: 9
Training loss: 0.1386603095376202
Validation loss: 2.4395191957377698

Epoch: 6| Step: 10
Training loss: 0.3274717981812031
Validation loss: 2.460847384249414

Epoch: 6| Step: 11
Training loss: 0.17794283494833646
Validation loss: 2.4589380911217336

Epoch: 6| Step: 12
Training loss: 0.2685450881629556
Validation loss: 2.483739417531495

Epoch: 6| Step: 13
Training loss: 0.27586008193347616
Validation loss: 2.4647413975249632

Epoch: 526| Step: 0
Training loss: 0.10131845129537434
Validation loss: 2.4561285804317614

Epoch: 6| Step: 1
Training loss: 0.2994140415975485
Validation loss: 2.46424708651081

Epoch: 6| Step: 2
Training loss: 0.16903142443397734
Validation loss: 2.470848432596197

Epoch: 6| Step: 3
Training loss: 0.21603777877033886
Validation loss: 2.4826348566290797

Epoch: 6| Step: 4
Training loss: 0.11694847207251664
Validation loss: 2.501754892882719

Epoch: 6| Step: 5
Training loss: 0.15480410823862845
Validation loss: 2.490028548174405

Epoch: 6| Step: 6
Training loss: 0.3607402658953498
Validation loss: 2.4910512211100055

Epoch: 6| Step: 7
Training loss: 0.15576921044393235
Validation loss: 2.48923802221792

Epoch: 6| Step: 8
Training loss: 0.235978506326839
Validation loss: 2.451542018751835

Epoch: 6| Step: 9
Training loss: 0.21980318217069675
Validation loss: 2.50599409385514

Epoch: 6| Step: 10
Training loss: 0.1446191288581435
Validation loss: 2.4218629130823666

Epoch: 6| Step: 11
Training loss: 0.19018267726079938
Validation loss: 2.4193431903873175

Epoch: 6| Step: 12
Training loss: 0.18420384876595372
Validation loss: 2.427606525106662

Epoch: 6| Step: 13
Training loss: 0.16187823719484637
Validation loss: 2.3925888763782193

Epoch: 527| Step: 0
Training loss: 0.16641161757753642
Validation loss: 2.402287079851084

Epoch: 6| Step: 1
Training loss: 0.27599457872981986
Validation loss: 2.442905535522607

Epoch: 6| Step: 2
Training loss: 0.18865378354292583
Validation loss: 2.3976210556393234

Epoch: 6| Step: 3
Training loss: 0.15323463402850007
Validation loss: 2.399087900869125

Epoch: 6| Step: 4
Training loss: 0.27874447808548336
Validation loss: 2.4268304783866905

Epoch: 6| Step: 5
Training loss: 0.18009437231220765
Validation loss: 2.4323427244540468

Epoch: 6| Step: 6
Training loss: 0.18461110910512493
Validation loss: 2.4528223951911463

Epoch: 6| Step: 7
Training loss: 0.240801343766353
Validation loss: 2.416804534266646

Epoch: 6| Step: 8
Training loss: 0.26221464632651326
Validation loss: 2.4251958355885073

Epoch: 6| Step: 9
Training loss: 0.16261297732274432
Validation loss: 2.4425945025005342

Epoch: 6| Step: 10
Training loss: 0.13696125865922779
Validation loss: 2.4009946687235337

Epoch: 6| Step: 11
Training loss: 0.2141277694044271
Validation loss: 2.4508266002992403

Epoch: 6| Step: 12
Training loss: 0.20676384156526809
Validation loss: 2.442708617050169

Epoch: 6| Step: 13
Training loss: 0.17310114799512208
Validation loss: 2.4600617495978008

Epoch: 528| Step: 0
Training loss: 0.13939587890007762
Validation loss: 2.506937253950028

Epoch: 6| Step: 1
Training loss: 0.1169371672964027
Validation loss: 2.473110923688158

Epoch: 6| Step: 2
Training loss: 0.20253329107877352
Validation loss: 2.510191227730186

Epoch: 6| Step: 3
Training loss: 0.24389614834537976
Validation loss: 2.49125665678427

Epoch: 6| Step: 4
Training loss: 0.12886441158694067
Validation loss: 2.470920180543583

Epoch: 6| Step: 5
Training loss: 0.23522187454724955
Validation loss: 2.4385899540851765

Epoch: 6| Step: 6
Training loss: 0.263983803370552
Validation loss: 2.479137860657579

Epoch: 6| Step: 7
Training loss: 0.11927726992337329
Validation loss: 2.4487272353156015

Epoch: 6| Step: 8
Training loss: 0.14347172630046273
Validation loss: 2.4252265543139617

Epoch: 6| Step: 9
Training loss: 0.18173948284491923
Validation loss: 2.3885598873868825

Epoch: 6| Step: 10
Training loss: 0.12508897297105254
Validation loss: 2.4542899949025694

Epoch: 6| Step: 11
Training loss: 0.2794415825989458
Validation loss: 2.3830950954894674

Epoch: 6| Step: 12
Training loss: 0.1697777103663848
Validation loss: 2.426418324422531

Epoch: 6| Step: 13
Training loss: 0.24672930257019854
Validation loss: 2.3910178367705743

Epoch: 529| Step: 0
Training loss: 0.13617660113749017
Validation loss: 2.4266484091942533

Epoch: 6| Step: 1
Training loss: 0.12422632908041982
Validation loss: 2.3866019099775713

Epoch: 6| Step: 2
Training loss: 0.2632581785603456
Validation loss: 2.4834370786814746

Epoch: 6| Step: 3
Training loss: 0.2147291571446659
Validation loss: 2.466256543566865

Epoch: 6| Step: 4
Training loss: 0.16225920497809782
Validation loss: 2.417466875208996

Epoch: 6| Step: 5
Training loss: 0.2094624123369318
Validation loss: 2.4488683361802233

Epoch: 6| Step: 6
Training loss: 0.14072355816755275
Validation loss: 2.451715804892993

Epoch: 6| Step: 7
Training loss: 0.26921397346071746
Validation loss: 2.393711176029182

Epoch: 6| Step: 8
Training loss: 0.14666440708910575
Validation loss: 2.428797737493365

Epoch: 6| Step: 9
Training loss: 0.24736083519317695
Validation loss: 2.3908850147565843

Epoch: 6| Step: 10
Training loss: 0.31226008265474964
Validation loss: 2.4063549628801857

Epoch: 6| Step: 11
Training loss: 0.11931836830832618
Validation loss: 2.4309409075628805

Epoch: 6| Step: 12
Training loss: 0.11314438082189321
Validation loss: 2.4229483500140225

Epoch: 6| Step: 13
Training loss: 0.1090677578158775
Validation loss: 2.4954875594017345

Epoch: 530| Step: 0
Training loss: 0.16868944582783277
Validation loss: 2.50918553372825

Epoch: 6| Step: 1
Training loss: 0.24314358636520955
Validation loss: 2.5320068568796636

Epoch: 6| Step: 2
Training loss: 0.1306441515704452
Validation loss: 2.49772562121573

Epoch: 6| Step: 3
Training loss: 0.18558256910218415
Validation loss: 2.5011746179977243

Epoch: 6| Step: 4
Training loss: 0.09227251036855412
Validation loss: 2.4586106865713666

Epoch: 6| Step: 5
Training loss: 0.19769965475514858
Validation loss: 2.470647973028665

Epoch: 6| Step: 6
Training loss: 0.22343436018865134
Validation loss: 2.45466497400002

Epoch: 6| Step: 7
Training loss: 0.22514758104608648
Validation loss: 2.4322482406879358

Epoch: 6| Step: 8
Training loss: 0.16081561454413693
Validation loss: 2.4425076375711257

Epoch: 6| Step: 9
Training loss: 0.12465154986439385
Validation loss: 2.41515279233349

Epoch: 6| Step: 10
Training loss: 0.27899612560111536
Validation loss: 2.462498144641821

Epoch: 6| Step: 11
Training loss: 0.16524631984633817
Validation loss: 2.4457486897940734

Epoch: 6| Step: 12
Training loss: 0.1845840973727026
Validation loss: 2.416518684378338

Epoch: 6| Step: 13
Training loss: 0.1507521223188497
Validation loss: 2.4250150555116976

Epoch: 531| Step: 0
Training loss: 0.13548967490236272
Validation loss: 2.4300392154027706

Epoch: 6| Step: 1
Training loss: 0.11706204056433253
Validation loss: 2.4209109644643556

Epoch: 6| Step: 2
Training loss: 0.2508683323812809
Validation loss: 2.4487699548321507

Epoch: 6| Step: 3
Training loss: 0.23508593499701294
Validation loss: 2.44167178442998

Epoch: 6| Step: 4
Training loss: 0.17127344675772693
Validation loss: 2.4568585994885943

Epoch: 6| Step: 5
Training loss: 0.15272892042210517
Validation loss: 2.463897359579221

Epoch: 6| Step: 6
Training loss: 0.19874756385701717
Validation loss: 2.494287008254408

Epoch: 6| Step: 7
Training loss: 0.18084628220494778
Validation loss: 2.5007927365803653

Epoch: 6| Step: 8
Training loss: 0.2465817970803537
Validation loss: 2.4932338480108127

Epoch: 6| Step: 9
Training loss: 0.1173422705319598
Validation loss: 2.50976226845998

Epoch: 6| Step: 10
Training loss: 0.10327218779195833
Validation loss: 2.4866170231124682

Epoch: 6| Step: 11
Training loss: 0.11861516817533911
Validation loss: 2.4494577793523984

Epoch: 6| Step: 12
Training loss: 0.22887421862324578
Validation loss: 2.4232988959667683

Epoch: 6| Step: 13
Training loss: 0.21702572196912429
Validation loss: 2.440269912590728

Epoch: 532| Step: 0
Training loss: 0.18617204450822894
Validation loss: 2.434098577914735

Epoch: 6| Step: 1
Training loss: 0.15871174608607194
Validation loss: 2.440687697727625

Epoch: 6| Step: 2
Training loss: 0.3009395430546035
Validation loss: 2.469499295950927

Epoch: 6| Step: 3
Training loss: 0.22465371233326303
Validation loss: 2.4777930440582168

Epoch: 6| Step: 4
Training loss: 0.14401803528245358
Validation loss: 2.491362257220585

Epoch: 6| Step: 5
Training loss: 0.19649182944443191
Validation loss: 2.5124066636461126

Epoch: 6| Step: 6
Training loss: 0.230582629371835
Validation loss: 2.4812429524553536

Epoch: 6| Step: 7
Training loss: 0.1701504003729553
Validation loss: 2.45628106258001

Epoch: 6| Step: 8
Training loss: 0.33319551877354825
Validation loss: 2.527255977789002

Epoch: 6| Step: 9
Training loss: 0.10290005128762345
Validation loss: 2.493330677467122

Epoch: 6| Step: 10
Training loss: 0.11153184922491033
Validation loss: 2.466979708162517

Epoch: 6| Step: 11
Training loss: 0.13082864030339933
Validation loss: 2.4731313084532913

Epoch: 6| Step: 12
Training loss: 0.13206897202369702
Validation loss: 2.44092451354397

Epoch: 6| Step: 13
Training loss: 0.11193952071140732
Validation loss: 2.4501080118143457

Epoch: 533| Step: 0
Training loss: 0.1845272054237069
Validation loss: 2.4724206973430625

Epoch: 6| Step: 1
Training loss: 0.11485684508317774
Validation loss: 2.407799662706816

Epoch: 6| Step: 2
Training loss: 0.19888770891302915
Validation loss: 2.4601242000245027

Epoch: 6| Step: 3
Training loss: 0.13190681530240045
Validation loss: 2.4609741572813997

Epoch: 6| Step: 4
Training loss: 0.12239683350364072
Validation loss: 2.4471001044450347

Epoch: 6| Step: 5
Training loss: 0.25746972966276893
Validation loss: 2.4445221946218054

Epoch: 6| Step: 6
Training loss: 0.1844643586424624
Validation loss: 2.431701741622379

Epoch: 6| Step: 7
Training loss: 0.19808482045479484
Validation loss: 2.4722871489197242

Epoch: 6| Step: 8
Training loss: 0.12894481746667544
Validation loss: 2.483927032065444

Epoch: 6| Step: 9
Training loss: 0.1766762887938608
Validation loss: 2.480619973671239

Epoch: 6| Step: 10
Training loss: 0.13652407546433254
Validation loss: 2.4636447358286624

Epoch: 6| Step: 11
Training loss: 0.13532790765853886
Validation loss: 2.4351022589513738

Epoch: 6| Step: 12
Training loss: 0.28756939112782964
Validation loss: 2.4536822111858827

Epoch: 6| Step: 13
Training loss: 0.15779015718116152
Validation loss: 2.497831423363083

Epoch: 534| Step: 0
Training loss: 0.19115297921740534
Validation loss: 2.4889254990437535

Epoch: 6| Step: 1
Training loss: 0.16712398793307104
Validation loss: 2.501407985643929

Epoch: 6| Step: 2
Training loss: 0.23088543610874274
Validation loss: 2.522004462513897

Epoch: 6| Step: 3
Training loss: 0.18645262247713307
Validation loss: 2.4938771445343657

Epoch: 6| Step: 4
Training loss: 0.11476623683010688
Validation loss: 2.480973816045252

Epoch: 6| Step: 5
Training loss: 0.14232320073992438
Validation loss: 2.462836903192433

Epoch: 6| Step: 6
Training loss: 0.14018858637582268
Validation loss: 2.4174587679353357

Epoch: 6| Step: 7
Training loss: 0.23865864525072894
Validation loss: 2.433028212353372

Epoch: 6| Step: 8
Training loss: 0.27532528041138443
Validation loss: 2.4021332161731164

Epoch: 6| Step: 9
Training loss: 0.20292160047437804
Validation loss: 2.3926159346210842

Epoch: 6| Step: 10
Training loss: 0.265554250382985
Validation loss: 2.4425894877150194

Epoch: 6| Step: 11
Training loss: 0.24153327254313361
Validation loss: 2.4292622330460625

Epoch: 6| Step: 12
Training loss: 0.18914548731356035
Validation loss: 2.4476969182844264

Epoch: 6| Step: 13
Training loss: 0.10385304017143124
Validation loss: 2.4522432741730396

Epoch: 535| Step: 0
Training loss: 0.17988538212136812
Validation loss: 2.4685309995600955

Epoch: 6| Step: 1
Training loss: 0.16372153637199305
Validation loss: 2.4929118984015197

Epoch: 6| Step: 2
Training loss: 0.26905653792985307
Validation loss: 2.4621335963144206

Epoch: 6| Step: 3
Training loss: 0.2136701521028172
Validation loss: 2.4939229814697077

Epoch: 6| Step: 4
Training loss: 0.11044251230185442
Validation loss: 2.425274567663592

Epoch: 6| Step: 5
Training loss: 0.2872219643444619
Validation loss: 2.437262013115524

Epoch: 6| Step: 6
Training loss: 0.21954019059950597
Validation loss: 2.4569334761970625

Epoch: 6| Step: 7
Training loss: 0.18685831097490413
Validation loss: 2.4413868898341917

Epoch: 6| Step: 8
Training loss: 0.1605078686945936
Validation loss: 2.427108162098899

Epoch: 6| Step: 9
Training loss: 0.1901846164587569
Validation loss: 2.416632284641914

Epoch: 6| Step: 10
Training loss: 0.18812553052415532
Validation loss: 2.4146521668792125

Epoch: 6| Step: 11
Training loss: 0.12905913736521066
Validation loss: 2.4425581823320917

Epoch: 6| Step: 12
Training loss: 0.20249993177106673
Validation loss: 2.511686933415425

Epoch: 6| Step: 13
Training loss: 0.24801908172128817
Validation loss: 2.499317443126015

Epoch: 536| Step: 0
Training loss: 0.24891155946077154
Validation loss: 2.4694218716260155

Epoch: 6| Step: 1
Training loss: 0.2347247216617024
Validation loss: 2.4985972499107434

Epoch: 6| Step: 2
Training loss: 0.11871967838312954
Validation loss: 2.455345246896531

Epoch: 6| Step: 3
Training loss: 0.2708760313464195
Validation loss: 2.4766442815356156

Epoch: 6| Step: 4
Training loss: 0.17204122741343192
Validation loss: 2.4590454724721433

Epoch: 6| Step: 5
Training loss: 0.21912906364637774
Validation loss: 2.443937616295853

Epoch: 6| Step: 6
Training loss: 0.16421874304026435
Validation loss: 2.409061089663063

Epoch: 6| Step: 7
Training loss: 0.12666084683479276
Validation loss: 2.4450914202466456

Epoch: 6| Step: 8
Training loss: 0.1925735689750113
Validation loss: 2.449264385420181

Epoch: 6| Step: 9
Training loss: 0.25834705825206505
Validation loss: 2.4438611502581824

Epoch: 6| Step: 10
Training loss: 0.31146940522092936
Validation loss: 2.477536122765375

Epoch: 6| Step: 11
Training loss: 0.18072010923623483
Validation loss: 2.519766588373722

Epoch: 6| Step: 12
Training loss: 0.23576969975417553
Validation loss: 2.470115846623514

Epoch: 6| Step: 13
Training loss: 0.091154606147188
Validation loss: 2.4597692958968005

Epoch: 537| Step: 0
Training loss: 0.1568430612734798
Validation loss: 2.531621679082258

Epoch: 6| Step: 1
Training loss: 0.17980067172176945
Validation loss: 2.5112870217763947

Epoch: 6| Step: 2
Training loss: 0.36020829161950235
Validation loss: 2.516617656755639

Epoch: 6| Step: 3
Training loss: 0.1303570343323198
Validation loss: 2.5128555038588423

Epoch: 6| Step: 4
Training loss: 0.22088186233894158
Validation loss: 2.5030631716341905

Epoch: 6| Step: 5
Training loss: 0.19044322430351973
Validation loss: 2.549112365561812

Epoch: 6| Step: 6
Training loss: 0.1332320990052086
Validation loss: 2.544557409398777

Epoch: 6| Step: 7
Training loss: 0.13466728464773028
Validation loss: 2.5007025972205326

Epoch: 6| Step: 8
Training loss: 0.10824907167391237
Validation loss: 2.4636230358186486

Epoch: 6| Step: 9
Training loss: 0.3083032375330887
Validation loss: 2.4826415284357877

Epoch: 6| Step: 10
Training loss: 0.24812098019416143
Validation loss: 2.447426662131267

Epoch: 6| Step: 11
Training loss: 0.1745067326751867
Validation loss: 2.4141492734115397

Epoch: 6| Step: 12
Training loss: 0.1948546001102267
Validation loss: 2.453469844668769

Epoch: 6| Step: 13
Training loss: 0.2691728171264933
Validation loss: 2.4222185439682127

Epoch: 538| Step: 0
Training loss: 0.2875051819292868
Validation loss: 2.4039411309523593

Epoch: 6| Step: 1
Training loss: 0.1688830696506698
Validation loss: 2.4364119110765685

Epoch: 6| Step: 2
Training loss: 0.281917178049694
Validation loss: 2.4490556429222576

Epoch: 6| Step: 3
Training loss: 0.32019969070194465
Validation loss: 2.4461759397705176

Epoch: 6| Step: 4
Training loss: 0.14264920174441867
Validation loss: 2.5017477653148297

Epoch: 6| Step: 5
Training loss: 0.3079386651040503
Validation loss: 2.454946804611049

Epoch: 6| Step: 6
Training loss: 0.14314871753926933
Validation loss: 2.4749624753087645

Epoch: 6| Step: 7
Training loss: 0.15956883750803458
Validation loss: 2.427017818029506

Epoch: 6| Step: 8
Training loss: 0.12220809027658157
Validation loss: 2.4521338071890746

Epoch: 6| Step: 9
Training loss: 0.17294812064788828
Validation loss: 2.42134397191337

Epoch: 6| Step: 10
Training loss: 0.17108910959300036
Validation loss: 2.428028202855428

Epoch: 6| Step: 11
Training loss: 0.18346424811078077
Validation loss: 2.3841686911454154

Epoch: 6| Step: 12
Training loss: 0.2131918954041054
Validation loss: 2.4362306384435817

Epoch: 6| Step: 13
Training loss: 0.2190618676082609
Validation loss: 2.460546479328511

Epoch: 539| Step: 0
Training loss: 0.29976596644354514
Validation loss: 2.4909153791496266

Epoch: 6| Step: 1
Training loss: 0.2803740237835961
Validation loss: 2.504710525958439

Epoch: 6| Step: 2
Training loss: 0.18239308442492147
Validation loss: 2.5153063806277527

Epoch: 6| Step: 3
Training loss: 0.1434195784465854
Validation loss: 2.470465470495354

Epoch: 6| Step: 4
Training loss: 0.1864122488746494
Validation loss: 2.5285085013473534

Epoch: 6| Step: 5
Training loss: 0.31153366167755736
Validation loss: 2.4823277430760884

Epoch: 6| Step: 6
Training loss: 0.1546805958218563
Validation loss: 2.532172003368427

Epoch: 6| Step: 7
Training loss: 0.2654334106633308
Validation loss: 2.487809635290766

Epoch: 6| Step: 8
Training loss: 0.16874985606575937
Validation loss: 2.458565542670681

Epoch: 6| Step: 9
Training loss: 0.2769956149931637
Validation loss: 2.4417437770714834

Epoch: 6| Step: 10
Training loss: 0.2123977046766873
Validation loss: 2.4519649668337125

Epoch: 6| Step: 11
Training loss: 0.20017694528572338
Validation loss: 2.4409614577182195

Epoch: 6| Step: 12
Training loss: 0.23087526289331642
Validation loss: 2.438237382930176

Epoch: 6| Step: 13
Training loss: 0.12560527261117513
Validation loss: 2.440051523180221

Epoch: 540| Step: 0
Training loss: 0.12004392995130198
Validation loss: 2.482121462007242

Epoch: 6| Step: 1
Training loss: 0.24330445338823045
Validation loss: 2.45069133638811

Epoch: 6| Step: 2
Training loss: 0.21760518369776363
Validation loss: 2.4696615064713323

Epoch: 6| Step: 3
Training loss: 0.19157308975495937
Validation loss: 2.4979337931744987

Epoch: 6| Step: 4
Training loss: 0.15289868251209218
Validation loss: 2.5049122039747123

Epoch: 6| Step: 5
Training loss: 0.28943111783896797
Validation loss: 2.512049070766629

Epoch: 6| Step: 6
Training loss: 0.19000338251779655
Validation loss: 2.4718417912356503

Epoch: 6| Step: 7
Training loss: 0.12241056324880518
Validation loss: 2.5109721972282624

Epoch: 6| Step: 8
Training loss: 0.16529922182339296
Validation loss: 2.4732267175975347

Epoch: 6| Step: 9
Training loss: 0.09909827340802352
Validation loss: 2.491250926998286

Epoch: 6| Step: 10
Training loss: 0.1747792081537991
Validation loss: 2.461628069707266

Epoch: 6| Step: 11
Training loss: 0.24441929743767882
Validation loss: 2.488146360822434

Epoch: 6| Step: 12
Training loss: 0.18376425678063957
Validation loss: 2.446418495578349

Epoch: 6| Step: 13
Training loss: 0.3424295074775036
Validation loss: 2.4333566390048205

Epoch: 541| Step: 0
Training loss: 0.2642781105337676
Validation loss: 2.459844139241199

Epoch: 6| Step: 1
Training loss: 0.14287705633898046
Validation loss: 2.4889458057861473

Epoch: 6| Step: 2
Training loss: 0.24748132466651485
Validation loss: 2.4627016457278996

Epoch: 6| Step: 3
Training loss: 0.2750448938051459
Validation loss: 2.4929240912635624

Epoch: 6| Step: 4
Training loss: 0.15021612521696193
Validation loss: 2.5201038622804086

Epoch: 6| Step: 5
Training loss: 0.25913542115785915
Validation loss: 2.534358827893816

Epoch: 6| Step: 6
Training loss: 0.1669566523795605
Validation loss: 2.5412440779972543

Epoch: 6| Step: 7
Training loss: 0.2527387480084764
Validation loss: 2.49810488150849

Epoch: 6| Step: 8
Training loss: 0.16120752278753794
Validation loss: 2.4686368036494017

Epoch: 6| Step: 9
Training loss: 0.27990243527503617
Validation loss: 2.489465261388231

Epoch: 6| Step: 10
Training loss: 0.14258975151419984
Validation loss: 2.4671817454263345

Epoch: 6| Step: 11
Training loss: 0.14063108616480263
Validation loss: 2.448803701205301

Epoch: 6| Step: 12
Training loss: 0.21610265706559026
Validation loss: 2.482725549740938

Epoch: 6| Step: 13
Training loss: 0.2027501903090895
Validation loss: 2.484236166628415

Epoch: 542| Step: 0
Training loss: 0.20399443995680117
Validation loss: 2.470356305068742

Epoch: 6| Step: 1
Training loss: 0.2710915062451471
Validation loss: 2.4886198700266795

Epoch: 6| Step: 2
Training loss: 0.22543978394667305
Validation loss: 2.5131287186218363

Epoch: 6| Step: 3
Training loss: 0.13729786835581692
Validation loss: 2.531812289147882

Epoch: 6| Step: 4
Training loss: 0.24013287640848838
Validation loss: 2.525164556040017

Epoch: 6| Step: 5
Training loss: 0.2630191211204067
Validation loss: 2.5424955441371972

Epoch: 6| Step: 6
Training loss: 0.2278364718217421
Validation loss: 2.5353764511789487

Epoch: 6| Step: 7
Training loss: 0.2953640610222707
Validation loss: 2.5506649700954838

Epoch: 6| Step: 8
Training loss: 0.19246556588691835
Validation loss: 2.5049153121761765

Epoch: 6| Step: 9
Training loss: 0.26156237186351267
Validation loss: 2.501488751983175

Epoch: 6| Step: 10
Training loss: 0.13887216985593054
Validation loss: 2.458626049948461

Epoch: 6| Step: 11
Training loss: 0.08600151051449921
Validation loss: 2.4668995682710393

Epoch: 6| Step: 12
Training loss: 0.2236141296978362
Validation loss: 2.4321305131832704

Epoch: 6| Step: 13
Training loss: 0.2287206707975517
Validation loss: 2.444190013447819

Epoch: 543| Step: 0
Training loss: 0.11783456971304712
Validation loss: 2.403720864185341

Epoch: 6| Step: 1
Training loss: 0.23665539488568038
Validation loss: 2.429373242423379

Epoch: 6| Step: 2
Training loss: 0.2693886033891624
Validation loss: 2.4294025438822886

Epoch: 6| Step: 3
Training loss: 0.2855204386025871
Validation loss: 2.443449753813054

Epoch: 6| Step: 4
Training loss: 0.24747807323737592
Validation loss: 2.4747620594471176

Epoch: 6| Step: 5
Training loss: 0.1839648412551985
Validation loss: 2.4616095127191464

Epoch: 6| Step: 6
Training loss: 0.1515291209186368
Validation loss: 2.4773831648331943

Epoch: 6| Step: 7
Training loss: 0.18819236081679777
Validation loss: 2.459609931455007

Epoch: 6| Step: 8
Training loss: 0.23728840776024784
Validation loss: 2.474309451580935

Epoch: 6| Step: 9
Training loss: 0.21075965306946529
Validation loss: 2.470239471636513

Epoch: 6| Step: 10
Training loss: 0.18159388894591286
Validation loss: 2.4748012037373766

Epoch: 6| Step: 11
Training loss: 0.15485302372866516
Validation loss: 2.479010261557989

Epoch: 6| Step: 12
Training loss: 0.18116802343080116
Validation loss: 2.491458989635128

Epoch: 6| Step: 13
Training loss: 0.12730010372921402
Validation loss: 2.415156238962304

Epoch: 544| Step: 0
Training loss: 0.11971002280912707
Validation loss: 2.5092418350236474

Epoch: 6| Step: 1
Training loss: 0.1178667687141694
Validation loss: 2.4547879850217256

Epoch: 6| Step: 2
Training loss: 0.11616050202779749
Validation loss: 2.444835480154801

Epoch: 6| Step: 3
Training loss: 0.2194355372507078
Validation loss: 2.432216573475942

Epoch: 6| Step: 4
Training loss: 0.24528357189448577
Validation loss: 2.4706280689576303

Epoch: 6| Step: 5
Training loss: 0.13920179714460615
Validation loss: 2.4926582349869335

Epoch: 6| Step: 6
Training loss: 0.16942250108273366
Validation loss: 2.486615911720888

Epoch: 6| Step: 7
Training loss: 0.1692910157911836
Validation loss: 2.463689306436857

Epoch: 6| Step: 8
Training loss: 0.27387714464191465
Validation loss: 2.4646345949839077

Epoch: 6| Step: 9
Training loss: 0.13489693312276416
Validation loss: 2.505277170221301

Epoch: 6| Step: 10
Training loss: 0.12004796801676099
Validation loss: 2.510638876691574

Epoch: 6| Step: 11
Training loss: 0.23892793296282266
Validation loss: 2.503289992762609

Epoch: 6| Step: 12
Training loss: 0.19959757820401258
Validation loss: 2.511116009735059

Epoch: 6| Step: 13
Training loss: 0.17091266027939797
Validation loss: 2.4715571385905544

Epoch: 545| Step: 0
Training loss: 0.18032656927109494
Validation loss: 2.4979528536285276

Epoch: 6| Step: 1
Training loss: 0.14374181656763946
Validation loss: 2.4960680723149373

Epoch: 6| Step: 2
Training loss: 0.1514261684562843
Validation loss: 2.4889749394662863

Epoch: 6| Step: 3
Training loss: 0.18627427720572307
Validation loss: 2.4954978417315985

Epoch: 6| Step: 4
Training loss: 0.16892680579457095
Validation loss: 2.4883542065530393

Epoch: 6| Step: 5
Training loss: 0.23714829617205327
Validation loss: 2.4852293726243047

Epoch: 6| Step: 6
Training loss: 0.2835969882706642
Validation loss: 2.449808464658224

Epoch: 6| Step: 7
Training loss: 0.17661900628874944
Validation loss: 2.473519614696629

Epoch: 6| Step: 8
Training loss: 0.2801793834498591
Validation loss: 2.4985152711773004

Epoch: 6| Step: 9
Training loss: 0.2640671486981451
Validation loss: 2.474129188911449

Epoch: 6| Step: 10
Training loss: 0.23172943767097465
Validation loss: 2.4348233916569457

Epoch: 6| Step: 11
Training loss: 0.33455276086914054
Validation loss: 2.484743391902396

Epoch: 6| Step: 12
Training loss: 0.16584140948916723
Validation loss: 2.4732319314740923

Epoch: 6| Step: 13
Training loss: 0.16010910014686136
Validation loss: 2.4638114954347485

Epoch: 546| Step: 0
Training loss: 0.19232825652999774
Validation loss: 2.4637311317840687

Epoch: 6| Step: 1
Training loss: 0.17613376133253508
Validation loss: 2.4229818767372797

Epoch: 6| Step: 2
Training loss: 0.17564631687386267
Validation loss: 2.4369244123349305

Epoch: 6| Step: 3
Training loss: 0.20141288986092565
Validation loss: 2.490283315886621

Epoch: 6| Step: 4
Training loss: 0.22869369708982693
Validation loss: 2.479461299967492

Epoch: 6| Step: 5
Training loss: 0.24057686435730646
Validation loss: 2.4910814014889606

Epoch: 6| Step: 6
Training loss: 0.10523290225317444
Validation loss: 2.525427306025524

Epoch: 6| Step: 7
Training loss: 0.23098624046742375
Validation loss: 2.556061526367448

Epoch: 6| Step: 8
Training loss: 0.3151940330586247
Validation loss: 2.5326546615517835

Epoch: 6| Step: 9
Training loss: 0.23478557863666344
Validation loss: 2.533063715027201

Epoch: 6| Step: 10
Training loss: 0.25387677241654716
Validation loss: 2.4788393518242366

Epoch: 6| Step: 11
Training loss: 0.21057265129201583
Validation loss: 2.407036052962043

Epoch: 6| Step: 12
Training loss: 0.18835292971266426
Validation loss: 2.3913066700983223

Epoch: 6| Step: 13
Training loss: 0.1874478188066014
Validation loss: 2.341192764311353

Epoch: 547| Step: 0
Training loss: 0.24754672050218432
Validation loss: 2.3597077806846447

Epoch: 6| Step: 1
Training loss: 0.16010997848121528
Validation loss: 2.344169508057023

Epoch: 6| Step: 2
Training loss: 0.2082603336629106
Validation loss: 2.360706410317681

Epoch: 6| Step: 3
Training loss: 0.2698525987156124
Validation loss: 2.409704691565135

Epoch: 6| Step: 4
Training loss: 0.263845753734534
Validation loss: 2.4161800038423715

Epoch: 6| Step: 5
Training loss: 0.16832325364219253
Validation loss: 2.4079800403235714

Epoch: 6| Step: 6
Training loss: 0.20346451774768937
Validation loss: 2.4786445507020582

Epoch: 6| Step: 7
Training loss: 0.2868187659753941
Validation loss: 2.491665154094225

Epoch: 6| Step: 8
Training loss: 0.16297870811292403
Validation loss: 2.444209554889967

Epoch: 6| Step: 9
Training loss: 0.1579044489634203
Validation loss: 2.4920780562764375

Epoch: 6| Step: 10
Training loss: 0.16986610330424182
Validation loss: 2.4728065637748977

Epoch: 6| Step: 11
Training loss: 0.18300138439829972
Validation loss: 2.4291331791786215

Epoch: 6| Step: 12
Training loss: 0.16100186893980664
Validation loss: 2.432976936433832

Epoch: 6| Step: 13
Training loss: 0.2236180779546282
Validation loss: 2.430034165212471

Epoch: 548| Step: 0
Training loss: 0.25541276755839104
Validation loss: 2.379565169671499

Epoch: 6| Step: 1
Training loss: 0.1998081743937317
Validation loss: 2.3789707403222606

Epoch: 6| Step: 2
Training loss: 0.21585545318497976
Validation loss: 2.3987959967638286

Epoch: 6| Step: 3
Training loss: 0.2169248443814641
Validation loss: 2.4208949577467593

Epoch: 6| Step: 4
Training loss: 0.18359246152060438
Validation loss: 2.4389443778648325

Epoch: 6| Step: 5
Training loss: 0.2517593289041833
Validation loss: 2.490419818199293

Epoch: 6| Step: 6
Training loss: 0.19629100779618025
Validation loss: 2.5350894246383326

Epoch: 6| Step: 7
Training loss: 0.23000055375239842
Validation loss: 2.532270840689091

Epoch: 6| Step: 8
Training loss: 0.17818049101891506
Validation loss: 2.5474564501152037

Epoch: 6| Step: 9
Training loss: 0.3569546548497927
Validation loss: 2.5473040444527144

Epoch: 6| Step: 10
Training loss: 0.18104991433313572
Validation loss: 2.509659833606843

Epoch: 6| Step: 11
Training loss: 0.14970818411525647
Validation loss: 2.4606114929600813

Epoch: 6| Step: 12
Training loss: 0.27991272313293875
Validation loss: 2.435565692140031

Epoch: 6| Step: 13
Training loss: 0.20147175335557432
Validation loss: 2.43704355771156

Epoch: 549| Step: 0
Training loss: 0.22153083071868776
Validation loss: 2.390068463943445

Epoch: 6| Step: 1
Training loss: 0.30860922569389876
Validation loss: 2.3556209895875253

Epoch: 6| Step: 2
Training loss: 0.30641397980973156
Validation loss: 2.36107806776387

Epoch: 6| Step: 3
Training loss: 0.18239669952825951
Validation loss: 2.382009129864852

Epoch: 6| Step: 4
Training loss: 0.10175060770224709
Validation loss: 2.4698153495046675

Epoch: 6| Step: 5
Training loss: 0.20582949730996175
Validation loss: 2.466614617069062

Epoch: 6| Step: 6
Training loss: 0.2400959515493622
Validation loss: 2.4845024236670232

Epoch: 6| Step: 7
Training loss: 0.16940177596742098
Validation loss: 2.509999744336992

Epoch: 6| Step: 8
Training loss: 0.1711028701929425
Validation loss: 2.5290518396788615

Epoch: 6| Step: 9
Training loss: 0.4212229953226188
Validation loss: 2.497783198979096

Epoch: 6| Step: 10
Training loss: 0.3034592103508536
Validation loss: 2.4514934307144554

Epoch: 6| Step: 11
Training loss: 0.2709281492544634
Validation loss: 2.3734379830809833

Epoch: 6| Step: 12
Training loss: 0.2852539783387581
Validation loss: 2.3971745183037045

Epoch: 6| Step: 13
Training loss: 0.14751565941025427
Validation loss: 2.3597856661453918

Epoch: 550| Step: 0
Training loss: 0.25479495701155985
Validation loss: 2.3553742164777405

Epoch: 6| Step: 1
Training loss: 0.2143186220377659
Validation loss: 2.369155923642005

Epoch: 6| Step: 2
Training loss: 0.3889140615755407
Validation loss: 2.3443413054845563

Epoch: 6| Step: 3
Training loss: 0.27953957636433524
Validation loss: 2.40086548566169

Epoch: 6| Step: 4
Training loss: 0.261981632810074
Validation loss: 2.4482694411368255

Epoch: 6| Step: 5
Training loss: 0.2475367278725931
Validation loss: 2.548328614203158

Epoch: 6| Step: 6
Training loss: 0.32092956094849134
Validation loss: 2.551626967677379

Epoch: 6| Step: 7
Training loss: 0.20060695103537898
Validation loss: 2.562900024772735

Epoch: 6| Step: 8
Training loss: 0.30552511743940164
Validation loss: 2.5038643759676042

Epoch: 6| Step: 9
Training loss: 0.15032823928306874
Validation loss: 2.4961189498424003

Epoch: 6| Step: 10
Training loss: 0.30643052599738
Validation loss: 2.4643086381581134

Epoch: 6| Step: 11
Training loss: 0.2726150814991174
Validation loss: 2.4721800399305742

Epoch: 6| Step: 12
Training loss: 0.338773753012608
Validation loss: 2.4781757448388047

Epoch: 6| Step: 13
Training loss: 0.07668140748553716
Validation loss: 2.4180378282525883

Testing loss: 2.2877355670827786
