Epoch: 1| Step: 0
Training loss: 5.154870420912293
Validation loss: 5.8158335966795445

Epoch: 5| Step: 1
Training loss: 6.5181382269820665
Validation loss: 5.794162308461376

Epoch: 5| Step: 2
Training loss: 5.345844416063
Validation loss: 5.772115407794462

Epoch: 5| Step: 3
Training loss: 5.897336986014223
Validation loss: 5.748008515128498

Epoch: 5| Step: 4
Training loss: 5.614406188925775
Validation loss: 5.7198427759877895

Epoch: 5| Step: 5
Training loss: 6.175530155296354
Validation loss: 5.688097331382994

Epoch: 5| Step: 6
Training loss: 5.606593215285861
Validation loss: 5.651522861856234

Epoch: 5| Step: 7
Training loss: 5.423288474402493
Validation loss: 5.6104527546172935

Epoch: 5| Step: 8
Training loss: 5.256380109957
Validation loss: 5.566247090696438

Epoch: 5| Step: 9
Training loss: 5.593358201951829
Validation loss: 5.5167024648751735

Epoch: 5| Step: 10
Training loss: 6.052610530860321
Validation loss: 5.463900180530715

Epoch: 2| Step: 0
Training loss: 5.466782221309407
Validation loss: 5.406035486892798

Epoch: 5| Step: 1
Training loss: 4.780618064856389
Validation loss: 5.344914994726249

Epoch: 5| Step: 2
Training loss: 5.1441586300846724
Validation loss: 5.281562420702871

Epoch: 5| Step: 3
Training loss: 5.914519802539248
Validation loss: 5.216398266683798

Epoch: 5| Step: 4
Training loss: 4.08249684284039
Validation loss: 5.148420340773823

Epoch: 5| Step: 5
Training loss: 4.78665732992921
Validation loss: 5.081963701415551

Epoch: 5| Step: 6
Training loss: 5.620936303389126
Validation loss: 5.01225587601582

Epoch: 5| Step: 7
Training loss: 5.0914170240938255
Validation loss: 4.943365573338284

Epoch: 5| Step: 8
Training loss: 5.256710486817009
Validation loss: 4.874844750813332

Epoch: 5| Step: 9
Training loss: 5.159267028381222
Validation loss: 4.808120166415929

Epoch: 5| Step: 10
Training loss: 4.977066852877085
Validation loss: 4.74564680652529

Epoch: 3| Step: 0
Training loss: 5.172591514165033
Validation loss: 4.68643566230655

Epoch: 5| Step: 1
Training loss: 3.9597290121664237
Validation loss: 4.631815926846557

Epoch: 5| Step: 2
Training loss: 3.730448298373258
Validation loss: 4.577884674344117

Epoch: 5| Step: 3
Training loss: 4.806147755104548
Validation loss: 4.535028595169261

Epoch: 5| Step: 4
Training loss: 5.356528902749086
Validation loss: 4.4861656039276365

Epoch: 5| Step: 5
Training loss: 5.031786398400757
Validation loss: 4.433842026119145

Epoch: 5| Step: 6
Training loss: 3.9031847103978934
Validation loss: 4.378421311761271

Epoch: 5| Step: 7
Training loss: 4.558618854365322
Validation loss: 4.33455805986911

Epoch: 5| Step: 8
Training loss: 3.718538294303773
Validation loss: 4.302736324511526

Epoch: 5| Step: 9
Training loss: 4.696369782037896
Validation loss: 4.272038529185939

Epoch: 5| Step: 10
Training loss: 4.825377833935326
Validation loss: 4.243908717144957

Epoch: 4| Step: 0
Training loss: 4.083725164388725
Validation loss: 4.214296095614637

Epoch: 5| Step: 1
Training loss: 4.295680764440076
Validation loss: 4.188569498169991

Epoch: 5| Step: 2
Training loss: 4.339523564569739
Validation loss: 4.165332946615144

Epoch: 5| Step: 3
Training loss: 3.6508475273348076
Validation loss: 4.1422968499251684

Epoch: 5| Step: 4
Training loss: 4.423676356392217
Validation loss: 4.118596695103022

Epoch: 5| Step: 5
Training loss: 4.444565212410339
Validation loss: 4.0952105452581415

Epoch: 5| Step: 6
Training loss: 3.8091864022062416
Validation loss: 4.067296272427409

Epoch: 5| Step: 7
Training loss: 4.8052485936984795
Validation loss: 4.036477804411556

Epoch: 5| Step: 8
Training loss: 4.71640704263804
Validation loss: 4.011291440889395

Epoch: 5| Step: 9
Training loss: 3.9299790746311327
Validation loss: 3.987662027385669

Epoch: 5| Step: 10
Training loss: 3.79835751322579
Validation loss: 3.9739933299717816

Epoch: 5| Step: 0
Training loss: 3.949684304285043
Validation loss: 3.9578672582629384

Epoch: 5| Step: 1
Training loss: 4.228588697405574
Validation loss: 3.9381315418582545

Epoch: 5| Step: 2
Training loss: 4.220597378360629
Validation loss: 3.9154515791426583

Epoch: 5| Step: 3
Training loss: 4.158110238144665
Validation loss: 3.8928392486715793

Epoch: 5| Step: 4
Training loss: 3.701598291316647
Validation loss: 3.87329593493687

Epoch: 5| Step: 5
Training loss: 4.170339694743783
Validation loss: 3.855911331381627

Epoch: 5| Step: 6
Training loss: 4.573774646860476
Validation loss: 3.835857145492318

Epoch: 5| Step: 7
Training loss: 3.7147174416618443
Validation loss: 3.82004659451093

Epoch: 5| Step: 8
Training loss: 4.210468443046176
Validation loss: 3.803180937453779

Epoch: 5| Step: 9
Training loss: 3.64986860482943
Validation loss: 3.791056563063617

Epoch: 5| Step: 10
Training loss: 3.5425671199451405
Validation loss: 3.776194986944285

Epoch: 6| Step: 0
Training loss: 3.8753823122501183
Validation loss: 3.763922609018922

Epoch: 5| Step: 1
Training loss: 3.878320809215547
Validation loss: 3.7481070003043016

Epoch: 5| Step: 2
Training loss: 3.8204782524113963
Validation loss: 3.737875495508045

Epoch: 5| Step: 3
Training loss: 3.9580706994448946
Validation loss: 3.732071439143983

Epoch: 5| Step: 4
Training loss: 4.17298125840601
Validation loss: 3.7140684729978943

Epoch: 5| Step: 5
Training loss: 3.1998996778497952
Validation loss: 3.7030312792083806

Epoch: 5| Step: 6
Training loss: 4.029701112781146
Validation loss: 3.700726495029846

Epoch: 5| Step: 7
Training loss: 4.516113254853565
Validation loss: 3.6890866978320753

Epoch: 5| Step: 8
Training loss: 4.345130975327328
Validation loss: 3.6724850551239965

Epoch: 5| Step: 9
Training loss: 2.881378230553449
Validation loss: 3.6649817518293024

Epoch: 5| Step: 10
Training loss: 3.9058014879230005
Validation loss: 3.6520970067566396

Epoch: 7| Step: 0
Training loss: 3.8260820192278793
Validation loss: 3.637694445665896

Epoch: 5| Step: 1
Training loss: 4.321560394906702
Validation loss: 3.6233846653068182

Epoch: 5| Step: 2
Training loss: 3.7100105493195046
Validation loss: 3.613171778835634

Epoch: 5| Step: 3
Training loss: 4.257838257877936
Validation loss: 3.6022396257691778

Epoch: 5| Step: 4
Training loss: 2.6486724479235177
Validation loss: 3.5914683628110993

Epoch: 5| Step: 5
Training loss: 4.072705171497248
Validation loss: 3.583499824927717

Epoch: 5| Step: 6
Training loss: 3.9620422387680607
Validation loss: 3.571266592369405

Epoch: 5| Step: 7
Training loss: 3.702871965865585
Validation loss: 3.5621407699595413

Epoch: 5| Step: 8
Training loss: 2.725957152927604
Validation loss: 3.563919912775759

Epoch: 5| Step: 9
Training loss: 3.7382496161801573
Validation loss: 3.5622963148176794

Epoch: 5| Step: 10
Training loss: 4.348151083699793
Validation loss: 3.5422547669466344

Epoch: 8| Step: 0
Training loss: 3.4548486058676047
Validation loss: 3.5328535395205263

Epoch: 5| Step: 1
Training loss: 3.9264736494887362
Validation loss: 3.531412537428014

Epoch: 5| Step: 2
Training loss: 4.253790791663732
Validation loss: 3.511280322494126

Epoch: 5| Step: 3
Training loss: 2.864010248368324
Validation loss: 3.507678920839789

Epoch: 5| Step: 4
Training loss: 2.6492238185589967
Validation loss: 3.5009865051724227

Epoch: 5| Step: 5
Training loss: 3.570587347958234
Validation loss: 3.489746836084404

Epoch: 5| Step: 6
Training loss: 3.8514879695343427
Validation loss: 3.479674849602383

Epoch: 5| Step: 7
Training loss: 4.091350988160903
Validation loss: 3.4723010486692876

Epoch: 5| Step: 8
Training loss: 4.053435556812569
Validation loss: 3.462763126548936

Epoch: 5| Step: 9
Training loss: 4.323735293660845
Validation loss: 3.4524506817321705

Epoch: 5| Step: 10
Training loss: 3.1677535015692273
Validation loss: 3.446056699401942

Epoch: 9| Step: 0
Training loss: 3.287491303058913
Validation loss: 3.4405470036099226

Epoch: 5| Step: 1
Training loss: 3.6560275018271144
Validation loss: 3.4322471152049303

Epoch: 5| Step: 2
Training loss: 3.452345678152395
Validation loss: 3.426629756671087

Epoch: 5| Step: 3
Training loss: 3.91704757677897
Validation loss: 3.4390587532594172

Epoch: 5| Step: 4
Training loss: 4.078771079614234
Validation loss: 3.424540133405148

Epoch: 5| Step: 5
Training loss: 3.988812417761627
Validation loss: 3.4094610298330355

Epoch: 5| Step: 6
Training loss: 3.8612749002480573
Validation loss: 3.409669858584732

Epoch: 5| Step: 7
Training loss: 3.3147758007614883
Validation loss: 3.401245973878934

Epoch: 5| Step: 8
Training loss: 3.8305182002324454
Validation loss: 3.391617089732317

Epoch: 5| Step: 9
Training loss: 3.3272054772040485
Validation loss: 3.387234040060597

Epoch: 5| Step: 10
Training loss: 3.067535153710628
Validation loss: 3.3835149823444564

Epoch: 10| Step: 0
Training loss: 3.8176237602632814
Validation loss: 3.388673639233489

Epoch: 5| Step: 1
Training loss: 3.3966688442753585
Validation loss: 3.3872322561559427

Epoch: 5| Step: 2
Training loss: 3.134257832216979
Validation loss: 3.3895284203477307

Epoch: 5| Step: 3
Training loss: 3.8721972758582512
Validation loss: 3.383246628249248

Epoch: 5| Step: 4
Training loss: 3.932497025068532
Validation loss: 3.3712289327954164

Epoch: 5| Step: 5
Training loss: 2.841857112495165
Validation loss: 3.363225458619076

Epoch: 5| Step: 6
Training loss: 3.165009684133554
Validation loss: 3.3577264600849923

Epoch: 5| Step: 7
Training loss: 3.7269977819192035
Validation loss: 3.3547378422625718

Epoch: 5| Step: 8
Training loss: 4.141790031780752
Validation loss: 3.3535735754271396

Epoch: 5| Step: 9
Training loss: 3.4968391859796095
Validation loss: 3.3419929804967157

Epoch: 5| Step: 10
Training loss: 3.876404415475993
Validation loss: 3.3383209880983356

Epoch: 11| Step: 0
Training loss: 3.680354679471997
Validation loss: 3.3337570464622277

Epoch: 5| Step: 1
Training loss: 3.272138315005473
Validation loss: 3.3338500596562484

Epoch: 5| Step: 2
Training loss: 3.7009130382365587
Validation loss: 3.3401435767842775

Epoch: 5| Step: 3
Training loss: 3.633466632975899
Validation loss: 3.3274360362273163

Epoch: 5| Step: 4
Training loss: 3.502213323216608
Validation loss: 3.343507558785083

Epoch: 5| Step: 5
Training loss: 3.434904193458284
Validation loss: 3.388954269275652

Epoch: 5| Step: 6
Training loss: 2.6512358069141126
Validation loss: 3.326639707773655

Epoch: 5| Step: 7
Training loss: 4.119890227105382
Validation loss: 3.3151258685688085

Epoch: 5| Step: 8
Training loss: 4.137057628205317
Validation loss: 3.333358345142991

Epoch: 5| Step: 9
Training loss: 3.8293484970826794
Validation loss: 3.3763162924175996

Epoch: 5| Step: 10
Training loss: 3.03718536380018
Validation loss: 3.3150201220744555

Epoch: 12| Step: 0
Training loss: 3.64706480027565
Validation loss: 3.3147450255694824

Epoch: 5| Step: 1
Training loss: 3.1917101413033473
Validation loss: 3.3336525384796523

Epoch: 5| Step: 2
Training loss: 3.635510826895327
Validation loss: 3.364768537699722

Epoch: 5| Step: 3
Training loss: 3.7586410148406544
Validation loss: 3.3421866536624174

Epoch: 5| Step: 4
Training loss: 2.592383886696455
Validation loss: 3.3180742902127003

Epoch: 5| Step: 5
Training loss: 3.6842132403428254
Validation loss: 3.308763448657808

Epoch: 5| Step: 6
Training loss: 3.411083606591135
Validation loss: 3.3029530018777318

Epoch: 5| Step: 7
Training loss: 3.6747893759646466
Validation loss: 3.3024920263083373

Epoch: 5| Step: 8
Training loss: 3.7666682780664646
Validation loss: 3.3095308193266653

Epoch: 5| Step: 9
Training loss: 4.0100498312424815
Validation loss: 3.3089289781299835

Epoch: 5| Step: 10
Training loss: 3.510927715890559
Validation loss: 3.292058587772382

Epoch: 13| Step: 0
Training loss: 3.6582808112079563
Validation loss: 3.2911573140300736

Epoch: 5| Step: 1
Training loss: 3.5225075046305045
Validation loss: 3.2883364673789566

Epoch: 5| Step: 2
Training loss: 3.915802772425989
Validation loss: 3.2908407966304924

Epoch: 5| Step: 3
Training loss: 3.253159381197401
Validation loss: 3.289688368427508

Epoch: 5| Step: 4
Training loss: 3.1940818599274317
Validation loss: 3.289437411550327

Epoch: 5| Step: 5
Training loss: 4.421882979854217
Validation loss: 3.3001423760604407

Epoch: 5| Step: 6
Training loss: 3.1184229493903133
Validation loss: 3.2899781399603536

Epoch: 5| Step: 7
Training loss: 3.484150832282484
Validation loss: 3.287428881258326

Epoch: 5| Step: 8
Training loss: 2.937692676474783
Validation loss: 3.2867222171293853

Epoch: 5| Step: 9
Training loss: 3.313772712782212
Validation loss: 3.2922047390357414

Epoch: 5| Step: 10
Training loss: 3.807265894324678
Validation loss: 3.270723675865529

Epoch: 14| Step: 0
Training loss: 3.2594514013097355
Validation loss: 3.2703170922848295

Epoch: 5| Step: 1
Training loss: 2.752589133999623
Validation loss: 3.270785253320452

Epoch: 5| Step: 2
Training loss: 4.282941720676905
Validation loss: 3.2730050823028254

Epoch: 5| Step: 3
Training loss: 3.338060904814058
Validation loss: 3.267877932735809

Epoch: 5| Step: 4
Training loss: 3.9754670738417888
Validation loss: 3.26803634866367

Epoch: 5| Step: 5
Training loss: 3.567843796137619
Validation loss: 3.264473269780422

Epoch: 5| Step: 6
Training loss: 3.2687684038566815
Validation loss: 3.2664627764543774

Epoch: 5| Step: 7
Training loss: 4.131607312607976
Validation loss: 3.265855733440364

Epoch: 5| Step: 8
Training loss: 3.2597711836194367
Validation loss: 3.2647653107462227

Epoch: 5| Step: 9
Training loss: 3.0359924028726244
Validation loss: 3.2609707963189165

Epoch: 5| Step: 10
Training loss: 3.4627449362155067
Validation loss: 3.2608211334208184

Epoch: 15| Step: 0
Training loss: 3.272737778781635
Validation loss: 3.261234801315917

Epoch: 5| Step: 1
Training loss: 4.222944195128666
Validation loss: 3.2567704186298108

Epoch: 5| Step: 2
Training loss: 3.7122078417764914
Validation loss: 3.2671022680568793

Epoch: 5| Step: 3
Training loss: 3.1588879127723075
Validation loss: 3.25342172546057

Epoch: 5| Step: 4
Training loss: 3.5899134848113228
Validation loss: 3.253081581171376

Epoch: 5| Step: 5
Training loss: 3.906230224559318
Validation loss: 3.251533772701186

Epoch: 5| Step: 6
Training loss: 3.0993473781147944
Validation loss: 3.2511238398425766

Epoch: 5| Step: 7
Training loss: 3.541587349994576
Validation loss: 3.2527916453402157

Epoch: 5| Step: 8
Training loss: 3.0273478452593268
Validation loss: 3.2509121636283256

Epoch: 5| Step: 9
Training loss: 3.264119800669105
Validation loss: 3.251135634799937

Epoch: 5| Step: 10
Training loss: 3.6051772507094855
Validation loss: 3.2504765781928717

Epoch: 16| Step: 0
Training loss: 4.310968099321675
Validation loss: 3.2494511957366763

Epoch: 5| Step: 1
Training loss: 3.0078475355609657
Validation loss: 3.24374030880351

Epoch: 5| Step: 2
Training loss: 3.589665621218188
Validation loss: 3.2436741349818776

Epoch: 5| Step: 3
Training loss: 3.361815236076866
Validation loss: 3.243109530322055

Epoch: 5| Step: 4
Training loss: 3.4446998795442014
Validation loss: 3.2399622164059707

Epoch: 5| Step: 5
Training loss: 2.983832504736283
Validation loss: 3.2406282860783393

Epoch: 5| Step: 6
Training loss: 3.7265665945994275
Validation loss: 3.241106558696271

Epoch: 5| Step: 7
Training loss: 3.658445302398226
Validation loss: 3.2403713159972445

Epoch: 5| Step: 8
Training loss: 2.934506778378376
Validation loss: 3.2378716107974785

Epoch: 5| Step: 9
Training loss: 3.6446026859457974
Validation loss: 3.237759672770444

Epoch: 5| Step: 10
Training loss: 3.556713155879395
Validation loss: 3.238540155949252

Epoch: 17| Step: 0
Training loss: 3.100580247288086
Validation loss: 3.2369252172193015

Epoch: 5| Step: 1
Training loss: 3.5649484619438634
Validation loss: 3.2353726921412878

Epoch: 5| Step: 2
Training loss: 3.101911933489963
Validation loss: 3.2323824750328565

Epoch: 5| Step: 3
Training loss: 3.8266143932383065
Validation loss: 3.2336341628104646

Epoch: 5| Step: 4
Training loss: 3.453387082195904
Validation loss: 3.2320959078695664

Epoch: 5| Step: 5
Training loss: 4.113654515500833
Validation loss: 3.2303579720417894

Epoch: 5| Step: 6
Training loss: 4.061625459879674
Validation loss: 3.228503226496665

Epoch: 5| Step: 7
Training loss: 3.813360648646481
Validation loss: 3.2284318456382755

Epoch: 5| Step: 8
Training loss: 2.64190462246079
Validation loss: 3.2267720338845516

Epoch: 5| Step: 9
Training loss: 2.8918281319544534
Validation loss: 3.2236750025945002

Epoch: 5| Step: 10
Training loss: 3.3913989612050215
Validation loss: 3.2208573216718475

Epoch: 18| Step: 0
Training loss: 4.197895867207054
Validation loss: 3.220694100076832

Epoch: 5| Step: 1
Training loss: 4.1383425773756
Validation loss: 3.219136105923479

Epoch: 5| Step: 2
Training loss: 3.1529575208905114
Validation loss: 3.216479292095322

Epoch: 5| Step: 3
Training loss: 3.5392745672355335
Validation loss: 3.213096123601695

Epoch: 5| Step: 4
Training loss: 3.370064128412731
Validation loss: 3.210846564744751

Epoch: 5| Step: 5
Training loss: 3.8646896772670774
Validation loss: 3.207418234291783

Epoch: 5| Step: 6
Training loss: 3.463271893007394
Validation loss: 3.2073971219136435

Epoch: 5| Step: 7
Training loss: 3.6094608709515974
Validation loss: 3.206376841720164

Epoch: 5| Step: 8
Training loss: 2.868559714262464
Validation loss: 3.204930208326902

Epoch: 5| Step: 9
Training loss: 2.6361113124088504
Validation loss: 3.203334207853405

Epoch: 5| Step: 10
Training loss: 2.8076386717927995
Validation loss: 3.202720356015025

Epoch: 19| Step: 0
Training loss: 4.553401706642055
Validation loss: 3.2039721305416218

Epoch: 5| Step: 1
Training loss: 3.0295869650250844
Validation loss: 3.2035081971839765

Epoch: 5| Step: 2
Training loss: 3.9186570541334893
Validation loss: 3.204813284037455

Epoch: 5| Step: 3
Training loss: 2.858950724158089
Validation loss: 3.2020571085319487

Epoch: 5| Step: 4
Training loss: 3.571973285007002
Validation loss: 3.207273673984075

Epoch: 5| Step: 5
Training loss: 3.232986815718609
Validation loss: 3.2078449057004774

Epoch: 5| Step: 6
Training loss: 3.7298588598716425
Validation loss: 3.2107023376526302

Epoch: 5| Step: 7
Training loss: 3.3514550820945463
Validation loss: 3.2091382831680355

Epoch: 5| Step: 8
Training loss: 3.0716500123252604
Validation loss: 3.2013653499619443

Epoch: 5| Step: 9
Training loss: 2.8607461278839694
Validation loss: 3.1936778136782067

Epoch: 5| Step: 10
Training loss: 3.4536588092242444
Validation loss: 3.192166715071448

Epoch: 20| Step: 0
Training loss: 3.6780964839740626
Validation loss: 3.1922239300696984

Epoch: 5| Step: 1
Training loss: 3.26318735650174
Validation loss: 3.193498075589636

Epoch: 5| Step: 2
Training loss: 3.483918164331194
Validation loss: 3.1960362744102766

Epoch: 5| Step: 3
Training loss: 3.829057229643258
Validation loss: 3.1892244145097326

Epoch: 5| Step: 4
Training loss: 3.5623440624708596
Validation loss: 3.1952940114466215

Epoch: 5| Step: 5
Training loss: 3.4352083370102244
Validation loss: 3.2422265855113763

Epoch: 5| Step: 6
Training loss: 3.8353837928558043
Validation loss: 3.2065816176900324

Epoch: 5| Step: 7
Training loss: 2.997120110727944
Validation loss: 3.1892619514173584

Epoch: 5| Step: 8
Training loss: 2.953183774010038
Validation loss: 3.2086599322511065

Epoch: 5| Step: 9
Training loss: 3.906325804928525
Validation loss: 3.2654412032355435

Epoch: 5| Step: 10
Training loss: 3.027907111140275
Validation loss: 3.243347430163193

Epoch: 21| Step: 0
Training loss: 3.494073482271333
Validation loss: 3.2292178660345376

Epoch: 5| Step: 1
Training loss: 3.4171322916225684
Validation loss: 3.1918376480870454

Epoch: 5| Step: 2
Training loss: 3.1443398743200865
Validation loss: 3.1881211906272826

Epoch: 5| Step: 3
Training loss: 3.675059654114979
Validation loss: 3.1917336297355456

Epoch: 5| Step: 4
Training loss: 3.476794837303208
Validation loss: 3.1968306305676504

Epoch: 5| Step: 5
Training loss: 2.175755170189861
Validation loss: 3.201433802875607

Epoch: 5| Step: 6
Training loss: 3.860803378410458
Validation loss: 3.213335849775615

Epoch: 5| Step: 7
Training loss: 3.504355853609971
Validation loss: 3.199687175175503

Epoch: 5| Step: 8
Training loss: 3.6939813583391072
Validation loss: 3.1857896269955157

Epoch: 5| Step: 9
Training loss: 3.2325540475243435
Validation loss: 3.175232490810502

Epoch: 5| Step: 10
Training loss: 3.9550837914697063
Validation loss: 3.1678574333137735

Epoch: 22| Step: 0
Training loss: 3.097043528816598
Validation loss: 3.162314700576347

Epoch: 5| Step: 1
Training loss: 3.186146317804547
Validation loss: 3.1592631902723687

Epoch: 5| Step: 2
Training loss: 3.6654372899741987
Validation loss: 3.1527646628727393

Epoch: 5| Step: 3
Training loss: 2.69216708874617
Validation loss: 3.14953155143262

Epoch: 5| Step: 4
Training loss: 3.676475467454253
Validation loss: 3.13926391298405

Epoch: 5| Step: 5
Training loss: 4.1387723412770505
Validation loss: 3.1367301137203936

Epoch: 5| Step: 6
Training loss: 3.2189850952808303
Validation loss: 3.1320677229905884

Epoch: 5| Step: 7
Training loss: 3.6292198875078268
Validation loss: 3.1307755191653377

Epoch: 5| Step: 8
Training loss: 3.7719568226306026
Validation loss: 3.1282062432398954

Epoch: 5| Step: 9
Training loss: 3.367595886813732
Validation loss: 3.1243118496482065

Epoch: 5| Step: 10
Training loss: 2.6915736706930513
Validation loss: 3.1199536159365784

Epoch: 23| Step: 0
Training loss: 3.3611462558839036
Validation loss: 3.120860630317277

Epoch: 5| Step: 1
Training loss: 3.2924965082032753
Validation loss: 3.1239581186323977

Epoch: 5| Step: 2
Training loss: 2.7138290594771255
Validation loss: 3.125583513807732

Epoch: 5| Step: 3
Training loss: 2.7619404359840614
Validation loss: 3.1237704181728096

Epoch: 5| Step: 4
Training loss: 3.5088337726329706
Validation loss: 3.1259014675230015

Epoch: 5| Step: 5
Training loss: 3.754264695344477
Validation loss: 3.12458901112567

Epoch: 5| Step: 6
Training loss: 3.775564916922305
Validation loss: 3.125314433368313

Epoch: 5| Step: 7
Training loss: 3.5676935720022334
Validation loss: 3.120094974966472

Epoch: 5| Step: 8
Training loss: 3.7577215171791782
Validation loss: 3.1186586072375753

Epoch: 5| Step: 9
Training loss: 3.1807495143188116
Validation loss: 3.116527781063381

Epoch: 5| Step: 10
Training loss: 3.435035654518733
Validation loss: 3.113433220297345

Epoch: 24| Step: 0
Training loss: 3.006815162876836
Validation loss: 3.110124347351891

Epoch: 5| Step: 1
Training loss: 2.61698589402487
Validation loss: 3.107064052743427

Epoch: 5| Step: 2
Training loss: 4.084757238713061
Validation loss: 3.105220813622047

Epoch: 5| Step: 3
Training loss: 2.7774621264933974
Validation loss: 3.1008505786951135

Epoch: 5| Step: 4
Training loss: 3.3142085437528483
Validation loss: 3.0986547188828824

Epoch: 5| Step: 5
Training loss: 3.107757914635798
Validation loss: 3.0957462304555077

Epoch: 5| Step: 6
Training loss: 3.4198393318850817
Validation loss: 3.0938842502342974

Epoch: 5| Step: 7
Training loss: 3.8863585338731417
Validation loss: 3.0924891221345754

Epoch: 5| Step: 8
Training loss: 2.957808237531183
Validation loss: 3.0886341836389355

Epoch: 5| Step: 9
Training loss: 4.135358808418592
Validation loss: 3.0857749014495353

Epoch: 5| Step: 10
Training loss: 3.357006994936158
Validation loss: 3.085087305297728

Epoch: 25| Step: 0
Training loss: 3.394203512614762
Validation loss: 3.081422318058938

Epoch: 5| Step: 1
Training loss: 3.134032052504877
Validation loss: 3.076583513804865

Epoch: 5| Step: 2
Training loss: 2.775443283966702
Validation loss: 3.0818086683073087

Epoch: 5| Step: 3
Training loss: 3.899149430273486
Validation loss: 3.080607768284273

Epoch: 5| Step: 4
Training loss: 2.6310478658349137
Validation loss: 3.062455227834115

Epoch: 5| Step: 5
Training loss: 3.469667468009292
Validation loss: 3.0770258811194884

Epoch: 5| Step: 6
Training loss: 4.274975041545267
Validation loss: 3.070396996850133

Epoch: 5| Step: 7
Training loss: 3.8961529660127967
Validation loss: 3.0610477502467313

Epoch: 5| Step: 8
Training loss: 3.0437844276439443
Validation loss: 3.0826347666114375

Epoch: 5| Step: 9
Training loss: 2.7721936512580942
Validation loss: 3.103886758446252

Epoch: 5| Step: 10
Training loss: 3.094391265068231
Validation loss: 3.1216468179831205

Epoch: 26| Step: 0
Training loss: 3.2262441556597525
Validation loss: 3.1088539775745203

Epoch: 5| Step: 1
Training loss: 3.7442912836065116
Validation loss: 3.0870390897194033

Epoch: 5| Step: 2
Training loss: 3.705824757154243
Validation loss: 3.0574345454761103

Epoch: 5| Step: 3
Training loss: 2.9341533345601505
Validation loss: 3.041343674063232

Epoch: 5| Step: 4
Training loss: 3.2326044958797895
Validation loss: 3.0420757939491527

Epoch: 5| Step: 5
Training loss: 2.957753908249078
Validation loss: 3.048497581443851

Epoch: 5| Step: 6
Training loss: 3.5756227497746536
Validation loss: 3.0764252124491565

Epoch: 5| Step: 7
Training loss: 3.5717522120292364
Validation loss: 3.046233707458989

Epoch: 5| Step: 8
Training loss: 2.8972140709419056
Validation loss: 3.031502291489044

Epoch: 5| Step: 9
Training loss: 3.590004868570496
Validation loss: 3.032581570961686

Epoch: 5| Step: 10
Training loss: 2.9830590986944445
Validation loss: 3.036280259093088

Epoch: 27| Step: 0
Training loss: 2.844324577888804
Validation loss: 3.0346887947298296

Epoch: 5| Step: 1
Training loss: 3.4847814211718826
Validation loss: 3.0389461350068654

Epoch: 5| Step: 2
Training loss: 2.7406568466650243
Validation loss: 3.0398344122542733

Epoch: 5| Step: 3
Training loss: 3.3683275739975103
Validation loss: 3.041197020891286

Epoch: 5| Step: 4
Training loss: 3.433880651853928
Validation loss: 3.0409196944187378

Epoch: 5| Step: 5
Training loss: 3.1885127534316666
Validation loss: 3.032300610779447

Epoch: 5| Step: 6
Training loss: 3.33854412648095
Validation loss: 3.025957331121916

Epoch: 5| Step: 7
Training loss: 2.7830329923329287
Validation loss: 3.017377997303527

Epoch: 5| Step: 8
Training loss: 3.9304594036393796
Validation loss: 3.0186526511335403

Epoch: 5| Step: 9
Training loss: 3.3025641507452352
Validation loss: 3.018220521040568

Epoch: 5| Step: 10
Training loss: 3.846254230803158
Validation loss: 3.0152393204737455

Epoch: 28| Step: 0
Training loss: 3.0169709517585486
Validation loss: 3.015541217891273

Epoch: 5| Step: 1
Training loss: 3.8799511442353025
Validation loss: 3.01231274123848

Epoch: 5| Step: 2
Training loss: 2.6520431415621863
Validation loss: 3.0125988000772423

Epoch: 5| Step: 3
Training loss: 3.520930512721749
Validation loss: 3.010960798241898

Epoch: 5| Step: 4
Training loss: 3.2926938993207404
Validation loss: 3.0112240780107156

Epoch: 5| Step: 5
Training loss: 4.240727350718832
Validation loss: 3.0113240551525275

Epoch: 5| Step: 6
Training loss: 3.407259030459377
Validation loss: 3.0096651446338325

Epoch: 5| Step: 7
Training loss: 2.6246712796699825
Validation loss: 3.007310542186029

Epoch: 5| Step: 8
Training loss: 3.413050451353435
Validation loss: 3.005688167890465

Epoch: 5| Step: 9
Training loss: 2.4380173745416367
Validation loss: 3.0053700935842795

Epoch: 5| Step: 10
Training loss: 3.2779939027069713
Validation loss: 3.003837959011158

Epoch: 29| Step: 0
Training loss: 3.0499102219672873
Validation loss: 3.010087198568279

Epoch: 5| Step: 1
Training loss: 3.4492891159742776
Validation loss: 3.026383971925533

Epoch: 5| Step: 2
Training loss: 2.9320521056370907
Validation loss: 3.0293278436999183

Epoch: 5| Step: 3
Training loss: 3.323002988517214
Validation loss: 3.0156053281781405

Epoch: 5| Step: 4
Training loss: 3.758647865503693
Validation loss: 2.9960789940893653

Epoch: 5| Step: 5
Training loss: 3.260543154536933
Validation loss: 2.9983639922058836

Epoch: 5| Step: 6
Training loss: 3.3378391965025793
Validation loss: 2.9991773602036647

Epoch: 5| Step: 7
Training loss: 2.9685586968071154
Validation loss: 3.0002749976724856

Epoch: 5| Step: 8
Training loss: 3.623073723788658
Validation loss: 3.0020541094327604

Epoch: 5| Step: 9
Training loss: 3.6017362010715575
Validation loss: 3.0087701571410848

Epoch: 5| Step: 10
Training loss: 2.713739799153516
Validation loss: 3.0003553405658443

Epoch: 30| Step: 0
Training loss: 3.4021375836736274
Validation loss: 2.99741863468961

Epoch: 5| Step: 1
Training loss: 3.018382338728648
Validation loss: 2.9950561292529603

Epoch: 5| Step: 2
Training loss: 3.0399929475702496
Validation loss: 2.9946768561671195

Epoch: 5| Step: 3
Training loss: 3.683854321419074
Validation loss: 2.9968255177750214

Epoch: 5| Step: 4
Training loss: 3.5954929271719145
Validation loss: 2.9966246697151253

Epoch: 5| Step: 5
Training loss: 2.809602983196604
Validation loss: 2.9979401296638537

Epoch: 5| Step: 6
Training loss: 3.2787614377309855
Validation loss: 2.9994154825553845

Epoch: 5| Step: 7
Training loss: 3.3887997825734155
Validation loss: 3.0007958587066113

Epoch: 5| Step: 8
Training loss: 3.5581224550271258
Validation loss: 3.003535204476436

Epoch: 5| Step: 9
Training loss: 2.901433090750593
Validation loss: 3.0054835047113744

Epoch: 5| Step: 10
Training loss: 3.3199948147652822
Validation loss: 2.994054626822813

Epoch: 31| Step: 0
Training loss: 3.436133928222336
Validation loss: 2.9932113220030883

Epoch: 5| Step: 1
Training loss: 2.809935863210918
Validation loss: 2.991123331198035

Epoch: 5| Step: 2
Training loss: 3.10501728734903
Validation loss: 2.986296766181899

Epoch: 5| Step: 3
Training loss: 3.4284701956835546
Validation loss: 2.987033834088651

Epoch: 5| Step: 4
Training loss: 3.510148729613021
Validation loss: 2.9866180254529455

Epoch: 5| Step: 5
Training loss: 3.3891623721921333
Validation loss: 2.9824788338971757

Epoch: 5| Step: 6
Training loss: 3.398911436511265
Validation loss: 2.9848291452818603

Epoch: 5| Step: 7
Training loss: 3.3505357000842513
Validation loss: 2.9825117740450793

Epoch: 5| Step: 8
Training loss: 3.799627491611804
Validation loss: 2.980951459696568

Epoch: 5| Step: 9
Training loss: 3.030338268219643
Validation loss: 2.980488490303516

Epoch: 5| Step: 10
Training loss: 2.394133243807709
Validation loss: 2.9811663884646684

Epoch: 32| Step: 0
Training loss: 3.563987287624991
Validation loss: 2.9790026579933215

Epoch: 5| Step: 1
Training loss: 2.735526403786033
Validation loss: 2.9777255873722845

Epoch: 5| Step: 2
Training loss: 3.2038891880908476
Validation loss: 2.977863985295436

Epoch: 5| Step: 3
Training loss: 3.632759602479462
Validation loss: 2.975258236110557

Epoch: 5| Step: 4
Training loss: 3.825378304516882
Validation loss: 2.975576331109922

Epoch: 5| Step: 5
Training loss: 2.83140719147917
Validation loss: 2.974945799782897

Epoch: 5| Step: 6
Training loss: 3.5154425679662915
Validation loss: 2.975625140727143

Epoch: 5| Step: 7
Training loss: 2.270647887144235
Validation loss: 2.9749083757445143

Epoch: 5| Step: 8
Training loss: 3.265651575007748
Validation loss: 2.9731355615172275

Epoch: 5| Step: 9
Training loss: 3.8216101192034544
Validation loss: 2.9768351535851205

Epoch: 5| Step: 10
Training loss: 2.7652402276091563
Validation loss: 2.9776378787621933

Epoch: 33| Step: 0
Training loss: 2.5427112829891123
Validation loss: 2.98869029867494

Epoch: 5| Step: 1
Training loss: 2.9492342714823345
Validation loss: 3.0110011202814126

Epoch: 5| Step: 2
Training loss: 3.279499422580757
Validation loss: 3.0372485074058977

Epoch: 5| Step: 3
Training loss: 3.5258523654506724
Validation loss: 3.011651499322594

Epoch: 5| Step: 4
Training loss: 3.3906912379672716
Validation loss: 2.989556814559682

Epoch: 5| Step: 5
Training loss: 3.123021834835513
Validation loss: 2.9756211913935013

Epoch: 5| Step: 6
Training loss: 3.6484692590544237
Validation loss: 2.9706523117719867

Epoch: 5| Step: 7
Training loss: 3.1379094316433496
Validation loss: 2.9695751397083736

Epoch: 5| Step: 8
Training loss: 3.507866602015273
Validation loss: 2.968164110902453

Epoch: 5| Step: 9
Training loss: 3.224164833928745
Validation loss: 2.9688963529633257

Epoch: 5| Step: 10
Training loss: 3.540069638876572
Validation loss: 2.969881126574631

Epoch: 34| Step: 0
Training loss: 3.3480302741939094
Validation loss: 2.965106248263237

Epoch: 5| Step: 1
Training loss: 3.2725335013217127
Validation loss: 2.96477426697215

Epoch: 5| Step: 2
Training loss: 2.993970852472365
Validation loss: 2.9650637751867213

Epoch: 5| Step: 3
Training loss: 3.4509221986740397
Validation loss: 2.96982746789323

Epoch: 5| Step: 4
Training loss: 3.171254665805871
Validation loss: 2.969167009738088

Epoch: 5| Step: 5
Training loss: 3.5008147517522867
Validation loss: 2.9802419068959654

Epoch: 5| Step: 6
Training loss: 3.9406874334848347
Validation loss: 2.970814165287864

Epoch: 5| Step: 7
Training loss: 2.982268703601907
Validation loss: 2.967929741018475

Epoch: 5| Step: 8
Training loss: 3.1266897592186584
Validation loss: 2.9641923860251853

Epoch: 5| Step: 9
Training loss: 2.737903694103135
Validation loss: 2.962063164481779

Epoch: 5| Step: 10
Training loss: 3.1209009371176393
Validation loss: 2.95931485220183

Epoch: 35| Step: 0
Training loss: 3.3269400479573776
Validation loss: 2.958971947445867

Epoch: 5| Step: 1
Training loss: 3.643450904989707
Validation loss: 2.958010192397147

Epoch: 5| Step: 2
Training loss: 3.62098655830086
Validation loss: 2.957658135746242

Epoch: 5| Step: 3
Training loss: 3.600568456273674
Validation loss: 2.956763504552959

Epoch: 5| Step: 4
Training loss: 2.827369040939748
Validation loss: 2.955542597489262

Epoch: 5| Step: 5
Training loss: 2.7985757100338127
Validation loss: 2.9539011759784293

Epoch: 5| Step: 6
Training loss: 3.324738548152955
Validation loss: 2.952842345120075

Epoch: 5| Step: 7
Training loss: 2.2391320653678397
Validation loss: 2.952077660454674

Epoch: 5| Step: 8
Training loss: 3.492756978481323
Validation loss: 2.9515609753453846

Epoch: 5| Step: 9
Training loss: 3.1059150806910925
Validation loss: 2.950056847062316

Epoch: 5| Step: 10
Training loss: 3.439777244186609
Validation loss: 2.948709795533784

Epoch: 36| Step: 0
Training loss: 4.05684820386999
Validation loss: 2.950545781591985

Epoch: 5| Step: 1
Training loss: 2.8282164669525653
Validation loss: 2.951540110456083

Epoch: 5| Step: 2
Training loss: 3.4489367187215967
Validation loss: 2.9565556766169196

Epoch: 5| Step: 3
Training loss: 3.5044109614639396
Validation loss: 2.9517637866836206

Epoch: 5| Step: 4
Training loss: 3.575917991738985
Validation loss: 2.9529862283096664

Epoch: 5| Step: 5
Training loss: 4.157599667417107
Validation loss: 2.9544451947966963

Epoch: 5| Step: 6
Training loss: 2.2530867278384163
Validation loss: 2.9537504321361734

Epoch: 5| Step: 7
Training loss: 2.7876501273881287
Validation loss: 2.9529857343311883

Epoch: 5| Step: 8
Training loss: 2.5654887006381077
Validation loss: 2.955473072745739

Epoch: 5| Step: 9
Training loss: 2.976195785881029
Validation loss: 2.9574099383151213

Epoch: 5| Step: 10
Training loss: 2.797518352485845
Validation loss: 2.953824517481349

Epoch: 37| Step: 0
Training loss: 4.024750193550328
Validation loss: 2.9405992104009697

Epoch: 5| Step: 1
Training loss: 2.9881649219085786
Validation loss: 2.9441127470953785

Epoch: 5| Step: 2
Training loss: 3.1824441343619783
Validation loss: 2.948063992423192

Epoch: 5| Step: 3
Training loss: 3.330086286875995
Validation loss: 2.962619012356548

Epoch: 5| Step: 4
Training loss: 3.5227397896105206
Validation loss: 2.96962162816586

Epoch: 5| Step: 5
Training loss: 2.980432912628581
Validation loss: 2.971762118185119

Epoch: 5| Step: 6
Training loss: 3.709613636185438
Validation loss: 2.946471929317721

Epoch: 5| Step: 7
Training loss: 2.951891121611306
Validation loss: 2.940925323831319

Epoch: 5| Step: 8
Training loss: 2.6373017295329815
Validation loss: 2.9395814850637723

Epoch: 5| Step: 9
Training loss: 2.6790294673391215
Validation loss: 2.939356778882894

Epoch: 5| Step: 10
Training loss: 3.3865378220396387
Validation loss: 2.9428752782482825

Epoch: 38| Step: 0
Training loss: 3.047810415804841
Validation loss: 2.94473872478408

Epoch: 5| Step: 1
Training loss: 3.6548769728467616
Validation loss: 2.9457977940483535

Epoch: 5| Step: 2
Training loss: 3.220865535862971
Validation loss: 2.9440676130766184

Epoch: 5| Step: 3
Training loss: 3.229925070681863
Validation loss: 2.9402526328525522

Epoch: 5| Step: 4
Training loss: 3.0840176175278518
Validation loss: 2.9385503035823577

Epoch: 5| Step: 5
Training loss: 3.4917005502396603
Validation loss: 2.939680399945894

Epoch: 5| Step: 6
Training loss: 3.2386478819330473
Validation loss: 2.935328125554823

Epoch: 5| Step: 7
Training loss: 3.2926886859143902
Validation loss: 2.934517342159314

Epoch: 5| Step: 8
Training loss: 3.463936154647149
Validation loss: 2.9327215524622847

Epoch: 5| Step: 9
Training loss: 2.8692072684674192
Validation loss: 2.933093026379938

Epoch: 5| Step: 10
Training loss: 2.6899418937335056
Validation loss: 2.932462731239885

Epoch: 39| Step: 0
Training loss: 3.547169274041431
Validation loss: 2.932488931731982

Epoch: 5| Step: 1
Training loss: 3.410656659617394
Validation loss: 2.9349155284330197

Epoch: 5| Step: 2
Training loss: 2.832205510533097
Validation loss: 2.9308103649462107

Epoch: 5| Step: 3
Training loss: 3.029760722416081
Validation loss: 2.933379257892343

Epoch: 5| Step: 4
Training loss: 3.257250840325964
Validation loss: 2.9318207263686173

Epoch: 5| Step: 5
Training loss: 2.9043689505914476
Validation loss: 2.930797821423838

Epoch: 5| Step: 6
Training loss: 3.326499577863842
Validation loss: 2.9307530176928958

Epoch: 5| Step: 7
Training loss: 3.4989189113172703
Validation loss: 2.9331546866318607

Epoch: 5| Step: 8
Training loss: 3.450728193086357
Validation loss: 2.9382740729731447

Epoch: 5| Step: 9
Training loss: 3.2566968439188377
Validation loss: 2.9387975579100716

Epoch: 5| Step: 10
Training loss: 2.692422041193857
Validation loss: 2.9236525193097607

Epoch: 40| Step: 0
Training loss: 3.326910952643068
Validation loss: 2.9222813972307304

Epoch: 5| Step: 1
Training loss: 3.1278972165521126
Validation loss: 2.920031878881305

Epoch: 5| Step: 2
Training loss: 2.643086927874447
Validation loss: 2.9203545759852716

Epoch: 5| Step: 3
Training loss: 3.13160846051798
Validation loss: 2.919613916894679

Epoch: 5| Step: 4
Training loss: 2.712232033286694
Validation loss: 2.9198014624698176

Epoch: 5| Step: 5
Training loss: 3.183251185796911
Validation loss: 2.919173743240424

Epoch: 5| Step: 6
Training loss: 3.478393346917353
Validation loss: 2.9192870096276593

Epoch: 5| Step: 7
Training loss: 3.840870841145192
Validation loss: 2.9163987231490727

Epoch: 5| Step: 8
Training loss: 3.769791573345896
Validation loss: 2.9168944754753965

Epoch: 5| Step: 9
Training loss: 2.784066649209169
Validation loss: 2.916396592347437

Epoch: 5| Step: 10
Training loss: 3.068516485027297
Validation loss: 2.9155723405674663

Epoch: 41| Step: 0
Training loss: 3.40660093407068
Validation loss: 2.915055588259552

Epoch: 5| Step: 1
Training loss: 3.5064235052742623
Validation loss: 2.9140068334140583

Epoch: 5| Step: 2
Training loss: 3.0519267140760147
Validation loss: 2.9139789508948937

Epoch: 5| Step: 3
Training loss: 3.1032455067511013
Validation loss: 2.9126062376541295

Epoch: 5| Step: 4
Training loss: 2.9205255503164613
Validation loss: 2.9118654239936945

Epoch: 5| Step: 5
Training loss: 3.1331059420706286
Validation loss: 2.9111494493776737

Epoch: 5| Step: 6
Training loss: 2.7507006879611158
Validation loss: 2.914003053062266

Epoch: 5| Step: 7
Training loss: 3.0535212092783466
Validation loss: 2.911065161460135

Epoch: 5| Step: 8
Training loss: 3.612428900735101
Validation loss: 2.915179054027852

Epoch: 5| Step: 9
Training loss: 3.498389827374494
Validation loss: 2.913974091903366

Epoch: 5| Step: 10
Training loss: 3.0648372839694886
Validation loss: 2.9118197100137473

Epoch: 42| Step: 0
Training loss: 3.464216964781096
Validation loss: 2.904144793110996

Epoch: 5| Step: 1
Training loss: 3.6750588756178875
Validation loss: 2.904086377269602

Epoch: 5| Step: 2
Training loss: 3.110129106791724
Validation loss: 2.909154874753809

Epoch: 5| Step: 3
Training loss: 2.9477849241188383
Validation loss: 2.9042232731481077

Epoch: 5| Step: 4
Training loss: 2.8946269607678974
Validation loss: 2.9084940650989943

Epoch: 5| Step: 5
Training loss: 3.3892389092407065
Validation loss: 2.910711354903114

Epoch: 5| Step: 6
Training loss: 2.8090082321671055
Validation loss: 2.9079209736288796

Epoch: 5| Step: 7
Training loss: 3.131707127262194
Validation loss: 2.9050446161978942

Epoch: 5| Step: 8
Training loss: 3.3903726932155065
Validation loss: 2.904484583452853

Epoch: 5| Step: 9
Training loss: 2.8463014328455536
Validation loss: 2.9070700182029223

Epoch: 5| Step: 10
Training loss: 3.4033963910524596
Validation loss: 2.899534243012528

Epoch: 43| Step: 0
Training loss: 2.4604104098230493
Validation loss: 2.897724396125466

Epoch: 5| Step: 1
Training loss: 3.460834854704935
Validation loss: 2.9010252398787673

Epoch: 5| Step: 2
Training loss: 3.41665041539739
Validation loss: 2.9229837792145155

Epoch: 5| Step: 3
Training loss: 3.158756884622864
Validation loss: 2.9586169629588044

Epoch: 5| Step: 4
Training loss: 2.589256162427814
Validation loss: 2.9779521211264597

Epoch: 5| Step: 5
Training loss: 3.4551296025436637
Validation loss: 2.952147831357936

Epoch: 5| Step: 6
Training loss: 3.4493813222587693
Validation loss: 2.915026984943224

Epoch: 5| Step: 7
Training loss: 3.9301592503864824
Validation loss: 2.8994467031725475

Epoch: 5| Step: 8
Training loss: 3.3084994936581347
Validation loss: 2.8983323940798815

Epoch: 5| Step: 9
Training loss: 3.0849566095846503
Validation loss: 2.895810426763232

Epoch: 5| Step: 10
Training loss: 2.7163251389118392
Validation loss: 2.8964703481074268

Epoch: 44| Step: 0
Training loss: 4.032346827606766
Validation loss: 2.8938817775278243

Epoch: 5| Step: 1
Training loss: 3.3029969853737655
Validation loss: 2.8927321594118007

Epoch: 5| Step: 2
Training loss: 2.852947745191277
Validation loss: 2.8985142586132073

Epoch: 5| Step: 3
Training loss: 3.5890356571852786
Validation loss: 2.9071912561126827

Epoch: 5| Step: 4
Training loss: 2.800601628926855
Validation loss: 2.9091069807172256

Epoch: 5| Step: 5
Training loss: 3.021335235643363
Validation loss: 2.9115320774897278

Epoch: 5| Step: 6
Training loss: 2.845758252994246
Validation loss: 2.9064499945780202

Epoch: 5| Step: 7
Training loss: 3.198482219046121
Validation loss: 2.898557018746466

Epoch: 5| Step: 8
Training loss: 2.7532324433334585
Validation loss: 2.890032722704317

Epoch: 5| Step: 9
Training loss: 3.127751016888176
Validation loss: 2.8886429731578365

Epoch: 5| Step: 10
Training loss: 3.3519615522651462
Validation loss: 2.887781596408524

Epoch: 45| Step: 0
Training loss: 3.3952203365058433
Validation loss: 2.8888956179775795

Epoch: 5| Step: 1
Training loss: 3.2300532118721943
Validation loss: 2.886944271186213

Epoch: 5| Step: 2
Training loss: 2.987013683879045
Validation loss: 2.887310815643934

Epoch: 5| Step: 3
Training loss: 2.9132638609027826
Validation loss: 2.8863315561554352

Epoch: 5| Step: 4
Training loss: 2.635306063254814
Validation loss: 2.8875070435529926

Epoch: 5| Step: 5
Training loss: 3.306181585689339
Validation loss: 2.885017222252147

Epoch: 5| Step: 6
Training loss: 3.122806542210587
Validation loss: 2.8831198452591913

Epoch: 5| Step: 7
Training loss: 2.9286446711722047
Validation loss: 2.88267906687855

Epoch: 5| Step: 8
Training loss: 3.448923860863656
Validation loss: 2.882086547861535

Epoch: 5| Step: 9
Training loss: 3.5414571513118207
Validation loss: 2.883145925076818

Epoch: 5| Step: 10
Training loss: 3.4310477998006093
Validation loss: 2.879969622444386

Epoch: 46| Step: 0
Training loss: 2.8715032791472344
Validation loss: 2.8805301672405825

Epoch: 5| Step: 1
Training loss: 3.5827894167649337
Validation loss: 2.8790982032232812

Epoch: 5| Step: 2
Training loss: 3.4991685697207116
Validation loss: 2.879267780968208

Epoch: 5| Step: 3
Training loss: 3.1116686465218417
Validation loss: 2.876471925144247

Epoch: 5| Step: 4
Training loss: 3.1410007536704136
Validation loss: 2.8751921863709815

Epoch: 5| Step: 5
Training loss: 3.3663259585621756
Validation loss: 2.8764336655331806

Epoch: 5| Step: 6
Training loss: 2.9116384124112846
Validation loss: 2.875668371764781

Epoch: 5| Step: 7
Training loss: 2.836648142657404
Validation loss: 2.8723561586310025

Epoch: 5| Step: 8
Training loss: 2.617362583054613
Validation loss: 2.8760329161487825

Epoch: 5| Step: 9
Training loss: 3.478383202578389
Validation loss: 2.8780599577347314

Epoch: 5| Step: 10
Training loss: 3.39789613818515
Validation loss: 2.8763844365507967

Epoch: 47| Step: 0
Training loss: 3.831664523776333
Validation loss: 2.871893773674841

Epoch: 5| Step: 1
Training loss: 2.520679206445001
Validation loss: 2.8728047702347936

Epoch: 5| Step: 2
Training loss: 3.390587872420573
Validation loss: 2.8709047870455504

Epoch: 5| Step: 3
Training loss: 3.698696917391144
Validation loss: 2.8674551723825017

Epoch: 5| Step: 4
Training loss: 3.762348062989723
Validation loss: 2.868485734355411

Epoch: 5| Step: 5
Training loss: 3.102052587421263
Validation loss: 2.8703448847730413

Epoch: 5| Step: 6
Training loss: 3.161629652799708
Validation loss: 2.865771838925408

Epoch: 5| Step: 7
Training loss: 2.1680737719142877
Validation loss: 2.8654652248004373

Epoch: 5| Step: 8
Training loss: 2.6294769982570285
Validation loss: 2.868055727805716

Epoch: 5| Step: 9
Training loss: 3.4761400287548425
Validation loss: 2.863705373036492

Epoch: 5| Step: 10
Training loss: 2.473988540197304
Validation loss: 2.8666093593296087

Epoch: 48| Step: 0
Training loss: 2.853775795858845
Validation loss: 2.864613032182389

Epoch: 5| Step: 1
Training loss: 3.8798134963446964
Validation loss: 2.8637220383665407

Epoch: 5| Step: 2
Training loss: 3.204426719585937
Validation loss: 2.8622198837334585

Epoch: 5| Step: 3
Training loss: 2.839123326239401
Validation loss: 2.8614633690261417

Epoch: 5| Step: 4
Training loss: 2.9813437521086534
Validation loss: 2.8648106340336126

Epoch: 5| Step: 5
Training loss: 2.656454370153801
Validation loss: 2.8616748385143356

Epoch: 5| Step: 6
Training loss: 3.208138018190958
Validation loss: 2.8583171700401753

Epoch: 5| Step: 7
Training loss: 3.4064037043338558
Validation loss: 2.8571334849334264

Epoch: 5| Step: 8
Training loss: 3.6577622636280887
Validation loss: 2.8595835928321165

Epoch: 5| Step: 9
Training loss: 2.5490099611862176
Validation loss: 2.8600737472584723

Epoch: 5| Step: 10
Training loss: 3.299974042616972
Validation loss: 2.8579538930174277

Epoch: 49| Step: 0
Training loss: 3.3729973962243913
Validation loss: 2.860429612009076

Epoch: 5| Step: 1
Training loss: 2.77510978893948
Validation loss: 2.858963295960178

Epoch: 5| Step: 2
Training loss: 2.1632362744032476
Validation loss: 2.8608764977427796

Epoch: 5| Step: 3
Training loss: 3.650222896929121
Validation loss: 2.8725548637153833

Epoch: 5| Step: 4
Training loss: 3.2752150486818885
Validation loss: 2.8641036206773824

Epoch: 5| Step: 5
Training loss: 3.509796872687138
Validation loss: 2.880752173602297

Epoch: 5| Step: 6
Training loss: 3.032276097874373
Validation loss: 2.923753446170721

Epoch: 5| Step: 7
Training loss: 2.4274690073315406
Validation loss: 2.927613255753874

Epoch: 5| Step: 8
Training loss: 3.622417055895588
Validation loss: 2.9307507766136305

Epoch: 5| Step: 9
Training loss: 3.4078676075001835
Validation loss: 2.9342031923315903

Epoch: 5| Step: 10
Training loss: 3.4435355173325655
Validation loss: 2.92422700232989

Epoch: 50| Step: 0
Training loss: 3.759548618940347
Validation loss: 2.9208354064569857

Epoch: 5| Step: 1
Training loss: 3.586169133569334
Validation loss: 2.9148716915816446

Epoch: 5| Step: 2
Training loss: 3.600816363914342
Validation loss: 2.904358912689176

Epoch: 5| Step: 3
Training loss: 2.8185003064317655
Validation loss: 2.8656645311576323

Epoch: 5| Step: 4
Training loss: 2.140794956115232
Validation loss: 2.8547975887592805

Epoch: 5| Step: 5
Training loss: 3.197594608819047
Validation loss: 2.8542197461840453

Epoch: 5| Step: 6
Training loss: 2.895843085037022
Validation loss: 2.854082976832023

Epoch: 5| Step: 7
Training loss: 3.464495687624372
Validation loss: 2.866989645276085

Epoch: 5| Step: 8
Training loss: 3.00566741945155
Validation loss: 2.86329676638416

Epoch: 5| Step: 9
Training loss: 3.036867265771916
Validation loss: 2.8532734856521618

Epoch: 5| Step: 10
Training loss: 3.074132198293204
Validation loss: 2.8655163716307057

Epoch: 51| Step: 0
Training loss: 3.221769527629212
Validation loss: 2.8775477630131365

Epoch: 5| Step: 1
Training loss: 3.0009301650944704
Validation loss: 2.892770082047332

Epoch: 5| Step: 2
Training loss: 2.9986127188943623
Validation loss: 2.9071570886310756

Epoch: 5| Step: 3
Training loss: 3.3153487138031514
Validation loss: 2.8880279208640145

Epoch: 5| Step: 4
Training loss: 3.5590485032054486
Validation loss: 2.8494068025309462

Epoch: 5| Step: 5
Training loss: 2.9116610124951996
Validation loss: 2.8457889731853774

Epoch: 5| Step: 6
Training loss: 3.403996413295125
Validation loss: 2.8475554493265403

Epoch: 5| Step: 7
Training loss: 2.7688985298220894
Validation loss: 2.8509989412096246

Epoch: 5| Step: 8
Training loss: 3.386109188358497
Validation loss: 2.857890220063446

Epoch: 5| Step: 9
Training loss: 3.067186467719038
Validation loss: 2.867063343674612

Epoch: 5| Step: 10
Training loss: 3.0759457072115852
Validation loss: 2.848128939068501

Epoch: 52| Step: 0
Training loss: 3.5174094863448735
Validation loss: 2.8499230248318486

Epoch: 5| Step: 1
Training loss: 2.467510829851527
Validation loss: 2.8682025575552164

Epoch: 5| Step: 2
Training loss: 3.39581113156665
Validation loss: 2.9136147169754776

Epoch: 5| Step: 3
Training loss: 2.6518259343578365
Validation loss: 2.9085455667327507

Epoch: 5| Step: 4
Training loss: 3.574747815607477
Validation loss: 2.8888519481030372

Epoch: 5| Step: 5
Training loss: 2.6973141521533033
Validation loss: 2.866086148517763

Epoch: 5| Step: 6
Training loss: 3.189236037276771
Validation loss: 2.8558720107161055

Epoch: 5| Step: 7
Training loss: 3.8740508855294964
Validation loss: 2.8470615531381105

Epoch: 5| Step: 8
Training loss: 3.5943288585690767
Validation loss: 2.854741070059498

Epoch: 5| Step: 9
Training loss: 2.3825991675762337
Validation loss: 2.8611336884160514

Epoch: 5| Step: 10
Training loss: 3.0828280851160628
Validation loss: 2.8644561226231176

Epoch: 53| Step: 0
Training loss: 3.1186186676811225
Validation loss: 2.863399514420691

Epoch: 5| Step: 1
Training loss: 3.1937852114772496
Validation loss: 2.8483131522357144

Epoch: 5| Step: 2
Training loss: 3.2706173058056116
Validation loss: 2.840692294547338

Epoch: 5| Step: 3
Training loss: 2.9887431666584465
Validation loss: 2.8357031624337945

Epoch: 5| Step: 4
Training loss: 3.250580955812817
Validation loss: 2.8356547632661813

Epoch: 5| Step: 5
Training loss: 3.0034363457234283
Validation loss: 2.8349472699543723

Epoch: 5| Step: 6
Training loss: 2.7957095483096097
Validation loss: 2.832204922169513

Epoch: 5| Step: 7
Training loss: 3.4690646467038135
Validation loss: 2.8308779445161916

Epoch: 5| Step: 8
Training loss: 2.9708454968246696
Validation loss: 2.831504065385086

Epoch: 5| Step: 9
Training loss: 3.111214711719825
Validation loss: 2.8283430582085827

Epoch: 5| Step: 10
Training loss: 3.4340163178097867
Validation loss: 2.8295462003916256

Epoch: 54| Step: 0
Training loss: 2.9272325326129787
Validation loss: 2.826150581487204

Epoch: 5| Step: 1
Training loss: 3.413541496555455
Validation loss: 2.8244979544059228

Epoch: 5| Step: 2
Training loss: 3.220992409025365
Validation loss: 2.8234811739155887

Epoch: 5| Step: 3
Training loss: 3.2931471444857086
Validation loss: 2.8209894884825797

Epoch: 5| Step: 4
Training loss: 2.936999014480524
Validation loss: 2.819465265204411

Epoch: 5| Step: 5
Training loss: 3.21734484769002
Validation loss: 2.818441308886555

Epoch: 5| Step: 6
Training loss: 3.5531349899970186
Validation loss: 2.817360609951697

Epoch: 5| Step: 7
Training loss: 3.4146577154735103
Validation loss: 2.817221397805801

Epoch: 5| Step: 8
Training loss: 2.9065205437856023
Validation loss: 2.816921059929008

Epoch: 5| Step: 9
Training loss: 2.9819303555968375
Validation loss: 2.8237591448085086

Epoch: 5| Step: 10
Training loss: 2.2993239238403067
Validation loss: 2.825637229917663

Epoch: 55| Step: 0
Training loss: 3.120708417917811
Validation loss: 2.8431831343889318

Epoch: 5| Step: 1
Training loss: 2.620961761562444
Validation loss: 2.829748789471548

Epoch: 5| Step: 2
Training loss: 3.53280132954994
Validation loss: 2.8242455952108467

Epoch: 5| Step: 3
Training loss: 2.8221775133574845
Validation loss: 2.8205226256001263

Epoch: 5| Step: 4
Training loss: 3.1336778316092637
Validation loss: 2.8108092372600066

Epoch: 5| Step: 5
Training loss: 3.2817086035543404
Validation loss: 2.8109541205184705

Epoch: 5| Step: 6
Training loss: 3.1589119138835278
Validation loss: 2.807260202220131

Epoch: 5| Step: 7
Training loss: 2.9997730169258094
Validation loss: 2.808983671742555

Epoch: 5| Step: 8
Training loss: 2.962766862269722
Validation loss: 2.8070000965426094

Epoch: 5| Step: 9
Training loss: 3.7706490712256637
Validation loss: 2.8089710213654016

Epoch: 5| Step: 10
Training loss: 2.744243579168559
Validation loss: 2.8085243355377085

Epoch: 56| Step: 0
Training loss: 3.5163662955440915
Validation loss: 2.8073700638524732

Epoch: 5| Step: 1
Training loss: 2.9747167756998114
Validation loss: 2.804160824662204

Epoch: 5| Step: 2
Training loss: 3.0705883106079503
Validation loss: 2.8041921971138692

Epoch: 5| Step: 3
Training loss: 3.1966909405924007
Validation loss: 2.804594094747454

Epoch: 5| Step: 4
Training loss: 3.2011863238024287
Validation loss: 2.8067230297688472

Epoch: 5| Step: 5
Training loss: 2.6227632711538553
Validation loss: 2.8122355711674976

Epoch: 5| Step: 6
Training loss: 3.592319236885111
Validation loss: 2.824401222329495

Epoch: 5| Step: 7
Training loss: 3.1172043266893903
Validation loss: 2.827100514855827

Epoch: 5| Step: 8
Training loss: 2.9847189819861137
Validation loss: 2.8173960156537547

Epoch: 5| Step: 9
Training loss: 2.841357555711603
Validation loss: 2.8098274777738608

Epoch: 5| Step: 10
Training loss: 3.1774921758691965
Validation loss: 2.8003094012922682

Epoch: 57| Step: 0
Training loss: 3.0620580860411577
Validation loss: 2.8026725246274595

Epoch: 5| Step: 1
Training loss: 3.192787273150881
Validation loss: 2.804228344113311

Epoch: 5| Step: 2
Training loss: 3.2469658994020683
Validation loss: 2.8098135693631563

Epoch: 5| Step: 3
Training loss: 2.928106669854079
Validation loss: 2.8139903724023467

Epoch: 5| Step: 4
Training loss: 3.3531038168089617
Validation loss: 2.810502295134218

Epoch: 5| Step: 5
Training loss: 3.3179354427741647
Validation loss: 2.809449688139706

Epoch: 5| Step: 6
Training loss: 2.629010724149925
Validation loss: 2.8094913081578206

Epoch: 5| Step: 7
Training loss: 3.1543800177703365
Validation loss: 2.808293108358253

Epoch: 5| Step: 8
Training loss: 3.704225014626457
Validation loss: 2.8080456406660783

Epoch: 5| Step: 9
Training loss: 2.998314224897575
Validation loss: 2.8046069997861154

Epoch: 5| Step: 10
Training loss: 2.5054284287893536
Validation loss: 2.801403733744071

Epoch: 58| Step: 0
Training loss: 2.773124741663221
Validation loss: 2.798329091579855

Epoch: 5| Step: 1
Training loss: 2.8095968733809245
Validation loss: 2.7993794878732117

Epoch: 5| Step: 2
Training loss: 3.3664157629155302
Validation loss: 2.798796435946738

Epoch: 5| Step: 3
Training loss: 3.0251663351435147
Validation loss: 2.7976502877979783

Epoch: 5| Step: 4
Training loss: 2.7003050631798287
Validation loss: 2.7976212181194846

Epoch: 5| Step: 5
Training loss: 3.837606094335155
Validation loss: 2.797940858936664

Epoch: 5| Step: 6
Training loss: 3.194941342909342
Validation loss: 2.7956967883500234

Epoch: 5| Step: 7
Training loss: 3.449980395717483
Validation loss: 2.7966098069608516

Epoch: 5| Step: 8
Training loss: 3.1533215222396254
Validation loss: 2.795774216521534

Epoch: 5| Step: 9
Training loss: 2.953146152319666
Validation loss: 2.79913841071984

Epoch: 5| Step: 10
Training loss: 2.764749679409498
Validation loss: 2.7969131334218655

Epoch: 59| Step: 0
Training loss: 3.5563421736908376
Validation loss: 2.7965342812024057

Epoch: 5| Step: 1
Training loss: 2.9439486879977164
Validation loss: 2.7980261724152875

Epoch: 5| Step: 2
Training loss: 3.132223249846256
Validation loss: 2.794759693248518

Epoch: 5| Step: 3
Training loss: 3.4779309269175642
Validation loss: 2.7957545126041814

Epoch: 5| Step: 4
Training loss: 2.567938453210103
Validation loss: 2.7946376471275434

Epoch: 5| Step: 5
Training loss: 3.0154875887066828
Validation loss: 2.794388790309385

Epoch: 5| Step: 6
Training loss: 3.336626397142978
Validation loss: 2.7917246370965145

Epoch: 5| Step: 7
Training loss: 2.912098076719783
Validation loss: 2.7955077232153074

Epoch: 5| Step: 8
Training loss: 3.206628883387719
Validation loss: 2.7947164952955315

Epoch: 5| Step: 9
Training loss: 3.5372877239254223
Validation loss: 2.792076490940685

Epoch: 5| Step: 10
Training loss: 2.201091504258655
Validation loss: 2.791432905503965

Epoch: 60| Step: 0
Training loss: 3.0919760810548698
Validation loss: 2.7906321551170086

Epoch: 5| Step: 1
Training loss: 2.8975802487968774
Validation loss: 2.788199910678558

Epoch: 5| Step: 2
Training loss: 2.9947099138241327
Validation loss: 2.7887187665636306

Epoch: 5| Step: 3
Training loss: 3.038545147712151
Validation loss: 2.7878589178881814

Epoch: 5| Step: 4
Training loss: 3.3818783780815864
Validation loss: 2.7866875280623966

Epoch: 5| Step: 5
Training loss: 3.052573016118991
Validation loss: 2.784042376133033

Epoch: 5| Step: 6
Training loss: 2.9219523536928143
Validation loss: 2.7864624967976193

Epoch: 5| Step: 7
Training loss: 3.1746834784901994
Validation loss: 2.790945482164502

Epoch: 5| Step: 8
Training loss: 3.1046212053444324
Validation loss: 2.794090031575917

Epoch: 5| Step: 9
Training loss: 3.169789798638659
Validation loss: 2.7932551503246605

Epoch: 5| Step: 10
Training loss: 3.315849913537838
Validation loss: 2.788109882975223

Epoch: 61| Step: 0
Training loss: 3.5118678382736697
Validation loss: 2.7889242735740534

Epoch: 5| Step: 1
Training loss: 2.5994925297158176
Validation loss: 2.7823832683620147

Epoch: 5| Step: 2
Training loss: 3.3564740097333
Validation loss: 2.7791019674278465

Epoch: 5| Step: 3
Training loss: 2.875190065155102
Validation loss: 2.779655934388908

Epoch: 5| Step: 4
Training loss: 3.4367108913157476
Validation loss: 2.7810799709296163

Epoch: 5| Step: 5
Training loss: 2.6733605789007506
Validation loss: 2.7764304585913746

Epoch: 5| Step: 6
Training loss: 2.8762434882496875
Validation loss: 2.775352393533723

Epoch: 5| Step: 7
Training loss: 3.1459014750462613
Validation loss: 2.772445904003264

Epoch: 5| Step: 8
Training loss: 3.2411481179416226
Validation loss: 2.7774795917380626

Epoch: 5| Step: 9
Training loss: 2.791715071149394
Validation loss: 2.771663017568256

Epoch: 5| Step: 10
Training loss: 3.3588091706436383
Validation loss: 2.7743230440942814

Epoch: 62| Step: 0
Training loss: 3.3102358871722637
Validation loss: 2.7728957381211057

Epoch: 5| Step: 1
Training loss: 2.8605814405429038
Validation loss: 2.769365634528436

Epoch: 5| Step: 2
Training loss: 2.9760027181346334
Validation loss: 2.7715621669419632

Epoch: 5| Step: 3
Training loss: 3.246913030730262
Validation loss: 2.774576778411853

Epoch: 5| Step: 4
Training loss: 2.6686369253320326
Validation loss: 2.772692695288252

Epoch: 5| Step: 5
Training loss: 3.503540972633805
Validation loss: 2.7716826652169853

Epoch: 5| Step: 6
Training loss: 3.130225428546722
Validation loss: 2.7809019830789854

Epoch: 5| Step: 7
Training loss: 2.5578887201043865
Validation loss: 2.786842840555508

Epoch: 5| Step: 8
Training loss: 3.3193645245992447
Validation loss: 2.787013765366619

Epoch: 5| Step: 9
Training loss: 3.38430576975735
Validation loss: 2.7955245814279714

Epoch: 5| Step: 10
Training loss: 2.810895843790928
Validation loss: 2.7824557047075973

Epoch: 63| Step: 0
Training loss: 2.752208343215559
Validation loss: 2.7744258078150135

Epoch: 5| Step: 1
Training loss: 3.109765416463848
Validation loss: 2.7655101576387127

Epoch: 5| Step: 2
Training loss: 3.2776507300918563
Validation loss: 2.764039831807583

Epoch: 5| Step: 3
Training loss: 2.7989587107805898
Validation loss: 2.7657839061612477

Epoch: 5| Step: 4
Training loss: 2.918955767482949
Validation loss: 2.7643901741862016

Epoch: 5| Step: 5
Training loss: 3.4866106875164182
Validation loss: 2.765294513129255

Epoch: 5| Step: 6
Training loss: 2.7362797669542513
Validation loss: 2.76157461727454

Epoch: 5| Step: 7
Training loss: 3.244659437462167
Validation loss: 2.761141288193899

Epoch: 5| Step: 8
Training loss: 3.006214698378035
Validation loss: 2.761417529890015

Epoch: 5| Step: 9
Training loss: 2.8905025971761775
Validation loss: 2.764679739043525

Epoch: 5| Step: 10
Training loss: 3.67923327191648
Validation loss: 2.7720094226933947

Epoch: 64| Step: 0
Training loss: 2.4953545324981152
Validation loss: 2.773704621090206

Epoch: 5| Step: 1
Training loss: 2.9941697688466653
Validation loss: 2.772301758424827

Epoch: 5| Step: 2
Training loss: 2.9343163302632873
Validation loss: 2.7702239614995876

Epoch: 5| Step: 3
Training loss: 2.939357413827993
Validation loss: 2.7568129618371175

Epoch: 5| Step: 4
Training loss: 3.2323411821971146
Validation loss: 2.7604835512985875

Epoch: 5| Step: 5
Training loss: 3.3266635605282193
Validation loss: 2.7584961692699315

Epoch: 5| Step: 6
Training loss: 3.0657521321633716
Validation loss: 2.762682103112948

Epoch: 5| Step: 7
Training loss: 3.4058155867715727
Validation loss: 2.763410162113804

Epoch: 5| Step: 8
Training loss: 3.370546723115928
Validation loss: 2.7658094563958677

Epoch: 5| Step: 9
Training loss: 3.1398952262552253
Validation loss: 2.769372245970181

Epoch: 5| Step: 10
Training loss: 2.942081368872536
Validation loss: 2.7626325935641405

Epoch: 65| Step: 0
Training loss: 3.2136210344715885
Validation loss: 2.7615218720906496

Epoch: 5| Step: 1
Training loss: 2.504344788710162
Validation loss: 2.7623215649975275

Epoch: 5| Step: 2
Training loss: 2.273771386027621
Validation loss: 2.760381023589371

Epoch: 5| Step: 3
Training loss: 3.3910634684628884
Validation loss: 2.7580553266464167

Epoch: 5| Step: 4
Training loss: 3.1535583198347736
Validation loss: 2.766998702548949

Epoch: 5| Step: 5
Training loss: 3.049187042204392
Validation loss: 2.7630259979939886

Epoch: 5| Step: 6
Training loss: 3.592486615564185
Validation loss: 2.764317045582846

Epoch: 5| Step: 7
Training loss: 3.457682506188015
Validation loss: 2.7556378975500535

Epoch: 5| Step: 8
Training loss: 2.919571891912144
Validation loss: 2.7526987598785015

Epoch: 5| Step: 9
Training loss: 3.285389205892035
Validation loss: 2.7550242980709765

Epoch: 5| Step: 10
Training loss: 2.737399363300949
Validation loss: 2.7549269607534006

Epoch: 66| Step: 0
Training loss: 3.2106345374864422
Validation loss: 2.7507771226452777

Epoch: 5| Step: 1
Training loss: 2.6753914876371985
Validation loss: 2.7531552005895654

Epoch: 5| Step: 2
Training loss: 3.501209867357043
Validation loss: 2.75827199905332

Epoch: 5| Step: 3
Training loss: 3.3569818533462894
Validation loss: 2.753498983715856

Epoch: 5| Step: 4
Training loss: 3.3449446781071237
Validation loss: 2.7488898565669926

Epoch: 5| Step: 5
Training loss: 3.0625456203254684
Validation loss: 2.744139977583044

Epoch: 5| Step: 6
Training loss: 2.6653268448332597
Validation loss: 2.7449669679329025

Epoch: 5| Step: 7
Training loss: 3.0283264534059793
Validation loss: 2.748311557365484

Epoch: 5| Step: 8
Training loss: 2.7204189220560706
Validation loss: 2.7473985042227587

Epoch: 5| Step: 9
Training loss: 3.2861976741834313
Validation loss: 2.748432852075664

Epoch: 5| Step: 10
Training loss: 2.7428047376689966
Validation loss: 2.750112820247297

Epoch: 67| Step: 0
Training loss: 3.252854487507016
Validation loss: 2.751033374388563

Epoch: 5| Step: 1
Training loss: 3.070606479693744
Validation loss: 2.752175307903742

Epoch: 5| Step: 2
Training loss: 2.9129558026476663
Validation loss: 2.7604160897797447

Epoch: 5| Step: 3
Training loss: 3.3322607857999467
Validation loss: 2.7567995903539573

Epoch: 5| Step: 4
Training loss: 3.0712441930844068
Validation loss: 2.7569931910869787

Epoch: 5| Step: 5
Training loss: 2.930467344124563
Validation loss: 2.756613961913384

Epoch: 5| Step: 6
Training loss: 2.434483152834611
Validation loss: 2.7535796820785294

Epoch: 5| Step: 7
Training loss: 3.3898851844451463
Validation loss: 2.757713922900516

Epoch: 5| Step: 8
Training loss: 2.9087602172724574
Validation loss: 2.749489860910999

Epoch: 5| Step: 9
Training loss: 2.8834809972918434
Validation loss: 2.743400323054095

Epoch: 5| Step: 10
Training loss: 3.579596604151047
Validation loss: 2.7391272033001814

Epoch: 68| Step: 0
Training loss: 2.8573678064347963
Validation loss: 2.7412715841020736

Epoch: 5| Step: 1
Training loss: 3.433393071096267
Validation loss: 2.744089164684912

Epoch: 5| Step: 2
Training loss: 3.523652131506751
Validation loss: 2.7546982423958655

Epoch: 5| Step: 3
Training loss: 2.8899698700703698
Validation loss: 2.7496685898583824

Epoch: 5| Step: 4
Training loss: 2.8109112808845294
Validation loss: 2.7410814417397895

Epoch: 5| Step: 5
Training loss: 3.385300916991573
Validation loss: 2.7389262613240035

Epoch: 5| Step: 6
Training loss: 3.2461244510525455
Validation loss: 2.7356605857082292

Epoch: 5| Step: 7
Training loss: 2.969789664273282
Validation loss: 2.736554390699506

Epoch: 5| Step: 8
Training loss: 2.7258822841402646
Validation loss: 2.7370978083886457

Epoch: 5| Step: 9
Training loss: 2.9804250731461415
Validation loss: 2.7337761561030534

Epoch: 5| Step: 10
Training loss: 2.6313983503913625
Validation loss: 2.736448569029978

Epoch: 69| Step: 0
Training loss: 2.764087572949055
Validation loss: 2.744959146155386

Epoch: 5| Step: 1
Training loss: 3.433254463870117
Validation loss: 2.745930969821829

Epoch: 5| Step: 2
Training loss: 3.266113390746466
Validation loss: 2.731203532929485

Epoch: 5| Step: 3
Training loss: 3.616236914021945
Validation loss: 2.7347707285678315

Epoch: 5| Step: 4
Training loss: 2.9897626408803277
Validation loss: 2.731956340419407

Epoch: 5| Step: 5
Training loss: 3.1693681102776345
Validation loss: 2.7373151450704656

Epoch: 5| Step: 6
Training loss: 2.9713971031534823
Validation loss: 2.7371642247640415

Epoch: 5| Step: 7
Training loss: 2.6677542693803105
Validation loss: 2.735033896850454

Epoch: 5| Step: 8
Training loss: 2.736002061954636
Validation loss: 2.7349544106980064

Epoch: 5| Step: 9
Training loss: 2.868588637922943
Validation loss: 2.7389967086134197

Epoch: 5| Step: 10
Training loss: 3.120881838521319
Validation loss: 2.743296167231072

Epoch: 70| Step: 0
Training loss: 3.398537399752948
Validation loss: 2.739288928753224

Epoch: 5| Step: 1
Training loss: 2.593596764139961
Validation loss: 2.735575527679726

Epoch: 5| Step: 2
Training loss: 3.4181619644049617
Validation loss: 2.7329938728279415

Epoch: 5| Step: 3
Training loss: 2.8227179669670894
Validation loss: 2.7351468179747758

Epoch: 5| Step: 4
Training loss: 3.0815099703237356
Validation loss: 2.733133196375459

Epoch: 5| Step: 5
Training loss: 3.0906953469998153
Validation loss: 2.7344185286893903

Epoch: 5| Step: 6
Training loss: 2.882883624101449
Validation loss: 2.750860776827879

Epoch: 5| Step: 7
Training loss: 3.041959739744683
Validation loss: 2.7564069918490763

Epoch: 5| Step: 8
Training loss: 3.1515797725690224
Validation loss: 2.737344996597136

Epoch: 5| Step: 9
Training loss: 3.3003242853526937
Validation loss: 2.7308375105035654

Epoch: 5| Step: 10
Training loss: 2.7783546378591373
Validation loss: 2.7271965999114895

Epoch: 71| Step: 0
Training loss: 2.977217474536591
Validation loss: 2.7273716688309695

Epoch: 5| Step: 1
Training loss: 3.056579160224666
Validation loss: 2.7262328860956675

Epoch: 5| Step: 2
Training loss: 2.408014121454597
Validation loss: 2.7309824891123418

Epoch: 5| Step: 3
Training loss: 3.104155026271082
Validation loss: 2.7278189401138677

Epoch: 5| Step: 4
Training loss: 3.1247270083397605
Validation loss: 2.726750807931258

Epoch: 5| Step: 5
Training loss: 3.1435439176869724
Validation loss: 2.7361264115349893

Epoch: 5| Step: 6
Training loss: 2.8453245729361005
Validation loss: 2.743892366298717

Epoch: 5| Step: 7
Training loss: 2.727607417522011
Validation loss: 2.747332574143009

Epoch: 5| Step: 8
Training loss: 3.7307921264454107
Validation loss: 2.750557431863948

Epoch: 5| Step: 9
Training loss: 2.9380749078995096
Validation loss: 2.735270330104297

Epoch: 5| Step: 10
Training loss: 3.4399485797143976
Validation loss: 2.7315166613258

Epoch: 72| Step: 0
Training loss: 2.861410615011875
Validation loss: 2.7385020510570905

Epoch: 5| Step: 1
Training loss: 2.6846520171042454
Validation loss: 2.739532156427707

Epoch: 5| Step: 2
Training loss: 2.899265058060765
Validation loss: 2.7450502752516948

Epoch: 5| Step: 3
Training loss: 2.2556757864621395
Validation loss: 2.7319062576144018

Epoch: 5| Step: 4
Training loss: 3.482715160024468
Validation loss: 2.7343452098061602

Epoch: 5| Step: 5
Training loss: 2.9166789644981157
Validation loss: 2.7284192954183917

Epoch: 5| Step: 6
Training loss: 3.3628782945855082
Validation loss: 2.7268845511092428

Epoch: 5| Step: 7
Training loss: 3.4751651313023006
Validation loss: 2.729916226738169

Epoch: 5| Step: 8
Training loss: 3.1615200047183594
Validation loss: 2.7287663066940606

Epoch: 5| Step: 9
Training loss: 3.0571683287991838
Validation loss: 2.7203397439356

Epoch: 5| Step: 10
Training loss: 3.1868882433684766
Validation loss: 2.722034010311303

Epoch: 73| Step: 0
Training loss: 3.2642130012200465
Validation loss: 2.720274309681859

Epoch: 5| Step: 1
Training loss: 3.009058944251586
Validation loss: 2.7166933553494355

Epoch: 5| Step: 2
Training loss: 3.0899824841938037
Validation loss: 2.71648672606264

Epoch: 5| Step: 3
Training loss: 2.9064383497014408
Validation loss: 2.716684545305514

Epoch: 5| Step: 4
Training loss: 2.963579031245578
Validation loss: 2.719522269625526

Epoch: 5| Step: 5
Training loss: 2.2005442119613017
Validation loss: 2.714257435678707

Epoch: 5| Step: 6
Training loss: 2.617215011224341
Validation loss: 2.7169848803479426

Epoch: 5| Step: 7
Training loss: 3.737661535542305
Validation loss: 2.7264584353010592

Epoch: 5| Step: 8
Training loss: 3.6879089904528275
Validation loss: 2.726754553611739

Epoch: 5| Step: 9
Training loss: 2.7923879593081806
Validation loss: 2.7208090945425827

Epoch: 5| Step: 10
Training loss: 2.8670622670943153
Validation loss: 2.7203068955394762

Epoch: 74| Step: 0
Training loss: 2.9161515098844015
Validation loss: 2.7270567559096297

Epoch: 5| Step: 1
Training loss: 2.748105870679811
Validation loss: 2.7269131479971924

Epoch: 5| Step: 2
Training loss: 3.0094535017222515
Validation loss: 2.7397220498003962

Epoch: 5| Step: 3
Training loss: 3.3137399044336355
Validation loss: 2.745173933875058

Epoch: 5| Step: 4
Training loss: 3.3578465022890147
Validation loss: 2.739802225732892

Epoch: 5| Step: 5
Training loss: 2.354173395828037
Validation loss: 2.724131898842934

Epoch: 5| Step: 6
Training loss: 2.2924223838654525
Validation loss: 2.72302117191933

Epoch: 5| Step: 7
Training loss: 3.325955825750876
Validation loss: 2.7188682884025264

Epoch: 5| Step: 8
Training loss: 3.402411161295803
Validation loss: 2.7128074489903002

Epoch: 5| Step: 9
Training loss: 3.300815920675902
Validation loss: 2.711455812381707

Epoch: 5| Step: 10
Training loss: 3.1526220640771787
Validation loss: 2.7113973826738413

Epoch: 75| Step: 0
Training loss: 3.2404167027420514
Validation loss: 2.705386638570009

Epoch: 5| Step: 1
Training loss: 2.74766745045765
Validation loss: 2.7058278325906517

Epoch: 5| Step: 2
Training loss: 3.1419079945070423
Validation loss: 2.705508944260592

Epoch: 5| Step: 3
Training loss: 3.658191784761187
Validation loss: 2.706667026052184

Epoch: 5| Step: 4
Training loss: 2.8905857392815206
Validation loss: 2.7062856796365375

Epoch: 5| Step: 5
Training loss: 3.011347924742762
Validation loss: 2.704199045584277

Epoch: 5| Step: 6
Training loss: 2.810093082909005
Validation loss: 2.7060052920167275

Epoch: 5| Step: 7
Training loss: 2.5957381200907075
Validation loss: 2.7027556483384076

Epoch: 5| Step: 8
Training loss: 3.2129010139459697
Validation loss: 2.7038987315113983

Epoch: 5| Step: 9
Training loss: 2.864625539757723
Validation loss: 2.7059978256308406

Epoch: 5| Step: 10
Training loss: 3.079163661709267
Validation loss: 2.706315107551617

Epoch: 76| Step: 0
Training loss: 3.4084099037380193
Validation loss: 2.7142848159126403

Epoch: 5| Step: 1
Training loss: 2.7669791661764798
Validation loss: 2.715343953291461

Epoch: 5| Step: 2
Training loss: 2.6795456740324606
Validation loss: 2.720297169865253

Epoch: 5| Step: 3
Training loss: 2.8292508913817236
Validation loss: 2.7325931022701058

Epoch: 5| Step: 4
Training loss: 2.590311551889473
Validation loss: 2.7175377781284453

Epoch: 5| Step: 5
Training loss: 3.442317292151284
Validation loss: 2.7126204139049084

Epoch: 5| Step: 6
Training loss: 3.0326363450963125
Validation loss: 2.703433638785063

Epoch: 5| Step: 7
Training loss: 3.5151373630994165
Validation loss: 2.6965578583192875

Epoch: 5| Step: 8
Training loss: 2.9881899751174754
Validation loss: 2.6937899785453334

Epoch: 5| Step: 9
Training loss: 2.781310348713242
Validation loss: 2.6974007160704496

Epoch: 5| Step: 10
Training loss: 3.1631861850720493
Validation loss: 2.6940651129270234

Epoch: 77| Step: 0
Training loss: 2.8595667706995176
Validation loss: 2.697931364146666

Epoch: 5| Step: 1
Training loss: 3.7640966582500144
Validation loss: 2.704453856249145

Epoch: 5| Step: 2
Training loss: 2.7735516591822016
Validation loss: 2.711665364402712

Epoch: 5| Step: 3
Training loss: 3.1267972736965053
Validation loss: 2.712757366573543

Epoch: 5| Step: 4
Training loss: 2.629201977266479
Validation loss: 2.70471465791676

Epoch: 5| Step: 5
Training loss: 3.031574979055886
Validation loss: 2.702289115140184

Epoch: 5| Step: 6
Training loss: 2.989474269104795
Validation loss: 2.698263469994221

Epoch: 5| Step: 7
Training loss: 2.826945612192285
Validation loss: 2.7008766745762585

Epoch: 5| Step: 8
Training loss: 2.9655278438173625
Validation loss: 2.695774331161731

Epoch: 5| Step: 9
Training loss: 3.0467693603982275
Validation loss: 2.697826815564522

Epoch: 5| Step: 10
Training loss: 3.1170736880068852
Validation loss: 2.6964584275821974

Epoch: 78| Step: 0
Training loss: 2.4885405161362475
Validation loss: 2.6975539237542496

Epoch: 5| Step: 1
Training loss: 3.0232726848145215
Validation loss: 2.696326134067221

Epoch: 5| Step: 2
Training loss: 3.4447337938278126
Validation loss: 2.699541048962363

Epoch: 5| Step: 3
Training loss: 3.3899996835714097
Validation loss: 2.7014229854192835

Epoch: 5| Step: 4
Training loss: 3.431175656373147
Validation loss: 2.7092280229771784

Epoch: 5| Step: 5
Training loss: 3.0144040497090536
Validation loss: 2.6994760668849365

Epoch: 5| Step: 6
Training loss: 1.9110445480743592
Validation loss: 2.6929805436576046

Epoch: 5| Step: 7
Training loss: 3.0403946258999293
Validation loss: 2.6939985799116286

Epoch: 5| Step: 8
Training loss: 2.97373110854573
Validation loss: 2.700529809393126

Epoch: 5| Step: 9
Training loss: 3.2611858366579267
Validation loss: 2.7007702399910274

Epoch: 5| Step: 10
Training loss: 3.025535939558084
Validation loss: 2.702043579594959

Epoch: 79| Step: 0
Training loss: 3.3743028273886226
Validation loss: 2.701224614167427

Epoch: 5| Step: 1
Training loss: 2.7264183902639614
Validation loss: 2.7033898264572658

Epoch: 5| Step: 2
Training loss: 2.858033746379979
Validation loss: 2.6993487259291533

Epoch: 5| Step: 3
Training loss: 3.3167892612311034
Validation loss: 2.6956908343469523

Epoch: 5| Step: 4
Training loss: 3.1095550331635007
Validation loss: 2.695886266415378

Epoch: 5| Step: 5
Training loss: 2.9908756737003004
Validation loss: 2.6942074467820274

Epoch: 5| Step: 6
Training loss: 3.311830848907798
Validation loss: 2.695337813729477

Epoch: 5| Step: 7
Training loss: 2.6162702632726265
Validation loss: 2.6990321562199786

Epoch: 5| Step: 8
Training loss: 2.7948577255042064
Validation loss: 2.7010407690676135

Epoch: 5| Step: 9
Training loss: 3.352954637620515
Validation loss: 2.7016385887931804

Epoch: 5| Step: 10
Training loss: 2.8610891405103565
Validation loss: 2.69527208637687

Epoch: 80| Step: 0
Training loss: 2.7521139169668998
Validation loss: 2.688061376283075

Epoch: 5| Step: 1
Training loss: 2.671231465612293
Validation loss: 2.6838278172731007

Epoch: 5| Step: 2
Training loss: 3.2525991170501403
Validation loss: 2.6827460880843588

Epoch: 5| Step: 3
Training loss: 3.374939388154736
Validation loss: 2.680977530355395

Epoch: 5| Step: 4
Training loss: 3.154482809438648
Validation loss: 2.682652392425294

Epoch: 5| Step: 5
Training loss: 2.8747667964395185
Validation loss: 2.683835860196595

Epoch: 5| Step: 6
Training loss: 3.3046694635570892
Validation loss: 2.691706322552125

Epoch: 5| Step: 7
Training loss: 2.751372515018667
Validation loss: 2.6912486305258287

Epoch: 5| Step: 8
Training loss: 3.1442863416370916
Validation loss: 2.693521924914637

Epoch: 5| Step: 9
Training loss: 2.992512418869369
Validation loss: 2.6870534811609654

Epoch: 5| Step: 10
Training loss: 2.788163069478174
Validation loss: 2.6879687195045294

Epoch: 81| Step: 0
Training loss: 2.9085189002296623
Validation loss: 2.6891425679958063

Epoch: 5| Step: 1
Training loss: 2.5844663370913916
Validation loss: 2.6940704037523524

Epoch: 5| Step: 2
Training loss: 3.195785226339628
Validation loss: 2.6980982782797587

Epoch: 5| Step: 3
Training loss: 3.2783969646329965
Validation loss: 2.6944913412518656

Epoch: 5| Step: 4
Training loss: 3.1742118157497172
Validation loss: 2.6966705662663553

Epoch: 5| Step: 5
Training loss: 2.890891727822858
Validation loss: 2.7029181472451356

Epoch: 5| Step: 6
Training loss: 3.3206195285435407
Validation loss: 2.6986635999953767

Epoch: 5| Step: 7
Training loss: 3.4027208717068627
Validation loss: 2.694636585718874

Epoch: 5| Step: 8
Training loss: 2.4715267934425365
Validation loss: 2.6808250947455834

Epoch: 5| Step: 9
Training loss: 2.57423458760184
Validation loss: 2.6802715783225817

Epoch: 5| Step: 10
Training loss: 3.229229653677323
Validation loss: 2.6766253478991633

Epoch: 82| Step: 0
Training loss: 3.383325832966225
Validation loss: 2.6768905573751036

Epoch: 5| Step: 1
Training loss: 2.8119707245313452
Validation loss: 2.673664818838543

Epoch: 5| Step: 2
Training loss: 2.606322736205405
Validation loss: 2.680027504655694

Epoch: 5| Step: 3
Training loss: 3.138831390334346
Validation loss: 2.680359104872504

Epoch: 5| Step: 4
Training loss: 3.360886628472219
Validation loss: 2.676116715861993

Epoch: 5| Step: 5
Training loss: 3.1926682403851583
Validation loss: 2.6840802656961835

Epoch: 5| Step: 6
Training loss: 2.718043005209396
Validation loss: 2.6884283917134804

Epoch: 5| Step: 7
Training loss: 2.698381440376085
Validation loss: 2.6973697952057862

Epoch: 5| Step: 8
Training loss: 3.030193813407645
Validation loss: 2.6941877527290603

Epoch: 5| Step: 9
Training loss: 2.900609274691907
Validation loss: 2.6722041686919105

Epoch: 5| Step: 10
Training loss: 3.206804051407116
Validation loss: 2.668179661229242

Epoch: 83| Step: 0
Training loss: 2.6288404073872966
Validation loss: 2.6698337297362547

Epoch: 5| Step: 1
Training loss: 2.64593901135316
Validation loss: 2.6732878188868257

Epoch: 5| Step: 2
Training loss: 2.999971230686843
Validation loss: 2.685233521437992

Epoch: 5| Step: 3
Training loss: 3.266606233647632
Validation loss: 2.684383786352663

Epoch: 5| Step: 4
Training loss: 3.0852253925209823
Validation loss: 2.6892076462897108

Epoch: 5| Step: 5
Training loss: 3.3958819021172455
Validation loss: 2.67834603439023

Epoch: 5| Step: 6
Training loss: 2.821346526651717
Validation loss: 2.6803891765792844

Epoch: 5| Step: 7
Training loss: 2.529862105792035
Validation loss: 2.6695873774918346

Epoch: 5| Step: 8
Training loss: 3.4890586952089646
Validation loss: 2.670357667254201

Epoch: 5| Step: 9
Training loss: 3.3068495727784266
Validation loss: 2.6657805563237664

Epoch: 5| Step: 10
Training loss: 2.9000090171410693
Validation loss: 2.663810708699089

Epoch: 84| Step: 0
Training loss: 2.8605397671417565
Validation loss: 2.6683577480947673

Epoch: 5| Step: 1
Training loss: 2.5411604914027777
Validation loss: 2.6775502363973738

Epoch: 5| Step: 2
Training loss: 3.2878940708703874
Validation loss: 2.6866776099282785

Epoch: 5| Step: 3
Training loss: 2.915429824887365
Validation loss: 2.68636714432526

Epoch: 5| Step: 4
Training loss: 2.6579647139481106
Validation loss: 2.6869889784877

Epoch: 5| Step: 5
Training loss: 2.948261272296626
Validation loss: 2.6778214914396172

Epoch: 5| Step: 6
Training loss: 2.8141542444095213
Validation loss: 2.666411566132985

Epoch: 5| Step: 7
Training loss: 3.2270585757135595
Validation loss: 2.6641980333609108

Epoch: 5| Step: 8
Training loss: 3.480056481396314
Validation loss: 2.660376575737174

Epoch: 5| Step: 9
Training loss: 3.279663865148283
Validation loss: 2.658562141184678

Epoch: 5| Step: 10
Training loss: 2.8449372548456653
Validation loss: 2.656871725306221

Epoch: 85| Step: 0
Training loss: 2.547904713296702
Validation loss: 2.660263962587495

Epoch: 5| Step: 1
Training loss: 3.506948521845664
Validation loss: 2.664285268140334

Epoch: 5| Step: 2
Training loss: 2.5638401899836483
Validation loss: 2.659213597551732

Epoch: 5| Step: 3
Training loss: 3.7273052123233734
Validation loss: 2.671391157684215

Epoch: 5| Step: 4
Training loss: 3.110658313710029
Validation loss: 2.6642850266219664

Epoch: 5| Step: 5
Training loss: 2.9211119609141654
Validation loss: 2.654141514207998

Epoch: 5| Step: 6
Training loss: 2.644678920302368
Validation loss: 2.6522108093588437

Epoch: 5| Step: 7
Training loss: 2.857514490072469
Validation loss: 2.6552095830685243

Epoch: 5| Step: 8
Training loss: 2.791698930088946
Validation loss: 2.6554025908872148

Epoch: 5| Step: 9
Training loss: 2.82256550499156
Validation loss: 2.6500605297083024

Epoch: 5| Step: 10
Training loss: 3.3526310851137637
Validation loss: 2.6527361932500404

Epoch: 86| Step: 0
Training loss: 2.5477220495781596
Validation loss: 2.648814960065226

Epoch: 5| Step: 1
Training loss: 3.2557397189976482
Validation loss: 2.6513452017476187

Epoch: 5| Step: 2
Training loss: 2.570819097527937
Validation loss: 2.6572708388071655

Epoch: 5| Step: 3
Training loss: 3.299851506678064
Validation loss: 2.699763870358311

Epoch: 5| Step: 4
Training loss: 2.7926755097644507
Validation loss: 2.6892179229201836

Epoch: 5| Step: 5
Training loss: 2.6992722766830015
Validation loss: 2.6740440991471717

Epoch: 5| Step: 6
Training loss: 3.243472807401961
Validation loss: 2.6732063653684968

Epoch: 5| Step: 7
Training loss: 2.8561803763353404
Validation loss: 2.6626826322516863

Epoch: 5| Step: 8
Training loss: 3.4399901647205366
Validation loss: 2.6482205420794145

Epoch: 5| Step: 9
Training loss: 3.234667188926879
Validation loss: 2.6387444673780034

Epoch: 5| Step: 10
Training loss: 2.7776699384313526
Validation loss: 2.644439435384631

Epoch: 87| Step: 0
Training loss: 2.8606944557510925
Validation loss: 2.6405961550322603

Epoch: 5| Step: 1
Training loss: 2.730600072843422
Validation loss: 2.6382589888778094

Epoch: 5| Step: 2
Training loss: 3.1920365606427477
Validation loss: 2.6418630230878515

Epoch: 5| Step: 3
Training loss: 2.9596446896279245
Validation loss: 2.641249972331996

Epoch: 5| Step: 4
Training loss: 3.0376867794176268
Validation loss: 2.646977968081584

Epoch: 5| Step: 5
Training loss: 3.141458581025124
Validation loss: 2.6512895703467536

Epoch: 5| Step: 6
Training loss: 2.718796565216126
Validation loss: 2.663688087971354

Epoch: 5| Step: 7
Training loss: 2.9575101396607737
Validation loss: 2.6859808441673363

Epoch: 5| Step: 8
Training loss: 3.137819166021577
Validation loss: 2.64407666909927

Epoch: 5| Step: 9
Training loss: 3.096820425097376
Validation loss: 2.634755863793822

Epoch: 5| Step: 10
Training loss: 2.9416411408639798
Validation loss: 2.6314860509420144

Epoch: 88| Step: 0
Training loss: 2.981824973779543
Validation loss: 2.636435665853974

Epoch: 5| Step: 1
Training loss: 3.2665221519682546
Validation loss: 2.637849715678555

Epoch: 5| Step: 2
Training loss: 3.3013714685882287
Validation loss: 2.6416936174345964

Epoch: 5| Step: 3
Training loss: 3.007510955359339
Validation loss: 2.6451269564487534

Epoch: 5| Step: 4
Training loss: 2.9661957041918874
Validation loss: 2.6406345434004863

Epoch: 5| Step: 5
Training loss: 3.202214106857508
Validation loss: 2.640023444714238

Epoch: 5| Step: 6
Training loss: 2.8191471809648205
Validation loss: 2.6364133474907065

Epoch: 5| Step: 7
Training loss: 3.1067984942952567
Validation loss: 2.6346813901074206

Epoch: 5| Step: 8
Training loss: 2.5788676723864077
Validation loss: 2.6293999273419026

Epoch: 5| Step: 9
Training loss: 3.0397946767735675
Validation loss: 2.629214942662738

Epoch: 5| Step: 10
Training loss: 2.4311573942537668
Validation loss: 2.635423646569306

Epoch: 89| Step: 0
Training loss: 3.0295125170063653
Validation loss: 2.6316431369303825

Epoch: 5| Step: 1
Training loss: 2.443699508886861
Validation loss: 2.6419663221229794

Epoch: 5| Step: 2
Training loss: 3.1379927046954204
Validation loss: 2.6464111366425906

Epoch: 5| Step: 3
Training loss: 2.916556510661642
Validation loss: 2.667500302798474

Epoch: 5| Step: 4
Training loss: 2.9510624863392523
Validation loss: 2.6800129723667303

Epoch: 5| Step: 5
Training loss: 3.1345074793923686
Validation loss: 2.643556410781136

Epoch: 5| Step: 6
Training loss: 2.8763893750841816
Validation loss: 2.627209773870663

Epoch: 5| Step: 7
Training loss: 3.184557734853267
Validation loss: 2.6231749890619107

Epoch: 5| Step: 8
Training loss: 2.906624226420698
Validation loss: 2.623931523746225

Epoch: 5| Step: 9
Training loss: 3.2982458365234892
Validation loss: 2.6221852561639793

Epoch: 5| Step: 10
Training loss: 2.6694332811499497
Validation loss: 2.625428392853731

Epoch: 90| Step: 0
Training loss: 3.3226825468205354
Validation loss: 2.620980497570567

Epoch: 5| Step: 1
Training loss: 2.649250007159262
Validation loss: 2.6238412697230324

Epoch: 5| Step: 2
Training loss: 2.871636454872914
Validation loss: 2.6220249851849475

Epoch: 5| Step: 3
Training loss: 2.8503045638795443
Validation loss: 2.620737257479062

Epoch: 5| Step: 4
Training loss: 2.3369075330299505
Validation loss: 2.618468213778041

Epoch: 5| Step: 5
Training loss: 3.13571435945103
Validation loss: 2.6193200523176676

Epoch: 5| Step: 6
Training loss: 3.448721446976466
Validation loss: 2.620252342496532

Epoch: 5| Step: 7
Training loss: 2.4317179839916085
Validation loss: 2.618915817967345

Epoch: 5| Step: 8
Training loss: 3.4431927792671955
Validation loss: 2.6274776134144364

Epoch: 5| Step: 9
Training loss: 2.7476480136256547
Validation loss: 2.6467082177752292

Epoch: 5| Step: 10
Training loss: 3.2107162213709897
Validation loss: 2.6570244332766855

Epoch: 91| Step: 0
Training loss: 3.2516193757039162
Validation loss: 2.663794534623664

Epoch: 5| Step: 1
Training loss: 3.488107503940412
Validation loss: 2.642085760206067

Epoch: 5| Step: 2
Training loss: 3.1500518673456432
Validation loss: 2.619255912559362

Epoch: 5| Step: 3
Training loss: 3.0508829996136435
Validation loss: 2.6158709605621615

Epoch: 5| Step: 4
Training loss: 3.3197497799811013
Validation loss: 2.6187393820666784

Epoch: 5| Step: 5
Training loss: 2.6378260117216286
Validation loss: 2.618986171103581

Epoch: 5| Step: 6
Training loss: 2.9529431806834223
Validation loss: 2.6213472816290135

Epoch: 5| Step: 7
Training loss: 2.6593200893089843
Validation loss: 2.6167432143149347

Epoch: 5| Step: 8
Training loss: 1.9646623349478018
Validation loss: 2.6165309728433948

Epoch: 5| Step: 9
Training loss: 3.2449473205428383
Validation loss: 2.6142123771838883

Epoch: 5| Step: 10
Training loss: 2.6076772500467493
Validation loss: 2.6114400746278124

Epoch: 92| Step: 0
Training loss: 2.8590357845024306
Validation loss: 2.6278828067124853

Epoch: 5| Step: 1
Training loss: 2.656118053076226
Validation loss: 2.6165498258193014

Epoch: 5| Step: 2
Training loss: 3.3797744605754256
Validation loss: 2.6142247883250596

Epoch: 5| Step: 3
Training loss: 2.9785807818180654
Validation loss: 2.615798945744365

Epoch: 5| Step: 4
Training loss: 3.376147463673968
Validation loss: 2.6189673288138993

Epoch: 5| Step: 5
Training loss: 2.7282350323522624
Validation loss: 2.6183996492244184

Epoch: 5| Step: 6
Training loss: 3.1433520268045867
Validation loss: 2.620501754707968

Epoch: 5| Step: 7
Training loss: 2.475355269239924
Validation loss: 2.621851786755236

Epoch: 5| Step: 8
Training loss: 2.865558379718634
Validation loss: 2.644932143260189

Epoch: 5| Step: 9
Training loss: 3.4570911122112307
Validation loss: 2.6792701011761104

Epoch: 5| Step: 10
Training loss: 2.297644142552202
Validation loss: 2.669765330125085

Epoch: 93| Step: 0
Training loss: 3.1000453207333254
Validation loss: 2.688877870484347

Epoch: 5| Step: 1
Training loss: 3.3817063564818466
Validation loss: 2.68483023643279

Epoch: 5| Step: 2
Training loss: 2.8421993848857303
Validation loss: 2.6306133441315356

Epoch: 5| Step: 3
Training loss: 3.005562076651628
Validation loss: 2.6148726345711464

Epoch: 5| Step: 4
Training loss: 2.932163992361373
Validation loss: 2.61561636786408

Epoch: 5| Step: 5
Training loss: 2.750996929143414
Validation loss: 2.616505120080063

Epoch: 5| Step: 6
Training loss: 2.7293153872748626
Validation loss: 2.616927534724259

Epoch: 5| Step: 7
Training loss: 2.805535403474083
Validation loss: 2.6158204128965528

Epoch: 5| Step: 8
Training loss: 2.8447885817561445
Validation loss: 2.6099433753949937

Epoch: 5| Step: 9
Training loss: 2.8286577428994204
Validation loss: 2.6200569850426665

Epoch: 5| Step: 10
Training loss: 3.545738004366012
Validation loss: 2.6553822305754418

Epoch: 94| Step: 0
Training loss: 2.548606798640133
Validation loss: 2.6633814782453977

Epoch: 5| Step: 1
Training loss: 2.7138902046185676
Validation loss: 2.639979849255568

Epoch: 5| Step: 2
Training loss: 2.596230481312699
Validation loss: 2.615694361421629

Epoch: 5| Step: 3
Training loss: 2.8281803020318175
Validation loss: 2.6175771458407473

Epoch: 5| Step: 4
Training loss: 3.042040936858582
Validation loss: 2.607775223252242

Epoch: 5| Step: 5
Training loss: 3.0902495955612084
Validation loss: 2.607448382179709

Epoch: 5| Step: 6
Training loss: 3.214640540262719
Validation loss: 2.6070832849993204

Epoch: 5| Step: 7
Training loss: 2.9187853792647998
Validation loss: 2.6093186447368395

Epoch: 5| Step: 8
Training loss: 3.2244549904366107
Validation loss: 2.608071672562159

Epoch: 5| Step: 9
Training loss: 3.341959964377703
Validation loss: 2.6079887769053594

Epoch: 5| Step: 10
Training loss: 2.8951296786185705
Validation loss: 2.6072577417736564

Epoch: 95| Step: 0
Training loss: 3.1700565029848757
Validation loss: 2.603953034200844

Epoch: 5| Step: 1
Training loss: 2.942545514398899
Validation loss: 2.604556039229063

Epoch: 5| Step: 2
Training loss: 2.606950558701706
Validation loss: 2.6068318002460935

Epoch: 5| Step: 3
Training loss: 2.7801811650476735
Validation loss: 2.605610284824427

Epoch: 5| Step: 4
Training loss: 2.8385865000879305
Validation loss: 2.604009530197522

Epoch: 5| Step: 5
Training loss: 2.6436309859810354
Validation loss: 2.6060007300687795

Epoch: 5| Step: 6
Training loss: 3.1354372820171177
Validation loss: 2.6098818803394614

Epoch: 5| Step: 7
Training loss: 2.5875145289800994
Validation loss: 2.620864452475524

Epoch: 5| Step: 8
Training loss: 3.221835537066607
Validation loss: 2.6478663540227387

Epoch: 5| Step: 9
Training loss: 3.5274948814349547
Validation loss: 2.6813613111236356

Epoch: 5| Step: 10
Training loss: 2.8969201077238336
Validation loss: 2.6126522974620374

Epoch: 96| Step: 0
Training loss: 2.444355055109018
Validation loss: 2.6017322691213454

Epoch: 5| Step: 1
Training loss: 2.8950117487166644
Validation loss: 2.6029186252505396

Epoch: 5| Step: 2
Training loss: 2.4010787486580027
Validation loss: 2.611565188312645

Epoch: 5| Step: 3
Training loss: 2.8000987989161037
Validation loss: 2.6136519659026485

Epoch: 5| Step: 4
Training loss: 3.5005419175365784
Validation loss: 2.614769983895328

Epoch: 5| Step: 5
Training loss: 2.8327770435031137
Validation loss: 2.606929439402333

Epoch: 5| Step: 6
Training loss: 3.1635063530327723
Validation loss: 2.605897602021878

Epoch: 5| Step: 7
Training loss: 3.2596484529476792
Validation loss: 2.6107391265762647

Epoch: 5| Step: 8
Training loss: 3.0296749466886332
Validation loss: 2.618164957465741

Epoch: 5| Step: 9
Training loss: 3.0991830610754714
Validation loss: 2.6386192603568377

Epoch: 5| Step: 10
Training loss: 3.09051760958481
Validation loss: 2.691609280418119

Epoch: 97| Step: 0
Training loss: 3.3990245092888185
Validation loss: 2.6785578263968235

Epoch: 5| Step: 1
Training loss: 2.868466790873947
Validation loss: 2.604301739214822

Epoch: 5| Step: 2
Training loss: 2.422107217792227
Validation loss: 2.6006960344989927

Epoch: 5| Step: 3
Training loss: 3.4208617778777217
Validation loss: 2.60043239760609

Epoch: 5| Step: 4
Training loss: 2.499080584261356
Validation loss: 2.617543158672484

Epoch: 5| Step: 5
Training loss: 2.9486964691723645
Validation loss: 2.62246658710886

Epoch: 5| Step: 6
Training loss: 3.0272256151345505
Validation loss: 2.626191384029756

Epoch: 5| Step: 7
Training loss: 2.8627719400158287
Validation loss: 2.632983498436422

Epoch: 5| Step: 8
Training loss: 3.2606206633071184
Validation loss: 2.6333659880973155

Epoch: 5| Step: 9
Training loss: 3.070038683768728
Validation loss: 2.6321433983101956

Epoch: 5| Step: 10
Training loss: 2.841797881765286
Validation loss: 2.6372513369674433

Epoch: 98| Step: 0
Training loss: 3.5850265110371033
Validation loss: 2.6428802426430513

Epoch: 5| Step: 1
Training loss: 2.898489815376081
Validation loss: 2.6354274695221744

Epoch: 5| Step: 2
Training loss: 2.5571189765089093
Validation loss: 2.6257968148335373

Epoch: 5| Step: 3
Training loss: 2.828921211243146
Validation loss: 2.622189506106574

Epoch: 5| Step: 4
Training loss: 3.112381291711007
Validation loss: 2.6318889351634684

Epoch: 5| Step: 5
Training loss: 3.2503031075789988
Validation loss: 2.6853733925668535

Epoch: 5| Step: 6
Training loss: 2.8391129131806405
Validation loss: 2.6641395352498183

Epoch: 5| Step: 7
Training loss: 3.0939821098417015
Validation loss: 2.6455700395879433

Epoch: 5| Step: 8
Training loss: 2.918994483265592
Validation loss: 2.63010975252835

Epoch: 5| Step: 9
Training loss: 3.098846707083373
Validation loss: 2.6162138414496385

Epoch: 5| Step: 10
Training loss: 2.0533233871879624
Validation loss: 2.615119437560583

Epoch: 99| Step: 0
Training loss: 2.9653573979675136
Validation loss: 2.6228107761542243

Epoch: 5| Step: 1
Training loss: 3.0321177390898946
Validation loss: 2.5980880147790537

Epoch: 5| Step: 2
Training loss: 3.266107842920891
Validation loss: 2.5985142293472565

Epoch: 5| Step: 3
Training loss: 2.6734056159859936
Validation loss: 2.597223238337669

Epoch: 5| Step: 4
Training loss: 3.467196417337634
Validation loss: 2.5995367647183736

Epoch: 5| Step: 5
Training loss: 2.8594115208028894
Validation loss: 2.5983581004383507

Epoch: 5| Step: 6
Training loss: 3.0562371813421425
Validation loss: 2.6070122831904636

Epoch: 5| Step: 7
Training loss: 3.226323227404221
Validation loss: 2.5996849673001607

Epoch: 5| Step: 8
Training loss: 3.1534499032193706
Validation loss: 2.607214409648799

Epoch: 5| Step: 9
Training loss: 2.3456747671123606
Validation loss: 2.6107009143164635

Epoch: 5| Step: 10
Training loss: 1.855211485043104
Validation loss: 2.628093008652624

Epoch: 100| Step: 0
Training loss: 2.0446711899382204
Validation loss: 2.6455074365069176

Epoch: 5| Step: 1
Training loss: 2.505625308753528
Validation loss: 2.6577896983271496

Epoch: 5| Step: 2
Training loss: 3.413990988953581
Validation loss: 2.6558223585216987

Epoch: 5| Step: 3
Training loss: 3.2162188605332966
Validation loss: 2.636670839276236

Epoch: 5| Step: 4
Training loss: 3.418994963132055
Validation loss: 2.6123353855927287

Epoch: 5| Step: 5
Training loss: 3.148753110150372
Validation loss: 2.590045311900793

Epoch: 5| Step: 6
Training loss: 3.148917717671196
Validation loss: 2.5878333560785194

Epoch: 5| Step: 7
Training loss: 2.8470346115039704
Validation loss: 2.5883316295186516

Epoch: 5| Step: 8
Training loss: 2.9016888009121287
Validation loss: 2.5936412212730966

Epoch: 5| Step: 9
Training loss: 2.7617848778217224
Validation loss: 2.5913186051825865

Epoch: 5| Step: 10
Training loss: 2.7253869263212596
Validation loss: 2.5901804128445653

Epoch: 101| Step: 0
Training loss: 3.07877463054833
Validation loss: 2.5883377386727484

Epoch: 5| Step: 1
Training loss: 3.1201002236921473
Validation loss: 2.5886345501262054

Epoch: 5| Step: 2
Training loss: 2.843941315304347
Validation loss: 2.587430973726441

Epoch: 5| Step: 3
Training loss: 3.4361351771648203
Validation loss: 2.5884740498804164

Epoch: 5| Step: 4
Training loss: 2.870902251000937
Validation loss: 2.580086340312096

Epoch: 5| Step: 5
Training loss: 2.675807178677978
Validation loss: 2.586074643547104

Epoch: 5| Step: 6
Training loss: 3.2324047629834065
Validation loss: 2.589210829982259

Epoch: 5| Step: 7
Training loss: 2.858951391307891
Validation loss: 2.59403795387671

Epoch: 5| Step: 8
Training loss: 2.924742245525029
Validation loss: 2.595678045536744

Epoch: 5| Step: 9
Training loss: 2.617780111603631
Validation loss: 2.590896920162182

Epoch: 5| Step: 10
Training loss: 2.502792896427842
Validation loss: 2.580159976877414

Epoch: 102| Step: 0
Training loss: 2.5536123457306643
Validation loss: 2.580880238544722

Epoch: 5| Step: 1
Training loss: 2.894509669337989
Validation loss: 2.5784422638530855

Epoch: 5| Step: 2
Training loss: 2.9812791355076893
Validation loss: 2.580308736001666

Epoch: 5| Step: 3
Training loss: 2.935660740109127
Validation loss: 2.58051832275783

Epoch: 5| Step: 4
Training loss: 2.909059376708278
Validation loss: 2.5807110934077215

Epoch: 5| Step: 5
Training loss: 2.739816537269959
Validation loss: 2.5862326103382385

Epoch: 5| Step: 6
Training loss: 3.028728104597636
Validation loss: 2.5834162771886757

Epoch: 5| Step: 7
Training loss: 3.196384837588907
Validation loss: 2.5817064841795725

Epoch: 5| Step: 8
Training loss: 2.687600777089432
Validation loss: 2.5820292741730935

Epoch: 5| Step: 9
Training loss: 3.3643293885256047
Validation loss: 2.575222327099193

Epoch: 5| Step: 10
Training loss: 2.981081118488688
Validation loss: 2.579203966869547

Epoch: 103| Step: 0
Training loss: 2.5912465342725293
Validation loss: 2.5858364300478316

Epoch: 5| Step: 1
Training loss: 2.9514127742823058
Validation loss: 2.5968883962594074

Epoch: 5| Step: 2
Training loss: 2.8123665672015425
Validation loss: 2.619277995402018

Epoch: 5| Step: 3
Training loss: 2.8572251205863135
Validation loss: 2.681196954023978

Epoch: 5| Step: 4
Training loss: 2.665890958337495
Validation loss: 2.7687838769414883

Epoch: 5| Step: 5
Training loss: 2.763026250365925
Validation loss: 2.610319265760722

Epoch: 5| Step: 6
Training loss: 3.3510600960584127
Validation loss: 2.584464472239811

Epoch: 5| Step: 7
Training loss: 2.998954590802487
Validation loss: 2.601401334918944

Epoch: 5| Step: 8
Training loss: 3.4234985958969517
Validation loss: 2.659940410800538

Epoch: 5| Step: 9
Training loss: 3.4523973345563594
Validation loss: 2.6930064790433303

Epoch: 5| Step: 10
Training loss: 2.411025423831186
Validation loss: 2.6305227180511004

Epoch: 104| Step: 0
Training loss: 2.9004004892509028
Validation loss: 2.6083821045989946

Epoch: 5| Step: 1
Training loss: 3.3083043427882686
Validation loss: 2.597006518613652

Epoch: 5| Step: 2
Training loss: 2.906647357643224
Validation loss: 2.58694948765604

Epoch: 5| Step: 3
Training loss: 3.2111993019316123
Validation loss: 2.5863960250447486

Epoch: 5| Step: 4
Training loss: 2.909309663458929
Validation loss: 2.5919852363243066

Epoch: 5| Step: 5
Training loss: 3.477930789813873
Validation loss: 2.5949276670791925

Epoch: 5| Step: 6
Training loss: 2.5087049565930664
Validation loss: 2.6123773138488655

Epoch: 5| Step: 7
Training loss: 3.030375718343145
Validation loss: 2.66071105860248

Epoch: 5| Step: 8
Training loss: 2.7458353585760107
Validation loss: 2.6103479169218256

Epoch: 5| Step: 9
Training loss: 2.4956071406183256
Validation loss: 2.5846367550391296

Epoch: 5| Step: 10
Training loss: 2.950703915165109
Validation loss: 2.5875463157686904

Epoch: 105| Step: 0
Training loss: 2.271395470805589
Validation loss: 2.5838697917136138

Epoch: 5| Step: 1
Training loss: 2.627227292413467
Validation loss: 2.583702146088972

Epoch: 5| Step: 2
Training loss: 2.987353371569218
Validation loss: 2.584060785506616

Epoch: 5| Step: 3
Training loss: 2.8033699192316264
Validation loss: 2.5845631408794008

Epoch: 5| Step: 4
Training loss: 3.4850040432483746
Validation loss: 2.5867509659468424

Epoch: 5| Step: 5
Training loss: 3.4614833289426445
Validation loss: 2.5931179691464235

Epoch: 5| Step: 6
Training loss: 2.962780059582135
Validation loss: 2.5905806561311113

Epoch: 5| Step: 7
Training loss: 2.8163048333096925
Validation loss: 2.585400159124924

Epoch: 5| Step: 8
Training loss: 2.8094187494420972
Validation loss: 2.5876773495437457

Epoch: 5| Step: 9
Training loss: 3.381507251705216
Validation loss: 2.589890078059706

Epoch: 5| Step: 10
Training loss: 2.472151911255993
Validation loss: 2.587913176580896

Epoch: 106| Step: 0
Training loss: 3.241399830195574
Validation loss: 2.5856081632013868

Epoch: 5| Step: 1
Training loss: 2.8168006229336027
Validation loss: 2.5793705273048997

Epoch: 5| Step: 2
Training loss: 3.31048234634751
Validation loss: 2.5859869772023067

Epoch: 5| Step: 3
Training loss: 2.607233413571838
Validation loss: 2.5848426951259347

Epoch: 5| Step: 4
Training loss: 2.731704366849343
Validation loss: 2.5846279293063543

Epoch: 5| Step: 5
Training loss: 3.505227272621142
Validation loss: 2.5828662540038807

Epoch: 5| Step: 6
Training loss: 3.0769754964691516
Validation loss: 2.583278189661698

Epoch: 5| Step: 7
Training loss: 2.3524478500374872
Validation loss: 2.578260795171632

Epoch: 5| Step: 8
Training loss: 2.3310062066203803
Validation loss: 2.5765098984351313

Epoch: 5| Step: 9
Training loss: 2.71315549322329
Validation loss: 2.574655501668426

Epoch: 5| Step: 10
Training loss: 3.3696284463415314
Validation loss: 2.5744251938574885

Epoch: 107| Step: 0
Training loss: 2.697140900022914
Validation loss: 2.5904897819717

Epoch: 5| Step: 1
Training loss: 2.866826255555264
Validation loss: 2.5892016960692135

Epoch: 5| Step: 2
Training loss: 3.352106223651565
Validation loss: 2.5948364160950543

Epoch: 5| Step: 3
Training loss: 2.7953410284165554
Validation loss: 2.5776452168409616

Epoch: 5| Step: 4
Training loss: 2.2315927536081808
Validation loss: 2.581400632258285

Epoch: 5| Step: 5
Training loss: 3.1137675021677764
Validation loss: 2.5761990500227196

Epoch: 5| Step: 6
Training loss: 2.7726349865013935
Validation loss: 2.6109217607663924

Epoch: 5| Step: 7
Training loss: 3.1798245637112506
Validation loss: 2.6805271619914963

Epoch: 5| Step: 8
Training loss: 3.090853481506463
Validation loss: 2.807069352341741

Epoch: 5| Step: 9
Training loss: 3.564116797060784
Validation loss: 2.6784666641928654

Epoch: 5| Step: 10
Training loss: 2.3146397768881726
Validation loss: 2.5692407132785724

Epoch: 108| Step: 0
Training loss: 2.951122755630275
Validation loss: 2.574038179213346

Epoch: 5| Step: 1
Training loss: 3.1720298391047486
Validation loss: 2.593142758987238

Epoch: 5| Step: 2
Training loss: 2.417951395838369
Validation loss: 2.5994618466277664

Epoch: 5| Step: 3
Training loss: 2.9559053119262346
Validation loss: 2.5877892657734645

Epoch: 5| Step: 4
Training loss: 2.7768748299312946
Validation loss: 2.5854478707171986

Epoch: 5| Step: 5
Training loss: 3.401895662182265
Validation loss: 2.5852444589399766

Epoch: 5| Step: 6
Training loss: 2.9090605241099006
Validation loss: 2.591487385415663

Epoch: 5| Step: 7
Training loss: 2.783278679073172
Validation loss: 2.5878687978742287

Epoch: 5| Step: 8
Training loss: 2.944255770830276
Validation loss: 2.5821025058465086

Epoch: 5| Step: 9
Training loss: 3.1049150081188377
Validation loss: 2.5767798590414106

Epoch: 5| Step: 10
Training loss: 3.005236823323216
Validation loss: 2.5747172247278343

Epoch: 109| Step: 0
Training loss: 3.045394616074368
Validation loss: 2.5732088491447045

Epoch: 5| Step: 1
Training loss: 3.3215687249025105
Validation loss: 2.5707602885247702

Epoch: 5| Step: 2
Training loss: 2.754919333826069
Validation loss: 2.569211560794201

Epoch: 5| Step: 3
Training loss: 2.581650329285315
Validation loss: 2.5686874611178885

Epoch: 5| Step: 4
Training loss: 2.9055860848055803
Validation loss: 2.5703919450137036

Epoch: 5| Step: 5
Training loss: 3.080458477872884
Validation loss: 2.5743869942684627

Epoch: 5| Step: 6
Training loss: 2.958949244325283
Validation loss: 2.573456434133938

Epoch: 5| Step: 7
Training loss: 2.990703164796178
Validation loss: 2.5874753292279444

Epoch: 5| Step: 8
Training loss: 3.3901520148658415
Validation loss: 2.5856146496119106

Epoch: 5| Step: 9
Training loss: 2.5941546021142243
Validation loss: 2.58567497185556

Epoch: 5| Step: 10
Training loss: 2.2290295234871045
Validation loss: 2.5876358007686866

Epoch: 110| Step: 0
Training loss: 2.916875304979595
Validation loss: 2.6055096050867856

Epoch: 5| Step: 1
Training loss: 2.885861818057539
Validation loss: 2.608984819969674

Epoch: 5| Step: 2
Training loss: 2.944745806100898
Validation loss: 2.6190866606995575

Epoch: 5| Step: 3
Training loss: 3.243094370299071
Validation loss: 2.619176576438953

Epoch: 5| Step: 4
Training loss: 2.7218985905812962
Validation loss: 2.620246340039036

Epoch: 5| Step: 5
Training loss: 2.4175995527912084
Validation loss: 2.607393716725611

Epoch: 5| Step: 6
Training loss: 2.901059838357351
Validation loss: 2.589838817411518

Epoch: 5| Step: 7
Training loss: 3.306092885544307
Validation loss: 2.6041421533887013

Epoch: 5| Step: 8
Training loss: 2.827596372653471
Validation loss: 2.624021163069863

Epoch: 5| Step: 9
Training loss: 2.5968350367219664
Validation loss: 2.604780170325522

Epoch: 5| Step: 10
Training loss: 3.2494730889068437
Validation loss: 2.5916499069247534

Epoch: 111| Step: 0
Training loss: 3.4825772835398263
Validation loss: 2.5640500270621644

Epoch: 5| Step: 1
Training loss: 3.2721786809880204
Validation loss: 2.566648910736985

Epoch: 5| Step: 2
Training loss: 2.878521131328276
Validation loss: 2.562648017584103

Epoch: 5| Step: 3
Training loss: 2.7688760560835215
Validation loss: 2.5668434320982354

Epoch: 5| Step: 4
Training loss: 2.8782141589873254
Validation loss: 2.5666082561203334

Epoch: 5| Step: 5
Training loss: 2.9153962956359654
Validation loss: 2.5681299989372985

Epoch: 5| Step: 6
Training loss: 2.6541691427254217
Validation loss: 2.5651798316877383

Epoch: 5| Step: 7
Training loss: 2.4483498913659703
Validation loss: 2.564949808972755

Epoch: 5| Step: 8
Training loss: 2.7822063387734617
Validation loss: 2.5719999530480737

Epoch: 5| Step: 9
Training loss: 2.52084084711978
Validation loss: 2.564099642658857

Epoch: 5| Step: 10
Training loss: 3.563205180728882
Validation loss: 2.5601776918931924

Epoch: 112| Step: 0
Training loss: 2.6417156427538546
Validation loss: 2.5593364124638844

Epoch: 5| Step: 1
Training loss: 2.9859771422464965
Validation loss: 2.556783274535237

Epoch: 5| Step: 2
Training loss: 2.642346966227032
Validation loss: 2.555472052886184

Epoch: 5| Step: 3
Training loss: 2.714195909663699
Validation loss: 2.55492035262847

Epoch: 5| Step: 4
Training loss: 3.309928327631524
Validation loss: 2.5678534832499382

Epoch: 5| Step: 5
Training loss: 2.2241783896811773
Validation loss: 2.580198273817221

Epoch: 5| Step: 6
Training loss: 2.8068503538386214
Validation loss: 2.586237622166812

Epoch: 5| Step: 7
Training loss: 3.2500539921897356
Validation loss: 2.6219452381045447

Epoch: 5| Step: 8
Training loss: 3.138472545397345
Validation loss: 2.6454350248635836

Epoch: 5| Step: 9
Training loss: 2.843243061196405
Validation loss: 2.619052347588609

Epoch: 5| Step: 10
Training loss: 3.421904960048281
Validation loss: 2.571934647160573

Epoch: 113| Step: 0
Training loss: 3.235522080616245
Validation loss: 2.549841606485635

Epoch: 5| Step: 1
Training loss: 2.5543054884190584
Validation loss: 2.5603846060409046

Epoch: 5| Step: 2
Training loss: 3.268491226368917
Validation loss: 2.5713738541283924

Epoch: 5| Step: 3
Training loss: 2.8423376244003005
Validation loss: 2.5908218403018144

Epoch: 5| Step: 4
Training loss: 2.995215892875517
Validation loss: 2.6000547367404896

Epoch: 5| Step: 5
Training loss: 3.044681953144003
Validation loss: 2.6055007841340028

Epoch: 5| Step: 6
Training loss: 3.37903382165244
Validation loss: 2.578775939602571

Epoch: 5| Step: 7
Training loss: 2.6947403894910082
Validation loss: 2.5629509379755007

Epoch: 5| Step: 8
Training loss: 3.110536138067382
Validation loss: 2.5612663572988565

Epoch: 5| Step: 9
Training loss: 2.5365735810486503
Validation loss: 2.5599762228340954

Epoch: 5| Step: 10
Training loss: 2.676603895269229
Validation loss: 2.5706553657654845

Epoch: 114| Step: 0
Training loss: 2.5912410137132946
Validation loss: 2.5976497966184415

Epoch: 5| Step: 1
Training loss: 3.198000945100054
Validation loss: 2.666709084968161

Epoch: 5| Step: 2
Training loss: 3.5097783958274893
Validation loss: 2.703418959207132

Epoch: 5| Step: 3
Training loss: 3.114791676028847
Validation loss: 2.633168823944266

Epoch: 5| Step: 4
Training loss: 2.8562828813325476
Validation loss: 2.6005096852571885

Epoch: 5| Step: 5
Training loss: 2.6543696311427523
Validation loss: 2.5792061854003454

Epoch: 5| Step: 6
Training loss: 3.051136968098237
Validation loss: 2.569011963759006

Epoch: 5| Step: 7
Training loss: 2.8435596779654335
Validation loss: 2.5604188823454233

Epoch: 5| Step: 8
Training loss: 2.3038670000656936
Validation loss: 2.558736148376354

Epoch: 5| Step: 9
Training loss: 2.641894785741749
Validation loss: 2.554059190728342

Epoch: 5| Step: 10
Training loss: 3.341947408347949
Validation loss: 2.5674247179875618

Epoch: 115| Step: 0
Training loss: 3.1212356783378286
Validation loss: 2.554071271852313

Epoch: 5| Step: 1
Training loss: 3.1721759521827355
Validation loss: 2.5513410006364565

Epoch: 5| Step: 2
Training loss: 2.8912771778008537
Validation loss: 2.5552225477411534

Epoch: 5| Step: 3
Training loss: 3.128236544179927
Validation loss: 2.56453110709924

Epoch: 5| Step: 4
Training loss: 2.7836559047820595
Validation loss: 2.558629648419724

Epoch: 5| Step: 5
Training loss: 2.2865372096007253
Validation loss: 2.560595884675628

Epoch: 5| Step: 6
Training loss: 2.6833611488875078
Validation loss: 2.5551859733830216

Epoch: 5| Step: 7
Training loss: 3.0309273459581725
Validation loss: 2.572143562754494

Epoch: 5| Step: 8
Training loss: 2.1594532931718216
Validation loss: 2.564806320732291

Epoch: 5| Step: 9
Training loss: 3.4962714634912633
Validation loss: 2.568497301416831

Epoch: 5| Step: 10
Training loss: 2.93255800129669
Validation loss: 2.5672995956220475

Epoch: 116| Step: 0
Training loss: 2.5199415242510157
Validation loss: 2.572810292686493

Epoch: 5| Step: 1
Training loss: 2.924087421180171
Validation loss: 2.5663174232859745

Epoch: 5| Step: 2
Training loss: 2.897528904399584
Validation loss: 2.5778573154212063

Epoch: 5| Step: 3
Training loss: 2.9883422047500567
Validation loss: 2.5837338408687534

Epoch: 5| Step: 4
Training loss: 2.9678929748260754
Validation loss: 2.587450974047372

Epoch: 5| Step: 5
Training loss: 2.6350621423505505
Validation loss: 2.5770363148216124

Epoch: 5| Step: 6
Training loss: 3.3616116906737625
Validation loss: 2.572601925508621

Epoch: 5| Step: 7
Training loss: 3.0596501071824123
Validation loss: 2.5647250304061187

Epoch: 5| Step: 8
Training loss: 2.637351812023436
Validation loss: 2.552058485528369

Epoch: 5| Step: 9
Training loss: 3.1721523520692965
Validation loss: 2.549988561271219

Epoch: 5| Step: 10
Training loss: 2.509248886644801
Validation loss: 2.5430335517087976

Epoch: 117| Step: 0
Training loss: 3.175548061616795
Validation loss: 2.54199898892504

Epoch: 5| Step: 1
Training loss: 2.4981351572860513
Validation loss: 2.545236066860149

Epoch: 5| Step: 2
Training loss: 3.235152146595442
Validation loss: 2.546637405173066

Epoch: 5| Step: 3
Training loss: 3.0581380180613507
Validation loss: 2.5518176612083123

Epoch: 5| Step: 4
Training loss: 2.9861762717380085
Validation loss: 2.564677925898114

Epoch: 5| Step: 5
Training loss: 2.4024914207662573
Validation loss: 2.603144360778441

Epoch: 5| Step: 6
Training loss: 2.7872444446237026
Validation loss: 2.6364628838496746

Epoch: 5| Step: 7
Training loss: 2.7076474323797237
Validation loss: 2.687549665010746

Epoch: 5| Step: 8
Training loss: 3.011632935405985
Validation loss: 2.677869584014603

Epoch: 5| Step: 9
Training loss: 2.910911677067343
Validation loss: 2.6205535180824207

Epoch: 5| Step: 10
Training loss: 3.2700072458169434
Validation loss: 2.5660872063268045

Epoch: 118| Step: 0
Training loss: 2.848552798199187
Validation loss: 2.5487390839818227

Epoch: 5| Step: 1
Training loss: 2.9239081994191216
Validation loss: 2.5385807420240827

Epoch: 5| Step: 2
Training loss: 2.8430067495399456
Validation loss: 2.537339616442551

Epoch: 5| Step: 3
Training loss: 2.846108600788183
Validation loss: 2.5391290693493724

Epoch: 5| Step: 4
Training loss: 2.7256839943676705
Validation loss: 2.539479481271427

Epoch: 5| Step: 5
Training loss: 2.7184751525158717
Validation loss: 2.5521106516765757

Epoch: 5| Step: 6
Training loss: 2.8879495972543805
Validation loss: 2.549112554633282

Epoch: 5| Step: 7
Training loss: 2.8804809735594654
Validation loss: 2.554589634350719

Epoch: 5| Step: 8
Training loss: 3.1968477100687904
Validation loss: 2.5616809117145185

Epoch: 5| Step: 9
Training loss: 3.134183436251419
Validation loss: 2.5677768700042196

Epoch: 5| Step: 10
Training loss: 3.031414538764859
Validation loss: 2.5804813151298456

Epoch: 119| Step: 0
Training loss: 2.604530634558745
Validation loss: 2.586898797038561

Epoch: 5| Step: 1
Training loss: 2.903653533423553
Validation loss: 2.5965320183409943

Epoch: 5| Step: 2
Training loss: 2.9922396105020925
Validation loss: 2.6125108723257937

Epoch: 5| Step: 3
Training loss: 3.105863035111351
Validation loss: 2.587744013633974

Epoch: 5| Step: 4
Training loss: 3.2464348238570504
Validation loss: 2.554338682074325

Epoch: 5| Step: 5
Training loss: 2.7221354310695545
Validation loss: 2.545277244144269

Epoch: 5| Step: 6
Training loss: 2.8907064890329672
Validation loss: 2.537006583140516

Epoch: 5| Step: 7
Training loss: 3.5511767143037782
Validation loss: 2.536413177481118

Epoch: 5| Step: 8
Training loss: 2.7111823331444693
Validation loss: 2.5441030172253387

Epoch: 5| Step: 9
Training loss: 2.4015274273626357
Validation loss: 2.5463810802956486

Epoch: 5| Step: 10
Training loss: 2.691484115205052
Validation loss: 2.548769150572145

Epoch: 120| Step: 0
Training loss: 2.8625239142206067
Validation loss: 2.550515597707246

Epoch: 5| Step: 1
Training loss: 2.603195456917145
Validation loss: 2.5413732693879045

Epoch: 5| Step: 2
Training loss: 2.890532950920374
Validation loss: 2.538316944802432

Epoch: 5| Step: 3
Training loss: 2.4123584448836706
Validation loss: 2.539809618912424

Epoch: 5| Step: 4
Training loss: 2.5324321859003613
Validation loss: 2.5292198155160133

Epoch: 5| Step: 5
Training loss: 2.8800841448995307
Validation loss: 2.537874016283038

Epoch: 5| Step: 6
Training loss: 3.292388177014079
Validation loss: 2.539719534929604

Epoch: 5| Step: 7
Training loss: 2.9796381401690537
Validation loss: 2.5418142880707006

Epoch: 5| Step: 8
Training loss: 3.0362509148990138
Validation loss: 2.554701910285288

Epoch: 5| Step: 9
Training loss: 3.1782413727676158
Validation loss: 2.568190821704947

Epoch: 5| Step: 10
Training loss: 3.1455293386410283
Validation loss: 2.571522245212225

Epoch: 121| Step: 0
Training loss: 2.807530059789404
Validation loss: 2.5717865260898374

Epoch: 5| Step: 1
Training loss: 2.9605116726697216
Validation loss: 2.55511181273505

Epoch: 5| Step: 2
Training loss: 2.9052604713471166
Validation loss: 2.5405630206579026

Epoch: 5| Step: 3
Training loss: 2.8814330069786553
Validation loss: 2.5332048444136226

Epoch: 5| Step: 4
Training loss: 2.4714430594393684
Validation loss: 2.5276990346202983

Epoch: 5| Step: 5
Training loss: 2.8219055579675905
Validation loss: 2.5272121311169324

Epoch: 5| Step: 6
Training loss: 2.6181669765229962
Validation loss: 2.5252967151266312

Epoch: 5| Step: 7
Training loss: 3.1092175007712233
Validation loss: 2.5291809250567763

Epoch: 5| Step: 8
Training loss: 3.122520989377263
Validation loss: 2.528242385686123

Epoch: 5| Step: 9
Training loss: 3.288548517728542
Validation loss: 2.5436030950528217

Epoch: 5| Step: 10
Training loss: 2.739605418842675
Validation loss: 2.5366443300440817

Epoch: 122| Step: 0
Training loss: 2.857488958649484
Validation loss: 2.5669644909991547

Epoch: 5| Step: 1
Training loss: 3.0207086120816093
Validation loss: 2.5798477577131047

Epoch: 5| Step: 2
Training loss: 2.4769139566950744
Validation loss: 2.601044736571231

Epoch: 5| Step: 3
Training loss: 2.8695296613905383
Validation loss: 2.5774680734147446

Epoch: 5| Step: 4
Training loss: 3.112543533204596
Validation loss: 2.5760887599244833

Epoch: 5| Step: 5
Training loss: 2.732159834451936
Validation loss: 2.544066599425011

Epoch: 5| Step: 6
Training loss: 2.8492152756632403
Validation loss: 2.527971448318851

Epoch: 5| Step: 7
Training loss: 2.865142175898144
Validation loss: 2.519929242876678

Epoch: 5| Step: 8
Training loss: 3.4394622750623602
Validation loss: 2.523735631984851

Epoch: 5| Step: 9
Training loss: 2.605734015234132
Validation loss: 2.5240995427014163

Epoch: 5| Step: 10
Training loss: 2.9602831114875974
Validation loss: 2.526917233759729

Epoch: 123| Step: 0
Training loss: 2.73531390827796
Validation loss: 2.530055340570985

Epoch: 5| Step: 1
Training loss: 2.3994458591961143
Validation loss: 2.527123935366765

Epoch: 5| Step: 2
Training loss: 2.42971046167054
Validation loss: 2.5206312757759197

Epoch: 5| Step: 3
Training loss: 2.88639431215559
Validation loss: 2.520889038213534

Epoch: 5| Step: 4
Training loss: 3.234599672337089
Validation loss: 2.5213375138223353

Epoch: 5| Step: 5
Training loss: 3.2552751132473037
Validation loss: 2.523375562952048

Epoch: 5| Step: 6
Training loss: 3.2304296341249588
Validation loss: 2.532262491005218

Epoch: 5| Step: 7
Training loss: 3.148685265724075
Validation loss: 2.5473252399315567

Epoch: 5| Step: 8
Training loss: 2.5924015446565742
Validation loss: 2.5650844531782413

Epoch: 5| Step: 9
Training loss: 2.646079034485626
Validation loss: 2.5996705884242766

Epoch: 5| Step: 10
Training loss: 3.114722020220204
Validation loss: 2.6264870597320824

Epoch: 124| Step: 0
Training loss: 2.5652543128876752
Validation loss: 2.62889086366193

Epoch: 5| Step: 1
Training loss: 3.114517024088159
Validation loss: 2.6082009654966622

Epoch: 5| Step: 2
Training loss: 3.056748575370134
Validation loss: 2.5882164046852534

Epoch: 5| Step: 3
Training loss: 3.3607790829376936
Validation loss: 2.540662140003345

Epoch: 5| Step: 4
Training loss: 2.8395626553412057
Validation loss: 2.5221460643635902

Epoch: 5| Step: 5
Training loss: 2.6935503963148326
Validation loss: 2.5236787133717713

Epoch: 5| Step: 6
Training loss: 2.102906658747666
Validation loss: 2.525713540625947

Epoch: 5| Step: 7
Training loss: 3.1307963212030256
Validation loss: 2.530713746553518

Epoch: 5| Step: 8
Training loss: 2.666647543441233
Validation loss: 2.5324163561481843

Epoch: 5| Step: 9
Training loss: 3.0654584646924974
Validation loss: 2.534608637033389

Epoch: 5| Step: 10
Training loss: 3.0318069732841493
Validation loss: 2.5406590210455176

Epoch: 125| Step: 0
Training loss: 3.0721901934676614
Validation loss: 2.5416208297036476

Epoch: 5| Step: 1
Training loss: 3.518855259677785
Validation loss: 2.5519223900566805

Epoch: 5| Step: 2
Training loss: 2.734968371722739
Validation loss: 2.536893996993723

Epoch: 5| Step: 3
Training loss: 2.819815805926303
Validation loss: 2.5406137881587654

Epoch: 5| Step: 4
Training loss: 3.1036067346699663
Validation loss: 2.5504551475084427

Epoch: 5| Step: 5
Training loss: 2.7389818892338047
Validation loss: 2.574992191945213

Epoch: 5| Step: 6
Training loss: 2.950081038574241
Validation loss: 2.6049396649052263

Epoch: 5| Step: 7
Training loss: 2.921468941119481
Validation loss: 2.6106178389692687

Epoch: 5| Step: 8
Training loss: 2.6884513767890406
Validation loss: 2.6135061061750937

Epoch: 5| Step: 9
Training loss: 2.2538986338151217
Validation loss: 2.5605001461825356

Epoch: 5| Step: 10
Training loss: 2.985386542207974
Validation loss: 2.548001435162102

Testing loss: 2.786660236399896
