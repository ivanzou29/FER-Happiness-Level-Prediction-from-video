Epoch: 1| Step: 0
Training loss: 6.246897117953434
Validation loss: 5.7404355224065515

Epoch: 5| Step: 1
Training loss: 6.050808043940838
Validation loss: 5.719820636596399

Epoch: 5| Step: 2
Training loss: 5.896956948912228
Validation loss: 5.698775005560085

Epoch: 5| Step: 3
Training loss: 5.1393173085012895
Validation loss: 5.67544912129799

Epoch: 5| Step: 4
Training loss: 5.990714517560339
Validation loss: 5.6478042180587495

Epoch: 5| Step: 5
Training loss: 5.36940118928263
Validation loss: 5.613832672613196

Epoch: 5| Step: 6
Training loss: 5.8953602020250715
Validation loss: 5.578212615213452

Epoch: 5| Step: 7
Training loss: 5.587572149369891
Validation loss: 5.535789246115647

Epoch: 5| Step: 8
Training loss: 6.0909154314813
Validation loss: 5.487637184691865

Epoch: 5| Step: 9
Training loss: 5.502134949127755
Validation loss: 5.432364647357296

Epoch: 5| Step: 10
Training loss: 3.568980162458796
Validation loss: 5.373518781426495

Epoch: 2| Step: 0
Training loss: 5.384096831200582
Validation loss: 5.3093316915815105

Epoch: 5| Step: 1
Training loss: 5.185958449415354
Validation loss: 5.243502014242064

Epoch: 5| Step: 2
Training loss: 5.427847878558632
Validation loss: 5.172318630401557

Epoch: 5| Step: 3
Training loss: 5.057437201886485
Validation loss: 5.098723674381672

Epoch: 5| Step: 4
Training loss: 5.793498163603721
Validation loss: 5.0241276900932546

Epoch: 5| Step: 5
Training loss: 5.443126354561205
Validation loss: 4.949748321860368

Epoch: 5| Step: 6
Training loss: 5.647852950497158
Validation loss: 4.877111736396653

Epoch: 5| Step: 7
Training loss: 4.453538306614902
Validation loss: 4.8017662128167276

Epoch: 5| Step: 8
Training loss: 4.242305522141054
Validation loss: 4.726451039692909

Epoch: 5| Step: 9
Training loss: 4.906394033079377
Validation loss: 4.654073755708434

Epoch: 5| Step: 10
Training loss: 3.099857659302209
Validation loss: 4.580886303185577

Epoch: 3| Step: 0
Training loss: 4.238821925118606
Validation loss: 4.512616506779201

Epoch: 5| Step: 1
Training loss: 4.7283391466576745
Validation loss: 4.450957806349827

Epoch: 5| Step: 2
Training loss: 4.421542637064787
Validation loss: 4.393438878662063

Epoch: 5| Step: 3
Training loss: 4.069502678556835
Validation loss: 4.339749448498275

Epoch: 5| Step: 4
Training loss: 4.7008511442187295
Validation loss: 4.2946642844531535

Epoch: 5| Step: 5
Training loss: 4.492412103760047
Validation loss: 4.2502511618013665

Epoch: 5| Step: 6
Training loss: 4.954525337464738
Validation loss: 4.2128365026210846

Epoch: 5| Step: 7
Training loss: 3.887242451566187
Validation loss: 4.180671042092936

Epoch: 5| Step: 8
Training loss: 4.2778712395921055
Validation loss: 4.149695026900831

Epoch: 5| Step: 9
Training loss: 4.2747811780105245
Validation loss: 4.121031612675645

Epoch: 5| Step: 10
Training loss: 4.176223374629845
Validation loss: 4.096983208256698

Epoch: 4| Step: 0
Training loss: 3.4861412874480293
Validation loss: 4.073698888262326

Epoch: 5| Step: 1
Training loss: 3.295503303860707
Validation loss: 4.054469306754831

Epoch: 5| Step: 2
Training loss: 4.303054859972121
Validation loss: 4.038646152029435

Epoch: 5| Step: 3
Training loss: 4.010189905402558
Validation loss: 4.015043097520527

Epoch: 5| Step: 4
Training loss: 4.751149088754659
Validation loss: 3.994507464151074

Epoch: 5| Step: 5
Training loss: 4.878884748376359
Validation loss: 3.977036239823153

Epoch: 5| Step: 6
Training loss: 3.9885092435674445
Validation loss: 3.9632825410049453

Epoch: 5| Step: 7
Training loss: 3.927376463833315
Validation loss: 3.9559014475587855

Epoch: 5| Step: 8
Training loss: 4.160039565191654
Validation loss: 3.9333415263552785

Epoch: 5| Step: 9
Training loss: 4.101646902033372
Validation loss: 3.9148322692344286

Epoch: 5| Step: 10
Training loss: 4.379166934772245
Validation loss: 3.8966144640489815

Epoch: 5| Step: 0
Training loss: 4.1162812540331455
Validation loss: 3.8736100841673373

Epoch: 5| Step: 1
Training loss: 3.1751757956068847
Validation loss: 3.852756918002071

Epoch: 5| Step: 2
Training loss: 2.9357495875617765
Validation loss: 3.8282775138658356

Epoch: 5| Step: 3
Training loss: 3.7507544712222307
Validation loss: 3.8095143632379806

Epoch: 5| Step: 4
Training loss: 3.7272219284385266
Validation loss: 3.7930246810766075

Epoch: 5| Step: 5
Training loss: 4.996755882689917
Validation loss: 3.777596965707766

Epoch: 5| Step: 6
Training loss: 3.657255637609726
Validation loss: 3.7613091796853717

Epoch: 5| Step: 7
Training loss: 4.390984897185319
Validation loss: 3.7488034311610265

Epoch: 5| Step: 8
Training loss: 4.351718098514143
Validation loss: 3.7381093071419538

Epoch: 5| Step: 9
Training loss: 4.420639027104451
Validation loss: 3.730892702913358

Epoch: 5| Step: 10
Training loss: 3.5161556945370176
Validation loss: 3.724284473229922

Epoch: 6| Step: 0
Training loss: 2.714012051532387
Validation loss: 3.714980253468192

Epoch: 5| Step: 1
Training loss: 4.3591619186555395
Validation loss: 3.7071664160258715

Epoch: 5| Step: 2
Training loss: 3.3769469120460487
Validation loss: 3.70494019663126

Epoch: 5| Step: 3
Training loss: 4.261125252269328
Validation loss: 3.6952917816497757

Epoch: 5| Step: 4
Training loss: 2.9505447337346102
Validation loss: 3.686156242004829

Epoch: 5| Step: 5
Training loss: 3.5337333386800602
Validation loss: 3.6791173206096683

Epoch: 5| Step: 6
Training loss: 4.371935397774589
Validation loss: 3.67075835463301

Epoch: 5| Step: 7
Training loss: 4.474088454509957
Validation loss: 3.659062505185766

Epoch: 5| Step: 8
Training loss: 4.209956067143726
Validation loss: 3.651389847144153

Epoch: 5| Step: 9
Training loss: 3.9138019041008523
Validation loss: 3.652395377003441

Epoch: 5| Step: 10
Training loss: 3.9167836489691426
Validation loss: 3.634766821207473

Epoch: 7| Step: 0
Training loss: 3.47888024040075
Validation loss: 3.6281386137656377

Epoch: 5| Step: 1
Training loss: 3.6227700839771577
Validation loss: 3.6224072200524553

Epoch: 5| Step: 2
Training loss: 4.500848054448019
Validation loss: 3.6172821380532274

Epoch: 5| Step: 3
Training loss: 4.30236377063732
Validation loss: 3.6111916321411193

Epoch: 5| Step: 4
Training loss: 2.393155622268945
Validation loss: 3.5980770717440036

Epoch: 5| Step: 5
Training loss: 3.6211113955037977
Validation loss: 3.5917084290172814

Epoch: 5| Step: 6
Training loss: 4.08435051114622
Validation loss: 3.584260640753282

Epoch: 5| Step: 7
Training loss: 4.3115845966429545
Validation loss: 3.577752331402219

Epoch: 5| Step: 8
Training loss: 3.9234500473107436
Validation loss: 3.569673556205464

Epoch: 5| Step: 9
Training loss: 3.895455054755242
Validation loss: 3.560180105882339

Epoch: 5| Step: 10
Training loss: 2.999770632558667
Validation loss: 3.5497926889814195

Epoch: 8| Step: 0
Training loss: 3.2446177003780345
Validation loss: 3.5450309118098184

Epoch: 5| Step: 1
Training loss: 4.154225709751288
Validation loss: 3.5413987282167736

Epoch: 5| Step: 2
Training loss: 4.050752056608883
Validation loss: 3.53123069450814

Epoch: 5| Step: 3
Training loss: 3.285358726621105
Validation loss: 3.52793086081024

Epoch: 5| Step: 4
Training loss: 3.967617804563693
Validation loss: 3.521450720855049

Epoch: 5| Step: 5
Training loss: 3.9745593468519185
Validation loss: 3.5044711511549114

Epoch: 5| Step: 6
Training loss: 3.740084572922097
Validation loss: 3.496253510555077

Epoch: 5| Step: 7
Training loss: 3.697191466380218
Validation loss: 3.496845531954367

Epoch: 5| Step: 8
Training loss: 3.316935322933421
Validation loss: 3.4789494183887437

Epoch: 5| Step: 9
Training loss: 3.3698705617796976
Validation loss: 3.4682101341660783

Epoch: 5| Step: 10
Training loss: 4.012455620921343
Validation loss: 3.45715779857964

Epoch: 9| Step: 0
Training loss: 4.048744506266895
Validation loss: 3.4461683294365364

Epoch: 5| Step: 1
Training loss: 3.0781655865622137
Validation loss: 3.4362662912178497

Epoch: 5| Step: 2
Training loss: 4.081401809275799
Validation loss: 3.4264024679722658

Epoch: 5| Step: 3
Training loss: 3.7164748468778295
Validation loss: 3.417831991011615

Epoch: 5| Step: 4
Training loss: 4.110452836978477
Validation loss: 3.4075396767085477

Epoch: 5| Step: 5
Training loss: 3.4967684132113073
Validation loss: 3.398115338897224

Epoch: 5| Step: 6
Training loss: 3.463973046689087
Validation loss: 3.390884319180537

Epoch: 5| Step: 7
Training loss: 3.7064545547620185
Validation loss: 3.3819532114172626

Epoch: 5| Step: 8
Training loss: 3.4112988772023556
Validation loss: 3.373231147032422

Epoch: 5| Step: 9
Training loss: 3.1750792305739965
Validation loss: 3.370876562823766

Epoch: 5| Step: 10
Training loss: 3.452870493351852
Validation loss: 3.362770565742386

Epoch: 10| Step: 0
Training loss: 3.8776653106493826
Validation loss: 3.3530353851571486

Epoch: 5| Step: 1
Training loss: 3.367114993418884
Validation loss: 3.343670087826801

Epoch: 5| Step: 2
Training loss: 3.8410337201152633
Validation loss: 3.339019568153851

Epoch: 5| Step: 3
Training loss: 3.2656787338581603
Validation loss: 3.335947362809264

Epoch: 5| Step: 4
Training loss: 3.959760080833953
Validation loss: 3.3264791842744676

Epoch: 5| Step: 5
Training loss: 3.928147971875886
Validation loss: 3.316150793379869

Epoch: 5| Step: 6
Training loss: 3.074147244194998
Validation loss: 3.3114686313419184

Epoch: 5| Step: 7
Training loss: 3.18825641707471
Validation loss: 3.3068759777446983

Epoch: 5| Step: 8
Training loss: 3.57998422352815
Validation loss: 3.3055686911357602

Epoch: 5| Step: 9
Training loss: 3.7497908215991878
Validation loss: 3.3003246628699223

Epoch: 5| Step: 10
Training loss: 3.118901978728649
Validation loss: 3.285632822332197

Epoch: 11| Step: 0
Training loss: 3.4235180955433395
Validation loss: 3.2849861372056783

Epoch: 5| Step: 1
Training loss: 2.374254109557717
Validation loss: 3.282949023577943

Epoch: 5| Step: 2
Training loss: 3.3898408747773154
Validation loss: 3.280712046475664

Epoch: 5| Step: 3
Training loss: 3.432617326413582
Validation loss: 3.2709257965677487

Epoch: 5| Step: 4
Training loss: 3.856711514892765
Validation loss: 3.2656963843207367

Epoch: 5| Step: 5
Training loss: 3.116402204448286
Validation loss: 3.2594302028138578

Epoch: 5| Step: 6
Training loss: 4.06567094734377
Validation loss: 3.259850596601606

Epoch: 5| Step: 7
Training loss: 2.5598033579166137
Validation loss: 3.2488224761335016

Epoch: 5| Step: 8
Training loss: 4.2075825137900225
Validation loss: 3.2440643527786186

Epoch: 5| Step: 9
Training loss: 3.6672924259162394
Validation loss: 3.239637761324365

Epoch: 5| Step: 10
Training loss: 4.086323998808977
Validation loss: 3.236414718739352

Epoch: 12| Step: 0
Training loss: 2.993155300507159
Validation loss: 3.2309378845658894

Epoch: 5| Step: 1
Training loss: 3.1811807860993464
Validation loss: 3.2249426475818637

Epoch: 5| Step: 2
Training loss: 3.5775281916479895
Validation loss: 3.219996433112135

Epoch: 5| Step: 3
Training loss: 3.1491907321494605
Validation loss: 3.2156864970978023

Epoch: 5| Step: 4
Training loss: 3.3830476110921075
Validation loss: 3.2126138932445816

Epoch: 5| Step: 5
Training loss: 3.642018587637932
Validation loss: 3.2111552210833247

Epoch: 5| Step: 6
Training loss: 3.1572686996975476
Validation loss: 3.2055301755277177

Epoch: 5| Step: 7
Training loss: 3.645515660569506
Validation loss: 3.2015999281557734

Epoch: 5| Step: 8
Training loss: 3.771722312940418
Validation loss: 3.1944444688176077

Epoch: 5| Step: 9
Training loss: 4.086040663282972
Validation loss: 3.186454426130076

Epoch: 5| Step: 10
Training loss: 3.332828833231045
Validation loss: 3.1819359821742212

Epoch: 13| Step: 0
Training loss: 3.184159267256871
Validation loss: 3.183344813139702

Epoch: 5| Step: 1
Training loss: 3.096567739570228
Validation loss: 3.173286086526801

Epoch: 5| Step: 2
Training loss: 3.3956145389647814
Validation loss: 3.1674299313333703

Epoch: 5| Step: 3
Training loss: 3.777446757256315
Validation loss: 3.1655971235343143

Epoch: 5| Step: 4
Training loss: 3.9569823251695353
Validation loss: 3.1622283103860784

Epoch: 5| Step: 5
Training loss: 3.735239479527569
Validation loss: 3.156354621607964

Epoch: 5| Step: 6
Training loss: 3.297242926004382
Validation loss: 3.158444653950048

Epoch: 5| Step: 7
Training loss: 3.682561768261734
Validation loss: 3.1484716237421857

Epoch: 5| Step: 8
Training loss: 2.9330999006965004
Validation loss: 3.143024450181645

Epoch: 5| Step: 9
Training loss: 3.2711215692015494
Validation loss: 3.1456109918913118

Epoch: 5| Step: 10
Training loss: 3.1854600549557595
Validation loss: 3.145502099229442

Epoch: 14| Step: 0
Training loss: 2.8163229497476654
Validation loss: 3.1412909433363256

Epoch: 5| Step: 1
Training loss: 3.0627748015759266
Validation loss: 3.1416320704436473

Epoch: 5| Step: 2
Training loss: 3.4453382426227908
Validation loss: 3.138665865042092

Epoch: 5| Step: 3
Training loss: 3.1496665959800443
Validation loss: 3.1354032420868956

Epoch: 5| Step: 4
Training loss: 3.27947019717666
Validation loss: 3.12941571397807

Epoch: 5| Step: 5
Training loss: 4.518695988206984
Validation loss: 3.1269644627209887

Epoch: 5| Step: 6
Training loss: 3.2665433185670745
Validation loss: 3.1211614533014957

Epoch: 5| Step: 7
Training loss: 3.144865598732995
Validation loss: 3.1215174706668747

Epoch: 5| Step: 8
Training loss: 3.8202985205521327
Validation loss: 3.1161184176701138

Epoch: 5| Step: 9
Training loss: 3.3468808641569336
Validation loss: 3.1131588923683395

Epoch: 5| Step: 10
Training loss: 3.2239956378575956
Validation loss: 3.114472583186299

Epoch: 15| Step: 0
Training loss: 3.0047833138283906
Validation loss: 3.1165485219084608

Epoch: 5| Step: 1
Training loss: 2.501119363052732
Validation loss: 3.130397691326623

Epoch: 5| Step: 2
Training loss: 2.8077401467640284
Validation loss: 3.1485556498858007

Epoch: 5| Step: 3
Training loss: 4.028387901895095
Validation loss: 3.1443027705555293

Epoch: 5| Step: 4
Training loss: 3.334293147819079
Validation loss: 3.107610798853148

Epoch: 5| Step: 5
Training loss: 3.9564284442595317
Validation loss: 3.2262453714293113

Epoch: 5| Step: 6
Training loss: 3.9031958275042618
Validation loss: 3.213871483806732

Epoch: 5| Step: 7
Training loss: 3.752922445226228
Validation loss: 3.124753949723134

Epoch: 5| Step: 8
Training loss: 2.978319825787717
Validation loss: 3.1235092249650225

Epoch: 5| Step: 9
Training loss: 3.982244782301127
Validation loss: 3.243070350315705

Epoch: 5| Step: 10
Training loss: 3.052501940527447
Validation loss: 3.1359720427435955

Epoch: 16| Step: 0
Training loss: 3.601253868665011
Validation loss: 3.125180945951621

Epoch: 5| Step: 1
Training loss: 3.7418686764792537
Validation loss: 3.1394276592318264

Epoch: 5| Step: 2
Training loss: 3.318145691186855
Validation loss: 3.161039579949806

Epoch: 5| Step: 3
Training loss: 2.515352127724175
Validation loss: 3.1577293984402894

Epoch: 5| Step: 4
Training loss: 3.8844210633472125
Validation loss: 3.1569919792301895

Epoch: 5| Step: 5
Training loss: 3.7708863031590516
Validation loss: 3.123527612319749

Epoch: 5| Step: 6
Training loss: 3.2053939598631627
Validation loss: 3.105136835077521

Epoch: 5| Step: 7
Training loss: 2.8774746734803758
Validation loss: 3.1125608470636115

Epoch: 5| Step: 8
Training loss: 2.8209549021667457
Validation loss: 3.124542258588593

Epoch: 5| Step: 9
Training loss: 4.569765550538632
Validation loss: 3.1496737309728036

Epoch: 5| Step: 10
Training loss: 2.5089306581660145
Validation loss: 3.1354128019547343

Epoch: 17| Step: 0
Training loss: 2.629113289784455
Validation loss: 3.128421808368282

Epoch: 5| Step: 1
Training loss: 2.459008614418358
Validation loss: 3.1165466102094697

Epoch: 5| Step: 2
Training loss: 3.4037525225464336
Validation loss: 3.1062034013997

Epoch: 5| Step: 3
Training loss: 4.222781367393609
Validation loss: 3.0886612954253154

Epoch: 5| Step: 4
Training loss: 3.7404082653768183
Validation loss: 3.0793974903881107

Epoch: 5| Step: 5
Training loss: 2.8835980758696556
Validation loss: 3.0796498998659776

Epoch: 5| Step: 6
Training loss: 3.392088402873686
Validation loss: 3.0787085998122294

Epoch: 5| Step: 7
Training loss: 3.7661236318106988
Validation loss: 3.078913900979713

Epoch: 5| Step: 8
Training loss: 3.5009757452927914
Validation loss: 3.0781444305128134

Epoch: 5| Step: 9
Training loss: 3.4166834916111477
Validation loss: 3.0769473552239033

Epoch: 5| Step: 10
Training loss: 3.254940825596866
Validation loss: 3.0766246439920857

Epoch: 18| Step: 0
Training loss: 3.1622915327396854
Validation loss: 3.077244664940475

Epoch: 5| Step: 1
Training loss: 3.107778935085762
Validation loss: 3.074183765351005

Epoch: 5| Step: 2
Training loss: 2.564794954875141
Validation loss: 3.0718047491132214

Epoch: 5| Step: 3
Training loss: 3.6180300297795647
Validation loss: 3.069235021810132

Epoch: 5| Step: 4
Training loss: 3.397340935245954
Validation loss: 3.0635287039014747

Epoch: 5| Step: 5
Training loss: 3.451892201195854
Validation loss: 3.0600762803861246

Epoch: 5| Step: 6
Training loss: 3.5281693515743644
Validation loss: 3.057830075261524

Epoch: 5| Step: 7
Training loss: 3.5749024117761796
Validation loss: 3.055295225528059

Epoch: 5| Step: 8
Training loss: 3.5931204866443
Validation loss: 3.055660912967948

Epoch: 5| Step: 9
Training loss: 3.2470512217483902
Validation loss: 3.0506898374904687

Epoch: 5| Step: 10
Training loss: 3.4870354455798793
Validation loss: 3.053182567282484

Epoch: 19| Step: 0
Training loss: 3.4538156500536714
Validation loss: 3.048531226913279

Epoch: 5| Step: 1
Training loss: 3.237950803970861
Validation loss: 3.0455976485894563

Epoch: 5| Step: 2
Training loss: 3.629694562520034
Validation loss: 3.0473880307506165

Epoch: 5| Step: 3
Training loss: 3.4957317484545807
Validation loss: 3.0481289109514775

Epoch: 5| Step: 4
Training loss: 2.769265833351472
Validation loss: 3.0458281134956033

Epoch: 5| Step: 5
Training loss: 3.6373392757812835
Validation loss: 3.0437157208131924

Epoch: 5| Step: 6
Training loss: 3.9804597654231895
Validation loss: 3.0431217902451704

Epoch: 5| Step: 7
Training loss: 3.2233743873146197
Validation loss: 3.041691105017184

Epoch: 5| Step: 8
Training loss: 2.3564594772678293
Validation loss: 3.041944300350461

Epoch: 5| Step: 9
Training loss: 3.5365586339166457
Validation loss: 3.0389768636534145

Epoch: 5| Step: 10
Training loss: 3.017594717035695
Validation loss: 3.0392796371652513

Epoch: 20| Step: 0
Training loss: 3.285624177064406
Validation loss: 3.0363698553268743

Epoch: 5| Step: 1
Training loss: 3.2483749728586497
Validation loss: 3.036437824983279

Epoch: 5| Step: 2
Training loss: 3.0449835750844665
Validation loss: 3.0327893555933194

Epoch: 5| Step: 3
Training loss: 3.3364703358126553
Validation loss: 3.0296899095959455

Epoch: 5| Step: 4
Training loss: 2.9187674086907225
Validation loss: 3.028564482222993

Epoch: 5| Step: 5
Training loss: 4.156969968920844
Validation loss: 3.0252070483290474

Epoch: 5| Step: 6
Training loss: 3.0138008253257027
Validation loss: 3.0218133591980005

Epoch: 5| Step: 7
Training loss: 2.9650919010014305
Validation loss: 3.0198042822976654

Epoch: 5| Step: 8
Training loss: 3.5870039274578644
Validation loss: 3.018134193094419

Epoch: 5| Step: 9
Training loss: 3.088198372008425
Validation loss: 3.0214352956684842

Epoch: 5| Step: 10
Training loss: 3.7154573882391384
Validation loss: 3.017389790079413

Epoch: 21| Step: 0
Training loss: 3.7737788012461544
Validation loss: 3.0148520865125534

Epoch: 5| Step: 1
Training loss: 2.6710987413465173
Validation loss: 3.015643974600279

Epoch: 5| Step: 2
Training loss: 3.3262365293462994
Validation loss: 3.0126099869492613

Epoch: 5| Step: 3
Training loss: 3.188460411042553
Validation loss: 3.0103600050271213

Epoch: 5| Step: 4
Training loss: 3.366819994491119
Validation loss: 3.0103812942501795

Epoch: 5| Step: 5
Training loss: 3.506087866857725
Validation loss: 3.0067825418417984

Epoch: 5| Step: 6
Training loss: 3.1063825306548796
Validation loss: 3.0081297348246765

Epoch: 5| Step: 7
Training loss: 3.5385694686670375
Validation loss: 3.0086788366544823

Epoch: 5| Step: 8
Training loss: 3.170948513376921
Validation loss: 3.004585772471469

Epoch: 5| Step: 9
Training loss: 3.310499486893506
Validation loss: 3.00497466894112

Epoch: 5| Step: 10
Training loss: 3.2732842530133843
Validation loss: 3.0042107199215913

Epoch: 22| Step: 0
Training loss: 3.7990010906156666
Validation loss: 2.997928547706131

Epoch: 5| Step: 1
Training loss: 3.265019848983741
Validation loss: 2.9934149272601736

Epoch: 5| Step: 2
Training loss: 3.352953926550339
Validation loss: 2.990731886112184

Epoch: 5| Step: 3
Training loss: 3.198794382196635
Validation loss: 2.9824530235646516

Epoch: 5| Step: 4
Training loss: 2.5695646641647247
Validation loss: 2.9768506034139754

Epoch: 5| Step: 5
Training loss: 2.8291603848626834
Validation loss: 3.0196618501332098

Epoch: 5| Step: 6
Training loss: 3.45401224328783
Validation loss: 3.0330571702608515

Epoch: 5| Step: 7
Training loss: 2.5991899365501223
Validation loss: 2.98900061815943

Epoch: 5| Step: 8
Training loss: 3.929877396047035
Validation loss: 2.974819431010952

Epoch: 5| Step: 9
Training loss: 3.478315755680588
Validation loss: 2.971203246445974

Epoch: 5| Step: 10
Training loss: 3.406575038695419
Validation loss: 2.974655884753556

Epoch: 23| Step: 0
Training loss: 3.431971456422351
Validation loss: 2.977400116493964

Epoch: 5| Step: 1
Training loss: 3.70742869683481
Validation loss: 2.983734961621991

Epoch: 5| Step: 2
Training loss: 3.220481925109355
Validation loss: 2.9837450031364274

Epoch: 5| Step: 3
Training loss: 3.152295345043483
Validation loss: 2.9844901203307432

Epoch: 5| Step: 4
Training loss: 2.936864905996566
Validation loss: 2.9812846337862347

Epoch: 5| Step: 5
Training loss: 3.209930633318317
Validation loss: 2.99019022349762

Epoch: 5| Step: 6
Training loss: 3.208420558255681
Validation loss: 3.0591984410943893

Epoch: 5| Step: 7
Training loss: 3.2378980826348247
Validation loss: 2.987157980000515

Epoch: 5| Step: 8
Training loss: 3.9747541771457757
Validation loss: 2.9808221702441537

Epoch: 5| Step: 9
Training loss: 2.960131532994261
Validation loss: 2.9747525337050105

Epoch: 5| Step: 10
Training loss: 2.9438142481958436
Validation loss: 2.9787396535771657

Epoch: 24| Step: 0
Training loss: 3.223291840731668
Validation loss: 2.985659073458702

Epoch: 5| Step: 1
Training loss: 3.2670238364488258
Validation loss: 2.9772275543936164

Epoch: 5| Step: 2
Training loss: 3.26510280102626
Validation loss: 2.968284080744249

Epoch: 5| Step: 3
Training loss: 3.381341416115632
Validation loss: 2.9649675021261412

Epoch: 5| Step: 4
Training loss: 3.5055678902590564
Validation loss: 2.958854576222422

Epoch: 5| Step: 5
Training loss: 3.3018515392179784
Validation loss: 2.955672435894585

Epoch: 5| Step: 6
Training loss: 3.503757911697693
Validation loss: 2.957617676752364

Epoch: 5| Step: 7
Training loss: 3.0435751236138486
Validation loss: 2.958612624391753

Epoch: 5| Step: 8
Training loss: 2.941361830985159
Validation loss: 2.9559183828938456

Epoch: 5| Step: 9
Training loss: 3.073473208617071
Validation loss: 2.9607919208114692

Epoch: 5| Step: 10
Training loss: 3.3780515085813754
Validation loss: 2.9554843700206592

Epoch: 25| Step: 0
Training loss: 2.823400777336241
Validation loss: 2.958916055730003

Epoch: 5| Step: 1
Training loss: 3.3425971209525818
Validation loss: 2.9542195434387706

Epoch: 5| Step: 2
Training loss: 3.358873480687407
Validation loss: 2.953013395262433

Epoch: 5| Step: 3
Training loss: 3.605974850000406
Validation loss: 2.9450391408250147

Epoch: 5| Step: 4
Training loss: 2.7879352588990476
Validation loss: 2.9446307861354075

Epoch: 5| Step: 5
Training loss: 2.791693720520415
Validation loss: 2.9441504580959816

Epoch: 5| Step: 6
Training loss: 3.2520708675662866
Validation loss: 2.943338272545267

Epoch: 5| Step: 7
Training loss: 3.508002533045064
Validation loss: 2.941494669419614

Epoch: 5| Step: 8
Training loss: 3.484589300707401
Validation loss: 2.9445558199795276

Epoch: 5| Step: 9
Training loss: 3.252173797176814
Validation loss: 2.9430910852345336

Epoch: 5| Step: 10
Training loss: 3.4150077855480805
Validation loss: 2.94408766014806

Epoch: 26| Step: 0
Training loss: 3.0253925163405966
Validation loss: 2.942496019276845

Epoch: 5| Step: 1
Training loss: 3.316788973701724
Validation loss: 2.940748451583642

Epoch: 5| Step: 2
Training loss: 3.159219081815818
Validation loss: 2.93901196424395

Epoch: 5| Step: 3
Training loss: 3.2185517777821517
Validation loss: 2.935809579160825

Epoch: 5| Step: 4
Training loss: 2.637540833215877
Validation loss: 2.936359850142925

Epoch: 5| Step: 5
Training loss: 3.4611203250861013
Validation loss: 2.9446824044645266

Epoch: 5| Step: 6
Training loss: 2.9936631351364174
Validation loss: 2.953799049551663

Epoch: 5| Step: 7
Training loss: 3.1923731036197576
Validation loss: 2.969193851643434

Epoch: 5| Step: 8
Training loss: 3.60548819126496
Validation loss: 3.035905477442645

Epoch: 5| Step: 9
Training loss: 3.2161568871847406
Validation loss: 2.99894626973199

Epoch: 5| Step: 10
Training loss: 3.850300858867575
Validation loss: 2.9457702777102157

Epoch: 27| Step: 0
Training loss: 3.0007773028136464
Validation loss: 2.9341467606522627

Epoch: 5| Step: 1
Training loss: 2.3333175408873412
Validation loss: 2.945626112543542

Epoch: 5| Step: 2
Training loss: 3.180700492240332
Validation loss: 2.948025642751114

Epoch: 5| Step: 3
Training loss: 3.767351443292467
Validation loss: 2.9280715294341517

Epoch: 5| Step: 4
Training loss: 3.8303741698596405
Validation loss: 2.931007149514884

Epoch: 5| Step: 5
Training loss: 2.94794101952153
Validation loss: 2.9359539120043663

Epoch: 5| Step: 6
Training loss: 4.042589429669429
Validation loss: 2.944851089709614

Epoch: 5| Step: 7
Training loss: 2.6396588245205828
Validation loss: 2.9406142420920296

Epoch: 5| Step: 8
Training loss: 3.2482089462721726
Validation loss: 2.9543776860282582

Epoch: 5| Step: 9
Training loss: 3.206546946674573
Validation loss: 2.9488934702683

Epoch: 5| Step: 10
Training loss: 3.016673800071867
Validation loss: 2.935203387563129

Epoch: 28| Step: 0
Training loss: 3.8781089616393154
Validation loss: 2.9301969343146506

Epoch: 5| Step: 1
Training loss: 2.8596074577854336
Validation loss: 2.9251309395590965

Epoch: 5| Step: 2
Training loss: 3.228801698466479
Validation loss: 2.924355424077943

Epoch: 5| Step: 3
Training loss: 3.4986492002630767
Validation loss: 2.9244439943466207

Epoch: 5| Step: 4
Training loss: 3.0250946156230683
Validation loss: 2.9213842278449103

Epoch: 5| Step: 5
Training loss: 2.932123661592416
Validation loss: 2.920513062690853

Epoch: 5| Step: 6
Training loss: 3.4361904077229832
Validation loss: 2.9176294782681533

Epoch: 5| Step: 7
Training loss: 3.1287419612962615
Validation loss: 2.918285987999231

Epoch: 5| Step: 8
Training loss: 3.112496041291565
Validation loss: 2.9169193340033175

Epoch: 5| Step: 9
Training loss: 2.8344830442989015
Validation loss: 2.9195236915154377

Epoch: 5| Step: 10
Training loss: 3.362513296108122
Validation loss: 2.9232296709976655

Epoch: 29| Step: 0
Training loss: 3.229777288642131
Validation loss: 2.914401779695498

Epoch: 5| Step: 1
Training loss: 3.5616104621599876
Validation loss: 2.92047893255966

Epoch: 5| Step: 2
Training loss: 3.7336459545533556
Validation loss: 2.913757771033155

Epoch: 5| Step: 3
Training loss: 3.8708204063196936
Validation loss: 2.9144969170897115

Epoch: 5| Step: 4
Training loss: 3.2979824140737986
Validation loss: 2.916951494035961

Epoch: 5| Step: 5
Training loss: 3.028895771519146
Validation loss: 2.9204679229813686

Epoch: 5| Step: 6
Training loss: 2.893681740007213
Validation loss: 2.914489686630129

Epoch: 5| Step: 7
Training loss: 3.0705091107731337
Validation loss: 2.9124222356125307

Epoch: 5| Step: 8
Training loss: 2.4944768931377075
Validation loss: 2.9132069989679037

Epoch: 5| Step: 9
Training loss: 3.030622909019663
Validation loss: 2.911850659450629

Epoch: 5| Step: 10
Training loss: 2.8499503817338163
Validation loss: 2.9112981502384665

Epoch: 30| Step: 0
Training loss: 3.178837393077988
Validation loss: 2.9108238170846783

Epoch: 5| Step: 1
Training loss: 3.018289446400225
Validation loss: 2.9047343765224882

Epoch: 5| Step: 2
Training loss: 3.7203892532884093
Validation loss: 2.9072340746858885

Epoch: 5| Step: 3
Training loss: 3.8905698473594605
Validation loss: 2.905249111576601

Epoch: 5| Step: 4
Training loss: 3.18314632711975
Validation loss: 2.902422037601988

Epoch: 5| Step: 5
Training loss: 2.7325201228204437
Validation loss: 2.9035297709233507

Epoch: 5| Step: 6
Training loss: 3.5059370367007534
Validation loss: 2.902297455870547

Epoch: 5| Step: 7
Training loss: 2.9930844070763025
Validation loss: 2.9027287337977934

Epoch: 5| Step: 8
Training loss: 3.031008523977509
Validation loss: 2.9042534967317413

Epoch: 5| Step: 9
Training loss: 3.175869235500885
Validation loss: 2.9020338647017794

Epoch: 5| Step: 10
Training loss: 2.551962049028672
Validation loss: 2.9037056373997854

Epoch: 31| Step: 0
Training loss: 3.04298520359199
Validation loss: 2.9094453892502745

Epoch: 5| Step: 1
Training loss: 2.6055832227183755
Validation loss: 2.9183873499296458

Epoch: 5| Step: 2
Training loss: 3.6848189095419825
Validation loss: 2.93111436537371

Epoch: 5| Step: 3
Training loss: 3.3229089974022896
Validation loss: 2.897151434276731

Epoch: 5| Step: 4
Training loss: 2.6241184752630353
Validation loss: 2.8917724726430096

Epoch: 5| Step: 5
Training loss: 3.1382305069938465
Validation loss: 2.8947307222396534

Epoch: 5| Step: 6
Training loss: 3.3122585856438485
Validation loss: 2.899061887511197

Epoch: 5| Step: 7
Training loss: 3.3256629110927305
Validation loss: 2.910859974219426

Epoch: 5| Step: 8
Training loss: 3.532174183586619
Validation loss: 2.922233918791992

Epoch: 5| Step: 9
Training loss: 2.858554076039082
Validation loss: 2.9039090657155637

Epoch: 5| Step: 10
Training loss: 3.7249089377108646
Validation loss: 2.8960679364174124

Epoch: 32| Step: 0
Training loss: 2.7232082250737593
Validation loss: 2.895420127904609

Epoch: 5| Step: 1
Training loss: 3.3707443533628503
Validation loss: 2.895783435825141

Epoch: 5| Step: 2
Training loss: 3.0446990239268756
Validation loss: 2.899487133029142

Epoch: 5| Step: 3
Training loss: 2.861430445589459
Validation loss: 2.8997800916207117

Epoch: 5| Step: 4
Training loss: 2.748071427767669
Validation loss: 2.9047889869893635

Epoch: 5| Step: 5
Training loss: 3.285487173062082
Validation loss: 2.9039984529189358

Epoch: 5| Step: 6
Training loss: 3.119101335998251
Validation loss: 2.8982553705935405

Epoch: 5| Step: 7
Training loss: 3.156185640490941
Validation loss: 2.892395112562153

Epoch: 5| Step: 8
Training loss: 3.730681440271879
Validation loss: 2.888186639653391

Epoch: 5| Step: 9
Training loss: 3.506771893342719
Validation loss: 2.888520518295395

Epoch: 5| Step: 10
Training loss: 3.4855939845469472
Validation loss: 2.885443473227313

Epoch: 33| Step: 0
Training loss: 3.362633265013535
Validation loss: 2.8855733669353274

Epoch: 5| Step: 1
Training loss: 3.68295499374645
Validation loss: 2.884038560902818

Epoch: 5| Step: 2
Training loss: 3.1234190947470792
Validation loss: 2.883687430347673

Epoch: 5| Step: 3
Training loss: 3.31401329741403
Validation loss: 2.8822543629965582

Epoch: 5| Step: 4
Training loss: 2.6637250848801615
Validation loss: 2.88210481297229

Epoch: 5| Step: 5
Training loss: 2.9606910945254232
Validation loss: 2.879872407949598

Epoch: 5| Step: 6
Training loss: 3.123360776125902
Validation loss: 2.877122745417875

Epoch: 5| Step: 7
Training loss: 2.8606337814746348
Validation loss: 2.879874761617438

Epoch: 5| Step: 8
Training loss: 3.190554184085723
Validation loss: 2.875679066104984

Epoch: 5| Step: 9
Training loss: 3.4528477069800885
Validation loss: 2.8786485748443313

Epoch: 5| Step: 10
Training loss: 3.203707460618884
Validation loss: 2.876092630914063

Epoch: 34| Step: 0
Training loss: 3.664229854836777
Validation loss: 2.875228605236853

Epoch: 5| Step: 1
Training loss: 2.9330873826982136
Validation loss: 2.875437023373596

Epoch: 5| Step: 2
Training loss: 2.6722890075811527
Validation loss: 2.8765585376833216

Epoch: 5| Step: 3
Training loss: 3.4929199816004615
Validation loss: 2.878640649643034

Epoch: 5| Step: 4
Training loss: 2.9840047716506564
Validation loss: 2.8817218600829606

Epoch: 5| Step: 5
Training loss: 3.293534018802267
Validation loss: 2.9107858249234395

Epoch: 5| Step: 6
Training loss: 3.425861144575066
Validation loss: 2.929717831034188

Epoch: 5| Step: 7
Training loss: 3.2808299931153986
Validation loss: 2.8761326403254257

Epoch: 5| Step: 8
Training loss: 2.842921209606119
Validation loss: 2.866322417765009

Epoch: 5| Step: 9
Training loss: 2.8868829373343265
Validation loss: 2.870903226128215

Epoch: 5| Step: 10
Training loss: 3.547087003446909
Validation loss: 2.872034310607787

Epoch: 35| Step: 0
Training loss: 3.485173292188914
Validation loss: 2.87674082697654

Epoch: 5| Step: 1
Training loss: 3.753961759190593
Validation loss: 2.877899231114111

Epoch: 5| Step: 2
Training loss: 3.038517371076074
Validation loss: 2.8731715454679088

Epoch: 5| Step: 3
Training loss: 2.182826908967855
Validation loss: 2.8700448680782125

Epoch: 5| Step: 4
Training loss: 3.6054789335328152
Validation loss: 2.8679414088628357

Epoch: 5| Step: 5
Training loss: 3.1490279559835472
Validation loss: 2.8651568268096397

Epoch: 5| Step: 6
Training loss: 2.9375818119425148
Validation loss: 2.862131566272118

Epoch: 5| Step: 7
Training loss: 3.279439081286038
Validation loss: 2.8614564847729467

Epoch: 5| Step: 8
Training loss: 2.959170979573931
Validation loss: 2.85580857591342

Epoch: 5| Step: 9
Training loss: 3.309548124372362
Validation loss: 2.8562598071685366

Epoch: 5| Step: 10
Training loss: 2.9916293666997245
Validation loss: 2.853510416884721

Epoch: 36| Step: 0
Training loss: 2.865887006556711
Validation loss: 2.8522220834867893

Epoch: 5| Step: 1
Training loss: 2.6815269985145043
Validation loss: 2.851682568341659

Epoch: 5| Step: 2
Training loss: 3.0263588367604215
Validation loss: 2.8531862597081057

Epoch: 5| Step: 3
Training loss: 3.5071296282095052
Validation loss: 2.8662609190109216

Epoch: 5| Step: 4
Training loss: 3.1823880960908313
Validation loss: 2.8589299222774134

Epoch: 5| Step: 5
Training loss: 3.5918713510580065
Validation loss: 2.8614752972725936

Epoch: 5| Step: 6
Training loss: 3.189873354080955
Validation loss: 2.8533264754656376

Epoch: 5| Step: 7
Training loss: 3.459781772368678
Validation loss: 2.8467313744725486

Epoch: 5| Step: 8
Training loss: 3.2140317241287546
Validation loss: 2.8444620237439606

Epoch: 5| Step: 9
Training loss: 3.005358361125039
Validation loss: 2.8442390072834978

Epoch: 5| Step: 10
Training loss: 2.8908663262333496
Validation loss: 2.8439528158444323

Epoch: 37| Step: 0
Training loss: 3.1268309760554414
Validation loss: 2.843094375256382

Epoch: 5| Step: 1
Training loss: 3.8732963016160156
Validation loss: 2.843263904811273

Epoch: 5| Step: 2
Training loss: 3.1754040558594667
Validation loss: 2.84306688655841

Epoch: 5| Step: 3
Training loss: 3.420176323924098
Validation loss: 2.841312162695023

Epoch: 5| Step: 4
Training loss: 3.24685619594794
Validation loss: 2.8431841100062454

Epoch: 5| Step: 5
Training loss: 2.9592223823936368
Validation loss: 2.8435343872822543

Epoch: 5| Step: 6
Training loss: 3.077219563651564
Validation loss: 2.8397271551205034

Epoch: 5| Step: 7
Training loss: 3.130744993865481
Validation loss: 2.8404239539669844

Epoch: 5| Step: 8
Training loss: 3.002212662109444
Validation loss: 2.836136792426188

Epoch: 5| Step: 9
Training loss: 2.733526130792799
Validation loss: 2.8354770963873177

Epoch: 5| Step: 10
Training loss: 2.737025605644673
Validation loss: 2.8349231684688236

Epoch: 38| Step: 0
Training loss: 3.2283688123568894
Validation loss: 2.832610623251004

Epoch: 5| Step: 1
Training loss: 2.5228455029212764
Validation loss: 2.8324116574627345

Epoch: 5| Step: 2
Training loss: 3.2534349336028683
Validation loss: 2.840157090027643

Epoch: 5| Step: 3
Training loss: 3.5058999061898044
Validation loss: 2.840167625627277

Epoch: 5| Step: 4
Training loss: 3.5360269559635404
Validation loss: 2.82937709295168

Epoch: 5| Step: 5
Training loss: 2.408931773542227
Validation loss: 2.828309280609197

Epoch: 5| Step: 6
Training loss: 2.8721559804250036
Validation loss: 2.829415378176652

Epoch: 5| Step: 7
Training loss: 2.7924870002191278
Validation loss: 2.8344728547769105

Epoch: 5| Step: 8
Training loss: 3.5468214930056843
Validation loss: 2.8287283644074637

Epoch: 5| Step: 9
Training loss: 3.4441747884579996
Validation loss: 2.832562025527299

Epoch: 5| Step: 10
Training loss: 3.238180823891367
Validation loss: 2.8297138961876587

Epoch: 39| Step: 0
Training loss: 3.375353335499164
Validation loss: 2.8282079118517816

Epoch: 5| Step: 1
Training loss: 3.231163310026216
Validation loss: 2.824244136495085

Epoch: 5| Step: 2
Training loss: 2.1181969294937377
Validation loss: 2.822262596517355

Epoch: 5| Step: 3
Training loss: 3.8688238824004677
Validation loss: 2.8247604666407065

Epoch: 5| Step: 4
Training loss: 3.1131303815291615
Validation loss: 2.822382014737732

Epoch: 5| Step: 5
Training loss: 3.202112102855003
Validation loss: 2.823511618038213

Epoch: 5| Step: 6
Training loss: 3.1815673370069772
Validation loss: 2.8242293786426

Epoch: 5| Step: 7
Training loss: 2.728118102948711
Validation loss: 2.828852687075692

Epoch: 5| Step: 8
Training loss: 2.986401893198602
Validation loss: 2.84853706380485

Epoch: 5| Step: 9
Training loss: 3.1970217733539625
Validation loss: 2.8752730865398344

Epoch: 5| Step: 10
Training loss: 3.2802682043535216
Validation loss: 2.8243772450638196

Epoch: 40| Step: 0
Training loss: 3.067953742184613
Validation loss: 2.8207984978027794

Epoch: 5| Step: 1
Training loss: 3.3268295417416094
Validation loss: 2.821650988981749

Epoch: 5| Step: 2
Training loss: 3.4693862743878268
Validation loss: 2.844246894041398

Epoch: 5| Step: 3
Training loss: 3.233040797053164
Validation loss: 2.8315219994694876

Epoch: 5| Step: 4
Training loss: 3.436019023571709
Validation loss: 2.828053563888852

Epoch: 5| Step: 5
Training loss: 3.647325235929468
Validation loss: 2.827038764105058

Epoch: 5| Step: 6
Training loss: 2.5271597888154136
Validation loss: 2.8233689082627587

Epoch: 5| Step: 7
Training loss: 2.8719861362940855
Validation loss: 2.8202757810415116

Epoch: 5| Step: 8
Training loss: 2.5725501619273285
Validation loss: 2.8191849785687926

Epoch: 5| Step: 9
Training loss: 3.6679196095450295
Validation loss: 2.818049748260243

Epoch: 5| Step: 10
Training loss: 2.4025938322576987
Validation loss: 2.8169832654456792

Epoch: 41| Step: 0
Training loss: 3.205158462772843
Validation loss: 2.815421076243724

Epoch: 5| Step: 1
Training loss: 3.3391238144924698
Validation loss: 2.8145810439250316

Epoch: 5| Step: 2
Training loss: 2.8131658825449386
Validation loss: 2.81812016892694

Epoch: 5| Step: 3
Training loss: 3.442058938665004
Validation loss: 2.816469622881758

Epoch: 5| Step: 4
Training loss: 2.6679196890792474
Validation loss: 2.8178078629281744

Epoch: 5| Step: 5
Training loss: 3.2450791298456747
Validation loss: 2.8258218433193476

Epoch: 5| Step: 6
Training loss: 3.1398334169846613
Validation loss: 2.8210264317030838

Epoch: 5| Step: 7
Training loss: 2.89607096915988
Validation loss: 2.8228149011267876

Epoch: 5| Step: 8
Training loss: 2.833863900566432
Validation loss: 2.817999524814099

Epoch: 5| Step: 9
Training loss: 3.1552796335729165
Validation loss: 2.8148559137257623

Epoch: 5| Step: 10
Training loss: 3.676868825100323
Validation loss: 2.8061070760237

Epoch: 42| Step: 0
Training loss: 3.147216105607155
Validation loss: 2.8047878898564726

Epoch: 5| Step: 1
Training loss: 3.0967341971314077
Validation loss: 2.805828075425633

Epoch: 5| Step: 2
Training loss: 2.391944371581309
Validation loss: 2.804609259395786

Epoch: 5| Step: 3
Training loss: 2.948285855920388
Validation loss: 2.8084991063520883

Epoch: 5| Step: 4
Training loss: 3.213844190275894
Validation loss: 2.8073761785144558

Epoch: 5| Step: 5
Training loss: 2.7671638991794243
Validation loss: 2.807555808118224

Epoch: 5| Step: 6
Training loss: 3.0215880580242933
Validation loss: 2.804964010160465

Epoch: 5| Step: 7
Training loss: 3.0736365730421173
Validation loss: 2.8003809272046483

Epoch: 5| Step: 8
Training loss: 3.6513082903029375
Validation loss: 2.801264918326781

Epoch: 5| Step: 9
Training loss: 3.2329480252959737
Validation loss: 2.80123178156469

Epoch: 5| Step: 10
Training loss: 3.694473913420995
Validation loss: 2.800027361016845

Epoch: 43| Step: 0
Training loss: 3.3071440095555205
Validation loss: 2.800165213304759

Epoch: 5| Step: 1
Training loss: 3.677982785855159
Validation loss: 2.796716478990417

Epoch: 5| Step: 2
Training loss: 3.0033723632049005
Validation loss: 2.809251467433609

Epoch: 5| Step: 3
Training loss: 2.566481869307835
Validation loss: 2.8265553366852494

Epoch: 5| Step: 4
Training loss: 2.391602459709152
Validation loss: 2.850173455000732

Epoch: 5| Step: 5
Training loss: 3.0532700940486603
Validation loss: 2.927381540089991

Epoch: 5| Step: 6
Training loss: 3.2423804535956875
Validation loss: 2.816052833242475

Epoch: 5| Step: 7
Training loss: 3.0344231111619404
Validation loss: 2.7946357445579944

Epoch: 5| Step: 8
Training loss: 3.3847136408208724
Validation loss: 2.793154993035521

Epoch: 5| Step: 9
Training loss: 3.87619061790824
Validation loss: 2.801972100000008

Epoch: 5| Step: 10
Training loss: 2.270242234971951
Validation loss: 2.816299884994946

Epoch: 44| Step: 0
Training loss: 2.9921999301104414
Validation loss: 2.8498891116958913

Epoch: 5| Step: 1
Training loss: 3.2272927702453535
Validation loss: 2.862673423275762

Epoch: 5| Step: 2
Training loss: 3.569113765956588
Validation loss: 2.817126529849586

Epoch: 5| Step: 3
Training loss: 2.8370381050764477
Validation loss: 2.8017699958517133

Epoch: 5| Step: 4
Training loss: 3.134129425803987
Validation loss: 2.7932432079271834

Epoch: 5| Step: 5
Training loss: 3.0729894252288537
Validation loss: 2.791140727342592

Epoch: 5| Step: 6
Training loss: 3.1064792356584565
Validation loss: 2.7902516093971124

Epoch: 5| Step: 7
Training loss: 3.007131999927877
Validation loss: 2.7881725271613136

Epoch: 5| Step: 8
Training loss: 3.095532452905669
Validation loss: 2.787479592922784

Epoch: 5| Step: 9
Training loss: 3.375242153946635
Validation loss: 2.7931003100418175

Epoch: 5| Step: 10
Training loss: 2.897186749750048
Validation loss: 2.7936702316336235

Epoch: 45| Step: 0
Training loss: 3.4738373437465526
Validation loss: 2.7935337666882027

Epoch: 5| Step: 1
Training loss: 2.251128549471651
Validation loss: 2.7990705944697933

Epoch: 5| Step: 2
Training loss: 3.5671865856755973
Validation loss: 2.796550364102688

Epoch: 5| Step: 3
Training loss: 2.7656247413764445
Validation loss: 2.7956640716025682

Epoch: 5| Step: 4
Training loss: 3.0510696099016377
Validation loss: 2.7963101890359683

Epoch: 5| Step: 5
Training loss: 3.494092588057165
Validation loss: 2.7962247040154162

Epoch: 5| Step: 6
Training loss: 2.841964160937506
Validation loss: 2.784281104981304

Epoch: 5| Step: 7
Training loss: 3.046877191004821
Validation loss: 2.780409638613298

Epoch: 5| Step: 8
Training loss: 3.3538929766399646
Validation loss: 2.7791455132470135

Epoch: 5| Step: 9
Training loss: 3.2202749251052647
Validation loss: 2.780372563257274

Epoch: 5| Step: 10
Training loss: 2.8531892499761033
Validation loss: 2.7813583754795066

Epoch: 46| Step: 0
Training loss: 2.9228853325083053
Validation loss: 2.776497100267235

Epoch: 5| Step: 1
Training loss: 3.296866466637727
Validation loss: 2.777543123615884

Epoch: 5| Step: 2
Training loss: 2.705241174294113
Validation loss: 2.7757218216334936

Epoch: 5| Step: 3
Training loss: 3.349453633861162
Validation loss: 2.7763579860077114

Epoch: 5| Step: 4
Training loss: 3.1043327508996366
Validation loss: 2.7804982265195295

Epoch: 5| Step: 5
Training loss: 2.9249822241088133
Validation loss: 2.7763958878342847

Epoch: 5| Step: 6
Training loss: 3.285574687930296
Validation loss: 2.7944513386918235

Epoch: 5| Step: 7
Training loss: 3.298225307099502
Validation loss: 2.8067295586930605

Epoch: 5| Step: 8
Training loss: 2.7286316636026995
Validation loss: 2.7899497842255703

Epoch: 5| Step: 9
Training loss: 3.2263380069545766
Validation loss: 2.7849354224585587

Epoch: 5| Step: 10
Training loss: 3.1426693160421246
Validation loss: 2.78646234683205

Epoch: 47| Step: 0
Training loss: 3.2897106266015106
Validation loss: 2.7825863162595104

Epoch: 5| Step: 1
Training loss: 2.815311129029057
Validation loss: 2.7895671814943634

Epoch: 5| Step: 2
Training loss: 2.8090480389288053
Validation loss: 2.7889911342254874

Epoch: 5| Step: 3
Training loss: 3.56184488262691
Validation loss: 2.7773559749116092

Epoch: 5| Step: 4
Training loss: 3.074327013758363
Validation loss: 2.770614423546238

Epoch: 5| Step: 5
Training loss: 3.236974289088156
Validation loss: 2.7672166637434414

Epoch: 5| Step: 6
Training loss: 2.9485552919406732
Validation loss: 2.766243277534722

Epoch: 5| Step: 7
Training loss: 3.3073089519059047
Validation loss: 2.7672659421249612

Epoch: 5| Step: 8
Training loss: 2.5618575616649273
Validation loss: 2.7677915751637303

Epoch: 5| Step: 9
Training loss: 3.332990501575687
Validation loss: 2.7667189948091

Epoch: 5| Step: 10
Training loss: 2.918453886053705
Validation loss: 2.766772101427265

Epoch: 48| Step: 0
Training loss: 3.1079039808093594
Validation loss: 2.7622027011347607

Epoch: 5| Step: 1
Training loss: 2.732132171695447
Validation loss: 2.766754841934502

Epoch: 5| Step: 2
Training loss: 2.54498014580977
Validation loss: 2.7673369491804953

Epoch: 5| Step: 3
Training loss: 3.4937718699526537
Validation loss: 2.77239549708692

Epoch: 5| Step: 4
Training loss: 3.5743649645639635
Validation loss: 2.771771802117732

Epoch: 5| Step: 5
Training loss: 3.1044954130114575
Validation loss: 2.765194724480697

Epoch: 5| Step: 6
Training loss: 2.921030177414003
Validation loss: 2.7658016370202696

Epoch: 5| Step: 7
Training loss: 2.8088287127899005
Validation loss: 2.767117678173313

Epoch: 5| Step: 8
Training loss: 3.4840210876001847
Validation loss: 2.767293211984636

Epoch: 5| Step: 9
Training loss: 3.017133582496218
Validation loss: 2.7649534854085434

Epoch: 5| Step: 10
Training loss: 3.0935352905983224
Validation loss: 2.7679500253682683

Epoch: 49| Step: 0
Training loss: 3.205155338563754
Validation loss: 2.7692669238816903

Epoch: 5| Step: 1
Training loss: 3.2387559494499825
Validation loss: 2.770053906253645

Epoch: 5| Step: 2
Training loss: 2.9766650244810466
Validation loss: 2.7686204612986347

Epoch: 5| Step: 3
Training loss: 3.208459050741593
Validation loss: 2.7682364858871806

Epoch: 5| Step: 4
Training loss: 2.9443905143677243
Validation loss: 2.7685979417822577

Epoch: 5| Step: 5
Training loss: 3.0243043272996744
Validation loss: 2.772874610554647

Epoch: 5| Step: 6
Training loss: 3.1453868389109223
Validation loss: 2.7698323281869013

Epoch: 5| Step: 7
Training loss: 3.3362156486243477
Validation loss: 2.7745781043162077

Epoch: 5| Step: 8
Training loss: 3.4855046515219645
Validation loss: 2.775642571499958

Epoch: 5| Step: 9
Training loss: 2.97456080296235
Validation loss: 2.7891233396272703

Epoch: 5| Step: 10
Training loss: 2.309537897830142
Validation loss: 2.7789688147913196

Epoch: 50| Step: 0
Training loss: 2.7942873956355956
Validation loss: 2.759871460158239

Epoch: 5| Step: 1
Training loss: 3.041656407029777
Validation loss: 2.759587422730562

Epoch: 5| Step: 2
Training loss: 2.9544154985564153
Validation loss: 2.7604243195780387

Epoch: 5| Step: 3
Training loss: 3.3511631156361363
Validation loss: 2.757353179124134

Epoch: 5| Step: 4
Training loss: 3.6704635179808847
Validation loss: 2.7559077215751633

Epoch: 5| Step: 5
Training loss: 3.3130819421289948
Validation loss: 2.7538773581057554

Epoch: 5| Step: 6
Training loss: 3.01041480111633
Validation loss: 2.7554793152575674

Epoch: 5| Step: 7
Training loss: 2.754577987666481
Validation loss: 2.753702419571653

Epoch: 5| Step: 8
Training loss: 3.0025896974707385
Validation loss: 2.754855478418993

Epoch: 5| Step: 9
Training loss: 2.9456772312816475
Validation loss: 2.7673092086764703

Epoch: 5| Step: 10
Training loss: 2.908287892537695
Validation loss: 2.7654147764906667

Epoch: 51| Step: 0
Training loss: 3.061676226002059
Validation loss: 2.7592671993686113

Epoch: 5| Step: 1
Training loss: 3.0893501823118394
Validation loss: 2.763198838609225

Epoch: 5| Step: 2
Training loss: 3.198572114423402
Validation loss: 2.760300181356019

Epoch: 5| Step: 3
Training loss: 3.300437557226743
Validation loss: 2.7546073347569955

Epoch: 5| Step: 4
Training loss: 3.2691602052003548
Validation loss: 2.7492242522541406

Epoch: 5| Step: 5
Training loss: 3.269797839527232
Validation loss: 2.7479653349897

Epoch: 5| Step: 6
Training loss: 2.1175022243231356
Validation loss: 2.752728410121577

Epoch: 5| Step: 7
Training loss: 3.2265042722311073
Validation loss: 2.757001918817245

Epoch: 5| Step: 8
Training loss: 3.135496896792424
Validation loss: 2.762192368415672

Epoch: 5| Step: 9
Training loss: 2.8691741962169717
Validation loss: 2.7485185111700248

Epoch: 5| Step: 10
Training loss: 3.068571028763932
Validation loss: 2.7495722265518507

Epoch: 52| Step: 0
Training loss: 3.441035585218885
Validation loss: 2.748849981628477

Epoch: 5| Step: 1
Training loss: 2.242616512712238
Validation loss: 2.749329091713635

Epoch: 5| Step: 2
Training loss: 2.9763308457469453
Validation loss: 2.7482243908890713

Epoch: 5| Step: 3
Training loss: 3.445266827131367
Validation loss: 2.7488862725465704

Epoch: 5| Step: 4
Training loss: 2.978743107347922
Validation loss: 2.748359405216408

Epoch: 5| Step: 5
Training loss: 2.9506079225181305
Validation loss: 2.7502080870326657

Epoch: 5| Step: 6
Training loss: 3.322304951358219
Validation loss: 2.7488190733968425

Epoch: 5| Step: 7
Training loss: 2.9570199621027946
Validation loss: 2.7488286888309683

Epoch: 5| Step: 8
Training loss: 3.2161871327002083
Validation loss: 2.7491190115380486

Epoch: 5| Step: 9
Training loss: 2.8095527465398473
Validation loss: 2.747516674251033

Epoch: 5| Step: 10
Training loss: 3.3935538444243556
Validation loss: 2.750015965375301

Epoch: 53| Step: 0
Training loss: 3.4893332472429375
Validation loss: 2.753525456085821

Epoch: 5| Step: 1
Training loss: 2.7415883857968595
Validation loss: 2.749537855154667

Epoch: 5| Step: 2
Training loss: 3.147392610713141
Validation loss: 2.7447240714940744

Epoch: 5| Step: 3
Training loss: 2.762181438875718
Validation loss: 2.745537499727146

Epoch: 5| Step: 4
Training loss: 2.7918428299013067
Validation loss: 2.7439708582611644

Epoch: 5| Step: 5
Training loss: 2.6912847970430716
Validation loss: 2.7391210542108437

Epoch: 5| Step: 6
Training loss: 3.495119643230487
Validation loss: 2.7367630138865953

Epoch: 5| Step: 7
Training loss: 3.0048975703955927
Validation loss: 2.746134663853549

Epoch: 5| Step: 8
Training loss: 2.989408711684571
Validation loss: 2.741949379069609

Epoch: 5| Step: 9
Training loss: 3.1015449734824383
Validation loss: 2.7415427603501747

Epoch: 5| Step: 10
Training loss: 3.495399039522613
Validation loss: 2.74307712684735

Epoch: 54| Step: 0
Training loss: 3.4423366851962705
Validation loss: 2.735687758287708

Epoch: 5| Step: 1
Training loss: 3.5799494593798205
Validation loss: 2.734640466604284

Epoch: 5| Step: 2
Training loss: 2.7685269578086613
Validation loss: 2.7367868332564376

Epoch: 5| Step: 3
Training loss: 3.0760314328059706
Validation loss: 2.736352779170234

Epoch: 5| Step: 4
Training loss: 2.711053147721248
Validation loss: 2.739786688343712

Epoch: 5| Step: 5
Training loss: 3.057570090063653
Validation loss: 2.757390378977359

Epoch: 5| Step: 6
Training loss: 2.501971230601448
Validation loss: 2.7677329972425415

Epoch: 5| Step: 7
Training loss: 2.4850047530928965
Validation loss: 2.7586617988535904

Epoch: 5| Step: 8
Training loss: 3.233050678784568
Validation loss: 2.756151670375673

Epoch: 5| Step: 9
Training loss: 3.158258384546706
Validation loss: 2.7406504615419163

Epoch: 5| Step: 10
Training loss: 3.7227375866229115
Validation loss: 2.743982865618043

Epoch: 55| Step: 0
Training loss: 2.958963747865398
Validation loss: 2.736740430819254

Epoch: 5| Step: 1
Training loss: 2.994917060327746
Validation loss: 2.7342493134426307

Epoch: 5| Step: 2
Training loss: 3.4972324328432984
Validation loss: 2.731520837830475

Epoch: 5| Step: 3
Training loss: 2.836503405895236
Validation loss: 2.7270559436838355

Epoch: 5| Step: 4
Training loss: 3.417435505278667
Validation loss: 2.728741135840652

Epoch: 5| Step: 5
Training loss: 2.9504503520595398
Validation loss: 2.7273474147426087

Epoch: 5| Step: 6
Training loss: 3.306879132992273
Validation loss: 2.726441311766141

Epoch: 5| Step: 7
Training loss: 2.771299757934467
Validation loss: 2.727915017419502

Epoch: 5| Step: 8
Training loss: 3.146983982536348
Validation loss: 2.7269683892130914

Epoch: 5| Step: 9
Training loss: 2.981333036086057
Validation loss: 2.723526967885998

Epoch: 5| Step: 10
Training loss: 2.6670224031952765
Validation loss: 2.7256227704934384

Epoch: 56| Step: 0
Training loss: 3.495402177147128
Validation loss: 2.7259297309963566

Epoch: 5| Step: 1
Training loss: 2.515805255758065
Validation loss: 2.728813385863496

Epoch: 5| Step: 2
Training loss: 3.1854600549557595
Validation loss: 2.736696587774288

Epoch: 5| Step: 3
Training loss: 2.795953950587336
Validation loss: 2.7446298295654747

Epoch: 5| Step: 4
Training loss: 3.2731256086033156
Validation loss: 2.7547668699477343

Epoch: 5| Step: 5
Training loss: 2.8440450997297626
Validation loss: 2.750902138865491

Epoch: 5| Step: 6
Training loss: 2.729679282775983
Validation loss: 2.7497300559011495

Epoch: 5| Step: 7
Training loss: 3.442480744395981
Validation loss: 2.7450583563968625

Epoch: 5| Step: 8
Training loss: 3.3991711054912694
Validation loss: 2.7185211820850372

Epoch: 5| Step: 9
Training loss: 3.0579081774261674
Validation loss: 2.7164971590209643

Epoch: 5| Step: 10
Training loss: 2.769398501810206
Validation loss: 2.7187668485476553

Epoch: 57| Step: 0
Training loss: 3.073297578296111
Validation loss: 2.7221210425844347

Epoch: 5| Step: 1
Training loss: 2.6720125932568037
Validation loss: 2.726739483421704

Epoch: 5| Step: 2
Training loss: 2.914438504666954
Validation loss: 2.7335952336059086

Epoch: 5| Step: 3
Training loss: 3.3722339173948077
Validation loss: 2.7494423693374856

Epoch: 5| Step: 4
Training loss: 3.26660667156738
Validation loss: 2.726589740683265

Epoch: 5| Step: 5
Training loss: 3.0726582736414327
Validation loss: 2.7255927031073326

Epoch: 5| Step: 6
Training loss: 2.4846101085809416
Validation loss: 2.72434067439311

Epoch: 5| Step: 7
Training loss: 3.427117220972907
Validation loss: 2.7259990893842216

Epoch: 5| Step: 8
Training loss: 3.1017595896329366
Validation loss: 2.7225912113448305

Epoch: 5| Step: 9
Training loss: 3.0183300476505703
Validation loss: 2.7201915912874

Epoch: 5| Step: 10
Training loss: 3.1809219101234194
Validation loss: 2.722547371145394

Epoch: 58| Step: 0
Training loss: 2.7017912468337157
Validation loss: 2.724748375511878

Epoch: 5| Step: 1
Training loss: 2.7568155275103496
Validation loss: 2.7266175207849868

Epoch: 5| Step: 2
Training loss: 3.3591026018286216
Validation loss: 2.7288495712223697

Epoch: 5| Step: 3
Training loss: 2.961658078082642
Validation loss: 2.7273884039603846

Epoch: 5| Step: 4
Training loss: 3.2220692232866255
Validation loss: 2.7309909038273186

Epoch: 5| Step: 5
Training loss: 2.865243361757379
Validation loss: 2.7560909047206232

Epoch: 5| Step: 6
Training loss: 2.8065572897498803
Validation loss: 2.8377603428526363

Epoch: 5| Step: 7
Training loss: 3.3488296001524076
Validation loss: 2.8292600921085893

Epoch: 5| Step: 8
Training loss: 3.1351954655650744
Validation loss: 2.74425970321371

Epoch: 5| Step: 9
Training loss: 3.501741520987746
Validation loss: 2.7125419834986517

Epoch: 5| Step: 10
Training loss: 2.8552438044626527
Validation loss: 2.712087408799755

Epoch: 59| Step: 0
Training loss: 3.3331905016497463
Validation loss: 2.7163467336861076

Epoch: 5| Step: 1
Training loss: 3.08215300847696
Validation loss: 2.7196750238837897

Epoch: 5| Step: 2
Training loss: 3.0351848429114905
Validation loss: 2.727480866425318

Epoch: 5| Step: 3
Training loss: 3.4410075932102737
Validation loss: 2.749105278109345

Epoch: 5| Step: 4
Training loss: 3.1715624425070352
Validation loss: 2.757022549663229

Epoch: 5| Step: 5
Training loss: 2.6327840650703913
Validation loss: 2.749527140111943

Epoch: 5| Step: 6
Training loss: 3.2604217691757365
Validation loss: 2.7340251439790726

Epoch: 5| Step: 7
Training loss: 2.9481365719427197
Validation loss: 2.72448258113941

Epoch: 5| Step: 8
Training loss: 2.8949371341606347
Validation loss: 2.7153511012985048

Epoch: 5| Step: 9
Training loss: 2.9333921888978156
Validation loss: 2.7120741769514596

Epoch: 5| Step: 10
Training loss: 2.9835221435072907
Validation loss: 2.708490946106303

Epoch: 60| Step: 0
Training loss: 2.978713972647788
Validation loss: 2.7089645527323976

Epoch: 5| Step: 1
Training loss: 3.3378619108533076
Validation loss: 2.7054534439688185

Epoch: 5| Step: 2
Training loss: 3.2319406387429828
Validation loss: 2.701879938825841

Epoch: 5| Step: 3
Training loss: 3.3599472623046855
Validation loss: 2.7003054362897836

Epoch: 5| Step: 4
Training loss: 3.3312393445959247
Validation loss: 2.701356731373511

Epoch: 5| Step: 5
Training loss: 3.1095459857490115
Validation loss: 2.7150177033571117

Epoch: 5| Step: 6
Training loss: 2.835265192885713
Validation loss: 2.7378781315838174

Epoch: 5| Step: 7
Training loss: 2.704011804724212
Validation loss: 2.76386682905537

Epoch: 5| Step: 8
Training loss: 2.8746694291844066
Validation loss: 2.7330465326002673

Epoch: 5| Step: 9
Training loss: 2.5814370814917575
Validation loss: 2.7124351900502366

Epoch: 5| Step: 10
Training loss: 3.133845361172389
Validation loss: 2.703372057990441

Epoch: 61| Step: 0
Training loss: 3.333367887953628
Validation loss: 2.695534695143978

Epoch: 5| Step: 1
Training loss: 2.554106853421577
Validation loss: 2.698350804371857

Epoch: 5| Step: 2
Training loss: 3.3667973338789716
Validation loss: 2.699628298326803

Epoch: 5| Step: 3
Training loss: 3.3290043058817305
Validation loss: 2.7012440709009065

Epoch: 5| Step: 4
Training loss: 2.910671848987411
Validation loss: 2.703951981617694

Epoch: 5| Step: 5
Training loss: 3.254654119487968
Validation loss: 2.7063309839330856

Epoch: 5| Step: 6
Training loss: 2.3589709611749154
Validation loss: 2.7049544341116496

Epoch: 5| Step: 7
Training loss: 3.026609191376822
Validation loss: 2.7074372019835713

Epoch: 5| Step: 8
Training loss: 3.224514733998806
Validation loss: 2.7099551063097196

Epoch: 5| Step: 9
Training loss: 3.227260708023334
Validation loss: 2.708812412520201

Epoch: 5| Step: 10
Training loss: 2.7688640011294323
Validation loss: 2.7074789812141016

Epoch: 62| Step: 0
Training loss: 2.8732939924421927
Validation loss: 2.704703005128997

Epoch: 5| Step: 1
Training loss: 3.0712111228186987
Validation loss: 2.702482532329683

Epoch: 5| Step: 2
Training loss: 3.0378966461039565
Validation loss: 2.701032111083763

Epoch: 5| Step: 3
Training loss: 2.737562055189245
Validation loss: 2.696397038318851

Epoch: 5| Step: 4
Training loss: 3.1276144154063363
Validation loss: 2.694082782910803

Epoch: 5| Step: 5
Training loss: 3.2880109614725543
Validation loss: 2.6923456752098676

Epoch: 5| Step: 6
Training loss: 2.9027758106020194
Validation loss: 2.6911798768906947

Epoch: 5| Step: 7
Training loss: 2.8609731408424777
Validation loss: 2.6899620467866

Epoch: 5| Step: 8
Training loss: 3.424412174318977
Validation loss: 2.688961053532901

Epoch: 5| Step: 9
Training loss: 2.9876840829996687
Validation loss: 2.689407678897045

Epoch: 5| Step: 10
Training loss: 3.07293045989136
Validation loss: 2.6868093594780227

Epoch: 63| Step: 0
Training loss: 2.7547233938387534
Validation loss: 2.6987735611539425

Epoch: 5| Step: 1
Training loss: 3.286071141926889
Validation loss: 2.692218297897282

Epoch: 5| Step: 2
Training loss: 3.2449166083531353
Validation loss: 2.6805686031883122

Epoch: 5| Step: 3
Training loss: 3.2733173211736157
Validation loss: 2.6869763214440567

Epoch: 5| Step: 4
Training loss: 2.9824818303465266
Validation loss: 2.681776688614041

Epoch: 5| Step: 5
Training loss: 2.8961035696130226
Validation loss: 2.6826741416690174

Epoch: 5| Step: 6
Training loss: 2.7655893959296747
Validation loss: 2.68535341128668

Epoch: 5| Step: 7
Training loss: 3.099061663959187
Validation loss: 2.684184701197552

Epoch: 5| Step: 8
Training loss: 2.836745302101791
Validation loss: 2.6827147173604513

Epoch: 5| Step: 9
Training loss: 3.215859012967481
Validation loss: 2.6836665735416747

Epoch: 5| Step: 10
Training loss: 2.9483846735505086
Validation loss: 2.682594517496839

Epoch: 64| Step: 0
Training loss: 2.699199847584411
Validation loss: 2.681947948982538

Epoch: 5| Step: 1
Training loss: 2.6223154418704784
Validation loss: 2.683146411503834

Epoch: 5| Step: 2
Training loss: 2.9141073351317974
Validation loss: 2.6978805684645617

Epoch: 5| Step: 3
Training loss: 2.7765706162556794
Validation loss: 2.707639118386287

Epoch: 5| Step: 4
Training loss: 3.221324298610186
Validation loss: 2.6963703169287685

Epoch: 5| Step: 5
Training loss: 3.277226915425294
Validation loss: 2.681434583459516

Epoch: 5| Step: 6
Training loss: 3.239478171911943
Validation loss: 2.6812115066679096

Epoch: 5| Step: 7
Training loss: 3.1478186062969726
Validation loss: 2.682746959594298

Epoch: 5| Step: 8
Training loss: 3.114615619879077
Validation loss: 2.68026404312

Epoch: 5| Step: 9
Training loss: 3.2852356455458622
Validation loss: 2.6824245303291776

Epoch: 5| Step: 10
Training loss: 2.8580229016955427
Validation loss: 2.6819005470562653

Epoch: 65| Step: 0
Training loss: 2.8885469132348356
Validation loss: 2.68297212648894

Epoch: 5| Step: 1
Training loss: 3.2290422641212744
Validation loss: 2.6840271227946

Epoch: 5| Step: 2
Training loss: 2.846250168603918
Validation loss: 2.6899356293492978

Epoch: 5| Step: 3
Training loss: 3.394570301037603
Validation loss: 2.6859243495406653

Epoch: 5| Step: 4
Training loss: 3.1714603547672406
Validation loss: 2.685834209564465

Epoch: 5| Step: 5
Training loss: 3.4593929521186184
Validation loss: 2.6806205981637534

Epoch: 5| Step: 6
Training loss: 3.0678025097901442
Validation loss: 2.6852473285334484

Epoch: 5| Step: 7
Training loss: 2.762339736639517
Validation loss: 2.687220883976984

Epoch: 5| Step: 8
Training loss: 2.5511921994111266
Validation loss: 2.6910393148935223

Epoch: 5| Step: 9
Training loss: 2.7931289733598965
Validation loss: 2.6987400009381246

Epoch: 5| Step: 10
Training loss: 2.881526174156013
Validation loss: 2.6967214170622986

Epoch: 66| Step: 0
Training loss: 3.152601493877591
Validation loss: 2.7039187625260417

Epoch: 5| Step: 1
Training loss: 2.4665144443796585
Validation loss: 2.6941375744441856

Epoch: 5| Step: 2
Training loss: 3.53912407356239
Validation loss: 2.69857073914985

Epoch: 5| Step: 3
Training loss: 3.204004678653725
Validation loss: 2.683615761007307

Epoch: 5| Step: 4
Training loss: 3.011783663474402
Validation loss: 2.676659625967733

Epoch: 5| Step: 5
Training loss: 2.5724348680204754
Validation loss: 2.673418258645984

Epoch: 5| Step: 6
Training loss: 2.960322575390427
Validation loss: 2.6751194135938605

Epoch: 5| Step: 7
Training loss: 3.427574810433132
Validation loss: 2.6729385551430043

Epoch: 5| Step: 8
Training loss: 3.046085666235827
Validation loss: 2.6708498412146784

Epoch: 5| Step: 9
Training loss: 2.597915613520413
Validation loss: 2.6761983097480346

Epoch: 5| Step: 10
Training loss: 3.00886703434753
Validation loss: 2.671030558410266

Epoch: 67| Step: 0
Training loss: 2.4413165022566563
Validation loss: 2.6724248604682925

Epoch: 5| Step: 1
Training loss: 2.5023555149131704
Validation loss: 2.67602435442469

Epoch: 5| Step: 2
Training loss: 3.364684269732504
Validation loss: 2.674219567575206

Epoch: 5| Step: 3
Training loss: 3.1155850299808105
Validation loss: 2.6794968987529875

Epoch: 5| Step: 4
Training loss: 3.167151782037202
Validation loss: 2.6787645227394985

Epoch: 5| Step: 5
Training loss: 2.549315424263003
Validation loss: 2.6777278474955093

Epoch: 5| Step: 6
Training loss: 3.299839657442698
Validation loss: 2.676675552779227

Epoch: 5| Step: 7
Training loss: 3.287257625797567
Validation loss: 2.6965122980788414

Epoch: 5| Step: 8
Training loss: 2.6548452814284214
Validation loss: 2.6875198088800896

Epoch: 5| Step: 9
Training loss: 3.351675889735824
Validation loss: 2.6825277869505975

Epoch: 5| Step: 10
Training loss: 3.1986794488780528
Validation loss: 2.6758167393535013

Epoch: 68| Step: 0
Training loss: 2.9376868330606962
Validation loss: 2.6727612981657827

Epoch: 5| Step: 1
Training loss: 2.2928063304246717
Validation loss: 2.6676977904594095

Epoch: 5| Step: 2
Training loss: 3.0572319653133757
Validation loss: 2.6659967929590107

Epoch: 5| Step: 3
Training loss: 2.9789004618190553
Validation loss: 2.6680249560615485

Epoch: 5| Step: 4
Training loss: 3.4197949920244612
Validation loss: 2.660808392284346

Epoch: 5| Step: 5
Training loss: 2.7139870149418455
Validation loss: 2.666437683028839

Epoch: 5| Step: 6
Training loss: 3.100922871702874
Validation loss: 2.6660439333922232

Epoch: 5| Step: 7
Training loss: 3.738056363443673
Validation loss: 2.6690939727865177

Epoch: 5| Step: 8
Training loss: 3.2853022666531566
Validation loss: 2.6685462936355324

Epoch: 5| Step: 9
Training loss: 2.4551648448598704
Validation loss: 2.668587109117485

Epoch: 5| Step: 10
Training loss: 2.66752287907607
Validation loss: 2.672711796704053

Epoch: 69| Step: 0
Training loss: 2.102396973071249
Validation loss: 2.6788254834866443

Epoch: 5| Step: 1
Training loss: 3.1048577241351305
Validation loss: 2.693404569772187

Epoch: 5| Step: 2
Training loss: 2.784578710226167
Validation loss: 2.6911686389455904

Epoch: 5| Step: 3
Training loss: 2.8849900867946356
Validation loss: 2.673968869803281

Epoch: 5| Step: 4
Training loss: 2.649802787208171
Validation loss: 2.6578925886413054

Epoch: 5| Step: 5
Training loss: 3.2905174534857484
Validation loss: 2.6625417202789885

Epoch: 5| Step: 6
Training loss: 2.947589833683906
Validation loss: 2.6581755953126733

Epoch: 5| Step: 7
Training loss: 3.1031414788337788
Validation loss: 2.656508744031888

Epoch: 5| Step: 8
Training loss: 3.2297474656722933
Validation loss: 2.6555208497479703

Epoch: 5| Step: 9
Training loss: 3.0072965897846964
Validation loss: 2.6552586307001236

Epoch: 5| Step: 10
Training loss: 3.7204368035427335
Validation loss: 2.6594809930564294

Epoch: 70| Step: 0
Training loss: 3.345989154941748
Validation loss: 2.655243596924927

Epoch: 5| Step: 1
Training loss: 3.0614407322859942
Validation loss: 2.656366103238953

Epoch: 5| Step: 2
Training loss: 2.799981379447057
Validation loss: 2.6543749943302677

Epoch: 5| Step: 3
Training loss: 3.1759370997851946
Validation loss: 2.6530181159403328

Epoch: 5| Step: 4
Training loss: 3.0042678357433172
Validation loss: 2.6581959467663903

Epoch: 5| Step: 5
Training loss: 2.972947536237842
Validation loss: 2.6600857270683016

Epoch: 5| Step: 6
Training loss: 2.2992261414015367
Validation loss: 2.6598861533363762

Epoch: 5| Step: 7
Training loss: 3.6747917116267055
Validation loss: 2.6543000236543928

Epoch: 5| Step: 8
Training loss: 3.12088825566272
Validation loss: 2.6526954856592604

Epoch: 5| Step: 9
Training loss: 2.303835436540216
Validation loss: 2.649947213088112

Epoch: 5| Step: 10
Training loss: 2.951896290763919
Validation loss: 2.651510967389308

Epoch: 71| Step: 0
Training loss: 3.459880727795935
Validation loss: 2.6558742365986356

Epoch: 5| Step: 1
Training loss: 2.3897079005168145
Validation loss: 2.66089388932808

Epoch: 5| Step: 2
Training loss: 3.185155118222067
Validation loss: 2.6590780338070905

Epoch: 5| Step: 3
Training loss: 3.0484503952527904
Validation loss: 2.657440426456955

Epoch: 5| Step: 4
Training loss: 2.828985093984644
Validation loss: 2.6526418038761923

Epoch: 5| Step: 5
Training loss: 2.8152890257905265
Validation loss: 2.6482787945459725

Epoch: 5| Step: 6
Training loss: 3.3406023558231897
Validation loss: 2.644776738346607

Epoch: 5| Step: 7
Training loss: 2.755152210800956
Validation loss: 2.6493248343138656

Epoch: 5| Step: 8
Training loss: 3.0035674818118956
Validation loss: 2.647025094684347

Epoch: 5| Step: 9
Training loss: 2.7952989794349246
Validation loss: 2.6464841241075474

Epoch: 5| Step: 10
Training loss: 3.30107377240229
Validation loss: 2.663108744692587

Epoch: 72| Step: 0
Training loss: 3.492829334238602
Validation loss: 2.6612861718412355

Epoch: 5| Step: 1
Training loss: 2.879054983119495
Validation loss: 2.673631886010564

Epoch: 5| Step: 2
Training loss: 2.7047916632504907
Validation loss: 2.6710174312676274

Epoch: 5| Step: 3
Training loss: 3.1867953250828216
Validation loss: 2.6544064971639716

Epoch: 5| Step: 4
Training loss: 3.076460334937515
Validation loss: 2.644218968408757

Epoch: 5| Step: 5
Training loss: 2.552068832252462
Validation loss: 2.6399735935288264

Epoch: 5| Step: 6
Training loss: 3.267482831423893
Validation loss: 2.63865224251764

Epoch: 5| Step: 7
Training loss: 3.123126116636579
Validation loss: 2.6389259182142366

Epoch: 5| Step: 8
Training loss: 2.4491530414144753
Validation loss: 2.6364874936700593

Epoch: 5| Step: 9
Training loss: 2.8830564648950165
Validation loss: 2.6398175946821425

Epoch: 5| Step: 10
Training loss: 3.1280841104462596
Validation loss: 2.6412299950289544

Epoch: 73| Step: 0
Training loss: 2.7133335221624035
Validation loss: 2.641728831073107

Epoch: 5| Step: 1
Training loss: 2.9620842235472806
Validation loss: 2.6480107654690634

Epoch: 5| Step: 2
Training loss: 2.9023762799951887
Validation loss: 2.6542850655810626

Epoch: 5| Step: 3
Training loss: 3.1136204858993977
Validation loss: 2.671136087658539

Epoch: 5| Step: 4
Training loss: 3.02494265919714
Validation loss: 2.6817092675805654

Epoch: 5| Step: 5
Training loss: 2.898714365935485
Validation loss: 2.697791605299801

Epoch: 5| Step: 6
Training loss: 3.0567463914408917
Validation loss: 2.7186308275845343

Epoch: 5| Step: 7
Training loss: 2.9832611402020524
Validation loss: 2.695704749552837

Epoch: 5| Step: 8
Training loss: 2.7983040169169877
Validation loss: 2.6619217921437217

Epoch: 5| Step: 9
Training loss: 3.265790287197139
Validation loss: 2.6343297984152825

Epoch: 5| Step: 10
Training loss: 3.2015156494406334
Validation loss: 2.6343073921421394

Epoch: 74| Step: 0
Training loss: 2.934020396166262
Validation loss: 2.632512798981132

Epoch: 5| Step: 1
Training loss: 3.2864296856985282
Validation loss: 2.6358100694438797

Epoch: 5| Step: 2
Training loss: 3.0443397342312886
Validation loss: 2.637553054881703

Epoch: 5| Step: 3
Training loss: 3.0297731557603798
Validation loss: 2.6387631266716824

Epoch: 5| Step: 4
Training loss: 3.055906867051143
Validation loss: 2.636885681094155

Epoch: 5| Step: 5
Training loss: 3.371162917752535
Validation loss: 2.6431467299328704

Epoch: 5| Step: 6
Training loss: 2.9856947931473417
Validation loss: 2.642010511640918

Epoch: 5| Step: 7
Training loss: 2.2328068492222606
Validation loss: 2.6410901467645838

Epoch: 5| Step: 8
Training loss: 2.8323176377286448
Validation loss: 2.6393374848843103

Epoch: 5| Step: 9
Training loss: 2.9531782841795065
Validation loss: 2.6376432722343974

Epoch: 5| Step: 10
Training loss: 3.0793488678734082
Validation loss: 2.6400137058615747

Epoch: 75| Step: 0
Training loss: 3.269851213155846
Validation loss: 2.6371731099338414

Epoch: 5| Step: 1
Training loss: 3.093468084880672
Validation loss: 2.6352899039305706

Epoch: 5| Step: 2
Training loss: 3.0258878492611307
Validation loss: 2.6379043573957746

Epoch: 5| Step: 3
Training loss: 2.7589986265814397
Validation loss: 2.6424119367439274

Epoch: 5| Step: 4
Training loss: 2.703377331549301
Validation loss: 2.6488757177341666

Epoch: 5| Step: 5
Training loss: 3.3093657150354434
Validation loss: 2.65375120410698

Epoch: 5| Step: 6
Training loss: 2.737313136163603
Validation loss: 2.690161924190149

Epoch: 5| Step: 7
Training loss: 3.0989493404653308
Validation loss: 2.7399520519840688

Epoch: 5| Step: 8
Training loss: 2.4028661144485026
Validation loss: 2.7359793714092144

Epoch: 5| Step: 9
Training loss: 3.370524511977304
Validation loss: 2.73705016267787

Epoch: 5| Step: 10
Training loss: 3.126432777012755
Validation loss: 2.7446083349622037

Epoch: 76| Step: 0
Training loss: 2.735341800344058
Validation loss: 2.7304823302345076

Epoch: 5| Step: 1
Training loss: 3.979378353433228
Validation loss: 2.721478390801045

Epoch: 5| Step: 2
Training loss: 2.291874431093019
Validation loss: 2.7054852569727394

Epoch: 5| Step: 3
Training loss: 3.0430720144043706
Validation loss: 2.694253316230061

Epoch: 5| Step: 4
Training loss: 3.331257523461984
Validation loss: 2.6969413544877976

Epoch: 5| Step: 5
Training loss: 3.094523785858282
Validation loss: 2.6945372696123675

Epoch: 5| Step: 6
Training loss: 2.5953740929650357
Validation loss: 2.6865010791058017

Epoch: 5| Step: 7
Training loss: 2.7244396963574244
Validation loss: 2.6877406661917886

Epoch: 5| Step: 8
Training loss: 2.986478533552865
Validation loss: 2.6784297416938427

Epoch: 5| Step: 9
Training loss: 3.0337179303448756
Validation loss: 2.6751995089323244

Epoch: 5| Step: 10
Training loss: 3.0932975977718904
Validation loss: 2.6689887633355256

Epoch: 77| Step: 0
Training loss: 3.0320126861971164
Validation loss: 2.6517412673738856

Epoch: 5| Step: 1
Training loss: 2.9613956308363165
Validation loss: 2.630163884444732

Epoch: 5| Step: 2
Training loss: 3.2085251854016117
Validation loss: 2.622767125267458

Epoch: 5| Step: 3
Training loss: 2.8746063958126804
Validation loss: 2.6254910265191103

Epoch: 5| Step: 4
Training loss: 2.720063955312446
Validation loss: 2.623366678374699

Epoch: 5| Step: 5
Training loss: 3.2020693644456983
Validation loss: 2.6290628036495125

Epoch: 5| Step: 6
Training loss: 2.7954190689677785
Validation loss: 2.6315917514539184

Epoch: 5| Step: 7
Training loss: 2.743505699039169
Validation loss: 2.6415266786424043

Epoch: 5| Step: 8
Training loss: 3.1803354263941155
Validation loss: 2.631513480876331

Epoch: 5| Step: 9
Training loss: 2.896894758994524
Validation loss: 2.640080842911724

Epoch: 5| Step: 10
Training loss: 3.0038160848789235
Validation loss: 2.6457036729209173

Epoch: 78| Step: 0
Training loss: 3.3367404373453775
Validation loss: 2.642441831027619

Epoch: 5| Step: 1
Training loss: 2.6114722863336723
Validation loss: 2.6346276784426013

Epoch: 5| Step: 2
Training loss: 2.1653469419114377
Validation loss: 2.6307621386949913

Epoch: 5| Step: 3
Training loss: 2.935668861560153
Validation loss: 2.643818107609539

Epoch: 5| Step: 4
Training loss: 3.2429346901160234
Validation loss: 2.625104506561369

Epoch: 5| Step: 5
Training loss: 3.8202749301178587
Validation loss: 2.635523069750687

Epoch: 5| Step: 6
Training loss: 2.7436399607218553
Validation loss: 2.6181601271929638

Epoch: 5| Step: 7
Training loss: 2.5413458783272724
Validation loss: 2.617937788894061

Epoch: 5| Step: 8
Training loss: 2.846919881590422
Validation loss: 2.6163338246177275

Epoch: 5| Step: 9
Training loss: 3.0827543041461225
Validation loss: 2.619937219839029

Epoch: 5| Step: 10
Training loss: 3.022078965413273
Validation loss: 2.6199866205421944

Epoch: 79| Step: 0
Training loss: 3.370586617914565
Validation loss: 2.6191806149498356

Epoch: 5| Step: 1
Training loss: 3.2558315484151317
Validation loss: 2.61949393390654

Epoch: 5| Step: 2
Training loss: 3.0987034455095714
Validation loss: 2.6202585308348105

Epoch: 5| Step: 3
Training loss: 2.5724830622435175
Validation loss: 2.618918959235884

Epoch: 5| Step: 4
Training loss: 2.9877038734494428
Validation loss: 2.617045596026597

Epoch: 5| Step: 5
Training loss: 2.630373042523526
Validation loss: 2.614308804199706

Epoch: 5| Step: 6
Training loss: 2.6779746762332595
Validation loss: 2.6138129964716317

Epoch: 5| Step: 7
Training loss: 3.0481861912285613
Validation loss: 2.6151972361570373

Epoch: 5| Step: 8
Training loss: 2.811193289789041
Validation loss: 2.6353663959707796

Epoch: 5| Step: 9
Training loss: 3.155204373131869
Validation loss: 2.6868097783533504

Epoch: 5| Step: 10
Training loss: 2.954409204022356
Validation loss: 2.7684507400072027

Epoch: 80| Step: 0
Training loss: 2.820916108607801
Validation loss: 2.782967199902046

Epoch: 5| Step: 1
Training loss: 2.9522421188204073
Validation loss: 2.821273063377735

Epoch: 5| Step: 2
Training loss: 2.6331435541585346
Validation loss: 2.7968710475794483

Epoch: 5| Step: 3
Training loss: 2.921624647216619
Validation loss: 2.7140604351164144

Epoch: 5| Step: 4
Training loss: 3.260060218769721
Validation loss: 2.630275760949078

Epoch: 5| Step: 5
Training loss: 2.4721653166185407
Validation loss: 2.6103606449958954

Epoch: 5| Step: 6
Training loss: 2.9282786325966437
Validation loss: 2.6180434929344325

Epoch: 5| Step: 7
Training loss: 3.61098348603953
Validation loss: 2.62959582201325

Epoch: 5| Step: 8
Training loss: 3.3442825891470025
Validation loss: 2.634390189495956

Epoch: 5| Step: 9
Training loss: 2.6529580754584834
Validation loss: 2.6448918651388604

Epoch: 5| Step: 10
Training loss: 3.2571618324577956
Validation loss: 2.6354166893645123

Epoch: 81| Step: 0
Training loss: 2.8041820017455312
Validation loss: 2.6324596161844505

Epoch: 5| Step: 1
Training loss: 3.211914507876603
Validation loss: 2.627591257065555

Epoch: 5| Step: 2
Training loss: 3.304990208967656
Validation loss: 2.621973555919142

Epoch: 5| Step: 3
Training loss: 2.9773026795108293
Validation loss: 2.622212075562078

Epoch: 5| Step: 4
Training loss: 3.194421322135355
Validation loss: 2.6216225315735286

Epoch: 5| Step: 5
Training loss: 2.4001381278025935
Validation loss: 2.6197535613321556

Epoch: 5| Step: 6
Training loss: 3.0252137794302874
Validation loss: 2.6201035538115054

Epoch: 5| Step: 7
Training loss: 3.090251910116869
Validation loss: 2.617748270825817

Epoch: 5| Step: 8
Training loss: 2.949483574099343
Validation loss: 2.615120380623378

Epoch: 5| Step: 9
Training loss: 2.8987905282184943
Validation loss: 2.6129214653812642

Epoch: 5| Step: 10
Training loss: 2.930544633729499
Validation loss: 2.6131455578603506

Epoch: 82| Step: 0
Training loss: 3.1416665243322472
Validation loss: 2.614632363900037

Epoch: 5| Step: 1
Training loss: 3.040325304495116
Validation loss: 2.6067742442792974

Epoch: 5| Step: 2
Training loss: 2.304412411581874
Validation loss: 2.6057676241759724

Epoch: 5| Step: 3
Training loss: 2.5741081619241775
Validation loss: 2.610939469110918

Epoch: 5| Step: 4
Training loss: 3.206823530451363
Validation loss: 2.6105082389816436

Epoch: 5| Step: 5
Training loss: 3.1005422610112725
Validation loss: 2.619976720123331

Epoch: 5| Step: 6
Training loss: 3.549203520063488
Validation loss: 2.625534595991827

Epoch: 5| Step: 7
Training loss: 3.1414004455072586
Validation loss: 2.6235539437475017

Epoch: 5| Step: 8
Training loss: 2.493979261371743
Validation loss: 2.6232364529743886

Epoch: 5| Step: 9
Training loss: 2.68895478018988
Validation loss: 2.6467678101586185

Epoch: 5| Step: 10
Training loss: 3.107056640030154
Validation loss: 2.6505230746682313

Epoch: 83| Step: 0
Training loss: 2.92878729659334
Validation loss: 2.690200486753052

Epoch: 5| Step: 1
Training loss: 3.0974507401977616
Validation loss: 2.6450382785759365

Epoch: 5| Step: 2
Training loss: 3.123598776427772
Validation loss: 2.61496220502334

Epoch: 5| Step: 3
Training loss: 2.462899337378028
Validation loss: 2.604711752337195

Epoch: 5| Step: 4
Training loss: 2.8250995280870037
Validation loss: 2.6061798058708203

Epoch: 5| Step: 5
Training loss: 2.8630177791681644
Validation loss: 2.6026764324882703

Epoch: 5| Step: 6
Training loss: 3.2493018354105763
Validation loss: 2.6067245292593486

Epoch: 5| Step: 7
Training loss: 3.146570148873568
Validation loss: 2.601736752501507

Epoch: 5| Step: 8
Training loss: 3.071740980513687
Validation loss: 2.6023424304803617

Epoch: 5| Step: 9
Training loss: 2.5097562203435175
Validation loss: 2.6088261053092716

Epoch: 5| Step: 10
Training loss: 3.2188969550797792
Validation loss: 2.6014560494272265

Epoch: 84| Step: 0
Training loss: 3.277963209205271
Validation loss: 2.6043170030740757

Epoch: 5| Step: 1
Training loss: 2.5319086795507597
Validation loss: 2.6027283376187627

Epoch: 5| Step: 2
Training loss: 2.7065431008845584
Validation loss: 2.6014624500064127

Epoch: 5| Step: 3
Training loss: 2.592371838748387
Validation loss: 2.5982427381083597

Epoch: 5| Step: 4
Training loss: 2.657627780601913
Validation loss: 2.5990921033100616

Epoch: 5| Step: 5
Training loss: 2.815318581422853
Validation loss: 2.5988960075332073

Epoch: 5| Step: 6
Training loss: 3.3541458950623735
Validation loss: 2.603843448064294

Epoch: 5| Step: 7
Training loss: 2.7790099992493253
Validation loss: 2.5998279056278384

Epoch: 5| Step: 8
Training loss: 3.085974893464109
Validation loss: 2.607908020627518

Epoch: 5| Step: 9
Training loss: 3.424761386550831
Validation loss: 2.6058791038637295

Epoch: 5| Step: 10
Training loss: 3.01804298351057
Validation loss: 2.6061730686543902

Epoch: 85| Step: 0
Training loss: 3.2233304514932883
Validation loss: 2.6089330530698316

Epoch: 5| Step: 1
Training loss: 2.4719891122744886
Validation loss: 2.604620968148899

Epoch: 5| Step: 2
Training loss: 2.9159778508207244
Validation loss: 2.6119236953353355

Epoch: 5| Step: 3
Training loss: 2.3516734150934573
Validation loss: 2.6265209321423706

Epoch: 5| Step: 4
Training loss: 3.087873484149532
Validation loss: 2.6278891682900665

Epoch: 5| Step: 5
Training loss: 2.945826154283753
Validation loss: 2.6444075423652333

Epoch: 5| Step: 6
Training loss: 3.152750019804604
Validation loss: 2.6512617571094323

Epoch: 5| Step: 7
Training loss: 2.696834941402954
Validation loss: 2.646592132562607

Epoch: 5| Step: 8
Training loss: 3.5714344624062044
Validation loss: 2.6279786940813996

Epoch: 5| Step: 9
Training loss: 2.752140772468213
Validation loss: 2.6172242187902004

Epoch: 5| Step: 10
Training loss: 2.9958655159768663
Validation loss: 2.605364902266326

Epoch: 86| Step: 0
Training loss: 3.429938861090721
Validation loss: 2.6012872152842803

Epoch: 5| Step: 1
Training loss: 2.7322412503402833
Validation loss: 2.592303153595717

Epoch: 5| Step: 2
Training loss: 2.8358182855775365
Validation loss: 2.5999829957499068

Epoch: 5| Step: 3
Training loss: 2.877199409752728
Validation loss: 2.605221149863271

Epoch: 5| Step: 4
Training loss: 3.5236331859981926
Validation loss: 2.6060121119755597

Epoch: 5| Step: 5
Training loss: 2.525219739662579
Validation loss: 2.603332361932229

Epoch: 5| Step: 6
Training loss: 2.5062131921819315
Validation loss: 2.6050323963683972

Epoch: 5| Step: 7
Training loss: 3.2501612403192754
Validation loss: 2.601642382123739

Epoch: 5| Step: 8
Training loss: 2.863332875451202
Validation loss: 2.6032976924699205

Epoch: 5| Step: 9
Training loss: 2.6388489658838177
Validation loss: 2.602555885192079

Epoch: 5| Step: 10
Training loss: 3.3316935002472605
Validation loss: 2.5962071033939256

Epoch: 87| Step: 0
Training loss: 2.7935862038746904
Validation loss: 2.597307644759892

Epoch: 5| Step: 1
Training loss: 2.451858290654991
Validation loss: 2.595708248912038

Epoch: 5| Step: 2
Training loss: 3.459343467782345
Validation loss: 2.6076302853467896

Epoch: 5| Step: 3
Training loss: 2.9080319427876713
Validation loss: 2.660086589618697

Epoch: 5| Step: 4
Training loss: 3.043264430987163
Validation loss: 2.7370106987867553

Epoch: 5| Step: 5
Training loss: 2.918458460883559
Validation loss: 2.7244742789994194

Epoch: 5| Step: 6
Training loss: 2.9978117909664737
Validation loss: 2.6863379860245242

Epoch: 5| Step: 7
Training loss: 3.171909726709146
Validation loss: 2.626156658079535

Epoch: 5| Step: 8
Training loss: 3.0574255182359793
Validation loss: 2.5980406014289867

Epoch: 5| Step: 9
Training loss: 3.076810294615236
Validation loss: 2.5934516971427297

Epoch: 5| Step: 10
Training loss: 2.4150513040530828
Validation loss: 2.5893626343646288

Epoch: 88| Step: 0
Training loss: 2.771441189817262
Validation loss: 2.592250904231862

Epoch: 5| Step: 1
Training loss: 2.824631108192605
Validation loss: 2.5992406448899903

Epoch: 5| Step: 2
Training loss: 2.9367809633087445
Validation loss: 2.59252455567237

Epoch: 5| Step: 3
Training loss: 3.245180224099988
Validation loss: 2.591904855782488

Epoch: 5| Step: 4
Training loss: 3.231683615655966
Validation loss: 2.592938255239472

Epoch: 5| Step: 5
Training loss: 3.2519806915122897
Validation loss: 2.59156437646818

Epoch: 5| Step: 6
Training loss: 2.4521628272676157
Validation loss: 2.5917401840053875

Epoch: 5| Step: 7
Training loss: 3.1523735489317244
Validation loss: 2.5859553348223776

Epoch: 5| Step: 8
Training loss: 2.782803048273621
Validation loss: 2.5889226006288415

Epoch: 5| Step: 9
Training loss: 3.1533410292270077
Validation loss: 2.58699605781298

Epoch: 5| Step: 10
Training loss: 2.515730766774051
Validation loss: 2.591509992750827

Epoch: 89| Step: 0
Training loss: 3.2230977443794995
Validation loss: 2.590341929673259

Epoch: 5| Step: 1
Training loss: 2.40897927998919
Validation loss: 2.5961472816245226

Epoch: 5| Step: 2
Training loss: 2.9832502712287035
Validation loss: 2.590958327551572

Epoch: 5| Step: 3
Training loss: 3.271680701898237
Validation loss: 2.594391261826905

Epoch: 5| Step: 4
Training loss: 2.907024977527834
Validation loss: 2.5899572959262045

Epoch: 5| Step: 5
Training loss: 2.975933338864586
Validation loss: 2.5933863472253726

Epoch: 5| Step: 6
Training loss: 2.856118771399455
Validation loss: 2.591143665919843

Epoch: 5| Step: 7
Training loss: 2.6628419647538513
Validation loss: 2.5929044355126476

Epoch: 5| Step: 8
Training loss: 3.047700897179215
Validation loss: 2.586567051276767

Epoch: 5| Step: 9
Training loss: 3.084081782324113
Validation loss: 2.590787892016449

Epoch: 5| Step: 10
Training loss: 2.632313304631543
Validation loss: 2.5846015074730486

Epoch: 90| Step: 0
Training loss: 3.2715333485140348
Validation loss: 2.5928712066032524

Epoch: 5| Step: 1
Training loss: 2.5558797404932356
Validation loss: 2.6054724516023393

Epoch: 5| Step: 2
Training loss: 3.0526629907580762
Validation loss: 2.627548086599548

Epoch: 5| Step: 3
Training loss: 2.92560848851588
Validation loss: 2.641098749844631

Epoch: 5| Step: 4
Training loss: 2.727019525825251
Validation loss: 2.6492553449067233

Epoch: 5| Step: 5
Training loss: 2.786807989601103
Validation loss: 2.624603790446292

Epoch: 5| Step: 6
Training loss: 2.995264766752552
Validation loss: 2.605803699121125

Epoch: 5| Step: 7
Training loss: 3.009965081756929
Validation loss: 2.5903808564406074

Epoch: 5| Step: 8
Training loss: 2.6840888264961964
Validation loss: 2.5821905324183323

Epoch: 5| Step: 9
Training loss: 2.7392386641487594
Validation loss: 2.577387314728634

Epoch: 5| Step: 10
Training loss: 3.4652292065135195
Validation loss: 2.576945086887759

Epoch: 91| Step: 0
Training loss: 3.0125536522104115
Validation loss: 2.5730799539767006

Epoch: 5| Step: 1
Training loss: 3.401547466870418
Validation loss: 2.5761094991383713

Epoch: 5| Step: 2
Training loss: 2.4697700035102983
Validation loss: 2.5767997918041163

Epoch: 5| Step: 3
Training loss: 3.408316309232718
Validation loss: 2.578738719076118

Epoch: 5| Step: 4
Training loss: 2.5252219112062573
Validation loss: 2.57764766745266

Epoch: 5| Step: 5
Training loss: 2.921513989019582
Validation loss: 2.572959936072981

Epoch: 5| Step: 6
Training loss: 2.881590214500778
Validation loss: 2.575030998818359

Epoch: 5| Step: 7
Training loss: 2.8876071332072706
Validation loss: 2.5722898603492

Epoch: 5| Step: 8
Training loss: 2.475399863569138
Validation loss: 2.581352156622059

Epoch: 5| Step: 9
Training loss: 3.2869175964369113
Validation loss: 2.596058557598885

Epoch: 5| Step: 10
Training loss: 2.7811406146195004
Validation loss: 2.6096014089535116

Epoch: 92| Step: 0
Training loss: 2.618733328172151
Validation loss: 2.6246942614570345

Epoch: 5| Step: 1
Training loss: 2.982354403808674
Validation loss: 2.6295446617119023

Epoch: 5| Step: 2
Training loss: 3.4854266713590314
Validation loss: 2.626973251861579

Epoch: 5| Step: 3
Training loss: 2.7735440945624825
Validation loss: 2.628926464301071

Epoch: 5| Step: 4
Training loss: 2.444831191400208
Validation loss: 2.6173563095111403

Epoch: 5| Step: 5
Training loss: 3.085087217214026
Validation loss: 2.607257299301719

Epoch: 5| Step: 6
Training loss: 3.103462310006575
Validation loss: 2.5971595414485322

Epoch: 5| Step: 7
Training loss: 2.7707127901019217
Validation loss: 2.5926752276597633

Epoch: 5| Step: 8
Training loss: 2.875979381100062
Validation loss: 2.5800655068735474

Epoch: 5| Step: 9
Training loss: 2.5308340225327646
Validation loss: 2.5826660436321522

Epoch: 5| Step: 10
Training loss: 3.2802022078452766
Validation loss: 2.5808813411299774

Epoch: 93| Step: 0
Training loss: 3.329271432487775
Validation loss: 2.5770418658102643

Epoch: 5| Step: 1
Training loss: 2.613847383265781
Validation loss: 2.579289420672988

Epoch: 5| Step: 2
Training loss: 3.0796164370408197
Validation loss: 2.5747806832604376

Epoch: 5| Step: 3
Training loss: 2.8038136600609245
Validation loss: 2.5754443280591244

Epoch: 5| Step: 4
Training loss: 3.245090150447856
Validation loss: 2.574334406169729

Epoch: 5| Step: 5
Training loss: 2.7087000867525264
Validation loss: 2.573835977822139

Epoch: 5| Step: 6
Training loss: 2.8879390300221868
Validation loss: 2.5834434008165106

Epoch: 5| Step: 7
Training loss: 2.9674721627990555
Validation loss: 2.5971872756809473

Epoch: 5| Step: 8
Training loss: 2.9896639149579767
Validation loss: 2.5986565780047735

Epoch: 5| Step: 9
Training loss: 2.421774979033408
Validation loss: 2.60115617621927

Epoch: 5| Step: 10
Training loss: 2.952112256332204
Validation loss: 2.6089966339830553

Epoch: 94| Step: 0
Training loss: 3.3298617563964164
Validation loss: 2.588839333436235

Epoch: 5| Step: 1
Training loss: 2.813039092214357
Validation loss: 2.584447839291297

Epoch: 5| Step: 2
Training loss: 2.621024072576572
Validation loss: 2.5820884480441997

Epoch: 5| Step: 3
Training loss: 2.918232324995549
Validation loss: 2.580738786856382

Epoch: 5| Step: 4
Training loss: 2.2183789225001047
Validation loss: 2.5720676414414934

Epoch: 5| Step: 5
Training loss: 3.0627856997136784
Validation loss: 2.573916280209898

Epoch: 5| Step: 6
Training loss: 3.4719491588456313
Validation loss: 2.574655301528334

Epoch: 5| Step: 7
Training loss: 2.7370554837452334
Validation loss: 2.575895031281843

Epoch: 5| Step: 8
Training loss: 2.9266468596023527
Validation loss: 2.571936385535909

Epoch: 5| Step: 9
Training loss: 2.754925997617695
Validation loss: 2.5781531468182135

Epoch: 5| Step: 10
Training loss: 3.054825801596645
Validation loss: 2.579986305581242

Epoch: 95| Step: 0
Training loss: 2.5533087039818727
Validation loss: 2.584434422153323

Epoch: 5| Step: 1
Training loss: 3.0760052348217615
Validation loss: 2.5816798944184107

Epoch: 5| Step: 2
Training loss: 2.792092864872255
Validation loss: 2.6042229988814403

Epoch: 5| Step: 3
Training loss: 3.470362932645135
Validation loss: 2.624539516079506

Epoch: 5| Step: 4
Training loss: 3.3646416122695912
Validation loss: 2.648424111802902

Epoch: 5| Step: 5
Training loss: 2.684101173370095
Validation loss: 2.5985284903134964

Epoch: 5| Step: 6
Training loss: 2.762000688678454
Validation loss: 2.5765550155539403

Epoch: 5| Step: 7
Training loss: 2.799120209620604
Validation loss: 2.564004759891296

Epoch: 5| Step: 8
Training loss: 3.0670540095083445
Validation loss: 2.5615383467695563

Epoch: 5| Step: 9
Training loss: 2.872890195846785
Validation loss: 2.563963499419657

Epoch: 5| Step: 10
Training loss: 2.379535961272956
Validation loss: 2.561621346489086

Epoch: 96| Step: 0
Training loss: 2.666376624625975
Validation loss: 2.5630323055746

Epoch: 5| Step: 1
Training loss: 2.5682365591179654
Validation loss: 2.564044220982771

Epoch: 5| Step: 2
Training loss: 3.021031726154111
Validation loss: 2.56436617908121

Epoch: 5| Step: 3
Training loss: 2.975347636451791
Validation loss: 2.5579886463565664

Epoch: 5| Step: 4
Training loss: 2.6276082296248684
Validation loss: 2.5564630479764876

Epoch: 5| Step: 5
Training loss: 3.1609961450994364
Validation loss: 2.568431770723329

Epoch: 5| Step: 6
Training loss: 2.732087230027037
Validation loss: 2.5802480011637834

Epoch: 5| Step: 7
Training loss: 2.5599249950984473
Validation loss: 2.5881661291475067

Epoch: 5| Step: 8
Training loss: 3.823215497192916
Validation loss: 2.5915485453552836

Epoch: 5| Step: 9
Training loss: 2.746827810183745
Validation loss: 2.5926614575762925

Epoch: 5| Step: 10
Training loss: 2.9415860266794778
Validation loss: 2.596786816629424

Epoch: 97| Step: 0
Training loss: 2.4522476085083778
Validation loss: 2.59098102162715

Epoch: 5| Step: 1
Training loss: 2.9797407188523826
Validation loss: 2.5955062941335116

Epoch: 5| Step: 2
Training loss: 2.637931307559873
Validation loss: 2.588514717618556

Epoch: 5| Step: 3
Training loss: 2.5331626541798964
Validation loss: 2.5753301770995196

Epoch: 5| Step: 4
Training loss: 3.2646921093867025
Validation loss: 2.5771719435391045

Epoch: 5| Step: 5
Training loss: 3.0452468042935465
Validation loss: 2.580993822217325

Epoch: 5| Step: 6
Training loss: 3.336704425070954
Validation loss: 2.5745148292182147

Epoch: 5| Step: 7
Training loss: 3.17049840360444
Validation loss: 2.5771015162980486

Epoch: 5| Step: 8
Training loss: 2.775340456311171
Validation loss: 2.579018757546797

Epoch: 5| Step: 9
Training loss: 2.8078359289789248
Validation loss: 2.5749473311918485

Epoch: 5| Step: 10
Training loss: 2.760372540583096
Validation loss: 2.5879715858962995

Epoch: 98| Step: 0
Training loss: 2.2458451373958424
Validation loss: 2.576949838225477

Epoch: 5| Step: 1
Training loss: 3.146977012518804
Validation loss: 2.5645137315756847

Epoch: 5| Step: 2
Training loss: 2.5630807916214153
Validation loss: 2.572837392113742

Epoch: 5| Step: 3
Training loss: 2.9458047875330164
Validation loss: 2.579692184513454

Epoch: 5| Step: 4
Training loss: 2.6941217860707694
Validation loss: 2.5964503054115955

Epoch: 5| Step: 5
Training loss: 3.21486332865393
Validation loss: 2.593084012364477

Epoch: 5| Step: 6
Training loss: 3.0997778228389783
Validation loss: 2.598857165398806

Epoch: 5| Step: 7
Training loss: 3.1908472475067473
Validation loss: 2.5829640249219348

Epoch: 5| Step: 8
Training loss: 2.497436544320539
Validation loss: 2.581031999512391

Epoch: 5| Step: 9
Training loss: 3.2527421973418313
Validation loss: 2.580216181097955

Epoch: 5| Step: 10
Training loss: 2.8411883879265165
Validation loss: 2.5789475576540726

Epoch: 99| Step: 0
Training loss: 2.8589352128812986
Validation loss: 2.582443307932673

Epoch: 5| Step: 1
Training loss: 2.6405114143816877
Validation loss: 2.585403629665517

Epoch: 5| Step: 2
Training loss: 3.085146413880639
Validation loss: 2.5776293305747715

Epoch: 5| Step: 3
Training loss: 2.8830164395279434
Validation loss: 2.5797630150485507

Epoch: 5| Step: 4
Training loss: 3.0117497819818264
Validation loss: 2.585754762815372

Epoch: 5| Step: 5
Training loss: 3.1397535339136327
Validation loss: 2.5787612602251255

Epoch: 5| Step: 6
Training loss: 2.7561897496149586
Validation loss: 2.5703850721041954

Epoch: 5| Step: 7
Training loss: 2.3999444160382635
Validation loss: 2.575122466790566

Epoch: 5| Step: 8
Training loss: 3.1268523257781333
Validation loss: 2.5941628874834723

Epoch: 5| Step: 9
Training loss: 2.758694861500124
Validation loss: 2.625986862041912

Epoch: 5| Step: 10
Training loss: 3.1092556877823405
Validation loss: 2.6539286411512846

Epoch: 100| Step: 0
Training loss: 3.2565145491256433
Validation loss: 2.6294812256896574

Epoch: 5| Step: 1
Training loss: 2.8307836691701866
Validation loss: 2.572234134750879

Epoch: 5| Step: 2
Training loss: 2.382388618163313
Validation loss: 2.5487648546482164

Epoch: 5| Step: 3
Training loss: 3.1511978657157664
Validation loss: 2.54559156334803

Epoch: 5| Step: 4
Training loss: 2.6964374350814433
Validation loss: 2.5465887817191013

Epoch: 5| Step: 5
Training loss: 3.079772043833761
Validation loss: 2.5485562502130334

Epoch: 5| Step: 6
Training loss: 2.783019456659004
Validation loss: 2.5459514659457345

Epoch: 5| Step: 7
Training loss: 2.3143418683702297
Validation loss: 2.5469522107784934

Epoch: 5| Step: 8
Training loss: 3.4145321730263904
Validation loss: 2.5468444802258468

Epoch: 5| Step: 9
Training loss: 3.1083409109014712
Validation loss: 2.5515659881916197

Epoch: 5| Step: 10
Training loss: 2.9371305192748687
Validation loss: 2.543687103792783

Epoch: 101| Step: 0
Training loss: 2.9856745102554236
Validation loss: 2.5523081633777367

Epoch: 5| Step: 1
Training loss: 3.2795050931513825
Validation loss: 2.559941185513076

Epoch: 5| Step: 2
Training loss: 3.363823646467831
Validation loss: 2.568626191003089

Epoch: 5| Step: 3
Training loss: 2.8312840811255002
Validation loss: 2.554956700007252

Epoch: 5| Step: 4
Training loss: 2.6918056507269243
Validation loss: 2.551419000672343

Epoch: 5| Step: 5
Training loss: 2.9730275707948866
Validation loss: 2.549494198994023

Epoch: 5| Step: 6
Training loss: 3.04331864388616
Validation loss: 2.5505874706668097

Epoch: 5| Step: 7
Training loss: 2.8741350946179023
Validation loss: 2.5541674390141043

Epoch: 5| Step: 8
Training loss: 2.8851933765889073
Validation loss: 2.5608278346618762

Epoch: 5| Step: 9
Training loss: 2.193910741758642
Validation loss: 2.5641560099468936

Epoch: 5| Step: 10
Training loss: 2.426448318732844
Validation loss: 2.5873099856293833

Epoch: 102| Step: 0
Training loss: 2.8914699659771586
Validation loss: 2.611817376516628

Epoch: 5| Step: 1
Training loss: 2.3559419020725367
Validation loss: 2.666121291207219

Epoch: 5| Step: 2
Training loss: 3.34046946235748
Validation loss: 2.723421975769435

Epoch: 5| Step: 3
Training loss: 2.641758602078872
Validation loss: 2.6808209215018817

Epoch: 5| Step: 4
Training loss: 2.717851687698518
Validation loss: 2.6514915682336917

Epoch: 5| Step: 5
Training loss: 2.347442871146107
Validation loss: 2.579955894301964

Epoch: 5| Step: 6
Training loss: 3.0599999635983135
Validation loss: 2.5461522585552285

Epoch: 5| Step: 7
Training loss: 2.999361924025499
Validation loss: 2.541260897884502

Epoch: 5| Step: 8
Training loss: 3.189834487830586
Validation loss: 2.53642427128016

Epoch: 5| Step: 9
Training loss: 2.908034894290495
Validation loss: 2.543657821714955

Epoch: 5| Step: 10
Training loss: 3.3196387471286672
Validation loss: 2.557869291439619

Epoch: 103| Step: 0
Training loss: 2.483556456644351
Validation loss: 2.554858210497419

Epoch: 5| Step: 1
Training loss: 3.016051425333518
Validation loss: 2.5554121292498886

Epoch: 5| Step: 2
Training loss: 2.7480278746511324
Validation loss: 2.5423348259845557

Epoch: 5| Step: 3
Training loss: 2.8374149057677736
Validation loss: 2.541581535897337

Epoch: 5| Step: 4
Training loss: 3.1735085476125664
Validation loss: 2.538942007987393

Epoch: 5| Step: 5
Training loss: 2.7204446882091218
Validation loss: 2.5427957007791555

Epoch: 5| Step: 6
Training loss: 2.7049617811171913
Validation loss: 2.5572034470022174

Epoch: 5| Step: 7
Training loss: 3.055360061479767
Validation loss: 2.577030265424127

Epoch: 5| Step: 8
Training loss: 3.2490883061979354
Validation loss: 2.6071419757720884

Epoch: 5| Step: 9
Training loss: 2.8131051154324846
Validation loss: 2.702437736969745

Epoch: 5| Step: 10
Training loss: 3.345391414304877
Validation loss: 2.8420265237179985

Epoch: 104| Step: 0
Training loss: 3.1645524010685757
Validation loss: 2.838107616741501

Epoch: 5| Step: 1
Training loss: 3.2739796337503253
Validation loss: 2.7721784683479123

Epoch: 5| Step: 2
Training loss: 3.3007863061629172
Validation loss: 2.690753510357868

Epoch: 5| Step: 3
Training loss: 2.776686192184739
Validation loss: 2.6223525375815115

Epoch: 5| Step: 4
Training loss: 3.2087256616933266
Validation loss: 2.604835198677928

Epoch: 5| Step: 5
Training loss: 2.6139716133146593
Validation loss: 2.6147338140136953

Epoch: 5| Step: 6
Training loss: 3.260289848875655
Validation loss: 2.6173968438786455

Epoch: 5| Step: 7
Training loss: 2.687692058709016
Validation loss: 2.6119666715698973

Epoch: 5| Step: 8
Training loss: 3.117977185717024
Validation loss: 2.6114942651649065

Epoch: 5| Step: 9
Training loss: 2.6837813799035843
Validation loss: 2.619546557863475

Epoch: 5| Step: 10
Training loss: 2.6510684468553634
Validation loss: 2.5861164672137456

Epoch: 105| Step: 0
Training loss: 2.789855929657632
Validation loss: 2.5977703510138097

Epoch: 5| Step: 1
Training loss: 2.6767275285590792
Validation loss: 2.5949250559445183

Epoch: 5| Step: 2
Training loss: 2.8409124617123114
Validation loss: 2.6112720367111737

Epoch: 5| Step: 3
Training loss: 3.0084237406522893
Validation loss: 2.6156003191877293

Epoch: 5| Step: 4
Training loss: 2.71864432644735
Validation loss: 2.6283631186009973

Epoch: 5| Step: 5
Training loss: 2.8971097223521185
Validation loss: 2.6766486048153837

Epoch: 5| Step: 6
Training loss: 3.3714732357650385
Validation loss: 2.7071279353325592

Epoch: 5| Step: 7
Training loss: 2.4531524073533655
Validation loss: 2.735029957232242

Epoch: 5| Step: 8
Training loss: 2.9921992926701364
Validation loss: 2.74414990556047

Epoch: 5| Step: 9
Training loss: 3.5549501426838286
Validation loss: 2.7766812914449504

Epoch: 5| Step: 10
Training loss: 3.3515064439331734
Validation loss: 2.756335072621417

Epoch: 106| Step: 0
Training loss: 2.926717570158356
Validation loss: 2.73280720523062

Epoch: 5| Step: 1
Training loss: 3.119306030856181
Validation loss: 2.710013324941061

Epoch: 5| Step: 2
Training loss: 2.785332758421205
Validation loss: 2.6732327764661368

Epoch: 5| Step: 3
Training loss: 3.0845576424520544
Validation loss: 2.6465635163356613

Epoch: 5| Step: 4
Training loss: 2.624155817075049
Validation loss: 2.6319341111080203

Epoch: 5| Step: 5
Training loss: 2.4494416593264368
Validation loss: 2.6344860949701214

Epoch: 5| Step: 6
Training loss: 3.769232450511803
Validation loss: 2.650419585842292

Epoch: 5| Step: 7
Training loss: 3.6438001940036173
Validation loss: 2.647311714135508

Epoch: 5| Step: 8
Training loss: 2.912591721559859
Validation loss: 2.5919730480535614

Epoch: 5| Step: 9
Training loss: 2.4302532359222258
Validation loss: 2.5793882057730517

Epoch: 5| Step: 10
Training loss: 2.7078034591744
Validation loss: 2.58690802133621

Epoch: 107| Step: 0
Training loss: 3.2634055156212516
Validation loss: 2.6226130227764806

Epoch: 5| Step: 1
Training loss: 2.9389680481193072
Validation loss: 2.6627566833413763

Epoch: 5| Step: 2
Training loss: 3.044574984499918
Validation loss: 2.715613965133692

Epoch: 5| Step: 3
Training loss: 3.0663934986796977
Validation loss: 2.705417674383998

Epoch: 5| Step: 4
Training loss: 2.6290049201394026
Validation loss: 2.660830522407303

Epoch: 5| Step: 5
Training loss: 2.162578859159249
Validation loss: 2.6440418289953698

Epoch: 5| Step: 6
Training loss: 3.109981458553473
Validation loss: 2.613865534720532

Epoch: 5| Step: 7
Training loss: 3.167739652917675
Validation loss: 2.604534685936183

Epoch: 5| Step: 8
Training loss: 3.1868509866034573
Validation loss: 2.574914665054654

Epoch: 5| Step: 9
Training loss: 2.684827318374906
Validation loss: 2.5622669026913725

Epoch: 5| Step: 10
Training loss: 2.649212659076786
Validation loss: 2.5593639645744304

Epoch: 108| Step: 0
Training loss: 2.5815575146323937
Validation loss: 2.5484028465004456

Epoch: 5| Step: 1
Training loss: 2.778957836840197
Validation loss: 2.540058915192417

Epoch: 5| Step: 2
Training loss: 2.950632324985364
Validation loss: 2.532647311705811

Epoch: 5| Step: 3
Training loss: 3.1318033547962094
Validation loss: 2.5253419249229356

Epoch: 5| Step: 4
Training loss: 2.9502785502677407
Validation loss: 2.520304810996486

Epoch: 5| Step: 5
Training loss: 2.8791561768741407
Validation loss: 2.5305755306096227

Epoch: 5| Step: 6
Training loss: 2.5443802298874165
Validation loss: 2.5354797944575194

Epoch: 5| Step: 7
Training loss: 2.5127598338733153
Validation loss: 2.546406725824343

Epoch: 5| Step: 8
Training loss: 2.9962075421981855
Validation loss: 2.5946287239930435

Epoch: 5| Step: 9
Training loss: 3.605594388977655
Validation loss: 2.6465966445641937

Epoch: 5| Step: 10
Training loss: 2.5171240847725582
Validation loss: 2.6279476763266207

Epoch: 109| Step: 0
Training loss: 2.9716718249259277
Validation loss: 2.5985710527402426

Epoch: 5| Step: 1
Training loss: 2.5643489958866907
Validation loss: 2.654045895913397

Epoch: 5| Step: 2
Training loss: 2.670422611008737
Validation loss: 2.662466205407677

Epoch: 5| Step: 3
Training loss: 2.9583013470133857
Validation loss: 2.6433546085719875

Epoch: 5| Step: 4
Training loss: 2.85134761470952
Validation loss: 2.5836762406782583

Epoch: 5| Step: 5
Training loss: 2.6996992155594275
Validation loss: 2.533610669284901

Epoch: 5| Step: 6
Training loss: 3.3266108117418622
Validation loss: 2.5253558022006426

Epoch: 5| Step: 7
Training loss: 2.9892546221601726
Validation loss: 2.5158727716589873

Epoch: 5| Step: 8
Training loss: 2.971828751550136
Validation loss: 2.515930522061591

Epoch: 5| Step: 9
Training loss: 2.814765949852227
Validation loss: 2.5209314338581414

Epoch: 5| Step: 10
Training loss: 2.6603320003490727
Validation loss: 2.5185392229837347

Epoch: 110| Step: 0
Training loss: 3.2108374067238272
Validation loss: 2.5221274225633876

Epoch: 5| Step: 1
Training loss: 2.804872299524202
Validation loss: 2.527324189988161

Epoch: 5| Step: 2
Training loss: 2.703083809775812
Validation loss: 2.5232651504120915

Epoch: 5| Step: 3
Training loss: 2.9499751655697084
Validation loss: 2.518398211835953

Epoch: 5| Step: 4
Training loss: 3.082868764434449
Validation loss: 2.5213010457971357

Epoch: 5| Step: 5
Training loss: 2.6222217025953882
Validation loss: 2.519183470601538

Epoch: 5| Step: 6
Training loss: 2.583736070393301
Validation loss: 2.520499074469208

Epoch: 5| Step: 7
Training loss: 2.6223581735027577
Validation loss: 2.531609826014268

Epoch: 5| Step: 8
Training loss: 3.2367026389179343
Validation loss: 2.5415929445387357

Epoch: 5| Step: 9
Training loss: 3.2300651694889235
Validation loss: 2.6059593101329073

Epoch: 5| Step: 10
Training loss: 2.462717145456496
Validation loss: 2.62758802274442

Epoch: 111| Step: 0
Training loss: 3.346275730426004
Validation loss: 2.7083707183706105

Epoch: 5| Step: 1
Training loss: 2.909679563255658
Validation loss: 2.6263943244167214

Epoch: 5| Step: 2
Training loss: 2.4710915000150306
Validation loss: 2.5930428191371657

Epoch: 5| Step: 3
Training loss: 2.5716649355566297
Validation loss: 2.5740277634362116

Epoch: 5| Step: 4
Training loss: 3.0478326319601945
Validation loss: 2.561054871711408

Epoch: 5| Step: 5
Training loss: 2.5870047496137163
Validation loss: 2.544597910057632

Epoch: 5| Step: 6
Training loss: 3.2785252474949638
Validation loss: 2.5297230873152716

Epoch: 5| Step: 7
Training loss: 3.0787266177219963
Validation loss: 2.5247362643010445

Epoch: 5| Step: 8
Training loss: 2.8764727593492556
Validation loss: 2.52211595484009

Epoch: 5| Step: 9
Training loss: 2.4689101155182422
Validation loss: 2.5297841464138893

Epoch: 5| Step: 10
Training loss: 2.860130502084238
Validation loss: 2.5265251442080903

Epoch: 112| Step: 0
Training loss: 3.43700613462263
Validation loss: 2.5282746743179176

Epoch: 5| Step: 1
Training loss: 2.8984404612729144
Validation loss: 2.5279656506464407

Epoch: 5| Step: 2
Training loss: 2.982560809683429
Validation loss: 2.5342054919102868

Epoch: 5| Step: 3
Training loss: 2.694392658229756
Validation loss: 2.533536825227076

Epoch: 5| Step: 4
Training loss: 3.353078361535291
Validation loss: 2.5414123626475384

Epoch: 5| Step: 5
Training loss: 2.879719219560876
Validation loss: 2.538014018594357

Epoch: 5| Step: 6
Training loss: 2.3375628376230715
Validation loss: 2.542392564182844

Epoch: 5| Step: 7
Training loss: 2.6928869860846776
Validation loss: 2.5507349392841974

Epoch: 5| Step: 8
Training loss: 2.781782377917007
Validation loss: 2.5646876759345507

Epoch: 5| Step: 9
Training loss: 2.3997728438960686
Validation loss: 2.5847107955807203

Epoch: 5| Step: 10
Training loss: 2.610502810222616
Validation loss: 2.601462598811069

Epoch: 113| Step: 0
Training loss: 1.9973139607254389
Validation loss: 2.6034248956038875

Epoch: 5| Step: 1
Training loss: 3.1262506652611686
Validation loss: 2.576363548920236

Epoch: 5| Step: 2
Training loss: 2.6324987932077453
Validation loss: 2.569114170578358

Epoch: 5| Step: 3
Training loss: 2.6941842634116258
Validation loss: 2.5883970090006243

Epoch: 5| Step: 4
Training loss: 2.95838129425572
Validation loss: 2.6157528638843637

Epoch: 5| Step: 5
Training loss: 2.7838333647723643
Validation loss: 2.6007879749241796

Epoch: 5| Step: 6
Training loss: 3.054030091552777
Validation loss: 2.574037563211635

Epoch: 5| Step: 7
Training loss: 3.4508725928700525
Validation loss: 2.5536852508798433

Epoch: 5| Step: 8
Training loss: 3.1012985155584394
Validation loss: 2.5427307730301267

Epoch: 5| Step: 9
Training loss: 2.5051494017798692
Validation loss: 2.5296323542911203

Epoch: 5| Step: 10
Training loss: 2.7784432811374433
Validation loss: 2.5258204429346445

Epoch: 114| Step: 0
Training loss: 2.9949191301282747
Validation loss: 2.516958700587649

Epoch: 5| Step: 1
Training loss: 2.6320586894080695
Validation loss: 2.522243388789775

Epoch: 5| Step: 2
Training loss: 2.2967723382337084
Validation loss: 2.5231719488609183

Epoch: 5| Step: 3
Training loss: 2.8763681556408365
Validation loss: 2.5178850981978846

Epoch: 5| Step: 4
Training loss: 3.2512336737000274
Validation loss: 2.5184297593842864

Epoch: 5| Step: 5
Training loss: 2.7340271646786776
Validation loss: 2.5289658693200505

Epoch: 5| Step: 6
Training loss: 3.0342090753827042
Validation loss: 2.5252108829125013

Epoch: 5| Step: 7
Training loss: 3.0913859881743755
Validation loss: 2.5242563200102355

Epoch: 5| Step: 8
Training loss: 2.823210519133396
Validation loss: 2.5288459566250245

Epoch: 5| Step: 9
Training loss: 3.046160335356018
Validation loss: 2.5426083415165714

Epoch: 5| Step: 10
Training loss: 2.509793743762716
Validation loss: 2.538599129699868

Epoch: 115| Step: 0
Training loss: 2.660563926434907
Validation loss: 2.534644098370739

Epoch: 5| Step: 1
Training loss: 3.037745173100327
Validation loss: 2.5351507468490677

Epoch: 5| Step: 2
Training loss: 2.6091216187033717
Validation loss: 2.539171426990736

Epoch: 5| Step: 3
Training loss: 2.926444982968633
Validation loss: 2.5531223069923072

Epoch: 5| Step: 4
Training loss: 2.3688511809226003
Validation loss: 2.558632275553471

Epoch: 5| Step: 5
Training loss: 2.6656342733206224
Validation loss: 2.564986818306074

Epoch: 5| Step: 6
Training loss: 2.8657547283864058
Validation loss: 2.5623535556601

Epoch: 5| Step: 7
Training loss: 3.132823611118466
Validation loss: 2.5477695661858664

Epoch: 5| Step: 8
Training loss: 2.6064182364414186
Validation loss: 2.5450701674882255

Epoch: 5| Step: 9
Training loss: 3.0735506255096565
Validation loss: 2.5344600642123916

Epoch: 5| Step: 10
Training loss: 3.27884433297955
Validation loss: 2.518551092269278

Epoch: 116| Step: 0
Training loss: 3.1134751473692757
Validation loss: 2.517697903332952

Epoch: 5| Step: 1
Training loss: 3.3260095884881093
Validation loss: 2.512579281067861

Epoch: 5| Step: 2
Training loss: 3.0294034386982815
Validation loss: 2.5118400406526615

Epoch: 5| Step: 3
Training loss: 2.887504584238616
Validation loss: 2.515526217961443

Epoch: 5| Step: 4
Training loss: 2.9297971984670728
Validation loss: 2.5106824634516136

Epoch: 5| Step: 5
Training loss: 3.1735136562959325
Validation loss: 2.5083556935219233

Epoch: 5| Step: 6
Training loss: 2.4440901263487262
Validation loss: 2.5114920301765262

Epoch: 5| Step: 7
Training loss: 2.709183095011735
Validation loss: 2.5176037645534373

Epoch: 5| Step: 8
Training loss: 2.22919915671751
Validation loss: 2.519750731958607

Epoch: 5| Step: 9
Training loss: 2.638104833161164
Validation loss: 2.541269315352403

Epoch: 5| Step: 10
Training loss: 2.680216211593283
Validation loss: 2.5485115342154563

Epoch: 117| Step: 0
Training loss: 2.7177686125821796
Validation loss: 2.5730726359113545

Epoch: 5| Step: 1
Training loss: 3.279519196835803
Validation loss: 2.5683525146183137

Epoch: 5| Step: 2
Training loss: 3.04578211820016
Validation loss: 2.551053428817912

Epoch: 5| Step: 3
Training loss: 3.096076321895734
Validation loss: 2.5568550435020647

Epoch: 5| Step: 4
Training loss: 2.80079197582282
Validation loss: 2.543463516802708

Epoch: 5| Step: 5
Training loss: 2.8250693152371986
Validation loss: 2.524101823884931

Epoch: 5| Step: 6
Training loss: 2.6161033092771375
Validation loss: 2.5204641535741503

Epoch: 5| Step: 7
Training loss: 2.5332734297479504
Validation loss: 2.520204849293313

Epoch: 5| Step: 8
Training loss: 2.8498404541866633
Validation loss: 2.5193073294984534

Epoch: 5| Step: 9
Training loss: 2.7503216295293416
Validation loss: 2.5289071930166185

Epoch: 5| Step: 10
Training loss: 2.69384265572141
Validation loss: 2.5280971339638114

Epoch: 118| Step: 0
Training loss: 2.6893257327025166
Validation loss: 2.5518487031794526

Epoch: 5| Step: 1
Training loss: 2.7571516677100125
Validation loss: 2.5487015203623655

Epoch: 5| Step: 2
Training loss: 3.2145034776823973
Validation loss: 2.5448334871003873

Epoch: 5| Step: 3
Training loss: 3.178807242204733
Validation loss: 2.552817614767916

Epoch: 5| Step: 4
Training loss: 2.7612631501575007
Validation loss: 2.5526012743067636

Epoch: 5| Step: 5
Training loss: 2.340329739087783
Validation loss: 2.5470588336396496

Epoch: 5| Step: 6
Training loss: 3.352000672479166
Validation loss: 2.5324270007740424

Epoch: 5| Step: 7
Training loss: 2.712516390843245
Validation loss: 2.53668775496048

Epoch: 5| Step: 8
Training loss: 2.3268509009069036
Validation loss: 2.5376659778912845

Epoch: 5| Step: 9
Training loss: 3.0713716577725427
Validation loss: 2.5392066681148537

Epoch: 5| Step: 10
Training loss: 2.4505508426419245
Validation loss: 2.5318931786383674

Epoch: 119| Step: 0
Training loss: 2.9916614040091156
Validation loss: 2.537507093156872

Epoch: 5| Step: 1
Training loss: 2.734273156585534
Validation loss: 2.5309921147460073

Epoch: 5| Step: 2
Training loss: 3.0577796836811357
Validation loss: 2.5433919293747653

Epoch: 5| Step: 3
Training loss: 2.3086599479259546
Validation loss: 2.5514884779496665

Epoch: 5| Step: 4
Training loss: 2.314138605178668
Validation loss: 2.545980560533854

Epoch: 5| Step: 5
Training loss: 2.8463908917616383
Validation loss: 2.5572170270651884

Epoch: 5| Step: 6
Training loss: 2.8981709730472547
Validation loss: 2.5698496108776245

Epoch: 5| Step: 7
Training loss: 3.159747914266875
Validation loss: 2.5725812955383534

Epoch: 5| Step: 8
Training loss: 3.078105945818643
Validation loss: 2.5397800852037102

Epoch: 5| Step: 9
Training loss: 2.7471004285087113
Validation loss: 2.5280800601882207

Epoch: 5| Step: 10
Training loss: 2.973812725468715
Validation loss: 2.521220260318552

Epoch: 120| Step: 0
Training loss: 2.8883877731214485
Validation loss: 2.515010259530675

Epoch: 5| Step: 1
Training loss: 3.1319303340739677
Validation loss: 2.515428036409628

Epoch: 5| Step: 2
Training loss: 2.4396725289457253
Validation loss: 2.5279284740364334

Epoch: 5| Step: 3
Training loss: 3.217024405422727
Validation loss: 2.5135892196041043

Epoch: 5| Step: 4
Training loss: 2.5207646153018843
Validation loss: 2.5288831288710005

Epoch: 5| Step: 5
Training loss: 3.0119817200874763
Validation loss: 2.535728575169647

Epoch: 5| Step: 6
Training loss: 2.6331546006529774
Validation loss: 2.5339191755014423

Epoch: 5| Step: 7
Training loss: 3.3094793978642163
Validation loss: 2.537026683891472

Epoch: 5| Step: 8
Training loss: 2.2277905741530457
Validation loss: 2.521103806724441

Epoch: 5| Step: 9
Training loss: 2.643209783674057
Validation loss: 2.5243486406374767

Epoch: 5| Step: 10
Training loss: 2.8851256149157134
Validation loss: 2.515054992695613

Epoch: 121| Step: 0
Training loss: 3.097883757309772
Validation loss: 2.5303205360813936

Epoch: 5| Step: 1
Training loss: 3.069055197897108
Validation loss: 2.5260113146706673

Epoch: 5| Step: 2
Training loss: 2.691096095580422
Validation loss: 2.5259415040340913

Epoch: 5| Step: 3
Training loss: 2.4574806760569574
Validation loss: 2.5220329246097477

Epoch: 5| Step: 4
Training loss: 3.021219075446741
Validation loss: 2.5102082475197074

Epoch: 5| Step: 5
Training loss: 2.818920182802145
Validation loss: 2.515127326532644

Epoch: 5| Step: 6
Training loss: 2.536478082996429
Validation loss: 2.507315827911703

Epoch: 5| Step: 7
Training loss: 2.8254930251667782
Validation loss: 2.5092965545527766

Epoch: 5| Step: 8
Training loss: 2.552771173283452
Validation loss: 2.52330482799832

Epoch: 5| Step: 9
Training loss: 2.706331677338554
Validation loss: 2.5237272677759757

Epoch: 5| Step: 10
Training loss: 3.240192728079627
Validation loss: 2.538931043833088

Epoch: 122| Step: 0
Training loss: 3.0236814730678447
Validation loss: 2.5533216380759636

Epoch: 5| Step: 1
Training loss: 2.906934103896993
Validation loss: 2.5553047553638013

Epoch: 5| Step: 2
Training loss: 2.6052192900278666
Validation loss: 2.550637839633225

Epoch: 5| Step: 3
Training loss: 2.966152138685179
Validation loss: 2.55267458293485

Epoch: 5| Step: 4
Training loss: 2.6611675743142413
Validation loss: 2.5543881029173203

Epoch: 5| Step: 5
Training loss: 2.632925512225837
Validation loss: 2.553038097105582

Epoch: 5| Step: 6
Training loss: 2.5356901808577366
Validation loss: 2.5641168255247653

Epoch: 5| Step: 7
Training loss: 2.8671030141248006
Validation loss: 2.556939084569298

Epoch: 5| Step: 8
Training loss: 2.5279362970003603
Validation loss: 2.554859533027753

Epoch: 5| Step: 9
Training loss: 3.2404386284703515
Validation loss: 2.54483213417482

Epoch: 5| Step: 10
Training loss: 3.0973532914585924
Validation loss: 2.535629116366219

Epoch: 123| Step: 0
Training loss: 2.1369925537979286
Validation loss: 2.537217504760588

Epoch: 5| Step: 1
Training loss: 3.033819623540383
Validation loss: 2.535721000690061

Epoch: 5| Step: 2
Training loss: 2.753185854357241
Validation loss: 2.533142777801436

Epoch: 5| Step: 3
Training loss: 3.2199731373110683
Validation loss: 2.5373174216445906

Epoch: 5| Step: 4
Training loss: 2.408861897774052
Validation loss: 2.5378621752438684

Epoch: 5| Step: 5
Training loss: 2.7507075353234582
Validation loss: 2.5472835432283594

Epoch: 5| Step: 6
Training loss: 3.0286038833997333
Validation loss: 2.5476223143454457

Epoch: 5| Step: 7
Training loss: 2.9594887281597293
Validation loss: 2.5681647218964403

Epoch: 5| Step: 8
Training loss: 2.3815664566701935
Validation loss: 2.5857561805852067

Epoch: 5| Step: 9
Training loss: 3.0146090520690088
Validation loss: 2.6113391695316626

Epoch: 5| Step: 10
Training loss: 3.289894705481733
Validation loss: 2.6010024176644384

Epoch: 124| Step: 0
Training loss: 2.910690524834247
Validation loss: 2.579987278875373

Epoch: 5| Step: 1
Training loss: 2.6592076608655364
Validation loss: 2.562686710773748

Epoch: 5| Step: 2
Training loss: 2.9656723935166043
Validation loss: 2.5466281467502783

Epoch: 5| Step: 3
Training loss: 2.7070109929459423
Validation loss: 2.5390644729139615

Epoch: 5| Step: 4
Training loss: 2.5378530585556107
Validation loss: 2.533545272405003

Epoch: 5| Step: 5
Training loss: 2.796609961882448
Validation loss: 2.5431966293746213

Epoch: 5| Step: 6
Training loss: 2.7114649542601788
Validation loss: 2.5307654298424005

Epoch: 5| Step: 7
Training loss: 2.996054757273562
Validation loss: 2.5286719104986104

Epoch: 5| Step: 8
Training loss: 3.200925788474377
Validation loss: 2.5350974702292817

Epoch: 5| Step: 9
Training loss: 2.820648849592721
Validation loss: 2.5491574365851903

Epoch: 5| Step: 10
Training loss: 2.853733688889356
Validation loss: 2.5572665085714266

Epoch: 125| Step: 0
Training loss: 2.580716489471391
Validation loss: 2.5545907337318776

Epoch: 5| Step: 1
Training loss: 2.7819909812457455
Validation loss: 2.6012230211591967

Epoch: 5| Step: 2
Training loss: 2.7586641806635375
Validation loss: 2.614300732713043

Epoch: 5| Step: 3
Training loss: 2.735510192651294
Validation loss: 2.626958412414858

Epoch: 5| Step: 4
Training loss: 3.205320619920768
Validation loss: 2.644117926293707

Epoch: 5| Step: 5
Training loss: 2.7972682910784497
Validation loss: 2.590503254339467

Epoch: 5| Step: 6
Training loss: 2.8496316303641724
Validation loss: 2.560781124986962

Epoch: 5| Step: 7
Training loss: 2.667427689520524
Validation loss: 2.55380101079674

Epoch: 5| Step: 8
Training loss: 3.00656125683903
Validation loss: 2.5275367442124783

Epoch: 5| Step: 9
Training loss: 2.6428110678349666
Validation loss: 2.525521556174785

Epoch: 5| Step: 10
Training loss: 2.9355645804210737
Validation loss: 2.521041073057775

Epoch: 126| Step: 0
Training loss: 3.38509822032429
Validation loss: 2.5192491059717432

Epoch: 5| Step: 1
Training loss: 2.466668519027977
Validation loss: 2.5171907464638275

Epoch: 5| Step: 2
Training loss: 2.8124598182351
Validation loss: 2.517445333107071

Epoch: 5| Step: 3
Training loss: 2.994241273585574
Validation loss: 2.5176499932945524

Epoch: 5| Step: 4
Training loss: 2.7676590158598056
Validation loss: 2.517848659587157

Epoch: 5| Step: 5
Training loss: 2.908913653023594
Validation loss: 2.523886579147607

Epoch: 5| Step: 6
Training loss: 3.0943846388797502
Validation loss: 2.561033297860608

Epoch: 5| Step: 7
Training loss: 2.119497130330621
Validation loss: 2.560620249497136

Epoch: 5| Step: 8
Training loss: 2.9190121257304043
Validation loss: 2.5791068764468865

Epoch: 5| Step: 9
Training loss: 2.9721820468108553
Validation loss: 2.576406455622497

Epoch: 5| Step: 10
Training loss: 2.4738875422471795
Validation loss: 2.5664119008976742

Epoch: 127| Step: 0
Training loss: 3.154414483585334
Validation loss: 2.5690341711340294

Epoch: 5| Step: 1
Training loss: 2.1154665550954803
Validation loss: 2.593226243397555

Epoch: 5| Step: 2
Training loss: 2.622153782714713
Validation loss: 2.561376275741784

Epoch: 5| Step: 3
Training loss: 2.615096073610422
Validation loss: 2.569912945702343

Epoch: 5| Step: 4
Training loss: 3.1755307932835097
Validation loss: 2.555608523091742

Epoch: 5| Step: 5
Training loss: 2.8483756874228616
Validation loss: 2.5442533888037064

Epoch: 5| Step: 6
Training loss: 2.7774767193303562
Validation loss: 2.5395695096675865

Epoch: 5| Step: 7
Training loss: 3.2404646742769496
Validation loss: 2.537172789495855

Epoch: 5| Step: 8
Training loss: 2.742736065979465
Validation loss: 2.5355031579926446

Epoch: 5| Step: 9
Training loss: 2.421182053399861
Validation loss: 2.5446953308483304

Epoch: 5| Step: 10
Training loss: 3.0456557744391457
Validation loss: 2.557166533047143

Epoch: 128| Step: 0
Training loss: 2.5837262890470125
Validation loss: 2.5537027758747484

Epoch: 5| Step: 1
Training loss: 2.8613897844252336
Validation loss: 2.5701196326815463

Epoch: 5| Step: 2
Training loss: 2.8034488418616714
Validation loss: 2.580995222736879

Epoch: 5| Step: 3
Training loss: 3.227602146934545
Validation loss: 2.5801443912591484

Epoch: 5| Step: 4
Training loss: 2.7840196342049954
Validation loss: 2.5922148918773504

Epoch: 5| Step: 5
Training loss: 2.899468004824081
Validation loss: 2.6136209036743434

Epoch: 5| Step: 6
Training loss: 2.7434984860896625
Validation loss: 2.6352092342380633

Epoch: 5| Step: 7
Training loss: 2.866488919920561
Validation loss: 2.6372756312812835

Epoch: 5| Step: 8
Training loss: 2.6662636889514504
Validation loss: 2.6015111865252294

Epoch: 5| Step: 9
Training loss: 3.108687435022143
Validation loss: 2.5956931280091142

Epoch: 5| Step: 10
Training loss: 2.511560699093923
Validation loss: 2.5752432116644766

Epoch: 129| Step: 0
Training loss: 2.8695117146953635
Validation loss: 2.563709076836749

Epoch: 5| Step: 1
Training loss: 3.201645076612059
Validation loss: 2.560987882268637

Epoch: 5| Step: 2
Training loss: 2.7389186928008518
Validation loss: 2.5439828012353556

Epoch: 5| Step: 3
Training loss: 3.0405832913116866
Validation loss: 2.537197275176926

Epoch: 5| Step: 4
Training loss: 2.3997198895070446
Validation loss: 2.541269327458042

Epoch: 5| Step: 5
Training loss: 2.5596980150742867
Validation loss: 2.541801814845698

Epoch: 5| Step: 6
Training loss: 3.1526276603582537
Validation loss: 2.5325307721432533

Epoch: 5| Step: 7
Training loss: 3.2709685052692543
Validation loss: 2.5243234707440436

Epoch: 5| Step: 8
Training loss: 2.4602915082511077
Validation loss: 2.5218234630053358

Epoch: 5| Step: 9
Training loss: 1.9450055841596212
Validation loss: 2.5260007292755433

Epoch: 5| Step: 10
Training loss: 2.928027361663797
Validation loss: 2.5318533399772365

Epoch: 130| Step: 0
Training loss: 2.6229889750392568
Validation loss: 2.530900551026984

Epoch: 5| Step: 1
Training loss: 3.044758222781059
Validation loss: 2.5444576191379347

Epoch: 5| Step: 2
Training loss: 2.7440964013062414
Validation loss: 2.554040328161298

Epoch: 5| Step: 3
Training loss: 2.832324708664255
Validation loss: 2.5675538830784927

Epoch: 5| Step: 4
Training loss: 2.7397879075711136
Validation loss: 2.556777362715173

Epoch: 5| Step: 5
Training loss: 2.2789969618786676
Validation loss: 2.55753990074452

Epoch: 5| Step: 6
Training loss: 2.823986671799933
Validation loss: 2.557190267876138

Epoch: 5| Step: 7
Training loss: 2.819227099588892
Validation loss: 2.587758206156433

Epoch: 5| Step: 8
Training loss: 3.0218217657660777
Validation loss: 2.594455103754119

Epoch: 5| Step: 9
Training loss: 2.759366297465131
Validation loss: 2.585130658412266

Epoch: 5| Step: 10
Training loss: 3.134185414081124
Validation loss: 2.549881775383687

Epoch: 131| Step: 0
Training loss: 2.615733457296978
Validation loss: 2.531183128228142

Epoch: 5| Step: 1
Training loss: 2.7366882130854564
Validation loss: 2.524229798431297

Epoch: 5| Step: 2
Training loss: 3.0124942953601814
Validation loss: 2.5119777892831436

Epoch: 5| Step: 3
Training loss: 3.027826007455002
Validation loss: 2.5052037374090044

Epoch: 5| Step: 4
Training loss: 2.452167396973449
Validation loss: 2.521207112732691

Epoch: 5| Step: 5
Training loss: 2.809253259721932
Validation loss: 2.512745969671797

Epoch: 5| Step: 6
Training loss: 2.501942642749802
Validation loss: 2.5226364202695644

Epoch: 5| Step: 7
Training loss: 2.690490921348308
Validation loss: 2.541148620279359

Epoch: 5| Step: 8
Training loss: 3.156569965120708
Validation loss: 2.565620965879403

Epoch: 5| Step: 9
Training loss: 2.554869479076132
Validation loss: 2.5700231896046075

Epoch: 5| Step: 10
Training loss: 3.305546930624202
Validation loss: 2.6032201202637886

Epoch: 132| Step: 0
Training loss: 2.9156700793151433
Validation loss: 2.5766214002803296

Epoch: 5| Step: 1
Training loss: 2.7707072829254717
Validation loss: 2.558761035867678

Epoch: 5| Step: 2
Training loss: 2.5649058515436223
Validation loss: 2.542121072619766

Epoch: 5| Step: 3
Training loss: 2.68519839713499
Validation loss: 2.522120671229677

Epoch: 5| Step: 4
Training loss: 3.3211940178623514
Validation loss: 2.5192749859744787

Epoch: 5| Step: 5
Training loss: 2.924569422664369
Validation loss: 2.5167571546681526

Epoch: 5| Step: 6
Training loss: 2.7288507079667896
Validation loss: 2.525817822271892

Epoch: 5| Step: 7
Training loss: 2.7219782988154795
Validation loss: 2.526221122663722

Epoch: 5| Step: 8
Training loss: 3.017728082085062
Validation loss: 2.5661700359415556

Epoch: 5| Step: 9
Training loss: 2.4966206598902585
Validation loss: 2.5626526623783166

Epoch: 5| Step: 10
Training loss: 2.4320663140817746
Validation loss: 2.5263790007284292

Epoch: 133| Step: 0
Training loss: 2.319671028425097
Validation loss: 2.510099850985666

Epoch: 5| Step: 1
Training loss: 2.690203615303268
Validation loss: 2.511061791318817

Epoch: 5| Step: 2
Training loss: 2.7233047041522394
Validation loss: 2.5068945894281716

Epoch: 5| Step: 3
Training loss: 3.0488032572756656
Validation loss: 2.517497322905616

Epoch: 5| Step: 4
Training loss: 2.762716973530981
Validation loss: 2.5131472812987146

Epoch: 5| Step: 5
Training loss: 2.850497279368121
Validation loss: 2.509842153098825

Epoch: 5| Step: 6
Training loss: 3.4159673269705997
Validation loss: 2.5168256728020144

Epoch: 5| Step: 7
Training loss: 2.8671598926846977
Validation loss: 2.5223273410626446

Epoch: 5| Step: 8
Training loss: 2.5210007751173125
Validation loss: 2.5192587000836673

Epoch: 5| Step: 9
Training loss: 2.9662767246873436
Validation loss: 2.5251946332739803

Epoch: 5| Step: 10
Training loss: 2.2748883523897656
Validation loss: 2.5176356865984806

Epoch: 134| Step: 0
Training loss: 3.184984598407007
Validation loss: 2.5206863877795773

Epoch: 5| Step: 1
Training loss: 2.791322876747188
Validation loss: 2.53090228112132

Epoch: 5| Step: 2
Training loss: 2.4772173379809663
Validation loss: 2.5146363805586764

Epoch: 5| Step: 3
Training loss: 2.4884768997478384
Validation loss: 2.5199063056831084

Epoch: 5| Step: 4
Training loss: 2.8364284290124715
Validation loss: 2.5119197938959603

Epoch: 5| Step: 5
Training loss: 2.8228824139495856
Validation loss: 2.51592288390179

Epoch: 5| Step: 6
Training loss: 2.8112378997338783
Validation loss: 2.509259946268607

Epoch: 5| Step: 7
Training loss: 2.2474183000050867
Validation loss: 2.5114086068535997

Epoch: 5| Step: 8
Training loss: 2.9061448273035504
Validation loss: 2.527389864489688

Epoch: 5| Step: 9
Training loss: 2.7223062167108836
Validation loss: 2.5444689771012845

Epoch: 5| Step: 10
Training loss: 3.243392389536746
Validation loss: 2.555023409106063

Epoch: 135| Step: 0
Training loss: 3.422119410595717
Validation loss: 2.5547841386748296

Epoch: 5| Step: 1
Training loss: 2.6256638550329447
Validation loss: 2.541895121496705

Epoch: 5| Step: 2
Training loss: 2.4138250635408376
Validation loss: 2.536863906884968

Epoch: 5| Step: 3
Training loss: 2.759168253807626
Validation loss: 2.536218611688165

Epoch: 5| Step: 4
Training loss: 2.8167667660805447
Validation loss: 2.5290944350239912

Epoch: 5| Step: 5
Training loss: 2.834984989832949
Validation loss: 2.529629284567497

Epoch: 5| Step: 6
Training loss: 2.536212060606038
Validation loss: 2.532914979724677

Epoch: 5| Step: 7
Training loss: 2.7294058852635366
Validation loss: 2.520483601031786

Epoch: 5| Step: 8
Training loss: 2.591749223904932
Validation loss: 2.5430235996930812

Epoch: 5| Step: 9
Training loss: 2.8773770664180653
Validation loss: 2.5475488230988512

Epoch: 5| Step: 10
Training loss: 2.8433859455865433
Validation loss: 2.545830166104827

Epoch: 136| Step: 0
Training loss: 2.684539139761948
Validation loss: 2.539461786949376

Epoch: 5| Step: 1
Training loss: 2.7123572070248705
Validation loss: 2.5539030674736716

Epoch: 5| Step: 2
Training loss: 3.2545802779536
Validation loss: 2.557133986649343

Epoch: 5| Step: 3
Training loss: 3.331185666262875
Validation loss: 2.5640554501904007

Epoch: 5| Step: 4
Training loss: 2.700441472730717
Validation loss: 2.5519410382285157

Epoch: 5| Step: 5
Training loss: 2.5958653292411284
Validation loss: 2.550978123973011

Epoch: 5| Step: 6
Training loss: 2.3485774868418625
Validation loss: 2.535745920966187

Epoch: 5| Step: 7
Training loss: 2.869501079563776
Validation loss: 2.5309750412545284

Epoch: 5| Step: 8
Training loss: 2.3153342328291813
Validation loss: 2.5242430948018666

Epoch: 5| Step: 9
Training loss: 2.933917844218883
Validation loss: 2.5298769564209116

Epoch: 5| Step: 10
Training loss: 2.469483278720347
Validation loss: 2.540984102610268

Epoch: 137| Step: 0
Training loss: 2.5165975834878322
Validation loss: 2.541826889828692

Epoch: 5| Step: 1
Training loss: 2.7068088544727535
Validation loss: 2.5487711954334147

Epoch: 5| Step: 2
Training loss: 2.546946612328383
Validation loss: 2.547568988597116

Epoch: 5| Step: 3
Training loss: 2.997411246747584
Validation loss: 2.544389734275426

Epoch: 5| Step: 4
Training loss: 2.9443365853025822
Validation loss: 2.5398389887595663

Epoch: 5| Step: 5
Training loss: 2.41569133238133
Validation loss: 2.547319578897633

Epoch: 5| Step: 6
Training loss: 2.5207541166947434
Validation loss: 2.5406850855669774

Epoch: 5| Step: 7
Training loss: 2.638490615593821
Validation loss: 2.5343884419736855

Epoch: 5| Step: 8
Training loss: 2.9473957010311715
Validation loss: 2.5348634368567105

Epoch: 5| Step: 9
Training loss: 3.2146669434218076
Validation loss: 2.5277154649162905

Epoch: 5| Step: 10
Training loss: 2.797813045110088
Validation loss: 2.5181774595561675

Epoch: 138| Step: 0
Training loss: 2.98800757657154
Validation loss: 2.521441619577406

Epoch: 5| Step: 1
Training loss: 2.4703856252889502
Validation loss: 2.5239992193709644

Epoch: 5| Step: 2
Training loss: 2.5689246422275307
Validation loss: 2.51997117143735

Epoch: 5| Step: 3
Training loss: 2.553726622203267
Validation loss: 2.5202441813957543

Epoch: 5| Step: 4
Training loss: 2.987908792658683
Validation loss: 2.5253214814322633

Epoch: 5| Step: 5
Training loss: 2.7621872219962085
Validation loss: 2.5346765926979735

Epoch: 5| Step: 6
Training loss: 2.37430401693198
Validation loss: 2.55476002826829

Epoch: 5| Step: 7
Training loss: 3.113622323645596
Validation loss: 2.579218232227821

Epoch: 5| Step: 8
Training loss: 2.586779684894636
Validation loss: 2.5753087626544398

Epoch: 5| Step: 9
Training loss: 2.996643732115408
Validation loss: 2.5609125321920407

Epoch: 5| Step: 10
Training loss: 2.905346309485248
Validation loss: 2.5568992360926632

Epoch: 139| Step: 0
Training loss: 2.528666178303571
Validation loss: 2.522679513157678

Epoch: 5| Step: 1
Training loss: 2.4370359321358976
Validation loss: 2.5126291243374657

Epoch: 5| Step: 2
Training loss: 3.05421369931869
Validation loss: 2.511869415019066

Epoch: 5| Step: 3
Training loss: 3.253729954004546
Validation loss: 2.50803587876424

Epoch: 5| Step: 4
Training loss: 2.7303092156820856
Validation loss: 2.5112860560546406

Epoch: 5| Step: 5
Training loss: 3.120745700340912
Validation loss: 2.5168119522118833

Epoch: 5| Step: 6
Training loss: 2.7793078553015707
Validation loss: 2.5120486482640096

Epoch: 5| Step: 7
Training loss: 2.3801496792055667
Validation loss: 2.4955786072453403

Epoch: 5| Step: 8
Training loss: 2.3755428296184355
Validation loss: 2.504974252648188

Epoch: 5| Step: 9
Training loss: 2.520746928434005
Validation loss: 2.5145764650677425

Epoch: 5| Step: 10
Training loss: 3.1713289439141774
Validation loss: 2.5288242134260805

Epoch: 140| Step: 0
Training loss: 2.585622347617593
Validation loss: 2.54004314205424

Epoch: 5| Step: 1
Training loss: 3.1615147258289498
Validation loss: 2.537695388711295

Epoch: 5| Step: 2
Training loss: 2.796726755656849
Validation loss: 2.530989531850976

Epoch: 5| Step: 3
Training loss: 2.7680293262559887
Validation loss: 2.540759462479581

Epoch: 5| Step: 4
Training loss: 2.680876354156535
Validation loss: 2.5357638186465623

Epoch: 5| Step: 5
Training loss: 2.637699289611959
Validation loss: 2.5348389367224544

Epoch: 5| Step: 6
Training loss: 2.487967143452054
Validation loss: 2.545269263466145

Epoch: 5| Step: 7
Training loss: 2.940130314177122
Validation loss: 2.5330397176951625

Epoch: 5| Step: 8
Training loss: 2.2613369054421217
Validation loss: 2.5201607863559015

Epoch: 5| Step: 9
Training loss: 2.704011099346788
Validation loss: 2.5171023462407405

Epoch: 5| Step: 10
Training loss: 3.303906792662967
Validation loss: 2.5120035064092923

Epoch: 141| Step: 0
Training loss: 2.4306997662102554
Validation loss: 2.508032130461708

Epoch: 5| Step: 1
Training loss: 2.7509913824980203
Validation loss: 2.5162519385694377

Epoch: 5| Step: 2
Training loss: 2.6378740054533005
Validation loss: 2.5142609909640554

Epoch: 5| Step: 3
Training loss: 2.731096929455239
Validation loss: 2.5240403784813314

Epoch: 5| Step: 4
Training loss: 3.000426262136199
Validation loss: 2.53707778285648

Epoch: 5| Step: 5
Training loss: 2.9961399039999486
Validation loss: 2.5462874995610325

Epoch: 5| Step: 6
Training loss: 2.5103402871401257
Validation loss: 2.5610771941292745

Epoch: 5| Step: 7
Training loss: 2.8285542367850347
Validation loss: 2.553599393030377

Epoch: 5| Step: 8
Training loss: 2.652127106798012
Validation loss: 2.561179983850318

Epoch: 5| Step: 9
Training loss: 2.983471638831909
Validation loss: 2.539868061515335

Epoch: 5| Step: 10
Training loss: 2.627333013017479
Validation loss: 2.519022562171369

Epoch: 142| Step: 0
Training loss: 3.082085554565548
Validation loss: 2.5119442481378558

Epoch: 5| Step: 1
Training loss: 2.639777323984155
Validation loss: 2.525414836120237

Epoch: 5| Step: 2
Training loss: 2.6019065102532304
Validation loss: 2.501442290160203

Epoch: 5| Step: 3
Training loss: 2.251583813494282
Validation loss: 2.507293954751209

Epoch: 5| Step: 4
Training loss: 2.532830392537819
Validation loss: 2.4932831022357345

Epoch: 5| Step: 5
Training loss: 2.9082911716964785
Validation loss: 2.5196551121502337

Epoch: 5| Step: 6
Training loss: 2.638124625199867
Validation loss: 2.5176839380240943

Epoch: 5| Step: 7
Training loss: 3.187970145465052
Validation loss: 2.5254084671461583

Epoch: 5| Step: 8
Training loss: 2.4357034958663157
Validation loss: 2.554472360630401

Epoch: 5| Step: 9
Training loss: 3.327198168150867
Validation loss: 2.568252725085729

Epoch: 5| Step: 10
Training loss: 2.3517431652334335
Validation loss: 2.5558244475088086

Epoch: 143| Step: 0
Training loss: 2.9888591531679083
Validation loss: 2.5377459701199037

Epoch: 5| Step: 1
Training loss: 2.6527268325502957
Validation loss: 2.5255428121442174

Epoch: 5| Step: 2
Training loss: 2.408122337452703
Validation loss: 2.5104572798522224

Epoch: 5| Step: 3
Training loss: 2.435386915544584
Validation loss: 2.5130722136709385

Epoch: 5| Step: 4
Training loss: 2.6791758591023065
Validation loss: 2.5033756764087176

Epoch: 5| Step: 5
Training loss: 2.744453645820311
Validation loss: 2.520833268585516

Epoch: 5| Step: 6
Training loss: 3.050323569222309
Validation loss: 2.5102463064766782

Epoch: 5| Step: 7
Training loss: 2.525548943250199
Validation loss: 2.530828534801022

Epoch: 5| Step: 8
Training loss: 2.6566101727607436
Validation loss: 2.5256958051823286

Epoch: 5| Step: 9
Training loss: 2.791070551828969
Validation loss: 2.5390677917273874

Epoch: 5| Step: 10
Training loss: 3.0920140183539377
Validation loss: 2.5341081928985614

Epoch: 144| Step: 0
Training loss: 2.76546939045697
Validation loss: 2.5480382877120444

Epoch: 5| Step: 1
Training loss: 3.248530128850104
Validation loss: 2.5830841566170397

Epoch: 5| Step: 2
Training loss: 2.2091767002234244
Validation loss: 2.606396103659464

Epoch: 5| Step: 3
Training loss: 2.6567267494953963
Validation loss: 2.659930410431684

Epoch: 5| Step: 4
Training loss: 3.185682040117937
Validation loss: 2.7170103507108605

Epoch: 5| Step: 5
Training loss: 3.1188876073901315
Validation loss: 2.592021201427957

Epoch: 5| Step: 6
Training loss: 2.7935027352301414
Validation loss: 2.5314928194327115

Epoch: 5| Step: 7
Training loss: 2.3921825844921636
Validation loss: 2.5232890415692064

Epoch: 5| Step: 8
Training loss: 2.567464624772226
Validation loss: 2.548448776085673

Epoch: 5| Step: 9
Training loss: 2.7582394536879162
Validation loss: 2.5804799669855165

Epoch: 5| Step: 10
Training loss: 3.0930749946725276
Validation loss: 2.5974658344532737

Epoch: 145| Step: 0
Training loss: 2.6885269332141117
Validation loss: 2.609909548136832

Epoch: 5| Step: 1
Training loss: 2.0003457962552242
Validation loss: 2.601331859306502

Epoch: 5| Step: 2
Training loss: 2.8827699901062056
Validation loss: 2.60846502412023

Epoch: 5| Step: 3
Training loss: 2.4864518223967456
Validation loss: 2.626523023836987

Epoch: 5| Step: 4
Training loss: 3.288341017216404
Validation loss: 2.6384971468927843

Epoch: 5| Step: 5
Training loss: 2.953135656912815
Validation loss: 2.6057184674715472

Epoch: 5| Step: 6
Training loss: 2.8267387238201094
Validation loss: 2.589698846966885

Epoch: 5| Step: 7
Training loss: 2.7152554206762427
Validation loss: 2.5794691860597605

Epoch: 5| Step: 8
Training loss: 3.1132869169980575
Validation loss: 2.5618451439980663

Epoch: 5| Step: 9
Training loss: 2.8674931584137746
Validation loss: 2.5626358068271307

Epoch: 5| Step: 10
Training loss: 3.318825350550778
Validation loss: 2.562382265913365

Epoch: 146| Step: 0
Training loss: 2.902431645865814
Validation loss: 2.6107348226433085

Epoch: 5| Step: 1
Training loss: 2.74791543154126
Validation loss: 2.693051699728687

Epoch: 5| Step: 2
Training loss: 3.8055068118894377
Validation loss: 2.646220213729961

Epoch: 5| Step: 3
Training loss: 2.5926480077946903
Validation loss: 2.5854866475742555

Epoch: 5| Step: 4
Training loss: 2.9078692775555717
Validation loss: 2.531628819756789

Epoch: 5| Step: 5
Training loss: 2.1356153690343134
Validation loss: 2.530621318763252

Epoch: 5| Step: 6
Training loss: 3.0697603384403522
Validation loss: 2.514487928075959

Epoch: 5| Step: 7
Training loss: 2.3725268889210853
Validation loss: 2.5003264862599583

Epoch: 5| Step: 8
Training loss: 2.6373192675530106
Validation loss: 2.4957065236020726

Epoch: 5| Step: 9
Training loss: 2.805146076254275
Validation loss: 2.4968303973728627

Epoch: 5| Step: 10
Training loss: 2.2824877163910595
Validation loss: 2.503626707242943

Epoch: 147| Step: 0
Training loss: 2.539849074377782
Validation loss: 2.4987680701847665

Epoch: 5| Step: 1
Training loss: 2.8034148237591
Validation loss: 2.487504444766597

Epoch: 5| Step: 2
Training loss: 2.848245107208097
Validation loss: 2.49435667601496

Epoch: 5| Step: 3
Training loss: 2.578128699097725
Validation loss: 2.4987210222106944

Epoch: 5| Step: 4
Training loss: 2.7698705812373614
Validation loss: 2.5031832271715393

Epoch: 5| Step: 5
Training loss: 2.9893010412690173
Validation loss: 2.5186739247147796

Epoch: 5| Step: 6
Training loss: 3.0360082660306196
Validation loss: 2.548898329675731

Epoch: 5| Step: 7
Training loss: 2.967912254589064
Validation loss: 2.5549259115311793

Epoch: 5| Step: 8
Training loss: 2.647454543547471
Validation loss: 2.581291806852461

Epoch: 5| Step: 9
Training loss: 2.700903271651653
Validation loss: 2.560249729188438

Epoch: 5| Step: 10
Training loss: 2.37279448246279
Validation loss: 2.576474384466317

Epoch: 148| Step: 0
Training loss: 2.3484919071557546
Validation loss: 2.557885328492549

Epoch: 5| Step: 1
Training loss: 2.6644385287795664
Validation loss: 2.5359167702671805

Epoch: 5| Step: 2
Training loss: 2.8201657412906798
Validation loss: 2.519252148656507

Epoch: 5| Step: 3
Training loss: 2.3171323824993997
Validation loss: 2.5065500529809284

Epoch: 5| Step: 4
Training loss: 2.8128526254637167
Validation loss: 2.5074259786262316

Epoch: 5| Step: 5
Training loss: 3.157551412156286
Validation loss: 2.4948441961913836

Epoch: 5| Step: 6
Training loss: 2.169816612897495
Validation loss: 2.494268202435598

Epoch: 5| Step: 7
Training loss: 2.8576131093090815
Validation loss: 2.490900669834147

Epoch: 5| Step: 8
Training loss: 3.1605759991435587
Validation loss: 2.4955171509059673

Epoch: 5| Step: 9
Training loss: 2.790612823698983
Validation loss: 2.4910298097587686

Epoch: 5| Step: 10
Training loss: 2.7868167159493424
Validation loss: 2.5065246726521475

Epoch: 149| Step: 0
Training loss: 2.7748469679967545
Validation loss: 2.5177078434494558

Epoch: 5| Step: 1
Training loss: 3.007137391260498
Validation loss: 2.534181165990146

Epoch: 5| Step: 2
Training loss: 2.999540293757854
Validation loss: 2.570119921950471

Epoch: 5| Step: 3
Training loss: 2.599414385354815
Validation loss: 2.6162507458759117

Epoch: 5| Step: 4
Training loss: 2.374797310462008
Validation loss: 2.625673218482044

Epoch: 5| Step: 5
Training loss: 2.674300581861047
Validation loss: 2.6525944291336576

Epoch: 5| Step: 6
Training loss: 2.9598710447006513
Validation loss: 2.674410613947631

Epoch: 5| Step: 7
Training loss: 2.4925182924202014
Validation loss: 2.624674782283531

Epoch: 5| Step: 8
Training loss: 3.0166089918268018
Validation loss: 2.5892881407060324

Epoch: 5| Step: 9
Training loss: 2.5444768368668735
Validation loss: 2.559077105987285

Epoch: 5| Step: 10
Training loss: 2.401247645967234
Validation loss: 2.5669390628415996

Epoch: 150| Step: 0
Training loss: 2.3040986941511243
Validation loss: 2.5488020683141346

Epoch: 5| Step: 1
Training loss: 2.9945874661474203
Validation loss: 2.5558603858279043

Epoch: 5| Step: 2
Training loss: 2.5135879324744153
Validation loss: 2.5532752569662147

Epoch: 5| Step: 3
Training loss: 2.6560035142415708
Validation loss: 2.571205870347639

Epoch: 5| Step: 4
Training loss: 3.2308409913445972
Validation loss: 2.547438421739223

Epoch: 5| Step: 5
Training loss: 2.9566635649047317
Validation loss: 2.5322089232938465

Epoch: 5| Step: 6
Training loss: 2.8513098199799614
Validation loss: 2.5333182715220257

Epoch: 5| Step: 7
Training loss: 1.8386482517660996
Validation loss: 2.519261541268901

Epoch: 5| Step: 8
Training loss: 2.9386701485231868
Validation loss: 2.5209709264849174

Epoch: 5| Step: 9
Training loss: 2.423225764476215
Validation loss: 2.518495685165379

Epoch: 5| Step: 10
Training loss: 2.999076701181601
Validation loss: 2.5146759822430824

Epoch: 151| Step: 0
Training loss: 2.8288799142441285
Validation loss: 2.5201124185725137

Epoch: 5| Step: 1
Training loss: 2.62723355409566
Validation loss: 2.5387967120599493

Epoch: 5| Step: 2
Training loss: 3.0409856756814406
Validation loss: 2.5586086372644385

Epoch: 5| Step: 3
Training loss: 2.5531656474469537
Validation loss: 2.561492578829458

Epoch: 5| Step: 4
Training loss: 1.7721026938671145
Validation loss: 2.5682316189695737

Epoch: 5| Step: 5
Training loss: 2.947349430861997
Validation loss: 2.603924146290888

Epoch: 5| Step: 6
Training loss: 2.8518758523251315
Validation loss: 2.6105407798736335

Epoch: 5| Step: 7
Training loss: 2.6334139988612106
Validation loss: 2.625313870464837

Epoch: 5| Step: 8
Training loss: 3.2639985483203726
Validation loss: 2.619446451942665

Epoch: 5| Step: 9
Training loss: 2.530461977519447
Validation loss: 2.5742872345039522

Epoch: 5| Step: 10
Training loss: 2.6403502372133487
Validation loss: 2.5517036609281805

Epoch: 152| Step: 0
Training loss: 2.7262942993818626
Validation loss: 2.528630450640108

Epoch: 5| Step: 1
Training loss: 2.644445871527293
Validation loss: 2.5338890470312507

Epoch: 5| Step: 2
Training loss: 2.7373885632830466
Validation loss: 2.519462971303892

Epoch: 5| Step: 3
Training loss: 2.7493758793834018
Validation loss: 2.5261070358872666

Epoch: 5| Step: 4
Training loss: 3.267513915238816
Validation loss: 2.5309336869900227

Epoch: 5| Step: 5
Training loss: 2.72680147102051
Validation loss: 2.533140404567618

Epoch: 5| Step: 6
Training loss: 2.788842969957969
Validation loss: 2.550402759527802

Epoch: 5| Step: 7
Training loss: 2.0359698113712152
Validation loss: 2.5530812271170777

Epoch: 5| Step: 8
Training loss: 2.6440534737643344
Validation loss: 2.559602232981807

Epoch: 5| Step: 9
Training loss: 2.484652713632398
Validation loss: 2.566473698350529

Epoch: 5| Step: 10
Training loss: 2.8284374085585315
Validation loss: 2.5980344016131247

Epoch: 153| Step: 0
Training loss: 2.513826663357719
Validation loss: 2.5929325627872393

Epoch: 5| Step: 1
Training loss: 2.1349213064373536
Validation loss: 2.5768775753614355

Epoch: 5| Step: 2
Training loss: 2.508089044362154
Validation loss: 2.584464478191467

Epoch: 5| Step: 3
Training loss: 2.595466780971529
Validation loss: 2.570359844349351

Epoch: 5| Step: 4
Training loss: 2.6704867141527417
Validation loss: 2.583899965441419

Epoch: 5| Step: 5
Training loss: 2.429125165721138
Validation loss: 2.5613190945982973

Epoch: 5| Step: 6
Training loss: 3.271962272697018
Validation loss: 2.5986280248441966

Epoch: 5| Step: 7
Training loss: 2.998162819673729
Validation loss: 2.575017165244188

Epoch: 5| Step: 8
Training loss: 2.571414235998491
Validation loss: 2.560406968345295

Epoch: 5| Step: 9
Training loss: 3.0006903807674776
Validation loss: 2.5651230251646977

Epoch: 5| Step: 10
Training loss: 2.4077815346580214
Validation loss: 2.5558897347292495

Epoch: 154| Step: 0
Training loss: 2.880650978956152
Validation loss: 2.551532647943557

Epoch: 5| Step: 1
Training loss: 3.2040490283048495
Validation loss: 2.54783113661873

Epoch: 5| Step: 2
Training loss: 2.3604030769228537
Validation loss: 2.5317317909757735

Epoch: 5| Step: 3
Training loss: 2.3598316079209805
Validation loss: 2.524872450367088

Epoch: 5| Step: 4
Training loss: 2.587831938456034
Validation loss: 2.535514104109404

Epoch: 5| Step: 5
Training loss: 2.6897452977644005
Validation loss: 2.5545522410600063

Epoch: 5| Step: 6
Training loss: 2.497047492837899
Validation loss: 2.570213649352638

Epoch: 5| Step: 7
Training loss: 2.82163230891602
Validation loss: 2.574575293035834

Epoch: 5| Step: 8
Training loss: 2.469677714584641
Validation loss: 2.5781108857057795

Epoch: 5| Step: 9
Training loss: 2.5684563796141666
Validation loss: 2.62030115708157

Epoch: 5| Step: 10
Training loss: 2.6986479976967006
Validation loss: 2.622576857446051

Epoch: 155| Step: 0
Training loss: 2.282548404276455
Validation loss: 2.614622017179134

Epoch: 5| Step: 1
Training loss: 2.808599352665222
Validation loss: 2.6334242508181736

Epoch: 5| Step: 2
Training loss: 2.3717826332733507
Validation loss: 2.615180117370613

Epoch: 5| Step: 3
Training loss: 2.977754929756963
Validation loss: 2.6078571387203615

Epoch: 5| Step: 4
Training loss: 2.405374937591449
Validation loss: 2.599062361425088

Epoch: 5| Step: 5
Training loss: 2.7004087174089686
Validation loss: 2.61206082597851

Epoch: 5| Step: 6
Training loss: 2.0410681904863766
Validation loss: 2.597739840518099

Epoch: 5| Step: 7
Training loss: 2.927536482481851
Validation loss: 2.5853564963515137

Epoch: 5| Step: 8
Training loss: 2.881918667801836
Validation loss: 2.569835818245404

Epoch: 5| Step: 9
Training loss: 2.8345279606065716
Validation loss: 2.5498212789904526

Epoch: 5| Step: 10
Training loss: 2.7189091602961173
Validation loss: 2.553817907593414

Epoch: 156| Step: 0
Training loss: 2.6650703738656225
Validation loss: 2.559641329270542

Epoch: 5| Step: 1
Training loss: 2.3204632334444204
Validation loss: 2.5428251430045115

Epoch: 5| Step: 2
Training loss: 2.5389896323678607
Validation loss: 2.5794498384437134

Epoch: 5| Step: 3
Training loss: 2.4201388134827884
Validation loss: 2.57818661911639

Epoch: 5| Step: 4
Training loss: 2.745975410440238
Validation loss: 2.6025034052832536

Epoch: 5| Step: 5
Training loss: 2.8639662939251322
Validation loss: 2.6157441451000256

Epoch: 5| Step: 6
Training loss: 2.9177548331373537
Validation loss: 2.6117757180374004

Epoch: 5| Step: 7
Training loss: 2.8640134117302596
Validation loss: 2.602314653660414

Epoch: 5| Step: 8
Training loss: 2.960685779671613
Validation loss: 2.5919937412761667

Epoch: 5| Step: 9
Training loss: 2.1100746407346436
Validation loss: 2.6162174631754627

Epoch: 5| Step: 10
Training loss: 2.367610075344348
Validation loss: 2.602536177276223

Epoch: 157| Step: 0
Training loss: 2.4304771979886226
Validation loss: 2.589885997834404

Epoch: 5| Step: 1
Training loss: 2.220657281058519
Validation loss: 2.581708675734854

Epoch: 5| Step: 2
Training loss: 2.631746161067348
Validation loss: 2.569830175874304

Epoch: 5| Step: 3
Training loss: 2.780891138134638
Validation loss: 2.582785607530902

Epoch: 5| Step: 4
Training loss: 2.922144749883212
Validation loss: 2.6255540297295545

Epoch: 5| Step: 5
Training loss: 2.8432397070164828
Validation loss: 2.643976121867837

Epoch: 5| Step: 6
Training loss: 2.4842669385524703
Validation loss: 2.6451431312745584

Epoch: 5| Step: 7
Training loss: 3.3558197370818483
Validation loss: 2.6446043116431226

Epoch: 5| Step: 8
Training loss: 2.385788556779224
Validation loss: 2.625427592640011

Epoch: 5| Step: 9
Training loss: 2.351186323018513
Validation loss: 2.617199746184211

Epoch: 5| Step: 10
Training loss: 2.160692476074689
Validation loss: 2.627118831308589

Epoch: 158| Step: 0
Training loss: 2.5063176438485315
Validation loss: 2.6064586723972294

Epoch: 5| Step: 1
Training loss: 2.2887769918136662
Validation loss: 2.6156535429008576

Epoch: 5| Step: 2
Training loss: 2.1070839201695226
Validation loss: 2.6459758223759087

Epoch: 5| Step: 3
Training loss: 2.440354363239563
Validation loss: 2.664442970629885

Epoch: 5| Step: 4
Training loss: 2.7191467872553092
Validation loss: 2.6504111571391014

Epoch: 5| Step: 5
Training loss: 2.959272978654525
Validation loss: 2.6239039940334727

Epoch: 5| Step: 6
Training loss: 2.8389973592554423
Validation loss: 2.5950324007552825

Epoch: 5| Step: 7
Training loss: 2.2217256176570968
Validation loss: 2.56710127500452

Epoch: 5| Step: 8
Training loss: 2.9093075327523206
Validation loss: 2.561671415437692

Epoch: 5| Step: 9
Training loss: 2.6891817552986272
Validation loss: 2.5411953165421743

Epoch: 5| Step: 10
Training loss: 2.851323867637056
Validation loss: 2.532651874868443

Epoch: 159| Step: 0
Training loss: 2.871341201602573
Validation loss: 2.5305033790034845

Epoch: 5| Step: 1
Training loss: 2.774849545635858
Validation loss: 2.5271898504185932

Epoch: 5| Step: 2
Training loss: 2.5529431095022908
Validation loss: 2.534993089950984

Epoch: 5| Step: 3
Training loss: 2.3958652881205156
Validation loss: 2.5539824246707084

Epoch: 5| Step: 4
Training loss: 2.8709446044382205
Validation loss: 2.5720188094931147

Epoch: 5| Step: 5
Training loss: 2.6118954118641677
Validation loss: 2.574517938029685

Epoch: 5| Step: 6
Training loss: 3.0111598029272124
Validation loss: 2.5826724947487114

Epoch: 5| Step: 7
Training loss: 2.2938474047193496
Validation loss: 2.564718652096147

Epoch: 5| Step: 8
Training loss: 2.6735597173421852
Validation loss: 2.559662727562798

Epoch: 5| Step: 9
Training loss: 2.1777830930999627
Validation loss: 2.5473610505858466

Epoch: 5| Step: 10
Training loss: 2.1570344686570517
Validation loss: 2.567690644672029

Epoch: 160| Step: 0
Training loss: 2.372952632838016
Validation loss: 2.5930282234918725

Epoch: 5| Step: 1
Training loss: 2.6819971212987506
Validation loss: 2.6099095167041333

Epoch: 5| Step: 2
Training loss: 2.3311663737907
Validation loss: 2.6340806074319865

Epoch: 5| Step: 3
Training loss: 2.6892476276906057
Validation loss: 2.6338871594153317

Epoch: 5| Step: 4
Training loss: 2.554468267990744
Validation loss: 2.627809335765304

Epoch: 5| Step: 5
Training loss: 2.1780604918024955
Validation loss: 2.6111999863648525

Epoch: 5| Step: 6
Training loss: 2.850089583745742
Validation loss: 2.612462725684751

Epoch: 5| Step: 7
Training loss: 2.792805785646677
Validation loss: 2.5972418840193567

Epoch: 5| Step: 8
Training loss: 2.7761033691267083
Validation loss: 2.57305084299797

Epoch: 5| Step: 9
Training loss: 2.686135588881445
Validation loss: 2.559796668895708

Epoch: 5| Step: 10
Training loss: 2.2105070847676243
Validation loss: 2.549241477996707

Epoch: 161| Step: 0
Training loss: 2.8377390622165195
Validation loss: 2.5653200176879576

Epoch: 5| Step: 1
Training loss: 2.30374415860028
Validation loss: 2.580072024110279

Epoch: 5| Step: 2
Training loss: 2.801148713717914
Validation loss: 2.5905998513463078

Epoch: 5| Step: 3
Training loss: 2.586400108793323
Validation loss: 2.604139762165183

Epoch: 5| Step: 4
Training loss: 2.4107447667692594
Validation loss: 2.612009433134257

Epoch: 5| Step: 5
Training loss: 1.8719221284311691
Validation loss: 2.613012677391385

Epoch: 5| Step: 6
Training loss: 1.9978118489773216
Validation loss: 2.623375692356919

Epoch: 5| Step: 7
Training loss: 2.4766112121219797
Validation loss: 2.6241673517706117

Epoch: 5| Step: 8
Training loss: 3.203933241683273
Validation loss: 2.695853166655752

Epoch: 5| Step: 9
Training loss: 2.8290831907951124
Validation loss: 2.5994808086059096

Epoch: 5| Step: 10
Training loss: 2.833614185849592
Validation loss: 2.569574077395467

Epoch: 162| Step: 0
Training loss: 2.7698772090591635
Validation loss: 2.5538102010538073

Epoch: 5| Step: 1
Training loss: 2.8892833998689538
Validation loss: 2.5411926350637533

Epoch: 5| Step: 2
Training loss: 2.131420309919332
Validation loss: 2.5396430632385716

Epoch: 5| Step: 3
Training loss: 2.90323983448837
Validation loss: 2.537540263073697

Epoch: 5| Step: 4
Training loss: 2.4103200600227446
Validation loss: 2.545087518113756

Epoch: 5| Step: 5
Training loss: 2.7108549165926785
Validation loss: 2.569172430527685

Epoch: 5| Step: 6
Training loss: 2.2409909341910477
Validation loss: 2.5758201610738105

Epoch: 5| Step: 7
Training loss: 2.234137782595853
Validation loss: 2.6271888545107775

Epoch: 5| Step: 8
Training loss: 2.364949896767623
Validation loss: 2.6485747795645165

Epoch: 5| Step: 9
Training loss: 2.7670479255168194
Validation loss: 2.649803083258124

Epoch: 5| Step: 10
Training loss: 2.8021277007002188
Validation loss: 2.6401180036196186

Epoch: 163| Step: 0
Training loss: 2.5968121756288776
Validation loss: 2.6557145758356944

Epoch: 5| Step: 1
Training loss: 2.411772496718489
Validation loss: 2.6564359615505477

Epoch: 5| Step: 2
Training loss: 2.6571790080387356
Validation loss: 2.6267636903400495

Epoch: 5| Step: 3
Training loss: 2.263774563399647
Validation loss: 2.5964675960661605

Epoch: 5| Step: 4
Training loss: 2.809910663121321
Validation loss: 2.562050788777068

Epoch: 5| Step: 5
Training loss: 2.511516462043885
Validation loss: 2.5641970253733692

Epoch: 5| Step: 6
Training loss: 2.7134968661797516
Validation loss: 2.5420021576729

Epoch: 5| Step: 7
Training loss: 2.467662716711355
Validation loss: 2.551297167964765

Epoch: 5| Step: 8
Training loss: 2.5686767382047684
Validation loss: 2.5661718521489623

Epoch: 5| Step: 9
Training loss: 2.304902147545427
Validation loss: 2.57315857030615

Epoch: 5| Step: 10
Training loss: 2.3703594044701033
Validation loss: 2.5831251235823376

Epoch: 164| Step: 0
Training loss: 2.398424278993233
Validation loss: 2.5763885268373903

Epoch: 5| Step: 1
Training loss: 2.5169698780971803
Validation loss: 2.6188521049060336

Epoch: 5| Step: 2
Training loss: 2.0678791068506195
Validation loss: 2.6227711455427425

Epoch: 5| Step: 3
Training loss: 2.7221568893412424
Validation loss: 2.6018569318006612

Epoch: 5| Step: 4
Training loss: 2.1129634145736893
Validation loss: 2.5910219517936177

Epoch: 5| Step: 5
Training loss: 2.955177038217757
Validation loss: 2.5826056957781387

Epoch: 5| Step: 6
Training loss: 2.0082594080993936
Validation loss: 2.571316402786546

Epoch: 5| Step: 7
Training loss: 2.6822581958842866
Validation loss: 2.5789717053598205

Epoch: 5| Step: 8
Training loss: 2.8108105989726733
Validation loss: 2.571653890105549

Epoch: 5| Step: 9
Training loss: 2.585536499279255
Validation loss: 2.5719127688489674

Epoch: 5| Step: 10
Training loss: 2.630717001094921
Validation loss: 2.529660984934468

Epoch: 165| Step: 0
Training loss: 2.0184346806066054
Validation loss: 2.5497386804105107

Epoch: 5| Step: 1
Training loss: 2.515708969325977
Validation loss: 2.5422894827466616

Epoch: 5| Step: 2
Training loss: 2.73868147554947
Validation loss: 2.572306446337648

Epoch: 5| Step: 3
Training loss: 1.9967929041169399
Validation loss: 2.5725943619361793

Epoch: 5| Step: 4
Training loss: 2.625414588522582
Validation loss: 2.5829581095024645

Epoch: 5| Step: 5
Training loss: 2.271918139776166
Validation loss: 2.5897292457967267

Epoch: 5| Step: 6
Training loss: 2.746728772121725
Validation loss: 2.616144530391518

Epoch: 5| Step: 7
Training loss: 2.2718594767002114
Validation loss: 2.609801473405309

Epoch: 5| Step: 8
Training loss: 2.515991279047178
Validation loss: 2.625352700051466

Epoch: 5| Step: 9
Training loss: 2.330721846982803
Validation loss: 2.6204883627053603

Epoch: 5| Step: 10
Training loss: 3.0644918698255754
Validation loss: 2.6308227354289

Epoch: 166| Step: 0
Training loss: 2.2883536116703374
Validation loss: 2.6123392933640783

Epoch: 5| Step: 1
Training loss: 2.5508323769462193
Validation loss: 2.60674045555657

Epoch: 5| Step: 2
Training loss: 2.3460269294747667
Validation loss: 2.6458340787672547

Epoch: 5| Step: 3
Training loss: 2.0901583711040623
Validation loss: 2.659923252280273

Epoch: 5| Step: 4
Training loss: 2.149498029262068
Validation loss: 2.6999003965083506

Epoch: 5| Step: 5
Training loss: 2.3986980284308195
Validation loss: 2.664695436732792

Epoch: 5| Step: 6
Training loss: 2.7237551864427587
Validation loss: 2.5885945220626367

Epoch: 5| Step: 7
Training loss: 2.9250167846198107
Validation loss: 2.5689741507058774

Epoch: 5| Step: 8
Training loss: 2.941460881226145
Validation loss: 2.539105498878244

Epoch: 5| Step: 9
Training loss: 2.0025242135135364
Validation loss: 2.5398425387160217

Epoch: 5| Step: 10
Training loss: 2.451621888938427
Validation loss: 2.528838798461792

Epoch: 167| Step: 0
Training loss: 2.3905485053695643
Validation loss: 2.531907749032927

Epoch: 5| Step: 1
Training loss: 2.9712781882483585
Validation loss: 2.5325425490290994

Epoch: 5| Step: 2
Training loss: 2.4490449834627723
Validation loss: 2.533189333216253

Epoch: 5| Step: 3
Training loss: 1.8850206271796015
Validation loss: 2.518323617327374

Epoch: 5| Step: 4
Training loss: 2.3337939579751357
Validation loss: 2.535082207248254

Epoch: 5| Step: 5
Training loss: 2.3721413725397347
Validation loss: 2.5606028699623047

Epoch: 5| Step: 6
Training loss: 2.443826339582981
Validation loss: 2.5375031479365844

Epoch: 5| Step: 7
Training loss: 2.51334547933718
Validation loss: 2.5305510963470383

Epoch: 5| Step: 8
Training loss: 2.447484913079089
Validation loss: 2.5389204158737146

Epoch: 5| Step: 9
Training loss: 2.7896728702579052
Validation loss: 2.5353707836884998

Epoch: 5| Step: 10
Training loss: 2.343836363154927
Validation loss: 2.531283160759257

Epoch: 168| Step: 0
Training loss: 2.4950673077817616
Validation loss: 2.558217704121024

Epoch: 5| Step: 1
Training loss: 2.802352145511844
Validation loss: 2.6146475654899115

Epoch: 5| Step: 2
Training loss: 2.4983207785113
Validation loss: 2.758242352635261

Epoch: 5| Step: 3
Training loss: 2.2121030074170562
Validation loss: 2.7639910640111167

Epoch: 5| Step: 4
Training loss: 2.6253897059762097
Validation loss: 2.629577823988101

Epoch: 5| Step: 5
Training loss: 2.5319361757427195
Validation loss: 2.539732041597694

Epoch: 5| Step: 6
Training loss: 2.611054753536271
Validation loss: 2.4749686302035827

Epoch: 5| Step: 7
Training loss: 2.7977525410596735
Validation loss: 2.4714726805479765

Epoch: 5| Step: 8
Training loss: 1.8515770505180515
Validation loss: 2.4746677651337703

Epoch: 5| Step: 9
Training loss: 2.6717489112415596
Validation loss: 2.478159244715943

Epoch: 5| Step: 10
Training loss: 2.3631059061372186
Validation loss: 2.50702923118036

Epoch: 169| Step: 0
Training loss: 1.9723268743816171
Validation loss: 2.4907632726870954

Epoch: 5| Step: 1
Training loss: 3.082424665707693
Validation loss: 2.4988238480284606

Epoch: 5| Step: 2
Training loss: 2.45091021231612
Validation loss: 2.545930204150773

Epoch: 5| Step: 3
Training loss: 2.5609381963741713
Validation loss: 2.591220908093309

Epoch: 5| Step: 4
Training loss: 1.9934660156238901
Validation loss: 2.6139881152846716

Epoch: 5| Step: 5
Training loss: 2.655366369138505
Validation loss: 2.638714545779713

Epoch: 5| Step: 6
Training loss: 2.6510943474372373
Validation loss: 2.631028266106559

Epoch: 5| Step: 7
Training loss: 2.3663632811822937
Validation loss: 2.602905782977107

Epoch: 5| Step: 8
Training loss: 2.4893675727934568
Validation loss: 2.576042731011253

Epoch: 5| Step: 9
Training loss: 2.375226261002221
Validation loss: 2.5773518019084745

Epoch: 5| Step: 10
Training loss: 2.6035906243593114
Validation loss: 2.5857285081553014

Epoch: 170| Step: 0
Training loss: 2.0502866312007613
Validation loss: 2.6220617418257386

Epoch: 5| Step: 1
Training loss: 2.368307824244648
Validation loss: 2.6208313902544105

Epoch: 5| Step: 2
Training loss: 2.80076039411582
Validation loss: 2.6331356582135172

Epoch: 5| Step: 3
Training loss: 1.8794927811703444
Validation loss: 2.62309961630392

Epoch: 5| Step: 4
Training loss: 2.64077866688374
Validation loss: 2.646604663083025

Epoch: 5| Step: 5
Training loss: 3.1654093571954647
Validation loss: 2.695895243324978

Epoch: 5| Step: 6
Training loss: 2.7655831888777587
Validation loss: 2.6629122096315543

Epoch: 5| Step: 7
Training loss: 1.7007754857145658
Validation loss: 2.627136234333955

Epoch: 5| Step: 8
Training loss: 2.7269606859697677
Validation loss: 2.6213762024680025

Epoch: 5| Step: 9
Training loss: 2.860095324228176
Validation loss: 2.6291165709840096

Epoch: 5| Step: 10
Training loss: 2.341074115360477
Validation loss: 2.5819127274970475

Epoch: 171| Step: 0
Training loss: 2.4294452117124696
Validation loss: 2.543295650112965

Epoch: 5| Step: 1
Training loss: 2.232298626505412
Validation loss: 2.527227239761363

Epoch: 5| Step: 2
Training loss: 2.498404088849604
Validation loss: 2.5163096802699956

Epoch: 5| Step: 3
Training loss: 2.5786647347255967
Validation loss: 2.525134794190266

Epoch: 5| Step: 4
Training loss: 2.178009481116922
Validation loss: 2.507618011261597

Epoch: 5| Step: 5
Training loss: 2.990603194361547
Validation loss: 2.4693325835616435

Epoch: 5| Step: 6
Training loss: 2.603473591447304
Validation loss: 2.477433875569158

Epoch: 5| Step: 7
Training loss: 2.450074163598933
Validation loss: 2.4568348272033145

Epoch: 5| Step: 8
Training loss: 2.6726825229989246
Validation loss: 2.431432884156558

Epoch: 5| Step: 9
Training loss: 2.0700788258088765
Validation loss: 2.444607221970331

Epoch: 5| Step: 10
Training loss: 2.230098767167504
Validation loss: 2.478000560684258

Epoch: 172| Step: 0
Training loss: 2.666782009093938
Validation loss: 2.5292578215234194

Epoch: 5| Step: 1
Training loss: 2.309677669941388
Validation loss: 2.529829348978983

Epoch: 5| Step: 2
Training loss: 2.5478077684047618
Validation loss: 2.527125116693403

Epoch: 5| Step: 3
Training loss: 2.7613798848140427
Validation loss: 2.4765419074588513

Epoch: 5| Step: 4
Training loss: 2.0621862461845284
Validation loss: 2.47357761806362

Epoch: 5| Step: 5
Training loss: 1.9703132236125442
Validation loss: 2.468818933581929

Epoch: 5| Step: 6
Training loss: 2.258318781600559
Validation loss: 2.4815871150446203

Epoch: 5| Step: 7
Training loss: 2.635807857705895
Validation loss: 2.4869751210183293

Epoch: 5| Step: 8
Training loss: 2.028388957522814
Validation loss: 2.549163249417998

Epoch: 5| Step: 9
Training loss: 2.1884125032458557
Validation loss: 2.6056464308194554

Epoch: 5| Step: 10
Training loss: 2.962904465504094
Validation loss: 2.670653555209138

Epoch: 173| Step: 0
Training loss: 2.803437275753112
Validation loss: 2.707149366725148

Epoch: 5| Step: 1
Training loss: 3.041446799775439
Validation loss: 2.627983023426913

Epoch: 5| Step: 2
Training loss: 2.0563957742424646
Validation loss: 2.5356961024114746

Epoch: 5| Step: 3
Training loss: 2.021915644100092
Validation loss: 2.538843662622097

Epoch: 5| Step: 4
Training loss: 2.175551232827325
Validation loss: 2.5296368610724045

Epoch: 5| Step: 5
Training loss: 2.043400501850265
Validation loss: 2.532332625975546

Epoch: 5| Step: 6
Training loss: 2.4838410769439165
Validation loss: 2.557787841783859

Epoch: 5| Step: 7
Training loss: 2.265106457530536
Validation loss: 2.597896834520293

Epoch: 5| Step: 8
Training loss: 3.0830331776553956
Validation loss: 2.644548988243413

Epoch: 5| Step: 9
Training loss: 2.072021469991789
Validation loss: 2.653583523504832

Epoch: 5| Step: 10
Training loss: 2.1348129783746206
Validation loss: 2.6638955637232042

Epoch: 174| Step: 0
Training loss: 2.86451034915311
Validation loss: 2.6047241993973365

Epoch: 5| Step: 1
Training loss: 1.9866847015475397
Validation loss: 2.5767435618157393

Epoch: 5| Step: 2
Training loss: 2.531682012920398
Validation loss: 2.5563605178661333

Epoch: 5| Step: 3
Training loss: 2.036932523371073
Validation loss: 2.5557939884624172

Epoch: 5| Step: 4
Training loss: 2.196443965295242
Validation loss: 2.574553427206575

Epoch: 5| Step: 5
Training loss: 2.4547500573241883
Validation loss: 2.5872617485346714

Epoch: 5| Step: 6
Training loss: 2.165392635589645
Validation loss: 2.583447949674954

Epoch: 5| Step: 7
Training loss: 2.187964471824957
Validation loss: 2.5795376931646286

Epoch: 5| Step: 8
Training loss: 2.680058489773303
Validation loss: 2.5817144669132155

Epoch: 5| Step: 9
Training loss: 2.186472297128326
Validation loss: 2.583103916673905

Epoch: 5| Step: 10
Training loss: 2.517710703694926
Validation loss: 2.573890058179552

Epoch: 175| Step: 0
Training loss: 2.5377643729358965
Validation loss: 2.533282932291235

Epoch: 5| Step: 1
Training loss: 2.013661455780513
Validation loss: 2.538888812943792

Epoch: 5| Step: 2
Training loss: 2.273754818718802
Validation loss: 2.566895056083802

Epoch: 5| Step: 3
Training loss: 2.364138310660951
Validation loss: 2.570096665622494

Epoch: 5| Step: 4
Training loss: 2.2577739567090203
Validation loss: 2.5534278072226058

Epoch: 5| Step: 5
Training loss: 1.9618994188687886
Validation loss: 2.5250058238131774

Epoch: 5| Step: 6
Training loss: 2.795435956144588
Validation loss: 2.536654343470474

Epoch: 5| Step: 7
Training loss: 2.1942522740086625
Validation loss: 2.512036875312203

Epoch: 5| Step: 8
Training loss: 1.5177338077219915
Validation loss: 2.493643147163455

Epoch: 5| Step: 9
Training loss: 2.7197406761583975
Validation loss: 2.5107187987880066

Epoch: 5| Step: 10
Training loss: 2.778179488275278
Validation loss: 2.517697705792849

Testing loss: 2.740772110265006
