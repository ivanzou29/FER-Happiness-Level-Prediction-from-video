Epoch: 1| Step: 0
Training loss: 5.408632278442383
Validation loss: 5.205344841044436

Epoch: 5| Step: 1
Training loss: 5.158071517944336
Validation loss: 5.175901459109399

Epoch: 5| Step: 2
Training loss: 5.2210845947265625
Validation loss: 5.153017884941511

Epoch: 5| Step: 3
Training loss: 4.974379062652588
Validation loss: 5.130954998795704

Epoch: 5| Step: 4
Training loss: 5.133749961853027
Validation loss: 5.1072846330622195

Epoch: 5| Step: 5
Training loss: 4.600735664367676
Validation loss: 5.080697818468976

Epoch: 5| Step: 6
Training loss: 5.1524858474731445
Validation loss: 5.0515714358257995

Epoch: 5| Step: 7
Training loss: 4.016495227813721
Validation loss: 5.018457525519914

Epoch: 5| Step: 8
Training loss: 4.681694507598877
Validation loss: 4.981566608593028

Epoch: 5| Step: 9
Training loss: 4.637059688568115
Validation loss: 4.940527751881589

Epoch: 5| Step: 10
Training loss: 4.474731922149658
Validation loss: 4.893420255312356

Epoch: 2| Step: 0
Training loss: 4.845825672149658
Validation loss: 4.842904336990848

Epoch: 5| Step: 1
Training loss: 4.7716169357299805
Validation loss: 4.787009157160277

Epoch: 5| Step: 2
Training loss: 4.3048996925354
Validation loss: 4.727186105584585

Epoch: 5| Step: 3
Training loss: 5.681525230407715
Validation loss: 4.665019753158734

Epoch: 5| Step: 4
Training loss: 3.6327338218688965
Validation loss: 4.601048243943081

Epoch: 5| Step: 5
Training loss: 3.67081880569458
Validation loss: 4.535779722275272

Epoch: 5| Step: 6
Training loss: 4.940683841705322
Validation loss: 4.469049474244477

Epoch: 5| Step: 7
Training loss: 3.685497283935547
Validation loss: 4.400968833636212

Epoch: 5| Step: 8
Training loss: 3.419323682785034
Validation loss: 4.332576172326201

Epoch: 5| Step: 9
Training loss: 4.416893005371094
Validation loss: 4.262871588430097

Epoch: 5| Step: 10
Training loss: 4.436373710632324
Validation loss: 4.193386975155081

Epoch: 3| Step: 0
Training loss: 3.3914990425109863
Validation loss: 4.123621002320321

Epoch: 5| Step: 1
Training loss: 2.442101001739502
Validation loss: 4.0533311725944605

Epoch: 5| Step: 2
Training loss: 3.296135663986206
Validation loss: 3.9869447677366194

Epoch: 5| Step: 3
Training loss: 4.6369194984436035
Validation loss: 3.9261578539366364

Epoch: 5| Step: 4
Training loss: 3.878376007080078
Validation loss: 3.875774009253389

Epoch: 5| Step: 5
Training loss: 4.804521560668945
Validation loss: 3.83519051664619

Epoch: 5| Step: 6
Training loss: 3.7156271934509277
Validation loss: 3.799142596542194

Epoch: 5| Step: 7
Training loss: 3.8341064453125
Validation loss: 3.7600769740279003

Epoch: 5| Step: 8
Training loss: 4.282055854797363
Validation loss: 3.730816559125018

Epoch: 5| Step: 9
Training loss: 3.692018985748291
Validation loss: 3.708302677318614

Epoch: 5| Step: 10
Training loss: 2.7002837657928467
Validation loss: 3.6888705991929576

Epoch: 4| Step: 0
Training loss: 3.7421715259552
Validation loss: 3.671464761098226

Epoch: 5| Step: 1
Training loss: 5.181044101715088
Validation loss: 3.650658902301583

Epoch: 5| Step: 2
Training loss: 2.714169979095459
Validation loss: 3.6247030509415494

Epoch: 5| Step: 3
Training loss: 2.796684980392456
Validation loss: 3.6090159313653105

Epoch: 5| Step: 4
Training loss: 3.099287748336792
Validation loss: 3.6118969763478925

Epoch: 5| Step: 5
Training loss: 3.143543004989624
Validation loss: 3.595630250951295

Epoch: 5| Step: 6
Training loss: 4.647181510925293
Validation loss: 3.566437921216411

Epoch: 5| Step: 7
Training loss: 3.3532817363739014
Validation loss: 3.5559914701728412

Epoch: 5| Step: 8
Training loss: 3.1985669136047363
Validation loss: 3.5475487119408062

Epoch: 5| Step: 9
Training loss: 4.082409381866455
Validation loss: 3.536017892181232

Epoch: 5| Step: 10
Training loss: 2.6110165119171143
Validation loss: 3.5241209101933304

Epoch: 5| Step: 0
Training loss: 4.166706085205078
Validation loss: 3.51401973027055

Epoch: 5| Step: 1
Training loss: 2.867581605911255
Validation loss: 3.502942164738973

Epoch: 5| Step: 2
Training loss: 3.8262031078338623
Validation loss: 3.493391398460634

Epoch: 5| Step: 3
Training loss: 3.4883224964141846
Validation loss: 3.488169216340588

Epoch: 5| Step: 4
Training loss: 3.4301490783691406
Validation loss: 3.4764992088399906

Epoch: 5| Step: 5
Training loss: 3.62144136428833
Validation loss: 3.4648124966570126

Epoch: 5| Step: 6
Training loss: 3.239635944366455
Validation loss: 3.454227098854639

Epoch: 5| Step: 7
Training loss: 3.145615339279175
Validation loss: 3.4428522715004544

Epoch: 5| Step: 8
Training loss: 3.740515947341919
Validation loss: 3.4325159185676166

Epoch: 5| Step: 9
Training loss: 3.231346845626831
Validation loss: 3.4231554333881666

Epoch: 5| Step: 10
Training loss: 2.614116907119751
Validation loss: 3.412647867715487

Epoch: 6| Step: 0
Training loss: 3.968972682952881
Validation loss: 3.401916419306109

Epoch: 5| Step: 1
Training loss: 3.0360023975372314
Validation loss: 3.3954984449571177

Epoch: 5| Step: 2
Training loss: 3.7407822608947754
Validation loss: 3.3885750001476658

Epoch: 5| Step: 3
Training loss: 3.1253201961517334
Validation loss: 3.3768332389093216

Epoch: 5| Step: 4
Training loss: 3.0807251930236816
Validation loss: 3.369801849447271

Epoch: 5| Step: 5
Training loss: 3.9909286499023438
Validation loss: 3.365855606653357

Epoch: 5| Step: 6
Training loss: 3.583590269088745
Validation loss: 3.3571564664122877

Epoch: 5| Step: 7
Training loss: 2.9865174293518066
Validation loss: 3.3488053301329255

Epoch: 5| Step: 8
Training loss: 3.4070847034454346
Validation loss: 3.340191189960767

Epoch: 5| Step: 9
Training loss: 2.473073959350586
Validation loss: 3.3320259253184

Epoch: 5| Step: 10
Training loss: 3.1799042224884033
Validation loss: 3.3248775415523077

Epoch: 7| Step: 0
Training loss: 3.6492342948913574
Validation loss: 3.3153327793203373

Epoch: 5| Step: 1
Training loss: 3.351834535598755
Validation loss: 3.3087401646439747

Epoch: 5| Step: 2
Training loss: 3.9861271381378174
Validation loss: 3.303335897384151

Epoch: 5| Step: 3
Training loss: 3.040208101272583
Validation loss: 3.2950802977367113

Epoch: 5| Step: 4
Training loss: 4.112381458282471
Validation loss: 3.28701477666055

Epoch: 5| Step: 5
Training loss: 2.45615816116333
Validation loss: 3.2763058523977957

Epoch: 5| Step: 6
Training loss: 2.806088924407959
Validation loss: 3.268511172263853

Epoch: 5| Step: 7
Training loss: 2.5667784214019775
Validation loss: 3.2601188203339935

Epoch: 5| Step: 8
Training loss: 3.372267246246338
Validation loss: 3.252467550257201

Epoch: 5| Step: 9
Training loss: 2.8951404094696045
Validation loss: 3.245348527867307

Epoch: 5| Step: 10
Training loss: 3.635005235671997
Validation loss: 3.2419835931511334

Epoch: 8| Step: 0
Training loss: 3.3399498462677
Validation loss: 3.2296380407066754

Epoch: 5| Step: 1
Training loss: 2.604661464691162
Validation loss: 3.225408254131194

Epoch: 5| Step: 2
Training loss: 2.6303179264068604
Validation loss: 3.2208146074766755

Epoch: 5| Step: 3
Training loss: 3.8263206481933594
Validation loss: 3.205522962795791

Epoch: 5| Step: 4
Training loss: 3.9504714012145996
Validation loss: 3.1922450680886545

Epoch: 5| Step: 5
Training loss: 3.2447807788848877
Validation loss: 3.1832735974301576

Epoch: 5| Step: 6
Training loss: 3.066671848297119
Validation loss: 3.1787316132617254

Epoch: 5| Step: 7
Training loss: 3.406172513961792
Validation loss: 3.172885899902672

Epoch: 5| Step: 8
Training loss: 2.6219325065612793
Validation loss: 3.157749419571251

Epoch: 5| Step: 9
Training loss: 3.572357177734375
Validation loss: 3.1460729645144556

Epoch: 5| Step: 10
Training loss: 2.818081855773926
Validation loss: 3.1342609646499797

Epoch: 9| Step: 0
Training loss: 2.7558672428131104
Validation loss: 3.124258836110433

Epoch: 5| Step: 1
Training loss: 2.9850268363952637
Validation loss: 3.122613932496758

Epoch: 5| Step: 2
Training loss: 2.911144971847534
Validation loss: 3.1113813102886243

Epoch: 5| Step: 3
Training loss: 2.901613235473633
Validation loss: 3.1001349802940124

Epoch: 5| Step: 4
Training loss: 3.1965134143829346
Validation loss: 3.0958009176356818

Epoch: 5| Step: 5
Training loss: 3.2379631996154785
Validation loss: 3.0950421133349018

Epoch: 5| Step: 6
Training loss: 3.8743255138397217
Validation loss: 3.082739927435434

Epoch: 5| Step: 7
Training loss: 2.2848055362701416
Validation loss: 3.065938062565301

Epoch: 5| Step: 8
Training loss: 3.137300491333008
Validation loss: 3.060503734055386

Epoch: 5| Step: 9
Training loss: 3.530308961868286
Validation loss: 3.0487596860495945

Epoch: 5| Step: 10
Training loss: 3.5812761783599854
Validation loss: 3.0375769240881807

Epoch: 10| Step: 0
Training loss: 3.0523788928985596
Validation loss: 3.0232998478797173

Epoch: 5| Step: 1
Training loss: 3.970282793045044
Validation loss: 3.0203149626331944

Epoch: 5| Step: 2
Training loss: 2.651517152786255
Validation loss: 3.0083719402231197

Epoch: 5| Step: 3
Training loss: 2.5565879344940186
Validation loss: 3.0002256490850963

Epoch: 5| Step: 4
Training loss: 2.5333714485168457
Validation loss: 2.9920795297109954

Epoch: 5| Step: 5
Training loss: 3.4134902954101562
Validation loss: 2.9983684068085044

Epoch: 5| Step: 6
Training loss: 2.9530086517333984
Validation loss: 2.973787066757038

Epoch: 5| Step: 7
Training loss: 3.0696349143981934
Validation loss: 2.9799460518744683

Epoch: 5| Step: 8
Training loss: 3.3241615295410156
Validation loss: 2.975642704194592

Epoch: 5| Step: 9
Training loss: 3.182778835296631
Validation loss: 2.969069124549948

Epoch: 5| Step: 10
Training loss: 2.930534839630127
Validation loss: 2.9553981493878108

Epoch: 11| Step: 0
Training loss: 2.7163846492767334
Validation loss: 2.9501513716995076

Epoch: 5| Step: 1
Training loss: 3.7056288719177246
Validation loss: 2.940931325317711

Epoch: 5| Step: 2
Training loss: 2.3067800998687744
Validation loss: 2.931756960448398

Epoch: 5| Step: 3
Training loss: 2.3751022815704346
Validation loss: 2.9206667971867386

Epoch: 5| Step: 4
Training loss: 3.362515926361084
Validation loss: 2.914325983293595

Epoch: 5| Step: 5
Training loss: 2.9809274673461914
Validation loss: 2.9060551043479674

Epoch: 5| Step: 6
Training loss: 2.958644390106201
Validation loss: 2.8971269130706787

Epoch: 5| Step: 7
Training loss: 3.092367649078369
Validation loss: 2.8847943018841486

Epoch: 5| Step: 8
Training loss: 2.923229694366455
Validation loss: 2.8774112527088453

Epoch: 5| Step: 9
Training loss: 2.969268321990967
Validation loss: 2.8649774520627913

Epoch: 5| Step: 10
Training loss: 3.685518503189087
Validation loss: 2.8581960073081394

Epoch: 12| Step: 0
Training loss: 2.5254502296447754
Validation loss: 2.842771568605977

Epoch: 5| Step: 1
Training loss: 2.949957847595215
Validation loss: 2.833230741562382

Epoch: 5| Step: 2
Training loss: 3.119410991668701
Validation loss: 2.825566994246616

Epoch: 5| Step: 3
Training loss: 2.7625303268432617
Validation loss: 2.819541818352156

Epoch: 5| Step: 4
Training loss: 2.9460015296936035
Validation loss: 2.8106638000857447

Epoch: 5| Step: 5
Training loss: 3.0732147693634033
Validation loss: 2.8003845727571877

Epoch: 5| Step: 6
Training loss: 3.444471836090088
Validation loss: 2.7955686123140397

Epoch: 5| Step: 7
Training loss: 2.534841537475586
Validation loss: 2.7923808328567015

Epoch: 5| Step: 8
Training loss: 2.656193733215332
Validation loss: 2.7785011645286315

Epoch: 5| Step: 9
Training loss: 3.046567440032959
Validation loss: 2.768237595917076

Epoch: 5| Step: 10
Training loss: 3.227937698364258
Validation loss: 2.765685601900983

Epoch: 13| Step: 0
Training loss: 1.8766227960586548
Validation loss: 2.7631972835909937

Epoch: 5| Step: 1
Training loss: 2.65498685836792
Validation loss: 2.751110235850016

Epoch: 5| Step: 2
Training loss: 2.0471768379211426
Validation loss: 2.7453522220734627

Epoch: 5| Step: 3
Training loss: 3.1486241817474365
Validation loss: 2.740513781065582

Epoch: 5| Step: 4
Training loss: 2.5158302783966064
Validation loss: 2.7363395203826246

Epoch: 5| Step: 5
Training loss: 3.0485122203826904
Validation loss: 2.7320574816837104

Epoch: 5| Step: 6
Training loss: 3.6673343181610107
Validation loss: 2.726817105406074

Epoch: 5| Step: 7
Training loss: 2.604985475540161
Validation loss: 2.7196307848858576

Epoch: 5| Step: 8
Training loss: 3.474661350250244
Validation loss: 2.7168864486038045

Epoch: 5| Step: 9
Training loss: 4.190375328063965
Validation loss: 2.7164266929831555

Epoch: 5| Step: 10
Training loss: 2.4214437007904053
Validation loss: 2.7034543329669583

Epoch: 14| Step: 0
Training loss: 3.1686854362487793
Validation loss: 2.6928076487715527

Epoch: 5| Step: 1
Training loss: 3.4565975666046143
Validation loss: 2.6890292244572795

Epoch: 5| Step: 2
Training loss: 2.642521381378174
Validation loss: 2.685355007007558

Epoch: 5| Step: 3
Training loss: 2.316190481185913
Validation loss: 2.675807788807859

Epoch: 5| Step: 4
Training loss: 2.9374685287475586
Validation loss: 2.6778002810734574

Epoch: 5| Step: 5
Training loss: 2.0123801231384277
Validation loss: 2.678158808779973

Epoch: 5| Step: 6
Training loss: 2.6945223808288574
Validation loss: 2.666127671477615

Epoch: 5| Step: 7
Training loss: 2.7579398155212402
Validation loss: 2.6670917746841267

Epoch: 5| Step: 8
Training loss: 3.152763843536377
Validation loss: 2.6845493214104765

Epoch: 5| Step: 9
Training loss: 3.344404935836792
Validation loss: 2.675136345689015

Epoch: 5| Step: 10
Training loss: 2.914595365524292
Validation loss: 2.656618315686462

Epoch: 15| Step: 0
Training loss: 2.6437630653381348
Validation loss: 2.642872387363065

Epoch: 5| Step: 1
Training loss: 3.225071430206299
Validation loss: 2.6442750577003724

Epoch: 5| Step: 2
Training loss: 3.4410126209259033
Validation loss: 2.6381284959854616

Epoch: 5| Step: 3
Training loss: 2.176697015762329
Validation loss: 2.642416395166869

Epoch: 5| Step: 4
Training loss: 3.4187350273132324
Validation loss: 2.6228939179451234

Epoch: 5| Step: 5
Training loss: 3.185767650604248
Validation loss: 2.6173099869041034

Epoch: 5| Step: 6
Training loss: 3.0039899349212646
Validation loss: 2.6144850766786965

Epoch: 5| Step: 7
Training loss: 2.189178943634033
Validation loss: 2.614396692604147

Epoch: 5| Step: 8
Training loss: 2.655164957046509
Validation loss: 2.615003767833915

Epoch: 5| Step: 9
Training loss: 2.7188873291015625
Validation loss: 2.6210563926286596

Epoch: 5| Step: 10
Training loss: 2.2443103790283203
Validation loss: 2.6228414145849084

Epoch: 16| Step: 0
Training loss: 3.394331455230713
Validation loss: 2.666955914548648

Epoch: 5| Step: 1
Training loss: 2.8968796730041504
Validation loss: 2.6352799066933255

Epoch: 5| Step: 2
Training loss: 3.1400396823883057
Validation loss: 2.5976574574747393

Epoch: 5| Step: 3
Training loss: 2.8800508975982666
Validation loss: 2.5914767173028763

Epoch: 5| Step: 4
Training loss: 3.084306001663208
Validation loss: 2.6004346211751304

Epoch: 5| Step: 5
Training loss: 2.6208858489990234
Validation loss: 2.583659828350108

Epoch: 5| Step: 6
Training loss: 3.0852789878845215
Validation loss: 2.583520407317787

Epoch: 5| Step: 7
Training loss: 2.0632481575012207
Validation loss: 2.5787110892675256

Epoch: 5| Step: 8
Training loss: 2.6032917499542236
Validation loss: 2.592808585013113

Epoch: 5| Step: 9
Training loss: 2.625753879547119
Validation loss: 2.6144705331453713

Epoch: 5| Step: 10
Training loss: 2.3011276721954346
Validation loss: 2.6056603770102225

Epoch: 17| Step: 0
Training loss: 2.0705413818359375
Validation loss: 2.6155252149028163

Epoch: 5| Step: 1
Training loss: 3.3780288696289062
Validation loss: 2.607502870662238

Epoch: 5| Step: 2
Training loss: 3.0129199028015137
Validation loss: 2.5728616201749412

Epoch: 5| Step: 3
Training loss: 2.615432024002075
Validation loss: 2.566986660803518

Epoch: 5| Step: 4
Training loss: 2.009434223175049
Validation loss: 2.5669396820888726

Epoch: 5| Step: 5
Training loss: 3.100182056427002
Validation loss: 2.571836289539132

Epoch: 5| Step: 6
Training loss: 3.4815056324005127
Validation loss: 2.56057563904793

Epoch: 5| Step: 7
Training loss: 2.9687745571136475
Validation loss: 2.546479196958644

Epoch: 5| Step: 8
Training loss: 2.6935338973999023
Validation loss: 2.5417904700002363

Epoch: 5| Step: 9
Training loss: 2.6666276454925537
Validation loss: 2.5602515769261185

Epoch: 5| Step: 10
Training loss: 2.4456639289855957
Validation loss: 2.5592462119235786

Epoch: 18| Step: 0
Training loss: 2.8008527755737305
Validation loss: 2.586859772282262

Epoch: 5| Step: 1
Training loss: 3.2807610034942627
Validation loss: 2.556722410263554

Epoch: 5| Step: 2
Training loss: 2.165956974029541
Validation loss: 2.5331450611032467

Epoch: 5| Step: 3
Training loss: 2.1245880126953125
Validation loss: 2.5333072370098484

Epoch: 5| Step: 4
Training loss: 3.2864394187927246
Validation loss: 2.541547188194849

Epoch: 5| Step: 5
Training loss: 3.4345803260803223
Validation loss: 2.5340703148995676

Epoch: 5| Step: 6
Training loss: 2.8497514724731445
Validation loss: 2.528503776878439

Epoch: 5| Step: 7
Training loss: 3.125826358795166
Validation loss: 2.529035440055273

Epoch: 5| Step: 8
Training loss: 1.9620857238769531
Validation loss: 2.55752819584262

Epoch: 5| Step: 9
Training loss: 2.4861273765563965
Validation loss: 2.569852372651459

Epoch: 5| Step: 10
Training loss: 2.9222090244293213
Validation loss: 2.5216071836410032

Epoch: 19| Step: 0
Training loss: 2.8409035205841064
Validation loss: 2.5139872079254477

Epoch: 5| Step: 1
Training loss: 2.457141399383545
Validation loss: 2.5167160059816096

Epoch: 5| Step: 2
Training loss: 2.678018808364868
Validation loss: 2.5161075874041487

Epoch: 5| Step: 3
Training loss: 3.743846893310547
Validation loss: 2.507827043533325

Epoch: 5| Step: 4
Training loss: 2.962149143218994
Validation loss: 2.5039993460460375

Epoch: 5| Step: 5
Training loss: 2.128775119781494
Validation loss: 2.502167752994004

Epoch: 5| Step: 6
Training loss: 2.996696949005127
Validation loss: 2.4995485685204946

Epoch: 5| Step: 7
Training loss: 2.7527101039886475
Validation loss: 2.496544840515301

Epoch: 5| Step: 8
Training loss: 2.6280651092529297
Validation loss: 2.4941911671751287

Epoch: 5| Step: 9
Training loss: 2.464600086212158
Validation loss: 2.5111867330407582

Epoch: 5| Step: 10
Training loss: 2.3298888206481934
Validation loss: 2.515682553732267

Epoch: 20| Step: 0
Training loss: 3.1128711700439453
Validation loss: 2.4911492998882006

Epoch: 5| Step: 1
Training loss: 3.2533669471740723
Validation loss: 2.4846147388540287

Epoch: 5| Step: 2
Training loss: 2.4027392864227295
Validation loss: 2.48340073708565

Epoch: 5| Step: 3
Training loss: 2.9903361797332764
Validation loss: 2.477752272800733

Epoch: 5| Step: 4
Training loss: 3.2682251930236816
Validation loss: 2.483755237312727

Epoch: 5| Step: 5
Training loss: 2.7230770587921143
Validation loss: 2.47790926758961

Epoch: 5| Step: 6
Training loss: 1.9635839462280273
Validation loss: 2.475210617947322

Epoch: 5| Step: 7
Training loss: 2.5553629398345947
Validation loss: 2.4760452316653345

Epoch: 5| Step: 8
Training loss: 1.981128454208374
Validation loss: 2.471494372173022

Epoch: 5| Step: 9
Training loss: 2.633452892303467
Validation loss: 2.470045353776665

Epoch: 5| Step: 10
Training loss: 3.0766289234161377
Validation loss: 2.4999915425495436

Epoch: 21| Step: 0
Training loss: 2.5284600257873535
Validation loss: 2.5663400824351976

Epoch: 5| Step: 1
Training loss: 2.9516890048980713
Validation loss: 2.5026398345988285

Epoch: 5| Step: 2
Training loss: 2.4368176460266113
Validation loss: 2.475566441012967

Epoch: 5| Step: 3
Training loss: 2.4429452419281006
Validation loss: 2.5017355539465465

Epoch: 5| Step: 4
Training loss: 2.898405075073242
Validation loss: 2.497996202079199

Epoch: 5| Step: 5
Training loss: 2.9587368965148926
Validation loss: 2.4955792965427523

Epoch: 5| Step: 6
Training loss: 2.69404935836792
Validation loss: 2.4884387523897233

Epoch: 5| Step: 7
Training loss: 3.0068275928497314
Validation loss: 2.4883278544231127

Epoch: 5| Step: 8
Training loss: 2.6424813270568848
Validation loss: 2.470130617900561

Epoch: 5| Step: 9
Training loss: 2.2151741981506348
Validation loss: 2.4706020073224138

Epoch: 5| Step: 10
Training loss: 3.4184563159942627
Validation loss: 2.4669315379153014

Epoch: 22| Step: 0
Training loss: 2.465067148208618
Validation loss: 2.482122157209663

Epoch: 5| Step: 1
Training loss: 3.429973602294922
Validation loss: 2.4875459824838946

Epoch: 5| Step: 2
Training loss: 2.4314303398132324
Validation loss: 2.464905615775816

Epoch: 5| Step: 3
Training loss: 3.0480153560638428
Validation loss: 2.4625601589038806

Epoch: 5| Step: 4
Training loss: 2.027705430984497
Validation loss: 2.459844728951813

Epoch: 5| Step: 5
Training loss: 2.498739719390869
Validation loss: 2.45541734849253

Epoch: 5| Step: 6
Training loss: 3.134084939956665
Validation loss: 2.4582291264687814

Epoch: 5| Step: 7
Training loss: 2.8910605907440186
Validation loss: 2.4499169729089223

Epoch: 5| Step: 8
Training loss: 2.665783643722534
Validation loss: 2.4530206136806036

Epoch: 5| Step: 9
Training loss: 2.811136245727539
Validation loss: 2.4501174624248216

Epoch: 5| Step: 10
Training loss: 2.222501277923584
Validation loss: 2.450448338703443

Epoch: 23| Step: 0
Training loss: 2.9481258392333984
Validation loss: 2.4564742221627185

Epoch: 5| Step: 1
Training loss: 2.680464267730713
Validation loss: 2.463259889233497

Epoch: 5| Step: 2
Training loss: 2.709320545196533
Validation loss: 2.458606735352547

Epoch: 5| Step: 3
Training loss: 2.1696245670318604
Validation loss: 2.449321359716436

Epoch: 5| Step: 4
Training loss: 2.800875186920166
Validation loss: 2.4399517813036518

Epoch: 5| Step: 5
Training loss: 2.5948665142059326
Validation loss: 2.4404772968702417

Epoch: 5| Step: 6
Training loss: 3.286698818206787
Validation loss: 2.4393088971414874

Epoch: 5| Step: 7
Training loss: 2.5059235095977783
Validation loss: 2.4363230659115698

Epoch: 5| Step: 8
Training loss: 2.6597206592559814
Validation loss: 2.440447594529839

Epoch: 5| Step: 9
Training loss: 2.5157017707824707
Validation loss: 2.4439242296321417

Epoch: 5| Step: 10
Training loss: 2.740558385848999
Validation loss: 2.4447028124204246

Epoch: 24| Step: 0
Training loss: 2.593008279800415
Validation loss: 2.4453223302800167

Epoch: 5| Step: 1
Training loss: 2.165668487548828
Validation loss: 2.440570987680907

Epoch: 5| Step: 2
Training loss: 2.5641732215881348
Validation loss: 2.4465748648489676

Epoch: 5| Step: 3
Training loss: 2.8133630752563477
Validation loss: 2.459767295468238

Epoch: 5| Step: 4
Training loss: 2.7452123165130615
Validation loss: 2.4875393093273206

Epoch: 5| Step: 5
Training loss: 3.646484375
Validation loss: 2.4899517964291316

Epoch: 5| Step: 6
Training loss: 2.908872604370117
Validation loss: 2.468117936964958

Epoch: 5| Step: 7
Training loss: 2.244077205657959
Validation loss: 2.441408316294352

Epoch: 5| Step: 8
Training loss: 2.953155279159546
Validation loss: 2.4328577518463135

Epoch: 5| Step: 9
Training loss: 2.343855619430542
Validation loss: 2.443342783117807

Epoch: 5| Step: 10
Training loss: 2.549964189529419
Validation loss: 2.447937124518938

Epoch: 25| Step: 0
Training loss: 3.1903774738311768
Validation loss: 2.469427336928665

Epoch: 5| Step: 1
Training loss: 2.340644598007202
Validation loss: 2.4534326138034945

Epoch: 5| Step: 2
Training loss: 3.218626022338867
Validation loss: 2.4390989042097524

Epoch: 5| Step: 3
Training loss: 2.5466232299804688
Validation loss: 2.4259660679806947

Epoch: 5| Step: 4
Training loss: 2.311131715774536
Validation loss: 2.4360696013255785

Epoch: 5| Step: 5
Training loss: 2.685108184814453
Validation loss: 2.475888939313991

Epoch: 5| Step: 6
Training loss: 2.453714370727539
Validation loss: 2.5396186049266527

Epoch: 5| Step: 7
Training loss: 2.5421855449676514
Validation loss: 2.5504030642970914

Epoch: 5| Step: 8
Training loss: 2.4997494220733643
Validation loss: 2.560866468696184

Epoch: 5| Step: 9
Training loss: 3.154632091522217
Validation loss: 2.4599879223813295

Epoch: 5| Step: 10
Training loss: 2.782668352127075
Validation loss: 2.4180773740173667

Epoch: 26| Step: 0
Training loss: 2.4605607986450195
Validation loss: 2.4170564682252946

Epoch: 5| Step: 1
Training loss: 2.602242946624756
Validation loss: 2.4408033176134993

Epoch: 5| Step: 2
Training loss: 2.668541431427002
Validation loss: 2.4410890251077633

Epoch: 5| Step: 3
Training loss: 2.65963077545166
Validation loss: 2.4667199709082164

Epoch: 5| Step: 4
Training loss: 2.2786688804626465
Validation loss: 2.5297815838167743

Epoch: 5| Step: 5
Training loss: 2.6153807640075684
Validation loss: 2.585365487683204

Epoch: 5| Step: 6
Training loss: 3.4624924659729004
Validation loss: 2.579450350935741

Epoch: 5| Step: 7
Training loss: 3.1294260025024414
Validation loss: 2.4693166491805867

Epoch: 5| Step: 8
Training loss: 2.9935100078582764
Validation loss: 2.453093174965151

Epoch: 5| Step: 9
Training loss: 2.7333173751831055
Validation loss: 2.444147591949791

Epoch: 5| Step: 10
Training loss: 2.222947359085083
Validation loss: 2.5055796433520574

Epoch: 27| Step: 0
Training loss: 3.2106566429138184
Validation loss: 2.5795041463708364

Epoch: 5| Step: 1
Training loss: 2.970224380493164
Validation loss: 2.5920607659124557

Epoch: 5| Step: 2
Training loss: 2.4800376892089844
Validation loss: 2.5143754046450377

Epoch: 5| Step: 3
Training loss: 2.087441921234131
Validation loss: 2.450071414311727

Epoch: 5| Step: 4
Training loss: 2.4112470149993896
Validation loss: 2.423126894940612

Epoch: 5| Step: 5
Training loss: 2.627272129058838
Validation loss: 2.413694166368054

Epoch: 5| Step: 6
Training loss: 2.504660129547119
Validation loss: 2.4179277625135196

Epoch: 5| Step: 7
Training loss: 2.513115644454956
Validation loss: 2.433401682043588

Epoch: 5| Step: 8
Training loss: 3.753732204437256
Validation loss: 2.4617625257020355

Epoch: 5| Step: 9
Training loss: 2.663003444671631
Validation loss: 2.4411708975350983

Epoch: 5| Step: 10
Training loss: 2.4441537857055664
Validation loss: 2.426786530402399

Epoch: 28| Step: 0
Training loss: 2.099306106567383
Validation loss: 2.414226398673109

Epoch: 5| Step: 1
Training loss: 3.1802868843078613
Validation loss: 2.411834283541608

Epoch: 5| Step: 2
Training loss: 2.3525946140289307
Validation loss: 2.4155435510860976

Epoch: 5| Step: 3
Training loss: 2.5271947383880615
Validation loss: 2.4243662049693446

Epoch: 5| Step: 4
Training loss: 2.264178514480591
Validation loss: 2.430976667711812

Epoch: 5| Step: 5
Training loss: 3.792267322540283
Validation loss: 2.4484960725230556

Epoch: 5| Step: 6
Training loss: 2.8491828441619873
Validation loss: 2.442794710077265

Epoch: 5| Step: 7
Training loss: 2.5131077766418457
Validation loss: 2.4242890650226223

Epoch: 5| Step: 8
Training loss: 2.795529365539551
Validation loss: 2.4063523738614974

Epoch: 5| Step: 9
Training loss: 2.2771968841552734
Validation loss: 2.4127944054142123

Epoch: 5| Step: 10
Training loss: 2.7441422939300537
Validation loss: 2.4140467618101384

Epoch: 29| Step: 0
Training loss: 2.340604305267334
Validation loss: 2.4120893196393083

Epoch: 5| Step: 1
Training loss: 2.7843680381774902
Validation loss: 2.431238684602963

Epoch: 5| Step: 2
Training loss: 1.9992144107818604
Validation loss: 2.4237267432674283

Epoch: 5| Step: 3
Training loss: 2.3492066860198975
Validation loss: 2.397703488667806

Epoch: 5| Step: 4
Training loss: 3.846994400024414
Validation loss: 2.3812482228843113

Epoch: 5| Step: 5
Training loss: 2.6194913387298584
Validation loss: 2.368572496598767

Epoch: 5| Step: 6
Training loss: 3.119473934173584
Validation loss: 2.36719540754954

Epoch: 5| Step: 7
Training loss: 2.2559125423431396
Validation loss: 2.3701969295419674

Epoch: 5| Step: 8
Training loss: 2.0111052989959717
Validation loss: 2.3893309562436995

Epoch: 5| Step: 9
Training loss: 3.302590847015381
Validation loss: 2.3939859892732356

Epoch: 5| Step: 10
Training loss: 2.583573818206787
Validation loss: 2.393354167220413

Epoch: 30| Step: 0
Training loss: 2.3263823986053467
Validation loss: 2.388487174946775

Epoch: 5| Step: 1
Training loss: 2.2585196495056152
Validation loss: 2.3779689804200204

Epoch: 5| Step: 2
Training loss: 2.451141357421875
Validation loss: 2.387539494422174

Epoch: 5| Step: 3
Training loss: 2.8360838890075684
Validation loss: 2.396386210636426

Epoch: 5| Step: 4
Training loss: 2.549180269241333
Validation loss: 2.4058669895254154

Epoch: 5| Step: 5
Training loss: 3.34393048286438
Validation loss: 2.401084041082731

Epoch: 5| Step: 6
Training loss: 3.124765634536743
Validation loss: 2.3797174064061974

Epoch: 5| Step: 7
Training loss: 2.0091452598571777
Validation loss: 2.3690606265939693

Epoch: 5| Step: 8
Training loss: 2.883694648742676
Validation loss: 2.365961320938603

Epoch: 5| Step: 9
Training loss: 2.383234739303589
Validation loss: 2.371337293296732

Epoch: 5| Step: 10
Training loss: 2.9982047080993652
Validation loss: 2.3671871359630297

Epoch: 31| Step: 0
Training loss: 3.0939290523529053
Validation loss: 2.379738712823519

Epoch: 5| Step: 1
Training loss: 2.9242405891418457
Validation loss: 2.3686674461569837

Epoch: 5| Step: 2
Training loss: 2.538999557495117
Validation loss: 2.366922693867837

Epoch: 5| Step: 3
Training loss: 2.661931276321411
Validation loss: 2.363929731871492

Epoch: 5| Step: 4
Training loss: 2.508058547973633
Validation loss: 2.3606077958178777

Epoch: 5| Step: 5
Training loss: 2.828070640563965
Validation loss: 2.357521567293393

Epoch: 5| Step: 6
Training loss: 2.6935629844665527
Validation loss: 2.3545529175830144

Epoch: 5| Step: 7
Training loss: 2.061509609222412
Validation loss: 2.3614612753673265

Epoch: 5| Step: 8
Training loss: 1.9055757522583008
Validation loss: 2.381013777948195

Epoch: 5| Step: 9
Training loss: 3.2419962882995605
Validation loss: 2.4053730554478143

Epoch: 5| Step: 10
Training loss: 2.6110706329345703
Validation loss: 2.422589535354286

Epoch: 32| Step: 0
Training loss: 2.4838151931762695
Validation loss: 2.4170965148556616

Epoch: 5| Step: 1
Training loss: 2.074178457260132
Validation loss: 2.4019247421654324

Epoch: 5| Step: 2
Training loss: 2.760047435760498
Validation loss: 2.3728111405526437

Epoch: 5| Step: 3
Training loss: 2.5828588008880615
Validation loss: 2.376288024328088

Epoch: 5| Step: 4
Training loss: 2.578423261642456
Validation loss: 2.3768029597497757

Epoch: 5| Step: 5
Training loss: 2.500777244567871
Validation loss: 2.382773689044419

Epoch: 5| Step: 6
Training loss: 2.9316823482513428
Validation loss: 2.4040324123956824

Epoch: 5| Step: 7
Training loss: 2.701427936553955
Validation loss: 2.4008259619435957

Epoch: 5| Step: 8
Training loss: 2.4430136680603027
Validation loss: 2.4239189188967467

Epoch: 5| Step: 9
Training loss: 2.5618205070495605
Validation loss: 2.4479722438320035

Epoch: 5| Step: 10
Training loss: 3.505397319793701
Validation loss: 2.4182068532513035

Epoch: 33| Step: 0
Training loss: 2.674421787261963
Validation loss: 2.375257179301272

Epoch: 5| Step: 1
Training loss: 2.2334799766540527
Validation loss: 2.360013584936819

Epoch: 5| Step: 2
Training loss: 2.9976165294647217
Validation loss: 2.366116205851237

Epoch: 5| Step: 3
Training loss: 2.9807288646698
Validation loss: 2.3699162852379585

Epoch: 5| Step: 4
Training loss: 2.9600958824157715
Validation loss: 2.365464707856537

Epoch: 5| Step: 5
Training loss: 2.455531120300293
Validation loss: 2.351883844662738

Epoch: 5| Step: 6
Training loss: 2.8737523555755615
Validation loss: 2.3536828538422943

Epoch: 5| Step: 7
Training loss: 2.7414181232452393
Validation loss: 2.3467624161833074

Epoch: 5| Step: 8
Training loss: 2.6277992725372314
Validation loss: 2.3440202359230287

Epoch: 5| Step: 9
Training loss: 2.1399619579315186
Validation loss: 2.34885766942014

Epoch: 5| Step: 10
Training loss: 2.199193000793457
Validation loss: 2.3667804630853797

Epoch: 34| Step: 0
Training loss: 2.5893352031707764
Validation loss: 2.3771046207797144

Epoch: 5| Step: 1
Training loss: 3.3283190727233887
Validation loss: 2.3721287968338176

Epoch: 5| Step: 2
Training loss: 3.0163424015045166
Validation loss: 2.3650631596965175

Epoch: 5| Step: 3
Training loss: 2.616283893585205
Validation loss: 2.3516267371434036

Epoch: 5| Step: 4
Training loss: 2.1064486503601074
Validation loss: 2.340771302100151

Epoch: 5| Step: 5
Training loss: 2.2000417709350586
Validation loss: 2.332922348412134

Epoch: 5| Step: 6
Training loss: 2.5009279251098633
Validation loss: 2.333895068014822

Epoch: 5| Step: 7
Training loss: 2.078313112258911
Validation loss: 2.335351208204864

Epoch: 5| Step: 8
Training loss: 2.71278715133667
Validation loss: 2.344967811338363

Epoch: 5| Step: 9
Training loss: 3.0509543418884277
Validation loss: 2.3668086887687765

Epoch: 5| Step: 10
Training loss: 2.744684934616089
Validation loss: 2.4002748817525883

Epoch: 35| Step: 0
Training loss: 2.5821645259857178
Validation loss: 2.4405329355629544

Epoch: 5| Step: 1
Training loss: 3.106222629547119
Validation loss: 2.4563923599899455

Epoch: 5| Step: 2
Training loss: 2.3376529216766357
Validation loss: 2.3993604644652335

Epoch: 5| Step: 3
Training loss: 2.726959228515625
Validation loss: 2.3474981323365243

Epoch: 5| Step: 4
Training loss: 1.8412208557128906
Validation loss: 2.3357948487804783

Epoch: 5| Step: 5
Training loss: 2.6741814613342285
Validation loss: 2.3277485524454424

Epoch: 5| Step: 6
Training loss: 2.845641851425171
Validation loss: 2.332149943997783

Epoch: 5| Step: 7
Training loss: 1.8511613607406616
Validation loss: 2.353163601249777

Epoch: 5| Step: 8
Training loss: 2.8591649532318115
Validation loss: 2.375916701491161

Epoch: 5| Step: 9
Training loss: 2.8768391609191895
Validation loss: 2.3669515296977055

Epoch: 5| Step: 10
Training loss: 3.3121047019958496
Validation loss: 2.3819665793449647

Epoch: 36| Step: 0
Training loss: 2.5155673027038574
Validation loss: 2.3535820104742564

Epoch: 5| Step: 1
Training loss: 1.8438478708267212
Validation loss: 2.332935325561031

Epoch: 5| Step: 2
Training loss: 3.036228656768799
Validation loss: 2.333535361033614

Epoch: 5| Step: 3
Training loss: 2.388667345046997
Validation loss: 2.3378438154856362

Epoch: 5| Step: 4
Training loss: 2.7098090648651123
Validation loss: 2.3358473752134588

Epoch: 5| Step: 5
Training loss: 2.6633002758026123
Validation loss: 2.333076032259131

Epoch: 5| Step: 6
Training loss: 2.4730656147003174
Validation loss: 2.330872271650581

Epoch: 5| Step: 7
Training loss: 2.755535364151001
Validation loss: 2.3461235800097064

Epoch: 5| Step: 8
Training loss: 2.736685276031494
Validation loss: 2.349592137080367

Epoch: 5| Step: 9
Training loss: 2.479454517364502
Validation loss: 2.346695764090425

Epoch: 5| Step: 10
Training loss: 3.0635290145874023
Validation loss: 2.3296926060030536

Epoch: 37| Step: 0
Training loss: 3.046801805496216
Validation loss: 2.3188592900512037

Epoch: 5| Step: 1
Training loss: 2.2018978595733643
Validation loss: 2.3137130378395

Epoch: 5| Step: 2
Training loss: 2.3104207515716553
Validation loss: 2.3167993304550007

Epoch: 5| Step: 3
Training loss: 2.29203462600708
Validation loss: 2.3194245112839567

Epoch: 5| Step: 4
Training loss: 2.8060591220855713
Validation loss: 2.3206762395879275

Epoch: 5| Step: 5
Training loss: 3.0537872314453125
Validation loss: 2.337821452848373

Epoch: 5| Step: 6
Training loss: 2.3415029048919678
Validation loss: 2.3490544519116803

Epoch: 5| Step: 7
Training loss: 3.287600040435791
Validation loss: 2.353884090659439

Epoch: 5| Step: 8
Training loss: 2.491025924682617
Validation loss: 2.3349435483255694

Epoch: 5| Step: 9
Training loss: 2.4404454231262207
Validation loss: 2.3125044017709713

Epoch: 5| Step: 10
Training loss: 2.292787551879883
Validation loss: 2.302442853168775

Epoch: 38| Step: 0
Training loss: 2.16587495803833
Validation loss: 2.3034220818550355

Epoch: 5| Step: 1
Training loss: 1.7845557928085327
Validation loss: 2.3061497083274265

Epoch: 5| Step: 2
Training loss: 2.8740737438201904
Validation loss: 2.3059945773052912

Epoch: 5| Step: 3
Training loss: 3.076413631439209
Validation loss: 2.303731438934162

Epoch: 5| Step: 4
Training loss: 2.339369297027588
Validation loss: 2.301742999784408

Epoch: 5| Step: 5
Training loss: 2.707484722137451
Validation loss: 2.2954169319521998

Epoch: 5| Step: 6
Training loss: 3.063096523284912
Validation loss: 2.2947070957511984

Epoch: 5| Step: 7
Training loss: 2.488417387008667
Validation loss: 2.2956774106589695

Epoch: 5| Step: 8
Training loss: 2.665417194366455
Validation loss: 2.304582631716164

Epoch: 5| Step: 9
Training loss: 2.8295655250549316
Validation loss: 2.305137936786939

Epoch: 5| Step: 10
Training loss: 2.69174861907959
Validation loss: 2.3047755559285483

Epoch: 39| Step: 0
Training loss: 2.333054304122925
Validation loss: 2.317259750058574

Epoch: 5| Step: 1
Training loss: 2.2693376541137695
Validation loss: 2.3234774117828696

Epoch: 5| Step: 2
Training loss: 2.3317291736602783
Validation loss: 2.340834157441252

Epoch: 5| Step: 3
Training loss: 2.2152938842773438
Validation loss: 2.342484128090643

Epoch: 5| Step: 4
Training loss: 2.6101441383361816
Validation loss: 2.3202679259802705

Epoch: 5| Step: 5
Training loss: 3.7199866771698
Validation loss: 2.310790044005199

Epoch: 5| Step: 6
Training loss: 2.9484896659851074
Validation loss: 2.2935735128259145

Epoch: 5| Step: 7
Training loss: 2.058767080307007
Validation loss: 2.2941103417386293

Epoch: 5| Step: 8
Training loss: 2.706505298614502
Validation loss: 2.2895925609014367

Epoch: 5| Step: 9
Training loss: 2.6834049224853516
Validation loss: 2.2907191861060356

Epoch: 5| Step: 10
Training loss: 2.4091553688049316
Validation loss: 2.2918656359436693

Epoch: 40| Step: 0
Training loss: 3.02927303314209
Validation loss: 2.291578180046492

Epoch: 5| Step: 1
Training loss: 2.9003961086273193
Validation loss: 2.2923260760563675

Epoch: 5| Step: 2
Training loss: 2.714479446411133
Validation loss: 2.2859408945165653

Epoch: 5| Step: 3
Training loss: 1.9461820125579834
Validation loss: 2.2868455379239974

Epoch: 5| Step: 4
Training loss: 2.8314871788024902
Validation loss: 2.291220208649994

Epoch: 5| Step: 5
Training loss: 1.9111852645874023
Validation loss: 2.292421902379682

Epoch: 5| Step: 6
Training loss: 2.5070414543151855
Validation loss: 2.298557432748938

Epoch: 5| Step: 7
Training loss: 2.864591598510742
Validation loss: 2.3284306423638457

Epoch: 5| Step: 8
Training loss: 2.2888476848602295
Validation loss: 2.363003238554924

Epoch: 5| Step: 9
Training loss: 2.5945680141448975
Validation loss: 2.4174110325433875

Epoch: 5| Step: 10
Training loss: 3.0492537021636963
Validation loss: 2.420753199567077

Epoch: 41| Step: 0
Training loss: 2.545595645904541
Validation loss: 2.337831743301884

Epoch: 5| Step: 1
Training loss: 2.8197033405303955
Validation loss: 2.287132638756947

Epoch: 5| Step: 2
Training loss: 2.738670587539673
Validation loss: 2.288011699594477

Epoch: 5| Step: 3
Training loss: 2.9206643104553223
Validation loss: 2.304891311994163

Epoch: 5| Step: 4
Training loss: 2.7629666328430176
Validation loss: 2.3143662329643004

Epoch: 5| Step: 5
Training loss: 2.496126890182495
Validation loss: 2.3098447630482335

Epoch: 5| Step: 6
Training loss: 2.1632304191589355
Validation loss: 2.282073069644231

Epoch: 5| Step: 7
Training loss: 2.670788526535034
Validation loss: 2.276509731046615

Epoch: 5| Step: 8
Training loss: 2.8594067096710205
Validation loss: 2.281814308576686

Epoch: 5| Step: 9
Training loss: 1.6303560733795166
Validation loss: 2.287875247258012

Epoch: 5| Step: 10
Training loss: 2.964219093322754
Validation loss: 2.308002059177686

Epoch: 42| Step: 0
Training loss: 2.6767942905426025
Validation loss: 2.331360455482237

Epoch: 5| Step: 1
Training loss: 2.2353787422180176
Validation loss: 2.36798688673204

Epoch: 5| Step: 2
Training loss: 3.5163052082061768
Validation loss: 2.381347474231515

Epoch: 5| Step: 3
Training loss: 2.3600409030914307
Validation loss: 2.353346388827088

Epoch: 5| Step: 4
Training loss: 2.796219825744629
Validation loss: 2.3158553287547123

Epoch: 5| Step: 5
Training loss: 2.942516803741455
Validation loss: 2.2824100935330955

Epoch: 5| Step: 6
Training loss: 2.8335771560668945
Validation loss: 2.2696654642781904

Epoch: 5| Step: 7
Training loss: 2.596240997314453
Validation loss: 2.2696754265857

Epoch: 5| Step: 8
Training loss: 1.933638334274292
Validation loss: 2.2766549612886164

Epoch: 5| Step: 9
Training loss: 2.544288396835327
Validation loss: 2.274535837993827

Epoch: 5| Step: 10
Training loss: 1.948243498802185
Validation loss: 2.277823148235198

Epoch: 43| Step: 0
Training loss: 2.421543836593628
Validation loss: 2.2747917957203363

Epoch: 5| Step: 1
Training loss: 2.8026623725891113
Validation loss: 2.2791668509924286

Epoch: 5| Step: 2
Training loss: 2.37864351272583
Validation loss: 2.29737881178497

Epoch: 5| Step: 3
Training loss: 2.561065196990967
Validation loss: 2.3252952688483783

Epoch: 5| Step: 4
Training loss: 2.631206750869751
Validation loss: 2.341784715652466

Epoch: 5| Step: 5
Training loss: 3.051621913909912
Validation loss: 2.3417485529376614

Epoch: 5| Step: 6
Training loss: 2.276247262954712
Validation loss: 2.3367512815742084

Epoch: 5| Step: 7
Training loss: 2.0936567783355713
Validation loss: 2.3575036243725846

Epoch: 5| Step: 8
Training loss: 2.36678147315979
Validation loss: 2.3787650600556405

Epoch: 5| Step: 9
Training loss: 2.7815661430358887
Validation loss: 2.375902057975851

Epoch: 5| Step: 10
Training loss: 3.25854754447937
Validation loss: 2.3196326507035123

Epoch: 44| Step: 0
Training loss: 1.7333450317382812
Validation loss: 2.2826243267264417

Epoch: 5| Step: 1
Training loss: 2.771886110305786
Validation loss: 2.266549630831647

Epoch: 5| Step: 2
Training loss: 2.529510736465454
Validation loss: 2.26301089666223

Epoch: 5| Step: 3
Training loss: 2.6534934043884277
Validation loss: 2.2660664486628708

Epoch: 5| Step: 4
Training loss: 2.134629011154175
Validation loss: 2.2729986649687572

Epoch: 5| Step: 5
Training loss: 3.3009109497070312
Validation loss: 2.2784747667210077

Epoch: 5| Step: 6
Training loss: 3.1389174461364746
Validation loss: 2.2804606550483295

Epoch: 5| Step: 7
Training loss: 2.993363857269287
Validation loss: 2.2642949191472863

Epoch: 5| Step: 8
Training loss: 2.039733409881592
Validation loss: 2.263287110995221

Epoch: 5| Step: 9
Training loss: 2.223306179046631
Validation loss: 2.273365315570626

Epoch: 5| Step: 10
Training loss: 2.5999410152435303
Validation loss: 2.263495111978182

Epoch: 45| Step: 0
Training loss: 2.1973068714141846
Validation loss: 2.2586645131470053

Epoch: 5| Step: 1
Training loss: 2.7289769649505615
Validation loss: 2.244466120196927

Epoch: 5| Step: 2
Training loss: 2.380270481109619
Validation loss: 2.240488608678182

Epoch: 5| Step: 3
Training loss: 2.4967763423919678
Validation loss: 2.231126844242055

Epoch: 5| Step: 4
Training loss: 3.061460494995117
Validation loss: 2.2335441573973625

Epoch: 5| Step: 5
Training loss: 1.9026470184326172
Validation loss: 2.2340489651567195

Epoch: 5| Step: 6
Training loss: 2.316771984100342
Validation loss: 2.2381354326842935

Epoch: 5| Step: 7
Training loss: 2.449119806289673
Validation loss: 2.2655718172750166

Epoch: 5| Step: 8
Training loss: 3.392336368560791
Validation loss: 2.2833815159336215

Epoch: 5| Step: 9
Training loss: 2.4659295082092285
Validation loss: 2.2955667152199695

Epoch: 5| Step: 10
Training loss: 2.7394657135009766
Validation loss: 2.3021763152973627

Epoch: 46| Step: 0
Training loss: 2.1263411045074463
Validation loss: 2.283882382095501

Epoch: 5| Step: 1
Training loss: 2.7456185817718506
Validation loss: 2.2665820147401545

Epoch: 5| Step: 2
Training loss: 3.0641021728515625
Validation loss: 2.268445958373367

Epoch: 5| Step: 3
Training loss: 2.8138835430145264
Validation loss: 2.2568369680835354

Epoch: 5| Step: 4
Training loss: 2.555743455886841
Validation loss: 2.241889871576781

Epoch: 5| Step: 5
Training loss: 2.199657440185547
Validation loss: 2.2315708334727953

Epoch: 5| Step: 6
Training loss: 1.9121971130371094
Validation loss: 2.2258458137512207

Epoch: 5| Step: 7
Training loss: 2.6441526412963867
Validation loss: 2.226615910889

Epoch: 5| Step: 8
Training loss: 2.3614931106567383
Validation loss: 2.2268431878859

Epoch: 5| Step: 9
Training loss: 3.2571816444396973
Validation loss: 2.233627465463454

Epoch: 5| Step: 10
Training loss: 2.345853567123413
Validation loss: 2.2324733887949297

Epoch: 47| Step: 0
Training loss: 2.2594408988952637
Validation loss: 2.2332542327142533

Epoch: 5| Step: 1
Training loss: 2.143991231918335
Validation loss: 2.238399840170337

Epoch: 5| Step: 2
Training loss: 2.5410053730010986
Validation loss: 2.2351787231301747

Epoch: 5| Step: 3
Training loss: 2.9075372219085693
Validation loss: 2.2335973503769084

Epoch: 5| Step: 4
Training loss: 2.4307801723480225
Validation loss: 2.2332550864065848

Epoch: 5| Step: 5
Training loss: 2.1579654216766357
Validation loss: 2.2264127833868868

Epoch: 5| Step: 6
Training loss: 3.3598110675811768
Validation loss: 2.230814803031183

Epoch: 5| Step: 7
Training loss: 2.1520068645477295
Validation loss: 2.2371851936463387

Epoch: 5| Step: 8
Training loss: 2.6367034912109375
Validation loss: 2.25076304071693

Epoch: 5| Step: 9
Training loss: 2.2386679649353027
Validation loss: 2.2632590160574964

Epoch: 5| Step: 10
Training loss: 3.139115810394287
Validation loss: 2.2742943058731737

Epoch: 48| Step: 0
Training loss: 2.3297042846679688
Validation loss: 2.275369385237335

Epoch: 5| Step: 1
Training loss: 2.9970450401306152
Validation loss: 2.298963141697709

Epoch: 5| Step: 2
Training loss: 2.957396984100342
Validation loss: 2.2964076893303984

Epoch: 5| Step: 3
Training loss: 2.0576329231262207
Validation loss: 2.290756430677188

Epoch: 5| Step: 4
Training loss: 2.713834285736084
Validation loss: 2.287196215762887

Epoch: 5| Step: 5
Training loss: 2.685875654220581
Validation loss: 2.2555005370929675

Epoch: 5| Step: 6
Training loss: 2.289701461791992
Validation loss: 2.2377715354324668

Epoch: 5| Step: 7
Training loss: 2.111269474029541
Validation loss: 2.229038069325109

Epoch: 5| Step: 8
Training loss: 2.325197458267212
Validation loss: 2.222613657674482

Epoch: 5| Step: 9
Training loss: 2.7059760093688965
Validation loss: 2.218713500166452

Epoch: 5| Step: 10
Training loss: 2.6237854957580566
Validation loss: 2.21454099429551

Epoch: 49| Step: 0
Training loss: 2.7769775390625
Validation loss: 2.209927479426066

Epoch: 5| Step: 1
Training loss: 1.4193328619003296
Validation loss: 2.2111342312187277

Epoch: 5| Step: 2
Training loss: 3.270371913909912
Validation loss: 2.214389253688115

Epoch: 5| Step: 3
Training loss: 2.482174873352051
Validation loss: 2.223216756697624

Epoch: 5| Step: 4
Training loss: 2.6184182167053223
Validation loss: 2.2362381745410222

Epoch: 5| Step: 5
Training loss: 1.9585201740264893
Validation loss: 2.2711717031335317

Epoch: 5| Step: 6
Training loss: 2.4841485023498535
Validation loss: 2.30344464958355

Epoch: 5| Step: 7
Training loss: 2.8988447189331055
Validation loss: 2.306743521844187

Epoch: 5| Step: 8
Training loss: 2.914745807647705
Validation loss: 2.2842853735851985

Epoch: 5| Step: 9
Training loss: 2.670240879058838
Validation loss: 2.2500668059113207

Epoch: 5| Step: 10
Training loss: 2.3706634044647217
Validation loss: 2.2234400190332884

Epoch: 50| Step: 0
Training loss: 2.3650200366973877
Validation loss: 2.2096863690242974

Epoch: 5| Step: 1
Training loss: 2.954763889312744
Validation loss: 2.2019808266752507

Epoch: 5| Step: 2
Training loss: 2.94901180267334
Validation loss: 2.2056961931208128

Epoch: 5| Step: 3
Training loss: 2.7762274742126465
Validation loss: 2.206963167395643

Epoch: 5| Step: 4
Training loss: 2.5577681064605713
Validation loss: 2.2060677530944988

Epoch: 5| Step: 5
Training loss: 2.5349209308624268
Validation loss: 2.205664825695817

Epoch: 5| Step: 6
Training loss: 2.5487477779388428
Validation loss: 2.203445960116643

Epoch: 5| Step: 7
Training loss: 2.112025737762451
Validation loss: 2.199006862537835

Epoch: 5| Step: 8
Training loss: 2.005601406097412
Validation loss: 2.197622873449838

Epoch: 5| Step: 9
Training loss: 2.652284860610962
Validation loss: 2.1938143366126606

Epoch: 5| Step: 10
Training loss: 2.5105977058410645
Validation loss: 2.1931532941838747

Epoch: 51| Step: 0
Training loss: 2.0900347232818604
Validation loss: 2.203589818810904

Epoch: 5| Step: 1
Training loss: 3.013291597366333
Validation loss: 2.207016796194097

Epoch: 5| Step: 2
Training loss: 3.037599563598633
Validation loss: 2.233359472725981

Epoch: 5| Step: 3
Training loss: 2.0019075870513916
Validation loss: 2.2437656259024017

Epoch: 5| Step: 4
Training loss: 1.868112564086914
Validation loss: 2.245608150318105

Epoch: 5| Step: 5
Training loss: 3.216181993484497
Validation loss: 2.23937891631998

Epoch: 5| Step: 6
Training loss: 1.7916162014007568
Validation loss: 2.2372373406605055

Epoch: 5| Step: 7
Training loss: 3.041290760040283
Validation loss: 2.2073432527562624

Epoch: 5| Step: 8
Training loss: 3.031339645385742
Validation loss: 2.20028087400621

Epoch: 5| Step: 9
Training loss: 2.0356650352478027
Validation loss: 2.193086983055197

Epoch: 5| Step: 10
Training loss: 2.5335965156555176
Validation loss: 2.182475177190637

Epoch: 52| Step: 0
Training loss: 2.8320422172546387
Validation loss: 2.187574255851007

Epoch: 5| Step: 1
Training loss: 2.5315489768981934
Validation loss: 2.189704061836325

Epoch: 5| Step: 2
Training loss: 2.217865467071533
Validation loss: 2.1900791019521733

Epoch: 5| Step: 3
Training loss: 2.6128132343292236
Validation loss: 2.1900168695757465

Epoch: 5| Step: 4
Training loss: 2.6937384605407715
Validation loss: 2.1837365140197096

Epoch: 5| Step: 5
Training loss: 2.485563278198242
Validation loss: 2.185377933645761

Epoch: 5| Step: 6
Training loss: 2.5055031776428223
Validation loss: 2.187690063189435

Epoch: 5| Step: 7
Training loss: 2.9284884929656982
Validation loss: 2.1821025750970326

Epoch: 5| Step: 8
Training loss: 1.9580923318862915
Validation loss: 2.1869906481876167

Epoch: 5| Step: 9
Training loss: 1.901673674583435
Validation loss: 2.194349229976695

Epoch: 5| Step: 10
Training loss: 3.0221128463745117
Validation loss: 2.2155076226880475

Epoch: 53| Step: 0
Training loss: 2.202944278717041
Validation loss: 2.218273755042784

Epoch: 5| Step: 1
Training loss: 2.4307210445404053
Validation loss: 2.239162173322452

Epoch: 5| Step: 2
Training loss: 2.0435264110565186
Validation loss: 2.2409551630737963

Epoch: 5| Step: 3
Training loss: 2.263643264770508
Validation loss: 2.2416428981288785

Epoch: 5| Step: 4
Training loss: 2.8478565216064453
Validation loss: 2.2436750332514444

Epoch: 5| Step: 5
Training loss: 2.7348577976226807
Validation loss: 2.223460897322624

Epoch: 5| Step: 6
Training loss: 2.260396718978882
Validation loss: 2.2049153799651773

Epoch: 5| Step: 7
Training loss: 2.5714774131774902
Validation loss: 2.198457348731256

Epoch: 5| Step: 8
Training loss: 2.8366572856903076
Validation loss: 2.191203873644593

Epoch: 5| Step: 9
Training loss: 2.786504030227661
Validation loss: 2.183980357262396

Epoch: 5| Step: 10
Training loss: 2.535895586013794
Validation loss: 2.179747030299197

Epoch: 54| Step: 0
Training loss: 2.4388716220855713
Validation loss: 2.1775016938486407

Epoch: 5| Step: 1
Training loss: 2.8109445571899414
Validation loss: 2.179148707338559

Epoch: 5| Step: 2
Training loss: 1.9314539432525635
Validation loss: 2.1778188969499324

Epoch: 5| Step: 3
Training loss: 2.5532116889953613
Validation loss: 2.1929565091286936

Epoch: 5| Step: 4
Training loss: 2.3551058769226074
Validation loss: 2.2066270202718754

Epoch: 5| Step: 5
Training loss: 2.705564022064209
Validation loss: 2.2295489003581386

Epoch: 5| Step: 6
Training loss: 2.282011032104492
Validation loss: 2.254529353111021

Epoch: 5| Step: 7
Training loss: 2.8193252086639404
Validation loss: 2.2838565662343013

Epoch: 5| Step: 8
Training loss: 1.9585888385772705
Validation loss: 2.266746864523939

Epoch: 5| Step: 9
Training loss: 3.220818281173706
Validation loss: 2.259075851850612

Epoch: 5| Step: 10
Training loss: 2.5619070529937744
Validation loss: 2.218371714315107

Epoch: 55| Step: 0
Training loss: 2.2942357063293457
Validation loss: 2.182227667941842

Epoch: 5| Step: 1
Training loss: 1.8778717517852783
Validation loss: 2.17514786412639

Epoch: 5| Step: 2
Training loss: 3.133516311645508
Validation loss: 2.170362105933569

Epoch: 5| Step: 3
Training loss: 2.849228620529175
Validation loss: 2.1691155587473223

Epoch: 5| Step: 4
Training loss: 2.512634754180908
Validation loss: 2.1736005570298884

Epoch: 5| Step: 5
Training loss: 2.1201961040496826
Validation loss: 2.1726856872599614

Epoch: 5| Step: 6
Training loss: 2.5045783519744873
Validation loss: 2.1689638578763573

Epoch: 5| Step: 7
Training loss: 2.8006739616394043
Validation loss: 2.1631949191452353

Epoch: 5| Step: 8
Training loss: 2.3590729236602783
Validation loss: 2.1609254524271977

Epoch: 5| Step: 9
Training loss: 3.1458983421325684
Validation loss: 2.1662109590345815

Epoch: 5| Step: 10
Training loss: 1.833016276359558
Validation loss: 2.182560641278503

Epoch: 56| Step: 0
Training loss: 2.927330493927002
Validation loss: 2.227791165792814

Epoch: 5| Step: 1
Training loss: 2.573626756668091
Validation loss: 2.2935896201800277

Epoch: 5| Step: 2
Training loss: 2.0868496894836426
Validation loss: 2.317233206123434

Epoch: 5| Step: 3
Training loss: 2.3292789459228516
Validation loss: 2.3148341819804203

Epoch: 5| Step: 4
Training loss: 2.468008518218994
Validation loss: 2.307688441327823

Epoch: 5| Step: 5
Training loss: 2.6183488368988037
Validation loss: 2.2648578190034434

Epoch: 5| Step: 6
Training loss: 2.15802001953125
Validation loss: 2.227627264556064

Epoch: 5| Step: 7
Training loss: 2.6619479656219482
Validation loss: 2.203932205835978

Epoch: 5| Step: 8
Training loss: 2.510222911834717
Validation loss: 2.171955798261909

Epoch: 5| Step: 9
Training loss: 2.2071280479431152
Validation loss: 2.163070805611149

Epoch: 5| Step: 10
Training loss: 2.9658000469207764
Validation loss: 2.164675922803981

Epoch: 57| Step: 0
Training loss: 2.51173734664917
Validation loss: 2.1664707083855905

Epoch: 5| Step: 1
Training loss: 1.6518971920013428
Validation loss: 2.1674372944780576

Epoch: 5| Step: 2
Training loss: 2.887996196746826
Validation loss: 2.1691628771443523

Epoch: 5| Step: 3
Training loss: 2.3185417652130127
Validation loss: 2.161029818237469

Epoch: 5| Step: 4
Training loss: 2.193735122680664
Validation loss: 2.171457862341276

Epoch: 5| Step: 5
Training loss: 3.085008382797241
Validation loss: 2.170248354634931

Epoch: 5| Step: 6
Training loss: 2.7307052612304688
Validation loss: 2.1742190250786404

Epoch: 5| Step: 7
Training loss: 2.3819656372070312
Validation loss: 2.1817233729106125

Epoch: 5| Step: 8
Training loss: 2.7298216819763184
Validation loss: 2.1772427199989237

Epoch: 5| Step: 9
Training loss: 2.383429765701294
Validation loss: 2.177150657100062

Epoch: 5| Step: 10
Training loss: 2.4411330223083496
Validation loss: 2.195678062336419

Epoch: 58| Step: 0
Training loss: 2.229288101196289
Validation loss: 2.2246373981557865

Epoch: 5| Step: 1
Training loss: 2.367950916290283
Validation loss: 2.2480785077618015

Epoch: 5| Step: 2
Training loss: 2.433408260345459
Validation loss: 2.244712241234318

Epoch: 5| Step: 3
Training loss: 2.9380648136138916
Validation loss: 2.2263337386551725

Epoch: 5| Step: 4
Training loss: 2.419736623764038
Validation loss: 2.1976463525525984

Epoch: 5| Step: 5
Training loss: 2.402559757232666
Validation loss: 2.1895974041313253

Epoch: 5| Step: 6
Training loss: 2.5070323944091797
Validation loss: 2.1800809906375025

Epoch: 5| Step: 7
Training loss: 2.4992597103118896
Validation loss: 2.1660546282286286

Epoch: 5| Step: 8
Training loss: 1.9866268634796143
Validation loss: 2.1646218056319864

Epoch: 5| Step: 9
Training loss: 2.78669810295105
Validation loss: 2.1711979143081175

Epoch: 5| Step: 10
Training loss: 2.6919772624969482
Validation loss: 2.1708014985566497

Epoch: 59| Step: 0
Training loss: 2.1020171642303467
Validation loss: 2.1595546378884265

Epoch: 5| Step: 1
Training loss: 2.229468584060669
Validation loss: 2.1598774592081704

Epoch: 5| Step: 2
Training loss: 2.6669671535491943
Validation loss: 2.160723514454339

Epoch: 5| Step: 3
Training loss: 2.2937374114990234
Validation loss: 2.1574451000459733

Epoch: 5| Step: 4
Training loss: 2.9775938987731934
Validation loss: 2.1634329326691164

Epoch: 5| Step: 5
Training loss: 2.447932481765747
Validation loss: 2.1598217128425516

Epoch: 5| Step: 6
Training loss: 1.663355827331543
Validation loss: 2.1620466837318997

Epoch: 5| Step: 7
Training loss: 2.084352970123291
Validation loss: 2.1733871044651156

Epoch: 5| Step: 8
Training loss: 2.759915828704834
Validation loss: 2.1880941288445586

Epoch: 5| Step: 9
Training loss: 3.005896806716919
Validation loss: 2.19540637282915

Epoch: 5| Step: 10
Training loss: 2.9407711029052734
Validation loss: 2.221760057633923

Epoch: 60| Step: 0
Training loss: 1.9161533117294312
Validation loss: 2.1957580761242936

Epoch: 5| Step: 1
Training loss: 3.0035183429718018
Validation loss: 2.1742481275271346

Epoch: 5| Step: 2
Training loss: 2.8385653495788574
Validation loss: 2.1684958960420344

Epoch: 5| Step: 3
Training loss: 2.042739152908325
Validation loss: 2.1528721906805552

Epoch: 5| Step: 4
Training loss: 2.9232678413391113
Validation loss: 2.148915836887975

Epoch: 5| Step: 5
Training loss: 2.6247365474700928
Validation loss: 2.150042510801746

Epoch: 5| Step: 6
Training loss: 2.260012149810791
Validation loss: 2.146122851679402

Epoch: 5| Step: 7
Training loss: 2.255803346633911
Validation loss: 2.145684511430802

Epoch: 5| Step: 8
Training loss: 2.3822426795959473
Validation loss: 2.153012065477269

Epoch: 5| Step: 9
Training loss: 2.1029129028320312
Validation loss: 2.16832975674701

Epoch: 5| Step: 10
Training loss: 2.697946548461914
Validation loss: 2.198850759895899

Epoch: 61| Step: 0
Training loss: 2.3512706756591797
Validation loss: 2.236598119940809

Epoch: 5| Step: 1
Training loss: 2.5393283367156982
Validation loss: 2.2356170044150403

Epoch: 5| Step: 2
Training loss: 2.2969484329223633
Validation loss: 2.203264994006003

Epoch: 5| Step: 3
Training loss: 2.4708824157714844
Validation loss: 2.1754906818430912

Epoch: 5| Step: 4
Training loss: 2.505629777908325
Validation loss: 2.1555651990316247

Epoch: 5| Step: 5
Training loss: 2.5896568298339844
Validation loss: 2.153606778831892

Epoch: 5| Step: 6
Training loss: 2.731614351272583
Validation loss: 2.147402168602072

Epoch: 5| Step: 7
Training loss: 2.3138744831085205
Validation loss: 2.145804851285873

Epoch: 5| Step: 8
Training loss: 2.4986109733581543
Validation loss: 2.1456456748388146

Epoch: 5| Step: 9
Training loss: 2.8618104457855225
Validation loss: 2.148471277247193

Epoch: 5| Step: 10
Training loss: 1.9391111135482788
Validation loss: 2.152087027026761

Epoch: 62| Step: 0
Training loss: 2.526015520095825
Validation loss: 2.1501991184808875

Epoch: 5| Step: 1
Training loss: 2.665193557739258
Validation loss: 2.1809242848427064

Epoch: 5| Step: 2
Training loss: 2.2471234798431396
Validation loss: 2.2107626866268855

Epoch: 5| Step: 3
Training loss: 2.9454238414764404
Validation loss: 2.2632942866253596

Epoch: 5| Step: 4
Training loss: 2.5132975578308105
Validation loss: 2.279259071555189

Epoch: 5| Step: 5
Training loss: 2.4429736137390137
Validation loss: 2.2592322480294014

Epoch: 5| Step: 6
Training loss: 1.8816028833389282
Validation loss: 2.2260747827509397

Epoch: 5| Step: 7
Training loss: 3.2008957862854004
Validation loss: 2.1663427916906213

Epoch: 5| Step: 8
Training loss: 2.2647693157196045
Validation loss: 2.152810201849989

Epoch: 5| Step: 9
Training loss: 1.4784820079803467
Validation loss: 2.144906267043083

Epoch: 5| Step: 10
Training loss: 3.0379836559295654
Validation loss: 2.140735364729358

Epoch: 63| Step: 0
Training loss: 2.989583730697632
Validation loss: 2.135547594357562

Epoch: 5| Step: 1
Training loss: 2.0330138206481934
Validation loss: 2.131853708656885

Epoch: 5| Step: 2
Training loss: 2.318582773208618
Validation loss: 2.1297586861477105

Epoch: 5| Step: 3
Training loss: 1.9685375690460205
Validation loss: 2.1371153708427184

Epoch: 5| Step: 4
Training loss: 3.0630741119384766
Validation loss: 2.1328895015101277

Epoch: 5| Step: 5
Training loss: 2.4347681999206543
Validation loss: 2.1414355026778353

Epoch: 5| Step: 6
Training loss: 2.1333134174346924
Validation loss: 2.159597425050633

Epoch: 5| Step: 7
Training loss: 2.4920647144317627
Validation loss: 2.176867356864355

Epoch: 5| Step: 8
Training loss: 2.638564348220825
Validation loss: 2.182023743147491

Epoch: 5| Step: 9
Training loss: 2.8557581901550293
Validation loss: 2.1985583459177325

Epoch: 5| Step: 10
Training loss: 2.12385630607605
Validation loss: 2.1979605228670183

Epoch: 64| Step: 0
Training loss: 2.7347404956817627
Validation loss: 2.1593320831175773

Epoch: 5| Step: 1
Training loss: 2.5302746295928955
Validation loss: 2.138925684395657

Epoch: 5| Step: 2
Training loss: 2.13419246673584
Validation loss: 2.1255356278470767

Epoch: 5| Step: 3
Training loss: 2.380807638168335
Validation loss: 2.1234430036237164

Epoch: 5| Step: 4
Training loss: 3.127089262008667
Validation loss: 2.1144133921592467

Epoch: 5| Step: 5
Training loss: 1.886343240737915
Validation loss: 2.110044515261086

Epoch: 5| Step: 6
Training loss: 2.220961570739746
Validation loss: 2.114141023287209

Epoch: 5| Step: 7
Training loss: 2.4199204444885254
Validation loss: 2.1180041784881265

Epoch: 5| Step: 8
Training loss: 2.8354477882385254
Validation loss: 2.1219209829966226

Epoch: 5| Step: 9
Training loss: 2.1743288040161133
Validation loss: 2.133537361698766

Epoch: 5| Step: 10
Training loss: 2.474508285522461
Validation loss: 2.132271400061987

Epoch: 65| Step: 0
Training loss: 2.737304449081421
Validation loss: 2.145385524278046

Epoch: 5| Step: 1
Training loss: 2.3105902671813965
Validation loss: 2.146558174522974

Epoch: 5| Step: 2
Training loss: 2.198423385620117
Validation loss: 2.1657007535298667

Epoch: 5| Step: 3
Training loss: 1.9045740365982056
Validation loss: 2.2134969670285463

Epoch: 5| Step: 4
Training loss: 2.6676838397979736
Validation loss: 2.2600586004154657

Epoch: 5| Step: 5
Training loss: 2.481696367263794
Validation loss: 2.265591399644011

Epoch: 5| Step: 6
Training loss: 2.5903449058532715
Validation loss: 2.2287091926861833

Epoch: 5| Step: 7
Training loss: 2.4853084087371826
Validation loss: 2.166184115153487

Epoch: 5| Step: 8
Training loss: 2.6326780319213867
Validation loss: 2.132007050257857

Epoch: 5| Step: 9
Training loss: 2.3502819538116455
Validation loss: 2.1226973661812405

Epoch: 5| Step: 10
Training loss: 2.555729389190674
Validation loss: 2.1152644516319357

Epoch: 66| Step: 0
Training loss: 2.240020275115967
Validation loss: 2.1201475410051245

Epoch: 5| Step: 1
Training loss: 2.5091793537139893
Validation loss: 2.125362423158461

Epoch: 5| Step: 2
Training loss: 2.513725757598877
Validation loss: 2.1308952249506468

Epoch: 5| Step: 3
Training loss: 2.6813302040100098
Validation loss: 2.153235791831888

Epoch: 5| Step: 4
Training loss: 2.467172384262085
Validation loss: 2.1269036121265863

Epoch: 5| Step: 5
Training loss: 2.2596538066864014
Validation loss: 2.132084708059988

Epoch: 5| Step: 6
Training loss: 2.5674357414245605
Validation loss: 2.123241059241756

Epoch: 5| Step: 7
Training loss: 2.3658251762390137
Validation loss: 2.1420116937288673

Epoch: 5| Step: 8
Training loss: 2.4413185119628906
Validation loss: 2.1432504205293554

Epoch: 5| Step: 9
Training loss: 2.5959956645965576
Validation loss: 2.1740136005545176

Epoch: 5| Step: 10
Training loss: 2.5582690238952637
Validation loss: 2.1820493641720025

Epoch: 67| Step: 0
Training loss: 1.7211767435073853
Validation loss: 2.1594540560117332

Epoch: 5| Step: 1
Training loss: 2.664016008377075
Validation loss: 2.1256836896301596

Epoch: 5| Step: 2
Training loss: 3.162015438079834
Validation loss: 2.112999135448087

Epoch: 5| Step: 3
Training loss: 2.263516664505005
Validation loss: 2.1019544665531447

Epoch: 5| Step: 4
Training loss: 2.953770875930786
Validation loss: 2.10011649388139

Epoch: 5| Step: 5
Training loss: 2.6079514026641846
Validation loss: 2.1107810697247906

Epoch: 5| Step: 6
Training loss: 2.206037759780884
Validation loss: 2.114642486777357

Epoch: 5| Step: 7
Training loss: 2.556809186935425
Validation loss: 2.1062221065644295

Epoch: 5| Step: 8
Training loss: 2.2479453086853027
Validation loss: 2.1026885663309405

Epoch: 5| Step: 9
Training loss: 2.3451995849609375
Validation loss: 2.110676151449962

Epoch: 5| Step: 10
Training loss: 1.912580132484436
Validation loss: 2.1372646759915095

Epoch: 68| Step: 0
Training loss: 1.9722877740859985
Validation loss: 2.150810953109495

Epoch: 5| Step: 1
Training loss: 1.9838497638702393
Validation loss: 2.1641090480230187

Epoch: 5| Step: 2
Training loss: 2.5032222270965576
Validation loss: 2.1723149873877086

Epoch: 5| Step: 3
Training loss: 2.8395285606384277
Validation loss: 2.1577337493178663

Epoch: 5| Step: 4
Training loss: 2.5720784664154053
Validation loss: 2.1387828806395173

Epoch: 5| Step: 5
Training loss: 2.631721019744873
Validation loss: 2.1151609215685117

Epoch: 5| Step: 6
Training loss: 2.067081928253174
Validation loss: 2.108635510167768

Epoch: 5| Step: 7
Training loss: 2.6735262870788574
Validation loss: 2.1010865806251444

Epoch: 5| Step: 8
Training loss: 2.7199394702911377
Validation loss: 2.0954529470013035

Epoch: 5| Step: 9
Training loss: 2.0709309577941895
Validation loss: 2.09170598881219

Epoch: 5| Step: 10
Training loss: 2.7264835834503174
Validation loss: 2.08806352461538

Epoch: 69| Step: 0
Training loss: 2.979788303375244
Validation loss: 2.099137185722269

Epoch: 5| Step: 1
Training loss: 2.7812278270721436
Validation loss: 2.1070507444361204

Epoch: 5| Step: 2
Training loss: 2.6969211101531982
Validation loss: 2.107942783704368

Epoch: 5| Step: 3
Training loss: 2.2934958934783936
Validation loss: 2.1232216153093564

Epoch: 5| Step: 4
Training loss: 2.8392081260681152
Validation loss: 2.138761922877322

Epoch: 5| Step: 5
Training loss: 1.4756966829299927
Validation loss: 2.150906068022533

Epoch: 5| Step: 6
Training loss: 2.1556670665740967
Validation loss: 2.1760004034606357

Epoch: 5| Step: 7
Training loss: 2.2321763038635254
Validation loss: 2.168307950419764

Epoch: 5| Step: 8
Training loss: 1.5408124923706055
Validation loss: 2.131461217839231

Epoch: 5| Step: 9
Training loss: 2.5452659130096436
Validation loss: 2.11103795677103

Epoch: 5| Step: 10
Training loss: 3.0363495349884033
Validation loss: 2.1034762320979947

Epoch: 70| Step: 0
Training loss: 2.155590057373047
Validation loss: 2.0982164849517164

Epoch: 5| Step: 1
Training loss: 2.5530972480773926
Validation loss: 2.085733962315385

Epoch: 5| Step: 2
Training loss: 2.221125841140747
Validation loss: 2.088903820642861

Epoch: 5| Step: 3
Training loss: 2.311720848083496
Validation loss: 2.0875720349691247

Epoch: 5| Step: 4
Training loss: 2.301119804382324
Validation loss: 2.110113546412478

Epoch: 5| Step: 5
Training loss: 2.6664812564849854
Validation loss: 2.116399557359757

Epoch: 5| Step: 6
Training loss: 2.5250256061553955
Validation loss: 2.1545311917540846

Epoch: 5| Step: 7
Training loss: 2.4679923057556152
Validation loss: 2.197911283021332

Epoch: 5| Step: 8
Training loss: 2.178373336791992
Validation loss: 2.2620612459798015

Epoch: 5| Step: 9
Training loss: 2.720273733139038
Validation loss: 2.2575209474050872

Epoch: 5| Step: 10
Training loss: 2.6020233631134033
Validation loss: 2.2439520589766966

Epoch: 71| Step: 0
Training loss: 1.9154008626937866
Validation loss: 2.157152837322604

Epoch: 5| Step: 1
Training loss: 2.399313449859619
Validation loss: 2.0991890686814503

Epoch: 5| Step: 2
Training loss: 1.9567649364471436
Validation loss: 2.090235884471606

Epoch: 5| Step: 3
Training loss: 3.0662341117858887
Validation loss: 2.087386797833186

Epoch: 5| Step: 4
Training loss: 2.141138792037964
Validation loss: 2.0870675310011833

Epoch: 5| Step: 5
Training loss: 3.080151319503784
Validation loss: 2.093943724068262

Epoch: 5| Step: 6
Training loss: 2.8000588417053223
Validation loss: 2.0937061079086794

Epoch: 5| Step: 7
Training loss: 2.5718352794647217
Validation loss: 2.089800919255903

Epoch: 5| Step: 8
Training loss: 2.458347797393799
Validation loss: 2.099995300333987

Epoch: 5| Step: 9
Training loss: 1.8416378498077393
Validation loss: 2.10711556993505

Epoch: 5| Step: 10
Training loss: 2.222458600997925
Validation loss: 2.099707982873404

Epoch: 72| Step: 0
Training loss: 2.9800193309783936
Validation loss: 2.0993696412732525

Epoch: 5| Step: 1
Training loss: 2.253232955932617
Validation loss: 2.09909846193047

Epoch: 5| Step: 2
Training loss: 2.5498695373535156
Validation loss: 2.09459174576626

Epoch: 5| Step: 3
Training loss: 2.6758170127868652
Validation loss: 2.102924754542689

Epoch: 5| Step: 4
Training loss: 2.1611170768737793
Validation loss: 2.1136876101134927

Epoch: 5| Step: 5
Training loss: 3.2266452312469482
Validation loss: 2.132153441829066

Epoch: 5| Step: 6
Training loss: 2.4197194576263428
Validation loss: 2.121227670741338

Epoch: 5| Step: 7
Training loss: 2.3932182788848877
Validation loss: 2.1114491608835038

Epoch: 5| Step: 8
Training loss: 2.4329304695129395
Validation loss: 2.103033688760573

Epoch: 5| Step: 9
Training loss: 1.3076484203338623
Validation loss: 2.1157541685206915

Epoch: 5| Step: 10
Training loss: 1.6932159662246704
Validation loss: 2.1043526485402095

Epoch: 73| Step: 0
Training loss: 1.9162237644195557
Validation loss: 2.0984327818757746

Epoch: 5| Step: 1
Training loss: 2.64036226272583
Validation loss: 2.1030788113993983

Epoch: 5| Step: 2
Training loss: 2.409247875213623
Validation loss: 2.1191009295884

Epoch: 5| Step: 3
Training loss: 2.85710072517395
Validation loss: 2.1104007844002015

Epoch: 5| Step: 4
Training loss: 2.3046393394470215
Validation loss: 2.1245541752025647

Epoch: 5| Step: 5
Training loss: 2.5020761489868164
Validation loss: 2.1540297705640077

Epoch: 5| Step: 6
Training loss: 2.0626933574676514
Validation loss: 2.186423235042121

Epoch: 5| Step: 7
Training loss: 2.0190186500549316
Validation loss: 2.156992056036508

Epoch: 5| Step: 8
Training loss: 2.245479106903076
Validation loss: 2.124371087679299

Epoch: 5| Step: 9
Training loss: 3.020639657974243
Validation loss: 2.106014688809713

Epoch: 5| Step: 10
Training loss: 2.2473926544189453
Validation loss: 2.085728519706316

Epoch: 74| Step: 0
Training loss: 2.117687463760376
Validation loss: 2.090722358354958

Epoch: 5| Step: 1
Training loss: 2.026831865310669
Validation loss: 2.081593205851893

Epoch: 5| Step: 2
Training loss: 2.928396701812744
Validation loss: 2.0672075389533915

Epoch: 5| Step: 3
Training loss: 2.71264386177063
Validation loss: 2.0689245911054712

Epoch: 5| Step: 4
Training loss: 2.3736178874969482
Validation loss: 2.0685479012868737

Epoch: 5| Step: 5
Training loss: 2.518289566040039
Validation loss: 2.083006058969805

Epoch: 5| Step: 6
Training loss: 1.6052261590957642
Validation loss: 2.0879029279114096

Epoch: 5| Step: 7
Training loss: 2.592550754547119
Validation loss: 2.0884525852818645

Epoch: 5| Step: 8
Training loss: 2.0445704460144043
Validation loss: 2.0949796002398253

Epoch: 5| Step: 9
Training loss: 3.3409194946289062
Validation loss: 2.093933243905344

Epoch: 5| Step: 10
Training loss: 2.0059969425201416
Validation loss: 2.0846038172321935

Epoch: 75| Step: 0
Training loss: 2.375382900238037
Validation loss: 2.07424061400916

Epoch: 5| Step: 1
Training loss: 2.6001081466674805
Validation loss: 2.0743892910659953

Epoch: 5| Step: 2
Training loss: 2.243805408477783
Validation loss: 2.0804620148033224

Epoch: 5| Step: 3
Training loss: 2.2777113914489746
Validation loss: 2.1006747291934107

Epoch: 5| Step: 4
Training loss: 2.108142375946045
Validation loss: 2.127816064383394

Epoch: 5| Step: 5
Training loss: 2.089059352874756
Validation loss: 2.1724907070077877

Epoch: 5| Step: 6
Training loss: 2.696104049682617
Validation loss: 2.1728908464472783

Epoch: 5| Step: 7
Training loss: 2.7641959190368652
Validation loss: 2.1803388518671833

Epoch: 5| Step: 8
Training loss: 2.038569450378418
Validation loss: 2.18586286165381

Epoch: 5| Step: 9
Training loss: 2.6292731761932373
Validation loss: 2.136824296366784

Epoch: 5| Step: 10
Training loss: 2.3377859592437744
Validation loss: 2.0875047637570288

Epoch: 76| Step: 0
Training loss: 3.0274603366851807
Validation loss: 2.0619953781045894

Epoch: 5| Step: 1
Training loss: 2.464066982269287
Validation loss: 2.056041222746654

Epoch: 5| Step: 2
Training loss: 2.3633720874786377
Validation loss: 2.0667722327734834

Epoch: 5| Step: 3
Training loss: 2.612274408340454
Validation loss: 2.0642857115755797

Epoch: 5| Step: 4
Training loss: 2.3867456912994385
Validation loss: 2.0588256735955515

Epoch: 5| Step: 5
Training loss: 2.4178662300109863
Validation loss: 2.0556475654725106

Epoch: 5| Step: 6
Training loss: 2.3137753009796143
Validation loss: 2.0655220605993785

Epoch: 5| Step: 7
Training loss: 3.100741386413574
Validation loss: 2.071117836941955

Epoch: 5| Step: 8
Training loss: 2.1674373149871826
Validation loss: 2.073669730976064

Epoch: 5| Step: 9
Training loss: 1.3940489292144775
Validation loss: 2.128974242876935

Epoch: 5| Step: 10
Training loss: 1.7744245529174805
Validation loss: 2.102036868372271

Epoch: 77| Step: 0
Training loss: 2.1815223693847656
Validation loss: 2.0858515206203667

Epoch: 5| Step: 1
Training loss: 2.3037984371185303
Validation loss: 2.0955749404045845

Epoch: 5| Step: 2
Training loss: 2.049274206161499
Validation loss: 2.1017020876689623

Epoch: 5| Step: 3
Training loss: 2.5633156299591064
Validation loss: 2.0966058046587053

Epoch: 5| Step: 4
Training loss: 3.018332004547119
Validation loss: 2.1029212628641436

Epoch: 5| Step: 5
Training loss: 2.253535509109497
Validation loss: 2.0914232756501887

Epoch: 5| Step: 6
Training loss: 2.0125129222869873
Validation loss: 2.088599665190584

Epoch: 5| Step: 7
Training loss: 2.118006706237793
Validation loss: 2.0725228555740847

Epoch: 5| Step: 8
Training loss: 2.621157169342041
Validation loss: 2.0591368880323184

Epoch: 5| Step: 9
Training loss: 2.1554064750671387
Validation loss: 2.04834795126351

Epoch: 5| Step: 10
Training loss: 2.4756317138671875
Validation loss: 2.0532974145745717

Epoch: 78| Step: 0
Training loss: 2.225621223449707
Validation loss: 2.05641161241839

Epoch: 5| Step: 1
Training loss: 1.7815290689468384
Validation loss: 2.052443656870114

Epoch: 5| Step: 2
Training loss: 2.234707832336426
Validation loss: 2.053743927709518

Epoch: 5| Step: 3
Training loss: 2.0113749504089355
Validation loss: 2.06649866924491

Epoch: 5| Step: 4
Training loss: 2.3116354942321777
Validation loss: 2.088946137377011

Epoch: 5| Step: 5
Training loss: 2.218648672103882
Validation loss: 2.117931124984577

Epoch: 5| Step: 6
Training loss: 2.3686318397521973
Validation loss: 2.1821727496321484

Epoch: 5| Step: 7
Training loss: 2.9752397537231445
Validation loss: 2.172810145603713

Epoch: 5| Step: 8
Training loss: 2.7070717811584473
Validation loss: 2.1569315938539404

Epoch: 5| Step: 9
Training loss: 2.5503451824188232
Validation loss: 2.1488286218335553

Epoch: 5| Step: 10
Training loss: 2.6957740783691406
Validation loss: 2.134335440974082

Epoch: 79| Step: 0
Training loss: 1.8505899906158447
Validation loss: 2.1085438869332753

Epoch: 5| Step: 1
Training loss: 1.9412702322006226
Validation loss: 2.0640054389994633

Epoch: 5| Step: 2
Training loss: 2.7568061351776123
Validation loss: 2.0496567897899176

Epoch: 5| Step: 3
Training loss: 1.7935489416122437
Validation loss: 2.052545077057295

Epoch: 5| Step: 4
Training loss: 3.0541768074035645
Validation loss: 2.048366601749133

Epoch: 5| Step: 5
Training loss: 2.7168397903442383
Validation loss: 2.058008704134213

Epoch: 5| Step: 6
Training loss: 1.8870235681533813
Validation loss: 2.055729176408501

Epoch: 5| Step: 7
Training loss: 2.682569742202759
Validation loss: 2.0589437536014024

Epoch: 5| Step: 8
Training loss: 2.5478408336639404
Validation loss: 2.065586769452659

Epoch: 5| Step: 9
Training loss: 1.7372509241104126
Validation loss: 2.0798729542763

Epoch: 5| Step: 10
Training loss: 3.1625638008117676
Validation loss: 2.1200462310544905

Epoch: 80| Step: 0
Training loss: 3.0682175159454346
Validation loss: 2.1420974898081955

Epoch: 5| Step: 1
Training loss: 1.7681694030761719
Validation loss: 2.13725184881559

Epoch: 5| Step: 2
Training loss: 1.9738483428955078
Validation loss: 2.161923062416815

Epoch: 5| Step: 3
Training loss: 2.2644541263580322
Validation loss: 2.1933397554582164

Epoch: 5| Step: 4
Training loss: 2.61032772064209
Validation loss: 2.244312281249672

Epoch: 5| Step: 5
Training loss: 2.970916271209717
Validation loss: 2.2553719756423787

Epoch: 5| Step: 6
Training loss: 2.2270736694335938
Validation loss: 2.2296670252277004

Epoch: 5| Step: 7
Training loss: 3.032724380493164
Validation loss: 2.149999803112399

Epoch: 5| Step: 8
Training loss: 1.9619770050048828
Validation loss: 2.0717161163207023

Epoch: 5| Step: 9
Training loss: 2.2875475883483887
Validation loss: 2.042835368905016

Epoch: 5| Step: 10
Training loss: 1.8922460079193115
Validation loss: 2.026401299302296

Epoch: 81| Step: 0
Training loss: 2.3890540599823
Validation loss: 2.033776867774225

Epoch: 5| Step: 1
Training loss: 2.6749987602233887
Validation loss: 2.021099034176078

Epoch: 5| Step: 2
Training loss: 2.7338273525238037
Validation loss: 2.0261755399806525

Epoch: 5| Step: 3
Training loss: 1.7091068029403687
Validation loss: 2.0306324292254705

Epoch: 5| Step: 4
Training loss: 2.061422348022461
Validation loss: 2.0296198911564325

Epoch: 5| Step: 5
Training loss: 2.476896286010742
Validation loss: 2.0353837372154318

Epoch: 5| Step: 6
Training loss: 2.2767300605773926
Validation loss: 2.0463136396100445

Epoch: 5| Step: 7
Training loss: 2.998100519180298
Validation loss: 2.072090051507437

Epoch: 5| Step: 8
Training loss: 1.9648816585540771
Validation loss: 2.1028617556377123

Epoch: 5| Step: 9
Training loss: 2.633937358856201
Validation loss: 2.1504884945449008

Epoch: 5| Step: 10
Training loss: 2.210082530975342
Validation loss: 2.158710504090914

Epoch: 82| Step: 0
Training loss: 1.954010248184204
Validation loss: 2.096242135570895

Epoch: 5| Step: 1
Training loss: 2.205439329147339
Validation loss: 2.029753783697723

Epoch: 5| Step: 2
Training loss: 2.480782985687256
Validation loss: 2.0213574222339097

Epoch: 5| Step: 3
Training loss: 2.701861619949341
Validation loss: 2.020464725391839

Epoch: 5| Step: 4
Training loss: 2.0690789222717285
Validation loss: 2.027839652953609

Epoch: 5| Step: 5
Training loss: 2.262901782989502
Validation loss: 2.032788094653878

Epoch: 5| Step: 6
Training loss: 2.40848970413208
Validation loss: 2.0381146118205082

Epoch: 5| Step: 7
Training loss: 2.8871798515319824
Validation loss: 2.0331792075146913

Epoch: 5| Step: 8
Training loss: 2.0888614654541016
Validation loss: 2.042115572960146

Epoch: 5| Step: 9
Training loss: 2.9090287685394287
Validation loss: 2.033787896556239

Epoch: 5| Step: 10
Training loss: 2.0928025245666504
Validation loss: 2.0386386891847015

Epoch: 83| Step: 0
Training loss: 2.2641215324401855
Validation loss: 2.0574098594727053

Epoch: 5| Step: 1
Training loss: 2.0320115089416504
Validation loss: 2.0909353456189557

Epoch: 5| Step: 2
Training loss: 1.9442510604858398
Validation loss: 2.1295423020598707

Epoch: 5| Step: 3
Training loss: 2.152459144592285
Validation loss: 2.154571420402937

Epoch: 5| Step: 4
Training loss: 2.4664270877838135
Validation loss: 2.160900669713174

Epoch: 5| Step: 5
Training loss: 1.9140077829360962
Validation loss: 2.154049640060753

Epoch: 5| Step: 6
Training loss: 2.7153708934783936
Validation loss: 2.1293136304424656

Epoch: 5| Step: 7
Training loss: 2.6720945835113525
Validation loss: 2.081956212238599

Epoch: 5| Step: 8
Training loss: 2.517946720123291
Validation loss: 2.0312974106880928

Epoch: 5| Step: 9
Training loss: 2.8137025833129883
Validation loss: 2.018798784543109

Epoch: 5| Step: 10
Training loss: 2.3755085468292236
Validation loss: 2.0143930040380007

Epoch: 84| Step: 0
Training loss: 1.8145720958709717
Validation loss: 2.014576886289863

Epoch: 5| Step: 1
Training loss: 2.3752245903015137
Validation loss: 2.022546237514865

Epoch: 5| Step: 2
Training loss: 2.561854124069214
Validation loss: 2.013091101441332

Epoch: 5| Step: 3
Training loss: 2.566084861755371
Validation loss: 2.0093305354477256

Epoch: 5| Step: 4
Training loss: 2.203526020050049
Validation loss: 2.007714529191294

Epoch: 5| Step: 5
Training loss: 2.700730323791504
Validation loss: 2.0223769910873903

Epoch: 5| Step: 6
Training loss: 2.24650502204895
Validation loss: 2.0728904124229186

Epoch: 5| Step: 7
Training loss: 2.1819896697998047
Validation loss: 2.1045507897612867

Epoch: 5| Step: 8
Training loss: 2.0707428455352783
Validation loss: 2.117531232936408

Epoch: 5| Step: 9
Training loss: 2.403590679168701
Validation loss: 2.1193501641673427

Epoch: 5| Step: 10
Training loss: 2.7581820487976074
Validation loss: 2.0550849001894713

Epoch: 85| Step: 0
Training loss: 2.6500680446624756
Validation loss: 2.0239671814826226

Epoch: 5| Step: 1
Training loss: 2.154533863067627
Validation loss: 2.0277269296748663

Epoch: 5| Step: 2
Training loss: 2.130263566970825
Validation loss: 2.0482866738432195

Epoch: 5| Step: 3
Training loss: 1.897383689880371
Validation loss: 2.085165940305238

Epoch: 5| Step: 4
Training loss: 2.5685906410217285
Validation loss: 2.0637247600863056

Epoch: 5| Step: 5
Training loss: 2.409839153289795
Validation loss: 2.0468222043847524

Epoch: 5| Step: 6
Training loss: 2.9823389053344727
Validation loss: 2.0563658181057183

Epoch: 5| Step: 7
Training loss: 2.129922866821289
Validation loss: 2.044844114652244

Epoch: 5| Step: 8
Training loss: 2.2569894790649414
Validation loss: 2.0368266541470765

Epoch: 5| Step: 9
Training loss: 2.2150685787200928
Validation loss: 2.0379931106362292

Epoch: 5| Step: 10
Training loss: 2.0482218265533447
Validation loss: 2.0405338938518236

Epoch: 86| Step: 0
Training loss: 2.141934871673584
Validation loss: 2.046078342263417

Epoch: 5| Step: 1
Training loss: 1.935034990310669
Validation loss: 2.0498872290375414

Epoch: 5| Step: 2
Training loss: 2.562037944793701
Validation loss: 2.0612639175948275

Epoch: 5| Step: 3
Training loss: 2.5347378253936768
Validation loss: 2.04437606821778

Epoch: 5| Step: 4
Training loss: 2.1100223064422607
Validation loss: 2.0210134303697975

Epoch: 5| Step: 5
Training loss: 2.7865943908691406
Validation loss: 2.0153599093037267

Epoch: 5| Step: 6
Training loss: 1.969437599182129
Validation loss: 2.0129155574306363

Epoch: 5| Step: 7
Training loss: 2.1384949684143066
Validation loss: 1.9924709873814737

Epoch: 5| Step: 8
Training loss: 2.1337108612060547
Validation loss: 1.993719998226371

Epoch: 5| Step: 9
Training loss: 2.4600906372070312
Validation loss: 2.000116143175351

Epoch: 5| Step: 10
Training loss: 2.6251864433288574
Validation loss: 2.001103521675192

Epoch: 87| Step: 0
Training loss: 2.2805027961730957
Validation loss: 2.0108811547679286

Epoch: 5| Step: 1
Training loss: 2.361642360687256
Validation loss: 2.0251227976173483

Epoch: 5| Step: 2
Training loss: 2.7675063610076904
Validation loss: 2.0409268653520973

Epoch: 5| Step: 3
Training loss: 2.5361247062683105
Validation loss: 2.093657483336746

Epoch: 5| Step: 4
Training loss: 2.3414790630340576
Validation loss: 2.0992294101304907

Epoch: 5| Step: 5
Training loss: 2.2417244911193848
Validation loss: 2.070381772133612

Epoch: 5| Step: 6
Training loss: 2.5405077934265137
Validation loss: 2.0415169833808817

Epoch: 5| Step: 7
Training loss: 2.274901866912842
Validation loss: 2.0312571628119356

Epoch: 5| Step: 8
Training loss: 1.9846084117889404
Validation loss: 2.0191117563555316

Epoch: 5| Step: 9
Training loss: 2.060734272003174
Validation loss: 2.0028307027714227

Epoch: 5| Step: 10
Training loss: 1.8092223405838013
Validation loss: 2.000407532979083

Epoch: 88| Step: 0
Training loss: 1.7139675617218018
Validation loss: 2.0058461094415314

Epoch: 5| Step: 1
Training loss: 1.8976058959960938
Validation loss: 2.0074471453184723

Epoch: 5| Step: 2
Training loss: 2.777547836303711
Validation loss: 2.0014801871392036

Epoch: 5| Step: 3
Training loss: 3.4012386798858643
Validation loss: 2.009341533466052

Epoch: 5| Step: 4
Training loss: 2.176299571990967
Validation loss: 2.0185216370449273

Epoch: 5| Step: 5
Training loss: 2.0284245014190674
Validation loss: 2.020487634084558

Epoch: 5| Step: 6
Training loss: 2.1264421939849854
Validation loss: 2.0288505426017185

Epoch: 5| Step: 7
Training loss: 2.242520809173584
Validation loss: 2.0291076475574124

Epoch: 5| Step: 8
Training loss: 2.0643813610076904
Validation loss: 2.0087051647965626

Epoch: 5| Step: 9
Training loss: 2.01114559173584
Validation loss: 2.003626879825387

Epoch: 5| Step: 10
Training loss: 2.5079405307769775
Validation loss: 2.000288765917542

Epoch: 89| Step: 0
Training loss: 2.3431594371795654
Validation loss: 1.9986481974201817

Epoch: 5| Step: 1
Training loss: 2.1769556999206543
Validation loss: 2.0013683201164327

Epoch: 5| Step: 2
Training loss: 2.291785955429077
Validation loss: 2.00432692035552

Epoch: 5| Step: 3
Training loss: 2.555849552154541
Validation loss: 2.0116460220788115

Epoch: 5| Step: 4
Training loss: 2.0404412746429443
Validation loss: 2.0375172002341158

Epoch: 5| Step: 5
Training loss: 2.8249568939208984
Validation loss: 2.0377422994182957

Epoch: 5| Step: 6
Training loss: 1.999505639076233
Validation loss: 2.0283539628469818

Epoch: 5| Step: 7
Training loss: 1.8934986591339111
Validation loss: 2.023166864149032

Epoch: 5| Step: 8
Training loss: 1.6787277460098267
Validation loss: 2.0138261830934914

Epoch: 5| Step: 9
Training loss: 2.8915293216705322
Validation loss: 2.0033181328927316

Epoch: 5| Step: 10
Training loss: 2.1984522342681885
Validation loss: 2.0122048098553895

Epoch: 90| Step: 0
Training loss: 1.9078929424285889
Validation loss: 2.017863909403483

Epoch: 5| Step: 1
Training loss: 2.0185887813568115
Validation loss: 2.0270843582768596

Epoch: 5| Step: 2
Training loss: 1.649627685546875
Validation loss: 2.0209245194670973

Epoch: 5| Step: 3
Training loss: 1.9498357772827148
Validation loss: 2.01465537471156

Epoch: 5| Step: 4
Training loss: 1.9889118671417236
Validation loss: 2.0083436517305273

Epoch: 5| Step: 5
Training loss: 2.4776604175567627
Validation loss: 2.0178556570442776

Epoch: 5| Step: 6
Training loss: 2.6268019676208496
Validation loss: 2.0264896756859234

Epoch: 5| Step: 7
Training loss: 2.8327701091766357
Validation loss: 2.008882353382726

Epoch: 5| Step: 8
Training loss: 2.617866039276123
Validation loss: 2.0040536465183383

Epoch: 5| Step: 9
Training loss: 2.1114847660064697
Validation loss: 2.0106125339385

Epoch: 5| Step: 10
Training loss: 2.6026229858398438
Validation loss: 2.0256730766706568

Epoch: 91| Step: 0
Training loss: 2.2536442279815674
Validation loss: 2.040622644526984

Epoch: 5| Step: 1
Training loss: 2.4772517681121826
Validation loss: 2.016176703155682

Epoch: 5| Step: 2
Training loss: 1.987523078918457
Validation loss: 2.0229180128343645

Epoch: 5| Step: 3
Training loss: 2.331378221511841
Validation loss: 2.008343122338736

Epoch: 5| Step: 4
Training loss: 2.3596277236938477
Validation loss: 2.010116325911655

Epoch: 5| Step: 5
Training loss: 1.6073777675628662
Validation loss: 2.0034254122805852

Epoch: 5| Step: 6
Training loss: 2.196690797805786
Validation loss: 2.0005881376163934

Epoch: 5| Step: 7
Training loss: 2.3766307830810547
Validation loss: 2.00805652013389

Epoch: 5| Step: 8
Training loss: 2.5462982654571533
Validation loss: 1.9986186181345293

Epoch: 5| Step: 9
Training loss: 2.5348286628723145
Validation loss: 2.006670449369697

Epoch: 5| Step: 10
Training loss: 1.8262462615966797
Validation loss: 2.0036308688502156

Epoch: 92| Step: 0
Training loss: 2.3772778511047363
Validation loss: 2.031115888267435

Epoch: 5| Step: 1
Training loss: 2.2778427600860596
Validation loss: 2.031882019453151

Epoch: 5| Step: 2
Training loss: 2.4748902320861816
Validation loss: 2.0488065212003645

Epoch: 5| Step: 3
Training loss: 2.473845958709717
Validation loss: 2.06518732219614

Epoch: 5| Step: 4
Training loss: 2.517268419265747
Validation loss: 2.0567097266515098

Epoch: 5| Step: 5
Training loss: 1.8025791645050049
Validation loss: 2.025696154563658

Epoch: 5| Step: 6
Training loss: 2.3694427013397217
Validation loss: 2.0072590420323033

Epoch: 5| Step: 7
Training loss: 2.3495676517486572
Validation loss: 1.9994344044757146

Epoch: 5| Step: 8
Training loss: 2.00142240524292
Validation loss: 1.9825794325079968

Epoch: 5| Step: 9
Training loss: 1.977677583694458
Validation loss: 1.9872016304282731

Epoch: 5| Step: 10
Training loss: 1.9026145935058594
Validation loss: 2.000966150273559

Epoch: 93| Step: 0
Training loss: 2.188594102859497
Validation loss: 2.0118472371050107

Epoch: 5| Step: 1
Training loss: 2.8222289085388184
Validation loss: 2.0177919646745086

Epoch: 5| Step: 2
Training loss: 2.055441379547119
Validation loss: 2.011852930950862

Epoch: 5| Step: 3
Training loss: 2.2526628971099854
Validation loss: 2.0337961924973356

Epoch: 5| Step: 4
Training loss: 2.1487693786621094
Validation loss: 2.015406982873076

Epoch: 5| Step: 5
Training loss: 2.301279067993164
Validation loss: 1.994828975328835

Epoch: 5| Step: 6
Training loss: 2.002565622329712
Validation loss: 1.993266845262179

Epoch: 5| Step: 7
Training loss: 2.138643741607666
Validation loss: 1.992674421238643

Epoch: 5| Step: 8
Training loss: 2.637324810028076
Validation loss: 2.0047279762965378

Epoch: 5| Step: 9
Training loss: 2.2277956008911133
Validation loss: 2.0458983221361713

Epoch: 5| Step: 10
Training loss: 2.0596871376037598
Validation loss: 2.1271351588669645

Epoch: 94| Step: 0
Training loss: 1.5583950281143188
Validation loss: 2.113883351766935

Epoch: 5| Step: 1
Training loss: 1.8869062662124634
Validation loss: 2.0550507063506753

Epoch: 5| Step: 2
Training loss: 2.5439600944519043
Validation loss: 2.019713601758403

Epoch: 5| Step: 3
Training loss: 2.4443047046661377
Validation loss: 1.9847355606735393

Epoch: 5| Step: 4
Training loss: 2.627023220062256
Validation loss: 1.9841479537307576

Epoch: 5| Step: 5
Training loss: 1.9879295825958252
Validation loss: 1.9841689832748906

Epoch: 5| Step: 6
Training loss: 2.3714637756347656
Validation loss: 1.987108330572805

Epoch: 5| Step: 7
Training loss: 1.947263479232788
Validation loss: 2.0273196851053545

Epoch: 5| Step: 8
Training loss: 2.516779661178589
Validation loss: 2.035777476526076

Epoch: 5| Step: 9
Training loss: 2.194519281387329
Validation loss: 2.0571451533225273

Epoch: 5| Step: 10
Training loss: 2.55312180519104
Validation loss: 2.0542003288063952

Epoch: 95| Step: 0
Training loss: 2.605440855026245
Validation loss: 1.9759880265881937

Epoch: 5| Step: 1
Training loss: 2.4062700271606445
Validation loss: 1.9733658747006488

Epoch: 5| Step: 2
Training loss: 2.597787380218506
Validation loss: 1.977319735352711

Epoch: 5| Step: 3
Training loss: 1.7777706384658813
Validation loss: 1.9812943653393817

Epoch: 5| Step: 4
Training loss: 2.024260997772217
Validation loss: 2.0235282810785438

Epoch: 5| Step: 5
Training loss: 1.9773237705230713
Validation loss: 2.094426534509146

Epoch: 5| Step: 6
Training loss: 2.5111985206604004
Validation loss: 2.1610604947613132

Epoch: 5| Step: 7
Training loss: 2.3612070083618164
Validation loss: 2.202361265818278

Epoch: 5| Step: 8
Training loss: 2.655932664871216
Validation loss: 2.1603282549047984

Epoch: 5| Step: 9
Training loss: 2.3072075843811035
Validation loss: 2.0656973328641666

Epoch: 5| Step: 10
Training loss: 2.182506561279297
Validation loss: 1.9926549644880398

Epoch: 96| Step: 0
Training loss: 2.179729461669922
Validation loss: 1.9645445705741964

Epoch: 5| Step: 1
Training loss: 2.9466075897216797
Validation loss: 1.9682235794682656

Epoch: 5| Step: 2
Training loss: 2.8335204124450684
Validation loss: 1.9604602218956075

Epoch: 5| Step: 3
Training loss: 1.418256402015686
Validation loss: 1.9635960850664365

Epoch: 5| Step: 4
Training loss: 2.157559394836426
Validation loss: 1.978095321245091

Epoch: 5| Step: 5
Training loss: 2.5699374675750732
Validation loss: 1.9770403433871526

Epoch: 5| Step: 6
Training loss: 2.526155948638916
Validation loss: 1.981636393454767

Epoch: 5| Step: 7
Training loss: 1.5117809772491455
Validation loss: 1.9855398901047245

Epoch: 5| Step: 8
Training loss: 2.018165111541748
Validation loss: 1.993180315981629

Epoch: 5| Step: 9
Training loss: 2.948472499847412
Validation loss: 1.9976779158397386

Epoch: 5| Step: 10
Training loss: 1.7665811777114868
Validation loss: 1.9807902766812233

Epoch: 97| Step: 0
Training loss: 1.9464566707611084
Validation loss: 1.9853666315796554

Epoch: 5| Step: 1
Training loss: 1.9069875478744507
Validation loss: 1.9770981778380692

Epoch: 5| Step: 2
Training loss: 1.8513050079345703
Validation loss: 1.9810604177495486

Epoch: 5| Step: 3
Training loss: 2.588031768798828
Validation loss: 1.9841919650313675

Epoch: 5| Step: 4
Training loss: 2.7941794395446777
Validation loss: 1.9714621318283903

Epoch: 5| Step: 5
Training loss: 2.5508179664611816
Validation loss: 1.9773773224123063

Epoch: 5| Step: 6
Training loss: 1.8397163152694702
Validation loss: 1.9783965772198093

Epoch: 5| Step: 7
Training loss: 2.0448520183563232
Validation loss: 1.9903780568030573

Epoch: 5| Step: 8
Training loss: 2.2256805896759033
Validation loss: 1.9981845437839467

Epoch: 5| Step: 9
Training loss: 2.687018871307373
Validation loss: 2.0048676793293287

Epoch: 5| Step: 10
Training loss: 2.181910753250122
Validation loss: 2.0053511716986216

Epoch: 98| Step: 0
Training loss: 2.3007144927978516
Validation loss: 1.995361335815922

Epoch: 5| Step: 1
Training loss: 2.4503417015075684
Validation loss: 2.0094828964561544

Epoch: 5| Step: 2
Training loss: 2.249621868133545
Validation loss: 2.0468240553332913

Epoch: 5| Step: 3
Training loss: 1.8129844665527344
Validation loss: 2.072724773037818

Epoch: 5| Step: 4
Training loss: 2.2152373790740967
Validation loss: 2.1027197966011624

Epoch: 5| Step: 5
Training loss: 2.138606309890747
Validation loss: 2.117339321362075

Epoch: 5| Step: 6
Training loss: 2.256746768951416
Validation loss: 2.1224325677399993

Epoch: 5| Step: 7
Training loss: 2.1209421157836914
Validation loss: 2.1118804280475905

Epoch: 5| Step: 8
Training loss: 2.4455137252807617
Validation loss: 2.0675007938056864

Epoch: 5| Step: 9
Training loss: 2.893066644668579
Validation loss: 2.030021203461514

Epoch: 5| Step: 10
Training loss: 1.8668229579925537
Validation loss: 2.005683309288435

Epoch: 99| Step: 0
Training loss: 2.0954272747039795
Validation loss: 2.004031168517246

Epoch: 5| Step: 1
Training loss: 2.6043357849121094
Validation loss: 2.031120518202423

Epoch: 5| Step: 2
Training loss: 1.7193527221679688
Validation loss: 2.037793490194505

Epoch: 5| Step: 3
Training loss: 2.824549436569214
Validation loss: 2.0370549822366364

Epoch: 5| Step: 4
Training loss: 2.1024258136749268
Validation loss: 2.0084094693583827

Epoch: 5| Step: 5
Training loss: 1.8654191493988037
Validation loss: 2.001879738223168

Epoch: 5| Step: 6
Training loss: 2.255200147628784
Validation loss: 2.0326665678331928

Epoch: 5| Step: 7
Training loss: 2.388922929763794
Validation loss: 2.0474968558998516

Epoch: 5| Step: 8
Training loss: 2.2124123573303223
Validation loss: 2.0770124158551617

Epoch: 5| Step: 9
Training loss: 2.158665418624878
Validation loss: 2.102847468468451

Epoch: 5| Step: 10
Training loss: 2.737501621246338
Validation loss: 2.0765773839848016

Epoch: 100| Step: 0
Training loss: 1.9662796258926392
Validation loss: 2.0331485655999955

Epoch: 5| Step: 1
Training loss: 2.220259189605713
Validation loss: 2.0008267074502926

Epoch: 5| Step: 2
Training loss: 2.8584203720092773
Validation loss: 1.9779253557164183

Epoch: 5| Step: 3
Training loss: 1.451751470565796
Validation loss: 1.9777093266928067

Epoch: 5| Step: 4
Training loss: 2.740384817123413
Validation loss: 1.995317688552282

Epoch: 5| Step: 5
Training loss: 1.6870777606964111
Validation loss: 2.0094564858303277

Epoch: 5| Step: 6
Training loss: 2.502624988555908
Validation loss: 2.009836930100636

Epoch: 5| Step: 7
Training loss: 1.6668201684951782
Validation loss: 2.004410530931206

Epoch: 5| Step: 8
Training loss: 2.323052167892456
Validation loss: 1.9830139298592844

Epoch: 5| Step: 9
Training loss: 2.8335506916046143
Validation loss: 1.9713258269012615

Epoch: 5| Step: 10
Training loss: 1.7814035415649414
Validation loss: 1.957559706062399

Epoch: 101| Step: 0
Training loss: 1.8839524984359741
Validation loss: 1.9608437579165223

Epoch: 5| Step: 1
Training loss: 2.2762961387634277
Validation loss: 1.9689989782148791

Epoch: 5| Step: 2
Training loss: 1.8907461166381836
Validation loss: 1.979488383057297

Epoch: 5| Step: 3
Training loss: 2.0164997577667236
Validation loss: 1.975811812185472

Epoch: 5| Step: 4
Training loss: 2.107217311859131
Validation loss: 1.9755718554219892

Epoch: 5| Step: 5
Training loss: 2.027080535888672
Validation loss: 1.9872443086357527

Epoch: 5| Step: 6
Training loss: 2.0840234756469727
Validation loss: 1.9681983609353342

Epoch: 5| Step: 7
Training loss: 2.5873332023620605
Validation loss: 1.965800549394341

Epoch: 5| Step: 8
Training loss: 2.371215581893921
Validation loss: 1.953370164799434

Epoch: 5| Step: 9
Training loss: 2.102815866470337
Validation loss: 1.9644305039477605

Epoch: 5| Step: 10
Training loss: 2.6623668670654297
Validation loss: 1.9612065592119772

Epoch: 102| Step: 0
Training loss: 1.9281189441680908
Validation loss: 1.963862044836885

Epoch: 5| Step: 1
Training loss: 2.121706485748291
Validation loss: 1.9560414744961647

Epoch: 5| Step: 2
Training loss: 1.47660231590271
Validation loss: 1.9629600612066125

Epoch: 5| Step: 3
Training loss: 2.565601110458374
Validation loss: 1.9771787863905712

Epoch: 5| Step: 4
Training loss: 2.430403232574463
Validation loss: 2.0020707153504893

Epoch: 5| Step: 5
Training loss: 1.9686790704727173
Validation loss: 2.003659586752615

Epoch: 5| Step: 6
Training loss: 1.9035173654556274
Validation loss: 1.9975649823424637

Epoch: 5| Step: 7
Training loss: 2.870032548904419
Validation loss: 2.0135098247117895

Epoch: 5| Step: 8
Training loss: 2.1463510990142822
Validation loss: 2.010284536628313

Epoch: 5| Step: 9
Training loss: 2.305774688720703
Validation loss: 2.0415289581462903

Epoch: 5| Step: 10
Training loss: 2.1633708477020264
Validation loss: 2.031632959201772

Epoch: 103| Step: 0
Training loss: 1.831732988357544
Validation loss: 2.03883469745677

Epoch: 5| Step: 1
Training loss: 2.2724804878234863
Validation loss: 2.019167600139495

Epoch: 5| Step: 2
Training loss: 1.7873306274414062
Validation loss: 2.030612777638179

Epoch: 5| Step: 3
Training loss: 2.157301902770996
Validation loss: 2.0175652785967757

Epoch: 5| Step: 4
Training loss: 2.369772434234619
Validation loss: 1.9959760276220178

Epoch: 5| Step: 5
Training loss: 1.926733374595642
Validation loss: 1.9742731945489043

Epoch: 5| Step: 6
Training loss: 2.271775484085083
Validation loss: 1.95416776082849

Epoch: 5| Step: 7
Training loss: 2.0012030601501465
Validation loss: 1.9390189955311437

Epoch: 5| Step: 8
Training loss: 2.578383445739746
Validation loss: 1.9350628058115642

Epoch: 5| Step: 9
Training loss: 2.246535539627075
Validation loss: 1.9416129435262373

Epoch: 5| Step: 10
Training loss: 2.520249366760254
Validation loss: 1.9368179818635345

Epoch: 104| Step: 0
Training loss: 2.2906947135925293
Validation loss: 1.9305234545020646

Epoch: 5| Step: 1
Training loss: 2.0211217403411865
Validation loss: 1.934840412550075

Epoch: 5| Step: 2
Training loss: 1.866029977798462
Validation loss: 1.95024997444563

Epoch: 5| Step: 3
Training loss: 2.502410888671875
Validation loss: 1.9711684783299763

Epoch: 5| Step: 4
Training loss: 2.0220603942871094
Validation loss: 1.9850181033534389

Epoch: 5| Step: 5
Training loss: 2.145517587661743
Validation loss: 1.9786527438830304

Epoch: 5| Step: 6
Training loss: 2.2140135765075684
Validation loss: 1.957436453911566

Epoch: 5| Step: 7
Training loss: 2.2630865573883057
Validation loss: 1.9453335192895704

Epoch: 5| Step: 8
Training loss: 2.1369595527648926
Validation loss: 1.9483813444773357

Epoch: 5| Step: 9
Training loss: 2.210265874862671
Validation loss: 1.9565223493883688

Epoch: 5| Step: 10
Training loss: 2.3167459964752197
Validation loss: 1.966014724905773

Epoch: 105| Step: 0
Training loss: 2.0223031044006348
Validation loss: 1.9675437532445437

Epoch: 5| Step: 1
Training loss: 1.6635242700576782
Validation loss: 1.959707329350133

Epoch: 5| Step: 2
Training loss: 2.656604290008545
Validation loss: 1.9705554874994422

Epoch: 5| Step: 3
Training loss: 1.6558449268341064
Validation loss: 1.9919150106368526

Epoch: 5| Step: 4
Training loss: 2.664214611053467
Validation loss: 2.03932354270771

Epoch: 5| Step: 5
Training loss: 1.9475377798080444
Validation loss: 2.0496602904412056

Epoch: 5| Step: 6
Training loss: 2.049919366836548
Validation loss: 2.029839705395442

Epoch: 5| Step: 7
Training loss: 2.719006299972534
Validation loss: 2.0218759570070493

Epoch: 5| Step: 8
Training loss: 2.229907274246216
Validation loss: 2.0066175127542145

Epoch: 5| Step: 9
Training loss: 2.1651504039764404
Validation loss: 2.0045370030146774

Epoch: 5| Step: 10
Training loss: 2.195401668548584
Validation loss: 2.0612844792745446

Epoch: 106| Step: 0
Training loss: 1.8794187307357788
Validation loss: 2.1188428863402335

Epoch: 5| Step: 1
Training loss: 2.0954689979553223
Validation loss: 2.129784289226737

Epoch: 5| Step: 2
Training loss: 2.7448232173919678
Validation loss: 2.108152174180554

Epoch: 5| Step: 3
Training loss: 2.193380832672119
Validation loss: 2.0663345667623703

Epoch: 5| Step: 4
Training loss: 2.2669856548309326
Validation loss: 2.0446437379365325

Epoch: 5| Step: 5
Training loss: 2.704495668411255
Validation loss: 2.038516552217545

Epoch: 5| Step: 6
Training loss: 2.4105188846588135
Validation loss: 2.0387031006556686

Epoch: 5| Step: 7
Training loss: 2.104930877685547
Validation loss: 2.0588254556860974

Epoch: 5| Step: 8
Training loss: 1.7913669347763062
Validation loss: 2.0585581641043387

Epoch: 5| Step: 9
Training loss: 2.029003858566284
Validation loss: 2.070866323286487

Epoch: 5| Step: 10
Training loss: 2.22367262840271
Validation loss: 2.063056463836342

Epoch: 107| Step: 0
Training loss: 2.002321720123291
Validation loss: 2.0263862468863048

Epoch: 5| Step: 1
Training loss: 2.3021464347839355
Validation loss: 2.006284298435334

Epoch: 5| Step: 2
Training loss: 2.1663289070129395
Validation loss: 1.9855292061323762

Epoch: 5| Step: 3
Training loss: 2.1322968006134033
Validation loss: 1.9627585513617403

Epoch: 5| Step: 4
Training loss: 2.2012598514556885
Validation loss: 1.9610839274621779

Epoch: 5| Step: 5
Training loss: 3.0407180786132812
Validation loss: 1.9518324431552683

Epoch: 5| Step: 6
Training loss: 2.1216561794281006
Validation loss: 1.9366991071290867

Epoch: 5| Step: 7
Training loss: 1.881076455116272
Validation loss: 1.9281494079097625

Epoch: 5| Step: 8
Training loss: 1.8963234424591064
Validation loss: 1.931228676149922

Epoch: 5| Step: 9
Training loss: 2.4950289726257324
Validation loss: 1.934847798398746

Epoch: 5| Step: 10
Training loss: 1.391950249671936
Validation loss: 1.9607380743949645

Epoch: 108| Step: 0
Training loss: 2.4541749954223633
Validation loss: 2.0003712920732397

Epoch: 5| Step: 1
Training loss: 2.6296939849853516
Validation loss: 2.0269136057105115

Epoch: 5| Step: 2
Training loss: 2.0437183380126953
Validation loss: 2.058476589059317

Epoch: 5| Step: 3
Training loss: 1.3976709842681885
Validation loss: 2.0526595628389748

Epoch: 5| Step: 4
Training loss: 2.669907569885254
Validation loss: 2.0453438297394784

Epoch: 5| Step: 5
Training loss: 2.968824863433838
Validation loss: 2.005380517692976

Epoch: 5| Step: 6
Training loss: 1.922491431236267
Validation loss: 1.9636702101717713

Epoch: 5| Step: 7
Training loss: 1.7782056331634521
Validation loss: 1.9400830961042834

Epoch: 5| Step: 8
Training loss: 1.2518900632858276
Validation loss: 1.9444436437340193

Epoch: 5| Step: 9
Training loss: 2.2531180381774902
Validation loss: 1.9479644580553936

Epoch: 5| Step: 10
Training loss: 2.3124523162841797
Validation loss: 1.9468423986947665

Epoch: 109| Step: 0
Training loss: 2.342653751373291
Validation loss: 1.940042152199694

Epoch: 5| Step: 1
Training loss: 2.097790241241455
Validation loss: 1.9552953679074523

Epoch: 5| Step: 2
Training loss: 2.2500221729278564
Validation loss: 1.9678055035170687

Epoch: 5| Step: 3
Training loss: 1.9226348400115967
Validation loss: 1.9682992043033722

Epoch: 5| Step: 4
Training loss: 1.9543602466583252
Validation loss: 1.9634817633577573

Epoch: 5| Step: 5
Training loss: 1.761885404586792
Validation loss: 1.9544235506365377

Epoch: 5| Step: 6
Training loss: 1.9756447076797485
Validation loss: 1.958897934165052

Epoch: 5| Step: 7
Training loss: 2.3091418743133545
Validation loss: 1.9629395930997786

Epoch: 5| Step: 8
Training loss: 2.0676636695861816
Validation loss: 1.9524578561065018

Epoch: 5| Step: 9
Training loss: 2.365482807159424
Validation loss: 1.9502465942854523

Epoch: 5| Step: 10
Training loss: 2.2738752365112305
Validation loss: 1.948946464446283

Epoch: 110| Step: 0
Training loss: 2.147080659866333
Validation loss: 1.9602325359980266

Epoch: 5| Step: 1
Training loss: 2.039966344833374
Validation loss: 1.948563560362785

Epoch: 5| Step: 2
Training loss: 1.875719428062439
Validation loss: 1.959951562266196

Epoch: 5| Step: 3
Training loss: 2.504631757736206
Validation loss: 1.9784631831671602

Epoch: 5| Step: 4
Training loss: 2.2354393005371094
Validation loss: 1.9808584361947992

Epoch: 5| Step: 5
Training loss: 1.821051001548767
Validation loss: 1.9629787757832518

Epoch: 5| Step: 6
Training loss: 1.6836566925048828
Validation loss: 1.9437137188449982

Epoch: 5| Step: 7
Training loss: 2.5403053760528564
Validation loss: 1.953397471417663

Epoch: 5| Step: 8
Training loss: 1.786773681640625
Validation loss: 1.9371120032443796

Epoch: 5| Step: 9
Training loss: 2.090578079223633
Validation loss: 1.952524636381416

Epoch: 5| Step: 10
Training loss: 2.472968339920044
Validation loss: 1.9601137420182586

Epoch: 111| Step: 0
Training loss: 2.223482847213745
Validation loss: 1.96139996282516

Epoch: 5| Step: 1
Training loss: 1.495422124862671
Validation loss: 1.972787312282029

Epoch: 5| Step: 2
Training loss: 1.9494285583496094
Validation loss: 1.96364337910888

Epoch: 5| Step: 3
Training loss: 1.6431779861450195
Validation loss: 1.9646262238102574

Epoch: 5| Step: 4
Training loss: 2.507930278778076
Validation loss: 1.9620760333153509

Epoch: 5| Step: 5
Training loss: 1.917853593826294
Validation loss: 1.9514783710561774

Epoch: 5| Step: 6
Training loss: 2.5836398601531982
Validation loss: 1.9471848241744503

Epoch: 5| Step: 7
Training loss: 2.398597478866577
Validation loss: 1.9498935643062796

Epoch: 5| Step: 8
Training loss: 1.9876267910003662
Validation loss: 1.9391916413461008

Epoch: 5| Step: 9
Training loss: 1.7163143157958984
Validation loss: 1.9316470802471202

Epoch: 5| Step: 10
Training loss: 2.526780843734741
Validation loss: 1.9396843846126268

Epoch: 112| Step: 0
Training loss: 3.1715993881225586
Validation loss: 1.9643686817538353

Epoch: 5| Step: 1
Training loss: 1.6199398040771484
Validation loss: 1.976546843846639

Epoch: 5| Step: 2
Training loss: 2.525804281234741
Validation loss: 1.991315059764411

Epoch: 5| Step: 3
Training loss: 2.3993191719055176
Validation loss: 1.9978001886798489

Epoch: 5| Step: 4
Training loss: 1.4537651538848877
Validation loss: 1.9513764201953847

Epoch: 5| Step: 5
Training loss: 2.4592440128326416
Validation loss: 1.939078938576483

Epoch: 5| Step: 6
Training loss: 1.8882274627685547
Validation loss: 1.9448722511209466

Epoch: 5| Step: 7
Training loss: 1.7971837520599365
Validation loss: 1.9580876852876397

Epoch: 5| Step: 8
Training loss: 2.1042959690093994
Validation loss: 1.947168702720314

Epoch: 5| Step: 9
Training loss: 1.4439547061920166
Validation loss: 1.9574421118664485

Epoch: 5| Step: 10
Training loss: 2.4190828800201416
Validation loss: 1.9733931813188779

Epoch: 113| Step: 0
Training loss: 2.4867756366729736
Validation loss: 1.9906972069894113

Epoch: 5| Step: 1
Training loss: 2.590921401977539
Validation loss: 2.0068735563626854

Epoch: 5| Step: 2
Training loss: 1.9991827011108398
Validation loss: 2.0089525945724978

Epoch: 5| Step: 3
Training loss: 1.7010071277618408
Validation loss: 1.984274983406067

Epoch: 5| Step: 4
Training loss: 2.1922085285186768
Validation loss: 1.9801494139496998

Epoch: 5| Step: 5
Training loss: 2.2386677265167236
Validation loss: 1.9887171637627385

Epoch: 5| Step: 6
Training loss: 1.4912980794906616
Validation loss: 2.0024533528153614

Epoch: 5| Step: 7
Training loss: 2.0083024501800537
Validation loss: 1.9914672349088935

Epoch: 5| Step: 8
Training loss: 2.051715612411499
Validation loss: 1.9885636055341331

Epoch: 5| Step: 9
Training loss: 2.116849184036255
Validation loss: 1.9552593128655547

Epoch: 5| Step: 10
Training loss: 2.302999496459961
Validation loss: 1.9799758465059343

Epoch: 114| Step: 0
Training loss: 2.702580213546753
Validation loss: 1.9840224353216027

Epoch: 5| Step: 1
Training loss: 2.831115961074829
Validation loss: 2.0057622771109305

Epoch: 5| Step: 2
Training loss: 2.227933883666992
Validation loss: 2.0014318702041463

Epoch: 5| Step: 3
Training loss: 1.674925446510315
Validation loss: 1.9948696154420094

Epoch: 5| Step: 4
Training loss: 2.1078832149505615
Validation loss: 1.9790506234733007

Epoch: 5| Step: 5
Training loss: 1.7396304607391357
Validation loss: 1.9684893495293074

Epoch: 5| Step: 6
Training loss: 1.28119695186615
Validation loss: 1.969369396086662

Epoch: 5| Step: 7
Training loss: 2.2207722663879395
Validation loss: 2.0033774760461625

Epoch: 5| Step: 8
Training loss: 2.000098466873169
Validation loss: 2.0237293320317424

Epoch: 5| Step: 9
Training loss: 2.150477886199951
Validation loss: 2.0522134637319915

Epoch: 5| Step: 10
Training loss: 2.290853261947632
Validation loss: 2.053043378296719

Epoch: 115| Step: 0
Training loss: 2.3328487873077393
Validation loss: 2.005903579855478

Epoch: 5| Step: 1
Training loss: 2.5437302589416504
Validation loss: 1.9828387204036917

Epoch: 5| Step: 2
Training loss: 2.487999677658081
Validation loss: 1.9719054237488778

Epoch: 5| Step: 3
Training loss: 2.0817885398864746
Validation loss: 1.9838396426170104

Epoch: 5| Step: 4
Training loss: 1.7223756313323975
Validation loss: 1.9773296976602206

Epoch: 5| Step: 5
Training loss: 1.0840030908584595
Validation loss: 1.962723703794582

Epoch: 5| Step: 6
Training loss: 2.261794328689575
Validation loss: 1.9605921160790227

Epoch: 5| Step: 7
Training loss: 1.4402039051055908
Validation loss: 1.9645365873972576

Epoch: 5| Step: 8
Training loss: 2.3472368717193604
Validation loss: 1.9616243787991103

Epoch: 5| Step: 9
Training loss: 2.386168956756592
Validation loss: 1.9524907976068475

Epoch: 5| Step: 10
Training loss: 2.2115652561187744
Validation loss: 1.9532453731823993

Epoch: 116| Step: 0
Training loss: 2.449803113937378
Validation loss: 1.9579269834744033

Epoch: 5| Step: 1
Training loss: 2.029208183288574
Validation loss: 1.948641623220136

Epoch: 5| Step: 2
Training loss: 1.4537808895111084
Validation loss: 1.9451401579764582

Epoch: 5| Step: 3
Training loss: 2.186391830444336
Validation loss: 1.9395518136280838

Epoch: 5| Step: 4
Training loss: 2.014812469482422
Validation loss: 1.9381670105841853

Epoch: 5| Step: 5
Training loss: 2.026341438293457
Validation loss: 1.9433934150203582

Epoch: 5| Step: 6
Training loss: 2.2321555614471436
Validation loss: 1.9746704357926563

Epoch: 5| Step: 7
Training loss: 2.1700949668884277
Validation loss: 1.981116937052819

Epoch: 5| Step: 8
Training loss: 2.5447723865509033
Validation loss: 1.981091268600956

Epoch: 5| Step: 9
Training loss: 1.6117385625839233
Validation loss: 1.9672202371781873

Epoch: 5| Step: 10
Training loss: 2.0385146141052246
Validation loss: 1.9488044041459278

Epoch: 117| Step: 0
Training loss: 1.633917212486267
Validation loss: 1.9517081604208997

Epoch: 5| Step: 1
Training loss: 1.3469948768615723
Validation loss: 1.9762430216676445

Epoch: 5| Step: 2
Training loss: 2.178504228591919
Validation loss: 1.9731890898878857

Epoch: 5| Step: 3
Training loss: 2.072841167449951
Validation loss: 1.9649382175937775

Epoch: 5| Step: 4
Training loss: 1.8133262395858765
Validation loss: 1.9663820676906134

Epoch: 5| Step: 5
Training loss: 1.9870589971542358
Validation loss: 1.9691928843016266

Epoch: 5| Step: 6
Training loss: 2.8445534706115723
Validation loss: 1.9924982606723745

Epoch: 5| Step: 7
Training loss: 1.8119659423828125
Validation loss: 1.987718261698241

Epoch: 5| Step: 8
Training loss: 1.9921791553497314
Validation loss: 1.9920514886097243

Epoch: 5| Step: 9
Training loss: 2.303227663040161
Validation loss: 1.9988390066290413

Epoch: 5| Step: 10
Training loss: 2.684307098388672
Validation loss: 1.9776870691648094

Epoch: 118| Step: 0
Training loss: 1.5618422031402588
Validation loss: 1.974569441169821

Epoch: 5| Step: 1
Training loss: 1.7368656396865845
Validation loss: 1.9678952950303272

Epoch: 5| Step: 2
Training loss: 1.7773988246917725
Validation loss: 1.9487011073738016

Epoch: 5| Step: 3
Training loss: 2.57319974899292
Validation loss: 1.9467197874540925

Epoch: 5| Step: 4
Training loss: 2.185342788696289
Validation loss: 1.953861431408954

Epoch: 5| Step: 5
Training loss: 1.7546113729476929
Validation loss: 1.9690103889793478

Epoch: 5| Step: 6
Training loss: 2.172746419906616
Validation loss: 1.9961860846447688

Epoch: 5| Step: 7
Training loss: 2.526505708694458
Validation loss: 1.9758907107896702

Epoch: 5| Step: 8
Training loss: 1.279149055480957
Validation loss: 1.980374046551284

Epoch: 5| Step: 9
Training loss: 2.0930190086364746
Validation loss: 1.9946488154831754

Epoch: 5| Step: 10
Training loss: 3.0104610919952393
Validation loss: 2.0074452879608318

Epoch: 119| Step: 0
Training loss: 1.900615930557251
Validation loss: 2.0451177538082166

Epoch: 5| Step: 1
Training loss: 1.9962104558944702
Validation loss: 2.0604823968743764

Epoch: 5| Step: 2
Training loss: 1.4832826852798462
Validation loss: 2.0926784417962514

Epoch: 5| Step: 3
Training loss: 2.803589344024658
Validation loss: 2.0788186237376225

Epoch: 5| Step: 4
Training loss: 2.460056781768799
Validation loss: 2.0059325771947063

Epoch: 5| Step: 5
Training loss: 2.514801025390625
Validation loss: 1.9888802407890238

Epoch: 5| Step: 6
Training loss: 1.8924667835235596
Validation loss: 2.003212172497985

Epoch: 5| Step: 7
Training loss: 2.4783778190612793
Validation loss: 2.0141044521844513

Epoch: 5| Step: 8
Training loss: 2.4299519062042236
Validation loss: 2.01208310486168

Epoch: 5| Step: 9
Training loss: 1.909377098083496
Validation loss: 2.0022658289119764

Epoch: 5| Step: 10
Training loss: 1.2751127481460571
Validation loss: 1.9924879663734025

Epoch: 120| Step: 0
Training loss: 2.0815374851226807
Validation loss: 1.9574980082050446

Epoch: 5| Step: 1
Training loss: 1.9924087524414062
Validation loss: 1.9541959775391446

Epoch: 5| Step: 2
Training loss: 1.704568862915039
Validation loss: 1.9540160753393685

Epoch: 5| Step: 3
Training loss: 2.1278457641601562
Validation loss: 1.9656774215800787

Epoch: 5| Step: 4
Training loss: 2.4192020893096924
Validation loss: 1.9456157915053829

Epoch: 5| Step: 5
Training loss: 2.30332088470459
Validation loss: 1.9308796146864533

Epoch: 5| Step: 6
Training loss: 1.7756321430206299
Validation loss: 1.932005524635315

Epoch: 5| Step: 7
Training loss: 2.5301289558410645
Validation loss: 1.9470291073604296

Epoch: 5| Step: 8
Training loss: 1.9654197692871094
Validation loss: 1.9681943334558958

Epoch: 5| Step: 9
Training loss: 1.7574764490127563
Validation loss: 1.9814012153174287

Epoch: 5| Step: 10
Training loss: 2.020122528076172
Validation loss: 1.9976437373827862

Epoch: 121| Step: 0
Training loss: 1.734951376914978
Validation loss: 1.9961825660479966

Epoch: 5| Step: 1
Training loss: 2.0852577686309814
Validation loss: 2.0053808009752663

Epoch: 5| Step: 2
Training loss: 1.8259350061416626
Validation loss: 2.0287914045395388

Epoch: 5| Step: 3
Training loss: 2.4066970348358154
Validation loss: 2.0390663326427503

Epoch: 5| Step: 4
Training loss: 2.1058456897735596
Validation loss: 2.0288872282992125

Epoch: 5| Step: 5
Training loss: 2.2624008655548096
Validation loss: 2.0172772433168147

Epoch: 5| Step: 6
Training loss: 1.9252666234970093
Validation loss: 2.0270390484922673

Epoch: 5| Step: 7
Training loss: 2.139559268951416
Validation loss: 2.0344235153608423

Epoch: 5| Step: 8
Training loss: 2.296051502227783
Validation loss: 2.0062208714023715

Epoch: 5| Step: 9
Training loss: 1.6510074138641357
Validation loss: 1.9992670602695917

Epoch: 5| Step: 10
Training loss: 2.0931339263916016
Validation loss: 1.9912417678422825

Epoch: 122| Step: 0
Training loss: 2.3499794006347656
Validation loss: 1.984859638316657

Epoch: 5| Step: 1
Training loss: 2.167206287384033
Validation loss: 1.9795463315902218

Epoch: 5| Step: 2
Training loss: 1.8057054281234741
Validation loss: 1.9973340034484863

Epoch: 5| Step: 3
Training loss: 2.1043601036071777
Validation loss: 1.9891144896066317

Epoch: 5| Step: 4
Training loss: 1.5721296072006226
Validation loss: 2.001577631119759

Epoch: 5| Step: 5
Training loss: 1.6128047704696655
Validation loss: 2.010893057751399

Epoch: 5| Step: 6
Training loss: 2.0628902912139893
Validation loss: 2.007233040307158

Epoch: 5| Step: 7
Training loss: 2.3142411708831787
Validation loss: 1.9910338822231497

Epoch: 5| Step: 8
Training loss: 2.6291544437408447
Validation loss: 1.9921466945320048

Epoch: 5| Step: 9
Training loss: 1.7461658716201782
Validation loss: 2.0001098558466923

Epoch: 5| Step: 10
Training loss: 1.7953392267227173
Validation loss: 2.0043070341951106

Epoch: 123| Step: 0
Training loss: 1.3127532005310059
Validation loss: 2.01750208229147

Epoch: 5| Step: 1
Training loss: 1.5187013149261475
Validation loss: 2.021441566046848

Epoch: 5| Step: 2
Training loss: 1.975623369216919
Validation loss: 2.0303093746144283

Epoch: 5| Step: 3
Training loss: 2.5978405475616455
Validation loss: 2.034892112978043

Epoch: 5| Step: 4
Training loss: 2.529594898223877
Validation loss: 2.0143621916412027

Epoch: 5| Step: 5
Training loss: 2.2369840145111084
Validation loss: 1.9995308819637503

Epoch: 5| Step: 6
Training loss: 1.9918544292449951
Validation loss: 1.9729049359598467

Epoch: 5| Step: 7
Training loss: 1.7793232202529907
Validation loss: 1.9683630492097588

Epoch: 5| Step: 8
Training loss: 2.1833362579345703
Validation loss: 1.9846803859997821

Epoch: 5| Step: 9
Training loss: 2.0478873252868652
Validation loss: 2.0001979694571546

Epoch: 5| Step: 10
Training loss: 1.732801914215088
Validation loss: 2.0137235285133444

Epoch: 124| Step: 0
Training loss: 2.1583008766174316
Validation loss: 2.0217910018018497

Epoch: 5| Step: 1
Training loss: 2.2076632976531982
Validation loss: 2.0216720245217763

Epoch: 5| Step: 2
Training loss: 1.9785476922988892
Validation loss: 1.9929917858492943

Epoch: 5| Step: 3
Training loss: 1.751926064491272
Validation loss: 1.9825868375839726

Epoch: 5| Step: 4
Training loss: 1.9795188903808594
Validation loss: 1.9839000740358907

Epoch: 5| Step: 5
Training loss: 2.0937371253967285
Validation loss: 1.9785028503787132

Epoch: 5| Step: 6
Training loss: 1.5154645442962646
Validation loss: 2.0010378232566257

Epoch: 5| Step: 7
Training loss: 1.7534278631210327
Validation loss: 2.00231756061636

Epoch: 5| Step: 8
Training loss: 2.3114547729492188
Validation loss: 1.9922010091043287

Epoch: 5| Step: 9
Training loss: 2.117845058441162
Validation loss: 2.0310877125750304

Epoch: 5| Step: 10
Training loss: 2.3293044567108154
Validation loss: 2.067808876755417

Epoch: 125| Step: 0
Training loss: 1.6323144435882568
Validation loss: 2.069923339351531

Epoch: 5| Step: 1
Training loss: 1.8616678714752197
Validation loss: 2.0766152874115975

Epoch: 5| Step: 2
Training loss: 2.1363930702209473
Validation loss: 2.092935190405897

Epoch: 5| Step: 3
Training loss: 1.9686886072158813
Validation loss: 2.07521177107288

Epoch: 5| Step: 4
Training loss: 2.1522138118743896
Validation loss: 2.0445651661965156

Epoch: 5| Step: 5
Training loss: 2.4513649940490723
Validation loss: 2.009214790918494

Epoch: 5| Step: 6
Training loss: 1.3600904941558838
Validation loss: 1.9942472019503195

Epoch: 5| Step: 7
Training loss: 1.8921539783477783
Validation loss: 1.993730083588631

Epoch: 5| Step: 8
Training loss: 2.967423915863037
Validation loss: 1.9895458464981408

Epoch: 5| Step: 9
Training loss: 1.4818832874298096
Validation loss: 1.9826025373192244

Epoch: 5| Step: 10
Training loss: 2.239205837249756
Validation loss: 1.9842759537440475

Epoch: 126| Step: 0
Training loss: 1.912427306175232
Validation loss: 1.970233686508671

Epoch: 5| Step: 1
Training loss: 2.1983532905578613
Validation loss: 1.9525968810563445

Epoch: 5| Step: 2
Training loss: 1.7781531810760498
Validation loss: 1.9576838452328917

Epoch: 5| Step: 3
Training loss: 1.9089515209197998
Validation loss: 1.9559042043583368

Epoch: 5| Step: 4
Training loss: 2.1905081272125244
Validation loss: 1.9618145445341706

Epoch: 5| Step: 5
Training loss: 2.4881319999694824
Validation loss: 2.014376696719918

Epoch: 5| Step: 6
Training loss: 2.011634349822998
Validation loss: 2.0349395018751903

Epoch: 5| Step: 7
Training loss: 1.9784904718399048
Validation loss: 2.0869592607662244

Epoch: 5| Step: 8
Training loss: 2.1164121627807617
Validation loss: 2.1234145395217405

Epoch: 5| Step: 9
Training loss: 2.0053699016571045
Validation loss: 2.0918964480841034

Epoch: 5| Step: 10
Training loss: 1.860901117324829
Validation loss: 2.0040827335849887

Epoch: 127| Step: 0
Training loss: 2.406219720840454
Validation loss: 1.9750221083241124

Epoch: 5| Step: 1
Training loss: 1.7314350605010986
Validation loss: 1.9593889918378604

Epoch: 5| Step: 2
Training loss: 1.7225176095962524
Validation loss: 1.9654234122204524

Epoch: 5| Step: 3
Training loss: 2.1675167083740234
Validation loss: 1.9967074073770994

Epoch: 5| Step: 4
Training loss: 2.263859272003174
Validation loss: 1.9928438766028291

Epoch: 5| Step: 5
Training loss: 1.6795063018798828
Validation loss: 2.023544094895804

Epoch: 5| Step: 6
Training loss: 1.767354965209961
Validation loss: 2.0193802464392876

Epoch: 5| Step: 7
Training loss: 2.1068296432495117
Validation loss: 2.007174253463745

Epoch: 5| Step: 8
Training loss: 1.7473556995391846
Validation loss: 1.9782108209466422

Epoch: 5| Step: 9
Training loss: 2.215451717376709
Validation loss: 1.9770596770830051

Epoch: 5| Step: 10
Training loss: 1.9959383010864258
Validation loss: 1.9701915248747794

Epoch: 128| Step: 0
Training loss: 2.7143447399139404
Validation loss: 1.9710608938688874

Epoch: 5| Step: 1
Training loss: 2.028888702392578
Validation loss: 1.9740113122488863

Epoch: 5| Step: 2
Training loss: 2.1867480278015137
Validation loss: 1.9795056543042582

Epoch: 5| Step: 3
Training loss: 1.8431892395019531
Validation loss: 1.9834917565827728

Epoch: 5| Step: 4
Training loss: 1.566882848739624
Validation loss: 1.9741966724395752

Epoch: 5| Step: 5
Training loss: 1.918408751487732
Validation loss: 1.996877867688415

Epoch: 5| Step: 6
Training loss: 2.136906147003174
Validation loss: 2.0473162871535107

Epoch: 5| Step: 7
Training loss: 1.8203537464141846
Validation loss: 2.0982025874558317

Epoch: 5| Step: 8
Training loss: 1.6188573837280273
Validation loss: 2.077430248260498

Epoch: 5| Step: 9
Training loss: 2.0112721920013428
Validation loss: 2.049966201987318

Epoch: 5| Step: 10
Training loss: 2.2800166606903076
Validation loss: 2.0159454960976877

Epoch: 129| Step: 0
Training loss: 2.4238524436950684
Validation loss: 1.9914336601893108

Epoch: 5| Step: 1
Training loss: 1.6298837661743164
Validation loss: 2.0000601250638246

Epoch: 5| Step: 2
Training loss: 1.39667809009552
Validation loss: 2.013527762505316

Epoch: 5| Step: 3
Training loss: 2.1757419109344482
Validation loss: 2.0263125922090266

Epoch: 5| Step: 4
Training loss: 2.546555280685425
Validation loss: 2.021495644764234

Epoch: 5| Step: 5
Training loss: 1.9517745971679688
Validation loss: 1.9969699562236827

Epoch: 5| Step: 6
Training loss: 1.8981359004974365
Validation loss: 1.9760707680897047

Epoch: 5| Step: 7
Training loss: 1.6888983249664307
Validation loss: 1.9770284147672756

Epoch: 5| Step: 8
Training loss: 2.9128410816192627
Validation loss: 1.9864653054104056

Epoch: 5| Step: 9
Training loss: 1.0321104526519775
Validation loss: 2.0243409269599506

Epoch: 5| Step: 10
Training loss: 2.392549514770508
Validation loss: 2.0490990479787192

Epoch: 130| Step: 0
Training loss: 2.4821383953094482
Validation loss: 2.044142985856661

Epoch: 5| Step: 1
Training loss: 1.6383081674575806
Validation loss: 2.06413431321421

Epoch: 5| Step: 2
Training loss: 2.2135651111602783
Validation loss: 2.043887215275918

Epoch: 5| Step: 3
Training loss: 2.0772552490234375
Validation loss: 2.032858689626058

Epoch: 5| Step: 4
Training loss: 1.7451013326644897
Validation loss: 2.00936694042657

Epoch: 5| Step: 5
Training loss: 2.0205295085906982
Validation loss: 1.9683727705350487

Epoch: 5| Step: 6
Training loss: 1.642078161239624
Validation loss: 1.955017702553862

Epoch: 5| Step: 7
Training loss: 2.008213520050049
Validation loss: 1.9678796798952165

Epoch: 5| Step: 8
Training loss: 2.073078155517578
Validation loss: 1.9731078404252247

Epoch: 5| Step: 9
Training loss: 1.607278823852539
Validation loss: 1.9864724861678256

Epoch: 5| Step: 10
Training loss: 2.383521795272827
Validation loss: 1.974442010284752

Epoch: 131| Step: 0
Training loss: 1.9017270803451538
Validation loss: 1.9661090630356983

Epoch: 5| Step: 1
Training loss: 1.7864052057266235
Validation loss: 1.9807278686954128

Epoch: 5| Step: 2
Training loss: 1.7809698581695557
Validation loss: 1.9679607319575485

Epoch: 5| Step: 3
Training loss: 1.557708501815796
Validation loss: 1.9954940913825907

Epoch: 5| Step: 4
Training loss: 2.298532009124756
Validation loss: 2.056510615092452

Epoch: 5| Step: 5
Training loss: 1.9151275157928467
Validation loss: 2.048346329760808

Epoch: 5| Step: 6
Training loss: 1.754144310951233
Validation loss: 2.008112428008869

Epoch: 5| Step: 7
Training loss: 1.9414288997650146
Validation loss: 1.9992468728814075

Epoch: 5| Step: 8
Training loss: 2.4353671073913574
Validation loss: 1.9583454439716954

Epoch: 5| Step: 9
Training loss: 1.692753553390503
Validation loss: 1.9510265742578814

Epoch: 5| Step: 10
Training loss: 2.858994245529175
Validation loss: 1.9444784272101618

Epoch: 132| Step: 0
Training loss: 1.7822656631469727
Validation loss: 1.9393301151132072

Epoch: 5| Step: 1
Training loss: 2.211160182952881
Validation loss: 1.9311329985177645

Epoch: 5| Step: 2
Training loss: 2.1858761310577393
Validation loss: 1.930993559539959

Epoch: 5| Step: 3
Training loss: 1.9090923070907593
Validation loss: 1.9316057620509979

Epoch: 5| Step: 4
Training loss: 1.7686405181884766
Validation loss: 1.9422324216493996

Epoch: 5| Step: 5
Training loss: 2.486025094985962
Validation loss: 1.950736661111155

Epoch: 5| Step: 6
Training loss: 2.0209431648254395
Validation loss: 1.964094772133776

Epoch: 5| Step: 7
Training loss: 1.8216445446014404
Validation loss: 1.9704830467060048

Epoch: 5| Step: 8
Training loss: 1.8733326196670532
Validation loss: 2.002133023354315

Epoch: 5| Step: 9
Training loss: 1.501055359840393
Validation loss: 2.037698094562818

Epoch: 5| Step: 10
Training loss: 2.3144636154174805
Validation loss: 2.0899838221970426

Epoch: 133| Step: 0
Training loss: 2.7555019855499268
Validation loss: 2.0821479776854157

Epoch: 5| Step: 1
Training loss: 2.3211593627929688
Validation loss: 2.1045265223390315

Epoch: 5| Step: 2
Training loss: 1.9187644720077515
Validation loss: 2.098132279611403

Epoch: 5| Step: 3
Training loss: 1.7171192169189453
Validation loss: 2.083188926019976

Epoch: 5| Step: 4
Training loss: 1.7003262042999268
Validation loss: 2.0803844364740516

Epoch: 5| Step: 5
Training loss: 1.8735853433609009
Validation loss: 2.0612049359147266

Epoch: 5| Step: 6
Training loss: 1.5584710836410522
Validation loss: 2.039080132720291

Epoch: 5| Step: 7
Training loss: 2.0006728172302246
Validation loss: 2.0095442584765855

Epoch: 5| Step: 8
Training loss: 2.1446022987365723
Validation loss: 1.988490403339427

Epoch: 5| Step: 9
Training loss: 1.313656210899353
Validation loss: 1.9848109650355514

Epoch: 5| Step: 10
Training loss: 2.1853249073028564
Validation loss: 1.9748867865531676

Epoch: 134| Step: 0
Training loss: 1.8179517984390259
Validation loss: 1.9534471599004601

Epoch: 5| Step: 1
Training loss: 2.278637409210205
Validation loss: 1.9452429791932464

Epoch: 5| Step: 2
Training loss: 2.3007826805114746
Validation loss: 1.9411076986661522

Epoch: 5| Step: 3
Training loss: 2.0135300159454346
Validation loss: 1.9301258453758814

Epoch: 5| Step: 4
Training loss: 1.8941752910614014
Validation loss: 1.9168729282194568

Epoch: 5| Step: 5
Training loss: 1.9333299398422241
Validation loss: 1.9165823049442743

Epoch: 5| Step: 6
Training loss: 1.9777263402938843
Validation loss: 1.91635311290782

Epoch: 5| Step: 7
Training loss: 2.251378059387207
Validation loss: 1.9257746550344652

Epoch: 5| Step: 8
Training loss: 1.9230690002441406
Validation loss: 1.9329271495983165

Epoch: 5| Step: 9
Training loss: 1.6970090866088867
Validation loss: 1.9504293587899977

Epoch: 5| Step: 10
Training loss: 1.6045711040496826
Validation loss: 1.9659036141569897

Epoch: 135| Step: 0
Training loss: 1.713688611984253
Validation loss: 1.9851433538621472

Epoch: 5| Step: 1
Training loss: 2.538292646408081
Validation loss: 2.0028251422348844

Epoch: 5| Step: 2
Training loss: 2.1604716777801514
Validation loss: 2.0421035738401514

Epoch: 5| Step: 3
Training loss: 1.916982889175415
Validation loss: 2.086228286066363

Epoch: 5| Step: 4
Training loss: 2.102933406829834
Validation loss: 2.1665565903468798

Epoch: 5| Step: 5
Training loss: 1.8742706775665283
Validation loss: 2.1836124543220765

Epoch: 5| Step: 6
Training loss: 1.7038148641586304
Validation loss: 2.1263738934711744

Epoch: 5| Step: 7
Training loss: 1.7333056926727295
Validation loss: 2.1077596320900867

Epoch: 5| Step: 8
Training loss: 2.118921995162964
Validation loss: 2.0352050181358092

Epoch: 5| Step: 9
Training loss: 1.7513234615325928
Validation loss: 2.00938085843158

Epoch: 5| Step: 10
Training loss: 2.135209083557129
Validation loss: 1.9809026474593787

Epoch: 136| Step: 0
Training loss: 1.9223483800888062
Validation loss: 1.9623759997788297

Epoch: 5| Step: 1
Training loss: 2.0167908668518066
Validation loss: 1.9426053570162864

Epoch: 5| Step: 2
Training loss: 2.290769100189209
Validation loss: 1.9458860428102556

Epoch: 5| Step: 3
Training loss: 1.8484853506088257
Validation loss: 1.945621596869602

Epoch: 5| Step: 4
Training loss: 2.035975456237793
Validation loss: 1.9198555420803767

Epoch: 5| Step: 5
Training loss: 2.144225597381592
Validation loss: 1.9108539165989045

Epoch: 5| Step: 6
Training loss: 1.8277794122695923
Validation loss: 1.939542531967163

Epoch: 5| Step: 7
Training loss: 2.0277934074401855
Validation loss: 1.9353315445684618

Epoch: 5| Step: 8
Training loss: 1.8796430826187134
Validation loss: 1.958200954621838

Epoch: 5| Step: 9
Training loss: 1.2937604188919067
Validation loss: 1.9483849463924285

Epoch: 5| Step: 10
Training loss: 1.893422245979309
Validation loss: 1.977930474024947

Epoch: 137| Step: 0
Training loss: 2.041212558746338
Validation loss: 1.9671870175228323

Epoch: 5| Step: 1
Training loss: 1.3193700313568115
Validation loss: 1.9509714021477649

Epoch: 5| Step: 2
Training loss: 2.113523006439209
Validation loss: 1.9746200807632939

Epoch: 5| Step: 3
Training loss: 1.840256929397583
Validation loss: 1.9912798250875166

Epoch: 5| Step: 4
Training loss: 2.0809788703918457
Validation loss: 2.0060250143851004

Epoch: 5| Step: 5
Training loss: 2.768678665161133
Validation loss: 1.999634611991144

Epoch: 5| Step: 6
Training loss: 2.020049810409546
Validation loss: 2.017660624237471

Epoch: 5| Step: 7
Training loss: 1.4959684610366821
Validation loss: 1.9964066923305552

Epoch: 5| Step: 8
Training loss: 1.932700514793396
Validation loss: 1.9992576940085298

Epoch: 5| Step: 9
Training loss: 1.525963544845581
Validation loss: 2.0141023346172866

Epoch: 5| Step: 10
Training loss: 1.8012514114379883
Validation loss: 2.039538868011967

Epoch: 138| Step: 0
Training loss: 1.7069575786590576
Validation loss: 2.039777999283165

Epoch: 5| Step: 1
Training loss: 2.0928895473480225
Validation loss: 2.0308029933642318

Epoch: 5| Step: 2
Training loss: 2.2547199726104736
Validation loss: 2.0433861747864754

Epoch: 5| Step: 3
Training loss: 2.2846693992614746
Validation loss: 2.0771338657666276

Epoch: 5| Step: 4
Training loss: 1.6438953876495361
Validation loss: 2.1243325459059847

Epoch: 5| Step: 5
Training loss: 2.0046494007110596
Validation loss: 2.1256723891022387

Epoch: 5| Step: 6
Training loss: 1.5774154663085938
Validation loss: 2.061711226740191

Epoch: 5| Step: 7
Training loss: 2.2332820892333984
Validation loss: 2.0095566805972847

Epoch: 5| Step: 8
Training loss: 1.921433448791504
Validation loss: 1.973882467516007

Epoch: 5| Step: 9
Training loss: 1.83990478515625
Validation loss: 1.95597029501392

Epoch: 5| Step: 10
Training loss: 1.6344215869903564
Validation loss: 1.9402372170520086

Epoch: 139| Step: 0
Training loss: 1.7230348587036133
Validation loss: 1.9280883727535125

Epoch: 5| Step: 1
Training loss: 2.282796859741211
Validation loss: 1.9198291917001047

Epoch: 5| Step: 2
Training loss: 1.7117488384246826
Validation loss: 1.9299143578416558

Epoch: 5| Step: 3
Training loss: 1.8800296783447266
Validation loss: 1.9437776675788305

Epoch: 5| Step: 4
Training loss: 1.851478934288025
Validation loss: 1.9466576563414706

Epoch: 5| Step: 5
Training loss: 2.0424585342407227
Validation loss: 1.972182112355386

Epoch: 5| Step: 6
Training loss: 2.261662244796753
Validation loss: 1.9768439979963406

Epoch: 5| Step: 7
Training loss: 1.5268909931182861
Validation loss: 1.9777460380267071

Epoch: 5| Step: 8
Training loss: 1.530579686164856
Validation loss: 2.005620333456224

Epoch: 5| Step: 9
Training loss: 1.4707835912704468
Validation loss: 1.9928147433906473

Epoch: 5| Step: 10
Training loss: 2.5953989028930664
Validation loss: 2.010594480781145

Epoch: 140| Step: 0
Training loss: 1.9647448062896729
Validation loss: 2.0270044572891726

Epoch: 5| Step: 1
Training loss: 1.2193933725357056
Validation loss: 2.1156491823093866

Epoch: 5| Step: 2
Training loss: 1.9401524066925049
Validation loss: 2.1924547533835135

Epoch: 5| Step: 3
Training loss: 1.8592361211776733
Validation loss: 2.2088919852369573

Epoch: 5| Step: 4
Training loss: 2.374849796295166
Validation loss: 2.169145735361243

Epoch: 5| Step: 5
Training loss: 1.3907769918441772
Validation loss: 2.0831686476225495

Epoch: 5| Step: 6
Training loss: 2.2472546100616455
Validation loss: 2.0489165077927294

Epoch: 5| Step: 7
Training loss: 1.7197997570037842
Validation loss: 2.0463806095943657

Epoch: 5| Step: 8
Training loss: 1.7631458044052124
Validation loss: 2.041168778173385

Epoch: 5| Step: 9
Training loss: 2.167501926422119
Validation loss: 2.0378223952426704

Epoch: 5| Step: 10
Training loss: 3.1138768196105957
Validation loss: 2.0313147524351716

Epoch: 141| Step: 0
Training loss: 2.1404004096984863
Validation loss: 2.018365272911646

Epoch: 5| Step: 1
Training loss: 1.698188066482544
Validation loss: 1.9963849923943962

Epoch: 5| Step: 2
Training loss: 2.3295960426330566
Validation loss: 1.9850858206390052

Epoch: 5| Step: 3
Training loss: 1.4558403491973877
Validation loss: 1.9997652012814757

Epoch: 5| Step: 4
Training loss: 1.5600407123565674
Validation loss: 2.0781327883402505

Epoch: 5| Step: 5
Training loss: 2.334064483642578
Validation loss: 2.1713866033861713

Epoch: 5| Step: 6
Training loss: 2.446829080581665
Validation loss: 2.306386906613586

Epoch: 5| Step: 7
Training loss: 2.314506769180298
Validation loss: 2.198563221962221

Epoch: 5| Step: 8
Training loss: 1.6673147678375244
Validation loss: 2.099460530024703

Epoch: 5| Step: 9
Training loss: 1.4623581171035767
Validation loss: 2.0136391167999594

Epoch: 5| Step: 10
Training loss: 2.0036120414733887
Validation loss: 1.9576802099904707

Epoch: 142| Step: 0
Training loss: 1.8269617557525635
Validation loss: 1.9567027604708107

Epoch: 5| Step: 1
Training loss: 1.4447556734085083
Validation loss: 1.93457612170968

Epoch: 5| Step: 2
Training loss: 1.9965627193450928
Validation loss: 1.9162768727989608

Epoch: 5| Step: 3
Training loss: 1.9138705730438232
Validation loss: 1.9220563980840868

Epoch: 5| Step: 4
Training loss: 2.2938690185546875
Validation loss: 1.9147751126238095

Epoch: 5| Step: 5
Training loss: 2.404517650604248
Validation loss: 1.9339746275255758

Epoch: 5| Step: 6
Training loss: 1.8502895832061768
Validation loss: 1.9432421256137151

Epoch: 5| Step: 7
Training loss: 2.077347993850708
Validation loss: 1.961880091697939

Epoch: 5| Step: 8
Training loss: 1.378153681755066
Validation loss: 1.9801520698813981

Epoch: 5| Step: 9
Training loss: 1.3852869272232056
Validation loss: 2.001766235597672

Epoch: 5| Step: 10
Training loss: 2.0062038898468018
Validation loss: 2.0283369838550525

Epoch: 143| Step: 0
Training loss: 1.8239619731903076
Validation loss: 2.0766119956970215

Epoch: 5| Step: 1
Training loss: 1.7378689050674438
Validation loss: 2.0694623942016275

Epoch: 5| Step: 2
Training loss: 1.2962687015533447
Validation loss: 2.078632434209188

Epoch: 5| Step: 3
Training loss: 1.5645473003387451
Validation loss: 2.1220676232409734

Epoch: 5| Step: 4
Training loss: 2.253614902496338
Validation loss: 2.1795506220991894

Epoch: 5| Step: 5
Training loss: 2.3440639972686768
Validation loss: 2.1873368358099334

Epoch: 5| Step: 6
Training loss: 1.7341588735580444
Validation loss: 2.0967339802813787

Epoch: 5| Step: 7
Training loss: 1.941232681274414
Validation loss: 2.0633766446062314

Epoch: 5| Step: 8
Training loss: 2.2043566703796387
Validation loss: 2.02793356808283

Epoch: 5| Step: 9
Training loss: 1.7249164581298828
Validation loss: 1.9888602879739576

Epoch: 5| Step: 10
Training loss: 2.261864185333252
Validation loss: 1.9549439466127785

Epoch: 144| Step: 0
Training loss: 2.33960223197937
Validation loss: 1.9665065632071546

Epoch: 5| Step: 1
Training loss: 1.3405637741088867
Validation loss: 1.9611062106265817

Epoch: 5| Step: 2
Training loss: 2.224639892578125
Validation loss: 1.9689778281796364

Epoch: 5| Step: 3
Training loss: 1.6871068477630615
Validation loss: 1.9663221220816336

Epoch: 5| Step: 4
Training loss: 1.7573093175888062
Validation loss: 1.9712618627855856

Epoch: 5| Step: 5
Training loss: 1.936719536781311
Validation loss: 1.941554020809871

Epoch: 5| Step: 6
Training loss: 2.456300973892212
Validation loss: 1.935248863312506

Epoch: 5| Step: 7
Training loss: 1.341281533241272
Validation loss: 1.9305039426331878

Epoch: 5| Step: 8
Training loss: 1.806057333946228
Validation loss: 1.9491944646322599

Epoch: 5| Step: 9
Training loss: 1.8556066751480103
Validation loss: 1.9868585525020477

Epoch: 5| Step: 10
Training loss: 1.8131166696548462
Validation loss: 2.026751047821455

Epoch: 145| Step: 0
Training loss: 2.6121535301208496
Validation loss: 2.1168631892050467

Epoch: 5| Step: 1
Training loss: 2.3035075664520264
Validation loss: 2.1753389514902586

Epoch: 5| Step: 2
Training loss: 1.92098867893219
Validation loss: 2.1594941077693814

Epoch: 5| Step: 3
Training loss: 1.6846206188201904
Validation loss: 2.0860282721058017

Epoch: 5| Step: 4
Training loss: 1.234114408493042
Validation loss: 2.0414216672220538

Epoch: 5| Step: 5
Training loss: 1.3215007781982422
Validation loss: 2.053715523853097

Epoch: 5| Step: 6
Training loss: 1.7549461126327515
Validation loss: 2.0333311403951337

Epoch: 5| Step: 7
Training loss: 1.4616801738739014
Validation loss: 2.016386825551269

Epoch: 5| Step: 8
Training loss: 1.4814178943634033
Validation loss: 2.0092414694447673

Epoch: 5| Step: 9
Training loss: 2.794968366622925
Validation loss: 2.0023814862774265

Epoch: 5| Step: 10
Training loss: 1.7953715324401855
Validation loss: 2.010090534405042

Epoch: 146| Step: 0
Training loss: 1.4963487386703491
Validation loss: 2.0066711646254345

Epoch: 5| Step: 1
Training loss: 1.8473577499389648
Validation loss: 2.0093935920346166

Epoch: 5| Step: 2
Training loss: 1.8323348760604858
Validation loss: 2.0124906057952554

Epoch: 5| Step: 3
Training loss: 2.00014591217041
Validation loss: 2.0258426743168987

Epoch: 5| Step: 4
Training loss: 2.150629997253418
Validation loss: 2.0547043482462564

Epoch: 5| Step: 5
Training loss: 2.0568108558654785
Validation loss: 2.048093861149203

Epoch: 5| Step: 6
Training loss: 1.497929573059082
Validation loss: 2.07162727591812

Epoch: 5| Step: 7
Training loss: 2.0824227333068848
Validation loss: 2.0702801814643284

Epoch: 5| Step: 8
Training loss: 1.521634817123413
Validation loss: 2.059462866475505

Epoch: 5| Step: 9
Training loss: 1.7137991189956665
Validation loss: 2.0879070271727858

Epoch: 5| Step: 10
Training loss: 1.6013814210891724
Validation loss: 2.0666019737079577

Epoch: 147| Step: 0
Training loss: 1.838079810142517
Validation loss: 2.0454952614281767

Epoch: 5| Step: 1
Training loss: 1.6361024379730225
Validation loss: 2.056172950293428

Epoch: 5| Step: 2
Training loss: 1.849035620689392
Validation loss: 2.0381283298615487

Epoch: 5| Step: 3
Training loss: 1.7805017232894897
Validation loss: 2.0330697977414696

Epoch: 5| Step: 4
Training loss: 1.1733511686325073
Validation loss: 2.024329093194777

Epoch: 5| Step: 5
Training loss: 2.0228207111358643
Validation loss: 2.0387170545516478

Epoch: 5| Step: 6
Training loss: 1.7454040050506592
Validation loss: 2.011005375974922

Epoch: 5| Step: 7
Training loss: 1.6267244815826416
Validation loss: 2.032851993396718

Epoch: 5| Step: 8
Training loss: 2.169597864151001
Validation loss: 2.049120936342465

Epoch: 5| Step: 9
Training loss: 1.5617730617523193
Validation loss: 2.0361676882672053

Epoch: 5| Step: 10
Training loss: 2.3629815578460693
Validation loss: 2.004697001108559

Epoch: 148| Step: 0
Training loss: 0.7650065422058105
Validation loss: 1.9646664768136957

Epoch: 5| Step: 1
Training loss: 2.391416549682617
Validation loss: 1.9634111850492415

Epoch: 5| Step: 2
Training loss: 1.4865975379943848
Validation loss: 1.9674751181756296

Epoch: 5| Step: 3
Training loss: 1.6123958826065063
Validation loss: 1.9552849210718626

Epoch: 5| Step: 4
Training loss: 2.2406909465789795
Validation loss: 1.9465652960602955

Epoch: 5| Step: 5
Training loss: 1.4525203704833984
Validation loss: 1.9375693669883154

Epoch: 5| Step: 6
Training loss: 2.320939302444458
Validation loss: 1.9613591676117272

Epoch: 5| Step: 7
Training loss: 1.4979829788208008
Validation loss: 1.986711130347303

Epoch: 5| Step: 8
Training loss: 2.700921058654785
Validation loss: 2.0780634546792633

Epoch: 5| Step: 9
Training loss: 2.029073715209961
Validation loss: 2.142540160045829

Epoch: 5| Step: 10
Training loss: 1.6139363050460815
Validation loss: 2.1707904723382767

Epoch: 149| Step: 0
Training loss: 1.627943754196167
Validation loss: 2.1518605857767086

Epoch: 5| Step: 1
Training loss: 1.8627220392227173
Validation loss: 2.146069577945176

Epoch: 5| Step: 2
Training loss: 1.264308214187622
Validation loss: 2.0667349779477684

Epoch: 5| Step: 3
Training loss: 1.607435941696167
Validation loss: 1.9962231651429208

Epoch: 5| Step: 4
Training loss: 2.238632917404175
Validation loss: 1.9778347553745392

Epoch: 5| Step: 5
Training loss: 1.779632568359375
Validation loss: 1.9461296322525188

Epoch: 5| Step: 6
Training loss: 1.9307315349578857
Validation loss: 1.9346146942466818

Epoch: 5| Step: 7
Training loss: 1.450838327407837
Validation loss: 1.938052656829998

Epoch: 5| Step: 8
Training loss: 1.6764366626739502
Validation loss: 1.9399591415159163

Epoch: 5| Step: 9
Training loss: 1.9762077331542969
Validation loss: 1.9483704977138068

Epoch: 5| Step: 10
Training loss: 2.1819825172424316
Validation loss: 1.955682300752209

Epoch: 150| Step: 0
Training loss: 1.9110825061798096
Validation loss: 1.9686519304911296

Epoch: 5| Step: 1
Training loss: 1.8281536102294922
Validation loss: 1.9744685285834855

Epoch: 5| Step: 2
Training loss: 1.7311691045761108
Validation loss: 2.0066193355027067

Epoch: 5| Step: 3
Training loss: 1.9276254177093506
Validation loss: 2.0034527496625016

Epoch: 5| Step: 4
Training loss: 1.187192678451538
Validation loss: 2.037686961953358

Epoch: 5| Step: 5
Training loss: 2.0371243953704834
Validation loss: 2.0089004924220424

Epoch: 5| Step: 6
Training loss: 1.9039413928985596
Validation loss: 2.00419290988676

Epoch: 5| Step: 7
Training loss: 2.058490753173828
Validation loss: 1.9978947665101738

Epoch: 5| Step: 8
Training loss: 1.787462830543518
Validation loss: 1.9814973544049006

Epoch: 5| Step: 9
Training loss: 1.6279418468475342
Validation loss: 1.9790370182324482

Epoch: 5| Step: 10
Training loss: 1.0038056373596191
Validation loss: 1.9574945511356476

Epoch: 151| Step: 0
Training loss: 1.7730789184570312
Validation loss: 1.9636526594879806

Epoch: 5| Step: 1
Training loss: 2.4140172004699707
Validation loss: 1.9570313410092426

Epoch: 5| Step: 2
Training loss: 2.1236443519592285
Validation loss: 1.9580472579566381

Epoch: 5| Step: 3
Training loss: 1.7744414806365967
Validation loss: 1.967129256135674

Epoch: 5| Step: 4
Training loss: 1.5636991262435913
Validation loss: 1.982468084622455

Epoch: 5| Step: 5
Training loss: 1.3114116191864014
Validation loss: 1.9955558892219298

Epoch: 5| Step: 6
Training loss: 1.4076049327850342
Validation loss: 2.0469290184718307

Epoch: 5| Step: 7
Training loss: 1.8229329586029053
Validation loss: 2.0534455596759753

Epoch: 5| Step: 8
Training loss: 1.6856286525726318
Validation loss: 2.0829097506820515

Epoch: 5| Step: 9
Training loss: 1.184370756149292
Validation loss: 2.0231251972977833

Epoch: 5| Step: 10
Training loss: 2.046947956085205
Validation loss: 1.9949804198357366

Epoch: 152| Step: 0
Training loss: 1.3640674352645874
Validation loss: 1.9692327783953758

Epoch: 5| Step: 1
Training loss: 1.8313003778457642
Validation loss: 1.9521002000378025

Epoch: 5| Step: 2
Training loss: 1.9516245126724243
Validation loss: 1.9459441413161576

Epoch: 5| Step: 3
Training loss: 1.5762876272201538
Validation loss: 1.9500303576069493

Epoch: 5| Step: 4
Training loss: 1.9759337902069092
Validation loss: 1.9584910767052763

Epoch: 5| Step: 5
Training loss: 1.7000224590301514
Validation loss: 1.9705275002346243

Epoch: 5| Step: 6
Training loss: 1.534015417098999
Validation loss: 2.005331982848465

Epoch: 5| Step: 7
Training loss: 1.659661054611206
Validation loss: 2.0615020746825845

Epoch: 5| Step: 8
Training loss: 2.109536647796631
Validation loss: 2.136645947733233

Epoch: 5| Step: 9
Training loss: 1.7462670803070068
Validation loss: 2.1525032674112627

Epoch: 5| Step: 10
Training loss: 1.7425658702850342
Validation loss: 2.1402260129169752

Epoch: 153| Step: 0
Training loss: 1.3879343271255493
Validation loss: 2.083718094774472

Epoch: 5| Step: 1
Training loss: 2.0852925777435303
Validation loss: 2.0441150716556016

Epoch: 5| Step: 2
Training loss: 1.7893165349960327
Validation loss: 1.9734705571205384

Epoch: 5| Step: 3
Training loss: 1.6431481838226318
Validation loss: 1.9552628417168894

Epoch: 5| Step: 4
Training loss: 1.3810453414916992
Validation loss: 1.9515623008051226

Epoch: 5| Step: 5
Training loss: 1.8874499797821045
Validation loss: 1.943407012570289

Epoch: 5| Step: 6
Training loss: 2.3860104084014893
Validation loss: 1.9600285176307923

Epoch: 5| Step: 7
Training loss: 1.6287683248519897
Validation loss: 1.9776233396222513

Epoch: 5| Step: 8
Training loss: 2.3900146484375
Validation loss: 1.976327726917882

Epoch: 5| Step: 9
Training loss: 1.4295151233673096
Validation loss: 1.9574037034024474

Epoch: 5| Step: 10
Training loss: 1.6398816108703613
Validation loss: 1.965105874564058

Epoch: 154| Step: 0
Training loss: 1.7603460550308228
Validation loss: 2.0053870793311828

Epoch: 5| Step: 1
Training loss: 1.640058159828186
Validation loss: 2.087577014841059

Epoch: 5| Step: 2
Training loss: 1.848741888999939
Validation loss: 2.1303206284840903

Epoch: 5| Step: 3
Training loss: 1.55696439743042
Validation loss: 2.124430719242301

Epoch: 5| Step: 4
Training loss: 1.8359800577163696
Validation loss: 2.132797561666017

Epoch: 5| Step: 5
Training loss: 1.741753339767456
Validation loss: 2.134398857752482

Epoch: 5| Step: 6
Training loss: 1.4245444536209106
Validation loss: 2.084524808391448

Epoch: 5| Step: 7
Training loss: 2.031480073928833
Validation loss: 2.022565431492303

Epoch: 5| Step: 8
Training loss: 2.0711584091186523
Validation loss: 1.9703620108225013

Epoch: 5| Step: 9
Training loss: 1.4364420175552368
Validation loss: 1.9810673972611785

Epoch: 5| Step: 10
Training loss: 1.917518138885498
Validation loss: 1.9779766413473314

Epoch: 155| Step: 0
Training loss: 1.7401679754257202
Validation loss: 1.9797691465705953

Epoch: 5| Step: 1
Training loss: 1.4613878726959229
Validation loss: 1.9574417529567596

Epoch: 5| Step: 2
Training loss: 1.4525638818740845
Validation loss: 1.939889866818664

Epoch: 5| Step: 3
Training loss: 1.2435758113861084
Validation loss: 1.9308260025516633

Epoch: 5| Step: 4
Training loss: 1.8108527660369873
Validation loss: 1.9466891622030607

Epoch: 5| Step: 5
Training loss: 1.6115280389785767
Validation loss: 1.9686754852212884

Epoch: 5| Step: 6
Training loss: 2.1067252159118652
Validation loss: 2.014398938866072

Epoch: 5| Step: 7
Training loss: 1.773206114768982
Validation loss: 2.0659693851265857

Epoch: 5| Step: 8
Training loss: 2.0117931365966797
Validation loss: 2.1346010290166384

Epoch: 5| Step: 9
Training loss: 2.7476890087127686
Validation loss: 2.1405528258251887

Epoch: 5| Step: 10
Training loss: 1.1683094501495361
Validation loss: 2.1628193265648297

Epoch: 156| Step: 0
Training loss: 1.6381855010986328
Validation loss: 2.153960206175363

Epoch: 5| Step: 1
Training loss: 1.244890570640564
Validation loss: 2.082803844123758

Epoch: 5| Step: 2
Training loss: 2.110891103744507
Validation loss: 2.050449637956517

Epoch: 5| Step: 3
Training loss: 2.2442786693573
Validation loss: 1.9959176714702318

Epoch: 5| Step: 4
Training loss: 1.5122671127319336
Validation loss: 1.9828564069604362

Epoch: 5| Step: 5
Training loss: 0.8116340637207031
Validation loss: 1.987443406094787

Epoch: 5| Step: 6
Training loss: 1.913488745689392
Validation loss: 1.9767823321844942

Epoch: 5| Step: 7
Training loss: 1.3549854755401611
Validation loss: 1.97562446260965

Epoch: 5| Step: 8
Training loss: 1.5768734216690063
Validation loss: 1.9726699923956266

Epoch: 5| Step: 9
Training loss: 2.4381752014160156
Validation loss: 1.9789462909903577

Epoch: 5| Step: 10
Training loss: 2.5625545978546143
Validation loss: 1.9903770980014597

Epoch: 157| Step: 0
Training loss: 1.2921926975250244
Validation loss: 1.974018471215361

Epoch: 5| Step: 1
Training loss: 1.9014804363250732
Validation loss: 1.9774762020316174

Epoch: 5| Step: 2
Training loss: 2.170572519302368
Validation loss: 2.0201332569122314

Epoch: 5| Step: 3
Training loss: 1.6878368854522705
Validation loss: 2.04759306036016

Epoch: 5| Step: 4
Training loss: 1.390518069267273
Validation loss: 2.129314668716923

Epoch: 5| Step: 5
Training loss: 1.969024658203125
Validation loss: 2.1791884617138932

Epoch: 5| Step: 6
Training loss: 2.167755126953125
Validation loss: 2.133330693808935

Epoch: 5| Step: 7
Training loss: 1.6617088317871094
Validation loss: 2.1141661315835933

Epoch: 5| Step: 8
Training loss: 1.4730143547058105
Validation loss: 2.058171590169271

Epoch: 5| Step: 9
Training loss: 1.548903226852417
Validation loss: 2.0316559371127876

Epoch: 5| Step: 10
Training loss: 1.3826773166656494
Validation loss: 1.9931462759612708

Epoch: 158| Step: 0
Training loss: 1.2429977655410767
Validation loss: 1.9396735378490981

Epoch: 5| Step: 1
Training loss: 1.687298059463501
Validation loss: 1.9391096125366867

Epoch: 5| Step: 2
Training loss: 1.7402359247207642
Validation loss: 1.9348294427317958

Epoch: 5| Step: 3
Training loss: 2.2226717472076416
Validation loss: 1.9496880436456332

Epoch: 5| Step: 4
Training loss: 1.5950530767440796
Validation loss: 1.9891343437215334

Epoch: 5| Step: 5
Training loss: 1.6993353366851807
Validation loss: 2.0042689500316495

Epoch: 5| Step: 6
Training loss: 1.2474733591079712
Validation loss: 2.0158556763843825

Epoch: 5| Step: 7
Training loss: 2.1018033027648926
Validation loss: 2.0274599393208823

Epoch: 5| Step: 8
Training loss: 1.9878056049346924
Validation loss: 2.0401634708527596

Epoch: 5| Step: 9
Training loss: 1.2768990993499756
Validation loss: 1.9627380755639845

Epoch: 5| Step: 10
Training loss: 1.4915270805358887
Validation loss: 1.9366184408946703

Epoch: 159| Step: 0
Training loss: 1.5777620077133179
Validation loss: 1.9324638356444657

Epoch: 5| Step: 1
Training loss: 1.401174545288086
Validation loss: 1.921126809171451

Epoch: 5| Step: 2
Training loss: 1.6322208642959595
Validation loss: 1.9319836298624675

Epoch: 5| Step: 3
Training loss: 1.569746971130371
Validation loss: 1.933625259707051

Epoch: 5| Step: 4
Training loss: 1.7780568599700928
Validation loss: 1.945865096584443

Epoch: 5| Step: 5
Training loss: 2.0726213455200195
Validation loss: 1.957422169305945

Epoch: 5| Step: 6
Training loss: 1.5333466529846191
Validation loss: 1.9835978220867854

Epoch: 5| Step: 7
Training loss: 1.4560601711273193
Validation loss: 2.0095864547196256

Epoch: 5| Step: 8
Training loss: 1.6022096872329712
Validation loss: 2.065674243434783

Epoch: 5| Step: 9
Training loss: 1.7255809307098389
Validation loss: 2.1652076808355187

Epoch: 5| Step: 10
Training loss: 2.1601643562316895
Validation loss: 2.2392352806624545

Epoch: 160| Step: 0
Training loss: 1.8191025257110596
Validation loss: 2.1757239500681558

Epoch: 5| Step: 1
Training loss: 2.0055336952209473
Validation loss: 2.071271929689633

Epoch: 5| Step: 2
Training loss: 1.4400310516357422
Validation loss: 2.0312399889833186

Epoch: 5| Step: 3
Training loss: 1.4945390224456787
Validation loss: 2.016652750712569

Epoch: 5| Step: 4
Training loss: 1.8394914865493774
Validation loss: 2.0298244081517702

Epoch: 5| Step: 5
Training loss: 1.6723289489746094
Validation loss: 2.0771495167927077

Epoch: 5| Step: 6
Training loss: 1.7533575296401978
Validation loss: 2.0371759142926944

Epoch: 5| Step: 7
Training loss: 1.9689232110977173
Validation loss: 1.9992255023730698

Epoch: 5| Step: 8
Training loss: 1.3064639568328857
Validation loss: 1.9803383478554346

Epoch: 5| Step: 9
Training loss: 1.912462830543518
Validation loss: 1.959807708699216

Epoch: 5| Step: 10
Training loss: 1.773702621459961
Validation loss: 1.9641457706369378

Epoch: 161| Step: 0
Training loss: 2.0172386169433594
Validation loss: 1.9942786808936828

Epoch: 5| Step: 1
Training loss: 2.021496534347534
Validation loss: 2.0189804415549

Epoch: 5| Step: 2
Training loss: 1.4021027088165283
Validation loss: 2.0646834424746934

Epoch: 5| Step: 3
Training loss: 1.910479187965393
Validation loss: 2.153621389019874

Epoch: 5| Step: 4
Training loss: 1.0070686340332031
Validation loss: 2.1814704018254436

Epoch: 5| Step: 5
Training loss: 1.7559322118759155
Validation loss: 2.1878960363326536

Epoch: 5| Step: 6
Training loss: 1.760723352432251
Validation loss: 2.1190227359853764

Epoch: 5| Step: 7
Training loss: 1.9856077432632446
Validation loss: 2.0114769153697516

Epoch: 5| Step: 8
Training loss: 1.552443027496338
Validation loss: 1.9655653635660808

Epoch: 5| Step: 9
Training loss: 1.8910026550292969
Validation loss: 1.9738686635930052

Epoch: 5| Step: 10
Training loss: 1.0876216888427734
Validation loss: 1.9629660716620825

Epoch: 162| Step: 0
Training loss: 1.7513980865478516
Validation loss: 1.9610572220176778

Epoch: 5| Step: 1
Training loss: 1.9275341033935547
Validation loss: 1.9589170127786615

Epoch: 5| Step: 2
Training loss: 1.4584296941757202
Validation loss: 1.950693472739189

Epoch: 5| Step: 3
Training loss: 1.5017812252044678
Validation loss: 1.9764733827242287

Epoch: 5| Step: 4
Training loss: 1.7040355205535889
Validation loss: 1.9881165822347004

Epoch: 5| Step: 5
Training loss: 2.068514347076416
Validation loss: 1.997492572312714

Epoch: 5| Step: 6
Training loss: 1.6924858093261719
Validation loss: 1.9939681099307152

Epoch: 5| Step: 7
Training loss: 0.7130392789840698
Validation loss: 2.0228039436442877

Epoch: 5| Step: 8
Training loss: 2.3726797103881836
Validation loss: 2.0576427854517454

Epoch: 5| Step: 9
Training loss: 1.3203473091125488
Validation loss: 2.1133222195409958

Epoch: 5| Step: 10
Training loss: 1.9159036874771118
Validation loss: 2.1416640243222638

Epoch: 163| Step: 0
Training loss: 1.7428785562515259
Validation loss: 2.1833157013821345

Epoch: 5| Step: 1
Training loss: 1.8786283731460571
Validation loss: 2.196787941840387

Epoch: 5| Step: 2
Training loss: 1.3244743347167969
Validation loss: 2.1849404586258756

Epoch: 5| Step: 3
Training loss: 1.8451493978500366
Validation loss: 2.1287556232944613

Epoch: 5| Step: 4
Training loss: 1.6763290166854858
Validation loss: 2.1051172697415916

Epoch: 5| Step: 5
Training loss: 1.3678648471832275
Validation loss: 2.0611801019278904

Epoch: 5| Step: 6
Training loss: 1.6286166906356812
Validation loss: 2.017631797380345

Epoch: 5| Step: 7
Training loss: 1.8231817483901978
Validation loss: 1.9780797189281834

Epoch: 5| Step: 8
Training loss: 0.8721928596496582
Validation loss: 1.9674149815754225

Epoch: 5| Step: 9
Training loss: 1.807006597518921
Validation loss: 1.9661674063692811

Epoch: 5| Step: 10
Training loss: 2.133768320083618
Validation loss: 1.9620265165964763

Epoch: 164| Step: 0
Training loss: 2.0232133865356445
Validation loss: 1.959691314287083

Epoch: 5| Step: 1
Training loss: 1.7604944705963135
Validation loss: 1.9493835280018468

Epoch: 5| Step: 2
Training loss: 1.7195942401885986
Validation loss: 1.928854896176246

Epoch: 5| Step: 3
Training loss: 1.0273041725158691
Validation loss: 1.9416433008768226

Epoch: 5| Step: 4
Training loss: 1.587712287902832
Validation loss: 1.968026848249538

Epoch: 5| Step: 5
Training loss: 1.352950096130371
Validation loss: 2.013810496176443

Epoch: 5| Step: 6
Training loss: 1.7497704029083252
Validation loss: 2.068788133641725

Epoch: 5| Step: 7
Training loss: 2.0846996307373047
Validation loss: 2.1136067631424114

Epoch: 5| Step: 8
Training loss: 1.5326569080352783
Validation loss: 2.0844457585324525

Epoch: 5| Step: 9
Training loss: 1.4700390100479126
Validation loss: 2.078996335306475

Epoch: 5| Step: 10
Training loss: 1.9039161205291748
Validation loss: 2.0406371765239264

Epoch: 165| Step: 0
Training loss: 1.6096359491348267
Validation loss: 1.9986634664638068

Epoch: 5| Step: 1
Training loss: 1.5097291469573975
Validation loss: 1.9728610361776044

Epoch: 5| Step: 2
Training loss: 1.3160886764526367
Validation loss: 1.9810462869623655

Epoch: 5| Step: 3
Training loss: 1.9834905862808228
Validation loss: 1.977818840293474

Epoch: 5| Step: 4
Training loss: 1.6344658136367798
Validation loss: 2.0002538914321573

Epoch: 5| Step: 5
Training loss: 1.2457849979400635
Validation loss: 1.9831923489929528

Epoch: 5| Step: 6
Training loss: 1.921025037765503
Validation loss: 2.001715556267769

Epoch: 5| Step: 7
Training loss: 1.7722667455673218
Validation loss: 2.038517064945672

Epoch: 5| Step: 8
Training loss: 1.6072505712509155
Validation loss: 2.078860088061261

Epoch: 5| Step: 9
Training loss: 1.4374834299087524
Validation loss: 2.069783860637296

Epoch: 5| Step: 10
Training loss: 1.182311773300171
Validation loss: 2.0571254273896575

Epoch: 166| Step: 0
Training loss: 1.9226157665252686
Validation loss: 2.0484818771321285

Epoch: 5| Step: 1
Training loss: 1.7442121505737305
Validation loss: 2.0481687938013384

Epoch: 5| Step: 2
Training loss: 1.3737939596176147
Validation loss: 2.028225255268876

Epoch: 5| Step: 3
Training loss: 1.6519393920898438
Validation loss: 2.0262766948310276

Epoch: 5| Step: 4
Training loss: 1.1441370248794556
Validation loss: 2.036270942739261

Epoch: 5| Step: 5
Training loss: 2.019355535507202
Validation loss: 2.027327529845699

Epoch: 5| Step: 6
Training loss: 1.5864224433898926
Validation loss: 2.0000672135301816

Epoch: 5| Step: 7
Training loss: 1.6696643829345703
Validation loss: 1.9658590785918697

Epoch: 5| Step: 8
Training loss: 1.6737184524536133
Validation loss: 1.9681919185064172

Epoch: 5| Step: 9
Training loss: 0.8292676210403442
Validation loss: 1.9730100631713867

Epoch: 5| Step: 10
Training loss: 1.4605779647827148
Validation loss: 1.9788082030511671

Epoch: 167| Step: 0
Training loss: 2.029735803604126
Validation loss: 1.9668628631099578

Epoch: 5| Step: 1
Training loss: 1.4822704792022705
Validation loss: 1.9772124751921623

Epoch: 5| Step: 2
Training loss: 1.6058681011199951
Validation loss: 1.9637765615217146

Epoch: 5| Step: 3
Training loss: 1.6914135217666626
Validation loss: 1.9811504912632767

Epoch: 5| Step: 4
Training loss: 1.3339186906814575
Validation loss: 1.9994364297518166

Epoch: 5| Step: 5
Training loss: 1.697048544883728
Validation loss: 2.0631508840027677

Epoch: 5| Step: 6
Training loss: 1.346941590309143
Validation loss: 2.1004045445431947

Epoch: 5| Step: 7
Training loss: 1.507033348083496
Validation loss: 2.1261833021717687

Epoch: 5| Step: 8
Training loss: 1.3468286991119385
Validation loss: 2.157136182631216

Epoch: 5| Step: 9
Training loss: 1.0875364542007446
Validation loss: 2.114121478091004

Epoch: 5| Step: 10
Training loss: 1.6943938732147217
Validation loss: 2.099127564378964

Epoch: 168| Step: 0
Training loss: 1.2798253297805786
Validation loss: 2.033180093252531

Epoch: 5| Step: 1
Training loss: 1.8699982166290283
Validation loss: 1.9731276624946184

Epoch: 5| Step: 2
Training loss: 1.820540428161621
Validation loss: 1.9901248972903016

Epoch: 5| Step: 3
Training loss: 1.727383017539978
Validation loss: 1.987481269785153

Epoch: 5| Step: 4
Training loss: 1.7428486347198486
Validation loss: 1.9992980021302418

Epoch: 5| Step: 5
Training loss: 1.690826654434204
Validation loss: 1.9754964561872586

Epoch: 5| Step: 6
Training loss: 1.5287342071533203
Validation loss: 2.0007482254376976

Epoch: 5| Step: 7
Training loss: 1.1865583658218384
Validation loss: 2.0443492551003732

Epoch: 5| Step: 8
Training loss: 1.5696923732757568
Validation loss: 2.114950628690822

Epoch: 5| Step: 9
Training loss: 1.6360666751861572
Validation loss: 2.1864744899093465

Epoch: 5| Step: 10
Training loss: 1.2558517456054688
Validation loss: 2.2225703424023044

Epoch: 169| Step: 0
Training loss: 1.3641681671142578
Validation loss: 2.228567954032652

Epoch: 5| Step: 1
Training loss: 1.7587063312530518
Validation loss: 2.2464582150982273

Epoch: 5| Step: 2
Training loss: 1.2941886186599731
Validation loss: 2.235369142665658

Epoch: 5| Step: 3
Training loss: 1.4464997053146362
Validation loss: 2.2003533071087253

Epoch: 5| Step: 4
Training loss: 1.578918695449829
Validation loss: 2.106524008576588

Epoch: 5| Step: 5
Training loss: 1.671130895614624
Validation loss: 2.0363576719837804

Epoch: 5| Step: 6
Training loss: 1.4310106039047241
Validation loss: 2.0044000379500853

Epoch: 5| Step: 7
Training loss: 1.7385272979736328
Validation loss: 2.005520728326613

Epoch: 5| Step: 8
Training loss: 2.2677700519561768
Validation loss: 2.0112361638776717

Epoch: 5| Step: 9
Training loss: 1.7160141468048096
Validation loss: 2.0056666097333355

Epoch: 5| Step: 10
Training loss: 1.8177690505981445
Validation loss: 1.986871047686505

Epoch: 170| Step: 0
Training loss: 1.502413034439087
Validation loss: 1.9647134273282942

Epoch: 5| Step: 1
Training loss: 1.5032260417938232
Validation loss: 1.948773020057268

Epoch: 5| Step: 2
Training loss: 1.605889081954956
Validation loss: 1.937613687207622

Epoch: 5| Step: 3
Training loss: 1.3109171390533447
Validation loss: 1.944333504605037

Epoch: 5| Step: 4
Training loss: 1.6173973083496094
Validation loss: 2.011710451495263

Epoch: 5| Step: 5
Training loss: 1.8036870956420898
Validation loss: 2.0893614087053525

Epoch: 5| Step: 6
Training loss: 1.313905954360962
Validation loss: 2.149725465364354

Epoch: 5| Step: 7
Training loss: 2.5716795921325684
Validation loss: 2.2254276070543515

Epoch: 5| Step: 8
Training loss: 1.6709959506988525
Validation loss: 2.2349156974464335

Epoch: 5| Step: 9
Training loss: 1.6592848300933838
Validation loss: 2.221964979684481

Epoch: 5| Step: 10
Training loss: 1.3655123710632324
Validation loss: 2.1967016945603075

Epoch: 171| Step: 0
Training loss: 1.3401148319244385
Validation loss: 2.137325385565399

Epoch: 5| Step: 1
Training loss: 1.3567415475845337
Validation loss: 2.1215713908595424

Epoch: 5| Step: 2
Training loss: 1.6278982162475586
Validation loss: 2.099642231900205

Epoch: 5| Step: 3
Training loss: 1.286656379699707
Validation loss: 2.0956698707354966

Epoch: 5| Step: 4
Training loss: 1.4878156185150146
Validation loss: 2.0320786519717147

Epoch: 5| Step: 5
Training loss: 1.770965576171875
Validation loss: 1.991222571301204

Epoch: 5| Step: 6
Training loss: 1.8061214685440063
Validation loss: 1.9699877846625544

Epoch: 5| Step: 7
Training loss: 1.53187894821167
Validation loss: 1.94793426862327

Epoch: 5| Step: 8
Training loss: 1.7105334997177124
Validation loss: 1.943279427866782

Epoch: 5| Step: 9
Training loss: 1.4722776412963867
Validation loss: 1.945852163017437

Epoch: 5| Step: 10
Training loss: 1.2367504835128784
Validation loss: 1.952021925680099

Epoch: 172| Step: 0
Training loss: 1.4929821491241455
Validation loss: 1.9448202809979838

Epoch: 5| Step: 1
Training loss: 1.5840011835098267
Validation loss: 1.978629922354093

Epoch: 5| Step: 2
Training loss: 1.2538162469863892
Validation loss: 2.031272884338133

Epoch: 5| Step: 3
Training loss: 1.4360311031341553
Validation loss: 2.089237772008424

Epoch: 5| Step: 4
Training loss: 2.296969413757324
Validation loss: 2.146449988888156

Epoch: 5| Step: 5
Training loss: 1.4091686010360718
Validation loss: 2.105795478308073

Epoch: 5| Step: 6
Training loss: 1.7477786540985107
Validation loss: 2.042894136521124

Epoch: 5| Step: 7
Training loss: 1.0855109691619873
Validation loss: 2.0099547319514777

Epoch: 5| Step: 8
Training loss: 1.613426923751831
Validation loss: 2.000357581723121

Epoch: 5| Step: 9
Training loss: 1.1573808193206787
Validation loss: 1.9878302158847931

Epoch: 5| Step: 10
Training loss: 1.6213337182998657
Validation loss: 1.9953870388769335

Epoch: 173| Step: 0
Training loss: 1.641588568687439
Validation loss: 1.989067240427899

Epoch: 5| Step: 1
Training loss: 1.4823801517486572
Validation loss: 1.9907258710553568

Epoch: 5| Step: 2
Training loss: 1.5753268003463745
Validation loss: 1.9956539856490267

Epoch: 5| Step: 3
Training loss: 1.4905002117156982
Validation loss: 2.010319757205184

Epoch: 5| Step: 4
Training loss: 1.3366483449935913
Validation loss: 2.0187068908445296

Epoch: 5| Step: 5
Training loss: 1.2997101545333862
Validation loss: 2.039275566736857

Epoch: 5| Step: 6
Training loss: 1.2806882858276367
Validation loss: 2.0251418518763717

Epoch: 5| Step: 7
Training loss: 2.0187015533447266
Validation loss: 2.044474117217525

Epoch: 5| Step: 8
Training loss: 1.4017837047576904
Validation loss: 2.083413170230004

Epoch: 5| Step: 9
Training loss: 1.2109367847442627
Validation loss: 2.0964957821753716

Epoch: 5| Step: 10
Training loss: 1.3415789604187012
Validation loss: 2.087011952554026

Epoch: 174| Step: 0
Training loss: 1.0963375568389893
Validation loss: 2.059965500267603

Epoch: 5| Step: 1
Training loss: 1.658495306968689
Validation loss: 2.067985532104328

Epoch: 5| Step: 2
Training loss: 1.641033411026001
Validation loss: 2.050960789444626

Epoch: 5| Step: 3
Training loss: 1.369877576828003
Validation loss: 2.023756560458932

Epoch: 5| Step: 4
Training loss: 1.4869989156723022
Validation loss: 1.9970158761547459

Epoch: 5| Step: 5
Training loss: 1.2814058065414429
Validation loss: 1.9928189862158991

Epoch: 5| Step: 6
Training loss: 1.4788177013397217
Validation loss: 1.9956676472899735

Epoch: 5| Step: 7
Training loss: 1.4980013370513916
Validation loss: 2.009052098438304

Epoch: 5| Step: 8
Training loss: 1.6205689907073975
Validation loss: 2.0334293637224423

Epoch: 5| Step: 9
Training loss: 1.2432153224945068
Validation loss: 2.062131145949005

Epoch: 5| Step: 10
Training loss: 1.5374213457107544
Validation loss: 2.058362748033257

Epoch: 175| Step: 0
Training loss: 1.154039740562439
Validation loss: 2.0526593962023334

Epoch: 5| Step: 1
Training loss: 2.297400712966919
Validation loss: 2.061005482109644

Epoch: 5| Step: 2
Training loss: 1.0587533712387085
Validation loss: 2.0570139013310915

Epoch: 5| Step: 3
Training loss: 1.3034355640411377
Validation loss: 2.078493893787425

Epoch: 5| Step: 4
Training loss: 1.2189069986343384
Validation loss: 2.063293392940234

Epoch: 5| Step: 5
Training loss: 1.7953506708145142
Validation loss: 2.050181827237529

Epoch: 5| Step: 6
Training loss: 1.1611335277557373
Validation loss: 2.0322027360239336

Epoch: 5| Step: 7
Training loss: 1.4161993265151978
Validation loss: 1.9807651094211045

Epoch: 5| Step: 8
Training loss: 1.0774447917938232
Validation loss: 1.963347464479426

Epoch: 5| Step: 9
Training loss: 1.2584247589111328
Validation loss: 1.9522824877051896

Epoch: 5| Step: 10
Training loss: 1.5174369812011719
Validation loss: 1.9493207777700117

Epoch: 176| Step: 0
Training loss: 1.6997931003570557
Validation loss: 1.929165929876348

Epoch: 5| Step: 1
Training loss: 1.5252442359924316
Validation loss: 1.947382806449808

Epoch: 5| Step: 2
Training loss: 1.1678779125213623
Validation loss: 1.9544674042732484

Epoch: 5| Step: 3
Training loss: 1.0563933849334717
Validation loss: 1.998233574692921

Epoch: 5| Step: 4
Training loss: 1.7947479486465454
Validation loss: 2.029435275703348

Epoch: 5| Step: 5
Training loss: 1.292791724205017
Validation loss: 2.050967102409691

Epoch: 5| Step: 6
Training loss: 1.2231146097183228
Validation loss: 2.0474639041449434

Epoch: 5| Step: 7
Training loss: 1.443520188331604
Validation loss: 2.05926856686992

Epoch: 5| Step: 8
Training loss: 1.3423031568527222
Validation loss: 2.0553894786424536

Epoch: 5| Step: 9
Training loss: 1.360315203666687
Validation loss: 2.0511229012602117

Epoch: 5| Step: 10
Training loss: 1.51178777217865
Validation loss: 2.045466415343746

Epoch: 177| Step: 0
Training loss: 1.0643525123596191
Validation loss: 2.062223437011883

Epoch: 5| Step: 1
Training loss: 1.0787689685821533
Validation loss: 2.0688233580640567

Epoch: 5| Step: 2
Training loss: 1.246246576309204
Validation loss: 2.0648159903864705

Epoch: 5| Step: 3
Training loss: 1.2673060894012451
Validation loss: 2.0248204328680552

Epoch: 5| Step: 4
Training loss: 1.8113864660263062
Validation loss: 2.0149972323448426

Epoch: 5| Step: 5
Training loss: 1.1599195003509521
Validation loss: 1.9620189794930079

Epoch: 5| Step: 6
Training loss: 1.2375376224517822
Validation loss: 1.9191651190480878

Epoch: 5| Step: 7
Training loss: 2.1567282676696777
Validation loss: 1.9388987351489324

Epoch: 5| Step: 8
Training loss: 1.2046468257904053
Validation loss: 1.922645757275243

Epoch: 5| Step: 9
Training loss: 1.19179368019104
Validation loss: 1.94943529816084

Epoch: 5| Step: 10
Training loss: 1.848313808441162
Validation loss: 1.9573875588755454

Epoch: 178| Step: 0
Training loss: 1.4657623767852783
Validation loss: 1.969198191037742

Epoch: 5| Step: 1
Training loss: 1.6304600238800049
Validation loss: 1.9925696260185652

Epoch: 5| Step: 2
Training loss: 1.330181360244751
Validation loss: 1.9906964045698925

Epoch: 5| Step: 3
Training loss: 1.0962789058685303
Validation loss: 1.9827020065758818

Epoch: 5| Step: 4
Training loss: 1.8419466018676758
Validation loss: 2.0070337505750757

Epoch: 5| Step: 5
Training loss: 1.2919219732284546
Validation loss: 1.9887366602497716

Epoch: 5| Step: 6
Training loss: 1.2188609838485718
Validation loss: 1.992678165435791

Epoch: 5| Step: 7
Training loss: 1.4662809371948242
Validation loss: 1.974091568300801

Epoch: 5| Step: 8
Training loss: 1.2613017559051514
Validation loss: 1.9987253771033338

Epoch: 5| Step: 9
Training loss: 1.0705106258392334
Validation loss: 1.9770851007071875

Epoch: 5| Step: 10
Training loss: 1.2672175168991089
Validation loss: 1.9788022630958146

Epoch: 179| Step: 0
Training loss: 1.3647067546844482
Validation loss: 1.9702180534280755

Epoch: 5| Step: 1
Training loss: 1.311293601989746
Validation loss: 2.016366874018023

Epoch: 5| Step: 2
Training loss: 1.0284335613250732
Validation loss: 2.0525086797693723

Epoch: 5| Step: 3
Training loss: 1.3423057794570923
Validation loss: 2.0525978201179096

Epoch: 5| Step: 4
Training loss: 2.02888822555542
Validation loss: 2.0478877508512108

Epoch: 5| Step: 5
Training loss: 1.25299072265625
Validation loss: 2.004393501948285

Epoch: 5| Step: 6
Training loss: 0.9700798988342285
Validation loss: 1.9665017832991898

Epoch: 5| Step: 7
Training loss: 1.6852970123291016
Validation loss: 1.9476883821589972

Epoch: 5| Step: 8
Training loss: 1.5238409042358398
Validation loss: 1.9439046459813272

Epoch: 5| Step: 9
Training loss: 0.9623183012008667
Validation loss: 1.947281188862298

Epoch: 5| Step: 10
Training loss: 1.796012043952942
Validation loss: 1.9533931427104498

Epoch: 180| Step: 0
Training loss: 0.9482558965682983
Validation loss: 1.9807486047026932

Epoch: 5| Step: 1
Training loss: 0.9860992431640625
Validation loss: 2.0283080685523247

Epoch: 5| Step: 2
Training loss: 1.4829028844833374
Validation loss: 2.040846524700042

Epoch: 5| Step: 3
Training loss: 1.2175934314727783
Validation loss: 2.0673416301768315

Epoch: 5| Step: 4
Training loss: 1.5147870779037476
Validation loss: 2.064792658693047

Epoch: 5| Step: 5
Training loss: 1.9467089176177979
Validation loss: 2.0606518945386334

Epoch: 5| Step: 6
Training loss: 0.7403402328491211
Validation loss: 2.0079882016745945

Epoch: 5| Step: 7
Training loss: 1.5637545585632324
Validation loss: 1.9713376824573805

Epoch: 5| Step: 8
Training loss: 1.5272791385650635
Validation loss: 1.9632336811352802

Epoch: 5| Step: 9
Training loss: 1.471189260482788
Validation loss: 1.976432700310984

Epoch: 5| Step: 10
Training loss: 1.4428274631500244
Validation loss: 1.9459690022212204

Epoch: 181| Step: 0
Training loss: 0.8519304394721985
Validation loss: 1.9518710272286528

Epoch: 5| Step: 1
Training loss: 1.2217339277267456
Validation loss: 1.946681978882

Epoch: 5| Step: 2
Training loss: 1.2126737833023071
Validation loss: 1.938805664739301

Epoch: 5| Step: 3
Training loss: 1.7553062438964844
Validation loss: 1.974535197340032

Epoch: 5| Step: 4
Training loss: 1.1667072772979736
Validation loss: 2.0263385080522105

Epoch: 5| Step: 5
Training loss: 1.5355451107025146
Validation loss: 2.0702363598731255

Epoch: 5| Step: 6
Training loss: 1.2473509311676025
Validation loss: 2.079641447272352

Epoch: 5| Step: 7
Training loss: 1.785627007484436
Validation loss: 2.0597391679722774

Epoch: 5| Step: 8
Training loss: 1.5599045753479004
Validation loss: 2.0259509266063733

Epoch: 5| Step: 9
Training loss: 1.2675411701202393
Validation loss: 2.002506847022682

Epoch: 5| Step: 10
Training loss: 1.2697503566741943
Validation loss: 1.9821385696370115

Epoch: 182| Step: 0
Training loss: 1.339625597000122
Validation loss: 1.9583092940750944

Epoch: 5| Step: 1
Training loss: 1.4545679092407227
Validation loss: 1.968697767103872

Epoch: 5| Step: 2
Training loss: 1.4611198902130127
Validation loss: 1.9507840551355833

Epoch: 5| Step: 3
Training loss: 1.225237488746643
Validation loss: 1.9892246236083329

Epoch: 5| Step: 4
Training loss: 1.1815588474273682
Validation loss: 2.025168493229856

Epoch: 5| Step: 5
Training loss: 1.022507667541504
Validation loss: 2.063234148486968

Epoch: 5| Step: 6
Training loss: 1.8489329814910889
Validation loss: 2.052877454347508

Epoch: 5| Step: 7
Training loss: 0.9943011999130249
Validation loss: 2.028909872936946

Epoch: 5| Step: 8
Training loss: 1.2983465194702148
Validation loss: 2.0219135002423356

Epoch: 5| Step: 9
Training loss: 1.1077722311019897
Validation loss: 2.0011729091726322

Epoch: 5| Step: 10
Training loss: 1.6052424907684326
Validation loss: 2.0071017293519873

Epoch: 183| Step: 0
Training loss: 1.276977300643921
Validation loss: 1.9926968877033522

Epoch: 5| Step: 1
Training loss: 1.0235931873321533
Validation loss: 2.0230511080834175

Epoch: 5| Step: 2
Training loss: 1.3704355955123901
Validation loss: 2.0377358441711753

Epoch: 5| Step: 3
Training loss: 1.450488805770874
Validation loss: 2.0305376001583633

Epoch: 5| Step: 4
Training loss: 1.280116081237793
Validation loss: 2.030252161846366

Epoch: 5| Step: 5
Training loss: 1.1889543533325195
Validation loss: 2.0094770718646306

Epoch: 5| Step: 6
Training loss: 1.5788015127182007
Validation loss: 2.0050562543253743

Epoch: 5| Step: 7
Training loss: 1.0242384672164917
Validation loss: 1.9888475735982258

Epoch: 5| Step: 8
Training loss: 1.2417986392974854
Validation loss: 1.9877271036947928

Epoch: 5| Step: 9
Training loss: 1.5639896392822266
Validation loss: 1.9960654153618762

Epoch: 5| Step: 10
Training loss: 1.115476131439209
Validation loss: 2.0088187956040904

Epoch: 184| Step: 0
Training loss: 1.6298017501831055
Validation loss: 2.0135983305592693

Epoch: 5| Step: 1
Training loss: 1.335876703262329
Validation loss: 2.0509390266992713

Epoch: 5| Step: 2
Training loss: 1.1842294931411743
Validation loss: 2.0414763035312777

Epoch: 5| Step: 3
Training loss: 1.0561630725860596
Validation loss: 2.0362826162768948

Epoch: 5| Step: 4
Training loss: 1.6964458227157593
Validation loss: 1.9954308207317064

Epoch: 5| Step: 5
Training loss: 1.4726388454437256
Validation loss: 1.9633129527491908

Epoch: 5| Step: 6
Training loss: 1.4431613683700562
Validation loss: 1.9616923011759275

Epoch: 5| Step: 7
Training loss: 1.1171752214431763
Validation loss: 1.9297119686680455

Epoch: 5| Step: 8
Training loss: 1.495125412940979
Validation loss: 1.948725615778277

Epoch: 5| Step: 9
Training loss: 0.9100677371025085
Validation loss: 1.973550231226029

Epoch: 5| Step: 10
Training loss: 0.7718966603279114
Validation loss: 2.0426622257437757

Epoch: 185| Step: 0
Training loss: 1.347774863243103
Validation loss: 2.0871716750565397

Epoch: 5| Step: 1
Training loss: 1.2389121055603027
Validation loss: 2.0717252018631145

Epoch: 5| Step: 2
Training loss: 0.9185230135917664
Validation loss: 2.0683557577030633

Epoch: 5| Step: 3
Training loss: 1.6094951629638672
Validation loss: 2.0318195999309583

Epoch: 5| Step: 4
Training loss: 1.4932653903961182
Validation loss: 1.9709452057397494

Epoch: 5| Step: 5
Training loss: 1.6893150806427002
Validation loss: 1.9472538771167878

Epoch: 5| Step: 6
Training loss: 1.0672141313552856
Validation loss: 1.939952144058802

Epoch: 5| Step: 7
Training loss: 1.2365529537200928
Validation loss: 1.9375301843048425

Epoch: 5| Step: 8
Training loss: 1.0337475538253784
Validation loss: 1.9255036231010192

Epoch: 5| Step: 9
Training loss: 1.0627050399780273
Validation loss: 1.9508868289250199

Epoch: 5| Step: 10
Training loss: 1.334138035774231
Validation loss: 1.9873136538331226

Epoch: 186| Step: 0
Training loss: 1.1257377862930298
Validation loss: 1.987429331707698

Epoch: 5| Step: 1
Training loss: 1.2234899997711182
Validation loss: 1.9625660578409831

Epoch: 5| Step: 2
Training loss: 1.245836853981018
Validation loss: 1.9484332505092825

Epoch: 5| Step: 3
Training loss: 0.8587452173233032
Validation loss: 1.939815886559025

Epoch: 5| Step: 4
Training loss: 1.1845777034759521
Validation loss: 1.9198417612301406

Epoch: 5| Step: 5
Training loss: 1.0626366138458252
Validation loss: 1.945645897619186

Epoch: 5| Step: 6
Training loss: 1.5867383480072021
Validation loss: 1.9504994320613083

Epoch: 5| Step: 7
Training loss: 1.2128263711929321
Validation loss: 1.9637671414241995

Epoch: 5| Step: 8
Training loss: 1.28147554397583
Validation loss: 1.9789980483311478

Epoch: 5| Step: 9
Training loss: 1.2032577991485596
Validation loss: 1.9536419286522815

Epoch: 5| Step: 10
Training loss: 1.6703037023544312
Validation loss: 1.9383466551380772

Epoch: 187| Step: 0
Training loss: 1.3111727237701416
Validation loss: 1.9702835570099533

Epoch: 5| Step: 1
Training loss: 1.3923479318618774
Validation loss: 1.9949711753476052

Epoch: 5| Step: 2
Training loss: 0.6911093592643738
Validation loss: 2.0271130043973207

Epoch: 5| Step: 3
Training loss: 1.160219430923462
Validation loss: 2.01899133190032

Epoch: 5| Step: 4
Training loss: 1.2022345066070557
Validation loss: 2.0319499136299215

Epoch: 5| Step: 5
Training loss: 0.7247794270515442
Validation loss: 2.050974166521462

Epoch: 5| Step: 6
Training loss: 1.0173590183258057
Validation loss: 2.0699202886191745

Epoch: 5| Step: 7
Training loss: 1.551682710647583
Validation loss: 2.0772459827443606

Epoch: 5| Step: 8
Training loss: 1.5814268589019775
Validation loss: 2.084158056525774

Epoch: 5| Step: 9
Training loss: 1.4974377155303955
Validation loss: 2.022560978448519

Epoch: 5| Step: 10
Training loss: 1.3216006755828857
Validation loss: 2.0099506916538363

Epoch: 188| Step: 0
Training loss: 0.9552940130233765
Validation loss: 1.9815341708480672

Epoch: 5| Step: 1
Training loss: 1.2173455953598022
Validation loss: 1.974073899689541

Epoch: 5| Step: 2
Training loss: 1.2390614748001099
Validation loss: 1.9601885452065417

Epoch: 5| Step: 3
Training loss: 0.9930470585823059
Validation loss: 1.9791976200636996

Epoch: 5| Step: 4
Training loss: 1.7956981658935547
Validation loss: 1.9938477880211287

Epoch: 5| Step: 5
Training loss: 0.6499517560005188
Validation loss: 1.9975391831449283

Epoch: 5| Step: 6
Training loss: 0.8941386938095093
Validation loss: 1.9938754240671794

Epoch: 5| Step: 7
Training loss: 1.5068042278289795
Validation loss: 2.0093144909028084

Epoch: 5| Step: 8
Training loss: 0.8748248815536499
Validation loss: 2.038387152456468

Epoch: 5| Step: 9
Training loss: 2.002694845199585
Validation loss: 2.025097454747846

Epoch: 5| Step: 10
Training loss: 1.1477231979370117
Validation loss: 2.0400739177580802

Epoch: 189| Step: 0
Training loss: 1.5404446125030518
Validation loss: 2.012822404984505

Epoch: 5| Step: 1
Training loss: 1.1331175565719604
Validation loss: 2.002109880088478

Epoch: 5| Step: 2
Training loss: 1.1360634565353394
Validation loss: 1.96762454125189

Epoch: 5| Step: 3
Training loss: 1.0894016027450562
Validation loss: 1.9381108258360176

Epoch: 5| Step: 4
Training loss: 1.1948716640472412
Validation loss: 1.9562840871913458

Epoch: 5| Step: 5
Training loss: 0.9092556834220886
Validation loss: 1.9656659864610242

Epoch: 5| Step: 6
Training loss: 1.1478512287139893
Validation loss: 1.9837328951845887

Epoch: 5| Step: 7
Training loss: 1.5828685760498047
Validation loss: 2.0110693952088714

Epoch: 5| Step: 8
Training loss: 0.9807131886482239
Validation loss: 2.063622477234051

Epoch: 5| Step: 9
Training loss: 1.5931227207183838
Validation loss: 2.0590221292229107

Epoch: 5| Step: 10
Training loss: 1.165398120880127
Validation loss: 2.073717050654914

Epoch: 190| Step: 0
Training loss: 1.609270453453064
Validation loss: 2.051996502825009

Epoch: 5| Step: 1
Training loss: 0.7590111494064331
Validation loss: 2.0195491634389406

Epoch: 5| Step: 2
Training loss: 0.8040712475776672
Validation loss: 2.0266402536822903

Epoch: 5| Step: 3
Training loss: 1.4309170246124268
Validation loss: 2.002941755838292

Epoch: 5| Step: 4
Training loss: 1.6577755212783813
Validation loss: 2.058883423446327

Epoch: 5| Step: 5
Training loss: 1.2173436880111694
Validation loss: 2.056306921025758

Epoch: 5| Step: 6
Training loss: 1.3813399076461792
Validation loss: 2.0330276437985

Epoch: 5| Step: 7
Training loss: 1.321752905845642
Validation loss: 2.020240004344653

Epoch: 5| Step: 8
Training loss: 1.152576208114624
Validation loss: 1.9887979299791398

Epoch: 5| Step: 9
Training loss: 1.036810040473938
Validation loss: 2.019832508538359

Epoch: 5| Step: 10
Training loss: 0.8646622896194458
Validation loss: 1.9877842574991205

Epoch: 191| Step: 0
Training loss: 0.9689346551895142
Validation loss: 1.966080973225255

Epoch: 5| Step: 1
Training loss: 1.2651288509368896
Validation loss: 1.9813556453233123

Epoch: 5| Step: 2
Training loss: 0.8734664916992188
Validation loss: 1.9987675964191396

Epoch: 5| Step: 3
Training loss: 0.9608357548713684
Validation loss: 2.0012060301278227

Epoch: 5| Step: 4
Training loss: 1.0310518741607666
Validation loss: 2.0174102501202653

Epoch: 5| Step: 5
Training loss: 1.5859012603759766
Validation loss: 2.0192679871794996

Epoch: 5| Step: 6
Training loss: 1.5525901317596436
Validation loss: 1.9884703005513837

Epoch: 5| Step: 7
Training loss: 1.0616204738616943
Validation loss: 2.020232069876886

Epoch: 5| Step: 8
Training loss: 0.9088144302368164
Validation loss: 2.0320579467281217

Epoch: 5| Step: 9
Training loss: 1.4412868022918701
Validation loss: 2.0670352084662325

Epoch: 5| Step: 10
Training loss: 1.145581841468811
Validation loss: 2.0797834883454027

Epoch: 192| Step: 0
Training loss: 1.2695424556732178
Validation loss: 2.079767765537385

Epoch: 5| Step: 1
Training loss: 1.037118673324585
Validation loss: 2.0636401163634432

Epoch: 5| Step: 2
Training loss: 1.0957928895950317
Validation loss: 2.057290784774288

Epoch: 5| Step: 3
Training loss: 1.1909445524215698
Validation loss: 2.034843574288071

Epoch: 5| Step: 4
Training loss: 1.456580400466919
Validation loss: 1.9735381885241436

Epoch: 5| Step: 5
Training loss: 1.0768799781799316
Validation loss: 1.9343036400374545

Epoch: 5| Step: 6
Training loss: 1.0879828929901123
Validation loss: 1.9464174765412525

Epoch: 5| Step: 7
Training loss: 1.126747488975525
Validation loss: 1.955056264836301

Epoch: 5| Step: 8
Training loss: 1.547580361366272
Validation loss: 1.9898800747368925

Epoch: 5| Step: 9
Training loss: 1.1427562236785889
Validation loss: 2.000759983575472

Epoch: 5| Step: 10
Training loss: 1.050859808921814
Validation loss: 1.9909575370050245

Epoch: 193| Step: 0
Training loss: 1.5007665157318115
Validation loss: 1.96398837079284

Epoch: 5| Step: 1
Training loss: 0.8279373049736023
Validation loss: 1.987610032481532

Epoch: 5| Step: 2
Training loss: 1.3427751064300537
Validation loss: 2.0041474514110114

Epoch: 5| Step: 3
Training loss: 1.5001366138458252
Validation loss: 2.025537201153335

Epoch: 5| Step: 4
Training loss: 0.8662618398666382
Validation loss: 2.0333970233958256

Epoch: 5| Step: 5
Training loss: 1.4710767269134521
Validation loss: 2.034711721122906

Epoch: 5| Step: 6
Training loss: 1.3358341455459595
Validation loss: 2.0260176299720682

Epoch: 5| Step: 7
Training loss: 1.1626793146133423
Validation loss: 1.9796074757011988

Epoch: 5| Step: 8
Training loss: 0.8828352093696594
Validation loss: 1.9700528729346491

Epoch: 5| Step: 9
Training loss: 1.2582401037216187
Validation loss: 1.9426269941432501

Epoch: 5| Step: 10
Training loss: 0.8087820410728455
Validation loss: 1.9318865242824759

Epoch: 194| Step: 0
Training loss: 1.848335862159729
Validation loss: 1.9197023184068742

Epoch: 5| Step: 1
Training loss: 1.4586124420166016
Validation loss: 1.9372694466703682

Epoch: 5| Step: 2
Training loss: 0.856718897819519
Validation loss: 1.9425801231015114

Epoch: 5| Step: 3
Training loss: 0.7399917840957642
Validation loss: 1.9587474535870295

Epoch: 5| Step: 4
Training loss: 1.5275853872299194
Validation loss: 1.9780490731680265

Epoch: 5| Step: 5
Training loss: 0.8951562643051147
Validation loss: 1.9924120005740915

Epoch: 5| Step: 6
Training loss: 1.0450046062469482
Validation loss: 2.003780382935719

Epoch: 5| Step: 7
Training loss: 1.0740253925323486
Validation loss: 2.025320779892706

Epoch: 5| Step: 8
Training loss: 1.0733392238616943
Validation loss: 2.015120701123309

Epoch: 5| Step: 9
Training loss: 1.078234076499939
Validation loss: 2.013459567100771

Epoch: 5| Step: 10
Training loss: 0.8315110206604004
Validation loss: 2.0048007298541326

Epoch: 195| Step: 0
Training loss: 0.820531964302063
Validation loss: 1.98544938846301

Epoch: 5| Step: 1
Training loss: 1.2596619129180908
Validation loss: 1.9951351534935735

Epoch: 5| Step: 2
Training loss: 1.192155122756958
Validation loss: 1.951354803577546

Epoch: 5| Step: 3
Training loss: 1.4144541025161743
Validation loss: 1.9377491884334113

Epoch: 5| Step: 4
Training loss: 1.0444133281707764
Validation loss: 1.9395785011270994

Epoch: 5| Step: 5
Training loss: 1.2822433710098267
Validation loss: 1.94671211319585

Epoch: 5| Step: 6
Training loss: 1.0065208673477173
Validation loss: 1.9832344952450003

Epoch: 5| Step: 7
Training loss: 0.8549812436103821
Validation loss: 2.0098104297473864

Epoch: 5| Step: 8
Training loss: 1.0370086431503296
Validation loss: 2.079750580172385

Epoch: 5| Step: 9
Training loss: 1.1185078620910645
Validation loss: 2.0048519654940535

Epoch: 5| Step: 10
Training loss: 1.5953096151351929
Validation loss: 1.9565135150827386

Epoch: 196| Step: 0
Training loss: 1.062562346458435
Validation loss: 1.9019068492356168

Epoch: 5| Step: 1
Training loss: 0.7522215843200684
Validation loss: 1.8564688967120262

Epoch: 5| Step: 2
Training loss: 0.899819016456604
Validation loss: 1.867970879359912

Epoch: 5| Step: 3
Training loss: 1.1012924909591675
Validation loss: 1.8668895908581313

Epoch: 5| Step: 4
Training loss: 1.702040433883667
Validation loss: 1.8870345969353952

Epoch: 5| Step: 5
Training loss: 1.2416956424713135
Validation loss: 1.9285811711383123

Epoch: 5| Step: 6
Training loss: 1.071008563041687
Validation loss: 2.0570938523097704

Epoch: 5| Step: 7
Training loss: 1.2550902366638184
Validation loss: 2.119018695687735

Epoch: 5| Step: 8
Training loss: 1.657679557800293
Validation loss: 2.1448150552729124

Epoch: 5| Step: 9
Training loss: 1.0706450939178467
Validation loss: 2.0830942353894635

Epoch: 5| Step: 10
Training loss: 0.8789488077163696
Validation loss: 2.0666055499866443

Epoch: 197| Step: 0
Training loss: 1.3523906469345093
Validation loss: 2.021689978978967

Epoch: 5| Step: 1
Training loss: 1.36640202999115
Validation loss: 1.9880516131718953

Epoch: 5| Step: 2
Training loss: 1.2159156799316406
Validation loss: 1.9391284706772014

Epoch: 5| Step: 3
Training loss: 1.3731274604797363
Validation loss: 1.9140026197638562

Epoch: 5| Step: 4
Training loss: 1.0315154790878296
Validation loss: 1.888014979259942

Epoch: 5| Step: 5
Training loss: 1.2678903341293335
Validation loss: 1.9114775888381466

Epoch: 5| Step: 6
Training loss: 0.8235797882080078
Validation loss: 1.904531555791055

Epoch: 5| Step: 7
Training loss: 0.6002191305160522
Validation loss: 1.9656778996990574

Epoch: 5| Step: 8
Training loss: 1.003553867340088
Validation loss: 2.025630251053841

Epoch: 5| Step: 9
Training loss: 1.2769343852996826
Validation loss: 2.0541513607066166

Epoch: 5| Step: 10
Training loss: 1.6028766632080078
Validation loss: 2.07976209732794

Epoch: 198| Step: 0
Training loss: 0.7505396604537964
Validation loss: 2.1075256152819564

Epoch: 5| Step: 1
Training loss: 0.8423269987106323
Validation loss: 2.082307523296725

Epoch: 5| Step: 2
Training loss: 1.2323707342147827
Validation loss: 2.056382312569567

Epoch: 5| Step: 3
Training loss: 1.360923171043396
Validation loss: 1.9953083761276738

Epoch: 5| Step: 4
Training loss: 1.6035587787628174
Validation loss: 1.9713070700245519

Epoch: 5| Step: 5
Training loss: 1.0773634910583496
Validation loss: 1.954525468170002

Epoch: 5| Step: 6
Training loss: 0.8164671063423157
Validation loss: 1.9291070456145911

Epoch: 5| Step: 7
Training loss: 1.1598669290542603
Validation loss: 1.8848828551589802

Epoch: 5| Step: 8
Training loss: 0.8083246350288391
Validation loss: 1.9476816090204383

Epoch: 5| Step: 9
Training loss: 1.4160178899765015
Validation loss: 1.9698686522822226

Epoch: 5| Step: 10
Training loss: 1.4960684776306152
Validation loss: 2.0127664073821037

Epoch: 199| Step: 0
Training loss: 1.3530950546264648
Validation loss: 2.0702223418861307

Epoch: 5| Step: 1
Training loss: 1.3982079029083252
Validation loss: 2.082483603108314

Epoch: 5| Step: 2
Training loss: 0.9500654935836792
Validation loss: 2.0434142927969656

Epoch: 5| Step: 3
Training loss: 0.8686483502388
Validation loss: 1.9926844617371917

Epoch: 5| Step: 4
Training loss: 1.2100387811660767
Validation loss: 1.9530151967079408

Epoch: 5| Step: 5
Training loss: 1.1254823207855225
Validation loss: 1.9316888957895257

Epoch: 5| Step: 6
Training loss: 0.7777578234672546
Validation loss: 1.9290565957305252

Epoch: 5| Step: 7
Training loss: 1.1411077976226807
Validation loss: 1.948535091133528

Epoch: 5| Step: 8
Training loss: 1.6288230419158936
Validation loss: 1.9637952748165335

Epoch: 5| Step: 9
Training loss: 0.7486283183097839
Validation loss: 1.9972703097968973

Epoch: 5| Step: 10
Training loss: 1.2608447074890137
Validation loss: 2.01184477216454

Epoch: 200| Step: 0
Training loss: 0.3049982190132141
Validation loss: 2.0907697293066208

Epoch: 5| Step: 1
Training loss: 1.1254866123199463
Validation loss: 2.1064320277142268

Epoch: 5| Step: 2
Training loss: 1.2767165899276733
Validation loss: 2.095716744340876

Epoch: 5| Step: 3
Training loss: 1.6037929058074951
Validation loss: 2.0767540675337597

Epoch: 5| Step: 4
Training loss: 0.8389619588851929
Validation loss: 2.0162978556848343

Epoch: 5| Step: 5
Training loss: 1.0736534595489502
Validation loss: 1.9709059269197526

Epoch: 5| Step: 6
Training loss: 1.5558063983917236
Validation loss: 1.957903406953299

Epoch: 5| Step: 7
Training loss: 1.2543830871582031
Validation loss: 1.9321818826019124

Epoch: 5| Step: 8
Training loss: 1.0338401794433594
Validation loss: 1.9267624937078005

Epoch: 5| Step: 9
Training loss: 0.8969966769218445
Validation loss: 1.9335849067216277

Epoch: 5| Step: 10
Training loss: 0.9510412812232971
Validation loss: 1.9201408714376471

Epoch: 201| Step: 0
Training loss: 0.816641628742218
Validation loss: 1.9230061500303206

Epoch: 5| Step: 1
Training loss: 0.7339159846305847
Validation loss: 1.9615713986017371

Epoch: 5| Step: 2
Training loss: 0.5579267740249634
Validation loss: 1.985234704068912

Epoch: 5| Step: 3
Training loss: 1.2229225635528564
Validation loss: 2.0135434109677552

Epoch: 5| Step: 4
Training loss: 1.4055687189102173
Validation loss: 2.0283705778019403

Epoch: 5| Step: 5
Training loss: 1.141723871231079
Validation loss: 2.000975376816206

Epoch: 5| Step: 6
Training loss: 1.0839762687683105
Validation loss: 1.9664768993213613

Epoch: 5| Step: 7
Training loss: 0.6461368799209595
Validation loss: 1.9317250431224864

Epoch: 5| Step: 8
Training loss: 1.2921804189682007
Validation loss: 1.9189908709577335

Epoch: 5| Step: 9
Training loss: 1.4061622619628906
Validation loss: 1.932843477495255

Epoch: 5| Step: 10
Training loss: 1.9276944398880005
Validation loss: 1.973801484671972

Epoch: 202| Step: 0
Training loss: 1.0031001567840576
Validation loss: 1.9825190856892576

Epoch: 5| Step: 1
Training loss: 1.0112916231155396
Validation loss: 2.014013595478509

Epoch: 5| Step: 2
Training loss: 0.9142748117446899
Validation loss: 2.0521632445755826

Epoch: 5| Step: 3
Training loss: 1.3029695749282837
Validation loss: 2.0129507023801088

Epoch: 5| Step: 4
Training loss: 0.9829392433166504
Validation loss: 2.0027723209832304

Epoch: 5| Step: 5
Training loss: 1.1387226581573486
Validation loss: 1.9739384446092831

Epoch: 5| Step: 6
Training loss: 0.9416211843490601
Validation loss: 1.9412532698723577

Epoch: 5| Step: 7
Training loss: 1.1973497867584229
Validation loss: 1.906885354749618

Epoch: 5| Step: 8
Training loss: 0.5880590677261353
Validation loss: 1.8942020041968233

Epoch: 5| Step: 9
Training loss: 1.2395535707473755
Validation loss: 1.8892677868566206

Epoch: 5| Step: 10
Training loss: 1.6673274040222168
Validation loss: 1.8797801925290016

Epoch: 203| Step: 0
Training loss: 0.9099022150039673
Validation loss: 1.9006493142856065

Epoch: 5| Step: 1
Training loss: 0.9681714773178101
Validation loss: 1.9725470312180058

Epoch: 5| Step: 2
Training loss: 1.1745011806488037
Validation loss: 1.9688263823909145

Epoch: 5| Step: 3
Training loss: 0.7446531057357788
Validation loss: 2.0043507622134302

Epoch: 5| Step: 4
Training loss: 1.175278663635254
Validation loss: 1.9938099691944737

Epoch: 5| Step: 5
Training loss: 1.2938209772109985
Validation loss: 1.9926740854017195

Epoch: 5| Step: 6
Training loss: 0.9664870500564575
Validation loss: 1.9389574912286573

Epoch: 5| Step: 7
Training loss: 1.0538079738616943
Validation loss: 1.8823742340969782

Epoch: 5| Step: 8
Training loss: 1.3110816478729248
Validation loss: 1.8776476562664073

Epoch: 5| Step: 9
Training loss: 1.389404535293579
Validation loss: 1.8624754105844805

Epoch: 5| Step: 10
Training loss: 0.9253633618354797
Validation loss: 1.8741973202715638

Epoch: 204| Step: 0
Training loss: 1.7042186260223389
Validation loss: 1.8655326571515811

Epoch: 5| Step: 1
Training loss: 1.4287543296813965
Validation loss: 1.8629358891517884

Epoch: 5| Step: 2
Training loss: 0.9723829030990601
Validation loss: 1.9013655877882434

Epoch: 5| Step: 3
Training loss: 0.8752714395523071
Validation loss: 1.9793148104862501

Epoch: 5| Step: 4
Training loss: 0.8002298474311829
Validation loss: 2.0698497154379405

Epoch: 5| Step: 5
Training loss: 1.0200308561325073
Validation loss: 2.06436925806025

Epoch: 5| Step: 6
Training loss: 1.03220534324646
Validation loss: 2.0369370598946848

Epoch: 5| Step: 7
Training loss: 0.7571206092834473
Validation loss: 2.0168452006514355

Epoch: 5| Step: 8
Training loss: 1.287424087524414
Validation loss: 1.9830940372200423

Epoch: 5| Step: 9
Training loss: 0.9209215044975281
Validation loss: 1.9613607980871712

Epoch: 5| Step: 10
Training loss: 1.3266191482543945
Validation loss: 1.9223758366800123

Epoch: 205| Step: 0
Training loss: 0.9332988858222961
Validation loss: 1.9076339378151843

Epoch: 5| Step: 1
Training loss: 1.1834304332733154
Validation loss: 1.848196268081665

Epoch: 5| Step: 2
Training loss: 1.2008854150772095
Validation loss: 1.8327107198776738

Epoch: 5| Step: 3
Training loss: 0.7238897085189819
Validation loss: 1.8735595441633655

Epoch: 5| Step: 4
Training loss: 1.076973795890808
Validation loss: 1.9064559910887031

Epoch: 5| Step: 5
Training loss: 0.9837910532951355
Validation loss: 1.9368197494937527

Epoch: 5| Step: 6
Training loss: 0.6653035879135132
Validation loss: 1.9709007099110594

Epoch: 5| Step: 7
Training loss: 0.7676843404769897
Validation loss: 2.0231887986583095

Epoch: 5| Step: 8
Training loss: 1.6984180212020874
Validation loss: 2.0607138423509497

Epoch: 5| Step: 9
Training loss: 1.0851606130599976
Validation loss: 2.0552607890098327

Epoch: 5| Step: 10
Training loss: 1.1642041206359863
Validation loss: 2.0497126258829588

Epoch: 206| Step: 0
Training loss: 1.2568010091781616
Validation loss: 1.9965522596913

Epoch: 5| Step: 1
Training loss: 1.223702073097229
Validation loss: 1.9546628652080413

Epoch: 5| Step: 2
Training loss: 1.1786466836929321
Validation loss: 1.9469069665478123

Epoch: 5| Step: 3
Training loss: 1.0292279720306396
Validation loss: 1.9289959246112454

Epoch: 5| Step: 4
Training loss: 0.7686358690261841
Validation loss: 1.9235497777180006

Epoch: 5| Step: 5
Training loss: 0.9336767196655273
Validation loss: 1.9293242757038405

Epoch: 5| Step: 6
Training loss: 1.19498610496521
Validation loss: 1.9417465656034407

Epoch: 5| Step: 7
Training loss: 0.6239972114562988
Validation loss: 1.9631061784682735

Epoch: 5| Step: 8
Training loss: 1.210679292678833
Validation loss: 1.9785825308933054

Epoch: 5| Step: 9
Training loss: 0.7609672546386719
Validation loss: 1.9678092746324436

Epoch: 5| Step: 10
Training loss: 0.8598343133926392
Validation loss: 1.976520840839673

Epoch: 207| Step: 0
Training loss: 1.2086076736450195
Validation loss: 1.9515249242064774

Epoch: 5| Step: 1
Training loss: 0.7659145593643188
Validation loss: 1.9365142583847046

Epoch: 5| Step: 2
Training loss: 0.5487954020500183
Validation loss: 1.9346978254215692

Epoch: 5| Step: 3
Training loss: 0.9683843851089478
Validation loss: 1.9551746460699266

Epoch: 5| Step: 4
Training loss: 0.9622767567634583
Validation loss: 1.9841625434096142

Epoch: 5| Step: 5
Training loss: 0.9728089570999146
Validation loss: 1.953217831991052

Epoch: 5| Step: 6
Training loss: 1.1840091943740845
Validation loss: 1.9536953728686097

Epoch: 5| Step: 7
Training loss: 0.7318608164787292
Validation loss: 1.939681363362138

Epoch: 5| Step: 8
Training loss: 1.1012073755264282
Validation loss: 1.9155219293409778

Epoch: 5| Step: 9
Training loss: 1.210166573524475
Validation loss: 1.9292014683446577

Epoch: 5| Step: 10
Training loss: 0.8534374833106995
Validation loss: 1.9169823533745223

Epoch: 208| Step: 0
Training loss: 0.9301856160163879
Validation loss: 1.9043219012598838

Epoch: 5| Step: 1
Training loss: 1.604404091835022
Validation loss: 1.9088781520884524

Epoch: 5| Step: 2
Training loss: 1.326523780822754
Validation loss: 1.8944290273933

Epoch: 5| Step: 3
Training loss: 1.033234715461731
Validation loss: 1.9199296582129695

Epoch: 5| Step: 4
Training loss: 0.876024067401886
Validation loss: 1.964645185778218

Epoch: 5| Step: 5
Training loss: 0.7487780451774597
Validation loss: 1.9877374069665068

Epoch: 5| Step: 6
Training loss: 0.5413678884506226
Validation loss: 2.0116865211917507

Epoch: 5| Step: 7
Training loss: 0.5732582807540894
Validation loss: 2.038134841508763

Epoch: 5| Step: 8
Training loss: 1.113949179649353
Validation loss: 2.044587835188835

Epoch: 5| Step: 9
Training loss: 1.0392378568649292
Validation loss: 2.0164811175356627

Epoch: 5| Step: 10
Training loss: 0.8751492500305176
Validation loss: 2.0269499812074887

Epoch: 209| Step: 0
Training loss: 0.9059883952140808
Validation loss: 1.987511227207799

Epoch: 5| Step: 1
Training loss: 1.0272424221038818
Validation loss: 1.9749887579230851

Epoch: 5| Step: 2
Training loss: 1.0607154369354248
Validation loss: 1.9315605727575158

Epoch: 5| Step: 3
Training loss: 0.7843963503837585
Validation loss: 1.9125448888347996

Epoch: 5| Step: 4
Training loss: 0.9003057479858398
Validation loss: 1.9263166073829896

Epoch: 5| Step: 5
Training loss: 0.8578212857246399
Validation loss: 1.9140947531628352

Epoch: 5| Step: 6
Training loss: 1.1069732904434204
Validation loss: 1.9463433642541208

Epoch: 5| Step: 7
Training loss: 0.651214599609375
Validation loss: 2.0072741008573964

Epoch: 5| Step: 8
Training loss: 1.0199798345565796
Validation loss: 2.0188404206306703

Epoch: 5| Step: 9
Training loss: 1.250031590461731
Validation loss: 2.030913588821247

Epoch: 5| Step: 10
Training loss: 0.8783323764801025
Validation loss: 2.0063477716138287

Epoch: 210| Step: 0
Training loss: 0.7497478723526001
Validation loss: 1.9881143185400194

Epoch: 5| Step: 1
Training loss: 1.2133362293243408
Validation loss: 1.9589677677359632

Epoch: 5| Step: 2
Training loss: 0.9383672475814819
Validation loss: 1.9303083932527931

Epoch: 5| Step: 3
Training loss: 0.8091846704483032
Validation loss: 1.9276781210335352

Epoch: 5| Step: 4
Training loss: 1.0511970520019531
Validation loss: 1.9109995134415165

Epoch: 5| Step: 5
Training loss: 0.48810404539108276
Validation loss: 1.873373418725947

Epoch: 5| Step: 6
Training loss: 1.0565720796585083
Validation loss: 1.8522670884286203

Epoch: 5| Step: 7
Training loss: 0.6778820157051086
Validation loss: 1.881242923839118

Epoch: 5| Step: 8
Training loss: 1.1409246921539307
Validation loss: 1.908300733053556

Epoch: 5| Step: 9
Training loss: 1.1122974157333374
Validation loss: 1.96184237798055

Epoch: 5| Step: 10
Training loss: 1.2885700464248657
Validation loss: 2.0156093861467097

Epoch: 211| Step: 0
Training loss: 1.493072271347046
Validation loss: 1.9919214594748713

Epoch: 5| Step: 1
Training loss: 0.8005366325378418
Validation loss: 1.9883288465520388

Epoch: 5| Step: 2
Training loss: 0.9054039716720581
Validation loss: 1.9161502597152547

Epoch: 5| Step: 3
Training loss: 0.30750054121017456
Validation loss: 1.8857818649661156

Epoch: 5| Step: 4
Training loss: 1.091717004776001
Validation loss: 1.8603254851474558

Epoch: 5| Step: 5
Training loss: 0.875754177570343
Validation loss: 1.8297928097427532

Epoch: 5| Step: 6
Training loss: 1.4013433456420898
Validation loss: 1.8603878200695079

Epoch: 5| Step: 7
Training loss: 0.6793950796127319
Validation loss: 1.878828243542743

Epoch: 5| Step: 8
Training loss: 1.0650495290756226
Validation loss: 1.8992019135464904

Epoch: 5| Step: 9
Training loss: 0.8288754224777222
Validation loss: 1.9314667281284128

Epoch: 5| Step: 10
Training loss: 1.079052448272705
Validation loss: 1.9719968457375803

Epoch: 212| Step: 0
Training loss: 0.9178912043571472
Validation loss: 1.9762150856756395

Epoch: 5| Step: 1
Training loss: 0.8799527883529663
Validation loss: 1.99695175181153

Epoch: 5| Step: 2
Training loss: 0.9477757215499878
Validation loss: 1.988656308061333

Epoch: 5| Step: 3
Training loss: 1.431183099746704
Validation loss: 2.0037490783199186

Epoch: 5| Step: 4
Training loss: 1.1213696002960205
Validation loss: 1.958923388552922

Epoch: 5| Step: 5
Training loss: 0.8126571774482727
Validation loss: 1.942634210791639

Epoch: 5| Step: 6
Training loss: 0.8544493913650513
Validation loss: 1.9203419505908925

Epoch: 5| Step: 7
Training loss: 0.9774767756462097
Validation loss: 1.9226457867571103

Epoch: 5| Step: 8
Training loss: 1.03751540184021
Validation loss: 1.9306601837117185

Epoch: 5| Step: 9
Training loss: 0.46257519721984863
Validation loss: 1.9262566220375799

Epoch: 5| Step: 10
Training loss: 0.634235143661499
Validation loss: 1.9123956426497428

Epoch: 213| Step: 0
Training loss: 1.3286852836608887
Validation loss: 1.9279630927629368

Epoch: 5| Step: 1
Training loss: 0.9898616075515747
Validation loss: 1.9239549457385976

Epoch: 5| Step: 2
Training loss: 0.9926902651786804
Validation loss: 1.9131733089364984

Epoch: 5| Step: 3
Training loss: 0.7033365368843079
Validation loss: 1.8870119945977324

Epoch: 5| Step: 4
Training loss: 0.8920402526855469
Validation loss: 1.883494302790652

Epoch: 5| Step: 5
Training loss: 1.3666610717773438
Validation loss: 1.89077514730474

Epoch: 5| Step: 6
Training loss: 0.605450451374054
Validation loss: 1.9094865886113976

Epoch: 5| Step: 7
Training loss: 0.9176508784294128
Validation loss: 1.9383506339083436

Epoch: 5| Step: 8
Training loss: 0.7666361927986145
Validation loss: 1.929760730394753

Epoch: 5| Step: 9
Training loss: 0.6565810441970825
Validation loss: 1.9672541900347638

Epoch: 5| Step: 10
Training loss: 0.7748154997825623
Validation loss: 1.9875699038146644

Epoch: 214| Step: 0
Training loss: 0.9614548683166504
Validation loss: 1.9955325639376076

Epoch: 5| Step: 1
Training loss: 0.9080713391304016
Validation loss: 1.9897905421513382

Epoch: 5| Step: 2
Training loss: 1.083592176437378
Validation loss: 1.9406717797761321

Epoch: 5| Step: 3
Training loss: 0.8371899724006653
Validation loss: 1.9027600160209082

Epoch: 5| Step: 4
Training loss: 1.1506410837173462
Validation loss: 1.8847077072307628

Epoch: 5| Step: 5
Training loss: 0.7432159185409546
Validation loss: 1.8779393793434225

Epoch: 5| Step: 6
Training loss: 0.8356383442878723
Validation loss: 1.8772591890827302

Epoch: 5| Step: 7
Training loss: 0.9498732686042786
Validation loss: 1.9122554576525124

Epoch: 5| Step: 8
Training loss: 0.7642310857772827
Validation loss: 1.9498128532081522

Epoch: 5| Step: 9
Training loss: 0.7202183604240417
Validation loss: 1.9651637051695137

Epoch: 5| Step: 10
Training loss: 1.1012616157531738
Validation loss: 1.9679252280983874

Epoch: 215| Step: 0
Training loss: 0.6167650818824768
Validation loss: 1.9402891230839554

Epoch: 5| Step: 1
Training loss: 0.8284309506416321
Validation loss: 1.902423156205044

Epoch: 5| Step: 2
Training loss: 1.0548770427703857
Validation loss: 1.8925932222797024

Epoch: 5| Step: 3
Training loss: 0.6525104641914368
Validation loss: 1.8466189420351418

Epoch: 5| Step: 4
Training loss: 1.0696022510528564
Validation loss: 1.8474148255522533

Epoch: 5| Step: 5
Training loss: 0.82746422290802
Validation loss: 1.8385649137599493

Epoch: 5| Step: 6
Training loss: 0.9330717921257019
Validation loss: 1.8765119480830368

Epoch: 5| Step: 7
Training loss: 1.2459626197814941
Validation loss: 1.9253623126655497

Epoch: 5| Step: 8
Training loss: 0.9276019930839539
Validation loss: 1.9759312855300082

Epoch: 5| Step: 9
Training loss: 0.8955672383308411
Validation loss: 1.9770385193568405

Epoch: 5| Step: 10
Training loss: 0.743165135383606
Validation loss: 1.959766031593405

Epoch: 216| Step: 0
Training loss: 0.7975846529006958
Validation loss: 1.940924362469745

Epoch: 5| Step: 1
Training loss: 0.7640222311019897
Validation loss: 1.917470056523559

Epoch: 5| Step: 2
Training loss: 1.3410134315490723
Validation loss: 1.9043914707758094

Epoch: 5| Step: 3
Training loss: 0.48745641112327576
Validation loss: 1.9182412726904756

Epoch: 5| Step: 4
Training loss: 1.1181341409683228
Validation loss: 1.9442049277726041

Epoch: 5| Step: 5
Training loss: 0.6850783824920654
Validation loss: 1.923967602432415

Epoch: 5| Step: 6
Training loss: 1.451416254043579
Validation loss: 1.933920568035495

Epoch: 5| Step: 7
Training loss: 0.9707509875297546
Validation loss: 1.9415155380002913

Epoch: 5| Step: 8
Training loss: 0.9741737246513367
Validation loss: 1.9345290378857685

Epoch: 5| Step: 9
Training loss: 0.8449742197990417
Validation loss: 1.922866339324623

Epoch: 5| Step: 10
Training loss: 0.47632718086242676
Validation loss: 1.8828073560550649

Epoch: 217| Step: 0
Training loss: 1.0377064943313599
Validation loss: 1.8532864227089831

Epoch: 5| Step: 1
Training loss: 1.1104406118392944
Validation loss: 1.8250344453319427

Epoch: 5| Step: 2
Training loss: 0.5247796773910522
Validation loss: 1.8300636122303624

Epoch: 5| Step: 3
Training loss: 1.3276031017303467
Validation loss: 1.8304100856986096

Epoch: 5| Step: 4
Training loss: 0.916050910949707
Validation loss: 1.83676960263201

Epoch: 5| Step: 5
Training loss: 0.6837509274482727
Validation loss: 1.8768582215873144

Epoch: 5| Step: 6
Training loss: 0.7059620022773743
Validation loss: 1.930490642465571

Epoch: 5| Step: 7
Training loss: 0.6418267488479614
Validation loss: 2.011824010520853

Epoch: 5| Step: 8
Training loss: 0.9163599014282227
Validation loss: 2.039497685688798

Epoch: 5| Step: 9
Training loss: 0.7276528477668762
Validation loss: 2.0205216074502594

Epoch: 5| Step: 10
Training loss: 1.375868797302246
Validation loss: 1.951558664280881

Epoch: 218| Step: 0
Training loss: 0.8239655494689941
Validation loss: 1.908633070607339

Epoch: 5| Step: 1
Training loss: 0.8255941271781921
Validation loss: 1.851249534596679

Epoch: 5| Step: 2
Training loss: 0.9833229184150696
Validation loss: 1.8066758750587382

Epoch: 5| Step: 3
Training loss: 0.733493983745575
Validation loss: 1.7889071279956448

Epoch: 5| Step: 4
Training loss: 0.8940068483352661
Validation loss: 1.7894139123219315

Epoch: 5| Step: 5
Training loss: 1.116718053817749
Validation loss: 1.7828272696464293

Epoch: 5| Step: 6
Training loss: 1.144021987915039
Validation loss: 1.8028818868821668

Epoch: 5| Step: 7
Training loss: 0.7911561727523804
Validation loss: 1.8667169219704085

Epoch: 5| Step: 8
Training loss: 0.7712504267692566
Validation loss: 1.890082093977159

Epoch: 5| Step: 9
Training loss: 0.9436553120613098
Validation loss: 1.9180155108051915

Epoch: 5| Step: 10
Training loss: 0.7780693173408508
Validation loss: 1.9594011857945433

Epoch: 219| Step: 0
Training loss: 0.9514528512954712
Validation loss: 1.9610677816534554

Epoch: 5| Step: 1
Training loss: 1.0487841367721558
Validation loss: 1.9764708139563119

Epoch: 5| Step: 2
Training loss: 1.1018733978271484
Validation loss: 1.92996201720289

Epoch: 5| Step: 3
Training loss: 0.5905140042304993
Validation loss: 1.922786255036631

Epoch: 5| Step: 4
Training loss: 0.5457863211631775
Validation loss: 1.8773314760577293

Epoch: 5| Step: 5
Training loss: 0.921099841594696
Validation loss: 1.883782265006855

Epoch: 5| Step: 6
Training loss: 0.7605973482131958
Validation loss: 1.878765449729017

Epoch: 5| Step: 7
Training loss: 0.8539093732833862
Validation loss: 1.9017348033125683

Epoch: 5| Step: 8
Training loss: 1.1150033473968506
Validation loss: 1.9070942991523332

Epoch: 5| Step: 9
Training loss: 1.220057725906372
Validation loss: 1.9163138789515342

Epoch: 5| Step: 10
Training loss: 0.7986600399017334
Validation loss: 1.9359612990451116

Epoch: 220| Step: 0
Training loss: 1.0457180738449097
Validation loss: 1.949160675848684

Epoch: 5| Step: 1
Training loss: 0.7589089870452881
Validation loss: 1.9316692134385467

Epoch: 5| Step: 2
Training loss: 0.9574103355407715
Validation loss: 1.9090467601694086

Epoch: 5| Step: 3
Training loss: 0.5530799031257629
Validation loss: 1.907427664726011

Epoch: 5| Step: 4
Training loss: 0.8612369298934937
Validation loss: 1.9297321278561828

Epoch: 5| Step: 5
Training loss: 1.10355544090271
Validation loss: 1.925197829482376

Epoch: 5| Step: 6
Training loss: 0.7069209814071655
Validation loss: 1.923055859022243

Epoch: 5| Step: 7
Training loss: 0.8820357322692871
Validation loss: 1.935967581246489

Epoch: 5| Step: 8
Training loss: 1.0495938062667847
Validation loss: 1.9391800254903815

Epoch: 5| Step: 9
Training loss: 0.9766607284545898
Validation loss: 1.9417380056073588

Epoch: 5| Step: 10
Training loss: 0.8304104208946228
Validation loss: 1.9183972163866925

Epoch: 221| Step: 0
Training loss: 0.9298244714736938
Validation loss: 1.8698887145647438

Epoch: 5| Step: 1
Training loss: 0.8000790476799011
Validation loss: 1.8031305125964585

Epoch: 5| Step: 2
Training loss: 0.7203562259674072
Validation loss: 1.8136727374087098

Epoch: 5| Step: 3
Training loss: 1.0143308639526367
Validation loss: 1.7873276395182456

Epoch: 5| Step: 4
Training loss: 0.5790365934371948
Validation loss: 1.8369915062381375

Epoch: 5| Step: 5
Training loss: 0.6503480672836304
Validation loss: 1.8727037996374152

Epoch: 5| Step: 6
Training loss: 0.7159960865974426
Validation loss: 1.9096210515627297

Epoch: 5| Step: 7
Training loss: 1.4496115446090698
Validation loss: 1.945892709557728

Epoch: 5| Step: 8
Training loss: 0.7731666564941406
Validation loss: 1.9841298980097617

Epoch: 5| Step: 9
Training loss: 1.1971015930175781
Validation loss: 1.9913120423593829

Epoch: 5| Step: 10
Training loss: 0.5110037326812744
Validation loss: 1.9397306211533085

Epoch: 222| Step: 0
Training loss: 0.9481450319290161
Validation loss: 1.9031585903577908

Epoch: 5| Step: 1
Training loss: 0.7857335209846497
Validation loss: 1.8429850621889996

Epoch: 5| Step: 2
Training loss: 1.0481754541397095
Validation loss: 1.7861853286784182

Epoch: 5| Step: 3
Training loss: 0.6370507478713989
Validation loss: 1.8039706035326886

Epoch: 5| Step: 4
Training loss: 1.0511069297790527
Validation loss: 1.7767336060923915

Epoch: 5| Step: 5
Training loss: 0.7336130738258362
Validation loss: 1.7873363123145154

Epoch: 5| Step: 6
Training loss: 0.6582468152046204
Validation loss: 1.8638299024233254

Epoch: 5| Step: 7
Training loss: 0.786086916923523
Validation loss: 1.9127146979813934

Epoch: 5| Step: 8
Training loss: 0.8027137517929077
Validation loss: 1.9190771067014305

Epoch: 5| Step: 9
Training loss: 1.0877597332000732
Validation loss: 1.9276431901480562

Epoch: 5| Step: 10
Training loss: 0.8417620658874512
Validation loss: 1.9491481473368983

Epoch: 223| Step: 0
Training loss: 0.7557982206344604
Validation loss: 1.9085432150030648

Epoch: 5| Step: 1
Training loss: 0.7047227621078491
Validation loss: 1.905983571083315

Epoch: 5| Step: 2
Training loss: 0.6740801930427551
Validation loss: 1.8793465142608972

Epoch: 5| Step: 3
Training loss: 0.7625786662101746
Validation loss: 1.8934251313568444

Epoch: 5| Step: 4
Training loss: 1.1008825302124023
Validation loss: 1.8783563772837322

Epoch: 5| Step: 5
Training loss: 0.9509609341621399
Validation loss: 1.8539837547527847

Epoch: 5| Step: 6
Training loss: 0.7823652625083923
Validation loss: 1.8502733245972665

Epoch: 5| Step: 7
Training loss: 1.1595176458358765
Validation loss: 1.8668739103501844

Epoch: 5| Step: 8
Training loss: 0.6981185674667358
Validation loss: 1.9068935007177374

Epoch: 5| Step: 9
Training loss: 0.8046938180923462
Validation loss: 1.8968975774703487

Epoch: 5| Step: 10
Training loss: 0.7554295063018799
Validation loss: 1.9272969743256927

Epoch: 224| Step: 0
Training loss: 0.7810088992118835
Validation loss: 1.8875886073676489

Epoch: 5| Step: 1
Training loss: 0.878006100654602
Validation loss: 1.874050804363784

Epoch: 5| Step: 2
Training loss: 0.7173531651496887
Validation loss: 1.8796330177655785

Epoch: 5| Step: 3
Training loss: 0.870494544506073
Validation loss: 1.8763580732448126

Epoch: 5| Step: 4
Training loss: 1.106066107749939
Validation loss: 1.8919197949030067

Epoch: 5| Step: 5
Training loss: 0.9958589673042297
Validation loss: 1.8924239040702902

Epoch: 5| Step: 6
Training loss: 0.9862019419670105
Validation loss: 1.9055242128269647

Epoch: 5| Step: 7
Training loss: 0.9713727831840515
Validation loss: 1.949812372525533

Epoch: 5| Step: 8
Training loss: 0.5240160822868347
Validation loss: 1.9439762356460735

Epoch: 5| Step: 9
Training loss: 0.8137646913528442
Validation loss: 1.9487656290813158

Epoch: 5| Step: 10
Training loss: 0.6088536977767944
Validation loss: 1.937536537006337

Epoch: 225| Step: 0
Training loss: 0.714126706123352
Validation loss: 1.8929139439777662

Epoch: 5| Step: 1
Training loss: 0.8813990354537964
Validation loss: 1.854391603059666

Epoch: 5| Step: 2
Training loss: 0.718193531036377
Validation loss: 1.8172983546410837

Epoch: 5| Step: 3
Training loss: 0.7305191159248352
Validation loss: 1.8122293615853915

Epoch: 5| Step: 4
Training loss: 0.9320982694625854
Validation loss: 1.8304689994422338

Epoch: 5| Step: 5
Training loss: 1.0140855312347412
Validation loss: 1.8454872241584204

Epoch: 5| Step: 6
Training loss: 0.8872516751289368
Validation loss: 1.8632831176122029

Epoch: 5| Step: 7
Training loss: 0.9707795977592468
Validation loss: 1.8949155948495353

Epoch: 5| Step: 8
Training loss: 0.943676769733429
Validation loss: 1.9243147270653838

Epoch: 5| Step: 9
Training loss: 0.6027353405952454
Validation loss: 1.9989430519842333

Epoch: 5| Step: 10
Training loss: 0.891562283039093
Validation loss: 2.044319778360346

Epoch: 226| Step: 0
Training loss: 0.7682385444641113
Validation loss: 2.0594493727530203

Epoch: 5| Step: 1
Training loss: 1.1028417348861694
Validation loss: 2.0435316485743367

Epoch: 5| Step: 2
Training loss: 0.892166256904602
Validation loss: 2.0008319154862435

Epoch: 5| Step: 3
Training loss: 0.5151064991950989
Validation loss: 1.9119400683269705

Epoch: 5| Step: 4
Training loss: 0.5925577282905579
Validation loss: 1.9111725899481005

Epoch: 5| Step: 5
Training loss: 1.0572278499603271
Validation loss: 1.8443493919987832

Epoch: 5| Step: 6
Training loss: 0.7776811718940735
Validation loss: 1.8284324010213215

Epoch: 5| Step: 7
Training loss: 0.7602575421333313
Validation loss: 1.8128208011709235

Epoch: 5| Step: 8
Training loss: 1.1175638437271118
Validation loss: 1.8131582506241337

Epoch: 5| Step: 9
Training loss: 0.7485024333000183
Validation loss: 1.863981931440292

Epoch: 5| Step: 10
Training loss: 0.9270404577255249
Validation loss: 1.9082752863566081

Epoch: 227| Step: 0
Training loss: 0.9345359802246094
Validation loss: 1.9706232560578214

Epoch: 5| Step: 1
Training loss: 0.7964364886283875
Validation loss: 2.0132436701046523

Epoch: 5| Step: 2
Training loss: 0.7342623472213745
Validation loss: 2.0247878720683437

Epoch: 5| Step: 3
Training loss: 0.6391348838806152
Validation loss: 2.0049409584332536

Epoch: 5| Step: 4
Training loss: 0.6457058787345886
Validation loss: 1.9527932341380785

Epoch: 5| Step: 5
Training loss: 0.5824750661849976
Validation loss: 1.919147886255736

Epoch: 5| Step: 6
Training loss: 1.027962327003479
Validation loss: 1.8664543423601376

Epoch: 5| Step: 7
Training loss: 1.1677501201629639
Validation loss: 1.8276261039959487

Epoch: 5| Step: 8
Training loss: 0.6576455235481262
Validation loss: 1.813546642180412

Epoch: 5| Step: 9
Training loss: 1.0094822645187378
Validation loss: 1.8210883499473653

Epoch: 5| Step: 10
Training loss: 0.5504204630851746
Validation loss: 1.832176657133205

Epoch: 228| Step: 0
Training loss: 0.7087203860282898
Validation loss: 1.8847893720032067

Epoch: 5| Step: 1
Training loss: 0.6804159283638
Validation loss: 1.8954412475708993

Epoch: 5| Step: 2
Training loss: 0.7466169595718384
Validation loss: 1.9040082116280832

Epoch: 5| Step: 3
Training loss: 0.5593259334564209
Validation loss: 1.9202071441117154

Epoch: 5| Step: 4
Training loss: 0.789575457572937
Validation loss: 1.9198393872989121

Epoch: 5| Step: 5
Training loss: 0.8843221664428711
Validation loss: 1.948441449032035

Epoch: 5| Step: 6
Training loss: 0.8496924638748169
Validation loss: 1.9036088733262913

Epoch: 5| Step: 7
Training loss: 0.6373003721237183
Validation loss: 1.8948885984318231

Epoch: 5| Step: 8
Training loss: 0.9011011123657227
Validation loss: 1.8950878304819907

Epoch: 5| Step: 9
Training loss: 1.0870686769485474
Validation loss: 1.872262547093053

Epoch: 5| Step: 10
Training loss: 0.6682546734809875
Validation loss: 1.865265469397268

Epoch: 229| Step: 0
Training loss: 0.7558305859565735
Validation loss: 1.8927706595390075

Epoch: 5| Step: 1
Training loss: 1.1746482849121094
Validation loss: 1.9464464033803632

Epoch: 5| Step: 2
Training loss: 0.8476190567016602
Validation loss: 1.964392735112098

Epoch: 5| Step: 3
Training loss: 0.7789397239685059
Validation loss: 1.9804769921046432

Epoch: 5| Step: 4
Training loss: 0.6119856834411621
Validation loss: 1.966901643301851

Epoch: 5| Step: 5
Training loss: 0.989966094493866
Validation loss: 1.9487963389324885

Epoch: 5| Step: 6
Training loss: 0.6961625814437866
Validation loss: 1.935088949818765

Epoch: 5| Step: 7
Training loss: 0.6004737615585327
Validation loss: 1.883470627569383

Epoch: 5| Step: 8
Training loss: 0.8139301538467407
Validation loss: 1.881646812603038

Epoch: 5| Step: 9
Training loss: 0.5672340989112854
Validation loss: 1.864946831939041

Epoch: 5| Step: 10
Training loss: 0.710216760635376
Validation loss: 1.8592646314251808

Epoch: 230| Step: 0
Training loss: 0.5616812705993652
Validation loss: 1.8808246389512093

Epoch: 5| Step: 1
Training loss: 0.7375694513320923
Validation loss: 1.901892844066825

Epoch: 5| Step: 2
Training loss: 0.5616030097007751
Validation loss: 1.9408272158715032

Epoch: 5| Step: 3
Training loss: 0.8048604726791382
Validation loss: 1.9646890189058037

Epoch: 5| Step: 4
Training loss: 0.8311446905136108
Validation loss: 1.9845948706391037

Epoch: 5| Step: 5
Training loss: 0.761421799659729
Validation loss: 1.9747591710859729

Epoch: 5| Step: 6
Training loss: 0.9718146324157715
Validation loss: 1.9429833760825537

Epoch: 5| Step: 7
Training loss: 0.9164212346076965
Validation loss: 1.9089032321847894

Epoch: 5| Step: 8
Training loss: 0.7169353365898132
Validation loss: 1.8666596233203847

Epoch: 5| Step: 9
Training loss: 0.7238921523094177
Validation loss: 1.8525129351564633

Epoch: 5| Step: 10
Training loss: 0.7151739597320557
Validation loss: 1.8327182262174544

Epoch: 231| Step: 0
Training loss: 1.0934556722640991
Validation loss: 1.823216958712506

Epoch: 5| Step: 1
Training loss: 0.7083162069320679
Validation loss: 1.8379838620462725

Epoch: 5| Step: 2
Training loss: 0.632211446762085
Validation loss: 1.8442317170481528

Epoch: 5| Step: 3
Training loss: 0.621472179889679
Validation loss: 1.8627091197557346

Epoch: 5| Step: 4
Training loss: 1.2326881885528564
Validation loss: 1.9005386983194659

Epoch: 5| Step: 5
Training loss: 0.7303498983383179
Validation loss: 1.968821943447154

Epoch: 5| Step: 6
Training loss: 0.5936397314071655
Validation loss: 1.9958197673161824

Epoch: 5| Step: 7
Training loss: 0.8854773640632629
Validation loss: 1.9710074541389302

Epoch: 5| Step: 8
Training loss: 0.7429741621017456
Validation loss: 1.9451048297266806

Epoch: 5| Step: 9
Training loss: 0.450857013463974
Validation loss: 1.9578192669858214

Epoch: 5| Step: 10
Training loss: 0.7747715711593628
Validation loss: 1.9593835133378223

Epoch: 232| Step: 0
Training loss: 0.7201240062713623
Validation loss: 1.9313444117064118

Epoch: 5| Step: 1
Training loss: 0.7344120144844055
Validation loss: 1.9257506657672185

Epoch: 5| Step: 2
Training loss: 0.5110318064689636
Validation loss: 1.922386227115508

Epoch: 5| Step: 3
Training loss: 0.5950796008110046
Validation loss: 1.8856198210870065

Epoch: 5| Step: 4
Training loss: 0.7311943769454956
Validation loss: 1.8613337329638902

Epoch: 5| Step: 5
Training loss: 0.5833218693733215
Validation loss: 1.8869015747501003

Epoch: 5| Step: 6
Training loss: 0.6499521732330322
Validation loss: 1.8855836237630537

Epoch: 5| Step: 7
Training loss: 0.7573772668838501
Validation loss: 1.9330041357266006

Epoch: 5| Step: 8
Training loss: 0.8641306161880493
Validation loss: 1.9324704101008754

Epoch: 5| Step: 9
Training loss: 1.297419786453247
Validation loss: 1.9297951434248237

Epoch: 5| Step: 10
Training loss: 0.6072911620140076
Validation loss: 1.937047940428539

Epoch: 233| Step: 0
Training loss: 0.7863099575042725
Validation loss: 1.9342205908990675

Epoch: 5| Step: 1
Training loss: 0.45672592520713806
Validation loss: 1.9139525505804247

Epoch: 5| Step: 2
Training loss: 0.8082617521286011
Validation loss: 1.9375447560382146

Epoch: 5| Step: 3
Training loss: 0.6064351797103882
Validation loss: 1.9170864487207064

Epoch: 5| Step: 4
Training loss: 0.8103922009468079
Validation loss: 1.9356169469894902

Epoch: 5| Step: 5
Training loss: 1.011927604675293
Validation loss: 1.934431150395383

Epoch: 5| Step: 6
Training loss: 1.076539397239685
Validation loss: 1.9295049649412914

Epoch: 5| Step: 7
Training loss: 0.750342071056366
Validation loss: 1.8950134092761624

Epoch: 5| Step: 8
Training loss: 0.5668141841888428
Validation loss: 1.8853086797139977

Epoch: 5| Step: 9
Training loss: 0.684557318687439
Validation loss: 1.857324941183931

Epoch: 5| Step: 10
Training loss: 0.4321591854095459
Validation loss: 1.8776264459856096

Epoch: 234| Step: 0
Training loss: 0.8630629777908325
Validation loss: 1.9104036041485366

Epoch: 5| Step: 1
Training loss: 0.5863510966300964
Validation loss: 1.9361428624840193

Epoch: 5| Step: 2
Training loss: 0.7853077054023743
Validation loss: 1.926286865306157

Epoch: 5| Step: 3
Training loss: 0.5116513967514038
Validation loss: 1.9574406711004113

Epoch: 5| Step: 4
Training loss: 0.7894876599311829
Validation loss: 1.9489440238603981

Epoch: 5| Step: 5
Training loss: 0.4825688302516937
Validation loss: 1.9412670750771799

Epoch: 5| Step: 6
Training loss: 0.5320514440536499
Validation loss: 1.9964853768707604

Epoch: 5| Step: 7
Training loss: 0.930799663066864
Validation loss: 1.9981677096377137

Epoch: 5| Step: 8
Training loss: 0.8403054475784302
Validation loss: 1.996732114463724

Epoch: 5| Step: 9
Training loss: 0.8870221376419067
Validation loss: 1.9358552745593491

Epoch: 5| Step: 10
Training loss: 0.5365709662437439
Validation loss: 1.9597801803260722

Epoch: 235| Step: 0
Training loss: 0.5097230672836304
Validation loss: 1.899967908859253

Epoch: 5| Step: 1
Training loss: 0.8293363451957703
Validation loss: 1.870910075403029

Epoch: 5| Step: 2
Training loss: 0.8150955438613892
Validation loss: 1.8594522245468632

Epoch: 5| Step: 3
Training loss: 0.7170920968055725
Validation loss: 1.8534462451934814

Epoch: 5| Step: 4
Training loss: 0.6350189447402954
Validation loss: 1.8578899521981516

Epoch: 5| Step: 5
Training loss: 0.75523442029953
Validation loss: 1.8680690014234154

Epoch: 5| Step: 6
Training loss: 0.9851670265197754
Validation loss: 1.8913183455826135

Epoch: 5| Step: 7
Training loss: 0.8275453448295593
Validation loss: 1.8649251999393586

Epoch: 5| Step: 8
Training loss: 0.5151742696762085
Validation loss: 1.8529518150514173

Epoch: 5| Step: 9
Training loss: 0.6795975565910339
Validation loss: 1.8453601932012906

Epoch: 5| Step: 10
Training loss: 0.5925712585449219
Validation loss: 1.8543327316161125

Epoch: 236| Step: 0
Training loss: 0.3776934742927551
Validation loss: 1.8460783868707635

Epoch: 5| Step: 1
Training loss: 0.8124576807022095
Validation loss: 1.8640019380918114

Epoch: 5| Step: 2
Training loss: 0.8983781933784485
Validation loss: 1.8939450158867785

Epoch: 5| Step: 3
Training loss: 0.8287822604179382
Validation loss: 1.843299642685921

Epoch: 5| Step: 4
Training loss: 0.5851750373840332
Validation loss: 1.875845342554072

Epoch: 5| Step: 5
Training loss: 0.6331297159194946
Validation loss: 1.8819224578078075

Epoch: 5| Step: 6
Training loss: 0.6479666829109192
Validation loss: 1.9158709177406885

Epoch: 5| Step: 7
Training loss: 0.9847509264945984
Validation loss: 1.9320339874554706

Epoch: 5| Step: 8
Training loss: 0.6725925207138062
Validation loss: 1.9563446237194924

Epoch: 5| Step: 9
Training loss: 0.9561125636100769
Validation loss: 2.011812779211229

Epoch: 5| Step: 10
Training loss: 0.5423079133033752
Validation loss: 1.997333800920876

Epoch: 237| Step: 0
Training loss: 0.9220498204231262
Validation loss: 1.9950040476296538

Epoch: 5| Step: 1
Training loss: 0.9310266375541687
Validation loss: 1.8973482001212336

Epoch: 5| Step: 2
Training loss: 0.7414253950119019
Validation loss: 1.8449025730932913

Epoch: 5| Step: 3
Training loss: 0.5275472402572632
Validation loss: 1.8090575100273214

Epoch: 5| Step: 4
Training loss: 0.4670526087284088
Validation loss: 1.7996527443649948

Epoch: 5| Step: 5
Training loss: 0.6199954748153687
Validation loss: 1.7881750227302633

Epoch: 5| Step: 6
Training loss: 0.6884240508079529
Validation loss: 1.7919196851791874

Epoch: 5| Step: 7
Training loss: 1.0742279291152954
Validation loss: 1.812381347020467

Epoch: 5| Step: 8
Training loss: 0.6070630550384521
Validation loss: 1.833120951088526

Epoch: 5| Step: 9
Training loss: 0.8460726737976074
Validation loss: 1.8961261908213298

Epoch: 5| Step: 10
Training loss: 0.6130018830299377
Validation loss: 1.9222192290008708

Epoch: 238| Step: 0
Training loss: 0.869282603263855
Validation loss: 1.9253626702934183

Epoch: 5| Step: 1
Training loss: 0.486017644405365
Validation loss: 1.8912584576555478

Epoch: 5| Step: 2
Training loss: 0.6997063755989075
Validation loss: 1.8488847286470476

Epoch: 5| Step: 3
Training loss: 0.500308632850647
Validation loss: 1.8459916012261504

Epoch: 5| Step: 4
Training loss: 0.5418779253959656
Validation loss: 1.8304060466827885

Epoch: 5| Step: 5
Training loss: 1.0081210136413574
Validation loss: 1.8155676113661898

Epoch: 5| Step: 6
Training loss: 0.6078842878341675
Validation loss: 1.8309047196501045

Epoch: 5| Step: 7
Training loss: 0.6672235727310181
Validation loss: 1.851758067325879

Epoch: 5| Step: 8
Training loss: 0.7290996313095093
Validation loss: 1.8539132379716443

Epoch: 5| Step: 9
Training loss: 0.5306341052055359
Validation loss: 1.876236177259876

Epoch: 5| Step: 10
Training loss: 1.093537449836731
Validation loss: 1.877897593282884

Epoch: 239| Step: 0
Training loss: 0.9447271227836609
Validation loss: 1.887621018194383

Epoch: 5| Step: 1
Training loss: 0.6513059735298157
Validation loss: 1.9106514146251063

Epoch: 5| Step: 2
Training loss: 0.8011050224304199
Validation loss: 1.9210569935460244

Epoch: 5| Step: 3
Training loss: 0.8574193716049194
Validation loss: 1.945214968855663

Epoch: 5| Step: 4
Training loss: 0.7509725689888
Validation loss: 1.942833492832799

Epoch: 5| Step: 5
Training loss: 0.17900970578193665
Validation loss: 1.9181987495832546

Epoch: 5| Step: 6
Training loss: 0.765532910823822
Validation loss: 1.8932135207678682

Epoch: 5| Step: 7
Training loss: 0.8092907071113586
Validation loss: 1.8565181122031262

Epoch: 5| Step: 8
Training loss: 0.6007046699523926
Validation loss: 1.8303613624265116

Epoch: 5| Step: 9
Training loss: 0.5037547945976257
Validation loss: 1.8147228123039327

Epoch: 5| Step: 10
Training loss: 0.5614039301872253
Validation loss: 1.8169302594277166

Epoch: 240| Step: 0
Training loss: 0.8131216764450073
Validation loss: 1.840872637687191

Epoch: 5| Step: 1
Training loss: 0.4248170256614685
Validation loss: 1.8367163071068384

Epoch: 5| Step: 2
Training loss: 0.4441836476325989
Validation loss: 1.8577959537506104

Epoch: 5| Step: 3
Training loss: 0.9379342794418335
Validation loss: 1.8973465529821252

Epoch: 5| Step: 4
Training loss: 0.872829258441925
Validation loss: 1.8958582314111854

Epoch: 5| Step: 5
Training loss: 0.6996194124221802
Validation loss: 1.9392609762889084

Epoch: 5| Step: 6
Training loss: 0.6096502542495728
Validation loss: 1.9069479588539369

Epoch: 5| Step: 7
Training loss: 0.5506584644317627
Validation loss: 1.9177998253094253

Epoch: 5| Step: 8
Training loss: 0.7083565592765808
Validation loss: 1.8997299517354658

Epoch: 5| Step: 9
Training loss: 0.6540152430534363
Validation loss: 1.915640833557293

Epoch: 5| Step: 10
Training loss: 0.609004557132721
Validation loss: 1.8777346944296232

Epoch: 241| Step: 0
Training loss: 0.7454708814620972
Validation loss: 1.8888318461756552

Epoch: 5| Step: 1
Training loss: 0.9273616671562195
Validation loss: 1.8795173501455655

Epoch: 5| Step: 2
Training loss: 0.6702775359153748
Validation loss: 1.8913428180961198

Epoch: 5| Step: 3
Training loss: 0.70106440782547
Validation loss: 1.8975564408045944

Epoch: 5| Step: 4
Training loss: 0.5109909176826477
Validation loss: 1.8914138886236376

Epoch: 5| Step: 5
Training loss: 0.6739861369132996
Validation loss: 1.8727434860762728

Epoch: 5| Step: 6
Training loss: 0.5772794485092163
Validation loss: 1.88947327931722

Epoch: 5| Step: 7
Training loss: 0.6768780946731567
Validation loss: 1.8741101757172616

Epoch: 5| Step: 8
Training loss: 0.9383566975593567
Validation loss: 1.8496203217455136

Epoch: 5| Step: 9
Training loss: 0.43930548429489136
Validation loss: 1.8820600355825117

Epoch: 5| Step: 10
Training loss: 0.34269559383392334
Validation loss: 1.9293384193092264

Epoch: 242| Step: 0
Training loss: 0.43992072343826294
Validation loss: 1.9687533840056388

Epoch: 5| Step: 1
Training loss: 0.6996244192123413
Validation loss: 2.0234957330970356

Epoch: 5| Step: 2
Training loss: 0.8366779088973999
Validation loss: 1.9919988775766024

Epoch: 5| Step: 3
Training loss: 0.7131978273391724
Validation loss: 1.9634464376716203

Epoch: 5| Step: 4
Training loss: 0.7864769697189331
Validation loss: 1.8902550769108597

Epoch: 5| Step: 5
Training loss: 0.5093914866447449
Validation loss: 1.820713702068534

Epoch: 5| Step: 6
Training loss: 1.0666191577911377
Validation loss: 1.826942281056476

Epoch: 5| Step: 7
Training loss: 0.4727986454963684
Validation loss: 1.8194413979848225

Epoch: 5| Step: 8
Training loss: 0.521088182926178
Validation loss: 1.8188045332508702

Epoch: 5| Step: 9
Training loss: 0.634377121925354
Validation loss: 1.8459729699678318

Epoch: 5| Step: 10
Training loss: 0.6728123426437378
Validation loss: 1.8835752035981865

Epoch: 243| Step: 0
Training loss: 0.8027679324150085
Validation loss: 1.9064616695527108

Epoch: 5| Step: 1
Training loss: 0.6681544184684753
Validation loss: 1.9670215883562643

Epoch: 5| Step: 2
Training loss: 0.6873129606246948
Validation loss: 1.9606761278644684

Epoch: 5| Step: 3
Training loss: 0.9929105639457703
Validation loss: 1.936491415064822

Epoch: 5| Step: 4
Training loss: 0.732951283454895
Validation loss: 1.8650648081174461

Epoch: 5| Step: 5
Training loss: 0.6514929533004761
Validation loss: 1.8147827604765534

Epoch: 5| Step: 6
Training loss: 0.6154094934463501
Validation loss: 1.7846927681276876

Epoch: 5| Step: 7
Training loss: 0.5114203691482544
Validation loss: 1.8001447698121429

Epoch: 5| Step: 8
Training loss: 0.5375756025314331
Validation loss: 1.8112222456162976

Epoch: 5| Step: 9
Training loss: 0.5372339487075806
Validation loss: 1.8269140951095089

Epoch: 5| Step: 10
Training loss: 0.45233872532844543
Validation loss: 1.8756089697601974

Epoch: 244| Step: 0
Training loss: 0.5025834441184998
Validation loss: 1.9068833871554303

Epoch: 5| Step: 1
Training loss: 0.6074783205986023
Validation loss: 1.97966097247216

Epoch: 5| Step: 2
Training loss: 0.8098050355911255
Validation loss: 1.9818098314346806

Epoch: 5| Step: 3
Training loss: 0.8685879707336426
Validation loss: 1.9814625734923987

Epoch: 5| Step: 4
Training loss: 0.4920722544193268
Validation loss: 1.9456160171057588

Epoch: 5| Step: 5
Training loss: 0.5783806443214417
Validation loss: 1.9148825368573588

Epoch: 5| Step: 6
Training loss: 0.9583327174186707
Validation loss: 1.8906844226262902

Epoch: 5| Step: 7
Training loss: 0.5594930648803711
Validation loss: 1.8616810575608285

Epoch: 5| Step: 8
Training loss: 0.39945417642593384
Validation loss: 1.8336412534918836

Epoch: 5| Step: 9
Training loss: 0.8170621991157532
Validation loss: 1.801927399891679

Epoch: 5| Step: 10
Training loss: 0.6225720643997192
Validation loss: 1.8567822940887944

Epoch: 245| Step: 0
Training loss: 0.5985535383224487
Validation loss: 1.8614453679771834

Epoch: 5| Step: 1
Training loss: 0.5393452048301697
Validation loss: 1.8787374073459255

Epoch: 5| Step: 2
Training loss: 0.5117648839950562
Validation loss: 1.92503527415696

Epoch: 5| Step: 3
Training loss: 0.9772855639457703
Validation loss: 1.9702475122226182

Epoch: 5| Step: 4
Training loss: 0.5142407417297363
Validation loss: 1.9647720706078313

Epoch: 5| Step: 5
Training loss: 0.3922134339809418
Validation loss: 1.9643992044592415

Epoch: 5| Step: 6
Training loss: 0.42405086755752563
Validation loss: 1.8781068171224287

Epoch: 5| Step: 7
Training loss: 0.6702063083648682
Validation loss: 1.831933431727912

Epoch: 5| Step: 8
Training loss: 0.7440875768661499
Validation loss: 1.8196975684935046

Epoch: 5| Step: 9
Training loss: 0.8666263818740845
Validation loss: 1.8334321245070426

Epoch: 5| Step: 10
Training loss: 1.079768180847168
Validation loss: 1.7935999952336794

Epoch: 246| Step: 0
Training loss: 0.43224963545799255
Validation loss: 1.8054300726100962

Epoch: 5| Step: 1
Training loss: 0.7326291799545288
Validation loss: 1.852115765694649

Epoch: 5| Step: 2
Training loss: 0.7457121014595032
Validation loss: 1.8714666392213555

Epoch: 5| Step: 3
Training loss: 0.7282177805900574
Validation loss: 1.890557424996489

Epoch: 5| Step: 4
Training loss: 0.45430701971054077
Validation loss: 1.8545850041092082

Epoch: 5| Step: 5
Training loss: 0.7292729616165161
Validation loss: 1.8344240316780664

Epoch: 5| Step: 6
Training loss: 0.5653036832809448
Validation loss: 1.8427489431955482

Epoch: 5| Step: 7
Training loss: 0.9766833186149597
Validation loss: 1.8616548033170803

Epoch: 5| Step: 8
Training loss: 0.6284180879592896
Validation loss: 1.9215297032428045

Epoch: 5| Step: 9
Training loss: 0.7368986010551453
Validation loss: 1.8931372652771652

Epoch: 5| Step: 10
Training loss: 0.6653647422790527
Validation loss: 1.9483425642854424

Epoch: 247| Step: 0
Training loss: 0.6761423349380493
Validation loss: 1.9295853132842689

Epoch: 5| Step: 1
Training loss: 0.5985039472579956
Validation loss: 1.8893935885480655

Epoch: 5| Step: 2
Training loss: 0.4905978739261627
Validation loss: 1.8644725840578797

Epoch: 5| Step: 3
Training loss: 0.571160614490509
Validation loss: 1.8261547268077891

Epoch: 5| Step: 4
Training loss: 0.8512344360351562
Validation loss: 1.803249801358869

Epoch: 5| Step: 5
Training loss: 1.0216730833053589
Validation loss: 1.7970786658666467

Epoch: 5| Step: 6
Training loss: 0.7528001070022583
Validation loss: 1.827540438662293

Epoch: 5| Step: 7
Training loss: 0.5740763545036316
Validation loss: 1.8183252273067352

Epoch: 5| Step: 8
Training loss: 0.39548271894454956
Validation loss: 1.8937711766971055

Epoch: 5| Step: 9
Training loss: 0.4466870427131653
Validation loss: 1.9337705630128101

Epoch: 5| Step: 10
Training loss: 0.6814284324645996
Validation loss: 1.9778372049331665

Epoch: 248| Step: 0
Training loss: 0.348597913980484
Validation loss: 1.9773038100170832

Epoch: 5| Step: 1
Training loss: 0.6146609783172607
Validation loss: 1.9571306026110085

Epoch: 5| Step: 2
Training loss: 1.0047099590301514
Validation loss: 1.9322831579433974

Epoch: 5| Step: 3
Training loss: 0.4279593825340271
Validation loss: 1.926437465093469

Epoch: 5| Step: 4
Training loss: 0.5624619722366333
Validation loss: 1.865054089535949

Epoch: 5| Step: 5
Training loss: 0.49261870980262756
Validation loss: 1.816999836634564

Epoch: 5| Step: 6
Training loss: 0.6758569478988647
Validation loss: 1.7879143024003634

Epoch: 5| Step: 7
Training loss: 0.7253670692443848
Validation loss: 1.7774855167635026

Epoch: 5| Step: 8
Training loss: 0.7355263829231262
Validation loss: 1.7822802169348604

Epoch: 5| Step: 9
Training loss: 0.7516501545906067
Validation loss: 1.7946426048073718

Epoch: 5| Step: 10
Training loss: 0.8051213622093201
Validation loss: 1.7970630943134267

Epoch: 249| Step: 0
Training loss: 0.7329872250556946
Validation loss: 1.832836115232078

Epoch: 5| Step: 1
Training loss: 0.32775136828422546
Validation loss: 1.8773216137322046

Epoch: 5| Step: 2
Training loss: 0.665541410446167
Validation loss: 1.9567877682306434

Epoch: 5| Step: 3
Training loss: 0.8533236384391785
Validation loss: 2.0103822267183693

Epoch: 5| Step: 4
Training loss: 0.6905635595321655
Validation loss: 1.9919763829118462

Epoch: 5| Step: 5
Training loss: 0.8674250841140747
Validation loss: 2.0122232308951755

Epoch: 5| Step: 6
Training loss: 0.42779308557510376
Validation loss: 1.975376094541242

Epoch: 5| Step: 7
Training loss: 0.6136730909347534
Validation loss: 1.955274264017741

Epoch: 5| Step: 8
Training loss: 0.6351526975631714
Validation loss: 1.9406137056248163

Epoch: 5| Step: 9
Training loss: 0.4833298623561859
Validation loss: 1.9006323993846934

Epoch: 5| Step: 10
Training loss: 0.36456426978111267
Validation loss: 1.9140815299044374

Epoch: 250| Step: 0
Training loss: 0.3345930576324463
Validation loss: 1.8865769178636613

Epoch: 5| Step: 1
Training loss: 0.6862991452217102
Validation loss: 1.8557276007949666

Epoch: 5| Step: 2
Training loss: 0.6508216261863708
Validation loss: 1.8608371416727703

Epoch: 5| Step: 3
Training loss: 0.6810402274131775
Validation loss: 1.858365240917411

Epoch: 5| Step: 4
Training loss: 0.7786179780960083
Validation loss: 1.8644066600389377

Epoch: 5| Step: 5
Training loss: 0.33088812232017517
Validation loss: 1.85415098744054

Epoch: 5| Step: 6
Training loss: 0.501316249370575
Validation loss: 1.8843665776714202

Epoch: 5| Step: 7
Training loss: 0.39334622025489807
Validation loss: 1.886580285205636

Epoch: 5| Step: 8
Training loss: 0.6266909837722778
Validation loss: 1.8847659634005638

Epoch: 5| Step: 9
Training loss: 0.8068186640739441
Validation loss: 1.870766967855474

Epoch: 5| Step: 10
Training loss: 0.7646986842155457
Validation loss: 1.8604971849790184

Epoch: 251| Step: 0
Training loss: 0.5125303864479065
Validation loss: 1.846293410947246

Epoch: 5| Step: 1
Training loss: 0.7780916690826416
Validation loss: 1.841534117216705

Epoch: 5| Step: 2
Training loss: 0.74263596534729
Validation loss: 1.820846805008509

Epoch: 5| Step: 3
Training loss: 0.6382134556770325
Validation loss: 1.8336633507923414

Epoch: 5| Step: 4
Training loss: 0.6392379999160767
Validation loss: 1.8640213820242113

Epoch: 5| Step: 5
Training loss: 0.4830424189567566
Validation loss: 1.8622800483498523

Epoch: 5| Step: 6
Training loss: 0.4731544554233551
Validation loss: 1.8570089635028635

Epoch: 5| Step: 7
Training loss: 0.5309711694717407
Validation loss: 1.8881668839403378

Epoch: 5| Step: 8
Training loss: 0.5951129198074341
Validation loss: 1.8509544403322282

Epoch: 5| Step: 9
Training loss: 0.563713788986206
Validation loss: 1.8310630795776204

Epoch: 5| Step: 10
Training loss: 0.5950121879577637
Validation loss: 1.8213925412906113

Epoch: 252| Step: 0
Training loss: 0.6802242994308472
Validation loss: 1.8508571681155954

Epoch: 5| Step: 1
Training loss: 0.6396764516830444
Validation loss: 1.884322222842965

Epoch: 5| Step: 2
Training loss: 0.6742194890975952
Validation loss: 1.9357891262218516

Epoch: 5| Step: 3
Training loss: 0.5942120552062988
Validation loss: 1.9454840742131716

Epoch: 5| Step: 4
Training loss: 0.834176242351532
Validation loss: 1.9127797221624723

Epoch: 5| Step: 5
Training loss: 0.5713105201721191
Validation loss: 1.9063952789511731

Epoch: 5| Step: 6
Training loss: 0.32314786314964294
Validation loss: 1.8574120895836943

Epoch: 5| Step: 7
Training loss: 0.8698854446411133
Validation loss: 1.809908224690345

Epoch: 5| Step: 8
Training loss: 0.4284389019012451
Validation loss: 1.8204998867486113

Epoch: 5| Step: 9
Training loss: 0.619236171245575
Validation loss: 1.8148700421856296

Epoch: 5| Step: 10
Training loss: 0.5244308114051819
Validation loss: 1.8276461708930232

Epoch: 253| Step: 0
Training loss: 0.39621788263320923
Validation loss: 1.8479424779133131

Epoch: 5| Step: 1
Training loss: 0.577269434928894
Validation loss: 1.8643891311460925

Epoch: 5| Step: 2
Training loss: 0.5296251177787781
Validation loss: 1.853765785053212

Epoch: 5| Step: 3
Training loss: 0.4462336599826813
Validation loss: 1.8882037542199577

Epoch: 5| Step: 4
Training loss: 0.6735886335372925
Validation loss: 1.8943204802851523

Epoch: 5| Step: 5
Training loss: 0.6240389943122864
Validation loss: 1.9156496024900866

Epoch: 5| Step: 6
Training loss: 0.7886738777160645
Validation loss: 1.9171636848039524

Epoch: 5| Step: 7
Training loss: 0.3910670876502991
Validation loss: 1.9150435745075185

Epoch: 5| Step: 8
Training loss: 0.7364805340766907
Validation loss: 1.928800320112577

Epoch: 5| Step: 9
Training loss: 0.6362501382827759
Validation loss: 1.9498524576105096

Epoch: 5| Step: 10
Training loss: 0.547661304473877
Validation loss: 1.9299074219119163

Epoch: 254| Step: 0
Training loss: 0.6087303161621094
Validation loss: 1.9099106557907597

Epoch: 5| Step: 1
Training loss: 0.6381035447120667
Validation loss: 1.8822367742497434

Epoch: 5| Step: 2
Training loss: 0.7106208205223083
Validation loss: 1.8646350265831075

Epoch: 5| Step: 3
Training loss: 0.4275566041469574
Validation loss: 1.891238051076089

Epoch: 5| Step: 4
Training loss: 0.47640085220336914
Validation loss: 1.9023170009736092

Epoch: 5| Step: 5
Training loss: 0.6828407049179077
Validation loss: 1.9055378103768954

Epoch: 5| Step: 6
Training loss: 0.6052522659301758
Validation loss: 1.9287123180204822

Epoch: 5| Step: 7
Training loss: 0.4121190905570984
Validation loss: 1.910731554031372

Epoch: 5| Step: 8
Training loss: 0.5300154685974121
Validation loss: 1.8923493482733285

Epoch: 5| Step: 9
Training loss: 0.6493495106697083
Validation loss: 1.8668183075484408

Epoch: 5| Step: 10
Training loss: 0.6215950846672058
Validation loss: 1.8467070287273777

Epoch: 255| Step: 0
Training loss: 0.4926840662956238
Validation loss: 1.8415205529941026

Epoch: 5| Step: 1
Training loss: 0.5277557373046875
Validation loss: 1.8326940831317697

Epoch: 5| Step: 2
Training loss: 0.5934926271438599
Validation loss: 1.8305998245875041

Epoch: 5| Step: 3
Training loss: 0.6786924600601196
Validation loss: 1.851877586815947

Epoch: 5| Step: 4
Training loss: 0.7468980550765991
Validation loss: 1.8811380786280478

Epoch: 5| Step: 5
Training loss: 0.5369956493377686
Validation loss: 1.8884760807919245

Epoch: 5| Step: 6
Training loss: 0.3675048351287842
Validation loss: 1.8685533667123446

Epoch: 5| Step: 7
Training loss: 0.4220121502876282
Validation loss: 1.8642096929652716

Epoch: 5| Step: 8
Training loss: 0.7675738334655762
Validation loss: 1.8699010943853727

Epoch: 5| Step: 9
Training loss: 0.6955268979072571
Validation loss: 1.8448632212095364

Epoch: 5| Step: 10
Training loss: 0.38898104429244995
Validation loss: 1.8590519966617707

Epoch: 256| Step: 0
Training loss: 0.6439946889877319
Validation loss: 1.8578363951816355

Epoch: 5| Step: 1
Training loss: 0.3722750246524811
Validation loss: 1.865733677341092

Epoch: 5| Step: 2
Training loss: 0.5660595297813416
Validation loss: 1.8418547632873699

Epoch: 5| Step: 3
Training loss: 0.8088499903678894
Validation loss: 1.8361198056128718

Epoch: 5| Step: 4
Training loss: 0.5637243986129761
Validation loss: 1.8382832311814832

Epoch: 5| Step: 5
Training loss: 0.2991641163825989
Validation loss: 1.8628031451215026

Epoch: 5| Step: 6
Training loss: 0.5827144980430603
Validation loss: 1.8305683135986328

Epoch: 5| Step: 7
Training loss: 0.7472313046455383
Validation loss: 1.8421502959343694

Epoch: 5| Step: 8
Training loss: 0.5494430661201477
Validation loss: 1.8196647295387842

Epoch: 5| Step: 9
Training loss: 0.5418168902397156
Validation loss: 1.8557536653293076

Epoch: 5| Step: 10
Training loss: 0.5061088800430298
Validation loss: 1.8583244264766734

Epoch: 257| Step: 0
Training loss: 0.9781017303466797
Validation loss: 1.8931498809527325

Epoch: 5| Step: 1
Training loss: 0.7363410592079163
Validation loss: 1.8871313987239715

Epoch: 5| Step: 2
Training loss: 0.5327418446540833
Validation loss: 1.8818616482519335

Epoch: 5| Step: 3
Training loss: 0.5503491163253784
Validation loss: 1.8726517064597017

Epoch: 5| Step: 4
Training loss: 0.5809746980667114
Validation loss: 1.8853893356938516

Epoch: 5| Step: 5
Training loss: 0.5113361477851868
Validation loss: 1.8888055765500633

Epoch: 5| Step: 6
Training loss: 0.3572775721549988
Validation loss: 1.8639316866474767

Epoch: 5| Step: 7
Training loss: 0.43072348833084106
Validation loss: 1.7860174666168869

Epoch: 5| Step: 8
Training loss: 0.5489858388900757
Validation loss: 1.7951701956410562

Epoch: 5| Step: 9
Training loss: 0.4590159058570862
Validation loss: 1.7655217839825539

Epoch: 5| Step: 10
Training loss: 0.5343365669250488
Validation loss: 1.7525071251776911

Epoch: 258| Step: 0
Training loss: 0.6528204083442688
Validation loss: 1.7950766266033213

Epoch: 5| Step: 1
Training loss: 0.5939560532569885
Validation loss: 1.8796046292910011

Epoch: 5| Step: 2
Training loss: 0.8326767086982727
Validation loss: 1.9043604686696043

Epoch: 5| Step: 3
Training loss: 0.49343013763427734
Validation loss: 1.9380490292784989

Epoch: 5| Step: 4
Training loss: 0.3199499547481537
Validation loss: 1.9191425026104014

Epoch: 5| Step: 5
Training loss: 0.48625558614730835
Validation loss: 1.9586867017130698

Epoch: 5| Step: 6
Training loss: 0.6087930798530579
Validation loss: 1.8923006416648946

Epoch: 5| Step: 7
Training loss: 0.3466882109642029
Validation loss: 1.859657387579641

Epoch: 5| Step: 8
Training loss: 0.6600905656814575
Validation loss: 1.822300148266618

Epoch: 5| Step: 9
Training loss: 0.6872859001159668
Validation loss: 1.8039949927278744

Epoch: 5| Step: 10
Training loss: 0.516473114490509
Validation loss: 1.8417122107680126

Epoch: 259| Step: 0
Training loss: 0.4676976203918457
Validation loss: 1.8441963695710706

Epoch: 5| Step: 1
Training loss: 0.5819911360740662
Validation loss: 1.8511142423076015

Epoch: 5| Step: 2
Training loss: 0.3940843641757965
Validation loss: 1.8491785769821496

Epoch: 5| Step: 3
Training loss: 0.8010503053665161
Validation loss: 1.8739068661966631

Epoch: 5| Step: 4
Training loss: 0.7091721296310425
Validation loss: 1.88160498808789

Epoch: 5| Step: 5
Training loss: 0.5764167904853821
Validation loss: 1.8527625760724467

Epoch: 5| Step: 6
Training loss: 0.4539182186126709
Validation loss: 1.820213153798093

Epoch: 5| Step: 7
Training loss: 0.41942206025123596
Validation loss: 1.783131181552846

Epoch: 5| Step: 8
Training loss: 0.6032991409301758
Validation loss: 1.767415254346786

Epoch: 5| Step: 9
Training loss: 0.6870085000991821
Validation loss: 1.7927420575131652

Epoch: 5| Step: 10
Training loss: 0.5604634284973145
Validation loss: 1.7966517684280232

Epoch: 260| Step: 0
Training loss: 0.6864242553710938
Validation loss: 1.839654343102568

Epoch: 5| Step: 1
Training loss: 0.8886404037475586
Validation loss: 1.897665016112789

Epoch: 5| Step: 2
Training loss: 0.34470123052597046
Validation loss: 1.8889698033691735

Epoch: 5| Step: 3
Training loss: 0.6755980253219604
Validation loss: 1.8972000845016972

Epoch: 5| Step: 4
Training loss: 0.4334370493888855
Validation loss: 1.8831893577370593

Epoch: 5| Step: 5
Training loss: 0.7007743120193481
Validation loss: 1.871438907038781

Epoch: 5| Step: 6
Training loss: 0.3716919720172882
Validation loss: 1.8755438520062355

Epoch: 5| Step: 7
Training loss: 0.3857928216457367
Validation loss: 1.8533627012724518

Epoch: 5| Step: 8
Training loss: 0.45370015501976013
Validation loss: 1.8586549323092225

Epoch: 5| Step: 9
Training loss: 0.3846765458583832
Validation loss: 1.8496885222773398

Epoch: 5| Step: 10
Training loss: 0.8442651033401489
Validation loss: 1.8593647018555672

Epoch: 261| Step: 0
Training loss: 0.5462244749069214
Validation loss: 1.8912429809570312

Epoch: 5| Step: 1
Training loss: 0.5259543657302856
Validation loss: 1.861623429482983

Epoch: 5| Step: 2
Training loss: 0.5974693298339844
Validation loss: 1.8123467968356224

Epoch: 5| Step: 3
Training loss: 0.5582133531570435
Validation loss: 1.773095041192988

Epoch: 5| Step: 4
Training loss: 0.4503956437110901
Validation loss: 1.7146317702467724

Epoch: 5| Step: 5
Training loss: 0.6789805889129639
Validation loss: 1.7281486398430281

Epoch: 5| Step: 6
Training loss: 0.6390610933303833
Validation loss: 1.7597349741125619

Epoch: 5| Step: 7
Training loss: 0.529676616191864
Validation loss: 1.7596875647062897

Epoch: 5| Step: 8
Training loss: 0.6334092617034912
Validation loss: 1.7943157547263688

Epoch: 5| Step: 9
Training loss: 0.7038187980651855
Validation loss: 1.8306422156672324

Epoch: 5| Step: 10
Training loss: 0.6074957251548767
Validation loss: 1.862589010628321

Epoch: 262| Step: 0
Training loss: 0.45392781496047974
Validation loss: 1.8652178113178541

Epoch: 5| Step: 1
Training loss: 0.5136054754257202
Validation loss: 1.8385525172756565

Epoch: 5| Step: 2
Training loss: 0.6146206259727478
Validation loss: 1.8390117717045609

Epoch: 5| Step: 3
Training loss: 0.28715237975120544
Validation loss: 1.7988461268845426

Epoch: 5| Step: 4
Training loss: 0.8652445673942566
Validation loss: 1.7655356878875403

Epoch: 5| Step: 5
Training loss: 0.6127285361289978
Validation loss: 1.7401700737655803

Epoch: 5| Step: 6
Training loss: 0.5642417073249817
Validation loss: 1.7199255958680184

Epoch: 5| Step: 7
Training loss: 0.7360635995864868
Validation loss: 1.7283082995363461

Epoch: 5| Step: 8
Training loss: 0.3147721588611603
Validation loss: 1.7325068814780122

Epoch: 5| Step: 9
Training loss: 0.4599294662475586
Validation loss: 1.773927257907006

Epoch: 5| Step: 10
Training loss: 0.668887197971344
Validation loss: 1.815580177050765

Epoch: 263| Step: 0
Training loss: 0.5003260374069214
Validation loss: 1.8579737870923934

Epoch: 5| Step: 1
Training loss: 0.3824365735054016
Validation loss: 1.8858790051552556

Epoch: 5| Step: 2
Training loss: 0.5507858991622925
Validation loss: 1.8855700018585368

Epoch: 5| Step: 3
Training loss: 0.5241328477859497
Validation loss: 1.8437153113785612

Epoch: 5| Step: 4
Training loss: 0.45012372732162476
Validation loss: 1.809448520342509

Epoch: 5| Step: 5
Training loss: 0.9277924299240112
Validation loss: 1.772873919497254

Epoch: 5| Step: 6
Training loss: 0.42456942796707153
Validation loss: 1.770586887995402

Epoch: 5| Step: 7
Training loss: 0.7853037118911743
Validation loss: 1.748408632893716

Epoch: 5| Step: 8
Training loss: 0.38269954919815063
Validation loss: 1.760127354693669

Epoch: 5| Step: 9
Training loss: 0.6252646446228027
Validation loss: 1.7643931373473136

Epoch: 5| Step: 10
Training loss: 0.5050844550132751
Validation loss: 1.7949925263722737

Epoch: 264| Step: 0
Training loss: 0.832467257976532
Validation loss: 1.854168216387431

Epoch: 5| Step: 1
Training loss: 0.5770144462585449
Validation loss: 1.8470875793887722

Epoch: 5| Step: 2
Training loss: 0.3951353430747986
Validation loss: 1.8958798557199457

Epoch: 5| Step: 3
Training loss: 0.600197970867157
Validation loss: 1.8988315238747546

Epoch: 5| Step: 4
Training loss: 0.5066667795181274
Validation loss: 1.8893427630906463

Epoch: 5| Step: 5
Training loss: 0.5312747955322266
Validation loss: 1.876224692149829

Epoch: 5| Step: 6
Training loss: 0.43453249335289
Validation loss: 1.8047911915727841

Epoch: 5| Step: 7
Training loss: 0.3358216881752014
Validation loss: 1.7637384835109915

Epoch: 5| Step: 8
Training loss: 0.4867861866950989
Validation loss: 1.7682803484701342

Epoch: 5| Step: 9
Training loss: 0.41826266050338745
Validation loss: 1.7449399143136957

Epoch: 5| Step: 10
Training loss: 0.8018603920936584
Validation loss: 1.7324005365371704

Epoch: 265| Step: 0
Training loss: 0.5817195177078247
Validation loss: 1.7471488855218376

Epoch: 5| Step: 1
Training loss: 0.35023728013038635
Validation loss: 1.7690840536548245

Epoch: 5| Step: 2
Training loss: 0.5365944504737854
Validation loss: 1.8237050810167867

Epoch: 5| Step: 3
Training loss: 0.27248769998550415
Validation loss: 1.8974255284955424

Epoch: 5| Step: 4
Training loss: 0.7786968350410461
Validation loss: 1.9184780992487425

Epoch: 5| Step: 5
Training loss: 0.7456174492835999
Validation loss: 1.9394431832016155

Epoch: 5| Step: 6
Training loss: 0.3697322905063629
Validation loss: 1.9484253365506408

Epoch: 5| Step: 7
Training loss: 0.25992536544799805
Validation loss: 1.9282225690862185

Epoch: 5| Step: 8
Training loss: 0.7431716918945312
Validation loss: 1.8974251208766815

Epoch: 5| Step: 9
Training loss: 0.42499956488609314
Validation loss: 1.8454372011205202

Epoch: 5| Step: 10
Training loss: 0.81512451171875
Validation loss: 1.8011957778725574

Epoch: 266| Step: 0
Training loss: 0.5921674966812134
Validation loss: 1.7692773111404911

Epoch: 5| Step: 1
Training loss: 0.607347846031189
Validation loss: 1.7395806261288222

Epoch: 5| Step: 2
Training loss: 0.30563050508499146
Validation loss: 1.7658592142084593

Epoch: 5| Step: 3
Training loss: 0.6140321493148804
Validation loss: 1.7539103056794854

Epoch: 5| Step: 4
Training loss: 0.4936002194881439
Validation loss: 1.7887067717890586

Epoch: 5| Step: 5
Training loss: 0.6284339427947998
Validation loss: 1.823275093109377

Epoch: 5| Step: 6
Training loss: 0.4763863682746887
Validation loss: 1.88376574618842

Epoch: 5| Step: 7
Training loss: 0.48910465836524963
Validation loss: 1.9341555026269728

Epoch: 5| Step: 8
Training loss: 0.7779203653335571
Validation loss: 1.962699342799443

Epoch: 5| Step: 9
Training loss: 0.6812604665756226
Validation loss: 1.9151372935182305

Epoch: 5| Step: 10
Training loss: 0.45620858669281006
Validation loss: 1.8751167456309001

Epoch: 267| Step: 0
Training loss: 0.5869452953338623
Validation loss: 1.8534604964717742

Epoch: 5| Step: 1
Training loss: 0.6046006679534912
Validation loss: 1.8286625826230614

Epoch: 5| Step: 2
Training loss: 0.4353554844856262
Validation loss: 1.7821090016313779

Epoch: 5| Step: 3
Training loss: 0.5125306844711304
Validation loss: 1.7658721093208558

Epoch: 5| Step: 4
Training loss: 0.5325311422348022
Validation loss: 1.7647744224917503

Epoch: 5| Step: 5
Training loss: 0.5130839347839355
Validation loss: 1.7658089232701126

Epoch: 5| Step: 6
Training loss: 0.5977529287338257
Validation loss: 1.783989341028275

Epoch: 5| Step: 7
Training loss: 0.5863631963729858
Validation loss: 1.8332747336356872

Epoch: 5| Step: 8
Training loss: 0.6750298738479614
Validation loss: 1.8635062017748434

Epoch: 5| Step: 9
Training loss: 0.5044585466384888
Validation loss: 1.8779682959279707

Epoch: 5| Step: 10
Training loss: 0.3096029758453369
Validation loss: 1.9038944013657109

Epoch: 268| Step: 0
Training loss: 0.5598303079605103
Validation loss: 1.913942507518235

Epoch: 5| Step: 1
Training loss: 0.43742161989212036
Validation loss: 1.878052060322095

Epoch: 5| Step: 2
Training loss: 0.2720375955104828
Validation loss: 1.8513092071779313

Epoch: 5| Step: 3
Training loss: 0.3944368362426758
Validation loss: 1.8155263123973724

Epoch: 5| Step: 4
Training loss: 0.6116756200790405
Validation loss: 1.7742481449598908

Epoch: 5| Step: 5
Training loss: 0.3768911361694336
Validation loss: 1.7678988043979933

Epoch: 5| Step: 6
Training loss: 0.5549442172050476
Validation loss: 1.8081399381801646

Epoch: 5| Step: 7
Training loss: 0.4206772744655609
Validation loss: 1.8227923018957979

Epoch: 5| Step: 8
Training loss: 0.6070281267166138
Validation loss: 1.823824965825645

Epoch: 5| Step: 9
Training loss: 0.35347795486450195
Validation loss: 1.8587375533196233

Epoch: 5| Step: 10
Training loss: 1.1293929815292358
Validation loss: 1.858535752501539

Epoch: 269| Step: 0
Training loss: 0.4415225088596344
Validation loss: 1.8350146983259468

Epoch: 5| Step: 1
Training loss: 0.3240179121494293
Validation loss: 1.7874980729113343

Epoch: 5| Step: 2
Training loss: 0.531279444694519
Validation loss: 1.7393529761222102

Epoch: 5| Step: 3
Training loss: 0.5420023202896118
Validation loss: 1.7217535780322166

Epoch: 5| Step: 4
Training loss: 0.48321533203125
Validation loss: 1.7434332857849777

Epoch: 5| Step: 5
Training loss: 0.5559040904045105
Validation loss: 1.7550097268114808

Epoch: 5| Step: 6
Training loss: 0.39774471521377563
Validation loss: 1.7747119472872825

Epoch: 5| Step: 7
Training loss: 0.43405523896217346
Validation loss: 1.7970697136335476

Epoch: 5| Step: 8
Training loss: 0.3748833239078522
Validation loss: 1.8525866564883982

Epoch: 5| Step: 9
Training loss: 0.5460673570632935
Validation loss: 1.8691318253035187

Epoch: 5| Step: 10
Training loss: 0.6668890714645386
Validation loss: 1.8865231929286834

Epoch: 270| Step: 0
Training loss: 0.4505603313446045
Validation loss: 1.9043355987917991

Epoch: 5| Step: 1
Training loss: 0.44788455963134766
Validation loss: 1.913253668815859

Epoch: 5| Step: 2
Training loss: 0.5239402055740356
Validation loss: 1.8469550891589093

Epoch: 5| Step: 3
Training loss: 0.5093851089477539
Validation loss: 1.7941163419395365

Epoch: 5| Step: 4
Training loss: 0.5794710516929626
Validation loss: 1.7613204704817904

Epoch: 5| Step: 5
Training loss: 0.39594489336013794
Validation loss: 1.7519779641141173

Epoch: 5| Step: 6
Training loss: 0.2747286260128021
Validation loss: 1.726574094064774

Epoch: 5| Step: 7
Training loss: 0.5809140205383301
Validation loss: 1.7320425792406964

Epoch: 5| Step: 8
Training loss: 0.4570137560367584
Validation loss: 1.7554044210782616

Epoch: 5| Step: 9
Training loss: 0.5844177007675171
Validation loss: 1.7810736292151994

Epoch: 5| Step: 10
Training loss: 0.4273824095726013
Validation loss: 1.7794842412394862

Epoch: 271| Step: 0
Training loss: 0.42544427514076233
Validation loss: 1.8244278328393095

Epoch: 5| Step: 1
Training loss: 0.37958282232284546
Validation loss: 1.832257987350546

Epoch: 5| Step: 2
Training loss: 0.34563785791397095
Validation loss: 1.8306477762037707

Epoch: 5| Step: 3
Training loss: 0.5015045404434204
Validation loss: 1.846697784239246

Epoch: 5| Step: 4
Training loss: 0.5810738801956177
Validation loss: 1.8379168330982167

Epoch: 5| Step: 5
Training loss: 0.4917239248752594
Validation loss: 1.8432661974301903

Epoch: 5| Step: 6
Training loss: 0.5807439088821411
Validation loss: 1.874713441377045

Epoch: 5| Step: 7
Training loss: 0.24251170456409454
Validation loss: 1.8776076480906496

Epoch: 5| Step: 8
Training loss: 0.3905482292175293
Validation loss: 1.8728840376741143

Epoch: 5| Step: 9
Training loss: 0.519589900970459
Validation loss: 1.8752004049157585

Epoch: 5| Step: 10
Training loss: 0.716152548789978
Validation loss: 1.874090757421268

Epoch: 272| Step: 0
Training loss: 0.6887795925140381
Validation loss: 1.8478299430621568

Epoch: 5| Step: 1
Training loss: 0.5826699733734131
Validation loss: 1.8312059807521042

Epoch: 5| Step: 2
Training loss: 0.34713229537010193
Validation loss: 1.7677005337130638

Epoch: 5| Step: 3
Training loss: 0.6584540605545044
Validation loss: 1.738572261666739

Epoch: 5| Step: 4
Training loss: 1.0303900241851807
Validation loss: 1.7307952168167278

Epoch: 5| Step: 5
Training loss: 0.41751042008399963
Validation loss: 1.7526928506871706

Epoch: 5| Step: 6
Training loss: 0.4823071360588074
Validation loss: 1.7921574602844894

Epoch: 5| Step: 7
Training loss: 0.3010804355144501
Validation loss: 1.8040225300737607

Epoch: 5| Step: 8
Training loss: 0.26807284355163574
Validation loss: 1.8211926978121522

Epoch: 5| Step: 9
Training loss: 0.3163414001464844
Validation loss: 1.8377175023478847

Epoch: 5| Step: 10
Training loss: 0.43781161308288574
Validation loss: 1.9203177344414495

Epoch: 273| Step: 0
Training loss: 0.5074588060379028
Validation loss: 1.9411946740201724

Epoch: 5| Step: 1
Training loss: 0.7102109789848328
Validation loss: 1.939424330188382

Epoch: 5| Step: 2
Training loss: 0.5480161905288696
Validation loss: 1.8986579936037782

Epoch: 5| Step: 3
Training loss: 0.5631508827209473
Validation loss: 1.8844096820841554

Epoch: 5| Step: 4
Training loss: 0.6395472288131714
Validation loss: 1.8493144178903231

Epoch: 5| Step: 5
Training loss: 0.38200029730796814
Validation loss: 1.8183966913530905

Epoch: 5| Step: 6
Training loss: 0.47312816977500916
Validation loss: 1.7735580000826108

Epoch: 5| Step: 7
Training loss: 0.37725675106048584
Validation loss: 1.7168138052827568

Epoch: 5| Step: 8
Training loss: 0.20869123935699463
Validation loss: 1.6972612565563572

Epoch: 5| Step: 9
Training loss: 0.4929150640964508
Validation loss: 1.6923129571381437

Epoch: 5| Step: 10
Training loss: 0.26739025115966797
Validation loss: 1.6734776727614864

Epoch: 274| Step: 0
Training loss: 0.4559996724128723
Validation loss: 1.685882451713726

Epoch: 5| Step: 1
Training loss: 0.44833335280418396
Validation loss: 1.6726402659570017

Epoch: 5| Step: 2
Training loss: 0.5381808280944824
Validation loss: 1.6631473046477123

Epoch: 5| Step: 3
Training loss: 0.37651318311691284
Validation loss: 1.7250225454248407

Epoch: 5| Step: 4
Training loss: 0.4424710273742676
Validation loss: 1.765470354787765

Epoch: 5| Step: 5
Training loss: 0.4486226439476013
Validation loss: 1.7582560495663715

Epoch: 5| Step: 6
Training loss: 0.5827862024307251
Validation loss: 1.8017934342866302

Epoch: 5| Step: 7
Training loss: 0.29160720109939575
Validation loss: 1.8520546382473362

Epoch: 5| Step: 8
Training loss: 0.5259706377983093
Validation loss: 1.8574837151394095

Epoch: 5| Step: 9
Training loss: 0.39932703971862793
Validation loss: 1.86619649523048

Epoch: 5| Step: 10
Training loss: 0.4369564950466156
Validation loss: 1.8837073849093529

Epoch: 275| Step: 0
Training loss: 0.28937509655952454
Validation loss: 1.8290789178622666

Epoch: 5| Step: 1
Training loss: 0.3897565007209778
Validation loss: 1.791237392733174

Epoch: 5| Step: 2
Training loss: 0.4856172502040863
Validation loss: 1.7728716711844168

Epoch: 5| Step: 3
Training loss: 0.3507811427116394
Validation loss: 1.7423966264212003

Epoch: 5| Step: 4
Training loss: 0.495687872171402
Validation loss: 1.7076500385038313

Epoch: 5| Step: 5
Training loss: 0.3413437306880951
Validation loss: 1.7078255978963708

Epoch: 5| Step: 6
Training loss: 0.7465355396270752
Validation loss: 1.7281575369578537

Epoch: 5| Step: 7
Training loss: 0.439610093832016
Validation loss: 1.7488467206237137

Epoch: 5| Step: 8
Training loss: 0.47571858763694763
Validation loss: 1.7536292947748655

Epoch: 5| Step: 9
Training loss: 0.3716149926185608
Validation loss: 1.7808485877129339

Epoch: 5| Step: 10
Training loss: 0.281690388917923
Validation loss: 1.7734338673212195

Epoch: 276| Step: 0
Training loss: 0.5205039978027344
Validation loss: 1.7820414920007028

Epoch: 5| Step: 1
Training loss: 0.3645399212837219
Validation loss: 1.7764574853322839

Epoch: 5| Step: 2
Training loss: 0.3757621943950653
Validation loss: 1.8016611068479476

Epoch: 5| Step: 3
Training loss: 0.47892171144485474
Validation loss: 1.783934973901318

Epoch: 5| Step: 4
Training loss: 0.5287183523178101
Validation loss: 1.7743070125579834

Epoch: 5| Step: 5
Training loss: 0.45526018738746643
Validation loss: 1.7764485113082393

Epoch: 5| Step: 6
Training loss: 0.31420812010765076
Validation loss: 1.7671439211855653

Epoch: 5| Step: 7
Training loss: 0.5876584649085999
Validation loss: 1.783812903588818

Epoch: 5| Step: 8
Training loss: 0.3080097436904907
Validation loss: 1.80442274514065

Epoch: 5| Step: 9
Training loss: 0.42689386010169983
Validation loss: 1.7868236892966813

Epoch: 5| Step: 10
Training loss: 0.39724984765052795
Validation loss: 1.840459938972227

Epoch: 277| Step: 0
Training loss: 0.31346726417541504
Validation loss: 1.8353740579338484

Epoch: 5| Step: 1
Training loss: 0.7297610640525818
Validation loss: 1.8018653649155811

Epoch: 5| Step: 2
Training loss: 0.329007089138031
Validation loss: 1.7857558893901047

Epoch: 5| Step: 3
Training loss: 0.3095352053642273
Validation loss: 1.7344222722514984

Epoch: 5| Step: 4
Training loss: 0.5121814012527466
Validation loss: 1.7079998024048344

Epoch: 5| Step: 5
Training loss: 0.548376202583313
Validation loss: 1.6723464650492514

Epoch: 5| Step: 6
Training loss: 0.4396122097969055
Validation loss: 1.6900563752779396

Epoch: 5| Step: 7
Training loss: 0.23361878097057343
Validation loss: 1.677529461922184

Epoch: 5| Step: 8
Training loss: 0.5135504007339478
Validation loss: 1.6866148517977806

Epoch: 5| Step: 9
Training loss: 0.5450088977813721
Validation loss: 1.749974170038777

Epoch: 5| Step: 10
Training loss: 0.3789424002170563
Validation loss: 1.7839958975392003

Epoch: 278| Step: 0
Training loss: 0.4231263995170593
Validation loss: 1.8788257978295768

Epoch: 5| Step: 1
Training loss: 0.5608252286911011
Validation loss: 1.8851030641986477

Epoch: 5| Step: 2
Training loss: 0.7492421865463257
Validation loss: 1.835197397457656

Epoch: 5| Step: 3
Training loss: 0.3387916684150696
Validation loss: 1.787702706552321

Epoch: 5| Step: 4
Training loss: 0.47124773263931274
Validation loss: 1.7557885877547725

Epoch: 5| Step: 5
Training loss: 0.3456304967403412
Validation loss: 1.7553649769034436

Epoch: 5| Step: 6
Training loss: 0.3794071078300476
Validation loss: 1.7354288895924885

Epoch: 5| Step: 7
Training loss: 0.3363558053970337
Validation loss: 1.7606206606793147

Epoch: 5| Step: 8
Training loss: 0.42837756872177124
Validation loss: 1.7689494625214608

Epoch: 5| Step: 9
Training loss: 0.5769580602645874
Validation loss: 1.7994718295271679

Epoch: 5| Step: 10
Training loss: 0.46048617362976074
Validation loss: 1.8120558620781027

Epoch: 279| Step: 0
Training loss: 0.7271395921707153
Validation loss: 1.832889005702029

Epoch: 5| Step: 1
Training loss: 0.4174206256866455
Validation loss: 1.8663820867897363

Epoch: 5| Step: 2
Training loss: 0.4711906909942627
Validation loss: 1.832469291584466

Epoch: 5| Step: 3
Training loss: 0.33651256561279297
Validation loss: 1.8221088327387327

Epoch: 5| Step: 4
Training loss: 0.3287068009376526
Validation loss: 1.7821004083079677

Epoch: 5| Step: 5
Training loss: 0.4134097695350647
Validation loss: 1.7267005623027842

Epoch: 5| Step: 6
Training loss: 0.551726222038269
Validation loss: 1.7011229075411314

Epoch: 5| Step: 7
Training loss: 0.41536036133766174
Validation loss: 1.6887653527721282

Epoch: 5| Step: 8
Training loss: 0.46252912282943726
Validation loss: 1.7047584761855423

Epoch: 5| Step: 9
Training loss: 0.45051759481430054
Validation loss: 1.7302000150885632

Epoch: 5| Step: 10
Training loss: 0.2505226135253906
Validation loss: 1.7182378384374803

Epoch: 280| Step: 0
Training loss: 0.22242462635040283
Validation loss: 1.749518488043098

Epoch: 5| Step: 1
Training loss: 0.3454117178916931
Validation loss: 1.7669511238733928

Epoch: 5| Step: 2
Training loss: 0.3124142289161682
Validation loss: 1.8069264504217333

Epoch: 5| Step: 3
Training loss: 0.34523633122444153
Validation loss: 1.823966650552647

Epoch: 5| Step: 4
Training loss: 0.6155675649642944
Validation loss: 1.799983746262007

Epoch: 5| Step: 5
Training loss: 0.6426555514335632
Validation loss: 1.784993948475007

Epoch: 5| Step: 6
Training loss: 0.2951943278312683
Validation loss: 1.7975141861105477

Epoch: 5| Step: 7
Training loss: 0.40096551179885864
Validation loss: 1.7771888689328266

Epoch: 5| Step: 8
Training loss: 0.24219968914985657
Validation loss: 1.7424550915277133

Epoch: 5| Step: 9
Training loss: 0.6918502449989319
Validation loss: 1.723345237393533

Epoch: 5| Step: 10
Training loss: 0.39522919058799744
Validation loss: 1.6933708178099764

Epoch: 281| Step: 0
Training loss: 0.5078672170639038
Validation loss: 1.6711624360853625

Epoch: 5| Step: 1
Training loss: 0.5523748397827148
Validation loss: 1.6756261164142239

Epoch: 5| Step: 2
Training loss: 0.29178541898727417
Validation loss: 1.714178664709932

Epoch: 5| Step: 3
Training loss: 0.4305292069911957
Validation loss: 1.7050859415402977

Epoch: 5| Step: 4
Training loss: 0.5922853350639343
Validation loss: 1.7518207168066373

Epoch: 5| Step: 5
Training loss: 0.2546288073062897
Validation loss: 1.7924440342892882

Epoch: 5| Step: 6
Training loss: 0.4749033451080322
Validation loss: 1.8267176599912747

Epoch: 5| Step: 7
Training loss: 0.41847342252731323
Validation loss: 1.8114313669102167

Epoch: 5| Step: 8
Training loss: 0.437781423330307
Validation loss: 1.8291238854008336

Epoch: 5| Step: 9
Training loss: 0.31767019629478455
Validation loss: 1.7987044754848684

Epoch: 5| Step: 10
Training loss: 0.390157014131546
Validation loss: 1.7961402298301778

Epoch: 282| Step: 0
Training loss: 0.46883806586265564
Validation loss: 1.743971379854346

Epoch: 5| Step: 1
Training loss: 0.39028653502464294
Validation loss: 1.724023021677489

Epoch: 5| Step: 2
Training loss: 0.5760909914970398
Validation loss: 1.7157831474017071

Epoch: 5| Step: 3
Training loss: 0.45772257447242737
Validation loss: 1.71129653018008

Epoch: 5| Step: 4
Training loss: 0.338279664516449
Validation loss: 1.7063076291033017

Epoch: 5| Step: 5
Training loss: 0.2874062955379486
Validation loss: 1.714417214034706

Epoch: 5| Step: 6
Training loss: 0.5014707446098328
Validation loss: 1.724545544193637

Epoch: 5| Step: 7
Training loss: 0.3851121664047241
Validation loss: 1.7348090423050748

Epoch: 5| Step: 8
Training loss: 0.22019657492637634
Validation loss: 1.8040606360281668

Epoch: 5| Step: 9
Training loss: 0.37439265847206116
Validation loss: 1.8063363311111287

Epoch: 5| Step: 10
Training loss: 0.5158259272575378
Validation loss: 1.8237064269281202

Epoch: 283| Step: 0
Training loss: 0.32176122069358826
Validation loss: 1.8149745836052844

Epoch: 5| Step: 1
Training loss: 0.24686472117900848
Validation loss: 1.7835689898460143

Epoch: 5| Step: 2
Training loss: 0.2848619818687439
Validation loss: 1.7555761741053673

Epoch: 5| Step: 3
Training loss: 0.5384469628334045
Validation loss: 1.7570047173448788

Epoch: 5| Step: 4
Training loss: 0.26947641372680664
Validation loss: 1.7311706453241327

Epoch: 5| Step: 5
Training loss: 0.6837959289550781
Validation loss: 1.7085795069253573

Epoch: 5| Step: 6
Training loss: 0.3470911383628845
Validation loss: 1.7187355372213549

Epoch: 5| Step: 7
Training loss: 0.6853803396224976
Validation loss: 1.7143785133156726

Epoch: 5| Step: 8
Training loss: 0.29371950030326843
Validation loss: 1.7478763928977392

Epoch: 5| Step: 9
Training loss: 0.5189881324768066
Validation loss: 1.7488136009503437

Epoch: 5| Step: 10
Training loss: 0.37414756417274475
Validation loss: 1.7591493886004212

Epoch: 284| Step: 0
Training loss: 0.403289794921875
Validation loss: 1.767540612528401

Epoch: 5| Step: 1
Training loss: 0.29757601022720337
Validation loss: 1.759455139918994

Epoch: 5| Step: 2
Training loss: 0.32167932391166687
Validation loss: 1.7704376866740565

Epoch: 5| Step: 3
Training loss: 0.20644250512123108
Validation loss: 1.718081183330987

Epoch: 5| Step: 4
Training loss: 0.4178904891014099
Validation loss: 1.7480510127159856

Epoch: 5| Step: 5
Training loss: 0.5398061871528625
Validation loss: 1.7492104704662035

Epoch: 5| Step: 6
Training loss: 0.3194909989833832
Validation loss: 1.7641514655082458

Epoch: 5| Step: 7
Training loss: 0.436722993850708
Validation loss: 1.7677125584694646

Epoch: 5| Step: 8
Training loss: 0.2904367744922638
Validation loss: 1.7388344887764222

Epoch: 5| Step: 9
Training loss: 0.5548497438430786
Validation loss: 1.7390993500268588

Epoch: 5| Step: 10
Training loss: 0.5787095427513123
Validation loss: 1.7089285888979513

Epoch: 285| Step: 0
Training loss: 0.5671702027320862
Validation loss: 1.751881581480785

Epoch: 5| Step: 1
Training loss: 0.24317702651023865
Validation loss: 1.7729390680149038

Epoch: 5| Step: 2
Training loss: 0.4654856324195862
Validation loss: 1.8389985689552881

Epoch: 5| Step: 3
Training loss: 0.5397206544876099
Validation loss: 1.865230465448031

Epoch: 5| Step: 4
Training loss: 0.4441397786140442
Validation loss: 1.8552789585564726

Epoch: 5| Step: 5
Training loss: 0.5118357539176941
Validation loss: 1.7821210661242086

Epoch: 5| Step: 6
Training loss: 0.5624942779541016
Validation loss: 1.709641351494738

Epoch: 5| Step: 7
Training loss: 0.36103156208992004
Validation loss: 1.6443246026192941

Epoch: 5| Step: 8
Training loss: 0.6691827774047852
Validation loss: 1.675682678017565

Epoch: 5| Step: 9
Training loss: 0.307365357875824
Validation loss: 1.6567828783424952

Epoch: 5| Step: 10
Training loss: 0.30333125591278076
Validation loss: 1.6606119531457142

Epoch: 286| Step: 0
Training loss: 0.5937327146530151
Validation loss: 1.6876127527606102

Epoch: 5| Step: 1
Training loss: 0.4902478754520416
Validation loss: 1.7656417405733498

Epoch: 5| Step: 2
Training loss: 0.5023199915885925
Validation loss: 1.8009917620689637

Epoch: 5| Step: 3
Training loss: 0.4348706603050232
Validation loss: 1.8240031414134528

Epoch: 5| Step: 4
Training loss: 0.2991548180580139
Validation loss: 1.827917323317579

Epoch: 5| Step: 5
Training loss: 0.30157169699668884
Validation loss: 1.7934665000566872

Epoch: 5| Step: 6
Training loss: 0.42170223593711853
Validation loss: 1.798967364013836

Epoch: 5| Step: 7
Training loss: 0.4973016679286957
Validation loss: 1.7908212061851256

Epoch: 5| Step: 8
Training loss: 0.31860703229904175
Validation loss: 1.761075137763895

Epoch: 5| Step: 9
Training loss: 0.24788852035999298
Validation loss: 1.7527444619004444

Epoch: 5| Step: 10
Training loss: 0.4756217300891876
Validation loss: 1.7487581083851476

Epoch: 287| Step: 0
Training loss: 0.29609256982803345
Validation loss: 1.7212438198827928

Epoch: 5| Step: 1
Training loss: 0.6060848236083984
Validation loss: 1.7497641194251277

Epoch: 5| Step: 2
Training loss: 0.36794978380203247
Validation loss: 1.7491976855903544

Epoch: 5| Step: 3
Training loss: 0.3705677390098572
Validation loss: 1.8051683851467666

Epoch: 5| Step: 4
Training loss: 0.5471664667129517
Validation loss: 1.7861557288836407

Epoch: 5| Step: 5
Training loss: 0.4826938509941101
Validation loss: 1.7713464113973802

Epoch: 5| Step: 6
Training loss: 0.4238794445991516
Validation loss: 1.766502482916719

Epoch: 5| Step: 7
Training loss: 0.4521781802177429
Validation loss: 1.7740854396614978

Epoch: 5| Step: 8
Training loss: 0.35556602478027344
Validation loss: 1.8167527362864504

Epoch: 5| Step: 9
Training loss: 0.4405384957790375
Validation loss: 1.8238845307339904

Epoch: 5| Step: 10
Training loss: 0.6199401617050171
Validation loss: 1.8124926551695792

Epoch: 288| Step: 0
Training loss: 0.6488542556762695
Validation loss: 1.8452668984731038

Epoch: 5| Step: 1
Training loss: 0.3342592418193817
Validation loss: 1.8471019537218156

Epoch: 5| Step: 2
Training loss: 0.2767467200756073
Validation loss: 1.8655839402188537

Epoch: 5| Step: 3
Training loss: 0.644655168056488
Validation loss: 1.8121636298394972

Epoch: 5| Step: 4
Training loss: 0.5610218644142151
Validation loss: 1.7744043309201476

Epoch: 5| Step: 5
Training loss: 0.3369658589363098
Validation loss: 1.7103999109678372

Epoch: 5| Step: 6
Training loss: 0.4510280191898346
Validation loss: 1.7183899956364785

Epoch: 5| Step: 7
Training loss: 0.4684669077396393
Validation loss: 1.6940531538378807

Epoch: 5| Step: 8
Training loss: 0.25212377309799194
Validation loss: 1.7104279456600067

Epoch: 5| Step: 9
Training loss: 0.221015065908432
Validation loss: 1.7421309409602996

Epoch: 5| Step: 10
Training loss: 0.463634729385376
Validation loss: 1.7659246947175713

Epoch: 289| Step: 0
Training loss: 0.3673521876335144
Validation loss: 1.8037809864167245

Epoch: 5| Step: 1
Training loss: 0.4646528363227844
Validation loss: 1.7813244904241254

Epoch: 5| Step: 2
Training loss: 0.3458591103553772
Validation loss: 1.7855209458258845

Epoch: 5| Step: 3
Training loss: 0.18423834443092346
Validation loss: 1.7576673312853741

Epoch: 5| Step: 4
Training loss: 0.22037068009376526
Validation loss: 1.7609277233000724

Epoch: 5| Step: 5
Training loss: 0.4066263735294342
Validation loss: 1.7513602677211966

Epoch: 5| Step: 6
Training loss: 0.6722074747085571
Validation loss: 1.7637732349416262

Epoch: 5| Step: 7
Training loss: 0.3935084342956543
Validation loss: 1.756528603133335

Epoch: 5| Step: 8
Training loss: 0.39521560072898865
Validation loss: 1.7276252008253528

Epoch: 5| Step: 9
Training loss: 0.4433823525905609
Validation loss: 1.7212406755775533

Epoch: 5| Step: 10
Training loss: 0.2997940480709076
Validation loss: 1.6745963545255764

Epoch: 290| Step: 0
Training loss: 0.4148320257663727
Validation loss: 1.6635793165494037

Epoch: 5| Step: 1
Training loss: 0.5497055649757385
Validation loss: 1.6608936799469816

Epoch: 5| Step: 2
Training loss: 0.47348102927207947
Validation loss: 1.6482244768450338

Epoch: 5| Step: 3
Training loss: 0.27510783076286316
Validation loss: 1.6559357130399315

Epoch: 5| Step: 4
Training loss: 0.26960986852645874
Validation loss: 1.6765923525697441

Epoch: 5| Step: 5
Training loss: 0.37325581908226013
Validation loss: 1.6830765790836786

Epoch: 5| Step: 6
Training loss: 0.4740903973579407
Validation loss: 1.7170060680758568

Epoch: 5| Step: 7
Training loss: 0.4350249171257019
Validation loss: 1.7203722384668165

Epoch: 5| Step: 8
Training loss: 0.26185885071754456
Validation loss: 1.7246141856716526

Epoch: 5| Step: 9
Training loss: 0.26293063163757324
Validation loss: 1.7322923726932977

Epoch: 5| Step: 10
Training loss: 0.3465019166469574
Validation loss: 1.7460986042535434

Epoch: 291| Step: 0
Training loss: 0.2980910837650299
Validation loss: 1.7638891294438352

Epoch: 5| Step: 1
Training loss: 0.5588716268539429
Validation loss: 1.7559490332039454

Epoch: 5| Step: 2
Training loss: 0.24780838191509247
Validation loss: 1.753507496208273

Epoch: 5| Step: 3
Training loss: 0.14864535629749298
Validation loss: 1.7712902356219549

Epoch: 5| Step: 4
Training loss: 0.5312947034835815
Validation loss: 1.7877016810960666

Epoch: 5| Step: 5
Training loss: 0.20919695496559143
Validation loss: 1.7719333505117765

Epoch: 5| Step: 6
Training loss: 0.29647576808929443
Validation loss: 1.7742789842749154

Epoch: 5| Step: 7
Training loss: 0.3828432857990265
Validation loss: 1.7625629901885986

Epoch: 5| Step: 8
Training loss: 0.7188096046447754
Validation loss: 1.727491069865483

Epoch: 5| Step: 9
Training loss: 0.2710084319114685
Validation loss: 1.6879986255399642

Epoch: 5| Step: 10
Training loss: 0.41538146138191223
Validation loss: 1.662513267609381

Epoch: 292| Step: 0
Training loss: 0.3352598249912262
Validation loss: 1.6972871083085255

Epoch: 5| Step: 1
Training loss: 0.3085120916366577
Validation loss: 1.6945220334555513

Epoch: 5| Step: 2
Training loss: 0.32383862137794495
Validation loss: 1.745917442024395

Epoch: 5| Step: 3
Training loss: 0.25788038969039917
Validation loss: 1.779837417346175

Epoch: 5| Step: 4
Training loss: 0.49498337507247925
Validation loss: 1.785408313556384

Epoch: 5| Step: 5
Training loss: 0.4636126458644867
Validation loss: 1.7744540604211951

Epoch: 5| Step: 6
Training loss: 0.4324682354927063
Validation loss: 1.7068627290828253

Epoch: 5| Step: 7
Training loss: 0.28558000922203064
Validation loss: 1.6877656393153693

Epoch: 5| Step: 8
Training loss: 0.2930990755558014
Validation loss: 1.6359506037927443

Epoch: 5| Step: 9
Training loss: 0.6568366289138794
Validation loss: 1.6124297662447857

Epoch: 5| Step: 10
Training loss: 0.4430123567581177
Validation loss: 1.6383129845383346

Epoch: 293| Step: 0
Training loss: 0.3918420970439911
Validation loss: 1.6563363190620177

Epoch: 5| Step: 1
Training loss: 0.5149495005607605
Validation loss: 1.7045466848599014

Epoch: 5| Step: 2
Training loss: 0.32206594944000244
Validation loss: 1.7333196670778337

Epoch: 5| Step: 3
Training loss: 0.42834311723709106
Validation loss: 1.742243520675167

Epoch: 5| Step: 4
Training loss: 0.23357558250427246
Validation loss: 1.7749620868313698

Epoch: 5| Step: 5
Training loss: 0.2613648772239685
Validation loss: 1.7562420240012548

Epoch: 5| Step: 6
Training loss: 0.30002012848854065
Validation loss: 1.7211395053453342

Epoch: 5| Step: 7
Training loss: 0.43790197372436523
Validation loss: 1.6751052538553874

Epoch: 5| Step: 8
Training loss: 0.34983664751052856
Validation loss: 1.6515803221733338

Epoch: 5| Step: 9
Training loss: 0.6029051542282104
Validation loss: 1.6878681849407893

Epoch: 5| Step: 10
Training loss: 0.3899195194244385
Validation loss: 1.666286677442571

Epoch: 294| Step: 0
Training loss: 0.40516096353530884
Validation loss: 1.6812720939677248

Epoch: 5| Step: 1
Training loss: 0.2821076214313507
Validation loss: 1.7228113041129163

Epoch: 5| Step: 2
Training loss: 0.30616462230682373
Validation loss: 1.7762967078916487

Epoch: 5| Step: 3
Training loss: 0.5954797863960266
Validation loss: 1.8374282813841296

Epoch: 5| Step: 4
Training loss: 0.2456304281949997
Validation loss: 1.8586191208131853

Epoch: 5| Step: 5
Training loss: 0.3312022089958191
Validation loss: 1.8202373443111297

Epoch: 5| Step: 6
Training loss: 0.37170305848121643
Validation loss: 1.7673861108800417

Epoch: 5| Step: 7
Training loss: 0.4518962502479553
Validation loss: 1.7024661328202935

Epoch: 5| Step: 8
Training loss: 0.3730299174785614
Validation loss: 1.6753149288956837

Epoch: 5| Step: 9
Training loss: 0.42877358198165894
Validation loss: 1.6373825419333674

Epoch: 5| Step: 10
Training loss: 0.4414340853691101
Validation loss: 1.6438444391373666

Epoch: 295| Step: 0
Training loss: 0.5440881848335266
Validation loss: 1.6413835005093647

Epoch: 5| Step: 1
Training loss: 0.3405701220035553
Validation loss: 1.653792449223098

Epoch: 5| Step: 2
Training loss: 0.3481346368789673
Validation loss: 1.6616399518905147

Epoch: 5| Step: 3
Training loss: 0.47638922929763794
Validation loss: 1.7124274648645872

Epoch: 5| Step: 4
Training loss: 0.3558427393436432
Validation loss: 1.7656891961251535

Epoch: 5| Step: 5
Training loss: 0.4985949397087097
Validation loss: 1.854690682503485

Epoch: 5| Step: 6
Training loss: 0.4650003910064697
Validation loss: 1.9068927944347422

Epoch: 5| Step: 7
Training loss: 0.5100611448287964
Validation loss: 1.8405104811473558

Epoch: 5| Step: 8
Training loss: 0.4838030934333801
Validation loss: 1.8033215038238033

Epoch: 5| Step: 9
Training loss: 0.5217646360397339
Validation loss: 1.7225381353850007

Epoch: 5| Step: 10
Training loss: 0.3380745053291321
Validation loss: 1.6895831233711653

Epoch: 296| Step: 0
Training loss: 0.5238552093505859
Validation loss: 1.6487740957608787

Epoch: 5| Step: 1
Training loss: 0.3690010905265808
Validation loss: 1.664364130266251

Epoch: 5| Step: 2
Training loss: 0.5657738447189331
Validation loss: 1.6802894710212626

Epoch: 5| Step: 3
Training loss: 0.27751240134239197
Validation loss: 1.6722714580515379

Epoch: 5| Step: 4
Training loss: 0.30518487095832825
Validation loss: 1.7543610270305345

Epoch: 5| Step: 5
Training loss: 0.27120059728622437
Validation loss: 1.8245169962606123

Epoch: 5| Step: 6
Training loss: 0.47910842299461365
Validation loss: 1.8579904853656728

Epoch: 5| Step: 7
Training loss: 0.27444297075271606
Validation loss: 1.8932664791742961

Epoch: 5| Step: 8
Training loss: 0.39496222138404846
Validation loss: 1.9194565408973283

Epoch: 5| Step: 9
Training loss: 0.6080835461616516
Validation loss: 1.9144740925040296

Epoch: 5| Step: 10
Training loss: 0.48754265904426575
Validation loss: 1.8458192822753743

Epoch: 297| Step: 0
Training loss: 0.42786112427711487
Validation loss: 1.7486849420814103

Epoch: 5| Step: 1
Training loss: 0.24825718998908997
Validation loss: 1.7368556658426921

Epoch: 5| Step: 2
Training loss: 0.3495105803012848
Validation loss: 1.7178224491816696

Epoch: 5| Step: 3
Training loss: 0.4453677535057068
Validation loss: 1.674307434789596

Epoch: 5| Step: 4
Training loss: 0.3797285258769989
Validation loss: 1.7048503609113796

Epoch: 5| Step: 5
Training loss: 0.49408024549484253
Validation loss: 1.7184036982956754

Epoch: 5| Step: 6
Training loss: 0.23197820782661438
Validation loss: 1.7400272559094172

Epoch: 5| Step: 7
Training loss: 0.34036731719970703
Validation loss: 1.762614175837527

Epoch: 5| Step: 8
Training loss: 0.424349844455719
Validation loss: 1.7861546777909802

Epoch: 5| Step: 9
Training loss: 0.3505007326602936
Validation loss: 1.7886359217346355

Epoch: 5| Step: 10
Training loss: 0.45459964871406555
Validation loss: 1.79393171751371

Epoch: 298| Step: 0
Training loss: 0.3642823100090027
Validation loss: 1.8146576343044158

Epoch: 5| Step: 1
Training loss: 0.2934889793395996
Validation loss: 1.8234985374635266

Epoch: 5| Step: 2
Training loss: 0.4594990313053131
Validation loss: 1.8082110702350576

Epoch: 5| Step: 3
Training loss: 0.44073930382728577
Validation loss: 1.7698517614795315

Epoch: 5| Step: 4
Training loss: 0.34732896089553833
Validation loss: 1.7250717519431986

Epoch: 5| Step: 5
Training loss: 0.2590254843235016
Validation loss: 1.6834128172166887

Epoch: 5| Step: 6
Training loss: 0.48795193433761597
Validation loss: 1.6926234614464544

Epoch: 5| Step: 7
Training loss: 0.2642969489097595
Validation loss: 1.702207285870788

Epoch: 5| Step: 8
Training loss: 0.3587859570980072
Validation loss: 1.6969343372570571

Epoch: 5| Step: 9
Training loss: 0.4839293360710144
Validation loss: 1.683578719374954

Epoch: 5| Step: 10
Training loss: 0.2017093300819397
Validation loss: 1.7089473560292234

Epoch: 299| Step: 0
Training loss: 0.31523409485816956
Validation loss: 1.739571427786222

Epoch: 5| Step: 1
Training loss: 0.2061961591243744
Validation loss: 1.7588703709263955

Epoch: 5| Step: 2
Training loss: 0.3197779953479767
Validation loss: 1.7503223778099142

Epoch: 5| Step: 3
Training loss: 0.2965308129787445
Validation loss: 1.7555869266551027

Epoch: 5| Step: 4
Training loss: 0.3625653386116028
Validation loss: 1.7566502760815363

Epoch: 5| Step: 5
Training loss: 0.32989007234573364
Validation loss: 1.7405375549870152

Epoch: 5| Step: 6
Training loss: 0.5068414807319641
Validation loss: 1.7480915925836051

Epoch: 5| Step: 7
Training loss: 0.4020465910434723
Validation loss: 1.7114718678177043

Epoch: 5| Step: 8
Training loss: 0.28115272521972656
Validation loss: 1.7077463647370696

Epoch: 5| Step: 9
Training loss: 0.3459397852420807
Validation loss: 1.6966001205546881

Epoch: 5| Step: 10
Training loss: 0.5632435083389282
Validation loss: 1.70585831006368

Epoch: 300| Step: 0
Training loss: 0.20556113123893738
Validation loss: 1.6996240641481133

Epoch: 5| Step: 1
Training loss: 0.3552910387516022
Validation loss: 1.7002846605034285

Epoch: 5| Step: 2
Training loss: 0.34317246079444885
Validation loss: 1.6940573646176247

Epoch: 5| Step: 3
Training loss: 0.38325563073158264
Validation loss: 1.70222887685222

Epoch: 5| Step: 4
Training loss: 0.3812111020088196
Validation loss: 1.761270156470678

Epoch: 5| Step: 5
Training loss: 0.4348611831665039
Validation loss: 1.7488457067038423

Epoch: 5| Step: 6
Training loss: 0.33843129873275757
Validation loss: 1.7783022106334727

Epoch: 5| Step: 7
Training loss: 0.2331048548221588
Validation loss: 1.7734256508529826

Epoch: 5| Step: 8
Training loss: 0.485635370016098
Validation loss: 1.7243262555009575

Epoch: 5| Step: 9
Training loss: 0.39644309878349304
Validation loss: 1.7266402988023655

Epoch: 5| Step: 10
Training loss: 0.3145899474620819
Validation loss: 1.7317883378715926

Epoch: 301| Step: 0
Training loss: 0.5800382494926453
Validation loss: 1.7504898450707878

Epoch: 5| Step: 1
Training loss: 0.2400909960269928
Validation loss: 1.7664217641276698

Epoch: 5| Step: 2
Training loss: 0.3389400839805603
Validation loss: 1.7594482898712158

Epoch: 5| Step: 3
Training loss: 0.2656278610229492
Validation loss: 1.7661880793110016

Epoch: 5| Step: 4
Training loss: 0.3479635715484619
Validation loss: 1.724016135738742

Epoch: 5| Step: 5
Training loss: 0.3496033251285553
Validation loss: 1.7065696447126326

Epoch: 5| Step: 6
Training loss: 0.2741355895996094
Validation loss: 1.703191177819365

Epoch: 5| Step: 7
Training loss: 0.3697894215583801
Validation loss: 1.7024507407219178

Epoch: 5| Step: 8
Training loss: 0.4229988157749176
Validation loss: 1.6812965472539265

Epoch: 5| Step: 9
Training loss: 0.3485001027584076
Validation loss: 1.6934862047113397

Epoch: 5| Step: 10
Training loss: 0.40464499592781067
Validation loss: 1.705652234374836

Epoch: 302| Step: 0
Training loss: 0.297301709651947
Validation loss: 1.720844789217877

Epoch: 5| Step: 1
Training loss: 0.37363091111183167
Validation loss: 1.75966461243168

Epoch: 5| Step: 2
Training loss: 0.38916289806365967
Validation loss: 1.7727129754199777

Epoch: 5| Step: 3
Training loss: 0.30679863691329956
Validation loss: 1.7581406075467345

Epoch: 5| Step: 4
Training loss: 0.4495042860507965
Validation loss: 1.7602891101632068

Epoch: 5| Step: 5
Training loss: 0.34785348176956177
Validation loss: 1.773670369578946

Epoch: 5| Step: 6
Training loss: 0.30849650502204895
Validation loss: 1.7398963718004123

Epoch: 5| Step: 7
Training loss: 0.13261130452156067
Validation loss: 1.7032626444293606

Epoch: 5| Step: 8
Training loss: 0.4745045602321625
Validation loss: 1.6768602273797477

Epoch: 5| Step: 9
Training loss: 0.26882919669151306
Validation loss: 1.6778732756132722

Epoch: 5| Step: 10
Training loss: 0.32113468647003174
Validation loss: 1.6553240988844184

Epoch: 303| Step: 0
Training loss: 0.2987998127937317
Validation loss: 1.6424337202502834

Epoch: 5| Step: 1
Training loss: 0.2722961902618408
Validation loss: 1.6884126496571366

Epoch: 5| Step: 2
Training loss: 0.38346946239471436
Validation loss: 1.6921196406887424

Epoch: 5| Step: 3
Training loss: 0.23343077301979065
Validation loss: 1.7730705071521062

Epoch: 5| Step: 4
Training loss: 0.3375847041606903
Validation loss: 1.7880098050640476

Epoch: 5| Step: 5
Training loss: 0.5931147336959839
Validation loss: 1.800260970669408

Epoch: 5| Step: 6
Training loss: 0.3122432231903076
Validation loss: 1.7880402662420785

Epoch: 5| Step: 7
Training loss: 0.20006398856639862
Validation loss: 1.7866098252675866

Epoch: 5| Step: 8
Training loss: 0.41119012236595154
Validation loss: 1.7754039764404297

Epoch: 5| Step: 9
Training loss: 0.12391874939203262
Validation loss: 1.7850840104523527

Epoch: 5| Step: 10
Training loss: 0.4289715588092804
Validation loss: 1.728400299626012

Epoch: 304| Step: 0
Training loss: 0.5734297633171082
Validation loss: 1.726024652040133

Epoch: 5| Step: 1
Training loss: 0.45090675354003906
Validation loss: 1.6937097105928647

Epoch: 5| Step: 2
Training loss: 0.2833401560783386
Validation loss: 1.7103247514335058

Epoch: 5| Step: 3
Training loss: 0.2275218665599823
Validation loss: 1.7272233001647457

Epoch: 5| Step: 4
Training loss: 0.2554865777492523
Validation loss: 1.7332991643618512

Epoch: 5| Step: 5
Training loss: 0.5387815237045288
Validation loss: 1.7580374966385544

Epoch: 5| Step: 6
Training loss: 0.27351388335227966
Validation loss: 1.7650134191718152

Epoch: 5| Step: 7
Training loss: 0.24135467410087585
Validation loss: 1.7708385259874406

Epoch: 5| Step: 8
Training loss: 0.17938101291656494
Validation loss: 1.7455525372617988

Epoch: 5| Step: 9
Training loss: 0.3408072292804718
Validation loss: 1.7337882877678

Epoch: 5| Step: 10
Training loss: 0.46956944465637207
Validation loss: 1.683186355457511

Epoch: 305| Step: 0
Training loss: 0.3021240234375
Validation loss: 1.7047491945246214

Epoch: 5| Step: 1
Training loss: 0.47671765089035034
Validation loss: 1.7249838946967997

Epoch: 5| Step: 2
Training loss: 0.4124489724636078
Validation loss: 1.7629092970202047

Epoch: 5| Step: 3
Training loss: 0.3025868535041809
Validation loss: 1.8079354583576162

Epoch: 5| Step: 4
Training loss: 0.35251060128211975
Validation loss: 1.833988425552204

Epoch: 5| Step: 5
Training loss: 0.48595255613327026
Validation loss: 1.8809792110996861

Epoch: 5| Step: 6
Training loss: 0.7873067855834961
Validation loss: 1.8877158485433108

Epoch: 5| Step: 7
Training loss: 0.1566733568906784
Validation loss: 1.822770195622598

Epoch: 5| Step: 8
Training loss: 0.226022869348526
Validation loss: 1.7446148369901924

Epoch: 5| Step: 9
Training loss: 0.33559873700141907
Validation loss: 1.6789585903126707

Epoch: 5| Step: 10
Training loss: 0.4280959367752075
Validation loss: 1.6490781396947882

Epoch: 306| Step: 0
Training loss: 0.5582887530326843
Validation loss: 1.626037190037389

Epoch: 5| Step: 1
Training loss: 0.5838348269462585
Validation loss: 1.660005622012641

Epoch: 5| Step: 2
Training loss: 0.2886064052581787
Validation loss: 1.6983329403784968

Epoch: 5| Step: 3
Training loss: 0.3474960923194885
Validation loss: 1.728174219849289

Epoch: 5| Step: 4
Training loss: 0.27717000246047974
Validation loss: 1.730853933160023

Epoch: 5| Step: 5
Training loss: 0.29322248697280884
Validation loss: 1.7510276135577951

Epoch: 5| Step: 6
Training loss: 0.37282660603523254
Validation loss: 1.740855836099194

Epoch: 5| Step: 7
Training loss: 0.19583244621753693
Validation loss: 1.7970635608960224

Epoch: 5| Step: 8
Training loss: 0.1972794383764267
Validation loss: 1.821763946164039

Epoch: 5| Step: 9
Training loss: 0.3827713131904602
Validation loss: 1.7523827962977911

Epoch: 5| Step: 10
Training loss: 0.16630351543426514
Validation loss: 1.767143875040034

Epoch: 307| Step: 0
Training loss: 0.46653756499290466
Validation loss: 1.729512224915207

Epoch: 5| Step: 1
Training loss: 0.381374329328537
Validation loss: 1.7155019320467466

Epoch: 5| Step: 2
Training loss: 0.3145599961280823
Validation loss: 1.7188368843447777

Epoch: 5| Step: 3
Training loss: 0.19430920481681824
Validation loss: 1.6767850575908538

Epoch: 5| Step: 4
Training loss: 0.24471023678779602
Validation loss: 1.6804375674134941

Epoch: 5| Step: 5
Training loss: 0.2910420000553131
Validation loss: 1.723403161571872

Epoch: 5| Step: 6
Training loss: 0.594639003276825
Validation loss: 1.713577042343796

Epoch: 5| Step: 7
Training loss: 0.20954735577106476
Validation loss: 1.7267619281686761

Epoch: 5| Step: 8
Training loss: 0.24999813735485077
Validation loss: 1.7309020847402594

Epoch: 5| Step: 9
Training loss: 0.26376909017562866
Validation loss: 1.7186740425325209

Epoch: 5| Step: 10
Training loss: 0.2529109716415405
Validation loss: 1.672297421322074

Epoch: 308| Step: 0
Training loss: 0.30369335412979126
Validation loss: 1.6689253173848635

Epoch: 5| Step: 1
Training loss: 0.3681814670562744
Validation loss: 1.6626443286095896

Epoch: 5| Step: 2
Training loss: 0.36274653673171997
Validation loss: 1.65689516580233

Epoch: 5| Step: 3
Training loss: 0.30621248483657837
Validation loss: 1.6963546006910262

Epoch: 5| Step: 4
Training loss: 0.30237501859664917
Validation loss: 1.7064453709510066

Epoch: 5| Step: 5
Training loss: 0.4399684965610504
Validation loss: 1.7400332663648872

Epoch: 5| Step: 6
Training loss: 0.3732414245605469
Validation loss: 1.7140250257266465

Epoch: 5| Step: 7
Training loss: 0.20201030373573303
Validation loss: 1.7150398967086629

Epoch: 5| Step: 8
Training loss: 0.2337561547756195
Validation loss: 1.6480607371176443

Epoch: 5| Step: 9
Training loss: 0.2725543677806854
Validation loss: 1.6772649352268507

Epoch: 5| Step: 10
Training loss: 0.13316364586353302
Validation loss: 1.6795549802882697

Epoch: 309| Step: 0
Training loss: 0.4247973561286926
Validation loss: 1.72190954736484

Epoch: 5| Step: 1
Training loss: 0.39797914028167725
Validation loss: 1.7389026047081075

Epoch: 5| Step: 2
Training loss: 0.22629323601722717
Validation loss: 1.72196150595142

Epoch: 5| Step: 3
Training loss: 0.34442466497421265
Validation loss: 1.7586511770884197

Epoch: 5| Step: 4
Training loss: 0.23074328899383545
Validation loss: 1.7310956139718332

Epoch: 5| Step: 5
Training loss: 0.23132824897766113
Validation loss: 1.6988982141658824

Epoch: 5| Step: 6
Training loss: 0.14272388815879822
Validation loss: 1.6832483583881008

Epoch: 5| Step: 7
Training loss: 0.3778509795665741
Validation loss: 1.6736484317369358

Epoch: 5| Step: 8
Training loss: 0.34705525636672974
Validation loss: 1.6495290597279866

Epoch: 5| Step: 9
Training loss: 0.2930639386177063
Validation loss: 1.672298022495803

Epoch: 5| Step: 10
Training loss: 0.3426852226257324
Validation loss: 1.6493145137704828

Epoch: 310| Step: 0
Training loss: 0.35931798815727234
Validation loss: 1.6772338536477858

Epoch: 5| Step: 1
Training loss: 0.19146063923835754
Validation loss: 1.6856959801848217

Epoch: 5| Step: 2
Training loss: 0.25841084122657776
Validation loss: 1.71574628737665

Epoch: 5| Step: 3
Training loss: 0.25488242506980896
Validation loss: 1.7451063381728305

Epoch: 5| Step: 4
Training loss: 0.4504922926425934
Validation loss: 1.700357662734165

Epoch: 5| Step: 5
Training loss: 0.26106175780296326
Validation loss: 1.6816884650978992

Epoch: 5| Step: 6
Training loss: 0.18254432082176208
Validation loss: 1.6810771713974655

Epoch: 5| Step: 7
Training loss: 0.2803858816623688
Validation loss: 1.6461544985412269

Epoch: 5| Step: 8
Training loss: 0.3089197278022766
Validation loss: 1.6688008551956506

Epoch: 5| Step: 9
Training loss: 0.3304813802242279
Validation loss: 1.6909145642352361

Epoch: 5| Step: 10
Training loss: 0.39085718989372253
Validation loss: 1.710670437864078

Epoch: 311| Step: 0
Training loss: 0.3010846674442291
Validation loss: 1.7178327037442116

Epoch: 5| Step: 1
Training loss: 0.25599175691604614
Validation loss: 1.7517149089485087

Epoch: 5| Step: 2
Training loss: 0.33847910165786743
Validation loss: 1.772172802238054

Epoch: 5| Step: 3
Training loss: 0.26568999886512756
Validation loss: 1.7764929674004997

Epoch: 5| Step: 4
Training loss: 0.48067373037338257
Validation loss: 1.7592491667757753

Epoch: 5| Step: 5
Training loss: 0.348708838224411
Validation loss: 1.7410094481642528

Epoch: 5| Step: 6
Training loss: 0.2689046263694763
Validation loss: 1.7470591516904934

Epoch: 5| Step: 7
Training loss: 0.2627066969871521
Validation loss: 1.7563668963729695

Epoch: 5| Step: 8
Training loss: 0.22644534707069397
Validation loss: 1.7460399263648576

Epoch: 5| Step: 9
Training loss: 0.24215355515480042
Validation loss: 1.7612543291943048

Epoch: 5| Step: 10
Training loss: 0.3254646360874176
Validation loss: 1.7930222647164458

Epoch: 312| Step: 0
Training loss: 0.21830818057060242
Validation loss: 1.7740560680307367

Epoch: 5| Step: 1
Training loss: 0.48923951387405396
Validation loss: 1.773990059411654

Epoch: 5| Step: 2
Training loss: 0.15619976818561554
Validation loss: 1.772032945386825

Epoch: 5| Step: 3
Training loss: 0.31258752942085266
Validation loss: 1.7465677645898634

Epoch: 5| Step: 4
Training loss: 0.20722103118896484
Validation loss: 1.7285078815234605

Epoch: 5| Step: 5
Training loss: 0.383307546377182
Validation loss: 1.733777790941218

Epoch: 5| Step: 6
Training loss: 0.20873315632343292
Validation loss: 1.6793151517068186

Epoch: 5| Step: 7
Training loss: 0.2718982696533203
Validation loss: 1.6790081390770533

Epoch: 5| Step: 8
Training loss: 0.3121306896209717
Validation loss: 1.667059705462507

Epoch: 5| Step: 9
Training loss: 0.3612139821052551
Validation loss: 1.6761715976140832

Epoch: 5| Step: 10
Training loss: 0.35659870505332947
Validation loss: 1.7027972487993137

Epoch: 313| Step: 0
Training loss: 0.20739546418190002
Validation loss: 1.7251682448130783

Epoch: 5| Step: 1
Training loss: 0.17768146097660065
Validation loss: 1.7669680208288214

Epoch: 5| Step: 2
Training loss: 0.43441644310951233
Validation loss: 1.8194022922105686

Epoch: 5| Step: 3
Training loss: 0.19103188812732697
Validation loss: 1.8073272499986874

Epoch: 5| Step: 4
Training loss: 0.350536972284317
Validation loss: 1.7765046614472584

Epoch: 5| Step: 5
Training loss: 0.30979838967323303
Validation loss: 1.7669960619300924

Epoch: 5| Step: 6
Training loss: 0.31896889209747314
Validation loss: 1.7228697512739448

Epoch: 5| Step: 7
Training loss: 0.3222557604312897
Validation loss: 1.6757817973372757

Epoch: 5| Step: 8
Training loss: 0.4922422766685486
Validation loss: 1.6309166287863126

Epoch: 5| Step: 9
Training loss: 0.34002885222435
Validation loss: 1.6613487851235174

Epoch: 5| Step: 10
Training loss: 0.3078637421131134
Validation loss: 1.6706299525435253

Epoch: 314| Step: 0
Training loss: 0.31741827726364136
Validation loss: 1.684653523147747

Epoch: 5| Step: 1
Training loss: 0.37899789214134216
Validation loss: 1.6753962168129541

Epoch: 5| Step: 2
Training loss: 0.35532984137535095
Validation loss: 1.716034968694051

Epoch: 5| Step: 3
Training loss: 0.15791869163513184
Validation loss: 1.7592847949715071

Epoch: 5| Step: 4
Training loss: 0.2565768361091614
Validation loss: 1.7888996703650362

Epoch: 5| Step: 5
Training loss: 0.40294894576072693
Validation loss: 1.8134423917339695

Epoch: 5| Step: 6
Training loss: 0.2865540385246277
Validation loss: 1.8512695566300423

Epoch: 5| Step: 7
Training loss: 0.7184769511222839
Validation loss: 1.7898589834090202

Epoch: 5| Step: 8
Training loss: 0.3469618856906891
Validation loss: 1.7743281549023044

Epoch: 5| Step: 9
Training loss: 0.31182846426963806
Validation loss: 1.7133712281462967

Epoch: 5| Step: 10
Training loss: 0.19251523911952972
Validation loss: 1.700510658243651

Epoch: 315| Step: 0
Training loss: 0.33717280626296997
Validation loss: 1.666303265479303

Epoch: 5| Step: 1
Training loss: 0.3298669159412384
Validation loss: 1.6559785873659196

Epoch: 5| Step: 2
Training loss: 0.3461478352546692
Validation loss: 1.6322717743535196

Epoch: 5| Step: 3
Training loss: 0.4490944743156433
Validation loss: 1.655670932544175

Epoch: 5| Step: 4
Training loss: 0.523291289806366
Validation loss: 1.6951945661216654

Epoch: 5| Step: 5
Training loss: 0.23044617474079132
Validation loss: 1.7137461067527853

Epoch: 5| Step: 6
Training loss: 0.22736454010009766
Validation loss: 1.747676412264506

Epoch: 5| Step: 7
Training loss: 0.22259263694286346
Validation loss: 1.7259525342654156

Epoch: 5| Step: 8
Training loss: 0.381562739610672
Validation loss: 1.7378909395587059

Epoch: 5| Step: 9
Training loss: 0.29405251145362854
Validation loss: 1.7163986313727595

Epoch: 5| Step: 10
Training loss: 0.20504087209701538
Validation loss: 1.7229391810714558

Epoch: 316| Step: 0
Training loss: 0.2909867465496063
Validation loss: 1.7241443472523843

Epoch: 5| Step: 1
Training loss: 0.25793707370758057
Validation loss: 1.7556777128609278

Epoch: 5| Step: 2
Training loss: 0.3582017719745636
Validation loss: 1.7469245233843405

Epoch: 5| Step: 3
Training loss: 0.29046911001205444
Validation loss: 1.724743781551238

Epoch: 5| Step: 4
Training loss: 0.25285062193870544
Validation loss: 1.7580093529916578

Epoch: 5| Step: 5
Training loss: 0.3491998016834259
Validation loss: 1.7461394776580155

Epoch: 5| Step: 6
Training loss: 0.21702823042869568
Validation loss: 1.7466586200139855

Epoch: 5| Step: 7
Training loss: 0.16472570598125458
Validation loss: 1.7445487405664177

Epoch: 5| Step: 8
Training loss: 0.28120678663253784
Validation loss: 1.7182510642595188

Epoch: 5| Step: 9
Training loss: 0.299430787563324
Validation loss: 1.6945149398619128

Epoch: 5| Step: 10
Training loss: 0.4484102129936218
Validation loss: 1.671976444541767

Epoch: 317| Step: 0
Training loss: 0.3278450667858124
Validation loss: 1.6756144441584104

Epoch: 5| Step: 1
Training loss: 0.21800895035266876
Validation loss: 1.668558560391908

Epoch: 5| Step: 2
Training loss: 0.32975107431411743
Validation loss: 1.679082993538149

Epoch: 5| Step: 3
Training loss: 0.27500542998313904
Validation loss: 1.684169428322905

Epoch: 5| Step: 4
Training loss: 0.26378875970840454
Validation loss: 1.683613492596534

Epoch: 5| Step: 5
Training loss: 0.2732231616973877
Validation loss: 1.689830890265844

Epoch: 5| Step: 6
Training loss: 0.23951904475688934
Validation loss: 1.6799747777241532

Epoch: 5| Step: 7
Training loss: 0.3120576739311218
Validation loss: 1.708123637783912

Epoch: 5| Step: 8
Training loss: 0.18005914986133575
Validation loss: 1.711652760864586

Epoch: 5| Step: 9
Training loss: 0.30058830976486206
Validation loss: 1.7140071443332139

Epoch: 5| Step: 10
Training loss: 0.4287241995334625
Validation loss: 1.7536984438537269

Epoch: 318| Step: 0
Training loss: 0.3336631655693054
Validation loss: 1.714148820087474

Epoch: 5| Step: 1
Training loss: 0.2960436940193176
Validation loss: 1.6976573967164563

Epoch: 5| Step: 2
Training loss: 0.19588136672973633
Validation loss: 1.6983673585358487

Epoch: 5| Step: 3
Training loss: 0.2266302853822708
Validation loss: 1.6515761613845825

Epoch: 5| Step: 4
Training loss: 0.37773048877716064
Validation loss: 1.6915253413620817

Epoch: 5| Step: 5
Training loss: 0.3519424796104431
Validation loss: 1.6742925900284962

Epoch: 5| Step: 6
Training loss: 0.2620849907398224
Validation loss: 1.6541309125961796

Epoch: 5| Step: 7
Training loss: 0.22753295302391052
Validation loss: 1.6780946421366867

Epoch: 5| Step: 8
Training loss: 0.2781369388103485
Validation loss: 1.675546714054641

Epoch: 5| Step: 9
Training loss: 0.2510473132133484
Validation loss: 1.656606319130108

Epoch: 5| Step: 10
Training loss: 0.3193680942058563
Validation loss: 1.6920229542639948

Epoch: 319| Step: 0
Training loss: 0.21534959971904755
Validation loss: 1.7147449293444235

Epoch: 5| Step: 1
Training loss: 0.2695876955986023
Validation loss: 1.6929052619523899

Epoch: 5| Step: 2
Training loss: 0.3254895806312561
Validation loss: 1.6955387797406924

Epoch: 5| Step: 3
Training loss: 0.2875707149505615
Validation loss: 1.730154372030689

Epoch: 5| Step: 4
Training loss: 0.48113521933555603
Validation loss: 1.7283976885580248

Epoch: 5| Step: 5
Training loss: 0.1604386270046234
Validation loss: 1.6833987748751076

Epoch: 5| Step: 6
Training loss: 0.1928766518831253
Validation loss: 1.7395821809768677

Epoch: 5| Step: 7
Training loss: 0.23354610800743103
Validation loss: 1.7212641598075948

Epoch: 5| Step: 8
Training loss: 0.3012496531009674
Validation loss: 1.7154074240756292

Epoch: 5| Step: 9
Training loss: 0.2275466024875641
Validation loss: 1.6991741247074579

Epoch: 5| Step: 10
Training loss: 0.2615785598754883
Validation loss: 1.6942725540489278

Epoch: 320| Step: 0
Training loss: 0.32972052693367004
Validation loss: 1.692576132794862

Epoch: 5| Step: 1
Training loss: 0.2383742332458496
Validation loss: 1.6641124038286106

Epoch: 5| Step: 2
Training loss: 0.26160648465156555
Validation loss: 1.6355414441836778

Epoch: 5| Step: 3
Training loss: 0.23251983523368835
Validation loss: 1.638562120417113

Epoch: 5| Step: 4
Training loss: 0.38546791672706604
Validation loss: 1.6438571509494577

Epoch: 5| Step: 5
Training loss: 0.1696544587612152
Validation loss: 1.6843593825576126

Epoch: 5| Step: 6
Training loss: 0.11521904170513153
Validation loss: 1.6747763797801027

Epoch: 5| Step: 7
Training loss: 0.1726367473602295
Validation loss: 1.6722280415155555

Epoch: 5| Step: 8
Training loss: 0.26422563195228577
Validation loss: 1.6963564413850025

Epoch: 5| Step: 9
Training loss: 0.3295920789241791
Validation loss: 1.6799519190224268

Epoch: 5| Step: 10
Training loss: 0.30533236265182495
Validation loss: 1.6734660735694311

Epoch: 321| Step: 0
Training loss: 0.20559492707252502
Validation loss: 1.6873964109728414

Epoch: 5| Step: 1
Training loss: 0.1839940994977951
Validation loss: 1.6887909045783422

Epoch: 5| Step: 2
Training loss: 0.2873563766479492
Validation loss: 1.6596802857614332

Epoch: 5| Step: 3
Training loss: 0.24179336428642273
Validation loss: 1.689928855947269

Epoch: 5| Step: 4
Training loss: 0.3082500398159027
Validation loss: 1.691174143104143

Epoch: 5| Step: 5
Training loss: 0.29348936676979065
Validation loss: 1.650304614856679

Epoch: 5| Step: 6
Training loss: 0.26780983805656433
Validation loss: 1.6619081740738244

Epoch: 5| Step: 7
Training loss: 0.20603236556053162
Validation loss: 1.684047750247422

Epoch: 5| Step: 8
Training loss: 0.20262086391448975
Validation loss: 1.6763114493380311

Epoch: 5| Step: 9
Training loss: 0.2777444124221802
Validation loss: 1.7074210810404953

Epoch: 5| Step: 10
Training loss: 0.344373494386673
Validation loss: 1.727193764460984

Epoch: 322| Step: 0
Training loss: 0.30329060554504395
Validation loss: 1.7278552773178264

Epoch: 5| Step: 1
Training loss: 0.2673857808113098
Validation loss: 1.7131443536409767

Epoch: 5| Step: 2
Training loss: 0.45458802580833435
Validation loss: 1.729266164123371

Epoch: 5| Step: 3
Training loss: 0.19663512706756592
Validation loss: 1.701189932002816

Epoch: 5| Step: 4
Training loss: 0.20810504257678986
Validation loss: 1.6596072912216187

Epoch: 5| Step: 5
Training loss: 0.2770775854587555
Validation loss: 1.6931557552788847

Epoch: 5| Step: 6
Training loss: 0.16940823197364807
Validation loss: 1.7188410015516384

Epoch: 5| Step: 7
Training loss: 0.311308890581131
Validation loss: 1.7045821900008826

Epoch: 5| Step: 8
Training loss: 0.2526652216911316
Validation loss: 1.684224062068488

Epoch: 5| Step: 9
Training loss: 0.19020310044288635
Validation loss: 1.6998299911458006

Epoch: 5| Step: 10
Training loss: 0.25973600149154663
Validation loss: 1.6917210099517659

Epoch: 323| Step: 0
Training loss: 0.2650487720966339
Validation loss: 1.665693312562922

Epoch: 5| Step: 1
Training loss: 0.19663143157958984
Validation loss: 1.654600384414837

Epoch: 5| Step: 2
Training loss: 0.28264254331588745
Validation loss: 1.6607263062589912

Epoch: 5| Step: 3
Training loss: 0.24813778698444366
Validation loss: 1.6271511534208893

Epoch: 5| Step: 4
Training loss: 0.2767927348613739
Validation loss: 1.6737185908902077

Epoch: 5| Step: 5
Training loss: 0.23664513230323792
Validation loss: 1.674580729135903

Epoch: 5| Step: 6
Training loss: 0.30318814516067505
Validation loss: 1.7093519638943415

Epoch: 5| Step: 7
Training loss: 0.4375728964805603
Validation loss: 1.7442573693490797

Epoch: 5| Step: 8
Training loss: 0.26331275701522827
Validation loss: 1.7308232335634128

Epoch: 5| Step: 9
Training loss: 0.2518627643585205
Validation loss: 1.701423551446648

Epoch: 5| Step: 10
Training loss: 0.1506335586309433
Validation loss: 1.691098004259089

Epoch: 324| Step: 0
Training loss: 0.4413803219795227
Validation loss: 1.6781253327605545

Epoch: 5| Step: 1
Training loss: 0.23011033236980438
Validation loss: 1.674087632086969

Epoch: 5| Step: 2
Training loss: 0.2885150611400604
Validation loss: 1.6880339576352028

Epoch: 5| Step: 3
Training loss: 0.32724279165267944
Validation loss: 1.684191349373069

Epoch: 5| Step: 4
Training loss: 0.24015609920024872
Validation loss: 1.7067746154723629

Epoch: 5| Step: 5
Training loss: 0.19503724575042725
Validation loss: 1.7432118936251568

Epoch: 5| Step: 6
Training loss: 0.19110114872455597
Validation loss: 1.7336819043723486

Epoch: 5| Step: 7
Training loss: 0.21744196116924286
Validation loss: 1.7117334065898773

Epoch: 5| Step: 8
Training loss: 0.3018014132976532
Validation loss: 1.6812610344220233

Epoch: 5| Step: 9
Training loss: 0.18895921111106873
Validation loss: 1.6966913233521164

Epoch: 5| Step: 10
Training loss: 0.2727309763431549
Validation loss: 1.6513696812814282

Epoch: 325| Step: 0
Training loss: 0.26942718029022217
Validation loss: 1.619073893434258

Epoch: 5| Step: 1
Training loss: 0.32763391733169556
Validation loss: 1.6234559410361833

Epoch: 5| Step: 2
Training loss: 0.2551735043525696
Validation loss: 1.608955567882907

Epoch: 5| Step: 3
Training loss: 0.1651165783405304
Validation loss: 1.623390072135515

Epoch: 5| Step: 4
Training loss: 0.3104655146598816
Validation loss: 1.6566852677252986

Epoch: 5| Step: 5
Training loss: 0.38814541697502136
Validation loss: 1.7191708677558488

Epoch: 5| Step: 6
Training loss: 0.1671653687953949
Validation loss: 1.702431232698502

Epoch: 5| Step: 7
Training loss: 0.21423068642616272
Validation loss: 1.7174824642878708

Epoch: 5| Step: 8
Training loss: 0.1302570104598999
Validation loss: 1.7159192331375615

Epoch: 5| Step: 9
Training loss: 0.2250255048274994
Validation loss: 1.6656585624141078

Epoch: 5| Step: 10
Training loss: 0.2782568633556366
Validation loss: 1.6966487399993404

Epoch: 326| Step: 0
Training loss: 0.16266457736492157
Validation loss: 1.671400664955057

Epoch: 5| Step: 1
Training loss: 0.27367740869522095
Validation loss: 1.6739648042186615

Epoch: 5| Step: 2
Training loss: 0.1429152488708496
Validation loss: 1.7026494754258024

Epoch: 5| Step: 3
Training loss: 0.36764341592788696
Validation loss: 1.6869021872038483

Epoch: 5| Step: 4
Training loss: 0.26968318223953247
Validation loss: 1.666450330006179

Epoch: 5| Step: 5
Training loss: 0.15445664525032043
Validation loss: 1.6922156823578702

Epoch: 5| Step: 6
Training loss: 0.21523065865039825
Validation loss: 1.6424854737456127

Epoch: 5| Step: 7
Training loss: 0.27711930871009827
Validation loss: 1.6481609652119298

Epoch: 5| Step: 8
Training loss: 0.15747225284576416
Validation loss: 1.6412981594762495

Epoch: 5| Step: 9
Training loss: 0.21922926604747772
Validation loss: 1.6701476573944092

Epoch: 5| Step: 10
Training loss: 0.2901645004749298
Validation loss: 1.6804041452305292

Epoch: 327| Step: 0
Training loss: 0.19660601019859314
Validation loss: 1.677757634911486

Epoch: 5| Step: 1
Training loss: 0.360066682100296
Validation loss: 1.7052527114909182

Epoch: 5| Step: 2
Training loss: 0.1652229130268097
Validation loss: 1.6956835049454884

Epoch: 5| Step: 3
Training loss: 0.33589720726013184
Validation loss: 1.725273834761753

Epoch: 5| Step: 4
Training loss: 0.15755558013916016
Validation loss: 1.7042688003150366

Epoch: 5| Step: 5
Training loss: 0.2588123679161072
Validation loss: 1.685339617472823

Epoch: 5| Step: 6
Training loss: 0.23185749351978302
Validation loss: 1.6794449155048659

Epoch: 5| Step: 7
Training loss: 0.3368072807788849
Validation loss: 1.6966996756933068

Epoch: 5| Step: 8
Training loss: 0.33024677634239197
Validation loss: 1.6604552102345291

Epoch: 5| Step: 9
Training loss: 0.1360052078962326
Validation loss: 1.6653198990770566

Epoch: 5| Step: 10
Training loss: 0.23975658416748047
Validation loss: 1.6744615160008913

Epoch: 328| Step: 0
Training loss: 0.3116872310638428
Validation loss: 1.6756990955721947

Epoch: 5| Step: 1
Training loss: 0.26643142104148865
Validation loss: 1.6789297698646464

Epoch: 5| Step: 2
Training loss: 0.20337286591529846
Validation loss: 1.693608381414926

Epoch: 5| Step: 3
Training loss: 0.24447616934776306
Validation loss: 1.6791908792270127

Epoch: 5| Step: 4
Training loss: 0.3574981391429901
Validation loss: 1.70261263590987

Epoch: 5| Step: 5
Training loss: 0.2069542109966278
Validation loss: 1.677486155622749

Epoch: 5| Step: 6
Training loss: 0.27232182025909424
Validation loss: 1.6437290996633551

Epoch: 5| Step: 7
Training loss: 0.19851118326187134
Validation loss: 1.6477062356087468

Epoch: 5| Step: 8
Training loss: 0.20110151171684265
Validation loss: 1.6880308774209791

Epoch: 5| Step: 9
Training loss: 0.2207300364971161
Validation loss: 1.6921920596912343

Epoch: 5| Step: 10
Training loss: 0.14430463314056396
Validation loss: 1.6851067594302598

Epoch: 329| Step: 0
Training loss: 0.2861085534095764
Validation loss: 1.6971073983817972

Epoch: 5| Step: 1
Training loss: 0.412271112203598
Validation loss: 1.7143093283458422

Epoch: 5| Step: 2
Training loss: 0.14313937723636627
Validation loss: 1.6895343129352858

Epoch: 5| Step: 3
Training loss: 0.1751435548067093
Validation loss: 1.6976511619424308

Epoch: 5| Step: 4
Training loss: 0.18464086949825287
Validation loss: 1.6662071379282142

Epoch: 5| Step: 5
Training loss: 0.13187816739082336
Validation loss: 1.6784872829273183

Epoch: 5| Step: 6
Training loss: 0.35218197107315063
Validation loss: 1.6716589978946153

Epoch: 5| Step: 7
Training loss: 0.20697927474975586
Validation loss: 1.6575894189137284

Epoch: 5| Step: 8
Training loss: 0.11718329042196274
Validation loss: 1.6655380469496532

Epoch: 5| Step: 9
Training loss: 0.3302358090877533
Validation loss: 1.6199109323563115

Epoch: 5| Step: 10
Training loss: 0.2111295461654663
Validation loss: 1.6606321809112385

Epoch: 330| Step: 0
Training loss: 0.20665320754051208
Validation loss: 1.6841493345076037

Epoch: 5| Step: 1
Training loss: 0.24145369231700897
Validation loss: 1.6879150354734032

Epoch: 5| Step: 2
Training loss: 0.10965454578399658
Validation loss: 1.6760872115371048

Epoch: 5| Step: 3
Training loss: 0.12271566689014435
Validation loss: 1.687678369142676

Epoch: 5| Step: 4
Training loss: 0.16998347640037537
Validation loss: 1.6921027104059856

Epoch: 5| Step: 5
Training loss: 0.3020328879356384
Validation loss: 1.6912304483434206

Epoch: 5| Step: 6
Training loss: 0.18254148960113525
Validation loss: 1.6954204523435203

Epoch: 5| Step: 7
Training loss: 0.42351263761520386
Validation loss: 1.7151065661061196

Epoch: 5| Step: 8
Training loss: 0.28156548738479614
Validation loss: 1.6856978157515168

Epoch: 5| Step: 9
Training loss: 0.3313214182853699
Validation loss: 1.6698180328133285

Epoch: 5| Step: 10
Training loss: 0.3759867548942566
Validation loss: 1.703962674704931

Epoch: 331| Step: 0
Training loss: 0.35536590218544006
Validation loss: 1.6836208451178767

Epoch: 5| Step: 1
Training loss: 0.1642596572637558
Validation loss: 1.6747771245177074

Epoch: 5| Step: 2
Training loss: 0.21409407258033752
Validation loss: 1.7188823710205734

Epoch: 5| Step: 3
Training loss: 0.45602983236312866
Validation loss: 1.728243495828362

Epoch: 5| Step: 4
Training loss: 0.196315735578537
Validation loss: 1.7148820469456334

Epoch: 5| Step: 5
Training loss: 0.24959218502044678
Validation loss: 1.7125569274348598

Epoch: 5| Step: 6
Training loss: 0.3827529549598694
Validation loss: 1.6973152788736487

Epoch: 5| Step: 7
Training loss: 0.22587580978870392
Validation loss: 1.659135180134927

Epoch: 5| Step: 8
Training loss: 0.18557952344417572
Validation loss: 1.6424659272675872

Epoch: 5| Step: 9
Training loss: 0.16013678908348083
Validation loss: 1.6429873781819497

Epoch: 5| Step: 10
Training loss: 0.2741410434246063
Validation loss: 1.6539450268591604

Epoch: 332| Step: 0
Training loss: 0.25342607498168945
Validation loss: 1.631604927842335

Epoch: 5| Step: 1
Training loss: 0.26867690682411194
Validation loss: 1.6526025072220834

Epoch: 5| Step: 2
Training loss: 0.17505328357219696
Validation loss: 1.6482720657061505

Epoch: 5| Step: 3
Training loss: 0.27674952149391174
Validation loss: 1.6562522931765484

Epoch: 5| Step: 4
Training loss: 0.31984853744506836
Validation loss: 1.6902852878775647

Epoch: 5| Step: 5
Training loss: 0.22869035601615906
Validation loss: 1.67720543056406

Epoch: 5| Step: 6
Training loss: 0.3533955514431
Validation loss: 1.699180959373392

Epoch: 5| Step: 7
Training loss: 0.4236937165260315
Validation loss: 1.6951399003305743

Epoch: 5| Step: 8
Training loss: 0.2338305413722992
Validation loss: 1.6917624704299434

Epoch: 5| Step: 9
Training loss: 0.10292471945285797
Validation loss: 1.6849588783838416

Epoch: 5| Step: 10
Training loss: 0.22145605087280273
Validation loss: 1.6829943810739825

Epoch: 333| Step: 0
Training loss: 0.2781318426132202
Validation loss: 1.6820759260526268

Epoch: 5| Step: 1
Training loss: 0.2975345253944397
Validation loss: 1.6489179570187804

Epoch: 5| Step: 2
Training loss: 0.35156288743019104
Validation loss: 1.637998629000879

Epoch: 5| Step: 3
Training loss: 0.281322717666626
Validation loss: 1.615707439761008

Epoch: 5| Step: 4
Training loss: 0.24604634940624237
Validation loss: 1.633787239751508

Epoch: 5| Step: 5
Training loss: 0.28702813386917114
Validation loss: 1.6728885532707296

Epoch: 5| Step: 6
Training loss: 0.23081693053245544
Validation loss: 1.6940533499563895

Epoch: 5| Step: 7
Training loss: 0.16080529987812042
Validation loss: 1.7144267443687684

Epoch: 5| Step: 8
Training loss: 0.2728930413722992
Validation loss: 1.7591674225304716

Epoch: 5| Step: 9
Training loss: 0.24949917197227478
Validation loss: 1.811375807690364

Epoch: 5| Step: 10
Training loss: 0.31757283210754395
Validation loss: 1.7681489375329786

Epoch: 334| Step: 0
Training loss: 0.17692384123802185
Validation loss: 1.778286071233852

Epoch: 5| Step: 1
Training loss: 0.15003454685211182
Validation loss: 1.721722695135301

Epoch: 5| Step: 2
Training loss: 0.24387197196483612
Validation loss: 1.7107479713296379

Epoch: 5| Step: 3
Training loss: 0.33131274580955505
Validation loss: 1.6753001238710137

Epoch: 5| Step: 4
Training loss: 0.23829884827136993
Validation loss: 1.6942402714042253

Epoch: 5| Step: 5
Training loss: 0.2520555555820465
Validation loss: 1.6857453994853522

Epoch: 5| Step: 6
Training loss: 0.31064531207084656
Validation loss: 1.6861558524511193

Epoch: 5| Step: 7
Training loss: 0.27258795499801636
Validation loss: 1.7123851365940546

Epoch: 5| Step: 8
Training loss: 0.39570996165275574
Validation loss: 1.7414276010246688

Epoch: 5| Step: 9
Training loss: 0.22122927010059357
Validation loss: 1.7184391675456878

Epoch: 5| Step: 10
Training loss: 0.11231888085603714
Validation loss: 1.7263952916668308

Epoch: 335| Step: 0
Training loss: 0.1820855438709259
Validation loss: 1.7280581023103447

Epoch: 5| Step: 1
Training loss: 0.22351758182048798
Validation loss: 1.7133252633515226

Epoch: 5| Step: 2
Training loss: 0.38875043392181396
Validation loss: 1.7380692112830378

Epoch: 5| Step: 3
Training loss: 0.2862356901168823
Validation loss: 1.7127386831468152

Epoch: 5| Step: 4
Training loss: 0.10145354270935059
Validation loss: 1.6780529445217502

Epoch: 5| Step: 5
Training loss: 0.3411180377006531
Validation loss: 1.7079360331258466

Epoch: 5| Step: 6
Training loss: 0.20707368850708008
Validation loss: 1.7045836910124748

Epoch: 5| Step: 7
Training loss: 0.09353302419185638
Validation loss: 1.740555945263114

Epoch: 5| Step: 8
Training loss: 0.1327524334192276
Validation loss: 1.722063865712894

Epoch: 5| Step: 9
Training loss: 0.2955288589000702
Validation loss: 1.6933924023823073

Epoch: 5| Step: 10
Training loss: 0.22876858711242676
Validation loss: 1.6956501096807501

Epoch: 336| Step: 0
Training loss: 0.22284770011901855
Validation loss: 1.6582825786323958

Epoch: 5| Step: 1
Training loss: 0.16972437500953674
Validation loss: 1.6517171295740272

Epoch: 5| Step: 2
Training loss: 0.20596441626548767
Validation loss: 1.6722116162700038

Epoch: 5| Step: 3
Training loss: 0.24884095788002014
Validation loss: 1.640680113146382

Epoch: 5| Step: 4
Training loss: 0.3932241201400757
Validation loss: 1.6962836198909308

Epoch: 5| Step: 5
Training loss: 0.20823724567890167
Validation loss: 1.7276302229973577

Epoch: 5| Step: 6
Training loss: 0.2668444514274597
Validation loss: 1.7272864977518718

Epoch: 5| Step: 7
Training loss: 0.17959904670715332
Validation loss: 1.7135612605720438

Epoch: 5| Step: 8
Training loss: 0.18901118636131287
Validation loss: 1.698243938466554

Epoch: 5| Step: 9
Training loss: 0.2597935199737549
Validation loss: 1.6813275916602022

Epoch: 5| Step: 10
Training loss: 0.22292611002922058
Validation loss: 1.671014480693366

Epoch: 337| Step: 0
Training loss: 0.15880532562732697
Validation loss: 1.6817671663017684

Epoch: 5| Step: 1
Training loss: 0.3329485058784485
Validation loss: 1.7035999657005392

Epoch: 5| Step: 2
Training loss: 0.29398995637893677
Validation loss: 1.7448977872889528

Epoch: 5| Step: 3
Training loss: 0.30308833718299866
Validation loss: 1.7264541067102903

Epoch: 5| Step: 4
Training loss: 0.2482469081878662
Validation loss: 1.719374123439994

Epoch: 5| Step: 5
Training loss: 0.25317662954330444
Validation loss: 1.74091576632633

Epoch: 5| Step: 6
Training loss: 0.15355534851551056
Validation loss: 1.735332150613108

Epoch: 5| Step: 7
Training loss: 0.14019978046417236
Validation loss: 1.7333156293438328

Epoch: 5| Step: 8
Training loss: 0.1811581403017044
Validation loss: 1.6881543179993987

Epoch: 5| Step: 9
Training loss: 0.18371780216693878
Validation loss: 1.6778244126227595

Epoch: 5| Step: 10
Training loss: 0.23987512290477753
Validation loss: 1.6587735645232662

Epoch: 338| Step: 0
Training loss: 0.12744498252868652
Validation loss: 1.6146287687363163

Epoch: 5| Step: 1
Training loss: 0.17578533291816711
Validation loss: 1.6531755026950632

Epoch: 5| Step: 2
Training loss: 0.22079677879810333
Validation loss: 1.6493893772043207

Epoch: 5| Step: 3
Training loss: 0.2299727499485016
Validation loss: 1.6553865953158307

Epoch: 5| Step: 4
Training loss: 0.23820677399635315
Validation loss: 1.6978188842855475

Epoch: 5| Step: 5
Training loss: 0.3813958764076233
Validation loss: 1.710779437454798

Epoch: 5| Step: 6
Training loss: 0.12160427868366241
Validation loss: 1.7317535402954265

Epoch: 5| Step: 7
Training loss: 0.29343920946121216
Validation loss: 1.7494962420514835

Epoch: 5| Step: 8
Training loss: 0.26428452134132385
Validation loss: 1.7546363658802484

Epoch: 5| Step: 9
Training loss: 0.29483938217163086
Validation loss: 1.7381932568806473

Epoch: 5| Step: 10
Training loss: 0.10781067609786987
Validation loss: 1.711673508408249

Epoch: 339| Step: 0
Training loss: 0.27151113748550415
Validation loss: 1.6935945813373854

Epoch: 5| Step: 1
Training loss: 0.17852672934532166
Validation loss: 1.6682167001949844

Epoch: 5| Step: 2
Training loss: 0.15540805459022522
Validation loss: 1.6731217856048255

Epoch: 5| Step: 3
Training loss: 0.17928826808929443
Validation loss: 1.698632631250607

Epoch: 5| Step: 4
Training loss: 0.22406697273254395
Validation loss: 1.7031240104347147

Epoch: 5| Step: 5
Training loss: 0.18256902694702148
Validation loss: 1.667205326018795

Epoch: 5| Step: 6
Training loss: 0.24687568843364716
Validation loss: 1.675993061834766

Epoch: 5| Step: 7
Training loss: 0.28450727462768555
Validation loss: 1.6797437680664884

Epoch: 5| Step: 8
Training loss: 0.28012341260910034
Validation loss: 1.6686957087568057

Epoch: 5| Step: 9
Training loss: 0.14118798077106476
Validation loss: 1.6797551403763473

Epoch: 5| Step: 10
Training loss: 0.2326349914073944
Validation loss: 1.6666143478885773

Epoch: 340| Step: 0
Training loss: 0.414484441280365
Validation loss: 1.6928225665964105

Epoch: 5| Step: 1
Training loss: 0.14054854214191437
Validation loss: 1.6840281999239357

Epoch: 5| Step: 2
Training loss: 0.1818186640739441
Validation loss: 1.6791751179643857

Epoch: 5| Step: 3
Training loss: 0.1320502907037735
Validation loss: 1.692474945898979

Epoch: 5| Step: 4
Training loss: 0.2625577449798584
Validation loss: 1.7074889277899137

Epoch: 5| Step: 5
Training loss: 0.15946385264396667
Validation loss: 1.6481086554065827

Epoch: 5| Step: 6
Training loss: 0.2716343402862549
Validation loss: 1.6743840376536052

Epoch: 5| Step: 7
Training loss: 0.19077810645103455
Validation loss: 1.6723315459425732

Epoch: 5| Step: 8
Training loss: 0.23129108548164368
Validation loss: 1.6531811401408205

Epoch: 5| Step: 9
Training loss: 0.1057199239730835
Validation loss: 1.6568824104083482

Epoch: 5| Step: 10
Training loss: 0.18099507689476013
Validation loss: 1.6747564231195757

Epoch: 341| Step: 0
Training loss: 0.183706134557724
Validation loss: 1.6864169361770793

Epoch: 5| Step: 1
Training loss: 0.11614395678043365
Validation loss: 1.6726378087074525

Epoch: 5| Step: 2
Training loss: 0.2346828430891037
Validation loss: 1.6739826458756641

Epoch: 5| Step: 3
Training loss: 0.18120531737804413
Validation loss: 1.6983262121036489

Epoch: 5| Step: 4
Training loss: 0.312960147857666
Validation loss: 1.7448554436365764

Epoch: 5| Step: 5
Training loss: 0.2153487205505371
Validation loss: 1.723199854614914

Epoch: 5| Step: 6
Training loss: 0.09319434314966202
Validation loss: 1.7214919982417938

Epoch: 5| Step: 7
Training loss: 0.1758141815662384
Validation loss: 1.6887433733991397

Epoch: 5| Step: 8
Training loss: 0.239392951130867
Validation loss: 1.701559252636407

Epoch: 5| Step: 9
Training loss: 0.3309946358203888
Validation loss: 1.6921043716451174

Epoch: 5| Step: 10
Training loss: 0.31508228182792664
Validation loss: 1.6323799587065173

Epoch: 342| Step: 0
Training loss: 0.351665198802948
Validation loss: 1.6553309960390932

Epoch: 5| Step: 1
Training loss: 0.18241511285305023
Validation loss: 1.6659539476517709

Epoch: 5| Step: 2
Training loss: 0.16468611359596252
Validation loss: 1.7165311100662395

Epoch: 5| Step: 3
Training loss: 0.22275245189666748
Validation loss: 1.7067829050043577

Epoch: 5| Step: 4
Training loss: 0.13192136585712433
Validation loss: 1.740538763743575

Epoch: 5| Step: 5
Training loss: 0.3330634832382202
Validation loss: 1.7576690668700843

Epoch: 5| Step: 6
Training loss: 0.19700071215629578
Validation loss: 1.7212838434403943

Epoch: 5| Step: 7
Training loss: 0.27825289964675903
Validation loss: 1.6806149533999863

Epoch: 5| Step: 8
Training loss: 0.23512911796569824
Validation loss: 1.6636331324936242

Epoch: 5| Step: 9
Training loss: 0.12589366734027863
Validation loss: 1.6599319622080813

Epoch: 5| Step: 10
Training loss: 0.24296700954437256
Validation loss: 1.6408570684412473

Epoch: 343| Step: 0
Training loss: 0.32367202639579773
Validation loss: 1.664263553516839

Epoch: 5| Step: 1
Training loss: 0.25107812881469727
Validation loss: 1.6953643778319

Epoch: 5| Step: 2
Training loss: 0.1696392297744751
Validation loss: 1.7198503735244914

Epoch: 5| Step: 3
Training loss: 0.21563085913658142
Validation loss: 1.737971910866358

Epoch: 5| Step: 4
Training loss: 0.2616334557533264
Validation loss: 1.7596532388400006

Epoch: 5| Step: 5
Training loss: 0.35162487626075745
Validation loss: 1.7688256245787426

Epoch: 5| Step: 6
Training loss: 0.23462486267089844
Validation loss: 1.7781701190497285

Epoch: 5| Step: 7
Training loss: 0.21877852082252502
Validation loss: 1.7252222902031356

Epoch: 5| Step: 8
Training loss: 0.20418253540992737
Validation loss: 1.64011198987243

Epoch: 5| Step: 9
Training loss: 0.1757306158542633
Validation loss: 1.6304182955013808

Epoch: 5| Step: 10
Training loss: 0.17743676900863647
Validation loss: 1.57019837697347

Epoch: 344| Step: 0
Training loss: 0.3765886127948761
Validation loss: 1.5741900141521166

Epoch: 5| Step: 1
Training loss: 0.3362995386123657
Validation loss: 1.5819920121982534

Epoch: 5| Step: 2
Training loss: 0.17286691069602966
Validation loss: 1.6173074283907491

Epoch: 5| Step: 3
Training loss: 0.17868609726428986
Validation loss: 1.6604487972874795

Epoch: 5| Step: 4
Training loss: 0.16704532504081726
Validation loss: 1.7275411364852742

Epoch: 5| Step: 5
Training loss: 0.29578274488449097
Validation loss: 1.710147016791887

Epoch: 5| Step: 6
Training loss: 0.09897905588150024
Validation loss: 1.724044584458874

Epoch: 5| Step: 7
Training loss: 0.3349637985229492
Validation loss: 1.7298570115079162

Epoch: 5| Step: 8
Training loss: 0.14477406442165375
Validation loss: 1.7085963205624652

Epoch: 5| Step: 9
Training loss: 0.23093628883361816
Validation loss: 1.7193896398749402

Epoch: 5| Step: 10
Training loss: 0.19727914035320282
Validation loss: 1.6947193068842734

Epoch: 345| Step: 0
Training loss: 0.22825828194618225
Validation loss: 1.650811682465256

Epoch: 5| Step: 1
Training loss: 0.2355377972126007
Validation loss: 1.6560255224986742

Epoch: 5| Step: 2
Training loss: 0.22357437014579773
Validation loss: 1.6058970266772854

Epoch: 5| Step: 3
Training loss: 0.28642964363098145
Validation loss: 1.6144822618012786

Epoch: 5| Step: 4
Training loss: 0.3106253147125244
Validation loss: 1.5800717094893098

Epoch: 5| Step: 5
Training loss: 0.12815465033054352
Validation loss: 1.575681406964538

Epoch: 5| Step: 6
Training loss: 0.18255400657653809
Validation loss: 1.632317146947307

Epoch: 5| Step: 7
Training loss: 0.2683599591255188
Validation loss: 1.641734746194655

Epoch: 5| Step: 8
Training loss: 0.19151684641838074
Validation loss: 1.664238811821066

Epoch: 5| Step: 9
Training loss: 0.09742772579193115
Validation loss: 1.6975027643224245

Epoch: 5| Step: 10
Training loss: 0.21418257057666779
Validation loss: 1.7014114023536764

Epoch: 346| Step: 0
Training loss: 0.15297886729240417
Validation loss: 1.709070409497907

Epoch: 5| Step: 1
Training loss: 0.26871252059936523
Validation loss: 1.699548070148755

Epoch: 5| Step: 2
Training loss: 0.22334647178649902
Validation loss: 1.697192661223873

Epoch: 5| Step: 3
Training loss: 0.12061469256877899
Validation loss: 1.6437701961045623

Epoch: 5| Step: 4
Training loss: 0.18803709745407104
Validation loss: 1.635949803936866

Epoch: 5| Step: 5
Training loss: 0.20050334930419922
Validation loss: 1.6297233643070344

Epoch: 5| Step: 6
Training loss: 0.18216243386268616
Validation loss: 1.656547256695327

Epoch: 5| Step: 7
Training loss: 0.27953535318374634
Validation loss: 1.6706272427753737

Epoch: 5| Step: 8
Training loss: 0.19415965676307678
Validation loss: 1.7054608380922707

Epoch: 5| Step: 9
Training loss: 0.1841498464345932
Validation loss: 1.7130429565265615

Epoch: 5| Step: 10
Training loss: 0.30379804968833923
Validation loss: 1.703076220327808

Epoch: 347| Step: 0
Training loss: 0.21187376976013184
Validation loss: 1.7217765713250766

Epoch: 5| Step: 1
Training loss: 0.1999748945236206
Validation loss: 1.698489995412929

Epoch: 5| Step: 2
Training loss: 0.1761535406112671
Validation loss: 1.689236182038502

Epoch: 5| Step: 3
Training loss: 0.16757658123970032
Validation loss: 1.7061178543234383

Epoch: 5| Step: 4
Training loss: 0.2919776439666748
Validation loss: 1.681659265871971

Epoch: 5| Step: 5
Training loss: 0.22760629653930664
Validation loss: 1.6600130886159918

Epoch: 5| Step: 6
Training loss: 0.15130403637886047
Validation loss: 1.655215883767733

Epoch: 5| Step: 7
Training loss: 0.2986733317375183
Validation loss: 1.6479381758679625

Epoch: 5| Step: 8
Training loss: 0.24057428538799286
Validation loss: 1.6575044085902553

Epoch: 5| Step: 9
Training loss: 0.26317551732063293
Validation loss: 1.6781787923587266

Epoch: 5| Step: 10
Training loss: 0.19289641082286835
Validation loss: 1.727781350894641

Epoch: 348| Step: 0
Training loss: 0.1728871762752533
Validation loss: 1.7174312440297936

Epoch: 5| Step: 1
Training loss: 0.23932914435863495
Validation loss: 1.7231714558857743

Epoch: 5| Step: 2
Training loss: 0.17036238312721252
Validation loss: 1.6999448601917555

Epoch: 5| Step: 3
Training loss: 0.23423540592193604
Validation loss: 1.6627622522333616

Epoch: 5| Step: 4
Training loss: 0.14329227805137634
Validation loss: 1.6391410904545938

Epoch: 5| Step: 5
Training loss: 0.25617843866348267
Validation loss: 1.6432967288519746

Epoch: 5| Step: 6
Training loss: 0.18170878291130066
Validation loss: 1.6242120240324287

Epoch: 5| Step: 7
Training loss: 0.22011122107505798
Validation loss: 1.660222025327785

Epoch: 5| Step: 8
Training loss: 0.3085710108280182
Validation loss: 1.683370687628305

Epoch: 5| Step: 9
Training loss: 0.36456841230392456
Validation loss: 1.689234851509012

Epoch: 5| Step: 10
Training loss: 0.16935312747955322
Validation loss: 1.737976953547488

Epoch: 349| Step: 0
Training loss: 0.2785232663154602
Validation loss: 1.7713397420862669

Epoch: 5| Step: 1
Training loss: 0.23220276832580566
Validation loss: 1.7722151279449463

Epoch: 5| Step: 2
Training loss: 0.22387182712554932
Validation loss: 1.7519256876360985

Epoch: 5| Step: 3
Training loss: 0.15280959010124207
Validation loss: 1.7429633294382403

Epoch: 5| Step: 4
Training loss: 0.276206910610199
Validation loss: 1.6952144625366374

Epoch: 5| Step: 5
Training loss: 0.24220474064350128
Validation loss: 1.6890435872539398

Epoch: 5| Step: 6
Training loss: 0.26035717129707336
Validation loss: 1.6809919124008508

Epoch: 5| Step: 7
Training loss: 0.21473094820976257
Validation loss: 1.6852152411655714

Epoch: 5| Step: 8
Training loss: 0.27482813596725464
Validation loss: 1.662694154888071

Epoch: 5| Step: 9
Training loss: 0.15812095999717712
Validation loss: 1.6210486324884559

Epoch: 5| Step: 10
Training loss: 0.1754082292318344
Validation loss: 1.655204729367328

Epoch: 350| Step: 0
Training loss: 0.20894142985343933
Validation loss: 1.644886492401041

Epoch: 5| Step: 1
Training loss: 0.13950614631175995
Validation loss: 1.66140547362707

Epoch: 5| Step: 2
Training loss: 0.18608635663986206
Validation loss: 1.7178071442470755

Epoch: 5| Step: 3
Training loss: 0.289884090423584
Validation loss: 1.7397539256721415

Epoch: 5| Step: 4
Training loss: 0.26712507009506226
Validation loss: 1.7095689299286052

Epoch: 5| Step: 5
Training loss: 0.23075056076049805
Validation loss: 1.7320331488886187

Epoch: 5| Step: 6
Training loss: 0.18576502799987793
Validation loss: 1.6991709765567575

Epoch: 5| Step: 7
Training loss: 0.25988858938217163
Validation loss: 1.6952869610119892

Epoch: 5| Step: 8
Training loss: 0.25779595971107483
Validation loss: 1.6994173936946417

Epoch: 5| Step: 9
Training loss: 0.17253975570201874
Validation loss: 1.698074794584705

Epoch: 5| Step: 10
Training loss: 0.14819465577602386
Validation loss: 1.6563571537694624

Epoch: 351| Step: 0
Training loss: 0.18355116248130798
Validation loss: 1.6436336694225189

Epoch: 5| Step: 1
Training loss: 0.26617103815078735
Validation loss: 1.6289016328832155

Epoch: 5| Step: 2
Training loss: 0.16660022735595703
Validation loss: 1.6508430319447671

Epoch: 5| Step: 3
Training loss: 0.19000455737113953
Validation loss: 1.6411910915887484

Epoch: 5| Step: 4
Training loss: 0.24495717883110046
Validation loss: 1.6791254320452291

Epoch: 5| Step: 5
Training loss: 0.22346875071525574
Validation loss: 1.6971818221512662

Epoch: 5| Step: 6
Training loss: 0.16623792052268982
Validation loss: 1.7141034756937334

Epoch: 5| Step: 7
Training loss: 0.275516152381897
Validation loss: 1.7362344213711318

Epoch: 5| Step: 8
Training loss: 0.2278977334499359
Validation loss: 1.713923333793558

Epoch: 5| Step: 9
Training loss: 0.1478426158428192
Validation loss: 1.715508053379674

Epoch: 5| Step: 10
Training loss: 0.1347811222076416
Validation loss: 1.7053257444853425

Epoch: 352| Step: 0
Training loss: 0.1622253954410553
Validation loss: 1.6830581900894002

Epoch: 5| Step: 1
Training loss: 0.21201631426811218
Validation loss: 1.6893052260080974

Epoch: 5| Step: 2
Training loss: 0.3229597508907318
Validation loss: 1.7005071332377772

Epoch: 5| Step: 3
Training loss: 0.15109477937221527
Validation loss: 1.6646951744633336

Epoch: 5| Step: 4
Training loss: 0.10653989017009735
Validation loss: 1.6602040285705237

Epoch: 5| Step: 5
Training loss: 0.18000997602939606
Validation loss: 1.6565664250363585

Epoch: 5| Step: 6
Training loss: 0.1365714967250824
Validation loss: 1.651871395367448

Epoch: 5| Step: 7
Training loss: 0.29022863507270813
Validation loss: 1.6832438873988327

Epoch: 5| Step: 8
Training loss: 0.1517190933227539
Validation loss: 1.7107284043424873

Epoch: 5| Step: 9
Training loss: 0.34385889768600464
Validation loss: 1.7092757071218183

Epoch: 5| Step: 10
Training loss: 0.3861706852912903
Validation loss: 1.6932906450763825

Epoch: 353| Step: 0
Training loss: 0.14421731233596802
Validation loss: 1.6541525548504246

Epoch: 5| Step: 1
Training loss: 0.2938588857650757
Validation loss: 1.6280289106471564

Epoch: 5| Step: 2
Training loss: 0.1690446436405182
Validation loss: 1.5819425095794022

Epoch: 5| Step: 3
Training loss: 0.18770623207092285
Validation loss: 1.5981852290450886

Epoch: 5| Step: 4
Training loss: 0.24586835503578186
Validation loss: 1.5920934856578868

Epoch: 5| Step: 5
Training loss: 0.19528236985206604
Validation loss: 1.6085002947879095

Epoch: 5| Step: 6
Training loss: 0.2662449777126312
Validation loss: 1.6539049328014415

Epoch: 5| Step: 7
Training loss: 0.2622002065181732
Validation loss: 1.7029473884131319

Epoch: 5| Step: 8
Training loss: 0.1819762885570526
Validation loss: 1.7280928152863697

Epoch: 5| Step: 9
Training loss: 0.20977473258972168
Validation loss: 1.770110482810646

Epoch: 5| Step: 10
Training loss: 0.25843968987464905
Validation loss: 1.7482499743020663

Epoch: 354| Step: 0
Training loss: 0.323326051235199
Validation loss: 1.738389745835335

Epoch: 5| Step: 1
Training loss: 0.24923160672187805
Validation loss: 1.6956159068692116

Epoch: 5| Step: 2
Training loss: 0.2558015286922455
Validation loss: 1.6695152367314985

Epoch: 5| Step: 3
Training loss: 0.13624221086502075
Validation loss: 1.626910037891839

Epoch: 5| Step: 4
Training loss: 0.1380978524684906
Validation loss: 1.6311869044457712

Epoch: 5| Step: 5
Training loss: 0.29324233531951904
Validation loss: 1.6042341686064197

Epoch: 5| Step: 6
Training loss: 0.3256741464138031
Validation loss: 1.6242540587661087

Epoch: 5| Step: 7
Training loss: 0.1593775451183319
Validation loss: 1.6328654930155764

Epoch: 5| Step: 8
Training loss: 0.14509636163711548
Validation loss: 1.6894882750767533

Epoch: 5| Step: 9
Training loss: 0.14416265487670898
Validation loss: 1.6841852818765948

Epoch: 5| Step: 10
Training loss: 0.1705462634563446
Validation loss: 1.6976773303042176

Epoch: 355| Step: 0
Training loss: 0.3210698068141937
Validation loss: 1.6896572292491954

Epoch: 5| Step: 1
Training loss: 0.3737502098083496
Validation loss: 1.6804607119611514

Epoch: 5| Step: 2
Training loss: 0.20161978900432587
Validation loss: 1.6680292211553103

Epoch: 5| Step: 3
Training loss: 0.10498230159282684
Validation loss: 1.6328008636351554

Epoch: 5| Step: 4
Training loss: 0.12159885466098785
Validation loss: 1.6493651123457058

Epoch: 5| Step: 5
Training loss: 0.23327533900737762
Validation loss: 1.6613711874972108

Epoch: 5| Step: 6
Training loss: 0.2180517166852951
Validation loss: 1.6312076692940087

Epoch: 5| Step: 7
Training loss: 0.18063749372959137
Validation loss: 1.6530226379312494

Epoch: 5| Step: 8
Training loss: 0.16686204075813293
Validation loss: 1.6993147186053696

Epoch: 5| Step: 9
Training loss: 0.17398759722709656
Validation loss: 1.66524560605326

Epoch: 5| Step: 10
Training loss: 0.1700657159090042
Validation loss: 1.6810891782083819

Epoch: 356| Step: 0
Training loss: 0.171019047498703
Validation loss: 1.682970061097094

Epoch: 5| Step: 1
Training loss: 0.21252688765525818
Validation loss: 1.722464947290318

Epoch: 5| Step: 2
Training loss: 0.1547880470752716
Validation loss: 1.7161553700764973

Epoch: 5| Step: 3
Training loss: 0.21620731055736542
Validation loss: 1.7119191295357161

Epoch: 5| Step: 4
Training loss: 0.15513165295124054
Validation loss: 1.6940337810465085

Epoch: 5| Step: 5
Training loss: 0.2617502212524414
Validation loss: 1.6421362648728073

Epoch: 5| Step: 6
Training loss: 0.18806517124176025
Validation loss: 1.6281878525210964

Epoch: 5| Step: 7
Training loss: 0.18044279515743256
Validation loss: 1.6022749472689886

Epoch: 5| Step: 8
Training loss: 0.2407725751399994
Validation loss: 1.603041547600941

Epoch: 5| Step: 9
Training loss: 0.15913747251033783
Validation loss: 1.6179737698647283

Epoch: 5| Step: 10
Training loss: 0.17351488769054413
Validation loss: 1.5976949173917052

Epoch: 357| Step: 0
Training loss: 0.13367891311645508
Validation loss: 1.6255138420289563

Epoch: 5| Step: 1
Training loss: 0.19312834739685059
Validation loss: 1.652842919031779

Epoch: 5| Step: 2
Training loss: 0.20953011512756348
Validation loss: 1.6862327385974187

Epoch: 5| Step: 3
Training loss: 0.16720552742481232
Validation loss: 1.7161899817887174

Epoch: 5| Step: 4
Training loss: 0.19768169522285461
Validation loss: 1.7341214354320238

Epoch: 5| Step: 5
Training loss: 0.1954289972782135
Validation loss: 1.7669575368204424

Epoch: 5| Step: 6
Training loss: 0.18803992867469788
Validation loss: 1.709939363182232

Epoch: 5| Step: 7
Training loss: 0.14181795716285706
Validation loss: 1.7163783760480984

Epoch: 5| Step: 8
Training loss: 0.3234231770038605
Validation loss: 1.6732387292769648

Epoch: 5| Step: 9
Training loss: 0.19746598601341248
Validation loss: 1.6565451045190134

Epoch: 5| Step: 10
Training loss: 0.20236757397651672
Validation loss: 1.6208798628981396

Epoch: 358| Step: 0
Training loss: 0.22594031691551208
Validation loss: 1.596739745909168

Epoch: 5| Step: 1
Training loss: 0.141902357339859
Validation loss: 1.5932392228034236

Epoch: 5| Step: 2
Training loss: 0.2053820639848709
Validation loss: 1.5880563054033505

Epoch: 5| Step: 3
Training loss: 0.28821343183517456
Validation loss: 1.6328933187710342

Epoch: 5| Step: 4
Training loss: 0.22437739372253418
Validation loss: 1.6243302783658427

Epoch: 5| Step: 5
Training loss: 0.23374053835868835
Validation loss: 1.6665862426962903

Epoch: 5| Step: 6
Training loss: 0.25985032320022583
Validation loss: 1.7126435208064255

Epoch: 5| Step: 7
Training loss: 0.22301062941551208
Validation loss: 1.7309531114434684

Epoch: 5| Step: 8
Training loss: 0.17367227375507355
Validation loss: 1.7498195196992608

Epoch: 5| Step: 9
Training loss: 0.3621814250946045
Validation loss: 1.7407329261943858

Epoch: 5| Step: 10
Training loss: 0.19174036383628845
Validation loss: 1.746726679545577

Epoch: 359| Step: 0
Training loss: 0.24156396090984344
Validation loss: 1.7812275117443455

Epoch: 5| Step: 1
Training loss: 0.3826819658279419
Validation loss: 1.7595093788639191

Epoch: 5| Step: 2
Training loss: 0.22107915580272675
Validation loss: 1.7444231894708448

Epoch: 5| Step: 3
Training loss: 0.30723169445991516
Validation loss: 1.7167377741106096

Epoch: 5| Step: 4
Training loss: 0.33991676568984985
Validation loss: 1.7186288731072539

Epoch: 5| Step: 5
Training loss: 0.2454620897769928
Validation loss: 1.6785555731865667

Epoch: 5| Step: 6
Training loss: 0.14399656653404236
Validation loss: 1.6545381648566133

Epoch: 5| Step: 7
Training loss: 0.26619482040405273
Validation loss: 1.6621550308760775

Epoch: 5| Step: 8
Training loss: 0.22571825981140137
Validation loss: 1.703402170570948

Epoch: 5| Step: 9
Training loss: 0.16311657428741455
Validation loss: 1.7057900915863693

Epoch: 5| Step: 10
Training loss: 0.18339863419532776
Validation loss: 1.721393198095342

Epoch: 360| Step: 0
Training loss: 0.2454606592655182
Validation loss: 1.6726376484799128

Epoch: 5| Step: 1
Training loss: 0.17731907963752747
Validation loss: 1.6760766166512684

Epoch: 5| Step: 2
Training loss: 0.17650741338729858
Validation loss: 1.640868550987654

Epoch: 5| Step: 3
Training loss: 0.21731014549732208
Validation loss: 1.6435996486294655

Epoch: 5| Step: 4
Training loss: 0.2220815122127533
Validation loss: 1.609568726631903

Epoch: 5| Step: 5
Training loss: 0.17710445821285248
Validation loss: 1.6184473704266291

Epoch: 5| Step: 6
Training loss: 0.21463672816753387
Validation loss: 1.6359665957830285

Epoch: 5| Step: 7
Training loss: 0.20142266154289246
Validation loss: 1.6734451247799782

Epoch: 5| Step: 8
Training loss: 0.2410859763622284
Validation loss: 1.7066599733086043

Epoch: 5| Step: 9
Training loss: 0.19452421367168427
Validation loss: 1.7196433697977374

Epoch: 5| Step: 10
Training loss: 0.14365556836128235
Validation loss: 1.7462195529732654

Epoch: 361| Step: 0
Training loss: 0.26004958152770996
Validation loss: 1.7292460344171012

Epoch: 5| Step: 1
Training loss: 0.12040718644857407
Validation loss: 1.7418076325488347

Epoch: 5| Step: 2
Training loss: 0.14387424290180206
Validation loss: 1.716473098724119

Epoch: 5| Step: 3
Training loss: 0.12702682614326477
Validation loss: 1.7336703038984729

Epoch: 5| Step: 4
Training loss: 0.2286454141139984
Validation loss: 1.6826050153342627

Epoch: 5| Step: 5
Training loss: 0.2055869996547699
Validation loss: 1.6793660553552772

Epoch: 5| Step: 6
Training loss: 0.2809630036354065
Validation loss: 1.6794570133250246

Epoch: 5| Step: 7
Training loss: 0.1012195348739624
Validation loss: 1.7022672776252992

Epoch: 5| Step: 8
Training loss: 0.21129333972930908
Validation loss: 1.6961555827048518

Epoch: 5| Step: 9
Training loss: 0.19910268485546112
Validation loss: 1.720000115774011

Epoch: 5| Step: 10
Training loss: 0.2465490996837616
Validation loss: 1.7145669101386942

Epoch: 362| Step: 0
Training loss: 0.14202411472797394
Validation loss: 1.6909246316520117

Epoch: 5| Step: 1
Training loss: 0.21429753303527832
Validation loss: 1.7171138281463294

Epoch: 5| Step: 2
Training loss: 0.1314702332019806
Validation loss: 1.7226722240447998

Epoch: 5| Step: 3
Training loss: 0.1345108300447464
Validation loss: 1.7159052843688636

Epoch: 5| Step: 4
Training loss: 0.23669114708900452
Validation loss: 1.7184254918047177

Epoch: 5| Step: 5
Training loss: 0.14995284378528595
Validation loss: 1.6765576357482581

Epoch: 5| Step: 6
Training loss: 0.23550207912921906
Validation loss: 1.6578232895943426

Epoch: 5| Step: 7
Training loss: 0.23293176293373108
Validation loss: 1.6816395944164646

Epoch: 5| Step: 8
Training loss: 0.2261897325515747
Validation loss: 1.6424010825413529

Epoch: 5| Step: 9
Training loss: 0.20419064164161682
Validation loss: 1.6536770828308598

Epoch: 5| Step: 10
Training loss: 0.1521184742450714
Validation loss: 1.6489040787502

Epoch: 363| Step: 0
Training loss: 0.2294405698776245
Validation loss: 1.6680820321524015

Epoch: 5| Step: 1
Training loss: 0.15770378708839417
Validation loss: 1.679704757146938

Epoch: 5| Step: 2
Training loss: 0.1344299018383026
Validation loss: 1.6742766973792866

Epoch: 5| Step: 3
Training loss: 0.1029825210571289
Validation loss: 1.673008680343628

Epoch: 5| Step: 4
Training loss: 0.18068012595176697
Validation loss: 1.6846004570684125

Epoch: 5| Step: 5
Training loss: 0.14425842463970184
Validation loss: 1.6941139364755282

Epoch: 5| Step: 6
Training loss: 0.14921726286411285
Validation loss: 1.6839715203931254

Epoch: 5| Step: 7
Training loss: 0.32507017254829407
Validation loss: 1.6599392480747674

Epoch: 5| Step: 8
Training loss: 0.21432188153266907
Validation loss: 1.6494817118490896

Epoch: 5| Step: 9
Training loss: 0.13414837419986725
Validation loss: 1.6625315117579635

Epoch: 5| Step: 10
Training loss: 0.1825195699930191
Validation loss: 1.6748625578418854

Epoch: 364| Step: 0
Training loss: 0.18278339505195618
Validation loss: 1.6667606522960048

Epoch: 5| Step: 1
Training loss: 0.12584784626960754
Validation loss: 1.7048072174031248

Epoch: 5| Step: 2
Training loss: 0.2048233300447464
Validation loss: 1.680811111645032

Epoch: 5| Step: 3
Training loss: 0.1817573755979538
Validation loss: 1.6673154843750821

Epoch: 5| Step: 4
Training loss: 0.1694900542497635
Validation loss: 1.6655602480775566

Epoch: 5| Step: 5
Training loss: 0.1774691641330719
Validation loss: 1.6680073738098145

Epoch: 5| Step: 6
Training loss: 0.0909721776843071
Validation loss: 1.6879429458290018

Epoch: 5| Step: 7
Training loss: 0.2257479727268219
Validation loss: 1.6725765120598577

Epoch: 5| Step: 8
Training loss: 0.1847141981124878
Validation loss: 1.6519023718372468

Epoch: 5| Step: 9
Training loss: 0.23765802383422852
Validation loss: 1.6453630975497666

Epoch: 5| Step: 10
Training loss: 0.21047136187553406
Validation loss: 1.5975949828342726

Epoch: 365| Step: 0
Training loss: 0.15687422454357147
Validation loss: 1.6539252188897902

Epoch: 5| Step: 1
Training loss: 0.21848352253437042
Validation loss: 1.6526246660499162

Epoch: 5| Step: 2
Training loss: 0.10220333188772202
Validation loss: 1.6917187616389284

Epoch: 5| Step: 3
Training loss: 0.24021801352500916
Validation loss: 1.6876348718520133

Epoch: 5| Step: 4
Training loss: 0.2650497555732727
Validation loss: 1.6851916441353418

Epoch: 5| Step: 5
Training loss: 0.17868933081626892
Validation loss: 1.694470379942207

Epoch: 5| Step: 6
Training loss: 0.18011200428009033
Validation loss: 1.6800167599032003

Epoch: 5| Step: 7
Training loss: 0.15156111121177673
Validation loss: 1.6679416792367094

Epoch: 5| Step: 8
Training loss: 0.2127799540758133
Validation loss: 1.6692560244632024

Epoch: 5| Step: 9
Training loss: 0.2353130280971527
Validation loss: 1.6682811680660452

Epoch: 5| Step: 10
Training loss: 0.19913439452648163
Validation loss: 1.6747864779605661

Epoch: 366| Step: 0
Training loss: 0.27672716975212097
Validation loss: 1.6731472194835704

Epoch: 5| Step: 1
Training loss: 0.2243930995464325
Validation loss: 1.67786277878669

Epoch: 5| Step: 2
Training loss: 0.12220169603824615
Validation loss: 1.6666249735381014

Epoch: 5| Step: 3
Training loss: 0.16783130168914795
Validation loss: 1.6410914108317385

Epoch: 5| Step: 4
Training loss: 0.15648803114891052
Validation loss: 1.6485500310056953

Epoch: 5| Step: 5
Training loss: 0.12800908088684082
Validation loss: 1.6437514225641887

Epoch: 5| Step: 6
Training loss: 0.10286135971546173
Validation loss: 1.6167076005730578

Epoch: 5| Step: 7
Training loss: 0.17000266909599304
Validation loss: 1.6561919040577386

Epoch: 5| Step: 8
Training loss: 0.19002994894981384
Validation loss: 1.644295746280301

Epoch: 5| Step: 9
Training loss: 0.17642013728618622
Validation loss: 1.6763991296932261

Epoch: 5| Step: 10
Training loss: 0.27314072847366333
Validation loss: 1.6815176612587386

Epoch: 367| Step: 0
Training loss: 0.25981006026268005
Validation loss: 1.7260777463195145

Epoch: 5| Step: 1
Training loss: 0.26264628767967224
Validation loss: 1.6905625302304503

Epoch: 5| Step: 2
Training loss: 0.1543271243572235
Validation loss: 1.6806741670895649

Epoch: 5| Step: 3
Training loss: 0.14875058829784393
Validation loss: 1.6331861519044446

Epoch: 5| Step: 4
Training loss: 0.18076328933238983
Validation loss: 1.6159881340560092

Epoch: 5| Step: 5
Training loss: 0.19874359667301178
Validation loss: 1.6243637595125424

Epoch: 5| Step: 6
Training loss: 0.16751402616500854
Validation loss: 1.617949640879067

Epoch: 5| Step: 7
Training loss: 0.22617223858833313
Validation loss: 1.6028593535064368

Epoch: 5| Step: 8
Training loss: 0.17659008502960205
Validation loss: 1.6844672208191247

Epoch: 5| Step: 9
Training loss: 0.2672565281391144
Validation loss: 1.6926889611828713

Epoch: 5| Step: 10
Training loss: 0.20686957240104675
Validation loss: 1.724388942923597

Epoch: 368| Step: 0
Training loss: 0.13626697659492493
Validation loss: 1.7128596857029905

Epoch: 5| Step: 1
Training loss: 0.13529427349567413
Validation loss: 1.6724412556617492

Epoch: 5| Step: 2
Training loss: 0.2812575101852417
Validation loss: 1.6464025961455477

Epoch: 5| Step: 3
Training loss: 0.269596129655838
Validation loss: 1.6113332452312592

Epoch: 5| Step: 4
Training loss: 0.2621868848800659
Validation loss: 1.6006684200738066

Epoch: 5| Step: 5
Training loss: 0.2129964530467987
Validation loss: 1.5937495205992012

Epoch: 5| Step: 6
Training loss: 0.24451589584350586
Validation loss: 1.620797259833223

Epoch: 5| Step: 7
Training loss: 0.1382342129945755
Validation loss: 1.6381175107853387

Epoch: 5| Step: 8
Training loss: 0.17792105674743652
Validation loss: 1.683714796138066

Epoch: 5| Step: 9
Training loss: 0.2411092221736908
Validation loss: 1.7325360172538347

Epoch: 5| Step: 10
Training loss: 0.33760952949523926
Validation loss: 1.77046246938808

Epoch: 369| Step: 0
Training loss: 0.27329161763191223
Validation loss: 1.7776422346791914

Epoch: 5| Step: 1
Training loss: 0.1661980152130127
Validation loss: 1.7725835295133694

Epoch: 5| Step: 2
Training loss: 0.09011539816856384
Validation loss: 1.7227940790114864

Epoch: 5| Step: 3
Training loss: 0.1456678807735443
Validation loss: 1.6741875576716598

Epoch: 5| Step: 4
Training loss: 0.1707954853773117
Validation loss: 1.6427501593866656

Epoch: 5| Step: 5
Training loss: 0.2901034951210022
Validation loss: 1.6002504223136491

Epoch: 5| Step: 6
Training loss: 0.2606934607028961
Validation loss: 1.5880622594587264

Epoch: 5| Step: 7
Training loss: 0.20777758955955505
Validation loss: 1.5962946466220322

Epoch: 5| Step: 8
Training loss: 0.17167167365550995
Validation loss: 1.5992779206204157

Epoch: 5| Step: 9
Training loss: 0.23834355175495148
Validation loss: 1.6113276737992481

Epoch: 5| Step: 10
Training loss: 0.14877526462078094
Validation loss: 1.6539657090299873

Epoch: 370| Step: 0
Training loss: 0.16822731494903564
Validation loss: 1.6897959286166775

Epoch: 5| Step: 1
Training loss: 0.2206869125366211
Validation loss: 1.6996263778337868

Epoch: 5| Step: 2
Training loss: 0.17764058709144592
Validation loss: 1.720897912979126

Epoch: 5| Step: 3
Training loss: 0.19200554490089417
Validation loss: 1.6980103267136442

Epoch: 5| Step: 4
Training loss: 0.1893896758556366
Validation loss: 1.7039882534293718

Epoch: 5| Step: 5
Training loss: 0.3148611783981323
Validation loss: 1.6806091057356967

Epoch: 5| Step: 6
Training loss: 0.1919219195842743
Validation loss: 1.7036297411047003

Epoch: 5| Step: 7
Training loss: 0.14906799793243408
Validation loss: 1.7021379342643164

Epoch: 5| Step: 8
Training loss: 0.20186510682106018
Validation loss: 1.6930239636410949

Epoch: 5| Step: 9
Training loss: 0.1998150646686554
Validation loss: 1.7086878412513322

Epoch: 5| Step: 10
Training loss: 0.21475107967853546
Validation loss: 1.7004277539509598

Epoch: 371| Step: 0
Training loss: 0.22823019325733185
Validation loss: 1.705455259610248

Epoch: 5| Step: 1
Training loss: 0.16123783588409424
Validation loss: 1.6911734278484056

Epoch: 5| Step: 2
Training loss: 0.17181511223316193
Validation loss: 1.692661032881788

Epoch: 5| Step: 3
Training loss: 0.23694129288196564
Validation loss: 1.657583159785117

Epoch: 5| Step: 4
Training loss: 0.17390532791614532
Validation loss: 1.6033674657985728

Epoch: 5| Step: 5
Training loss: 0.22682508826255798
Validation loss: 1.5974928435458933

Epoch: 5| Step: 6
Training loss: 0.14588038623332977
Validation loss: 1.6259158285715247

Epoch: 5| Step: 7
Training loss: 0.2956274449825287
Validation loss: 1.6150392024747786

Epoch: 5| Step: 8
Training loss: 0.14068922400474548
Validation loss: 1.6267032956564298

Epoch: 5| Step: 9
Training loss: 0.22089505195617676
Validation loss: 1.5880285001570178

Epoch: 5| Step: 10
Training loss: 0.244303360581398
Validation loss: 1.6068638986156834

Epoch: 372| Step: 0
Training loss: 0.15453755855560303
Validation loss: 1.5991182045270038

Epoch: 5| Step: 1
Training loss: 0.21312400698661804
Validation loss: 1.6208313908628238

Epoch: 5| Step: 2
Training loss: 0.1567063331604004
Validation loss: 1.6175810931831278

Epoch: 5| Step: 3
Training loss: 0.10035312175750732
Validation loss: 1.621694311018913

Epoch: 5| Step: 4
Training loss: 0.11550585925579071
Validation loss: 1.6083197286052089

Epoch: 5| Step: 5
Training loss: 0.14596343040466309
Validation loss: 1.6539440334484141

Epoch: 5| Step: 6
Training loss: 0.1903758943080902
Validation loss: 1.6624986433213758

Epoch: 5| Step: 7
Training loss: 0.21687431633472443
Validation loss: 1.6780949843827115

Epoch: 5| Step: 8
Training loss: 0.2603512406349182
Validation loss: 1.6406591964024368

Epoch: 5| Step: 9
Training loss: 0.2977142930030823
Validation loss: 1.6559702452792917

Epoch: 5| Step: 10
Training loss: 0.22980527579784393
Validation loss: 1.6361552207700667

Epoch: 373| Step: 0
Training loss: 0.2647460997104645
Validation loss: 1.602562083992907

Epoch: 5| Step: 1
Training loss: 0.2988370656967163
Validation loss: 1.6309162660311627

Epoch: 5| Step: 2
Training loss: 0.1682346612215042
Validation loss: 1.6113584156959289

Epoch: 5| Step: 3
Training loss: 0.1448601484298706
Validation loss: 1.637008805428782

Epoch: 5| Step: 4
Training loss: 0.1358712762594223
Validation loss: 1.6287998089226343

Epoch: 5| Step: 5
Training loss: 0.09125824272632599
Validation loss: 1.6485755930664718

Epoch: 5| Step: 6
Training loss: 0.09397495537996292
Validation loss: 1.6110269049162507

Epoch: 5| Step: 7
Training loss: 0.1556752324104309
Validation loss: 1.647282786266778

Epoch: 5| Step: 8
Training loss: 0.17701099812984467
Validation loss: 1.6268180903568064

Epoch: 5| Step: 9
Training loss: 0.1877911537885666
Validation loss: 1.641393910172165

Epoch: 5| Step: 10
Training loss: 0.12279920279979706
Validation loss: 1.6512004040902661

Epoch: 374| Step: 0
Training loss: 0.1727553904056549
Validation loss: 1.6724105112014278

Epoch: 5| Step: 1
Training loss: 0.11373648792505264
Validation loss: 1.6727446548400386

Epoch: 5| Step: 2
Training loss: 0.11685967445373535
Validation loss: 1.6731984935781008

Epoch: 5| Step: 3
Training loss: 0.1656954437494278
Validation loss: 1.6322462616428253

Epoch: 5| Step: 4
Training loss: 0.08889521658420563
Validation loss: 1.6071898706497685

Epoch: 5| Step: 5
Training loss: 0.18384647369384766
Validation loss: 1.6373274903143606

Epoch: 5| Step: 6
Training loss: 0.24461016058921814
Validation loss: 1.5881763478761077

Epoch: 5| Step: 7
Training loss: 0.26769471168518066
Validation loss: 1.5920928030885675

Epoch: 5| Step: 8
Training loss: 0.21684205532073975
Validation loss: 1.5861256891681301

Epoch: 5| Step: 9
Training loss: 0.19169484078884125
Validation loss: 1.5980589223164383

Epoch: 5| Step: 10
Training loss: 0.1670846790075302
Validation loss: 1.5712159602872786

Epoch: 375| Step: 0
Training loss: 0.12804748117923737
Validation loss: 1.601079252458388

Epoch: 5| Step: 1
Training loss: 0.18004503846168518
Validation loss: 1.6269782999510407

Epoch: 5| Step: 2
Training loss: 0.14445896446704865
Validation loss: 1.6300683893183225

Epoch: 5| Step: 3
Training loss: 0.19111418724060059
Validation loss: 1.6857036736703688

Epoch: 5| Step: 4
Training loss: 0.17465560138225555
Validation loss: 1.7101016916254514

Epoch: 5| Step: 5
Training loss: 0.19122552871704102
Validation loss: 1.704487423742971

Epoch: 5| Step: 6
Training loss: 0.18508364260196686
Validation loss: 1.7045766743280555

Epoch: 5| Step: 7
Training loss: 0.19360831379890442
Validation loss: 1.691234968041861

Epoch: 5| Step: 8
Training loss: 0.09671227633953094
Validation loss: 1.6794660693855696

Epoch: 5| Step: 9
Training loss: 0.22652670741081238
Validation loss: 1.6926040264867968

Epoch: 5| Step: 10
Training loss: 0.24736101925373077
Validation loss: 1.6802363908419045

Epoch: 376| Step: 0
Training loss: 0.19498436152935028
Validation loss: 1.71529979987811

Epoch: 5| Step: 1
Training loss: 0.17963364720344543
Validation loss: 1.7302138690025575

Epoch: 5| Step: 2
Training loss: 0.14063310623168945
Validation loss: 1.7289599654495076

Epoch: 5| Step: 3
Training loss: 0.13157227635383606
Validation loss: 1.7336936214918732

Epoch: 5| Step: 4
Training loss: 0.14753565192222595
Validation loss: 1.7568779933837153

Epoch: 5| Step: 5
Training loss: 0.17412754893302917
Validation loss: 1.7487468847664454

Epoch: 5| Step: 6
Training loss: 0.14279484748840332
Validation loss: 1.7081764257082375

Epoch: 5| Step: 7
Training loss: 0.31778255105018616
Validation loss: 1.6904437888053157

Epoch: 5| Step: 8
Training loss: 0.1840427815914154
Validation loss: 1.681797376243017

Epoch: 5| Step: 9
Training loss: 0.17988070845603943
Validation loss: 1.6439936789133216

Epoch: 5| Step: 10
Training loss: 0.19740545749664307
Validation loss: 1.6690540928994455

Epoch: 377| Step: 0
Training loss: 0.2762685716152191
Validation loss: 1.6934196833641297

Epoch: 5| Step: 1
Training loss: 0.1782475709915161
Validation loss: 1.683079150415236

Epoch: 5| Step: 2
Training loss: 0.18501093983650208
Validation loss: 1.6873766837581512

Epoch: 5| Step: 3
Training loss: 0.16833814978599548
Validation loss: 1.6925908596284929

Epoch: 5| Step: 4
Training loss: 0.12929017841815948
Validation loss: 1.6884844392858527

Epoch: 5| Step: 5
Training loss: 0.1392788141965866
Validation loss: 1.680140305590886

Epoch: 5| Step: 6
Training loss: 0.1593395620584488
Validation loss: 1.681595548506706

Epoch: 5| Step: 7
Training loss: 0.15315203368663788
Validation loss: 1.693527626734908

Epoch: 5| Step: 8
Training loss: 0.09478084743022919
Validation loss: 1.6846466269544376

Epoch: 5| Step: 9
Training loss: 0.1498841792345047
Validation loss: 1.7214460116560741

Epoch: 5| Step: 10
Training loss: 0.12233579903841019
Validation loss: 1.7146969277371642

Epoch: 378| Step: 0
Training loss: 0.1067802757024765
Validation loss: 1.7183082103729248

Epoch: 5| Step: 1
Training loss: 0.1228877529501915
Validation loss: 1.7091387318026634

Epoch: 5| Step: 2
Training loss: 0.1689896285533905
Validation loss: 1.7128902084083968

Epoch: 5| Step: 3
Training loss: 0.186673104763031
Validation loss: 1.738587382019207

Epoch: 5| Step: 4
Training loss: 0.26110225915908813
Validation loss: 1.7100794648611417

Epoch: 5| Step: 5
Training loss: 0.18000656366348267
Validation loss: 1.7118240050090257

Epoch: 5| Step: 6
Training loss: 0.1695556938648224
Validation loss: 1.7180882423154769

Epoch: 5| Step: 7
Training loss: 0.12485511600971222
Validation loss: 1.6861906936091762

Epoch: 5| Step: 8
Training loss: 0.1684776246547699
Validation loss: 1.655891106974694

Epoch: 5| Step: 9
Training loss: 0.147787943482399
Validation loss: 1.6695969476494739

Epoch: 5| Step: 10
Training loss: 0.30524057149887085
Validation loss: 1.6822652175862303

Epoch: 379| Step: 0
Training loss: 0.1614466905593872
Validation loss: 1.6845098682629165

Epoch: 5| Step: 1
Training loss: 0.13166603446006775
Validation loss: 1.6939521886969124

Epoch: 5| Step: 2
Training loss: 0.15262724459171295
Validation loss: 1.69416553871606

Epoch: 5| Step: 3
Training loss: 0.14777971804141998
Validation loss: 1.7109120379212082

Epoch: 5| Step: 4
Training loss: 0.19795487821102142
Validation loss: 1.7189280845785653

Epoch: 5| Step: 5
Training loss: 0.09765125811100006
Validation loss: 1.7107698545661023

Epoch: 5| Step: 6
Training loss: 0.24801930785179138
Validation loss: 1.7314470493665306

Epoch: 5| Step: 7
Training loss: 0.14871154725551605
Validation loss: 1.730147615555794

Epoch: 5| Step: 8
Training loss: 0.09364806860685349
Validation loss: 1.699282564142699

Epoch: 5| Step: 9
Training loss: 0.12741348147392273
Validation loss: 1.6825371826848676

Epoch: 5| Step: 10
Training loss: 0.15163792669773102
Validation loss: 1.6777367720039942

Epoch: 380| Step: 0
Training loss: 0.15699782967567444
Validation loss: 1.671523417195966

Epoch: 5| Step: 1
Training loss: 0.13453474640846252
Validation loss: 1.6599236572942426

Epoch: 5| Step: 2
Training loss: 0.21343474090099335
Validation loss: 1.651067885019446

Epoch: 5| Step: 3
Training loss: 0.14162909984588623
Validation loss: 1.6198962414136497

Epoch: 5| Step: 4
Training loss: 0.15700869262218475
Validation loss: 1.6391151053931123

Epoch: 5| Step: 5
Training loss: 0.14263072609901428
Validation loss: 1.6387830395852365

Epoch: 5| Step: 6
Training loss: 0.16408295929431915
Validation loss: 1.6580872138341267

Epoch: 5| Step: 7
Training loss: 0.21897900104522705
Validation loss: 1.6694887120236632

Epoch: 5| Step: 8
Training loss: 0.17937353253364563
Validation loss: 1.6842460183687107

Epoch: 5| Step: 9
Training loss: 0.16653095185756683
Validation loss: 1.756231366947133

Epoch: 5| Step: 10
Training loss: 0.149602472782135
Validation loss: 1.718716812390153

Epoch: 381| Step: 0
Training loss: 0.09948551654815674
Validation loss: 1.7077039005935832

Epoch: 5| Step: 1
Training loss: 0.10091356933116913
Validation loss: 1.6802563039205407

Epoch: 5| Step: 2
Training loss: 0.14873093366622925
Validation loss: 1.6873278502495057

Epoch: 5| Step: 3
Training loss: 0.19277988374233246
Validation loss: 1.6816921593040548

Epoch: 5| Step: 4
Training loss: 0.11784075200557709
Validation loss: 1.6428871834149925

Epoch: 5| Step: 5
Training loss: 0.19918283820152283
Validation loss: 1.660022485640741

Epoch: 5| Step: 6
Training loss: 0.13415387272834778
Validation loss: 1.645744114793757

Epoch: 5| Step: 7
Training loss: 0.15692372620105743
Validation loss: 1.6546959364286034

Epoch: 5| Step: 8
Training loss: 0.234401136636734
Validation loss: 1.6408125918398622

Epoch: 5| Step: 9
Training loss: 0.15454068779945374
Validation loss: 1.6505045211443337

Epoch: 5| Step: 10
Training loss: 0.15901882946491241
Validation loss: 1.6441572238040227

Epoch: 382| Step: 0
Training loss: 0.08079459518194199
Validation loss: 1.633466342444061

Epoch: 5| Step: 1
Training loss: 0.13810762763023376
Validation loss: 1.6691914168737267

Epoch: 5| Step: 2
Training loss: 0.14992141723632812
Validation loss: 1.6818692940537647

Epoch: 5| Step: 3
Training loss: 0.17938973009586334
Validation loss: 1.6730719894491217

Epoch: 5| Step: 4
Training loss: 0.17241592705249786
Validation loss: 1.7051826536014516

Epoch: 5| Step: 5
Training loss: 0.16014721989631653
Validation loss: 1.7068580735114314

Epoch: 5| Step: 6
Training loss: 0.1714862883090973
Validation loss: 1.6851572913508261

Epoch: 5| Step: 7
Training loss: 0.19444173574447632
Validation loss: 1.642296975658786

Epoch: 5| Step: 8
Training loss: 0.15457959473133087
Validation loss: 1.6502855041975617

Epoch: 5| Step: 9
Training loss: 0.16959556937217712
Validation loss: 1.6236020685524069

Epoch: 5| Step: 10
Training loss: 0.2019352912902832
Validation loss: 1.6256060933554044

Epoch: 383| Step: 0
Training loss: 0.16988018155097961
Validation loss: 1.6389769149082962

Epoch: 5| Step: 1
Training loss: 0.14766016602516174
Validation loss: 1.670900624285462

Epoch: 5| Step: 2
Training loss: 0.21427306532859802
Validation loss: 1.6665350224382134

Epoch: 5| Step: 3
Training loss: 0.12393232434988022
Validation loss: 1.683278533720201

Epoch: 5| Step: 4
Training loss: 0.15572002530097961
Validation loss: 1.6868128545822636

Epoch: 5| Step: 5
Training loss: 0.29911383986473083
Validation loss: 1.681093442824579

Epoch: 5| Step: 6
Training loss: 0.22718481719493866
Validation loss: 1.6654679493237567

Epoch: 5| Step: 7
Training loss: 0.09537583589553833
Validation loss: 1.6514252206330657

Epoch: 5| Step: 8
Training loss: 0.12624302506446838
Validation loss: 1.6170115086340136

Epoch: 5| Step: 9
Training loss: 0.1555398404598236
Validation loss: 1.6249686825659968

Epoch: 5| Step: 10
Training loss: 0.1788892149925232
Validation loss: 1.6222172142356954

Epoch: 384| Step: 0
Training loss: 0.08540727943181992
Validation loss: 1.6268824492731402

Epoch: 5| Step: 1
Training loss: 0.16898474097251892
Validation loss: 1.628098549381379

Epoch: 5| Step: 2
Training loss: 0.2006995677947998
Validation loss: 1.6480717838451426

Epoch: 5| Step: 3
Training loss: 0.18108370900154114
Validation loss: 1.678305628479168

Epoch: 5| Step: 4
Training loss: 0.16251656413078308
Validation loss: 1.6629238923390706

Epoch: 5| Step: 5
Training loss: 0.09958933293819427
Validation loss: 1.6344972207982054

Epoch: 5| Step: 6
Training loss: 0.22475139796733856
Validation loss: 1.625181903121292

Epoch: 5| Step: 7
Training loss: 0.2105645388364792
Validation loss: 1.6019187460663498

Epoch: 5| Step: 8
Training loss: 0.2740006148815155
Validation loss: 1.664974263919297

Epoch: 5| Step: 9
Training loss: 0.16817188262939453
Validation loss: 1.6881122076383202

Epoch: 5| Step: 10
Training loss: 0.13487684726715088
Validation loss: 1.7028643738838933

Epoch: 385| Step: 0
Training loss: 0.11000542342662811
Validation loss: 1.7230724621844549

Epoch: 5| Step: 1
Training loss: 0.11381681263446808
Validation loss: 1.7545975113427767

Epoch: 5| Step: 2
Training loss: 0.18043045699596405
Validation loss: 1.730038676210629

Epoch: 5| Step: 3
Training loss: 0.20402641594409943
Validation loss: 1.722310478969287

Epoch: 5| Step: 4
Training loss: 0.2244245558977127
Validation loss: 1.7002551811997608

Epoch: 5| Step: 5
Training loss: 0.1882457733154297
Validation loss: 1.7242006422370992

Epoch: 5| Step: 6
Training loss: 0.18647484481334686
Validation loss: 1.695726800990361

Epoch: 5| Step: 7
Training loss: 0.2322007119655609
Validation loss: 1.7134113375858595

Epoch: 5| Step: 8
Training loss: 0.18544651567935944
Validation loss: 1.7158894167151502

Epoch: 5| Step: 9
Training loss: 0.147817924618721
Validation loss: 1.6873170829588366

Epoch: 5| Step: 10
Training loss: 0.0916898101568222
Validation loss: 1.6731071549077188

Epoch: 386| Step: 0
Training loss: 0.2008167803287506
Validation loss: 1.6592710723159134

Epoch: 5| Step: 1
Training loss: 0.21428751945495605
Validation loss: 1.6780232626904723

Epoch: 5| Step: 2
Training loss: 0.14362022280693054
Validation loss: 1.665847336092303

Epoch: 5| Step: 3
Training loss: 0.11094534397125244
Validation loss: 1.6531408486827728

Epoch: 5| Step: 4
Training loss: 0.17415080964565277
Validation loss: 1.6493888644761936

Epoch: 5| Step: 5
Training loss: 0.14344096183776855
Validation loss: 1.6339174368048226

Epoch: 5| Step: 6
Training loss: 0.22460612654685974
Validation loss: 1.609205384408274

Epoch: 5| Step: 7
Training loss: 0.20610976219177246
Validation loss: 1.6357754917554959

Epoch: 5| Step: 8
Training loss: 0.10487987846136093
Validation loss: 1.6398751966414913

Epoch: 5| Step: 9
Training loss: 0.09213707596063614
Validation loss: 1.6755785083258024

Epoch: 5| Step: 10
Training loss: 0.20285283029079437
Validation loss: 1.65830139447284

Epoch: 387| Step: 0
Training loss: 0.15261562168598175
Validation loss: 1.658239600478962

Epoch: 5| Step: 1
Training loss: 0.06711218506097794
Validation loss: 1.6626198855779504

Epoch: 5| Step: 2
Training loss: 0.12047278881072998
Validation loss: 1.6520742806055213

Epoch: 5| Step: 3
Training loss: 0.13899953663349152
Validation loss: 1.6175544749024093

Epoch: 5| Step: 4
Training loss: 0.15769091248512268
Validation loss: 1.6247443973377187

Epoch: 5| Step: 5
Training loss: 0.32876524329185486
Validation loss: 1.608389828794746

Epoch: 5| Step: 6
Training loss: 0.16877610981464386
Validation loss: 1.602251322038712

Epoch: 5| Step: 7
Training loss: 0.13942763209342957
Validation loss: 1.610767105574249

Epoch: 5| Step: 8
Training loss: 0.15795667469501495
Validation loss: 1.6146511506008845

Epoch: 5| Step: 9
Training loss: 0.12596707046031952
Validation loss: 1.623854201327088

Epoch: 5| Step: 10
Training loss: 0.13972511887550354
Validation loss: 1.6471579215859855

Epoch: 388| Step: 0
Training loss: 0.1802445352077484
Validation loss: 1.6732938610097414

Epoch: 5| Step: 1
Training loss: 0.13118264079093933
Validation loss: 1.6642368634541829

Epoch: 5| Step: 2
Training loss: 0.12106840312480927
Validation loss: 1.6769392067386257

Epoch: 5| Step: 3
Training loss: 0.1875084936618805
Validation loss: 1.6629060981094197

Epoch: 5| Step: 4
Training loss: 0.10375650227069855
Validation loss: 1.62932982496036

Epoch: 5| Step: 5
Training loss: 0.16834022104740143
Validation loss: 1.5999789648158576

Epoch: 5| Step: 6
Training loss: 0.20516352355480194
Validation loss: 1.599677904959648

Epoch: 5| Step: 7
Training loss: 0.21308307349681854
Validation loss: 1.595906654993693

Epoch: 5| Step: 8
Training loss: 0.1538630723953247
Validation loss: 1.604257140108334

Epoch: 5| Step: 9
Training loss: 0.1688460260629654
Validation loss: 1.5975759490843742

Epoch: 5| Step: 10
Training loss: 0.10024616867303848
Validation loss: 1.6103536159761491

Epoch: 389| Step: 0
Training loss: 0.12320208549499512
Validation loss: 1.6370560763984598

Epoch: 5| Step: 1
Training loss: 0.15729668736457825
Validation loss: 1.6356845401948499

Epoch: 5| Step: 2
Training loss: 0.1817929744720459
Validation loss: 1.6463132135329708

Epoch: 5| Step: 3
Training loss: 0.11295165866613388
Validation loss: 1.6623794494136688

Epoch: 5| Step: 4
Training loss: 0.1239919513463974
Validation loss: 1.658435478005358

Epoch: 5| Step: 5
Training loss: 0.2209833562374115
Validation loss: 1.6570790339541692

Epoch: 5| Step: 6
Training loss: 0.20811998844146729
Validation loss: 1.6849405368169148

Epoch: 5| Step: 7
Training loss: 0.0958155170083046
Validation loss: 1.688605890479139

Epoch: 5| Step: 8
Training loss: 0.09997662156820297
Validation loss: 1.6990715752365768

Epoch: 5| Step: 9
Training loss: 0.12425293773412704
Validation loss: 1.6959365580671577

Epoch: 5| Step: 10
Training loss: 0.13887465000152588
Validation loss: 1.7083139599010508

Epoch: 390| Step: 0
Training loss: 0.09325361251831055
Validation loss: 1.6720313904105977

Epoch: 5| Step: 1
Training loss: 0.15865841507911682
Validation loss: 1.672048839189673

Epoch: 5| Step: 2
Training loss: 0.26988860964775085
Validation loss: 1.678319460602217

Epoch: 5| Step: 3
Training loss: 0.16011735796928406
Validation loss: 1.6832781978832778

Epoch: 5| Step: 4
Training loss: 0.17963184416294098
Validation loss: 1.6584175376481907

Epoch: 5| Step: 5
Training loss: 0.187237948179245
Validation loss: 1.6462121945555492

Epoch: 5| Step: 6
Training loss: 0.17300668358802795
Validation loss: 1.638198430820178

Epoch: 5| Step: 7
Training loss: 0.11704768985509872
Validation loss: 1.6460098220456032

Epoch: 5| Step: 8
Training loss: 0.18601346015930176
Validation loss: 1.6384058690840198

Epoch: 5| Step: 9
Training loss: 0.07245512306690216
Validation loss: 1.6498325947792298

Epoch: 5| Step: 10
Training loss: 0.1802126169204712
Validation loss: 1.6827548152656966

Epoch: 391| Step: 0
Training loss: 0.1905873864889145
Validation loss: 1.6827627151243147

Epoch: 5| Step: 1
Training loss: 0.15983696281909943
Validation loss: 1.6670557580968386

Epoch: 5| Step: 2
Training loss: 0.22689981758594513
Validation loss: 1.633957184771056

Epoch: 5| Step: 3
Training loss: 0.09896792471408844
Validation loss: 1.6141256632343415

Epoch: 5| Step: 4
Training loss: 0.11975955963134766
Validation loss: 1.6145227186141475

Epoch: 5| Step: 5
Training loss: 0.19701151549816132
Validation loss: 1.560216660140663

Epoch: 5| Step: 6
Training loss: 0.10707668215036392
Validation loss: 1.5856024936963153

Epoch: 5| Step: 7
Training loss: 0.07980520278215408
Validation loss: 1.6040696149231286

Epoch: 5| Step: 8
Training loss: 0.1169227808713913
Validation loss: 1.6486074616832118

Epoch: 5| Step: 9
Training loss: 0.12559737265110016
Validation loss: 1.6840435292131157

Epoch: 5| Step: 10
Training loss: 0.14936023950576782
Validation loss: 1.7123941836818573

Epoch: 392| Step: 0
Training loss: 0.16205747425556183
Validation loss: 1.6781988246466524

Epoch: 5| Step: 1
Training loss: 0.14474913477897644
Validation loss: 1.6729496217543078

Epoch: 5| Step: 2
Training loss: 0.11958328634500504
Validation loss: 1.6329396155572706

Epoch: 5| Step: 3
Training loss: 0.0938350185751915
Validation loss: 1.6400860983838317

Epoch: 5| Step: 4
Training loss: 0.13271170854568481
Validation loss: 1.661293791186425

Epoch: 5| Step: 5
Training loss: 0.10022368282079697
Validation loss: 1.6630115765397266

Epoch: 5| Step: 6
Training loss: 0.14903025329113007
Validation loss: 1.6460758569420024

Epoch: 5| Step: 7
Training loss: 0.19720987975597382
Validation loss: 1.6757146504617506

Epoch: 5| Step: 8
Training loss: 0.09568578749895096
Validation loss: 1.6894997217321908

Epoch: 5| Step: 9
Training loss: 0.16912487149238586
Validation loss: 1.6781283194018948

Epoch: 5| Step: 10
Training loss: 0.2870153486728668
Validation loss: 1.6749442879871657

Epoch: 393| Step: 0
Training loss: 0.1586136370897293
Validation loss: 1.6555414187010897

Epoch: 5| Step: 1
Training loss: 0.25566548109054565
Validation loss: 1.6472822543113463

Epoch: 5| Step: 2
Training loss: 0.19122402369976044
Validation loss: 1.6359327954630698

Epoch: 5| Step: 3
Training loss: 0.13790357112884521
Validation loss: 1.6476826821604083

Epoch: 5| Step: 4
Training loss: 0.11158227920532227
Validation loss: 1.6382994100611696

Epoch: 5| Step: 5
Training loss: 0.10995118319988251
Validation loss: 1.6189357503767936

Epoch: 5| Step: 6
Training loss: 0.13583703339099884
Validation loss: 1.6286696189193315

Epoch: 5| Step: 7
Training loss: 0.07160933315753937
Validation loss: 1.626252737096561

Epoch: 5| Step: 8
Training loss: 0.19471828639507294
Validation loss: 1.6421728134155273

Epoch: 5| Step: 9
Training loss: 0.09042736887931824
Validation loss: 1.637439848274313

Epoch: 5| Step: 10
Training loss: 0.14823514223098755
Validation loss: 1.6455919069628562

Epoch: 394| Step: 0
Training loss: 0.11899586766958237
Validation loss: 1.6362872123718262

Epoch: 5| Step: 1
Training loss: 0.0798494964838028
Validation loss: 1.6454743569897068

Epoch: 5| Step: 2
Training loss: 0.08175385743379593
Validation loss: 1.6085172058433614

Epoch: 5| Step: 3
Training loss: 0.21113410592079163
Validation loss: 1.59888030123967

Epoch: 5| Step: 4
Training loss: 0.08408989757299423
Validation loss: 1.6393815676371257

Epoch: 5| Step: 5
Training loss: 0.16038274765014648
Validation loss: 1.6350841470943984

Epoch: 5| Step: 6
Training loss: 0.1266104280948639
Validation loss: 1.6545298137972433

Epoch: 5| Step: 7
Training loss: 0.1641327440738678
Validation loss: 1.644487629654587

Epoch: 5| Step: 8
Training loss: 0.15926656126976013
Validation loss: 1.6664551137596049

Epoch: 5| Step: 9
Training loss: 0.17459286749362946
Validation loss: 1.6476172336968042

Epoch: 5| Step: 10
Training loss: 0.10367929190397263
Validation loss: 1.6445855632905038

Epoch: 395| Step: 0
Training loss: 0.13121119141578674
Validation loss: 1.6570111013227893

Epoch: 5| Step: 1
Training loss: 0.06925509870052338
Validation loss: 1.631152227360715

Epoch: 5| Step: 2
Training loss: 0.12678366899490356
Validation loss: 1.6501102524418985

Epoch: 5| Step: 3
Training loss: 0.1265072524547577
Validation loss: 1.6467104150402931

Epoch: 5| Step: 4
Training loss: 0.09408906102180481
Validation loss: 1.6462417879412252

Epoch: 5| Step: 5
Training loss: 0.11143036186695099
Validation loss: 1.6550407384031562

Epoch: 5| Step: 6
Training loss: 0.11885811388492584
Validation loss: 1.6452959891288512

Epoch: 5| Step: 7
Training loss: 0.1247035413980484
Validation loss: 1.6263719694588774

Epoch: 5| Step: 8
Training loss: 0.2609575688838959
Validation loss: 1.6236612707056024

Epoch: 5| Step: 9
Training loss: 0.18300941586494446
Validation loss: 1.6266558606137511

Epoch: 5| Step: 10
Training loss: 0.21081075072288513
Validation loss: 1.6122371855602469

Epoch: 396| Step: 0
Training loss: 0.20147740840911865
Validation loss: 1.613090649727852

Epoch: 5| Step: 1
Training loss: 0.1477302759885788
Validation loss: 1.6304600315709268

Epoch: 5| Step: 2
Training loss: 0.1526893675327301
Validation loss: 1.6450053491900045

Epoch: 5| Step: 3
Training loss: 0.15511520206928253
Validation loss: 1.6510178786452099

Epoch: 5| Step: 4
Training loss: 0.11808977276086807
Validation loss: 1.645406102621427

Epoch: 5| Step: 5
Training loss: 0.12882016599178314
Validation loss: 1.6088940225621706

Epoch: 5| Step: 6
Training loss: 0.11620566993951797
Validation loss: 1.6241509709306943

Epoch: 5| Step: 7
Training loss: 0.11200358718633652
Validation loss: 1.6108355342700917

Epoch: 5| Step: 8
Training loss: 0.1548192799091339
Validation loss: 1.625941543168919

Epoch: 5| Step: 9
Training loss: 0.1757550984621048
Validation loss: 1.6184542102198447

Epoch: 5| Step: 10
Training loss: 0.16196037828922272
Validation loss: 1.6250260209524503

Epoch: 397| Step: 0
Training loss: 0.10342307388782501
Validation loss: 1.6132458345864409

Epoch: 5| Step: 1
Training loss: 0.10207052528858185
Validation loss: 1.5858279569174654

Epoch: 5| Step: 2
Training loss: 0.09519164264202118
Validation loss: 1.6216752195871005

Epoch: 5| Step: 3
Training loss: 0.10903646796941757
Validation loss: 1.6225402701285578

Epoch: 5| Step: 4
Training loss: 0.09097065031528473
Validation loss: 1.6507568417056915

Epoch: 5| Step: 5
Training loss: 0.08218605816364288
Validation loss: 1.6645625970696891

Epoch: 5| Step: 6
Training loss: 0.1568477302789688
Validation loss: 1.6624579557808496

Epoch: 5| Step: 7
Training loss: 0.1315324902534485
Validation loss: 1.6760257546619703

Epoch: 5| Step: 8
Training loss: 0.1326635777950287
Validation loss: 1.6616796421748337

Epoch: 5| Step: 9
Training loss: 0.17402121424674988
Validation loss: 1.6586741734576482

Epoch: 5| Step: 10
Training loss: 0.3822561800479889
Validation loss: 1.6866620509855208

Epoch: 398| Step: 0
Training loss: 0.08244586735963821
Validation loss: 1.6678564349810283

Epoch: 5| Step: 1
Training loss: 0.18550002574920654
Validation loss: 1.621159759900903

Epoch: 5| Step: 2
Training loss: 0.15461456775665283
Validation loss: 1.5859382088466356

Epoch: 5| Step: 3
Training loss: 0.19126001000404358
Validation loss: 1.6055932493620022

Epoch: 5| Step: 4
Training loss: 0.15231125056743622
Validation loss: 1.5949170922720304

Epoch: 5| Step: 5
Training loss: 0.10108932107686996
Validation loss: 1.586380862420605

Epoch: 5| Step: 6
Training loss: 0.19980524480342865
Validation loss: 1.6296579068706882

Epoch: 5| Step: 7
Training loss: 0.11383514106273651
Validation loss: 1.6327082533990183

Epoch: 5| Step: 8
Training loss: 0.1669873297214508
Validation loss: 1.6237703715601275

Epoch: 5| Step: 9
Training loss: 0.16528932750225067
Validation loss: 1.6810058188694779

Epoch: 5| Step: 10
Training loss: 0.15659932792186737
Validation loss: 1.6822853511379612

Epoch: 399| Step: 0
Training loss: 0.15690012276172638
Validation loss: 1.6760180598946028

Epoch: 5| Step: 1
Training loss: 0.09735782444477081
Validation loss: 1.6656611119547198

Epoch: 5| Step: 2
Training loss: 0.15434247255325317
Validation loss: 1.6316938323359336

Epoch: 5| Step: 3
Training loss: 0.13942046463489532
Validation loss: 1.6174785129485592

Epoch: 5| Step: 4
Training loss: 0.2099665403366089
Validation loss: 1.584025216358964

Epoch: 5| Step: 5
Training loss: 0.1534654200077057
Validation loss: 1.551085961762295

Epoch: 5| Step: 6
Training loss: 0.14582927525043488
Validation loss: 1.5846281538727462

Epoch: 5| Step: 7
Training loss: 0.11909008026123047
Validation loss: 1.5436047161779096

Epoch: 5| Step: 8
Training loss: 0.2252412736415863
Validation loss: 1.5744647633644842

Epoch: 5| Step: 9
Training loss: 0.27685263752937317
Validation loss: 1.6113068749827724

Epoch: 5| Step: 10
Training loss: 0.08228737860918045
Validation loss: 1.6368296261756652

Epoch: 400| Step: 0
Training loss: 0.20300325751304626
Validation loss: 1.6517011478383055

Epoch: 5| Step: 1
Training loss: 0.14832055568695068
Validation loss: 1.6456060512091524

Epoch: 5| Step: 2
Training loss: 0.13057830929756165
Validation loss: 1.6617019612302062

Epoch: 5| Step: 3
Training loss: 0.1526319980621338
Validation loss: 1.6336542380753385

Epoch: 5| Step: 4
Training loss: 0.1107947826385498
Validation loss: 1.6293098721452939

Epoch: 5| Step: 5
Training loss: 0.1645050346851349
Validation loss: 1.624616817761493

Epoch: 5| Step: 6
Training loss: 0.13600441813468933
Validation loss: 1.6204450899554836

Epoch: 5| Step: 7
Training loss: 0.20312073826789856
Validation loss: 1.6359697131700413

Epoch: 5| Step: 8
Training loss: 0.14268091320991516
Validation loss: 1.6465919171610186

Epoch: 5| Step: 9
Training loss: 0.12637832760810852
Validation loss: 1.6668805922231367

Epoch: 5| Step: 10
Training loss: 0.19387470185756683
Validation loss: 1.6844517210478425

Epoch: 401| Step: 0
Training loss: 0.15174129605293274
Validation loss: 1.6958866042475547

Epoch: 5| Step: 1
Training loss: 0.13521930575370789
Validation loss: 1.6894153728280017

Epoch: 5| Step: 2
Training loss: 0.16090723872184753
Validation loss: 1.6634604879604873

Epoch: 5| Step: 3
Training loss: 0.18909038603305817
Validation loss: 1.6405988175381896

Epoch: 5| Step: 4
Training loss: 0.11205554008483887
Validation loss: 1.6245616501377476

Epoch: 5| Step: 5
Training loss: 0.12233307212591171
Validation loss: 1.618487577284536

Epoch: 5| Step: 6
Training loss: 0.18294990062713623
Validation loss: 1.5944762524738108

Epoch: 5| Step: 7
Training loss: 0.13894037902355194
Validation loss: 1.6154101638383762

Epoch: 5| Step: 8
Training loss: 0.12265738099813461
Validation loss: 1.6127463194631761

Epoch: 5| Step: 9
Training loss: 0.20386652648448944
Validation loss: 1.6262929272908035

Epoch: 5| Step: 10
Training loss: 0.17277003824710846
Validation loss: 1.6533730632515364

Epoch: 402| Step: 0
Training loss: 0.1636657565832138
Validation loss: 1.6600302329627417

Epoch: 5| Step: 1
Training loss: 0.14892470836639404
Validation loss: 1.673398522920506

Epoch: 5| Step: 2
Training loss: 0.1635223627090454
Validation loss: 1.648441844089057

Epoch: 5| Step: 3
Training loss: 0.11219505965709686
Validation loss: 1.6145691102550876

Epoch: 5| Step: 4
Training loss: 0.08658395707607269
Validation loss: 1.6110039757144066

Epoch: 5| Step: 5
Training loss: 0.1582355797290802
Validation loss: 1.5773449751638597

Epoch: 5| Step: 6
Training loss: 0.16983118653297424
Validation loss: 1.5927055394777687

Epoch: 5| Step: 7
Training loss: 0.16942362487316132
Validation loss: 1.6022067531462638

Epoch: 5| Step: 8
Training loss: 0.10423803329467773
Validation loss: 1.6357818290751467

Epoch: 5| Step: 9
Training loss: 0.1274408996105194
Validation loss: 1.6139895121256511

Epoch: 5| Step: 10
Training loss: 0.20546302199363708
Validation loss: 1.6436908065631826

Epoch: 403| Step: 0
Training loss: 0.1533229649066925
Validation loss: 1.6911066757735385

Epoch: 5| Step: 1
Training loss: 0.12911158800125122
Validation loss: 1.645394048383159

Epoch: 5| Step: 2
Training loss: 0.15723058581352234
Validation loss: 1.607434320193465

Epoch: 5| Step: 3
Training loss: 0.08574192225933075
Validation loss: 1.5724530707123459

Epoch: 5| Step: 4
Training loss: 0.17891670763492584
Validation loss: 1.5759530016171035

Epoch: 5| Step: 5
Training loss: 0.2173599749803543
Validation loss: 1.553388435353515

Epoch: 5| Step: 6
Training loss: 0.08691613376140594
Validation loss: 1.5791816083333825

Epoch: 5| Step: 7
Training loss: 0.15669122338294983
Validation loss: 1.5633945208723827

Epoch: 5| Step: 8
Training loss: 0.16980504989624023
Validation loss: 1.58539500159602

Epoch: 5| Step: 9
Training loss: 0.14934153854846954
Validation loss: 1.621544332914455

Epoch: 5| Step: 10
Training loss: 0.18186692893505096
Validation loss: 1.6153056519005888

Epoch: 404| Step: 0
Training loss: 0.12756335735321045
Validation loss: 1.6242994762236072

Epoch: 5| Step: 1
Training loss: 0.09451550990343094
Validation loss: 1.609355261248927

Epoch: 5| Step: 2
Training loss: 0.22444529831409454
Validation loss: 1.6164782688181887

Epoch: 5| Step: 3
Training loss: 0.08656095713376999
Validation loss: 1.5879014384362005

Epoch: 5| Step: 4
Training loss: 0.1307380497455597
Validation loss: 1.5964242425016177

Epoch: 5| Step: 5
Training loss: 0.10810937732458115
Validation loss: 1.6072075969429427

Epoch: 5| Step: 6
Training loss: 0.10897479951381683
Validation loss: 1.5950448301530653

Epoch: 5| Step: 7
Training loss: 0.1416464000940323
Validation loss: 1.6021208455485683

Epoch: 5| Step: 8
Training loss: 0.12273271381855011
Validation loss: 1.643587717445948

Epoch: 5| Step: 9
Training loss: 0.1517641842365265
Validation loss: 1.6237572726383005

Epoch: 5| Step: 10
Training loss: 0.118894562125206
Validation loss: 1.6504318073231687

Epoch: 405| Step: 0
Training loss: 0.10098443180322647
Validation loss: 1.6728704103859522

Epoch: 5| Step: 1
Training loss: 0.10306577384471893
Validation loss: 1.6760735537416191

Epoch: 5| Step: 2
Training loss: 0.1411774903535843
Validation loss: 1.6827741451160882

Epoch: 5| Step: 3
Training loss: 0.07915330678224564
Validation loss: 1.6797378704112063

Epoch: 5| Step: 4
Training loss: 0.24556338787078857
Validation loss: 1.6798721846713816

Epoch: 5| Step: 5
Training loss: 0.21756848692893982
Validation loss: 1.6316375001784293

Epoch: 5| Step: 6
Training loss: 0.1037069708108902
Validation loss: 1.6098659269271358

Epoch: 5| Step: 7
Training loss: 0.07385535538196564
Validation loss: 1.5949987365353493

Epoch: 5| Step: 8
Training loss: 0.14458715915679932
Validation loss: 1.561329100721626

Epoch: 5| Step: 9
Training loss: 0.22120527923107147
Validation loss: 1.561789693370942

Epoch: 5| Step: 10
Training loss: 0.09428297728300095
Validation loss: 1.6188029807101014

Epoch: 406| Step: 0
Training loss: 0.2204241007566452
Validation loss: 1.666831588232389

Epoch: 5| Step: 1
Training loss: 0.15524539351463318
Validation loss: 1.675028234399775

Epoch: 5| Step: 2
Training loss: 0.22204121947288513
Validation loss: 1.6934550859594857

Epoch: 5| Step: 3
Training loss: 0.16644978523254395
Validation loss: 1.7030816719096193

Epoch: 5| Step: 4
Training loss: 0.18861116468906403
Validation loss: 1.711120464468515

Epoch: 5| Step: 5
Training loss: 0.07636900246143341
Validation loss: 1.6995815897500643

Epoch: 5| Step: 6
Training loss: 0.12763690948486328
Validation loss: 1.6553759100616618

Epoch: 5| Step: 7
Training loss: 0.10958321392536163
Validation loss: 1.6350586427155362

Epoch: 5| Step: 8
Training loss: 0.10584387928247452
Validation loss: 1.609728883030594

Epoch: 5| Step: 9
Training loss: 0.15551277995109558
Validation loss: 1.6002888141139862

Epoch: 5| Step: 10
Training loss: 0.20635148882865906
Validation loss: 1.5869113668318717

Epoch: 407| Step: 0
Training loss: 0.1253470629453659
Validation loss: 1.57515771542826

Epoch: 5| Step: 1
Training loss: 0.18115456402301788
Validation loss: 1.5988823726613035

Epoch: 5| Step: 2
Training loss: 0.1515195667743683
Validation loss: 1.636173011154257

Epoch: 5| Step: 3
Training loss: 0.1289023607969284
Validation loss: 1.681538934348732

Epoch: 5| Step: 4
Training loss: 0.15610817074775696
Validation loss: 1.6754220608742005

Epoch: 5| Step: 5
Training loss: 0.15946002304553986
Validation loss: 1.693258946941745

Epoch: 5| Step: 6
Training loss: 0.1716523915529251
Validation loss: 1.6658398310343425

Epoch: 5| Step: 7
Training loss: 0.08835653215646744
Validation loss: 1.6317640119983303

Epoch: 5| Step: 8
Training loss: 0.1571105420589447
Validation loss: 1.6164331782248713

Epoch: 5| Step: 9
Training loss: 0.11613209545612335
Validation loss: 1.586949288204152

Epoch: 5| Step: 10
Training loss: 0.13786518573760986
Validation loss: 1.575605357846906

Epoch: 408| Step: 0
Training loss: 0.0946987047791481
Validation loss: 1.6142527236733386

Epoch: 5| Step: 1
Training loss: 0.09840591996908188
Validation loss: 1.6052373154188997

Epoch: 5| Step: 2
Training loss: 0.13631847500801086
Validation loss: 1.6293405339282045

Epoch: 5| Step: 3
Training loss: 0.1371435821056366
Validation loss: 1.6237344895639727

Epoch: 5| Step: 4
Training loss: 0.09976024925708771
Validation loss: 1.624270954439717

Epoch: 5| Step: 5
Training loss: 0.12350122630596161
Validation loss: 1.6298329907078897

Epoch: 5| Step: 6
Training loss: 0.12625561654567719
Validation loss: 1.6190844646064184

Epoch: 5| Step: 7
Training loss: 0.10939568281173706
Validation loss: 1.6468464097669047

Epoch: 5| Step: 8
Training loss: 0.15184907615184784
Validation loss: 1.6096362054988902

Epoch: 5| Step: 9
Training loss: 0.23079967498779297
Validation loss: 1.6096967292088333

Epoch: 5| Step: 10
Training loss: 0.13651472330093384
Validation loss: 1.6057699303473196

Epoch: 409| Step: 0
Training loss: 0.11435399949550629
Validation loss: 1.6197522417191537

Epoch: 5| Step: 1
Training loss: 0.111676886677742
Validation loss: 1.6028209065878263

Epoch: 5| Step: 2
Training loss: 0.22020933032035828
Validation loss: 1.607484270167607

Epoch: 5| Step: 3
Training loss: 0.1445283591747284
Validation loss: 1.6022317114696707

Epoch: 5| Step: 4
Training loss: 0.10221324115991592
Validation loss: 1.6093772124218684

Epoch: 5| Step: 5
Training loss: 0.12063063681125641
Validation loss: 1.59484742277412

Epoch: 5| Step: 6
Training loss: 0.12048482894897461
Validation loss: 1.590251075965102

Epoch: 5| Step: 7
Training loss: 0.07507313787937164
Validation loss: 1.6426474291791198

Epoch: 5| Step: 8
Training loss: 0.08928393572568893
Validation loss: 1.6147830229933544

Epoch: 5| Step: 9
Training loss: 0.11848962306976318
Validation loss: 1.6324067141420098

Epoch: 5| Step: 10
Training loss: 0.10352582484483719
Validation loss: 1.6413035444034043

Epoch: 410| Step: 0
Training loss: 0.11180295795202255
Validation loss: 1.6726592112612981

Epoch: 5| Step: 1
Training loss: 0.1134352907538414
Validation loss: 1.6608068712296025

Epoch: 5| Step: 2
Training loss: 0.1114819198846817
Validation loss: 1.665893949488158

Epoch: 5| Step: 3
Training loss: 0.11407196521759033
Validation loss: 1.6893379995899815

Epoch: 5| Step: 4
Training loss: 0.1496766060590744
Validation loss: 1.7084098797972485

Epoch: 5| Step: 5
Training loss: 0.11458579450845718
Validation loss: 1.6704774133620723

Epoch: 5| Step: 6
Training loss: 0.21223409473896027
Validation loss: 1.631774171706169

Epoch: 5| Step: 7
Training loss: 0.19641265273094177
Validation loss: 1.581894746390722

Epoch: 5| Step: 8
Training loss: 0.14976979792118073
Validation loss: 1.5749817279077345

Epoch: 5| Step: 9
Training loss: 0.13440805673599243
Validation loss: 1.5868745670523694

Epoch: 5| Step: 10
Training loss: 0.1142449826002121
Validation loss: 1.5743763856990363

Epoch: 411| Step: 0
Training loss: 0.14065515995025635
Validation loss: 1.5867879211261708

Epoch: 5| Step: 1
Training loss: 0.11332333087921143
Validation loss: 1.5754091162835397

Epoch: 5| Step: 2
Training loss: 0.13471026718616486
Validation loss: 1.5864395480002127

Epoch: 5| Step: 3
Training loss: 0.14245641231536865
Validation loss: 1.600878938551872

Epoch: 5| Step: 4
Training loss: 0.15764231979846954
Validation loss: 1.6062434052908292

Epoch: 5| Step: 5
Training loss: 0.058821260929107666
Validation loss: 1.6201983856898483

Epoch: 5| Step: 6
Training loss: 0.10230465233325958
Validation loss: 1.605722091531241

Epoch: 5| Step: 7
Training loss: 0.14507348835468292
Validation loss: 1.6392354285845192

Epoch: 5| Step: 8
Training loss: 0.10443112999200821
Validation loss: 1.6432092830698977

Epoch: 5| Step: 9
Training loss: 0.12778496742248535
Validation loss: 1.6599993346839823

Epoch: 5| Step: 10
Training loss: 0.21242830157279968
Validation loss: 1.651503147617463

Epoch: 412| Step: 0
Training loss: 0.12567627429962158
Validation loss: 1.6572946476679977

Epoch: 5| Step: 1
Training loss: 0.18085993826389313
Validation loss: 1.6835037110954203

Epoch: 5| Step: 2
Training loss: 0.09578458219766617
Validation loss: 1.6599861216801468

Epoch: 5| Step: 3
Training loss: 0.08179798722267151
Validation loss: 1.63320755445829

Epoch: 5| Step: 4
Training loss: 0.0943291038274765
Validation loss: 1.608192463074961

Epoch: 5| Step: 5
Training loss: 0.09425872564315796
Validation loss: 1.6184039782452326

Epoch: 5| Step: 6
Training loss: 0.14118489623069763
Validation loss: 1.6114474650352233

Epoch: 5| Step: 7
Training loss: 0.10742110013961792
Validation loss: 1.6238088838515743

Epoch: 5| Step: 8
Training loss: 0.21874091029167175
Validation loss: 1.6246147104488906

Epoch: 5| Step: 9
Training loss: 0.12361957877874374
Validation loss: 1.625697184634465

Epoch: 5| Step: 10
Training loss: 0.17380256950855255
Validation loss: 1.6342993436321136

Epoch: 413| Step: 0
Training loss: 0.1705295592546463
Validation loss: 1.6190239062873266

Epoch: 5| Step: 1
Training loss: 0.13095197081565857
Validation loss: 1.626198935252364

Epoch: 5| Step: 2
Training loss: 0.09315566718578339
Validation loss: 1.6064369191405594

Epoch: 5| Step: 3
Training loss: 0.08873562514781952
Validation loss: 1.6256684859593709

Epoch: 5| Step: 4
Training loss: 0.1290329247713089
Validation loss: 1.6537442091972596

Epoch: 5| Step: 5
Training loss: 0.07178325951099396
Validation loss: 1.640901865497712

Epoch: 5| Step: 6
Training loss: 0.15894097089767456
Validation loss: 1.661200831013341

Epoch: 5| Step: 7
Training loss: 0.11390233039855957
Validation loss: 1.6764229894966207

Epoch: 5| Step: 8
Training loss: 0.12851674854755402
Validation loss: 1.666719034153928

Epoch: 5| Step: 9
Training loss: 0.15166492760181427
Validation loss: 1.6590097347895305

Epoch: 5| Step: 10
Training loss: 0.15799759328365326
Validation loss: 1.6948014151665471

Epoch: 414| Step: 0
Training loss: 0.07727702707052231
Validation loss: 1.6479977619263433

Epoch: 5| Step: 1
Training loss: 0.12408418953418732
Validation loss: 1.6423908869425456

Epoch: 5| Step: 2
Training loss: 0.06613438576459885
Validation loss: 1.6185083773828322

Epoch: 5| Step: 3
Training loss: 0.1655077040195465
Validation loss: 1.6275971871550365

Epoch: 5| Step: 4
Training loss: 0.22053904831409454
Validation loss: 1.6454725983322307

Epoch: 5| Step: 5
Training loss: 0.07535567134618759
Validation loss: 1.6466823265116701

Epoch: 5| Step: 6
Training loss: 0.09073551744222641
Validation loss: 1.6754702278362807

Epoch: 5| Step: 7
Training loss: 0.1256638765335083
Validation loss: 1.6699299543134627

Epoch: 5| Step: 8
Training loss: 0.15543170273303986
Validation loss: 1.7214710353523173

Epoch: 5| Step: 9
Training loss: 0.2377249002456665
Validation loss: 1.7311774428172777

Epoch: 5| Step: 10
Training loss: 0.12793204188346863
Validation loss: 1.72758230727206

Epoch: 415| Step: 0
Training loss: 0.19890089333057404
Validation loss: 1.6896851639593802

Epoch: 5| Step: 1
Training loss: 0.15402822196483612
Validation loss: 1.6842690552434614

Epoch: 5| Step: 2
Training loss: 0.07144670933485031
Validation loss: 1.6606183680154945

Epoch: 5| Step: 3
Training loss: 0.14823664724826813
Validation loss: 1.6552676757176716

Epoch: 5| Step: 4
Training loss: 0.16010014712810516
Validation loss: 1.6666765841104652

Epoch: 5| Step: 5
Training loss: 0.0942840725183487
Validation loss: 1.648643914089408

Epoch: 5| Step: 6
Training loss: 0.12728892266750336
Validation loss: 1.7065440249699417

Epoch: 5| Step: 7
Training loss: 0.14144550263881683
Validation loss: 1.6926598907798849

Epoch: 5| Step: 8
Training loss: 0.11558276414871216
Validation loss: 1.7124970484805364

Epoch: 5| Step: 9
Training loss: 0.14336594939231873
Validation loss: 1.6983864743222472

Epoch: 5| Step: 10
Training loss: 0.16696058213710785
Validation loss: 1.6542397147865706

Epoch: 416| Step: 0
Training loss: 0.082920141518116
Validation loss: 1.6356638195694133

Epoch: 5| Step: 1
Training loss: 0.2142307311296463
Validation loss: 1.598833135379258

Epoch: 5| Step: 2
Training loss: 0.14530476927757263
Validation loss: 1.593107477311165

Epoch: 5| Step: 3
Training loss: 0.17748446762561798
Validation loss: 1.6056924520000335

Epoch: 5| Step: 4
Training loss: 0.18102887272834778
Validation loss: 1.616242952244256

Epoch: 5| Step: 5
Training loss: 0.09235165268182755
Validation loss: 1.6233404297982492

Epoch: 5| Step: 6
Training loss: 0.13378524780273438
Validation loss: 1.6416675198462702

Epoch: 5| Step: 7
Training loss: 0.15824417769908905
Validation loss: 1.6579315905929894

Epoch: 5| Step: 8
Training loss: 0.17948761582374573
Validation loss: 1.641097528960115

Epoch: 5| Step: 9
Training loss: 0.22340063750743866
Validation loss: 1.6360170187488678

Epoch: 5| Step: 10
Training loss: 0.08837027102708817
Validation loss: 1.6214538081999748

Epoch: 417| Step: 0
Training loss: 0.13488489389419556
Validation loss: 1.6199451582406157

Epoch: 5| Step: 1
Training loss: 0.12139077484607697
Validation loss: 1.5996527646177559

Epoch: 5| Step: 2
Training loss: 0.17885883152484894
Validation loss: 1.649054399100683

Epoch: 5| Step: 3
Training loss: 0.16422918438911438
Validation loss: 1.6707540135229788

Epoch: 5| Step: 4
Training loss: 0.20210044085979462
Validation loss: 1.6583416359398955

Epoch: 5| Step: 5
Training loss: 0.14487893879413605
Validation loss: 1.67322991612137

Epoch: 5| Step: 6
Training loss: 0.14280545711517334
Validation loss: 1.7166702696072158

Epoch: 5| Step: 7
Training loss: 0.17311671376228333
Validation loss: 1.6883561764993975

Epoch: 5| Step: 8
Training loss: 0.08223170787096024
Validation loss: 1.6571800439588484

Epoch: 5| Step: 9
Training loss: 0.10720999538898468
Validation loss: 1.6517098526800833

Epoch: 5| Step: 10
Training loss: 0.18506558239459991
Validation loss: 1.6254467887263144

Epoch: 418| Step: 0
Training loss: 0.12976233661174774
Validation loss: 1.631694902655899

Epoch: 5| Step: 1
Training loss: 0.0970253199338913
Validation loss: 1.6296468825750454

Epoch: 5| Step: 2
Training loss: 0.13365238904953003
Validation loss: 1.6314490072188839

Epoch: 5| Step: 3
Training loss: 0.15515567362308502
Validation loss: 1.6281724514499787

Epoch: 5| Step: 4
Training loss: 0.07107248157262802
Validation loss: 1.6257181885421916

Epoch: 5| Step: 5
Training loss: 0.15373268723487854
Validation loss: 1.6385904486461351

Epoch: 5| Step: 6
Training loss: 0.23402634263038635
Validation loss: 1.6704346825999599

Epoch: 5| Step: 7
Training loss: 0.22852244973182678
Validation loss: 1.6528084175561064

Epoch: 5| Step: 8
Training loss: 0.09725023806095123
Validation loss: 1.6565476104777346

Epoch: 5| Step: 9
Training loss: 0.12145586311817169
Validation loss: 1.6478553484844904

Epoch: 5| Step: 10
Training loss: 0.14667777717113495
Validation loss: 1.6253683336319462

Epoch: 419| Step: 0
Training loss: 0.10867886245250702
Validation loss: 1.6778744266879173

Epoch: 5| Step: 1
Training loss: 0.13123387098312378
Validation loss: 1.6930928922468615

Epoch: 5| Step: 2
Training loss: 0.19110119342803955
Validation loss: 1.6530454633056477

Epoch: 5| Step: 3
Training loss: 0.09531621634960175
Validation loss: 1.6742007142754012

Epoch: 5| Step: 4
Training loss: 0.22455620765686035
Validation loss: 1.6617796356960008

Epoch: 5| Step: 5
Training loss: 0.12543447315692902
Validation loss: 1.6811563366202897

Epoch: 5| Step: 6
Training loss: 0.16043353080749512
Validation loss: 1.6595385343797746

Epoch: 5| Step: 7
Training loss: 0.11827118694782257
Validation loss: 1.6211226883754934

Epoch: 5| Step: 8
Training loss: 0.10815711319446564
Validation loss: 1.6162735364770378

Epoch: 5| Step: 9
Training loss: 0.13987520337104797
Validation loss: 1.6087882813586984

Epoch: 5| Step: 10
Training loss: 0.18116417527198792
Validation loss: 1.5610764436824347

Epoch: 420| Step: 0
Training loss: 0.2122316062450409
Validation loss: 1.584334708029224

Epoch: 5| Step: 1
Training loss: 0.09879959374666214
Validation loss: 1.5811184529335267

Epoch: 5| Step: 2
Training loss: 0.11436085402965546
Validation loss: 1.5939956031819826

Epoch: 5| Step: 3
Training loss: 0.18699949979782104
Validation loss: 1.6372453442183874

Epoch: 5| Step: 4
Training loss: 0.15215235948562622
Validation loss: 1.6341697900525984

Epoch: 5| Step: 5
Training loss: 0.11619991064071655
Validation loss: 1.6078694174366612

Epoch: 5| Step: 6
Training loss: 0.10155598819255829
Validation loss: 1.5854899011632448

Epoch: 5| Step: 7
Training loss: 0.09770544618368149
Validation loss: 1.5777997406580115

Epoch: 5| Step: 8
Training loss: 0.20103788375854492
Validation loss: 1.5499798617055338

Epoch: 5| Step: 9
Training loss: 0.09615211933851242
Validation loss: 1.5654012785162976

Epoch: 5| Step: 10
Training loss: 0.13010883331298828
Validation loss: 1.561212420463562

Epoch: 421| Step: 0
Training loss: 0.21699388325214386
Validation loss: 1.5600068415364912

Epoch: 5| Step: 1
Training loss: 0.09073736518621445
Validation loss: 1.600797071251818

Epoch: 5| Step: 2
Training loss: 0.0775202065706253
Validation loss: 1.6057030936723113

Epoch: 5| Step: 3
Training loss: 0.2032744139432907
Validation loss: 1.630543815192356

Epoch: 5| Step: 4
Training loss: 0.10195542871952057
Validation loss: 1.6207137357804082

Epoch: 5| Step: 5
Training loss: 0.1503891497850418
Validation loss: 1.6399223214836531

Epoch: 5| Step: 6
Training loss: 0.09642945975065231
Validation loss: 1.6145459195618987

Epoch: 5| Step: 7
Training loss: 0.06603285670280457
Validation loss: 1.6000392847163702

Epoch: 5| Step: 8
Training loss: 0.13759355247020721
Validation loss: 1.5694105625152588

Epoch: 5| Step: 9
Training loss: 0.12831424176692963
Validation loss: 1.5432011132599206

Epoch: 5| Step: 10
Training loss: 0.1306426227092743
Validation loss: 1.5648999714082288

Epoch: 422| Step: 0
Training loss: 0.19481605291366577
Validation loss: 1.562413961656632

Epoch: 5| Step: 1
Training loss: 0.07206015288829803
Validation loss: 1.5783380603277555

Epoch: 5| Step: 2
Training loss: 0.08654380589723587
Validation loss: 1.5985512207913142

Epoch: 5| Step: 3
Training loss: 0.09881611913442612
Validation loss: 1.6061127314003565

Epoch: 5| Step: 4
Training loss: 0.15758410096168518
Validation loss: 1.6021460115268666

Epoch: 5| Step: 5
Training loss: 0.10619871318340302
Validation loss: 1.6336016578059043

Epoch: 5| Step: 6
Training loss: 0.08631740510463715
Validation loss: 1.6374002066991662

Epoch: 5| Step: 7
Training loss: 0.17799393832683563
Validation loss: 1.655217052787863

Epoch: 5| Step: 8
Training loss: 0.10656902939081192
Validation loss: 1.6408214402455155

Epoch: 5| Step: 9
Training loss: 0.19961360096931458
Validation loss: 1.6376836517805695

Epoch: 5| Step: 10
Training loss: 0.11386332660913467
Validation loss: 1.6245127057516446

Epoch: 423| Step: 0
Training loss: 0.1640489399433136
Validation loss: 1.6242121919508903

Epoch: 5| Step: 1
Training loss: 0.0843302384018898
Validation loss: 1.6049178390092746

Epoch: 5| Step: 2
Training loss: 0.15969648957252502
Validation loss: 1.6159951738131944

Epoch: 5| Step: 3
Training loss: 0.12000694125890732
Validation loss: 1.599103925048664

Epoch: 5| Step: 4
Training loss: 0.12274201214313507
Validation loss: 1.6068371803529802

Epoch: 5| Step: 5
Training loss: 0.06555759906768799
Validation loss: 1.579271702356236

Epoch: 5| Step: 6
Training loss: 0.1436339169740677
Validation loss: 1.5845357371914772

Epoch: 5| Step: 7
Training loss: 0.11643968522548676
Validation loss: 1.5990174534500285

Epoch: 5| Step: 8
Training loss: 0.11985435336828232
Validation loss: 1.5868723597577823

Epoch: 5| Step: 9
Training loss: 0.13197770714759827
Validation loss: 1.6238215405453917

Epoch: 5| Step: 10
Training loss: 0.11535792797803879
Validation loss: 1.6101916913063294

Epoch: 424| Step: 0
Training loss: 0.15738432109355927
Validation loss: 1.6318840890802362

Epoch: 5| Step: 1
Training loss: 0.13955822587013245
Validation loss: 1.6217498292205155

Epoch: 5| Step: 2
Training loss: 0.17309865355491638
Validation loss: 1.6151215299483268

Epoch: 5| Step: 3
Training loss: 0.21367430686950684
Validation loss: 1.5990653435389202

Epoch: 5| Step: 4
Training loss: 0.12965598702430725
Validation loss: 1.600212271495532

Epoch: 5| Step: 5
Training loss: 0.16629573702812195
Validation loss: 1.5965874618099583

Epoch: 5| Step: 6
Training loss: 0.09061618149280548
Validation loss: 1.5733487170229676

Epoch: 5| Step: 7
Training loss: 0.14962951838970184
Validation loss: 1.5840254714412074

Epoch: 5| Step: 8
Training loss: 0.0703478455543518
Validation loss: 1.5900209283316007

Epoch: 5| Step: 9
Training loss: 0.10091713815927505
Validation loss: 1.6079419594939037

Epoch: 5| Step: 10
Training loss: 0.140440434217453
Validation loss: 1.6391742216643466

Epoch: 425| Step: 0
Training loss: 0.09487876296043396
Validation loss: 1.6326608337381834

Epoch: 5| Step: 1
Training loss: 0.13722549378871918
Validation loss: 1.6591479124561432

Epoch: 5| Step: 2
Training loss: 0.09921667724847794
Validation loss: 1.6545552079395582

Epoch: 5| Step: 3
Training loss: 0.21649996936321259
Validation loss: 1.6753222506533387

Epoch: 5| Step: 4
Training loss: 0.06435800343751907
Validation loss: 1.6615771068039762

Epoch: 5| Step: 5
Training loss: 0.09995489567518234
Validation loss: 1.6725641476210726

Epoch: 5| Step: 6
Training loss: 0.19260413944721222
Validation loss: 1.6893894146847468

Epoch: 5| Step: 7
Training loss: 0.10448260605335236
Validation loss: 1.6680078224469257

Epoch: 5| Step: 8
Training loss: 0.1284724324941635
Validation loss: 1.6789406704646286

Epoch: 5| Step: 9
Training loss: 0.1334567368030548
Validation loss: 1.6732461362756708

Epoch: 5| Step: 10
Training loss: 0.11163224279880524
Validation loss: 1.6463461857970043

Epoch: 426| Step: 0
Training loss: 0.12683074176311493
Validation loss: 1.6332573147230252

Epoch: 5| Step: 1
Training loss: 0.10742570459842682
Validation loss: 1.626909702054916

Epoch: 5| Step: 2
Training loss: 0.12733519077301025
Validation loss: 1.6221485714758597

Epoch: 5| Step: 3
Training loss: 0.1611558198928833
Validation loss: 1.6299092461985927

Epoch: 5| Step: 4
Training loss: 0.13109400868415833
Validation loss: 1.625901340156473

Epoch: 5| Step: 5
Training loss: 0.10243457555770874
Validation loss: 1.6183507698838429

Epoch: 5| Step: 6
Training loss: 0.08337479829788208
Validation loss: 1.5887401847429172

Epoch: 5| Step: 7
Training loss: 0.07621779292821884
Validation loss: 1.5709346020093529

Epoch: 5| Step: 8
Training loss: 0.1496793031692505
Validation loss: 1.5584906583191247

Epoch: 5| Step: 9
Training loss: 0.1716356724500656
Validation loss: 1.5719533222977833

Epoch: 5| Step: 10
Training loss: 0.10525153577327728
Validation loss: 1.5695461624412126

Epoch: 427| Step: 0
Training loss: 0.08215352147817612
Validation loss: 1.5987541803749659

Epoch: 5| Step: 1
Training loss: 0.11161534488201141
Validation loss: 1.596969828810743

Epoch: 5| Step: 2
Training loss: 0.13954022526741028
Validation loss: 1.6052457606920632

Epoch: 5| Step: 3
Training loss: 0.08687891811132431
Validation loss: 1.625848147176927

Epoch: 5| Step: 4
Training loss: 0.17054860293865204
Validation loss: 1.6527654727300007

Epoch: 5| Step: 5
Training loss: 0.09120744466781616
Validation loss: 1.655173304260418

Epoch: 5| Step: 6
Training loss: 0.07986846566200256
Validation loss: 1.6232750454256613

Epoch: 5| Step: 7
Training loss: 0.07786013185977936
Validation loss: 1.6127643988978477

Epoch: 5| Step: 8
Training loss: 0.1424996554851532
Validation loss: 1.6198751029147898

Epoch: 5| Step: 9
Training loss: 0.19572792947292328
Validation loss: 1.6264278042700984

Epoch: 5| Step: 10
Training loss: 0.13150209188461304
Validation loss: 1.6313064021448935

Epoch: 428| Step: 0
Training loss: 0.11055569350719452
Validation loss: 1.6167587362309939

Epoch: 5| Step: 1
Training loss: 0.06213576719164848
Validation loss: 1.6107404334570772

Epoch: 5| Step: 2
Training loss: 0.11666004359722137
Validation loss: 1.5746091155595676

Epoch: 5| Step: 3
Training loss: 0.12542906403541565
Validation loss: 1.6371673448111421

Epoch: 5| Step: 4
Training loss: 0.09357737004756927
Validation loss: 1.6254127051240654

Epoch: 5| Step: 5
Training loss: 0.07491962611675262
Validation loss: 1.6479766714957453

Epoch: 5| Step: 6
Training loss: 0.14282965660095215
Validation loss: 1.6342630258170507

Epoch: 5| Step: 7
Training loss: 0.10414294898509979
Validation loss: 1.6166965384637155

Epoch: 5| Step: 8
Training loss: 0.14591391384601593
Validation loss: 1.6420180797576904

Epoch: 5| Step: 9
Training loss: 0.13630439341068268
Validation loss: 1.61231622516468

Epoch: 5| Step: 10
Training loss: 0.07443171739578247
Validation loss: 1.6083662022826493

Epoch: 429| Step: 0
Training loss: 0.09594381600618362
Validation loss: 1.600237855347254

Epoch: 5| Step: 1
Training loss: 0.15180884301662445
Validation loss: 1.5788629131932412

Epoch: 5| Step: 2
Training loss: 0.09150408208370209
Validation loss: 1.5875381090307747

Epoch: 5| Step: 3
Training loss: 0.11018258333206177
Validation loss: 1.5717286672643436

Epoch: 5| Step: 4
Training loss: 0.1552215814590454
Validation loss: 1.5458408658222487

Epoch: 5| Step: 5
Training loss: 0.09639828652143478
Validation loss: 1.58081470253647

Epoch: 5| Step: 6
Training loss: 0.10174275934696198
Validation loss: 1.5768813439594802

Epoch: 5| Step: 7
Training loss: 0.1184278279542923
Validation loss: 1.6099170087486185

Epoch: 5| Step: 8
Training loss: 0.1760437786579132
Validation loss: 1.6431730255003898

Epoch: 5| Step: 9
Training loss: 0.14414569735527039
Validation loss: 1.634030270320113

Epoch: 5| Step: 10
Training loss: 0.10975738614797592
Validation loss: 1.6808186179848128

Epoch: 430| Step: 0
Training loss: 0.11704723536968231
Validation loss: 1.6685722181873937

Epoch: 5| Step: 1
Training loss: 0.11466389894485474
Validation loss: 1.6889915581672423

Epoch: 5| Step: 2
Training loss: 0.07109387218952179
Validation loss: 1.6960503708931707

Epoch: 5| Step: 3
Training loss: 0.06003517657518387
Validation loss: 1.666974582979756

Epoch: 5| Step: 4
Training loss: 0.11463326215744019
Validation loss: 1.6155323572056268

Epoch: 5| Step: 5
Training loss: 0.16472695767879486
Validation loss: 1.584479239679152

Epoch: 5| Step: 6
Training loss: 0.1771523505449295
Validation loss: 1.5683817863464355

Epoch: 5| Step: 7
Training loss: 0.15964064002037048
Validation loss: 1.5594109053252845

Epoch: 5| Step: 8
Training loss: 0.18445883691310883
Validation loss: 1.5987184944973196

Epoch: 5| Step: 9
Training loss: 0.1289220154285431
Validation loss: 1.627121542089729

Epoch: 5| Step: 10
Training loss: 0.26964321732521057
Validation loss: 1.6446805756579164

Epoch: 431| Step: 0
Training loss: 0.18108496069908142
Validation loss: 1.6420441526238636

Epoch: 5| Step: 1
Training loss: 0.06600130349397659
Validation loss: 1.6398317096053914

Epoch: 5| Step: 2
Training loss: 0.08394704014062881
Validation loss: 1.6674468824940343

Epoch: 5| Step: 3
Training loss: 0.1109711080789566
Validation loss: 1.636242466588174

Epoch: 5| Step: 4
Training loss: 0.17818066477775574
Validation loss: 1.6408220850011355

Epoch: 5| Step: 5
Training loss: 0.12637069821357727
Validation loss: 1.6557042265451083

Epoch: 5| Step: 6
Training loss: 0.09776373207569122
Validation loss: 1.663098228875027

Epoch: 5| Step: 7
Training loss: 0.08761204779148102
Validation loss: 1.6353778775020311

Epoch: 5| Step: 8
Training loss: 0.18210157752037048
Validation loss: 1.682950613319233

Epoch: 5| Step: 9
Training loss: 0.10738029330968857
Validation loss: 1.6944381601067

Epoch: 5| Step: 10
Training loss: 0.19883649051189423
Validation loss: 1.6849940746061263

Epoch: 432| Step: 0
Training loss: 0.14380839467048645
Validation loss: 1.6979438540756062

Epoch: 5| Step: 1
Training loss: 0.12435956299304962
Validation loss: 1.6763603354013095

Epoch: 5| Step: 2
Training loss: 0.2265634983778
Validation loss: 1.6645543216377177

Epoch: 5| Step: 3
Training loss: 0.1018659695982933
Validation loss: 1.6345941597415554

Epoch: 5| Step: 4
Training loss: 0.10231812298297882
Validation loss: 1.631497247244722

Epoch: 5| Step: 5
Training loss: 0.1097288504242897
Validation loss: 1.593329462953793

Epoch: 5| Step: 6
Training loss: 0.15906411409378052
Validation loss: 1.6381161776922082

Epoch: 5| Step: 7
Training loss: 0.08793284744024277
Validation loss: 1.6382932573236444

Epoch: 5| Step: 8
Training loss: 0.1860150396823883
Validation loss: 1.6367528387295303

Epoch: 5| Step: 9
Training loss: 0.09953181445598602
Validation loss: 1.652344702392496

Epoch: 5| Step: 10
Training loss: 0.08594352006912231
Validation loss: 1.6471016996650285

Epoch: 433| Step: 0
Training loss: 0.1199626699090004
Validation loss: 1.6747429370880127

Epoch: 5| Step: 1
Training loss: 0.14373433589935303
Validation loss: 1.6985892275328278

Epoch: 5| Step: 2
Training loss: 0.06749484688043594
Validation loss: 1.6440415305476035

Epoch: 5| Step: 3
Training loss: 0.10620041191577911
Validation loss: 1.6387862351632887

Epoch: 5| Step: 4
Training loss: 0.06311766058206558
Validation loss: 1.6047617440582604

Epoch: 5| Step: 5
Training loss: 0.16007617115974426
Validation loss: 1.5902672429238596

Epoch: 5| Step: 6
Training loss: 0.09645218402147293
Validation loss: 1.5872762382671397

Epoch: 5| Step: 7
Training loss: 0.10145799815654755
Validation loss: 1.5903335502070766

Epoch: 5| Step: 8
Training loss: 0.13016949594020844
Validation loss: 1.573477912974614

Epoch: 5| Step: 9
Training loss: 0.16039355099201202
Validation loss: 1.5710171563650972

Epoch: 5| Step: 10
Training loss: 0.08656901866197586
Validation loss: 1.5786911441433815

Epoch: 434| Step: 0
Training loss: 0.1329711377620697
Validation loss: 1.6214167815382763

Epoch: 5| Step: 1
Training loss: 0.07674755901098251
Validation loss: 1.6159458250127814

Epoch: 5| Step: 2
Training loss: 0.10753021389245987
Validation loss: 1.6144715996198757

Epoch: 5| Step: 3
Training loss: 0.168655127286911
Validation loss: 1.6303640886019635

Epoch: 5| Step: 4
Training loss: 0.07836995273828506
Validation loss: 1.6513152353225216

Epoch: 5| Step: 5
Training loss: 0.14091022312641144
Validation loss: 1.696352303669017

Epoch: 5| Step: 6
Training loss: 0.1492914855480194
Validation loss: 1.688157569977545

Epoch: 5| Step: 7
Training loss: 0.06582862883806229
Validation loss: 1.6493802583345802

Epoch: 5| Step: 8
Training loss: 0.1453273445367813
Validation loss: 1.6380505324691854

Epoch: 5| Step: 9
Training loss: 0.1046888679265976
Validation loss: 1.6138126645036923

Epoch: 5| Step: 10
Training loss: 0.09966757893562317
Validation loss: 1.586111089234711

Epoch: 435| Step: 0
Training loss: 0.07855900377035141
Validation loss: 1.5964420514722024

Epoch: 5| Step: 1
Training loss: 0.09411615878343582
Validation loss: 1.6000540525682512

Epoch: 5| Step: 2
Training loss: 0.10151132196187973
Validation loss: 1.6056301773235362

Epoch: 5| Step: 3
Training loss: 0.1324659138917923
Validation loss: 1.6175571026340607

Epoch: 5| Step: 4
Training loss: 0.1940426528453827
Validation loss: 1.6426125854574225

Epoch: 5| Step: 5
Training loss: 0.0716039165854454
Validation loss: 1.613976385003777

Epoch: 5| Step: 6
Training loss: 0.11340658366680145
Validation loss: 1.6344146728515625

Epoch: 5| Step: 7
Training loss: 0.08018754422664642
Validation loss: 1.5688293723649875

Epoch: 5| Step: 8
Training loss: 0.054959796369075775
Validation loss: 1.5772680492811306

Epoch: 5| Step: 9
Training loss: 0.16585075855255127
Validation loss: 1.5599294785530335

Epoch: 5| Step: 10
Training loss: 0.15558253228664398
Validation loss: 1.5558459758758545

Epoch: 436| Step: 0
Training loss: 0.19366517663002014
Validation loss: 1.5543721414381457

Epoch: 5| Step: 1
Training loss: 0.1388048231601715
Validation loss: 1.5602778568062732

Epoch: 5| Step: 2
Training loss: 0.1355019062757492
Validation loss: 1.6000452233899025

Epoch: 5| Step: 3
Training loss: 0.2073630839586258
Validation loss: 1.5947873412921865

Epoch: 5| Step: 4
Training loss: 0.11119414865970612
Validation loss: 1.6161948224549652

Epoch: 5| Step: 5
Training loss: 0.15441152453422546
Validation loss: 1.636415740495087

Epoch: 5| Step: 6
Training loss: 0.14390023052692413
Validation loss: 1.6195119632187711

Epoch: 5| Step: 7
Training loss: 0.11890586465597153
Validation loss: 1.6072669247145295

Epoch: 5| Step: 8
Training loss: 0.11053715646266937
Validation loss: 1.5994732790095831

Epoch: 5| Step: 9
Training loss: 0.10353629291057587
Validation loss: 1.5980736606864518

Epoch: 5| Step: 10
Training loss: 0.10968302190303802
Validation loss: 1.5825334723277757

Epoch: 437| Step: 0
Training loss: 0.09955500066280365
Validation loss: 1.5696376985119236

Epoch: 5| Step: 1
Training loss: 0.13104622066020966
Validation loss: 1.5443948693172906

Epoch: 5| Step: 2
Training loss: 0.11834152042865753
Validation loss: 1.54790759471155

Epoch: 5| Step: 3
Training loss: 0.09814424067735672
Validation loss: 1.566384942300858

Epoch: 5| Step: 4
Training loss: 0.1942998468875885
Validation loss: 1.5510747291708504

Epoch: 5| Step: 5
Training loss: 0.17328579723834991
Validation loss: 1.5494136169392576

Epoch: 5| Step: 6
Training loss: 0.19010260701179504
Validation loss: 1.5890779879785353

Epoch: 5| Step: 7
Training loss: 0.15203842520713806
Validation loss: 1.5844776130491687

Epoch: 5| Step: 8
Training loss: 0.09776528179645538
Validation loss: 1.6023411712338846

Epoch: 5| Step: 9
Training loss: 0.15624286234378815
Validation loss: 1.6302691275073635

Epoch: 5| Step: 10
Training loss: 0.11920227855443954
Validation loss: 1.6335825099739978

Epoch: 438| Step: 0
Training loss: 0.10751817375421524
Validation loss: 1.6150976586085495

Epoch: 5| Step: 1
Training loss: 0.06142451614141464
Validation loss: 1.5815787366641465

Epoch: 5| Step: 2
Training loss: 0.15972477197647095
Validation loss: 1.5489393498307915

Epoch: 5| Step: 3
Training loss: 0.16206125915050507
Validation loss: 1.5599817499037711

Epoch: 5| Step: 4
Training loss: 0.12575455009937286
Validation loss: 1.5789643654259302

Epoch: 5| Step: 5
Training loss: 0.10164210945367813
Validation loss: 1.606893398428476

Epoch: 5| Step: 6
Training loss: 0.09762454032897949
Validation loss: 1.6258269125415432

Epoch: 5| Step: 7
Training loss: 0.23669962584972382
Validation loss: 1.6466122724676644

Epoch: 5| Step: 8
Training loss: 0.09692075103521347
Validation loss: 1.66174304357139

Epoch: 5| Step: 9
Training loss: 0.05940974876284599
Validation loss: 1.657992632158341

Epoch: 5| Step: 10
Training loss: 0.08681485801935196
Validation loss: 1.6547074497386973

Epoch: 439| Step: 0
Training loss: 0.1570175439119339
Validation loss: 1.6289473829730865

Epoch: 5| Step: 1
Training loss: 0.1737656146287918
Validation loss: 1.6446235282446748

Epoch: 5| Step: 2
Training loss: 0.1353244185447693
Validation loss: 1.6627647774193877

Epoch: 5| Step: 3
Training loss: 0.07853582501411438
Validation loss: 1.673438077331871

Epoch: 5| Step: 4
Training loss: 0.09134981036186218
Validation loss: 1.6731832476072415

Epoch: 5| Step: 5
Training loss: 0.09256679564714432
Validation loss: 1.657186710065411

Epoch: 5| Step: 6
Training loss: 0.04376241937279701
Validation loss: 1.6971845383285193

Epoch: 5| Step: 7
Training loss: 0.08276300132274628
Validation loss: 1.6580440485349266

Epoch: 5| Step: 8
Training loss: 0.13808324933052063
Validation loss: 1.6848609678206905

Epoch: 5| Step: 9
Training loss: 0.08046481758356094
Validation loss: 1.6528192912378619

Epoch: 5| Step: 10
Training loss: 0.14192955195903778
Validation loss: 1.6425407753195813

Epoch: 440| Step: 0
Training loss: 0.10851369053125381
Validation loss: 1.6371101833158923

Epoch: 5| Step: 1
Training loss: 0.2085692584514618
Validation loss: 1.6212791537725797

Epoch: 5| Step: 2
Training loss: 0.09516972303390503
Validation loss: 1.5666970488845662

Epoch: 5| Step: 3
Training loss: 0.14661237597465515
Validation loss: 1.597433497828822

Epoch: 5| Step: 4
Training loss: 0.09144775569438934
Validation loss: 1.6001242988853044

Epoch: 5| Step: 5
Training loss: 0.06636287271976471
Validation loss: 1.6181674900875296

Epoch: 5| Step: 6
Training loss: 0.11330650001764297
Validation loss: 1.6397694862017067

Epoch: 5| Step: 7
Training loss: 0.1727716028690338
Validation loss: 1.6780723910177908

Epoch: 5| Step: 8
Training loss: 0.08983056247234344
Validation loss: 1.65079967693616

Epoch: 5| Step: 9
Training loss: 0.1060851439833641
Validation loss: 1.6375878421209191

Epoch: 5| Step: 10
Training loss: 0.08035176992416382
Validation loss: 1.6382843063723656

Epoch: 441| Step: 0
Training loss: 0.06970870494842529
Validation loss: 1.6470186030992897

Epoch: 5| Step: 1
Training loss: 0.056161291897296906
Validation loss: 1.599684444806909

Epoch: 5| Step: 2
Training loss: 0.0784989446401596
Validation loss: 1.613975323656554

Epoch: 5| Step: 3
Training loss: 0.07948603481054306
Validation loss: 1.6043305102215017

Epoch: 5| Step: 4
Training loss: 0.04008578881621361
Validation loss: 1.5980763935273694

Epoch: 5| Step: 5
Training loss: 0.09000103920698166
Validation loss: 1.5989785796852523

Epoch: 5| Step: 6
Training loss: 0.17527084052562714
Validation loss: 1.609969323681247

Epoch: 5| Step: 7
Training loss: 0.14528825879096985
Validation loss: 1.6144260911531345

Epoch: 5| Step: 8
Training loss: 0.1364000290632248
Validation loss: 1.6276573916917205

Epoch: 5| Step: 9
Training loss: 0.13893882930278778
Validation loss: 1.5964594412875432

Epoch: 5| Step: 10
Training loss: 0.12257615476846695
Validation loss: 1.623869688280167

Epoch: 442| Step: 0
Training loss: 0.10909964889287949
Validation loss: 1.6287865305459628

Epoch: 5| Step: 1
Training loss: 0.18102726340293884
Validation loss: 1.6143460094287831

Epoch: 5| Step: 2
Training loss: 0.05197108909487724
Validation loss: 1.653505899572885

Epoch: 5| Step: 3
Training loss: 0.11960025876760483
Validation loss: 1.635471938758768

Epoch: 5| Step: 4
Training loss: 0.13163702189922333
Validation loss: 1.6557129890688005

Epoch: 5| Step: 5
Training loss: 0.12192082405090332
Validation loss: 1.6383851042357824

Epoch: 5| Step: 6
Training loss: 0.0868629589676857
Validation loss: 1.621563906310707

Epoch: 5| Step: 7
Training loss: 0.06997557729482651
Validation loss: 1.614569979329263

Epoch: 5| Step: 8
Training loss: 0.15989871323108673
Validation loss: 1.5998743426415227

Epoch: 5| Step: 9
Training loss: 0.12255503982305527
Validation loss: 1.572054426516256

Epoch: 5| Step: 10
Training loss: 0.0705685093998909
Validation loss: 1.5974351129224222

Epoch: 443| Step: 0
Training loss: 0.07296529412269592
Validation loss: 1.5939274398229455

Epoch: 5| Step: 1
Training loss: 0.2029985934495926
Validation loss: 1.6060700262746503

Epoch: 5| Step: 2
Training loss: 0.11307007074356079
Validation loss: 1.5815784008272233

Epoch: 5| Step: 3
Training loss: 0.08388140797615051
Validation loss: 1.5926091850444835

Epoch: 5| Step: 4
Training loss: 0.10116084665060043
Validation loss: 1.5821483442860265

Epoch: 5| Step: 5
Training loss: 0.19906768202781677
Validation loss: 1.6073162747967629

Epoch: 5| Step: 6
Training loss: 0.12787026166915894
Validation loss: 1.5995170301006687

Epoch: 5| Step: 7
Training loss: 0.10181967914104462
Validation loss: 1.5928505210466282

Epoch: 5| Step: 8
Training loss: 0.11922087520360947
Validation loss: 1.59950122269251

Epoch: 5| Step: 9
Training loss: 0.11844418942928314
Validation loss: 1.601958026168167

Epoch: 5| Step: 10
Training loss: 0.1534358412027359
Validation loss: 1.6113108652894215

Epoch: 444| Step: 0
Training loss: 0.16155701875686646
Validation loss: 1.6082342529809603

Epoch: 5| Step: 1
Training loss: 0.09070277214050293
Validation loss: 1.6300209978575348

Epoch: 5| Step: 2
Training loss: 0.13170139491558075
Validation loss: 1.6267998603082472

Epoch: 5| Step: 3
Training loss: 0.09947296977043152
Validation loss: 1.6237398450092604

Epoch: 5| Step: 4
Training loss: 0.14414672553539276
Validation loss: 1.6401042951050626

Epoch: 5| Step: 5
Training loss: 0.0937512069940567
Validation loss: 1.6430493926489225

Epoch: 5| Step: 6
Training loss: 0.08421183377504349
Validation loss: 1.629557886431294

Epoch: 5| Step: 7
Training loss: 0.14618168771266937
Validation loss: 1.6277856634509178

Epoch: 5| Step: 8
Training loss: 0.13751927018165588
Validation loss: 1.6373671600895543

Epoch: 5| Step: 9
Training loss: 0.09206818044185638
Validation loss: 1.6094099475491432

Epoch: 5| Step: 10
Training loss: 0.10051476210355759
Validation loss: 1.6054478486378987

Epoch: 445| Step: 0
Training loss: 0.15424832701683044
Validation loss: 1.6265776183015557

Epoch: 5| Step: 1
Training loss: 0.08971897512674332
Validation loss: 1.6275731209785707

Epoch: 5| Step: 2
Training loss: 0.06353110820055008
Validation loss: 1.6252046182591429

Epoch: 5| Step: 3
Training loss: 0.10066082328557968
Validation loss: 1.6178940944774176

Epoch: 5| Step: 4
Training loss: 0.08779643476009369
Validation loss: 1.6159919743896813

Epoch: 5| Step: 5
Training loss: 0.13933861255645752
Validation loss: 1.6192942614196448

Epoch: 5| Step: 6
Training loss: 0.06741936504840851
Validation loss: 1.6372500311943792

Epoch: 5| Step: 7
Training loss: 0.08541166037321091
Validation loss: 1.639109819166122

Epoch: 5| Step: 8
Training loss: 0.06944777071475983
Validation loss: 1.6477437852531351

Epoch: 5| Step: 9
Training loss: 0.11876199394464493
Validation loss: 1.6254861342009677

Epoch: 5| Step: 10
Training loss: 0.12369615584611893
Validation loss: 1.6425834368633967

Epoch: 446| Step: 0
Training loss: 0.06375128030776978
Validation loss: 1.618210559250206

Epoch: 5| Step: 1
Training loss: 0.07580272108316422
Validation loss: 1.6522315240675403

Epoch: 5| Step: 2
Training loss: 0.10470225661993027
Validation loss: 1.6712989627674062

Epoch: 5| Step: 3
Training loss: 0.0804947167634964
Validation loss: 1.6530812927471694

Epoch: 5| Step: 4
Training loss: 0.12247760593891144
Validation loss: 1.658919890721639

Epoch: 5| Step: 5
Training loss: 0.17898516356945038
Validation loss: 1.6484939103485436

Epoch: 5| Step: 6
Training loss: 0.056622814387083054
Validation loss: 1.6217625743599349

Epoch: 5| Step: 7
Training loss: 0.11083276569843292
Validation loss: 1.5960958362907491

Epoch: 5| Step: 8
Training loss: 0.09583346545696259
Validation loss: 1.5882385751252532

Epoch: 5| Step: 9
Training loss: 0.09940604865550995
Validation loss: 1.5654980290320613

Epoch: 5| Step: 10
Training loss: 0.05492570996284485
Validation loss: 1.5679308752859793

Epoch: 447| Step: 0
Training loss: 0.03457989543676376
Validation loss: 1.5717403196519422

Epoch: 5| Step: 1
Training loss: 0.058464426547288895
Validation loss: 1.5884967645009358

Epoch: 5| Step: 2
Training loss: 0.21045701205730438
Validation loss: 1.6364589237397718

Epoch: 5| Step: 3
Training loss: 0.1142609715461731
Validation loss: 1.6096995415226105

Epoch: 5| Step: 4
Training loss: 0.08798352628946304
Validation loss: 1.6253593762715657

Epoch: 5| Step: 5
Training loss: 0.07693792879581451
Validation loss: 1.6385674707351192

Epoch: 5| Step: 6
Training loss: 0.10989153385162354
Validation loss: 1.6258924391961866

Epoch: 5| Step: 7
Training loss: 0.10719259083271027
Validation loss: 1.636672467313787

Epoch: 5| Step: 8
Training loss: 0.15411175787448883
Validation loss: 1.643504023551941

Epoch: 5| Step: 9
Training loss: 0.08708097040653229
Validation loss: 1.6648132467782626

Epoch: 5| Step: 10
Training loss: 0.0670699030160904
Validation loss: 1.7050411996021066

Epoch: 448| Step: 0
Training loss: 0.14835277199745178
Validation loss: 1.7026921715787662

Epoch: 5| Step: 1
Training loss: 0.10269596427679062
Validation loss: 1.7045505085299093

Epoch: 5| Step: 2
Training loss: 0.11468317359685898
Validation loss: 1.6845881003205494

Epoch: 5| Step: 3
Training loss: 0.13152119517326355
Validation loss: 1.651140574486025

Epoch: 5| Step: 4
Training loss: 0.10236506164073944
Validation loss: 1.6092822218454013

Epoch: 5| Step: 5
Training loss: 0.113974928855896
Validation loss: 1.6022176922008555

Epoch: 5| Step: 6
Training loss: 0.13846907019615173
Validation loss: 1.5674262764633342

Epoch: 5| Step: 7
Training loss: 0.18059870600700378
Validation loss: 1.5835147134719356

Epoch: 5| Step: 8
Training loss: 0.05054502561688423
Validation loss: 1.6101777015193817

Epoch: 5| Step: 9
Training loss: 0.09152976423501968
Validation loss: 1.6348840716064617

Epoch: 5| Step: 10
Training loss: 0.10858799517154694
Validation loss: 1.656476721968702

Epoch: 449| Step: 0
Training loss: 0.12989668548107147
Validation loss: 1.663807285729275

Epoch: 5| Step: 1
Training loss: 0.13644781708717346
Validation loss: 1.6726305843681417

Epoch: 5| Step: 2
Training loss: 0.16795781254768372
Validation loss: 1.6698609552075785

Epoch: 5| Step: 3
Training loss: 0.12059912830591202
Validation loss: 1.613903719891784

Epoch: 5| Step: 4
Training loss: 0.13692444562911987
Validation loss: 1.59649742931448

Epoch: 5| Step: 5
Training loss: 0.0720667839050293
Validation loss: 1.58971829055458

Epoch: 5| Step: 6
Training loss: 0.1295933872461319
Validation loss: 1.57125860516743

Epoch: 5| Step: 7
Training loss: 0.11562328040599823
Validation loss: 1.5982025220829954

Epoch: 5| Step: 8
Training loss: 0.12430105358362198
Validation loss: 1.5899926988027429

Epoch: 5| Step: 9
Training loss: 0.12112896144390106
Validation loss: 1.6143407629382225

Epoch: 5| Step: 10
Training loss: 0.09126879274845123
Validation loss: 1.6327590160472418

Epoch: 450| Step: 0
Training loss: 0.05675297975540161
Validation loss: 1.6287513163781935

Epoch: 5| Step: 1
Training loss: 0.19269536435604095
Validation loss: 1.6325411924751856

Epoch: 5| Step: 2
Training loss: 0.13152001798152924
Validation loss: 1.596390010208212

Epoch: 5| Step: 3
Training loss: 0.1531558334827423
Validation loss: 1.6047221915696257

Epoch: 5| Step: 4
Training loss: 0.08440835773944855
Validation loss: 1.5668087133797266

Epoch: 5| Step: 5
Training loss: 0.06832905858755112
Validation loss: 1.5472746946478402

Epoch: 5| Step: 6
Training loss: 0.11781072616577148
Validation loss: 1.5773759875246274

Epoch: 5| Step: 7
Training loss: 0.18195530772209167
Validation loss: 1.5869098914566862

Epoch: 5| Step: 8
Training loss: 0.10147907584905624
Validation loss: 1.6009269042681622

Epoch: 5| Step: 9
Training loss: 0.11145959794521332
Validation loss: 1.6109244926001436

Epoch: 5| Step: 10
Training loss: 0.10786551237106323
Validation loss: 1.60600749651591

Epoch: 451| Step: 0
Training loss: 0.07935509830713272
Validation loss: 1.6136871742945846

Epoch: 5| Step: 1
Training loss: 0.08422897756099701
Validation loss: 1.6251520520897322

Epoch: 5| Step: 2
Training loss: 0.18588809669017792
Validation loss: 1.6416892197824293

Epoch: 5| Step: 3
Training loss: 0.09028105437755585
Validation loss: 1.6098289925565001

Epoch: 5| Step: 4
Training loss: 0.10080611705780029
Validation loss: 1.6455636050111504

Epoch: 5| Step: 5
Training loss: 0.1371302306652069
Validation loss: 1.6279855094930178

Epoch: 5| Step: 6
Training loss: 0.08423513174057007
Validation loss: 1.596922113049415

Epoch: 5| Step: 7
Training loss: 0.13473083078861237
Validation loss: 1.5842314099752774

Epoch: 5| Step: 8
Training loss: 0.09713451564311981
Validation loss: 1.5428667863210042

Epoch: 5| Step: 9
Training loss: 0.09843792021274567
Validation loss: 1.5230533833144813

Epoch: 5| Step: 10
Training loss: 0.12506020069122314
Validation loss: 1.5289408968340965

Epoch: 452| Step: 0
Training loss: 0.10535845905542374
Validation loss: 1.5499127949437788

Epoch: 5| Step: 1
Training loss: 0.13497819006443024
Validation loss: 1.5596568738260577

Epoch: 5| Step: 2
Training loss: 0.1142134815454483
Validation loss: 1.585578445465334

Epoch: 5| Step: 3
Training loss: 0.10193388164043427
Validation loss: 1.6185064956706057

Epoch: 5| Step: 4
Training loss: 0.13898348808288574
Validation loss: 1.642890759693679

Epoch: 5| Step: 5
Training loss: 0.10208351910114288
Validation loss: 1.640045049369976

Epoch: 5| Step: 6
Training loss: 0.0995122566819191
Validation loss: 1.6159149075067172

Epoch: 5| Step: 7
Training loss: 0.05355365201830864
Validation loss: 1.647398788441894

Epoch: 5| Step: 8
Training loss: 0.09454276412725449
Validation loss: 1.6337388971800446

Epoch: 5| Step: 9
Training loss: 0.13876672089099884
Validation loss: 1.6286185999070444

Epoch: 5| Step: 10
Training loss: 0.09094896167516708
Validation loss: 1.6287621605780818

Epoch: 453| Step: 0
Training loss: 0.09187553822994232
Validation loss: 1.623918144933639

Epoch: 5| Step: 1
Training loss: 0.09838385879993439
Validation loss: 1.5970419517127417

Epoch: 5| Step: 2
Training loss: 0.14654457569122314
Validation loss: 1.5973194363296672

Epoch: 5| Step: 3
Training loss: 0.09203075617551804
Validation loss: 1.6388372516119352

Epoch: 5| Step: 4
Training loss: 0.08358629047870636
Validation loss: 1.6511349543448417

Epoch: 5| Step: 5
Training loss: 0.218470498919487
Validation loss: 1.658634239627469

Epoch: 5| Step: 6
Training loss: 0.1430637538433075
Validation loss: 1.6685391664505005

Epoch: 5| Step: 7
Training loss: 0.12896262109279633
Validation loss: 1.686137198120035

Epoch: 5| Step: 8
Training loss: 0.0749557837843895
Validation loss: 1.6221103616940078

Epoch: 5| Step: 9
Training loss: 0.0577385239303112
Validation loss: 1.6146591773597143

Epoch: 5| Step: 10
Training loss: 0.17259910702705383
Validation loss: 1.5913694648332493

Epoch: 454| Step: 0
Training loss: 0.12988901138305664
Validation loss: 1.5503118486814602

Epoch: 5| Step: 1
Training loss: 0.10973615944385529
Validation loss: 1.5674529037167948

Epoch: 5| Step: 2
Training loss: 0.1341843605041504
Validation loss: 1.5536593961459335

Epoch: 5| Step: 3
Training loss: 0.18075953423976898
Validation loss: 1.5526214799573343

Epoch: 5| Step: 4
Training loss: 0.10863608121871948
Validation loss: 1.5866453352794851

Epoch: 5| Step: 5
Training loss: 0.12626123428344727
Validation loss: 1.5747498376395113

Epoch: 5| Step: 6
Training loss: 0.11300643533468246
Validation loss: 1.5971954573867142

Epoch: 5| Step: 7
Training loss: 0.06472805887460709
Validation loss: 1.6041276493380148

Epoch: 5| Step: 8
Training loss: 0.13791801035404205
Validation loss: 1.621682754126928

Epoch: 5| Step: 9
Training loss: 0.07304533571004868
Validation loss: 1.6217455402497323

Epoch: 5| Step: 10
Training loss: 0.14819641411304474
Validation loss: 1.614157675414957

Epoch: 455| Step: 0
Training loss: 0.11399545520544052
Validation loss: 1.5962856841343704

Epoch: 5| Step: 1
Training loss: 0.13263104856014252
Validation loss: 1.5822339468104865

Epoch: 5| Step: 2
Training loss: 0.16359122097492218
Validation loss: 1.540844577614979

Epoch: 5| Step: 3
Training loss: 0.13098981976509094
Validation loss: 1.5449077211400515

Epoch: 5| Step: 4
Training loss: 0.10806305706501007
Validation loss: 1.542928716187836

Epoch: 5| Step: 5
Training loss: 0.10209270566701889
Validation loss: 1.5372997150626233

Epoch: 5| Step: 6
Training loss: 0.09154532849788666
Validation loss: 1.5623760236206876

Epoch: 5| Step: 7
Training loss: 0.10372738540172577
Validation loss: 1.5657128531445739

Epoch: 5| Step: 8
Training loss: 0.06873045861721039
Validation loss: 1.6130762612947853

Epoch: 5| Step: 9
Training loss: 0.1259828507900238
Validation loss: 1.6135768839108047

Epoch: 5| Step: 10
Training loss: 0.13470050692558289
Validation loss: 1.649109084119079

Epoch: 456| Step: 0
Training loss: 0.11961062252521515
Validation loss: 1.6527521879442277

Epoch: 5| Step: 1
Training loss: 0.18134155869483948
Validation loss: 1.5985273532969977

Epoch: 5| Step: 2
Training loss: 0.10393631458282471
Validation loss: 1.6052523466848558

Epoch: 5| Step: 3
Training loss: 0.0486268550157547
Validation loss: 1.555998917548887

Epoch: 5| Step: 4
Training loss: 0.09937186539173126
Validation loss: 1.5407975617275442

Epoch: 5| Step: 5
Training loss: 0.09170867502689362
Validation loss: 1.5273199594149025

Epoch: 5| Step: 6
Training loss: 0.08253632485866547
Validation loss: 1.5585680020752775

Epoch: 5| Step: 7
Training loss: 0.1541658192873001
Validation loss: 1.5493449177793277

Epoch: 5| Step: 8
Training loss: 0.11660808324813843
Validation loss: 1.5916563054566741

Epoch: 5| Step: 9
Training loss: 0.10561172664165497
Validation loss: 1.6090828641768424

Epoch: 5| Step: 10
Training loss: 0.12326335906982422
Validation loss: 1.6047191632691251

Epoch: 457| Step: 0
Training loss: 0.09399427473545074
Validation loss: 1.6041380320825884

Epoch: 5| Step: 1
Training loss: 0.10304031521081924
Validation loss: 1.6176713294880365

Epoch: 5| Step: 2
Training loss: 0.10919163376092911
Validation loss: 1.6074988034463698

Epoch: 5| Step: 3
Training loss: 0.07236219197511673
Validation loss: 1.5828591110885784

Epoch: 5| Step: 4
Training loss: 0.10065438598394394
Validation loss: 1.607722479809997

Epoch: 5| Step: 5
Training loss: 0.0877951830625534
Validation loss: 1.5998301236860213

Epoch: 5| Step: 6
Training loss: 0.09705451130867004
Validation loss: 1.5754130514719153

Epoch: 5| Step: 7
Training loss: 0.21415653824806213
Validation loss: 1.5826434666110623

Epoch: 5| Step: 8
Training loss: 0.11503235250711441
Validation loss: 1.5723310273180726

Epoch: 5| Step: 9
Training loss: 0.0698465034365654
Validation loss: 1.572102508237285

Epoch: 5| Step: 10
Training loss: 0.046582937240600586
Validation loss: 1.5655885127282911

Epoch: 458| Step: 0
Training loss: 0.10443011671304703
Validation loss: 1.5690163489310973

Epoch: 5| Step: 1
Training loss: 0.15170155465602875
Validation loss: 1.569793047443513

Epoch: 5| Step: 2
Training loss: 0.16397491097450256
Validation loss: 1.5574077739510486

Epoch: 5| Step: 3
Training loss: 0.0893482193350792
Validation loss: 1.570332763015583

Epoch: 5| Step: 4
Training loss: 0.09898921102285385
Validation loss: 1.598001104529186

Epoch: 5| Step: 5
Training loss: 0.0671277865767479
Validation loss: 1.6259648056440457

Epoch: 5| Step: 6
Training loss: 0.07641828805208206
Validation loss: 1.6187019207144295

Epoch: 5| Step: 7
Training loss: 0.1576809287071228
Validation loss: 1.6533276240030925

Epoch: 5| Step: 8
Training loss: 0.13770513236522675
Validation loss: 1.6497741899182718

Epoch: 5| Step: 9
Training loss: 0.095082126557827
Validation loss: 1.6090318618282196

Epoch: 5| Step: 10
Training loss: 0.11208850890398026
Validation loss: 1.6203846841730096

Epoch: 459| Step: 0
Training loss: 0.0951809510588646
Validation loss: 1.6023830688127907

Epoch: 5| Step: 1
Training loss: 0.13977821171283722
Validation loss: 1.6167871106055476

Epoch: 5| Step: 2
Training loss: 0.15044279396533966
Validation loss: 1.5873685190754552

Epoch: 5| Step: 3
Training loss: 0.1031913161277771
Validation loss: 1.5920020995601531

Epoch: 5| Step: 4
Training loss: 0.0768430083990097
Validation loss: 1.6054745745915238

Epoch: 5| Step: 5
Training loss: 0.060076672583818436
Validation loss: 1.6242378219481437

Epoch: 5| Step: 6
Training loss: 0.12657558917999268
Validation loss: 1.6435160970175138

Epoch: 5| Step: 7
Training loss: 0.1245424747467041
Validation loss: 1.6596682584413918

Epoch: 5| Step: 8
Training loss: 0.09995070844888687
Validation loss: 1.6538970713974328

Epoch: 5| Step: 9
Training loss: 0.09807808697223663
Validation loss: 1.6570548472865936

Epoch: 5| Step: 10
Training loss: 0.0998157411813736
Validation loss: 1.647027748887257

Epoch: 460| Step: 0
Training loss: 0.056749384850263596
Validation loss: 1.6080173266831266

Epoch: 5| Step: 1
Training loss: 0.04537821561098099
Validation loss: 1.5987255163090204

Epoch: 5| Step: 2
Training loss: 0.13798904418945312
Validation loss: 1.5984275161579091

Epoch: 5| Step: 3
Training loss: 0.09256182610988617
Validation loss: 1.5918239995997439

Epoch: 5| Step: 4
Training loss: 0.12575075030326843
Validation loss: 1.6141381571369786

Epoch: 5| Step: 5
Training loss: 0.09361956268548965
Validation loss: 1.600465443826491

Epoch: 5| Step: 6
Training loss: 0.0686207190155983
Validation loss: 1.614365985316615

Epoch: 5| Step: 7
Training loss: 0.08037467300891876
Validation loss: 1.6082811804227932

Epoch: 5| Step: 8
Training loss: 0.1575428992509842
Validation loss: 1.6154045199835172

Epoch: 5| Step: 9
Training loss: 0.07253231108188629
Validation loss: 1.609763435138169

Epoch: 5| Step: 10
Training loss: 0.1344578117132187
Validation loss: 1.6442220108483427

Epoch: 461| Step: 0
Training loss: 0.07960285246372223
Validation loss: 1.6170755137679398

Epoch: 5| Step: 1
Training loss: 0.16535979509353638
Validation loss: 1.641025363758046

Epoch: 5| Step: 2
Training loss: 0.0925268679857254
Validation loss: 1.5990092690272997

Epoch: 5| Step: 3
Training loss: 0.07619185745716095
Validation loss: 1.579350479187504

Epoch: 5| Step: 4
Training loss: 0.07291582971811295
Validation loss: 1.5997118872980918

Epoch: 5| Step: 5
Training loss: 0.06815476715564728
Validation loss: 1.6176434870689147

Epoch: 5| Step: 6
Training loss: 0.14200052618980408
Validation loss: 1.6110683615489672

Epoch: 5| Step: 7
Training loss: 0.13703015446662903
Validation loss: 1.6381693661853831

Epoch: 5| Step: 8
Training loss: 0.06369863450527191
Validation loss: 1.633849004263519

Epoch: 5| Step: 9
Training loss: 0.07728934288024902
Validation loss: 1.6349884668986003

Epoch: 5| Step: 10
Training loss: 0.07492818683385849
Validation loss: 1.6322280206987936

Epoch: 462| Step: 0
Training loss: 0.0826912373304367
Validation loss: 1.6283168267178278

Epoch: 5| Step: 1
Training loss: 0.07623999565839767
Validation loss: 1.6529499997374832

Epoch: 5| Step: 2
Training loss: 0.10035232454538345
Validation loss: 1.6406102667572677

Epoch: 5| Step: 3
Training loss: 0.10770820081233978
Validation loss: 1.64021715810222

Epoch: 5| Step: 4
Training loss: 0.11242260783910751
Validation loss: 1.6358852617202266

Epoch: 5| Step: 5
Training loss: 0.11912403255701065
Validation loss: 1.6440041629217004

Epoch: 5| Step: 6
Training loss: 0.08100882917642593
Validation loss: 1.62062499343708

Epoch: 5| Step: 7
Training loss: 0.11485008895397186
Validation loss: 1.6136695979743876

Epoch: 5| Step: 8
Training loss: 0.08107997477054596
Validation loss: 1.587776977528808

Epoch: 5| Step: 9
Training loss: 0.12520596385002136
Validation loss: 1.5959951480229695

Epoch: 5| Step: 10
Training loss: 0.07801751792430878
Validation loss: 1.5819465896134735

Epoch: 463| Step: 0
Training loss: 0.08691166341304779
Validation loss: 1.5835901447521743

Epoch: 5| Step: 1
Training loss: 0.0662757158279419
Validation loss: 1.6055733055196784

Epoch: 5| Step: 2
Training loss: 0.10059750080108643
Validation loss: 1.5938929178381478

Epoch: 5| Step: 3
Training loss: 0.1507108509540558
Validation loss: 1.5983091695334322

Epoch: 5| Step: 4
Training loss: 0.14678040146827698
Validation loss: 1.6429275979277909

Epoch: 5| Step: 5
Training loss: 0.07498879730701447
Validation loss: 1.6426292234851467

Epoch: 5| Step: 6
Training loss: 0.0770028606057167
Validation loss: 1.6542107930747412

Epoch: 5| Step: 7
Training loss: 0.11414048820734024
Validation loss: 1.6750683053847282

Epoch: 5| Step: 8
Training loss: 0.11783631891012192
Validation loss: 1.665760842702722

Epoch: 5| Step: 9
Training loss: 0.10610375553369522
Validation loss: 1.6638365599416918

Epoch: 5| Step: 10
Training loss: 0.13213251531124115
Validation loss: 1.63342071348621

Epoch: 464| Step: 0
Training loss: 0.110264852643013
Validation loss: 1.593930858437733

Epoch: 5| Step: 1
Training loss: 0.0700702890753746
Validation loss: 1.5734096304062875

Epoch: 5| Step: 2
Training loss: 0.09019785374403
Validation loss: 1.5500331668443577

Epoch: 5| Step: 3
Training loss: 0.08785708248615265
Validation loss: 1.5720929612395584

Epoch: 5| Step: 4
Training loss: 0.172993466258049
Validation loss: 1.57273514745056

Epoch: 5| Step: 5
Training loss: 0.12382528930902481
Validation loss: 1.5455406122310187

Epoch: 5| Step: 6
Training loss: 0.17046529054641724
Validation loss: 1.5891423545857912

Epoch: 5| Step: 7
Training loss: 0.08801440894603729
Validation loss: 1.6303408517632434

Epoch: 5| Step: 8
Training loss: 0.08919239789247513
Validation loss: 1.6624018120509323

Epoch: 5| Step: 9
Training loss: 0.105015829205513
Validation loss: 1.6385424316570323

Epoch: 5| Step: 10
Training loss: 0.059230122715234756
Validation loss: 1.6653419284410373

Epoch: 465| Step: 0
Training loss: 0.15676212310791016
Validation loss: 1.6778997964756464

Epoch: 5| Step: 1
Training loss: 0.0670396015048027
Validation loss: 1.6680748924132316

Epoch: 5| Step: 2
Training loss: 0.05917041748762131
Validation loss: 1.6345083072621336

Epoch: 5| Step: 3
Training loss: 0.06380343437194824
Validation loss: 1.5961248618300243

Epoch: 5| Step: 4
Training loss: 0.11852885782718658
Validation loss: 1.5919693439237532

Epoch: 5| Step: 5
Training loss: 0.09867070615291595
Validation loss: 1.59981878213985

Epoch: 5| Step: 6
Training loss: 0.12443006038665771
Validation loss: 1.5978462683257235

Epoch: 5| Step: 7
Training loss: 0.13703349232673645
Validation loss: 1.604636025685136

Epoch: 5| Step: 8
Training loss: 0.12318422645330429
Validation loss: 1.6185945823628416

Epoch: 5| Step: 9
Training loss: 0.12013481557369232
Validation loss: 1.6474506239737234

Epoch: 5| Step: 10
Training loss: 0.1475588083267212
Validation loss: 1.661955742425816

Epoch: 466| Step: 0
Training loss: 0.06432762742042542
Validation loss: 1.6834484697670065

Epoch: 5| Step: 1
Training loss: 0.12936246395111084
Validation loss: 1.680053170009326

Epoch: 5| Step: 2
Training loss: 0.10062386840581894
Validation loss: 1.6449191621554795

Epoch: 5| Step: 3
Training loss: 0.09495095908641815
Validation loss: 1.650337855021159

Epoch: 5| Step: 4
Training loss: 0.12722136080265045
Validation loss: 1.6224382513312883

Epoch: 5| Step: 5
Training loss: 0.08356442302465439
Validation loss: 1.579345633906703

Epoch: 5| Step: 6
Training loss: 0.11733230203390121
Validation loss: 1.6040152503598122

Epoch: 5| Step: 7
Training loss: 0.09437846392393112
Validation loss: 1.5781940093604467

Epoch: 5| Step: 8
Training loss: 0.1256972998380661
Validation loss: 1.5725671129841958

Epoch: 5| Step: 9
Training loss: 0.0918494462966919
Validation loss: 1.5805651577570106

Epoch: 5| Step: 10
Training loss: 0.07159478217363358
Validation loss: 1.6008950587241881

Epoch: 467| Step: 0
Training loss: 0.08936630934476852
Validation loss: 1.6144228789114183

Epoch: 5| Step: 1
Training loss: 0.05996353179216385
Validation loss: 1.6225703236877278

Epoch: 5| Step: 2
Training loss: 0.04607458785176277
Validation loss: 1.6240441183890066

Epoch: 5| Step: 3
Training loss: 0.12029174715280533
Validation loss: 1.6023970483451762

Epoch: 5| Step: 4
Training loss: 0.10081527382135391
Validation loss: 1.6265357719954623

Epoch: 5| Step: 5
Training loss: 0.04739610105752945
Validation loss: 1.6255798186025312

Epoch: 5| Step: 6
Training loss: 0.07115083932876587
Validation loss: 1.5808957244760247

Epoch: 5| Step: 7
Training loss: 0.0824299082159996
Validation loss: 1.5888498483165618

Epoch: 5| Step: 8
Training loss: 0.11792431026697159
Validation loss: 1.6048673839979275

Epoch: 5| Step: 9
Training loss: 0.06313487887382507
Validation loss: 1.5874475048434349

Epoch: 5| Step: 10
Training loss: 0.15692375600337982
Validation loss: 1.6022282185093049

Epoch: 468| Step: 0
Training loss: 0.0637996643781662
Validation loss: 1.5915048365951867

Epoch: 5| Step: 1
Training loss: 0.07911030948162079
Validation loss: 1.58777000698992

Epoch: 5| Step: 2
Training loss: 0.09693270921707153
Validation loss: 1.5967892216097923

Epoch: 5| Step: 3
Training loss: 0.07268558442592621
Validation loss: 1.5848969067296674

Epoch: 5| Step: 4
Training loss: 0.05187028646469116
Validation loss: 1.600523417995822

Epoch: 5| Step: 5
Training loss: 0.14025399088859558
Validation loss: 1.6003431235590289

Epoch: 5| Step: 6
Training loss: 0.07980219274759293
Validation loss: 1.5852979152433333

Epoch: 5| Step: 7
Training loss: 0.08207948505878448
Validation loss: 1.6301976147518362

Epoch: 5| Step: 8
Training loss: 0.1430663913488388
Validation loss: 1.617233739104322

Epoch: 5| Step: 9
Training loss: 0.06646750867366791
Validation loss: 1.608438330311929

Epoch: 5| Step: 10
Training loss: 0.08398748189210892
Validation loss: 1.6059829445295437

Epoch: 469| Step: 0
Training loss: 0.129018634557724
Validation loss: 1.6237176310631536

Epoch: 5| Step: 1
Training loss: 0.06193404272198677
Validation loss: 1.613261418957864

Epoch: 5| Step: 2
Training loss: 0.06105927750468254
Validation loss: 1.645588646652878

Epoch: 5| Step: 3
Training loss: 0.09159418195486069
Validation loss: 1.609667786987879

Epoch: 5| Step: 4
Training loss: 0.07477624714374542
Validation loss: 1.6541259993789017

Epoch: 5| Step: 5
Training loss: 0.07910577952861786
Validation loss: 1.6435625142948602

Epoch: 5| Step: 6
Training loss: 0.11972691118717194
Validation loss: 1.6313906728580434

Epoch: 5| Step: 7
Training loss: 0.07863745838403702
Validation loss: 1.6295662362088439

Epoch: 5| Step: 8
Training loss: 0.06509614735841751
Validation loss: 1.613269223961779

Epoch: 5| Step: 9
Training loss: 0.10499590635299683
Validation loss: 1.6388070929434992

Epoch: 5| Step: 10
Training loss: 0.1363365203142166
Validation loss: 1.6159506984936294

Epoch: 470| Step: 0
Training loss: 0.09791987389326096
Validation loss: 1.6166639558730587

Epoch: 5| Step: 1
Training loss: 0.11023084819316864
Validation loss: 1.5981955310349822

Epoch: 5| Step: 2
Training loss: 0.06693759560585022
Validation loss: 1.6080025742130895

Epoch: 5| Step: 3
Training loss: 0.09139987081289291
Validation loss: 1.6145670593425792

Epoch: 5| Step: 4
Training loss: 0.08965135365724564
Validation loss: 1.6172517627798102

Epoch: 5| Step: 5
Training loss: 0.14944502711296082
Validation loss: 1.6016634452727534

Epoch: 5| Step: 6
Training loss: 0.041562777012586594
Validation loss: 1.576151955512262

Epoch: 5| Step: 7
Training loss: 0.10671590268611908
Validation loss: 1.5896603932944677

Epoch: 5| Step: 8
Training loss: 0.09480606019496918
Validation loss: 1.5701553872836533

Epoch: 5| Step: 9
Training loss: 0.09069971740245819
Validation loss: 1.576385812092853

Epoch: 5| Step: 10
Training loss: 0.07314547896385193
Validation loss: 1.5359398229147798

Epoch: 471| Step: 0
Training loss: 0.12185756117105484
Validation loss: 1.5391678002572828

Epoch: 5| Step: 1
Training loss: 0.1562240719795227
Validation loss: 1.5366402441455471

Epoch: 5| Step: 2
Training loss: 0.1464461386203766
Validation loss: 1.595234101818454

Epoch: 5| Step: 3
Training loss: 0.051807235926389694
Validation loss: 1.5821911615710105

Epoch: 5| Step: 4
Training loss: 0.14168938994407654
Validation loss: 1.623046745536148

Epoch: 5| Step: 5
Training loss: 0.09401556849479675
Validation loss: 1.60632505724507

Epoch: 5| Step: 6
Training loss: 0.10660766065120697
Validation loss: 1.6120967467625935

Epoch: 5| Step: 7
Training loss: 0.08165906369686127
Validation loss: 1.6327838795159453

Epoch: 5| Step: 8
Training loss: 0.08603485673666
Validation loss: 1.618723928287465

Epoch: 5| Step: 9
Training loss: 0.09428630024194717
Validation loss: 1.611320677623954

Epoch: 5| Step: 10
Training loss: 0.08609068393707275
Validation loss: 1.607305044768959

Epoch: 472| Step: 0
Training loss: 0.13799259066581726
Validation loss: 1.5949856632499284

Epoch: 5| Step: 1
Training loss: 0.15513408184051514
Validation loss: 1.607014940631005

Epoch: 5| Step: 2
Training loss: 0.09102096408605576
Validation loss: 1.5997729327089043

Epoch: 5| Step: 3
Training loss: 0.08378899097442627
Validation loss: 1.5956544671007382

Epoch: 5| Step: 4
Training loss: 0.07741130143404007
Validation loss: 1.6151064621504916

Epoch: 5| Step: 5
Training loss: 0.09869436919689178
Validation loss: 1.5828608133459603

Epoch: 5| Step: 6
Training loss: 0.09441934525966644
Validation loss: 1.6112885936614005

Epoch: 5| Step: 7
Training loss: 0.1283094584941864
Validation loss: 1.6297679924836723

Epoch: 5| Step: 8
Training loss: 0.06139519065618515
Validation loss: 1.6381231956584479

Epoch: 5| Step: 9
Training loss: 0.10273484885692596
Validation loss: 1.6446065941164572

Epoch: 5| Step: 10
Training loss: 0.0903700590133667
Validation loss: 1.6143148906769291

Epoch: 473| Step: 0
Training loss: 0.10930974781513214
Validation loss: 1.6097058301330895

Epoch: 5| Step: 1
Training loss: 0.07953916490077972
Validation loss: 1.586244438284187

Epoch: 5| Step: 2
Training loss: 0.09950431436300278
Validation loss: 1.5464194384954308

Epoch: 5| Step: 3
Training loss: 0.10130387544631958
Validation loss: 1.544577721626528

Epoch: 5| Step: 4
Training loss: 0.12423787266016006
Validation loss: 1.5665257899991927

Epoch: 5| Step: 5
Training loss: 0.1619693785905838
Validation loss: 1.5982108769878265

Epoch: 5| Step: 6
Training loss: 0.12247131019830704
Validation loss: 1.5936854744470248

Epoch: 5| Step: 7
Training loss: 0.08802954852581024
Validation loss: 1.624417205010691

Epoch: 5| Step: 8
Training loss: 0.09394586086273193
Validation loss: 1.6529941251201015

Epoch: 5| Step: 9
Training loss: 0.12297555059194565
Validation loss: 1.649023227794196

Epoch: 5| Step: 10
Training loss: 0.10501136630773544
Validation loss: 1.6277530001055809

Epoch: 474| Step: 0
Training loss: 0.16364623606204987
Validation loss: 1.614394397504868

Epoch: 5| Step: 1
Training loss: 0.08818930387496948
Validation loss: 1.5762106654464558

Epoch: 5| Step: 2
Training loss: 0.08725674450397491
Validation loss: 1.5615020439188967

Epoch: 5| Step: 3
Training loss: 0.08057651668787003
Validation loss: 1.5290732563182872

Epoch: 5| Step: 4
Training loss: 0.1215837225317955
Validation loss: 1.5378887294441141

Epoch: 5| Step: 5
Training loss: 0.12792107462882996
Validation loss: 1.5288451845927904

Epoch: 5| Step: 6
Training loss: 0.09736521542072296
Validation loss: 1.5627756926321215

Epoch: 5| Step: 7
Training loss: 0.15188995003700256
Validation loss: 1.5690470408367854

Epoch: 5| Step: 8
Training loss: 0.07941979169845581
Validation loss: 1.6019553099909136

Epoch: 5| Step: 9
Training loss: 0.0787624940276146
Validation loss: 1.640863287833429

Epoch: 5| Step: 10
Training loss: 0.12916670739650726
Validation loss: 1.6268790204037902

Epoch: 475| Step: 0
Training loss: 0.12509062886238098
Validation loss: 1.6493621257043654

Epoch: 5| Step: 1
Training loss: 0.10813789069652557
Validation loss: 1.6568418984772058

Epoch: 5| Step: 2
Training loss: 0.12830422818660736
Validation loss: 1.6519283850987752

Epoch: 5| Step: 3
Training loss: 0.0754215195775032
Validation loss: 1.6317608587203487

Epoch: 5| Step: 4
Training loss: 0.08099812269210815
Validation loss: 1.6049467632847447

Epoch: 5| Step: 5
Training loss: 0.13431993126869202
Validation loss: 1.5876780415094027

Epoch: 5| Step: 6
Training loss: 0.08200093358755112
Validation loss: 1.573422546027809

Epoch: 5| Step: 7
Training loss: 0.06810767203569412
Validation loss: 1.5699010766962522

Epoch: 5| Step: 8
Training loss: 0.10956986248493195
Validation loss: 1.5680874791196597

Epoch: 5| Step: 9
Training loss: 0.08159379661083221
Validation loss: 1.5747397176681026

Epoch: 5| Step: 10
Training loss: 0.0788114070892334
Validation loss: 1.558665047409714

Epoch: 476| Step: 0
Training loss: 0.10693247616291046
Validation loss: 1.5731716425188127

Epoch: 5| Step: 1
Training loss: 0.10496463626623154
Validation loss: 1.565500432445157

Epoch: 5| Step: 2
Training loss: 0.09214349836111069
Validation loss: 1.5862023317685692

Epoch: 5| Step: 3
Training loss: 0.1333206743001938
Validation loss: 1.5608212999118272

Epoch: 5| Step: 4
Training loss: 0.10100426524877548
Validation loss: 1.5497367273094833

Epoch: 5| Step: 5
Training loss: 0.06344461441040039
Validation loss: 1.549294416622449

Epoch: 5| Step: 6
Training loss: 0.12825320661067963
Validation loss: 1.5670448426277406

Epoch: 5| Step: 7
Training loss: 0.09456808865070343
Validation loss: 1.581267414554473

Epoch: 5| Step: 8
Training loss: 0.12048903852701187
Validation loss: 1.5848951647358556

Epoch: 5| Step: 9
Training loss: 0.1025182455778122
Validation loss: 1.6086072203933552

Epoch: 5| Step: 10
Training loss: 0.1323799341917038
Validation loss: 1.6246419798943303

Epoch: 477| Step: 0
Training loss: 0.17400212585926056
Validation loss: 1.6208963291619414

Epoch: 5| Step: 1
Training loss: 0.11038385331630707
Validation loss: 1.63032744520454

Epoch: 5| Step: 2
Training loss: 0.18163633346557617
Validation loss: 1.5930424582573675

Epoch: 5| Step: 3
Training loss: 0.06002827733755112
Validation loss: 1.574215422394455

Epoch: 5| Step: 4
Training loss: 0.08900831639766693
Validation loss: 1.569422310398471

Epoch: 5| Step: 5
Training loss: 0.05949634313583374
Validation loss: 1.5848621886263612

Epoch: 5| Step: 6
Training loss: 0.06342488527297974
Validation loss: 1.5730008899524648

Epoch: 5| Step: 7
Training loss: 0.09220040589570999
Validation loss: 1.5884853229727796

Epoch: 5| Step: 8
Training loss: 0.13619741797447205
Validation loss: 1.6023861631270377

Epoch: 5| Step: 9
Training loss: 0.07322068512439728
Validation loss: 1.603115080505289

Epoch: 5| Step: 10
Training loss: 0.06424647569656372
Validation loss: 1.6048272925038491

Epoch: 478| Step: 0
Training loss: 0.15754434466362
Validation loss: 1.6312491034948697

Epoch: 5| Step: 1
Training loss: 0.09143449366092682
Validation loss: 1.613470431297056

Epoch: 5| Step: 2
Training loss: 0.07453252375125885
Validation loss: 1.6219605015170189

Epoch: 5| Step: 3
Training loss: 0.06932332366704941
Validation loss: 1.6205146472941163

Epoch: 5| Step: 4
Training loss: 0.09663637727499008
Validation loss: 1.6070965989943473

Epoch: 5| Step: 5
Training loss: 0.08596178889274597
Validation loss: 1.5994722202260008

Epoch: 5| Step: 6
Training loss: 0.06224524974822998
Validation loss: 1.6227644592203119

Epoch: 5| Step: 7
Training loss: 0.15876992046833038
Validation loss: 1.5908067232819014

Epoch: 5| Step: 8
Training loss: 0.12783029675483704
Validation loss: 1.6007933052637244

Epoch: 5| Step: 9
Training loss: 0.0980507880449295
Validation loss: 1.5785511347555345

Epoch: 5| Step: 10
Training loss: 0.07053481787443161
Validation loss: 1.5682420704954414

Epoch: 479| Step: 0
Training loss: 0.0750121921300888
Validation loss: 1.5796237927611156

Epoch: 5| Step: 1
Training loss: 0.08930442482233047
Validation loss: 1.6030907784738848

Epoch: 5| Step: 2
Training loss: 0.1055290549993515
Validation loss: 1.5842544840228172

Epoch: 5| Step: 3
Training loss: 0.07015632092952728
Validation loss: 1.6116957613216933

Epoch: 5| Step: 4
Training loss: 0.0954858809709549
Validation loss: 1.6332658311372161

Epoch: 5| Step: 5
Training loss: 0.15384359657764435
Validation loss: 1.641964864346289

Epoch: 5| Step: 6
Training loss: 0.11788322031497955
Validation loss: 1.6529947711575417

Epoch: 5| Step: 7
Training loss: 0.10768654197454453
Validation loss: 1.6540439744149484

Epoch: 5| Step: 8
Training loss: 0.0821312665939331
Validation loss: 1.6394985946275855

Epoch: 5| Step: 9
Training loss: 0.0899328961968422
Validation loss: 1.629979573270326

Epoch: 5| Step: 10
Training loss: 0.0900510624051094
Validation loss: 1.5927865915401007

Epoch: 480| Step: 0
Training loss: 0.06072137504816055
Validation loss: 1.5627452301722702

Epoch: 5| Step: 1
Training loss: 0.11456732451915741
Validation loss: 1.57331943896509

Epoch: 5| Step: 2
Training loss: 0.08311551809310913
Validation loss: 1.5744435441109441

Epoch: 5| Step: 3
Training loss: 0.06720761954784393
Validation loss: 1.5943612706276677

Epoch: 5| Step: 4
Training loss: 0.10114159435033798
Validation loss: 1.5933155295669392

Epoch: 5| Step: 5
Training loss: 0.09057412296533585
Validation loss: 1.6050932920107277

Epoch: 5| Step: 6
Training loss: 0.07977615296840668
Validation loss: 1.578074929534748

Epoch: 5| Step: 7
Training loss: 0.09437495470046997
Validation loss: 1.5774901496466769

Epoch: 5| Step: 8
Training loss: 0.0774008184671402
Validation loss: 1.5765918967544392

Epoch: 5| Step: 9
Training loss: 0.11718881130218506
Validation loss: 1.5435653989033034

Epoch: 5| Step: 10
Training loss: 0.11015946418046951
Validation loss: 1.566975821730911

Epoch: 481| Step: 0
Training loss: 0.06714408844709396
Validation loss: 1.5721285740534465

Epoch: 5| Step: 1
Training loss: 0.09404169768095016
Validation loss: 1.5795496958558277

Epoch: 5| Step: 2
Training loss: 0.052868373692035675
Validation loss: 1.5804818932728102

Epoch: 5| Step: 3
Training loss: 0.1347970813512802
Validation loss: 1.5860840735896942

Epoch: 5| Step: 4
Training loss: 0.08099786192178726
Validation loss: 1.6125390632178194

Epoch: 5| Step: 5
Training loss: 0.14519712328910828
Validation loss: 1.6198889106832526

Epoch: 5| Step: 6
Training loss: 0.15490850806236267
Validation loss: 1.6030292011076404

Epoch: 5| Step: 7
Training loss: 0.07993592321872711
Validation loss: 1.5907068893473635

Epoch: 5| Step: 8
Training loss: 0.03928753361105919
Validation loss: 1.5801638185337026

Epoch: 5| Step: 9
Training loss: 0.07039789110422134
Validation loss: 1.562694707224446

Epoch: 5| Step: 10
Training loss: 0.09996630251407623
Validation loss: 1.5927394205524075

Epoch: 482| Step: 0
Training loss: 0.06946196407079697
Validation loss: 1.549612541352549

Epoch: 5| Step: 1
Training loss: 0.10377460718154907
Validation loss: 1.5460657432515135

Epoch: 5| Step: 2
Training loss: 0.08416737616062164
Validation loss: 1.5330701412693146

Epoch: 5| Step: 3
Training loss: 0.09953863173723221
Validation loss: 1.5833803017934163

Epoch: 5| Step: 4
Training loss: 0.15748897194862366
Validation loss: 1.5887286842510264

Epoch: 5| Step: 5
Training loss: 0.0866280347108841
Validation loss: 1.5927258550479848

Epoch: 5| Step: 6
Training loss: 0.07061997801065445
Validation loss: 1.5783267200634044

Epoch: 5| Step: 7
Training loss: 0.07396738231182098
Validation loss: 1.582629631924373

Epoch: 5| Step: 8
Training loss: 0.12153768539428711
Validation loss: 1.601351261138916

Epoch: 5| Step: 9
Training loss: 0.12593357264995575
Validation loss: 1.6031937355636268

Epoch: 5| Step: 10
Training loss: 0.0726500004529953
Validation loss: 1.6176082395738172

Epoch: 483| Step: 0
Training loss: 0.10599468648433685
Validation loss: 1.6143241556741859

Epoch: 5| Step: 1
Training loss: 0.09689635038375854
Validation loss: 1.5847658982840918

Epoch: 5| Step: 2
Training loss: 0.07690360397100449
Validation loss: 1.6023472983350036

Epoch: 5| Step: 3
Training loss: 0.06964036822319031
Validation loss: 1.5619639453067575

Epoch: 5| Step: 4
Training loss: 0.06459422409534454
Validation loss: 1.5727495378063572

Epoch: 5| Step: 5
Training loss: 0.12371402978897095
Validation loss: 1.5866851191366873

Epoch: 5| Step: 6
Training loss: 0.08748343586921692
Validation loss: 1.5681426153388074

Epoch: 5| Step: 7
Training loss: 0.04656447097659111
Validation loss: 1.5895838250396073

Epoch: 5| Step: 8
Training loss: 0.06569666415452957
Validation loss: 1.5689526091339767

Epoch: 5| Step: 9
Training loss: 0.09251292049884796
Validation loss: 1.5718743685753114

Epoch: 5| Step: 10
Training loss: 0.0854211151599884
Validation loss: 1.5777747349072528

Epoch: 484| Step: 0
Training loss: 0.051563460379838943
Validation loss: 1.5652145493415095

Epoch: 5| Step: 1
Training loss: 0.0969916433095932
Validation loss: 1.5682508407100555

Epoch: 5| Step: 2
Training loss: 0.08415829390287399
Validation loss: 1.5823439193028275

Epoch: 5| Step: 3
Training loss: 0.07854912430047989
Validation loss: 1.5838765322521169

Epoch: 5| Step: 4
Training loss: 0.0705171748995781
Validation loss: 1.5789792973508117

Epoch: 5| Step: 5
Training loss: 0.09051001071929932
Validation loss: 1.5767790450844714

Epoch: 5| Step: 6
Training loss: 0.045231372117996216
Validation loss: 1.5585669061189056

Epoch: 5| Step: 7
Training loss: 0.053077228367328644
Validation loss: 1.5410921022456179

Epoch: 5| Step: 8
Training loss: 0.08219969272613525
Validation loss: 1.5934457573839413

Epoch: 5| Step: 9
Training loss: 0.07000638544559479
Validation loss: 1.5912089399112168

Epoch: 5| Step: 10
Training loss: 0.11496308445930481
Validation loss: 1.6145250143543366

Epoch: 485| Step: 0
Training loss: 0.0720440223813057
Validation loss: 1.6149271124152726

Epoch: 5| Step: 1
Training loss: 0.1031888946890831
Validation loss: 1.616369000045202

Epoch: 5| Step: 2
Training loss: 0.06939683109521866
Validation loss: 1.6034260385779924

Epoch: 5| Step: 3
Training loss: 0.0804741382598877
Validation loss: 1.560253490683853

Epoch: 5| Step: 4
Training loss: 0.06814101338386536
Validation loss: 1.5247620626162457

Epoch: 5| Step: 5
Training loss: 0.09322661906480789
Validation loss: 1.5234446551210137

Epoch: 5| Step: 6
Training loss: 0.09933875501155853
Validation loss: 1.546315006030503

Epoch: 5| Step: 7
Training loss: 0.08516503870487213
Validation loss: 1.5570400837929017

Epoch: 5| Step: 8
Training loss: 0.06022120639681816
Validation loss: 1.528735964528976

Epoch: 5| Step: 9
Training loss: 0.2034505307674408
Validation loss: 1.5654913571573073

Epoch: 5| Step: 10
Training loss: 0.0890110433101654
Validation loss: 1.5621817778515559

Epoch: 486| Step: 0
Training loss: 0.08163104206323624
Validation loss: 1.5777973776222558

Epoch: 5| Step: 1
Training loss: 0.12704750895500183
Validation loss: 1.549973157144362

Epoch: 5| Step: 2
Training loss: 0.0638456866145134
Validation loss: 1.5567431860072638

Epoch: 5| Step: 3
Training loss: 0.12136001884937286
Validation loss: 1.5762253807437034

Epoch: 5| Step: 4
Training loss: 0.08467163145542145
Validation loss: 1.5713046840442124

Epoch: 5| Step: 5
Training loss: 0.11002236604690552
Validation loss: 1.6050365445434407

Epoch: 5| Step: 6
Training loss: 0.09102122485637665
Validation loss: 1.5995737903861589

Epoch: 5| Step: 7
Training loss: 0.10227066278457642
Validation loss: 1.5954955957269157

Epoch: 5| Step: 8
Training loss: 0.11579079926013947
Validation loss: 1.5997178580171318

Epoch: 5| Step: 9
Training loss: 0.08266918361186981
Validation loss: 1.5820688765536073

Epoch: 5| Step: 10
Training loss: 0.0795082375407219
Validation loss: 1.5862262069538076

Epoch: 487| Step: 0
Training loss: 0.0996006578207016
Validation loss: 1.579133810535554

Epoch: 5| Step: 1
Training loss: 0.07768739759922028
Validation loss: 1.616890775260105

Epoch: 5| Step: 2
Training loss: 0.0991244986653328
Validation loss: 1.6132310039253646

Epoch: 5| Step: 3
Training loss: 0.0676439180970192
Validation loss: 1.587113029213362

Epoch: 5| Step: 4
Training loss: 0.13066186010837555
Validation loss: 1.6487240637502363

Epoch: 5| Step: 5
Training loss: 0.13684289157390594
Validation loss: 1.6149821486524356

Epoch: 5| Step: 6
Training loss: 0.12251918017864227
Validation loss: 1.6079661999979327

Epoch: 5| Step: 7
Training loss: 0.05714130401611328
Validation loss: 1.5973355898293116

Epoch: 5| Step: 8
Training loss: 0.09486512094736099
Validation loss: 1.5884422871374315

Epoch: 5| Step: 9
Training loss: 0.11041052639484406
Validation loss: 1.6075773559590822

Epoch: 5| Step: 10
Training loss: 0.10803546011447906
Validation loss: 1.6219599631524855

Epoch: 488| Step: 0
Training loss: 0.1334175318479538
Validation loss: 1.6238004123010943

Epoch: 5| Step: 1
Training loss: 0.0556764230132103
Validation loss: 1.6095298092852357

Epoch: 5| Step: 2
Training loss: 0.1256321221590042
Validation loss: 1.607190232123098

Epoch: 5| Step: 3
Training loss: 0.07079672068357468
Validation loss: 1.568642428485296

Epoch: 5| Step: 4
Training loss: 0.11863664537668228
Validation loss: 1.5953907697431502

Epoch: 5| Step: 5
Training loss: 0.057809822261333466
Validation loss: 1.59917107576965

Epoch: 5| Step: 6
Training loss: 0.09568570554256439
Validation loss: 1.5989346145301737

Epoch: 5| Step: 7
Training loss: 0.046038009226322174
Validation loss: 1.6104410207399757

Epoch: 5| Step: 8
Training loss: 0.0970795676112175
Validation loss: 1.6096339225769043

Epoch: 5| Step: 9
Training loss: 0.0675010085105896
Validation loss: 1.6250246737592964

Epoch: 5| Step: 10
Training loss: 0.06286219507455826
Validation loss: 1.6128019632831696

Epoch: 489| Step: 0
Training loss: 0.05854702740907669
Validation loss: 1.6232820210918304

Epoch: 5| Step: 1
Training loss: 0.16785535216331482
Validation loss: 1.641793853493147

Epoch: 5| Step: 2
Training loss: 0.12610863149166107
Validation loss: 1.632464083933061

Epoch: 5| Step: 3
Training loss: 0.0627676397562027
Validation loss: 1.5910648517711188

Epoch: 5| Step: 4
Training loss: 0.07320883125066757
Validation loss: 1.5691905444668186

Epoch: 5| Step: 5
Training loss: 0.09887044131755829
Validation loss: 1.567516972941737

Epoch: 5| Step: 6
Training loss: 0.08359558880329132
Validation loss: 1.5315600069620277

Epoch: 5| Step: 7
Training loss: 0.07043282687664032
Validation loss: 1.5353534798468313

Epoch: 5| Step: 8
Training loss: 0.11965155601501465
Validation loss: 1.5660859333571566

Epoch: 5| Step: 9
Training loss: 0.08767279982566833
Validation loss: 1.5533094636855587

Epoch: 5| Step: 10
Training loss: 0.07552438974380493
Validation loss: 1.5569798382379676

Epoch: 490| Step: 0
Training loss: 0.08329249918460846
Validation loss: 1.583666584825003

Epoch: 5| Step: 1
Training loss: 0.09452861547470093
Validation loss: 1.6091437455146544

Epoch: 5| Step: 2
Training loss: 0.06268734484910965
Validation loss: 1.5913538445708573

Epoch: 5| Step: 3
Training loss: 0.08316095173358917
Validation loss: 1.5939455634804183

Epoch: 5| Step: 4
Training loss: 0.12168367207050323
Validation loss: 1.5587170393236223

Epoch: 5| Step: 5
Training loss: 0.06361262500286102
Validation loss: 1.5323862106569353

Epoch: 5| Step: 6
Training loss: 0.08914727717638016
Validation loss: 1.5320738630910073

Epoch: 5| Step: 7
Training loss: 0.12790536880493164
Validation loss: 1.5173575365415184

Epoch: 5| Step: 8
Training loss: 0.11997022479772568
Validation loss: 1.4774964778654036

Epoch: 5| Step: 9
Training loss: 0.08761675655841827
Validation loss: 1.5116698254821122

Epoch: 5| Step: 10
Training loss: 0.04072820395231247
Validation loss: 1.517363961024951

Epoch: 491| Step: 0
Training loss: 0.11765486001968384
Validation loss: 1.5492465303790184

Epoch: 5| Step: 1
Training loss: 0.08201836049556732
Validation loss: 1.5566853246381205

Epoch: 5| Step: 2
Training loss: 0.13624747097492218
Validation loss: 1.5823074707420923

Epoch: 5| Step: 3
Training loss: 0.09847082197666168
Validation loss: 1.563023046780658

Epoch: 5| Step: 4
Training loss: 0.06138719990849495
Validation loss: 1.5962195383605136

Epoch: 5| Step: 5
Training loss: 0.0699797198176384
Validation loss: 1.5746415853500366

Epoch: 5| Step: 6
Training loss: 0.06045446917414665
Validation loss: 1.5610183208219466

Epoch: 5| Step: 7
Training loss: 0.08759085834026337
Validation loss: 1.578074219406292

Epoch: 5| Step: 8
Training loss: 0.10462550818920135
Validation loss: 1.5637192162134315

Epoch: 5| Step: 9
Training loss: 0.12909109890460968
Validation loss: 1.5879506141908708

Epoch: 5| Step: 10
Training loss: 0.07227443903684616
Validation loss: 1.5682284050090338

Epoch: 492| Step: 0
Training loss: 0.08135149627923965
Validation loss: 1.585638815356839

Epoch: 5| Step: 1
Training loss: 0.047247085720300674
Validation loss: 1.5963161030123312

Epoch: 5| Step: 2
Training loss: 0.118494413793087
Validation loss: 1.5832748695086407

Epoch: 5| Step: 3
Training loss: 0.08173219859600067
Validation loss: 1.620357519836836

Epoch: 5| Step: 4
Training loss: 0.061653099954128265
Validation loss: 1.6075802951730707

Epoch: 5| Step: 5
Training loss: 0.079290471971035
Validation loss: 1.6247262083074099

Epoch: 5| Step: 6
Training loss: 0.09775929152965546
Validation loss: 1.6178283383769374

Epoch: 5| Step: 7
Training loss: 0.0876801386475563
Validation loss: 1.5909243963098014

Epoch: 5| Step: 8
Training loss: 0.11729902029037476
Validation loss: 1.5861703439425396

Epoch: 5| Step: 9
Training loss: 0.07690460234880447
Validation loss: 1.5687462219627955

Epoch: 5| Step: 10
Training loss: 0.08475680649280548
Validation loss: 1.5799093336187384

Epoch: 493| Step: 0
Training loss: 0.12133945524692535
Validation loss: 1.6023493069474415

Epoch: 5| Step: 1
Training loss: 0.11733095347881317
Validation loss: 1.616541991951645

Epoch: 5| Step: 2
Training loss: 0.08780394494533539
Validation loss: 1.6308182618951286

Epoch: 5| Step: 3
Training loss: 0.05829659849405289
Validation loss: 1.6417480796896002

Epoch: 5| Step: 4
Training loss: 0.12199340015649796
Validation loss: 1.6440849278562812

Epoch: 5| Step: 5
Training loss: 0.0652211457490921
Validation loss: 1.6707811022317538

Epoch: 5| Step: 6
Training loss: 0.1147303357720375
Validation loss: 1.6421411524536789

Epoch: 5| Step: 7
Training loss: 0.08439238369464874
Validation loss: 1.6263641029275873

Epoch: 5| Step: 8
Training loss: 0.08791449666023254
Validation loss: 1.5899466840169763

Epoch: 5| Step: 9
Training loss: 0.11295557022094727
Validation loss: 1.590847578099979

Epoch: 5| Step: 10
Training loss: 0.06422198563814163
Validation loss: 1.584870223076113

Epoch: 494| Step: 0
Training loss: 0.11419159173965454
Validation loss: 1.554171698067778

Epoch: 5| Step: 1
Training loss: 0.09561401605606079
Validation loss: 1.5352800981972807

Epoch: 5| Step: 2
Training loss: 0.11067570745944977
Validation loss: 1.5516393261571084

Epoch: 5| Step: 3
Training loss: 0.07460226118564606
Validation loss: 1.5940742710585236

Epoch: 5| Step: 4
Training loss: 0.13848909735679626
Validation loss: 1.5909399960630684

Epoch: 5| Step: 5
Training loss: 0.12896661460399628
Validation loss: 1.6094254396295036

Epoch: 5| Step: 6
Training loss: 0.10517070442438126
Validation loss: 1.607948758268869

Epoch: 5| Step: 7
Training loss: 0.15236897766590118
Validation loss: 1.6268823249365694

Epoch: 5| Step: 8
Training loss: 0.10131190717220306
Validation loss: 1.6289745005228187

Epoch: 5| Step: 9
Training loss: 0.12394905090332031
Validation loss: 1.6271600184902069

Epoch: 5| Step: 10
Training loss: 0.07561057806015015
Validation loss: 1.6014248209614907

Epoch: 495| Step: 0
Training loss: 0.07876785844564438
Validation loss: 1.5959205383895545

Epoch: 5| Step: 1
Training loss: 0.07315686345100403
Validation loss: 1.578855501708164

Epoch: 5| Step: 2
Training loss: 0.07456306368112564
Validation loss: 1.5766180920344528

Epoch: 5| Step: 3
Training loss: 0.08487895131111145
Validation loss: 1.5517961427729616

Epoch: 5| Step: 4
Training loss: 0.18315629661083221
Validation loss: 1.5822717733280633

Epoch: 5| Step: 5
Training loss: 0.11412620544433594
Validation loss: 1.5762576762066092

Epoch: 5| Step: 6
Training loss: 0.08085215836763382
Validation loss: 1.5884457172886017

Epoch: 5| Step: 7
Training loss: 0.07007597386837006
Validation loss: 1.6149478509861936

Epoch: 5| Step: 8
Training loss: 0.057322047650814056
Validation loss: 1.6142421422466156

Epoch: 5| Step: 9
Training loss: 0.06040745973587036
Validation loss: 1.6260483059831845

Epoch: 5| Step: 10
Training loss: 0.10784357786178589
Validation loss: 1.6582068243334371

Epoch: 496| Step: 0
Training loss: 0.15228235721588135
Validation loss: 1.643683523260137

Epoch: 5| Step: 1
Training loss: 0.12489612400531769
Validation loss: 1.633883713394083

Epoch: 5| Step: 2
Training loss: 0.07946687191724777
Validation loss: 1.6015016455804147

Epoch: 5| Step: 3
Training loss: 0.08016806840896606
Validation loss: 1.605141612791246

Epoch: 5| Step: 4
Training loss: 0.07587907463312149
Validation loss: 1.5951914915474512

Epoch: 5| Step: 5
Training loss: 0.07941979914903641
Validation loss: 1.5706739502568399

Epoch: 5| Step: 6
Training loss: 0.12592275440692902
Validation loss: 1.5751627491366478

Epoch: 5| Step: 7
Training loss: 0.09807904064655304
Validation loss: 1.5497625694479993

Epoch: 5| Step: 8
Training loss: 0.11739347130060196
Validation loss: 1.6056194292601718

Epoch: 5| Step: 9
Training loss: 0.08255372941493988
Validation loss: 1.575681762028766

Epoch: 5| Step: 10
Training loss: 0.05679860711097717
Validation loss: 1.5721544834875292

Epoch: 497| Step: 0
Training loss: 0.0965435802936554
Validation loss: 1.5825726421930457

Epoch: 5| Step: 1
Training loss: 0.1163138896226883
Validation loss: 1.5696110571584394

Epoch: 5| Step: 2
Training loss: 0.07656131684780121
Validation loss: 1.5678387303506174

Epoch: 5| Step: 3
Training loss: 0.08744297176599503
Validation loss: 1.5597255505541319

Epoch: 5| Step: 4
Training loss: 0.06902845948934555
Validation loss: 1.5751381804866176

Epoch: 5| Step: 5
Training loss: 0.08978111296892166
Validation loss: 1.566729937830279

Epoch: 5| Step: 6
Training loss: 0.1538139283657074
Validation loss: 1.5907299326312156

Epoch: 5| Step: 7
Training loss: 0.08481695502996445
Validation loss: 1.5804259892432921

Epoch: 5| Step: 8
Training loss: 0.0856020525097847
Validation loss: 1.5878269185302079

Epoch: 5| Step: 9
Training loss: 0.075250044465065
Validation loss: 1.5996519198981665

Epoch: 5| Step: 10
Training loss: 0.08955761790275574
Validation loss: 1.6141881250566052

Epoch: 498| Step: 0
Training loss: 0.06888861954212189
Validation loss: 1.6275548870845506

Epoch: 5| Step: 1
Training loss: 0.08874092251062393
Validation loss: 1.6433355308348132

Epoch: 5| Step: 2
Training loss: 0.08953025937080383
Validation loss: 1.651989172863704

Epoch: 5| Step: 3
Training loss: 0.06267891079187393
Validation loss: 1.620856551713841

Epoch: 5| Step: 4
Training loss: 0.07679532468318939
Validation loss: 1.5932314242086103

Epoch: 5| Step: 5
Training loss: 0.07794411480426788
Validation loss: 1.5791599737700595

Epoch: 5| Step: 6
Training loss: 0.12109359353780746
Validation loss: 1.5643824864459295

Epoch: 5| Step: 7
Training loss: 0.14592337608337402
Validation loss: 1.5349202848249865

Epoch: 5| Step: 8
Training loss: 0.08655466884374619
Validation loss: 1.5562094103905462

Epoch: 5| Step: 9
Training loss: 0.08080850541591644
Validation loss: 1.5516606274471487

Epoch: 5| Step: 10
Training loss: 0.09644284844398499
Validation loss: 1.5631588018068703

Epoch: 499| Step: 0
Training loss: 0.10193492472171783
Validation loss: 1.5869835320339407

Epoch: 5| Step: 1
Training loss: 0.10460536181926727
Validation loss: 1.5784656950222549

Epoch: 5| Step: 2
Training loss: 0.05338156968355179
Validation loss: 1.5834420445144817

Epoch: 5| Step: 3
Training loss: 0.07485870271921158
Validation loss: 1.6000469666655346

Epoch: 5| Step: 4
Training loss: 0.12087831646203995
Validation loss: 1.591806225879218

Epoch: 5| Step: 5
Training loss: 0.06592825800180435
Validation loss: 1.6092960949867003

Epoch: 5| Step: 6
Training loss: 0.10498587042093277
Validation loss: 1.591085050695686

Epoch: 5| Step: 7
Training loss: 0.0729491114616394
Validation loss: 1.6078976815746677

Epoch: 5| Step: 8
Training loss: 0.06919942051172256
Validation loss: 1.592578972539594

Epoch: 5| Step: 9
Training loss: 0.05417603254318237
Validation loss: 1.58386311159339

Epoch: 5| Step: 10
Training loss: 0.06417924165725708
Validation loss: 1.5761056984624555

Epoch: 500| Step: 0
Training loss: 0.0624455101788044
Validation loss: 1.5757682156819168

Epoch: 5| Step: 1
Training loss: 0.05957593768835068
Validation loss: 1.6163511506972774

Epoch: 5| Step: 2
Training loss: 0.07025996595621109
Validation loss: 1.5828575357314079

Epoch: 5| Step: 3
Training loss: 0.09581545740365982
Validation loss: 1.6125584943320161

Epoch: 5| Step: 4
Training loss: 0.09712692350149155
Validation loss: 1.6051700410022531

Epoch: 5| Step: 5
Training loss: 0.10688108205795288
Validation loss: 1.597631847986611

Epoch: 5| Step: 6
Training loss: 0.07960013300180435
Validation loss: 1.5998336948374265

Epoch: 5| Step: 7
Training loss: 0.10159356892108917
Validation loss: 1.5877684829055623

Epoch: 5| Step: 8
Training loss: 0.12501703202724457
Validation loss: 1.581304806534962

Epoch: 5| Step: 9
Training loss: 0.07396910339593887
Validation loss: 1.581273514737365

Epoch: 5| Step: 10
Training loss: 0.05100215598940849
Validation loss: 1.5604046698539489

Epoch: 501| Step: 0
Training loss: 0.08917395025491714
Validation loss: 1.5793062717683855

Epoch: 5| Step: 1
Training loss: 0.0614866241812706
Validation loss: 1.582379405216504

Epoch: 5| Step: 2
Training loss: 0.09264679253101349
Validation loss: 1.572287146763135

Epoch: 5| Step: 3
Training loss: 0.11015812307596207
Validation loss: 1.6064506948635142

Epoch: 5| Step: 4
Training loss: 0.08424384146928787
Validation loss: 1.5811442329037575

Epoch: 5| Step: 5
Training loss: 0.08432211726903915
Validation loss: 1.5856806212855923

Epoch: 5| Step: 6
Training loss: 0.10663123428821564
Validation loss: 1.5560597412047847

Epoch: 5| Step: 7
Training loss: 0.08938224613666534
Validation loss: 1.556710417552661

Epoch: 5| Step: 8
Training loss: 0.06479669362306595
Validation loss: 1.5382105906804402

Epoch: 5| Step: 9
Training loss: 0.08900143951177597
Validation loss: 1.5407877519566526

Epoch: 5| Step: 10
Training loss: 0.115726038813591
Validation loss: 1.5492266147367415

Epoch: 502| Step: 0
Training loss: 0.11497004330158234
Validation loss: 1.570096795276929

Epoch: 5| Step: 1
Training loss: 0.06874894350767136
Validation loss: 1.5682579727583035

Epoch: 5| Step: 2
Training loss: 0.05882023647427559
Validation loss: 1.5704847792143464

Epoch: 5| Step: 3
Training loss: 0.08996593207120895
Validation loss: 1.571409171627414

Epoch: 5| Step: 4
Training loss: 0.03902578353881836
Validation loss: 1.567427674929301

Epoch: 5| Step: 5
Training loss: 0.10811960697174072
Validation loss: 1.5755809648062593

Epoch: 5| Step: 6
Training loss: 0.07823667675256729
Validation loss: 1.5842240202811457

Epoch: 5| Step: 7
Training loss: 0.1767268180847168
Validation loss: 1.5932767724478116

Epoch: 5| Step: 8
Training loss: 0.06320200115442276
Validation loss: 1.5554585585030176

Epoch: 5| Step: 9
Training loss: 0.10856634378433228
Validation loss: 1.565869463387356

Epoch: 5| Step: 10
Training loss: 0.08151327818632126
Validation loss: 1.5490991377061414

Epoch: 503| Step: 0
Training loss: 0.05099600553512573
Validation loss: 1.5610587801984561

Epoch: 5| Step: 1
Training loss: 0.07379354536533356
Validation loss: 1.5696652538032942

Epoch: 5| Step: 2
Training loss: 0.09799423068761826
Validation loss: 1.6212815277038082

Epoch: 5| Step: 3
Training loss: 0.10896756500005722
Validation loss: 1.6224142172003304

Epoch: 5| Step: 4
Training loss: 0.10738120228052139
Validation loss: 1.6189510572341181

Epoch: 5| Step: 5
Training loss: 0.07112817466259003
Validation loss: 1.616693736404501

Epoch: 5| Step: 6
Training loss: 0.0945153459906578
Validation loss: 1.6067026840743197

Epoch: 5| Step: 7
Training loss: 0.10908577591180801
Validation loss: 1.5959221701468191

Epoch: 5| Step: 8
Training loss: 0.0973116010427475
Validation loss: 1.6101754929429741

Epoch: 5| Step: 9
Training loss: 0.11703970283269882
Validation loss: 1.5864193131846767

Epoch: 5| Step: 10
Training loss: 0.05857508257031441
Validation loss: 1.5748680176273469

Epoch: 504| Step: 0
Training loss: 0.058681607246398926
Validation loss: 1.6001550715456727

Epoch: 5| Step: 1
Training loss: 0.08019857853651047
Validation loss: 1.5735071730870072

Epoch: 5| Step: 2
Training loss: 0.05752681940793991
Validation loss: 1.5567256314780122

Epoch: 5| Step: 3
Training loss: 0.10778911411762238
Validation loss: 1.5535087444448983

Epoch: 5| Step: 4
Training loss: 0.10035042464733124
Validation loss: 1.5419883971573205

Epoch: 5| Step: 5
Training loss: 0.18176895380020142
Validation loss: 1.5634467922231203

Epoch: 5| Step: 6
Training loss: 0.11284538358449936
Validation loss: 1.538900161302218

Epoch: 5| Step: 7
Training loss: 0.055803071707487106
Validation loss: 1.5525056226279146

Epoch: 5| Step: 8
Training loss: 0.09708891808986664
Validation loss: 1.5860789591266262

Epoch: 5| Step: 9
Training loss: 0.10504050552845001
Validation loss: 1.5759861802542081

Epoch: 5| Step: 10
Training loss: 0.11712338030338287
Validation loss: 1.563660139678627

Epoch: 505| Step: 0
Training loss: 0.06957916915416718
Validation loss: 1.5780185358498686

Epoch: 5| Step: 1
Training loss: 0.12300203740596771
Validation loss: 1.5456472301995883

Epoch: 5| Step: 2
Training loss: 0.04971052333712578
Validation loss: 1.5392542731377385

Epoch: 5| Step: 3
Training loss: 0.08576054126024246
Validation loss: 1.5880052338364303

Epoch: 5| Step: 4
Training loss: 0.10629333555698395
Validation loss: 1.5643048965802757

Epoch: 5| Step: 5
Training loss: 0.06637632101774216
Validation loss: 1.5577833344859462

Epoch: 5| Step: 6
Training loss: 0.1393858641386032
Validation loss: 1.586246895533736

Epoch: 5| Step: 7
Training loss: 0.07563252747058868
Validation loss: 1.632977993257584

Epoch: 5| Step: 8
Training loss: 0.13296473026275635
Validation loss: 1.6229697030077699

Epoch: 5| Step: 9
Training loss: 0.05640677362680435
Validation loss: 1.650708161374574

Epoch: 5| Step: 10
Training loss: 0.09891486912965775
Validation loss: 1.6738017784651888

Epoch: 506| Step: 0
Training loss: 0.10682351887226105
Validation loss: 1.6711446341647898

Epoch: 5| Step: 1
Training loss: 0.11606156826019287
Validation loss: 1.6365634574685046

Epoch: 5| Step: 2
Training loss: 0.08048351109027863
Validation loss: 1.565544686009807

Epoch: 5| Step: 3
Training loss: 0.12537959218025208
Validation loss: 1.5775322183485954

Epoch: 5| Step: 4
Training loss: 0.15593935549259186
Validation loss: 1.5455592857894076

Epoch: 5| Step: 5
Training loss: 0.117551788687706
Validation loss: 1.5710670948028564

Epoch: 5| Step: 6
Training loss: 0.12446584552526474
Validation loss: 1.5701378353180424

Epoch: 5| Step: 7
Training loss: 0.08570092916488647
Validation loss: 1.5550387719626069

Epoch: 5| Step: 8
Training loss: 0.06707893311977386
Validation loss: 1.5669133214540378

Epoch: 5| Step: 9
Training loss: 0.11190037429332733
Validation loss: 1.5247915188471477

Epoch: 5| Step: 10
Training loss: 0.04915571212768555
Validation loss: 1.5489122777856805

Epoch: 507| Step: 0
Training loss: 0.06733320653438568
Validation loss: 1.5886040849070395

Epoch: 5| Step: 1
Training loss: 0.18156488239765167
Validation loss: 1.5829277987121253

Epoch: 5| Step: 2
Training loss: 0.07043719291687012
Validation loss: 1.5689305079880582

Epoch: 5| Step: 3
Training loss: 0.05574573948979378
Validation loss: 1.5722559575111634

Epoch: 5| Step: 4
Training loss: 0.10918840020895004
Validation loss: 1.5858029127120972

Epoch: 5| Step: 5
Training loss: 0.09422500431537628
Validation loss: 1.5920486219467656

Epoch: 5| Step: 6
Training loss: 0.09506112337112427
Validation loss: 1.5749843146211358

Epoch: 5| Step: 7
Training loss: 0.08582095801830292
Validation loss: 1.5717213705021849

Epoch: 5| Step: 8
Training loss: 0.11004169285297394
Validation loss: 1.6257356994895524

Epoch: 5| Step: 9
Training loss: 0.0658344179391861
Validation loss: 1.5899488150432546

Epoch: 5| Step: 10
Training loss: 0.0531558133661747
Validation loss: 1.58681099261007

Epoch: 508| Step: 0
Training loss: 0.09766699373722076
Validation loss: 1.5840340096463439

Epoch: 5| Step: 1
Training loss: 0.1072264090180397
Validation loss: 1.586658239364624

Epoch: 5| Step: 2
Training loss: 0.044044576585292816
Validation loss: 1.5843909030319543

Epoch: 5| Step: 3
Training loss: 0.07117825746536255
Validation loss: 1.5869898590990292

Epoch: 5| Step: 4
Training loss: 0.06424663960933685
Validation loss: 1.562935745844277

Epoch: 5| Step: 5
Training loss: 0.11372190713882446
Validation loss: 1.5675812998125631

Epoch: 5| Step: 6
Training loss: 0.05615393444895744
Validation loss: 1.5802004465492823

Epoch: 5| Step: 7
Training loss: 0.08175475150346756
Validation loss: 1.5819924595535442

Epoch: 5| Step: 8
Training loss: 0.09307755529880524
Validation loss: 1.5560707174321657

Epoch: 5| Step: 9
Training loss: 0.07904350012540817
Validation loss: 1.567564638712073

Epoch: 5| Step: 10
Training loss: 0.06240076199173927
Validation loss: 1.5893303655808972

Epoch: 509| Step: 0
Training loss: 0.04828038066625595
Validation loss: 1.6002588861732072

Epoch: 5| Step: 1
Training loss: 0.09471351653337479
Validation loss: 1.6163454517241447

Epoch: 5| Step: 2
Training loss: 0.1419813334941864
Validation loss: 1.631342597546116

Epoch: 5| Step: 3
Training loss: 0.039369117468595505
Validation loss: 1.6369051164196384

Epoch: 5| Step: 4
Training loss: 0.07093656063079834
Validation loss: 1.6291638497383363

Epoch: 5| Step: 5
Training loss: 0.07097779214382172
Validation loss: 1.6361461442003968

Epoch: 5| Step: 6
Training loss: 0.1107335090637207
Validation loss: 1.642033943565943

Epoch: 5| Step: 7
Training loss: 0.1191227063536644
Validation loss: 1.6289143536680488

Epoch: 5| Step: 8
Training loss: 0.06995240598917007
Validation loss: 1.600596297171808

Epoch: 5| Step: 9
Training loss: 0.06810756772756577
Validation loss: 1.5914332751304872

Epoch: 5| Step: 10
Training loss: 0.09483572840690613
Validation loss: 1.5565048007554905

Epoch: 510| Step: 0
Training loss: 0.06676025688648224
Validation loss: 1.5131133615329702

Epoch: 5| Step: 1
Training loss: 0.12749028205871582
Validation loss: 1.537527653478807

Epoch: 5| Step: 2
Training loss: 0.08868321776390076
Validation loss: 1.523170712173626

Epoch: 5| Step: 3
Training loss: 0.13961490988731384
Validation loss: 1.5272786155823739

Epoch: 5| Step: 4
Training loss: 0.07555046677589417
Validation loss: 1.553852326126509

Epoch: 5| Step: 5
Training loss: 0.05849022790789604
Validation loss: 1.5661871471712667

Epoch: 5| Step: 6
Training loss: 0.06137051433324814
Validation loss: 1.5709624341739121

Epoch: 5| Step: 7
Training loss: 0.08937504142522812
Validation loss: 1.5900825069796654

Epoch: 5| Step: 8
Training loss: 0.11371109634637833
Validation loss: 1.610656561390046

Epoch: 5| Step: 9
Training loss: 0.102175273001194
Validation loss: 1.5784744607504977

Epoch: 5| Step: 10
Training loss: 0.0855981633067131
Validation loss: 1.5861592151785409

Epoch: 511| Step: 0
Training loss: 0.10804945230484009
Validation loss: 1.5774086098517142

Epoch: 5| Step: 1
Training loss: 0.11633505672216415
Validation loss: 1.5657676906995877

Epoch: 5| Step: 2
Training loss: 0.1007116287946701
Validation loss: 1.5637405380125968

Epoch: 5| Step: 3
Training loss: 0.0990590900182724
Validation loss: 1.5380486057650657

Epoch: 5| Step: 4
Training loss: 0.14196284115314484
Validation loss: 1.564501423989573

Epoch: 5| Step: 5
Training loss: 0.08806595206260681
Validation loss: 1.5302185166266657

Epoch: 5| Step: 6
Training loss: 0.08244714885950089
Validation loss: 1.5503213841428038

Epoch: 5| Step: 7
Training loss: 0.08474081754684448
Validation loss: 1.5851101695850331

Epoch: 5| Step: 8
Training loss: 0.12408187240362167
Validation loss: 1.565617751049739

Epoch: 5| Step: 9
Training loss: 0.13333973288536072
Validation loss: 1.596736172194122

Epoch: 5| Step: 10
Training loss: 0.07601852715015411
Validation loss: 1.578633386601684

Epoch: 512| Step: 0
Training loss: 0.06966011226177216
Validation loss: 1.5619711145277946

Epoch: 5| Step: 1
Training loss: 0.09265190362930298
Validation loss: 1.5592054397829118

Epoch: 5| Step: 2
Training loss: 0.08250276744365692
Validation loss: 1.5539819912243915

Epoch: 5| Step: 3
Training loss: 0.07564753293991089
Validation loss: 1.5850267102641444

Epoch: 5| Step: 4
Training loss: 0.11475082486867905
Validation loss: 1.5748294707267516

Epoch: 5| Step: 5
Training loss: 0.08188702911138535
Validation loss: 1.5936435550771735

Epoch: 5| Step: 6
Training loss: 0.0910089761018753
Validation loss: 1.6068311519520257

Epoch: 5| Step: 7
Training loss: 0.10029304027557373
Validation loss: 1.6197249633009716

Epoch: 5| Step: 8
Training loss: 0.14520224928855896
Validation loss: 1.611374996041739

Epoch: 5| Step: 9
Training loss: 0.13119420409202576
Validation loss: 1.6288978207495906

Epoch: 5| Step: 10
Training loss: 0.1045495793223381
Validation loss: 1.6076137891379736

Epoch: 513| Step: 0
Training loss: 0.05978478863835335
Validation loss: 1.606315251319639

Epoch: 5| Step: 1
Training loss: 0.08285454660654068
Validation loss: 1.5701726777579195

Epoch: 5| Step: 2
Training loss: 0.06113266944885254
Validation loss: 1.5573195859950075

Epoch: 5| Step: 3
Training loss: 0.06944586336612701
Validation loss: 1.5415450911368094

Epoch: 5| Step: 4
Training loss: 0.05522676557302475
Validation loss: 1.5858822971261957

Epoch: 5| Step: 5
Training loss: 0.1334363967180252
Validation loss: 1.5291515550305765

Epoch: 5| Step: 6
Training loss: 0.09241573512554169
Validation loss: 1.567490275188159

Epoch: 5| Step: 7
Training loss: 0.09313695877790451
Validation loss: 1.5477398390411048

Epoch: 5| Step: 8
Training loss: 0.1292629987001419
Validation loss: 1.5430531450497207

Epoch: 5| Step: 9
Training loss: 0.07887782156467438
Validation loss: 1.5468994045770297

Epoch: 5| Step: 10
Training loss: 0.06368225812911987
Validation loss: 1.5451417738391506

Epoch: 514| Step: 0
Training loss: 0.05487311631441116
Validation loss: 1.5683843102506412

Epoch: 5| Step: 1
Training loss: 0.09427247941493988
Validation loss: 1.5986441758371168

Epoch: 5| Step: 2
Training loss: 0.09673909097909927
Validation loss: 1.594326001341625

Epoch: 5| Step: 3
Training loss: 0.13092896342277527
Validation loss: 1.6275674476418445

Epoch: 5| Step: 4
Training loss: 0.103548564016819
Validation loss: 1.627802228414884

Epoch: 5| Step: 5
Training loss: 0.07435768842697144
Validation loss: 1.6288221331052883

Epoch: 5| Step: 6
Training loss: 0.10785093158483505
Validation loss: 1.6234678376105525

Epoch: 5| Step: 7
Training loss: 0.08817420899868011
Validation loss: 1.5879171356078117

Epoch: 5| Step: 8
Training loss: 0.04769165813922882
Validation loss: 1.559236700816821

Epoch: 5| Step: 9
Training loss: 0.07494278252124786
Validation loss: 1.5555798853597333

Epoch: 5| Step: 10
Training loss: 0.08082369714975357
Validation loss: 1.5532191254759347

Epoch: 515| Step: 0
Training loss: 0.0900268480181694
Validation loss: 1.5289760840836393

Epoch: 5| Step: 1
Training loss: 0.10422780364751816
Validation loss: 1.5734115454458422

Epoch: 5| Step: 2
Training loss: 0.1209370344877243
Validation loss: 1.556139419155736

Epoch: 5| Step: 3
Training loss: 0.07708106935024261
Validation loss: 1.5807002206002512

Epoch: 5| Step: 4
Training loss: 0.09309191256761551
Validation loss: 1.5804611034290765

Epoch: 5| Step: 5
Training loss: 0.04162865877151489
Validation loss: 1.599871325236495

Epoch: 5| Step: 6
Training loss: 0.10936830192804337
Validation loss: 1.6221693382468274

Epoch: 5| Step: 7
Training loss: 0.08144982904195786
Validation loss: 1.6313420111133206

Epoch: 5| Step: 8
Training loss: 0.12669679522514343
Validation loss: 1.6364568497544976

Epoch: 5| Step: 9
Training loss: 0.0705275759100914
Validation loss: 1.5935698734816683

Epoch: 5| Step: 10
Training loss: 0.07341460883617401
Validation loss: 1.5793513277525544

Epoch: 516| Step: 0
Training loss: 0.08168090879917145
Validation loss: 1.56817723730559

Epoch: 5| Step: 1
Training loss: 0.09217128902673721
Validation loss: 1.5372300404374317

Epoch: 5| Step: 2
Training loss: 0.07727501541376114
Validation loss: 1.5340267586451706

Epoch: 5| Step: 3
Training loss: 0.09284263849258423
Validation loss: 1.543782047046128

Epoch: 5| Step: 4
Training loss: 0.10523970425128937
Validation loss: 1.5629100684196717

Epoch: 5| Step: 5
Training loss: 0.06362730264663696
Validation loss: 1.5752444728728263

Epoch: 5| Step: 6
Training loss: 0.0709599182009697
Validation loss: 1.617339834090202

Epoch: 5| Step: 7
Training loss: 0.10076943784952164
Validation loss: 1.640319630663882

Epoch: 5| Step: 8
Training loss: 0.14291176199913025
Validation loss: 1.638539630879638

Epoch: 5| Step: 9
Training loss: 0.08498694747686386
Validation loss: 1.631513479576316

Epoch: 5| Step: 10
Training loss: 0.11459803581237793
Validation loss: 1.6088852318384315

Epoch: 517| Step: 0
Training loss: 0.06965567171573639
Validation loss: 1.5788205849227084

Epoch: 5| Step: 1
Training loss: 0.07571310549974442
Validation loss: 1.6030097341024747

Epoch: 5| Step: 2
Training loss: 0.09001574665307999
Validation loss: 1.5826289192322762

Epoch: 5| Step: 3
Training loss: 0.08064223825931549
Validation loss: 1.5776850984942528

Epoch: 5| Step: 4
Training loss: 0.10275764763355255
Validation loss: 1.6007344543292958

Epoch: 5| Step: 5
Training loss: 0.10499832779169083
Validation loss: 1.6480560841098908

Epoch: 5| Step: 6
Training loss: 0.1068316251039505
Validation loss: 1.6201187910572175

Epoch: 5| Step: 7
Training loss: 0.05812860652804375
Validation loss: 1.6283323918619463

Epoch: 5| Step: 8
Training loss: 0.07539615035057068
Validation loss: 1.6092431096620456

Epoch: 5| Step: 9
Training loss: 0.07184633612632751
Validation loss: 1.595194217979267

Epoch: 5| Step: 10
Training loss: 0.07085271179676056
Validation loss: 1.5712267557779949

Epoch: 518| Step: 0
Training loss: 0.05222851037979126
Validation loss: 1.5552158330076484

Epoch: 5| Step: 1
Training loss: 0.10250020027160645
Validation loss: 1.5519817836823002

Epoch: 5| Step: 2
Training loss: 0.11229021847248077
Validation loss: 1.526001190626493

Epoch: 5| Step: 3
Training loss: 0.06633976846933365
Validation loss: 1.5769706567128499

Epoch: 5| Step: 4
Training loss: 0.0659673884510994
Validation loss: 1.5792625950228782

Epoch: 5| Step: 5
Training loss: 0.0875081941485405
Validation loss: 1.6104760913438694

Epoch: 5| Step: 6
Training loss: 0.09390626847743988
Validation loss: 1.6107434585530271

Epoch: 5| Step: 7
Training loss: 0.07608862966299057
Validation loss: 1.6345819696303336

Epoch: 5| Step: 8
Training loss: 0.15331360697746277
Validation loss: 1.6049105146879792

Epoch: 5| Step: 9
Training loss: 0.07600678503513336
Validation loss: 1.5728309308328936

Epoch: 5| Step: 10
Training loss: 0.06424430012702942
Validation loss: 1.5276461314129572

Epoch: 519| Step: 0
Training loss: 0.08099262416362762
Validation loss: 1.5463540387409989

Epoch: 5| Step: 1
Training loss: 0.1304948627948761
Validation loss: 1.4954292594745595

Epoch: 5| Step: 2
Training loss: 0.09071715921163559
Validation loss: 1.5382422990696405

Epoch: 5| Step: 3
Training loss: 0.0773073136806488
Validation loss: 1.532769271122512

Epoch: 5| Step: 4
Training loss: 0.08449620753526688
Validation loss: 1.5573130935750983

Epoch: 5| Step: 5
Training loss: 0.13933786749839783
Validation loss: 1.5946209892149894

Epoch: 5| Step: 6
Training loss: 0.0849255695939064
Validation loss: 1.6038629342150945

Epoch: 5| Step: 7
Training loss: 0.06133528798818588
Validation loss: 1.6302491670013757

Epoch: 5| Step: 8
Training loss: 0.1068224087357521
Validation loss: 1.6457374185644171

Epoch: 5| Step: 9
Training loss: 0.0775938630104065
Validation loss: 1.6123724932311683

Epoch: 5| Step: 10
Training loss: 0.1022285595536232
Validation loss: 1.6432431359444895

Epoch: 520| Step: 0
Training loss: 0.06262706965208054
Validation loss: 1.6298905085491877

Epoch: 5| Step: 1
Training loss: 0.11222436279058456
Validation loss: 1.5888234530725787

Epoch: 5| Step: 2
Training loss: 0.09114882349967957
Validation loss: 1.5539192691926034

Epoch: 5| Step: 3
Training loss: 0.08340446650981903
Validation loss: 1.5925383888265139

Epoch: 5| Step: 4
Training loss: 0.07697125524282455
Validation loss: 1.5230799727542426

Epoch: 5| Step: 5
Training loss: 0.09336523711681366
Validation loss: 1.5671036281893331

Epoch: 5| Step: 6
Training loss: 0.07980585843324661
Validation loss: 1.5369801944301975

Epoch: 5| Step: 7
Training loss: 0.1921047568321228
Validation loss: 1.5595140021334413

Epoch: 5| Step: 8
Training loss: 0.043469104915857315
Validation loss: 1.5417683034814813

Epoch: 5| Step: 9
Training loss: 0.07256652414798737
Validation loss: 1.5342666461903562

Epoch: 5| Step: 10
Training loss: 0.05839848518371582
Validation loss: 1.5589785793776154

Epoch: 521| Step: 0
Training loss: 0.08850294351577759
Validation loss: 1.5653242795698104

Epoch: 5| Step: 1
Training loss: 0.09855540096759796
Validation loss: 1.5577379529194166

Epoch: 5| Step: 2
Training loss: 0.11844493448734283
Validation loss: 1.544000002645677

Epoch: 5| Step: 3
Training loss: 0.06375069916248322
Validation loss: 1.5587899800269835

Epoch: 5| Step: 4
Training loss: 0.07415322214365005
Validation loss: 1.5514003974135204

Epoch: 5| Step: 5
Training loss: 0.07821876555681229
Validation loss: 1.552559632127003

Epoch: 5| Step: 6
Training loss: 0.09604550898075104
Validation loss: 1.5267581888424453

Epoch: 5| Step: 7
Training loss: 0.1103915199637413
Validation loss: 1.5480132615694435

Epoch: 5| Step: 8
Training loss: 0.08025974035263062
Validation loss: 1.5407872597376506

Epoch: 5| Step: 9
Training loss: 0.08327005803585052
Validation loss: 1.5600179408186226

Epoch: 5| Step: 10
Training loss: 0.05972979962825775
Validation loss: 1.5298970553182787

Epoch: 522| Step: 0
Training loss: 0.07745597511529922
Validation loss: 1.5656292682052941

Epoch: 5| Step: 1
Training loss: 0.04479099065065384
Validation loss: 1.5547629761439499

Epoch: 5| Step: 2
Training loss: 0.044179826974868774
Validation loss: 1.5517202731101745

Epoch: 5| Step: 3
Training loss: 0.13510218262672424
Validation loss: 1.5444744568999096

Epoch: 5| Step: 4
Training loss: 0.07257352024316788
Validation loss: 1.5549810112163585

Epoch: 5| Step: 5
Training loss: 0.09486987441778183
Validation loss: 1.5396229643975534

Epoch: 5| Step: 6
Training loss: 0.06555637717247009
Validation loss: 1.5574461144785727

Epoch: 5| Step: 7
Training loss: 0.07569614052772522
Validation loss: 1.5734157549437655

Epoch: 5| Step: 8
Training loss: 0.10541536659002304
Validation loss: 1.5827678929093063

Epoch: 5| Step: 9
Training loss: 0.11347385495901108
Validation loss: 1.6192859667603687

Epoch: 5| Step: 10
Training loss: 0.13467244803905487
Validation loss: 1.6057031244359992

Epoch: 523| Step: 0
Training loss: 0.13426566123962402
Validation loss: 1.6394101804302585

Epoch: 5| Step: 1
Training loss: 0.08680423349142075
Validation loss: 1.6540714335697952

Epoch: 5| Step: 2
Training loss: 0.07952303439378738
Validation loss: 1.6415934396046463

Epoch: 5| Step: 3
Training loss: 0.14105069637298584
Validation loss: 1.6549876146419074

Epoch: 5| Step: 4
Training loss: 0.09126939624547958
Validation loss: 1.61616958854019

Epoch: 5| Step: 5
Training loss: 0.10490413010120392
Validation loss: 1.6020119664489583

Epoch: 5| Step: 6
Training loss: 0.06133146211504936
Validation loss: 1.54287641022795

Epoch: 5| Step: 7
Training loss: 0.10808825492858887
Validation loss: 1.5479211038158787

Epoch: 5| Step: 8
Training loss: 0.1080486923456192
Validation loss: 1.4852939985131706

Epoch: 5| Step: 9
Training loss: 0.14245453476905823
Validation loss: 1.514921631223412

Epoch: 5| Step: 10
Training loss: 0.12644706666469574
Validation loss: 1.514368550751799

Epoch: 524| Step: 0
Training loss: 0.07317203283309937
Validation loss: 1.5421335222900554

Epoch: 5| Step: 1
Training loss: 0.07027601450681686
Validation loss: 1.5759195589250135

Epoch: 5| Step: 2
Training loss: 0.10898242145776749
Validation loss: 1.591176248365833

Epoch: 5| Step: 3
Training loss: 0.11419639736413956
Validation loss: 1.5820423826094596

Epoch: 5| Step: 4
Training loss: 0.06377392262220383
Validation loss: 1.5831866238706855

Epoch: 5| Step: 5
Training loss: 0.044351570308208466
Validation loss: 1.5613905691331433

Epoch: 5| Step: 6
Training loss: 0.07080736011266708
Validation loss: 1.586838883738364

Epoch: 5| Step: 7
Training loss: 0.10763046890497208
Validation loss: 1.5410914190353886

Epoch: 5| Step: 8
Training loss: 0.10360448062419891
Validation loss: 1.560002185965097

Epoch: 5| Step: 9
Training loss: 0.09357142448425293
Validation loss: 1.562146564965607

Epoch: 5| Step: 10
Training loss: 0.12753170728683472
Validation loss: 1.5654776955163607

Epoch: 525| Step: 0
Training loss: 0.07761295139789581
Validation loss: 1.5772678852081299

Epoch: 5| Step: 1
Training loss: 0.10262956470251083
Validation loss: 1.5609439957526423

Epoch: 5| Step: 2
Training loss: 0.05264340713620186
Validation loss: 1.5794972514593473

Epoch: 5| Step: 3
Training loss: 0.048144999891519547
Validation loss: 1.5888991407168809

Epoch: 5| Step: 4
Training loss: 0.06062392145395279
Validation loss: 1.5964639558587024

Epoch: 5| Step: 5
Training loss: 0.07413052022457123
Validation loss: 1.5907868185350973

Epoch: 5| Step: 6
Training loss: 0.1423516720533371
Validation loss: 1.590524722171086

Epoch: 5| Step: 7
Training loss: 0.14348074793815613
Validation loss: 1.5839826214698054

Epoch: 5| Step: 8
Training loss: 0.07870019972324371
Validation loss: 1.5604569668410926

Epoch: 5| Step: 9
Training loss: 0.13180971145629883
Validation loss: 1.5376569506942586

Epoch: 5| Step: 10
Training loss: 0.09580927342176437
Validation loss: 1.5407016700313938

Epoch: 526| Step: 0
Training loss: 0.12212417274713516
Validation loss: 1.519870852911344

Epoch: 5| Step: 1
Training loss: 0.1039169654250145
Validation loss: 1.5287963126295356

Epoch: 5| Step: 2
Training loss: 0.06712973117828369
Validation loss: 1.5506846161298855

Epoch: 5| Step: 3
Training loss: 0.05080357939004898
Validation loss: 1.5448429699867003

Epoch: 5| Step: 4
Training loss: 0.08595515787601471
Validation loss: 1.5631829359198128

Epoch: 5| Step: 5
Training loss: 0.10200469195842743
Validation loss: 1.5720290086602653

Epoch: 5| Step: 6
Training loss: 0.06796698272228241
Validation loss: 1.5532415425905617

Epoch: 5| Step: 7
Training loss: 0.0721655935049057
Validation loss: 1.5690450411970898

Epoch: 5| Step: 8
Training loss: 0.05825961381196976
Validation loss: 1.5604816995641237

Epoch: 5| Step: 9
Training loss: 0.0704028457403183
Validation loss: 1.5432986520951795

Epoch: 5| Step: 10
Training loss: 0.1266617327928543
Validation loss: 1.526820360973317

Epoch: 527| Step: 0
Training loss: 0.07015954703092575
Validation loss: 1.5568521061251241

Epoch: 5| Step: 1
Training loss: 0.09709438681602478
Validation loss: 1.5778931558773082

Epoch: 5| Step: 2
Training loss: 0.06370767205953598
Validation loss: 1.5857201442923596

Epoch: 5| Step: 3
Training loss: 0.08476446568965912
Validation loss: 1.6188956999009656

Epoch: 5| Step: 4
Training loss: 0.09433386474847794
Validation loss: 1.612541885786159

Epoch: 5| Step: 5
Training loss: 0.08538196980953217
Validation loss: 1.5893143838451755

Epoch: 5| Step: 6
Training loss: 0.06352503597736359
Validation loss: 1.5884930446583738

Epoch: 5| Step: 7
Training loss: 0.04425313323736191
Validation loss: 1.5833213944588937

Epoch: 5| Step: 8
Training loss: 0.1071813553571701
Validation loss: 1.5767976699336883

Epoch: 5| Step: 9
Training loss: 0.051068492233753204
Validation loss: 1.5829450673954462

Epoch: 5| Step: 10
Training loss: 0.10424201935529709
Validation loss: 1.586362143998505

Epoch: 528| Step: 0
Training loss: 0.08840523660182953
Validation loss: 1.5469859377030404

Epoch: 5| Step: 1
Training loss: 0.09997012466192245
Validation loss: 1.5598772879569762

Epoch: 5| Step: 2
Training loss: 0.07750391960144043
Validation loss: 1.5799664348684332

Epoch: 5| Step: 3
Training loss: 0.10895122587680817
Validation loss: 1.569898719428688

Epoch: 5| Step: 4
Training loss: 0.06964521110057831
Validation loss: 1.5715463007650068

Epoch: 5| Step: 5
Training loss: 0.06985577195882797
Validation loss: 1.5116666068312943

Epoch: 5| Step: 6
Training loss: 0.10598435252904892
Validation loss: 1.518194120417359

Epoch: 5| Step: 7
Training loss: 0.11225026845932007
Validation loss: 1.5247485958119875

Epoch: 5| Step: 8
Training loss: 0.0531022846698761
Validation loss: 1.5515324146516862

Epoch: 5| Step: 9
Training loss: 0.09705479443073273
Validation loss: 1.5660999513441516

Epoch: 5| Step: 10
Training loss: 0.10539744794368744
Validation loss: 1.5900224242159116

Epoch: 529| Step: 0
Training loss: 0.06196054071187973
Validation loss: 1.5932277979389313

Epoch: 5| Step: 1
Training loss: 0.11330194771289825
Validation loss: 1.6189880307002733

Epoch: 5| Step: 2
Training loss: 0.07305090129375458
Validation loss: 1.6159928293638333

Epoch: 5| Step: 3
Training loss: 0.05785742402076721
Validation loss: 1.6014982474747526

Epoch: 5| Step: 4
Training loss: 0.05291575938463211
Validation loss: 1.5930299489728865

Epoch: 5| Step: 5
Training loss: 0.0862928256392479
Validation loss: 1.5859179855674825

Epoch: 5| Step: 6
Training loss: 0.13386625051498413
Validation loss: 1.6008270517472298

Epoch: 5| Step: 7
Training loss: 0.058829665184020996
Validation loss: 1.5957448918332335

Epoch: 5| Step: 8
Training loss: 0.06537424027919769
Validation loss: 1.5891326473605247

Epoch: 5| Step: 9
Training loss: 0.12327688932418823
Validation loss: 1.5913085283771637

Epoch: 5| Step: 10
Training loss: 0.13208097219467163
Validation loss: 1.621793516220585

Epoch: 530| Step: 0
Training loss: 0.13847823441028595
Validation loss: 1.6351608986495643

Epoch: 5| Step: 1
Training loss: 0.08219648897647858
Validation loss: 1.6046836850463704

Epoch: 5| Step: 2
Training loss: 0.06188199669122696
Validation loss: 1.5764053047344249

Epoch: 5| Step: 3
Training loss: 0.0981646403670311
Validation loss: 1.5511494746772192

Epoch: 5| Step: 4
Training loss: 0.08531016856431961
Validation loss: 1.572217664410991

Epoch: 5| Step: 5
Training loss: 0.05525105074048042
Validation loss: 1.54469834860935

Epoch: 5| Step: 6
Training loss: 0.07934091985225677
Validation loss: 1.5499657238683393

Epoch: 5| Step: 7
Training loss: 0.13989338278770447
Validation loss: 1.5597653453068068

Epoch: 5| Step: 8
Training loss: 0.06432168185710907
Validation loss: 1.5636093949758878

Epoch: 5| Step: 9
Training loss: 0.06377170234918594
Validation loss: 1.5684575688454412

Epoch: 5| Step: 10
Training loss: 0.032657161355018616
Validation loss: 1.5547302769076439

Epoch: 531| Step: 0
Training loss: 0.08171864598989487
Validation loss: 1.548235047248102

Epoch: 5| Step: 1
Training loss: 0.03281039744615555
Validation loss: 1.5567109783490498

Epoch: 5| Step: 2
Training loss: 0.07512445747852325
Validation loss: 1.5445584693262655

Epoch: 5| Step: 3
Training loss: 0.058914076536893845
Validation loss: 1.5514295011438348

Epoch: 5| Step: 4
Training loss: 0.0775223970413208
Validation loss: 1.5292583550176313

Epoch: 5| Step: 5
Training loss: 0.07820838689804077
Validation loss: 1.567699210618132

Epoch: 5| Step: 6
Training loss: 0.17894896864891052
Validation loss: 1.5356739810718003

Epoch: 5| Step: 7
Training loss: 0.08641114085912704
Validation loss: 1.5321796786400579

Epoch: 5| Step: 8
Training loss: 0.07229597866535187
Validation loss: 1.5245026324384956

Epoch: 5| Step: 9
Training loss: 0.09327904880046844
Validation loss: 1.5312423167690155

Epoch: 5| Step: 10
Training loss: 0.06772676110267639
Validation loss: 1.5575175522476115

Epoch: 532| Step: 0
Training loss: 0.08128808438777924
Validation loss: 1.5689215455003964

Epoch: 5| Step: 1
Training loss: 0.061999477446079254
Validation loss: 1.5913541214440459

Epoch: 5| Step: 2
Training loss: 0.10581786930561066
Validation loss: 1.5805624069706086

Epoch: 5| Step: 3
Training loss: 0.07879650592803955
Validation loss: 1.5661253711228729

Epoch: 5| Step: 4
Training loss: 0.07376709580421448
Validation loss: 1.582204923834852

Epoch: 5| Step: 5
Training loss: 0.06694971770048141
Validation loss: 1.569687722831644

Epoch: 5| Step: 6
Training loss: 0.06046471744775772
Validation loss: 1.5701479732349355

Epoch: 5| Step: 7
Training loss: 0.06602296233177185
Validation loss: 1.5690806014563448

Epoch: 5| Step: 8
Training loss: 0.07222342491149902
Validation loss: 1.5498060936568885

Epoch: 5| Step: 9
Training loss: 0.11452339589595795
Validation loss: 1.5318148648867043

Epoch: 5| Step: 10
Training loss: 0.10659272968769073
Validation loss: 1.5272263589725699

Epoch: 533| Step: 0
Training loss: 0.11929406225681305
Validation loss: 1.5335134075533958

Epoch: 5| Step: 1
Training loss: 0.05019655078649521
Validation loss: 1.5464641330062703

Epoch: 5| Step: 2
Training loss: 0.06121537834405899
Validation loss: 1.5672616971436368

Epoch: 5| Step: 3
Training loss: 0.06519830226898193
Validation loss: 1.5799182858518375

Epoch: 5| Step: 4
Training loss: 0.07969360053539276
Validation loss: 1.5788379279516076

Epoch: 5| Step: 5
Training loss: 0.03469432517886162
Validation loss: 1.6039179922432028

Epoch: 5| Step: 6
Training loss: 0.11482928693294525
Validation loss: 1.5959252926611132

Epoch: 5| Step: 7
Training loss: 0.05745067447423935
Validation loss: 1.5954712206317532

Epoch: 5| Step: 8
Training loss: 0.07918894290924072
Validation loss: 1.5903112516608289

Epoch: 5| Step: 9
Training loss: 0.11353864520788193
Validation loss: 1.5969953652351134

Epoch: 5| Step: 10
Training loss: 0.07483562082052231
Validation loss: 1.596816957637828

Epoch: 534| Step: 0
Training loss: 0.06076942756772041
Validation loss: 1.5904245043313632

Epoch: 5| Step: 1
Training loss: 0.06339540332555771
Validation loss: 1.623278203190014

Epoch: 5| Step: 2
Training loss: 0.09688699245452881
Validation loss: 1.5753593547369844

Epoch: 5| Step: 3
Training loss: 0.1450081616640091
Validation loss: 1.574582407551427

Epoch: 5| Step: 4
Training loss: 0.12356896698474884
Validation loss: 1.5574565510596

Epoch: 5| Step: 5
Training loss: 0.04152297228574753
Validation loss: 1.551774541536967

Epoch: 5| Step: 6
Training loss: 0.10670659691095352
Validation loss: 1.594595201553837

Epoch: 5| Step: 7
Training loss: 0.06861089169979095
Validation loss: 1.598063962433928

Epoch: 5| Step: 8
Training loss: 0.08480112999677658
Validation loss: 1.594665027433826

Epoch: 5| Step: 9
Training loss: 0.09126516431570053
Validation loss: 1.6020081280380167

Epoch: 5| Step: 10
Training loss: 0.09825608879327774
Validation loss: 1.6019244117121543

Epoch: 535| Step: 0
Training loss: 0.1055309996008873
Validation loss: 1.5868808274628015

Epoch: 5| Step: 1
Training loss: 0.06946605443954468
Validation loss: 1.5999341748094047

Epoch: 5| Step: 2
Training loss: 0.10750017315149307
Validation loss: 1.581222136815389

Epoch: 5| Step: 3
Training loss: 0.10650704056024551
Validation loss: 1.559045809571461

Epoch: 5| Step: 4
Training loss: 0.08937399089336395
Validation loss: 1.5588348020789444

Epoch: 5| Step: 5
Training loss: 0.09014369547367096
Validation loss: 1.5579734233117872

Epoch: 5| Step: 6
Training loss: 0.0821709930896759
Validation loss: 1.6092116114913777

Epoch: 5| Step: 7
Training loss: 0.06566141545772552
Validation loss: 1.652427654112539

Epoch: 5| Step: 8
Training loss: 0.08391191065311432
Validation loss: 1.6101526124503023

Epoch: 5| Step: 9
Training loss: 0.14718207716941833
Validation loss: 1.616327294739344

Epoch: 5| Step: 10
Training loss: 0.09114354103803635
Validation loss: 1.626155202106763

Epoch: 536| Step: 0
Training loss: 0.11560499668121338
Validation loss: 1.6160459351795975

Epoch: 5| Step: 1
Training loss: 0.07171376794576645
Validation loss: 1.5989250252323766

Epoch: 5| Step: 2
Training loss: 0.13225087523460388
Validation loss: 1.5869596991487729

Epoch: 5| Step: 3
Training loss: 0.07449128478765488
Validation loss: 1.574737451409781

Epoch: 5| Step: 4
Training loss: 0.08086885511875153
Validation loss: 1.5743908286094666

Epoch: 5| Step: 5
Training loss: 0.1291896551847458
Validation loss: 1.583978783699774

Epoch: 5| Step: 6
Training loss: 0.0813819169998169
Validation loss: 1.5935536943456179

Epoch: 5| Step: 7
Training loss: 0.09157753735780716
Validation loss: 1.58244663541035

Epoch: 5| Step: 8
Training loss: 0.10736825317144394
Validation loss: 1.585008890398087

Epoch: 5| Step: 9
Training loss: 0.14151924848556519
Validation loss: 1.6195225254181893

Epoch: 5| Step: 10
Training loss: 0.054788738489151
Validation loss: 1.6063740535448956

Epoch: 537| Step: 0
Training loss: 0.13113956153392792
Validation loss: 1.616306330568047

Epoch: 5| Step: 1
Training loss: 0.07646895200014114
Validation loss: 1.6325081599655973

Epoch: 5| Step: 2
Training loss: 0.09710519015789032
Validation loss: 1.6226539637452813

Epoch: 5| Step: 3
Training loss: 0.0930725559592247
Validation loss: 1.6196996319678523

Epoch: 5| Step: 4
Training loss: 0.1037314161658287
Validation loss: 1.6034350600293887

Epoch: 5| Step: 5
Training loss: 0.08275528252124786
Validation loss: 1.585185347064849

Epoch: 5| Step: 6
Training loss: 0.10481914132833481
Validation loss: 1.5816595579988213

Epoch: 5| Step: 7
Training loss: 0.09947634488344193
Validation loss: 1.54867987350751

Epoch: 5| Step: 8
Training loss: 0.09621836990118027
Validation loss: 1.5552318942162298

Epoch: 5| Step: 9
Training loss: 0.061813075095415115
Validation loss: 1.5493690454831688

Epoch: 5| Step: 10
Training loss: 0.061293911188840866
Validation loss: 1.5607152626078615

Epoch: 538| Step: 0
Training loss: 0.0769234374165535
Validation loss: 1.598951555067493

Epoch: 5| Step: 1
Training loss: 0.07986593246459961
Validation loss: 1.5939057411686066

Epoch: 5| Step: 2
Training loss: 0.08290191739797592
Validation loss: 1.5873638250494515

Epoch: 5| Step: 3
Training loss: 0.05234166979789734
Validation loss: 1.5795683271141463

Epoch: 5| Step: 4
Training loss: 0.06456213444471359
Validation loss: 1.5526142927908129

Epoch: 5| Step: 5
Training loss: 0.08948394656181335
Validation loss: 1.5756176581946753

Epoch: 5| Step: 6
Training loss: 0.07310112565755844
Validation loss: 1.5695155500083842

Epoch: 5| Step: 7
Training loss: 0.09702910482883453
Validation loss: 1.5830822119148829

Epoch: 5| Step: 8
Training loss: 0.08278970420360565
Validation loss: 1.602084796915772

Epoch: 5| Step: 9
Training loss: 0.09159259498119354
Validation loss: 1.5836911329659082

Epoch: 5| Step: 10
Training loss: 0.08569560945034027
Validation loss: 1.5893016617785218

Epoch: 539| Step: 0
Training loss: 0.06325583159923553
Validation loss: 1.5570491744625954

Epoch: 5| Step: 1
Training loss: 0.053652919828891754
Validation loss: 1.5735024777791833

Epoch: 5| Step: 2
Training loss: 0.0719701275229454
Validation loss: 1.5424071268368793

Epoch: 5| Step: 3
Training loss: 0.1077437549829483
Validation loss: 1.5661223806360716

Epoch: 5| Step: 4
Training loss: 0.10211237519979477
Validation loss: 1.5689389321111864

Epoch: 5| Step: 5
Training loss: 0.12083344161510468
Validation loss: 1.57978307431744

Epoch: 5| Step: 6
Training loss: 0.11010380834341049
Validation loss: 1.5764678114203996

Epoch: 5| Step: 7
Training loss: 0.08173312246799469
Validation loss: 1.6103187478998655

Epoch: 5| Step: 8
Training loss: 0.06873264163732529
Validation loss: 1.6034483685288379

Epoch: 5| Step: 9
Training loss: 0.07269458472728729
Validation loss: 1.601196809481549

Epoch: 5| Step: 10
Training loss: 0.08910124003887177
Validation loss: 1.589413268591768

Epoch: 540| Step: 0
Training loss: 0.1255369335412979
Validation loss: 1.5922016302744548

Epoch: 5| Step: 1
Training loss: 0.10877218097448349
Validation loss: 1.598028153501531

Epoch: 5| Step: 2
Training loss: 0.050254613161087036
Validation loss: 1.6142038081281929

Epoch: 5| Step: 3
Training loss: 0.04146835207939148
Validation loss: 1.5977952018860848

Epoch: 5| Step: 4
Training loss: 0.0484108030796051
Validation loss: 1.5980222276462022

Epoch: 5| Step: 5
Training loss: 0.03825315088033676
Validation loss: 1.6174814547261884

Epoch: 5| Step: 6
Training loss: 0.07695843279361725
Validation loss: 1.6133100037933679

Epoch: 5| Step: 7
Training loss: 0.11792466789484024
Validation loss: 1.6199751387360275

Epoch: 5| Step: 8
Training loss: 0.05275392532348633
Validation loss: 1.5819955756587367

Epoch: 5| Step: 9
Training loss: 0.0812566727399826
Validation loss: 1.5806301973199333

Epoch: 5| Step: 10
Training loss: 0.15996767580509186
Validation loss: 1.597569877101529

Epoch: 541| Step: 0
Training loss: 0.09550628811120987
Validation loss: 1.6099027074793333

Epoch: 5| Step: 1
Training loss: 0.10258130729198456
Validation loss: 1.6295459719114407

Epoch: 5| Step: 2
Training loss: 0.0761227086186409
Validation loss: 1.6433662701678533

Epoch: 5| Step: 3
Training loss: 0.08012671768665314
Validation loss: 1.6710150959671184

Epoch: 5| Step: 4
Training loss: 0.09846315532922745
Validation loss: 1.6722716644246092

Epoch: 5| Step: 5
Training loss: 0.10910997539758682
Validation loss: 1.6514184128853582

Epoch: 5| Step: 6
Training loss: 0.07873324304819107
Validation loss: 1.6303093151379657

Epoch: 5| Step: 7
Training loss: 0.10249147564172745
Validation loss: 1.6381237192820477

Epoch: 5| Step: 8
Training loss: 0.13200397789478302
Validation loss: 1.6305607211205266

Epoch: 5| Step: 9
Training loss: 0.10084816068410873
Validation loss: 1.6044251803428895

Epoch: 5| Step: 10
Training loss: 0.08834414184093475
Validation loss: 1.6220843138233307

Epoch: 542| Step: 0
Training loss: 0.08088931441307068
Validation loss: 1.5924557255160423

Epoch: 5| Step: 1
Training loss: 0.09454268962144852
Validation loss: 1.6028111134805987

Epoch: 5| Step: 2
Training loss: 0.0801263079047203
Validation loss: 1.6047244264233498

Epoch: 5| Step: 3
Training loss: 0.09332028031349182
Validation loss: 1.6009109225324405

Epoch: 5| Step: 4
Training loss: 0.1810777485370636
Validation loss: 1.596635498026366

Epoch: 5| Step: 5
Training loss: 0.1348036676645279
Validation loss: 1.581510531005039

Epoch: 5| Step: 6
Training loss: 0.06455548852682114
Validation loss: 1.5783888934760966

Epoch: 5| Step: 7
Training loss: 0.11546690762042999
Validation loss: 1.5649853457686722

Epoch: 5| Step: 8
Training loss: 0.05774978548288345
Validation loss: 1.5962272254369592

Epoch: 5| Step: 9
Training loss: 0.059194959700107574
Validation loss: 1.576777801718763

Epoch: 5| Step: 10
Training loss: 0.051965076476335526
Validation loss: 1.5665240018598494

Epoch: 543| Step: 0
Training loss: 0.08211595565080643
Validation loss: 1.5719946122938586

Epoch: 5| Step: 1
Training loss: 0.06366697698831558
Validation loss: 1.5873706340789795

Epoch: 5| Step: 2
Training loss: 0.07670815289020538
Validation loss: 1.5834499354003577

Epoch: 5| Step: 3
Training loss: 0.048880260437726974
Validation loss: 1.59848468213953

Epoch: 5| Step: 4
Training loss: 0.11427842080593109
Validation loss: 1.6175468660170031

Epoch: 5| Step: 5
Training loss: 0.06331335753202438
Validation loss: 1.6298785376292404

Epoch: 5| Step: 6
Training loss: 0.0833042562007904
Validation loss: 1.632619139968708

Epoch: 5| Step: 7
Training loss: 0.03965064883232117
Validation loss: 1.6174669778475197

Epoch: 5| Step: 8
Training loss: 0.0641527771949768
Validation loss: 1.6153129121308685

Epoch: 5| Step: 9
Training loss: 0.07367072999477386
Validation loss: 1.593881853165165

Epoch: 5| Step: 10
Training loss: 0.10738924145698547
Validation loss: 1.5745200303293043

Epoch: 544| Step: 0
Training loss: 0.07058268785476685
Validation loss: 1.5900788191826112

Epoch: 5| Step: 1
Training loss: 0.07797234505414963
Validation loss: 1.5741886631135018

Epoch: 5| Step: 2
Training loss: 0.0969495102763176
Validation loss: 1.568684047268283

Epoch: 5| Step: 3
Training loss: 0.05363811179995537
Validation loss: 1.5688113384349371

Epoch: 5| Step: 4
Training loss: 0.07996632158756256
Validation loss: 1.569573417786629

Epoch: 5| Step: 5
Training loss: 0.04850303381681442
Validation loss: 1.5567373396247945

Epoch: 5| Step: 6
Training loss: 0.0605144202709198
Validation loss: 1.5851867788581437

Epoch: 5| Step: 7
Training loss: 0.06304273754358292
Validation loss: 1.57781300621648

Epoch: 5| Step: 8
Training loss: 0.07838551700115204
Validation loss: 1.606835651141341

Epoch: 5| Step: 9
Training loss: 0.08475208282470703
Validation loss: 1.6062270069635043

Epoch: 5| Step: 10
Training loss: 0.07084081321954727
Validation loss: 1.6032712151927333

Epoch: 545| Step: 0
Training loss: 0.10633258521556854
Validation loss: 1.5857240307715632

Epoch: 5| Step: 1
Training loss: 0.06393571197986603
Validation loss: 1.5989362885875087

Epoch: 5| Step: 2
Training loss: 0.08373794704675674
Validation loss: 1.5680005153020222

Epoch: 5| Step: 3
Training loss: 0.07786600291728973
Validation loss: 1.5556423600002

Epoch: 5| Step: 4
Training loss: 0.09082163870334625
Validation loss: 1.4975088719398744

Epoch: 5| Step: 5
Training loss: 0.09017889946699142
Validation loss: 1.5017470967385076

Epoch: 5| Step: 6
Training loss: 0.07300212234258652
Validation loss: 1.5142529062045518

Epoch: 5| Step: 7
Training loss: 0.05871517211198807
Validation loss: 1.529415202397172

Epoch: 5| Step: 8
Training loss: 0.11723555624485016
Validation loss: 1.537722747812989

Epoch: 5| Step: 9
Training loss: 0.10246803611516953
Validation loss: 1.5539990753255866

Epoch: 5| Step: 10
Training loss: 0.08566493541002274
Validation loss: 1.5850761167464718

Epoch: 546| Step: 0
Training loss: 0.04497862607240677
Validation loss: 1.611549477423391

Epoch: 5| Step: 1
Training loss: 0.09792379289865494
Validation loss: 1.6242078068435832

Epoch: 5| Step: 2
Training loss: 0.0619327537715435
Validation loss: 1.6384352227692962

Epoch: 5| Step: 3
Training loss: 0.06658603250980377
Validation loss: 1.6304055054982503

Epoch: 5| Step: 4
Training loss: 0.10654199123382568
Validation loss: 1.6152303885388117

Epoch: 5| Step: 5
Training loss: 0.09456706047058105
Validation loss: 1.6100186192861168

Epoch: 5| Step: 6
Training loss: 0.10960763692855835
Validation loss: 1.5795266243719286

Epoch: 5| Step: 7
Training loss: 0.13874275982379913
Validation loss: 1.5757722995614494

Epoch: 5| Step: 8
Training loss: 0.08118747174739838
Validation loss: 1.562838472345824

Epoch: 5| Step: 9
Training loss: 0.06453309953212738
Validation loss: 1.5551934998522523

Epoch: 5| Step: 10
Training loss: 0.07833510637283325
Validation loss: 1.5735499102582213

Epoch: 547| Step: 0
Training loss: 0.08364424109458923
Validation loss: 1.5587110609136603

Epoch: 5| Step: 1
Training loss: 0.06849463284015656
Validation loss: 1.5791849064570602

Epoch: 5| Step: 2
Training loss: 0.06692269444465637
Validation loss: 1.5744789402971986

Epoch: 5| Step: 3
Training loss: 0.14671292901039124
Validation loss: 1.5699692169825237

Epoch: 5| Step: 4
Training loss: 0.08737599104642868
Validation loss: 1.6015386337875037

Epoch: 5| Step: 5
Training loss: 0.09312363713979721
Validation loss: 1.5767486967066282

Epoch: 5| Step: 6
Training loss: 0.08353634923696518
Validation loss: 1.5812101620499805

Epoch: 5| Step: 7
Training loss: 0.09700505435466766
Validation loss: 1.5733888405625538

Epoch: 5| Step: 8
Training loss: 0.08959408104419708
Validation loss: 1.5776527043311828

Epoch: 5| Step: 9
Training loss: 0.08201022446155548
Validation loss: 1.5774444713387439

Epoch: 5| Step: 10
Training loss: 0.03861389681696892
Validation loss: 1.595970119199445

Epoch: 548| Step: 0
Training loss: 0.05609585717320442
Validation loss: 1.6048105955123901

Epoch: 5| Step: 1
Training loss: 0.07925047725439072
Validation loss: 1.5855471395677136

Epoch: 5| Step: 2
Training loss: 0.06560667604207993
Validation loss: 1.56116138222397

Epoch: 5| Step: 3
Training loss: 0.09468140453100204
Validation loss: 1.550819557200196

Epoch: 5| Step: 4
Training loss: 0.07694720476865768
Validation loss: 1.5471677446878085

Epoch: 5| Step: 5
Training loss: 0.06281615793704987
Validation loss: 1.5454027716831495

Epoch: 5| Step: 6
Training loss: 0.11359866708517075
Validation loss: 1.5699763503125919

Epoch: 5| Step: 7
Training loss: 0.08463935554027557
Validation loss: 1.5716617491937452

Epoch: 5| Step: 8
Training loss: 0.07021383941173553
Validation loss: 1.5855466909306024

Epoch: 5| Step: 9
Training loss: 0.08081670105457306
Validation loss: 1.5894509938455397

Epoch: 5| Step: 10
Training loss: 0.04249641299247742
Validation loss: 1.5894163308605072

Epoch: 549| Step: 0
Training loss: 0.08352635055780411
Validation loss: 1.5886422998161727

Epoch: 5| Step: 1
Training loss: 0.06737331300973892
Validation loss: 1.6062608406107912

Epoch: 5| Step: 2
Training loss: 0.07376008480787277
Validation loss: 1.5886956568687194

Epoch: 5| Step: 3
Training loss: 0.12004218250513077
Validation loss: 1.587494948858856

Epoch: 5| Step: 4
Training loss: 0.03932421654462814
Validation loss: 1.582369077590204

Epoch: 5| Step: 5
Training loss: 0.09207040071487427
Validation loss: 1.5564332803090413

Epoch: 5| Step: 6
Training loss: 0.060566991567611694
Validation loss: 1.5745065865978118

Epoch: 5| Step: 7
Training loss: 0.06040417030453682
Validation loss: 1.5287116650612123

Epoch: 5| Step: 8
Training loss: 0.07132026553153992
Validation loss: 1.5732807087641891

Epoch: 5| Step: 9
Training loss: 0.05038747936487198
Validation loss: 1.5868720700663905

Epoch: 5| Step: 10
Training loss: 0.08079670369625092
Validation loss: 1.584041964623236

Epoch: 550| Step: 0
Training loss: 0.11208822578191757
Validation loss: 1.578778075915511

Epoch: 5| Step: 1
Training loss: 0.08695261925458908
Validation loss: 1.5751569194178427

Epoch: 5| Step: 2
Training loss: 0.088554248213768
Validation loss: 1.5283200112722253

Epoch: 5| Step: 3
Training loss: 0.08437748998403549
Validation loss: 1.5066372092052172

Epoch: 5| Step: 4
Training loss: 0.08317171782255173
Validation loss: 1.5209761601622387

Epoch: 5| Step: 5
Training loss: 0.08254538476467133
Validation loss: 1.5108044147491455

Epoch: 5| Step: 6
Training loss: 0.12096297740936279
Validation loss: 1.4882100051449192

Epoch: 5| Step: 7
Training loss: 0.07095886766910553
Validation loss: 1.522267726159865

Epoch: 5| Step: 8
Training loss: 0.07439950853586197
Validation loss: 1.5442168866434405

Epoch: 5| Step: 9
Training loss: 0.03731194883584976
Validation loss: 1.5676283092908962

Epoch: 5| Step: 10
Training loss: 0.08478674292564392
Validation loss: 1.5855040986050841

Epoch: 551| Step: 0
Training loss: 0.05362548306584358
Validation loss: 1.6066023483071277

Epoch: 5| Step: 1
Training loss: 0.04422036558389664
Validation loss: 1.623882434701407

Epoch: 5| Step: 2
Training loss: 0.13021384179592133
Validation loss: 1.6197910642111173

Epoch: 5| Step: 3
Training loss: 0.04033280536532402
Validation loss: 1.6048006524321854

Epoch: 5| Step: 4
Training loss: 0.04419144243001938
Validation loss: 1.566927109995196

Epoch: 5| Step: 5
Training loss: 0.06954077631235123
Validation loss: 1.5283471640720163

Epoch: 5| Step: 6
Training loss: 0.08053116500377655
Validation loss: 1.5219774771762151

Epoch: 5| Step: 7
Training loss: 0.10646952688694
Validation loss: 1.5209215661530853

Epoch: 5| Step: 8
Training loss: 0.08441440016031265
Validation loss: 1.5386556515129663

Epoch: 5| Step: 9
Training loss: 0.1138865128159523
Validation loss: 1.562518842758671

Epoch: 5| Step: 10
Training loss: 0.10053472220897675
Validation loss: 1.564704070809067

Epoch: 552| Step: 0
Training loss: 0.08941133320331573
Validation loss: 1.5415619393830657

Epoch: 5| Step: 1
Training loss: 0.04574396088719368
Validation loss: 1.5526702083567137

Epoch: 5| Step: 2
Training loss: 0.06655874103307724
Validation loss: 1.5663292266989266

Epoch: 5| Step: 3
Training loss: 0.07694946229457855
Validation loss: 1.560657024383545

Epoch: 5| Step: 4
Training loss: 0.0703873261809349
Validation loss: 1.5852693550048336

Epoch: 5| Step: 5
Training loss: 0.10670751333236694
Validation loss: 1.5726049510381555

Epoch: 5| Step: 6
Training loss: 0.043994367122650146
Validation loss: 1.580084922493145

Epoch: 5| Step: 7
Training loss: 0.07867231220006943
Validation loss: 1.571544688235047

Epoch: 5| Step: 8
Training loss: 0.07900077849626541
Validation loss: 1.5682750619867796

Epoch: 5| Step: 9
Training loss: 0.09668853133916855
Validation loss: 1.6138966878255208

Epoch: 5| Step: 10
Training loss: 0.05100977420806885
Validation loss: 1.6058880347077564

Epoch: 553| Step: 0
Training loss: 0.08055661618709564
Validation loss: 1.609841710777693

Epoch: 5| Step: 1
Training loss: 0.05936872959136963
Validation loss: 1.5864822082622076

Epoch: 5| Step: 2
Training loss: 0.12187446653842926
Validation loss: 1.6059893344038276

Epoch: 5| Step: 3
Training loss: 0.04946626350283623
Validation loss: 1.5989041661703458

Epoch: 5| Step: 4
Training loss: 0.05491560697555542
Validation loss: 1.5795808287077053

Epoch: 5| Step: 5
Training loss: 0.05677415058016777
Validation loss: 1.5696032585636261

Epoch: 5| Step: 6
Training loss: 0.08363966643810272
Validation loss: 1.5842026587455504

Epoch: 5| Step: 7
Training loss: 0.09180518239736557
Validation loss: 1.5400538867519749

Epoch: 5| Step: 8
Training loss: 0.07633839547634125
Validation loss: 1.5732530099089428

Epoch: 5| Step: 9
Training loss: 0.07390885055065155
Validation loss: 1.5605000488219722

Epoch: 5| Step: 10
Training loss: 0.09720791131258011
Validation loss: 1.555862561989856

Epoch: 554| Step: 0
Training loss: 0.06942598521709442
Validation loss: 1.6002481778462727

Epoch: 5| Step: 1
Training loss: 0.06122924014925957
Validation loss: 1.584810221067039

Epoch: 5| Step: 2
Training loss: 0.08754348009824753
Validation loss: 1.5752688120770197

Epoch: 5| Step: 3
Training loss: 0.08250852674245834
Validation loss: 1.566814850735408

Epoch: 5| Step: 4
Training loss: 0.06616536527872086
Validation loss: 1.59084963926705

Epoch: 5| Step: 5
Training loss: 0.10546804964542389
Validation loss: 1.5815819822331911

Epoch: 5| Step: 6
Training loss: 0.08989789336919785
Validation loss: 1.5861987375443982

Epoch: 5| Step: 7
Training loss: 0.11626893281936646
Validation loss: 1.600913732282577

Epoch: 5| Step: 8
Training loss: 0.04828258603811264
Validation loss: 1.598809742158459

Epoch: 5| Step: 9
Training loss: 0.0599469318985939
Validation loss: 1.62314086832026

Epoch: 5| Step: 10
Training loss: 0.07859734445810318
Validation loss: 1.6186192535584973

Epoch: 555| Step: 0
Training loss: 0.09693040698766708
Validation loss: 1.6181954453068395

Epoch: 5| Step: 1
Training loss: 0.09030504524707794
Validation loss: 1.6114955153516544

Epoch: 5| Step: 2
Training loss: 0.10018397867679596
Validation loss: 1.6281447320856073

Epoch: 5| Step: 3
Training loss: 0.06097746640443802
Validation loss: 1.6104904169677405

Epoch: 5| Step: 4
Training loss: 0.07175768166780472
Validation loss: 1.5974694836524226

Epoch: 5| Step: 5
Training loss: 0.04974370822310448
Validation loss: 1.580349403042947

Epoch: 5| Step: 6
Training loss: 0.03570517897605896
Validation loss: 1.592010582647016

Epoch: 5| Step: 7
Training loss: 0.06425437331199646
Validation loss: 1.5979738799474572

Epoch: 5| Step: 8
Training loss: 0.08901491016149521
Validation loss: 1.5878063183958813

Epoch: 5| Step: 9
Training loss: 0.08882080763578415
Validation loss: 1.5853942927493845

Epoch: 5| Step: 10
Training loss: 0.05100322514772415
Validation loss: 1.5796210778656827

Epoch: 556| Step: 0
Training loss: 0.08640966564416885
Validation loss: 1.589136064693492

Epoch: 5| Step: 1
Training loss: 0.07644903659820557
Validation loss: 1.5761172374089558

Epoch: 5| Step: 2
Training loss: 0.05824415013194084
Validation loss: 1.5713130581763484

Epoch: 5| Step: 3
Training loss: 0.05067424848675728
Validation loss: 1.560185513188762

Epoch: 5| Step: 4
Training loss: 0.05893666669726372
Validation loss: 1.566530369943188

Epoch: 5| Step: 5
Training loss: 0.05524132400751114
Validation loss: 1.5793958376812678

Epoch: 5| Step: 6
Training loss: 0.09816274791955948
Validation loss: 1.58533812081942

Epoch: 5| Step: 7
Training loss: 0.0768309235572815
Validation loss: 1.611736391180305

Epoch: 5| Step: 8
Training loss: 0.05580953508615494
Validation loss: 1.6015501432521368

Epoch: 5| Step: 9
Training loss: 0.07551597058773041
Validation loss: 1.617385527139069

Epoch: 5| Step: 10
Training loss: 0.09108318388462067
Validation loss: 1.5926565534325057

Epoch: 557| Step: 0
Training loss: 0.055352382361888885
Validation loss: 1.5460919436588083

Epoch: 5| Step: 1
Training loss: 0.09989473968744278
Validation loss: 1.5552176519106793

Epoch: 5| Step: 2
Training loss: 0.1023099422454834
Validation loss: 1.5588924666886688

Epoch: 5| Step: 3
Training loss: 0.1047687903046608
Validation loss: 1.5568201336809384

Epoch: 5| Step: 4
Training loss: 0.07283367216587067
Validation loss: 1.5839850261647215

Epoch: 5| Step: 5
Training loss: 0.05272935703396797
Validation loss: 1.5891217070241128

Epoch: 5| Step: 6
Training loss: 0.07508717477321625
Validation loss: 1.6126248605789677

Epoch: 5| Step: 7
Training loss: 0.09076006710529327
Validation loss: 1.6318348658982145

Epoch: 5| Step: 8
Training loss: 0.06166551262140274
Validation loss: 1.6132646004358928

Epoch: 5| Step: 9
Training loss: 0.12722153961658478
Validation loss: 1.6008164164840535

Epoch: 5| Step: 10
Training loss: 0.07404883205890656
Validation loss: 1.5815318681860482

Epoch: 558| Step: 0
Training loss: 0.0680382177233696
Validation loss: 1.5850483768729753

Epoch: 5| Step: 1
Training loss: 0.09385935962200165
Validation loss: 1.601240151671953

Epoch: 5| Step: 2
Training loss: 0.1441781371831894
Validation loss: 1.6021624149814728

Epoch: 5| Step: 3
Training loss: 0.05387893319129944
Validation loss: 1.5698579761289781

Epoch: 5| Step: 4
Training loss: 0.04769320413470268
Validation loss: 1.5520771408593783

Epoch: 5| Step: 5
Training loss: 0.05395223945379257
Validation loss: 1.5604015063214045

Epoch: 5| Step: 6
Training loss: 0.05715881660580635
Validation loss: 1.5602104022938719

Epoch: 5| Step: 7
Training loss: 0.050900526344776154
Validation loss: 1.5568866358008435

Epoch: 5| Step: 8
Training loss: 0.0608951561152935
Validation loss: 1.5691455179645168

Epoch: 5| Step: 9
Training loss: 0.09667927771806717
Validation loss: 1.5491222296991656

Epoch: 5| Step: 10
Training loss: 0.09150497615337372
Validation loss: 1.5704440275828044

Epoch: 559| Step: 0
Training loss: 0.1008705347776413
Validation loss: 1.529328764125865

Epoch: 5| Step: 1
Training loss: 0.1100635752081871
Validation loss: 1.5263684821385208

Epoch: 5| Step: 2
Training loss: 0.09141344577074051
Validation loss: 1.5440828851474229

Epoch: 5| Step: 3
Training loss: 0.07737104594707489
Validation loss: 1.5456665100589875

Epoch: 5| Step: 4
Training loss: 0.08031239360570908
Validation loss: 1.5335210433570288

Epoch: 5| Step: 5
Training loss: 0.06425212323665619
Validation loss: 1.5434128648491316

Epoch: 5| Step: 6
Training loss: 0.04974747076630592
Validation loss: 1.5157920801511375

Epoch: 5| Step: 7
Training loss: 0.06499727070331573
Validation loss: 1.510214417211471

Epoch: 5| Step: 8
Training loss: 0.04773038998246193
Validation loss: 1.5261193449779222

Epoch: 5| Step: 9
Training loss: 0.06037437170743942
Validation loss: 1.5475640950664398

Epoch: 5| Step: 10
Training loss: 0.052144136279821396
Validation loss: 1.552549071209405

Epoch: 560| Step: 0
Training loss: 0.06214476749300957
Validation loss: 1.60316514712508

Epoch: 5| Step: 1
Training loss: 0.10989134013652802
Validation loss: 1.597419201686818

Epoch: 5| Step: 2
Training loss: 0.10276863723993301
Validation loss: 1.6153841646768714

Epoch: 5| Step: 3
Training loss: 0.0744682252407074
Validation loss: 1.575490842583359

Epoch: 5| Step: 4
Training loss: 0.058316707611083984
Validation loss: 1.5618833572633806

Epoch: 5| Step: 5
Training loss: 0.06573288142681122
Validation loss: 1.547386933398503

Epoch: 5| Step: 6
Training loss: 0.08319889008998871
Validation loss: 1.481499461717503

Epoch: 5| Step: 7
Training loss: 0.10098443925380707
Validation loss: 1.5074272130125312

Epoch: 5| Step: 8
Training loss: 0.06587325781583786
Validation loss: 1.5448831191626928

Epoch: 5| Step: 9
Training loss: 0.0759626105427742
Validation loss: 1.5402390912014952

Epoch: 5| Step: 10
Training loss: 0.058583538979291916
Validation loss: 1.5872629816814134

Epoch: 561| Step: 0
Training loss: 0.06754277646541595
Validation loss: 1.601897169184941

Epoch: 5| Step: 1
Training loss: 0.0724719762802124
Validation loss: 1.6077195200868832

Epoch: 5| Step: 2
Training loss: 0.10263756662607193
Validation loss: 1.6222098976053216

Epoch: 5| Step: 3
Training loss: 0.09436346590518951
Validation loss: 1.6183004225454023

Epoch: 5| Step: 4
Training loss: 0.06832047551870346
Validation loss: 1.6147239195403231

Epoch: 5| Step: 5
Training loss: 0.0618460476398468
Validation loss: 1.6181341166137366

Epoch: 5| Step: 6
Training loss: 0.08183974772691727
Validation loss: 1.592143512541248

Epoch: 5| Step: 7
Training loss: 0.09122849255800247
Validation loss: 1.5920421641360047

Epoch: 5| Step: 8
Training loss: 0.08929256349802017
Validation loss: 1.5930193335779252

Epoch: 5| Step: 9
Training loss: 0.10416054725646973
Validation loss: 1.5776545142614713

Epoch: 5| Step: 10
Training loss: 0.05966953560709953
Validation loss: 1.5793936816594933

Epoch: 562| Step: 0
Training loss: 0.06797696650028229
Validation loss: 1.5924319451855076

Epoch: 5| Step: 1
Training loss: 0.050467170774936676
Validation loss: 1.5921797598561933

Epoch: 5| Step: 2
Training loss: 0.06065831333398819
Validation loss: 1.6117178265766432

Epoch: 5| Step: 3
Training loss: 0.14116358757019043
Validation loss: 1.6229923937910347

Epoch: 5| Step: 4
Training loss: 0.05055636912584305
Validation loss: 1.6188566941086964

Epoch: 5| Step: 5
Training loss: 0.0661887675523758
Validation loss: 1.5874308591247888

Epoch: 5| Step: 6
Training loss: 0.08113617449998856
Validation loss: 1.5857348929169357

Epoch: 5| Step: 7
Training loss: 0.06009219214320183
Validation loss: 1.552181936079456

Epoch: 5| Step: 8
Training loss: 0.08499021828174591
Validation loss: 1.5470195624136156

Epoch: 5| Step: 9
Training loss: 0.11454226821660995
Validation loss: 1.5498045009951438

Epoch: 5| Step: 10
Training loss: 0.10003937035799026
Validation loss: 1.5643277809184084

Epoch: 563| Step: 0
Training loss: 0.061496712267398834
Validation loss: 1.5552845590858049

Epoch: 5| Step: 1
Training loss: 0.06778028607368469
Validation loss: 1.570009167476367

Epoch: 5| Step: 2
Training loss: 0.038386791944503784
Validation loss: 1.597825050354004

Epoch: 5| Step: 3
Training loss: 0.10887811332941055
Validation loss: 1.617210295892531

Epoch: 5| Step: 4
Training loss: 0.07945015281438828
Validation loss: 1.6211538968547698

Epoch: 5| Step: 5
Training loss: 0.0913974717259407
Validation loss: 1.636939444849568

Epoch: 5| Step: 6
Training loss: 0.09703338891267776
Validation loss: 1.6245887766602218

Epoch: 5| Step: 7
Training loss: 0.07036374509334564
Validation loss: 1.6227520204359485

Epoch: 5| Step: 8
Training loss: 0.04756289720535278
Validation loss: 1.6160879827314807

Epoch: 5| Step: 9
Training loss: 0.05779040977358818
Validation loss: 1.6151017399244412

Epoch: 5| Step: 10
Training loss: 0.08286500722169876
Validation loss: 1.5951873166586763

Epoch: 564| Step: 0
Training loss: 0.05028136447072029
Validation loss: 1.6182198947475803

Epoch: 5| Step: 1
Training loss: 0.061727024614810944
Validation loss: 1.6149929556795346

Epoch: 5| Step: 2
Training loss: 0.05031973123550415
Validation loss: 1.6134209709782754

Epoch: 5| Step: 3
Training loss: 0.09834371507167816
Validation loss: 1.5835733285514257

Epoch: 5| Step: 4
Training loss: 0.059851400554180145
Validation loss: 1.6106701256126486

Epoch: 5| Step: 5
Training loss: 0.054398756474256516
Validation loss: 1.6229051287456224

Epoch: 5| Step: 6
Training loss: 0.06786458939313889
Validation loss: 1.607734744266797

Epoch: 5| Step: 7
Training loss: 0.03349419683218002
Validation loss: 1.62320714740343

Epoch: 5| Step: 8
Training loss: 0.08134907484054565
Validation loss: 1.6042166691954418

Epoch: 5| Step: 9
Training loss: 0.0787518173456192
Validation loss: 1.5992550593550487

Epoch: 5| Step: 10
Training loss: 0.11570757627487183
Validation loss: 1.603501744167779

Epoch: 565| Step: 0
Training loss: 0.06492625176906586
Validation loss: 1.5874998569488525

Epoch: 5| Step: 1
Training loss: 0.09777869284152985
Validation loss: 1.6132072838403846

Epoch: 5| Step: 2
Training loss: 0.06001145392656326
Validation loss: 1.5975299163531231

Epoch: 5| Step: 3
Training loss: 0.0913858562707901
Validation loss: 1.5959856587071573

Epoch: 5| Step: 4
Training loss: 0.06363483518362045
Validation loss: 1.6064284565628215

Epoch: 5| Step: 5
Training loss: 0.056679170578718185
Validation loss: 1.5953434923643708

Epoch: 5| Step: 6
Training loss: 0.04796954244375229
Validation loss: 1.5635273616801026

Epoch: 5| Step: 7
Training loss: 0.06864430010318756
Validation loss: 1.5768728986863167

Epoch: 5| Step: 8
Training loss: 0.08574952185153961
Validation loss: 1.5914956267162035

Epoch: 5| Step: 9
Training loss: 0.07558940351009369
Validation loss: 1.5674162353238752

Epoch: 5| Step: 10
Training loss: 0.06857836991548538
Validation loss: 1.5844351335238385

Epoch: 566| Step: 0
Training loss: 0.09363166987895966
Validation loss: 1.5444223957677041

Epoch: 5| Step: 1
Training loss: 0.06017925217747688
Validation loss: 1.566240031232116

Epoch: 5| Step: 2
Training loss: 0.06254714727401733
Validation loss: 1.56414887725666

Epoch: 5| Step: 3
Training loss: 0.08902379125356674
Validation loss: 1.5800648504687893

Epoch: 5| Step: 4
Training loss: 0.0549483522772789
Validation loss: 1.5810465120500135

Epoch: 5| Step: 5
Training loss: 0.050443828105926514
Validation loss: 1.571980550724973

Epoch: 5| Step: 6
Training loss: 0.07473696768283844
Validation loss: 1.5827509100719164

Epoch: 5| Step: 7
Training loss: 0.06016882136464119
Validation loss: 1.578122712591643

Epoch: 5| Step: 8
Training loss: 0.044944994151592255
Validation loss: 1.5630045533180237

Epoch: 5| Step: 9
Training loss: 0.06376753002405167
Validation loss: 1.5539587172128821

Epoch: 5| Step: 10
Training loss: 0.05853714793920517
Validation loss: 1.5486511748324159

Epoch: 567| Step: 0
Training loss: 0.07728240638971329
Validation loss: 1.5719588161796652

Epoch: 5| Step: 1
Training loss: 0.05098961666226387
Validation loss: 1.5574856945263442

Epoch: 5| Step: 2
Training loss: 0.06932590901851654
Validation loss: 1.5508362875189832

Epoch: 5| Step: 3
Training loss: 0.04831797629594803
Validation loss: 1.5580428518274778

Epoch: 5| Step: 4
Training loss: 0.08097796142101288
Validation loss: 1.538816398189914

Epoch: 5| Step: 5
Training loss: 0.07157011330127716
Validation loss: 1.5726391910224833

Epoch: 5| Step: 6
Training loss: 0.09699873626232147
Validation loss: 1.5899884290592645

Epoch: 5| Step: 7
Training loss: 0.07840093970298767
Validation loss: 1.5932781888592629

Epoch: 5| Step: 8
Training loss: 0.059517115354537964
Validation loss: 1.585687021414439

Epoch: 5| Step: 9
Training loss: 0.08781330287456512
Validation loss: 1.599966565767924

Epoch: 5| Step: 10
Training loss: 0.06328924745321274
Validation loss: 1.5718519239015476

Epoch: 568| Step: 0
Training loss: 0.06702525168657303
Validation loss: 1.571191886419891

Epoch: 5| Step: 1
Training loss: 0.06311468780040741
Validation loss: 1.556264236409177

Epoch: 5| Step: 2
Training loss: 0.06935404241085052
Validation loss: 1.581187237975418

Epoch: 5| Step: 3
Training loss: 0.051680099219083786
Validation loss: 1.5442002255429503

Epoch: 5| Step: 4
Training loss: 0.07682943344116211
Validation loss: 1.5509094653591033

Epoch: 5| Step: 5
Training loss: 0.0585382878780365
Validation loss: 1.5707854378607966

Epoch: 5| Step: 6
Training loss: 0.053372811526060104
Validation loss: 1.5996773672360245

Epoch: 5| Step: 7
Training loss: 0.05098439007997513
Validation loss: 1.571667096948111

Epoch: 5| Step: 8
Training loss: 0.07630410045385361
Validation loss: 1.590095018827787

Epoch: 5| Step: 9
Training loss: 0.0428583025932312
Validation loss: 1.5919878335409268

Epoch: 5| Step: 10
Training loss: 0.044627588242292404
Validation loss: 1.5702369123376825

Epoch: 569| Step: 0
Training loss: 0.05749223381280899
Validation loss: 1.530909897178732

Epoch: 5| Step: 1
Training loss: 0.06920871883630753
Validation loss: 1.5561569775304487

Epoch: 5| Step: 2
Training loss: 0.06252893060445786
Validation loss: 1.566833499939211

Epoch: 5| Step: 3
Training loss: 0.05576300621032715
Validation loss: 1.5445057269065612

Epoch: 5| Step: 4
Training loss: 0.07851696014404297
Validation loss: 1.5242710036616172

Epoch: 5| Step: 5
Training loss: 0.036798808723688126
Validation loss: 1.5044908703014415

Epoch: 5| Step: 6
Training loss: 0.08269225060939789
Validation loss: 1.5121291363111107

Epoch: 5| Step: 7
Training loss: 0.04782649129629135
Validation loss: 1.5066748921589186

Epoch: 5| Step: 8
Training loss: 0.08202681690454483
Validation loss: 1.4996490452879219

Epoch: 5| Step: 9
Training loss: 0.10087589919567108
Validation loss: 1.5243219355101227

Epoch: 5| Step: 10
Training loss: 0.05074337124824524
Validation loss: 1.5065976624847741

Epoch: 570| Step: 0
Training loss: 0.10035277903079987
Validation loss: 1.5294976029344785

Epoch: 5| Step: 1
Training loss: 0.08901594579219818
Validation loss: 1.530426074099797

Epoch: 5| Step: 2
Training loss: 0.05627318099141121
Validation loss: 1.54040160230411

Epoch: 5| Step: 3
Training loss: 0.07671035081148148
Validation loss: 1.5575879722513177

Epoch: 5| Step: 4
Training loss: 0.05128256604075432
Validation loss: 1.5618558135083926

Epoch: 5| Step: 5
Training loss: 0.06524818390607834
Validation loss: 1.5696012307238836

Epoch: 5| Step: 6
Training loss: 0.05370035767555237
Validation loss: 1.5579919148516912

Epoch: 5| Step: 7
Training loss: 0.05893968418240547
Validation loss: 1.56627135122976

Epoch: 5| Step: 8
Training loss: 0.0376095175743103
Validation loss: 1.59178251348516

Epoch: 5| Step: 9
Training loss: 0.06749599426984787
Validation loss: 1.5814443788220804

Epoch: 5| Step: 10
Training loss: 0.08463852852582932
Validation loss: 1.5910581991236696

Epoch: 571| Step: 0
Training loss: 0.07367204129695892
Validation loss: 1.5966286665649825

Epoch: 5| Step: 1
Training loss: 0.09012822806835175
Validation loss: 1.6007767774725472

Epoch: 5| Step: 2
Training loss: 0.1040988564491272
Validation loss: 1.6192199081502936

Epoch: 5| Step: 3
Training loss: 0.08024521172046661
Validation loss: 1.6020684524249005

Epoch: 5| Step: 4
Training loss: 0.058109868317842484
Validation loss: 1.6148613793875581

Epoch: 5| Step: 5
Training loss: 0.09501953423023224
Validation loss: 1.5896653795755038

Epoch: 5| Step: 6
Training loss: 0.04887712001800537
Validation loss: 1.5901080100767073

Epoch: 5| Step: 7
Training loss: 0.07396156340837479
Validation loss: 1.596651631016885

Epoch: 5| Step: 8
Training loss: 0.04582929238677025
Validation loss: 1.591261294580275

Epoch: 5| Step: 9
Training loss: 0.06307201087474823
Validation loss: 1.6054607085002366

Epoch: 5| Step: 10
Training loss: 0.04535512998700142
Validation loss: 1.5957104685486003

Epoch: 572| Step: 0
Training loss: 0.08533398807048798
Validation loss: 1.5860525254280335

Epoch: 5| Step: 1
Training loss: 0.05675704404711723
Validation loss: 1.5713818150181924

Epoch: 5| Step: 2
Training loss: 0.05826936289668083
Validation loss: 1.5563378462227442

Epoch: 5| Step: 3
Training loss: 0.05262317508459091
Validation loss: 1.5629273076211252

Epoch: 5| Step: 4
Training loss: 0.08523419499397278
Validation loss: 1.546046151909777

Epoch: 5| Step: 5
Training loss: 0.08036430925130844
Validation loss: 1.530174514298798

Epoch: 5| Step: 6
Training loss: 0.05288495868444443
Validation loss: 1.5437912453887284

Epoch: 5| Step: 7
Training loss: 0.050531841814517975
Validation loss: 1.5561595065619356

Epoch: 5| Step: 8
Training loss: 0.10213033854961395
Validation loss: 1.5523466845994354

Epoch: 5| Step: 9
Training loss: 0.09542141854763031
Validation loss: 1.5905544257933093

Epoch: 5| Step: 10
Training loss: 0.05884825438261032
Validation loss: 1.5683231020486483

Epoch: 573| Step: 0
Training loss: 0.1009921208024025
Validation loss: 1.5814477166821879

Epoch: 5| Step: 1
Training loss: 0.08457428961992264
Validation loss: 1.5547879216491536

Epoch: 5| Step: 2
Training loss: 0.051463693380355835
Validation loss: 1.5805191775803924

Epoch: 5| Step: 3
Training loss: 0.05587010458111763
Validation loss: 1.5637192803044473

Epoch: 5| Step: 4
Training loss: 0.047765593975782394
Validation loss: 1.5907206009793025

Epoch: 5| Step: 5
Training loss: 0.055029429495334625
Validation loss: 1.5933787438177294

Epoch: 5| Step: 6
Training loss: 0.05202137306332588
Validation loss: 1.597868101571196

Epoch: 5| Step: 7
Training loss: 0.0650593489408493
Validation loss: 1.5730814010866228

Epoch: 5| Step: 8
Training loss: 0.08218839764595032
Validation loss: 1.601266589856917

Epoch: 5| Step: 9
Training loss: 0.0690402239561081
Validation loss: 1.595326187790081

Epoch: 5| Step: 10
Training loss: 0.057291701436042786
Validation loss: 1.5997973424132153

Epoch: 574| Step: 0
Training loss: 0.04116862267255783
Validation loss: 1.5788206182500368

Epoch: 5| Step: 1
Training loss: 0.08874067664146423
Validation loss: 1.5814776112956386

Epoch: 5| Step: 2
Training loss: 0.041237540543079376
Validation loss: 1.575367357141228

Epoch: 5| Step: 3
Training loss: 0.07774768769741058
Validation loss: 1.577680515986617

Epoch: 5| Step: 4
Training loss: 0.07686496526002884
Validation loss: 1.5624504448265157

Epoch: 5| Step: 5
Training loss: 0.09260313212871552
Validation loss: 1.5913520795042797

Epoch: 5| Step: 6
Training loss: 0.07656992226839066
Validation loss: 1.6008646078007196

Epoch: 5| Step: 7
Training loss: 0.08142955601215363
Validation loss: 1.5929324985832296

Epoch: 5| Step: 8
Training loss: 0.04164701700210571
Validation loss: 1.6097567042996805

Epoch: 5| Step: 9
Training loss: 0.0643816664814949
Validation loss: 1.6011624041424002

Epoch: 5| Step: 10
Training loss: 0.09013325721025467
Validation loss: 1.618205319168747

Epoch: 575| Step: 0
Training loss: 0.08144240081310272
Validation loss: 1.6183175925285584

Epoch: 5| Step: 1
Training loss: 0.0436377115547657
Validation loss: 1.5944881528936408

Epoch: 5| Step: 2
Training loss: 0.0722619816660881
Validation loss: 1.5894319203592115

Epoch: 5| Step: 3
Training loss: 0.08604396879673004
Validation loss: 1.5418005143442461

Epoch: 5| Step: 4
Training loss: 0.08365930616855621
Validation loss: 1.5534948969400058

Epoch: 5| Step: 5
Training loss: 0.095968097448349
Validation loss: 1.558775455720963

Epoch: 5| Step: 6
Training loss: 0.08243559300899506
Validation loss: 1.5579144390680457

Epoch: 5| Step: 7
Training loss: 0.07615413516759872
Validation loss: 1.5871430789270708

Epoch: 5| Step: 8
Training loss: 0.09320272505283356
Validation loss: 1.573593892076964

Epoch: 5| Step: 9
Training loss: 0.05684654787182808
Validation loss: 1.5966511067523752

Epoch: 5| Step: 10
Training loss: 0.050171107053756714
Validation loss: 1.6054919086476809

Epoch: 576| Step: 0
Training loss: 0.07345123589038849
Validation loss: 1.6141586290892733

Epoch: 5| Step: 1
Training loss: 0.07159604132175446
Validation loss: 1.6240719120989564

Epoch: 5| Step: 2
Training loss: 0.08244191110134125
Validation loss: 1.608097759626245

Epoch: 5| Step: 3
Training loss: 0.06903757154941559
Validation loss: 1.5750007193575624

Epoch: 5| Step: 4
Training loss: 0.061382852494716644
Validation loss: 1.5487695765751663

Epoch: 5| Step: 5
Training loss: 0.06520289182662964
Validation loss: 1.5745633827742709

Epoch: 5| Step: 6
Training loss: 0.11536313593387604
Validation loss: 1.544714258563134

Epoch: 5| Step: 7
Training loss: 0.11679182201623917
Validation loss: 1.567934613714936

Epoch: 5| Step: 8
Training loss: 0.08101578801870346
Validation loss: 1.5879874562704435

Epoch: 5| Step: 9
Training loss: 0.06633392721414566
Validation loss: 1.5852250937492616

Epoch: 5| Step: 10
Training loss: 0.12364360690116882
Validation loss: 1.5970083500749321

Epoch: 577| Step: 0
Training loss: 0.09218810498714447
Validation loss: 1.5794417601759716

Epoch: 5| Step: 1
Training loss: 0.08459990471601486
Validation loss: 1.5997099696948964

Epoch: 5| Step: 2
Training loss: 0.09023492783308029
Validation loss: 1.5725174437287033

Epoch: 5| Step: 3
Training loss: 0.11869748681783676
Validation loss: 1.5702967464282949

Epoch: 5| Step: 4
Training loss: 0.07869468629360199
Validation loss: 1.582059952520555

Epoch: 5| Step: 5
Training loss: 0.0469951331615448
Validation loss: 1.5620653142211258

Epoch: 5| Step: 6
Training loss: 0.05454368144273758
Validation loss: 1.5382190994037095

Epoch: 5| Step: 7
Training loss: 0.0666721761226654
Validation loss: 1.5040285369401336

Epoch: 5| Step: 8
Training loss: 0.0794663205742836
Validation loss: 1.5228805170264295

Epoch: 5| Step: 9
Training loss: 0.09195432811975479
Validation loss: 1.5391675695296256

Epoch: 5| Step: 10
Training loss: 0.08025848865509033
Validation loss: 1.5760039680747575

Epoch: 578| Step: 0
Training loss: 0.05630213022232056
Validation loss: 1.560231375437911

Epoch: 5| Step: 1
Training loss: 0.13874764740467072
Validation loss: 1.5385383072719778

Epoch: 5| Step: 2
Training loss: 0.07950874418020248
Validation loss: 1.5463987088972522

Epoch: 5| Step: 3
Training loss: 0.16833965480327606
Validation loss: 1.536517632904873

Epoch: 5| Step: 4
Training loss: 0.09378564357757568
Validation loss: 1.537136621372674

Epoch: 5| Step: 5
Training loss: 0.049871038645505905
Validation loss: 1.5522398871760215

Epoch: 5| Step: 6
Training loss: 0.040742769837379456
Validation loss: 1.5706115871347406

Epoch: 5| Step: 7
Training loss: 0.07896542549133301
Validation loss: 1.5551682749102194

Epoch: 5| Step: 8
Training loss: 0.08112213760614395
Validation loss: 1.6146981562337568

Epoch: 5| Step: 9
Training loss: 0.10124542564153671
Validation loss: 1.5940381532074304

Epoch: 5| Step: 10
Training loss: 0.08927880972623825
Validation loss: 1.591780354899745

Epoch: 579| Step: 0
Training loss: 0.0875498428940773
Validation loss: 1.5769839581622873

Epoch: 5| Step: 1
Training loss: 0.061219751834869385
Validation loss: 1.5699899709352882

Epoch: 5| Step: 2
Training loss: 0.07597871124744415
Validation loss: 1.5623201631730603

Epoch: 5| Step: 3
Training loss: 0.10030512511730194
Validation loss: 1.5537746683243783

Epoch: 5| Step: 4
Training loss: 0.055827993899583817
Validation loss: 1.5826579293897074

Epoch: 5| Step: 5
Training loss: 0.09071390330791473
Validation loss: 1.5914317664279733

Epoch: 5| Step: 6
Training loss: 0.0795174092054367
Validation loss: 1.5971651679726058

Epoch: 5| Step: 7
Training loss: 0.09400077164173126
Validation loss: 1.5970898828198832

Epoch: 5| Step: 8
Training loss: 0.05589338019490242
Validation loss: 1.6345585366731048

Epoch: 5| Step: 9
Training loss: 0.06321821361780167
Validation loss: 1.6148317629291165

Epoch: 5| Step: 10
Training loss: 0.04732677340507507
Validation loss: 1.6129382502648137

Epoch: 580| Step: 0
Training loss: 0.05917101353406906
Validation loss: 1.5864061924719042

Epoch: 5| Step: 1
Training loss: 0.0598992221057415
Validation loss: 1.5548010641528713

Epoch: 5| Step: 2
Training loss: 0.048342883586883545
Validation loss: 1.5523331344768565

Epoch: 5| Step: 3
Training loss: 0.06929785013198853
Validation loss: 1.5393307542288175

Epoch: 5| Step: 4
Training loss: 0.08811575174331665
Validation loss: 1.5393094144841677

Epoch: 5| Step: 5
Training loss: 0.05718660354614258
Validation loss: 1.5336695268589964

Epoch: 5| Step: 6
Training loss: 0.044007815420627594
Validation loss: 1.5543254588239936

Epoch: 5| Step: 7
Training loss: 0.07765963673591614
Validation loss: 1.5401737061879968

Epoch: 5| Step: 8
Training loss: 0.0656832829117775
Validation loss: 1.5687177668335617

Epoch: 5| Step: 9
Training loss: 0.055722128599882126
Validation loss: 1.5949113586897492

Epoch: 5| Step: 10
Training loss: 0.09848129004240036
Validation loss: 1.586287872765654

Epoch: 581| Step: 0
Training loss: 0.06992638111114502
Validation loss: 1.606692938394444

Epoch: 5| Step: 1
Training loss: 0.046368204057216644
Validation loss: 1.6260206968553605

Epoch: 5| Step: 2
Training loss: 0.05214453488588333
Validation loss: 1.6139085959362727

Epoch: 5| Step: 3
Training loss: 0.08943827450275421
Validation loss: 1.5945836613255162

Epoch: 5| Step: 4
Training loss: 0.07353909313678741
Validation loss: 1.577264142292802

Epoch: 5| Step: 5
Training loss: 0.06662620604038239
Validation loss: 1.5787503129692488

Epoch: 5| Step: 6
Training loss: 0.07270784676074982
Validation loss: 1.5863554503328057

Epoch: 5| Step: 7
Training loss: 0.0835094079375267
Validation loss: 1.5528531965389047

Epoch: 5| Step: 8
Training loss: 0.07869582623243332
Validation loss: 1.5619106305542814

Epoch: 5| Step: 9
Training loss: 0.051846135407686234
Validation loss: 1.5697780078457249

Epoch: 5| Step: 10
Training loss: 0.11306308209896088
Validation loss: 1.5557316785217614

Epoch: 582| Step: 0
Training loss: 0.07888489961624146
Validation loss: 1.5788140168754004

Epoch: 5| Step: 1
Training loss: 0.069590263068676
Validation loss: 1.5489616483770392

Epoch: 5| Step: 2
Training loss: 0.06233849376440048
Validation loss: 1.5793206307195848

Epoch: 5| Step: 3
Training loss: 0.08586638420820236
Validation loss: 1.584351275556831

Epoch: 5| Step: 4
Training loss: 0.06987576186656952
Validation loss: 1.5897981992331884

Epoch: 5| Step: 5
Training loss: 0.0648222491145134
Validation loss: 1.5961190731294694

Epoch: 5| Step: 6
Training loss: 0.053639065474271774
Validation loss: 1.583459122206575

Epoch: 5| Step: 7
Training loss: 0.05708075687289238
Validation loss: 1.593375781530975

Epoch: 5| Step: 8
Training loss: 0.07099436968564987
Validation loss: 1.5721302391380392

Epoch: 5| Step: 9
Training loss: 0.039398618042469025
Validation loss: 1.5661510344474547

Epoch: 5| Step: 10
Training loss: 0.049859728664159775
Validation loss: 1.5819348776212303

Epoch: 583| Step: 0
Training loss: 0.06289397925138474
Validation loss: 1.5792825106651551

Epoch: 5| Step: 1
Training loss: 0.08099444955587387
Validation loss: 1.5931651258981356

Epoch: 5| Step: 2
Training loss: 0.044686172157526016
Validation loss: 1.6044527010251117

Epoch: 5| Step: 3
Training loss: 0.050915300846099854
Validation loss: 1.611741473597865

Epoch: 5| Step: 4
Training loss: 0.062359172850847244
Validation loss: 1.5771129554317844

Epoch: 5| Step: 5
Training loss: 0.051205433905124664
Validation loss: 1.6065979202588399

Epoch: 5| Step: 6
Training loss: 0.08216691762208939
Validation loss: 1.5951728026072185

Epoch: 5| Step: 7
Training loss: 0.0940871611237526
Validation loss: 1.5868212689635575

Epoch: 5| Step: 8
Training loss: 0.07371778786182404
Validation loss: 1.5897395277536044

Epoch: 5| Step: 9
Training loss: 0.057395271956920624
Validation loss: 1.594596444919545

Epoch: 5| Step: 10
Training loss: 0.13671144843101501
Validation loss: 1.5805552992769467

Epoch: 584| Step: 0
Training loss: 0.0978543683886528
Validation loss: 1.5755612901462022

Epoch: 5| Step: 1
Training loss: 0.07325629889965057
Validation loss: 1.5818774123345651

Epoch: 5| Step: 2
Training loss: 0.06772338598966599
Validation loss: 1.6116157500974593

Epoch: 5| Step: 3
Training loss: 0.0800473615527153
Validation loss: 1.6272143035806634

Epoch: 5| Step: 4
Training loss: 0.13391977548599243
Validation loss: 1.626876986154946

Epoch: 5| Step: 5
Training loss: 0.08485938608646393
Validation loss: 1.6114065095942507

Epoch: 5| Step: 6
Training loss: 0.05484016612172127
Validation loss: 1.5903590340768137

Epoch: 5| Step: 7
Training loss: 0.06066683679819107
Validation loss: 1.5753661560755905

Epoch: 5| Step: 8
Training loss: 0.07492540776729584
Validation loss: 1.559644288914178

Epoch: 5| Step: 9
Training loss: 0.07785195857286453
Validation loss: 1.5501468296973937

Epoch: 5| Step: 10
Training loss: 0.05996779724955559
Validation loss: 1.5295020739237468

Epoch: 585| Step: 0
Training loss: 0.09564821422100067
Validation loss: 1.5288282722555182

Epoch: 5| Step: 1
Training loss: 0.0702802985906601
Validation loss: 1.5253983992402271

Epoch: 5| Step: 2
Training loss: 0.02732509933412075
Validation loss: 1.5358711929731472

Epoch: 5| Step: 3
Training loss: 0.05320221185684204
Validation loss: 1.5443895427129601

Epoch: 5| Step: 4
Training loss: 0.07623843848705292
Validation loss: 1.5507991390843545

Epoch: 5| Step: 5
Training loss: 0.07695802301168442
Validation loss: 1.5507404906775362

Epoch: 5| Step: 6
Training loss: 0.03486763313412666
Validation loss: 1.566801924859324

Epoch: 5| Step: 7
Training loss: 0.050586141645908356
Validation loss: 1.582678738460746

Epoch: 5| Step: 8
Training loss: 0.057056449353694916
Validation loss: 1.5867655200342978

Epoch: 5| Step: 9
Training loss: 0.08223631232976913
Validation loss: 1.555610147855615

Epoch: 5| Step: 10
Training loss: 0.09528015553951263
Validation loss: 1.5455480672979867

Epoch: 586| Step: 0
Training loss: 0.06022991985082626
Validation loss: 1.5254436705702095

Epoch: 5| Step: 1
Training loss: 0.0734763965010643
Validation loss: 1.5519259027255479

Epoch: 5| Step: 2
Training loss: 0.06294677406549454
Validation loss: 1.5596777162244242

Epoch: 5| Step: 3
Training loss: 0.04568096622824669
Validation loss: 1.5335963349188528

Epoch: 5| Step: 4
Training loss: 0.055100876837968826
Validation loss: 1.5507715286747101

Epoch: 5| Step: 5
Training loss: 0.09748758375644684
Validation loss: 1.5105024358277679

Epoch: 5| Step: 6
Training loss: 0.1156715378165245
Validation loss: 1.5507729489316222

Epoch: 5| Step: 7
Training loss: 0.07157569378614426
Validation loss: 1.5279882569466867

Epoch: 5| Step: 8
Training loss: 0.08427044004201889
Validation loss: 1.5014141375018704

Epoch: 5| Step: 9
Training loss: 0.0865531787276268
Validation loss: 1.5267246218137844

Epoch: 5| Step: 10
Training loss: 0.07952877879142761
Validation loss: 1.5317873044680523

Epoch: 587| Step: 0
Training loss: 0.04949001967906952
Validation loss: 1.5287635826295423

Epoch: 5| Step: 1
Training loss: 0.07660035789012909
Validation loss: 1.5437263545169626

Epoch: 5| Step: 2
Training loss: 0.12369587272405624
Validation loss: 1.5506953065113356

Epoch: 5| Step: 3
Training loss: 0.053619422018527985
Validation loss: 1.577604611714681

Epoch: 5| Step: 4
Training loss: 0.09678817540407181
Validation loss: 1.5969141247451946

Epoch: 5| Step: 5
Training loss: 0.053114794194698334
Validation loss: 1.5663164225957726

Epoch: 5| Step: 6
Training loss: 0.08291305601596832
Validation loss: 1.5375519106465

Epoch: 5| Step: 7
Training loss: 0.1037478893995285
Validation loss: 1.533444191819878

Epoch: 5| Step: 8
Training loss: 0.06298723071813583
Validation loss: 1.5509749586864183

Epoch: 5| Step: 9
Training loss: 0.07584810256958008
Validation loss: 1.544496194008858

Epoch: 5| Step: 10
Training loss: 0.11485481262207031
Validation loss: 1.532460121698277

Epoch: 588| Step: 0
Training loss: 0.09850679337978363
Validation loss: 1.558267424183507

Epoch: 5| Step: 1
Training loss: 0.058911751955747604
Validation loss: 1.5686126998675767

Epoch: 5| Step: 2
Training loss: 0.1658276617527008
Validation loss: 1.6003694841938634

Epoch: 5| Step: 3
Training loss: 0.1202944964170456
Validation loss: 1.5802894279520998

Epoch: 5| Step: 4
Training loss: 0.053908396512269974
Validation loss: 1.6203716160148702

Epoch: 5| Step: 5
Training loss: 0.05294934660196304
Validation loss: 1.6156963879062283

Epoch: 5| Step: 6
Training loss: 0.07185336202383041
Validation loss: 1.607497638271701

Epoch: 5| Step: 7
Training loss: 0.09616238623857498
Validation loss: 1.5810165110454764

Epoch: 5| Step: 8
Training loss: 0.03942651301622391
Validation loss: 1.5480322120010213

Epoch: 5| Step: 9
Training loss: 0.06545861810445786
Validation loss: 1.5161221604193411

Epoch: 5| Step: 10
Training loss: 0.0971360057592392
Validation loss: 1.5209387630544684

Epoch: 589| Step: 0
Training loss: 0.09504552185535431
Validation loss: 1.5125267838919034

Epoch: 5| Step: 1
Training loss: 0.0786728709936142
Validation loss: 1.5176344507484025

Epoch: 5| Step: 2
Training loss: 0.09813641011714935
Validation loss: 1.5314619278395047

Epoch: 5| Step: 3
Training loss: 0.10277841240167618
Validation loss: 1.548504557660831

Epoch: 5| Step: 4
Training loss: 0.07176338136196136
Validation loss: 1.557682873100363

Epoch: 5| Step: 5
Training loss: 0.09465107321739197
Validation loss: 1.5633575583017

Epoch: 5| Step: 6
Training loss: 0.0662514716386795
Validation loss: 1.550278006061431

Epoch: 5| Step: 7
Training loss: 0.12407586723566055
Validation loss: 1.559952070636134

Epoch: 5| Step: 8
Training loss: 0.09615539014339447
Validation loss: 1.5755947905202066

Epoch: 5| Step: 9
Training loss: 0.05396242067217827
Validation loss: 1.5662927960836759

Epoch: 5| Step: 10
Training loss: 0.07616965472698212
Validation loss: 1.5758305698312738

Epoch: 590| Step: 0
Training loss: 0.10139983892440796
Validation loss: 1.564986522479724

Epoch: 5| Step: 1
Training loss: 0.06184127926826477
Validation loss: 1.5902248608168734

Epoch: 5| Step: 2
Training loss: 0.05948736518621445
Validation loss: 1.6000054767054896

Epoch: 5| Step: 3
Training loss: 0.0626123696565628
Validation loss: 1.5874878155287875

Epoch: 5| Step: 4
Training loss: 0.08096438646316528
Validation loss: 1.5728768046184252

Epoch: 5| Step: 5
Training loss: 0.06541468948125839
Validation loss: 1.592351846797492

Epoch: 5| Step: 6
Training loss: 0.061258308589458466
Validation loss: 1.5870860533047748

Epoch: 5| Step: 7
Training loss: 0.06520260870456696
Validation loss: 1.5669519568002352

Epoch: 5| Step: 8
Training loss: 0.09951770305633545
Validation loss: 1.5416715427111554

Epoch: 5| Step: 9
Training loss: 0.07803726941347122
Validation loss: 1.535898143886238

Epoch: 5| Step: 10
Training loss: 0.10279055684804916
Validation loss: 1.52940619760944

Epoch: 591| Step: 0
Training loss: 0.06480608880519867
Validation loss: 1.519226896506484

Epoch: 5| Step: 1
Training loss: 0.09266021102666855
Validation loss: 1.50017931384425

Epoch: 5| Step: 2
Training loss: 0.07289169728755951
Validation loss: 1.5353411961627264

Epoch: 5| Step: 3
Training loss: 0.06078217178583145
Validation loss: 1.526262697353158

Epoch: 5| Step: 4
Training loss: 0.07604055106639862
Validation loss: 1.5705710675126763

Epoch: 5| Step: 5
Training loss: 0.07813598960638046
Validation loss: 1.5836520323189356

Epoch: 5| Step: 6
Training loss: 0.10415999591350555
Validation loss: 1.5820439054119972

Epoch: 5| Step: 7
Training loss: 0.07773913443088531
Validation loss: 1.5589195220701155

Epoch: 5| Step: 8
Training loss: 0.0809355154633522
Validation loss: 1.5453244986072663

Epoch: 5| Step: 9
Training loss: 0.06995707005262375
Validation loss: 1.5343527370883572

Epoch: 5| Step: 10
Training loss: 0.052871450781822205
Validation loss: 1.5392834217317644

Epoch: 592| Step: 0
Training loss: 0.0591217577457428
Validation loss: 1.54220151388517

Epoch: 5| Step: 1
Training loss: 0.04745561629533768
Validation loss: 1.5286025936885546

Epoch: 5| Step: 2
Training loss: 0.09700445085763931
Validation loss: 1.5100912842699277

Epoch: 5| Step: 3
Training loss: 0.07740069180727005
Validation loss: 1.5342161296516337

Epoch: 5| Step: 4
Training loss: 0.06539753824472427
Validation loss: 1.54261657755862

Epoch: 5| Step: 5
Training loss: 0.04102714732289314
Validation loss: 1.5568648871555124

Epoch: 5| Step: 6
Training loss: 0.05670733377337456
Validation loss: 1.5737955313856884

Epoch: 5| Step: 7
Training loss: 0.05175751447677612
Validation loss: 1.5937588464829229

Epoch: 5| Step: 8
Training loss: 0.05658531188964844
Validation loss: 1.6159709333091654

Epoch: 5| Step: 9
Training loss: 0.10821539163589478
Validation loss: 1.6446950089546941

Epoch: 5| Step: 10
Training loss: 0.07896671444177628
Validation loss: 1.6545108838747906

Epoch: 593| Step: 0
Training loss: 0.0834566056728363
Validation loss: 1.6311484741908249

Epoch: 5| Step: 1
Training loss: 0.052848853170871735
Validation loss: 1.6244932977102136

Epoch: 5| Step: 2
Training loss: 0.08524813503026962
Validation loss: 1.5792742608695902

Epoch: 5| Step: 3
Training loss: 0.055429816246032715
Validation loss: 1.5718295112732918

Epoch: 5| Step: 4
Training loss: 0.10353071987628937
Validation loss: 1.5222471555074055

Epoch: 5| Step: 5
Training loss: 0.0678703561425209
Validation loss: 1.5177342071328113

Epoch: 5| Step: 6
Training loss: 0.08377065509557724
Validation loss: 1.5003955428318312

Epoch: 5| Step: 7
Training loss: 0.07478897273540497
Validation loss: 1.4994995478660829

Epoch: 5| Step: 8
Training loss: 0.06958819925785065
Validation loss: 1.5544604101488668

Epoch: 5| Step: 9
Training loss: 0.052839815616607666
Validation loss: 1.5661088625590007

Epoch: 5| Step: 10
Training loss: 0.0691024661064148
Validation loss: 1.5751638758567073

Epoch: 594| Step: 0
Training loss: 0.1218491941690445
Validation loss: 1.5983008851287186

Epoch: 5| Step: 1
Training loss: 0.06506819278001785
Validation loss: 1.6033129243440525

Epoch: 5| Step: 2
Training loss: 0.07339774072170258
Validation loss: 1.589376139384444

Epoch: 5| Step: 3
Training loss: 0.0539180263876915
Validation loss: 1.5622358642598635

Epoch: 5| Step: 4
Training loss: 0.0715782642364502
Validation loss: 1.5311035584377986

Epoch: 5| Step: 5
Training loss: 0.11958993971347809
Validation loss: 1.5452052970086374

Epoch: 5| Step: 6
Training loss: 0.1500283181667328
Validation loss: 1.500413474216256

Epoch: 5| Step: 7
Training loss: 0.11267378181219101
Validation loss: 1.4867554646666332

Epoch: 5| Step: 8
Training loss: 0.11049910634756088
Validation loss: 1.5116574597615067

Epoch: 5| Step: 9
Training loss: 0.07711020857095718
Validation loss: 1.55467648659983

Epoch: 5| Step: 10
Training loss: 0.09971936792135239
Validation loss: 1.6026390393575032

Epoch: 595| Step: 0
Training loss: 0.125171959400177
Validation loss: 1.6643647442581833

Epoch: 5| Step: 1
Training loss: 0.14760516583919525
Validation loss: 1.671226341237304

Epoch: 5| Step: 2
Training loss: 0.13461410999298096
Validation loss: 1.6648809140728367

Epoch: 5| Step: 3
Training loss: 0.06581613421440125
Validation loss: 1.6069900079440045

Epoch: 5| Step: 4
Training loss: 0.12528035044670105
Validation loss: 1.5671417866983721

Epoch: 5| Step: 5
Training loss: 0.0969012975692749
Validation loss: 1.567863332327976

Epoch: 5| Step: 6
Training loss: 0.09164011478424072
Validation loss: 1.5849003612354238

Epoch: 5| Step: 7
Training loss: 0.1965496987104416
Validation loss: 1.5954701714618231

Epoch: 5| Step: 8
Training loss: 0.06180337071418762
Validation loss: 1.6198692437141173

Epoch: 5| Step: 9
Training loss: 0.06555775552988052
Validation loss: 1.6294101835579

Epoch: 5| Step: 10
Training loss: 0.11185950040817261
Validation loss: 1.6557376384735107

Epoch: 596| Step: 0
Training loss: 0.10673791170120239
Validation loss: 1.6546719022976455

Epoch: 5| Step: 1
Training loss: 0.08067376911640167
Validation loss: 1.6600399555698517

Epoch: 5| Step: 2
Training loss: 0.11251555383205414
Validation loss: 1.6890102650529595

Epoch: 5| Step: 3
Training loss: 0.10205052047967911
Validation loss: 1.6669968199986283

Epoch: 5| Step: 4
Training loss: 0.08548443019390106
Validation loss: 1.6138264543266707

Epoch: 5| Step: 5
Training loss: 0.07775133848190308
Validation loss: 1.587895688190255

Epoch: 5| Step: 6
Training loss: 0.12486325204372406
Validation loss: 1.5561967575421898

Epoch: 5| Step: 7
Training loss: 0.11726081371307373
Validation loss: 1.5700427447595904

Epoch: 5| Step: 8
Training loss: 0.08172480762004852
Validation loss: 1.5440445574381019

Epoch: 5| Step: 9
Training loss: 0.06584606319665909
Validation loss: 1.5589346603680683

Epoch: 5| Step: 10
Training loss: 0.07411219924688339
Validation loss: 1.5745038678569179

Epoch: 597| Step: 0
Training loss: 0.06505531072616577
Validation loss: 1.5891311143034248

Epoch: 5| Step: 1
Training loss: 0.10874804109334946
Validation loss: 1.5890011954051193

Epoch: 5| Step: 2
Training loss: 0.060434263199567795
Validation loss: 1.586765884071268

Epoch: 5| Step: 3
Training loss: 0.10541001707315445
Validation loss: 1.5943648122972058

Epoch: 5| Step: 4
Training loss: 0.05597700923681259
Validation loss: 1.5658827186912618

Epoch: 5| Step: 5
Training loss: 0.039106979966163635
Validation loss: 1.5812343282084311

Epoch: 5| Step: 6
Training loss: 0.06277258694171906
Validation loss: 1.5571464389883063

Epoch: 5| Step: 7
Training loss: 0.05398380756378174
Validation loss: 1.5590996806339552

Epoch: 5| Step: 8
Training loss: 0.06618649512529373
Validation loss: 1.5542640480943906

Epoch: 5| Step: 9
Training loss: 0.12121307849884033
Validation loss: 1.536091725031535

Epoch: 5| Step: 10
Training loss: 0.0710023045539856
Validation loss: 1.557361195164342

Epoch: 598| Step: 0
Training loss: 0.059895552694797516
Validation loss: 1.5542624650462982

Epoch: 5| Step: 1
Training loss: 0.08271163702011108
Validation loss: 1.5653267598921252

Epoch: 5| Step: 2
Training loss: 0.10811547189950943
Validation loss: 1.5729711196755851

Epoch: 5| Step: 3
Training loss: 0.06735401600599289
Validation loss: 1.5836540037585842

Epoch: 5| Step: 4
Training loss: 0.09068210422992706
Validation loss: 1.5565563183958813

Epoch: 5| Step: 5
Training loss: 0.07741038501262665
Validation loss: 1.5626195015445832

Epoch: 5| Step: 6
Training loss: 0.07565483450889587
Validation loss: 1.5794161032604914

Epoch: 5| Step: 7
Training loss: 0.056159526109695435
Validation loss: 1.5649683590858214

Epoch: 5| Step: 8
Training loss: 0.06790407747030258
Validation loss: 1.5309788629572878

Epoch: 5| Step: 9
Training loss: 0.059551797807216644
Validation loss: 1.574475606282552

Epoch: 5| Step: 10
Training loss: 0.10362406075000763
Validation loss: 1.5574647803460397

Epoch: 599| Step: 0
Training loss: 0.07403640449047089
Validation loss: 1.5771211020408138

Epoch: 5| Step: 1
Training loss: 0.10755185037851334
Validation loss: 1.5773863766783027

Epoch: 5| Step: 2
Training loss: 0.05154646188020706
Validation loss: 1.5649278753547258

Epoch: 5| Step: 3
Training loss: 0.07622813433408737
Validation loss: 1.54225064862159

Epoch: 5| Step: 4
Training loss: 0.08361315727233887
Validation loss: 1.5212351276028542

Epoch: 5| Step: 5
Training loss: 0.05085115507245064
Validation loss: 1.5100681999678254

Epoch: 5| Step: 6
Training loss: 0.07939699292182922
Validation loss: 1.4894930162737448

Epoch: 5| Step: 7
Training loss: 0.04964572563767433
Validation loss: 1.492958450830111

Epoch: 5| Step: 8
Training loss: 0.05809719115495682
Validation loss: 1.4828824074037614

Epoch: 5| Step: 9
Training loss: 0.05733302980661392
Validation loss: 1.5020266527770667

Epoch: 5| Step: 10
Training loss: 0.10169222950935364
Validation loss: 1.511977505940263

Epoch: 600| Step: 0
Training loss: 0.051538050174713135
Validation loss: 1.489803127063218

Epoch: 5| Step: 1
Training loss: 0.046428754925727844
Validation loss: 1.5199141758744434

Epoch: 5| Step: 2
Training loss: 0.07418687641620636
Validation loss: 1.5232651361855127

Epoch: 5| Step: 3
Training loss: 0.09668111801147461
Validation loss: 1.560703412179024

Epoch: 5| Step: 4
Training loss: 0.08066041767597198
Validation loss: 1.539717734500926

Epoch: 5| Step: 5
Training loss: 0.07329019904136658
Validation loss: 1.5312391352909867

Epoch: 5| Step: 6
Training loss: 0.08914616703987122
Validation loss: 1.5782434376337195

Epoch: 5| Step: 7
Training loss: 0.05257696658372879
Validation loss: 1.601709975991198

Epoch: 5| Step: 8
Training loss: 0.0715060606598854
Validation loss: 1.5970164409247778

Epoch: 5| Step: 9
Training loss: 0.049247127026319504
Validation loss: 1.5917608763581963

Epoch: 5| Step: 10
Training loss: 0.11631674319505692
Validation loss: 1.605239781000281

Epoch: 601| Step: 0
Training loss: 0.1082163080573082
Validation loss: 1.6253011277926865

Epoch: 5| Step: 1
Training loss: 0.0817413404583931
Validation loss: 1.5691254638856458

Epoch: 5| Step: 2
Training loss: 0.0493539422750473
Validation loss: 1.5918624196001279

Epoch: 5| Step: 3
Training loss: 0.07439199835062027
Validation loss: 1.6194534058211951

Epoch: 5| Step: 4
Training loss: 0.07333874702453613
Validation loss: 1.5787667741057694

Epoch: 5| Step: 5
Training loss: 0.05272170156240463
Validation loss: 1.582063462144585

Epoch: 5| Step: 6
Training loss: 0.0848790779709816
Validation loss: 1.5931110587171329

Epoch: 5| Step: 7
Training loss: 0.03781423717737198
Validation loss: 1.5761842503342578

Epoch: 5| Step: 8
Training loss: 0.0937681570649147
Validation loss: 1.559387896650581

Epoch: 5| Step: 9
Training loss: 0.058624379336833954
Validation loss: 1.5719099583164338

Epoch: 5| Step: 10
Training loss: 0.07717317342758179
Validation loss: 1.5824940204620361

Epoch: 602| Step: 0
Training loss: 0.058143675327301025
Validation loss: 1.561422622332009

Epoch: 5| Step: 1
Training loss: 0.07941941916942596
Validation loss: 1.563559207864987

Epoch: 5| Step: 2
Training loss: 0.055979419499635696
Validation loss: 1.562738092996741

Epoch: 5| Step: 3
Training loss: 0.03454025462269783
Validation loss: 1.556042271275674

Epoch: 5| Step: 4
Training loss: 0.06652136147022247
Validation loss: 1.5616603436008576

Epoch: 5| Step: 5
Training loss: 0.03908059000968933
Validation loss: 1.539493727427657

Epoch: 5| Step: 6
Training loss: 0.049772780388593674
Validation loss: 1.5438691185366722

Epoch: 5| Step: 7
Training loss: 0.06832367181777954
Validation loss: 1.5266641647584978

Epoch: 5| Step: 8
Training loss: 0.06498710811138153
Validation loss: 1.5318035771769862

Epoch: 5| Step: 9
Training loss: 0.04035058617591858
Validation loss: 1.5073923269907634

Epoch: 5| Step: 10
Training loss: 0.08988215029239655
Validation loss: 1.5217825225604478

Epoch: 603| Step: 0
Training loss: 0.09358436614274979
Validation loss: 1.5254659184845545

Epoch: 5| Step: 1
Training loss: 0.052410196512937546
Validation loss: 1.541815209132369

Epoch: 5| Step: 2
Training loss: 0.07193399220705032
Validation loss: 1.5847056796473842

Epoch: 5| Step: 3
Training loss: 0.06802423298358917
Validation loss: 1.6035774805212533

Epoch: 5| Step: 4
Training loss: 0.07646548002958298
Validation loss: 1.6187152798457811

Epoch: 5| Step: 5
Training loss: 0.0743216723203659
Validation loss: 1.5902846987529466

Epoch: 5| Step: 6
Training loss: 0.060192979872226715
Validation loss: 1.568891849569095

Epoch: 5| Step: 7
Training loss: 0.03992136940360069
Validation loss: 1.5549243765492593

Epoch: 5| Step: 8
Training loss: 0.10521300137042999
Validation loss: 1.554563981230541

Epoch: 5| Step: 9
Training loss: 0.0667809322476387
Validation loss: 1.5425236314855597

Epoch: 5| Step: 10
Training loss: 0.08498365432024002
Validation loss: 1.5539461579374088

Epoch: 604| Step: 0
Training loss: 0.04786334186792374
Validation loss: 1.5531977979085778

Epoch: 5| Step: 1
Training loss: 0.06634096056222916
Validation loss: 1.5725805823520949

Epoch: 5| Step: 2
Training loss: 0.09127793461084366
Validation loss: 1.569378178606751

Epoch: 5| Step: 3
Training loss: 0.09193291515111923
Validation loss: 1.5784855606735393

Epoch: 5| Step: 4
Training loss: 0.07417725026607513
Validation loss: 1.5876514860378799

Epoch: 5| Step: 5
Training loss: 0.05661667138338089
Validation loss: 1.6033774819425357

Epoch: 5| Step: 6
Training loss: 0.07909588515758514
Validation loss: 1.6078631788171747

Epoch: 5| Step: 7
Training loss: 0.07156213372945786
Validation loss: 1.6212772823149157

Epoch: 5| Step: 8
Training loss: 0.06752769649028778
Validation loss: 1.5930215466407038

Epoch: 5| Step: 9
Training loss: 0.0727880448102951
Validation loss: 1.6155319700958908

Epoch: 5| Step: 10
Training loss: 0.04586614668369293
Validation loss: 1.6156510576125114

Epoch: 605| Step: 0
Training loss: 0.05310242250561714
Validation loss: 1.585813913294064

Epoch: 5| Step: 1
Training loss: 0.05680878087878227
Validation loss: 1.5669601322502218

Epoch: 5| Step: 2
Training loss: 0.04793480038642883
Validation loss: 1.558490366064092

Epoch: 5| Step: 3
Training loss: 0.06390471756458282
Validation loss: 1.5601840839591077

Epoch: 5| Step: 4
Training loss: 0.06891590356826782
Validation loss: 1.5575129242353543

Epoch: 5| Step: 5
Training loss: 0.03908753767609596
Validation loss: 1.5555718124553721

Epoch: 5| Step: 6
Training loss: 0.09680725634098053
Validation loss: 1.5803580046981893

Epoch: 5| Step: 7
Training loss: 0.13745705783367157
Validation loss: 1.56352654451965

Epoch: 5| Step: 8
Training loss: 0.06869558990001678
Validation loss: 1.5444553846954017

Epoch: 5| Step: 9
Training loss: 0.11231987178325653
Validation loss: 1.559538023446196

Epoch: 5| Step: 10
Training loss: 0.1301855742931366
Validation loss: 1.5404391134938886

Epoch: 606| Step: 0
Training loss: 0.0966557115316391
Validation loss: 1.504770992904581

Epoch: 5| Step: 1
Training loss: 0.06782270222902298
Validation loss: 1.5119899806155954

Epoch: 5| Step: 2
Training loss: 0.06882965564727783
Validation loss: 1.5227949606475009

Epoch: 5| Step: 3
Training loss: 0.12104890495538712
Validation loss: 1.5319700100088631

Epoch: 5| Step: 4
Training loss: 0.09063464403152466
Validation loss: 1.5392321014917025

Epoch: 5| Step: 5
Training loss: 0.0830191969871521
Validation loss: 1.5720596672386251

Epoch: 5| Step: 6
Training loss: 0.0742959976196289
Validation loss: 1.6109632862511503

Epoch: 5| Step: 7
Training loss: 0.08985263109207153
Validation loss: 1.622422468277716

Epoch: 5| Step: 8
Training loss: 0.10163307189941406
Validation loss: 1.625953310279436

Epoch: 5| Step: 9
Training loss: 0.058262865990400314
Validation loss: 1.5842263429395613

Epoch: 5| Step: 10
Training loss: 0.08182889223098755
Validation loss: 1.5990537879287556

Epoch: 607| Step: 0
Training loss: 0.06419353187084198
Validation loss: 1.5604712719558387

Epoch: 5| Step: 1
Training loss: 0.077171191573143
Validation loss: 1.5641730446969309

Epoch: 5| Step: 2
Training loss: 0.08065357059240341
Validation loss: 1.5644052874657415

Epoch: 5| Step: 3
Training loss: 0.05550265312194824
Validation loss: 1.5718007754254084

Epoch: 5| Step: 4
Training loss: 0.06179656460881233
Validation loss: 1.5642012178256948

Epoch: 5| Step: 5
Training loss: 0.0549616739153862
Validation loss: 1.5904732775944534

Epoch: 5| Step: 6
Training loss: 0.041771382093429565
Validation loss: 1.549528165530133

Epoch: 5| Step: 7
Training loss: 0.09195486456155777
Validation loss: 1.5693253586369176

Epoch: 5| Step: 8
Training loss: 0.053232431411743164
Validation loss: 1.5681873367678734

Epoch: 5| Step: 9
Training loss: 0.0747523158788681
Validation loss: 1.5639056249331402

Epoch: 5| Step: 10
Training loss: 0.06147569790482521
Validation loss: 1.561042248561818

Epoch: 608| Step: 0
Training loss: 0.06636776775121689
Validation loss: 1.5586000809105494

Epoch: 5| Step: 1
Training loss: 0.05596199631690979
Validation loss: 1.5788473903491933

Epoch: 5| Step: 2
Training loss: 0.04443876072764397
Validation loss: 1.5680081357238114

Epoch: 5| Step: 3
Training loss: 0.058310698717832565
Validation loss: 1.6005958446892359

Epoch: 5| Step: 4
Training loss: 0.06512451171875
Validation loss: 1.5579287743055692

Epoch: 5| Step: 5
Training loss: 0.08182963728904724
Validation loss: 1.5679815264158352

Epoch: 5| Step: 6
Training loss: 0.06608517467975616
Validation loss: 1.563437081152393

Epoch: 5| Step: 7
Training loss: 0.11470375210046768
Validation loss: 1.5485800389320619

Epoch: 5| Step: 8
Training loss: 0.07377910614013672
Validation loss: 1.5507456525679557

Epoch: 5| Step: 9
Training loss: 0.05633195489645004
Validation loss: 1.5312291294015863

Epoch: 5| Step: 10
Training loss: 0.048387560993433
Validation loss: 1.5151860521685692

Epoch: 609| Step: 0
Training loss: 0.04646977409720421
Validation loss: 1.5298795238617928

Epoch: 5| Step: 1
Training loss: 0.05478353425860405
Validation loss: 1.523391290377545

Epoch: 5| Step: 2
Training loss: 0.07530692219734192
Validation loss: 1.5022006880852483

Epoch: 5| Step: 3
Training loss: 0.07400571554899216
Validation loss: 1.5287176332166117

Epoch: 5| Step: 4
Training loss: 0.05559948831796646
Validation loss: 1.5126688582922823

Epoch: 5| Step: 5
Training loss: 0.05526240915060043
Validation loss: 1.543239067318619

Epoch: 5| Step: 6
Training loss: 0.05388191342353821
Validation loss: 1.53950245277856

Epoch: 5| Step: 7
Training loss: 0.05117877200245857
Validation loss: 1.5282825705825642

Epoch: 5| Step: 8
Training loss: 0.10392079502344131
Validation loss: 1.5243537272176435

Epoch: 5| Step: 9
Training loss: 0.051522500813007355
Validation loss: 1.5459988014672392

Epoch: 5| Step: 10
Training loss: 0.06368750333786011
Validation loss: 1.5208412665192799

Epoch: 610| Step: 0
Training loss: 0.0712757483124733
Validation loss: 1.5054303433305474

Epoch: 5| Step: 1
Training loss: 0.05467679351568222
Validation loss: 1.5498060026476461

Epoch: 5| Step: 2
Training loss: 0.05162521079182625
Validation loss: 1.5437064068291777

Epoch: 5| Step: 3
Training loss: 0.07832882553339005
Validation loss: 1.5774339052938646

Epoch: 5| Step: 4
Training loss: 0.058087460696697235
Validation loss: 1.5353811915202806

Epoch: 5| Step: 5
Training loss: 0.07868313044309616
Validation loss: 1.5391538450794835

Epoch: 5| Step: 6
Training loss: 0.05268231779336929
Validation loss: 1.5142577220034856

Epoch: 5| Step: 7
Training loss: 0.12200961261987686
Validation loss: 1.5308681482909827

Epoch: 5| Step: 8
Training loss: 0.07103442400693893
Validation loss: 1.5287621803181146

Epoch: 5| Step: 9
Training loss: 0.10189685970544815
Validation loss: 1.5394172412092968

Epoch: 5| Step: 10
Training loss: 0.06531816720962524
Validation loss: 1.5030057378994521

Epoch: 611| Step: 0
Training loss: 0.07339651882648468
Validation loss: 1.5317674093349005

Epoch: 5| Step: 1
Training loss: 0.08523169904947281
Validation loss: 1.5330000115979103

Epoch: 5| Step: 2
Training loss: 0.061867646872997284
Validation loss: 1.5534264336350143

Epoch: 5| Step: 3
Training loss: 0.03576191887259483
Validation loss: 1.5208009308384312

Epoch: 5| Step: 4
Training loss: 0.07002755254507065
Validation loss: 1.5638652693840764

Epoch: 5| Step: 5
Training loss: 0.03659839183092117
Validation loss: 1.5774255952527445

Epoch: 5| Step: 6
Training loss: 0.056496284902095795
Validation loss: 1.5699544273396975

Epoch: 5| Step: 7
Training loss: 0.06082364171743393
Validation loss: 1.5855173551908104

Epoch: 5| Step: 8
Training loss: 0.08045996725559235
Validation loss: 1.577243980541024

Epoch: 5| Step: 9
Training loss: 0.030069846659898758
Validation loss: 1.572258278887759

Epoch: 5| Step: 10
Training loss: 0.05737149715423584
Validation loss: 1.5674483122364167

Epoch: 612| Step: 0
Training loss: 0.05704760551452637
Validation loss: 1.5676190096844909

Epoch: 5| Step: 1
Training loss: 0.06803761422634125
Validation loss: 1.5407746197074972

Epoch: 5| Step: 2
Training loss: 0.06017286330461502
Validation loss: 1.5600738192117343

Epoch: 5| Step: 3
Training loss: 0.05140947550535202
Validation loss: 1.5374570585066272

Epoch: 5| Step: 4
Training loss: 0.08988232910633087
Validation loss: 1.554542237712491

Epoch: 5| Step: 5
Training loss: 0.08220180124044418
Validation loss: 1.5529031163902693

Epoch: 5| Step: 6
Training loss: 0.07163135707378387
Validation loss: 1.5600145247674757

Epoch: 5| Step: 7
Training loss: 0.05898066237568855
Validation loss: 1.5859033317976101

Epoch: 5| Step: 8
Training loss: 0.0665278211236
Validation loss: 1.5531116493286625

Epoch: 5| Step: 9
Training loss: 0.041850894689559937
Validation loss: 1.5387990090154833

Epoch: 5| Step: 10
Training loss: 0.0906665176153183
Validation loss: 1.5581001094592515

Epoch: 613| Step: 0
Training loss: 0.07837937772274017
Validation loss: 1.5486656337656

Epoch: 5| Step: 1
Training loss: 0.079039566218853
Validation loss: 1.5717933947040188

Epoch: 5| Step: 2
Training loss: 0.07193007320165634
Validation loss: 1.562364629519883

Epoch: 5| Step: 3
Training loss: 0.04094488546252251
Validation loss: 1.5756541631555046

Epoch: 5| Step: 4
Training loss: 0.04566029831767082
Validation loss: 1.5725303670411468

Epoch: 5| Step: 5
Training loss: 0.05556046962738037
Validation loss: 1.5711173575411561

Epoch: 5| Step: 6
Training loss: 0.06801830232143402
Validation loss: 1.568169943747982

Epoch: 5| Step: 7
Training loss: 0.05384046956896782
Validation loss: 1.5608466902086813

Epoch: 5| Step: 8
Training loss: 0.05627923458814621
Validation loss: 1.5586404851687852

Epoch: 5| Step: 9
Training loss: 0.08258120715618134
Validation loss: 1.5592359958156463

Epoch: 5| Step: 10
Training loss: 0.05738306790590286
Validation loss: 1.558078122395341

Epoch: 614| Step: 0
Training loss: 0.04543112590909004
Validation loss: 1.5792631321055914

Epoch: 5| Step: 1
Training loss: 0.09868905693292618
Validation loss: 1.584892669031697

Epoch: 5| Step: 2
Training loss: 0.05523756891489029
Validation loss: 1.5864175186362317

Epoch: 5| Step: 3
Training loss: 0.05254014581441879
Validation loss: 1.5868449211120605

Epoch: 5| Step: 4
Training loss: 0.03192681446671486
Validation loss: 1.575110553413309

Epoch: 5| Step: 5
Training loss: 0.05163050815463066
Validation loss: 1.5970178227270804

Epoch: 5| Step: 6
Training loss: 0.0745098665356636
Validation loss: 1.5865843206323602

Epoch: 5| Step: 7
Training loss: 0.050590574741363525
Validation loss: 1.5790036468095676

Epoch: 5| Step: 8
Training loss: 0.0675296038389206
Validation loss: 1.572818281829998

Epoch: 5| Step: 9
Training loss: 0.05394391342997551
Validation loss: 1.5958896683108421

Epoch: 5| Step: 10
Training loss: 0.0813174694776535
Validation loss: 1.606830907124345

Epoch: 615| Step: 0
Training loss: 0.09071938693523407
Validation loss: 1.6230817699945101

Epoch: 5| Step: 1
Training loss: 0.08140338957309723
Validation loss: 1.6193814918559084

Epoch: 5| Step: 2
Training loss: 0.07325557619333267
Validation loss: 1.61735450965102

Epoch: 5| Step: 3
Training loss: 0.08139012008905411
Validation loss: 1.6118409428545224

Epoch: 5| Step: 4
Training loss: 0.05931231379508972
Validation loss: 1.6058254818762503

Epoch: 5| Step: 5
Training loss: 0.07894368469715118
Validation loss: 1.5907346458845242

Epoch: 5| Step: 6
Training loss: 0.06362170726060867
Validation loss: 1.602396043398047

Epoch: 5| Step: 7
Training loss: 0.08321832865476608
Validation loss: 1.5820554456403177

Epoch: 5| Step: 8
Training loss: 0.06467242538928986
Validation loss: 1.5711393740869337

Epoch: 5| Step: 9
Training loss: 0.06962201744318008
Validation loss: 1.5731989760552683

Epoch: 5| Step: 10
Training loss: 0.06490478664636612
Validation loss: 1.5651771368518952

Epoch: 616| Step: 0
Training loss: 0.059758275747299194
Validation loss: 1.559075104293003

Epoch: 5| Step: 1
Training loss: 0.05458163470029831
Validation loss: 1.5853067591626158

Epoch: 5| Step: 2
Training loss: 0.04810703545808792
Validation loss: 1.574857884837735

Epoch: 5| Step: 3
Training loss: 0.06232551485300064
Validation loss: 1.607835892708071

Epoch: 5| Step: 4
Training loss: 0.10010342299938202
Validation loss: 1.623048549057335

Epoch: 5| Step: 5
Training loss: 0.06638394296169281
Validation loss: 1.5749680214030768

Epoch: 5| Step: 6
Training loss: 0.07647693157196045
Validation loss: 1.5502110610726059

Epoch: 5| Step: 7
Training loss: 0.06036607176065445
Validation loss: 1.5507668705396755

Epoch: 5| Step: 8
Training loss: 0.06111512333154678
Validation loss: 1.5074530250282698

Epoch: 5| Step: 9
Training loss: 0.07669142633676529
Validation loss: 1.530353683297352

Epoch: 5| Step: 10
Training loss: 0.10961025953292847
Validation loss: 1.5047391896606774

Epoch: 617| Step: 0
Training loss: 0.05325691029429436
Validation loss: 1.5052415068431566

Epoch: 5| Step: 1
Training loss: 0.07611316442489624
Validation loss: 1.509889610992965

Epoch: 5| Step: 2
Training loss: 0.044619761407375336
Validation loss: 1.5340715198106663

Epoch: 5| Step: 3
Training loss: 0.03570617362856865
Validation loss: 1.5671272688014533

Epoch: 5| Step: 4
Training loss: 0.05245555564761162
Validation loss: 1.587018823110929

Epoch: 5| Step: 5
Training loss: 0.07006020098924637
Validation loss: 1.5815422637488252

Epoch: 5| Step: 6
Training loss: 0.05977750942111015
Validation loss: 1.5978384979309574

Epoch: 5| Step: 7
Training loss: 0.06017090007662773
Validation loss: 1.6007648975618425

Epoch: 5| Step: 8
Training loss: 0.055549681186676025
Validation loss: 1.5903004074609408

Epoch: 5| Step: 9
Training loss: 0.05355255678296089
Validation loss: 1.5725929608909033

Epoch: 5| Step: 10
Training loss: 0.07122070342302322
Validation loss: 1.5907144559326993

Epoch: 618| Step: 0
Training loss: 0.05090830475091934
Validation loss: 1.5848137204365065

Epoch: 5| Step: 1
Training loss: 0.04022521525621414
Validation loss: 1.5736194900287095

Epoch: 5| Step: 2
Training loss: 0.09311497211456299
Validation loss: 1.5842277234600437

Epoch: 5| Step: 3
Training loss: 0.04666983336210251
Validation loss: 1.5730252919658538

Epoch: 5| Step: 4
Training loss: 0.06372740864753723
Validation loss: 1.579544214792149

Epoch: 5| Step: 5
Training loss: 0.07874130457639694
Validation loss: 1.5469420404844387

Epoch: 5| Step: 6
Training loss: 0.056604426354169846
Validation loss: 1.569918946553302

Epoch: 5| Step: 7
Training loss: 0.05646154284477234
Validation loss: 1.5273174752471268

Epoch: 5| Step: 8
Training loss: 0.048573147505521774
Validation loss: 1.5434011810569352

Epoch: 5| Step: 9
Training loss: 0.07910982519388199
Validation loss: 1.5264806914073166

Epoch: 5| Step: 10
Training loss: 0.032721664756536484
Validation loss: 1.5545074875636766

Epoch: 619| Step: 0
Training loss: 0.07993186265230179
Validation loss: 1.537690785623366

Epoch: 5| Step: 1
Training loss: 0.0617549791932106
Validation loss: 1.5484177604798348

Epoch: 5| Step: 2
Training loss: 0.06042579934000969
Validation loss: 1.5307243626604798

Epoch: 5| Step: 3
Training loss: 0.054443128407001495
Validation loss: 1.543905000532827

Epoch: 5| Step: 4
Training loss: 0.05002612620592117
Validation loss: 1.5464222405546455

Epoch: 5| Step: 5
Training loss: 0.05461801961064339
Validation loss: 1.5602999656431136

Epoch: 5| Step: 6
Training loss: 0.06755390763282776
Validation loss: 1.5483008456486527

Epoch: 5| Step: 7
Training loss: 0.07624363154172897
Validation loss: 1.5675361271827453

Epoch: 5| Step: 8
Training loss: 0.04823904111981392
Validation loss: 1.5590709140223842

Epoch: 5| Step: 9
Training loss: 0.05970786139369011
Validation loss: 1.5403224524631296

Epoch: 5| Step: 10
Training loss: 0.04701310768723488
Validation loss: 1.570915925887323

Epoch: 620| Step: 0
Training loss: 0.0751526802778244
Validation loss: 1.5615488675332838

Epoch: 5| Step: 1
Training loss: 0.05073115974664688
Validation loss: 1.5392709624382757

Epoch: 5| Step: 2
Training loss: 0.07628940045833588
Validation loss: 1.5289721629952873

Epoch: 5| Step: 3
Training loss: 0.054925281554460526
Validation loss: 1.5565990696671188

Epoch: 5| Step: 4
Training loss: 0.051932383328676224
Validation loss: 1.5545679247507485

Epoch: 5| Step: 5
Training loss: 0.09302381426095963
Validation loss: 1.5789137437779417

Epoch: 5| Step: 6
Training loss: 0.06991741806268692
Validation loss: 1.6145355983447003

Epoch: 5| Step: 7
Training loss: 0.08427178114652634
Validation loss: 1.6276875426692348

Epoch: 5| Step: 8
Training loss: 0.08002883940935135
Validation loss: 1.6153153488712926

Epoch: 5| Step: 9
Training loss: 0.05840400606393814
Validation loss: 1.5961073047371321

Epoch: 5| Step: 10
Training loss: 0.08756624907255173
Validation loss: 1.6178798329445623

Epoch: 621| Step: 0
Training loss: 0.05197504162788391
Validation loss: 1.578419062399095

Epoch: 5| Step: 1
Training loss: 0.06029777601361275
Validation loss: 1.5828221074996456

Epoch: 5| Step: 2
Training loss: 0.09289926290512085
Validation loss: 1.5812824400522376

Epoch: 5| Step: 3
Training loss: 0.05549678951501846
Validation loss: 1.575362607996951

Epoch: 5| Step: 4
Training loss: 0.06652550399303436
Validation loss: 1.5991563566269413

Epoch: 5| Step: 5
Training loss: 0.07420045137405396
Validation loss: 1.6007619852660804

Epoch: 5| Step: 6
Training loss: 0.0790087878704071
Validation loss: 1.5782689907217538

Epoch: 5| Step: 7
Training loss: 0.038777440786361694
Validation loss: 1.6137995335363573

Epoch: 5| Step: 8
Training loss: 0.06569062918424606
Validation loss: 1.6045420477467198

Epoch: 5| Step: 9
Training loss: 0.05796012282371521
Validation loss: 1.6091732389183455

Epoch: 5| Step: 10
Training loss: 0.055932626128196716
Validation loss: 1.5963301709903184

Epoch: 622| Step: 0
Training loss: 0.054254621267318726
Validation loss: 1.6022205288692186

Epoch: 5| Step: 1
Training loss: 0.06345436722040176
Validation loss: 1.6142056629221926

Epoch: 5| Step: 2
Training loss: 0.0566784143447876
Validation loss: 1.5842584499748804

Epoch: 5| Step: 3
Training loss: 0.060384731739759445
Validation loss: 1.592568374449207

Epoch: 5| Step: 4
Training loss: 0.058629147708415985
Validation loss: 1.573031497258012

Epoch: 5| Step: 5
Training loss: 0.05892134830355644
Validation loss: 1.577202070143915

Epoch: 5| Step: 6
Training loss: 0.06528936326503754
Validation loss: 1.5556096261547459

Epoch: 5| Step: 7
Training loss: 0.06515529751777649
Validation loss: 1.5427759475605463

Epoch: 5| Step: 8
Training loss: 0.05941108986735344
Validation loss: 1.5288087988412509

Epoch: 5| Step: 9
Training loss: 0.1184486374258995
Validation loss: 1.5383273555386452

Epoch: 5| Step: 10
Training loss: 0.04689573496580124
Validation loss: 1.5667113437447497

Epoch: 623| Step: 0
Training loss: 0.03794416785240173
Validation loss: 1.557502656854609

Epoch: 5| Step: 1
Training loss: 0.06433683633804321
Validation loss: 1.5541587593734905

Epoch: 5| Step: 2
Training loss: 0.07584867626428604
Validation loss: 1.5443584175520046

Epoch: 5| Step: 3
Training loss: 0.06477663666009903
Validation loss: 1.5452230912382885

Epoch: 5| Step: 4
Training loss: 0.07414378225803375
Validation loss: 1.5458765158089258

Epoch: 5| Step: 5
Training loss: 0.09246771782636642
Validation loss: 1.5574101953096287

Epoch: 5| Step: 6
Training loss: 0.09312935173511505
Validation loss: 1.5527054417517878

Epoch: 5| Step: 7
Training loss: 0.10453017801046371
Validation loss: 1.5756314992904663

Epoch: 5| Step: 8
Training loss: 0.07472550868988037
Validation loss: 1.6104250210587696

Epoch: 5| Step: 9
Training loss: 0.066721111536026
Validation loss: 1.6261960332111647

Epoch: 5| Step: 10
Training loss: 0.036019980907440186
Validation loss: 1.6199456517414381

Epoch: 624| Step: 0
Training loss: 0.0404171496629715
Validation loss: 1.6226797014154413

Epoch: 5| Step: 1
Training loss: 0.05321269482374191
Validation loss: 1.6310943800915954

Epoch: 5| Step: 2
Training loss: 0.06588222831487656
Validation loss: 1.6279138916282243

Epoch: 5| Step: 3
Training loss: 0.06310474127531052
Validation loss: 1.6302347157591133

Epoch: 5| Step: 4
Training loss: 0.045411981642246246
Validation loss: 1.6172664332133468

Epoch: 5| Step: 5
Training loss: 0.0657300129532814
Validation loss: 1.6064677405100998

Epoch: 5| Step: 6
Training loss: 0.07598121464252472
Validation loss: 1.589767918791822

Epoch: 5| Step: 7
Training loss: 0.06491009891033173
Validation loss: 1.6019975216157976

Epoch: 5| Step: 8
Training loss: 0.07888499647378922
Validation loss: 1.5948356620727047

Epoch: 5| Step: 9
Training loss: 0.062367986887693405
Validation loss: 1.5964221569799608

Epoch: 5| Step: 10
Training loss: 0.06395839899778366
Validation loss: 1.5697369190954393

Epoch: 625| Step: 0
Training loss: 0.04404231905937195
Validation loss: 1.5650069021409558

Epoch: 5| Step: 1
Training loss: 0.09623827040195465
Validation loss: 1.585981131881796

Epoch: 5| Step: 2
Training loss: 0.09363086521625519
Validation loss: 1.5676581551951747

Epoch: 5| Step: 3
Training loss: 0.04916074872016907
Validation loss: 1.5611257360827537

Epoch: 5| Step: 4
Training loss: 0.06647753715515137
Validation loss: 1.5344946012702039

Epoch: 5| Step: 5
Training loss: 0.08415064960718155
Validation loss: 1.5373627895949988

Epoch: 5| Step: 6
Training loss: 0.05711526796221733
Validation loss: 1.533320851223443

Epoch: 5| Step: 7
Training loss: 0.05750007554888725
Validation loss: 1.538059671719869

Epoch: 5| Step: 8
Training loss: 0.05581969767808914
Validation loss: 1.5234884529985406

Epoch: 5| Step: 9
Training loss: 0.08581290394067764
Validation loss: 1.5550284411317559

Epoch: 5| Step: 10
Training loss: 0.06853920221328735
Validation loss: 1.562989680997787

Epoch: 626| Step: 0
Training loss: 0.044997137039899826
Validation loss: 1.5789412138282612

Epoch: 5| Step: 1
Training loss: 0.04594847559928894
Validation loss: 1.580090989348709

Epoch: 5| Step: 2
Training loss: 0.06225693225860596
Validation loss: 1.6013666763100574

Epoch: 5| Step: 3
Training loss: 0.04664699360728264
Validation loss: 1.5773594328152236

Epoch: 5| Step: 4
Training loss: 0.06945989280939102
Validation loss: 1.5782330330982004

Epoch: 5| Step: 5
Training loss: 0.1022757738828659
Validation loss: 1.5827331004604217

Epoch: 5| Step: 6
Training loss: 0.03586168214678764
Validation loss: 1.551992485600133

Epoch: 5| Step: 7
Training loss: 0.07653118669986725
Validation loss: 1.5462017674599924

Epoch: 5| Step: 8
Training loss: 0.044847287237644196
Validation loss: 1.5372987113973147

Epoch: 5| Step: 9
Training loss: 0.04323757439851761
Validation loss: 1.524511045025241

Epoch: 5| Step: 10
Training loss: 0.06870473176240921
Validation loss: 1.5381223988789383

Epoch: 627| Step: 0
Training loss: 0.06332695484161377
Validation loss: 1.5553872444296395

Epoch: 5| Step: 1
Training loss: 0.08048681169748306
Validation loss: 1.5616218287457702

Epoch: 5| Step: 2
Training loss: 0.09559297561645508
Validation loss: 1.550379813358348

Epoch: 5| Step: 3
Training loss: 0.0583312101662159
Validation loss: 1.5507405419503488

Epoch: 5| Step: 4
Training loss: 0.046075619757175446
Validation loss: 1.591397923807944

Epoch: 5| Step: 5
Training loss: 0.05484546348452568
Validation loss: 1.5854902985275432

Epoch: 5| Step: 6
Training loss: 0.06683636456727982
Validation loss: 1.5739664851978261

Epoch: 5| Step: 7
Training loss: 0.06451676785945892
Validation loss: 1.5700023597286594

Epoch: 5| Step: 8
Training loss: 0.06860313564538956
Validation loss: 1.567516827455131

Epoch: 5| Step: 9
Training loss: 0.0399162694811821
Validation loss: 1.542248091390056

Epoch: 5| Step: 10
Training loss: 0.05405765026807785
Validation loss: 1.5420942780792073

Epoch: 628| Step: 0
Training loss: 0.04206332191824913
Validation loss: 1.5000429486715665

Epoch: 5| Step: 1
Training loss: 0.040603604167699814
Validation loss: 1.5453724476598925

Epoch: 5| Step: 2
Training loss: 0.07534796744585037
Validation loss: 1.5508848620999245

Epoch: 5| Step: 3
Training loss: 0.039776138961315155
Validation loss: 1.5444722367871193

Epoch: 5| Step: 4
Training loss: 0.061124276369810104
Validation loss: 1.5549545185540312

Epoch: 5| Step: 5
Training loss: 0.07678432017564774
Validation loss: 1.5676755289877615

Epoch: 5| Step: 6
Training loss: 0.042146969586610794
Validation loss: 1.5758822528264855

Epoch: 5| Step: 7
Training loss: 0.05683140084147453
Validation loss: 1.5805070143873974

Epoch: 5| Step: 8
Training loss: 0.09710730612277985
Validation loss: 1.5733267017590102

Epoch: 5| Step: 9
Training loss: 0.04633324593305588
Validation loss: 1.5655906405500186

Epoch: 5| Step: 10
Training loss: 0.0569126158952713
Validation loss: 1.566163852650632

Epoch: 629| Step: 0
Training loss: 0.08253221213817596
Validation loss: 1.563345479708846

Epoch: 5| Step: 1
Training loss: 0.07563921064138412
Validation loss: 1.5412641718823423

Epoch: 5| Step: 2
Training loss: 0.08115468174219131
Validation loss: 1.53992594698424

Epoch: 5| Step: 3
Training loss: 0.06643950939178467
Validation loss: 1.5341230310419554

Epoch: 5| Step: 4
Training loss: 0.04168655723333359
Validation loss: 1.549082640678652

Epoch: 5| Step: 5
Training loss: 0.05809655040502548
Validation loss: 1.5586795627429921

Epoch: 5| Step: 6
Training loss: 0.04460354149341583
Validation loss: 1.571178231188046

Epoch: 5| Step: 7
Training loss: 0.0312102772295475
Validation loss: 1.5922263001882901

Epoch: 5| Step: 8
Training loss: 0.049077898263931274
Validation loss: 1.5942157814579625

Epoch: 5| Step: 9
Training loss: 0.08213865756988525
Validation loss: 1.603645881017049

Epoch: 5| Step: 10
Training loss: 0.0618862621486187
Validation loss: 1.5851234479617047

Epoch: 630| Step: 0
Training loss: 0.04491099342703819
Validation loss: 1.5830856587297173

Epoch: 5| Step: 1
Training loss: 0.05217234045267105
Validation loss: 1.5643958724955076

Epoch: 5| Step: 2
Training loss: 0.038854923099279404
Validation loss: 1.5755176025052224

Epoch: 5| Step: 3
Training loss: 0.09067384898662567
Validation loss: 1.539950534861575

Epoch: 5| Step: 4
Training loss: 0.045635201036930084
Validation loss: 1.5622041045978505

Epoch: 5| Step: 5
Training loss: 0.06516049802303314
Validation loss: 1.531017126575593

Epoch: 5| Step: 6
Training loss: 0.051196299493312836
Validation loss: 1.5308488479224585

Epoch: 5| Step: 7
Training loss: 0.11089922487735748
Validation loss: 1.562100464297879

Epoch: 5| Step: 8
Training loss: 0.06525380909442902
Validation loss: 1.5716662753012873

Epoch: 5| Step: 9
Training loss: 0.049794457852840424
Validation loss: 1.5825974364434519

Epoch: 5| Step: 10
Training loss: 0.08389779180288315
Validation loss: 1.6194888263620355

Epoch: 631| Step: 0
Training loss: 0.04915997013449669
Validation loss: 1.5964632418847853

Epoch: 5| Step: 1
Training loss: 0.03756168484687805
Validation loss: 1.6116781080922773

Epoch: 5| Step: 2
Training loss: 0.07787498086690903
Validation loss: 1.583210991274926

Epoch: 5| Step: 3
Training loss: 0.07681657373905182
Validation loss: 1.5926474037990774

Epoch: 5| Step: 4
Training loss: 0.06142054870724678
Validation loss: 1.5756335284120293

Epoch: 5| Step: 5
Training loss: 0.052581243216991425
Validation loss: 1.5620893791157713

Epoch: 5| Step: 6
Training loss: 0.04899925738573074
Validation loss: 1.5731071079930952

Epoch: 5| Step: 7
Training loss: 0.038892824202775955
Validation loss: 1.5636888883447135

Epoch: 5| Step: 8
Training loss: 0.07075546681880951
Validation loss: 1.5533143397300475

Epoch: 5| Step: 9
Training loss: 0.06310533732175827
Validation loss: 1.5424800342129124

Epoch: 5| Step: 10
Training loss: 0.06445889919996262
Validation loss: 1.5718776884899344

Epoch: 632| Step: 0
Training loss: 0.0712379664182663
Validation loss: 1.557447523840012

Epoch: 5| Step: 1
Training loss: 0.04040040075778961
Validation loss: 1.5914114585486792

Epoch: 5| Step: 2
Training loss: 0.05655156448483467
Validation loss: 1.546723674702388

Epoch: 5| Step: 3
Training loss: 0.06903042644262314
Validation loss: 1.5764574248303649

Epoch: 5| Step: 4
Training loss: 0.03408392146229744
Validation loss: 1.592713189381425

Epoch: 5| Step: 5
Training loss: 0.08274148404598236
Validation loss: 1.6195530186417282

Epoch: 5| Step: 6
Training loss: 0.07315637171268463
Validation loss: 1.6178664936814258

Epoch: 5| Step: 7
Training loss: 0.07867814600467682
Validation loss: 1.5859811754636868

Epoch: 5| Step: 8
Training loss: 0.06674966961145401
Validation loss: 1.614242152501178

Epoch: 5| Step: 9
Training loss: 0.08189409971237183
Validation loss: 1.5975486514388875

Epoch: 5| Step: 10
Training loss: 0.08744555711746216
Validation loss: 1.5943901551667081

Epoch: 633| Step: 0
Training loss: 0.08382818102836609
Validation loss: 1.5876001478523336

Epoch: 5| Step: 1
Training loss: 0.04357633367180824
Validation loss: 1.5558361737958846

Epoch: 5| Step: 2
Training loss: 0.0635354146361351
Validation loss: 1.5406266591882194

Epoch: 5| Step: 3
Training loss: 0.10713402926921844
Validation loss: 1.5353921100657473

Epoch: 5| Step: 4
Training loss: 0.06996332854032516
Validation loss: 1.5378679152457946

Epoch: 5| Step: 5
Training loss: 0.08009922504425049
Validation loss: 1.5428712239829443

Epoch: 5| Step: 6
Training loss: 0.0714828372001648
Validation loss: 1.5415222042350358

Epoch: 5| Step: 7
Training loss: 0.044809408485889435
Validation loss: 1.578021667977815

Epoch: 5| Step: 8
Training loss: 0.047622717916965485
Validation loss: 1.5805325995209396

Epoch: 5| Step: 9
Training loss: 0.057704973965883255
Validation loss: 1.6087706345383839

Epoch: 5| Step: 10
Training loss: 0.060227204114198685
Validation loss: 1.6231070692821215

Epoch: 634| Step: 0
Training loss: 0.0625990703701973
Validation loss: 1.6199919575004167

Epoch: 5| Step: 1
Training loss: 0.089431032538414
Validation loss: 1.5911407534794142

Epoch: 5| Step: 2
Training loss: 0.06815284490585327
Validation loss: 1.5818183678452686

Epoch: 5| Step: 3
Training loss: 0.03751817345619202
Validation loss: 1.5527792233292774

Epoch: 5| Step: 4
Training loss: 0.0916297659277916
Validation loss: 1.5200282758282078

Epoch: 5| Step: 5
Training loss: 0.036484070122241974
Validation loss: 1.512420379987327

Epoch: 5| Step: 6
Training loss: 0.07755737751722336
Validation loss: 1.5383039379632601

Epoch: 5| Step: 7
Training loss: 0.0682389885187149
Validation loss: 1.5626885403868973

Epoch: 5| Step: 8
Training loss: 0.04532252997159958
Validation loss: 1.5700847935932938

Epoch: 5| Step: 9
Training loss: 0.05216682702302933
Validation loss: 1.5712741010932512

Epoch: 5| Step: 10
Training loss: 0.0807437002658844
Validation loss: 1.5909537833224061

Epoch: 635| Step: 0
Training loss: 0.06545203179121017
Validation loss: 1.5820307468855253

Epoch: 5| Step: 1
Training loss: 0.07632680237293243
Validation loss: 1.5972661074771677

Epoch: 5| Step: 2
Training loss: 0.03672086074948311
Validation loss: 1.5713599907454623

Epoch: 5| Step: 3
Training loss: 0.035945478826761246
Validation loss: 1.5803127840001097

Epoch: 5| Step: 4
Training loss: 0.04988010600209236
Validation loss: 1.5813521915866482

Epoch: 5| Step: 5
Training loss: 0.06627654284238815
Validation loss: 1.5542405882189352

Epoch: 5| Step: 6
Training loss: 0.06264347583055496
Validation loss: 1.5547734793796335

Epoch: 5| Step: 7
Training loss: 0.10171367973089218
Validation loss: 1.5625181198120117

Epoch: 5| Step: 8
Training loss: 0.08530823141336441
Validation loss: 1.5521585774678055

Epoch: 5| Step: 9
Training loss: 0.05311072617769241
Validation loss: 1.5507256061800065

Epoch: 5| Step: 10
Training loss: 0.03998217731714249
Validation loss: 1.5882138513749646

Epoch: 636| Step: 0
Training loss: 0.06833098828792572
Validation loss: 1.6035604060337108

Epoch: 5| Step: 1
Training loss: 0.07901735603809357
Validation loss: 1.5733495514879945

Epoch: 5| Step: 2
Training loss: 0.0716341957449913
Validation loss: 1.5851850804462229

Epoch: 5| Step: 3
Training loss: 0.05928611755371094
Validation loss: 1.5897540033504527

Epoch: 5| Step: 4
Training loss: 0.049519915133714676
Validation loss: 1.6002674628329534

Epoch: 5| Step: 5
Training loss: 0.05979493260383606
Validation loss: 1.5735279654943815

Epoch: 5| Step: 6
Training loss: 0.06831421703100204
Validation loss: 1.5723527144360285

Epoch: 5| Step: 7
Training loss: 0.0532342903316021
Validation loss: 1.5849881979726976

Epoch: 5| Step: 8
Training loss: 0.05638971924781799
Validation loss: 1.5931888729013421

Epoch: 5| Step: 9
Training loss: 0.04727640002965927
Validation loss: 1.5951296872990106

Epoch: 5| Step: 10
Training loss: 0.09708503633737564
Validation loss: 1.567072614546745

Epoch: 637| Step: 0
Training loss: 0.0637192577123642
Validation loss: 1.5596914240109023

Epoch: 5| Step: 1
Training loss: 0.0424400269985199
Validation loss: 1.5595658081834034

Epoch: 5| Step: 2
Training loss: 0.08057455718517303
Validation loss: 1.5432990315139934

Epoch: 5| Step: 3
Training loss: 0.0919085443019867
Validation loss: 1.5431782814764208

Epoch: 5| Step: 4
Training loss: 0.04748648777604103
Validation loss: 1.5427195038846744

Epoch: 5| Step: 5
Training loss: 0.07624369859695435
Validation loss: 1.5749497503362677

Epoch: 5| Step: 6
Training loss: 0.1000143513083458
Validation loss: 1.575129875572779

Epoch: 5| Step: 7
Training loss: 0.0642084851861
Validation loss: 1.577617509390718

Epoch: 5| Step: 8
Training loss: 0.05072666332125664
Validation loss: 1.6072550178855978

Epoch: 5| Step: 9
Training loss: 0.09728409349918365
Validation loss: 1.6458023889090425

Epoch: 5| Step: 10
Training loss: 0.07400506734848022
Validation loss: 1.648427068546254

Epoch: 638| Step: 0
Training loss: 0.10280446708202362
Validation loss: 1.592578600811702

Epoch: 5| Step: 1
Training loss: 0.060279108583927155
Validation loss: 1.5873587464773526

Epoch: 5| Step: 2
Training loss: 0.04637967795133591
Validation loss: 1.5243240453863656

Epoch: 5| Step: 3
Training loss: 0.06977042555809021
Validation loss: 1.501559647180701

Epoch: 5| Step: 4
Training loss: 0.12765374779701233
Validation loss: 1.5262370583831624

Epoch: 5| Step: 5
Training loss: 0.16514059901237488
Validation loss: 1.5100580030871975

Epoch: 5| Step: 6
Training loss: 0.07692673057317734
Validation loss: 1.5009207430706228

Epoch: 5| Step: 7
Training loss: 0.04833722487092018
Validation loss: 1.53494906169112

Epoch: 5| Step: 8
Training loss: 0.045448269695043564
Validation loss: 1.5434287478846889

Epoch: 5| Step: 9
Training loss: 0.14854039251804352
Validation loss: 1.5872498545595395

Epoch: 5| Step: 10
Training loss: 0.08400879055261612
Validation loss: 1.6132327907828874

Epoch: 639| Step: 0
Training loss: 0.09877687692642212
Validation loss: 1.6009349399997341

Epoch: 5| Step: 1
Training loss: 0.1257058084011078
Validation loss: 1.5869827552508282

Epoch: 5| Step: 2
Training loss: 0.0917392447590828
Validation loss: 1.5562297349335046

Epoch: 5| Step: 3
Training loss: 0.05802205950021744
Validation loss: 1.5181487798690796

Epoch: 5| Step: 4
Training loss: 0.05320584774017334
Validation loss: 1.5267510747396817

Epoch: 5| Step: 5
Training loss: 0.06784341484308243
Validation loss: 1.5025657684572282

Epoch: 5| Step: 6
Training loss: 0.0714714378118515
Validation loss: 1.4985433099090413

Epoch: 5| Step: 7
Training loss: 0.05577635020017624
Validation loss: 1.468114902896266

Epoch: 5| Step: 8
Training loss: 0.07897336781024933
Validation loss: 1.5217362988379695

Epoch: 5| Step: 9
Training loss: 0.054435890167951584
Validation loss: 1.480738737249887

Epoch: 5| Step: 10
Training loss: 0.06418676674365997
Validation loss: 1.5500044656056229

Epoch: 640| Step: 0
Training loss: 0.056024450808763504
Validation loss: 1.5742913484573364

Epoch: 5| Step: 1
Training loss: 0.0677037388086319
Validation loss: 1.551076437837334

Epoch: 5| Step: 2
Training loss: 0.07321392744779587
Validation loss: 1.561805836616024

Epoch: 5| Step: 3
Training loss: 0.10064752399921417
Validation loss: 1.5908681308069537

Epoch: 5| Step: 4
Training loss: 0.057427335530519485
Validation loss: 1.5408343435615621

Epoch: 5| Step: 5
Training loss: 0.03239526227116585
Validation loss: 1.563107249557331

Epoch: 5| Step: 6
Training loss: 0.08802071958780289
Validation loss: 1.548018333732441

Epoch: 5| Step: 7
Training loss: 0.04728531837463379
Validation loss: 1.5860097831295383

Epoch: 5| Step: 8
Training loss: 0.05137866735458374
Validation loss: 1.5670301773214852

Epoch: 5| Step: 9
Training loss: 0.08624231815338135
Validation loss: 1.6018258935661727

Epoch: 5| Step: 10
Training loss: 0.06600221991539001
Validation loss: 1.611304816379342

Epoch: 641| Step: 0
Training loss: 0.034838128834962845
Validation loss: 1.5995838206301454

Epoch: 5| Step: 1
Training loss: 0.027692100033164024
Validation loss: 1.6030074024713168

Epoch: 5| Step: 2
Training loss: 0.06568069756031036
Validation loss: 1.5844121876583304

Epoch: 5| Step: 3
Training loss: 0.04685783386230469
Validation loss: 1.5621597459239345

Epoch: 5| Step: 4
Training loss: 0.10217471420764923
Validation loss: 1.544968738350817

Epoch: 5| Step: 5
Training loss: 0.051669467240571976
Validation loss: 1.527667719830749

Epoch: 5| Step: 6
Training loss: 0.06721626222133636
Validation loss: 1.5287564492994739

Epoch: 5| Step: 7
Training loss: 0.03739765286445618
Validation loss: 1.4937489609564505

Epoch: 5| Step: 8
Training loss: 0.10056436061859131
Validation loss: 1.5285825242278397

Epoch: 5| Step: 9
Training loss: 0.07222883403301239
Validation loss: 1.5297398849200177

Epoch: 5| Step: 10
Training loss: 0.051350999623537064
Validation loss: 1.5239812750970163

Epoch: 642| Step: 0
Training loss: 0.04761452600359917
Validation loss: 1.5001892864063222

Epoch: 5| Step: 1
Training loss: 0.04490349814295769
Validation loss: 1.5239273002070766

Epoch: 5| Step: 2
Training loss: 0.054505687206983566
Validation loss: 1.5212350327481505

Epoch: 5| Step: 3
Training loss: 0.046312253922224045
Validation loss: 1.5035406633089947

Epoch: 5| Step: 4
Training loss: 0.04271766170859337
Validation loss: 1.523001141445611

Epoch: 5| Step: 5
Training loss: 0.09718138724565506
Validation loss: 1.5133937116592162

Epoch: 5| Step: 6
Training loss: 0.07218491286039352
Validation loss: 1.5365040609913487

Epoch: 5| Step: 7
Training loss: 0.042979784309864044
Validation loss: 1.542143730707066

Epoch: 5| Step: 8
Training loss: 0.07462577521800995
Validation loss: 1.5483021966872677

Epoch: 5| Step: 9
Training loss: 0.048761554062366486
Validation loss: 1.5758601311714417

Epoch: 5| Step: 10
Training loss: 0.05315053462982178
Validation loss: 1.529190025021953

Epoch: 643| Step: 0
Training loss: 0.030724521726369858
Validation loss: 1.4987646918142996

Epoch: 5| Step: 1
Training loss: 0.06741515547037125
Validation loss: 1.523292132603225

Epoch: 5| Step: 2
Training loss: 0.043888919055461884
Validation loss: 1.5208981344776769

Epoch: 5| Step: 3
Training loss: 0.08778171241283417
Validation loss: 1.4910424204282864

Epoch: 5| Step: 4
Training loss: 0.08375091850757599
Validation loss: 1.499254052357007

Epoch: 5| Step: 5
Training loss: 0.07907899469137192
Validation loss: 1.4851767696360105

Epoch: 5| Step: 6
Training loss: 0.05429550260305405
Validation loss: 1.5301244861336165

Epoch: 5| Step: 7
Training loss: 0.09649978578090668
Validation loss: 1.5309487914526334

Epoch: 5| Step: 8
Training loss: 0.06111244484782219
Validation loss: 1.5732832647139026

Epoch: 5| Step: 9
Training loss: 0.058421432971954346
Validation loss: 1.5892480445164505

Epoch: 5| Step: 10
Training loss: 0.10470063239336014
Validation loss: 1.5801156182442941

Epoch: 644| Step: 0
Training loss: 0.11461639404296875
Validation loss: 1.5771719486482683

Epoch: 5| Step: 1
Training loss: 0.05987132713198662
Validation loss: 1.5376944849568028

Epoch: 5| Step: 2
Training loss: 0.045704495161771774
Validation loss: 1.5124229154279154

Epoch: 5| Step: 3
Training loss: 0.06049305200576782
Validation loss: 1.5007812476927234

Epoch: 5| Step: 4
Training loss: 0.06101716682314873
Validation loss: 1.5144613276245773

Epoch: 5| Step: 5
Training loss: 0.11113075166940689
Validation loss: 1.5048986263172601

Epoch: 5| Step: 6
Training loss: 0.04262809082865715
Validation loss: 1.500707172578381

Epoch: 5| Step: 7
Training loss: 0.06333480775356293
Validation loss: 1.5427014853364678

Epoch: 5| Step: 8
Training loss: 0.03451906144618988
Validation loss: 1.5604285309391637

Epoch: 5| Step: 9
Training loss: 0.1079079657793045
Validation loss: 1.5454924273234543

Epoch: 5| Step: 10
Training loss: 0.11295315623283386
Validation loss: 1.5580890813181478

Epoch: 645| Step: 0
Training loss: 0.04676738381385803
Validation loss: 1.5580725093041696

Epoch: 5| Step: 1
Training loss: 0.07409320771694183
Validation loss: 1.5952562183462164

Epoch: 5| Step: 2
Training loss: 0.04502372071146965
Validation loss: 1.6007884599829232

Epoch: 5| Step: 3
Training loss: 0.05424152687191963
Validation loss: 1.610042937340275

Epoch: 5| Step: 4
Training loss: 0.08567364513874054
Validation loss: 1.609239060391662

Epoch: 5| Step: 5
Training loss: 0.05635148286819458
Validation loss: 1.5933680457453574

Epoch: 5| Step: 6
Training loss: 0.05542699247598648
Validation loss: 1.5532617043423396

Epoch: 5| Step: 7
Training loss: 0.06530685722827911
Validation loss: 1.5480730546418058

Epoch: 5| Step: 8
Training loss: 0.057866524904966354
Validation loss: 1.510451445015528

Epoch: 5| Step: 9
Training loss: 0.11023703962564468
Validation loss: 1.4979766761102984

Epoch: 5| Step: 10
Training loss: 0.09378749132156372
Validation loss: 1.4846007324034167

Epoch: 646| Step: 0
Training loss: 0.10912785679101944
Validation loss: 1.5264286533478768

Epoch: 5| Step: 1
Training loss: 0.08935530483722687
Validation loss: 1.5180123608599427

Epoch: 5| Step: 2
Training loss: 0.06557481735944748
Validation loss: 1.5429547909767396

Epoch: 5| Step: 3
Training loss: 0.07122233510017395
Validation loss: 1.5421837670828706

Epoch: 5| Step: 4
Training loss: 0.03822314366698265
Validation loss: 1.555148837386921

Epoch: 5| Step: 5
Training loss: 0.07039998471736908
Validation loss: 1.5884916551651493

Epoch: 5| Step: 6
Training loss: 0.06372199952602386
Validation loss: 1.6021044626030871

Epoch: 5| Step: 7
Training loss: 0.04852858930826187
Validation loss: 1.5918275387056413

Epoch: 5| Step: 8
Training loss: 0.05115728825330734
Validation loss: 1.5410438814470846

Epoch: 5| Step: 9
Training loss: 0.08092159032821655
Validation loss: 1.5424679197290891

Epoch: 5| Step: 10
Training loss: 0.08469229191541672
Validation loss: 1.5350815378209597

Epoch: 647| Step: 0
Training loss: 0.05477406829595566
Validation loss: 1.5612373736596876

Epoch: 5| Step: 1
Training loss: 0.060658831149339676
Validation loss: 1.5568335543396652

Epoch: 5| Step: 2
Training loss: 0.06455273181200027
Validation loss: 1.5569969620755924

Epoch: 5| Step: 3
Training loss: 0.04814065992832184
Validation loss: 1.5714996976237143

Epoch: 5| Step: 4
Training loss: 0.05198327451944351
Validation loss: 1.5595528669254755

Epoch: 5| Step: 5
Training loss: 0.041419606655836105
Validation loss: 1.577081138087857

Epoch: 5| Step: 6
Training loss: 0.06005392223596573
Validation loss: 1.5727500428435623

Epoch: 5| Step: 7
Training loss: 0.06982670724391937
Validation loss: 1.568564761069513

Epoch: 5| Step: 8
Training loss: 0.06315401941537857
Validation loss: 1.5694007174943083

Epoch: 5| Step: 9
Training loss: 0.07233873754739761
Validation loss: 1.5679640487958026

Epoch: 5| Step: 10
Training loss: 0.04542003571987152
Validation loss: 1.5750911940810501

Epoch: 648| Step: 0
Training loss: 0.0422591008245945
Validation loss: 1.5798541038267073

Epoch: 5| Step: 1
Training loss: 0.07496324181556702
Validation loss: 1.6128296980293848

Epoch: 5| Step: 2
Training loss: 0.06915989518165588
Validation loss: 1.6317139415330784

Epoch: 5| Step: 3
Training loss: 0.07622049003839493
Validation loss: 1.6338486927811817

Epoch: 5| Step: 4
Training loss: 0.06021042540669441
Validation loss: 1.598272115953507

Epoch: 5| Step: 5
Training loss: 0.07088014483451843
Validation loss: 1.5911408573068597

Epoch: 5| Step: 6
Training loss: 0.057401467114686966
Validation loss: 1.5935006692845335

Epoch: 5| Step: 7
Training loss: 0.035264838486909866
Validation loss: 1.574578901772858

Epoch: 5| Step: 8
Training loss: 0.03309664502739906
Validation loss: 1.5886082482594315

Epoch: 5| Step: 9
Training loss: 0.04191801697015762
Validation loss: 1.5712338468079925

Epoch: 5| Step: 10
Training loss: 0.08436407148838043
Validation loss: 1.5382489235170427

Epoch: 649| Step: 0
Training loss: 0.06001846864819527
Validation loss: 1.5356235414422967

Epoch: 5| Step: 1
Training loss: 0.044908832758665085
Validation loss: 1.5375016543173021

Epoch: 5| Step: 2
Training loss: 0.06035829335451126
Validation loss: 1.5537125782300067

Epoch: 5| Step: 3
Training loss: 0.03981531783938408
Validation loss: 1.548847734287221

Epoch: 5| Step: 4
Training loss: 0.09379351139068604
Validation loss: 1.587879994864105

Epoch: 5| Step: 5
Training loss: 0.06480192393064499
Validation loss: 1.5524730567009217

Epoch: 5| Step: 6
Training loss: 0.0810454711318016
Validation loss: 1.5846665623367473

Epoch: 5| Step: 7
Training loss: 0.041168153285980225
Validation loss: 1.584677493700417

Epoch: 5| Step: 8
Training loss: 0.04647313803434372
Validation loss: 1.591345456338698

Epoch: 5| Step: 9
Training loss: 0.0667189210653305
Validation loss: 1.601479471370738

Epoch: 5| Step: 10
Training loss: 0.05779949203133583
Validation loss: 1.5892837047576904

Epoch: 650| Step: 0
Training loss: 0.055327631533145905
Validation loss: 1.5920153407640354

Epoch: 5| Step: 1
Training loss: 0.05045018345117569
Validation loss: 1.5898105098355202

Epoch: 5| Step: 2
Training loss: 0.07616756111383438
Validation loss: 1.5729085245440084

Epoch: 5| Step: 3
Training loss: 0.07877107709646225
Validation loss: 1.564480068863079

Epoch: 5| Step: 4
Training loss: 0.05106257274746895
Validation loss: 1.5445049693507533

Epoch: 5| Step: 5
Training loss: 0.08501540869474411
Validation loss: 1.5693875884497037

Epoch: 5| Step: 6
Training loss: 0.0595160610973835
Validation loss: 1.5649015352290163

Epoch: 5| Step: 7
Training loss: 0.07035299390554428
Validation loss: 1.5623276707946614

Epoch: 5| Step: 8
Training loss: 0.04566561430692673
Validation loss: 1.554985023313953

Epoch: 5| Step: 9
Training loss: 0.06832678616046906
Validation loss: 1.5518631217300252

Epoch: 5| Step: 10
Training loss: 0.08436297625303268
Validation loss: 1.5794678324012346

Epoch: 651| Step: 0
Training loss: 0.07222913205623627
Validation loss: 1.581542379112654

Epoch: 5| Step: 1
Training loss: 0.07521957159042358
Validation loss: 1.5617084221173358

Epoch: 5| Step: 2
Training loss: 0.06949074566364288
Validation loss: 1.5545707178372208

Epoch: 5| Step: 3
Training loss: 0.09335805475711823
Validation loss: 1.5267959153780373

Epoch: 5| Step: 4
Training loss: 0.07715411484241486
Validation loss: 1.5326047687120334

Epoch: 5| Step: 5
Training loss: 0.06929926574230194
Validation loss: 1.5388314070240143

Epoch: 5| Step: 6
Training loss: 0.07169491052627563
Validation loss: 1.562173674183507

Epoch: 5| Step: 7
Training loss: 0.06860465556383133
Validation loss: 1.563891513373262

Epoch: 5| Step: 8
Training loss: 0.04446534439921379
Validation loss: 1.5609098519048383

Epoch: 5| Step: 9
Training loss: 0.07741627842187881
Validation loss: 1.6091723044713337

Epoch: 5| Step: 10
Training loss: 0.0691792443394661
Validation loss: 1.6157246994715866

Epoch: 652| Step: 0
Training loss: 0.07133021950721741
Validation loss: 1.578510324160258

Epoch: 5| Step: 1
Training loss: 0.0684686154127121
Validation loss: 1.5660980747592064

Epoch: 5| Step: 2
Training loss: 0.06694941222667694
Validation loss: 1.5682239904198596

Epoch: 5| Step: 3
Training loss: 0.05577536299824715
Validation loss: 1.5395799362531273

Epoch: 5| Step: 4
Training loss: 0.09425393491983414
Validation loss: 1.5485602828764147

Epoch: 5| Step: 5
Training loss: 0.06822692602872849
Validation loss: 1.5473516538578977

Epoch: 5| Step: 6
Training loss: 0.07364973425865173
Validation loss: 1.5782624624108756

Epoch: 5| Step: 7
Training loss: 0.057387787848711014
Validation loss: 1.5999949837243685

Epoch: 5| Step: 8
Training loss: 0.07642508298158646
Validation loss: 1.6078212184290732

Epoch: 5| Step: 9
Training loss: 0.07548423111438751
Validation loss: 1.609266911783526

Epoch: 5| Step: 10
Training loss: 0.0340254083275795
Validation loss: 1.5877449615027315

Epoch: 653| Step: 0
Training loss: 0.06806109845638275
Validation loss: 1.5931168281903831

Epoch: 5| Step: 1
Training loss: 0.040849409997463226
Validation loss: 1.5540037232060586

Epoch: 5| Step: 2
Training loss: 0.05118359252810478
Validation loss: 1.5440282911382697

Epoch: 5| Step: 3
Training loss: 0.06387413293123245
Validation loss: 1.5523749987284343

Epoch: 5| Step: 4
Training loss: 0.05860894173383713
Validation loss: 1.5473657013267599

Epoch: 5| Step: 5
Training loss: 0.07040192186832428
Validation loss: 1.5513200298432381

Epoch: 5| Step: 6
Training loss: 0.0532090850174427
Validation loss: 1.5411761755584388

Epoch: 5| Step: 7
Training loss: 0.05876772850751877
Validation loss: 1.547912864274876

Epoch: 5| Step: 8
Training loss: 0.07025064527988434
Validation loss: 1.5519217445004372

Epoch: 5| Step: 9
Training loss: 0.07184731960296631
Validation loss: 1.5585486888885498

Epoch: 5| Step: 10
Training loss: 0.1405131220817566
Validation loss: 1.5348590381683842

Epoch: 654| Step: 0
Training loss: 0.06089979410171509
Validation loss: 1.5482536695336784

Epoch: 5| Step: 1
Training loss: 0.04104479029774666
Validation loss: 1.545445970309678

Epoch: 5| Step: 2
Training loss: 0.050163984298706055
Validation loss: 1.535561635930051

Epoch: 5| Step: 3
Training loss: 0.060225509107112885
Validation loss: 1.5567739035493584

Epoch: 5| Step: 4
Training loss: 0.07086914032697678
Validation loss: 1.5623219833579114

Epoch: 5| Step: 5
Training loss: 0.11587951332330704
Validation loss: 1.5578417854924356

Epoch: 5| Step: 6
Training loss: 0.09545335918664932
Validation loss: 1.5336057973164383

Epoch: 5| Step: 7
Training loss: 0.05226211994886398
Validation loss: 1.544439209404812

Epoch: 5| Step: 8
Training loss: 0.060446031391620636
Validation loss: 1.5216077194418958

Epoch: 5| Step: 9
Training loss: 0.07367810606956482
Validation loss: 1.527458628018697

Epoch: 5| Step: 10
Training loss: 0.050472188740968704
Validation loss: 1.5178998131905832

Epoch: 655| Step: 0
Training loss: 0.05015600845217705
Validation loss: 1.5418645181963522

Epoch: 5| Step: 1
Training loss: 0.09570179879665375
Validation loss: 1.5261300738139818

Epoch: 5| Step: 2
Training loss: 0.04934331774711609
Validation loss: 1.5293957674375145

Epoch: 5| Step: 3
Training loss: 0.0631781592965126
Validation loss: 1.5401871986286615

Epoch: 5| Step: 4
Training loss: 0.06079423427581787
Validation loss: 1.5640528663512199

Epoch: 5| Step: 5
Training loss: 0.09058384597301483
Validation loss: 1.58382595739057

Epoch: 5| Step: 6
Training loss: 0.09605139493942261
Validation loss: 1.590884400952247

Epoch: 5| Step: 7
Training loss: 0.057110805064439774
Validation loss: 1.5825744014914318

Epoch: 5| Step: 8
Training loss: 0.048766009509563446
Validation loss: 1.585703980538153

Epoch: 5| Step: 9
Training loss: 0.05789858102798462
Validation loss: 1.5787828865871634

Epoch: 5| Step: 10
Training loss: 0.07704778015613556
Validation loss: 1.5570035044864943

Epoch: 656| Step: 0
Training loss: 0.07070688903331757
Validation loss: 1.5450593656109226

Epoch: 5| Step: 1
Training loss: 0.0739237368106842
Validation loss: 1.5441081780259327

Epoch: 5| Step: 2
Training loss: 0.06631635129451752
Validation loss: 1.551354318536738

Epoch: 5| Step: 3
Training loss: 0.052702195942401886
Validation loss: 1.543617812536096

Epoch: 5| Step: 4
Training loss: 0.06347768753767014
Validation loss: 1.5405218588408602

Epoch: 5| Step: 5
Training loss: 0.059499114751815796
Validation loss: 1.5719408117314821

Epoch: 5| Step: 6
Training loss: 0.03712969273328781
Validation loss: 1.592086544600866

Epoch: 5| Step: 7
Training loss: 0.05277424305677414
Validation loss: 1.5959858484165643

Epoch: 5| Step: 8
Training loss: 0.05736876651644707
Validation loss: 1.5987920248380272

Epoch: 5| Step: 9
Training loss: 0.04044618085026741
Validation loss: 1.5761541115340365

Epoch: 5| Step: 10
Training loss: 0.08960658311843872
Validation loss: 1.587970745178961

Epoch: 657| Step: 0
Training loss: 0.05026981234550476
Validation loss: 1.5818429018861504

Epoch: 5| Step: 1
Training loss: 0.05627426505088806
Validation loss: 1.5618277160070275

Epoch: 5| Step: 2
Training loss: 0.06974197924137115
Validation loss: 1.561219584557318

Epoch: 5| Step: 3
Training loss: 0.06268315017223358
Validation loss: 1.5358666040564095

Epoch: 5| Step: 4
Training loss: 0.07332810759544373
Validation loss: 1.5556465156616703

Epoch: 5| Step: 5
Training loss: 0.04219263419508934
Validation loss: 1.5537171581740021

Epoch: 5| Step: 6
Training loss: 0.08242922276258469
Validation loss: 1.5743325782078568

Epoch: 5| Step: 7
Training loss: 0.08245152235031128
Validation loss: 1.5835170060075738

Epoch: 5| Step: 8
Training loss: 0.06316032260656357
Validation loss: 1.5961256193858322

Epoch: 5| Step: 9
Training loss: 0.08896700292825699
Validation loss: 1.578911285246572

Epoch: 5| Step: 10
Training loss: 0.053467750549316406
Validation loss: 1.609763818402444

Epoch: 658| Step: 0
Training loss: 0.08895359933376312
Validation loss: 1.6024738255367483

Epoch: 5| Step: 1
Training loss: 0.0965355783700943
Validation loss: 1.5849936674999934

Epoch: 5| Step: 2
Training loss: 0.05272543430328369
Validation loss: 1.5657258572116974

Epoch: 5| Step: 3
Training loss: 0.05242763087153435
Validation loss: 1.5474780887685797

Epoch: 5| Step: 4
Training loss: 0.07190456241369247
Validation loss: 1.5365563208057034

Epoch: 5| Step: 5
Training loss: 0.10147134959697723
Validation loss: 1.4958862361087595

Epoch: 5| Step: 6
Training loss: 0.07930438220500946
Validation loss: 1.5305181485350414

Epoch: 5| Step: 7
Training loss: 0.07339926809072495
Validation loss: 1.5328543506642824

Epoch: 5| Step: 8
Training loss: 0.0678577795624733
Validation loss: 1.52404539046749

Epoch: 5| Step: 9
Training loss: 0.04669928550720215
Validation loss: 1.5530167882160475

Epoch: 5| Step: 10
Training loss: 0.0886760726571083
Validation loss: 1.5810121144017866

Epoch: 659| Step: 0
Training loss: 0.08333368599414825
Validation loss: 1.5847079164238387

Epoch: 5| Step: 1
Training loss: 0.10154499113559723
Validation loss: 1.5742256615751533

Epoch: 5| Step: 2
Training loss: 0.07924820482730865
Validation loss: 1.5608982796310096

Epoch: 5| Step: 3
Training loss: 0.05786365270614624
Validation loss: 1.5269215350509973

Epoch: 5| Step: 4
Training loss: 0.05858045816421509
Validation loss: 1.520690062994598

Epoch: 5| Step: 5
Training loss: 0.07377193868160248
Validation loss: 1.4884421645954091

Epoch: 5| Step: 6
Training loss: 0.07776566594839096
Validation loss: 1.506667737037905

Epoch: 5| Step: 7
Training loss: 0.11053057014942169
Validation loss: 1.484006799677367

Epoch: 5| Step: 8
Training loss: 0.08532720059156418
Validation loss: 1.5169481282593102

Epoch: 5| Step: 9
Training loss: 0.07831428945064545
Validation loss: 1.5407479527176067

Epoch: 5| Step: 10
Training loss: 0.07838138937950134
Validation loss: 1.5421182776010165

Epoch: 660| Step: 0
Training loss: 0.05058319494128227
Validation loss: 1.598031678507405

Epoch: 5| Step: 1
Training loss: 0.06809656322002411
Validation loss: 1.6393465483060448

Epoch: 5| Step: 2
Training loss: 0.11730177700519562
Validation loss: 1.6575768904019428

Epoch: 5| Step: 3
Training loss: 0.06678293645381927
Validation loss: 1.6418547945958313

Epoch: 5| Step: 4
Training loss: 0.08082597702741623
Validation loss: 1.6214864933362572

Epoch: 5| Step: 5
Training loss: 0.0740208700299263
Validation loss: 1.5711629723989835

Epoch: 5| Step: 6
Training loss: 0.06343023478984833
Validation loss: 1.5527919184777044

Epoch: 5| Step: 7
Training loss: 0.051959145814180374
Validation loss: 1.5152513814228836

Epoch: 5| Step: 8
Training loss: 0.05417210981249809
Validation loss: 1.498123324045571

Epoch: 5| Step: 9
Training loss: 0.07905835658311844
Validation loss: 1.5049464074514245

Epoch: 5| Step: 10
Training loss: 0.05631747096776962
Validation loss: 1.498852619560816

Epoch: 661| Step: 0
Training loss: 0.05714146047830582
Validation loss: 1.5115565843479608

Epoch: 5| Step: 1
Training loss: 0.05406159162521362
Validation loss: 1.5352085867235739

Epoch: 5| Step: 2
Training loss: 0.0737985223531723
Validation loss: 1.5670374580608901

Epoch: 5| Step: 3
Training loss: 0.06267320364713669
Validation loss: 1.5444577688811927

Epoch: 5| Step: 4
Training loss: 0.049083299934864044
Validation loss: 1.5600767135620117

Epoch: 5| Step: 5
Training loss: 0.06304652988910675
Validation loss: 1.5511569310260076

Epoch: 5| Step: 6
Training loss: 0.048531774431467056
Validation loss: 1.5371449096228487

Epoch: 5| Step: 7
Training loss: 0.04515449330210686
Validation loss: 1.5453448680139357

Epoch: 5| Step: 8
Training loss: 0.06799986958503723
Validation loss: 1.522495936321956

Epoch: 5| Step: 9
Training loss: 0.06884486973285675
Validation loss: 1.5431143083880026

Epoch: 5| Step: 10
Training loss: 0.05654318258166313
Validation loss: 1.542022055195224

Epoch: 662| Step: 0
Training loss: 0.04177337884902954
Validation loss: 1.5557453952809817

Epoch: 5| Step: 1
Training loss: 0.02479991316795349
Validation loss: 1.5501018390860608

Epoch: 5| Step: 2
Training loss: 0.06095970794558525
Validation loss: 1.5547298231432516

Epoch: 5| Step: 3
Training loss: 0.05022218078374863
Validation loss: 1.5480866957736272

Epoch: 5| Step: 4
Training loss: 0.0648610070347786
Validation loss: 1.5722033464780418

Epoch: 5| Step: 5
Training loss: 0.06912455707788467
Validation loss: 1.5522941722664783

Epoch: 5| Step: 6
Training loss: 0.0600130632519722
Validation loss: 1.535028152568366

Epoch: 5| Step: 7
Training loss: 0.08024511486291885
Validation loss: 1.5287366195391583

Epoch: 5| Step: 8
Training loss: 0.06169940158724785
Validation loss: 1.5174373779245602

Epoch: 5| Step: 9
Training loss: 0.08484560251235962
Validation loss: 1.5208694306753014

Epoch: 5| Step: 10
Training loss: 0.09002843499183655
Validation loss: 1.5010952231704549

Epoch: 663| Step: 0
Training loss: 0.09937229007482529
Validation loss: 1.4899501762082499

Epoch: 5| Step: 1
Training loss: 0.07802870124578476
Validation loss: 1.5071929052311888

Epoch: 5| Step: 2
Training loss: 0.050751835107803345
Validation loss: 1.5020841090909895

Epoch: 5| Step: 3
Training loss: 0.09719274193048477
Validation loss: 1.5672451142341859

Epoch: 5| Step: 4
Training loss: 0.05978594347834587
Validation loss: 1.5609390889444659

Epoch: 5| Step: 5
Training loss: 0.09297497570514679
Validation loss: 1.5854553009874077

Epoch: 5| Step: 6
Training loss: 0.047744378447532654
Validation loss: 1.5782809667689826

Epoch: 5| Step: 7
Training loss: 0.05151631683111191
Validation loss: 1.5549984542272424

Epoch: 5| Step: 8
Training loss: 0.03592635318636894
Validation loss: 1.5380126455778718

Epoch: 5| Step: 9
Training loss: 0.055606305599212646
Validation loss: 1.5115648161980413

Epoch: 5| Step: 10
Training loss: 0.050906721502542496
Validation loss: 1.4934086709894159

Epoch: 664| Step: 0
Training loss: 0.10322220623493195
Validation loss: 1.4791906918248823

Epoch: 5| Step: 1
Training loss: 0.06893403828144073
Validation loss: 1.4973949745137205

Epoch: 5| Step: 2
Training loss: 0.09234277904033661
Validation loss: 1.513342139541462

Epoch: 5| Step: 3
Training loss: 0.03462483361363411
Validation loss: 1.5132285869249733

Epoch: 5| Step: 4
Training loss: 0.030238285660743713
Validation loss: 1.554041656114722

Epoch: 5| Step: 5
Training loss: 0.07789110392332077
Validation loss: 1.590084993711082

Epoch: 5| Step: 6
Training loss: 0.05381699278950691
Validation loss: 1.5764951526477773

Epoch: 5| Step: 7
Training loss: 0.0652875006198883
Validation loss: 1.5797676501735565

Epoch: 5| Step: 8
Training loss: 0.04676887392997742
Validation loss: 1.5651685653194305

Epoch: 5| Step: 9
Training loss: 0.053061388432979584
Validation loss: 1.5107510589784192

Epoch: 5| Step: 10
Training loss: 0.11603596061468124
Validation loss: 1.5165620952524164

Epoch: 665| Step: 0
Training loss: 0.08397062122821808
Validation loss: 1.4689247262093328

Epoch: 5| Step: 1
Training loss: 0.08594062179327011
Validation loss: 1.4819874045669392

Epoch: 5| Step: 2
Training loss: 0.032636452466249466
Validation loss: 1.4846465728616203

Epoch: 5| Step: 3
Training loss: 0.05823512002825737
Validation loss: 1.4554663281286917

Epoch: 5| Step: 4
Training loss: 0.09592580795288086
Validation loss: 1.4682272813653434

Epoch: 5| Step: 5
Training loss: 0.06595323979854584
Validation loss: 1.472412133088676

Epoch: 5| Step: 6
Training loss: 0.07715049386024475
Validation loss: 1.4994130182650782

Epoch: 5| Step: 7
Training loss: 0.09214533865451813
Validation loss: 1.4962221428912172

Epoch: 5| Step: 8
Training loss: 0.09769705682992935
Validation loss: 1.5014805383579706

Epoch: 5| Step: 9
Training loss: 0.0654836893081665
Validation loss: 1.5298792290431198

Epoch: 5| Step: 10
Training loss: 0.05586228147149086
Validation loss: 1.5315062845906904

Epoch: 666| Step: 0
Training loss: 0.053501956164836884
Validation loss: 1.513656359846874

Epoch: 5| Step: 1
Training loss: 0.06403382122516632
Validation loss: 1.5329009768783406

Epoch: 5| Step: 2
Training loss: 0.06668448448181152
Validation loss: 1.5278115285340177

Epoch: 5| Step: 3
Training loss: 0.05315958708524704
Validation loss: 1.5014874281421784

Epoch: 5| Step: 4
Training loss: 0.06885650753974915
Validation loss: 1.4650180339813232

Epoch: 5| Step: 5
Training loss: 0.10308374464511871
Validation loss: 1.492330551147461

Epoch: 5| Step: 6
Training loss: 0.05094001442193985
Validation loss: 1.486455662276155

Epoch: 5| Step: 7
Training loss: 0.07756825536489487
Validation loss: 1.5259266848205237

Epoch: 5| Step: 8
Training loss: 0.03524245321750641
Validation loss: 1.5327719872997654

Epoch: 5| Step: 9
Training loss: 0.05520195886492729
Validation loss: 1.5538375749382922

Epoch: 5| Step: 10
Training loss: 0.05878424271941185
Validation loss: 1.5493564772349533

Epoch: 667| Step: 0
Training loss: 0.09442290663719177
Validation loss: 1.575774791420147

Epoch: 5| Step: 1
Training loss: 0.06924710422754288
Validation loss: 1.539319537019217

Epoch: 5| Step: 2
Training loss: 0.04021293297410011
Validation loss: 1.5239914450594174

Epoch: 5| Step: 3
Training loss: 0.047689925879240036
Validation loss: 1.5644661124034593

Epoch: 5| Step: 4
Training loss: 0.04915968328714371
Validation loss: 1.52847876984586

Epoch: 5| Step: 5
Training loss: 0.06755869090557098
Validation loss: 1.518034287037388

Epoch: 5| Step: 6
Training loss: 0.06587044894695282
Validation loss: 1.5226320835851854

Epoch: 5| Step: 7
Training loss: 0.07701121270656586
Validation loss: 1.5332074511435725

Epoch: 5| Step: 8
Training loss: 0.09869225323200226
Validation loss: 1.528152496584

Epoch: 5| Step: 9
Training loss: 0.12198574841022491
Validation loss: 1.5576958015400877

Epoch: 5| Step: 10
Training loss: 0.05589868873357773
Validation loss: 1.6022301899489535

Epoch: 668| Step: 0
Training loss: 0.06354427337646484
Validation loss: 1.6071061088192848

Epoch: 5| Step: 1
Training loss: 0.1486240029335022
Validation loss: 1.6139213077483638

Epoch: 5| Step: 2
Training loss: 0.09957475960254669
Validation loss: 1.6122404362565728

Epoch: 5| Step: 3
Training loss: 0.06301283091306686
Validation loss: 1.5850871852649155

Epoch: 5| Step: 4
Training loss: 0.051284559071063995
Validation loss: 1.526103392724068

Epoch: 5| Step: 5
Training loss: 0.05206881836056709
Validation loss: 1.529669964185325

Epoch: 5| Step: 6
Training loss: 0.08254288136959076
Validation loss: 1.520025796146803

Epoch: 5| Step: 7
Training loss: 0.0998336523771286
Validation loss: 1.53455364383677

Epoch: 5| Step: 8
Training loss: 0.11482592672109604
Validation loss: 1.554922951165066

Epoch: 5| Step: 9
Training loss: 0.1150733008980751
Validation loss: 1.5667516954483525

Epoch: 5| Step: 10
Training loss: 0.060464732348918915
Validation loss: 1.585856258228261

Epoch: 669| Step: 0
Training loss: 0.06833577156066895
Validation loss: 1.6267971377218924

Epoch: 5| Step: 1
Training loss: 0.07215094566345215
Validation loss: 1.6017272010926278

Epoch: 5| Step: 2
Training loss: 0.07526321709156036
Validation loss: 1.5884430459750596

Epoch: 5| Step: 3
Training loss: 0.09228745102882385
Validation loss: 1.5945346381074639

Epoch: 5| Step: 4
Training loss: 0.09635250270366669
Validation loss: 1.5865251594974148

Epoch: 5| Step: 5
Training loss: 0.06411579996347427
Validation loss: 1.558708147336078

Epoch: 5| Step: 6
Training loss: 0.06334232538938522
Validation loss: 1.5681357537546465

Epoch: 5| Step: 7
Training loss: 0.08515137434005737
Validation loss: 1.5435947128521499

Epoch: 5| Step: 8
Training loss: 0.06919051706790924
Validation loss: 1.545361541932629

Epoch: 5| Step: 9
Training loss: 0.09569238126277924
Validation loss: 1.5269639427943895

Epoch: 5| Step: 10
Training loss: 0.04881672561168671
Validation loss: 1.5425038837617444

Epoch: 670| Step: 0
Training loss: 0.06771515309810638
Validation loss: 1.515997822566699

Epoch: 5| Step: 1
Training loss: 0.09633152186870575
Validation loss: 1.5128847014519475

Epoch: 5| Step: 2
Training loss: 0.07418148219585419
Validation loss: 1.5055873829831359

Epoch: 5| Step: 3
Training loss: 0.09596192091703415
Validation loss: 1.524389547686423

Epoch: 5| Step: 4
Training loss: 0.04988058656454086
Validation loss: 1.5320256910016459

Epoch: 5| Step: 5
Training loss: 0.08805778622627258
Validation loss: 1.5410238414682367

Epoch: 5| Step: 6
Training loss: 0.049735113978385925
Validation loss: 1.5282903255954865

Epoch: 5| Step: 7
Training loss: 0.05181008577346802
Validation loss: 1.548371445748114

Epoch: 5| Step: 8
Training loss: 0.07190795987844467
Validation loss: 1.5766400714074411

Epoch: 5| Step: 9
Training loss: 0.09568490087985992
Validation loss: 1.5754109300592893

Epoch: 5| Step: 10
Training loss: 0.06680209934711456
Validation loss: 1.6084145320359098

Epoch: 671| Step: 0
Training loss: 0.07580135017633438
Validation loss: 1.614502977299434

Epoch: 5| Step: 1
Training loss: 0.10237996280193329
Validation loss: 1.6377575551309893

Epoch: 5| Step: 2
Training loss: 0.09103436022996902
Validation loss: 1.6175222794214885

Epoch: 5| Step: 3
Training loss: 0.05613383650779724
Validation loss: 1.613540402022741

Epoch: 5| Step: 4
Training loss: 0.07181459665298462
Validation loss: 1.5891301772927726

Epoch: 5| Step: 5
Training loss: 0.06759844720363617
Validation loss: 1.587156932841065

Epoch: 5| Step: 6
Training loss: 0.06757452338933945
Validation loss: 1.5811361369266306

Epoch: 5| Step: 7
Training loss: 0.03094174526631832
Validation loss: 1.5803654757879113

Epoch: 5| Step: 8
Training loss: 0.07801369577646255
Validation loss: 1.5942423625658917

Epoch: 5| Step: 9
Training loss: 0.07285185158252716
Validation loss: 1.5682853152675014

Epoch: 5| Step: 10
Training loss: 0.0624496228992939
Validation loss: 1.5714838197154384

Epoch: 672| Step: 0
Training loss: 0.06417551636695862
Validation loss: 1.5504966423075686

Epoch: 5| Step: 1
Training loss: 0.06190655753016472
Validation loss: 1.5462333784308484

Epoch: 5| Step: 2
Training loss: 0.042247429490089417
Validation loss: 1.5313802790898148

Epoch: 5| Step: 3
Training loss: 0.0823478028178215
Validation loss: 1.5206807210881224

Epoch: 5| Step: 4
Training loss: 0.05392218381166458
Validation loss: 1.5187114695067048

Epoch: 5| Step: 5
Training loss: 0.0819360762834549
Validation loss: 1.5192328165936213

Epoch: 5| Step: 6
Training loss: 0.050405003130435944
Validation loss: 1.550006075571942

Epoch: 5| Step: 7
Training loss: 0.04129518195986748
Validation loss: 1.5604367474074006

Epoch: 5| Step: 8
Training loss: 0.05795416980981827
Validation loss: 1.5385202195054741

Epoch: 5| Step: 9
Training loss: 0.06988196074962616
Validation loss: 1.5297052706441572

Epoch: 5| Step: 10
Training loss: 0.04090297222137451
Validation loss: 1.5586488657100226

Epoch: 673| Step: 0
Training loss: 0.049495600163936615
Validation loss: 1.5383298986701555

Epoch: 5| Step: 1
Training loss: 0.04656229913234711
Validation loss: 1.5541022554520638

Epoch: 5| Step: 2
Training loss: 0.04058874770998955
Validation loss: 1.5366513754731865

Epoch: 5| Step: 3
Training loss: 0.03694029524922371
Validation loss: 1.5304422250358007

Epoch: 5| Step: 4
Training loss: 0.05750129371881485
Validation loss: 1.516767394158148

Epoch: 5| Step: 5
Training loss: 0.04876794293522835
Validation loss: 1.502471290608888

Epoch: 5| Step: 6
Training loss: 0.056480370461940765
Validation loss: 1.4744054771238757

Epoch: 5| Step: 7
Training loss: 0.08261749148368835
Validation loss: 1.4831896091020236

Epoch: 5| Step: 8
Training loss: 0.03960699588060379
Validation loss: 1.4800316749080535

Epoch: 5| Step: 9
Training loss: 0.040104009211063385
Validation loss: 1.4792488492945188

Epoch: 5| Step: 10
Training loss: 0.09614769369363785
Validation loss: 1.4626260777955413

Epoch: 674| Step: 0
Training loss: 0.06663410365581512
Validation loss: 1.4767705420012116

Epoch: 5| Step: 1
Training loss: 0.02228844165802002
Validation loss: 1.4627163679369035

Epoch: 5| Step: 2
Training loss: 0.056887637823820114
Validation loss: 1.5101427250010993

Epoch: 5| Step: 3
Training loss: 0.03965502604842186
Validation loss: 1.5085914622070968

Epoch: 5| Step: 4
Training loss: 0.05949686840176582
Validation loss: 1.520638592781559

Epoch: 5| Step: 5
Training loss: 0.06770968437194824
Validation loss: 1.5056074844893588

Epoch: 5| Step: 6
Training loss: 0.06942620128393173
Validation loss: 1.5241788612898959

Epoch: 5| Step: 7
Training loss: 0.10418009757995605
Validation loss: 1.5308511673763234

Epoch: 5| Step: 8
Training loss: 0.05416868254542351
Validation loss: 1.4911067331990888

Epoch: 5| Step: 9
Training loss: 0.08434444665908813
Validation loss: 1.4803634753791235

Epoch: 5| Step: 10
Training loss: 0.04088357090950012
Validation loss: 1.4664980903748543

Epoch: 675| Step: 0
Training loss: 0.06449615955352783
Validation loss: 1.4926036903935094

Epoch: 5| Step: 1
Training loss: 0.04886597394943237
Validation loss: 1.4786942992159116

Epoch: 5| Step: 2
Training loss: 0.0536743625998497
Validation loss: 1.5167654804004136

Epoch: 5| Step: 3
Training loss: 0.05012930557131767
Validation loss: 1.5076803468888806

Epoch: 5| Step: 4
Training loss: 0.06584005802869797
Validation loss: 1.5165460160983506

Epoch: 5| Step: 5
Training loss: 0.055945105850696564
Validation loss: 1.5303080927941106

Epoch: 5| Step: 6
Training loss: 0.04621027037501335
Validation loss: 1.5484684590370423

Epoch: 5| Step: 7
Training loss: 0.08548050373792648
Validation loss: 1.5689243629414549

Epoch: 5| Step: 8
Training loss: 0.0863705724477768
Validation loss: 1.5383081769430509

Epoch: 5| Step: 9
Training loss: 0.0619220957159996
Validation loss: 1.5088756225442375

Epoch: 5| Step: 10
Training loss: 0.06521660834550858
Validation loss: 1.5061716674476542

Epoch: 676| Step: 0
Training loss: 0.06185588985681534
Validation loss: 1.4826294747732018

Epoch: 5| Step: 1
Training loss: 0.05231187865138054
Validation loss: 1.4933844157444534

Epoch: 5| Step: 2
Training loss: 0.05801966041326523
Validation loss: 1.4854191426307923

Epoch: 5| Step: 3
Training loss: 0.043296314775943756
Validation loss: 1.5096102042864727

Epoch: 5| Step: 4
Training loss: 0.059748340398073196
Validation loss: 1.477257086384681

Epoch: 5| Step: 5
Training loss: 0.036087363958358765
Validation loss: 1.4964805315899592

Epoch: 5| Step: 6
Training loss: 0.0359635166823864
Validation loss: 1.5048659834810483

Epoch: 5| Step: 7
Training loss: 0.06357382237911224
Validation loss: 1.4959179323206666

Epoch: 5| Step: 8
Training loss: 0.0673246830701828
Validation loss: 1.5230760144931015

Epoch: 5| Step: 9
Training loss: 0.06503334641456604
Validation loss: 1.5034093420992616

Epoch: 5| Step: 10
Training loss: 0.07224270701408386
Validation loss: 1.5126355873641146

Epoch: 677| Step: 0
Training loss: 0.04013025015592575
Validation loss: 1.492858325281451

Epoch: 5| Step: 1
Training loss: 0.07280614227056503
Validation loss: 1.4971570584081835

Epoch: 5| Step: 2
Training loss: 0.04353884607553482
Validation loss: 1.5050310306651618

Epoch: 5| Step: 3
Training loss: 0.06375862658023834
Validation loss: 1.4906793563596663

Epoch: 5| Step: 4
Training loss: 0.0582260899245739
Validation loss: 1.4955672012862338

Epoch: 5| Step: 5
Training loss: 0.044410932809114456
Validation loss: 1.4939091936234505

Epoch: 5| Step: 6
Training loss: 0.0625176876783371
Validation loss: 1.5314581099376883

Epoch: 5| Step: 7
Training loss: 0.0727672427892685
Validation loss: 1.5086796290131026

Epoch: 5| Step: 8
Training loss: 0.046431392431259155
Validation loss: 1.5139798900132537

Epoch: 5| Step: 9
Training loss: 0.06405213475227356
Validation loss: 1.5119671731866815

Epoch: 5| Step: 10
Training loss: 0.06353988498449326
Validation loss: 1.545789566091312

Epoch: 678| Step: 0
Training loss: 0.06060178205370903
Validation loss: 1.5585998822284002

Epoch: 5| Step: 1
Training loss: 0.0906803086400032
Validation loss: 1.5742141418559576

Epoch: 5| Step: 2
Training loss: 0.06423555314540863
Validation loss: 1.559088332678682

Epoch: 5| Step: 3
Training loss: 0.06214553117752075
Validation loss: 1.5419944088946107

Epoch: 5| Step: 4
Training loss: 0.04413192719221115
Validation loss: 1.5404294806142007

Epoch: 5| Step: 5
Training loss: 0.03472170978784561
Validation loss: 1.5590460505536807

Epoch: 5| Step: 6
Training loss: 0.051938362419605255
Validation loss: 1.5764260945781585

Epoch: 5| Step: 7
Training loss: 0.0625007376074791
Validation loss: 1.5683292394043298

Epoch: 5| Step: 8
Training loss: 0.06840574741363525
Validation loss: 1.563744079682135

Epoch: 5| Step: 9
Training loss: 0.07743687927722931
Validation loss: 1.5775351626898653

Epoch: 5| Step: 10
Training loss: 0.038247525691986084
Validation loss: 1.5530094869675175

Epoch: 679| Step: 0
Training loss: 0.05246830731630325
Validation loss: 1.5347085973267913

Epoch: 5| Step: 1
Training loss: 0.06321509927511215
Validation loss: 1.5331623387593094

Epoch: 5| Step: 2
Training loss: 0.04751205071806908
Validation loss: 1.5285066622559742

Epoch: 5| Step: 3
Training loss: 0.044693365693092346
Validation loss: 1.495981301030805

Epoch: 5| Step: 4
Training loss: 0.05013931542634964
Validation loss: 1.4986685924632575

Epoch: 5| Step: 5
Training loss: 0.04871600121259689
Validation loss: 1.5057218600344915

Epoch: 5| Step: 6
Training loss: 0.04023125022649765
Validation loss: 1.5177238051609327

Epoch: 5| Step: 7
Training loss: 0.04852769896388054
Validation loss: 1.5366271952147126

Epoch: 5| Step: 8
Training loss: 0.0994131937623024
Validation loss: 1.5350242301981936

Epoch: 5| Step: 9
Training loss: 0.07274048030376434
Validation loss: 1.520190813208139

Epoch: 5| Step: 10
Training loss: 0.07037058472633362
Validation loss: 1.5312730266201882

Epoch: 680| Step: 0
Training loss: 0.05049394443631172
Validation loss: 1.547436729554207

Epoch: 5| Step: 1
Training loss: 0.05250099301338196
Validation loss: 1.5298685014888804

Epoch: 5| Step: 2
Training loss: 0.03281363099813461
Validation loss: 1.5243749541621054

Epoch: 5| Step: 3
Training loss: 0.03950115293264389
Validation loss: 1.5351290369546542

Epoch: 5| Step: 4
Training loss: 0.0647253543138504
Validation loss: 1.5417991094691779

Epoch: 5| Step: 5
Training loss: 0.03879178315401077
Validation loss: 1.5606834247548094

Epoch: 5| Step: 6
Training loss: 0.03559258580207825
Validation loss: 1.5557968744667627

Epoch: 5| Step: 7
Training loss: 0.055220235139131546
Validation loss: 1.587930392193538

Epoch: 5| Step: 8
Training loss: 0.07849139720201492
Validation loss: 1.582798986024754

Epoch: 5| Step: 9
Training loss: 0.04435189813375473
Validation loss: 1.5966548791495703

Epoch: 5| Step: 10
Training loss: 0.057651814073324203
Validation loss: 1.6120285308489235

Epoch: 681| Step: 0
Training loss: 0.071395143866539
Validation loss: 1.597629850910556

Epoch: 5| Step: 1
Training loss: 0.03586419299244881
Validation loss: 1.5989821713457826

Epoch: 5| Step: 2
Training loss: 0.042125385254621506
Validation loss: 1.5695843773503457

Epoch: 5| Step: 3
Training loss: 0.04957639425992966
Validation loss: 1.5737759310712096

Epoch: 5| Step: 4
Training loss: 0.03849378973245621
Validation loss: 1.5783437490463257

Epoch: 5| Step: 5
Training loss: 0.04637063667178154
Validation loss: 1.5691578324123094

Epoch: 5| Step: 6
Training loss: 0.0511556975543499
Validation loss: 1.5175343610907113

Epoch: 5| Step: 7
Training loss: 0.05581214278936386
Validation loss: 1.5512315432230632

Epoch: 5| Step: 8
Training loss: 0.07706697285175323
Validation loss: 1.5421058042075044

Epoch: 5| Step: 9
Training loss: 0.04841626435518265
Validation loss: 1.536591637519098

Epoch: 5| Step: 10
Training loss: 0.05674535408616066
Validation loss: 1.5383556555676203

Epoch: 682| Step: 0
Training loss: 0.05993343144655228
Validation loss: 1.560873790453839

Epoch: 5| Step: 1
Training loss: 0.043109335005283356
Validation loss: 1.550236277682807

Epoch: 5| Step: 2
Training loss: 0.043901145458221436
Validation loss: 1.5633429160682104

Epoch: 5| Step: 3
Training loss: 0.03158150240778923
Validation loss: 1.5549288321566839

Epoch: 5| Step: 4
Training loss: 0.047112852334976196
Validation loss: 1.5579743898043068

Epoch: 5| Step: 5
Training loss: 0.06504221260547638
Validation loss: 1.5401684417519519

Epoch: 5| Step: 6
Training loss: 0.05744100362062454
Validation loss: 1.541187047958374

Epoch: 5| Step: 7
Training loss: 0.06118493154644966
Validation loss: 1.5747092718719153

Epoch: 5| Step: 8
Training loss: 0.05237702280282974
Validation loss: 1.5503902012302029

Epoch: 5| Step: 9
Training loss: 0.0786013975739479
Validation loss: 1.5388961338227796

Epoch: 5| Step: 10
Training loss: 0.06782879680395126
Validation loss: 1.5639725397991877

Epoch: 683| Step: 0
Training loss: 0.03432885929942131
Validation loss: 1.5408798648465065

Epoch: 5| Step: 1
Training loss: 0.04430435225367546
Validation loss: 1.5326820163316623

Epoch: 5| Step: 2
Training loss: 0.09751750528812408
Validation loss: 1.5191345599389845

Epoch: 5| Step: 3
Training loss: 0.04419712349772453
Validation loss: 1.539164500851785

Epoch: 5| Step: 4
Training loss: 0.04923519864678383
Validation loss: 1.5397041664328626

Epoch: 5| Step: 5
Training loss: 0.030816415324807167
Validation loss: 1.5148646549511982

Epoch: 5| Step: 6
Training loss: 0.040430206805467606
Validation loss: 1.5344468175723989

Epoch: 5| Step: 7
Training loss: 0.08691360801458359
Validation loss: 1.5600981507250058

Epoch: 5| Step: 8
Training loss: 0.04499422386288643
Validation loss: 1.55325993158484

Epoch: 5| Step: 9
Training loss: 0.06712287664413452
Validation loss: 1.5671456603593723

Epoch: 5| Step: 10
Training loss: 0.0459337942302227
Validation loss: 1.5691890357643046

Epoch: 684| Step: 0
Training loss: 0.06241995096206665
Validation loss: 1.569164183831984

Epoch: 5| Step: 1
Training loss: 0.03412821143865585
Validation loss: 1.5841453690682687

Epoch: 5| Step: 2
Training loss: 0.057334721088409424
Validation loss: 1.554245553990846

Epoch: 5| Step: 3
Training loss: 0.06625670194625854
Validation loss: 1.5325407514008142

Epoch: 5| Step: 4
Training loss: 0.04463344067335129
Validation loss: 1.5426103350936726

Epoch: 5| Step: 5
Training loss: 0.06270873546600342
Validation loss: 1.503010335788932

Epoch: 5| Step: 6
Training loss: 0.05187114328145981
Validation loss: 1.526067849128477

Epoch: 5| Step: 7
Training loss: 0.035640690475702286
Validation loss: 1.5357912804490776

Epoch: 5| Step: 8
Training loss: 0.03347209468483925
Validation loss: 1.5434478559801657

Epoch: 5| Step: 9
Training loss: 0.042477432638406754
Validation loss: 1.5582229168184343

Epoch: 5| Step: 10
Training loss: 0.05513724684715271
Validation loss: 1.5788092523492792

Epoch: 685| Step: 0
Training loss: 0.08187399059534073
Validation loss: 1.5676394354912542

Epoch: 5| Step: 1
Training loss: 0.07667512446641922
Validation loss: 1.5258941291480936

Epoch: 5| Step: 2
Training loss: 0.04051271826028824
Validation loss: 1.5363055967515515

Epoch: 5| Step: 3
Training loss: 0.05407519266009331
Validation loss: 1.5207035490261611

Epoch: 5| Step: 4
Training loss: 0.04996820166707039
Validation loss: 1.5012120123832458

Epoch: 5| Step: 5
Training loss: 0.058539051562547684
Validation loss: 1.5224443225450413

Epoch: 5| Step: 6
Training loss: 0.06846563518047333
Validation loss: 1.5225839986596057

Epoch: 5| Step: 7
Training loss: 0.0798598974943161
Validation loss: 1.5258625899591753

Epoch: 5| Step: 8
Training loss: 0.0782497376203537
Validation loss: 1.5289717002581524

Epoch: 5| Step: 9
Training loss: 0.06671097129583359
Validation loss: 1.51681532654711

Epoch: 5| Step: 10
Training loss: 0.04706898331642151
Validation loss: 1.5384560336348831

Epoch: 686| Step: 0
Training loss: 0.06053191423416138
Validation loss: 1.5761066534185921

Epoch: 5| Step: 1
Training loss: 0.11934492737054825
Validation loss: 1.579571331060061

Epoch: 5| Step: 2
Training loss: 0.06470783799886703
Validation loss: 1.5625113120643042

Epoch: 5| Step: 3
Training loss: 0.05434814840555191
Validation loss: 1.5279524710870558

Epoch: 5| Step: 4
Training loss: 0.056049883365631104
Validation loss: 1.516264924439051

Epoch: 5| Step: 5
Training loss: 0.09885171800851822
Validation loss: 1.4921372167525753

Epoch: 5| Step: 6
Training loss: 0.057146232575178146
Validation loss: 1.4959566400897117

Epoch: 5| Step: 7
Training loss: 0.052435994148254395
Validation loss: 1.486358545159781

Epoch: 5| Step: 8
Training loss: 0.0660669356584549
Validation loss: 1.5297857112781976

Epoch: 5| Step: 9
Training loss: 0.06532134115695953
Validation loss: 1.5805117545589324

Epoch: 5| Step: 10
Training loss: 0.05174512788653374
Validation loss: 1.5803085309202953

Epoch: 687| Step: 0
Training loss: 0.08611533790826797
Validation loss: 1.6168393185061793

Epoch: 5| Step: 1
Training loss: 0.06990208476781845
Validation loss: 1.5971889521486016

Epoch: 5| Step: 2
Training loss: 0.05009358003735542
Validation loss: 1.5718270937601726

Epoch: 5| Step: 3
Training loss: 0.06147807091474533
Validation loss: 1.5516226689020793

Epoch: 5| Step: 4
Training loss: 0.0588812455534935
Validation loss: 1.5508293413346814

Epoch: 5| Step: 5
Training loss: 0.0733468160033226
Validation loss: 1.5458899717177115

Epoch: 5| Step: 6
Training loss: 0.037010084837675095
Validation loss: 1.545401357835339

Epoch: 5| Step: 7
Training loss: 0.04823170229792595
Validation loss: 1.5357803965127597

Epoch: 5| Step: 8
Training loss: 0.09507354348897934
Validation loss: 1.5179423260432419

Epoch: 5| Step: 9
Training loss: 0.0627380758523941
Validation loss: 1.5565277389300767

Epoch: 5| Step: 10
Training loss: 0.04747351258993149
Validation loss: 1.5564574067310621

Epoch: 688| Step: 0
Training loss: 0.05631226301193237
Validation loss: 1.5637832283973694

Epoch: 5| Step: 1
Training loss: 0.05458560585975647
Validation loss: 1.5927951874271515

Epoch: 5| Step: 2
Training loss: 0.06382686644792557
Validation loss: 1.5906689487477785

Epoch: 5| Step: 3
Training loss: 0.07255414873361588
Validation loss: 1.5943089467222973

Epoch: 5| Step: 4
Training loss: 0.08926133811473846
Validation loss: 1.5712035503438724

Epoch: 5| Step: 5
Training loss: 0.06963817775249481
Validation loss: 1.6033327874316965

Epoch: 5| Step: 6
Training loss: 0.03924524784088135
Validation loss: 1.5943773241453274

Epoch: 5| Step: 7
Training loss: 0.10280422866344452
Validation loss: 1.5828643447609358

Epoch: 5| Step: 8
Training loss: 0.0638098269701004
Validation loss: 1.563207580197242

Epoch: 5| Step: 9
Training loss: 0.10301051288843155
Validation loss: 1.5554344102900515

Epoch: 5| Step: 10
Training loss: 0.08818680793046951
Validation loss: 1.5425932035651257

Epoch: 689| Step: 0
Training loss: 0.043747201561927795
Validation loss: 1.5849562447558168

Epoch: 5| Step: 1
Training loss: 0.061255477368831635
Validation loss: 1.5811382737211002

Epoch: 5| Step: 2
Training loss: 0.058984000235795975
Validation loss: 1.61366629985071

Epoch: 5| Step: 3
Training loss: 0.09068045020103455
Validation loss: 1.6264441782428372

Epoch: 5| Step: 4
Training loss: 0.09926071017980576
Validation loss: 1.6150872950912805

Epoch: 5| Step: 5
Training loss: 0.06817208975553513
Validation loss: 1.6191709144141084

Epoch: 5| Step: 6
Training loss: 0.061648376286029816
Validation loss: 1.6199965887172247

Epoch: 5| Step: 7
Training loss: 0.09199750423431396
Validation loss: 1.616978524833597

Epoch: 5| Step: 8
Training loss: 0.09695492684841156
Validation loss: 1.6139294921710927

Epoch: 5| Step: 9
Training loss: 0.06880662590265274
Validation loss: 1.5651109949234994

Epoch: 5| Step: 10
Training loss: 0.05072950944304466
Validation loss: 1.545608405143984

Epoch: 690| Step: 0
Training loss: 0.04517930746078491
Validation loss: 1.5393310541747718

Epoch: 5| Step: 1
Training loss: 0.06413176655769348
Validation loss: 1.517459963598559

Epoch: 5| Step: 2
Training loss: 0.08520461618900299
Validation loss: 1.506154873037851

Epoch: 5| Step: 3
Training loss: 0.05261208862066269
Validation loss: 1.5214844173000706

Epoch: 5| Step: 4
Training loss: 0.13180261850357056
Validation loss: 1.521655249339278

Epoch: 5| Step: 5
Training loss: 0.06421732157468796
Validation loss: 1.527461230113942

Epoch: 5| Step: 6
Training loss: 0.05030951648950577
Validation loss: 1.5325069824854534

Epoch: 5| Step: 7
Training loss: 0.045433126389980316
Validation loss: 1.5591051886158604

Epoch: 5| Step: 8
Training loss: 0.08233189582824707
Validation loss: 1.5474628594613844

Epoch: 5| Step: 9
Training loss: 0.04851499944925308
Validation loss: 1.5766973726211055

Epoch: 5| Step: 10
Training loss: 0.06952071189880371
Validation loss: 1.5825708341854874

Epoch: 691| Step: 0
Training loss: 0.0603896789252758
Validation loss: 1.5839523141102125

Epoch: 5| Step: 1
Training loss: 0.05422113090753555
Validation loss: 1.5704711919189782

Epoch: 5| Step: 2
Training loss: 0.06877066195011139
Validation loss: 1.567232608795166

Epoch: 5| Step: 3
Training loss: 0.09759800881147385
Validation loss: 1.553115826781078

Epoch: 5| Step: 4
Training loss: 0.09602491557598114
Validation loss: 1.5683986833018642

Epoch: 5| Step: 5
Training loss: 0.0545947439968586
Validation loss: 1.577865522394898

Epoch: 5| Step: 6
Training loss: 0.059624094516038895
Validation loss: 1.6060314793740549

Epoch: 5| Step: 7
Training loss: 0.07180488854646683
Validation loss: 1.6017843190059866

Epoch: 5| Step: 8
Training loss: 0.06370457261800766
Validation loss: 1.6114090097847806

Epoch: 5| Step: 9
Training loss: 0.07401493191719055
Validation loss: 1.6166470576358098

Epoch: 5| Step: 10
Training loss: 0.04543055593967438
Validation loss: 1.6204126829742103

Epoch: 692| Step: 0
Training loss: 0.04612932354211807
Validation loss: 1.6212395506520425

Epoch: 5| Step: 1
Training loss: 0.06864180415868759
Validation loss: 1.6092998648202548

Epoch: 5| Step: 2
Training loss: 0.07546184957027435
Validation loss: 1.5783656207464074

Epoch: 5| Step: 3
Training loss: 0.055863626301288605
Validation loss: 1.5833858687390563

Epoch: 5| Step: 4
Training loss: 0.06628377735614777
Validation loss: 1.5405278193053378

Epoch: 5| Step: 5
Training loss: 0.05389363691210747
Validation loss: 1.541477358469399

Epoch: 5| Step: 6
Training loss: 0.07241245359182358
Validation loss: 1.5257628489566106

Epoch: 5| Step: 7
Training loss: 0.05572476238012314
Validation loss: 1.5215926003712479

Epoch: 5| Step: 8
Training loss: 0.04660097509622574
Validation loss: 1.4809773570747786

Epoch: 5| Step: 9
Training loss: 0.06265078485012054
Validation loss: 1.5049707863920478

Epoch: 5| Step: 10
Training loss: 0.09960293024778366
Validation loss: 1.5273886816475981

Epoch: 693| Step: 0
Training loss: 0.028589462861418724
Validation loss: 1.52893615025346

Epoch: 5| Step: 1
Training loss: 0.035357214510440826
Validation loss: 1.5362877307399627

Epoch: 5| Step: 2
Training loss: 0.09858403354883194
Validation loss: 1.5462655918572539

Epoch: 5| Step: 3
Training loss: 0.08453807979822159
Validation loss: 1.558878101328368

Epoch: 5| Step: 4
Training loss: 0.07752150297164917
Validation loss: 1.5769902121636175

Epoch: 5| Step: 5
Training loss: 0.0688537210226059
Validation loss: 1.5690523514183619

Epoch: 5| Step: 6
Training loss: 0.06972414255142212
Validation loss: 1.5757158225582493

Epoch: 5| Step: 7
Training loss: 0.0754094272851944
Validation loss: 1.602552310112984

Epoch: 5| Step: 8
Training loss: 0.054881371557712555
Validation loss: 1.595625998512391

Epoch: 5| Step: 9
Training loss: 0.054704856127500534
Validation loss: 1.5968254150882844

Epoch: 5| Step: 10
Training loss: 0.06103239208459854
Validation loss: 1.570705121563327

Epoch: 694| Step: 0
Training loss: 0.04986410588026047
Validation loss: 1.560208765409326

Epoch: 5| Step: 1
Training loss: 0.03969687223434448
Validation loss: 1.567476700710994

Epoch: 5| Step: 2
Training loss: 0.06541595607995987
Validation loss: 1.5674554788938133

Epoch: 5| Step: 3
Training loss: 0.06332238018512726
Validation loss: 1.5549769786096388

Epoch: 5| Step: 4
Training loss: 0.04531281068921089
Validation loss: 1.5555019545298752

Epoch: 5| Step: 5
Training loss: 0.03990287706255913
Validation loss: 1.5739799853294127

Epoch: 5| Step: 6
Training loss: 0.0591745600104332
Validation loss: 1.6048879059412147

Epoch: 5| Step: 7
Training loss: 0.054913800209760666
Validation loss: 1.5831981448717014

Epoch: 5| Step: 8
Training loss: 0.04887871816754341
Validation loss: 1.5695022139497983

Epoch: 5| Step: 9
Training loss: 0.04002553969621658
Validation loss: 1.5655566684661373

Epoch: 5| Step: 10
Training loss: 0.075340636074543
Validation loss: 1.542271831984161

Epoch: 695| Step: 0
Training loss: 0.051812488585710526
Validation loss: 1.540708314987921

Epoch: 5| Step: 1
Training loss: 0.06787123531103134
Validation loss: 1.5087174279715425

Epoch: 5| Step: 2
Training loss: 0.040207382291555405
Validation loss: 1.5279173415194276

Epoch: 5| Step: 3
Training loss: 0.05408235266804695
Validation loss: 1.5014313318396126

Epoch: 5| Step: 4
Training loss: 0.05781986564397812
Validation loss: 1.5432269034847137

Epoch: 5| Step: 5
Training loss: 0.05871771648526192
Validation loss: 1.546089413345501

Epoch: 5| Step: 6
Training loss: 0.046323563903570175
Validation loss: 1.5679422193957913

Epoch: 5| Step: 7
Training loss: 0.047421894967556
Validation loss: 1.5518884889541134

Epoch: 5| Step: 8
Training loss: 0.08007287979125977
Validation loss: 1.5669996392342351

Epoch: 5| Step: 9
Training loss: 0.04182928055524826
Validation loss: 1.5841320483915267

Epoch: 5| Step: 10
Training loss: 0.06187792494893074
Validation loss: 1.5709897215648363

Epoch: 696| Step: 0
Training loss: 0.060356296598911285
Validation loss: 1.5844542262374715

Epoch: 5| Step: 1
Training loss: 0.07399509847164154
Validation loss: 1.5348029290476153

Epoch: 5| Step: 2
Training loss: 0.055533815175294876
Validation loss: 1.5796153481288622

Epoch: 5| Step: 3
Training loss: 0.048044510185718536
Validation loss: 1.5726551560945408

Epoch: 5| Step: 4
Training loss: 0.09798594564199448
Validation loss: 1.545031447564402

Epoch: 5| Step: 5
Training loss: 0.08217569440603256
Validation loss: 1.5313426794544343

Epoch: 5| Step: 6
Training loss: 0.08448212593793869
Validation loss: 1.5725466846137919

Epoch: 5| Step: 7
Training loss: 0.05114319175481796
Validation loss: 1.5743108859626196

Epoch: 5| Step: 8
Training loss: 0.03686388581991196
Validation loss: 1.5799704379932855

Epoch: 5| Step: 9
Training loss: 0.04868302866816521
Validation loss: 1.5337226506202453

Epoch: 5| Step: 10
Training loss: 0.05864732712507248
Validation loss: 1.5616425160438783

Epoch: 697| Step: 0
Training loss: 0.06622301787137985
Validation loss: 1.5778869018759778

Epoch: 5| Step: 1
Training loss: 0.05597345903515816
Validation loss: 1.575622389393468

Epoch: 5| Step: 2
Training loss: 0.1074143648147583
Validation loss: 1.5487410573549167

Epoch: 5| Step: 3
Training loss: 0.06269936263561249
Validation loss: 1.534320769771453

Epoch: 5| Step: 4
Training loss: 0.05118255689740181
Validation loss: 1.5477822096117082

Epoch: 5| Step: 5
Training loss: 0.06520108878612518
Validation loss: 1.522461970647176

Epoch: 5| Step: 6
Training loss: 0.05549148470163345
Validation loss: 1.5318896417976708

Epoch: 5| Step: 7
Training loss: 0.0667727142572403
Validation loss: 1.5303901132716928

Epoch: 5| Step: 8
Training loss: 0.049815185368061066
Validation loss: 1.5592233083581413

Epoch: 5| Step: 9
Training loss: 0.04902518913149834
Validation loss: 1.5368554207586473

Epoch: 5| Step: 10
Training loss: 0.06745857000350952
Validation loss: 1.5447943338783838

Epoch: 698| Step: 0
Training loss: 0.09110970795154572
Validation loss: 1.5826000167477516

Epoch: 5| Step: 1
Training loss: 0.06981343775987625
Validation loss: 1.5869199178552116

Epoch: 5| Step: 2
Training loss: 0.05089777708053589
Validation loss: 1.5923229366220453

Epoch: 5| Step: 3
Training loss: 0.06389299035072327
Validation loss: 1.5858210543150544

Epoch: 5| Step: 4
Training loss: 0.04397999495267868
Validation loss: 1.5802322344113422

Epoch: 5| Step: 5
Training loss: 0.06836284697055817
Validation loss: 1.5613062445835402

Epoch: 5| Step: 6
Training loss: 0.09177741408348083
Validation loss: 1.5721396553900935

Epoch: 5| Step: 7
Training loss: 0.052779875695705414
Validation loss: 1.5801591129713162

Epoch: 5| Step: 8
Training loss: 0.05004952475428581
Validation loss: 1.5867192450390066

Epoch: 5| Step: 9
Training loss: 0.06316541135311127
Validation loss: 1.5990763992391608

Epoch: 5| Step: 10
Training loss: 0.07421278208494186
Validation loss: 1.5668847317336707

Epoch: 699| Step: 0
Training loss: 0.041918378323316574
Validation loss: 1.5441451572602796

Epoch: 5| Step: 1
Training loss: 0.0521203875541687
Validation loss: 1.4961763774195025

Epoch: 5| Step: 2
Training loss: 0.0519431009888649
Validation loss: 1.4806176616299538

Epoch: 5| Step: 3
Training loss: 0.07615140825510025
Validation loss: 1.510245947427647

Epoch: 5| Step: 4
Training loss: 0.048504602164030075
Validation loss: 1.5329460815716816

Epoch: 5| Step: 5
Training loss: 0.05270884558558464
Validation loss: 1.5226303556913972

Epoch: 5| Step: 6
Training loss: 0.06627921760082245
Validation loss: 1.5135267447399836

Epoch: 5| Step: 7
Training loss: 0.06811495870351791
Validation loss: 1.529203926363299

Epoch: 5| Step: 8
Training loss: 0.06363876163959503
Validation loss: 1.5221939907279065

Epoch: 5| Step: 9
Training loss: 0.03113429807126522
Validation loss: 1.5249569018681843

Epoch: 5| Step: 10
Training loss: 0.06268975138664246
Validation loss: 1.5065283685602167

Epoch: 700| Step: 0
Training loss: 0.05499674752354622
Validation loss: 1.5234489787009455

Epoch: 5| Step: 1
Training loss: 0.09204799681901932
Validation loss: 1.5222903707975983

Epoch: 5| Step: 2
Training loss: 0.03381616249680519
Validation loss: 1.4817020739278486

Epoch: 5| Step: 3
Training loss: 0.03967547416687012
Validation loss: 1.479181581927884

Epoch: 5| Step: 4
Training loss: 0.05726207420229912
Validation loss: 1.4975049431606005

Epoch: 5| Step: 5
Training loss: 0.0579281821846962
Validation loss: 1.481808772651098

Epoch: 5| Step: 6
Training loss: 0.05190148204565048
Validation loss: 1.503551407526898

Epoch: 5| Step: 7
Training loss: 0.06571774184703827
Validation loss: 1.506696730531672

Epoch: 5| Step: 8
Training loss: 0.055400848388671875
Validation loss: 1.5321114370899815

Epoch: 5| Step: 9
Training loss: 0.05683504790067673
Validation loss: 1.5485164042442077

Epoch: 5| Step: 10
Training loss: 0.03594839945435524
Validation loss: 1.5926171400213753

Testing loss: 2.2024399042129517
