Epoch: 1| Step: 0
Training loss: 5.119971752166748
Validation loss: 5.194035427544707

Epoch: 6| Step: 1
Training loss: 5.527863502502441
Validation loss: 5.1770578148544475

Epoch: 6| Step: 2
Training loss: 4.653933525085449
Validation loss: 5.161412033983456

Epoch: 6| Step: 3
Training loss: 4.906181812286377
Validation loss: 5.144001530062768

Epoch: 6| Step: 4
Training loss: 4.49455451965332
Validation loss: 5.123486693187426

Epoch: 6| Step: 5
Training loss: 4.548437118530273
Validation loss: 5.098136794182562

Epoch: 6| Step: 6
Training loss: 5.170973777770996
Validation loss: 5.067573398672124

Epoch: 6| Step: 7
Training loss: 4.7716474533081055
Validation loss: 5.032911997969433

Epoch: 6| Step: 8
Training loss: 4.633587837219238
Validation loss: 4.994122079623643

Epoch: 6| Step: 9
Training loss: 4.104991912841797
Validation loss: 4.949832034367387

Epoch: 6| Step: 10
Training loss: 5.002908706665039
Validation loss: 4.9010502087172645

Epoch: 6| Step: 11
Training loss: 4.18385124206543
Validation loss: 4.847093371934788

Epoch: 6| Step: 12
Training loss: 5.905054092407227
Validation loss: 4.788138256278089

Epoch: 6| Step: 13
Training loss: 4.0363993644714355
Validation loss: 4.723236412130376

Epoch: 2| Step: 0
Training loss: 4.150074005126953
Validation loss: 4.65287640274212

Epoch: 6| Step: 1
Training loss: 4.668527603149414
Validation loss: 4.575123997144802

Epoch: 6| Step: 2
Training loss: 5.219901084899902
Validation loss: 4.493610661516907

Epoch: 6| Step: 3
Training loss: 3.2388038635253906
Validation loss: 4.4080015818278

Epoch: 6| Step: 4
Training loss: 4.768951416015625
Validation loss: 4.322418807655253

Epoch: 6| Step: 5
Training loss: 3.084655284881592
Validation loss: 4.239276839840796

Epoch: 6| Step: 6
Training loss: 3.6845216751098633
Validation loss: 4.164068216918617

Epoch: 6| Step: 7
Training loss: 5.082888603210449
Validation loss: 4.096614788937313

Epoch: 6| Step: 8
Training loss: 3.2553722858428955
Validation loss: 4.035824688532019

Epoch: 6| Step: 9
Training loss: 3.1561779975891113
Validation loss: 3.9815916297256306

Epoch: 6| Step: 10
Training loss: 3.985748291015625
Validation loss: 3.937010734311996

Epoch: 6| Step: 11
Training loss: 3.8021163940429688
Validation loss: 3.896167278289795

Epoch: 6| Step: 12
Training loss: 4.453602313995361
Validation loss: 3.8622830631912395

Epoch: 6| Step: 13
Training loss: 3.5002079010009766
Validation loss: 3.8328164110901537

Epoch: 3| Step: 0
Training loss: 4.001683712005615
Validation loss: 3.806237810401506

Epoch: 6| Step: 1
Training loss: 2.816157341003418
Validation loss: 3.780536195283295

Epoch: 6| Step: 2
Training loss: 3.0157265663146973
Validation loss: 3.7574042761197655

Epoch: 6| Step: 3
Training loss: 2.726017475128174
Validation loss: 3.734188941217238

Epoch: 6| Step: 4
Training loss: 3.707216739654541
Validation loss: 3.708873184778357

Epoch: 6| Step: 5
Training loss: 3.739806652069092
Validation loss: 3.6858247377539195

Epoch: 6| Step: 6
Training loss: 3.8513710498809814
Validation loss: 3.6680885181632092

Epoch: 6| Step: 7
Training loss: 3.769040584564209
Validation loss: 3.653371928840555

Epoch: 6| Step: 8
Training loss: 4.076265811920166
Validation loss: 3.6410711503797963

Epoch: 6| Step: 9
Training loss: 4.392211437225342
Validation loss: 3.619282358436174

Epoch: 6| Step: 10
Training loss: 3.43503475189209
Validation loss: 3.5909383066238894

Epoch: 6| Step: 11
Training loss: 4.13542366027832
Validation loss: 3.567528852852442

Epoch: 6| Step: 12
Training loss: 3.451636791229248
Validation loss: 3.5467432134894916

Epoch: 6| Step: 13
Training loss: 2.493734359741211
Validation loss: 3.5310063208303144

Epoch: 4| Step: 0
Training loss: 4.332274436950684
Validation loss: 3.5158795310604956

Epoch: 6| Step: 1
Training loss: 3.115028142929077
Validation loss: 3.5021492024903655

Epoch: 6| Step: 2
Training loss: 2.2237462997436523
Validation loss: 3.484362994470904

Epoch: 6| Step: 3
Training loss: 3.681212902069092
Validation loss: 3.468272683440998

Epoch: 6| Step: 4
Training loss: 4.229549407958984
Validation loss: 3.4543686015631563

Epoch: 6| Step: 5
Training loss: 2.8878931999206543
Validation loss: 3.438913171009351

Epoch: 6| Step: 6
Training loss: 4.576991081237793
Validation loss: 3.4281463776865313

Epoch: 6| Step: 7
Training loss: 3.6381466388702393
Validation loss: 3.4197662056133313

Epoch: 6| Step: 8
Training loss: 3.810748338699341
Validation loss: 3.408376437361522

Epoch: 6| Step: 9
Training loss: 3.1776726245880127
Validation loss: 3.39852040044723

Epoch: 6| Step: 10
Training loss: 3.4977455139160156
Validation loss: 3.386257007557859

Epoch: 6| Step: 11
Training loss: 2.5191874504089355
Validation loss: 3.374952362429711

Epoch: 6| Step: 12
Training loss: 2.6958532333374023
Validation loss: 3.3657526431545133

Epoch: 6| Step: 13
Training loss: 2.484642267227173
Validation loss: 3.3528249443218274

Epoch: 5| Step: 0
Training loss: 2.6807427406311035
Validation loss: 3.340086244767712

Epoch: 6| Step: 1
Training loss: 3.6990275382995605
Validation loss: 3.332383971060476

Epoch: 6| Step: 2
Training loss: 2.9418067932128906
Validation loss: 3.3257140600553123

Epoch: 6| Step: 3
Training loss: 2.619164228439331
Validation loss: 3.313379241574195

Epoch: 6| Step: 4
Training loss: 3.763704776763916
Validation loss: 3.2998264733181206

Epoch: 6| Step: 5
Training loss: 3.9309051036834717
Validation loss: 3.2909316452600623

Epoch: 6| Step: 6
Training loss: 3.2156500816345215
Validation loss: 3.2774660459128757

Epoch: 6| Step: 7
Training loss: 2.9948670864105225
Validation loss: 3.2673987855193434

Epoch: 6| Step: 8
Training loss: 2.5775132179260254
Validation loss: 3.2555914489171838

Epoch: 6| Step: 9
Training loss: 3.80441951751709
Validation loss: 3.2497395751296834

Epoch: 6| Step: 10
Training loss: 3.963611602783203
Validation loss: 3.240922689437866

Epoch: 6| Step: 11
Training loss: 2.521225929260254
Validation loss: 3.2309081836413314

Epoch: 6| Step: 12
Training loss: 3.594999313354492
Validation loss: 3.220701174069476

Epoch: 6| Step: 13
Training loss: 3.2813873291015625
Validation loss: 3.2186809150121545

Epoch: 6| Step: 0
Training loss: 3.138916015625
Validation loss: 3.2177592426218014

Epoch: 6| Step: 1
Training loss: 4.333652973175049
Validation loss: 3.2034631852180726

Epoch: 6| Step: 2
Training loss: 4.415858745574951
Validation loss: 3.193438811968732

Epoch: 6| Step: 3
Training loss: 3.2816648483276367
Validation loss: 3.1891480799644225

Epoch: 6| Step: 4
Training loss: 3.616408109664917
Validation loss: 3.1770955439536803

Epoch: 6| Step: 5
Training loss: 2.403470277786255
Validation loss: 3.167565917456022

Epoch: 6| Step: 6
Training loss: 3.2239909172058105
Validation loss: 3.1584322657636417

Epoch: 6| Step: 7
Training loss: 2.6502914428710938
Validation loss: 3.15293030072284

Epoch: 6| Step: 8
Training loss: 2.795234203338623
Validation loss: 3.1502474046522573

Epoch: 6| Step: 9
Training loss: 3.625675916671753
Validation loss: 3.141468583896596

Epoch: 6| Step: 10
Training loss: 2.830463409423828
Validation loss: 3.136783217871061

Epoch: 6| Step: 11
Training loss: 3.1226470470428467
Validation loss: 3.132012718467302

Epoch: 6| Step: 12
Training loss: 2.475847005844116
Validation loss: 3.127034971790929

Epoch: 6| Step: 13
Training loss: 2.2243659496307373
Validation loss: 3.1171430233986146

Epoch: 7| Step: 0
Training loss: 3.5709879398345947
Validation loss: 3.111359175815377

Epoch: 6| Step: 1
Training loss: 3.051054000854492
Validation loss: 3.110356620562974

Epoch: 6| Step: 2
Training loss: 2.7157647609710693
Validation loss: 3.104507810326033

Epoch: 6| Step: 3
Training loss: 2.969223976135254
Validation loss: 3.102395872915945

Epoch: 6| Step: 4
Training loss: 2.6353018283843994
Validation loss: 3.0939244788180114

Epoch: 6| Step: 5
Training loss: 3.32549786567688
Validation loss: 3.0944489894374723

Epoch: 6| Step: 6
Training loss: 3.341743230819702
Validation loss: 3.0797554805714595

Epoch: 6| Step: 7
Training loss: 3.688107490539551
Validation loss: 3.0762360941979194

Epoch: 6| Step: 8
Training loss: 2.7140631675720215
Validation loss: 3.060887598222302

Epoch: 6| Step: 9
Training loss: 3.8323380947113037
Validation loss: 3.062289232848793

Epoch: 6| Step: 10
Training loss: 2.3003976345062256
Validation loss: 3.0580274392199773

Epoch: 6| Step: 11
Training loss: 3.611595869064331
Validation loss: 3.053504543919717

Epoch: 6| Step: 12
Training loss: 3.3381948471069336
Validation loss: 3.0425811941905687

Epoch: 6| Step: 13
Training loss: 2.1801271438598633
Validation loss: 3.026219678181474

Epoch: 8| Step: 0
Training loss: 3.468120574951172
Validation loss: 3.0265395436235654

Epoch: 6| Step: 1
Training loss: 3.2840957641601562
Validation loss: 3.034675726326563

Epoch: 6| Step: 2
Training loss: 3.3922958374023438
Validation loss: 3.0304022014781995

Epoch: 6| Step: 3
Training loss: 3.5718026161193848
Validation loss: 3.0163167650981615

Epoch: 6| Step: 4
Training loss: 3.437577247619629
Validation loss: 3.0026254295020975

Epoch: 6| Step: 5
Training loss: 3.3427939414978027
Validation loss: 2.993632188407324

Epoch: 6| Step: 6
Training loss: 3.515660285949707
Validation loss: 2.9858653647925264

Epoch: 6| Step: 7
Training loss: 2.3210678100585938
Validation loss: 2.980765478585356

Epoch: 6| Step: 8
Training loss: 2.932530641555786
Validation loss: 2.9769395243737007

Epoch: 6| Step: 9
Training loss: 2.4436633586883545
Validation loss: 2.9666183148660967

Epoch: 6| Step: 10
Training loss: 3.0519418716430664
Validation loss: 2.960166741442937

Epoch: 6| Step: 11
Training loss: 2.573698043823242
Validation loss: 2.9523742891127065

Epoch: 6| Step: 12
Training loss: 2.5949697494506836
Validation loss: 2.950930885089341

Epoch: 6| Step: 13
Training loss: 2.649825096130371
Validation loss: 2.941192921771798

Epoch: 9| Step: 0
Training loss: 2.5671353340148926
Validation loss: 2.941538421056604

Epoch: 6| Step: 1
Training loss: 2.56941556930542
Validation loss: 2.941130727849981

Epoch: 6| Step: 2
Training loss: 3.4302947521209717
Validation loss: 2.9240284940247894

Epoch: 6| Step: 3
Training loss: 2.6783385276794434
Validation loss: 2.9115311074000534

Epoch: 6| Step: 4
Training loss: 3.1773812770843506
Validation loss: 2.918189822986562

Epoch: 6| Step: 5
Training loss: 3.390378952026367
Validation loss: 2.9195177939630326

Epoch: 6| Step: 6
Training loss: 3.414907932281494
Validation loss: 2.918740305849301

Epoch: 6| Step: 7
Training loss: 3.3959105014801025
Validation loss: 2.9007612633448776

Epoch: 6| Step: 8
Training loss: 3.4148638248443604
Validation loss: 2.8868141892135784

Epoch: 6| Step: 9
Training loss: 2.710513114929199
Validation loss: 2.8844956121137066

Epoch: 6| Step: 10
Training loss: 2.609614849090576
Validation loss: 2.877446279730848

Epoch: 6| Step: 11
Training loss: 2.7422051429748535
Validation loss: 2.873482765689973

Epoch: 6| Step: 12
Training loss: 3.3247792720794678
Validation loss: 2.8702465975156395

Epoch: 6| Step: 13
Training loss: 2.2086567878723145
Validation loss: 2.8673756994226927

Epoch: 10| Step: 0
Training loss: 2.5310564041137695
Validation loss: 2.8611970357997443

Epoch: 6| Step: 1
Training loss: 2.971956253051758
Validation loss: 2.85965528539432

Epoch: 6| Step: 2
Training loss: 1.9727373123168945
Validation loss: 2.853560342583605

Epoch: 6| Step: 3
Training loss: 4.1051836013793945
Validation loss: 2.8541897599415114

Epoch: 6| Step: 4
Training loss: 3.638396739959717
Validation loss: 2.8582890033721924

Epoch: 6| Step: 5
Training loss: 2.8377323150634766
Validation loss: 2.8414568388333885

Epoch: 6| Step: 6
Training loss: 1.502373218536377
Validation loss: 2.839272842612318

Epoch: 6| Step: 7
Training loss: 2.7146806716918945
Validation loss: 2.8407103835895495

Epoch: 6| Step: 8
Training loss: 4.126051902770996
Validation loss: 2.846166956809259

Epoch: 6| Step: 9
Training loss: 2.7252097129821777
Validation loss: 2.834100592520929

Epoch: 6| Step: 10
Training loss: 2.5199921131134033
Validation loss: 2.8279986355894353

Epoch: 6| Step: 11
Training loss: 3.466078996658325
Validation loss: 2.829279371487197

Epoch: 6| Step: 12
Training loss: 3.021406412124634
Validation loss: 2.819611903159849

Epoch: 6| Step: 13
Training loss: 3.477644205093384
Validation loss: 2.8256443777391986

Epoch: 11| Step: 0
Training loss: 2.2862186431884766
Validation loss: 2.8098985213105396

Epoch: 6| Step: 1
Training loss: 2.3268818855285645
Validation loss: 2.8096661439505954

Epoch: 6| Step: 2
Training loss: 3.8412013053894043
Validation loss: 2.809990680345925

Epoch: 6| Step: 3
Training loss: 2.8128483295440674
Validation loss: 2.8093026607267317

Epoch: 6| Step: 4
Training loss: 2.703059673309326
Validation loss: 2.808581039469729

Epoch: 6| Step: 5
Training loss: 3.90938401222229
Validation loss: 2.8020404795164704

Epoch: 6| Step: 6
Training loss: 2.1828153133392334
Validation loss: 2.7987177115614696

Epoch: 6| Step: 7
Training loss: 2.5301389694213867
Validation loss: 2.8059379772473405

Epoch: 6| Step: 8
Training loss: 2.859834671020508
Validation loss: 2.8069645461215766

Epoch: 6| Step: 9
Training loss: 3.49764347076416
Validation loss: 2.7956607085402294

Epoch: 6| Step: 10
Training loss: 2.6717569828033447
Validation loss: 2.791801521855016

Epoch: 6| Step: 11
Training loss: 2.888479709625244
Validation loss: 2.7856707547300603

Epoch: 6| Step: 12
Training loss: 3.484776496887207
Validation loss: 2.7833475707679667

Epoch: 6| Step: 13
Training loss: 3.15419340133667
Validation loss: 2.778849127472088

Epoch: 12| Step: 0
Training loss: 2.6336052417755127
Validation loss: 2.77874570251793

Epoch: 6| Step: 1
Training loss: 2.1788105964660645
Validation loss: 2.7752270108910015

Epoch: 6| Step: 2
Training loss: 2.8574976921081543
Validation loss: 2.7764393796202955

Epoch: 6| Step: 3
Training loss: 3.5904111862182617
Validation loss: 2.7728715609478694

Epoch: 6| Step: 4
Training loss: 3.1860365867614746
Validation loss: 2.7840340445118565

Epoch: 6| Step: 5
Training loss: 2.9787817001342773
Validation loss: 2.770125812099826

Epoch: 6| Step: 6
Training loss: 3.535153865814209
Validation loss: 2.7690970359310025

Epoch: 6| Step: 7
Training loss: 2.4083499908447266
Validation loss: 2.7575798983215005

Epoch: 6| Step: 8
Training loss: 2.892557144165039
Validation loss: 2.7627133066936205

Epoch: 6| Step: 9
Training loss: 2.8179593086242676
Validation loss: 2.756145559331422

Epoch: 6| Step: 10
Training loss: 4.413975715637207
Validation loss: 2.7562755025843138

Epoch: 6| Step: 11
Training loss: 1.999704360961914
Validation loss: 2.7580678488618586

Epoch: 6| Step: 12
Training loss: 2.0580058097839355
Validation loss: 2.763274005664292

Epoch: 6| Step: 13
Training loss: 3.3946964740753174
Validation loss: 2.7632553731241534

Epoch: 13| Step: 0
Training loss: 3.06669282913208
Validation loss: 2.743274493884015

Epoch: 6| Step: 1
Training loss: 2.4317188262939453
Validation loss: 2.7454638070957635

Epoch: 6| Step: 2
Training loss: 3.250561237335205
Validation loss: 2.7609572615674747

Epoch: 6| Step: 3
Training loss: 2.883549451828003
Validation loss: 2.779029953864313

Epoch: 6| Step: 4
Training loss: 2.770827293395996
Validation loss: 2.746206029768913

Epoch: 6| Step: 5
Training loss: 3.173274278640747
Validation loss: 2.7423408646737375

Epoch: 6| Step: 6
Training loss: 3.06123685836792
Validation loss: 2.7424314765519995

Epoch: 6| Step: 7
Training loss: 2.7677390575408936
Validation loss: 2.7497073886215047

Epoch: 6| Step: 8
Training loss: 2.996936798095703
Validation loss: 2.7950507081964964

Epoch: 6| Step: 9
Training loss: 2.3704991340637207
Validation loss: 2.7817567548444195

Epoch: 6| Step: 10
Training loss: 3.4219703674316406
Validation loss: 2.734424547482562

Epoch: 6| Step: 11
Training loss: 2.8711137771606445
Validation loss: 2.729337615351523

Epoch: 6| Step: 12
Training loss: 2.7385506629943848
Validation loss: 2.7461716974935224

Epoch: 6| Step: 13
Training loss: 2.661839485168457
Validation loss: 2.7665877649860997

Epoch: 14| Step: 0
Training loss: 3.230863571166992
Validation loss: 2.8685042191577215

Epoch: 6| Step: 1
Training loss: 3.2259087562561035
Validation loss: 2.902548884832731

Epoch: 6| Step: 2
Training loss: 3.2978298664093018
Validation loss: 2.904374796857116

Epoch: 6| Step: 3
Training loss: 2.720324754714966
Validation loss: 2.753101387331563

Epoch: 6| Step: 4
Training loss: 2.400724411010742
Validation loss: 2.7202047481331775

Epoch: 6| Step: 5
Training loss: 2.5309641361236572
Validation loss: 2.7318387441737677

Epoch: 6| Step: 6
Training loss: 2.6711130142211914
Validation loss: 2.7911872735587497

Epoch: 6| Step: 7
Training loss: 2.759190320968628
Validation loss: 2.8168894219142135

Epoch: 6| Step: 8
Training loss: 3.136906862258911
Validation loss: 2.8049162997994372

Epoch: 6| Step: 9
Training loss: 2.4549179077148438
Validation loss: 2.727885170649457

Epoch: 6| Step: 10
Training loss: 3.396794319152832
Validation loss: 2.7167392776858423

Epoch: 6| Step: 11
Training loss: 3.0018277168273926
Validation loss: 2.719480078707459

Epoch: 6| Step: 12
Training loss: 2.739386796951294
Validation loss: 2.725858457626835

Epoch: 6| Step: 13
Training loss: 3.7958734035491943
Validation loss: 2.7311544828517462

Epoch: 15| Step: 0
Training loss: 2.600398063659668
Validation loss: 2.719051089338077

Epoch: 6| Step: 1
Training loss: 2.356292247772217
Validation loss: 2.7121997597397014

Epoch: 6| Step: 2
Training loss: 2.3881053924560547
Validation loss: 2.7095479426845426

Epoch: 6| Step: 3
Training loss: 3.726792097091675
Validation loss: 2.7075514588304745

Epoch: 6| Step: 4
Training loss: 1.891587495803833
Validation loss: 2.708271836721769

Epoch: 6| Step: 5
Training loss: 2.7769699096679688
Validation loss: 2.718411317435644

Epoch: 6| Step: 6
Training loss: 2.5228757858276367
Validation loss: 2.7157564317026446

Epoch: 6| Step: 7
Training loss: 2.7429449558258057
Validation loss: 2.723535583865258

Epoch: 6| Step: 8
Training loss: 3.684084892272949
Validation loss: 2.719906378817815

Epoch: 6| Step: 9
Training loss: 2.6981019973754883
Validation loss: 2.7206979233731508

Epoch: 6| Step: 10
Training loss: 3.402454376220703
Validation loss: 2.6962421401854484

Epoch: 6| Step: 11
Training loss: 3.242703437805176
Validation loss: 2.691110211033975

Epoch: 6| Step: 12
Training loss: 3.3170483112335205
Validation loss: 2.690032491119959

Epoch: 6| Step: 13
Training loss: 2.7788240909576416
Validation loss: 2.6948009767839984

Epoch: 16| Step: 0
Training loss: 2.6748886108398438
Validation loss: 2.6921405100053355

Epoch: 6| Step: 1
Training loss: 2.4352681636810303
Validation loss: 2.695358548113095

Epoch: 6| Step: 2
Training loss: 2.3831050395965576
Validation loss: 2.693956108503444

Epoch: 6| Step: 3
Training loss: 3.102787494659424
Validation loss: 2.687059356320289

Epoch: 6| Step: 4
Training loss: 3.2997779846191406
Validation loss: 2.679216374633133

Epoch: 6| Step: 5
Training loss: 3.736767530441284
Validation loss: 2.678105472236551

Epoch: 6| Step: 6
Training loss: 2.6894912719726562
Validation loss: 2.6778974609990276

Epoch: 6| Step: 7
Training loss: 3.081486701965332
Validation loss: 2.6834436539680726

Epoch: 6| Step: 8
Training loss: 2.561669111251831
Validation loss: 2.702737908209524

Epoch: 6| Step: 9
Training loss: 3.0544819831848145
Validation loss: 2.7027206420898438

Epoch: 6| Step: 10
Training loss: 3.004262924194336
Validation loss: 2.67505709842969

Epoch: 6| Step: 11
Training loss: 2.3442492485046387
Validation loss: 2.6727309944809123

Epoch: 6| Step: 12
Training loss: 2.483915090560913
Validation loss: 2.6704187829007386

Epoch: 6| Step: 13
Training loss: 3.35384464263916
Validation loss: 2.671574338789909

Epoch: 17| Step: 0
Training loss: 2.630204200744629
Validation loss: 2.669632716845441

Epoch: 6| Step: 1
Training loss: 2.630051374435425
Validation loss: 2.6767529159463863

Epoch: 6| Step: 2
Training loss: 2.971100330352783
Validation loss: 2.6735882092547674

Epoch: 6| Step: 3
Training loss: 2.714150905609131
Validation loss: 2.672862378499841

Epoch: 6| Step: 4
Training loss: 2.7269954681396484
Validation loss: 2.670217416619742

Epoch: 6| Step: 5
Training loss: 3.3843789100646973
Validation loss: 2.6661888655795845

Epoch: 6| Step: 6
Training loss: 2.496075391769409
Validation loss: 2.6633044160822386

Epoch: 6| Step: 7
Training loss: 3.01027774810791
Validation loss: 2.660139517117572

Epoch: 6| Step: 8
Training loss: 3.6412315368652344
Validation loss: 2.6585501317054994

Epoch: 6| Step: 9
Training loss: 2.707831621170044
Validation loss: 2.656057239860617

Epoch: 6| Step: 10
Training loss: 2.5665316581726074
Validation loss: 2.6565356844214985

Epoch: 6| Step: 11
Training loss: 2.473576784133911
Validation loss: 2.6676710472312024

Epoch: 6| Step: 12
Training loss: 3.4686503410339355
Validation loss: 2.6730537312005156

Epoch: 6| Step: 13
Training loss: 1.952989101409912
Validation loss: 2.672197090682163

Epoch: 18| Step: 0
Training loss: 3.1428823471069336
Validation loss: 2.664873294932868

Epoch: 6| Step: 1
Training loss: 3.1032052040100098
Validation loss: 2.659527781189129

Epoch: 6| Step: 2
Training loss: 2.39654541015625
Validation loss: 2.6498127214370237

Epoch: 6| Step: 3
Training loss: 2.920605182647705
Validation loss: 2.642084229377008

Epoch: 6| Step: 4
Training loss: 1.976294994354248
Validation loss: 2.641951907065607

Epoch: 6| Step: 5
Training loss: 2.5934698581695557
Validation loss: 2.6450504103014545

Epoch: 6| Step: 6
Training loss: 3.383197069168091
Validation loss: 2.6545095828271683

Epoch: 6| Step: 7
Training loss: 2.289283275604248
Validation loss: 2.654860124793104

Epoch: 6| Step: 8
Training loss: 3.985490560531616
Validation loss: 2.646068937035017

Epoch: 6| Step: 9
Training loss: 2.5133049488067627
Validation loss: 2.6437484936047624

Epoch: 6| Step: 10
Training loss: 2.7932393550872803
Validation loss: 2.639990250269572

Epoch: 6| Step: 11
Training loss: 3.1466264724731445
Validation loss: 2.6389293619381484

Epoch: 6| Step: 12
Training loss: 2.142979621887207
Validation loss: 2.6361659137151574

Epoch: 6| Step: 13
Training loss: 3.401710033416748
Validation loss: 2.633008844108992

Epoch: 19| Step: 0
Training loss: 2.7616689205169678
Validation loss: 2.6404325423702115

Epoch: 6| Step: 1
Training loss: 2.5922250747680664
Validation loss: 2.63288293346282

Epoch: 6| Step: 2
Training loss: 2.615933656692505
Validation loss: 2.636525223332067

Epoch: 6| Step: 3
Training loss: 3.012988567352295
Validation loss: 2.648191918608963

Epoch: 6| Step: 4
Training loss: 2.55367374420166
Validation loss: 2.6405413355878604

Epoch: 6| Step: 5
Training loss: 2.3965775966644287
Validation loss: 2.647227220637824

Epoch: 6| Step: 6
Training loss: 2.9368224143981934
Validation loss: 2.63994917561931

Epoch: 6| Step: 7
Training loss: 2.7626090049743652
Validation loss: 2.6264916030309533

Epoch: 6| Step: 8
Training loss: 3.009733200073242
Validation loss: 2.6218846997907086

Epoch: 6| Step: 9
Training loss: 3.4937210083007812
Validation loss: 2.617319440328947

Epoch: 6| Step: 10
Training loss: 2.718945026397705
Validation loss: 2.62322602733489

Epoch: 6| Step: 11
Training loss: 3.232504367828369
Validation loss: 2.622956988632038

Epoch: 6| Step: 12
Training loss: 2.7428603172302246
Validation loss: 2.6139993975239415

Epoch: 6| Step: 13
Training loss: 2.456345319747925
Validation loss: 2.623997019183251

Epoch: 20| Step: 0
Training loss: 2.6380743980407715
Validation loss: 2.6340147167123775

Epoch: 6| Step: 1
Training loss: 2.9766626358032227
Validation loss: 2.71293197395981

Epoch: 6| Step: 2
Training loss: 2.2775306701660156
Validation loss: 2.7519626796886487

Epoch: 6| Step: 3
Training loss: 3.087416172027588
Validation loss: 2.69417433328526

Epoch: 6| Step: 4
Training loss: 2.733355760574341
Validation loss: 2.643045663833618

Epoch: 6| Step: 5
Training loss: 3.4888644218444824
Validation loss: 2.6180683438495924

Epoch: 6| Step: 6
Training loss: 3.2049977779388428
Validation loss: 2.621678667683755

Epoch: 6| Step: 7
Training loss: 2.4454288482666016
Validation loss: 2.6299499170754546

Epoch: 6| Step: 8
Training loss: 2.8470687866210938
Validation loss: 2.641611691444151

Epoch: 6| Step: 9
Training loss: 2.7188196182250977
Validation loss: 2.6454459210877777

Epoch: 6| Step: 10
Training loss: 2.5111188888549805
Validation loss: 2.6280243730032318

Epoch: 6| Step: 11
Training loss: 2.67340350151062
Validation loss: 2.6131545600070747

Epoch: 6| Step: 12
Training loss: 3.127610683441162
Validation loss: 2.6061578719846663

Epoch: 6| Step: 13
Training loss: 2.984727621078491
Validation loss: 2.601850640389227

Epoch: 21| Step: 0
Training loss: 2.7639899253845215
Validation loss: 2.5999956284799883

Epoch: 6| Step: 1
Training loss: 2.3720006942749023
Validation loss: 2.598924293312975

Epoch: 6| Step: 2
Training loss: 2.8619964122772217
Validation loss: 2.6028352655390257

Epoch: 6| Step: 3
Training loss: 2.766714572906494
Validation loss: 2.603599153539186

Epoch: 6| Step: 4
Training loss: 2.998650312423706
Validation loss: 2.6242632558268886

Epoch: 6| Step: 5
Training loss: 2.467658758163452
Validation loss: 2.6446812345135595

Epoch: 6| Step: 6
Training loss: 3.5807228088378906
Validation loss: 2.6604131806281304

Epoch: 6| Step: 7
Training loss: 2.4904403686523438
Validation loss: 2.6505240650587183

Epoch: 6| Step: 8
Training loss: 2.575908660888672
Validation loss: 2.6215932702505462

Epoch: 6| Step: 9
Training loss: 2.6473422050476074
Validation loss: 2.592880364387266

Epoch: 6| Step: 10
Training loss: 3.021252155303955
Validation loss: 2.588232442896853

Epoch: 6| Step: 11
Training loss: 2.9460692405700684
Validation loss: 2.5902464107800554

Epoch: 6| Step: 12
Training loss: 2.524905204772949
Validation loss: 2.5930195726374143

Epoch: 6| Step: 13
Training loss: 3.5182831287384033
Validation loss: 2.603855384293423

Epoch: 22| Step: 0
Training loss: 3.335814952850342
Validation loss: 2.612188252069617

Epoch: 6| Step: 1
Training loss: 3.3017187118530273
Validation loss: 2.6027302178003455

Epoch: 6| Step: 2
Training loss: 2.2729296684265137
Validation loss: 2.588833298734439

Epoch: 6| Step: 3
Training loss: 2.7016592025756836
Validation loss: 2.584422319166122

Epoch: 6| Step: 4
Training loss: 2.5054845809936523
Validation loss: 2.580101987367035

Epoch: 6| Step: 5
Training loss: 2.942373037338257
Validation loss: 2.605546453947662

Epoch: 6| Step: 6
Training loss: 3.0691747665405273
Validation loss: 2.6337174574534097

Epoch: 6| Step: 7
Training loss: 2.6796839237213135
Validation loss: 2.642836719430903

Epoch: 6| Step: 8
Training loss: 2.3643369674682617
Validation loss: 2.650780229158299

Epoch: 6| Step: 9
Training loss: 2.756560802459717
Validation loss: 2.6569004956112114

Epoch: 6| Step: 10
Training loss: 2.837313175201416
Validation loss: 2.627346859183363

Epoch: 6| Step: 11
Training loss: 2.154039144515991
Validation loss: 2.6258116332433556

Epoch: 6| Step: 12
Training loss: 3.224823474884033
Validation loss: 2.6213220601440756

Epoch: 6| Step: 13
Training loss: 3.0745534896850586
Validation loss: 2.6213720998456402

Epoch: 23| Step: 0
Training loss: 2.6444976329803467
Validation loss: 2.6269480105369323

Epoch: 6| Step: 1
Training loss: 2.76126766204834
Validation loss: 2.605563827740249

Epoch: 6| Step: 2
Training loss: 2.362666368484497
Validation loss: 2.573385433484149

Epoch: 6| Step: 3
Training loss: 3.454984188079834
Validation loss: 2.5737475349057104

Epoch: 6| Step: 4
Training loss: 2.5082778930664062
Validation loss: 2.57482268733363

Epoch: 6| Step: 5
Training loss: 2.5778889656066895
Validation loss: 2.5846497448541785

Epoch: 6| Step: 6
Training loss: 2.9586257934570312
Validation loss: 2.577970935452369

Epoch: 6| Step: 7
Training loss: 3.102328300476074
Validation loss: 2.5709936670077744

Epoch: 6| Step: 8
Training loss: 3.4762444496154785
Validation loss: 2.5726452386507423

Epoch: 6| Step: 9
Training loss: 2.69907808303833
Validation loss: 2.5662411053975425

Epoch: 6| Step: 10
Training loss: 2.7071285247802734
Validation loss: 2.566097059557515

Epoch: 6| Step: 11
Training loss: 2.70375919342041
Validation loss: 2.5716978913994244

Epoch: 6| Step: 12
Training loss: 2.406787872314453
Validation loss: 2.5761309926227858

Epoch: 6| Step: 13
Training loss: 2.1627185344696045
Validation loss: 2.588642822798862

Epoch: 24| Step: 0
Training loss: 3.3981828689575195
Validation loss: 2.5844462789515013

Epoch: 6| Step: 1
Training loss: 3.311990737915039
Validation loss: 2.5776622013379167

Epoch: 6| Step: 2
Training loss: 2.1104116439819336
Validation loss: 2.5575464848549134

Epoch: 6| Step: 3
Training loss: 2.691279888153076
Validation loss: 2.5571463954064155

Epoch: 6| Step: 4
Training loss: 1.9516887664794922
Validation loss: 2.560298683822796

Epoch: 6| Step: 5
Training loss: 2.8875155448913574
Validation loss: 2.557797157636253

Epoch: 6| Step: 6
Training loss: 2.5385589599609375
Validation loss: 2.556207405623569

Epoch: 6| Step: 7
Training loss: 3.074855327606201
Validation loss: 2.555226074751987

Epoch: 6| Step: 8
Training loss: 3.4671740531921387
Validation loss: 2.5583665345304754

Epoch: 6| Step: 9
Training loss: 3.072134256362915
Validation loss: 2.5568264402369016

Epoch: 6| Step: 10
Training loss: 2.566183090209961
Validation loss: 2.5507487122730543

Epoch: 6| Step: 11
Training loss: 2.066922426223755
Validation loss: 2.547012165028562

Epoch: 6| Step: 12
Training loss: 2.5441505908966064
Validation loss: 2.554685866960915

Epoch: 6| Step: 13
Training loss: 2.969050407409668
Validation loss: 2.5673587706781205

Epoch: 25| Step: 0
Training loss: 2.4291865825653076
Validation loss: 2.5733817879871657

Epoch: 6| Step: 1
Training loss: 2.534184455871582
Validation loss: 2.5672775160881782

Epoch: 6| Step: 2
Training loss: 1.880443811416626
Validation loss: 2.5547236216965543

Epoch: 6| Step: 3
Training loss: 3.0456297397613525
Validation loss: 2.5500169005445255

Epoch: 6| Step: 4
Training loss: 3.24165415763855
Validation loss: 2.5431570468410367

Epoch: 6| Step: 5
Training loss: 2.7783937454223633
Validation loss: 2.5408062678511425

Epoch: 6| Step: 6
Training loss: 3.0882043838500977
Validation loss: 2.539452081085533

Epoch: 6| Step: 7
Training loss: 3.1040072441101074
Validation loss: 2.539131861861034

Epoch: 6| Step: 8
Training loss: 2.884458541870117
Validation loss: 2.559908720754808

Epoch: 6| Step: 9
Training loss: 2.080432891845703
Validation loss: 2.5318855136953373

Epoch: 6| Step: 10
Training loss: 2.470097064971924
Validation loss: 2.5296793342918478

Epoch: 6| Step: 11
Training loss: 2.690898895263672
Validation loss: 2.5314906053645636

Epoch: 6| Step: 12
Training loss: 3.020137310028076
Validation loss: 2.5404302791882585

Epoch: 6| Step: 13
Training loss: 3.19246768951416
Validation loss: 2.554282001269761

Epoch: 26| Step: 0
Training loss: 3.0477547645568848
Validation loss: 2.5503021004379436

Epoch: 6| Step: 1
Training loss: 2.1696906089782715
Validation loss: 2.5478001256142893

Epoch: 6| Step: 2
Training loss: 2.6020305156707764
Validation loss: 2.5415142761763705

Epoch: 6| Step: 3
Training loss: 2.2455782890319824
Validation loss: 2.5239264170328775

Epoch: 6| Step: 4
Training loss: 2.595616340637207
Validation loss: 2.5210164541839273

Epoch: 6| Step: 5
Training loss: 2.9128732681274414
Validation loss: 2.517485469900152

Epoch: 6| Step: 6
Training loss: 2.7280242443084717
Validation loss: 2.513033600263698

Epoch: 6| Step: 7
Training loss: 2.804699420928955
Validation loss: 2.5154716763445126

Epoch: 6| Step: 8
Training loss: 2.8644886016845703
Validation loss: 2.521645397268316

Epoch: 6| Step: 9
Training loss: 3.1527390480041504
Validation loss: 2.53527743329284

Epoch: 6| Step: 10
Training loss: 2.9763169288635254
Validation loss: 2.546891317572645

Epoch: 6| Step: 11
Training loss: 3.0196566581726074
Validation loss: 2.5497690195678384

Epoch: 6| Step: 12
Training loss: 2.4554572105407715
Validation loss: 2.5461408092129614

Epoch: 6| Step: 13
Training loss: 2.0423154830932617
Validation loss: 2.5218104059978197

Epoch: 27| Step: 0
Training loss: 2.436563491821289
Validation loss: 2.5236434654522966

Epoch: 6| Step: 1
Training loss: 2.672635555267334
Validation loss: 2.5147602711954424

Epoch: 6| Step: 2
Training loss: 4.008925914764404
Validation loss: 2.5165941458876415

Epoch: 6| Step: 3
Training loss: 2.2042524814605713
Validation loss: 2.5220528187290316

Epoch: 6| Step: 4
Training loss: 2.9582531452178955
Validation loss: 2.5139192919577322

Epoch: 6| Step: 5
Training loss: 2.4133806228637695
Validation loss: 2.5012410481770835

Epoch: 6| Step: 6
Training loss: 2.2025279998779297
Validation loss: 2.508234534212338

Epoch: 6| Step: 7
Training loss: 3.4331560134887695
Validation loss: 2.5247786685984623

Epoch: 6| Step: 8
Training loss: 2.1049773693084717
Validation loss: 2.5401929757928334

Epoch: 6| Step: 9
Training loss: 2.2626519203186035
Validation loss: 2.544959045225574

Epoch: 6| Step: 10
Training loss: 2.9218664169311523
Validation loss: 2.535494742854949

Epoch: 6| Step: 11
Training loss: 3.1620426177978516
Validation loss: 2.517017645220603

Epoch: 6| Step: 12
Training loss: 2.772458553314209
Validation loss: 2.5064659169925156

Epoch: 6| Step: 13
Training loss: 2.5241105556488037
Validation loss: 2.504139756643644

Epoch: 28| Step: 0
Training loss: 2.8828659057617188
Validation loss: 2.4993036293214366

Epoch: 6| Step: 1
Training loss: 2.022031307220459
Validation loss: 2.494753186420728

Epoch: 6| Step: 2
Training loss: 1.836755633354187
Validation loss: 2.511280523833408

Epoch: 6| Step: 3
Training loss: 2.1795005798339844
Validation loss: 2.526063157666114

Epoch: 6| Step: 4
Training loss: 3.0026845932006836
Validation loss: 2.5147462660266506

Epoch: 6| Step: 5
Training loss: 3.01252818107605
Validation loss: 2.5013330213485228

Epoch: 6| Step: 6
Training loss: 2.5087506771087646
Validation loss: 2.4929140613925074

Epoch: 6| Step: 7
Training loss: 3.00618314743042
Validation loss: 2.491706091870544

Epoch: 6| Step: 8
Training loss: 3.3102922439575195
Validation loss: 2.4937918801461496

Epoch: 6| Step: 9
Training loss: 3.3429007530212402
Validation loss: 2.49947755054761

Epoch: 6| Step: 10
Training loss: 2.6931395530700684
Validation loss: 2.501568471231768

Epoch: 6| Step: 11
Training loss: 2.8693583011627197
Validation loss: 2.4974326574674217

Epoch: 6| Step: 12
Training loss: 2.5748252868652344
Validation loss: 2.4959654936226467

Epoch: 6| Step: 13
Training loss: 2.770756721496582
Validation loss: 2.4896455862188853

Epoch: 29| Step: 0
Training loss: 1.9431469440460205
Validation loss: 2.4850431334587837

Epoch: 6| Step: 1
Training loss: 3.1516125202178955
Validation loss: 2.483179456444197

Epoch: 6| Step: 2
Training loss: 2.13222599029541
Validation loss: 2.480532359051448

Epoch: 6| Step: 3
Training loss: 2.3407654762268066
Validation loss: 2.4848321637799664

Epoch: 6| Step: 4
Training loss: 2.916923999786377
Validation loss: 2.507963490742509

Epoch: 6| Step: 5
Training loss: 2.3841490745544434
Validation loss: 2.5140432875643492

Epoch: 6| Step: 6
Training loss: 2.1533279418945312
Validation loss: 2.5346344260759253

Epoch: 6| Step: 7
Training loss: 3.4007134437561035
Validation loss: 2.5589792818151493

Epoch: 6| Step: 8
Training loss: 2.9831552505493164
Validation loss: 2.5463746183662006

Epoch: 6| Step: 9
Training loss: 3.0533125400543213
Validation loss: 2.519629950164467

Epoch: 6| Step: 10
Training loss: 3.083806276321411
Validation loss: 2.4906998526665474

Epoch: 6| Step: 11
Training loss: 2.0072109699249268
Validation loss: 2.4733433082539547

Epoch: 6| Step: 12
Training loss: 3.1669235229492188
Validation loss: 2.4800421550709713

Epoch: 6| Step: 13
Training loss: 3.4438915252685547
Validation loss: 2.5099370325765302

Epoch: 30| Step: 0
Training loss: 1.765300989151001
Validation loss: 2.492536675545477

Epoch: 6| Step: 1
Training loss: 3.3716702461242676
Validation loss: 2.482615291431386

Epoch: 6| Step: 2
Training loss: 3.5499582290649414
Validation loss: 2.472471042345929

Epoch: 6| Step: 3
Training loss: 2.562155246734619
Validation loss: 2.468870803874026

Epoch: 6| Step: 4
Training loss: 3.058560371398926
Validation loss: 2.48108156265751

Epoch: 6| Step: 5
Training loss: 2.602334499359131
Validation loss: 2.49447109365976

Epoch: 6| Step: 6
Training loss: 3.10927152633667
Validation loss: 2.486830683164699

Epoch: 6| Step: 7
Training loss: 2.818850040435791
Validation loss: 2.4901767417948735

Epoch: 6| Step: 8
Training loss: 2.8533408641815186
Validation loss: 2.511048388737504

Epoch: 6| Step: 9
Training loss: 2.117950916290283
Validation loss: 2.477629710269231

Epoch: 6| Step: 10
Training loss: 2.880457878112793
Validation loss: 2.4811754559957855

Epoch: 6| Step: 11
Training loss: 2.457655668258667
Validation loss: 2.4705196913852485

Epoch: 6| Step: 12
Training loss: 1.792151927947998
Validation loss: 2.462823342251521

Epoch: 6| Step: 13
Training loss: 2.9124550819396973
Validation loss: 2.4541631975481586

Epoch: 31| Step: 0
Training loss: 3.1649210453033447
Validation loss: 2.458470042033862

Epoch: 6| Step: 1
Training loss: 1.576765775680542
Validation loss: 2.4684310472139748

Epoch: 6| Step: 2
Training loss: 3.8212132453918457
Validation loss: 2.4673449582951044

Epoch: 6| Step: 3
Training loss: 2.3058040142059326
Validation loss: 2.4545329411824546

Epoch: 6| Step: 4
Training loss: 2.1129884719848633
Validation loss: 2.463656794640326

Epoch: 6| Step: 5
Training loss: 2.6800875663757324
Validation loss: 2.4849265736918293

Epoch: 6| Step: 6
Training loss: 2.8531360626220703
Validation loss: 2.50862019805498

Epoch: 6| Step: 7
Training loss: 2.0628161430358887
Validation loss: 2.542303503200572

Epoch: 6| Step: 8
Training loss: 2.9071788787841797
Validation loss: 2.5621822264886673

Epoch: 6| Step: 9
Training loss: 2.673685073852539
Validation loss: 2.5348146807762886

Epoch: 6| Step: 10
Training loss: 2.929253101348877
Validation loss: 2.5384727113990375

Epoch: 6| Step: 11
Training loss: 3.305809497833252
Validation loss: 2.562362758062219

Epoch: 6| Step: 12
Training loss: 3.0898656845092773
Validation loss: 2.5658857617326962

Epoch: 6| Step: 13
Training loss: 2.640852689743042
Validation loss: 2.5448833716812955

Epoch: 32| Step: 0
Training loss: 2.625685214996338
Validation loss: 2.5191281328919115

Epoch: 6| Step: 1
Training loss: 3.0168447494506836
Validation loss: 2.4717706377788256

Epoch: 6| Step: 2
Training loss: 2.3753271102905273
Validation loss: 2.46758238474528

Epoch: 6| Step: 3
Training loss: 2.761767625808716
Validation loss: 2.4637479192467144

Epoch: 6| Step: 4
Training loss: 2.500870704650879
Validation loss: 2.4843574980253815

Epoch: 6| Step: 5
Training loss: 2.264749526977539
Validation loss: 2.527661315856441

Epoch: 6| Step: 6
Training loss: 3.4478530883789062
Validation loss: 2.5404061066207064

Epoch: 6| Step: 7
Training loss: 2.1909666061401367
Validation loss: 2.5353258117552726

Epoch: 6| Step: 8
Training loss: 2.7540698051452637
Validation loss: 2.501499019643312

Epoch: 6| Step: 9
Training loss: 2.778439521789551
Validation loss: 2.459935957385648

Epoch: 6| Step: 10
Training loss: 2.6576924324035645
Validation loss: 2.4535177189816713

Epoch: 6| Step: 11
Training loss: 3.1343584060668945
Validation loss: 2.4607966766562512

Epoch: 6| Step: 12
Training loss: 2.3155601024627686
Validation loss: 2.4678680768577

Epoch: 6| Step: 13
Training loss: 3.4394309520721436
Validation loss: 2.474728527889457

Epoch: 33| Step: 0
Training loss: 2.8307549953460693
Validation loss: 2.4745718125374085

Epoch: 6| Step: 1
Training loss: 2.5115365982055664
Validation loss: 2.4634641421738492

Epoch: 6| Step: 2
Training loss: 2.4146461486816406
Validation loss: 2.455594062805176

Epoch: 6| Step: 3
Training loss: 2.682121753692627
Validation loss: 2.4471406039371284

Epoch: 6| Step: 4
Training loss: 2.136552333831787
Validation loss: 2.442235674909366

Epoch: 6| Step: 5
Training loss: 2.953660249710083
Validation loss: 2.436531138676469

Epoch: 6| Step: 6
Training loss: 1.9780173301696777
Validation loss: 2.4611886086002475

Epoch: 6| Step: 7
Training loss: 2.7719950675964355
Validation loss: 2.4800796636971096

Epoch: 6| Step: 8
Training loss: 3.506232261657715
Validation loss: 2.4587973702338433

Epoch: 6| Step: 9
Training loss: 3.5131616592407227
Validation loss: 2.4310252410109325

Epoch: 6| Step: 10
Training loss: 1.739538311958313
Validation loss: 2.428325573603312

Epoch: 6| Step: 11
Training loss: 2.911867618560791
Validation loss: 2.426895600493236

Epoch: 6| Step: 12
Training loss: 2.588254928588867
Validation loss: 2.4298879587522118

Epoch: 6| Step: 13
Training loss: 3.374661445617676
Validation loss: 2.4262706310518327

Epoch: 34| Step: 0
Training loss: 2.6984572410583496
Validation loss: 2.4266357319329375

Epoch: 6| Step: 1
Training loss: 2.835573196411133
Validation loss: 2.4296205069429133

Epoch: 6| Step: 2
Training loss: 2.370974540710449
Validation loss: 2.4293899228495937

Epoch: 6| Step: 3
Training loss: 2.7338411808013916
Validation loss: 2.436097057916785

Epoch: 6| Step: 4
Training loss: 2.6852476596832275
Validation loss: 2.4499610316368843

Epoch: 6| Step: 5
Training loss: 2.6435954570770264
Validation loss: 2.4810908789275796

Epoch: 6| Step: 6
Training loss: 3.8699305057525635
Validation loss: 2.5284153620402017

Epoch: 6| Step: 7
Training loss: 2.442262649536133
Validation loss: 2.465213878180391

Epoch: 6| Step: 8
Training loss: 2.3495635986328125
Validation loss: 2.455459628053891

Epoch: 6| Step: 9
Training loss: 2.7502875328063965
Validation loss: 2.453449450513368

Epoch: 6| Step: 10
Training loss: 2.2967405319213867
Validation loss: 2.494819518058531

Epoch: 6| Step: 11
Training loss: 2.830965280532837
Validation loss: 2.52556868778762

Epoch: 6| Step: 12
Training loss: 2.6828627586364746
Validation loss: 2.4951611488096175

Epoch: 6| Step: 13
Training loss: 2.0108273029327393
Validation loss: 2.5035249212736725

Epoch: 35| Step: 0
Training loss: 2.944239377975464
Validation loss: 2.501568219994986

Epoch: 6| Step: 1
Training loss: 2.0409293174743652
Validation loss: 2.4982254723066926

Epoch: 6| Step: 2
Training loss: 3.1263484954833984
Validation loss: 2.5068146464645222

Epoch: 6| Step: 3
Training loss: 1.6673288345336914
Validation loss: 2.5054145474587717

Epoch: 6| Step: 4
Training loss: 2.9167096614837646
Validation loss: 2.495820230053317

Epoch: 6| Step: 5
Training loss: 2.9032788276672363
Validation loss: 2.49140065972523

Epoch: 6| Step: 6
Training loss: 2.56699538230896
Validation loss: 2.4848937116643435

Epoch: 6| Step: 7
Training loss: 3.3846049308776855
Validation loss: 2.482363336829729

Epoch: 6| Step: 8
Training loss: 3.209430456161499
Validation loss: 2.4835267810411352

Epoch: 6| Step: 9
Training loss: 2.8570339679718018
Validation loss: 2.4888967314074115

Epoch: 6| Step: 10
Training loss: 1.9530065059661865
Validation loss: 2.4999731715007494

Epoch: 6| Step: 11
Training loss: 2.491438865661621
Validation loss: 2.492367770082207

Epoch: 6| Step: 12
Training loss: 2.478849411010742
Validation loss: 2.473189693625255

Epoch: 6| Step: 13
Training loss: 3.207221746444702
Validation loss: 2.4627163307641142

Epoch: 36| Step: 0
Training loss: 2.723267078399658
Validation loss: 2.4655421190364386

Epoch: 6| Step: 1
Training loss: 3.154229164123535
Validation loss: 2.477531176741405

Epoch: 6| Step: 2
Training loss: 3.7520663738250732
Validation loss: 2.465459010934317

Epoch: 6| Step: 3
Training loss: 2.0831949710845947
Validation loss: 2.4457323910087667

Epoch: 6| Step: 4
Training loss: 3.1129603385925293
Validation loss: 2.4679947360869376

Epoch: 6| Step: 5
Training loss: 1.871910572052002
Validation loss: 2.482071045906313

Epoch: 6| Step: 6
Training loss: 2.6315550804138184
Validation loss: 2.4818679953134186

Epoch: 6| Step: 7
Training loss: 2.4137096405029297
Validation loss: 2.4480106446050827

Epoch: 6| Step: 8
Training loss: 2.7140305042266846
Validation loss: 2.4252456772711968

Epoch: 6| Step: 9
Training loss: 2.4638891220092773
Validation loss: 2.414942144065775

Epoch: 6| Step: 10
Training loss: 2.447779417037964
Validation loss: 2.403647376644996

Epoch: 6| Step: 11
Training loss: 2.6221017837524414
Validation loss: 2.400274093433093

Epoch: 6| Step: 12
Training loss: 2.8098764419555664
Validation loss: 2.414816138564899

Epoch: 6| Step: 13
Training loss: 2.701040506362915
Validation loss: 2.4312408688247844

Epoch: 37| Step: 0
Training loss: 2.5608432292938232
Validation loss: 2.446304831453549

Epoch: 6| Step: 1
Training loss: 3.0029397010803223
Validation loss: 2.428562661652924

Epoch: 6| Step: 2
Training loss: 3.065852642059326
Validation loss: 2.410148274513983

Epoch: 6| Step: 3
Training loss: 2.3409855365753174
Validation loss: 2.3844432164263982

Epoch: 6| Step: 4
Training loss: 2.55863618850708
Validation loss: 2.3866667850043184

Epoch: 6| Step: 5
Training loss: 2.4540772438049316
Validation loss: 2.392352778424499

Epoch: 6| Step: 6
Training loss: 2.988903522491455
Validation loss: 2.4040688084017847

Epoch: 6| Step: 7
Training loss: 2.504310131072998
Validation loss: 2.3935735123131865

Epoch: 6| Step: 8
Training loss: 2.57535457611084
Validation loss: 2.432418297695857

Epoch: 6| Step: 9
Training loss: 2.8055429458618164
Validation loss: 2.4637512955614316

Epoch: 6| Step: 10
Training loss: 2.861037015914917
Validation loss: 2.4934228158766225

Epoch: 6| Step: 11
Training loss: 2.2534968852996826
Validation loss: 2.462770099280983

Epoch: 6| Step: 12
Training loss: 2.4634346961975098
Validation loss: 2.4467009164953746

Epoch: 6| Step: 13
Training loss: 2.9544870853424072
Validation loss: 2.3931727050453104

Epoch: 38| Step: 0
Training loss: 1.9795717000961304
Validation loss: 2.367168790550642

Epoch: 6| Step: 1
Training loss: 2.730515480041504
Validation loss: 2.3689110932811612

Epoch: 6| Step: 2
Training loss: 2.322061538696289
Validation loss: 2.3696538222733365

Epoch: 6| Step: 3
Training loss: 3.38258957862854
Validation loss: 2.372876057060816

Epoch: 6| Step: 4
Training loss: 2.8591246604919434
Validation loss: 2.372982443019908

Epoch: 6| Step: 5
Training loss: 3.21671986579895
Validation loss: 2.368340733230755

Epoch: 6| Step: 6
Training loss: 2.0936484336853027
Validation loss: 2.365590585175381

Epoch: 6| Step: 7
Training loss: 2.4198527336120605
Validation loss: 2.3723264407086115

Epoch: 6| Step: 8
Training loss: 2.7383499145507812
Validation loss: 2.3776259191574587

Epoch: 6| Step: 9
Training loss: 2.6971206665039062
Validation loss: 2.382579626575593

Epoch: 6| Step: 10
Training loss: 2.2487049102783203
Validation loss: 2.3919503073538504

Epoch: 6| Step: 11
Training loss: 2.849567413330078
Validation loss: 2.39607826868693

Epoch: 6| Step: 12
Training loss: 2.878185749053955
Validation loss: 2.383007455897588

Epoch: 6| Step: 13
Training loss: 2.3880701065063477
Validation loss: 2.374220076427665

Epoch: 39| Step: 0
Training loss: 3.304633855819702
Validation loss: 2.3718061216415895

Epoch: 6| Step: 1
Training loss: 1.8059293031692505
Validation loss: 2.374100190336986

Epoch: 6| Step: 2
Training loss: 2.4734702110290527
Validation loss: 2.3749620453003915

Epoch: 6| Step: 3
Training loss: 3.031754732131958
Validation loss: 2.3793096567994807

Epoch: 6| Step: 4
Training loss: 2.0940465927124023
Validation loss: 2.3956210690159954

Epoch: 6| Step: 5
Training loss: 1.8350718021392822
Validation loss: 2.407469884041817

Epoch: 6| Step: 6
Training loss: 2.7039589881896973
Validation loss: 2.408224800581573

Epoch: 6| Step: 7
Training loss: 3.022394895553589
Validation loss: 2.390384579217562

Epoch: 6| Step: 8
Training loss: 3.1489968299865723
Validation loss: 2.377429331502607

Epoch: 6| Step: 9
Training loss: 2.699496030807495
Validation loss: 2.3715265694484917

Epoch: 6| Step: 10
Training loss: 2.9605207443237305
Validation loss: 2.3711877971567135

Epoch: 6| Step: 11
Training loss: 2.7055857181549072
Validation loss: 2.36007869884532

Epoch: 6| Step: 12
Training loss: 2.1085028648376465
Validation loss: 2.3546857628771054

Epoch: 6| Step: 13
Training loss: 3.232590913772583
Validation loss: 2.3563904762268066

Epoch: 40| Step: 0
Training loss: 2.1763792037963867
Validation loss: 2.3506722450256348

Epoch: 6| Step: 1
Training loss: 2.5257229804992676
Validation loss: 2.352298039262013

Epoch: 6| Step: 2
Training loss: 2.5867152214050293
Validation loss: 2.3530715255327124

Epoch: 6| Step: 3
Training loss: 2.3090322017669678
Validation loss: 2.35813541822536

Epoch: 6| Step: 4
Training loss: 2.9590651988983154
Validation loss: 2.361516021913098

Epoch: 6| Step: 5
Training loss: 2.670271873474121
Validation loss: 2.374695493328956

Epoch: 6| Step: 6
Training loss: 1.914201021194458
Validation loss: 2.3960269394741265

Epoch: 6| Step: 7
Training loss: 2.7120585441589355
Validation loss: 2.3835258509523127

Epoch: 6| Step: 8
Training loss: 2.266211748123169
Validation loss: 2.3534158327246226

Epoch: 6| Step: 9
Training loss: 2.9780585765838623
Validation loss: 2.3461762269337973

Epoch: 6| Step: 10
Training loss: 3.2627837657928467
Validation loss: 2.341817666125554

Epoch: 6| Step: 11
Training loss: 2.8042588233947754
Validation loss: 2.3447805912263933

Epoch: 6| Step: 12
Training loss: 2.9875705242156982
Validation loss: 2.354015488778391

Epoch: 6| Step: 13
Training loss: 2.4718174934387207
Validation loss: 2.3506304679378385

Epoch: 41| Step: 0
Training loss: 2.7950706481933594
Validation loss: 2.3583857577334166

Epoch: 6| Step: 1
Training loss: 2.941192626953125
Validation loss: 2.3608782111957507

Epoch: 6| Step: 2
Training loss: 2.3750181198120117
Validation loss: 2.354209369228732

Epoch: 6| Step: 3
Training loss: 2.5962963104248047
Validation loss: 2.349956399650984

Epoch: 6| Step: 4
Training loss: 2.6149544715881348
Validation loss: 2.33809599825131

Epoch: 6| Step: 5
Training loss: 2.8984341621398926
Validation loss: 2.353582300165648

Epoch: 6| Step: 6
Training loss: 1.9308273792266846
Validation loss: 2.3542044803660405

Epoch: 6| Step: 7
Training loss: 3.0028319358825684
Validation loss: 2.3744217118909283

Epoch: 6| Step: 8
Training loss: 2.6280455589294434
Validation loss: 2.4014207137528287

Epoch: 6| Step: 9
Training loss: 2.8326737880706787
Validation loss: 2.412470348419682

Epoch: 6| Step: 10
Training loss: 3.216656446456909
Validation loss: 2.4231017789533063

Epoch: 6| Step: 11
Training loss: 2.184015989303589
Validation loss: 2.4426344517738587

Epoch: 6| Step: 12
Training loss: 2.490481376647949
Validation loss: 2.4601586326476066

Epoch: 6| Step: 13
Training loss: 2.544687271118164
Validation loss: 2.4504203924568753

Epoch: 42| Step: 0
Training loss: 2.410346031188965
Validation loss: 2.430144358706731

Epoch: 6| Step: 1
Training loss: 3.0396203994750977
Validation loss: 2.4350168038440008

Epoch: 6| Step: 2
Training loss: 3.200620651245117
Validation loss: 2.4481966418604695

Epoch: 6| Step: 3
Training loss: 2.9363369941711426
Validation loss: 2.4643404458158757

Epoch: 6| Step: 4
Training loss: 3.056290864944458
Validation loss: 2.454758181366869

Epoch: 6| Step: 5
Training loss: 3.090745449066162
Validation loss: 2.4393809687706733

Epoch: 6| Step: 6
Training loss: 2.957554817199707
Validation loss: 2.4110960934751775

Epoch: 6| Step: 7
Training loss: 2.820249080657959
Validation loss: 2.397398838432886

Epoch: 6| Step: 8
Training loss: 1.9585906267166138
Validation loss: 2.3923950733677035

Epoch: 6| Step: 9
Training loss: 1.9823079109191895
Validation loss: 2.3923883720110823

Epoch: 6| Step: 10
Training loss: 2.7054901123046875
Validation loss: 2.390591867508427

Epoch: 6| Step: 11
Training loss: 2.3425674438476562
Validation loss: 2.3901255335859073

Epoch: 6| Step: 12
Training loss: 2.399146556854248
Validation loss: 2.3932795114414667

Epoch: 6| Step: 13
Training loss: 1.9058194160461426
Validation loss: 2.38197906555668

Epoch: 43| Step: 0
Training loss: 2.8649468421936035
Validation loss: 2.3793350035144436

Epoch: 6| Step: 1
Training loss: 2.4459943771362305
Validation loss: 2.368928522192022

Epoch: 6| Step: 2
Training loss: 2.692525863647461
Validation loss: 2.3747732562403523

Epoch: 6| Step: 3
Training loss: 2.862147331237793
Validation loss: 2.3696901875157512

Epoch: 6| Step: 4
Training loss: 2.120034694671631
Validation loss: 2.3663230249958653

Epoch: 6| Step: 5
Training loss: 2.1993532180786133
Validation loss: 2.3589592851618284

Epoch: 6| Step: 6
Training loss: 3.1547796726226807
Validation loss: 2.340429141957273

Epoch: 6| Step: 7
Training loss: 2.6028194427490234
Validation loss: 2.331322585382769

Epoch: 6| Step: 8
Training loss: 2.5563766956329346
Validation loss: 2.334324457312143

Epoch: 6| Step: 9
Training loss: 3.3136191368103027
Validation loss: 2.331032858099989

Epoch: 6| Step: 10
Training loss: 2.5849056243896484
Validation loss: 2.3351510673440914

Epoch: 6| Step: 11
Training loss: 2.5193123817443848
Validation loss: 2.3268495452019478

Epoch: 6| Step: 12
Training loss: 2.8319849967956543
Validation loss: 2.323632073658769

Epoch: 6| Step: 13
Training loss: 1.3956716060638428
Validation loss: 2.3282087028667493

Epoch: 44| Step: 0
Training loss: 2.9687647819519043
Validation loss: 2.343953024956488

Epoch: 6| Step: 1
Training loss: 2.6455297470092773
Validation loss: 2.375293162561232

Epoch: 6| Step: 2
Training loss: 2.7421865463256836
Validation loss: 2.4196178502933954

Epoch: 6| Step: 3
Training loss: 2.3659093379974365
Validation loss: 2.4463567323582147

Epoch: 6| Step: 4
Training loss: 2.674463987350464
Validation loss: 2.4427861321356987

Epoch: 6| Step: 5
Training loss: 2.735896587371826
Validation loss: 2.392977491501839

Epoch: 6| Step: 6
Training loss: 3.159278392791748
Validation loss: 2.3412366374846427

Epoch: 6| Step: 7
Training loss: 2.2439956665039062
Validation loss: 2.318977568739204

Epoch: 6| Step: 8
Training loss: 2.5677456855773926
Validation loss: 2.3138687354262157

Epoch: 6| Step: 9
Training loss: 2.3369338512420654
Validation loss: 2.322332530893305

Epoch: 6| Step: 10
Training loss: 2.5378670692443848
Validation loss: 2.333494391492618

Epoch: 6| Step: 11
Training loss: 2.883474826812744
Validation loss: 2.348057393104799

Epoch: 6| Step: 12
Training loss: 2.3485310077667236
Validation loss: 2.3534732044384046

Epoch: 6| Step: 13
Training loss: 2.470677137374878
Validation loss: 2.382833086034303

Epoch: 45| Step: 0
Training loss: 3.009493350982666
Validation loss: 2.341512921035931

Epoch: 6| Step: 1
Training loss: 2.848139762878418
Validation loss: 2.3221106593326857

Epoch: 6| Step: 2
Training loss: 2.1008715629577637
Validation loss: 2.3128381595816663

Epoch: 6| Step: 3
Training loss: 2.7515923976898193
Validation loss: 2.3020119308143534

Epoch: 6| Step: 4
Training loss: 1.8642711639404297
Validation loss: 2.3169674129896265

Epoch: 6| Step: 5
Training loss: 2.8393208980560303
Validation loss: 2.3414768313848846

Epoch: 6| Step: 6
Training loss: 1.362889289855957
Validation loss: 2.37382742410065

Epoch: 6| Step: 7
Training loss: 2.2247557640075684
Validation loss: 2.419847410212281

Epoch: 6| Step: 8
Training loss: 2.7626452445983887
Validation loss: 2.424275129072128

Epoch: 6| Step: 9
Training loss: 3.32425594329834
Validation loss: 2.4185389408501248

Epoch: 6| Step: 10
Training loss: 2.693753957748413
Validation loss: 2.3748485067839264

Epoch: 6| Step: 11
Training loss: 3.036410093307495
Validation loss: 2.3277522030697075

Epoch: 6| Step: 12
Training loss: 2.9336562156677246
Validation loss: 2.3159913145085818

Epoch: 6| Step: 13
Training loss: 3.3881571292877197
Validation loss: 2.327180234334802

Epoch: 46| Step: 0
Training loss: 2.5075697898864746
Validation loss: 2.333381542595484

Epoch: 6| Step: 1
Training loss: 2.894148826599121
Validation loss: 2.351569137265605

Epoch: 6| Step: 2
Training loss: 2.053966760635376
Validation loss: 2.3429960358527397

Epoch: 6| Step: 3
Training loss: 2.392775535583496
Validation loss: 2.3387557768052623

Epoch: 6| Step: 4
Training loss: 2.060708522796631
Validation loss: 2.338615604626235

Epoch: 6| Step: 5
Training loss: 3.4644832611083984
Validation loss: 2.330316202614897

Epoch: 6| Step: 6
Training loss: 2.5304477214813232
Validation loss: 2.3283320344904417

Epoch: 6| Step: 7
Training loss: 2.794708728790283
Validation loss: 2.329652511945335

Epoch: 6| Step: 8
Training loss: 2.2900664806365967
Validation loss: 2.330495552350116

Epoch: 6| Step: 9
Training loss: 3.0587856769561768
Validation loss: 2.331199376813827

Epoch: 6| Step: 10
Training loss: 2.5421082973480225
Validation loss: 2.327283477270475

Epoch: 6| Step: 11
Training loss: 2.6768555641174316
Validation loss: 2.314416580302741

Epoch: 6| Step: 12
Training loss: 2.896336555480957
Validation loss: 2.307480324981033

Epoch: 6| Step: 13
Training loss: 2.5609941482543945
Validation loss: 2.300395888666953

Epoch: 47| Step: 0
Training loss: 2.733919620513916
Validation loss: 2.303069458212904

Epoch: 6| Step: 1
Training loss: 3.2543118000030518
Validation loss: 2.304325608796971

Epoch: 6| Step: 2
Training loss: 1.991999626159668
Validation loss: 2.306605226250105

Epoch: 6| Step: 3
Training loss: 2.8742363452911377
Validation loss: 2.3087934088963333

Epoch: 6| Step: 4
Training loss: 2.8973429203033447
Validation loss: 2.3174719554121777

Epoch: 6| Step: 5
Training loss: 2.4019689559936523
Validation loss: 2.3219229482835337

Epoch: 6| Step: 6
Training loss: 2.611250877380371
Validation loss: 2.3388145892850813

Epoch: 6| Step: 7
Training loss: 2.6885061264038086
Validation loss: 2.3242783366992907

Epoch: 6| Step: 8
Training loss: 1.7707724571228027
Validation loss: 2.3541074824589554

Epoch: 6| Step: 9
Training loss: 3.265317440032959
Validation loss: 2.3391785160187752

Epoch: 6| Step: 10
Training loss: 1.6675366163253784
Validation loss: 2.3365104890638784

Epoch: 6| Step: 11
Training loss: 2.0462727546691895
Validation loss: 2.312031494673862

Epoch: 6| Step: 12
Training loss: 2.7569024562835693
Validation loss: 2.3027656283429874

Epoch: 6| Step: 13
Training loss: 3.6851603984832764
Validation loss: 2.295380630800801

Epoch: 48| Step: 0
Training loss: 3.0534396171569824
Validation loss: 2.2932028398718884

Epoch: 6| Step: 1
Training loss: 2.373990058898926
Validation loss: 2.2915602627620903

Epoch: 6| Step: 2
Training loss: 2.5971009731292725
Validation loss: 2.292775297677645

Epoch: 6| Step: 3
Training loss: 3.1827008724212646
Validation loss: 2.294284356537686

Epoch: 6| Step: 4
Training loss: 2.2566158771514893
Validation loss: 2.29298407800736

Epoch: 6| Step: 5
Training loss: 2.7488465309143066
Validation loss: 2.2911981151949976

Epoch: 6| Step: 6
Training loss: 2.848402500152588
Validation loss: 2.2916769289201304

Epoch: 6| Step: 7
Training loss: 2.4915127754211426
Validation loss: 2.290636198495024

Epoch: 6| Step: 8
Training loss: 2.09134578704834
Validation loss: 2.2891658172812512

Epoch: 6| Step: 9
Training loss: 2.896423816680908
Validation loss: 2.2906927242073962

Epoch: 6| Step: 10
Training loss: 2.7133073806762695
Validation loss: 2.2865342504234722

Epoch: 6| Step: 11
Training loss: 2.0003066062927246
Validation loss: 2.2815578112038235

Epoch: 6| Step: 12
Training loss: 2.5075039863586426
Validation loss: 2.284288913972916

Epoch: 6| Step: 13
Training loss: 2.6811208724975586
Validation loss: 2.2802424328301543

Epoch: 49| Step: 0
Training loss: 3.2780888080596924
Validation loss: 2.280946990495087

Epoch: 6| Step: 1
Training loss: 2.5322723388671875
Validation loss: 2.2872545898601575

Epoch: 6| Step: 2
Training loss: 1.6318763494491577
Validation loss: 2.284563749067245

Epoch: 6| Step: 3
Training loss: 2.3451104164123535
Validation loss: 2.288601113903907

Epoch: 6| Step: 4
Training loss: 2.709573745727539
Validation loss: 2.3083970828722884

Epoch: 6| Step: 5
Training loss: 1.9383323192596436
Validation loss: 2.3182532530958935

Epoch: 6| Step: 6
Training loss: 2.5018436908721924
Validation loss: 2.3342978031404558

Epoch: 6| Step: 7
Training loss: 2.41973876953125
Validation loss: 2.349493488188713

Epoch: 6| Step: 8
Training loss: 2.4663171768188477
Validation loss: 2.3640135360020462

Epoch: 6| Step: 9
Training loss: 3.568814754486084
Validation loss: 2.3542843787900862

Epoch: 6| Step: 10
Training loss: 2.1339218616485596
Validation loss: 2.338862888274654

Epoch: 6| Step: 11
Training loss: 3.3276638984680176
Validation loss: 2.3172031474369827

Epoch: 6| Step: 12
Training loss: 2.7614829540252686
Validation loss: 2.2999252298826813

Epoch: 6| Step: 13
Training loss: 2.213879108428955
Validation loss: 2.2930137700932

Epoch: 50| Step: 0
Training loss: 2.839460849761963
Validation loss: 2.284157117207845

Epoch: 6| Step: 1
Training loss: 2.5961763858795166
Validation loss: 2.2825835289493686

Epoch: 6| Step: 2
Training loss: 3.341230630874634
Validation loss: 2.282709087094953

Epoch: 6| Step: 3
Training loss: 2.2577931880950928
Validation loss: 2.282696436810237

Epoch: 6| Step: 4
Training loss: 2.0995583534240723
Validation loss: 2.2778263040768203

Epoch: 6| Step: 5
Training loss: 2.889285087585449
Validation loss: 2.282074184827907

Epoch: 6| Step: 6
Training loss: 1.620192289352417
Validation loss: 2.2788036587417766

Epoch: 6| Step: 7
Training loss: 2.23667573928833
Validation loss: 2.2767026680772022

Epoch: 6| Step: 8
Training loss: 3.2600650787353516
Validation loss: 2.2779416345780894

Epoch: 6| Step: 9
Training loss: 2.134556531906128
Validation loss: 2.275210157517464

Epoch: 6| Step: 10
Training loss: 2.666903257369995
Validation loss: 2.277421239883669

Epoch: 6| Step: 11
Training loss: 2.6377296447753906
Validation loss: 2.275314414373008

Epoch: 6| Step: 12
Training loss: 2.566628932952881
Validation loss: 2.2764179578391452

Epoch: 6| Step: 13
Training loss: 3.340796947479248
Validation loss: 2.293580383382818

Epoch: 51| Step: 0
Training loss: 2.6160390377044678
Validation loss: 2.30485801799323

Epoch: 6| Step: 1
Training loss: 3.2780814170837402
Validation loss: 2.319275676563222

Epoch: 6| Step: 2
Training loss: 2.3569860458374023
Validation loss: 2.3141643103732856

Epoch: 6| Step: 3
Training loss: 3.0419514179229736
Validation loss: 2.3378829904781875

Epoch: 6| Step: 4
Training loss: 2.7155823707580566
Validation loss: 2.327382359453427

Epoch: 6| Step: 5
Training loss: 2.9870500564575195
Validation loss: 2.331062783477127

Epoch: 6| Step: 6
Training loss: 2.6098034381866455
Validation loss: 2.3308367549732165

Epoch: 6| Step: 7
Training loss: 2.7175936698913574
Validation loss: 2.3020191448991016

Epoch: 6| Step: 8
Training loss: 2.517852306365967
Validation loss: 2.284565758961503

Epoch: 6| Step: 9
Training loss: 1.9384676218032837
Validation loss: 2.2707369032726494

Epoch: 6| Step: 10
Training loss: 2.9406723976135254
Validation loss: 2.261399708768373

Epoch: 6| Step: 11
Training loss: 1.642869472503662
Validation loss: 2.263318666847803

Epoch: 6| Step: 12
Training loss: 1.868715763092041
Validation loss: 2.2602224760158087

Epoch: 6| Step: 13
Training loss: 2.8797409534454346
Validation loss: 2.2615452838200394

Epoch: 52| Step: 0
Training loss: 1.9963963031768799
Validation loss: 2.2659474060099614

Epoch: 6| Step: 1
Training loss: 2.785818576812744
Validation loss: 2.2710734323788713

Epoch: 6| Step: 2
Training loss: 2.7718305587768555
Validation loss: 2.277333572346677

Epoch: 6| Step: 3
Training loss: 2.9773833751678467
Validation loss: 2.28050926680206

Epoch: 6| Step: 4
Training loss: 1.857147455215454
Validation loss: 2.2702929691601823

Epoch: 6| Step: 5
Training loss: 3.178640604019165
Validation loss: 2.2677090526908956

Epoch: 6| Step: 6
Training loss: 3.4281044006347656
Validation loss: 2.256870892740065

Epoch: 6| Step: 7
Training loss: 2.828700542449951
Validation loss: 2.253887520041517

Epoch: 6| Step: 8
Training loss: 2.480820655822754
Validation loss: 2.252265771230062

Epoch: 6| Step: 9
Training loss: 2.6633453369140625
Validation loss: 2.251914057680356

Epoch: 6| Step: 10
Training loss: 2.206131935119629
Validation loss: 2.249495444759246

Epoch: 6| Step: 11
Training loss: 2.2412166595458984
Validation loss: 2.2429672928266626

Epoch: 6| Step: 12
Training loss: 2.41121768951416
Validation loss: 2.2470939338848157

Epoch: 6| Step: 13
Training loss: 2.1906979084014893
Validation loss: 2.2481164496432067

Epoch: 53| Step: 0
Training loss: 2.4086291790008545
Validation loss: 2.26653705873797

Epoch: 6| Step: 1
Training loss: 2.8612775802612305
Validation loss: 2.2892121076583862

Epoch: 6| Step: 2
Training loss: 2.7612392902374268
Validation loss: 2.3292712088554137

Epoch: 6| Step: 3
Training loss: 2.7347140312194824
Validation loss: 2.3646341216179634

Epoch: 6| Step: 4
Training loss: 2.5506069660186768
Validation loss: 2.3707534369601997

Epoch: 6| Step: 5
Training loss: 2.2322702407836914
Validation loss: 2.3663679040888304

Epoch: 6| Step: 6
Training loss: 2.3786840438842773
Validation loss: 2.297970951244395

Epoch: 6| Step: 7
Training loss: 2.682398796081543
Validation loss: 2.2626096587027273

Epoch: 6| Step: 8
Training loss: 2.2948319911956787
Validation loss: 2.2553077487535376

Epoch: 6| Step: 9
Training loss: 2.9547293186187744
Validation loss: 2.2642276876716205

Epoch: 6| Step: 10
Training loss: 2.438694953918457
Validation loss: 2.2745226301172727

Epoch: 6| Step: 11
Training loss: 2.567873239517212
Validation loss: 2.284882048124908

Epoch: 6| Step: 12
Training loss: 2.4365344047546387
Validation loss: 2.284369453307121

Epoch: 6| Step: 13
Training loss: 3.7651045322418213
Validation loss: 2.2727605476174304

Epoch: 54| Step: 0
Training loss: 2.400588035583496
Validation loss: 2.2626732113540813

Epoch: 6| Step: 1
Training loss: 2.792893409729004
Validation loss: 2.2550796590825564

Epoch: 6| Step: 2
Training loss: 2.091586112976074
Validation loss: 2.2500318750258415

Epoch: 6| Step: 3
Training loss: 2.704468250274658
Validation loss: 2.246196593007734

Epoch: 6| Step: 4
Training loss: 2.808339834213257
Validation loss: 2.2363181985834593

Epoch: 6| Step: 5
Training loss: 3.116298198699951
Validation loss: 2.233149287521198

Epoch: 6| Step: 6
Training loss: 2.264780044555664
Validation loss: 2.2424212886441137

Epoch: 6| Step: 7
Training loss: 2.5675406455993652
Validation loss: 2.262815685682399

Epoch: 6| Step: 8
Training loss: 2.160985231399536
Validation loss: 2.3110527107792516

Epoch: 6| Step: 9
Training loss: 2.2877655029296875
Validation loss: 2.3663809273832586

Epoch: 6| Step: 10
Training loss: 3.07658052444458
Validation loss: 2.5150892324345087

Epoch: 6| Step: 11
Training loss: 3.3463854789733887
Validation loss: 2.5726533628279165

Epoch: 6| Step: 12
Training loss: 2.7477569580078125
Validation loss: 2.555675768083142

Epoch: 6| Step: 13
Training loss: 2.112443208694458
Validation loss: 2.4135980708624727

Epoch: 55| Step: 0
Training loss: 2.4038941860198975
Validation loss: 2.313981807360085

Epoch: 6| Step: 1
Training loss: 2.7173805236816406
Validation loss: 2.2836491164340766

Epoch: 6| Step: 2
Training loss: 2.7203187942504883
Validation loss: 2.277324597040812

Epoch: 6| Step: 3
Training loss: 2.04897141456604
Validation loss: 2.2917765853225545

Epoch: 6| Step: 4
Training loss: 2.255244016647339
Validation loss: 2.303918905155633

Epoch: 6| Step: 5
Training loss: 2.375545024871826
Validation loss: 2.3231508949751496

Epoch: 6| Step: 6
Training loss: 2.7117533683776855
Validation loss: 2.3337205738149662

Epoch: 6| Step: 7
Training loss: 3.2176125049591064
Validation loss: 2.3203157045507945

Epoch: 6| Step: 8
Training loss: 1.911312222480774
Validation loss: 2.2863190609921693

Epoch: 6| Step: 9
Training loss: 3.072532892227173
Validation loss: 2.2639015028553624

Epoch: 6| Step: 10
Training loss: 3.0442726612091064
Validation loss: 2.248868070622926

Epoch: 6| Step: 11
Training loss: 2.2510933876037598
Validation loss: 2.233419608044368

Epoch: 6| Step: 12
Training loss: 3.0105981826782227
Validation loss: 2.2217310474764917

Epoch: 6| Step: 13
Training loss: 3.2604196071624756
Validation loss: 2.226683150055588

Epoch: 56| Step: 0
Training loss: 2.3815760612487793
Validation loss: 2.224321106428741

Epoch: 6| Step: 1
Training loss: 1.3474968671798706
Validation loss: 2.2297096252441406

Epoch: 6| Step: 2
Training loss: 2.7450027465820312
Validation loss: 2.280003365649972

Epoch: 6| Step: 3
Training loss: 2.325406789779663
Validation loss: 2.335370579073506

Epoch: 6| Step: 4
Training loss: 2.7697854042053223
Validation loss: 2.3960161209106445

Epoch: 6| Step: 5
Training loss: 2.0718283653259277
Validation loss: 2.372445059078996

Epoch: 6| Step: 6
Training loss: 3.519254207611084
Validation loss: 2.379817578100389

Epoch: 6| Step: 7
Training loss: 3.2098774909973145
Validation loss: 2.2996855833197154

Epoch: 6| Step: 8
Training loss: 2.322844982147217
Validation loss: 2.2539847871308685

Epoch: 6| Step: 9
Training loss: 2.514580249786377
Validation loss: 2.2469313452320714

Epoch: 6| Step: 10
Training loss: 2.8074042797088623
Validation loss: 2.233911639900618

Epoch: 6| Step: 11
Training loss: 2.84871768951416
Validation loss: 2.234890132822016

Epoch: 6| Step: 12
Training loss: 2.316093921661377
Validation loss: 2.2354779346014864

Epoch: 6| Step: 13
Training loss: 2.737405776977539
Validation loss: 2.24284977041265

Epoch: 57| Step: 0
Training loss: 2.760211229324341
Validation loss: 2.242916299450782

Epoch: 6| Step: 1
Training loss: 3.1346750259399414
Validation loss: 2.245241057488226

Epoch: 6| Step: 2
Training loss: 2.116858959197998
Validation loss: 2.2646919219724593

Epoch: 6| Step: 3
Training loss: 2.712054967880249
Validation loss: 2.27164956831163

Epoch: 6| Step: 4
Training loss: 2.4950618743896484
Validation loss: 2.274754290939659

Epoch: 6| Step: 5
Training loss: 2.6032261848449707
Validation loss: 2.2664168573194936

Epoch: 6| Step: 6
Training loss: 2.399510622024536
Validation loss: 2.2322464245621876

Epoch: 6| Step: 7
Training loss: 3.56364107131958
Validation loss: 2.24609891317224

Epoch: 6| Step: 8
Training loss: 3.055270195007324
Validation loss: 2.2478951561835503

Epoch: 6| Step: 9
Training loss: 1.8701014518737793
Validation loss: 2.2547348699262066

Epoch: 6| Step: 10
Training loss: 2.1851868629455566
Validation loss: 2.257151496025824

Epoch: 6| Step: 11
Training loss: 2.4595699310302734
Validation loss: 2.2433778573107976

Epoch: 6| Step: 12
Training loss: 2.460134983062744
Validation loss: 2.2258531021815475

Epoch: 6| Step: 13
Training loss: 1.9094526767730713
Validation loss: 2.2110969635748092

Epoch: 58| Step: 0
Training loss: 2.894670009613037
Validation loss: 2.214481658833001

Epoch: 6| Step: 1
Training loss: 3.081031322479248
Validation loss: 2.2238797705660582

Epoch: 6| Step: 2
Training loss: 2.635272979736328
Validation loss: 2.2431072855508454

Epoch: 6| Step: 3
Training loss: 2.8476946353912354
Validation loss: 2.265717811481927

Epoch: 6| Step: 4
Training loss: 2.5752625465393066
Validation loss: 2.282149645590013

Epoch: 6| Step: 5
Training loss: 2.0471317768096924
Validation loss: 2.271190094691451

Epoch: 6| Step: 6
Training loss: 2.4594712257385254
Validation loss: 2.2728411805245186

Epoch: 6| Step: 7
Training loss: 2.5815205574035645
Validation loss: 2.2883399019959154

Epoch: 6| Step: 8
Training loss: 2.7768561840057373
Validation loss: 2.2810546095653246

Epoch: 6| Step: 9
Training loss: 3.0483956336975098
Validation loss: 2.3024606140710975

Epoch: 6| Step: 10
Training loss: 2.15384578704834
Validation loss: 2.3424927573050223

Epoch: 6| Step: 11
Training loss: 2.418774127960205
Validation loss: 2.333852723080625

Epoch: 6| Step: 12
Training loss: 1.8556574583053589
Validation loss: 2.3361780643463135

Epoch: 6| Step: 13
Training loss: 2.326845407485962
Validation loss: 2.29164021758623

Epoch: 59| Step: 0
Training loss: 2.560431480407715
Validation loss: 2.258421177505165

Epoch: 6| Step: 1
Training loss: 1.9290738105773926
Validation loss: 2.2499994565081853

Epoch: 6| Step: 2
Training loss: 2.6497018337249756
Validation loss: 2.215567805433786

Epoch: 6| Step: 3
Training loss: 1.986185073852539
Validation loss: 2.223187438903316

Epoch: 6| Step: 4
Training loss: 2.2319397926330566
Validation loss: 2.257592083305441

Epoch: 6| Step: 5
Training loss: 2.269428014755249
Validation loss: 2.335446964028061

Epoch: 6| Step: 6
Training loss: 2.918466567993164
Validation loss: 2.487434712789392

Epoch: 6| Step: 7
Training loss: 3.081143379211426
Validation loss: 2.5221507421103855

Epoch: 6| Step: 8
Training loss: 3.169070243835449
Validation loss: 2.382587153424499

Epoch: 6| Step: 9
Training loss: 2.994581699371338
Validation loss: 2.251028489041072

Epoch: 6| Step: 10
Training loss: 2.737652540206909
Validation loss: 2.2033724810487483

Epoch: 6| Step: 11
Training loss: 2.4434685707092285
Validation loss: 2.1924246664970153

Epoch: 6| Step: 12
Training loss: 2.465430736541748
Validation loss: 2.18738966859797

Epoch: 6| Step: 13
Training loss: 2.343677520751953
Validation loss: 2.188751123284781

Epoch: 60| Step: 0
Training loss: 2.7317392826080322
Validation loss: 2.186671946638374

Epoch: 6| Step: 1
Training loss: 2.4650204181671143
Validation loss: 2.2026576329303045

Epoch: 6| Step: 2
Training loss: 2.5235400199890137
Validation loss: 2.2371061078963743

Epoch: 6| Step: 3
Training loss: 2.4131321907043457
Validation loss: 2.275698309303612

Epoch: 6| Step: 4
Training loss: 3.4077987670898438
Validation loss: 2.3031162010726107

Epoch: 6| Step: 5
Training loss: 2.051746129989624
Validation loss: 2.2508724581810737

Epoch: 6| Step: 6
Training loss: 1.8545182943344116
Validation loss: 2.211855399993158

Epoch: 6| Step: 7
Training loss: 2.447348117828369
Validation loss: 2.2093799062954482

Epoch: 6| Step: 8
Training loss: 1.503156304359436
Validation loss: 2.2035633671668267

Epoch: 6| Step: 9
Training loss: 2.436509132385254
Validation loss: 2.2016797963009087

Epoch: 6| Step: 10
Training loss: 2.968021869659424
Validation loss: 2.2217795361754713

Epoch: 6| Step: 11
Training loss: 3.1514148712158203
Validation loss: 2.228590634561354

Epoch: 6| Step: 12
Training loss: 2.919705390930176
Validation loss: 2.232099534362875

Epoch: 6| Step: 13
Training loss: 2.735679864883423
Validation loss: 2.2343768099302888

Epoch: 61| Step: 0
Training loss: 2.213683843612671
Validation loss: 2.2263561807652956

Epoch: 6| Step: 1
Training loss: 2.0854132175445557
Validation loss: 2.2172833463197112

Epoch: 6| Step: 2
Training loss: 2.59891676902771
Validation loss: 2.216941290004279

Epoch: 6| Step: 3
Training loss: 2.0129640102386475
Validation loss: 2.216387161644556

Epoch: 6| Step: 4
Training loss: 2.823544502258301
Validation loss: 2.2330804358246508

Epoch: 6| Step: 5
Training loss: 2.8240251541137695
Validation loss: 2.2454689420679563

Epoch: 6| Step: 6
Training loss: 2.4549551010131836
Validation loss: 2.271714646329162

Epoch: 6| Step: 7
Training loss: 2.4192543029785156
Validation loss: 2.2830078524927937

Epoch: 6| Step: 8
Training loss: 3.0657286643981934
Validation loss: 2.268398787385674

Epoch: 6| Step: 9
Training loss: 2.4027886390686035
Validation loss: 2.229254491867558

Epoch: 6| Step: 10
Training loss: 2.232067108154297
Validation loss: 2.2010737721638014

Epoch: 6| Step: 11
Training loss: 2.6106162071228027
Validation loss: 2.201932345667193

Epoch: 6| Step: 12
Training loss: 2.761298894882202
Validation loss: 2.1941263598780476

Epoch: 6| Step: 13
Training loss: 2.6788063049316406
Validation loss: 2.2059014151173253

Epoch: 62| Step: 0
Training loss: 3.258606433868408
Validation loss: 2.19710571663354

Epoch: 6| Step: 1
Training loss: 2.501544952392578
Validation loss: 2.189858328911566

Epoch: 6| Step: 2
Training loss: 2.471055030822754
Validation loss: 2.191080326675087

Epoch: 6| Step: 3
Training loss: 2.668165683746338
Validation loss: 2.1906624301787345

Epoch: 6| Step: 4
Training loss: 2.0825061798095703
Validation loss: 2.2111701375694683

Epoch: 6| Step: 5
Training loss: 2.48034405708313
Validation loss: 2.2487632997574343

Epoch: 6| Step: 6
Training loss: 2.8596456050872803
Validation loss: 2.2867865126620055

Epoch: 6| Step: 7
Training loss: 2.914714813232422
Validation loss: 2.3490629273076213

Epoch: 6| Step: 8
Training loss: 1.949310541152954
Validation loss: 2.2800096132422007

Epoch: 6| Step: 9
Training loss: 2.3663854598999023
Validation loss: 2.2306217967822985

Epoch: 6| Step: 10
Training loss: 2.246893882751465
Validation loss: 2.188466784774616

Epoch: 6| Step: 11
Training loss: 2.4302926063537598
Validation loss: 2.1786784818095546

Epoch: 6| Step: 12
Training loss: 2.4236083030700684
Validation loss: 2.1738741961858605

Epoch: 6| Step: 13
Training loss: 2.3288345336914062
Validation loss: 2.1728514676452964

Epoch: 63| Step: 0
Training loss: 2.755563735961914
Validation loss: 2.1711798098779496

Epoch: 6| Step: 1
Training loss: 2.034424066543579
Validation loss: 2.181588189576262

Epoch: 6| Step: 2
Training loss: 1.971238374710083
Validation loss: 2.1825772690516647

Epoch: 6| Step: 3
Training loss: 2.2851672172546387
Validation loss: 2.183903217315674

Epoch: 6| Step: 4
Training loss: 2.1044235229492188
Validation loss: 2.1810223197424286

Epoch: 6| Step: 5
Training loss: 2.5948567390441895
Validation loss: 2.1794932388490245

Epoch: 6| Step: 6
Training loss: 2.7982680797576904
Validation loss: 2.1879907346540883

Epoch: 6| Step: 7
Training loss: 2.52658748626709
Validation loss: 2.1845980639098794

Epoch: 6| Step: 8
Training loss: 2.7696635723114014
Validation loss: 2.1894553656219156

Epoch: 6| Step: 9
Training loss: 3.2009763717651367
Validation loss: 2.1855538224661224

Epoch: 6| Step: 10
Training loss: 2.502173900604248
Validation loss: 2.1908173573914396

Epoch: 6| Step: 11
Training loss: 2.819488286972046
Validation loss: 2.196137177046909

Epoch: 6| Step: 12
Training loss: 2.3865132331848145
Validation loss: 2.241170216632146

Epoch: 6| Step: 13
Training loss: 2.0347325801849365
Validation loss: 2.2444466954918316

Epoch: 64| Step: 0
Training loss: 2.1457979679107666
Validation loss: 2.281055427366687

Epoch: 6| Step: 1
Training loss: 3.2125415802001953
Validation loss: 2.3066768569331013

Epoch: 6| Step: 2
Training loss: 2.281160831451416
Validation loss: 2.3116126880850842

Epoch: 6| Step: 3
Training loss: 2.1477997303009033
Validation loss: 2.3401918616346133

Epoch: 6| Step: 4
Training loss: 2.6061978340148926
Validation loss: 2.384345216135825

Epoch: 6| Step: 5
Training loss: 2.1658151149749756
Validation loss: 2.3417191813069005

Epoch: 6| Step: 6
Training loss: 2.5390615463256836
Validation loss: 2.3307112801459526

Epoch: 6| Step: 7
Training loss: 3.23368763923645
Validation loss: 2.263950583755329

Epoch: 6| Step: 8
Training loss: 2.449308395385742
Validation loss: 2.210781556303783

Epoch: 6| Step: 9
Training loss: 2.334381103515625
Validation loss: 2.172795513624786

Epoch: 6| Step: 10
Training loss: 2.6517109870910645
Validation loss: 2.1596608033744236

Epoch: 6| Step: 11
Training loss: 2.7412190437316895
Validation loss: 2.1559356694580405

Epoch: 6| Step: 12
Training loss: 2.2937910556793213
Validation loss: 2.1567947479986374

Epoch: 6| Step: 13
Training loss: 2.3797662258148193
Validation loss: 2.158912850964454

Epoch: 65| Step: 0
Training loss: 1.752428412437439
Validation loss: 2.1598926718517015

Epoch: 6| Step: 1
Training loss: 2.8321099281311035
Validation loss: 2.1527822786761868

Epoch: 6| Step: 2
Training loss: 2.051511764526367
Validation loss: 2.1546187054726387

Epoch: 6| Step: 3
Training loss: 2.1438210010528564
Validation loss: 2.155335100748206

Epoch: 6| Step: 4
Training loss: 1.9943768978118896
Validation loss: 2.1418948891342326

Epoch: 6| Step: 5
Training loss: 2.7190308570861816
Validation loss: 2.1478804875445623

Epoch: 6| Step: 6
Training loss: 3.002319812774658
Validation loss: 2.157473369311261

Epoch: 6| Step: 7
Training loss: 2.7925353050231934
Validation loss: 2.1617805586066297

Epoch: 6| Step: 8
Training loss: 2.3924872875213623
Validation loss: 2.1704300244649253

Epoch: 6| Step: 9
Training loss: 2.5664334297180176
Validation loss: 2.1781949048401206

Epoch: 6| Step: 10
Training loss: 2.0581178665161133
Validation loss: 2.1975992187376945

Epoch: 6| Step: 11
Training loss: 2.7562637329101562
Validation loss: 2.1876799060452368

Epoch: 6| Step: 12
Training loss: 2.511754274368286
Validation loss: 2.223709616609799

Epoch: 6| Step: 13
Training loss: 3.9342265129089355
Validation loss: 2.2534820469476844

Epoch: 66| Step: 0
Training loss: 1.7474720478057861
Validation loss: 2.2338282882526355

Epoch: 6| Step: 1
Training loss: 3.1557986736297607
Validation loss: 2.1798999142903153

Epoch: 6| Step: 2
Training loss: 2.3699259757995605
Validation loss: 2.1547224726728214

Epoch: 6| Step: 3
Training loss: 2.9714531898498535
Validation loss: 2.1421613616328083

Epoch: 6| Step: 4
Training loss: 2.0940542221069336
Validation loss: 2.1486490464979604

Epoch: 6| Step: 5
Training loss: 2.235957145690918
Validation loss: 2.15286789401885

Epoch: 6| Step: 6
Training loss: 2.8728532791137695
Validation loss: 2.1504481274594545

Epoch: 6| Step: 7
Training loss: 2.435391426086426
Validation loss: 2.15320655351044

Epoch: 6| Step: 8
Training loss: 1.7797882556915283
Validation loss: 2.1566250760068177

Epoch: 6| Step: 9
Training loss: 2.9279065132141113
Validation loss: 2.1609406343070408

Epoch: 6| Step: 10
Training loss: 2.2255825996398926
Validation loss: 2.161788494356217

Epoch: 6| Step: 11
Training loss: 2.5755250453948975
Validation loss: 2.163219500613469

Epoch: 6| Step: 12
Training loss: 3.227384567260742
Validation loss: 2.1636798766351517

Epoch: 6| Step: 13
Training loss: 3.439992666244507
Validation loss: 2.15925028247218

Epoch: 67| Step: 0
Training loss: 2.692131757736206
Validation loss: 2.158234473197691

Epoch: 6| Step: 1
Training loss: 3.192875862121582
Validation loss: 2.1522671253450456

Epoch: 6| Step: 2
Training loss: 2.238687753677368
Validation loss: 2.1498617754187634

Epoch: 6| Step: 3
Training loss: 2.2012481689453125
Validation loss: 2.1456815324803835

Epoch: 6| Step: 4
Training loss: 2.326456069946289
Validation loss: 2.1461830216069377

Epoch: 6| Step: 5
Training loss: 2.4158835411071777
Validation loss: 2.1464783863354753

Epoch: 6| Step: 6
Training loss: 2.361304998397827
Validation loss: 2.1507480349591983

Epoch: 6| Step: 7
Training loss: 2.144179105758667
Validation loss: 2.1536220824846657

Epoch: 6| Step: 8
Training loss: 2.019552230834961
Validation loss: 2.1594112278312765

Epoch: 6| Step: 9
Training loss: 2.693669319152832
Validation loss: 2.178042581004481

Epoch: 6| Step: 10
Training loss: 2.866849899291992
Validation loss: 2.208039060715706

Epoch: 6| Step: 11
Training loss: 2.8968658447265625
Validation loss: 2.237808317266485

Epoch: 6| Step: 12
Training loss: 2.457490921020508
Validation loss: 2.2657010760358585

Epoch: 6| Step: 13
Training loss: 2.205050468444824
Validation loss: 2.2931440235466085

Epoch: 68| Step: 0
Training loss: 3.034782886505127
Validation loss: 2.2790466175284436

Epoch: 6| Step: 1
Training loss: 2.3392181396484375
Validation loss: 2.28005765714953

Epoch: 6| Step: 2
Training loss: 2.1477813720703125
Validation loss: 2.2155121167500815

Epoch: 6| Step: 3
Training loss: 3.0716590881347656
Validation loss: 2.186385705906858

Epoch: 6| Step: 4
Training loss: 2.3261287212371826
Validation loss: 2.1757777096122823

Epoch: 6| Step: 5
Training loss: 1.953298807144165
Validation loss: 2.1747203949959046

Epoch: 6| Step: 6
Training loss: 3.2367091178894043
Validation loss: 2.166905323664347

Epoch: 6| Step: 7
Training loss: 2.419239044189453
Validation loss: 2.1656709896620883

Epoch: 6| Step: 8
Training loss: 2.446927785873413
Validation loss: 2.1711974964346936

Epoch: 6| Step: 9
Training loss: 2.29335880279541
Validation loss: 2.1625575352740545

Epoch: 6| Step: 10
Training loss: 2.818556547164917
Validation loss: 2.1602820709187496

Epoch: 6| Step: 11
Training loss: 2.4700777530670166
Validation loss: 2.1516319064683813

Epoch: 6| Step: 12
Training loss: 2.417487859725952
Validation loss: 2.1499501043750393

Epoch: 6| Step: 13
Training loss: 1.8972593545913696
Validation loss: 2.133878110557474

Epoch: 69| Step: 0
Training loss: 2.878037452697754
Validation loss: 2.132429704871229

Epoch: 6| Step: 1
Training loss: 2.6507210731506348
Validation loss: 2.1317400393947477

Epoch: 6| Step: 2
Training loss: 2.3655009269714355
Validation loss: 2.136917680822393

Epoch: 6| Step: 3
Training loss: 2.6691818237304688
Validation loss: 2.1442039423091437

Epoch: 6| Step: 4
Training loss: 2.41951584815979
Validation loss: 2.1483052853615052

Epoch: 6| Step: 5
Training loss: 2.4653282165527344
Validation loss: 2.1532327641722975

Epoch: 6| Step: 6
Training loss: 2.255169153213501
Validation loss: 2.172539339270643

Epoch: 6| Step: 7
Training loss: 2.2316043376922607
Validation loss: 2.157373318108179

Epoch: 6| Step: 8
Training loss: 2.9843757152557373
Validation loss: 2.156776835841517

Epoch: 6| Step: 9
Training loss: 2.301687002182007
Validation loss: 2.1605154314348773

Epoch: 6| Step: 10
Training loss: 2.9025421142578125
Validation loss: 2.16456272268808

Epoch: 6| Step: 11
Training loss: 2.3252501487731934
Validation loss: 2.1730693258265013

Epoch: 6| Step: 12
Training loss: 2.2406530380249023
Validation loss: 2.1790007570738434

Epoch: 6| Step: 13
Training loss: 1.10340416431427
Validation loss: 2.184329012388824

Epoch: 70| Step: 0
Training loss: 2.548612117767334
Validation loss: 2.175522450477846

Epoch: 6| Step: 1
Training loss: 2.0595223903656006
Validation loss: 2.1676808608475553

Epoch: 6| Step: 2
Training loss: 1.7416635751724243
Validation loss: 2.1624089261536956

Epoch: 6| Step: 3
Training loss: 2.8244783878326416
Validation loss: 2.1675857754163843

Epoch: 6| Step: 4
Training loss: 2.4395430088043213
Validation loss: 2.1670574923997283

Epoch: 6| Step: 5
Training loss: 1.8491337299346924
Validation loss: 2.169939802538964

Epoch: 6| Step: 6
Training loss: 2.7075188159942627
Validation loss: 2.14833487490172

Epoch: 6| Step: 7
Training loss: 2.4213006496429443
Validation loss: 2.1334304501933437

Epoch: 6| Step: 8
Training loss: 2.7475171089172363
Validation loss: 2.130495845630605

Epoch: 6| Step: 9
Training loss: 2.5757102966308594
Validation loss: 2.1283516217303533

Epoch: 6| Step: 10
Training loss: 2.5423812866210938
Validation loss: 2.129713027707992

Epoch: 6| Step: 11
Training loss: 2.4108712673187256
Validation loss: 2.1314784365315593

Epoch: 6| Step: 12
Training loss: 2.923691749572754
Validation loss: 2.1330566944614535

Epoch: 6| Step: 13
Training loss: 3.0331578254699707
Validation loss: 2.127595575906897

Epoch: 71| Step: 0
Training loss: 2.5358572006225586
Validation loss: 2.1372184138144217

Epoch: 6| Step: 1
Training loss: 2.234189748764038
Validation loss: 2.1427655245668147

Epoch: 6| Step: 2
Training loss: 2.8311147689819336
Validation loss: 2.156871085525841

Epoch: 6| Step: 3
Training loss: 2.768765449523926
Validation loss: 2.1807018031356153

Epoch: 6| Step: 4
Training loss: 2.1625139713287354
Validation loss: 2.183541856786256

Epoch: 6| Step: 5
Training loss: 2.166351318359375
Validation loss: 2.18134561405387

Epoch: 6| Step: 6
Training loss: 2.269235849380493
Validation loss: 2.1826424585875643

Epoch: 6| Step: 7
Training loss: 2.5869975090026855
Validation loss: 2.2065616192356234

Epoch: 6| Step: 8
Training loss: 2.8447492122650146
Validation loss: 2.224761143807442

Epoch: 6| Step: 9
Training loss: 2.5129194259643555
Validation loss: 2.2642683636757637

Epoch: 6| Step: 10
Training loss: 2.4904377460479736
Validation loss: 2.2678338763534382

Epoch: 6| Step: 11
Training loss: 2.542649269104004
Validation loss: 2.252125806705926

Epoch: 6| Step: 12
Training loss: 2.2645297050476074
Validation loss: 2.2333245597859865

Epoch: 6| Step: 13
Training loss: 1.9919883012771606
Validation loss: 2.1840858331290622

Epoch: 72| Step: 0
Training loss: 2.3306121826171875
Validation loss: 2.1531459439185356

Epoch: 6| Step: 1
Training loss: 2.323850154876709
Validation loss: 2.1386624856661727

Epoch: 6| Step: 2
Training loss: 2.5738677978515625
Validation loss: 2.1252045208407986

Epoch: 6| Step: 3
Training loss: 2.341431140899658
Validation loss: 2.1161490050695275

Epoch: 6| Step: 4
Training loss: 2.5988311767578125
Validation loss: 2.1143328810250885

Epoch: 6| Step: 5
Training loss: 2.1347644329071045
Validation loss: 2.116722991389613

Epoch: 6| Step: 6
Training loss: 2.612706184387207
Validation loss: 2.118003419650498

Epoch: 6| Step: 7
Training loss: 2.417494297027588
Validation loss: 2.1133413827547463

Epoch: 6| Step: 8
Training loss: 2.5775327682495117
Validation loss: 2.1181021736514185

Epoch: 6| Step: 9
Training loss: 2.7962372303009033
Validation loss: 2.1179148804756904

Epoch: 6| Step: 10
Training loss: 2.7686147689819336
Validation loss: 2.122858667886385

Epoch: 6| Step: 11
Training loss: 2.2711501121520996
Validation loss: 2.1257678398522

Epoch: 6| Step: 12
Training loss: 2.2096691131591797
Validation loss: 2.137986801003897

Epoch: 6| Step: 13
Training loss: 2.4312658309936523
Validation loss: 2.166858756414024

Epoch: 73| Step: 0
Training loss: 2.4270858764648438
Validation loss: 2.197990377744039

Epoch: 6| Step: 1
Training loss: 2.3584671020507812
Validation loss: 2.2231890283605105

Epoch: 6| Step: 2
Training loss: 2.584695339202881
Validation loss: 2.2591053388452016

Epoch: 6| Step: 3
Training loss: 1.943053126335144
Validation loss: 2.2359418305017615

Epoch: 6| Step: 4
Training loss: 2.6774961948394775
Validation loss: 2.236728124721076

Epoch: 6| Step: 5
Training loss: 2.506087303161621
Validation loss: 2.216167006441342

Epoch: 6| Step: 6
Training loss: 3.0285356044769287
Validation loss: 2.1936499098295807

Epoch: 6| Step: 7
Training loss: 2.7128219604492188
Validation loss: 2.146631228026523

Epoch: 6| Step: 8
Training loss: 2.0522563457489014
Validation loss: 2.1215784344621884

Epoch: 6| Step: 9
Training loss: 2.093860626220703
Validation loss: 2.1123740698701594

Epoch: 6| Step: 10
Training loss: 2.141921043395996
Validation loss: 2.1138630784967893

Epoch: 6| Step: 11
Training loss: 2.3698477745056152
Validation loss: 2.10532251609269

Epoch: 6| Step: 12
Training loss: 2.509443759918213
Validation loss: 2.1103836669716785

Epoch: 6| Step: 13
Training loss: 3.3868792057037354
Validation loss: 2.106487884316393

Epoch: 74| Step: 0
Training loss: 2.118349552154541
Validation loss: 2.109741387828704

Epoch: 6| Step: 1
Training loss: 2.4476404190063477
Validation loss: 2.1004083643677416

Epoch: 6| Step: 2
Training loss: 2.8580403327941895
Validation loss: 2.11016853650411

Epoch: 6| Step: 3
Training loss: 1.6774227619171143
Validation loss: 2.10489365618716

Epoch: 6| Step: 4
Training loss: 2.20993971824646
Validation loss: 2.1109022658358336

Epoch: 6| Step: 5
Training loss: 2.6689159870147705
Validation loss: 2.118100614957912

Epoch: 6| Step: 6
Training loss: 2.124706983566284
Validation loss: 2.1319660666168376

Epoch: 6| Step: 7
Training loss: 2.286482810974121
Validation loss: 2.1453201437509186

Epoch: 6| Step: 8
Training loss: 2.717986822128296
Validation loss: 2.1445367310636785

Epoch: 6| Step: 9
Training loss: 2.4060425758361816
Validation loss: 2.1485087845915105

Epoch: 6| Step: 10
Training loss: 2.8396553993225098
Validation loss: 2.139497060929575

Epoch: 6| Step: 11
Training loss: 2.9516396522521973
Validation loss: 2.1299123994765745

Epoch: 6| Step: 12
Training loss: 2.5342233180999756
Validation loss: 2.121850441860896

Epoch: 6| Step: 13
Training loss: 2.3693017959594727
Validation loss: 2.107986464295336

Epoch: 75| Step: 0
Training loss: 2.548982858657837
Validation loss: 2.1098057185449908

Epoch: 6| Step: 1
Training loss: 2.6983442306518555
Validation loss: 2.1152459293283443

Epoch: 6| Step: 2
Training loss: 2.806922197341919
Validation loss: 2.1129781738404305

Epoch: 6| Step: 3
Training loss: 2.0103952884674072
Validation loss: 2.113601118005732

Epoch: 6| Step: 4
Training loss: 2.5781021118164062
Validation loss: 2.119611788821477

Epoch: 6| Step: 5
Training loss: 2.169750452041626
Validation loss: 2.122244458044729

Epoch: 6| Step: 6
Training loss: 2.5334105491638184
Validation loss: 2.107481369408228

Epoch: 6| Step: 7
Training loss: 2.683518886566162
Validation loss: 2.109386582528391

Epoch: 6| Step: 8
Training loss: 2.5719165802001953
Validation loss: 2.1020436299744474

Epoch: 6| Step: 9
Training loss: 1.9070137739181519
Validation loss: 2.111196876854025

Epoch: 6| Step: 10
Training loss: 2.3479976654052734
Validation loss: 2.107829655370405

Epoch: 6| Step: 11
Training loss: 2.2649965286254883
Validation loss: 2.100546180561025

Epoch: 6| Step: 12
Training loss: 2.960031032562256
Validation loss: 2.103657013626509

Epoch: 6| Step: 13
Training loss: 1.3387224674224854
Validation loss: 2.1001540127620903

Epoch: 76| Step: 0
Training loss: 2.696138381958008
Validation loss: 2.1186756062251266

Epoch: 6| Step: 1
Training loss: 2.772104024887085
Validation loss: 2.1500988570592736

Epoch: 6| Step: 2
Training loss: 1.9199886322021484
Validation loss: 2.1661182731710453

Epoch: 6| Step: 3
Training loss: 1.6801018714904785
Validation loss: 2.1679885413057063

Epoch: 6| Step: 4
Training loss: 2.7796990871429443
Validation loss: 2.1693105877086682

Epoch: 6| Step: 5
Training loss: 2.301201820373535
Validation loss: 2.1546508163534184

Epoch: 6| Step: 6
Training loss: 3.195075273513794
Validation loss: 2.188532490884104

Epoch: 6| Step: 7
Training loss: 2.816683769226074
Validation loss: 2.247878195137106

Epoch: 6| Step: 8
Training loss: 1.5857272148132324
Validation loss: 2.309554938347109

Epoch: 6| Step: 9
Training loss: 3.1653366088867188
Validation loss: 2.360506811449605

Epoch: 6| Step: 10
Training loss: 2.438371181488037
Validation loss: 2.3565987899739254

Epoch: 6| Step: 11
Training loss: 2.4518704414367676
Validation loss: 2.352878109101326

Epoch: 6| Step: 12
Training loss: 2.536447048187256
Validation loss: 2.2994701913608018

Epoch: 6| Step: 13
Training loss: 2.2374072074890137
Validation loss: 2.199137790228731

Epoch: 77| Step: 0
Training loss: 2.090324640274048
Validation loss: 2.149692416191101

Epoch: 6| Step: 1
Training loss: 2.4351723194122314
Validation loss: 2.1152078618285475

Epoch: 6| Step: 2
Training loss: 1.6665358543395996
Validation loss: 2.083302895228068

Epoch: 6| Step: 3
Training loss: 3.078789234161377
Validation loss: 2.0934536123788483

Epoch: 6| Step: 4
Training loss: 2.8439877033233643
Validation loss: 2.10077081700807

Epoch: 6| Step: 5
Training loss: 2.922161340713501
Validation loss: 2.1064679417558896

Epoch: 6| Step: 6
Training loss: 1.8590404987335205
Validation loss: 2.104334000618227

Epoch: 6| Step: 7
Training loss: 2.54416561126709
Validation loss: 2.109296016795661

Epoch: 6| Step: 8
Training loss: 2.4158170223236084
Validation loss: 2.098665827064104

Epoch: 6| Step: 9
Training loss: 2.498504877090454
Validation loss: 2.0956779961944907

Epoch: 6| Step: 10
Training loss: 2.0839896202087402
Validation loss: 2.0988790809467273

Epoch: 6| Step: 11
Training loss: 2.539083480834961
Validation loss: 2.0959450980668426

Epoch: 6| Step: 12
Training loss: 2.508863925933838
Validation loss: 2.106310377838791

Epoch: 6| Step: 13
Training loss: 2.806407928466797
Validation loss: 2.111764261799474

Epoch: 78| Step: 0
Training loss: 2.533017635345459
Validation loss: 2.131277766278995

Epoch: 6| Step: 1
Training loss: 1.6179628372192383
Validation loss: 2.166581151305988

Epoch: 6| Step: 2
Training loss: 2.680401086807251
Validation loss: 2.1953061088438957

Epoch: 6| Step: 3
Training loss: 2.93457293510437
Validation loss: 2.225516644857263

Epoch: 6| Step: 4
Training loss: 2.0854451656341553
Validation loss: 2.237505203934126

Epoch: 6| Step: 5
Training loss: 2.3733272552490234
Validation loss: 2.2692889269962104

Epoch: 6| Step: 6
Training loss: 2.7014894485473633
Validation loss: 2.2421353581131145

Epoch: 6| Step: 7
Training loss: 1.9842820167541504
Validation loss: 2.1727191837885047

Epoch: 6| Step: 8
Training loss: 2.0225343704223633
Validation loss: 2.136083423450429

Epoch: 6| Step: 9
Training loss: 2.7189388275146484
Validation loss: 2.111877477297219

Epoch: 6| Step: 10
Training loss: 2.716543436050415
Validation loss: 2.0907809542071436

Epoch: 6| Step: 11
Training loss: 2.978755474090576
Validation loss: 2.098324147603845

Epoch: 6| Step: 12
Training loss: 2.573923110961914
Validation loss: 2.093350436097832

Epoch: 6| Step: 13
Training loss: 2.0835602283477783
Validation loss: 2.0923718662672144

Epoch: 79| Step: 0
Training loss: 2.294901132583618
Validation loss: 2.103151398320352

Epoch: 6| Step: 1
Training loss: 2.0172019004821777
Validation loss: 2.0981209149924656

Epoch: 6| Step: 2
Training loss: 2.542818307876587
Validation loss: 2.1061623686103412

Epoch: 6| Step: 3
Training loss: 2.2426764965057373
Validation loss: 2.113059571994248

Epoch: 6| Step: 4
Training loss: 2.2000679969787598
Validation loss: 2.1257097285280944

Epoch: 6| Step: 5
Training loss: 2.4599390029907227
Validation loss: 2.126549337499885

Epoch: 6| Step: 6
Training loss: 3.174752950668335
Validation loss: 2.145606706219335

Epoch: 6| Step: 7
Training loss: 2.0236051082611084
Validation loss: 2.150212408393942

Epoch: 6| Step: 8
Training loss: 2.5797066688537598
Validation loss: 2.1680927609884613

Epoch: 6| Step: 9
Training loss: 2.897141456604004
Validation loss: 2.18780795861316

Epoch: 6| Step: 10
Training loss: 2.882826805114746
Validation loss: 2.207083950760544

Epoch: 6| Step: 11
Training loss: 1.8243962526321411
Validation loss: 2.242283818542316

Epoch: 6| Step: 12
Training loss: 3.0021491050720215
Validation loss: 2.2547453475254837

Epoch: 6| Step: 13
Training loss: 1.3846783638000488
Validation loss: 2.2111850989762174

Epoch: 80| Step: 0
Training loss: 2.070953130722046
Validation loss: 2.176668856733589

Epoch: 6| Step: 1
Training loss: 2.8300788402557373
Validation loss: 2.155781240873439

Epoch: 6| Step: 2
Training loss: 2.4594359397888184
Validation loss: 2.126129256781711

Epoch: 6| Step: 3
Training loss: 2.697896718978882
Validation loss: 2.1166164657121063

Epoch: 6| Step: 4
Training loss: 2.5315403938293457
Validation loss: 2.1025851285585793

Epoch: 6| Step: 5
Training loss: 2.0006003379821777
Validation loss: 2.10763451104523

Epoch: 6| Step: 6
Training loss: 2.085482120513916
Validation loss: 2.1026295026143393

Epoch: 6| Step: 7
Training loss: 2.7222695350646973
Validation loss: 2.0964281507717666

Epoch: 6| Step: 8
Training loss: 3.0493011474609375
Validation loss: 2.0842662319060294

Epoch: 6| Step: 9
Training loss: 2.387631893157959
Validation loss: 2.092323454477454

Epoch: 6| Step: 10
Training loss: 2.565126895904541
Validation loss: 2.087636818167984

Epoch: 6| Step: 11
Training loss: 2.0579326152801514
Validation loss: 2.0886639959068707

Epoch: 6| Step: 12
Training loss: 2.2261407375335693
Validation loss: 2.1172700979376353

Epoch: 6| Step: 13
Training loss: 2.1938040256500244
Validation loss: 2.16466946242958

Epoch: 81| Step: 0
Training loss: 2.6676621437072754
Validation loss: 2.204871557092154

Epoch: 6| Step: 1
Training loss: 2.9898459911346436
Validation loss: 2.233999506119759

Epoch: 6| Step: 2
Training loss: 2.294184923171997
Validation loss: 2.3265616509222213

Epoch: 6| Step: 3
Training loss: 2.304900646209717
Validation loss: 2.3663541578477427

Epoch: 6| Step: 4
Training loss: 2.3474204540252686
Validation loss: 2.344848717412641

Epoch: 6| Step: 5
Training loss: 2.78170108795166
Validation loss: 2.3169910164289576

Epoch: 6| Step: 6
Training loss: 2.2985920906066895
Validation loss: 2.2840122689482985

Epoch: 6| Step: 7
Training loss: 2.57794451713562
Validation loss: 2.219722297883803

Epoch: 6| Step: 8
Training loss: 2.6047463417053223
Validation loss: 2.1882688563357116

Epoch: 6| Step: 9
Training loss: 1.9771184921264648
Validation loss: 2.1618430024834088

Epoch: 6| Step: 10
Training loss: 2.3847038745880127
Validation loss: 2.1412823712953957

Epoch: 6| Step: 11
Training loss: 2.6016769409179688
Validation loss: 2.103262262959634

Epoch: 6| Step: 12
Training loss: 2.4909486770629883
Validation loss: 2.0885309262942244

Epoch: 6| Step: 13
Training loss: 1.4908746480941772
Validation loss: 2.0834915766152005

Epoch: 82| Step: 0
Training loss: 2.7056989669799805
Validation loss: 2.0696116339775825

Epoch: 6| Step: 1
Training loss: 2.4405269622802734
Validation loss: 2.075004264872561

Epoch: 6| Step: 2
Training loss: 2.3962602615356445
Validation loss: 2.0712927387606714

Epoch: 6| Step: 3
Training loss: 2.303892135620117
Validation loss: 2.0611037015914917

Epoch: 6| Step: 4
Training loss: 2.892979621887207
Validation loss: 2.0661350975754442

Epoch: 6| Step: 5
Training loss: 3.035223960876465
Validation loss: 2.06192325263895

Epoch: 6| Step: 6
Training loss: 2.4740309715270996
Validation loss: 2.0607901824417936

Epoch: 6| Step: 7
Training loss: 2.3166966438293457
Validation loss: 2.0560593015404156

Epoch: 6| Step: 8
Training loss: 1.9309436082839966
Validation loss: 2.061775671538486

Epoch: 6| Step: 9
Training loss: 1.853982925415039
Validation loss: 2.070467474640057

Epoch: 6| Step: 10
Training loss: 2.526106595993042
Validation loss: 2.079328324205132

Epoch: 6| Step: 11
Training loss: 2.3178153038024902
Validation loss: 2.098127511239821

Epoch: 6| Step: 12
Training loss: 1.9045392274856567
Validation loss: 2.117080347512358

Epoch: 6| Step: 13
Training loss: 2.335202217102051
Validation loss: 2.1600011112869426

Epoch: 83| Step: 0
Training loss: 2.1078522205352783
Validation loss: 2.18244602346933

Epoch: 6| Step: 1
Training loss: 2.259981393814087
Validation loss: 2.2446333259664555

Epoch: 6| Step: 2
Training loss: 2.6999917030334473
Validation loss: 2.2797737377946095

Epoch: 6| Step: 3
Training loss: 2.716765880584717
Validation loss: 2.2274843262087916

Epoch: 6| Step: 4
Training loss: 2.889768600463867
Validation loss: 2.1743840120171987

Epoch: 6| Step: 5
Training loss: 2.7314271926879883
Validation loss: 2.1124062358692126

Epoch: 6| Step: 6
Training loss: 3.164419651031494
Validation loss: 2.065477150742726

Epoch: 6| Step: 7
Training loss: 1.7448996305465698
Validation loss: 2.055020163136144

Epoch: 6| Step: 8
Training loss: 1.6532745361328125
Validation loss: 2.0667922983887377

Epoch: 6| Step: 9
Training loss: 2.2399251461029053
Validation loss: 2.0662882981761808

Epoch: 6| Step: 10
Training loss: 2.8060302734375
Validation loss: 2.058947055570541

Epoch: 6| Step: 11
Training loss: 2.383657932281494
Validation loss: 2.0653455744507494

Epoch: 6| Step: 12
Training loss: 2.456155776977539
Validation loss: 2.0573835667743476

Epoch: 6| Step: 13
Training loss: 1.9759423732757568
Validation loss: 2.045137207995179

Epoch: 84| Step: 0
Training loss: 2.341723680496216
Validation loss: 2.0553414385805846

Epoch: 6| Step: 1
Training loss: 2.4443483352661133
Validation loss: 2.0539870236509588

Epoch: 6| Step: 2
Training loss: 2.653182029724121
Validation loss: 2.053090295483989

Epoch: 6| Step: 3
Training loss: 3.024811267852783
Validation loss: 2.0689757959817046

Epoch: 6| Step: 4
Training loss: 1.7935240268707275
Validation loss: 2.081215778986613

Epoch: 6| Step: 5
Training loss: 2.16853666305542
Validation loss: 2.083838483338715

Epoch: 6| Step: 6
Training loss: 2.769886016845703
Validation loss: 2.096186989097185

Epoch: 6| Step: 7
Training loss: 2.0774309635162354
Validation loss: 2.1049726188823743

Epoch: 6| Step: 8
Training loss: 2.1562247276306152
Validation loss: 2.1354797142808155

Epoch: 6| Step: 9
Training loss: 2.556553363800049
Validation loss: 2.1645750255994898

Epoch: 6| Step: 10
Training loss: 1.9823582172393799
Validation loss: 2.22648891838648

Epoch: 6| Step: 11
Training loss: 2.9853591918945312
Validation loss: 2.26001525181596

Epoch: 6| Step: 12
Training loss: 2.9654037952423096
Validation loss: 2.2747614716970794

Epoch: 6| Step: 13
Training loss: 1.4623103141784668
Validation loss: 2.195072421463587

Epoch: 85| Step: 0
Training loss: 2.0076756477355957
Validation loss: 2.1471269899798977

Epoch: 6| Step: 1
Training loss: 2.6448636054992676
Validation loss: 2.118570139331202

Epoch: 6| Step: 2
Training loss: 2.481339931488037
Validation loss: 2.096710007677796

Epoch: 6| Step: 3
Training loss: 2.1735315322875977
Validation loss: 2.0681282294693815

Epoch: 6| Step: 4
Training loss: 2.745434284210205
Validation loss: 2.0570856396869948

Epoch: 6| Step: 5
Training loss: 2.6781418323516846
Validation loss: 2.050510899994963

Epoch: 6| Step: 6
Training loss: 2.0331223011016846
Validation loss: 2.0507447719573975

Epoch: 6| Step: 7
Training loss: 2.030465602874756
Validation loss: 2.0528968687980407

Epoch: 6| Step: 8
Training loss: 2.6885390281677246
Validation loss: 2.043673848593107

Epoch: 6| Step: 9
Training loss: 2.6357321739196777
Validation loss: 2.0408072471618652

Epoch: 6| Step: 10
Training loss: 2.446368932723999
Validation loss: 2.042971941732591

Epoch: 6| Step: 11
Training loss: 2.0202457904815674
Validation loss: 2.0490383166138844

Epoch: 6| Step: 12
Training loss: 2.125857353210449
Validation loss: 2.0472441950151996

Epoch: 6| Step: 13
Training loss: 2.8229894638061523
Validation loss: 2.0446770306556457

Epoch: 86| Step: 0
Training loss: 2.3808045387268066
Validation loss: 2.0432126778428272

Epoch: 6| Step: 1
Training loss: 2.5612239837646484
Validation loss: 2.0370169967733402

Epoch: 6| Step: 2
Training loss: 3.058208465576172
Validation loss: 2.046022258779054

Epoch: 6| Step: 3
Training loss: 2.469170570373535
Validation loss: 2.047681039379489

Epoch: 6| Step: 4
Training loss: 2.9121594429016113
Validation loss: 2.0549758018985873

Epoch: 6| Step: 5
Training loss: 1.7018797397613525
Validation loss: 2.0570909515503915

Epoch: 6| Step: 6
Training loss: 2.9168620109558105
Validation loss: 2.0793496716407036

Epoch: 6| Step: 7
Training loss: 2.0723791122436523
Validation loss: 2.097306454053489

Epoch: 6| Step: 8
Training loss: 2.005622148513794
Validation loss: 2.113336665655977

Epoch: 6| Step: 9
Training loss: 2.042459487915039
Validation loss: 2.129446336018142

Epoch: 6| Step: 10
Training loss: 2.0868678092956543
Validation loss: 2.124446074167887

Epoch: 6| Step: 11
Training loss: 2.4784348011016846
Validation loss: 2.1311890463675223

Epoch: 6| Step: 12
Training loss: 2.624765634536743
Validation loss: 2.1324609223232476

Epoch: 6| Step: 13
Training loss: 2.4497532844543457
Validation loss: 2.1111911060989543

Epoch: 87| Step: 0
Training loss: 2.189901351928711
Validation loss: 2.0938767310111754

Epoch: 6| Step: 1
Training loss: 1.8330656290054321
Validation loss: 2.0772036711374917

Epoch: 6| Step: 2
Training loss: 2.9801127910614014
Validation loss: 2.0640293167483423

Epoch: 6| Step: 3
Training loss: 2.2404356002807617
Validation loss: 2.0456859834732546

Epoch: 6| Step: 4
Training loss: 2.4209747314453125
Validation loss: 2.045847959415887

Epoch: 6| Step: 5
Training loss: 2.4391236305236816
Validation loss: 2.0506457205741637

Epoch: 6| Step: 6
Training loss: 2.444131851196289
Validation loss: 2.0620711054853214

Epoch: 6| Step: 7
Training loss: 1.7579092979431152
Validation loss: 2.0630499573164087

Epoch: 6| Step: 8
Training loss: 2.815196990966797
Validation loss: 2.05824436167235

Epoch: 6| Step: 9
Training loss: 2.212171792984009
Validation loss: 2.0523598963214504

Epoch: 6| Step: 10
Training loss: 2.4046483039855957
Validation loss: 2.0591624077930244

Epoch: 6| Step: 11
Training loss: 2.4991862773895264
Validation loss: 2.0499320889032013

Epoch: 6| Step: 12
Training loss: 3.056251049041748
Validation loss: 2.045543348917397

Epoch: 6| Step: 13
Training loss: 2.6749627590179443
Validation loss: 2.0408547950047318

Epoch: 88| Step: 0
Training loss: 2.7924342155456543
Validation loss: 2.0412089414494012

Epoch: 6| Step: 1
Training loss: 2.412247657775879
Validation loss: 2.0428615065031153

Epoch: 6| Step: 2
Training loss: 2.76007080078125
Validation loss: 2.0554560256260697

Epoch: 6| Step: 3
Training loss: 2.5358808040618896
Validation loss: 2.06702253126329

Epoch: 6| Step: 4
Training loss: 1.8848031759262085
Validation loss: 2.1013159008436304

Epoch: 6| Step: 5
Training loss: 2.308405637741089
Validation loss: 2.0719803558882846

Epoch: 6| Step: 6
Training loss: 2.6745448112487793
Validation loss: 2.0663139051006687

Epoch: 6| Step: 7
Training loss: 2.38731050491333
Validation loss: 2.058956973014339

Epoch: 6| Step: 8
Training loss: 2.4792909622192383
Validation loss: 2.0577351290692567

Epoch: 6| Step: 9
Training loss: 1.8894472122192383
Validation loss: 2.049584701497068

Epoch: 6| Step: 10
Training loss: 2.1013309955596924
Validation loss: 2.0510391317388064

Epoch: 6| Step: 11
Training loss: 2.6965556144714355
Validation loss: 2.0653417841080697

Epoch: 6| Step: 12
Training loss: 2.0763773918151855
Validation loss: 2.103454887226064

Epoch: 6| Step: 13
Training loss: 2.093338966369629
Validation loss: 2.0957880109869023

Epoch: 89| Step: 0
Training loss: 1.6366395950317383
Validation loss: 2.0736897401912238

Epoch: 6| Step: 1
Training loss: 1.9891717433929443
Validation loss: 2.0565485877375447

Epoch: 6| Step: 2
Training loss: 2.1737077236175537
Validation loss: 2.031962343441543

Epoch: 6| Step: 3
Training loss: 3.1555190086364746
Validation loss: 2.03220054282937

Epoch: 6| Step: 4
Training loss: 2.2245326042175293
Validation loss: 2.024578340591923

Epoch: 6| Step: 5
Training loss: 2.4433913230895996
Validation loss: 2.0253015192606116

Epoch: 6| Step: 6
Training loss: 3.215794801712036
Validation loss: 2.0262353522803194

Epoch: 6| Step: 7
Training loss: 1.8331022262573242
Validation loss: 2.0320265600758214

Epoch: 6| Step: 8
Training loss: 2.7221477031707764
Validation loss: 2.0332311161102785

Epoch: 6| Step: 9
Training loss: 2.3953044414520264
Validation loss: 2.0311701989942983

Epoch: 6| Step: 10
Training loss: 2.440011501312256
Validation loss: 2.0290794782741095

Epoch: 6| Step: 11
Training loss: 2.625771999359131
Validation loss: 2.0429294237526516

Epoch: 6| Step: 12
Training loss: 2.2482223510742188
Validation loss: 2.024901772058138

Epoch: 6| Step: 13
Training loss: 2.1429190635681152
Validation loss: 2.0334088802337646

Epoch: 90| Step: 0
Training loss: 2.201594829559326
Validation loss: 2.029792683098906

Epoch: 6| Step: 1
Training loss: 2.7844090461730957
Validation loss: 2.0156622061165432

Epoch: 6| Step: 2
Training loss: 2.4259262084960938
Validation loss: 2.0243835346673125

Epoch: 6| Step: 3
Training loss: 2.160942554473877
Validation loss: 2.044918026975406

Epoch: 6| Step: 4
Training loss: 2.088958978652954
Validation loss: 2.070228156223092

Epoch: 6| Step: 5
Training loss: 2.3034768104553223
Validation loss: 2.1057999146881925

Epoch: 6| Step: 6
Training loss: 3.42276668548584
Validation loss: 2.1560398917044363

Epoch: 6| Step: 7
Training loss: 2.307846784591675
Validation loss: 2.238436729677262

Epoch: 6| Step: 8
Training loss: 2.41340970993042
Validation loss: 2.3002949299350863

Epoch: 6| Step: 9
Training loss: 2.0184760093688965
Validation loss: 2.301620057834092

Epoch: 6| Step: 10
Training loss: 2.283538818359375
Validation loss: 2.302812368639054

Epoch: 6| Step: 11
Training loss: 2.686264991760254
Validation loss: 2.2395250951090167

Epoch: 6| Step: 12
Training loss: 2.3236002922058105
Validation loss: 2.117750055046492

Epoch: 6| Step: 13
Training loss: 1.980904459953308
Validation loss: 2.0309539430884906

Epoch: 91| Step: 0
Training loss: 2.479304790496826
Validation loss: 2.0186132641248804

Epoch: 6| Step: 1
Training loss: 2.2174549102783203
Validation loss: 2.029937759522469

Epoch: 6| Step: 2
Training loss: 2.0476179122924805
Validation loss: 2.0489125187679003

Epoch: 6| Step: 3
Training loss: 2.8218116760253906
Validation loss: 2.047125575362995

Epoch: 6| Step: 4
Training loss: 2.6995952129364014
Validation loss: 2.054449519803447

Epoch: 6| Step: 5
Training loss: 2.4793171882629395
Validation loss: 2.047462735124814

Epoch: 6| Step: 6
Training loss: 2.0562901496887207
Validation loss: 2.03984538842273

Epoch: 6| Step: 7
Training loss: 2.0809249877929688
Validation loss: 2.027612884839376

Epoch: 6| Step: 8
Training loss: 2.598137617111206
Validation loss: 2.0099110295695644

Epoch: 6| Step: 9
Training loss: 2.458528518676758
Validation loss: 2.0116400834052794

Epoch: 6| Step: 10
Training loss: 1.9125138521194458
Validation loss: 2.0249329972010788

Epoch: 6| Step: 11
Training loss: 2.8162567615509033
Validation loss: 2.0701925908365557

Epoch: 6| Step: 12
Training loss: 2.805202007293701
Validation loss: 2.1234750722044256

Epoch: 6| Step: 13
Training loss: 2.2679035663604736
Validation loss: 2.1971008700709187

Epoch: 92| Step: 0
Training loss: 3.1244215965270996
Validation loss: 2.1935787893110708

Epoch: 6| Step: 1
Training loss: 2.614312171936035
Validation loss: 2.158841677891311

Epoch: 6| Step: 2
Training loss: 2.287062406539917
Validation loss: 2.1446569940095306

Epoch: 6| Step: 3
Training loss: 1.954043984413147
Validation loss: 2.117136457914947

Epoch: 6| Step: 4
Training loss: 1.7759008407592773
Validation loss: 2.077730460833478

Epoch: 6| Step: 5
Training loss: 2.0220282077789307
Validation loss: 2.0436409288837063

Epoch: 6| Step: 6
Training loss: 1.9125914573669434
Validation loss: 2.00594574405301

Epoch: 6| Step: 7
Training loss: 2.6419591903686523
Validation loss: 2.005379246127221

Epoch: 6| Step: 8
Training loss: 2.4789700508117676
Validation loss: 2.011721928914388

Epoch: 6| Step: 9
Training loss: 2.7422361373901367
Validation loss: 2.0055923244004608

Epoch: 6| Step: 10
Training loss: 2.577876329421997
Validation loss: 2.006580711692892

Epoch: 6| Step: 11
Training loss: 2.363410472869873
Validation loss: 2.0122047009006625

Epoch: 6| Step: 12
Training loss: 2.157835006713867
Validation loss: 2.0058142087792836

Epoch: 6| Step: 13
Training loss: 2.465299606323242
Validation loss: 2.0022958722165836

Epoch: 93| Step: 0
Training loss: 2.0386505126953125
Validation loss: 2.0114051257410357

Epoch: 6| Step: 1
Training loss: 2.1953821182250977
Validation loss: 2.0031240550420617

Epoch: 6| Step: 2
Training loss: 2.633784532546997
Validation loss: 2.0037350987875335

Epoch: 6| Step: 3
Training loss: 2.286679267883301
Validation loss: 2.011094027949918

Epoch: 6| Step: 4
Training loss: 2.4558792114257812
Validation loss: 2.0172815028057305

Epoch: 6| Step: 5
Training loss: 2.6598024368286133
Validation loss: 2.034883032562912

Epoch: 6| Step: 6
Training loss: 2.2279653549194336
Validation loss: 2.0354233800723986

Epoch: 6| Step: 7
Training loss: 2.316035747528076
Validation loss: 2.0379297758943293

Epoch: 6| Step: 8
Training loss: 2.6964972019195557
Validation loss: 2.037907718330301

Epoch: 6| Step: 9
Training loss: 3.019326686859131
Validation loss: 2.0448355674743652

Epoch: 6| Step: 10
Training loss: 2.40794038772583
Validation loss: 2.042713028128429

Epoch: 6| Step: 11
Training loss: 1.6837316751480103
Validation loss: 2.0390060845241753

Epoch: 6| Step: 12
Training loss: 1.8059394359588623
Validation loss: 2.048115627740019

Epoch: 6| Step: 13
Training loss: 2.478764772415161
Validation loss: 2.052746820193465

Epoch: 94| Step: 0
Training loss: 2.541419267654419
Validation loss: 2.0734669521290767

Epoch: 6| Step: 1
Training loss: 2.8193013668060303
Validation loss: 2.0818444426341722

Epoch: 6| Step: 2
Training loss: 2.3080286979675293
Validation loss: 2.0805105932297243

Epoch: 6| Step: 3
Training loss: 2.8008346557617188
Validation loss: 2.0873745949037614

Epoch: 6| Step: 4
Training loss: 2.077242851257324
Validation loss: 2.0917379727927585

Epoch: 6| Step: 5
Training loss: 2.397986888885498
Validation loss: 2.1066936344228764

Epoch: 6| Step: 6
Training loss: 1.8863203525543213
Validation loss: 2.0989387163551907

Epoch: 6| Step: 7
Training loss: 2.840182065963745
Validation loss: 2.1085309302935036

Epoch: 6| Step: 8
Training loss: 2.5073108673095703
Validation loss: 2.115781112383771

Epoch: 6| Step: 9
Training loss: 1.8200109004974365
Validation loss: 2.0880258852435696

Epoch: 6| Step: 10
Training loss: 2.2782273292541504
Validation loss: 2.0925298852305256

Epoch: 6| Step: 11
Training loss: 2.03324556350708
Validation loss: 2.0591981616071475

Epoch: 6| Step: 12
Training loss: 1.84992253780365
Validation loss: 2.042756408773443

Epoch: 6| Step: 13
Training loss: 2.66603684425354
Validation loss: 2.0158517642687728

Epoch: 95| Step: 0
Training loss: 1.8879380226135254
Validation loss: 2.013093827873148

Epoch: 6| Step: 1
Training loss: 2.367748260498047
Validation loss: 2.017728679923601

Epoch: 6| Step: 2
Training loss: 1.8999838829040527
Validation loss: 2.0033523369860906

Epoch: 6| Step: 3
Training loss: 2.645585536956787
Validation loss: 2.011998584193568

Epoch: 6| Step: 4
Training loss: 2.8189797401428223
Validation loss: 2.0158974175812094

Epoch: 6| Step: 5
Training loss: 2.1534266471862793
Validation loss: 2.007552800639983

Epoch: 6| Step: 6
Training loss: 2.5137248039245605
Validation loss: 2.0065441311046643

Epoch: 6| Step: 7
Training loss: 2.7133069038391113
Validation loss: 2.045193346597815

Epoch: 6| Step: 8
Training loss: 2.0251731872558594
Validation loss: 2.0630606733342653

Epoch: 6| Step: 9
Training loss: 2.0030465126037598
Validation loss: 2.0965368568256335

Epoch: 6| Step: 10
Training loss: 2.4957098960876465
Validation loss: 2.093696580138258

Epoch: 6| Step: 11
Training loss: 2.4279966354370117
Validation loss: 2.056308023391231

Epoch: 6| Step: 12
Training loss: 2.356518268585205
Validation loss: 2.053472531739102

Epoch: 6| Step: 13
Training loss: 3.263233184814453
Validation loss: 2.043858789628552

Epoch: 96| Step: 0
Training loss: 2.7067337036132812
Validation loss: 2.0385941202922533

Epoch: 6| Step: 1
Training loss: 2.028621196746826
Validation loss: 2.0443336194561375

Epoch: 6| Step: 2
Training loss: 2.7513489723205566
Validation loss: 2.02808310908656

Epoch: 6| Step: 3
Training loss: 1.6339612007141113
Validation loss: 2.024374927243879

Epoch: 6| Step: 4
Training loss: 2.3466973304748535
Validation loss: 2.035929972125638

Epoch: 6| Step: 5
Training loss: 2.4291892051696777
Validation loss: 2.036356992619012

Epoch: 6| Step: 6
Training loss: 3.177582025527954
Validation loss: 2.032753723923878

Epoch: 6| Step: 7
Training loss: 2.273743152618408
Validation loss: 2.0327173702178465

Epoch: 6| Step: 8
Training loss: 2.367570161819458
Validation loss: 2.0174083863535235

Epoch: 6| Step: 9
Training loss: 2.031327724456787
Validation loss: 2.0123722873708254

Epoch: 6| Step: 10
Training loss: 2.5259389877319336
Validation loss: 2.012386491221766

Epoch: 6| Step: 11
Training loss: 2.5930709838867188
Validation loss: 1.9964350218413978

Epoch: 6| Step: 12
Training loss: 1.7485579252243042
Validation loss: 1.9928894299332813

Epoch: 6| Step: 13
Training loss: 2.0420124530792236
Validation loss: 2.0022325977202384

Epoch: 97| Step: 0
Training loss: 2.5614328384399414
Validation loss: 1.9875041361778014

Epoch: 6| Step: 1
Training loss: 3.003117799758911
Validation loss: 1.9959652129039969

Epoch: 6| Step: 2
Training loss: 1.3510431051254272
Validation loss: 1.9886666933695476

Epoch: 6| Step: 3
Training loss: 3.114264965057373
Validation loss: 1.983754324656661

Epoch: 6| Step: 4
Training loss: 2.536858081817627
Validation loss: 1.9840246772253385

Epoch: 6| Step: 5
Training loss: 2.9783525466918945
Validation loss: 1.9929446456252888

Epoch: 6| Step: 6
Training loss: 2.4957001209259033
Validation loss: 1.9961425719722625

Epoch: 6| Step: 7
Training loss: 1.632319688796997
Validation loss: 1.9969730018287577

Epoch: 6| Step: 8
Training loss: 2.809687614440918
Validation loss: 1.9896345215459024

Epoch: 6| Step: 9
Training loss: 1.8817092180252075
Validation loss: 2.008709162794134

Epoch: 6| Step: 10
Training loss: 2.9645438194274902
Validation loss: 2.0460099904767928

Epoch: 6| Step: 11
Training loss: 1.6033935546875
Validation loss: 2.0576592619701097

Epoch: 6| Step: 12
Training loss: 1.6797966957092285
Validation loss: 2.066001876708

Epoch: 6| Step: 13
Training loss: 2.2274787425994873
Validation loss: 2.0606873548159035

Epoch: 98| Step: 0
Training loss: 2.223437547683716
Validation loss: 2.070859129710864

Epoch: 6| Step: 1
Training loss: 2.446359157562256
Validation loss: 2.0523337664142733

Epoch: 6| Step: 2
Training loss: 1.954057216644287
Validation loss: 2.0309985312082435

Epoch: 6| Step: 3
Training loss: 2.643613815307617
Validation loss: 1.9994858618705504

Epoch: 6| Step: 4
Training loss: 1.752463459968567
Validation loss: 1.9972442439807359

Epoch: 6| Step: 5
Training loss: 2.662818193435669
Validation loss: 1.9900864939535818

Epoch: 6| Step: 6
Training loss: 2.408043384552002
Validation loss: 1.9824124023478518

Epoch: 6| Step: 7
Training loss: 2.251378059387207
Validation loss: 1.9919543779024513

Epoch: 6| Step: 8
Training loss: 2.5251636505126953
Validation loss: 1.9897920611084148

Epoch: 6| Step: 9
Training loss: 2.4973068237304688
Validation loss: 1.988855436284055

Epoch: 6| Step: 10
Training loss: 2.9807307720184326
Validation loss: 1.9854961774682487

Epoch: 6| Step: 11
Training loss: 2.241273880004883
Validation loss: 1.9910849960901404

Epoch: 6| Step: 12
Training loss: 2.157930374145508
Validation loss: 1.9852741277346047

Epoch: 6| Step: 13
Training loss: 1.8214678764343262
Validation loss: 1.9921341685838596

Epoch: 99| Step: 0
Training loss: 2.644636392593384
Validation loss: 1.9941925899956816

Epoch: 6| Step: 1
Training loss: 2.1999478340148926
Validation loss: 2.0271724731691423

Epoch: 6| Step: 2
Training loss: 2.4184420108795166
Validation loss: 2.077681585024762

Epoch: 6| Step: 3
Training loss: 2.5474538803100586
Validation loss: 2.1060394766510173

Epoch: 6| Step: 4
Training loss: 2.3125572204589844
Validation loss: 2.13994715931595

Epoch: 6| Step: 5
Training loss: 2.5742666721343994
Validation loss: 2.2208382262978503

Epoch: 6| Step: 6
Training loss: 2.2274539470672607
Validation loss: 2.329728158571387

Epoch: 6| Step: 7
Training loss: 1.9342323541641235
Validation loss: 2.312882154218612

Epoch: 6| Step: 8
Training loss: 2.4390926361083984
Validation loss: 2.2895496737572456

Epoch: 6| Step: 9
Training loss: 2.583767890930176
Validation loss: 2.2481526943945114

Epoch: 6| Step: 10
Training loss: 2.7601475715637207
Validation loss: 2.236436508035147

Epoch: 6| Step: 11
Training loss: 2.326702117919922
Validation loss: 2.1273425458579935

Epoch: 6| Step: 12
Training loss: 2.2992358207702637
Validation loss: 2.090013478391914

Epoch: 6| Step: 13
Training loss: 2.3455560207366943
Validation loss: 2.033507823944092

Epoch: 100| Step: 0
Training loss: 2.3615806102752686
Validation loss: 2.0118633880410144

Epoch: 6| Step: 1
Training loss: 2.374567985534668
Validation loss: 1.9880403754531697

Epoch: 6| Step: 2
Training loss: 2.2278966903686523
Validation loss: 1.9956455243531095

Epoch: 6| Step: 3
Training loss: 2.335476875305176
Validation loss: 1.999034486791139

Epoch: 6| Step: 4
Training loss: 2.7107937335968018
Validation loss: 2.013252346746383

Epoch: 6| Step: 5
Training loss: 2.771139621734619
Validation loss: 2.0053192159181

Epoch: 6| Step: 6
Training loss: 1.406172275543213
Validation loss: 2.018111518634263

Epoch: 6| Step: 7
Training loss: 1.8381047248840332
Validation loss: 2.02133350218496

Epoch: 6| Step: 8
Training loss: 2.667571544647217
Validation loss: 2.03256417089893

Epoch: 6| Step: 9
Training loss: 1.6822011470794678
Validation loss: 2.047023416847311

Epoch: 6| Step: 10
Training loss: 2.236893653869629
Validation loss: 2.070198351337064

Epoch: 6| Step: 11
Training loss: 2.4832029342651367
Validation loss: 2.128942370414734

Epoch: 6| Step: 12
Training loss: 2.764437198638916
Validation loss: 2.119555979646662

Epoch: 6| Step: 13
Training loss: 3.150477647781372
Validation loss: 2.074418931879023

Epoch: 101| Step: 0
Training loss: 2.5583744049072266
Validation loss: 2.0057006574446157

Epoch: 6| Step: 1
Training loss: 2.489743709564209
Validation loss: 2.0015635618599514

Epoch: 6| Step: 2
Training loss: 2.3496556282043457
Validation loss: 2.0129566833537114

Epoch: 6| Step: 3
Training loss: 1.8678257465362549
Validation loss: 2.0166458211919314

Epoch: 6| Step: 4
Training loss: 2.4535622596740723
Validation loss: 2.0395708725016606

Epoch: 6| Step: 5
Training loss: 3.3767457008361816
Validation loss: 2.0395160054647796

Epoch: 6| Step: 6
Training loss: 1.8303453922271729
Validation loss: 2.045084212415962

Epoch: 6| Step: 7
Training loss: 2.4895212650299072
Validation loss: 2.0805028728259507

Epoch: 6| Step: 8
Training loss: 1.8509663343429565
Validation loss: 2.0638314729095786

Epoch: 6| Step: 9
Training loss: 2.619161605834961
Validation loss: 2.0726489059386717

Epoch: 6| Step: 10
Training loss: 2.5422768592834473
Validation loss: 2.042015783248409

Epoch: 6| Step: 11
Training loss: 2.5129826068878174
Validation loss: 2.0163660767257854

Epoch: 6| Step: 12
Training loss: 1.1835421323776245
Validation loss: 1.9819851254904142

Epoch: 6| Step: 13
Training loss: 2.9718878269195557
Validation loss: 1.9752042408912414

Epoch: 102| Step: 0
Training loss: 2.2575368881225586
Validation loss: 1.9684739881946194

Epoch: 6| Step: 1
Training loss: 1.8504154682159424
Validation loss: 1.9691702858094247

Epoch: 6| Step: 2
Training loss: 1.6631205081939697
Validation loss: 1.960754257376476

Epoch: 6| Step: 3
Training loss: 1.9561238288879395
Validation loss: 1.9628732281346475

Epoch: 6| Step: 4
Training loss: 2.6575591564178467
Validation loss: 1.9625133827168455

Epoch: 6| Step: 5
Training loss: 2.6149439811706543
Validation loss: 1.9608853658040364

Epoch: 6| Step: 6
Training loss: 2.615785598754883
Validation loss: 1.9615510484223724

Epoch: 6| Step: 7
Training loss: 2.3823776245117188
Validation loss: 1.9604411035455682

Epoch: 6| Step: 8
Training loss: 2.8461222648620605
Validation loss: 1.9702369936050907

Epoch: 6| Step: 9
Training loss: 2.6507935523986816
Validation loss: 1.970257979567333

Epoch: 6| Step: 10
Training loss: 2.248277187347412
Validation loss: 1.9787740143396522

Epoch: 6| Step: 11
Training loss: 2.431267738342285
Validation loss: 1.988913833454091

Epoch: 6| Step: 12
Training loss: 2.2073535919189453
Validation loss: 1.9936458115936608

Epoch: 6| Step: 13
Training loss: 1.575541377067566
Validation loss: 2.0044088107283398

Epoch: 103| Step: 0
Training loss: 2.753798723220825
Validation loss: 2.01257574430076

Epoch: 6| Step: 1
Training loss: 1.8106410503387451
Validation loss: 2.020660545236321

Epoch: 6| Step: 2
Training loss: 1.4283127784729004
Validation loss: 1.9868519408728487

Epoch: 6| Step: 3
Training loss: 2.979315996170044
Validation loss: 1.9738714233521493

Epoch: 6| Step: 4
Training loss: 1.8433455228805542
Validation loss: 1.9609204056442424

Epoch: 6| Step: 5
Training loss: 2.532778739929199
Validation loss: 1.9678026578759635

Epoch: 6| Step: 6
Training loss: 2.314711570739746
Validation loss: 1.9591266750007548

Epoch: 6| Step: 7
Training loss: 2.4626407623291016
Validation loss: 1.9642284749656596

Epoch: 6| Step: 8
Training loss: 2.1802072525024414
Validation loss: 1.9666351451668689

Epoch: 6| Step: 9
Training loss: 2.2314581871032715
Validation loss: 1.9754842289032475

Epoch: 6| Step: 10
Training loss: 2.733468532562256
Validation loss: 1.9745528364694247

Epoch: 6| Step: 11
Training loss: 2.3629069328308105
Validation loss: 1.9756883011069348

Epoch: 6| Step: 12
Training loss: 2.8858869075775146
Validation loss: 1.9583667080889466

Epoch: 6| Step: 13
Training loss: 1.4468103647232056
Validation loss: 1.9656627473010813

Epoch: 104| Step: 0
Training loss: 2.1785824298858643
Validation loss: 1.975460002499242

Epoch: 6| Step: 1
Training loss: 2.566092014312744
Validation loss: 2.0034712694024526

Epoch: 6| Step: 2
Training loss: 2.578500270843506
Validation loss: 2.0254799960761942

Epoch: 6| Step: 3
Training loss: 2.936192274093628
Validation loss: 2.0391248323584117

Epoch: 6| Step: 4
Training loss: 2.404489040374756
Validation loss: 2.0525617214941208

Epoch: 6| Step: 5
Training loss: 1.2106374502182007
Validation loss: 2.0045404844386603

Epoch: 6| Step: 6
Training loss: 2.520709276199341
Validation loss: 1.9809051636726625

Epoch: 6| Step: 7
Training loss: 2.3464818000793457
Validation loss: 1.9832917157039847

Epoch: 6| Step: 8
Training loss: 2.5957422256469727
Validation loss: 1.9500272145835302

Epoch: 6| Step: 9
Training loss: 2.103069305419922
Validation loss: 1.948603060937697

Epoch: 6| Step: 10
Training loss: 2.4233012199401855
Validation loss: 1.9443668165514547

Epoch: 6| Step: 11
Training loss: 1.9663307666778564
Validation loss: 1.9436639188438334

Epoch: 6| Step: 12
Training loss: 2.4802136421203613
Validation loss: 1.9498393997069328

Epoch: 6| Step: 13
Training loss: 1.7468196153640747
Validation loss: 1.950101270470568

Epoch: 105| Step: 0
Training loss: 2.499462842941284
Validation loss: 1.9522204206835838

Epoch: 6| Step: 1
Training loss: 1.9624135494232178
Validation loss: 1.968109497459986

Epoch: 6| Step: 2
Training loss: 2.5646300315856934
Validation loss: 1.9737883883137857

Epoch: 6| Step: 3
Training loss: 2.318108558654785
Validation loss: 1.9992381911123953

Epoch: 6| Step: 4
Training loss: 2.56172513961792
Validation loss: 2.005981924713299

Epoch: 6| Step: 5
Training loss: 2.109457015991211
Validation loss: 2.034395997242261

Epoch: 6| Step: 6
Training loss: 2.3465614318847656
Validation loss: 2.0549576705501926

Epoch: 6| Step: 7
Training loss: 2.635399341583252
Validation loss: 2.031615008590042

Epoch: 6| Step: 8
Training loss: 1.8830779790878296
Validation loss: 2.008112317772322

Epoch: 6| Step: 9
Training loss: 2.7246665954589844
Validation loss: 1.9791971996266355

Epoch: 6| Step: 10
Training loss: 2.759841203689575
Validation loss: 1.9672537529340355

Epoch: 6| Step: 11
Training loss: 2.6705379486083984
Validation loss: 1.9559066487896828

Epoch: 6| Step: 12
Training loss: 1.6378576755523682
Validation loss: 1.9561659982127528

Epoch: 6| Step: 13
Training loss: 0.8156526684761047
Validation loss: 1.954328457514445

Epoch: 106| Step: 0
Training loss: 1.8655073642730713
Validation loss: 1.951836960290068

Epoch: 6| Step: 1
Training loss: 2.7589917182922363
Validation loss: 1.937775247840471

Epoch: 6| Step: 2
Training loss: 2.9757790565490723
Validation loss: 1.9410462200000722

Epoch: 6| Step: 3
Training loss: 2.243520736694336
Validation loss: 1.9261957265997445

Epoch: 6| Step: 4
Training loss: 2.2838940620422363
Validation loss: 1.9313062288427865

Epoch: 6| Step: 5
Training loss: 2.475616455078125
Validation loss: 1.9318514664967854

Epoch: 6| Step: 6
Training loss: 1.8224737644195557
Validation loss: 1.9567279764401015

Epoch: 6| Step: 7
Training loss: 2.0237629413604736
Validation loss: 1.9546301339262275

Epoch: 6| Step: 8
Training loss: 1.824904441833496
Validation loss: 1.9339241596960253

Epoch: 6| Step: 9
Training loss: 2.682649612426758
Validation loss: 1.9330366067988898

Epoch: 6| Step: 10
Training loss: 2.369781255722046
Validation loss: 1.935928988200362

Epoch: 6| Step: 11
Training loss: 2.305342197418213
Validation loss: 1.9375444907014088

Epoch: 6| Step: 12
Training loss: 1.773005485534668
Validation loss: 1.9408030971404044

Epoch: 6| Step: 13
Training loss: 3.0016720294952393
Validation loss: 1.9380390105708953

Epoch: 107| Step: 0
Training loss: 2.1880035400390625
Validation loss: 1.9410619466535506

Epoch: 6| Step: 1
Training loss: 2.3000686168670654
Validation loss: 1.9439251730518956

Epoch: 6| Step: 2
Training loss: 2.5915398597717285
Validation loss: 1.9461076413431475

Epoch: 6| Step: 3
Training loss: 2.082028865814209
Validation loss: 1.9496167193176925

Epoch: 6| Step: 4
Training loss: 2.41996431350708
Validation loss: 1.9558367216458885

Epoch: 6| Step: 5
Training loss: 2.539992332458496
Validation loss: 1.957745821245255

Epoch: 6| Step: 6
Training loss: 2.269881010055542
Validation loss: 1.9490632036680817

Epoch: 6| Step: 7
Training loss: 2.4170398712158203
Validation loss: 1.9547214431147422

Epoch: 6| Step: 8
Training loss: 1.776280403137207
Validation loss: 1.9604174398606824

Epoch: 6| Step: 9
Training loss: 1.7812614440917969
Validation loss: 1.9423568120566748

Epoch: 6| Step: 10
Training loss: 3.1730713844299316
Validation loss: 1.9466670943844704

Epoch: 6| Step: 11
Training loss: 2.64542293548584
Validation loss: 1.9369409686775618

Epoch: 6| Step: 12
Training loss: 1.893996238708496
Validation loss: 1.967812665047184

Epoch: 6| Step: 13
Training loss: 1.2967736721038818
Validation loss: 1.9581471143230316

Epoch: 108| Step: 0
Training loss: 2.4400148391723633
Validation loss: 1.9529568674743816

Epoch: 6| Step: 1
Training loss: 1.9632835388183594
Validation loss: 1.970297521160495

Epoch: 6| Step: 2
Training loss: 2.8035902976989746
Validation loss: 1.988316741040958

Epoch: 6| Step: 3
Training loss: 1.7611091136932373
Validation loss: 1.9956938733336747

Epoch: 6| Step: 4
Training loss: 1.6514750719070435
Validation loss: 1.9968924060944588

Epoch: 6| Step: 5
Training loss: 1.2830419540405273
Validation loss: 1.9832299806738412

Epoch: 6| Step: 6
Training loss: 2.485006093978882
Validation loss: 1.9454681437502626

Epoch: 6| Step: 7
Training loss: 2.0592119693756104
Validation loss: 1.949848892868206

Epoch: 6| Step: 8
Training loss: 2.922056198120117
Validation loss: 1.9369768378555134

Epoch: 6| Step: 9
Training loss: 2.6286497116088867
Validation loss: 1.9341115579810193

Epoch: 6| Step: 10
Training loss: 2.1961660385131836
Validation loss: 1.933214242740344

Epoch: 6| Step: 11
Training loss: 2.725799083709717
Validation loss: 1.929165312038955

Epoch: 6| Step: 12
Training loss: 2.438854217529297
Validation loss: 1.939226181276383

Epoch: 6| Step: 13
Training loss: 2.1283655166625977
Validation loss: 1.9322706281497914

Epoch: 109| Step: 0
Training loss: 2.498167037963867
Validation loss: 1.9381678463310323

Epoch: 6| Step: 1
Training loss: 2.368919610977173
Validation loss: 1.961580781526463

Epoch: 6| Step: 2
Training loss: 1.7146873474121094
Validation loss: 1.9591670754135295

Epoch: 6| Step: 3
Training loss: 2.013908863067627
Validation loss: 1.9462804320038005

Epoch: 6| Step: 4
Training loss: 1.2389779090881348
Validation loss: 1.930992013664656

Epoch: 6| Step: 5
Training loss: 2.2363121509552
Validation loss: 1.9212755874920917

Epoch: 6| Step: 6
Training loss: 2.47238826751709
Validation loss: 1.9314357285858483

Epoch: 6| Step: 7
Training loss: 2.3152167797088623
Validation loss: 1.9585708572018532

Epoch: 6| Step: 8
Training loss: 2.696324348449707
Validation loss: 1.9645251753509685

Epoch: 6| Step: 9
Training loss: 2.2536048889160156
Validation loss: 1.9699153361781951

Epoch: 6| Step: 10
Training loss: 1.84762704372406
Validation loss: 1.9562809749316143

Epoch: 6| Step: 11
Training loss: 2.888432502746582
Validation loss: 1.938700940019341

Epoch: 6| Step: 12
Training loss: 2.9207892417907715
Validation loss: 1.9173274886223577

Epoch: 6| Step: 13
Training loss: 2.0068249702453613
Validation loss: 1.9154609813485095

Epoch: 110| Step: 0
Training loss: 2.5925698280334473
Validation loss: 1.9217299748492498

Epoch: 6| Step: 1
Training loss: 2.0980963706970215
Validation loss: 1.9176666941694034

Epoch: 6| Step: 2
Training loss: 2.3160154819488525
Validation loss: 1.9272374876083866

Epoch: 6| Step: 3
Training loss: 1.7027252912521362
Validation loss: 1.9311875502268474

Epoch: 6| Step: 4
Training loss: 2.642488479614258
Validation loss: 1.92809421272688

Epoch: 6| Step: 5
Training loss: 1.984033226966858
Validation loss: 1.9226604751361314

Epoch: 6| Step: 6
Training loss: 1.291060447692871
Validation loss: 1.9840874261753534

Epoch: 6| Step: 7
Training loss: 2.601722478866577
Validation loss: 2.0023617731627597

Epoch: 6| Step: 8
Training loss: 1.4312453269958496
Validation loss: 2.0182003590368454

Epoch: 6| Step: 9
Training loss: 2.7477149963378906
Validation loss: 2.0007942543234876

Epoch: 6| Step: 10
Training loss: 3.1102583408355713
Validation loss: 1.9585851494983961

Epoch: 6| Step: 11
Training loss: 2.333153247833252
Validation loss: 1.9364038129006662

Epoch: 6| Step: 12
Training loss: 2.326871395111084
Validation loss: 1.9368600165972145

Epoch: 6| Step: 13
Training loss: 2.0905985832214355
Validation loss: 1.9700912429440407

Epoch: 111| Step: 0
Training loss: 1.3977917432785034
Validation loss: 1.9914488087418258

Epoch: 6| Step: 1
Training loss: 2.1639914512634277
Validation loss: 1.9921622776216077

Epoch: 6| Step: 2
Training loss: 1.9595904350280762
Validation loss: 1.9706292716405724

Epoch: 6| Step: 3
Training loss: 2.557990074157715
Validation loss: 1.934399406115214

Epoch: 6| Step: 4
Training loss: 2.995631456375122
Validation loss: 1.9165660488990046

Epoch: 6| Step: 5
Training loss: 2.5900988578796387
Validation loss: 1.954574813124954

Epoch: 6| Step: 6
Training loss: 2.3731131553649902
Validation loss: 2.0136955963668

Epoch: 6| Step: 7
Training loss: 2.629688024520874
Validation loss: 2.052859701136107

Epoch: 6| Step: 8
Training loss: 2.4994924068450928
Validation loss: 2.119767765845022

Epoch: 6| Step: 9
Training loss: 1.9631154537200928
Validation loss: 2.1772165913735666

Epoch: 6| Step: 10
Training loss: 2.313742160797119
Validation loss: 2.195761101220244

Epoch: 6| Step: 11
Training loss: 3.116273880004883
Validation loss: 2.158234703925348

Epoch: 6| Step: 12
Training loss: 2.1899867057800293
Validation loss: 2.096488780872796

Epoch: 6| Step: 13
Training loss: 2.0612680912017822
Validation loss: 2.0351223304707515

Epoch: 112| Step: 0
Training loss: 2.14290714263916
Validation loss: 1.998214969071009

Epoch: 6| Step: 1
Training loss: 1.892107605934143
Validation loss: 1.969490970334699

Epoch: 6| Step: 2
Training loss: 3.2808032035827637
Validation loss: 1.9515247729516798

Epoch: 6| Step: 3
Training loss: 2.036471366882324
Validation loss: 1.9579605646030878

Epoch: 6| Step: 4
Training loss: 2.1183974742889404
Validation loss: 1.9510449709430817

Epoch: 6| Step: 5
Training loss: 1.5937082767486572
Validation loss: 1.9514151593690277

Epoch: 6| Step: 6
Training loss: 3.4489693641662598
Validation loss: 1.9585059919664938

Epoch: 6| Step: 7
Training loss: 1.8471838235855103
Validation loss: 1.9678528257595596

Epoch: 6| Step: 8
Training loss: 1.8394888639450073
Validation loss: 2.003498802902878

Epoch: 6| Step: 9
Training loss: 2.6529667377471924
Validation loss: 2.056354747023634

Epoch: 6| Step: 10
Training loss: 2.2819652557373047
Validation loss: 2.09518349811595

Epoch: 6| Step: 11
Training loss: 2.024289608001709
Validation loss: 2.116819735496275

Epoch: 6| Step: 12
Training loss: 2.254978656768799
Validation loss: 2.139087523183515

Epoch: 6| Step: 13
Training loss: 2.521439552307129
Validation loss: 2.1110652633892593

Epoch: 113| Step: 0
Training loss: 2.2103233337402344
Validation loss: 2.0731508552387194

Epoch: 6| Step: 1
Training loss: 2.365299701690674
Validation loss: 2.042306984624555

Epoch: 6| Step: 2
Training loss: 2.221442222595215
Validation loss: 1.9921653680903937

Epoch: 6| Step: 3
Training loss: 2.147594928741455
Validation loss: 2.005243771819658

Epoch: 6| Step: 4
Training loss: 1.999389886856079
Validation loss: 2.001442002993758

Epoch: 6| Step: 5
Training loss: 2.5626683235168457
Validation loss: 2.012344323178773

Epoch: 6| Step: 6
Training loss: 2.10125994682312
Validation loss: 1.994302813724805

Epoch: 6| Step: 7
Training loss: 2.0096583366394043
Validation loss: 1.997206280308385

Epoch: 6| Step: 8
Training loss: 2.302785873413086
Validation loss: 1.993121054864699

Epoch: 6| Step: 9
Training loss: 1.4731616973876953
Validation loss: 1.9761052259834864

Epoch: 6| Step: 10
Training loss: 2.181321144104004
Validation loss: 1.9645822637824601

Epoch: 6| Step: 11
Training loss: 2.9869446754455566
Validation loss: 1.977418291953302

Epoch: 6| Step: 12
Training loss: 1.8708020448684692
Validation loss: 1.986856980990338

Epoch: 6| Step: 13
Training loss: 3.0735790729522705
Validation loss: 1.98303549392249

Epoch: 114| Step: 0
Training loss: 2.2055656909942627
Validation loss: 1.9999907888391966

Epoch: 6| Step: 1
Training loss: 2.085808038711548
Validation loss: 1.999372427181531

Epoch: 6| Step: 2
Training loss: 2.3540825843811035
Validation loss: 1.991505297281409

Epoch: 6| Step: 3
Training loss: 2.7528305053710938
Validation loss: 1.9640204714190574

Epoch: 6| Step: 4
Training loss: 2.4142980575561523
Validation loss: 1.9682114931844896

Epoch: 6| Step: 5
Training loss: 1.5325980186462402
Validation loss: 1.9618470579065301

Epoch: 6| Step: 6
Training loss: 2.6354258060455322
Validation loss: 1.9580947429903093

Epoch: 6| Step: 7
Training loss: 1.7762892246246338
Validation loss: 1.945118809259066

Epoch: 6| Step: 8
Training loss: 2.342367649078369
Validation loss: 1.9711832795091855

Epoch: 6| Step: 9
Training loss: 2.248988628387451
Validation loss: 1.959104158545053

Epoch: 6| Step: 10
Training loss: 2.6488537788391113
Validation loss: 1.9640919623836395

Epoch: 6| Step: 11
Training loss: 2.392253875732422
Validation loss: 1.990578314309479

Epoch: 6| Step: 12
Training loss: 1.7014048099517822
Validation loss: 1.9747017942449099

Epoch: 6| Step: 13
Training loss: 1.701689600944519
Validation loss: 1.9658210931285736

Epoch: 115| Step: 0
Training loss: 2.6234519481658936
Validation loss: 1.9698165283408215

Epoch: 6| Step: 1
Training loss: 2.314579963684082
Validation loss: 1.9709954492507442

Epoch: 6| Step: 2
Training loss: 1.8508694171905518
Validation loss: 1.9591893919052616

Epoch: 6| Step: 3
Training loss: 2.158968448638916
Validation loss: 1.9583883721341369

Epoch: 6| Step: 4
Training loss: 1.7200747728347778
Validation loss: 1.9523594481970674

Epoch: 6| Step: 5
Training loss: 1.6996803283691406
Validation loss: 1.954565107181508

Epoch: 6| Step: 6
Training loss: 1.8951213359832764
Validation loss: 1.9568222517608314

Epoch: 6| Step: 7
Training loss: 2.5267324447631836
Validation loss: 1.9738558723080544

Epoch: 6| Step: 8
Training loss: 2.2706007957458496
Validation loss: 1.9684101240609282

Epoch: 6| Step: 9
Training loss: 2.1753835678100586
Validation loss: 1.9335678264658938

Epoch: 6| Step: 10
Training loss: 2.8968234062194824
Validation loss: 1.941390904047156

Epoch: 6| Step: 11
Training loss: 2.4126029014587402
Validation loss: 1.9386800296844975

Epoch: 6| Step: 12
Training loss: 2.056734561920166
Validation loss: 1.932187500820365

Epoch: 6| Step: 13
Training loss: 2.025094985961914
Validation loss: 1.9218311925088205

Epoch: 116| Step: 0
Training loss: 2.1314330101013184
Validation loss: 1.9189673418639808

Epoch: 6| Step: 1
Training loss: 2.1958017349243164
Validation loss: 1.9253079378476707

Epoch: 6| Step: 2
Training loss: 2.684011697769165
Validation loss: 1.9325694473840858

Epoch: 6| Step: 3
Training loss: 2.228799819946289
Validation loss: 1.9459335803985596

Epoch: 6| Step: 4
Training loss: 2.2113747596740723
Validation loss: 1.9606085567064182

Epoch: 6| Step: 5
Training loss: 1.889883279800415
Validation loss: 1.9860237119018391

Epoch: 6| Step: 6
Training loss: 1.9839658737182617
Validation loss: 1.9879470909795454

Epoch: 6| Step: 7
Training loss: 2.190660238265991
Validation loss: 1.992379144955707

Epoch: 6| Step: 8
Training loss: 2.651336908340454
Validation loss: 1.9854338476734776

Epoch: 6| Step: 9
Training loss: 2.0790834426879883
Validation loss: 1.9954497403995965

Epoch: 6| Step: 10
Training loss: 2.061736822128296
Validation loss: 1.9834215461566884

Epoch: 6| Step: 11
Training loss: 2.230447292327881
Validation loss: 1.9849345235414402

Epoch: 6| Step: 12
Training loss: 2.1643550395965576
Validation loss: 2.014136391301309

Epoch: 6| Step: 13
Training loss: 1.841902256011963
Validation loss: 1.9888246520873039

Epoch: 117| Step: 0
Training loss: 2.6799068450927734
Validation loss: 1.9951812862068095

Epoch: 6| Step: 1
Training loss: 2.380394458770752
Validation loss: 2.0028671564594394

Epoch: 6| Step: 2
Training loss: 2.8790435791015625
Validation loss: 1.963891319049302

Epoch: 6| Step: 3
Training loss: 1.8109803199768066
Validation loss: 1.9326900307850172

Epoch: 6| Step: 4
Training loss: 1.6001290082931519
Validation loss: 1.9355892314705798

Epoch: 6| Step: 5
Training loss: 1.9625372886657715
Validation loss: 1.9170898891264392

Epoch: 6| Step: 6
Training loss: 3.077867269515991
Validation loss: 1.9230211729644446

Epoch: 6| Step: 7
Training loss: 1.9284019470214844
Validation loss: 1.9147518911669332

Epoch: 6| Step: 8
Training loss: 1.7158141136169434
Validation loss: 1.9199677154582033

Epoch: 6| Step: 9
Training loss: 2.364912986755371
Validation loss: 1.9179709226854387

Epoch: 6| Step: 10
Training loss: 1.4373881816864014
Validation loss: 1.9465805074220062

Epoch: 6| Step: 11
Training loss: 2.276951551437378
Validation loss: 1.9860483523338073

Epoch: 6| Step: 12
Training loss: 2.434384346008301
Validation loss: 2.0302087824831725

Epoch: 6| Step: 13
Training loss: 2.0574519634246826
Validation loss: 2.0658955548399236

Epoch: 118| Step: 0
Training loss: 2.0471251010894775
Validation loss: 2.054509664094576

Epoch: 6| Step: 1
Training loss: 2.3342251777648926
Validation loss: 2.054335231422096

Epoch: 6| Step: 2
Training loss: 2.986448287963867
Validation loss: 2.041981363809237

Epoch: 6| Step: 3
Training loss: 1.916722297668457
Validation loss: 2.0291638335874005

Epoch: 6| Step: 4
Training loss: 2.7109718322753906
Validation loss: 2.0092714960857103

Epoch: 6| Step: 5
Training loss: 1.990000605583191
Validation loss: 1.9962754377754786

Epoch: 6| Step: 6
Training loss: 1.7638270854949951
Validation loss: 1.9827736654589254

Epoch: 6| Step: 7
Training loss: 2.1010992527008057
Validation loss: 1.956275386195029

Epoch: 6| Step: 8
Training loss: 1.517866849899292
Validation loss: 1.9434930573227585

Epoch: 6| Step: 9
Training loss: 2.546642780303955
Validation loss: 1.954003377627301

Epoch: 6| Step: 10
Training loss: 2.3214802742004395
Validation loss: 1.9488555257038405

Epoch: 6| Step: 11
Training loss: 2.4716920852661133
Validation loss: 1.9431501665422994

Epoch: 6| Step: 12
Training loss: 2.586791515350342
Validation loss: 1.9383482510043728

Epoch: 6| Step: 13
Training loss: 1.210784912109375
Validation loss: 1.944056599370895

Epoch: 119| Step: 0
Training loss: 2.3966245651245117
Validation loss: 1.928879427653487

Epoch: 6| Step: 1
Training loss: 1.4529752731323242
Validation loss: 1.931587637111705

Epoch: 6| Step: 2
Training loss: 2.4420320987701416
Validation loss: 1.951163952068616

Epoch: 6| Step: 3
Training loss: 2.1499009132385254
Validation loss: 1.9665831699166247

Epoch: 6| Step: 4
Training loss: 1.8670940399169922
Validation loss: 1.9525119566148328

Epoch: 6| Step: 5
Training loss: 2.084995746612549
Validation loss: 1.9612366230257097

Epoch: 6| Step: 6
Training loss: 2.381563186645508
Validation loss: 1.9444314536227976

Epoch: 6| Step: 7
Training loss: 2.899324893951416
Validation loss: 1.9275522026964413

Epoch: 6| Step: 8
Training loss: 2.012441635131836
Validation loss: 1.9276599819942186

Epoch: 6| Step: 9
Training loss: 2.288349151611328
Validation loss: 1.9303289510870492

Epoch: 6| Step: 10
Training loss: 2.591890335083008
Validation loss: 1.9264731894257248

Epoch: 6| Step: 11
Training loss: 2.3956429958343506
Validation loss: 1.933946709479055

Epoch: 6| Step: 12
Training loss: 1.9298169612884521
Validation loss: 1.9350400663191272

Epoch: 6| Step: 13
Training loss: 1.530930995941162
Validation loss: 1.9419225005693332

Epoch: 120| Step: 0
Training loss: 2.294952392578125
Validation loss: 1.9489283459160918

Epoch: 6| Step: 1
Training loss: 2.3179354667663574
Validation loss: 1.9575426347794072

Epoch: 6| Step: 2
Training loss: 2.254467248916626
Validation loss: 2.006072712200944

Epoch: 6| Step: 3
Training loss: 1.8977831602096558
Validation loss: 2.054008545414094

Epoch: 6| Step: 4
Training loss: 2.4753336906433105
Validation loss: 2.0846363190681703

Epoch: 6| Step: 5
Training loss: 1.6867693662643433
Validation loss: 2.0902988410765126

Epoch: 6| Step: 6
Training loss: 2.690354347229004
Validation loss: 2.0701090776792137

Epoch: 6| Step: 7
Training loss: 1.740096926689148
Validation loss: 2.046680465821297

Epoch: 6| Step: 8
Training loss: 2.009589433670044
Validation loss: 2.0352137114412043

Epoch: 6| Step: 9
Training loss: 2.5717458724975586
Validation loss: 2.049008248954691

Epoch: 6| Step: 10
Training loss: 2.2741706371307373
Validation loss: 2.0534216896180184

Epoch: 6| Step: 11
Training loss: 1.9426798820495605
Validation loss: 2.0455271351721978

Epoch: 6| Step: 12
Training loss: 2.6872081756591797
Validation loss: 2.0282052588719193

Epoch: 6| Step: 13
Training loss: 1.9449397325515747
Validation loss: 2.0030273481081893

Epoch: 121| Step: 0
Training loss: 2.3562731742858887
Validation loss: 2.012143135070801

Epoch: 6| Step: 1
Training loss: 2.5646262168884277
Validation loss: 1.98902125640582

Epoch: 6| Step: 2
Training loss: 1.3138138055801392
Validation loss: 1.9883149798198412

Epoch: 6| Step: 3
Training loss: 2.558605194091797
Validation loss: 1.9930219381086287

Epoch: 6| Step: 4
Training loss: 2.032280445098877
Validation loss: 1.988819517115111

Epoch: 6| Step: 5
Training loss: 1.8511877059936523
Validation loss: 1.9964311609986007

Epoch: 6| Step: 6
Training loss: 2.3731961250305176
Validation loss: 2.006762808369052

Epoch: 6| Step: 7
Training loss: 2.2938344478607178
Validation loss: 1.9788940721942532

Epoch: 6| Step: 8
Training loss: 1.973717212677002
Validation loss: 1.9575157780801096

Epoch: 6| Step: 9
Training loss: 2.983501434326172
Validation loss: 1.9476425814372238

Epoch: 6| Step: 10
Training loss: 1.7797640562057495
Validation loss: 1.9346294864531486

Epoch: 6| Step: 11
Training loss: 1.5662580728530884
Validation loss: 1.9469340475656653

Epoch: 6| Step: 12
Training loss: 2.382673501968384
Validation loss: 1.9432821735259025

Epoch: 6| Step: 13
Training loss: 2.2061879634857178
Validation loss: 1.9392097368035266

Epoch: 122| Step: 0
Training loss: 2.392641544342041
Validation loss: 1.9371047865959905

Epoch: 6| Step: 1
Training loss: 1.9617700576782227
Validation loss: 1.924963205091415

Epoch: 6| Step: 2
Training loss: 1.9844961166381836
Validation loss: 1.935282373941073

Epoch: 6| Step: 3
Training loss: 2.7643418312072754
Validation loss: 1.9699474906408658

Epoch: 6| Step: 4
Training loss: 2.35186767578125
Validation loss: 1.9846482482007755

Epoch: 6| Step: 5
Training loss: 2.1916184425354004
Validation loss: 1.9992787748254754

Epoch: 6| Step: 6
Training loss: 1.9182747602462769
Validation loss: 2.009474797915387

Epoch: 6| Step: 7
Training loss: 2.51305890083313
Validation loss: 2.0417049572031987

Epoch: 6| Step: 8
Training loss: 1.4329017400741577
Validation loss: 2.029864513745872

Epoch: 6| Step: 9
Training loss: 2.61016583442688
Validation loss: 2.022386150975381

Epoch: 6| Step: 10
Training loss: 1.9221783876419067
Validation loss: 1.990147977746943

Epoch: 6| Step: 11
Training loss: 2.80661940574646
Validation loss: 1.964632543825334

Epoch: 6| Step: 12
Training loss: 1.5295188426971436
Validation loss: 1.9543664173413349

Epoch: 6| Step: 13
Training loss: 1.369470238685608
Validation loss: 1.9521846425148748

Epoch: 123| Step: 0
Training loss: 2.2847437858581543
Validation loss: 1.9265302086389193

Epoch: 6| Step: 1
Training loss: 2.2275209426879883
Validation loss: 1.914724701194353

Epoch: 6| Step: 2
Training loss: 1.5044467449188232
Validation loss: 1.9308985766544138

Epoch: 6| Step: 3
Training loss: 1.6589562892913818
Validation loss: 1.9227390122669998

Epoch: 6| Step: 4
Training loss: 2.0300111770629883
Validation loss: 1.931558960227556

Epoch: 6| Step: 5
Training loss: 2.3099019527435303
Validation loss: 1.93694915053665

Epoch: 6| Step: 6
Training loss: 2.107905626296997
Validation loss: 1.9345528323163268

Epoch: 6| Step: 7
Training loss: 2.305360794067383
Validation loss: 1.9357577459786528

Epoch: 6| Step: 8
Training loss: 2.116086006164551
Validation loss: 1.9302425140975623

Epoch: 6| Step: 9
Training loss: 2.4779248237609863
Validation loss: 1.9360057384737077

Epoch: 6| Step: 10
Training loss: 1.748769760131836
Validation loss: 1.940134871390558

Epoch: 6| Step: 11
Training loss: 2.4816155433654785
Validation loss: 1.9117208501344085

Epoch: 6| Step: 12
Training loss: 1.9308953285217285
Validation loss: 1.928411106909475

Epoch: 6| Step: 13
Training loss: 3.036569356918335
Validation loss: 1.93071436753837

Epoch: 124| Step: 0
Training loss: 1.9231014251708984
Validation loss: 1.9262870127154934

Epoch: 6| Step: 1
Training loss: 2.5233209133148193
Validation loss: 1.9339929537106586

Epoch: 6| Step: 2
Training loss: 2.550137996673584
Validation loss: 1.958526304973069

Epoch: 6| Step: 3
Training loss: 2.6491007804870605
Validation loss: 1.966671032290305

Epoch: 6| Step: 4
Training loss: 2.0066089630126953
Validation loss: 1.9664814062015985

Epoch: 6| Step: 5
Training loss: 2.5541601181030273
Validation loss: 1.9852583869811027

Epoch: 6| Step: 6
Training loss: 1.4863040447235107
Validation loss: 1.9847356798828288

Epoch: 6| Step: 7
Training loss: 1.6785805225372314
Validation loss: 1.9871362306738412

Epoch: 6| Step: 8
Training loss: 1.3571979999542236
Validation loss: 2.002929563163429

Epoch: 6| Step: 9
Training loss: 1.8938932418823242
Validation loss: 2.0353167762038527

Epoch: 6| Step: 10
Training loss: 2.2930006980895996
Validation loss: 2.0423868689485776

Epoch: 6| Step: 11
Training loss: 2.077164649963379
Validation loss: 2.0909940927259383

Epoch: 6| Step: 12
Training loss: 2.499070167541504
Validation loss: 2.032485000548824

Epoch: 6| Step: 13
Training loss: 2.2173407077789307
Validation loss: 2.0151357881484495

Epoch: 125| Step: 0
Training loss: 2.768252372741699
Validation loss: 1.9961499719209568

Epoch: 6| Step: 1
Training loss: 1.4470409154891968
Validation loss: 1.955266511568459

Epoch: 6| Step: 2
Training loss: 1.8552062511444092
Validation loss: 1.9625813486755534

Epoch: 6| Step: 3
Training loss: 2.4737930297851562
Validation loss: 1.9542292459036714

Epoch: 6| Step: 4
Training loss: 2.293951988220215
Validation loss: 1.9468483219864547

Epoch: 6| Step: 5
Training loss: 1.5752840042114258
Validation loss: 1.967933463793929

Epoch: 6| Step: 6
Training loss: 2.7229573726654053
Validation loss: 1.99165972586601

Epoch: 6| Step: 7
Training loss: 2.145535945892334
Validation loss: 1.9677435403229089

Epoch: 6| Step: 8
Training loss: 2.29374623298645
Validation loss: 1.9658886437774987

Epoch: 6| Step: 9
Training loss: 2.0204176902770996
Validation loss: 1.9596609787274433

Epoch: 6| Step: 10
Training loss: 1.885818600654602
Validation loss: 1.9817276000976562

Epoch: 6| Step: 11
Training loss: 2.539980173110962
Validation loss: 2.0361651387265933

Epoch: 6| Step: 12
Training loss: 1.8397451639175415
Validation loss: 2.084285610465593

Epoch: 6| Step: 13
Training loss: 2.2588651180267334
Validation loss: 2.111694610247048

Epoch: 126| Step: 0
Training loss: 2.492032766342163
Validation loss: 2.0864213051334506

Epoch: 6| Step: 1
Training loss: 2.2966127395629883
Validation loss: 2.0448976691051195

Epoch: 6| Step: 2
Training loss: 2.4258344173431396
Validation loss: 1.9915018030392226

Epoch: 6| Step: 3
Training loss: 2.2398035526275635
Validation loss: 1.9576329428662536

Epoch: 6| Step: 4
Training loss: 1.5722626447677612
Validation loss: 1.973333489510321

Epoch: 6| Step: 5
Training loss: 2.229220390319824
Validation loss: 1.9541291293277536

Epoch: 6| Step: 6
Training loss: 2.019989252090454
Validation loss: 1.981522455010363

Epoch: 6| Step: 7
Training loss: 2.598695993423462
Validation loss: 1.9971385335409513

Epoch: 6| Step: 8
Training loss: 1.5966402292251587
Validation loss: 1.968790062012211

Epoch: 6| Step: 9
Training loss: 2.1870334148406982
Validation loss: 1.966323229574388

Epoch: 6| Step: 10
Training loss: 1.9718246459960938
Validation loss: 1.9481524088049447

Epoch: 6| Step: 11
Training loss: 3.009997844696045
Validation loss: 1.9436799300614225

Epoch: 6| Step: 12
Training loss: 1.8668782711029053
Validation loss: 1.9504826812333957

Epoch: 6| Step: 13
Training loss: 2.1744449138641357
Validation loss: 1.9372619736579157

Epoch: 127| Step: 0
Training loss: 1.8010517358779907
Validation loss: 1.9504711269050516

Epoch: 6| Step: 1
Training loss: 1.6974960565567017
Validation loss: 1.9898939953055432

Epoch: 6| Step: 2
Training loss: 2.0864481925964355
Validation loss: 2.0838985520024456

Epoch: 6| Step: 3
Training loss: 3.4714720249176025
Validation loss: 2.1544446329916678

Epoch: 6| Step: 4
Training loss: 1.9151341915130615
Validation loss: 2.167753625941533

Epoch: 6| Step: 5
Training loss: 2.452631950378418
Validation loss: 2.153422155687886

Epoch: 6| Step: 6
Training loss: 2.695164203643799
Validation loss: 2.1107215919802265

Epoch: 6| Step: 7
Training loss: 1.1563985347747803
Validation loss: 2.0300893527205273

Epoch: 6| Step: 8
Training loss: 2.3332552909851074
Validation loss: 1.9809680702865764

Epoch: 6| Step: 9
Training loss: 2.6242802143096924
Validation loss: 1.988556056894282

Epoch: 6| Step: 10
Training loss: 2.7563631534576416
Validation loss: 2.0224315145964264

Epoch: 6| Step: 11
Training loss: 1.195858120918274
Validation loss: 2.060511278849776

Epoch: 6| Step: 12
Training loss: 1.9818994998931885
Validation loss: 2.0830642548940514

Epoch: 6| Step: 13
Training loss: 2.250971794128418
Validation loss: 2.079691174209759

Epoch: 128| Step: 0
Training loss: 1.9112067222595215
Validation loss: 1.9980051594395791

Epoch: 6| Step: 1
Training loss: 2.3925769329071045
Validation loss: 1.9761089970988612

Epoch: 6| Step: 2
Training loss: 2.1830363273620605
Validation loss: 1.9680191265639437

Epoch: 6| Step: 3
Training loss: 2.3383851051330566
Validation loss: 1.9644966945853284

Epoch: 6| Step: 4
Training loss: 1.629446268081665
Validation loss: 2.0092290703968336

Epoch: 6| Step: 5
Training loss: 1.4410200119018555
Validation loss: 2.004957224733086

Epoch: 6| Step: 6
Training loss: 2.6655282974243164
Validation loss: 2.0122302706523607

Epoch: 6| Step: 7
Training loss: 2.174234390258789
Validation loss: 2.016382204589023

Epoch: 6| Step: 8
Training loss: 2.2023990154266357
Validation loss: 2.0310872677833802

Epoch: 6| Step: 9
Training loss: 2.609515428543091
Validation loss: 2.025920642319546

Epoch: 6| Step: 10
Training loss: 1.9287043809890747
Validation loss: 2.018793655980018

Epoch: 6| Step: 11
Training loss: 2.202068328857422
Validation loss: 2.007137736966533

Epoch: 6| Step: 12
Training loss: 1.8074731826782227
Validation loss: 1.9988710085550945

Epoch: 6| Step: 13
Training loss: 1.2485041618347168
Validation loss: 1.9654450121746267

Epoch: 129| Step: 0
Training loss: 2.2847442626953125
Validation loss: 1.9535569708834413

Epoch: 6| Step: 1
Training loss: 2.3123607635498047
Validation loss: 1.9488019302327146

Epoch: 6| Step: 2
Training loss: 2.1630239486694336
Validation loss: 1.9591223116843932

Epoch: 6| Step: 3
Training loss: 1.7263164520263672
Validation loss: 1.9547713084887433

Epoch: 6| Step: 4
Training loss: 3.241305351257324
Validation loss: 1.9547987035525742

Epoch: 6| Step: 5
Training loss: 1.8984153270721436
Validation loss: 1.971325671801003

Epoch: 6| Step: 6
Training loss: 1.5743026733398438
Validation loss: 1.943198311713434

Epoch: 6| Step: 7
Training loss: 1.140228033065796
Validation loss: 1.9393288743111394

Epoch: 6| Step: 8
Training loss: 1.5493781566619873
Validation loss: 1.9419049678310272

Epoch: 6| Step: 9
Training loss: 2.0847561359405518
Validation loss: 1.9319334722334338

Epoch: 6| Step: 10
Training loss: 2.3569750785827637
Validation loss: 1.9432404156654113

Epoch: 6| Step: 11
Training loss: 2.1145668029785156
Validation loss: 1.9381602682093138

Epoch: 6| Step: 12
Training loss: 2.2064857482910156
Validation loss: 1.9582542424560876

Epoch: 6| Step: 13
Training loss: 1.9480586051940918
Validation loss: 1.9980033136183215

Epoch: 130| Step: 0
Training loss: 2.5555641651153564
Validation loss: 2.0595536257631037

Epoch: 6| Step: 1
Training loss: 2.130999803543091
Validation loss: 2.0919470453775055

Epoch: 6| Step: 2
Training loss: 2.2348825931549072
Validation loss: 2.0920192503160044

Epoch: 6| Step: 3
Training loss: 2.651132106781006
Validation loss: 2.120030762046896

Epoch: 6| Step: 4
Training loss: 2.047508955001831
Validation loss: 2.121028341272826

Epoch: 6| Step: 5
Training loss: 1.6951544284820557
Validation loss: 2.1119137220485236

Epoch: 6| Step: 6
Training loss: 2.111269950866699
Validation loss: 2.0785012937361196

Epoch: 6| Step: 7
Training loss: 2.130725383758545
Validation loss: 2.0377867747378606

Epoch: 6| Step: 8
Training loss: 1.790074110031128
Validation loss: 2.021442654312298

Epoch: 6| Step: 9
Training loss: 2.079193353652954
Validation loss: 2.0515129604647235

Epoch: 6| Step: 10
Training loss: 1.702094554901123
Validation loss: 2.075457860064763

Epoch: 6| Step: 11
Training loss: 1.618039608001709
Validation loss: 2.052223579857939

Epoch: 6| Step: 12
Training loss: 2.223975658416748
Validation loss: 2.0258573114231067

Epoch: 6| Step: 13
Training loss: 1.8793959617614746
Validation loss: 2.025961591351417

Epoch: 131| Step: 0
Training loss: 2.7372841835021973
Validation loss: 2.036955725762152

Epoch: 6| Step: 1
Training loss: 2.0806145668029785
Validation loss: 2.056597395609784

Epoch: 6| Step: 2
Training loss: 1.800984263420105
Validation loss: 2.0559792300706268

Epoch: 6| Step: 3
Training loss: 2.2957005500793457
Validation loss: 2.0602460830442366

Epoch: 6| Step: 4
Training loss: 2.14111065864563
Validation loss: 2.0633710738151305

Epoch: 6| Step: 5
Training loss: 1.500511646270752
Validation loss: 2.055223850793736

Epoch: 6| Step: 6
Training loss: 1.888754963874817
Validation loss: 2.0278609234799623

Epoch: 6| Step: 7
Training loss: 2.5279884338378906
Validation loss: 2.020196887754625

Epoch: 6| Step: 8
Training loss: 1.7791459560394287
Validation loss: 2.0216782298139346

Epoch: 6| Step: 9
Training loss: 1.2202565670013428
Validation loss: 2.0372884440165695

Epoch: 6| Step: 10
Training loss: 1.7932072877883911
Validation loss: 2.0486534936453706

Epoch: 6| Step: 11
Training loss: 2.400649070739746
Validation loss: 2.044879044255903

Epoch: 6| Step: 12
Training loss: 1.9723963737487793
Validation loss: 2.019430165649742

Epoch: 6| Step: 13
Training loss: 2.7395122051239014
Validation loss: 2.016782163291849

Epoch: 132| Step: 0
Training loss: 2.7181410789489746
Validation loss: 2.063618044699392

Epoch: 6| Step: 1
Training loss: 2.184112548828125
Validation loss: 2.045835412958617

Epoch: 6| Step: 2
Training loss: 1.2512742280960083
Validation loss: 2.0033987696452806

Epoch: 6| Step: 3
Training loss: 2.5834531784057617
Validation loss: 1.9857489075711978

Epoch: 6| Step: 4
Training loss: 1.7551103830337524
Validation loss: 1.9833827672466156

Epoch: 6| Step: 5
Training loss: 2.4088573455810547
Validation loss: 1.9915973563348093

Epoch: 6| Step: 6
Training loss: 1.8700205087661743
Validation loss: 2.006502412980603

Epoch: 6| Step: 7
Training loss: 1.841872215270996
Validation loss: 2.0183916181646366

Epoch: 6| Step: 8
Training loss: 2.13204288482666
Validation loss: 1.9965275538864957

Epoch: 6| Step: 9
Training loss: 1.486203670501709
Validation loss: 1.984129382717994

Epoch: 6| Step: 10
Training loss: 2.781179904937744
Validation loss: 1.9894369007438741

Epoch: 6| Step: 11
Training loss: 1.546066403388977
Validation loss: 1.9969183091194398

Epoch: 6| Step: 12
Training loss: 1.849958896636963
Validation loss: 2.021956862941865

Epoch: 6| Step: 13
Training loss: 1.575632095336914
Validation loss: 2.038022756576538

Epoch: 133| Step: 0
Training loss: 2.5970544815063477
Validation loss: 2.070105146336299

Epoch: 6| Step: 1
Training loss: 1.7237660884857178
Validation loss: 2.1057717736049364

Epoch: 6| Step: 2
Training loss: 2.2850160598754883
Validation loss: 2.1015799840291343

Epoch: 6| Step: 3
Training loss: 2.1433560848236084
Validation loss: 2.0810555488832536

Epoch: 6| Step: 4
Training loss: 2.6695470809936523
Validation loss: 2.065891642724314

Epoch: 6| Step: 5
Training loss: 0.9270910024642944
Validation loss: 2.0583839390867498

Epoch: 6| Step: 6
Training loss: 2.2552688121795654
Validation loss: 2.0956091368070213

Epoch: 6| Step: 7
Training loss: 2.0480170249938965
Validation loss: 2.087098385698052

Epoch: 6| Step: 8
Training loss: 1.2167539596557617
Validation loss: 2.090339954181384

Epoch: 6| Step: 9
Training loss: 1.915626883506775
Validation loss: 2.0551253544386996

Epoch: 6| Step: 10
Training loss: 2.2575290203094482
Validation loss: 2.0512430847332044

Epoch: 6| Step: 11
Training loss: 2.08109188079834
Validation loss: 2.015267837432123

Epoch: 6| Step: 12
Training loss: 2.5984020233154297
Validation loss: 1.9926231420168312

Epoch: 6| Step: 13
Training loss: 2.0031044483184814
Validation loss: 1.9770172795941752

Epoch: 134| Step: 0
Training loss: 2.4082412719726562
Validation loss: 1.9598289894801315

Epoch: 6| Step: 1
Training loss: 1.4427491426467896
Validation loss: 1.9621778726577759

Epoch: 6| Step: 2
Training loss: 1.873600721359253
Validation loss: 2.0076161930637975

Epoch: 6| Step: 3
Training loss: 1.4041128158569336
Validation loss: 2.032659505003242

Epoch: 6| Step: 4
Training loss: 1.438581109046936
Validation loss: 2.0386272322747017

Epoch: 6| Step: 5
Training loss: 1.9653794765472412
Validation loss: 2.0644385468575264

Epoch: 6| Step: 6
Training loss: 1.9059035778045654
Validation loss: 2.0551041736397693

Epoch: 6| Step: 7
Training loss: 2.5179624557495117
Validation loss: 2.0223897451995523

Epoch: 6| Step: 8
Training loss: 2.390725612640381
Validation loss: 2.0069154552234116

Epoch: 6| Step: 9
Training loss: 2.8366055488586426
Validation loss: 2.0144437871953493

Epoch: 6| Step: 10
Training loss: 2.135183334350586
Validation loss: 2.037454879412087

Epoch: 6| Step: 11
Training loss: 2.1937716007232666
Validation loss: 2.036616083114378

Epoch: 6| Step: 12
Training loss: 1.9121432304382324
Validation loss: 2.005507310231527

Epoch: 6| Step: 13
Training loss: 1.4867991209030151
Validation loss: 2.0042926585802467

Epoch: 135| Step: 0
Training loss: 1.3034663200378418
Validation loss: 1.9711947902556388

Epoch: 6| Step: 1
Training loss: 2.0097336769104004
Validation loss: 1.9508399476287186

Epoch: 6| Step: 2
Training loss: 1.8057225942611694
Validation loss: 1.937083254578293

Epoch: 6| Step: 3
Training loss: 2.1316988468170166
Validation loss: 1.953893635862617

Epoch: 6| Step: 4
Training loss: 2.045499324798584
Validation loss: 1.9616620745710147

Epoch: 6| Step: 5
Training loss: 1.9401099681854248
Validation loss: 1.9804507045335666

Epoch: 6| Step: 6
Training loss: 2.3245739936828613
Validation loss: 1.9837212152378534

Epoch: 6| Step: 7
Training loss: 1.4829604625701904
Validation loss: 1.9999605686433855

Epoch: 6| Step: 8
Training loss: 2.008225679397583
Validation loss: 2.037317672083455

Epoch: 6| Step: 9
Training loss: 1.712405800819397
Validation loss: 2.0962787930683424

Epoch: 6| Step: 10
Training loss: 2.649876117706299
Validation loss: 2.124989042999924

Epoch: 6| Step: 11
Training loss: 2.617859363555908
Validation loss: 2.1634911555115894

Epoch: 6| Step: 12
Training loss: 1.5724618434906006
Validation loss: 2.1542472672718826

Epoch: 6| Step: 13
Training loss: 2.0230424404144287
Validation loss: 2.1307297291294223

Epoch: 136| Step: 0
Training loss: 1.4879505634307861
Validation loss: 2.0817196920353878

Epoch: 6| Step: 1
Training loss: 1.8716671466827393
Validation loss: 2.0434653515456827

Epoch: 6| Step: 2
Training loss: 1.8599417209625244
Validation loss: 2.0248692984222085

Epoch: 6| Step: 3
Training loss: 2.223414421081543
Validation loss: 2.0124189674213366

Epoch: 6| Step: 4
Training loss: 2.0962634086608887
Validation loss: 1.9929641869760328

Epoch: 6| Step: 5
Training loss: 2.9053454399108887
Validation loss: 2.0023238761450655

Epoch: 6| Step: 6
Training loss: 2.5543410778045654
Validation loss: 1.9744534800129552

Epoch: 6| Step: 7
Training loss: 1.2991292476654053
Validation loss: 1.9668934755427863

Epoch: 6| Step: 8
Training loss: 2.673309803009033
Validation loss: 1.9628359040906351

Epoch: 6| Step: 9
Training loss: 1.1849333047866821
Validation loss: 1.9430397543855893

Epoch: 6| Step: 10
Training loss: 2.1261682510375977
Validation loss: 1.9346889167703607

Epoch: 6| Step: 11
Training loss: 1.7491376399993896
Validation loss: 1.9250640458958124

Epoch: 6| Step: 12
Training loss: 2.119457960128784
Validation loss: 1.9392437524692987

Epoch: 6| Step: 13
Training loss: 1.0276027917861938
Validation loss: 1.9581660775728122

Epoch: 137| Step: 0
Training loss: 2.234987497329712
Validation loss: 1.968956321798345

Epoch: 6| Step: 1
Training loss: 1.5304906368255615
Validation loss: 1.963196922374028

Epoch: 6| Step: 2
Training loss: 2.2672598361968994
Validation loss: 1.999971079569991

Epoch: 6| Step: 3
Training loss: 1.812870979309082
Validation loss: 2.013924161593119

Epoch: 6| Step: 4
Training loss: 1.596394419670105
Validation loss: 2.0363813228504632

Epoch: 6| Step: 5
Training loss: 2.419279098510742
Validation loss: 2.065308763134864

Epoch: 6| Step: 6
Training loss: 2.4966704845428467
Validation loss: 2.0767265801788657

Epoch: 6| Step: 7
Training loss: 2.049755096435547
Validation loss: 2.034337615454069

Epoch: 6| Step: 8
Training loss: 1.2976500988006592
Validation loss: 2.0101782045056744

Epoch: 6| Step: 9
Training loss: 2.1348729133605957
Validation loss: 1.9684440807629657

Epoch: 6| Step: 10
Training loss: 2.465409278869629
Validation loss: 1.9514659630355013

Epoch: 6| Step: 11
Training loss: 1.8854079246520996
Validation loss: 1.9502863089243572

Epoch: 6| Step: 12
Training loss: 1.0655021667480469
Validation loss: 1.928447740052336

Epoch: 6| Step: 13
Training loss: 2.938594341278076
Validation loss: 1.939507640818114

Epoch: 138| Step: 0
Training loss: 2.1664810180664062
Validation loss: 1.9559441881795083

Epoch: 6| Step: 1
Training loss: 2.038729667663574
Validation loss: 1.9636258643160585

Epoch: 6| Step: 2
Training loss: 1.8195178508758545
Validation loss: 1.9947758413130237

Epoch: 6| Step: 3
Training loss: 2.0479893684387207
Validation loss: 2.0252187559681554

Epoch: 6| Step: 4
Training loss: 2.188953399658203
Validation loss: 2.0253556146416614

Epoch: 6| Step: 5
Training loss: 1.7331626415252686
Validation loss: 2.030783268713182

Epoch: 6| Step: 6
Training loss: 2.0954701900482178
Validation loss: 2.0219781744864678

Epoch: 6| Step: 7
Training loss: 1.889286994934082
Validation loss: 2.0163460726379068

Epoch: 6| Step: 8
Training loss: 2.236848831176758
Validation loss: 2.00938872368105

Epoch: 6| Step: 9
Training loss: 2.1470413208007812
Validation loss: 2.009402664758826

Epoch: 6| Step: 10
Training loss: 1.8977546691894531
Validation loss: 2.0322276289745043

Epoch: 6| Step: 11
Training loss: 1.6565237045288086
Validation loss: 2.039624288517942

Epoch: 6| Step: 12
Training loss: 1.1758495569229126
Validation loss: 2.0577571571514173

Epoch: 6| Step: 13
Training loss: 1.8430067300796509
Validation loss: 2.0790885520237747

Epoch: 139| Step: 0
Training loss: 1.4955596923828125
Validation loss: 2.087911921162759

Epoch: 6| Step: 1
Training loss: 2.6117284297943115
Validation loss: 2.1145088570092314

Epoch: 6| Step: 2
Training loss: 1.9861745834350586
Validation loss: 2.0729546072662517

Epoch: 6| Step: 3
Training loss: 1.5623888969421387
Validation loss: 2.049804973345931

Epoch: 6| Step: 4
Training loss: 1.6292715072631836
Validation loss: 2.042322366468368

Epoch: 6| Step: 5
Training loss: 2.2972490787506104
Validation loss: 2.051500505016696

Epoch: 6| Step: 6
Training loss: 1.6321237087249756
Validation loss: 2.045715093612671

Epoch: 6| Step: 7
Training loss: 1.0620002746582031
Validation loss: 2.0361732603401266

Epoch: 6| Step: 8
Training loss: 2.595493793487549
Validation loss: 2.0369643165219213

Epoch: 6| Step: 9
Training loss: 2.8919477462768555
Validation loss: 2.0129921692673878

Epoch: 6| Step: 10
Training loss: 2.39416241645813
Validation loss: 1.9980272221308883

Epoch: 6| Step: 11
Training loss: 1.4725338220596313
Validation loss: 1.9564976846018145

Epoch: 6| Step: 12
Training loss: 2.1007416248321533
Validation loss: 1.958858742508837

Epoch: 6| Step: 13
Training loss: 1.724790334701538
Validation loss: 1.952515632875504

Epoch: 140| Step: 0
Training loss: 2.401071548461914
Validation loss: 1.9829561825721496

Epoch: 6| Step: 1
Training loss: 1.809738278388977
Validation loss: 2.0103819459997196

Epoch: 6| Step: 2
Training loss: 2.4549717903137207
Validation loss: 2.0123011963341826

Epoch: 6| Step: 3
Training loss: 2.1635615825653076
Validation loss: 1.9842607590460009

Epoch: 6| Step: 4
Training loss: 1.4290728569030762
Validation loss: 1.9896390566261866

Epoch: 6| Step: 5
Training loss: 1.7182762622833252
Validation loss: 1.9605664860817693

Epoch: 6| Step: 6
Training loss: 2.766326904296875
Validation loss: 1.9667665586676648

Epoch: 6| Step: 7
Training loss: 1.6635481119155884
Validation loss: 2.0152025684233634

Epoch: 6| Step: 8
Training loss: 1.8497916460037231
Validation loss: 2.0382753700338383

Epoch: 6| Step: 9
Training loss: 1.4733290672302246
Validation loss: 2.066798315253309

Epoch: 6| Step: 10
Training loss: 2.030461311340332
Validation loss: 2.084886804703743

Epoch: 6| Step: 11
Training loss: 1.839689016342163
Validation loss: 2.1187060007485012

Epoch: 6| Step: 12
Training loss: 2.196080207824707
Validation loss: 2.0963426687384166

Epoch: 6| Step: 13
Training loss: 1.3234362602233887
Validation loss: 2.0526544342758837

Epoch: 141| Step: 0
Training loss: 2.1849875450134277
Validation loss: 2.0189104054563787

Epoch: 6| Step: 1
Training loss: 1.6440703868865967
Validation loss: 2.000908754205191

Epoch: 6| Step: 2
Training loss: 1.8211474418640137
Validation loss: 1.9864006401390157

Epoch: 6| Step: 3
Training loss: 2.409560441970825
Validation loss: 1.9788267138183757

Epoch: 6| Step: 4
Training loss: 1.7573281526565552
Validation loss: 1.966438720303197

Epoch: 6| Step: 5
Training loss: 1.5243408679962158
Validation loss: 1.9848144259504092

Epoch: 6| Step: 6
Training loss: 1.5078184604644775
Validation loss: 1.9876902282878917

Epoch: 6| Step: 7
Training loss: 1.505081295967102
Validation loss: 1.9803863110080842

Epoch: 6| Step: 8
Training loss: 1.1612560749053955
Validation loss: 1.9705034430309007

Epoch: 6| Step: 9
Training loss: 2.2885022163391113
Validation loss: 1.9895026606898154

Epoch: 6| Step: 10
Training loss: 1.661049246788025
Validation loss: 2.026308528838619

Epoch: 6| Step: 11
Training loss: 1.8051385879516602
Validation loss: 2.0478588791303736

Epoch: 6| Step: 12
Training loss: 2.7428629398345947
Validation loss: 2.0771334120022353

Epoch: 6| Step: 13
Training loss: 2.8477156162261963
Validation loss: 2.0974510690217376

Epoch: 142| Step: 0
Training loss: 2.4752800464630127
Validation loss: 2.095801140672417

Epoch: 6| Step: 1
Training loss: 1.9810378551483154
Validation loss: 2.0577879516027306

Epoch: 6| Step: 2
Training loss: 2.0840232372283936
Validation loss: 2.0370619040663525

Epoch: 6| Step: 3
Training loss: 2.358397960662842
Validation loss: 2.0222909412076397

Epoch: 6| Step: 4
Training loss: 1.756823182106018
Validation loss: 2.0438124210603776

Epoch: 6| Step: 5
Training loss: 1.990938425064087
Validation loss: 2.038346302124762

Epoch: 6| Step: 6
Training loss: 1.470655918121338
Validation loss: 2.017888230662192

Epoch: 6| Step: 7
Training loss: 1.6656560897827148
Validation loss: 1.9950962643469534

Epoch: 6| Step: 8
Training loss: 1.949881911277771
Validation loss: 1.9752358249438706

Epoch: 6| Step: 9
Training loss: 1.6882216930389404
Validation loss: 1.9534588424108361

Epoch: 6| Step: 10
Training loss: 1.9445881843566895
Validation loss: 1.9237150133297007

Epoch: 6| Step: 11
Training loss: 2.357578754425049
Validation loss: 1.9139068716315812

Epoch: 6| Step: 12
Training loss: 1.4084888696670532
Validation loss: 1.927759128232156

Epoch: 6| Step: 13
Training loss: 1.937894344329834
Validation loss: 1.96422210303686

Epoch: 143| Step: 0
Training loss: 2.0498046875
Validation loss: 1.9768134509363482

Epoch: 6| Step: 1
Training loss: 2.0074827671051025
Validation loss: 1.9618051129002725

Epoch: 6| Step: 2
Training loss: 1.7280296087265015
Validation loss: 1.962821666912366

Epoch: 6| Step: 3
Training loss: 1.6608726978302002
Validation loss: 1.981772720172841

Epoch: 6| Step: 4
Training loss: 2.3523213863372803
Validation loss: 1.9890899248020624

Epoch: 6| Step: 5
Training loss: 1.8948941230773926
Validation loss: 2.0216828751307663

Epoch: 6| Step: 6
Training loss: 1.3581559658050537
Validation loss: 2.0324348095924623

Epoch: 6| Step: 7
Training loss: 0.9872274994850159
Validation loss: 2.0188384081727717

Epoch: 6| Step: 8
Training loss: 1.5861226320266724
Validation loss: 2.0377142993352746

Epoch: 6| Step: 9
Training loss: 2.118760108947754
Validation loss: 2.010424662661809

Epoch: 6| Step: 10
Training loss: 2.0372257232666016
Validation loss: 2.002869857254849

Epoch: 6| Step: 11
Training loss: 2.001218795776367
Validation loss: 1.9831404186064197

Epoch: 6| Step: 12
Training loss: 2.2708029747009277
Validation loss: 1.9970114026018368

Epoch: 6| Step: 13
Training loss: 2.4529521465301514
Validation loss: 2.0131837860230477

Epoch: 144| Step: 0
Training loss: 1.5766632556915283
Validation loss: 2.0451481073133406

Epoch: 6| Step: 1
Training loss: 2.073136568069458
Validation loss: 2.0502285867609005

Epoch: 6| Step: 2
Training loss: 1.824312686920166
Validation loss: 2.039842064662646

Epoch: 6| Step: 3
Training loss: 2.1767029762268066
Validation loss: 2.025233368719778

Epoch: 6| Step: 4
Training loss: 1.5754663944244385
Validation loss: 2.0321959372489684

Epoch: 6| Step: 5
Training loss: 2.339156150817871
Validation loss: 2.0225331962749524

Epoch: 6| Step: 6
Training loss: 1.8125505447387695
Validation loss: 2.003770525737475

Epoch: 6| Step: 7
Training loss: 1.3062164783477783
Validation loss: 1.9906955713866858

Epoch: 6| Step: 8
Training loss: 1.5867369174957275
Validation loss: 1.9693461041296683

Epoch: 6| Step: 9
Training loss: 1.7400169372558594
Validation loss: 1.9657436468267953

Epoch: 6| Step: 10
Training loss: 2.173222064971924
Validation loss: 2.006544114441

Epoch: 6| Step: 11
Training loss: 1.8382072448730469
Validation loss: 2.044350576657121

Epoch: 6| Step: 12
Training loss: 2.013575553894043
Validation loss: 2.0393191922095513

Epoch: 6| Step: 13
Training loss: 2.0565483570098877
Validation loss: 2.04984555193173

Epoch: 145| Step: 0
Training loss: 2.008126735687256
Validation loss: 2.037050421519946

Epoch: 6| Step: 1
Training loss: 2.066802501678467
Validation loss: 2.0035426078304166

Epoch: 6| Step: 2
Training loss: 1.8536090850830078
Validation loss: 1.9980942331334597

Epoch: 6| Step: 3
Training loss: 1.256385087966919
Validation loss: 2.0173466372233566

Epoch: 6| Step: 4
Training loss: 2.168764114379883
Validation loss: 2.0396260317935737

Epoch: 6| Step: 5
Training loss: 1.3433486223220825
Validation loss: 2.01869898585863

Epoch: 6| Step: 6
Training loss: 2.050548791885376
Validation loss: 2.0065677191621516

Epoch: 6| Step: 7
Training loss: 1.4890484809875488
Validation loss: 1.9723920142778786

Epoch: 6| Step: 8
Training loss: 2.034870147705078
Validation loss: 1.975814987254399

Epoch: 6| Step: 9
Training loss: 1.7886734008789062
Validation loss: 1.9618216970915436

Epoch: 6| Step: 10
Training loss: 1.8943209648132324
Validation loss: 1.9599783138562274

Epoch: 6| Step: 11
Training loss: 2.0127527713775635
Validation loss: 1.962545492315805

Epoch: 6| Step: 12
Training loss: 1.5583149194717407
Validation loss: 1.9655505098322386

Epoch: 6| Step: 13
Training loss: 2.2059738636016846
Validation loss: 2.0014435860418502

Epoch: 146| Step: 0
Training loss: 1.2279810905456543
Validation loss: 2.0058058538744525

Epoch: 6| Step: 1
Training loss: 1.7400741577148438
Validation loss: 1.9999760273964173

Epoch: 6| Step: 2
Training loss: 2.5232491493225098
Validation loss: 2.0186338578501055

Epoch: 6| Step: 3
Training loss: 2.2363388538360596
Validation loss: 2.006424250141267

Epoch: 6| Step: 4
Training loss: 1.8399866819381714
Validation loss: 2.0067252894883514

Epoch: 6| Step: 5
Training loss: 1.4014525413513184
Validation loss: 1.9956531396476171

Epoch: 6| Step: 6
Training loss: 1.0930280685424805
Validation loss: 2.0207443160395466

Epoch: 6| Step: 7
Training loss: 2.2386913299560547
Validation loss: 2.0231246486786874

Epoch: 6| Step: 8
Training loss: 2.1813583374023438
Validation loss: 2.039350176370272

Epoch: 6| Step: 9
Training loss: 1.8252270221710205
Validation loss: 2.0917225012215237

Epoch: 6| Step: 10
Training loss: 2.075979232788086
Validation loss: 2.059910005138766

Epoch: 6| Step: 11
Training loss: 1.6495897769927979
Validation loss: 2.038831305760209

Epoch: 6| Step: 12
Training loss: 2.2308602333068848
Validation loss: 2.0007345945604387

Epoch: 6| Step: 13
Training loss: 1.5939301252365112
Validation loss: 1.9760949586027412

Epoch: 147| Step: 0
Training loss: 1.6508276462554932
Validation loss: 1.9288860879918581

Epoch: 6| Step: 1
Training loss: 1.7137855291366577
Validation loss: 1.9033441799943165

Epoch: 6| Step: 2
Training loss: 2.5964174270629883
Validation loss: 1.8979342137613604

Epoch: 6| Step: 3
Training loss: 1.7176005840301514
Validation loss: 1.8967421888023295

Epoch: 6| Step: 4
Training loss: 2.209808588027954
Validation loss: 1.9092010682629001

Epoch: 6| Step: 5
Training loss: 2.1418910026550293
Validation loss: 1.9134403313359907

Epoch: 6| Step: 6
Training loss: 1.960077166557312
Validation loss: 1.9217880131095968

Epoch: 6| Step: 7
Training loss: 1.2897521257400513
Validation loss: 1.9319624323998728

Epoch: 6| Step: 8
Training loss: 1.8616665601730347
Validation loss: 1.9514970805055352

Epoch: 6| Step: 9
Training loss: 1.0643892288208008
Validation loss: 1.9797406337594474

Epoch: 6| Step: 10
Training loss: 2.121342897415161
Validation loss: 2.009713113948863

Epoch: 6| Step: 11
Training loss: 1.8800913095474243
Validation loss: 2.057929792711812

Epoch: 6| Step: 12
Training loss: 1.461824893951416
Validation loss: 2.088350065292851

Epoch: 6| Step: 13
Training loss: 1.9409048557281494
Validation loss: 2.124269082982053

Epoch: 148| Step: 0
Training loss: 2.0489134788513184
Validation loss: 2.1722558480437084

Epoch: 6| Step: 1
Training loss: 1.816569209098816
Validation loss: 2.2177224569423224

Epoch: 6| Step: 2
Training loss: 2.1889102458953857
Validation loss: 2.282807396304223

Epoch: 6| Step: 3
Training loss: 2.199312686920166
Validation loss: 2.285838375809372

Epoch: 6| Step: 4
Training loss: 2.0303964614868164
Validation loss: 2.2696879781702513

Epoch: 6| Step: 5
Training loss: 2.012962818145752
Validation loss: 2.2010520196730092

Epoch: 6| Step: 6
Training loss: 1.5658848285675049
Validation loss: 2.15666691974927

Epoch: 6| Step: 7
Training loss: 1.2520215511322021
Validation loss: 2.128131858764156

Epoch: 6| Step: 8
Training loss: 1.4527522325515747
Validation loss: 2.05990739791624

Epoch: 6| Step: 9
Training loss: 2.0097720623016357
Validation loss: 2.0812339987806094

Epoch: 6| Step: 10
Training loss: 2.036193370819092
Validation loss: 2.0698740764330794

Epoch: 6| Step: 11
Training loss: 2.0755205154418945
Validation loss: 2.0611198897002847

Epoch: 6| Step: 12
Training loss: 1.7371715307235718
Validation loss: 1.9860984689445906

Epoch: 6| Step: 13
Training loss: 1.3962135314941406
Validation loss: 1.933068360051801

Epoch: 149| Step: 0
Training loss: 2.2713189125061035
Validation loss: 1.9258416301460677

Epoch: 6| Step: 1
Training loss: 2.2397964000701904
Validation loss: 1.9301642128216323

Epoch: 6| Step: 2
Training loss: 1.8566206693649292
Validation loss: 1.9102281678107478

Epoch: 6| Step: 3
Training loss: 2.3397178649902344
Validation loss: 1.8897052221400763

Epoch: 6| Step: 4
Training loss: 1.217907428741455
Validation loss: 1.8996687960881058

Epoch: 6| Step: 5
Training loss: 2.023376941680908
Validation loss: 1.898800620468714

Epoch: 6| Step: 6
Training loss: 2.2135009765625
Validation loss: 1.903638247520693

Epoch: 6| Step: 7
Training loss: 1.5391756296157837
Validation loss: 1.902637122779764

Epoch: 6| Step: 8
Training loss: 1.961491584777832
Validation loss: 1.9502679430028445

Epoch: 6| Step: 9
Training loss: 1.071879267692566
Validation loss: 1.9679898510697067

Epoch: 6| Step: 10
Training loss: 1.9665513038635254
Validation loss: 2.012468445685602

Epoch: 6| Step: 11
Training loss: 1.3596749305725098
Validation loss: 2.0489997825314923

Epoch: 6| Step: 12
Training loss: 1.666475772857666
Validation loss: 2.0443042888436267

Epoch: 6| Step: 13
Training loss: 1.585497498512268
Validation loss: 2.055805003771218

Epoch: 150| Step: 0
Training loss: 2.048257350921631
Validation loss: 2.066794362119449

Epoch: 6| Step: 1
Training loss: 1.853399395942688
Validation loss: 2.047387166689801

Epoch: 6| Step: 2
Training loss: 1.6937865018844604
Validation loss: 2.0447159787660003

Epoch: 6| Step: 3
Training loss: 1.3751412630081177
Validation loss: 2.0369247544196343

Epoch: 6| Step: 4
Training loss: 1.5231832265853882
Validation loss: 2.0709276019885974

Epoch: 6| Step: 5
Training loss: 1.8907183408737183
Validation loss: 2.081582889761976

Epoch: 6| Step: 6
Training loss: 1.6345045566558838
Validation loss: 2.1066462134802215

Epoch: 6| Step: 7
Training loss: 1.7755916118621826
Validation loss: 2.106686753611411

Epoch: 6| Step: 8
Training loss: 2.3122830390930176
Validation loss: 2.083202169787499

Epoch: 6| Step: 9
Training loss: 1.97212553024292
Validation loss: 2.052832700872934

Epoch: 6| Step: 10
Training loss: 1.5628080368041992
Validation loss: 2.0421214642063266

Epoch: 6| Step: 11
Training loss: 1.8608899116516113
Validation loss: 2.0231602499561925

Epoch: 6| Step: 12
Training loss: 1.3169233798980713
Validation loss: 2.0114747721661805

Epoch: 6| Step: 13
Training loss: 2.2825210094451904
Validation loss: 1.9943416926168627

Epoch: 151| Step: 0
Training loss: 1.2382550239562988
Validation loss: 1.9909464877138856

Epoch: 6| Step: 1
Training loss: 2.163602590560913
Validation loss: 2.0155223261925483

Epoch: 6| Step: 2
Training loss: 2.176666736602783
Validation loss: 2.012212409768053

Epoch: 6| Step: 3
Training loss: 2.0526280403137207
Validation loss: 2.0179882998107583

Epoch: 6| Step: 4
Training loss: 1.4511892795562744
Validation loss: 2.029094111534857

Epoch: 6| Step: 5
Training loss: 1.45119047164917
Validation loss: 2.024416446685791

Epoch: 6| Step: 6
Training loss: 2.36788272857666
Validation loss: 2.025967264688143

Epoch: 6| Step: 7
Training loss: 1.9146302938461304
Validation loss: 2.0451703674049786

Epoch: 6| Step: 8
Training loss: 1.415498971939087
Validation loss: 2.011248225806862

Epoch: 6| Step: 9
Training loss: 1.4859578609466553
Validation loss: 1.993876298268636

Epoch: 6| Step: 10
Training loss: 2.06941556930542
Validation loss: 1.9757582513234948

Epoch: 6| Step: 11
Training loss: 1.973347544670105
Validation loss: 1.950080043526106

Epoch: 6| Step: 12
Training loss: 1.6127346754074097
Validation loss: 1.9372551313010595

Epoch: 6| Step: 13
Training loss: 1.329285979270935
Validation loss: 1.9291440466398835

Epoch: 152| Step: 0
Training loss: 1.9172017574310303
Validation loss: 1.951505103418904

Epoch: 6| Step: 1
Training loss: 1.4117056131362915
Validation loss: 1.9790668884913127

Epoch: 6| Step: 2
Training loss: 2.0783920288085938
Validation loss: 1.968170327524985

Epoch: 6| Step: 3
Training loss: 1.4993071556091309
Validation loss: 1.987345007158095

Epoch: 6| Step: 4
Training loss: 1.7937886714935303
Validation loss: 1.972911988535235

Epoch: 6| Step: 5
Training loss: 1.8255162239074707
Validation loss: 1.9655612694319857

Epoch: 6| Step: 6
Training loss: 1.5507407188415527
Validation loss: 1.954632979567333

Epoch: 6| Step: 7
Training loss: 2.3174638748168945
Validation loss: 1.9685507615407307

Epoch: 6| Step: 8
Training loss: 1.2055399417877197
Validation loss: 1.957124125572943

Epoch: 6| Step: 9
Training loss: 1.242875099182129
Validation loss: 1.9626454819915116

Epoch: 6| Step: 10
Training loss: 1.860662817955017
Validation loss: 1.9555340902779692

Epoch: 6| Step: 11
Training loss: 1.6724367141723633
Validation loss: 1.9744487347141388

Epoch: 6| Step: 12
Training loss: 2.131932020187378
Validation loss: 1.9607142004915463

Epoch: 6| Step: 13
Training loss: 1.6493185758590698
Validation loss: 1.966545469017439

Epoch: 153| Step: 0
Training loss: 1.7536022663116455
Validation loss: 1.9670897619698637

Epoch: 6| Step: 1
Training loss: 1.4213789701461792
Validation loss: 1.9961849989429596

Epoch: 6| Step: 2
Training loss: 2.2166552543640137
Validation loss: 1.9851367345420263

Epoch: 6| Step: 3
Training loss: 1.7231613397598267
Validation loss: 1.9992154823836459

Epoch: 6| Step: 4
Training loss: 1.165743112564087
Validation loss: 2.0147544914676296

Epoch: 6| Step: 5
Training loss: 1.3384556770324707
Validation loss: 2.016023233372678

Epoch: 6| Step: 6
Training loss: 2.2429189682006836
Validation loss: 2.0308980787954023

Epoch: 6| Step: 7
Training loss: 2.3717398643493652
Validation loss: 2.0532712090399956

Epoch: 6| Step: 8
Training loss: 2.389620780944824
Validation loss: 2.0512411466208835

Epoch: 6| Step: 9
Training loss: 1.171351432800293
Validation loss: 2.0672220747957946

Epoch: 6| Step: 10
Training loss: 1.5150593519210815
Validation loss: 2.0912498915067284

Epoch: 6| Step: 11
Training loss: 1.606276273727417
Validation loss: 2.112791484402072

Epoch: 6| Step: 12
Training loss: 1.8908545970916748
Validation loss: 2.102799279715425

Epoch: 6| Step: 13
Training loss: 1.3801243305206299
Validation loss: 2.115773021533925

Epoch: 154| Step: 0
Training loss: 1.1199336051940918
Validation loss: 2.090443818799911

Epoch: 6| Step: 1
Training loss: 1.9652774333953857
Validation loss: 2.0900192863197735

Epoch: 6| Step: 2
Training loss: 2.6965136528015137
Validation loss: 2.0936433064040316

Epoch: 6| Step: 3
Training loss: 1.5503225326538086
Validation loss: 2.120230536307058

Epoch: 6| Step: 4
Training loss: 2.0736236572265625
Validation loss: 2.0877530536343976

Epoch: 6| Step: 5
Training loss: 1.9260286092758179
Validation loss: 2.0057586610958142

Epoch: 6| Step: 6
Training loss: 1.3466204404830933
Validation loss: 1.9712296429500784

Epoch: 6| Step: 7
Training loss: 1.8402893543243408
Validation loss: 1.9371558530356294

Epoch: 6| Step: 8
Training loss: 1.945968508720398
Validation loss: 1.9235642853603567

Epoch: 6| Step: 9
Training loss: 1.22748601436615
Validation loss: 1.9115883368317799

Epoch: 6| Step: 10
Training loss: 1.7992169857025146
Validation loss: 1.9148009669396184

Epoch: 6| Step: 11
Training loss: 2.106873035430908
Validation loss: 1.9343216265401533

Epoch: 6| Step: 12
Training loss: 1.3877387046813965
Validation loss: 1.923280958206423

Epoch: 6| Step: 13
Training loss: 1.7451125383377075
Validation loss: 1.9174218485432286

Epoch: 155| Step: 0
Training loss: 2.2318530082702637
Validation loss: 1.9170517639447284

Epoch: 6| Step: 1
Training loss: 1.5984246730804443
Validation loss: 1.9321153740729056

Epoch: 6| Step: 2
Training loss: 1.3136088848114014
Validation loss: 1.914767220456113

Epoch: 6| Step: 3
Training loss: 1.9640403985977173
Validation loss: 1.9206959573171472

Epoch: 6| Step: 4
Training loss: 1.6556099653244019
Validation loss: 1.9271006404712636

Epoch: 6| Step: 5
Training loss: 2.1035220623016357
Validation loss: 1.9129473714418308

Epoch: 6| Step: 6
Training loss: 2.4568967819213867
Validation loss: 1.914183142364666

Epoch: 6| Step: 7
Training loss: 1.0900311470031738
Validation loss: 1.9178720161479006

Epoch: 6| Step: 8
Training loss: 2.044973850250244
Validation loss: 1.948842962582906

Epoch: 6| Step: 9
Training loss: 1.6386010646820068
Validation loss: 1.9655040976821736

Epoch: 6| Step: 10
Training loss: 1.8313387632369995
Validation loss: 1.984593778528193

Epoch: 6| Step: 11
Training loss: 1.0906460285186768
Validation loss: 2.0060033567490114

Epoch: 6| Step: 12
Training loss: 1.582615613937378
Validation loss: 2.021419535401047

Epoch: 6| Step: 13
Training loss: 1.580077052116394
Validation loss: 2.0430529668766964

Epoch: 156| Step: 0
Training loss: 1.7054283618927002
Validation loss: 2.090587685185094

Epoch: 6| Step: 1
Training loss: 1.130846381187439
Validation loss: 2.0382308190868748

Epoch: 6| Step: 2
Training loss: 2.533132553100586
Validation loss: 2.012808661307058

Epoch: 6| Step: 3
Training loss: 1.297034502029419
Validation loss: 2.002247505290534

Epoch: 6| Step: 4
Training loss: 2.135450839996338
Validation loss: 1.9819306532541912

Epoch: 6| Step: 5
Training loss: 1.2107696533203125
Validation loss: 1.9906473839154808

Epoch: 6| Step: 6
Training loss: 1.8349336385726929
Validation loss: 1.9773063390485701

Epoch: 6| Step: 7
Training loss: 1.3812353610992432
Validation loss: 1.9801508534339167

Epoch: 6| Step: 8
Training loss: 1.6589884757995605
Validation loss: 1.9773874167473084

Epoch: 6| Step: 9
Training loss: 1.2624071836471558
Validation loss: 1.9891733302864978

Epoch: 6| Step: 10
Training loss: 2.1696572303771973
Validation loss: 1.9833429872348745

Epoch: 6| Step: 11
Training loss: 0.9698014259338379
Validation loss: 1.9854699885973366

Epoch: 6| Step: 12
Training loss: 2.5762131214141846
Validation loss: 1.9868756853124148

Epoch: 6| Step: 13
Training loss: 2.0245158672332764
Validation loss: 1.989252080199539

Epoch: 157| Step: 0
Training loss: 0.9344003200531006
Validation loss: 1.989820829001806

Epoch: 6| Step: 1
Training loss: 1.8812611103057861
Validation loss: 2.022715131441752

Epoch: 6| Step: 2
Training loss: 1.878368616104126
Validation loss: 2.0263354534743936

Epoch: 6| Step: 3
Training loss: 1.66339111328125
Validation loss: 2.0581719131879908

Epoch: 6| Step: 4
Training loss: 1.7270684242248535
Validation loss: 2.0475549620966755

Epoch: 6| Step: 5
Training loss: 1.2179734706878662
Validation loss: 2.0382136170582106

Epoch: 6| Step: 6
Training loss: 2.4534177780151367
Validation loss: 2.0454448551260014

Epoch: 6| Step: 7
Training loss: 1.1033052206039429
Validation loss: 2.0275825479979157

Epoch: 6| Step: 8
Training loss: 1.4199953079223633
Validation loss: 2.0174519361988192

Epoch: 6| Step: 9
Training loss: 2.217186212539673
Validation loss: 2.006932871316069

Epoch: 6| Step: 10
Training loss: 2.044495105743408
Validation loss: 1.9947822375964093

Epoch: 6| Step: 11
Training loss: 1.9239171743392944
Validation loss: 1.9956688009282595

Epoch: 6| Step: 12
Training loss: 1.829571008682251
Validation loss: 1.9719062287320372

Epoch: 6| Step: 13
Training loss: 0.8330143094062805
Validation loss: 1.9505214486070859

Epoch: 158| Step: 0
Training loss: 1.9555045366287231
Validation loss: 1.9547524811119161

Epoch: 6| Step: 1
Training loss: 1.3022956848144531
Validation loss: 1.9568291556450628

Epoch: 6| Step: 2
Training loss: 1.1616191864013672
Validation loss: 1.9805494918618152

Epoch: 6| Step: 3
Training loss: 1.6584563255310059
Validation loss: 2.0050537009393015

Epoch: 6| Step: 4
Training loss: 1.5147418975830078
Validation loss: 2.0312384572080386

Epoch: 6| Step: 5
Training loss: 1.5781426429748535
Validation loss: 2.017952278096189

Epoch: 6| Step: 6
Training loss: 1.5806820392608643
Validation loss: 2.0009889218115036

Epoch: 6| Step: 7
Training loss: 1.5215215682983398
Validation loss: 2.0189975487288607

Epoch: 6| Step: 8
Training loss: 1.7756664752960205
Validation loss: 2.0528174228565668

Epoch: 6| Step: 9
Training loss: 2.230630397796631
Validation loss: 2.0631808491163355

Epoch: 6| Step: 10
Training loss: 2.013777732849121
Validation loss: 2.0403805753236175

Epoch: 6| Step: 11
Training loss: 2.2312746047973633
Validation loss: 2.011838650190702

Epoch: 6| Step: 12
Training loss: 1.6605777740478516
Validation loss: 2.027628416656166

Epoch: 6| Step: 13
Training loss: 1.2164793014526367
Validation loss: 2.0026805093211513

Epoch: 159| Step: 0
Training loss: 1.352393388748169
Validation loss: 2.026220243464234

Epoch: 6| Step: 1
Training loss: 1.2072575092315674
Validation loss: 2.010012431811261

Epoch: 6| Step: 2
Training loss: 1.6942827701568604
Validation loss: 2.0075466017569266

Epoch: 6| Step: 3
Training loss: 1.3639774322509766
Validation loss: 2.0203407810580347

Epoch: 6| Step: 4
Training loss: 1.2921898365020752
Validation loss: 1.9954287198282057

Epoch: 6| Step: 5
Training loss: 1.5390987396240234
Validation loss: 1.9710792546631188

Epoch: 6| Step: 6
Training loss: 2.2848124504089355
Validation loss: 1.9576726011050645

Epoch: 6| Step: 7
Training loss: 1.7846349477767944
Validation loss: 1.9560460377764959

Epoch: 6| Step: 8
Training loss: 1.6432104110717773
Validation loss: 1.927684691644484

Epoch: 6| Step: 9
Training loss: 1.6885302066802979
Validation loss: 1.9092481918232416

Epoch: 6| Step: 10
Training loss: 1.592622995376587
Validation loss: 1.9233794596887404

Epoch: 6| Step: 11
Training loss: 1.5841479301452637
Validation loss: 1.9251037900165846

Epoch: 6| Step: 12
Training loss: 1.9994008541107178
Validation loss: 1.954825306451449

Epoch: 6| Step: 13
Training loss: 2.473966360092163
Validation loss: 1.9516554801694808

Epoch: 160| Step: 0
Training loss: 1.8211112022399902
Validation loss: 1.9589667012614589

Epoch: 6| Step: 1
Training loss: 0.9925499558448792
Validation loss: 1.9792697993657922

Epoch: 6| Step: 2
Training loss: 2.4417221546173096
Validation loss: 1.98446326486526

Epoch: 6| Step: 3
Training loss: 1.5697740316390991
Validation loss: 1.9761875726843392

Epoch: 6| Step: 4
Training loss: 1.7714065313339233
Validation loss: 1.9611095177230013

Epoch: 6| Step: 5
Training loss: 2.1428821086883545
Validation loss: 1.977747424956291

Epoch: 6| Step: 6
Training loss: 1.3925310373306274
Validation loss: 1.9622941324787755

Epoch: 6| Step: 7
Training loss: 1.8920137882232666
Validation loss: 1.945035260210755

Epoch: 6| Step: 8
Training loss: 1.501266360282898
Validation loss: 1.9717858786224036

Epoch: 6| Step: 9
Training loss: 0.9332001209259033
Validation loss: 1.9964508061767907

Epoch: 6| Step: 10
Training loss: 1.5564095973968506
Validation loss: 2.043139439757152

Epoch: 6| Step: 11
Training loss: 1.304233431816101
Validation loss: 2.067353638269568

Epoch: 6| Step: 12
Training loss: 2.221986770629883
Validation loss: 2.0607778846576648

Epoch: 6| Step: 13
Training loss: 1.1927634477615356
Validation loss: 2.046154563144971

Epoch: 161| Step: 0
Training loss: 1.4913630485534668
Validation loss: 2.0113271833747945

Epoch: 6| Step: 1
Training loss: 1.2956316471099854
Validation loss: 1.9612138143149755

Epoch: 6| Step: 2
Training loss: 2.164024829864502
Validation loss: 1.9462356413564375

Epoch: 6| Step: 3
Training loss: 2.22536301612854
Validation loss: 1.9445033047788887

Epoch: 6| Step: 4
Training loss: 2.1283507347106934
Validation loss: 1.9267210883478965

Epoch: 6| Step: 5
Training loss: 1.4760024547576904
Validation loss: 1.9197382350121774

Epoch: 6| Step: 6
Training loss: 1.7193882465362549
Validation loss: 1.9123998675295102

Epoch: 6| Step: 7
Training loss: 1.2272284030914307
Validation loss: 1.9097607046045282

Epoch: 6| Step: 8
Training loss: 2.1890039443969727
Validation loss: 1.9334700851030246

Epoch: 6| Step: 9
Training loss: 1.0721051692962646
Validation loss: 1.9723028649565995

Epoch: 6| Step: 10
Training loss: 1.3673489093780518
Validation loss: 1.9726109286790252

Epoch: 6| Step: 11
Training loss: 1.5722410678863525
Validation loss: 1.999750767984698

Epoch: 6| Step: 12
Training loss: 1.3548672199249268
Validation loss: 2.044616363381827

Epoch: 6| Step: 13
Training loss: 1.1693185567855835
Validation loss: 2.0614611935871903

Epoch: 162| Step: 0
Training loss: 1.2476553916931152
Validation loss: 2.085615873336792

Epoch: 6| Step: 1
Training loss: 2.0377869606018066
Validation loss: 2.079657023952853

Epoch: 6| Step: 2
Training loss: 1.9546399116516113
Validation loss: 2.064629509884824

Epoch: 6| Step: 3
Training loss: 1.1745234727859497
Validation loss: 2.054506100634093

Epoch: 6| Step: 4
Training loss: 1.1839590072631836
Validation loss: 2.043784426104638

Epoch: 6| Step: 5
Training loss: 1.1391053199768066
Validation loss: 2.0239792408481723

Epoch: 6| Step: 6
Training loss: 1.825579047203064
Validation loss: 2.0005635305117537

Epoch: 6| Step: 7
Training loss: 1.5556323528289795
Validation loss: 1.9750014838352

Epoch: 6| Step: 8
Training loss: 2.3973045349121094
Validation loss: 1.9840197460625761

Epoch: 6| Step: 9
Training loss: 2.6278676986694336
Validation loss: 1.9917633892387472

Epoch: 6| Step: 10
Training loss: 1.3450305461883545
Validation loss: 2.0058467157425417

Epoch: 6| Step: 11
Training loss: 1.5374128818511963
Validation loss: 1.9970740143970778

Epoch: 6| Step: 12
Training loss: 1.7098181247711182
Validation loss: 1.9753680690642326

Epoch: 6| Step: 13
Training loss: 1.4787935018539429
Validation loss: 1.9881921045241817

Epoch: 163| Step: 0
Training loss: 2.0276377201080322
Validation loss: 1.9459016784544914

Epoch: 6| Step: 1
Training loss: 2.433698892593384
Validation loss: 1.940460148678031

Epoch: 6| Step: 2
Training loss: 1.230207920074463
Validation loss: 1.9453886760178434

Epoch: 6| Step: 3
Training loss: 1.1466079950332642
Validation loss: 1.956985431332742

Epoch: 6| Step: 4
Training loss: 1.2324535846710205
Validation loss: 1.9700863053721767

Epoch: 6| Step: 5
Training loss: 1.3856267929077148
Validation loss: 2.006287492731566

Epoch: 6| Step: 6
Training loss: 1.1636995077133179
Validation loss: 2.012417283109439

Epoch: 6| Step: 7
Training loss: 1.3981165885925293
Validation loss: 2.039311506414926

Epoch: 6| Step: 8
Training loss: 1.8609530925750732
Validation loss: 2.0671397383495043

Epoch: 6| Step: 9
Training loss: 1.9194425344467163
Validation loss: 2.0909882027615785

Epoch: 6| Step: 10
Training loss: 1.8179430961608887
Validation loss: 2.1141609120112594

Epoch: 6| Step: 11
Training loss: 0.9555701017379761
Validation loss: 2.1034801467772453

Epoch: 6| Step: 12
Training loss: 2.395805835723877
Validation loss: 2.120655587924424

Epoch: 6| Step: 13
Training loss: 1.6630589962005615
Validation loss: 2.115514968031196

Epoch: 164| Step: 0
Training loss: 1.4043300151824951
Validation loss: 2.077024495729836

Epoch: 6| Step: 1
Training loss: 1.5634026527404785
Validation loss: 2.054456739015477

Epoch: 6| Step: 2
Training loss: 1.869821310043335
Validation loss: 2.0140725143494143

Epoch: 6| Step: 3
Training loss: 2.1647884845733643
Validation loss: 1.9885123750214935

Epoch: 6| Step: 4
Training loss: 1.4321660995483398
Validation loss: 1.9761341387225735

Epoch: 6| Step: 5
Training loss: 1.6980431079864502
Validation loss: 1.9388127865329865

Epoch: 6| Step: 6
Training loss: 1.7895803451538086
Validation loss: 1.9408750277693554

Epoch: 6| Step: 7
Training loss: 1.662210464477539
Validation loss: 1.9484752813975017

Epoch: 6| Step: 8
Training loss: 1.2625030279159546
Validation loss: 1.9426339544275755

Epoch: 6| Step: 9
Training loss: 1.656104564666748
Validation loss: 1.9527050423365768

Epoch: 6| Step: 10
Training loss: 1.7488842010498047
Validation loss: 1.9384008492192915

Epoch: 6| Step: 11
Training loss: 1.0787503719329834
Validation loss: 1.9731751936738209

Epoch: 6| Step: 12
Training loss: 1.5422594547271729
Validation loss: 1.9749563329963273

Epoch: 6| Step: 13
Training loss: 1.9594590663909912
Validation loss: 2.0122287760498705

Epoch: 165| Step: 0
Training loss: 2.130622386932373
Validation loss: 2.012845036804035

Epoch: 6| Step: 1
Training loss: 1.4492355585098267
Validation loss: 2.0312938074911795

Epoch: 6| Step: 2
Training loss: 1.575917363166809
Validation loss: 2.0652523322771956

Epoch: 6| Step: 3
Training loss: 0.613342821598053
Validation loss: 2.101054338998692

Epoch: 6| Step: 4
Training loss: 1.2463107109069824
Validation loss: 2.101969244659588

Epoch: 6| Step: 5
Training loss: 1.8994426727294922
Validation loss: 2.0774102210998535

Epoch: 6| Step: 6
Training loss: 1.0935707092285156
Validation loss: 2.0567803946874474

Epoch: 6| Step: 7
Training loss: 1.947635293006897
Validation loss: 1.9920684958017

Epoch: 6| Step: 8
Training loss: 2.0521326065063477
Validation loss: 1.9820678259736748

Epoch: 6| Step: 9
Training loss: 1.6134066581726074
Validation loss: 1.975002763091877

Epoch: 6| Step: 10
Training loss: 1.9188258647918701
Validation loss: 1.956397077088715

Epoch: 6| Step: 11
Training loss: 1.5100877285003662
Validation loss: 1.964242027651879

Epoch: 6| Step: 12
Training loss: 2.105088233947754
Validation loss: 1.953461552178988

Epoch: 6| Step: 13
Training loss: 1.5466527938842773
Validation loss: 1.9407636145109772

Epoch: 166| Step: 0
Training loss: 1.4888761043548584
Validation loss: 1.9304235353264758

Epoch: 6| Step: 1
Training loss: 1.2010891437530518
Validation loss: 1.9225736151459396

Epoch: 6| Step: 2
Training loss: 1.4173252582550049
Validation loss: 1.926250123208569

Epoch: 6| Step: 3
Training loss: 1.9678065776824951
Validation loss: 1.95276439574457

Epoch: 6| Step: 4
Training loss: 1.2446558475494385
Validation loss: 1.9780530032291208

Epoch: 6| Step: 5
Training loss: 1.836035966873169
Validation loss: 1.9927992384920838

Epoch: 6| Step: 6
Training loss: 1.272958755493164
Validation loss: 2.0267284301019486

Epoch: 6| Step: 7
Training loss: 1.6198577880859375
Validation loss: 2.0476647115522817

Epoch: 6| Step: 8
Training loss: 1.8901208639144897
Validation loss: 2.0679757389971005

Epoch: 6| Step: 9
Training loss: 1.5407356023788452
Validation loss: 2.0529109098578013

Epoch: 6| Step: 10
Training loss: 1.720285177230835
Validation loss: 2.022631037619806

Epoch: 6| Step: 11
Training loss: 1.6181132793426514
Validation loss: 2.010611826373685

Epoch: 6| Step: 12
Training loss: 2.012061595916748
Validation loss: 1.9840303838893931

Epoch: 6| Step: 13
Training loss: 1.648424744606018
Validation loss: 1.9785788815508607

Epoch: 167| Step: 0
Training loss: 1.389601469039917
Validation loss: 1.9791579118338964

Epoch: 6| Step: 1
Training loss: 1.9045774936676025
Validation loss: 1.9854961274772562

Epoch: 6| Step: 2
Training loss: 1.4777321815490723
Validation loss: 1.9793671100370345

Epoch: 6| Step: 3
Training loss: 2.065188407897949
Validation loss: 1.9799417757218885

Epoch: 6| Step: 4
Training loss: 1.3780543804168701
Validation loss: 2.002569129390101

Epoch: 6| Step: 5
Training loss: 1.5035827159881592
Validation loss: 2.022278062758907

Epoch: 6| Step: 6
Training loss: 1.5274658203125
Validation loss: 2.021681208764353

Epoch: 6| Step: 7
Training loss: 1.0956578254699707
Validation loss: 2.01124136165906

Epoch: 6| Step: 8
Training loss: 1.8102463483810425
Validation loss: 2.0222745018620647

Epoch: 6| Step: 9
Training loss: 1.975687026977539
Validation loss: 2.0251913775679884

Epoch: 6| Step: 10
Training loss: 0.9761934280395508
Validation loss: 2.0319633663341565

Epoch: 6| Step: 11
Training loss: 1.5190821886062622
Validation loss: 2.016354350633519

Epoch: 6| Step: 12
Training loss: 1.5507197380065918
Validation loss: 1.9878621639743927

Epoch: 6| Step: 13
Training loss: 1.2662336826324463
Validation loss: 1.9866805409872403

Epoch: 168| Step: 0
Training loss: 1.2664439678192139
Validation loss: 1.9830596164990497

Epoch: 6| Step: 1
Training loss: 1.13509202003479
Validation loss: 1.9777502834155996

Epoch: 6| Step: 2
Training loss: 2.0364930629730225
Validation loss: 1.950143539777366

Epoch: 6| Step: 3
Training loss: 1.4192681312561035
Validation loss: 1.9695210226120488

Epoch: 6| Step: 4
Training loss: 1.283751130104065
Validation loss: 1.9788204393079203

Epoch: 6| Step: 5
Training loss: 1.649026870727539
Validation loss: 1.9583961835471533

Epoch: 6| Step: 6
Training loss: 1.969426155090332
Validation loss: 2.004820212241142

Epoch: 6| Step: 7
Training loss: 1.9548839330673218
Validation loss: 2.0819506555475216

Epoch: 6| Step: 8
Training loss: 1.4212719202041626
Validation loss: 2.063174633569615

Epoch: 6| Step: 9
Training loss: 1.9494664669036865
Validation loss: 2.050546015462568

Epoch: 6| Step: 10
Training loss: 1.484034776687622
Validation loss: 1.9991913251979376

Epoch: 6| Step: 11
Training loss: 1.2197651863098145
Validation loss: 1.9706627168963033

Epoch: 6| Step: 12
Training loss: 1.866830587387085
Validation loss: 1.9721550108284078

Epoch: 6| Step: 13
Training loss: 1.3437895774841309
Validation loss: 1.9789974740756455

Epoch: 169| Step: 0
Training loss: 1.54679536819458
Validation loss: 1.9750519760193364

Epoch: 6| Step: 1
Training loss: 1.1414624452590942
Validation loss: 1.9736953473860217

Epoch: 6| Step: 2
Training loss: 1.9634819030761719
Validation loss: 1.963131543128721

Epoch: 6| Step: 3
Training loss: 1.6140656471252441
Validation loss: 1.9651056476818618

Epoch: 6| Step: 4
Training loss: 1.753072738647461
Validation loss: 1.9682083745156564

Epoch: 6| Step: 5
Training loss: 1.4068571329116821
Validation loss: 1.956927680200146

Epoch: 6| Step: 6
Training loss: 1.1515439748764038
Validation loss: 1.9831862475282402

Epoch: 6| Step: 7
Training loss: 1.7126257419586182
Validation loss: 2.049545144522062

Epoch: 6| Step: 8
Training loss: 1.3530550003051758
Validation loss: 2.0511742074002504

Epoch: 6| Step: 9
Training loss: 1.6692339181900024
Validation loss: 2.010315519507213

Epoch: 6| Step: 10
Training loss: 1.3013973236083984
Validation loss: 1.9810526601729854

Epoch: 6| Step: 11
Training loss: 1.3769254684448242
Validation loss: 1.9514094142503635

Epoch: 6| Step: 12
Training loss: 2.101365566253662
Validation loss: 1.9529134047928678

Epoch: 6| Step: 13
Training loss: 2.8452529907226562
Validation loss: 1.9498109509868007

Epoch: 170| Step: 0
Training loss: 1.1608595848083496
Validation loss: 1.95846269207616

Epoch: 6| Step: 1
Training loss: 1.3493989706039429
Validation loss: 1.9836164059177521

Epoch: 6| Step: 2
Training loss: 1.9755597114562988
Validation loss: 1.998988095150199

Epoch: 6| Step: 3
Training loss: 1.193483591079712
Validation loss: 2.0278492050786174

Epoch: 6| Step: 4
Training loss: 1.7301474809646606
Validation loss: 2.0539703317867812

Epoch: 6| Step: 5
Training loss: 1.8330433368682861
Validation loss: 2.071191321137131

Epoch: 6| Step: 6
Training loss: 1.693514347076416
Validation loss: 2.1199654327925814

Epoch: 6| Step: 7
Training loss: 1.9972937107086182
Validation loss: 2.1472042260631437

Epoch: 6| Step: 8
Training loss: 1.225724458694458
Validation loss: 2.13076287956648

Epoch: 6| Step: 9
Training loss: 1.9405879974365234
Validation loss: 2.125132706857497

Epoch: 6| Step: 10
Training loss: 2.1260828971862793
Validation loss: 2.0757990139786915

Epoch: 6| Step: 11
Training loss: 1.3883676528930664
Validation loss: 2.0472970726669475

Epoch: 6| Step: 12
Training loss: 0.8653374314308167
Validation loss: 2.0200809509523454

Epoch: 6| Step: 13
Training loss: 1.6559805870056152
Validation loss: 1.9937614189681185

Epoch: 171| Step: 0
Training loss: 1.2592010498046875
Validation loss: 1.9790721760001233

Epoch: 6| Step: 1
Training loss: 1.658650279045105
Validation loss: 1.969564289175054

Epoch: 6| Step: 2
Training loss: 1.3130466938018799
Validation loss: 1.9666793372041436

Epoch: 6| Step: 3
Training loss: 1.8208431005477905
Validation loss: 1.9416037298017932

Epoch: 6| Step: 4
Training loss: 1.6803760528564453
Validation loss: 1.950454633723023

Epoch: 6| Step: 5
Training loss: 2.093527317047119
Validation loss: 1.9585970845273746

Epoch: 6| Step: 6
Training loss: 1.2055516242980957
Validation loss: 1.9698605486141738

Epoch: 6| Step: 7
Training loss: 1.7748172283172607
Validation loss: 1.9860978869981663

Epoch: 6| Step: 8
Training loss: 1.5879086256027222
Validation loss: 2.0233920210151264

Epoch: 6| Step: 9
Training loss: 1.4157931804656982
Validation loss: 2.0239629053300425

Epoch: 6| Step: 10
Training loss: 1.694864273071289
Validation loss: 2.0370081470858667

Epoch: 6| Step: 11
Training loss: 1.1733663082122803
Validation loss: 2.0423845129628337

Epoch: 6| Step: 12
Training loss: 1.30387282371521
Validation loss: 2.058961222248693

Epoch: 6| Step: 13
Training loss: 1.4976825714111328
Validation loss: 2.0977574215140393

Epoch: 172| Step: 0
Training loss: 1.5339890718460083
Validation loss: 2.1020628534337527

Epoch: 6| Step: 1
Training loss: 2.2549705505371094
Validation loss: 2.1227831353423414

Epoch: 6| Step: 2
Training loss: 2.101199150085449
Validation loss: 2.1531831449077976

Epoch: 6| Step: 3
Training loss: 1.6975748538970947
Validation loss: 2.0837912354418027

Epoch: 6| Step: 4
Training loss: 1.014214277267456
Validation loss: 2.02301751541835

Epoch: 6| Step: 5
Training loss: 1.6688549518585205
Validation loss: 2.001460967525359

Epoch: 6| Step: 6
Training loss: 1.823535680770874
Validation loss: 2.0009440747640466

Epoch: 6| Step: 7
Training loss: 1.6187678575515747
Validation loss: 1.9962807804025628

Epoch: 6| Step: 8
Training loss: 1.5771856307983398
Validation loss: 1.9839331103909401

Epoch: 6| Step: 9
Training loss: 1.899885654449463
Validation loss: 1.9798819788040654

Epoch: 6| Step: 10
Training loss: 1.7143633365631104
Validation loss: 1.9697645095086866

Epoch: 6| Step: 11
Training loss: 0.9993593096733093
Validation loss: 1.9992853992728776

Epoch: 6| Step: 12
Training loss: 1.4335277080535889
Validation loss: 2.008377164922735

Epoch: 6| Step: 13
Training loss: 0.5805922746658325
Validation loss: 1.9954174128911828

Epoch: 173| Step: 0
Training loss: 1.660461187362671
Validation loss: 2.0312655048985637

Epoch: 6| Step: 1
Training loss: 1.3687005043029785
Validation loss: 2.011908333788636

Epoch: 6| Step: 2
Training loss: 1.2772247791290283
Validation loss: 2.0031288182863625

Epoch: 6| Step: 3
Training loss: 1.657127857208252
Validation loss: 2.0043845715061313

Epoch: 6| Step: 4
Training loss: 1.4041695594787598
Validation loss: 2.020872959526636

Epoch: 6| Step: 5
Training loss: 1.645578145980835
Validation loss: 2.0330107071066417

Epoch: 6| Step: 6
Training loss: 1.3929396867752075
Validation loss: 2.0246755640993834

Epoch: 6| Step: 7
Training loss: 1.7665776014328003
Validation loss: 2.0361374129531202

Epoch: 6| Step: 8
Training loss: 1.6859025955200195
Validation loss: 2.044798158830212

Epoch: 6| Step: 9
Training loss: 1.1573026180267334
Validation loss: 2.0698980874912714

Epoch: 6| Step: 10
Training loss: 1.781683325767517
Validation loss: 2.085942163262316

Epoch: 6| Step: 11
Training loss: 1.2740252017974854
Validation loss: 2.0823809998009795

Epoch: 6| Step: 12
Training loss: 1.255651593208313
Validation loss: 2.063800452857889

Epoch: 6| Step: 13
Training loss: 1.1496427059173584
Validation loss: 2.0412280123720885

Epoch: 174| Step: 0
Training loss: 1.7131627798080444
Validation loss: 2.016652758403491

Epoch: 6| Step: 1
Training loss: 1.6248588562011719
Validation loss: 2.002052599383939

Epoch: 6| Step: 2
Training loss: 1.6048152446746826
Validation loss: 1.9878443517992574

Epoch: 6| Step: 3
Training loss: 1.327178955078125
Validation loss: 1.9767552447575394

Epoch: 6| Step: 4
Training loss: 1.5637603998184204
Validation loss: 1.9545294366857058

Epoch: 6| Step: 5
Training loss: 1.484388828277588
Validation loss: 1.9578831529104581

Epoch: 6| Step: 6
Training loss: 1.2932345867156982
Validation loss: 1.9590473162230624

Epoch: 6| Step: 7
Training loss: 1.9560436010360718
Validation loss: 1.9604317501027098

Epoch: 6| Step: 8
Training loss: 1.4867823123931885
Validation loss: 1.9612339811940347

Epoch: 6| Step: 9
Training loss: 1.3449676036834717
Validation loss: 1.9903503746114752

Epoch: 6| Step: 10
Training loss: 1.0278992652893066
Validation loss: 2.0168820632401334

Epoch: 6| Step: 11
Training loss: 1.373748540878296
Validation loss: 2.0658755199883574

Epoch: 6| Step: 12
Training loss: 1.4409013986587524
Validation loss: 2.0386041543817006

Epoch: 6| Step: 13
Training loss: 1.5570670366287231
Validation loss: 2.0582498478633102

Epoch: 175| Step: 0
Training loss: 1.6613483428955078
Validation loss: 2.0205481462581183

Epoch: 6| Step: 1
Training loss: 1.1895337104797363
Validation loss: 1.9934176142497728

Epoch: 6| Step: 2
Training loss: 1.924659013748169
Validation loss: 1.989925317866828

Epoch: 6| Step: 3
Training loss: 1.9290467500686646
Validation loss: 1.9589367387115315

Epoch: 6| Step: 4
Training loss: 1.0544321537017822
Validation loss: 1.984024163215391

Epoch: 6| Step: 5
Training loss: 1.080142855644226
Validation loss: 1.9764950288239347

Epoch: 6| Step: 6
Training loss: 1.386269450187683
Validation loss: 1.9616670095792381

Epoch: 6| Step: 7
Training loss: 1.4369089603424072
Validation loss: 1.9609768224018875

Epoch: 6| Step: 8
Training loss: 1.5682666301727295
Validation loss: 1.966085216050507

Epoch: 6| Step: 9
Training loss: 1.758305549621582
Validation loss: 1.9697664809483353

Epoch: 6| Step: 10
Training loss: 1.645724892616272
Validation loss: 1.9846780441140617

Epoch: 6| Step: 11
Training loss: 1.3273977041244507
Validation loss: 2.0145048044061147

Epoch: 6| Step: 12
Training loss: 1.212429165840149
Validation loss: 2.035229698304207

Epoch: 6| Step: 13
Training loss: 1.7263569831848145
Validation loss: 2.0695581615612073

Epoch: 176| Step: 0
Training loss: 1.2272801399230957
Validation loss: 2.063563521190356

Epoch: 6| Step: 1
Training loss: 1.0656375885009766
Validation loss: 2.088715191810362

Epoch: 6| Step: 2
Training loss: 0.8639819622039795
Validation loss: 2.085939912385838

Epoch: 6| Step: 3
Training loss: 1.5933550596237183
Validation loss: 2.0696204529013684

Epoch: 6| Step: 4
Training loss: 1.183607578277588
Validation loss: 2.017185495745751

Epoch: 6| Step: 5
Training loss: 1.8408410549163818
Validation loss: 2.006239793633902

Epoch: 6| Step: 6
Training loss: 2.0236656665802
Validation loss: 2.0106270056898876

Epoch: 6| Step: 7
Training loss: 1.4696266651153564
Validation loss: 2.0181532290674027

Epoch: 6| Step: 8
Training loss: 1.597238302230835
Validation loss: 2.00671644877362

Epoch: 6| Step: 9
Training loss: 0.834476888179779
Validation loss: 2.007031370234746

Epoch: 6| Step: 10
Training loss: 2.0100653171539307
Validation loss: 2.0094060487644647

Epoch: 6| Step: 11
Training loss: 1.3536052703857422
Validation loss: 2.0214350531178136

Epoch: 6| Step: 12
Training loss: 2.055706024169922
Validation loss: 2.031240213301874

Epoch: 6| Step: 13
Training loss: 1.2974821329116821
Validation loss: 2.0342047009416806

Epoch: 177| Step: 0
Training loss: 1.402944803237915
Validation loss: 1.99165722375275

Epoch: 6| Step: 1
Training loss: 1.7344255447387695
Validation loss: 1.9868584909746725

Epoch: 6| Step: 2
Training loss: 0.9320721626281738
Validation loss: 1.9710708484854749

Epoch: 6| Step: 3
Training loss: 1.5119178295135498
Validation loss: 1.9698010324150004

Epoch: 6| Step: 4
Training loss: 1.5212090015411377
Validation loss: 1.9527734735960602

Epoch: 6| Step: 5
Training loss: 1.2692149877548218
Validation loss: 1.948623457262593

Epoch: 6| Step: 6
Training loss: 1.4909205436706543
Validation loss: 1.9522127336071384

Epoch: 6| Step: 7
Training loss: 1.313035249710083
Validation loss: 1.968802131632323

Epoch: 6| Step: 8
Training loss: 1.2976083755493164
Validation loss: 1.977201509219344

Epoch: 6| Step: 9
Training loss: 1.8470499515533447
Validation loss: 1.992251742270685

Epoch: 6| Step: 10
Training loss: 1.1771812438964844
Validation loss: 1.9469640049883115

Epoch: 6| Step: 11
Training loss: 1.8655192852020264
Validation loss: 1.9427950330959853

Epoch: 6| Step: 12
Training loss: 1.1969761848449707
Validation loss: 1.93934420616396

Epoch: 6| Step: 13
Training loss: 2.3934476375579834
Validation loss: 1.9624442285107029

Epoch: 178| Step: 0
Training loss: 1.5521684885025024
Validation loss: 1.9875952133568384

Epoch: 6| Step: 1
Training loss: 1.166011095046997
Validation loss: 2.0246217955825148

Epoch: 6| Step: 2
Training loss: 1.0350825786590576
Validation loss: 2.0331122695758777

Epoch: 6| Step: 3
Training loss: 2.0678536891937256
Validation loss: 2.0472286426892845

Epoch: 6| Step: 4
Training loss: 1.2263193130493164
Validation loss: 2.049013066035445

Epoch: 6| Step: 5
Training loss: 1.4038091897964478
Validation loss: 2.042502713459794

Epoch: 6| Step: 6
Training loss: 1.0599229335784912
Validation loss: 2.0913747946421304

Epoch: 6| Step: 7
Training loss: 1.477473258972168
Validation loss: 2.0855410650212276

Epoch: 6| Step: 8
Training loss: 1.3107799291610718
Validation loss: 2.0864145601949384

Epoch: 6| Step: 9
Training loss: 2.1382498741149902
Validation loss: 2.0483422997177287

Epoch: 6| Step: 10
Training loss: 1.41600501537323
Validation loss: 2.0210008480215587

Epoch: 6| Step: 11
Training loss: 1.3382824659347534
Validation loss: 2.0183973004741054

Epoch: 6| Step: 12
Training loss: 1.7249557971954346
Validation loss: 2.031313629560573

Epoch: 6| Step: 13
Training loss: 0.9894108176231384
Validation loss: 2.0024000188355804

Epoch: 179| Step: 0
Training loss: 1.4642198085784912
Validation loss: 2.0067443309291715

Epoch: 6| Step: 1
Training loss: 1.3470473289489746
Validation loss: 1.962732913673565

Epoch: 6| Step: 2
Training loss: 1.646214246749878
Validation loss: 1.9401101284129645

Epoch: 6| Step: 3
Training loss: 1.2210469245910645
Validation loss: 1.9320566679841729

Epoch: 6| Step: 4
Training loss: 1.7357604503631592
Validation loss: 1.9400743656260993

Epoch: 6| Step: 5
Training loss: 1.729032039642334
Validation loss: 1.9384084132409864

Epoch: 6| Step: 6
Training loss: 1.6337237358093262
Validation loss: 1.9298934859614219

Epoch: 6| Step: 7
Training loss: 1.4023743867874146
Validation loss: 1.9322341244707826

Epoch: 6| Step: 8
Training loss: 1.309276819229126
Validation loss: 1.9624096796076784

Epoch: 6| Step: 9
Training loss: 1.0850399732589722
Validation loss: 1.9766740670768164

Epoch: 6| Step: 10
Training loss: 1.2725975513458252
Validation loss: 2.001663755345088

Epoch: 6| Step: 11
Training loss: 1.1226544380187988
Validation loss: 2.017238873307423

Epoch: 6| Step: 12
Training loss: 1.855407953262329
Validation loss: 2.05252158000905

Epoch: 6| Step: 13
Training loss: 0.8343093991279602
Validation loss: 2.0699349628981722

Epoch: 180| Step: 0
Training loss: 0.6788949370384216
Validation loss: 2.088128505214568

Epoch: 6| Step: 1
Training loss: 2.004531145095825
Validation loss: 2.0803394881627892

Epoch: 6| Step: 2
Training loss: 0.9503138065338135
Validation loss: 2.0564995619558517

Epoch: 6| Step: 3
Training loss: 1.27897310256958
Validation loss: 2.029014928366548

Epoch: 6| Step: 4
Training loss: 1.3821114301681519
Validation loss: 1.9897321731813493

Epoch: 6| Step: 5
Training loss: 1.8595250844955444
Validation loss: 1.9664558595226658

Epoch: 6| Step: 6
Training loss: 1.7926501035690308
Validation loss: 1.9437014274699713

Epoch: 6| Step: 7
Training loss: 1.2376012802124023
Validation loss: 1.9139244094971688

Epoch: 6| Step: 8
Training loss: 1.6968063116073608
Validation loss: 1.9175606427654144

Epoch: 6| Step: 9
Training loss: 1.4696100950241089
Validation loss: 1.9056517078030495

Epoch: 6| Step: 10
Training loss: 1.7187244892120361
Validation loss: 1.911866803323069

Epoch: 6| Step: 11
Training loss: 2.044451951980591
Validation loss: 1.9564791084617696

Epoch: 6| Step: 12
Training loss: 1.261303186416626
Validation loss: 1.9614515778838948

Epoch: 6| Step: 13
Training loss: 1.0773968696594238
Validation loss: 1.9816664777776247

Epoch: 181| Step: 0
Training loss: 1.5699909925460815
Validation loss: 1.9975228694177443

Epoch: 6| Step: 1
Training loss: 1.1884461641311646
Validation loss: 1.971378017497319

Epoch: 6| Step: 2
Training loss: 1.3341968059539795
Validation loss: 1.9548880066922916

Epoch: 6| Step: 3
Training loss: 1.3242336511611938
Validation loss: 1.9524211614362654

Epoch: 6| Step: 4
Training loss: 1.6009212732315063
Validation loss: 1.9838626987190657

Epoch: 6| Step: 5
Training loss: 1.6246174573898315
Validation loss: 1.9849430873829832

Epoch: 6| Step: 6
Training loss: 1.0307316780090332
Validation loss: 2.0059015289429696

Epoch: 6| Step: 7
Training loss: 1.996293067932129
Validation loss: 2.029907459853798

Epoch: 6| Step: 8
Training loss: 1.6692811250686646
Validation loss: 2.044913327822121

Epoch: 6| Step: 9
Training loss: 1.5256762504577637
Validation loss: 2.0264450337297175

Epoch: 6| Step: 10
Training loss: 1.2801036834716797
Validation loss: 2.0259308097183064

Epoch: 6| Step: 11
Training loss: 1.4993057250976562
Validation loss: 2.0476812829253492

Epoch: 6| Step: 12
Training loss: 0.8414006233215332
Validation loss: 2.066964554530318

Epoch: 6| Step: 13
Training loss: 1.2272570133209229
Validation loss: 2.043135926287661

Epoch: 182| Step: 0
Training loss: 1.5062758922576904
Validation loss: 2.0743167118359636

Epoch: 6| Step: 1
Training loss: 1.2536234855651855
Validation loss: 2.0740415037319226

Epoch: 6| Step: 2
Training loss: 1.6596992015838623
Validation loss: 2.0605528444372196

Epoch: 6| Step: 3
Training loss: 0.9612869620323181
Validation loss: 2.0380717682582077

Epoch: 6| Step: 4
Training loss: 1.9634017944335938
Validation loss: 2.033558914738317

Epoch: 6| Step: 5
Training loss: 1.3455851078033447
Validation loss: 2.0262251182269027

Epoch: 6| Step: 6
Training loss: 1.549280047416687
Validation loss: 2.0265536218561153

Epoch: 6| Step: 7
Training loss: 2.3590002059936523
Validation loss: 2.0379068184924383

Epoch: 6| Step: 8
Training loss: 0.9384225606918335
Validation loss: 2.0223300341636903

Epoch: 6| Step: 9
Training loss: 1.7325042486190796
Validation loss: 2.0191837395391157

Epoch: 6| Step: 10
Training loss: 1.206857442855835
Validation loss: 1.9914826654618787

Epoch: 6| Step: 11
Training loss: 1.0718681812286377
Validation loss: 1.995188372109526

Epoch: 6| Step: 12
Training loss: 1.0563781261444092
Validation loss: 1.9645839891126078

Epoch: 6| Step: 13
Training loss: 2.1363039016723633
Validation loss: 1.9325424240481468

Epoch: 183| Step: 0
Training loss: 1.5210140943527222
Validation loss: 1.9473809606285506

Epoch: 6| Step: 1
Training loss: 1.5138529539108276
Validation loss: 1.9350674549738567

Epoch: 6| Step: 2
Training loss: 1.1831722259521484
Validation loss: 1.9742108403995473

Epoch: 6| Step: 3
Training loss: 2.1632046699523926
Validation loss: 1.9720697044044413

Epoch: 6| Step: 4
Training loss: 1.1240942478179932
Validation loss: 2.007922198182793

Epoch: 6| Step: 5
Training loss: 1.0848361253738403
Validation loss: 2.012759648343568

Epoch: 6| Step: 6
Training loss: 1.336125373840332
Validation loss: 2.070800224939982

Epoch: 6| Step: 7
Training loss: 1.6011791229248047
Validation loss: 2.0801223683100876

Epoch: 6| Step: 8
Training loss: 1.9371342658996582
Validation loss: 2.1271217587173625

Epoch: 6| Step: 9
Training loss: 1.973240852355957
Validation loss: 2.1370086311012186

Epoch: 6| Step: 10
Training loss: 0.9866523742675781
Validation loss: 2.077825387318929

Epoch: 6| Step: 11
Training loss: 0.8647741079330444
Validation loss: 2.072667206487348

Epoch: 6| Step: 12
Training loss: 1.2771975994110107
Validation loss: 2.015389085456889

Epoch: 6| Step: 13
Training loss: 1.0108472108840942
Validation loss: 1.9790122816639562

Epoch: 184| Step: 0
Training loss: 0.9298840761184692
Validation loss: 1.9791155835633636

Epoch: 6| Step: 1
Training loss: 1.468157172203064
Validation loss: 1.9670496858576292

Epoch: 6| Step: 2
Training loss: 0.879179835319519
Validation loss: 1.9659824589247346

Epoch: 6| Step: 3
Training loss: 1.4993958473205566
Validation loss: 2.0061158364818943

Epoch: 6| Step: 4
Training loss: 2.321228265762329
Validation loss: 2.026041953794418

Epoch: 6| Step: 5
Training loss: 1.76022207736969
Validation loss: 2.019274914136497

Epoch: 6| Step: 6
Training loss: 1.0119976997375488
Validation loss: 2.000416309602799

Epoch: 6| Step: 7
Training loss: 1.7236124277114868
Validation loss: 1.9754651874624274

Epoch: 6| Step: 8
Training loss: 1.193539023399353
Validation loss: 1.9768977447222638

Epoch: 6| Step: 9
Training loss: 1.684662103652954
Validation loss: 2.0184249865111483

Epoch: 6| Step: 10
Training loss: 1.0402028560638428
Validation loss: 2.0300203113145727

Epoch: 6| Step: 11
Training loss: 1.143057107925415
Validation loss: 2.0556016468232676

Epoch: 6| Step: 12
Training loss: 2.016423225402832
Validation loss: 2.077971271289292

Epoch: 6| Step: 13
Training loss: 1.6933945417404175
Validation loss: 2.100478410720825

Epoch: 185| Step: 0
Training loss: 1.1456223726272583
Validation loss: 2.087989954538243

Epoch: 6| Step: 1
Training loss: 1.2700934410095215
Validation loss: 2.078520805604996

Epoch: 6| Step: 2
Training loss: 1.3138097524642944
Validation loss: 2.0446053217816096

Epoch: 6| Step: 3
Training loss: 1.1007251739501953
Validation loss: 2.0100695317791355

Epoch: 6| Step: 4
Training loss: 1.2092761993408203
Validation loss: 1.9759670329350296

Epoch: 6| Step: 5
Training loss: 1.2580010890960693
Validation loss: 1.9432716241446875

Epoch: 6| Step: 6
Training loss: 1.7348380088806152
Validation loss: 1.9212947173785138

Epoch: 6| Step: 7
Training loss: 1.839355230331421
Validation loss: 1.9355884277692406

Epoch: 6| Step: 8
Training loss: 2.3518245220184326
Validation loss: 1.9542606030741045

Epoch: 6| Step: 9
Training loss: 1.0145587921142578
Validation loss: 1.9516463407906153

Epoch: 6| Step: 10
Training loss: 1.850395917892456
Validation loss: 1.962083799864656

Epoch: 6| Step: 11
Training loss: 1.423120141029358
Validation loss: 1.9783422408565399

Epoch: 6| Step: 12
Training loss: 1.7999392747879028
Validation loss: 1.9846265085281865

Epoch: 6| Step: 13
Training loss: 1.6335148811340332
Validation loss: 2.017265876134237

Epoch: 186| Step: 0
Training loss: 1.8837512731552124
Validation loss: 2.0020133064639185

Epoch: 6| Step: 1
Training loss: 1.5056109428405762
Validation loss: 2.01662774496181

Epoch: 6| Step: 2
Training loss: 1.099514126777649
Validation loss: 2.025623502269868

Epoch: 6| Step: 3
Training loss: 1.3315006494522095
Validation loss: 2.036016574469946

Epoch: 6| Step: 4
Training loss: 1.9347798824310303
Validation loss: 2.097486521608086

Epoch: 6| Step: 5
Training loss: 1.3771164417266846
Validation loss: 2.1568817489890644

Epoch: 6| Step: 6
Training loss: 1.4397623538970947
Validation loss: 2.1300356003545944

Epoch: 6| Step: 7
Training loss: 1.4637231826782227
Validation loss: 2.0582630685580674

Epoch: 6| Step: 8
Training loss: 1.1714892387390137
Validation loss: 1.9935824845426826

Epoch: 6| Step: 9
Training loss: 1.2042611837387085
Validation loss: 1.9794667100393644

Epoch: 6| Step: 10
Training loss: 1.2446776628494263
Validation loss: 1.9828866348471692

Epoch: 6| Step: 11
Training loss: 1.2079569101333618
Validation loss: 1.9608382307073122

Epoch: 6| Step: 12
Training loss: 1.6211328506469727
Validation loss: 1.9597761349011493

Epoch: 6| Step: 13
Training loss: 1.9194951057434082
Validation loss: 1.9761732355240853

Epoch: 187| Step: 0
Training loss: 1.835620641708374
Validation loss: 1.9693086403672413

Epoch: 6| Step: 1
Training loss: 1.0468740463256836
Validation loss: 1.965536686681932

Epoch: 6| Step: 2
Training loss: 0.7442857027053833
Validation loss: 1.9870195029884257

Epoch: 6| Step: 3
Training loss: 1.3478190898895264
Validation loss: 2.00348856372218

Epoch: 6| Step: 4
Training loss: 0.9239765405654907
Validation loss: 1.9917362710481048

Epoch: 6| Step: 5
Training loss: 2.0558371543884277
Validation loss: 1.9845843533033967

Epoch: 6| Step: 6
Training loss: 1.1163737773895264
Validation loss: 1.9842977369985273

Epoch: 6| Step: 7
Training loss: 0.9275230169296265
Validation loss: 1.9497541740376463

Epoch: 6| Step: 8
Training loss: 2.068632125854492
Validation loss: 1.973089692413166

Epoch: 6| Step: 9
Training loss: 1.3341020345687866
Validation loss: 1.9920896791642713

Epoch: 6| Step: 10
Training loss: 1.8103342056274414
Validation loss: 2.0072460815470707

Epoch: 6| Step: 11
Training loss: 1.4265351295471191
Validation loss: 2.0136948080473047

Epoch: 6| Step: 12
Training loss: 1.474554419517517
Validation loss: 2.007337060025943

Epoch: 6| Step: 13
Training loss: 1.794404149055481
Validation loss: 2.014474925174508

Epoch: 188| Step: 0
Training loss: 1.119460105895996
Validation loss: 2.0493091306378766

Epoch: 6| Step: 1
Training loss: 2.335252285003662
Validation loss: 2.0710333880557807

Epoch: 6| Step: 2
Training loss: 1.5530617237091064
Validation loss: 2.063252933563725

Epoch: 6| Step: 3
Training loss: 0.955538809299469
Validation loss: 2.0499345371800084

Epoch: 6| Step: 4
Training loss: 1.5476300716400146
Validation loss: 2.028703607538695

Epoch: 6| Step: 5
Training loss: 0.8801814317703247
Validation loss: 2.033012068399819

Epoch: 6| Step: 6
Training loss: 1.1937367916107178
Validation loss: 2.019617211434149

Epoch: 6| Step: 7
Training loss: 1.526719331741333
Validation loss: 1.9611191954664005

Epoch: 6| Step: 8
Training loss: 0.8161182999610901
Validation loss: 1.9627779491486088

Epoch: 6| Step: 9
Training loss: 1.4891724586486816
Validation loss: 1.9740855104179793

Epoch: 6| Step: 10
Training loss: 0.971612811088562
Validation loss: 1.9926076832637991

Epoch: 6| Step: 11
Training loss: 1.2117092609405518
Validation loss: 1.9755914544546476

Epoch: 6| Step: 12
Training loss: 1.5332019329071045
Validation loss: 1.9912922792537238

Epoch: 6| Step: 13
Training loss: 1.8954176902770996
Validation loss: 1.9828965920273975

Epoch: 189| Step: 0
Training loss: 0.9509713053703308
Validation loss: 1.97079130911058

Epoch: 6| Step: 1
Training loss: 1.1556402444839478
Validation loss: 1.9665402494451052

Epoch: 6| Step: 2
Training loss: 1.6875323057174683
Validation loss: 1.9773458703871696

Epoch: 6| Step: 3
Training loss: 1.0731806755065918
Validation loss: 1.9869896468295847

Epoch: 6| Step: 4
Training loss: 1.4236781597137451
Validation loss: 1.9915654748998664

Epoch: 6| Step: 5
Training loss: 1.612978219985962
Validation loss: 2.0294642653516544

Epoch: 6| Step: 6
Training loss: 1.3640533685684204
Validation loss: 1.976210060939994

Epoch: 6| Step: 7
Training loss: 1.8248578310012817
Validation loss: 1.9574122403257637

Epoch: 6| Step: 8
Training loss: 1.5485656261444092
Validation loss: 1.9654464157678748

Epoch: 6| Step: 9
Training loss: 1.1731178760528564
Validation loss: 1.954357208744172

Epoch: 6| Step: 10
Training loss: 1.593780517578125
Validation loss: 1.9537709143853956

Epoch: 6| Step: 11
Training loss: 1.0969115495681763
Validation loss: 1.9661135968341623

Epoch: 6| Step: 12
Training loss: 1.311983585357666
Validation loss: 1.9549160824027112

Epoch: 6| Step: 13
Training loss: 0.8855551481246948
Validation loss: 1.9652388339401574

Epoch: 190| Step: 0
Training loss: 1.136552333831787
Validation loss: 1.9992953474803636

Epoch: 6| Step: 1
Training loss: 1.177691102027893
Validation loss: 1.976079669049991

Epoch: 6| Step: 2
Training loss: 1.3610979318618774
Validation loss: 1.9784886631914365

Epoch: 6| Step: 3
Training loss: 1.0609495639801025
Validation loss: 1.9797875471012567

Epoch: 6| Step: 4
Training loss: 1.247314453125
Validation loss: 1.9837925972477082

Epoch: 6| Step: 5
Training loss: 1.0089832544326782
Validation loss: 1.9856334911879672

Epoch: 6| Step: 6
Training loss: 1.5351827144622803
Validation loss: 1.9870104597460838

Epoch: 6| Step: 7
Training loss: 1.847034215927124
Validation loss: 1.9940524152530137

Epoch: 6| Step: 8
Training loss: 1.7054758071899414
Validation loss: 2.0225214663372246

Epoch: 6| Step: 9
Training loss: 1.7188193798065186
Validation loss: 1.9924634643780288

Epoch: 6| Step: 10
Training loss: 0.8311600685119629
Validation loss: 2.006896493255451

Epoch: 6| Step: 11
Training loss: 1.531474232673645
Validation loss: 2.019939717426095

Epoch: 6| Step: 12
Training loss: 1.1240246295928955
Validation loss: 2.0208206868940786

Epoch: 6| Step: 13
Training loss: 1.1373786926269531
Validation loss: 2.0377935517218804

Epoch: 191| Step: 0
Training loss: 0.9014726877212524
Validation loss: 2.0217803985841813

Epoch: 6| Step: 1
Training loss: 1.442853331565857
Validation loss: 2.1068205705253025

Epoch: 6| Step: 2
Training loss: 1.568295955657959
Validation loss: 2.147842421326586

Epoch: 6| Step: 3
Training loss: 1.3395206928253174
Validation loss: 2.104842271856082

Epoch: 6| Step: 4
Training loss: 1.4280542135238647
Validation loss: 2.0646607081095376

Epoch: 6| Step: 5
Training loss: 1.5186257362365723
Validation loss: 1.959353159832698

Epoch: 6| Step: 6
Training loss: 1.2497460842132568
Validation loss: 1.9457369055799258

Epoch: 6| Step: 7
Training loss: 1.850684642791748
Validation loss: 1.9496257382054483

Epoch: 6| Step: 8
Training loss: 1.2725073099136353
Validation loss: 1.9465618825727893

Epoch: 6| Step: 9
Training loss: 1.4003844261169434
Validation loss: 1.9557100483166274

Epoch: 6| Step: 10
Training loss: 1.7994377613067627
Validation loss: 1.9652213191473356

Epoch: 6| Step: 11
Training loss: 1.104597568511963
Validation loss: 1.9247543568252234

Epoch: 6| Step: 12
Training loss: 1.4177672863006592
Validation loss: 1.946354450718049

Epoch: 6| Step: 13
Training loss: 1.1815065145492554
Validation loss: 1.9914379427509923

Epoch: 192| Step: 0
Training loss: 1.3566088676452637
Validation loss: 2.014292960525841

Epoch: 6| Step: 1
Training loss: 1.609142780303955
Validation loss: 2.054111382012726

Epoch: 6| Step: 2
Training loss: 1.25184965133667
Validation loss: 2.112028855149464

Epoch: 6| Step: 3
Training loss: 1.6967825889587402
Validation loss: 2.1456337564735004

Epoch: 6| Step: 4
Training loss: 1.2366247177124023
Validation loss: 2.1435661649191253

Epoch: 6| Step: 5
Training loss: 1.8764269351959229
Validation loss: 2.1254305121719197

Epoch: 6| Step: 6
Training loss: 1.5844682455062866
Validation loss: 2.1404779239367415

Epoch: 6| Step: 7
Training loss: 1.9790576696395874
Validation loss: 2.106612677215248

Epoch: 6| Step: 8
Training loss: 0.8695515394210815
Validation loss: 2.094220656220631

Epoch: 6| Step: 9
Training loss: 1.0229905843734741
Validation loss: 2.040125427707549

Epoch: 6| Step: 10
Training loss: 1.7391432523727417
Validation loss: 2.002161607947401

Epoch: 6| Step: 11
Training loss: 1.4518928527832031
Validation loss: 1.9680920647036644

Epoch: 6| Step: 12
Training loss: 0.9528664946556091
Validation loss: 1.9358108300034718

Epoch: 6| Step: 13
Training loss: 1.1238176822662354
Validation loss: 1.9549606077132686

Epoch: 193| Step: 0
Training loss: 1.1188273429870605
Validation loss: 2.0073304740331506

Epoch: 6| Step: 1
Training loss: 1.1169908046722412
Validation loss: 2.0203124810290594

Epoch: 6| Step: 2
Training loss: 1.7929887771606445
Validation loss: 2.022960611568984

Epoch: 6| Step: 3
Training loss: 1.3681808710098267
Validation loss: 2.02004829529793

Epoch: 6| Step: 4
Training loss: 0.7272865772247314
Validation loss: 2.066734557510704

Epoch: 6| Step: 5
Training loss: 1.9194730520248413
Validation loss: 2.0575975666763964

Epoch: 6| Step: 6
Training loss: 0.7936739921569824
Validation loss: 2.0158663757385744

Epoch: 6| Step: 7
Training loss: 1.4776078462600708
Validation loss: 1.987208358703121

Epoch: 6| Step: 8
Training loss: 1.6945277452468872
Validation loss: 1.9820439918066866

Epoch: 6| Step: 9
Training loss: 1.1875851154327393
Validation loss: 1.9942332954816921

Epoch: 6| Step: 10
Training loss: 1.381624698638916
Validation loss: 2.0109345015659126

Epoch: 6| Step: 11
Training loss: 1.1603471040725708
Validation loss: 1.9961493143471338

Epoch: 6| Step: 12
Training loss: 1.5980429649353027
Validation loss: 1.9981962365488852

Epoch: 6| Step: 13
Training loss: 1.02592933177948
Validation loss: 1.9866578040584442

Epoch: 194| Step: 0
Training loss: 1.1425752639770508
Validation loss: 1.9783834718888806

Epoch: 6| Step: 1
Training loss: 1.5386303663253784
Validation loss: 2.028516184899115

Epoch: 6| Step: 2
Training loss: 2.1385650634765625
Validation loss: 2.0911731412333827

Epoch: 6| Step: 3
Training loss: 1.6052533388137817
Validation loss: 2.0866504228243263

Epoch: 6| Step: 4
Training loss: 1.5213654041290283
Validation loss: 2.061733466322704

Epoch: 6| Step: 5
Training loss: 0.9215744733810425
Validation loss: 2.0129170417785645

Epoch: 6| Step: 6
Training loss: 1.1959872245788574
Validation loss: 1.9617119514813988

Epoch: 6| Step: 7
Training loss: 1.458648443222046
Validation loss: 1.9526705870064356

Epoch: 6| Step: 8
Training loss: 1.1709072589874268
Validation loss: 1.9401977241680186

Epoch: 6| Step: 9
Training loss: 1.3589342832565308
Validation loss: 1.9682949614781204

Epoch: 6| Step: 10
Training loss: 1.4293208122253418
Validation loss: 1.9940338647493752

Epoch: 6| Step: 11
Training loss: 1.1322306394577026
Validation loss: 1.9965814287944506

Epoch: 6| Step: 12
Training loss: 1.1096599102020264
Validation loss: 1.9856221214417489

Epoch: 6| Step: 13
Training loss: 0.7738219499588013
Validation loss: 2.022715840288388

Epoch: 195| Step: 0
Training loss: 0.59745854139328
Validation loss: 2.0309868166523595

Epoch: 6| Step: 1
Training loss: 1.087782859802246
Validation loss: 2.0243399143218994

Epoch: 6| Step: 2
Training loss: 1.5927248001098633
Validation loss: 1.9864258125264158

Epoch: 6| Step: 3
Training loss: 0.9323967695236206
Validation loss: 1.9679499223668089

Epoch: 6| Step: 4
Training loss: 1.039759635925293
Validation loss: 1.9374376753325104

Epoch: 6| Step: 5
Training loss: 1.6240644454956055
Validation loss: 1.9321282268852316

Epoch: 6| Step: 6
Training loss: 1.0480889081954956
Validation loss: 1.9171047890058128

Epoch: 6| Step: 7
Training loss: 1.0991764068603516
Validation loss: 1.9429814918066866

Epoch: 6| Step: 8
Training loss: 1.284467101097107
Validation loss: 1.9255288390703098

Epoch: 6| Step: 9
Training loss: 1.8563497066497803
Validation loss: 1.9265230612088275

Epoch: 6| Step: 10
Training loss: 1.9633415937423706
Validation loss: 1.948025009965384

Epoch: 6| Step: 11
Training loss: 1.2139116525650024
Validation loss: 1.970088884394656

Epoch: 6| Step: 12
Training loss: 1.3226170539855957
Validation loss: 1.9833665355559318

Epoch: 6| Step: 13
Training loss: 1.1217790842056274
Validation loss: 2.008443145341771

Epoch: 196| Step: 0
Training loss: 1.3398241996765137
Validation loss: 2.0433119009899836

Epoch: 6| Step: 1
Training loss: 0.589842677116394
Validation loss: 2.064592512704993

Epoch: 6| Step: 2
Training loss: 0.46180593967437744
Validation loss: 2.0557950312091458

Epoch: 6| Step: 3
Training loss: 1.2920337915420532
Validation loss: 2.060839012104978

Epoch: 6| Step: 4
Training loss: 1.5274863243103027
Validation loss: 1.991567998804072

Epoch: 6| Step: 5
Training loss: 1.0626754760742188
Validation loss: 1.9459258535856843

Epoch: 6| Step: 6
Training loss: 1.4881855249404907
Validation loss: 1.9313144632565078

Epoch: 6| Step: 7
Training loss: 1.264220952987671
Validation loss: 1.9152328045137468

Epoch: 6| Step: 8
Training loss: 1.7132755517959595
Validation loss: 1.899797090920069

Epoch: 6| Step: 9
Training loss: 1.1375532150268555
Validation loss: 1.9186926054698166

Epoch: 6| Step: 10
Training loss: 1.3656152486801147
Validation loss: 1.9139965157355032

Epoch: 6| Step: 11
Training loss: 1.2941986322402954
Validation loss: 1.9231960850377237

Epoch: 6| Step: 12
Training loss: 1.3863880634307861
Validation loss: 1.9736700404074885

Epoch: 6| Step: 13
Training loss: 2.4271485805511475
Validation loss: 2.063003102938334

Epoch: 197| Step: 0
Training loss: 1.0871787071228027
Validation loss: 2.0820276019393757

Epoch: 6| Step: 1
Training loss: 1.511673927307129
Validation loss: 2.118712948214623

Epoch: 6| Step: 2
Training loss: 1.7131891250610352
Validation loss: 2.0987291669332855

Epoch: 6| Step: 3
Training loss: 1.2726503610610962
Validation loss: 2.0361727591483825

Epoch: 6| Step: 4
Training loss: 1.139103889465332
Validation loss: 1.9530091670251661

Epoch: 6| Step: 5
Training loss: 0.9422174692153931
Validation loss: 1.9278492261004705

Epoch: 6| Step: 6
Training loss: 1.4204511642456055
Validation loss: 1.9289474666759532

Epoch: 6| Step: 7
Training loss: 1.9592556953430176
Validation loss: 1.9447669175363356

Epoch: 6| Step: 8
Training loss: 1.3857545852661133
Validation loss: 1.9320400978929253

Epoch: 6| Step: 9
Training loss: 1.0183500051498413
Validation loss: 1.9352973058659544

Epoch: 6| Step: 10
Training loss: 0.8675071001052856
Validation loss: 1.9414618912563528

Epoch: 6| Step: 11
Training loss: 0.9176561832427979
Validation loss: 1.9423269302614274

Epoch: 6| Step: 12
Training loss: 1.5559921264648438
Validation loss: 1.9828149464822584

Epoch: 6| Step: 13
Training loss: 1.263772964477539
Validation loss: 1.9998278925495763

Epoch: 198| Step: 0
Training loss: 1.6082537174224854
Validation loss: 2.075726068148049

Epoch: 6| Step: 1
Training loss: 1.1548175811767578
Validation loss: 2.071795748126122

Epoch: 6| Step: 2
Training loss: 1.9187853336334229
Validation loss: 2.094036199713266

Epoch: 6| Step: 3
Training loss: 0.7648380994796753
Validation loss: 2.056356786399759

Epoch: 6| Step: 4
Training loss: 1.2515769004821777
Validation loss: 2.0098248630441646

Epoch: 6| Step: 5
Training loss: 1.2024857997894287
Validation loss: 1.9802468643393567

Epoch: 6| Step: 6
Training loss: 1.8502384424209595
Validation loss: 1.990566474135204

Epoch: 6| Step: 7
Training loss: 1.0810441970825195
Validation loss: 1.9752979073473202

Epoch: 6| Step: 8
Training loss: 1.0776536464691162
Validation loss: 1.9738529805214173

Epoch: 6| Step: 9
Training loss: 1.3451043367385864
Validation loss: 1.960230633776675

Epoch: 6| Step: 10
Training loss: 1.4739543199539185
Validation loss: 1.9580045271945257

Epoch: 6| Step: 11
Training loss: 0.7611169219017029
Validation loss: 1.9786591760573848

Epoch: 6| Step: 12
Training loss: 1.178672432899475
Validation loss: 2.029618437572192

Epoch: 6| Step: 13
Training loss: 1.472044825553894
Validation loss: 2.0931786285933627

Epoch: 199| Step: 0
Training loss: 1.2024726867675781
Validation loss: 2.092868617785874

Epoch: 6| Step: 1
Training loss: 0.6826746463775635
Validation loss: 2.042977730433146

Epoch: 6| Step: 2
Training loss: 1.3667628765106201
Validation loss: 1.9993928017154816

Epoch: 6| Step: 3
Training loss: 1.2565193176269531
Validation loss: 1.9438184038285287

Epoch: 6| Step: 4
Training loss: 1.504807710647583
Validation loss: 1.9392257403301936

Epoch: 6| Step: 5
Training loss: 1.0503199100494385
Validation loss: 1.9570231347955682

Epoch: 6| Step: 6
Training loss: 1.2140684127807617
Validation loss: 1.961591766726586

Epoch: 6| Step: 7
Training loss: 0.6196169853210449
Validation loss: 1.9759219282416887

Epoch: 6| Step: 8
Training loss: 1.231518268585205
Validation loss: 1.9807670270242999

Epoch: 6| Step: 9
Training loss: 1.2154291868209839
Validation loss: 1.9953569417358727

Epoch: 6| Step: 10
Training loss: 1.610403299331665
Validation loss: 2.014634745095366

Epoch: 6| Step: 11
Training loss: 1.0831704139709473
Validation loss: 1.9805126497822423

Epoch: 6| Step: 12
Training loss: 1.5661847591400146
Validation loss: 2.0013410173436648

Epoch: 6| Step: 13
Training loss: 2.2590603828430176
Validation loss: 1.9998260787738267

Epoch: 200| Step: 0
Training loss: 1.344477891921997
Validation loss: 1.962839359878212

Epoch: 6| Step: 1
Training loss: 0.6669327020645142
Validation loss: 1.9523236431101316

Epoch: 6| Step: 2
Training loss: 1.8404335975646973
Validation loss: 1.9264071961884857

Epoch: 6| Step: 3
Training loss: 1.5061918497085571
Validation loss: 1.930989364142059

Epoch: 6| Step: 4
Training loss: 1.0126103162765503
Validation loss: 1.9217342304927048

Epoch: 6| Step: 5
Training loss: 1.1134529113769531
Validation loss: 1.9328764305319837

Epoch: 6| Step: 6
Training loss: 1.2691888809204102
Validation loss: 1.9211566089301981

Epoch: 6| Step: 7
Training loss: 1.2137532234191895
Validation loss: 1.9453563433821484

Epoch: 6| Step: 8
Training loss: 1.6246291399002075
Validation loss: 1.9449288101606472

Epoch: 6| Step: 9
Training loss: 0.6865636110305786
Validation loss: 1.9679113549570884

Epoch: 6| Step: 10
Training loss: 1.24806547164917
Validation loss: 1.9979469622335126

Epoch: 6| Step: 11
Training loss: 0.6441617608070374
Validation loss: 2.043404882954013

Epoch: 6| Step: 12
Training loss: 1.4866447448730469
Validation loss: 2.059111246498682

Epoch: 6| Step: 13
Training loss: 1.215774655342102
Validation loss: 2.064758631490892

Epoch: 201| Step: 0
Training loss: 1.5397002696990967
Validation loss: 2.1107830334735174

Epoch: 6| Step: 1
Training loss: 0.7977819442749023
Validation loss: 2.095270949025308

Epoch: 6| Step: 2
Training loss: 1.3032305240631104
Validation loss: 2.093291558245177

Epoch: 6| Step: 3
Training loss: 0.7397717237472534
Validation loss: 2.0598222901744228

Epoch: 6| Step: 4
Training loss: 1.5053476095199585
Validation loss: 2.0334460684048232

Epoch: 6| Step: 5
Training loss: 0.8209242224693298
Validation loss: 1.99094404456436

Epoch: 6| Step: 6
Training loss: 1.1950490474700928
Validation loss: 1.9710495843682239

Epoch: 6| Step: 7
Training loss: 1.7939701080322266
Validation loss: 1.9220089053594938

Epoch: 6| Step: 8
Training loss: 0.8766433596611023
Validation loss: 1.9185600434580157

Epoch: 6| Step: 9
Training loss: 1.8338196277618408
Validation loss: 1.920677541404642

Epoch: 6| Step: 10
Training loss: 1.3420913219451904
Validation loss: 1.9334440474869103

Epoch: 6| Step: 11
Training loss: 0.9656610488891602
Validation loss: 1.9539157472630984

Epoch: 6| Step: 12
Training loss: 1.3610401153564453
Validation loss: 1.9877048077121857

Epoch: 6| Step: 13
Training loss: 1.4847198724746704
Validation loss: 1.9782433356008222

Epoch: 202| Step: 0
Training loss: 1.7417521476745605
Validation loss: 1.9636166095733643

Epoch: 6| Step: 1
Training loss: 0.9772663712501526
Validation loss: 1.988728856527677

Epoch: 6| Step: 2
Training loss: 0.9372519254684448
Validation loss: 2.0076263809716828

Epoch: 6| Step: 3
Training loss: 1.1137490272521973
Validation loss: 2.0200065771738687

Epoch: 6| Step: 4
Training loss: 1.735460638999939
Validation loss: 2.0221791933941584

Epoch: 6| Step: 5
Training loss: 1.2387057542800903
Validation loss: 2.057100539566368

Epoch: 6| Step: 6
Training loss: 0.8274129629135132
Validation loss: 2.0740678489849134

Epoch: 6| Step: 7
Training loss: 1.5654884576797485
Validation loss: 2.117855948786582

Epoch: 6| Step: 8
Training loss: 1.3601959943771362
Validation loss: 2.085606357102753

Epoch: 6| Step: 9
Training loss: 1.152766227722168
Validation loss: 2.0767541649521037

Epoch: 6| Step: 10
Training loss: 1.3861550092697144
Validation loss: 2.0331680236324186

Epoch: 6| Step: 11
Training loss: 0.7174891829490662
Validation loss: 1.9904111482763802

Epoch: 6| Step: 12
Training loss: 0.9929320812225342
Validation loss: 1.9179849278542302

Epoch: 6| Step: 13
Training loss: 1.4838212728500366
Validation loss: 1.9143346509625834

Epoch: 203| Step: 0
Training loss: 1.5548419952392578
Validation loss: 1.8787079677786878

Epoch: 6| Step: 1
Training loss: 2.044315814971924
Validation loss: 1.8827991242049842

Epoch: 6| Step: 2
Training loss: 0.8630694150924683
Validation loss: 1.8767177110077233

Epoch: 6| Step: 3
Training loss: 1.2251540422439575
Validation loss: 1.8884669452585199

Epoch: 6| Step: 4
Training loss: 1.285046935081482
Validation loss: 1.874927241315124

Epoch: 6| Step: 5
Training loss: 0.8923728466033936
Validation loss: 1.8896761248188634

Epoch: 6| Step: 6
Training loss: 1.618279218673706
Validation loss: 1.8937276947882868

Epoch: 6| Step: 7
Training loss: 1.5060224533081055
Validation loss: 1.9130210004827028

Epoch: 6| Step: 8
Training loss: 0.47290608286857605
Validation loss: 1.9566243771583802

Epoch: 6| Step: 9
Training loss: 1.3412035703659058
Validation loss: 1.9560727906483475

Epoch: 6| Step: 10
Training loss: 1.1062161922454834
Validation loss: 1.9740535443828953

Epoch: 6| Step: 11
Training loss: 1.2405632734298706
Validation loss: 1.977668535324835

Epoch: 6| Step: 12
Training loss: 0.7848914861679077
Validation loss: 1.991875804880614

Epoch: 6| Step: 13
Training loss: 0.7114014625549316
Validation loss: 2.015505624073808

Epoch: 204| Step: 0
Training loss: 1.1555283069610596
Validation loss: 2.006519158681234

Epoch: 6| Step: 1
Training loss: 0.8236926794052124
Validation loss: 2.003317222800306

Epoch: 6| Step: 2
Training loss: 0.8946313858032227
Validation loss: 1.970623972595379

Epoch: 6| Step: 3
Training loss: 0.8378372192382812
Validation loss: 1.9742767528821064

Epoch: 6| Step: 4
Training loss: 1.4811912775039673
Validation loss: 2.0003380262723534

Epoch: 6| Step: 5
Training loss: 1.601949691772461
Validation loss: 2.0222273026743243

Epoch: 6| Step: 6
Training loss: 1.4896875619888306
Validation loss: 1.9976351261138916

Epoch: 6| Step: 7
Training loss: 1.2114636898040771
Validation loss: 2.00283036949814

Epoch: 6| Step: 8
Training loss: 0.8859043121337891
Validation loss: 1.9759225922246133

Epoch: 6| Step: 9
Training loss: 0.9780995845794678
Validation loss: 1.9685554940213439

Epoch: 6| Step: 10
Training loss: 1.1242833137512207
Validation loss: 1.9441488160881946

Epoch: 6| Step: 11
Training loss: 1.1919729709625244
Validation loss: 1.9539942228665916

Epoch: 6| Step: 12
Training loss: 1.1951191425323486
Validation loss: 1.9376214922115367

Epoch: 6| Step: 13
Training loss: 1.532240390777588
Validation loss: 1.9502213654979583

Epoch: 205| Step: 0
Training loss: 0.6209803819656372
Validation loss: 1.9663847338768743

Epoch: 6| Step: 1
Training loss: 1.6573933362960815
Validation loss: 1.9805867261784051

Epoch: 6| Step: 2
Training loss: 0.6541641354560852
Validation loss: 1.975233958613488

Epoch: 6| Step: 3
Training loss: 0.7231659293174744
Validation loss: 1.9330653682831795

Epoch: 6| Step: 4
Training loss: 0.9124011993408203
Validation loss: 1.9456438877249276

Epoch: 6| Step: 5
Training loss: 1.176168441772461
Validation loss: 1.963007257830712

Epoch: 6| Step: 6
Training loss: 1.2434195280075073
Validation loss: 1.9731844625165385

Epoch: 6| Step: 7
Training loss: 1.1145155429840088
Validation loss: 1.9416466733460784

Epoch: 6| Step: 8
Training loss: 0.7504264116287231
Validation loss: 1.9531013311878327

Epoch: 6| Step: 9
Training loss: 1.0847885608673096
Validation loss: 1.9369356363050398

Epoch: 6| Step: 10
Training loss: 1.3861356973648071
Validation loss: 1.921618188581159

Epoch: 6| Step: 11
Training loss: 1.6027631759643555
Validation loss: 1.9056954537668536

Epoch: 6| Step: 12
Training loss: 1.5237128734588623
Validation loss: 1.9299138566499114

Epoch: 6| Step: 13
Training loss: 1.6995105743408203
Validation loss: 1.9282900300077213

Epoch: 206| Step: 0
Training loss: 0.8813112378120422
Validation loss: 1.9316506180711972

Epoch: 6| Step: 1
Training loss: 1.0725477933883667
Validation loss: 1.9555166844398744

Epoch: 6| Step: 2
Training loss: 0.8995728492736816
Validation loss: 1.9525342859247679

Epoch: 6| Step: 3
Training loss: 1.6862602233886719
Validation loss: 1.9600022198051534

Epoch: 6| Step: 4
Training loss: 1.230637788772583
Validation loss: 1.9418872774288218

Epoch: 6| Step: 5
Training loss: 0.8083018064498901
Validation loss: 1.9471312299851449

Epoch: 6| Step: 6
Training loss: 1.1288797855377197
Validation loss: 1.9515904688066052

Epoch: 6| Step: 7
Training loss: 0.6811290979385376
Validation loss: 1.9579823260666223

Epoch: 6| Step: 8
Training loss: 1.1963326930999756
Validation loss: 1.9773551033389183

Epoch: 6| Step: 9
Training loss: 1.26963472366333
Validation loss: 2.001297535434846

Epoch: 6| Step: 10
Training loss: 1.3460499048233032
Validation loss: 1.955742984689692

Epoch: 6| Step: 11
Training loss: 1.697027564048767
Validation loss: 1.9504474824474705

Epoch: 6| Step: 12
Training loss: 1.4454084634780884
Validation loss: 1.9258231937244374

Epoch: 6| Step: 13
Training loss: 0.494268000125885
Validation loss: 1.9600260180811728

Epoch: 207| Step: 0
Training loss: 1.1399976015090942
Validation loss: 1.9428220102863927

Epoch: 6| Step: 1
Training loss: 0.8581111431121826
Validation loss: 1.9463130799672936

Epoch: 6| Step: 2
Training loss: 1.6991057395935059
Validation loss: 1.959755265584556

Epoch: 6| Step: 3
Training loss: 1.282024621963501
Validation loss: 1.9449574857629754

Epoch: 6| Step: 4
Training loss: 1.5659990310668945
Validation loss: 1.9944049748041297

Epoch: 6| Step: 5
Training loss: 1.2149462699890137
Validation loss: 1.9911745953303512

Epoch: 6| Step: 6
Training loss: 0.3076239228248596
Validation loss: 1.985131412424067

Epoch: 6| Step: 7
Training loss: 1.152710199356079
Validation loss: 1.9887888482821885

Epoch: 6| Step: 8
Training loss: 0.6752767562866211
Validation loss: 1.9999718166166736

Epoch: 6| Step: 9
Training loss: 1.31072998046875
Validation loss: 1.990381315190305

Epoch: 6| Step: 10
Training loss: 1.2920840978622437
Validation loss: 1.989549498404226

Epoch: 6| Step: 11
Training loss: 0.8722038269042969
Validation loss: 1.981316324203245

Epoch: 6| Step: 12
Training loss: 0.9875999689102173
Validation loss: 1.9708721970999112

Epoch: 6| Step: 13
Training loss: 1.4681142568588257
Validation loss: 1.9236167412932201

Epoch: 208| Step: 0
Training loss: 1.2962613105773926
Validation loss: 1.924857113950996

Epoch: 6| Step: 1
Training loss: 0.6474483609199524
Validation loss: 1.9212605120033346

Epoch: 6| Step: 2
Training loss: 0.5656851530075073
Validation loss: 1.9331077311628608

Epoch: 6| Step: 3
Training loss: 0.9105539321899414
Validation loss: 1.9334749239747242

Epoch: 6| Step: 4
Training loss: 1.0043293237686157
Validation loss: 1.9231981449229743

Epoch: 6| Step: 5
Training loss: 1.2332500219345093
Validation loss: 1.9553952127374628

Epoch: 6| Step: 6
Training loss: 1.8416130542755127
Validation loss: 1.992359612577705

Epoch: 6| Step: 7
Training loss: 0.8930162787437439
Validation loss: 1.9943955547066146

Epoch: 6| Step: 8
Training loss: 1.3766045570373535
Validation loss: 2.0253906147454375

Epoch: 6| Step: 9
Training loss: 1.1389081478118896
Validation loss: 2.004124402999878

Epoch: 6| Step: 10
Training loss: 1.4027073383331299
Validation loss: 1.9801813710120417

Epoch: 6| Step: 11
Training loss: 1.1128356456756592
Validation loss: 1.9419287750797887

Epoch: 6| Step: 12
Training loss: 1.2652826309204102
Validation loss: 1.9163807361356673

Epoch: 6| Step: 13
Training loss: 0.4768974483013153
Validation loss: 1.9116413747110674

Epoch: 209| Step: 0
Training loss: 1.2821056842803955
Validation loss: 1.883363236663162

Epoch: 6| Step: 1
Training loss: 0.7250006198883057
Validation loss: 1.8724977431758758

Epoch: 6| Step: 2
Training loss: 1.4668298959732056
Validation loss: 1.8763216336568196

Epoch: 6| Step: 3
Training loss: 0.6981078386306763
Validation loss: 1.8845369418462117

Epoch: 6| Step: 4
Training loss: 0.8884868621826172
Validation loss: 1.8897057989592194

Epoch: 6| Step: 5
Training loss: 0.8424262404441833
Validation loss: 1.9060800178076631

Epoch: 6| Step: 6
Training loss: 1.554739236831665
Validation loss: 1.9813282874322706

Epoch: 6| Step: 7
Training loss: 0.7515437602996826
Validation loss: 1.9703875485286917

Epoch: 6| Step: 8
Training loss: 1.535688877105713
Validation loss: 1.9508149764871086

Epoch: 6| Step: 9
Training loss: 0.9414904117584229
Validation loss: 1.9437435544947141

Epoch: 6| Step: 10
Training loss: 2.0009164810180664
Validation loss: 1.9669458558482509

Epoch: 6| Step: 11
Training loss: 1.0438451766967773
Validation loss: 1.943528409927122

Epoch: 6| Step: 12
Training loss: 1.003656268119812
Validation loss: 1.9547628138654976

Epoch: 6| Step: 13
Training loss: 0.7223929166793823
Validation loss: 1.9073375566031343

Epoch: 210| Step: 0
Training loss: 0.9110957384109497
Validation loss: 1.9047277665907336

Epoch: 6| Step: 1
Training loss: 1.1142215728759766
Validation loss: 1.9391517190523044

Epoch: 6| Step: 2
Training loss: 0.8467400670051575
Validation loss: 1.955093749107853

Epoch: 6| Step: 3
Training loss: 1.3054614067077637
Validation loss: 2.0030649682526946

Epoch: 6| Step: 4
Training loss: 0.7950562238693237
Validation loss: 2.032956087461082

Epoch: 6| Step: 5
Training loss: 1.0185596942901611
Validation loss: 2.034824848175049

Epoch: 6| Step: 6
Training loss: 0.9230778217315674
Validation loss: 1.9513813141853578

Epoch: 6| Step: 7
Training loss: 0.8719645142555237
Validation loss: 1.9076420927560458

Epoch: 6| Step: 8
Training loss: 2.023505210876465
Validation loss: 1.8918395747420609

Epoch: 6| Step: 9
Training loss: 1.231655240058899
Validation loss: 1.881096404085877

Epoch: 6| Step: 10
Training loss: 1.33785080909729
Validation loss: 1.8812054741767146

Epoch: 6| Step: 11
Training loss: 1.3596348762512207
Validation loss: 1.8806155958483297

Epoch: 6| Step: 12
Training loss: 1.0122801065444946
Validation loss: 1.89009173967505

Epoch: 6| Step: 13
Training loss: 1.2657088041305542
Validation loss: 1.9246734547358688

Epoch: 211| Step: 0
Training loss: 1.0188181400299072
Validation loss: 1.9070987752688828

Epoch: 6| Step: 1
Training loss: 1.539167881011963
Validation loss: 1.921089574854861

Epoch: 6| Step: 2
Training loss: 0.9227500557899475
Validation loss: 1.935506469459944

Epoch: 6| Step: 3
Training loss: 0.6567029356956482
Validation loss: 1.959810983750128

Epoch: 6| Step: 4
Training loss: 0.7395766973495483
Validation loss: 2.0048631301490207

Epoch: 6| Step: 5
Training loss: 1.1108320951461792
Validation loss: 1.9982115517380417

Epoch: 6| Step: 6
Training loss: 1.5619735717773438
Validation loss: 1.9558435793845885

Epoch: 6| Step: 7
Training loss: 0.9943177700042725
Validation loss: 1.909567758601199

Epoch: 6| Step: 8
Training loss: 1.5331591367721558
Validation loss: 1.8755789520919963

Epoch: 6| Step: 9
Training loss: 1.1220054626464844
Validation loss: 1.8770833297442364

Epoch: 6| Step: 10
Training loss: 1.5185707807540894
Validation loss: 1.9151999950408936

Epoch: 6| Step: 11
Training loss: 0.9238327741622925
Validation loss: 1.8845691680908203

Epoch: 6| Step: 12
Training loss: 0.908959686756134
Validation loss: 1.8880968619418401

Epoch: 6| Step: 13
Training loss: 0.947500467300415
Validation loss: 1.9264212218664025

Epoch: 212| Step: 0
Training loss: 0.9009314775466919
Validation loss: 1.9858235569410427

Epoch: 6| Step: 1
Training loss: 1.2095897197723389
Validation loss: 2.03941515696946

Epoch: 6| Step: 2
Training loss: 1.2656346559524536
Validation loss: 2.0197515846580587

Epoch: 6| Step: 3
Training loss: 1.357133388519287
Validation loss: 2.0144759070488716

Epoch: 6| Step: 4
Training loss: 1.6511801481246948
Validation loss: 1.9631314892922678

Epoch: 6| Step: 5
Training loss: 0.5922366380691528
Validation loss: 1.9380223417794833

Epoch: 6| Step: 6
Training loss: 1.367584466934204
Validation loss: 1.950497910540591

Epoch: 6| Step: 7
Training loss: 0.9433822631835938
Validation loss: 1.9475457399122176

Epoch: 6| Step: 8
Training loss: 1.4605185985565186
Validation loss: 1.9498030126735728

Epoch: 6| Step: 9
Training loss: 1.0092246532440186
Validation loss: 1.948845091686454

Epoch: 6| Step: 10
Training loss: 1.1163959503173828
Validation loss: 1.9532605101985316

Epoch: 6| Step: 11
Training loss: 0.8803210258483887
Validation loss: 1.9418331038567327

Epoch: 6| Step: 12
Training loss: 0.6047782897949219
Validation loss: 1.9272594400631484

Epoch: 6| Step: 13
Training loss: 1.416104793548584
Validation loss: 1.9445154333627352

Epoch: 213| Step: 0
Training loss: 0.7110209465026855
Validation loss: 1.945608385147587

Epoch: 6| Step: 1
Training loss: 1.047510027885437
Validation loss: 1.965612228198718

Epoch: 6| Step: 2
Training loss: 0.8431775569915771
Validation loss: 1.924882496556928

Epoch: 6| Step: 3
Training loss: 1.3889434337615967
Validation loss: 1.9366543805727394

Epoch: 6| Step: 4
Training loss: 0.9651980400085449
Validation loss: 1.941703506695327

Epoch: 6| Step: 5
Training loss: 0.7410883903503418
Validation loss: 1.9590666447916338

Epoch: 6| Step: 6
Training loss: 1.7012462615966797
Validation loss: 1.9996120058080202

Epoch: 6| Step: 7
Training loss: 1.9049861431121826
Validation loss: 1.996042392587149

Epoch: 6| Step: 8
Training loss: 0.639893114566803
Validation loss: 1.9684995707645212

Epoch: 6| Step: 9
Training loss: 1.467896819114685
Validation loss: 1.9555057889671736

Epoch: 6| Step: 10
Training loss: 0.9134977459907532
Validation loss: 1.9483787910912627

Epoch: 6| Step: 11
Training loss: 0.9273511171340942
Validation loss: 1.9349012400514336

Epoch: 6| Step: 12
Training loss: 1.1381678581237793
Validation loss: 1.9413475041748376

Epoch: 6| Step: 13
Training loss: 0.8177101612091064
Validation loss: 1.9140279575060772

Epoch: 214| Step: 0
Training loss: 1.0829660892486572
Validation loss: 1.9167722412334975

Epoch: 6| Step: 1
Training loss: 0.7196815013885498
Validation loss: 1.9077554915540962

Epoch: 6| Step: 2
Training loss: 1.1574409008026123
Validation loss: 1.9299737304769538

Epoch: 6| Step: 3
Training loss: 1.3115742206573486
Validation loss: 1.9338654202799643

Epoch: 6| Step: 4
Training loss: 0.9758670926094055
Validation loss: 1.9234612821250834

Epoch: 6| Step: 5
Training loss: 1.1780660152435303
Validation loss: 1.9163840099047589

Epoch: 6| Step: 6
Training loss: 0.8509740829467773
Validation loss: 1.9247979553796912

Epoch: 6| Step: 7
Training loss: 0.9082967638969421
Validation loss: 1.9214521095316897

Epoch: 6| Step: 8
Training loss: 0.7056272029876709
Validation loss: 1.9409251866802093

Epoch: 6| Step: 9
Training loss: 0.6891679167747498
Validation loss: 1.9707877302682528

Epoch: 6| Step: 10
Training loss: 0.5380976796150208
Validation loss: 1.9792575374726327

Epoch: 6| Step: 11
Training loss: 1.218359112739563
Validation loss: 1.996003302194739

Epoch: 6| Step: 12
Training loss: 1.8755440711975098
Validation loss: 2.003371259217621

Epoch: 6| Step: 13
Training loss: 1.9627331495285034
Validation loss: 1.9799716498262139

Epoch: 215| Step: 0
Training loss: 1.351698637008667
Validation loss: 1.9912694731066305

Epoch: 6| Step: 1
Training loss: 1.0000982284545898
Validation loss: 1.9349341571971934

Epoch: 6| Step: 2
Training loss: 1.0552209615707397
Validation loss: 1.9123059036911174

Epoch: 6| Step: 3
Training loss: 1.2231920957565308
Validation loss: 1.8842219909032185

Epoch: 6| Step: 4
Training loss: 0.7820931077003479
Validation loss: 1.894186632607573

Epoch: 6| Step: 5
Training loss: 1.4561649560928345
Validation loss: 1.8908131584044425

Epoch: 6| Step: 6
Training loss: 1.0068823099136353
Validation loss: 1.9239429632822673

Epoch: 6| Step: 7
Training loss: 1.228228211402893
Validation loss: 1.962716293591325

Epoch: 6| Step: 8
Training loss: 0.8857555389404297
Validation loss: 1.9984799379943519

Epoch: 6| Step: 9
Training loss: 0.6720280647277832
Validation loss: 2.025813606477553

Epoch: 6| Step: 10
Training loss: 0.9357250332832336
Validation loss: 1.9994120072293025

Epoch: 6| Step: 11
Training loss: 1.3066904544830322
Validation loss: 1.9838627794737458

Epoch: 6| Step: 12
Training loss: 0.915786623954773
Validation loss: 1.9753034268656084

Epoch: 6| Step: 13
Training loss: 1.052049994468689
Validation loss: 1.9406029665341942

Epoch: 216| Step: 0
Training loss: 1.1223630905151367
Validation loss: 1.927849292755127

Epoch: 6| Step: 1
Training loss: 0.8724769949913025
Validation loss: 1.9120949186304563

Epoch: 6| Step: 2
Training loss: 0.8909091949462891
Validation loss: 1.9265563065005886

Epoch: 6| Step: 3
Training loss: 1.2018113136291504
Validation loss: 1.9433411039331907

Epoch: 6| Step: 4
Training loss: 0.7850972414016724
Validation loss: 1.9526404898653749

Epoch: 6| Step: 5
Training loss: 1.2084429264068604
Validation loss: 1.9628978865121

Epoch: 6| Step: 6
Training loss: 0.7737929224967957
Validation loss: 1.9856669556710027

Epoch: 6| Step: 7
Training loss: 1.2508362531661987
Validation loss: 2.025964677974742

Epoch: 6| Step: 8
Training loss: 0.8230279684066772
Validation loss: 2.0135836370529665

Epoch: 6| Step: 9
Training loss: 0.9889339804649353
Validation loss: 2.018545078974898

Epoch: 6| Step: 10
Training loss: 1.2548234462738037
Validation loss: 1.955498444136753

Epoch: 6| Step: 11
Training loss: 1.0874605178833008
Validation loss: 1.9114971699253205

Epoch: 6| Step: 12
Training loss: 1.1813247203826904
Validation loss: 1.9023964956242552

Epoch: 6| Step: 13
Training loss: 1.017639398574829
Validation loss: 1.88179430653972

Epoch: 217| Step: 0
Training loss: 1.165923833847046
Validation loss: 1.876081552556766

Epoch: 6| Step: 1
Training loss: 1.4217374324798584
Validation loss: 1.8759260536521993

Epoch: 6| Step: 2
Training loss: 1.2437779903411865
Validation loss: 1.8866153993914205

Epoch: 6| Step: 3
Training loss: 1.4883283376693726
Validation loss: 1.9024684249713857

Epoch: 6| Step: 4
Training loss: 0.92127525806427
Validation loss: 1.9286914551129906

Epoch: 6| Step: 5
Training loss: 0.7989299297332764
Validation loss: 1.9874502099970335

Epoch: 6| Step: 6
Training loss: 1.5085501670837402
Validation loss: 2.039160156762728

Epoch: 6| Step: 7
Training loss: 1.0347239971160889
Validation loss: 2.0425028647145917

Epoch: 6| Step: 8
Training loss: 0.9472014307975769
Validation loss: 2.0003498318374797

Epoch: 6| Step: 9
Training loss: 0.9112950563430786
Validation loss: 1.9504008164969824

Epoch: 6| Step: 10
Training loss: 0.8103552460670471
Validation loss: 1.9206953561434181

Epoch: 6| Step: 11
Training loss: 0.7457411289215088
Validation loss: 1.9393042390064528

Epoch: 6| Step: 12
Training loss: 1.4282063245773315
Validation loss: 1.922316981900123

Epoch: 6| Step: 13
Training loss: 0.9882301688194275
Validation loss: 1.9414000908533733

Epoch: 218| Step: 0
Training loss: 1.0262202024459839
Validation loss: 1.9787610115543488

Epoch: 6| Step: 1
Training loss: 0.8792747259140015
Validation loss: 2.0081569571648874

Epoch: 6| Step: 2
Training loss: 1.1004209518432617
Validation loss: 2.057847633156725

Epoch: 6| Step: 3
Training loss: 0.7814382314682007
Validation loss: 2.083340894791388

Epoch: 6| Step: 4
Training loss: 1.8440520763397217
Validation loss: 2.117575901810841

Epoch: 6| Step: 5
Training loss: 1.176070213317871
Validation loss: 2.0685547039073002

Epoch: 6| Step: 6
Training loss: 1.30126953125
Validation loss: 1.989965272206132

Epoch: 6| Step: 7
Training loss: 0.900237500667572
Validation loss: 1.9285940816325526

Epoch: 6| Step: 8
Training loss: 1.1040862798690796
Validation loss: 1.88991920281482

Epoch: 6| Step: 9
Training loss: 0.6163375377655029
Validation loss: 1.8446956962667487

Epoch: 6| Step: 10
Training loss: 1.5353667736053467
Validation loss: 1.8569314326009443

Epoch: 6| Step: 11
Training loss: 0.7071059346199036
Validation loss: 1.8508808074458953

Epoch: 6| Step: 12
Training loss: 0.8183086514472961
Validation loss: 1.8706848518822783

Epoch: 6| Step: 13
Training loss: 1.0545891523361206
Validation loss: 1.8779193380827546

Epoch: 219| Step: 0
Training loss: 0.9492217302322388
Validation loss: 1.893728119070812

Epoch: 6| Step: 1
Training loss: 1.1011865139007568
Validation loss: 1.9233995176130725

Epoch: 6| Step: 2
Training loss: 0.9616332054138184
Validation loss: 1.967044816222242

Epoch: 6| Step: 3
Training loss: 0.9541336297988892
Validation loss: 1.947017200531498

Epoch: 6| Step: 4
Training loss: 1.0059823989868164
Validation loss: 1.98481281598409

Epoch: 6| Step: 5
Training loss: 1.3576347827911377
Validation loss: 1.9641650081962667

Epoch: 6| Step: 6
Training loss: 1.20269775390625
Validation loss: 1.9918198354782597

Epoch: 6| Step: 7
Training loss: 1.1846848726272583
Validation loss: 1.9800784536587295

Epoch: 6| Step: 8
Training loss: 0.8100756406784058
Validation loss: 1.9366583670339277

Epoch: 6| Step: 9
Training loss: 1.1105064153671265
Validation loss: 1.879363647071264

Epoch: 6| Step: 10
Training loss: 1.5063447952270508
Validation loss: 1.8792475936233357

Epoch: 6| Step: 11
Training loss: 0.7677327990531921
Validation loss: 1.8788762118226738

Epoch: 6| Step: 12
Training loss: 0.7903870940208435
Validation loss: 1.9129283300010107

Epoch: 6| Step: 13
Training loss: 0.8353747725486755
Validation loss: 1.9308848022132792

Epoch: 220| Step: 0
Training loss: 0.8019767999649048
Validation loss: 1.9259108535705074

Epoch: 6| Step: 1
Training loss: 0.9030888080596924
Validation loss: 1.9295381858784666

Epoch: 6| Step: 2
Training loss: 0.9291061162948608
Validation loss: 1.8996633996245682

Epoch: 6| Step: 3
Training loss: 0.7639182806015015
Validation loss: 1.923013053914552

Epoch: 6| Step: 4
Training loss: 1.7687780857086182
Validation loss: 1.9560587585613292

Epoch: 6| Step: 5
Training loss: 1.197981834411621
Validation loss: 1.9704777245880456

Epoch: 6| Step: 6
Training loss: 0.9854525327682495
Validation loss: 1.9553268058325655

Epoch: 6| Step: 7
Training loss: 1.0652140378952026
Validation loss: 1.9799232764910626

Epoch: 6| Step: 8
Training loss: 0.7856255769729614
Validation loss: 1.9390581782146166

Epoch: 6| Step: 9
Training loss: 1.2701513767242432
Validation loss: 1.9434255912739744

Epoch: 6| Step: 10
Training loss: 1.2704041004180908
Validation loss: 1.9145797350073372

Epoch: 6| Step: 11
Training loss: 0.9955953359603882
Validation loss: 1.9199202919519076

Epoch: 6| Step: 12
Training loss: 0.8896763324737549
Validation loss: 1.8869658029207619

Epoch: 6| Step: 13
Training loss: 0.6209585070610046
Validation loss: 1.8824806726107033

Epoch: 221| Step: 0
Training loss: 1.3320387601852417
Validation loss: 1.8905258537620626

Epoch: 6| Step: 1
Training loss: 0.5367482304573059
Validation loss: 1.9138593058432303

Epoch: 6| Step: 2
Training loss: 1.0533342361450195
Validation loss: 1.9079592112571961

Epoch: 6| Step: 3
Training loss: 0.9851890802383423
Validation loss: 1.8942996199413011

Epoch: 6| Step: 4
Training loss: 0.9659302234649658
Validation loss: 1.9127385347120223

Epoch: 6| Step: 5
Training loss: 1.1813329458236694
Validation loss: 1.9469927715998825

Epoch: 6| Step: 6
Training loss: 0.996692955493927
Validation loss: 1.9463923131265948

Epoch: 6| Step: 7
Training loss: 1.0854663848876953
Validation loss: 1.954249378173582

Epoch: 6| Step: 8
Training loss: 1.2667810916900635
Validation loss: 1.9419524849102061

Epoch: 6| Step: 9
Training loss: 0.622351348400116
Validation loss: 1.9116045210951118

Epoch: 6| Step: 10
Training loss: 1.042210578918457
Validation loss: 1.903571949210218

Epoch: 6| Step: 11
Training loss: 0.6854814887046814
Validation loss: 1.882290635057675

Epoch: 6| Step: 12
Training loss: 1.048879861831665
Validation loss: 1.8781400149868381

Epoch: 6| Step: 13
Training loss: 0.9302213191986084
Validation loss: 1.901010485105617

Epoch: 222| Step: 0
Training loss: 0.98464035987854
Validation loss: 1.8916855037853282

Epoch: 6| Step: 1
Training loss: 0.651116669178009
Validation loss: 1.9029889081114082

Epoch: 6| Step: 2
Training loss: 0.6274221539497375
Validation loss: 1.9200820999760781

Epoch: 6| Step: 3
Training loss: 1.2907230854034424
Validation loss: 1.9199424251433341

Epoch: 6| Step: 4
Training loss: 0.6856089234352112
Validation loss: 1.9018301207532164

Epoch: 6| Step: 5
Training loss: 1.0368376970291138
Validation loss: 1.9174141627486034

Epoch: 6| Step: 6
Training loss: 1.2480406761169434
Validation loss: 1.9129272276355374

Epoch: 6| Step: 7
Training loss: 1.1921851634979248
Validation loss: 1.9324699191636936

Epoch: 6| Step: 8
Training loss: 1.1456644535064697
Validation loss: 1.9020850632780342

Epoch: 6| Step: 9
Training loss: 0.9466795921325684
Validation loss: 1.8918539311296196

Epoch: 6| Step: 10
Training loss: 0.9252303838729858
Validation loss: 1.8968744329226914

Epoch: 6| Step: 11
Training loss: 0.9174356460571289
Validation loss: 1.8769405759790891

Epoch: 6| Step: 12
Training loss: 1.1493628025054932
Validation loss: 1.8561984415977233

Epoch: 6| Step: 13
Training loss: 0.6066669821739197
Validation loss: 1.865896333930313

Epoch: 223| Step: 0
Training loss: 1.026308298110962
Validation loss: 1.8482167631067254

Epoch: 6| Step: 1
Training loss: 0.7460678815841675
Validation loss: 1.8470593306326097

Epoch: 6| Step: 2
Training loss: 1.0660558938980103
Validation loss: 1.8385618066274991

Epoch: 6| Step: 3
Training loss: 0.7696377038955688
Validation loss: 1.9030784535151657

Epoch: 6| Step: 4
Training loss: 0.7464586496353149
Validation loss: 1.8732062616655905

Epoch: 6| Step: 5
Training loss: 1.0323576927185059
Validation loss: 1.9145838496505574

Epoch: 6| Step: 6
Training loss: 1.3334660530090332
Validation loss: 1.9653963222298572

Epoch: 6| Step: 7
Training loss: 1.1260019540786743
Validation loss: 2.022916288786037

Epoch: 6| Step: 8
Training loss: 0.7865806818008423
Validation loss: 2.010032635863109

Epoch: 6| Step: 9
Training loss: 1.343146800994873
Validation loss: 1.9944107301773564

Epoch: 6| Step: 10
Training loss: 1.243835687637329
Validation loss: 2.030679832222641

Epoch: 6| Step: 11
Training loss: 0.8130009770393372
Validation loss: 1.9992783197792627

Epoch: 6| Step: 12
Training loss: 0.594109296798706
Validation loss: 1.9659011453710578

Epoch: 6| Step: 13
Training loss: 1.3651552200317383
Validation loss: 1.9075168230200326

Epoch: 224| Step: 0
Training loss: 0.9491075277328491
Validation loss: 1.8813281482265842

Epoch: 6| Step: 1
Training loss: 1.208409070968628
Validation loss: 1.8414667062861945

Epoch: 6| Step: 2
Training loss: 0.7406574487686157
Validation loss: 1.85552139436045

Epoch: 6| Step: 3
Training loss: 1.498424768447876
Validation loss: 1.8533823426051805

Epoch: 6| Step: 4
Training loss: 0.8835228681564331
Validation loss: 1.865487862658757

Epoch: 6| Step: 5
Training loss: 1.136704444885254
Validation loss: 1.897127579617244

Epoch: 6| Step: 6
Training loss: 0.74809730052948
Validation loss: 1.9444547519888928

Epoch: 6| Step: 7
Training loss: 0.7476596832275391
Validation loss: 1.9709576163240659

Epoch: 6| Step: 8
Training loss: 1.0861666202545166
Validation loss: 2.0375987842518795

Epoch: 6| Step: 9
Training loss: 0.9938510656356812
Validation loss: 2.043606363317018

Epoch: 6| Step: 10
Training loss: 0.33630722761154175
Validation loss: 1.995215485172887

Epoch: 6| Step: 11
Training loss: 0.9119796752929688
Validation loss: 1.967320765218427

Epoch: 6| Step: 12
Training loss: 1.2495393753051758
Validation loss: 1.915083077646071

Epoch: 6| Step: 13
Training loss: 1.2498146295547485
Validation loss: 1.8945312448727187

Epoch: 225| Step: 0
Training loss: 0.9983352422714233
Validation loss: 1.8963211672280424

Epoch: 6| Step: 1
Training loss: 1.0417358875274658
Validation loss: 1.880324645708966

Epoch: 6| Step: 2
Training loss: 0.7499770522117615
Validation loss: 1.8562443153832549

Epoch: 6| Step: 3
Training loss: 0.8598557710647583
Validation loss: 1.8346299586757537

Epoch: 6| Step: 4
Training loss: 0.7799817323684692
Validation loss: 1.828979274278046

Epoch: 6| Step: 5
Training loss: 0.9985252022743225
Validation loss: 1.824270603477314

Epoch: 6| Step: 6
Training loss: 0.7559676170349121
Validation loss: 1.8582362987661873

Epoch: 6| Step: 7
Training loss: 0.5871596336364746
Validation loss: 1.8879872868137975

Epoch: 6| Step: 8
Training loss: 0.44534847140312195
Validation loss: 1.8884806825268654

Epoch: 6| Step: 9
Training loss: 1.0720807313919067
Validation loss: 1.9056561531559113

Epoch: 6| Step: 10
Training loss: 0.9151037931442261
Validation loss: 1.9269632254877398

Epoch: 6| Step: 11
Training loss: 1.6117558479309082
Validation loss: 1.8954298086063837

Epoch: 6| Step: 12
Training loss: 1.1671953201293945
Validation loss: 1.8852447514892907

Epoch: 6| Step: 13
Training loss: 1.2571457624435425
Validation loss: 1.9073664693422214

Epoch: 226| Step: 0
Training loss: 0.5239320993423462
Validation loss: 1.9241927554530482

Epoch: 6| Step: 1
Training loss: 1.3671092987060547
Validation loss: 1.9383729632182787

Epoch: 6| Step: 2
Training loss: 1.2774019241333008
Validation loss: 1.9410129593264671

Epoch: 6| Step: 3
Training loss: 0.9920562505722046
Validation loss: 1.9673931765299972

Epoch: 6| Step: 4
Training loss: 1.0451425313949585
Validation loss: 2.0033888611742245

Epoch: 6| Step: 5
Training loss: 0.6821526288986206
Validation loss: 1.994336453817224

Epoch: 6| Step: 6
Training loss: 0.8325924873352051
Validation loss: 1.9649695747642106

Epoch: 6| Step: 7
Training loss: 0.6556522250175476
Validation loss: 1.9242691865531347

Epoch: 6| Step: 8
Training loss: 0.8780096769332886
Validation loss: 1.8891446667332803

Epoch: 6| Step: 9
Training loss: 0.6322097778320312
Validation loss: 1.8721568481896513

Epoch: 6| Step: 10
Training loss: 0.6458418369293213
Validation loss: 1.850214433926408

Epoch: 6| Step: 11
Training loss: 1.4245996475219727
Validation loss: 1.854740579922994

Epoch: 6| Step: 12
Training loss: 1.0025272369384766
Validation loss: 1.8543456113466652

Epoch: 6| Step: 13
Training loss: 1.3232159614562988
Validation loss: 1.8504476636968634

Epoch: 227| Step: 0
Training loss: 1.013169765472412
Validation loss: 1.8596464741614558

Epoch: 6| Step: 1
Training loss: 1.063326358795166
Validation loss: 1.8860953059247745

Epoch: 6| Step: 2
Training loss: 0.6170246601104736
Validation loss: 1.8842991257226596

Epoch: 6| Step: 3
Training loss: 0.41790956258773804
Validation loss: 1.937171092597387

Epoch: 6| Step: 4
Training loss: 1.105540156364441
Validation loss: 1.9507275781323832

Epoch: 6| Step: 5
Training loss: 1.1481249332427979
Validation loss: 1.9191122721600276

Epoch: 6| Step: 6
Training loss: 0.9833123683929443
Validation loss: 1.9315263148277038

Epoch: 6| Step: 7
Training loss: 1.114172101020813
Validation loss: 1.9171291128281625

Epoch: 6| Step: 8
Training loss: 0.7379900217056274
Validation loss: 1.932237760995024

Epoch: 6| Step: 9
Training loss: 1.465746283531189
Validation loss: 1.9346597656126945

Epoch: 6| Step: 10
Training loss: 0.8783443570137024
Validation loss: 1.9361492920947332

Epoch: 6| Step: 11
Training loss: 0.9485495686531067
Validation loss: 1.896811903163951

Epoch: 6| Step: 12
Training loss: 0.8195967078208923
Validation loss: 1.8605074062142322

Epoch: 6| Step: 13
Training loss: 0.5228627324104309
Validation loss: 1.8423191757612332

Epoch: 228| Step: 0
Training loss: 0.7881835103034973
Validation loss: 1.8312987614703435

Epoch: 6| Step: 1
Training loss: 0.8366036415100098
Validation loss: 1.854536356464509

Epoch: 6| Step: 2
Training loss: 0.9003515243530273
Validation loss: 1.8486122046747515

Epoch: 6| Step: 3
Training loss: 1.4709826707839966
Validation loss: 1.8741285390751337

Epoch: 6| Step: 4
Training loss: 0.6309903264045715
Validation loss: 1.8935281833012898

Epoch: 6| Step: 5
Training loss: 0.6855829954147339
Validation loss: 1.8794410408184092

Epoch: 6| Step: 6
Training loss: 1.202481985092163
Validation loss: 1.892763586454494

Epoch: 6| Step: 7
Training loss: 0.608612060546875
Validation loss: 1.8900475719923615

Epoch: 6| Step: 8
Training loss: 1.0551040172576904
Validation loss: 1.9004677418739564

Epoch: 6| Step: 9
Training loss: 0.6793581247329712
Validation loss: 1.9120247953681535

Epoch: 6| Step: 10
Training loss: 0.8540949821472168
Validation loss: 1.9166791721056866

Epoch: 6| Step: 11
Training loss: 1.2385566234588623
Validation loss: 1.91211240009595

Epoch: 6| Step: 12
Training loss: 0.8591895699501038
Validation loss: 1.9049183386628346

Epoch: 6| Step: 13
Training loss: 0.6562673449516296
Validation loss: 1.9108219941457112

Epoch: 229| Step: 0
Training loss: 0.8951394557952881
Validation loss: 1.8502222889213151

Epoch: 6| Step: 1
Training loss: 0.7553336024284363
Validation loss: 1.829400436852568

Epoch: 6| Step: 2
Training loss: 0.9801023602485657
Validation loss: 1.8330922947135022

Epoch: 6| Step: 3
Training loss: 0.8482750654220581
Validation loss: 1.8267956177393596

Epoch: 6| Step: 4
Training loss: 0.9361013174057007
Validation loss: 1.839138005369453

Epoch: 6| Step: 5
Training loss: 0.9640629291534424
Validation loss: 1.8483957987959667

Epoch: 6| Step: 6
Training loss: 0.6482882499694824
Validation loss: 1.8411415828171598

Epoch: 6| Step: 7
Training loss: 1.0578186511993408
Validation loss: 1.8851708699298162

Epoch: 6| Step: 8
Training loss: 0.7379025220870972
Validation loss: 1.9019912365944154

Epoch: 6| Step: 9
Training loss: 1.0050922632217407
Validation loss: 1.9071936107450915

Epoch: 6| Step: 10
Training loss: 1.0136175155639648
Validation loss: 1.9051329628113778

Epoch: 6| Step: 11
Training loss: 1.009119987487793
Validation loss: 1.8793184026595084

Epoch: 6| Step: 12
Training loss: 0.9828920960426331
Validation loss: 1.8893299679602347

Epoch: 6| Step: 13
Training loss: 0.6891117095947266
Validation loss: 1.8670280428342922

Epoch: 230| Step: 0
Training loss: 1.2359998226165771
Validation loss: 1.8781538727462932

Epoch: 6| Step: 1
Training loss: 1.1444698572158813
Validation loss: 1.8960031796527166

Epoch: 6| Step: 2
Training loss: 1.4044644832611084
Validation loss: 1.9203693687274892

Epoch: 6| Step: 3
Training loss: 0.778599202632904
Validation loss: 1.9421147390078473

Epoch: 6| Step: 4
Training loss: 0.6564096212387085
Validation loss: 1.9675363058684974

Epoch: 6| Step: 5
Training loss: 1.1585414409637451
Validation loss: 1.9416653071680376

Epoch: 6| Step: 6
Training loss: 0.729191780090332
Validation loss: 1.9000319139931792

Epoch: 6| Step: 7
Training loss: 0.8005844354629517
Validation loss: 1.893413032254865

Epoch: 6| Step: 8
Training loss: 0.9013480544090271
Validation loss: 1.878209549893615

Epoch: 6| Step: 9
Training loss: 0.6612211465835571
Validation loss: 1.8440435599255305

Epoch: 6| Step: 10
Training loss: 0.7623172998428345
Validation loss: 1.8376347864827802

Epoch: 6| Step: 11
Training loss: 0.7943248748779297
Validation loss: 1.8672930771304714

Epoch: 6| Step: 12
Training loss: 0.8333916664123535
Validation loss: 1.8974460171115013

Epoch: 6| Step: 13
Training loss: 0.8239611387252808
Validation loss: 1.9360502689115462

Epoch: 231| Step: 0
Training loss: 0.6679124236106873
Validation loss: 1.9708563973826747

Epoch: 6| Step: 1
Training loss: 0.9447202682495117
Validation loss: 2.0280515647703603

Epoch: 6| Step: 2
Training loss: 0.7090109586715698
Validation loss: 1.974420488521617

Epoch: 6| Step: 3
Training loss: 1.3375966548919678
Validation loss: 1.9220737359857047

Epoch: 6| Step: 4
Training loss: 1.3203551769256592
Validation loss: 1.8827269833575013

Epoch: 6| Step: 5
Training loss: 0.537909746170044
Validation loss: 1.8596170358760382

Epoch: 6| Step: 6
Training loss: 1.0152947902679443
Validation loss: 1.837785231169834

Epoch: 6| Step: 7
Training loss: 1.156134843826294
Validation loss: 1.826907254034473

Epoch: 6| Step: 8
Training loss: 1.0201542377471924
Validation loss: 1.8296342742058538

Epoch: 6| Step: 9
Training loss: 0.6878100633621216
Validation loss: 1.8452157410242225

Epoch: 6| Step: 10
Training loss: 0.8991426229476929
Validation loss: 1.8881163776561778

Epoch: 6| Step: 11
Training loss: 1.2618787288665771
Validation loss: 1.9224069605591476

Epoch: 6| Step: 12
Training loss: 0.7304230332374573
Validation loss: 1.9091571505351732

Epoch: 6| Step: 13
Training loss: 1.093733787536621
Validation loss: 1.917027206831081

Epoch: 232| Step: 0
Training loss: 1.117514729499817
Validation loss: 1.8733500652415778

Epoch: 6| Step: 1
Training loss: 0.8055107593536377
Validation loss: 1.8792002406171573

Epoch: 6| Step: 2
Training loss: 1.0872485637664795
Validation loss: 1.883852945860996

Epoch: 6| Step: 3
Training loss: 1.0192975997924805
Validation loss: 1.9025623900915987

Epoch: 6| Step: 4
Training loss: 0.6294137239456177
Validation loss: 1.916506181481064

Epoch: 6| Step: 5
Training loss: 0.7642053365707397
Validation loss: 1.9137839219903434

Epoch: 6| Step: 6
Training loss: 0.977940022945404
Validation loss: 1.98714155022816

Epoch: 6| Step: 7
Training loss: 1.2912949323654175
Validation loss: 1.981857556168751

Epoch: 6| Step: 8
Training loss: 0.9868393540382385
Validation loss: 1.9834941433322044

Epoch: 6| Step: 9
Training loss: 1.0988584756851196
Validation loss: 1.9267620219979236

Epoch: 6| Step: 10
Training loss: 0.7118619084358215
Validation loss: 1.877949753115254

Epoch: 6| Step: 11
Training loss: 0.9835090637207031
Validation loss: 1.8296110040398055

Epoch: 6| Step: 12
Training loss: 0.8386704921722412
Validation loss: 1.8506326124232302

Epoch: 6| Step: 13
Training loss: 0.7477312684059143
Validation loss: 1.8238536311734108

Epoch: 233| Step: 0
Training loss: 0.7991623878479004
Validation loss: 1.8394670614632227

Epoch: 6| Step: 1
Training loss: 1.0192420482635498
Validation loss: 1.835403747456048

Epoch: 6| Step: 2
Training loss: 0.45518478751182556
Validation loss: 1.8717174799211564

Epoch: 6| Step: 3
Training loss: 0.6175214052200317
Validation loss: 1.8623760182370421

Epoch: 6| Step: 4
Training loss: 0.9705842733383179
Validation loss: 1.907317158996418

Epoch: 6| Step: 5
Training loss: 1.3200232982635498
Validation loss: 1.9539600777369674

Epoch: 6| Step: 6
Training loss: 1.6832544803619385
Validation loss: 1.9709917140263382

Epoch: 6| Step: 7
Training loss: 1.3680400848388672
Validation loss: 1.947782447261195

Epoch: 6| Step: 8
Training loss: 0.6928207874298096
Validation loss: 1.9536528036158571

Epoch: 6| Step: 9
Training loss: 0.6881342530250549
Validation loss: 1.915566086769104

Epoch: 6| Step: 10
Training loss: 0.9738049507141113
Validation loss: 1.9211903874592116

Epoch: 6| Step: 11
Training loss: 0.8605103492736816
Validation loss: 1.9048938623038671

Epoch: 6| Step: 12
Training loss: 0.7414569854736328
Validation loss: 1.8760290383010783

Epoch: 6| Step: 13
Training loss: 0.7045211791992188
Validation loss: 1.864153423616963

Epoch: 234| Step: 0
Training loss: 0.9544079899787903
Validation loss: 1.8788007779787945

Epoch: 6| Step: 1
Training loss: 0.7967625856399536
Validation loss: 1.8895588074961016

Epoch: 6| Step: 2
Training loss: 0.881085991859436
Validation loss: 1.9083715408079085

Epoch: 6| Step: 3
Training loss: 1.3479011058807373
Validation loss: 1.927836989843717

Epoch: 6| Step: 4
Training loss: 0.8198806047439575
Validation loss: 1.932079820222752

Epoch: 6| Step: 5
Training loss: 0.8056856393814087
Validation loss: 1.9210333260156776

Epoch: 6| Step: 6
Training loss: 0.9323939085006714
Validation loss: 1.8974491793622252

Epoch: 6| Step: 7
Training loss: 1.0386871099472046
Validation loss: 1.8840123222720238

Epoch: 6| Step: 8
Training loss: 0.7892392873764038
Validation loss: 1.8713303586488128

Epoch: 6| Step: 9
Training loss: 0.7820215225219727
Validation loss: 1.8702214251282394

Epoch: 6| Step: 10
Training loss: 0.5200465321540833
Validation loss: 1.8731783308008665

Epoch: 6| Step: 11
Training loss: 0.8894757032394409
Validation loss: 1.9059550044357136

Epoch: 6| Step: 12
Training loss: 1.0676885843276978
Validation loss: 1.882751851953486

Epoch: 6| Step: 13
Training loss: 0.6978647708892822
Validation loss: 1.8910219489887197

Epoch: 235| Step: 0
Training loss: 0.8820258378982544
Validation loss: 1.9176298623443933

Epoch: 6| Step: 1
Training loss: 0.840770959854126
Validation loss: 1.943769706192837

Epoch: 6| Step: 2
Training loss: 0.5999124050140381
Validation loss: 1.9556930757338

Epoch: 6| Step: 3
Training loss: 0.6298779845237732
Validation loss: 1.9588424480089577

Epoch: 6| Step: 4
Training loss: 0.9601474404335022
Validation loss: 1.9735743140661588

Epoch: 6| Step: 5
Training loss: 0.8881339430809021
Validation loss: 1.9245294345322477

Epoch: 6| Step: 6
Training loss: 1.1668797731399536
Validation loss: 1.9307056780784362

Epoch: 6| Step: 7
Training loss: 1.0472133159637451
Validation loss: 1.9272546896370508

Epoch: 6| Step: 8
Training loss: 0.7475374937057495
Validation loss: 1.903197209040324

Epoch: 6| Step: 9
Training loss: 0.8211110234260559
Validation loss: 1.884140073612172

Epoch: 6| Step: 10
Training loss: 1.0665456056594849
Validation loss: 1.8894151064657396

Epoch: 6| Step: 11
Training loss: 0.6061954498291016
Validation loss: 1.8761654079601329

Epoch: 6| Step: 12
Training loss: 1.0790339708328247
Validation loss: 1.9097789628531343

Epoch: 6| Step: 13
Training loss: 0.8706645965576172
Validation loss: 1.876639425113637

Epoch: 236| Step: 0
Training loss: 0.5390174984931946
Validation loss: 1.8835094859523158

Epoch: 6| Step: 1
Training loss: 0.5690888166427612
Validation loss: 1.8755106951600762

Epoch: 6| Step: 2
Training loss: 0.4258953928947449
Validation loss: 1.8820210784994147

Epoch: 6| Step: 3
Training loss: 1.202089548110962
Validation loss: 1.8469992670961606

Epoch: 6| Step: 4
Training loss: 0.7313865423202515
Validation loss: 1.8556057765919676

Epoch: 6| Step: 5
Training loss: 0.8760323524475098
Validation loss: 1.8580348927487609

Epoch: 6| Step: 6
Training loss: 0.8413547277450562
Validation loss: 1.8683794865044214

Epoch: 6| Step: 7
Training loss: 0.6956973671913147
Validation loss: 1.8867120512070195

Epoch: 6| Step: 8
Training loss: 1.4998645782470703
Validation loss: 1.904228627040822

Epoch: 6| Step: 9
Training loss: 0.7607560157775879
Validation loss: 1.8902146072797879

Epoch: 6| Step: 10
Training loss: 0.9636352062225342
Validation loss: 1.8706715312055362

Epoch: 6| Step: 11
Training loss: 0.8461790084838867
Validation loss: 1.8560396907150105

Epoch: 6| Step: 12
Training loss: 1.1951756477355957
Validation loss: 1.836196296958513

Epoch: 6| Step: 13
Training loss: 0.3922760784626007
Validation loss: 1.8219191579408542

Epoch: 237| Step: 0
Training loss: 0.8728317022323608
Validation loss: 1.8125317635074738

Epoch: 6| Step: 1
Training loss: 0.752660870552063
Validation loss: 1.7941142384723952

Epoch: 6| Step: 2
Training loss: 0.549331784248352
Validation loss: 1.798792641649964

Epoch: 6| Step: 3
Training loss: 0.958046555519104
Validation loss: 1.823535248797427

Epoch: 6| Step: 4
Training loss: 0.6019217371940613
Validation loss: 1.8589280869371148

Epoch: 6| Step: 5
Training loss: 0.8263164758682251
Validation loss: 1.8822200708491827

Epoch: 6| Step: 6
Training loss: 0.7400577068328857
Validation loss: 1.857745837139827

Epoch: 6| Step: 7
Training loss: 0.7023714780807495
Validation loss: 1.8552083328206053

Epoch: 6| Step: 8
Training loss: 0.5309765338897705
Validation loss: 1.8517337563217326

Epoch: 6| Step: 9
Training loss: 0.7484520673751831
Validation loss: 1.863040477998795

Epoch: 6| Step: 10
Training loss: 1.5849900245666504
Validation loss: 1.871325110876432

Epoch: 6| Step: 11
Training loss: 0.7821322679519653
Validation loss: 1.8770754670584073

Epoch: 6| Step: 12
Training loss: 0.7849546670913696
Validation loss: 1.8998054406976188

Epoch: 6| Step: 13
Training loss: 1.6199650764465332
Validation loss: 1.9032379222172562

Epoch: 238| Step: 0
Training loss: 1.0627185106277466
Validation loss: 1.8896903414880075

Epoch: 6| Step: 1
Training loss: 0.6692469120025635
Validation loss: 1.8436018433622134

Epoch: 6| Step: 2
Training loss: 0.5961203575134277
Validation loss: 1.8391241206917712

Epoch: 6| Step: 3
Training loss: 0.8334111571311951
Validation loss: 1.8276908987311906

Epoch: 6| Step: 4
Training loss: 0.7647448182106018
Validation loss: 1.8696830247038154

Epoch: 6| Step: 5
Training loss: 0.8421404361724854
Validation loss: 1.892128380396033

Epoch: 6| Step: 6
Training loss: 0.9461233615875244
Validation loss: 1.9136095021360664

Epoch: 6| Step: 7
Training loss: 0.9650874137878418
Validation loss: 1.8903524619276806

Epoch: 6| Step: 8
Training loss: 0.9339216947555542
Validation loss: 1.867654396641639

Epoch: 6| Step: 9
Training loss: 0.9343851804733276
Validation loss: 1.8351415946919432

Epoch: 6| Step: 10
Training loss: 0.6633226871490479
Validation loss: 1.8494999767631612

Epoch: 6| Step: 11
Training loss: 0.8119467496871948
Validation loss: 1.8176287630552888

Epoch: 6| Step: 12
Training loss: 1.235290288925171
Validation loss: 1.8112638708083861

Epoch: 6| Step: 13
Training loss: 0.765863835811615
Validation loss: 1.8397863193224835

Epoch: 239| Step: 0
Training loss: 1.0390567779541016
Validation loss: 1.8211674485155331

Epoch: 6| Step: 1
Training loss: 0.7109006643295288
Validation loss: 1.8293789432894798

Epoch: 6| Step: 2
Training loss: 1.222329020500183
Validation loss: 1.8640302791390368

Epoch: 6| Step: 3
Training loss: 0.9512833952903748
Validation loss: 1.879276466625993

Epoch: 6| Step: 4
Training loss: 0.7884804010391235
Validation loss: 1.881364050731864

Epoch: 6| Step: 5
Training loss: 0.5687053203582764
Validation loss: 1.919906754647532

Epoch: 6| Step: 6
Training loss: 0.8136597871780396
Validation loss: 1.858989845040024

Epoch: 6| Step: 7
Training loss: 0.588089108467102
Validation loss: 1.8029131261251305

Epoch: 6| Step: 8
Training loss: 0.8665593862533569
Validation loss: 1.7656875425769436

Epoch: 6| Step: 9
Training loss: 1.2749618291854858
Validation loss: 1.7703519354584396

Epoch: 6| Step: 10
Training loss: 0.7794545888900757
Validation loss: 1.7690798249295963

Epoch: 6| Step: 11
Training loss: 0.7759409546852112
Validation loss: 1.7832115542504094

Epoch: 6| Step: 12
Training loss: 1.0647385120391846
Validation loss: 1.7780952184431014

Epoch: 6| Step: 13
Training loss: 0.817245364189148
Validation loss: 1.853453795115153

Epoch: 240| Step: 0
Training loss: 1.0215413570404053
Validation loss: 1.897074148219119

Epoch: 6| Step: 1
Training loss: 0.748363196849823
Validation loss: 2.029036546266207

Epoch: 6| Step: 2
Training loss: 1.2355291843414307
Validation loss: 2.0631193896775604

Epoch: 6| Step: 3
Training loss: 0.5351623296737671
Validation loss: 2.082447277602329

Epoch: 6| Step: 4
Training loss: 1.0714452266693115
Validation loss: 2.0252811049902313

Epoch: 6| Step: 5
Training loss: 1.516019344329834
Validation loss: 1.9527385811651907

Epoch: 6| Step: 6
Training loss: 1.1469049453735352
Validation loss: 1.8717031581427461

Epoch: 6| Step: 7
Training loss: 0.888904333114624
Validation loss: 1.8179210885878532

Epoch: 6| Step: 8
Training loss: 0.6941982507705688
Validation loss: 1.7985145597047703

Epoch: 6| Step: 9
Training loss: 1.0756416320800781
Validation loss: 1.7947123114780714

Epoch: 6| Step: 10
Training loss: 0.44162458181381226
Validation loss: 1.811121125375071

Epoch: 6| Step: 11
Training loss: 0.8169184327125549
Validation loss: 1.8280905856881091

Epoch: 6| Step: 12
Training loss: 0.48560991883277893
Validation loss: 1.8454002334225563

Epoch: 6| Step: 13
Training loss: 0.8882449269294739
Validation loss: 1.884509672400772

Epoch: 241| Step: 0
Training loss: 1.0528655052185059
Validation loss: 1.8621815314856909

Epoch: 6| Step: 1
Training loss: 0.8289512991905212
Validation loss: 1.8618787065629037

Epoch: 6| Step: 2
Training loss: 0.905552864074707
Validation loss: 1.8159247829068093

Epoch: 6| Step: 3
Training loss: 1.0456489324569702
Validation loss: 1.8201366650160922

Epoch: 6| Step: 4
Training loss: 1.0890777111053467
Validation loss: 1.8243651569530528

Epoch: 6| Step: 5
Training loss: 0.952184796333313
Validation loss: 1.8123470416633032

Epoch: 6| Step: 6
Training loss: 0.9630290865898132
Validation loss: 1.8125220550003873

Epoch: 6| Step: 7
Training loss: 0.6798269152641296
Validation loss: 1.8096924379307737

Epoch: 6| Step: 8
Training loss: 0.9695954918861389
Validation loss: 1.8134318192799885

Epoch: 6| Step: 9
Training loss: 0.4266536831855774
Validation loss: 1.839127839252513

Epoch: 6| Step: 10
Training loss: 0.8215745091438293
Validation loss: 1.897827556056361

Epoch: 6| Step: 11
Training loss: 0.9489850997924805
Validation loss: 1.955260056321339

Epoch: 6| Step: 12
Training loss: 0.8739984631538391
Validation loss: 1.9782808416633195

Epoch: 6| Step: 13
Training loss: 0.4393771290779114
Validation loss: 1.9521841259412869

Epoch: 242| Step: 0
Training loss: 1.076204538345337
Validation loss: 1.8643283100538357

Epoch: 6| Step: 1
Training loss: 0.8603179454803467
Validation loss: 1.8174734935965589

Epoch: 6| Step: 2
Training loss: 0.7470967769622803
Validation loss: 1.7781673592905844

Epoch: 6| Step: 3
Training loss: 0.74339759349823
Validation loss: 1.8187035258098314

Epoch: 6| Step: 4
Training loss: 0.6703412532806396
Validation loss: 1.812269647916158

Epoch: 6| Step: 5
Training loss: 0.6961407661437988
Validation loss: 1.8128841730856127

Epoch: 6| Step: 6
Training loss: 1.1270891427993774
Validation loss: 1.8008611253512803

Epoch: 6| Step: 7
Training loss: 0.5367794632911682
Validation loss: 1.826859563909551

Epoch: 6| Step: 8
Training loss: 0.5873992443084717
Validation loss: 1.8516634894955544

Epoch: 6| Step: 9
Training loss: 1.3721766471862793
Validation loss: 1.8753311275154032

Epoch: 6| Step: 10
Training loss: 0.716340184211731
Validation loss: 1.9080378368336668

Epoch: 6| Step: 11
Training loss: 0.8094350695610046
Validation loss: 1.9153051248160742

Epoch: 6| Step: 12
Training loss: 0.9296749830245972
Validation loss: 1.8849679757190008

Epoch: 6| Step: 13
Training loss: 0.96634441614151
Validation loss: 1.9174715690715338

Epoch: 243| Step: 0
Training loss: 1.128645658493042
Validation loss: 1.910890169041131

Epoch: 6| Step: 1
Training loss: 1.3394086360931396
Validation loss: 1.9075197071157477

Epoch: 6| Step: 2
Training loss: 1.1016194820404053
Validation loss: 1.8589359457774828

Epoch: 6| Step: 3
Training loss: 0.8357768058776855
Validation loss: 1.8265697276720436

Epoch: 6| Step: 4
Training loss: 0.9407142400741577
Validation loss: 1.814218649300196

Epoch: 6| Step: 5
Training loss: 0.5635573863983154
Validation loss: 1.8311911552183089

Epoch: 6| Step: 6
Training loss: 0.6527883410453796
Validation loss: 1.8034672583303144

Epoch: 6| Step: 7
Training loss: 0.5111756324768066
Validation loss: 1.8064908622413554

Epoch: 6| Step: 8
Training loss: 0.8821775913238525
Validation loss: 1.8127443700708368

Epoch: 6| Step: 9
Training loss: 0.6130992770195007
Validation loss: 1.8176205081324424

Epoch: 6| Step: 10
Training loss: 0.5359383821487427
Validation loss: 1.813227213839049

Epoch: 6| Step: 11
Training loss: 0.6235561370849609
Validation loss: 1.8056182861328125

Epoch: 6| Step: 12
Training loss: 0.9001345634460449
Validation loss: 1.8017162802398845

Epoch: 6| Step: 13
Training loss: 0.8643373847007751
Validation loss: 1.8121177945085751

Epoch: 244| Step: 0
Training loss: 1.1896905899047852
Validation loss: 1.817596976475049

Epoch: 6| Step: 1
Training loss: 0.7753053903579712
Validation loss: 1.783535244644329

Epoch: 6| Step: 2
Training loss: 0.4951059818267822
Validation loss: 1.8129664826136764

Epoch: 6| Step: 3
Training loss: 1.192598581314087
Validation loss: 1.7996288973798034

Epoch: 6| Step: 4
Training loss: 0.4428606629371643
Validation loss: 1.8372356660904423

Epoch: 6| Step: 5
Training loss: 0.675722599029541
Validation loss: 1.8357668243428713

Epoch: 6| Step: 6
Training loss: 0.8648457527160645
Validation loss: 1.8829659210738314

Epoch: 6| Step: 7
Training loss: 0.7652531266212463
Validation loss: 1.907076742059441

Epoch: 6| Step: 8
Training loss: 0.8915176391601562
Validation loss: 1.9476739860350085

Epoch: 6| Step: 9
Training loss: 0.525328516960144
Validation loss: 1.9481444025552401

Epoch: 6| Step: 10
Training loss: 1.0386273860931396
Validation loss: 1.9085337577327606

Epoch: 6| Step: 11
Training loss: 0.7703787088394165
Validation loss: 1.8670224053885347

Epoch: 6| Step: 12
Training loss: 0.9169260263442993
Validation loss: 1.8025518335321897

Epoch: 6| Step: 13
Training loss: 0.4815639853477478
Validation loss: 1.7707960759439776

Epoch: 245| Step: 0
Training loss: 0.951482892036438
Validation loss: 1.7825381550737607

Epoch: 6| Step: 1
Training loss: 1.0068538188934326
Validation loss: 1.8034887429206603

Epoch: 6| Step: 2
Training loss: 0.6623508930206299
Validation loss: 1.8139645720040927

Epoch: 6| Step: 3
Training loss: 0.4735986888408661
Validation loss: 1.7881083962737874

Epoch: 6| Step: 4
Training loss: 0.9988476037979126
Validation loss: 1.8099539523483605

Epoch: 6| Step: 5
Training loss: 0.6411796808242798
Validation loss: 1.8076370005966516

Epoch: 6| Step: 6
Training loss: 0.7794313430786133
Validation loss: 1.8546220871710009

Epoch: 6| Step: 7
Training loss: 0.9186460971832275
Validation loss: 1.8687233130137126

Epoch: 6| Step: 8
Training loss: 0.9117375016212463
Validation loss: 1.8604670865561372

Epoch: 6| Step: 9
Training loss: 0.8145380020141602
Validation loss: 1.8582025471554007

Epoch: 6| Step: 10
Training loss: 0.6500817537307739
Validation loss: 1.8396670741419638

Epoch: 6| Step: 11
Training loss: 0.5860542058944702
Validation loss: 1.837932184178342

Epoch: 6| Step: 12
Training loss: 0.5734422206878662
Validation loss: 1.8105378945668538

Epoch: 6| Step: 13
Training loss: 1.1801897287368774
Validation loss: 1.7942565461640716

Epoch: 246| Step: 0
Training loss: 0.9554567933082581
Validation loss: 1.812328456550516

Epoch: 6| Step: 1
Training loss: 0.7673174142837524
Validation loss: 1.8016050989909838

Epoch: 6| Step: 2
Training loss: 0.5982091426849365
Validation loss: 1.791099799576626

Epoch: 6| Step: 3
Training loss: 0.7303195595741272
Validation loss: 1.780667208856152

Epoch: 6| Step: 4
Training loss: 0.6830742359161377
Validation loss: 1.8270596483702302

Epoch: 6| Step: 5
Training loss: 0.6696333885192871
Validation loss: 1.846576065145513

Epoch: 6| Step: 6
Training loss: 0.9560564756393433
Validation loss: 1.8976182783803632

Epoch: 6| Step: 7
Training loss: 1.185765027999878
Validation loss: 1.942879948564755

Epoch: 6| Step: 8
Training loss: 0.8141705989837646
Validation loss: 1.8747419746973182

Epoch: 6| Step: 9
Training loss: 0.8671724796295166
Validation loss: 1.782159254115115

Epoch: 6| Step: 10
Training loss: 0.736554741859436
Validation loss: 1.7734256021438106

Epoch: 6| Step: 11
Training loss: 1.0861358642578125
Validation loss: 1.756750419575681

Epoch: 6| Step: 12
Training loss: 0.6620662808418274
Validation loss: 1.7628472851168724

Epoch: 6| Step: 13
Training loss: 0.9005861282348633
Validation loss: 1.7618183089840798

Epoch: 247| Step: 0
Training loss: 0.4237167239189148
Validation loss: 1.764809359786331

Epoch: 6| Step: 1
Training loss: 0.9999855160713196
Validation loss: 1.7569139401117961

Epoch: 6| Step: 2
Training loss: 0.6706752181053162
Validation loss: 1.8388237555821736

Epoch: 6| Step: 3
Training loss: 0.7815455794334412
Validation loss: 1.918954897952336

Epoch: 6| Step: 4
Training loss: 1.0862234830856323
Validation loss: 1.9592161947681057

Epoch: 6| Step: 5
Training loss: 0.6840075254440308
Validation loss: 1.9609138709242626

Epoch: 6| Step: 6
Training loss: 0.9349798560142517
Validation loss: 1.9304897400640673

Epoch: 6| Step: 7
Training loss: 1.0273877382278442
Validation loss: 1.8686079927670058

Epoch: 6| Step: 8
Training loss: 1.131246566772461
Validation loss: 1.8091360163945023

Epoch: 6| Step: 9
Training loss: 0.8565605282783508
Validation loss: 1.8234961519959152

Epoch: 6| Step: 10
Training loss: 0.9858935475349426
Validation loss: 1.8390017247969104

Epoch: 6| Step: 11
Training loss: 0.5362838506698608
Validation loss: 1.7910432815551758

Epoch: 6| Step: 12
Training loss: 0.7686542272567749
Validation loss: 1.798880894978841

Epoch: 6| Step: 13
Training loss: 0.7202282547950745
Validation loss: 1.8295458298857494

Epoch: 248| Step: 0
Training loss: 0.965709924697876
Validation loss: 1.7917215144762428

Epoch: 6| Step: 1
Training loss: 0.7786248922348022
Validation loss: 1.830499586238656

Epoch: 6| Step: 2
Training loss: 0.7910219430923462
Validation loss: 1.8354556252879481

Epoch: 6| Step: 3
Training loss: 0.6885441541671753
Validation loss: 1.8424649046313377

Epoch: 6| Step: 4
Training loss: 0.5365639925003052
Validation loss: 1.8626220123742216

Epoch: 6| Step: 5
Training loss: 0.7182353734970093
Validation loss: 1.8656164984549246

Epoch: 6| Step: 6
Training loss: 0.5640676021575928
Validation loss: 1.8099620701164327

Epoch: 6| Step: 7
Training loss: 1.2204058170318604
Validation loss: 1.7983325912106423

Epoch: 6| Step: 8
Training loss: 0.7253624796867371
Validation loss: 1.818265047124637

Epoch: 6| Step: 9
Training loss: 0.9437144994735718
Validation loss: 1.8230427029312297

Epoch: 6| Step: 10
Training loss: 0.7500261664390564
Validation loss: 1.8374265457994194

Epoch: 6| Step: 11
Training loss: 0.6353641748428345
Validation loss: 1.8481722877871605

Epoch: 6| Step: 12
Training loss: 0.7590519785881042
Validation loss: 1.8346446944821266

Epoch: 6| Step: 13
Training loss: 0.5467935800552368
Validation loss: 1.8288895237830378

Epoch: 249| Step: 0
Training loss: 0.6390047669410706
Validation loss: 1.8696724817317019

Epoch: 6| Step: 1
Training loss: 0.5156422853469849
Validation loss: 1.8678321056468512

Epoch: 6| Step: 2
Training loss: 0.7544407844543457
Validation loss: 1.8344049620371994

Epoch: 6| Step: 3
Training loss: 0.5810768604278564
Validation loss: 1.8158973032428372

Epoch: 6| Step: 4
Training loss: 0.49421727657318115
Validation loss: 1.779687839169656

Epoch: 6| Step: 5
Training loss: 0.5883176326751709
Validation loss: 1.7901629094154603

Epoch: 6| Step: 6
Training loss: 0.998103141784668
Validation loss: 1.7707115193848968

Epoch: 6| Step: 7
Training loss: 0.7645008563995361
Validation loss: 1.7821451848553074

Epoch: 6| Step: 8
Training loss: 1.2514457702636719
Validation loss: 1.7459366654837003

Epoch: 6| Step: 9
Training loss: 0.9793884754180908
Validation loss: 1.7514868564503168

Epoch: 6| Step: 10
Training loss: 1.0200462341308594
Validation loss: 1.809159094287503

Epoch: 6| Step: 11
Training loss: 0.6245881915092468
Validation loss: 1.8287178803515691

Epoch: 6| Step: 12
Training loss: 0.8251944184303284
Validation loss: 1.8397235652451873

Epoch: 6| Step: 13
Training loss: 0.5099242329597473
Validation loss: 1.8617940231036114

Epoch: 250| Step: 0
Training loss: 0.802681028842926
Validation loss: 1.8480994073293542

Epoch: 6| Step: 1
Training loss: 0.6313210129737854
Validation loss: 1.8477727020940473

Epoch: 6| Step: 2
Training loss: 0.5930379033088684
Validation loss: 1.798730888674336

Epoch: 6| Step: 3
Training loss: 0.595353364944458
Validation loss: 1.810936197157829

Epoch: 6| Step: 4
Training loss: 0.6957554221153259
Validation loss: 1.8262048959732056

Epoch: 6| Step: 5
Training loss: 0.49853599071502686
Validation loss: 1.8062552828942575

Epoch: 6| Step: 6
Training loss: 0.8388692140579224
Validation loss: 1.8346813596704954

Epoch: 6| Step: 7
Training loss: 0.9363338947296143
Validation loss: 1.8243068905286892

Epoch: 6| Step: 8
Training loss: 0.7394826412200928
Validation loss: 1.8455720088815177

Epoch: 6| Step: 9
Training loss: 1.2379907369613647
Validation loss: 1.8986880971539406

Epoch: 6| Step: 10
Training loss: 0.6779388189315796
Validation loss: 1.877559713138047

Epoch: 6| Step: 11
Training loss: 1.0077927112579346
Validation loss: 1.9045679338516728

Epoch: 6| Step: 12
Training loss: 0.5761393904685974
Validation loss: 1.8873674305536414

Epoch: 6| Step: 13
Training loss: 1.238176941871643
Validation loss: 1.8622484796790666

Epoch: 251| Step: 0
Training loss: 0.8305823802947998
Validation loss: 1.8620720973578833

Epoch: 6| Step: 1
Training loss: 0.7841356992721558
Validation loss: 1.8122102637444772

Epoch: 6| Step: 2
Training loss: 0.9116036891937256
Validation loss: 1.8132817206844207

Epoch: 6| Step: 3
Training loss: 0.7042438387870789
Validation loss: 1.8143164316813152

Epoch: 6| Step: 4
Training loss: 0.6805827617645264
Validation loss: 1.7665563424428303

Epoch: 6| Step: 5
Training loss: 0.5713463425636292
Validation loss: 1.7703462749399164

Epoch: 6| Step: 6
Training loss: 0.7937266826629639
Validation loss: 1.7743112771741805

Epoch: 6| Step: 7
Training loss: 0.9265674352645874
Validation loss: 1.7264266334554201

Epoch: 6| Step: 8
Training loss: 0.9427880048751831
Validation loss: 1.759069344048859

Epoch: 6| Step: 9
Training loss: 0.7015269994735718
Validation loss: 1.7726005610599314

Epoch: 6| Step: 10
Training loss: 0.5698760747909546
Validation loss: 1.7858920110169278

Epoch: 6| Step: 11
Training loss: 0.5818302035331726
Validation loss: 1.822874746014995

Epoch: 6| Step: 12
Training loss: 0.6821449995040894
Validation loss: 1.8276424254140546

Epoch: 6| Step: 13
Training loss: 0.8403864502906799
Validation loss: 1.8382340579904535

Epoch: 252| Step: 0
Training loss: 0.7296888828277588
Validation loss: 1.844566942543112

Epoch: 6| Step: 1
Training loss: 0.2330482006072998
Validation loss: 1.8250406301149757

Epoch: 6| Step: 2
Training loss: 0.8334361910820007
Validation loss: 1.8047858412547777

Epoch: 6| Step: 3
Training loss: 0.876901388168335
Validation loss: 1.7965495560758857

Epoch: 6| Step: 4
Training loss: 0.9407711029052734
Validation loss: 1.8107682543416177

Epoch: 6| Step: 5
Training loss: 1.2512822151184082
Validation loss: 1.8117727477063414

Epoch: 6| Step: 6
Training loss: 0.6295973062515259
Validation loss: 1.819065486231158

Epoch: 6| Step: 7
Training loss: 0.3069659471511841
Validation loss: 1.7745022363560174

Epoch: 6| Step: 8
Training loss: 0.8476881384849548
Validation loss: 1.803368014674033

Epoch: 6| Step: 9
Training loss: 0.4103226661682129
Validation loss: 1.7951203841035084

Epoch: 6| Step: 10
Training loss: 0.9986838102340698
Validation loss: 1.7874049063651793

Epoch: 6| Step: 11
Training loss: 0.7347299456596375
Validation loss: 1.8168448735308904

Epoch: 6| Step: 12
Training loss: 0.7807981967926025
Validation loss: 1.7958964327330231

Epoch: 6| Step: 13
Training loss: 0.5288602113723755
Validation loss: 1.7789024922155565

Epoch: 253| Step: 0
Training loss: 0.7996833324432373
Validation loss: 1.7422642323278612

Epoch: 6| Step: 1
Training loss: 0.7697805762290955
Validation loss: 1.746931674659893

Epoch: 6| Step: 2
Training loss: 0.6810183525085449
Validation loss: 1.7385305781518259

Epoch: 6| Step: 3
Training loss: 0.8055132627487183
Validation loss: 1.7487274651886315

Epoch: 6| Step: 4
Training loss: 0.5793194770812988
Validation loss: 1.7834213343999719

Epoch: 6| Step: 5
Training loss: 0.659320056438446
Validation loss: 1.824607232565521

Epoch: 6| Step: 6
Training loss: 0.8566501140594482
Validation loss: 1.8355362428131925

Epoch: 6| Step: 7
Training loss: 0.82767254114151
Validation loss: 1.8592969268880866

Epoch: 6| Step: 8
Training loss: 0.6032264828681946
Validation loss: 1.8644695102527578

Epoch: 6| Step: 9
Training loss: 0.7341197729110718
Validation loss: 1.8023336830959524

Epoch: 6| Step: 10
Training loss: 1.1516205072402954
Validation loss: 1.8350802031896447

Epoch: 6| Step: 11
Training loss: 0.22005680203437805
Validation loss: 1.8001803787805701

Epoch: 6| Step: 12
Training loss: 0.5866060256958008
Validation loss: 1.7828287155397478

Epoch: 6| Step: 13
Training loss: 0.5694836378097534
Validation loss: 1.7802322397949875

Epoch: 254| Step: 0
Training loss: 0.9245347380638123
Validation loss: 1.7503471130965857

Epoch: 6| Step: 1
Training loss: 1.2767679691314697
Validation loss: 1.756320054813098

Epoch: 6| Step: 2
Training loss: 0.5607941746711731
Validation loss: 1.7431946275054768

Epoch: 6| Step: 3
Training loss: 0.7221060991287231
Validation loss: 1.7456832649887248

Epoch: 6| Step: 4
Training loss: 0.613557755947113
Validation loss: 1.7753280772957751

Epoch: 6| Step: 5
Training loss: 0.9153524041175842
Validation loss: 1.8093347619938593

Epoch: 6| Step: 6
Training loss: 0.5478972792625427
Validation loss: 1.8331025031305128

Epoch: 6| Step: 7
Training loss: 0.5627825260162354
Validation loss: 1.8440453878013037

Epoch: 6| Step: 8
Training loss: 0.5607972741127014
Validation loss: 1.8576561084357641

Epoch: 6| Step: 9
Training loss: 0.7251745462417603
Validation loss: 1.8172470561919674

Epoch: 6| Step: 10
Training loss: 0.41258928179740906
Validation loss: 1.759024400864878

Epoch: 6| Step: 11
Training loss: 0.7353534698486328
Validation loss: 1.758792322169068

Epoch: 6| Step: 12
Training loss: 0.5640590786933899
Validation loss: 1.7955683662045387

Epoch: 6| Step: 13
Training loss: 1.071347713470459
Validation loss: 1.7550129326440955

Epoch: 255| Step: 0
Training loss: 0.6036964058876038
Validation loss: 1.7546611832034202

Epoch: 6| Step: 1
Training loss: 0.6326982975006104
Validation loss: 1.735933574297095

Epoch: 6| Step: 2
Training loss: 0.6829268932342529
Validation loss: 1.766827647404004

Epoch: 6| Step: 3
Training loss: 0.9292749166488647
Validation loss: 1.8149212688528082

Epoch: 6| Step: 4
Training loss: 0.8216530084609985
Validation loss: 1.8038719290046281

Epoch: 6| Step: 5
Training loss: 0.6098133325576782
Validation loss: 1.7664771054380684

Epoch: 6| Step: 6
Training loss: 0.7892627716064453
Validation loss: 1.7271304181827012

Epoch: 6| Step: 7
Training loss: 0.4974069595336914
Validation loss: 1.7539021686841083

Epoch: 6| Step: 8
Training loss: 0.718153715133667
Validation loss: 1.7396157480055285

Epoch: 6| Step: 9
Training loss: 0.4379171133041382
Validation loss: 1.8049513870669949

Epoch: 6| Step: 10
Training loss: 1.1083552837371826
Validation loss: 1.7989130276505665

Epoch: 6| Step: 11
Training loss: 0.5267651081085205
Validation loss: 1.8096653799856863

Epoch: 6| Step: 12
Training loss: 0.6934108734130859
Validation loss: 1.8647465987872052

Epoch: 6| Step: 13
Training loss: 1.3419756889343262
Validation loss: 1.8353415112341604

Epoch: 256| Step: 0
Training loss: 0.5822008848190308
Validation loss: 1.7923283089873612

Epoch: 6| Step: 1
Training loss: 0.4326396584510803
Validation loss: 1.8311347807607343

Epoch: 6| Step: 2
Training loss: 1.1240034103393555
Validation loss: 1.8221107439328266

Epoch: 6| Step: 3
Training loss: 0.913429856300354
Validation loss: 1.8305925938390917

Epoch: 6| Step: 4
Training loss: 0.7273334860801697
Validation loss: 1.8122522895054152

Epoch: 6| Step: 5
Training loss: 0.30994004011154175
Validation loss: 1.7633887311463714

Epoch: 6| Step: 6
Training loss: 0.6611269116401672
Validation loss: 1.7155449903139504

Epoch: 6| Step: 7
Training loss: 0.6850353479385376
Validation loss: 1.7189330413777342

Epoch: 6| Step: 8
Training loss: 1.031713604927063
Validation loss: 1.7297140129150883

Epoch: 6| Step: 9
Training loss: 0.8507030606269836
Validation loss: 1.738555859493953

Epoch: 6| Step: 10
Training loss: 0.7973707914352417
Validation loss: 1.7627396660466348

Epoch: 6| Step: 11
Training loss: 0.4688166379928589
Validation loss: 1.7968699714188934

Epoch: 6| Step: 12
Training loss: 0.609792947769165
Validation loss: 1.7739782512828868

Epoch: 6| Step: 13
Training loss: 0.8085572719573975
Validation loss: 1.8029261327558948

Epoch: 257| Step: 0
Training loss: 1.5621390342712402
Validation loss: 1.7896617574076499

Epoch: 6| Step: 1
Training loss: 0.6155171394348145
Validation loss: 1.8010255957162509

Epoch: 6| Step: 2
Training loss: 0.7164598703384399
Validation loss: 1.7740406400413924

Epoch: 6| Step: 3
Training loss: 0.6439645886421204
Validation loss: 1.7798920613463207

Epoch: 6| Step: 4
Training loss: 0.734512209892273
Validation loss: 1.7606252175505444

Epoch: 6| Step: 5
Training loss: 0.4106408655643463
Validation loss: 1.762342745257962

Epoch: 6| Step: 6
Training loss: 0.6692667603492737
Validation loss: 1.7560076367470525

Epoch: 6| Step: 7
Training loss: 0.7414112091064453
Validation loss: 1.7559943468339982

Epoch: 6| Step: 8
Training loss: 0.3708009421825409
Validation loss: 1.7543588594723774

Epoch: 6| Step: 9
Training loss: 1.0841035842895508
Validation loss: 1.7565487059213782

Epoch: 6| Step: 10
Training loss: 0.4281938672065735
Validation loss: 1.769153869280251

Epoch: 6| Step: 11
Training loss: 0.6241629719734192
Validation loss: 1.7379959206427298

Epoch: 6| Step: 12
Training loss: 0.6011273264884949
Validation loss: 1.7704089572352748

Epoch: 6| Step: 13
Training loss: 0.20017464458942413
Validation loss: 1.8037235531755673

Epoch: 258| Step: 0
Training loss: 0.6878049373626709
Validation loss: 1.8369684808997697

Epoch: 6| Step: 1
Training loss: 0.3818163573741913
Validation loss: 1.8366336463600077

Epoch: 6| Step: 2
Training loss: 0.9172159433364868
Validation loss: 1.7843667332844069

Epoch: 6| Step: 3
Training loss: 0.8259280920028687
Validation loss: 1.7710217493836597

Epoch: 6| Step: 4
Training loss: 0.5403435826301575
Validation loss: 1.7451312554779874

Epoch: 6| Step: 5
Training loss: 0.9904922246932983
Validation loss: 1.7185780540589364

Epoch: 6| Step: 6
Training loss: 1.0457470417022705
Validation loss: 1.7295093459467734

Epoch: 6| Step: 7
Training loss: 0.3655947744846344
Validation loss: 1.7594001959728938

Epoch: 6| Step: 8
Training loss: 0.8620597720146179
Validation loss: 1.7351720217735536

Epoch: 6| Step: 9
Training loss: 0.7539954781532288
Validation loss: 1.763663068894417

Epoch: 6| Step: 10
Training loss: 0.6643497943878174
Validation loss: 1.7781819733240272

Epoch: 6| Step: 11
Training loss: 0.9241714477539062
Validation loss: 1.7894256948142924

Epoch: 6| Step: 12
Training loss: 0.8480055928230286
Validation loss: 1.8083962202072144

Epoch: 6| Step: 13
Training loss: 0.07890573889017105
Validation loss: 1.8137379346355316

Epoch: 259| Step: 0
Training loss: 0.6346705555915833
Validation loss: 1.8206007980531262

Epoch: 6| Step: 1
Training loss: 0.6628410816192627
Validation loss: 1.8287104791210544

Epoch: 6| Step: 2
Training loss: 0.39175939559936523
Validation loss: 1.8402443073129142

Epoch: 6| Step: 3
Training loss: 0.41012951731681824
Validation loss: 1.770891458757462

Epoch: 6| Step: 4
Training loss: 0.6439378261566162
Validation loss: 1.763886905485584

Epoch: 6| Step: 5
Training loss: 0.9648289680480957
Validation loss: 1.7561273485101678

Epoch: 6| Step: 6
Training loss: 0.8143249154090881
Validation loss: 1.7597615436841083

Epoch: 6| Step: 7
Training loss: 0.8645880222320557
Validation loss: 1.7582517849501742

Epoch: 6| Step: 8
Training loss: 1.1839600801467896
Validation loss: 1.7480350155984201

Epoch: 6| Step: 9
Training loss: 0.9263081550598145
Validation loss: 1.7087117023365472

Epoch: 6| Step: 10
Training loss: 0.7324168086051941
Validation loss: 1.7146036919727121

Epoch: 6| Step: 11
Training loss: 0.5448148846626282
Validation loss: 1.7040534288652482

Epoch: 6| Step: 12
Training loss: 0.45151492953300476
Validation loss: 1.7044912692039245

Epoch: 6| Step: 13
Training loss: 0.5808813571929932
Validation loss: 1.7226890902365408

Epoch: 260| Step: 0
Training loss: 0.5117318630218506
Validation loss: 1.7785083683588172

Epoch: 6| Step: 1
Training loss: 0.549041211605072
Validation loss: 1.816876772911318

Epoch: 6| Step: 2
Training loss: 1.1823400259017944
Validation loss: 1.8660623642706102

Epoch: 6| Step: 3
Training loss: 0.7706851363182068
Validation loss: 1.8756320886714484

Epoch: 6| Step: 4
Training loss: 0.5485813617706299
Validation loss: 1.83752715715798

Epoch: 6| Step: 5
Training loss: 0.44318872690200806
Validation loss: 1.7950320884745607

Epoch: 6| Step: 6
Training loss: 0.4071999788284302
Validation loss: 1.7722933170615986

Epoch: 6| Step: 7
Training loss: 0.519169807434082
Validation loss: 1.7404915261012253

Epoch: 6| Step: 8
Training loss: 1.0488934516906738
Validation loss: 1.7307277623043265

Epoch: 6| Step: 9
Training loss: 0.6311195492744446
Validation loss: 1.7372201565773255

Epoch: 6| Step: 10
Training loss: 0.6227818727493286
Validation loss: 1.7531518167065037

Epoch: 6| Step: 11
Training loss: 1.3137130737304688
Validation loss: 1.7713387461118801

Epoch: 6| Step: 12
Training loss: 0.4897367060184479
Validation loss: 1.8244235400230653

Epoch: 6| Step: 13
Training loss: 0.7184668779373169
Validation loss: 1.8106776680997623

Epoch: 261| Step: 0
Training loss: 0.6316521167755127
Validation loss: 1.8213248355414278

Epoch: 6| Step: 1
Training loss: 0.693312406539917
Validation loss: 1.779465154934955

Epoch: 6| Step: 2
Training loss: 0.6257474422454834
Validation loss: 1.7479003437103764

Epoch: 6| Step: 3
Training loss: 0.7807813882827759
Validation loss: 1.7437164565568328

Epoch: 6| Step: 4
Training loss: 0.4849516451358795
Validation loss: 1.7676510157123688

Epoch: 6| Step: 5
Training loss: 0.9519418478012085
Validation loss: 1.7534507602773688

Epoch: 6| Step: 6
Training loss: 0.9800933003425598
Validation loss: 1.8044804873005036

Epoch: 6| Step: 7
Training loss: 0.6989123821258545
Validation loss: 1.7885236201747772

Epoch: 6| Step: 8
Training loss: 0.32649850845336914
Validation loss: 1.7859346430788758

Epoch: 6| Step: 9
Training loss: 1.1342557668685913
Validation loss: 1.7970083464858353

Epoch: 6| Step: 10
Training loss: 0.5023801326751709
Validation loss: 1.7831139256877284

Epoch: 6| Step: 11
Training loss: 0.5637482404708862
Validation loss: 1.7861917775164369

Epoch: 6| Step: 12
Training loss: 0.4988948106765747
Validation loss: 1.7681099484043736

Epoch: 6| Step: 13
Training loss: 0.4902738928794861
Validation loss: 1.7606717143007504

Epoch: 262| Step: 0
Training loss: 0.7108624577522278
Validation loss: 1.7451836345016316

Epoch: 6| Step: 1
Training loss: 0.9050148129463196
Validation loss: 1.777178910470778

Epoch: 6| Step: 2
Training loss: 1.2867465019226074
Validation loss: 1.787054387472009

Epoch: 6| Step: 3
Training loss: 0.30961090326309204
Validation loss: 1.7636240400293821

Epoch: 6| Step: 4
Training loss: 0.625119686126709
Validation loss: 1.791483147169954

Epoch: 6| Step: 5
Training loss: 0.6996908783912659
Validation loss: 1.7820598668949579

Epoch: 6| Step: 6
Training loss: 0.6586072444915771
Validation loss: 1.7618721223646594

Epoch: 6| Step: 7
Training loss: 0.37436604499816895
Validation loss: 1.7652790777144893

Epoch: 6| Step: 8
Training loss: 0.5073797106742859
Validation loss: 1.761271890773568

Epoch: 6| Step: 9
Training loss: 0.45245346426963806
Validation loss: 1.7933638236855949

Epoch: 6| Step: 10
Training loss: 1.0062346458435059
Validation loss: 1.793747208451712

Epoch: 6| Step: 11
Training loss: 0.9182259440422058
Validation loss: 1.7963837987633162

Epoch: 6| Step: 12
Training loss: 0.5043827295303345
Validation loss: 1.7900097280420282

Epoch: 6| Step: 13
Training loss: 0.33222702145576477
Validation loss: 1.7514178534989715

Epoch: 263| Step: 0
Training loss: 0.5223938226699829
Validation loss: 1.7223226037076724

Epoch: 6| Step: 1
Training loss: 0.8407989144325256
Validation loss: 1.7141938978625881

Epoch: 6| Step: 2
Training loss: 0.8639743328094482
Validation loss: 1.6804454390720656

Epoch: 6| Step: 3
Training loss: 0.8118428587913513
Validation loss: 1.6896532991881013

Epoch: 6| Step: 4
Training loss: 0.5140994787216187
Validation loss: 1.7062855048846173

Epoch: 6| Step: 5
Training loss: 0.7255911827087402
Validation loss: 1.7169072935658116

Epoch: 6| Step: 6
Training loss: 0.5115573406219482
Validation loss: 1.7277906556283273

Epoch: 6| Step: 7
Training loss: 0.8869005441665649
Validation loss: 1.729557450099658

Epoch: 6| Step: 8
Training loss: 0.7115136384963989
Validation loss: 1.719480396598898

Epoch: 6| Step: 9
Training loss: 0.8087536692619324
Validation loss: 1.7524646366796186

Epoch: 6| Step: 10
Training loss: 0.7656611204147339
Validation loss: 1.7505753911951536

Epoch: 6| Step: 11
Training loss: 0.48991039395332336
Validation loss: 1.756582131949804

Epoch: 6| Step: 12
Training loss: 0.2766359746456146
Validation loss: 1.696873120082322

Epoch: 6| Step: 13
Training loss: 0.28406471014022827
Validation loss: 1.6949312956102434

Epoch: 264| Step: 0
Training loss: 0.813982367515564
Validation loss: 1.7125333355319114

Epoch: 6| Step: 1
Training loss: 0.8424279093742371
Validation loss: 1.723487454075967

Epoch: 6| Step: 2
Training loss: 0.516696572303772
Validation loss: 1.7353920334128923

Epoch: 6| Step: 3
Training loss: 0.8427923321723938
Validation loss: 1.7732213774035055

Epoch: 6| Step: 4
Training loss: 0.47568008303642273
Validation loss: 1.7796994704072193

Epoch: 6| Step: 5
Training loss: 0.6286168694496155
Validation loss: 1.7720901286730202

Epoch: 6| Step: 6
Training loss: 0.6595820188522339
Validation loss: 1.7466614554005284

Epoch: 6| Step: 7
Training loss: 0.38399776816368103
Validation loss: 1.7402208338501632

Epoch: 6| Step: 8
Training loss: 0.8940663933753967
Validation loss: 1.7334316853554017

Epoch: 6| Step: 9
Training loss: 0.844449520111084
Validation loss: 1.7318159880176667

Epoch: 6| Step: 10
Training loss: 0.4350280165672302
Validation loss: 1.7212183962586105

Epoch: 6| Step: 11
Training loss: 0.3470613360404968
Validation loss: 1.7144797143115793

Epoch: 6| Step: 12
Training loss: 0.6978839635848999
Validation loss: 1.7182502515854374

Epoch: 6| Step: 13
Training loss: 0.6088076233863831
Validation loss: 1.7391886454756542

Epoch: 265| Step: 0
Training loss: 0.5372674465179443
Validation loss: 1.7738966172741306

Epoch: 6| Step: 1
Training loss: 0.4783441126346588
Validation loss: 1.8232403455242034

Epoch: 6| Step: 2
Training loss: 0.8847655057907104
Validation loss: 1.8398918336437595

Epoch: 6| Step: 3
Training loss: 0.3306077718734741
Validation loss: 1.7958453060478292

Epoch: 6| Step: 4
Training loss: 0.555277943611145
Validation loss: 1.7431197345897715

Epoch: 6| Step: 5
Training loss: 0.44093674421310425
Validation loss: 1.6959437260063746

Epoch: 6| Step: 6
Training loss: 0.596103310585022
Validation loss: 1.7000343773954658

Epoch: 6| Step: 7
Training loss: 0.520862340927124
Validation loss: 1.6881045884983514

Epoch: 6| Step: 8
Training loss: 0.6657454371452332
Validation loss: 1.701184070238503

Epoch: 6| Step: 9
Training loss: 0.45999646186828613
Validation loss: 1.679937119125038

Epoch: 6| Step: 10
Training loss: 1.0183475017547607
Validation loss: 1.6942478764441706

Epoch: 6| Step: 11
Training loss: 0.8903223276138306
Validation loss: 1.71457544578019

Epoch: 6| Step: 12
Training loss: 1.0694589614868164
Validation loss: 1.7348480288700392

Epoch: 6| Step: 13
Training loss: 0.5647792220115662
Validation loss: 1.7488577404329855

Epoch: 266| Step: 0
Training loss: 0.5081056356430054
Validation loss: 1.8103166985255417

Epoch: 6| Step: 1
Training loss: 0.715408205986023
Validation loss: 1.8078610358699676

Epoch: 6| Step: 2
Training loss: 0.387694776058197
Validation loss: 1.8335852405076385

Epoch: 6| Step: 3
Training loss: 0.3535109758377075
Validation loss: 1.8122890700576126

Epoch: 6| Step: 4
Training loss: 0.9965565800666809
Validation loss: 1.7381192535482428

Epoch: 6| Step: 5
Training loss: 0.6959479451179504
Validation loss: 1.7234015791646895

Epoch: 6| Step: 6
Training loss: 0.47961530089378357
Validation loss: 1.6790573417499501

Epoch: 6| Step: 7
Training loss: 0.8626943230628967
Validation loss: 1.6656259029142317

Epoch: 6| Step: 8
Training loss: 1.0094062089920044
Validation loss: 1.686015482871763

Epoch: 6| Step: 9
Training loss: 0.910008430480957
Validation loss: 1.6773834151606406

Epoch: 6| Step: 10
Training loss: 0.8060218691825867
Validation loss: 1.7076827018491683

Epoch: 6| Step: 11
Training loss: 0.5139492154121399
Validation loss: 1.7034505169878724

Epoch: 6| Step: 12
Training loss: 0.5309482216835022
Validation loss: 1.6883824903477904

Epoch: 6| Step: 13
Training loss: 0.3437790870666504
Validation loss: 1.7222010576596825

Epoch: 267| Step: 0
Training loss: 0.5033771991729736
Validation loss: 1.7422083654711324

Epoch: 6| Step: 1
Training loss: 0.7463271617889404
Validation loss: 1.747137220956946

Epoch: 6| Step: 2
Training loss: 0.5646913647651672
Validation loss: 1.737401145760731

Epoch: 6| Step: 3
Training loss: 0.6872653961181641
Validation loss: 1.764773690572349

Epoch: 6| Step: 4
Training loss: 0.4557705521583557
Validation loss: 1.732092663805972

Epoch: 6| Step: 5
Training loss: 0.8535509705543518
Validation loss: 1.708166435200681

Epoch: 6| Step: 6
Training loss: 0.8598524928092957
Validation loss: 1.690746525282501

Epoch: 6| Step: 7
Training loss: 0.5621603727340698
Validation loss: 1.7049795363539009

Epoch: 6| Step: 8
Training loss: 0.8152813911437988
Validation loss: 1.719752029706073

Epoch: 6| Step: 9
Training loss: 0.46183377504348755
Validation loss: 1.7082627819430443

Epoch: 6| Step: 10
Training loss: 0.5712857246398926
Validation loss: 1.6838483887334024

Epoch: 6| Step: 11
Training loss: 0.6781952381134033
Validation loss: 1.669068141650128

Epoch: 6| Step: 12
Training loss: 0.4738733768463135
Validation loss: 1.6931202257833173

Epoch: 6| Step: 13
Training loss: 0.7084969878196716
Validation loss: 1.688823594841906

Epoch: 268| Step: 0
Training loss: 1.023007869720459
Validation loss: 1.6774254409215783

Epoch: 6| Step: 1
Training loss: 0.6296604871749878
Validation loss: 1.6973266383653045

Epoch: 6| Step: 2
Training loss: 0.7810876965522766
Validation loss: 1.7269426853426042

Epoch: 6| Step: 3
Training loss: 0.49351203441619873
Validation loss: 1.724413461582635

Epoch: 6| Step: 4
Training loss: 0.6513776779174805
Validation loss: 1.7546987943751837

Epoch: 6| Step: 5
Training loss: 0.645984411239624
Validation loss: 1.764478983417634

Epoch: 6| Step: 6
Training loss: 0.49307578802108765
Validation loss: 1.7557125014643515

Epoch: 6| Step: 7
Training loss: 0.4198817014694214
Validation loss: 1.7385046533358994

Epoch: 6| Step: 8
Training loss: 0.5134481191635132
Validation loss: 1.7267922778283396

Epoch: 6| Step: 9
Training loss: 0.6439700126647949
Validation loss: 1.7199700224784114

Epoch: 6| Step: 10
Training loss: 0.5380395650863647
Validation loss: 1.6709281949586765

Epoch: 6| Step: 11
Training loss: 0.7066329121589661
Validation loss: 1.6653853206224338

Epoch: 6| Step: 12
Training loss: 0.6747733354568481
Validation loss: 1.6707232357353292

Epoch: 6| Step: 13
Training loss: 0.4726249873638153
Validation loss: 1.6503822201041765

Epoch: 269| Step: 0
Training loss: 0.7417567372322083
Validation loss: 1.6664323268398162

Epoch: 6| Step: 1
Training loss: 0.4920418858528137
Validation loss: 1.682659428606751

Epoch: 6| Step: 2
Training loss: 0.7994250059127808
Validation loss: 1.6828036641561857

Epoch: 6| Step: 3
Training loss: 0.5592410564422607
Validation loss: 1.6916496881874659

Epoch: 6| Step: 4
Training loss: 0.7783641219139099
Validation loss: 1.7022307636917278

Epoch: 6| Step: 5
Training loss: 0.3626613914966583
Validation loss: 1.735326006848325

Epoch: 6| Step: 6
Training loss: 0.714530348777771
Validation loss: 1.784569868477442

Epoch: 6| Step: 7
Training loss: 0.7222445011138916
Validation loss: 1.8422673915022163

Epoch: 6| Step: 8
Training loss: 0.884462833404541
Validation loss: 1.889734205379281

Epoch: 6| Step: 9
Training loss: 0.7606582045555115
Validation loss: 1.8916966915130615

Epoch: 6| Step: 10
Training loss: 0.8591935634613037
Validation loss: 1.8001466604971117

Epoch: 6| Step: 11
Training loss: 0.43995481729507446
Validation loss: 1.7299532121227634

Epoch: 6| Step: 12
Training loss: 0.3929644227027893
Validation loss: 1.7105301682667067

Epoch: 6| Step: 13
Training loss: 0.6982854604721069
Validation loss: 1.6810245667734454

Epoch: 270| Step: 0
Training loss: 0.6868948936462402
Validation loss: 1.6947268273240776

Epoch: 6| Step: 1
Training loss: 0.5688074827194214
Validation loss: 1.6832071940104167

Epoch: 6| Step: 2
Training loss: 0.7539808750152588
Validation loss: 1.6689961148846535

Epoch: 6| Step: 3
Training loss: 0.6474093198776245
Validation loss: 1.6796790476768249

Epoch: 6| Step: 4
Training loss: 0.7711122035980225
Validation loss: 1.6725048288222282

Epoch: 6| Step: 5
Training loss: 0.8420810699462891
Validation loss: 1.7477299936356083

Epoch: 6| Step: 6
Training loss: 0.5973752737045288
Validation loss: 1.7792142834714664

Epoch: 6| Step: 7
Training loss: 0.44280117750167847
Validation loss: 1.8185199896494548

Epoch: 6| Step: 8
Training loss: 0.676148533821106
Validation loss: 1.8789013483191048

Epoch: 6| Step: 9
Training loss: 0.6887261867523193
Validation loss: 1.8808278319656209

Epoch: 6| Step: 10
Training loss: 0.6614277362823486
Validation loss: 1.8759210442983976

Epoch: 6| Step: 11
Training loss: 0.7491472959518433
Validation loss: 1.82135683490384

Epoch: 6| Step: 12
Training loss: 0.5153974294662476
Validation loss: 1.7923440151317145

Epoch: 6| Step: 13
Training loss: 0.7190290689468384
Validation loss: 1.7960168776973602

Epoch: 271| Step: 0
Training loss: 1.2844284772872925
Validation loss: 1.774120009073647

Epoch: 6| Step: 1
Training loss: 0.5930920243263245
Validation loss: 1.7418076428033973

Epoch: 6| Step: 2
Training loss: 1.1166975498199463
Validation loss: 1.7134932382132417

Epoch: 6| Step: 3
Training loss: 0.7386187314987183
Validation loss: 1.7125239679890294

Epoch: 6| Step: 4
Training loss: 0.5034352540969849
Validation loss: 1.7146913607915242

Epoch: 6| Step: 5
Training loss: 0.4600299596786499
Validation loss: 1.7207639755741242

Epoch: 6| Step: 6
Training loss: 0.5964314937591553
Validation loss: 1.6956980369424308

Epoch: 6| Step: 7
Training loss: 0.37500864267349243
Validation loss: 1.6915590224727508

Epoch: 6| Step: 8
Training loss: 0.41023463010787964
Validation loss: 1.6806886683228195

Epoch: 6| Step: 9
Training loss: 0.3914485573768616
Validation loss: 1.698300958961569

Epoch: 6| Step: 10
Training loss: 0.7924334406852722
Validation loss: 1.7855423112069406

Epoch: 6| Step: 11
Training loss: 0.7111956477165222
Validation loss: 1.7840481073625627

Epoch: 6| Step: 12
Training loss: 0.3923312723636627
Validation loss: 1.8514395631769651

Epoch: 6| Step: 13
Training loss: 0.6664427518844604
Validation loss: 1.8847116513918805

Epoch: 272| Step: 0
Training loss: 0.8892021775245667
Validation loss: 1.8179067322002944

Epoch: 6| Step: 1
Training loss: 0.6338032484054565
Validation loss: 1.7935749689737956

Epoch: 6| Step: 2
Training loss: 0.4074150025844574
Validation loss: 1.7551922785338534

Epoch: 6| Step: 3
Training loss: 0.6330217123031616
Validation loss: 1.7239836018572572

Epoch: 6| Step: 4
Training loss: 0.37510472536087036
Validation loss: 1.6929392917181856

Epoch: 6| Step: 5
Training loss: 0.9069681167602539
Validation loss: 1.7080974091765702

Epoch: 6| Step: 6
Training loss: 0.4960777759552002
Validation loss: 1.7033799873885287

Epoch: 6| Step: 7
Training loss: 0.6746016144752502
Validation loss: 1.6908235985745665

Epoch: 6| Step: 8
Training loss: 0.7285298705101013
Validation loss: 1.6959829048443866

Epoch: 6| Step: 9
Training loss: 0.3462977707386017
Validation loss: 1.7141326191604778

Epoch: 6| Step: 10
Training loss: 0.2115616649389267
Validation loss: 1.8296510314428678

Epoch: 6| Step: 11
Training loss: 0.8317462205886841
Validation loss: 1.8820826225383307

Epoch: 6| Step: 12
Training loss: 0.8142457008361816
Validation loss: 1.8668998056842434

Epoch: 6| Step: 13
Training loss: 0.8828524351119995
Validation loss: 1.8087233048613354

Epoch: 273| Step: 0
Training loss: 0.2576076090335846
Validation loss: 1.801470248929916

Epoch: 6| Step: 1
Training loss: 0.8349254131317139
Validation loss: 1.78413257034876

Epoch: 6| Step: 2
Training loss: 0.6175774335861206
Validation loss: 1.768370263038143

Epoch: 6| Step: 3
Training loss: 0.5137799978256226
Validation loss: 1.7908081085451188

Epoch: 6| Step: 4
Training loss: 0.4301312565803528
Validation loss: 1.7828505039215088

Epoch: 6| Step: 5
Training loss: 0.58803391456604
Validation loss: 1.7802049908586728

Epoch: 6| Step: 6
Training loss: 0.9757716655731201
Validation loss: 1.7958189159311273

Epoch: 6| Step: 7
Training loss: 0.6041080951690674
Validation loss: 1.839111961344237

Epoch: 6| Step: 8
Training loss: 0.7330926656723022
Validation loss: 1.889551672884213

Epoch: 6| Step: 9
Training loss: 0.7701284885406494
Validation loss: 1.8815334996869486

Epoch: 6| Step: 10
Training loss: 0.5180517435073853
Validation loss: 1.8570430836369913

Epoch: 6| Step: 11
Training loss: 0.9485398530960083
Validation loss: 1.8247284286765642

Epoch: 6| Step: 12
Training loss: 0.4937797486782074
Validation loss: 1.7694430120529667

Epoch: 6| Step: 13
Training loss: 0.33700940012931824
Validation loss: 1.75746504722103

Epoch: 274| Step: 0
Training loss: 0.6889829635620117
Validation loss: 1.7221605034284695

Epoch: 6| Step: 1
Training loss: 0.5456587672233582
Validation loss: 1.7084945324928529

Epoch: 6| Step: 2
Training loss: 0.47083139419555664
Validation loss: 1.7412309531242616

Epoch: 6| Step: 3
Training loss: 0.5299835205078125
Validation loss: 1.772890419088384

Epoch: 6| Step: 4
Training loss: 0.5227484703063965
Validation loss: 1.779597205500449

Epoch: 6| Step: 5
Training loss: 0.5895240902900696
Validation loss: 1.7950107859027

Epoch: 6| Step: 6
Training loss: 0.6621543169021606
Validation loss: 1.8162799458349905

Epoch: 6| Step: 7
Training loss: 0.5801393985748291
Validation loss: 1.8043223606642855

Epoch: 6| Step: 8
Training loss: 0.48762309551239014
Validation loss: 1.8395248254140217

Epoch: 6| Step: 9
Training loss: 1.2871479988098145
Validation loss: 1.8529621234504126

Epoch: 6| Step: 10
Training loss: 0.5462818145751953
Validation loss: 1.8264001389985443

Epoch: 6| Step: 11
Training loss: 0.6369282007217407
Validation loss: 1.8024568378284413

Epoch: 6| Step: 12
Training loss: 0.5118641257286072
Validation loss: 1.7555182428770169

Epoch: 6| Step: 13
Training loss: 0.3735176622867584
Validation loss: 1.688191980443975

Epoch: 275| Step: 0
Training loss: 0.9765379428863525
Validation loss: 1.6737812680582846

Epoch: 6| Step: 1
Training loss: 0.40806275606155396
Validation loss: 1.6421005520769345

Epoch: 6| Step: 2
Training loss: 0.3226044774055481
Validation loss: 1.6762615660185456

Epoch: 6| Step: 3
Training loss: 0.6034391522407532
Validation loss: 1.715499920229758

Epoch: 6| Step: 4
Training loss: 0.5845402479171753
Validation loss: 1.7424058273274412

Epoch: 6| Step: 5
Training loss: 0.4901912212371826
Validation loss: 1.7509839855214602

Epoch: 6| Step: 6
Training loss: 0.8364903926849365
Validation loss: 1.7679377704538324

Epoch: 6| Step: 7
Training loss: 1.1868014335632324
Validation loss: 1.7799400283444313

Epoch: 6| Step: 8
Training loss: 0.7336863279342651
Validation loss: 1.7582639519886305

Epoch: 6| Step: 9
Training loss: 0.4729345440864563
Validation loss: 1.735636741884293

Epoch: 6| Step: 10
Training loss: 0.2556689381599426
Validation loss: 1.7566024962291922

Epoch: 6| Step: 11
Training loss: 0.4930207431316376
Validation loss: 1.7939062874804261

Epoch: 6| Step: 12
Training loss: 0.6417805552482605
Validation loss: 1.7955645720163982

Epoch: 6| Step: 13
Training loss: 0.8200550079345703
Validation loss: 1.7927220508616457

Epoch: 276| Step: 0
Training loss: 0.6906610727310181
Validation loss: 1.7466303366486744

Epoch: 6| Step: 1
Training loss: 0.5427541136741638
Validation loss: 1.7712622188752698

Epoch: 6| Step: 2
Training loss: 0.4239947199821472
Validation loss: 1.7764339729021954

Epoch: 6| Step: 3
Training loss: 0.5557416677474976
Validation loss: 1.7599353662101171

Epoch: 6| Step: 4
Training loss: 0.8642928600311279
Validation loss: 1.7473139647514588

Epoch: 6| Step: 5
Training loss: 0.38351887464523315
Validation loss: 1.7160079697126984

Epoch: 6| Step: 6
Training loss: 0.5462644696235657
Validation loss: 1.6858872521308161

Epoch: 6| Step: 7
Training loss: 0.41740572452545166
Validation loss: 1.683646664824537

Epoch: 6| Step: 8
Training loss: 0.879676103591919
Validation loss: 1.6568311657956851

Epoch: 6| Step: 9
Training loss: 0.5202280282974243
Validation loss: 1.647113884648969

Epoch: 6| Step: 10
Training loss: 0.7074371576309204
Validation loss: 1.6705865603621288

Epoch: 6| Step: 11
Training loss: 0.6913154125213623
Validation loss: 1.6974134701554493

Epoch: 6| Step: 12
Training loss: 0.5735044479370117
Validation loss: 1.6915517289151427

Epoch: 6| Step: 13
Training loss: 0.4644339978694916
Validation loss: 1.758703411266368

Epoch: 277| Step: 0
Training loss: 0.6154091358184814
Validation loss: 1.7870651791172643

Epoch: 6| Step: 1
Training loss: 0.4877201020717621
Validation loss: 1.8405740978897258

Epoch: 6| Step: 2
Training loss: 0.4453156292438507
Validation loss: 1.8105329236676615

Epoch: 6| Step: 3
Training loss: 0.460149347782135
Validation loss: 1.7305710059340282

Epoch: 6| Step: 4
Training loss: 0.8109147548675537
Validation loss: 1.7615638702146468

Epoch: 6| Step: 5
Training loss: 0.49356985092163086
Validation loss: 1.756256793134956

Epoch: 6| Step: 6
Training loss: 0.7623531222343445
Validation loss: 1.780587064322605

Epoch: 6| Step: 7
Training loss: 0.886764645576477
Validation loss: 1.7745727031461653

Epoch: 6| Step: 8
Training loss: 0.7875924706459045
Validation loss: 1.7514134607007426

Epoch: 6| Step: 9
Training loss: 0.6829988956451416
Validation loss: 1.7445583497324297

Epoch: 6| Step: 10
Training loss: 0.47670412063598633
Validation loss: 1.7440463227610434

Epoch: 6| Step: 11
Training loss: 0.6636412143707275
Validation loss: 1.7681815931873937

Epoch: 6| Step: 12
Training loss: 0.8433657884597778
Validation loss: 1.769672106671077

Epoch: 6| Step: 13
Training loss: 0.2422768771648407
Validation loss: 1.7747851712729341

Epoch: 278| Step: 0
Training loss: 0.569149374961853
Validation loss: 1.7264856869174587

Epoch: 6| Step: 1
Training loss: 0.7197980880737305
Validation loss: 1.7109536124813942

Epoch: 6| Step: 2
Training loss: 0.4781659245491028
Validation loss: 1.6778975302173245

Epoch: 6| Step: 3
Training loss: 0.6123147010803223
Validation loss: 1.6831079144631662

Epoch: 6| Step: 4
Training loss: 0.42642056941986084
Validation loss: 1.6831636108377928

Epoch: 6| Step: 5
Training loss: 0.9324827790260315
Validation loss: 1.7080083431736115

Epoch: 6| Step: 6
Training loss: 0.4349671006202698
Validation loss: 1.7455730861233127

Epoch: 6| Step: 7
Training loss: 0.5119214057922363
Validation loss: 1.7362698098664642

Epoch: 6| Step: 8
Training loss: 0.5479516386985779
Validation loss: 1.7361434787832282

Epoch: 6| Step: 9
Training loss: 0.8134814500808716
Validation loss: 1.7498718077136624

Epoch: 6| Step: 10
Training loss: 0.38420170545578003
Validation loss: 1.7324114576462777

Epoch: 6| Step: 11
Training loss: 0.6558610200881958
Validation loss: 1.699779482298

Epoch: 6| Step: 12
Training loss: 0.4827633500099182
Validation loss: 1.7347193841011292

Epoch: 6| Step: 13
Training loss: 0.23519550263881683
Validation loss: 1.7423561619174095

Epoch: 279| Step: 0
Training loss: 0.5059850215911865
Validation loss: 1.717964638945877

Epoch: 6| Step: 1
Training loss: 0.6255678534507751
Validation loss: 1.7319060217949651

Epoch: 6| Step: 2
Training loss: 0.8806558847427368
Validation loss: 1.7201822175774524

Epoch: 6| Step: 3
Training loss: 0.5982511043548584
Validation loss: 1.6916609105243479

Epoch: 6| Step: 4
Training loss: 0.42978012561798096
Validation loss: 1.705232745857649

Epoch: 6| Step: 5
Training loss: 0.2745554745197296
Validation loss: 1.7088299425699378

Epoch: 6| Step: 6
Training loss: 0.46206650137901306
Validation loss: 1.7246489781205372

Epoch: 6| Step: 7
Training loss: 0.5267709493637085
Validation loss: 1.7730532743597542

Epoch: 6| Step: 8
Training loss: 0.5010936260223389
Validation loss: 1.794375265798261

Epoch: 6| Step: 9
Training loss: 0.2526933550834656
Validation loss: 1.8031624645315192

Epoch: 6| Step: 10
Training loss: 0.7115324139595032
Validation loss: 1.8188901575662757

Epoch: 6| Step: 11
Training loss: 0.5990307331085205
Validation loss: 1.802063677900581

Epoch: 6| Step: 12
Training loss: 0.984756588935852
Validation loss: 1.7792389610762238

Epoch: 6| Step: 13
Training loss: 0.46038681268692017
Validation loss: 1.7252044408552107

Epoch: 280| Step: 0
Training loss: 0.673020601272583
Validation loss: 1.704926965057209

Epoch: 6| Step: 1
Training loss: 0.41110101342201233
Validation loss: 1.6942838814950758

Epoch: 6| Step: 2
Training loss: 0.5687028169631958
Validation loss: 1.6716171810703893

Epoch: 6| Step: 3
Training loss: 0.6159545183181763
Validation loss: 1.6629948551936815

Epoch: 6| Step: 4
Training loss: 0.4509980380535126
Validation loss: 1.6809568994788713

Epoch: 6| Step: 5
Training loss: 0.27423781156539917
Validation loss: 1.6793155131801483

Epoch: 6| Step: 6
Training loss: 0.7221777439117432
Validation loss: 1.713141373408738

Epoch: 6| Step: 7
Training loss: 0.5562204718589783
Validation loss: 1.7390541081787438

Epoch: 6| Step: 8
Training loss: 0.4205554723739624
Validation loss: 1.7871759681291477

Epoch: 6| Step: 9
Training loss: 0.7245254516601562
Validation loss: 1.8146777037651307

Epoch: 6| Step: 10
Training loss: 0.767985999584198
Validation loss: 1.82971026051429

Epoch: 6| Step: 11
Training loss: 0.5088393688201904
Validation loss: 1.8107398299760715

Epoch: 6| Step: 12
Training loss: 0.6059896945953369
Validation loss: 1.8117120227506083

Epoch: 6| Step: 13
Training loss: 0.6244521737098694
Validation loss: 1.7656889551429338

Epoch: 281| Step: 0
Training loss: 0.5774715542793274
Validation loss: 1.727245294919578

Epoch: 6| Step: 1
Training loss: 0.4319363236427307
Validation loss: 1.7261672814687092

Epoch: 6| Step: 2
Training loss: 0.5038778781890869
Validation loss: 1.74124111155028

Epoch: 6| Step: 3
Training loss: 0.7174190282821655
Validation loss: 1.7050353532196374

Epoch: 6| Step: 4
Training loss: 0.4743689298629761
Validation loss: 1.6800389161673925

Epoch: 6| Step: 5
Training loss: 0.3725826144218445
Validation loss: 1.7009441903842393

Epoch: 6| Step: 6
Training loss: 0.6731657981872559
Validation loss: 1.7308402599826935

Epoch: 6| Step: 7
Training loss: 0.7211365103721619
Validation loss: 1.7250625420642156

Epoch: 6| Step: 8
Training loss: 0.732652485370636
Validation loss: 1.6880357470563663

Epoch: 6| Step: 9
Training loss: 0.5023492574691772
Validation loss: 1.7086161926228514

Epoch: 6| Step: 10
Training loss: 0.2145499289035797
Validation loss: 1.7139038757611347

Epoch: 6| Step: 11
Training loss: 0.5754972696304321
Validation loss: 1.743197157818784

Epoch: 6| Step: 12
Training loss: 0.44608330726623535
Validation loss: 1.7191748977989278

Epoch: 6| Step: 13
Training loss: 0.497042179107666
Validation loss: 1.7168380637322702

Epoch: 282| Step: 0
Training loss: 0.8139503598213196
Validation loss: 1.6839889275130404

Epoch: 6| Step: 1
Training loss: 0.7568732500076294
Validation loss: 1.7153369072944886

Epoch: 6| Step: 2
Training loss: 0.5752112865447998
Validation loss: 1.7199104639791674

Epoch: 6| Step: 3
Training loss: 0.655683159828186
Validation loss: 1.7255347544147122

Epoch: 6| Step: 4
Training loss: 0.5123564004898071
Validation loss: 1.7481900453567505

Epoch: 6| Step: 5
Training loss: 0.41573482751846313
Validation loss: 1.7448007368272351

Epoch: 6| Step: 6
Training loss: 0.34450241923332214
Validation loss: 1.7388623478592082

Epoch: 6| Step: 7
Training loss: 0.5512455701828003
Validation loss: 1.7476372359901347

Epoch: 6| Step: 8
Training loss: 0.4878638684749603
Validation loss: 1.7259718320702995

Epoch: 6| Step: 9
Training loss: 0.3092590272426605
Validation loss: 1.7393572125383603

Epoch: 6| Step: 10
Training loss: 0.34588849544525146
Validation loss: 1.7090294181659658

Epoch: 6| Step: 11
Training loss: 0.6533808708190918
Validation loss: 1.6845991111570788

Epoch: 6| Step: 12
Training loss: 0.4643614888191223
Validation loss: 1.667226291471912

Epoch: 6| Step: 13
Training loss: 0.7516840696334839
Validation loss: 1.6677620462192002

Epoch: 283| Step: 0
Training loss: 0.5565922260284424
Validation loss: 1.6682109371308358

Epoch: 6| Step: 1
Training loss: 0.4149085581302643
Validation loss: 1.6482421262289888

Epoch: 6| Step: 2
Training loss: 0.6968068480491638
Validation loss: 1.659914078251008

Epoch: 6| Step: 3
Training loss: 0.5253252983093262
Validation loss: 1.6292311491504792

Epoch: 6| Step: 4
Training loss: 0.45421019196510315
Validation loss: 1.6869528229518602

Epoch: 6| Step: 5
Training loss: 0.48937782645225525
Validation loss: 1.7047317745865032

Epoch: 6| Step: 6
Training loss: 0.4567030072212219
Validation loss: 1.730645405348911

Epoch: 6| Step: 7
Training loss: 0.646390438079834
Validation loss: 1.7267617384592693

Epoch: 6| Step: 8
Training loss: 0.39616823196411133
Validation loss: 1.694743570461068

Epoch: 6| Step: 9
Training loss: 0.5260606408119202
Validation loss: 1.679411284385189

Epoch: 6| Step: 10
Training loss: 0.6453090906143188
Validation loss: 1.7009855572895338

Epoch: 6| Step: 11
Training loss: 0.7333378791809082
Validation loss: 1.698065039932087

Epoch: 6| Step: 12
Training loss: 0.3868452310562134
Validation loss: 1.7139794313779442

Epoch: 6| Step: 13
Training loss: 0.5671089887619019
Validation loss: 1.708405456235332

Epoch: 284| Step: 0
Training loss: 0.4231850504875183
Validation loss: 1.7261617965595697

Epoch: 6| Step: 1
Training loss: 0.7234653830528259
Validation loss: 1.7736167548805155

Epoch: 6| Step: 2
Training loss: 0.4907451272010803
Validation loss: 1.8207052881999681

Epoch: 6| Step: 3
Training loss: 0.4449007511138916
Validation loss: 1.8375234116790116

Epoch: 6| Step: 4
Training loss: 0.27506303787231445
Validation loss: 1.791359878355457

Epoch: 6| Step: 5
Training loss: 0.5493939518928528
Validation loss: 1.745751009192518

Epoch: 6| Step: 6
Training loss: 0.51861572265625
Validation loss: 1.7298515112169328

Epoch: 6| Step: 7
Training loss: 0.7207304835319519
Validation loss: 1.6753714546080558

Epoch: 6| Step: 8
Training loss: 0.7049740552902222
Validation loss: 1.706433291076332

Epoch: 6| Step: 9
Training loss: 0.3338664472103119
Validation loss: 1.6939605641108688

Epoch: 6| Step: 10
Training loss: 0.659919261932373
Validation loss: 1.711424236656517

Epoch: 6| Step: 11
Training loss: 0.4613398611545563
Validation loss: 1.714461390690137

Epoch: 6| Step: 12
Training loss: 0.5412700772285461
Validation loss: 1.7520335374339935

Epoch: 6| Step: 13
Training loss: 0.8371849656105042
Validation loss: 1.7443784680417789

Epoch: 285| Step: 0
Training loss: 0.3265841603279114
Validation loss: 1.709371175817264

Epoch: 6| Step: 1
Training loss: 0.7708551287651062
Validation loss: 1.6904897561637304

Epoch: 6| Step: 2
Training loss: 0.35123196244239807
Validation loss: 1.7128119545598184

Epoch: 6| Step: 3
Training loss: 0.35768604278564453
Validation loss: 1.7287928071073306

Epoch: 6| Step: 4
Training loss: 0.7849911451339722
Validation loss: 1.758128777627022

Epoch: 6| Step: 5
Training loss: 0.36476898193359375
Validation loss: 1.7706441815181444

Epoch: 6| Step: 6
Training loss: 0.2960283160209656
Validation loss: 1.742774591651014

Epoch: 6| Step: 7
Training loss: 0.5336660146713257
Validation loss: 1.7723474002653552

Epoch: 6| Step: 8
Training loss: 0.5195697546005249
Validation loss: 1.7757184454189834

Epoch: 6| Step: 9
Training loss: 0.4972294867038727
Validation loss: 1.777943217626182

Epoch: 6| Step: 10
Training loss: 0.7281845808029175
Validation loss: 1.756210034893405

Epoch: 6| Step: 11
Training loss: 0.37445691227912903
Validation loss: 1.7480699644293836

Epoch: 6| Step: 12
Training loss: 0.6929980516433716
Validation loss: 1.7447554552426903

Epoch: 6| Step: 13
Training loss: 0.6417820453643799
Validation loss: 1.73835285504659

Epoch: 286| Step: 0
Training loss: 0.6716872453689575
Validation loss: 1.7511606607385861

Epoch: 6| Step: 1
Training loss: 0.40951818227767944
Validation loss: 1.7195268100307834

Epoch: 6| Step: 2
Training loss: 0.39100736379623413
Validation loss: 1.7456477047294698

Epoch: 6| Step: 3
Training loss: 0.6940045952796936
Validation loss: 1.7598972474375079

Epoch: 6| Step: 4
Training loss: 0.4664997160434723
Validation loss: 1.716779242279709

Epoch: 6| Step: 5
Training loss: 0.4081316888332367
Validation loss: 1.743079311104231

Epoch: 6| Step: 6
Training loss: 0.5485683083534241
Validation loss: 1.716118085768915

Epoch: 6| Step: 7
Training loss: 0.4319798946380615
Validation loss: 1.713287430424844

Epoch: 6| Step: 8
Training loss: 0.25958001613616943
Validation loss: 1.6942714504016343

Epoch: 6| Step: 9
Training loss: 0.7483832836151123
Validation loss: 1.703355925057524

Epoch: 6| Step: 10
Training loss: 0.5140601396560669
Validation loss: 1.7371616504525627

Epoch: 6| Step: 11
Training loss: 0.4680219292640686
Validation loss: 1.7366123417372346

Epoch: 6| Step: 12
Training loss: 0.6116739511489868
Validation loss: 1.7419596602839809

Epoch: 6| Step: 13
Training loss: 0.2458530068397522
Validation loss: 1.745018510408299

Epoch: 287| Step: 0
Training loss: 0.6008793115615845
Validation loss: 1.7084556318098498

Epoch: 6| Step: 1
Training loss: 0.2599582076072693
Validation loss: 1.6812893036873109

Epoch: 6| Step: 2
Training loss: 0.3358147144317627
Validation loss: 1.691394018870528

Epoch: 6| Step: 3
Training loss: 0.49125900864601135
Validation loss: 1.6900627484885595

Epoch: 6| Step: 4
Training loss: 0.5356637835502625
Validation loss: 1.7052386870948217

Epoch: 6| Step: 5
Training loss: 0.238258495926857
Validation loss: 1.690447615038964

Epoch: 6| Step: 6
Training loss: 0.4052280783653259
Validation loss: 1.6953988421347834

Epoch: 6| Step: 7
Training loss: 0.4960136413574219
Validation loss: 1.6923442399629982

Epoch: 6| Step: 8
Training loss: 0.4727764427661896
Validation loss: 1.7303264307719406

Epoch: 6| Step: 9
Training loss: 0.46300238370895386
Validation loss: 1.745298735557064

Epoch: 6| Step: 10
Training loss: 0.45904541015625
Validation loss: 1.746542324302017

Epoch: 6| Step: 11
Training loss: 0.6559526920318604
Validation loss: 1.7490114858073573

Epoch: 6| Step: 12
Training loss: 0.6010812520980835
Validation loss: 1.7482509920673985

Epoch: 6| Step: 13
Training loss: 0.6756703853607178
Validation loss: 1.762766707328058

Epoch: 288| Step: 0
Training loss: 0.46471697092056274
Validation loss: 1.7350041956029914

Epoch: 6| Step: 1
Training loss: 0.30764898657798767
Validation loss: 1.7006701871912966

Epoch: 6| Step: 2
Training loss: 0.4284283518791199
Validation loss: 1.6887513565760788

Epoch: 6| Step: 3
Training loss: 0.21455226838588715
Validation loss: 1.6573221375865321

Epoch: 6| Step: 4
Training loss: 0.49406886100769043
Validation loss: 1.7024540926820488

Epoch: 6| Step: 5
Training loss: 0.3846948742866516
Validation loss: 1.7052180523513465

Epoch: 6| Step: 6
Training loss: 0.9645731449127197
Validation loss: 1.730315592981154

Epoch: 6| Step: 7
Training loss: 0.502739429473877
Validation loss: 1.767002042903695

Epoch: 6| Step: 8
Training loss: 0.4635070562362671
Validation loss: 1.7895560110768964

Epoch: 6| Step: 9
Training loss: 0.4797113537788391
Validation loss: 1.8075379658770818

Epoch: 6| Step: 10
Training loss: 0.3741968274116516
Validation loss: 1.8059537897827804

Epoch: 6| Step: 11
Training loss: 0.5852638483047485
Validation loss: 1.7578160044967488

Epoch: 6| Step: 12
Training loss: 0.41515928506851196
Validation loss: 1.7499985015520485

Epoch: 6| Step: 13
Training loss: 0.7023911476135254
Validation loss: 1.7340387041850756

Epoch: 289| Step: 0
Training loss: 0.29665952920913696
Validation loss: 1.689063370868724

Epoch: 6| Step: 1
Training loss: 0.3496275246143341
Validation loss: 1.6885909752179218

Epoch: 6| Step: 2
Training loss: 0.3192140758037567
Validation loss: 1.6648160488374772

Epoch: 6| Step: 3
Training loss: 0.5164991617202759
Validation loss: 1.71830125265224

Epoch: 6| Step: 4
Training loss: 0.5671073794364929
Validation loss: 1.7322099939469369

Epoch: 6| Step: 5
Training loss: 0.5131187438964844
Validation loss: 1.7544057317959365

Epoch: 6| Step: 6
Training loss: 0.6701868176460266
Validation loss: 1.7664170585652834

Epoch: 6| Step: 7
Training loss: 0.6814777255058289
Validation loss: 1.7250502365891651

Epoch: 6| Step: 8
Training loss: 0.3929700553417206
Validation loss: 1.689283755517775

Epoch: 6| Step: 9
Training loss: 0.17817944288253784
Validation loss: 1.6982824039715592

Epoch: 6| Step: 10
Training loss: 0.5074462890625
Validation loss: 1.717397443709835

Epoch: 6| Step: 11
Training loss: 0.9673935770988464
Validation loss: 1.7631435375059805

Epoch: 6| Step: 12
Training loss: 0.5411152243614197
Validation loss: 1.771443606704794

Epoch: 6| Step: 13
Training loss: 0.6777364611625671
Validation loss: 1.7849917693804669

Epoch: 290| Step: 0
Training loss: 0.5792301297187805
Validation loss: 1.7638927544316938

Epoch: 6| Step: 1
Training loss: 0.5410996079444885
Validation loss: 1.756818462443608

Epoch: 6| Step: 2
Training loss: 0.41835543513298035
Validation loss: 1.8125600122636365

Epoch: 6| Step: 3
Training loss: 0.7057937383651733
Validation loss: 1.8223126652420207

Epoch: 6| Step: 4
Training loss: 0.3115682601928711
Validation loss: 1.7910771998026038

Epoch: 6| Step: 5
Training loss: 0.41550832986831665
Validation loss: 1.7536706719347226

Epoch: 6| Step: 6
Training loss: 0.457233726978302
Validation loss: 1.714476986597943

Epoch: 6| Step: 7
Training loss: 0.4851222634315491
Validation loss: 1.671160477463917

Epoch: 6| Step: 8
Training loss: 0.6764544248580933
Validation loss: 1.6447084526861868

Epoch: 6| Step: 9
Training loss: 1.1889936923980713
Validation loss: 1.6387048344458304

Epoch: 6| Step: 10
Training loss: 0.7106645107269287
Validation loss: 1.68957567855876

Epoch: 6| Step: 11
Training loss: 0.4270990490913391
Validation loss: 1.7050793517020442

Epoch: 6| Step: 12
Training loss: 0.5160295367240906
Validation loss: 1.7238502284531951

Epoch: 6| Step: 13
Training loss: 0.38688918948173523
Validation loss: 1.731723786682211

Epoch: 291| Step: 0
Training loss: 0.6057556867599487
Validation loss: 1.7988120112367856

Epoch: 6| Step: 1
Training loss: 0.3014071583747864
Validation loss: 1.8140886150380617

Epoch: 6| Step: 2
Training loss: 0.5656797289848328
Validation loss: 1.8848268114110476

Epoch: 6| Step: 3
Training loss: 0.5906651616096497
Validation loss: 1.8189030039695002

Epoch: 6| Step: 4
Training loss: 0.7675397396087646
Validation loss: 1.758293677401799

Epoch: 6| Step: 5
Training loss: 0.5065181255340576
Validation loss: 1.6990416588321808

Epoch: 6| Step: 6
Training loss: 0.5169326066970825
Validation loss: 1.683775459566424

Epoch: 6| Step: 7
Training loss: 0.6214637756347656
Validation loss: 1.6746724908069899

Epoch: 6| Step: 8
Training loss: 0.45188844203948975
Validation loss: 1.6718306169714978

Epoch: 6| Step: 9
Training loss: 0.9635169506072998
Validation loss: 1.7110288732795305

Epoch: 6| Step: 10
Training loss: 0.2817925810813904
Validation loss: 1.742006124988679

Epoch: 6| Step: 11
Training loss: 0.5546931624412537
Validation loss: 1.8079173321365027

Epoch: 6| Step: 12
Training loss: 0.3219258189201355
Validation loss: 1.799388773338769

Epoch: 6| Step: 13
Training loss: 0.48314031958580017
Validation loss: 1.8468796437786472

Epoch: 292| Step: 0
Training loss: 0.38368478417396545
Validation loss: 1.8292196360967492

Epoch: 6| Step: 1
Training loss: 0.5926600694656372
Validation loss: 1.8005242347717285

Epoch: 6| Step: 2
Training loss: 0.4717302620410919
Validation loss: 1.76446743037111

Epoch: 6| Step: 3
Training loss: 0.22738556563854218
Validation loss: 1.729253730466289

Epoch: 6| Step: 4
Training loss: 0.8987582325935364
Validation loss: 1.723669094424094

Epoch: 6| Step: 5
Training loss: 0.48147958517074585
Validation loss: 1.7074352772005144

Epoch: 6| Step: 6
Training loss: 0.35436949133872986
Validation loss: 1.6852947973435926

Epoch: 6| Step: 7
Training loss: 0.5715242624282837
Validation loss: 1.7022577870276667

Epoch: 6| Step: 8
Training loss: 0.24394652247428894
Validation loss: 1.7248870403535905

Epoch: 6| Step: 9
Training loss: 0.47818970680236816
Validation loss: 1.7347644221398137

Epoch: 6| Step: 10
Training loss: 0.8085116147994995
Validation loss: 1.7634963925166796

Epoch: 6| Step: 11
Training loss: 0.4206005930900574
Validation loss: 1.7871548693667176

Epoch: 6| Step: 12
Training loss: 0.3817608952522278
Validation loss: 1.7752537394082675

Epoch: 6| Step: 13
Training loss: 0.43108946084976196
Validation loss: 1.7605789887007846

Epoch: 293| Step: 0
Training loss: 0.2997795641422272
Validation loss: 1.7771519332803705

Epoch: 6| Step: 1
Training loss: 0.2557483911514282
Validation loss: 1.7609280540097145

Epoch: 6| Step: 2
Training loss: 0.6340763568878174
Validation loss: 1.7509364902332265

Epoch: 6| Step: 3
Training loss: 0.7176918983459473
Validation loss: 1.7257251739501953

Epoch: 6| Step: 4
Training loss: 0.5991560220718384
Validation loss: 1.7434954540703886

Epoch: 6| Step: 5
Training loss: 0.6217260360717773
Validation loss: 1.7129710028248448

Epoch: 6| Step: 6
Training loss: 0.2775745093822479
Validation loss: 1.7044593659780358

Epoch: 6| Step: 7
Training loss: 0.3890533149242401
Validation loss: 1.741752084865365

Epoch: 6| Step: 8
Training loss: 0.36716312170028687
Validation loss: 1.78385252593666

Epoch: 6| Step: 9
Training loss: 0.49990350008010864
Validation loss: 1.8346319634427306

Epoch: 6| Step: 10
Training loss: 0.7927499413490295
Validation loss: 1.8593394346134637

Epoch: 6| Step: 11
Training loss: 0.42513594031333923
Validation loss: 1.8090525724554574

Epoch: 6| Step: 12
Training loss: 0.4381588101387024
Validation loss: 1.7343352981792983

Epoch: 6| Step: 13
Training loss: 0.22090403735637665
Validation loss: 1.6588545204490743

Epoch: 294| Step: 0
Training loss: 0.38426822423934937
Validation loss: 1.6456971937610256

Epoch: 6| Step: 1
Training loss: 0.499112606048584
Validation loss: 1.629530570840323

Epoch: 6| Step: 2
Training loss: 0.790732204914093
Validation loss: 1.608885096606388

Epoch: 6| Step: 3
Training loss: 0.30964118242263794
Validation loss: 1.6039287826066375

Epoch: 6| Step: 4
Training loss: 0.5108335018157959
Validation loss: 1.626656892479107

Epoch: 6| Step: 5
Training loss: 0.40985924005508423
Validation loss: 1.6459485292434692

Epoch: 6| Step: 6
Training loss: 0.42889174818992615
Validation loss: 1.6431647513502388

Epoch: 6| Step: 7
Training loss: 0.6696329116821289
Validation loss: 1.655439669086087

Epoch: 6| Step: 8
Training loss: 0.3959888815879822
Validation loss: 1.6540560837714904

Epoch: 6| Step: 9
Training loss: 0.3260260224342346
Validation loss: 1.7046409460806078

Epoch: 6| Step: 10
Training loss: 0.4167497456073761
Validation loss: 1.7542592799791725

Epoch: 6| Step: 11
Training loss: 0.3982654809951782
Validation loss: 1.7660210568417785

Epoch: 6| Step: 12
Training loss: 0.40586090087890625
Validation loss: 1.7716266544916297

Epoch: 6| Step: 13
Training loss: 0.7070088386535645
Validation loss: 1.7492055123852146

Epoch: 295| Step: 0
Training loss: 0.5835727453231812
Validation loss: 1.703372056766223

Epoch: 6| Step: 1
Training loss: 0.2925739884376526
Validation loss: 1.6335039228521369

Epoch: 6| Step: 2
Training loss: 0.3019135296344757
Validation loss: 1.6342226882134714

Epoch: 6| Step: 3
Training loss: 0.43546262383461
Validation loss: 1.6586531580135386

Epoch: 6| Step: 4
Training loss: 0.9911422729492188
Validation loss: 1.667267099503548

Epoch: 6| Step: 5
Training loss: 0.6096047759056091
Validation loss: 1.6133567222984888

Epoch: 6| Step: 6
Training loss: 0.5809870362281799
Validation loss: 1.636625671899447

Epoch: 6| Step: 7
Training loss: 0.47666803002357483
Validation loss: 1.6622058832517235

Epoch: 6| Step: 8
Training loss: 0.619206428527832
Validation loss: 1.679120913628609

Epoch: 6| Step: 9
Training loss: 0.6767255663871765
Validation loss: 1.73868743834957

Epoch: 6| Step: 10
Training loss: 0.5919632315635681
Validation loss: 1.8283553636202248

Epoch: 6| Step: 11
Training loss: 0.40374553203582764
Validation loss: 1.8633610163965533

Epoch: 6| Step: 12
Training loss: 0.5187002420425415
Validation loss: 1.8585479336400186

Epoch: 6| Step: 13
Training loss: 0.4140149652957916
Validation loss: 1.7848374958961242

Epoch: 296| Step: 0
Training loss: 0.3499140441417694
Validation loss: 1.7243293562243063

Epoch: 6| Step: 1
Training loss: 0.680605411529541
Validation loss: 1.6588626728262952

Epoch: 6| Step: 2
Training loss: 0.7249722480773926
Validation loss: 1.6375153385182863

Epoch: 6| Step: 3
Training loss: 0.1840587854385376
Validation loss: 1.627448663916639

Epoch: 6| Step: 4
Training loss: 0.5763760805130005
Validation loss: 1.627148514152855

Epoch: 6| Step: 5
Training loss: 0.512524425983429
Validation loss: 1.6077041600340156

Epoch: 6| Step: 6
Training loss: 0.5037330985069275
Validation loss: 1.631843638676469

Epoch: 6| Step: 7
Training loss: 0.5808868408203125
Validation loss: 1.645868614155759

Epoch: 6| Step: 8
Training loss: 0.3387559652328491
Validation loss: 1.6311347894771124

Epoch: 6| Step: 9
Training loss: 0.45145517587661743
Validation loss: 1.6565015521100772

Epoch: 6| Step: 10
Training loss: 0.3543834984302521
Validation loss: 1.658447806553174

Epoch: 6| Step: 11
Training loss: 0.31439152359962463
Validation loss: 1.6706245355708624

Epoch: 6| Step: 12
Training loss: 0.6363550424575806
Validation loss: 1.6416362985487907

Epoch: 6| Step: 13
Training loss: 0.3239460587501526
Validation loss: 1.6528689399842293

Epoch: 297| Step: 0
Training loss: 0.5625326633453369
Validation loss: 1.6651340799946939

Epoch: 6| Step: 1
Training loss: 0.3887196183204651
Validation loss: 1.6850565979557652

Epoch: 6| Step: 2
Training loss: 0.38772711157798767
Validation loss: 1.6853834300912836

Epoch: 6| Step: 3
Training loss: 0.38377195596694946
Validation loss: 1.713166735505545

Epoch: 6| Step: 4
Training loss: 0.661321222782135
Validation loss: 1.7222651640574138

Epoch: 6| Step: 5
Training loss: 0.3899579644203186
Validation loss: 1.6808525785323112

Epoch: 6| Step: 6
Training loss: 0.7239193916320801
Validation loss: 1.6888393958409627

Epoch: 6| Step: 7
Training loss: 0.4041101932525635
Validation loss: 1.680081723838724

Epoch: 6| Step: 8
Training loss: 0.5620431303977966
Validation loss: 1.6786805070856565

Epoch: 6| Step: 9
Training loss: 0.5164508819580078
Validation loss: 1.6774361300212082

Epoch: 6| Step: 10
Training loss: 0.41559335589408875
Validation loss: 1.6779979954483688

Epoch: 6| Step: 11
Training loss: 0.32591354846954346
Validation loss: 1.7034164013401154

Epoch: 6| Step: 12
Training loss: 0.27939459681510925
Validation loss: 1.6884967101517545

Epoch: 6| Step: 13
Training loss: 0.2798495888710022
Validation loss: 1.691417412091327

Epoch: 298| Step: 0
Training loss: 0.4282153248786926
Validation loss: 1.6848813359455397

Epoch: 6| Step: 1
Training loss: 0.4148466885089874
Validation loss: 1.669536454703218

Epoch: 6| Step: 2
Training loss: 0.6164348125457764
Validation loss: 1.6892926077688895

Epoch: 6| Step: 3
Training loss: 0.32628974318504333
Validation loss: 1.7102206964646616

Epoch: 6| Step: 4
Training loss: 0.45074528455734253
Validation loss: 1.671327849870087

Epoch: 6| Step: 5
Training loss: 0.4805748164653778
Validation loss: 1.6770909973370132

Epoch: 6| Step: 6
Training loss: 0.32909417152404785
Validation loss: 1.7007701755851827

Epoch: 6| Step: 7
Training loss: 0.30886128544807434
Validation loss: 1.7016183560894382

Epoch: 6| Step: 8
Training loss: 0.4362557530403137
Validation loss: 1.6606234709421794

Epoch: 6| Step: 9
Training loss: 0.606604814529419
Validation loss: 1.7000946396140642

Epoch: 6| Step: 10
Training loss: 0.3677300214767456
Validation loss: 1.688059138995345

Epoch: 6| Step: 11
Training loss: 0.5860944986343384
Validation loss: 1.6730802238628428

Epoch: 6| Step: 12
Training loss: 0.3094745874404907
Validation loss: 1.6942036908159974

Epoch: 6| Step: 13
Training loss: 0.19550484418869019
Validation loss: 1.6745560720402708

Epoch: 299| Step: 0
Training loss: 0.480465829372406
Validation loss: 1.6843207100386262

Epoch: 6| Step: 1
Training loss: 0.23795324563980103
Validation loss: 1.6697958592445619

Epoch: 6| Step: 2
Training loss: 0.5729154348373413
Validation loss: 1.6687597215816539

Epoch: 6| Step: 3
Training loss: 0.4962768852710724
Validation loss: 1.7013158772581367

Epoch: 6| Step: 4
Training loss: 0.4239983558654785
Validation loss: 1.7375613720186296

Epoch: 6| Step: 5
Training loss: 0.47719037532806396
Validation loss: 1.7526910792114914

Epoch: 6| Step: 6
Training loss: 0.5383933186531067
Validation loss: 1.7717671355893534

Epoch: 6| Step: 7
Training loss: 0.2811901867389679
Validation loss: 1.7756181711791663

Epoch: 6| Step: 8
Training loss: 0.3989584147930145
Validation loss: 1.7992148117352558

Epoch: 6| Step: 9
Training loss: 0.3589353859424591
Validation loss: 1.7871090019902875

Epoch: 6| Step: 10
Training loss: 0.41514551639556885
Validation loss: 1.764465687095478

Epoch: 6| Step: 11
Training loss: 0.8483572006225586
Validation loss: 1.7152771014039234

Epoch: 6| Step: 12
Training loss: 0.7281523942947388
Validation loss: 1.6607894935915548

Epoch: 6| Step: 13
Training loss: 0.2114209085702896
Validation loss: 1.648544894751682

Epoch: 300| Step: 0
Training loss: 0.32111427187919617
Validation loss: 1.6193735138062508

Epoch: 6| Step: 1
Training loss: 0.48699378967285156
Validation loss: 1.6170476457124114

Epoch: 6| Step: 2
Training loss: 0.3119250535964966
Validation loss: 1.6259826678101734

Epoch: 6| Step: 3
Training loss: 0.6230825185775757
Validation loss: 1.6739516540240216

Epoch: 6| Step: 4
Training loss: 0.653459370136261
Validation loss: 1.6639923049557594

Epoch: 6| Step: 5
Training loss: 0.267928808927536
Validation loss: 1.668001106990281

Epoch: 6| Step: 6
Training loss: 0.5080605149269104
Validation loss: 1.7191984384290633

Epoch: 6| Step: 7
Training loss: 0.3005538284778595
Validation loss: 1.723253930768659

Epoch: 6| Step: 8
Training loss: 0.2860220670700073
Validation loss: 1.7184782130743868

Epoch: 6| Step: 9
Training loss: 0.5345994234085083
Validation loss: 1.7214166336162116

Epoch: 6| Step: 10
Training loss: 0.33263444900512695
Validation loss: 1.7425945830601517

Epoch: 6| Step: 11
Training loss: 0.3880290389060974
Validation loss: 1.7002652204164894

Epoch: 6| Step: 12
Training loss: 0.6383734345436096
Validation loss: 1.6692071242999005

Epoch: 6| Step: 13
Training loss: 0.22870270907878876
Validation loss: 1.6441854302601149

Epoch: 301| Step: 0
Training loss: 0.5842437744140625
Validation loss: 1.6050472733795003

Epoch: 6| Step: 1
Training loss: 0.6552644968032837
Validation loss: 1.6181622410333285

Epoch: 6| Step: 2
Training loss: 0.19855210185050964
Validation loss: 1.635010334753221

Epoch: 6| Step: 3
Training loss: 0.20142102241516113
Validation loss: 1.5965360826061619

Epoch: 6| Step: 4
Training loss: 0.8344830274581909
Validation loss: 1.602387830134361

Epoch: 6| Step: 5
Training loss: 0.4687251150608063
Validation loss: 1.6271475566330778

Epoch: 6| Step: 6
Training loss: 0.22239607572555542
Validation loss: 1.6400347089254728

Epoch: 6| Step: 7
Training loss: 0.6032372713088989
Validation loss: 1.6912999832501976

Epoch: 6| Step: 8
Training loss: 0.15818724036216736
Validation loss: 1.7096022995569373

Epoch: 6| Step: 9
Training loss: 0.5869770050048828
Validation loss: 1.79013015121542

Epoch: 6| Step: 10
Training loss: 0.3204394280910492
Validation loss: 1.7904319404273905

Epoch: 6| Step: 11
Training loss: 0.56166672706604
Validation loss: 1.752422236627148

Epoch: 6| Step: 12
Training loss: 0.49892741441726685
Validation loss: 1.7349354759339364

Epoch: 6| Step: 13
Training loss: 0.22664624452590942
Validation loss: 1.7126795373937136

Epoch: 302| Step: 0
Training loss: 0.5295849442481995
Validation loss: 1.689859123640163

Epoch: 6| Step: 1
Training loss: 0.5920259952545166
Validation loss: 1.657761143099877

Epoch: 6| Step: 2
Training loss: 0.71257483959198
Validation loss: 1.6312700477979516

Epoch: 6| Step: 3
Training loss: 0.32348793745040894
Validation loss: 1.6785909860364852

Epoch: 6| Step: 4
Training loss: 0.4979698956012726
Validation loss: 1.6577268351790726

Epoch: 6| Step: 5
Training loss: 0.3933412432670593
Validation loss: 1.6799323456261748

Epoch: 6| Step: 6
Training loss: 0.49951601028442383
Validation loss: 1.6697690999636086

Epoch: 6| Step: 7
Training loss: 0.3042965531349182
Validation loss: 1.6949038197917323

Epoch: 6| Step: 8
Training loss: 0.3588501513004303
Validation loss: 1.7190436054301519

Epoch: 6| Step: 9
Training loss: 0.41592565178871155
Validation loss: 1.7269559457737913

Epoch: 6| Step: 10
Training loss: 0.34808290004730225
Validation loss: 1.7297559835577523

Epoch: 6| Step: 11
Training loss: 0.6074714660644531
Validation loss: 1.7245235212387577

Epoch: 6| Step: 12
Training loss: 0.39547044038772583
Validation loss: 1.7167279271669285

Epoch: 6| Step: 13
Training loss: 0.6320276856422424
Validation loss: 1.6777987249435917

Epoch: 303| Step: 0
Training loss: 0.40414080023765564
Validation loss: 1.6929821070804392

Epoch: 6| Step: 1
Training loss: 0.5114759206771851
Validation loss: 1.6890062901281542

Epoch: 6| Step: 2
Training loss: 0.7742984890937805
Validation loss: 1.6933066921849405

Epoch: 6| Step: 3
Training loss: 0.2758384346961975
Validation loss: 1.6626014735109063

Epoch: 6| Step: 4
Training loss: 0.30087292194366455
Validation loss: 1.6323262260806175

Epoch: 6| Step: 5
Training loss: 0.6199184656143188
Validation loss: 1.6333708532394902

Epoch: 6| Step: 6
Training loss: 0.43937116861343384
Validation loss: 1.596688437205489

Epoch: 6| Step: 7
Training loss: 0.48639923334121704
Validation loss: 1.5924105310952792

Epoch: 6| Step: 8
Training loss: 0.3231261968612671
Validation loss: 1.6030901465364682

Epoch: 6| Step: 9
Training loss: 0.3137942850589752
Validation loss: 1.607246955235799

Epoch: 6| Step: 10
Training loss: 0.4727270305156708
Validation loss: 1.6190361938168925

Epoch: 6| Step: 11
Training loss: 0.6876279711723328
Validation loss: 1.5949116945266724

Epoch: 6| Step: 12
Training loss: 0.1929437518119812
Validation loss: 1.6310137625663512

Epoch: 6| Step: 13
Training loss: 0.32545989751815796
Validation loss: 1.6275415330804803

Epoch: 304| Step: 0
Training loss: 0.6329399943351746
Validation loss: 1.6571316526782127

Epoch: 6| Step: 1
Training loss: 0.4697839021682739
Validation loss: 1.6783564731638918

Epoch: 6| Step: 2
Training loss: 0.3119915723800659
Validation loss: 1.6995844994821856

Epoch: 6| Step: 3
Training loss: 0.3273012936115265
Validation loss: 1.6883256743031163

Epoch: 6| Step: 4
Training loss: 0.42609545588493347
Validation loss: 1.6756339278272403

Epoch: 6| Step: 5
Training loss: 0.35267990827560425
Validation loss: 1.6421568861571691

Epoch: 6| Step: 6
Training loss: 0.5622079372406006
Validation loss: 1.6723508783566055

Epoch: 6| Step: 7
Training loss: 0.37506043910980225
Validation loss: 1.6567623256355204

Epoch: 6| Step: 8
Training loss: 0.17085301876068115
Validation loss: 1.6446078503003685

Epoch: 6| Step: 9
Training loss: 0.5609285831451416
Validation loss: 1.6649110522321475

Epoch: 6| Step: 10
Training loss: 0.4538162350654602
Validation loss: 1.6583575228209138

Epoch: 6| Step: 11
Training loss: 0.4078846573829651
Validation loss: 1.713984194622245

Epoch: 6| Step: 12
Training loss: 0.5280097126960754
Validation loss: 1.7477307037640644

Epoch: 6| Step: 13
Training loss: 0.19218595325946808
Validation loss: 1.7844282837324246

Epoch: 305| Step: 0
Training loss: 0.5279998183250427
Validation loss: 1.7903493847898257

Epoch: 6| Step: 1
Training loss: 0.4172250032424927
Validation loss: 1.7583975471476072

Epoch: 6| Step: 2
Training loss: 0.37483903765678406
Validation loss: 1.7379973370541808

Epoch: 6| Step: 3
Training loss: 0.2596795856952667
Validation loss: 1.6783890596000097

Epoch: 6| Step: 4
Training loss: 0.5774686932563782
Validation loss: 1.6398778038640176

Epoch: 6| Step: 5
Training loss: 0.36403942108154297
Validation loss: 1.613386170838469

Epoch: 6| Step: 6
Training loss: 0.5200601816177368
Validation loss: 1.5968728975583149

Epoch: 6| Step: 7
Training loss: 0.5294673442840576
Validation loss: 1.5888008686804003

Epoch: 6| Step: 8
Training loss: 0.3156799077987671
Validation loss: 1.6036269818582842

Epoch: 6| Step: 9
Training loss: 0.39679861068725586
Validation loss: 1.6496672899492326

Epoch: 6| Step: 10
Training loss: 0.44345512986183167
Validation loss: 1.6767744377095213

Epoch: 6| Step: 11
Training loss: 0.3650182783603668
Validation loss: 1.6932680542751024

Epoch: 6| Step: 12
Training loss: 0.406801700592041
Validation loss: 1.7174995560799875

Epoch: 6| Step: 13
Training loss: 0.35236600041389465
Validation loss: 1.7301648470663256

Epoch: 306| Step: 0
Training loss: 0.44305285811424255
Validation loss: 1.7138072649637859

Epoch: 6| Step: 1
Training loss: 0.3322489559650421
Validation loss: 1.7013172462422361

Epoch: 6| Step: 2
Training loss: 0.4542333781719208
Validation loss: 1.6829811488428423

Epoch: 6| Step: 3
Training loss: 0.3293061852455139
Validation loss: 1.7065904627564132

Epoch: 6| Step: 4
Training loss: 0.3681277632713318
Validation loss: 1.6893135886038504

Epoch: 6| Step: 5
Training loss: 0.3550799489021301
Validation loss: 1.7041622759193502

Epoch: 6| Step: 6
Training loss: 0.3845835328102112
Validation loss: 1.6942096205167874

Epoch: 6| Step: 7
Training loss: 0.32697778940200806
Validation loss: 1.7276658294021443

Epoch: 6| Step: 8
Training loss: 0.5777440667152405
Validation loss: 1.772406058926736

Epoch: 6| Step: 9
Training loss: 0.9316504001617432
Validation loss: 1.7842507298274706

Epoch: 6| Step: 10
Training loss: 0.46626192331314087
Validation loss: 1.7652319759450934

Epoch: 6| Step: 11
Training loss: 0.45905181765556335
Validation loss: 1.7356194398736442

Epoch: 6| Step: 12
Training loss: 0.3613700866699219
Validation loss: 1.6752376107759372

Epoch: 6| Step: 13
Training loss: 0.7895867228507996
Validation loss: 1.6648690033984441

Epoch: 307| Step: 0
Training loss: 0.559938907623291
Validation loss: 1.6237347715644426

Epoch: 6| Step: 1
Training loss: 0.4023067355155945
Validation loss: 1.6714169325367096

Epoch: 6| Step: 2
Training loss: 0.35710999369621277
Validation loss: 1.6979326227659821

Epoch: 6| Step: 3
Training loss: 0.6521410346031189
Validation loss: 1.6842443789205244

Epoch: 6| Step: 4
Training loss: 0.4030085802078247
Validation loss: 1.6916304557554183

Epoch: 6| Step: 5
Training loss: 0.16830208897590637
Validation loss: 1.7215095245709984

Epoch: 6| Step: 6
Training loss: 0.3809478282928467
Validation loss: 1.7299795189211447

Epoch: 6| Step: 7
Training loss: 0.2975282669067383
Validation loss: 1.7520161982505553

Epoch: 6| Step: 8
Training loss: 0.2230844497680664
Validation loss: 1.7408398966635428

Epoch: 6| Step: 9
Training loss: 0.9130761623382568
Validation loss: 1.7269396564011932

Epoch: 6| Step: 10
Training loss: 0.38943246006965637
Validation loss: 1.6603066254687566

Epoch: 6| Step: 11
Training loss: 0.3345153331756592
Validation loss: 1.6588338985238025

Epoch: 6| Step: 12
Training loss: 0.22890229523181915
Validation loss: 1.670873054894068

Epoch: 6| Step: 13
Training loss: 0.22134804725646973
Validation loss: 1.6649235128074564

Epoch: 308| Step: 0
Training loss: 0.34490811824798584
Validation loss: 1.6918991855395737

Epoch: 6| Step: 1
Training loss: 0.26312851905822754
Validation loss: 1.6946898493715512

Epoch: 6| Step: 2
Training loss: 0.4723951816558838
Validation loss: 1.734364942837787

Epoch: 6| Step: 3
Training loss: 0.6389238834381104
Validation loss: 1.7279032507250387

Epoch: 6| Step: 4
Training loss: 0.3913875222206116
Validation loss: 1.7392743877185288

Epoch: 6| Step: 5
Training loss: 0.3034694790840149
Validation loss: 1.7412560498842629

Epoch: 6| Step: 6
Training loss: 0.4566502273082733
Validation loss: 1.7298949700529858

Epoch: 6| Step: 7
Training loss: 0.29609444737434387
Validation loss: 1.7241309304391184

Epoch: 6| Step: 8
Training loss: 0.4415910542011261
Validation loss: 1.7060601095999441

Epoch: 6| Step: 9
Training loss: 0.2703462839126587
Validation loss: 1.6604645072772939

Epoch: 6| Step: 10
Training loss: 0.37183889746665955
Validation loss: 1.6783477593493719

Epoch: 6| Step: 11
Training loss: 0.8061723709106445
Validation loss: 1.6657887966402116

Epoch: 6| Step: 12
Training loss: 0.4775935411453247
Validation loss: 1.6434474683577014

Epoch: 6| Step: 13
Training loss: 0.19709672033786774
Validation loss: 1.592826836852617

Epoch: 309| Step: 0
Training loss: 0.6118407249450684
Validation loss: 1.6062491106730636

Epoch: 6| Step: 1
Training loss: 0.6537421941757202
Validation loss: 1.613224273086876

Epoch: 6| Step: 2
Training loss: 0.3674900233745575
Validation loss: 1.5999338524315947

Epoch: 6| Step: 3
Training loss: 0.5337096452713013
Validation loss: 1.6581518534691102

Epoch: 6| Step: 4
Training loss: 0.5594589114189148
Validation loss: 1.6434261734767626

Epoch: 6| Step: 5
Training loss: 0.34988826513290405
Validation loss: 1.670973926462153

Epoch: 6| Step: 6
Training loss: 0.2480030506849289
Validation loss: 1.6683384551796863

Epoch: 6| Step: 7
Training loss: 0.39300429821014404
Validation loss: 1.7115582368707145

Epoch: 6| Step: 8
Training loss: 0.4251059889793396
Validation loss: 1.686437156892592

Epoch: 6| Step: 9
Training loss: 0.36195191740989685
Validation loss: 1.7017801269408195

Epoch: 6| Step: 10
Training loss: 0.16668838262557983
Validation loss: 1.6870862771106023

Epoch: 6| Step: 11
Training loss: 0.4768733084201813
Validation loss: 1.703591827423342

Epoch: 6| Step: 12
Training loss: 0.37098151445388794
Validation loss: 1.7062447814531223

Epoch: 6| Step: 13
Training loss: 0.3387325406074524
Validation loss: 1.7131092394551923

Epoch: 310| Step: 0
Training loss: 0.4041696786880493
Validation loss: 1.7151769515006774

Epoch: 6| Step: 1
Training loss: 0.4259547293186188
Validation loss: 1.745567916541971

Epoch: 6| Step: 2
Training loss: 0.7104877233505249
Validation loss: 1.7561417882160475

Epoch: 6| Step: 3
Training loss: 0.3868117332458496
Validation loss: 1.7460852335858088

Epoch: 6| Step: 4
Training loss: 0.4516916275024414
Validation loss: 1.71932928921074

Epoch: 6| Step: 5
Training loss: 0.2503361701965332
Validation loss: 1.6919715481419717

Epoch: 6| Step: 6
Training loss: 0.3041379451751709
Validation loss: 1.6677845652385423

Epoch: 6| Step: 7
Training loss: 0.37245672941207886
Validation loss: 1.6661968564474454

Epoch: 6| Step: 8
Training loss: 0.1846545934677124
Validation loss: 1.6380696822238225

Epoch: 6| Step: 9
Training loss: 0.4269891679286957
Validation loss: 1.6345037516727243

Epoch: 6| Step: 10
Training loss: 0.503275990486145
Validation loss: 1.6112952680997952

Epoch: 6| Step: 11
Training loss: 0.5211265087127686
Validation loss: 1.6188005619151618

Epoch: 6| Step: 12
Training loss: 0.29197949171066284
Validation loss: 1.6446308846114783

Epoch: 6| Step: 13
Training loss: 0.16961902379989624
Validation loss: 1.6649502118428547

Epoch: 311| Step: 0
Training loss: 0.3407588601112366
Validation loss: 1.7013335458693966

Epoch: 6| Step: 1
Training loss: 0.4369257092475891
Validation loss: 1.6982176752500637

Epoch: 6| Step: 2
Training loss: 0.549166738986969
Validation loss: 1.721133021898167

Epoch: 6| Step: 3
Training loss: 0.1821204572916031
Validation loss: 1.7331877100852229

Epoch: 6| Step: 4
Training loss: 0.49871379137039185
Validation loss: 1.7254868156166487

Epoch: 6| Step: 5
Training loss: 0.48531574010849
Validation loss: 1.731662541307429

Epoch: 6| Step: 6
Training loss: 0.4663456976413727
Validation loss: 1.7062690258026123

Epoch: 6| Step: 7
Training loss: 0.2608233094215393
Validation loss: 1.670201398993051

Epoch: 6| Step: 8
Training loss: 0.28224846720695496
Validation loss: 1.6429046905168923

Epoch: 6| Step: 9
Training loss: 0.4674484133720398
Validation loss: 1.6536917532643964

Epoch: 6| Step: 10
Training loss: 0.3180616497993469
Validation loss: 1.6321330916497014

Epoch: 6| Step: 11
Training loss: 0.8341382741928101
Validation loss: 1.6393201966439523

Epoch: 6| Step: 12
Training loss: 0.2461402714252472
Validation loss: 1.6299166884473575

Epoch: 6| Step: 13
Training loss: 0.18254715204238892
Validation loss: 1.6109197690922727

Epoch: 312| Step: 0
Training loss: 0.3952891230583191
Validation loss: 1.6118976031580279

Epoch: 6| Step: 1
Training loss: 0.5031757354736328
Validation loss: 1.6213905401127313

Epoch: 6| Step: 2
Training loss: 0.30269432067871094
Validation loss: 1.6454041952727942

Epoch: 6| Step: 3
Training loss: 0.5241912603378296
Validation loss: 1.668492897864311

Epoch: 6| Step: 4
Training loss: 0.3815070390701294
Validation loss: 1.693259991625304

Epoch: 6| Step: 5
Training loss: 0.3242858648300171
Validation loss: 1.7122171226368155

Epoch: 6| Step: 6
Training loss: 0.3358941674232483
Validation loss: 1.732431250233804

Epoch: 6| Step: 7
Training loss: 0.4810708463191986
Validation loss: 1.7707530336995279

Epoch: 6| Step: 8
Training loss: 0.31032830476760864
Validation loss: 1.7452438313473937

Epoch: 6| Step: 9
Training loss: 0.44822487235069275
Validation loss: 1.731301966533866

Epoch: 6| Step: 10
Training loss: 0.48759257793426514
Validation loss: 1.736063544468213

Epoch: 6| Step: 11
Training loss: 0.40537017583847046
Validation loss: 1.7111365333680184

Epoch: 6| Step: 12
Training loss: 0.5224224328994751
Validation loss: 1.7126899201382872

Epoch: 6| Step: 13
Training loss: 0.2713368833065033
Validation loss: 1.6962211952414563

Epoch: 313| Step: 0
Training loss: 0.41940250992774963
Validation loss: 1.6825256142565

Epoch: 6| Step: 1
Training loss: 0.35255110263824463
Validation loss: 1.6730640460086126

Epoch: 6| Step: 2
Training loss: 0.3865046501159668
Validation loss: 1.6671290115643573

Epoch: 6| Step: 3
Training loss: 0.28597742319107056
Validation loss: 1.6342724805237145

Epoch: 6| Step: 4
Training loss: 0.38392940163612366
Validation loss: 1.6565294214474258

Epoch: 6| Step: 5
Training loss: 0.39000439643859863
Validation loss: 1.6540732076091151

Epoch: 6| Step: 6
Training loss: 0.5596956014633179
Validation loss: 1.7243596123110863

Epoch: 6| Step: 7
Training loss: 0.4433419704437256
Validation loss: 1.7648289254916611

Epoch: 6| Step: 8
Training loss: 0.8096319437026978
Validation loss: 1.7726892873805056

Epoch: 6| Step: 9
Training loss: 0.19858680665493011
Validation loss: 1.727111885624547

Epoch: 6| Step: 10
Training loss: 0.24868790805339813
Validation loss: 1.6775904381146995

Epoch: 6| Step: 11
Training loss: 0.24691811203956604
Validation loss: 1.6395229037090013

Epoch: 6| Step: 12
Training loss: 0.5663425922393799
Validation loss: 1.631688206426559

Epoch: 6| Step: 13
Training loss: 0.4253648817539215
Validation loss: 1.6306907143644107

Epoch: 314| Step: 0
Training loss: 0.5902451276779175
Validation loss: 1.620819180242477

Epoch: 6| Step: 1
Training loss: 0.5849239826202393
Validation loss: 1.6353675985849032

Epoch: 6| Step: 2
Training loss: 0.2968757450580597
Validation loss: 1.6337677560826784

Epoch: 6| Step: 3
Training loss: 0.30931198596954346
Validation loss: 1.6641048333978141

Epoch: 6| Step: 4
Training loss: 0.5281451344490051
Validation loss: 1.6505738086597894

Epoch: 6| Step: 5
Training loss: 0.4577140510082245
Validation loss: 1.6662778335232888

Epoch: 6| Step: 6
Training loss: 0.26234740018844604
Validation loss: 1.651870865975657

Epoch: 6| Step: 7
Training loss: 0.3173346221446991
Validation loss: 1.6378453239317863

Epoch: 6| Step: 8
Training loss: 0.3318904638290405
Validation loss: 1.6100116199062717

Epoch: 6| Step: 9
Training loss: 0.32519835233688354
Validation loss: 1.5871252295791463

Epoch: 6| Step: 10
Training loss: 0.3154829144477844
Validation loss: 1.569192155714958

Epoch: 6| Step: 11
Training loss: 0.4528658986091614
Validation loss: 1.5652501454917334

Epoch: 6| Step: 12
Training loss: 0.11148495227098465
Validation loss: 1.5863410644633795

Epoch: 6| Step: 13
Training loss: 0.36937394738197327
Validation loss: 1.6122974029151342

Epoch: 315| Step: 0
Training loss: 0.35647913813591003
Validation loss: 1.680499788253538

Epoch: 6| Step: 1
Training loss: 0.24240010976791382
Validation loss: 1.718791796315101

Epoch: 6| Step: 2
Training loss: 0.27765709161758423
Validation loss: 1.6971456004727272

Epoch: 6| Step: 3
Training loss: 0.4115945100784302
Validation loss: 1.7101922394126974

Epoch: 6| Step: 4
Training loss: 0.2649843692779541
Validation loss: 1.703186014647125

Epoch: 6| Step: 5
Training loss: 0.7806751728057861
Validation loss: 1.6652461200632074

Epoch: 6| Step: 6
Training loss: 0.3675087094306946
Validation loss: 1.6818130247054561

Epoch: 6| Step: 7
Training loss: 0.437466561794281
Validation loss: 1.6440322283775575

Epoch: 6| Step: 8
Training loss: 0.2694084942340851
Validation loss: 1.6568339332457511

Epoch: 6| Step: 9
Training loss: 0.23143893480300903
Validation loss: 1.6542565694419287

Epoch: 6| Step: 10
Training loss: 0.2886645793914795
Validation loss: 1.6556030575947096

Epoch: 6| Step: 11
Training loss: 0.5314471125602722
Validation loss: 1.6343853832573019

Epoch: 6| Step: 12
Training loss: 0.3482736349105835
Validation loss: 1.6983478787124797

Epoch: 6| Step: 13
Training loss: 0.4849904477596283
Validation loss: 1.6786543387238697

Epoch: 316| Step: 0
Training loss: 0.3583478331565857
Validation loss: 1.7017331020806425

Epoch: 6| Step: 1
Training loss: 0.2919148802757263
Validation loss: 1.6860936739111458

Epoch: 6| Step: 2
Training loss: 0.31527605652809143
Validation loss: 1.6943740690908125

Epoch: 6| Step: 3
Training loss: 0.3604901432991028
Validation loss: 1.6825047731399536

Epoch: 6| Step: 4
Training loss: 0.41453200578689575
Validation loss: 1.7051395600841892

Epoch: 6| Step: 5
Training loss: 0.44159722328186035
Validation loss: 1.6887347031665105

Epoch: 6| Step: 6
Training loss: 0.263004869222641
Validation loss: 1.7118706677549629

Epoch: 6| Step: 7
Training loss: 0.5966534614562988
Validation loss: 1.691396726075039

Epoch: 6| Step: 8
Training loss: 0.4060957431793213
Validation loss: 1.6778017013303694

Epoch: 6| Step: 9
Training loss: 0.30020761489868164
Validation loss: 1.6733626780971405

Epoch: 6| Step: 10
Training loss: 0.34482234716415405
Validation loss: 1.67247982435329

Epoch: 6| Step: 11
Training loss: 0.5270471572875977
Validation loss: 1.6673940484241774

Epoch: 6| Step: 12
Training loss: 0.26836127042770386
Validation loss: 1.6259522168867049

Epoch: 6| Step: 13
Training loss: 0.2737373113632202
Validation loss: 1.6203370696754866

Epoch: 317| Step: 0
Training loss: 0.17604772746562958
Validation loss: 1.5972651409846481

Epoch: 6| Step: 1
Training loss: 0.32823991775512695
Validation loss: 1.5884302252082414

Epoch: 6| Step: 2
Training loss: 0.2971894145011902
Validation loss: 1.588758505800719

Epoch: 6| Step: 3
Training loss: 0.36790433526039124
Validation loss: 1.5782708762794413

Epoch: 6| Step: 4
Training loss: 0.27896296977996826
Validation loss: 1.5885275666431715

Epoch: 6| Step: 5
Training loss: 0.8480650186538696
Validation loss: 1.5905471078811153

Epoch: 6| Step: 6
Training loss: 0.4237842559814453
Validation loss: 1.5786592844993836

Epoch: 6| Step: 7
Training loss: 0.3451084792613983
Validation loss: 1.6146920355417396

Epoch: 6| Step: 8
Training loss: 0.3101269602775574
Validation loss: 1.6374973789338143

Epoch: 6| Step: 9
Training loss: 0.3785340189933777
Validation loss: 1.6507985348342566

Epoch: 6| Step: 10
Training loss: 0.5016319751739502
Validation loss: 1.6671848207391717

Epoch: 6| Step: 11
Training loss: 0.23819267749786377
Validation loss: 1.6687630466235581

Epoch: 6| Step: 12
Training loss: 0.2691807746887207
Validation loss: 1.6250785537945327

Epoch: 6| Step: 13
Training loss: 0.3629046678543091
Validation loss: 1.6073612384898688

Epoch: 318| Step: 0
Training loss: 0.4233866035938263
Validation loss: 1.58360856322832

Epoch: 6| Step: 1
Training loss: 0.420183390378952
Validation loss: 1.595271142580176

Epoch: 6| Step: 2
Training loss: 0.4792601466178894
Validation loss: 1.5867347460921093

Epoch: 6| Step: 3
Training loss: 0.55302894115448
Validation loss: 1.5980596644904024

Epoch: 6| Step: 4
Training loss: 0.28319060802459717
Validation loss: 1.6312548678408387

Epoch: 6| Step: 5
Training loss: 0.42854082584381104
Validation loss: 1.6224578510048568

Epoch: 6| Step: 6
Training loss: 0.21578845381736755
Validation loss: 1.6031180069010744

Epoch: 6| Step: 7
Training loss: 0.4263434410095215
Validation loss: 1.6612823317127843

Epoch: 6| Step: 8
Training loss: 0.35101866722106934
Validation loss: 1.6667641196199643

Epoch: 6| Step: 9
Training loss: 0.3101068139076233
Validation loss: 1.630751440601964

Epoch: 6| Step: 10
Training loss: 0.43211403489112854
Validation loss: 1.6763918092173915

Epoch: 6| Step: 11
Training loss: 0.27128440141677856
Validation loss: 1.6352363696662329

Epoch: 6| Step: 12
Training loss: 0.16957253217697144
Validation loss: 1.6495125844914427

Epoch: 6| Step: 13
Training loss: 0.4438501000404358
Validation loss: 1.6318820779041578

Epoch: 319| Step: 0
Training loss: 0.3546983301639557
Validation loss: 1.6408490045096285

Epoch: 6| Step: 1
Training loss: 0.17980670928955078
Validation loss: 1.63399209642923

Epoch: 6| Step: 2
Training loss: 0.5502212047576904
Validation loss: 1.6088217317417104

Epoch: 6| Step: 3
Training loss: 0.23867645859718323
Validation loss: 1.6321058247679023

Epoch: 6| Step: 4
Training loss: 0.2917037010192871
Validation loss: 1.6382093698747697

Epoch: 6| Step: 5
Training loss: 0.35061728954315186
Validation loss: 1.629194736480713

Epoch: 6| Step: 6
Training loss: 0.2872927784919739
Validation loss: 1.6223592809451524

Epoch: 6| Step: 7
Training loss: 0.7133066654205322
Validation loss: 1.652595373892015

Epoch: 6| Step: 8
Training loss: 0.5465354323387146
Validation loss: 1.645550053606751

Epoch: 6| Step: 9
Training loss: 0.262487530708313
Validation loss: 1.6301419260681316

Epoch: 6| Step: 10
Training loss: 0.4026753902435303
Validation loss: 1.6386347688654417

Epoch: 6| Step: 11
Training loss: 0.4669985771179199
Validation loss: 1.6542476146451888

Epoch: 6| Step: 12
Training loss: 0.2175920605659485
Validation loss: 1.631361948546543

Epoch: 6| Step: 13
Training loss: 0.1964428573846817
Validation loss: 1.6236376063798064

Epoch: 320| Step: 0
Training loss: 0.24694932997226715
Validation loss: 1.605127546095079

Epoch: 6| Step: 1
Training loss: 0.25351905822753906
Validation loss: 1.5763944502799743

Epoch: 6| Step: 2
Training loss: 0.3750160038471222
Validation loss: 1.5755991012819353

Epoch: 6| Step: 3
Training loss: 0.21642500162124634
Validation loss: 1.578881065050761

Epoch: 6| Step: 4
Training loss: 0.3346864581108093
Validation loss: 1.5631509442483225

Epoch: 6| Step: 5
Training loss: 0.37255048751831055
Validation loss: 1.5725317885798793

Epoch: 6| Step: 6
Training loss: 0.6280587911605835
Validation loss: 1.5708286659691924

Epoch: 6| Step: 7
Training loss: 0.24011404812335968
Validation loss: 1.5682528083042433

Epoch: 6| Step: 8
Training loss: 0.5441685914993286
Validation loss: 1.612149687223537

Epoch: 6| Step: 9
Training loss: 0.534770131111145
Validation loss: 1.6122388737176054

Epoch: 6| Step: 10
Training loss: 0.19673067331314087
Validation loss: 1.6225912058225243

Epoch: 6| Step: 11
Training loss: 0.2853246331214905
Validation loss: 1.6245758777023644

Epoch: 6| Step: 12
Training loss: 0.19409765303134918
Validation loss: 1.6435276077639671

Epoch: 6| Step: 13
Training loss: 0.5655279159545898
Validation loss: 1.67224823018556

Epoch: 321| Step: 0
Training loss: 0.42975854873657227
Validation loss: 1.6981140041864047

Epoch: 6| Step: 1
Training loss: 0.6875083446502686
Validation loss: 1.7036567836679437

Epoch: 6| Step: 2
Training loss: 0.45950350165367126
Validation loss: 1.6522516794102167

Epoch: 6| Step: 3
Training loss: 0.13428828120231628
Validation loss: 1.61425071249726

Epoch: 6| Step: 4
Training loss: 0.24543516337871552
Validation loss: 1.5731098292976298

Epoch: 6| Step: 5
Training loss: 0.22025898098945618
Validation loss: 1.557380526296554

Epoch: 6| Step: 6
Training loss: 0.32950109243392944
Validation loss: 1.5535458646794802

Epoch: 6| Step: 7
Training loss: 0.2742726802825928
Validation loss: 1.5509243729293987

Epoch: 6| Step: 8
Training loss: 0.550557017326355
Validation loss: 1.5654946309263988

Epoch: 6| Step: 9
Training loss: 0.4017177224159241
Validation loss: 1.586598543710606

Epoch: 6| Step: 10
Training loss: 0.19070729613304138
Validation loss: 1.592877689228263

Epoch: 6| Step: 11
Training loss: 0.31762897968292236
Validation loss: 1.6031209243241178

Epoch: 6| Step: 12
Training loss: 0.2157387137413025
Validation loss: 1.6012099468579857

Epoch: 6| Step: 13
Training loss: 0.3437974452972412
Validation loss: 1.6152649438509377

Epoch: 322| Step: 0
Training loss: 0.08071798831224442
Validation loss: 1.577286026811087

Epoch: 6| Step: 1
Training loss: 0.3186531066894531
Validation loss: 1.6113855146592664

Epoch: 6| Step: 2
Training loss: 0.4060264825820923
Validation loss: 1.6305293825364882

Epoch: 6| Step: 3
Training loss: 0.3004017174243927
Validation loss: 1.6206072735530075

Epoch: 6| Step: 4
Training loss: 0.46165376901626587
Validation loss: 1.6167896152824484

Epoch: 6| Step: 5
Training loss: 0.2709483206272125
Validation loss: 1.6222335471901843

Epoch: 6| Step: 6
Training loss: 0.4840298891067505
Validation loss: 1.644473906486265

Epoch: 6| Step: 7
Training loss: 0.5918445587158203
Validation loss: 1.6811868529165945

Epoch: 6| Step: 8
Training loss: 0.5832823514938354
Validation loss: 1.6777368976223854

Epoch: 6| Step: 9
Training loss: 0.2561635375022888
Validation loss: 1.694993249831661

Epoch: 6| Step: 10
Training loss: 0.3220801055431366
Validation loss: 1.721879183605153

Epoch: 6| Step: 11
Training loss: 0.40021800994873047
Validation loss: 1.6702864477711339

Epoch: 6| Step: 12
Training loss: 0.1487041413784027
Validation loss: 1.6110409421305503

Epoch: 6| Step: 13
Training loss: 0.4482768774032593
Validation loss: 1.5850667133126208

Epoch: 323| Step: 0
Training loss: 0.2989494502544403
Validation loss: 1.5867306686216784

Epoch: 6| Step: 1
Training loss: 0.1744401901960373
Validation loss: 1.5699368023103284

Epoch: 6| Step: 2
Training loss: 0.5044355392456055
Validation loss: 1.5532214667207451

Epoch: 6| Step: 3
Training loss: 0.26474466919898987
Validation loss: 1.5413501890756751

Epoch: 6| Step: 4
Training loss: 0.30953800678253174
Validation loss: 1.591435956698592

Epoch: 6| Step: 5
Training loss: 0.31620895862579346
Validation loss: 1.6013324734985188

Epoch: 6| Step: 6
Training loss: 0.37836289405822754
Validation loss: 1.6571396307278705

Epoch: 6| Step: 7
Training loss: 0.31669914722442627
Validation loss: 1.6720930748088385

Epoch: 6| Step: 8
Training loss: 0.7229625582695007
Validation loss: 1.7088006747666227

Epoch: 6| Step: 9
Training loss: 0.23420222103595734
Validation loss: 1.6922910598016554

Epoch: 6| Step: 10
Training loss: 0.199232280254364
Validation loss: 1.671281426183639

Epoch: 6| Step: 11
Training loss: 0.09146157652139664
Validation loss: 1.6686150322678268

Epoch: 6| Step: 12
Training loss: 0.44629645347595215
Validation loss: 1.6774838252734112

Epoch: 6| Step: 13
Training loss: 0.23808890581130981
Validation loss: 1.6634384778238112

Epoch: 324| Step: 0
Training loss: 0.2798455059528351
Validation loss: 1.636953135972382

Epoch: 6| Step: 1
Training loss: 0.4494321942329407
Validation loss: 1.5790302215083953

Epoch: 6| Step: 2
Training loss: 0.19287116825580597
Validation loss: 1.5534811058352072

Epoch: 6| Step: 3
Training loss: 0.2625696659088135
Validation loss: 1.5622690800697572

Epoch: 6| Step: 4
Training loss: 0.45438477396965027
Validation loss: 1.5175486303144885

Epoch: 6| Step: 5
Training loss: 0.34493330121040344
Validation loss: 1.5110237572782783

Epoch: 6| Step: 6
Training loss: 0.26726996898651123
Validation loss: 1.5358409022772184

Epoch: 6| Step: 7
Training loss: 0.3081843852996826
Validation loss: 1.5650602957253814

Epoch: 6| Step: 8
Training loss: 0.4345338046550751
Validation loss: 1.6206453961710776

Epoch: 6| Step: 9
Training loss: 0.2817080020904541
Validation loss: 1.6569365762895154

Epoch: 6| Step: 10
Training loss: 0.37211745977401733
Validation loss: 1.678919171774259

Epoch: 6| Step: 11
Training loss: 0.6089920401573181
Validation loss: 1.7196759485429334

Epoch: 6| Step: 12
Training loss: 0.33137696981430054
Validation loss: 1.7742226854447396

Epoch: 6| Step: 13
Training loss: 0.5277189016342163
Validation loss: 1.7658169384925597

Epoch: 325| Step: 0
Training loss: 0.3953089118003845
Validation loss: 1.7493934144255936

Epoch: 6| Step: 1
Training loss: 0.23398825526237488
Validation loss: 1.6862322873966669

Epoch: 6| Step: 2
Training loss: 0.1963631957769394
Validation loss: 1.6403288225973807

Epoch: 6| Step: 3
Training loss: 0.23788809776306152
Validation loss: 1.59123440711729

Epoch: 6| Step: 4
Training loss: 0.3538580536842346
Validation loss: 1.5978979051754039

Epoch: 6| Step: 5
Training loss: 0.9364617466926575
Validation loss: 1.5576471064680366

Epoch: 6| Step: 6
Training loss: 0.3509930968284607
Validation loss: 1.5536577996387277

Epoch: 6| Step: 7
Training loss: 0.26312726736068726
Validation loss: 1.5085436746638308

Epoch: 6| Step: 8
Training loss: 0.3865140378475189
Validation loss: 1.525750135862699

Epoch: 6| Step: 9
Training loss: 0.2899710536003113
Validation loss: 1.529058248766007

Epoch: 6| Step: 10
Training loss: 0.17926129698753357
Validation loss: 1.5674943757313553

Epoch: 6| Step: 11
Training loss: 0.3115956485271454
Validation loss: 1.5841607022029098

Epoch: 6| Step: 12
Training loss: 0.3221445083618164
Validation loss: 1.6182722058347476

Epoch: 6| Step: 13
Training loss: 0.2075670212507248
Validation loss: 1.6496410933873986

Epoch: 326| Step: 0
Training loss: 0.34763669967651367
Validation loss: 1.7217216145607732

Epoch: 6| Step: 1
Training loss: 0.37745174765586853
Validation loss: 1.7850689477817987

Epoch: 6| Step: 2
Training loss: 0.37906795740127563
Validation loss: 1.7961061129006006

Epoch: 6| Step: 3
Training loss: 0.6783788800239563
Validation loss: 1.7524838819298694

Epoch: 6| Step: 4
Training loss: 0.38900482654571533
Validation loss: 1.678002365173832

Epoch: 6| Step: 5
Training loss: 0.27473729848861694
Validation loss: 1.62282734147964

Epoch: 6| Step: 6
Training loss: 0.32027435302734375
Validation loss: 1.5662642653270433

Epoch: 6| Step: 7
Training loss: 0.5017237663269043
Validation loss: 1.5246277009287188

Epoch: 6| Step: 8
Training loss: 0.24353991448879242
Validation loss: 1.5330493104073308

Epoch: 6| Step: 9
Training loss: 0.4141491651535034
Validation loss: 1.5202510664539952

Epoch: 6| Step: 10
Training loss: 0.3020690977573395
Validation loss: 1.5410432354096444

Epoch: 6| Step: 11
Training loss: 0.3031293749809265
Validation loss: 1.5575620807627195

Epoch: 6| Step: 12
Training loss: 0.1787678450345993
Validation loss: 1.5750695172176565

Epoch: 6| Step: 13
Training loss: 0.39639562368392944
Validation loss: 1.6011304611800818

Epoch: 327| Step: 0
Training loss: 0.21607288718223572
Validation loss: 1.6023901431791243

Epoch: 6| Step: 1
Training loss: 0.2875324785709381
Validation loss: 1.6535503838651924

Epoch: 6| Step: 2
Training loss: 0.3129464387893677
Validation loss: 1.6489285371636833

Epoch: 6| Step: 3
Training loss: 0.4910351037979126
Validation loss: 1.6920121792824037

Epoch: 6| Step: 4
Training loss: 0.3948383033275604
Validation loss: 1.6678850163695633

Epoch: 6| Step: 5
Training loss: 0.3014366626739502
Validation loss: 1.6457421933451006

Epoch: 6| Step: 6
Training loss: 0.44528207182884216
Validation loss: 1.603885914689751

Epoch: 6| Step: 7
Training loss: 0.34938251972198486
Validation loss: 1.5842916914211806

Epoch: 6| Step: 8
Training loss: 0.19799725711345673
Validation loss: 1.5445482807774698

Epoch: 6| Step: 9
Training loss: 0.28427061438560486
Validation loss: 1.5650104053558842

Epoch: 6| Step: 10
Training loss: 0.2570764720439911
Validation loss: 1.6038268958368609

Epoch: 6| Step: 11
Training loss: 0.3922147750854492
Validation loss: 1.6242165924400411

Epoch: 6| Step: 12
Training loss: 0.33427345752716064
Validation loss: 1.6251440714764338

Epoch: 6| Step: 13
Training loss: 0.6905529499053955
Validation loss: 1.6012721548798263

Epoch: 328| Step: 0
Training loss: 0.2625058889389038
Validation loss: 1.6241755921353576

Epoch: 6| Step: 1
Training loss: 0.1721632182598114
Validation loss: 1.6241520630416049

Epoch: 6| Step: 2
Training loss: 0.5597337484359741
Validation loss: 1.6609796490720523

Epoch: 6| Step: 3
Training loss: 0.31360387802124023
Validation loss: 1.6393056249105802

Epoch: 6| Step: 4
Training loss: 0.2945956289768219
Validation loss: 1.6553324255892026

Epoch: 6| Step: 5
Training loss: 0.3600460886955261
Validation loss: 1.6355896470367268

Epoch: 6| Step: 6
Training loss: 0.43077513575553894
Validation loss: 1.6078909212543118

Epoch: 6| Step: 7
Training loss: 0.34912389516830444
Validation loss: 1.6040859568503596

Epoch: 6| Step: 8
Training loss: 0.14385586977005005
Validation loss: 1.6187607293487878

Epoch: 6| Step: 9
Training loss: 0.36952710151672363
Validation loss: 1.61262603985366

Epoch: 6| Step: 10
Training loss: 0.6124290227890015
Validation loss: 1.6089866725347375

Epoch: 6| Step: 11
Training loss: 0.2421031892299652
Validation loss: 1.6459049601708688

Epoch: 6| Step: 12
Training loss: 0.3308156132698059
Validation loss: 1.620750964328807

Epoch: 6| Step: 13
Training loss: 0.15798304975032806
Validation loss: 1.6029334324662403

Epoch: 329| Step: 0
Training loss: 0.36234748363494873
Validation loss: 1.6113350814388645

Epoch: 6| Step: 1
Training loss: 0.20184947550296783
Validation loss: 1.6414861377849375

Epoch: 6| Step: 2
Training loss: 0.5325429439544678
Validation loss: 1.6305232048034668

Epoch: 6| Step: 3
Training loss: 0.5798339247703552
Validation loss: 1.6622213996866697

Epoch: 6| Step: 4
Training loss: 0.27684280276298523
Validation loss: 1.745835268369285

Epoch: 6| Step: 5
Training loss: 0.42081066966056824
Validation loss: 1.7403567157765871

Epoch: 6| Step: 6
Training loss: 0.3515337109565735
Validation loss: 1.7408491167970883

Epoch: 6| Step: 7
Training loss: 0.6088132262229919
Validation loss: 1.7105594963155768

Epoch: 6| Step: 8
Training loss: 0.26572415232658386
Validation loss: 1.6398335054356565

Epoch: 6| Step: 9
Training loss: 0.389300137758255
Validation loss: 1.6310695095728802

Epoch: 6| Step: 10
Training loss: 0.17464017868041992
Validation loss: 1.577485756207538

Epoch: 6| Step: 11
Training loss: 0.33875608444213867
Validation loss: 1.5502139233773755

Epoch: 6| Step: 12
Training loss: 0.28194406628608704
Validation loss: 1.5422230741029144

Epoch: 6| Step: 13
Training loss: 0.1444123387336731
Validation loss: 1.5507897177050192

Epoch: 330| Step: 0
Training loss: 0.3598640263080597
Validation loss: 1.5691205686138523

Epoch: 6| Step: 1
Training loss: 0.33657681941986084
Validation loss: 1.5545945359814552

Epoch: 6| Step: 2
Training loss: 0.3153085708618164
Validation loss: 1.5593134408356042

Epoch: 6| Step: 3
Training loss: 0.5896584391593933
Validation loss: 1.5965479202167963

Epoch: 6| Step: 4
Training loss: 0.3151596784591675
Validation loss: 1.6142430690027052

Epoch: 6| Step: 5
Training loss: 0.3633018136024475
Validation loss: 1.6648012861128776

Epoch: 6| Step: 6
Training loss: 0.28336408734321594
Validation loss: 1.7176223993301392

Epoch: 6| Step: 7
Training loss: 0.37317895889282227
Validation loss: 1.7007833975617603

Epoch: 6| Step: 8
Training loss: 0.2291327714920044
Validation loss: 1.6895106812959075

Epoch: 6| Step: 9
Training loss: 0.244659423828125
Validation loss: 1.626373666588978

Epoch: 6| Step: 10
Training loss: 0.5476746559143066
Validation loss: 1.5818504864169705

Epoch: 6| Step: 11
Training loss: 0.3387845754623413
Validation loss: 1.5513466051829758

Epoch: 6| Step: 12
Training loss: 0.21409015357494354
Validation loss: 1.520958189041384

Epoch: 6| Step: 13
Training loss: 0.36456945538520813
Validation loss: 1.5261358496963338

Epoch: 331| Step: 0
Training loss: 0.5423357486724854
Validation loss: 1.5487976292128205

Epoch: 6| Step: 1
Training loss: 0.3811054825782776
Validation loss: 1.5114029915102067

Epoch: 6| Step: 2
Training loss: 0.45119911432266235
Validation loss: 1.572170513932423

Epoch: 6| Step: 3
Training loss: 0.4195728898048401
Validation loss: 1.5664422153144755

Epoch: 6| Step: 4
Training loss: 0.31480300426483154
Validation loss: 1.6032074042545852

Epoch: 6| Step: 5
Training loss: 0.28615602850914
Validation loss: 1.5982167067066315

Epoch: 6| Step: 6
Training loss: 0.2970597743988037
Validation loss: 1.6150452334393737

Epoch: 6| Step: 7
Training loss: 0.19164559245109558
Validation loss: 1.6249498295527633

Epoch: 6| Step: 8
Training loss: 0.3466022312641144
Validation loss: 1.6258016465812601

Epoch: 6| Step: 9
Training loss: 0.23521696031093597
Validation loss: 1.64288200998819

Epoch: 6| Step: 10
Training loss: 0.2882469594478607
Validation loss: 1.6105383006475305

Epoch: 6| Step: 11
Training loss: 0.4885481595993042
Validation loss: 1.5925163017806185

Epoch: 6| Step: 12
Training loss: 0.3292221426963806
Validation loss: 1.5602678534805134

Epoch: 6| Step: 13
Training loss: 0.36170727014541626
Validation loss: 1.5491084091124996

Epoch: 332| Step: 0
Training loss: 0.45306530594825745
Validation loss: 1.511351199560268

Epoch: 6| Step: 1
Training loss: 0.4474833607673645
Validation loss: 1.5193579966022122

Epoch: 6| Step: 2
Training loss: 0.36230435967445374
Validation loss: 1.5665612592492053

Epoch: 6| Step: 3
Training loss: 0.40294361114501953
Validation loss: 1.585791100737869

Epoch: 6| Step: 4
Training loss: 0.37963104248046875
Validation loss: 1.5856633006885488

Epoch: 6| Step: 5
Training loss: 0.39125964045524597
Validation loss: 1.5752251173860283

Epoch: 6| Step: 6
Training loss: 0.17544543743133545
Validation loss: 1.5936133951269171

Epoch: 6| Step: 7
Training loss: 0.31558966636657715
Validation loss: 1.6059887812983604

Epoch: 6| Step: 8
Training loss: 0.33762410283088684
Validation loss: 1.61708519663862

Epoch: 6| Step: 9
Training loss: 0.20474781095981598
Validation loss: 1.6167327460422312

Epoch: 6| Step: 10
Training loss: 0.5646581649780273
Validation loss: 1.5884540991116596

Epoch: 6| Step: 11
Training loss: 0.23732289671897888
Validation loss: 1.5919676544845744

Epoch: 6| Step: 12
Training loss: 0.19502602517604828
Validation loss: 1.6044961726793678

Epoch: 6| Step: 13
Training loss: 0.4480455219745636
Validation loss: 1.647029439608256

Epoch: 333| Step: 0
Training loss: 0.2307370901107788
Validation loss: 1.6268505973200644

Epoch: 6| Step: 1
Training loss: 0.2932826280593872
Validation loss: 1.6358875510513142

Epoch: 6| Step: 2
Training loss: 0.21628104150295258
Validation loss: 1.605425702628269

Epoch: 6| Step: 3
Training loss: 0.43729591369628906
Validation loss: 1.5867126013642998

Epoch: 6| Step: 4
Training loss: 0.35762447118759155
Validation loss: 1.5931764046351116

Epoch: 6| Step: 5
Training loss: 0.3092281222343445
Validation loss: 1.5445460299009919

Epoch: 6| Step: 6
Training loss: 0.3820156455039978
Validation loss: 1.5425972489900486

Epoch: 6| Step: 7
Training loss: 0.26447242498397827
Validation loss: 1.5518394606087798

Epoch: 6| Step: 8
Training loss: 0.4487929940223694
Validation loss: 1.550844609096486

Epoch: 6| Step: 9
Training loss: 0.3679507076740265
Validation loss: 1.5631823334642636

Epoch: 6| Step: 10
Training loss: 0.2970747947692871
Validation loss: 1.5917621312602874

Epoch: 6| Step: 11
Training loss: 0.3049018681049347
Validation loss: 1.611504949549193

Epoch: 6| Step: 12
Training loss: 0.290559858083725
Validation loss: 1.6309795905185003

Epoch: 6| Step: 13
Training loss: 0.2789265215396881
Validation loss: 1.6424556932141703

Epoch: 334| Step: 0
Training loss: 0.13778945803642273
Validation loss: 1.6612302846806024

Epoch: 6| Step: 1
Training loss: 0.2104858160018921
Validation loss: 1.6889763673146565

Epoch: 6| Step: 2
Training loss: 0.6371713876724243
Validation loss: 1.7045573265321794

Epoch: 6| Step: 3
Training loss: 0.21878312528133392
Validation loss: 1.6882545307118406

Epoch: 6| Step: 4
Training loss: 0.4587893486022949
Validation loss: 1.6911406568301621

Epoch: 6| Step: 5
Training loss: 0.39388373494148254
Validation loss: 1.708337762022531

Epoch: 6| Step: 6
Training loss: 0.1544080525636673
Validation loss: 1.6756554854813444

Epoch: 6| Step: 7
Training loss: 0.25117307901382446
Validation loss: 1.6426262368438065

Epoch: 6| Step: 8
Training loss: 0.18838408589363098
Validation loss: 1.6184370876640402

Epoch: 6| Step: 9
Training loss: 0.20394940674304962
Validation loss: 1.5839662398061445

Epoch: 6| Step: 10
Training loss: 0.19101043045520782
Validation loss: 1.5602520204359485

Epoch: 6| Step: 11
Training loss: 0.28940531611442566
Validation loss: 1.5216090051076745

Epoch: 6| Step: 12
Training loss: 0.6111980080604553
Validation loss: 1.5105828956891132

Epoch: 6| Step: 13
Training loss: 0.4458672106266022
Validation loss: 1.477710985688753

Epoch: 335| Step: 0
Training loss: 0.3875179886817932
Validation loss: 1.4789316417068563

Epoch: 6| Step: 1
Training loss: 0.295549213886261
Validation loss: 1.5106436578176354

Epoch: 6| Step: 2
Training loss: 0.27813029289245605
Validation loss: 1.5029212979860203

Epoch: 6| Step: 3
Training loss: 0.20694392919540405
Validation loss: 1.5424488770064486

Epoch: 6| Step: 4
Training loss: 0.20582035183906555
Validation loss: 1.5685272088614843

Epoch: 6| Step: 5
Training loss: 0.4676121473312378
Validation loss: 1.628446049587701

Epoch: 6| Step: 6
Training loss: 0.11747515201568604
Validation loss: 1.7091941231040544

Epoch: 6| Step: 7
Training loss: 0.616452157497406
Validation loss: 1.7333998282750447

Epoch: 6| Step: 8
Training loss: 0.2411690503358841
Validation loss: 1.7234413957083097

Epoch: 6| Step: 9
Training loss: 0.4154566526412964
Validation loss: 1.7190734647935437

Epoch: 6| Step: 10
Training loss: 0.4600515067577362
Validation loss: 1.6764782474886986

Epoch: 6| Step: 11
Training loss: 0.33301305770874023
Validation loss: 1.5907554600828437

Epoch: 6| Step: 12
Training loss: 0.30025190114974976
Validation loss: 1.536963693557247

Epoch: 6| Step: 13
Training loss: 0.13738664984703064
Validation loss: 1.5151624218110116

Epoch: 336| Step: 0
Training loss: 0.33751577138900757
Validation loss: 1.535458517330949

Epoch: 6| Step: 1
Training loss: 0.37540608644485474
Validation loss: 1.5407873533105338

Epoch: 6| Step: 2
Training loss: 0.7789627313613892
Validation loss: 1.5115845100854033

Epoch: 6| Step: 3
Training loss: 0.27573883533477783
Validation loss: 1.4923128645907167

Epoch: 6| Step: 4
Training loss: 0.4869506359100342
Validation loss: 1.5000489514361146

Epoch: 6| Step: 5
Training loss: 0.4635917544364929
Validation loss: 1.5305367669751566

Epoch: 6| Step: 6
Training loss: 0.49984702467918396
Validation loss: 1.5459036647632558

Epoch: 6| Step: 7
Training loss: 0.33786502480506897
Validation loss: 1.5599840264166556

Epoch: 6| Step: 8
Training loss: 0.17450875043869019
Validation loss: 1.5610184746403848

Epoch: 6| Step: 9
Training loss: 0.16836635768413544
Validation loss: 1.6070795405295588

Epoch: 6| Step: 10
Training loss: 0.3967927098274231
Validation loss: 1.6639127372413554

Epoch: 6| Step: 11
Training loss: 0.3526281416416168
Validation loss: 1.7246993011043918

Epoch: 6| Step: 12
Training loss: 0.4796196520328522
Validation loss: 1.7662086025361092

Epoch: 6| Step: 13
Training loss: 0.35175621509552
Validation loss: 1.7764530335703204

Epoch: 337| Step: 0
Training loss: 0.3356015086174011
Validation loss: 1.740207169645576

Epoch: 6| Step: 1
Training loss: 0.17835097014904022
Validation loss: 1.6872087370964788

Epoch: 6| Step: 2
Training loss: 0.24748918414115906
Validation loss: 1.6527800957361858

Epoch: 6| Step: 3
Training loss: 0.3714118003845215
Validation loss: 1.6076716530707575

Epoch: 6| Step: 4
Training loss: 0.22794321179389954
Validation loss: 1.5827215294684134

Epoch: 6| Step: 5
Training loss: 0.5418254137039185
Validation loss: 1.546707841657823

Epoch: 6| Step: 6
Training loss: 0.20073997974395752
Validation loss: 1.5465265063829319

Epoch: 6| Step: 7
Training loss: 0.24341997504234314
Validation loss: 1.5405908887104323

Epoch: 6| Step: 8
Training loss: 0.3133363723754883
Validation loss: 1.5586643603540236

Epoch: 6| Step: 9
Training loss: 0.3095637559890747
Validation loss: 1.577244747069574

Epoch: 6| Step: 10
Training loss: 0.26461753249168396
Validation loss: 1.5696925424760388

Epoch: 6| Step: 11
Training loss: 0.20892676711082458
Validation loss: 1.606174030611592

Epoch: 6| Step: 12
Training loss: 0.4547296464443207
Validation loss: 1.6202008506303192

Epoch: 6| Step: 13
Training loss: 0.5334041118621826
Validation loss: 1.6019254493457016

Epoch: 338| Step: 0
Training loss: 0.3245721757411957
Validation loss: 1.6217120860212593

Epoch: 6| Step: 1
Training loss: 0.4128628969192505
Validation loss: 1.650809258543035

Epoch: 6| Step: 2
Training loss: 0.3228546977043152
Validation loss: 1.6685780620062223

Epoch: 6| Step: 3
Training loss: 0.30145925283432007
Validation loss: 1.7044669889634656

Epoch: 6| Step: 4
Training loss: 0.2516458034515381
Validation loss: 1.6690753954713062

Epoch: 6| Step: 5
Training loss: 0.5556827783584595
Validation loss: 1.6982464175070486

Epoch: 6| Step: 6
Training loss: 0.27241745591163635
Validation loss: 1.6769399078943397

Epoch: 6| Step: 7
Training loss: 0.23441623151302338
Validation loss: 1.6621579534264022

Epoch: 6| Step: 8
Training loss: 0.24894632399082184
Validation loss: 1.6717231132650887

Epoch: 6| Step: 9
Training loss: 0.39168763160705566
Validation loss: 1.6210693774684783

Epoch: 6| Step: 10
Training loss: 0.20473796129226685
Validation loss: 1.6116882960001628

Epoch: 6| Step: 11
Training loss: 0.27373313903808594
Validation loss: 1.6169151554825485

Epoch: 6| Step: 12
Training loss: 0.417610228061676
Validation loss: 1.5636391126981346

Epoch: 6| Step: 13
Training loss: 0.21132534742355347
Validation loss: 1.5575792661277197

Epoch: 339| Step: 0
Training loss: 0.1926286518573761
Validation loss: 1.496950327709157

Epoch: 6| Step: 1
Training loss: 0.3295348882675171
Validation loss: 1.5356944402058919

Epoch: 6| Step: 2
Training loss: 0.4482797682285309
Validation loss: 1.5345801820037186

Epoch: 6| Step: 3
Training loss: 0.21141093969345093
Validation loss: 1.5159643170654133

Epoch: 6| Step: 4
Training loss: 0.35112106800079346
Validation loss: 1.545144268261489

Epoch: 6| Step: 5
Training loss: 0.19547149538993835
Validation loss: 1.5596969999292845

Epoch: 6| Step: 6
Training loss: 0.7305386066436768
Validation loss: 1.5667902526035105

Epoch: 6| Step: 7
Training loss: 0.1838623583316803
Validation loss: 1.574120540772715

Epoch: 6| Step: 8
Training loss: 0.5152882933616638
Validation loss: 1.5918072974810036

Epoch: 6| Step: 9
Training loss: 0.36731112003326416
Validation loss: 1.619538386662801

Epoch: 6| Step: 10
Training loss: 0.23225732147693634
Validation loss: 1.6728071064077399

Epoch: 6| Step: 11
Training loss: 0.3117655813694
Validation loss: 1.7057349938218311

Epoch: 6| Step: 12
Training loss: 0.25193971395492554
Validation loss: 1.695529519870717

Epoch: 6| Step: 13
Training loss: 0.1327408403158188
Validation loss: 1.6708465981227096

Epoch: 340| Step: 0
Training loss: 0.2671396732330322
Validation loss: 1.6060778748604558

Epoch: 6| Step: 1
Training loss: 0.24973489344120026
Validation loss: 1.6356607214097054

Epoch: 6| Step: 2
Training loss: 0.23607051372528076
Validation loss: 1.6176142974566388

Epoch: 6| Step: 3
Training loss: 0.2623676657676697
Validation loss: 1.5686171490658996

Epoch: 6| Step: 4
Training loss: 0.26773741841316223
Validation loss: 1.5673255074408747

Epoch: 6| Step: 5
Training loss: 0.4664630889892578
Validation loss: 1.5563809256399832

Epoch: 6| Step: 6
Training loss: 0.2907316982746124
Validation loss: 1.5737549989454207

Epoch: 6| Step: 7
Training loss: 0.585179328918457
Validation loss: 1.5931179113285516

Epoch: 6| Step: 8
Training loss: 0.32148516178131104
Validation loss: 1.6038705962960438

Epoch: 6| Step: 9
Training loss: 0.23422691226005554
Validation loss: 1.6190447140765447

Epoch: 6| Step: 10
Training loss: 0.23611360788345337
Validation loss: 1.66361492167237

Epoch: 6| Step: 11
Training loss: 0.338031142950058
Validation loss: 1.6491152419838855

Epoch: 6| Step: 12
Training loss: 0.2705550491809845
Validation loss: 1.6756976573697981

Epoch: 6| Step: 13
Training loss: 0.43710970878601074
Validation loss: 1.679020006169555

Epoch: 341| Step: 0
Training loss: 0.371628075838089
Validation loss: 1.6741086411219772

Epoch: 6| Step: 1
Training loss: 0.31120628118515015
Validation loss: 1.6535215852081135

Epoch: 6| Step: 2
Training loss: 0.5008980631828308
Validation loss: 1.6206340584703671

Epoch: 6| Step: 3
Training loss: 0.387580543756485
Validation loss: 1.5989380010994532

Epoch: 6| Step: 4
Training loss: 0.2824476659297943
Validation loss: 1.5843535738606607

Epoch: 6| Step: 5
Training loss: 0.2790807783603668
Validation loss: 1.5867473950950048

Epoch: 6| Step: 6
Training loss: 0.30684274435043335
Validation loss: 1.6022350275388328

Epoch: 6| Step: 7
Training loss: 0.5084027647972107
Validation loss: 1.6204876412627518

Epoch: 6| Step: 8
Training loss: 0.24405783414840698
Validation loss: 1.629515363324073

Epoch: 6| Step: 9
Training loss: 0.2227807193994522
Validation loss: 1.6286785692297003

Epoch: 6| Step: 10
Training loss: 0.24382241070270538
Validation loss: 1.643436203720749

Epoch: 6| Step: 11
Training loss: 0.262521892786026
Validation loss: 1.6691114902496338

Epoch: 6| Step: 12
Training loss: 0.18298602104187012
Validation loss: 1.6595580257395262

Epoch: 6| Step: 13
Training loss: 0.27127504348754883
Validation loss: 1.6140433562699186

Epoch: 342| Step: 0
Training loss: 0.24528473615646362
Validation loss: 1.5985321537140877

Epoch: 6| Step: 1
Training loss: 0.2800654172897339
Validation loss: 1.5666197576830465

Epoch: 6| Step: 2
Training loss: 0.4387147128582001
Validation loss: 1.5655259701513475

Epoch: 6| Step: 3
Training loss: 0.24390758574008942
Validation loss: 1.583101894265862

Epoch: 6| Step: 4
Training loss: 0.2715608775615692
Validation loss: 1.582204878971141

Epoch: 6| Step: 5
Training loss: 0.2610933184623718
Validation loss: 1.6096854530354983

Epoch: 6| Step: 6
Training loss: 0.4452204406261444
Validation loss: 1.6022632122039795

Epoch: 6| Step: 7
Training loss: 0.2336193025112152
Validation loss: 1.5929852403620237

Epoch: 6| Step: 8
Training loss: 0.5750737190246582
Validation loss: 1.5992917168524958

Epoch: 6| Step: 9
Training loss: 0.1941690742969513
Validation loss: 1.6305714358565628

Epoch: 6| Step: 10
Training loss: 0.13650557398796082
Validation loss: 1.6254449198322911

Epoch: 6| Step: 11
Training loss: 0.21252356469631195
Validation loss: 1.6057518246353313

Epoch: 6| Step: 12
Training loss: 0.2766784429550171
Validation loss: 1.6367592696220643

Epoch: 6| Step: 13
Training loss: 0.2384365200996399
Validation loss: 1.5930931952691847

Epoch: 343| Step: 0
Training loss: 0.28140562772750854
Validation loss: 1.5943178355052907

Epoch: 6| Step: 1
Training loss: 0.3822893500328064
Validation loss: 1.5617230271780362

Epoch: 6| Step: 2
Training loss: 0.5078240633010864
Validation loss: 1.5460342104716966

Epoch: 6| Step: 3
Training loss: 0.2725542485713959
Validation loss: 1.565480338629856

Epoch: 6| Step: 4
Training loss: 0.33820056915283203
Validation loss: 1.5145904569215671

Epoch: 6| Step: 5
Training loss: 0.20512041449546814
Validation loss: 1.5305080388181953

Epoch: 6| Step: 6
Training loss: 0.38401758670806885
Validation loss: 1.5078442301801456

Epoch: 6| Step: 7
Training loss: 0.13675686717033386
Validation loss: 1.51008778361864

Epoch: 6| Step: 8
Training loss: 0.2664523720741272
Validation loss: 1.5305508003439954

Epoch: 6| Step: 9
Training loss: 0.2922627925872803
Validation loss: 1.5458204900064776

Epoch: 6| Step: 10
Training loss: 0.2513401508331299
Validation loss: 1.5711057468127179

Epoch: 6| Step: 11
Training loss: 0.2536173462867737
Validation loss: 1.5544512810245636

Epoch: 6| Step: 12
Training loss: 0.32244956493377686
Validation loss: 1.5379771942733436

Epoch: 6| Step: 13
Training loss: 0.39854779839515686
Validation loss: 1.5116262794822775

Epoch: 344| Step: 0
Training loss: 0.2469702959060669
Validation loss: 1.525147476503926

Epoch: 6| Step: 1
Training loss: 0.3533009886741638
Validation loss: 1.53847945890119

Epoch: 6| Step: 2
Training loss: 0.4260682165622711
Validation loss: 1.5500174965909732

Epoch: 6| Step: 3
Training loss: 0.2820408344268799
Validation loss: 1.6138346079857118

Epoch: 6| Step: 4
Training loss: 0.27576732635498047
Validation loss: 1.5995227252283404

Epoch: 6| Step: 5
Training loss: 0.576779305934906
Validation loss: 1.6124946058437388

Epoch: 6| Step: 6
Training loss: 0.1646992713212967
Validation loss: 1.6182167683878252

Epoch: 6| Step: 7
Training loss: 0.3872504234313965
Validation loss: 1.6183858007513068

Epoch: 6| Step: 8
Training loss: 0.22249914705753326
Validation loss: 1.611263809665557

Epoch: 6| Step: 9
Training loss: 0.2104504108428955
Validation loss: 1.5826942830957391

Epoch: 6| Step: 10
Training loss: 0.2651115357875824
Validation loss: 1.5875527948461554

Epoch: 6| Step: 11
Training loss: 0.20482534170150757
Validation loss: 1.582428034915719

Epoch: 6| Step: 12
Training loss: 0.1821492612361908
Validation loss: 1.580169302161022

Epoch: 6| Step: 13
Training loss: 0.24517162144184113
Validation loss: 1.5631387144006708

Epoch: 345| Step: 0
Training loss: 0.17495974898338318
Validation loss: 1.5482070740833078

Epoch: 6| Step: 1
Training loss: 0.2779300808906555
Validation loss: 1.5234233794673797

Epoch: 6| Step: 2
Training loss: 0.24955007433891296
Validation loss: 1.5412906485219156

Epoch: 6| Step: 3
Training loss: 0.2505664825439453
Validation loss: 1.5234387638748332

Epoch: 6| Step: 4
Training loss: 0.16896937787532806
Validation loss: 1.5335227161325433

Epoch: 6| Step: 5
Training loss: 0.4030815362930298
Validation loss: 1.5193319705224806

Epoch: 6| Step: 6
Training loss: 0.18868261575698853
Validation loss: 1.5160969329136673

Epoch: 6| Step: 7
Training loss: 0.160803884267807
Validation loss: 1.5274538647743963

Epoch: 6| Step: 8
Training loss: 0.2235146164894104
Validation loss: 1.5755380622802242

Epoch: 6| Step: 9
Training loss: 0.24882332980632782
Validation loss: 1.5846174737458587

Epoch: 6| Step: 10
Training loss: 0.1960579752922058
Validation loss: 1.6159581215150896

Epoch: 6| Step: 11
Training loss: 0.567926287651062
Validation loss: 1.6533550588033532

Epoch: 6| Step: 12
Training loss: 0.30948662757873535
Validation loss: 1.6254551385038642

Epoch: 6| Step: 13
Training loss: 0.1722833514213562
Validation loss: 1.6120518638241677

Epoch: 346| Step: 0
Training loss: 0.1992267370223999
Validation loss: 1.6074239579580163

Epoch: 6| Step: 1
Training loss: 0.2821020483970642
Validation loss: 1.580931628904035

Epoch: 6| Step: 2
Training loss: 0.2416272759437561
Validation loss: 1.5670472524499381

Epoch: 6| Step: 3
Training loss: 0.2996678948402405
Validation loss: 1.5480916192454677

Epoch: 6| Step: 4
Training loss: 0.2990019917488098
Validation loss: 1.558865366443511

Epoch: 6| Step: 5
Training loss: 0.1580834835767746
Validation loss: 1.5626636243635608

Epoch: 6| Step: 6
Training loss: 0.16359105706214905
Validation loss: 1.5948002902410363

Epoch: 6| Step: 7
Training loss: 0.09877893328666687
Validation loss: 1.581697283252593

Epoch: 6| Step: 8
Training loss: 0.3419274389743805
Validation loss: 1.6057007338411065

Epoch: 6| Step: 9
Training loss: 0.27680546045303345
Validation loss: 1.6077634403782506

Epoch: 6| Step: 10
Training loss: 0.21291452646255493
Validation loss: 1.6066599046030352

Epoch: 6| Step: 11
Training loss: 0.42119190096855164
Validation loss: 1.630090675046367

Epoch: 6| Step: 12
Training loss: 0.45829519629478455
Validation loss: 1.6500487942849436

Epoch: 6| Step: 13
Training loss: 0.16586285829544067
Validation loss: 1.65453407713162

Epoch: 347| Step: 0
Training loss: 0.34413769841194153
Validation loss: 1.6476976974036104

Epoch: 6| Step: 1
Training loss: 0.1483493447303772
Validation loss: 1.6148762613214471

Epoch: 6| Step: 2
Training loss: 0.14599192142486572
Validation loss: 1.6027729716352237

Epoch: 6| Step: 3
Training loss: 0.17065826058387756
Validation loss: 1.54365578902665

Epoch: 6| Step: 4
Training loss: 0.4591313600540161
Validation loss: 1.5402570514268772

Epoch: 6| Step: 5
Training loss: 0.15532802045345306
Validation loss: 1.5483593710007206

Epoch: 6| Step: 6
Training loss: 0.1491517722606659
Validation loss: 1.535346406762318

Epoch: 6| Step: 7
Training loss: 0.2555347681045532
Validation loss: 1.5358348790035452

Epoch: 6| Step: 8
Training loss: 0.39125776290893555
Validation loss: 1.555519042476531

Epoch: 6| Step: 9
Training loss: 0.34955066442489624
Validation loss: 1.5386640217996412

Epoch: 6| Step: 10
Training loss: 0.26346367597579956
Validation loss: 1.5563513732725573

Epoch: 6| Step: 11
Training loss: 0.44474920630455017
Validation loss: 1.5626117016679497

Epoch: 6| Step: 12
Training loss: 0.1712988018989563
Validation loss: 1.6219987587262226

Epoch: 6| Step: 13
Training loss: 0.29068416357040405
Validation loss: 1.6156529688066052

Epoch: 348| Step: 0
Training loss: 0.2303360104560852
Validation loss: 1.6111275598567019

Epoch: 6| Step: 1
Training loss: 0.15022963285446167
Validation loss: 1.5896216566844652

Epoch: 6| Step: 2
Training loss: 0.29813241958618164
Validation loss: 1.588117399523335

Epoch: 6| Step: 3
Training loss: 0.24625076353549957
Validation loss: 1.5724184461819228

Epoch: 6| Step: 4
Training loss: 0.3531302213668823
Validation loss: 1.5696950856075491

Epoch: 6| Step: 5
Training loss: 0.22661404311656952
Validation loss: 1.5570129489385953

Epoch: 6| Step: 6
Training loss: 0.14019496738910675
Validation loss: 1.5710364041789886

Epoch: 6| Step: 7
Training loss: 0.16622446477413177
Validation loss: 1.554825557175503

Epoch: 6| Step: 8
Training loss: 0.2576189935207367
Validation loss: 1.5443901810594785

Epoch: 6| Step: 9
Training loss: 0.6985254287719727
Validation loss: 1.526845613474487

Epoch: 6| Step: 10
Training loss: 0.2958238124847412
Validation loss: 1.5023231852439143

Epoch: 6| Step: 11
Training loss: 0.14872747659683228
Validation loss: 1.5228216327646726

Epoch: 6| Step: 12
Training loss: 0.29588037729263306
Validation loss: 1.5432833702333513

Epoch: 6| Step: 13
Training loss: 0.24957677721977234
Validation loss: 1.5627613426536642

Epoch: 349| Step: 0
Training loss: 0.23842555284500122
Validation loss: 1.5364509872210923

Epoch: 6| Step: 1
Training loss: 0.3178569972515106
Validation loss: 1.4987951510696

Epoch: 6| Step: 2
Training loss: 0.3452482223510742
Validation loss: 1.5252014616484284

Epoch: 6| Step: 3
Training loss: 0.16536612808704376
Validation loss: 1.5092917155194026

Epoch: 6| Step: 4
Training loss: 0.38385939598083496
Validation loss: 1.523909273967948

Epoch: 6| Step: 5
Training loss: 0.30029821395874023
Validation loss: 1.5488068788282332

Epoch: 6| Step: 6
Training loss: 0.48917800188064575
Validation loss: 1.532367056415927

Epoch: 6| Step: 7
Training loss: 0.16288933157920837
Validation loss: 1.576042188111172

Epoch: 6| Step: 8
Training loss: 0.3009536564350128
Validation loss: 1.5692949807772072

Epoch: 6| Step: 9
Training loss: 0.1499505192041397
Validation loss: 1.6035381811921314

Epoch: 6| Step: 10
Training loss: 0.2430586814880371
Validation loss: 1.5904560832567112

Epoch: 6| Step: 11
Training loss: 0.12032856047153473
Validation loss: 1.6155738945930236

Epoch: 6| Step: 12
Training loss: 0.217617005109787
Validation loss: 1.613193247266995

Epoch: 6| Step: 13
Training loss: 0.24363555014133453
Validation loss: 1.5750175945220455

Epoch: 350| Step: 0
Training loss: 0.15983837842941284
Validation loss: 1.6160366612095987

Epoch: 6| Step: 1
Training loss: 0.37862932682037354
Validation loss: 1.575048331291445

Epoch: 6| Step: 2
Training loss: 0.1567792147397995
Validation loss: 1.5591011637000627

Epoch: 6| Step: 3
Training loss: 0.26410844922065735
Validation loss: 1.520522955925234

Epoch: 6| Step: 4
Training loss: 0.12031620740890503
Validation loss: 1.5169386697071854

Epoch: 6| Step: 5
Training loss: 0.32949304580688477
Validation loss: 1.4951462220120173

Epoch: 6| Step: 6
Training loss: 0.29176658391952515
Validation loss: 1.5268860658009846

Epoch: 6| Step: 7
Training loss: 0.15736715495586395
Validation loss: 1.5141617636526785

Epoch: 6| Step: 8
Training loss: 0.17633754014968872
Validation loss: 1.5379253318232875

Epoch: 6| Step: 9
Training loss: 0.22924333810806274
Validation loss: 1.5595120999120897

Epoch: 6| Step: 10
Training loss: 0.3194016218185425
Validation loss: 1.5777418023796492

Epoch: 6| Step: 11
Training loss: 0.20649439096450806
Validation loss: 1.5832327155656711

Epoch: 6| Step: 12
Training loss: 0.38948386907577515
Validation loss: 1.6255085750292706

Epoch: 6| Step: 13
Training loss: 0.37970036268234253
Validation loss: 1.641053908614702

Epoch: 351| Step: 0
Training loss: 0.2825627326965332
Validation loss: 1.6642593850371659

Epoch: 6| Step: 1
Training loss: 0.3943210244178772
Validation loss: 1.6531554588707544

Epoch: 6| Step: 2
Training loss: 0.3216894268989563
Validation loss: 1.6367480178033151

Epoch: 6| Step: 3
Training loss: 0.2746424674987793
Validation loss: 1.612438823587151

Epoch: 6| Step: 4
Training loss: 0.38662487268447876
Validation loss: 1.591597165471764

Epoch: 6| Step: 5
Training loss: 0.31556472182273865
Validation loss: 1.577974138721343

Epoch: 6| Step: 6
Training loss: 0.23182597756385803
Validation loss: 1.5423287089153002

Epoch: 6| Step: 7
Training loss: 0.23017257452011108
Validation loss: 1.503321147734119

Epoch: 6| Step: 8
Training loss: 0.5268847942352295
Validation loss: 1.4935666937981882

Epoch: 6| Step: 9
Training loss: 0.3043731153011322
Validation loss: 1.4992357107900804

Epoch: 6| Step: 10
Training loss: 0.3627977967262268
Validation loss: 1.4873891030588458

Epoch: 6| Step: 11
Training loss: 0.14383487403392792
Validation loss: 1.5171059011131205

Epoch: 6| Step: 12
Training loss: 0.31412994861602783
Validation loss: 1.535093362613391

Epoch: 6| Step: 13
Training loss: 0.3876512050628662
Validation loss: 1.5350679710347166

Epoch: 352| Step: 0
Training loss: 0.14348116517066956
Validation loss: 1.5225670837586927

Epoch: 6| Step: 1
Training loss: 0.28591257333755493
Validation loss: 1.5549969493701894

Epoch: 6| Step: 2
Training loss: 0.2747977375984192
Validation loss: 1.5219967352446688

Epoch: 6| Step: 3
Training loss: 0.26568469405174255
Validation loss: 1.5250563429247948

Epoch: 6| Step: 4
Training loss: 0.4380965828895569
Validation loss: 1.4919224246855705

Epoch: 6| Step: 5
Training loss: 0.3432893753051758
Validation loss: 1.5200332454455796

Epoch: 6| Step: 6
Training loss: 0.16938982903957367
Validation loss: 1.5325690161797307

Epoch: 6| Step: 7
Training loss: 0.18018396198749542
Validation loss: 1.551430909223454

Epoch: 6| Step: 8
Training loss: 0.11843227595090866
Validation loss: 1.57036712092738

Epoch: 6| Step: 9
Training loss: 0.33427906036376953
Validation loss: 1.5738418794447375

Epoch: 6| Step: 10
Training loss: 0.22633244097232819
Validation loss: 1.617656305272092

Epoch: 6| Step: 11
Training loss: 0.44402214884757996
Validation loss: 1.5978602094034995

Epoch: 6| Step: 12
Training loss: 0.19883587956428528
Validation loss: 1.5766241217172274

Epoch: 6| Step: 13
Training loss: 0.345395565032959
Validation loss: 1.5515731201376965

Epoch: 353| Step: 0
Training loss: 0.22885452210903168
Validation loss: 1.541186604448544

Epoch: 6| Step: 1
Training loss: 0.1528072953224182
Validation loss: 1.5555790111582766

Epoch: 6| Step: 2
Training loss: 0.22647833824157715
Validation loss: 1.5842993374793761

Epoch: 6| Step: 3
Training loss: 0.43243950605392456
Validation loss: 1.5626566076791415

Epoch: 6| Step: 4
Training loss: 0.4275921583175659
Validation loss: 1.5746818255352717

Epoch: 6| Step: 5
Training loss: 0.1274697184562683
Validation loss: 1.5803854773121495

Epoch: 6| Step: 6
Training loss: 0.24763832986354828
Validation loss: 1.592148091203423

Epoch: 6| Step: 7
Training loss: 0.19854673743247986
Validation loss: 1.6126057999108427

Epoch: 6| Step: 8
Training loss: 0.307864248752594
Validation loss: 1.6286149947874007

Epoch: 6| Step: 9
Training loss: 0.2781530022621155
Validation loss: 1.6343787947008688

Epoch: 6| Step: 10
Training loss: 0.24479332566261292
Validation loss: 1.5279676247668523

Epoch: 6| Step: 11
Training loss: 0.4206138253211975
Validation loss: 1.5034776759404007

Epoch: 6| Step: 12
Training loss: 0.35175013542175293
Validation loss: 1.45386081100792

Epoch: 6| Step: 13
Training loss: 0.6358776092529297
Validation loss: 1.476162681015589

Epoch: 354| Step: 0
Training loss: 0.23994125425815582
Validation loss: 1.4854863491109622

Epoch: 6| Step: 1
Training loss: 0.27669018507003784
Validation loss: 1.4828228258317517

Epoch: 6| Step: 2
Training loss: 0.32980963587760925
Validation loss: 1.4955479637269051

Epoch: 6| Step: 3
Training loss: 0.2364756464958191
Validation loss: 1.5151605279214921

Epoch: 6| Step: 4
Training loss: 0.4615302085876465
Validation loss: 1.5626274007622913

Epoch: 6| Step: 5
Training loss: 0.14483030140399933
Validation loss: 1.5694415761578469

Epoch: 6| Step: 6
Training loss: 0.2747190594673157
Validation loss: 1.6184171656126618

Epoch: 6| Step: 7
Training loss: 0.42088228464126587
Validation loss: 1.6558221117142709

Epoch: 6| Step: 8
Training loss: 0.22310587763786316
Validation loss: 1.6415376355571132

Epoch: 6| Step: 9
Training loss: 0.2125018835067749
Validation loss: 1.658302717311408

Epoch: 6| Step: 10
Training loss: 0.354621559381485
Validation loss: 1.6248097355647753

Epoch: 6| Step: 11
Training loss: 0.247260183095932
Validation loss: 1.5881513760935875

Epoch: 6| Step: 12
Training loss: 0.19724571704864502
Validation loss: 1.5699556053325694

Epoch: 6| Step: 13
Training loss: 0.22189635038375854
Validation loss: 1.536354959651988

Epoch: 355| Step: 0
Training loss: 0.20398294925689697
Validation loss: 1.5268389178860573

Epoch: 6| Step: 1
Training loss: 0.18532663583755493
Validation loss: 1.4937272379475255

Epoch: 6| Step: 2
Training loss: 0.3222886919975281
Validation loss: 1.5183230343685354

Epoch: 6| Step: 3
Training loss: 0.15262243151664734
Validation loss: 1.5013475969273558

Epoch: 6| Step: 4
Training loss: 0.45995715260505676
Validation loss: 1.4911346832911174

Epoch: 6| Step: 5
Training loss: 0.17750921845436096
Validation loss: 1.4907785641249789

Epoch: 6| Step: 6
Training loss: 0.3091735541820526
Validation loss: 1.5276166508274693

Epoch: 6| Step: 7
Training loss: 0.2275867462158203
Validation loss: 1.520624101802867

Epoch: 6| Step: 8
Training loss: 0.2395278513431549
Validation loss: 1.5792404323495843

Epoch: 6| Step: 9
Training loss: 0.24029408395290375
Validation loss: 1.5978996458873953

Epoch: 6| Step: 10
Training loss: 0.20779426395893097
Validation loss: 1.6078866592017553

Epoch: 6| Step: 11
Training loss: 0.4296345114707947
Validation loss: 1.622317030865659

Epoch: 6| Step: 12
Training loss: 0.4531969428062439
Validation loss: 1.6184192133206192

Epoch: 6| Step: 13
Training loss: 0.21392348408699036
Validation loss: 1.6104867804434992

Epoch: 356| Step: 0
Training loss: 0.1860419660806656
Validation loss: 1.5570395428647277

Epoch: 6| Step: 1
Training loss: 0.20219939947128296
Validation loss: 1.5026511466631325

Epoch: 6| Step: 2
Training loss: 0.1968708634376526
Validation loss: 1.502054319586805

Epoch: 6| Step: 3
Training loss: 0.21430431306362152
Validation loss: 1.4848647245796778

Epoch: 6| Step: 4
Training loss: 0.22982358932495117
Validation loss: 1.491264736139646

Epoch: 6| Step: 5
Training loss: 0.36312198638916016
Validation loss: 1.478222567548034

Epoch: 6| Step: 6
Training loss: 0.19468258321285248
Validation loss: 1.4822348535701793

Epoch: 6| Step: 7
Training loss: 0.4722597599029541
Validation loss: 1.4899273803157191

Epoch: 6| Step: 8
Training loss: 0.19916820526123047
Validation loss: 1.502177789647092

Epoch: 6| Step: 9
Training loss: 0.17710429430007935
Validation loss: 1.5052036546891736

Epoch: 6| Step: 10
Training loss: 0.3857705891132355
Validation loss: 1.5282742425959597

Epoch: 6| Step: 11
Training loss: 0.18180641531944275
Validation loss: 1.531173913709579

Epoch: 6| Step: 12
Training loss: 0.3519700765609741
Validation loss: 1.5715313726855862

Epoch: 6| Step: 13
Training loss: 0.5015976428985596
Validation loss: 1.6141263131172425

Epoch: 357| Step: 0
Training loss: 0.23236937820911407
Validation loss: 1.5837551996272097

Epoch: 6| Step: 1
Training loss: 0.24389278888702393
Validation loss: 1.6188041151210826

Epoch: 6| Step: 2
Training loss: 0.2782251238822937
Validation loss: 1.601521049776385

Epoch: 6| Step: 3
Training loss: 0.2404966801404953
Validation loss: 1.6061031933753722

Epoch: 6| Step: 4
Training loss: 0.3492189943790436
Validation loss: 1.6036282136876097

Epoch: 6| Step: 5
Training loss: 0.3023577928543091
Validation loss: 1.5797366455037107

Epoch: 6| Step: 6
Training loss: 0.21279051899909973
Validation loss: 1.5973130861918132

Epoch: 6| Step: 7
Training loss: 0.2653379738330841
Validation loss: 1.5753284705582487

Epoch: 6| Step: 8
Training loss: 0.19441969692707062
Validation loss: 1.5727487251322756

Epoch: 6| Step: 9
Training loss: 0.26411983370780945
Validation loss: 1.6028349309839227

Epoch: 6| Step: 10
Training loss: 0.16360218822956085
Validation loss: 1.5807672392937444

Epoch: 6| Step: 11
Training loss: 0.3552798628807068
Validation loss: 1.571210245932302

Epoch: 6| Step: 12
Training loss: 0.3411667048931122
Validation loss: 1.5577304376068937

Epoch: 6| Step: 13
Training loss: 0.2230493277311325
Validation loss: 1.5678742854825911

Epoch: 358| Step: 0
Training loss: 0.21716779470443726
Validation loss: 1.5582578541130148

Epoch: 6| Step: 1
Training loss: 0.2957780361175537
Validation loss: 1.5650286559135682

Epoch: 6| Step: 2
Training loss: 0.2611123323440552
Validation loss: 1.601043306371217

Epoch: 6| Step: 3
Training loss: 0.21109463274478912
Validation loss: 1.5723619589241602

Epoch: 6| Step: 4
Training loss: 0.3003053665161133
Validation loss: 1.5899462738344747

Epoch: 6| Step: 5
Training loss: 0.3318834900856018
Validation loss: 1.6087744287265244

Epoch: 6| Step: 6
Training loss: 0.16408434510231018
Validation loss: 1.609894972975536

Epoch: 6| Step: 7
Training loss: 0.14892172813415527
Validation loss: 1.6031672108557917

Epoch: 6| Step: 8
Training loss: 0.382165789604187
Validation loss: 1.6102115300393873

Epoch: 6| Step: 9
Training loss: 0.22390706837177277
Validation loss: 1.5970841941013132

Epoch: 6| Step: 10
Training loss: 0.16536687314510345
Validation loss: 1.5689822153378559

Epoch: 6| Step: 11
Training loss: 0.40093669295310974
Validation loss: 1.5368469363899642

Epoch: 6| Step: 12
Training loss: 0.15013328194618225
Validation loss: 1.5566607982881608

Epoch: 6| Step: 13
Training loss: 0.31311649084091187
Validation loss: 1.5222145600985455

Epoch: 359| Step: 0
Training loss: 0.22889381647109985
Validation loss: 1.5153738875542917

Epoch: 6| Step: 1
Training loss: 0.12709668278694153
Validation loss: 1.5154093260406165

Epoch: 6| Step: 2
Training loss: 0.24115347862243652
Validation loss: 1.484420196984404

Epoch: 6| Step: 3
Training loss: 0.19820448756217957
Validation loss: 1.4997295641130017

Epoch: 6| Step: 4
Training loss: 0.15257184207439423
Validation loss: 1.4953466589732836

Epoch: 6| Step: 5
Training loss: 0.3154236972332001
Validation loss: 1.4722510140429261

Epoch: 6| Step: 6
Training loss: 0.20933951437473297
Validation loss: 1.472421125699115

Epoch: 6| Step: 7
Training loss: 0.1914806067943573
Validation loss: 1.5205710934054466

Epoch: 6| Step: 8
Training loss: 0.21003961563110352
Validation loss: 1.5132906859920872

Epoch: 6| Step: 9
Training loss: 0.15095531940460205
Validation loss: 1.535889244848682

Epoch: 6| Step: 10
Training loss: 0.3202165961265564
Validation loss: 1.5346381164366198

Epoch: 6| Step: 11
Training loss: 0.44753825664520264
Validation loss: 1.5848500831152803

Epoch: 6| Step: 12
Training loss: 0.3016722798347473
Validation loss: 1.5919392467826925

Epoch: 6| Step: 13
Training loss: 0.2687843143939972
Validation loss: 1.6112884013883528

Epoch: 360| Step: 0
Training loss: 0.25183039903640747
Validation loss: 1.6675841090499715

Epoch: 6| Step: 1
Training loss: 0.1891520917415619
Validation loss: 1.6367530181843748

Epoch: 6| Step: 2
Training loss: 0.20173993706703186
Validation loss: 1.6502061390107678

Epoch: 6| Step: 3
Training loss: 0.16092942655086517
Validation loss: 1.6334284518354683

Epoch: 6| Step: 4
Training loss: 0.22132712602615356
Validation loss: 1.576775034268697

Epoch: 6| Step: 5
Training loss: 0.22638817131519318
Validation loss: 1.5609408270928167

Epoch: 6| Step: 6
Training loss: 0.1776280552148819
Validation loss: 1.5541658350216445

Epoch: 6| Step: 7
Training loss: 0.1990695595741272
Validation loss: 1.5219599354651667

Epoch: 6| Step: 8
Training loss: 0.25001299381256104
Validation loss: 1.496507288307272

Epoch: 6| Step: 9
Training loss: 0.20645572245121002
Validation loss: 1.509763603569359

Epoch: 6| Step: 10
Training loss: 0.5743502378463745
Validation loss: 1.5172728633367887

Epoch: 6| Step: 11
Training loss: 0.2541084885597229
Validation loss: 1.4995949832342004

Epoch: 6| Step: 12
Training loss: 0.3387919068336487
Validation loss: 1.5458596803808724

Epoch: 6| Step: 13
Training loss: 0.24658305943012238
Validation loss: 1.5444846678805608

Epoch: 361| Step: 0
Training loss: 0.14580662548542023
Validation loss: 1.5783097282532723

Epoch: 6| Step: 1
Training loss: 0.191424161195755
Validation loss: 1.5763023694356282

Epoch: 6| Step: 2
Training loss: 0.1730123907327652
Validation loss: 1.6139351155168267

Epoch: 6| Step: 3
Training loss: 0.13929259777069092
Validation loss: 1.6164364417394002

Epoch: 6| Step: 4
Training loss: 0.5444207191467285
Validation loss: 1.6237784329281058

Epoch: 6| Step: 5
Training loss: 0.2819024920463562
Validation loss: 1.6291883491700696

Epoch: 6| Step: 6
Training loss: 0.18061843514442444
Validation loss: 1.6353902252771522

Epoch: 6| Step: 7
Training loss: 0.3132075071334839
Validation loss: 1.6056149544254426

Epoch: 6| Step: 8
Training loss: 0.18306651711463928
Validation loss: 1.639495841918453

Epoch: 6| Step: 9
Training loss: 0.23510149121284485
Validation loss: 1.5955541056971396

Epoch: 6| Step: 10
Training loss: 0.246344193816185
Validation loss: 1.5772601737770984

Epoch: 6| Step: 11
Training loss: 0.1662192940711975
Validation loss: 1.5448796249205066

Epoch: 6| Step: 12
Training loss: 0.3995397984981537
Validation loss: 1.542328155168923

Epoch: 6| Step: 13
Training loss: 0.1552690863609314
Validation loss: 1.5277596263475315

Epoch: 362| Step: 0
Training loss: 0.209123432636261
Validation loss: 1.5079763653457805

Epoch: 6| Step: 1
Training loss: 0.2374553382396698
Validation loss: 1.4937317730278097

Epoch: 6| Step: 2
Training loss: 0.17881567776203156
Validation loss: 1.508263027155271

Epoch: 6| Step: 3
Training loss: 0.23134280741214752
Validation loss: 1.5167468337602512

Epoch: 6| Step: 4
Training loss: 0.19519945979118347
Validation loss: 1.5375372517493464

Epoch: 6| Step: 5
Training loss: 0.15906938910484314
Validation loss: 1.5577077852782382

Epoch: 6| Step: 6
Training loss: 0.13926488161087036
Validation loss: 1.5896348478973552

Epoch: 6| Step: 7
Training loss: 0.24185863137245178
Validation loss: 1.5643038865058654

Epoch: 6| Step: 8
Training loss: 0.24805109202861786
Validation loss: 1.5563354581914923

Epoch: 6| Step: 9
Training loss: 0.22003048658370972
Validation loss: 1.5545966586759012

Epoch: 6| Step: 10
Training loss: 0.3850312829017639
Validation loss: 1.5588528802317958

Epoch: 6| Step: 11
Training loss: 0.3797761797904968
Validation loss: 1.5517055411492624

Epoch: 6| Step: 12
Training loss: 0.3188135623931885
Validation loss: 1.5742005994243007

Epoch: 6| Step: 13
Training loss: 0.24867312610149384
Validation loss: 1.5426796790092223

Epoch: 363| Step: 0
Training loss: 0.17045611143112183
Validation loss: 1.5391393233371038

Epoch: 6| Step: 1
Training loss: 0.19444607198238373
Validation loss: 1.5281865045588503

Epoch: 6| Step: 2
Training loss: 0.2556198835372925
Validation loss: 1.5108568770911104

Epoch: 6| Step: 3
Training loss: 0.2534254789352417
Validation loss: 1.5225979794738114

Epoch: 6| Step: 4
Training loss: 0.15820641815662384
Validation loss: 1.483552002137707

Epoch: 6| Step: 5
Training loss: 0.4782305061817169
Validation loss: 1.49108547805458

Epoch: 6| Step: 6
Training loss: 0.20198236405849457
Validation loss: 1.5057894209379792

Epoch: 6| Step: 7
Training loss: 0.20869874954223633
Validation loss: 1.4909441958191574

Epoch: 6| Step: 8
Training loss: 0.20600947737693787
Validation loss: 1.4947452698984454

Epoch: 6| Step: 9
Training loss: 0.18871156871318817
Validation loss: 1.5025110526751446

Epoch: 6| Step: 10
Training loss: 0.12449266016483307
Validation loss: 1.5264086402872556

Epoch: 6| Step: 11
Training loss: 0.2245425134897232
Validation loss: 1.5197567888485488

Epoch: 6| Step: 12
Training loss: 0.24082671105861664
Validation loss: 1.531806243363247

Epoch: 6| Step: 13
Training loss: 0.09731309115886688
Validation loss: 1.5490025679270427

Epoch: 364| Step: 0
Training loss: 0.13854166865348816
Validation loss: 1.5132370866755003

Epoch: 6| Step: 1
Training loss: 0.16789986193180084
Validation loss: 1.5281987010791738

Epoch: 6| Step: 2
Training loss: 0.16241061687469482
Validation loss: 1.5504513632866643

Epoch: 6| Step: 3
Training loss: 0.12219016253948212
Validation loss: 1.5378536062855874

Epoch: 6| Step: 4
Training loss: 0.28592464327812195
Validation loss: 1.564809658194101

Epoch: 6| Step: 5
Training loss: 0.175828218460083
Validation loss: 1.5626664251409552

Epoch: 6| Step: 6
Training loss: 0.21473518013954163
Validation loss: 1.5796681629714144

Epoch: 6| Step: 7
Training loss: 0.14670118689537048
Validation loss: 1.5813672491299209

Epoch: 6| Step: 8
Training loss: 0.1652328372001648
Validation loss: 1.540578047434489

Epoch: 6| Step: 9
Training loss: 0.18488697707653046
Validation loss: 1.5607274360554193

Epoch: 6| Step: 10
Training loss: 0.47990089654922485
Validation loss: 1.5458691761057863

Epoch: 6| Step: 11
Training loss: 0.19910965859889984
Validation loss: 1.5281185219364781

Epoch: 6| Step: 12
Training loss: 0.13169452548027039
Validation loss: 1.536545685542527

Epoch: 6| Step: 13
Training loss: 0.3591311275959015
Validation loss: 1.4867490324922787

Epoch: 365| Step: 0
Training loss: 0.1560504138469696
Validation loss: 1.4884899585477767

Epoch: 6| Step: 1
Training loss: 0.3090139627456665
Validation loss: 1.4929211101224344

Epoch: 6| Step: 2
Training loss: 0.10626924782991409
Validation loss: 1.4981194119299612

Epoch: 6| Step: 3
Training loss: 0.2123418003320694
Validation loss: 1.4803309645704044

Epoch: 6| Step: 4
Training loss: 0.1889428049325943
Validation loss: 1.503947946333116

Epoch: 6| Step: 5
Training loss: 0.1701555848121643
Validation loss: 1.501079765699243

Epoch: 6| Step: 6
Training loss: 0.36679092049598694
Validation loss: 1.5133952543299685

Epoch: 6| Step: 7
Training loss: 0.12441172450780869
Validation loss: 1.5455491670998194

Epoch: 6| Step: 8
Training loss: 0.18753181397914886
Validation loss: 1.597162450513532

Epoch: 6| Step: 9
Training loss: 0.22353678941726685
Validation loss: 1.6154473186821066

Epoch: 6| Step: 10
Training loss: 0.23407025635242462
Validation loss: 1.5896953831436813

Epoch: 6| Step: 11
Training loss: 0.3610263168811798
Validation loss: 1.587517915233489

Epoch: 6| Step: 12
Training loss: 0.2829023003578186
Validation loss: 1.5786506309304187

Epoch: 6| Step: 13
Training loss: 0.36679965257644653
Validation loss: 1.544109030436444

Epoch: 366| Step: 0
Training loss: 0.11317695677280426
Validation loss: 1.5353121193506385

Epoch: 6| Step: 1
Training loss: 0.2969999313354492
Validation loss: 1.5023255937842912

Epoch: 6| Step: 2
Training loss: 0.1651877462863922
Validation loss: 1.5390292367627543

Epoch: 6| Step: 3
Training loss: 0.24601969122886658
Validation loss: 1.5210206457363662

Epoch: 6| Step: 4
Training loss: 0.242036372423172
Validation loss: 1.5306090847138436

Epoch: 6| Step: 5
Training loss: 0.21345296502113342
Validation loss: 1.555737058321635

Epoch: 6| Step: 6
Training loss: 0.4760606586933136
Validation loss: 1.5461840898759904

Epoch: 6| Step: 7
Training loss: 0.14090989530086517
Validation loss: 1.5725552612735378

Epoch: 6| Step: 8
Training loss: 0.21455225348472595
Validation loss: 1.5470760906896284

Epoch: 6| Step: 9
Training loss: 0.19010575115680695
Validation loss: 1.559098365486309

Epoch: 6| Step: 10
Training loss: 0.19835355877876282
Validation loss: 1.5610767949012019

Epoch: 6| Step: 11
Training loss: 0.3311917185783386
Validation loss: 1.561349376555412

Epoch: 6| Step: 12
Training loss: 0.0919378399848938
Validation loss: 1.5465356547345397

Epoch: 6| Step: 13
Training loss: 0.09551512449979782
Validation loss: 1.5169032299390404

Epoch: 367| Step: 0
Training loss: 0.2407168745994568
Validation loss: 1.5537376326899375

Epoch: 6| Step: 1
Training loss: 0.24563544988632202
Validation loss: 1.539946613773223

Epoch: 6| Step: 2
Training loss: 0.10359969735145569
Validation loss: 1.567483860959289

Epoch: 6| Step: 3
Training loss: 0.21072842180728912
Validation loss: 1.5557524145290416

Epoch: 6| Step: 4
Training loss: 0.11495888233184814
Validation loss: 1.5848916179390364

Epoch: 6| Step: 5
Training loss: 0.3211139738559723
Validation loss: 1.5542602295516639

Epoch: 6| Step: 6
Training loss: 0.2009868621826172
Validation loss: 1.5087911569943993

Epoch: 6| Step: 7
Training loss: 0.18452337384223938
Validation loss: 1.5227589389329315

Epoch: 6| Step: 8
Training loss: 0.20649176836013794
Validation loss: 1.5093819351606472

Epoch: 6| Step: 9
Training loss: 0.15721642971038818
Validation loss: 1.4922290155964513

Epoch: 6| Step: 10
Training loss: 0.3050641715526581
Validation loss: 1.4652335797586749

Epoch: 6| Step: 11
Training loss: 0.41539281606674194
Validation loss: 1.4710556102055374

Epoch: 6| Step: 12
Training loss: 0.18759962916374207
Validation loss: 1.4839704921168666

Epoch: 6| Step: 13
Training loss: 0.1257198303937912
Validation loss: 1.4959932270870413

Epoch: 368| Step: 0
Training loss: 0.2199653685092926
Validation loss: 1.4822321720020746

Epoch: 6| Step: 1
Training loss: 0.13386407494544983
Validation loss: 1.4991245423593829

Epoch: 6| Step: 2
Training loss: 0.24107065796852112
Validation loss: 1.5103754779343963

Epoch: 6| Step: 3
Training loss: 0.34990084171295166
Validation loss: 1.5191274201998146

Epoch: 6| Step: 4
Training loss: 0.18780338764190674
Validation loss: 1.5261696307889876

Epoch: 6| Step: 5
Training loss: 0.19703827798366547
Validation loss: 1.5486074942414478

Epoch: 6| Step: 6
Training loss: 0.3923649191856384
Validation loss: 1.534921371808616

Epoch: 6| Step: 7
Training loss: 0.1736261248588562
Validation loss: 1.5379290555113105

Epoch: 6| Step: 8
Training loss: 0.21698082983493805
Validation loss: 1.5311135527908162

Epoch: 6| Step: 9
Training loss: 0.313840389251709
Validation loss: 1.5373131703304987

Epoch: 6| Step: 10
Training loss: 0.1459130197763443
Validation loss: 1.516173437077512

Epoch: 6| Step: 11
Training loss: 0.17294089496135712
Validation loss: 1.5384037930478331

Epoch: 6| Step: 12
Training loss: 0.13662073016166687
Validation loss: 1.5290676316907328

Epoch: 6| Step: 13
Training loss: 0.09745735675096512
Validation loss: 1.4925415233899189

Epoch: 369| Step: 0
Training loss: 0.11329883337020874
Validation loss: 1.541783127092546

Epoch: 6| Step: 1
Training loss: 0.14409483969211578
Validation loss: 1.5548046429951985

Epoch: 6| Step: 2
Training loss: 0.14975714683532715
Validation loss: 1.537901488683557

Epoch: 6| Step: 3
Training loss: 0.13955804705619812
Validation loss: 1.548660300111258

Epoch: 6| Step: 4
Training loss: 0.2600298225879669
Validation loss: 1.5295033006257908

Epoch: 6| Step: 5
Training loss: 0.19317087531089783
Validation loss: 1.5123770416423838

Epoch: 6| Step: 6
Training loss: 0.1856580376625061
Validation loss: 1.5009129919031614

Epoch: 6| Step: 7
Training loss: 0.155337393283844
Validation loss: 1.4957959972402102

Epoch: 6| Step: 8
Training loss: 0.22252175211906433
Validation loss: 1.502311606560984

Epoch: 6| Step: 9
Training loss: 0.389590322971344
Validation loss: 1.5047357120821554

Epoch: 6| Step: 10
Training loss: 0.14438803493976593
Validation loss: 1.5260660725255166

Epoch: 6| Step: 11
Training loss: 0.16093096137046814
Validation loss: 1.5072639039767686

Epoch: 6| Step: 12
Training loss: 0.37576860189437866
Validation loss: 1.487737431321093

Epoch: 6| Step: 13
Training loss: 0.07313823699951172
Validation loss: 1.499765965246385

Epoch: 370| Step: 0
Training loss: 0.17570146918296814
Validation loss: 1.510233151015415

Epoch: 6| Step: 1
Training loss: 0.14296336472034454
Validation loss: 1.5007721352320846

Epoch: 6| Step: 2
Training loss: 0.1268872320652008
Validation loss: 1.520770078064293

Epoch: 6| Step: 3
Training loss: 0.23507121205329895
Validation loss: 1.5135689614921488

Epoch: 6| Step: 4
Training loss: 0.3852677047252655
Validation loss: 1.53329247941253

Epoch: 6| Step: 5
Training loss: 0.10567601770162582
Validation loss: 1.5262040540736208

Epoch: 6| Step: 6
Training loss: 0.16707640886306763
Validation loss: 1.5280250656989314

Epoch: 6| Step: 7
Training loss: 0.28703171014785767
Validation loss: 1.539165992890635

Epoch: 6| Step: 8
Training loss: 0.21372480690479279
Validation loss: 1.5454650771233343

Epoch: 6| Step: 9
Training loss: 0.18082305788993835
Validation loss: 1.5387439176600466

Epoch: 6| Step: 10
Training loss: 0.3299747109413147
Validation loss: 1.5420315727110832

Epoch: 6| Step: 11
Training loss: 0.23805522918701172
Validation loss: 1.596222408356205

Epoch: 6| Step: 12
Training loss: 0.22175081074237823
Validation loss: 1.5610875378372848

Epoch: 6| Step: 13
Training loss: 0.3039577603340149
Validation loss: 1.5781174487965082

Epoch: 371| Step: 0
Training loss: 0.2649916112422943
Validation loss: 1.5402544185679445

Epoch: 6| Step: 1
Training loss: 0.16315874457359314
Validation loss: 1.5474835647049772

Epoch: 6| Step: 2
Training loss: 0.13149072229862213
Validation loss: 1.5435598896395775

Epoch: 6| Step: 3
Training loss: 0.2139894664287567
Validation loss: 1.5194137762951594

Epoch: 6| Step: 4
Training loss: 0.22252394258975983
Validation loss: 1.5458971890070106

Epoch: 6| Step: 5
Training loss: 0.21955779194831848
Validation loss: 1.5021274743541595

Epoch: 6| Step: 6
Training loss: 0.13507547974586487
Validation loss: 1.5280206318824523

Epoch: 6| Step: 7
Training loss: 0.11818313598632812
Validation loss: 1.512461591792363

Epoch: 6| Step: 8
Training loss: 0.34099552035331726
Validation loss: 1.5041022454538653

Epoch: 6| Step: 9
Training loss: 0.32787472009658813
Validation loss: 1.5148553540629726

Epoch: 6| Step: 10
Training loss: 0.23229674994945526
Validation loss: 1.5457235510631273

Epoch: 6| Step: 11
Training loss: 0.14041109383106232
Validation loss: 1.5692038215616697

Epoch: 6| Step: 12
Training loss: 0.3213171362876892
Validation loss: 1.5452207506343882

Epoch: 6| Step: 13
Training loss: 0.17477470636367798
Validation loss: 1.544387061108825

Epoch: 372| Step: 0
Training loss: 0.23440319299697876
Validation loss: 1.5064668924577775

Epoch: 6| Step: 1
Training loss: 0.11595088988542557
Validation loss: 1.5461328285996632

Epoch: 6| Step: 2
Training loss: 0.36980706453323364
Validation loss: 1.5703597889151624

Epoch: 6| Step: 3
Training loss: 0.3772464394569397
Validation loss: 1.5776441904806322

Epoch: 6| Step: 4
Training loss: 0.2442093938589096
Validation loss: 1.5746567762026222

Epoch: 6| Step: 5
Training loss: 0.20019367337226868
Validation loss: 1.5823757994559504

Epoch: 6| Step: 6
Training loss: 0.13354623317718506
Validation loss: 1.5766945500527658

Epoch: 6| Step: 7
Training loss: 0.21779252588748932
Validation loss: 1.6251096687009257

Epoch: 6| Step: 8
Training loss: 0.2069598138332367
Validation loss: 1.6124515815447735

Epoch: 6| Step: 9
Training loss: 0.23687666654586792
Validation loss: 1.6053202190706808

Epoch: 6| Step: 10
Training loss: 0.18504954874515533
Validation loss: 1.6085094559577204

Epoch: 6| Step: 11
Training loss: 0.1303669959306717
Validation loss: 1.5565896290604786

Epoch: 6| Step: 12
Training loss: 0.2742432951927185
Validation loss: 1.5431404485497424

Epoch: 6| Step: 13
Training loss: 0.24355503916740417
Validation loss: 1.5361626366133332

Epoch: 373| Step: 0
Training loss: 0.2782405614852905
Validation loss: 1.5308984402687318

Epoch: 6| Step: 1
Training loss: 0.2806955575942993
Validation loss: 1.5538835551149102

Epoch: 6| Step: 2
Training loss: 0.1351478099822998
Validation loss: 1.5273778630841164

Epoch: 6| Step: 3
Training loss: 0.20192354917526245
Validation loss: 1.5294546863084197

Epoch: 6| Step: 4
Training loss: 0.4106218218803406
Validation loss: 1.551439654442572

Epoch: 6| Step: 5
Training loss: 0.19080032408237457
Validation loss: 1.53834395511176

Epoch: 6| Step: 6
Training loss: 0.18895599246025085
Validation loss: 1.5611386247860488

Epoch: 6| Step: 7
Training loss: 0.12303673475980759
Validation loss: 1.5375542563776816

Epoch: 6| Step: 8
Training loss: 0.17757540941238403
Validation loss: 1.5570159676254436

Epoch: 6| Step: 9
Training loss: 0.1758159101009369
Validation loss: 1.557085879387394

Epoch: 6| Step: 10
Training loss: 0.16983884572982788
Validation loss: 1.565829715421123

Epoch: 6| Step: 11
Training loss: 0.2194482386112213
Validation loss: 1.5668087441434142

Epoch: 6| Step: 12
Training loss: 0.1589561253786087
Validation loss: 1.5426164391220256

Epoch: 6| Step: 13
Training loss: 0.10071493685245514
Validation loss: 1.5283854469176261

Epoch: 374| Step: 0
Training loss: 0.15341416001319885
Validation loss: 1.5181143835026731

Epoch: 6| Step: 1
Training loss: 0.25085708498954773
Validation loss: 1.4805623933833132

Epoch: 6| Step: 2
Training loss: 0.18004876375198364
Validation loss: 1.5075958954390658

Epoch: 6| Step: 3
Training loss: 0.30263960361480713
Validation loss: 1.506240657580796

Epoch: 6| Step: 4
Training loss: 0.17201387882232666
Validation loss: 1.508621479875298

Epoch: 6| Step: 5
Training loss: 0.24388828873634338
Validation loss: 1.51981173792193

Epoch: 6| Step: 6
Training loss: 0.16647428274154663
Validation loss: 1.5222902759428947

Epoch: 6| Step: 7
Training loss: 0.1539493203163147
Validation loss: 1.5555279511277393

Epoch: 6| Step: 8
Training loss: 0.3615037202835083
Validation loss: 1.5626974567290275

Epoch: 6| Step: 9
Training loss: 0.2438964992761612
Validation loss: 1.5596541461124216

Epoch: 6| Step: 10
Training loss: 0.2650391161441803
Validation loss: 1.5759368135083107

Epoch: 6| Step: 11
Training loss: 0.18865758180618286
Validation loss: 1.5786284849207888

Epoch: 6| Step: 12
Training loss: 0.288211464881897
Validation loss: 1.5509521448484032

Epoch: 6| Step: 13
Training loss: 0.09615860879421234
Validation loss: 1.5421020894922235

Epoch: 375| Step: 0
Training loss: 0.14944112300872803
Validation loss: 1.5218352643392419

Epoch: 6| Step: 1
Training loss: 0.2721725106239319
Validation loss: 1.4980284949784637

Epoch: 6| Step: 2
Training loss: 0.19784009456634521
Validation loss: 1.5302411151188675

Epoch: 6| Step: 3
Training loss: 0.3818855583667755
Validation loss: 1.5050800808014408

Epoch: 6| Step: 4
Training loss: 0.12809711694717407
Validation loss: 1.5034666292129024

Epoch: 6| Step: 5
Training loss: 0.1557701677083969
Validation loss: 1.5150585097651328

Epoch: 6| Step: 6
Training loss: 0.2602519392967224
Validation loss: 1.50726403087698

Epoch: 6| Step: 7
Training loss: 0.15403923392295837
Validation loss: 1.494045735687338

Epoch: 6| Step: 8
Training loss: 0.10798384249210358
Validation loss: 1.5048405739568895

Epoch: 6| Step: 9
Training loss: 0.17284759879112244
Validation loss: 1.5144141015186106

Epoch: 6| Step: 10
Training loss: 0.131181538105011
Validation loss: 1.5190362584206365

Epoch: 6| Step: 11
Training loss: 0.2439178079366684
Validation loss: 1.5234124788673975

Epoch: 6| Step: 12
Training loss: 0.20912238955497742
Validation loss: 1.563070724728287

Epoch: 6| Step: 13
Training loss: 0.23213471472263336
Validation loss: 1.5491348235837874

Epoch: 376| Step: 0
Training loss: 0.32926613092422485
Validation loss: 1.5847621669051468

Epoch: 6| Step: 1
Training loss: 0.19104017317295074
Validation loss: 1.5709760509511477

Epoch: 6| Step: 2
Training loss: 0.11777952313423157
Validation loss: 1.589157873584378

Epoch: 6| Step: 3
Training loss: 0.11985701322555542
Validation loss: 1.579439607999658

Epoch: 6| Step: 4
Training loss: 0.11488273739814758
Validation loss: 1.5797843862605352

Epoch: 6| Step: 5
Training loss: 0.09704457223415375
Validation loss: 1.5847988397844377

Epoch: 6| Step: 6
Training loss: 0.12868079543113708
Validation loss: 1.5901742378870647

Epoch: 6| Step: 7
Training loss: 0.2077445089817047
Validation loss: 1.5635544023206156

Epoch: 6| Step: 8
Training loss: 0.19786596298217773
Validation loss: 1.555872207046837

Epoch: 6| Step: 9
Training loss: 0.13988712430000305
Validation loss: 1.5558806798791374

Epoch: 6| Step: 10
Training loss: 0.23068374395370483
Validation loss: 1.5608114170771774

Epoch: 6| Step: 11
Training loss: 0.38820433616638184
Validation loss: 1.5295021264783797

Epoch: 6| Step: 12
Training loss: 0.16559922695159912
Validation loss: 1.5662643255725983

Epoch: 6| Step: 13
Training loss: 0.3707333207130432
Validation loss: 1.5458169368005568

Epoch: 377| Step: 0
Training loss: 0.23967763781547546
Validation loss: 1.5411198382736535

Epoch: 6| Step: 1
Training loss: 0.1294456273317337
Validation loss: 1.5459595623836722

Epoch: 6| Step: 2
Training loss: 0.1931304931640625
Validation loss: 1.5021984769452004

Epoch: 6| Step: 3
Training loss: 0.08251357078552246
Validation loss: 1.529440333766322

Epoch: 6| Step: 4
Training loss: 0.11052852869033813
Validation loss: 1.497485363355247

Epoch: 6| Step: 5
Training loss: 0.24478870630264282
Validation loss: 1.5294610101689574

Epoch: 6| Step: 6
Training loss: 0.19919541478157043
Validation loss: 1.509541114171346

Epoch: 6| Step: 7
Training loss: 0.16945333778858185
Validation loss: 1.543811490458827

Epoch: 6| Step: 8
Training loss: 0.32891175150871277
Validation loss: 1.5146042621263893

Epoch: 6| Step: 9
Training loss: 0.2131752222776413
Validation loss: 1.538438166341474

Epoch: 6| Step: 10
Training loss: 0.12655916810035706
Validation loss: 1.5378419224933912

Epoch: 6| Step: 11
Training loss: 0.16074258089065552
Validation loss: 1.5748026935003137

Epoch: 6| Step: 12
Training loss: 0.11923001706600189
Validation loss: 1.5563595218043174

Epoch: 6| Step: 13
Training loss: 0.21761958301067352
Validation loss: 1.5458386393003567

Epoch: 378| Step: 0
Training loss: 0.20936715602874756
Validation loss: 1.5582378718160814

Epoch: 6| Step: 1
Training loss: 0.10407780110836029
Validation loss: 1.5311642385298205

Epoch: 6| Step: 2
Training loss: 0.2298334687948227
Validation loss: 1.5240680684325516

Epoch: 6| Step: 3
Training loss: 0.1180267333984375
Validation loss: 1.502438243999276

Epoch: 6| Step: 4
Training loss: 0.21101075410842896
Validation loss: 1.5187377570777811

Epoch: 6| Step: 5
Training loss: 0.18049323558807373
Validation loss: 1.5098305017717424

Epoch: 6| Step: 6
Training loss: 0.21032671630382538
Validation loss: 1.5136123498280842

Epoch: 6| Step: 7
Training loss: 0.17973914742469788
Validation loss: 1.5388992845371205

Epoch: 6| Step: 8
Training loss: 0.16627317667007446
Validation loss: 1.5007552357130154

Epoch: 6| Step: 9
Training loss: 0.11182679235935211
Validation loss: 1.5238638244649416

Epoch: 6| Step: 10
Training loss: 0.12029986083507538
Validation loss: 1.4990467999571113

Epoch: 6| Step: 11
Training loss: 0.16492517292499542
Validation loss: 1.5047795516188427

Epoch: 6| Step: 12
Training loss: 0.1597377359867096
Validation loss: 1.496867133725074

Epoch: 6| Step: 13
Training loss: 0.5490098595619202
Validation loss: 1.5068674049069803

Epoch: 379| Step: 0
Training loss: 0.16466085612773895
Validation loss: 1.5519839320131528

Epoch: 6| Step: 1
Training loss: 0.2196606695652008
Validation loss: 1.5242275153436968

Epoch: 6| Step: 2
Training loss: 0.21327565610408783
Validation loss: 1.5485437672625306

Epoch: 6| Step: 3
Training loss: 0.20878168940544128
Validation loss: 1.5430419073309949

Epoch: 6| Step: 4
Training loss: 0.1247701570391655
Validation loss: 1.521782358487447

Epoch: 6| Step: 5
Training loss: 0.33982887864112854
Validation loss: 1.5140715132477462

Epoch: 6| Step: 6
Training loss: 0.17775721848011017
Validation loss: 1.528486623558947

Epoch: 6| Step: 7
Training loss: 0.13271808624267578
Validation loss: 1.5456608149313158

Epoch: 6| Step: 8
Training loss: 0.15877765417099
Validation loss: 1.5511802716921734

Epoch: 6| Step: 9
Training loss: 0.18441691994667053
Validation loss: 1.5761804292278905

Epoch: 6| Step: 10
Training loss: 0.16566890478134155
Validation loss: 1.5452592975349837

Epoch: 6| Step: 11
Training loss: 0.34221959114074707
Validation loss: 1.5183029975942386

Epoch: 6| Step: 12
Training loss: 0.12769275903701782
Validation loss: 1.533337253396229

Epoch: 6| Step: 13
Training loss: 0.2943769693374634
Validation loss: 1.5256886264329315

Epoch: 380| Step: 0
Training loss: 0.18370574712753296
Validation loss: 1.5513578627699165

Epoch: 6| Step: 1
Training loss: 0.19472602009773254
Validation loss: 1.5369444367706135

Epoch: 6| Step: 2
Training loss: 0.20619620382785797
Validation loss: 1.5144769235323834

Epoch: 6| Step: 3
Training loss: 0.2942141592502594
Validation loss: 1.50790439626222

Epoch: 6| Step: 4
Training loss: 0.31453537940979004
Validation loss: 1.4854035467229865

Epoch: 6| Step: 5
Training loss: 0.21604087948799133
Validation loss: 1.4881525219127696

Epoch: 6| Step: 6
Training loss: 0.15061357617378235
Validation loss: 1.4748954798585625

Epoch: 6| Step: 7
Training loss: 0.12054839730262756
Validation loss: 1.5297412244222497

Epoch: 6| Step: 8
Training loss: 0.07986091077327728
Validation loss: 1.5178983826791086

Epoch: 6| Step: 9
Training loss: 0.2691621482372284
Validation loss: 1.5368410976984168

Epoch: 6| Step: 10
Training loss: 0.22859466075897217
Validation loss: 1.566639191360884

Epoch: 6| Step: 11
Training loss: 0.36588457226753235
Validation loss: 1.5339893756374237

Epoch: 6| Step: 12
Training loss: 0.22177273035049438
Validation loss: 1.5262694563916934

Epoch: 6| Step: 13
Training loss: 0.09906821697950363
Validation loss: 1.537349615045773

Epoch: 381| Step: 0
Training loss: 0.16317006945610046
Validation loss: 1.5177120688141033

Epoch: 6| Step: 1
Training loss: 0.23342834413051605
Validation loss: 1.5327843004657375

Epoch: 6| Step: 2
Training loss: 0.17113658785820007
Validation loss: 1.4939672344474382

Epoch: 6| Step: 3
Training loss: 0.08221230655908585
Validation loss: 1.5403728651744064

Epoch: 6| Step: 4
Training loss: 0.14248910546302795
Validation loss: 1.529749990791403

Epoch: 6| Step: 5
Training loss: 0.19142726063728333
Validation loss: 1.5426545925037836

Epoch: 6| Step: 6
Training loss: 0.3572429418563843
Validation loss: 1.5355471616150231

Epoch: 6| Step: 7
Training loss: 0.19073277711868286
Validation loss: 1.5453145888543898

Epoch: 6| Step: 8
Training loss: 0.1415911316871643
Validation loss: 1.561335588014254

Epoch: 6| Step: 9
Training loss: 0.2343607097864151
Validation loss: 1.5522140822102946

Epoch: 6| Step: 10
Training loss: 0.20525552332401276
Validation loss: 1.5680909566981818

Epoch: 6| Step: 11
Training loss: 0.20864200592041016
Validation loss: 1.5543452206478323

Epoch: 6| Step: 12
Training loss: 0.21286866068840027
Validation loss: 1.558569594096112

Epoch: 6| Step: 13
Training loss: 0.17683850228786469
Validation loss: 1.5125654006517062

Epoch: 382| Step: 0
Training loss: 0.2659309208393097
Validation loss: 1.5154402871285715

Epoch: 6| Step: 1
Training loss: 0.08929771929979324
Validation loss: 1.4988898102955153

Epoch: 6| Step: 2
Training loss: 0.14911270141601562
Validation loss: 1.4656553947797386

Epoch: 6| Step: 3
Training loss: 0.20979782938957214
Validation loss: 1.468883418267773

Epoch: 6| Step: 4
Training loss: 0.11122997105121613
Validation loss: 1.4473048769017702

Epoch: 6| Step: 5
Training loss: 0.24001048505306244
Validation loss: 1.449832256122302

Epoch: 6| Step: 6
Training loss: 0.15510796010494232
Validation loss: 1.4892806218516441

Epoch: 6| Step: 7
Training loss: 0.15537573397159576
Validation loss: 1.502572036558582

Epoch: 6| Step: 8
Training loss: 0.363512247800827
Validation loss: 1.5020701757041357

Epoch: 6| Step: 9
Training loss: 0.26929742097854614
Validation loss: 1.5441835708515619

Epoch: 6| Step: 10
Training loss: 0.13638459146022797
Validation loss: 1.5495829774487404

Epoch: 6| Step: 11
Training loss: 0.1820393204689026
Validation loss: 1.5208879568243538

Epoch: 6| Step: 12
Training loss: 0.31519195437431335
Validation loss: 1.526210372165967

Epoch: 6| Step: 13
Training loss: 0.28614822030067444
Validation loss: 1.4846325484655236

Epoch: 383| Step: 0
Training loss: 0.11928260326385498
Validation loss: 1.517488657787282

Epoch: 6| Step: 1
Training loss: 0.38546788692474365
Validation loss: 1.470635591014739

Epoch: 6| Step: 2
Training loss: 0.267589271068573
Validation loss: 1.5055878893021615

Epoch: 6| Step: 3
Training loss: 0.14720836281776428
Validation loss: 1.5038975233672767

Epoch: 6| Step: 4
Training loss: 0.2312629222869873
Validation loss: 1.4899126893730574

Epoch: 6| Step: 5
Training loss: 0.18559321761131287
Validation loss: 1.4895065869054487

Epoch: 6| Step: 6
Training loss: 0.11419425904750824
Validation loss: 1.4909516008951331

Epoch: 6| Step: 7
Training loss: 0.18851065635681152
Validation loss: 1.5078643201499857

Epoch: 6| Step: 8
Training loss: 0.20797167718410492
Validation loss: 1.5047333009781376

Epoch: 6| Step: 9
Training loss: 0.14106181263923645
Validation loss: 1.4904563016788934

Epoch: 6| Step: 10
Training loss: 0.22000935673713684
Validation loss: 1.4802387709258704

Epoch: 6| Step: 11
Training loss: 0.20441347360610962
Validation loss: 1.4970039090802592

Epoch: 6| Step: 12
Training loss: 0.2175121009349823
Validation loss: 1.5092293741882488

Epoch: 6| Step: 13
Training loss: 0.27995336055755615
Validation loss: 1.5122760713741343

Epoch: 384| Step: 0
Training loss: 0.21090936660766602
Validation loss: 1.502763731505281

Epoch: 6| Step: 1
Training loss: 0.12826970219612122
Validation loss: 1.5212419058686943

Epoch: 6| Step: 2
Training loss: 0.11283959448337555
Validation loss: 1.504021208773377

Epoch: 6| Step: 3
Training loss: 0.31394869089126587
Validation loss: 1.493840959764296

Epoch: 6| Step: 4
Training loss: 0.23022077977657318
Validation loss: 1.4985616707032727

Epoch: 6| Step: 5
Training loss: 0.2524182200431824
Validation loss: 1.5081908959214405

Epoch: 6| Step: 6
Training loss: 0.20290228724479675
Validation loss: 1.5242554833812099

Epoch: 6| Step: 7
Training loss: 0.2171749472618103
Validation loss: 1.5168982513489262

Epoch: 6| Step: 8
Training loss: 0.2659609019756317
Validation loss: 1.4771738334368634

Epoch: 6| Step: 9
Training loss: 0.08593638241291046
Validation loss: 1.4647538399183622

Epoch: 6| Step: 10
Training loss: 0.20657306909561157
Validation loss: 1.4839985960273332

Epoch: 6| Step: 11
Training loss: 0.15022039413452148
Validation loss: 1.4605371144510084

Epoch: 6| Step: 12
Training loss: 0.1321965456008911
Validation loss: 1.4640534808558803

Epoch: 6| Step: 13
Training loss: 0.152932807803154
Validation loss: 1.4313099550944504

Epoch: 385| Step: 0
Training loss: 0.10199888795614243
Validation loss: 1.4238352160299979

Epoch: 6| Step: 1
Training loss: 0.1470816731452942
Validation loss: 1.454081759017001

Epoch: 6| Step: 2
Training loss: 0.09488114714622498
Validation loss: 1.4687355692668627

Epoch: 6| Step: 3
Training loss: 0.22000570595264435
Validation loss: 1.4451889389304704

Epoch: 6| Step: 4
Training loss: 0.14336882531642914
Validation loss: 1.4844303579740628

Epoch: 6| Step: 5
Training loss: 0.37638890743255615
Validation loss: 1.462996543094676

Epoch: 6| Step: 6
Training loss: 0.10616957396268845
Validation loss: 1.5014309203752907

Epoch: 6| Step: 7
Training loss: 0.19970360398292542
Validation loss: 1.4715178435848606

Epoch: 6| Step: 8
Training loss: 0.12199738621711731
Validation loss: 1.4806337971841135

Epoch: 6| Step: 9
Training loss: 0.23080623149871826
Validation loss: 1.4970991457662275

Epoch: 6| Step: 10
Training loss: 0.17130053043365479
Validation loss: 1.507128316869018

Epoch: 6| Step: 11
Training loss: 0.14281320571899414
Validation loss: 1.5034269466195056

Epoch: 6| Step: 12
Training loss: 0.26810240745544434
Validation loss: 1.4699133737112886

Epoch: 6| Step: 13
Training loss: 0.1266220360994339
Validation loss: 1.5106011206103909

Epoch: 386| Step: 0
Training loss: 0.18586520850658417
Validation loss: 1.5080639816099597

Epoch: 6| Step: 1
Training loss: 0.17756476998329163
Validation loss: 1.5043753834180935

Epoch: 6| Step: 2
Training loss: 0.10679622739553452
Validation loss: 1.5147562898615354

Epoch: 6| Step: 3
Training loss: 0.11987359821796417
Validation loss: 1.5206323464711506

Epoch: 6| Step: 4
Training loss: 0.18058446049690247
Validation loss: 1.528755299506649

Epoch: 6| Step: 5
Training loss: 0.40839412808418274
Validation loss: 1.5485917919425554

Epoch: 6| Step: 6
Training loss: 0.16957396268844604
Validation loss: 1.5787888867880708

Epoch: 6| Step: 7
Training loss: 0.1555112898349762
Validation loss: 1.5417762520492717

Epoch: 6| Step: 8
Training loss: 0.18451911211013794
Validation loss: 1.5175979188693467

Epoch: 6| Step: 9
Training loss: 0.18961814045906067
Validation loss: 1.4925715564399638

Epoch: 6| Step: 10
Training loss: 0.1725980043411255
Validation loss: 1.4980090741188294

Epoch: 6| Step: 11
Training loss: 0.1255771815776825
Validation loss: 1.4657298941766062

Epoch: 6| Step: 12
Training loss: 0.1843622326850891
Validation loss: 1.4624685856603807

Epoch: 6| Step: 13
Training loss: 0.4729580283164978
Validation loss: 1.4411158843707013

Epoch: 387| Step: 0
Training loss: 0.1918513923883438
Validation loss: 1.4493510518022763

Epoch: 6| Step: 1
Training loss: 0.21819975972175598
Validation loss: 1.4407978198861564

Epoch: 6| Step: 2
Training loss: 0.2350444793701172
Validation loss: 1.4420827755364038

Epoch: 6| Step: 3
Training loss: 0.1352313607931137
Validation loss: 1.4430986271109632

Epoch: 6| Step: 4
Training loss: 0.19025486707687378
Validation loss: 1.4467992872320197

Epoch: 6| Step: 5
Training loss: 0.2437979280948639
Validation loss: 1.4651708115813553

Epoch: 6| Step: 6
Training loss: 0.4166122376918793
Validation loss: 1.4772175300505854

Epoch: 6| Step: 7
Training loss: 0.2031944841146469
Validation loss: 1.4670410207522813

Epoch: 6| Step: 8
Training loss: 0.15240533649921417
Validation loss: 1.4772972035151657

Epoch: 6| Step: 9
Training loss: 0.0805325135588646
Validation loss: 1.5088160396904073

Epoch: 6| Step: 10
Training loss: 0.26133203506469727
Validation loss: 1.5249398626307005

Epoch: 6| Step: 11
Training loss: 0.11844897270202637
Validation loss: 1.564898310169097

Epoch: 6| Step: 12
Training loss: 0.1665974259376526
Validation loss: 1.5648246401099748

Epoch: 6| Step: 13
Training loss: 0.12571734189987183
Validation loss: 1.541597076641616

Epoch: 388| Step: 0
Training loss: 0.0709596574306488
Validation loss: 1.5061712777742775

Epoch: 6| Step: 1
Training loss: 0.22953587770462036
Validation loss: 1.4692473488469278

Epoch: 6| Step: 2
Training loss: 0.15801118314266205
Validation loss: 1.508948726038779

Epoch: 6| Step: 3
Training loss: 0.24706676602363586
Validation loss: 1.4992707980576383

Epoch: 6| Step: 4
Training loss: 0.1592463254928589
Validation loss: 1.4886986888864988

Epoch: 6| Step: 5
Training loss: 0.26987332105636597
Validation loss: 1.496320648859906

Epoch: 6| Step: 6
Training loss: 0.18637362122535706
Validation loss: 1.460500027543755

Epoch: 6| Step: 7
Training loss: 0.37277278304100037
Validation loss: 1.461761591255024

Epoch: 6| Step: 8
Training loss: 0.12759976089000702
Validation loss: 1.4767531919223007

Epoch: 6| Step: 9
Training loss: 0.18083682656288147
Validation loss: 1.4806217109003375

Epoch: 6| Step: 10
Training loss: 0.09893176704645157
Validation loss: 1.4876981704465804

Epoch: 6| Step: 11
Training loss: 0.164429172873497
Validation loss: 1.4663817728719404

Epoch: 6| Step: 12
Training loss: 0.15784117579460144
Validation loss: 1.510816793287954

Epoch: 6| Step: 13
Training loss: 0.19132789969444275
Validation loss: 1.4959055044317757

Epoch: 389| Step: 0
Training loss: 0.17135772109031677
Validation loss: 1.4802139446299563

Epoch: 6| Step: 1
Training loss: 0.25737908482551575
Validation loss: 1.499365011850993

Epoch: 6| Step: 2
Training loss: 0.18470855057239532
Validation loss: 1.502910093594623

Epoch: 6| Step: 3
Training loss: 0.20442262291908264
Validation loss: 1.4929630884560205

Epoch: 6| Step: 4
Training loss: 0.13688066601753235
Validation loss: 1.5062495611047233

Epoch: 6| Step: 5
Training loss: 0.17822381854057312
Validation loss: 1.5149823952746648

Epoch: 6| Step: 6
Training loss: 0.09502333402633667
Validation loss: 1.5023474302343143

Epoch: 6| Step: 7
Training loss: 0.3592096269130707
Validation loss: 1.5145490874526322

Epoch: 6| Step: 8
Training loss: 0.13778088986873627
Validation loss: 1.5530846426563878

Epoch: 6| Step: 9
Training loss: 0.2218848168849945
Validation loss: 1.5446171247830955

Epoch: 6| Step: 10
Training loss: 0.17260167002677917
Validation loss: 1.5734589548521145

Epoch: 6| Step: 11
Training loss: 0.2001827508211136
Validation loss: 1.5789300985233758

Epoch: 6| Step: 12
Training loss: 0.17705897986888885
Validation loss: 1.553800590576664

Epoch: 6| Step: 13
Training loss: 0.19670051336288452
Validation loss: 1.5554375520316504

Epoch: 390| Step: 0
Training loss: 0.23025310039520264
Validation loss: 1.5623111571035078

Epoch: 6| Step: 1
Training loss: 0.22263574600219727
Validation loss: 1.535975012727963

Epoch: 6| Step: 2
Training loss: 0.18478628993034363
Validation loss: 1.520827776642256

Epoch: 6| Step: 3
Training loss: 0.1305263340473175
Validation loss: 1.5327078078382759

Epoch: 6| Step: 4
Training loss: 0.18163557350635529
Validation loss: 1.4971144635190246

Epoch: 6| Step: 5
Training loss: 0.09426451474428177
Validation loss: 1.4781323696977349

Epoch: 6| Step: 6
Training loss: 0.16967105865478516
Validation loss: 1.4722700670201292

Epoch: 6| Step: 7
Training loss: 0.15062850713729858
Validation loss: 1.4548929840005853

Epoch: 6| Step: 8
Training loss: 0.12629371881484985
Validation loss: 1.4557850565961612

Epoch: 6| Step: 9
Training loss: 0.17826972901821136
Validation loss: 1.4782118874211465

Epoch: 6| Step: 10
Training loss: 0.1319373995065689
Validation loss: 1.4861049805918047

Epoch: 6| Step: 11
Training loss: 0.29863354563713074
Validation loss: 1.5162095997923164

Epoch: 6| Step: 12
Training loss: 0.3677120506763458
Validation loss: 1.5275233881447905

Epoch: 6| Step: 13
Training loss: 0.14502698183059692
Validation loss: 1.5913607484550887

Epoch: 391| Step: 0
Training loss: 0.17409968376159668
Validation loss: 1.581911220345446

Epoch: 6| Step: 1
Training loss: 0.24252569675445557
Validation loss: 1.6470863575576453

Epoch: 6| Step: 2
Training loss: 0.29046958684921265
Validation loss: 1.6166253717996741

Epoch: 6| Step: 3
Training loss: 0.3756025433540344
Validation loss: 1.581086101070527

Epoch: 6| Step: 4
Training loss: 0.2206674963235855
Validation loss: 1.577279265208911

Epoch: 6| Step: 5
Training loss: 0.20040418207645416
Validation loss: 1.5527915672589374

Epoch: 6| Step: 6
Training loss: 0.24892215430736542
Validation loss: 1.516353677677852

Epoch: 6| Step: 7
Training loss: 0.1450435072183609
Validation loss: 1.5490397625072028

Epoch: 6| Step: 8
Training loss: 0.1839195191860199
Validation loss: 1.497386537572389

Epoch: 6| Step: 9
Training loss: 0.3273894190788269
Validation loss: 1.4765490178138978

Epoch: 6| Step: 10
Training loss: 0.17734524607658386
Validation loss: 1.4697511362773117

Epoch: 6| Step: 11
Training loss: 0.2710055112838745
Validation loss: 1.4530377977637834

Epoch: 6| Step: 12
Training loss: 0.20734532177448273
Validation loss: 1.489830852836691

Epoch: 6| Step: 13
Training loss: 0.14853884279727936
Validation loss: 1.4670815954926193

Epoch: 392| Step: 0
Training loss: 0.09513027966022491
Validation loss: 1.48433691840018

Epoch: 6| Step: 1
Training loss: 0.18923550844192505
Validation loss: 1.5094437060817596

Epoch: 6| Step: 2
Training loss: 0.12787264585494995
Validation loss: 1.5114013764166063

Epoch: 6| Step: 3
Training loss: 0.28577038645744324
Validation loss: 1.536550908960322

Epoch: 6| Step: 4
Training loss: 0.21117664873600006
Validation loss: 1.5379217670809837

Epoch: 6| Step: 5
Training loss: 0.25076979398727417
Validation loss: 1.5440672469395462

Epoch: 6| Step: 6
Training loss: 0.1459553986787796
Validation loss: 1.5288325516126489

Epoch: 6| Step: 7
Training loss: 0.1710088551044464
Validation loss: 1.520811750042823

Epoch: 6| Step: 8
Training loss: 0.13733945786952972
Validation loss: 1.5024039450512137

Epoch: 6| Step: 9
Training loss: 0.1288316249847412
Validation loss: 1.4957434336344402

Epoch: 6| Step: 10
Training loss: 0.1952209621667862
Validation loss: 1.4940471790170158

Epoch: 6| Step: 11
Training loss: 0.2443850338459015
Validation loss: 1.5095710280121013

Epoch: 6| Step: 12
Training loss: 0.15412329137325287
Validation loss: 1.532368217745135

Epoch: 6| Step: 13
Training loss: 0.2656591534614563
Validation loss: 1.5158805898440781

Epoch: 393| Step: 0
Training loss: 0.157902330160141
Validation loss: 1.510971023190406

Epoch: 6| Step: 1
Training loss: 0.1017438992857933
Validation loss: 1.5385219435538016

Epoch: 6| Step: 2
Training loss: 0.07293560355901718
Validation loss: 1.530891110820155

Epoch: 6| Step: 3
Training loss: 0.08411233872175217
Validation loss: 1.538520110550747

Epoch: 6| Step: 4
Training loss: 0.20886728167533875
Validation loss: 1.520771853385433

Epoch: 6| Step: 5
Training loss: 0.1360989809036255
Validation loss: 1.520498844885057

Epoch: 6| Step: 6
Training loss: 0.34677064418792725
Validation loss: 1.5311323583766978

Epoch: 6| Step: 7
Training loss: 0.20316213369369507
Validation loss: 1.4940877883665022

Epoch: 6| Step: 8
Training loss: 0.29966849088668823
Validation loss: 1.502729924776221

Epoch: 6| Step: 9
Training loss: 0.13415363430976868
Validation loss: 1.5104452948416434

Epoch: 6| Step: 10
Training loss: 0.16609033942222595
Validation loss: 1.5100798696599982

Epoch: 6| Step: 11
Training loss: 0.1531354784965515
Validation loss: 1.5403220089532996

Epoch: 6| Step: 12
Training loss: 0.15257301926612854
Validation loss: 1.5186985769579489

Epoch: 6| Step: 13
Training loss: 0.06901872903108597
Validation loss: 1.5158333073380172

Epoch: 394| Step: 0
Training loss: 0.09362490475177765
Validation loss: 1.52120243605747

Epoch: 6| Step: 1
Training loss: 0.10372978448867798
Validation loss: 1.4999954392833095

Epoch: 6| Step: 2
Training loss: 0.11485282331705093
Validation loss: 1.5173097066981818

Epoch: 6| Step: 3
Training loss: 0.1585599035024643
Validation loss: 1.532871594352107

Epoch: 6| Step: 4
Training loss: 0.17316564917564392
Validation loss: 1.549976561659126

Epoch: 6| Step: 5
Training loss: 0.20710599422454834
Validation loss: 1.5286092501814648

Epoch: 6| Step: 6
Training loss: 0.17784877121448517
Validation loss: 1.5304803309902069

Epoch: 6| Step: 7
Training loss: 0.3311172127723694
Validation loss: 1.526336089257271

Epoch: 6| Step: 8
Training loss: 0.1097600907087326
Validation loss: 1.5039958210401638

Epoch: 6| Step: 9
Training loss: 0.12417621910572052
Validation loss: 1.522513202441636

Epoch: 6| Step: 10
Training loss: 0.20844577252864838
Validation loss: 1.510206514789212

Epoch: 6| Step: 11
Training loss: 0.15510255098342896
Validation loss: 1.4984500472263624

Epoch: 6| Step: 12
Training loss: 0.16433686017990112
Validation loss: 1.4976068363394788

Epoch: 6| Step: 13
Training loss: 0.3870794475078583
Validation loss: 1.4806998519487278

Epoch: 395| Step: 0
Training loss: 0.08315537124872208
Validation loss: 1.4733709878818964

Epoch: 6| Step: 1
Training loss: 0.3310244083404541
Validation loss: 1.4641814872782717

Epoch: 6| Step: 2
Training loss: 0.20750898122787476
Validation loss: 1.4667693876451062

Epoch: 6| Step: 3
Training loss: 0.11622890830039978
Validation loss: 1.460657404315087

Epoch: 6| Step: 4
Training loss: 0.13286444544792175
Validation loss: 1.4894685604239022

Epoch: 6| Step: 5
Training loss: 0.1842738538980484
Validation loss: 1.5111726137899584

Epoch: 6| Step: 6
Training loss: 0.1335105448961258
Validation loss: 1.5173687627238612

Epoch: 6| Step: 7
Training loss: 0.13014671206474304
Validation loss: 1.5038724150708926

Epoch: 6| Step: 8
Training loss: 0.10390292853116989
Validation loss: 1.4961249930884248

Epoch: 6| Step: 9
Training loss: 0.11994105577468872
Validation loss: 1.5049932669567805

Epoch: 6| Step: 10
Training loss: 0.11215485632419586
Validation loss: 1.4988831345753004

Epoch: 6| Step: 11
Training loss: 0.28117474913597107
Validation loss: 1.5145767516987299

Epoch: 6| Step: 12
Training loss: 0.23404815793037415
Validation loss: 1.5036004961177867

Epoch: 6| Step: 13
Training loss: 0.27683234214782715
Validation loss: 1.477979249851678

Epoch: 396| Step: 0
Training loss: 0.17157921195030212
Validation loss: 1.487116047131118

Epoch: 6| Step: 1
Training loss: 0.26154738664627075
Validation loss: 1.4861254204985916

Epoch: 6| Step: 2
Training loss: 0.1324722021818161
Validation loss: 1.4880314116836877

Epoch: 6| Step: 3
Training loss: 0.14049676060676575
Validation loss: 1.4936507619837278

Epoch: 6| Step: 4
Training loss: 0.18705889582633972
Validation loss: 1.4800416833610945

Epoch: 6| Step: 5
Training loss: 0.17577223479747772
Validation loss: 1.477645666368546

Epoch: 6| Step: 6
Training loss: 0.11368662118911743
Validation loss: 1.4603530719716062

Epoch: 6| Step: 7
Training loss: 0.19443589448928833
Validation loss: 1.4823576442656978

Epoch: 6| Step: 8
Training loss: 0.12917563319206238
Validation loss: 1.4971964846375168

Epoch: 6| Step: 9
Training loss: 0.15163977444171906
Validation loss: 1.4611630619213145

Epoch: 6| Step: 10
Training loss: 0.16794608533382416
Validation loss: 1.511183447735284

Epoch: 6| Step: 11
Training loss: 0.19177448749542236
Validation loss: 1.507890764103141

Epoch: 6| Step: 12
Training loss: 0.42465633153915405
Validation loss: 1.527757812571782

Epoch: 6| Step: 13
Training loss: 0.12244267016649246
Validation loss: 1.5444587789556032

Epoch: 397| Step: 0
Training loss: 0.30109837651252747
Validation loss: 1.625050768416415

Epoch: 6| Step: 1
Training loss: 0.24640844762325287
Validation loss: 1.5897078360280683

Epoch: 6| Step: 2
Training loss: 0.1995093673467636
Validation loss: 1.4918235091752903

Epoch: 6| Step: 3
Training loss: 0.1325642168521881
Validation loss: 1.4584640892603065

Epoch: 6| Step: 4
Training loss: 0.19877555966377258
Validation loss: 1.439955602410019

Epoch: 6| Step: 5
Training loss: 0.4452919065952301
Validation loss: 1.4491813029012373

Epoch: 6| Step: 6
Training loss: 0.253084272146225
Validation loss: 1.4613370113475348

Epoch: 6| Step: 7
Training loss: 0.1960078477859497
Validation loss: 1.4708108837886522

Epoch: 6| Step: 8
Training loss: 0.42642292380332947
Validation loss: 1.5125699466274631

Epoch: 6| Step: 9
Training loss: 0.217802494764328
Validation loss: 1.4810977648663264

Epoch: 6| Step: 10
Training loss: 0.14286664128303528
Validation loss: 1.4909740442870765

Epoch: 6| Step: 11
Training loss: 0.13679705560207367
Validation loss: 1.5339589913686116

Epoch: 6| Step: 12
Training loss: 0.17596375942230225
Validation loss: 1.5962143585246096

Epoch: 6| Step: 13
Training loss: 0.23910580575466156
Validation loss: 1.6574316024780273

Epoch: 398| Step: 0
Training loss: 0.3992547392845154
Validation loss: 1.6526126310389528

Epoch: 6| Step: 1
Training loss: 0.287743479013443
Validation loss: 1.6044405378321165

Epoch: 6| Step: 2
Training loss: 0.25125616788864136
Validation loss: 1.5364824648826354

Epoch: 6| Step: 3
Training loss: 0.1965414136648178
Validation loss: 1.4496485206388658

Epoch: 6| Step: 4
Training loss: 0.33802369236946106
Validation loss: 1.4386277695496876

Epoch: 6| Step: 5
Training loss: 0.2514466941356659
Validation loss: 1.4371415979118758

Epoch: 6| Step: 6
Training loss: 0.2166326344013214
Validation loss: 1.4345145084524666

Epoch: 6| Step: 7
Training loss: 0.3122727870941162
Validation loss: 1.4563119552468742

Epoch: 6| Step: 8
Training loss: 0.19848808646202087
Validation loss: 1.4629177983089159

Epoch: 6| Step: 9
Training loss: 0.12906423211097717
Validation loss: 1.4582906955031938

Epoch: 6| Step: 10
Training loss: 0.30992019176483154
Validation loss: 1.4459246807200934

Epoch: 6| Step: 11
Training loss: 0.1264180839061737
Validation loss: 1.4557727754756968

Epoch: 6| Step: 12
Training loss: 0.08106573671102524
Validation loss: 1.5185903336412163

Epoch: 6| Step: 13
Training loss: 0.15933936834335327
Validation loss: 1.5751018575442735

Epoch: 399| Step: 0
Training loss: 0.26640594005584717
Validation loss: 1.6261226541252547

Epoch: 6| Step: 1
Training loss: 0.24634726345539093
Validation loss: 1.6468948010475404

Epoch: 6| Step: 2
Training loss: 0.21648725867271423
Validation loss: 1.5940935342542586

Epoch: 6| Step: 3
Training loss: 0.17863336205482483
Validation loss: 1.5827386635606007

Epoch: 6| Step: 4
Training loss: 0.23128971457481384
Validation loss: 1.5660654473048385

Epoch: 6| Step: 5
Training loss: 0.3496394157409668
Validation loss: 1.559102698038983

Epoch: 6| Step: 6
Training loss: 0.2673930525779724
Validation loss: 1.5328105201003372

Epoch: 6| Step: 7
Training loss: 0.13461820781230927
Validation loss: 1.5259639242643952

Epoch: 6| Step: 8
Training loss: 0.11756527423858643
Validation loss: 1.5159430785845684

Epoch: 6| Step: 9
Training loss: 0.13412225246429443
Validation loss: 1.5323281083055722

Epoch: 6| Step: 10
Training loss: 0.13606123626232147
Validation loss: 1.506540672753447

Epoch: 6| Step: 11
Training loss: 0.18608058989048004
Validation loss: 1.5028295247785506

Epoch: 6| Step: 12
Training loss: 0.1648470014333725
Validation loss: 1.5171265935385099

Epoch: 6| Step: 13
Training loss: 0.11955209821462631
Validation loss: 1.515032487530862

Epoch: 400| Step: 0
Training loss: 0.18582502007484436
Validation loss: 1.5218328609261462

Epoch: 6| Step: 1
Training loss: 0.18995508551597595
Validation loss: 1.501003239744453

Epoch: 6| Step: 2
Training loss: 0.19395358860492706
Validation loss: 1.5232384384319346

Epoch: 6| Step: 3
Training loss: 0.14260828495025635
Validation loss: 1.530269850966751

Epoch: 6| Step: 4
Training loss: 0.1598512828350067
Validation loss: 1.5362162590026855

Epoch: 6| Step: 5
Training loss: 0.15673568844795227
Validation loss: 1.5285505915200839

Epoch: 6| Step: 6
Training loss: 0.3402813971042633
Validation loss: 1.5196183676360755

Epoch: 6| Step: 7
Training loss: 0.14423686265945435
Validation loss: 1.5254064503536429

Epoch: 6| Step: 8
Training loss: 0.16611701250076294
Validation loss: 1.5210039250312313

Epoch: 6| Step: 9
Training loss: 0.13603533804416656
Validation loss: 1.501857837041219

Epoch: 6| Step: 10
Training loss: 0.15183645486831665
Validation loss: 1.4901225586091318

Epoch: 6| Step: 11
Training loss: 0.13515305519104004
Validation loss: 1.4620071514960258

Epoch: 6| Step: 12
Training loss: 0.15726733207702637
Validation loss: 1.481375204619541

Epoch: 6| Step: 13
Training loss: 0.22383202612400055
Validation loss: 1.4599141254219958

Epoch: 401| Step: 0
Training loss: 0.2895624339580536
Validation loss: 1.459032694498698

Epoch: 6| Step: 1
Training loss: 0.20196881890296936
Validation loss: 1.4631045108200402

Epoch: 6| Step: 2
Training loss: 0.09635759145021439
Validation loss: 1.4855324427286785

Epoch: 6| Step: 3
Training loss: 0.21697382628917694
Validation loss: 1.4805360160848147

Epoch: 6| Step: 4
Training loss: 0.10703499615192413
Validation loss: 1.473314941570323

Epoch: 6| Step: 5
Training loss: 0.08357249945402145
Validation loss: 1.4957746921047088

Epoch: 6| Step: 6
Training loss: 0.12410960346460342
Validation loss: 1.5078930406160251

Epoch: 6| Step: 7
Training loss: 0.09788557887077332
Validation loss: 1.4940312318904425

Epoch: 6| Step: 8
Training loss: 0.16950896382331848
Validation loss: 1.4880648095120665

Epoch: 6| Step: 9
Training loss: 0.13973987102508545
Validation loss: 1.4865895368719613

Epoch: 6| Step: 10
Training loss: 0.13524389266967773
Validation loss: 1.4877443082870976

Epoch: 6| Step: 11
Training loss: 0.2044796347618103
Validation loss: 1.4833836760572208

Epoch: 6| Step: 12
Training loss: 0.12798461318016052
Validation loss: 1.4872039928231189

Epoch: 6| Step: 13
Training loss: 0.1905660629272461
Validation loss: 1.4953639456020889

Epoch: 402| Step: 0
Training loss: 0.15122565627098083
Validation loss: 1.492241371062494

Epoch: 6| Step: 1
Training loss: 0.22150205075740814
Validation loss: 1.473736334872502

Epoch: 6| Step: 2
Training loss: 0.16758711636066437
Validation loss: 1.481632327520719

Epoch: 6| Step: 3
Training loss: 0.3356524705886841
Validation loss: 1.475849147765867

Epoch: 6| Step: 4
Training loss: 0.06759011745452881
Validation loss: 1.4833923020670492

Epoch: 6| Step: 5
Training loss: 0.18862739205360413
Validation loss: 1.4955204622719878

Epoch: 6| Step: 6
Training loss: 0.18915873765945435
Validation loss: 1.484001980032972

Epoch: 6| Step: 7
Training loss: 0.1441560685634613
Validation loss: 1.503029800230457

Epoch: 6| Step: 8
Training loss: 0.1062699481844902
Validation loss: 1.5597167835440686

Epoch: 6| Step: 9
Training loss: 0.27663102746009827
Validation loss: 1.5701516494956067

Epoch: 6| Step: 10
Training loss: 0.13151699304580688
Validation loss: 1.5870905665941135

Epoch: 6| Step: 11
Training loss: 0.18107739090919495
Validation loss: 1.5654390415837687

Epoch: 6| Step: 12
Training loss: 0.2494770884513855
Validation loss: 1.5302207213576122

Epoch: 6| Step: 13
Training loss: 0.14675435423851013
Validation loss: 1.49479002593666

Epoch: 403| Step: 0
Training loss: 0.12575937807559967
Validation loss: 1.4047299995217273

Epoch: 6| Step: 1
Training loss: 0.20944681763648987
Validation loss: 1.3617724013584915

Epoch: 6| Step: 2
Training loss: 0.2884405255317688
Validation loss: 1.3639289666247625

Epoch: 6| Step: 3
Training loss: 0.3617859482765198
Validation loss: 1.3804814456611552

Epoch: 6| Step: 4
Training loss: 0.2461048662662506
Validation loss: 1.3584320096559421

Epoch: 6| Step: 5
Training loss: 0.20588666200637817
Validation loss: 1.3759266240622408

Epoch: 6| Step: 6
Training loss: 0.1985236406326294
Validation loss: 1.4121776293682795

Epoch: 6| Step: 7
Training loss: 0.1592753529548645
Validation loss: 1.4375983053638088

Epoch: 6| Step: 8
Training loss: 0.10363996028900146
Validation loss: 1.4624037665705527

Epoch: 6| Step: 9
Training loss: 0.14780867099761963
Validation loss: 1.5101528340770352

Epoch: 6| Step: 10
Training loss: 0.147645503282547
Validation loss: 1.5350385763311898

Epoch: 6| Step: 11
Training loss: 0.16200312972068787
Validation loss: 1.5794205537406347

Epoch: 6| Step: 12
Training loss: 0.15157245099544525
Validation loss: 1.561437491447695

Epoch: 6| Step: 13
Training loss: 0.24058116972446442
Validation loss: 1.625143672830315

Epoch: 404| Step: 0
Training loss: 0.17378529906272888
Validation loss: 1.5749703543160551

Epoch: 6| Step: 1
Training loss: 0.18156076967716217
Validation loss: 1.5883696797073528

Epoch: 6| Step: 2
Training loss: 0.1856091320514679
Validation loss: 1.5384684724192466

Epoch: 6| Step: 3
Training loss: 0.13420403003692627
Validation loss: 1.5038253197105982

Epoch: 6| Step: 4
Training loss: 0.12646393477916718
Validation loss: 1.4670004857483732

Epoch: 6| Step: 5
Training loss: 0.07411319017410278
Validation loss: 1.4501662818334435

Epoch: 6| Step: 6
Training loss: 0.2501089870929718
Validation loss: 1.4419899858454222

Epoch: 6| Step: 7
Training loss: 0.46549248695373535
Validation loss: 1.4169557914938977

Epoch: 6| Step: 8
Training loss: 0.18107806146144867
Validation loss: 1.4355747712555753

Epoch: 6| Step: 9
Training loss: 0.16936129331588745
Validation loss: 1.4224167831482426

Epoch: 6| Step: 10
Training loss: 0.13949912786483765
Validation loss: 1.4370576207355787

Epoch: 6| Step: 11
Training loss: 0.159902423620224
Validation loss: 1.4380797968115857

Epoch: 6| Step: 12
Training loss: 0.12112540006637573
Validation loss: 1.46041989198295

Epoch: 6| Step: 13
Training loss: 0.09728453308343887
Validation loss: 1.4562598812964656

Epoch: 405| Step: 0
Training loss: 0.1576925367116928
Validation loss: 1.4661245858797463

Epoch: 6| Step: 1
Training loss: 0.1440846025943756
Validation loss: 1.4697915366900864

Epoch: 6| Step: 2
Training loss: 0.14788654446601868
Validation loss: 1.4954102270064815

Epoch: 6| Step: 3
Training loss: 0.12651771306991577
Validation loss: 1.5272750309718552

Epoch: 6| Step: 4
Training loss: 0.20078182220458984
Validation loss: 1.5336816592883038

Epoch: 6| Step: 5
Training loss: 0.24010711908340454
Validation loss: 1.5529542071844942

Epoch: 6| Step: 6
Training loss: 0.1812378317117691
Validation loss: 1.5349611813022244

Epoch: 6| Step: 7
Training loss: 0.21588866412639618
Validation loss: 1.5279518391496392

Epoch: 6| Step: 8
Training loss: 0.09067923575639725
Validation loss: 1.5254731524375178

Epoch: 6| Step: 9
Training loss: 0.13044960796833038
Validation loss: 1.5107226499947168

Epoch: 6| Step: 10
Training loss: 0.15097205340862274
Validation loss: 1.5223544727089584

Epoch: 6| Step: 11
Training loss: 0.1451318860054016
Validation loss: 1.504053795209495

Epoch: 6| Step: 12
Training loss: 0.3284136652946472
Validation loss: 1.5035093497204524

Epoch: 6| Step: 13
Training loss: 0.09713079035282135
Validation loss: 1.464567756781014

Epoch: 406| Step: 0
Training loss: 0.14571118354797363
Validation loss: 1.4849029407706311

Epoch: 6| Step: 1
Training loss: 0.16384287178516388
Validation loss: 1.4635848973387031

Epoch: 6| Step: 2
Training loss: 0.16425859928131104
Validation loss: 1.4276421249553721

Epoch: 6| Step: 3
Training loss: 0.11293777823448181
Validation loss: 1.4373419348911574

Epoch: 6| Step: 4
Training loss: 0.10219607502222061
Validation loss: 1.4365454450730355

Epoch: 6| Step: 5
Training loss: 0.11022675037384033
Validation loss: 1.4229326081532303

Epoch: 6| Step: 6
Training loss: 0.17024116218090057
Validation loss: 1.444609224155385

Epoch: 6| Step: 7
Training loss: 0.14551317691802979
Validation loss: 1.4197031297991354

Epoch: 6| Step: 8
Training loss: 0.16541805863380432
Validation loss: 1.4249942110430809

Epoch: 6| Step: 9
Training loss: 0.3357261121273041
Validation loss: 1.4428239163532053

Epoch: 6| Step: 10
Training loss: 0.11653611063957214
Validation loss: 1.4540976068024993

Epoch: 6| Step: 11
Training loss: 0.1211969405412674
Validation loss: 1.4814320251505861

Epoch: 6| Step: 12
Training loss: 0.14401870965957642
Validation loss: 1.482007590673303

Epoch: 6| Step: 13
Training loss: 0.1183699518442154
Validation loss: 1.5150539285393172

Epoch: 407| Step: 0
Training loss: 0.08005266636610031
Validation loss: 1.5121276058176512

Epoch: 6| Step: 1
Training loss: 0.14461080729961395
Validation loss: 1.5058128744043329

Epoch: 6| Step: 2
Training loss: 0.11829280853271484
Validation loss: 1.5121037126869283

Epoch: 6| Step: 3
Training loss: 0.1171826645731926
Validation loss: 1.5150196398458173

Epoch: 6| Step: 4
Training loss: 0.1543688178062439
Validation loss: 1.5204833387046732

Epoch: 6| Step: 5
Training loss: 0.1496148556470871
Validation loss: 1.5121486033162763

Epoch: 6| Step: 6
Training loss: 0.1735565960407257
Validation loss: 1.4939298552851523

Epoch: 6| Step: 7
Training loss: 0.2223692387342453
Validation loss: 1.499912477308704

Epoch: 6| Step: 8
Training loss: 0.18515001237392426
Validation loss: 1.4848062325549383

Epoch: 6| Step: 9
Training loss: 0.12267212569713593
Validation loss: 1.4958318818000056

Epoch: 6| Step: 10
Training loss: 0.24222244322299957
Validation loss: 1.4972818192615305

Epoch: 6| Step: 11
Training loss: 0.08801963180303574
Validation loss: 1.4718851889333417

Epoch: 6| Step: 12
Training loss: 0.0874049961566925
Validation loss: 1.464194941264327

Epoch: 6| Step: 13
Training loss: 0.16935628652572632
Validation loss: 1.4904186725616455

Epoch: 408| Step: 0
Training loss: 0.17860375344753265
Validation loss: 1.4773829457580403

Epoch: 6| Step: 1
Training loss: 0.11113471537828445
Validation loss: 1.4878079378476707

Epoch: 6| Step: 2
Training loss: 0.1595643162727356
Validation loss: 1.482643340223579

Epoch: 6| Step: 3
Training loss: 0.22175264358520508
Validation loss: 1.4936733579122892

Epoch: 6| Step: 4
Training loss: 0.1614575982093811
Validation loss: 1.4632061655803392

Epoch: 6| Step: 5
Training loss: 0.11324293166399002
Validation loss: 1.4548387078828708

Epoch: 6| Step: 6
Training loss: 0.14745500683784485
Validation loss: 1.4657643302794425

Epoch: 6| Step: 7
Training loss: 0.10378527641296387
Validation loss: 1.4503610941671556

Epoch: 6| Step: 8
Training loss: 0.15848509967327118
Validation loss: 1.450838928581566

Epoch: 6| Step: 9
Training loss: 0.10946111381053925
Validation loss: 1.4222905789652178

Epoch: 6| Step: 10
Training loss: 0.0902068167924881
Validation loss: 1.4214859816335863

Epoch: 6| Step: 11
Training loss: 0.06936836242675781
Validation loss: 1.4330199521075013

Epoch: 6| Step: 12
Training loss: 0.12062972784042358
Validation loss: 1.421508458352858

Epoch: 6| Step: 13
Training loss: 0.4620915651321411
Validation loss: 1.4630575064689881

Epoch: 409| Step: 0
Training loss: 0.20193371176719666
Validation loss: 1.4683328905413229

Epoch: 6| Step: 1
Training loss: 0.08854170143604279
Validation loss: 1.5002377622870988

Epoch: 6| Step: 2
Training loss: 0.16556501388549805
Validation loss: 1.5120177756073654

Epoch: 6| Step: 3
Training loss: 0.09915593266487122
Validation loss: 1.5112132500576716

Epoch: 6| Step: 4
Training loss: 0.1399538367986679
Validation loss: 1.517842915750319

Epoch: 6| Step: 5
Training loss: 0.24526624381542206
Validation loss: 1.503527509268894

Epoch: 6| Step: 6
Training loss: 0.20505589246749878
Validation loss: 1.4978035996037145

Epoch: 6| Step: 7
Training loss: 0.1301232874393463
Validation loss: 1.5003185297853203

Epoch: 6| Step: 8
Training loss: 0.055361419916152954
Validation loss: 1.4825859659461564

Epoch: 6| Step: 9
Training loss: 0.1662178784608841
Validation loss: 1.4816149063007806

Epoch: 6| Step: 10
Training loss: 0.12651494145393372
Validation loss: 1.485459102097378

Epoch: 6| Step: 11
Training loss: 0.16198307275772095
Validation loss: 1.5135143277465657

Epoch: 6| Step: 12
Training loss: 0.14559787511825562
Validation loss: 1.498342897302361

Epoch: 6| Step: 13
Training loss: 0.09972790628671646
Validation loss: 1.5129571653181506

Epoch: 410| Step: 0
Training loss: 0.08741964399814606
Validation loss: 1.5086949204885831

Epoch: 6| Step: 1
Training loss: 0.07153388857841492
Validation loss: 1.4983839219616306

Epoch: 6| Step: 2
Training loss: 0.20070883631706238
Validation loss: 1.5264944748211933

Epoch: 6| Step: 3
Training loss: 0.15580379962921143
Validation loss: 1.506078702147289

Epoch: 6| Step: 4
Training loss: 0.10953515022993088
Validation loss: 1.5052436731194938

Epoch: 6| Step: 5
Training loss: 0.11299607902765274
Validation loss: 1.4689596686311948

Epoch: 6| Step: 6
Training loss: 0.10558950901031494
Validation loss: 1.4591025511423747

Epoch: 6| Step: 7
Training loss: 0.14515411853790283
Validation loss: 1.4551807039527482

Epoch: 6| Step: 8
Training loss: 0.24763180315494537
Validation loss: 1.4484760145987234

Epoch: 6| Step: 9
Training loss: 0.17056240141391754
Validation loss: 1.4739057787003056

Epoch: 6| Step: 10
Training loss: 0.14613047242164612
Validation loss: 1.4644829996170536

Epoch: 6| Step: 11
Training loss: 0.15360002219676971
Validation loss: 1.4755070504321848

Epoch: 6| Step: 12
Training loss: 0.0935240387916565
Validation loss: 1.4975076734378774

Epoch: 6| Step: 13
Training loss: 0.17297855019569397
Validation loss: 1.50185715511281

Epoch: 411| Step: 0
Training loss: 0.10089111328125
Validation loss: 1.5064745397977932

Epoch: 6| Step: 1
Training loss: 0.14592836797237396
Validation loss: 1.4696558034548195

Epoch: 6| Step: 2
Training loss: 0.2829740345478058
Validation loss: 1.4671930049055366

Epoch: 6| Step: 3
Training loss: 0.13048861920833588
Validation loss: 1.484162893346561

Epoch: 6| Step: 4
Training loss: 0.13847117125988007
Validation loss: 1.4784976872064735

Epoch: 6| Step: 5
Training loss: 0.07032472640275955
Validation loss: 1.4927975618711082

Epoch: 6| Step: 6
Training loss: 0.13620054721832275
Validation loss: 1.4825742334447882

Epoch: 6| Step: 7
Training loss: 0.08182152360677719
Validation loss: 1.4859052294044084

Epoch: 6| Step: 8
Training loss: 0.19631794095039368
Validation loss: 1.4684337121184154

Epoch: 6| Step: 9
Training loss: 0.1494830995798111
Validation loss: 1.486882512287427

Epoch: 6| Step: 10
Training loss: 0.10681378841400146
Validation loss: 1.5197374295162898

Epoch: 6| Step: 11
Training loss: 0.1579889953136444
Validation loss: 1.5188910807332685

Epoch: 6| Step: 12
Training loss: 0.10549069941043854
Validation loss: 1.5294080767580258

Epoch: 6| Step: 13
Training loss: 0.16033992171287537
Validation loss: 1.5299797442651564

Epoch: 412| Step: 0
Training loss: 0.1629534363746643
Validation loss: 1.543089441073838

Epoch: 6| Step: 1
Training loss: 0.2082381248474121
Validation loss: 1.5626790100528347

Epoch: 6| Step: 2
Training loss: 0.21854472160339355
Validation loss: 1.5514615863882086

Epoch: 6| Step: 3
Training loss: 0.11050905287265778
Validation loss: 1.504686063335788

Epoch: 6| Step: 4
Training loss: 0.07731488347053528
Validation loss: 1.4946576113341956

Epoch: 6| Step: 5
Training loss: 0.17232346534729004
Validation loss: 1.4863782775017522

Epoch: 6| Step: 6
Training loss: 0.08587118983268738
Validation loss: 1.4879832293397637

Epoch: 6| Step: 7
Training loss: 0.07523475587368011
Validation loss: 1.4524795547608407

Epoch: 6| Step: 8
Training loss: 0.16261565685272217
Validation loss: 1.4467434729299238

Epoch: 6| Step: 9
Training loss: 0.1075473204255104
Validation loss: 1.466453363818507

Epoch: 6| Step: 10
Training loss: 0.09996163845062256
Validation loss: 1.4536730320222917

Epoch: 6| Step: 11
Training loss: 0.12667128443717957
Validation loss: 1.437345814961259

Epoch: 6| Step: 12
Training loss: 0.11556605994701385
Validation loss: 1.4408960662862307

Epoch: 6| Step: 13
Training loss: 0.40878307819366455
Validation loss: 1.4448420546388114

Epoch: 413| Step: 0
Training loss: 0.1902816891670227
Validation loss: 1.4584184276160372

Epoch: 6| Step: 1
Training loss: 0.108016237616539
Validation loss: 1.4850142617379465

Epoch: 6| Step: 2
Training loss: 0.1316051036119461
Validation loss: 1.4923667292441092

Epoch: 6| Step: 3
Training loss: 0.13087508082389832
Validation loss: 1.5113022391514113

Epoch: 6| Step: 4
Training loss: 0.17244170606136322
Validation loss: 1.5287102307042768

Epoch: 6| Step: 5
Training loss: 0.0958823412656784
Validation loss: 1.5388236776474984

Epoch: 6| Step: 6
Training loss: 0.12063892930746078
Validation loss: 1.5245687551395868

Epoch: 6| Step: 7
Training loss: 0.2694259583950043
Validation loss: 1.537564036666706

Epoch: 6| Step: 8
Training loss: 0.19807080924510956
Validation loss: 1.5199780175762792

Epoch: 6| Step: 9
Training loss: 0.18912240862846375
Validation loss: 1.5450477113005936

Epoch: 6| Step: 10
Training loss: 0.11878050863742828
Validation loss: 1.5273870242539274

Epoch: 6| Step: 11
Training loss: 0.09989887475967407
Validation loss: 1.5196955345010246

Epoch: 6| Step: 12
Training loss: 0.14364254474639893
Validation loss: 1.5403781655014201

Epoch: 6| Step: 13
Training loss: 0.14182673394680023
Validation loss: 1.5363206837766914

Epoch: 414| Step: 0
Training loss: 0.17278355360031128
Validation loss: 1.502858724645389

Epoch: 6| Step: 1
Training loss: 0.06892441213130951
Validation loss: 1.5022957305754385

Epoch: 6| Step: 2
Training loss: 0.2434057593345642
Validation loss: 1.491530829860318

Epoch: 6| Step: 3
Training loss: 0.16769328713417053
Validation loss: 1.480592732788414

Epoch: 6| Step: 4
Training loss: 0.09821689873933792
Validation loss: 1.5158582502795803

Epoch: 6| Step: 5
Training loss: 0.09486916661262512
Validation loss: 1.5011834111264957

Epoch: 6| Step: 6
Training loss: 0.1334916055202484
Validation loss: 1.4958078399781258

Epoch: 6| Step: 7
Training loss: 0.2518910765647888
Validation loss: 1.4702490811706872

Epoch: 6| Step: 8
Training loss: 0.1495433747768402
Validation loss: 1.5094611208925965

Epoch: 6| Step: 9
Training loss: 0.13233959674835205
Validation loss: 1.4958948659640487

Epoch: 6| Step: 10
Training loss: 0.15818379819393158
Validation loss: 1.512135583867309

Epoch: 6| Step: 11
Training loss: 0.14190761744976044
Validation loss: 1.5335839358709191

Epoch: 6| Step: 12
Training loss: 0.11432796716690063
Validation loss: 1.522646959109973

Epoch: 6| Step: 13
Training loss: 0.08707980066537857
Validation loss: 1.50824918541857

Epoch: 415| Step: 0
Training loss: 0.12976908683776855
Validation loss: 1.4871541453946022

Epoch: 6| Step: 1
Training loss: 0.15706181526184082
Validation loss: 1.4941857284115208

Epoch: 6| Step: 2
Training loss: 0.1881096363067627
Validation loss: 1.4650305086566555

Epoch: 6| Step: 3
Training loss: 0.13884249329566956
Validation loss: 1.469845303925135

Epoch: 6| Step: 4
Training loss: 0.1009545624256134
Validation loss: 1.4597578407615743

Epoch: 6| Step: 5
Training loss: 0.12209837138652802
Validation loss: 1.439091670897699

Epoch: 6| Step: 6
Training loss: 0.16551901400089264
Validation loss: 1.4727608503833893

Epoch: 6| Step: 7
Training loss: 0.12010809779167175
Validation loss: 1.4661288261413574

Epoch: 6| Step: 8
Training loss: 0.2709197998046875
Validation loss: 1.4616639101377098

Epoch: 6| Step: 9
Training loss: 0.10111263394355774
Validation loss: 1.4558611967230355

Epoch: 6| Step: 10
Training loss: 0.136269211769104
Validation loss: 1.4842955079129947

Epoch: 6| Step: 11
Training loss: 0.14566412568092346
Validation loss: 1.5114771499428699

Epoch: 6| Step: 12
Training loss: 0.08884385973215103
Validation loss: 1.508768504665744

Epoch: 6| Step: 13
Training loss: 0.11421390622854233
Validation loss: 1.522714053430865

Epoch: 416| Step: 0
Training loss: 0.1565587967634201
Validation loss: 1.5528724962665188

Epoch: 6| Step: 1
Training loss: 0.1553138941526413
Validation loss: 1.523730747161373

Epoch: 6| Step: 2
Training loss: 0.11465620249509811
Validation loss: 1.5265771304407427

Epoch: 6| Step: 3
Training loss: 0.12914834916591644
Validation loss: 1.4807588118378834

Epoch: 6| Step: 4
Training loss: 0.15997876226902008
Validation loss: 1.4915185102852442

Epoch: 6| Step: 5
Training loss: 0.09808260947465897
Validation loss: 1.4568522655835716

Epoch: 6| Step: 6
Training loss: 0.10290063917636871
Validation loss: 1.4458743423543952

Epoch: 6| Step: 7
Training loss: 0.17169031500816345
Validation loss: 1.4538562977185814

Epoch: 6| Step: 8
Training loss: 0.295708030462265
Validation loss: 1.4429700028511785

Epoch: 6| Step: 9
Training loss: 0.08705729991197586
Validation loss: 1.4491646020643172

Epoch: 6| Step: 10
Training loss: 0.2320265918970108
Validation loss: 1.4537280182684622

Epoch: 6| Step: 11
Training loss: 0.18398985266685486
Validation loss: 1.4459922582872453

Epoch: 6| Step: 12
Training loss: 0.12128162384033203
Validation loss: 1.442375817606526

Epoch: 6| Step: 13
Training loss: 0.05405879020690918
Validation loss: 1.4602439044624247

Epoch: 417| Step: 0
Training loss: 0.1665669083595276
Validation loss: 1.4692638138289094

Epoch: 6| Step: 1
Training loss: 0.10662475973367691
Validation loss: 1.494282466109081

Epoch: 6| Step: 2
Training loss: 0.1562664955854416
Validation loss: 1.5144093369924894

Epoch: 6| Step: 3
Training loss: 0.19219692051410675
Validation loss: 1.5153505007425945

Epoch: 6| Step: 4
Training loss: 0.14348241686820984
Validation loss: 1.5540368710794756

Epoch: 6| Step: 5
Training loss: 0.08322398364543915
Validation loss: 1.5229395743339293

Epoch: 6| Step: 6
Training loss: 0.12210941314697266
Validation loss: 1.5393548172007325

Epoch: 6| Step: 7
Training loss: 0.16531607508659363
Validation loss: 1.4902267366327264

Epoch: 6| Step: 8
Training loss: 0.0773477703332901
Validation loss: 1.5150479065474642

Epoch: 6| Step: 9
Training loss: 0.10046857595443726
Validation loss: 1.5202635283111243

Epoch: 6| Step: 10
Training loss: 0.24245797097682953
Validation loss: 1.4917095566308627

Epoch: 6| Step: 11
Training loss: 0.06683260947465897
Validation loss: 1.487135592327323

Epoch: 6| Step: 12
Training loss: 0.19433552026748657
Validation loss: 1.4792344416341474

Epoch: 6| Step: 13
Training loss: 0.08967606723308563
Validation loss: 1.4882308757433327

Epoch: 418| Step: 0
Training loss: 0.12168009579181671
Validation loss: 1.4673784932782572

Epoch: 6| Step: 1
Training loss: 0.09303522109985352
Validation loss: 1.449797934101474

Epoch: 6| Step: 2
Training loss: 0.08268599212169647
Validation loss: 1.461764027995448

Epoch: 6| Step: 3
Training loss: 0.23523381352424622
Validation loss: 1.466597459649527

Epoch: 6| Step: 4
Training loss: 0.1418769508600235
Validation loss: 1.4624636711612824

Epoch: 6| Step: 5
Training loss: 0.08735349029302597
Validation loss: 1.4245222089111165

Epoch: 6| Step: 6
Training loss: 0.09928325563669205
Validation loss: 1.4200426968195106

Epoch: 6| Step: 7
Training loss: 0.1699676215648651
Validation loss: 1.4202772071284633

Epoch: 6| Step: 8
Training loss: 0.11342987418174744
Validation loss: 1.4225490041958389

Epoch: 6| Step: 9
Training loss: 0.16959957778453827
Validation loss: 1.4502956905672628

Epoch: 6| Step: 10
Training loss: 0.3710551857948303
Validation loss: 1.4503712384931502

Epoch: 6| Step: 11
Training loss: 0.06452520936727524
Validation loss: 1.4540411592811666

Epoch: 6| Step: 12
Training loss: 0.11767562478780746
Validation loss: 1.4934674988510788

Epoch: 6| Step: 13
Training loss: 0.13169237971305847
Validation loss: 1.5090320469230734

Epoch: 419| Step: 0
Training loss: 0.15333035588264465
Validation loss: 1.5190383747059812

Epoch: 6| Step: 1
Training loss: 0.24668379127979279
Validation loss: 1.5083290697425924

Epoch: 6| Step: 2
Training loss: 0.14649060368537903
Validation loss: 1.5426695898015013

Epoch: 6| Step: 3
Training loss: 0.14110635221004486
Validation loss: 1.543945038190452

Epoch: 6| Step: 4
Training loss: 0.13070586323738098
Validation loss: 1.5242915063775995

Epoch: 6| Step: 5
Training loss: 0.17225930094718933
Validation loss: 1.5062985234363104

Epoch: 6| Step: 6
Training loss: 0.1678289920091629
Validation loss: 1.4817259619312901

Epoch: 6| Step: 7
Training loss: 0.09950132668018341
Validation loss: 1.4626898316926853

Epoch: 6| Step: 8
Training loss: 0.1587924063205719
Validation loss: 1.4858054025198824

Epoch: 6| Step: 9
Training loss: 0.08099091053009033
Validation loss: 1.4330824818662418

Epoch: 6| Step: 10
Training loss: 0.09666267782449722
Validation loss: 1.4274155260414205

Epoch: 6| Step: 11
Training loss: 0.17322224378585815
Validation loss: 1.4163548664380146

Epoch: 6| Step: 12
Training loss: 0.1552722007036209
Validation loss: 1.432739080921296

Epoch: 6| Step: 13
Training loss: 0.15365807712078094
Validation loss: 1.44048434944563

Epoch: 420| Step: 0
Training loss: 0.09677772969007492
Validation loss: 1.4180879490349882

Epoch: 6| Step: 1
Training loss: 0.05082377791404724
Validation loss: 1.4728285830507997

Epoch: 6| Step: 2
Training loss: 0.13307535648345947
Validation loss: 1.4790070415824972

Epoch: 6| Step: 3
Training loss: 0.2308558225631714
Validation loss: 1.4886023613714403

Epoch: 6| Step: 4
Training loss: 0.19186481833457947
Validation loss: 1.5205897823456795

Epoch: 6| Step: 5
Training loss: 0.2338538020849228
Validation loss: 1.516583493960801

Epoch: 6| Step: 6
Training loss: 0.19325467944145203
Validation loss: 1.538227649145229

Epoch: 6| Step: 7
Training loss: 0.13232940435409546
Validation loss: 1.5367421821881366

Epoch: 6| Step: 8
Training loss: 0.12807223200798035
Validation loss: 1.536339222743947

Epoch: 6| Step: 9
Training loss: 0.1494370549917221
Validation loss: 1.5421035456401047

Epoch: 6| Step: 10
Training loss: 0.14719998836517334
Validation loss: 1.520664902143581

Epoch: 6| Step: 11
Training loss: 0.12825724482536316
Validation loss: 1.5216718437851116

Epoch: 6| Step: 12
Training loss: 0.07570625096559525
Validation loss: 1.4900897843863374

Epoch: 6| Step: 13
Training loss: 0.0815427303314209
Validation loss: 1.483906449810151

Epoch: 421| Step: 0
Training loss: 0.14648489654064178
Validation loss: 1.4631263133018249

Epoch: 6| Step: 1
Training loss: 0.11523865163326263
Validation loss: 1.4323899220394831

Epoch: 6| Step: 2
Training loss: 0.08007853478193283
Validation loss: 1.4398965245933943

Epoch: 6| Step: 3
Training loss: 0.28958243131637573
Validation loss: 1.4309413971439484

Epoch: 6| Step: 4
Training loss: 0.08895102143287659
Validation loss: 1.424999713897705

Epoch: 6| Step: 5
Training loss: 0.11819784343242645
Validation loss: 1.4230588007998723

Epoch: 6| Step: 6
Training loss: 0.15292996168136597
Validation loss: 1.4342102068726734

Epoch: 6| Step: 7
Training loss: 0.08001065999269485
Validation loss: 1.4441183023555304

Epoch: 6| Step: 8
Training loss: 0.19820740818977356
Validation loss: 1.4531752409473542

Epoch: 6| Step: 9
Training loss: 0.09724847972393036
Validation loss: 1.4751802875149636

Epoch: 6| Step: 10
Training loss: 0.23212888836860657
Validation loss: 1.4746473040632022

Epoch: 6| Step: 11
Training loss: 0.16796189546585083
Validation loss: 1.5077550603497414

Epoch: 6| Step: 12
Training loss: 0.09034189581871033
Validation loss: 1.5376940722106605

Epoch: 6| Step: 13
Training loss: 0.1310768574476242
Validation loss: 1.5688991213357577

Epoch: 422| Step: 0
Training loss: 0.14822471141815186
Validation loss: 1.549903913210797

Epoch: 6| Step: 1
Training loss: 0.19765125215053558
Validation loss: 1.5446410935412171

Epoch: 6| Step: 2
Training loss: 0.1628054678440094
Validation loss: 1.518862098134974

Epoch: 6| Step: 3
Training loss: 0.1602252721786499
Validation loss: 1.5332617810977403

Epoch: 6| Step: 4
Training loss: 0.102413609623909
Validation loss: 1.5324616355280722

Epoch: 6| Step: 5
Training loss: 0.14924989640712738
Validation loss: 1.5488094668234549

Epoch: 6| Step: 6
Training loss: 0.06992729753255844
Validation loss: 1.5352889799302625

Epoch: 6| Step: 7
Training loss: 0.10750463604927063
Validation loss: 1.5480438227294593

Epoch: 6| Step: 8
Training loss: 0.12498985230922699
Validation loss: 1.5084382923700477

Epoch: 6| Step: 9
Training loss: 0.15412545204162598
Validation loss: 1.4839067177105976

Epoch: 6| Step: 10
Training loss: 0.13619542121887207
Validation loss: 1.466349470999933

Epoch: 6| Step: 11
Training loss: 0.2873668670654297
Validation loss: 1.437266061382909

Epoch: 6| Step: 12
Training loss: 0.09205681085586548
Validation loss: 1.397706922023527

Epoch: 6| Step: 13
Training loss: 0.07555392384529114
Validation loss: 1.3978898320146786

Epoch: 423| Step: 0
Training loss: 0.12268690764904022
Validation loss: 1.388476365356035

Epoch: 6| Step: 1
Training loss: 0.1666886806488037
Validation loss: 1.4081904311333933

Epoch: 6| Step: 2
Training loss: 0.07622182369232178
Validation loss: 1.4129266879891837

Epoch: 6| Step: 3
Training loss: 0.13505560159683228
Validation loss: 1.41341935178285

Epoch: 6| Step: 4
Training loss: 0.20225052535533905
Validation loss: 1.4326788382504576

Epoch: 6| Step: 5
Training loss: 0.11113288998603821
Validation loss: 1.4392024829823484

Epoch: 6| Step: 6
Training loss: 0.09539581835269928
Validation loss: 1.4300519689436881

Epoch: 6| Step: 7
Training loss: 0.2809336185455322
Validation loss: 1.4886569951170234

Epoch: 6| Step: 8
Training loss: 0.11329395323991776
Validation loss: 1.4806422482254684

Epoch: 6| Step: 9
Training loss: 0.1297731101512909
Validation loss: 1.5221992256820842

Epoch: 6| Step: 10
Training loss: 0.11233280599117279
Validation loss: 1.5104143824628604

Epoch: 6| Step: 11
Training loss: 0.09476587176322937
Validation loss: 1.5373292930664555

Epoch: 6| Step: 12
Training loss: 0.21754451096057892
Validation loss: 1.5240960486473576

Epoch: 6| Step: 13
Training loss: 0.20473966002464294
Validation loss: 1.5294684338313278

Epoch: 424| Step: 0
Training loss: 0.09040571004152298
Validation loss: 1.5294351308576521

Epoch: 6| Step: 1
Training loss: 0.11183930188417435
Validation loss: 1.4944246840733353

Epoch: 6| Step: 2
Training loss: 0.0728815495967865
Validation loss: 1.4997109367001442

Epoch: 6| Step: 3
Training loss: 0.08043643832206726
Validation loss: 1.502693792825104

Epoch: 6| Step: 4
Training loss: 0.12025812268257141
Validation loss: 1.4774646092486639

Epoch: 6| Step: 5
Training loss: 0.20796680450439453
Validation loss: 1.4563068061746576

Epoch: 6| Step: 6
Training loss: 0.06666997075080872
Validation loss: 1.4592390137334024

Epoch: 6| Step: 7
Training loss: 0.15304356813430786
Validation loss: 1.441566796712978

Epoch: 6| Step: 8
Training loss: 0.14054721593856812
Validation loss: 1.4663726719476844

Epoch: 6| Step: 9
Training loss: 0.29874253273010254
Validation loss: 1.4511062227269655

Epoch: 6| Step: 10
Training loss: 0.11945699155330658
Validation loss: 1.4598375328125492

Epoch: 6| Step: 11
Training loss: 0.13559946417808533
Validation loss: 1.4763905386770926

Epoch: 6| Step: 12
Training loss: 0.11324939876794815
Validation loss: 1.5082432672541628

Epoch: 6| Step: 13
Training loss: 0.12160273641347885
Validation loss: 1.521167314821674

Epoch: 425| Step: 0
Training loss: 0.12934523820877075
Validation loss: 1.5263891514911447

Epoch: 6| Step: 1
Training loss: 0.3367198705673218
Validation loss: 1.5163186647558724

Epoch: 6| Step: 2
Training loss: 0.1080692857503891
Validation loss: 1.5456980928297965

Epoch: 6| Step: 3
Training loss: 0.12069585919380188
Validation loss: 1.5023053000050206

Epoch: 6| Step: 4
Training loss: 0.15841113030910492
Validation loss: 1.5075477669315953

Epoch: 6| Step: 5
Training loss: 0.11397214233875275
Validation loss: 1.4785586364807621

Epoch: 6| Step: 6
Training loss: 0.11885392665863037
Validation loss: 1.4601066689337454

Epoch: 6| Step: 7
Training loss: 0.13823792338371277
Validation loss: 1.460456557171319

Epoch: 6| Step: 8
Training loss: 0.1145118921995163
Validation loss: 1.4683440231507825

Epoch: 6| Step: 9
Training loss: 0.10878054052591324
Validation loss: 1.4615056155830302

Epoch: 6| Step: 10
Training loss: 0.20718780159950256
Validation loss: 1.4629301025021462

Epoch: 6| Step: 11
Training loss: 0.0728878602385521
Validation loss: 1.4328280302786058

Epoch: 6| Step: 12
Training loss: 0.11796701699495316
Validation loss: 1.4471029825108026

Epoch: 6| Step: 13
Training loss: 0.07448194921016693
Validation loss: 1.4343092505649855

Epoch: 426| Step: 0
Training loss: 0.1560901254415512
Validation loss: 1.4238352788391935

Epoch: 6| Step: 1
Training loss: 0.13341835141181946
Validation loss: 1.4441030551028509

Epoch: 6| Step: 2
Training loss: 0.18247893452644348
Validation loss: 1.4400503020132742

Epoch: 6| Step: 3
Training loss: 0.18344277143478394
Validation loss: 1.4497511104870868

Epoch: 6| Step: 4
Training loss: 0.17614972591400146
Validation loss: 1.4243140310369513

Epoch: 6| Step: 5
Training loss: 0.14744409918785095
Validation loss: 1.4186984415977233

Epoch: 6| Step: 6
Training loss: 0.07412590086460114
Validation loss: 1.44785508032768

Epoch: 6| Step: 7
Training loss: 0.2456747144460678
Validation loss: 1.4535846825568908

Epoch: 6| Step: 8
Training loss: 0.12647467851638794
Validation loss: 1.4752499147128033

Epoch: 6| Step: 9
Training loss: 0.12173153460025787
Validation loss: 1.4589343788803264

Epoch: 6| Step: 10
Training loss: 0.14507678151130676
Validation loss: 1.440297503625193

Epoch: 6| Step: 11
Training loss: 0.12108191847801208
Validation loss: 1.455495253685982

Epoch: 6| Step: 12
Training loss: 0.13955970108509064
Validation loss: 1.4451378609544487

Epoch: 6| Step: 13
Training loss: 0.04038938134908676
Validation loss: 1.4591957035885061

Epoch: 427| Step: 0
Training loss: 0.1607891172170639
Validation loss: 1.4863245487213135

Epoch: 6| Step: 1
Training loss: 0.1276189088821411
Validation loss: 1.500009741834415

Epoch: 6| Step: 2
Training loss: 0.08045436441898346
Validation loss: 1.4819700833289855

Epoch: 6| Step: 3
Training loss: 0.23248738050460815
Validation loss: 1.510595865147088

Epoch: 6| Step: 4
Training loss: 0.12722092866897583
Validation loss: 1.4944577447829708

Epoch: 6| Step: 5
Training loss: 0.14632704854011536
Validation loss: 1.5034970000226011

Epoch: 6| Step: 6
Training loss: 0.1426539421081543
Validation loss: 1.4723499949260423

Epoch: 6| Step: 7
Training loss: 0.14201021194458008
Validation loss: 1.4559396774538103

Epoch: 6| Step: 8
Training loss: 0.1745297759771347
Validation loss: 1.43125569628131

Epoch: 6| Step: 9
Training loss: 0.1380537450313568
Validation loss: 1.4543634665909635

Epoch: 6| Step: 10
Training loss: 0.07081129401922226
Validation loss: 1.4795812137665287

Epoch: 6| Step: 11
Training loss: 0.07914513349533081
Validation loss: 1.468649261741228

Epoch: 6| Step: 12
Training loss: 0.11208143085241318
Validation loss: 1.4763759323345718

Epoch: 6| Step: 13
Training loss: 0.19495272636413574
Validation loss: 1.4474933173066826

Epoch: 428| Step: 0
Training loss: 0.07813604921102524
Validation loss: 1.4638126473273

Epoch: 6| Step: 1
Training loss: 0.11565278470516205
Validation loss: 1.4798350859713811

Epoch: 6| Step: 2
Training loss: 0.19179996848106384
Validation loss: 1.4961786398323633

Epoch: 6| Step: 3
Training loss: 0.07921092212200165
Validation loss: 1.4974169000502555

Epoch: 6| Step: 4
Training loss: 0.13571591675281525
Validation loss: 1.4702575815621244

Epoch: 6| Step: 5
Training loss: 0.14195013046264648
Validation loss: 1.4602089607587425

Epoch: 6| Step: 6
Training loss: 0.11660648882389069
Validation loss: 1.4683200236289733

Epoch: 6| Step: 7
Training loss: 0.2399691343307495
Validation loss: 1.4712395309120097

Epoch: 6| Step: 8
Training loss: 0.14944447576999664
Validation loss: 1.465645670890808

Epoch: 6| Step: 9
Training loss: 0.0934104472398758
Validation loss: 1.4840501495586929

Epoch: 6| Step: 10
Training loss: 0.1263633668422699
Validation loss: 1.477197773994938

Epoch: 6| Step: 11
Training loss: 0.12859375774860382
Validation loss: 1.4689592546032322

Epoch: 6| Step: 12
Training loss: 0.2123228907585144
Validation loss: 1.4597244929241877

Epoch: 6| Step: 13
Training loss: 0.11445796489715576
Validation loss: 1.4366212480811662

Epoch: 429| Step: 0
Training loss: 0.2252008318901062
Validation loss: 1.4642769828919442

Epoch: 6| Step: 1
Training loss: 0.18887703120708466
Validation loss: 1.4643050124568324

Epoch: 6| Step: 2
Training loss: 0.06496047973632812
Validation loss: 1.478316976178077

Epoch: 6| Step: 3
Training loss: 0.10007607191801071
Validation loss: 1.4576254237082698

Epoch: 6| Step: 4
Training loss: 0.2191002070903778
Validation loss: 1.483139463650283

Epoch: 6| Step: 5
Training loss: 0.14532867074012756
Validation loss: 1.4821942506297943

Epoch: 6| Step: 6
Training loss: 0.1713721603155136
Validation loss: 1.4706713948198544

Epoch: 6| Step: 7
Training loss: 0.12957921624183655
Validation loss: 1.4905355092017882

Epoch: 6| Step: 8
Training loss: 0.19819946587085724
Validation loss: 1.4780764861773419

Epoch: 6| Step: 9
Training loss: 0.1981002241373062
Validation loss: 1.4563324348900908

Epoch: 6| Step: 10
Training loss: 0.1128450259566307
Validation loss: 1.4590439078628377

Epoch: 6| Step: 11
Training loss: 0.12707269191741943
Validation loss: 1.4570608382583947

Epoch: 6| Step: 12
Training loss: 0.09402411431074142
Validation loss: 1.4397692206085368

Epoch: 6| Step: 13
Training loss: 0.1563378870487213
Validation loss: 1.4740202362819383

Epoch: 430| Step: 0
Training loss: 0.15451329946517944
Validation loss: 1.4659907574294715

Epoch: 6| Step: 1
Training loss: 0.2999535799026489
Validation loss: 1.4905750969404816

Epoch: 6| Step: 2
Training loss: 0.11945343017578125
Validation loss: 1.49610984581773

Epoch: 6| Step: 3
Training loss: 0.10389885306358337
Validation loss: 1.4646816304934922

Epoch: 6| Step: 4
Training loss: 0.08421196788549423
Validation loss: 1.4655587211731942

Epoch: 6| Step: 5
Training loss: 0.14346060156822205
Validation loss: 1.4615601788284958

Epoch: 6| Step: 6
Training loss: 0.11560886353254318
Validation loss: 1.49263515780049

Epoch: 6| Step: 7
Training loss: 0.075370192527771
Validation loss: 1.5022860778275358

Epoch: 6| Step: 8
Training loss: 0.08102014660835266
Validation loss: 1.524816354115804

Epoch: 6| Step: 9
Training loss: 0.14954736828804016
Validation loss: 1.5434506913667083

Epoch: 6| Step: 10
Training loss: 0.1692531257867813
Validation loss: 1.548047789963343

Epoch: 6| Step: 11
Training loss: 0.11818427592515945
Validation loss: 1.5205938175160398

Epoch: 6| Step: 12
Training loss: 0.24475479125976562
Validation loss: 1.5221420475231704

Epoch: 6| Step: 13
Training loss: 0.16593869030475616
Validation loss: 1.5130485450067828

Epoch: 431| Step: 0
Training loss: 0.12240147590637207
Validation loss: 1.4661866150876528

Epoch: 6| Step: 1
Training loss: 0.11747284233570099
Validation loss: 1.4515995671672206

Epoch: 6| Step: 2
Training loss: 0.09802217781543732
Validation loss: 1.4538636720308693

Epoch: 6| Step: 3
Training loss: 0.1579694151878357
Validation loss: 1.4509695063355148

Epoch: 6| Step: 4
Training loss: 0.1462131142616272
Validation loss: 1.4520831120911466

Epoch: 6| Step: 5
Training loss: 0.16228604316711426
Validation loss: 1.4569357569499681

Epoch: 6| Step: 6
Training loss: 0.10974659025669098
Validation loss: 1.468258487280979

Epoch: 6| Step: 7
Training loss: 0.29018503427505493
Validation loss: 1.4852832350679623

Epoch: 6| Step: 8
Training loss: 0.10010197758674622
Validation loss: 1.4794243381869407

Epoch: 6| Step: 9
Training loss: 0.17043311893939972
Validation loss: 1.4994866565991474

Epoch: 6| Step: 10
Training loss: 0.1703442633152008
Validation loss: 1.4977580488369029

Epoch: 6| Step: 11
Training loss: 0.17225651443004608
Validation loss: 1.5348938921446442

Epoch: 6| Step: 12
Training loss: 0.16006913781166077
Validation loss: 1.5475445780702817

Epoch: 6| Step: 13
Training loss: 0.10290413349866867
Validation loss: 1.5956718216660202

Epoch: 432| Step: 0
Training loss: 0.18505355715751648
Validation loss: 1.5708606884043703

Epoch: 6| Step: 1
Training loss: 0.0984625369310379
Validation loss: 1.5282329910544938

Epoch: 6| Step: 2
Training loss: 0.15673576295375824
Validation loss: 1.4969154314328266

Epoch: 6| Step: 3
Training loss: 0.09579895436763763
Validation loss: 1.475929649927283

Epoch: 6| Step: 4
Training loss: 0.2779375910758972
Validation loss: 1.4561485628927908

Epoch: 6| Step: 5
Training loss: 0.10592849552631378
Validation loss: 1.47714925260954

Epoch: 6| Step: 6
Training loss: 0.14441701769828796
Validation loss: 1.4408821046993296

Epoch: 6| Step: 7
Training loss: 0.25950419902801514
Validation loss: 1.4330960967207467

Epoch: 6| Step: 8
Training loss: 0.08770938217639923
Validation loss: 1.42921321622787

Epoch: 6| Step: 9
Training loss: 0.12896397709846497
Validation loss: 1.4243682366545483

Epoch: 6| Step: 10
Training loss: 0.07237648218870163
Validation loss: 1.4123396117200133

Epoch: 6| Step: 11
Training loss: 0.12194112688302994
Validation loss: 1.4157704666096678

Epoch: 6| Step: 12
Training loss: 0.13769088685512543
Validation loss: 1.4401965295114825

Epoch: 6| Step: 13
Training loss: 0.16232550144195557
Validation loss: 1.4353836351825344

Epoch: 433| Step: 0
Training loss: 0.08179797977209091
Validation loss: 1.4666298422762143

Epoch: 6| Step: 1
Training loss: 0.0948898047208786
Validation loss: 1.4516069568613523

Epoch: 6| Step: 2
Training loss: 0.15380698442459106
Validation loss: 1.4555681905438822

Epoch: 6| Step: 3
Training loss: 0.11677710711956024
Validation loss: 1.4752174820951236

Epoch: 6| Step: 4
Training loss: 0.26672324538230896
Validation loss: 1.4812809382715533

Epoch: 6| Step: 5
Training loss: 0.08630619943141937
Validation loss: 1.5029942758621708

Epoch: 6| Step: 6
Training loss: 0.12627361714839935
Validation loss: 1.5049638978896602

Epoch: 6| Step: 7
Training loss: 0.12297345697879791
Validation loss: 1.512857433288328

Epoch: 6| Step: 8
Training loss: 0.14941133558750153
Validation loss: 1.522699567579454

Epoch: 6| Step: 9
Training loss: 0.10449111461639404
Validation loss: 1.4885084539331415

Epoch: 6| Step: 10
Training loss: 0.19134855270385742
Validation loss: 1.514474532937491

Epoch: 6| Step: 11
Training loss: 0.119273342192173
Validation loss: 1.4989728760975662

Epoch: 6| Step: 12
Training loss: 0.16355957090854645
Validation loss: 1.468527236292439

Epoch: 6| Step: 13
Training loss: 0.0989910364151001
Validation loss: 1.4855209691550142

Epoch: 434| Step: 0
Training loss: 0.19466295838356018
Validation loss: 1.4495277949558791

Epoch: 6| Step: 1
Training loss: 0.08695270866155624
Validation loss: 1.4650355436468636

Epoch: 6| Step: 2
Training loss: 0.0509427972137928
Validation loss: 1.4910179235601937

Epoch: 6| Step: 3
Training loss: 0.11913751065731049
Validation loss: 1.5039140306493288

Epoch: 6| Step: 4
Training loss: 0.30684536695480347
Validation loss: 1.5031482904188094

Epoch: 6| Step: 5
Training loss: 0.14923931658267975
Validation loss: 1.5082648043991418

Epoch: 6| Step: 6
Training loss: 0.1121697947382927
Validation loss: 1.505913535753886

Epoch: 6| Step: 7
Training loss: 0.1267538070678711
Validation loss: 1.4973016900400962

Epoch: 6| Step: 8
Training loss: 0.18948298692703247
Validation loss: 1.545333029121481

Epoch: 6| Step: 9
Training loss: 0.22764238715171814
Validation loss: 1.5472999413808186

Epoch: 6| Step: 10
Training loss: 0.23177704215049744
Validation loss: 1.5632057625760314

Epoch: 6| Step: 11
Training loss: 0.1406172215938568
Validation loss: 1.5098512787972727

Epoch: 6| Step: 12
Training loss: 0.16585609316825867
Validation loss: 1.4816213794933852

Epoch: 6| Step: 13
Training loss: 0.12872038781642914
Validation loss: 1.4415932188751877

Epoch: 435| Step: 0
Training loss: 0.33436352014541626
Validation loss: 1.4167395202062463

Epoch: 6| Step: 1
Training loss: 0.22196441888809204
Validation loss: 1.4033075481332757

Epoch: 6| Step: 2
Training loss: 0.24538613855838776
Validation loss: 1.3748000257758684

Epoch: 6| Step: 3
Training loss: 0.2562248110771179
Validation loss: 1.428008621738803

Epoch: 6| Step: 4
Training loss: 0.11780665069818497
Validation loss: 1.4024465096894132

Epoch: 6| Step: 5
Training loss: 0.17190657556056976
Validation loss: 1.4409804395450059

Epoch: 6| Step: 6
Training loss: 0.2165772020816803
Validation loss: 1.4563527446921154

Epoch: 6| Step: 7
Training loss: 0.15694186091423035
Validation loss: 1.4700024486869894

Epoch: 6| Step: 8
Training loss: 0.16669781506061554
Validation loss: 1.4835322864593998

Epoch: 6| Step: 9
Training loss: 0.13472045958042145
Validation loss: 1.520092228407501

Epoch: 6| Step: 10
Training loss: 0.12172131985425949
Validation loss: 1.5311486400583738

Epoch: 6| Step: 11
Training loss: 0.0936025083065033
Validation loss: 1.578518021491266

Epoch: 6| Step: 12
Training loss: 0.1349751055240631
Validation loss: 1.628263714492962

Epoch: 6| Step: 13
Training loss: 0.2377339005470276
Validation loss: 1.6159055002274052

Epoch: 436| Step: 0
Training loss: 0.20660653710365295
Validation loss: 1.6180870840626378

Epoch: 6| Step: 1
Training loss: 0.22532066702842712
Validation loss: 1.5867022378470308

Epoch: 6| Step: 2
Training loss: 0.15934757888317108
Validation loss: 1.5735122234590593

Epoch: 6| Step: 3
Training loss: 0.07312597334384918
Validation loss: 1.532520914590487

Epoch: 6| Step: 4
Training loss: 0.0869668573141098
Validation loss: 1.5359108723619932

Epoch: 6| Step: 5
Training loss: 0.11776740849018097
Validation loss: 1.5188932957187775

Epoch: 6| Step: 6
Training loss: 0.1909528225660324
Validation loss: 1.5136174181456208

Epoch: 6| Step: 7
Training loss: 0.11551500856876373
Validation loss: 1.4862635968833842

Epoch: 6| Step: 8
Training loss: 0.15211178362369537
Validation loss: 1.4623860928320116

Epoch: 6| Step: 9
Training loss: 0.30957695841789246
Validation loss: 1.4644107754512499

Epoch: 6| Step: 10
Training loss: 0.21870841085910797
Validation loss: 1.45500728776378

Epoch: 6| Step: 11
Training loss: 0.14965569972991943
Validation loss: 1.4697819999469224

Epoch: 6| Step: 12
Training loss: 0.1051136702299118
Validation loss: 1.4679080811879968

Epoch: 6| Step: 13
Training loss: 0.13220930099487305
Validation loss: 1.4683959368736512

Epoch: 437| Step: 0
Training loss: 0.14706958830356598
Validation loss: 1.4900349942586755

Epoch: 6| Step: 1
Training loss: 0.06981848180294037
Validation loss: 1.4852231978088297

Epoch: 6| Step: 2
Training loss: 0.08300240337848663
Validation loss: 1.5040722021492579

Epoch: 6| Step: 3
Training loss: 0.19968746602535248
Validation loss: 1.558082038997322

Epoch: 6| Step: 4
Training loss: 0.11152765154838562
Validation loss: 1.5626850384537891

Epoch: 6| Step: 5
Training loss: 0.21122696995735168
Validation loss: 1.552938283771597

Epoch: 6| Step: 6
Training loss: 0.17689485847949982
Validation loss: 1.5786733960592618

Epoch: 6| Step: 7
Training loss: 0.1649756133556366
Validation loss: 1.5307281504395187

Epoch: 6| Step: 8
Training loss: 0.1420644223690033
Validation loss: 1.573111568727801

Epoch: 6| Step: 9
Training loss: 0.207045316696167
Validation loss: 1.5335891964615032

Epoch: 6| Step: 10
Training loss: 0.3050623834133148
Validation loss: 1.5180931091308594

Epoch: 6| Step: 11
Training loss: 0.0891602486371994
Validation loss: 1.511602868315994

Epoch: 6| Step: 12
Training loss: 0.1155632883310318
Validation loss: 1.505889340113568

Epoch: 6| Step: 13
Training loss: 0.10085606575012207
Validation loss: 1.487016047200849

Epoch: 438| Step: 0
Training loss: 0.16126368939876556
Validation loss: 1.498771693116875

Epoch: 6| Step: 1
Training loss: 0.11570236086845398
Validation loss: 1.49483932218244

Epoch: 6| Step: 2
Training loss: 0.15087899565696716
Validation loss: 1.4810939642690844

Epoch: 6| Step: 3
Training loss: 0.13815093040466309
Validation loss: 1.5041449589114035

Epoch: 6| Step: 4
Training loss: 0.32624930143356323
Validation loss: 1.5265899371075373

Epoch: 6| Step: 5
Training loss: 0.1398007869720459
Validation loss: 1.5302707200409265

Epoch: 6| Step: 6
Training loss: 0.07248315215110779
Validation loss: 1.5305752113301268

Epoch: 6| Step: 7
Training loss: 0.08557161688804626
Validation loss: 1.554010880890713

Epoch: 6| Step: 8
Training loss: 0.1692800223827362
Validation loss: 1.5685941352639148

Epoch: 6| Step: 9
Training loss: 0.16722655296325684
Validation loss: 1.5606920719146729

Epoch: 6| Step: 10
Training loss: 0.17322425544261932
Validation loss: 1.585448561176177

Epoch: 6| Step: 11
Training loss: 0.1418064534664154
Validation loss: 1.5796729390339186

Epoch: 6| Step: 12
Training loss: 0.1295570284128189
Validation loss: 1.5569743648652108

Epoch: 6| Step: 13
Training loss: 0.2124989628791809
Validation loss: 1.5304876578751432

Epoch: 439| Step: 0
Training loss: 0.0639336109161377
Validation loss: 1.5054183019104825

Epoch: 6| Step: 1
Training loss: 0.1372082382440567
Validation loss: 1.504427412504791

Epoch: 6| Step: 2
Training loss: 0.08370187878608704
Validation loss: 1.508243122408467

Epoch: 6| Step: 3
Training loss: 0.12144795060157776
Validation loss: 1.4928847794891686

Epoch: 6| Step: 4
Training loss: 0.20123548805713654
Validation loss: 1.4815052401634954

Epoch: 6| Step: 5
Training loss: 0.14296525716781616
Validation loss: 1.4591221335113689

Epoch: 6| Step: 6
Training loss: 0.12392525374889374
Validation loss: 1.4689446918426021

Epoch: 6| Step: 7
Training loss: 0.10626064240932465
Validation loss: 1.4650264222134826

Epoch: 6| Step: 8
Training loss: 0.1362244039773941
Validation loss: 1.4698490711950487

Epoch: 6| Step: 9
Training loss: 0.1504027545452118
Validation loss: 1.4853225279879827

Epoch: 6| Step: 10
Training loss: 0.2647643983364105
Validation loss: 1.4983085047814153

Epoch: 6| Step: 11
Training loss: 0.1182088851928711
Validation loss: 1.4996072143636725

Epoch: 6| Step: 12
Training loss: 0.14137263596057892
Validation loss: 1.5278247325651106

Epoch: 6| Step: 13
Training loss: 0.1920597106218338
Validation loss: 1.5006439685821533

Epoch: 440| Step: 0
Training loss: 0.08624973893165588
Validation loss: 1.5002868354961436

Epoch: 6| Step: 1
Training loss: 0.052624449133872986
Validation loss: 1.4800840744408228

Epoch: 6| Step: 2
Training loss: 0.1697838455438614
Validation loss: 1.4783484249986627

Epoch: 6| Step: 3
Training loss: 0.12834709882736206
Validation loss: 1.4570438144027547

Epoch: 6| Step: 4
Training loss: 0.08440934121608734
Validation loss: 1.4613188633354761

Epoch: 6| Step: 5
Training loss: 0.21904540061950684
Validation loss: 1.4631671213334607

Epoch: 6| Step: 6
Training loss: 0.12659919261932373
Validation loss: 1.4608374616151214

Epoch: 6| Step: 7
Training loss: 0.14597925543785095
Validation loss: 1.4782074100227767

Epoch: 6| Step: 8
Training loss: 0.17343655228614807
Validation loss: 1.464857412922767

Epoch: 6| Step: 9
Training loss: 0.15055468678474426
Validation loss: 1.465799380374211

Epoch: 6| Step: 10
Training loss: 0.0861746072769165
Validation loss: 1.4886749265014485

Epoch: 6| Step: 11
Training loss: 0.10779570043087006
Validation loss: 1.4828194450306635

Epoch: 6| Step: 12
Training loss: 0.07659769058227539
Validation loss: 1.4253937480270222

Epoch: 6| Step: 13
Training loss: 0.14771315455436707
Validation loss: 1.4816899094530331

Epoch: 441| Step: 0
Training loss: 0.11821586638689041
Validation loss: 1.4739007565283007

Epoch: 6| Step: 1
Training loss: 0.2105637788772583
Validation loss: 1.4657806234975015

Epoch: 6| Step: 2
Training loss: 0.10905353724956512
Validation loss: 1.501941825753899

Epoch: 6| Step: 3
Training loss: 0.14114230871200562
Validation loss: 1.4886238831345753

Epoch: 6| Step: 4
Training loss: 0.06357723474502563
Validation loss: 1.4927566461665656

Epoch: 6| Step: 5
Training loss: 0.0941663384437561
Validation loss: 1.498384234725788

Epoch: 6| Step: 6
Training loss: 0.10372821986675262
Validation loss: 1.5125966828356507

Epoch: 6| Step: 7
Training loss: 0.11651643365621567
Validation loss: 1.517459709157226

Epoch: 6| Step: 8
Training loss: 0.14085406064987183
Validation loss: 1.5034356399249005

Epoch: 6| Step: 9
Training loss: 0.1457979381084442
Validation loss: 1.4953518067636797

Epoch: 6| Step: 10
Training loss: 0.10736509412527084
Validation loss: 1.490805579769996

Epoch: 6| Step: 11
Training loss: 0.06693494319915771
Validation loss: 1.48319971945978

Epoch: 6| Step: 12
Training loss: 0.1281244456768036
Validation loss: 1.4852477094178558

Epoch: 6| Step: 13
Training loss: 0.03690585866570473
Validation loss: 1.4886316330202165

Epoch: 442| Step: 0
Training loss: 0.18571051955223083
Validation loss: 1.4865724848162742

Epoch: 6| Step: 1
Training loss: 0.08683481812477112
Validation loss: 1.461046846964026

Epoch: 6| Step: 2
Training loss: 0.1530046910047531
Validation loss: 1.4873827644573745

Epoch: 6| Step: 3
Training loss: 0.16710922122001648
Validation loss: 1.4577002102328884

Epoch: 6| Step: 4
Training loss: 0.12770229578018188
Validation loss: 1.4795558337242372

Epoch: 6| Step: 5
Training loss: 0.08680383116006851
Validation loss: 1.4791661936749694

Epoch: 6| Step: 6
Training loss: 0.11396737396717072
Validation loss: 1.4753443412883307

Epoch: 6| Step: 7
Training loss: 0.10981235653162003
Validation loss: 1.479839797942869

Epoch: 6| Step: 8
Training loss: 0.09603038430213928
Validation loss: 1.4962522329822663

Epoch: 6| Step: 9
Training loss: 0.19057609140872955
Validation loss: 1.5218904723403275

Epoch: 6| Step: 10
Training loss: 0.0935056060552597
Validation loss: 1.495785823432348

Epoch: 6| Step: 11
Training loss: 0.1371164619922638
Validation loss: 1.5034964238443682

Epoch: 6| Step: 12
Training loss: 0.08854006230831146
Validation loss: 1.5006726403390207

Epoch: 6| Step: 13
Training loss: 0.11827949434518814
Validation loss: 1.503853036511329

Epoch: 443| Step: 0
Training loss: 0.10838804394006729
Validation loss: 1.5157031346392889

Epoch: 6| Step: 1
Training loss: 0.048980481922626495
Validation loss: 1.5139336778271584

Epoch: 6| Step: 2
Training loss: 0.11546541750431061
Validation loss: 1.5315290702286588

Epoch: 6| Step: 3
Training loss: 0.22550824284553528
Validation loss: 1.5823404019878757

Epoch: 6| Step: 4
Training loss: 0.21739798784255981
Validation loss: 1.5383522151618876

Epoch: 6| Step: 5
Training loss: 0.16132701933383942
Validation loss: 1.507279654984833

Epoch: 6| Step: 6
Training loss: 0.2319687157869339
Validation loss: 1.5332019482889483

Epoch: 6| Step: 7
Training loss: 0.11777223646640778
Validation loss: 1.4929824811156078

Epoch: 6| Step: 8
Training loss: 0.1625864952802658
Validation loss: 1.4919059571399484

Epoch: 6| Step: 9
Training loss: 0.15513134002685547
Validation loss: 1.5118110051719091

Epoch: 6| Step: 10
Training loss: 0.23583601415157318
Validation loss: 1.4963292441060465

Epoch: 6| Step: 11
Training loss: 0.11801723390817642
Validation loss: 1.475234334186841

Epoch: 6| Step: 12
Training loss: 0.09720449149608612
Validation loss: 1.492302030645391

Epoch: 6| Step: 13
Training loss: 0.07684031873941422
Validation loss: 1.5035074667264057

Epoch: 444| Step: 0
Training loss: 0.09088895469903946
Validation loss: 1.5485691639684862

Epoch: 6| Step: 1
Training loss: 0.18858702480793
Validation loss: 1.5237312983441096

Epoch: 6| Step: 2
Training loss: 0.13028845191001892
Validation loss: 1.5233813037154496

Epoch: 6| Step: 3
Training loss: 0.10264486074447632
Validation loss: 1.5610999881580312

Epoch: 6| Step: 4
Training loss: 0.15933988988399506
Validation loss: 1.5103098154067993

Epoch: 6| Step: 5
Training loss: 0.049667537212371826
Validation loss: 1.5062663247508388

Epoch: 6| Step: 6
Training loss: 0.09915143996477127
Validation loss: 1.518026194264812

Epoch: 6| Step: 7
Training loss: 0.08097293972969055
Validation loss: 1.5161860642894622

Epoch: 6| Step: 8
Training loss: 0.23743797838687897
Validation loss: 1.5231909700619277

Epoch: 6| Step: 9
Training loss: 0.10317479074001312
Validation loss: 1.5067128686494724

Epoch: 6| Step: 10
Training loss: 0.15149250626564026
Validation loss: 1.502867232086838

Epoch: 6| Step: 11
Training loss: 0.23229990899562836
Validation loss: 1.4930774396465671

Epoch: 6| Step: 12
Training loss: 0.1203446313738823
Validation loss: 1.4763854005003487

Epoch: 6| Step: 13
Training loss: 0.1527022421360016
Validation loss: 1.447584830945538

Epoch: 445| Step: 0
Training loss: 0.06153080612421036
Validation loss: 1.4438676629015195

Epoch: 6| Step: 1
Training loss: 0.08308541774749756
Validation loss: 1.4674604656875774

Epoch: 6| Step: 2
Training loss: 0.1949825882911682
Validation loss: 1.4578396222924674

Epoch: 6| Step: 3
Training loss: 0.11462418735027313
Validation loss: 1.469986117014321

Epoch: 6| Step: 4
Training loss: 0.11851634085178375
Validation loss: 1.4776168895024124

Epoch: 6| Step: 5
Training loss: 0.1352953314781189
Validation loss: 1.4690574048667826

Epoch: 6| Step: 6
Training loss: 0.211153045296669
Validation loss: 1.4772865259519188

Epoch: 6| Step: 7
Training loss: 0.10413657128810883
Validation loss: 1.495833573802825

Epoch: 6| Step: 8
Training loss: 0.15126125514507294
Validation loss: 1.5127621671204925

Epoch: 6| Step: 9
Training loss: 0.15208007395267487
Validation loss: 1.4821827591106456

Epoch: 6| Step: 10
Training loss: 0.15188735723495483
Validation loss: 1.5142766685896023

Epoch: 6| Step: 11
Training loss: 0.10284028202295303
Validation loss: 1.4943908055623372

Epoch: 6| Step: 12
Training loss: 0.10042238235473633
Validation loss: 1.4369060313829811

Epoch: 6| Step: 13
Training loss: 0.16394869983196259
Validation loss: 1.4390609520737843

Epoch: 446| Step: 0
Training loss: 0.09393244236707687
Validation loss: 1.437469074803014

Epoch: 6| Step: 1
Training loss: 0.21425366401672363
Validation loss: 1.4209647742650842

Epoch: 6| Step: 2
Training loss: 0.1035521924495697
Validation loss: 1.407610075448149

Epoch: 6| Step: 3
Training loss: 0.18430233001708984
Validation loss: 1.3962863119699622

Epoch: 6| Step: 4
Training loss: 0.13459175825119019
Validation loss: 1.4052655517414052

Epoch: 6| Step: 5
Training loss: 0.11272105574607849
Validation loss: 1.4371614943268478

Epoch: 6| Step: 6
Training loss: 0.128638356924057
Validation loss: 1.4430147447893698

Epoch: 6| Step: 7
Training loss: 0.08074496686458588
Validation loss: 1.4425912255881934

Epoch: 6| Step: 8
Training loss: 0.0746418908238411
Validation loss: 1.4645646599031263

Epoch: 6| Step: 9
Training loss: 0.08670692145824432
Validation loss: 1.483266802244289

Epoch: 6| Step: 10
Training loss: 0.14818042516708374
Validation loss: 1.4802181515642392

Epoch: 6| Step: 11
Training loss: 0.17427870631217957
Validation loss: 1.49610185879533

Epoch: 6| Step: 12
Training loss: 0.16757898032665253
Validation loss: 1.5047564134802869

Epoch: 6| Step: 13
Training loss: 0.11324843764305115
Validation loss: 1.5398331457568752

Epoch: 447| Step: 0
Training loss: 0.2158510982990265
Validation loss: 1.529976664050933

Epoch: 6| Step: 1
Training loss: 0.1487608253955841
Validation loss: 1.5834710572355537

Epoch: 6| Step: 2
Training loss: 0.1703616976737976
Validation loss: 1.5618025449014479

Epoch: 6| Step: 3
Training loss: 0.2533406615257263
Validation loss: 1.5610802583797003

Epoch: 6| Step: 4
Training loss: 0.15527531504631042
Validation loss: 1.5474664690673992

Epoch: 6| Step: 5
Training loss: 0.14152738451957703
Validation loss: 1.5263456490732008

Epoch: 6| Step: 6
Training loss: 0.20315107703208923
Validation loss: 1.488352144918134

Epoch: 6| Step: 7
Training loss: 0.21230584383010864
Validation loss: 1.4717027320656726

Epoch: 6| Step: 8
Training loss: 0.11911569535732269
Validation loss: 1.4471251195476902

Epoch: 6| Step: 9
Training loss: 0.1465110182762146
Validation loss: 1.4217872491446875

Epoch: 6| Step: 10
Training loss: 0.1227433979511261
Validation loss: 1.4226004769725185

Epoch: 6| Step: 11
Training loss: 0.07741688936948776
Validation loss: 1.4179268255028674

Epoch: 6| Step: 12
Training loss: 0.15934619307518005
Validation loss: 1.4381177912476242

Epoch: 6| Step: 13
Training loss: 0.16739170253276825
Validation loss: 1.4491688038713189

Epoch: 448| Step: 0
Training loss: 0.11599046736955643
Validation loss: 1.4742844989222865

Epoch: 6| Step: 1
Training loss: 0.1889079064130783
Validation loss: 1.4862915021117016

Epoch: 6| Step: 2
Training loss: 0.21146395802497864
Validation loss: 1.5057706909794961

Epoch: 6| Step: 3
Training loss: 0.14890903234481812
Validation loss: 1.5250662578049528

Epoch: 6| Step: 4
Training loss: 0.11710929870605469
Validation loss: 1.5164666611661193

Epoch: 6| Step: 5
Training loss: 0.1450202763080597
Validation loss: 1.5328219090738604

Epoch: 6| Step: 6
Training loss: 0.2739343047142029
Validation loss: 1.5289633043350712

Epoch: 6| Step: 7
Training loss: 0.16901463270187378
Validation loss: 1.5086231347053283

Epoch: 6| Step: 8
Training loss: 0.17393890023231506
Validation loss: 1.5070382343825472

Epoch: 6| Step: 9
Training loss: 0.19041752815246582
Validation loss: 1.4646578360629339

Epoch: 6| Step: 10
Training loss: 0.13458256423473358
Validation loss: 1.4796402441558016

Epoch: 6| Step: 11
Training loss: 0.06904162466526031
Validation loss: 1.454104805505404

Epoch: 6| Step: 12
Training loss: 0.21649546921253204
Validation loss: 1.474219661886974

Epoch: 6| Step: 13
Training loss: 0.124088354408741
Validation loss: 1.4986258270919963

Epoch: 449| Step: 0
Training loss: 0.1210169568657875
Validation loss: 1.4750123229078067

Epoch: 6| Step: 1
Training loss: 0.20457392930984497
Validation loss: 1.5278005138520272

Epoch: 6| Step: 2
Training loss: 0.15966391563415527
Validation loss: 1.4973673038585211

Epoch: 6| Step: 3
Training loss: 0.1253325492143631
Validation loss: 1.470980069970572

Epoch: 6| Step: 4
Training loss: 0.1448322832584381
Validation loss: 1.4744498281068699

Epoch: 6| Step: 5
Training loss: 0.09572191536426544
Validation loss: 1.4667330339390745

Epoch: 6| Step: 6
Training loss: 0.11913888901472092
Validation loss: 1.4816619132154731

Epoch: 6| Step: 7
Training loss: 0.1432877480983734
Validation loss: 1.4795466520453011

Epoch: 6| Step: 8
Training loss: 0.15769906342029572
Validation loss: 1.4776678187872774

Epoch: 6| Step: 9
Training loss: 0.07929406315088272
Validation loss: 1.4791672050312001

Epoch: 6| Step: 10
Training loss: 0.3490893840789795
Validation loss: 1.496044780618401

Epoch: 6| Step: 11
Training loss: 0.1258610486984253
Validation loss: 1.5185041158430037

Epoch: 6| Step: 12
Training loss: 0.18657904863357544
Validation loss: 1.520514395929152

Epoch: 6| Step: 13
Training loss: 0.25986549258232117
Validation loss: 1.5462554539403608

Epoch: 450| Step: 0
Training loss: 0.17912952601909637
Validation loss: 1.5408486371399255

Epoch: 6| Step: 1
Training loss: 0.23770248889923096
Validation loss: 1.518308816417571

Epoch: 6| Step: 2
Training loss: 0.12188678979873657
Validation loss: 1.4602695011323499

Epoch: 6| Step: 3
Training loss: 0.10894569754600525
Validation loss: 1.4383695420398508

Epoch: 6| Step: 4
Training loss: 0.18499769270420074
Validation loss: 1.4100637884550198

Epoch: 6| Step: 5
Training loss: 0.1536029577255249
Validation loss: 1.4334274607319986

Epoch: 6| Step: 6
Training loss: 0.1785963773727417
Validation loss: 1.4088959501635643

Epoch: 6| Step: 7
Training loss: 0.16790984570980072
Validation loss: 1.4227484195463118

Epoch: 6| Step: 8
Training loss: 0.14519798755645752
Validation loss: 1.4274823870710147

Epoch: 6| Step: 9
Training loss: 0.15371540188789368
Validation loss: 1.4487039235330397

Epoch: 6| Step: 10
Training loss: 0.1720939576625824
Validation loss: 1.471948374984085

Epoch: 6| Step: 11
Training loss: 0.11923569440841675
Validation loss: 1.491419602465886

Epoch: 6| Step: 12
Training loss: 0.12334498763084412
Validation loss: 1.504419953592362

Epoch: 6| Step: 13
Training loss: 0.1055036261677742
Validation loss: 1.4907854910819762

Epoch: 451| Step: 0
Training loss: 0.10150933265686035
Validation loss: 1.4720144335941603

Epoch: 6| Step: 1
Training loss: 0.1255960315465927
Validation loss: 1.4581127615385159

Epoch: 6| Step: 2
Training loss: 0.09730792045593262
Validation loss: 1.4814241432374524

Epoch: 6| Step: 3
Training loss: 0.1014227569103241
Validation loss: 1.4660464441904457

Epoch: 6| Step: 4
Training loss: 0.08213860541582108
Validation loss: 1.459396182849843

Epoch: 6| Step: 5
Training loss: 0.05215265974402428
Validation loss: 1.4712274741101008

Epoch: 6| Step: 6
Training loss: 0.20343433320522308
Validation loss: 1.4931459529425508

Epoch: 6| Step: 7
Training loss: 0.12184882164001465
Validation loss: 1.5312169456994662

Epoch: 6| Step: 8
Training loss: 0.0823078379034996
Validation loss: 1.5107620236694173

Epoch: 6| Step: 9
Training loss: 0.1150784119963646
Validation loss: 1.5027319846614715

Epoch: 6| Step: 10
Training loss: 0.2826603055000305
Validation loss: 1.4884313460319274

Epoch: 6| Step: 11
Training loss: 0.11128230392932892
Validation loss: 1.4958105574371994

Epoch: 6| Step: 12
Training loss: 0.11781822144985199
Validation loss: 1.483683737375403

Epoch: 6| Step: 13
Training loss: 0.1870308220386505
Validation loss: 1.479726073562458

Epoch: 452| Step: 0
Training loss: 0.12284540385007858
Validation loss: 1.4672592570704799

Epoch: 6| Step: 1
Training loss: 0.17199519276618958
Validation loss: 1.4828417865178918

Epoch: 6| Step: 2
Training loss: 0.12547831237316132
Validation loss: 1.4483880330157537

Epoch: 6| Step: 3
Training loss: 0.1913786679506302
Validation loss: 1.4824360929509646

Epoch: 6| Step: 4
Training loss: 0.17717401683330536
Validation loss: 1.480363820188789

Epoch: 6| Step: 5
Training loss: 0.27851682901382446
Validation loss: 1.469118110595211

Epoch: 6| Step: 6
Training loss: 0.2236476093530655
Validation loss: 1.4606950385596162

Epoch: 6| Step: 7
Training loss: 0.10628031939268112
Validation loss: 1.4508359829584758

Epoch: 6| Step: 8
Training loss: 0.09712396562099457
Validation loss: 1.4467290793695757

Epoch: 6| Step: 9
Training loss: 0.11756402254104614
Validation loss: 1.447472313398956

Epoch: 6| Step: 10
Training loss: 0.0687214806675911
Validation loss: 1.4066313774354997

Epoch: 6| Step: 11
Training loss: 0.15645289421081543
Validation loss: 1.4083016469914427

Epoch: 6| Step: 12
Training loss: 0.09925680607557297
Validation loss: 1.394741455713908

Epoch: 6| Step: 13
Training loss: 0.14123035967350006
Validation loss: 1.3909900278173468

Epoch: 453| Step: 0
Training loss: 0.135113924741745
Validation loss: 1.3917337002292756

Epoch: 6| Step: 1
Training loss: 0.13825693726539612
Validation loss: 1.3727088935913578

Epoch: 6| Step: 2
Training loss: 0.13227391242980957
Validation loss: 1.3809893951621106

Epoch: 6| Step: 3
Training loss: 0.1179829016327858
Validation loss: 1.4082172570690032

Epoch: 6| Step: 4
Training loss: 0.13967949151992798
Validation loss: 1.4036727682236703

Epoch: 6| Step: 5
Training loss: 0.09332723915576935
Validation loss: 1.4483931788834192

Epoch: 6| Step: 6
Training loss: 0.11085767298936844
Validation loss: 1.4354677136226366

Epoch: 6| Step: 7
Training loss: 0.15826569497585297
Validation loss: 1.48880139986674

Epoch: 6| Step: 8
Training loss: 0.09897232800722122
Validation loss: 1.4746212446561424

Epoch: 6| Step: 9
Training loss: 0.1053689569234848
Validation loss: 1.4541506600636307

Epoch: 6| Step: 10
Training loss: 0.24041692912578583
Validation loss: 1.4630330583100677

Epoch: 6| Step: 11
Training loss: 0.09971798956394196
Validation loss: 1.463064302680313

Epoch: 6| Step: 12
Training loss: 0.17332760989665985
Validation loss: 1.46639197744349

Epoch: 6| Step: 13
Training loss: 0.0993049144744873
Validation loss: 1.469668278130152

Epoch: 454| Step: 0
Training loss: 0.0908266007900238
Validation loss: 1.452286918958028

Epoch: 6| Step: 1
Training loss: 0.10676838457584381
Validation loss: 1.4478509990117883

Epoch: 6| Step: 2
Training loss: 0.21162712574005127
Validation loss: 1.4404902753009592

Epoch: 6| Step: 3
Training loss: 0.09903324395418167
Validation loss: 1.4598940636522026

Epoch: 6| Step: 4
Training loss: 0.18176719546318054
Validation loss: 1.4422425018843783

Epoch: 6| Step: 5
Training loss: 0.08673276007175446
Validation loss: 1.427985381054622

Epoch: 6| Step: 6
Training loss: 0.0775616317987442
Validation loss: 1.4538684096387637

Epoch: 6| Step: 7
Training loss: 0.11266017705202103
Validation loss: 1.4423011169638684

Epoch: 6| Step: 8
Training loss: 0.11325017362833023
Validation loss: 1.4512567814960275

Epoch: 6| Step: 9
Training loss: 0.08524300903081894
Validation loss: 1.4629493221159904

Epoch: 6| Step: 10
Training loss: 0.08915790915489197
Validation loss: 1.4446100099112398

Epoch: 6| Step: 11
Training loss: 0.14924579858779907
Validation loss: 1.4564683950075539

Epoch: 6| Step: 12
Training loss: 0.08279451727867126
Validation loss: 1.4561990743042321

Epoch: 6| Step: 13
Training loss: 0.13184885680675507
Validation loss: 1.4477917199493737

Epoch: 455| Step: 0
Training loss: 0.08201035857200623
Validation loss: 1.4124729197512391

Epoch: 6| Step: 1
Training loss: 0.13918739557266235
Validation loss: 1.4468416231934742

Epoch: 6| Step: 2
Training loss: 0.08788467943668365
Validation loss: 1.4305092942330144

Epoch: 6| Step: 3
Training loss: 0.1372184008359909
Validation loss: 1.4534916775200957

Epoch: 6| Step: 4
Training loss: 0.10669051855802536
Validation loss: 1.4532861671140116

Epoch: 6| Step: 5
Training loss: 0.10557842999696732
Validation loss: 1.4325768178509128

Epoch: 6| Step: 6
Training loss: 0.07525265216827393
Validation loss: 1.4510883682517595

Epoch: 6| Step: 7
Training loss: 0.11255644261837006
Validation loss: 1.4706188324959046

Epoch: 6| Step: 8
Training loss: 0.06676141917705536
Validation loss: 1.4788424186809088

Epoch: 6| Step: 9
Training loss: 0.16896259784698486
Validation loss: 1.4903776696933213

Epoch: 6| Step: 10
Training loss: 0.14457815885543823
Validation loss: 1.4972970716414913

Epoch: 6| Step: 11
Training loss: 0.2616078555583954
Validation loss: 1.49780289588436

Epoch: 6| Step: 12
Training loss: 0.0747687965631485
Validation loss: 1.5257388237983949

Epoch: 6| Step: 13
Training loss: 0.12416745722293854
Validation loss: 1.525385215718259

Epoch: 456| Step: 0
Training loss: 0.23733901977539062
Validation loss: 1.5200123351107362

Epoch: 6| Step: 1
Training loss: 0.16318494081497192
Validation loss: 1.5175326338378332

Epoch: 6| Step: 2
Training loss: 0.15153786540031433
Validation loss: 1.54457567327766

Epoch: 6| Step: 3
Training loss: 0.1228879913687706
Validation loss: 1.5161079078592279

Epoch: 6| Step: 4
Training loss: 0.16176429390907288
Validation loss: 1.5185886557384203

Epoch: 6| Step: 5
Training loss: 0.11830136179924011
Validation loss: 1.4927084138316493

Epoch: 6| Step: 6
Training loss: 0.13084180653095245
Validation loss: 1.4828798117176178

Epoch: 6| Step: 7
Training loss: 0.1641840934753418
Validation loss: 1.4910971016012213

Epoch: 6| Step: 8
Training loss: 0.12353075295686722
Validation loss: 1.4871377150217693

Epoch: 6| Step: 9
Training loss: 0.12317672371864319
Validation loss: 1.493968059939723

Epoch: 6| Step: 10
Training loss: 0.06456318497657776
Validation loss: 1.4787746885771393

Epoch: 6| Step: 11
Training loss: 0.12829884886741638
Validation loss: 1.4551144133331955

Epoch: 6| Step: 12
Training loss: 0.19797897338867188
Validation loss: 1.477763993765718

Epoch: 6| Step: 13
Training loss: 0.1343459039926529
Validation loss: 1.4957464561667493

Epoch: 457| Step: 0
Training loss: 0.13206714391708374
Validation loss: 1.4608031037033244

Epoch: 6| Step: 1
Training loss: 0.16217923164367676
Validation loss: 1.4489741761197326

Epoch: 6| Step: 2
Training loss: 0.09348269551992416
Validation loss: 1.4452965823552941

Epoch: 6| Step: 3
Training loss: 0.1504211276769638
Validation loss: 1.4585131957966795

Epoch: 6| Step: 4
Training loss: 0.09330567717552185
Validation loss: 1.4622098284382974

Epoch: 6| Step: 5
Training loss: 0.22822339832782745
Validation loss: 1.4471204165489442

Epoch: 6| Step: 6
Training loss: 0.09119786322116852
Validation loss: 1.4618676875227241

Epoch: 6| Step: 7
Training loss: 0.09297821670770645
Validation loss: 1.4497122469768728

Epoch: 6| Step: 8
Training loss: 0.10261116921901703
Validation loss: 1.4842321565074306

Epoch: 6| Step: 9
Training loss: 0.08904008567333221
Validation loss: 1.4795518421357678

Epoch: 6| Step: 10
Training loss: 0.09493090212345123
Validation loss: 1.4537132183710735

Epoch: 6| Step: 11
Training loss: 0.12169814854860306
Validation loss: 1.4737256387228608

Epoch: 6| Step: 12
Training loss: 0.12331297248601913
Validation loss: 1.469814472301032

Epoch: 6| Step: 13
Training loss: 0.1612803339958191
Validation loss: 1.4768477806480982

Epoch: 458| Step: 0
Training loss: 0.2678932547569275
Validation loss: 1.4752596860290856

Epoch: 6| Step: 1
Training loss: 0.09038771688938141
Validation loss: 1.4614634436945761

Epoch: 6| Step: 2
Training loss: 0.07178410142660141
Validation loss: 1.46937910972103

Epoch: 6| Step: 3
Training loss: 0.14481741189956665
Validation loss: 1.456513350368828

Epoch: 6| Step: 4
Training loss: 0.11654845625162125
Validation loss: 1.4424223656295447

Epoch: 6| Step: 5
Training loss: 0.1397969275712967
Validation loss: 1.4262011442133176

Epoch: 6| Step: 6
Training loss: 0.12329979240894318
Validation loss: 1.4417543744528165

Epoch: 6| Step: 7
Training loss: 0.17291730642318726
Validation loss: 1.4183433408378272

Epoch: 6| Step: 8
Training loss: 0.10163301974534988
Validation loss: 1.42934682420505

Epoch: 6| Step: 9
Training loss: 0.08002778887748718
Validation loss: 1.4196381594545098

Epoch: 6| Step: 10
Training loss: 0.14745786786079407
Validation loss: 1.4172481554810719

Epoch: 6| Step: 11
Training loss: 0.10911466181278229
Validation loss: 1.4127428070191415

Epoch: 6| Step: 12
Training loss: 0.11012378334999084
Validation loss: 1.424785655031922

Epoch: 6| Step: 13
Training loss: 0.10646490007638931
Validation loss: 1.4311679319668842

Epoch: 459| Step: 0
Training loss: 0.07191454619169235
Validation loss: 1.418100336546539

Epoch: 6| Step: 1
Training loss: 0.15555739402770996
Validation loss: 1.430754284704885

Epoch: 6| Step: 2
Training loss: 0.10049360245466232
Validation loss: 1.4553502657080208

Epoch: 6| Step: 3
Training loss: 0.04387470707297325
Validation loss: 1.4444913223225584

Epoch: 6| Step: 4
Training loss: 0.19247713685035706
Validation loss: 1.4542050169360252

Epoch: 6| Step: 5
Training loss: 0.0747753232717514
Validation loss: 1.464337174610425

Epoch: 6| Step: 6
Training loss: 0.0774051621556282
Validation loss: 1.458047902712258

Epoch: 6| Step: 7
Training loss: 0.10808879882097244
Validation loss: 1.4637579071906306

Epoch: 6| Step: 8
Training loss: 0.07107587903738022
Validation loss: 1.4735168718522595

Epoch: 6| Step: 9
Training loss: 0.08420171588659286
Validation loss: 1.4694335870845343

Epoch: 6| Step: 10
Training loss: 0.13101552426815033
Validation loss: 1.4577555502614667

Epoch: 6| Step: 11
Training loss: 0.1081010103225708
Validation loss: 1.46816853169472

Epoch: 6| Step: 12
Training loss: 0.1865561306476593
Validation loss: 1.447422477506822

Epoch: 6| Step: 13
Training loss: 0.1499202698469162
Validation loss: 1.486306789100811

Epoch: 460| Step: 0
Training loss: 0.19393235445022583
Validation loss: 1.5016541583563692

Epoch: 6| Step: 1
Training loss: 0.07352219521999359
Validation loss: 1.5238899043811265

Epoch: 6| Step: 2
Training loss: 0.07359243184328079
Validation loss: 1.5262820182308074

Epoch: 6| Step: 3
Training loss: 0.09440696239471436
Validation loss: 1.4920399419723018

Epoch: 6| Step: 4
Training loss: 0.2260129600763321
Validation loss: 1.4989784648341518

Epoch: 6| Step: 5
Training loss: 0.0738145112991333
Validation loss: 1.5019041979184715

Epoch: 6| Step: 6
Training loss: 0.14272825419902802
Validation loss: 1.4993515886286253

Epoch: 6| Step: 7
Training loss: 0.10727532207965851
Validation loss: 1.4739451305840605

Epoch: 6| Step: 8
Training loss: 0.06094560772180557
Validation loss: 1.4492409229278564

Epoch: 6| Step: 9
Training loss: 0.13859739899635315
Validation loss: 1.4621917163172076

Epoch: 6| Step: 10
Training loss: 0.06354129314422607
Validation loss: 1.4549044178378197

Epoch: 6| Step: 11
Training loss: 0.11938982456922531
Validation loss: 1.4358388570047194

Epoch: 6| Step: 12
Training loss: 0.1405969262123108
Validation loss: 1.4302214236669644

Epoch: 6| Step: 13
Training loss: 0.13612914085388184
Validation loss: 1.4556576096883385

Epoch: 461| Step: 0
Training loss: 0.08550490438938141
Validation loss: 1.4616089726007113

Epoch: 6| Step: 1
Training loss: 0.09529593586921692
Validation loss: 1.4485498628308695

Epoch: 6| Step: 2
Training loss: 0.11544165015220642
Validation loss: 1.446136974519299

Epoch: 6| Step: 3
Training loss: 0.09757500886917114
Validation loss: 1.4496430466251988

Epoch: 6| Step: 4
Training loss: 0.09934164583683014
Validation loss: 1.444379892400516

Epoch: 6| Step: 5
Training loss: 0.1175725907087326
Validation loss: 1.440841720950219

Epoch: 6| Step: 6
Training loss: 0.12149283289909363
Validation loss: 1.4574246688555645

Epoch: 6| Step: 7
Training loss: 0.21787965297698975
Validation loss: 1.465818933261338

Epoch: 6| Step: 8
Training loss: 0.1555578112602234
Validation loss: 1.439551616227755

Epoch: 6| Step: 9
Training loss: 0.1920895278453827
Validation loss: 1.4608299347662157

Epoch: 6| Step: 10
Training loss: 0.05508272349834442
Validation loss: 1.4611095946322206

Epoch: 6| Step: 11
Training loss: 0.11227142810821533
Validation loss: 1.476323099546535

Epoch: 6| Step: 12
Training loss: 0.06416007876396179
Validation loss: 1.4660564161116076

Epoch: 6| Step: 13
Training loss: 0.08237704634666443
Validation loss: 1.4624234668670162

Epoch: 462| Step: 0
Training loss: 0.14141657948493958
Validation loss: 1.46351654811572

Epoch: 6| Step: 1
Training loss: 0.061532482504844666
Validation loss: 1.4837718625222482

Epoch: 6| Step: 2
Training loss: 0.07634896039962769
Validation loss: 1.4737686905809628

Epoch: 6| Step: 3
Training loss: 0.08603637665510178
Validation loss: 1.424442780915127

Epoch: 6| Step: 4
Training loss: 0.11499319970607758
Validation loss: 1.4324645983275546

Epoch: 6| Step: 5
Training loss: 0.14607086777687073
Validation loss: 1.4559047657956359

Epoch: 6| Step: 6
Training loss: 0.21559898555278778
Validation loss: 1.455917227652765

Epoch: 6| Step: 7
Training loss: 0.07178853452205658
Validation loss: 1.444562465913834

Epoch: 6| Step: 8
Training loss: 0.11439648270606995
Validation loss: 1.4232382402625134

Epoch: 6| Step: 9
Training loss: 0.10990520566701889
Validation loss: 1.429764820683387

Epoch: 6| Step: 10
Training loss: 0.11586572974920273
Validation loss: 1.4418863109363023

Epoch: 6| Step: 11
Training loss: 0.06758274137973785
Validation loss: 1.3973741839008946

Epoch: 6| Step: 12
Training loss: 0.1979871690273285
Validation loss: 1.394904488517392

Epoch: 6| Step: 13
Training loss: 0.10294198244810104
Validation loss: 1.4267547617676437

Epoch: 463| Step: 0
Training loss: 0.1392204314470291
Validation loss: 1.4144421110871017

Epoch: 6| Step: 1
Training loss: 0.11057698726654053
Validation loss: 1.4249921165486819

Epoch: 6| Step: 2
Training loss: 0.1951236128807068
Validation loss: 1.396516320525959

Epoch: 6| Step: 3
Training loss: 0.09781070053577423
Validation loss: 1.4144549382630216

Epoch: 6| Step: 4
Training loss: 0.14881107211112976
Validation loss: 1.4188489747303787

Epoch: 6| Step: 5
Training loss: 0.11074800789356232
Validation loss: 1.416139668033969

Epoch: 6| Step: 6
Training loss: 0.1633438766002655
Validation loss: 1.4419726005164526

Epoch: 6| Step: 7
Training loss: 0.14177685976028442
Validation loss: 1.478437287833101

Epoch: 6| Step: 8
Training loss: 0.08534236997365952
Validation loss: 1.521894561347141

Epoch: 6| Step: 9
Training loss: 0.08309399336576462
Validation loss: 1.5203626450671945

Epoch: 6| Step: 10
Training loss: 0.20580898225307465
Validation loss: 1.5116458849240375

Epoch: 6| Step: 11
Training loss: 0.10577450692653656
Validation loss: 1.4998335287135134

Epoch: 6| Step: 12
Training loss: 0.1735120266675949
Validation loss: 1.4760630989587435

Epoch: 6| Step: 13
Training loss: 0.09461161494255066
Validation loss: 1.4416241440721738

Epoch: 464| Step: 0
Training loss: 0.10528381168842316
Validation loss: 1.388888720543154

Epoch: 6| Step: 1
Training loss: 0.0824027955532074
Validation loss: 1.3468212613495447

Epoch: 6| Step: 2
Training loss: 0.22866667807102203
Validation loss: 1.3540885307455575

Epoch: 6| Step: 3
Training loss: 0.20791538059711456
Validation loss: 1.3360289873615387

Epoch: 6| Step: 4
Training loss: 0.19613388180732727
Validation loss: 1.3531890146193966

Epoch: 6| Step: 5
Training loss: 0.104270339012146
Validation loss: 1.3410747628058157

Epoch: 6| Step: 6
Training loss: 0.19340939819812775
Validation loss: 1.3568739250142088

Epoch: 6| Step: 7
Training loss: 0.13234615325927734
Validation loss: 1.378579084591199

Epoch: 6| Step: 8
Training loss: 0.06994201987981796
Validation loss: 1.4246453098071519

Epoch: 6| Step: 9
Training loss: 0.10729672014713287
Validation loss: 1.4406128262960782

Epoch: 6| Step: 10
Training loss: 0.22956842184066772
Validation loss: 1.4724437511095436

Epoch: 6| Step: 11
Training loss: 0.10736744850873947
Validation loss: 1.4888532238621865

Epoch: 6| Step: 12
Training loss: 0.31799617409706116
Validation loss: 1.5182133900221957

Epoch: 6| Step: 13
Training loss: 0.07025983929634094
Validation loss: 1.4827453192844187

Epoch: 465| Step: 0
Training loss: 0.11022880673408508
Validation loss: 1.4504928345321326

Epoch: 6| Step: 1
Training loss: 0.20545688271522522
Validation loss: 1.4392088626020698

Epoch: 6| Step: 2
Training loss: 0.1275942176580429
Validation loss: 1.4297095908913562

Epoch: 6| Step: 3
Training loss: 0.1775677353143692
Validation loss: 1.3995316695141535

Epoch: 6| Step: 4
Training loss: 0.21662800014019012
Validation loss: 1.4121349216789327

Epoch: 6| Step: 5
Training loss: 0.0874166414141655
Validation loss: 1.3784723563860821

Epoch: 6| Step: 6
Training loss: 0.07532797008752823
Validation loss: 1.3813680500112555

Epoch: 6| Step: 7
Training loss: 0.10287906974554062
Validation loss: 1.389841010493617

Epoch: 6| Step: 8
Training loss: 0.24613647162914276
Validation loss: 1.386810903908104

Epoch: 6| Step: 9
Training loss: 0.19514229893684387
Validation loss: 1.3963330067614073

Epoch: 6| Step: 10
Training loss: 0.07607374340295792
Validation loss: 1.420838685445888

Epoch: 6| Step: 11
Training loss: 0.0898064598441124
Validation loss: 1.4399738568131641

Epoch: 6| Step: 12
Training loss: 0.1565447747707367
Validation loss: 1.441922841533538

Epoch: 6| Step: 13
Training loss: 0.08174720406532288
Validation loss: 1.4544843999288415

Epoch: 466| Step: 0
Training loss: 0.2234056144952774
Validation loss: 1.481326417256427

Epoch: 6| Step: 1
Training loss: 0.11560286581516266
Validation loss: 1.4758551966759466

Epoch: 6| Step: 2
Training loss: 0.10389729589223862
Validation loss: 1.5154646212054836

Epoch: 6| Step: 3
Training loss: 0.16285006701946259
Validation loss: 1.4805923020967873

Epoch: 6| Step: 4
Training loss: 0.09289427101612091
Validation loss: 1.5051742253764984

Epoch: 6| Step: 5
Training loss: 0.10711166262626648
Validation loss: 1.4788377900277414

Epoch: 6| Step: 6
Training loss: 0.13631275296211243
Validation loss: 1.4649902780850728

Epoch: 6| Step: 7
Training loss: 0.09202630817890167
Validation loss: 1.4565518735557474

Epoch: 6| Step: 8
Training loss: 0.1282264143228531
Validation loss: 1.4509651917283253

Epoch: 6| Step: 9
Training loss: 0.10098452866077423
Validation loss: 1.4571108715508574

Epoch: 6| Step: 10
Training loss: 0.0804736316204071
Validation loss: 1.4470104658475487

Epoch: 6| Step: 11
Training loss: 0.11820048838853836
Validation loss: 1.4478674088754961

Epoch: 6| Step: 12
Training loss: 0.15187636017799377
Validation loss: 1.4390036662419636

Epoch: 6| Step: 13
Training loss: 0.0688190832734108
Validation loss: 1.4654293124393751

Epoch: 467| Step: 0
Training loss: 0.06138577684760094
Validation loss: 1.4909108018362394

Epoch: 6| Step: 1
Training loss: 0.12031346559524536
Validation loss: 1.46166391077862

Epoch: 6| Step: 2
Training loss: 0.08971643447875977
Validation loss: 1.4801834116699875

Epoch: 6| Step: 3
Training loss: 0.12637799978256226
Validation loss: 1.4674095812664236

Epoch: 6| Step: 4
Training loss: 0.13741853833198547
Validation loss: 1.4848549699270597

Epoch: 6| Step: 5
Training loss: 0.2133810669183731
Validation loss: 1.4857892515838786

Epoch: 6| Step: 6
Training loss: 0.09184867888689041
Validation loss: 1.4794593587998421

Epoch: 6| Step: 7
Training loss: 0.1014033704996109
Validation loss: 1.4841169144517632

Epoch: 6| Step: 8
Training loss: 0.11450430750846863
Validation loss: 1.48778082670704

Epoch: 6| Step: 9
Training loss: 0.062179435044527054
Validation loss: 1.4681260470421083

Epoch: 6| Step: 10
Training loss: 0.1875699758529663
Validation loss: 1.4387237538573563

Epoch: 6| Step: 11
Training loss: 0.14699330925941467
Validation loss: 1.4359461517744168

Epoch: 6| Step: 12
Training loss: 0.06737020611763
Validation loss: 1.4089413496755785

Epoch: 6| Step: 13
Training loss: 0.059999123215675354
Validation loss: 1.4070467872004355

Epoch: 468| Step: 0
Training loss: 0.19470146298408508
Validation loss: 1.3983512898927093

Epoch: 6| Step: 1
Training loss: 0.13354258239269257
Validation loss: 1.383143073769026

Epoch: 6| Step: 2
Training loss: 0.11317913979291916
Validation loss: 1.3904713481985114

Epoch: 6| Step: 3
Training loss: 0.12964625656604767
Validation loss: 1.432418538678077

Epoch: 6| Step: 4
Training loss: 0.1530485451221466
Validation loss: 1.4281766940188665

Epoch: 6| Step: 5
Training loss: 0.11238879710435867
Validation loss: 1.4461495376402331

Epoch: 6| Step: 6
Training loss: 0.050263918936252594
Validation loss: 1.4596521931309854

Epoch: 6| Step: 7
Training loss: 0.11134535074234009
Validation loss: 1.485264394872932

Epoch: 6| Step: 8
Training loss: 0.1092565506696701
Validation loss: 1.4712749360710062

Epoch: 6| Step: 9
Training loss: 0.10507147014141083
Validation loss: 1.4943055555384646

Epoch: 6| Step: 10
Training loss: 0.08223295211791992
Validation loss: 1.509246257043654

Epoch: 6| Step: 11
Training loss: 0.11600577086210251
Validation loss: 1.4703314752988919

Epoch: 6| Step: 12
Training loss: 0.09053747355937958
Validation loss: 1.4686894878264396

Epoch: 6| Step: 13
Training loss: 0.06614509969949722
Validation loss: 1.4860522336857294

Epoch: 469| Step: 0
Training loss: 0.15845435857772827
Validation loss: 1.4620314810865669

Epoch: 6| Step: 1
Training loss: 0.04879738390445709
Validation loss: 1.465002832874175

Epoch: 6| Step: 2
Training loss: 0.11894309520721436
Validation loss: 1.4566169220914122

Epoch: 6| Step: 3
Training loss: 0.056180160492658615
Validation loss: 1.4380779445812266

Epoch: 6| Step: 4
Training loss: 0.09513819217681885
Validation loss: 1.437398399076154

Epoch: 6| Step: 5
Training loss: 0.11252865940332413
Validation loss: 1.4258772070689867

Epoch: 6| Step: 6
Training loss: 0.1214376911520958
Validation loss: 1.441102009947582

Epoch: 6| Step: 7
Training loss: 0.12017539888620377
Validation loss: 1.4388150707367928

Epoch: 6| Step: 8
Training loss: 0.14177149534225464
Validation loss: 1.4305994433741416

Epoch: 6| Step: 9
Training loss: 0.12863966822624207
Validation loss: 1.396552837023171

Epoch: 6| Step: 10
Training loss: 0.12036944925785065
Validation loss: 1.3844992653016122

Epoch: 6| Step: 11
Training loss: 0.12484560161828995
Validation loss: 1.3758511850910802

Epoch: 6| Step: 12
Training loss: 0.12504178285598755
Validation loss: 1.4072236681497226

Epoch: 6| Step: 13
Training loss: 0.11708598583936691
Validation loss: 1.387380244911358

Epoch: 470| Step: 0
Training loss: 0.12772585451602936
Validation loss: 1.4132130716436653

Epoch: 6| Step: 1
Training loss: 0.1219952255487442
Validation loss: 1.427247562716084

Epoch: 6| Step: 2
Training loss: 0.12224946916103363
Validation loss: 1.421390587283719

Epoch: 6| Step: 3
Training loss: 0.07123803347349167
Validation loss: 1.4363048666266984

Epoch: 6| Step: 4
Training loss: 0.14193645119667053
Validation loss: 1.441750607823813

Epoch: 6| Step: 5
Training loss: 0.17368100583553314
Validation loss: 1.4428774746515418

Epoch: 6| Step: 6
Training loss: 0.09297755360603333
Validation loss: 1.4552484737929476

Epoch: 6| Step: 7
Training loss: 0.11880628019571304
Validation loss: 1.4676705175830471

Epoch: 6| Step: 8
Training loss: 0.10954026877880096
Validation loss: 1.495015493644181

Epoch: 6| Step: 9
Training loss: 0.06823782622814178
Validation loss: 1.4662033998838035

Epoch: 6| Step: 10
Training loss: 0.06039722263813019
Validation loss: 1.4811150200905339

Epoch: 6| Step: 11
Training loss: 0.1162402480840683
Validation loss: 1.4925899351796796

Epoch: 6| Step: 12
Training loss: 0.15529221296310425
Validation loss: 1.4862480945484613

Epoch: 6| Step: 13
Training loss: 0.11492396891117096
Validation loss: 1.4489217201868694

Epoch: 471| Step: 0
Training loss: 0.07724132388830185
Validation loss: 1.4351462087323588

Epoch: 6| Step: 1
Training loss: 0.06389133632183075
Validation loss: 1.4205662024918424

Epoch: 6| Step: 2
Training loss: 0.14297448098659515
Validation loss: 1.4240936047287398

Epoch: 6| Step: 3
Training loss: 0.20412276685237885
Validation loss: 1.4329451091827885

Epoch: 6| Step: 4
Training loss: 0.1503826081752777
Validation loss: 1.4549786403614988

Epoch: 6| Step: 5
Training loss: 0.1132717877626419
Validation loss: 1.432796646189946

Epoch: 6| Step: 6
Training loss: 0.09361563622951508
Validation loss: 1.4158859496475549

Epoch: 6| Step: 7
Training loss: 0.11147025972604752
Validation loss: 1.3998604512983752

Epoch: 6| Step: 8
Training loss: 0.11594441533088684
Validation loss: 1.4139229559129285

Epoch: 6| Step: 9
Training loss: 0.11968087404966354
Validation loss: 1.439495595552588

Epoch: 6| Step: 10
Training loss: 0.11083932965993881
Validation loss: 1.4627244882686163

Epoch: 6| Step: 11
Training loss: 0.07593367993831635
Validation loss: 1.4555664306045861

Epoch: 6| Step: 12
Training loss: 0.0869312435388565
Validation loss: 1.4568941593170166

Epoch: 6| Step: 13
Training loss: 0.11453171819448471
Validation loss: 1.4476075967152913

Epoch: 472| Step: 0
Training loss: 0.0819287896156311
Validation loss: 1.4496018203996843

Epoch: 6| Step: 1
Training loss: 0.10224556922912598
Validation loss: 1.4267257721193376

Epoch: 6| Step: 2
Training loss: 0.12258356064558029
Validation loss: 1.439237472831562

Epoch: 6| Step: 3
Training loss: 0.06088678538799286
Validation loss: 1.439847174511161

Epoch: 6| Step: 4
Training loss: 0.1123974397778511
Validation loss: 1.462394752169168

Epoch: 6| Step: 5
Training loss: 0.18089155852794647
Validation loss: 1.4630136566777383

Epoch: 6| Step: 6
Training loss: 0.1190369725227356
Validation loss: 1.450870822193802

Epoch: 6| Step: 7
Training loss: 0.13174401223659515
Validation loss: 1.46233110274038

Epoch: 6| Step: 8
Training loss: 0.08689834177494049
Validation loss: 1.4291711494486818

Epoch: 6| Step: 9
Training loss: 0.08890484273433685
Validation loss: 1.4155259914295648

Epoch: 6| Step: 10
Training loss: 0.10221326351165771
Validation loss: 1.4206709092663181

Epoch: 6| Step: 11
Training loss: 0.059337466955184937
Validation loss: 1.4173699937840945

Epoch: 6| Step: 12
Training loss: 0.12004227191209793
Validation loss: 1.4084148535164454

Epoch: 6| Step: 13
Training loss: 0.12514357268810272
Validation loss: 1.4069284034031693

Epoch: 473| Step: 0
Training loss: 0.07076359540224075
Validation loss: 1.4152006577419978

Epoch: 6| Step: 1
Training loss: 0.13245394825935364
Validation loss: 1.4252978640217935

Epoch: 6| Step: 2
Training loss: 0.0870434120297432
Validation loss: 1.452825254009616

Epoch: 6| Step: 3
Training loss: 0.1257028579711914
Validation loss: 1.4542972233987623

Epoch: 6| Step: 4
Training loss: 0.07196053862571716
Validation loss: 1.4704167765955771

Epoch: 6| Step: 5
Training loss: 0.1884233057498932
Validation loss: 1.4865708197316816

Epoch: 6| Step: 6
Training loss: 0.08862818777561188
Validation loss: 1.5030467087222683

Epoch: 6| Step: 7
Training loss: 0.06565797328948975
Validation loss: 1.5004340358959731

Epoch: 6| Step: 8
Training loss: 0.12973028421401978
Validation loss: 1.4836930023726596

Epoch: 6| Step: 9
Training loss: 0.06713999807834625
Validation loss: 1.4852620324780863

Epoch: 6| Step: 10
Training loss: 0.08399685472249985
Validation loss: 1.462661862373352

Epoch: 6| Step: 11
Training loss: 0.12093564867973328
Validation loss: 1.4535577668938586

Epoch: 6| Step: 12
Training loss: 0.14721891283988953
Validation loss: 1.4459038447308283

Epoch: 6| Step: 13
Training loss: 0.06524182111024857
Validation loss: 1.4658149160364622

Epoch: 474| Step: 0
Training loss: 0.13894307613372803
Validation loss: 1.4619312901650705

Epoch: 6| Step: 1
Training loss: 0.12915152311325073
Validation loss: 1.4439566468679776

Epoch: 6| Step: 2
Training loss: 0.15950781106948853
Validation loss: 1.4361215586303382

Epoch: 6| Step: 3
Training loss: 0.043797627091407776
Validation loss: 1.4521638610029732

Epoch: 6| Step: 4
Training loss: 0.060052044689655304
Validation loss: 1.465529086769268

Epoch: 6| Step: 5
Training loss: 0.07851094007492065
Validation loss: 1.4642613767295756

Epoch: 6| Step: 6
Training loss: 0.09155390411615372
Validation loss: 1.4698704923352888

Epoch: 6| Step: 7
Training loss: 0.10512066632509232
Validation loss: 1.4845916724974109

Epoch: 6| Step: 8
Training loss: 0.10860459506511688
Validation loss: 1.4653658110608336

Epoch: 6| Step: 9
Training loss: 0.11369968205690384
Validation loss: 1.4735593513775898

Epoch: 6| Step: 10
Training loss: 0.08180610835552216
Validation loss: 1.4538312868405414

Epoch: 6| Step: 11
Training loss: 0.0777612179517746
Validation loss: 1.4546281253137896

Epoch: 6| Step: 12
Training loss: 0.0818159431219101
Validation loss: 1.4641072391181864

Epoch: 6| Step: 13
Training loss: 0.09705564379692078
Validation loss: 1.470418616007733

Epoch: 475| Step: 0
Training loss: 0.05267404019832611
Validation loss: 1.4870505775174787

Epoch: 6| Step: 1
Training loss: 0.09083078801631927
Validation loss: 1.4589247011369275

Epoch: 6| Step: 2
Training loss: 0.09632431715726852
Validation loss: 1.4766626152940976

Epoch: 6| Step: 3
Training loss: 0.10676312446594238
Validation loss: 1.4466799433513353

Epoch: 6| Step: 4
Training loss: 0.09482501447200775
Validation loss: 1.4380462573420616

Epoch: 6| Step: 5
Training loss: 0.11080863326787949
Validation loss: 1.4173417629734162

Epoch: 6| Step: 6
Training loss: 0.20192262530326843
Validation loss: 1.4466982291590782

Epoch: 6| Step: 7
Training loss: 0.09149064868688583
Validation loss: 1.4209101071921728

Epoch: 6| Step: 8
Training loss: 0.17564131319522858
Validation loss: 1.4322977245494883

Epoch: 6| Step: 9
Training loss: 0.12064792215824127
Validation loss: 1.4631832177921007

Epoch: 6| Step: 10
Training loss: 0.08159074187278748
Validation loss: 1.4632165149975849

Epoch: 6| Step: 11
Training loss: 0.08900028467178345
Validation loss: 1.4490910665963286

Epoch: 6| Step: 12
Training loss: 0.10029371082782745
Validation loss: 1.4766061190635926

Epoch: 6| Step: 13
Training loss: 0.11133371293544769
Validation loss: 1.4779503460853332

Epoch: 476| Step: 0
Training loss: 0.0970967710018158
Validation loss: 1.483912419247371

Epoch: 6| Step: 1
Training loss: 0.19124501943588257
Validation loss: 1.474626395010179

Epoch: 6| Step: 2
Training loss: 0.054814450442790985
Validation loss: 1.4522965403013333

Epoch: 6| Step: 3
Training loss: 0.07059381157159805
Validation loss: 1.4423409661939066

Epoch: 6| Step: 4
Training loss: 0.13509750366210938
Validation loss: 1.483593992007676

Epoch: 6| Step: 5
Training loss: 0.15438495576381683
Validation loss: 1.4382819360302341

Epoch: 6| Step: 6
Training loss: 0.1214156299829483
Validation loss: 1.4452030556176299

Epoch: 6| Step: 7
Training loss: 0.09891215711832047
Validation loss: 1.4120212729259203

Epoch: 6| Step: 8
Training loss: 0.1404026597738266
Validation loss: 1.4479485481016097

Epoch: 6| Step: 9
Training loss: 0.05394384264945984
Validation loss: 1.4440680985809655

Epoch: 6| Step: 10
Training loss: 0.08753188699483871
Validation loss: 1.4408006911636682

Epoch: 6| Step: 11
Training loss: 0.07263822853565216
Validation loss: 1.4653495127154934

Epoch: 6| Step: 12
Training loss: 0.1181674599647522
Validation loss: 1.4293030141502299

Epoch: 6| Step: 13
Training loss: 0.04891343414783478
Validation loss: 1.4367541831026795

Epoch: 477| Step: 0
Training loss: 0.10739082098007202
Validation loss: 1.4312656182114796

Epoch: 6| Step: 1
Training loss: 0.10155878216028214
Validation loss: 1.4368193675112981

Epoch: 6| Step: 2
Training loss: 0.12237057089805603
Validation loss: 1.4153948394201135

Epoch: 6| Step: 3
Training loss: 0.13878929615020752
Validation loss: 1.4646171472405876

Epoch: 6| Step: 4
Training loss: 0.19538544118404388
Validation loss: 1.4442843967868435

Epoch: 6| Step: 5
Training loss: 0.10333427786827087
Validation loss: 1.4405867835526824

Epoch: 6| Step: 6
Training loss: 0.058853816241025925
Validation loss: 1.4556239830550326

Epoch: 6| Step: 7
Training loss: 0.13984373211860657
Validation loss: 1.4485964569994199

Epoch: 6| Step: 8
Training loss: 0.0832207053899765
Validation loss: 1.468123322533023

Epoch: 6| Step: 9
Training loss: 0.11131634563207626
Validation loss: 1.492891236018109

Epoch: 6| Step: 10
Training loss: 0.0667649507522583
Validation loss: 1.4935282173977102

Epoch: 6| Step: 11
Training loss: 0.11095256358385086
Validation loss: 1.4968227135237826

Epoch: 6| Step: 12
Training loss: 0.1133807897567749
Validation loss: 1.490452774109379

Epoch: 6| Step: 13
Training loss: 0.11565399169921875
Validation loss: 1.4670286768226213

Epoch: 478| Step: 0
Training loss: 0.10379616916179657
Validation loss: 1.4688180069769583

Epoch: 6| Step: 1
Training loss: 0.05605171248316765
Validation loss: 1.448651791900717

Epoch: 6| Step: 2
Training loss: 0.1344720423221588
Validation loss: 1.4445569771592335

Epoch: 6| Step: 3
Training loss: 0.06239385902881622
Validation loss: 1.4451149509799095

Epoch: 6| Step: 4
Training loss: 0.2565392851829529
Validation loss: 1.4151659665569183

Epoch: 6| Step: 5
Training loss: 0.1140495017170906
Validation loss: 1.4404209916309645

Epoch: 6| Step: 6
Training loss: 0.10198064148426056
Validation loss: 1.4559334619070894

Epoch: 6| Step: 7
Training loss: 0.11467745900154114
Validation loss: 1.4174930575073406

Epoch: 6| Step: 8
Training loss: 0.10366716980934143
Validation loss: 1.4435462195386168

Epoch: 6| Step: 9
Training loss: 0.06782278418540955
Validation loss: 1.4264436960220337

Epoch: 6| Step: 10
Training loss: 0.06325066089630127
Validation loss: 1.4415765436746741

Epoch: 6| Step: 11
Training loss: 0.14843130111694336
Validation loss: 1.4419489778498167

Epoch: 6| Step: 12
Training loss: 0.05980605259537697
Validation loss: 1.4490262987793132

Epoch: 6| Step: 13
Training loss: 0.1210755780339241
Validation loss: 1.440355493176368

Epoch: 479| Step: 0
Training loss: 0.08982543647289276
Validation loss: 1.441424976113022

Epoch: 6| Step: 1
Training loss: 0.06872859597206116
Validation loss: 1.44957858772688

Epoch: 6| Step: 2
Training loss: 0.11060455441474915
Validation loss: 1.449462616315452

Epoch: 6| Step: 3
Training loss: 0.10902097821235657
Validation loss: 1.4496633660408758

Epoch: 6| Step: 4
Training loss: 0.060145605355501175
Validation loss: 1.4211873444177772

Epoch: 6| Step: 5
Training loss: 0.07468005269765854
Validation loss: 1.4141454171108943

Epoch: 6| Step: 6
Training loss: 0.14549657702445984
Validation loss: 1.4316176317071403

Epoch: 6| Step: 7
Training loss: 0.09795548766851425
Validation loss: 1.426377929666991

Epoch: 6| Step: 8
Training loss: 0.23733001947402954
Validation loss: 1.4241394099368845

Epoch: 6| Step: 9
Training loss: 0.09729336947202682
Validation loss: 1.4130933810305852

Epoch: 6| Step: 10
Training loss: 0.13151681423187256
Validation loss: 1.420711636543274

Epoch: 6| Step: 11
Training loss: 0.06325765699148178
Validation loss: 1.4359360100120626

Epoch: 6| Step: 12
Training loss: 0.07430985569953918
Validation loss: 1.4307560484896424

Epoch: 6| Step: 13
Training loss: 0.04608292505145073
Validation loss: 1.4559469274295274

Epoch: 480| Step: 0
Training loss: 0.07824651151895523
Validation loss: 1.4417435789621005

Epoch: 6| Step: 1
Training loss: 0.09615689516067505
Validation loss: 1.4599204294143184

Epoch: 6| Step: 2
Training loss: 0.15254846215248108
Validation loss: 1.4346056202406525

Epoch: 6| Step: 3
Training loss: 0.10770517587661743
Validation loss: 1.4417491625714045

Epoch: 6| Step: 4
Training loss: 0.07856369018554688
Validation loss: 1.42251709968813

Epoch: 6| Step: 5
Training loss: 0.060917481780052185
Validation loss: 1.4321405624830594

Epoch: 6| Step: 6
Training loss: 0.12162088602781296
Validation loss: 1.4188710348580473

Epoch: 6| Step: 7
Training loss: 0.06845871359109879
Validation loss: 1.414858220725931

Epoch: 6| Step: 8
Training loss: 0.0739261656999588
Validation loss: 1.4372058645371468

Epoch: 6| Step: 9
Training loss: 0.0706455335021019
Validation loss: 1.426895562679537

Epoch: 6| Step: 10
Training loss: 0.06186196953058243
Validation loss: 1.4472275126364924

Epoch: 6| Step: 11
Training loss: 0.10233114659786224
Validation loss: 1.4470521698715866

Epoch: 6| Step: 12
Training loss: 0.1690489649772644
Validation loss: 1.4641168925069994

Epoch: 6| Step: 13
Training loss: 0.2788044214248657
Validation loss: 1.458169662824241

Epoch: 481| Step: 0
Training loss: 0.11490088701248169
Validation loss: 1.4707376790303055

Epoch: 6| Step: 1
Training loss: 0.18177463114261627
Validation loss: 1.4691228084666754

Epoch: 6| Step: 2
Training loss: 0.0765984058380127
Validation loss: 1.4709605888653827

Epoch: 6| Step: 3
Training loss: 0.09978988021612167
Validation loss: 1.491575829444393

Epoch: 6| Step: 4
Training loss: 0.10791291296482086
Validation loss: 1.5013912839274253

Epoch: 6| Step: 5
Training loss: 0.07273456454277039
Validation loss: 1.5221167572083012

Epoch: 6| Step: 6
Training loss: 0.1151529997587204
Validation loss: 1.5187180939541067

Epoch: 6| Step: 7
Training loss: 0.11124287545681
Validation loss: 1.531223177909851

Epoch: 6| Step: 8
Training loss: 0.08593782782554626
Validation loss: 1.5011906329021658

Epoch: 6| Step: 9
Training loss: 0.1516605019569397
Validation loss: 1.5002432830872074

Epoch: 6| Step: 10
Training loss: 0.09586434066295624
Validation loss: 1.481718711955573

Epoch: 6| Step: 11
Training loss: 0.07454316318035126
Validation loss: 1.4582848651434785

Epoch: 6| Step: 12
Training loss: 0.1649131029844284
Validation loss: 1.477936521653206

Epoch: 6| Step: 13
Training loss: 0.1296139359474182
Validation loss: 1.4326804280281067

Epoch: 482| Step: 0
Training loss: 0.07935009151697159
Validation loss: 1.4382305798992034

Epoch: 6| Step: 1
Training loss: 0.07290636003017426
Validation loss: 1.445660311688659

Epoch: 6| Step: 2
Training loss: 0.13708707690238953
Validation loss: 1.4295518808467413

Epoch: 6| Step: 3
Training loss: 0.09452211111783981
Validation loss: 1.43568451686572

Epoch: 6| Step: 4
Training loss: 0.06493325531482697
Validation loss: 1.4187925297726867

Epoch: 6| Step: 5
Training loss: 0.10158597677946091
Validation loss: 1.4286747568397111

Epoch: 6| Step: 6
Training loss: 0.10929787904024124
Validation loss: 1.4402812655254076

Epoch: 6| Step: 7
Training loss: 0.05546509474515915
Validation loss: 1.4410512447357178

Epoch: 6| Step: 8
Training loss: 0.18696939945220947
Validation loss: 1.4461462702802432

Epoch: 6| Step: 9
Training loss: 0.09171003103256226
Validation loss: 1.4407358586147267

Epoch: 6| Step: 10
Training loss: 0.061812639236450195
Validation loss: 1.4553029729473976

Epoch: 6| Step: 11
Training loss: 0.054903026670217514
Validation loss: 1.4491993227312643

Epoch: 6| Step: 12
Training loss: 0.10586055368185043
Validation loss: 1.483472821533039

Epoch: 6| Step: 13
Training loss: 0.1458916962146759
Validation loss: 1.484636950236495

Epoch: 483| Step: 0
Training loss: 0.15458643436431885
Validation loss: 1.4498917389941472

Epoch: 6| Step: 1
Training loss: 0.07356564700603485
Validation loss: 1.4785140534882903

Epoch: 6| Step: 2
Training loss: 0.09714406728744507
Validation loss: 1.4738528369575419

Epoch: 6| Step: 3
Training loss: 0.21379658579826355
Validation loss: 1.4571320062042565

Epoch: 6| Step: 4
Training loss: 0.09662885218858719
Validation loss: 1.4432041991141535

Epoch: 6| Step: 5
Training loss: 0.07865024358034134
Validation loss: 1.4372767171552103

Epoch: 6| Step: 6
Training loss: 0.09237893670797348
Validation loss: 1.424225002206782

Epoch: 6| Step: 7
Training loss: 0.13563427329063416
Validation loss: 1.4467942919782413

Epoch: 6| Step: 8
Training loss: 0.15471039712429047
Validation loss: 1.4345323744640555

Epoch: 6| Step: 9
Training loss: 0.10765613615512848
Validation loss: 1.4374891814365183

Epoch: 6| Step: 10
Training loss: 0.06579678505659103
Validation loss: 1.4523628578391126

Epoch: 6| Step: 11
Training loss: 0.18681347370147705
Validation loss: 1.45685879389445

Epoch: 6| Step: 12
Training loss: 0.07565003633499146
Validation loss: 1.469964265182454

Epoch: 6| Step: 13
Training loss: 0.22407902777194977
Validation loss: 1.5155221749377508

Epoch: 484| Step: 0
Training loss: 0.10415109246969223
Validation loss: 1.5084684548839447

Epoch: 6| Step: 1
Training loss: 0.12856373190879822
Validation loss: 1.5066539792604343

Epoch: 6| Step: 2
Training loss: 0.07072938978672028
Validation loss: 1.5416379974734398

Epoch: 6| Step: 3
Training loss: 0.11522669345140457
Validation loss: 1.5377587221002067

Epoch: 6| Step: 4
Training loss: 0.09532235562801361
Validation loss: 1.5121688253136092

Epoch: 6| Step: 5
Training loss: 0.22915133833885193
Validation loss: 1.4948759848071682

Epoch: 6| Step: 6
Training loss: 0.05291319638490677
Validation loss: 1.4444629582025672

Epoch: 6| Step: 7
Training loss: 0.04781079292297363
Validation loss: 1.4395139550649991

Epoch: 6| Step: 8
Training loss: 0.09808355569839478
Validation loss: 1.4298716232340822

Epoch: 6| Step: 9
Training loss: 0.0885031521320343
Validation loss: 1.4113349940187188

Epoch: 6| Step: 10
Training loss: 0.13024696707725525
Validation loss: 1.3956521480314192

Epoch: 6| Step: 11
Training loss: 0.13581553101539612
Validation loss: 1.3987274855695746

Epoch: 6| Step: 12
Training loss: 0.15199093520641327
Validation loss: 1.3982315871023363

Epoch: 6| Step: 13
Training loss: 0.08342225104570389
Validation loss: 1.3844695398884435

Epoch: 485| Step: 0
Training loss: 0.14700394868850708
Validation loss: 1.3706966119427835

Epoch: 6| Step: 1
Training loss: 0.12556865811347961
Validation loss: 1.4164948796713224

Epoch: 6| Step: 2
Training loss: 0.06762171536684036
Validation loss: 1.4055806872665242

Epoch: 6| Step: 3
Training loss: 0.11597585678100586
Validation loss: 1.3904604616985525

Epoch: 6| Step: 4
Training loss: 0.07515234500169754
Validation loss: 1.380217509884988

Epoch: 6| Step: 5
Training loss: 0.0895911380648613
Validation loss: 1.4015193331626155

Epoch: 6| Step: 6
Training loss: 0.05758495256304741
Validation loss: 1.418569722483235

Epoch: 6| Step: 7
Training loss: 0.1537785679101944
Validation loss: 1.4082461608353483

Epoch: 6| Step: 8
Training loss: 0.1049111858010292
Validation loss: 1.3883487447615592

Epoch: 6| Step: 9
Training loss: 0.08801719546318054
Validation loss: 1.4069460758598902

Epoch: 6| Step: 10
Training loss: 0.12683221697807312
Validation loss: 1.4223720540282547

Epoch: 6| Step: 11
Training loss: 0.05817890912294388
Validation loss: 1.4452965669734503

Epoch: 6| Step: 12
Training loss: 0.19669169187545776
Validation loss: 1.4497105818922802

Epoch: 6| Step: 13
Training loss: 0.04529108107089996
Validation loss: 1.5079959413056732

Epoch: 486| Step: 0
Training loss: 0.16100138425827026
Validation loss: 1.5164147179613832

Epoch: 6| Step: 1
Training loss: 0.11285323649644852
Validation loss: 1.5461816672355897

Epoch: 6| Step: 2
Training loss: 0.09019893407821655
Validation loss: 1.565214664705338

Epoch: 6| Step: 3
Training loss: 0.3292560577392578
Validation loss: 1.5314742429282076

Epoch: 6| Step: 4
Training loss: 0.13852250576019287
Validation loss: 1.5509815754428986

Epoch: 6| Step: 5
Training loss: 0.12853354215621948
Validation loss: 1.5131424767996675

Epoch: 6| Step: 6
Training loss: 0.10333383083343506
Validation loss: 1.4656695460760465

Epoch: 6| Step: 7
Training loss: 0.06348571181297302
Validation loss: 1.4428565502166748

Epoch: 6| Step: 8
Training loss: 0.12152476608753204
Validation loss: 1.4110577042384813

Epoch: 6| Step: 9
Training loss: 0.1251702904701233
Validation loss: 1.4099900696867256

Epoch: 6| Step: 10
Training loss: 0.11061080545186996
Validation loss: 1.3922290212364608

Epoch: 6| Step: 11
Training loss: 0.09932555258274078
Validation loss: 1.4025183493091213

Epoch: 6| Step: 12
Training loss: 0.13070717453956604
Validation loss: 1.3982277957982914

Epoch: 6| Step: 13
Training loss: 0.17620891332626343
Validation loss: 1.3907360133304392

Epoch: 487| Step: 0
Training loss: 0.119468092918396
Validation loss: 1.4302011715468539

Epoch: 6| Step: 1
Training loss: 0.12584568560123444
Validation loss: 1.4417841870297667

Epoch: 6| Step: 2
Training loss: 0.11520173400640488
Validation loss: 1.4259645663281924

Epoch: 6| Step: 3
Training loss: 0.0903436690568924
Validation loss: 1.4730895591038529

Epoch: 6| Step: 4
Training loss: 0.18860158324241638
Validation loss: 1.4650087433476602

Epoch: 6| Step: 5
Training loss: 0.08211546391248703
Validation loss: 1.4423224003084245

Epoch: 6| Step: 6
Training loss: 0.20193777978420258
Validation loss: 1.4788614460217056

Epoch: 6| Step: 7
Training loss: 0.06341631710529327
Validation loss: 1.4416714740055863

Epoch: 6| Step: 8
Training loss: 0.09770850837230682
Validation loss: 1.4578103634618944

Epoch: 6| Step: 9
Training loss: 0.07937389612197876
Validation loss: 1.4580690271110945

Epoch: 6| Step: 10
Training loss: 0.1416233628988266
Validation loss: 1.4451277922558528

Epoch: 6| Step: 11
Training loss: 0.16066958010196686
Validation loss: 1.4627028126870432

Epoch: 6| Step: 12
Training loss: 0.1002798080444336
Validation loss: 1.4291874260030768

Epoch: 6| Step: 13
Training loss: 0.0701342523097992
Validation loss: 1.4280570412194857

Epoch: 488| Step: 0
Training loss: 0.0998099073767662
Validation loss: 1.4237743154648812

Epoch: 6| Step: 1
Training loss: 0.16757148504257202
Validation loss: 1.4478372944298612

Epoch: 6| Step: 2
Training loss: 0.28665879368782043
Validation loss: 1.4636825669196345

Epoch: 6| Step: 3
Training loss: 0.21953028440475464
Validation loss: 1.4528583557375017

Epoch: 6| Step: 4
Training loss: 0.10760921239852905
Validation loss: 1.4315580488533102

Epoch: 6| Step: 5
Training loss: 0.11974412947893143
Validation loss: 1.4351098729718117

Epoch: 6| Step: 6
Training loss: 0.09834587574005127
Validation loss: 1.440359846238167

Epoch: 6| Step: 7
Training loss: 0.19703172147274017
Validation loss: 1.4299308881964734

Epoch: 6| Step: 8
Training loss: 0.15969766676425934
Validation loss: 1.4360791342232817

Epoch: 6| Step: 9
Training loss: 0.23350739479064941
Validation loss: 1.4185305295451995

Epoch: 6| Step: 10
Training loss: 0.06918024271726608
Validation loss: 1.398414631043711

Epoch: 6| Step: 11
Training loss: 0.08286921679973602
Validation loss: 1.3975242619873376

Epoch: 6| Step: 12
Training loss: 0.07381139695644379
Validation loss: 1.3899890331811802

Epoch: 6| Step: 13
Training loss: 0.26896852254867554
Validation loss: 1.3908463665234145

Epoch: 489| Step: 0
Training loss: 0.16267988085746765
Validation loss: 1.4047028749219832

Epoch: 6| Step: 1
Training loss: 0.08515090495347977
Validation loss: 1.3823263337535243

Epoch: 6| Step: 2
Training loss: 0.06216160207986832
Validation loss: 1.4162978151793122

Epoch: 6| Step: 3
Training loss: 0.11352986842393875
Validation loss: 1.4389687481746878

Epoch: 6| Step: 4
Training loss: 0.15900126099586487
Validation loss: 1.438926444258741

Epoch: 6| Step: 5
Training loss: 0.12735937535762787
Validation loss: 1.4155971055389733

Epoch: 6| Step: 6
Training loss: 0.0631713718175888
Validation loss: 1.4105964155607327

Epoch: 6| Step: 7
Training loss: 0.10695283114910126
Validation loss: 1.3906769085955877

Epoch: 6| Step: 8
Training loss: 0.08252382278442383
Validation loss: 1.4036808462553128

Epoch: 6| Step: 9
Training loss: 0.10868724435567856
Validation loss: 1.3924337112775413

Epoch: 6| Step: 10
Training loss: 0.18060177564620972
Validation loss: 1.3900546604587185

Epoch: 6| Step: 11
Training loss: 0.1394006907939911
Validation loss: 1.421424255576185

Epoch: 6| Step: 12
Training loss: 0.19171257317066193
Validation loss: 1.3834339098263813

Epoch: 6| Step: 13
Training loss: 0.1432139277458191
Validation loss: 1.4532647671238068

Epoch: 490| Step: 0
Training loss: 0.06441309303045273
Validation loss: 1.4163003749744867

Epoch: 6| Step: 1
Training loss: 0.11149398982524872
Validation loss: 1.4271996751908334

Epoch: 6| Step: 2
Training loss: 0.1535821557044983
Validation loss: 1.47393843179108

Epoch: 6| Step: 3
Training loss: 0.19271817803382874
Validation loss: 1.4589930503599104

Epoch: 6| Step: 4
Training loss: 0.17540262639522552
Validation loss: 1.4449377098391134

Epoch: 6| Step: 5
Training loss: 0.22284209728240967
Validation loss: 1.4317769888908631

Epoch: 6| Step: 6
Training loss: 0.07698962092399597
Validation loss: 1.46971474283485

Epoch: 6| Step: 7
Training loss: 0.08170231431722641
Validation loss: 1.4801224444502143

Epoch: 6| Step: 8
Training loss: 0.12767285108566284
Validation loss: 1.4878642853870188

Epoch: 6| Step: 9
Training loss: 0.15080171823501587
Validation loss: 1.4346995046061854

Epoch: 6| Step: 10
Training loss: 0.126417338848114
Validation loss: 1.4322574343732608

Epoch: 6| Step: 11
Training loss: 0.11318830400705338
Validation loss: 1.4097836761064426

Epoch: 6| Step: 12
Training loss: 0.10497790575027466
Validation loss: 1.4219636327476912

Epoch: 6| Step: 13
Training loss: 0.07069853693246841
Validation loss: 1.4407282926703011

Epoch: 491| Step: 0
Training loss: 0.09280309826135635
Validation loss: 1.4190687979421308

Epoch: 6| Step: 1
Training loss: 0.14388538897037506
Validation loss: 1.4289714142840395

Epoch: 6| Step: 2
Training loss: 0.17885255813598633
Validation loss: 1.4370563940335346

Epoch: 6| Step: 3
Training loss: 0.1361474096775055
Validation loss: 1.4418081801424745

Epoch: 6| Step: 4
Training loss: 0.10797332972288132
Validation loss: 1.4341281024358605

Epoch: 6| Step: 5
Training loss: 0.08641322702169418
Validation loss: 1.447960921513137

Epoch: 6| Step: 6
Training loss: 0.11475367099046707
Validation loss: 1.408158076706753

Epoch: 6| Step: 7
Training loss: 0.15198081731796265
Validation loss: 1.415414128252255

Epoch: 6| Step: 8
Training loss: 0.16118484735488892
Validation loss: 1.4503875650385374

Epoch: 6| Step: 9
Training loss: 0.0992206558585167
Validation loss: 1.4360913499709098

Epoch: 6| Step: 10
Training loss: 0.08347678184509277
Validation loss: 1.4274029116476736

Epoch: 6| Step: 11
Training loss: 0.11783211678266525
Validation loss: 1.392142294555582

Epoch: 6| Step: 12
Training loss: 0.11221767961978912
Validation loss: 1.4345362878614856

Epoch: 6| Step: 13
Training loss: 0.062754325568676
Validation loss: 1.433556850238513

Epoch: 492| Step: 0
Training loss: 0.06117682158946991
Validation loss: 1.4357143025244437

Epoch: 6| Step: 1
Training loss: 0.13186675310134888
Validation loss: 1.4577297126093218

Epoch: 6| Step: 2
Training loss: 0.11196811497211456
Validation loss: 1.4419165759958246

Epoch: 6| Step: 3
Training loss: 0.088826984167099
Validation loss: 1.4568890269084642

Epoch: 6| Step: 4
Training loss: 0.13372693955898285
Validation loss: 1.4505060001086163

Epoch: 6| Step: 5
Training loss: 0.13533729314804077
Validation loss: 1.4463256366791264

Epoch: 6| Step: 6
Training loss: 0.08137926459312439
Validation loss: 1.4839650264350317

Epoch: 6| Step: 7
Training loss: 0.09538961946964264
Validation loss: 1.4561076433427873

Epoch: 6| Step: 8
Training loss: 0.13716785609722137
Validation loss: 1.4855717356486986

Epoch: 6| Step: 9
Training loss: 0.25843632221221924
Validation loss: 1.4644722951355802

Epoch: 6| Step: 10
Training loss: 0.09493730962276459
Validation loss: 1.463458647010147

Epoch: 6| Step: 11
Training loss: 0.13620755076408386
Validation loss: 1.471204734617664

Epoch: 6| Step: 12
Training loss: 0.18599680066108704
Validation loss: 1.4239379590557468

Epoch: 6| Step: 13
Training loss: 0.111097052693367
Validation loss: 1.4197296231023726

Epoch: 493| Step: 0
Training loss: 0.16180044412612915
Validation loss: 1.3953886044922696

Epoch: 6| Step: 1
Training loss: 0.0810077115893364
Validation loss: 1.4178893707131828

Epoch: 6| Step: 2
Training loss: 0.045852985233068466
Validation loss: 1.4284915193434684

Epoch: 6| Step: 3
Training loss: 0.14714185893535614
Validation loss: 1.4539851527060232

Epoch: 6| Step: 4
Training loss: 0.07716703414916992
Validation loss: 1.468715674133711

Epoch: 6| Step: 5
Training loss: 0.09799830615520477
Validation loss: 1.4724490719456826

Epoch: 6| Step: 6
Training loss: 0.14406347274780273
Validation loss: 1.5084546945428337

Epoch: 6| Step: 7
Training loss: 0.07152163982391357
Validation loss: 1.486291076547356

Epoch: 6| Step: 8
Training loss: 0.10740603506565094
Validation loss: 1.4877931648685085

Epoch: 6| Step: 9
Training loss: 0.08321337401866913
Validation loss: 1.4553590468181077

Epoch: 6| Step: 10
Training loss: 0.1582135558128357
Validation loss: 1.419873745210709

Epoch: 6| Step: 11
Training loss: 0.19518670439720154
Validation loss: 1.3845102646017586

Epoch: 6| Step: 12
Training loss: 0.16091567277908325
Validation loss: 1.3769929857664212

Epoch: 6| Step: 13
Training loss: 0.10141628235578537
Validation loss: 1.3911305345514768

Epoch: 494| Step: 0
Training loss: 0.13138434290885925
Validation loss: 1.367731830125214

Epoch: 6| Step: 1
Training loss: 0.07968788594007492
Validation loss: 1.3759284275834278

Epoch: 6| Step: 2
Training loss: 0.10904091596603394
Validation loss: 1.3788572972820652

Epoch: 6| Step: 3
Training loss: 0.09249725937843323
Validation loss: 1.3895629490575483

Epoch: 6| Step: 4
Training loss: 0.07398393750190735
Validation loss: 1.4121891183237876

Epoch: 6| Step: 5
Training loss: 0.10589368641376495
Validation loss: 1.4030080687615178

Epoch: 6| Step: 6
Training loss: 0.0924210175871849
Validation loss: 1.4168195416850429

Epoch: 6| Step: 7
Training loss: 0.1749427765607834
Validation loss: 1.4408872460806241

Epoch: 6| Step: 8
Training loss: 0.0934472605586052
Validation loss: 1.461858408425444

Epoch: 6| Step: 9
Training loss: 0.1609252691268921
Validation loss: 1.4449245904081611

Epoch: 6| Step: 10
Training loss: 0.07362349331378937
Validation loss: 1.5036957712583645

Epoch: 6| Step: 11
Training loss: 0.15537524223327637
Validation loss: 1.5147944996433873

Epoch: 6| Step: 12
Training loss: 0.2077975571155548
Validation loss: 1.4980262825565953

Epoch: 6| Step: 13
Training loss: 0.165420800447464
Validation loss: 1.4719273877400223

Epoch: 495| Step: 0
Training loss: 0.09309704601764679
Validation loss: 1.4344354041161076

Epoch: 6| Step: 1
Training loss: 0.07027942687273026
Validation loss: 1.428811562958584

Epoch: 6| Step: 2
Training loss: 0.25150609016418457
Validation loss: 1.3897196477459324

Epoch: 6| Step: 3
Training loss: 0.08161933720111847
Validation loss: 1.3757411587622859

Epoch: 6| Step: 4
Training loss: 0.08990326523780823
Validation loss: 1.3710348580473213

Epoch: 6| Step: 5
Training loss: 0.1870429962873459
Validation loss: 1.3717621359773862

Epoch: 6| Step: 6
Training loss: 0.09619683772325516
Validation loss: 1.384264338401056

Epoch: 6| Step: 7
Training loss: 0.16200001537799835
Validation loss: 1.3986535097963066

Epoch: 6| Step: 8
Training loss: 0.08761438727378845
Validation loss: 1.4099851154511975

Epoch: 6| Step: 9
Training loss: 0.15692582726478577
Validation loss: 1.3981414879522016

Epoch: 6| Step: 10
Training loss: 0.12751637399196625
Validation loss: 1.4224804960271364

Epoch: 6| Step: 11
Training loss: 0.14564360678195953
Validation loss: 1.430468580735627

Epoch: 6| Step: 12
Training loss: 0.08337555825710297
Validation loss: 1.463541038574711

Epoch: 6| Step: 13
Training loss: 0.13280925154685974
Validation loss: 1.4656684257650887

Epoch: 496| Step: 0
Training loss: 0.08687753975391388
Validation loss: 1.4708819575207208

Epoch: 6| Step: 1
Training loss: 0.10765114426612854
Validation loss: 1.4873169801568473

Epoch: 6| Step: 2
Training loss: 0.14254134893417358
Validation loss: 1.4658989470492128

Epoch: 6| Step: 3
Training loss: 0.06256000697612762
Validation loss: 1.4480089974659744

Epoch: 6| Step: 4
Training loss: 0.09832468628883362
Validation loss: 1.4474731702958383

Epoch: 6| Step: 5
Training loss: 0.1499614417552948
Validation loss: 1.4529035898946947

Epoch: 6| Step: 6
Training loss: 0.1574476659297943
Validation loss: 1.448605336168761

Epoch: 6| Step: 7
Training loss: 0.125522643327713
Validation loss: 1.432896642274754

Epoch: 6| Step: 8
Training loss: 0.22527508437633514
Validation loss: 1.4290178168204524

Epoch: 6| Step: 9
Training loss: 0.114863321185112
Validation loss: 1.4386170576977473

Epoch: 6| Step: 10
Training loss: 0.13905635476112366
Validation loss: 1.4432054745253695

Epoch: 6| Step: 11
Training loss: 0.056349437683820724
Validation loss: 1.4418431789644304

Epoch: 6| Step: 12
Training loss: 0.14620909094810486
Validation loss: 1.4641058726977276

Epoch: 6| Step: 13
Training loss: 0.05909454822540283
Validation loss: 1.4755119533949002

Epoch: 497| Step: 0
Training loss: 0.22231218218803406
Validation loss: 1.4996605201434063

Epoch: 6| Step: 1
Training loss: 0.10068538784980774
Validation loss: 1.5236459355200491

Epoch: 6| Step: 2
Training loss: 0.15362340211868286
Validation loss: 1.5277815352204025

Epoch: 6| Step: 3
Training loss: 0.10044004023075104
Validation loss: 1.5214779735893331

Epoch: 6| Step: 4
Training loss: 0.10249638557434082
Validation loss: 1.4932800723660378

Epoch: 6| Step: 5
Training loss: 0.20165947079658508
Validation loss: 1.5145538071150422

Epoch: 6| Step: 6
Training loss: 0.06500433385372162
Validation loss: 1.4588103602009435

Epoch: 6| Step: 7
Training loss: 0.11563161760568619
Validation loss: 1.4493366390146234

Epoch: 6| Step: 8
Training loss: 0.0599205382168293
Validation loss: 1.4295784004272953

Epoch: 6| Step: 9
Training loss: 0.15087690949440002
Validation loss: 1.440474711438661

Epoch: 6| Step: 10
Training loss: 0.21591980755329132
Validation loss: 1.4144110589899042

Epoch: 6| Step: 11
Training loss: 0.1535106897354126
Validation loss: 1.3816640319362763

Epoch: 6| Step: 12
Training loss: 0.14466601610183716
Validation loss: 1.3871854505231302

Epoch: 6| Step: 13
Training loss: 0.035746436566114426
Validation loss: 1.3807685272667998

Epoch: 498| Step: 0
Training loss: 0.14929792284965515
Validation loss: 1.3914667893481512

Epoch: 6| Step: 1
Training loss: 0.06781159341335297
Validation loss: 1.4132884779284078

Epoch: 6| Step: 2
Training loss: 0.14063650369644165
Validation loss: 1.396084120196681

Epoch: 6| Step: 3
Training loss: 0.06106596812605858
Validation loss: 1.4172567821318103

Epoch: 6| Step: 4
Training loss: 0.10495175421237946
Validation loss: 1.4263869485547465

Epoch: 6| Step: 5
Training loss: 0.06050068885087967
Validation loss: 1.4303117016310334

Epoch: 6| Step: 6
Training loss: 0.1054515689611435
Validation loss: 1.4683475411066444

Epoch: 6| Step: 7
Training loss: 0.11862701922655106
Validation loss: 1.4819392555503434

Epoch: 6| Step: 8
Training loss: 0.11094063520431519
Validation loss: 1.478526807600452

Epoch: 6| Step: 9
Training loss: 0.09627625346183777
Validation loss: 1.4704772631327312

Epoch: 6| Step: 10
Training loss: 0.1438872218132019
Validation loss: 1.4614055400253625

Epoch: 6| Step: 11
Training loss: 0.08501125872135162
Validation loss: 1.470253470123455

Epoch: 6| Step: 12
Training loss: 0.0734529197216034
Validation loss: 1.4529812733332317

Epoch: 6| Step: 13
Training loss: 0.21344000101089478
Validation loss: 1.4547273100063365

Epoch: 499| Step: 0
Training loss: 0.10509902983903885
Validation loss: 1.4717145158398537

Epoch: 6| Step: 1
Training loss: 0.2165001481771469
Validation loss: 1.4745432228170416

Epoch: 6| Step: 2
Training loss: 0.05909501761198044
Validation loss: 1.4559582907666442

Epoch: 6| Step: 3
Training loss: 0.07930891215801239
Validation loss: 1.4636665595475065

Epoch: 6| Step: 4
Training loss: 0.05395808070898056
Validation loss: 1.4663793053678287

Epoch: 6| Step: 5
Training loss: 0.05401977151632309
Validation loss: 1.479121877942034

Epoch: 6| Step: 6
Training loss: 0.1255943924188614
Validation loss: 1.4504001935323079

Epoch: 6| Step: 7
Training loss: 0.0598653182387352
Validation loss: 1.4655186123745416

Epoch: 6| Step: 8
Training loss: 0.06667404621839523
Validation loss: 1.4646267185929

Epoch: 6| Step: 9
Training loss: 0.13900794088840485
Validation loss: 1.4289777676264446

Epoch: 6| Step: 10
Training loss: 0.11259844899177551
Validation loss: 1.4589884627249934

Epoch: 6| Step: 11
Training loss: 0.09471064060926437
Validation loss: 1.4265806880048526

Epoch: 6| Step: 12
Training loss: 0.12137993425130844
Validation loss: 1.4283616235179286

Epoch: 6| Step: 13
Training loss: 0.1141267865896225
Validation loss: 1.38645371314018

Epoch: 500| Step: 0
Training loss: 0.03607594221830368
Validation loss: 1.3913108828247234

Epoch: 6| Step: 1
Training loss: 0.07474450767040253
Validation loss: 1.3648144839912333

Epoch: 6| Step: 2
Training loss: 0.11272573471069336
Validation loss: 1.3548609787417996

Epoch: 6| Step: 3
Training loss: 0.13366341590881348
Validation loss: 1.3558966190584245

Epoch: 6| Step: 4
Training loss: 0.09649336338043213
Validation loss: 1.36006006245972

Epoch: 6| Step: 5
Training loss: 0.21214061975479126
Validation loss: 1.3702262986090876

Epoch: 6| Step: 6
Training loss: 0.07726730406284332
Validation loss: 1.371460049383102

Epoch: 6| Step: 7
Training loss: 0.14576737582683563
Validation loss: 1.3816768046348327

Epoch: 6| Step: 8
Training loss: 0.09440582990646362
Validation loss: 1.386477123024643

Epoch: 6| Step: 9
Training loss: 0.1119820773601532
Validation loss: 1.438347457557596

Epoch: 6| Step: 10
Training loss: 0.1210206001996994
Validation loss: 1.4619847946269537

Epoch: 6| Step: 11
Training loss: 0.16069301962852478
Validation loss: 1.466627650363471

Epoch: 6| Step: 12
Training loss: 0.16642753779888153
Validation loss: 1.4841364173478977

Epoch: 6| Step: 13
Training loss: 0.05583369731903076
Validation loss: 1.4768182359715945

Epoch: 501| Step: 0
Training loss: 0.1703355312347412
Validation loss: 1.4558858076731365

Epoch: 6| Step: 1
Training loss: 0.10884742438793182
Validation loss: 1.4524288292854064

Epoch: 6| Step: 2
Training loss: 0.09929350018501282
Validation loss: 1.454951581134591

Epoch: 6| Step: 3
Training loss: 0.08761034160852432
Validation loss: 1.4678867324706046

Epoch: 6| Step: 4
Training loss: 0.12932348251342773
Validation loss: 1.4266240519862021

Epoch: 6| Step: 5
Training loss: 0.13978895545005798
Validation loss: 1.4314994427465624

Epoch: 6| Step: 6
Training loss: 0.06042078882455826
Validation loss: 1.4157699936179704

Epoch: 6| Step: 7
Training loss: 0.0953524187207222
Validation loss: 1.4057744010802238

Epoch: 6| Step: 8
Training loss: 0.07596578449010849
Validation loss: 1.4269913088890813

Epoch: 6| Step: 9
Training loss: 0.07736600190401077
Validation loss: 1.402771007630133

Epoch: 6| Step: 10
Training loss: 0.09170075505971909
Validation loss: 1.3901984383982997

Epoch: 6| Step: 11
Training loss: 0.0867975726723671
Validation loss: 1.4012079943892777

Epoch: 6| Step: 12
Training loss: 0.09116925299167633
Validation loss: 1.4028050989233039

Epoch: 6| Step: 13
Training loss: 0.2637987732887268
Validation loss: 1.3981806129537604

Epoch: 502| Step: 0
Training loss: 0.0942765474319458
Validation loss: 1.4304033928020026

Epoch: 6| Step: 1
Training loss: 0.07520532608032227
Validation loss: 1.4163701265088973

Epoch: 6| Step: 2
Training loss: 0.04173888638615608
Validation loss: 1.4238015618375552

Epoch: 6| Step: 3
Training loss: 0.06285466998815536
Validation loss: 1.434793983736346

Epoch: 6| Step: 4
Training loss: 0.0934704914689064
Validation loss: 1.4289796711296163

Epoch: 6| Step: 5
Training loss: 0.14688323438167572
Validation loss: 1.425742172425793

Epoch: 6| Step: 6
Training loss: 0.052182357758283615
Validation loss: 1.417104407023358

Epoch: 6| Step: 7
Training loss: 0.16850008070468903
Validation loss: 1.415737211063344

Epoch: 6| Step: 8
Training loss: 0.09672660380601883
Validation loss: 1.4458994480871386

Epoch: 6| Step: 9
Training loss: 0.1107015311717987
Validation loss: 1.4193863522621892

Epoch: 6| Step: 10
Training loss: 0.0896029993891716
Validation loss: 1.4308820732178227

Epoch: 6| Step: 11
Training loss: 0.09908386319875717
Validation loss: 1.4293279506826913

Epoch: 6| Step: 12
Training loss: 0.05323433130979538
Validation loss: 1.4121302968712264

Epoch: 6| Step: 13
Training loss: 0.10725551098585129
Validation loss: 1.4174680120201522

Epoch: 503| Step: 0
Training loss: 0.10904337465763092
Validation loss: 1.434609410583332

Epoch: 6| Step: 1
Training loss: 0.07628186792135239
Validation loss: 1.423663003470308

Epoch: 6| Step: 2
Training loss: 0.04716767370700836
Validation loss: 1.4407037611930602

Epoch: 6| Step: 3
Training loss: 0.07806728780269623
Validation loss: 1.432728381567104

Epoch: 6| Step: 4
Training loss: 0.11330097168684006
Validation loss: 1.4288975897655691

Epoch: 6| Step: 5
Training loss: 0.09304829686880112
Validation loss: 1.4328198625195412

Epoch: 6| Step: 6
Training loss: 0.09480983018875122
Validation loss: 1.4288574957078504

Epoch: 6| Step: 7
Training loss: 0.09107184410095215
Validation loss: 1.4592037803383284

Epoch: 6| Step: 8
Training loss: 0.14317366480827332
Validation loss: 1.4404689458108717

Epoch: 6| Step: 9
Training loss: 0.061092376708984375
Validation loss: 1.4364310810642857

Epoch: 6| Step: 10
Training loss: 0.12827029824256897
Validation loss: 1.4430831939943376

Epoch: 6| Step: 11
Training loss: 0.10552354902029037
Validation loss: 1.4482118211766726

Epoch: 6| Step: 12
Training loss: 0.10377360880374908
Validation loss: 1.4437327474676154

Epoch: 6| Step: 13
Training loss: 0.05918975546956062
Validation loss: 1.465692650887274

Epoch: 504| Step: 0
Training loss: 0.08579841256141663
Validation loss: 1.4594358782614432

Epoch: 6| Step: 1
Training loss: 0.0958293080329895
Validation loss: 1.433339709876686

Epoch: 6| Step: 2
Training loss: 0.08430147171020508
Validation loss: 1.4209793639439408

Epoch: 6| Step: 3
Training loss: 0.18366950750350952
Validation loss: 1.4385125957509524

Epoch: 6| Step: 4
Training loss: 0.06836912035942078
Validation loss: 1.4262474685586908

Epoch: 6| Step: 5
Training loss: 0.08246614038944244
Validation loss: 1.4165353736569803

Epoch: 6| Step: 6
Training loss: 0.06875041127204895
Validation loss: 1.4315358631072506

Epoch: 6| Step: 7
Training loss: 0.1578221172094345
Validation loss: 1.4498320215491838

Epoch: 6| Step: 8
Training loss: 0.07064291834831238
Validation loss: 1.4187873499367827

Epoch: 6| Step: 9
Training loss: 0.1009950339794159
Validation loss: 1.42227715446103

Epoch: 6| Step: 10
Training loss: 0.08073828369379044
Validation loss: 1.4197237555698683

Epoch: 6| Step: 11
Training loss: 0.06600093841552734
Validation loss: 1.4181325102365145

Epoch: 6| Step: 12
Training loss: 0.14987081289291382
Validation loss: 1.4120267065622474

Epoch: 6| Step: 13
Training loss: 0.18142113089561462
Validation loss: 1.4303187304927456

Epoch: 505| Step: 0
Training loss: 0.09141857922077179
Validation loss: 1.4437957950817641

Epoch: 6| Step: 1
Training loss: 0.14820361137390137
Validation loss: 1.455523616524153

Epoch: 6| Step: 2
Training loss: 0.094618059694767
Validation loss: 1.4397338949224001

Epoch: 6| Step: 3
Training loss: 0.07556980848312378
Validation loss: 1.4452084200356596

Epoch: 6| Step: 4
Training loss: 0.11555255949497223
Validation loss: 1.4284731200946275

Epoch: 6| Step: 5
Training loss: 0.13587945699691772
Validation loss: 1.4382563085966213

Epoch: 6| Step: 6
Training loss: 0.09163855016231537
Validation loss: 1.451049784178375

Epoch: 6| Step: 7
Training loss: 0.09635640680789948
Validation loss: 1.4034041486760622

Epoch: 6| Step: 8
Training loss: 0.21285265684127808
Validation loss: 1.4532389345989432

Epoch: 6| Step: 9
Training loss: 0.08518598973751068
Validation loss: 1.429210130245455

Epoch: 6| Step: 10
Training loss: 0.1547916978597641
Validation loss: 1.4433818671011156

Epoch: 6| Step: 11
Training loss: 0.09608297049999237
Validation loss: 1.4564960592536516

Epoch: 6| Step: 12
Training loss: 0.17393678426742554
Validation loss: 1.4562649476912715

Epoch: 6| Step: 13
Training loss: 0.10105308890342712
Validation loss: 1.4519886303973455

Epoch: 506| Step: 0
Training loss: 0.13001465797424316
Validation loss: 1.4548415727512811

Epoch: 6| Step: 1
Training loss: 0.12817302346229553
Validation loss: 1.4346448298423522

Epoch: 6| Step: 2
Training loss: 0.11221851408481598
Validation loss: 1.3974611784822197

Epoch: 6| Step: 3
Training loss: 0.13842442631721497
Validation loss: 1.4106837088061916

Epoch: 6| Step: 4
Training loss: 0.09482335299253464
Validation loss: 1.4134881086246942

Epoch: 6| Step: 5
Training loss: 0.08272945135831833
Validation loss: 1.3885197319010252

Epoch: 6| Step: 6
Training loss: 0.07689376920461655
Validation loss: 1.409437874312042

Epoch: 6| Step: 7
Training loss: 0.07860040664672852
Validation loss: 1.4119864195905707

Epoch: 6| Step: 8
Training loss: 0.06987526267766953
Validation loss: 1.413491226011707

Epoch: 6| Step: 9
Training loss: 0.0866255834698677
Validation loss: 1.4065876686444847

Epoch: 6| Step: 10
Training loss: 0.07423125207424164
Validation loss: 1.411778147502612

Epoch: 6| Step: 11
Training loss: 0.09570759534835815
Validation loss: 1.4179844087170017

Epoch: 6| Step: 12
Training loss: 0.08392082899808884
Validation loss: 1.4017881475469118

Epoch: 6| Step: 13
Training loss: 0.06760207563638687
Validation loss: 1.422902202093473

Epoch: 507| Step: 0
Training loss: 0.05633865296840668
Validation loss: 1.4330766970111477

Epoch: 6| Step: 1
Training loss: 0.0613502562046051
Validation loss: 1.435966742936001

Epoch: 6| Step: 2
Training loss: 0.1720696985721588
Validation loss: 1.4237399575530842

Epoch: 6| Step: 3
Training loss: 0.04336509481072426
Validation loss: 1.4342865572180798

Epoch: 6| Step: 4
Training loss: 0.04676198586821556
Validation loss: 1.434996743356028

Epoch: 6| Step: 5
Training loss: 0.07530893385410309
Validation loss: 1.4258434234126922

Epoch: 6| Step: 6
Training loss: 0.07759944349527359
Validation loss: 1.4394994410135413

Epoch: 6| Step: 7
Training loss: 0.12148160487413406
Validation loss: 1.4403756126280753

Epoch: 6| Step: 8
Training loss: 0.07291774451732635
Validation loss: 1.4514621637200797

Epoch: 6| Step: 9
Training loss: 0.12219163030385971
Validation loss: 1.439491259154453

Epoch: 6| Step: 10
Training loss: 0.09633680433034897
Validation loss: 1.456391494761231

Epoch: 6| Step: 11
Training loss: 0.10409626364707947
Validation loss: 1.4453793533386723

Epoch: 6| Step: 12
Training loss: 0.055933788418769836
Validation loss: 1.4610431707033547

Epoch: 6| Step: 13
Training loss: 0.078829325735569
Validation loss: 1.4390245868313698

Epoch: 508| Step: 0
Training loss: 0.08138281106948853
Validation loss: 1.4267295483619935

Epoch: 6| Step: 1
Training loss: 0.05945097655057907
Validation loss: 1.4191500192047448

Epoch: 6| Step: 2
Training loss: 0.09643489122390747
Validation loss: 1.4042057785936581

Epoch: 6| Step: 3
Training loss: 0.07824080437421799
Validation loss: 1.422416228120045

Epoch: 6| Step: 4
Training loss: 0.07007384300231934
Validation loss: 1.425671149325627

Epoch: 6| Step: 5
Training loss: 0.09002727270126343
Validation loss: 1.4415064063123477

Epoch: 6| Step: 6
Training loss: 0.0819612517952919
Validation loss: 1.4300322840290685

Epoch: 6| Step: 7
Training loss: 0.098565474152565
Validation loss: 1.443780638838327

Epoch: 6| Step: 8
Training loss: 0.08321765065193176
Validation loss: 1.4140068818164129

Epoch: 6| Step: 9
Training loss: 0.06311028450727463
Validation loss: 1.4390181097933041

Epoch: 6| Step: 10
Training loss: 0.09578043222427368
Validation loss: 1.4366134148772045

Epoch: 6| Step: 11
Training loss: 0.19357633590698242
Validation loss: 1.4371935949530652

Epoch: 6| Step: 12
Training loss: 0.09411866962909698
Validation loss: 1.426475114719842

Epoch: 6| Step: 13
Training loss: 0.0574190616607666
Validation loss: 1.4166363323888471

Epoch: 509| Step: 0
Training loss: 0.14916907250881195
Validation loss: 1.4075876256471038

Epoch: 6| Step: 1
Training loss: 0.07593226432800293
Validation loss: 1.429699485019971

Epoch: 6| Step: 2
Training loss: 0.05616593360900879
Validation loss: 1.4287510187395158

Epoch: 6| Step: 3
Training loss: 0.14688526093959808
Validation loss: 1.4380531272580546

Epoch: 6| Step: 4
Training loss: 0.08583371341228485
Validation loss: 1.4179283906054754

Epoch: 6| Step: 5
Training loss: 0.13966482877731323
Validation loss: 1.4285156697996202

Epoch: 6| Step: 6
Training loss: 0.07387551665306091
Validation loss: 1.4062118248272968

Epoch: 6| Step: 7
Training loss: 0.07548834383487701
Validation loss: 1.4106017428059732

Epoch: 6| Step: 8
Training loss: 0.08410490304231644
Validation loss: 1.4342211113181165

Epoch: 6| Step: 9
Training loss: 0.1274355947971344
Validation loss: 1.4540470928274176

Epoch: 6| Step: 10
Training loss: 0.07131169736385345
Validation loss: 1.46163696371099

Epoch: 6| Step: 11
Training loss: 0.12916876375675201
Validation loss: 1.4847281088111222

Epoch: 6| Step: 12
Training loss: 0.1020333543419838
Validation loss: 1.480183078396705

Epoch: 6| Step: 13
Training loss: 0.0777132660150528
Validation loss: 1.4779577729522542

Epoch: 510| Step: 0
Training loss: 0.07768084108829498
Validation loss: 1.4907610954776886

Epoch: 6| Step: 1
Training loss: 0.051334746181964874
Validation loss: 1.4936031462043844

Epoch: 6| Step: 2
Training loss: 0.08659202605485916
Validation loss: 1.5250575209176669

Epoch: 6| Step: 3
Training loss: 0.06149512156844139
Validation loss: 1.519529963052401

Epoch: 6| Step: 4
Training loss: 0.09432525932788849
Validation loss: 1.4990556368263819

Epoch: 6| Step: 5
Training loss: 0.09511187672615051
Validation loss: 1.5122436605474001

Epoch: 6| Step: 6
Training loss: 0.07997117936611176
Validation loss: 1.4908642576586815

Epoch: 6| Step: 7
Training loss: 0.10221744328737259
Validation loss: 1.4632052721515778

Epoch: 6| Step: 8
Training loss: 0.09372971206903458
Validation loss: 1.4532383987980504

Epoch: 6| Step: 9
Training loss: 0.18278713524341583
Validation loss: 1.4401069776986235

Epoch: 6| Step: 10
Training loss: 0.15934574604034424
Validation loss: 1.4132340685013802

Epoch: 6| Step: 11
Training loss: 0.11095257103443146
Validation loss: 1.4117634001598562

Epoch: 6| Step: 12
Training loss: 0.17258326709270477
Validation loss: 1.4237686318735923

Epoch: 6| Step: 13
Training loss: 0.07350940257310867
Validation loss: 1.4425286221247848

Epoch: 511| Step: 0
Training loss: 0.08647356182336807
Validation loss: 1.4628128787522674

Epoch: 6| Step: 1
Training loss: 0.15213578939437866
Validation loss: 1.4873596276006391

Epoch: 6| Step: 2
Training loss: 0.12744884192943573
Validation loss: 1.4966437919165498

Epoch: 6| Step: 3
Training loss: 0.07873084396123886
Validation loss: 1.4973815577004546

Epoch: 6| Step: 4
Training loss: 0.08199243992567062
Validation loss: 1.4967361342522405

Epoch: 6| Step: 5
Training loss: 0.1439601182937622
Validation loss: 1.4778376292156916

Epoch: 6| Step: 6
Training loss: 0.06900566071271896
Validation loss: 1.4796242303745721

Epoch: 6| Step: 7
Training loss: 0.056987058371305466
Validation loss: 1.46940992980875

Epoch: 6| Step: 8
Training loss: 0.05513513833284378
Validation loss: 1.461557021705053

Epoch: 6| Step: 9
Training loss: 0.13550521433353424
Validation loss: 1.4703834261945499

Epoch: 6| Step: 10
Training loss: 0.1084599420428276
Validation loss: 1.4641298664513456

Epoch: 6| Step: 11
Training loss: 0.1034984290599823
Validation loss: 1.4386561634720012

Epoch: 6| Step: 12
Training loss: 0.131323903799057
Validation loss: 1.42322338011957

Epoch: 6| Step: 13
Training loss: 0.10906587541103363
Validation loss: 1.4198453913452804

Epoch: 512| Step: 0
Training loss: 0.08905366063117981
Validation loss: 1.4233564189685288

Epoch: 6| Step: 1
Training loss: 0.09126642346382141
Validation loss: 1.4231910218474686

Epoch: 6| Step: 2
Training loss: 0.05635276436805725
Validation loss: 1.417466926318343

Epoch: 6| Step: 3
Training loss: 0.10378777235746384
Validation loss: 1.4280212861235424

Epoch: 6| Step: 4
Training loss: 0.08784063160419464
Validation loss: 1.417269613153191

Epoch: 6| Step: 5
Training loss: 0.2160477638244629
Validation loss: 1.406954901192778

Epoch: 6| Step: 6
Training loss: 0.12212765216827393
Validation loss: 1.4249741185096003

Epoch: 6| Step: 7
Training loss: 0.04696018993854523
Validation loss: 1.4440662271233016

Epoch: 6| Step: 8
Training loss: 0.13348546624183655
Validation loss: 1.4643332791584793

Epoch: 6| Step: 9
Training loss: 0.08874809741973877
Validation loss: 1.4932139317194622

Epoch: 6| Step: 10
Training loss: 0.09270573407411575
Validation loss: 1.4558272605301232

Epoch: 6| Step: 11
Training loss: 0.06342501193284988
Validation loss: 1.4702127800192883

Epoch: 6| Step: 12
Training loss: 0.11009388417005539
Validation loss: 1.4575983388449556

Epoch: 6| Step: 13
Training loss: 0.06046798452734947
Validation loss: 1.4205353119040047

Epoch: 513| Step: 0
Training loss: 0.07043029367923737
Validation loss: 1.4022122749718287

Epoch: 6| Step: 1
Training loss: 0.09698769450187683
Validation loss: 1.409736733282766

Epoch: 6| Step: 2
Training loss: 0.12085773050785065
Validation loss: 1.4209266503651936

Epoch: 6| Step: 3
Training loss: 0.16710370779037476
Validation loss: 1.4251205908354891

Epoch: 6| Step: 4
Training loss: 0.09681487083435059
Validation loss: 1.426796329918728

Epoch: 6| Step: 5
Training loss: 0.0924326479434967
Validation loss: 1.4139215471923992

Epoch: 6| Step: 6
Training loss: 0.12148638814687729
Validation loss: 1.4014030291188149

Epoch: 6| Step: 7
Training loss: 0.13976439833641052
Validation loss: 1.4096116955562303

Epoch: 6| Step: 8
Training loss: 0.08596137166023254
Validation loss: 1.412703271835081

Epoch: 6| Step: 9
Training loss: 0.10716262459754944
Validation loss: 1.4519659921687136

Epoch: 6| Step: 10
Training loss: 0.11580194532871246
Validation loss: 1.456418784715796

Epoch: 6| Step: 11
Training loss: 0.1424013376235962
Validation loss: 1.4602087543856712

Epoch: 6| Step: 12
Training loss: 0.06970509886741638
Validation loss: 1.4576266722012592

Epoch: 6| Step: 13
Training loss: 0.09112071990966797
Validation loss: 1.4787018965649348

Epoch: 514| Step: 0
Training loss: 0.06624039262533188
Validation loss: 1.4636273204639394

Epoch: 6| Step: 1
Training loss: 0.1296737939119339
Validation loss: 1.4519599599222983

Epoch: 6| Step: 2
Training loss: 0.12182804197072983
Validation loss: 1.4485175391679168

Epoch: 6| Step: 3
Training loss: 0.09456133842468262
Validation loss: 1.4293444207919541

Epoch: 6| Step: 4
Training loss: 0.16989803314208984
Validation loss: 1.4303685631803287

Epoch: 6| Step: 5
Training loss: 0.07374133914709091
Validation loss: 1.4339201181165633

Epoch: 6| Step: 6
Training loss: 0.10496038943529129
Validation loss: 1.4109405099704702

Epoch: 6| Step: 7
Training loss: 0.10087120532989502
Validation loss: 1.4208214821354035

Epoch: 6| Step: 8
Training loss: 0.09450198709964752
Validation loss: 1.4162038833864274

Epoch: 6| Step: 9
Training loss: 0.10958361625671387
Validation loss: 1.4281238791763142

Epoch: 6| Step: 10
Training loss: 0.10807214677333832
Validation loss: 1.4361733698075818

Epoch: 6| Step: 11
Training loss: 0.10115528851747513
Validation loss: 1.4361442583863453

Epoch: 6| Step: 12
Training loss: 0.053006261587142944
Validation loss: 1.4320632283405592

Epoch: 6| Step: 13
Training loss: 0.1851414442062378
Validation loss: 1.457906562154011

Epoch: 515| Step: 0
Training loss: 0.16245795786380768
Validation loss: 1.4934575698708976

Epoch: 6| Step: 1
Training loss: 0.06251721829175949
Validation loss: 1.5230279994267288

Epoch: 6| Step: 2
Training loss: 0.11131729185581207
Validation loss: 1.5023759488136537

Epoch: 6| Step: 3
Training loss: 0.1954408586025238
Validation loss: 1.5313381225832048

Epoch: 6| Step: 4
Training loss: 0.09085215628147125
Validation loss: 1.5251461741744832

Epoch: 6| Step: 5
Training loss: 0.09868830442428589
Validation loss: 1.5018278065548147

Epoch: 6| Step: 6
Training loss: 0.14261427521705627
Validation loss: 1.4997283104927308

Epoch: 6| Step: 7
Training loss: 0.11585879325866699
Validation loss: 1.4538379228243263

Epoch: 6| Step: 8
Training loss: 0.13494929671287537
Validation loss: 1.4309689050079675

Epoch: 6| Step: 9
Training loss: 0.08370396494865417
Validation loss: 1.3914920271083873

Epoch: 6| Step: 10
Training loss: 0.09467299282550812
Validation loss: 1.4170167087226786

Epoch: 6| Step: 11
Training loss: 0.07727913558483124
Validation loss: 1.4059623819525524

Epoch: 6| Step: 12
Training loss: 0.11155465245246887
Validation loss: 1.4186873012973416

Epoch: 6| Step: 13
Training loss: 0.1267092078924179
Validation loss: 1.4053296504482147

Epoch: 516| Step: 0
Training loss: 0.11583029478788376
Validation loss: 1.4048879338848976

Epoch: 6| Step: 1
Training loss: 0.0921262577176094
Validation loss: 1.419819821593582

Epoch: 6| Step: 2
Training loss: 0.15357066690921783
Validation loss: 1.4592317688849665

Epoch: 6| Step: 3
Training loss: 0.0698164850473404
Validation loss: 1.4428282348058556

Epoch: 6| Step: 4
Training loss: 0.1521218717098236
Validation loss: 1.4209814225473711

Epoch: 6| Step: 5
Training loss: 0.11013060063123703
Validation loss: 1.4367315384649462

Epoch: 6| Step: 6
Training loss: 0.14293083548545837
Validation loss: 1.4350603434347338

Epoch: 6| Step: 7
Training loss: 0.07779020071029663
Validation loss: 1.4434787246488756

Epoch: 6| Step: 8
Training loss: 0.06914319097995758
Validation loss: 1.4275199341517624

Epoch: 6| Step: 9
Training loss: 0.07789412140846252
Validation loss: 1.4366735912138415

Epoch: 6| Step: 10
Training loss: 0.11871829628944397
Validation loss: 1.4421850494159165

Epoch: 6| Step: 11
Training loss: 0.023208634927868843
Validation loss: 1.4048104811740179

Epoch: 6| Step: 12
Training loss: 0.06119665876030922
Validation loss: 1.432524460618214

Epoch: 6| Step: 13
Training loss: 0.0453617125749588
Validation loss: 1.4258975213573826

Epoch: 517| Step: 0
Training loss: 0.09299719333648682
Validation loss: 1.4133363898082445

Epoch: 6| Step: 1
Training loss: 0.09499506652355194
Validation loss: 1.4039968406000445

Epoch: 6| Step: 2
Training loss: 0.0901373103260994
Validation loss: 1.4225549249238865

Epoch: 6| Step: 3
Training loss: 0.06716811656951904
Validation loss: 1.4291377182929748

Epoch: 6| Step: 4
Training loss: 0.07712727785110474
Validation loss: 1.424986796994363

Epoch: 6| Step: 5
Training loss: 0.08490630984306335
Validation loss: 1.4268431996786466

Epoch: 6| Step: 6
Training loss: 0.1197129338979721
Validation loss: 1.403547361332883

Epoch: 6| Step: 7
Training loss: 0.06254912912845612
Validation loss: 1.396153401303035

Epoch: 6| Step: 8
Training loss: 0.08731056749820709
Validation loss: 1.4156866137699415

Epoch: 6| Step: 9
Training loss: 0.09732025116682053
Validation loss: 1.4033696382276473

Epoch: 6| Step: 10
Training loss: 0.06843738257884979
Validation loss: 1.4068660248992264

Epoch: 6| Step: 11
Training loss: 0.12395535409450531
Validation loss: 1.4066503086397726

Epoch: 6| Step: 12
Training loss: 0.11903318762779236
Validation loss: 1.391635456392842

Epoch: 6| Step: 13
Training loss: 0.0924806073307991
Validation loss: 1.3970754659304054

Epoch: 518| Step: 0
Training loss: 0.09087374806404114
Validation loss: 1.3913687390665854

Epoch: 6| Step: 1
Training loss: 0.049250148236751556
Validation loss: 1.3779354774823753

Epoch: 6| Step: 2
Training loss: 0.14759859442710876
Validation loss: 1.3902368814714494

Epoch: 6| Step: 3
Training loss: 0.09730394929647446
Validation loss: 1.3996104674954568

Epoch: 6| Step: 4
Training loss: 0.10034827888011932
Validation loss: 1.4258725130429832

Epoch: 6| Step: 5
Training loss: 0.05381982773542404
Validation loss: 1.4381223468370334

Epoch: 6| Step: 6
Training loss: 0.06404925137758255
Validation loss: 1.4475329345272434

Epoch: 6| Step: 7
Training loss: 0.06781864166259766
Validation loss: 1.447564692907436

Epoch: 6| Step: 8
Training loss: 0.10120769590139389
Validation loss: 1.4632080754926127

Epoch: 6| Step: 9
Training loss: 0.08243422210216522
Validation loss: 1.4449358024904806

Epoch: 6| Step: 10
Training loss: 0.0485675111413002
Validation loss: 1.440982207175224

Epoch: 6| Step: 11
Training loss: 0.12553012371063232
Validation loss: 1.425631796160052

Epoch: 6| Step: 12
Training loss: 0.10507997125387192
Validation loss: 1.426082012473896

Epoch: 6| Step: 13
Training loss: 0.07594108581542969
Validation loss: 1.4128126252082087

Epoch: 519| Step: 0
Training loss: 0.09685496240854263
Validation loss: 1.4083429280147757

Epoch: 6| Step: 1
Training loss: 0.049802567809820175
Validation loss: 1.4086088236942087

Epoch: 6| Step: 2
Training loss: 0.06373542547225952
Validation loss: 1.4053111242991623

Epoch: 6| Step: 3
Training loss: 0.055634524673223495
Validation loss: 1.43617570272056

Epoch: 6| Step: 4
Training loss: 0.08428996801376343
Validation loss: 1.4245666675670172

Epoch: 6| Step: 5
Training loss: 0.17152968049049377
Validation loss: 1.4184618906308246

Epoch: 6| Step: 6
Training loss: 0.0705641657114029
Validation loss: 1.4178798493518625

Epoch: 6| Step: 7
Training loss: 0.08290261030197144
Validation loss: 1.423482079659739

Epoch: 6| Step: 8
Training loss: 0.11632838845252991
Validation loss: 1.4128353852097706

Epoch: 6| Step: 9
Training loss: 0.07814963907003403
Validation loss: 1.416028457303201

Epoch: 6| Step: 10
Training loss: 0.12639722228050232
Validation loss: 1.42224205822073

Epoch: 6| Step: 11
Training loss: 0.09002517908811569
Validation loss: 1.4122499894070368

Epoch: 6| Step: 12
Training loss: 0.05101408064365387
Validation loss: 1.4526300814843947

Epoch: 6| Step: 13
Training loss: 0.05288436636328697
Validation loss: 1.4567689998175508

Epoch: 520| Step: 0
Training loss: 0.08032165467739105
Validation loss: 1.452286881785239

Epoch: 6| Step: 1
Training loss: 0.12656882405281067
Validation loss: 1.477378527323405

Epoch: 6| Step: 2
Training loss: 0.053026605397462845
Validation loss: 1.4732972178407895

Epoch: 6| Step: 3
Training loss: 0.10591381788253784
Validation loss: 1.5068683034630233

Epoch: 6| Step: 4
Training loss: 0.10832162946462631
Validation loss: 1.4802311261494954

Epoch: 6| Step: 5
Training loss: 0.07966069877147675
Validation loss: 1.4460424543708883

Epoch: 6| Step: 6
Training loss: 0.1849946230649948
Validation loss: 1.4510933455600534

Epoch: 6| Step: 7
Training loss: 0.13942331075668335
Validation loss: 1.450775320171028

Epoch: 6| Step: 8
Training loss: 0.18976753950119019
Validation loss: 1.437008547526534

Epoch: 6| Step: 9
Training loss: 0.05883568897843361
Validation loss: 1.4387167102547103

Epoch: 6| Step: 10
Training loss: 0.06416060030460358
Validation loss: 1.4191159432934177

Epoch: 6| Step: 11
Training loss: 0.07649418711662292
Validation loss: 1.4247964005316458

Epoch: 6| Step: 12
Training loss: 0.13432817161083221
Validation loss: 1.4097344324152956

Epoch: 6| Step: 13
Training loss: 0.09746429324150085
Validation loss: 1.4591644015363467

Epoch: 521| Step: 0
Training loss: 0.1549340784549713
Validation loss: 1.4621294711225776

Epoch: 6| Step: 1
Training loss: 0.09226522594690323
Validation loss: 1.44713286430605

Epoch: 6| Step: 2
Training loss: 0.08732262253761292
Validation loss: 1.4455121364644778

Epoch: 6| Step: 3
Training loss: 0.14378772675991058
Validation loss: 1.4433380942190848

Epoch: 6| Step: 4
Training loss: 0.04955120384693146
Validation loss: 1.4276797681726434

Epoch: 6| Step: 5
Training loss: 0.10498108714818954
Validation loss: 1.4272021529495076

Epoch: 6| Step: 6
Training loss: 0.04167359322309494
Validation loss: 1.4225553479245914

Epoch: 6| Step: 7
Training loss: 0.06894572079181671
Validation loss: 1.4416669607162476

Epoch: 6| Step: 8
Training loss: 0.06797626614570618
Validation loss: 1.4216230197619366

Epoch: 6| Step: 9
Training loss: 0.05890531465411186
Validation loss: 1.4187030382053827

Epoch: 6| Step: 10
Training loss: 0.07539662718772888
Validation loss: 1.4144058919722033

Epoch: 6| Step: 11
Training loss: 0.14629648625850677
Validation loss: 1.4212796252260926

Epoch: 6| Step: 12
Training loss: 0.05097826570272446
Validation loss: 1.4215304223440026

Epoch: 6| Step: 13
Training loss: 0.06364236772060394
Validation loss: 1.4294330714851298

Epoch: 522| Step: 0
Training loss: 0.08658330887556076
Validation loss: 1.408980050394612

Epoch: 6| Step: 1
Training loss: 0.09515154361724854
Validation loss: 1.408734465158114

Epoch: 6| Step: 2
Training loss: 0.11335553228855133
Validation loss: 1.4076057698137017

Epoch: 6| Step: 3
Training loss: 0.1052096039056778
Validation loss: 1.409811386498072

Epoch: 6| Step: 4
Training loss: 0.09101327508687973
Validation loss: 1.4163612614395797

Epoch: 6| Step: 5
Training loss: 0.032503642141819
Validation loss: 1.4055881525880547

Epoch: 6| Step: 6
Training loss: 0.09558793157339096
Validation loss: 1.4063302240064066

Epoch: 6| Step: 7
Training loss: 0.05307324230670929
Validation loss: 1.4288808024057778

Epoch: 6| Step: 8
Training loss: 0.11432299017906189
Validation loss: 1.4105304018143685

Epoch: 6| Step: 9
Training loss: 0.0689820945262909
Validation loss: 1.4197230313413887

Epoch: 6| Step: 10
Training loss: 0.1391761749982834
Validation loss: 1.3979381098542163

Epoch: 6| Step: 11
Training loss: 0.11920619010925293
Validation loss: 1.400944878978114

Epoch: 6| Step: 12
Training loss: 0.07603555917739868
Validation loss: 1.429037473535025

Epoch: 6| Step: 13
Training loss: 0.09358348697423935
Validation loss: 1.4432351999385382

Epoch: 523| Step: 0
Training loss: 0.11583015322685242
Validation loss: 1.4459160630420973

Epoch: 6| Step: 1
Training loss: 0.04569816589355469
Validation loss: 1.4390167895183767

Epoch: 6| Step: 2
Training loss: 0.05448021739721298
Validation loss: 1.4331237257167857

Epoch: 6| Step: 3
Training loss: 0.11693587899208069
Validation loss: 1.4141193013037405

Epoch: 6| Step: 4
Training loss: 0.09458856284618378
Validation loss: 1.4069514941143733

Epoch: 6| Step: 5
Training loss: 0.0707208514213562
Validation loss: 1.4161434814494143

Epoch: 6| Step: 6
Training loss: 0.14184021949768066
Validation loss: 1.4149258047021844

Epoch: 6| Step: 7
Training loss: 0.061208464205265045
Validation loss: 1.397040597854122

Epoch: 6| Step: 8
Training loss: 0.06836859881877899
Validation loss: 1.4132352144487443

Epoch: 6| Step: 9
Training loss: 0.1219407394528389
Validation loss: 1.4105454760213052

Epoch: 6| Step: 10
Training loss: 0.05243958532810211
Validation loss: 1.4240209876850087

Epoch: 6| Step: 11
Training loss: 0.06790097057819366
Validation loss: 1.4008155317716702

Epoch: 6| Step: 12
Training loss: 0.14874182641506195
Validation loss: 1.415840015616468

Epoch: 6| Step: 13
Training loss: 0.056484367698431015
Validation loss: 1.404984652355153

Epoch: 524| Step: 0
Training loss: 0.09022333472967148
Validation loss: 1.418754562254875

Epoch: 6| Step: 1
Training loss: 0.047774624079465866
Validation loss: 1.3901938110269525

Epoch: 6| Step: 2
Training loss: 0.09518908709287643
Validation loss: 1.374494416739351

Epoch: 6| Step: 3
Training loss: 0.15125373005867004
Validation loss: 1.3868105949894074

Epoch: 6| Step: 4
Training loss: 0.10322935879230499
Validation loss: 1.3959430084433606

Epoch: 6| Step: 5
Training loss: 0.04432743042707443
Validation loss: 1.402973803140784

Epoch: 6| Step: 6
Training loss: 0.052450958639383316
Validation loss: 1.376354089347265

Epoch: 6| Step: 7
Training loss: 0.1666412204504013
Validation loss: 1.4011949800675916

Epoch: 6| Step: 8
Training loss: 0.0790792852640152
Validation loss: 1.3952578460016558

Epoch: 6| Step: 9
Training loss: 0.06870481371879578
Validation loss: 1.4151052851830759

Epoch: 6| Step: 10
Training loss: 0.1122877448797226
Validation loss: 1.4063655009833715

Epoch: 6| Step: 11
Training loss: 0.09736838936805725
Validation loss: 1.4049713227056688

Epoch: 6| Step: 12
Training loss: 0.18559493124485016
Validation loss: 1.412714260880665

Epoch: 6| Step: 13
Training loss: 0.08749278634786606
Validation loss: 1.4003620929615472

Epoch: 525| Step: 0
Training loss: 0.12829944491386414
Validation loss: 1.4271569880106116

Epoch: 6| Step: 1
Training loss: 0.09277954697608948
Validation loss: 1.4014958566234959

Epoch: 6| Step: 2
Training loss: 0.062223169952631
Validation loss: 1.422271760561133

Epoch: 6| Step: 3
Training loss: 0.0888976901769638
Validation loss: 1.4217367745855802

Epoch: 6| Step: 4
Training loss: 0.05474470183253288
Validation loss: 1.4030752899826213

Epoch: 6| Step: 5
Training loss: 0.07545540481805801
Validation loss: 1.400993145922179

Epoch: 6| Step: 6
Training loss: 0.058044061064720154
Validation loss: 1.4027607556312316

Epoch: 6| Step: 7
Training loss: 0.1289147287607193
Validation loss: 1.3870483495855843

Epoch: 6| Step: 8
Training loss: 0.15166504681110382
Validation loss: 1.428180778539309

Epoch: 6| Step: 9
Training loss: 0.09184449911117554
Validation loss: 1.4274667507858687

Epoch: 6| Step: 10
Training loss: 0.08059529960155487
Validation loss: 1.4319458546177033

Epoch: 6| Step: 11
Training loss: 0.11113418638706207
Validation loss: 1.4237959833555325

Epoch: 6| Step: 12
Training loss: 0.09800009429454803
Validation loss: 1.4290920457532328

Epoch: 6| Step: 13
Training loss: 0.06324183940887451
Validation loss: 1.429537659050316

Epoch: 526| Step: 0
Training loss: 0.09077639877796173
Validation loss: 1.4404499409019307

Epoch: 6| Step: 1
Training loss: 0.07743659615516663
Validation loss: 1.4994732679859284

Epoch: 6| Step: 2
Training loss: 0.10520967096090317
Validation loss: 1.4714511882874273

Epoch: 6| Step: 3
Training loss: 0.06627234071493149
Validation loss: 1.4421689792345929

Epoch: 6| Step: 4
Training loss: 0.054386038333177567
Validation loss: 1.4371261007042342

Epoch: 6| Step: 5
Training loss: 0.07531869411468506
Validation loss: 1.4346696099927347

Epoch: 6| Step: 6
Training loss: 0.05787726119160652
Validation loss: 1.4144553728001092

Epoch: 6| Step: 7
Training loss: 0.12398902326822281
Validation loss: 1.42181824099633

Epoch: 6| Step: 8
Training loss: 0.10160309076309204
Validation loss: 1.413492020740304

Epoch: 6| Step: 9
Training loss: 0.10519550740718842
Validation loss: 1.422121100528266

Epoch: 6| Step: 10
Training loss: 0.1134551614522934
Validation loss: 1.4167362284916702

Epoch: 6| Step: 11
Training loss: 0.07557840645313263
Validation loss: 1.4403398870139994

Epoch: 6| Step: 12
Training loss: 0.15443460643291473
Validation loss: 1.4277193354022117

Epoch: 6| Step: 13
Training loss: 0.02498294599354267
Validation loss: 1.4197590197286298

Epoch: 527| Step: 0
Training loss: 0.05061754584312439
Validation loss: 1.4492062945519724

Epoch: 6| Step: 1
Training loss: 0.07708129286766052
Validation loss: 1.4293985751367384

Epoch: 6| Step: 2
Training loss: 0.04858238250017166
Validation loss: 1.4358423550923665

Epoch: 6| Step: 3
Training loss: 0.055085644125938416
Validation loss: 1.4314492184628722

Epoch: 6| Step: 4
Training loss: 0.060173291712999344
Validation loss: 1.433732573704053

Epoch: 6| Step: 5
Training loss: 0.22863729298114777
Validation loss: 1.4213676183454451

Epoch: 6| Step: 6
Training loss: 0.05822908878326416
Validation loss: 1.434763781486019

Epoch: 6| Step: 7
Training loss: 0.061380866914987564
Validation loss: 1.4552511809974589

Epoch: 6| Step: 8
Training loss: 0.119984470307827
Validation loss: 1.4503864883094706

Epoch: 6| Step: 9
Training loss: 0.05708884447813034
Validation loss: 1.4595004191962622

Epoch: 6| Step: 10
Training loss: 0.08891613036394119
Validation loss: 1.4491444044215704

Epoch: 6| Step: 11
Training loss: 0.09897860884666443
Validation loss: 1.4326419215048514

Epoch: 6| Step: 12
Training loss: 0.08508866280317307
Validation loss: 1.436931461416265

Epoch: 6| Step: 13
Training loss: 0.12160608172416687
Validation loss: 1.410240770668112

Epoch: 528| Step: 0
Training loss: 0.08123908936977386
Validation loss: 1.432830987438079

Epoch: 6| Step: 1
Training loss: 0.09183626621961594
Validation loss: 1.3972015137313514

Epoch: 6| Step: 2
Training loss: 0.056800276041030884
Validation loss: 1.4199659683371102

Epoch: 6| Step: 3
Training loss: 0.0939393937587738
Validation loss: 1.427719602020838

Epoch: 6| Step: 4
Training loss: 0.08823979645967484
Validation loss: 1.4419889475709649

Epoch: 6| Step: 5
Training loss: 0.1145789846777916
Validation loss: 1.424795663484963

Epoch: 6| Step: 6
Training loss: 0.06458421051502228
Validation loss: 1.4186036112487956

Epoch: 6| Step: 7
Training loss: 0.0831010714173317
Validation loss: 1.4061001680230583

Epoch: 6| Step: 8
Training loss: 0.060474880039691925
Validation loss: 1.3913524932758783

Epoch: 6| Step: 9
Training loss: 0.10641306638717651
Validation loss: 1.392343844136884

Epoch: 6| Step: 10
Training loss: 0.07485808432102203
Validation loss: 1.4146367606296335

Epoch: 6| Step: 11
Training loss: 0.1746348887681961
Validation loss: 1.3921144905910696

Epoch: 6| Step: 12
Training loss: 0.061838194727897644
Validation loss: 1.4131603446058048

Epoch: 6| Step: 13
Training loss: 0.1638144850730896
Validation loss: 1.4115021895336848

Epoch: 529| Step: 0
Training loss: 0.0845574215054512
Validation loss: 1.4255688933915989

Epoch: 6| Step: 1
Training loss: 0.1699964553117752
Validation loss: 1.441097185175906

Epoch: 6| Step: 2
Training loss: 0.07392485439777374
Validation loss: 1.4420437607713925

Epoch: 6| Step: 3
Training loss: 0.1106097549200058
Validation loss: 1.4515956306970248

Epoch: 6| Step: 4
Training loss: 0.0891876295208931
Validation loss: 1.4551041497979114

Epoch: 6| Step: 5
Training loss: 0.0829528272151947
Validation loss: 1.4492015197712889

Epoch: 6| Step: 6
Training loss: 0.09576386213302612
Validation loss: 1.44416953286817

Epoch: 6| Step: 7
Training loss: 0.04596947133541107
Validation loss: 1.4392766183422459

Epoch: 6| Step: 8
Training loss: 0.0806775689125061
Validation loss: 1.4284258978341215

Epoch: 6| Step: 9
Training loss: 0.07654175907373428
Validation loss: 1.4205636003965973

Epoch: 6| Step: 10
Training loss: 0.052472807466983795
Validation loss: 1.4044049862892396

Epoch: 6| Step: 11
Training loss: 0.07719895243644714
Validation loss: 1.4164160028580697

Epoch: 6| Step: 12
Training loss: 0.14542457461357117
Validation loss: 1.4007058041070097

Epoch: 6| Step: 13
Training loss: 0.05635946989059448
Validation loss: 1.3966244298924682

Epoch: 530| Step: 0
Training loss: 0.09349817037582397
Validation loss: 1.4117884251379198

Epoch: 6| Step: 1
Training loss: 0.08684161305427551
Validation loss: 1.421555325549136

Epoch: 6| Step: 2
Training loss: 0.06740307807922363
Validation loss: 1.4395479117670367

Epoch: 6| Step: 3
Training loss: 0.11930292844772339
Validation loss: 1.424170651743489

Epoch: 6| Step: 4
Training loss: 0.07139658182859421
Validation loss: 1.4636722809524947

Epoch: 6| Step: 5
Training loss: 0.08344752341508865
Validation loss: 1.4767800864352976

Epoch: 6| Step: 6
Training loss: 0.1126534640789032
Validation loss: 1.4670821761572233

Epoch: 6| Step: 7
Training loss: 0.0882602110505104
Validation loss: 1.4632551106073524

Epoch: 6| Step: 8
Training loss: 0.1325361579656601
Validation loss: 1.4570235744599374

Epoch: 6| Step: 9
Training loss: 0.19179955124855042
Validation loss: 1.4775620263109925

Epoch: 6| Step: 10
Training loss: 0.1295526921749115
Validation loss: 1.4253341985005203

Epoch: 6| Step: 11
Training loss: 0.07072716951370239
Validation loss: 1.4170676418530044

Epoch: 6| Step: 12
Training loss: 0.0858287513256073
Validation loss: 1.3965659782450686

Epoch: 6| Step: 13
Training loss: 0.0598127506673336
Validation loss: 1.3710803511322185

Epoch: 531| Step: 0
Training loss: 0.12940861284732819
Validation loss: 1.361021363607017

Epoch: 6| Step: 1
Training loss: 0.05801932141184807
Validation loss: 1.3722358147303264

Epoch: 6| Step: 2
Training loss: 0.11540166288614273
Validation loss: 1.3643964009900247

Epoch: 6| Step: 3
Training loss: 0.0727272778749466
Validation loss: 1.3645116821412118

Epoch: 6| Step: 4
Training loss: 0.0812368094921112
Validation loss: 1.3884391900031798

Epoch: 6| Step: 5
Training loss: 0.04659859091043472
Validation loss: 1.3768895550440716

Epoch: 6| Step: 6
Training loss: 0.09353141486644745
Validation loss: 1.3818697775563886

Epoch: 6| Step: 7
Training loss: 0.05065292492508888
Validation loss: 1.3690202338721162

Epoch: 6| Step: 8
Training loss: 0.059533167630434036
Validation loss: 1.3944337432102492

Epoch: 6| Step: 9
Training loss: 0.08109478652477264
Validation loss: 1.4196993099745883

Epoch: 6| Step: 10
Training loss: 0.07742560654878616
Validation loss: 1.4396142190502537

Epoch: 6| Step: 11
Training loss: 0.09169761836528778
Validation loss: 1.4362782791096678

Epoch: 6| Step: 12
Training loss: 0.14801394939422607
Validation loss: 1.46584100748903

Epoch: 6| Step: 13
Training loss: 0.09244444966316223
Validation loss: 1.4637586198827273

Epoch: 532| Step: 0
Training loss: 0.061386801302433014
Validation loss: 1.4622265049206313

Epoch: 6| Step: 1
Training loss: 0.07226160913705826
Validation loss: 1.4402631598134195

Epoch: 6| Step: 2
Training loss: 0.1003052294254303
Validation loss: 1.4400516094699982

Epoch: 6| Step: 3
Training loss: 0.13633766770362854
Validation loss: 1.4483533636216195

Epoch: 6| Step: 4
Training loss: 0.04811743646860123
Validation loss: 1.4382707380479383

Epoch: 6| Step: 5
Training loss: 0.05612911283969879
Validation loss: 1.466702889370662

Epoch: 6| Step: 6
Training loss: 0.0990346148610115
Validation loss: 1.4414416865635944

Epoch: 6| Step: 7
Training loss: 0.054024893790483475
Validation loss: 1.4348130303044473

Epoch: 6| Step: 8
Training loss: 0.12701445817947388
Validation loss: 1.4501091126472718

Epoch: 6| Step: 9
Training loss: 0.12676189839839935
Validation loss: 1.4406014501407582

Epoch: 6| Step: 10
Training loss: 0.12147389352321625
Validation loss: 1.4173889416520313

Epoch: 6| Step: 11
Training loss: 0.06256727874279022
Validation loss: 1.4462259507948352

Epoch: 6| Step: 12
Training loss: 0.08053494244813919
Validation loss: 1.40151765782346

Epoch: 6| Step: 13
Training loss: 0.0633372962474823
Validation loss: 1.4271915587045814

Epoch: 533| Step: 0
Training loss: 0.09311656653881073
Validation loss: 1.3962540998253772

Epoch: 6| Step: 1
Training loss: 0.06850337982177734
Validation loss: 1.4023512524943198

Epoch: 6| Step: 2
Training loss: 0.11754117161035538
Validation loss: 1.3948907083080662

Epoch: 6| Step: 3
Training loss: 0.057164281606674194
Validation loss: 1.388681971898643

Epoch: 6| Step: 4
Training loss: 0.09145481884479523
Validation loss: 1.4317378510711014

Epoch: 6| Step: 5
Training loss: 0.080042265355587
Validation loss: 1.4021177368779336

Epoch: 6| Step: 6
Training loss: 0.09688016772270203
Validation loss: 1.4412886070948776

Epoch: 6| Step: 7
Training loss: 0.09454818814992905
Validation loss: 1.4590065287005516

Epoch: 6| Step: 8
Training loss: 0.05162995681166649
Validation loss: 1.4371250265388078

Epoch: 6| Step: 9
Training loss: 0.11463750153779984
Validation loss: 1.4516401457530197

Epoch: 6| Step: 10
Training loss: 0.07860421389341354
Validation loss: 1.484680647491127

Epoch: 6| Step: 11
Training loss: 0.12951131165027618
Validation loss: 1.473564926655062

Epoch: 6| Step: 12
Training loss: 0.11204130947589874
Validation loss: 1.4642472690151584

Epoch: 6| Step: 13
Training loss: 0.17258460819721222
Validation loss: 1.471826873799806

Epoch: 534| Step: 0
Training loss: 0.06270119547843933
Validation loss: 1.4475929737091064

Epoch: 6| Step: 1
Training loss: 0.1057417020201683
Validation loss: 1.441249237265638

Epoch: 6| Step: 2
Training loss: 0.06904612481594086
Validation loss: 1.4511395577461488

Epoch: 6| Step: 3
Training loss: 0.08708001673221588
Validation loss: 1.4473138252894084

Epoch: 6| Step: 4
Training loss: 0.10027892887592316
Validation loss: 1.4213456492270193

Epoch: 6| Step: 5
Training loss: 0.15483862161636353
Validation loss: 1.4252934750690256

Epoch: 6| Step: 6
Training loss: 0.07763714343309402
Validation loss: 1.413039240144914

Epoch: 6| Step: 7
Training loss: 0.08438961207866669
Validation loss: 1.3997499007050709

Epoch: 6| Step: 8
Training loss: 0.15723592042922974
Validation loss: 1.4125833972807853

Epoch: 6| Step: 9
Training loss: 0.07551711052656174
Validation loss: 1.4162706969886698

Epoch: 6| Step: 10
Training loss: 0.12248381227254868
Validation loss: 1.4338851872310843

Epoch: 6| Step: 11
Training loss: 0.21555578708648682
Validation loss: 1.424076610354967

Epoch: 6| Step: 12
Training loss: 0.26425135135650635
Validation loss: 1.4043285077618015

Epoch: 6| Step: 13
Training loss: 0.17482131719589233
Validation loss: 1.4154070756768669

Epoch: 535| Step: 0
Training loss: 0.10109642148017883
Validation loss: 1.4146382885594522

Epoch: 6| Step: 1
Training loss: 0.21853838860988617
Validation loss: 1.4240799168104767

Epoch: 6| Step: 2
Training loss: 0.1443396955728531
Validation loss: 1.4548752500164894

Epoch: 6| Step: 3
Training loss: 0.19014990329742432
Validation loss: 1.4513956308364868

Epoch: 6| Step: 4
Training loss: 0.12509474158287048
Validation loss: 1.4675606784000192

Epoch: 6| Step: 5
Training loss: 0.16294416785240173
Validation loss: 1.4512346136954524

Epoch: 6| Step: 6
Training loss: 0.054436344653367996
Validation loss: 1.4230027096245879

Epoch: 6| Step: 7
Training loss: 0.1696201115846634
Validation loss: 1.4164823101412864

Epoch: 6| Step: 8
Training loss: 0.1091327965259552
Validation loss: 1.399048016917321

Epoch: 6| Step: 9
Training loss: 0.22629334032535553
Validation loss: 1.407687283331348

Epoch: 6| Step: 10
Training loss: 0.06070569157600403
Validation loss: 1.405359952039616

Epoch: 6| Step: 11
Training loss: 0.10582535713911057
Validation loss: 1.4054343969591203

Epoch: 6| Step: 12
Training loss: 0.07331804931163788
Validation loss: 1.4265458532558974

Epoch: 6| Step: 13
Training loss: 0.10552684217691422
Validation loss: 1.4670462864701466

Epoch: 536| Step: 0
Training loss: 0.12498705089092255
Validation loss: 1.491599609774928

Epoch: 6| Step: 1
Training loss: 0.09623314440250397
Validation loss: 1.5195907508173296

Epoch: 6| Step: 2
Training loss: 0.08515897393226624
Validation loss: 1.5059475078377673

Epoch: 6| Step: 3
Training loss: 0.1712898463010788
Validation loss: 1.5066979021154425

Epoch: 6| Step: 4
Training loss: 0.10830319672822952
Validation loss: 1.4913044757740472

Epoch: 6| Step: 5
Training loss: 0.11061052978038788
Validation loss: 1.44617913487137

Epoch: 6| Step: 6
Training loss: 0.13870951533317566
Validation loss: 1.434536978762637

Epoch: 6| Step: 7
Training loss: 0.1648983359336853
Validation loss: 1.402280742122281

Epoch: 6| Step: 8
Training loss: 0.05786067992448807
Validation loss: 1.4188651897573983

Epoch: 6| Step: 9
Training loss: 0.08012416958808899
Validation loss: 1.4122873326783538

Epoch: 6| Step: 10
Training loss: 0.056104354560375214
Validation loss: 1.405487165656141

Epoch: 6| Step: 11
Training loss: 0.10281001031398773
Validation loss: 1.4159653455980363

Epoch: 6| Step: 12
Training loss: 0.07744761556386948
Validation loss: 1.4226480600654439

Epoch: 6| Step: 13
Training loss: 0.09007572382688522
Validation loss: 1.4323836936745593

Epoch: 537| Step: 0
Training loss: 0.0726296603679657
Validation loss: 1.4595412118460542

Epoch: 6| Step: 1
Training loss: 0.08842217922210693
Validation loss: 1.4574527253386795

Epoch: 6| Step: 2
Training loss: 0.12839847803115845
Validation loss: 1.4362861417954969

Epoch: 6| Step: 3
Training loss: 0.061898358166217804
Validation loss: 1.4267750401650705

Epoch: 6| Step: 4
Training loss: 0.09443530440330505
Validation loss: 1.4167232923610236

Epoch: 6| Step: 5
Training loss: 0.11086748540401459
Validation loss: 1.413817690264794

Epoch: 6| Step: 6
Training loss: 0.05875222384929657
Validation loss: 1.4101209332866054

Epoch: 6| Step: 7
Training loss: 0.09928547590970993
Validation loss: 1.3747129920990235

Epoch: 6| Step: 8
Training loss: 0.08561652898788452
Validation loss: 1.3673953317826795

Epoch: 6| Step: 9
Training loss: 0.08943601697683334
Validation loss: 1.3753006919737785

Epoch: 6| Step: 10
Training loss: 0.10795707255601883
Validation loss: 1.3970000179865028

Epoch: 6| Step: 11
Training loss: 0.07015740871429443
Validation loss: 1.395792071537305

Epoch: 6| Step: 12
Training loss: 0.11381308734416962
Validation loss: 1.418299671142332

Epoch: 6| Step: 13
Training loss: 0.054137710481882095
Validation loss: 1.418387984716764

Epoch: 538| Step: 0
Training loss: 0.06823956966400146
Validation loss: 1.4197272741666405

Epoch: 6| Step: 1
Training loss: 0.10041444003582001
Validation loss: 1.4349304976001862

Epoch: 6| Step: 2
Training loss: 0.12326593697071075
Validation loss: 1.4385787902339813

Epoch: 6| Step: 3
Training loss: 0.07985778152942657
Validation loss: 1.4719041393649193

Epoch: 6| Step: 4
Training loss: 0.09199878573417664
Validation loss: 1.4857263526608866

Epoch: 6| Step: 5
Training loss: 0.18040435016155243
Validation loss: 1.4761085676890549

Epoch: 6| Step: 6
Training loss: 0.11288145184516907
Validation loss: 1.4943490207836192

Epoch: 6| Step: 7
Training loss: 0.07759791612625122
Validation loss: 1.4899965204218382

Epoch: 6| Step: 8
Training loss: 0.13552457094192505
Validation loss: 1.5008660490794847

Epoch: 6| Step: 9
Training loss: 0.11724146455526352
Validation loss: 1.4765166762054607

Epoch: 6| Step: 10
Training loss: 0.06648653745651245
Validation loss: 1.4541493051795549

Epoch: 6| Step: 11
Training loss: 0.15321257710456848
Validation loss: 1.448416272799174

Epoch: 6| Step: 12
Training loss: 0.06432954967021942
Validation loss: 1.4353742945578791

Epoch: 6| Step: 13
Training loss: 0.06470070779323578
Validation loss: 1.4495900190004738

Epoch: 539| Step: 0
Training loss: 0.08259917795658112
Validation loss: 1.4044678108666533

Epoch: 6| Step: 1
Training loss: 0.10377209633588791
Validation loss: 1.3934835990269978

Epoch: 6| Step: 2
Training loss: 0.060983818024396896
Validation loss: 1.412971753587005

Epoch: 6| Step: 3
Training loss: 0.11859222501516342
Validation loss: 1.425381564324902

Epoch: 6| Step: 4
Training loss: 0.10334360599517822
Validation loss: 1.429332402444655

Epoch: 6| Step: 5
Training loss: 0.12296135723590851
Validation loss: 1.4173325223307456

Epoch: 6| Step: 6
Training loss: 0.08985383808612823
Validation loss: 1.4192365830944431

Epoch: 6| Step: 7
Training loss: 0.13774922490119934
Validation loss: 1.4245289589769097

Epoch: 6| Step: 8
Training loss: 0.11386549472808838
Validation loss: 1.4543460030709543

Epoch: 6| Step: 9
Training loss: 0.13073574006557465
Validation loss: 1.4522695772109493

Epoch: 6| Step: 10
Training loss: 0.16732046008110046
Validation loss: 1.481826602771718

Epoch: 6| Step: 11
Training loss: 0.07466401904821396
Validation loss: 1.4776538366912513

Epoch: 6| Step: 12
Training loss: 0.11595135182142258
Validation loss: 1.4787374055513771

Epoch: 6| Step: 13
Training loss: 0.08865616470575333
Validation loss: 1.477155279087764

Epoch: 540| Step: 0
Training loss: 0.047357141971588135
Validation loss: 1.4704124145610358

Epoch: 6| Step: 1
Training loss: 0.08080936223268509
Validation loss: 1.4663110740723149

Epoch: 6| Step: 2
Training loss: 0.06874734908342361
Validation loss: 1.4492274920145671

Epoch: 6| Step: 3
Training loss: 0.15342554450035095
Validation loss: 1.4499727385018462

Epoch: 6| Step: 4
Training loss: 0.06037335842847824
Validation loss: 1.436131808065599

Epoch: 6| Step: 5
Training loss: 0.1380733996629715
Validation loss: 1.43426594426555

Epoch: 6| Step: 6
Training loss: 0.1091328039765358
Validation loss: 1.441089322490077

Epoch: 6| Step: 7
Training loss: 0.07528902590274811
Validation loss: 1.4571694520211989

Epoch: 6| Step: 8
Training loss: 0.11071927845478058
Validation loss: 1.437827064144996

Epoch: 6| Step: 9
Training loss: 0.13166937232017517
Validation loss: 1.447370421501898

Epoch: 6| Step: 10
Training loss: 0.10667212307453156
Validation loss: 1.4493725786926925

Epoch: 6| Step: 11
Training loss: 0.08806391805410385
Validation loss: 1.4654341487474338

Epoch: 6| Step: 12
Training loss: 0.09657807648181915
Validation loss: 1.4637175657415902

Epoch: 6| Step: 13
Training loss: 0.08396725356578827
Validation loss: 1.477826928579679

Epoch: 541| Step: 0
Training loss: 0.0620780847966671
Validation loss: 1.4733054682772646

Epoch: 6| Step: 1
Training loss: 0.1512899249792099
Validation loss: 1.5002878622342182

Epoch: 6| Step: 2
Training loss: 0.1422225534915924
Validation loss: 1.4710976436573973

Epoch: 6| Step: 3
Training loss: 0.07539768517017365
Validation loss: 1.480205665352524

Epoch: 6| Step: 4
Training loss: 0.09176824986934662
Validation loss: 1.4412123798042216

Epoch: 6| Step: 5
Training loss: 0.10968895256519318
Validation loss: 1.4301093611665951

Epoch: 6| Step: 6
Training loss: 0.050793759524822235
Validation loss: 1.4084958632787068

Epoch: 6| Step: 7
Training loss: 0.08786767721176147
Validation loss: 1.3872648746736589

Epoch: 6| Step: 8
Training loss: 0.12254982441663742
Validation loss: 1.4017606319919709

Epoch: 6| Step: 9
Training loss: 0.1393536925315857
Validation loss: 1.415068478994472

Epoch: 6| Step: 10
Training loss: 0.08361627161502838
Validation loss: 1.3952470562791313

Epoch: 6| Step: 11
Training loss: 0.11367662250995636
Validation loss: 1.3965840173024002

Epoch: 6| Step: 12
Training loss: 0.09040569514036179
Validation loss: 1.396949404029436

Epoch: 6| Step: 13
Training loss: 0.08941219747066498
Validation loss: 1.4150025024208972

Epoch: 542| Step: 0
Training loss: 0.11614798754453659
Validation loss: 1.3981237514044649

Epoch: 6| Step: 1
Training loss: 0.09478814154863358
Validation loss: 1.4375288736435674

Epoch: 6| Step: 2
Training loss: 0.05132032558321953
Validation loss: 1.4525001971952376

Epoch: 6| Step: 3
Training loss: 0.07870683073997498
Validation loss: 1.4368114779072423

Epoch: 6| Step: 4
Training loss: 0.050733424723148346
Validation loss: 1.451488128272436

Epoch: 6| Step: 5
Training loss: 0.08897341787815094
Validation loss: 1.4539708950186288

Epoch: 6| Step: 6
Training loss: 0.07837600260972977
Validation loss: 1.4753213672227756

Epoch: 6| Step: 7
Training loss: 0.10225336253643036
Validation loss: 1.4648386419460337

Epoch: 6| Step: 8
Training loss: 0.0728474110364914
Validation loss: 1.4300930282121063

Epoch: 6| Step: 9
Training loss: 0.10043731331825256
Validation loss: 1.4270709099308136

Epoch: 6| Step: 10
Training loss: 0.07054092735052109
Validation loss: 1.4032586582245365

Epoch: 6| Step: 11
Training loss: 0.10570816695690155
Validation loss: 1.4000241012983425

Epoch: 6| Step: 12
Training loss: 0.14430202543735504
Validation loss: 1.4019347288275277

Epoch: 6| Step: 13
Training loss: 0.1601731777191162
Validation loss: 1.3834510182821622

Epoch: 543| Step: 0
Training loss: 0.10638689249753952
Validation loss: 1.3926623329039542

Epoch: 6| Step: 1
Training loss: 0.07295523583889008
Validation loss: 1.3810645623873639

Epoch: 6| Step: 2
Training loss: 0.06222425773739815
Validation loss: 1.365183501474319

Epoch: 6| Step: 3
Training loss: 0.0996314287185669
Validation loss: 1.3708941019991392

Epoch: 6| Step: 4
Training loss: 0.14066237211227417
Validation loss: 1.366619961236113

Epoch: 6| Step: 5
Training loss: 0.08358194679021835
Validation loss: 1.369671751414576

Epoch: 6| Step: 6
Training loss: 0.10751339793205261
Validation loss: 1.3820531291346396

Epoch: 6| Step: 7
Training loss: 0.07106476277112961
Validation loss: 1.376274299877946

Epoch: 6| Step: 8
Training loss: 0.1050432026386261
Validation loss: 1.380995688899871

Epoch: 6| Step: 9
Training loss: 0.10785650461912155
Validation loss: 1.388341481967639

Epoch: 6| Step: 10
Training loss: 0.0988955870270729
Validation loss: 1.3992376994061213

Epoch: 6| Step: 11
Training loss: 0.09240375459194183
Validation loss: 1.3642991178779191

Epoch: 6| Step: 12
Training loss: 0.07628947496414185
Validation loss: 1.394905077513828

Epoch: 6| Step: 13
Training loss: 0.07113780081272125
Validation loss: 1.371801164842421

Epoch: 544| Step: 0
Training loss: 0.03233073651790619
Validation loss: 1.4184023129042758

Epoch: 6| Step: 1
Training loss: 0.08505433052778244
Validation loss: 1.4372857821884977

Epoch: 6| Step: 2
Training loss: 0.15098419785499573
Validation loss: 1.4130292156691193

Epoch: 6| Step: 3
Training loss: 0.09923306852579117
Validation loss: 1.4293949501488799

Epoch: 6| Step: 4
Training loss: 0.11405692249536514
Validation loss: 1.4481557594832553

Epoch: 6| Step: 5
Training loss: 0.10229625552892685
Validation loss: 1.4457783878490489

Epoch: 6| Step: 6
Training loss: 0.0818854346871376
Validation loss: 1.4313142389379523

Epoch: 6| Step: 7
Training loss: 0.08291730284690857
Validation loss: 1.4380352945737942

Epoch: 6| Step: 8
Training loss: 0.05047864466905594
Validation loss: 1.4348404458774033

Epoch: 6| Step: 9
Training loss: 0.052887286990880966
Validation loss: 1.436783557297081

Epoch: 6| Step: 10
Training loss: 0.08343295007944107
Validation loss: 1.4421927787924325

Epoch: 6| Step: 11
Training loss: 0.10697615146636963
Validation loss: 1.443170734631118

Epoch: 6| Step: 12
Training loss: 0.10473926365375519
Validation loss: 1.4310265792313444

Epoch: 6| Step: 13
Training loss: 0.0571167878806591
Validation loss: 1.4574330724695677

Epoch: 545| Step: 0
Training loss: 0.07872287184000015
Validation loss: 1.468795067520552

Epoch: 6| Step: 1
Training loss: 0.08698040246963501
Validation loss: 1.4427829224576232

Epoch: 6| Step: 2
Training loss: 0.06354933977127075
Validation loss: 1.455984139955172

Epoch: 6| Step: 3
Training loss: 0.10572926700115204
Validation loss: 1.4524434125551613

Epoch: 6| Step: 4
Training loss: 0.06987256556749344
Validation loss: 1.4508042540601505

Epoch: 6| Step: 5
Training loss: 0.1030585914850235
Validation loss: 1.4318234420591784

Epoch: 6| Step: 6
Training loss: 0.0905652642250061
Validation loss: 1.446221440069137

Epoch: 6| Step: 7
Training loss: 0.09710094332695007
Validation loss: 1.4537515819713633

Epoch: 6| Step: 8
Training loss: 0.054465875029563904
Validation loss: 1.449577304624742

Epoch: 6| Step: 9
Training loss: 0.07884852588176727
Validation loss: 1.4441388909534743

Epoch: 6| Step: 10
Training loss: 0.13096675276756287
Validation loss: 1.4232287829922092

Epoch: 6| Step: 11
Training loss: 0.08115841448307037
Validation loss: 1.4432310865771385

Epoch: 6| Step: 12
Training loss: 0.05502217262983322
Validation loss: 1.4364488663211945

Epoch: 6| Step: 13
Training loss: 0.09813521802425385
Validation loss: 1.4426703106972478

Epoch: 546| Step: 0
Training loss: 0.05202446132898331
Validation loss: 1.4375974965351883

Epoch: 6| Step: 1
Training loss: 0.07682129740715027
Validation loss: 1.44351375743907

Epoch: 6| Step: 2
Training loss: 0.12426641583442688
Validation loss: 1.4277448372174335

Epoch: 6| Step: 3
Training loss: 0.07721678912639618
Validation loss: 1.41455889004533

Epoch: 6| Step: 4
Training loss: 0.06516338139772415
Validation loss: 1.4295849079085934

Epoch: 6| Step: 5
Training loss: 0.10388536751270294
Validation loss: 1.4224820213933145

Epoch: 6| Step: 6
Training loss: 0.10697007179260254
Validation loss: 1.4129775288284465

Epoch: 6| Step: 7
Training loss: 0.053014084696769714
Validation loss: 1.4136412053979852

Epoch: 6| Step: 8
Training loss: 0.05647315829992294
Validation loss: 1.408519136008396

Epoch: 6| Step: 9
Training loss: 0.12164096534252167
Validation loss: 1.4055662911425355

Epoch: 6| Step: 10
Training loss: 0.08602387458086014
Validation loss: 1.4265622477377615

Epoch: 6| Step: 11
Training loss: 0.09421145915985107
Validation loss: 1.4077357656212264

Epoch: 6| Step: 12
Training loss: 0.07145151495933533
Validation loss: 1.4289134933102516

Epoch: 6| Step: 13
Training loss: 0.04603121802210808
Validation loss: 1.4490082635674426

Epoch: 547| Step: 0
Training loss: 0.08358065038919449
Validation loss: 1.475050676253534

Epoch: 6| Step: 1
Training loss: 0.08030164241790771
Validation loss: 1.468282712403164

Epoch: 6| Step: 2
Training loss: 0.10269232094287872
Validation loss: 1.5024857687693771

Epoch: 6| Step: 3
Training loss: 0.09383191913366318
Validation loss: 1.4931731300969278

Epoch: 6| Step: 4
Training loss: 0.0791836827993393
Validation loss: 1.4787705713702786

Epoch: 6| Step: 5
Training loss: 0.06955235451459885
Validation loss: 1.4558846873621787

Epoch: 6| Step: 6
Training loss: 0.06146472319960594
Validation loss: 1.4452134986077585

Epoch: 6| Step: 7
Training loss: 0.09736913442611694
Validation loss: 1.419694282034392

Epoch: 6| Step: 8
Training loss: 0.07735439389944077
Validation loss: 1.4027953019706152

Epoch: 6| Step: 9
Training loss: 0.1522371470928192
Validation loss: 1.3883423407872517

Epoch: 6| Step: 10
Training loss: 0.06155483424663544
Validation loss: 1.3986053466796875

Epoch: 6| Step: 11
Training loss: 0.07757405191659927
Validation loss: 1.399631800190095

Epoch: 6| Step: 12
Training loss: 0.09128770232200623
Validation loss: 1.385950284619485

Epoch: 6| Step: 13
Training loss: 0.12168814241886139
Validation loss: 1.3744459908495668

Epoch: 548| Step: 0
Training loss: 0.05392500385642052
Validation loss: 1.3920068381935038

Epoch: 6| Step: 1
Training loss: 0.09957718849182129
Validation loss: 1.3750138923686037

Epoch: 6| Step: 2
Training loss: 0.06519056856632233
Validation loss: 1.3642357485268706

Epoch: 6| Step: 3
Training loss: 0.09830410033464432
Validation loss: 1.3838057293686816

Epoch: 6| Step: 4
Training loss: 0.061804112046957016
Validation loss: 1.388628222609079

Epoch: 6| Step: 5
Training loss: 0.07342914491891861
Validation loss: 1.423303650271508

Epoch: 6| Step: 6
Training loss: 0.06112512946128845
Validation loss: 1.441438075034849

Epoch: 6| Step: 7
Training loss: 0.13345913589000702
Validation loss: 1.4506931138294998

Epoch: 6| Step: 8
Training loss: 0.07829451560974121
Validation loss: 1.4396079342852357

Epoch: 6| Step: 9
Training loss: 0.08548782020807266
Validation loss: 1.4523767655895603

Epoch: 6| Step: 10
Training loss: 0.12478262186050415
Validation loss: 1.4613292723573663

Epoch: 6| Step: 11
Training loss: 0.1004561185836792
Validation loss: 1.4567098335553241

Epoch: 6| Step: 12
Training loss: 0.1596035361289978
Validation loss: 1.4163930108470302

Epoch: 6| Step: 13
Training loss: 0.18504497408866882
Validation loss: 1.3937809416042861

Epoch: 549| Step: 0
Training loss: 0.08327048271894455
Validation loss: 1.380159931798135

Epoch: 6| Step: 1
Training loss: 0.07644352316856384
Validation loss: 1.3575848392260972

Epoch: 6| Step: 2
Training loss: 0.07354488223791122
Validation loss: 1.3620043544359104

Epoch: 6| Step: 3
Training loss: 0.07536090910434723
Validation loss: 1.3627310209376837

Epoch: 6| Step: 4
Training loss: 0.05492107570171356
Validation loss: 1.3512016163077405

Epoch: 6| Step: 5
Training loss: 0.09255535900592804
Validation loss: 1.3806031378366614

Epoch: 6| Step: 6
Training loss: 0.10264037549495697
Validation loss: 1.4034823256154214

Epoch: 6| Step: 7
Training loss: 0.11033895611763
Validation loss: 1.3746537687957927

Epoch: 6| Step: 8
Training loss: 0.10187594592571259
Validation loss: 1.4291691869817755

Epoch: 6| Step: 9
Training loss: 0.0870438888669014
Validation loss: 1.4331321024125623

Epoch: 6| Step: 10
Training loss: 0.11251860111951828
Validation loss: 1.4422535281027518

Epoch: 6| Step: 11
Training loss: 0.1309010088443756
Validation loss: 1.4278827495472406

Epoch: 6| Step: 12
Training loss: 0.06392449885606766
Validation loss: 1.4535652052971624

Epoch: 6| Step: 13
Training loss: 0.06805939227342606
Validation loss: 1.4523197040762952

Epoch: 550| Step: 0
Training loss: 0.13741767406463623
Validation loss: 1.439178861597533

Epoch: 6| Step: 1
Training loss: 0.11476754397153854
Validation loss: 1.4418227018848542

Epoch: 6| Step: 2
Training loss: 0.15718665719032288
Validation loss: 1.4150034958316433

Epoch: 6| Step: 3
Training loss: 0.05641390383243561
Validation loss: 1.4069975742729761

Epoch: 6| Step: 4
Training loss: 0.0927400141954422
Validation loss: 1.4088675040070728

Epoch: 6| Step: 5
Training loss: 0.056934505701065063
Validation loss: 1.4081921961999708

Epoch: 6| Step: 6
Training loss: 0.08195460587739944
Validation loss: 1.3873269865589757

Epoch: 6| Step: 7
Training loss: 0.08911699801683426
Validation loss: 1.4087212290815128

Epoch: 6| Step: 8
Training loss: 0.05034387856721878
Validation loss: 1.389963719152635

Epoch: 6| Step: 9
Training loss: 0.03501813858747482
Validation loss: 1.3961584414205244

Epoch: 6| Step: 10
Training loss: 0.05483219027519226
Validation loss: 1.396486533585415

Epoch: 6| Step: 11
Training loss: 0.04956250637769699
Validation loss: 1.3930443352268589

Epoch: 6| Step: 12
Training loss: 0.0383380688726902
Validation loss: 1.4089513978650492

Epoch: 6| Step: 13
Training loss: 0.1431945115327835
Validation loss: 1.4304968169940415

Epoch: 551| Step: 0
Training loss: 0.055167894810438156
Validation loss: 1.4080762799068163

Epoch: 6| Step: 1
Training loss: 0.061935871839523315
Validation loss: 1.425959410205964

Epoch: 6| Step: 2
Training loss: 0.10191468149423599
Validation loss: 1.4473807657918623

Epoch: 6| Step: 3
Training loss: 0.1415378749370575
Validation loss: 1.4522684568999915

Epoch: 6| Step: 4
Training loss: 0.09820188581943512
Validation loss: 1.4428749738201019

Epoch: 6| Step: 5
Training loss: 0.03781780228018761
Validation loss: 1.4115946087785947

Epoch: 6| Step: 6
Training loss: 0.17246073484420776
Validation loss: 1.4215518543797154

Epoch: 6| Step: 7
Training loss: 0.11641046404838562
Validation loss: 1.4397653789930447

Epoch: 6| Step: 8
Training loss: 0.17596565186977386
Validation loss: 1.436717528168873

Epoch: 6| Step: 9
Training loss: 0.14741230010986328
Validation loss: 1.4342611605121243

Epoch: 6| Step: 10
Training loss: 0.16350455582141876
Validation loss: 1.4278114867466751

Epoch: 6| Step: 11
Training loss: 0.03955215960741043
Validation loss: 1.415868438700194

Epoch: 6| Step: 12
Training loss: 0.07887917757034302
Validation loss: 1.397261550349574

Epoch: 6| Step: 13
Training loss: 0.08188382536172867
Validation loss: 1.4142134445969776

Epoch: 552| Step: 0
Training loss: 0.126604825258255
Validation loss: 1.437877017964599

Epoch: 6| Step: 1
Training loss: 0.14085814356803894
Validation loss: 1.4574146552752423

Epoch: 6| Step: 2
Training loss: 0.095497265458107
Validation loss: 1.4903943397665536

Epoch: 6| Step: 3
Training loss: 0.07705104351043701
Validation loss: 1.473903363750827

Epoch: 6| Step: 4
Training loss: 0.09795078635215759
Validation loss: 1.4422189727906258

Epoch: 6| Step: 5
Training loss: 0.0663108080625534
Validation loss: 1.4519515370809903

Epoch: 6| Step: 6
Training loss: 0.16780981421470642
Validation loss: 1.4366126893669047

Epoch: 6| Step: 7
Training loss: 0.08477441221475601
Validation loss: 1.453055750939154

Epoch: 6| Step: 8
Training loss: 0.07597983628511429
Validation loss: 1.4474457399819487

Epoch: 6| Step: 9
Training loss: 0.04729527235031128
Validation loss: 1.4174123169273458

Epoch: 6| Step: 10
Training loss: 0.07517530024051666
Validation loss: 1.4112451166234992

Epoch: 6| Step: 11
Training loss: 0.11995057761669159
Validation loss: 1.4130843544519076

Epoch: 6| Step: 12
Training loss: 0.035254910588264465
Validation loss: 1.4226248905222902

Epoch: 6| Step: 13
Training loss: 0.049945808947086334
Validation loss: 1.4097903877176263

Epoch: 553| Step: 0
Training loss: 0.08128713071346283
Validation loss: 1.4471610438439153

Epoch: 6| Step: 1
Training loss: 0.06954626739025116
Validation loss: 1.448446769868174

Epoch: 6| Step: 2
Training loss: 0.11844460666179657
Validation loss: 1.4591624711149482

Epoch: 6| Step: 3
Training loss: 0.030107418075203896
Validation loss: 1.4325373390669465

Epoch: 6| Step: 4
Training loss: 0.09959113597869873
Validation loss: 1.4480058813607821

Epoch: 6| Step: 5
Training loss: 0.14114180207252502
Validation loss: 1.4391720410316222

Epoch: 6| Step: 6
Training loss: 0.07147132605314255
Validation loss: 1.4720229102719216

Epoch: 6| Step: 7
Training loss: 0.09671996533870697
Validation loss: 1.4460534895620039

Epoch: 6| Step: 8
Training loss: 0.08335195481777191
Validation loss: 1.4426992324090773

Epoch: 6| Step: 9
Training loss: 0.06058776378631592
Validation loss: 1.449216724723898

Epoch: 6| Step: 10
Training loss: 0.06839288771152496
Validation loss: 1.4518793821334839

Epoch: 6| Step: 11
Training loss: 0.06846945732831955
Validation loss: 1.441940975445573

Epoch: 6| Step: 12
Training loss: 0.04656507447361946
Validation loss: 1.4152218423863894

Epoch: 6| Step: 13
Training loss: 0.09474057704210281
Validation loss: 1.4235210867338284

Epoch: 554| Step: 0
Training loss: 0.06141231209039688
Validation loss: 1.4051596195467058

Epoch: 6| Step: 1
Training loss: 0.04626031219959259
Validation loss: 1.399882702417271

Epoch: 6| Step: 2
Training loss: 0.10555224120616913
Validation loss: 1.4005115772447279

Epoch: 6| Step: 3
Training loss: 0.0776049941778183
Validation loss: 1.3980988911403123

Epoch: 6| Step: 4
Training loss: 0.06891480833292007
Validation loss: 1.3989604698714388

Epoch: 6| Step: 5
Training loss: 0.1115340068936348
Validation loss: 1.3996642481896184

Epoch: 6| Step: 6
Training loss: 0.09416940808296204
Validation loss: 1.4204480186585458

Epoch: 6| Step: 7
Training loss: 0.09429433941841125
Validation loss: 1.4407877409329979

Epoch: 6| Step: 8
Training loss: 0.11525656282901764
Validation loss: 1.4505339232824181

Epoch: 6| Step: 9
Training loss: 0.06464847177267075
Validation loss: 1.4706805572714856

Epoch: 6| Step: 10
Training loss: 0.062456317245960236
Validation loss: 1.4496517187805587

Epoch: 6| Step: 11
Training loss: 0.04519573226571083
Validation loss: 1.4656748066666305

Epoch: 6| Step: 12
Training loss: 0.09101200103759766
Validation loss: 1.4525151265564786

Epoch: 6| Step: 13
Training loss: 0.13341845571994781
Validation loss: 1.4649110609485256

Epoch: 555| Step: 0
Training loss: 0.06964734196662903
Validation loss: 1.4596999383741809

Epoch: 6| Step: 1
Training loss: 0.07832811772823334
Validation loss: 1.4478395433836087

Epoch: 6| Step: 2
Training loss: 0.08552764356136322
Validation loss: 1.4274588669500043

Epoch: 6| Step: 3
Training loss: 0.07871139049530029
Validation loss: 1.4361351151620187

Epoch: 6| Step: 4
Training loss: 0.11085189878940582
Validation loss: 1.443829196755604

Epoch: 6| Step: 5
Training loss: 0.09623522311449051
Validation loss: 1.4404920685675837

Epoch: 6| Step: 6
Training loss: 0.08264019340276718
Validation loss: 1.4392824506246915

Epoch: 6| Step: 7
Training loss: 0.06064695864915848
Validation loss: 1.4310666386799147

Epoch: 6| Step: 8
Training loss: 0.06932833790779114
Validation loss: 1.4240875077503983

Epoch: 6| Step: 9
Training loss: 0.06352296471595764
Validation loss: 1.4245189441147672

Epoch: 6| Step: 10
Training loss: 0.07189558446407318
Validation loss: 1.3965045585427234

Epoch: 6| Step: 11
Training loss: 0.04599718749523163
Validation loss: 1.4295455486543718

Epoch: 6| Step: 12
Training loss: 0.10833396017551422
Validation loss: 1.4242537688183528

Epoch: 6| Step: 13
Training loss: 0.07845327258110046
Validation loss: 1.445984463537893

Epoch: 556| Step: 0
Training loss: 0.08417638391256332
Validation loss: 1.458594374759223

Epoch: 6| Step: 1
Training loss: 0.08031538128852844
Validation loss: 1.4319594739585795

Epoch: 6| Step: 2
Training loss: 0.037743017077445984
Validation loss: 1.4640605308676278

Epoch: 6| Step: 3
Training loss: 0.06540104001760483
Validation loss: 1.4443866283662858

Epoch: 6| Step: 4
Training loss: 0.044373612850904465
Validation loss: 1.4602529996184892

Epoch: 6| Step: 5
Training loss: 0.08524785935878754
Validation loss: 1.4559477862491403

Epoch: 6| Step: 6
Training loss: 0.09451981633901596
Validation loss: 1.4517072234102475

Epoch: 6| Step: 7
Training loss: 0.09756118059158325
Validation loss: 1.4122731096001082

Epoch: 6| Step: 8
Training loss: 0.06852048635482788
Validation loss: 1.3881965516715922

Epoch: 6| Step: 9
Training loss: 0.06784126162528992
Validation loss: 1.4246109019043625

Epoch: 6| Step: 10
Training loss: 0.09029029309749603
Validation loss: 1.3948854054174116

Epoch: 6| Step: 11
Training loss: 0.0865478590130806
Validation loss: 1.3933228754228162

Epoch: 6| Step: 12
Training loss: 0.04331725835800171
Validation loss: 1.401459555472097

Epoch: 6| Step: 13
Training loss: 0.024273745715618134
Validation loss: 1.4010250523526182

Epoch: 557| Step: 0
Training loss: 0.06847857683897018
Validation loss: 1.3819937513720604

Epoch: 6| Step: 1
Training loss: 0.04722216725349426
Validation loss: 1.400499434881313

Epoch: 6| Step: 2
Training loss: 0.06907279789447784
Validation loss: 1.3947736851630672

Epoch: 6| Step: 3
Training loss: 0.06080637872219086
Validation loss: 1.4101947699823687

Epoch: 6| Step: 4
Training loss: 0.05825869366526604
Validation loss: 1.4060244867878575

Epoch: 6| Step: 5
Training loss: 0.04668532684445381
Validation loss: 1.4158378493401311

Epoch: 6| Step: 6
Training loss: 0.05735135078430176
Validation loss: 1.4114699793118302

Epoch: 6| Step: 7
Training loss: 0.07673067599534988
Validation loss: 1.39135145115596

Epoch: 6| Step: 8
Training loss: 0.11872564256191254
Validation loss: 1.4088721608602872

Epoch: 6| Step: 9
Training loss: 0.08752904087305069
Validation loss: 1.4143328666687012

Epoch: 6| Step: 10
Training loss: 0.09846602380275726
Validation loss: 1.3860940830681914

Epoch: 6| Step: 11
Training loss: 0.11963213980197906
Validation loss: 1.3970754428576397

Epoch: 6| Step: 12
Training loss: 0.04469669610261917
Validation loss: 1.4211862612796087

Epoch: 6| Step: 13
Training loss: 0.10292769968509674
Validation loss: 1.427475231950001

Epoch: 558| Step: 0
Training loss: 0.11343804746866226
Validation loss: 1.4076140753684505

Epoch: 6| Step: 1
Training loss: 0.10037370026111603
Validation loss: 1.4179692973372757

Epoch: 6| Step: 2
Training loss: 0.05919002369046211
Validation loss: 1.4478882781920894

Epoch: 6| Step: 3
Training loss: 0.08592112362384796
Validation loss: 1.4272438941463348

Epoch: 6| Step: 4
Training loss: 0.07520388066768646
Validation loss: 1.4140975436856669

Epoch: 6| Step: 5
Training loss: 0.045673757791519165
Validation loss: 1.4197325924391389

Epoch: 6| Step: 6
Training loss: 0.05753789842128754
Validation loss: 1.4341684579849243

Epoch: 6| Step: 7
Training loss: 0.029598429799079895
Validation loss: 1.4235154800517584

Epoch: 6| Step: 8
Training loss: 0.0967504009604454
Validation loss: 1.3911031138512395

Epoch: 6| Step: 9
Training loss: 0.06425458192825317
Validation loss: 1.3962693829690256

Epoch: 6| Step: 10
Training loss: 0.04744632542133331
Validation loss: 1.3804219409983645

Epoch: 6| Step: 11
Training loss: 0.06803397834300995
Validation loss: 1.3794091927107943

Epoch: 6| Step: 12
Training loss: 0.12932337820529938
Validation loss: 1.3891525409554923

Epoch: 6| Step: 13
Training loss: 0.053926508873701096
Validation loss: 1.3797315102751537

Epoch: 559| Step: 0
Training loss: 0.052260249853134155
Validation loss: 1.4044760209257885

Epoch: 6| Step: 1
Training loss: 0.08289654552936554
Validation loss: 1.3711827461437514

Epoch: 6| Step: 2
Training loss: 0.051393404603004456
Validation loss: 1.3852958909926876

Epoch: 6| Step: 3
Training loss: 0.08855107426643372
Validation loss: 1.3864268372135777

Epoch: 6| Step: 4
Training loss: 0.06752355396747589
Validation loss: 1.4095135555472424

Epoch: 6| Step: 5
Training loss: 0.08174557983875275
Validation loss: 1.422153224227249

Epoch: 6| Step: 6
Training loss: 0.08958029747009277
Validation loss: 1.405148817646888

Epoch: 6| Step: 7
Training loss: 0.03854124993085861
Validation loss: 1.4204448333350561

Epoch: 6| Step: 8
Training loss: 0.11391206085681915
Validation loss: 1.4122414999110724

Epoch: 6| Step: 9
Training loss: 0.0552251897752285
Validation loss: 1.3979661926146476

Epoch: 6| Step: 10
Training loss: 0.06989885121583939
Validation loss: 1.4041790757127988

Epoch: 6| Step: 11
Training loss: 0.0886264443397522
Validation loss: 1.4128436811508671

Epoch: 6| Step: 12
Training loss: 0.05114179104566574
Validation loss: 1.4279406609073761

Epoch: 6| Step: 13
Training loss: 0.051656324416399
Validation loss: 1.400466904845289

Epoch: 560| Step: 0
Training loss: 0.09659383445978165
Validation loss: 1.4247376893156318

Epoch: 6| Step: 1
Training loss: 0.0662803202867508
Validation loss: 1.4281858782614432

Epoch: 6| Step: 2
Training loss: 0.04692046344280243
Validation loss: 1.4111755176257061

Epoch: 6| Step: 3
Training loss: 0.07423508912324905
Validation loss: 1.3801069708280667

Epoch: 6| Step: 4
Training loss: 0.11705806106328964
Validation loss: 1.3951870702928113

Epoch: 6| Step: 5
Training loss: 0.07770156860351562
Validation loss: 1.3802435885193527

Epoch: 6| Step: 6
Training loss: 0.061459675431251526
Validation loss: 1.3967702657945695

Epoch: 6| Step: 7
Training loss: 0.04780484735965729
Validation loss: 1.39396321645347

Epoch: 6| Step: 8
Training loss: 0.07328739762306213
Validation loss: 1.414118234188326

Epoch: 6| Step: 9
Training loss: 0.10995543003082275
Validation loss: 1.4069829602395334

Epoch: 6| Step: 10
Training loss: 0.08865215629339218
Validation loss: 1.4217223980093514

Epoch: 6| Step: 11
Training loss: 0.08314185589551926
Validation loss: 1.4345117153659943

Epoch: 6| Step: 12
Training loss: 0.06668262183666229
Validation loss: 1.4353336057355326

Epoch: 6| Step: 13
Training loss: 0.08578531444072723
Validation loss: 1.4735857978943856

Epoch: 561| Step: 0
Training loss: 0.09614266455173492
Validation loss: 1.469372683955777

Epoch: 6| Step: 1
Training loss: 0.1614222228527069
Validation loss: 1.4651544376086163

Epoch: 6| Step: 2
Training loss: 0.07589922845363617
Validation loss: 1.4744564698588463

Epoch: 6| Step: 3
Training loss: 0.06974582374095917
Validation loss: 1.4769404831752981

Epoch: 6| Step: 4
Training loss: 0.05620194226503372
Validation loss: 1.421126954017147

Epoch: 6| Step: 5
Training loss: 0.07018459588289261
Validation loss: 1.4405341968741467

Epoch: 6| Step: 6
Training loss: 0.061398573219776154
Validation loss: 1.4231321811676025

Epoch: 6| Step: 7
Training loss: 0.06462891399860382
Validation loss: 1.4222764533053163

Epoch: 6| Step: 8
Training loss: 0.07364867627620697
Validation loss: 1.3899376232136962

Epoch: 6| Step: 9
Training loss: 0.04895859211683273
Validation loss: 1.4260100638994606

Epoch: 6| Step: 10
Training loss: 0.05348078906536102
Validation loss: 1.418293555577596

Epoch: 6| Step: 11
Training loss: 0.07542388141155243
Validation loss: 1.401525330799882

Epoch: 6| Step: 12
Training loss: 0.0634155347943306
Validation loss: 1.4159672798648957

Epoch: 6| Step: 13
Training loss: 0.11517936736345291
Validation loss: 1.4351274813375166

Epoch: 562| Step: 0
Training loss: 0.051108650863170624
Validation loss: 1.4128124765170518

Epoch: 6| Step: 1
Training loss: 0.07504945248365402
Validation loss: 1.3943854967753093

Epoch: 6| Step: 2
Training loss: 0.07037380337715149
Validation loss: 1.4149966521929669

Epoch: 6| Step: 3
Training loss: 0.1315842717885971
Validation loss: 1.432781636074025

Epoch: 6| Step: 4
Training loss: 0.10866916179656982
Validation loss: 1.4368535895501413

Epoch: 6| Step: 5
Training loss: 0.11359257996082306
Validation loss: 1.4303713537031604

Epoch: 6| Step: 6
Training loss: 0.05112592130899429
Validation loss: 1.4179002725949852

Epoch: 6| Step: 7
Training loss: 0.08084359019994736
Validation loss: 1.4095024242196033

Epoch: 6| Step: 8
Training loss: 0.049725938588380814
Validation loss: 1.3949600996509675

Epoch: 6| Step: 9
Training loss: 0.07993032038211823
Validation loss: 1.419238176397098

Epoch: 6| Step: 10
Training loss: 0.12890781462192535
Validation loss: 1.4129196360547056

Epoch: 6| Step: 11
Training loss: 0.0898766964673996
Validation loss: 1.4327774816943752

Epoch: 6| Step: 12
Training loss: 0.05844689533114433
Validation loss: 1.405488912777234

Epoch: 6| Step: 13
Training loss: 0.04699762165546417
Validation loss: 1.4213635524113972

Epoch: 563| Step: 0
Training loss: 0.07913906872272491
Validation loss: 1.4379621218609553

Epoch: 6| Step: 1
Training loss: 0.06795329600572586
Validation loss: 1.4149767583416355

Epoch: 6| Step: 2
Training loss: 0.05247987434267998
Validation loss: 1.421870929579581

Epoch: 6| Step: 3
Training loss: 0.11800263077020645
Validation loss: 1.4024824673129666

Epoch: 6| Step: 4
Training loss: 0.11713245511054993
Validation loss: 1.423517248963797

Epoch: 6| Step: 5
Training loss: 0.11634977161884308
Validation loss: 1.4321702449552474

Epoch: 6| Step: 6
Training loss: 0.09071145206689835
Validation loss: 1.4413277808056082

Epoch: 6| Step: 7
Training loss: 0.05863935127854347
Validation loss: 1.4041058042997956

Epoch: 6| Step: 8
Training loss: 0.10065317898988724
Validation loss: 1.3991186157349618

Epoch: 6| Step: 9
Training loss: 0.0929839015007019
Validation loss: 1.3849476075941516

Epoch: 6| Step: 10
Training loss: 0.08057655394077301
Validation loss: 1.3694583780022078

Epoch: 6| Step: 11
Training loss: 0.0966169610619545
Validation loss: 1.406627038473724

Epoch: 6| Step: 12
Training loss: 0.0831674188375473
Validation loss: 1.3982632583187473

Epoch: 6| Step: 13
Training loss: 0.06865920126438141
Validation loss: 1.3941521849683536

Epoch: 564| Step: 0
Training loss: 0.07659748196601868
Validation loss: 1.40794716470985

Epoch: 6| Step: 1
Training loss: 0.06764470040798187
Validation loss: 1.4568276251516035

Epoch: 6| Step: 2
Training loss: 0.059117164462804794
Validation loss: 1.441040405663111

Epoch: 6| Step: 3
Training loss: 0.06821341067552567
Validation loss: 1.5017905248108732

Epoch: 6| Step: 4
Training loss: 0.08932556211948395
Validation loss: 1.486526753312798

Epoch: 6| Step: 5
Training loss: 0.10956558585166931
Validation loss: 1.446371583528416

Epoch: 6| Step: 6
Training loss: 0.08094856142997742
Validation loss: 1.4398069945714806

Epoch: 6| Step: 7
Training loss: 0.08681705594062805
Validation loss: 1.4152599521862563

Epoch: 6| Step: 8
Training loss: 0.07654193788766861
Validation loss: 1.4148164333835724

Epoch: 6| Step: 9
Training loss: 0.08748328685760498
Validation loss: 1.4026126284753122

Epoch: 6| Step: 10
Training loss: 0.07338638603687286
Validation loss: 1.41364953466641

Epoch: 6| Step: 11
Training loss: 0.09699776768684387
Validation loss: 1.42066571276675

Epoch: 6| Step: 12
Training loss: 0.06614385545253754
Validation loss: 1.4258500299146097

Epoch: 6| Step: 13
Training loss: 0.09435164928436279
Validation loss: 1.393525242805481

Epoch: 565| Step: 0
Training loss: 0.10231560468673706
Validation loss: 1.4045913873180267

Epoch: 6| Step: 1
Training loss: 0.10668079555034637
Validation loss: 1.40712752649861

Epoch: 6| Step: 2
Training loss: 0.04748205095529556
Validation loss: 1.4097372716472996

Epoch: 6| Step: 3
Training loss: 0.03837047144770622
Validation loss: 1.407691644084069

Epoch: 6| Step: 4
Training loss: 0.05459901690483093
Validation loss: 1.42793748968391

Epoch: 6| Step: 5
Training loss: 0.10022726655006409
Validation loss: 1.3984466086151779

Epoch: 6| Step: 6
Training loss: 0.09006161987781525
Validation loss: 1.4372877510645057

Epoch: 6| Step: 7
Training loss: 0.04520074278116226
Validation loss: 1.3942499891404183

Epoch: 6| Step: 8
Training loss: 0.0538061298429966
Validation loss: 1.3877486118706324

Epoch: 6| Step: 9
Training loss: 0.055861953645944595
Validation loss: 1.3994700536932996

Epoch: 6| Step: 10
Training loss: 0.08623228222131729
Validation loss: 1.3927333598495812

Epoch: 6| Step: 11
Training loss: 0.06735231727361679
Validation loss: 1.4006016062152

Epoch: 6| Step: 12
Training loss: 0.057686977088451385
Validation loss: 1.3534297250932263

Epoch: 6| Step: 13
Training loss: 0.09171673655509949
Validation loss: 1.3679481065401466

Epoch: 566| Step: 0
Training loss: 0.0698767676949501
Validation loss: 1.3606848979509005

Epoch: 6| Step: 1
Training loss: 0.054184190928936005
Validation loss: 1.401613377755688

Epoch: 6| Step: 2
Training loss: 0.06217595934867859
Validation loss: 1.4064678261356969

Epoch: 6| Step: 3
Training loss: 0.11874230206012726
Validation loss: 1.4083133653927875

Epoch: 6| Step: 4
Training loss: 0.11144581437110901
Validation loss: 1.4187901853233256

Epoch: 6| Step: 5
Training loss: 0.11781282722949982
Validation loss: 1.4100441830132597

Epoch: 6| Step: 6
Training loss: 0.06631754338741302
Validation loss: 1.4255139968728507

Epoch: 6| Step: 7
Training loss: 0.062152035534381866
Validation loss: 1.416502861566441

Epoch: 6| Step: 8
Training loss: 0.04552522301673889
Validation loss: 1.4046672031443606

Epoch: 6| Step: 9
Training loss: 0.10118706524372101
Validation loss: 1.421666351697778

Epoch: 6| Step: 10
Training loss: 0.07148639857769012
Validation loss: 1.4207840170911563

Epoch: 6| Step: 11
Training loss: 0.05970557779073715
Validation loss: 1.4333853119163102

Epoch: 6| Step: 12
Training loss: 0.05443878099322319
Validation loss: 1.4006159959300872

Epoch: 6| Step: 13
Training loss: 0.08862137794494629
Validation loss: 1.3901879018352878

Epoch: 567| Step: 0
Training loss: 0.05566856265068054
Validation loss: 1.4131268737136677

Epoch: 6| Step: 1
Training loss: 0.09082236886024475
Validation loss: 1.3894194992639686

Epoch: 6| Step: 2
Training loss: 0.09607088565826416
Validation loss: 1.396895384275785

Epoch: 6| Step: 3
Training loss: 0.06864471733570099
Validation loss: 1.3913090357216455

Epoch: 6| Step: 4
Training loss: 0.06971768289804459
Validation loss: 1.3905253448793966

Epoch: 6| Step: 5
Training loss: 0.08820391446352005
Validation loss: 1.3662776831657655

Epoch: 6| Step: 6
Training loss: 0.05217297375202179
Validation loss: 1.401384699729181

Epoch: 6| Step: 7
Training loss: 0.07109443843364716
Validation loss: 1.367435129739905

Epoch: 6| Step: 8
Training loss: 0.046879082918167114
Validation loss: 1.3914735406957648

Epoch: 6| Step: 9
Training loss: 0.044219207018613815
Validation loss: 1.4082755331070191

Epoch: 6| Step: 10
Training loss: 0.08741691708564758
Validation loss: 1.403676475248029

Epoch: 6| Step: 11
Training loss: 0.08925753831863403
Validation loss: 1.3941934198461554

Epoch: 6| Step: 12
Training loss: 0.10316754877567291
Validation loss: 1.3888478407295801

Epoch: 6| Step: 13
Training loss: 0.11103468388319016
Validation loss: 1.4195664608350365

Epoch: 568| Step: 0
Training loss: 0.06881721317768097
Validation loss: 1.4218540947924379

Epoch: 6| Step: 1
Training loss: 0.12245221436023712
Validation loss: 1.4089088042577107

Epoch: 6| Step: 2
Training loss: 0.06245092302560806
Validation loss: 1.4204499477981238

Epoch: 6| Step: 3
Training loss: 0.07990050315856934
Validation loss: 1.4072259132580092

Epoch: 6| Step: 4
Training loss: 0.07127483934164047
Validation loss: 1.3976527157650198

Epoch: 6| Step: 5
Training loss: 0.06131403148174286
Validation loss: 1.3940978575778264

Epoch: 6| Step: 6
Training loss: 0.09061267226934433
Validation loss: 1.386456125526018

Epoch: 6| Step: 7
Training loss: 0.10322168469429016
Validation loss: 1.373435346029138

Epoch: 6| Step: 8
Training loss: 0.059738535434007645
Validation loss: 1.3824818993127475

Epoch: 6| Step: 9
Training loss: 0.033679693937301636
Validation loss: 1.3551337706145419

Epoch: 6| Step: 10
Training loss: 0.06054840236902237
Validation loss: 1.356978790734404

Epoch: 6| Step: 11
Training loss: 0.0967135950922966
Validation loss: 1.3818016385519376

Epoch: 6| Step: 12
Training loss: 0.0905068963766098
Validation loss: 1.3830484023658178

Epoch: 6| Step: 13
Training loss: 0.07545679062604904
Validation loss: 1.4122439481878792

Epoch: 569| Step: 0
Training loss: 0.13855472207069397
Validation loss: 1.4242037970532653

Epoch: 6| Step: 1
Training loss: 0.09219837188720703
Validation loss: 1.4589095820662796

Epoch: 6| Step: 2
Training loss: 0.08596056699752808
Validation loss: 1.4501373703761766

Epoch: 6| Step: 3
Training loss: 0.08837562799453735
Validation loss: 1.4710298321580375

Epoch: 6| Step: 4
Training loss: 0.07660265266895294
Validation loss: 1.4512312976262902

Epoch: 6| Step: 5
Training loss: 0.06268377602100372
Validation loss: 1.4652002126939836

Epoch: 6| Step: 6
Training loss: 0.0931367576122284
Validation loss: 1.4442343288852322

Epoch: 6| Step: 7
Training loss: 0.032936014235019684
Validation loss: 1.4194307968180666

Epoch: 6| Step: 8
Training loss: 0.13099050521850586
Validation loss: 1.3961665412431121

Epoch: 6| Step: 9
Training loss: 0.05169348791241646
Validation loss: 1.4082915936746905

Epoch: 6| Step: 10
Training loss: 0.14523856341838837
Validation loss: 1.4199796145962131

Epoch: 6| Step: 11
Training loss: 0.08019675314426422
Validation loss: 1.385140690752255

Epoch: 6| Step: 12
Training loss: 0.10729771107435226
Validation loss: 1.3897913425199446

Epoch: 6| Step: 13
Training loss: 0.08190052956342697
Validation loss: 1.3899661116702582

Epoch: 570| Step: 0
Training loss: 0.07167808711528778
Validation loss: 1.3728156781965686

Epoch: 6| Step: 1
Training loss: 0.0589599646627903
Validation loss: 1.367915698277053

Epoch: 6| Step: 2
Training loss: 0.10984249413013458
Validation loss: 1.387735641130837

Epoch: 6| Step: 3
Training loss: 0.15441326797008514
Validation loss: 1.4008183761309552

Epoch: 6| Step: 4
Training loss: 0.10864140093326569
Validation loss: 1.413399370767737

Epoch: 6| Step: 5
Training loss: 0.13063184916973114
Validation loss: 1.3994615667609758

Epoch: 6| Step: 6
Training loss: 0.06171180307865143
Validation loss: 1.4316268197951778

Epoch: 6| Step: 7
Training loss: 0.11499349027872086
Validation loss: 1.446997183625416

Epoch: 6| Step: 8
Training loss: 0.10546273738145828
Validation loss: 1.4435374916240733

Epoch: 6| Step: 9
Training loss: 0.1231832504272461
Validation loss: 1.442934727156034

Epoch: 6| Step: 10
Training loss: 0.07252954691648483
Validation loss: 1.4405629974539562

Epoch: 6| Step: 11
Training loss: 0.10791904479265213
Validation loss: 1.4434306288278231

Epoch: 6| Step: 12
Training loss: 0.10175509005784988
Validation loss: 1.4340935522510159

Epoch: 6| Step: 13
Training loss: 0.06266066431999207
Validation loss: 1.4172935703749299

Epoch: 571| Step: 0
Training loss: 0.09317268431186676
Validation loss: 1.4349547906588482

Epoch: 6| Step: 1
Training loss: 0.09440365433692932
Validation loss: 1.4361648687752344

Epoch: 6| Step: 2
Training loss: 0.12119241803884506
Validation loss: 1.4263266222451323

Epoch: 6| Step: 3
Training loss: 0.09591609984636307
Validation loss: 1.4013171625393692

Epoch: 6| Step: 4
Training loss: 0.06481827795505524
Validation loss: 1.367543633266162

Epoch: 6| Step: 5
Training loss: 0.12614265084266663
Validation loss: 1.3956777152194773

Epoch: 6| Step: 6
Training loss: 0.052480340003967285
Validation loss: 1.3569775678778206

Epoch: 6| Step: 7
Training loss: 0.1168365553021431
Validation loss: 1.335020940149984

Epoch: 6| Step: 8
Training loss: 0.1371108591556549
Validation loss: 1.359327015056405

Epoch: 6| Step: 9
Training loss: 0.10597329586744308
Validation loss: 1.3427436531230967

Epoch: 6| Step: 10
Training loss: 0.11883595585823059
Validation loss: 1.3721185371439943

Epoch: 6| Step: 11
Training loss: 0.09638933837413788
Validation loss: 1.3882780216073478

Epoch: 6| Step: 12
Training loss: 0.11041603237390518
Validation loss: 1.4026508369753439

Epoch: 6| Step: 13
Training loss: 0.07722128927707672
Validation loss: 1.4026173058376517

Epoch: 572| Step: 0
Training loss: 0.0847083330154419
Validation loss: 1.4182008786868023

Epoch: 6| Step: 1
Training loss: 0.07503724843263626
Validation loss: 1.4233193807704474

Epoch: 6| Step: 2
Training loss: 0.07761500030755997
Validation loss: 1.4382723595506401

Epoch: 6| Step: 3
Training loss: 0.11696219444274902
Validation loss: 1.4263224806836856

Epoch: 6| Step: 4
Training loss: 0.09186108410358429
Validation loss: 1.4523184991651965

Epoch: 6| Step: 5
Training loss: 0.07775253057479858
Validation loss: 1.4188355015170189

Epoch: 6| Step: 6
Training loss: 0.08700720220804214
Validation loss: 1.4005270324727541

Epoch: 6| Step: 7
Training loss: 0.08873715251684189
Validation loss: 1.3694541287678543

Epoch: 6| Step: 8
Training loss: 0.09915459901094437
Validation loss: 1.3594501928616596

Epoch: 6| Step: 9
Training loss: 0.11321604996919632
Validation loss: 1.382984935596425

Epoch: 6| Step: 10
Training loss: 0.15599152445793152
Validation loss: 1.3854797168444561

Epoch: 6| Step: 11
Training loss: 0.10931556671857834
Validation loss: 1.3853909905238817

Epoch: 6| Step: 12
Training loss: 0.13553258776664734
Validation loss: 1.3974441251447123

Epoch: 6| Step: 13
Training loss: 0.13370180130004883
Validation loss: 1.413260550909145

Epoch: 573| Step: 0
Training loss: 0.05349203944206238
Validation loss: 1.3835566838582356

Epoch: 6| Step: 1
Training loss: 0.11450698226690292
Validation loss: 1.426243325715424

Epoch: 6| Step: 2
Training loss: 0.10932618379592896
Validation loss: 1.4189793140657487

Epoch: 6| Step: 3
Training loss: 0.10586926341056824
Validation loss: 1.4204729193000383

Epoch: 6| Step: 4
Training loss: 0.0704503282904625
Validation loss: 1.457853525556544

Epoch: 6| Step: 5
Training loss: 0.10181986540555954
Validation loss: 1.4447623356696098

Epoch: 6| Step: 6
Training loss: 0.05342448130249977
Validation loss: 1.419161635060464

Epoch: 6| Step: 7
Training loss: 0.06019775569438934
Validation loss: 1.4384505223202448

Epoch: 6| Step: 8
Training loss: 0.05486804246902466
Validation loss: 1.4001939873541556

Epoch: 6| Step: 9
Training loss: 0.06703507900238037
Validation loss: 1.4379502355411489

Epoch: 6| Step: 10
Training loss: 0.12165119498968124
Validation loss: 1.4272595092814455

Epoch: 6| Step: 11
Training loss: 0.08639348298311234
Validation loss: 1.4154864434273011

Epoch: 6| Step: 12
Training loss: 0.08507855236530304
Validation loss: 1.4185504298056326

Epoch: 6| Step: 13
Training loss: 0.13010616600513458
Validation loss: 1.4085748093102568

Epoch: 574| Step: 0
Training loss: 0.09680602699518204
Validation loss: 1.4237270124496952

Epoch: 6| Step: 1
Training loss: 0.05696134269237518
Validation loss: 1.4216831743076284

Epoch: 6| Step: 2
Training loss: 0.05272223800420761
Validation loss: 1.4049155160944948

Epoch: 6| Step: 3
Training loss: 0.10114026069641113
Validation loss: 1.4096012064205703

Epoch: 6| Step: 4
Training loss: 0.06740658730268478
Validation loss: 1.4273449669602096

Epoch: 6| Step: 5
Training loss: 0.06827007234096527
Validation loss: 1.4332387434538973

Epoch: 6| Step: 6
Training loss: 0.11090057343244553
Validation loss: 1.4228956404552664

Epoch: 6| Step: 7
Training loss: 0.060827143490314484
Validation loss: 1.4427651179734098

Epoch: 6| Step: 8
Training loss: 0.043250907212495804
Validation loss: 1.4284696816116251

Epoch: 6| Step: 9
Training loss: 0.07517917454242706
Validation loss: 1.4163034885160384

Epoch: 6| Step: 10
Training loss: 0.07734957337379456
Validation loss: 1.4433064832482287

Epoch: 6| Step: 11
Training loss: 0.04522453248500824
Validation loss: 1.4191495151289049

Epoch: 6| Step: 12
Training loss: 0.06877616047859192
Validation loss: 1.4105001739276353

Epoch: 6| Step: 13
Training loss: 0.10670729726552963
Validation loss: 1.4089705367242136

Epoch: 575| Step: 0
Training loss: 0.05332844704389572
Validation loss: 1.3977220987760892

Epoch: 6| Step: 1
Training loss: 0.051133912056684494
Validation loss: 1.3874918363427604

Epoch: 6| Step: 2
Training loss: 0.09030546993017197
Validation loss: 1.3803340696519422

Epoch: 6| Step: 3
Training loss: 0.11707814782857895
Validation loss: 1.3739060464725699

Epoch: 6| Step: 4
Training loss: 0.10816936194896698
Validation loss: 1.3670071158357846

Epoch: 6| Step: 5
Training loss: 0.06753669679164886
Validation loss: 1.3523411827702676

Epoch: 6| Step: 6
Training loss: 0.08404640853404999
Validation loss: 1.3781663064033753

Epoch: 6| Step: 7
Training loss: 0.08364011347293854
Validation loss: 1.392514116020613

Epoch: 6| Step: 8
Training loss: 0.044687218964099884
Validation loss: 1.3776843573457451

Epoch: 6| Step: 9
Training loss: 0.050108980387449265
Validation loss: 1.4067553192056634

Epoch: 6| Step: 10
Training loss: 0.09574365615844727
Validation loss: 1.410977646868716

Epoch: 6| Step: 11
Training loss: 0.07306498289108276
Validation loss: 1.4414672992562736

Epoch: 6| Step: 12
Training loss: 0.07175276428461075
Validation loss: 1.4483731203181769

Epoch: 6| Step: 13
Training loss: 0.09307689219713211
Validation loss: 1.4641242104191934

Epoch: 576| Step: 0
Training loss: 0.08261868357658386
Validation loss: 1.4456711405067033

Epoch: 6| Step: 1
Training loss: 0.13866671919822693
Validation loss: 1.4524731418137908

Epoch: 6| Step: 2
Training loss: 0.039064034819602966
Validation loss: 1.4210513894275953

Epoch: 6| Step: 3
Training loss: 0.057942382991313934
Validation loss: 1.3890648324002501

Epoch: 6| Step: 4
Training loss: 0.028009792789816856
Validation loss: 1.4287117399195188

Epoch: 6| Step: 5
Training loss: 0.05973516032099724
Validation loss: 1.4021392701774515

Epoch: 6| Step: 6
Training loss: 0.06288033723831177
Validation loss: 1.3985253271236215

Epoch: 6| Step: 7
Training loss: 0.09609244763851166
Validation loss: 1.3646227320035298

Epoch: 6| Step: 8
Training loss: 0.0890047699213028
Validation loss: 1.3722087465306765

Epoch: 6| Step: 9
Training loss: 0.07847069203853607
Validation loss: 1.3610519452761578

Epoch: 6| Step: 10
Training loss: 0.0860646441578865
Validation loss: 1.365761185205111

Epoch: 6| Step: 11
Training loss: 0.06873679161071777
Validation loss: 1.381286080165576

Epoch: 6| Step: 12
Training loss: 0.12517163157463074
Validation loss: 1.3672668767231766

Epoch: 6| Step: 13
Training loss: 0.1164604127407074
Validation loss: 1.3630529078104163

Epoch: 577| Step: 0
Training loss: 0.05453597009181976
Validation loss: 1.387380996058064

Epoch: 6| Step: 1
Training loss: 0.061766915023326874
Validation loss: 1.392192582930288

Epoch: 6| Step: 2
Training loss: 0.06702801585197449
Validation loss: 1.396850980738158

Epoch: 6| Step: 3
Training loss: 0.0210128054022789
Validation loss: 1.3940153814131213

Epoch: 6| Step: 4
Training loss: 0.07381658256053925
Validation loss: 1.3947163935630553

Epoch: 6| Step: 5
Training loss: 0.03885127231478691
Validation loss: 1.3918659449905477

Epoch: 6| Step: 6
Training loss: 0.05245969444513321
Validation loss: 1.3919524300482966

Epoch: 6| Step: 7
Training loss: 0.1035250574350357
Validation loss: 1.3785167541555179

Epoch: 6| Step: 8
Training loss: 0.08394331485033035
Validation loss: 1.3916517060290101

Epoch: 6| Step: 9
Training loss: 0.039213769137859344
Validation loss: 1.3728949818559872

Epoch: 6| Step: 10
Training loss: 0.06877952814102173
Validation loss: 1.3795152037374434

Epoch: 6| Step: 11
Training loss: 0.04694549739360809
Validation loss: 1.3890116291661416

Epoch: 6| Step: 12
Training loss: 0.10596971213817596
Validation loss: 1.3962050740436842

Epoch: 6| Step: 13
Training loss: 0.062352076172828674
Validation loss: 1.419965059526505

Epoch: 578| Step: 0
Training loss: 0.0718832015991211
Validation loss: 1.3872179215954197

Epoch: 6| Step: 1
Training loss: 0.10088509321212769
Validation loss: 1.3650595372722996

Epoch: 6| Step: 2
Training loss: 0.03306179493665695
Validation loss: 1.397892093145719

Epoch: 6| Step: 3
Training loss: 0.028183087706565857
Validation loss: 1.373449203147683

Epoch: 6| Step: 4
Training loss: 0.09317256510257721
Validation loss: 1.361282366578297

Epoch: 6| Step: 5
Training loss: 0.06888260692358017
Validation loss: 1.3623864971181399

Epoch: 6| Step: 6
Training loss: 0.08291187137365341
Validation loss: 1.362079511406601

Epoch: 6| Step: 7
Training loss: 0.09717583656311035
Validation loss: 1.3600617108806488

Epoch: 6| Step: 8
Training loss: 0.04240833967924118
Validation loss: 1.3937823669884795

Epoch: 6| Step: 9
Training loss: 0.04186695069074631
Validation loss: 1.4079521945727769

Epoch: 6| Step: 10
Training loss: 0.054975688457489014
Validation loss: 1.408514211254735

Epoch: 6| Step: 11
Training loss: 0.08385471999645233
Validation loss: 1.4035612088377758

Epoch: 6| Step: 12
Training loss: 0.03910753130912781
Validation loss: 1.4133459573150964

Epoch: 6| Step: 13
Training loss: 0.12983404099941254
Validation loss: 1.372555726317949

Epoch: 579| Step: 0
Training loss: 0.12560176849365234
Validation loss: 1.3974645509514758

Epoch: 6| Step: 1
Training loss: 0.06897138804197311
Validation loss: 1.3701339921643656

Epoch: 6| Step: 2
Training loss: 0.09944399446249008
Validation loss: 1.3823256761797014

Epoch: 6| Step: 3
Training loss: 0.09869961440563202
Validation loss: 1.3575882873227518

Epoch: 6| Step: 4
Training loss: 0.054344937205314636
Validation loss: 1.3950480491884294

Epoch: 6| Step: 5
Training loss: 0.10422651469707489
Validation loss: 1.3922775714628157

Epoch: 6| Step: 6
Training loss: 0.057271189987659454
Validation loss: 1.3880164046441354

Epoch: 6| Step: 7
Training loss: 0.1330794095993042
Validation loss: 1.3990261131717312

Epoch: 6| Step: 8
Training loss: 0.13245636224746704
Validation loss: 1.4083860676775697

Epoch: 6| Step: 9
Training loss: 0.05551657825708389
Validation loss: 1.3982592616029965

Epoch: 6| Step: 10
Training loss: 0.08719456195831299
Validation loss: 1.415710037754428

Epoch: 6| Step: 11
Training loss: 0.04794390872120857
Validation loss: 1.3992015713004655

Epoch: 6| Step: 12
Training loss: 0.04470222443342209
Validation loss: 1.3989988885900027

Epoch: 6| Step: 13
Training loss: 0.035476431250572205
Validation loss: 1.373517297929333

Epoch: 580| Step: 0
Training loss: 0.0602276474237442
Validation loss: 1.389097995014601

Epoch: 6| Step: 1
Training loss: 0.05944249778985977
Validation loss: 1.3892414800582393

Epoch: 6| Step: 2
Training loss: 0.04585292190313339
Validation loss: 1.3703829780701668

Epoch: 6| Step: 3
Training loss: 0.06420430541038513
Validation loss: 1.3553506712759695

Epoch: 6| Step: 4
Training loss: 0.07414165884256363
Validation loss: 1.3571068292023034

Epoch: 6| Step: 5
Training loss: 0.134229838848114
Validation loss: 1.3473715769347323

Epoch: 6| Step: 6
Training loss: 0.13094191253185272
Validation loss: 1.370533484925506

Epoch: 6| Step: 7
Training loss: 0.07488632947206497
Validation loss: 1.3720314694989113

Epoch: 6| Step: 8
Training loss: 0.07142387330532074
Validation loss: 1.3812027644085627

Epoch: 6| Step: 9
Training loss: 0.07675270736217499
Validation loss: 1.3971556168730541

Epoch: 6| Step: 10
Training loss: 0.051561012864112854
Validation loss: 1.4484426988068448

Epoch: 6| Step: 11
Training loss: 0.03233189135789871
Validation loss: 1.45612508122639

Epoch: 6| Step: 12
Training loss: 0.07775461673736572
Validation loss: 1.446821931869753

Epoch: 6| Step: 13
Training loss: 0.13534697890281677
Validation loss: 1.4454718789746683

Epoch: 581| Step: 0
Training loss: 0.09033824503421783
Validation loss: 1.4327652755603995

Epoch: 6| Step: 1
Training loss: 0.049794796854257584
Validation loss: 1.4390409813132337

Epoch: 6| Step: 2
Training loss: 0.05061912536621094
Validation loss: 1.4023187525810734

Epoch: 6| Step: 3
Training loss: 0.06740512698888779
Validation loss: 1.4083872943796136

Epoch: 6| Step: 4
Training loss: 0.08049528300762177
Validation loss: 1.4115321520836122

Epoch: 6| Step: 5
Training loss: 0.06990662217140198
Validation loss: 1.3853587155701013

Epoch: 6| Step: 6
Training loss: 0.08820487558841705
Validation loss: 1.4004178559908302

Epoch: 6| Step: 7
Training loss: 0.08932556957006454
Validation loss: 1.4093301347506944

Epoch: 6| Step: 8
Training loss: 0.07535611093044281
Validation loss: 1.40597947694922

Epoch: 6| Step: 9
Training loss: 0.0734689012169838
Validation loss: 1.3975648777459257

Epoch: 6| Step: 10
Training loss: 0.08899476379156113
Validation loss: 1.403774974166706

Epoch: 6| Step: 11
Training loss: 0.1005253866314888
Validation loss: 1.404437013851699

Epoch: 6| Step: 12
Training loss: 0.06876778602600098
Validation loss: 1.4198755577046385

Epoch: 6| Step: 13
Training loss: 0.04859723150730133
Validation loss: 1.4152287988252537

Epoch: 582| Step: 0
Training loss: 0.06881271302700043
Validation loss: 1.409675701971977

Epoch: 6| Step: 1
Training loss: 0.09604085236787796
Validation loss: 1.4366793119779198

Epoch: 6| Step: 2
Training loss: 0.08335942029953003
Validation loss: 1.4080761132701751

Epoch: 6| Step: 3
Training loss: 0.09376667439937592
Validation loss: 1.4266860036439792

Epoch: 6| Step: 4
Training loss: 0.08970703184604645
Validation loss: 1.3853684138226252

Epoch: 6| Step: 5
Training loss: 0.0631139799952507
Validation loss: 1.367805370720484

Epoch: 6| Step: 6
Training loss: 0.08871662616729736
Validation loss: 1.3917474740295

Epoch: 6| Step: 7
Training loss: 0.07307985424995422
Validation loss: 1.3827384466766028

Epoch: 6| Step: 8
Training loss: 0.07030663639307022
Validation loss: 1.3829038207248976

Epoch: 6| Step: 9
Training loss: 0.10897256433963776
Validation loss: 1.407879803770332

Epoch: 6| Step: 10
Training loss: 0.055710386484861374
Validation loss: 1.4028658431063417

Epoch: 6| Step: 11
Training loss: 0.09881629794836044
Validation loss: 1.4200257460276287

Epoch: 6| Step: 12
Training loss: 0.09270761907100677
Validation loss: 1.4340145062374812

Epoch: 6| Step: 13
Training loss: 0.06263504922389984
Validation loss: 1.4236974408549647

Epoch: 583| Step: 0
Training loss: 0.049457989633083344
Validation loss: 1.433739294287979

Epoch: 6| Step: 1
Training loss: 0.06651577353477478
Validation loss: 1.4256539479378731

Epoch: 6| Step: 2
Training loss: 0.03533834218978882
Validation loss: 1.4310968236256671

Epoch: 6| Step: 3
Training loss: 0.0876721739768982
Validation loss: 1.3997628035083893

Epoch: 6| Step: 4
Training loss: 0.06676270067691803
Validation loss: 1.4046461569365634

Epoch: 6| Step: 5
Training loss: 0.06887659430503845
Validation loss: 1.4111118592241758

Epoch: 6| Step: 6
Training loss: 0.06454439461231232
Validation loss: 1.384165858709684

Epoch: 6| Step: 7
Training loss: 0.09560703486204147
Validation loss: 1.3769274873118247

Epoch: 6| Step: 8
Training loss: 0.083797387778759
Validation loss: 1.3865612463284565

Epoch: 6| Step: 9
Training loss: 0.08127723634243011
Validation loss: 1.40301090158442

Epoch: 6| Step: 10
Training loss: 0.07401163130998611
Validation loss: 1.3791123397888676

Epoch: 6| Step: 11
Training loss: 0.04597344994544983
Validation loss: 1.3903106374125327

Epoch: 6| Step: 12
Training loss: 0.061301589012145996
Validation loss: 1.3959174553553264

Epoch: 6| Step: 13
Training loss: 0.08798623830080032
Validation loss: 1.3892038804228588

Epoch: 584| Step: 0
Training loss: 0.11305943131446838
Validation loss: 1.398425514980029

Epoch: 6| Step: 1
Training loss: 0.07586123049259186
Validation loss: 1.4086341819455546

Epoch: 6| Step: 2
Training loss: 0.04712420329451561
Validation loss: 1.400949126930647

Epoch: 6| Step: 3
Training loss: 0.06493070721626282
Validation loss: 1.4183671884639288

Epoch: 6| Step: 4
Training loss: 0.06168510764837265
Validation loss: 1.423574919982623

Epoch: 6| Step: 5
Training loss: 0.05325224623084068
Validation loss: 1.4246897312902636

Epoch: 6| Step: 6
Training loss: 0.0944090336561203
Validation loss: 1.4439886475122103

Epoch: 6| Step: 7
Training loss: 0.06777619570493698
Validation loss: 1.4351233384942497

Epoch: 6| Step: 8
Training loss: 0.07643438130617142
Validation loss: 1.3829372621351672

Epoch: 6| Step: 9
Training loss: 0.06798461079597473
Validation loss: 1.3788041696753552

Epoch: 6| Step: 10
Training loss: 0.0541539303958416
Validation loss: 1.3574779315661358

Epoch: 6| Step: 11
Training loss: 0.10847253352403641
Validation loss: 1.3756337806742678

Epoch: 6| Step: 12
Training loss: 0.1403670310974121
Validation loss: 1.3799460857145247

Epoch: 6| Step: 13
Training loss: 0.03566586598753929
Validation loss: 1.3809445711874193

Epoch: 585| Step: 0
Training loss: 0.10177642852067947
Validation loss: 1.3903150904563166

Epoch: 6| Step: 1
Training loss: 0.051868557929992676
Validation loss: 1.3923025605499104

Epoch: 6| Step: 2
Training loss: 0.08128925412893295
Validation loss: 1.4024842836523568

Epoch: 6| Step: 3
Training loss: 0.05158573389053345
Validation loss: 1.3930361014540478

Epoch: 6| Step: 4
Training loss: 0.12145388871431351
Validation loss: 1.439939909083869

Epoch: 6| Step: 5
Training loss: 0.06087810546159744
Validation loss: 1.4469867290989045

Epoch: 6| Step: 6
Training loss: 0.08552014827728271
Validation loss: 1.4760339760011243

Epoch: 6| Step: 7
Training loss: 0.09820711612701416
Validation loss: 1.4485232458319715

Epoch: 6| Step: 8
Training loss: 0.06566744297742844
Validation loss: 1.4478531447790002

Epoch: 6| Step: 9
Training loss: 0.08993774652481079
Validation loss: 1.4249721509154125

Epoch: 6| Step: 10
Training loss: 0.09284940361976624
Validation loss: 1.4272245104594896

Epoch: 6| Step: 11
Training loss: 0.06565190851688385
Validation loss: 1.3835405765041229

Epoch: 6| Step: 12
Training loss: 0.055202122777700424
Validation loss: 1.415876498786352

Epoch: 6| Step: 13
Training loss: 0.15619632601737976
Validation loss: 1.4050638944871965

Epoch: 586| Step: 0
Training loss: 0.09107273817062378
Validation loss: 1.4192904157023276

Epoch: 6| Step: 1
Training loss: 0.07138566672801971
Validation loss: 1.3833591643200125

Epoch: 6| Step: 2
Training loss: 0.09695681929588318
Validation loss: 1.4084298059504519

Epoch: 6| Step: 3
Training loss: 0.05405053496360779
Validation loss: 1.4092258766133299

Epoch: 6| Step: 4
Training loss: 0.10128944367170334
Validation loss: 1.417810889982408

Epoch: 6| Step: 5
Training loss: 0.10599394887685776
Validation loss: 1.4205094082381136

Epoch: 6| Step: 6
Training loss: 0.07645563036203384
Validation loss: 1.4214402014209377

Epoch: 6| Step: 7
Training loss: 0.06135961413383484
Validation loss: 1.402313998950425

Epoch: 6| Step: 8
Training loss: 0.10315223783254623
Validation loss: 1.4153718807364022

Epoch: 6| Step: 9
Training loss: 0.07581233978271484
Validation loss: 1.4352447063692155

Epoch: 6| Step: 10
Training loss: 0.05120476707816124
Validation loss: 1.4317288956334513

Epoch: 6| Step: 11
Training loss: 0.08735864609479904
Validation loss: 1.4202050483354958

Epoch: 6| Step: 12
Training loss: 0.108073890209198
Validation loss: 1.4228152414803863

Epoch: 6| Step: 13
Training loss: 0.13466772437095642
Validation loss: 1.421524372152103

Epoch: 587| Step: 0
Training loss: 0.10553711652755737
Validation loss: 1.421322609788628

Epoch: 6| Step: 1
Training loss: 0.06632515788078308
Validation loss: 1.4258578086412081

Epoch: 6| Step: 2
Training loss: 0.06559747457504272
Validation loss: 1.4448952354410642

Epoch: 6| Step: 3
Training loss: 0.07461231201887131
Validation loss: 1.449632873458247

Epoch: 6| Step: 4
Training loss: 0.067244753241539
Validation loss: 1.4201547920062978

Epoch: 6| Step: 5
Training loss: 0.07704176753759384
Validation loss: 1.4404179126985612

Epoch: 6| Step: 6
Training loss: 0.07224991917610168
Validation loss: 1.412179828971945

Epoch: 6| Step: 7
Training loss: 0.061545480042696
Validation loss: 1.4136204347815564

Epoch: 6| Step: 8
Training loss: 0.10951633751392365
Validation loss: 1.4124731107424664

Epoch: 6| Step: 9
Training loss: 0.10676754266023636
Validation loss: 1.4131310806479505

Epoch: 6| Step: 10
Training loss: 0.05783925577998161
Validation loss: 1.394074531011684

Epoch: 6| Step: 11
Training loss: 0.15102875232696533
Validation loss: 1.4036493352664414

Epoch: 6| Step: 12
Training loss: 0.0813715010881424
Validation loss: 1.4132092806600756

Epoch: 6| Step: 13
Training loss: 0.0649443045258522
Validation loss: 1.4070036654831262

Epoch: 588| Step: 0
Training loss: 0.08485430479049683
Validation loss: 1.4211609107191845

Epoch: 6| Step: 1
Training loss: 0.1070641279220581
Validation loss: 1.3886231914643319

Epoch: 6| Step: 2
Training loss: 0.07239818572998047
Validation loss: 1.3959632842771468

Epoch: 6| Step: 3
Training loss: 0.05232549458742142
Validation loss: 1.403164573895034

Epoch: 6| Step: 4
Training loss: 0.06820648908615112
Validation loss: 1.4163021285046813

Epoch: 6| Step: 5
Training loss: 0.0797044113278389
Validation loss: 1.4202744819784676

Epoch: 6| Step: 6
Training loss: 0.04661460965871811
Validation loss: 1.4050449113692007

Epoch: 6| Step: 7
Training loss: 0.07325965166091919
Validation loss: 1.414375042402616

Epoch: 6| Step: 8
Training loss: 0.1173507422208786
Validation loss: 1.4352202492375528

Epoch: 6| Step: 9
Training loss: 0.05771730840206146
Validation loss: 1.411950058834527

Epoch: 6| Step: 10
Training loss: 0.10974619537591934
Validation loss: 1.432092688416922

Epoch: 6| Step: 11
Training loss: 0.09930676966905594
Validation loss: 1.422166088575958

Epoch: 6| Step: 12
Training loss: 0.12373480200767517
Validation loss: 1.3858957611104494

Epoch: 6| Step: 13
Training loss: 0.07302824407815933
Validation loss: 1.3945984257164823

Epoch: 589| Step: 0
Training loss: 0.07681502401828766
Validation loss: 1.3802428950545609

Epoch: 6| Step: 1
Training loss: 0.12851600348949432
Validation loss: 1.4156016617692926

Epoch: 6| Step: 2
Training loss: 0.09922565519809723
Validation loss: 1.4250522467397875

Epoch: 6| Step: 3
Training loss: 0.07073985040187836
Validation loss: 1.419652210768833

Epoch: 6| Step: 4
Training loss: 0.07624543458223343
Validation loss: 1.4336682250422816

Epoch: 6| Step: 5
Training loss: 0.09437675774097443
Validation loss: 1.4153321366156302

Epoch: 6| Step: 6
Training loss: 0.06838569790124893
Validation loss: 1.4414738910172575

Epoch: 6| Step: 7
Training loss: 0.037205323576927185
Validation loss: 1.425773633423672

Epoch: 6| Step: 8
Training loss: 0.1539088934659958
Validation loss: 1.4273113345587125

Epoch: 6| Step: 9
Training loss: 0.0630696713924408
Validation loss: 1.413921457464977

Epoch: 6| Step: 10
Training loss: 0.09388145804405212
Validation loss: 1.4104330334612118

Epoch: 6| Step: 11
Training loss: 0.09882233291864395
Validation loss: 1.413367723905912

Epoch: 6| Step: 12
Training loss: 0.0923302173614502
Validation loss: 1.4205493491183045

Epoch: 6| Step: 13
Training loss: 0.061178430914878845
Validation loss: 1.4314772044458697

Epoch: 590| Step: 0
Training loss: 0.08433344960212708
Validation loss: 1.4565163273965158

Epoch: 6| Step: 1
Training loss: 0.09834820032119751
Validation loss: 1.4780764759227794

Epoch: 6| Step: 2
Training loss: 0.10070125013589859
Validation loss: 1.4722205938831452

Epoch: 6| Step: 3
Training loss: 0.06250423938035965
Validation loss: 1.474236729324505

Epoch: 6| Step: 4
Training loss: 0.08974669873714447
Validation loss: 1.483058342369654

Epoch: 6| Step: 5
Training loss: 0.1264275461435318
Validation loss: 1.5089849989901307

Epoch: 6| Step: 6
Training loss: 0.08366993814706802
Validation loss: 1.4901501991415536

Epoch: 6| Step: 7
Training loss: 0.10551712661981583
Validation loss: 1.4390852784597745

Epoch: 6| Step: 8
Training loss: 0.07354265451431274
Validation loss: 1.4440309597599892

Epoch: 6| Step: 9
Training loss: 0.08562382310628891
Validation loss: 1.4061374484851796

Epoch: 6| Step: 10
Training loss: 0.11636671423912048
Validation loss: 1.388658506895906

Epoch: 6| Step: 11
Training loss: 0.06278984993696213
Validation loss: 1.3745570317391427

Epoch: 6| Step: 12
Training loss: 0.07233604043722153
Validation loss: 1.3459780703308761

Epoch: 6| Step: 13
Training loss: 0.0729234516620636
Validation loss: 1.3452173291995961

Epoch: 591| Step: 0
Training loss: 0.10921447724103928
Validation loss: 1.3568743480149137

Epoch: 6| Step: 1
Training loss: 0.08168958127498627
Validation loss: 1.3659355922411847

Epoch: 6| Step: 2
Training loss: 0.10584528744220734
Validation loss: 1.3539322435214955

Epoch: 6| Step: 3
Training loss: 0.059171807020902634
Validation loss: 1.4097766184037732

Epoch: 6| Step: 4
Training loss: 0.06607425212860107
Validation loss: 1.4338511715653122

Epoch: 6| Step: 5
Training loss: 0.08838802576065063
Validation loss: 1.4430476337350824

Epoch: 6| Step: 6
Training loss: 0.14007022976875305
Validation loss: 1.468043751614068

Epoch: 6| Step: 7
Training loss: 0.06653772294521332
Validation loss: 1.438961713544784

Epoch: 6| Step: 8
Training loss: 0.07910405099391937
Validation loss: 1.421172691929725

Epoch: 6| Step: 9
Training loss: 0.040761880576610565
Validation loss: 1.4095398585001628

Epoch: 6| Step: 10
Training loss: 0.08226537704467773
Validation loss: 1.385003892324304

Epoch: 6| Step: 11
Training loss: 0.08596630394458771
Validation loss: 1.3738671310486332

Epoch: 6| Step: 12
Training loss: 0.10233809053897858
Validation loss: 1.3690220963570379

Epoch: 6| Step: 13
Training loss: 0.08072749525308609
Validation loss: 1.369539422373618

Epoch: 592| Step: 0
Training loss: 0.0953182578086853
Validation loss: 1.3732849141602874

Epoch: 6| Step: 1
Training loss: 0.08735855668783188
Validation loss: 1.3495791176313996

Epoch: 6| Step: 2
Training loss: 0.08757095038890839
Validation loss: 1.370373934827825

Epoch: 6| Step: 3
Training loss: 0.07594934105873108
Validation loss: 1.3906106910397928

Epoch: 6| Step: 4
Training loss: 0.11708907037973404
Validation loss: 1.4024275156759447

Epoch: 6| Step: 5
Training loss: 0.06256131827831268
Validation loss: 1.4206137541801698

Epoch: 6| Step: 6
Training loss: 0.09936406463384628
Validation loss: 1.4427291731680594

Epoch: 6| Step: 7
Training loss: 0.06298631429672241
Validation loss: 1.424830041905885

Epoch: 6| Step: 8
Training loss: 0.06296619772911072
Validation loss: 1.4213792765012352

Epoch: 6| Step: 9
Training loss: 0.05999486893415451
Validation loss: 1.4169135824326546

Epoch: 6| Step: 10
Training loss: 0.14061231911182404
Validation loss: 1.418755527465574

Epoch: 6| Step: 11
Training loss: 0.10273003578186035
Validation loss: 1.4356790082429045

Epoch: 6| Step: 12
Training loss: 0.0537942498922348
Validation loss: 1.4065224009175454

Epoch: 6| Step: 13
Training loss: 0.1146087497472763
Validation loss: 1.377022797061551

Epoch: 593| Step: 0
Training loss: 0.08561548590660095
Validation loss: 1.3835580400241319

Epoch: 6| Step: 1
Training loss: 0.09148548543453217
Validation loss: 1.3748758659567883

Epoch: 6| Step: 2
Training loss: 0.08403949439525604
Validation loss: 1.3901819554708337

Epoch: 6| Step: 3
Training loss: 0.04961804673075676
Validation loss: 1.3698682611988438

Epoch: 6| Step: 4
Training loss: 0.058959998190402985
Validation loss: 1.3854223746125416

Epoch: 6| Step: 5
Training loss: 0.08822927623987198
Validation loss: 1.4061930410323604

Epoch: 6| Step: 6
Training loss: 0.08009257912635803
Validation loss: 1.3871336688277542

Epoch: 6| Step: 7
Training loss: 0.0763879120349884
Validation loss: 1.3710533700963503

Epoch: 6| Step: 8
Training loss: 0.030628055334091187
Validation loss: 1.3914967236980316

Epoch: 6| Step: 9
Training loss: 0.06787572801113129
Validation loss: 1.4096081179957236

Epoch: 6| Step: 10
Training loss: 0.08680935204029083
Validation loss: 1.4234617320440148

Epoch: 6| Step: 11
Training loss: 0.0882672369480133
Validation loss: 1.411667158526759

Epoch: 6| Step: 12
Training loss: 0.059231966733932495
Validation loss: 1.433698828502368

Epoch: 6| Step: 13
Training loss: 0.11216257512569427
Validation loss: 1.4226465955857308

Epoch: 594| Step: 0
Training loss: 0.07073644548654556
Validation loss: 1.419154018484136

Epoch: 6| Step: 1
Training loss: 0.06169196218252182
Validation loss: 1.432019345221981

Epoch: 6| Step: 2
Training loss: 0.06351373344659805
Validation loss: 1.3867858802118609

Epoch: 6| Step: 3
Training loss: 0.0588243268430233
Validation loss: 1.3984039739895893

Epoch: 6| Step: 4
Training loss: 0.05483970046043396
Validation loss: 1.385598503133302

Epoch: 6| Step: 5
Training loss: 0.0915507823228836
Validation loss: 1.371484871833555

Epoch: 6| Step: 6
Training loss: 0.032243043184280396
Validation loss: 1.3562097421256445

Epoch: 6| Step: 7
Training loss: 0.07745879143476486
Validation loss: 1.3675315828733547

Epoch: 6| Step: 8
Training loss: 0.10869355499744415
Validation loss: 1.3888494365958757

Epoch: 6| Step: 9
Training loss: 0.092924565076828
Validation loss: 1.3841261479162401

Epoch: 6| Step: 10
Training loss: 0.04843347892165184
Validation loss: 1.3629022388048069

Epoch: 6| Step: 11
Training loss: 0.031372252851724625
Validation loss: 1.3898965953498759

Epoch: 6| Step: 12
Training loss: 0.05296100676059723
Validation loss: 1.3736151623469528

Epoch: 6| Step: 13
Training loss: 0.10635527968406677
Validation loss: 1.397563849726031

Epoch: 595| Step: 0
Training loss: 0.0511280819773674
Validation loss: 1.3723485585181945

Epoch: 6| Step: 1
Training loss: 0.06643610447645187
Validation loss: 1.3622306892948766

Epoch: 6| Step: 2
Training loss: 0.05167863890528679
Validation loss: 1.3913659754619803

Epoch: 6| Step: 3
Training loss: 0.06677138060331345
Validation loss: 1.4109876078944052

Epoch: 6| Step: 4
Training loss: 0.05175420641899109
Validation loss: 1.3985649507532838

Epoch: 6| Step: 5
Training loss: 0.0826619490981102
Validation loss: 1.393769323184926

Epoch: 6| Step: 6
Training loss: 0.06858542561531067
Validation loss: 1.430222422845902

Epoch: 6| Step: 7
Training loss: 0.08840807527303696
Validation loss: 1.4121449564092903

Epoch: 6| Step: 8
Training loss: 0.10332652926445007
Validation loss: 1.4260549391469648

Epoch: 6| Step: 9
Training loss: 0.08026613295078278
Validation loss: 1.3908221708830966

Epoch: 6| Step: 10
Training loss: 0.09365669637918472
Validation loss: 1.4468602031789801

Epoch: 6| Step: 11
Training loss: 0.08314451575279236
Validation loss: 1.4337536916937879

Epoch: 6| Step: 12
Training loss: 0.07452380657196045
Validation loss: 1.4349087463912142

Epoch: 6| Step: 13
Training loss: 0.17389363050460815
Validation loss: 1.4470021506791473

Epoch: 596| Step: 0
Training loss: 0.06902267038822174
Validation loss: 1.4422699866756317

Epoch: 6| Step: 1
Training loss: 0.042327627539634705
Validation loss: 1.4405032178407073

Epoch: 6| Step: 2
Training loss: 0.10366576910018921
Validation loss: 1.4453287400225157

Epoch: 6| Step: 3
Training loss: 0.06470076739788055
Validation loss: 1.4100198406045155

Epoch: 6| Step: 4
Training loss: 0.08495216071605682
Validation loss: 1.4521697387900403

Epoch: 6| Step: 5
Training loss: 0.09043973684310913
Validation loss: 1.4283921410960536

Epoch: 6| Step: 6
Training loss: 0.06550736725330353
Validation loss: 1.4107459463098997

Epoch: 6| Step: 7
Training loss: 0.03691025450825691
Validation loss: 1.413799112842929

Epoch: 6| Step: 8
Training loss: 0.06042128801345825
Validation loss: 1.3901856894134192

Epoch: 6| Step: 9
Training loss: 0.09544950723648071
Validation loss: 1.3771539747074086

Epoch: 6| Step: 10
Training loss: 0.045161642134189606
Validation loss: 1.3744378410359865

Epoch: 6| Step: 11
Training loss: 0.11134234070777893
Validation loss: 1.3685446823796918

Epoch: 6| Step: 12
Training loss: 0.08730015158653259
Validation loss: 1.36943773300417

Epoch: 6| Step: 13
Training loss: 0.07242169976234436
Validation loss: 1.3867072828354374

Epoch: 597| Step: 0
Training loss: 0.08794799447059631
Validation loss: 1.3800211606487152

Epoch: 6| Step: 1
Training loss: 0.05168405920267105
Validation loss: 1.387453366351384

Epoch: 6| Step: 2
Training loss: 0.05691466107964516
Validation loss: 1.387998463005148

Epoch: 6| Step: 3
Training loss: 0.03844550997018814
Validation loss: 1.4077978287973711

Epoch: 6| Step: 4
Training loss: 0.07800568640232086
Validation loss: 1.422982172299457

Epoch: 6| Step: 5
Training loss: 0.0614037960767746
Validation loss: 1.398608922958374

Epoch: 6| Step: 6
Training loss: 0.10276943445205688
Validation loss: 1.4125243143368793

Epoch: 6| Step: 7
Training loss: 0.06268498301506042
Validation loss: 1.4235313130963234

Epoch: 6| Step: 8
Training loss: 0.07088184356689453
Validation loss: 1.4019390677893033

Epoch: 6| Step: 9
Training loss: 0.08119869232177734
Validation loss: 1.402459709234135

Epoch: 6| Step: 10
Training loss: 0.05112574249505997
Validation loss: 1.4122915601217618

Epoch: 6| Step: 11
Training loss: 0.0830218493938446
Validation loss: 1.40717194157262

Epoch: 6| Step: 12
Training loss: 0.0588841512799263
Validation loss: 1.386370902420372

Epoch: 6| Step: 13
Training loss: 0.10248017311096191
Validation loss: 1.4187140349418885

Epoch: 598| Step: 0
Training loss: 0.03755362331867218
Validation loss: 1.4032585902880597

Epoch: 6| Step: 1
Training loss: 0.05051710829138756
Validation loss: 1.3967392867611301

Epoch: 6| Step: 2
Training loss: 0.07682982087135315
Validation loss: 1.3930520293533162

Epoch: 6| Step: 3
Training loss: 0.08125869929790497
Validation loss: 1.421867533396649

Epoch: 6| Step: 4
Training loss: 0.06404069066047668
Validation loss: 1.3975355637970792

Epoch: 6| Step: 5
Training loss: 0.07680327445268631
Validation loss: 1.421630100537372

Epoch: 6| Step: 6
Training loss: 0.05443984642624855
Validation loss: 1.4002200877794655

Epoch: 6| Step: 7
Training loss: 0.10693449527025223
Validation loss: 1.4175338360571093

Epoch: 6| Step: 8
Training loss: 0.09727565944194794
Validation loss: 1.409260824162473

Epoch: 6| Step: 9
Training loss: 0.06864115595817566
Validation loss: 1.407995803381807

Epoch: 6| Step: 10
Training loss: 0.06559821963310242
Validation loss: 1.3876069937982867

Epoch: 6| Step: 11
Training loss: 0.05519358068704605
Validation loss: 1.3949526779113277

Epoch: 6| Step: 12
Training loss: 0.06114759296178818
Validation loss: 1.428823386469195

Epoch: 6| Step: 13
Training loss: 0.11265778541564941
Validation loss: 1.403279141072304

Epoch: 599| Step: 0
Training loss: 0.0809006541967392
Validation loss: 1.411357270774021

Epoch: 6| Step: 1
Training loss: 0.061762019991874695
Validation loss: 1.4267846422810708

Epoch: 6| Step: 2
Training loss: 0.03499171882867813
Validation loss: 1.3906954616628668

Epoch: 6| Step: 3
Training loss: 0.051157817244529724
Validation loss: 1.4057951415738752

Epoch: 6| Step: 4
Training loss: 0.09971584379673004
Validation loss: 1.3797636134650118

Epoch: 6| Step: 5
Training loss: 0.06105091795325279
Validation loss: 1.3568436330364597

Epoch: 6| Step: 6
Training loss: 0.10929257422685623
Validation loss: 1.3692267287162043

Epoch: 6| Step: 7
Training loss: 0.13154146075248718
Validation loss: 1.3681161733724738

Epoch: 6| Step: 8
Training loss: 0.07806885987520218
Validation loss: 1.36855104918121

Epoch: 6| Step: 9
Training loss: 0.06710551679134369
Validation loss: 1.3702812976734613

Epoch: 6| Step: 10
Training loss: 0.06690628081560135
Validation loss: 1.4112724540054158

Epoch: 6| Step: 11
Training loss: 0.08015169203281403
Validation loss: 1.3890478264900945

Epoch: 6| Step: 12
Training loss: 0.04201171547174454
Validation loss: 1.405987161462025

Epoch: 6| Step: 13
Training loss: 0.0420554094016552
Validation loss: 1.3945236770055627

Epoch: 600| Step: 0
Training loss: 0.07336267083883286
Validation loss: 1.4054038934810187

Epoch: 6| Step: 1
Training loss: 0.1083751991391182
Validation loss: 1.4035728875026907

Epoch: 6| Step: 2
Training loss: 0.05756690353155136
Validation loss: 1.41443109127783

Epoch: 6| Step: 3
Training loss: 0.05593455210328102
Validation loss: 1.3898301509118849

Epoch: 6| Step: 4
Training loss: 0.08517900109291077
Validation loss: 1.3816782723190963

Epoch: 6| Step: 5
Training loss: 0.10821376740932465
Validation loss: 1.3887610948213966

Epoch: 6| Step: 6
Training loss: 0.0731733962893486
Validation loss: 1.3864623308181763

Epoch: 6| Step: 7
Training loss: 0.031348660588264465
Validation loss: 1.393088867587428

Epoch: 6| Step: 8
Training loss: 0.09966035932302475
Validation loss: 1.4056431067887174

Epoch: 6| Step: 9
Training loss: 0.05387287586927414
Validation loss: 1.4163304708337272

Epoch: 6| Step: 10
Training loss: 0.06326694786548615
Validation loss: 1.4198012621172014

Epoch: 6| Step: 11
Training loss: 0.06469538807868958
Validation loss: 1.4493042986880067

Epoch: 6| Step: 12
Training loss: 0.10956191271543503
Validation loss: 1.4621814643183062

Epoch: 6| Step: 13
Training loss: 0.09850484877824783
Validation loss: 1.4750635431658836

Epoch: 601| Step: 0
Training loss: 0.07743126153945923
Validation loss: 1.5019765720572522

Epoch: 6| Step: 1
Training loss: 0.1009606346487999
Validation loss: 1.4647569118007537

Epoch: 6| Step: 2
Training loss: 0.0930790975689888
Validation loss: 1.4432354742480862

Epoch: 6| Step: 3
Training loss: 0.04360831156373024
Validation loss: 1.4496107396259104

Epoch: 6| Step: 4
Training loss: 0.0934266746044159
Validation loss: 1.4154364652531122

Epoch: 6| Step: 5
Training loss: 0.08771241456270218
Validation loss: 1.4180904062845374

Epoch: 6| Step: 6
Training loss: 0.08916771411895752
Validation loss: 1.4037230424983527

Epoch: 6| Step: 7
Training loss: 0.06824468076229095
Validation loss: 1.4224119301765197

Epoch: 6| Step: 8
Training loss: 0.03723069280385971
Validation loss: 1.3848926258343521

Epoch: 6| Step: 9
Training loss: 0.10320087522268295
Validation loss: 1.4016142673389886

Epoch: 6| Step: 10
Training loss: 0.032957080751657486
Validation loss: 1.4133928732205463

Epoch: 6| Step: 11
Training loss: 0.05728929862380028
Validation loss: 1.38755468527476

Epoch: 6| Step: 12
Training loss: 0.08544280380010605
Validation loss: 1.3693928487839238

Epoch: 6| Step: 13
Training loss: 0.049537353217601776
Validation loss: 1.3954499947127474

Epoch: 602| Step: 0
Training loss: 0.06550021469593048
Validation loss: 1.380840568132298

Epoch: 6| Step: 1
Training loss: 0.047090668231248856
Validation loss: 1.374950817195318

Epoch: 6| Step: 2
Training loss: 0.09092273563146591
Validation loss: 1.3816897561473231

Epoch: 6| Step: 3
Training loss: 0.061439745128154755
Validation loss: 1.4038592717980827

Epoch: 6| Step: 4
Training loss: 0.09683474898338318
Validation loss: 1.4133959111346994

Epoch: 6| Step: 5
Training loss: 0.07202373445034027
Validation loss: 1.4306408051521546

Epoch: 6| Step: 6
Training loss: 0.11241410672664642
Validation loss: 1.420755458775387

Epoch: 6| Step: 7
Training loss: 0.11587649583816528
Validation loss: 1.4211743454779349

Epoch: 6| Step: 8
Training loss: 0.09349179267883301
Validation loss: 1.4206173676316456

Epoch: 6| Step: 9
Training loss: 0.04646368324756622
Validation loss: 1.40237803997532

Epoch: 6| Step: 10
Training loss: 0.069804348051548
Validation loss: 1.386653329736443

Epoch: 6| Step: 11
Training loss: 0.07936318963766098
Validation loss: 1.368946042753035

Epoch: 6| Step: 12
Training loss: 0.10411541163921356
Validation loss: 1.3603886481254333

Epoch: 6| Step: 13
Training loss: 0.0869683027267456
Validation loss: 1.3720990906479538

Epoch: 603| Step: 0
Training loss: 0.09201198071241379
Validation loss: 1.3590166376483055

Epoch: 6| Step: 1
Training loss: 0.06311172991991043
Validation loss: 1.342524972013248

Epoch: 6| Step: 2
Training loss: 0.051530398428440094
Validation loss: 1.3456346732313915

Epoch: 6| Step: 3
Training loss: 0.06182604283094406
Validation loss: 1.3333700305672103

Epoch: 6| Step: 4
Training loss: 0.07854773104190826
Validation loss: 1.3634026922205442

Epoch: 6| Step: 5
Training loss: 0.09943238645792007
Validation loss: 1.3804572961663688

Epoch: 6| Step: 6
Training loss: 0.07421454042196274
Validation loss: 1.391515854866274

Epoch: 6| Step: 7
Training loss: 0.09796962141990662
Validation loss: 1.4058701005033267

Epoch: 6| Step: 8
Training loss: 0.05351163074374199
Validation loss: 1.4333218554014802

Epoch: 6| Step: 9
Training loss: 0.0729168951511383
Validation loss: 1.4564302480348976

Epoch: 6| Step: 10
Training loss: 0.06532531976699829
Validation loss: 1.4585331896299958

Epoch: 6| Step: 11
Training loss: 0.09555336087942123
Validation loss: 1.4448170610653457

Epoch: 6| Step: 12
Training loss: 0.10090382397174835
Validation loss: 1.4356294408921273

Epoch: 6| Step: 13
Training loss: 0.0533137321472168
Validation loss: 1.4234529054293068

Epoch: 604| Step: 0
Training loss: 0.09798416495323181
Validation loss: 1.386731871994593

Epoch: 6| Step: 1
Training loss: 0.06795798242092133
Validation loss: 1.3734676543102469

Epoch: 6| Step: 2
Training loss: 0.07726703584194183
Validation loss: 1.360690765483405

Epoch: 6| Step: 3
Training loss: 0.1095685288310051
Validation loss: 1.3513613516284573

Epoch: 6| Step: 4
Training loss: 0.1246863454580307
Validation loss: 1.357402696404406

Epoch: 6| Step: 5
Training loss: 0.11767232418060303
Validation loss: 1.3422970348788845

Epoch: 6| Step: 6
Training loss: 0.1023729145526886
Validation loss: 1.378830300864353

Epoch: 6| Step: 7
Training loss: 0.07882704585790634
Validation loss: 1.438331627076672

Epoch: 6| Step: 8
Training loss: 0.06826014816761017
Validation loss: 1.4493818757354573

Epoch: 6| Step: 9
Training loss: 0.09256500005722046
Validation loss: 1.4701610842058737

Epoch: 6| Step: 10
Training loss: 0.16588863730430603
Validation loss: 1.4561175723229685

Epoch: 6| Step: 11
Training loss: 0.06422387808561325
Validation loss: 1.461477784700291

Epoch: 6| Step: 12
Training loss: 0.09834054112434387
Validation loss: 1.4511593439245736

Epoch: 6| Step: 13
Training loss: 0.10259781777858734
Validation loss: 1.4441458826423974

Epoch: 605| Step: 0
Training loss: 0.04041045904159546
Validation loss: 1.4513165630320066

Epoch: 6| Step: 1
Training loss: 0.08302409201860428
Validation loss: 1.4098574948567215

Epoch: 6| Step: 2
Training loss: 0.0742153599858284
Validation loss: 1.4214487921807073

Epoch: 6| Step: 3
Training loss: 0.12018626183271408
Validation loss: 1.4153166118488516

Epoch: 6| Step: 4
Training loss: 0.08432674407958984
Validation loss: 1.429967858458078

Epoch: 6| Step: 5
Training loss: 0.08666764944791794
Validation loss: 1.4288607643496605

Epoch: 6| Step: 6
Training loss: 0.08452300727367401
Validation loss: 1.4321641492587265

Epoch: 6| Step: 7
Training loss: 0.08258232474327087
Validation loss: 1.4471891567271242

Epoch: 6| Step: 8
Training loss: 0.11208093166351318
Validation loss: 1.457973289233382

Epoch: 6| Step: 9
Training loss: 0.07932214438915253
Validation loss: 1.4531610191509288

Epoch: 6| Step: 10
Training loss: 0.1202828511595726
Validation loss: 1.4327037911261282

Epoch: 6| Step: 11
Training loss: 0.09960929304361343
Validation loss: 1.4530645596083773

Epoch: 6| Step: 12
Training loss: 0.08314190059900284
Validation loss: 1.4414339373188634

Epoch: 6| Step: 13
Training loss: 0.09086200594902039
Validation loss: 1.416799203042061

Epoch: 606| Step: 0
Training loss: 0.052764780819416046
Validation loss: 1.4017478701888875

Epoch: 6| Step: 1
Training loss: 0.09133967757225037
Validation loss: 1.4030286112139303

Epoch: 6| Step: 2
Training loss: 0.05270019918680191
Validation loss: 1.4001044265685543

Epoch: 6| Step: 3
Training loss: 0.06112557649612427
Validation loss: 1.3693582678353915

Epoch: 6| Step: 4
Training loss: 0.09376408159732819
Validation loss: 1.4017962358331169

Epoch: 6| Step: 5
Training loss: 0.09019463509321213
Validation loss: 1.4024974889652704

Epoch: 6| Step: 6
Training loss: 0.10440219938755035
Validation loss: 1.4236835805318688

Epoch: 6| Step: 7
Training loss: 0.05761820822954178
Validation loss: 1.4380724936403253

Epoch: 6| Step: 8
Training loss: 0.04867155849933624
Validation loss: 1.416921333600116

Epoch: 6| Step: 9
Training loss: 0.038930777460336685
Validation loss: 1.4210466620742634

Epoch: 6| Step: 10
Training loss: 0.0796213150024414
Validation loss: 1.4082146357464533

Epoch: 6| Step: 11
Training loss: 0.06208021193742752
Validation loss: 1.4380632818386119

Epoch: 6| Step: 12
Training loss: 0.10416233539581299
Validation loss: 1.4121804365547754

Epoch: 6| Step: 13
Training loss: 0.11798533797264099
Validation loss: 1.4104471796302385

Epoch: 607| Step: 0
Training loss: 0.06720384210348129
Validation loss: 1.3866957784980856

Epoch: 6| Step: 1
Training loss: 0.08026834577322006
Validation loss: 1.401756844212932

Epoch: 6| Step: 2
Training loss: 0.0642964318394661
Validation loss: 1.3975962631164058

Epoch: 6| Step: 3
Training loss: 0.16837871074676514
Validation loss: 1.4248697373174852

Epoch: 6| Step: 4
Training loss: 0.0467480830848217
Validation loss: 1.4213386594608266

Epoch: 6| Step: 5
Training loss: 0.024256164208054543
Validation loss: 1.4426424029052898

Epoch: 6| Step: 6
Training loss: 0.07929166406393051
Validation loss: 1.4311639647330008

Epoch: 6| Step: 7
Training loss: 0.053560610860586166
Validation loss: 1.430510651680731

Epoch: 6| Step: 8
Training loss: 0.11326064169406891
Validation loss: 1.441563102506822

Epoch: 6| Step: 9
Training loss: 0.09282035380601883
Validation loss: 1.4325872800683463

Epoch: 6| Step: 10
Training loss: 0.07690741866827011
Validation loss: 1.4257795483835283

Epoch: 6| Step: 11
Training loss: 0.05568081513047218
Validation loss: 1.4051045320367301

Epoch: 6| Step: 12
Training loss: 0.08168470859527588
Validation loss: 1.3795219070167952

Epoch: 6| Step: 13
Training loss: 0.06986908614635468
Validation loss: 1.4111953781497093

Epoch: 608| Step: 0
Training loss: 0.06242739036679268
Validation loss: 1.3837816817786104

Epoch: 6| Step: 1
Training loss: 0.07543083280324936
Validation loss: 1.386424785019249

Epoch: 6| Step: 2
Training loss: 0.09222747385501862
Validation loss: 1.3873408174002042

Epoch: 6| Step: 3
Training loss: 0.08406521379947662
Validation loss: 1.3885887720251595

Epoch: 6| Step: 4
Training loss: 0.09828951954841614
Validation loss: 1.3892102972153695

Epoch: 6| Step: 5
Training loss: 0.07079379260540009
Validation loss: 1.3762236410571682

Epoch: 6| Step: 6
Training loss: 0.09504488110542297
Validation loss: 1.3857367910364622

Epoch: 6| Step: 7
Training loss: 0.09408065676689148
Validation loss: 1.4019365361941758

Epoch: 6| Step: 8
Training loss: 0.10222579538822174
Validation loss: 1.4148452653679797

Epoch: 6| Step: 9
Training loss: 0.0379573255777359
Validation loss: 1.4358722920058875

Epoch: 6| Step: 10
Training loss: 0.12319875508546829
Validation loss: 1.451526125272115

Epoch: 6| Step: 11
Training loss: 0.0974569022655487
Validation loss: 1.452105499082996

Epoch: 6| Step: 12
Training loss: 0.07704369723796844
Validation loss: 1.447221649590359

Epoch: 6| Step: 13
Training loss: 0.11038626730442047
Validation loss: 1.4366535871259627

Epoch: 609| Step: 0
Training loss: 0.04475824907422066
Validation loss: 1.4020860477160382

Epoch: 6| Step: 1
Training loss: 0.08531320095062256
Validation loss: 1.3934578998114473

Epoch: 6| Step: 2
Training loss: 0.07592067867517471
Validation loss: 1.4116687133748045

Epoch: 6| Step: 3
Training loss: 0.10132662951946259
Validation loss: 1.3930347734881985

Epoch: 6| Step: 4
Training loss: 0.03687615320086479
Validation loss: 1.3769598494293869

Epoch: 6| Step: 5
Training loss: 0.06379694491624832
Validation loss: 1.4083979437428136

Epoch: 6| Step: 6
Training loss: 0.05208352953195572
Validation loss: 1.3933849052716327

Epoch: 6| Step: 7
Training loss: 0.08594263345003128
Validation loss: 1.4130814972744192

Epoch: 6| Step: 8
Training loss: 0.06935101747512817
Validation loss: 1.4079953021900629

Epoch: 6| Step: 9
Training loss: 0.041083551943302155
Validation loss: 1.3822341490817327

Epoch: 6| Step: 10
Training loss: 0.09057451784610748
Validation loss: 1.4009594725024315

Epoch: 6| Step: 11
Training loss: 0.06566084921360016
Validation loss: 1.408497586045214

Epoch: 6| Step: 12
Training loss: 0.07601255923509598
Validation loss: 1.3993916780717912

Epoch: 6| Step: 13
Training loss: 0.044874392449855804
Validation loss: 1.428002925329311

Epoch: 610| Step: 0
Training loss: 0.11832650750875473
Validation loss: 1.4095259533133557

Epoch: 6| Step: 1
Training loss: 0.08089324831962585
Validation loss: 1.4103747849823327

Epoch: 6| Step: 2
Training loss: 0.07159364223480225
Validation loss: 1.4190322763176375

Epoch: 6| Step: 3
Training loss: 0.07626450061798096
Validation loss: 1.3896484028908513

Epoch: 6| Step: 4
Training loss: 0.06298918277025223
Validation loss: 1.390461746082511

Epoch: 6| Step: 5
Training loss: 0.09268248826265335
Validation loss: 1.3855512667727727

Epoch: 6| Step: 6
Training loss: 0.06645938754081726
Validation loss: 1.378741636071154

Epoch: 6| Step: 7
Training loss: 0.09642311930656433
Validation loss: 1.39296031062321

Epoch: 6| Step: 8
Training loss: 0.03327775374054909
Validation loss: 1.386772859481073

Epoch: 6| Step: 9
Training loss: 0.06175634264945984
Validation loss: 1.374396804840334

Epoch: 6| Step: 10
Training loss: 0.07531363517045975
Validation loss: 1.3856448845196796

Epoch: 6| Step: 11
Training loss: 0.07727332413196564
Validation loss: 1.4036287005229662

Epoch: 6| Step: 12
Training loss: 0.10748397558927536
Validation loss: 1.4229183966113674

Epoch: 6| Step: 13
Training loss: 0.13349699974060059
Validation loss: 1.415925411767857

Epoch: 611| Step: 0
Training loss: 0.09429557621479034
Validation loss: 1.3890471676344514

Epoch: 6| Step: 1
Training loss: 0.06558704376220703
Validation loss: 1.387502637601668

Epoch: 6| Step: 2
Training loss: 0.04162653535604477
Validation loss: 1.375688220864983

Epoch: 6| Step: 3
Training loss: 0.03482348844408989
Validation loss: 1.3540505164413041

Epoch: 6| Step: 4
Training loss: 0.09057903289794922
Validation loss: 1.378923241169222

Epoch: 6| Step: 5
Training loss: 0.057208359241485596
Validation loss: 1.3732806854350592

Epoch: 6| Step: 6
Training loss: 0.07915264368057251
Validation loss: 1.385856682254422

Epoch: 6| Step: 7
Training loss: 0.09133819490671158
Validation loss: 1.3929094345338884

Epoch: 6| Step: 8
Training loss: 0.06546054035425186
Validation loss: 1.3731609954628894

Epoch: 6| Step: 9
Training loss: 0.0917973667383194
Validation loss: 1.3862977104802285

Epoch: 6| Step: 10
Training loss: 0.07506050169467926
Validation loss: 1.398970107878408

Epoch: 6| Step: 11
Training loss: 0.14745166897773743
Validation loss: 1.3830699343835153

Epoch: 6| Step: 12
Training loss: 0.08522283285856247
Validation loss: 1.4087938416388728

Epoch: 6| Step: 13
Training loss: 0.09189765900373459
Validation loss: 1.388169777008795

Epoch: 612| Step: 0
Training loss: 0.06342318654060364
Validation loss: 1.4260849465606034

Epoch: 6| Step: 1
Training loss: 0.08963029831647873
Validation loss: 1.4170990631144533

Epoch: 6| Step: 2
Training loss: 0.10883887857198715
Validation loss: 1.4099011921113538

Epoch: 6| Step: 3
Training loss: 0.06923561543226242
Validation loss: 1.4120946930300804

Epoch: 6| Step: 4
Training loss: 0.08057469874620438
Validation loss: 1.4284316262891215

Epoch: 6| Step: 5
Training loss: 0.034766778349876404
Validation loss: 1.431720470869413

Epoch: 6| Step: 6
Training loss: 0.09808912128210068
Validation loss: 1.429986088506637

Epoch: 6| Step: 7
Training loss: 0.05787979066371918
Validation loss: 1.4481632465957313

Epoch: 6| Step: 8
Training loss: 0.0844387412071228
Validation loss: 1.418130046577864

Epoch: 6| Step: 9
Training loss: 0.0758613795042038
Validation loss: 1.4287539118079728

Epoch: 6| Step: 10
Training loss: 0.057383179664611816
Validation loss: 1.4447017523550219

Epoch: 6| Step: 11
Training loss: 0.06101347878575325
Validation loss: 1.4288632241628503

Epoch: 6| Step: 12
Training loss: 0.04767009615898132
Validation loss: 1.4048802237356863

Epoch: 6| Step: 13
Training loss: 0.020217524841427803
Validation loss: 1.434469174313289

Epoch: 613| Step: 0
Training loss: 0.08763551712036133
Validation loss: 1.4268179311547229

Epoch: 6| Step: 1
Training loss: 0.033670615404844284
Validation loss: 1.4085190103900047

Epoch: 6| Step: 2
Training loss: 0.049881093204021454
Validation loss: 1.4346198599825624

Epoch: 6| Step: 3
Training loss: 0.061563849449157715
Validation loss: 1.4228056297507337

Epoch: 6| Step: 4
Training loss: 0.06820692121982574
Validation loss: 1.4059520665035452

Epoch: 6| Step: 5
Training loss: 0.1471908837556839
Validation loss: 1.41832733667025

Epoch: 6| Step: 6
Training loss: 0.05942273139953613
Validation loss: 1.3947583968921373

Epoch: 6| Step: 7
Training loss: 0.06009036675095558
Validation loss: 1.3955827964249479

Epoch: 6| Step: 8
Training loss: 0.07656241953372955
Validation loss: 1.3767411978014055

Epoch: 6| Step: 9
Training loss: 0.06195370852947235
Validation loss: 1.4007495000798216

Epoch: 6| Step: 10
Training loss: 0.10136504471302032
Validation loss: 1.4043325660049275

Epoch: 6| Step: 11
Training loss: 0.07425296306610107
Validation loss: 1.4333081412059006

Epoch: 6| Step: 12
Training loss: 0.07638134807348251
Validation loss: 1.427929647507206

Epoch: 6| Step: 13
Training loss: 0.059412259608507156
Validation loss: 1.4308697818427958

Epoch: 614| Step: 0
Training loss: 0.11135128140449524
Validation loss: 1.4270686052178825

Epoch: 6| Step: 1
Training loss: 0.05044737830758095
Validation loss: 1.4027544721480338

Epoch: 6| Step: 2
Training loss: 0.07701355218887329
Validation loss: 1.3691838364447317

Epoch: 6| Step: 3
Training loss: 0.05178338661789894
Validation loss: 1.3623244647056825

Epoch: 6| Step: 4
Training loss: 0.06579078733921051
Validation loss: 1.3596838046145696

Epoch: 6| Step: 5
Training loss: 0.08181247115135193
Validation loss: 1.3192763841280373

Epoch: 6| Step: 6
Training loss: 0.11573725938796997
Validation loss: 1.337190778024735

Epoch: 6| Step: 7
Training loss: 0.08606192469596863
Validation loss: 1.3410550830184773

Epoch: 6| Step: 8
Training loss: 0.1040961742401123
Validation loss: 1.3534608617905648

Epoch: 6| Step: 9
Training loss: 0.10598565638065338
Validation loss: 1.3549538043237501

Epoch: 6| Step: 10
Training loss: 0.11949556320905685
Validation loss: 1.377819889335222

Epoch: 6| Step: 11
Training loss: 0.05143618583679199
Validation loss: 1.3943713467608216

Epoch: 6| Step: 12
Training loss: 0.05572633445262909
Validation loss: 1.4328336843880274

Epoch: 6| Step: 13
Training loss: 0.08103097975254059
Validation loss: 1.4471258014760993

Epoch: 615| Step: 0
Training loss: 0.0751778781414032
Validation loss: 1.443494842898461

Epoch: 6| Step: 1
Training loss: 0.11842551827430725
Validation loss: 1.4436063189660349

Epoch: 6| Step: 2
Training loss: 0.07299796491861343
Validation loss: 1.4452521833040382

Epoch: 6| Step: 3
Training loss: 0.10310938209295273
Validation loss: 1.4334946550348753

Epoch: 6| Step: 4
Training loss: 0.09204470366239548
Validation loss: 1.4176898656352874

Epoch: 6| Step: 5
Training loss: 0.09515819698572159
Validation loss: 1.3655006568278036

Epoch: 6| Step: 6
Training loss: 0.06748518347740173
Validation loss: 1.3796600244378532

Epoch: 6| Step: 7
Training loss: 0.054503001272678375
Validation loss: 1.3277140137969807

Epoch: 6| Step: 8
Training loss: 0.06737019866704941
Validation loss: 1.3182081650662165

Epoch: 6| Step: 9
Training loss: 0.08002565056085587
Validation loss: 1.3260181834620814

Epoch: 6| Step: 10
Training loss: 0.18998751044273376
Validation loss: 1.3392356749503844

Epoch: 6| Step: 11
Training loss: 0.08698627352714539
Validation loss: 1.325836504659345

Epoch: 6| Step: 12
Training loss: 0.11038324236869812
Validation loss: 1.3264412867125643

Epoch: 6| Step: 13
Training loss: 0.05350031703710556
Validation loss: 1.3498075790302728

Epoch: 616| Step: 0
Training loss: 0.06523673981428146
Validation loss: 1.3759227914194907

Epoch: 6| Step: 1
Training loss: 0.07227620482444763
Validation loss: 1.398755681130194

Epoch: 6| Step: 2
Training loss: 0.08377770334482193
Validation loss: 1.4386843635189919

Epoch: 6| Step: 3
Training loss: 0.11273270845413208
Validation loss: 1.4563301417135424

Epoch: 6| Step: 4
Training loss: 0.10175042599439621
Validation loss: 1.4508186194204515

Epoch: 6| Step: 5
Training loss: 0.0853508934378624
Validation loss: 1.4494352988017503

Epoch: 6| Step: 6
Training loss: 0.1030392050743103
Validation loss: 1.4573181380507767

Epoch: 6| Step: 7
Training loss: 0.10840396583080292
Validation loss: 1.425539719161167

Epoch: 6| Step: 8
Training loss: 0.0692124143242836
Validation loss: 1.4186158398146271

Epoch: 6| Step: 9
Training loss: 0.10194779187440872
Validation loss: 1.3975943685859762

Epoch: 6| Step: 10
Training loss: 0.09702953696250916
Validation loss: 1.3998838419555335

Epoch: 6| Step: 11
Training loss: 0.07547999173402786
Validation loss: 1.372494375833901

Epoch: 6| Step: 12
Training loss: 0.05844423174858093
Validation loss: 1.4033531245364939

Epoch: 6| Step: 13
Training loss: 0.11772799491882324
Validation loss: 1.3927412199717697

Epoch: 617| Step: 0
Training loss: 0.07899141311645508
Validation loss: 1.371970921434382

Epoch: 6| Step: 1
Training loss: 0.11698862165212631
Validation loss: 1.3973857856565906

Epoch: 6| Step: 2
Training loss: 0.10282483696937561
Validation loss: 1.39853403516995

Epoch: 6| Step: 3
Training loss: 0.0676959827542305
Validation loss: 1.4087302197692215

Epoch: 6| Step: 4
Training loss: 0.058106765151023865
Validation loss: 1.4588747409082228

Epoch: 6| Step: 5
Training loss: 0.10197184979915619
Validation loss: 1.4604668207066034

Epoch: 6| Step: 6
Training loss: 0.10710951685905457
Validation loss: 1.4749261627915085

Epoch: 6| Step: 7
Training loss: 0.07541483640670776
Validation loss: 1.4913154090604475

Epoch: 6| Step: 8
Training loss: 0.2668747007846832
Validation loss: 1.4920652579235774

Epoch: 6| Step: 9
Training loss: 0.08116178214550018
Validation loss: 1.400952264826785

Epoch: 6| Step: 10
Training loss: 0.09884088486433029
Validation loss: 1.3788265874308925

Epoch: 6| Step: 11
Training loss: 0.09155671298503876
Validation loss: 1.3462523029696556

Epoch: 6| Step: 12
Training loss: 0.13799786567687988
Validation loss: 1.3151235093352616

Epoch: 6| Step: 13
Training loss: 0.2984568476676941
Validation loss: 1.34562845512103

Epoch: 618| Step: 0
Training loss: 0.16838133335113525
Validation loss: 1.3501559598471529

Epoch: 6| Step: 1
Training loss: 0.09286904335021973
Validation loss: 1.3293863599018385

Epoch: 6| Step: 2
Training loss: 0.10855918377637863
Validation loss: 1.3418315751578218

Epoch: 6| Step: 3
Training loss: 0.06912214308977127
Validation loss: 1.3682036092204433

Epoch: 6| Step: 4
Training loss: 0.14559322595596313
Validation loss: 1.4434005598868094

Epoch: 6| Step: 5
Training loss: 0.13293035328388214
Validation loss: 1.5262652263846448

Epoch: 6| Step: 6
Training loss: 0.21809479594230652
Validation loss: 1.5419153257082867

Epoch: 6| Step: 7
Training loss: 0.10329017788171768
Validation loss: 1.490463977218956

Epoch: 6| Step: 8
Training loss: 0.13551205396652222
Validation loss: 1.4397809825917727

Epoch: 6| Step: 9
Training loss: 0.15591897070407867
Validation loss: 1.4302171577689469

Epoch: 6| Step: 10
Training loss: 0.1622522920370102
Validation loss: 1.371040754420783

Epoch: 6| Step: 11
Training loss: 0.11108280718326569
Validation loss: 1.3422839410843388

Epoch: 6| Step: 12
Training loss: 0.2055688500404358
Validation loss: 1.3362774720755957

Epoch: 6| Step: 13
Training loss: 0.1251421570777893
Validation loss: 1.3781247754250803

Epoch: 619| Step: 0
Training loss: 0.2601935863494873
Validation loss: 1.417213596323485

Epoch: 6| Step: 1
Training loss: 0.22935035824775696
Validation loss: 1.4175757342769253

Epoch: 6| Step: 2
Training loss: 0.1468280553817749
Validation loss: 1.4150088346132668

Epoch: 6| Step: 3
Training loss: 0.12918734550476074
Validation loss: 1.4405688367864138

Epoch: 6| Step: 4
Training loss: 0.10247411578893661
Validation loss: 1.4746371071825746

Epoch: 6| Step: 5
Training loss: 0.1527174413204193
Validation loss: 1.5314720952382652

Epoch: 6| Step: 6
Training loss: 0.3176203966140747
Validation loss: 1.5771721960395895

Epoch: 6| Step: 7
Training loss: 0.2724594175815582
Validation loss: 1.599543111298674

Epoch: 6| Step: 8
Training loss: 0.13838651776313782
Validation loss: 1.564248554168209

Epoch: 6| Step: 9
Training loss: 0.1380990892648697
Validation loss: 1.5037105147556593

Epoch: 6| Step: 10
Training loss: 0.1693122237920761
Validation loss: 1.4379245619620047

Epoch: 6| Step: 11
Training loss: 0.12500767409801483
Validation loss: 1.4163565558771933

Epoch: 6| Step: 12
Training loss: 0.18748816847801208
Validation loss: 1.4227430602555633

Epoch: 6| Step: 13
Training loss: 0.14815272390842438
Validation loss: 1.4259905007577711

Epoch: 620| Step: 0
Training loss: 0.14507082104682922
Validation loss: 1.4328653145861883

Epoch: 6| Step: 1
Training loss: 0.11136166751384735
Validation loss: 1.3643612771905878

Epoch: 6| Step: 2
Training loss: 0.13534124195575714
Validation loss: 1.36513554152622

Epoch: 6| Step: 3
Training loss: 0.12452132254838943
Validation loss: 1.3607888516559397

Epoch: 6| Step: 4
Training loss: 0.13944925367832184
Validation loss: 1.3631753062689176

Epoch: 6| Step: 5
Training loss: 0.14972741901874542
Validation loss: 1.3626296289505497

Epoch: 6| Step: 6
Training loss: 0.13447153568267822
Validation loss: 1.3873072824170511

Epoch: 6| Step: 7
Training loss: 0.1801167130470276
Validation loss: 1.39427658050291

Epoch: 6| Step: 8
Training loss: 0.17604127526283264
Validation loss: 1.4049645008579377

Epoch: 6| Step: 9
Training loss: 0.10274532437324524
Validation loss: 1.400243434854733

Epoch: 6| Step: 10
Training loss: 0.06176552176475525
Validation loss: 1.3982456230348157

Epoch: 6| Step: 11
Training loss: 0.07849785685539246
Validation loss: 1.3944047157482435

Epoch: 6| Step: 12
Training loss: 0.11096484214067459
Validation loss: 1.4089858403769873

Epoch: 6| Step: 13
Training loss: 0.10464408993721008
Validation loss: 1.3699795674252253

Epoch: 621| Step: 0
Training loss: 0.07310419529676437
Validation loss: 1.3565493719552153

Epoch: 6| Step: 1
Training loss: 0.0689331516623497
Validation loss: 1.348903025350263

Epoch: 6| Step: 2
Training loss: 0.16036522388458252
Validation loss: 1.3659853140513103

Epoch: 6| Step: 3
Training loss: 0.11200400441884995
Validation loss: 1.3486773660106044

Epoch: 6| Step: 4
Training loss: 0.12488759309053421
Validation loss: 1.3587103069469493

Epoch: 6| Step: 5
Training loss: 0.1405317485332489
Validation loss: 1.3871959268405873

Epoch: 6| Step: 6
Training loss: 0.12031415849924088
Validation loss: 1.4054990763305335

Epoch: 6| Step: 7
Training loss: 0.09690123796463013
Validation loss: 1.3960768984210106

Epoch: 6| Step: 8
Training loss: 0.0803234875202179
Validation loss: 1.4088407703625259

Epoch: 6| Step: 9
Training loss: 0.08084142953157425
Validation loss: 1.3793463681333809

Epoch: 6| Step: 10
Training loss: 0.06788309663534164
Validation loss: 1.4226065656190277

Epoch: 6| Step: 11
Training loss: 0.11850541830062866
Validation loss: 1.4322120989522626

Epoch: 6| Step: 12
Training loss: 0.07985083758831024
Validation loss: 1.4324230295355602

Epoch: 6| Step: 13
Training loss: 0.06908618658781052
Validation loss: 1.4549468422448764

Epoch: 622| Step: 0
Training loss: 0.05652919411659241
Validation loss: 1.4587258549146755

Epoch: 6| Step: 1
Training loss: 0.07164003700017929
Validation loss: 1.4709142113244662

Epoch: 6| Step: 2
Training loss: 0.14087136089801788
Validation loss: 1.4635305084208006

Epoch: 6| Step: 3
Training loss: 0.1418665498495102
Validation loss: 1.4644596333144813

Epoch: 6| Step: 4
Training loss: 0.08114679902791977
Validation loss: 1.43420293126055

Epoch: 6| Step: 5
Training loss: 0.15525701642036438
Validation loss: 1.4321838373778968

Epoch: 6| Step: 6
Training loss: 0.07168366760015488
Validation loss: 1.4115832646687825

Epoch: 6| Step: 7
Training loss: 0.07510679960250854
Validation loss: 1.3747838748398649

Epoch: 6| Step: 8
Training loss: 0.0880761444568634
Validation loss: 1.3724383038859214

Epoch: 6| Step: 9
Training loss: 0.1288330852985382
Validation loss: 1.3500952900096934

Epoch: 6| Step: 10
Training loss: 0.11769208312034607
Validation loss: 1.3695037928960656

Epoch: 6| Step: 11
Training loss: 0.09022398293018341
Validation loss: 1.3566114646132275

Epoch: 6| Step: 12
Training loss: 0.18059426546096802
Validation loss: 1.352613805442728

Epoch: 6| Step: 13
Training loss: 0.06498617678880692
Validation loss: 1.3832563789941932

Epoch: 623| Step: 0
Training loss: 0.10497714579105377
Validation loss: 1.3889327754256546

Epoch: 6| Step: 1
Training loss: 0.10700961947441101
Validation loss: 1.3820701273538734

Epoch: 6| Step: 2
Training loss: 0.038790613412857056
Validation loss: 1.4256990942903744

Epoch: 6| Step: 3
Training loss: 0.12096882611513138
Validation loss: 1.4324917357455018

Epoch: 6| Step: 4
Training loss: 0.06038608029484749
Validation loss: 1.4762256619750813

Epoch: 6| Step: 5
Training loss: 0.13277855515480042
Validation loss: 1.4939698230835698

Epoch: 6| Step: 6
Training loss: 0.05903623253107071
Validation loss: 1.5075858113586262

Epoch: 6| Step: 7
Training loss: 0.09290549159049988
Validation loss: 1.5018913245970202

Epoch: 6| Step: 8
Training loss: 0.128716841340065
Validation loss: 1.486830206327541

Epoch: 6| Step: 9
Training loss: 0.10521762073040009
Validation loss: 1.4776400814774215

Epoch: 6| Step: 10
Training loss: 0.09009173512458801
Validation loss: 1.4506379391557427

Epoch: 6| Step: 11
Training loss: 0.0649159848690033
Validation loss: 1.4227821493661532

Epoch: 6| Step: 12
Training loss: 0.10565903782844543
Validation loss: 1.4212612208499704

Epoch: 6| Step: 13
Training loss: 0.0748768225312233
Validation loss: 1.3688171525155344

Epoch: 624| Step: 0
Training loss: 0.052803728729486465
Validation loss: 1.3594688523200251

Epoch: 6| Step: 1
Training loss: 0.08653867989778519
Validation loss: 1.333042399857634

Epoch: 6| Step: 2
Training loss: 0.03874533995985985
Validation loss: 1.342534666420311

Epoch: 6| Step: 3
Training loss: 0.12102727591991425
Validation loss: 1.3279369800321517

Epoch: 6| Step: 4
Training loss: 0.085851289331913
Validation loss: 1.3400482503316735

Epoch: 6| Step: 5
Training loss: 0.03537121042609215
Validation loss: 1.3074574252610565

Epoch: 6| Step: 6
Training loss: 0.06683777272701263
Validation loss: 1.3085698594329178

Epoch: 6| Step: 7
Training loss: 0.04838479310274124
Validation loss: 1.3300507953090053

Epoch: 6| Step: 8
Training loss: 0.11026114225387573
Validation loss: 1.34402375067434

Epoch: 6| Step: 9
Training loss: 0.07551879435777664
Validation loss: 1.3602010165491412

Epoch: 6| Step: 10
Training loss: 0.09774094820022583
Validation loss: 1.3481678167978923

Epoch: 6| Step: 11
Training loss: 0.0635896623134613
Validation loss: 1.373961329460144

Epoch: 6| Step: 12
Training loss: 0.09380050003528595
Validation loss: 1.3831489419424405

Epoch: 6| Step: 13
Training loss: 0.07463138550519943
Validation loss: 1.3820800909432032

Epoch: 625| Step: 0
Training loss: 0.11389481276273727
Validation loss: 1.4247992564273138

Epoch: 6| Step: 1
Training loss: 0.10052408277988434
Validation loss: 1.4538389123896116

Epoch: 6| Step: 2
Training loss: 0.06859400868415833
Validation loss: 1.4264450316788049

Epoch: 6| Step: 3
Training loss: 0.11338846385478973
Validation loss: 1.4228499961155716

Epoch: 6| Step: 4
Training loss: 0.09976497292518616
Validation loss: 1.4349382333858038

Epoch: 6| Step: 5
Training loss: 0.09863724559545517
Validation loss: 1.4145885526493032

Epoch: 6| Step: 6
Training loss: 0.0731147974729538
Validation loss: 1.4162861403598581

Epoch: 6| Step: 7
Training loss: 0.13583940267562866
Validation loss: 1.4045515175788634

Epoch: 6| Step: 8
Training loss: 0.06296055018901825
Validation loss: 1.432503665647199

Epoch: 6| Step: 9
Training loss: 0.07755228132009506
Validation loss: 1.4065659866538098

Epoch: 6| Step: 10
Training loss: 0.06162107363343239
Validation loss: 1.3938537733529204

Epoch: 6| Step: 11
Training loss: 0.10355755686759949
Validation loss: 1.39384993942835

Epoch: 6| Step: 12
Training loss: 0.06682348251342773
Validation loss: 1.4004929296432003

Epoch: 6| Step: 13
Training loss: 0.07052994519472122
Validation loss: 1.3987783373043101

Epoch: 626| Step: 0
Training loss: 0.08272910118103027
Validation loss: 1.3925919994231193

Epoch: 6| Step: 1
Training loss: 0.08624092489480972
Validation loss: 1.3767470685384606

Epoch: 6| Step: 2
Training loss: 0.09948542714118958
Validation loss: 1.4053520867901463

Epoch: 6| Step: 3
Training loss: 0.0699777603149414
Validation loss: 1.4009524808135083

Epoch: 6| Step: 4
Training loss: 0.067176453769207
Validation loss: 1.3935200732241395

Epoch: 6| Step: 5
Training loss: 0.10572479665279388
Validation loss: 1.3758002929790045

Epoch: 6| Step: 6
Training loss: 0.07144799083471298
Validation loss: 1.3882972514757546

Epoch: 6| Step: 7
Training loss: 0.049312882125377655
Validation loss: 1.373469566786161

Epoch: 6| Step: 8
Training loss: 0.08054128289222717
Validation loss: 1.3696129104142547

Epoch: 6| Step: 9
Training loss: 0.06680276989936829
Validation loss: 1.3692355412308888

Epoch: 6| Step: 10
Training loss: 0.05521557852625847
Validation loss: 1.3617724000766713

Epoch: 6| Step: 11
Training loss: 0.06884036213159561
Validation loss: 1.3701989343089442

Epoch: 6| Step: 12
Training loss: 0.08230546861886978
Validation loss: 1.362603678498217

Epoch: 6| Step: 13
Training loss: 0.05588828772306442
Validation loss: 1.3421625706457323

Epoch: 627| Step: 0
Training loss: 0.07672064006328583
Validation loss: 1.323507652487806

Epoch: 6| Step: 1
Training loss: 0.03324985131621361
Validation loss: 1.3439632397826

Epoch: 6| Step: 2
Training loss: 0.07350926101207733
Validation loss: 1.3608474699399804

Epoch: 6| Step: 3
Training loss: 0.08434171974658966
Validation loss: 1.3504569684305499

Epoch: 6| Step: 4
Training loss: 0.0977368950843811
Validation loss: 1.3470736062654884

Epoch: 6| Step: 5
Training loss: 0.0760105550289154
Validation loss: 1.3444381538898713

Epoch: 6| Step: 6
Training loss: 0.06544133275747299
Validation loss: 1.3407004949867085

Epoch: 6| Step: 7
Training loss: 0.06897810846567154
Validation loss: 1.3413673870025142

Epoch: 6| Step: 8
Training loss: 0.0682314857840538
Validation loss: 1.3239272358596965

Epoch: 6| Step: 9
Training loss: 0.05718182772397995
Validation loss: 1.3566683556443901

Epoch: 6| Step: 10
Training loss: 0.05772954598069191
Validation loss: 1.3435506307950584

Epoch: 6| Step: 11
Training loss: 0.04192642867565155
Validation loss: 1.3527735811407848

Epoch: 6| Step: 12
Training loss: 0.08907235413789749
Validation loss: 1.3490115154174067

Epoch: 6| Step: 13
Training loss: 0.09881149232387543
Validation loss: 1.3642625090896443

Epoch: 628| Step: 0
Training loss: 0.07933628559112549
Validation loss: 1.354676761293924

Epoch: 6| Step: 1
Training loss: 0.09341903030872345
Validation loss: 1.3916316372092052

Epoch: 6| Step: 2
Training loss: 0.049678511917591095
Validation loss: 1.3685544472868725

Epoch: 6| Step: 3
Training loss: 0.04673402011394501
Validation loss: 1.3925840085552585

Epoch: 6| Step: 4
Training loss: 0.07846857607364655
Validation loss: 1.4188920080020864

Epoch: 6| Step: 5
Training loss: 0.07911721616983414
Validation loss: 1.4200287224144064

Epoch: 6| Step: 6
Training loss: 0.05383647233247757
Validation loss: 1.400416306270066

Epoch: 6| Step: 7
Training loss: 0.07724462449550629
Validation loss: 1.4202500620195944

Epoch: 6| Step: 8
Training loss: 0.06349050253629684
Validation loss: 1.4240933323419223

Epoch: 6| Step: 9
Training loss: 0.08660108596086502
Validation loss: 1.4144775200915594

Epoch: 6| Step: 10
Training loss: 0.09295754134654999
Validation loss: 1.414013716482347

Epoch: 6| Step: 11
Training loss: 0.12477584183216095
Validation loss: 1.4314417851868497

Epoch: 6| Step: 12
Training loss: 0.10529984533786774
Validation loss: 1.4094931925496748

Epoch: 6| Step: 13
Training loss: 0.05360521003603935
Validation loss: 1.4013171766393928

Epoch: 629| Step: 0
Training loss: 0.08311410248279572
Validation loss: 1.4001787067741476

Epoch: 6| Step: 1
Training loss: 0.08030220866203308
Validation loss: 1.3870399741716282

Epoch: 6| Step: 2
Training loss: 0.06097067892551422
Validation loss: 1.376506305509998

Epoch: 6| Step: 3
Training loss: 0.06794429570436478
Validation loss: 1.3553289200669976

Epoch: 6| Step: 4
Training loss: 0.11798188090324402
Validation loss: 1.3419591258930903

Epoch: 6| Step: 5
Training loss: 0.10862389951944351
Validation loss: 1.354049769780969

Epoch: 6| Step: 6
Training loss: 0.04510030150413513
Validation loss: 1.3317125176870694

Epoch: 6| Step: 7
Training loss: 0.11862488836050034
Validation loss: 1.3519683179034983

Epoch: 6| Step: 8
Training loss: 0.08790050446987152
Validation loss: 1.35134684014064

Epoch: 6| Step: 9
Training loss: 0.09480904042720795
Validation loss: 1.3411410277889622

Epoch: 6| Step: 10
Training loss: 0.04600490257143974
Validation loss: 1.3571810953078731

Epoch: 6| Step: 11
Training loss: 0.10038865357637405
Validation loss: 1.356343593648685

Epoch: 6| Step: 12
Training loss: 0.06294150650501251
Validation loss: 1.352086793350917

Epoch: 6| Step: 13
Training loss: 0.051700394600629807
Validation loss: 1.3481568341614099

Epoch: 630| Step: 0
Training loss: 0.040015578269958496
Validation loss: 1.363940993944804

Epoch: 6| Step: 1
Training loss: 0.04877104610204697
Validation loss: 1.381682297234894

Epoch: 6| Step: 2
Training loss: 0.08729121834039688
Validation loss: 1.3815077889350154

Epoch: 6| Step: 3
Training loss: 0.05803227424621582
Validation loss: 1.3909813152846469

Epoch: 6| Step: 4
Training loss: 0.0919472724199295
Validation loss: 1.4212455480329451

Epoch: 6| Step: 5
Training loss: 0.08334923535585403
Validation loss: 1.4040536354946833

Epoch: 6| Step: 6
Training loss: 0.06699949502944946
Validation loss: 1.3916937458899714

Epoch: 6| Step: 7
Training loss: 0.0752934068441391
Validation loss: 1.3836353504529564

Epoch: 6| Step: 8
Training loss: 0.0816962942481041
Validation loss: 1.3970784705172303

Epoch: 6| Step: 9
Training loss: 0.06421873718500137
Validation loss: 1.4117902953137633

Epoch: 6| Step: 10
Training loss: 0.10967350006103516
Validation loss: 1.3792832288690793

Epoch: 6| Step: 11
Training loss: 0.0911407396197319
Validation loss: 1.3778935658034457

Epoch: 6| Step: 12
Training loss: 0.09467974305152893
Validation loss: 1.3792050730797552

Epoch: 6| Step: 13
Training loss: 0.0914306789636612
Validation loss: 1.3774707868535032

Epoch: 631| Step: 0
Training loss: 0.07436644285917282
Validation loss: 1.369009433254119

Epoch: 6| Step: 1
Training loss: 0.0602591447532177
Validation loss: 1.378212345543728

Epoch: 6| Step: 2
Training loss: 0.0755322128534317
Validation loss: 1.39125649006136

Epoch: 6| Step: 3
Training loss: 0.12488004565238953
Validation loss: 1.4036282134312454

Epoch: 6| Step: 4
Training loss: 0.07240357995033264
Validation loss: 1.4040366744482389

Epoch: 6| Step: 5
Training loss: 0.1552068293094635
Validation loss: 1.404105887618116

Epoch: 6| Step: 6
Training loss: 0.07668145000934601
Validation loss: 1.374885300154327

Epoch: 6| Step: 7
Training loss: 0.09040343016386032
Validation loss: 1.3739531309373918

Epoch: 6| Step: 8
Training loss: 0.0862547978758812
Validation loss: 1.3597640542573826

Epoch: 6| Step: 9
Training loss: 0.0814128965139389
Validation loss: 1.3535526080798077

Epoch: 6| Step: 10
Training loss: 0.07733280956745148
Validation loss: 1.3635623070501512

Epoch: 6| Step: 11
Training loss: 0.06646279990673065
Validation loss: 1.3580461496947913

Epoch: 6| Step: 12
Training loss: 0.08314254134893417
Validation loss: 1.3570721521172473

Epoch: 6| Step: 13
Training loss: 0.07011881470680237
Validation loss: 1.3467264393324494

Epoch: 632| Step: 0
Training loss: 0.06788547337055206
Validation loss: 1.357331984786577

Epoch: 6| Step: 1
Training loss: 0.0636044442653656
Validation loss: 1.3775494560118644

Epoch: 6| Step: 2
Training loss: 0.09341936558485031
Validation loss: 1.3781089180259294

Epoch: 6| Step: 3
Training loss: 0.09983126074075699
Validation loss: 1.3922947504187142

Epoch: 6| Step: 4
Training loss: 0.055808763951063156
Validation loss: 1.3620601290015764

Epoch: 6| Step: 5
Training loss: 0.09282204508781433
Validation loss: 1.3982101666030062

Epoch: 6| Step: 6
Training loss: 0.07629784941673279
Validation loss: 1.3919656853522024

Epoch: 6| Step: 7
Training loss: 0.05356845259666443
Validation loss: 1.4256752562779251

Epoch: 6| Step: 8
Training loss: 0.0808136910200119
Validation loss: 1.4304139524377801

Epoch: 6| Step: 9
Training loss: 0.11399973928928375
Validation loss: 1.4139598467016732

Epoch: 6| Step: 10
Training loss: 0.06833445280790329
Validation loss: 1.4228269336044148

Epoch: 6| Step: 11
Training loss: 0.06775612384080887
Validation loss: 1.43631616843644

Epoch: 6| Step: 12
Training loss: 0.06779415905475616
Validation loss: 1.4436981062735281

Epoch: 6| Step: 13
Training loss: 0.0833531990647316
Validation loss: 1.4440306155912337

Epoch: 633| Step: 0
Training loss: 0.06433586031198502
Validation loss: 1.438824644652746

Epoch: 6| Step: 1
Training loss: 0.09263715147972107
Validation loss: 1.446063223705497

Epoch: 6| Step: 2
Training loss: 0.0870119035243988
Validation loss: 1.4453813093964771

Epoch: 6| Step: 3
Training loss: 0.11459605395793915
Validation loss: 1.4456136079244717

Epoch: 6| Step: 4
Training loss: 0.07395093888044357
Validation loss: 1.4471009328801145

Epoch: 6| Step: 5
Training loss: 0.05517544597387314
Validation loss: 1.4508742241449253

Epoch: 6| Step: 6
Training loss: 0.05476841703057289
Validation loss: 1.430377819204843

Epoch: 6| Step: 7
Training loss: 0.06979958713054657
Validation loss: 1.4313475367843465

Epoch: 6| Step: 8
Training loss: 0.06822076439857483
Validation loss: 1.4359194463299167

Epoch: 6| Step: 9
Training loss: 0.08898303657770157
Validation loss: 1.4544528004943684

Epoch: 6| Step: 10
Training loss: 0.058405570685863495
Validation loss: 1.4521112762471682

Epoch: 6| Step: 11
Training loss: 0.08777322620153427
Validation loss: 1.4601309094377743

Epoch: 6| Step: 12
Training loss: 0.13164937496185303
Validation loss: 1.4886323995487665

Epoch: 6| Step: 13
Training loss: 0.16716665029525757
Validation loss: 1.5039204807691677

Epoch: 634| Step: 0
Training loss: 0.07293297350406647
Validation loss: 1.488684518362886

Epoch: 6| Step: 1
Training loss: 0.059374138712882996
Validation loss: 1.4776341440857097

Epoch: 6| Step: 2
Training loss: 0.11360698193311691
Validation loss: 1.419024525150176

Epoch: 6| Step: 3
Training loss: 0.05542884021997452
Validation loss: 1.4057341314131213

Epoch: 6| Step: 4
Training loss: 0.08031207323074341
Validation loss: 1.3537744437494585

Epoch: 6| Step: 5
Training loss: 0.15053462982177734
Validation loss: 1.3465083536281381

Epoch: 6| Step: 6
Training loss: 0.05418048053979874
Validation loss: 1.3390255916503169

Epoch: 6| Step: 7
Training loss: 0.09020175039768219
Validation loss: 1.3429029859522337

Epoch: 6| Step: 8
Training loss: 0.09495413303375244
Validation loss: 1.3169372735484954

Epoch: 6| Step: 9
Training loss: 0.11661478877067566
Validation loss: 1.3223910613726544

Epoch: 6| Step: 10
Training loss: 0.08497385680675507
Validation loss: 1.3279696305592854

Epoch: 6| Step: 11
Training loss: 0.07096026837825775
Validation loss: 1.3385404079191145

Epoch: 6| Step: 12
Training loss: 0.07814621180295944
Validation loss: 1.3584287320413897

Epoch: 6| Step: 13
Training loss: 0.06279390305280685
Validation loss: 1.3775625395518478

Epoch: 635| Step: 0
Training loss: 0.056357335299253464
Validation loss: 1.3815092207283102

Epoch: 6| Step: 1
Training loss: 0.05720151215791702
Validation loss: 1.3899211704090078

Epoch: 6| Step: 2
Training loss: 0.06616707146167755
Validation loss: 1.4270501880235569

Epoch: 6| Step: 3
Training loss: 0.07255393266677856
Validation loss: 1.434574173342797

Epoch: 6| Step: 4
Training loss: 0.08210791647434235
Validation loss: 1.461479224825418

Epoch: 6| Step: 5
Training loss: 0.10665971785783768
Validation loss: 1.482996331748142

Epoch: 6| Step: 6
Training loss: 0.1730639487504959
Validation loss: 1.4582820015568887

Epoch: 6| Step: 7
Training loss: 0.07367218285799026
Validation loss: 1.4542710947734054

Epoch: 6| Step: 8
Training loss: 0.0906466394662857
Validation loss: 1.4309830857861427

Epoch: 6| Step: 9
Training loss: 0.11575312912464142
Validation loss: 1.4135583792963335

Epoch: 6| Step: 10
Training loss: 0.06873422861099243
Validation loss: 1.3911735357776764

Epoch: 6| Step: 11
Training loss: 0.06221649795770645
Validation loss: 1.3848756526106147

Epoch: 6| Step: 12
Training loss: 0.1186157688498497
Validation loss: 1.3751921474292714

Epoch: 6| Step: 13
Training loss: 0.0714198499917984
Validation loss: 1.3953657284859688

Epoch: 636| Step: 0
Training loss: 0.08941309154033661
Validation loss: 1.3628402974015923

Epoch: 6| Step: 1
Training loss: 0.0781383290886879
Validation loss: 1.3793547089381883

Epoch: 6| Step: 2
Training loss: 0.06257583200931549
Validation loss: 1.3893079232144099

Epoch: 6| Step: 3
Training loss: 0.06741012632846832
Validation loss: 1.4024900902983963

Epoch: 6| Step: 4
Training loss: 0.10913141071796417
Validation loss: 1.4305340795106785

Epoch: 6| Step: 5
Training loss: 0.08071490377187729
Validation loss: 1.4254048870455833

Epoch: 6| Step: 6
Training loss: 0.04973398149013519
Validation loss: 1.4321656380930254

Epoch: 6| Step: 7
Training loss: 0.06346935033798218
Validation loss: 1.4309016222594886

Epoch: 6| Step: 8
Training loss: 0.07536979764699936
Validation loss: 1.3964595166585778

Epoch: 6| Step: 9
Training loss: 0.05326464772224426
Validation loss: 1.3934845924377441

Epoch: 6| Step: 10
Training loss: 0.07452075928449631
Validation loss: 1.3806396735611783

Epoch: 6| Step: 11
Training loss: 0.05883670225739479
Validation loss: 1.3597824893971926

Epoch: 6| Step: 12
Training loss: 0.06982015818357468
Validation loss: 1.3448843199719664

Epoch: 6| Step: 13
Training loss: 0.04010994732379913
Validation loss: 1.3420890544050483

Epoch: 637| Step: 0
Training loss: 0.04856089875102043
Validation loss: 1.3410271508719331

Epoch: 6| Step: 1
Training loss: 0.12685750424861908
Validation loss: 1.347992350978236

Epoch: 6| Step: 2
Training loss: 0.04486444592475891
Validation loss: 1.3659746960927082

Epoch: 6| Step: 3
Training loss: 0.05438317358493805
Validation loss: 1.3977400461832683

Epoch: 6| Step: 4
Training loss: 0.07162941247224808
Validation loss: 1.3797082612591405

Epoch: 6| Step: 5
Training loss: 0.048355571925640106
Validation loss: 1.4080172277265979

Epoch: 6| Step: 6
Training loss: 0.05063728988170624
Validation loss: 1.4289661466434438

Epoch: 6| Step: 7
Training loss: 0.11133696138858795
Validation loss: 1.4326781765107186

Epoch: 6| Step: 8
Training loss: 0.06511980295181274
Validation loss: 1.3989319057874783

Epoch: 6| Step: 9
Training loss: 0.07891802489757538
Validation loss: 1.420347700836838

Epoch: 6| Step: 10
Training loss: 0.07077670097351074
Validation loss: 1.3928672459817701

Epoch: 6| Step: 11
Training loss: 0.06487319618463516
Validation loss: 1.3850048665077455

Epoch: 6| Step: 12
Training loss: 0.0916055217385292
Validation loss: 1.3825036703899343

Epoch: 6| Step: 13
Training loss: 0.05137701332569122
Validation loss: 1.3631892761876505

Epoch: 638| Step: 0
Training loss: 0.0542202889919281
Validation loss: 1.3870753947124685

Epoch: 6| Step: 1
Training loss: 0.03344177082180977
Validation loss: 1.3899724227125927

Epoch: 6| Step: 2
Training loss: 0.06066226214170456
Validation loss: 1.3615048495672082

Epoch: 6| Step: 3
Training loss: 0.059680499136447906
Validation loss: 1.3944261843158352

Epoch: 6| Step: 4
Training loss: 0.062257811427116394
Validation loss: 1.3857508500417073

Epoch: 6| Step: 5
Training loss: 0.10974230617284775
Validation loss: 1.3799732013415265

Epoch: 6| Step: 6
Training loss: 0.07729330658912659
Validation loss: 1.3802887880673973

Epoch: 6| Step: 7
Training loss: 0.055923208594322205
Validation loss: 1.4157823868977126

Epoch: 6| Step: 8
Training loss: 0.11279325932264328
Validation loss: 1.4070721467336018

Epoch: 6| Step: 9
Training loss: 0.09343923628330231
Validation loss: 1.4117135693950038

Epoch: 6| Step: 10
Training loss: 0.046517618000507355
Validation loss: 1.402705188720457

Epoch: 6| Step: 11
Training loss: 0.07983355224132538
Validation loss: 1.4186635248122677

Epoch: 6| Step: 12
Training loss: 0.061984285712242126
Validation loss: 1.395912822856698

Epoch: 6| Step: 13
Training loss: 0.07708685845136642
Validation loss: 1.4131206927760955

Epoch: 639| Step: 0
Training loss: 0.04870521277189255
Validation loss: 1.4005060965015041

Epoch: 6| Step: 1
Training loss: 0.09360340982675552
Validation loss: 1.3783002905948187

Epoch: 6| Step: 2
Training loss: 0.028833111748099327
Validation loss: 1.3862872149354668

Epoch: 6| Step: 3
Training loss: 0.09756025671958923
Validation loss: 1.3788609209881033

Epoch: 6| Step: 4
Training loss: 0.08023978769779205
Validation loss: 1.3878310938035288

Epoch: 6| Step: 5
Training loss: 0.04052971303462982
Validation loss: 1.368500546742511

Epoch: 6| Step: 6
Training loss: 0.0748840868473053
Validation loss: 1.383972237187047

Epoch: 6| Step: 7
Training loss: 0.049787476658821106
Validation loss: 1.3725098230505501

Epoch: 6| Step: 8
Training loss: 0.07014767080545425
Validation loss: 1.4035604935820385

Epoch: 6| Step: 9
Training loss: 0.06338240951299667
Validation loss: 1.3874116456636818

Epoch: 6| Step: 10
Training loss: 0.07192937284708023
Validation loss: 1.3983351806158661

Epoch: 6| Step: 11
Training loss: 0.07687355577945709
Validation loss: 1.4062048760793542

Epoch: 6| Step: 12
Training loss: 0.10604153573513031
Validation loss: 1.3855949627455844

Epoch: 6| Step: 13
Training loss: 0.05847744643688202
Validation loss: 1.4019914442493069

Epoch: 640| Step: 0
Training loss: 0.052242688834667206
Validation loss: 1.393710337018454

Epoch: 6| Step: 1
Training loss: 0.06955654919147491
Validation loss: 1.415724100605134

Epoch: 6| Step: 2
Training loss: 0.07877811789512634
Validation loss: 1.431040781800465

Epoch: 6| Step: 3
Training loss: 0.05943350866436958
Validation loss: 1.4331803860202912

Epoch: 6| Step: 4
Training loss: 0.09280883520841599
Validation loss: 1.4242890496407785

Epoch: 6| Step: 5
Training loss: 0.06865545362234116
Validation loss: 1.3938898142947946

Epoch: 6| Step: 6
Training loss: 0.07589109987020493
Validation loss: 1.3665536475437943

Epoch: 6| Step: 7
Training loss: 0.04462252929806709
Validation loss: 1.3968004808630994

Epoch: 6| Step: 8
Training loss: 0.061999306082725525
Validation loss: 1.38469131787618

Epoch: 6| Step: 9
Training loss: 0.06092480570077896
Validation loss: 1.389783650316218

Epoch: 6| Step: 10
Training loss: 0.05075833946466446
Validation loss: 1.3821679802351101

Epoch: 6| Step: 11
Training loss: 0.07410447299480438
Validation loss: 1.380174006185224

Epoch: 6| Step: 12
Training loss: 0.08439899235963821
Validation loss: 1.3851520246075046

Epoch: 6| Step: 13
Training loss: 0.09991579502820969
Validation loss: 1.4095997310453845

Epoch: 641| Step: 0
Training loss: 0.10497009754180908
Validation loss: 1.4241418748773553

Epoch: 6| Step: 1
Training loss: 0.09844818711280823
Validation loss: 1.4176662109231437

Epoch: 6| Step: 2
Training loss: 0.0660383403301239
Validation loss: 1.4181630758829014

Epoch: 6| Step: 3
Training loss: 0.07219307124614716
Validation loss: 1.41179447661164

Epoch: 6| Step: 4
Training loss: 0.07503676414489746
Validation loss: 1.4119172685889787

Epoch: 6| Step: 5
Training loss: 0.07614301145076752
Validation loss: 1.4344538411786478

Epoch: 6| Step: 6
Training loss: 0.14584273099899292
Validation loss: 1.4365728055277178

Epoch: 6| Step: 7
Training loss: 0.08316158503293991
Validation loss: 1.4409737125519784

Epoch: 6| Step: 8
Training loss: 0.14784932136535645
Validation loss: 1.3982156181848178

Epoch: 6| Step: 9
Training loss: 0.04343515262007713
Validation loss: 1.3901571343022008

Epoch: 6| Step: 10
Training loss: 0.0678265392780304
Validation loss: 1.3692553722730247

Epoch: 6| Step: 11
Training loss: 0.0698757916688919
Validation loss: 1.3899726713857343

Epoch: 6| Step: 12
Training loss: 0.13886946439743042
Validation loss: 1.3787627547017989

Epoch: 6| Step: 13
Training loss: 0.1797706037759781
Validation loss: 1.3847624640310965

Epoch: 642| Step: 0
Training loss: 0.05175021290779114
Validation loss: 1.3851655311481927

Epoch: 6| Step: 1
Training loss: 0.07350552082061768
Validation loss: 1.3715193938183528

Epoch: 6| Step: 2
Training loss: 0.07877035439014435
Validation loss: 1.4241008809817735

Epoch: 6| Step: 3
Training loss: 0.28500744700431824
Validation loss: 1.4519908665328898

Epoch: 6| Step: 4
Training loss: 0.3116007447242737
Validation loss: 1.4387430247440134

Epoch: 6| Step: 5
Training loss: 0.1964162290096283
Validation loss: 1.4036566172876666

Epoch: 6| Step: 6
Training loss: 0.15572471916675568
Validation loss: 1.4001624673925421

Epoch: 6| Step: 7
Training loss: 0.06470157206058502
Validation loss: 1.3899396427216069

Epoch: 6| Step: 8
Training loss: 0.08734587579965591
Validation loss: 1.387613134999429

Epoch: 6| Step: 9
Training loss: 0.08326135575771332
Validation loss: 1.3955986602332002

Epoch: 6| Step: 10
Training loss: 0.10026954114437103
Validation loss: 1.4057051802194247

Epoch: 6| Step: 11
Training loss: 0.16969284415245056
Validation loss: 1.3948896649063274

Epoch: 6| Step: 12
Training loss: 0.09707705676555634
Validation loss: 1.3978195190429688

Epoch: 6| Step: 13
Training loss: 0.05854286253452301
Validation loss: 1.3885743092465144

Epoch: 643| Step: 0
Training loss: 0.09027475118637085
Validation loss: 1.397725901296062

Epoch: 6| Step: 1
Training loss: 0.04809970781207085
Validation loss: 1.3959409857308993

Epoch: 6| Step: 2
Training loss: 0.06770235300064087
Validation loss: 1.3826988025378155

Epoch: 6| Step: 3
Training loss: 0.061672575771808624
Validation loss: 1.4025842669189617

Epoch: 6| Step: 4
Training loss: 0.09215760976076126
Validation loss: 1.398904896551563

Epoch: 6| Step: 5
Training loss: 0.1223650574684143
Validation loss: 1.4057938591126473

Epoch: 6| Step: 6
Training loss: 0.079423688352108
Validation loss: 1.4023444434647918

Epoch: 6| Step: 7
Training loss: 0.03737102448940277
Validation loss: 1.4074419217724954

Epoch: 6| Step: 8
Training loss: 0.07480371743440628
Validation loss: 1.4164442067505212

Epoch: 6| Step: 9
Training loss: 0.06937384605407715
Validation loss: 1.41197330656872

Epoch: 6| Step: 10
Training loss: 0.09302051365375519
Validation loss: 1.4316861924304758

Epoch: 6| Step: 11
Training loss: 0.09717340767383575
Validation loss: 1.4298787642550725

Epoch: 6| Step: 12
Training loss: 0.12590539455413818
Validation loss: 1.4422216953769806

Epoch: 6| Step: 13
Training loss: 0.10000776499509811
Validation loss: 1.4156967363049906

Epoch: 644| Step: 0
Training loss: 0.08021190017461777
Validation loss: 1.4004684827661003

Epoch: 6| Step: 1
Training loss: 0.09398368746042252
Validation loss: 1.408657072692789

Epoch: 6| Step: 2
Training loss: 0.08215123414993286
Validation loss: 1.3875092588445193

Epoch: 6| Step: 3
Training loss: 0.07077813148498535
Validation loss: 1.3664572661922825

Epoch: 6| Step: 4
Training loss: 0.0875929594039917
Validation loss: 1.3681747862087783

Epoch: 6| Step: 5
Training loss: 0.06406033039093018
Validation loss: 1.3576840816005584

Epoch: 6| Step: 6
Training loss: 0.08530499786138535
Validation loss: 1.3756203260473026

Epoch: 6| Step: 7
Training loss: 0.0669182613492012
Validation loss: 1.364429021714836

Epoch: 6| Step: 8
Training loss: 0.07779766619205475
Validation loss: 1.3585192516285887

Epoch: 6| Step: 9
Training loss: 0.06206737831234932
Validation loss: 1.376249001872155

Epoch: 6| Step: 10
Training loss: 0.07971952110528946
Validation loss: 1.3599293783146849

Epoch: 6| Step: 11
Training loss: 0.04969590902328491
Validation loss: 1.3499052857839933

Epoch: 6| Step: 12
Training loss: 0.12551113963127136
Validation loss: 1.3725667602272444

Epoch: 6| Step: 13
Training loss: 0.08262863010168076
Validation loss: 1.356990643085972

Epoch: 645| Step: 0
Training loss: 0.09224319458007812
Validation loss: 1.3651121252326555

Epoch: 6| Step: 1
Training loss: 0.06038437411189079
Validation loss: 1.350627686387749

Epoch: 6| Step: 2
Training loss: 0.04876335710287094
Validation loss: 1.3679482270312566

Epoch: 6| Step: 3
Training loss: 0.0827290266752243
Validation loss: 1.3850759331898024

Epoch: 6| Step: 4
Training loss: 0.08041461557149887
Validation loss: 1.3863080099064817

Epoch: 6| Step: 5
Training loss: 0.07732083648443222
Validation loss: 1.3881363163712204

Epoch: 6| Step: 6
Training loss: 0.06899089366197586
Validation loss: 1.3736808248745498

Epoch: 6| Step: 7
Training loss: 0.06456863135099411
Validation loss: 1.3752265412320372

Epoch: 6| Step: 8
Training loss: 0.06977155059576035
Validation loss: 1.3740126939230068

Epoch: 6| Step: 9
Training loss: 0.030036527663469315
Validation loss: 1.3802021011229484

Epoch: 6| Step: 10
Training loss: 0.0362403467297554
Validation loss: 1.3843573844561012

Epoch: 6| Step: 11
Training loss: 0.048050276935100555
Validation loss: 1.3996270010548253

Epoch: 6| Step: 12
Training loss: 0.08728760480880737
Validation loss: 1.363752092084577

Epoch: 6| Step: 13
Training loss: 0.036496687680482864
Validation loss: 1.397726825488511

Epoch: 646| Step: 0
Training loss: 0.040556203573942184
Validation loss: 1.3930912287004533

Epoch: 6| Step: 1
Training loss: 0.08813229203224182
Validation loss: 1.3700165896005527

Epoch: 6| Step: 2
Training loss: 0.04204361140727997
Validation loss: 1.3811492855830858

Epoch: 6| Step: 3
Training loss: 0.06130778789520264
Validation loss: 1.3706502734973867

Epoch: 6| Step: 4
Training loss: 0.09494298696517944
Validation loss: 1.3888203405564832

Epoch: 6| Step: 5
Training loss: 0.07181024551391602
Validation loss: 1.4238484559520599

Epoch: 6| Step: 6
Training loss: 0.05564797669649124
Validation loss: 1.3924839272293994

Epoch: 6| Step: 7
Training loss: 0.054420746862888336
Validation loss: 1.3927978995025798

Epoch: 6| Step: 8
Training loss: 0.03492584079504013
Validation loss: 1.3987561169491018

Epoch: 6| Step: 9
Training loss: 0.08519578725099564
Validation loss: 1.4036351185972973

Epoch: 6| Step: 10
Training loss: 0.08626623451709747
Validation loss: 1.3990592687360701

Epoch: 6| Step: 11
Training loss: 0.06584321707487106
Validation loss: 1.3763495683670044

Epoch: 6| Step: 12
Training loss: 0.08408404886722565
Validation loss: 1.3723194829879268

Epoch: 6| Step: 13
Training loss: 0.09894905984401703
Validation loss: 1.3529724305675876

Epoch: 647| Step: 0
Training loss: 0.09208841621875763
Validation loss: 1.3709871051132039

Epoch: 6| Step: 1
Training loss: 0.10521261394023895
Validation loss: 1.3802738510152346

Epoch: 6| Step: 2
Training loss: 0.1470663845539093
Validation loss: 1.3643691309036747

Epoch: 6| Step: 3
Training loss: 0.06849268078804016
Validation loss: 1.3690035048351492

Epoch: 6| Step: 4
Training loss: 0.06199478358030319
Validation loss: 1.3582446869983469

Epoch: 6| Step: 5
Training loss: 0.06752802431583405
Validation loss: 1.3862118887644943

Epoch: 6| Step: 6
Training loss: 0.07775303721427917
Validation loss: 1.4173071627975793

Epoch: 6| Step: 7
Training loss: 0.047521330416202545
Validation loss: 1.4075709081465198

Epoch: 6| Step: 8
Training loss: 0.11910386383533478
Validation loss: 1.4522239123621294

Epoch: 6| Step: 9
Training loss: 0.08189667016267776
Validation loss: 1.465240143960522

Epoch: 6| Step: 10
Training loss: 0.03861154988408089
Validation loss: 1.4398342383805143

Epoch: 6| Step: 11
Training loss: 0.07196666300296783
Validation loss: 1.4611676816017396

Epoch: 6| Step: 12
Training loss: 0.07316690683364868
Validation loss: 1.4603772176209318

Epoch: 6| Step: 13
Training loss: 0.06212352216243744
Validation loss: 1.4533082413417038

Epoch: 648| Step: 0
Training loss: 0.08041476458311081
Validation loss: 1.4408961380681684

Epoch: 6| Step: 1
Training loss: 0.08105272799730301
Validation loss: 1.4492256859297394

Epoch: 6| Step: 2
Training loss: 0.07353454828262329
Validation loss: 1.457279553977392

Epoch: 6| Step: 3
Training loss: 0.078782819211483
Validation loss: 1.4502312175689205

Epoch: 6| Step: 4
Training loss: 0.07816385477781296
Validation loss: 1.4529788929929015

Epoch: 6| Step: 5
Training loss: 0.04066936671733856
Validation loss: 1.4369462722091264

Epoch: 6| Step: 6
Training loss: 0.036057934165000916
Validation loss: 1.4172991603933356

Epoch: 6| Step: 7
Training loss: 0.05538613721728325
Validation loss: 1.4292735386920232

Epoch: 6| Step: 8
Training loss: 0.09183189272880554
Validation loss: 1.4316859668300999

Epoch: 6| Step: 9
Training loss: 0.06438735872507095
Validation loss: 1.408509139091738

Epoch: 6| Step: 10
Training loss: 0.09978578984737396
Validation loss: 1.4078676021227272

Epoch: 6| Step: 11
Training loss: 0.10781484097242355
Validation loss: 1.3953570127487183

Epoch: 6| Step: 12
Training loss: 0.09227461367845535
Validation loss: 1.403012792269389

Epoch: 6| Step: 13
Training loss: 0.13069632649421692
Validation loss: 1.4164090156555176

Epoch: 649| Step: 0
Training loss: 0.06737568974494934
Validation loss: 1.420514166355133

Epoch: 6| Step: 1
Training loss: 0.054223425686359406
Validation loss: 1.4055606504922271

Epoch: 6| Step: 2
Training loss: 0.084329754114151
Validation loss: 1.41197088585105

Epoch: 6| Step: 3
Training loss: 0.0644729733467102
Validation loss: 1.3929401469487015

Epoch: 6| Step: 4
Training loss: 0.051209691911935806
Validation loss: 1.3990470978521532

Epoch: 6| Step: 5
Training loss: 0.11931432783603668
Validation loss: 1.3630134726083407

Epoch: 6| Step: 6
Training loss: 0.07963535189628601
Validation loss: 1.3847839832305908

Epoch: 6| Step: 7
Training loss: 0.1063852608203888
Validation loss: 1.400922034376411

Epoch: 6| Step: 8
Training loss: 0.04653472453355789
Validation loss: 1.3920184899401922

Epoch: 6| Step: 9
Training loss: 0.05786251649260521
Validation loss: 1.3923001097094627

Epoch: 6| Step: 10
Training loss: 0.05730950087308884
Validation loss: 1.378000308108586

Epoch: 6| Step: 11
Training loss: 0.06437313556671143
Validation loss: 1.3763378986748316

Epoch: 6| Step: 12
Training loss: 0.08782777190208435
Validation loss: 1.3524344710893528

Epoch: 6| Step: 13
Training loss: 0.05952870845794678
Validation loss: 1.3739747821643788

Epoch: 650| Step: 0
Training loss: 0.07219703495502472
Validation loss: 1.386440416818024

Epoch: 6| Step: 1
Training loss: 0.0344725176692009
Validation loss: 1.372000801947809

Epoch: 6| Step: 2
Training loss: 0.07688628137111664
Validation loss: 1.3733072793611916

Epoch: 6| Step: 3
Training loss: 0.0426083579659462
Validation loss: 1.3867434526002536

Epoch: 6| Step: 4
Training loss: 0.10054287314414978
Validation loss: 1.3949392245661827

Epoch: 6| Step: 5
Training loss: 0.07765631377696991
Validation loss: 1.389706511651316

Epoch: 6| Step: 6
Training loss: 0.12232686579227448
Validation loss: 1.3857244265976774

Epoch: 6| Step: 7
Training loss: 0.05909864977002144
Validation loss: 1.3808856061709824

Epoch: 6| Step: 8
Training loss: 0.08468252420425415
Validation loss: 1.3898752363779212

Epoch: 6| Step: 9
Training loss: 0.09803536534309387
Validation loss: 1.4148544752469627

Epoch: 6| Step: 10
Training loss: 0.04947250708937645
Validation loss: 1.4274151735408331

Epoch: 6| Step: 11
Training loss: 0.06866282224655151
Validation loss: 1.4240661654421078

Epoch: 6| Step: 12
Training loss: 0.10782694071531296
Validation loss: 1.427510033371628

Epoch: 6| Step: 13
Training loss: 0.05941620096564293
Validation loss: 1.425958812877696

Epoch: 651| Step: 0
Training loss: 0.04537099599838257
Validation loss: 1.4350515373291508

Epoch: 6| Step: 1
Training loss: 0.049013152718544006
Validation loss: 1.412865408005253

Epoch: 6| Step: 2
Training loss: 0.06765002012252808
Validation loss: 1.4183045997414538

Epoch: 6| Step: 3
Training loss: 0.10671433806419373
Validation loss: 1.4124853931447512

Epoch: 6| Step: 4
Training loss: 0.07741007208824158
Validation loss: 1.38426637136808

Epoch: 6| Step: 5
Training loss: 0.09885555505752563
Validation loss: 1.3922885515356576

Epoch: 6| Step: 6
Training loss: 0.03841673210263252
Validation loss: 1.3895214001337688

Epoch: 6| Step: 7
Training loss: 0.055466428399086
Validation loss: 1.3908879321108583

Epoch: 6| Step: 8
Training loss: 0.07660209387540817
Validation loss: 1.3955035709565686

Epoch: 6| Step: 9
Training loss: 0.07430307567119598
Validation loss: 1.3900911756741103

Epoch: 6| Step: 10
Training loss: 0.0513397678732872
Validation loss: 1.421142114106045

Epoch: 6| Step: 11
Training loss: 0.04063470661640167
Validation loss: 1.421976085632078

Epoch: 6| Step: 12
Training loss: 0.06159331649541855
Validation loss: 1.4107324384873914

Epoch: 6| Step: 13
Training loss: 0.07349035888910294
Validation loss: 1.4322428793035529

Epoch: 652| Step: 0
Training loss: 0.044637203216552734
Validation loss: 1.428949225333429

Epoch: 6| Step: 1
Training loss: 0.07008607685565948
Validation loss: 1.4074207364871938

Epoch: 6| Step: 2
Training loss: 0.08543603122234344
Validation loss: 1.405405685465823

Epoch: 6| Step: 3
Training loss: 0.06430555880069733
Validation loss: 1.4177852074305217

Epoch: 6| Step: 4
Training loss: 0.08456501364707947
Validation loss: 1.3867030733375139

Epoch: 6| Step: 5
Training loss: 0.0506695881485939
Validation loss: 1.4057054173561834

Epoch: 6| Step: 6
Training loss: 0.07799986004829407
Validation loss: 1.4198945414635442

Epoch: 6| Step: 7
Training loss: 0.04983745887875557
Validation loss: 1.4292443362615441

Epoch: 6| Step: 8
Training loss: 0.05164685472846031
Validation loss: 1.4586726042532152

Epoch: 6| Step: 9
Training loss: 0.04492630809545517
Validation loss: 1.4341833309460712

Epoch: 6| Step: 10
Training loss: 0.11266671866178513
Validation loss: 1.4295749036214684

Epoch: 6| Step: 11
Training loss: 0.08325216174125671
Validation loss: 1.4223865719251736

Epoch: 6| Step: 12
Training loss: 0.05981253460049629
Validation loss: 1.4166803090803084

Epoch: 6| Step: 13
Training loss: 0.06810151040554047
Validation loss: 1.395079997278029

Epoch: 653| Step: 0
Training loss: 0.04246305301785469
Validation loss: 1.410966827023414

Epoch: 6| Step: 1
Training loss: 0.0776805728673935
Validation loss: 1.3887805502901795

Epoch: 6| Step: 2
Training loss: 0.07926033437252045
Validation loss: 1.3815715530867219

Epoch: 6| Step: 3
Training loss: 0.04913591220974922
Validation loss: 1.3749355795562908

Epoch: 6| Step: 4
Training loss: 0.06326515227556229
Validation loss: 1.3700259449661418

Epoch: 6| Step: 5
Training loss: 0.06111866980791092
Validation loss: 1.3655480671954412

Epoch: 6| Step: 6
Training loss: 0.11863060295581818
Validation loss: 1.3792878081721645

Epoch: 6| Step: 7
Training loss: 0.09984377771615982
Validation loss: 1.3600089203926824

Epoch: 6| Step: 8
Training loss: 0.05568741261959076
Validation loss: 1.3719572879934823

Epoch: 6| Step: 9
Training loss: 0.038576483726501465
Validation loss: 1.4057071503772531

Epoch: 6| Step: 10
Training loss: 0.05955005809664726
Validation loss: 1.3753294624308103

Epoch: 6| Step: 11
Training loss: 0.0909905806183815
Validation loss: 1.4031587300762054

Epoch: 6| Step: 12
Training loss: 0.049611400812864304
Validation loss: 1.3991993499058548

Epoch: 6| Step: 13
Training loss: 0.06737308949232101
Validation loss: 1.4264920398753176

Epoch: 654| Step: 0
Training loss: 0.0548587292432785
Validation loss: 1.4187156077354186

Epoch: 6| Step: 1
Training loss: 0.0652952641248703
Validation loss: 1.4187457138492214

Epoch: 6| Step: 2
Training loss: 0.0705622062087059
Validation loss: 1.4331903137186521

Epoch: 6| Step: 3
Training loss: 0.05904385447502136
Validation loss: 1.4514128303015104

Epoch: 6| Step: 4
Training loss: 0.10828368365764618
Validation loss: 1.4643333240221905

Epoch: 6| Step: 5
Training loss: 0.084217369556427
Validation loss: 1.4204760033597228

Epoch: 6| Step: 6
Training loss: 0.06071805581450462
Validation loss: 1.4344577802124845

Epoch: 6| Step: 7
Training loss: 0.11933613568544388
Validation loss: 1.4324619987959504

Epoch: 6| Step: 8
Training loss: 0.06531272083520889
Validation loss: 1.4069294897458886

Epoch: 6| Step: 9
Training loss: 0.05117525905370712
Validation loss: 1.4208261953887118

Epoch: 6| Step: 10
Training loss: 0.06817035377025604
Validation loss: 1.40620788451164

Epoch: 6| Step: 11
Training loss: 0.06306322664022446
Validation loss: 1.4083620925103464

Epoch: 6| Step: 12
Training loss: 0.04978287220001221
Validation loss: 1.4269131082360462

Epoch: 6| Step: 13
Training loss: 0.03756360337138176
Validation loss: 1.414636932393556

Epoch: 655| Step: 0
Training loss: 0.10099872201681137
Validation loss: 1.412120681937023

Epoch: 6| Step: 1
Training loss: 0.07165814936161041
Validation loss: 1.399227903735253

Epoch: 6| Step: 2
Training loss: 0.04706713184714317
Validation loss: 1.3884590620635657

Epoch: 6| Step: 3
Training loss: 0.0467073917388916
Validation loss: 1.4055560993891891

Epoch: 6| Step: 4
Training loss: 0.058228857815265656
Validation loss: 1.390301202574084

Epoch: 6| Step: 5
Training loss: 0.054220981895923615
Validation loss: 1.377419908841451

Epoch: 6| Step: 6
Training loss: 0.07239697873592377
Validation loss: 1.3701755423699655

Epoch: 6| Step: 7
Training loss: 0.07282198965549469
Validation loss: 1.3922991791079122

Epoch: 6| Step: 8
Training loss: 0.04275398701429367
Validation loss: 1.405941415858525

Epoch: 6| Step: 9
Training loss: 0.06151418387889862
Validation loss: 1.3962011234734648

Epoch: 6| Step: 10
Training loss: 0.10044312477111816
Validation loss: 1.4055957845462266

Epoch: 6| Step: 11
Training loss: 0.05111946910619736
Validation loss: 1.402375881389905

Epoch: 6| Step: 12
Training loss: 0.04928605258464813
Validation loss: 1.3992249940031318

Epoch: 6| Step: 13
Training loss: 0.09744559228420258
Validation loss: 1.4130485468013312

Epoch: 656| Step: 0
Training loss: 0.04794669151306152
Validation loss: 1.3859211116708734

Epoch: 6| Step: 1
Training loss: 0.06821894645690918
Validation loss: 1.40674167038292

Epoch: 6| Step: 2
Training loss: 0.07026182115077972
Validation loss: 1.411173742304566

Epoch: 6| Step: 3
Training loss: 0.06688480824232101
Validation loss: 1.4253729261377805

Epoch: 6| Step: 4
Training loss: 0.057075854390859604
Validation loss: 1.4137874034143263

Epoch: 6| Step: 5
Training loss: 0.09434831887483597
Validation loss: 1.4339018855043637

Epoch: 6| Step: 6
Training loss: 0.05311589688062668
Validation loss: 1.409998046454563

Epoch: 6| Step: 7
Training loss: 0.05430593341588974
Validation loss: 1.4264758594574467

Epoch: 6| Step: 8
Training loss: 0.07617640495300293
Validation loss: 1.4092442527894051

Epoch: 6| Step: 9
Training loss: 0.043756794184446335
Validation loss: 1.3866196434984925

Epoch: 6| Step: 10
Training loss: 0.041213639080524445
Validation loss: 1.3825780255820161

Epoch: 6| Step: 11
Training loss: 0.07715438306331635
Validation loss: 1.3929455280303955

Epoch: 6| Step: 12
Training loss: 0.06686948984861374
Validation loss: 1.3856408314038349

Epoch: 6| Step: 13
Training loss: 0.04601550102233887
Validation loss: 1.376396300972149

Epoch: 657| Step: 0
Training loss: 0.06539925932884216
Validation loss: 1.3721649383985868

Epoch: 6| Step: 1
Training loss: 0.05720680207014084
Validation loss: 1.3874081373214722

Epoch: 6| Step: 2
Training loss: 0.07884250581264496
Validation loss: 1.3591701112767702

Epoch: 6| Step: 3
Training loss: 0.053703393787145615
Validation loss: 1.3803086896096506

Epoch: 6| Step: 4
Training loss: 0.06414354592561722
Validation loss: 1.4050950363118162

Epoch: 6| Step: 5
Training loss: 0.036217477172613144
Validation loss: 1.4128331292060115

Epoch: 6| Step: 6
Training loss: 0.06598865985870361
Validation loss: 1.4378479437161518

Epoch: 6| Step: 7
Training loss: 0.046949900686740875
Validation loss: 1.4137913700072997

Epoch: 6| Step: 8
Training loss: 0.055367693305015564
Validation loss: 1.4130834866595525

Epoch: 6| Step: 9
Training loss: 0.07818961143493652
Validation loss: 1.4577605185970184

Epoch: 6| Step: 10
Training loss: 0.05286722630262375
Validation loss: 1.4512954655513968

Epoch: 6| Step: 11
Training loss: 0.08044712990522385
Validation loss: 1.4473590363738358

Epoch: 6| Step: 12
Training loss: 0.08182072639465332
Validation loss: 1.4412378226557085

Epoch: 6| Step: 13
Training loss: 0.06267055869102478
Validation loss: 1.4319902209825413

Epoch: 658| Step: 0
Training loss: 0.0881144106388092
Validation loss: 1.4229587265240249

Epoch: 6| Step: 1
Training loss: 0.021750109270215034
Validation loss: 1.4032352355218702

Epoch: 6| Step: 2
Training loss: 0.03877836465835571
Validation loss: 1.4159847241576

Epoch: 6| Step: 3
Training loss: 0.04059409350156784
Validation loss: 1.3886843009661602

Epoch: 6| Step: 4
Training loss: 0.13197405636310577
Validation loss: 1.3785719999703028

Epoch: 6| Step: 5
Training loss: 0.06539035588502884
Validation loss: 1.3726799206067157

Epoch: 6| Step: 6
Training loss: 0.062191203236579895
Validation loss: 1.3678035056719215

Epoch: 6| Step: 7
Training loss: 0.07621161639690399
Validation loss: 1.3750788921950965

Epoch: 6| Step: 8
Training loss: 0.045184098184108734
Validation loss: 1.3934833747084423

Epoch: 6| Step: 9
Training loss: 0.04820285737514496
Validation loss: 1.3949339940983763

Epoch: 6| Step: 10
Training loss: 0.08031359314918518
Validation loss: 1.3817468266333304

Epoch: 6| Step: 11
Training loss: 0.08258563280105591
Validation loss: 1.4054502184673021

Epoch: 6| Step: 12
Training loss: 0.06736946851015091
Validation loss: 1.387936717720442

Epoch: 6| Step: 13
Training loss: 0.04130728915333748
Validation loss: 1.4093709722641976

Epoch: 659| Step: 0
Training loss: 0.0677652657032013
Validation loss: 1.4153080524936799

Epoch: 6| Step: 1
Training loss: 0.06681056320667267
Validation loss: 1.4140449403434672

Epoch: 6| Step: 2
Training loss: 0.041339460760354996
Validation loss: 1.417595301904986

Epoch: 6| Step: 3
Training loss: 0.048233624547719955
Validation loss: 1.4033216994295838

Epoch: 6| Step: 4
Training loss: 0.031152354553341866
Validation loss: 1.4152383060865505

Epoch: 6| Step: 5
Training loss: 0.03943759202957153
Validation loss: 1.404497964407808

Epoch: 6| Step: 6
Training loss: 0.06970644742250443
Validation loss: 1.4134646154219104

Epoch: 6| Step: 7
Training loss: 0.08195946365594864
Validation loss: 1.3924042563284598

Epoch: 6| Step: 8
Training loss: 0.07851327955722809
Validation loss: 1.4093061057470178

Epoch: 6| Step: 9
Training loss: 0.11129072308540344
Validation loss: 1.4140641971301007

Epoch: 6| Step: 10
Training loss: 0.05970392003655434
Validation loss: 1.4001427683778989

Epoch: 6| Step: 11
Training loss: 0.04323125630617142
Validation loss: 1.3890295515778244

Epoch: 6| Step: 12
Training loss: 0.06464482098817825
Validation loss: 1.4031069509444698

Epoch: 6| Step: 13
Training loss: 0.09738308936357498
Validation loss: 1.3727456549162507

Epoch: 660| Step: 0
Training loss: 0.07538564503192902
Validation loss: 1.4087386720923967

Epoch: 6| Step: 1
Training loss: 0.07002216577529907
Validation loss: 1.4093936220292123

Epoch: 6| Step: 2
Training loss: 0.06385840475559235
Validation loss: 1.4169026549144457

Epoch: 6| Step: 3
Training loss: 0.06593172252178192
Validation loss: 1.4283816916968233

Epoch: 6| Step: 4
Training loss: 0.061589524149894714
Validation loss: 1.3887823333022415

Epoch: 6| Step: 5
Training loss: 0.0844944640994072
Validation loss: 1.4193639511703162

Epoch: 6| Step: 6
Training loss: 0.07350653409957886
Validation loss: 1.3935956724228398

Epoch: 6| Step: 7
Training loss: 0.060024991631507874
Validation loss: 1.3895951342839066

Epoch: 6| Step: 8
Training loss: 0.04217001050710678
Validation loss: 1.365150797751642

Epoch: 6| Step: 9
Training loss: 0.061475008726119995
Validation loss: 1.3545009666873562

Epoch: 6| Step: 10
Training loss: 0.05277874693274498
Validation loss: 1.3863482334280526

Epoch: 6| Step: 11
Training loss: 0.037808291614055634
Validation loss: 1.3805582266981884

Epoch: 6| Step: 12
Training loss: 0.10249456763267517
Validation loss: 1.3972799560075164

Epoch: 6| Step: 13
Training loss: 0.061806872487068176
Validation loss: 1.3740541012056413

Epoch: 661| Step: 0
Training loss: 0.07751074433326721
Validation loss: 1.3728219937252741

Epoch: 6| Step: 1
Training loss: 0.04210921376943588
Validation loss: 1.3857743150444441

Epoch: 6| Step: 2
Training loss: 0.03855278715491295
Validation loss: 1.3873101870218914

Epoch: 6| Step: 3
Training loss: 0.05993989109992981
Validation loss: 1.4078169433019494

Epoch: 6| Step: 4
Training loss: 0.06140570342540741
Validation loss: 1.4067807729526232

Epoch: 6| Step: 5
Training loss: 0.06792895495891571
Validation loss: 1.4045807892276394

Epoch: 6| Step: 6
Training loss: 0.05813545361161232
Validation loss: 1.4023991771923598

Epoch: 6| Step: 7
Training loss: 0.03431054949760437
Validation loss: 1.411636112838663

Epoch: 6| Step: 8
Training loss: 0.09693267196416855
Validation loss: 1.4028608798980713

Epoch: 6| Step: 9
Training loss: 0.06541021168231964
Validation loss: 1.402888899208397

Epoch: 6| Step: 10
Training loss: 0.09939602017402649
Validation loss: 1.3970055246865878

Epoch: 6| Step: 11
Training loss: 0.06245560199022293
Validation loss: 1.3917869983180877

Epoch: 6| Step: 12
Training loss: 0.06879280507564545
Validation loss: 1.3800450832613054

Epoch: 6| Step: 13
Training loss: 0.08915761113166809
Validation loss: 1.3848939916139007

Epoch: 662| Step: 0
Training loss: 0.032590948045253754
Validation loss: 1.4059255020592802

Epoch: 6| Step: 1
Training loss: 0.0475173257291317
Validation loss: 1.3948121743817483

Epoch: 6| Step: 2
Training loss: 0.046285733580589294
Validation loss: 1.3985334968054166

Epoch: 6| Step: 3
Training loss: 0.0664399117231369
Validation loss: 1.4229540119888962

Epoch: 6| Step: 4
Training loss: 0.0588773712515831
Validation loss: 1.4304982385327738

Epoch: 6| Step: 5
Training loss: 0.08235855400562286
Validation loss: 1.4148396240767611

Epoch: 6| Step: 6
Training loss: 0.11263041198253632
Validation loss: 1.411045011653695

Epoch: 6| Step: 7
Training loss: 0.09314130246639252
Validation loss: 1.4183943451091807

Epoch: 6| Step: 8
Training loss: 0.025901637971401215
Validation loss: 1.3990277039107455

Epoch: 6| Step: 9
Training loss: 0.08413868397474289
Validation loss: 1.3758496494703396

Epoch: 6| Step: 10
Training loss: 0.048844318836927414
Validation loss: 1.3855891099540136

Epoch: 6| Step: 11
Training loss: 0.061155155301094055
Validation loss: 1.4027531544367473

Epoch: 6| Step: 12
Training loss: 0.06841134279966354
Validation loss: 1.406597811688659

Epoch: 6| Step: 13
Training loss: 0.052912261337041855
Validation loss: 1.4070750974839734

Epoch: 663| Step: 0
Training loss: 0.06052987277507782
Validation loss: 1.3888915495205951

Epoch: 6| Step: 1
Training loss: 0.048801030963659286
Validation loss: 1.4189389905621927

Epoch: 6| Step: 2
Training loss: 0.1377817988395691
Validation loss: 1.3945016752007187

Epoch: 6| Step: 3
Training loss: 0.09122616052627563
Validation loss: 1.381118300140545

Epoch: 6| Step: 4
Training loss: 0.06311734020709991
Validation loss: 1.401696724276389

Epoch: 6| Step: 5
Training loss: 0.05269404500722885
Validation loss: 1.3940309824482087

Epoch: 6| Step: 6
Training loss: 0.10487858951091766
Validation loss: 1.397781930943971

Epoch: 6| Step: 7
Training loss: 0.03737039119005203
Validation loss: 1.381985874586208

Epoch: 6| Step: 8
Training loss: 0.04574555158615112
Validation loss: 1.383848613308322

Epoch: 6| Step: 9
Training loss: 0.09776601195335388
Validation loss: 1.4027195348534534

Epoch: 6| Step: 10
Training loss: 0.09065945446491241
Validation loss: 1.3855214708594865

Epoch: 6| Step: 11
Training loss: 0.06580018997192383
Validation loss: 1.3938066933744697

Epoch: 6| Step: 12
Training loss: 0.0763973593711853
Validation loss: 1.4089694670451585

Epoch: 6| Step: 13
Training loss: 0.08487299084663391
Validation loss: 1.407533509756929

Epoch: 664| Step: 0
Training loss: 0.052398234605789185
Validation loss: 1.411052127038279

Epoch: 6| Step: 1
Training loss: 0.0653165727853775
Validation loss: 1.4115068643323836

Epoch: 6| Step: 2
Training loss: 0.05677963048219681
Validation loss: 1.4258153784659602

Epoch: 6| Step: 3
Training loss: 0.05931229889392853
Validation loss: 1.404347667130091

Epoch: 6| Step: 4
Training loss: 0.04242298752069473
Validation loss: 1.4018865054653538

Epoch: 6| Step: 5
Training loss: 0.07798487693071365
Validation loss: 1.4124773151131087

Epoch: 6| Step: 6
Training loss: 0.04889817535877228
Validation loss: 1.4260432079274168

Epoch: 6| Step: 7
Training loss: 0.0457904152572155
Validation loss: 1.3929650860448037

Epoch: 6| Step: 8
Training loss: 0.041048720479011536
Validation loss: 1.4089930595890168

Epoch: 6| Step: 9
Training loss: 0.09444620460271835
Validation loss: 1.381940363555826

Epoch: 6| Step: 10
Training loss: 0.048599645495414734
Validation loss: 1.3928287311266827

Epoch: 6| Step: 11
Training loss: 0.05541987717151642
Validation loss: 1.3823106199182489

Epoch: 6| Step: 12
Training loss: 0.061899177730083466
Validation loss: 1.3946613778350174

Epoch: 6| Step: 13
Training loss: 0.08504791557788849
Validation loss: 1.430417594089303

Epoch: 665| Step: 0
Training loss: 0.0709565207362175
Validation loss: 1.4504872022136566

Epoch: 6| Step: 1
Training loss: 0.0927014872431755
Validation loss: 1.442263077664119

Epoch: 6| Step: 2
Training loss: 0.061176598072052
Validation loss: 1.4393511728573871

Epoch: 6| Step: 3
Training loss: 0.11954930424690247
Validation loss: 1.4476510491422427

Epoch: 6| Step: 4
Training loss: 0.04663816839456558
Validation loss: 1.4168209798874394

Epoch: 6| Step: 5
Training loss: 0.04631778225302696
Validation loss: 1.4053800644413117

Epoch: 6| Step: 6
Training loss: 0.06565774977207184
Validation loss: 1.4024495719581522

Epoch: 6| Step: 7
Training loss: 0.04092894122004509
Validation loss: 1.390284231913987

Epoch: 6| Step: 8
Training loss: 0.05343012139201164
Validation loss: 1.3968559183100218

Epoch: 6| Step: 9
Training loss: 0.03384815901517868
Validation loss: 1.3753701153621878

Epoch: 6| Step: 10
Training loss: 0.07982868701219559
Validation loss: 1.35656270288652

Epoch: 6| Step: 11
Training loss: 0.07462630420923233
Validation loss: 1.3585647703498922

Epoch: 6| Step: 12
Training loss: 0.06871625781059265
Validation loss: 1.3542348530984694

Epoch: 6| Step: 13
Training loss: 0.11118033528327942
Validation loss: 1.3323898828157814

Epoch: 666| Step: 0
Training loss: 0.03323057293891907
Validation loss: 1.3654024113890946

Epoch: 6| Step: 1
Training loss: 0.04156165570020676
Validation loss: 1.3649358031570271

Epoch: 6| Step: 2
Training loss: 0.05860670655965805
Validation loss: 1.377424217039539

Epoch: 6| Step: 3
Training loss: 0.09935183823108673
Validation loss: 1.385558735298854

Epoch: 6| Step: 4
Training loss: 0.07296028733253479
Validation loss: 1.3531302611033122

Epoch: 6| Step: 5
Training loss: 0.09703340381383896
Validation loss: 1.3765270107535905

Epoch: 6| Step: 6
Training loss: 0.07014422118663788
Validation loss: 1.3817052815550117

Epoch: 6| Step: 7
Training loss: 0.05591052025556564
Validation loss: 1.387215760446364

Epoch: 6| Step: 8
Training loss: 0.08122242987155914
Validation loss: 1.4086617577460505

Epoch: 6| Step: 9
Training loss: 0.09109975397586823
Validation loss: 1.4260290066401164

Epoch: 6| Step: 10
Training loss: 0.05819166824221611
Validation loss: 1.4273191113625803

Epoch: 6| Step: 11
Training loss: 0.07348697632551193
Validation loss: 1.427793341298257

Epoch: 6| Step: 12
Training loss: 0.0979870930314064
Validation loss: 1.4192693021989637

Epoch: 6| Step: 13
Training loss: 0.1100405752658844
Validation loss: 1.4110631301838865

Epoch: 667| Step: 0
Training loss: 0.04512086510658264
Validation loss: 1.4182968216557656

Epoch: 6| Step: 1
Training loss: 0.06894887238740921
Validation loss: 1.3983071081099971

Epoch: 6| Step: 2
Training loss: 0.028882235288619995
Validation loss: 1.3660416064723846

Epoch: 6| Step: 3
Training loss: 0.05350080132484436
Validation loss: 1.381278355916341

Epoch: 6| Step: 4
Training loss: 0.06544230878353119
Validation loss: 1.3711878868841356

Epoch: 6| Step: 5
Training loss: 0.12507787346839905
Validation loss: 1.3577008426830333

Epoch: 6| Step: 6
Training loss: 0.08644774556159973
Validation loss: 1.361164337845259

Epoch: 6| Step: 7
Training loss: 0.07207168638706207
Validation loss: 1.352529271956413

Epoch: 6| Step: 8
Training loss: 0.051321521401405334
Validation loss: 1.3756073085210656

Epoch: 6| Step: 9
Training loss: 0.05496794730424881
Validation loss: 1.3635936924206313

Epoch: 6| Step: 10
Training loss: 0.02430201694369316
Validation loss: 1.361746076614626

Epoch: 6| Step: 11
Training loss: 0.09619338065385818
Validation loss: 1.3791663198060886

Epoch: 6| Step: 12
Training loss: 0.02147861197590828
Validation loss: 1.3650676537585515

Epoch: 6| Step: 13
Training loss: 0.033652164041996
Validation loss: 1.3816582041402017

Epoch: 668| Step: 0
Training loss: 0.05749864876270294
Validation loss: 1.3818944077337942

Epoch: 6| Step: 1
Training loss: 0.057713184505701065
Validation loss: 1.3767561162671735

Epoch: 6| Step: 2
Training loss: 0.07094453275203705
Validation loss: 1.409689280935513

Epoch: 6| Step: 3
Training loss: 0.06985264271497726
Validation loss: 1.3954004895302556

Epoch: 6| Step: 4
Training loss: 0.07124843448400497
Validation loss: 1.4130038343450075

Epoch: 6| Step: 5
Training loss: 0.07012543827295303
Validation loss: 1.4154428179546068

Epoch: 6| Step: 6
Training loss: 0.06800009310245514
Validation loss: 1.4015219570488058

Epoch: 6| Step: 7
Training loss: 0.04149314761161804
Validation loss: 1.3878985002476683

Epoch: 6| Step: 8
Training loss: 0.0860590860247612
Validation loss: 1.406805258925243

Epoch: 6| Step: 9
Training loss: 0.060421161353588104
Validation loss: 1.3682640419211438

Epoch: 6| Step: 10
Training loss: 0.032970644533634186
Validation loss: 1.3818423055833386

Epoch: 6| Step: 11
Training loss: 0.048491381108760834
Validation loss: 1.3995306017578288

Epoch: 6| Step: 12
Training loss: 0.030943354591727257
Validation loss: 1.3947805717427244

Epoch: 6| Step: 13
Training loss: 0.08391593396663666
Validation loss: 1.3843390108436666

Epoch: 669| Step: 0
Training loss: 0.032557498663663864
Validation loss: 1.3659738558594898

Epoch: 6| Step: 1
Training loss: 0.03635586053133011
Validation loss: 1.3860905285804503

Epoch: 6| Step: 2
Training loss: 0.0879548043012619
Validation loss: 1.3586936061100294

Epoch: 6| Step: 3
Training loss: 0.09082624316215515
Validation loss: 1.361068969772708

Epoch: 6| Step: 4
Training loss: 0.07745854556560516
Validation loss: 1.3824994038510066

Epoch: 6| Step: 5
Training loss: 0.08258621394634247
Validation loss: 1.3569821529490973

Epoch: 6| Step: 6
Training loss: 0.06827175617218018
Validation loss: 1.3561907096575665

Epoch: 6| Step: 7
Training loss: 0.04368584230542183
Validation loss: 1.3641061641836678

Epoch: 6| Step: 8
Training loss: 0.05895914137363434
Validation loss: 1.3778067634951683

Epoch: 6| Step: 9
Training loss: 0.04812387377023697
Validation loss: 1.4058732371176443

Epoch: 6| Step: 10
Training loss: 0.06803986430168152
Validation loss: 1.3946008348977694

Epoch: 6| Step: 11
Training loss: 0.0777583047747612
Validation loss: 1.4104304621296544

Epoch: 6| Step: 12
Training loss: 0.04110743850469589
Validation loss: 1.4072204674443891

Epoch: 6| Step: 13
Training loss: 0.10870145261287689
Validation loss: 1.3882868315583916

Epoch: 670| Step: 0
Training loss: 0.08134886622428894
Validation loss: 1.40271250278719

Epoch: 6| Step: 1
Training loss: 0.07146984338760376
Validation loss: 1.3901174991361556

Epoch: 6| Step: 2
Training loss: 0.05881093442440033
Validation loss: 1.3816056443798927

Epoch: 6| Step: 3
Training loss: 0.06217268109321594
Validation loss: 1.4117620491212415

Epoch: 6| Step: 4
Training loss: 0.0715942531824112
Validation loss: 1.3755749117943548

Epoch: 6| Step: 5
Training loss: 0.0413588285446167
Validation loss: 1.3666958398716424

Epoch: 6| Step: 6
Training loss: 0.07912994921207428
Validation loss: 1.393186161595006

Epoch: 6| Step: 7
Training loss: 0.050348374992609024
Validation loss: 1.3552915588501961

Epoch: 6| Step: 8
Training loss: 0.04084961488842964
Validation loss: 1.3671761302537815

Epoch: 6| Step: 9
Training loss: 0.07112541049718857
Validation loss: 1.3966343402862549

Epoch: 6| Step: 10
Training loss: 0.04666353017091751
Validation loss: 1.3709605816871888

Epoch: 6| Step: 11
Training loss: 0.0489947572350502
Validation loss: 1.366112498826878

Epoch: 6| Step: 12
Training loss: 0.07146447896957397
Validation loss: 1.377991916030966

Epoch: 6| Step: 13
Training loss: 0.08122239261865616
Validation loss: 1.3742450219328686

Epoch: 671| Step: 0
Training loss: 0.06459739059209824
Validation loss: 1.3686175730920607

Epoch: 6| Step: 1
Training loss: 0.09600063413381577
Validation loss: 1.3953550002908195

Epoch: 6| Step: 2
Training loss: 0.08763937652111053
Validation loss: 1.3731067385724796

Epoch: 6| Step: 3
Training loss: 0.07222805917263031
Validation loss: 1.379789807463205

Epoch: 6| Step: 4
Training loss: 0.05216553807258606
Validation loss: 1.3869227145307808

Epoch: 6| Step: 5
Training loss: 0.0642162412405014
Validation loss: 1.4112366937821912

Epoch: 6| Step: 6
Training loss: 0.1003439798951149
Validation loss: 1.3934281090254426

Epoch: 6| Step: 7
Training loss: 0.0618082657456398
Validation loss: 1.4184207967532578

Epoch: 6| Step: 8
Training loss: 0.05406850948929787
Validation loss: 1.419091510516341

Epoch: 6| Step: 9
Training loss: 0.06274686753749847
Validation loss: 1.412514825021067

Epoch: 6| Step: 10
Training loss: 0.05122111365199089
Validation loss: 1.4023436551452966

Epoch: 6| Step: 11
Training loss: 0.0729965940117836
Validation loss: 1.420890163349849

Epoch: 6| Step: 12
Training loss: 0.04719345271587372
Validation loss: 1.4207553517433904

Epoch: 6| Step: 13
Training loss: 0.054780084639787674
Validation loss: 1.408632122060304

Epoch: 672| Step: 0
Training loss: 0.1049683690071106
Validation loss: 1.3861996422531784

Epoch: 6| Step: 1
Training loss: 0.06240608170628548
Validation loss: 1.3900284792787285

Epoch: 6| Step: 2
Training loss: 0.069603830575943
Validation loss: 1.399063124451586

Epoch: 6| Step: 3
Training loss: 0.038436152040958405
Validation loss: 1.3966398527545314

Epoch: 6| Step: 4
Training loss: 0.06818720698356628
Validation loss: 1.391430216450845

Epoch: 6| Step: 5
Training loss: 0.050446003675460815
Validation loss: 1.4036981745432782

Epoch: 6| Step: 6
Training loss: 0.05954299122095108
Validation loss: 1.40505249269547

Epoch: 6| Step: 7
Training loss: 0.05874820798635483
Validation loss: 1.4126898511763541

Epoch: 6| Step: 8
Training loss: 0.08522844314575195
Validation loss: 1.4254048293636692

Epoch: 6| Step: 9
Training loss: 0.052741553634405136
Validation loss: 1.397487945454095

Epoch: 6| Step: 10
Training loss: 0.046807173639535904
Validation loss: 1.4011034991151543

Epoch: 6| Step: 11
Training loss: 0.04683134704828262
Validation loss: 1.401959817896607

Epoch: 6| Step: 12
Training loss: 0.03334522992372513
Validation loss: 1.4154187325508363

Epoch: 6| Step: 13
Training loss: 0.10041581094264984
Validation loss: 1.4325462951455066

Epoch: 673| Step: 0
Training loss: 0.02713637799024582
Validation loss: 1.394348983482648

Epoch: 6| Step: 1
Training loss: 0.053711920976638794
Validation loss: 1.3867261012395222

Epoch: 6| Step: 2
Training loss: 0.07251892238855362
Validation loss: 1.3622259196414743

Epoch: 6| Step: 3
Training loss: 0.0547984354197979
Validation loss: 1.3768398723294657

Epoch: 6| Step: 4
Training loss: 0.08103947341442108
Validation loss: 1.358821028663266

Epoch: 6| Step: 5
Training loss: 0.07982738316059113
Validation loss: 1.3637366602497716

Epoch: 6| Step: 6
Training loss: 0.09214170277118683
Validation loss: 1.359763261451516

Epoch: 6| Step: 7
Training loss: 0.0771765410900116
Validation loss: 1.3454723678609377

Epoch: 6| Step: 8
Training loss: 0.049794312566518784
Validation loss: 1.3451393368423625

Epoch: 6| Step: 9
Training loss: 0.05713672563433647
Validation loss: 1.3456584279255202

Epoch: 6| Step: 10
Training loss: 0.04919431731104851
Validation loss: 1.3579768762793591

Epoch: 6| Step: 11
Training loss: 0.10332696884870529
Validation loss: 1.333043647068803

Epoch: 6| Step: 12
Training loss: 0.03318631649017334
Validation loss: 1.356998497439969

Epoch: 6| Step: 13
Training loss: 0.029800262302160263
Validation loss: 1.3686737296401814

Epoch: 674| Step: 0
Training loss: 0.05856344848871231
Validation loss: 1.3582350092549478

Epoch: 6| Step: 1
Training loss: 0.06520260870456696
Validation loss: 1.3654318150653635

Epoch: 6| Step: 2
Training loss: 0.07821248471736908
Validation loss: 1.3686881731915217

Epoch: 6| Step: 3
Training loss: 0.07853887975215912
Validation loss: 1.401636956840433

Epoch: 6| Step: 4
Training loss: 0.033682018518447876
Validation loss: 1.386890612622743

Epoch: 6| Step: 5
Training loss: 0.04184769466519356
Validation loss: 1.4053451579104188

Epoch: 6| Step: 6
Training loss: 0.06417782604694366
Validation loss: 1.3988235970979095

Epoch: 6| Step: 7
Training loss: 0.043991267681121826
Validation loss: 1.4184088771061232

Epoch: 6| Step: 8
Training loss: 0.06069463863968849
Validation loss: 1.417581287763452

Epoch: 6| Step: 9
Training loss: 0.05042121186852455
Validation loss: 1.4192374348640442

Epoch: 6| Step: 10
Training loss: 0.07102062553167343
Validation loss: 1.4202653143995552

Epoch: 6| Step: 11
Training loss: 0.10164906829595566
Validation loss: 1.419109550214583

Epoch: 6| Step: 12
Training loss: 0.03677336871623993
Validation loss: 1.3873887356891428

Epoch: 6| Step: 13
Training loss: 0.020370768383145332
Validation loss: 1.4130092910541001

Epoch: 675| Step: 0
Training loss: 0.09577252715826035
Validation loss: 1.3964088347650343

Epoch: 6| Step: 1
Training loss: 0.06365088373422623
Validation loss: 1.399212300136525

Epoch: 6| Step: 2
Training loss: 0.056337952613830566
Validation loss: 1.3871882410459622

Epoch: 6| Step: 3
Training loss: 0.0666818618774414
Validation loss: 1.3505297809518793

Epoch: 6| Step: 4
Training loss: 0.04772598668932915
Validation loss: 1.35500015494644

Epoch: 6| Step: 5
Training loss: 0.04513149708509445
Validation loss: 1.3613672153924101

Epoch: 6| Step: 6
Training loss: 0.07683581858873367
Validation loss: 1.363637670393913

Epoch: 6| Step: 7
Training loss: 0.07525545358657837
Validation loss: 1.3726939373118903

Epoch: 6| Step: 8
Training loss: 0.044119976460933685
Validation loss: 1.3677301432496758

Epoch: 6| Step: 9
Training loss: 0.0344354547560215
Validation loss: 1.3768711115724297

Epoch: 6| Step: 10
Training loss: 0.07502031326293945
Validation loss: 1.3601043096152685

Epoch: 6| Step: 11
Training loss: 0.07977992296218872
Validation loss: 1.3835617226939048

Epoch: 6| Step: 12
Training loss: 0.060176581144332886
Validation loss: 1.3810233275095622

Epoch: 6| Step: 13
Training loss: 0.03865904361009598
Validation loss: 1.3724540580985367

Epoch: 676| Step: 0
Training loss: 0.0410713255405426
Validation loss: 1.4022842927645611

Epoch: 6| Step: 1
Training loss: 0.054564155638217926
Validation loss: 1.3912350029073737

Epoch: 6| Step: 2
Training loss: 0.027552034705877304
Validation loss: 1.3758267279594176

Epoch: 6| Step: 3
Training loss: 0.060602061450481415
Validation loss: 1.3911876434920936

Epoch: 6| Step: 4
Training loss: 0.07416485249996185
Validation loss: 1.3826917704715525

Epoch: 6| Step: 5
Training loss: 0.07131693512201309
Validation loss: 1.3802776131578671

Epoch: 6| Step: 6
Training loss: 0.08459271490573883
Validation loss: 1.3839524715177474

Epoch: 6| Step: 7
Training loss: 0.07671840488910675
Validation loss: 1.3716656187529206

Epoch: 6| Step: 8
Training loss: 0.09234098345041275
Validation loss: 1.3672254867451166

Epoch: 6| Step: 9
Training loss: 0.057513512670993805
Validation loss: 1.3827126769609348

Epoch: 6| Step: 10
Training loss: 0.05378582328557968
Validation loss: 1.385727361966205

Epoch: 6| Step: 11
Training loss: 0.07007577270269394
Validation loss: 1.383778755382825

Epoch: 6| Step: 12
Training loss: 0.06802356243133545
Validation loss: 1.3775670464320848

Epoch: 6| Step: 13
Training loss: 0.07831612229347229
Validation loss: 1.3496881704176626

Epoch: 677| Step: 0
Training loss: 0.026253093034029007
Validation loss: 1.3733732405529226

Epoch: 6| Step: 1
Training loss: 0.06507763266563416
Validation loss: 1.3842211423381683

Epoch: 6| Step: 2
Training loss: 0.05381777137517929
Validation loss: 1.3881256503443564

Epoch: 6| Step: 3
Training loss: 0.05668780952692032
Validation loss: 1.3743155451231106

Epoch: 6| Step: 4
Training loss: 0.04299071058630943
Validation loss: 1.3839374178199357

Epoch: 6| Step: 5
Training loss: 0.10978920757770538
Validation loss: 1.3925510670549126

Epoch: 6| Step: 6
Training loss: 0.05878057703375816
Validation loss: 1.3916585560767882

Epoch: 6| Step: 7
Training loss: 0.05443651229143143
Validation loss: 1.4062688453223116

Epoch: 6| Step: 8
Training loss: 0.05583228915929794
Validation loss: 1.397205336119539

Epoch: 6| Step: 9
Training loss: 0.03579597547650337
Validation loss: 1.3952860454077363

Epoch: 6| Step: 10
Training loss: 0.06235793977975845
Validation loss: 1.4031321258955105

Epoch: 6| Step: 11
Training loss: 0.03358161449432373
Validation loss: 1.3863783459509573

Epoch: 6| Step: 12
Training loss: 0.048656582832336426
Validation loss: 1.3986300768390778

Epoch: 6| Step: 13
Training loss: 0.046912893652915955
Validation loss: 1.3845581957089004

Epoch: 678| Step: 0
Training loss: 0.08111879229545593
Validation loss: 1.3866688884714597

Epoch: 6| Step: 1
Training loss: 0.032605573534965515
Validation loss: 1.3921929649127427

Epoch: 6| Step: 2
Training loss: 0.05378672480583191
Validation loss: 1.3994219995314074

Epoch: 6| Step: 3
Training loss: 0.13063189387321472
Validation loss: 1.3731650511423747

Epoch: 6| Step: 4
Training loss: 0.04453640431165695
Validation loss: 1.3747740701962543

Epoch: 6| Step: 5
Training loss: 0.03867567703127861
Validation loss: 1.3892219303756632

Epoch: 6| Step: 6
Training loss: 0.03037775307893753
Validation loss: 1.3976448633337533

Epoch: 6| Step: 7
Training loss: 0.046287380158901215
Validation loss: 1.4049363943838304

Epoch: 6| Step: 8
Training loss: 0.030048012733459473
Validation loss: 1.3664605412431943

Epoch: 6| Step: 9
Training loss: 0.020799405872821808
Validation loss: 1.363665118012377

Epoch: 6| Step: 10
Training loss: 0.03646154701709747
Validation loss: 1.396670642719474

Epoch: 6| Step: 11
Training loss: 0.06458356976509094
Validation loss: 1.3587925100839267

Epoch: 6| Step: 12
Training loss: 0.07593731582164764
Validation loss: 1.370822246356677

Epoch: 6| Step: 13
Training loss: 0.06502851098775864
Validation loss: 1.370750226000304

Epoch: 679| Step: 0
Training loss: 0.06936931610107422
Validation loss: 1.3571684181049306

Epoch: 6| Step: 1
Training loss: 0.06207747757434845
Validation loss: 1.327429098467673

Epoch: 6| Step: 2
Training loss: 0.06270480155944824
Validation loss: 1.3468911788796867

Epoch: 6| Step: 3
Training loss: 0.07977794110774994
Validation loss: 1.349179487074575

Epoch: 6| Step: 4
Training loss: 0.052525684237480164
Validation loss: 1.3620304458884782

Epoch: 6| Step: 5
Training loss: 0.0403904914855957
Validation loss: 1.3728728268736152

Epoch: 6| Step: 6
Training loss: 0.0443509966135025
Validation loss: 1.3739129061340003

Epoch: 6| Step: 7
Training loss: 0.09451374411582947
Validation loss: 1.3755204805763819

Epoch: 6| Step: 8
Training loss: 0.06518097221851349
Validation loss: 1.3698660763361121

Epoch: 6| Step: 9
Training loss: 0.0467243455350399
Validation loss: 1.3683644404975317

Epoch: 6| Step: 10
Training loss: 0.06381730735301971
Validation loss: 1.3876659633010946

Epoch: 6| Step: 11
Training loss: 0.07247376441955566
Validation loss: 1.3807271859979118

Epoch: 6| Step: 12
Training loss: 0.07310961186885834
Validation loss: 1.3845520455350158

Epoch: 6| Step: 13
Training loss: 0.0796068087220192
Validation loss: 1.4083318159144411

Epoch: 680| Step: 0
Training loss: 0.04840182140469551
Validation loss: 1.4208115993007537

Epoch: 6| Step: 1
Training loss: 0.09108953922986984
Validation loss: 1.4056864489791214

Epoch: 6| Step: 2
Training loss: 0.07568240910768509
Validation loss: 1.4076038945105769

Epoch: 6| Step: 3
Training loss: 0.061307840049266815
Validation loss: 1.420365515575614

Epoch: 6| Step: 4
Training loss: 0.07160713523626328
Validation loss: 1.4109767201126262

Epoch: 6| Step: 5
Training loss: 0.04262615367770195
Validation loss: 1.4278323688814718

Epoch: 6| Step: 6
Training loss: 0.05970083177089691
Validation loss: 1.4238134955847135

Epoch: 6| Step: 7
Training loss: 0.05086936801671982
Validation loss: 1.422104166400048

Epoch: 6| Step: 8
Training loss: 0.032372161746025085
Validation loss: 1.420663781063531

Epoch: 6| Step: 9
Training loss: 0.06032227724790573
Validation loss: 1.4197602887307443

Epoch: 6| Step: 10
Training loss: 0.06315352022647858
Validation loss: 1.4100722292418122

Epoch: 6| Step: 11
Training loss: 0.06596066057682037
Validation loss: 1.4074776595638645

Epoch: 6| Step: 12
Training loss: 0.08463302254676819
Validation loss: 1.3978729183955858

Epoch: 6| Step: 13
Training loss: 0.05086657777428627
Validation loss: 1.3559692354612454

Epoch: 681| Step: 0
Training loss: 0.022841662168502808
Validation loss: 1.3698859458328576

Epoch: 6| Step: 1
Training loss: 0.06377795338630676
Validation loss: 1.364313449910892

Epoch: 6| Step: 2
Training loss: 0.04257157817482948
Validation loss: 1.344551642735799

Epoch: 6| Step: 3
Training loss: 0.06320561468601227
Validation loss: 1.3635679406504477

Epoch: 6| Step: 4
Training loss: 0.06899432837963104
Validation loss: 1.3676926782054286

Epoch: 6| Step: 5
Training loss: 0.038555797189474106
Validation loss: 1.3552218047521447

Epoch: 6| Step: 6
Training loss: 0.10730276256799698
Validation loss: 1.345449770650556

Epoch: 6| Step: 7
Training loss: 0.035257454961538315
Validation loss: 1.3597568568362985

Epoch: 6| Step: 8
Training loss: 0.05514085665345192
Validation loss: 1.3660791131757921

Epoch: 6| Step: 9
Training loss: 0.054881613701581955
Validation loss: 1.3770235251354914

Epoch: 6| Step: 10
Training loss: 0.08281334489583969
Validation loss: 1.3636611033511419

Epoch: 6| Step: 11
Training loss: 0.07377876341342926
Validation loss: 1.3806746980195403

Epoch: 6| Step: 12
Training loss: 0.053711894899606705
Validation loss: 1.3866818963840444

Epoch: 6| Step: 13
Training loss: 0.04116879403591156
Validation loss: 1.3940968385306738

Epoch: 682| Step: 0
Training loss: 0.06640572845935822
Validation loss: 1.4303840565425094

Epoch: 6| Step: 1
Training loss: 0.05823606625199318
Validation loss: 1.4367927389760171

Epoch: 6| Step: 2
Training loss: 0.06555343419313431
Validation loss: 1.4405996735377977

Epoch: 6| Step: 3
Training loss: 0.05111788958311081
Validation loss: 1.4313310141204505

Epoch: 6| Step: 4
Training loss: 0.04959818720817566
Validation loss: 1.429192005947072

Epoch: 6| Step: 5
Training loss: 0.08830618858337402
Validation loss: 1.4113021768549436

Epoch: 6| Step: 6
Training loss: 0.05048002302646637
Validation loss: 1.4098865562869656

Epoch: 6| Step: 7
Training loss: 0.07532185316085815
Validation loss: 1.4016888244177705

Epoch: 6| Step: 8
Training loss: 0.034057363867759705
Validation loss: 1.3981294862685665

Epoch: 6| Step: 9
Training loss: 0.05777557194232941
Validation loss: 1.3886764831440424

Epoch: 6| Step: 10
Training loss: 0.06978906691074371
Validation loss: 1.3861156612314203

Epoch: 6| Step: 11
Training loss: 0.0674246996641159
Validation loss: 1.3822884662176973

Epoch: 6| Step: 12
Training loss: 0.07482343912124634
Validation loss: 1.3818438527404622

Epoch: 6| Step: 13
Training loss: 0.030100055038928986
Validation loss: 1.3781110714840632

Epoch: 683| Step: 0
Training loss: 0.04871377721428871
Validation loss: 1.3996349701317408

Epoch: 6| Step: 1
Training loss: 0.038025494664907455
Validation loss: 1.4053468524768788

Epoch: 6| Step: 2
Training loss: 0.09504052251577377
Validation loss: 1.3869649537148014

Epoch: 6| Step: 3
Training loss: 0.0516134649515152
Validation loss: 1.4040950241909231

Epoch: 6| Step: 4
Training loss: 0.04358764737844467
Validation loss: 1.4199587234886744

Epoch: 6| Step: 5
Training loss: 0.11165377497673035
Validation loss: 1.4211760874717467

Epoch: 6| Step: 6
Training loss: 0.0386541485786438
Validation loss: 1.4083598070247199

Epoch: 6| Step: 7
Training loss: 0.08362824469804764
Validation loss: 1.4166729616862472

Epoch: 6| Step: 8
Training loss: 0.03360338136553764
Validation loss: 1.3744523563692648

Epoch: 6| Step: 9
Training loss: 0.04724906384944916
Validation loss: 1.4010749914312874

Epoch: 6| Step: 10
Training loss: 0.04764321818947792
Validation loss: 1.3677463428948515

Epoch: 6| Step: 11
Training loss: 0.04356193542480469
Validation loss: 1.3788090380289222

Epoch: 6| Step: 12
Training loss: 0.04229358211159706
Validation loss: 1.368222290469754

Epoch: 6| Step: 13
Training loss: 0.03847191110253334
Validation loss: 1.3700597850225305

Epoch: 684| Step: 0
Training loss: 0.03422711044549942
Validation loss: 1.384241557890369

Epoch: 6| Step: 1
Training loss: 0.03456445783376694
Validation loss: 1.3808417640706545

Epoch: 6| Step: 2
Training loss: 0.04173773527145386
Validation loss: 1.3853824279641593

Epoch: 6| Step: 3
Training loss: 0.03661645948886871
Validation loss: 1.3885760230402793

Epoch: 6| Step: 4
Training loss: 0.08306078612804413
Validation loss: 1.3817011938300183

Epoch: 6| Step: 5
Training loss: 0.04681304097175598
Validation loss: 1.3984230506804682

Epoch: 6| Step: 6
Training loss: 0.07524719089269638
Validation loss: 1.3804398595645864

Epoch: 6| Step: 7
Training loss: 0.06679731607437134
Validation loss: 1.3874346492111043

Epoch: 6| Step: 8
Training loss: 0.03475044667720795
Validation loss: 1.4083787805290633

Epoch: 6| Step: 9
Training loss: 0.05633766949176788
Validation loss: 1.4087069060212822

Epoch: 6| Step: 10
Training loss: 0.05863472819328308
Validation loss: 1.4206653923116705

Epoch: 6| Step: 11
Training loss: 0.07590645551681519
Validation loss: 1.4241089256860877

Epoch: 6| Step: 12
Training loss: 0.05696652829647064
Validation loss: 1.4315814228468045

Epoch: 6| Step: 13
Training loss: 0.1103442907333374
Validation loss: 1.4396962863142773

Epoch: 685| Step: 0
Training loss: 0.06747585535049438
Validation loss: 1.4135832043104275

Epoch: 6| Step: 1
Training loss: 0.05308820679783821
Validation loss: 1.4308803581422376

Epoch: 6| Step: 2
Training loss: 0.03651322424411774
Validation loss: 1.4160989112751459

Epoch: 6| Step: 3
Training loss: 0.046751368790864944
Validation loss: 1.4082874559587049

Epoch: 6| Step: 4
Training loss: 0.07405756413936615
Validation loss: 1.4165758317516697

Epoch: 6| Step: 5
Training loss: 0.048675186932086945
Validation loss: 1.402107156733031

Epoch: 6| Step: 6
Training loss: 0.059596143662929535
Validation loss: 1.3939033810810377

Epoch: 6| Step: 7
Training loss: 0.04346339404582977
Validation loss: 1.3863936854946999

Epoch: 6| Step: 8
Training loss: 0.05095107853412628
Validation loss: 1.3766839401696318

Epoch: 6| Step: 9
Training loss: 0.06479640305042267
Validation loss: 1.3764492529694752

Epoch: 6| Step: 10
Training loss: 0.0761055275797844
Validation loss: 1.3514630627888504

Epoch: 6| Step: 11
Training loss: 0.062261734157800674
Validation loss: 1.3385750427041003

Epoch: 6| Step: 12
Training loss: 0.0632953941822052
Validation loss: 1.3450363195070656

Epoch: 6| Step: 13
Training loss: 0.06743288040161133
Validation loss: 1.3574355315136653

Epoch: 686| Step: 0
Training loss: 0.06275337934494019
Validation loss: 1.3691596138861872

Epoch: 6| Step: 1
Training loss: 0.024161141365766525
Validation loss: 1.3639037839827999

Epoch: 6| Step: 2
Training loss: 0.06166408583521843
Validation loss: 1.3758048511320544

Epoch: 6| Step: 3
Training loss: 0.03725619986653328
Validation loss: 1.3749557874536003

Epoch: 6| Step: 4
Training loss: 0.0389951691031456
Validation loss: 1.3514920998645086

Epoch: 6| Step: 5
Training loss: 0.04354023560881615
Validation loss: 1.3763107317750172

Epoch: 6| Step: 6
Training loss: 0.05875970423221588
Validation loss: 1.353700739081188

Epoch: 6| Step: 7
Training loss: 0.06475870311260223
Validation loss: 1.343349665723821

Epoch: 6| Step: 8
Training loss: 0.059599868953228
Validation loss: 1.3727159371940039

Epoch: 6| Step: 9
Training loss: 0.10490065813064575
Validation loss: 1.3722779302186863

Epoch: 6| Step: 10
Training loss: 0.06142691895365715
Validation loss: 1.3732703501178372

Epoch: 6| Step: 11
Training loss: 0.10658179223537445
Validation loss: 1.3696973464822257

Epoch: 6| Step: 12
Training loss: 0.07040133327245712
Validation loss: 1.3875864930050348

Epoch: 6| Step: 13
Training loss: 0.0724530890583992
Validation loss: 1.3797068403613182

Epoch: 687| Step: 0
Training loss: 0.02763472869992256
Validation loss: 1.3810519390208746

Epoch: 6| Step: 1
Training loss: 0.09558974206447601
Validation loss: 1.3975337936032204

Epoch: 6| Step: 2
Training loss: 0.043971747159957886
Validation loss: 1.373306228268531

Epoch: 6| Step: 3
Training loss: 0.03854551911354065
Validation loss: 1.3636998053519958

Epoch: 6| Step: 4
Training loss: 0.056622982025146484
Validation loss: 1.3707705069613714

Epoch: 6| Step: 5
Training loss: 0.03669161722064018
Validation loss: 1.3612024707178916

Epoch: 6| Step: 6
Training loss: 0.03498756140470505
Validation loss: 1.3721812745576263

Epoch: 6| Step: 7
Training loss: 0.05886012688279152
Validation loss: 1.3520631078750855

Epoch: 6| Step: 8
Training loss: 0.09589283168315887
Validation loss: 1.3653618174214517

Epoch: 6| Step: 9
Training loss: 0.04049372673034668
Validation loss: 1.379323741441132

Epoch: 6| Step: 10
Training loss: 0.06561318039894104
Validation loss: 1.3819568516105734

Epoch: 6| Step: 11
Training loss: 0.04797610640525818
Validation loss: 1.373358577810308

Epoch: 6| Step: 12
Training loss: 0.08624009788036346
Validation loss: 1.3793263730182443

Epoch: 6| Step: 13
Training loss: 0.05402173101902008
Validation loss: 1.3825027686293407

Epoch: 688| Step: 0
Training loss: 0.0389765240252018
Validation loss: 1.378833258023826

Epoch: 6| Step: 1
Training loss: 0.050932735204696655
Validation loss: 1.3972818954016573

Epoch: 6| Step: 2
Training loss: 0.06925377994775772
Validation loss: 1.3999837290856145

Epoch: 6| Step: 3
Training loss: 0.040348395705223083
Validation loss: 1.4098306958393385

Epoch: 6| Step: 4
Training loss: 0.08540906012058258
Validation loss: 1.4099962083242272

Epoch: 6| Step: 5
Training loss: 0.07506445050239563
Validation loss: 1.40081319116777

Epoch: 6| Step: 6
Training loss: 0.06795915961265564
Validation loss: 1.4105729403034333

Epoch: 6| Step: 7
Training loss: 0.07215982675552368
Validation loss: 1.39833455060118

Epoch: 6| Step: 8
Training loss: 0.046640545129776
Validation loss: 1.4101873136335803

Epoch: 6| Step: 9
Training loss: 0.03882496803998947
Validation loss: 1.3901575996029762

Epoch: 6| Step: 10
Training loss: 0.0388561375439167
Validation loss: 1.3779407034638107

Epoch: 6| Step: 11
Training loss: 0.050418250262737274
Validation loss: 1.3845617457102704

Epoch: 6| Step: 12
Training loss: 0.05544111877679825
Validation loss: 1.3529882507939492

Epoch: 6| Step: 13
Training loss: 0.05864279717206955
Validation loss: 1.3767311329482703

Epoch: 689| Step: 0
Training loss: 0.07740627974271774
Validation loss: 1.3667878335522068

Epoch: 6| Step: 1
Training loss: 0.03875907510519028
Validation loss: 1.3904725684914538

Epoch: 6| Step: 2
Training loss: 0.06775249540805817
Validation loss: 1.4026275809093187

Epoch: 6| Step: 3
Training loss: 0.04350858926773071
Validation loss: 1.405895020372124

Epoch: 6| Step: 4
Training loss: 0.0378718227148056
Validation loss: 1.411619508138267

Epoch: 6| Step: 5
Training loss: 0.05203938111662865
Validation loss: 1.4345528259072253

Epoch: 6| Step: 6
Training loss: 0.06168316304683685
Validation loss: 1.4116986746429114

Epoch: 6| Step: 7
Training loss: 0.08016183972358704
Validation loss: 1.4219363844522865

Epoch: 6| Step: 8
Training loss: 0.05400218814611435
Validation loss: 1.4238101538791452

Epoch: 6| Step: 9
Training loss: 0.05250537395477295
Validation loss: 1.4200722165005182

Epoch: 6| Step: 10
Training loss: 0.0916215255856514
Validation loss: 1.4199100848167174

Epoch: 6| Step: 11
Training loss: 0.05498139560222626
Validation loss: 1.4152553081512451

Epoch: 6| Step: 12
Training loss: 0.062266021966934204
Validation loss: 1.3881666737218057

Epoch: 6| Step: 13
Training loss: 0.08960200846195221
Validation loss: 1.3698273538261332

Epoch: 690| Step: 0
Training loss: 0.052629485726356506
Validation loss: 1.384503004371479

Epoch: 6| Step: 1
Training loss: 0.041188471019268036
Validation loss: 1.3556511350857314

Epoch: 6| Step: 2
Training loss: 0.05499067157506943
Validation loss: 1.3564810855414278

Epoch: 6| Step: 3
Training loss: 0.039451561868190765
Validation loss: 1.3467660104074786

Epoch: 6| Step: 4
Training loss: 0.07306374609470367
Validation loss: 1.3625740415306502

Epoch: 6| Step: 5
Training loss: 0.09829738736152649
Validation loss: 1.3714848154334611

Epoch: 6| Step: 6
Training loss: 0.06786700338125229
Validation loss: 1.3576822857702933

Epoch: 6| Step: 7
Training loss: 0.051462579518556595
Validation loss: 1.3839426976378246

Epoch: 6| Step: 8
Training loss: 0.05781145766377449
Validation loss: 1.4005302581735837

Epoch: 6| Step: 9
Training loss: 0.08974114060401917
Validation loss: 1.4195000894608036

Epoch: 6| Step: 10
Training loss: 0.08343799412250519
Validation loss: 1.4126704444167435

Epoch: 6| Step: 11
Training loss: 0.06036869436502457
Validation loss: 1.41238373069353

Epoch: 6| Step: 12
Training loss: 0.038229815661907196
Validation loss: 1.4411503653372488

Epoch: 6| Step: 13
Training loss: 0.060189325362443924
Validation loss: 1.4323099511925892

Epoch: 691| Step: 0
Training loss: 0.07743338495492935
Validation loss: 1.4415348037596671

Epoch: 6| Step: 1
Training loss: 0.04075365141034126
Validation loss: 1.4475209225890457

Epoch: 6| Step: 2
Training loss: 0.06297671049833298
Validation loss: 1.448751191939077

Epoch: 6| Step: 3
Training loss: 0.04766815900802612
Validation loss: 1.4135000507036846

Epoch: 6| Step: 4
Training loss: 0.06534077227115631
Validation loss: 1.4195121347263295

Epoch: 6| Step: 5
Training loss: 0.0919385626912117
Validation loss: 1.4312848250071208

Epoch: 6| Step: 6
Training loss: 0.06004291772842407
Validation loss: 1.434966674415014

Epoch: 6| Step: 7
Training loss: 0.04047366976737976
Validation loss: 1.4479339391954484

Epoch: 6| Step: 8
Training loss: 0.04275119677186012
Validation loss: 1.4523675826288038

Epoch: 6| Step: 9
Training loss: 0.08168592303991318
Validation loss: 1.464092077747468

Epoch: 6| Step: 10
Training loss: 0.07475759088993073
Validation loss: 1.4435240466107604

Epoch: 6| Step: 11
Training loss: 0.10271717607975006
Validation loss: 1.438792162044074

Epoch: 6| Step: 12
Training loss: 0.06406892836093903
Validation loss: 1.4124372415645148

Epoch: 6| Step: 13
Training loss: 0.09820226579904556
Validation loss: 1.4019381448786745

Epoch: 692| Step: 0
Training loss: 0.10283759981393814
Validation loss: 1.3929001291592915

Epoch: 6| Step: 1
Training loss: 0.08043667674064636
Validation loss: 1.379376772911318

Epoch: 6| Step: 2
Training loss: 0.07282131910324097
Validation loss: 1.37739799996858

Epoch: 6| Step: 3
Training loss: 0.056447673588991165
Validation loss: 1.3890962882708477

Epoch: 6| Step: 4
Training loss: 0.03712839260697365
Validation loss: 1.3568363753698205

Epoch: 6| Step: 5
Training loss: 0.04822917282581329
Validation loss: 1.3871223054906374

Epoch: 6| Step: 6
Training loss: 0.06165977939963341
Validation loss: 1.384601343062616

Epoch: 6| Step: 7
Training loss: 0.06070972979068756
Validation loss: 1.4056173665549165

Epoch: 6| Step: 8
Training loss: 0.0748969316482544
Validation loss: 1.4101760041329168

Epoch: 6| Step: 9
Training loss: 0.10949602723121643
Validation loss: 1.3926990327014719

Epoch: 6| Step: 10
Training loss: 0.07739639282226562
Validation loss: 1.3929150732614661

Epoch: 6| Step: 11
Training loss: 0.08737750351428986
Validation loss: 1.3770841014000677

Epoch: 6| Step: 12
Training loss: 0.08070148527622223
Validation loss: 1.3871716594183316

Epoch: 6| Step: 13
Training loss: 0.06223248690366745
Validation loss: 1.401374597703257

Epoch: 693| Step: 0
Training loss: 0.1190931499004364
Validation loss: 1.3850478138974918

Epoch: 6| Step: 1
Training loss: 0.14372900128364563
Validation loss: 1.375105833494535

Epoch: 6| Step: 2
Training loss: 0.07685748487710953
Validation loss: 1.3800174574698172

Epoch: 6| Step: 3
Training loss: 0.06641893833875656
Validation loss: 1.3615365054017754

Epoch: 6| Step: 4
Training loss: 0.03755662590265274
Validation loss: 1.3614409059606574

Epoch: 6| Step: 5
Training loss: 0.06398415565490723
Validation loss: 1.3709968648931032

Epoch: 6| Step: 6
Training loss: 0.09182591736316681
Validation loss: 1.3972764181834396

Epoch: 6| Step: 7
Training loss: 0.08915925025939941
Validation loss: 1.3887437184651692

Epoch: 6| Step: 8
Training loss: 0.0703856348991394
Validation loss: 1.36160994345142

Epoch: 6| Step: 9
Training loss: 0.08520060777664185
Validation loss: 1.376525681505921

Epoch: 6| Step: 10
Training loss: 0.04209066554903984
Validation loss: 1.4072542370006602

Epoch: 6| Step: 11
Training loss: 0.06794928759336472
Validation loss: 1.4227845502156082

Epoch: 6| Step: 12
Training loss: 0.08287453651428223
Validation loss: 1.4665662652702742

Epoch: 6| Step: 13
Training loss: 0.09061706066131592
Validation loss: 1.4600187142690022

Epoch: 694| Step: 0
Training loss: 0.061307795345783234
Validation loss: 1.486118503796157

Epoch: 6| Step: 1
Training loss: 0.049259625375270844
Validation loss: 1.5096565831092097

Epoch: 6| Step: 2
Training loss: 0.061049558222293854
Validation loss: 1.459628237191067

Epoch: 6| Step: 3
Training loss: 0.06007624417543411
Validation loss: 1.4863284659642044

Epoch: 6| Step: 4
Training loss: 0.0929035097360611
Validation loss: 1.4558378637477916

Epoch: 6| Step: 5
Training loss: 0.029007811099290848
Validation loss: 1.4261799832826019

Epoch: 6| Step: 6
Training loss: 0.05175863951444626
Validation loss: 1.4186411961432426

Epoch: 6| Step: 7
Training loss: 0.10324797034263611
Validation loss: 1.4322518879367458

Epoch: 6| Step: 8
Training loss: 0.10368897020816803
Validation loss: 1.4204524012022122

Epoch: 6| Step: 9
Training loss: 0.057191863656044006
Validation loss: 1.4179231095057663

Epoch: 6| Step: 10
Training loss: 0.10179607570171356
Validation loss: 1.3963669256497455

Epoch: 6| Step: 11
Training loss: 0.1319686472415924
Validation loss: 1.3792825796270882

Epoch: 6| Step: 12
Training loss: 0.04296034574508667
Validation loss: 1.375619012822387

Epoch: 6| Step: 13
Training loss: 0.07259318977594376
Validation loss: 1.3576046907773582

Epoch: 695| Step: 0
Training loss: 0.06325209885835648
Validation loss: 1.377412703729445

Epoch: 6| Step: 1
Training loss: 0.05838563293218613
Validation loss: 1.3655353592288109

Epoch: 6| Step: 2
Training loss: 0.0562974214553833
Validation loss: 1.3752078728009296

Epoch: 6| Step: 3
Training loss: 0.07223770022392273
Validation loss: 1.3954505984501173

Epoch: 6| Step: 4
Training loss: 0.0972454845905304
Validation loss: 1.4114552556827504

Epoch: 6| Step: 5
Training loss: 0.06338447332382202
Validation loss: 1.4123803800152195

Epoch: 6| Step: 6
Training loss: 0.09040284156799316
Validation loss: 1.4065225867814914

Epoch: 6| Step: 7
Training loss: 0.07218269258737564
Validation loss: 1.403987560220944

Epoch: 6| Step: 8
Training loss: 0.07492582499980927
Validation loss: 1.4216782739085536

Epoch: 6| Step: 9
Training loss: 0.04503579065203667
Validation loss: 1.4247782217558993

Epoch: 6| Step: 10
Training loss: 0.08355188369750977
Validation loss: 1.4325959208191081

Epoch: 6| Step: 11
Training loss: 0.10934913903474808
Validation loss: 1.4055340097796531

Epoch: 6| Step: 12
Training loss: 0.08523789793252945
Validation loss: 1.4421552515798999

Epoch: 6| Step: 13
Training loss: 0.028800897300243378
Validation loss: 1.413917883749931

Epoch: 696| Step: 0
Training loss: 0.02949335053563118
Validation loss: 1.4191768618040188

Epoch: 6| Step: 1
Training loss: 0.09275183081626892
Validation loss: 1.4353998630277571

Epoch: 6| Step: 2
Training loss: 0.08765171468257904
Validation loss: 1.4305740492318266

Epoch: 6| Step: 3
Training loss: 0.04212129861116409
Validation loss: 1.4289798134116716

Epoch: 6| Step: 4
Training loss: 0.039328157901763916
Validation loss: 1.4176074093387974

Epoch: 6| Step: 5
Training loss: 0.08069784194231033
Validation loss: 1.3842681184891732

Epoch: 6| Step: 6
Training loss: 0.10306601226329803
Validation loss: 1.3824713294224074

Epoch: 6| Step: 7
Training loss: 0.04451914131641388
Validation loss: 1.3719276100076654

Epoch: 6| Step: 8
Training loss: 0.045046765357255936
Validation loss: 1.368576689433026

Epoch: 6| Step: 9
Training loss: 0.06631797552108765
Validation loss: 1.3676467300743185

Epoch: 6| Step: 10
Training loss: 0.0813058465719223
Validation loss: 1.3700907704650716

Epoch: 6| Step: 11
Training loss: 0.06855496019124985
Validation loss: 1.3861498871157247

Epoch: 6| Step: 12
Training loss: 0.037474170327186584
Validation loss: 1.4122788188278035

Epoch: 6| Step: 13
Training loss: 0.07189592719078064
Validation loss: 1.4376717934044458

Epoch: 697| Step: 0
Training loss: 0.05133141949772835
Validation loss: 1.4347637058586202

Epoch: 6| Step: 1
Training loss: 0.0948418378829956
Validation loss: 1.447874753705917

Epoch: 6| Step: 2
Training loss: 0.0975286141037941
Validation loss: 1.4561196745082896

Epoch: 6| Step: 3
Training loss: 0.04374527186155319
Validation loss: 1.452688350472399

Epoch: 6| Step: 4
Training loss: 0.10203157365322113
Validation loss: 1.460450941516507

Epoch: 6| Step: 5
Training loss: 0.06944537162780762
Validation loss: 1.4402890134883184

Epoch: 6| Step: 6
Training loss: 0.07644934952259064
Validation loss: 1.4397439200391051

Epoch: 6| Step: 7
Training loss: 0.04572058096528053
Validation loss: 1.437394865097538

Epoch: 6| Step: 8
Training loss: 0.04584790766239166
Validation loss: 1.4012185514614146

Epoch: 6| Step: 9
Training loss: 0.08052083849906921
Validation loss: 1.3946719002980057

Epoch: 6| Step: 10
Training loss: 0.07258288562297821
Validation loss: 1.3969672200500325

Epoch: 6| Step: 11
Training loss: 0.052953530102968216
Validation loss: 1.3854767968577724

Epoch: 6| Step: 12
Training loss: 0.07343913614749908
Validation loss: 1.4072306425340715

Epoch: 6| Step: 13
Training loss: 0.09930197149515152
Validation loss: 1.3780968964740794

Epoch: 698| Step: 0
Training loss: 0.06282363831996918
Validation loss: 1.41015508033896

Epoch: 6| Step: 1
Training loss: 0.05225426331162453
Validation loss: 1.386148916777744

Epoch: 6| Step: 2
Training loss: 0.05030721798539162
Validation loss: 1.4093532011073122

Epoch: 6| Step: 3
Training loss: 0.06403619050979614
Validation loss: 1.4308207073519308

Epoch: 6| Step: 4
Training loss: 0.026035867631435394
Validation loss: 1.4515290990952523

Epoch: 6| Step: 5
Training loss: 0.0454614982008934
Validation loss: 1.455147090778556

Epoch: 6| Step: 6
Training loss: 0.0809093788266182
Validation loss: 1.473794847406367

Epoch: 6| Step: 7
Training loss: 0.04242876172065735
Validation loss: 1.4277864310049242

Epoch: 6| Step: 8
Training loss: 0.06917063891887665
Validation loss: 1.4544895643829017

Epoch: 6| Step: 9
Training loss: 0.07982780039310455
Validation loss: 1.423183464234875

Epoch: 6| Step: 10
Training loss: 0.05978840962052345
Validation loss: 1.4282899210529942

Epoch: 6| Step: 11
Training loss: 0.05932871997356415
Validation loss: 1.4041588088517547

Epoch: 6| Step: 12
Training loss: 0.11077883839607239
Validation loss: 1.4040369090213571

Epoch: 6| Step: 13
Training loss: 0.0228926669806242
Validation loss: 1.4120756490256197

Epoch: 699| Step: 0
Training loss: 0.04943471774458885
Validation loss: 1.4278820022459953

Epoch: 6| Step: 1
Training loss: 0.05972806736826897
Validation loss: 1.4496446437733148

Epoch: 6| Step: 2
Training loss: 0.06135833263397217
Validation loss: 1.43344844284878

Epoch: 6| Step: 3
Training loss: 0.09308396279811859
Validation loss: 1.4128881231431039

Epoch: 6| Step: 4
Training loss: 0.061646219342947006
Validation loss: 1.4266960172243015

Epoch: 6| Step: 5
Training loss: 0.07389288395643234
Validation loss: 1.4206608931223552

Epoch: 6| Step: 6
Training loss: 0.06827814877033234
Validation loss: 1.4145728682958951

Epoch: 6| Step: 7
Training loss: 0.11086766421794891
Validation loss: 1.3826372623443604

Epoch: 6| Step: 8
Training loss: 0.0850895494222641
Validation loss: 1.4105124781208653

Epoch: 6| Step: 9
Training loss: 0.05829319357872009
Validation loss: 1.4083777358455043

Epoch: 6| Step: 10
Training loss: 0.06241871789097786
Validation loss: 1.4296986646549676

Epoch: 6| Step: 11
Training loss: 0.034732885658741
Validation loss: 1.4105904435598722

Epoch: 6| Step: 12
Training loss: 0.09016528725624084
Validation loss: 1.4187368103252944

Epoch: 6| Step: 13
Training loss: 0.03522205352783203
Validation loss: 1.3960325192379694

Epoch: 700| Step: 0
Training loss: 0.0847623348236084
Validation loss: 1.399958715643934

Epoch: 6| Step: 1
Training loss: 0.10391475260257721
Validation loss: 1.3799944257223478

Epoch: 6| Step: 2
Training loss: 0.08320765197277069
Validation loss: 1.3994865314934843

Epoch: 6| Step: 3
Training loss: 0.07969294488430023
Validation loss: 1.4020416954512238

Epoch: 6| Step: 4
Training loss: 0.07468507438898087
Validation loss: 1.4241297283480245

Epoch: 6| Step: 5
Training loss: 0.06618916988372803
Validation loss: 1.420619773608382

Epoch: 6| Step: 6
Training loss: 0.06570632755756378
Validation loss: 1.4274392538173224

Epoch: 6| Step: 7
Training loss: 0.07516222447156906
Validation loss: 1.4131044815945368

Epoch: 6| Step: 8
Training loss: 0.05209524184465408
Validation loss: 1.420833956810736

Epoch: 6| Step: 9
Training loss: 0.07508160918951035
Validation loss: 1.4022133388826925

Epoch: 6| Step: 10
Training loss: 0.05035163089632988
Validation loss: 1.4088891174203606

Epoch: 6| Step: 11
Training loss: 0.09182558208703995
Validation loss: 1.3977303658762286

Epoch: 6| Step: 12
Training loss: 0.06109822168946266
Validation loss: 1.4118200258542133

Epoch: 6| Step: 13
Training loss: 0.048138994723558426
Validation loss: 1.4195018724728656

Epoch: 701| Step: 0
Training loss: 0.048131972551345825
Validation loss: 1.4027818761846071

Epoch: 6| Step: 1
Training loss: 0.04567338526248932
Validation loss: 1.399211404144123

Epoch: 6| Step: 2
Training loss: 0.033675238490104675
Validation loss: 1.4162569007565897

Epoch: 6| Step: 3
Training loss: 0.07533245533704758
Validation loss: 1.3723911700710174

Epoch: 6| Step: 4
Training loss: 0.041495613753795624
Validation loss: 1.3848560676779798

Epoch: 6| Step: 5
Training loss: 0.04509616643190384
Validation loss: 1.3871970471515451

Epoch: 6| Step: 6
Training loss: 0.04919544979929924
Validation loss: 1.38650433991545

Epoch: 6| Step: 7
Training loss: 0.06823920458555222
Validation loss: 1.3852782339178107

Epoch: 6| Step: 8
Training loss: 0.05434494465589523
Validation loss: 1.3894043635296565

Epoch: 6| Step: 9
Training loss: 0.05859445780515671
Validation loss: 1.403058950619031

Epoch: 6| Step: 10
Training loss: 0.06934679299592972
Validation loss: 1.4150966534050562

Epoch: 6| Step: 11
Training loss: 0.07465701550245285
Validation loss: 1.4164960371550692

Epoch: 6| Step: 12
Training loss: 0.0690278634428978
Validation loss: 1.4298595215684624

Epoch: 6| Step: 13
Training loss: 0.05792798101902008
Validation loss: 1.4131837993539789

Epoch: 702| Step: 0
Training loss: 0.05666681379079819
Validation loss: 1.3947061274641304

Epoch: 6| Step: 1
Training loss: 0.05817509442567825
Validation loss: 1.393698376353069

Epoch: 6| Step: 2
Training loss: 0.04097302630543709
Validation loss: 1.375003460914858

Epoch: 6| Step: 3
Training loss: 0.08015687763690948
Validation loss: 1.4031330846971082

Epoch: 6| Step: 4
Training loss: 0.029326610267162323
Validation loss: 1.3847686770141765

Epoch: 6| Step: 5
Training loss: 0.07365413010120392
Validation loss: 1.3910617366913827

Epoch: 6| Step: 6
Training loss: 0.05117090791463852
Validation loss: 1.3821913401285808

Epoch: 6| Step: 7
Training loss: 0.07562877237796783
Validation loss: 1.3797537972850185

Epoch: 6| Step: 8
Training loss: 0.05495844781398773
Validation loss: 1.4141128293929561

Epoch: 6| Step: 9
Training loss: 0.06098422408103943
Validation loss: 1.3941104194169402

Epoch: 6| Step: 10
Training loss: 0.10272391140460968
Validation loss: 1.4043553247246692

Epoch: 6| Step: 11
Training loss: 0.06601212918758392
Validation loss: 1.4052358474782718

Epoch: 6| Step: 12
Training loss: 0.05284857749938965
Validation loss: 1.3755012814716627

Epoch: 6| Step: 13
Training loss: 0.07299354672431946
Validation loss: 1.404688145524712

Epoch: 703| Step: 0
Training loss: 0.04194314777851105
Validation loss: 1.3817966586800032

Epoch: 6| Step: 1
Training loss: 0.05942440405488014
Validation loss: 1.383554445799961

Epoch: 6| Step: 2
Training loss: 0.041523147374391556
Validation loss: 1.378532621168321

Epoch: 6| Step: 3
Training loss: 0.035383518785238266
Validation loss: 1.3765024549217635

Epoch: 6| Step: 4
Training loss: 0.0648658275604248
Validation loss: 1.3919410936294063

Epoch: 6| Step: 5
Training loss: 0.061862215399742126
Validation loss: 1.3997617998430807

Epoch: 6| Step: 6
Training loss: 0.04935089498758316
Validation loss: 1.404913422881916

Epoch: 6| Step: 7
Training loss: 0.04595078155398369
Validation loss: 1.4093056007098126

Epoch: 6| Step: 8
Training loss: 0.05132794752717018
Validation loss: 1.4139625026333718

Epoch: 6| Step: 9
Training loss: 0.05124849081039429
Validation loss: 1.4227046338460778

Epoch: 6| Step: 10
Training loss: 0.06470008194446564
Validation loss: 1.4318350040784447

Epoch: 6| Step: 11
Training loss: 0.1220112219452858
Validation loss: 1.4539333697288268

Epoch: 6| Step: 12
Training loss: 0.05941641330718994
Validation loss: 1.454440248909817

Epoch: 6| Step: 13
Training loss: 0.041554827243089676
Validation loss: 1.430074586663195

Epoch: 704| Step: 0
Training loss: 0.05141102150082588
Validation loss: 1.3927755381471367

Epoch: 6| Step: 1
Training loss: 0.06198820844292641
Validation loss: 1.35988748586306

Epoch: 6| Step: 2
Training loss: 0.11189717054367065
Validation loss: 1.3371353521141955

Epoch: 6| Step: 3
Training loss: 0.13175612688064575
Validation loss: 1.3374840277497486

Epoch: 6| Step: 4
Training loss: 0.09665397554636002
Validation loss: 1.3334717148093767

Epoch: 6| Step: 5
Training loss: 0.0858587697148323
Validation loss: 1.344743271027842

Epoch: 6| Step: 6
Training loss: 0.03911089524626732
Validation loss: 1.3504595154075212

Epoch: 6| Step: 7
Training loss: 0.06305225938558578
Validation loss: 1.3735834385759087

Epoch: 6| Step: 8
Training loss: 0.06297817826271057
Validation loss: 1.3983473444497714

Epoch: 6| Step: 9
Training loss: 0.037864625453948975
Validation loss: 1.4080048805923873

Epoch: 6| Step: 10
Training loss: 0.06255465745925903
Validation loss: 1.4365071404364802

Epoch: 6| Step: 11
Training loss: 0.04913192614912987
Validation loss: 1.4546960733270133

Epoch: 6| Step: 12
Training loss: 0.05751662328839302
Validation loss: 1.4391177495320637

Epoch: 6| Step: 13
Training loss: 0.13756565749645233
Validation loss: 1.4533435157550278

Epoch: 705| Step: 0
Training loss: 0.10954174399375916
Validation loss: 1.4256567737107635

Epoch: 6| Step: 1
Training loss: 0.07115088403224945
Validation loss: 1.429018892267699

Epoch: 6| Step: 2
Training loss: 0.06835344433784485
Validation loss: 1.4227912413176669

Epoch: 6| Step: 3
Training loss: 0.06418667733669281
Validation loss: 1.399842248808953

Epoch: 6| Step: 4
Training loss: 0.09798994660377502
Validation loss: 1.4017735963226647

Epoch: 6| Step: 5
Training loss: 0.08189542591571808
Validation loss: 1.4223165274948202

Epoch: 6| Step: 6
Training loss: 0.08185793459415436
Validation loss: 1.400615635738578

Epoch: 6| Step: 7
Training loss: 0.042097222059965134
Validation loss: 1.4256059559442664

Epoch: 6| Step: 8
Training loss: 0.06538473814725876
Validation loss: 1.3916156586780344

Epoch: 6| Step: 9
Training loss: 0.04065985232591629
Validation loss: 1.452029972948054

Epoch: 6| Step: 10
Training loss: 0.09197058528661728
Validation loss: 1.4290016671662689

Epoch: 6| Step: 11
Training loss: 0.05775032937526703
Validation loss: 1.4517044956966112

Epoch: 6| Step: 12
Training loss: 0.04114555940032005
Validation loss: 1.4533634660064534

Epoch: 6| Step: 13
Training loss: 0.08191312104463577
Validation loss: 1.4385493301576184

Epoch: 706| Step: 0
Training loss: 0.08309334516525269
Validation loss: 1.4477906227111816

Epoch: 6| Step: 1
Training loss: 0.0752175822854042
Validation loss: 1.4359155701052757

Epoch: 6| Step: 2
Training loss: 0.05053907632827759
Validation loss: 1.421225332444714

Epoch: 6| Step: 3
Training loss: 0.04131650924682617
Validation loss: 1.4084891324402184

Epoch: 6| Step: 4
Training loss: 0.05305936932563782
Validation loss: 1.3994783123013794

Epoch: 6| Step: 5
Training loss: 0.03901226818561554
Validation loss: 1.3863451750047746

Epoch: 6| Step: 6
Training loss: 0.05820164084434509
Validation loss: 1.370299865481674

Epoch: 6| Step: 7
Training loss: 0.07794347405433655
Validation loss: 1.3776223633878975

Epoch: 6| Step: 8
Training loss: 0.063491091132164
Validation loss: 1.4084303379058838

Epoch: 6| Step: 9
Training loss: 0.0430622436106205
Validation loss: 1.4196684027230868

Epoch: 6| Step: 10
Training loss: 0.04345446452498436
Validation loss: 1.4284553758559688

Epoch: 6| Step: 11
Training loss: 0.11344444751739502
Validation loss: 1.423655351003011

Epoch: 6| Step: 12
Training loss: 0.07084307819604874
Validation loss: 1.4273439902131275

Epoch: 6| Step: 13
Training loss: 0.06764665991067886
Validation loss: 1.4206152436553792

Epoch: 707| Step: 0
Training loss: 0.04533403366804123
Validation loss: 1.4046753939761911

Epoch: 6| Step: 1
Training loss: 0.029564855620265007
Validation loss: 1.4264015061880952

Epoch: 6| Step: 2
Training loss: 0.14660045504570007
Validation loss: 1.4166308949070592

Epoch: 6| Step: 3
Training loss: 0.05435675010085106
Validation loss: 1.425873524399214

Epoch: 6| Step: 4
Training loss: 0.11073624342679977
Validation loss: 1.393146917384158

Epoch: 6| Step: 5
Training loss: 0.08261235058307648
Validation loss: 1.4105075661854078

Epoch: 6| Step: 6
Training loss: 0.04163225740194321
Validation loss: 1.4216731222726966

Epoch: 6| Step: 7
Training loss: 0.06698587536811829
Validation loss: 1.421936724775581

Epoch: 6| Step: 8
Training loss: 0.11367592215538025
Validation loss: 1.4155476400929112

Epoch: 6| Step: 9
Training loss: 0.05978096276521683
Validation loss: 1.4286883082441104

Epoch: 6| Step: 10
Training loss: 0.06554749608039856
Validation loss: 1.4652810673559866

Epoch: 6| Step: 11
Training loss: 0.08344264328479767
Validation loss: 1.453644448711026

Epoch: 6| Step: 12
Training loss: 0.10720501840114594
Validation loss: 1.4528782342069892

Epoch: 6| Step: 13
Training loss: 0.05057011544704437
Validation loss: 1.4316343210076774

Epoch: 708| Step: 0
Training loss: 0.04720878228545189
Validation loss: 1.4376949020611343

Epoch: 6| Step: 1
Training loss: 0.05324820429086685
Validation loss: 1.4348887371760544

Epoch: 6| Step: 2
Training loss: 0.0867379829287529
Validation loss: 1.4472028741272547

Epoch: 6| Step: 3
Training loss: 0.0820537582039833
Validation loss: 1.4138457031660183

Epoch: 6| Step: 4
Training loss: 0.10861122608184814
Validation loss: 1.4196511962080514

Epoch: 6| Step: 5
Training loss: 0.07604280859231949
Validation loss: 1.4158354151633479

Epoch: 6| Step: 6
Training loss: 0.06704701483249664
Validation loss: 1.4053067904646679

Epoch: 6| Step: 7
Training loss: 0.0804365873336792
Validation loss: 1.4309543050745481

Epoch: 6| Step: 8
Training loss: 0.0791315957903862
Validation loss: 1.4085623782168153

Epoch: 6| Step: 9
Training loss: 0.05124601721763611
Validation loss: 1.400518645522415

Epoch: 6| Step: 10
Training loss: 0.07234644889831543
Validation loss: 1.4009613990783691

Epoch: 6| Step: 11
Training loss: 0.06717735528945923
Validation loss: 1.4318447792401878

Epoch: 6| Step: 12
Training loss: 0.07951541244983673
Validation loss: 1.4108989713012532

Epoch: 6| Step: 13
Training loss: 0.06574586033821106
Validation loss: 1.4053323845709524

Epoch: 709| Step: 0
Training loss: 0.04003752022981644
Validation loss: 1.41929377407156

Epoch: 6| Step: 1
Training loss: 0.07611305266618729
Validation loss: 1.4280935846349245

Epoch: 6| Step: 2
Training loss: 0.041578128933906555
Validation loss: 1.422746583979617

Epoch: 6| Step: 3
Training loss: 0.03731659799814224
Validation loss: 1.4301049561910733

Epoch: 6| Step: 4
Training loss: 0.0704139843583107
Validation loss: 1.4200860492644771

Epoch: 6| Step: 5
Training loss: 0.09664204716682434
Validation loss: 1.4122736966738136

Epoch: 6| Step: 6
Training loss: 0.09158787876367569
Validation loss: 1.390643532558154

Epoch: 6| Step: 7
Training loss: 0.1066296398639679
Validation loss: 1.37326084157472

Epoch: 6| Step: 8
Training loss: 0.06050616130232811
Validation loss: 1.363665303235413

Epoch: 6| Step: 9
Training loss: 0.05230129882693291
Validation loss: 1.372044442802347

Epoch: 6| Step: 10
Training loss: 0.05525324493646622
Validation loss: 1.3536720198969687

Epoch: 6| Step: 11
Training loss: 0.051592979580163956
Validation loss: 1.3603758004403883

Epoch: 6| Step: 12
Training loss: 0.048191942274570465
Validation loss: 1.3858829685436782

Epoch: 6| Step: 13
Training loss: 0.07339829951524734
Validation loss: 1.3500124946717293

Epoch: 710| Step: 0
Training loss: 0.10128418356180191
Validation loss: 1.3550432683319173

Epoch: 6| Step: 1
Training loss: 0.03910414129495621
Validation loss: 1.3552719623811784

Epoch: 6| Step: 2
Training loss: 0.054687704890966415
Validation loss: 1.3473533763680408

Epoch: 6| Step: 3
Training loss: 0.059433795511722565
Validation loss: 1.3600692819523554

Epoch: 6| Step: 4
Training loss: 0.03476083651185036
Validation loss: 1.3697943405438495

Epoch: 6| Step: 5
Training loss: 0.042683616280555725
Validation loss: 1.3779623469998759

Epoch: 6| Step: 6
Training loss: 0.04388932138681412
Validation loss: 1.3800907814374535

Epoch: 6| Step: 7
Training loss: 0.058394595980644226
Validation loss: 1.39442838135586

Epoch: 6| Step: 8
Training loss: 0.058761030435562134
Validation loss: 1.3995126876779782

Epoch: 6| Step: 9
Training loss: 0.05291416496038437
Validation loss: 1.4118794093849838

Epoch: 6| Step: 10
Training loss: 0.044892292469739914
Validation loss: 1.4145737239109573

Epoch: 6| Step: 11
Training loss: 0.06258852779865265
Validation loss: 1.4250520416485366

Epoch: 6| Step: 12
Training loss: 0.043995484709739685
Validation loss: 1.3961284365705264

Epoch: 6| Step: 13
Training loss: 0.05009985715150833
Validation loss: 1.4016221415612005

Epoch: 711| Step: 0
Training loss: 0.06597425788640976
Validation loss: 1.4259958523575977

Epoch: 6| Step: 1
Training loss: 0.016203248873353004
Validation loss: 1.4205993580561813

Epoch: 6| Step: 2
Training loss: 0.08679665625095367
Validation loss: 1.4189677084645917

Epoch: 6| Step: 3
Training loss: 0.04986431449651718
Validation loss: 1.417193611462911

Epoch: 6| Step: 4
Training loss: 0.06329413503408432
Validation loss: 1.4262818495432537

Epoch: 6| Step: 5
Training loss: 0.04738735780119896
Validation loss: 1.4103103991477721

Epoch: 6| Step: 6
Training loss: 0.08941039443016052
Validation loss: 1.4085298071625412

Epoch: 6| Step: 7
Training loss: 0.036092668771743774
Validation loss: 1.3972228483487201

Epoch: 6| Step: 8
Training loss: 0.04485796019434929
Validation loss: 1.3905246462873233

Epoch: 6| Step: 9
Training loss: 0.08731984347105026
Validation loss: 1.3893715258567565

Epoch: 6| Step: 10
Training loss: 0.030933905392885208
Validation loss: 1.4088709508219073

Epoch: 6| Step: 11
Training loss: 0.045133545994758606
Validation loss: 1.3889110306257844

Epoch: 6| Step: 12
Training loss: 0.04687297344207764
Validation loss: 1.393924924635118

Epoch: 6| Step: 13
Training loss: 0.05830351635813713
Validation loss: 1.4069198523798296

Epoch: 712| Step: 0
Training loss: 0.040469247847795486
Validation loss: 1.4350188214291808

Epoch: 6| Step: 1
Training loss: 0.04213442653417587
Validation loss: 1.4231600043594197

Epoch: 6| Step: 2
Training loss: 0.04139920324087143
Validation loss: 1.4527859815987207

Epoch: 6| Step: 3
Training loss: 0.06255771964788437
Validation loss: 1.4558226075223697

Epoch: 6| Step: 4
Training loss: 0.09338576346635818
Validation loss: 1.4518600099830217

Epoch: 6| Step: 5
Training loss: 0.13023436069488525
Validation loss: 1.4198111910973825

Epoch: 6| Step: 6
Training loss: 0.04687071964144707
Validation loss: 1.3860156279738232

Epoch: 6| Step: 7
Training loss: 0.07620686292648315
Validation loss: 1.358450041022352

Epoch: 6| Step: 8
Training loss: 0.06849011033773422
Validation loss: 1.351886362157842

Epoch: 6| Step: 9
Training loss: 0.06023125723004341
Validation loss: 1.3712424424386793

Epoch: 6| Step: 10
Training loss: 0.06734013557434082
Validation loss: 1.3627810708938106

Epoch: 6| Step: 11
Training loss: 0.08600793778896332
Validation loss: 1.365744189549518

Epoch: 6| Step: 12
Training loss: 0.06077088415622711
Validation loss: 1.3808297790506834

Epoch: 6| Step: 13
Training loss: 0.12543174624443054
Validation loss: 1.3913004366300439

Epoch: 713| Step: 0
Training loss: 0.05319780856370926
Validation loss: 1.395917848874164

Epoch: 6| Step: 1
Training loss: 0.04675508663058281
Validation loss: 1.4200587093189199

Epoch: 6| Step: 2
Training loss: 0.03687242045998573
Validation loss: 1.4465711257791007

Epoch: 6| Step: 3
Training loss: 0.07124761492013931
Validation loss: 1.4492881951793548

Epoch: 6| Step: 4
Training loss: 0.09404317289590836
Validation loss: 1.453787806213543

Epoch: 6| Step: 5
Training loss: 0.05408940464258194
Validation loss: 1.4590117598092684

Epoch: 6| Step: 6
Training loss: 0.061350420117378235
Validation loss: 1.4466212628990092

Epoch: 6| Step: 7
Training loss: 0.06403912603855133
Validation loss: 1.4333073913410146

Epoch: 6| Step: 8
Training loss: 0.0634276270866394
Validation loss: 1.4355139822088263

Epoch: 6| Step: 9
Training loss: 0.06980235874652863
Validation loss: 1.4134426430989337

Epoch: 6| Step: 10
Training loss: 0.06557578593492508
Validation loss: 1.4150429092427736

Epoch: 6| Step: 11
Training loss: 0.07689361274242401
Validation loss: 1.4195516840104134

Epoch: 6| Step: 12
Training loss: 0.05800383910536766
Validation loss: 1.40620094601826

Epoch: 6| Step: 13
Training loss: 0.1058029979467392
Validation loss: 1.411763278386926

Epoch: 714| Step: 0
Training loss: 0.045000914484262466
Validation loss: 1.4025271746420092

Epoch: 6| Step: 1
Training loss: 0.044603198766708374
Validation loss: 1.4090827062565794

Epoch: 6| Step: 2
Training loss: 0.06331154704093933
Validation loss: 1.4078003232197096

Epoch: 6| Step: 3
Training loss: 0.05600208789110184
Validation loss: 1.4613695657381447

Epoch: 6| Step: 4
Training loss: 0.07093709707260132
Validation loss: 1.4459260356041692

Epoch: 6| Step: 5
Training loss: 0.07246171683073044
Validation loss: 1.4425622801626883

Epoch: 6| Step: 6
Training loss: 0.10801059752702713
Validation loss: 1.4561911616274106

Epoch: 6| Step: 7
Training loss: 0.0758376494050026
Validation loss: 1.4584603668541036

Epoch: 6| Step: 8
Training loss: 0.05463743582367897
Validation loss: 1.4727658123098395

Epoch: 6| Step: 9
Training loss: 0.09125660359859467
Validation loss: 1.4225768453331404

Epoch: 6| Step: 10
Training loss: 0.07943451404571533
Validation loss: 1.4274423276224444

Epoch: 6| Step: 11
Training loss: 0.03728114068508148
Validation loss: 1.4123977294532202

Epoch: 6| Step: 12
Training loss: 0.06123114749789238
Validation loss: 1.384940182009051

Epoch: 6| Step: 13
Training loss: 0.09767842292785645
Validation loss: 1.380901458442852

Epoch: 715| Step: 0
Training loss: 0.06054970249533653
Validation loss: 1.381767088367093

Epoch: 6| Step: 1
Training loss: 0.14726151525974274
Validation loss: 1.3759644813435052

Epoch: 6| Step: 2
Training loss: 0.06142324581742287
Validation loss: 1.3686384417677437

Epoch: 6| Step: 3
Training loss: 0.060462020337581635
Validation loss: 1.3812534322020829

Epoch: 6| Step: 4
Training loss: 0.06993955373764038
Validation loss: 1.3749481458817758

Epoch: 6| Step: 5
Training loss: 0.031977154314517975
Validation loss: 1.3731691721946961

Epoch: 6| Step: 6
Training loss: 0.04632321745157242
Validation loss: 1.3767635758205126

Epoch: 6| Step: 7
Training loss: 0.057499807327985764
Validation loss: 1.373767347745998

Epoch: 6| Step: 8
Training loss: 0.053986646234989166
Validation loss: 1.38350506495404

Epoch: 6| Step: 9
Training loss: 0.0755838006734848
Validation loss: 1.4125580345430682

Epoch: 6| Step: 10
Training loss: 0.05895845592021942
Validation loss: 1.4006307304546397

Epoch: 6| Step: 11
Training loss: 0.06239169463515282
Validation loss: 1.383219849678778

Epoch: 6| Step: 12
Training loss: 0.07307279109954834
Validation loss: 1.373833252537635

Epoch: 6| Step: 13
Training loss: 0.11523416638374329
Validation loss: 1.3470565375461374

Epoch: 716| Step: 0
Training loss: 0.04094458371400833
Validation loss: 1.3554314201877964

Epoch: 6| Step: 1
Training loss: 0.049341291189193726
Validation loss: 1.3842334760132657

Epoch: 6| Step: 2
Training loss: 0.06585562974214554
Validation loss: 1.3997000737856793

Epoch: 6| Step: 3
Training loss: 0.06751066446304321
Validation loss: 1.3681547052116805

Epoch: 6| Step: 4
Training loss: 0.06837765872478485
Validation loss: 1.3787412284522929

Epoch: 6| Step: 5
Training loss: 0.07640302181243896
Validation loss: 1.3536381542041738

Epoch: 6| Step: 6
Training loss: 0.05021781474351883
Validation loss: 1.3784423117996545

Epoch: 6| Step: 7
Training loss: 0.08851245790719986
Validation loss: 1.3792282612093034

Epoch: 6| Step: 8
Training loss: 0.05768948793411255
Validation loss: 1.378444645994453

Epoch: 6| Step: 9
Training loss: 0.06041966751217842
Validation loss: 1.3823558361299577

Epoch: 6| Step: 10
Training loss: 0.046335071325302124
Validation loss: 1.3653370609847448

Epoch: 6| Step: 11
Training loss: 0.08256565034389496
Validation loss: 1.4016247526291878

Epoch: 6| Step: 12
Training loss: 0.0468122661113739
Validation loss: 1.3993144112248574

Epoch: 6| Step: 13
Training loss: 0.044461317360401154
Validation loss: 1.3935057040183776

Epoch: 717| Step: 0
Training loss: 0.04395928606390953
Validation loss: 1.4080198862219369

Epoch: 6| Step: 1
Training loss: 0.06763175874948502
Validation loss: 1.4067274037227835

Epoch: 6| Step: 2
Training loss: 0.03187122941017151
Validation loss: 1.3947830930832894

Epoch: 6| Step: 3
Training loss: 0.07678235322237015
Validation loss: 1.4244206272145754

Epoch: 6| Step: 4
Training loss: 0.07601872086524963
Validation loss: 1.3776977959499563

Epoch: 6| Step: 5
Training loss: 0.0339353047311306
Validation loss: 1.3844669672750658

Epoch: 6| Step: 6
Training loss: 0.05425841733813286
Validation loss: 1.3770810378495084

Epoch: 6| Step: 7
Training loss: 0.051273196935653687
Validation loss: 1.3999658951195337

Epoch: 6| Step: 8
Training loss: 0.04875306040048599
Validation loss: 1.3849573519922072

Epoch: 6| Step: 9
Training loss: 0.06457261741161346
Validation loss: 1.4131471828747821

Epoch: 6| Step: 10
Training loss: 0.0776890441775322
Validation loss: 1.4215983857390702

Epoch: 6| Step: 11
Training loss: 0.05505061894655228
Validation loss: 1.4062399377105057

Epoch: 6| Step: 12
Training loss: 0.05602031946182251
Validation loss: 1.3988568923806632

Epoch: 6| Step: 13
Training loss: 0.07516422867774963
Validation loss: 1.417182368616904

Epoch: 718| Step: 0
Training loss: 0.07809081673622131
Validation loss: 1.3764172805252897

Epoch: 6| Step: 1
Training loss: 0.07147982716560364
Validation loss: 1.3871871732896375

Epoch: 6| Step: 2
Training loss: 0.07371336221694946
Validation loss: 1.368303350223008

Epoch: 6| Step: 3
Training loss: 0.03847481682896614
Validation loss: 1.369335118160453

Epoch: 6| Step: 4
Training loss: 0.07359574735164642
Validation loss: 1.3751730072882868

Epoch: 6| Step: 5
Training loss: 0.05038915574550629
Validation loss: 1.3705366016716085

Epoch: 6| Step: 6
Training loss: 0.03637383133172989
Validation loss: 1.355716041339341

Epoch: 6| Step: 7
Training loss: 0.06878015398979187
Validation loss: 1.3766931526122554

Epoch: 6| Step: 8
Training loss: 0.05457248538732529
Validation loss: 1.3674691159238097

Epoch: 6| Step: 9
Training loss: 0.06238972395658493
Validation loss: 1.3770718023341189

Epoch: 6| Step: 10
Training loss: 0.08395279943943024
Validation loss: 1.3776008582884265

Epoch: 6| Step: 11
Training loss: 0.05735953152179718
Validation loss: 1.3950015203927153

Epoch: 6| Step: 12
Training loss: 0.08293107897043228
Validation loss: 1.3891371475752963

Epoch: 6| Step: 13
Training loss: 0.06950052827596664
Validation loss: 1.3739205227103284

Epoch: 719| Step: 0
Training loss: 0.09909066557884216
Validation loss: 1.4080692696314987

Epoch: 6| Step: 1
Training loss: 0.04917018115520477
Validation loss: 1.408225138982137

Epoch: 6| Step: 2
Training loss: 0.07206027209758759
Validation loss: 1.4136094611178163

Epoch: 6| Step: 3
Training loss: 0.044035762548446655
Validation loss: 1.4311173500553254

Epoch: 6| Step: 4
Training loss: 0.04320545494556427
Validation loss: 1.4393477683426232

Epoch: 6| Step: 5
Training loss: 0.05477796494960785
Validation loss: 1.4372572745046308

Epoch: 6| Step: 6
Training loss: 0.0812506228685379
Validation loss: 1.4247549964535622

Epoch: 6| Step: 7
Training loss: 0.049009427428245544
Validation loss: 1.4309532821819346

Epoch: 6| Step: 8
Training loss: 0.06531817466020584
Validation loss: 1.4011306326876405

Epoch: 6| Step: 9
Training loss: 0.043669965118169785
Validation loss: 1.407809768953631

Epoch: 6| Step: 10
Training loss: 0.04655672609806061
Validation loss: 1.4216031246287848

Epoch: 6| Step: 11
Training loss: 0.07207082957029343
Validation loss: 1.3950684621769895

Epoch: 6| Step: 12
Training loss: 0.08311210572719574
Validation loss: 1.412961947020664

Epoch: 6| Step: 13
Training loss: 0.06687382608652115
Validation loss: 1.3812722723971131

Epoch: 720| Step: 0
Training loss: 0.06872459501028061
Validation loss: 1.398369864750934

Epoch: 6| Step: 1
Training loss: 0.08672022819519043
Validation loss: 1.3871730348115325

Epoch: 6| Step: 2
Training loss: 0.051364243030548096
Validation loss: 1.384983898490988

Epoch: 6| Step: 3
Training loss: 0.0632719099521637
Validation loss: 1.3820082128688853

Epoch: 6| Step: 4
Training loss: 0.060818009078502655
Validation loss: 1.3731987053348171

Epoch: 6| Step: 5
Training loss: 0.06815072149038315
Validation loss: 1.3768352000944075

Epoch: 6| Step: 6
Training loss: 0.08285612612962723
Validation loss: 1.3954340591225574

Epoch: 6| Step: 7
Training loss: 0.06054070591926575
Validation loss: 1.3908185869134881

Epoch: 6| Step: 8
Training loss: 0.04421039670705795
Validation loss: 1.398018398592549

Epoch: 6| Step: 9
Training loss: 0.07359642535448074
Validation loss: 1.4321924473649712

Epoch: 6| Step: 10
Training loss: 0.04529904946684837
Validation loss: 1.4409333557210944

Epoch: 6| Step: 11
Training loss: 0.052622050046920776
Validation loss: 1.4566663760010914

Epoch: 6| Step: 12
Training loss: 0.051672667264938354
Validation loss: 1.4279152680468816

Epoch: 6| Step: 13
Training loss: 0.03541580215096474
Validation loss: 1.4171336684175717

Epoch: 721| Step: 0
Training loss: 0.04950980469584465
Validation loss: 1.4018668833599295

Epoch: 6| Step: 1
Training loss: 0.04530488699674606
Validation loss: 1.4111778531023251

Epoch: 6| Step: 2
Training loss: 0.05052749067544937
Validation loss: 1.3915348040160311

Epoch: 6| Step: 3
Training loss: 0.09739306569099426
Validation loss: 1.4077931052895003

Epoch: 6| Step: 4
Training loss: 0.035617608577013016
Validation loss: 1.3696915244543424

Epoch: 6| Step: 5
Training loss: 0.07232518494129181
Validation loss: 1.40894184061276

Epoch: 6| Step: 6
Training loss: 0.05570017546415329
Validation loss: 1.386837827262058

Epoch: 6| Step: 7
Training loss: 0.0700727179646492
Validation loss: 1.3878849232068626

Epoch: 6| Step: 8
Training loss: 0.062480825930833817
Validation loss: 1.4040067952166322

Epoch: 6| Step: 9
Training loss: 0.03724386543035507
Validation loss: 1.3890041843537362

Epoch: 6| Step: 10
Training loss: 0.030819684267044067
Validation loss: 1.3942824730309107

Epoch: 6| Step: 11
Training loss: 0.09013967961072922
Validation loss: 1.4026568820399623

Epoch: 6| Step: 12
Training loss: 0.06326521188020706
Validation loss: 1.4036043305550852

Epoch: 6| Step: 13
Training loss: 0.040667612105607986
Validation loss: 1.4173979631034277

Epoch: 722| Step: 0
Training loss: 0.04374374449253082
Validation loss: 1.4038275082906086

Epoch: 6| Step: 1
Training loss: 0.08384402841329575
Validation loss: 1.4108317077800792

Epoch: 6| Step: 2
Training loss: 0.07362493127584457
Validation loss: 1.4052539499857093

Epoch: 6| Step: 3
Training loss: 0.04449920356273651
Validation loss: 1.3897372804662234

Epoch: 6| Step: 4
Training loss: 0.03775458410382271
Validation loss: 1.3928587769949308

Epoch: 6| Step: 5
Training loss: 0.04930891469120979
Validation loss: 1.3791086789100402

Epoch: 6| Step: 6
Training loss: 0.04789912700653076
Validation loss: 1.3743059487753018

Epoch: 6| Step: 7
Training loss: 0.06830441951751709
Validation loss: 1.3734010124719271

Epoch: 6| Step: 8
Training loss: 0.03864986449480057
Validation loss: 1.3473582722807442

Epoch: 6| Step: 9
Training loss: 0.060879506170749664
Validation loss: 1.3651379590393395

Epoch: 6| Step: 10
Training loss: 0.09317681193351746
Validation loss: 1.3439741044916131

Epoch: 6| Step: 11
Training loss: 0.11201970279216766
Validation loss: 1.3719506295778419

Epoch: 6| Step: 12
Training loss: 0.056072454899549484
Validation loss: 1.3669171243585565

Epoch: 6| Step: 13
Training loss: 0.03079143539071083
Validation loss: 1.4145786172600203

Epoch: 723| Step: 0
Training loss: 0.033684611320495605
Validation loss: 1.4122362188113633

Epoch: 6| Step: 1
Training loss: 0.037126410752534866
Validation loss: 1.429582579161531

Epoch: 6| Step: 2
Training loss: 0.04263875633478165
Validation loss: 1.4443774838601389

Epoch: 6| Step: 3
Training loss: 0.07366371899843216
Validation loss: 1.4304194123514238

Epoch: 6| Step: 4
Training loss: 0.0618555061519146
Validation loss: 1.4368126789728801

Epoch: 6| Step: 5
Training loss: 0.07927147299051285
Validation loss: 1.4287201832699519

Epoch: 6| Step: 6
Training loss: 0.09509949386119843
Validation loss: 1.4188620871113193

Epoch: 6| Step: 7
Training loss: 0.0657808855175972
Validation loss: 1.421759836135372

Epoch: 6| Step: 8
Training loss: 0.05083104968070984
Validation loss: 1.384693439288806

Epoch: 6| Step: 9
Training loss: 0.09105512499809265
Validation loss: 1.369905888393361

Epoch: 6| Step: 10
Training loss: 0.04445694759488106
Validation loss: 1.3504991774917932

Epoch: 6| Step: 11
Training loss: 0.056591931730508804
Validation loss: 1.3608804082357755

Epoch: 6| Step: 12
Training loss: 0.05869501456618309
Validation loss: 1.3695008947003273

Epoch: 6| Step: 13
Training loss: 0.06662948429584503
Validation loss: 1.3550204923076015

Epoch: 724| Step: 0
Training loss: 0.04863815754652023
Validation loss: 1.3472888283832098

Epoch: 6| Step: 1
Training loss: 0.03101593255996704
Validation loss: 1.385825655793631

Epoch: 6| Step: 2
Training loss: 0.06170334666967392
Validation loss: 1.3990801950936675

Epoch: 6| Step: 3
Training loss: 0.05774005129933357
Validation loss: 1.4059306267769105

Epoch: 6| Step: 4
Training loss: 0.04795894771814346
Validation loss: 1.4085956837541314

Epoch: 6| Step: 5
Training loss: 0.056418679654598236
Validation loss: 1.4446400532158472

Epoch: 6| Step: 6
Training loss: 0.0776863545179367
Validation loss: 1.4263272247006815

Epoch: 6| Step: 7
Training loss: 0.03873181343078613
Validation loss: 1.4177775229177167

Epoch: 6| Step: 8
Training loss: 0.08441157639026642
Validation loss: 1.3980541447157502

Epoch: 6| Step: 9
Training loss: 0.07022644579410553
Validation loss: 1.416826190487031

Epoch: 6| Step: 10
Training loss: 0.04651796072721481
Validation loss: 1.39600730839596

Epoch: 6| Step: 11
Training loss: 0.06306571513414383
Validation loss: 1.400213676114236

Epoch: 6| Step: 12
Training loss: 0.04961783438920975
Validation loss: 1.411723885484921

Epoch: 6| Step: 13
Training loss: 0.050953831523656845
Validation loss: 1.406535658785092

Epoch: 725| Step: 0
Training loss: 0.042939409613609314
Validation loss: 1.4008664302928473

Epoch: 6| Step: 1
Training loss: 0.05267702043056488
Validation loss: 1.4185856875552927

Epoch: 6| Step: 2
Training loss: 0.08648224174976349
Validation loss: 1.4075253317433019

Epoch: 6| Step: 3
Training loss: 0.09754358232021332
Validation loss: 1.4167521281908917

Epoch: 6| Step: 4
Training loss: 0.07045631110668182
Validation loss: 1.4171591548509495

Epoch: 6| Step: 5
Training loss: 0.03760509192943573
Validation loss: 1.3943351276459233

Epoch: 6| Step: 6
Training loss: 0.03424327075481415
Validation loss: 1.4134249136012087

Epoch: 6| Step: 7
Training loss: 0.08748408406972885
Validation loss: 1.401686704286965

Epoch: 6| Step: 8
Training loss: 0.08115127682685852
Validation loss: 1.3880776654007614

Epoch: 6| Step: 9
Training loss: 0.09747233241796494
Validation loss: 1.4379622128701979

Epoch: 6| Step: 10
Training loss: 0.06355170160531998
Validation loss: 1.4117640897791872

Epoch: 6| Step: 11
Training loss: 0.08845341205596924
Validation loss: 1.429283825300073

Epoch: 6| Step: 12
Training loss: 0.055731114000082016
Validation loss: 1.4164091079465804

Epoch: 6| Step: 13
Training loss: 0.06991123408079147
Validation loss: 1.4085838845981065

Epoch: 726| Step: 0
Training loss: 0.05509613826870918
Validation loss: 1.3798962363632776

Epoch: 6| Step: 1
Training loss: 0.06254872679710388
Validation loss: 1.3899129744498961

Epoch: 6| Step: 2
Training loss: 0.09465682506561279
Validation loss: 1.378514475078993

Epoch: 6| Step: 3
Training loss: 0.081027090549469
Validation loss: 1.3615242896541473

Epoch: 6| Step: 4
Training loss: 0.03335513174533844
Validation loss: 1.385675241870265

Epoch: 6| Step: 5
Training loss: 0.08497326076030731
Validation loss: 1.3827252375182284

Epoch: 6| Step: 6
Training loss: 0.07507859170436859
Validation loss: 1.3866066099495016

Epoch: 6| Step: 7
Training loss: 0.07640819996595383
Validation loss: 1.3908782389856154

Epoch: 6| Step: 8
Training loss: 0.04124578833580017
Validation loss: 1.4103574893807853

Epoch: 6| Step: 9
Training loss: 0.07558022439479828
Validation loss: 1.3726970611080047

Epoch: 6| Step: 10
Training loss: 0.06654126942157745
Validation loss: 1.3987578550974529

Epoch: 6| Step: 11
Training loss: 0.0826142206788063
Validation loss: 1.3994748451376473

Epoch: 6| Step: 12
Training loss: 0.0673520565032959
Validation loss: 1.3841350847674954

Epoch: 6| Step: 13
Training loss: 0.0544220432639122
Validation loss: 1.4127872464477376

Epoch: 727| Step: 0
Training loss: 0.04859431833028793
Validation loss: 1.3915026187896729

Epoch: 6| Step: 1
Training loss: 0.10846716910600662
Validation loss: 1.3959778297332026

Epoch: 6| Step: 2
Training loss: 0.034590184688568115
Validation loss: 1.4034301439921062

Epoch: 6| Step: 3
Training loss: 0.09436450898647308
Validation loss: 1.3896337157936507

Epoch: 6| Step: 4
Training loss: 0.09537991881370544
Validation loss: 1.3877949086568688

Epoch: 6| Step: 5
Training loss: 0.09122360497713089
Validation loss: 1.3978955489332958

Epoch: 6| Step: 6
Training loss: 0.055036745965480804
Validation loss: 1.4124617179234822

Epoch: 6| Step: 7
Training loss: 0.05698095262050629
Validation loss: 1.4233131806055705

Epoch: 6| Step: 8
Training loss: 0.05929780378937721
Validation loss: 1.4351745895160142

Epoch: 6| Step: 9
Training loss: 0.03970547765493393
Validation loss: 1.4195446410486776

Epoch: 6| Step: 10
Training loss: 0.03760745748877525
Validation loss: 1.44267249748271

Epoch: 6| Step: 11
Training loss: 0.06067425012588501
Validation loss: 1.44204568734733

Epoch: 6| Step: 12
Training loss: 0.08099400997161865
Validation loss: 1.4660003005817372

Epoch: 6| Step: 13
Training loss: 0.054491810500621796
Validation loss: 1.475425733033047

Epoch: 728| Step: 0
Training loss: 0.059909041970968246
Validation loss: 1.4764712638752435

Epoch: 6| Step: 1
Training loss: 0.05762006342411041
Validation loss: 1.4460304257690266

Epoch: 6| Step: 2
Training loss: 0.07282004505395889
Validation loss: 1.4480828123707925

Epoch: 6| Step: 3
Training loss: 0.04402598738670349
Validation loss: 1.4232194090402255

Epoch: 6| Step: 4
Training loss: 0.07377199828624725
Validation loss: 1.4134475672116844

Epoch: 6| Step: 5
Training loss: 0.05210711061954498
Validation loss: 1.3926572235681678

Epoch: 6| Step: 6
Training loss: 0.04619074612855911
Validation loss: 1.3989126400281024

Epoch: 6| Step: 7
Training loss: 0.06399950385093689
Validation loss: 1.3906459013621013

Epoch: 6| Step: 8
Training loss: 0.07250675559043884
Validation loss: 1.3911194096329391

Epoch: 6| Step: 9
Training loss: 0.06028825417160988
Validation loss: 1.4038710517268027

Epoch: 6| Step: 10
Training loss: 0.0519196018576622
Validation loss: 1.4114026651587537

Epoch: 6| Step: 11
Training loss: 0.08059278130531311
Validation loss: 1.4323627974397393

Epoch: 6| Step: 12
Training loss: 0.05353083461523056
Validation loss: 1.4188609616730803

Epoch: 6| Step: 13
Training loss: 0.04200155287981033
Validation loss: 1.42240995489141

Epoch: 729| Step: 0
Training loss: 0.07230457663536072
Validation loss: 1.4006459994982647

Epoch: 6| Step: 1
Training loss: 0.05451120436191559
Validation loss: 1.4289675951004028

Epoch: 6| Step: 2
Training loss: 0.019764326512813568
Validation loss: 1.3959397821016208

Epoch: 6| Step: 3
Training loss: 0.06217881292104721
Validation loss: 1.3973189528270433

Epoch: 6| Step: 4
Training loss: 0.04209987074136734
Validation loss: 1.3754939199775778

Epoch: 6| Step: 5
Training loss: 0.05009305849671364
Validation loss: 1.3903951978170743

Epoch: 6| Step: 6
Training loss: 0.02301032654941082
Validation loss: 1.3975177067582325

Epoch: 6| Step: 7
Training loss: 0.07046131789684296
Validation loss: 1.3904451401002946

Epoch: 6| Step: 8
Training loss: 0.05070243030786514
Validation loss: 1.4099651408451859

Epoch: 6| Step: 9
Training loss: 0.04993852600455284
Validation loss: 1.4151925233102614

Epoch: 6| Step: 10
Training loss: 0.07053859531879425
Validation loss: 1.4059753469241563

Epoch: 6| Step: 11
Training loss: 0.04417882859706879
Validation loss: 1.401270216511142

Epoch: 6| Step: 12
Training loss: 0.05997632443904877
Validation loss: 1.3937142818204817

Epoch: 6| Step: 13
Training loss: 0.09354759752750397
Validation loss: 1.4090183434947845

Epoch: 730| Step: 0
Training loss: 0.03248438984155655
Validation loss: 1.395084100384866

Epoch: 6| Step: 1
Training loss: 0.042263489216566086
Validation loss: 1.433991684708544

Epoch: 6| Step: 2
Training loss: 0.038600604981184006
Validation loss: 1.4196701613805627

Epoch: 6| Step: 3
Training loss: 0.04191076010465622
Validation loss: 1.3925147691080648

Epoch: 6| Step: 4
Training loss: 0.09908106923103333
Validation loss: 1.4001166153979558

Epoch: 6| Step: 5
Training loss: 0.0360516756772995
Validation loss: 1.3721695369289768

Epoch: 6| Step: 6
Training loss: 0.06887982785701752
Validation loss: 1.3557731079798874

Epoch: 6| Step: 7
Training loss: 0.04205131158232689
Validation loss: 1.346079009835438

Epoch: 6| Step: 8
Training loss: 0.07203401625156403
Validation loss: 1.3478768794767317

Epoch: 6| Step: 9
Training loss: 0.04401272535324097
Validation loss: 1.367827779503279

Epoch: 6| Step: 10
Training loss: 0.08120352774858475
Validation loss: 1.3583663971193376

Epoch: 6| Step: 11
Training loss: 0.049536414444446564
Validation loss: 1.3547267170362576

Epoch: 6| Step: 12
Training loss: 0.06518645584583282
Validation loss: 1.3562252559969503

Epoch: 6| Step: 13
Training loss: 0.02593124844133854
Validation loss: 1.3670977559140933

Epoch: 731| Step: 0
Training loss: 0.06119263172149658
Validation loss: 1.372189239789081

Epoch: 6| Step: 1
Training loss: 0.039391811937093735
Validation loss: 1.3913226653170843

Epoch: 6| Step: 2
Training loss: 0.06776460260152817
Validation loss: 1.365809089394026

Epoch: 6| Step: 3
Training loss: 0.08563284575939178
Validation loss: 1.3908064102613797

Epoch: 6| Step: 4
Training loss: 0.06638310849666595
Validation loss: 1.404112244165072

Epoch: 6| Step: 5
Training loss: 0.05338059365749359
Validation loss: 1.3786701848430019

Epoch: 6| Step: 6
Training loss: 0.07085833698511124
Validation loss: 1.3934736585104337

Epoch: 6| Step: 7
Training loss: 0.06369476020336151
Validation loss: 1.3884100606364589

Epoch: 6| Step: 8
Training loss: 0.04189252480864525
Validation loss: 1.3883001362123797

Epoch: 6| Step: 9
Training loss: 0.03689571097493172
Validation loss: 1.3609303947417968

Epoch: 6| Step: 10
Training loss: 0.06366579234600067
Validation loss: 1.368066010936614

Epoch: 6| Step: 11
Training loss: 0.07249454408884048
Validation loss: 1.374830658717822

Epoch: 6| Step: 12
Training loss: 0.043786969035863876
Validation loss: 1.3766320097830989

Epoch: 6| Step: 13
Training loss: 0.10231524705886841
Validation loss: 1.3792096837874381

Epoch: 732| Step: 0
Training loss: 0.04714129865169525
Validation loss: 1.3748341247599611

Epoch: 6| Step: 1
Training loss: 0.048456475138664246
Validation loss: 1.3871728374112038

Epoch: 6| Step: 2
Training loss: 0.05439745634794235
Validation loss: 1.3944381385721185

Epoch: 6| Step: 3
Training loss: 0.06798907369375229
Validation loss: 1.3859703950984503

Epoch: 6| Step: 4
Training loss: 0.06988918781280518
Validation loss: 1.3889251050128733

Epoch: 6| Step: 5
Training loss: 0.05213576927781105
Validation loss: 1.3836088712497423

Epoch: 6| Step: 6
Training loss: 0.040877170860767365
Validation loss: 1.3519400486382105

Epoch: 6| Step: 7
Training loss: 0.05031673610210419
Validation loss: 1.3552758206603348

Epoch: 6| Step: 8
Training loss: 0.06823540478944778
Validation loss: 1.359857145176139

Epoch: 6| Step: 9
Training loss: 0.030558589845895767
Validation loss: 1.3794999725075179

Epoch: 6| Step: 10
Training loss: 0.03933413326740265
Validation loss: 1.3576628802925028

Epoch: 6| Step: 11
Training loss: 0.034333519637584686
Validation loss: 1.344362203792859

Epoch: 6| Step: 12
Training loss: 0.06781858205795288
Validation loss: 1.3404521314046716

Epoch: 6| Step: 13
Training loss: 0.08355727791786194
Validation loss: 1.358382095572769

Epoch: 733| Step: 0
Training loss: 0.04717160761356354
Validation loss: 1.3499967423818444

Epoch: 6| Step: 1
Training loss: 0.03664711117744446
Validation loss: 1.3798495223445277

Epoch: 6| Step: 2
Training loss: 0.06011222302913666
Validation loss: 1.3802938384394492

Epoch: 6| Step: 3
Training loss: 0.04847833514213562
Validation loss: 1.3845248824806624

Epoch: 6| Step: 4
Training loss: 0.05048421025276184
Validation loss: 1.4042688441532913

Epoch: 6| Step: 5
Training loss: 0.05530763417482376
Validation loss: 1.3950154704432334

Epoch: 6| Step: 6
Training loss: 0.05575944483280182
Validation loss: 1.396438047450076

Epoch: 6| Step: 7
Training loss: 0.08575336635112762
Validation loss: 1.3864181708264094

Epoch: 6| Step: 8
Training loss: 0.052811555564403534
Validation loss: 1.3623105364461099

Epoch: 6| Step: 9
Training loss: 0.08167164772748947
Validation loss: 1.36722299937279

Epoch: 6| Step: 10
Training loss: 0.06701595336198807
Validation loss: 1.3743493467248895

Epoch: 6| Step: 11
Training loss: 0.033463116735219955
Validation loss: 1.3681384049436098

Epoch: 6| Step: 12
Training loss: 0.05988447368144989
Validation loss: 1.3780936246277184

Epoch: 6| Step: 13
Training loss: 0.030621925368905067
Validation loss: 1.3909296579258417

Epoch: 734| Step: 0
Training loss: 0.07656845450401306
Validation loss: 1.3622286601733136

Epoch: 6| Step: 1
Training loss: 0.03576353192329407
Validation loss: 1.3740889795364872

Epoch: 6| Step: 2
Training loss: 0.0418429896235466
Validation loss: 1.3927188304162794

Epoch: 6| Step: 3
Training loss: 0.0647636204957962
Validation loss: 1.3795083774033414

Epoch: 6| Step: 4
Training loss: 0.048268333077430725
Validation loss: 1.3778913328724522

Epoch: 6| Step: 5
Training loss: 0.044148121029138565
Validation loss: 1.3784793250022396

Epoch: 6| Step: 6
Training loss: 0.04935062676668167
Validation loss: 1.3697799136561732

Epoch: 6| Step: 7
Training loss: 0.04650433734059334
Validation loss: 1.3832451790891669

Epoch: 6| Step: 8
Training loss: 0.023542102426290512
Validation loss: 1.4092278198529316

Epoch: 6| Step: 9
Training loss: 0.03363539278507233
Validation loss: 1.4107208405771563

Epoch: 6| Step: 10
Training loss: 0.050306208431720734
Validation loss: 1.3881864035001366

Epoch: 6| Step: 11
Training loss: 0.03955012559890747
Validation loss: 1.4206226525768157

Epoch: 6| Step: 12
Training loss: 0.06748973578214645
Validation loss: 1.4424483692774208

Epoch: 6| Step: 13
Training loss: 0.027163080871105194
Validation loss: 1.4295701903681601

Epoch: 735| Step: 0
Training loss: 0.09115396440029144
Validation loss: 1.4572932630456903

Epoch: 6| Step: 1
Training loss: 0.05004369467496872
Validation loss: 1.4364337741687734

Epoch: 6| Step: 2
Training loss: 0.05041653290390968
Validation loss: 1.4140471412289528

Epoch: 6| Step: 3
Training loss: 0.03817417100071907
Validation loss: 1.397050546061608

Epoch: 6| Step: 4
Training loss: 0.02837645821273327
Validation loss: 1.3890184715229978

Epoch: 6| Step: 5
Training loss: 0.11692694574594498
Validation loss: 1.3801701235514816

Epoch: 6| Step: 6
Training loss: 0.0911724641919136
Validation loss: 1.4018725643875778

Epoch: 6| Step: 7
Training loss: 0.05929085612297058
Validation loss: 1.3676203079121088

Epoch: 6| Step: 8
Training loss: 0.043339863419532776
Validation loss: 1.4043049581589238

Epoch: 6| Step: 9
Training loss: 0.02978966012597084
Validation loss: 1.3896649140183643

Epoch: 6| Step: 10
Training loss: 0.06368120014667511
Validation loss: 1.4336151397356423

Epoch: 6| Step: 11
Training loss: 0.053298309445381165
Validation loss: 1.4178196422515377

Epoch: 6| Step: 12
Training loss: 0.07245232909917831
Validation loss: 1.4255754960480558

Epoch: 6| Step: 13
Training loss: 0.08800806105136871
Validation loss: 1.4309163029475878

Epoch: 736| Step: 0
Training loss: 0.05950090289115906
Validation loss: 1.4483730498180594

Epoch: 6| Step: 1
Training loss: 0.08044852316379547
Validation loss: 1.434245260812903

Epoch: 6| Step: 2
Training loss: 0.09198504686355591
Validation loss: 1.4254212084636892

Epoch: 6| Step: 3
Training loss: 0.03586124628782272
Validation loss: 1.408360376152941

Epoch: 6| Step: 4
Training loss: 0.03992925211787224
Validation loss: 1.3959649570526615

Epoch: 6| Step: 5
Training loss: 0.0681258887052536
Validation loss: 1.3779565057446879

Epoch: 6| Step: 6
Training loss: 0.045739952474832535
Validation loss: 1.3664647097228675

Epoch: 6| Step: 7
Training loss: 0.059782806783914566
Validation loss: 1.3558356076158502

Epoch: 6| Step: 8
Training loss: 0.08772183954715729
Validation loss: 1.3631675397196124

Epoch: 6| Step: 9
Training loss: 0.1038919985294342
Validation loss: 1.3655022716009488

Epoch: 6| Step: 10
Training loss: 0.07638633251190186
Validation loss: 1.344031632587474

Epoch: 6| Step: 11
Training loss: 0.06890334188938141
Validation loss: 1.3573050216961933

Epoch: 6| Step: 12
Training loss: 0.03909201920032501
Validation loss: 1.3655603162703975

Epoch: 6| Step: 13
Training loss: 0.06283333152532578
Validation loss: 1.371649133261814

Epoch: 737| Step: 0
Training loss: 0.08467239141464233
Validation loss: 1.3989971042961202

Epoch: 6| Step: 1
Training loss: 0.05783793330192566
Validation loss: 1.397062566972548

Epoch: 6| Step: 2
Training loss: 0.07443706691265106
Validation loss: 1.4472132626400198

Epoch: 6| Step: 3
Training loss: 0.08402611315250397
Validation loss: 1.4506037312169229

Epoch: 6| Step: 4
Training loss: 0.0624304860830307
Validation loss: 1.4372450062023696

Epoch: 6| Step: 5
Training loss: 0.09158928692340851
Validation loss: 1.4299883419467556

Epoch: 6| Step: 6
Training loss: 0.07811962068080902
Validation loss: 1.420288303846954

Epoch: 6| Step: 7
Training loss: 0.07402463257312775
Validation loss: 1.4124972294735652

Epoch: 6| Step: 8
Training loss: 0.05624176561832428
Validation loss: 1.3750207731800694

Epoch: 6| Step: 9
Training loss: 0.03829742223024368
Validation loss: 1.3625101684242167

Epoch: 6| Step: 10
Training loss: 0.06674158573150635
Validation loss: 1.348370526426582

Epoch: 6| Step: 11
Training loss: 0.06884931772947311
Validation loss: 1.3427199445744997

Epoch: 6| Step: 12
Training loss: 0.05220073461532593
Validation loss: 1.349056689969955

Epoch: 6| Step: 13
Training loss: 0.053688786923885345
Validation loss: 1.3552203883406937

Epoch: 738| Step: 0
Training loss: 0.06695453822612762
Validation loss: 1.359878557984547

Epoch: 6| Step: 1
Training loss: 0.07593632489442825
Validation loss: 1.3671229039469073

Epoch: 6| Step: 2
Training loss: 0.07467283308506012
Validation loss: 1.4074918288056568

Epoch: 6| Step: 3
Training loss: 0.05547921359539032
Validation loss: 1.3931428649092232

Epoch: 6| Step: 4
Training loss: 0.09047970920801163
Validation loss: 1.4186569401012954

Epoch: 6| Step: 5
Training loss: 0.0395929291844368
Validation loss: 1.4335200530226513

Epoch: 6| Step: 6
Training loss: 0.04137828201055527
Validation loss: 1.4286589891679826

Epoch: 6| Step: 7
Training loss: 0.06852321326732635
Validation loss: 1.4405753676609327

Epoch: 6| Step: 8
Training loss: 0.05998056381940842
Validation loss: 1.4281558529023202

Epoch: 6| Step: 9
Training loss: 0.05779437720775604
Validation loss: 1.42315028431595

Epoch: 6| Step: 10
Training loss: 0.048475589603185654
Validation loss: 1.4203729680789414

Epoch: 6| Step: 11
Training loss: 0.04446953535079956
Validation loss: 1.3922720186171993

Epoch: 6| Step: 12
Training loss: 0.03477128595113754
Validation loss: 1.3739037090732205

Epoch: 6| Step: 13
Training loss: 0.05539613217115402
Validation loss: 1.3737600567520305

Epoch: 739| Step: 0
Training loss: 0.03707338497042656
Validation loss: 1.381597944485244

Epoch: 6| Step: 1
Training loss: 0.045102301985025406
Validation loss: 1.37609948009573

Epoch: 6| Step: 2
Training loss: 0.07237708568572998
Validation loss: 1.3554753744474022

Epoch: 6| Step: 3
Training loss: 0.0511489175260067
Validation loss: 1.3518088581741496

Epoch: 6| Step: 4
Training loss: 0.07818472385406494
Validation loss: 1.3779720875524706

Epoch: 6| Step: 5
Training loss: 0.07149126380681992
Validation loss: 1.396617329248818

Epoch: 6| Step: 6
Training loss: 0.057155147194862366
Validation loss: 1.4180107860155002

Epoch: 6| Step: 7
Training loss: 0.12600573897361755
Validation loss: 1.4179323155392882

Epoch: 6| Step: 8
Training loss: 0.061495814472436905
Validation loss: 1.4352825585231985

Epoch: 6| Step: 9
Training loss: 0.0717281922698021
Validation loss: 1.4279644720015987

Epoch: 6| Step: 10
Training loss: 0.04739198833703995
Validation loss: 1.4406651694287536

Epoch: 6| Step: 11
Training loss: 0.09573102742433548
Validation loss: 1.416866590899806

Epoch: 6| Step: 12
Training loss: 0.08122193068265915
Validation loss: 1.4451680388501895

Epoch: 6| Step: 13
Training loss: 0.05776705965399742
Validation loss: 1.4207062702025137

Epoch: 740| Step: 0
Training loss: 0.043327800929546356
Validation loss: 1.389361346921613

Epoch: 6| Step: 1
Training loss: 0.03219015896320343
Validation loss: 1.373508281605218

Epoch: 6| Step: 2
Training loss: 0.03801760822534561
Validation loss: 1.3645536797021025

Epoch: 6| Step: 3
Training loss: 0.04269871488213539
Validation loss: 1.3845559400255962

Epoch: 6| Step: 4
Training loss: 0.07311025261878967
Validation loss: 1.3674161895628898

Epoch: 6| Step: 5
Training loss: 0.015302348881959915
Validation loss: 1.3742005671224287

Epoch: 6| Step: 6
Training loss: 0.051320817321538925
Validation loss: 1.358569255439184

Epoch: 6| Step: 7
Training loss: 0.04290974140167236
Validation loss: 1.3778783672599382

Epoch: 6| Step: 8
Training loss: 0.08005554974079132
Validation loss: 1.3692478608059626

Epoch: 6| Step: 9
Training loss: 0.037962716072797775
Validation loss: 1.3688734526275306

Epoch: 6| Step: 10
Training loss: 0.12288767844438553
Validation loss: 1.3700053345772527

Epoch: 6| Step: 11
Training loss: 0.06953021883964539
Validation loss: 1.369711664415175

Epoch: 6| Step: 12
Training loss: 0.06056968495249748
Validation loss: 1.3730086139453355

Epoch: 6| Step: 13
Training loss: 0.03937024995684624
Validation loss: 1.3827659212132937

Epoch: 741| Step: 0
Training loss: 0.048594873398542404
Validation loss: 1.3931348323822021

Epoch: 6| Step: 1
Training loss: 0.09768008440732956
Validation loss: 1.390728114753641

Epoch: 6| Step: 2
Training loss: 0.05662807077169418
Validation loss: 1.4254320821454447

Epoch: 6| Step: 3
Training loss: 0.06047946959733963
Validation loss: 1.4676027054427772

Epoch: 6| Step: 4
Training loss: 0.1084422618150711
Validation loss: 1.462901956291609

Epoch: 6| Step: 5
Training loss: 0.048628244549036026
Validation loss: 1.451013034389865

Epoch: 6| Step: 6
Training loss: 0.06579230725765228
Validation loss: 1.4529187576745146

Epoch: 6| Step: 7
Training loss: 0.061679717153310776
Validation loss: 1.4230621335326985

Epoch: 6| Step: 8
Training loss: 0.07251375168561935
Validation loss: 1.4427811996911162

Epoch: 6| Step: 9
Training loss: 0.07915543764829636
Validation loss: 1.413143829632831

Epoch: 6| Step: 10
Training loss: 0.07425888627767563
Validation loss: 1.39480770275157

Epoch: 6| Step: 11
Training loss: 0.028446469455957413
Validation loss: 1.3857795320531374

Epoch: 6| Step: 12
Training loss: 0.05798907205462456
Validation loss: 1.3789805635329215

Epoch: 6| Step: 13
Training loss: 0.03214577957987785
Validation loss: 1.3854363861904349

Epoch: 742| Step: 0
Training loss: 0.03659588843584061
Validation loss: 1.3625349203745525

Epoch: 6| Step: 1
Training loss: 0.0753822848200798
Validation loss: 1.367379512838138

Epoch: 6| Step: 2
Training loss: 0.0393863171339035
Validation loss: 1.3631312501045965

Epoch: 6| Step: 3
Training loss: 0.01782384142279625
Validation loss: 1.3701607129907096

Epoch: 6| Step: 4
Training loss: 0.03996816650032997
Validation loss: 1.3756561535660938

Epoch: 6| Step: 5
Training loss: 0.070354163646698
Validation loss: 1.3775074610146143

Epoch: 6| Step: 6
Training loss: 0.04708098620176315
Validation loss: 1.382010599618317

Epoch: 6| Step: 7
Training loss: 0.036871135234832764
Validation loss: 1.3652235333637526

Epoch: 6| Step: 8
Training loss: 0.023712120950222015
Validation loss: 1.375072467711664

Epoch: 6| Step: 9
Training loss: 0.07096011191606522
Validation loss: 1.3706666423428444

Epoch: 6| Step: 10
Training loss: 0.05312511697411537
Validation loss: 1.4015850161993375

Epoch: 6| Step: 11
Training loss: 0.05916178971529007
Validation loss: 1.3734500446627218

Epoch: 6| Step: 12
Training loss: 0.05509500205516815
Validation loss: 1.3980340816641366

Epoch: 6| Step: 13
Training loss: 0.027189109474420547
Validation loss: 1.3933866421381633

Epoch: 743| Step: 0
Training loss: 0.030223006382584572
Validation loss: 1.368672537547286

Epoch: 6| Step: 1
Training loss: 0.08235660195350647
Validation loss: 1.3741343123938448

Epoch: 6| Step: 2
Training loss: 0.04968053847551346
Validation loss: 1.369925324634839

Epoch: 6| Step: 3
Training loss: 0.07328294217586517
Validation loss: 1.3573888501813334

Epoch: 6| Step: 4
Training loss: 0.027891412377357483
Validation loss: 1.3517692114717217

Epoch: 6| Step: 5
Training loss: 0.04107324779033661
Validation loss: 1.3383854358426985

Epoch: 6| Step: 6
Training loss: 0.04781394824385643
Validation loss: 1.3085790731573617

Epoch: 6| Step: 7
Training loss: 0.06763163208961487
Validation loss: 1.3387054794578142

Epoch: 6| Step: 8
Training loss: 0.05161089450120926
Validation loss: 1.326322772810536

Epoch: 6| Step: 9
Training loss: 0.0553254596889019
Validation loss: 1.3342237081578983

Epoch: 6| Step: 10
Training loss: 0.03893665224313736
Validation loss: 1.3408620344695223

Epoch: 6| Step: 11
Training loss: 0.05211614817380905
Validation loss: 1.3568353941363673

Epoch: 6| Step: 12
Training loss: 0.049452319741249084
Validation loss: 1.3545240227894118

Epoch: 6| Step: 13
Training loss: 0.057475049048662186
Validation loss: 1.3452291322010819

Epoch: 744| Step: 0
Training loss: 0.03567294031381607
Validation loss: 1.3797790414543563

Epoch: 6| Step: 1
Training loss: 0.03188978135585785
Validation loss: 1.397214517798475

Epoch: 6| Step: 2
Training loss: 0.0577382892370224
Validation loss: 1.3810546564799484

Epoch: 6| Step: 3
Training loss: 0.0427238866686821
Validation loss: 1.3842820454669256

Epoch: 6| Step: 4
Training loss: 0.06766478717327118
Validation loss: 1.388235289563415

Epoch: 6| Step: 5
Training loss: 0.0752888172864914
Validation loss: 1.4130826355308614

Epoch: 6| Step: 6
Training loss: 0.0886847972869873
Validation loss: 1.4021587653826642

Epoch: 6| Step: 7
Training loss: 0.07057620584964752
Validation loss: 1.4242770979481358

Epoch: 6| Step: 8
Training loss: 0.057484276592731476
Validation loss: 1.4269847023871638

Epoch: 6| Step: 9
Training loss: 0.05374593287706375
Validation loss: 1.4462980608786307

Epoch: 6| Step: 10
Training loss: 0.02714613825082779
Validation loss: 1.4206612263956377

Epoch: 6| Step: 11
Training loss: 0.07323990762233734
Validation loss: 1.4195562062724945

Epoch: 6| Step: 12
Training loss: 0.0623227134346962
Validation loss: 1.4275246948324225

Epoch: 6| Step: 13
Training loss: 0.03686891496181488
Validation loss: 1.4258075837166078

Epoch: 745| Step: 0
Training loss: 0.051519572734832764
Validation loss: 1.4297120084044754

Epoch: 6| Step: 1
Training loss: 0.04485509172081947
Validation loss: 1.4302583689330726

Epoch: 6| Step: 2
Training loss: 0.0828094333410263
Validation loss: 1.3974838667018439

Epoch: 6| Step: 3
Training loss: 0.06123345345258713
Validation loss: 1.4155770642783052

Epoch: 6| Step: 4
Training loss: 0.06383837759494781
Validation loss: 1.419437462283719

Epoch: 6| Step: 5
Training loss: 0.037918590009212494
Validation loss: 1.4121941238321283

Epoch: 6| Step: 6
Training loss: 0.03493722900748253
Validation loss: 1.399220219222448

Epoch: 6| Step: 7
Training loss: 0.06504551321268082
Validation loss: 1.4130577246348064

Epoch: 6| Step: 8
Training loss: 0.07171346247196198
Validation loss: 1.3888821973595569

Epoch: 6| Step: 9
Training loss: 0.03802448511123657
Validation loss: 1.3986530534682735

Epoch: 6| Step: 10
Training loss: 0.03522711992263794
Validation loss: 1.4108036897515739

Epoch: 6| Step: 11
Training loss: 0.0563424751162529
Validation loss: 1.399431154292117

Epoch: 6| Step: 12
Training loss: 0.06840258091688156
Validation loss: 1.3742595744389359

Epoch: 6| Step: 13
Training loss: 0.0858626738190651
Validation loss: 1.3946761033868278

Epoch: 746| Step: 0
Training loss: 0.036373548209667206
Validation loss: 1.378437981810621

Epoch: 6| Step: 1
Training loss: 0.05721963942050934
Validation loss: 1.3922095888404435

Epoch: 6| Step: 2
Training loss: 0.022743886336684227
Validation loss: 1.3984601613013976

Epoch: 6| Step: 3
Training loss: 0.03998635709285736
Validation loss: 1.4126016760385165

Epoch: 6| Step: 4
Training loss: 0.024593111127614975
Validation loss: 1.3845530985504069

Epoch: 6| Step: 5
Training loss: 0.05315018445253372
Validation loss: 1.3760271508206603

Epoch: 6| Step: 6
Training loss: 0.04257670044898987
Validation loss: 1.3855635504568777

Epoch: 6| Step: 7
Training loss: 0.042359352111816406
Validation loss: 1.3890329176379788

Epoch: 6| Step: 8
Training loss: 0.03608722984790802
Validation loss: 1.3958796865196639

Epoch: 6| Step: 9
Training loss: 0.06699454039335251
Validation loss: 1.3788252210104337

Epoch: 6| Step: 10
Training loss: 0.056821342557668686
Validation loss: 1.3775499277217413

Epoch: 6| Step: 11
Training loss: 0.07959111034870148
Validation loss: 1.3660302700534943

Epoch: 6| Step: 12
Training loss: 0.04524559527635574
Validation loss: 1.3881648086732434

Epoch: 6| Step: 13
Training loss: 0.07903987169265747
Validation loss: 1.3734466145115514

Epoch: 747| Step: 0
Training loss: 0.05853084474802017
Validation loss: 1.3708157001003143

Epoch: 6| Step: 1
Training loss: 0.07290848344564438
Validation loss: 1.3561288913091023

Epoch: 6| Step: 2
Training loss: 0.04747048765420914
Validation loss: 1.3573654723423783

Epoch: 6| Step: 3
Training loss: 0.05567189306020737
Validation loss: 1.3600075449994815

Epoch: 6| Step: 4
Training loss: 0.04090587794780731
Validation loss: 1.3544336672752135

Epoch: 6| Step: 5
Training loss: 0.02778535708785057
Validation loss: 1.358393419173456

Epoch: 6| Step: 6
Training loss: 0.024571584537625313
Validation loss: 1.3529605788569297

Epoch: 6| Step: 7
Training loss: 0.06175532937049866
Validation loss: 1.3765567900032125

Epoch: 6| Step: 8
Training loss: 0.0749688595533371
Validation loss: 1.3806099763480566

Epoch: 6| Step: 9
Training loss: 0.05551101639866829
Validation loss: 1.4000089771004134

Epoch: 6| Step: 10
Training loss: 0.06659361720085144
Validation loss: 1.3958807978578793

Epoch: 6| Step: 11
Training loss: 0.04292075335979462
Validation loss: 1.4182771623775523

Epoch: 6| Step: 12
Training loss: 0.09362684190273285
Validation loss: 1.4230407059833567

Epoch: 6| Step: 13
Training loss: 0.022392870858311653
Validation loss: 1.4381014288112681

Epoch: 748| Step: 0
Training loss: 0.0936562642455101
Validation loss: 1.465994215780689

Epoch: 6| Step: 1
Training loss: 0.05034025385975838
Validation loss: 1.4490243786124772

Epoch: 6| Step: 2
Training loss: 0.046999722719192505
Validation loss: 1.4407790425003215

Epoch: 6| Step: 3
Training loss: 0.06750160455703735
Validation loss: 1.4464460380615727

Epoch: 6| Step: 4
Training loss: 0.05316951125860214
Validation loss: 1.4102815440905991

Epoch: 6| Step: 5
Training loss: 0.09068148583173752
Validation loss: 1.3926833034843527

Epoch: 6| Step: 6
Training loss: 0.10663732141256332
Validation loss: 1.3987997667763823

Epoch: 6| Step: 7
Training loss: 0.055310025811195374
Validation loss: 1.3804084806032078

Epoch: 6| Step: 8
Training loss: 0.05233730375766754
Validation loss: 1.3471672291396766

Epoch: 6| Step: 9
Training loss: 0.07767036557197571
Validation loss: 1.347376319669908

Epoch: 6| Step: 10
Training loss: 0.044815801084041595
Validation loss: 1.3705615933223436

Epoch: 6| Step: 11
Training loss: 0.058690864592790604
Validation loss: 1.3580203940791469

Epoch: 6| Step: 12
Training loss: 0.06115669757127762
Validation loss: 1.3631386205714235

Epoch: 6| Step: 13
Training loss: 0.14722813665866852
Validation loss: 1.3837059108159875

Epoch: 749| Step: 0
Training loss: 0.07588841021060944
Validation loss: 1.400531796998875

Epoch: 6| Step: 1
Training loss: 0.04353362321853638
Validation loss: 1.3982928119679934

Epoch: 6| Step: 2
Training loss: 0.0641944482922554
Validation loss: 1.412897075376203

Epoch: 6| Step: 3
Training loss: 0.07268449664115906
Validation loss: 1.40825048441528

Epoch: 6| Step: 4
Training loss: 0.04900910705327988
Validation loss: 1.40980141521782

Epoch: 6| Step: 5
Training loss: 0.033997006714344025
Validation loss: 1.3891505015793668

Epoch: 6| Step: 6
Training loss: 0.0620705746114254
Validation loss: 1.3767088215838197

Epoch: 6| Step: 7
Training loss: 0.03935149312019348
Validation loss: 1.3564444459894651

Epoch: 6| Step: 8
Training loss: 0.059403419494628906
Validation loss: 1.3418624593365578

Epoch: 6| Step: 9
Training loss: 0.0664421021938324
Validation loss: 1.3261991649545648

Epoch: 6| Step: 10
Training loss: 0.05152487754821777
Validation loss: 1.3426145110079037

Epoch: 6| Step: 11
Training loss: 0.0812356248497963
Validation loss: 1.3451290489524923

Epoch: 6| Step: 12
Training loss: 0.054882440716028214
Validation loss: 1.3398472621876707

Epoch: 6| Step: 13
Training loss: 0.07623711973428726
Validation loss: 1.3822333261530886

Epoch: 750| Step: 0
Training loss: 0.04235660657286644
Validation loss: 1.4110009054983816

Epoch: 6| Step: 1
Training loss: 0.09554670751094818
Validation loss: 1.4161800517830798

Epoch: 6| Step: 2
Training loss: 0.07435458898544312
Validation loss: 1.436016623691846

Epoch: 6| Step: 3
Training loss: 0.10306423902511597
Validation loss: 1.461125345640285

Epoch: 6| Step: 4
Training loss: 0.07570450752973557
Validation loss: 1.4662993377254856

Epoch: 6| Step: 5
Training loss: 0.044306494295597076
Validation loss: 1.4541202540038733

Epoch: 6| Step: 6
Training loss: 0.04200850427150726
Validation loss: 1.4551003812461771

Epoch: 6| Step: 7
Training loss: 0.05710434541106224
Validation loss: 1.4213727392176145

Epoch: 6| Step: 8
Training loss: 0.05197300761938095
Validation loss: 1.395713149860341

Epoch: 6| Step: 9
Training loss: 0.062283240258693695
Validation loss: 1.3786642897513606

Epoch: 6| Step: 10
Training loss: 0.07318924367427826
Validation loss: 1.3967994964250954

Epoch: 6| Step: 11
Training loss: 0.06138388812541962
Validation loss: 1.3967412787099038

Epoch: 6| Step: 12
Training loss: 0.07630496472120285
Validation loss: 1.3946596678867136

Epoch: 6| Step: 13
Training loss: 0.1093122661113739
Validation loss: 1.3629247744878132

Epoch: 751| Step: 0
Training loss: 0.066942498087883
Validation loss: 1.387127080271321

Epoch: 6| Step: 1
Training loss: 0.10372990369796753
Validation loss: 1.3964410616505532

Epoch: 6| Step: 2
Training loss: 0.06400550901889801
Validation loss: 1.389083989204899

Epoch: 6| Step: 3
Training loss: 0.053623661398887634
Validation loss: 1.3893624544143677

Epoch: 6| Step: 4
Training loss: 0.10180622339248657
Validation loss: 1.4132202133055656

Epoch: 6| Step: 5
Training loss: 0.0674503967165947
Validation loss: 1.4120791266041417

Epoch: 6| Step: 6
Training loss: 0.07472807168960571
Validation loss: 1.4025690286390242

Epoch: 6| Step: 7
Training loss: 0.06255540251731873
Validation loss: 1.4098325070514475

Epoch: 6| Step: 8
Training loss: 0.07375256717205048
Validation loss: 1.414159954235118

Epoch: 6| Step: 9
Training loss: 0.10111586004495621
Validation loss: 1.4008372137623448

Epoch: 6| Step: 10
Training loss: 0.058717451989650726
Validation loss: 1.3960915303999377

Epoch: 6| Step: 11
Training loss: 0.053536947816610336
Validation loss: 1.3839264941471878

Epoch: 6| Step: 12
Training loss: 0.03691483289003372
Validation loss: 1.390517924421577

Epoch: 6| Step: 13
Training loss: 0.04805421084165573
Validation loss: 1.3626052051462152

Epoch: 752| Step: 0
Training loss: 0.06696785986423492
Validation loss: 1.3694984054052701

Epoch: 6| Step: 1
Training loss: 0.09165795892477036
Validation loss: 1.3780550367088729

Epoch: 6| Step: 2
Training loss: 0.0878591388463974
Validation loss: 1.352425189428432

Epoch: 6| Step: 3
Training loss: 0.027346983551979065
Validation loss: 1.3765623364397275

Epoch: 6| Step: 4
Training loss: 0.037437133491039276
Validation loss: 1.402858563007847

Epoch: 6| Step: 5
Training loss: 0.034017741680145264
Validation loss: 1.3587821850212671

Epoch: 6| Step: 6
Training loss: 0.049204081296920776
Validation loss: 1.3880870393527451

Epoch: 6| Step: 7
Training loss: 0.061860933899879456
Validation loss: 1.3726966842528312

Epoch: 6| Step: 8
Training loss: 0.09100489318370819
Validation loss: 1.4033091927087435

Epoch: 6| Step: 9
Training loss: 0.04174206405878067
Validation loss: 1.377796289741352

Epoch: 6| Step: 10
Training loss: 0.06651090085506439
Validation loss: 1.386376832121162

Epoch: 6| Step: 11
Training loss: 0.0526723712682724
Validation loss: 1.3677449739107521

Epoch: 6| Step: 12
Training loss: 0.07290017604827881
Validation loss: 1.3674619787482805

Epoch: 6| Step: 13
Training loss: 0.0706225261092186
Validation loss: 1.374780394697702

Epoch: 753| Step: 0
Training loss: 0.055228091776371
Validation loss: 1.3789987461541289

Epoch: 6| Step: 1
Training loss: 0.07493513822555542
Validation loss: 1.3951145166991858

Epoch: 6| Step: 2
Training loss: 0.06223155930638313
Validation loss: 1.3618219026955225

Epoch: 6| Step: 3
Training loss: 0.07017397880554199
Validation loss: 1.3868037539143716

Epoch: 6| Step: 4
Training loss: 0.05076714605093002
Validation loss: 1.389102848627234

Epoch: 6| Step: 5
Training loss: 0.05014185979962349
Validation loss: 1.3684364185538342

Epoch: 6| Step: 6
Training loss: 0.02843622863292694
Validation loss: 1.3765097933430825

Epoch: 6| Step: 7
Training loss: 0.04318992793560028
Validation loss: 1.359728829835051

Epoch: 6| Step: 8
Training loss: 0.03533663973212242
Validation loss: 1.3655166613158358

Epoch: 6| Step: 9
Training loss: 0.054095759987831116
Validation loss: 1.3641767405694532

Epoch: 6| Step: 10
Training loss: 0.08297054469585419
Validation loss: 1.369565725326538

Epoch: 6| Step: 11
Training loss: 0.09791791439056396
Validation loss: 1.3820197146425965

Epoch: 6| Step: 12
Training loss: 0.06234370172023773
Validation loss: 1.389913539732656

Epoch: 6| Step: 13
Training loss: 0.06274521350860596
Validation loss: 1.3841674712396437

Epoch: 754| Step: 0
Training loss: 0.0946846529841423
Validation loss: 1.4019191938061868

Epoch: 6| Step: 1
Training loss: 0.07790511101484299
Validation loss: 1.4133385971028318

Epoch: 6| Step: 2
Training loss: 0.03010866418480873
Validation loss: 1.39963670187099

Epoch: 6| Step: 3
Training loss: 0.03855990990996361
Validation loss: 1.3953471536277442

Epoch: 6| Step: 4
Training loss: 0.050663549453020096
Validation loss: 1.3570316344179132

Epoch: 6| Step: 5
Training loss: 0.06944041699171066
Validation loss: 1.3603400043261948

Epoch: 6| Step: 6
Training loss: 0.06619683653116226
Validation loss: 1.3667464179377402

Epoch: 6| Step: 7
Training loss: 0.03285232186317444
Validation loss: 1.37460373550333

Epoch: 6| Step: 8
Training loss: 0.06369680166244507
Validation loss: 1.359847814806046

Epoch: 6| Step: 9
Training loss: 0.033307142555713654
Validation loss: 1.3769496185805208

Epoch: 6| Step: 10
Training loss: 0.060639649629592896
Validation loss: 1.3983691084769465

Epoch: 6| Step: 11
Training loss: 0.034200672060251236
Validation loss: 1.356777096307406

Epoch: 6| Step: 12
Training loss: 0.0440235510468483
Validation loss: 1.368133798722298

Epoch: 6| Step: 13
Training loss: 0.03848154842853546
Validation loss: 1.3728974730737749

Epoch: 755| Step: 0
Training loss: 0.060859717428684235
Validation loss: 1.3892947409742622

Epoch: 6| Step: 1
Training loss: 0.029567942023277283
Validation loss: 1.387233926403907

Epoch: 6| Step: 2
Training loss: 0.026788845658302307
Validation loss: 1.3760623124337965

Epoch: 6| Step: 3
Training loss: 0.04250866919755936
Validation loss: 1.3848523869309375

Epoch: 6| Step: 4
Training loss: 0.04143080115318298
Validation loss: 1.3910918466506466

Epoch: 6| Step: 5
Training loss: 0.07005452364683151
Validation loss: 1.382686282998772

Epoch: 6| Step: 6
Training loss: 0.03582121431827545
Validation loss: 1.3970886545796548

Epoch: 6| Step: 7
Training loss: 0.08747095614671707
Validation loss: 1.3757877426762735

Epoch: 6| Step: 8
Training loss: 0.050051502883434296
Validation loss: 1.366614749354701

Epoch: 6| Step: 9
Training loss: 0.06311522424221039
Validation loss: 1.404364046230111

Epoch: 6| Step: 10
Training loss: 0.03902801126241684
Validation loss: 1.408658359640388

Epoch: 6| Step: 11
Training loss: 0.0928400307893753
Validation loss: 1.4079293499710739

Epoch: 6| Step: 12
Training loss: 0.05735425651073456
Validation loss: 1.4177744401398527

Epoch: 6| Step: 13
Training loss: 0.05149199441075325
Validation loss: 1.4261376396302254

Epoch: 756| Step: 0
Training loss: 0.037413809448480606
Validation loss: 1.4345411728787165

Epoch: 6| Step: 1
Training loss: 0.05025308206677437
Validation loss: 1.4446300383537047

Epoch: 6| Step: 2
Training loss: 0.05404328927397728
Validation loss: 1.4399148110420472

Epoch: 6| Step: 3
Training loss: 0.05283579230308533
Validation loss: 1.421833743331253

Epoch: 6| Step: 4
Training loss: 0.07664190232753754
Validation loss: 1.422005038107595

Epoch: 6| Step: 5
Training loss: 0.03983241319656372
Validation loss: 1.395977609901018

Epoch: 6| Step: 6
Training loss: 0.07342323660850525
Validation loss: 1.3684240387332054

Epoch: 6| Step: 7
Training loss: 0.053941525518894196
Validation loss: 1.386039149376654

Epoch: 6| Step: 8
Training loss: 0.05434281378984451
Validation loss: 1.3907276532983268

Epoch: 6| Step: 9
Training loss: 0.05688019469380379
Validation loss: 1.3669287978961904

Epoch: 6| Step: 10
Training loss: 0.08907902240753174
Validation loss: 1.349914708445149

Epoch: 6| Step: 11
Training loss: 0.047201722860336304
Validation loss: 1.376473287100433

Epoch: 6| Step: 12
Training loss: 0.02405756339430809
Validation loss: 1.3731508229368476

Epoch: 6| Step: 13
Training loss: 0.05148801580071449
Validation loss: 1.3815950244985602

Epoch: 757| Step: 0
Training loss: 0.061214253306388855
Validation loss: 1.4089345778188398

Epoch: 6| Step: 1
Training loss: 0.07177600264549255
Validation loss: 1.4420183192017257

Epoch: 6| Step: 2
Training loss: 0.07005076110363007
Validation loss: 1.440298395131224

Epoch: 6| Step: 3
Training loss: 0.053895123302936554
Validation loss: 1.4411332786724131

Epoch: 6| Step: 4
Training loss: 0.05001067370176315
Validation loss: 1.4457377746541014

Epoch: 6| Step: 5
Training loss: 0.040180057287216187
Validation loss: 1.4518768140064773

Epoch: 6| Step: 6
Training loss: 0.06990458816289902
Validation loss: 1.4291654671392133

Epoch: 6| Step: 7
Training loss: 0.0367167666554451
Validation loss: 1.429031696370853

Epoch: 6| Step: 8
Training loss: 0.06225176155567169
Validation loss: 1.4101810980868597

Epoch: 6| Step: 9
Training loss: 0.05031956732273102
Validation loss: 1.4169589037536292

Epoch: 6| Step: 10
Training loss: 0.05682186037302017
Validation loss: 1.4171062977083269

Epoch: 6| Step: 11
Training loss: 0.037759874016046524
Validation loss: 1.396506090318003

Epoch: 6| Step: 12
Training loss: 0.06748241186141968
Validation loss: 1.3782515948818577

Epoch: 6| Step: 13
Training loss: 0.022385306656360626
Validation loss: 1.3651028294717111

Epoch: 758| Step: 0
Training loss: 0.08468098938465118
Validation loss: 1.372467347370681

Epoch: 6| Step: 1
Training loss: 0.055742524564266205
Validation loss: 1.3541464267238494

Epoch: 6| Step: 2
Training loss: 0.04214521870017052
Validation loss: 1.358010543290005

Epoch: 6| Step: 3
Training loss: 0.06002649664878845
Validation loss: 1.3865871089760975

Epoch: 6| Step: 4
Training loss: 0.03508846461772919
Validation loss: 1.3682068188985188

Epoch: 6| Step: 5
Training loss: 0.044247858226299286
Validation loss: 1.3846918293224868

Epoch: 6| Step: 6
Training loss: 0.02943645790219307
Validation loss: 1.4041418734417166

Epoch: 6| Step: 7
Training loss: 0.0514412596821785
Validation loss: 1.397966819424783

Epoch: 6| Step: 8
Training loss: 0.048726435750722885
Validation loss: 1.4049865994402158

Epoch: 6| Step: 9
Training loss: 0.08140713721513748
Validation loss: 1.4193444469923615

Epoch: 6| Step: 10
Training loss: 0.03858742117881775
Validation loss: 1.4395685234377462

Epoch: 6| Step: 11
Training loss: 0.03145437687635422
Validation loss: 1.4138767257813485

Epoch: 6| Step: 12
Training loss: 0.04550160467624664
Validation loss: 1.4215877773941203

Epoch: 6| Step: 13
Training loss: 0.07956160604953766
Validation loss: 1.4495828010702645

Epoch: 759| Step: 0
Training loss: 0.030444681644439697
Validation loss: 1.4043838439449188

Epoch: 6| Step: 1
Training loss: 0.03669897839426994
Validation loss: 1.4003139285631077

Epoch: 6| Step: 2
Training loss: 0.06591425091028214
Validation loss: 1.400594634394492

Epoch: 6| Step: 3
Training loss: 0.08207747340202332
Validation loss: 1.3831137380292338

Epoch: 6| Step: 4
Training loss: 0.03476843237876892
Validation loss: 1.4039723693683583

Epoch: 6| Step: 5
Training loss: 0.03813141956925392
Validation loss: 1.3971734790391819

Epoch: 6| Step: 6
Training loss: 0.06772712618112564
Validation loss: 1.367049786352342

Epoch: 6| Step: 7
Training loss: 0.042676039040088654
Validation loss: 1.35593548897774

Epoch: 6| Step: 8
Training loss: 0.041864633560180664
Validation loss: 1.3849558702079199

Epoch: 6| Step: 9
Training loss: 0.04853595048189163
Validation loss: 1.3726398444944812

Epoch: 6| Step: 10
Training loss: 0.0381237268447876
Validation loss: 1.390198285861682

Epoch: 6| Step: 11
Training loss: 0.046197935938835144
Validation loss: 1.3609923867769138

Epoch: 6| Step: 12
Training loss: 0.07448729127645493
Validation loss: 1.392349350836969

Epoch: 6| Step: 13
Training loss: 0.04551272839307785
Validation loss: 1.3740486124510407

Epoch: 760| Step: 0
Training loss: 0.04285557568073273
Validation loss: 1.3733649702482327

Epoch: 6| Step: 1
Training loss: 0.055018335580825806
Validation loss: 1.3924058124583254

Epoch: 6| Step: 2
Training loss: 0.04113616421818733
Validation loss: 1.4001669319727088

Epoch: 6| Step: 3
Training loss: 0.03856009244918823
Validation loss: 1.394312168962212

Epoch: 6| Step: 4
Training loss: 0.024163417518138885
Validation loss: 1.3998279994533909

Epoch: 6| Step: 5
Training loss: 0.0492108017206192
Validation loss: 1.3937671428085656

Epoch: 6| Step: 6
Training loss: 0.06990795582532883
Validation loss: 1.4024277797309301

Epoch: 6| Step: 7
Training loss: 0.03449077159166336
Validation loss: 1.4019437592516664

Epoch: 6| Step: 8
Training loss: 0.050060972571372986
Validation loss: 1.3925673115637995

Epoch: 6| Step: 9
Training loss: 0.03946808725595474
Validation loss: 1.399494186524422

Epoch: 6| Step: 10
Training loss: 0.030774228274822235
Validation loss: 1.3804349591655116

Epoch: 6| Step: 11
Training loss: 0.07916499674320221
Validation loss: 1.402443253865806

Epoch: 6| Step: 12
Training loss: 0.0572669580578804
Validation loss: 1.3977332691992483

Epoch: 6| Step: 13
Training loss: 0.08393392711877823
Validation loss: 1.3854107728568457

Epoch: 761| Step: 0
Training loss: 0.06992207467556
Validation loss: 1.3846835936269453

Epoch: 6| Step: 1
Training loss: 0.04939398914575577
Validation loss: 1.3676355282465618

Epoch: 6| Step: 2
Training loss: 0.04223322868347168
Validation loss: 1.3661479385950233

Epoch: 6| Step: 3
Training loss: 0.038435544818639755
Validation loss: 1.3638269529547742

Epoch: 6| Step: 4
Training loss: 0.06862502545118332
Validation loss: 1.348274011765757

Epoch: 6| Step: 5
Training loss: 0.06966671347618103
Validation loss: 1.3526385836703803

Epoch: 6| Step: 6
Training loss: 0.0442810133099556
Validation loss: 1.3925155901139783

Epoch: 6| Step: 7
Training loss: 0.049516111612319946
Validation loss: 1.3862629282859065

Epoch: 6| Step: 8
Training loss: 0.038253866136074066
Validation loss: 1.365923523902893

Epoch: 6| Step: 9
Training loss: 0.028127875179052353
Validation loss: 1.3755382760878532

Epoch: 6| Step: 10
Training loss: 0.06088927388191223
Validation loss: 1.3524788105359642

Epoch: 6| Step: 11
Training loss: 0.06875108927488327
Validation loss: 1.3628235619555238

Epoch: 6| Step: 12
Training loss: 0.0397358201444149
Validation loss: 1.3607630845039123

Epoch: 6| Step: 13
Training loss: 0.034276869148015976
Validation loss: 1.348367529530679

Epoch: 762| Step: 0
Training loss: 0.04737155884504318
Validation loss: 1.3689517154488513

Epoch: 6| Step: 1
Training loss: 0.05801559239625931
Validation loss: 1.378148668555803

Epoch: 6| Step: 2
Training loss: 0.04915197938680649
Validation loss: 1.3700235389894055

Epoch: 6| Step: 3
Training loss: 0.05137605965137482
Validation loss: 1.3885480485936648

Epoch: 6| Step: 4
Training loss: 0.0757526308298111
Validation loss: 1.3684542332926104

Epoch: 6| Step: 5
Training loss: 0.046839989721775055
Validation loss: 1.3793864493728967

Epoch: 6| Step: 6
Training loss: 0.0386715792119503
Validation loss: 1.3829262102803876

Epoch: 6| Step: 7
Training loss: 0.04936108738183975
Validation loss: 1.412350954548005

Epoch: 6| Step: 8
Training loss: 0.05859331786632538
Validation loss: 1.386714498202006

Epoch: 6| Step: 9
Training loss: 0.05569349229335785
Validation loss: 1.385591745376587

Epoch: 6| Step: 10
Training loss: 0.03876467049121857
Validation loss: 1.3852851762566516

Epoch: 6| Step: 11
Training loss: 0.03989076614379883
Validation loss: 1.3710760454977713

Epoch: 6| Step: 12
Training loss: 0.04658998176455498
Validation loss: 1.3843323133325065

Epoch: 6| Step: 13
Training loss: 0.08615919947624207
Validation loss: 1.3996183474858601

Epoch: 763| Step: 0
Training loss: 0.03742743283510208
Validation loss: 1.4098195760480818

Epoch: 6| Step: 1
Training loss: 0.05681166797876358
Validation loss: 1.4169278260200255

Epoch: 6| Step: 2
Training loss: 0.032619133591651917
Validation loss: 1.394600954107059

Epoch: 6| Step: 3
Training loss: 0.07361487299203873
Validation loss: 1.3686092694600422

Epoch: 6| Step: 4
Training loss: 0.07724109292030334
Validation loss: 1.3886300645848757

Epoch: 6| Step: 5
Training loss: 0.07737617194652557
Validation loss: 1.3898022303017237

Epoch: 6| Step: 6
Training loss: 0.05945024639368057
Validation loss: 1.3674849297410698

Epoch: 6| Step: 7
Training loss: 0.06529591977596283
Validation loss: 1.3637059157894504

Epoch: 6| Step: 8
Training loss: 0.10036808252334595
Validation loss: 1.3788313583661151

Epoch: 6| Step: 9
Training loss: 0.054425135254859924
Validation loss: 1.3805677108867194

Epoch: 6| Step: 10
Training loss: 0.04930974543094635
Validation loss: 1.387646493091378

Epoch: 6| Step: 11
Training loss: 0.04895950108766556
Validation loss: 1.3732814942636797

Epoch: 6| Step: 12
Training loss: 0.04407387599349022
Validation loss: 1.409725716037135

Epoch: 6| Step: 13
Training loss: 0.0756983757019043
Validation loss: 1.4028902207651446

Epoch: 764| Step: 0
Training loss: 0.04181660711765289
Validation loss: 1.4288965175228734

Epoch: 6| Step: 1
Training loss: 0.07089067995548248
Validation loss: 1.4271599970838076

Epoch: 6| Step: 2
Training loss: 0.04066092520952225
Validation loss: 1.4172705668275074

Epoch: 6| Step: 3
Training loss: 0.03993396461009979
Validation loss: 1.4273621946252801

Epoch: 6| Step: 4
Training loss: 0.043657831847667694
Validation loss: 1.4044912668966478

Epoch: 6| Step: 5
Training loss: 0.06536227464675903
Validation loss: 1.4212664083767963

Epoch: 6| Step: 6
Training loss: 0.03699878603219986
Validation loss: 1.3816686919940415

Epoch: 6| Step: 7
Training loss: 0.06542488932609558
Validation loss: 1.4061261646209224

Epoch: 6| Step: 8
Training loss: 0.0393858477473259
Validation loss: 1.3758266638684016

Epoch: 6| Step: 9
Training loss: 0.10186292231082916
Validation loss: 1.3870476445844095

Epoch: 6| Step: 10
Training loss: 0.06643009185791016
Validation loss: 1.3934584215123167

Epoch: 6| Step: 11
Training loss: 0.06468383967876434
Validation loss: 1.3924791505259853

Epoch: 6| Step: 12
Training loss: 0.04530002549290657
Validation loss: 1.3932475056699527

Epoch: 6| Step: 13
Training loss: 0.0326809361577034
Validation loss: 1.3979518362270889

Epoch: 765| Step: 0
Training loss: 0.056972600519657135
Validation loss: 1.4040158423044349

Epoch: 6| Step: 1
Training loss: 0.05980217456817627
Validation loss: 1.4288729672790856

Epoch: 6| Step: 2
Training loss: 0.1002139300107956
Validation loss: 1.4416144535105715

Epoch: 6| Step: 3
Training loss: 0.0592276006937027
Validation loss: 1.4310021990089006

Epoch: 6| Step: 4
Training loss: 0.07151380181312561
Validation loss: 1.42980416487622

Epoch: 6| Step: 5
Training loss: 0.041662029922008514
Validation loss: 1.4205658538367159

Epoch: 6| Step: 6
Training loss: 0.02315327525138855
Validation loss: 1.3943685780289352

Epoch: 6| Step: 7
Training loss: 0.04007025063037872
Validation loss: 1.4036131610152542

Epoch: 6| Step: 8
Training loss: 0.05544818192720413
Validation loss: 1.3783734229303175

Epoch: 6| Step: 9
Training loss: 0.03261665999889374
Validation loss: 1.372348427772522

Epoch: 6| Step: 10
Training loss: 0.057743556797504425
Validation loss: 1.3240529811510475

Epoch: 6| Step: 11
Training loss: 0.039514586329460144
Validation loss: 1.342175211957706

Epoch: 6| Step: 12
Training loss: 0.06453855335712433
Validation loss: 1.3374680729322537

Epoch: 6| Step: 13
Training loss: 0.024601569399237633
Validation loss: 1.3476674851550852

Epoch: 766| Step: 0
Training loss: 0.057563818991184235
Validation loss: 1.3320333419307586

Epoch: 6| Step: 1
Training loss: 0.03728853538632393
Validation loss: 1.344872845116482

Epoch: 6| Step: 2
Training loss: 0.05195896327495575
Validation loss: 1.3420358934710104

Epoch: 6| Step: 3
Training loss: 0.05254054069519043
Validation loss: 1.350162152321108

Epoch: 6| Step: 4
Training loss: 0.03530838340520859
Validation loss: 1.3458204846228323

Epoch: 6| Step: 5
Training loss: 0.06425033509731293
Validation loss: 1.3594722344029335

Epoch: 6| Step: 6
Training loss: 0.07521936297416687
Validation loss: 1.3421632730832664

Epoch: 6| Step: 7
Training loss: 0.053699202835559845
Validation loss: 1.3373743667397449

Epoch: 6| Step: 8
Training loss: 0.03257537633180618
Validation loss: 1.3726395849258668

Epoch: 6| Step: 9
Training loss: 0.03663555532693863
Validation loss: 1.3709233403205872

Epoch: 6| Step: 10
Training loss: 0.07629452645778656
Validation loss: 1.3818228398599932

Epoch: 6| Step: 11
Training loss: 0.06004669517278671
Validation loss: 1.3970594534309961

Epoch: 6| Step: 12
Training loss: 0.033766843378543854
Validation loss: 1.3718721533334384

Epoch: 6| Step: 13
Training loss: 0.05454714968800545
Validation loss: 1.3947027139766242

Epoch: 767| Step: 0
Training loss: 0.0828275978565216
Validation loss: 1.3971311892232587

Epoch: 6| Step: 1
Training loss: 0.05855144187808037
Validation loss: 1.3924841195024469

Epoch: 6| Step: 2
Training loss: 0.05963587015867233
Validation loss: 1.3867570841184227

Epoch: 6| Step: 3
Training loss: 0.04809851944446564
Validation loss: 1.3987952983507546

Epoch: 6| Step: 4
Training loss: 0.04576123505830765
Validation loss: 1.420016844426432

Epoch: 6| Step: 5
Training loss: 0.05505531281232834
Validation loss: 1.4242711355609279

Epoch: 6| Step: 6
Training loss: 0.03705664351582527
Validation loss: 1.400056468543186

Epoch: 6| Step: 7
Training loss: 0.037929438054561615
Validation loss: 1.4151877062295073

Epoch: 6| Step: 8
Training loss: 0.024025509133934975
Validation loss: 1.3722716018717775

Epoch: 6| Step: 9
Training loss: 0.03778021037578583
Validation loss: 1.3827796354088733

Epoch: 6| Step: 10
Training loss: 0.06443780660629272
Validation loss: 1.3731768297892746

Epoch: 6| Step: 11
Training loss: 0.05611681938171387
Validation loss: 1.3613039716597526

Epoch: 6| Step: 12
Training loss: 0.0395631343126297
Validation loss: 1.3430072504986998

Epoch: 6| Step: 13
Training loss: 0.04057035967707634
Validation loss: 1.3725627994024625

Epoch: 768| Step: 0
Training loss: 0.03727826476097107
Validation loss: 1.3718861956750192

Epoch: 6| Step: 1
Training loss: 0.07957838475704193
Validation loss: 1.3653504649798076

Epoch: 6| Step: 2
Training loss: 0.033927299082279205
Validation loss: 1.357114206078232

Epoch: 6| Step: 3
Training loss: 0.06179708242416382
Validation loss: 1.340060282138086

Epoch: 6| Step: 4
Training loss: 0.05132713168859482
Validation loss: 1.3633154528115385

Epoch: 6| Step: 5
Training loss: 0.05333228409290314
Validation loss: 1.3581325431023874

Epoch: 6| Step: 6
Training loss: 0.02561834827065468
Validation loss: 1.3682165068964804

Epoch: 6| Step: 7
Training loss: 0.04418770968914032
Validation loss: 1.3779198059471705

Epoch: 6| Step: 8
Training loss: 0.05199427157640457
Validation loss: 1.3941582120874876

Epoch: 6| Step: 9
Training loss: 0.05214597284793854
Validation loss: 1.383672833442688

Epoch: 6| Step: 10
Training loss: 0.044468797743320465
Validation loss: 1.4019295188688463

Epoch: 6| Step: 11
Training loss: 0.05839049443602562
Validation loss: 1.4085764064583728

Epoch: 6| Step: 12
Training loss: 0.05812522768974304
Validation loss: 1.4014811323535057

Epoch: 6| Step: 13
Training loss: 0.018466684967279434
Validation loss: 1.3910391292264384

Epoch: 769| Step: 0
Training loss: 0.04641413688659668
Validation loss: 1.4072370695811447

Epoch: 6| Step: 1
Training loss: 0.06859178096055984
Validation loss: 1.4190668649570917

Epoch: 6| Step: 2
Training loss: 0.04950603470206261
Validation loss: 1.4333463791877992

Epoch: 6| Step: 3
Training loss: 0.025713331997394562
Validation loss: 1.4086290700461275

Epoch: 6| Step: 4
Training loss: 0.14254358410835266
Validation loss: 1.3967246842640701

Epoch: 6| Step: 5
Training loss: 0.03591427952051163
Validation loss: 1.3982712350865847

Epoch: 6| Step: 6
Training loss: 0.03512166067957878
Validation loss: 1.3774737106856478

Epoch: 6| Step: 7
Training loss: 0.05859098583459854
Validation loss: 1.3614139864521642

Epoch: 6| Step: 8
Training loss: 0.026389285922050476
Validation loss: 1.356106158225767

Epoch: 6| Step: 9
Training loss: 0.06566863507032394
Validation loss: 1.3477529761611775

Epoch: 6| Step: 10
Training loss: 0.07063624262809753
Validation loss: 1.337252209263463

Epoch: 6| Step: 11
Training loss: 0.06475315988063812
Validation loss: 1.3164891081471597

Epoch: 6| Step: 12
Training loss: 0.07130728662014008
Validation loss: 1.3379357553297473

Epoch: 6| Step: 13
Training loss: 0.041445087641477585
Validation loss: 1.3337491026488684

Epoch: 770| Step: 0
Training loss: 0.05345921963453293
Validation loss: 1.3427580620652886

Epoch: 6| Step: 1
Training loss: 0.05800776183605194
Validation loss: 1.3470418504489365

Epoch: 6| Step: 2
Training loss: 0.04682062938809395
Validation loss: 1.3685533910669305

Epoch: 6| Step: 3
Training loss: 0.05430717021226883
Validation loss: 1.3710838774199128

Epoch: 6| Step: 4
Training loss: 0.10147282481193542
Validation loss: 1.3823011421388196

Epoch: 6| Step: 5
Training loss: 0.03604866936802864
Validation loss: 1.4244368435234152

Epoch: 6| Step: 6
Training loss: 0.03237874060869217
Validation loss: 1.4291605423855525

Epoch: 6| Step: 7
Training loss: 0.07008326798677444
Validation loss: 1.4336288270129953

Epoch: 6| Step: 8
Training loss: 0.028102077543735504
Validation loss: 1.4336098009540188

Epoch: 6| Step: 9
Training loss: 0.05790715664625168
Validation loss: 1.4342424228627195

Epoch: 6| Step: 10
Training loss: 0.05776900798082352
Validation loss: 1.4350890985099218

Epoch: 6| Step: 11
Training loss: 0.06171538308262825
Validation loss: 1.4110708198239725

Epoch: 6| Step: 12
Training loss: 0.045512933284044266
Validation loss: 1.3888359736370783

Epoch: 6| Step: 13
Training loss: 0.031196322292089462
Validation loss: 1.4003825585047405

Epoch: 771| Step: 0
Training loss: 0.041401006281375885
Validation loss: 1.3996461719594977

Epoch: 6| Step: 1
Training loss: 0.02658919245004654
Validation loss: 1.4015580428543912

Epoch: 6| Step: 2
Training loss: 0.07728105783462524
Validation loss: 1.4011326534773714

Epoch: 6| Step: 3
Training loss: 0.08650142699480057
Validation loss: 1.4117513446397678

Epoch: 6| Step: 4
Training loss: 0.05784964933991432
Validation loss: 1.385647061050579

Epoch: 6| Step: 5
Training loss: 0.055786460638046265
Validation loss: 1.3725579451489192

Epoch: 6| Step: 6
Training loss: 0.05125889554619789
Validation loss: 1.3812908600735407

Epoch: 6| Step: 7
Training loss: 0.07018398493528366
Validation loss: 1.359159937468908

Epoch: 6| Step: 8
Training loss: 0.038634832948446274
Validation loss: 1.358169146122471

Epoch: 6| Step: 9
Training loss: 0.08855758607387543
Validation loss: 1.3333443518607848

Epoch: 6| Step: 10
Training loss: 0.028602570295333862
Validation loss: 1.3554343895245624

Epoch: 6| Step: 11
Training loss: 0.029999110847711563
Validation loss: 1.3542123206200138

Epoch: 6| Step: 12
Training loss: 0.06024438887834549
Validation loss: 1.3619004487991333

Epoch: 6| Step: 13
Training loss: 0.0817505419254303
Validation loss: 1.3719619358739545

Epoch: 772| Step: 0
Training loss: 0.03943200781941414
Validation loss: 1.3940605591702204

Epoch: 6| Step: 1
Training loss: 0.026360400021076202
Validation loss: 1.3912455522885887

Epoch: 6| Step: 2
Training loss: 0.06240173429250717
Validation loss: 1.403671351812219

Epoch: 6| Step: 3
Training loss: 0.052439987659454346
Validation loss: 1.4122359701382217

Epoch: 6| Step: 4
Training loss: 0.032657917588949203
Validation loss: 1.408032307060816

Epoch: 6| Step: 5
Training loss: 0.043963514268398285
Validation loss: 1.3991889299884919

Epoch: 6| Step: 6
Training loss: 0.06679922342300415
Validation loss: 1.4010936816533406

Epoch: 6| Step: 7
Training loss: 0.06697987020015717
Validation loss: 1.3826990512109572

Epoch: 6| Step: 8
Training loss: 0.06714746356010437
Validation loss: 1.3790945731183535

Epoch: 6| Step: 9
Training loss: 0.05524606257677078
Validation loss: 1.4000119086234801

Epoch: 6| Step: 10
Training loss: 0.04813983291387558
Validation loss: 1.3810140138031335

Epoch: 6| Step: 11
Training loss: 0.0426691472530365
Validation loss: 1.4076738434453164

Epoch: 6| Step: 12
Training loss: 0.0373133048415184
Validation loss: 1.3678153586643997

Epoch: 6| Step: 13
Training loss: 0.09414704889059067
Validation loss: 1.4007334606621855

Epoch: 773| Step: 0
Training loss: 0.08825433254241943
Validation loss: 1.3811775381847093

Epoch: 6| Step: 1
Training loss: 0.05258817970752716
Validation loss: 1.4243176842248568

Epoch: 6| Step: 2
Training loss: 0.042655885219573975
Validation loss: 1.4190863678532262

Epoch: 6| Step: 3
Training loss: 0.05485408753156662
Validation loss: 1.4444024973018195

Epoch: 6| Step: 4
Training loss: 0.06373739242553711
Validation loss: 1.4509493843201668

Epoch: 6| Step: 5
Training loss: 0.0588073655962944
Validation loss: 1.4501381817684378

Epoch: 6| Step: 6
Training loss: 0.04525187239050865
Validation loss: 1.472975306613471

Epoch: 6| Step: 7
Training loss: 0.06832339614629745
Validation loss: 1.4667379490790828

Epoch: 6| Step: 8
Training loss: 0.07819931209087372
Validation loss: 1.4706788396322599

Epoch: 6| Step: 9
Training loss: 0.07738684862852097
Validation loss: 1.4462430400233115

Epoch: 6| Step: 10
Training loss: 0.04528588801622391
Validation loss: 1.4166073709405878

Epoch: 6| Step: 11
Training loss: 0.03417512774467468
Validation loss: 1.3973306353374193

Epoch: 6| Step: 12
Training loss: 0.053962014615535736
Validation loss: 1.383467290991096

Epoch: 6| Step: 13
Training loss: 0.06074574217200279
Validation loss: 1.3840922463324763

Epoch: 774| Step: 0
Training loss: 0.03871338814496994
Validation loss: 1.3822232548908522

Epoch: 6| Step: 1
Training loss: 0.04104924947023392
Validation loss: 1.3636887150426065

Epoch: 6| Step: 2
Training loss: 0.07533444464206696
Validation loss: 1.3535407743146342

Epoch: 6| Step: 3
Training loss: 0.04786558449268341
Validation loss: 1.3617782131318124

Epoch: 6| Step: 4
Training loss: 0.08755336701869965
Validation loss: 1.3518303748100036

Epoch: 6| Step: 5
Training loss: 0.04550470411777496
Validation loss: 1.3904557125542754

Epoch: 6| Step: 6
Training loss: 0.03551912680268288
Validation loss: 1.363786615351195

Epoch: 6| Step: 7
Training loss: 0.04926879331469536
Validation loss: 1.3900500933329265

Epoch: 6| Step: 8
Training loss: 0.04564131796360016
Validation loss: 1.4020004426279375

Epoch: 6| Step: 9
Training loss: 0.054770708084106445
Validation loss: 1.3942787044791765

Epoch: 6| Step: 10
Training loss: 0.05436740443110466
Validation loss: 1.3791256194473596

Epoch: 6| Step: 11
Training loss: 0.06727196276187897
Validation loss: 1.3974277716810986

Epoch: 6| Step: 12
Training loss: 0.052390582859516144
Validation loss: 1.3852555226254206

Epoch: 6| Step: 13
Training loss: 0.03988289833068848
Validation loss: 1.3763441231942946

Epoch: 775| Step: 0
Training loss: 0.04646183177828789
Validation loss: 1.3739104129934823

Epoch: 6| Step: 1
Training loss: 0.059440385550260544
Validation loss: 1.3551072087339175

Epoch: 6| Step: 2
Training loss: 0.06801443547010422
Validation loss: 1.364350300963207

Epoch: 6| Step: 3
Training loss: 0.05175185203552246
Validation loss: 1.3537190236071104

Epoch: 6| Step: 4
Training loss: 0.055167749524116516
Validation loss: 1.337587962868393

Epoch: 6| Step: 5
Training loss: 0.05404875427484512
Validation loss: 1.3462905819698046

Epoch: 6| Step: 6
Training loss: 0.0452718622982502
Validation loss: 1.3447543228826215

Epoch: 6| Step: 7
Training loss: 0.09141488373279572
Validation loss: 1.3524984723778182

Epoch: 6| Step: 8
Training loss: 0.0741884857416153
Validation loss: 1.3602367319086546

Epoch: 6| Step: 9
Training loss: 0.06489419937133789
Validation loss: 1.3359787169323172

Epoch: 6| Step: 10
Training loss: 0.05900805816054344
Validation loss: 1.3852703699501612

Epoch: 6| Step: 11
Training loss: 0.06334088742733002
Validation loss: 1.3771301264403968

Epoch: 6| Step: 12
Training loss: 0.04723307862877846
Validation loss: 1.354964763887467

Epoch: 6| Step: 13
Training loss: 0.057862427085638046
Validation loss: 1.3719751155504616

Epoch: 776| Step: 0
Training loss: 0.09610852599143982
Validation loss: 1.4019593346503474

Epoch: 6| Step: 1
Training loss: 0.054424919188022614
Validation loss: 1.3842384943398096

Epoch: 6| Step: 2
Training loss: 0.06468796730041504
Validation loss: 1.422923957147906

Epoch: 6| Step: 3
Training loss: 0.08418838679790497
Validation loss: 1.382660811306328

Epoch: 6| Step: 4
Training loss: 0.06616110354661942
Validation loss: 1.3799000606741956

Epoch: 6| Step: 5
Training loss: 0.05901838093996048
Validation loss: 1.3359863693996141

Epoch: 6| Step: 6
Training loss: 0.04650667682290077
Validation loss: 1.3602717743125012

Epoch: 6| Step: 7
Training loss: 0.06973636150360107
Validation loss: 1.3818217580036452

Epoch: 6| Step: 8
Training loss: 0.047497086226940155
Validation loss: 1.366022450949556

Epoch: 6| Step: 9
Training loss: 0.03871827572584152
Validation loss: 1.3754958273262106

Epoch: 6| Step: 10
Training loss: 0.03126471862196922
Validation loss: 1.3789668198554748

Epoch: 6| Step: 11
Training loss: 0.06069987267255783
Validation loss: 1.3850840253214682

Epoch: 6| Step: 12
Training loss: 0.04101720452308655
Validation loss: 1.3625116412357619

Epoch: 6| Step: 13
Training loss: 0.08765268325805664
Validation loss: 1.3779205327392907

Epoch: 777| Step: 0
Training loss: 0.06938832998275757
Validation loss: 1.3985487197035102

Epoch: 6| Step: 1
Training loss: 0.0489557683467865
Validation loss: 1.387515914055609

Epoch: 6| Step: 2
Training loss: 0.04763904586434364
Validation loss: 1.423292794535237

Epoch: 6| Step: 3
Training loss: 0.05154610425233841
Validation loss: 1.4285538324745752

Epoch: 6| Step: 4
Training loss: 0.052130043506622314
Validation loss: 1.426228189981112

Epoch: 6| Step: 5
Training loss: 0.05285615846514702
Validation loss: 1.4208100162526613

Epoch: 6| Step: 6
Training loss: 0.04215284436941147
Validation loss: 1.4280134272831742

Epoch: 6| Step: 7
Training loss: 0.06139484792947769
Validation loss: 1.4175880314201437

Epoch: 6| Step: 8
Training loss: 0.05534340441226959
Validation loss: 1.3982760944674093

Epoch: 6| Step: 9
Training loss: 0.06508677452802658
Validation loss: 1.404088503570967

Epoch: 6| Step: 10
Training loss: 0.050846319645643234
Validation loss: 1.3783423605785574

Epoch: 6| Step: 11
Training loss: 0.05046646296977997
Validation loss: 1.3802431847459526

Epoch: 6| Step: 12
Training loss: 0.04123248904943466
Validation loss: 1.3648276354676934

Epoch: 6| Step: 13
Training loss: 0.06375359743833542
Validation loss: 1.3578665589773526

Epoch: 778| Step: 0
Training loss: 0.05063395947217941
Validation loss: 1.354807734489441

Epoch: 6| Step: 1
Training loss: 0.05015307664871216
Validation loss: 1.363740986393344

Epoch: 6| Step: 2
Training loss: 0.05781080573797226
Validation loss: 1.3835587886071974

Epoch: 6| Step: 3
Training loss: 0.07088752090930939
Validation loss: 1.3822631976937736

Epoch: 6| Step: 4
Training loss: 0.04836304113268852
Validation loss: 1.3711656114106536

Epoch: 6| Step: 5
Training loss: 0.07385572046041489
Validation loss: 1.4014791109228646

Epoch: 6| Step: 6
Training loss: 0.058131277561187744
Validation loss: 1.3976245310998732

Epoch: 6| Step: 7
Training loss: 0.06720025837421417
Validation loss: 1.368263844520815

Epoch: 6| Step: 8
Training loss: 0.07468383014202118
Validation loss: 1.3806881366237518

Epoch: 6| Step: 9
Training loss: 0.046134255826473236
Validation loss: 1.3808589443083732

Epoch: 6| Step: 10
Training loss: 0.03587840124964714
Validation loss: 1.3906729708435714

Epoch: 6| Step: 11
Training loss: 0.05294670909643173
Validation loss: 1.3866330167298675

Epoch: 6| Step: 12
Training loss: 0.061402760446071625
Validation loss: 1.3777643890791043

Epoch: 6| Step: 13
Training loss: 0.0669490396976471
Validation loss: 1.3886596695069344

Epoch: 779| Step: 0
Training loss: 0.042779505252838135
Validation loss: 1.3809699294387654

Epoch: 6| Step: 1
Training loss: 0.07004448771476746
Validation loss: 1.3697535273849324

Epoch: 6| Step: 2
Training loss: 0.0680704265832901
Validation loss: 1.3664509557908582

Epoch: 6| Step: 3
Training loss: 0.053676482290029526
Validation loss: 1.3827054051942722

Epoch: 6| Step: 4
Training loss: 0.047489557415246964
Validation loss: 1.3544950562138711

Epoch: 6| Step: 5
Training loss: 0.060707107186317444
Validation loss: 1.362307817705216

Epoch: 6| Step: 6
Training loss: 0.0915503203868866
Validation loss: 1.3870105140952653

Epoch: 6| Step: 7
Training loss: 0.03241134434938431
Validation loss: 1.3967342607436641

Epoch: 6| Step: 8
Training loss: 0.05675419420003891
Validation loss: 1.4123554691191642

Epoch: 6| Step: 9
Training loss: 0.029803501442074776
Validation loss: 1.3948047430284563

Epoch: 6| Step: 10
Training loss: 0.055719658732414246
Validation loss: 1.4157464286332488

Epoch: 6| Step: 11
Training loss: 0.06328524649143219
Validation loss: 1.423011201684193

Epoch: 6| Step: 12
Training loss: 0.08771355450153351
Validation loss: 1.4112787746614026

Epoch: 6| Step: 13
Training loss: 0.052080485969781876
Validation loss: 1.4316798422926216

Epoch: 780| Step: 0
Training loss: 0.046259887516498566
Validation loss: 1.429744843513735

Epoch: 6| Step: 1
Training loss: 0.038354381918907166
Validation loss: 1.4468526763300742

Epoch: 6| Step: 2
Training loss: 0.04382612928748131
Validation loss: 1.4291119165317987

Epoch: 6| Step: 3
Training loss: 0.059285879135131836
Validation loss: 1.4135991757915867

Epoch: 6| Step: 4
Training loss: 0.02209017425775528
Validation loss: 1.407479272093824

Epoch: 6| Step: 5
Training loss: 0.033224187791347504
Validation loss: 1.3724419160555767

Epoch: 6| Step: 6
Training loss: 0.07965916395187378
Validation loss: 1.3788138999733874

Epoch: 6| Step: 7
Training loss: 0.04614613205194473
Validation loss: 1.3826422524708573

Epoch: 6| Step: 8
Training loss: 0.06782995909452438
Validation loss: 1.3737881645079582

Epoch: 6| Step: 9
Training loss: 0.046090565621852875
Validation loss: 1.3495829028467978

Epoch: 6| Step: 10
Training loss: 0.040396157652139664
Validation loss: 1.3627748591925508

Epoch: 6| Step: 11
Training loss: 0.05487750470638275
Validation loss: 1.3559421646979548

Epoch: 6| Step: 12
Training loss: 0.05827466398477554
Validation loss: 1.3545043692793897

Epoch: 6| Step: 13
Training loss: 0.05888030305504799
Validation loss: 1.3665805837159515

Epoch: 781| Step: 0
Training loss: 0.04271532595157623
Validation loss: 1.358022561637304

Epoch: 6| Step: 1
Training loss: 0.05025613680481911
Validation loss: 1.3622912322321246

Epoch: 6| Step: 2
Training loss: 0.051644451916217804
Validation loss: 1.3530296946084628

Epoch: 6| Step: 3
Training loss: 0.045260339975357056
Validation loss: 1.3556525079152917

Epoch: 6| Step: 4
Training loss: 0.03893537446856499
Validation loss: 1.3517929341203423

Epoch: 6| Step: 5
Training loss: 0.08170443773269653
Validation loss: 1.3774178540834816

Epoch: 6| Step: 6
Training loss: 0.08117442578077316
Validation loss: 1.3645819771674372

Epoch: 6| Step: 7
Training loss: 0.02740474045276642
Validation loss: 1.3502578876351798

Epoch: 6| Step: 8
Training loss: 0.0490339919924736
Validation loss: 1.3740783071005216

Epoch: 6| Step: 9
Training loss: 0.03742680326104164
Validation loss: 1.3548654381946852

Epoch: 6| Step: 10
Training loss: 0.0435643345117569
Validation loss: 1.3487808691558016

Epoch: 6| Step: 11
Training loss: 0.09071674942970276
Validation loss: 1.36075141737538

Epoch: 6| Step: 12
Training loss: 0.04409356415271759
Validation loss: 1.391410703300148

Epoch: 6| Step: 13
Training loss: 0.03268973156809807
Validation loss: 1.3743042202406033

Epoch: 782| Step: 0
Training loss: 0.0323343351483345
Validation loss: 1.3676817660690637

Epoch: 6| Step: 1
Training loss: 0.04514973610639572
Validation loss: 1.393430063801427

Epoch: 6| Step: 2
Training loss: 0.04285498708486557
Validation loss: 1.3998343162639166

Epoch: 6| Step: 3
Training loss: 0.043921973556280136
Validation loss: 1.3980581209223757

Epoch: 6| Step: 4
Training loss: 0.05871187150478363
Validation loss: 1.3838923643994074

Epoch: 6| Step: 5
Training loss: 0.07022684812545776
Validation loss: 1.388548985604317

Epoch: 6| Step: 6
Training loss: 0.042916860431432724
Validation loss: 1.376091303363923

Epoch: 6| Step: 7
Training loss: 0.05863405764102936
Validation loss: 1.3627179771341302

Epoch: 6| Step: 8
Training loss: 0.039197660982608795
Validation loss: 1.3395717964377454

Epoch: 6| Step: 9
Training loss: 0.047355566173791885
Validation loss: 1.3654932757859588

Epoch: 6| Step: 10
Training loss: 0.02320536971092224
Validation loss: 1.3623470837070095

Epoch: 6| Step: 11
Training loss: 0.0427979975938797
Validation loss: 1.3682421548392183

Epoch: 6| Step: 12
Training loss: 0.036334749311208725
Validation loss: 1.3812012890333771

Epoch: 6| Step: 13
Training loss: 0.10489673912525177
Validation loss: 1.3988524329277776

Epoch: 783| Step: 0
Training loss: 0.05006375163793564
Validation loss: 1.40176772814925

Epoch: 6| Step: 1
Training loss: 0.05306144803762436
Validation loss: 1.4157011816578526

Epoch: 6| Step: 2
Training loss: 0.09589598327875137
Validation loss: 1.4130547649116927

Epoch: 6| Step: 3
Training loss: 0.042227234691381454
Validation loss: 1.4017248089595506

Epoch: 6| Step: 4
Training loss: 0.025706373155117035
Validation loss: 1.388539893652803

Epoch: 6| Step: 5
Training loss: 0.03243148699402809
Validation loss: 1.3753312877429429

Epoch: 6| Step: 6
Training loss: 0.031049631536006927
Validation loss: 1.3633943027065647

Epoch: 6| Step: 7
Training loss: 0.0642578974366188
Validation loss: 1.3643043874412455

Epoch: 6| Step: 8
Training loss: 0.0827440395951271
Validation loss: 1.3943738565650037

Epoch: 6| Step: 9
Training loss: 0.049414556473493576
Validation loss: 1.3557604551315308

Epoch: 6| Step: 10
Training loss: 0.046047039330005646
Validation loss: 1.3749289788225645

Epoch: 6| Step: 11
Training loss: 0.06642545014619827
Validation loss: 1.3680799750871555

Epoch: 6| Step: 12
Training loss: 0.0695359855890274
Validation loss: 1.3699680041241389

Epoch: 6| Step: 13
Training loss: 0.06399933993816376
Validation loss: 1.3746106522057646

Epoch: 784| Step: 0
Training loss: 0.0741346925497055
Validation loss: 1.3797337073151783

Epoch: 6| Step: 1
Training loss: 0.04309893399477005
Validation loss: 1.4044413399952713

Epoch: 6| Step: 2
Training loss: 0.03311815857887268
Validation loss: 1.4078582473980483

Epoch: 6| Step: 3
Training loss: 0.03487188741564751
Validation loss: 1.394983430062571

Epoch: 6| Step: 4
Training loss: 0.03958754986524582
Validation loss: 1.3911224539561937

Epoch: 6| Step: 5
Training loss: 0.042242880910634995
Validation loss: 1.3989472030311503

Epoch: 6| Step: 6
Training loss: 0.0855293795466423
Validation loss: 1.384885589281718

Epoch: 6| Step: 7
Training loss: 0.026430953294038773
Validation loss: 1.388187357174453

Epoch: 6| Step: 8
Training loss: 0.05840137600898743
Validation loss: 1.397829048095211

Epoch: 6| Step: 9
Training loss: 0.02822292596101761
Validation loss: 1.417718163100622

Epoch: 6| Step: 10
Training loss: 0.07555513083934784
Validation loss: 1.3887408830786263

Epoch: 6| Step: 11
Training loss: 0.03694295883178711
Validation loss: 1.4118766848758986

Epoch: 6| Step: 12
Training loss: 0.07871287316083908
Validation loss: 1.4066437559743081

Epoch: 6| Step: 13
Training loss: 0.03347410261631012
Validation loss: 1.4079801703012118

Epoch: 785| Step: 0
Training loss: 0.05208584666252136
Validation loss: 1.3926523981555816

Epoch: 6| Step: 1
Training loss: 0.05141591280698776
Validation loss: 1.4315779324500792

Epoch: 6| Step: 2
Training loss: 0.044142067432403564
Validation loss: 1.3946939322256273

Epoch: 6| Step: 3
Training loss: 0.06636437773704529
Validation loss: 1.4145086939616869

Epoch: 6| Step: 4
Training loss: 0.0675286054611206
Validation loss: 1.4366959999966364

Epoch: 6| Step: 5
Training loss: 0.04771773889660835
Validation loss: 1.4114918080709313

Epoch: 6| Step: 6
Training loss: 0.04551295191049576
Validation loss: 1.4163994699396112

Epoch: 6| Step: 7
Training loss: 0.03420571610331535
Validation loss: 1.4107650877327047

Epoch: 6| Step: 8
Training loss: 0.04125043377280235
Validation loss: 1.4049703292949225

Epoch: 6| Step: 9
Training loss: 0.03776595741510391
Validation loss: 1.3794517690135586

Epoch: 6| Step: 10
Training loss: 0.050578415393829346
Validation loss: 1.3541067287486086

Epoch: 6| Step: 11
Training loss: 0.08186392486095428
Validation loss: 1.3400137065559306

Epoch: 6| Step: 12
Training loss: 0.04491192847490311
Validation loss: 1.325135733491631

Epoch: 6| Step: 13
Training loss: 0.05949120968580246
Validation loss: 1.3237310667191782

Epoch: 786| Step: 0
Training loss: 0.06769996881484985
Validation loss: 1.3287296564348283

Epoch: 6| Step: 1
Training loss: 0.03662891685962677
Validation loss: 1.330363747894123

Epoch: 6| Step: 2
Training loss: 0.06528579443693161
Validation loss: 1.3448817653040732

Epoch: 6| Step: 3
Training loss: 0.03820112347602844
Validation loss: 1.3432591679275676

Epoch: 6| Step: 4
Training loss: 0.05574186518788338
Validation loss: 1.3537885578729774

Epoch: 6| Step: 5
Training loss: 0.02634356915950775
Validation loss: 1.3603472286655056

Epoch: 6| Step: 6
Training loss: 0.0668451339006424
Validation loss: 1.3680830976014495

Epoch: 6| Step: 7
Training loss: 0.06700699776411057
Validation loss: 1.3744419031245734

Epoch: 6| Step: 8
Training loss: 0.04918534681200981
Validation loss: 1.3909498606958697

Epoch: 6| Step: 9
Training loss: 0.03230476379394531
Validation loss: 1.4221470727715442

Epoch: 6| Step: 10
Training loss: 0.033489927649497986
Validation loss: 1.4085548385497062

Epoch: 6| Step: 11
Training loss: 0.043718159198760986
Validation loss: 1.421752570777811

Epoch: 6| Step: 12
Training loss: 0.03996323049068451
Validation loss: 1.399007801086672

Epoch: 6| Step: 13
Training loss: 0.04936773329973221
Validation loss: 1.3977432917523127

Epoch: 787| Step: 0
Training loss: 0.07265271246433258
Validation loss: 1.4012540662160484

Epoch: 6| Step: 1
Training loss: 0.05237755924463272
Validation loss: 1.411413678558924

Epoch: 6| Step: 2
Training loss: 0.02811961993575096
Validation loss: 1.3851557970046997

Epoch: 6| Step: 3
Training loss: 0.01580154150724411
Validation loss: 1.38365642357898

Epoch: 6| Step: 4
Training loss: 0.03822238743305206
Validation loss: 1.370435542957757

Epoch: 6| Step: 5
Training loss: 0.0641210675239563
Validation loss: 1.3625909615588445

Epoch: 6| Step: 6
Training loss: 0.07968321442604065
Validation loss: 1.3479359707524698

Epoch: 6| Step: 7
Training loss: 0.030079606920480728
Validation loss: 1.3343470019678916

Epoch: 6| Step: 8
Training loss: 0.05558381974697113
Validation loss: 1.336567949223262

Epoch: 6| Step: 9
Training loss: 0.03155166283249855
Validation loss: 1.3276346101555774

Epoch: 6| Step: 10
Training loss: 0.04314017295837402
Validation loss: 1.3375096218560332

Epoch: 6| Step: 11
Training loss: 0.045640528202056885
Validation loss: 1.3479662031255744

Epoch: 6| Step: 12
Training loss: 0.054409272968769073
Validation loss: 1.3513392504825388

Epoch: 6| Step: 13
Training loss: 0.06778143346309662
Validation loss: 1.3567519008472402

Epoch: 788| Step: 0
Training loss: 0.059992291033267975
Validation loss: 1.3643723175089846

Epoch: 6| Step: 1
Training loss: 0.04021547734737396
Validation loss: 1.3875700145639398

Epoch: 6| Step: 2
Training loss: 0.026815537363290787
Validation loss: 1.396901556240615

Epoch: 6| Step: 3
Training loss: 0.0720779150724411
Validation loss: 1.4057339263218704

Epoch: 6| Step: 4
Training loss: 0.04348699375987053
Validation loss: 1.4032594157803444

Epoch: 6| Step: 5
Training loss: 0.07162589579820633
Validation loss: 1.4136314443362656

Epoch: 6| Step: 6
Training loss: 0.04363536834716797
Validation loss: 1.401599964146973

Epoch: 6| Step: 7
Training loss: 0.043755412101745605
Validation loss: 1.4070837702802432

Epoch: 6| Step: 8
Training loss: 0.04919017106294632
Validation loss: 1.4207506154173164

Epoch: 6| Step: 9
Training loss: 0.04754921793937683
Validation loss: 1.4039427772645028

Epoch: 6| Step: 10
Training loss: 0.044615089893341064
Validation loss: 1.406800103443925

Epoch: 6| Step: 11
Training loss: 0.07731713354587555
Validation loss: 1.4001498145441855

Epoch: 6| Step: 12
Training loss: 0.03950294852256775
Validation loss: 1.4158376455307007

Epoch: 6| Step: 13
Training loss: 0.03295165300369263
Validation loss: 1.380241262015476

Epoch: 789| Step: 0
Training loss: 0.02732989937067032
Validation loss: 1.3555843727563017

Epoch: 6| Step: 1
Training loss: 0.04384954646229744
Validation loss: 1.3322776120196107

Epoch: 6| Step: 2
Training loss: 0.07789446413516998
Validation loss: 1.3458785036558747

Epoch: 6| Step: 3
Training loss: 0.040840283036231995
Validation loss: 1.3599531176269695

Epoch: 6| Step: 4
Training loss: 0.04740632325410843
Validation loss: 1.3862969452334988

Epoch: 6| Step: 5
Training loss: 0.018278541043400764
Validation loss: 1.3683216507716844

Epoch: 6| Step: 6
Training loss: 0.026205390691757202
Validation loss: 1.3917029134688839

Epoch: 6| Step: 7
Training loss: 0.07776527106761932
Validation loss: 1.3846653930602535

Epoch: 6| Step: 8
Training loss: 0.03427153453230858
Validation loss: 1.3930467021080755

Epoch: 6| Step: 9
Training loss: 0.056904762983322144
Validation loss: 1.3921215136845906

Epoch: 6| Step: 10
Training loss: 0.059875912964344025
Validation loss: 1.4096428835263817

Epoch: 6| Step: 11
Training loss: 0.0647396519780159
Validation loss: 1.3992920678148988

Epoch: 6| Step: 12
Training loss: 0.04171012341976166
Validation loss: 1.4055933670331073

Epoch: 6| Step: 13
Training loss: 0.04896678030490875
Validation loss: 1.4149118238879788

Epoch: 790| Step: 0
Training loss: 0.03962220996618271
Validation loss: 1.4358416616275747

Epoch: 6| Step: 1
Training loss: 0.04927699267864227
Validation loss: 1.4356724357092252

Epoch: 6| Step: 2
Training loss: 0.07406766712665558
Validation loss: 1.4377872597786687

Epoch: 6| Step: 3
Training loss: 0.07074999809265137
Validation loss: 1.4284131206491941

Epoch: 6| Step: 4
Training loss: 0.05870819836854935
Validation loss: 1.4116754019132225

Epoch: 6| Step: 5
Training loss: 0.05296468734741211
Validation loss: 1.4029423376565338

Epoch: 6| Step: 6
Training loss: 0.03795096278190613
Validation loss: 1.4081128053767706

Epoch: 6| Step: 7
Training loss: 0.04223755747079849
Validation loss: 1.3728347516828967

Epoch: 6| Step: 8
Training loss: 0.060943081974983215
Validation loss: 1.3930157820383708

Epoch: 6| Step: 9
Training loss: 0.03094693087041378
Validation loss: 1.3764646271223664

Epoch: 6| Step: 10
Training loss: 0.040302809327840805
Validation loss: 1.3582406736189319

Epoch: 6| Step: 11
Training loss: 0.06457317620515823
Validation loss: 1.3362586536715109

Epoch: 6| Step: 12
Training loss: 0.02413996309041977
Validation loss: 1.3493023264792658

Epoch: 6| Step: 13
Training loss: 0.08008752763271332
Validation loss: 1.3562200787246868

Epoch: 791| Step: 0
Training loss: 0.0307566300034523
Validation loss: 1.3239694705573462

Epoch: 6| Step: 1
Training loss: 0.050193365663290024
Validation loss: 1.3463297364532307

Epoch: 6| Step: 2
Training loss: 0.03868406265974045
Validation loss: 1.3543309832131991

Epoch: 6| Step: 3
Training loss: 0.07784555107355118
Validation loss: 1.3625481814466498

Epoch: 6| Step: 4
Training loss: 0.07026839256286621
Validation loss: 1.3490605649127756

Epoch: 6| Step: 5
Training loss: 0.06886942684650421
Validation loss: 1.363458119412904

Epoch: 6| Step: 6
Training loss: 0.03901875764131546
Validation loss: 1.366275841189969

Epoch: 6| Step: 7
Training loss: 0.05360174924135208
Validation loss: 1.3657900902532762

Epoch: 6| Step: 8
Training loss: 0.04770691692829132
Validation loss: 1.3828420985129573

Epoch: 6| Step: 9
Training loss: 0.05909240245819092
Validation loss: 1.4182511260432582

Epoch: 6| Step: 10
Training loss: 0.021457944065332413
Validation loss: 1.4181220653236553

Epoch: 6| Step: 11
Training loss: 0.10848100483417511
Validation loss: 1.4531121612876974

Epoch: 6| Step: 12
Training loss: 0.027127563953399658
Validation loss: 1.445887307966909

Epoch: 6| Step: 13
Training loss: 0.10805834084749222
Validation loss: 1.4555063811681603

Epoch: 792| Step: 0
Training loss: 0.06074205040931702
Validation loss: 1.4066688530547644

Epoch: 6| Step: 1
Training loss: 0.05087289959192276
Validation loss: 1.3969066014853857

Epoch: 6| Step: 2
Training loss: 0.06658946722745895
Validation loss: 1.3787600994110107

Epoch: 6| Step: 3
Training loss: 0.013669803738594055
Validation loss: 1.3693386816209363

Epoch: 6| Step: 4
Training loss: 0.073454849421978
Validation loss: 1.350365755378559

Epoch: 6| Step: 5
Training loss: 0.07622324675321579
Validation loss: 1.350681471568282

Epoch: 6| Step: 6
Training loss: 0.08033052086830139
Validation loss: 1.3604326446851094

Epoch: 6| Step: 7
Training loss: 0.05497024208307266
Validation loss: 1.3607470784136044

Epoch: 6| Step: 8
Training loss: 0.06598398834466934
Validation loss: 1.356549080982003

Epoch: 6| Step: 9
Training loss: 0.08388523757457733
Validation loss: 1.366638006702546

Epoch: 6| Step: 10
Training loss: 0.04553701728582382
Validation loss: 1.3793438365382533

Epoch: 6| Step: 11
Training loss: 0.08246243000030518
Validation loss: 1.3914306663697766

Epoch: 6| Step: 12
Training loss: 0.0942845344543457
Validation loss: 1.3730244284035058

Epoch: 6| Step: 13
Training loss: 0.07117666304111481
Validation loss: 1.3759611614288823

Epoch: 793| Step: 0
Training loss: 0.06470077484846115
Validation loss: 1.3733767142859838

Epoch: 6| Step: 1
Training loss: 0.07278935611248016
Validation loss: 1.3697903899736301

Epoch: 6| Step: 2
Training loss: 0.06348428130149841
Validation loss: 1.3723980739552488

Epoch: 6| Step: 3
Training loss: 0.07269987463951111
Validation loss: 1.3536257090107087

Epoch: 6| Step: 4
Training loss: 0.03138390928506851
Validation loss: 1.3339624327998008

Epoch: 6| Step: 5
Training loss: 0.06763693690299988
Validation loss: 1.3496981461842854

Epoch: 6| Step: 6
Training loss: 0.07358498126268387
Validation loss: 1.3761566492819017

Epoch: 6| Step: 7
Training loss: 0.030579587444663048
Validation loss: 1.3390257409823838

Epoch: 6| Step: 8
Training loss: 0.0789206251502037
Validation loss: 1.3518641520571966

Epoch: 6| Step: 9
Training loss: 0.043448083102703094
Validation loss: 1.3539838995984805

Epoch: 6| Step: 10
Training loss: 0.0773378387093544
Validation loss: 1.35833179566168

Epoch: 6| Step: 11
Training loss: 0.04160595312714577
Validation loss: 1.356616618812725

Epoch: 6| Step: 12
Training loss: 0.025219757109880447
Validation loss: 1.3465373528900968

Epoch: 6| Step: 13
Training loss: 0.059300024062395096
Validation loss: 1.3307943587662072

Epoch: 794| Step: 0
Training loss: 0.03284388780593872
Validation loss: 1.3533747824289466

Epoch: 6| Step: 1
Training loss: 0.04921604320406914
Validation loss: 1.3597745113475348

Epoch: 6| Step: 2
Training loss: 0.0650305449962616
Validation loss: 1.3950504859288533

Epoch: 6| Step: 3
Training loss: 0.0838233232498169
Validation loss: 1.3833987982042375

Epoch: 6| Step: 4
Training loss: 0.02130594104528427
Validation loss: 1.3806292754347607

Epoch: 6| Step: 5
Training loss: 0.048354633152484894
Validation loss: 1.3538408510146602

Epoch: 6| Step: 6
Training loss: 0.04650788754224777
Validation loss: 1.3499470513354066

Epoch: 6| Step: 7
Training loss: 0.08324973285198212
Validation loss: 1.3423390401306974

Epoch: 6| Step: 8
Training loss: 0.048071712255477905
Validation loss: 1.3216589106026517

Epoch: 6| Step: 9
Training loss: 0.04233813285827637
Validation loss: 1.3415661627246487

Epoch: 6| Step: 10
Training loss: 0.074327751994133
Validation loss: 1.3321409776646604

Epoch: 6| Step: 11
Training loss: 0.07093826681375504
Validation loss: 1.3358555583543674

Epoch: 6| Step: 12
Training loss: 0.02711666375398636
Validation loss: 1.3429554200941516

Epoch: 6| Step: 13
Training loss: 0.10906892269849777
Validation loss: 1.3681261283095165

Epoch: 795| Step: 0
Training loss: 0.06494034081697464
Validation loss: 1.3514718945308397

Epoch: 6| Step: 1
Training loss: 0.07463435083627701
Validation loss: 1.354166200084071

Epoch: 6| Step: 2
Training loss: 0.051188647747039795
Validation loss: 1.3330134050820464

Epoch: 6| Step: 3
Training loss: 0.03834206983447075
Validation loss: 1.351016172798731

Epoch: 6| Step: 4
Training loss: 0.02558375522494316
Validation loss: 1.351263516692705

Epoch: 6| Step: 5
Training loss: 0.03308290243148804
Validation loss: 1.344096500386474

Epoch: 6| Step: 6
Training loss: 0.054412007331848145
Validation loss: 1.3540175063635713

Epoch: 6| Step: 7
Training loss: 0.03925139829516411
Validation loss: 1.3668270290538829

Epoch: 6| Step: 8
Training loss: 0.0788215845823288
Validation loss: 1.3638673360629747

Epoch: 6| Step: 9
Training loss: 0.05942566692829132
Validation loss: 1.3768085792500486

Epoch: 6| Step: 10
Training loss: 0.05350930988788605
Validation loss: 1.3674853001871417

Epoch: 6| Step: 11
Training loss: 0.06376795470714569
Validation loss: 1.3663772716317126

Epoch: 6| Step: 12
Training loss: 0.057594481855630875
Validation loss: 1.357817929919048

Epoch: 6| Step: 13
Training loss: 0.07269341498613358
Validation loss: 1.3459285100301106

Epoch: 796| Step: 0
Training loss: 0.06005287915468216
Validation loss: 1.3589156340527278

Epoch: 6| Step: 1
Training loss: 0.03594071418046951
Validation loss: 1.375467029950952

Epoch: 6| Step: 2
Training loss: 0.01783740147948265
Validation loss: 1.3666988867585377

Epoch: 6| Step: 3
Training loss: 0.03949355334043503
Validation loss: 1.3772560896412018

Epoch: 6| Step: 4
Training loss: 0.048870526254177094
Validation loss: 1.374185380115304

Epoch: 6| Step: 5
Training loss: 0.0661470890045166
Validation loss: 1.4004352310652375

Epoch: 6| Step: 6
Training loss: 0.060357339680194855
Validation loss: 1.4210577023926603

Epoch: 6| Step: 7
Training loss: 0.07579301297664642
Validation loss: 1.4149166268687094

Epoch: 6| Step: 8
Training loss: 0.06864108145236969
Validation loss: 1.416582295971532

Epoch: 6| Step: 9
Training loss: 0.04345198720693588
Validation loss: 1.3991048220665223

Epoch: 6| Step: 10
Training loss: 0.0446530357003212
Validation loss: 1.3958919650764876

Epoch: 6| Step: 11
Training loss: 0.03179113194346428
Validation loss: 1.3704185960113362

Epoch: 6| Step: 12
Training loss: 0.08517022430896759
Validation loss: 1.3511371804821877

Epoch: 6| Step: 13
Training loss: 0.03855292126536369
Validation loss: 1.3710070758737543

Epoch: 797| Step: 0
Training loss: 0.06726446002721786
Validation loss: 1.3431240268932876

Epoch: 6| Step: 1
Training loss: 0.03912397474050522
Validation loss: 1.3433974599966438

Epoch: 6| Step: 2
Training loss: 0.0539739653468132
Validation loss: 1.3169104591492684

Epoch: 6| Step: 3
Training loss: 0.0668255090713501
Validation loss: 1.3206644558137464

Epoch: 6| Step: 4
Training loss: 0.0729694813489914
Validation loss: 1.3257068331523607

Epoch: 6| Step: 5
Training loss: 0.0548371896147728
Validation loss: 1.322470945696677

Epoch: 6| Step: 6
Training loss: 0.04759246110916138
Validation loss: 1.3515197448833014

Epoch: 6| Step: 7
Training loss: 0.07840010523796082
Validation loss: 1.375481197910924

Epoch: 6| Step: 8
Training loss: 0.08689770847558975
Validation loss: 1.3606788740363172

Epoch: 6| Step: 9
Training loss: 0.02803732454776764
Validation loss: 1.331727252211622

Epoch: 6| Step: 10
Training loss: 0.03928304463624954
Validation loss: 1.3516930277629564

Epoch: 6| Step: 11
Training loss: 0.08263550698757172
Validation loss: 1.328064041752969

Epoch: 6| Step: 12
Training loss: 0.04981395602226257
Validation loss: 1.3283162463095881

Epoch: 6| Step: 13
Training loss: 0.03184731677174568
Validation loss: 1.3524967188476233

Epoch: 798| Step: 0
Training loss: 0.05237835273146629
Validation loss: 1.340624528546487

Epoch: 6| Step: 1
Training loss: 0.07771334052085876
Validation loss: 1.3276941494275165

Epoch: 6| Step: 2
Training loss: 0.026437796652317047
Validation loss: 1.343866644367095

Epoch: 6| Step: 3
Training loss: 0.03987719863653183
Validation loss: 1.3468534690077587

Epoch: 6| Step: 4
Training loss: 0.04962320625782013
Validation loss: 1.3343577205493886

Epoch: 6| Step: 5
Training loss: 0.054901063442230225
Validation loss: 1.3336987303149315

Epoch: 6| Step: 6
Training loss: 0.032217901200056076
Validation loss: 1.3227546714967298

Epoch: 6| Step: 7
Training loss: 0.05021722614765167
Validation loss: 1.3363334671143563

Epoch: 6| Step: 8
Training loss: 0.024381553754210472
Validation loss: 1.3515942814529582

Epoch: 6| Step: 9
Training loss: 0.054127421230077744
Validation loss: 1.3595664546053896

Epoch: 6| Step: 10
Training loss: 0.07011990994215012
Validation loss: 1.3443651955614808

Epoch: 6| Step: 11
Training loss: 0.09902528673410416
Validation loss: 1.3520975023187616

Epoch: 6| Step: 12
Training loss: 0.068830206990242
Validation loss: 1.325608343206426

Epoch: 6| Step: 13
Training loss: 0.11949817091226578
Validation loss: 1.3370212983059626

Epoch: 799| Step: 0
Training loss: 0.01883552223443985
Validation loss: 1.329194199654364

Epoch: 6| Step: 1
Training loss: 0.06769781559705734
Validation loss: 1.3186776509848974

Epoch: 6| Step: 2
Training loss: 0.06185796484351158
Validation loss: 1.3427392821158133

Epoch: 6| Step: 3
Training loss: 0.05606980249285698
Validation loss: 1.373758618549634

Epoch: 6| Step: 4
Training loss: 0.09374947100877762
Validation loss: 1.3840692568850774

Epoch: 6| Step: 5
Training loss: 0.04048622399568558
Validation loss: 1.4022834685540968

Epoch: 6| Step: 6
Training loss: 0.034096140414476395
Validation loss: 1.3979986303596086

Epoch: 6| Step: 7
Training loss: 0.05379832535982132
Validation loss: 1.4217175681103942

Epoch: 6| Step: 8
Training loss: 0.05293789505958557
Validation loss: 1.4350428081327868

Epoch: 6| Step: 9
Training loss: 0.03867701441049576
Validation loss: 1.4172154370174612

Epoch: 6| Step: 10
Training loss: 0.08941500633955002
Validation loss: 1.4026144012328117

Epoch: 6| Step: 11
Training loss: 0.05380260944366455
Validation loss: 1.4092752254137428

Epoch: 6| Step: 12
Training loss: 0.032449256628751755
Validation loss: 1.3643149457952028

Epoch: 6| Step: 13
Training loss: 0.059736914932727814
Validation loss: 1.3415194506286292

Epoch: 800| Step: 0
Training loss: 0.027352336794137955
Validation loss: 1.346378331543297

Epoch: 6| Step: 1
Training loss: 0.042168281972408295
Validation loss: 1.330684272832768

Epoch: 6| Step: 2
Training loss: 0.05097158998250961
Validation loss: 1.3500807464763682

Epoch: 6| Step: 3
Training loss: 0.035390790551900864
Validation loss: 1.3473522291388562

Epoch: 6| Step: 4
Training loss: 0.05466663837432861
Validation loss: 1.3679470336565407

Epoch: 6| Step: 5
Training loss: 0.04440484941005707
Validation loss: 1.3506469893199142

Epoch: 6| Step: 6
Training loss: 0.060997314751148224
Validation loss: 1.3616837096470658

Epoch: 6| Step: 7
Training loss: 0.038719452917575836
Validation loss: 1.370219842080147

Epoch: 6| Step: 8
Training loss: 0.06849736720323563
Validation loss: 1.3615608074331795

Epoch: 6| Step: 9
Training loss: 0.0533275380730629
Validation loss: 1.4032131433486938

Epoch: 6| Step: 10
Training loss: 0.0432969331741333
Validation loss: 1.4120122130199144

Epoch: 6| Step: 11
Training loss: 0.06610718369483948
Validation loss: 1.431183272792447

Epoch: 6| Step: 12
Training loss: 0.027058130130171776
Validation loss: 1.4205316587160992

Epoch: 6| Step: 13
Training loss: 0.04481665790081024
Validation loss: 1.4190975363536547

Testing loss: 2.0715512063768173
