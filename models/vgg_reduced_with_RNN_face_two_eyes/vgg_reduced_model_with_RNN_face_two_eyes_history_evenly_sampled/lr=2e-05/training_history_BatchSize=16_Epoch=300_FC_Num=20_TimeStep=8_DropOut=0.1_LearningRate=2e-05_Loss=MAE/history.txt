Epoch: 1| Step: 0
Training loss: 5.669303894042969
Validation loss: 5.246804545002599

Epoch: 6| Step: 1
Training loss: 4.123013019561768
Validation loss: 5.228650872425367

Epoch: 6| Step: 2
Training loss: 4.830294132232666
Validation loss: 5.213366021392166

Epoch: 6| Step: 3
Training loss: 5.315191745758057
Validation loss: 5.198674363474692

Epoch: 6| Step: 4
Training loss: 4.834965705871582
Validation loss: 5.183278878529866

Epoch: 6| Step: 5
Training loss: 4.688814163208008
Validation loss: 5.165495498206026

Epoch: 6| Step: 6
Training loss: 4.322114944458008
Validation loss: 5.1458450696801625

Epoch: 6| Step: 7
Training loss: 5.201581001281738
Validation loss: 5.122516750007548

Epoch: 6| Step: 8
Training loss: 4.353891372680664
Validation loss: 5.096523310548516

Epoch: 6| Step: 9
Training loss: 5.56536340713501
Validation loss: 5.0667480807150564

Epoch: 6| Step: 10
Training loss: 5.845996856689453
Validation loss: 5.033286653539186

Epoch: 6| Step: 11
Training loss: 5.224289417266846
Validation loss: 4.995922355241673

Epoch: 6| Step: 12
Training loss: 3.5119099617004395
Validation loss: 4.9550034974211

Epoch: 6| Step: 13
Training loss: 5.554683685302734
Validation loss: 4.909513637583743

Epoch: 2| Step: 0
Training loss: 4.639270782470703
Validation loss: 4.859375758837628

Epoch: 6| Step: 1
Training loss: 3.938288927078247
Validation loss: 4.805710577195691

Epoch: 6| Step: 2
Training loss: 4.437583923339844
Validation loss: 4.749353634413852

Epoch: 6| Step: 3
Training loss: 4.793246746063232
Validation loss: 4.690249976291452

Epoch: 6| Step: 4
Training loss: 4.693526744842529
Validation loss: 4.630724404447822

Epoch: 6| Step: 5
Training loss: 4.84507942199707
Validation loss: 4.566690080909319

Epoch: 6| Step: 6
Training loss: 3.2323670387268066
Validation loss: 4.504651079895676

Epoch: 6| Step: 7
Training loss: 4.139554977416992
Validation loss: 4.441237254809308

Epoch: 6| Step: 8
Training loss: 5.176910400390625
Validation loss: 4.379655966194727

Epoch: 6| Step: 9
Training loss: 4.110283851623535
Validation loss: 4.321669050442275

Epoch: 6| Step: 10
Training loss: 4.61842155456543
Validation loss: 4.267434427815099

Epoch: 6| Step: 11
Training loss: 3.441226005554199
Validation loss: 4.210850408000331

Epoch: 6| Step: 12
Training loss: 3.91454815864563
Validation loss: 4.156276272189233

Epoch: 6| Step: 13
Training loss: 3.7507340908050537
Validation loss: 4.104871167931505

Epoch: 3| Step: 0
Training loss: 4.506612777709961
Validation loss: 4.056452889596263

Epoch: 6| Step: 1
Training loss: 4.12005615234375
Validation loss: 4.006889681662282

Epoch: 6| Step: 2
Training loss: 3.6720919609069824
Validation loss: 3.961429811293079

Epoch: 6| Step: 3
Training loss: 4.724843978881836
Validation loss: 3.9229614196285123

Epoch: 6| Step: 4
Training loss: 3.9330735206604004
Validation loss: 3.8915437652218725

Epoch: 6| Step: 5
Training loss: 2.0968072414398193
Validation loss: 3.8667020003000894

Epoch: 6| Step: 6
Training loss: 4.031824588775635
Validation loss: 3.8496300430708033

Epoch: 6| Step: 7
Training loss: 2.8129677772521973
Validation loss: 3.8298969935345393

Epoch: 6| Step: 8
Training loss: 2.256019115447998
Validation loss: 3.8096799030098865

Epoch: 6| Step: 9
Training loss: 4.301826477050781
Validation loss: 3.7856614564054754

Epoch: 6| Step: 10
Training loss: 4.467612266540527
Validation loss: 3.7551592601242887

Epoch: 6| Step: 11
Training loss: 4.686595439910889
Validation loss: 3.734257503222394

Epoch: 6| Step: 12
Training loss: 3.094524383544922
Validation loss: 3.716524877855855

Epoch: 6| Step: 13
Training loss: 3.2212014198303223
Validation loss: 3.686713434034778

Epoch: 4| Step: 0
Training loss: 3.4358720779418945
Validation loss: 3.6650847465761247

Epoch: 6| Step: 1
Training loss: 2.7577548027038574
Validation loss: 3.6474253234042915

Epoch: 6| Step: 2
Training loss: 3.8135006427764893
Validation loss: 3.627845266813873

Epoch: 6| Step: 3
Training loss: 2.1757688522338867
Validation loss: 3.615437256392612

Epoch: 6| Step: 4
Training loss: 3.3558030128479004
Validation loss: 3.6120060772024174

Epoch: 6| Step: 5
Training loss: 4.113227844238281
Validation loss: 3.60314909104378

Epoch: 6| Step: 6
Training loss: 3.582477569580078
Validation loss: 3.5758780817831717

Epoch: 6| Step: 7
Training loss: 3.9729807376861572
Validation loss: 3.5564635184503373

Epoch: 6| Step: 8
Training loss: 2.5704169273376465
Validation loss: 3.5481245133184616

Epoch: 6| Step: 9
Training loss: 3.1209325790405273
Validation loss: 3.532969743974747

Epoch: 6| Step: 10
Training loss: 4.764946937561035
Validation loss: 3.5243068792486705

Epoch: 6| Step: 11
Training loss: 4.609137058258057
Validation loss: 3.510820988685854

Epoch: 6| Step: 12
Training loss: 2.3608999252319336
Validation loss: 3.5172098990409606

Epoch: 6| Step: 13
Training loss: 4.843087196350098
Validation loss: 3.483775164491387

Epoch: 5| Step: 0
Training loss: 3.1686882972717285
Validation loss: 3.480130434036255

Epoch: 6| Step: 1
Training loss: 4.333952903747559
Validation loss: 3.4803704548907537

Epoch: 6| Step: 2
Training loss: 2.2612338066101074
Validation loss: 3.466449470930202

Epoch: 6| Step: 3
Training loss: 3.3031394481658936
Validation loss: 3.454135587138514

Epoch: 6| Step: 4
Training loss: 3.8992257118225098
Validation loss: 3.435066020616921

Epoch: 6| Step: 5
Training loss: 2.968789577484131
Validation loss: 3.422478393841815

Epoch: 6| Step: 6
Training loss: 3.7644290924072266
Validation loss: 3.418602656292659

Epoch: 6| Step: 7
Training loss: 3.7536821365356445
Validation loss: 3.433230733358732

Epoch: 6| Step: 8
Training loss: 3.85990834236145
Validation loss: 3.4117459507398706

Epoch: 6| Step: 9
Training loss: 2.7410049438476562
Validation loss: 3.3860708231567056

Epoch: 6| Step: 10
Training loss: 2.5115768909454346
Validation loss: 3.3746104855691232

Epoch: 6| Step: 11
Training loss: 3.852522850036621
Validation loss: 3.368501535025976

Epoch: 6| Step: 12
Training loss: 2.837477207183838
Validation loss: 3.3612721453430834

Epoch: 6| Step: 13
Training loss: 4.249975681304932
Validation loss: 3.3527575641550045

Epoch: 6| Step: 0
Training loss: 3.646669387817383
Validation loss: 3.339596535569878

Epoch: 6| Step: 1
Training loss: 2.531250238418579
Validation loss: 3.324464480082194

Epoch: 6| Step: 2
Training loss: 3.458963394165039
Validation loss: 3.3169054754318728

Epoch: 6| Step: 3
Training loss: 3.3509063720703125
Validation loss: 3.3806798740099837

Epoch: 6| Step: 4
Training loss: 3.676048994064331
Validation loss: 3.400439077808011

Epoch: 6| Step: 5
Training loss: 3.6518678665161133
Validation loss: 3.3990368535441737

Epoch: 6| Step: 6
Training loss: 2.823212146759033
Validation loss: 3.3937244902374926

Epoch: 6| Step: 7
Training loss: 3.6707677841186523
Validation loss: 3.38588047540316

Epoch: 6| Step: 8
Training loss: 4.0071306228637695
Validation loss: 3.3768571679310133

Epoch: 6| Step: 9
Training loss: 2.793217658996582
Validation loss: 3.362686595609111

Epoch: 6| Step: 10
Training loss: 3.3758769035339355
Validation loss: 3.35283689601447

Epoch: 6| Step: 11
Training loss: 1.9555853605270386
Validation loss: 3.3504826971279678

Epoch: 6| Step: 12
Training loss: 4.08392333984375
Validation loss: 3.3625709779800905

Epoch: 6| Step: 13
Training loss: 3.6444597244262695
Validation loss: 3.3363488745945755

Epoch: 7| Step: 0
Training loss: 2.888483762741089
Validation loss: 3.328753596992903

Epoch: 6| Step: 1
Training loss: 3.0372822284698486
Validation loss: 3.3170101924609114

Epoch: 6| Step: 2
Training loss: 3.4009554386138916
Validation loss: 3.306473449994159

Epoch: 6| Step: 3
Training loss: 3.6887121200561523
Validation loss: 3.301666053392554

Epoch: 6| Step: 4
Training loss: 3.576024055480957
Validation loss: 3.2971138108161187

Epoch: 6| Step: 5
Training loss: 3.072471857070923
Validation loss: 3.290917468327348

Epoch: 6| Step: 6
Training loss: 3.8855247497558594
Validation loss: 3.2830070654551187

Epoch: 6| Step: 7
Training loss: 3.4980459213256836
Validation loss: 3.2742276396802676

Epoch: 6| Step: 8
Training loss: 3.625779628753662
Validation loss: 3.2665223972771757

Epoch: 6| Step: 9
Training loss: 3.1235382556915283
Validation loss: 3.257440374743554

Epoch: 6| Step: 10
Training loss: 3.1768293380737305
Validation loss: 3.2513065261225544

Epoch: 6| Step: 11
Training loss: 2.203312397003174
Validation loss: 3.2440693609176146

Epoch: 6| Step: 12
Training loss: 2.9247400760650635
Validation loss: 3.236224059135683

Epoch: 6| Step: 13
Training loss: 3.7026278972625732
Validation loss: 3.2325413893627863

Epoch: 8| Step: 0
Training loss: 2.729245185852051
Validation loss: 3.2257222539635113

Epoch: 6| Step: 1
Training loss: 2.7110137939453125
Validation loss: 3.216358753942674

Epoch: 6| Step: 2
Training loss: 3.172577142715454
Validation loss: 3.213932534699799

Epoch: 6| Step: 3
Training loss: 3.2678747177124023
Validation loss: 3.2087831907374884

Epoch: 6| Step: 4
Training loss: 4.422268867492676
Validation loss: 3.2048490483273744

Epoch: 6| Step: 5
Training loss: 3.0387320518493652
Validation loss: 3.197137104567661

Epoch: 6| Step: 6
Training loss: 2.5598251819610596
Validation loss: 3.192462231523247

Epoch: 6| Step: 7
Training loss: 4.094176292419434
Validation loss: 3.1878408514043337

Epoch: 6| Step: 8
Training loss: 3.528454542160034
Validation loss: 3.181751202511531

Epoch: 6| Step: 9
Training loss: 2.859091281890869
Validation loss: 3.1762399878553165

Epoch: 6| Step: 10
Training loss: 3.40570068359375
Validation loss: 3.170596920033937

Epoch: 6| Step: 11
Training loss: 2.3564183712005615
Validation loss: 3.1624047628013034

Epoch: 6| Step: 12
Training loss: 3.6190555095672607
Validation loss: 3.1586768524621123

Epoch: 6| Step: 13
Training loss: 2.7037439346313477
Validation loss: 3.152377010673605

Epoch: 9| Step: 0
Training loss: 4.340898513793945
Validation loss: 3.1443918546040854

Epoch: 6| Step: 1
Training loss: 3.416316270828247
Validation loss: 3.134389708119054

Epoch: 6| Step: 2
Training loss: 2.815053701400757
Validation loss: 3.12687837436635

Epoch: 6| Step: 3
Training loss: 3.131366491317749
Validation loss: 3.1181377698016424

Epoch: 6| Step: 4
Training loss: 4.398617744445801
Validation loss: 3.1119564169196674

Epoch: 6| Step: 5
Training loss: 2.9582927227020264
Validation loss: 3.102844868936846

Epoch: 6| Step: 6
Training loss: 2.9153380393981934
Validation loss: 3.099621688165972

Epoch: 6| Step: 7
Training loss: 3.3962647914886475
Validation loss: 3.092467290098949

Epoch: 6| Step: 8
Training loss: 2.6175975799560547
Validation loss: 3.084348581170523

Epoch: 6| Step: 9
Training loss: 2.998164176940918
Validation loss: 3.0766755278392504

Epoch: 6| Step: 10
Training loss: 2.2541608810424805
Validation loss: 3.0740043629882154

Epoch: 6| Step: 11
Training loss: 2.4340550899505615
Validation loss: 3.0688538423148533

Epoch: 6| Step: 12
Training loss: 3.137516498565674
Validation loss: 3.0653030769799345

Epoch: 6| Step: 13
Training loss: 3.0096428394317627
Validation loss: 3.0598768008652555

Epoch: 10| Step: 0
Training loss: 3.846500873565674
Validation loss: 3.049471632126839

Epoch: 6| Step: 1
Training loss: 2.810055732727051
Validation loss: 3.0377844379794214

Epoch: 6| Step: 2
Training loss: 2.764261245727539
Validation loss: 3.03289391404839

Epoch: 6| Step: 3
Training loss: 3.6205129623413086
Validation loss: 3.031273308620658

Epoch: 6| Step: 4
Training loss: 3.56254243850708
Validation loss: 3.018834052547332

Epoch: 6| Step: 5
Training loss: 2.8315372467041016
Validation loss: 3.0168374200021066

Epoch: 6| Step: 6
Training loss: 2.5903396606445312
Validation loss: 3.01104445867641

Epoch: 6| Step: 7
Training loss: 2.0608255863189697
Validation loss: 3.0072931628073416

Epoch: 6| Step: 8
Training loss: 3.2319958209991455
Validation loss: 2.997041271578881

Epoch: 6| Step: 9
Training loss: 2.2165110111236572
Validation loss: 2.9955086297886346

Epoch: 6| Step: 10
Training loss: 2.9137330055236816
Validation loss: 2.9929848512013755

Epoch: 6| Step: 11
Training loss: 4.3550801277160645
Validation loss: 2.992484108094246

Epoch: 6| Step: 12
Training loss: 2.809985876083374
Validation loss: 2.985700712409071

Epoch: 6| Step: 13
Training loss: 3.73152756690979
Validation loss: 2.982197287262127

Epoch: 11| Step: 0
Training loss: 2.220484972000122
Validation loss: 2.974742140821231

Epoch: 6| Step: 1
Training loss: 3.0688743591308594
Validation loss: 2.970171046513383

Epoch: 6| Step: 2
Training loss: 3.8745508193969727
Validation loss: 2.964865933182419

Epoch: 6| Step: 3
Training loss: 3.0028786659240723
Validation loss: 2.960389849960163

Epoch: 6| Step: 4
Training loss: 3.6199309825897217
Validation loss: 2.9574243663459696

Epoch: 6| Step: 5
Training loss: 3.1532158851623535
Validation loss: 2.9618297161594516

Epoch: 6| Step: 6
Training loss: 2.6664175987243652
Validation loss: 2.9647476596217

Epoch: 6| Step: 7
Training loss: 3.1732988357543945
Validation loss: 2.9577611031070834

Epoch: 6| Step: 8
Training loss: 2.8010377883911133
Validation loss: 2.9465170316798712

Epoch: 6| Step: 9
Training loss: 3.0122811794281006
Validation loss: 2.9427256712349514

Epoch: 6| Step: 10
Training loss: 3.0608346462249756
Validation loss: 2.9367607742227535

Epoch: 6| Step: 11
Training loss: 4.009454250335693
Validation loss: 2.9309897140790055

Epoch: 6| Step: 12
Training loss: 2.3420772552490234
Validation loss: 2.9262972442052697

Epoch: 6| Step: 13
Training loss: 2.0131890773773193
Validation loss: 2.9214173029827815

Epoch: 12| Step: 0
Training loss: 3.151022434234619
Validation loss: 2.923054572074644

Epoch: 6| Step: 1
Training loss: 3.369112968444824
Validation loss: 2.9167830456969557

Epoch: 6| Step: 2
Training loss: 3.2302279472351074
Validation loss: 2.907452403858144

Epoch: 6| Step: 3
Training loss: 2.8291378021240234
Validation loss: 2.902531326458018

Epoch: 6| Step: 4
Training loss: 2.8151440620422363
Validation loss: 2.899276925671485

Epoch: 6| Step: 5
Training loss: 3.8409152030944824
Validation loss: 2.908896553900934

Epoch: 6| Step: 6
Training loss: 2.296466827392578
Validation loss: 2.8860571692066808

Epoch: 6| Step: 7
Training loss: 2.2643325328826904
Validation loss: 2.8844781716664634

Epoch: 6| Step: 8
Training loss: 2.3188211917877197
Validation loss: 2.8861318993312057

Epoch: 6| Step: 9
Training loss: 3.3998796939849854
Validation loss: 2.88210436349274

Epoch: 6| Step: 10
Training loss: 3.1332263946533203
Validation loss: 2.8750894582399757

Epoch: 6| Step: 11
Training loss: 3.5409016609191895
Validation loss: 2.8751917885195826

Epoch: 6| Step: 12
Training loss: 2.5973477363586426
Validation loss: 2.868764797846476

Epoch: 6| Step: 13
Training loss: 3.2016892433166504
Validation loss: 2.873551227713144

Epoch: 13| Step: 0
Training loss: 2.823256015777588
Validation loss: 2.8865952773760726

Epoch: 6| Step: 1
Training loss: 3.7987241744995117
Validation loss: 2.8633649374849055

Epoch: 6| Step: 2
Training loss: 2.2266435623168945
Validation loss: 2.8546652588793027

Epoch: 6| Step: 3
Training loss: 2.8204214572906494
Validation loss: 2.860781502980058

Epoch: 6| Step: 4
Training loss: 3.3684566020965576
Validation loss: 2.860009131893035

Epoch: 6| Step: 5
Training loss: 2.200554847717285
Validation loss: 2.848027306218301

Epoch: 6| Step: 6
Training loss: 3.141061544418335
Validation loss: 2.8500252462202504

Epoch: 6| Step: 7
Training loss: 3.2841415405273438
Validation loss: 2.862441614109983

Epoch: 6| Step: 8
Training loss: 3.082892417907715
Validation loss: 2.858734405168923

Epoch: 6| Step: 9
Training loss: 3.2597055435180664
Validation loss: 2.85228326243739

Epoch: 6| Step: 10
Training loss: 2.762322425842285
Validation loss: 2.8478973296380814

Epoch: 6| Step: 11
Training loss: 2.573246479034424
Validation loss: 2.840726455052694

Epoch: 6| Step: 12
Training loss: 3.045799732208252
Validation loss: 2.8405878492580947

Epoch: 6| Step: 13
Training loss: 3.3302829265594482
Validation loss: 2.8365222305379887

Epoch: 14| Step: 0
Training loss: 1.794856309890747
Validation loss: 2.834274794465752

Epoch: 6| Step: 1
Training loss: 2.377002000808716
Validation loss: 2.834894564843947

Epoch: 6| Step: 2
Training loss: 2.9972286224365234
Validation loss: 2.8462945594582507

Epoch: 6| Step: 3
Training loss: 3.1716532707214355
Validation loss: 2.825680030289517

Epoch: 6| Step: 4
Training loss: 3.2569174766540527
Validation loss: 2.827753054198398

Epoch: 6| Step: 5
Training loss: 2.9219870567321777
Validation loss: 2.825715257275489

Epoch: 6| Step: 6
Training loss: 3.4641497135162354
Validation loss: 2.8304517551134993

Epoch: 6| Step: 7
Training loss: 3.050504684448242
Validation loss: 2.825556362828901

Epoch: 6| Step: 8
Training loss: 3.027008056640625
Validation loss: 2.8220156418379916

Epoch: 6| Step: 9
Training loss: 2.6577720642089844
Validation loss: 2.8196056068584485

Epoch: 6| Step: 10
Training loss: 2.2900686264038086
Validation loss: 2.818980050343339

Epoch: 6| Step: 11
Training loss: 4.13425874710083
Validation loss: 2.818706145850561

Epoch: 6| Step: 12
Training loss: 2.955862045288086
Validation loss: 2.815897264788228

Epoch: 6| Step: 13
Training loss: 3.416382312774658
Validation loss: 2.8134874079817083

Epoch: 15| Step: 0
Training loss: 2.9589388370513916
Validation loss: 2.8130774395440215

Epoch: 6| Step: 1
Training loss: 2.2735471725463867
Validation loss: 2.8129624294978317

Epoch: 6| Step: 2
Training loss: 3.1693198680877686
Validation loss: 2.815359925711027

Epoch: 6| Step: 3
Training loss: 4.141854286193848
Validation loss: 2.8118760047420377

Epoch: 6| Step: 4
Training loss: 3.743882417678833
Validation loss: 2.797847640129828

Epoch: 6| Step: 5
Training loss: 2.137603282928467
Validation loss: 2.797701668995683

Epoch: 6| Step: 6
Training loss: 2.1767077445983887
Validation loss: 2.8001084814789476

Epoch: 6| Step: 7
Training loss: 2.394237756729126
Validation loss: 2.8015327991977816

Epoch: 6| Step: 8
Training loss: 2.854926824569702
Validation loss: 2.8070070717924382

Epoch: 6| Step: 9
Training loss: 3.009394407272339
Validation loss: 2.7962020853514313

Epoch: 6| Step: 10
Training loss: 3.26497745513916
Validation loss: 2.797886727958597

Epoch: 6| Step: 11
Training loss: 3.2821578979492188
Validation loss: 2.79573235460507

Epoch: 6| Step: 12
Training loss: 3.10433292388916
Validation loss: 2.7894678269663165

Epoch: 6| Step: 13
Training loss: 2.272730827331543
Validation loss: 2.7875560919443765

Epoch: 16| Step: 0
Training loss: 2.7851343154907227
Validation loss: 2.78508484748102

Epoch: 6| Step: 1
Training loss: 3.7007663249969482
Validation loss: 2.786048840450984

Epoch: 6| Step: 2
Training loss: 3.652862548828125
Validation loss: 2.7853248068081435

Epoch: 6| Step: 3
Training loss: 2.4484481811523438
Validation loss: 2.7831860601261096

Epoch: 6| Step: 4
Training loss: 2.9505019187927246
Validation loss: 2.781631600472235

Epoch: 6| Step: 5
Training loss: 3.744255304336548
Validation loss: 2.7824318665330128

Epoch: 6| Step: 6
Training loss: 3.0411243438720703
Validation loss: 2.7787803680666032

Epoch: 6| Step: 7
Training loss: 3.2429730892181396
Validation loss: 2.7809763518712853

Epoch: 6| Step: 8
Training loss: 1.834489345550537
Validation loss: 2.778320727809783

Epoch: 6| Step: 9
Training loss: 2.377903699874878
Validation loss: 2.777582264715625

Epoch: 6| Step: 10
Training loss: 3.428868532180786
Validation loss: 2.7750675652616765

Epoch: 6| Step: 11
Training loss: 2.868594169616699
Validation loss: 2.772068974792316

Epoch: 6| Step: 12
Training loss: 2.1640467643737793
Validation loss: 2.7710683679067962

Epoch: 6| Step: 13
Training loss: 2.445829153060913
Validation loss: 2.770203713447817

Epoch: 17| Step: 0
Training loss: 2.591857433319092
Validation loss: 2.769176693372829

Epoch: 6| Step: 1
Training loss: 3.009484052658081
Validation loss: 2.7687745940300728

Epoch: 6| Step: 2
Training loss: 3.793407917022705
Validation loss: 2.768958704445952

Epoch: 6| Step: 3
Training loss: 2.350980281829834
Validation loss: 2.7676061276466615

Epoch: 6| Step: 4
Training loss: 3.200991630554199
Validation loss: 2.766580597046883

Epoch: 6| Step: 5
Training loss: 2.959300994873047
Validation loss: 2.7628328108018443

Epoch: 6| Step: 6
Training loss: 2.819624423980713
Validation loss: 2.7656394512422624

Epoch: 6| Step: 7
Training loss: 2.788356304168701
Validation loss: 2.767270862415273

Epoch: 6| Step: 8
Training loss: 2.9730210304260254
Validation loss: 2.7636007621724117

Epoch: 6| Step: 9
Training loss: 2.8062291145324707
Validation loss: 2.761633285912134

Epoch: 6| Step: 10
Training loss: 2.146895170211792
Validation loss: 2.760739193167738

Epoch: 6| Step: 11
Training loss: 2.8421549797058105
Validation loss: 2.7605961086929485

Epoch: 6| Step: 12
Training loss: 3.351804494857788
Validation loss: 2.7593608697255454

Epoch: 6| Step: 13
Training loss: 3.3012678623199463
Validation loss: 2.7623192443642566

Epoch: 18| Step: 0
Training loss: 2.2624263763427734
Validation loss: 2.7627965839960242

Epoch: 6| Step: 1
Training loss: 3.6628475189208984
Validation loss: 2.7578798288940103

Epoch: 6| Step: 2
Training loss: 3.1886610984802246
Validation loss: 2.7792747020721436

Epoch: 6| Step: 3
Training loss: 3.168760061264038
Validation loss: 2.7597730005941083

Epoch: 6| Step: 4
Training loss: 2.190070629119873
Validation loss: 2.7522231789045435

Epoch: 6| Step: 5
Training loss: 3.2344918251037598
Validation loss: 2.7465249723003757

Epoch: 6| Step: 6
Training loss: 3.85366153717041
Validation loss: 2.749028657072334

Epoch: 6| Step: 7
Training loss: 2.625096321105957
Validation loss: 2.750198438603391

Epoch: 6| Step: 8
Training loss: 2.592740535736084
Validation loss: 2.761091693755119

Epoch: 6| Step: 9
Training loss: 2.6488161087036133
Validation loss: 2.7996379995858796

Epoch: 6| Step: 10
Training loss: 3.196415901184082
Validation loss: 2.773259003957113

Epoch: 6| Step: 11
Training loss: 1.9261274337768555
Validation loss: 2.741359544056718

Epoch: 6| Step: 12
Training loss: 3.277691125869751
Validation loss: 2.741769713740195

Epoch: 6| Step: 13
Training loss: 2.8965578079223633
Validation loss: 2.78849426392586

Epoch: 19| Step: 0
Training loss: 2.9715559482574463
Validation loss: 2.7899081399363856

Epoch: 6| Step: 1
Training loss: 2.5665132999420166
Validation loss: 2.746341000321091

Epoch: 6| Step: 2
Training loss: 3.098100185394287
Validation loss: 2.7375280190539617

Epoch: 6| Step: 3
Training loss: 2.417023181915283
Validation loss: 2.7406540455356723

Epoch: 6| Step: 4
Training loss: 2.7459373474121094
Validation loss: 2.74429682249664

Epoch: 6| Step: 5
Training loss: 3.2446365356445312
Validation loss: 2.747143245512439

Epoch: 6| Step: 6
Training loss: 3.2777276039123535
Validation loss: 2.7549242742599978

Epoch: 6| Step: 7
Training loss: 2.4782307147979736
Validation loss: 2.742406088818786

Epoch: 6| Step: 8
Training loss: 2.2798545360565186
Validation loss: 2.7376891182314966

Epoch: 6| Step: 9
Training loss: 2.947213888168335
Validation loss: 2.73508882522583

Epoch: 6| Step: 10
Training loss: 2.7279553413391113
Validation loss: 2.7332255199391353

Epoch: 6| Step: 11
Training loss: 3.3336124420166016
Validation loss: 2.737798749759633

Epoch: 6| Step: 12
Training loss: 3.241389274597168
Validation loss: 2.7388308099521104

Epoch: 6| Step: 13
Training loss: 3.499364137649536
Validation loss: 2.743331455415295

Epoch: 20| Step: 0
Training loss: 3.577866554260254
Validation loss: 2.7284727609285744

Epoch: 6| Step: 1
Training loss: 2.2683138847351074
Validation loss: 2.6729846744127173

Epoch: 6| Step: 2
Training loss: 3.054525852203369
Validation loss: 2.6768017891914613

Epoch: 6| Step: 3
Training loss: 3.2014126777648926
Validation loss: 2.678407492176179

Epoch: 6| Step: 4
Training loss: 3.2348828315734863
Validation loss: 2.6665274763620026

Epoch: 6| Step: 5
Training loss: 3.3605899810791016
Validation loss: 2.6603984243126324

Epoch: 6| Step: 6
Training loss: 2.948943853378296
Validation loss: 2.6620853870145735

Epoch: 6| Step: 7
Training loss: 2.2490501403808594
Validation loss: 2.667094184506324

Epoch: 6| Step: 8
Training loss: 2.8403539657592773
Validation loss: 2.7080147574024815

Epoch: 6| Step: 9
Training loss: 3.0058112144470215
Validation loss: 2.6787505534387406

Epoch: 6| Step: 10
Training loss: 2.818530559539795
Validation loss: 2.687812820557625

Epoch: 6| Step: 11
Training loss: 2.7494308948516846
Validation loss: 2.7034391331416305

Epoch: 6| Step: 12
Training loss: 2.400904655456543
Validation loss: 2.6949605762317614

Epoch: 6| Step: 13
Training loss: 1.700289249420166
Validation loss: 2.673398281938286

Epoch: 21| Step: 0
Training loss: 2.4922943115234375
Validation loss: 2.674719713067496

Epoch: 6| Step: 1
Training loss: 3.471400737762451
Validation loss: 2.670962543897731

Epoch: 6| Step: 2
Training loss: 2.5938143730163574
Validation loss: 2.6815494337389545

Epoch: 6| Step: 3
Training loss: 2.636399745941162
Validation loss: 2.6683629789660053

Epoch: 6| Step: 4
Training loss: 3.4264159202575684
Validation loss: 2.6727672007776078

Epoch: 6| Step: 5
Training loss: 2.739426612854004
Validation loss: 2.662639323101249

Epoch: 6| Step: 6
Training loss: 2.3599772453308105
Validation loss: 2.6609451873328096

Epoch: 6| Step: 7
Training loss: 2.9702341556549072
Validation loss: 2.65583303923248

Epoch: 6| Step: 8
Training loss: 2.9211642742156982
Validation loss: 2.6592867169328915

Epoch: 6| Step: 9
Training loss: 3.2626287937164307
Validation loss: 2.660258662316107

Epoch: 6| Step: 10
Training loss: 2.8068645000457764
Validation loss: 2.6589259409135386

Epoch: 6| Step: 11
Training loss: 2.459157943725586
Validation loss: 2.6528809224405596

Epoch: 6| Step: 12
Training loss: 2.3698627948760986
Validation loss: 2.652000911774174

Epoch: 6| Step: 13
Training loss: 3.7241697311401367
Validation loss: 2.6544396620924755

Epoch: 22| Step: 0
Training loss: 2.7078003883361816
Validation loss: 2.6566239249321724

Epoch: 6| Step: 1
Training loss: 2.216463088989258
Validation loss: 2.655617687009996

Epoch: 6| Step: 2
Training loss: 2.7348973751068115
Validation loss: 2.6440589812494095

Epoch: 6| Step: 3
Training loss: 2.7854294776916504
Validation loss: 2.6698085031201764

Epoch: 6| Step: 4
Training loss: 3.2612521648406982
Validation loss: 2.6436384724032496

Epoch: 6| Step: 5
Training loss: 2.527975082397461
Validation loss: 2.6497350738894556

Epoch: 6| Step: 6
Training loss: 2.5291523933410645
Validation loss: 2.6732701614338863

Epoch: 6| Step: 7
Training loss: 3.745271921157837
Validation loss: 2.668768923769715

Epoch: 6| Step: 8
Training loss: 3.001004695892334
Validation loss: 2.647451808375697

Epoch: 6| Step: 9
Training loss: 3.177442789077759
Validation loss: 2.6583759964153333

Epoch: 6| Step: 10
Training loss: 2.4306511878967285
Validation loss: 2.6787127346120854

Epoch: 6| Step: 11
Training loss: 3.05460786819458
Validation loss: 2.6530040489730013

Epoch: 6| Step: 12
Training loss: 2.597498655319214
Validation loss: 2.6508491372549408

Epoch: 6| Step: 13
Training loss: 3.2102038860321045
Validation loss: 2.6509559872329875

Epoch: 23| Step: 0
Training loss: 2.4200968742370605
Validation loss: 2.656496835011308

Epoch: 6| Step: 1
Training loss: 3.3474197387695312
Validation loss: 2.6572870592917166

Epoch: 6| Step: 2
Training loss: 2.973567485809326
Validation loss: 2.646752908665647

Epoch: 6| Step: 3
Training loss: 2.920604705810547
Validation loss: 2.641020897896059

Epoch: 6| Step: 4
Training loss: 2.235539436340332
Validation loss: 2.6370825280425367

Epoch: 6| Step: 5
Training loss: 2.7861266136169434
Validation loss: 2.638227698623493

Epoch: 6| Step: 6
Training loss: 3.422091007232666
Validation loss: 2.6584422126893075

Epoch: 6| Step: 7
Training loss: 3.098353862762451
Validation loss: 2.642495519371443

Epoch: 6| Step: 8
Training loss: 2.5767123699188232
Validation loss: 2.6359380316990677

Epoch: 6| Step: 9
Training loss: 2.8889527320861816
Validation loss: 2.63631022104653

Epoch: 6| Step: 10
Training loss: 3.0597715377807617
Validation loss: 2.636444860889066

Epoch: 6| Step: 11
Training loss: 2.7058610916137695
Validation loss: 2.6415283603052937

Epoch: 6| Step: 12
Training loss: 2.4512176513671875
Validation loss: 2.643817904174969

Epoch: 6| Step: 13
Training loss: 2.6162729263305664
Validation loss: 2.6405882758478962

Epoch: 24| Step: 0
Training loss: 2.3463573455810547
Validation loss: 2.651157530405188

Epoch: 6| Step: 1
Training loss: 3.061936140060425
Validation loss: 2.6643156338763494

Epoch: 6| Step: 2
Training loss: 3.224247455596924
Validation loss: 2.640509049097697

Epoch: 6| Step: 3
Training loss: 2.474069118499756
Validation loss: 2.6263081591616393

Epoch: 6| Step: 4
Training loss: 2.8045332431793213
Validation loss: 2.634183191484021

Epoch: 6| Step: 5
Training loss: 2.5580782890319824
Validation loss: 2.6490857690893193

Epoch: 6| Step: 6
Training loss: 3.0610508918762207
Validation loss: 2.6727228062127226

Epoch: 6| Step: 7
Training loss: 3.3778157234191895
Validation loss: 2.695184164149787

Epoch: 6| Step: 8
Training loss: 3.013643503189087
Validation loss: 2.6749157187759236

Epoch: 6| Step: 9
Training loss: 2.439748764038086
Validation loss: 2.6585553846051617

Epoch: 6| Step: 10
Training loss: 3.3525755405426025
Validation loss: 2.6292642008873726

Epoch: 6| Step: 11
Training loss: 2.404637098312378
Validation loss: 2.620653211429555

Epoch: 6| Step: 12
Training loss: 3.2942113876342773
Validation loss: 2.620810301073136

Epoch: 6| Step: 13
Training loss: 1.5373249053955078
Validation loss: 2.6192090588231243

Epoch: 25| Step: 0
Training loss: 2.435664653778076
Validation loss: 2.628839736343712

Epoch: 6| Step: 1
Training loss: 3.2693896293640137
Validation loss: 2.632254636415871

Epoch: 6| Step: 2
Training loss: 3.2572107315063477
Validation loss: 2.670362413570445

Epoch: 6| Step: 3
Training loss: 2.1133532524108887
Validation loss: 2.6389699520603305

Epoch: 6| Step: 4
Training loss: 2.725579261779785
Validation loss: 2.6221017068432224

Epoch: 6| Step: 5
Training loss: 3.6546425819396973
Validation loss: 2.6187433786289667

Epoch: 6| Step: 6
Training loss: 2.2841758728027344
Validation loss: 2.616662016478918

Epoch: 6| Step: 7
Training loss: 2.889247179031372
Validation loss: 2.6148639340554514

Epoch: 6| Step: 8
Training loss: 3.2112627029418945
Validation loss: 2.610482256899598

Epoch: 6| Step: 9
Training loss: 3.0456299781799316
Validation loss: 2.609599203191778

Epoch: 6| Step: 10
Training loss: 2.155579090118408
Validation loss: 2.6106838897992204

Epoch: 6| Step: 11
Training loss: 3.687851905822754
Validation loss: 2.6151894215614564

Epoch: 6| Step: 12
Training loss: 2.2897961139678955
Validation loss: 2.608480663709743

Epoch: 6| Step: 13
Training loss: 1.8398394584655762
Validation loss: 2.609069142290341

Epoch: 26| Step: 0
Training loss: 3.1239242553710938
Validation loss: 2.6089728032388995

Epoch: 6| Step: 1
Training loss: 2.120598793029785
Validation loss: 2.613426644315002

Epoch: 6| Step: 2
Training loss: 2.910733222961426
Validation loss: 2.633258955453032

Epoch: 6| Step: 3
Training loss: 1.9633667469024658
Validation loss: 2.676575065940939

Epoch: 6| Step: 4
Training loss: 3.085829019546509
Validation loss: 2.7146862501739175

Epoch: 6| Step: 5
Training loss: 3.4322571754455566
Validation loss: 2.685222251440889

Epoch: 6| Step: 6
Training loss: 3.363743782043457
Validation loss: 2.631198433137709

Epoch: 6| Step: 7
Training loss: 2.506438732147217
Validation loss: 2.60172184564734

Epoch: 6| Step: 8
Training loss: 2.643400192260742
Validation loss: 2.6110333345269643

Epoch: 6| Step: 9
Training loss: 2.0344676971435547
Validation loss: 2.623154991416521

Epoch: 6| Step: 10
Training loss: 2.846436023712158
Validation loss: 2.6339909363818426

Epoch: 6| Step: 11
Training loss: 3.2879912853240967
Validation loss: 2.6239322949481267

Epoch: 6| Step: 12
Training loss: 2.9338274002075195
Validation loss: 2.614478680395311

Epoch: 6| Step: 13
Training loss: 3.217792272567749
Validation loss: 2.6042329572862193

Epoch: 27| Step: 0
Training loss: 3.7981691360473633
Validation loss: 2.6002921391558904

Epoch: 6| Step: 1
Training loss: 3.1964516639709473
Validation loss: 2.5929734399241786

Epoch: 6| Step: 2
Training loss: 2.6629748344421387
Validation loss: 2.61133332919049

Epoch: 6| Step: 3
Training loss: 2.230295419692993
Validation loss: 2.6372734859425533

Epoch: 6| Step: 4
Training loss: 2.8513107299804688
Validation loss: 2.6160443341860207

Epoch: 6| Step: 5
Training loss: 2.4883780479431152
Validation loss: 2.5922462683852

Epoch: 6| Step: 6
Training loss: 3.038785934448242
Validation loss: 2.5881754403473227

Epoch: 6| Step: 7
Training loss: 2.7408738136291504
Validation loss: 2.5912492147056003

Epoch: 6| Step: 8
Training loss: 2.902198314666748
Validation loss: 2.5989412338502946

Epoch: 6| Step: 9
Training loss: 2.5032691955566406
Validation loss: 2.593761759419595

Epoch: 6| Step: 10
Training loss: 2.3590450286865234
Validation loss: 2.5892059418462936

Epoch: 6| Step: 11
Training loss: 3.259810447692871
Validation loss: 2.589760685479769

Epoch: 6| Step: 12
Training loss: 2.184450626373291
Validation loss: 2.585874783095493

Epoch: 6| Step: 13
Training loss: 2.9303534030914307
Validation loss: 2.5843402967658093

Epoch: 28| Step: 0
Training loss: 3.0496115684509277
Validation loss: 2.5821435323325534

Epoch: 6| Step: 1
Training loss: 2.4814372062683105
Validation loss: 2.5965046677538144

Epoch: 6| Step: 2
Training loss: 2.3086328506469727
Validation loss: 2.612227362971152

Epoch: 6| Step: 3
Training loss: 3.024648427963257
Validation loss: 2.6064657524067867

Epoch: 6| Step: 4
Training loss: 2.0726733207702637
Validation loss: 2.5978139190263647

Epoch: 6| Step: 5
Training loss: 2.911550998687744
Validation loss: 2.5863778027155067

Epoch: 6| Step: 6
Training loss: 2.8684937953948975
Validation loss: 2.582480271657308

Epoch: 6| Step: 7
Training loss: 2.3410582542419434
Validation loss: 2.576677768461166

Epoch: 6| Step: 8
Training loss: 2.94691801071167
Validation loss: 2.5774277692200034

Epoch: 6| Step: 9
Training loss: 1.7301723957061768
Validation loss: 2.576218194859002

Epoch: 6| Step: 10
Training loss: 3.792590618133545
Validation loss: 2.5731223731912594

Epoch: 6| Step: 11
Training loss: 2.8245229721069336
Validation loss: 2.576358151692216

Epoch: 6| Step: 12
Training loss: 3.007228374481201
Validation loss: 2.5793605491679203

Epoch: 6| Step: 13
Training loss: 3.85119891166687
Validation loss: 2.570292931731029

Epoch: 29| Step: 0
Training loss: 2.6150026321411133
Validation loss: 2.5715146551850023

Epoch: 6| Step: 1
Training loss: 3.087080478668213
Validation loss: 2.573086154076361

Epoch: 6| Step: 2
Training loss: 2.341759443283081
Validation loss: 2.5757655020683043

Epoch: 6| Step: 3
Training loss: 3.308835983276367
Validation loss: 2.5803477097583074

Epoch: 6| Step: 4
Training loss: 2.2452917098999023
Validation loss: 2.565594862866145

Epoch: 6| Step: 5
Training loss: 2.9754011631011963
Validation loss: 2.5617375220021894

Epoch: 6| Step: 6
Training loss: 3.220456600189209
Validation loss: 2.5608010984236196

Epoch: 6| Step: 7
Training loss: 2.613852024078369
Validation loss: 2.561573777147519

Epoch: 6| Step: 8
Training loss: 2.3988757133483887
Validation loss: 2.5684039541470107

Epoch: 6| Step: 9
Training loss: 2.5211129188537598
Validation loss: 2.56619869765415

Epoch: 6| Step: 10
Training loss: 3.0990567207336426
Validation loss: 2.5665237749776533

Epoch: 6| Step: 11
Training loss: 2.8495495319366455
Validation loss: 2.568984090640981

Epoch: 6| Step: 12
Training loss: 2.9279861450195312
Validation loss: 2.570468023259153

Epoch: 6| Step: 13
Training loss: 2.0919437408447266
Validation loss: 2.571412653051397

Epoch: 30| Step: 0
Training loss: 2.255906820297241
Validation loss: 2.5663458224265807

Epoch: 6| Step: 1
Training loss: 2.8635878562927246
Validation loss: 2.5667509699380524

Epoch: 6| Step: 2
Training loss: 2.8398709297180176
Validation loss: 2.570346211874357

Epoch: 6| Step: 3
Training loss: 2.6059646606445312
Validation loss: 2.566968922973961

Epoch: 6| Step: 4
Training loss: 3.2578327655792236
Validation loss: 2.560904731032669

Epoch: 6| Step: 5
Training loss: 3.226912498474121
Validation loss: 2.554954039153232

Epoch: 6| Step: 6
Training loss: 2.7998836040496826
Validation loss: 2.5570575703856764

Epoch: 6| Step: 7
Training loss: 3.059774875640869
Validation loss: 2.564878297108476

Epoch: 6| Step: 8
Training loss: 3.4654812812805176
Validation loss: 2.590428747156615

Epoch: 6| Step: 9
Training loss: 2.1340465545654297
Validation loss: 2.6136705183213755

Epoch: 6| Step: 10
Training loss: 2.7293801307678223
Validation loss: 2.6010767875179166

Epoch: 6| Step: 11
Training loss: 2.41835880279541
Validation loss: 2.5872191716265935

Epoch: 6| Step: 12
Training loss: 2.18135666847229
Validation loss: 2.5628534516980572

Epoch: 6| Step: 13
Training loss: 2.6828203201293945
Validation loss: 2.550125745034987

Epoch: 31| Step: 0
Training loss: 2.9307923316955566
Validation loss: 2.5532717961137013

Epoch: 6| Step: 1
Training loss: 2.964230537414551
Validation loss: 2.5748601241778304

Epoch: 6| Step: 2
Training loss: 2.4388880729675293
Validation loss: 2.589855122309859

Epoch: 6| Step: 3
Training loss: 2.54538893699646
Validation loss: 2.5885675414916007

Epoch: 6| Step: 4
Training loss: 2.652479648590088
Validation loss: 2.5771015382582143

Epoch: 6| Step: 5
Training loss: 2.4058661460876465
Validation loss: 2.5713491593637774

Epoch: 6| Step: 6
Training loss: 2.122955799102783
Validation loss: 2.561412262660201

Epoch: 6| Step: 7
Training loss: 2.8733677864074707
Validation loss: 2.5510817086824806

Epoch: 6| Step: 8
Training loss: 2.2602391242980957
Validation loss: 2.550226216675133

Epoch: 6| Step: 9
Training loss: 3.3659543991088867
Validation loss: 2.5460202360665924

Epoch: 6| Step: 10
Training loss: 2.7036049365997314
Validation loss: 2.54675619832931

Epoch: 6| Step: 11
Training loss: 3.3274786472320557
Validation loss: 2.540174925199119

Epoch: 6| Step: 12
Training loss: 3.315856456756592
Validation loss: 2.5434922479814097

Epoch: 6| Step: 13
Training loss: 2.491225242614746
Validation loss: 2.547636874260441

Epoch: 32| Step: 0
Training loss: 1.7285706996917725
Validation loss: 2.548673886124806

Epoch: 6| Step: 1
Training loss: 2.9736876487731934
Validation loss: 2.543560968932285

Epoch: 6| Step: 2
Training loss: 2.705639123916626
Validation loss: 2.535964660747077

Epoch: 6| Step: 3
Training loss: 3.111668586730957
Validation loss: 2.541683212403328

Epoch: 6| Step: 4
Training loss: 3.237363338470459
Validation loss: 2.5452368746521654

Epoch: 6| Step: 5
Training loss: 2.0401110649108887
Validation loss: 2.5521194627208095

Epoch: 6| Step: 6
Training loss: 3.3166019916534424
Validation loss: 2.5540671015298493

Epoch: 6| Step: 7
Training loss: 3.9186294078826904
Validation loss: 2.545927955258277

Epoch: 6| Step: 8
Training loss: 2.533646583557129
Validation loss: 2.5408285330700617

Epoch: 6| Step: 9
Training loss: 3.153639078140259
Validation loss: 2.5356404986432803

Epoch: 6| Step: 10
Training loss: 2.256227970123291
Validation loss: 2.5340055111915833

Epoch: 6| Step: 11
Training loss: 2.5746419429779053
Validation loss: 2.5337498572564896

Epoch: 6| Step: 12
Training loss: 2.0632073879241943
Validation loss: 2.5429326847035396

Epoch: 6| Step: 13
Training loss: 2.694171905517578
Validation loss: 2.5469802015571186

Epoch: 33| Step: 0
Training loss: 2.2203028202056885
Validation loss: 2.5393445568699993

Epoch: 6| Step: 1
Training loss: 3.0506129264831543
Validation loss: 2.522690914010489

Epoch: 6| Step: 2
Training loss: 3.4969029426574707
Validation loss: 2.521402261590445

Epoch: 6| Step: 3
Training loss: 2.813601016998291
Validation loss: 2.529413489885228

Epoch: 6| Step: 4
Training loss: 2.1537179946899414
Validation loss: 2.544345781367312

Epoch: 6| Step: 5
Training loss: 3.7187914848327637
Validation loss: 2.5779969076956473

Epoch: 6| Step: 6
Training loss: 2.945629835128784
Validation loss: 2.5813112899821293

Epoch: 6| Step: 7
Training loss: 2.6246252059936523
Validation loss: 2.584368733949559

Epoch: 6| Step: 8
Training loss: 2.1836097240448
Validation loss: 2.55582364912956

Epoch: 6| Step: 9
Training loss: 2.6796584129333496
Validation loss: 2.544395333977156

Epoch: 6| Step: 10
Training loss: 2.83735990524292
Validation loss: 2.5741026837338685

Epoch: 6| Step: 11
Training loss: 2.4941868782043457
Validation loss: 2.5549776733562513

Epoch: 6| Step: 12
Training loss: 1.8489809036254883
Validation loss: 2.5300046756703365

Epoch: 6| Step: 13
Training loss: 3.956284761428833
Validation loss: 2.539592430155764

Epoch: 34| Step: 0
Training loss: 3.0604801177978516
Validation loss: 2.542738893980621

Epoch: 6| Step: 1
Training loss: 3.013180732727051
Validation loss: 2.556377036597139

Epoch: 6| Step: 2
Training loss: 2.7071733474731445
Validation loss: 2.551179696154851

Epoch: 6| Step: 3
Training loss: 3.077815055847168
Validation loss: 2.5417392792240268

Epoch: 6| Step: 4
Training loss: 2.1774377822875977
Validation loss: 2.5349518637503348

Epoch: 6| Step: 5
Training loss: 2.368645191192627
Validation loss: 2.531852078694169

Epoch: 6| Step: 6
Training loss: 2.8260130882263184
Validation loss: 2.523830508673063

Epoch: 6| Step: 7
Training loss: 2.359715223312378
Validation loss: 2.529051555100308

Epoch: 6| Step: 8
Training loss: 2.067610263824463
Validation loss: 2.5345902827478226

Epoch: 6| Step: 9
Training loss: 3.2749485969543457
Validation loss: 2.5312923590342202

Epoch: 6| Step: 10
Training loss: 3.3403549194335938
Validation loss: 2.520610394016389

Epoch: 6| Step: 11
Training loss: 2.228720188140869
Validation loss: 2.516005018705963

Epoch: 6| Step: 12
Training loss: 3.1621971130371094
Validation loss: 2.510138575748731

Epoch: 6| Step: 13
Training loss: 2.2092199325561523
Validation loss: 2.506640270192136

Epoch: 35| Step: 0
Training loss: 3.7903614044189453
Validation loss: 2.5092538146562475

Epoch: 6| Step: 1
Training loss: 3.256589412689209
Validation loss: 2.5124315574604976

Epoch: 6| Step: 2
Training loss: 2.863739252090454
Validation loss: 2.5244022082257014

Epoch: 6| Step: 3
Training loss: 2.666027307510376
Validation loss: 2.547661409583143

Epoch: 6| Step: 4
Training loss: 2.2774295806884766
Validation loss: 2.562359026683274

Epoch: 6| Step: 5
Training loss: 2.695690631866455
Validation loss: 2.557100219111289

Epoch: 6| Step: 6
Training loss: 2.384557008743286
Validation loss: 2.531612060403311

Epoch: 6| Step: 7
Training loss: 2.5601675510406494
Validation loss: 2.519310025758641

Epoch: 6| Step: 8
Training loss: 2.4721689224243164
Validation loss: 2.5117804363209713

Epoch: 6| Step: 9
Training loss: 2.220656633377075
Validation loss: 2.5059970194293606

Epoch: 6| Step: 10
Training loss: 2.795091152191162
Validation loss: 2.513987374562089

Epoch: 6| Step: 11
Training loss: 2.4984850883483887
Validation loss: 2.535322199585617

Epoch: 6| Step: 12
Training loss: 3.0046401023864746
Validation loss: 2.554237493904688

Epoch: 6| Step: 13
Training loss: 2.73336124420166
Validation loss: 2.573603389083698

Epoch: 36| Step: 0
Training loss: 2.9527769088745117
Validation loss: 2.5549038969060427

Epoch: 6| Step: 1
Training loss: 2.9703962802886963
Validation loss: 2.5186555923954135

Epoch: 6| Step: 2
Training loss: 2.686595916748047
Validation loss: 2.502940905991421

Epoch: 6| Step: 3
Training loss: 2.888913869857788
Validation loss: 2.503445748359926

Epoch: 6| Step: 4
Training loss: 3.1672139167785645
Validation loss: 2.514179527118642

Epoch: 6| Step: 5
Training loss: 2.562410354614258
Validation loss: 2.5238095252744612

Epoch: 6| Step: 6
Training loss: 2.570713996887207
Validation loss: 2.528790827720396

Epoch: 6| Step: 7
Training loss: 3.584582567214966
Validation loss: 2.5534401247578282

Epoch: 6| Step: 8
Training loss: 3.129889965057373
Validation loss: 2.582984047551309

Epoch: 6| Step: 9
Training loss: 2.0507850646972656
Validation loss: 2.5695135131958993

Epoch: 6| Step: 10
Training loss: 2.9956207275390625
Validation loss: 2.5684773486147643

Epoch: 6| Step: 11
Training loss: 2.6156599521636963
Validation loss: 2.530878443871775

Epoch: 6| Step: 12
Training loss: 1.925610899925232
Validation loss: 2.5095152060190835

Epoch: 6| Step: 13
Training loss: 2.337636709213257
Validation loss: 2.499724239431402

Epoch: 37| Step: 0
Training loss: 2.8258280754089355
Validation loss: 2.490118944516746

Epoch: 6| Step: 1
Training loss: 3.1937875747680664
Validation loss: 2.4936546253901657

Epoch: 6| Step: 2
Training loss: 3.785635471343994
Validation loss: 2.5219934140482256

Epoch: 6| Step: 3
Training loss: 2.186840534210205
Validation loss: 2.5427715906532864

Epoch: 6| Step: 4
Training loss: 2.4334826469421387
Validation loss: 2.5224868225794967

Epoch: 6| Step: 5
Training loss: 2.702167272567749
Validation loss: 2.5018828094646497

Epoch: 6| Step: 6
Training loss: 2.5233349800109863
Validation loss: 2.494441880974718

Epoch: 6| Step: 7
Training loss: 2.9204885959625244
Validation loss: 2.4871948380624094

Epoch: 6| Step: 8
Training loss: 2.6328234672546387
Validation loss: 2.484640670079057

Epoch: 6| Step: 9
Training loss: 2.4882850646972656
Validation loss: 2.474341397644371

Epoch: 6| Step: 10
Training loss: 2.6994714736938477
Validation loss: 2.4804885643784718

Epoch: 6| Step: 11
Training loss: 2.4200823307037354
Validation loss: 2.488566960057905

Epoch: 6| Step: 12
Training loss: 2.1107330322265625
Validation loss: 2.488268029305243

Epoch: 6| Step: 13
Training loss: 3.2865617275238037
Validation loss: 2.4866948819929555

Epoch: 38| Step: 0
Training loss: 2.910625457763672
Validation loss: 2.491691194554811

Epoch: 6| Step: 1
Training loss: 3.5382981300354004
Validation loss: 2.4865962459195043

Epoch: 6| Step: 2
Training loss: 2.0130224227905273
Validation loss: 2.4826851506387033

Epoch: 6| Step: 3
Training loss: 2.868759870529175
Validation loss: 2.488901945852464

Epoch: 6| Step: 4
Training loss: 3.0509772300720215
Validation loss: 2.4966349960655294

Epoch: 6| Step: 5
Training loss: 3.2204151153564453
Validation loss: 2.490787445857961

Epoch: 6| Step: 6
Training loss: 2.3912861347198486
Validation loss: 2.476147405562862

Epoch: 6| Step: 7
Training loss: 2.20576548576355
Validation loss: 2.4687904721947125

Epoch: 6| Step: 8
Training loss: 2.2990000247955322
Validation loss: 2.4732204585947017

Epoch: 6| Step: 9
Training loss: 2.4777467250823975
Validation loss: 2.469647240895097

Epoch: 6| Step: 10
Training loss: 2.2155356407165527
Validation loss: 2.4706476221802416

Epoch: 6| Step: 11
Training loss: 2.851515769958496
Validation loss: 2.4718793105053645

Epoch: 6| Step: 12
Training loss: 2.8347339630126953
Validation loss: 2.468394838353639

Epoch: 6| Step: 13
Training loss: 3.1680755615234375
Validation loss: 2.474285010368593

Epoch: 39| Step: 0
Training loss: 3.5387685298919678
Validation loss: 2.4866882216545845

Epoch: 6| Step: 1
Training loss: 2.4174718856811523
Validation loss: 2.504496233437651

Epoch: 6| Step: 2
Training loss: 2.3511199951171875
Validation loss: 2.50807664984016

Epoch: 6| Step: 3
Training loss: 3.4906396865844727
Validation loss: 2.4830912441335697

Epoch: 6| Step: 4
Training loss: 2.246983766555786
Validation loss: 2.4752578299532653

Epoch: 6| Step: 5
Training loss: 2.5159192085266113
Validation loss: 2.4701528779921995

Epoch: 6| Step: 6
Training loss: 3.429935932159424
Validation loss: 2.4732611384443057

Epoch: 6| Step: 7
Training loss: 3.3200416564941406
Validation loss: 2.4654688604416384

Epoch: 6| Step: 8
Training loss: 2.242077589035034
Validation loss: 2.4652604697853007

Epoch: 6| Step: 9
Training loss: 1.8482506275177002
Validation loss: 2.465545851697204

Epoch: 6| Step: 10
Training loss: 2.9010469913482666
Validation loss: 2.4660750076334965

Epoch: 6| Step: 11
Training loss: 2.4529809951782227
Validation loss: 2.4677194446645756

Epoch: 6| Step: 12
Training loss: 2.245551347732544
Validation loss: 2.4667960059258247

Epoch: 6| Step: 13
Training loss: 2.6995880603790283
Validation loss: 2.4753635032202608

Epoch: 40| Step: 0
Training loss: 2.382883071899414
Validation loss: 2.4880545934041343

Epoch: 6| Step: 1
Training loss: 2.8683226108551025
Validation loss: 2.497906074729017

Epoch: 6| Step: 2
Training loss: 2.956740379333496
Validation loss: 2.511050357613512

Epoch: 6| Step: 3
Training loss: 2.2573964595794678
Validation loss: 2.517308840187647

Epoch: 6| Step: 4
Training loss: 3.5311999320983887
Validation loss: 2.552377152186568

Epoch: 6| Step: 5
Training loss: 1.8464192152023315
Validation loss: 2.5608977476755777

Epoch: 6| Step: 6
Training loss: 2.452808141708374
Validation loss: 2.5311458559446436

Epoch: 6| Step: 7
Training loss: 2.5136630535125732
Validation loss: 2.487891950914937

Epoch: 6| Step: 8
Training loss: 3.3945860862731934
Validation loss: 2.473782390676519

Epoch: 6| Step: 9
Training loss: 2.7007901668548584
Validation loss: 2.459678247410764

Epoch: 6| Step: 10
Training loss: 2.6844685077667236
Validation loss: 2.4558392109409457

Epoch: 6| Step: 11
Training loss: 2.604436159133911
Validation loss: 2.466753352072931

Epoch: 6| Step: 12
Training loss: 2.9482083320617676
Validation loss: 2.4890934395533737

Epoch: 6| Step: 13
Training loss: 2.317699670791626
Validation loss: 2.5076775961024786

Epoch: 41| Step: 0
Training loss: 2.3305912017822266
Validation loss: 2.5409174580727854

Epoch: 6| Step: 1
Training loss: 2.142561912536621
Validation loss: 2.566081887932234

Epoch: 6| Step: 2
Training loss: 2.3752503395080566
Validation loss: 2.565296998587988

Epoch: 6| Step: 3
Training loss: 2.6204333305358887
Validation loss: 2.5409070189281175

Epoch: 6| Step: 4
Training loss: 2.8006088733673096
Validation loss: 2.496834919016848

Epoch: 6| Step: 5
Training loss: 2.2600154876708984
Validation loss: 2.475608935920141

Epoch: 6| Step: 6
Training loss: 2.6188266277313232
Validation loss: 2.4588368759360364

Epoch: 6| Step: 7
Training loss: 2.8053464889526367
Validation loss: 2.4540067641965804

Epoch: 6| Step: 8
Training loss: 3.8046131134033203
Validation loss: 2.4578807097609325

Epoch: 6| Step: 9
Training loss: 3.1220014095306396
Validation loss: 2.475049582860803

Epoch: 6| Step: 10
Training loss: 3.1162776947021484
Validation loss: 2.50083133738528

Epoch: 6| Step: 11
Training loss: 2.928288459777832
Validation loss: 2.5296086034467145

Epoch: 6| Step: 12
Training loss: 2.470702886581421
Validation loss: 2.5547413569624706

Epoch: 6| Step: 13
Training loss: 2.500105619430542
Validation loss: 2.5571445854761268

Epoch: 42| Step: 0
Training loss: 2.977735757827759
Validation loss: 2.5403701566880748

Epoch: 6| Step: 1
Training loss: 2.7549405097961426
Validation loss: 2.504789403689805

Epoch: 6| Step: 2
Training loss: 2.674384593963623
Validation loss: 2.4908189517195507

Epoch: 6| Step: 3
Training loss: 2.4208104610443115
Validation loss: 2.4788972152176725

Epoch: 6| Step: 4
Training loss: 2.8032188415527344
Validation loss: 2.44627244369958

Epoch: 6| Step: 5
Training loss: 2.7454042434692383
Validation loss: 2.450838642735635

Epoch: 6| Step: 6
Training loss: 2.6268584728240967
Validation loss: 2.4698440336411998

Epoch: 6| Step: 7
Training loss: 3.2578978538513184
Validation loss: 2.4719836878520187

Epoch: 6| Step: 8
Training loss: 3.038163185119629
Validation loss: 2.4538824558258057

Epoch: 6| Step: 9
Training loss: 1.8570060729980469
Validation loss: 2.460132550167781

Epoch: 6| Step: 10
Training loss: 3.6345229148864746
Validation loss: 2.456098371936429

Epoch: 6| Step: 11
Training loss: 1.933762788772583
Validation loss: 2.455598403048772

Epoch: 6| Step: 12
Training loss: 2.433526039123535
Validation loss: 2.450965222492013

Epoch: 6| Step: 13
Training loss: 2.570050001144409
Validation loss: 2.447137632677632

Epoch: 43| Step: 0
Training loss: 2.798760414123535
Validation loss: 2.4421594001913585

Epoch: 6| Step: 1
Training loss: 2.1524498462677
Validation loss: 2.442635146520471

Epoch: 6| Step: 2
Training loss: 2.8586153984069824
Validation loss: 2.4401291006354877

Epoch: 6| Step: 3
Training loss: 2.540377378463745
Validation loss: 2.4414964516957602

Epoch: 6| Step: 4
Training loss: 2.9736015796661377
Validation loss: 2.4424535433451333

Epoch: 6| Step: 5
Training loss: 2.0477657318115234
Validation loss: 2.4359191515112437

Epoch: 6| Step: 6
Training loss: 2.761565923690796
Validation loss: 2.4330448309580484

Epoch: 6| Step: 7
Training loss: 3.4988489151000977
Validation loss: 2.4337145154194166

Epoch: 6| Step: 8
Training loss: 2.9353528022766113
Validation loss: 2.436504123031452

Epoch: 6| Step: 9
Training loss: 2.7477152347564697
Validation loss: 2.4410560489982687

Epoch: 6| Step: 10
Training loss: 2.266812324523926
Validation loss: 2.439449602557767

Epoch: 6| Step: 11
Training loss: 2.4444408416748047
Validation loss: 2.4409251828347482

Epoch: 6| Step: 12
Training loss: 2.5597782135009766
Validation loss: 2.4451655136641635

Epoch: 6| Step: 13
Training loss: 2.9936695098876953
Validation loss: 2.4535249945937947

Epoch: 44| Step: 0
Training loss: 2.698239326477051
Validation loss: 2.4615588213807795

Epoch: 6| Step: 1
Training loss: 2.9169392585754395
Validation loss: 2.480681893646076

Epoch: 6| Step: 2
Training loss: 2.5543646812438965
Validation loss: 2.4927069987020185

Epoch: 6| Step: 3
Training loss: 2.8901760578155518
Validation loss: 2.473665060535554

Epoch: 6| Step: 4
Training loss: 2.1542258262634277
Validation loss: 2.4614240559198524

Epoch: 6| Step: 5
Training loss: 2.6365368366241455
Validation loss: 2.4678112229993268

Epoch: 6| Step: 6
Training loss: 2.4336118698120117
Validation loss: 2.4677015812166276

Epoch: 6| Step: 7
Training loss: 3.3530685901641846
Validation loss: 2.4415559691767537

Epoch: 6| Step: 8
Training loss: 2.89827299118042
Validation loss: 2.433638549620105

Epoch: 6| Step: 9
Training loss: 2.418300151824951
Validation loss: 2.428002454901254

Epoch: 6| Step: 10
Training loss: 2.754040241241455
Validation loss: 2.433718494189683

Epoch: 6| Step: 11
Training loss: 2.643733501434326
Validation loss: 2.442567179279943

Epoch: 6| Step: 12
Training loss: 2.829371929168701
Validation loss: 2.4453588865136586

Epoch: 6| Step: 13
Training loss: 1.9784064292907715
Validation loss: 2.4496639005599485

Epoch: 45| Step: 0
Training loss: 2.6634557247161865
Validation loss: 2.4391781053235455

Epoch: 6| Step: 1
Training loss: 3.155479907989502
Validation loss: 2.4268345858461116

Epoch: 6| Step: 2
Training loss: 2.3980093002319336
Validation loss: 2.4164974010118874

Epoch: 6| Step: 3
Training loss: 2.6569371223449707
Validation loss: 2.4199062419194046

Epoch: 6| Step: 4
Training loss: 2.7146596908569336
Validation loss: 2.4145241911693285

Epoch: 6| Step: 5
Training loss: 3.151036500930786
Validation loss: 2.4334857950928392

Epoch: 6| Step: 6
Training loss: 3.076162576675415
Validation loss: 2.4462790489196777

Epoch: 6| Step: 7
Training loss: 2.4086477756500244
Validation loss: 2.4565088902750323

Epoch: 6| Step: 8
Training loss: 1.885419249534607
Validation loss: 2.461514472961426

Epoch: 6| Step: 9
Training loss: 2.528292179107666
Validation loss: 2.4479798065718783

Epoch: 6| Step: 10
Training loss: 3.4586918354034424
Validation loss: 2.4476175564591602

Epoch: 6| Step: 11
Training loss: 2.7980709075927734
Validation loss: 2.435066189817203

Epoch: 6| Step: 12
Training loss: 2.1651341915130615
Validation loss: 2.4289831781900055

Epoch: 6| Step: 13
Training loss: 2.0908584594726562
Validation loss: 2.4228724330984135

Epoch: 46| Step: 0
Training loss: 2.9078164100646973
Validation loss: 2.4111280505375197

Epoch: 6| Step: 1
Training loss: 3.0539357662200928
Validation loss: 2.410232704172852

Epoch: 6| Step: 2
Training loss: 2.1779398918151855
Validation loss: 2.407296778053366

Epoch: 6| Step: 3
Training loss: 2.4603333473205566
Validation loss: 2.410304779647499

Epoch: 6| Step: 4
Training loss: 2.00797176361084
Validation loss: 2.4130588552003265

Epoch: 6| Step: 5
Training loss: 2.091893196105957
Validation loss: 2.421272426523188

Epoch: 6| Step: 6
Training loss: 3.0620601177215576
Validation loss: 2.4223124673289638

Epoch: 6| Step: 7
Training loss: 3.1527485847473145
Validation loss: 2.426133563441615

Epoch: 6| Step: 8
Training loss: 3.0932564735412598
Validation loss: 2.4296220105181456

Epoch: 6| Step: 9
Training loss: 2.602811336517334
Validation loss: 2.430250585720103

Epoch: 6| Step: 10
Training loss: 2.4030680656433105
Validation loss: 2.4233358931797806

Epoch: 6| Step: 11
Training loss: 3.0123507976531982
Validation loss: 2.4163135251691266

Epoch: 6| Step: 12
Training loss: 2.9046218395233154
Validation loss: 2.410769480530934

Epoch: 6| Step: 13
Training loss: 2.5285069942474365
Validation loss: 2.408461134920838

Epoch: 47| Step: 0
Training loss: 2.64884090423584
Validation loss: 2.406864015004968

Epoch: 6| Step: 1
Training loss: 2.6274142265319824
Validation loss: 2.4170000527494695

Epoch: 6| Step: 2
Training loss: 2.5710487365722656
Validation loss: 2.4160400962316864

Epoch: 6| Step: 3
Training loss: 2.5548348426818848
Validation loss: 2.4221539189738612

Epoch: 6| Step: 4
Training loss: 2.7656431198120117
Validation loss: 2.4232533234421925

Epoch: 6| Step: 5
Training loss: 2.546283721923828
Validation loss: 2.4207692864120647

Epoch: 6| Step: 6
Training loss: 2.471907615661621
Validation loss: 2.4130584245086997

Epoch: 6| Step: 7
Training loss: 2.631643533706665
Validation loss: 2.4244504436369865

Epoch: 6| Step: 8
Training loss: 2.924683094024658
Validation loss: 2.4225505936530327

Epoch: 6| Step: 9
Training loss: 2.831958532333374
Validation loss: 2.4499854349320933

Epoch: 6| Step: 10
Training loss: 2.2025651931762695
Validation loss: 2.421422322591146

Epoch: 6| Step: 11
Training loss: 2.9555015563964844
Validation loss: 2.4134958636376167

Epoch: 6| Step: 12
Training loss: 2.619105815887451
Validation loss: 2.4144115191633984

Epoch: 6| Step: 13
Training loss: 2.837967872619629
Validation loss: 2.415380980378838

Epoch: 48| Step: 0
Training loss: 2.4847264289855957
Validation loss: 2.4174449161816667

Epoch: 6| Step: 1
Training loss: 2.0352253913879395
Validation loss: 2.413448584977017

Epoch: 6| Step: 2
Training loss: 2.9800949096679688
Validation loss: 2.4192918731320288

Epoch: 6| Step: 3
Training loss: 2.8541407585144043
Validation loss: 2.4144237349110265

Epoch: 6| Step: 4
Training loss: 3.0005030632019043
Validation loss: 2.415011167526245

Epoch: 6| Step: 5
Training loss: 2.3501834869384766
Validation loss: 2.4158571330449914

Epoch: 6| Step: 6
Training loss: 3.5778284072875977
Validation loss: 2.4196693243518954

Epoch: 6| Step: 7
Training loss: 2.203122138977051
Validation loss: 2.4240690636378464

Epoch: 6| Step: 8
Training loss: 2.676866054534912
Validation loss: 2.4335046327242287

Epoch: 6| Step: 9
Training loss: 2.388805627822876
Validation loss: 2.4362408230381627

Epoch: 6| Step: 10
Training loss: 2.561760425567627
Validation loss: 2.436976081581526

Epoch: 6| Step: 11
Training loss: 2.737964630126953
Validation loss: 2.4362306799939883

Epoch: 6| Step: 12
Training loss: 2.9883670806884766
Validation loss: 2.424069937839303

Epoch: 6| Step: 13
Training loss: 2.0733935832977295
Validation loss: 2.419894459427044

Epoch: 49| Step: 0
Training loss: 2.775761127471924
Validation loss: 2.4100255581640426

Epoch: 6| Step: 1
Training loss: 2.623032331466675
Validation loss: 2.4043620171085482

Epoch: 6| Step: 2
Training loss: 2.664888858795166
Validation loss: 2.404198761909239

Epoch: 6| Step: 3
Training loss: 3.5493831634521484
Validation loss: 2.4038411468587895

Epoch: 6| Step: 4
Training loss: 2.913451671600342
Validation loss: 2.4093737140778573

Epoch: 6| Step: 5
Training loss: 2.2742443084716797
Validation loss: 2.4094550301951747

Epoch: 6| Step: 6
Training loss: 2.3435964584350586
Validation loss: 2.40374324142292

Epoch: 6| Step: 7
Training loss: 2.9221603870391846
Validation loss: 2.4012865020382788

Epoch: 6| Step: 8
Training loss: 2.7853050231933594
Validation loss: 2.4011577457510014

Epoch: 6| Step: 9
Training loss: 2.3055944442749023
Validation loss: 2.4011317786350044

Epoch: 6| Step: 10
Training loss: 2.1961872577667236
Validation loss: 2.400064940093666

Epoch: 6| Step: 11
Training loss: 3.052919864654541
Validation loss: 2.3991783665072535

Epoch: 6| Step: 12
Training loss: 2.6023149490356445
Validation loss: 2.3989904939487414

Epoch: 6| Step: 13
Training loss: 1.649373173713684
Validation loss: 2.4057925003831104

Epoch: 50| Step: 0
Training loss: 2.4031615257263184
Validation loss: 2.4303827106311755

Epoch: 6| Step: 1
Training loss: 2.8226499557495117
Validation loss: 2.468591615717898

Epoch: 6| Step: 2
Training loss: 2.7582409381866455
Validation loss: 2.474905662639167

Epoch: 6| Step: 3
Training loss: 3.017202377319336
Validation loss: 2.4696910714590423

Epoch: 6| Step: 4
Training loss: 3.4568798542022705
Validation loss: 2.4407448230251187

Epoch: 6| Step: 5
Training loss: 2.3028950691223145
Validation loss: 2.4026009677558817

Epoch: 6| Step: 6
Training loss: 1.8443067073822021
Validation loss: 2.390124328674809

Epoch: 6| Step: 7
Training loss: 2.9431567192077637
Validation loss: 2.3909952589260635

Epoch: 6| Step: 8
Training loss: 2.811769962310791
Validation loss: 2.3927005926767984

Epoch: 6| Step: 9
Training loss: 2.993529796600342
Validation loss: 2.3951900364250265

Epoch: 6| Step: 10
Training loss: 2.1064987182617188
Validation loss: 2.3995941274909565

Epoch: 6| Step: 11
Training loss: 1.9286218881607056
Validation loss: 2.3913324443242883

Epoch: 6| Step: 12
Training loss: 3.242626667022705
Validation loss: 2.400169593031688

Epoch: 6| Step: 13
Training loss: 2.727266788482666
Validation loss: 2.4152351194812405

Epoch: 51| Step: 0
Training loss: 2.238403797149658
Validation loss: 2.3996041359439975

Epoch: 6| Step: 1
Training loss: 2.161674976348877
Validation loss: 2.3930782118151264

Epoch: 6| Step: 2
Training loss: 4.033281326293945
Validation loss: 2.3916159496512464

Epoch: 6| Step: 3
Training loss: 3.375389814376831
Validation loss: 2.3906672180339856

Epoch: 6| Step: 4
Training loss: 2.7597832679748535
Validation loss: 2.3924540755569295

Epoch: 6| Step: 5
Training loss: 1.9771442413330078
Validation loss: 2.393455336170812

Epoch: 6| Step: 6
Training loss: 1.790740728378296
Validation loss: 2.40213377757739

Epoch: 6| Step: 7
Training loss: 2.746960163116455
Validation loss: 2.4053781468381166

Epoch: 6| Step: 8
Training loss: 3.1757936477661133
Validation loss: 2.4148109548835346

Epoch: 6| Step: 9
Training loss: 2.842750072479248
Validation loss: 2.4203565735970773

Epoch: 6| Step: 10
Training loss: 2.35789155960083
Validation loss: 2.422392104261665

Epoch: 6| Step: 11
Training loss: 2.3058478832244873
Validation loss: 2.430899562374238

Epoch: 6| Step: 12
Training loss: 2.5697579383850098
Validation loss: 2.43971775936824

Epoch: 6| Step: 13
Training loss: 2.647143840789795
Validation loss: 2.436856021163284

Epoch: 52| Step: 0
Training loss: 2.9374966621398926
Validation loss: 2.463034301675776

Epoch: 6| Step: 1
Training loss: 2.496802806854248
Validation loss: 2.4824406177766862

Epoch: 6| Step: 2
Training loss: 2.6456146240234375
Validation loss: 2.442256513462272

Epoch: 6| Step: 3
Training loss: 2.864473342895508
Validation loss: 2.415609739160025

Epoch: 6| Step: 4
Training loss: 2.6498372554779053
Validation loss: 2.392416772022042

Epoch: 6| Step: 5
Training loss: 2.7505953311920166
Validation loss: 2.3742732412071637

Epoch: 6| Step: 6
Training loss: 3.0255885124206543
Validation loss: 2.3718400668072444

Epoch: 6| Step: 7
Training loss: 1.7838022708892822
Validation loss: 2.3689396176286923

Epoch: 6| Step: 8
Training loss: 3.2416393756866455
Validation loss: 2.368895935755904

Epoch: 6| Step: 9
Training loss: 2.294929265975952
Validation loss: 2.377951791209559

Epoch: 6| Step: 10
Training loss: 3.229372978210449
Validation loss: 2.3786649370706208

Epoch: 6| Step: 11
Training loss: 1.8853999376296997
Validation loss: 2.381140888378184

Epoch: 6| Step: 12
Training loss: 2.924924373626709
Validation loss: 2.3917815992909093

Epoch: 6| Step: 13
Training loss: 2.094761848449707
Validation loss: 2.4009451071421304

Epoch: 53| Step: 0
Training loss: 2.386432409286499
Validation loss: 2.4103610977049796

Epoch: 6| Step: 1
Training loss: 2.6415228843688965
Validation loss: 2.409427042930357

Epoch: 6| Step: 2
Training loss: 2.6353719234466553
Validation loss: 2.4001264725961993

Epoch: 6| Step: 3
Training loss: 2.9104838371276855
Validation loss: 2.381035589402722

Epoch: 6| Step: 4
Training loss: 3.0806918144226074
Validation loss: 2.370049202313987

Epoch: 6| Step: 5
Training loss: 2.8558249473571777
Validation loss: 2.3671557621289323

Epoch: 6| Step: 6
Training loss: 2.786550998687744
Validation loss: 2.3749795101022206

Epoch: 6| Step: 7
Training loss: 2.8313403129577637
Validation loss: 2.402048426289712

Epoch: 6| Step: 8
Training loss: 2.354710102081299
Validation loss: 2.409184330253191

Epoch: 6| Step: 9
Training loss: 2.488452672958374
Validation loss: 2.4351382999009985

Epoch: 6| Step: 10
Training loss: 2.5548770427703857
Validation loss: 2.40569289781714

Epoch: 6| Step: 11
Training loss: 2.629296064376831
Validation loss: 2.385924553358427

Epoch: 6| Step: 12
Training loss: 2.305711030960083
Validation loss: 2.3722432787700365

Epoch: 6| Step: 13
Training loss: 2.5724568367004395
Validation loss: 2.355292199760355

Epoch: 54| Step: 0
Training loss: 2.6455278396606445
Validation loss: 2.36062293155219

Epoch: 6| Step: 1
Training loss: 2.7910232543945312
Validation loss: 2.3597917326035036

Epoch: 6| Step: 2
Training loss: 1.9783204793930054
Validation loss: 2.360724784994638

Epoch: 6| Step: 3
Training loss: 2.661184787750244
Validation loss: 2.3596549803210842

Epoch: 6| Step: 4
Training loss: 2.229768753051758
Validation loss: 2.3600716821609007

Epoch: 6| Step: 5
Training loss: 2.791731834411621
Validation loss: 2.3590291520600677

Epoch: 6| Step: 6
Training loss: 2.325901508331299
Validation loss: 2.3625653661707395

Epoch: 6| Step: 7
Training loss: 2.966392993927002
Validation loss: 2.3614579298162974

Epoch: 6| Step: 8
Training loss: 2.675144672393799
Validation loss: 2.380032245830823

Epoch: 6| Step: 9
Training loss: 2.8895585536956787
Validation loss: 2.403833458500524

Epoch: 6| Step: 10
Training loss: 3.190363883972168
Validation loss: 2.424151600048106

Epoch: 6| Step: 11
Training loss: 2.592320442199707
Validation loss: 2.4485659086576073

Epoch: 6| Step: 12
Training loss: 2.32989501953125
Validation loss: 2.466165796402962

Epoch: 6| Step: 13
Training loss: 2.9719979763031006
Validation loss: 2.486728378521499

Epoch: 55| Step: 0
Training loss: 1.9699602127075195
Validation loss: 2.4534751651107625

Epoch: 6| Step: 1
Training loss: 2.4287075996398926
Validation loss: 2.4076578412004697

Epoch: 6| Step: 2
Training loss: 2.444535732269287
Validation loss: 2.3754625576798634

Epoch: 6| Step: 3
Training loss: 2.7787632942199707
Validation loss: 2.362096607044179

Epoch: 6| Step: 4
Training loss: 2.903291702270508
Validation loss: 2.3587467593531453

Epoch: 6| Step: 5
Training loss: 2.8452348709106445
Validation loss: 2.3776088735108734

Epoch: 6| Step: 6
Training loss: 2.82047176361084
Validation loss: 2.379457732682587

Epoch: 6| Step: 7
Training loss: 2.3033559322357178
Validation loss: 2.3872604036843903

Epoch: 6| Step: 8
Training loss: 2.4350385665893555
Validation loss: 2.393334839933662

Epoch: 6| Step: 9
Training loss: 3.0232138633728027
Validation loss: 2.3861077754728255

Epoch: 6| Step: 10
Training loss: 3.353816032409668
Validation loss: 2.381664514541626

Epoch: 6| Step: 11
Training loss: 2.9642553329467773
Validation loss: 2.37301448083693

Epoch: 6| Step: 12
Training loss: 2.6378519535064697
Validation loss: 2.3745550724767868

Epoch: 6| Step: 13
Training loss: 2.054933786392212
Validation loss: 2.3675603007757537

Epoch: 56| Step: 0
Training loss: 2.5248165130615234
Validation loss: 2.3851257267818657

Epoch: 6| Step: 1
Training loss: 2.178844451904297
Validation loss: 2.3792352984028478

Epoch: 6| Step: 2
Training loss: 2.291562795639038
Validation loss: 2.3668946707120506

Epoch: 6| Step: 3
Training loss: 2.7613027095794678
Validation loss: 2.354916331588581

Epoch: 6| Step: 4
Training loss: 2.737224578857422
Validation loss: 2.347838089030276

Epoch: 6| Step: 5
Training loss: 2.2051010131835938
Validation loss: 2.360016199850267

Epoch: 6| Step: 6
Training loss: 2.9023146629333496
Validation loss: 2.378031566578855

Epoch: 6| Step: 7
Training loss: 2.9168667793273926
Validation loss: 2.4300820955666165

Epoch: 6| Step: 8
Training loss: 2.5928728580474854
Validation loss: 2.4647161819601573

Epoch: 6| Step: 9
Training loss: 2.497004508972168
Validation loss: 2.3866341652408725

Epoch: 6| Step: 10
Training loss: 2.396973133087158
Validation loss: 2.353632829522574

Epoch: 6| Step: 11
Training loss: 3.262272596359253
Validation loss: 2.347180571607364

Epoch: 6| Step: 12
Training loss: 2.849426746368408
Validation loss: 2.3518334845060944

Epoch: 6| Step: 13
Training loss: 2.755507469177246
Validation loss: 2.3498997483202206

Epoch: 57| Step: 0
Training loss: 2.7666234970092773
Validation loss: 2.3468010348658406

Epoch: 6| Step: 1
Training loss: 2.0071115493774414
Validation loss: 2.3477832527570826

Epoch: 6| Step: 2
Training loss: 2.58555269241333
Validation loss: 2.352411118886804

Epoch: 6| Step: 3
Training loss: 2.2737269401550293
Validation loss: 2.3653076233402377

Epoch: 6| Step: 4
Training loss: 2.6184895038604736
Validation loss: 2.36019960013769

Epoch: 6| Step: 5
Training loss: 2.53570818901062
Validation loss: 2.353546937306722

Epoch: 6| Step: 6
Training loss: 2.8921120166778564
Validation loss: 2.3561453434728805

Epoch: 6| Step: 7
Training loss: 3.1275033950805664
Validation loss: 2.3822918630415395

Epoch: 6| Step: 8
Training loss: 2.7931456565856934
Validation loss: 2.3715677953535512

Epoch: 6| Step: 9
Training loss: 2.692716598510742
Validation loss: 2.3651153708017

Epoch: 6| Step: 10
Training loss: 3.0116677284240723
Validation loss: 2.3558279160530335

Epoch: 6| Step: 11
Training loss: 2.7378838062286377
Validation loss: 2.3718600068041074

Epoch: 6| Step: 12
Training loss: 2.3684592247009277
Validation loss: 2.3943359108381372

Epoch: 6| Step: 13
Training loss: 2.390174627304077
Validation loss: 2.4102958069052747

Epoch: 58| Step: 0
Training loss: 2.622969150543213
Validation loss: 2.421848209955359

Epoch: 6| Step: 1
Training loss: 1.8078949451446533
Validation loss: 2.481201579493861

Epoch: 6| Step: 2
Training loss: 2.841881275177002
Validation loss: 2.5145063284904725

Epoch: 6| Step: 3
Training loss: 2.705075263977051
Validation loss: 2.5010669821052143

Epoch: 6| Step: 4
Training loss: 2.7509403228759766
Validation loss: 2.4196551281918763

Epoch: 6| Step: 5
Training loss: 2.4806411266326904
Validation loss: 2.3645794212177234

Epoch: 6| Step: 6
Training loss: 2.5565476417541504
Validation loss: 2.345557043629308

Epoch: 6| Step: 7
Training loss: 3.3372159004211426
Validation loss: 2.3420685106708157

Epoch: 6| Step: 8
Training loss: 2.571927547454834
Validation loss: 2.3560803372372865

Epoch: 6| Step: 9
Training loss: 2.6061787605285645
Validation loss: 2.3666481971740723

Epoch: 6| Step: 10
Training loss: 2.4009857177734375
Validation loss: 2.3782324970409436

Epoch: 6| Step: 11
Training loss: 2.7656702995300293
Validation loss: 2.3816876744711273

Epoch: 6| Step: 12
Training loss: 3.122641086578369
Validation loss: 2.364000189688898

Epoch: 6| Step: 13
Training loss: 2.764674663543701
Validation loss: 2.348133079467281

Epoch: 59| Step: 0
Training loss: 2.1684463024139404
Validation loss: 2.341040790721934

Epoch: 6| Step: 1
Training loss: 3.12068247795105
Validation loss: 2.3433457010535785

Epoch: 6| Step: 2
Training loss: 2.4360857009887695
Validation loss: 2.334800809942266

Epoch: 6| Step: 3
Training loss: 3.8684160709381104
Validation loss: 2.3266295425353514

Epoch: 6| Step: 4
Training loss: 2.711409091949463
Validation loss: 2.3244870606289116

Epoch: 6| Step: 5
Training loss: 2.260521173477173
Validation loss: 2.3265651656735327

Epoch: 6| Step: 6
Training loss: 2.2388529777526855
Validation loss: 2.3291160906514814

Epoch: 6| Step: 7
Training loss: 2.936830997467041
Validation loss: 2.3326982144386537

Epoch: 6| Step: 8
Training loss: 2.5324056148529053
Validation loss: 2.3353839202593734

Epoch: 6| Step: 9
Training loss: 1.509273648262024
Validation loss: 2.3473369126678794

Epoch: 6| Step: 10
Training loss: 2.1099181175231934
Validation loss: 2.3475535890107513

Epoch: 6| Step: 11
Training loss: 2.624988079071045
Validation loss: 2.3520886000766548

Epoch: 6| Step: 12
Training loss: 2.7623255252838135
Validation loss: 2.348328246865221

Epoch: 6| Step: 13
Training loss: 3.672556161880493
Validation loss: 2.3544823379926783

Epoch: 60| Step: 0
Training loss: 2.5745837688446045
Validation loss: 2.374519912145471

Epoch: 6| Step: 1
Training loss: 2.6514668464660645
Validation loss: 2.3777641327150407

Epoch: 6| Step: 2
Training loss: 2.806016445159912
Validation loss: 2.373432400406048

Epoch: 6| Step: 3
Training loss: 1.4391942024230957
Validation loss: 2.3744837519943074

Epoch: 6| Step: 4
Training loss: 3.551210880279541
Validation loss: 2.3743631147569224

Epoch: 6| Step: 5
Training loss: 3.651716709136963
Validation loss: 2.350055886853126

Epoch: 6| Step: 6
Training loss: 2.4377098083496094
Validation loss: 2.338265665115849

Epoch: 6| Step: 7
Training loss: 2.4526302814483643
Validation loss: 2.3236510599813154

Epoch: 6| Step: 8
Training loss: 2.722679615020752
Validation loss: 2.3200149382314375

Epoch: 6| Step: 9
Training loss: 2.445188283920288
Validation loss: 2.316897448673043

Epoch: 6| Step: 10
Training loss: 2.2594869136810303
Validation loss: 2.316829522450765

Epoch: 6| Step: 11
Training loss: 2.713658332824707
Validation loss: 2.3228599871358564

Epoch: 6| Step: 12
Training loss: 2.1938912868499756
Validation loss: 2.3219504305111465

Epoch: 6| Step: 13
Training loss: 2.5499112606048584
Validation loss: 2.317435719633615

Epoch: 61| Step: 0
Training loss: 2.258445978164673
Validation loss: 2.3218463877195954

Epoch: 6| Step: 1
Training loss: 2.7460830211639404
Validation loss: 2.320214677882451

Epoch: 6| Step: 2
Training loss: 2.8653011322021484
Validation loss: 2.3229736717798377

Epoch: 6| Step: 3
Training loss: 3.1612958908081055
Validation loss: 2.3254232714253087

Epoch: 6| Step: 4
Training loss: 2.868511915206909
Validation loss: 2.325993453302691

Epoch: 6| Step: 5
Training loss: 2.9147796630859375
Validation loss: 2.3431181933290217

Epoch: 6| Step: 6
Training loss: 2.6736087799072266
Validation loss: 2.377445605493361

Epoch: 6| Step: 7
Training loss: 2.6208243370056152
Validation loss: 2.3723665027208227

Epoch: 6| Step: 8
Training loss: 2.4673147201538086
Validation loss: 2.362826781888162

Epoch: 6| Step: 9
Training loss: 2.4466042518615723
Validation loss: 2.3473995321540424

Epoch: 6| Step: 10
Training loss: 1.70578134059906
Validation loss: 2.3390194677537486

Epoch: 6| Step: 11
Training loss: 2.7522363662719727
Validation loss: 2.339854060962636

Epoch: 6| Step: 12
Training loss: 2.4735989570617676
Validation loss: 2.3306336402893066

Epoch: 6| Step: 13
Training loss: 2.474637985229492
Validation loss: 2.3317557329772622

Epoch: 62| Step: 0
Training loss: 2.729712963104248
Validation loss: 2.3271284334121214

Epoch: 6| Step: 1
Training loss: 2.0826263427734375
Validation loss: 2.3307977337991037

Epoch: 6| Step: 2
Training loss: 2.172234058380127
Validation loss: 2.3436447010245374

Epoch: 6| Step: 3
Training loss: 3.2026596069335938
Validation loss: 2.3710377472703175

Epoch: 6| Step: 4
Training loss: 2.4015166759490967
Validation loss: 2.3807071690918296

Epoch: 6| Step: 5
Training loss: 2.3458282947540283
Validation loss: 2.37504852971723

Epoch: 6| Step: 6
Training loss: 2.3447916507720947
Validation loss: 2.370203066897649

Epoch: 6| Step: 7
Training loss: 2.2936837673187256
Validation loss: 2.3460839076708724

Epoch: 6| Step: 8
Training loss: 3.0832982063293457
Validation loss: 2.3353306683160926

Epoch: 6| Step: 9
Training loss: 3.6627349853515625
Validation loss: 2.320968117765201

Epoch: 6| Step: 10
Training loss: 2.7887144088745117
Validation loss: 2.3173972201603714

Epoch: 6| Step: 11
Training loss: 2.316483974456787
Validation loss: 2.307949886527113

Epoch: 6| Step: 12
Training loss: 2.3371405601501465
Validation loss: 2.3157933706878335

Epoch: 6| Step: 13
Training loss: 2.4081554412841797
Validation loss: 2.3147517429885043

Epoch: 63| Step: 0
Training loss: 2.7956953048706055
Validation loss: 2.318880911796324

Epoch: 6| Step: 1
Training loss: 2.4468894004821777
Validation loss: 2.321257819411575

Epoch: 6| Step: 2
Training loss: 3.3030638694763184
Validation loss: 2.3179833555734284

Epoch: 6| Step: 3
Training loss: 2.453346014022827
Validation loss: 2.3239283459160918

Epoch: 6| Step: 4
Training loss: 3.054849624633789
Validation loss: 2.3205198677637244

Epoch: 6| Step: 5
Training loss: 3.0141916275024414
Validation loss: 2.32261799996899

Epoch: 6| Step: 6
Training loss: 2.5942883491516113
Validation loss: 2.3263138583911362

Epoch: 6| Step: 7
Training loss: 2.385248899459839
Validation loss: 2.333451787630717

Epoch: 6| Step: 8
Training loss: 2.1227312088012695
Validation loss: 2.338745055660125

Epoch: 6| Step: 9
Training loss: 2.118190288543701
Validation loss: 2.349638774830808

Epoch: 6| Step: 10
Training loss: 2.3795013427734375
Validation loss: 2.3650842456407446

Epoch: 6| Step: 11
Training loss: 2.3986172676086426
Validation loss: 2.3541271071280203

Epoch: 6| Step: 12
Training loss: 2.6570839881896973
Validation loss: 2.3635766454922256

Epoch: 6| Step: 13
Training loss: 2.624440908432007
Validation loss: 2.3775847342706498

Epoch: 64| Step: 0
Training loss: 1.8509624004364014
Validation loss: 2.3838578244691253

Epoch: 6| Step: 1
Training loss: 3.1305317878723145
Validation loss: 2.3746198941302556

Epoch: 6| Step: 2
Training loss: 2.19779109954834
Validation loss: 2.410014360181747

Epoch: 6| Step: 3
Training loss: 2.90303897857666
Validation loss: 2.4101062538803264

Epoch: 6| Step: 4
Training loss: 1.8689014911651611
Validation loss: 2.391601639409219

Epoch: 6| Step: 5
Training loss: 2.726551055908203
Validation loss: 2.3636238216072

Epoch: 6| Step: 6
Training loss: 1.7671997547149658
Validation loss: 2.3297963398759083

Epoch: 6| Step: 7
Training loss: 2.9247817993164062
Validation loss: 2.3048242035732476

Epoch: 6| Step: 8
Training loss: 2.9461379051208496
Validation loss: 2.298000954812573

Epoch: 6| Step: 9
Training loss: 2.5390784740448
Validation loss: 2.2946876889915875

Epoch: 6| Step: 10
Training loss: 3.319611072540283
Validation loss: 2.3030626286742506

Epoch: 6| Step: 11
Training loss: 2.7872462272644043
Validation loss: 2.3088239828745523

Epoch: 6| Step: 12
Training loss: 2.0943567752838135
Validation loss: 2.309377880506618

Epoch: 6| Step: 13
Training loss: 3.4475064277648926
Validation loss: 2.3254392505973898

Epoch: 65| Step: 0
Training loss: 2.213338851928711
Validation loss: 2.3065027318974978

Epoch: 6| Step: 1
Training loss: 2.060863971710205
Validation loss: 2.3022185987041843

Epoch: 6| Step: 2
Training loss: 2.6420650482177734
Validation loss: 2.3010871102732997

Epoch: 6| Step: 3
Training loss: 2.576889753341675
Validation loss: 2.3032523931995517

Epoch: 6| Step: 4
Training loss: 2.4091169834136963
Validation loss: 2.318433941051524

Epoch: 6| Step: 5
Training loss: 2.571962356567383
Validation loss: 2.3636740458908903

Epoch: 6| Step: 6
Training loss: 2.436248779296875
Validation loss: 2.398545503616333

Epoch: 6| Step: 7
Training loss: 2.770958185195923
Validation loss: 2.4416130537627847

Epoch: 6| Step: 8
Training loss: 3.014090061187744
Validation loss: 2.4576155395917993

Epoch: 6| Step: 9
Training loss: 2.3415441513061523
Validation loss: 2.414528657031316

Epoch: 6| Step: 10
Training loss: 2.722764015197754
Validation loss: 2.365906024491915

Epoch: 6| Step: 11
Training loss: 2.8949856758117676
Validation loss: 2.3254883955883723

Epoch: 6| Step: 12
Training loss: 2.9083852767944336
Validation loss: 2.319834234893963

Epoch: 6| Step: 13
Training loss: 3.1812081336975098
Validation loss: 2.3077886796766713

Epoch: 66| Step: 0
Training loss: 2.308933734893799
Validation loss: 2.307571654678673

Epoch: 6| Step: 1
Training loss: 2.84603214263916
Validation loss: 2.3065418889445644

Epoch: 6| Step: 2
Training loss: 2.230311393737793
Validation loss: 2.3075994394158803

Epoch: 6| Step: 3
Training loss: 2.2611122131347656
Validation loss: 2.300682465235392

Epoch: 6| Step: 4
Training loss: 2.6232399940490723
Validation loss: 2.3084836467619865

Epoch: 6| Step: 5
Training loss: 2.5301473140716553
Validation loss: 2.301949331837316

Epoch: 6| Step: 6
Training loss: 2.807652711868286
Validation loss: 2.291884119792651

Epoch: 6| Step: 7
Training loss: 2.5088295936584473
Validation loss: 2.2905044042935936

Epoch: 6| Step: 8
Training loss: 2.761157512664795
Validation loss: 2.2870825131734214

Epoch: 6| Step: 9
Training loss: 3.0662331581115723
Validation loss: 2.282034715016683

Epoch: 6| Step: 10
Training loss: 2.8490376472473145
Validation loss: 2.2844428657203593

Epoch: 6| Step: 11
Training loss: 2.210425853729248
Validation loss: 2.287659322061846

Epoch: 6| Step: 12
Training loss: 2.5482211112976074
Validation loss: 2.289154432153189

Epoch: 6| Step: 13
Training loss: 2.9456961154937744
Validation loss: 2.3043320204622004

Epoch: 67| Step: 0
Training loss: 3.1967287063598633
Validation loss: 2.31454014009045

Epoch: 6| Step: 1
Training loss: 2.635519027709961
Validation loss: 2.3227625739189888

Epoch: 6| Step: 2
Training loss: 2.011763095855713
Validation loss: 2.3124152947497625

Epoch: 6| Step: 3
Training loss: 2.822899341583252
Validation loss: 2.3065774492038194

Epoch: 6| Step: 4
Training loss: 2.5137288570404053
Validation loss: 2.3009543521429903

Epoch: 6| Step: 5
Training loss: 1.861238956451416
Validation loss: 2.3113887874029015

Epoch: 6| Step: 6
Training loss: 2.051237106323242
Validation loss: 2.31052202563132

Epoch: 6| Step: 7
Training loss: 2.7369887828826904
Validation loss: 2.3309754017860658

Epoch: 6| Step: 8
Training loss: 2.5889532566070557
Validation loss: 2.350510921529544

Epoch: 6| Step: 9
Training loss: 2.350933790206909
Validation loss: 2.3457775885058987

Epoch: 6| Step: 10
Training loss: 2.562467575073242
Validation loss: 2.3314939980865805

Epoch: 6| Step: 11
Training loss: 2.8688101768493652
Validation loss: 2.332239673983666

Epoch: 6| Step: 12
Training loss: 2.734377384185791
Validation loss: 2.3201352985956336

Epoch: 6| Step: 13
Training loss: 3.401353120803833
Validation loss: 2.3142842990095898

Epoch: 68| Step: 0
Training loss: 2.8541245460510254
Validation loss: 2.3189549317923923

Epoch: 6| Step: 1
Training loss: 2.4607791900634766
Validation loss: 2.3057331756878923

Epoch: 6| Step: 2
Training loss: 2.5198538303375244
Validation loss: 2.3150664785856843

Epoch: 6| Step: 3
Training loss: 2.7690587043762207
Validation loss: 2.3068921386554675

Epoch: 6| Step: 4
Training loss: 3.2686538696289062
Validation loss: 2.316081646950014

Epoch: 6| Step: 5
Training loss: 2.014503002166748
Validation loss: 2.3246552405818814

Epoch: 6| Step: 6
Training loss: 2.2607831954956055
Validation loss: 2.315266755319411

Epoch: 6| Step: 7
Training loss: 3.1897144317626953
Validation loss: 2.3147083866980767

Epoch: 6| Step: 8
Training loss: 2.877230644226074
Validation loss: 2.298715588867023

Epoch: 6| Step: 9
Training loss: 2.2853450775146484
Validation loss: 2.281970634255358

Epoch: 6| Step: 10
Training loss: 2.233530044555664
Validation loss: 2.2809144553317817

Epoch: 6| Step: 11
Training loss: 1.9693269729614258
Validation loss: 2.2733642208960747

Epoch: 6| Step: 12
Training loss: 2.622468948364258
Validation loss: 2.269863379898892

Epoch: 6| Step: 13
Training loss: 2.4886605739593506
Validation loss: 2.2714431285858154

Epoch: 69| Step: 0
Training loss: 2.9497485160827637
Validation loss: 2.265858281043268

Epoch: 6| Step: 1
Training loss: 2.7852330207824707
Validation loss: 2.2691240464487383

Epoch: 6| Step: 2
Training loss: 1.3052623271942139
Validation loss: 2.267919553223477

Epoch: 6| Step: 3
Training loss: 2.8688957691192627
Validation loss: 2.2782335140371837

Epoch: 6| Step: 4
Training loss: 2.6376953125
Validation loss: 2.2730988199992845

Epoch: 6| Step: 5
Training loss: 2.7535388469696045
Validation loss: 2.2715055045261177

Epoch: 6| Step: 6
Training loss: 2.5656299591064453
Validation loss: 2.281816244125366

Epoch: 6| Step: 7
Training loss: 2.631809711456299
Validation loss: 2.292608840491182

Epoch: 6| Step: 8
Training loss: 1.9843270778656006
Validation loss: 2.3165269538920414

Epoch: 6| Step: 9
Training loss: 2.750833749771118
Validation loss: 2.3572609680955128

Epoch: 6| Step: 10
Training loss: 2.4745230674743652
Validation loss: 2.3900168736775718

Epoch: 6| Step: 11
Training loss: 2.6627955436706543
Validation loss: 2.342955022729853

Epoch: 6| Step: 12
Training loss: 3.272733688354492
Validation loss: 2.289611070386825

Epoch: 6| Step: 13
Training loss: 2.078589916229248
Validation loss: 2.2675947809732087

Epoch: 70| Step: 0
Training loss: 2.7797513008117676
Validation loss: 2.2622951666514077

Epoch: 6| Step: 1
Training loss: 2.817782163619995
Validation loss: 2.27448336796094

Epoch: 6| Step: 2
Training loss: 2.7011446952819824
Validation loss: 2.2752222015011694

Epoch: 6| Step: 3
Training loss: 2.210555076599121
Validation loss: 2.3081529550654913

Epoch: 6| Step: 4
Training loss: 2.59110951423645
Validation loss: 2.3134757652077624

Epoch: 6| Step: 5
Training loss: 3.3933265209198
Validation loss: 2.3484204251279115

Epoch: 6| Step: 6
Training loss: 2.592602014541626
Validation loss: 2.3112412293752036

Epoch: 6| Step: 7
Training loss: 1.6269251108169556
Validation loss: 2.302881330572149

Epoch: 6| Step: 8
Training loss: 2.340557098388672
Validation loss: 2.272566141620759

Epoch: 6| Step: 9
Training loss: 2.186197280883789
Validation loss: 2.282470947952681

Epoch: 6| Step: 10
Training loss: 2.342517852783203
Validation loss: 2.2828328583830144

Epoch: 6| Step: 11
Training loss: 2.871664047241211
Validation loss: 2.2991075054291756

Epoch: 6| Step: 12
Training loss: 2.3037848472595215
Validation loss: 2.309900975996448

Epoch: 6| Step: 13
Training loss: 3.9974610805511475
Validation loss: 2.32990034421285

Epoch: 71| Step: 0
Training loss: 3.0633482933044434
Validation loss: 2.314304749170939

Epoch: 6| Step: 1
Training loss: 1.680795669555664
Validation loss: 2.296413010166537

Epoch: 6| Step: 2
Training loss: 2.691267490386963
Validation loss: 2.298194036688856

Epoch: 6| Step: 3
Training loss: 2.244504928588867
Validation loss: 2.306807576969106

Epoch: 6| Step: 4
Training loss: 3.4724490642547607
Validation loss: 2.316924282299575

Epoch: 6| Step: 5
Training loss: 3.4200220108032227
Validation loss: 2.2886443266304592

Epoch: 6| Step: 6
Training loss: 2.314176082611084
Validation loss: 2.2696296630367154

Epoch: 6| Step: 7
Training loss: 2.1049561500549316
Validation loss: 2.2582573365139704

Epoch: 6| Step: 8
Training loss: 2.4008047580718994
Validation loss: 2.2482992910569712

Epoch: 6| Step: 9
Training loss: 2.443537712097168
Validation loss: 2.250665451890679

Epoch: 6| Step: 10
Training loss: 2.420536994934082
Validation loss: 2.252518359050956

Epoch: 6| Step: 11
Training loss: 2.429269313812256
Validation loss: 2.2591681044588805

Epoch: 6| Step: 12
Training loss: 2.798415422439575
Validation loss: 2.2611273411781556

Epoch: 6| Step: 13
Training loss: 2.240603446960449
Validation loss: 2.260124667998283

Epoch: 72| Step: 0
Training loss: 2.912153959274292
Validation loss: 2.2582712019643476

Epoch: 6| Step: 1
Training loss: 2.74082612991333
Validation loss: 2.254694700241089

Epoch: 6| Step: 2
Training loss: 2.1128792762756348
Validation loss: 2.2575856267765

Epoch: 6| Step: 3
Training loss: 2.226719379425049
Validation loss: 2.257317586611676

Epoch: 6| Step: 4
Training loss: 1.9657249450683594
Validation loss: 2.2607229089224212

Epoch: 6| Step: 5
Training loss: 3.263777256011963
Validation loss: 2.273106357102753

Epoch: 6| Step: 6
Training loss: 2.685001850128174
Validation loss: 2.278332128319689

Epoch: 6| Step: 7
Training loss: 1.3696134090423584
Validation loss: 2.2865189506161596

Epoch: 6| Step: 8
Training loss: 2.97188401222229
Validation loss: 2.286637706141318

Epoch: 6| Step: 9
Training loss: 2.9560487270355225
Validation loss: 2.30449838279396

Epoch: 6| Step: 10
Training loss: 3.6694679260253906
Validation loss: 2.3267842262021956

Epoch: 6| Step: 11
Training loss: 2.2311229705810547
Validation loss: 2.336415834324334

Epoch: 6| Step: 12
Training loss: 2.6121737957000732
Validation loss: 2.3208718504956973

Epoch: 6| Step: 13
Training loss: 1.586530089378357
Validation loss: 2.2987254306834233

Epoch: 73| Step: 0
Training loss: 2.7865800857543945
Validation loss: 2.2841399882429387

Epoch: 6| Step: 1
Training loss: 2.71453857421875
Validation loss: 2.271104374239522

Epoch: 6| Step: 2
Training loss: 2.3055787086486816
Validation loss: 2.2601120318135908

Epoch: 6| Step: 3
Training loss: 2.6602907180786133
Validation loss: 2.2565448796877297

Epoch: 6| Step: 4
Training loss: 2.3432459831237793
Validation loss: 2.247749792632236

Epoch: 6| Step: 5
Training loss: 3.0337700843811035
Validation loss: 2.247272722182735

Epoch: 6| Step: 6
Training loss: 2.679739475250244
Validation loss: 2.245470295670212

Epoch: 6| Step: 7
Training loss: 3.281738519668579
Validation loss: 2.2414522888839885

Epoch: 6| Step: 8
Training loss: 2.7468581199645996
Validation loss: 2.243022093208887

Epoch: 6| Step: 9
Training loss: 2.6087701320648193
Validation loss: 2.24136931409118

Epoch: 6| Step: 10
Training loss: 1.8052242994308472
Validation loss: 2.2442280797548193

Epoch: 6| Step: 11
Training loss: 2.065251350402832
Validation loss: 2.2445740776677288

Epoch: 6| Step: 12
Training loss: 2.142991781234741
Validation loss: 2.261939899895781

Epoch: 6| Step: 13
Training loss: 2.470088005065918
Validation loss: 2.265906564650997

Epoch: 74| Step: 0
Training loss: 2.1779680252075195
Validation loss: 2.2604198378901326

Epoch: 6| Step: 1
Training loss: 2.548328399658203
Validation loss: 2.2635703471399125

Epoch: 6| Step: 2
Training loss: 2.4014244079589844
Validation loss: 2.2659861938927763

Epoch: 6| Step: 3
Training loss: 2.282811164855957
Validation loss: 2.2649134153960855

Epoch: 6| Step: 4
Training loss: 2.486656665802002
Validation loss: 2.2646392853029313

Epoch: 6| Step: 5
Training loss: 2.3741655349731445
Validation loss: 2.2624688071589314

Epoch: 6| Step: 6
Training loss: 2.7857775688171387
Validation loss: 2.2625489978380102

Epoch: 6| Step: 7
Training loss: 2.4700353145599365
Validation loss: 2.256616133515553

Epoch: 6| Step: 8
Training loss: 2.6981277465820312
Validation loss: 2.249327431442917

Epoch: 6| Step: 9
Training loss: 2.6642253398895264
Validation loss: 2.2455322460461686

Epoch: 6| Step: 10
Training loss: 2.1070609092712402
Validation loss: 2.2500916065708285

Epoch: 6| Step: 11
Training loss: 3.004410982131958
Validation loss: 2.242353170148788

Epoch: 6| Step: 12
Training loss: 3.14027738571167
Validation loss: 2.2498570539618052

Epoch: 6| Step: 13
Training loss: 2.145354747772217
Validation loss: 2.2504739633170505

Epoch: 75| Step: 0
Training loss: 2.6653008460998535
Validation loss: 2.2452685858613703

Epoch: 6| Step: 1
Training loss: 2.238480567932129
Validation loss: 2.249674913703754

Epoch: 6| Step: 2
Training loss: 2.441171169281006
Validation loss: 2.2459091781288065

Epoch: 6| Step: 3
Training loss: 2.198645830154419
Validation loss: 2.2317268668964343

Epoch: 6| Step: 4
Training loss: 2.668790340423584
Validation loss: 2.2337263373918432

Epoch: 6| Step: 5
Training loss: 2.756836175918579
Validation loss: 2.2300756772359214

Epoch: 6| Step: 6
Training loss: 3.543221950531006
Validation loss: 2.2325030783171296

Epoch: 6| Step: 7
Training loss: 2.2462854385375977
Validation loss: 2.225149275154196

Epoch: 6| Step: 8
Training loss: 2.4308018684387207
Validation loss: 2.224247194105579

Epoch: 6| Step: 9
Training loss: 2.2194793224334717
Validation loss: 2.2295727524706113

Epoch: 6| Step: 10
Training loss: 2.2280731201171875
Validation loss: 2.234656483896317

Epoch: 6| Step: 11
Training loss: 3.373990058898926
Validation loss: 2.231470546414775

Epoch: 6| Step: 12
Training loss: 1.5945098400115967
Validation loss: 2.240970967918314

Epoch: 6| Step: 13
Training loss: 2.856142282485962
Validation loss: 2.2374494152684368

Epoch: 76| Step: 0
Training loss: 2.974942922592163
Validation loss: 2.2307711519220823

Epoch: 6| Step: 1
Training loss: 2.4427731037139893
Validation loss: 2.22434494315937

Epoch: 6| Step: 2
Training loss: 2.5371346473693848
Validation loss: 2.2274093730475313

Epoch: 6| Step: 3
Training loss: 1.988756537437439
Validation loss: 2.236229322289908

Epoch: 6| Step: 4
Training loss: 2.79641056060791
Validation loss: 2.236921041242538

Epoch: 6| Step: 5
Training loss: 2.739672899246216
Validation loss: 2.2317322274690032

Epoch: 6| Step: 6
Training loss: 2.1167445182800293
Validation loss: 2.221691469992361

Epoch: 6| Step: 7
Training loss: 2.2211191654205322
Validation loss: 2.221607426161407

Epoch: 6| Step: 8
Training loss: 2.7259681224823
Validation loss: 2.232714265905401

Epoch: 6| Step: 9
Training loss: 2.206820249557495
Validation loss: 2.2230247553958686

Epoch: 6| Step: 10
Training loss: 2.2458598613739014
Validation loss: 2.230096452979631

Epoch: 6| Step: 11
Training loss: 3.2878146171569824
Validation loss: 2.2385011642209944

Epoch: 6| Step: 12
Training loss: 2.392155647277832
Validation loss: 2.238403356203469

Epoch: 6| Step: 13
Training loss: 2.566434144973755
Validation loss: 2.2408859563130203

Epoch: 77| Step: 0
Training loss: 2.5345640182495117
Validation loss: 2.2483897670622794

Epoch: 6| Step: 1
Training loss: 2.6734018325805664
Validation loss: 2.2453147698474187

Epoch: 6| Step: 2
Training loss: 2.9525489807128906
Validation loss: 2.251627468293713

Epoch: 6| Step: 3
Training loss: 2.273805856704712
Validation loss: 2.2346006824124243

Epoch: 6| Step: 4
Training loss: 1.995252013206482
Validation loss: 2.245352270782635

Epoch: 6| Step: 5
Training loss: 2.608767032623291
Validation loss: 2.2364688637436076

Epoch: 6| Step: 6
Training loss: 2.9542531967163086
Validation loss: 2.2312467098236084

Epoch: 6| Step: 7
Training loss: 2.6074378490448
Validation loss: 2.220694690622309

Epoch: 6| Step: 8
Training loss: 2.328713893890381
Validation loss: 2.2170728611689743

Epoch: 6| Step: 9
Training loss: 2.453371047973633
Validation loss: 2.213360676201441

Epoch: 6| Step: 10
Training loss: 2.124096393585205
Validation loss: 2.21199538887188

Epoch: 6| Step: 11
Training loss: 2.619371175765991
Validation loss: 2.214261616429975

Epoch: 6| Step: 12
Training loss: 2.4624710083007812
Validation loss: 2.202714127878989

Epoch: 6| Step: 13
Training loss: 2.6606287956237793
Validation loss: 2.202935552084318

Epoch: 78| Step: 0
Training loss: 2.307760715484619
Validation loss: 2.206688578410815

Epoch: 6| Step: 1
Training loss: 2.091806411743164
Validation loss: 2.210816926853631

Epoch: 6| Step: 2
Training loss: 2.1484875679016113
Validation loss: 2.220531589241438

Epoch: 6| Step: 3
Training loss: 2.023581027984619
Validation loss: 2.2403626031773065

Epoch: 6| Step: 4
Training loss: 3.029039144515991
Validation loss: 2.2468969360474618

Epoch: 6| Step: 5
Training loss: 2.7405762672424316
Validation loss: 2.2570261237441853

Epoch: 6| Step: 6
Training loss: 2.3842992782592773
Validation loss: 2.267711229221795

Epoch: 6| Step: 7
Training loss: 2.506373405456543
Validation loss: 2.2457904918219453

Epoch: 6| Step: 8
Training loss: 2.823157548904419
Validation loss: 2.2857065290533085

Epoch: 6| Step: 9
Training loss: 2.648280620574951
Validation loss: 2.262585375898628

Epoch: 6| Step: 10
Training loss: 2.769686698913574
Validation loss: 2.233964189406364

Epoch: 6| Step: 11
Training loss: 2.244328260421753
Validation loss: 2.2084623716210805

Epoch: 6| Step: 12
Training loss: 2.562286376953125
Validation loss: 2.2066570815219673

Epoch: 6| Step: 13
Training loss: 3.0540647506713867
Validation loss: 2.19993233424361

Epoch: 79| Step: 0
Training loss: 2.0102102756500244
Validation loss: 2.202413930687853

Epoch: 6| Step: 1
Training loss: 3.2030539512634277
Validation loss: 2.1950751658408874

Epoch: 6| Step: 2
Training loss: 2.648059844970703
Validation loss: 2.2007460799268497

Epoch: 6| Step: 3
Training loss: 2.4214463233947754
Validation loss: 2.1962061364163636

Epoch: 6| Step: 4
Training loss: 2.012754440307617
Validation loss: 2.194776641425266

Epoch: 6| Step: 5
Training loss: 2.410845994949341
Validation loss: 2.197073778798503

Epoch: 6| Step: 6
Training loss: 2.8745765686035156
Validation loss: 2.2021398839130195

Epoch: 6| Step: 7
Training loss: 2.56664776802063
Validation loss: 2.198758558560443

Epoch: 6| Step: 8
Training loss: 2.8826613426208496
Validation loss: 2.2095529443474224

Epoch: 6| Step: 9
Training loss: 1.7732799053192139
Validation loss: 2.2171907296744724

Epoch: 6| Step: 10
Training loss: 2.6608238220214844
Validation loss: 2.2166100727614535

Epoch: 6| Step: 11
Training loss: 2.77077579498291
Validation loss: 2.226708427552254

Epoch: 6| Step: 12
Training loss: 2.4810736179351807
Validation loss: 2.237755706233363

Epoch: 6| Step: 13
Training loss: 1.868508219718933
Validation loss: 2.2483710140310307

Epoch: 80| Step: 0
Training loss: 3.0088510513305664
Validation loss: 2.232736800306587

Epoch: 6| Step: 1
Training loss: 2.4892029762268066
Validation loss: 2.2139594042172996

Epoch: 6| Step: 2
Training loss: 2.646998405456543
Validation loss: 2.2037243650805567

Epoch: 6| Step: 3
Training loss: 2.7931346893310547
Validation loss: 2.1969486436536236

Epoch: 6| Step: 4
Training loss: 2.595594644546509
Validation loss: 2.19073325075129

Epoch: 6| Step: 5
Training loss: 2.0989584922790527
Validation loss: 2.198437713807629

Epoch: 6| Step: 6
Training loss: 2.652425765991211
Validation loss: 2.1994238720145276

Epoch: 6| Step: 7
Training loss: 2.503479242324829
Validation loss: 2.2034188009077504

Epoch: 6| Step: 8
Training loss: 2.320761203765869
Validation loss: 2.199656096837854

Epoch: 6| Step: 9
Training loss: 2.5502066612243652
Validation loss: 2.1840031839186147

Epoch: 6| Step: 10
Training loss: 2.4836392402648926
Validation loss: 2.1867244423076673

Epoch: 6| Step: 11
Training loss: 1.7217271327972412
Validation loss: 2.1888084206529843

Epoch: 6| Step: 12
Training loss: 2.34450101852417
Validation loss: 2.185805023357432

Epoch: 6| Step: 13
Training loss: 2.667512893676758
Validation loss: 2.1863317720351683

Epoch: 81| Step: 0
Training loss: 2.4887843132019043
Validation loss: 2.197135668928905

Epoch: 6| Step: 1
Training loss: 2.7939131259918213
Validation loss: 2.1986709589599283

Epoch: 6| Step: 2
Training loss: 3.0443758964538574
Validation loss: 2.1988841718243015

Epoch: 6| Step: 3
Training loss: 2.6229124069213867
Validation loss: 2.2027347267314954

Epoch: 6| Step: 4
Training loss: 1.9519826173782349
Validation loss: 2.20845385777053

Epoch: 6| Step: 5
Training loss: 3.0247085094451904
Validation loss: 2.2025396567518993

Epoch: 6| Step: 6
Training loss: 2.6440680027008057
Validation loss: 2.196466666395946

Epoch: 6| Step: 7
Training loss: 1.6301946640014648
Validation loss: 2.1891367717455794

Epoch: 6| Step: 8
Training loss: 2.200559616088867
Validation loss: 2.1973749950367916

Epoch: 6| Step: 9
Training loss: 2.0403690338134766
Validation loss: 2.1973640534185592

Epoch: 6| Step: 10
Training loss: 2.5812766551971436
Validation loss: 2.200324708415616

Epoch: 6| Step: 11
Training loss: 2.223222255706787
Validation loss: 2.216892155267859

Epoch: 6| Step: 12
Training loss: 2.3595080375671387
Validation loss: 2.245037204475813

Epoch: 6| Step: 13
Training loss: 3.598924398422241
Validation loss: 2.2863653372692805

Epoch: 82| Step: 0
Training loss: 3.3258814811706543
Validation loss: 2.2724989921815935

Epoch: 6| Step: 1
Training loss: 2.4458065032958984
Validation loss: 2.2343415726897535

Epoch: 6| Step: 2
Training loss: 2.1371188163757324
Validation loss: 2.198292460492862

Epoch: 6| Step: 3
Training loss: 2.4102141857147217
Validation loss: 2.173439223279235

Epoch: 6| Step: 4
Training loss: 1.9391218423843384
Validation loss: 2.171031657085624

Epoch: 6| Step: 5
Training loss: 2.847701072692871
Validation loss: 2.1674320697784424

Epoch: 6| Step: 6
Training loss: 2.3202149868011475
Validation loss: 2.172714005234421

Epoch: 6| Step: 7
Training loss: 1.8074405193328857
Validation loss: 2.177671624768165

Epoch: 6| Step: 8
Training loss: 2.4183971881866455
Validation loss: 2.1818430193008913

Epoch: 6| Step: 9
Training loss: 2.545238494873047
Validation loss: 2.183495834309568

Epoch: 6| Step: 10
Training loss: 2.8868415355682373
Validation loss: 2.168049837953301

Epoch: 6| Step: 11
Training loss: 2.4660983085632324
Validation loss: 2.1633077283059396

Epoch: 6| Step: 12
Training loss: 2.6160836219787598
Validation loss: 2.1594353388714533

Epoch: 6| Step: 13
Training loss: 2.92405366897583
Validation loss: 2.1604954632379676

Epoch: 83| Step: 0
Training loss: 2.0191824436187744
Validation loss: 2.189102575343142

Epoch: 6| Step: 1
Training loss: 3.1040091514587402
Validation loss: 2.200739763116324

Epoch: 6| Step: 2
Training loss: 2.3729569911956787
Validation loss: 2.2469784162377797

Epoch: 6| Step: 3
Training loss: 2.4035205841064453
Validation loss: 2.2405977697782617

Epoch: 6| Step: 4
Training loss: 2.0308079719543457
Validation loss: 2.249398123833441

Epoch: 6| Step: 5
Training loss: 1.9118343591690063
Validation loss: 2.214537351362167

Epoch: 6| Step: 6
Training loss: 2.1386306285858154
Validation loss: 2.181874862281225

Epoch: 6| Step: 7
Training loss: 2.567124843597412
Validation loss: 2.1698436173059608

Epoch: 6| Step: 8
Training loss: 2.2368602752685547
Validation loss: 2.1684829265840593

Epoch: 6| Step: 9
Training loss: 2.8072614669799805
Validation loss: 2.164726536761048

Epoch: 6| Step: 10
Training loss: 2.5732555389404297
Validation loss: 2.170463595339047

Epoch: 6| Step: 11
Training loss: 2.5117266178131104
Validation loss: 2.1720371861611643

Epoch: 6| Step: 12
Training loss: 3.158620834350586
Validation loss: 2.172414154134771

Epoch: 6| Step: 13
Training loss: 3.2059667110443115
Validation loss: 2.1818307112622004

Epoch: 84| Step: 0
Training loss: 2.7711410522460938
Validation loss: 2.1693685464961554

Epoch: 6| Step: 1
Training loss: 2.4176602363586426
Validation loss: 2.162186905901919

Epoch: 6| Step: 2
Training loss: 2.7927961349487305
Validation loss: 2.166193272477837

Epoch: 6| Step: 3
Training loss: 2.1355910301208496
Validation loss: 2.154003830366237

Epoch: 6| Step: 4
Training loss: 3.055734872817993
Validation loss: 2.156013032441498

Epoch: 6| Step: 5
Training loss: 1.8282727003097534
Validation loss: 2.1564682606727845

Epoch: 6| Step: 6
Training loss: 2.7519304752349854
Validation loss: 2.159867395636856

Epoch: 6| Step: 7
Training loss: 2.1250743865966797
Validation loss: 2.1620991306920208

Epoch: 6| Step: 8
Training loss: 2.4966039657592773
Validation loss: 2.162943532389979

Epoch: 6| Step: 9
Training loss: 2.854890823364258
Validation loss: 2.164754895753758

Epoch: 6| Step: 10
Training loss: 2.2815051078796387
Validation loss: 2.169314399842293

Epoch: 6| Step: 11
Training loss: 2.4899520874023438
Validation loss: 2.177706686399316

Epoch: 6| Step: 12
Training loss: 2.1733052730560303
Validation loss: 2.1878703794171734

Epoch: 6| Step: 13
Training loss: 2.2403581142425537
Validation loss: 2.214380011763624

Epoch: 85| Step: 0
Training loss: 2.17911434173584
Validation loss: 2.2508760729143695

Epoch: 6| Step: 1
Training loss: 1.976436734199524
Validation loss: 2.289283724241359

Epoch: 6| Step: 2
Training loss: 2.544076919555664
Validation loss: 2.2852087995057464

Epoch: 6| Step: 3
Training loss: 2.5546422004699707
Validation loss: 2.2437108306474585

Epoch: 6| Step: 4
Training loss: 2.511841297149658
Validation loss: 2.2358142227254887

Epoch: 6| Step: 5
Training loss: 2.912611246109009
Validation loss: 2.2248266537984214

Epoch: 6| Step: 6
Training loss: 3.422863245010376
Validation loss: 2.2030690818704586

Epoch: 6| Step: 7
Training loss: 2.6542468070983887
Validation loss: 2.1743400994167534

Epoch: 6| Step: 8
Training loss: 2.6474452018737793
Validation loss: 2.1577253226310975

Epoch: 6| Step: 9
Training loss: 2.1230034828186035
Validation loss: 2.153622442676175

Epoch: 6| Step: 10
Training loss: 1.9087750911712646
Validation loss: 2.1490537504996023

Epoch: 6| Step: 11
Training loss: 2.392406463623047
Validation loss: 2.156452041800304

Epoch: 6| Step: 12
Training loss: 2.599396228790283
Validation loss: 2.143707977828159

Epoch: 6| Step: 13
Training loss: 2.27228045463562
Validation loss: 2.1506096316922094

Epoch: 86| Step: 0
Training loss: 2.6703004837036133
Validation loss: 2.1591871335942256

Epoch: 6| Step: 1
Training loss: 2.5331342220306396
Validation loss: 2.166171286695747

Epoch: 6| Step: 2
Training loss: 2.669872999191284
Validation loss: 2.1893718293918076

Epoch: 6| Step: 3
Training loss: 2.8905093669891357
Validation loss: 2.2343771278217273

Epoch: 6| Step: 4
Training loss: 2.153470277786255
Validation loss: 2.2433198754505446

Epoch: 6| Step: 5
Training loss: 2.0569238662719727
Validation loss: 2.2432034810384116

Epoch: 6| Step: 6
Training loss: 2.5736405849456787
Validation loss: 2.223227357351652

Epoch: 6| Step: 7
Training loss: 2.774855136871338
Validation loss: 2.186205211506095

Epoch: 6| Step: 8
Training loss: 2.4444377422332764
Validation loss: 2.157405690480304

Epoch: 6| Step: 9
Training loss: 2.4367189407348633
Validation loss: 2.15239288473642

Epoch: 6| Step: 10
Training loss: 2.163907527923584
Validation loss: 2.1522569143643944

Epoch: 6| Step: 11
Training loss: 1.9028608798980713
Validation loss: 2.1610265931775494

Epoch: 6| Step: 12
Training loss: 2.4458203315734863
Validation loss: 2.163017044785202

Epoch: 6| Step: 13
Training loss: 3.1868767738342285
Validation loss: 2.1662850892671974

Epoch: 87| Step: 0
Training loss: 3.002119541168213
Validation loss: 2.1773652363848943

Epoch: 6| Step: 1
Training loss: 2.146698474884033
Validation loss: 2.1712009599131923

Epoch: 6| Step: 2
Training loss: 2.6923587322235107
Validation loss: 2.171560589985181

Epoch: 6| Step: 3
Training loss: 1.9185004234313965
Validation loss: 2.1621260899369434

Epoch: 6| Step: 4
Training loss: 2.5826079845428467
Validation loss: 2.1649780286255704

Epoch: 6| Step: 5
Training loss: 2.289466619491577
Validation loss: 2.175528657051825

Epoch: 6| Step: 6
Training loss: 3.210900068283081
Validation loss: 2.1773812847752727

Epoch: 6| Step: 7
Training loss: 2.5879011154174805
Validation loss: 2.190535245403167

Epoch: 6| Step: 8
Training loss: 2.7186617851257324
Validation loss: 2.183457136154175

Epoch: 6| Step: 9
Training loss: 2.1208202838897705
Validation loss: 2.182583516643893

Epoch: 6| Step: 10
Training loss: 2.4359242916107178
Validation loss: 2.179624634404336

Epoch: 6| Step: 11
Training loss: 1.7890840768814087
Validation loss: 2.1868152951681488

Epoch: 6| Step: 12
Training loss: 2.224398612976074
Validation loss: 2.176816658307147

Epoch: 6| Step: 13
Training loss: 2.514490842819214
Validation loss: 2.186608486278083

Epoch: 88| Step: 0
Training loss: 2.5140485763549805
Validation loss: 2.1653729126017582

Epoch: 6| Step: 1
Training loss: 2.446155071258545
Validation loss: 2.1614950164671867

Epoch: 6| Step: 2
Training loss: 2.1738181114196777
Validation loss: 2.15222426127362

Epoch: 6| Step: 3
Training loss: 1.9714093208312988
Validation loss: 2.1530481692283385

Epoch: 6| Step: 4
Training loss: 2.4957189559936523
Validation loss: 2.156934097249021

Epoch: 6| Step: 5
Training loss: 2.305901527404785
Validation loss: 2.1629404150029665

Epoch: 6| Step: 6
Training loss: 2.1305713653564453
Validation loss: 2.1611661526464645

Epoch: 6| Step: 7
Training loss: 1.6955928802490234
Validation loss: 2.1648751407541256

Epoch: 6| Step: 8
Training loss: 3.01937198638916
Validation loss: 2.161467224039057

Epoch: 6| Step: 9
Training loss: 2.718404531478882
Validation loss: 2.167362992481519

Epoch: 6| Step: 10
Training loss: 2.723015069961548
Validation loss: 2.1559501873549594

Epoch: 6| Step: 11
Training loss: 2.396852493286133
Validation loss: 2.146935365533316

Epoch: 6| Step: 12
Training loss: 2.852919101715088
Validation loss: 2.147455355172516

Epoch: 6| Step: 13
Training loss: 2.7864208221435547
Validation loss: 2.147688670824933

Epoch: 89| Step: 0
Training loss: 1.939515233039856
Validation loss: 2.149806971191078

Epoch: 6| Step: 1
Training loss: 3.0836827754974365
Validation loss: 2.1466421516992713

Epoch: 6| Step: 2
Training loss: 2.323115348815918
Validation loss: 2.1485736318813857

Epoch: 6| Step: 3
Training loss: 2.60166072845459
Validation loss: 2.144002805473984

Epoch: 6| Step: 4
Training loss: 2.5846643447875977
Validation loss: 2.149460892523489

Epoch: 6| Step: 5
Training loss: 2.8395233154296875
Validation loss: 2.14052822256601

Epoch: 6| Step: 6
Training loss: 2.350558280944824
Validation loss: 2.130002857536398

Epoch: 6| Step: 7
Training loss: 2.17274808883667
Validation loss: 2.1247458022127867

Epoch: 6| Step: 8
Training loss: 2.649538040161133
Validation loss: 2.1219497111535843

Epoch: 6| Step: 9
Training loss: 2.249967336654663
Validation loss: 2.147471261280839

Epoch: 6| Step: 10
Training loss: 2.499210834503174
Validation loss: 2.1584159148636686

Epoch: 6| Step: 11
Training loss: 2.6059651374816895
Validation loss: 2.1755383040315364

Epoch: 6| Step: 12
Training loss: 2.088989019393921
Validation loss: 2.2163446564828195

Epoch: 6| Step: 13
Training loss: 2.122468948364258
Validation loss: 2.2117622206288

Epoch: 90| Step: 0
Training loss: 2.638195276260376
Validation loss: 2.1407148094587427

Epoch: 6| Step: 1
Training loss: 2.893606185913086
Validation loss: 2.133782712362146

Epoch: 6| Step: 2
Training loss: 3.2885987758636475
Validation loss: 2.138003777432185

Epoch: 6| Step: 3
Training loss: 2.8113627433776855
Validation loss: 2.1427786081067977

Epoch: 6| Step: 4
Training loss: 1.6397545337677002
Validation loss: 2.1571871157615417

Epoch: 6| Step: 5
Training loss: 2.60427188873291
Validation loss: 2.206002946822874

Epoch: 6| Step: 6
Training loss: 2.3122165203094482
Validation loss: 2.3367504919728925

Epoch: 6| Step: 7
Training loss: 2.635444164276123
Validation loss: 2.3255999370287825

Epoch: 6| Step: 8
Training loss: 3.0931711196899414
Validation loss: 2.2456947808624594

Epoch: 6| Step: 9
Training loss: 2.0648207664489746
Validation loss: 2.1652411466003745

Epoch: 6| Step: 10
Training loss: 1.6296184062957764
Validation loss: 2.121211331377747

Epoch: 6| Step: 11
Training loss: 2.135721206665039
Validation loss: 2.1231269823607577

Epoch: 6| Step: 12
Training loss: 2.7629990577697754
Validation loss: 2.12342377631895

Epoch: 6| Step: 13
Training loss: 2.1442582607269287
Validation loss: 2.1293779201405023

Epoch: 91| Step: 0
Training loss: 1.7963573932647705
Validation loss: 2.1393688994069255

Epoch: 6| Step: 1
Training loss: 3.266951084136963
Validation loss: 2.182503059346189

Epoch: 6| Step: 2
Training loss: 2.462934970855713
Validation loss: 2.191459999289564

Epoch: 6| Step: 3
Training loss: 2.558541774749756
Validation loss: 2.2001859808480866

Epoch: 6| Step: 4
Training loss: 1.9777284860610962
Validation loss: 2.2304131779619443

Epoch: 6| Step: 5
Training loss: 2.2532291412353516
Validation loss: 2.20436643913228

Epoch: 6| Step: 6
Training loss: 1.6724601984024048
Validation loss: 2.18314790725708

Epoch: 6| Step: 7
Training loss: 2.9708542823791504
Validation loss: 2.169052776469979

Epoch: 6| Step: 8
Training loss: 2.4855780601501465
Validation loss: 2.1466146207624868

Epoch: 6| Step: 9
Training loss: 2.6178195476531982
Validation loss: 2.1332819846368607

Epoch: 6| Step: 10
Training loss: 3.078277111053467
Validation loss: 2.120483777856314

Epoch: 6| Step: 11
Training loss: 2.4554569721221924
Validation loss: 2.1184383771752797

Epoch: 6| Step: 12
Training loss: 2.3190460205078125
Validation loss: 2.110661002897447

Epoch: 6| Step: 13
Training loss: 2.264601469039917
Validation loss: 2.1123469260431107

Epoch: 92| Step: 0
Training loss: 2.130896806716919
Validation loss: 2.110683474489438

Epoch: 6| Step: 1
Training loss: 2.941678524017334
Validation loss: 2.114699920018514

Epoch: 6| Step: 2
Training loss: 1.7739750146865845
Validation loss: 2.117293196339761

Epoch: 6| Step: 3
Training loss: 2.1605477333068848
Validation loss: 2.114063133475601

Epoch: 6| Step: 4
Training loss: 1.653700590133667
Validation loss: 2.1147965064612766

Epoch: 6| Step: 5
Training loss: 1.6200432777404785
Validation loss: 2.1166257217366207

Epoch: 6| Step: 6
Training loss: 2.568317413330078
Validation loss: 2.126043091538132

Epoch: 6| Step: 7
Training loss: 3.1090569496154785
Validation loss: 2.136254446480864

Epoch: 6| Step: 8
Training loss: 3.11236572265625
Validation loss: 2.131959858761039

Epoch: 6| Step: 9
Training loss: 2.5591049194335938
Validation loss: 2.142828567053682

Epoch: 6| Step: 10
Training loss: 2.307344436645508
Validation loss: 2.14087817745824

Epoch: 6| Step: 11
Training loss: 2.7650303840637207
Validation loss: 2.1507101546051683

Epoch: 6| Step: 12
Training loss: 2.713209629058838
Validation loss: 2.1474187245932956

Epoch: 6| Step: 13
Training loss: 2.5108888149261475
Validation loss: 2.1599694682705786

Epoch: 93| Step: 0
Training loss: 2.5248684883117676
Validation loss: 2.159449132539893

Epoch: 6| Step: 1
Training loss: 2.0969295501708984
Validation loss: 2.1679544987217074

Epoch: 6| Step: 2
Training loss: 2.2472524642944336
Validation loss: 2.149933635547597

Epoch: 6| Step: 3
Training loss: 3.2444963455200195
Validation loss: 2.144217016876385

Epoch: 6| Step: 4
Training loss: 1.9181334972381592
Validation loss: 2.157520899208643

Epoch: 6| Step: 5
Training loss: 2.2804019451141357
Validation loss: 2.1687568233859156

Epoch: 6| Step: 6
Training loss: 1.6288293600082397
Validation loss: 2.1670302780725623

Epoch: 6| Step: 7
Training loss: 2.132920980453491
Validation loss: 2.1254921036381877

Epoch: 6| Step: 8
Training loss: 2.5368075370788574
Validation loss: 2.123370555139357

Epoch: 6| Step: 9
Training loss: 2.978247880935669
Validation loss: 2.113908508772491

Epoch: 6| Step: 10
Training loss: 2.3762688636779785
Validation loss: 2.1147600348277757

Epoch: 6| Step: 11
Training loss: 2.9251298904418945
Validation loss: 2.1263504848685315

Epoch: 6| Step: 12
Training loss: 2.622791051864624
Validation loss: 2.130678314034657

Epoch: 6| Step: 13
Training loss: 2.274271011352539
Validation loss: 2.134694558317943

Epoch: 94| Step: 0
Training loss: 2.0193591117858887
Validation loss: 2.1291817298499485

Epoch: 6| Step: 1
Training loss: 2.074533224105835
Validation loss: 2.1333896575435514

Epoch: 6| Step: 2
Training loss: 2.6271791458129883
Validation loss: 2.118692144270866

Epoch: 6| Step: 3
Training loss: 2.704500675201416
Validation loss: 2.1314091451706423

Epoch: 6| Step: 4
Training loss: 2.931025505065918
Validation loss: 2.130278241249823

Epoch: 6| Step: 5
Training loss: 2.0318055152893066
Validation loss: 2.1358392084798505

Epoch: 6| Step: 6
Training loss: 2.1804656982421875
Validation loss: 2.146759816395339

Epoch: 6| Step: 7
Training loss: 2.078299045562744
Validation loss: 2.1546165558599655

Epoch: 6| Step: 8
Training loss: 2.4283199310302734
Validation loss: 2.161019072737745

Epoch: 6| Step: 9
Training loss: 2.8039848804473877
Validation loss: 2.1706564759695404

Epoch: 6| Step: 10
Training loss: 2.1859121322631836
Validation loss: 2.165177365785004

Epoch: 6| Step: 11
Training loss: 2.52984881401062
Validation loss: 2.1569441569748746

Epoch: 6| Step: 12
Training loss: 2.704136371612549
Validation loss: 2.147790321739771

Epoch: 6| Step: 13
Training loss: 2.50466251373291
Validation loss: 2.140825876625635

Epoch: 95| Step: 0
Training loss: 2.675661087036133
Validation loss: 2.157481885725452

Epoch: 6| Step: 1
Training loss: 2.150465726852417
Validation loss: 2.151118222103324

Epoch: 6| Step: 2
Training loss: 2.9517762660980225
Validation loss: 2.162316394108598

Epoch: 6| Step: 3
Training loss: 2.0996830463409424
Validation loss: 2.1456411564221947

Epoch: 6| Step: 4
Training loss: 2.223651885986328
Validation loss: 2.1380079971846713

Epoch: 6| Step: 5
Training loss: 2.7801387310028076
Validation loss: 2.124463571015225

Epoch: 6| Step: 6
Training loss: 1.552128553390503
Validation loss: 2.1282918658307803

Epoch: 6| Step: 7
Training loss: 2.6555628776550293
Validation loss: 2.136693194348325

Epoch: 6| Step: 8
Training loss: 2.4732513427734375
Validation loss: 2.1362361138866794

Epoch: 6| Step: 9
Training loss: 2.8989667892456055
Validation loss: 2.1211327891195975

Epoch: 6| Step: 10
Training loss: 2.7782225608825684
Validation loss: 2.10588340861823

Epoch: 6| Step: 11
Training loss: 2.1726503372192383
Validation loss: 2.1046489361793763

Epoch: 6| Step: 12
Training loss: 1.7151249647140503
Validation loss: 2.112122622869348

Epoch: 6| Step: 13
Training loss: 2.4978926181793213
Validation loss: 2.1044440192560994

Epoch: 96| Step: 0
Training loss: 1.9223296642303467
Validation loss: 2.1146213264875513

Epoch: 6| Step: 1
Training loss: 2.699714422225952
Validation loss: 2.110779236721736

Epoch: 6| Step: 2
Training loss: 1.694985270500183
Validation loss: 2.1137878035986297

Epoch: 6| Step: 3
Training loss: 2.5972986221313477
Validation loss: 2.103623672198224

Epoch: 6| Step: 4
Training loss: 2.84842586517334
Validation loss: 2.1038997609128236

Epoch: 6| Step: 5
Training loss: 2.4327170848846436
Validation loss: 2.102622357747888

Epoch: 6| Step: 6
Training loss: 2.190656900405884
Validation loss: 2.1027930064867904

Epoch: 6| Step: 7
Training loss: 1.6892842054367065
Validation loss: 2.0970106586333244

Epoch: 6| Step: 8
Training loss: 2.520111322402954
Validation loss: 2.10233106664432

Epoch: 6| Step: 9
Training loss: 2.5297651290893555
Validation loss: 2.09232561690833

Epoch: 6| Step: 10
Training loss: 2.3057594299316406
Validation loss: 2.0901010472287416

Epoch: 6| Step: 11
Training loss: 2.8584556579589844
Validation loss: 2.087925926331551

Epoch: 6| Step: 12
Training loss: 2.6946234703063965
Validation loss: 2.082230098785893

Epoch: 6| Step: 13
Training loss: 2.714998960494995
Validation loss: 2.0892964281061643

Epoch: 97| Step: 0
Training loss: 2.309473991394043
Validation loss: 2.0940961068676365

Epoch: 6| Step: 1
Training loss: 1.8745996952056885
Validation loss: 2.106018768843784

Epoch: 6| Step: 2
Training loss: 2.6326704025268555
Validation loss: 2.1032751247447026

Epoch: 6| Step: 3
Training loss: 1.8962581157684326
Validation loss: 2.112836948005102

Epoch: 6| Step: 4
Training loss: 1.9228953123092651
Validation loss: 2.129859588479483

Epoch: 6| Step: 5
Training loss: 2.884662389755249
Validation loss: 2.1332897499043453

Epoch: 6| Step: 6
Training loss: 2.5572969913482666
Validation loss: 2.14697491609922

Epoch: 6| Step: 7
Training loss: 3.716331958770752
Validation loss: 2.1542698016730686

Epoch: 6| Step: 8
Training loss: 1.5075139999389648
Validation loss: 2.1245921478476575

Epoch: 6| Step: 9
Training loss: 2.467207193374634
Validation loss: 2.113491214731688

Epoch: 6| Step: 10
Training loss: 2.198110342025757
Validation loss: 2.0963658004678707

Epoch: 6| Step: 11
Training loss: 2.109973907470703
Validation loss: 2.104518021306684

Epoch: 6| Step: 12
Training loss: 2.7080535888671875
Validation loss: 2.0896406660797777

Epoch: 6| Step: 13
Training loss: 3.0473227500915527
Validation loss: 2.0903155085861043

Epoch: 98| Step: 0
Training loss: 2.571929931640625
Validation loss: 2.0977738006140596

Epoch: 6| Step: 1
Training loss: 3.2972521781921387
Validation loss: 2.104569628674497

Epoch: 6| Step: 2
Training loss: 2.527327537536621
Validation loss: 2.1093601001206266

Epoch: 6| Step: 3
Training loss: 2.0047450065612793
Validation loss: 2.1290509457229287

Epoch: 6| Step: 4
Training loss: 1.988288164138794
Validation loss: 2.1525240508458947

Epoch: 6| Step: 5
Training loss: 2.530327081680298
Validation loss: 2.1494970936929025

Epoch: 6| Step: 6
Training loss: 1.972062110900879
Validation loss: 2.149868888239707

Epoch: 6| Step: 7
Training loss: 2.6320478916168213
Validation loss: 2.1359944433294316

Epoch: 6| Step: 8
Training loss: 3.145817279815674
Validation loss: 2.144837510201239

Epoch: 6| Step: 9
Training loss: 2.1518068313598633
Validation loss: 2.153802811458547

Epoch: 6| Step: 10
Training loss: 2.5704379081726074
Validation loss: 2.1613766249789985

Epoch: 6| Step: 11
Training loss: 2.0336713790893555
Validation loss: 2.182301257246284

Epoch: 6| Step: 12
Training loss: 1.8973907232284546
Validation loss: 2.1830278186387915

Epoch: 6| Step: 13
Training loss: 2.3602230548858643
Validation loss: 2.1768485730694187

Epoch: 99| Step: 0
Training loss: 2.1491870880126953
Validation loss: 2.148418495731969

Epoch: 6| Step: 1
Training loss: 3.2975456714630127
Validation loss: 2.1243569902194444

Epoch: 6| Step: 2
Training loss: 1.8953955173492432
Validation loss: 2.118488670677267

Epoch: 6| Step: 3
Training loss: 2.60274600982666
Validation loss: 2.1070637100486347

Epoch: 6| Step: 4
Training loss: 2.993952751159668
Validation loss: 2.1262079054309475

Epoch: 6| Step: 5
Training loss: 2.408517599105835
Validation loss: 2.140851077213082

Epoch: 6| Step: 6
Training loss: 2.465050458908081
Validation loss: 2.2031613960061023

Epoch: 6| Step: 7
Training loss: 2.3874456882476807
Validation loss: 2.144677973562671

Epoch: 6| Step: 8
Training loss: 1.9042508602142334
Validation loss: 2.1218811414575063

Epoch: 6| Step: 9
Training loss: 2.2742080688476562
Validation loss: 2.0969121712510304

Epoch: 6| Step: 10
Training loss: 2.048225164413452
Validation loss: 2.10100572083586

Epoch: 6| Step: 11
Training loss: 1.730513334274292
Validation loss: 2.093044473278907

Epoch: 6| Step: 12
Training loss: 2.7875709533691406
Validation loss: 2.10768917042722

Epoch: 6| Step: 13
Training loss: 2.566185235977173
Validation loss: 2.0876655552976873

Epoch: 100| Step: 0
Training loss: 2.96336030960083
Validation loss: 2.0817070673870783

Epoch: 6| Step: 1
Training loss: 2.5502614974975586
Validation loss: 2.0839634518469534

Epoch: 6| Step: 2
Training loss: 2.769578695297241
Validation loss: 2.0757692872837024

Epoch: 6| Step: 3
Training loss: 2.298731565475464
Validation loss: 2.083287214720121

Epoch: 6| Step: 4
Training loss: 2.3956282138824463
Validation loss: 2.0773700693602204

Epoch: 6| Step: 5
Training loss: 2.0152039527893066
Validation loss: 2.0769441435413976

Epoch: 6| Step: 6
Training loss: 2.317086696624756
Validation loss: 2.0872468127999255

Epoch: 6| Step: 7
Training loss: 2.3216519355773926
Validation loss: 2.091742930873748

Epoch: 6| Step: 8
Training loss: 2.8121275901794434
Validation loss: 2.092047932327435

Epoch: 6| Step: 9
Training loss: 2.3014822006225586
Validation loss: 2.107833436740342

Epoch: 6| Step: 10
Training loss: 1.8771591186523438
Validation loss: 2.093914726729034

Epoch: 6| Step: 11
Training loss: 2.7452125549316406
Validation loss: 2.0886070536028956

Epoch: 6| Step: 12
Training loss: 1.5704634189605713
Validation loss: 2.086385437237319

Epoch: 6| Step: 13
Training loss: 2.5993893146514893
Validation loss: 2.089356158369331

Epoch: 101| Step: 0
Training loss: 2.784407615661621
Validation loss: 2.0878183034158524

Epoch: 6| Step: 1
Training loss: 1.9248400926589966
Validation loss: 2.0869910383737214

Epoch: 6| Step: 2
Training loss: 2.6243906021118164
Validation loss: 2.0817282507496495

Epoch: 6| Step: 3
Training loss: 2.0164918899536133
Validation loss: 2.0972053312486216

Epoch: 6| Step: 4
Training loss: 2.048104763031006
Validation loss: 2.104217431878531

Epoch: 6| Step: 5
Training loss: 2.437680244445801
Validation loss: 2.1110758550705446

Epoch: 6| Step: 6
Training loss: 3.2973856925964355
Validation loss: 2.105078302403932

Epoch: 6| Step: 7
Training loss: 2.4477384090423584
Validation loss: 2.104656198973297

Epoch: 6| Step: 8
Training loss: 2.5147650241851807
Validation loss: 2.113674925219628

Epoch: 6| Step: 9
Training loss: 1.8952891826629639
Validation loss: 2.117323297326283

Epoch: 6| Step: 10
Training loss: 2.293207883834839
Validation loss: 2.104489012431073

Epoch: 6| Step: 11
Training loss: 2.7782156467437744
Validation loss: 2.093294141113117

Epoch: 6| Step: 12
Training loss: 2.4965462684631348
Validation loss: 2.0788551607439594

Epoch: 6| Step: 13
Training loss: 1.267691969871521
Validation loss: 2.077942963569395

Epoch: 102| Step: 0
Training loss: 2.3214612007141113
Validation loss: 2.07629608338879

Epoch: 6| Step: 1
Training loss: 2.1361308097839355
Validation loss: 2.067264421011812

Epoch: 6| Step: 2
Training loss: 2.1144468784332275
Validation loss: 2.0704368109344156

Epoch: 6| Step: 3
Training loss: 1.6621977090835571
Validation loss: 2.0807727383029078

Epoch: 6| Step: 4
Training loss: 2.249028205871582
Validation loss: 2.081752000316497

Epoch: 6| Step: 5
Training loss: 2.4203829765319824
Validation loss: 2.0905970476006948

Epoch: 6| Step: 6
Training loss: 2.616684913635254
Validation loss: 2.093595814961259

Epoch: 6| Step: 7
Training loss: 2.777278423309326
Validation loss: 2.1157963301545832

Epoch: 6| Step: 8
Training loss: 2.84175968170166
Validation loss: 2.1321507551336802

Epoch: 6| Step: 9
Training loss: 2.959944009780884
Validation loss: 2.1474878377811883

Epoch: 6| Step: 10
Training loss: 2.1576414108276367
Validation loss: 2.137722184581141

Epoch: 6| Step: 11
Training loss: 2.259711265563965
Validation loss: 2.1169697469280613

Epoch: 6| Step: 12
Training loss: 2.389146089553833
Validation loss: 2.098391085542658

Epoch: 6| Step: 13
Training loss: 2.64070987701416
Validation loss: 2.106097205992668

Epoch: 103| Step: 0
Training loss: 1.837356448173523
Validation loss: 2.135848186349356

Epoch: 6| Step: 1
Training loss: 2.6764326095581055
Validation loss: 2.131972748746154

Epoch: 6| Step: 2
Training loss: 2.3768858909606934
Validation loss: 2.1065495424373175

Epoch: 6| Step: 3
Training loss: 1.992357850074768
Validation loss: 2.0842484107581516

Epoch: 6| Step: 4
Training loss: 2.6363627910614014
Validation loss: 2.06331887296451

Epoch: 6| Step: 5
Training loss: 1.8232569694519043
Validation loss: 2.0533390609166955

Epoch: 6| Step: 6
Training loss: 2.1374075412750244
Validation loss: 2.0497809943332466

Epoch: 6| Step: 7
Training loss: 2.3361897468566895
Validation loss: 2.0644053848840858

Epoch: 6| Step: 8
Training loss: 2.8269457817077637
Validation loss: 2.062025503445697

Epoch: 6| Step: 9
Training loss: 2.35844087600708
Validation loss: 2.0559659440030336

Epoch: 6| Step: 10
Training loss: 2.8088951110839844
Validation loss: 2.074310028424827

Epoch: 6| Step: 11
Training loss: 2.2537989616394043
Validation loss: 2.063552018134825

Epoch: 6| Step: 12
Training loss: 2.7021923065185547
Validation loss: 2.0726017849419707

Epoch: 6| Step: 13
Training loss: 2.6957223415374756
Validation loss: 2.0756825785483084

Epoch: 104| Step: 0
Training loss: 2.639772891998291
Validation loss: 2.057006912846719

Epoch: 6| Step: 1
Training loss: 1.9081627130508423
Validation loss: 2.0560086645105833

Epoch: 6| Step: 2
Training loss: 2.3352789878845215
Validation loss: 2.04219711724148

Epoch: 6| Step: 3
Training loss: 2.3874707221984863
Validation loss: 2.045047588245843

Epoch: 6| Step: 4
Training loss: 2.5628371238708496
Validation loss: 2.049715038268797

Epoch: 6| Step: 5
Training loss: 2.5320382118225098
Validation loss: 2.0742051370682253

Epoch: 6| Step: 6
Training loss: 2.2042107582092285
Validation loss: 2.080738167608938

Epoch: 6| Step: 7
Training loss: 2.7754178047180176
Validation loss: 2.08780780530745

Epoch: 6| Step: 8
Training loss: 2.56756329536438
Validation loss: 2.078141530354818

Epoch: 6| Step: 9
Training loss: 2.8766722679138184
Validation loss: 2.0698592496174637

Epoch: 6| Step: 10
Training loss: 2.127763271331787
Validation loss: 2.0621063529804187

Epoch: 6| Step: 11
Training loss: 1.7336550951004028
Validation loss: 2.045558470551686

Epoch: 6| Step: 12
Training loss: 2.532663345336914
Validation loss: 2.0306456242838213

Epoch: 6| Step: 13
Training loss: 1.5806514024734497
Validation loss: 2.034794811279543

Epoch: 105| Step: 0
Training loss: 2.1482839584350586
Validation loss: 2.027782810631619

Epoch: 6| Step: 1
Training loss: 2.91829252243042
Validation loss: 2.0252307794427358

Epoch: 6| Step: 2
Training loss: 2.0500102043151855
Validation loss: 2.025265975665021

Epoch: 6| Step: 3
Training loss: 2.809998035430908
Validation loss: 2.0250033665728826

Epoch: 6| Step: 4
Training loss: 2.150859832763672
Validation loss: 2.0349985937918387

Epoch: 6| Step: 5
Training loss: 2.637974262237549
Validation loss: 2.0266983021972

Epoch: 6| Step: 6
Training loss: 2.3758349418640137
Validation loss: 2.0349149780888713

Epoch: 6| Step: 7
Training loss: 2.9749033451080322
Validation loss: 2.0373998893204557

Epoch: 6| Step: 8
Training loss: 2.3877573013305664
Validation loss: 2.0445401835185226

Epoch: 6| Step: 9
Training loss: 2.765568256378174
Validation loss: 2.0470587130515807

Epoch: 6| Step: 10
Training loss: 1.8234210014343262
Validation loss: 2.0496835529163318

Epoch: 6| Step: 11
Training loss: 2.891871929168701
Validation loss: 2.049559752146403

Epoch: 6| Step: 12
Training loss: 1.348114013671875
Validation loss: 2.0496770220418132

Epoch: 6| Step: 13
Training loss: 1.6926374435424805
Validation loss: 2.04516936373967

Epoch: 106| Step: 0
Training loss: 2.264284133911133
Validation loss: 2.0648509135810276

Epoch: 6| Step: 1
Training loss: 1.981536865234375
Validation loss: 2.075379007606096

Epoch: 6| Step: 2
Training loss: 2.6585779190063477
Validation loss: 2.08955882441613

Epoch: 6| Step: 3
Training loss: 1.9426465034484863
Validation loss: 2.0958450968547533

Epoch: 6| Step: 4
Training loss: 2.1428122520446777
Validation loss: 2.0792706204998876

Epoch: 6| Step: 5
Training loss: 2.8627419471740723
Validation loss: 2.063129904449627

Epoch: 6| Step: 6
Training loss: 1.941321611404419
Validation loss: 2.043945663718767

Epoch: 6| Step: 7
Training loss: 2.268444061279297
Validation loss: 2.0460099327948784

Epoch: 6| Step: 8
Training loss: 1.9681730270385742
Validation loss: 2.0316962234435545

Epoch: 6| Step: 9
Training loss: 2.5563817024230957
Validation loss: 2.0351548399976505

Epoch: 6| Step: 10
Training loss: 2.4671545028686523
Validation loss: 2.038802014884128

Epoch: 6| Step: 11
Training loss: 3.044057607650757
Validation loss: 2.0380199288809173

Epoch: 6| Step: 12
Training loss: 2.3698325157165527
Validation loss: 2.0395742898346274

Epoch: 6| Step: 13
Training loss: 2.916747808456421
Validation loss: 2.0468516401065293

Epoch: 107| Step: 0
Training loss: 2.635929584503174
Validation loss: 2.0492783669502503

Epoch: 6| Step: 1
Training loss: 2.7114973068237305
Validation loss: 2.0453627737619544

Epoch: 6| Step: 2
Training loss: 2.6730852127075195
Validation loss: 2.0615927891064714

Epoch: 6| Step: 3
Training loss: 2.2843565940856934
Validation loss: 2.078088661675812

Epoch: 6| Step: 4
Training loss: 2.19352388381958
Validation loss: 2.0731289809749973

Epoch: 6| Step: 5
Training loss: 2.507823944091797
Validation loss: 2.1005071619505524

Epoch: 6| Step: 6
Training loss: 2.3454785346984863
Validation loss: 2.1038956513968845

Epoch: 6| Step: 7
Training loss: 1.6996002197265625
Validation loss: 2.128332696935182

Epoch: 6| Step: 8
Training loss: 1.7476575374603271
Validation loss: 2.1605082634956605

Epoch: 6| Step: 9
Training loss: 1.9271035194396973
Validation loss: 2.185756165494201

Epoch: 6| Step: 10
Training loss: 1.9337173700332642
Validation loss: 2.218123843592982

Epoch: 6| Step: 11
Training loss: 3.0218725204467773
Validation loss: 2.2914703520395423

Epoch: 6| Step: 12
Training loss: 3.216642379760742
Validation loss: 2.223661531684219

Epoch: 6| Step: 13
Training loss: 2.2819676399230957
Validation loss: 2.1584446096933014

Epoch: 108| Step: 0
Training loss: 2.1884546279907227
Validation loss: 2.1134034984855243

Epoch: 6| Step: 1
Training loss: 2.100907564163208
Validation loss: 2.0888370198588215

Epoch: 6| Step: 2
Training loss: 2.630119800567627
Validation loss: 2.094485454661872

Epoch: 6| Step: 3
Training loss: 2.8261733055114746
Validation loss: 2.0885132230738157

Epoch: 6| Step: 4
Training loss: 2.3369574546813965
Validation loss: 2.0886049270629883

Epoch: 6| Step: 5
Training loss: 2.226369619369507
Validation loss: 2.1034664979545017

Epoch: 6| Step: 6
Training loss: 2.5248348712921143
Validation loss: 2.0953137848966863

Epoch: 6| Step: 7
Training loss: 2.134521007537842
Validation loss: 2.0786003630648375

Epoch: 6| Step: 8
Training loss: 1.7535628080368042
Validation loss: 2.0889900063955658

Epoch: 6| Step: 9
Training loss: 2.4322519302368164
Validation loss: 2.0950343698583622

Epoch: 6| Step: 10
Training loss: 2.7600624561309814
Validation loss: 2.084314433477258

Epoch: 6| Step: 11
Training loss: 2.1942391395568848
Validation loss: 2.095906619102724

Epoch: 6| Step: 12
Training loss: 3.144562244415283
Validation loss: 2.0559903062799925

Epoch: 6| Step: 13
Training loss: 1.5563366413116455
Validation loss: 2.03928788246647

Epoch: 109| Step: 0
Training loss: 2.6623430252075195
Validation loss: 2.0359303938445223

Epoch: 6| Step: 1
Training loss: 2.133108139038086
Validation loss: 2.032590584088397

Epoch: 6| Step: 2
Training loss: 3.0420310497283936
Validation loss: 2.0372675080453195

Epoch: 6| Step: 3
Training loss: 2.5859568119049072
Validation loss: 2.0521295121921006

Epoch: 6| Step: 4
Training loss: 1.745572566986084
Validation loss: 2.0758862046785254

Epoch: 6| Step: 5
Training loss: 2.46803617477417
Validation loss: 2.08338656989477

Epoch: 6| Step: 6
Training loss: 2.7214202880859375
Validation loss: 2.094594717025757

Epoch: 6| Step: 7
Training loss: 1.7581669092178345
Validation loss: 2.099116127978089

Epoch: 6| Step: 8
Training loss: 2.316239356994629
Validation loss: 2.0986187406765517

Epoch: 6| Step: 9
Training loss: 3.1040127277374268
Validation loss: 2.08763946512694

Epoch: 6| Step: 10
Training loss: 2.4246976375579834
Validation loss: 2.056337438603883

Epoch: 6| Step: 11
Training loss: 2.2791004180908203
Validation loss: 2.0428607335654636

Epoch: 6| Step: 12
Training loss: 1.4013797044754028
Validation loss: 2.0347967378554808

Epoch: 6| Step: 13
Training loss: 2.093747854232788
Validation loss: 2.0224397361919446

Epoch: 110| Step: 0
Training loss: 2.368063449859619
Validation loss: 2.0213047868462017

Epoch: 6| Step: 1
Training loss: 2.5729048252105713
Validation loss: 2.0351275218430387

Epoch: 6| Step: 2
Training loss: 2.4483981132507324
Validation loss: 2.0396935606515534

Epoch: 6| Step: 3
Training loss: 1.9029436111450195
Validation loss: 2.039996116392074

Epoch: 6| Step: 4
Training loss: 2.39359450340271
Validation loss: 2.0375744706840924

Epoch: 6| Step: 5
Training loss: 2.0628793239593506
Validation loss: 2.0266930210974907

Epoch: 6| Step: 6
Training loss: 2.031362771987915
Validation loss: 2.023554907050184

Epoch: 6| Step: 7
Training loss: 2.663238048553467
Validation loss: 2.024921477481883

Epoch: 6| Step: 8
Training loss: 2.25469970703125
Validation loss: 2.029950249579645

Epoch: 6| Step: 9
Training loss: 2.792684555053711
Validation loss: 2.046658818439771

Epoch: 6| Step: 10
Training loss: 1.8949003219604492
Validation loss: 2.0783406457593365

Epoch: 6| Step: 11
Training loss: 2.6169514656066895
Validation loss: 2.087072495491274

Epoch: 6| Step: 12
Training loss: 2.028613328933716
Validation loss: 2.102729946054438

Epoch: 6| Step: 13
Training loss: 3.2656643390655518
Validation loss: 2.085828488872897

Epoch: 111| Step: 0
Training loss: 2.2046236991882324
Validation loss: 2.0911444105127805

Epoch: 6| Step: 1
Training loss: 2.343912363052368
Validation loss: 2.080947391448482

Epoch: 6| Step: 2
Training loss: 2.231320381164551
Validation loss: 2.069107876029066

Epoch: 6| Step: 3
Training loss: 2.669675350189209
Validation loss: 2.0666845331909838

Epoch: 6| Step: 4
Training loss: 2.146735668182373
Validation loss: 2.0601601895465644

Epoch: 6| Step: 5
Training loss: 2.5109341144561768
Validation loss: 2.0599010016328547

Epoch: 6| Step: 6
Training loss: 2.5004453659057617
Validation loss: 2.085319971525541

Epoch: 6| Step: 7
Training loss: 2.268299102783203
Validation loss: 2.100696853412095

Epoch: 6| Step: 8
Training loss: 2.354004144668579
Validation loss: 2.117139244592318

Epoch: 6| Step: 9
Training loss: 2.526209831237793
Validation loss: 2.1111677641509683

Epoch: 6| Step: 10
Training loss: 2.309372901916504
Validation loss: 2.117446494358842

Epoch: 6| Step: 11
Training loss: 1.6818156242370605
Validation loss: 2.094218284853043

Epoch: 6| Step: 12
Training loss: 1.899612545967102
Validation loss: 2.082650456377255

Epoch: 6| Step: 13
Training loss: 3.77958083152771
Validation loss: 2.0680036749891055

Epoch: 112| Step: 0
Training loss: 1.6721923351287842
Validation loss: 2.064017700892623

Epoch: 6| Step: 1
Training loss: 1.9273686408996582
Validation loss: 2.0563310474477787

Epoch: 6| Step: 2
Training loss: 2.5223796367645264
Validation loss: 2.0413473639436948

Epoch: 6| Step: 3
Training loss: 2.5391578674316406
Validation loss: 2.033746216886787

Epoch: 6| Step: 4
Training loss: 2.516073703765869
Validation loss: 2.026244019949308

Epoch: 6| Step: 5
Training loss: 1.9572862386703491
Validation loss: 2.026498107499974

Epoch: 6| Step: 6
Training loss: 2.423123359680176
Validation loss: 2.028631934555628

Epoch: 6| Step: 7
Training loss: 2.5463309288024902
Validation loss: 2.0363961663297427

Epoch: 6| Step: 8
Training loss: 2.3889734745025635
Validation loss: 2.053347251748526

Epoch: 6| Step: 9
Training loss: 2.857421398162842
Validation loss: 2.0493796666463218

Epoch: 6| Step: 10
Training loss: 2.854074001312256
Validation loss: 2.075959790137506

Epoch: 6| Step: 11
Training loss: 1.5121186971664429
Validation loss: 2.0778956182541384

Epoch: 6| Step: 12
Training loss: 2.3561346530914307
Validation loss: 2.0916466174587125

Epoch: 6| Step: 13
Training loss: 2.294034004211426
Validation loss: 2.105976149600039

Epoch: 113| Step: 0
Training loss: 2.5250329971313477
Validation loss: 2.084576795178075

Epoch: 6| Step: 1
Training loss: 1.8529140949249268
Validation loss: 2.0981552575224187

Epoch: 6| Step: 2
Training loss: 2.6582977771759033
Validation loss: 2.0803942244539977

Epoch: 6| Step: 3
Training loss: 2.382437229156494
Validation loss: 2.057730249179307

Epoch: 6| Step: 4
Training loss: 1.8374924659729004
Validation loss: 2.042287754756148

Epoch: 6| Step: 5
Training loss: 2.5937724113464355
Validation loss: 2.0557425342580324

Epoch: 6| Step: 6
Training loss: 2.774942398071289
Validation loss: 2.0631530451518234

Epoch: 6| Step: 7
Training loss: 2.770327091217041
Validation loss: 2.0619111727642756

Epoch: 6| Step: 8
Training loss: 2.4123356342315674
Validation loss: 2.068287995553786

Epoch: 6| Step: 9
Training loss: 2.5106143951416016
Validation loss: 2.070378441964426

Epoch: 6| Step: 10
Training loss: 1.6080255508422852
Validation loss: 2.0607488027182956

Epoch: 6| Step: 11
Training loss: 1.6692335605621338
Validation loss: 2.0631846279226322

Epoch: 6| Step: 12
Training loss: 2.573631763458252
Validation loss: 2.0584547904229935

Epoch: 6| Step: 13
Training loss: 1.8762449026107788
Validation loss: 2.04523717716176

Epoch: 114| Step: 0
Training loss: 1.716052532196045
Validation loss: 2.0360524244205926

Epoch: 6| Step: 1
Training loss: 1.805335283279419
Validation loss: 2.0199163831690305

Epoch: 6| Step: 2
Training loss: 1.793567180633545
Validation loss: 2.039568026860555

Epoch: 6| Step: 3
Training loss: 2.1895132064819336
Validation loss: 2.027003703578826

Epoch: 6| Step: 4
Training loss: 2.7728190422058105
Validation loss: 2.0351437701973865

Epoch: 6| Step: 5
Training loss: 2.5214827060699463
Validation loss: 2.034182599795762

Epoch: 6| Step: 6
Training loss: 1.9741432666778564
Validation loss: 2.023071471080985

Epoch: 6| Step: 7
Training loss: 2.936971426010132
Validation loss: 2.0138120279517224

Epoch: 6| Step: 8
Training loss: 1.7757573127746582
Validation loss: 2.0114666800345145

Epoch: 6| Step: 9
Training loss: 1.9564507007598877
Validation loss: 2.0155631265332623

Epoch: 6| Step: 10
Training loss: 2.6335530281066895
Validation loss: 2.0224168710811163

Epoch: 6| Step: 11
Training loss: 2.5870463848114014
Validation loss: 2.0331381572190153

Epoch: 6| Step: 12
Training loss: 3.1922359466552734
Validation loss: 2.0422834119489117

Epoch: 6| Step: 13
Training loss: 2.5163328647613525
Validation loss: 2.0503073405194026

Epoch: 115| Step: 0
Training loss: 3.213315725326538
Validation loss: 2.0862043301264444

Epoch: 6| Step: 1
Training loss: 2.0774807929992676
Validation loss: 2.0992450637202107

Epoch: 6| Step: 2
Training loss: 2.454775333404541
Validation loss: 2.1281478879272298

Epoch: 6| Step: 3
Training loss: 2.336294651031494
Validation loss: 2.122214332703621

Epoch: 6| Step: 4
Training loss: 2.674765110015869
Validation loss: 2.090045195753856

Epoch: 6| Step: 5
Training loss: 2.257629632949829
Validation loss: 2.049739351836584

Epoch: 6| Step: 6
Training loss: 2.203218460083008
Validation loss: 2.039840941788048

Epoch: 6| Step: 7
Training loss: 2.6072134971618652
Validation loss: 2.087601798836903

Epoch: 6| Step: 8
Training loss: 1.7882721424102783
Validation loss: 2.094448506191213

Epoch: 6| Step: 9
Training loss: 2.8230133056640625
Validation loss: 2.125161006886472

Epoch: 6| Step: 10
Training loss: 2.0973830223083496
Validation loss: 2.10638056647393

Epoch: 6| Step: 11
Training loss: 2.0792927742004395
Validation loss: 2.0741422099451863

Epoch: 6| Step: 12
Training loss: 2.153660297393799
Validation loss: 2.0497174480909943

Epoch: 6| Step: 13
Training loss: 1.5864331722259521
Validation loss: 2.0289349094513924

Epoch: 116| Step: 0
Training loss: 2.5064897537231445
Validation loss: 2.007399914085224

Epoch: 6| Step: 1
Training loss: 1.6148544549942017
Validation loss: 2.014446376472391

Epoch: 6| Step: 2
Training loss: 2.761021375656128
Validation loss: 2.0313438677018687

Epoch: 6| Step: 3
Training loss: 2.6267812252044678
Validation loss: 2.067179197906166

Epoch: 6| Step: 4
Training loss: 2.9713728427886963
Validation loss: 2.0657612072524203

Epoch: 6| Step: 5
Training loss: 1.7309958934783936
Validation loss: 2.0612573367293163

Epoch: 6| Step: 6
Training loss: 2.457479953765869
Validation loss: 2.079874110478227

Epoch: 6| Step: 7
Training loss: 2.230922222137451
Validation loss: 2.0441777757419053

Epoch: 6| Step: 8
Training loss: 2.392850399017334
Validation loss: 2.0146898223507788

Epoch: 6| Step: 9
Training loss: 2.0334889888763428
Validation loss: 2.006387948989868

Epoch: 6| Step: 10
Training loss: 2.6365585327148438
Validation loss: 1.9861842714330202

Epoch: 6| Step: 11
Training loss: 2.2713160514831543
Validation loss: 1.9690977065793929

Epoch: 6| Step: 12
Training loss: 2.1152215003967285
Validation loss: 1.9691967041261735

Epoch: 6| Step: 13
Training loss: 2.1111881732940674
Validation loss: 1.983775879747124

Epoch: 117| Step: 0
Training loss: 2.8900296688079834
Validation loss: 1.993362977940549

Epoch: 6| Step: 1
Training loss: 2.3663015365600586
Validation loss: 2.01810722966348

Epoch: 6| Step: 2
Training loss: 2.8598403930664062
Validation loss: 2.026609492558305

Epoch: 6| Step: 3
Training loss: 2.228883981704712
Validation loss: 2.0299137907643474

Epoch: 6| Step: 4
Training loss: 2.5028696060180664
Validation loss: 2.051386861390965

Epoch: 6| Step: 5
Training loss: 2.181945323944092
Validation loss: 2.041356819932179

Epoch: 6| Step: 6
Training loss: 2.4975545406341553
Validation loss: 2.039938690841839

Epoch: 6| Step: 7
Training loss: 1.901643991470337
Validation loss: 2.0775189707356114

Epoch: 6| Step: 8
Training loss: 2.2498679161071777
Validation loss: 2.1869628198685183

Epoch: 6| Step: 9
Training loss: 3.03745174407959
Validation loss: 2.27329324394144

Epoch: 6| Step: 10
Training loss: 2.110185146331787
Validation loss: 2.203668018823029

Epoch: 6| Step: 11
Training loss: 1.9462014436721802
Validation loss: 2.2704635486807874

Epoch: 6| Step: 12
Training loss: 2.348855972290039
Validation loss: 2.188107264939175

Epoch: 6| Step: 13
Training loss: 1.932058334350586
Validation loss: 2.091994898293608

Epoch: 118| Step: 0
Training loss: 2.0325677394866943
Validation loss: 2.075057839834562

Epoch: 6| Step: 1
Training loss: 2.395897388458252
Validation loss: 2.081534021644182

Epoch: 6| Step: 2
Training loss: 3.131258964538574
Validation loss: 2.0727904201835714

Epoch: 6| Step: 3
Training loss: 2.55735445022583
Validation loss: 2.0733423553487307

Epoch: 6| Step: 4
Training loss: 2.0673885345458984
Validation loss: 2.0951108958131526

Epoch: 6| Step: 5
Training loss: 2.425668954849243
Validation loss: 2.0898752212524414

Epoch: 6| Step: 6
Training loss: 2.605142593383789
Validation loss: 2.105121274148264

Epoch: 6| Step: 7
Training loss: 2.0688083171844482
Validation loss: 2.085844575717885

Epoch: 6| Step: 8
Training loss: 2.17714524269104
Validation loss: 2.0635144043994207

Epoch: 6| Step: 9
Training loss: 2.4724316596984863
Validation loss: 2.0697105494878625

Epoch: 6| Step: 10
Training loss: 1.8986319303512573
Validation loss: 2.089545585775888

Epoch: 6| Step: 11
Training loss: 2.267564296722412
Validation loss: 2.0861977300336285

Epoch: 6| Step: 12
Training loss: 2.366309404373169
Validation loss: 2.071925163269043

Epoch: 6| Step: 13
Training loss: 2.7011287212371826
Validation loss: 2.0658392931825373

Epoch: 119| Step: 0
Training loss: 2.300957202911377
Validation loss: 2.047305719826811

Epoch: 6| Step: 1
Training loss: 2.193474769592285
Validation loss: 2.044608131531746

Epoch: 6| Step: 2
Training loss: 2.3484644889831543
Validation loss: 2.032471154325752

Epoch: 6| Step: 3
Training loss: 1.7674152851104736
Validation loss: 2.0235461829811014

Epoch: 6| Step: 4
Training loss: 2.7747435569763184
Validation loss: 2.0267216825997956

Epoch: 6| Step: 5
Training loss: 2.7874326705932617
Validation loss: 2.0200638232692594

Epoch: 6| Step: 6
Training loss: 2.7817397117614746
Validation loss: 2.0135194332368913

Epoch: 6| Step: 7
Training loss: 1.9057960510253906
Validation loss: 2.000285061456824

Epoch: 6| Step: 8
Training loss: 1.7117204666137695
Validation loss: 2.016216766449713

Epoch: 6| Step: 9
Training loss: 2.806809902191162
Validation loss: 2.025801101038533

Epoch: 6| Step: 10
Training loss: 2.423408031463623
Validation loss: 2.0371520942257297

Epoch: 6| Step: 11
Training loss: 2.1256585121154785
Validation loss: 2.0695736241597

Epoch: 6| Step: 12
Training loss: 1.7130827903747559
Validation loss: 2.067173211805282

Epoch: 6| Step: 13
Training loss: 2.297459125518799
Validation loss: 2.083925207455953

Epoch: 120| Step: 0
Training loss: 2.0885534286499023
Validation loss: 2.070519442199379

Epoch: 6| Step: 1
Training loss: 2.379584312438965
Validation loss: 2.0326129954348326

Epoch: 6| Step: 2
Training loss: 2.107177257537842
Validation loss: 2.0117237555083407

Epoch: 6| Step: 3
Training loss: 1.5468478202819824
Validation loss: 2.0050777799339703

Epoch: 6| Step: 4
Training loss: 2.477090358734131
Validation loss: 2.0101493789303686

Epoch: 6| Step: 5
Training loss: 2.530383348464966
Validation loss: 2.029032950760216

Epoch: 6| Step: 6
Training loss: 2.2535409927368164
Validation loss: 2.0331853000066613

Epoch: 6| Step: 7
Training loss: 1.6516631841659546
Validation loss: 2.0407903450791554

Epoch: 6| Step: 8
Training loss: 2.5001256465911865
Validation loss: 2.0290374153403827

Epoch: 6| Step: 9
Training loss: 2.137408494949341
Validation loss: 2.018035860471828

Epoch: 6| Step: 10
Training loss: 2.452458381652832
Validation loss: 2.015960237031342

Epoch: 6| Step: 11
Training loss: 2.9203431606292725
Validation loss: 2.0229533103204544

Epoch: 6| Step: 12
Training loss: 2.036512851715088
Validation loss: 2.0347847271991033

Epoch: 6| Step: 13
Training loss: 3.1882264614105225
Validation loss: 2.010441780090332

Epoch: 121| Step: 0
Training loss: 3.181185245513916
Validation loss: 2.0087034420300554

Epoch: 6| Step: 1
Training loss: 1.4288251399993896
Validation loss: 1.9997836030939573

Epoch: 6| Step: 2
Training loss: 1.9217356443405151
Validation loss: 2.011100310151295

Epoch: 6| Step: 3
Training loss: 2.3471176624298096
Validation loss: 2.0142122096912836

Epoch: 6| Step: 4
Training loss: 2.072028160095215
Validation loss: 2.0293033481926046

Epoch: 6| Step: 5
Training loss: 1.8961058855056763
Validation loss: 2.0456819008755427

Epoch: 6| Step: 6
Training loss: 2.1426455974578857
Validation loss: 2.0642751519398024

Epoch: 6| Step: 7
Training loss: 2.6412999629974365
Validation loss: 2.050017172290433

Epoch: 6| Step: 8
Training loss: 1.9534964561462402
Validation loss: 2.026233543631851

Epoch: 6| Step: 9
Training loss: 2.0263872146606445
Validation loss: 2.022398741014542

Epoch: 6| Step: 10
Training loss: 2.681234359741211
Validation loss: 2.03495200475057

Epoch: 6| Step: 11
Training loss: 2.3378255367279053
Validation loss: 2.0471887024500037

Epoch: 6| Step: 12
Training loss: 2.9293432235717773
Validation loss: 2.0523397743061023

Epoch: 6| Step: 13
Training loss: 1.5470118522644043
Validation loss: 2.050833093222751

Epoch: 122| Step: 0
Training loss: 2.1502344608306885
Validation loss: 2.0770434179613666

Epoch: 6| Step: 1
Training loss: 1.7169411182403564
Validation loss: 2.0709812564234578

Epoch: 6| Step: 2
Training loss: 2.347517728805542
Validation loss: 2.0351658687796643

Epoch: 6| Step: 3
Training loss: 2.3145577907562256
Validation loss: 2.0147202745560677

Epoch: 6| Step: 4
Training loss: 2.098757743835449
Validation loss: 2.0119943900774886

Epoch: 6| Step: 5
Training loss: 2.537893772125244
Validation loss: 1.9821404692947224

Epoch: 6| Step: 6
Training loss: 2.5743765830993652
Validation loss: 1.9679275981841549

Epoch: 6| Step: 7
Training loss: 1.9487512111663818
Validation loss: 1.959576327313659

Epoch: 6| Step: 8
Training loss: 2.4780404567718506
Validation loss: 1.9567143327446395

Epoch: 6| Step: 9
Training loss: 2.8857779502868652
Validation loss: 1.9712300300598145

Epoch: 6| Step: 10
Training loss: 2.536403179168701
Validation loss: 1.9788047664908952

Epoch: 6| Step: 11
Training loss: 2.073136806488037
Validation loss: 2.012708456285538

Epoch: 6| Step: 12
Training loss: 2.1904802322387695
Validation loss: 2.066393451024127

Epoch: 6| Step: 13
Training loss: 1.6514019966125488
Validation loss: 2.086199895028145

Epoch: 123| Step: 0
Training loss: 2.3945374488830566
Validation loss: 2.1607296543736614

Epoch: 6| Step: 1
Training loss: 2.54982852935791
Validation loss: 2.1632333468365412

Epoch: 6| Step: 2
Training loss: 3.0345659255981445
Validation loss: 2.1806443173398256

Epoch: 6| Step: 3
Training loss: 2.3096444606781006
Validation loss: 2.097253627674554

Epoch: 6| Step: 4
Training loss: 1.6804428100585938
Validation loss: 2.060893207468012

Epoch: 6| Step: 5
Training loss: 2.1763434410095215
Validation loss: 2.047222750161284

Epoch: 6| Step: 6
Training loss: 1.8367445468902588
Validation loss: 2.0362724770781813

Epoch: 6| Step: 7
Training loss: 2.366950511932373
Validation loss: 2.0326149514926377

Epoch: 6| Step: 8
Training loss: 2.1653575897216797
Validation loss: 2.0400932988812848

Epoch: 6| Step: 9
Training loss: 2.46095871925354
Validation loss: 2.0390151264846965

Epoch: 6| Step: 10
Training loss: 2.348928928375244
Validation loss: 2.0345729922735565

Epoch: 6| Step: 11
Training loss: 2.6760005950927734
Validation loss: 2.0209286110375517

Epoch: 6| Step: 12
Training loss: 2.478377342224121
Validation loss: 2.0072149051133024

Epoch: 6| Step: 13
Training loss: 1.4842782020568848
Validation loss: 1.9974386640774306

Epoch: 124| Step: 0
Training loss: 2.6432290077209473
Validation loss: 1.9876735107873076

Epoch: 6| Step: 1
Training loss: 2.6823976039886475
Validation loss: 2.0030219759992374

Epoch: 6| Step: 2
Training loss: 2.248439073562622
Validation loss: 2.0091321237625612

Epoch: 6| Step: 3
Training loss: 2.1479899883270264
Validation loss: 2.0352053180817635

Epoch: 6| Step: 4
Training loss: 2.3362936973571777
Validation loss: 2.02213930314587

Epoch: 6| Step: 5
Training loss: 1.3417834043502808
Validation loss: 2.02780238018241

Epoch: 6| Step: 6
Training loss: 2.0218629837036133
Validation loss: 2.0069602227980092

Epoch: 6| Step: 7
Training loss: 1.6948288679122925
Validation loss: 1.9973333074200539

Epoch: 6| Step: 8
Training loss: 2.269355535507202
Validation loss: 2.0194243897673902

Epoch: 6| Step: 9
Training loss: 2.605046033859253
Validation loss: 2.018111764743764

Epoch: 6| Step: 10
Training loss: 2.7645456790924072
Validation loss: 2.030549483914529

Epoch: 6| Step: 11
Training loss: 2.0133674144744873
Validation loss: 2.042351467635042

Epoch: 6| Step: 12
Training loss: 2.106581926345825
Validation loss: 2.0200251738230386

Epoch: 6| Step: 13
Training loss: 3.036343574523926
Validation loss: 2.0128277437661284

Epoch: 125| Step: 0
Training loss: 1.8556960821151733
Validation loss: 2.0000361396420385

Epoch: 6| Step: 1
Training loss: 2.6193723678588867
Validation loss: 2.000946165412985

Epoch: 6| Step: 2
Training loss: 2.0059151649475098
Validation loss: 2.015560280892157

Epoch: 6| Step: 3
Training loss: 1.6173286437988281
Validation loss: 2.043960743052985

Epoch: 6| Step: 4
Training loss: 3.0185205936431885
Validation loss: 2.0663688464831282

Epoch: 6| Step: 5
Training loss: 2.297027826309204
Validation loss: 2.047301556474419

Epoch: 6| Step: 6
Training loss: 1.8403029441833496
Validation loss: 2.041455440623786

Epoch: 6| Step: 7
Training loss: 2.4736883640289307
Validation loss: 2.038629908715525

Epoch: 6| Step: 8
Training loss: 2.184697151184082
Validation loss: 2.03124858871583

Epoch: 6| Step: 9
Training loss: 2.053403854370117
Validation loss: 2.026131776071364

Epoch: 6| Step: 10
Training loss: 2.3153700828552246
Validation loss: 2.038081479328935

Epoch: 6| Step: 11
Training loss: 1.9553550481796265
Validation loss: 2.05434327484459

Epoch: 6| Step: 12
Training loss: 2.7857871055603027
Validation loss: 2.044614471415038

Epoch: 6| Step: 13
Training loss: 1.591664433479309
Validation loss: 2.0388672044200282

Epoch: 126| Step: 0
Training loss: 1.5919928550720215
Validation loss: 2.0215882280821442

Epoch: 6| Step: 1
Training loss: 2.155930995941162
Validation loss: 2.020600588090958

Epoch: 6| Step: 2
Training loss: 2.193108558654785
Validation loss: 2.00431380989731

Epoch: 6| Step: 3
Training loss: 2.3969919681549072
Validation loss: 2.009347361903037

Epoch: 6| Step: 4
Training loss: 2.4163923263549805
Validation loss: 2.0174978856117494

Epoch: 6| Step: 5
Training loss: 2.5546412467956543
Validation loss: 2.01409468343181

Epoch: 6| Step: 6
Training loss: 2.565042495727539
Validation loss: 2.0179933271100445

Epoch: 6| Step: 7
Training loss: 1.9507582187652588
Validation loss: 2.00509201839406

Epoch: 6| Step: 8
Training loss: 2.7264466285705566
Validation loss: 1.9856910051838044

Epoch: 6| Step: 9
Training loss: 1.5165064334869385
Validation loss: 1.9902961433574717

Epoch: 6| Step: 10
Training loss: 1.6264095306396484
Validation loss: 1.9944350668179092

Epoch: 6| Step: 11
Training loss: 3.030684471130371
Validation loss: 2.020925224468272

Epoch: 6| Step: 12
Training loss: 2.0230422019958496
Validation loss: 2.0152697870808263

Epoch: 6| Step: 13
Training loss: 1.3185280561447144
Validation loss: 2.0338482190203924

Epoch: 127| Step: 0
Training loss: 2.538072347640991
Validation loss: 2.0589162354828208

Epoch: 6| Step: 1
Training loss: 1.671586513519287
Validation loss: 2.073285759136241

Epoch: 6| Step: 2
Training loss: 2.486743927001953
Validation loss: 2.085735615863595

Epoch: 6| Step: 3
Training loss: 1.85691237449646
Validation loss: 2.076779780849334

Epoch: 6| Step: 4
Training loss: 1.483871579170227
Validation loss: 2.065693668139878

Epoch: 6| Step: 5
Training loss: 2.0777692794799805
Validation loss: 2.0524766086250223

Epoch: 6| Step: 6
Training loss: 2.7239933013916016
Validation loss: 2.0640243637946343

Epoch: 6| Step: 7
Training loss: 2.219700574874878
Validation loss: 2.083700080071726

Epoch: 6| Step: 8
Training loss: 2.4219212532043457
Validation loss: 2.0920392133856334

Epoch: 6| Step: 9
Training loss: 1.9968504905700684
Validation loss: 2.0925678527483376

Epoch: 6| Step: 10
Training loss: 3.069343328475952
Validation loss: 2.10323138519

Epoch: 6| Step: 11
Training loss: 2.2046523094177246
Validation loss: 2.1071929854731404

Epoch: 6| Step: 12
Training loss: 2.234088659286499
Validation loss: 2.1014982679838776

Epoch: 6| Step: 13
Training loss: 1.9299310445785522
Validation loss: 2.091070088007117

Epoch: 128| Step: 0
Training loss: 2.715162992477417
Validation loss: 2.0578317488393476

Epoch: 6| Step: 1
Training loss: 2.3507485389709473
Validation loss: 2.023625507149645

Epoch: 6| Step: 2
Training loss: 2.0671584606170654
Validation loss: 2.0296357857283724

Epoch: 6| Step: 3
Training loss: 1.8918092250823975
Validation loss: 2.0016023420518443

Epoch: 6| Step: 4
Training loss: 2.4326364994049072
Validation loss: 1.9935361595563992

Epoch: 6| Step: 5
Training loss: 1.920166015625
Validation loss: 2.0064571313960577

Epoch: 6| Step: 6
Training loss: 2.6222352981567383
Validation loss: 2.011188578862016

Epoch: 6| Step: 7
Training loss: 1.7008593082427979
Validation loss: 2.0242159751153763

Epoch: 6| Step: 8
Training loss: 2.793179988861084
Validation loss: 2.005660218577231

Epoch: 6| Step: 9
Training loss: 2.141761064529419
Validation loss: 2.0067506874761274

Epoch: 6| Step: 10
Training loss: 1.7887593507766724
Validation loss: 1.9984227611172585

Epoch: 6| Step: 11
Training loss: 2.115872859954834
Validation loss: 2.010581693341655

Epoch: 6| Step: 12
Training loss: 1.6382241249084473
Validation loss: 2.0174825242770615

Epoch: 6| Step: 13
Training loss: 2.68278169631958
Validation loss: 2.018310172583467

Epoch: 129| Step: 0
Training loss: 1.3219573497772217
Validation loss: 2.0155083979329755

Epoch: 6| Step: 1
Training loss: 2.0581421852111816
Validation loss: 2.0295569358333463

Epoch: 6| Step: 2
Training loss: 2.3686981201171875
Validation loss: 2.0308708324227283

Epoch: 6| Step: 3
Training loss: 1.8093950748443604
Validation loss: 2.0465400065145185

Epoch: 6| Step: 4
Training loss: 2.280266761779785
Validation loss: 2.05572868803496

Epoch: 6| Step: 5
Training loss: 2.2039403915405273
Validation loss: 2.0632108796027397

Epoch: 6| Step: 6
Training loss: 2.2243549823760986
Validation loss: 2.0736712947968514

Epoch: 6| Step: 7
Training loss: 2.098775863647461
Validation loss: 2.0839642222209642

Epoch: 6| Step: 8
Training loss: 2.090155601501465
Validation loss: 2.094589562826259

Epoch: 6| Step: 9
Training loss: 2.062499523162842
Validation loss: 2.081745378432735

Epoch: 6| Step: 10
Training loss: 2.133023262023926
Validation loss: 2.0955479247595674

Epoch: 6| Step: 11
Training loss: 2.225156545639038
Validation loss: 2.079393986732729

Epoch: 6| Step: 12
Training loss: 2.957284927368164
Validation loss: 2.0640078206216135

Epoch: 6| Step: 13
Training loss: 2.869816303253174
Validation loss: 2.0772870663673646

Epoch: 130| Step: 0
Training loss: 1.9040013551712036
Validation loss: 2.0491398534467145

Epoch: 6| Step: 1
Training loss: 2.007888078689575
Validation loss: 2.0142814472157466

Epoch: 6| Step: 2
Training loss: 3.1054797172546387
Validation loss: 2.0073006665834816

Epoch: 6| Step: 3
Training loss: 2.6853222846984863
Validation loss: 1.9952231837857155

Epoch: 6| Step: 4
Training loss: 2.099249839782715
Validation loss: 1.9874589302206551

Epoch: 6| Step: 5
Training loss: 2.435452461242676
Validation loss: 2.0017568257547196

Epoch: 6| Step: 6
Training loss: 1.9897222518920898
Validation loss: 2.001440070008719

Epoch: 6| Step: 7
Training loss: 1.1604382991790771
Validation loss: 1.9974117766144455

Epoch: 6| Step: 8
Training loss: 2.3333446979522705
Validation loss: 1.985150501292239

Epoch: 6| Step: 9
Training loss: 2.4077916145324707
Validation loss: 1.9858488370013494

Epoch: 6| Step: 10
Training loss: 2.3380608558654785
Validation loss: 2.006108755706459

Epoch: 6| Step: 11
Training loss: 2.2615160942077637
Validation loss: 2.0224695885053245

Epoch: 6| Step: 12
Training loss: 1.5569102764129639
Validation loss: 2.0436034484576155

Epoch: 6| Step: 13
Training loss: 1.4118905067443848
Validation loss: 2.06264445986799

Epoch: 131| Step: 0
Training loss: 1.6356761455535889
Validation loss: 2.090911449924592

Epoch: 6| Step: 1
Training loss: 2.057378053665161
Validation loss: 2.1631919773676063

Epoch: 6| Step: 2
Training loss: 2.089357614517212
Validation loss: 2.181430849977719

Epoch: 6| Step: 3
Training loss: 2.5778260231018066
Validation loss: 2.192542746502866

Epoch: 6| Step: 4
Training loss: 1.9781681299209595
Validation loss: 2.1787684373958136

Epoch: 6| Step: 5
Training loss: 2.3658981323242188
Validation loss: 2.1315337842510593

Epoch: 6| Step: 6
Training loss: 1.646726131439209
Validation loss: 2.0956833388215754

Epoch: 6| Step: 7
Training loss: 2.3308565616607666
Validation loss: 2.094999026226741

Epoch: 6| Step: 8
Training loss: 1.9410558938980103
Validation loss: 2.0655363400777182

Epoch: 6| Step: 9
Training loss: 2.6473960876464844
Validation loss: 2.0603919747055217

Epoch: 6| Step: 10
Training loss: 2.517529249191284
Validation loss: 2.064764292009415

Epoch: 6| Step: 11
Training loss: 2.184755325317383
Validation loss: 2.0410839588411394

Epoch: 6| Step: 12
Training loss: 1.646761178970337
Validation loss: 2.0426017033156527

Epoch: 6| Step: 13
Training loss: 2.8438806533813477
Validation loss: 2.0443289369665165

Epoch: 132| Step: 0
Training loss: 2.416069507598877
Validation loss: 2.0342011144084315

Epoch: 6| Step: 1
Training loss: 1.6580045223236084
Validation loss: 2.0406796445128736

Epoch: 6| Step: 2
Training loss: 2.5572638511657715
Validation loss: 2.063083060326115

Epoch: 6| Step: 3
Training loss: 2.400761604309082
Validation loss: 2.1009952099092546

Epoch: 6| Step: 4
Training loss: 1.5372083187103271
Validation loss: 2.1400225290688137

Epoch: 6| Step: 5
Training loss: 2.1252970695495605
Validation loss: 2.141313865620603

Epoch: 6| Step: 6
Training loss: 2.322270393371582
Validation loss: 2.1215270770493375

Epoch: 6| Step: 7
Training loss: 2.2542991638183594
Validation loss: 2.0907635432417675

Epoch: 6| Step: 8
Training loss: 1.869702696800232
Validation loss: 2.0858050482247465

Epoch: 6| Step: 9
Training loss: 1.8717079162597656
Validation loss: 2.048913376305693

Epoch: 6| Step: 10
Training loss: 2.26530385017395
Validation loss: 2.0478035403836157

Epoch: 6| Step: 11
Training loss: 1.7238017320632935
Validation loss: 2.095187651213779

Epoch: 6| Step: 12
Training loss: 3.072486162185669
Validation loss: 2.115636653797601

Epoch: 6| Step: 13
Training loss: 2.919398546218872
Validation loss: 2.1538847697678434

Epoch: 133| Step: 0
Training loss: 2.7742772102355957
Validation loss: 2.1905285850647958

Epoch: 6| Step: 1
Training loss: 2.510937213897705
Validation loss: 2.2208192963753977

Epoch: 6| Step: 2
Training loss: 1.84121835231781
Validation loss: 2.211030190990817

Epoch: 6| Step: 3
Training loss: 2.0202319622039795
Validation loss: 2.2203049864820255

Epoch: 6| Step: 4
Training loss: 2.4613375663757324
Validation loss: 2.213313874377999

Epoch: 6| Step: 5
Training loss: 1.8103196620941162
Validation loss: 2.1974886924989763

Epoch: 6| Step: 6
Training loss: 2.0302276611328125
Validation loss: 2.170578961731285

Epoch: 6| Step: 7
Training loss: 2.1981403827667236
Validation loss: 2.1707169804521786

Epoch: 6| Step: 8
Training loss: 1.594482421875
Validation loss: 2.1528390325525755

Epoch: 6| Step: 9
Training loss: 2.584259271621704
Validation loss: 2.1078051162022415

Epoch: 6| Step: 10
Training loss: 1.9140079021453857
Validation loss: 2.061095094168058

Epoch: 6| Step: 11
Training loss: 1.930425763130188
Validation loss: 2.029255995186426

Epoch: 6| Step: 12
Training loss: 1.8938860893249512
Validation loss: 2.0279323080534577

Epoch: 6| Step: 13
Training loss: 2.643895149230957
Validation loss: 2.012944539388021

Epoch: 134| Step: 0
Training loss: 2.220548152923584
Validation loss: 2.018225153287252

Epoch: 6| Step: 1
Training loss: 1.8053231239318848
Validation loss: 2.0380088744624967

Epoch: 6| Step: 2
Training loss: 1.5466032028198242
Validation loss: 2.0210134547243834

Epoch: 6| Step: 3
Training loss: 2.536914348602295
Validation loss: 2.024097119608233

Epoch: 6| Step: 4
Training loss: 2.2125868797302246
Validation loss: 2.0110966197906004

Epoch: 6| Step: 5
Training loss: 2.2850635051727295
Validation loss: 1.9863702071610319

Epoch: 6| Step: 6
Training loss: 2.5079212188720703
Validation loss: 1.9672276332814207

Epoch: 6| Step: 7
Training loss: 1.9226678609848022
Validation loss: 1.945171513865071

Epoch: 6| Step: 8
Training loss: 2.0765910148620605
Validation loss: 1.9424817459557646

Epoch: 6| Step: 9
Training loss: 1.574223518371582
Validation loss: 1.9476222094669138

Epoch: 6| Step: 10
Training loss: 2.4505887031555176
Validation loss: 1.9582968283725042

Epoch: 6| Step: 11
Training loss: 2.467319965362549
Validation loss: 1.9603441146112257

Epoch: 6| Step: 12
Training loss: 2.408491849899292
Validation loss: 1.9652519700347737

Epoch: 6| Step: 13
Training loss: 2.108706474304199
Validation loss: 1.9726511624551588

Epoch: 135| Step: 0
Training loss: 1.849313735961914
Validation loss: 1.9913606964131838

Epoch: 6| Step: 1
Training loss: 2.096226215362549
Validation loss: 2.0253786258800055

Epoch: 6| Step: 2
Training loss: 2.4110965728759766
Validation loss: 2.0277631052078737

Epoch: 6| Step: 3
Training loss: 2.3285305500030518
Validation loss: 2.063651624546256

Epoch: 6| Step: 4
Training loss: 1.4144666194915771
Validation loss: 2.0927424418028964

Epoch: 6| Step: 5
Training loss: 2.3390541076660156
Validation loss: 2.092620684254554

Epoch: 6| Step: 6
Training loss: 2.0670838356018066
Validation loss: 2.0954493989226637

Epoch: 6| Step: 7
Training loss: 2.4509220123291016
Validation loss: 2.097231243246345

Epoch: 6| Step: 8
Training loss: 2.121933937072754
Validation loss: 2.076808984561633

Epoch: 6| Step: 9
Training loss: 2.02868390083313
Validation loss: 2.081651633785617

Epoch: 6| Step: 10
Training loss: 1.2382760047912598
Validation loss: 2.0629176914051013

Epoch: 6| Step: 11
Training loss: 2.285597801208496
Validation loss: 2.0725330639910955

Epoch: 6| Step: 12
Training loss: 2.3987371921539307
Validation loss: 2.0768477865444717

Epoch: 6| Step: 13
Training loss: 1.7311530113220215
Validation loss: 2.0697017664550454

Epoch: 136| Step: 0
Training loss: 1.8959819078445435
Validation loss: 2.081429389215285

Epoch: 6| Step: 1
Training loss: 2.1085762977600098
Validation loss: 2.0595168195744997

Epoch: 6| Step: 2
Training loss: 2.4852938652038574
Validation loss: 2.0706879144073813

Epoch: 6| Step: 3
Training loss: 1.8222591876983643
Validation loss: 2.0597355801572084

Epoch: 6| Step: 4
Training loss: 1.5471268892288208
Validation loss: 2.05164320494539

Epoch: 6| Step: 5
Training loss: 2.3164496421813965
Validation loss: 2.046507720024355

Epoch: 6| Step: 6
Training loss: 2.065100908279419
Validation loss: 2.0600274737163256

Epoch: 6| Step: 7
Training loss: 1.75486159324646
Validation loss: 2.0484789084362727

Epoch: 6| Step: 8
Training loss: 1.8749988079071045
Validation loss: 2.1018307029560046

Epoch: 6| Step: 9
Training loss: 2.4333856105804443
Validation loss: 2.1384435469104397

Epoch: 6| Step: 10
Training loss: 2.2369136810302734
Validation loss: 2.10716571346406

Epoch: 6| Step: 11
Training loss: 2.0952072143554688
Validation loss: 2.1103791344550347

Epoch: 6| Step: 12
Training loss: 2.3824591636657715
Validation loss: 2.0798386809646443

Epoch: 6| Step: 13
Training loss: 1.759610652923584
Validation loss: 2.0722297853039158

Epoch: 137| Step: 0
Training loss: 2.170978546142578
Validation loss: 2.043500042730762

Epoch: 6| Step: 1
Training loss: 2.257467269897461
Validation loss: 2.037187123811373

Epoch: 6| Step: 2
Training loss: 2.324329137802124
Validation loss: 2.04354622287135

Epoch: 6| Step: 3
Training loss: 1.2063498497009277
Validation loss: 2.0447191089712162

Epoch: 6| Step: 4
Training loss: 2.302604913711548
Validation loss: 2.044011180118848

Epoch: 6| Step: 5
Training loss: 2.3911447525024414
Validation loss: 2.057190801507683

Epoch: 6| Step: 6
Training loss: 2.4476401805877686
Validation loss: 2.0685926714251117

Epoch: 6| Step: 7
Training loss: 1.2264727354049683
Validation loss: 2.066722595563499

Epoch: 6| Step: 8
Training loss: 2.5315446853637695
Validation loss: 2.0666467707644225

Epoch: 6| Step: 9
Training loss: 1.9273861646652222
Validation loss: 2.0699962826185327

Epoch: 6| Step: 10
Training loss: 2.229679584503174
Validation loss: 2.064143757666311

Epoch: 6| Step: 11
Training loss: 1.3821500539779663
Validation loss: 2.0448271125875492

Epoch: 6| Step: 12
Training loss: 1.5381524562835693
Validation loss: 2.0324425594781035

Epoch: 6| Step: 13
Training loss: 3.070981502532959
Validation loss: 2.0485915189148276

Epoch: 138| Step: 0
Training loss: 2.5306105613708496
Validation loss: 2.0436619417641753

Epoch: 6| Step: 1
Training loss: 1.3123924732208252
Validation loss: 2.061599046953263

Epoch: 6| Step: 2
Training loss: 2.219482898712158
Validation loss: 2.0973342093088294

Epoch: 6| Step: 3
Training loss: 1.1318937540054321
Validation loss: 2.1105561358954317

Epoch: 6| Step: 4
Training loss: 1.5901954174041748
Validation loss: 2.13943656798332

Epoch: 6| Step: 5
Training loss: 2.458186388015747
Validation loss: 2.0831346255476757

Epoch: 6| Step: 6
Training loss: 2.2244577407836914
Validation loss: 2.05523003814041

Epoch: 6| Step: 7
Training loss: 2.3852171897888184
Validation loss: 2.02164113906122

Epoch: 6| Step: 8
Training loss: 1.9005639553070068
Validation loss: 2.018424040527754

Epoch: 6| Step: 9
Training loss: 3.183072566986084
Validation loss: 2.0376187063032583

Epoch: 6| Step: 10
Training loss: 1.9755125045776367
Validation loss: 2.0349469774512836

Epoch: 6| Step: 11
Training loss: 2.5599846839904785
Validation loss: 2.013353337523758

Epoch: 6| Step: 12
Training loss: 1.6023733615875244
Validation loss: 2.018208529359551

Epoch: 6| Step: 13
Training loss: 2.125403881072998
Validation loss: 2.010285126265659

Epoch: 139| Step: 0
Training loss: 1.635971188545227
Validation loss: 1.9962006461235784

Epoch: 6| Step: 1
Training loss: 2.5776772499084473
Validation loss: 1.9990485329781809

Epoch: 6| Step: 2
Training loss: 1.4915015697479248
Validation loss: 2.014856666646978

Epoch: 6| Step: 3
Training loss: 2.845313549041748
Validation loss: 2.010316087353614

Epoch: 6| Step: 4
Training loss: 1.879626750946045
Validation loss: 2.039657405627671

Epoch: 6| Step: 5
Training loss: 1.3920427560806274
Validation loss: 2.071357468123077

Epoch: 6| Step: 6
Training loss: 2.4289627075195312
Validation loss: 2.0760677501719487

Epoch: 6| Step: 7
Training loss: 3.306089401245117
Validation loss: 2.092918183213921

Epoch: 6| Step: 8
Training loss: 1.5980942249298096
Validation loss: 2.095616650837724

Epoch: 6| Step: 9
Training loss: 1.9277443885803223
Validation loss: 2.093599837313416

Epoch: 6| Step: 10
Training loss: 1.855900526046753
Validation loss: 2.100538856239729

Epoch: 6| Step: 11
Training loss: 2.1516644954681396
Validation loss: 2.063201688951062

Epoch: 6| Step: 12
Training loss: 1.9325504302978516
Validation loss: 2.075994340322351

Epoch: 6| Step: 13
Training loss: 2.1392204761505127
Validation loss: 2.0867209306327243

Epoch: 140| Step: 0
Training loss: 1.7548898458480835
Validation loss: 2.091556131198842

Epoch: 6| Step: 1
Training loss: 1.5132640600204468
Validation loss: 2.1028040967961794

Epoch: 6| Step: 2
Training loss: 2.5287461280822754
Validation loss: 2.1005444167762675

Epoch: 6| Step: 3
Training loss: 2.5135698318481445
Validation loss: 2.1010711231539325

Epoch: 6| Step: 4
Training loss: 2.1201798915863037
Validation loss: 2.108330052386048

Epoch: 6| Step: 5
Training loss: 2.287911891937256
Validation loss: 2.094690066511913

Epoch: 6| Step: 6
Training loss: 1.7718391418457031
Validation loss: 2.0869990330870434

Epoch: 6| Step: 7
Training loss: 1.7047398090362549
Validation loss: 2.0682266783970658

Epoch: 6| Step: 8
Training loss: 0.9835683703422546
Validation loss: 2.043210756394171

Epoch: 6| Step: 9
Training loss: 2.970259189605713
Validation loss: 2.0377281865765973

Epoch: 6| Step: 10
Training loss: 1.911952257156372
Validation loss: 2.030440543287544

Epoch: 6| Step: 11
Training loss: 2.030270576477051
Validation loss: 2.036047322775728

Epoch: 6| Step: 12
Training loss: 2.4361000061035156
Validation loss: 2.0484353675637195

Epoch: 6| Step: 13
Training loss: 1.5221514701843262
Validation loss: 2.0472297207001717

Epoch: 141| Step: 0
Training loss: 2.325228214263916
Validation loss: 2.054328465974459

Epoch: 6| Step: 1
Training loss: 1.955599308013916
Validation loss: 2.0606200425855574

Epoch: 6| Step: 2
Training loss: 1.8725347518920898
Validation loss: 2.0695268543817664

Epoch: 6| Step: 3
Training loss: 1.0824472904205322
Validation loss: 2.08383854486609

Epoch: 6| Step: 4
Training loss: 2.1253345012664795
Validation loss: 2.092049603821129

Epoch: 6| Step: 5
Training loss: 2.47226619720459
Validation loss: 2.1157457136338755

Epoch: 6| Step: 6
Training loss: 1.6430763006210327
Validation loss: 2.111379264503397

Epoch: 6| Step: 7
Training loss: 1.9037163257598877
Validation loss: 2.1035232031217186

Epoch: 6| Step: 8
Training loss: 3.0168375968933105
Validation loss: 2.096477149635233

Epoch: 6| Step: 9
Training loss: 1.3868328332901
Validation loss: 2.10251171101806

Epoch: 6| Step: 10
Training loss: 1.9430925846099854
Validation loss: 2.0822504335834133

Epoch: 6| Step: 11
Training loss: 1.9677751064300537
Validation loss: 2.062502231649173

Epoch: 6| Step: 12
Training loss: 1.7922370433807373
Validation loss: 2.0782523949941

Epoch: 6| Step: 13
Training loss: 2.3117029666900635
Validation loss: 2.0636503645168838

Epoch: 142| Step: 0
Training loss: 2.2783899307250977
Validation loss: 2.0775161186854043

Epoch: 6| Step: 1
Training loss: 2.028240203857422
Validation loss: 2.0939097071206696

Epoch: 6| Step: 2
Training loss: 1.4821723699569702
Validation loss: 2.100696094574467

Epoch: 6| Step: 3
Training loss: 2.0378236770629883
Validation loss: 2.076328246824203

Epoch: 6| Step: 4
Training loss: 2.1594955921173096
Validation loss: 2.0523692382279264

Epoch: 6| Step: 5
Training loss: 2.309218406677246
Validation loss: 2.065797908331758

Epoch: 6| Step: 6
Training loss: 1.8805303573608398
Validation loss: 2.0599700430388093

Epoch: 6| Step: 7
Training loss: 1.0784462690353394
Validation loss: 2.0771295447503366

Epoch: 6| Step: 8
Training loss: 2.1138157844543457
Validation loss: 2.072169465403403

Epoch: 6| Step: 9
Training loss: 2.0156209468841553
Validation loss: 2.0728862516341673

Epoch: 6| Step: 10
Training loss: 1.5664753913879395
Validation loss: 2.05553920935559

Epoch: 6| Step: 11
Training loss: 1.6679770946502686
Validation loss: 2.056543330992422

Epoch: 6| Step: 12
Training loss: 1.9988806247711182
Validation loss: 2.051050883467479

Epoch: 6| Step: 13
Training loss: 3.242555618286133
Validation loss: 2.067911506980978

Epoch: 143| Step: 0
Training loss: 1.5808334350585938
Validation loss: 2.0803707773967455

Epoch: 6| Step: 1
Training loss: 1.9499940872192383
Validation loss: 2.1147552203106623

Epoch: 6| Step: 2
Training loss: 2.2097301483154297
Validation loss: 2.1431184122639317

Epoch: 6| Step: 3
Training loss: 2.355787754058838
Validation loss: 2.1527801354726157

Epoch: 6| Step: 4
Training loss: 1.2127158641815186
Validation loss: 2.101250563898394

Epoch: 6| Step: 5
Training loss: 2.2292449474334717
Validation loss: 2.1093488252291115

Epoch: 6| Step: 6
Training loss: 1.6079387664794922
Validation loss: 2.096196069512316

Epoch: 6| Step: 7
Training loss: 2.0528383255004883
Validation loss: 2.097116352409445

Epoch: 6| Step: 8
Training loss: 1.60500168800354
Validation loss: 2.0752053260803223

Epoch: 6| Step: 9
Training loss: 2.0018210411071777
Validation loss: 2.0704832435936056

Epoch: 6| Step: 10
Training loss: 2.513132095336914
Validation loss: 2.0768738254424064

Epoch: 6| Step: 11
Training loss: 2.39315128326416
Validation loss: 2.084941469213014

Epoch: 6| Step: 12
Training loss: 1.8560254573822021
Validation loss: 2.0689882206660446

Epoch: 6| Step: 13
Training loss: 1.9462323188781738
Validation loss: 2.0791227996990247

Epoch: 144| Step: 0
Training loss: 1.6082934141159058
Validation loss: 2.059402395320195

Epoch: 6| Step: 1
Training loss: 1.753240942955017
Validation loss: 2.085996945699056

Epoch: 6| Step: 2
Training loss: 2.4762001037597656
Validation loss: 2.0980309658153082

Epoch: 6| Step: 3
Training loss: 2.3568196296691895
Validation loss: 2.0983241078674153

Epoch: 6| Step: 4
Training loss: 1.7351582050323486
Validation loss: 2.0897772619801183

Epoch: 6| Step: 5
Training loss: 1.646152138710022
Validation loss: 2.0621704824509157

Epoch: 6| Step: 6
Training loss: 1.518675684928894
Validation loss: 2.0565369026635283

Epoch: 6| Step: 7
Training loss: 1.6851805448532104
Validation loss: 2.028175033548827

Epoch: 6| Step: 8
Training loss: 2.1134696006774902
Validation loss: 2.0303921045795565

Epoch: 6| Step: 9
Training loss: 2.0418171882629395
Validation loss: 2.0242549937258483

Epoch: 6| Step: 10
Training loss: 1.1204200983047485
Validation loss: 2.00766162718496

Epoch: 6| Step: 11
Training loss: 2.3680663108825684
Validation loss: 2.026470381726501

Epoch: 6| Step: 12
Training loss: 2.3273282051086426
Validation loss: 2.068688404175543

Epoch: 6| Step: 13
Training loss: 2.8646650314331055
Validation loss: 2.122502023173917

Epoch: 145| Step: 0
Training loss: 1.7205700874328613
Validation loss: 2.1474226264543432

Epoch: 6| Step: 1
Training loss: 1.5767803192138672
Validation loss: 2.2028729864346084

Epoch: 6| Step: 2
Training loss: 1.99008309841156
Validation loss: 2.2299789382565405

Epoch: 6| Step: 3
Training loss: 2.216256856918335
Validation loss: 2.2397027502777758

Epoch: 6| Step: 4
Training loss: 2.358956813812256
Validation loss: 2.256457313414543

Epoch: 6| Step: 5
Training loss: 2.0160441398620605
Validation loss: 2.187066034604144

Epoch: 6| Step: 6
Training loss: 1.6360727548599243
Validation loss: 2.132985226569637

Epoch: 6| Step: 7
Training loss: 2.5890984535217285
Validation loss: 2.0759669632040043

Epoch: 6| Step: 8
Training loss: 1.706152319908142
Validation loss: 2.0422028559510426

Epoch: 6| Step: 9
Training loss: 1.9343756437301636
Validation loss: 2.008305295821159

Epoch: 6| Step: 10
Training loss: 1.8357945680618286
Validation loss: 2.0247861134108676

Epoch: 6| Step: 11
Training loss: 1.7129443883895874
Validation loss: 2.0248169001712593

Epoch: 6| Step: 12
Training loss: 2.6255011558532715
Validation loss: 2.0423587547835482

Epoch: 6| Step: 13
Training loss: 1.6622328758239746
Validation loss: 2.0301778085770144

Epoch: 146| Step: 0
Training loss: 1.2559723854064941
Validation loss: 2.029541289934548

Epoch: 6| Step: 1
Training loss: 2.437105178833008
Validation loss: 2.038301824241556

Epoch: 6| Step: 2
Training loss: 1.9208608865737915
Validation loss: 2.0448998840906287

Epoch: 6| Step: 3
Training loss: 1.7744314670562744
Validation loss: 2.045334226341658

Epoch: 6| Step: 4
Training loss: 1.064206600189209
Validation loss: 2.073705715517844

Epoch: 6| Step: 5
Training loss: 1.4066896438598633
Validation loss: 2.0709184280005832

Epoch: 6| Step: 6
Training loss: 2.147860050201416
Validation loss: 2.089453475449675

Epoch: 6| Step: 7
Training loss: 2.138124942779541
Validation loss: 2.0880083319961384

Epoch: 6| Step: 8
Training loss: 2.588320732116699
Validation loss: 2.105623250366539

Epoch: 6| Step: 9
Training loss: 1.9816384315490723
Validation loss: 2.096792506915267

Epoch: 6| Step: 10
Training loss: 2.1010308265686035
Validation loss: 2.094085006303685

Epoch: 6| Step: 11
Training loss: 1.8000681400299072
Validation loss: 2.099266859792894

Epoch: 6| Step: 12
Training loss: 2.017338275909424
Validation loss: 2.127954948333002

Epoch: 6| Step: 13
Training loss: 2.020967721939087
Validation loss: 2.0880406031044583

Epoch: 147| Step: 0
Training loss: 1.793455719947815
Validation loss: 2.084997651397541

Epoch: 6| Step: 1
Training loss: 1.5855271816253662
Validation loss: 2.0938919769820346

Epoch: 6| Step: 2
Training loss: 1.9843471050262451
Validation loss: 2.0516596596728087

Epoch: 6| Step: 3
Training loss: 1.9024258852005005
Validation loss: 2.0542617241541543

Epoch: 6| Step: 4
Training loss: 2.4740920066833496
Validation loss: 2.0442008074893745

Epoch: 6| Step: 5
Training loss: 2.259963035583496
Validation loss: 2.0387229855342577

Epoch: 6| Step: 6
Training loss: 1.1435600519180298
Validation loss: 2.028701795044766

Epoch: 6| Step: 7
Training loss: 1.5620019435882568
Validation loss: 2.024477985597426

Epoch: 6| Step: 8
Training loss: 1.8322389125823975
Validation loss: 2.0330635680947253

Epoch: 6| Step: 9
Training loss: 2.2443690299987793
Validation loss: 2.0284710994330784

Epoch: 6| Step: 10
Training loss: 1.938814401626587
Validation loss: 2.008648657029675

Epoch: 6| Step: 11
Training loss: 1.6248021125793457
Validation loss: 2.0122955409429406

Epoch: 6| Step: 12
Training loss: 2.044067859649658
Validation loss: 2.0501573931786323

Epoch: 6| Step: 13
Training loss: 2.6834864616394043
Validation loss: 2.057206855025343

Epoch: 148| Step: 0
Training loss: 2.181962490081787
Validation loss: 2.0678918964119366

Epoch: 6| Step: 1
Training loss: 1.3956434726715088
Validation loss: 2.0817697971097884

Epoch: 6| Step: 2
Training loss: 1.493340015411377
Validation loss: 2.0739889837080434

Epoch: 6| Step: 3
Training loss: 2.1595020294189453
Validation loss: 2.0803601280335458

Epoch: 6| Step: 4
Training loss: 2.237874746322632
Validation loss: 2.0954145590464273

Epoch: 6| Step: 5
Training loss: 2.5636744499206543
Validation loss: 2.0805237318879817

Epoch: 6| Step: 6
Training loss: 2.3741559982299805
Validation loss: 2.081867342354149

Epoch: 6| Step: 7
Training loss: 2.45926833152771
Validation loss: 2.0838557956039265

Epoch: 6| Step: 8
Training loss: 1.3271825313568115
Validation loss: 2.063506687841108

Epoch: 6| Step: 9
Training loss: 1.550724983215332
Validation loss: 2.0579927890531478

Epoch: 6| Step: 10
Training loss: 1.9929062128067017
Validation loss: 2.0627803212852887

Epoch: 6| Step: 11
Training loss: 1.0479164123535156
Validation loss: 2.0541746770181963

Epoch: 6| Step: 12
Training loss: 1.3197423219680786
Validation loss: 2.0624507832270798

Epoch: 6| Step: 13
Training loss: 1.7795270681381226
Validation loss: 2.113659958685598

Epoch: 149| Step: 0
Training loss: 1.7781996726989746
Validation loss: 2.124197501008229

Epoch: 6| Step: 1
Training loss: 1.887859582901001
Validation loss: 2.1516729221549085

Epoch: 6| Step: 2
Training loss: 1.8757483959197998
Validation loss: 2.12953528024817

Epoch: 6| Step: 3
Training loss: 1.4622280597686768
Validation loss: 2.121768984743344

Epoch: 6| Step: 4
Training loss: 2.2411715984344482
Validation loss: 2.0960567587165424

Epoch: 6| Step: 5
Training loss: 1.72967529296875
Validation loss: 2.066439982383482

Epoch: 6| Step: 6
Training loss: 1.7910903692245483
Validation loss: 2.046172836775421

Epoch: 6| Step: 7
Training loss: 1.9931660890579224
Validation loss: 2.0466131779455368

Epoch: 6| Step: 8
Training loss: 2.1917314529418945
Validation loss: 2.0311504410159205

Epoch: 6| Step: 9
Training loss: 1.5735913515090942
Validation loss: 2.0248202534132105

Epoch: 6| Step: 10
Training loss: 1.8465700149536133
Validation loss: 2.0293407312003513

Epoch: 6| Step: 11
Training loss: 1.9362304210662842
Validation loss: 2.0239009267540387

Epoch: 6| Step: 12
Training loss: 2.356337547302246
Validation loss: 2.0671269791100615

Epoch: 6| Step: 13
Training loss: 2.3732004165649414
Validation loss: 2.1029544671376548

Epoch: 150| Step: 0
Training loss: 2.4180757999420166
Validation loss: 2.127661194852603

Epoch: 6| Step: 1
Training loss: 1.6753371953964233
Validation loss: 2.202744445493144

Epoch: 6| Step: 2
Training loss: 2.301962375640869
Validation loss: 2.201287333683301

Epoch: 6| Step: 3
Training loss: 1.801170825958252
Validation loss: 2.181659452376827

Epoch: 6| Step: 4
Training loss: 2.0219974517822266
Validation loss: 2.1593079874592442

Epoch: 6| Step: 5
Training loss: 2.1450891494750977
Validation loss: 2.092608005769791

Epoch: 6| Step: 6
Training loss: 1.1314507722854614
Validation loss: 2.072200708491828

Epoch: 6| Step: 7
Training loss: 1.3291099071502686
Validation loss: 2.0535617438695764

Epoch: 6| Step: 8
Training loss: 2.196902275085449
Validation loss: 2.0676500246088994

Epoch: 6| Step: 9
Training loss: 2.06282377243042
Validation loss: 2.073536877991051

Epoch: 6| Step: 10
Training loss: 1.7171027660369873
Validation loss: 2.0682121963911158

Epoch: 6| Step: 11
Training loss: 1.9220354557037354
Validation loss: 2.0579400062561035

Epoch: 6| Step: 12
Training loss: 1.4749817848205566
Validation loss: 2.0729528511724165

Epoch: 6| Step: 13
Training loss: 2.363358497619629
Validation loss: 2.0813569971310195

Epoch: 151| Step: 0
Training loss: 1.6881829500198364
Validation loss: 2.129934633931806

Epoch: 6| Step: 1
Training loss: 1.772460699081421
Validation loss: 2.1757334611749135

Epoch: 6| Step: 2
Training loss: 1.1896989345550537
Validation loss: 2.1881013967657603

Epoch: 6| Step: 3
Training loss: 2.3153913021087646
Validation loss: 2.1562988065904185

Epoch: 6| Step: 4
Training loss: 1.6740782260894775
Validation loss: 2.1091120935255483

Epoch: 6| Step: 5
Training loss: 1.974198341369629
Validation loss: 2.080444726892697

Epoch: 6| Step: 6
Training loss: 1.5602006912231445
Validation loss: 2.0487862504938597

Epoch: 6| Step: 7
Training loss: 2.1862850189208984
Validation loss: 2.0573591263063493

Epoch: 6| Step: 8
Training loss: 1.095646858215332
Validation loss: 2.0560890910446004

Epoch: 6| Step: 9
Training loss: 1.9553152322769165
Validation loss: 2.059456168964345

Epoch: 6| Step: 10
Training loss: 2.011460781097412
Validation loss: 2.071458103836224

Epoch: 6| Step: 11
Training loss: 1.6790668964385986
Validation loss: 2.089313009733795

Epoch: 6| Step: 12
Training loss: 2.6234092712402344
Validation loss: 2.0915605944971882

Epoch: 6| Step: 13
Training loss: 2.1810531616210938
Validation loss: 2.092447264220125

Epoch: 152| Step: 0
Training loss: 1.6045019626617432
Validation loss: 2.084132025318761

Epoch: 6| Step: 1
Training loss: 1.9649375677108765
Validation loss: 2.071553832741194

Epoch: 6| Step: 2
Training loss: 1.425001621246338
Validation loss: 2.060325845595329

Epoch: 6| Step: 3
Training loss: 1.8765157461166382
Validation loss: 2.0378468023833407

Epoch: 6| Step: 4
Training loss: 2.3728456497192383
Validation loss: 2.011915001817929

Epoch: 6| Step: 5
Training loss: 1.69448721408844
Validation loss: 2.0181731408642185

Epoch: 6| Step: 6
Training loss: 1.770837664604187
Validation loss: 2.02064162172297

Epoch: 6| Step: 7
Training loss: 1.7886232137680054
Validation loss: 2.046765006998534

Epoch: 6| Step: 8
Training loss: 1.5638715028762817
Validation loss: 2.05528248253689

Epoch: 6| Step: 9
Training loss: 2.5432679653167725
Validation loss: 2.0685982499071347

Epoch: 6| Step: 10
Training loss: 1.9568266868591309
Validation loss: 2.0686548948287964

Epoch: 6| Step: 11
Training loss: 1.3230336904525757
Validation loss: 2.0610016674123783

Epoch: 6| Step: 12
Training loss: 1.7475026845932007
Validation loss: 2.0427809146142777

Epoch: 6| Step: 13
Training loss: 1.5118746757507324
Validation loss: 2.048032281219318

Epoch: 153| Step: 0
Training loss: 1.3551552295684814
Validation loss: 2.056796271313903

Epoch: 6| Step: 1
Training loss: 1.5187208652496338
Validation loss: 2.0732666292498187

Epoch: 6| Step: 2
Training loss: 1.8225730657577515
Validation loss: 2.1003319935132096

Epoch: 6| Step: 3
Training loss: 1.7973320484161377
Validation loss: 2.106502902123236

Epoch: 6| Step: 4
Training loss: 1.8452528715133667
Validation loss: 2.1217750618534703

Epoch: 6| Step: 5
Training loss: 1.9328807592391968
Validation loss: 2.1246273773972706

Epoch: 6| Step: 6
Training loss: 2.208369731903076
Validation loss: 2.088350442148024

Epoch: 6| Step: 7
Training loss: 2.0023040771484375
Validation loss: 2.0914180227505264

Epoch: 6| Step: 8
Training loss: 1.4040114879608154
Validation loss: 2.094964749069624

Epoch: 6| Step: 9
Training loss: 1.4974931478500366
Validation loss: 2.0846864715699227

Epoch: 6| Step: 10
Training loss: 1.9872783422470093
Validation loss: 2.080753784025869

Epoch: 6| Step: 11
Training loss: 1.8702985048294067
Validation loss: 2.062220432425058

Epoch: 6| Step: 12
Training loss: 2.33463191986084
Validation loss: 2.0674851504705285

Epoch: 6| Step: 13
Training loss: 1.0866464376449585
Validation loss: 2.054156147023683

Epoch: 154| Step: 0
Training loss: 1.8663716316223145
Validation loss: 2.0488258125961467

Epoch: 6| Step: 1
Training loss: 1.728587031364441
Validation loss: 2.035694024896109

Epoch: 6| Step: 2
Training loss: 2.477360248565674
Validation loss: 2.050482355138307

Epoch: 6| Step: 3
Training loss: 1.5034990310668945
Validation loss: 2.0542165938244072

Epoch: 6| Step: 4
Training loss: 1.75424063205719
Validation loss: 2.0546872884996477

Epoch: 6| Step: 5
Training loss: 1.3713691234588623
Validation loss: 2.038395127942485

Epoch: 6| Step: 6
Training loss: 1.4072151184082031
Validation loss: 2.047041423859135

Epoch: 6| Step: 7
Training loss: 1.759874939918518
Validation loss: 2.0661076832843084

Epoch: 6| Step: 8
Training loss: 1.09690260887146
Validation loss: 2.0762221172291744

Epoch: 6| Step: 9
Training loss: 1.8809213638305664
Validation loss: 2.0825639488876506

Epoch: 6| Step: 10
Training loss: 2.2888076305389404
Validation loss: 2.0939429498487905

Epoch: 6| Step: 11
Training loss: 2.1628940105438232
Validation loss: 2.1216631525306293

Epoch: 6| Step: 12
Training loss: 1.525052547454834
Validation loss: 2.108097340471001

Epoch: 6| Step: 13
Training loss: 1.914906620979309
Validation loss: 2.091086608107372

Epoch: 155| Step: 0
Training loss: 2.0961012840270996
Validation loss: 2.0738471913081344

Epoch: 6| Step: 1
Training loss: 1.5781054496765137
Validation loss: 2.059456152300681

Epoch: 6| Step: 2
Training loss: 2.3749024868011475
Validation loss: 2.058041029078986

Epoch: 6| Step: 3
Training loss: 0.9905494451522827
Validation loss: 2.0806337530894945

Epoch: 6| Step: 4
Training loss: 2.080430030822754
Validation loss: 2.063447683088241

Epoch: 6| Step: 5
Training loss: 1.5522546768188477
Validation loss: 2.054694350047778

Epoch: 6| Step: 6
Training loss: 2.112788438796997
Validation loss: 2.0633275073061705

Epoch: 6| Step: 7
Training loss: 1.1953158378601074
Validation loss: 2.058067935769276

Epoch: 6| Step: 8
Training loss: 1.7730951309204102
Validation loss: 2.058181237148982

Epoch: 6| Step: 9
Training loss: 1.7460052967071533
Validation loss: 2.0592420383166243

Epoch: 6| Step: 10
Training loss: 1.5753414630889893
Validation loss: 2.046746843604631

Epoch: 6| Step: 11
Training loss: 1.4036979675292969
Validation loss: 2.0488040165234636

Epoch: 6| Step: 12
Training loss: 2.3596458435058594
Validation loss: 2.0687687217548327

Epoch: 6| Step: 13
Training loss: 1.91671621799469
Validation loss: 2.0873372016414518

Epoch: 156| Step: 0
Training loss: 1.4432425498962402
Validation loss: 2.1220529643438195

Epoch: 6| Step: 1
Training loss: 1.8723653554916382
Validation loss: 2.0999219494481243

Epoch: 6| Step: 2
Training loss: 1.8786368370056152
Validation loss: 2.10925768908634

Epoch: 6| Step: 3
Training loss: 2.3014822006225586
Validation loss: 2.111683314846408

Epoch: 6| Step: 4
Training loss: 1.3650975227355957
Validation loss: 2.1253893913761264

Epoch: 6| Step: 5
Training loss: 1.9368594884872437
Validation loss: 2.0961717149262786

Epoch: 6| Step: 6
Training loss: 1.9300899505615234
Validation loss: 2.0981278227221583

Epoch: 6| Step: 7
Training loss: 1.9842329025268555
Validation loss: 2.0981386143674134

Epoch: 6| Step: 8
Training loss: 1.6616791486740112
Validation loss: 2.0654005183968493

Epoch: 6| Step: 9
Training loss: 1.98236083984375
Validation loss: 2.068646425841957

Epoch: 6| Step: 10
Training loss: 1.3668794631958008
Validation loss: 2.0609575189569944

Epoch: 6| Step: 11
Training loss: 1.630959153175354
Validation loss: 2.1028188941299275

Epoch: 6| Step: 12
Training loss: 1.977698802947998
Validation loss: 2.110471676754695

Epoch: 6| Step: 13
Training loss: 2.3579862117767334
Validation loss: 2.1134791489570373

Epoch: 157| Step: 0
Training loss: 1.5833725929260254
Validation loss: 2.1078800821817048

Epoch: 6| Step: 1
Training loss: 1.5577561855316162
Validation loss: 2.0696585498830324

Epoch: 6| Step: 2
Training loss: 1.9795005321502686
Validation loss: 2.0749896303299935

Epoch: 6| Step: 3
Training loss: 2.4716014862060547
Validation loss: 2.0741300749522384

Epoch: 6| Step: 4
Training loss: 1.3900481462478638
Validation loss: 2.0504609166934924

Epoch: 6| Step: 5
Training loss: 1.5563323497772217
Validation loss: 2.0727354403465026

Epoch: 6| Step: 6
Training loss: 2.025923252105713
Validation loss: 2.0632699458829817

Epoch: 6| Step: 7
Training loss: 2.2042179107666016
Validation loss: 2.0670228004455566

Epoch: 6| Step: 8
Training loss: 2.5852859020233154
Validation loss: 2.0821917492856263

Epoch: 6| Step: 9
Training loss: 1.1790311336517334
Validation loss: 2.0804152193889824

Epoch: 6| Step: 10
Training loss: 1.1739935874938965
Validation loss: 2.099264398697884

Epoch: 6| Step: 11
Training loss: 1.5322506427764893
Validation loss: 2.1174714744731946

Epoch: 6| Step: 12
Training loss: 1.7161279916763306
Validation loss: 2.117797554180186

Epoch: 6| Step: 13
Training loss: 2.1599011421203613
Validation loss: 2.1382223175417994

Epoch: 158| Step: 0
Training loss: 1.764495849609375
Validation loss: 2.157248786700669

Epoch: 6| Step: 1
Training loss: 1.6412242650985718
Validation loss: 2.161930461083689

Epoch: 6| Step: 2
Training loss: 1.452059268951416
Validation loss: 2.15661189376667

Epoch: 6| Step: 3
Training loss: 1.4323294162750244
Validation loss: 2.099046014970349

Epoch: 6| Step: 4
Training loss: 1.522470474243164
Validation loss: 2.088948711272209

Epoch: 6| Step: 5
Training loss: 2.139528751373291
Validation loss: 2.07935344788336

Epoch: 6| Step: 6
Training loss: 2.4232234954833984
Validation loss: 2.071894032980806

Epoch: 6| Step: 7
Training loss: 1.8570164442062378
Validation loss: 2.0622398058573403

Epoch: 6| Step: 8
Training loss: 2.093214511871338
Validation loss: 2.0387466453736827

Epoch: 6| Step: 9
Training loss: 2.0371077060699463
Validation loss: 2.0373224314822944

Epoch: 6| Step: 10
Training loss: 1.896459937095642
Validation loss: 2.0522165067734255

Epoch: 6| Step: 11
Training loss: 1.0691039562225342
Validation loss: 2.0446971360073296

Epoch: 6| Step: 12
Training loss: 2.0190672874450684
Validation loss: 2.081993350418665

Epoch: 6| Step: 13
Training loss: 1.3571504354476929
Validation loss: 2.088896329684924

Epoch: 159| Step: 0
Training loss: 1.817772388458252
Validation loss: 2.094844456641905

Epoch: 6| Step: 1
Training loss: 1.2183573246002197
Validation loss: 2.1068065089564167

Epoch: 6| Step: 2
Training loss: 1.41263747215271
Validation loss: 2.1172476173729025

Epoch: 6| Step: 3
Training loss: 2.684197425842285
Validation loss: 2.117307073326521

Epoch: 6| Step: 4
Training loss: 1.9446651935577393
Validation loss: 2.125530909466487

Epoch: 6| Step: 5
Training loss: 1.4123256206512451
Validation loss: 2.124864906393072

Epoch: 6| Step: 6
Training loss: 2.113112688064575
Validation loss: 2.1133718721328245

Epoch: 6| Step: 7
Training loss: 1.466827154159546
Validation loss: 2.0962744579520276

Epoch: 6| Step: 8
Training loss: 2.054844379425049
Validation loss: 2.079398056512238

Epoch: 6| Step: 9
Training loss: 1.8880329132080078
Validation loss: 2.0768440346564017

Epoch: 6| Step: 10
Training loss: 1.9553107023239136
Validation loss: 2.0636842686642884

Epoch: 6| Step: 11
Training loss: 1.7180094718933105
Validation loss: 2.065738553641945

Epoch: 6| Step: 12
Training loss: 1.3530519008636475
Validation loss: 2.0650351406425558

Epoch: 6| Step: 13
Training loss: 1.7651903629302979
Validation loss: 2.0536604722340903

Epoch: 160| Step: 0
Training loss: 2.3105387687683105
Validation loss: 2.0308635670651674

Epoch: 6| Step: 1
Training loss: 1.181957721710205
Validation loss: 2.037611351218275

Epoch: 6| Step: 2
Training loss: 1.5250649452209473
Validation loss: 2.065796252219908

Epoch: 6| Step: 3
Training loss: 2.0564277172088623
Validation loss: 2.1157806688739407

Epoch: 6| Step: 4
Training loss: 2.1063928604125977
Validation loss: 2.116417449007752

Epoch: 6| Step: 5
Training loss: 1.2263245582580566
Validation loss: 2.03907916110049

Epoch: 6| Step: 6
Training loss: 2.0419321060180664
Validation loss: 2.0245100067507837

Epoch: 6| Step: 7
Training loss: 1.925223469734192
Validation loss: 2.0245612103451966

Epoch: 6| Step: 8
Training loss: 1.7014338970184326
Validation loss: 2.000438238984795

Epoch: 6| Step: 9
Training loss: 1.9386026859283447
Validation loss: 2.0033566451841787

Epoch: 6| Step: 10
Training loss: 1.844300627708435
Validation loss: 2.006236542937576

Epoch: 6| Step: 11
Training loss: 1.7657501697540283
Validation loss: 2.0318590543603383

Epoch: 6| Step: 12
Training loss: 1.8945727348327637
Validation loss: 2.0288702313617994

Epoch: 6| Step: 13
Training loss: 0.9089588522911072
Validation loss: 2.017036255969796

Epoch: 161| Step: 0
Training loss: 1.5024757385253906
Validation loss: 2.0187743889388217

Epoch: 6| Step: 1
Training loss: 1.6902719736099243
Validation loss: 2.0435944898154146

Epoch: 6| Step: 2
Training loss: 1.8912835121154785
Validation loss: 2.0577456822959324

Epoch: 6| Step: 3
Training loss: 2.055842399597168
Validation loss: 2.0551139334196686

Epoch: 6| Step: 4
Training loss: 1.5408976078033447
Validation loss: 2.0508608074598413

Epoch: 6| Step: 5
Training loss: 1.8291490077972412
Validation loss: 2.084697625970328

Epoch: 6| Step: 6
Training loss: 1.8109217882156372
Validation loss: 2.1171985326274747

Epoch: 6| Step: 7
Training loss: 1.4080886840820312
Validation loss: 2.16035678181597

Epoch: 6| Step: 8
Training loss: 1.38887619972229
Validation loss: 2.17510215954114

Epoch: 6| Step: 9
Training loss: 2.395904541015625
Validation loss: 2.1687716566106325

Epoch: 6| Step: 10
Training loss: 2.088732957839966
Validation loss: 2.0990111084394556

Epoch: 6| Step: 11
Training loss: 1.9185233116149902
Validation loss: 2.064239030243248

Epoch: 6| Step: 12
Training loss: 1.2209216356277466
Validation loss: 2.0507464383238103

Epoch: 6| Step: 13
Training loss: 1.4463237524032593
Validation loss: 2.0500446673362487

Epoch: 162| Step: 0
Training loss: 2.1359400749206543
Validation loss: 2.0470262624884166

Epoch: 6| Step: 1
Training loss: 1.9966402053833008
Validation loss: 2.0627305174386628

Epoch: 6| Step: 2
Training loss: 1.5687499046325684
Validation loss: 2.051619593815137

Epoch: 6| Step: 3
Training loss: 1.5710785388946533
Validation loss: 2.0358181627847816

Epoch: 6| Step: 4
Training loss: 1.7519747018814087
Validation loss: 2.0236393867000455

Epoch: 6| Step: 5
Training loss: 1.5679707527160645
Validation loss: 2.0205771974338

Epoch: 6| Step: 6
Training loss: 1.2112524509429932
Validation loss: 2.0294593841798845

Epoch: 6| Step: 7
Training loss: 1.4948372840881348
Validation loss: 2.065021776383923

Epoch: 6| Step: 8
Training loss: 2.021641254425049
Validation loss: 2.086974417009661

Epoch: 6| Step: 9
Training loss: 2.0184781551361084
Validation loss: 2.0931973380427205

Epoch: 6| Step: 10
Training loss: 1.6808061599731445
Validation loss: 2.066822692912112

Epoch: 6| Step: 11
Training loss: 2.0460243225097656
Validation loss: 2.0709417250848587

Epoch: 6| Step: 12
Training loss: 1.4286701679229736
Validation loss: 2.060895845454226

Epoch: 6| Step: 13
Training loss: 1.6660044193267822
Validation loss: 2.0689320166905723

Epoch: 163| Step: 0
Training loss: 1.593630075454712
Validation loss: 2.0854969357931488

Epoch: 6| Step: 1
Training loss: 1.5927892923355103
Validation loss: 2.0749504809738486

Epoch: 6| Step: 2
Training loss: 1.7406258583068848
Validation loss: 2.078615196289555

Epoch: 6| Step: 3
Training loss: 1.800605297088623
Validation loss: 2.0519026415322417

Epoch: 6| Step: 4
Training loss: 1.39579439163208
Validation loss: 2.063270556029453

Epoch: 6| Step: 5
Training loss: 2.1521189212799072
Validation loss: 2.0868094967257593

Epoch: 6| Step: 6
Training loss: 1.5038707256317139
Validation loss: 2.06904003953421

Epoch: 6| Step: 7
Training loss: 1.7564083337783813
Validation loss: 2.0508058660773822

Epoch: 6| Step: 8
Training loss: 1.0985678434371948
Validation loss: 2.0350809763836604

Epoch: 6| Step: 9
Training loss: 1.638807773590088
Validation loss: 2.0224447429821057

Epoch: 6| Step: 10
Training loss: 2.074716567993164
Validation loss: 2.0244053281763548

Epoch: 6| Step: 11
Training loss: 2.268115520477295
Validation loss: 2.0179984620822373

Epoch: 6| Step: 12
Training loss: 0.9893782138824463
Validation loss: 2.04345041449352

Epoch: 6| Step: 13
Training loss: 1.8303331136703491
Validation loss: 2.0645467094195786

Epoch: 164| Step: 0
Training loss: 1.2162487506866455
Validation loss: 2.072581857763311

Epoch: 6| Step: 1
Training loss: 2.484205961227417
Validation loss: 2.0550217705388225

Epoch: 6| Step: 2
Training loss: 1.9560177326202393
Validation loss: 2.0586454970862276

Epoch: 6| Step: 3
Training loss: 1.0863577127456665
Validation loss: 2.0614559253056846

Epoch: 6| Step: 4
Training loss: 1.9216246604919434
Validation loss: 2.041721608049126

Epoch: 6| Step: 5
Training loss: 1.0312345027923584
Validation loss: 2.0351918794775523

Epoch: 6| Step: 6
Training loss: 2.3872032165527344
Validation loss: 2.037462096060476

Epoch: 6| Step: 7
Training loss: 1.7745198011398315
Validation loss: 2.0613054485731226

Epoch: 6| Step: 8
Training loss: 1.0981192588806152
Validation loss: 2.0571819505383893

Epoch: 6| Step: 9
Training loss: 1.3908987045288086
Validation loss: 2.0839714670694

Epoch: 6| Step: 10
Training loss: 1.6969339847564697
Validation loss: 2.090131785279961

Epoch: 6| Step: 11
Training loss: 1.6768683195114136
Validation loss: 2.1376156947946034

Epoch: 6| Step: 12
Training loss: 2.192932605743408
Validation loss: 2.1521804486551592

Epoch: 6| Step: 13
Training loss: 1.8710458278656006
Validation loss: 2.154388604625579

Epoch: 165| Step: 0
Training loss: 1.8318215608596802
Validation loss: 2.0765176152670257

Epoch: 6| Step: 1
Training loss: 2.1500000953674316
Validation loss: 2.0358264715440813

Epoch: 6| Step: 2
Training loss: 1.4808560609817505
Validation loss: 2.0130952186481927

Epoch: 6| Step: 3
Training loss: 1.1518189907073975
Validation loss: 1.9851155845067834

Epoch: 6| Step: 4
Training loss: 1.81346595287323
Validation loss: 1.9868447421699442

Epoch: 6| Step: 5
Training loss: 1.7094500064849854
Validation loss: 1.9942929539629208

Epoch: 6| Step: 6
Training loss: 2.2161805629730225
Validation loss: 1.9754129584117601

Epoch: 6| Step: 7
Training loss: 1.3455275297164917
Validation loss: 1.9614726753645046

Epoch: 6| Step: 8
Training loss: 1.3163471221923828
Validation loss: 2.00511033432458

Epoch: 6| Step: 9
Training loss: 2.092153549194336
Validation loss: 2.0161173010385163

Epoch: 6| Step: 10
Training loss: 2.0511324405670166
Validation loss: 2.0455976570806196

Epoch: 6| Step: 11
Training loss: 1.7648712396621704
Validation loss: 2.073440590212422

Epoch: 6| Step: 12
Training loss: 1.7485685348510742
Validation loss: 2.1135657372013217

Epoch: 6| Step: 13
Training loss: 1.503942608833313
Validation loss: 2.1376457521992345

Epoch: 166| Step: 0
Training loss: 1.2307963371276855
Validation loss: 2.1139299279900006

Epoch: 6| Step: 1
Training loss: 2.018815040588379
Validation loss: 2.079154240187778

Epoch: 6| Step: 2
Training loss: 1.3719100952148438
Validation loss: 2.053777507556382

Epoch: 6| Step: 3
Training loss: 1.8842685222625732
Validation loss: 2.0269351133736233

Epoch: 6| Step: 4
Training loss: 1.7905428409576416
Validation loss: 2.0259173416322276

Epoch: 6| Step: 5
Training loss: 2.092447280883789
Validation loss: 2.010267050035538

Epoch: 6| Step: 6
Training loss: 1.5067386627197266
Validation loss: 2.025317138241183

Epoch: 6| Step: 7
Training loss: 1.495667815208435
Validation loss: 2.02741188515899

Epoch: 6| Step: 8
Training loss: 1.9584758281707764
Validation loss: 2.0514444292232556

Epoch: 6| Step: 9
Training loss: 1.701209306716919
Validation loss: 2.079718633364606

Epoch: 6| Step: 10
Training loss: 2.010493278503418
Validation loss: 2.048179039391138

Epoch: 6| Step: 11
Training loss: 1.4631301164627075
Validation loss: 2.066374958202403

Epoch: 6| Step: 12
Training loss: 1.4123964309692383
Validation loss: 2.0587200836468766

Epoch: 6| Step: 13
Training loss: 1.9736186265945435
Validation loss: 2.0943447069455217

Epoch: 167| Step: 0
Training loss: 1.6486148834228516
Validation loss: 2.1110664939367645

Epoch: 6| Step: 1
Training loss: 1.6153240203857422
Validation loss: 2.0951941141518216

Epoch: 6| Step: 2
Training loss: 1.7799148559570312
Validation loss: 2.080559221647119

Epoch: 6| Step: 3
Training loss: 1.8934025764465332
Validation loss: 2.0696797781093146

Epoch: 6| Step: 4
Training loss: 1.8272130489349365
Validation loss: 2.065913502888013

Epoch: 6| Step: 5
Training loss: 2.1951427459716797
Validation loss: 2.0439454342729304

Epoch: 6| Step: 6
Training loss: 1.7042546272277832
Validation loss: 2.0437313228525142

Epoch: 6| Step: 7
Training loss: 1.6972651481628418
Validation loss: 2.033899143177976

Epoch: 6| Step: 8
Training loss: 1.8923335075378418
Validation loss: 2.0394589849697646

Epoch: 6| Step: 9
Training loss: 2.172537326812744
Validation loss: 2.0374362571265108

Epoch: 6| Step: 10
Training loss: 0.8788072466850281
Validation loss: 2.025953241573867

Epoch: 6| Step: 11
Training loss: 1.0815203189849854
Validation loss: 2.027586829277777

Epoch: 6| Step: 12
Training loss: 2.0553579330444336
Validation loss: 2.0284526322477605

Epoch: 6| Step: 13
Training loss: 1.0563246011734009
Validation loss: 2.076752257603471

Epoch: 168| Step: 0
Training loss: 1.6610580682754517
Validation loss: 2.1105165097021286

Epoch: 6| Step: 1
Training loss: 2.575378894805908
Validation loss: 2.165666232826889

Epoch: 6| Step: 2
Training loss: 1.4598214626312256
Validation loss: 2.16199734903151

Epoch: 6| Step: 3
Training loss: 1.5040253400802612
Validation loss: 2.138903384567589

Epoch: 6| Step: 4
Training loss: 1.7615658044815063
Validation loss: 2.099522250954823

Epoch: 6| Step: 5
Training loss: 2.1841859817504883
Validation loss: 2.0752217743986394

Epoch: 6| Step: 6
Training loss: 1.3581984043121338
Validation loss: 2.062502940495809

Epoch: 6| Step: 7
Training loss: 2.0769600868225098
Validation loss: 2.042899949576265

Epoch: 6| Step: 8
Training loss: 1.444985032081604
Validation loss: 2.0196824560883226

Epoch: 6| Step: 9
Training loss: 1.8017139434814453
Validation loss: 2.0185128924667195

Epoch: 6| Step: 10
Training loss: 1.7773953676223755
Validation loss: 2.0209699394882366

Epoch: 6| Step: 11
Training loss: 1.5026283264160156
Validation loss: 2.02386881971872

Epoch: 6| Step: 12
Training loss: 1.236327886581421
Validation loss: 2.0225049065005396

Epoch: 6| Step: 13
Training loss: 0.9267427921295166
Validation loss: 2.0327188917385635

Epoch: 169| Step: 0
Training loss: 1.7454289197921753
Validation loss: 2.0671343444496073

Epoch: 6| Step: 1
Training loss: 1.9306148290634155
Validation loss: 2.0684771794144825

Epoch: 6| Step: 2
Training loss: 1.3095178604125977
Validation loss: 2.062778357536562

Epoch: 6| Step: 3
Training loss: 2.075106620788574
Validation loss: 2.0663000806685416

Epoch: 6| Step: 4
Training loss: 1.7636979818344116
Validation loss: 2.0796740080720637

Epoch: 6| Step: 5
Training loss: 1.5105167627334595
Validation loss: 2.084364917970473

Epoch: 6| Step: 6
Training loss: 1.6403467655181885
Validation loss: 2.0937759773705595

Epoch: 6| Step: 7
Training loss: 1.5767462253570557
Validation loss: 2.0809915322129444

Epoch: 6| Step: 8
Training loss: 2.1152358055114746
Validation loss: 2.0766476943928707

Epoch: 6| Step: 9
Training loss: 1.031234622001648
Validation loss: 2.079714805849137

Epoch: 6| Step: 10
Training loss: 0.917611300945282
Validation loss: 2.0783606024198633

Epoch: 6| Step: 11
Training loss: 1.6949365139007568
Validation loss: 2.067065179988902

Epoch: 6| Step: 12
Training loss: 1.8367961645126343
Validation loss: 2.0416416827068535

Epoch: 6| Step: 13
Training loss: 1.6335631608963013
Validation loss: 2.040474836544324

Epoch: 170| Step: 0
Training loss: 2.042001247406006
Validation loss: 2.0174827216773905

Epoch: 6| Step: 1
Training loss: 1.2514454126358032
Validation loss: 2.0241391915147022

Epoch: 6| Step: 2
Training loss: 1.4014172554016113
Validation loss: 2.0308243971998974

Epoch: 6| Step: 3
Training loss: 1.8598206043243408
Validation loss: 2.0285740026863675

Epoch: 6| Step: 4
Training loss: 1.9774333238601685
Validation loss: 2.014775904276038

Epoch: 6| Step: 5
Training loss: 1.6806278228759766
Validation loss: 2.01912998384045

Epoch: 6| Step: 6
Training loss: 1.8208484649658203
Validation loss: 2.028303600126697

Epoch: 6| Step: 7
Training loss: 1.482328176498413
Validation loss: 2.074871427269392

Epoch: 6| Step: 8
Training loss: 1.6801929473876953
Validation loss: 2.1334805668041272

Epoch: 6| Step: 9
Training loss: 1.865761637687683
Validation loss: 2.1681160593545563

Epoch: 6| Step: 10
Training loss: 1.481736421585083
Validation loss: 2.1884740180866693

Epoch: 6| Step: 11
Training loss: 1.4881020784378052
Validation loss: 2.169834275399485

Epoch: 6| Step: 12
Training loss: 1.8793730735778809
Validation loss: 2.0962193345510833

Epoch: 6| Step: 13
Training loss: 1.4417662620544434
Validation loss: 2.065117415561471

Epoch: 171| Step: 0
Training loss: 1.4301332235336304
Validation loss: 2.0311863242938952

Epoch: 6| Step: 1
Training loss: 2.313873529434204
Validation loss: 2.03749143949119

Epoch: 6| Step: 2
Training loss: 1.144007682800293
Validation loss: 2.0532608314227034

Epoch: 6| Step: 3
Training loss: 1.6794427633285522
Validation loss: 2.062514735806373

Epoch: 6| Step: 4
Training loss: 1.7833092212677002
Validation loss: 2.0855429121243056

Epoch: 6| Step: 5
Training loss: 1.4626917839050293
Validation loss: 2.058497853176568

Epoch: 6| Step: 6
Training loss: 0.7950356006622314
Validation loss: 2.0743707700442244

Epoch: 6| Step: 7
Training loss: 1.1919097900390625
Validation loss: 2.061702405252764

Epoch: 6| Step: 8
Training loss: 2.020216464996338
Validation loss: 2.060637822715185

Epoch: 6| Step: 9
Training loss: 1.7057424783706665
Validation loss: 2.0699415873455744

Epoch: 6| Step: 10
Training loss: 1.9560788869857788
Validation loss: 2.0745760228044245

Epoch: 6| Step: 11
Training loss: 2.1640191078186035
Validation loss: 2.06510837616459

Epoch: 6| Step: 12
Training loss: 1.7641056776046753
Validation loss: 2.068054114618609

Epoch: 6| Step: 13
Training loss: 1.2640141248703003
Validation loss: 2.022050405061373

Epoch: 172| Step: 0
Training loss: 1.475563645362854
Validation loss: 2.005821727937268

Epoch: 6| Step: 1
Training loss: 1.6447699069976807
Validation loss: 2.015594343985281

Epoch: 6| Step: 2
Training loss: 1.4371857643127441
Validation loss: 2.0177766917854227

Epoch: 6| Step: 3
Training loss: 1.702150583267212
Validation loss: 2.055380504618409

Epoch: 6| Step: 4
Training loss: 1.4577018022537231
Validation loss: 2.080024711547359

Epoch: 6| Step: 5
Training loss: 1.4036253690719604
Validation loss: 2.102726058293414

Epoch: 6| Step: 6
Training loss: 1.3552813529968262
Validation loss: 2.0920904144164054

Epoch: 6| Step: 7
Training loss: 2.154168128967285
Validation loss: 2.077270338612218

Epoch: 6| Step: 8
Training loss: 1.7764562368392944
Validation loss: 2.047334576165804

Epoch: 6| Step: 9
Training loss: 2.3357865810394287
Validation loss: 2.0139509413831975

Epoch: 6| Step: 10
Training loss: 1.7151957750320435
Validation loss: 2.0263559920813448

Epoch: 6| Step: 11
Training loss: 1.7716445922851562
Validation loss: 2.019972626880933

Epoch: 6| Step: 12
Training loss: 1.5088106393814087
Validation loss: 1.9985442751197404

Epoch: 6| Step: 13
Training loss: 1.6031564474105835
Validation loss: 2.006810131893363

Epoch: 173| Step: 0
Training loss: 1.7782424688339233
Validation loss: 2.028514181413958

Epoch: 6| Step: 1
Training loss: 1.8128077983856201
Validation loss: 2.0378157759225495

Epoch: 6| Step: 2
Training loss: 1.8759160041809082
Validation loss: 2.0699743968184277

Epoch: 6| Step: 3
Training loss: 1.2895259857177734
Validation loss: 2.076092061176095

Epoch: 6| Step: 4
Training loss: 1.874603509902954
Validation loss: 2.0876747331311627

Epoch: 6| Step: 5
Training loss: 1.8468220233917236
Validation loss: 2.0999215546474663

Epoch: 6| Step: 6
Training loss: 1.0217208862304688
Validation loss: 2.1042110484133483

Epoch: 6| Step: 7
Training loss: 1.7313413619995117
Validation loss: 2.097727308991135

Epoch: 6| Step: 8
Training loss: 1.8991374969482422
Validation loss: 2.090371895861882

Epoch: 6| Step: 9
Training loss: 1.7892158031463623
Validation loss: 2.0426311826193206

Epoch: 6| Step: 10
Training loss: 1.5571314096450806
Validation loss: 2.0258672019486785

Epoch: 6| Step: 11
Training loss: 1.824387788772583
Validation loss: 2.0080066727053736

Epoch: 6| Step: 12
Training loss: 0.8996744155883789
Validation loss: 2.014310913701211

Epoch: 6| Step: 13
Training loss: 1.193014144897461
Validation loss: 2.0095720444956133

Epoch: 174| Step: 0
Training loss: 1.3633959293365479
Validation loss: 2.00891552945619

Epoch: 6| Step: 1
Training loss: 1.413294792175293
Validation loss: 2.0115633677410822

Epoch: 6| Step: 2
Training loss: 1.3523473739624023
Validation loss: 2.0214386550329064

Epoch: 6| Step: 3
Training loss: 1.9774069786071777
Validation loss: 2.0420059132319626

Epoch: 6| Step: 4
Training loss: 1.0427261590957642
Validation loss: 2.0957268361122376

Epoch: 6| Step: 5
Training loss: 1.3853837251663208
Validation loss: 2.1392674125650877

Epoch: 6| Step: 6
Training loss: 2.0522141456604004
Validation loss: 2.1770629575175624

Epoch: 6| Step: 7
Training loss: 1.4892454147338867
Validation loss: 2.1858397927335513

Epoch: 6| Step: 8
Training loss: 1.674330234527588
Validation loss: 2.142621709454444

Epoch: 6| Step: 9
Training loss: 1.8644977807998657
Validation loss: 2.1265867910077496

Epoch: 6| Step: 10
Training loss: 1.6987318992614746
Validation loss: 2.0720327208119054

Epoch: 6| Step: 11
Training loss: 1.925665259361267
Validation loss: 2.0718664789712555

Epoch: 6| Step: 12
Training loss: 1.6656471490859985
Validation loss: 2.063236762118596

Epoch: 6| Step: 13
Training loss: 1.861939787864685
Validation loss: 2.0472311486480055

Epoch: 175| Step: 0
Training loss: 1.746044397354126
Validation loss: 2.041760011385846

Epoch: 6| Step: 1
Training loss: 2.07704758644104
Validation loss: 2.0171081045622468

Epoch: 6| Step: 2
Training loss: 0.6632451415061951
Validation loss: 2.002253036345205

Epoch: 6| Step: 3
Training loss: 1.7820823192596436
Validation loss: 1.9682323458374187

Epoch: 6| Step: 4
Training loss: 1.455034852027893
Validation loss: 1.9806814103998163

Epoch: 6| Step: 5
Training loss: 1.2786682844161987
Validation loss: 1.965565759648559

Epoch: 6| Step: 6
Training loss: 1.3181551694869995
Validation loss: 1.9713059240771877

Epoch: 6| Step: 7
Training loss: 1.1884286403656006
Validation loss: 2.0204351012424757

Epoch: 6| Step: 8
Training loss: 1.4970004558563232
Validation loss: 2.05988968700491

Epoch: 6| Step: 9
Training loss: 2.392108917236328
Validation loss: 2.1007429809980493

Epoch: 6| Step: 10
Training loss: 1.9769545793533325
Validation loss: 2.115270568478492

Epoch: 6| Step: 11
Training loss: 1.5274046659469604
Validation loss: 2.0919239341571765

Epoch: 6| Step: 12
Training loss: 2.288804769515991
Validation loss: 2.0517206333016835

Epoch: 6| Step: 13
Training loss: 1.164016842842102
Validation loss: 2.0096491357331634

Epoch: 176| Step: 0
Training loss: 1.8543875217437744
Validation loss: 2.0022311249086933

Epoch: 6| Step: 1
Training loss: 1.3637293577194214
Validation loss: 1.9951745669047039

Epoch: 6| Step: 2
Training loss: 1.1123783588409424
Validation loss: 1.985289289105323

Epoch: 6| Step: 3
Training loss: 1.278965950012207
Validation loss: 1.9996977185690274

Epoch: 6| Step: 4
Training loss: 1.6334385871887207
Validation loss: 1.9954365889231365

Epoch: 6| Step: 5
Training loss: 1.8263652324676514
Validation loss: 2.0107673509146577

Epoch: 6| Step: 6
Training loss: 1.981568455696106
Validation loss: 2.0354728647457656

Epoch: 6| Step: 7
Training loss: 1.777315616607666
Validation loss: 2.073277024812596

Epoch: 6| Step: 8
Training loss: 1.2620824575424194
Validation loss: 2.1019208174879833

Epoch: 6| Step: 9
Training loss: 1.8455548286437988
Validation loss: 2.116894006729126

Epoch: 6| Step: 10
Training loss: 2.103748321533203
Validation loss: 2.1229786821590957

Epoch: 6| Step: 11
Training loss: 1.388668179512024
Validation loss: 2.1227838211162116

Epoch: 6| Step: 12
Training loss: 0.9939645528793335
Validation loss: 2.0897993297987085

Epoch: 6| Step: 13
Training loss: 2.2206552028656006
Validation loss: 2.0570685299493934

Epoch: 177| Step: 0
Training loss: 1.5515732765197754
Validation loss: 2.0299200422020367

Epoch: 6| Step: 1
Training loss: 1.687134027481079
Validation loss: 2.0175803835673998

Epoch: 6| Step: 2
Training loss: 1.3062655925750732
Validation loss: 1.989806721287389

Epoch: 6| Step: 3
Training loss: 1.6367348432540894
Validation loss: 2.0007463988437446

Epoch: 6| Step: 4
Training loss: 1.5409443378448486
Validation loss: 1.9970041449351976

Epoch: 6| Step: 5
Training loss: 1.710930585861206
Validation loss: 1.9748996124472669

Epoch: 6| Step: 6
Training loss: 1.2116156816482544
Validation loss: 1.992919792411148

Epoch: 6| Step: 7
Training loss: 1.0701056718826294
Validation loss: 1.9812706401271205

Epoch: 6| Step: 8
Training loss: 1.7771837711334229
Validation loss: 2.01854266658906

Epoch: 6| Step: 9
Training loss: 2.0033576488494873
Validation loss: 2.034657589850887

Epoch: 6| Step: 10
Training loss: 1.633049488067627
Validation loss: 2.0265779392693632

Epoch: 6| Step: 11
Training loss: 1.7866935729980469
Validation loss: 2.0302077800996843

Epoch: 6| Step: 12
Training loss: 2.0027823448181152
Validation loss: 2.0210149134359052

Epoch: 6| Step: 13
Training loss: 0.4335702061653137
Validation loss: 2.059111133698494

Epoch: 178| Step: 0
Training loss: 1.3287310600280762
Validation loss: 2.024943196645347

Epoch: 6| Step: 1
Training loss: 1.8958215713500977
Validation loss: 2.0203359511590775

Epoch: 6| Step: 2
Training loss: 1.5045175552368164
Validation loss: 2.0145784116560415

Epoch: 6| Step: 3
Training loss: 0.9831572771072388
Validation loss: 2.046293866249823

Epoch: 6| Step: 4
Training loss: 1.7140132188796997
Validation loss: 2.0588668854005876

Epoch: 6| Step: 5
Training loss: 1.1981086730957031
Validation loss: 2.067402239768736

Epoch: 6| Step: 6
Training loss: 2.1734633445739746
Validation loss: 2.073256351614511

Epoch: 6| Step: 7
Training loss: 1.9352235794067383
Validation loss: 2.068284264174841

Epoch: 6| Step: 8
Training loss: 1.4806920289993286
Validation loss: 2.078440361125495

Epoch: 6| Step: 9
Training loss: 1.4084789752960205
Validation loss: 2.0840021384659635

Epoch: 6| Step: 10
Training loss: 1.3209724426269531
Validation loss: 2.0924305736377673

Epoch: 6| Step: 11
Training loss: 1.6966190338134766
Validation loss: 2.117448599107804

Epoch: 6| Step: 12
Training loss: 1.2290749549865723
Validation loss: 2.1245378986481698

Epoch: 6| Step: 13
Training loss: 2.0473692417144775
Validation loss: 2.124493222082815

Epoch: 179| Step: 0
Training loss: 1.641823410987854
Validation loss: 2.124904360822452

Epoch: 6| Step: 1
Training loss: 1.3889049291610718
Validation loss: 2.128879685555735

Epoch: 6| Step: 2
Training loss: 1.0411791801452637
Validation loss: 2.1098311639601186

Epoch: 6| Step: 3
Training loss: 1.1874600648880005
Validation loss: 2.0765049124276764

Epoch: 6| Step: 4
Training loss: 2.3284988403320312
Validation loss: 2.047008991241455

Epoch: 6| Step: 5
Training loss: 1.7229316234588623
Validation loss: 1.9988767280373523

Epoch: 6| Step: 6
Training loss: 1.3433921337127686
Validation loss: 1.993034129501671

Epoch: 6| Step: 7
Training loss: 1.6756067276000977
Validation loss: 1.9714649133784796

Epoch: 6| Step: 8
Training loss: 1.230151653289795
Validation loss: 1.9822847714988134

Epoch: 6| Step: 9
Training loss: 1.5015538930892944
Validation loss: 1.9605205751234485

Epoch: 6| Step: 10
Training loss: 1.4228003025054932
Validation loss: 1.97784988598157

Epoch: 6| Step: 11
Training loss: 1.7784810066223145
Validation loss: 2.005420745060008

Epoch: 6| Step: 12
Training loss: 1.4963053464889526
Validation loss: 2.0490426017392065

Epoch: 6| Step: 13
Training loss: 2.202448844909668
Validation loss: 2.080833776022798

Epoch: 180| Step: 0
Training loss: 1.8110973834991455
Validation loss: 2.070723218302573

Epoch: 6| Step: 1
Training loss: 1.6617825031280518
Validation loss: 2.0659382740656533

Epoch: 6| Step: 2
Training loss: 1.5086581707000732
Validation loss: 2.0427078662380094

Epoch: 6| Step: 3
Training loss: 1.1502882242202759
Validation loss: 2.0114695923302763

Epoch: 6| Step: 4
Training loss: 1.8851255178451538
Validation loss: 2.00339933108258

Epoch: 6| Step: 5
Training loss: 0.9875772595405579
Validation loss: 2.000674004195839

Epoch: 6| Step: 6
Training loss: 1.5651578903198242
Validation loss: 2.0136161350434825

Epoch: 6| Step: 7
Training loss: 1.6158976554870605
Validation loss: 2.00479406310666

Epoch: 6| Step: 8
Training loss: 1.430356740951538
Validation loss: 2.0376567443211875

Epoch: 6| Step: 9
Training loss: 1.6757938861846924
Validation loss: 2.103106583318403

Epoch: 6| Step: 10
Training loss: 1.4309678077697754
Validation loss: 2.120175184742097

Epoch: 6| Step: 11
Training loss: 1.5069785118103027
Validation loss: 2.1525016446267404

Epoch: 6| Step: 12
Training loss: 2.043755054473877
Validation loss: 2.1359330633635163

Epoch: 6| Step: 13
Training loss: 1.332582950592041
Validation loss: 2.1095000364447154

Epoch: 181| Step: 0
Training loss: 1.3175048828125
Validation loss: 2.0758439545990317

Epoch: 6| Step: 1
Training loss: 2.031118392944336
Validation loss: 2.056919938774519

Epoch: 6| Step: 2
Training loss: 1.5321990251541138
Validation loss: 2.0204657713572183

Epoch: 6| Step: 3
Training loss: 1.620378017425537
Validation loss: 2.0151694564409155

Epoch: 6| Step: 4
Training loss: 1.261871576309204
Validation loss: 2.0153268870487007

Epoch: 6| Step: 5
Training loss: 1.338800072669983
Validation loss: 1.990298096851636

Epoch: 6| Step: 6
Training loss: 1.5572057962417603
Validation loss: 1.9806435928549817

Epoch: 6| Step: 7
Training loss: 1.6925327777862549
Validation loss: 1.9890998166094545

Epoch: 6| Step: 8
Training loss: 1.5545436143875122
Validation loss: 2.0003827130922707

Epoch: 6| Step: 9
Training loss: 0.9897948503494263
Validation loss: 2.0131681106423818

Epoch: 6| Step: 10
Training loss: 1.7145311832427979
Validation loss: 2.0125696171996412

Epoch: 6| Step: 11
Training loss: 1.0923815965652466
Validation loss: 1.9693808171056932

Epoch: 6| Step: 12
Training loss: 1.6299231052398682
Validation loss: 2.0000740097415064

Epoch: 6| Step: 13
Training loss: 1.5016664266586304
Validation loss: 1.989424003067837

Epoch: 182| Step: 0
Training loss: 1.817217469215393
Validation loss: 1.982297582011069

Epoch: 6| Step: 1
Training loss: 1.3703019618988037
Validation loss: 1.960445160506874

Epoch: 6| Step: 2
Training loss: 1.7024004459381104
Validation loss: 1.9859234081801547

Epoch: 6| Step: 3
Training loss: 1.843619465827942
Validation loss: 1.9766952273666218

Epoch: 6| Step: 4
Training loss: 1.9244920015335083
Validation loss: 1.9784902282940444

Epoch: 6| Step: 5
Training loss: 0.896952748298645
Validation loss: 1.979265243776383

Epoch: 6| Step: 6
Training loss: 1.077502965927124
Validation loss: 1.9946889441500428

Epoch: 6| Step: 7
Training loss: 1.3713634014129639
Validation loss: 2.0401814099281066

Epoch: 6| Step: 8
Training loss: 1.422276496887207
Validation loss: 2.0694555005719586

Epoch: 6| Step: 9
Training loss: 1.6207612752914429
Validation loss: 2.1255412178654827

Epoch: 6| Step: 10
Training loss: 1.468783974647522
Validation loss: 2.117684502755442

Epoch: 6| Step: 11
Training loss: 1.254613995552063
Validation loss: 2.1155668227903304

Epoch: 6| Step: 12
Training loss: 1.7021472454071045
Validation loss: 2.105654319127401

Epoch: 6| Step: 13
Training loss: 1.194266676902771
Validation loss: 2.0780164939101025

Epoch: 183| Step: 0
Training loss: 1.9914233684539795
Validation loss: 2.0566899955913587

Epoch: 6| Step: 1
Training loss: 1.165738582611084
Validation loss: 2.0336136305204002

Epoch: 6| Step: 2
Training loss: 0.990714967250824
Validation loss: 2.0198332007213304

Epoch: 6| Step: 3
Training loss: 1.3325529098510742
Validation loss: 2.0117651724046275

Epoch: 6| Step: 4
Training loss: 2.034595489501953
Validation loss: 2.0054610800999466

Epoch: 6| Step: 5
Training loss: 0.9876380562782288
Validation loss: 2.0072766093797583

Epoch: 6| Step: 6
Training loss: 1.459702730178833
Validation loss: 2.0100332793369087

Epoch: 6| Step: 7
Training loss: 1.1390362977981567
Validation loss: 1.9914396180901477

Epoch: 6| Step: 8
Training loss: 2.0046117305755615
Validation loss: 1.9986607669502177

Epoch: 6| Step: 9
Training loss: 1.886244297027588
Validation loss: 2.0108723640441895

Epoch: 6| Step: 10
Training loss: 1.2705938816070557
Validation loss: 2.0177124161874094

Epoch: 6| Step: 11
Training loss: 1.909827470779419
Validation loss: 2.0486569225147204

Epoch: 6| Step: 12
Training loss: 1.486506462097168
Validation loss: 2.0621951933830016

Epoch: 6| Step: 13
Training loss: 1.3914775848388672
Validation loss: 2.056941904047484

Epoch: 184| Step: 0
Training loss: 1.096256971359253
Validation loss: 2.0351942367451166

Epoch: 6| Step: 1
Training loss: 2.039944648742676
Validation loss: 2.016534792479648

Epoch: 6| Step: 2
Training loss: 0.8922497034072876
Validation loss: 2.035810858972611

Epoch: 6| Step: 3
Training loss: 1.7012107372283936
Validation loss: 2.0273104252353793

Epoch: 6| Step: 4
Training loss: 1.27228844165802
Validation loss: 2.035763793094184

Epoch: 6| Step: 5
Training loss: 1.3591628074645996
Validation loss: 2.035018878598367

Epoch: 6| Step: 6
Training loss: 1.254913091659546
Validation loss: 2.0535292804882093

Epoch: 6| Step: 7
Training loss: 1.916826605796814
Validation loss: 2.056441371158887

Epoch: 6| Step: 8
Training loss: 1.7580769062042236
Validation loss: 2.0338299325717393

Epoch: 6| Step: 9
Training loss: 1.8337101936340332
Validation loss: 2.032385399264674

Epoch: 6| Step: 10
Training loss: 1.3675730228424072
Validation loss: 2.0423567089983212

Epoch: 6| Step: 11
Training loss: 1.4174492359161377
Validation loss: 2.0382819944812405

Epoch: 6| Step: 12
Training loss: 1.3184573650360107
Validation loss: 2.0362538586380663

Epoch: 6| Step: 13
Training loss: 1.7956182956695557
Validation loss: 2.013110065972933

Epoch: 185| Step: 0
Training loss: 1.3772121667861938
Validation loss: 1.9919276737397718

Epoch: 6| Step: 1
Training loss: 1.1042892932891846
Validation loss: 1.9638785828826248

Epoch: 6| Step: 2
Training loss: 1.2318789958953857
Validation loss: 1.9639268318812053

Epoch: 6| Step: 3
Training loss: 1.6092133522033691
Validation loss: 1.9915819296272852

Epoch: 6| Step: 4
Training loss: 1.433661937713623
Validation loss: 2.001741946384471

Epoch: 6| Step: 5
Training loss: 2.16827392578125
Validation loss: 2.0097162851723294

Epoch: 6| Step: 6
Training loss: 1.4765870571136475
Validation loss: 2.0088134837406937

Epoch: 6| Step: 7
Training loss: 1.6333119869232178
Validation loss: 2.0161791360506447

Epoch: 6| Step: 8
Training loss: 1.2728683948516846
Validation loss: 2.0640624184762277

Epoch: 6| Step: 9
Training loss: 1.845138669013977
Validation loss: 2.0897081000830537

Epoch: 6| Step: 10
Training loss: 1.543092131614685
Validation loss: 2.1091717058612454

Epoch: 6| Step: 11
Training loss: 1.9162943363189697
Validation loss: 2.104559334375525

Epoch: 6| Step: 12
Training loss: 1.429033637046814
Validation loss: 2.032150632591658

Epoch: 6| Step: 13
Training loss: 1.4990320205688477
Validation loss: 1.9999051145327988

Epoch: 186| Step: 0
Training loss: 1.8400025367736816
Validation loss: 1.9860412074673561

Epoch: 6| Step: 1
Training loss: 1.3915574550628662
Validation loss: 1.9685435730923888

Epoch: 6| Step: 2
Training loss: 1.8405919075012207
Validation loss: 1.9645479981617262

Epoch: 6| Step: 3
Training loss: 2.065720558166504
Validation loss: 1.975567606187636

Epoch: 6| Step: 4
Training loss: 1.6860003471374512
Validation loss: 1.9703951458777151

Epoch: 6| Step: 5
Training loss: 0.8990666270256042
Validation loss: 1.9807776135783042

Epoch: 6| Step: 6
Training loss: 1.042889952659607
Validation loss: 1.9930958132590018

Epoch: 6| Step: 7
Training loss: 0.6487093567848206
Validation loss: 2.0032786656451482

Epoch: 6| Step: 8
Training loss: 1.6747982501983643
Validation loss: 2.012862636196998

Epoch: 6| Step: 9
Training loss: 2.0737104415893555
Validation loss: 2.0139191612120597

Epoch: 6| Step: 10
Training loss: 0.8088924884796143
Validation loss: 2.0564668960468744

Epoch: 6| Step: 11
Training loss: 1.3432528972625732
Validation loss: 2.0799247603262625

Epoch: 6| Step: 12
Training loss: 1.7194421291351318
Validation loss: 2.1146998379820134

Epoch: 6| Step: 13
Training loss: 1.2626023292541504
Validation loss: 2.1342612133231214

Epoch: 187| Step: 0
Training loss: 1.6223374605178833
Validation loss: 2.1431215309327647

Epoch: 6| Step: 1
Training loss: 1.0532621145248413
Validation loss: 2.1090693537906935

Epoch: 6| Step: 2
Training loss: 1.2722339630126953
Validation loss: 2.0933894598355858

Epoch: 6| Step: 3
Training loss: 1.2017717361450195
Validation loss: 2.042053959702933

Epoch: 6| Step: 4
Training loss: 1.3280348777770996
Validation loss: 2.050621498015619

Epoch: 6| Step: 5
Training loss: 1.4093655347824097
Validation loss: 2.0240676121045182

Epoch: 6| Step: 6
Training loss: 1.6549760103225708
Validation loss: 2.0145494681532665

Epoch: 6| Step: 7
Training loss: 1.0611238479614258
Validation loss: 2.001877074600548

Epoch: 6| Step: 8
Training loss: 1.157247543334961
Validation loss: 1.9767279624938965

Epoch: 6| Step: 9
Training loss: 1.078062653541565
Validation loss: 1.975382649770347

Epoch: 6| Step: 10
Training loss: 1.695038080215454
Validation loss: 1.982801019504506

Epoch: 6| Step: 11
Training loss: 1.415961503982544
Validation loss: 1.9955851826616513

Epoch: 6| Step: 12
Training loss: 2.4920992851257324
Validation loss: 2.0280564997785833

Epoch: 6| Step: 13
Training loss: 2.093325614929199
Validation loss: 2.0161425093168854

Epoch: 188| Step: 0
Training loss: 2.2235093116760254
Validation loss: 2.0183169559765886

Epoch: 6| Step: 1
Training loss: 0.9529069662094116
Validation loss: 1.9811133030922181

Epoch: 6| Step: 2
Training loss: 1.4898138046264648
Validation loss: 1.9891554591476277

Epoch: 6| Step: 3
Training loss: 1.1149033308029175
Validation loss: 1.9650079460554226

Epoch: 6| Step: 4
Training loss: 2.117713451385498
Validation loss: 1.9452374532658567

Epoch: 6| Step: 5
Training loss: 1.3127989768981934
Validation loss: 1.9599644112330612

Epoch: 6| Step: 6
Training loss: 1.5379332304000854
Validation loss: 1.9344065573907667

Epoch: 6| Step: 7
Training loss: 1.3558180332183838
Validation loss: 1.9577276937423214

Epoch: 6| Step: 8
Training loss: 1.4387444257736206
Validation loss: 1.9755893804693734

Epoch: 6| Step: 9
Training loss: 1.169255256652832
Validation loss: 1.9963398338646017

Epoch: 6| Step: 10
Training loss: 1.4564988613128662
Validation loss: 2.0019414565896474

Epoch: 6| Step: 11
Training loss: 0.9055471420288086
Validation loss: 2.036520945128574

Epoch: 6| Step: 12
Training loss: 1.406134843826294
Validation loss: 2.0443463658773773

Epoch: 6| Step: 13
Training loss: 1.9859384298324585
Validation loss: 2.031466753252091

Epoch: 189| Step: 0
Training loss: 1.2815881967544556
Validation loss: 2.017819881439209

Epoch: 6| Step: 1
Training loss: 1.5190699100494385
Validation loss: 2.0152352599687475

Epoch: 6| Step: 2
Training loss: 1.0823686122894287
Validation loss: 2.0009786146943287

Epoch: 6| Step: 3
Training loss: 1.30411696434021
Validation loss: 1.990326919863301

Epoch: 6| Step: 4
Training loss: 1.1970040798187256
Validation loss: 2.00420029188997

Epoch: 6| Step: 5
Training loss: 1.1246250867843628
Validation loss: 1.993939571483161

Epoch: 6| Step: 6
Training loss: 0.8870841264724731
Validation loss: 2.0020781870811217

Epoch: 6| Step: 7
Training loss: 1.5881708860397339
Validation loss: 2.0109096214335453

Epoch: 6| Step: 8
Training loss: 1.678370475769043
Validation loss: 2.0008106718781176

Epoch: 6| Step: 9
Training loss: 1.5524609088897705
Validation loss: 2.001359740893046

Epoch: 6| Step: 10
Training loss: 1.428650140762329
Validation loss: 2.0237033379975187

Epoch: 6| Step: 11
Training loss: 1.861701488494873
Validation loss: 2.0369768424700667

Epoch: 6| Step: 12
Training loss: 1.703202486038208
Validation loss: 2.0313388878299343

Epoch: 6| Step: 13
Training loss: 1.088099479675293
Validation loss: 2.0041012225612516

Epoch: 190| Step: 0
Training loss: 0.8901023864746094
Validation loss: 2.019502055260443

Epoch: 6| Step: 1
Training loss: 2.0030007362365723
Validation loss: 2.0152372852448495

Epoch: 6| Step: 2
Training loss: 1.3590375185012817
Validation loss: 1.9968798416917042

Epoch: 6| Step: 3
Training loss: 1.170568823814392
Validation loss: 1.9823858968673214

Epoch: 6| Step: 4
Training loss: 1.163290023803711
Validation loss: 1.9883715132231354

Epoch: 6| Step: 5
Training loss: 1.5936856269836426
Validation loss: 2.0088616930028445

Epoch: 6| Step: 6
Training loss: 1.5404713153839111
Validation loss: 2.000969183060431

Epoch: 6| Step: 7
Training loss: 1.3929686546325684
Validation loss: 2.011113164245441

Epoch: 6| Step: 8
Training loss: 1.5606884956359863
Validation loss: 2.008495961466143

Epoch: 6| Step: 9
Training loss: 1.3130064010620117
Validation loss: 2.0581655912501837

Epoch: 6| Step: 10
Training loss: 1.154579997062683
Validation loss: 2.071749212921307

Epoch: 6| Step: 11
Training loss: 1.514091968536377
Validation loss: 2.098421755657401

Epoch: 6| Step: 12
Training loss: 1.2874735593795776
Validation loss: 2.1134770762535835

Epoch: 6| Step: 13
Training loss: 1.8190449476242065
Validation loss: 2.126747772257815

Epoch: 191| Step: 0
Training loss: 1.004793643951416
Validation loss: 2.1337784131368003

Epoch: 6| Step: 1
Training loss: 1.3164918422698975
Validation loss: 2.082451992137458

Epoch: 6| Step: 2
Training loss: 1.413090467453003
Validation loss: 2.067376297007325

Epoch: 6| Step: 3
Training loss: 1.042978286743164
Validation loss: 2.0436503861540105

Epoch: 6| Step: 4
Training loss: 1.4871692657470703
Validation loss: 2.0356189525255592

Epoch: 6| Step: 5
Training loss: 1.5653231143951416
Validation loss: 2.007155095377276

Epoch: 6| Step: 6
Training loss: 1.4011350870132446
Validation loss: 2.0211797183559788

Epoch: 6| Step: 7
Training loss: 1.3663768768310547
Validation loss: 1.9967831014305033

Epoch: 6| Step: 8
Training loss: 1.0612201690673828
Validation loss: 2.016561882470244

Epoch: 6| Step: 9
Training loss: 1.9462742805480957
Validation loss: 2.0034873280473935

Epoch: 6| Step: 10
Training loss: 1.3194901943206787
Validation loss: 2.0016175393135316

Epoch: 6| Step: 11
Training loss: 1.6907787322998047
Validation loss: 2.036571733413204

Epoch: 6| Step: 12
Training loss: 1.7184710502624512
Validation loss: 2.0896412595625846

Epoch: 6| Step: 13
Training loss: 1.878703236579895
Validation loss: 2.10350094174826

Epoch: 192| Step: 0
Training loss: 1.079345941543579
Validation loss: 2.095197485339257

Epoch: 6| Step: 1
Training loss: 1.784309983253479
Validation loss: 2.1072537053015923

Epoch: 6| Step: 2
Training loss: 1.7958130836486816
Validation loss: 2.0732246509162326

Epoch: 6| Step: 3
Training loss: 1.382030963897705
Validation loss: 2.0348475428037744

Epoch: 6| Step: 4
Training loss: 1.3954505920410156
Validation loss: 2.0218729998475764

Epoch: 6| Step: 5
Training loss: 0.8841608762741089
Validation loss: 1.9709546130190614

Epoch: 6| Step: 6
Training loss: 1.5408031940460205
Validation loss: 2.001664935901601

Epoch: 6| Step: 7
Training loss: 1.030306339263916
Validation loss: 1.9596595866705782

Epoch: 6| Step: 8
Training loss: 1.151277780532837
Validation loss: 1.962439726757747

Epoch: 6| Step: 9
Training loss: 1.6854815483093262
Validation loss: 1.9534740447998047

Epoch: 6| Step: 10
Training loss: 1.4023188352584839
Validation loss: 1.9564656903666835

Epoch: 6| Step: 11
Training loss: 1.8045532703399658
Validation loss: 1.9675607527455976

Epoch: 6| Step: 12
Training loss: 1.0544745922088623
Validation loss: 1.9960502962912283

Epoch: 6| Step: 13
Training loss: 1.5362154245376587
Validation loss: 2.0172616127998597

Epoch: 193| Step: 0
Training loss: 1.4926316738128662
Validation loss: 2.0164186569952194

Epoch: 6| Step: 1
Training loss: 1.290784478187561
Validation loss: 2.0221343425012406

Epoch: 6| Step: 2
Training loss: 1.7245652675628662
Validation loss: 1.993785474890022

Epoch: 6| Step: 3
Training loss: 1.206305742263794
Validation loss: 1.9773836289682696

Epoch: 6| Step: 4
Training loss: 1.1698269844055176
Validation loss: 1.9651386763459893

Epoch: 6| Step: 5
Training loss: 1.2847044467926025
Validation loss: 1.9789260818112282

Epoch: 6| Step: 6
Training loss: 1.6985646486282349
Validation loss: 1.9772531524781258

Epoch: 6| Step: 7
Training loss: 1.6879467964172363
Validation loss: 1.97836745426219

Epoch: 6| Step: 8
Training loss: 1.3600006103515625
Validation loss: 1.996039875092045

Epoch: 6| Step: 9
Training loss: 1.817126750946045
Validation loss: 1.9773837007502073

Epoch: 6| Step: 10
Training loss: 0.843024492263794
Validation loss: 1.9716364170915337

Epoch: 6| Step: 11
Training loss: 1.4213935136795044
Validation loss: 1.9740875280031593

Epoch: 6| Step: 12
Training loss: 1.319995403289795
Validation loss: 2.0392025106696674

Epoch: 6| Step: 13
Training loss: 1.341247320175171
Validation loss: 2.104845708416354

Epoch: 194| Step: 0
Training loss: 1.4262945652008057
Validation loss: 2.1124871494949504

Epoch: 6| Step: 1
Training loss: 1.7172508239746094
Validation loss: 2.098619791769212

Epoch: 6| Step: 2
Training loss: 1.4244413375854492
Validation loss: 2.0898345337119153

Epoch: 6| Step: 3
Training loss: 2.157662868499756
Validation loss: 2.0993063578041653

Epoch: 6| Step: 4
Training loss: 1.6025725603103638
Validation loss: 2.094718658795921

Epoch: 6| Step: 5
Training loss: 1.097579002380371
Validation loss: 2.0651005955152613

Epoch: 6| Step: 6
Training loss: 1.4382168054580688
Validation loss: 2.0170953978774366

Epoch: 6| Step: 7
Training loss: 1.0400047302246094
Validation loss: 2.001414429756903

Epoch: 6| Step: 8
Training loss: 1.2353851795196533
Validation loss: 1.990686257680257

Epoch: 6| Step: 9
Training loss: 0.8395671844482422
Validation loss: 1.9722159395935714

Epoch: 6| Step: 10
Training loss: 1.2943191528320312
Validation loss: 1.9893185477102957

Epoch: 6| Step: 11
Training loss: 0.9133901000022888
Validation loss: 1.9705736342296805

Epoch: 6| Step: 12
Training loss: 1.2795541286468506
Validation loss: 1.9514271264435143

Epoch: 6| Step: 13
Training loss: 2.091994047164917
Validation loss: 1.9445522741604877

Epoch: 195| Step: 0
Training loss: 1.3315939903259277
Validation loss: 1.9243925797042025

Epoch: 6| Step: 1
Training loss: 0.8022792339324951
Validation loss: 1.960956908041431

Epoch: 6| Step: 2
Training loss: 1.118978500366211
Validation loss: 1.9703745329251854

Epoch: 6| Step: 3
Training loss: 0.7200953960418701
Validation loss: 2.0167147241612917

Epoch: 6| Step: 4
Training loss: 1.6347551345825195
Validation loss: 2.0155909330614152

Epoch: 6| Step: 5
Training loss: 1.1680946350097656
Validation loss: 2.0430892129098215

Epoch: 6| Step: 6
Training loss: 1.7203471660614014
Validation loss: 2.048142949740092

Epoch: 6| Step: 7
Training loss: 1.4631152153015137
Validation loss: 2.0231532563445387

Epoch: 6| Step: 8
Training loss: 0.8921089768409729
Validation loss: 1.979039167845121

Epoch: 6| Step: 9
Training loss: 1.7738621234893799
Validation loss: 1.9901060442770682

Epoch: 6| Step: 10
Training loss: 1.6385589838027954
Validation loss: 1.9717666795176845

Epoch: 6| Step: 11
Training loss: 1.183886170387268
Validation loss: 1.9801694526467273

Epoch: 6| Step: 12
Training loss: 2.0543296337127686
Validation loss: 1.9897822257011168

Epoch: 6| Step: 13
Training loss: 1.5353102684020996
Validation loss: 2.0158925312821583

Epoch: 196| Step: 0
Training loss: 1.2283639907836914
Validation loss: 2.0113739634072907

Epoch: 6| Step: 1
Training loss: 1.6022326946258545
Validation loss: 2.0150460350898003

Epoch: 6| Step: 2
Training loss: 1.414642095565796
Validation loss: 2.003041890359694

Epoch: 6| Step: 3
Training loss: 1.0190527439117432
Validation loss: 2.0033606508726716

Epoch: 6| Step: 4
Training loss: 0.9282053112983704
Validation loss: 1.9903175907750283

Epoch: 6| Step: 5
Training loss: 1.7559893131256104
Validation loss: 1.9905643540043985

Epoch: 6| Step: 6
Training loss: 1.175959587097168
Validation loss: 1.9943743521167385

Epoch: 6| Step: 7
Training loss: 1.5717239379882812
Validation loss: 1.9905632875298942

Epoch: 6| Step: 8
Training loss: 1.1669762134552002
Validation loss: 1.9819459222978162

Epoch: 6| Step: 9
Training loss: 1.3370983600616455
Validation loss: 1.9932182822176205

Epoch: 6| Step: 10
Training loss: 1.383749008178711
Validation loss: 2.0009050523081133

Epoch: 6| Step: 11
Training loss: 1.2699453830718994
Validation loss: 1.9844123304531138

Epoch: 6| Step: 12
Training loss: 1.1018977165222168
Validation loss: 1.976110863429244

Epoch: 6| Step: 13
Training loss: 1.1470167636871338
Validation loss: 1.9938524435925227

Epoch: 197| Step: 0
Training loss: 1.418036699295044
Validation loss: 1.9896974640507852

Epoch: 6| Step: 1
Training loss: 1.7620153427124023
Validation loss: 1.9893267154693604

Epoch: 6| Step: 2
Training loss: 1.4230226278305054
Validation loss: 1.962034999683339

Epoch: 6| Step: 3
Training loss: 1.287042498588562
Validation loss: 1.9456379823787238

Epoch: 6| Step: 4
Training loss: 1.9299793243408203
Validation loss: 1.967536308432138

Epoch: 6| Step: 5
Training loss: 1.1373600959777832
Validation loss: 1.9589698340303154

Epoch: 6| Step: 6
Training loss: 1.432564616203308
Validation loss: 1.963104486465454

Epoch: 6| Step: 7
Training loss: 0.973578929901123
Validation loss: 1.9599722841734528

Epoch: 6| Step: 8
Training loss: 1.2212178707122803
Validation loss: 1.996669989760204

Epoch: 6| Step: 9
Training loss: 1.1825592517852783
Validation loss: 2.021091966218846

Epoch: 6| Step: 10
Training loss: 1.406428337097168
Validation loss: 2.0030268571710073

Epoch: 6| Step: 11
Training loss: 1.2363110780715942
Validation loss: 1.9694962527162285

Epoch: 6| Step: 12
Training loss: 0.8421027660369873
Validation loss: 1.9451177504754835

Epoch: 6| Step: 13
Training loss: 1.164015293121338
Validation loss: 1.9533964741614558

Epoch: 198| Step: 0
Training loss: 1.4162529706954956
Validation loss: 1.972618523464408

Epoch: 6| Step: 1
Training loss: 1.5590451955795288
Validation loss: 1.9628527933551418

Epoch: 6| Step: 2
Training loss: 1.2703049182891846
Validation loss: 1.987895873285109

Epoch: 6| Step: 3
Training loss: 1.2239617109298706
Validation loss: 1.9851496681090324

Epoch: 6| Step: 4
Training loss: 0.9212088584899902
Validation loss: 1.9842787224759337

Epoch: 6| Step: 5
Training loss: 1.7476842403411865
Validation loss: 2.0116020556419127

Epoch: 6| Step: 6
Training loss: 0.9889335036277771
Validation loss: 2.0188473245149017

Epoch: 6| Step: 7
Training loss: 1.3165836334228516
Validation loss: 2.039673924446106

Epoch: 6| Step: 8
Training loss: 1.5955283641815186
Validation loss: 2.0361749792611725

Epoch: 6| Step: 9
Training loss: 1.2540065050125122
Validation loss: 2.0294689491230953

Epoch: 6| Step: 10
Training loss: 1.1144548654556274
Validation loss: 2.0282213713533137

Epoch: 6| Step: 11
Training loss: 0.6349789500236511
Validation loss: 1.991145876146132

Epoch: 6| Step: 12
Training loss: 1.3605926036834717
Validation loss: 2.000081959591117

Epoch: 6| Step: 13
Training loss: 1.5519464015960693
Validation loss: 2.00318419548773

Epoch: 199| Step: 0
Training loss: 1.807903528213501
Validation loss: 1.9783279434327157

Epoch: 6| Step: 1
Training loss: 1.1974513530731201
Validation loss: 1.9529935800901024

Epoch: 6| Step: 2
Training loss: 1.5166523456573486
Validation loss: 1.9394018060417586

Epoch: 6| Step: 3
Training loss: 0.6028270721435547
Validation loss: 1.9408631478586504

Epoch: 6| Step: 4
Training loss: 0.7546702027320862
Validation loss: 1.9244857872686079

Epoch: 6| Step: 5
Training loss: 1.186448574066162
Validation loss: 1.8945212710288264

Epoch: 6| Step: 6
Training loss: 1.4400219917297363
Validation loss: 1.9085216317125546

Epoch: 6| Step: 7
Training loss: 1.2030261754989624
Validation loss: 1.9346747731649747

Epoch: 6| Step: 8
Training loss: 1.3345303535461426
Validation loss: 1.952052471458271

Epoch: 6| Step: 9
Training loss: 1.6188005208969116
Validation loss: 1.9541730150099723

Epoch: 6| Step: 10
Training loss: 0.9406193494796753
Validation loss: 1.9613928461587558

Epoch: 6| Step: 11
Training loss: 1.1757495403289795
Validation loss: 1.9938695943483742

Epoch: 6| Step: 12
Training loss: 1.572080135345459
Validation loss: 2.019617224252352

Epoch: 6| Step: 13
Training loss: 2.257587194442749
Validation loss: 2.000481036401564

Epoch: 200| Step: 0
Training loss: 1.2142053842544556
Validation loss: 1.9865269366131033

Epoch: 6| Step: 1
Training loss: 1.9526753425598145
Validation loss: 1.9687164188713155

Epoch: 6| Step: 2
Training loss: 0.8734416365623474
Validation loss: 1.976650853310862

Epoch: 6| Step: 3
Training loss: 1.739000678062439
Validation loss: 1.9768628279368083

Epoch: 6| Step: 4
Training loss: 0.9920897483825684
Validation loss: 1.9756437552872526

Epoch: 6| Step: 5
Training loss: 1.11259126663208
Validation loss: 1.9385587374369304

Epoch: 6| Step: 6
Training loss: 1.2791578769683838
Validation loss: 1.9434176875698952

Epoch: 6| Step: 7
Training loss: 1.1856722831726074
Validation loss: 1.9564575584985877

Epoch: 6| Step: 8
Training loss: 1.386164665222168
Validation loss: 1.9961409235513339

Epoch: 6| Step: 9
Training loss: 1.4042683839797974
Validation loss: 1.9644687355205577

Epoch: 6| Step: 10
Training loss: 1.9565083980560303
Validation loss: 1.9606628289786718

Epoch: 6| Step: 11
Training loss: 1.0667932033538818
Validation loss: 1.942835089980915

Epoch: 6| Step: 12
Training loss: 1.1719367504119873
Validation loss: 1.962983250617981

Epoch: 6| Step: 13
Training loss: 1.3630222082138062
Validation loss: 1.9794230871303107

Epoch: 201| Step: 0
Training loss: 0.8325533866882324
Validation loss: 1.9956743576193368

Epoch: 6| Step: 1
Training loss: 1.0871803760528564
Validation loss: 1.9853940715071976

Epoch: 6| Step: 2
Training loss: 1.1103088855743408
Validation loss: 1.9895351035620576

Epoch: 6| Step: 3
Training loss: 1.422458291053772
Validation loss: 1.995758569368752

Epoch: 6| Step: 4
Training loss: 1.7655420303344727
Validation loss: 1.9719226001411356

Epoch: 6| Step: 5
Training loss: 2.0268311500549316
Validation loss: 1.9566083108225176

Epoch: 6| Step: 6
Training loss: 1.190497636795044
Validation loss: 1.9581523377408263

Epoch: 6| Step: 7
Training loss: 1.553480863571167
Validation loss: 1.943372098348474

Epoch: 6| Step: 8
Training loss: 0.8413937091827393
Validation loss: 1.9391028560617918

Epoch: 6| Step: 9
Training loss: 1.3948328495025635
Validation loss: 1.9351325522186935

Epoch: 6| Step: 10
Training loss: 1.3636658191680908
Validation loss: 1.9392118018160585

Epoch: 6| Step: 11
Training loss: 1.1797910928726196
Validation loss: 1.9447789884382678

Epoch: 6| Step: 12
Training loss: 1.2345802783966064
Validation loss: 2.008468093410615

Epoch: 6| Step: 13
Training loss: 1.662115454673767
Validation loss: 2.046959007939985

Epoch: 202| Step: 0
Training loss: 1.1830633878707886
Validation loss: 2.0941442751115367

Epoch: 6| Step: 1
Training loss: 1.6245712041854858
Validation loss: 2.0910643018702024

Epoch: 6| Step: 2
Training loss: 0.8580528497695923
Validation loss: 2.0619180074302097

Epoch: 6| Step: 3
Training loss: 1.9346164464950562
Validation loss: 2.0538573829076623

Epoch: 6| Step: 4
Training loss: 1.1620570421218872
Validation loss: 2.0167797355241674

Epoch: 6| Step: 5
Training loss: 1.4185065031051636
Validation loss: 1.9865753266119188

Epoch: 6| Step: 6
Training loss: 0.9156050086021423
Validation loss: 1.9810561095514605

Epoch: 6| Step: 7
Training loss: 1.0943191051483154
Validation loss: 1.9796241329562279

Epoch: 6| Step: 8
Training loss: 1.282684326171875
Validation loss: 1.986618867484472

Epoch: 6| Step: 9
Training loss: 0.9732105731964111
Validation loss: 1.9882749203712708

Epoch: 6| Step: 10
Training loss: 1.9090145826339722
Validation loss: 1.9681912032506799

Epoch: 6| Step: 11
Training loss: 1.959693193435669
Validation loss: 1.9509347267048334

Epoch: 6| Step: 12
Training loss: 1.164467692375183
Validation loss: 1.9369147054610714

Epoch: 6| Step: 13
Training loss: 1.027620553970337
Validation loss: 1.9367181024243754

Epoch: 203| Step: 0
Training loss: 1.413313627243042
Validation loss: 1.9536340416118663

Epoch: 6| Step: 1
Training loss: 1.408430814743042
Validation loss: 1.9800929305373982

Epoch: 6| Step: 2
Training loss: 1.320290446281433
Validation loss: 2.0057228611361597

Epoch: 6| Step: 3
Training loss: 1.6491060256958008
Validation loss: 2.0427726968642204

Epoch: 6| Step: 4
Training loss: 1.502288579940796
Validation loss: 2.0511274491586993

Epoch: 6| Step: 5
Training loss: 0.6510306596755981
Validation loss: 2.0380292771964945

Epoch: 6| Step: 6
Training loss: 0.7783347368240356
Validation loss: 1.9998298101527716

Epoch: 6| Step: 7
Training loss: 1.0190287828445435
Validation loss: 1.9920312281577819

Epoch: 6| Step: 8
Training loss: 1.0875128507614136
Validation loss: 1.9523368471412248

Epoch: 6| Step: 9
Training loss: 1.01068913936615
Validation loss: 1.9365947605461202

Epoch: 6| Step: 10
Training loss: 1.3631694316864014
Validation loss: 1.925242071510643

Epoch: 6| Step: 11
Training loss: 1.4486141204833984
Validation loss: 1.9398633741563367

Epoch: 6| Step: 12
Training loss: 1.6479976177215576
Validation loss: 1.9837967503455378

Epoch: 6| Step: 13
Training loss: 1.7929178476333618
Validation loss: 1.9780451815615419

Epoch: 204| Step: 0
Training loss: 0.9851034879684448
Validation loss: 1.9961323712461738

Epoch: 6| Step: 1
Training loss: 1.3513187170028687
Validation loss: 1.9818728508487824

Epoch: 6| Step: 2
Training loss: 1.1173397302627563
Validation loss: 2.001728123234164

Epoch: 6| Step: 3
Training loss: 1.89078688621521
Validation loss: 2.0086981660576275

Epoch: 6| Step: 4
Training loss: 1.4089441299438477
Validation loss: 2.024458562174151

Epoch: 6| Step: 5
Training loss: 1.5870221853256226
Validation loss: 2.018643577893575

Epoch: 6| Step: 6
Training loss: 1.163395643234253
Validation loss: 2.0406298381026073

Epoch: 6| Step: 7
Training loss: 1.2274048328399658
Validation loss: 2.047756729587432

Epoch: 6| Step: 8
Training loss: 0.8006433248519897
Validation loss: 2.0427829001539495

Epoch: 6| Step: 9
Training loss: 0.9028646945953369
Validation loss: 2.024751978535806

Epoch: 6| Step: 10
Training loss: 1.2025153636932373
Validation loss: 1.9944560681619952

Epoch: 6| Step: 11
Training loss: 1.220381259918213
Validation loss: 1.9674267563768613

Epoch: 6| Step: 12
Training loss: 1.4237957000732422
Validation loss: 1.9561035991996847

Epoch: 6| Step: 13
Training loss: 1.7313131093978882
Validation loss: 1.9343261872568438

Epoch: 205| Step: 0
Training loss: 0.86211097240448
Validation loss: 1.911662104309246

Epoch: 6| Step: 1
Training loss: 1.4624216556549072
Validation loss: 1.912154705293717

Epoch: 6| Step: 2
Training loss: 1.3820489645004272
Validation loss: 1.9171764030251452

Epoch: 6| Step: 3
Training loss: 1.2248039245605469
Validation loss: 1.9319356218461068

Epoch: 6| Step: 4
Training loss: 1.2013285160064697
Validation loss: 1.9342133768143193

Epoch: 6| Step: 5
Training loss: 1.363168716430664
Validation loss: 1.942322459272159

Epoch: 6| Step: 6
Training loss: 1.1701810359954834
Validation loss: 1.9335918887968986

Epoch: 6| Step: 7
Training loss: 1.1558012962341309
Validation loss: 1.95240088816612

Epoch: 6| Step: 8
Training loss: 1.2236453294754028
Validation loss: 1.9499493247719222

Epoch: 6| Step: 9
Training loss: 1.1333181858062744
Validation loss: 1.9844651683684318

Epoch: 6| Step: 10
Training loss: 0.9734667539596558
Validation loss: 1.9710545744947208

Epoch: 6| Step: 11
Training loss: 1.4089411497116089
Validation loss: 1.996110486727889

Epoch: 6| Step: 12
Training loss: 0.8814491033554077
Validation loss: 1.9797551298654208

Epoch: 6| Step: 13
Training loss: 1.4960596561431885
Validation loss: 1.995332670468156

Epoch: 206| Step: 0
Training loss: 1.2622612714767456
Validation loss: 1.996714138215588

Epoch: 6| Step: 1
Training loss: 1.1846855878829956
Validation loss: 2.006848777494123

Epoch: 6| Step: 2
Training loss: 0.8315838575363159
Validation loss: 2.0072938524266726

Epoch: 6| Step: 3
Training loss: 0.9020113945007324
Validation loss: 2.000355170619103

Epoch: 6| Step: 4
Training loss: 1.0758907794952393
Validation loss: 1.996373543175318

Epoch: 6| Step: 5
Training loss: 1.2837729454040527
Validation loss: 2.022726712688323

Epoch: 6| Step: 6
Training loss: 1.3493247032165527
Validation loss: 2.0203852012593257

Epoch: 6| Step: 7
Training loss: 1.1208633184432983
Validation loss: 2.01041175729485

Epoch: 6| Step: 8
Training loss: 1.4606190919876099
Validation loss: 1.9768099477214198

Epoch: 6| Step: 9
Training loss: 1.2700854539871216
Validation loss: 1.959418095568175

Epoch: 6| Step: 10
Training loss: 1.1681771278381348
Validation loss: 1.931780356232838

Epoch: 6| Step: 11
Training loss: 1.3471860885620117
Validation loss: 1.9213003471333494

Epoch: 6| Step: 12
Training loss: 1.7318446636199951
Validation loss: 1.9144033411497712

Epoch: 6| Step: 13
Training loss: 0.8759456276893616
Validation loss: 1.9015324936118176

Epoch: 207| Step: 0
Training loss: 0.939647376537323
Validation loss: 1.8962529269597863

Epoch: 6| Step: 1
Training loss: 1.268289566040039
Validation loss: 1.9076332161503453

Epoch: 6| Step: 2
Training loss: 1.266271948814392
Validation loss: 1.9043027816280242

Epoch: 6| Step: 3
Training loss: 1.1104717254638672
Validation loss: 1.9348383718921291

Epoch: 6| Step: 4
Training loss: 0.9556952714920044
Validation loss: 1.9463042648889686

Epoch: 6| Step: 5
Training loss: 1.3328129053115845
Validation loss: 1.9695606616235548

Epoch: 6| Step: 6
Training loss: 1.293332815170288
Validation loss: 1.9874630974185081

Epoch: 6| Step: 7
Training loss: 1.6082441806793213
Validation loss: 1.9785923009277673

Epoch: 6| Step: 8
Training loss: 0.7534772157669067
Validation loss: 1.9677780417985813

Epoch: 6| Step: 9
Training loss: 1.083496332168579
Validation loss: 1.9913239248337284

Epoch: 6| Step: 10
Training loss: 1.2995901107788086
Validation loss: 1.9821589723710091

Epoch: 6| Step: 11
Training loss: 0.9591951370239258
Validation loss: 1.9836666353287236

Epoch: 6| Step: 12
Training loss: 1.5735357999801636
Validation loss: 1.9704329429134246

Epoch: 6| Step: 13
Training loss: 1.1900792121887207
Validation loss: 1.9717699302140104

Epoch: 208| Step: 0
Training loss: 1.1349468231201172
Validation loss: 1.9643175063594696

Epoch: 6| Step: 1
Training loss: 1.3040671348571777
Validation loss: 1.9730131562038133

Epoch: 6| Step: 2
Training loss: 1.194551944732666
Validation loss: 1.9693720443274385

Epoch: 6| Step: 3
Training loss: 0.7078949213027954
Validation loss: 1.9628312446737801

Epoch: 6| Step: 4
Training loss: 1.223595380783081
Validation loss: 1.9474412497653757

Epoch: 6| Step: 5
Training loss: 0.9627072811126709
Validation loss: 1.928771835501476

Epoch: 6| Step: 6
Training loss: 0.9567493796348572
Validation loss: 1.9189239907008346

Epoch: 6| Step: 7
Training loss: 0.9718631505966187
Validation loss: 1.9110688919662147

Epoch: 6| Step: 8
Training loss: 0.9631404876708984
Validation loss: 1.892646453713858

Epoch: 6| Step: 9
Training loss: 1.3824689388275146
Validation loss: 1.88366501562057

Epoch: 6| Step: 10
Training loss: 1.8212890625
Validation loss: 1.8751016919330885

Epoch: 6| Step: 11
Training loss: 1.1070611476898193
Validation loss: 1.8868108898080804

Epoch: 6| Step: 12
Training loss: 1.405072808265686
Validation loss: 1.9089050421150782

Epoch: 6| Step: 13
Training loss: 1.349193811416626
Validation loss: 1.9223934142820296

Epoch: 209| Step: 0
Training loss: 0.9320087432861328
Validation loss: 1.9339017970587618

Epoch: 6| Step: 1
Training loss: 1.2830572128295898
Validation loss: 1.9065680837118497

Epoch: 6| Step: 2
Training loss: 0.7931888103485107
Validation loss: 1.9266810212084042

Epoch: 6| Step: 3
Training loss: 1.6001527309417725
Validation loss: 1.9228267182586014

Epoch: 6| Step: 4
Training loss: 1.3767731189727783
Validation loss: 1.9057196058252805

Epoch: 6| Step: 5
Training loss: 0.9627156257629395
Validation loss: 1.9072862799449632

Epoch: 6| Step: 6
Training loss: 1.456876516342163
Validation loss: 1.899137217511413

Epoch: 6| Step: 7
Training loss: 1.0249643325805664
Validation loss: 1.8847823412187639

Epoch: 6| Step: 8
Training loss: 1.9444657564163208
Validation loss: 1.8982696776748986

Epoch: 6| Step: 9
Training loss: 1.2362899780273438
Validation loss: 1.8717919139451877

Epoch: 6| Step: 10
Training loss: 1.1181690692901611
Validation loss: 1.8878713025841662

Epoch: 6| Step: 11
Training loss: 1.0786291360855103
Validation loss: 1.8807925844705233

Epoch: 6| Step: 12
Training loss: 0.6966412663459778
Validation loss: 1.8871508157381447

Epoch: 6| Step: 13
Training loss: 0.579581081867218
Validation loss: 1.894096193775054

Epoch: 210| Step: 0
Training loss: 1.6321334838867188
Validation loss: 1.8902443237202142

Epoch: 6| Step: 1
Training loss: 1.3436155319213867
Validation loss: 1.9392327544509724

Epoch: 6| Step: 2
Training loss: 0.923365592956543
Validation loss: 1.9374139091019988

Epoch: 6| Step: 3
Training loss: 1.6949400901794434
Validation loss: 1.9425959215369275

Epoch: 6| Step: 4
Training loss: 0.818013072013855
Validation loss: 1.9432040529866372

Epoch: 6| Step: 5
Training loss: 1.4549037218093872
Validation loss: 1.9180884617631153

Epoch: 6| Step: 6
Training loss: 1.065060019493103
Validation loss: 1.904598295047719

Epoch: 6| Step: 7
Training loss: 0.9977050423622131
Validation loss: 1.8923753999894666

Epoch: 6| Step: 8
Training loss: 1.0157136917114258
Validation loss: 1.9124076289515342

Epoch: 6| Step: 9
Training loss: 1.1906077861785889
Validation loss: 1.887915139557213

Epoch: 6| Step: 10
Training loss: 0.7037416696548462
Validation loss: 1.9144541807072137

Epoch: 6| Step: 11
Training loss: 1.2196389436721802
Validation loss: 1.9462136953107771

Epoch: 6| Step: 12
Training loss: 0.9097813963890076
Validation loss: 1.9769366325870636

Epoch: 6| Step: 13
Training loss: 0.9888474941253662
Validation loss: 1.9847469406743203

Epoch: 211| Step: 0
Training loss: 1.0800611972808838
Validation loss: 2.019525529235922

Epoch: 6| Step: 1
Training loss: 0.819851279258728
Validation loss: 2.0135697728844097

Epoch: 6| Step: 2
Training loss: 1.0914252996444702
Validation loss: 1.9764403104782104

Epoch: 6| Step: 3
Training loss: 1.4135124683380127
Validation loss: 1.9851037686870945

Epoch: 6| Step: 4
Training loss: 0.6897853016853333
Validation loss: 1.959049428662946

Epoch: 6| Step: 5
Training loss: 1.3036484718322754
Validation loss: 1.9639628420593918

Epoch: 6| Step: 6
Training loss: 1.1853318214416504
Validation loss: 1.95365571975708

Epoch: 6| Step: 7
Training loss: 0.9706108570098877
Validation loss: 1.9688371650634273

Epoch: 6| Step: 8
Training loss: 0.9447857141494751
Validation loss: 1.9815895403585126

Epoch: 6| Step: 9
Training loss: 1.111151933670044
Validation loss: 2.005378956435829

Epoch: 6| Step: 10
Training loss: 1.2157928943634033
Validation loss: 2.03042096220037

Epoch: 6| Step: 11
Training loss: 1.59788179397583
Validation loss: 1.9922255175088042

Epoch: 6| Step: 12
Training loss: 1.1013970375061035
Validation loss: 1.9842872158173592

Epoch: 6| Step: 13
Training loss: 1.9524781703948975
Validation loss: 1.9300024329975087

Epoch: 212| Step: 0
Training loss: 1.021071434020996
Validation loss: 1.9088146455826298

Epoch: 6| Step: 1
Training loss: 0.7096595764160156
Validation loss: 1.8928040548037457

Epoch: 6| Step: 2
Training loss: 1.0988712310791016
Validation loss: 1.9183133366287395

Epoch: 6| Step: 3
Training loss: 1.1135847568511963
Validation loss: 1.8980421866140058

Epoch: 6| Step: 4
Training loss: 0.8970047235488892
Validation loss: 1.9187161486635926

Epoch: 6| Step: 5
Training loss: 1.3918769359588623
Validation loss: 1.9355486157119914

Epoch: 6| Step: 6
Training loss: 1.4930059909820557
Validation loss: 1.9494902523615028

Epoch: 6| Step: 7
Training loss: 1.377417802810669
Validation loss: 1.9259714182987009

Epoch: 6| Step: 8
Training loss: 1.0571035146713257
Validation loss: 1.9459940464265886

Epoch: 6| Step: 9
Training loss: 0.6404130458831787
Validation loss: 1.966961351774072

Epoch: 6| Step: 10
Training loss: 1.3720450401306152
Validation loss: 1.9939999926474787

Epoch: 6| Step: 11
Training loss: 1.3444451093673706
Validation loss: 1.9789781019251833

Epoch: 6| Step: 12
Training loss: 1.149131417274475
Validation loss: 1.957775305676204

Epoch: 6| Step: 13
Training loss: 1.1021959781646729
Validation loss: 1.9455796980088758

Epoch: 213| Step: 0
Training loss: 0.704662561416626
Validation loss: 1.9830836429390857

Epoch: 6| Step: 1
Training loss: 0.9158995151519775
Validation loss: 1.9596872188711678

Epoch: 6| Step: 2
Training loss: 1.7671535015106201
Validation loss: 1.9548809195077548

Epoch: 6| Step: 3
Training loss: 0.7769002318382263
Validation loss: 1.9438842035108996

Epoch: 6| Step: 4
Training loss: 0.7243570685386658
Validation loss: 1.95556386440031

Epoch: 6| Step: 5
Training loss: 1.120348572731018
Validation loss: 1.9360794572420017

Epoch: 6| Step: 6
Training loss: 1.092416524887085
Validation loss: 1.9434981999858734

Epoch: 6| Step: 7
Training loss: 1.130408763885498
Validation loss: 1.9446581999460857

Epoch: 6| Step: 8
Training loss: 1.6208398342132568
Validation loss: 1.9474742310021513

Epoch: 6| Step: 9
Training loss: 1.3170642852783203
Validation loss: 1.9574956573465818

Epoch: 6| Step: 10
Training loss: 0.8757339119911194
Validation loss: 1.9454004021101101

Epoch: 6| Step: 11
Training loss: 1.4472050666809082
Validation loss: 1.9417921561066822

Epoch: 6| Step: 12
Training loss: 0.8489243388175964
Validation loss: 1.9409535110637706

Epoch: 6| Step: 13
Training loss: 1.1308043003082275
Validation loss: 1.9267629769540602

Epoch: 214| Step: 0
Training loss: 1.2125968933105469
Validation loss: 1.8869800823991016

Epoch: 6| Step: 1
Training loss: 0.7423818111419678
Validation loss: 1.9108544011269846

Epoch: 6| Step: 2
Training loss: 0.8899029493331909
Validation loss: 1.8955740287739744

Epoch: 6| Step: 3
Training loss: 1.5007786750793457
Validation loss: 1.9110547586153912

Epoch: 6| Step: 4
Training loss: 1.3408782482147217
Validation loss: 1.8867874953054613

Epoch: 6| Step: 5
Training loss: 0.9171873331069946
Validation loss: 1.8836621289612145

Epoch: 6| Step: 6
Training loss: 1.067611813545227
Validation loss: 1.9085918357295375

Epoch: 6| Step: 7
Training loss: 1.0674777030944824
Validation loss: 1.9331273648046678

Epoch: 6| Step: 8
Training loss: 0.6274464130401611
Validation loss: 1.9334110829137987

Epoch: 6| Step: 9
Training loss: 0.7717063426971436
Validation loss: 1.9585339253948582

Epoch: 6| Step: 10
Training loss: 0.98383629322052
Validation loss: 1.967031273790585

Epoch: 6| Step: 11
Training loss: 1.4166948795318604
Validation loss: 1.98917709114731

Epoch: 6| Step: 12
Training loss: 1.4023847579956055
Validation loss: 1.9797138398693455

Epoch: 6| Step: 13
Training loss: 1.5062695741653442
Validation loss: 1.9819348717248568

Epoch: 215| Step: 0
Training loss: 1.1580510139465332
Validation loss: 2.006407699277324

Epoch: 6| Step: 1
Training loss: 0.4740404486656189
Validation loss: 1.9925412003711989

Epoch: 6| Step: 2
Training loss: 1.3461980819702148
Validation loss: 1.965961520389844

Epoch: 6| Step: 3
Training loss: 1.4559953212738037
Validation loss: 1.9561165430212533

Epoch: 6| Step: 4
Training loss: 0.9908591508865356
Validation loss: 1.9558114133855349

Epoch: 6| Step: 5
Training loss: 1.2318699359893799
Validation loss: 1.9769337997641614

Epoch: 6| Step: 6
Training loss: 1.2722184658050537
Validation loss: 1.959097009833141

Epoch: 6| Step: 7
Training loss: 0.7841930389404297
Validation loss: 1.9651295395307644

Epoch: 6| Step: 8
Training loss: 1.3022676706314087
Validation loss: 1.9739565759576776

Epoch: 6| Step: 9
Training loss: 0.8805913925170898
Validation loss: 1.963320339879682

Epoch: 6| Step: 10
Training loss: 1.46486496925354
Validation loss: 1.92178637237959

Epoch: 6| Step: 11
Training loss: 0.8008478879928589
Validation loss: 1.9001601306341027

Epoch: 6| Step: 12
Training loss: 1.2462573051452637
Validation loss: 1.8986256353316768

Epoch: 6| Step: 13
Training loss: 1.007875680923462
Validation loss: 1.9069349778595792

Epoch: 216| Step: 0
Training loss: 1.1270134449005127
Validation loss: 1.8719252976038123

Epoch: 6| Step: 1
Training loss: 1.1685110330581665
Validation loss: 1.8669244807253602

Epoch: 6| Step: 2
Training loss: 1.1186857223510742
Validation loss: 1.8746729743096135

Epoch: 6| Step: 3
Training loss: 1.1258537769317627
Validation loss: 1.8704689266861125

Epoch: 6| Step: 4
Training loss: 0.8204147815704346
Validation loss: 1.8873389113333918

Epoch: 6| Step: 5
Training loss: 1.1215901374816895
Validation loss: 1.9311881475551154

Epoch: 6| Step: 6
Training loss: 1.1887810230255127
Validation loss: 1.9294786478883477

Epoch: 6| Step: 7
Training loss: 1.172135829925537
Validation loss: 1.9866520538124988

Epoch: 6| Step: 8
Training loss: 1.1879792213439941
Validation loss: 2.0227881528997935

Epoch: 6| Step: 9
Training loss: 1.2735002040863037
Validation loss: 2.0318580929951002

Epoch: 6| Step: 10
Training loss: 1.4729117155075073
Validation loss: 2.034377936393984

Epoch: 6| Step: 11
Training loss: 0.7695982456207275
Validation loss: 1.9817493577157297

Epoch: 6| Step: 12
Training loss: 1.286759376525879
Validation loss: 1.9543088674545288

Epoch: 6| Step: 13
Training loss: 0.7077412605285645
Validation loss: 1.947924688298215

Epoch: 217| Step: 0
Training loss: 0.9269135594367981
Validation loss: 1.9488864624372093

Epoch: 6| Step: 1
Training loss: 1.237356185913086
Validation loss: 1.9392070026807888

Epoch: 6| Step: 2
Training loss: 1.0916110277175903
Validation loss: 1.9330853980074647

Epoch: 6| Step: 3
Training loss: 0.5991223454475403
Validation loss: 1.9433416743432321

Epoch: 6| Step: 4
Training loss: 1.0123196840286255
Validation loss: 1.9538350515468146

Epoch: 6| Step: 5
Training loss: 1.1331021785736084
Validation loss: 1.9712232812758415

Epoch: 6| Step: 6
Training loss: 1.4386975765228271
Validation loss: 1.9835499307160736

Epoch: 6| Step: 7
Training loss: 1.2009689807891846
Validation loss: 1.998123336863774

Epoch: 6| Step: 8
Training loss: 1.176200032234192
Validation loss: 1.9826575684291061

Epoch: 6| Step: 9
Training loss: 1.0681228637695312
Validation loss: 1.9798305573001984

Epoch: 6| Step: 10
Training loss: 0.8114916682243347
Validation loss: 1.9610021345077022

Epoch: 6| Step: 11
Training loss: 1.2528949975967407
Validation loss: 1.9660592258617442

Epoch: 6| Step: 12
Training loss: 1.1908223628997803
Validation loss: 1.9361841934983448

Epoch: 6| Step: 13
Training loss: 1.1926615238189697
Validation loss: 1.9319255428929483

Epoch: 218| Step: 0
Training loss: 1.0571858882904053
Validation loss: 1.9151336736576532

Epoch: 6| Step: 1
Training loss: 1.4049150943756104
Validation loss: 1.9205159294989802

Epoch: 6| Step: 2
Training loss: 1.1651315689086914
Validation loss: 1.9460063672834826

Epoch: 6| Step: 3
Training loss: 0.6662966012954712
Validation loss: 1.921543034174109

Epoch: 6| Step: 4
Training loss: 1.0974384546279907
Validation loss: 1.96295944593286

Epoch: 6| Step: 5
Training loss: 1.1055471897125244
Validation loss: 1.9694830858579246

Epoch: 6| Step: 6
Training loss: 1.5522727966308594
Validation loss: 1.986745479286358

Epoch: 6| Step: 7
Training loss: 1.2018132209777832
Validation loss: 2.0072021676648046

Epoch: 6| Step: 8
Training loss: 0.622567892074585
Validation loss: 2.006642537732278

Epoch: 6| Step: 9
Training loss: 1.1912353038787842
Validation loss: 2.019696856057772

Epoch: 6| Step: 10
Training loss: 0.8831727504730225
Validation loss: 2.0092302855624946

Epoch: 6| Step: 11
Training loss: 1.050582766532898
Validation loss: 2.0099333140157882

Epoch: 6| Step: 12
Training loss: 1.2567707300186157
Validation loss: 1.9969216636432114

Epoch: 6| Step: 13
Training loss: 0.8144909739494324
Validation loss: 1.9709643484443746

Epoch: 219| Step: 0
Training loss: 1.1535520553588867
Validation loss: 1.980467406652307

Epoch: 6| Step: 1
Training loss: 0.9747503399848938
Validation loss: 1.9581649534163936

Epoch: 6| Step: 2
Training loss: 1.180227279663086
Validation loss: 1.951611436823363

Epoch: 6| Step: 3
Training loss: 1.3053126335144043
Validation loss: 1.917026447993453

Epoch: 6| Step: 4
Training loss: 1.2254784107208252
Validation loss: 1.8976746797561646

Epoch: 6| Step: 5
Training loss: 1.3757964372634888
Validation loss: 1.9053996814194547

Epoch: 6| Step: 6
Training loss: 1.1752305030822754
Validation loss: 1.9194376417385635

Epoch: 6| Step: 7
Training loss: 1.2329716682434082
Validation loss: 1.9282486669478878

Epoch: 6| Step: 8
Training loss: 0.976445198059082
Validation loss: 1.9814948753644062

Epoch: 6| Step: 9
Training loss: 1.361596703529358
Validation loss: 1.9847064018249512

Epoch: 6| Step: 10
Training loss: 0.8193470239639282
Validation loss: 1.9901115561044345

Epoch: 6| Step: 11
Training loss: 0.6649817228317261
Validation loss: 1.9712159902818742

Epoch: 6| Step: 12
Training loss: 0.6575204133987427
Validation loss: 1.9493613050829979

Epoch: 6| Step: 13
Training loss: 1.2328286170959473
Validation loss: 1.919422145812742

Epoch: 220| Step: 0
Training loss: 1.4513195753097534
Validation loss: 1.9294475458001579

Epoch: 6| Step: 1
Training loss: 1.1122615337371826
Validation loss: 1.926175308483903

Epoch: 6| Step: 2
Training loss: 1.343999981880188
Validation loss: 1.925862350771504

Epoch: 6| Step: 3
Training loss: 0.37466031312942505
Validation loss: 1.9296012001652871

Epoch: 6| Step: 4
Training loss: 0.8559684157371521
Validation loss: 1.9298694877214329

Epoch: 6| Step: 5
Training loss: 0.8713394999504089
Validation loss: 1.9785471077888244

Epoch: 6| Step: 6
Training loss: 0.951003909111023
Validation loss: 1.9999934575890983

Epoch: 6| Step: 7
Training loss: 1.037672519683838
Validation loss: 1.9976124096942205

Epoch: 6| Step: 8
Training loss: 1.2544690370559692
Validation loss: 1.9963958750488937

Epoch: 6| Step: 9
Training loss: 1.8995661735534668
Validation loss: 1.9866952421844646

Epoch: 6| Step: 10
Training loss: 0.739493191242218
Validation loss: 1.9627295642770746

Epoch: 6| Step: 11
Training loss: 0.9855608940124512
Validation loss: 1.9438707943885558

Epoch: 6| Step: 12
Training loss: 1.0382070541381836
Validation loss: 1.9403955564703992

Epoch: 6| Step: 13
Training loss: 0.5199804306030273
Validation loss: 1.9487569473123039

Epoch: 221| Step: 0
Training loss: 1.1939210891723633
Validation loss: 1.931042399457706

Epoch: 6| Step: 1
Training loss: 1.0629812479019165
Validation loss: 1.9300562950872606

Epoch: 6| Step: 2
Training loss: 1.4931124448776245
Validation loss: 1.929762767207238

Epoch: 6| Step: 3
Training loss: 0.7864834070205688
Validation loss: 1.925908975703742

Epoch: 6| Step: 4
Training loss: 1.333226203918457
Validation loss: 1.9425313677839053

Epoch: 6| Step: 5
Training loss: 1.2345657348632812
Validation loss: 1.9402742180773007

Epoch: 6| Step: 6
Training loss: 1.0399256944656372
Validation loss: 1.9548748193248626

Epoch: 6| Step: 7
Training loss: 1.2442649602890015
Validation loss: 1.964865707582043

Epoch: 6| Step: 8
Training loss: 0.8283286690711975
Validation loss: 1.925691254677311

Epoch: 6| Step: 9
Training loss: 1.0665555000305176
Validation loss: 1.9053533487422492

Epoch: 6| Step: 10
Training loss: 0.6356816291809082
Validation loss: 1.9134683070644256

Epoch: 6| Step: 11
Training loss: 0.8563622236251831
Validation loss: 1.9183835316729803

Epoch: 6| Step: 12
Training loss: 0.8039513826370239
Validation loss: 1.9129804821424587

Epoch: 6| Step: 13
Training loss: 0.9729532599449158
Validation loss: 1.9078167894835114

Epoch: 222| Step: 0
Training loss: 0.9865898489952087
Validation loss: 1.9660890025477256

Epoch: 6| Step: 1
Training loss: 1.1310756206512451
Validation loss: 1.9790804411775322

Epoch: 6| Step: 2
Training loss: 1.0819185972213745
Validation loss: 1.977390484143329

Epoch: 6| Step: 3
Training loss: 0.9977891445159912
Validation loss: 1.9840155359237426

Epoch: 6| Step: 4
Training loss: 0.9701904058456421
Validation loss: 1.9651034211599698

Epoch: 6| Step: 5
Training loss: 1.273139476776123
Validation loss: 1.9632329479340584

Epoch: 6| Step: 6
Training loss: 1.0817406177520752
Validation loss: 1.9501239279265046

Epoch: 6| Step: 7
Training loss: 0.5870246291160583
Validation loss: 1.9408513474208053

Epoch: 6| Step: 8
Training loss: 1.7208837270736694
Validation loss: 1.8939149943731164

Epoch: 6| Step: 9
Training loss: 1.5940678119659424
Validation loss: 1.9021941333688714

Epoch: 6| Step: 10
Training loss: 0.519765317440033
Validation loss: 1.9169319932178785

Epoch: 6| Step: 11
Training loss: 0.9888569712638855
Validation loss: 1.9518590383632208

Epoch: 6| Step: 12
Training loss: 0.7147232294082642
Validation loss: 1.9724872907002766

Epoch: 6| Step: 13
Training loss: 1.2758288383483887
Validation loss: 1.9777372896030385

Epoch: 223| Step: 0
Training loss: 1.0135252475738525
Validation loss: 1.9449367138647264

Epoch: 6| Step: 1
Training loss: 1.3577923774719238
Validation loss: 1.9440653811218918

Epoch: 6| Step: 2
Training loss: 0.8632563948631287
Validation loss: 1.9146817576500677

Epoch: 6| Step: 3
Training loss: 0.9912437200546265
Validation loss: 1.9052166323507986

Epoch: 6| Step: 4
Training loss: 1.1188092231750488
Validation loss: 1.9195761078147477

Epoch: 6| Step: 5
Training loss: 1.0510194301605225
Validation loss: 1.9136767771936232

Epoch: 6| Step: 6
Training loss: 1.1523241996765137
Validation loss: 1.9561534876464515

Epoch: 6| Step: 7
Training loss: 0.7674745917320251
Validation loss: 1.9493433378076042

Epoch: 6| Step: 8
Training loss: 0.902996301651001
Validation loss: 1.9452971117470854

Epoch: 6| Step: 9
Training loss: 1.320873737335205
Validation loss: 1.980963107078306

Epoch: 6| Step: 10
Training loss: 1.1695990562438965
Validation loss: 1.967022563821526

Epoch: 6| Step: 11
Training loss: 1.0874425172805786
Validation loss: 2.006422130010461

Epoch: 6| Step: 12
Training loss: 0.9237087965011597
Validation loss: 1.9881409188752532

Epoch: 6| Step: 13
Training loss: 1.2011208534240723
Validation loss: 2.0185906246144283

Epoch: 224| Step: 0
Training loss: 1.0527455806732178
Validation loss: 2.005666329014686

Epoch: 6| Step: 1
Training loss: 1.1367267370224
Validation loss: 1.9900028295414423

Epoch: 6| Step: 2
Training loss: 0.7289813160896301
Validation loss: 1.9723832914906163

Epoch: 6| Step: 3
Training loss: 0.8226972818374634
Validation loss: 1.964731639431369

Epoch: 6| Step: 4
Training loss: 0.9320762157440186
Validation loss: 1.956506508652882

Epoch: 6| Step: 5
Training loss: 0.6206347942352295
Validation loss: 1.9541061257803312

Epoch: 6| Step: 6
Training loss: 1.320087194442749
Validation loss: 1.9547383631429365

Epoch: 6| Step: 7
Training loss: 0.8276026248931885
Validation loss: 1.995265168528403

Epoch: 6| Step: 8
Training loss: 1.6198843717575073
Validation loss: 1.9812790604047879

Epoch: 6| Step: 9
Training loss: 0.8120642900466919
Validation loss: 1.9577794626194944

Epoch: 6| Step: 10
Training loss: 0.9107675552368164
Validation loss: 1.9211671608750538

Epoch: 6| Step: 11
Training loss: 1.1296648979187012
Validation loss: 1.8801577501399542

Epoch: 6| Step: 12
Training loss: 1.2494091987609863
Validation loss: 1.8884656147290302

Epoch: 6| Step: 13
Training loss: 0.9207560420036316
Validation loss: 1.8727887304880286

Epoch: 225| Step: 0
Training loss: 0.5218608379364014
Validation loss: 1.8507058594816475

Epoch: 6| Step: 1
Training loss: 1.040273666381836
Validation loss: 1.8718126845616165

Epoch: 6| Step: 2
Training loss: 1.1054067611694336
Validation loss: 1.8863699795097433

Epoch: 6| Step: 3
Training loss: 1.3828494548797607
Validation loss: 1.8981534614357898

Epoch: 6| Step: 4
Training loss: 0.4037139415740967
Validation loss: 1.9189640937312957

Epoch: 6| Step: 5
Training loss: 1.3182477951049805
Validation loss: 1.9232377570162538

Epoch: 6| Step: 6
Training loss: 0.7468308210372925
Validation loss: 1.9658577749806065

Epoch: 6| Step: 7
Training loss: 0.7810273766517639
Validation loss: 1.9605852403948385

Epoch: 6| Step: 8
Training loss: 1.3378517627716064
Validation loss: 1.9926244135825866

Epoch: 6| Step: 9
Training loss: 0.7144277691841125
Validation loss: 1.9366316231348182

Epoch: 6| Step: 10
Training loss: 1.159841537475586
Validation loss: 1.9093161616274106

Epoch: 6| Step: 11
Training loss: 1.0324879884719849
Validation loss: 1.8872082464156612

Epoch: 6| Step: 12
Training loss: 1.4124045372009277
Validation loss: 1.9006065732689315

Epoch: 6| Step: 13
Training loss: 1.5400251150131226
Validation loss: 1.8980301605757846

Epoch: 226| Step: 0
Training loss: 0.6810028553009033
Validation loss: 1.9183323896059425

Epoch: 6| Step: 1
Training loss: 0.9141309857368469
Validation loss: 1.9313711979055916

Epoch: 6| Step: 2
Training loss: 1.1438636779785156
Validation loss: 1.9295495825429116

Epoch: 6| Step: 3
Training loss: 0.9956375360488892
Validation loss: 1.9301488399505615

Epoch: 6| Step: 4
Training loss: 0.6102360486984253
Validation loss: 1.9478774891104749

Epoch: 6| Step: 5
Training loss: 0.7921661734580994
Validation loss: 1.9530369991897254

Epoch: 6| Step: 6
Training loss: 1.368140459060669
Validation loss: 1.932492547137763

Epoch: 6| Step: 7
Training loss: 1.0754907131195068
Validation loss: 1.9127123073865009

Epoch: 6| Step: 8
Training loss: 1.0687075853347778
Validation loss: 1.8980205956325735

Epoch: 6| Step: 9
Training loss: 1.1777513027191162
Validation loss: 1.8896171662115282

Epoch: 6| Step: 10
Training loss: 1.24679696559906
Validation loss: 1.8601876163995394

Epoch: 6| Step: 11
Training loss: 0.9054124355316162
Validation loss: 1.8757151352461947

Epoch: 6| Step: 12
Training loss: 1.4305498600006104
Validation loss: 1.8863008355581632

Epoch: 6| Step: 13
Training loss: 1.048022747039795
Validation loss: 1.8854154079191145

Epoch: 227| Step: 0
Training loss: 0.6602317094802856
Validation loss: 1.9055529294475433

Epoch: 6| Step: 1
Training loss: 1.2840054035186768
Validation loss: 1.9203271109570739

Epoch: 6| Step: 2
Training loss: 1.1934162378311157
Validation loss: 1.944517804730323

Epoch: 6| Step: 3
Training loss: 1.391746997833252
Validation loss: 1.9139186131056918

Epoch: 6| Step: 4
Training loss: 0.9863796830177307
Validation loss: 1.925259251748362

Epoch: 6| Step: 5
Training loss: 0.8755033612251282
Validation loss: 1.9402280930549867

Epoch: 6| Step: 6
Training loss: 1.2049696445465088
Validation loss: 1.9233560075042069

Epoch: 6| Step: 7
Training loss: 0.62740159034729
Validation loss: 1.9411406222210135

Epoch: 6| Step: 8
Training loss: 0.4615572392940521
Validation loss: 1.9383862749222787

Epoch: 6| Step: 9
Training loss: 1.0628679990768433
Validation loss: 1.9561807538873406

Epoch: 6| Step: 10
Training loss: 1.4171565771102905
Validation loss: 1.9380750604855117

Epoch: 6| Step: 11
Training loss: 0.8873621821403503
Validation loss: 1.9323085405493294

Epoch: 6| Step: 12
Training loss: 0.7372555732727051
Validation loss: 1.900615515247468

Epoch: 6| Step: 13
Training loss: 0.6605980396270752
Validation loss: 1.9208159831262404

Epoch: 228| Step: 0
Training loss: 0.9732920527458191
Validation loss: 1.8840893596731207

Epoch: 6| Step: 1
Training loss: 1.258812665939331
Validation loss: 1.9043828082341019

Epoch: 6| Step: 2
Training loss: 0.9853770732879639
Validation loss: 1.8989039262135823

Epoch: 6| Step: 3
Training loss: 0.7693879008293152
Validation loss: 1.904284228560745

Epoch: 6| Step: 4
Training loss: 1.1535987854003906
Validation loss: 1.9078744201249973

Epoch: 6| Step: 5
Training loss: 1.0181446075439453
Validation loss: 1.894367620509158

Epoch: 6| Step: 6
Training loss: 1.1228915452957153
Validation loss: 1.8820785912134315

Epoch: 6| Step: 7
Training loss: 0.9747013449668884
Validation loss: 1.8791819259684572

Epoch: 6| Step: 8
Training loss: 0.610377311706543
Validation loss: 1.8580564850120134

Epoch: 6| Step: 9
Training loss: 0.5176676511764526
Validation loss: 1.826742519614517

Epoch: 6| Step: 10
Training loss: 1.5187761783599854
Validation loss: 1.8622214947977374

Epoch: 6| Step: 11
Training loss: 0.9556911587715149
Validation loss: 1.8517225903849448

Epoch: 6| Step: 12
Training loss: 1.0706827640533447
Validation loss: 1.869811027280746

Epoch: 6| Step: 13
Training loss: 1.0827233791351318
Validation loss: 1.8936199193359704

Epoch: 229| Step: 0
Training loss: 0.7161643505096436
Validation loss: 1.9410096163390784

Epoch: 6| Step: 1
Training loss: 1.0095967054367065
Validation loss: 1.9460623597586026

Epoch: 6| Step: 2
Training loss: 1.0283119678497314
Validation loss: 1.9950167620053856

Epoch: 6| Step: 3
Training loss: 1.2198978662490845
Validation loss: 2.0107932116395686

Epoch: 6| Step: 4
Training loss: 0.8734697103500366
Validation loss: 2.0135895103536625

Epoch: 6| Step: 5
Training loss: 0.8026528358459473
Validation loss: 1.9628619519613122

Epoch: 6| Step: 6
Training loss: 0.7182348370552063
Validation loss: 1.922050114600889

Epoch: 6| Step: 7
Training loss: 1.3496172428131104
Validation loss: 1.924767933866029

Epoch: 6| Step: 8
Training loss: 0.7708795070648193
Validation loss: 1.9186839160098825

Epoch: 6| Step: 9
Training loss: 1.0619608163833618
Validation loss: 1.9133631849801669

Epoch: 6| Step: 10
Training loss: 1.3396401405334473
Validation loss: 1.9104794840658865

Epoch: 6| Step: 11
Training loss: 1.4578094482421875
Validation loss: 1.8868971383699806

Epoch: 6| Step: 12
Training loss: 0.8473750948905945
Validation loss: 1.8715492653590378

Epoch: 6| Step: 13
Training loss: 0.7482694387435913
Validation loss: 1.8771913743788196

Epoch: 230| Step: 0
Training loss: 0.9540730714797974
Validation loss: 1.8862591046158985

Epoch: 6| Step: 1
Training loss: 1.1956040859222412
Validation loss: 1.8865237569296232

Epoch: 6| Step: 2
Training loss: 0.6640299558639526
Validation loss: 1.86540380472778

Epoch: 6| Step: 3
Training loss: 0.7808287143707275
Validation loss: 1.901758401624618

Epoch: 6| Step: 4
Training loss: 1.0420589447021484
Validation loss: 1.9207814739596458

Epoch: 6| Step: 5
Training loss: 0.8309271335601807
Validation loss: 1.91939728747132

Epoch: 6| Step: 6
Training loss: 0.7335857152938843
Validation loss: 1.9334276389050227

Epoch: 6| Step: 7
Training loss: 0.8927345275878906
Validation loss: 1.9292736297012658

Epoch: 6| Step: 8
Training loss: 0.690326988697052
Validation loss: 1.9608416582948418

Epoch: 6| Step: 9
Training loss: 1.391761302947998
Validation loss: 1.9834812892380582

Epoch: 6| Step: 10
Training loss: 1.0276436805725098
Validation loss: 1.9633823287102483

Epoch: 6| Step: 11
Training loss: 1.2324540615081787
Validation loss: 1.918337275904994

Epoch: 6| Step: 12
Training loss: 1.121410846710205
Validation loss: 1.8978856955805132

Epoch: 6| Step: 13
Training loss: 0.7294924259185791
Validation loss: 1.904306834743869

Epoch: 231| Step: 0
Training loss: 1.2010371685028076
Validation loss: 1.879231720842341

Epoch: 6| Step: 1
Training loss: 0.9611040353775024
Validation loss: 1.8710820662078036

Epoch: 6| Step: 2
Training loss: 0.7202423810958862
Validation loss: 1.8558458910193494

Epoch: 6| Step: 3
Training loss: 0.9913140535354614
Validation loss: 1.8591629151375062

Epoch: 6| Step: 4
Training loss: 0.6040148735046387
Validation loss: 1.8492822083093787

Epoch: 6| Step: 5
Training loss: 1.36669921875
Validation loss: 1.8807423076322

Epoch: 6| Step: 6
Training loss: 0.795385479927063
Validation loss: 1.888446218223982

Epoch: 6| Step: 7
Training loss: 0.7463834285736084
Validation loss: 1.8974037772865706

Epoch: 6| Step: 8
Training loss: 1.1964406967163086
Validation loss: 1.9081870509732155

Epoch: 6| Step: 9
Training loss: 1.483248233795166
Validation loss: 1.9276250177814114

Epoch: 6| Step: 10
Training loss: 1.026611328125
Validation loss: 1.9188288565604918

Epoch: 6| Step: 11
Training loss: 0.6336401104927063
Validation loss: 1.9247519636666903

Epoch: 6| Step: 12
Training loss: 1.1251022815704346
Validation loss: 1.9216052357868483

Epoch: 6| Step: 13
Training loss: 0.9395329356193542
Validation loss: 1.9050937160368888

Epoch: 232| Step: 0
Training loss: 1.0277185440063477
Validation loss: 1.8809527479192263

Epoch: 6| Step: 1
Training loss: 1.1801508665084839
Validation loss: 1.8974810877153951

Epoch: 6| Step: 2
Training loss: 1.2060718536376953
Validation loss: 1.8781308051078551

Epoch: 6| Step: 3
Training loss: 1.014678716659546
Validation loss: 1.875858332521172

Epoch: 6| Step: 4
Training loss: 0.9069477319717407
Validation loss: 1.8863179465775848

Epoch: 6| Step: 5
Training loss: 0.5963259935379028
Validation loss: 1.8708001823835476

Epoch: 6| Step: 6
Training loss: 0.5658166408538818
Validation loss: 1.8740885334630166

Epoch: 6| Step: 7
Training loss: 1.0866084098815918
Validation loss: 1.8730384585677937

Epoch: 6| Step: 8
Training loss: 1.0392667055130005
Validation loss: 1.9004366115857196

Epoch: 6| Step: 9
Training loss: 0.8945808410644531
Validation loss: 1.9075211799272926

Epoch: 6| Step: 10
Training loss: 0.8278818726539612
Validation loss: 1.9004724820454915

Epoch: 6| Step: 11
Training loss: 0.802047610282898
Validation loss: 1.9334309101104736

Epoch: 6| Step: 12
Training loss: 0.9910073280334473
Validation loss: 1.9402823499453965

Epoch: 6| Step: 13
Training loss: 1.2257821559906006
Validation loss: 1.9171386777713735

Epoch: 233| Step: 0
Training loss: 1.0703905820846558
Validation loss: 1.8959507032107281

Epoch: 6| Step: 1
Training loss: 0.4812313914299011
Validation loss: 1.9471776972534836

Epoch: 6| Step: 2
Training loss: 1.0207715034484863
Validation loss: 1.9452616860789638

Epoch: 6| Step: 3
Training loss: 1.082461953163147
Validation loss: 1.9350806308049027

Epoch: 6| Step: 4
Training loss: 1.0220980644226074
Validation loss: 1.941777208799957

Epoch: 6| Step: 5
Training loss: 0.5739672183990479
Validation loss: 1.9145064046305995

Epoch: 6| Step: 6
Training loss: 1.1206977367401123
Validation loss: 1.9051806490908387

Epoch: 6| Step: 7
Training loss: 0.3784169554710388
Validation loss: 1.8929926221088698

Epoch: 6| Step: 8
Training loss: 1.1413203477859497
Validation loss: 1.8859300639039727

Epoch: 6| Step: 9
Training loss: 0.8140074014663696
Validation loss: 1.8844341001202982

Epoch: 6| Step: 10
Training loss: 1.3207755088806152
Validation loss: 1.8939793366257862

Epoch: 6| Step: 11
Training loss: 1.2504520416259766
Validation loss: 1.8919394484130285

Epoch: 6| Step: 12
Training loss: 0.7015573382377625
Validation loss: 1.8730306766366447

Epoch: 6| Step: 13
Training loss: 0.9388957619667053
Validation loss: 1.8847683988591677

Epoch: 234| Step: 0
Training loss: 1.0402650833129883
Validation loss: 1.8924089067725725

Epoch: 6| Step: 1
Training loss: 0.8879413604736328
Validation loss: 1.9063991487667125

Epoch: 6| Step: 2
Training loss: 1.0033434629440308
Validation loss: 1.903143455905299

Epoch: 6| Step: 3
Training loss: 1.0593856573104858
Validation loss: 1.8967330507052842

Epoch: 6| Step: 4
Training loss: 1.0742460489273071
Validation loss: 1.8622573062937746

Epoch: 6| Step: 5
Training loss: 0.8841444253921509
Validation loss: 1.8555902922025291

Epoch: 6| Step: 6
Training loss: 1.0682599544525146
Validation loss: 1.8430689252832884

Epoch: 6| Step: 7
Training loss: 0.8761278986930847
Validation loss: 1.8565576461053663

Epoch: 6| Step: 8
Training loss: 1.0463958978652954
Validation loss: 1.8688891779991887

Epoch: 6| Step: 9
Training loss: 1.0100080966949463
Validation loss: 1.8953820851541334

Epoch: 6| Step: 10
Training loss: 1.083821415901184
Validation loss: 1.9200910496455368

Epoch: 6| Step: 11
Training loss: 0.9926549196243286
Validation loss: 1.9218650992198656

Epoch: 6| Step: 12
Training loss: 0.3299962282180786
Validation loss: 1.9019607087617278

Epoch: 6| Step: 13
Training loss: 0.2881040573120117
Validation loss: 1.9106400961517005

Epoch: 235| Step: 0
Training loss: 1.2930982112884521
Validation loss: 1.9114029112682547

Epoch: 6| Step: 1
Training loss: 0.7231801748275757
Validation loss: 1.9565682321466424

Epoch: 6| Step: 2
Training loss: 0.7740498185157776
Validation loss: 1.9626068210089078

Epoch: 6| Step: 3
Training loss: 1.0985642671585083
Validation loss: 1.9690648842883367

Epoch: 6| Step: 4
Training loss: 0.8469536900520325
Validation loss: 1.9535171754898564

Epoch: 6| Step: 5
Training loss: 1.3458350896835327
Validation loss: 1.9354722602393037

Epoch: 6| Step: 6
Training loss: 0.9707269668579102
Validation loss: 1.8908191880872172

Epoch: 6| Step: 7
Training loss: 1.5896015167236328
Validation loss: 1.8785747956204157

Epoch: 6| Step: 8
Training loss: 0.5983356833457947
Validation loss: 1.8684562066549897

Epoch: 6| Step: 9
Training loss: 0.8646093606948853
Validation loss: 1.878835347390944

Epoch: 6| Step: 10
Training loss: 0.6560072898864746
Validation loss: 1.8941136021767893

Epoch: 6| Step: 11
Training loss: 0.10273179411888123
Validation loss: 1.9225217937141337

Epoch: 6| Step: 12
Training loss: 0.9724425077438354
Validation loss: 1.9422174512699086

Epoch: 6| Step: 13
Training loss: 0.9738693237304688
Validation loss: 1.9793758110333515

Epoch: 236| Step: 0
Training loss: 0.8699253797531128
Validation loss: 1.979445808677263

Epoch: 6| Step: 1
Training loss: 0.7398748397827148
Validation loss: 1.974282951765163

Epoch: 6| Step: 2
Training loss: 0.8214760422706604
Validation loss: 1.9655836218146867

Epoch: 6| Step: 3
Training loss: 0.4105878472328186
Validation loss: 1.9630069290438006

Epoch: 6| Step: 4
Training loss: 1.1806721687316895
Validation loss: 1.918497952081824

Epoch: 6| Step: 5
Training loss: 1.1073765754699707
Validation loss: 1.9423768686991867

Epoch: 6| Step: 6
Training loss: 0.7328730225563049
Validation loss: 1.9106527156727289

Epoch: 6| Step: 7
Training loss: 0.873778223991394
Validation loss: 1.8969835389044978

Epoch: 6| Step: 8
Training loss: 1.2059261798858643
Validation loss: 1.8833374848929785

Epoch: 6| Step: 9
Training loss: 0.8041090965270996
Validation loss: 1.8563173227412726

Epoch: 6| Step: 10
Training loss: 0.5928020477294922
Validation loss: 1.8819713784802345

Epoch: 6| Step: 11
Training loss: 1.1209136247634888
Validation loss: 1.8908334932019633

Epoch: 6| Step: 12
Training loss: 1.0385879278182983
Validation loss: 1.8930634542178082

Epoch: 6| Step: 13
Training loss: 0.9508739113807678
Validation loss: 1.875014228205527

Epoch: 237| Step: 0
Training loss: 1.016377568244934
Validation loss: 1.8953573267946962

Epoch: 6| Step: 1
Training loss: 0.6685253381729126
Validation loss: 1.9009152817469772

Epoch: 6| Step: 2
Training loss: 0.7076815366744995
Validation loss: 1.8648785544979958

Epoch: 6| Step: 3
Training loss: 0.950456976890564
Validation loss: 1.8735543963729695

Epoch: 6| Step: 4
Training loss: 0.5396233797073364
Validation loss: 1.8618303986005886

Epoch: 6| Step: 5
Training loss: 0.9667304754257202
Validation loss: 1.8321541560593473

Epoch: 6| Step: 6
Training loss: 0.6140623092651367
Validation loss: 1.875267913264613

Epoch: 6| Step: 7
Training loss: 0.9814885854721069
Validation loss: 1.889381145918241

Epoch: 6| Step: 8
Training loss: 0.7436861991882324
Validation loss: 1.8838279503647999

Epoch: 6| Step: 9
Training loss: 1.3442697525024414
Validation loss: 1.8855054070872646

Epoch: 6| Step: 10
Training loss: 0.6601672172546387
Validation loss: 1.8732434806003366

Epoch: 6| Step: 11
Training loss: 1.069950819015503
Validation loss: 1.8742776404144943

Epoch: 6| Step: 12
Training loss: 1.1247704029083252
Validation loss: 1.891788113501764

Epoch: 6| Step: 13
Training loss: 1.2354017496109009
Validation loss: 1.9162464590482815

Epoch: 238| Step: 0
Training loss: 0.9735339283943176
Validation loss: 1.879432237276467

Epoch: 6| Step: 1
Training loss: 0.6934996843338013
Validation loss: 1.8723801605163082

Epoch: 6| Step: 2
Training loss: 0.5014681816101074
Validation loss: 1.8524351683996056

Epoch: 6| Step: 3
Training loss: 0.5463618040084839
Validation loss: 1.8527774336517497

Epoch: 6| Step: 4
Training loss: 0.9851769208908081
Validation loss: 1.8487487890387093

Epoch: 6| Step: 5
Training loss: 0.5230542421340942
Validation loss: 1.838733562859156

Epoch: 6| Step: 6
Training loss: 1.181884765625
Validation loss: 1.8503106371048959

Epoch: 6| Step: 7
Training loss: 0.6854345202445984
Validation loss: 1.8543605419897264

Epoch: 6| Step: 8
Training loss: 0.9289546012878418
Validation loss: 1.826071730224035

Epoch: 6| Step: 9
Training loss: 0.7819838523864746
Validation loss: 1.8447864055633545

Epoch: 6| Step: 10
Training loss: 1.5079877376556396
Validation loss: 1.8570498561346402

Epoch: 6| Step: 11
Training loss: 1.2238671779632568
Validation loss: 1.8326007345671296

Epoch: 6| Step: 12
Training loss: 1.047973394393921
Validation loss: 1.8472224140679965

Epoch: 6| Step: 13
Training loss: 0.99940425157547
Validation loss: 1.8339628634914276

Epoch: 239| Step: 0
Training loss: 1.1061103343963623
Validation loss: 1.8257852946558306

Epoch: 6| Step: 1
Training loss: 1.2063899040222168
Validation loss: 1.8326154344825334

Epoch: 6| Step: 2
Training loss: 0.7409570217132568
Validation loss: 1.86043381690979

Epoch: 6| Step: 3
Training loss: 0.9509527683258057
Validation loss: 1.8712915041113412

Epoch: 6| Step: 4
Training loss: 0.5532326698303223
Validation loss: 1.8539827331419914

Epoch: 6| Step: 5
Training loss: 0.8176602125167847
Validation loss: 1.8823553067381664

Epoch: 6| Step: 6
Training loss: 0.7103976011276245
Validation loss: 1.8829944428577219

Epoch: 6| Step: 7
Training loss: 0.857407808303833
Validation loss: 1.891704285016624

Epoch: 6| Step: 8
Training loss: 0.8550605773925781
Validation loss: 1.8884417818438621

Epoch: 6| Step: 9
Training loss: 0.6839582920074463
Validation loss: 1.8603945239897697

Epoch: 6| Step: 10
Training loss: 0.8539161682128906
Validation loss: 1.8749690260938419

Epoch: 6| Step: 11
Training loss: 0.8523654341697693
Validation loss: 1.8844591750893542

Epoch: 6| Step: 12
Training loss: 0.9092288017272949
Validation loss: 1.8928756380593905

Epoch: 6| Step: 13
Training loss: 1.5116527080535889
Validation loss: 1.8753897925858856

Epoch: 240| Step: 0
Training loss: 1.0387301445007324
Validation loss: 1.8444743387160762

Epoch: 6| Step: 1
Training loss: 0.9920885562896729
Validation loss: 1.8490510294514317

Epoch: 6| Step: 2
Training loss: 0.653853714466095
Validation loss: 1.8141358206349034

Epoch: 6| Step: 3
Training loss: 0.5540986061096191
Validation loss: 1.843186883516209

Epoch: 6| Step: 4
Training loss: 0.8102410435676575
Validation loss: 1.8074175157854635

Epoch: 6| Step: 5
Training loss: 0.8344569206237793
Validation loss: 1.8552494946346487

Epoch: 6| Step: 6
Training loss: 0.938791811466217
Validation loss: 1.849380798237298

Epoch: 6| Step: 7
Training loss: 0.9517918825149536
Validation loss: 1.8289318469262892

Epoch: 6| Step: 8
Training loss: 0.7381927967071533
Validation loss: 1.8150810631372596

Epoch: 6| Step: 9
Training loss: 0.1961815357208252
Validation loss: 1.8479694397218767

Epoch: 6| Step: 10
Training loss: 1.239498496055603
Validation loss: 1.838675896326701

Epoch: 6| Step: 11
Training loss: 0.9330676794052124
Validation loss: 1.8504528307145642

Epoch: 6| Step: 12
Training loss: 1.1346855163574219
Validation loss: 1.874706583638345

Epoch: 6| Step: 13
Training loss: 0.7780886292457581
Validation loss: 1.888518028361823

Epoch: 241| Step: 0
Training loss: 0.8138286471366882
Validation loss: 1.8844878596644248

Epoch: 6| Step: 1
Training loss: 0.7040284276008606
Validation loss: 1.9004355425475745

Epoch: 6| Step: 2
Training loss: 0.825163722038269
Validation loss: 1.9013460349011164

Epoch: 6| Step: 3
Training loss: 1.1283040046691895
Validation loss: 1.9019034959936654

Epoch: 6| Step: 4
Training loss: 1.0814318656921387
Validation loss: 1.9026193939229494

Epoch: 6| Step: 5
Training loss: 0.7932896018028259
Validation loss: 1.8614327625561786

Epoch: 6| Step: 6
Training loss: 1.0791640281677246
Validation loss: 1.8368970822262507

Epoch: 6| Step: 7
Training loss: 0.9121901988983154
Validation loss: 1.8166988998331048

Epoch: 6| Step: 8
Training loss: 0.9855082035064697
Validation loss: 1.818351771241875

Epoch: 6| Step: 9
Training loss: 0.7192150354385376
Validation loss: 1.8392761727815032

Epoch: 6| Step: 10
Training loss: 0.5602971911430359
Validation loss: 1.859091257536283

Epoch: 6| Step: 11
Training loss: 0.7238011360168457
Validation loss: 1.900142176176912

Epoch: 6| Step: 12
Training loss: 0.9469503164291382
Validation loss: 1.920185314711704

Epoch: 6| Step: 13
Training loss: 0.5245507955551147
Validation loss: 1.9280351797739665

Epoch: 242| Step: 0
Training loss: 0.6059269309043884
Validation loss: 1.9424007246571202

Epoch: 6| Step: 1
Training loss: 0.6798881888389587
Validation loss: 1.903909880627868

Epoch: 6| Step: 2
Training loss: 0.6860522627830505
Validation loss: 1.914482315381368

Epoch: 6| Step: 3
Training loss: 0.7966687679290771
Validation loss: 1.9175170237018215

Epoch: 6| Step: 4
Training loss: 1.0711829662322998
Validation loss: 1.866667885934153

Epoch: 6| Step: 5
Training loss: 0.8158798813819885
Validation loss: 1.8765167626001502

Epoch: 6| Step: 6
Training loss: 0.6953503489494324
Validation loss: 1.8670315768129082

Epoch: 6| Step: 7
Training loss: 1.0399249792099
Validation loss: 1.864954839470566

Epoch: 6| Step: 8
Training loss: 0.6107923984527588
Validation loss: 1.8657631848448066

Epoch: 6| Step: 9
Training loss: 0.8865887522697449
Validation loss: 1.8621393275517288

Epoch: 6| Step: 10
Training loss: 0.8717519640922546
Validation loss: 1.8687804719453216

Epoch: 6| Step: 11
Training loss: 0.8727178573608398
Validation loss: 1.9003615097333026

Epoch: 6| Step: 12
Training loss: 1.108618140220642
Validation loss: 1.8543699787509056

Epoch: 6| Step: 13
Training loss: 0.7726471424102783
Validation loss: 1.8666165233940206

Epoch: 243| Step: 0
Training loss: 0.7303625345230103
Validation loss: 1.9100035441819059

Epoch: 6| Step: 1
Training loss: 1.0169451236724854
Validation loss: 1.9101572126470587

Epoch: 6| Step: 2
Training loss: 0.8590531945228577
Validation loss: 1.8870377925134474

Epoch: 6| Step: 3
Training loss: 0.9363764524459839
Validation loss: 1.8858481440492856

Epoch: 6| Step: 4
Training loss: 0.7773401737213135
Validation loss: 1.8822374984782229

Epoch: 6| Step: 5
Training loss: 0.8367383480072021
Validation loss: 1.8866767344936248

Epoch: 6| Step: 6
Training loss: 1.0473694801330566
Validation loss: 1.8621218819772043

Epoch: 6| Step: 7
Training loss: 0.5785450339317322
Validation loss: 1.8577675755305956

Epoch: 6| Step: 8
Training loss: 0.5065425038337708
Validation loss: 1.8400797292750368

Epoch: 6| Step: 9
Training loss: 1.1957283020019531
Validation loss: 1.8396758546111405

Epoch: 6| Step: 10
Training loss: 0.799592137336731
Validation loss: 1.8300843623376661

Epoch: 6| Step: 11
Training loss: 0.6694862842559814
Validation loss: 1.8427932621330343

Epoch: 6| Step: 12
Training loss: 0.8198382258415222
Validation loss: 1.829097799075547

Epoch: 6| Step: 13
Training loss: 0.6156147122383118
Validation loss: 1.832187875624626

Epoch: 244| Step: 0
Training loss: 0.8155167102813721
Validation loss: 1.8648816949577742

Epoch: 6| Step: 1
Training loss: 0.8221451640129089
Validation loss: 1.874317778054104

Epoch: 6| Step: 2
Training loss: 0.8996872305870056
Validation loss: 1.8692090716413272

Epoch: 6| Step: 3
Training loss: 0.8024314641952515
Validation loss: 1.9083064858631422

Epoch: 6| Step: 4
Training loss: 0.652700662612915
Validation loss: 1.9062914027962634

Epoch: 6| Step: 5
Training loss: 0.699953019618988
Validation loss: 1.9065766821625412

Epoch: 6| Step: 6
Training loss: 0.7117272019386292
Validation loss: 1.8827915089104765

Epoch: 6| Step: 7
Training loss: 0.8336874842643738
Validation loss: 1.8474377355267924

Epoch: 6| Step: 8
Training loss: 1.10599684715271
Validation loss: 1.8512818095504597

Epoch: 6| Step: 9
Training loss: 0.6658097505569458
Validation loss: 1.8404186797398392

Epoch: 6| Step: 10
Training loss: 0.6194109916687012
Validation loss: 1.8535001136923348

Epoch: 6| Step: 11
Training loss: 0.9402043223381042
Validation loss: 1.856166567853702

Epoch: 6| Step: 12
Training loss: 0.8162447810173035
Validation loss: 1.8490463123526624

Epoch: 6| Step: 13
Training loss: 0.9696257710456848
Validation loss: 1.837785469588413

Epoch: 245| Step: 0
Training loss: 0.9337145090103149
Validation loss: 1.8531674672198553

Epoch: 6| Step: 1
Training loss: 0.536873459815979
Validation loss: 1.8703924173949866

Epoch: 6| Step: 2
Training loss: 1.055462121963501
Validation loss: 1.9391744534174602

Epoch: 6| Step: 3
Training loss: 0.8716163635253906
Validation loss: 1.91985870176746

Epoch: 6| Step: 4
Training loss: 1.1870852708816528
Validation loss: 1.9077295218744585

Epoch: 6| Step: 5
Training loss: 0.8290942311286926
Validation loss: 1.8740949707646524

Epoch: 6| Step: 6
Training loss: 0.8057864904403687
Validation loss: 1.851116664948002

Epoch: 6| Step: 7
Training loss: 0.6498854160308838
Validation loss: 1.8492281744557042

Epoch: 6| Step: 8
Training loss: 0.6322236061096191
Validation loss: 1.8697712780326925

Epoch: 6| Step: 9
Training loss: 0.6878948211669922
Validation loss: 1.8690109740021408

Epoch: 6| Step: 10
Training loss: 1.1286765336990356
Validation loss: 1.8724357094815982

Epoch: 6| Step: 11
Training loss: 0.5610209703445435
Validation loss: 1.8874063389275664

Epoch: 6| Step: 12
Training loss: 0.7617512941360474
Validation loss: 1.9085510007796749

Epoch: 6| Step: 13
Training loss: 0.7780568599700928
Validation loss: 1.8959915240605671

Epoch: 246| Step: 0
Training loss: 0.8004827499389648
Validation loss: 1.8962434004711848

Epoch: 6| Step: 1
Training loss: 0.5995317697525024
Validation loss: 1.910024360943866

Epoch: 6| Step: 2
Training loss: 0.5627864003181458
Validation loss: 1.9178971680261756

Epoch: 6| Step: 3
Training loss: 0.8550561666488647
Validation loss: 1.9278689097332697

Epoch: 6| Step: 4
Training loss: 1.2330495119094849
Validation loss: 1.9080796049487205

Epoch: 6| Step: 5
Training loss: 0.42330312728881836
Validation loss: 1.9149347453989007

Epoch: 6| Step: 6
Training loss: 0.9993821382522583
Validation loss: 1.9124823539487776

Epoch: 6| Step: 7
Training loss: 0.6583013534545898
Validation loss: 1.8880371227059314

Epoch: 6| Step: 8
Training loss: 0.966313362121582
Validation loss: 1.8537701445241128

Epoch: 6| Step: 9
Training loss: 0.8247998952865601
Validation loss: 1.828665223172916

Epoch: 6| Step: 10
Training loss: 0.9198161363601685
Validation loss: 1.8526331737477293

Epoch: 6| Step: 11
Training loss: 0.6744737029075623
Validation loss: 1.804926130079454

Epoch: 6| Step: 12
Training loss: 0.7896165251731873
Validation loss: 1.8502009940403763

Epoch: 6| Step: 13
Training loss: 0.57869553565979
Validation loss: 1.8443987036264071

Epoch: 247| Step: 0
Training loss: 0.6668215990066528
Validation loss: 1.8558627020928167

Epoch: 6| Step: 1
Training loss: 1.0593106746673584
Validation loss: 1.8865404500756213

Epoch: 6| Step: 2
Training loss: 0.6413689851760864
Validation loss: 1.912914986251503

Epoch: 6| Step: 3
Training loss: 0.8183027505874634
Validation loss: 1.912789301205707

Epoch: 6| Step: 4
Training loss: 0.8710687160491943
Validation loss: 1.8870812321221957

Epoch: 6| Step: 5
Training loss: 0.39281976222991943
Validation loss: 1.8812093016921834

Epoch: 6| Step: 6
Training loss: 0.7346898913383484
Validation loss: 1.8325707207443893

Epoch: 6| Step: 7
Training loss: 0.7228685617446899
Validation loss: 1.8206100284412343

Epoch: 6| Step: 8
Training loss: 0.7565194368362427
Validation loss: 1.8258537233516734

Epoch: 6| Step: 9
Training loss: 0.8193652033805847
Validation loss: 1.8314585096092635

Epoch: 6| Step: 10
Training loss: 0.8181887865066528
Validation loss: 1.8303153002133934

Epoch: 6| Step: 11
Training loss: 0.5934081077575684
Validation loss: 1.8386014687117709

Epoch: 6| Step: 12
Training loss: 0.852043628692627
Validation loss: 1.8728108482976114

Epoch: 6| Step: 13
Training loss: 1.1861528158187866
Validation loss: 1.8316518350314068

Epoch: 248| Step: 0
Training loss: 0.7617101669311523
Validation loss: 1.872502257747035

Epoch: 6| Step: 1
Training loss: 0.5121535062789917
Validation loss: 1.8506674151266775

Epoch: 6| Step: 2
Training loss: 1.0458364486694336
Validation loss: 1.8486912442791847

Epoch: 6| Step: 3
Training loss: 0.45435163378715515
Validation loss: 1.8492332299550374

Epoch: 6| Step: 4
Training loss: 0.7476097941398621
Validation loss: 1.8718726173523934

Epoch: 6| Step: 5
Training loss: 0.9419682621955872
Validation loss: 1.8969530161990915

Epoch: 6| Step: 6
Training loss: 0.7162528038024902
Validation loss: 1.9710649854393416

Epoch: 6| Step: 7
Training loss: 0.6198751926422119
Validation loss: 1.9713667925967966

Epoch: 6| Step: 8
Training loss: 0.6645634174346924
Validation loss: 1.946798493785243

Epoch: 6| Step: 9
Training loss: 0.9626518487930298
Validation loss: 1.892316843873711

Epoch: 6| Step: 10
Training loss: 0.5118544101715088
Validation loss: 1.8764618955632693

Epoch: 6| Step: 11
Training loss: 1.0578758716583252
Validation loss: 1.8383381725639425

Epoch: 6| Step: 12
Training loss: 0.7833845615386963
Validation loss: 1.800298543386562

Epoch: 6| Step: 13
Training loss: 1.12279212474823
Validation loss: 1.8306277798068138

Epoch: 249| Step: 0
Training loss: 0.9450576901435852
Validation loss: 1.8185075906015211

Epoch: 6| Step: 1
Training loss: 0.9837037920951843
Validation loss: 1.824646903622535

Epoch: 6| Step: 2
Training loss: 0.7140038013458252
Validation loss: 1.8099463242356495

Epoch: 6| Step: 3
Training loss: 1.0198394060134888
Validation loss: 1.8109549860800467

Epoch: 6| Step: 4
Training loss: 0.9509537220001221
Validation loss: 1.8282218005067559

Epoch: 6| Step: 5
Training loss: 0.527036190032959
Validation loss: 1.8654384971946798

Epoch: 6| Step: 6
Training loss: 0.563603937625885
Validation loss: 1.8627894745078137

Epoch: 6| Step: 7
Training loss: 0.7468144297599792
Validation loss: 1.9037531627121793

Epoch: 6| Step: 8
Training loss: 0.7755253314971924
Validation loss: 1.870800002928703

Epoch: 6| Step: 9
Training loss: 1.0186049938201904
Validation loss: 1.8463750936651742

Epoch: 6| Step: 10
Training loss: 1.146234393119812
Validation loss: 1.8613415533496487

Epoch: 6| Step: 11
Training loss: 0.5775455832481384
Validation loss: 1.8404660045459706

Epoch: 6| Step: 12
Training loss: 0.5175706744194031
Validation loss: 1.827174017506261

Epoch: 6| Step: 13
Training loss: 0.4556105434894562
Validation loss: 1.8641829311206777

Epoch: 250| Step: 0
Training loss: 0.7394282221794128
Validation loss: 1.8387833628603207

Epoch: 6| Step: 1
Training loss: 0.9741837978363037
Validation loss: 1.8627444159600042

Epoch: 6| Step: 2
Training loss: 0.6932921409606934
Validation loss: 1.8672221373486262

Epoch: 6| Step: 3
Training loss: 0.9163147211074829
Validation loss: 1.814248102967457

Epoch: 6| Step: 4
Training loss: 0.8990107774734497
Validation loss: 1.8246793516220585

Epoch: 6| Step: 5
Training loss: 0.7483687400817871
Validation loss: 1.7819863237360472

Epoch: 6| Step: 6
Training loss: 0.7223618626594543
Validation loss: 1.7812769271994149

Epoch: 6| Step: 7
Training loss: 0.7855709195137024
Validation loss: 1.7991306768950595

Epoch: 6| Step: 8
Training loss: 0.508201003074646
Validation loss: 1.7838760524667718

Epoch: 6| Step: 9
Training loss: 0.4980705976486206
Validation loss: 1.8278505904700166

Epoch: 6| Step: 10
Training loss: 0.49363088607788086
Validation loss: 1.8298212635901667

Epoch: 6| Step: 11
Training loss: 1.0717682838439941
Validation loss: 1.8486100627530007

Epoch: 6| Step: 12
Training loss: 0.7114549875259399
Validation loss: 1.8299976100203812

Epoch: 6| Step: 13
Training loss: 0.9295608997344971
Validation loss: 1.8407437852633897

Epoch: 251| Step: 0
Training loss: 0.6466007828712463
Validation loss: 1.8560476149282148

Epoch: 6| Step: 1
Training loss: 0.48573487997055054
Validation loss: 1.8645219649038007

Epoch: 6| Step: 2
Training loss: 1.1363680362701416
Validation loss: 1.897371361332555

Epoch: 6| Step: 3
Training loss: 0.7015776038169861
Validation loss: 1.9017708916817941

Epoch: 6| Step: 4
Training loss: 0.47878801822662354
Validation loss: 1.8929443590102657

Epoch: 6| Step: 5
Training loss: 1.1516456604003906
Validation loss: 1.9115890764421033

Epoch: 6| Step: 6
Training loss: 0.7868077158927917
Validation loss: 1.8803399044980285

Epoch: 6| Step: 7
Training loss: 0.8789137601852417
Validation loss: 1.870226372954666

Epoch: 6| Step: 8
Training loss: 1.0096373558044434
Validation loss: 1.8569177196871849

Epoch: 6| Step: 9
Training loss: 0.47878068685531616
Validation loss: 1.8691564926537134

Epoch: 6| Step: 10
Training loss: 0.775972843170166
Validation loss: 1.9014434686271093

Epoch: 6| Step: 11
Training loss: 0.9142371416091919
Validation loss: 1.8691820277962634

Epoch: 6| Step: 12
Training loss: 0.7061351537704468
Validation loss: 1.8953685606679609

Epoch: 6| Step: 13
Training loss: 0.5687929391860962
Validation loss: 1.8733131193345594

Epoch: 252| Step: 0
Training loss: 0.5645802021026611
Validation loss: 1.8359652642280824

Epoch: 6| Step: 1
Training loss: 0.39692604541778564
Validation loss: 1.7935683393991122

Epoch: 6| Step: 2
Training loss: 0.5548542737960815
Validation loss: 1.8049960879869358

Epoch: 6| Step: 3
Training loss: 0.801099419593811
Validation loss: 1.8243179372561875

Epoch: 6| Step: 4
Training loss: 0.5869788527488708
Validation loss: 1.8600285668526926

Epoch: 6| Step: 5
Training loss: 0.6298096776008606
Validation loss: 1.8363233138156194

Epoch: 6| Step: 6
Training loss: 0.5475559234619141
Validation loss: 1.8690392958220614

Epoch: 6| Step: 7
Training loss: 0.6362893581390381
Validation loss: 1.848631679370839

Epoch: 6| Step: 8
Training loss: 0.6276043057441711
Validation loss: 1.8688246665462371

Epoch: 6| Step: 9
Training loss: 0.9432094693183899
Validation loss: 1.9211634435961324

Epoch: 6| Step: 10
Training loss: 0.9095476865768433
Validation loss: 1.908837059492706

Epoch: 6| Step: 11
Training loss: 0.9431034922599792
Validation loss: 1.9058677560539656

Epoch: 6| Step: 12
Training loss: 0.7157103419303894
Validation loss: 1.918151137649372

Epoch: 6| Step: 13
Training loss: 1.5515570640563965
Validation loss: 1.9191661701407483

Epoch: 253| Step: 0
Training loss: 0.725616455078125
Validation loss: 1.9112633082174486

Epoch: 6| Step: 1
Training loss: 0.6312748193740845
Validation loss: 1.9267404643438195

Epoch: 6| Step: 2
Training loss: 0.5482348799705505
Validation loss: 1.9136420898540045

Epoch: 6| Step: 3
Training loss: 0.8258417844772339
Validation loss: 1.9186951562922487

Epoch: 6| Step: 4
Training loss: 0.37943100929260254
Validation loss: 1.8536520068363478

Epoch: 6| Step: 5
Training loss: 0.7523224353790283
Validation loss: 1.8187178347700386

Epoch: 6| Step: 6
Training loss: 1.0088196992874146
Validation loss: 1.8205084672538183

Epoch: 6| Step: 7
Training loss: 0.829460859298706
Validation loss: 1.80197657820999

Epoch: 6| Step: 8
Training loss: 0.7258129119873047
Validation loss: 1.7813373393909906

Epoch: 6| Step: 9
Training loss: 0.9274378418922424
Validation loss: 1.788148815913867

Epoch: 6| Step: 10
Training loss: 0.9095374941825867
Validation loss: 1.8276271999523204

Epoch: 6| Step: 11
Training loss: 0.7464948892593384
Validation loss: 1.8508342696774391

Epoch: 6| Step: 12
Training loss: 1.1079901456832886
Validation loss: 1.830405524981919

Epoch: 6| Step: 13
Training loss: 0.7565048336982727
Validation loss: 1.8664131946461175

Epoch: 254| Step: 0
Training loss: 0.48163750767707825
Validation loss: 1.859175205230713

Epoch: 6| Step: 1
Training loss: 0.6418079137802124
Validation loss: 1.8126797060812674

Epoch: 6| Step: 2
Training loss: 0.8305119276046753
Validation loss: 1.7682536718665913

Epoch: 6| Step: 3
Training loss: 0.2955859303474426
Validation loss: 1.7695972252917547

Epoch: 6| Step: 4
Training loss: 0.9978657364845276
Validation loss: 1.7550582526832499

Epoch: 6| Step: 5
Training loss: 0.7617248296737671
Validation loss: 1.7564894871045185

Epoch: 6| Step: 6
Training loss: 0.998362123966217
Validation loss: 1.7742620116920882

Epoch: 6| Step: 7
Training loss: 0.8270370960235596
Validation loss: 1.7599922110957484

Epoch: 6| Step: 8
Training loss: 0.781268298625946
Validation loss: 1.7919149578258555

Epoch: 6| Step: 9
Training loss: 0.981529951095581
Validation loss: 1.778655844350015

Epoch: 6| Step: 10
Training loss: 0.6645557880401611
Validation loss: 1.8435119890397595

Epoch: 6| Step: 11
Training loss: 0.837422251701355
Validation loss: 1.915220135001726

Epoch: 6| Step: 12
Training loss: 0.7229040861129761
Validation loss: 1.9613928410314745

Epoch: 6| Step: 13
Training loss: 0.7193587422370911
Validation loss: 1.9673196179892427

Epoch: 255| Step: 0
Training loss: 0.7895635962486267
Validation loss: 1.933268307357706

Epoch: 6| Step: 1
Training loss: 0.5244149565696716
Validation loss: 1.931277262267246

Epoch: 6| Step: 2
Training loss: 0.8381474614143372
Validation loss: 1.9180863006140596

Epoch: 6| Step: 3
Training loss: 0.8789608478546143
Validation loss: 1.9131624647366103

Epoch: 6| Step: 4
Training loss: 1.0371296405792236
Validation loss: 1.899522231471154

Epoch: 6| Step: 5
Training loss: 0.46340590715408325
Validation loss: 1.9168031138758506

Epoch: 6| Step: 6
Training loss: 0.9106824398040771
Validation loss: 1.8922359661389423

Epoch: 6| Step: 7
Training loss: 0.5755864977836609
Validation loss: 1.894718047111265

Epoch: 6| Step: 8
Training loss: 0.7312444448471069
Validation loss: 1.892671056973037

Epoch: 6| Step: 9
Training loss: 0.7050074934959412
Validation loss: 1.8752301367380286

Epoch: 6| Step: 10
Training loss: 0.6383939385414124
Validation loss: 1.8919464272837485

Epoch: 6| Step: 11
Training loss: 0.8626687526702881
Validation loss: 1.9261521703453475

Epoch: 6| Step: 12
Training loss: 0.8636631369590759
Validation loss: 1.9010852408665482

Epoch: 6| Step: 13
Training loss: 0.8845743536949158
Validation loss: 1.9519222205685032

Epoch: 256| Step: 0
Training loss: 0.37324756383895874
Validation loss: 1.9150804524780602

Epoch: 6| Step: 1
Training loss: 0.8636209964752197
Validation loss: 1.8994531580196914

Epoch: 6| Step: 2
Training loss: 0.6576606035232544
Validation loss: 1.871509195655905

Epoch: 6| Step: 3
Training loss: 0.6121237277984619
Validation loss: 1.8444019889318815

Epoch: 6| Step: 4
Training loss: 0.6680720448493958
Validation loss: 1.8454513472895469

Epoch: 6| Step: 5
Training loss: 0.7456400990486145
Validation loss: 1.8399971390283236

Epoch: 6| Step: 6
Training loss: 0.5972784757614136
Validation loss: 1.8307053568542644

Epoch: 6| Step: 7
Training loss: 0.7311155796051025
Validation loss: 1.8475125425605363

Epoch: 6| Step: 8
Training loss: 0.7498089075088501
Validation loss: 1.833162949931237

Epoch: 6| Step: 9
Training loss: 0.906845211982727
Validation loss: 1.8455486015606952

Epoch: 6| Step: 10
Training loss: 0.8578264713287354
Validation loss: 1.8410068096653107

Epoch: 6| Step: 11
Training loss: 0.3178764283657074
Validation loss: 1.84314461036395

Epoch: 6| Step: 12
Training loss: 0.9184836149215698
Validation loss: 1.8606484859220442

Epoch: 6| Step: 13
Training loss: 1.0162495374679565
Validation loss: 1.8679572561735749

Epoch: 257| Step: 0
Training loss: 0.8693557977676392
Validation loss: 1.8570008662439161

Epoch: 6| Step: 1
Training loss: 0.9340225458145142
Validation loss: 1.8641000845099007

Epoch: 6| Step: 2
Training loss: 0.6594721674919128
Validation loss: 1.8656295550766813

Epoch: 6| Step: 3
Training loss: 0.5643672943115234
Validation loss: 1.8933591304286834

Epoch: 6| Step: 4
Training loss: 0.4925548732280731
Validation loss: 1.8972857331716886

Epoch: 6| Step: 5
Training loss: 0.7980374097824097
Validation loss: 1.878329559039044

Epoch: 6| Step: 6
Training loss: 0.2824779152870178
Validation loss: 1.8854407648886404

Epoch: 6| Step: 7
Training loss: 0.6067808270454407
Validation loss: 1.9211948456302765

Epoch: 6| Step: 8
Training loss: 0.7215101718902588
Validation loss: 1.8564022241100189

Epoch: 6| Step: 9
Training loss: 0.8042339086532593
Validation loss: 1.8972073434501566

Epoch: 6| Step: 10
Training loss: 0.7094624042510986
Validation loss: 1.9113978878144295

Epoch: 6| Step: 11
Training loss: 0.837685227394104
Validation loss: 1.9002251958334317

Epoch: 6| Step: 12
Training loss: 0.7805213332176208
Validation loss: 1.891148353135714

Epoch: 6| Step: 13
Training loss: 0.3720608949661255
Validation loss: 1.8920477756889917

Epoch: 258| Step: 0
Training loss: 0.7026436924934387
Validation loss: 1.8700504706751915

Epoch: 6| Step: 1
Training loss: 0.4432721734046936
Validation loss: 1.8876049121220906

Epoch: 6| Step: 2
Training loss: 0.5300115346908569
Validation loss: 1.8859896788033106

Epoch: 6| Step: 3
Training loss: 0.932324230670929
Validation loss: 1.8934597610145487

Epoch: 6| Step: 4
Training loss: 0.5974644422531128
Validation loss: 1.8658497500163254

Epoch: 6| Step: 5
Training loss: 0.6837817430496216
Validation loss: 1.8816702570966495

Epoch: 6| Step: 6
Training loss: 0.8193225264549255
Validation loss: 1.879471053359329

Epoch: 6| Step: 7
Training loss: 0.35455864667892456
Validation loss: 1.8558510631643317

Epoch: 6| Step: 8
Training loss: 0.9378580451011658
Validation loss: 1.8421866316949167

Epoch: 6| Step: 9
Training loss: 0.9244531989097595
Validation loss: 1.8315168824247134

Epoch: 6| Step: 10
Training loss: 1.0076264142990112
Validation loss: 1.8196328506674817

Epoch: 6| Step: 11
Training loss: 0.3986359238624573
Validation loss: 1.801712380942478

Epoch: 6| Step: 12
Training loss: 0.475224107503891
Validation loss: 1.7958955040542028

Epoch: 6| Step: 13
Training loss: 0.5395690202713013
Validation loss: 1.821168461153584

Epoch: 259| Step: 0
Training loss: 0.7205355167388916
Validation loss: 1.798907749114498

Epoch: 6| Step: 1
Training loss: 0.8566672205924988
Validation loss: 1.8206607218711608

Epoch: 6| Step: 2
Training loss: 0.543197512626648
Validation loss: 1.8289343093031196

Epoch: 6| Step: 3
Training loss: 0.439320832490921
Validation loss: 1.8134948386940906

Epoch: 6| Step: 4
Training loss: 0.4965369403362274
Validation loss: 1.8635635555431407

Epoch: 6| Step: 5
Training loss: 0.5283763408660889
Validation loss: 1.8619616980193763

Epoch: 6| Step: 6
Training loss: 0.5672227740287781
Validation loss: 1.8645379735577492

Epoch: 6| Step: 7
Training loss: 1.0887792110443115
Validation loss: 1.8590626255158456

Epoch: 6| Step: 8
Training loss: 0.7416986227035522
Validation loss: 1.8872165987568517

Epoch: 6| Step: 9
Training loss: 0.8226912021636963
Validation loss: 1.8457760157123688

Epoch: 6| Step: 10
Training loss: 0.4776207208633423
Validation loss: 1.8556294120768064

Epoch: 6| Step: 11
Training loss: 0.7552976608276367
Validation loss: 1.8180532045261835

Epoch: 6| Step: 12
Training loss: 0.6004812717437744
Validation loss: 1.7939020036369242

Epoch: 6| Step: 13
Training loss: 0.6683820486068726
Validation loss: 1.7511131660912627

Epoch: 260| Step: 0
Training loss: 0.46965712308883667
Validation loss: 1.7790352631640691

Epoch: 6| Step: 1
Training loss: 0.6612899303436279
Validation loss: 1.7964157827438847

Epoch: 6| Step: 2
Training loss: 0.7481468915939331
Validation loss: 1.8127859959038355

Epoch: 6| Step: 3
Training loss: 0.5228226184844971
Validation loss: 1.853339067069433

Epoch: 6| Step: 4
Training loss: 0.7041404247283936
Validation loss: 1.8907604602075392

Epoch: 6| Step: 5
Training loss: 0.7911628484725952
Validation loss: 1.9586721774070495

Epoch: 6| Step: 6
Training loss: 0.8078070282936096
Validation loss: 1.9197178963691957

Epoch: 6| Step: 7
Training loss: 1.010853886604309
Validation loss: 1.8850608820556312

Epoch: 6| Step: 8
Training loss: 0.8603399991989136
Validation loss: 1.8741473164609683

Epoch: 6| Step: 9
Training loss: 0.8292691111564636
Validation loss: 1.882485464055051

Epoch: 6| Step: 10
Training loss: 0.8862761855125427
Validation loss: 1.8874023063208467

Epoch: 6| Step: 11
Training loss: 0.6536032557487488
Validation loss: 1.9025390122526435

Epoch: 6| Step: 12
Training loss: 0.3422042429447174
Validation loss: 1.89261975596028

Epoch: 6| Step: 13
Training loss: 0.6584587693214417
Validation loss: 1.8672372205283052

Epoch: 261| Step: 0
Training loss: 0.43253016471862793
Validation loss: 1.8324483671495992

Epoch: 6| Step: 1
Training loss: 0.5863512754440308
Validation loss: 1.8126774654593518

Epoch: 6| Step: 2
Training loss: 0.5480403900146484
Validation loss: 1.8173527320226033

Epoch: 6| Step: 3
Training loss: 0.4411498010158539
Validation loss: 1.8053449020590833

Epoch: 6| Step: 4
Training loss: 0.4252049922943115
Validation loss: 1.7992936052301878

Epoch: 6| Step: 5
Training loss: 0.5129008293151855
Validation loss: 1.804782256003349

Epoch: 6| Step: 6
Training loss: 0.7428461313247681
Validation loss: 1.75975158650388

Epoch: 6| Step: 7
Training loss: 0.6502624750137329
Validation loss: 1.8076687051403908

Epoch: 6| Step: 8
Training loss: 1.0484240055084229
Validation loss: 1.7668850703905987

Epoch: 6| Step: 9
Training loss: 0.5873271226882935
Validation loss: 1.7354953327486593

Epoch: 6| Step: 10
Training loss: 0.6798920631408691
Validation loss: 1.78336719030975

Epoch: 6| Step: 11
Training loss: 0.8568557500839233
Validation loss: 1.7649930677106302

Epoch: 6| Step: 12
Training loss: 0.8168100118637085
Validation loss: 1.7637459206324753

Epoch: 6| Step: 13
Training loss: 0.9281256794929504
Validation loss: 1.7684196682386502

Epoch: 262| Step: 0
Training loss: 0.6742449998855591
Validation loss: 1.7919273953283987

Epoch: 6| Step: 1
Training loss: 0.6999946236610413
Validation loss: 1.8292525224788214

Epoch: 6| Step: 2
Training loss: 0.6844136118888855
Validation loss: 1.8247769648028958

Epoch: 6| Step: 3
Training loss: 0.8668239116668701
Validation loss: 1.831259835150934

Epoch: 6| Step: 4
Training loss: 0.7801628112792969
Validation loss: 1.8523065454216414

Epoch: 6| Step: 5
Training loss: 0.6298942565917969
Validation loss: 1.8296857110915645

Epoch: 6| Step: 6
Training loss: 0.6617876887321472
Validation loss: 1.8315533694400583

Epoch: 6| Step: 7
Training loss: 0.6586334705352783
Validation loss: 1.826341736701227

Epoch: 6| Step: 8
Training loss: 0.38515549898147583
Validation loss: 1.8163565012716478

Epoch: 6| Step: 9
Training loss: 0.3891419768333435
Validation loss: 1.8214606572222967

Epoch: 6| Step: 10
Training loss: 0.8096714019775391
Validation loss: 1.8121294821462324

Epoch: 6| Step: 11
Training loss: 0.493955135345459
Validation loss: 1.8068413324253534

Epoch: 6| Step: 12
Training loss: 0.5487060546875
Validation loss: 1.7932269137392762

Epoch: 6| Step: 13
Training loss: 0.3765278160572052
Validation loss: 1.804443024819897

Epoch: 263| Step: 0
Training loss: 0.5338784456253052
Validation loss: 1.7499026419014059

Epoch: 6| Step: 1
Training loss: 0.5921305418014526
Validation loss: 1.7383722643698416

Epoch: 6| Step: 2
Training loss: 0.514234185218811
Validation loss: 1.7247210638497465

Epoch: 6| Step: 3
Training loss: 0.40420863032341003
Validation loss: 1.7448304776222474

Epoch: 6| Step: 4
Training loss: 0.7766046524047852
Validation loss: 1.7549829636850665

Epoch: 6| Step: 5
Training loss: 0.6682591438293457
Validation loss: 1.7487151340771747

Epoch: 6| Step: 6
Training loss: 0.855567216873169
Validation loss: 1.7804882090578797

Epoch: 6| Step: 7
Training loss: 0.43025919795036316
Validation loss: 1.7690277637973908

Epoch: 6| Step: 8
Training loss: 0.309805303812027
Validation loss: 1.793057946748631

Epoch: 6| Step: 9
Training loss: 0.6228185892105103
Validation loss: 1.8134815116082468

Epoch: 6| Step: 10
Training loss: 0.3437926471233368
Validation loss: 1.7767760817722609

Epoch: 6| Step: 11
Training loss: 1.1325395107269287
Validation loss: 1.7992625697966544

Epoch: 6| Step: 12
Training loss: 1.075418472290039
Validation loss: 1.8098553444749566

Epoch: 6| Step: 13
Training loss: 0.5538201928138733
Validation loss: 1.8075247157004573

Epoch: 264| Step: 0
Training loss: 0.4390397071838379
Validation loss: 1.8125144050967308

Epoch: 6| Step: 1
Training loss: 0.7394772171974182
Validation loss: 1.822096122208462

Epoch: 6| Step: 2
Training loss: 0.6937470436096191
Validation loss: 1.8177688762705813

Epoch: 6| Step: 3
Training loss: 0.8177021741867065
Validation loss: 1.859556882612167

Epoch: 6| Step: 4
Training loss: 0.4861437678337097
Validation loss: 1.8437241969570037

Epoch: 6| Step: 5
Training loss: 0.47790294885635376
Validation loss: 1.854345901038057

Epoch: 6| Step: 6
Training loss: 0.913356602191925
Validation loss: 1.8810663479630665

Epoch: 6| Step: 7
Training loss: 0.3598385155200958
Validation loss: 1.8831987509163477

Epoch: 6| Step: 8
Training loss: 0.992469847202301
Validation loss: 1.8776315002031223

Epoch: 6| Step: 9
Training loss: 0.3911598026752472
Validation loss: 1.8690166729752735

Epoch: 6| Step: 10
Training loss: 0.6864302158355713
Validation loss: 1.8820842722410798

Epoch: 6| Step: 11
Training loss: 0.7064321041107178
Validation loss: 1.8701309157956032

Epoch: 6| Step: 12
Training loss: 0.3995373845100403
Validation loss: 1.8227547548150504

Epoch: 6| Step: 13
Training loss: 0.7898997664451599
Validation loss: 1.8118585002037786

Epoch: 265| Step: 0
Training loss: 0.6272699236869812
Validation loss: 1.7801503160948395

Epoch: 6| Step: 1
Training loss: 0.6065226793289185
Validation loss: 1.7584301963929208

Epoch: 6| Step: 2
Training loss: 0.5195307731628418
Validation loss: 1.749610758596851

Epoch: 6| Step: 3
Training loss: 0.5829591155052185
Validation loss: 1.7572475133403656

Epoch: 6| Step: 4
Training loss: 0.5516752004623413
Validation loss: 1.74184597692182

Epoch: 6| Step: 5
Training loss: 0.7573609352111816
Validation loss: 1.7555815724916355

Epoch: 6| Step: 6
Training loss: 0.6944774389266968
Validation loss: 1.7625562324318835

Epoch: 6| Step: 7
Training loss: 0.6692357659339905
Validation loss: 1.7657920570783718

Epoch: 6| Step: 8
Training loss: 0.4369179308414459
Validation loss: 1.772776061488736

Epoch: 6| Step: 9
Training loss: 0.47986292839050293
Validation loss: 1.7915715145808395

Epoch: 6| Step: 10
Training loss: 0.8025901317596436
Validation loss: 1.7828241291866507

Epoch: 6| Step: 11
Training loss: 0.8578557968139648
Validation loss: 1.8110633075878184

Epoch: 6| Step: 12
Training loss: 0.566011369228363
Validation loss: 1.8285847017841954

Epoch: 6| Step: 13
Training loss: 0.5542923212051392
Validation loss: 1.8254609454062678

Epoch: 266| Step: 0
Training loss: 0.5382505655288696
Validation loss: 1.8061396383470105

Epoch: 6| Step: 1
Training loss: 0.6435563564300537
Validation loss: 1.8053855537086405

Epoch: 6| Step: 2
Training loss: 0.6594971418380737
Validation loss: 1.7864172663739932

Epoch: 6| Step: 3
Training loss: 0.9578787088394165
Validation loss: 1.8299506274602746

Epoch: 6| Step: 4
Training loss: 0.3065444231033325
Validation loss: 1.818380359680422

Epoch: 6| Step: 5
Training loss: 0.538275420665741
Validation loss: 1.8363021291712278

Epoch: 6| Step: 6
Training loss: 0.5711670517921448
Validation loss: 1.8791241350994314

Epoch: 6| Step: 7
Training loss: 0.5575306415557861
Validation loss: 1.8639645384204002

Epoch: 6| Step: 8
Training loss: 1.0097787380218506
Validation loss: 1.8143127823388705

Epoch: 6| Step: 9
Training loss: 0.5487117171287537
Validation loss: 1.831614871178904

Epoch: 6| Step: 10
Training loss: 0.6207095384597778
Validation loss: 1.814299988490279

Epoch: 6| Step: 11
Training loss: 0.706929087638855
Validation loss: 1.8004876990472116

Epoch: 6| Step: 12
Training loss: 0.37182173132896423
Validation loss: 1.808837221514794

Epoch: 6| Step: 13
Training loss: 0.8305396437644958
Validation loss: 1.791903370170183

Epoch: 267| Step: 0
Training loss: 0.664219856262207
Validation loss: 1.771129778636399

Epoch: 6| Step: 1
Training loss: 0.673672080039978
Validation loss: 1.7558715240929716

Epoch: 6| Step: 2
Training loss: 0.6024590730667114
Validation loss: 1.757588299371863

Epoch: 6| Step: 3
Training loss: 0.46643149852752686
Validation loss: 1.7571760339121665

Epoch: 6| Step: 4
Training loss: 0.5531634092330933
Validation loss: 1.7597162415904384

Epoch: 6| Step: 5
Training loss: 0.7207264304161072
Validation loss: 1.7804679268149919

Epoch: 6| Step: 6
Training loss: 0.6558657884597778
Validation loss: 1.7812387033175396

Epoch: 6| Step: 7
Training loss: 0.5270535349845886
Validation loss: 1.7921463802296629

Epoch: 6| Step: 8
Training loss: 0.6680681705474854
Validation loss: 1.818413798527051

Epoch: 6| Step: 9
Training loss: 0.727300226688385
Validation loss: 1.8158958291494718

Epoch: 6| Step: 10
Training loss: 0.41727155447006226
Validation loss: 1.8010418107432704

Epoch: 6| Step: 11
Training loss: 0.5763472318649292
Validation loss: 1.7703696886698406

Epoch: 6| Step: 12
Training loss: 0.4292926788330078
Validation loss: 1.8089474785712458

Epoch: 6| Step: 13
Training loss: 0.9902265071868896
Validation loss: 1.7986990585122058

Epoch: 268| Step: 0
Training loss: 0.7247928380966187
Validation loss: 1.8397892111091203

Epoch: 6| Step: 1
Training loss: 0.6262452006340027
Validation loss: 1.8704740449946413

Epoch: 6| Step: 2
Training loss: 0.6724549531936646
Validation loss: 1.820644014625139

Epoch: 6| Step: 3
Training loss: 0.9578601121902466
Validation loss: 1.8522711953809183

Epoch: 6| Step: 4
Training loss: 0.4818122386932373
Validation loss: 1.8717258989170034

Epoch: 6| Step: 5
Training loss: 0.5315645933151245
Validation loss: 1.7986358916887673

Epoch: 6| Step: 6
Training loss: 0.486461341381073
Validation loss: 1.7958112109091975

Epoch: 6| Step: 7
Training loss: 0.4890039563179016
Validation loss: 1.8325489208262453

Epoch: 6| Step: 8
Training loss: 0.7795090079307556
Validation loss: 1.8552006957351521

Epoch: 6| Step: 9
Training loss: 0.6454615592956543
Validation loss: 1.833749158408052

Epoch: 6| Step: 10
Training loss: 0.4098927080631256
Validation loss: 1.8555541371786466

Epoch: 6| Step: 11
Training loss: 0.4602890908718109
Validation loss: 1.8561082065746348

Epoch: 6| Step: 12
Training loss: 0.7472246289253235
Validation loss: 1.890694922016513

Epoch: 6| Step: 13
Training loss: 0.5723488926887512
Validation loss: 1.898070607134091

Epoch: 269| Step: 0
Training loss: 0.6327036023139954
Validation loss: 1.8669151106188375

Epoch: 6| Step: 1
Training loss: 0.6918559074401855
Validation loss: 1.839645290887484

Epoch: 6| Step: 2
Training loss: 0.49852877855300903
Validation loss: 1.798418188607821

Epoch: 6| Step: 3
Training loss: 0.5272663235664368
Validation loss: 1.7924285088815997

Epoch: 6| Step: 4
Training loss: 0.8519975543022156
Validation loss: 1.7588709887637888

Epoch: 6| Step: 5
Training loss: 0.6893261671066284
Validation loss: 1.7346939297132595

Epoch: 6| Step: 6
Training loss: 0.5200918912887573
Validation loss: 1.7002834978924002

Epoch: 6| Step: 7
Training loss: 0.46055251359939575
Validation loss: 1.7006710690836753

Epoch: 6| Step: 8
Training loss: 0.5452839136123657
Validation loss: 1.7206012305393015

Epoch: 6| Step: 9
Training loss: 0.6132420301437378
Validation loss: 1.7411304122658187

Epoch: 6| Step: 10
Training loss: 0.7565155029296875
Validation loss: 1.760556047962558

Epoch: 6| Step: 11
Training loss: 0.6060476303100586
Validation loss: 1.763919816222242

Epoch: 6| Step: 12
Training loss: 0.3086684048175812
Validation loss: 1.801664335753328

Epoch: 6| Step: 13
Training loss: 0.3849247097969055
Validation loss: 1.8102257251739502

Epoch: 270| Step: 0
Training loss: 0.2987998127937317
Validation loss: 1.8522607793090164

Epoch: 6| Step: 1
Training loss: 0.9438714981079102
Validation loss: 1.8468662000471545

Epoch: 6| Step: 2
Training loss: 0.8307077884674072
Validation loss: 1.83773688731655

Epoch: 6| Step: 3
Training loss: 0.2696385681629181
Validation loss: 1.8738670836212814

Epoch: 6| Step: 4
Training loss: 0.6678920984268188
Validation loss: 1.8767755428949993

Epoch: 6| Step: 5
Training loss: 0.3534449338912964
Validation loss: 1.8999821037374518

Epoch: 6| Step: 6
Training loss: 0.35768961906433105
Validation loss: 1.8990476246803039

Epoch: 6| Step: 7
Training loss: 0.530533492565155
Validation loss: 1.8811323578639696

Epoch: 6| Step: 8
Training loss: 0.7386623024940491
Validation loss: 1.8432532920632312

Epoch: 6| Step: 9
Training loss: 0.833177924156189
Validation loss: 1.8535095991626862

Epoch: 6| Step: 10
Training loss: 0.7850732803344727
Validation loss: 1.8288185570829658

Epoch: 6| Step: 11
Training loss: 0.2855258285999298
Validation loss: 1.8347934471663607

Epoch: 6| Step: 12
Training loss: 0.48585861921310425
Validation loss: 1.797919383613012

Epoch: 6| Step: 13
Training loss: 0.6897092461585999
Validation loss: 1.7841220196857248

Epoch: 271| Step: 0
Training loss: 0.7639586925506592
Validation loss: 1.7740313212076824

Epoch: 6| Step: 1
Training loss: 0.5704650282859802
Validation loss: 1.778732584368798

Epoch: 6| Step: 2
Training loss: 0.6283622980117798
Validation loss: 1.7309128802309754

Epoch: 6| Step: 3
Training loss: 0.6009496450424194
Validation loss: 1.7176345881595407

Epoch: 6| Step: 4
Training loss: 0.4857969284057617
Validation loss: 1.7241929167060441

Epoch: 6| Step: 5
Training loss: 0.6889525651931763
Validation loss: 1.705567018960112

Epoch: 6| Step: 6
Training loss: 0.6531385183334351
Validation loss: 1.735931424684422

Epoch: 6| Step: 7
Training loss: 0.5737849473953247
Validation loss: 1.7412833821388982

Epoch: 6| Step: 8
Training loss: 0.6453535556793213
Validation loss: 1.7373046054634997

Epoch: 6| Step: 9
Training loss: 0.6175809502601624
Validation loss: 1.7549430016548402

Epoch: 6| Step: 10
Training loss: 0.5758476257324219
Validation loss: 1.7938782540700768

Epoch: 6| Step: 11
Training loss: 0.6705126762390137
Validation loss: 1.8307001449728524

Epoch: 6| Step: 12
Training loss: 0.6925941705703735
Validation loss: 1.8318519515375937

Epoch: 6| Step: 13
Training loss: 0.7124469876289368
Validation loss: 1.8623741442157375

Epoch: 272| Step: 0
Training loss: 0.42283034324645996
Validation loss: 1.8677807084975704

Epoch: 6| Step: 1
Training loss: 0.455999493598938
Validation loss: 1.8388176810356878

Epoch: 6| Step: 2
Training loss: 0.6372660398483276
Validation loss: 1.8508273286204184

Epoch: 6| Step: 3
Training loss: 0.7479879260063171
Validation loss: 1.857173950441422

Epoch: 6| Step: 4
Training loss: 0.7102012038230896
Validation loss: 1.8264263214603547

Epoch: 6| Step: 5
Training loss: 0.5942531824111938
Validation loss: 1.8401708769541916

Epoch: 6| Step: 6
Training loss: 0.31923142075538635
Validation loss: 1.8163798316832511

Epoch: 6| Step: 7
Training loss: 0.7348500490188599
Validation loss: 1.7961124168929232

Epoch: 6| Step: 8
Training loss: 0.7306069731712341
Validation loss: 1.7963500151070215

Epoch: 6| Step: 9
Training loss: 0.48855075240135193
Validation loss: 1.7817509943439114

Epoch: 6| Step: 10
Training loss: 0.5230321884155273
Validation loss: 1.7588747444973196

Epoch: 6| Step: 11
Training loss: 0.7632362246513367
Validation loss: 1.7894717006273166

Epoch: 6| Step: 12
Training loss: 0.6019260287284851
Validation loss: 1.7591768541643698

Epoch: 6| Step: 13
Training loss: 0.39543259143829346
Validation loss: 1.737514776568259

Epoch: 273| Step: 0
Training loss: 0.36203116178512573
Validation loss: 1.7019052761857227

Epoch: 6| Step: 1
Training loss: 0.7148764729499817
Validation loss: 1.7078174685919156

Epoch: 6| Step: 2
Training loss: 0.4699641466140747
Validation loss: 1.7492300361715338

Epoch: 6| Step: 3
Training loss: 0.7019205093383789
Validation loss: 1.7322323629933019

Epoch: 6| Step: 4
Training loss: 0.5659036636352539
Validation loss: 1.729675680719396

Epoch: 6| Step: 5
Training loss: 0.5590541958808899
Validation loss: 1.720147148255379

Epoch: 6| Step: 6
Training loss: 0.6023088097572327
Validation loss: 1.7577397554151473

Epoch: 6| Step: 7
Training loss: 0.5905587077140808
Validation loss: 1.7346651631016885

Epoch: 6| Step: 8
Training loss: 0.2714824676513672
Validation loss: 1.753332584134994

Epoch: 6| Step: 9
Training loss: 0.5954976081848145
Validation loss: 1.751140530391406

Epoch: 6| Step: 10
Training loss: 0.6414828896522522
Validation loss: 1.792827470328218

Epoch: 6| Step: 11
Training loss: 0.7328485250473022
Validation loss: 1.7817621218260897

Epoch: 6| Step: 12
Training loss: 0.35162580013275146
Validation loss: 1.7785824550095426

Epoch: 6| Step: 13
Training loss: 0.6401420831680298
Validation loss: 1.7875075417180215

Epoch: 274| Step: 0
Training loss: 0.3498460352420807
Validation loss: 1.7622980481834822

Epoch: 6| Step: 1
Training loss: 0.5258164405822754
Validation loss: 1.7745736786114272

Epoch: 6| Step: 2
Training loss: 0.6169098615646362
Validation loss: 1.7612862689520723

Epoch: 6| Step: 3
Training loss: 0.6165305972099304
Validation loss: 1.78031462495045

Epoch: 6| Step: 4
Training loss: 0.2703801393508911
Validation loss: 1.7954933386977001

Epoch: 6| Step: 5
Training loss: 0.4794090688228607
Validation loss: 1.7741828605692873

Epoch: 6| Step: 6
Training loss: 0.49898141622543335
Validation loss: 1.752653109130039

Epoch: 6| Step: 7
Training loss: 0.443246066570282
Validation loss: 1.7574341117694814

Epoch: 6| Step: 8
Training loss: 0.5952115058898926
Validation loss: 1.7666519508566907

Epoch: 6| Step: 9
Training loss: 0.5910444259643555
Validation loss: 1.7620575146008564

Epoch: 6| Step: 10
Training loss: 0.8166055679321289
Validation loss: 1.7915796810580837

Epoch: 6| Step: 11
Training loss: 0.720258355140686
Validation loss: 1.7952261124887774

Epoch: 6| Step: 12
Training loss: 0.29835939407348633
Validation loss: 1.7681101765683902

Epoch: 6| Step: 13
Training loss: 0.8946354985237122
Validation loss: 1.7728414266340193

Epoch: 275| Step: 0
Training loss: 0.8933570384979248
Validation loss: 1.7636899563574022

Epoch: 6| Step: 1
Training loss: 0.534042239189148
Validation loss: 1.7554812277517011

Epoch: 6| Step: 2
Training loss: 0.37911608815193176
Validation loss: 1.7690268716504496

Epoch: 6| Step: 3
Training loss: 0.33982378244400024
Validation loss: 1.7651496651352092

Epoch: 6| Step: 4
Training loss: 0.4479805529117584
Validation loss: 1.7529426428579515

Epoch: 6| Step: 5
Training loss: 0.5504297614097595
Validation loss: 1.7587654090696765

Epoch: 6| Step: 6
Training loss: 0.38510608673095703
Validation loss: 1.7490957488295853

Epoch: 6| Step: 7
Training loss: 0.38907545804977417
Validation loss: 1.7455205891721992

Epoch: 6| Step: 8
Training loss: 0.59892737865448
Validation loss: 1.7495824124223442

Epoch: 6| Step: 9
Training loss: 0.2807958722114563
Validation loss: 1.7550461279448641

Epoch: 6| Step: 10
Training loss: 0.6895191669464111
Validation loss: 1.7781288828901065

Epoch: 6| Step: 11
Training loss: 0.48802509903907776
Validation loss: 1.7886550913574875

Epoch: 6| Step: 12
Training loss: 0.5499883890151978
Validation loss: 1.8119093089975336

Epoch: 6| Step: 13
Training loss: 0.9842907786369324
Validation loss: 1.8055984153542468

Epoch: 276| Step: 0
Training loss: 0.6141664981842041
Validation loss: 1.7836167376528504

Epoch: 6| Step: 1
Training loss: 0.557672917842865
Validation loss: 1.779622374042388

Epoch: 6| Step: 2
Training loss: 0.5219516158103943
Validation loss: 1.7921556324087164

Epoch: 6| Step: 3
Training loss: 0.6410117149353027
Validation loss: 1.7993635028921149

Epoch: 6| Step: 4
Training loss: 0.6465462446212769
Validation loss: 1.7966970423216462

Epoch: 6| Step: 5
Training loss: 0.49716830253601074
Validation loss: 1.8253049747918242

Epoch: 6| Step: 6
Training loss: 0.5827100276947021
Validation loss: 1.809495436247959

Epoch: 6| Step: 7
Training loss: 0.343052476644516
Validation loss: 1.7842266892874112

Epoch: 6| Step: 8
Training loss: 0.5950011014938354
Validation loss: 1.8079047318427794

Epoch: 6| Step: 9
Training loss: 0.45511263608932495
Validation loss: 1.7978582343747538

Epoch: 6| Step: 10
Training loss: 0.5201438665390015
Validation loss: 1.8255816403255667

Epoch: 6| Step: 11
Training loss: 0.49083244800567627
Validation loss: 1.7896806501573133

Epoch: 6| Step: 12
Training loss: 0.42474713921546936
Validation loss: 1.8345231368977537

Epoch: 6| Step: 13
Training loss: 0.31457892060279846
Validation loss: 1.7941899632894864

Epoch: 277| Step: 0
Training loss: 0.5915107727050781
Validation loss: 1.795940403015383

Epoch: 6| Step: 1
Training loss: 0.5082219243049622
Validation loss: 1.7482920897904264

Epoch: 6| Step: 2
Training loss: 0.41135096549987793
Validation loss: 1.751649345121076

Epoch: 6| Step: 3
Training loss: 0.5778517127037048
Validation loss: 1.730299001098961

Epoch: 6| Step: 4
Training loss: 0.5649769306182861
Validation loss: 1.733659166161732

Epoch: 6| Step: 5
Training loss: 0.5715019106864929
Validation loss: 1.7541732134357575

Epoch: 6| Step: 6
Training loss: 0.4604955017566681
Validation loss: 1.7780267295017038

Epoch: 6| Step: 7
Training loss: 0.7202032804489136
Validation loss: 1.7951250871022542

Epoch: 6| Step: 8
Training loss: 0.39982372522354126
Validation loss: 1.7889599569382206

Epoch: 6| Step: 9
Training loss: 0.5915164351463318
Validation loss: 1.7916847108512797

Epoch: 6| Step: 10
Training loss: 0.7418435215950012
Validation loss: 1.7852435701636857

Epoch: 6| Step: 11
Training loss: 0.4573984444141388
Validation loss: 1.7526234439624253

Epoch: 6| Step: 12
Training loss: 0.45551711320877075
Validation loss: 1.7588480416164602

Epoch: 6| Step: 13
Training loss: 0.564270555973053
Validation loss: 1.7465611157878753

Epoch: 278| Step: 0
Training loss: 0.5029069781303406
Validation loss: 1.7516606892308881

Epoch: 6| Step: 1
Training loss: 0.7397793531417847
Validation loss: 1.7395453145427089

Epoch: 6| Step: 2
Training loss: 0.45428138971328735
Validation loss: 1.7388553132293045

Epoch: 6| Step: 3
Training loss: 0.5696428418159485
Validation loss: 1.7662937371961531

Epoch: 6| Step: 4
Training loss: 0.6168177127838135
Validation loss: 1.782536357961675

Epoch: 6| Step: 5
Training loss: 0.5717682838439941
Validation loss: 1.787378752103416

Epoch: 6| Step: 6
Training loss: 0.32746630907058716
Validation loss: 1.7735064106602823

Epoch: 6| Step: 7
Training loss: 0.5011081695556641
Validation loss: 1.7641495107322611

Epoch: 6| Step: 8
Training loss: 0.7718909978866577
Validation loss: 1.7875175693983674

Epoch: 6| Step: 9
Training loss: 0.4326323866844177
Validation loss: 1.7624610495823685

Epoch: 6| Step: 10
Training loss: 0.5965158343315125
Validation loss: 1.7625008821487427

Epoch: 6| Step: 11
Training loss: 0.38486722111701965
Validation loss: 1.7680104547931301

Epoch: 6| Step: 12
Training loss: 0.2502114474773407
Validation loss: 1.784045373239825

Epoch: 6| Step: 13
Training loss: 0.4528980255126953
Validation loss: 1.7752403789950955

Epoch: 279| Step: 0
Training loss: 0.29388707876205444
Validation loss: 1.7452802786263086

Epoch: 6| Step: 1
Training loss: 0.510886549949646
Validation loss: 1.7862959459263792

Epoch: 6| Step: 2
Training loss: 0.550396740436554
Validation loss: 1.778109868367513

Epoch: 6| Step: 3
Training loss: 0.46445232629776
Validation loss: 1.7780368661367765

Epoch: 6| Step: 4
Training loss: 0.5555821657180786
Validation loss: 1.7736326520160963

Epoch: 6| Step: 5
Training loss: 0.3180256485939026
Validation loss: 1.7472015273186468

Epoch: 6| Step: 6
Training loss: 0.7927118539810181
Validation loss: 1.7583546305215487

Epoch: 6| Step: 7
Training loss: 0.567855179309845
Validation loss: 1.7579168837557557

Epoch: 6| Step: 8
Training loss: 0.4600222706794739
Validation loss: 1.741952617963155

Epoch: 6| Step: 9
Training loss: 0.6531315445899963
Validation loss: 1.7637868401824788

Epoch: 6| Step: 10
Training loss: 0.4252378046512604
Validation loss: 1.7728138546789847

Epoch: 6| Step: 11
Training loss: 0.43067193031311035
Validation loss: 1.7459825828511228

Epoch: 6| Step: 12
Training loss: 0.48532941937446594
Validation loss: 1.7313473263094503

Epoch: 6| Step: 13
Training loss: 0.5790590643882751
Validation loss: 1.7264036696444276

Epoch: 280| Step: 0
Training loss: 0.48782825469970703
Validation loss: 1.7249030015801872

Epoch: 6| Step: 1
Training loss: 0.38279715180397034
Validation loss: 1.710727330177061

Epoch: 6| Step: 2
Training loss: 0.29934030771255493
Validation loss: 1.7194954464512486

Epoch: 6| Step: 3
Training loss: 0.6864335536956787
Validation loss: 1.7378341459458875

Epoch: 6| Step: 4
Training loss: 0.6310586929321289
Validation loss: 1.7128337121778918

Epoch: 6| Step: 5
Training loss: 0.5069424510002136
Validation loss: 1.7663543865244875

Epoch: 6| Step: 6
Training loss: 0.4864436089992523
Validation loss: 1.7350324071863645

Epoch: 6| Step: 7
Training loss: 0.36711564660072327
Validation loss: 1.7586071542514268

Epoch: 6| Step: 8
Training loss: 0.6119499206542969
Validation loss: 1.773136051752234

Epoch: 6| Step: 9
Training loss: 0.6118011474609375
Validation loss: 1.8022557573933755

Epoch: 6| Step: 10
Training loss: 0.4786936640739441
Validation loss: 1.8109579393940587

Epoch: 6| Step: 11
Training loss: 0.501278817653656
Validation loss: 1.8059478677729124

Epoch: 6| Step: 12
Training loss: 0.6519834995269775
Validation loss: 1.81773054727944

Epoch: 6| Step: 13
Training loss: 0.6219193935394287
Validation loss: 1.8055875185997254

Epoch: 281| Step: 0
Training loss: 0.8938378691673279
Validation loss: 1.820394508300289

Epoch: 6| Step: 1
Training loss: 0.4386668801307678
Validation loss: 1.8071618541594474

Epoch: 6| Step: 2
Training loss: 0.4278942346572876
Validation loss: 1.7909520864486694

Epoch: 6| Step: 3
Training loss: 0.319571852684021
Validation loss: 1.7812623195750739

Epoch: 6| Step: 4
Training loss: 0.5887787938117981
Validation loss: 1.78354605936235

Epoch: 6| Step: 5
Training loss: 0.5295275449752808
Validation loss: 1.7840063379656883

Epoch: 6| Step: 6
Training loss: 0.6598929166793823
Validation loss: 1.8036717599438084

Epoch: 6| Step: 7
Training loss: 0.7452512979507446
Validation loss: 1.818262222633567

Epoch: 6| Step: 8
Training loss: 0.26508238911628723
Validation loss: 1.8370966424224198

Epoch: 6| Step: 9
Training loss: 0.47050240635871887
Validation loss: 1.8098185895591654

Epoch: 6| Step: 10
Training loss: 0.48159441351890564
Validation loss: 1.760148544465342

Epoch: 6| Step: 11
Training loss: 0.41398942470550537
Validation loss: 1.7486554243231331

Epoch: 6| Step: 12
Training loss: 0.4416784346103668
Validation loss: 1.7152188234431769

Epoch: 6| Step: 13
Training loss: 0.2655200958251953
Validation loss: 1.6846047486028364

Epoch: 282| Step: 0
Training loss: 0.3511850833892822
Validation loss: 1.698169567251718

Epoch: 6| Step: 1
Training loss: 0.4845584034919739
Validation loss: 1.6968846128832908

Epoch: 6| Step: 2
Training loss: 0.35665780305862427
Validation loss: 1.7090281466002106

Epoch: 6| Step: 3
Training loss: 0.7048437595367432
Validation loss: 1.6860168159648936

Epoch: 6| Step: 4
Training loss: 0.4877948760986328
Validation loss: 1.729579931946211

Epoch: 6| Step: 5
Training loss: 0.5167602300643921
Validation loss: 1.724184956601871

Epoch: 6| Step: 6
Training loss: 0.3903158903121948
Validation loss: 1.760011407636827

Epoch: 6| Step: 7
Training loss: 0.4073019027709961
Validation loss: 1.7884554991158106

Epoch: 6| Step: 8
Training loss: 0.7317991256713867
Validation loss: 1.7868088035173313

Epoch: 6| Step: 9
Training loss: 0.4188997149467468
Validation loss: 1.8018763116610947

Epoch: 6| Step: 10
Training loss: 0.3730030655860901
Validation loss: 1.8455834555369552

Epoch: 6| Step: 11
Training loss: 0.6212707161903381
Validation loss: 1.8383905169784382

Epoch: 6| Step: 12
Training loss: 0.4891830086708069
Validation loss: 1.8329305007893553

Epoch: 6| Step: 13
Training loss: 0.5479929447174072
Validation loss: 1.7883012474224131

Epoch: 283| Step: 0
Training loss: 0.5965152978897095
Validation loss: 1.7565688497276717

Epoch: 6| Step: 1
Training loss: 0.5031757354736328
Validation loss: 1.737677506221238

Epoch: 6| Step: 2
Training loss: 0.5374613404273987
Validation loss: 1.7371548888503865

Epoch: 6| Step: 3
Training loss: 0.5226027965545654
Validation loss: 1.7405977556782384

Epoch: 6| Step: 4
Training loss: 0.7034553289413452
Validation loss: 1.7420887934264315

Epoch: 6| Step: 5
Training loss: 0.6257066130638123
Validation loss: 1.7497571693953646

Epoch: 6| Step: 6
Training loss: 0.30711328983306885
Validation loss: 1.7113549260682956

Epoch: 6| Step: 7
Training loss: 0.4307851791381836
Validation loss: 1.7460498450904764

Epoch: 6| Step: 8
Training loss: 0.4796220660209656
Validation loss: 1.747119636945827

Epoch: 6| Step: 9
Training loss: 0.27665090560913086
Validation loss: 1.7998544003373833

Epoch: 6| Step: 10
Training loss: 0.5169613361358643
Validation loss: 1.8327895813090826

Epoch: 6| Step: 11
Training loss: 0.6715549230575562
Validation loss: 1.7907674645864835

Epoch: 6| Step: 12
Training loss: 0.3572812080383301
Validation loss: 1.8017835565792617

Epoch: 6| Step: 13
Training loss: 0.5380933284759521
Validation loss: 1.7893991598518946

Epoch: 284| Step: 0
Training loss: 0.5479959845542908
Validation loss: 1.7781325463325746

Epoch: 6| Step: 1
Training loss: 0.3501087725162506
Validation loss: 1.7592395672234156

Epoch: 6| Step: 2
Training loss: 0.4102628231048584
Validation loss: 1.8069138732007755

Epoch: 6| Step: 3
Training loss: 0.6018069386482239
Validation loss: 1.796577900968572

Epoch: 6| Step: 4
Training loss: 0.8007489442825317
Validation loss: 1.7899370219117852

Epoch: 6| Step: 5
Training loss: 0.39623939990997314
Validation loss: 1.7980486205829087

Epoch: 6| Step: 6
Training loss: 0.41756054759025574
Validation loss: 1.774209669841233

Epoch: 6| Step: 7
Training loss: 0.4640014171600342
Validation loss: 1.8197458790194603

Epoch: 6| Step: 8
Training loss: 0.44913139939308167
Validation loss: 1.8336433620863064

Epoch: 6| Step: 9
Training loss: 0.541671097278595
Validation loss: 1.797907147356259

Epoch: 6| Step: 10
Training loss: 0.49499738216400146
Validation loss: 1.8050549773759739

Epoch: 6| Step: 11
Training loss: 0.617012619972229
Validation loss: 1.7705009432249172

Epoch: 6| Step: 12
Training loss: 0.2693203091621399
Validation loss: 1.7749960678879932

Epoch: 6| Step: 13
Training loss: 0.37905871868133545
Validation loss: 1.7478839018011605

Epoch: 285| Step: 0
Training loss: 0.4114076495170593
Validation loss: 1.7561529554346555

Epoch: 6| Step: 1
Training loss: 0.37467408180236816
Validation loss: 1.7461336684483353

Epoch: 6| Step: 2
Training loss: 0.4029913544654846
Validation loss: 1.75239533762778

Epoch: 6| Step: 3
Training loss: 0.2973814606666565
Validation loss: 1.7476730333861483

Epoch: 6| Step: 4
Training loss: 0.4763101041316986
Validation loss: 1.7600034859872633

Epoch: 6| Step: 5
Training loss: 0.41106826066970825
Validation loss: 1.7688259334974392

Epoch: 6| Step: 6
Training loss: 0.5073965787887573
Validation loss: 1.7747668130423433

Epoch: 6| Step: 7
Training loss: 0.5476187467575073
Validation loss: 1.7653875222770117

Epoch: 6| Step: 8
Training loss: 0.8444679975509644
Validation loss: 1.746893972478887

Epoch: 6| Step: 9
Training loss: 0.6180167198181152
Validation loss: 1.7434843752973823

Epoch: 6| Step: 10
Training loss: 0.25461089611053467
Validation loss: 1.7185723268857567

Epoch: 6| Step: 11
Training loss: 0.6564258337020874
Validation loss: 1.7314130901008524

Epoch: 6| Step: 12
Training loss: 0.4139455556869507
Validation loss: 1.7419455384695401

Epoch: 6| Step: 13
Training loss: 0.5668167471885681
Validation loss: 1.7371456315440517

Epoch: 286| Step: 0
Training loss: 0.509081244468689
Validation loss: 1.7637641288900887

Epoch: 6| Step: 1
Training loss: 0.7894535064697266
Validation loss: 1.7684366908124698

Epoch: 6| Step: 2
Training loss: 0.3037474751472473
Validation loss: 1.756865393730902

Epoch: 6| Step: 3
Training loss: 0.39265164732933044
Validation loss: 1.7548698930330173

Epoch: 6| Step: 4
Training loss: 0.3676273226737976
Validation loss: 1.7588779926300049

Epoch: 6| Step: 5
Training loss: 0.36325445771217346
Validation loss: 1.8005151851202852

Epoch: 6| Step: 6
Training loss: 0.6900782585144043
Validation loss: 1.8339443219605314

Epoch: 6| Step: 7
Training loss: 0.822432816028595
Validation loss: 1.8310640447883195

Epoch: 6| Step: 8
Training loss: 0.6332599520683289
Validation loss: 1.8327092893661991

Epoch: 6| Step: 9
Training loss: 0.39842158555984497
Validation loss: 1.8242283815978675

Epoch: 6| Step: 10
Training loss: 0.20789086818695068
Validation loss: 1.7687572920194237

Epoch: 6| Step: 11
Training loss: 0.44432657957077026
Validation loss: 1.7513869718838764

Epoch: 6| Step: 12
Training loss: 0.40133780241012573
Validation loss: 1.7342584133148193

Epoch: 6| Step: 13
Training loss: 0.645949125289917
Validation loss: 1.7299607799899193

Epoch: 287| Step: 0
Training loss: 0.6522963047027588
Validation loss: 1.7242850539504841

Epoch: 6| Step: 1
Training loss: 0.5641465187072754
Validation loss: 1.772949239259125

Epoch: 6| Step: 2
Training loss: 0.582076907157898
Validation loss: 1.8110204383891115

Epoch: 6| Step: 3
Training loss: 0.3404678702354431
Validation loss: 1.7884420502570368

Epoch: 6| Step: 4
Training loss: 0.4448779821395874
Validation loss: 1.8304887561387913

Epoch: 6| Step: 5
Training loss: 0.4961615204811096
Validation loss: 1.8435099855546029

Epoch: 6| Step: 6
Training loss: 0.40576356649398804
Validation loss: 1.8365263913267402

Epoch: 6| Step: 7
Training loss: 0.5705135464668274
Validation loss: 1.8474604058009323

Epoch: 6| Step: 8
Training loss: 0.23383484780788422
Validation loss: 1.8187600739540593

Epoch: 6| Step: 9
Training loss: 0.7026641368865967
Validation loss: 1.8088537864787604

Epoch: 6| Step: 10
Training loss: 0.5703310966491699
Validation loss: 1.7922663073385916

Epoch: 6| Step: 11
Training loss: 0.27591097354888916
Validation loss: 1.7789772031127766

Epoch: 6| Step: 12
Training loss: 0.31765955686569214
Validation loss: 1.7515916798704414

Epoch: 6| Step: 13
Training loss: 0.39732664823532104
Validation loss: 1.725595551152383

Epoch: 288| Step: 0
Training loss: 0.37745195627212524
Validation loss: 1.7093111584263463

Epoch: 6| Step: 1
Training loss: 0.4126478135585785
Validation loss: 1.6764766477769422

Epoch: 6| Step: 2
Training loss: 0.24516744911670685
Validation loss: 1.6874871253967285

Epoch: 6| Step: 3
Training loss: 0.39832746982574463
Validation loss: 1.6895550758607927

Epoch: 6| Step: 4
Training loss: 0.7848834991455078
Validation loss: 1.7155442878764162

Epoch: 6| Step: 5
Training loss: 0.35196825861930847
Validation loss: 1.7460637912955335

Epoch: 6| Step: 6
Training loss: 0.6560117602348328
Validation loss: 1.7381931402349984

Epoch: 6| Step: 7
Training loss: 0.32741546630859375
Validation loss: 1.7556371765751992

Epoch: 6| Step: 8
Training loss: 0.6189634203910828
Validation loss: 1.7252904292075866

Epoch: 6| Step: 9
Training loss: 0.6405105590820312
Validation loss: 1.7103460860508743

Epoch: 6| Step: 10
Training loss: 0.5799989700317383
Validation loss: 1.7258295660377831

Epoch: 6| Step: 11
Training loss: 0.49558937549591064
Validation loss: 1.7454547907716484

Epoch: 6| Step: 12
Training loss: 0.3418876826763153
Validation loss: 1.757769048854869

Epoch: 6| Step: 13
Training loss: 0.5124858617782593
Validation loss: 1.748807757131515

Epoch: 289| Step: 0
Training loss: 0.42949068546295166
Validation loss: 1.7638291415347849

Epoch: 6| Step: 1
Training loss: 0.6131271123886108
Validation loss: 1.7956743265992852

Epoch: 6| Step: 2
Training loss: 0.5157269239425659
Validation loss: 1.7903506960920108

Epoch: 6| Step: 3
Training loss: 0.4606504440307617
Validation loss: 1.7987502364702121

Epoch: 6| Step: 4
Training loss: 0.3838910162448883
Validation loss: 1.7889058077207176

Epoch: 6| Step: 5
Training loss: 0.49613022804260254
Validation loss: 1.7822612421486967

Epoch: 6| Step: 6
Training loss: 0.5390336513519287
Validation loss: 1.7864733537038167

Epoch: 6| Step: 7
Training loss: 0.5790327191352844
Validation loss: 1.776473815082222

Epoch: 6| Step: 8
Training loss: 0.4560621678829193
Validation loss: 1.783648713942497

Epoch: 6| Step: 9
Training loss: 0.46599966287612915
Validation loss: 1.801707693325576

Epoch: 6| Step: 10
Training loss: 0.3501746952533722
Validation loss: 1.7946335269558815

Epoch: 6| Step: 11
Training loss: 0.49377545714378357
Validation loss: 1.7680192096259004

Epoch: 6| Step: 12
Training loss: 0.41290387511253357
Validation loss: 1.7653440147317865

Epoch: 6| Step: 13
Training loss: 0.5556738972663879
Validation loss: 1.749492201753842

Epoch: 290| Step: 0
Training loss: 0.24899639189243317
Validation loss: 1.7302263167596632

Epoch: 6| Step: 1
Training loss: 0.568264901638031
Validation loss: 1.7226372444501488

Epoch: 6| Step: 2
Training loss: 0.4872789978981018
Validation loss: 1.6850341263637747

Epoch: 6| Step: 3
Training loss: 0.4236869215965271
Validation loss: 1.7074363282931748

Epoch: 6| Step: 4
Training loss: 0.5568540692329407
Validation loss: 1.701214321198002

Epoch: 6| Step: 5
Training loss: 0.32668688893318176
Validation loss: 1.7186156613852388

Epoch: 6| Step: 6
Training loss: 0.5330927968025208
Validation loss: 1.7002982067805466

Epoch: 6| Step: 7
Training loss: 0.7154358625411987
Validation loss: 1.6807289520899455

Epoch: 6| Step: 8
Training loss: 0.3264898359775543
Validation loss: 1.6947851437394337

Epoch: 6| Step: 9
Training loss: 0.5922205448150635
Validation loss: 1.699850921989769

Epoch: 6| Step: 10
Training loss: 0.7948888540267944
Validation loss: 1.7081523979863813

Epoch: 6| Step: 11
Training loss: 0.3076222836971283
Validation loss: 1.7412916255253617

Epoch: 6| Step: 12
Training loss: 0.29250067472457886
Validation loss: 1.7443223332846036

Epoch: 6| Step: 13
Training loss: 0.3219063878059387
Validation loss: 1.7609175353921869

Epoch: 291| Step: 0
Training loss: 0.3351362347602844
Validation loss: 1.7733753906783236

Epoch: 6| Step: 1
Training loss: 0.49719029664993286
Validation loss: 1.7723623142447522

Epoch: 6| Step: 2
Training loss: 0.35366466641426086
Validation loss: 1.8070167892722673

Epoch: 6| Step: 3
Training loss: 0.4543731212615967
Validation loss: 1.845384128632084

Epoch: 6| Step: 4
Training loss: 0.49382394552230835
Validation loss: 1.8623191630968483

Epoch: 6| Step: 5
Training loss: 0.2993355393409729
Validation loss: 1.820508804372562

Epoch: 6| Step: 6
Training loss: 0.6160243153572083
Validation loss: 1.800720932663128

Epoch: 6| Step: 7
Training loss: 0.5778182744979858
Validation loss: 1.8029485120568225

Epoch: 6| Step: 8
Training loss: 0.2549566924571991
Validation loss: 1.7702297228638844

Epoch: 6| Step: 9
Training loss: 0.3695884346961975
Validation loss: 1.748408858494092

Epoch: 6| Step: 10
Training loss: 0.3055020272731781
Validation loss: 1.7377371275296776

Epoch: 6| Step: 11
Training loss: 0.4905480444431305
Validation loss: 1.7421199044873636

Epoch: 6| Step: 12
Training loss: 0.4765884578227997
Validation loss: 1.7138751809315016

Epoch: 6| Step: 13
Training loss: 0.5847819447517395
Validation loss: 1.7448934085907475

Epoch: 292| Step: 0
Training loss: 0.6671707034111023
Validation loss: 1.7373641216626732

Epoch: 6| Step: 1
Training loss: 0.6402335166931152
Validation loss: 1.750317406910722

Epoch: 6| Step: 2
Training loss: 0.5861753821372986
Validation loss: 1.7419060353309876

Epoch: 6| Step: 3
Training loss: 0.4246388375759125
Validation loss: 1.7522564959782425

Epoch: 6| Step: 4
Training loss: 0.23204970359802246
Validation loss: 1.7564082773782874

Epoch: 6| Step: 5
Training loss: 0.15208691358566284
Validation loss: 1.7353141974377375

Epoch: 6| Step: 6
Training loss: 0.29716771841049194
Validation loss: 1.7273292785049768

Epoch: 6| Step: 7
Training loss: 0.4192308187484741
Validation loss: 1.741516190190469

Epoch: 6| Step: 8
Training loss: 0.4715847074985504
Validation loss: 1.7746413625696653

Epoch: 6| Step: 9
Training loss: 0.5100416541099548
Validation loss: 1.7752473610703663

Epoch: 6| Step: 10
Training loss: 0.43202221393585205
Validation loss: 1.7851435125515025

Epoch: 6| Step: 11
Training loss: 0.4337082505226135
Validation loss: 1.7744038899739583

Epoch: 6| Step: 12
Training loss: 0.5100542902946472
Validation loss: 1.7889578618029112

Epoch: 6| Step: 13
Training loss: 0.5701616406440735
Validation loss: 1.7949872785998928

Epoch: 293| Step: 0
Training loss: 0.27690309286117554
Validation loss: 1.7764060240919872

Epoch: 6| Step: 1
Training loss: 0.6978613138198853
Validation loss: 1.7266173362731934

Epoch: 6| Step: 2
Training loss: 0.7013888359069824
Validation loss: 1.7496261391588437

Epoch: 6| Step: 3
Training loss: 0.42790675163269043
Validation loss: 1.6975995174018286

Epoch: 6| Step: 4
Training loss: 0.5185480117797852
Validation loss: 1.6995344456805979

Epoch: 6| Step: 5
Training loss: 0.22969655692577362
Validation loss: 1.677208100595782

Epoch: 6| Step: 6
Training loss: 0.2634006142616272
Validation loss: 1.7100779241131199

Epoch: 6| Step: 7
Training loss: 0.2810437083244324
Validation loss: 1.6834318855757355

Epoch: 6| Step: 8
Training loss: 0.5854915380477905
Validation loss: 1.7218498119743921

Epoch: 6| Step: 9
Training loss: 0.26581430435180664
Validation loss: 1.7198641120746572

Epoch: 6| Step: 10
Training loss: 0.34301501512527466
Validation loss: 1.7218948692403815

Epoch: 6| Step: 11
Training loss: 0.5082885026931763
Validation loss: 1.7459764980500745

Epoch: 6| Step: 12
Training loss: 0.4931451976299286
Validation loss: 1.7437888178774106

Epoch: 6| Step: 13
Training loss: 0.2597864270210266
Validation loss: 1.7402413455388879

Epoch: 294| Step: 0
Training loss: 0.3428146243095398
Validation loss: 1.747327099564255

Epoch: 6| Step: 1
Training loss: 0.2998281717300415
Validation loss: 1.7305367710769817

Epoch: 6| Step: 2
Training loss: 0.669926643371582
Validation loss: 1.7413852624995734

Epoch: 6| Step: 3
Training loss: 0.5507714152336121
Validation loss: 1.7384906033033967

Epoch: 6| Step: 4
Training loss: 0.44351211190223694
Validation loss: 1.7435683768282655

Epoch: 6| Step: 5
Training loss: 0.41270020604133606
Validation loss: 1.7690647622590423

Epoch: 6| Step: 6
Training loss: 0.4315599203109741
Validation loss: 1.7522011841497114

Epoch: 6| Step: 7
Training loss: 0.36904966831207275
Validation loss: 1.742003438293293

Epoch: 6| Step: 8
Training loss: 0.37590551376342773
Validation loss: 1.7360659389085666

Epoch: 6| Step: 9
Training loss: 0.5435747504234314
Validation loss: 1.7510107768479215

Epoch: 6| Step: 10
Training loss: 0.5767449736595154
Validation loss: 1.7583447579414613

Epoch: 6| Step: 11
Training loss: 0.3628029227256775
Validation loss: 1.7537081510789934

Epoch: 6| Step: 12
Training loss: 0.2751539349555969
Validation loss: 1.7673058317553612

Epoch: 6| Step: 13
Training loss: 0.29666996002197266
Validation loss: 1.7871530530273274

Epoch: 295| Step: 0
Training loss: 0.4053793251514435
Validation loss: 1.7590113788522699

Epoch: 6| Step: 1
Training loss: 0.37895700335502625
Validation loss: 1.7538255914565055

Epoch: 6| Step: 2
Training loss: 0.5225975513458252
Validation loss: 1.7717689019377514

Epoch: 6| Step: 3
Training loss: 0.38253360986709595
Validation loss: 1.7749623278135895

Epoch: 6| Step: 4
Training loss: 0.22449372708797455
Validation loss: 1.7640708159374934

Epoch: 6| Step: 5
Training loss: 0.32050779461860657
Validation loss: 1.73301475919703

Epoch: 6| Step: 6
Training loss: 0.35475224256515503
Validation loss: 1.7345652759716075

Epoch: 6| Step: 7
Training loss: 0.3114737272262573
Validation loss: 1.7296490887159943

Epoch: 6| Step: 8
Training loss: 0.33689993619918823
Validation loss: 1.725679312982867

Epoch: 6| Step: 9
Training loss: 0.6776579022407532
Validation loss: 1.7190453788285613

Epoch: 6| Step: 10
Training loss: 0.5643718242645264
Validation loss: 1.7290924236338625

Epoch: 6| Step: 11
Training loss: 0.4814417362213135
Validation loss: 1.7050042870224162

Epoch: 6| Step: 12
Training loss: 0.3149440288543701
Validation loss: 1.7194755308089718

Epoch: 6| Step: 13
Training loss: 0.2655707597732544
Validation loss: 1.6923441066536853

Epoch: 296| Step: 0
Training loss: 0.3207641541957855
Validation loss: 1.6910695363116521

Epoch: 6| Step: 1
Training loss: 0.5379511117935181
Validation loss: 1.7274947153624667

Epoch: 6| Step: 2
Training loss: 0.45246005058288574
Validation loss: 1.7692229542680966

Epoch: 6| Step: 3
Training loss: 0.45271384716033936
Validation loss: 1.7699007629066386

Epoch: 6| Step: 4
Training loss: 0.5417056679725647
Validation loss: 1.7775021765821724

Epoch: 6| Step: 5
Training loss: 0.2833513915538788
Validation loss: 1.7643670176946988

Epoch: 6| Step: 6
Training loss: 0.30595311522483826
Validation loss: 1.7603258663608181

Epoch: 6| Step: 7
Training loss: 0.5970038771629333
Validation loss: 1.7437137121795325

Epoch: 6| Step: 8
Training loss: 0.2415214478969574
Validation loss: 1.7331838312969412

Epoch: 6| Step: 9
Training loss: 0.4110722541809082
Validation loss: 1.7604467894441338

Epoch: 6| Step: 10
Training loss: 0.33269548416137695
Validation loss: 1.7515182559208204

Epoch: 6| Step: 11
Training loss: 0.48168620467185974
Validation loss: 1.742940361781787

Epoch: 6| Step: 12
Training loss: 0.44583970308303833
Validation loss: 1.7896340252250753

Epoch: 6| Step: 13
Training loss: 0.2010544240474701
Validation loss: 1.7760095737313712

Epoch: 297| Step: 0
Training loss: 0.32246118783950806
Validation loss: 1.7631563935228574

Epoch: 6| Step: 1
Training loss: 0.24446746706962585
Validation loss: 1.7432220174420265

Epoch: 6| Step: 2
Training loss: 0.5726827383041382
Validation loss: 1.7550803897201375

Epoch: 6| Step: 3
Training loss: 0.4675229787826538
Validation loss: 1.7451398359831942

Epoch: 6| Step: 4
Training loss: 0.4441561996936798
Validation loss: 1.7164853080626457

Epoch: 6| Step: 5
Training loss: 0.21633383631706238
Validation loss: 1.760419507180491

Epoch: 6| Step: 6
Training loss: 0.4600710868835449
Validation loss: 1.7568048277208883

Epoch: 6| Step: 7
Training loss: 0.23797930777072906
Validation loss: 1.781519761649511

Epoch: 6| Step: 8
Training loss: 0.7656980752944946
Validation loss: 1.792386253674825

Epoch: 6| Step: 9
Training loss: 0.231724351644516
Validation loss: 1.7787359991381246

Epoch: 6| Step: 10
Training loss: 0.5199271440505981
Validation loss: 1.7565990712053032

Epoch: 6| Step: 11
Training loss: 0.329306960105896
Validation loss: 1.7617380119139148

Epoch: 6| Step: 12
Training loss: 0.4596260190010071
Validation loss: 1.7752462458866898

Epoch: 6| Step: 13
Training loss: 0.5249191522598267
Validation loss: 1.7669239864554456

Epoch: 298| Step: 0
Training loss: 0.2772689461708069
Validation loss: 1.7718319418609783

Epoch: 6| Step: 1
Training loss: 0.40396636724472046
Validation loss: 1.7631129994187305

Epoch: 6| Step: 2
Training loss: 0.4464692771434784
Validation loss: 1.7931419457158735

Epoch: 6| Step: 3
Training loss: 0.6586803197860718
Validation loss: 1.7679425593345397

Epoch: 6| Step: 4
Training loss: 0.527042031288147
Validation loss: 1.7946970885799778

Epoch: 6| Step: 5
Training loss: 0.442732036113739
Validation loss: 1.759115703644291

Epoch: 6| Step: 6
Training loss: 0.5446168184280396
Validation loss: 1.7586958408355713

Epoch: 6| Step: 7
Training loss: 0.33592772483825684
Validation loss: 1.7599881541344427

Epoch: 6| Step: 8
Training loss: 0.5599675178527832
Validation loss: 1.8041549267307404

Epoch: 6| Step: 9
Training loss: 0.5405476093292236
Validation loss: 1.774494513388603

Epoch: 6| Step: 10
Training loss: 0.45076850056648254
Validation loss: 1.7935978302391626

Epoch: 6| Step: 11
Training loss: 0.46227753162384033
Validation loss: 1.7670914383344754

Epoch: 6| Step: 12
Training loss: 0.30028143525123596
Validation loss: 1.8044783325605496

Epoch: 6| Step: 13
Training loss: 0.11587580293416977
Validation loss: 1.7673430878628966

Epoch: 299| Step: 0
Training loss: 0.2919638752937317
Validation loss: 1.802486696550923

Epoch: 6| Step: 1
Training loss: 0.36438170075416565
Validation loss: 1.8124017279635194

Epoch: 6| Step: 2
Training loss: 0.4541385769844055
Validation loss: 1.8025793324234665

Epoch: 6| Step: 3
Training loss: 0.5274525880813599
Validation loss: 1.817958745905148

Epoch: 6| Step: 4
Training loss: 0.48570600152015686
Validation loss: 1.7942617631727649

Epoch: 6| Step: 5
Training loss: 0.539786696434021
Validation loss: 1.8124431333234232

Epoch: 6| Step: 6
Training loss: 0.5292692184448242
Validation loss: 1.8097909086494035

Epoch: 6| Step: 7
Training loss: 0.6210184693336487
Validation loss: 1.7858377836083854

Epoch: 6| Step: 8
Training loss: 0.2952965199947357
Validation loss: 1.8111588416561004

Epoch: 6| Step: 9
Training loss: 0.3853437006473541
Validation loss: 1.8091728687286377

Epoch: 6| Step: 10
Training loss: 0.1946496069431305
Validation loss: 1.8185463131115

Epoch: 6| Step: 11
Training loss: 0.3942120373249054
Validation loss: 1.7943763553455312

Epoch: 6| Step: 12
Training loss: 0.36839503049850464
Validation loss: 1.780960202217102

Epoch: 6| Step: 13
Training loss: 0.40626025199890137
Validation loss: 1.771005786875243

Epoch: 300| Step: 0
Training loss: 0.37711256742477417
Validation loss: 1.7784674372724307

Epoch: 6| Step: 1
Training loss: 0.5681188106536865
Validation loss: 1.7377154288753387

Epoch: 6| Step: 2
Training loss: 0.4978371262550354
Validation loss: 1.7472572736842658

Epoch: 6| Step: 3
Training loss: 0.5583909749984741
Validation loss: 1.7535097047846804

Epoch: 6| Step: 4
Training loss: 0.38785797357559204
Validation loss: 1.734727935124469

Epoch: 6| Step: 5
Training loss: 0.3459557294845581
Validation loss: 1.725626564154061

Epoch: 6| Step: 6
Training loss: 0.40067070722579956
Validation loss: 1.7342564931479834

Epoch: 6| Step: 7
Training loss: 0.484855055809021
Validation loss: 1.7211500790811354

Epoch: 6| Step: 8
Training loss: 0.35703516006469727
Validation loss: 1.7038464943567913

Epoch: 6| Step: 9
Training loss: 0.33005738258361816
Validation loss: 1.7247471950387443

Epoch: 6| Step: 10
Training loss: 0.35144883394241333
Validation loss: 1.7280432831856511

Epoch: 6| Step: 11
Training loss: 0.32644152641296387
Validation loss: 1.7226933727982223

Epoch: 6| Step: 12
Training loss: 0.4097176790237427
Validation loss: 1.71883987867704

Epoch: 6| Step: 13
Training loss: 0.41587966680526733
Validation loss: 1.7282443367024904

Testing loss: 2.029174894756741
