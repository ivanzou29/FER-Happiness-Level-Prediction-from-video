Epoch: 1| Step: 0
Training loss: 5.538975715637207
Validation loss: 5.247188050259826

Epoch: 5| Step: 1
Training loss: 4.1730241775512695
Validation loss: 5.230607550631287

Epoch: 5| Step: 2
Training loss: 5.410543918609619
Validation loss: 5.217030545716645

Epoch: 5| Step: 3
Training loss: 5.34511137008667
Validation loss: 5.2035270096153345

Epoch: 5| Step: 4
Training loss: 5.286041736602783
Validation loss: 5.1887548867092335

Epoch: 5| Step: 5
Training loss: 5.109236240386963
Validation loss: 5.172394537156628

Epoch: 5| Step: 6
Training loss: 4.923365592956543
Validation loss: 5.153018956543297

Epoch: 5| Step: 7
Training loss: 4.054247856140137
Validation loss: 5.130954885995516

Epoch: 5| Step: 8
Training loss: 5.538331031799316
Validation loss: 5.104814514037101

Epoch: 5| Step: 9
Training loss: 4.831107139587402
Validation loss: 5.074821728532032

Epoch: 5| Step: 10
Training loss: 4.218334674835205
Validation loss: 5.040435908943095

Epoch: 2| Step: 0
Training loss: 4.435163974761963
Validation loss: 5.000057076895109

Epoch: 5| Step: 1
Training loss: 4.921523571014404
Validation loss: 4.9545457132401

Epoch: 5| Step: 2
Training loss: 3.989612579345703
Validation loss: 4.903186941659579

Epoch: 5| Step: 3
Training loss: 5.299616813659668
Validation loss: 4.844023130273306

Epoch: 5| Step: 4
Training loss: 5.175861358642578
Validation loss: 4.778024945207822

Epoch: 5| Step: 5
Training loss: 5.36796760559082
Validation loss: 4.706922720837337

Epoch: 5| Step: 6
Training loss: 3.776959180831909
Validation loss: 4.6308137063057195

Epoch: 5| Step: 7
Training loss: 4.282475471496582
Validation loss: 4.550644274680845

Epoch: 5| Step: 8
Training loss: 4.507828712463379
Validation loss: 4.470113692745086

Epoch: 5| Step: 9
Training loss: 4.162746906280518
Validation loss: 4.389637716354862

Epoch: 5| Step: 10
Training loss: 3.1108169555664062
Validation loss: 4.31051105581304

Epoch: 3| Step: 0
Training loss: 4.793537139892578
Validation loss: 4.2363407816938174

Epoch: 5| Step: 1
Training loss: 4.2393388748168945
Validation loss: 4.166476962386921

Epoch: 5| Step: 2
Training loss: 3.115424633026123
Validation loss: 4.099587261035878

Epoch: 5| Step: 3
Training loss: 4.514245510101318
Validation loss: 4.03760596757294

Epoch: 5| Step: 4
Training loss: 3.65195894241333
Validation loss: 3.9778532904963337

Epoch: 5| Step: 5
Training loss: 3.55351185798645
Validation loss: 3.92163912967969

Epoch: 5| Step: 6
Training loss: 3.766977310180664
Validation loss: 3.8677682517677225

Epoch: 5| Step: 7
Training loss: 3.825047016143799
Validation loss: 3.814997457688855

Epoch: 5| Step: 8
Training loss: 3.687577486038208
Validation loss: 3.7626723371526247

Epoch: 5| Step: 9
Training loss: 2.960409641265869
Validation loss: 3.7132649011509393

Epoch: 5| Step: 10
Training loss: 3.6045143604278564
Validation loss: 3.670735174609769

Epoch: 4| Step: 0
Training loss: 3.1155505180358887
Validation loss: 3.631295034962316

Epoch: 5| Step: 1
Training loss: 3.774972438812256
Validation loss: 3.5992180660206783

Epoch: 5| Step: 2
Training loss: 3.403812885284424
Validation loss: 3.5706959873117428

Epoch: 5| Step: 3
Training loss: 2.794663906097412
Validation loss: 3.5466813118227067

Epoch: 5| Step: 4
Training loss: 3.479832410812378
Validation loss: 3.534782117412936

Epoch: 5| Step: 5
Training loss: 4.209610939025879
Validation loss: 3.546526232073384

Epoch: 5| Step: 6
Training loss: 3.7341384887695312
Validation loss: 3.5031213273284254

Epoch: 5| Step: 7
Training loss: 2.5988001823425293
Validation loss: 3.467878649311681

Epoch: 5| Step: 8
Training loss: 3.7404122352600098
Validation loss: 3.4505355486305813

Epoch: 5| Step: 9
Training loss: 3.8388009071350098
Validation loss: 3.4382630009805

Epoch: 5| Step: 10
Training loss: 3.1612555980682373
Validation loss: 3.4264397980064474

Epoch: 5| Step: 0
Training loss: 3.771923780441284
Validation loss: 3.414684018781108

Epoch: 5| Step: 1
Training loss: 3.6680312156677246
Validation loss: 3.386976529193181

Epoch: 5| Step: 2
Training loss: 3.370182752609253
Validation loss: 3.3779893126539005

Epoch: 5| Step: 3
Training loss: 3.8525893688201904
Validation loss: 3.3578346365241596

Epoch: 5| Step: 4
Training loss: 2.602782726287842
Validation loss: 3.346316568313106

Epoch: 5| Step: 5
Training loss: 2.5066778659820557
Validation loss: 3.3371129266677366

Epoch: 5| Step: 6
Training loss: 3.550779342651367
Validation loss: 3.3301846545229674

Epoch: 5| Step: 7
Training loss: 3.393238067626953
Validation loss: 3.324576747032904

Epoch: 5| Step: 8
Training loss: 2.9387855529785156
Validation loss: 3.311232305342151

Epoch: 5| Step: 9
Training loss: 3.531576156616211
Validation loss: 3.299275980200819

Epoch: 5| Step: 10
Training loss: 3.1733603477478027
Validation loss: 3.2766432710873183

Epoch: 6| Step: 0
Training loss: 2.5704617500305176
Validation loss: 3.2558900028146724

Epoch: 5| Step: 1
Training loss: 3.4825668334960938
Validation loss: 3.245000495705553

Epoch: 5| Step: 2
Training loss: 3.010087013244629
Validation loss: 3.2395393592055126

Epoch: 5| Step: 3
Training loss: 3.099233627319336
Validation loss: 3.211801072602631

Epoch: 5| Step: 4
Training loss: 2.895051956176758
Validation loss: 3.1980827341797533

Epoch: 5| Step: 5
Training loss: 3.9441490173339844
Validation loss: 3.189138002293084

Epoch: 5| Step: 6
Training loss: 2.6443703174591064
Validation loss: 3.187701681608795

Epoch: 5| Step: 7
Training loss: 3.18890118598938
Validation loss: 3.1797817240479174

Epoch: 5| Step: 8
Training loss: 2.3709921836853027
Validation loss: 3.1692996614722797

Epoch: 5| Step: 9
Training loss: 4.207402229309082
Validation loss: 3.153387064574867

Epoch: 5| Step: 10
Training loss: 3.817317247390747
Validation loss: 3.1376149192933114

Epoch: 7| Step: 0
Training loss: 2.978745222091675
Validation loss: 3.129206783028059

Epoch: 5| Step: 1
Training loss: 2.9829349517822266
Validation loss: 3.1168642505522697

Epoch: 5| Step: 2
Training loss: 2.8842480182647705
Validation loss: 3.1043734319748415

Epoch: 5| Step: 3
Training loss: 2.636352062225342
Validation loss: 3.0912506400897937

Epoch: 5| Step: 4
Training loss: 3.3961968421936035
Validation loss: 3.0752384278082077

Epoch: 5| Step: 5
Training loss: 4.262361526489258
Validation loss: 3.0644906156806537

Epoch: 5| Step: 6
Training loss: 2.869452953338623
Validation loss: 3.0547618225056636

Epoch: 5| Step: 7
Training loss: 2.2624480724334717
Validation loss: 3.0535543016208115

Epoch: 5| Step: 8
Training loss: 3.6200249195098877
Validation loss: 3.048355669103643

Epoch: 5| Step: 9
Training loss: 3.306708812713623
Validation loss: 3.0413265715363207

Epoch: 5| Step: 10
Training loss: 3.002725124359131
Validation loss: 3.0274044416284047

Epoch: 8| Step: 0
Training loss: 2.482511043548584
Validation loss: 3.0134799582983858

Epoch: 5| Step: 1
Training loss: 2.4573025703430176
Validation loss: 3.002891194435858

Epoch: 5| Step: 2
Training loss: 3.833728075027466
Validation loss: 2.995698321250177

Epoch: 5| Step: 3
Training loss: 3.1569743156433105
Validation loss: 2.988553841908773

Epoch: 5| Step: 4
Training loss: 1.8676817417144775
Validation loss: 2.982829752788749

Epoch: 5| Step: 5
Training loss: 3.0583014488220215
Validation loss: 2.975525084362235

Epoch: 5| Step: 6
Training loss: 2.9718894958496094
Validation loss: 2.9716746986553235

Epoch: 5| Step: 7
Training loss: 3.177232503890991
Validation loss: 2.9649788897524596

Epoch: 5| Step: 8
Training loss: 3.6641173362731934
Validation loss: 2.959069864724272

Epoch: 5| Step: 9
Training loss: 3.0757086277008057
Validation loss: 2.9540464852445867

Epoch: 5| Step: 10
Training loss: 3.890549659729004
Validation loss: 2.9480583206299813

Epoch: 9| Step: 0
Training loss: 3.1932690143585205
Validation loss: 2.943526819188108

Epoch: 5| Step: 1
Training loss: 3.4380061626434326
Validation loss: 2.9355047492570776

Epoch: 5| Step: 2
Training loss: 3.376620054244995
Validation loss: 2.932105436119982

Epoch: 5| Step: 3
Training loss: 3.392712116241455
Validation loss: 2.9258697058564875

Epoch: 5| Step: 4
Training loss: 2.9626624584198
Validation loss: 2.921705961227417

Epoch: 5| Step: 5
Training loss: 2.012493848800659
Validation loss: 2.9095557812721498

Epoch: 5| Step: 6
Training loss: 3.4162774085998535
Validation loss: 2.9068920817426456

Epoch: 5| Step: 7
Training loss: 3.234663724899292
Validation loss: 2.9044299484581075

Epoch: 5| Step: 8
Training loss: 2.1368157863616943
Validation loss: 2.90139026282936

Epoch: 5| Step: 9
Training loss: 3.4353489875793457
Validation loss: 2.894045998973231

Epoch: 5| Step: 10
Training loss: 2.402144193649292
Validation loss: 2.888098760317731

Epoch: 10| Step: 0
Training loss: 2.5583977699279785
Validation loss: 2.886238210944719

Epoch: 5| Step: 1
Training loss: 3.5739760398864746
Validation loss: 2.8804892570741716

Epoch: 5| Step: 2
Training loss: 3.166642665863037
Validation loss: 2.874087825898201

Epoch: 5| Step: 3
Training loss: 3.0510077476501465
Validation loss: 2.8720046730451685

Epoch: 5| Step: 4
Training loss: 3.4192211627960205
Validation loss: 2.8676066629348265

Epoch: 5| Step: 5
Training loss: 2.711707830429077
Validation loss: 2.863816217709613

Epoch: 5| Step: 6
Training loss: 3.434237003326416
Validation loss: 2.8570595941235943

Epoch: 5| Step: 7
Training loss: 2.5930066108703613
Validation loss: 2.8497919395405757

Epoch: 5| Step: 8
Training loss: 2.556335926055908
Validation loss: 2.8437611851640927

Epoch: 5| Step: 9
Training loss: 2.8830714225769043
Validation loss: 2.8410298824310303

Epoch: 5| Step: 10
Training loss: 2.6831281185150146
Validation loss: 2.840187103517594

Epoch: 11| Step: 0
Training loss: 3.279409885406494
Validation loss: 2.836619866791592

Epoch: 5| Step: 1
Training loss: 3.335547685623169
Validation loss: 2.829500631619525

Epoch: 5| Step: 2
Training loss: 2.2868449687957764
Validation loss: 2.82326707788693

Epoch: 5| Step: 3
Training loss: 2.685119390487671
Validation loss: 2.8183495947109756

Epoch: 5| Step: 4
Training loss: 3.3603007793426514
Validation loss: 2.8143275194270636

Epoch: 5| Step: 5
Training loss: 2.5475850105285645
Validation loss: 2.8081447796155046

Epoch: 5| Step: 6
Training loss: 2.852627992630005
Validation loss: 2.80326795834367

Epoch: 5| Step: 7
Training loss: 3.017780065536499
Validation loss: 2.8008460562716246

Epoch: 5| Step: 8
Training loss: 2.4861605167388916
Validation loss: 2.7994872472619496

Epoch: 5| Step: 9
Training loss: 3.256995439529419
Validation loss: 2.7958650947898946

Epoch: 5| Step: 10
Training loss: 3.3441226482391357
Validation loss: 2.7903009306999946

Epoch: 12| Step: 0
Training loss: 2.380892276763916
Validation loss: 2.7891573675217165

Epoch: 5| Step: 1
Training loss: 3.1688101291656494
Validation loss: 2.7844422401920443

Epoch: 5| Step: 2
Training loss: 2.7916557788848877
Validation loss: 2.78036504919811

Epoch: 5| Step: 3
Training loss: 3.1696815490722656
Validation loss: 2.7743488345094907

Epoch: 5| Step: 4
Training loss: 2.718018054962158
Validation loss: 2.7716126211227907

Epoch: 5| Step: 5
Training loss: 3.127974271774292
Validation loss: 2.766181743273171

Epoch: 5| Step: 6
Training loss: 2.853128671646118
Validation loss: 2.7683168636855258

Epoch: 5| Step: 7
Training loss: 3.2866597175598145
Validation loss: 2.763516823450724

Epoch: 5| Step: 8
Training loss: 3.283358335494995
Validation loss: 2.7628556272035003

Epoch: 5| Step: 9
Training loss: 2.8412649631500244
Validation loss: 2.762559644637569

Epoch: 5| Step: 10
Training loss: 2.354642152786255
Validation loss: 2.7601994596501833

Epoch: 13| Step: 0
Training loss: 2.435821294784546
Validation loss: 2.760010970536099

Epoch: 5| Step: 1
Training loss: 2.7643485069274902
Validation loss: 2.759577141013197

Epoch: 5| Step: 2
Training loss: 3.131690263748169
Validation loss: 2.7564091374797206

Epoch: 5| Step: 3
Training loss: 3.150825023651123
Validation loss: 2.749722367973738

Epoch: 5| Step: 4
Training loss: 3.3393540382385254
Validation loss: 2.78714798086433

Epoch: 5| Step: 5
Training loss: 2.572099208831787
Validation loss: 2.738501843585763

Epoch: 5| Step: 6
Training loss: 2.122528553009033
Validation loss: 2.737453112038233

Epoch: 5| Step: 7
Training loss: 3.3513576984405518
Validation loss: 2.7432453350354264

Epoch: 5| Step: 8
Training loss: 2.571810245513916
Validation loss: 2.7378973396875526

Epoch: 5| Step: 9
Training loss: 3.8190016746520996
Validation loss: 2.734774448538339

Epoch: 5| Step: 10
Training loss: 2.5963034629821777
Validation loss: 2.7321881248104956

Epoch: 14| Step: 0
Training loss: 3.5330300331115723
Validation loss: 2.736189408968854

Epoch: 5| Step: 1
Training loss: 2.2727620601654053
Validation loss: 2.7327905598507134

Epoch: 5| Step: 2
Training loss: 2.828066110610962
Validation loss: 2.7272101192064184

Epoch: 5| Step: 3
Training loss: 2.3166377544403076
Validation loss: 2.7228462542257

Epoch: 5| Step: 4
Training loss: 2.819946765899658
Validation loss: 2.7191902898973033

Epoch: 5| Step: 5
Training loss: 2.5654187202453613
Validation loss: 2.719036235604235

Epoch: 5| Step: 6
Training loss: 3.1488118171691895
Validation loss: 2.7253997069533153

Epoch: 5| Step: 7
Training loss: 2.7473692893981934
Validation loss: 2.7080771282155025

Epoch: 5| Step: 8
Training loss: 3.390071153640747
Validation loss: 2.7064085365623556

Epoch: 5| Step: 9
Training loss: 2.8949763774871826
Validation loss: 2.704952137444609

Epoch: 5| Step: 10
Training loss: 3.2046096324920654
Validation loss: 2.7010251860464773

Epoch: 15| Step: 0
Training loss: 3.4047908782958984
Validation loss: 2.7001405736451507

Epoch: 5| Step: 1
Training loss: 2.3293418884277344
Validation loss: 2.705130471978136

Epoch: 5| Step: 2
Training loss: 3.5127017498016357
Validation loss: 2.700024858597786

Epoch: 5| Step: 3
Training loss: 2.8349928855895996
Validation loss: 2.6949989718775593

Epoch: 5| Step: 4
Training loss: 2.7979636192321777
Validation loss: 2.693094899577479

Epoch: 5| Step: 5
Training loss: 3.074091672897339
Validation loss: 2.685843857385779

Epoch: 5| Step: 6
Training loss: 2.2404699325561523
Validation loss: 2.683618337877335

Epoch: 5| Step: 7
Training loss: 2.6831846237182617
Validation loss: 2.6814639747783704

Epoch: 5| Step: 8
Training loss: 3.701096296310425
Validation loss: 2.681355058505971

Epoch: 5| Step: 9
Training loss: 2.4512038230895996
Validation loss: 2.6785741647084556

Epoch: 5| Step: 10
Training loss: 2.35774302482605
Validation loss: 2.6741346697653494

Epoch: 16| Step: 0
Training loss: 2.6252729892730713
Validation loss: 2.672555761952554

Epoch: 5| Step: 1
Training loss: 3.2717292308807373
Validation loss: 2.6680227761627524

Epoch: 5| Step: 2
Training loss: 2.078167200088501
Validation loss: 2.670600670640187

Epoch: 5| Step: 3
Training loss: 2.735579013824463
Validation loss: 2.669027172109132

Epoch: 5| Step: 4
Training loss: 2.880155563354492
Validation loss: 2.6730063089760403

Epoch: 5| Step: 5
Training loss: 3.6378815174102783
Validation loss: 2.672224519073322

Epoch: 5| Step: 6
Training loss: 2.049962282180786
Validation loss: 2.664689458826537

Epoch: 5| Step: 7
Training loss: 3.2762234210968018
Validation loss: 2.660278356203469

Epoch: 5| Step: 8
Training loss: 3.0881383419036865
Validation loss: 2.658974121975642

Epoch: 5| Step: 9
Training loss: 3.0094456672668457
Validation loss: 2.6566564857318835

Epoch: 5| Step: 10
Training loss: 2.5927367210388184
Validation loss: 2.6566771948209373

Epoch: 17| Step: 0
Training loss: 2.5892844200134277
Validation loss: 2.6569784354138117

Epoch: 5| Step: 1
Training loss: 2.9771132469177246
Validation loss: 2.65357824935708

Epoch: 5| Step: 2
Training loss: 3.106710195541382
Validation loss: 2.6540485684589674

Epoch: 5| Step: 3
Training loss: 3.476830244064331
Validation loss: 2.6541262134428947

Epoch: 5| Step: 4
Training loss: 2.7090563774108887
Validation loss: 2.65731797423414

Epoch: 5| Step: 5
Training loss: 2.851749897003174
Validation loss: 2.655123231231525

Epoch: 5| Step: 6
Training loss: 3.1988279819488525
Validation loss: 2.6520233641388598

Epoch: 5| Step: 7
Training loss: 2.668593645095825
Validation loss: 2.6531871672599547

Epoch: 5| Step: 8
Training loss: 2.4019477367401123
Validation loss: 2.6507943343090754

Epoch: 5| Step: 9
Training loss: 2.619079113006592
Validation loss: 2.647329358644383

Epoch: 5| Step: 10
Training loss: 2.5323219299316406
Validation loss: 2.6467269312950874

Epoch: 18| Step: 0
Training loss: 3.1350722312927246
Validation loss: 2.644368576747115

Epoch: 5| Step: 1
Training loss: 2.829497814178467
Validation loss: 2.6457742106529976

Epoch: 5| Step: 2
Training loss: 2.5187628269195557
Validation loss: 2.6470093932203067

Epoch: 5| Step: 3
Training loss: 2.456122636795044
Validation loss: 2.6452371099943757

Epoch: 5| Step: 4
Training loss: 2.44246768951416
Validation loss: 2.647018181380405

Epoch: 5| Step: 5
Training loss: 2.7021186351776123
Validation loss: 2.6447497439640824

Epoch: 5| Step: 6
Training loss: 3.121201276779175
Validation loss: 2.639386469318021

Epoch: 5| Step: 7
Training loss: 2.9042999744415283
Validation loss: 2.6389312718504216

Epoch: 5| Step: 8
Training loss: 3.1770594120025635
Validation loss: 2.639044633475683

Epoch: 5| Step: 9
Training loss: 2.6826086044311523
Validation loss: 2.6379103660583496

Epoch: 5| Step: 10
Training loss: 3.1719648838043213
Validation loss: 2.638349240826022

Epoch: 19| Step: 0
Training loss: 3.987010955810547
Validation loss: 2.63405772947496

Epoch: 5| Step: 1
Training loss: 2.232390880584717
Validation loss: 2.6328179810636785

Epoch: 5| Step: 2
Training loss: 2.6651625633239746
Validation loss: 2.6309042925475747

Epoch: 5| Step: 3
Training loss: 3.1951560974121094
Validation loss: 2.632325774879866

Epoch: 5| Step: 4
Training loss: 2.4479660987854004
Validation loss: 2.6292538822338147

Epoch: 5| Step: 5
Training loss: 2.8369336128234863
Validation loss: 2.6304884213273243

Epoch: 5| Step: 6
Training loss: 2.249582290649414
Validation loss: 2.62746246399418

Epoch: 5| Step: 7
Training loss: 2.8688278198242188
Validation loss: 2.632122806323472

Epoch: 5| Step: 8
Training loss: 2.8082127571105957
Validation loss: 2.6442825486583095

Epoch: 5| Step: 9
Training loss: 3.3380541801452637
Validation loss: 2.6449987375608055

Epoch: 5| Step: 10
Training loss: 2.344104290008545
Validation loss: 2.6266647333739908

Epoch: 20| Step: 0
Training loss: 3.1945202350616455
Validation loss: 2.624336273439469

Epoch: 5| Step: 1
Training loss: 2.8368754386901855
Validation loss: 2.6234906873395367

Epoch: 5| Step: 2
Training loss: 2.822561740875244
Validation loss: 2.6240496455982165

Epoch: 5| Step: 3
Training loss: 2.0278282165527344
Validation loss: 2.6255365904941352

Epoch: 5| Step: 4
Training loss: 3.3773598670959473
Validation loss: 2.6258529052939465

Epoch: 5| Step: 5
Training loss: 3.479724884033203
Validation loss: 2.6246964111123035

Epoch: 5| Step: 6
Training loss: 2.895817518234253
Validation loss: 2.6195421475236134

Epoch: 5| Step: 7
Training loss: 1.9514964818954468
Validation loss: 2.6184089183807373

Epoch: 5| Step: 8
Training loss: 2.669893741607666
Validation loss: 2.6166339125684512

Epoch: 5| Step: 9
Training loss: 2.507040023803711
Validation loss: 2.630352814992269

Epoch: 5| Step: 10
Training loss: 3.2058820724487305
Validation loss: 2.661390007183116

Epoch: 21| Step: 0
Training loss: 2.387362003326416
Validation loss: 2.6777167550979124

Epoch: 5| Step: 1
Training loss: 2.1149606704711914
Validation loss: 2.649055260483937

Epoch: 5| Step: 2
Training loss: 2.8404860496520996
Validation loss: 2.636839169327931

Epoch: 5| Step: 3
Training loss: 3.0294485092163086
Validation loss: 2.622176544640654

Epoch: 5| Step: 4
Training loss: 3.2926621437072754
Validation loss: 2.611746206078478

Epoch: 5| Step: 5
Training loss: 2.924642562866211
Validation loss: 2.6230081383899977

Epoch: 5| Step: 6
Training loss: 2.5494513511657715
Validation loss: 2.665507790862873

Epoch: 5| Step: 7
Training loss: 3.2557575702667236
Validation loss: 2.613235699233188

Epoch: 5| Step: 8
Training loss: 2.9242916107177734
Validation loss: 2.6110293788294636

Epoch: 5| Step: 9
Training loss: 3.5900473594665527
Validation loss: 2.624070805888022

Epoch: 5| Step: 10
Training loss: 1.9405115842819214
Validation loss: 2.632187315212783

Epoch: 22| Step: 0
Training loss: 3.019473075866699
Validation loss: 2.6803767450394167

Epoch: 5| Step: 1
Training loss: 2.66198468208313
Validation loss: 2.661156746648973

Epoch: 5| Step: 2
Training loss: 2.6436848640441895
Validation loss: 2.6666895240865727

Epoch: 5| Step: 3
Training loss: 3.162558078765869
Validation loss: 2.6609216197844474

Epoch: 5| Step: 4
Training loss: 2.633092164993286
Validation loss: 2.662652248977333

Epoch: 5| Step: 5
Training loss: 2.6671793460845947
Validation loss: 2.660708578683997

Epoch: 5| Step: 6
Training loss: 2.1798367500305176
Validation loss: 2.6396529007983465

Epoch: 5| Step: 7
Training loss: 3.53834867477417
Validation loss: 2.6129833652127172

Epoch: 5| Step: 8
Training loss: 3.1828722953796387
Validation loss: 2.62485666941571

Epoch: 5| Step: 9
Training loss: 2.7231152057647705
Validation loss: 2.6251250569538405

Epoch: 5| Step: 10
Training loss: 2.4998388290405273
Validation loss: 2.6268168444274576

Epoch: 23| Step: 0
Training loss: 3.4937949180603027
Validation loss: 2.6366272998112503

Epoch: 5| Step: 1
Training loss: 3.0603747367858887
Validation loss: 2.6272880056852936

Epoch: 5| Step: 2
Training loss: 2.718240737915039
Validation loss: 2.6141734841049358

Epoch: 5| Step: 3
Training loss: 2.8883445262908936
Validation loss: 2.6024302615914294

Epoch: 5| Step: 4
Training loss: 2.7932090759277344
Validation loss: 2.600860854630829

Epoch: 5| Step: 5
Training loss: 2.5610761642456055
Validation loss: 2.5972830992872997

Epoch: 5| Step: 6
Training loss: 2.222430944442749
Validation loss: 2.59578711243086

Epoch: 5| Step: 7
Training loss: 3.017859697341919
Validation loss: 2.602087390038275

Epoch: 5| Step: 8
Training loss: 2.4316296577453613
Validation loss: 2.624738126672724

Epoch: 5| Step: 9
Training loss: 2.6961967945098877
Validation loss: 2.6971763128875406

Epoch: 5| Step: 10
Training loss: 3.0392558574676514
Validation loss: 2.645817502852409

Epoch: 24| Step: 0
Training loss: 2.6698355674743652
Validation loss: 2.595855279635358

Epoch: 5| Step: 1
Training loss: 2.7374603748321533
Validation loss: 2.5888644341499574

Epoch: 5| Step: 2
Training loss: 2.7701430320739746
Validation loss: 2.5856135147874073

Epoch: 5| Step: 3
Training loss: 2.322108507156372
Validation loss: 2.5837765791082896

Epoch: 5| Step: 4
Training loss: 2.9398303031921387
Validation loss: 2.592430437764814

Epoch: 5| Step: 5
Training loss: 3.0693359375
Validation loss: 2.5939984706140335

Epoch: 5| Step: 6
Training loss: 2.9720852375030518
Validation loss: 2.579031931456699

Epoch: 5| Step: 7
Training loss: 3.017021656036377
Validation loss: 2.578970686081917

Epoch: 5| Step: 8
Training loss: 2.5810508728027344
Validation loss: 2.578580274376818

Epoch: 5| Step: 9
Training loss: 2.769932508468628
Validation loss: 2.577591857602519

Epoch: 5| Step: 10
Training loss: 2.650587558746338
Validation loss: 2.5813292175210933

Epoch: 25| Step: 0
Training loss: 2.0801806449890137
Validation loss: 2.577276522113431

Epoch: 5| Step: 1
Training loss: 2.360269069671631
Validation loss: 2.5724273086875997

Epoch: 5| Step: 2
Training loss: 3.1046040058135986
Validation loss: 2.5726898485614407

Epoch: 5| Step: 3
Training loss: 3.2288920879364014
Validation loss: 2.5757913410022693

Epoch: 5| Step: 4
Training loss: 2.7349355220794678
Validation loss: 2.629241463958576

Epoch: 5| Step: 5
Training loss: 3.0550758838653564
Validation loss: 2.700185339937928

Epoch: 5| Step: 6
Training loss: 2.926474094390869
Validation loss: 2.6078774826501006

Epoch: 5| Step: 7
Training loss: 2.557039976119995
Validation loss: 2.5747468343345066

Epoch: 5| Step: 8
Training loss: 2.6740641593933105
Validation loss: 2.572907437560379

Epoch: 5| Step: 9
Training loss: 3.1279664039611816
Validation loss: 2.6025333250722578

Epoch: 5| Step: 10
Training loss: 2.7817745208740234
Validation loss: 2.609287764436455

Epoch: 26| Step: 0
Training loss: 2.646049737930298
Validation loss: 2.5876389677806566

Epoch: 5| Step: 1
Training loss: 2.508950710296631
Validation loss: 2.574409713027298

Epoch: 5| Step: 2
Training loss: 2.6296749114990234
Validation loss: 2.5759536630363873

Epoch: 5| Step: 3
Training loss: 2.914830207824707
Validation loss: 2.5750897238331456

Epoch: 5| Step: 4
Training loss: 3.054640293121338
Validation loss: 2.572181301732217

Epoch: 5| Step: 5
Training loss: 2.943182945251465
Validation loss: 2.5707785519220496

Epoch: 5| Step: 6
Training loss: 2.8799917697906494
Validation loss: 2.5631916830616612

Epoch: 5| Step: 7
Training loss: 2.9350106716156006
Validation loss: 2.557253022347727

Epoch: 5| Step: 8
Training loss: 3.296706438064575
Validation loss: 2.571684040049071

Epoch: 5| Step: 9
Training loss: 1.7144033908843994
Validation loss: 2.573182495691443

Epoch: 5| Step: 10
Training loss: 2.8718130588531494
Validation loss: 2.5744224312484905

Epoch: 27| Step: 0
Training loss: 2.740834951400757
Validation loss: 2.561687207991077

Epoch: 5| Step: 1
Training loss: 2.957510232925415
Validation loss: 2.5455214938809796

Epoch: 5| Step: 2
Training loss: 2.3150551319122314
Validation loss: 2.5383902800980436

Epoch: 5| Step: 3
Training loss: 2.843292713165283
Validation loss: 2.561794275878578

Epoch: 5| Step: 4
Training loss: 2.874941825866699
Validation loss: 2.5989303460685154

Epoch: 5| Step: 5
Training loss: 2.9292666912078857
Validation loss: 2.60545677010731

Epoch: 5| Step: 6
Training loss: 2.7795329093933105
Validation loss: 2.5949459486110236

Epoch: 5| Step: 7
Training loss: 2.7867095470428467
Validation loss: 2.5735022893515964

Epoch: 5| Step: 8
Training loss: 2.5557918548583984
Validation loss: 2.549350569325109

Epoch: 5| Step: 9
Training loss: 2.4407434463500977
Validation loss: 2.5429472384914273

Epoch: 5| Step: 10
Training loss: 3.101109504699707
Validation loss: 2.5378489391778105

Epoch: 28| Step: 0
Training loss: 2.8034768104553223
Validation loss: 2.537419234552691

Epoch: 5| Step: 1
Training loss: 2.040601968765259
Validation loss: 2.5370568203669723

Epoch: 5| Step: 2
Training loss: 2.5292696952819824
Validation loss: 2.53754920856927

Epoch: 5| Step: 3
Training loss: 2.849968910217285
Validation loss: 2.536526369792159

Epoch: 5| Step: 4
Training loss: 2.8040668964385986
Validation loss: 2.537998401990501

Epoch: 5| Step: 5
Training loss: 3.3889362812042236
Validation loss: 2.544049539873677

Epoch: 5| Step: 6
Training loss: 3.2994377613067627
Validation loss: 2.5427887580728017

Epoch: 5| Step: 7
Training loss: 2.2122044563293457
Validation loss: 2.5369772911071777

Epoch: 5| Step: 8
Training loss: 3.306420087814331
Validation loss: 2.534853501986432

Epoch: 5| Step: 9
Training loss: 2.7340149879455566
Validation loss: 2.536300410506546

Epoch: 5| Step: 10
Training loss: 1.9450292587280273
Validation loss: 2.5370232546201317

Epoch: 29| Step: 0
Training loss: 3.0815227031707764
Validation loss: 2.5522929135189263

Epoch: 5| Step: 1
Training loss: 2.9174599647521973
Validation loss: 2.5697727485369612

Epoch: 5| Step: 2
Training loss: 2.0718493461608887
Validation loss: 2.5904872904541674

Epoch: 5| Step: 3
Training loss: 2.7665915489196777
Validation loss: 2.5798529424974994

Epoch: 5| Step: 4
Training loss: 2.731316328048706
Validation loss: 2.5757981218317503

Epoch: 5| Step: 5
Training loss: 3.5273170471191406
Validation loss: 2.5571275167567755

Epoch: 5| Step: 6
Training loss: 1.790501356124878
Validation loss: 2.5407380724465973

Epoch: 5| Step: 7
Training loss: 2.27677845954895
Validation loss: 2.538400606442523

Epoch: 5| Step: 8
Training loss: 2.8430371284484863
Validation loss: 2.52792352502064

Epoch: 5| Step: 9
Training loss: 2.7077808380126953
Validation loss: 2.5228681205421366

Epoch: 5| Step: 10
Training loss: 3.4484879970550537
Validation loss: 2.5246099605355212

Epoch: 30| Step: 0
Training loss: 2.7542226314544678
Validation loss: 2.5269501850169194

Epoch: 5| Step: 1
Training loss: 2.885537624359131
Validation loss: 2.5237856885438323

Epoch: 5| Step: 2
Training loss: 3.076036214828491
Validation loss: 2.527157978344989

Epoch: 5| Step: 3
Training loss: 2.7692599296569824
Validation loss: 2.52500133873314

Epoch: 5| Step: 4
Training loss: 2.402045249938965
Validation loss: 2.5327932321897118

Epoch: 5| Step: 5
Training loss: 2.9131133556365967
Validation loss: 2.5607636051793254

Epoch: 5| Step: 6
Training loss: 3.347433567047119
Validation loss: 2.5834589132698635

Epoch: 5| Step: 7
Training loss: 2.872572898864746
Validation loss: 2.6026823136114303

Epoch: 5| Step: 8
Training loss: 2.3782432079315186
Validation loss: 2.57099320555246

Epoch: 5| Step: 9
Training loss: 2.3743648529052734
Validation loss: 2.52509016888116

Epoch: 5| Step: 10
Training loss: 2.1959662437438965
Validation loss: 2.5136687755584717

Epoch: 31| Step: 0
Training loss: 2.6645662784576416
Validation loss: 2.515788229562903

Epoch: 5| Step: 1
Training loss: 3.0978102684020996
Validation loss: 2.514922772684405

Epoch: 5| Step: 2
Training loss: 2.6052818298339844
Validation loss: 2.521349455720635

Epoch: 5| Step: 3
Training loss: 2.441951274871826
Validation loss: 2.5115212163617535

Epoch: 5| Step: 4
Training loss: 2.9068453311920166
Validation loss: 2.5059319529482114

Epoch: 5| Step: 5
Training loss: 2.1977035999298096
Validation loss: 2.50955036891404

Epoch: 5| Step: 6
Training loss: 2.335397243499756
Validation loss: 2.5154391322084653

Epoch: 5| Step: 7
Training loss: 2.3273861408233643
Validation loss: 2.524642849481234

Epoch: 5| Step: 8
Training loss: 3.3713955879211426
Validation loss: 2.5294475401601484

Epoch: 5| Step: 9
Training loss: 3.0200657844543457
Validation loss: 2.5404816853102816

Epoch: 5| Step: 10
Training loss: 2.90407133102417
Validation loss: 2.566207557596186

Epoch: 32| Step: 0
Training loss: 2.952826976776123
Validation loss: 2.57871389132674

Epoch: 5| Step: 1
Training loss: 2.8936450481414795
Validation loss: 2.5509159770063174

Epoch: 5| Step: 2
Training loss: 3.414315700531006
Validation loss: 2.514331340789795

Epoch: 5| Step: 3
Training loss: 1.6711019277572632
Validation loss: 2.5029969599939164

Epoch: 5| Step: 4
Training loss: 2.9808757305145264
Validation loss: 2.522138346907913

Epoch: 5| Step: 5
Training loss: 3.2754337787628174
Validation loss: 2.5381974815040507

Epoch: 5| Step: 6
Training loss: 2.8153374195098877
Validation loss: 2.5730416851658977

Epoch: 5| Step: 7
Training loss: 2.364438772201538
Validation loss: 2.570249213967272

Epoch: 5| Step: 8
Training loss: 2.6297125816345215
Validation loss: 2.5703880633077314

Epoch: 5| Step: 9
Training loss: 2.9555587768554688
Validation loss: 2.542311660705074

Epoch: 5| Step: 10
Training loss: 2.486429452896118
Validation loss: 2.5120414354467906

Epoch: 33| Step: 0
Training loss: 3.282994031906128
Validation loss: 2.4988708239729687

Epoch: 5| Step: 1
Training loss: 3.294050693511963
Validation loss: 2.4917787480097946

Epoch: 5| Step: 2
Training loss: 2.720447540283203
Validation loss: 2.4947640075478503

Epoch: 5| Step: 3
Training loss: 2.0607635974884033
Validation loss: 2.5023443442518993

Epoch: 5| Step: 4
Training loss: 2.8113012313842773
Validation loss: 2.52694272482267

Epoch: 5| Step: 5
Training loss: 2.3733978271484375
Validation loss: 2.557151445778467

Epoch: 5| Step: 6
Training loss: 2.313995838165283
Validation loss: 2.5800601590064263

Epoch: 5| Step: 7
Training loss: 3.3625214099884033
Validation loss: 2.588786176455918

Epoch: 5| Step: 8
Training loss: 2.2405881881713867
Validation loss: 2.5273944126662387

Epoch: 5| Step: 9
Training loss: 2.250474452972412
Validation loss: 2.503340090474775

Epoch: 5| Step: 10
Training loss: 3.185133695602417
Validation loss: 2.493593459488243

Epoch: 34| Step: 0
Training loss: 2.044490337371826
Validation loss: 2.486243642786498

Epoch: 5| Step: 1
Training loss: 2.28836727142334
Validation loss: 2.4882059610018166

Epoch: 5| Step: 2
Training loss: 2.5592892169952393
Validation loss: 2.4905940922357703

Epoch: 5| Step: 3
Training loss: 3.2924933433532715
Validation loss: 2.486913593866492

Epoch: 5| Step: 4
Training loss: 3.316298246383667
Validation loss: 2.489693364789409

Epoch: 5| Step: 5
Training loss: 2.4903616905212402
Validation loss: 2.491378281706123

Epoch: 5| Step: 6
Training loss: 2.8563790321350098
Validation loss: 2.49087494163103

Epoch: 5| Step: 7
Training loss: 2.2045207023620605
Validation loss: 2.4947203846387964

Epoch: 5| Step: 8
Training loss: 2.5006906986236572
Validation loss: 2.503364380969796

Epoch: 5| Step: 9
Training loss: 3.1760802268981934
Validation loss: 2.5214705723588184

Epoch: 5| Step: 10
Training loss: 3.114856004714966
Validation loss: 2.5075537312415337

Epoch: 35| Step: 0
Training loss: 2.733874559402466
Validation loss: 2.4971104770578365

Epoch: 5| Step: 1
Training loss: 2.4128925800323486
Validation loss: 2.492770835917483

Epoch: 5| Step: 2
Training loss: 3.2945809364318848
Validation loss: 2.487814813531855

Epoch: 5| Step: 3
Training loss: 1.9694849252700806
Validation loss: 2.48194428413145

Epoch: 5| Step: 4
Training loss: 2.7355337142944336
Validation loss: 2.4832434320962555

Epoch: 5| Step: 5
Training loss: 2.1887640953063965
Validation loss: 2.4804645892112487

Epoch: 5| Step: 6
Training loss: 3.6343467235565186
Validation loss: 2.4844364171387046

Epoch: 5| Step: 7
Training loss: 2.841695547103882
Validation loss: 2.4944308445017827

Epoch: 5| Step: 8
Training loss: 2.7088589668273926
Validation loss: 2.5125463213971866

Epoch: 5| Step: 9
Training loss: 2.4875144958496094
Validation loss: 2.5345645053412325

Epoch: 5| Step: 10
Training loss: 2.628340244293213
Validation loss: 2.5435964010095082

Epoch: 36| Step: 0
Training loss: 2.680372476577759
Validation loss: 2.529695554446149

Epoch: 5| Step: 1
Training loss: 3.1830601692199707
Validation loss: 2.509391535994827

Epoch: 5| Step: 2
Training loss: 3.4269371032714844
Validation loss: 2.49726451084178

Epoch: 5| Step: 3
Training loss: 2.858919620513916
Validation loss: 2.486259960359143

Epoch: 5| Step: 4
Training loss: 2.426988124847412
Validation loss: 2.4813802908825617

Epoch: 5| Step: 5
Training loss: 2.767197370529175
Validation loss: 2.472086396268619

Epoch: 5| Step: 6
Training loss: 2.2398681640625
Validation loss: 2.477515910261421

Epoch: 5| Step: 7
Training loss: 2.5622661113739014
Validation loss: 2.4775063299363658

Epoch: 5| Step: 8
Training loss: 2.3539609909057617
Validation loss: 2.473025224542105

Epoch: 5| Step: 9
Training loss: 2.830570697784424
Validation loss: 2.4791634672431537

Epoch: 5| Step: 10
Training loss: 2.226754665374756
Validation loss: 2.4868665510608303

Epoch: 37| Step: 0
Training loss: 2.671926259994507
Validation loss: 2.4879541550913165

Epoch: 5| Step: 1
Training loss: 2.2806544303894043
Validation loss: 2.500017371228946

Epoch: 5| Step: 2
Training loss: 2.7379775047302246
Validation loss: 2.491196224766393

Epoch: 5| Step: 3
Training loss: 2.632505178451538
Validation loss: 2.4890408285202517

Epoch: 5| Step: 4
Training loss: 2.447411060333252
Validation loss: 2.4835179364809425

Epoch: 5| Step: 5
Training loss: 2.9111275672912598
Validation loss: 2.4748907448143087

Epoch: 5| Step: 6
Training loss: 3.202909469604492
Validation loss: 2.4774576669098227

Epoch: 5| Step: 7
Training loss: 3.155327558517456
Validation loss: 2.4830032625506

Epoch: 5| Step: 8
Training loss: 2.8693935871124268
Validation loss: 2.487538036479745

Epoch: 5| Step: 9
Training loss: 2.512101650238037
Validation loss: 2.482339289880568

Epoch: 5| Step: 10
Training loss: 2.16874623298645
Validation loss: 2.500703909063852

Epoch: 38| Step: 0
Training loss: 3.303429126739502
Validation loss: 2.482990082874093

Epoch: 5| Step: 1
Training loss: 2.158212423324585
Validation loss: 2.4792579117641655

Epoch: 5| Step: 2
Training loss: 2.7152023315429688
Validation loss: 2.4860643443240913

Epoch: 5| Step: 3
Training loss: 2.3267922401428223
Validation loss: 2.4862009338153306

Epoch: 5| Step: 4
Training loss: 2.4901695251464844
Validation loss: 2.4893700333051783

Epoch: 5| Step: 5
Training loss: 2.452540874481201
Validation loss: 2.474871499564058

Epoch: 5| Step: 6
Training loss: 2.2574715614318848
Validation loss: 2.4618543527459584

Epoch: 5| Step: 7
Training loss: 2.29693341255188
Validation loss: 2.4575916259519515

Epoch: 5| Step: 8
Training loss: 3.1097166538238525
Validation loss: 2.467233222018006

Epoch: 5| Step: 9
Training loss: 3.2236480712890625
Validation loss: 2.462746661196473

Epoch: 5| Step: 10
Training loss: 3.118213415145874
Validation loss: 2.4626970932047856

Epoch: 39| Step: 0
Training loss: 2.5013229846954346
Validation loss: 2.4675689640865532

Epoch: 5| Step: 1
Training loss: 2.8818888664245605
Validation loss: 2.4644849120929675

Epoch: 5| Step: 2
Training loss: 2.3592374324798584
Validation loss: 2.4643697866829495

Epoch: 5| Step: 3
Training loss: 2.398261070251465
Validation loss: 2.474993626276652

Epoch: 5| Step: 4
Training loss: 2.692655086517334
Validation loss: 2.4787056138438563

Epoch: 5| Step: 5
Training loss: 2.7027580738067627
Validation loss: 2.471274155442433

Epoch: 5| Step: 6
Training loss: 2.1729369163513184
Validation loss: 2.4751851686867337

Epoch: 5| Step: 7
Training loss: 2.421825408935547
Validation loss: 2.47663708912429

Epoch: 5| Step: 8
Training loss: 3.1076881885528564
Validation loss: 2.4623752665776077

Epoch: 5| Step: 9
Training loss: 2.995532512664795
Validation loss: 2.458837104100053

Epoch: 5| Step: 10
Training loss: 3.272552728652954
Validation loss: 2.4565050960868917

Epoch: 40| Step: 0
Training loss: 2.3109889030456543
Validation loss: 2.4575473082962858

Epoch: 5| Step: 1
Training loss: 3.388371229171753
Validation loss: 2.4560608812557754

Epoch: 5| Step: 2
Training loss: 3.0962119102478027
Validation loss: 2.456508603147281

Epoch: 5| Step: 3
Training loss: 3.0576539039611816
Validation loss: 2.450992226600647

Epoch: 5| Step: 4
Training loss: 3.6542181968688965
Validation loss: 2.4544666787629486

Epoch: 5| Step: 5
Training loss: 2.178626537322998
Validation loss: 2.452618234901018

Epoch: 5| Step: 6
Training loss: 2.4910473823547363
Validation loss: 2.453678697668096

Epoch: 5| Step: 7
Training loss: 2.883129119873047
Validation loss: 2.4565836998724166

Epoch: 5| Step: 8
Training loss: 2.3838374614715576
Validation loss: 2.4722886905875257

Epoch: 5| Step: 9
Training loss: 2.106657028198242
Validation loss: 2.5086761648936937

Epoch: 5| Step: 10
Training loss: 1.7661226987838745
Validation loss: 2.5389878365301315

Epoch: 41| Step: 0
Training loss: 1.8025052547454834
Validation loss: 2.547559766359227

Epoch: 5| Step: 1
Training loss: 2.8377456665039062
Validation loss: 2.5636540664139615

Epoch: 5| Step: 2
Training loss: 2.6536459922790527
Validation loss: 2.602164165948027

Epoch: 5| Step: 3
Training loss: 3.477499485015869
Validation loss: 2.5830367790755404

Epoch: 5| Step: 4
Training loss: 3.1771903038024902
Validation loss: 2.5528256918794368

Epoch: 5| Step: 5
Training loss: 2.5572428703308105
Validation loss: 2.561394158230033

Epoch: 5| Step: 6
Training loss: 2.6768035888671875
Validation loss: 2.5449315963252896

Epoch: 5| Step: 7
Training loss: 2.625877618789673
Validation loss: 2.5125778387951594

Epoch: 5| Step: 8
Training loss: 2.9263033866882324
Validation loss: 2.4839920587437128

Epoch: 5| Step: 9
Training loss: 2.177133798599243
Validation loss: 2.4450255978491997

Epoch: 5| Step: 10
Training loss: 3.0138115882873535
Validation loss: 2.4482605354760283

Epoch: 42| Step: 0
Training loss: 3.005885362625122
Validation loss: 2.4450096340589624

Epoch: 5| Step: 1
Training loss: 2.1396968364715576
Validation loss: 2.446511301943051

Epoch: 5| Step: 2
Training loss: 2.7844974994659424
Validation loss: 2.4429403915200183

Epoch: 5| Step: 3
Training loss: 2.2236945629119873
Validation loss: 2.440014644335675

Epoch: 5| Step: 4
Training loss: 2.783900737762451
Validation loss: 2.4380036759120163

Epoch: 5| Step: 5
Training loss: 2.7286465167999268
Validation loss: 2.433901943186278

Epoch: 5| Step: 6
Training loss: 2.9504504203796387
Validation loss: 2.4336676751413653

Epoch: 5| Step: 7
Training loss: 2.3185372352600098
Validation loss: 2.43788662264424

Epoch: 5| Step: 8
Training loss: 2.2738595008850098
Validation loss: 2.4359531069314606

Epoch: 5| Step: 9
Training loss: 2.7908523082733154
Validation loss: 2.446393030945973

Epoch: 5| Step: 10
Training loss: 3.4647388458251953
Validation loss: 2.4573897110518588

Epoch: 43| Step: 0
Training loss: 3.296107769012451
Validation loss: 2.4942192441673687

Epoch: 5| Step: 1
Training loss: 2.5712661743164062
Validation loss: 2.5093023700098835

Epoch: 5| Step: 2
Training loss: 3.077969789505005
Validation loss: 2.4923757199318177

Epoch: 5| Step: 3
Training loss: 3.1219844818115234
Validation loss: 2.474203448141775

Epoch: 5| Step: 4
Training loss: 2.3830032348632812
Validation loss: 2.4508102837429253

Epoch: 5| Step: 5
Training loss: 2.6477484703063965
Validation loss: 2.439217677680395

Epoch: 5| Step: 6
Training loss: 2.3536360263824463
Validation loss: 2.4222535292307534

Epoch: 5| Step: 7
Training loss: 3.0895724296569824
Validation loss: 2.423391866427596

Epoch: 5| Step: 8
Training loss: 2.1309921741485596
Validation loss: 2.4253095067957395

Epoch: 5| Step: 9
Training loss: 1.8327617645263672
Validation loss: 2.42755393059023

Epoch: 5| Step: 10
Training loss: 2.9435935020446777
Validation loss: 2.4254996827853623

Epoch: 44| Step: 0
Training loss: 3.1221349239349365
Validation loss: 2.423649105974423

Epoch: 5| Step: 1
Training loss: 2.507002830505371
Validation loss: 2.4215136727979107

Epoch: 5| Step: 2
Training loss: 2.6572489738464355
Validation loss: 2.4239080336786087

Epoch: 5| Step: 3
Training loss: 2.497114896774292
Validation loss: 2.425414485316123

Epoch: 5| Step: 4
Training loss: 2.880948305130005
Validation loss: 2.4348100180267007

Epoch: 5| Step: 5
Training loss: 2.524644374847412
Validation loss: 2.442214899165656

Epoch: 5| Step: 6
Training loss: 2.6333999633789062
Validation loss: 2.438169671643165

Epoch: 5| Step: 7
Training loss: 2.9562253952026367
Validation loss: 2.446530426702192

Epoch: 5| Step: 8
Training loss: 2.6036429405212402
Validation loss: 2.4451587200164795

Epoch: 5| Step: 9
Training loss: 2.203038454055786
Validation loss: 2.4473143623721216

Epoch: 5| Step: 10
Training loss: 2.582822322845459
Validation loss: 2.4519000668679514

Epoch: 45| Step: 0
Training loss: 2.2211787700653076
Validation loss: 2.4615695732896046

Epoch: 5| Step: 1
Training loss: 1.70720636844635
Validation loss: 2.4818468606600197

Epoch: 5| Step: 2
Training loss: 2.9244236946105957
Validation loss: 2.4831776285684235

Epoch: 5| Step: 3
Training loss: 2.7579727172851562
Validation loss: 2.476392953626571

Epoch: 5| Step: 4
Training loss: 3.1056299209594727
Validation loss: 2.4284230739839616

Epoch: 5| Step: 5
Training loss: 2.8150572776794434
Validation loss: 2.43118239730917

Epoch: 5| Step: 6
Training loss: 2.999779224395752
Validation loss: 2.430186092212636

Epoch: 5| Step: 7
Training loss: 2.431933641433716
Validation loss: 2.4361468079269573

Epoch: 5| Step: 8
Training loss: 2.9186272621154785
Validation loss: 2.43240862764338

Epoch: 5| Step: 9
Training loss: 2.7143490314483643
Validation loss: 2.4219190907734696

Epoch: 5| Step: 10
Training loss: 2.697551965713501
Validation loss: 2.417710663169943

Epoch: 46| Step: 0
Training loss: 2.1471762657165527
Validation loss: 2.415720098762102

Epoch: 5| Step: 1
Training loss: 2.5974509716033936
Validation loss: 2.4189236061547392

Epoch: 5| Step: 2
Training loss: 2.3562309741973877
Validation loss: 2.4217929737542265

Epoch: 5| Step: 3
Training loss: 2.4939379692077637
Validation loss: 2.4138165827720397

Epoch: 5| Step: 4
Training loss: 2.5716652870178223
Validation loss: 2.4103250862449728

Epoch: 5| Step: 5
Training loss: 3.4426071643829346
Validation loss: 2.4086145790674354

Epoch: 5| Step: 6
Training loss: 2.5573909282684326
Validation loss: 2.408537557048182

Epoch: 5| Step: 7
Training loss: 3.0673282146453857
Validation loss: 2.408706631711734

Epoch: 5| Step: 8
Training loss: 2.506908893585205
Validation loss: 2.4083431177241827

Epoch: 5| Step: 9
Training loss: 3.0214130878448486
Validation loss: 2.413581477698459

Epoch: 5| Step: 10
Training loss: 2.327948808670044
Validation loss: 2.410151122718729

Epoch: 47| Step: 0
Training loss: 3.0357375144958496
Validation loss: 2.4092449449723765

Epoch: 5| Step: 1
Training loss: 2.1623640060424805
Validation loss: 2.4082758324120634

Epoch: 5| Step: 2
Training loss: 2.839498281478882
Validation loss: 2.4104688577754523

Epoch: 5| Step: 3
Training loss: 2.2291507720947266
Validation loss: 2.4028861381674327

Epoch: 5| Step: 4
Training loss: 2.6316490173339844
Validation loss: 2.4066022903688493

Epoch: 5| Step: 5
Training loss: 2.840017080307007
Validation loss: 2.4059055723169798

Epoch: 5| Step: 6
Training loss: 2.557269811630249
Validation loss: 2.4058380408953597

Epoch: 5| Step: 7
Training loss: 2.215167284011841
Validation loss: 2.4113641080035957

Epoch: 5| Step: 8
Training loss: 2.828195333480835
Validation loss: 2.4222382037870345

Epoch: 5| Step: 9
Training loss: 2.597144603729248
Validation loss: 2.4450102262599493

Epoch: 5| Step: 10
Training loss: 3.292356491088867
Validation loss: 2.469105294955674

Epoch: 48| Step: 0
Training loss: 3.061400890350342
Validation loss: 2.501110271740985

Epoch: 5| Step: 1
Training loss: 2.9452710151672363
Validation loss: 2.5113608401308776

Epoch: 5| Step: 2
Training loss: 2.4810709953308105
Validation loss: 2.5708431889933925

Epoch: 5| Step: 3
Training loss: 3.151453733444214
Validation loss: 2.600957762810492

Epoch: 5| Step: 4
Training loss: 2.6161177158355713
Validation loss: 2.5994878661247993

Epoch: 5| Step: 5
Training loss: 2.6961669921875
Validation loss: 2.5451110793698217

Epoch: 5| Step: 6
Training loss: 2.7741215229034424
Validation loss: 2.4843091144356677

Epoch: 5| Step: 7
Training loss: 2.6024601459503174
Validation loss: 2.4537923233483427

Epoch: 5| Step: 8
Training loss: 2.662924289703369
Validation loss: 2.439005903018418

Epoch: 5| Step: 9
Training loss: 2.5732789039611816
Validation loss: 2.4453082828111548

Epoch: 5| Step: 10
Training loss: 2.059311866760254
Validation loss: 2.451742354259696

Epoch: 49| Step: 0
Training loss: 2.698368787765503
Validation loss: 2.4489725712806947

Epoch: 5| Step: 1
Training loss: 1.6882307529449463
Validation loss: 2.4641665438170075

Epoch: 5| Step: 2
Training loss: 2.5678324699401855
Validation loss: 2.4855050861194568

Epoch: 5| Step: 3
Training loss: 3.314336061477661
Validation loss: 2.4668690748112176

Epoch: 5| Step: 4
Training loss: 2.3894267082214355
Validation loss: 2.442930752231229

Epoch: 5| Step: 5
Training loss: 3.133280038833618
Validation loss: 2.4350470624944216

Epoch: 5| Step: 6
Training loss: 2.2523176670074463
Validation loss: 2.4360729340584046

Epoch: 5| Step: 7
Training loss: 2.084256649017334
Validation loss: 2.453717288150582

Epoch: 5| Step: 8
Training loss: 2.802685022354126
Validation loss: 2.4863940592735045

Epoch: 5| Step: 9
Training loss: 2.356943130493164
Validation loss: 2.4886910095009753

Epoch: 5| Step: 10
Training loss: 4.337027072906494
Validation loss: 2.505919469300137

Epoch: 50| Step: 0
Training loss: 2.5427842140197754
Validation loss: 2.472022054015949

Epoch: 5| Step: 1
Training loss: 2.6709561347961426
Validation loss: 2.4488194745074034

Epoch: 5| Step: 2
Training loss: 3.376598358154297
Validation loss: 2.4113140798384145

Epoch: 5| Step: 3
Training loss: 1.6782995462417603
Validation loss: 2.38735717855474

Epoch: 5| Step: 4
Training loss: 2.9162113666534424
Validation loss: 2.3958027439732708

Epoch: 5| Step: 5
Training loss: 2.912414789199829
Validation loss: 2.4190262491985033

Epoch: 5| Step: 6
Training loss: 2.736691474914551
Validation loss: 2.3930588204373597

Epoch: 5| Step: 7
Training loss: 2.681839942932129
Validation loss: 2.3777937222552556

Epoch: 5| Step: 8
Training loss: 2.673149824142456
Validation loss: 2.3695696374421478

Epoch: 5| Step: 9
Training loss: 2.1801631450653076
Validation loss: 2.3737195217481224

Epoch: 5| Step: 10
Training loss: 2.9076154232025146
Validation loss: 2.3745977647842897

Epoch: 51| Step: 0
Training loss: 2.948761463165283
Validation loss: 2.3752084444927912

Epoch: 5| Step: 1
Training loss: 2.4181160926818848
Validation loss: 2.3738683423688336

Epoch: 5| Step: 2
Training loss: 2.42497181892395
Validation loss: 2.375781969357562

Epoch: 5| Step: 3
Training loss: 3.029120922088623
Validation loss: 2.3806014753157094

Epoch: 5| Step: 4
Training loss: 2.341508388519287
Validation loss: 2.3796113921749975

Epoch: 5| Step: 5
Training loss: 2.1634726524353027
Validation loss: 2.37961596058261

Epoch: 5| Step: 6
Training loss: 2.2952792644500732
Validation loss: 2.372611553438248

Epoch: 5| Step: 7
Training loss: 2.4844977855682373
Validation loss: 2.3721458322258404

Epoch: 5| Step: 8
Training loss: 2.8814196586608887
Validation loss: 2.371587643059351

Epoch: 5| Step: 9
Training loss: 2.513115406036377
Validation loss: 2.368111853958458

Epoch: 5| Step: 10
Training loss: 3.5210413932800293
Validation loss: 2.3726296706866195

Epoch: 52| Step: 0
Training loss: 2.696190357208252
Validation loss: 2.3743409277290426

Epoch: 5| Step: 1
Training loss: 3.0973429679870605
Validation loss: 2.372010923201038

Epoch: 5| Step: 2
Training loss: 2.7697863578796387
Validation loss: 2.3816307385762534

Epoch: 5| Step: 3
Training loss: 3.203056812286377
Validation loss: 2.385535142754996

Epoch: 5| Step: 4
Training loss: 2.2560882568359375
Validation loss: 2.3888015516342653

Epoch: 5| Step: 5
Training loss: 2.683642625808716
Validation loss: 2.3779399318079792

Epoch: 5| Step: 6
Training loss: 2.327852964401245
Validation loss: 2.369090093079434

Epoch: 5| Step: 7
Training loss: 2.755466938018799
Validation loss: 2.3693097304272395

Epoch: 5| Step: 8
Training loss: 2.236017942428589
Validation loss: 2.365266328216881

Epoch: 5| Step: 9
Training loss: 2.314293384552002
Validation loss: 2.361387942426948

Epoch: 5| Step: 10
Training loss: 2.569139003753662
Validation loss: 2.363469810896022

Epoch: 53| Step: 0
Training loss: 2.252779722213745
Validation loss: 2.3718580789463495

Epoch: 5| Step: 1
Training loss: 2.8610446453094482
Validation loss: 2.364208144526328

Epoch: 5| Step: 2
Training loss: 2.3471357822418213
Validation loss: 2.3614791670153217

Epoch: 5| Step: 3
Training loss: 2.464656352996826
Validation loss: 2.3680884351012526

Epoch: 5| Step: 4
Training loss: 2.4398908615112305
Validation loss: 2.3672454741693314

Epoch: 5| Step: 5
Training loss: 2.5167055130004883
Validation loss: 2.3656350387040006

Epoch: 5| Step: 6
Training loss: 2.7255892753601074
Validation loss: 2.3788107287499214

Epoch: 5| Step: 7
Training loss: 2.691934585571289
Validation loss: 2.3920167799918883

Epoch: 5| Step: 8
Training loss: 2.602482318878174
Validation loss: 2.382583036217638

Epoch: 5| Step: 9
Training loss: 3.40179181098938
Validation loss: 2.3725774416359524

Epoch: 5| Step: 10
Training loss: 2.5552403926849365
Validation loss: 2.357951238591184

Epoch: 54| Step: 0
Training loss: 2.693037748336792
Validation loss: 2.3521043767211256

Epoch: 5| Step: 1
Training loss: 2.586568832397461
Validation loss: 2.355891935286983

Epoch: 5| Step: 2
Training loss: 2.1599514484405518
Validation loss: 2.352208734840475

Epoch: 5| Step: 3
Training loss: 2.1497962474823
Validation loss: 2.3507501002280944

Epoch: 5| Step: 4
Training loss: 2.329399585723877
Validation loss: 2.3535613706035

Epoch: 5| Step: 5
Training loss: 2.907047748565674
Validation loss: 2.350511466303179

Epoch: 5| Step: 6
Training loss: 3.0482912063598633
Validation loss: 2.359763744056866

Epoch: 5| Step: 7
Training loss: 3.0057554244995117
Validation loss: 2.3631290082008607

Epoch: 5| Step: 8
Training loss: 2.6380884647369385
Validation loss: 2.3702279726664224

Epoch: 5| Step: 9
Training loss: 2.3741772174835205
Validation loss: 2.38319492852816

Epoch: 5| Step: 10
Training loss: 2.917034149169922
Validation loss: 2.3828918882595596

Epoch: 55| Step: 0
Training loss: 2.6230854988098145
Validation loss: 2.3867099259489324

Epoch: 5| Step: 1
Training loss: 2.7899184226989746
Validation loss: 2.4013917523045696

Epoch: 5| Step: 2
Training loss: 2.604269504547119
Validation loss: 2.3950767837544924

Epoch: 5| Step: 3
Training loss: 2.6110477447509766
Validation loss: 2.397511407893191

Epoch: 5| Step: 4
Training loss: 2.9290499687194824
Validation loss: 2.3781557365130355

Epoch: 5| Step: 5
Training loss: 2.9373950958251953
Validation loss: 2.3663997816783127

Epoch: 5| Step: 6
Training loss: 2.5485050678253174
Validation loss: 2.356905009156914

Epoch: 5| Step: 7
Training loss: 1.78353750705719
Validation loss: 2.349931634882445

Epoch: 5| Step: 8
Training loss: 2.47580623626709
Validation loss: 2.3462930161465883

Epoch: 5| Step: 9
Training loss: 2.2106480598449707
Validation loss: 2.3454291179615963

Epoch: 5| Step: 10
Training loss: 3.3815996646881104
Validation loss: 2.344232354112851

Epoch: 56| Step: 0
Training loss: 2.708855628967285
Validation loss: 2.343392151658253

Epoch: 5| Step: 1
Training loss: 2.466377019882202
Validation loss: 2.344673128538234

Epoch: 5| Step: 2
Training loss: 2.787151575088501
Validation loss: 2.3464826614625993

Epoch: 5| Step: 3
Training loss: 2.149528741836548
Validation loss: 2.3456931678197717

Epoch: 5| Step: 4
Training loss: 2.596426248550415
Validation loss: 2.348683670002927

Epoch: 5| Step: 5
Training loss: 2.7558581829071045
Validation loss: 2.3539597654855378

Epoch: 5| Step: 6
Training loss: 2.6919105052948
Validation loss: 2.3671321715078046

Epoch: 5| Step: 7
Training loss: 2.6724443435668945
Validation loss: 2.387875779982536

Epoch: 5| Step: 8
Training loss: 2.0241286754608154
Validation loss: 2.4126598629900204

Epoch: 5| Step: 9
Training loss: 2.8658745288848877
Validation loss: 2.4315724962501117

Epoch: 5| Step: 10
Training loss: 3.1549413204193115
Validation loss: 2.410663471427015

Epoch: 57| Step: 0
Training loss: 1.9368617534637451
Validation loss: 2.3738131228313653

Epoch: 5| Step: 1
Training loss: 2.372852087020874
Validation loss: 2.355683511303317

Epoch: 5| Step: 2
Training loss: 3.0755863189697266
Validation loss: 2.339988818732641

Epoch: 5| Step: 3
Training loss: 2.5915589332580566
Validation loss: 2.3359069721673125

Epoch: 5| Step: 4
Training loss: 2.664854049682617
Validation loss: 2.33109607747806

Epoch: 5| Step: 5
Training loss: 2.5337910652160645
Validation loss: 2.3303983698609056

Epoch: 5| Step: 6
Training loss: 3.2128219604492188
Validation loss: 2.3322048289801485

Epoch: 5| Step: 7
Training loss: 2.3749759197235107
Validation loss: 2.3284654014854023

Epoch: 5| Step: 8
Training loss: 2.341452121734619
Validation loss: 2.3345620914172103

Epoch: 5| Step: 9
Training loss: 3.3598060607910156
Validation loss: 2.3315080353008804

Epoch: 5| Step: 10
Training loss: 2.10193133354187
Validation loss: 2.3293894106341946

Epoch: 58| Step: 0
Training loss: 2.66574764251709
Validation loss: 2.3345293447535527

Epoch: 5| Step: 1
Training loss: 2.521174430847168
Validation loss: 2.3344598021558536

Epoch: 5| Step: 2
Training loss: 2.6079587936401367
Validation loss: 2.331083051619991

Epoch: 5| Step: 3
Training loss: 2.8292953968048096
Validation loss: 2.332560267499698

Epoch: 5| Step: 4
Training loss: 2.3163974285125732
Validation loss: 2.339863413123674

Epoch: 5| Step: 5
Training loss: 2.1784236431121826
Validation loss: 2.345731750611336

Epoch: 5| Step: 6
Training loss: 2.7163288593292236
Validation loss: 2.349601302095639

Epoch: 5| Step: 7
Training loss: 2.7926394939422607
Validation loss: 2.34576577268621

Epoch: 5| Step: 8
Training loss: 2.234591484069824
Validation loss: 2.355232256715016

Epoch: 5| Step: 9
Training loss: 3.1033239364624023
Validation loss: 2.3802161883282404

Epoch: 5| Step: 10
Training loss: 2.6538472175598145
Validation loss: 2.4261765300586657

Epoch: 59| Step: 0
Training loss: 2.7020888328552246
Validation loss: 2.441220191217238

Epoch: 5| Step: 1
Training loss: 2.4725232124328613
Validation loss: 2.484966595967611

Epoch: 5| Step: 2
Training loss: 2.0844624042510986
Validation loss: 2.4792824970778597

Epoch: 5| Step: 3
Training loss: 2.435058116912842
Validation loss: 2.408001046026907

Epoch: 5| Step: 4
Training loss: 3.039012908935547
Validation loss: 2.3632832163123676

Epoch: 5| Step: 5
Training loss: 3.1354992389678955
Validation loss: 2.3447275366834415

Epoch: 5| Step: 6
Training loss: 1.9633541107177734
Validation loss: 2.330097475359517

Epoch: 5| Step: 7
Training loss: 2.6033072471618652
Validation loss: 2.3727269480305333

Epoch: 5| Step: 8
Training loss: 3.2654507160186768
Validation loss: 2.489340615528886

Epoch: 5| Step: 9
Training loss: 2.489316701889038
Validation loss: 2.4851087113862396

Epoch: 5| Step: 10
Training loss: 2.9079415798187256
Validation loss: 2.449613783949165

Epoch: 60| Step: 0
Training loss: 2.241472005844116
Validation loss: 2.4098188672014462

Epoch: 5| Step: 1
Training loss: 2.4086856842041016
Validation loss: 2.4080994282999346

Epoch: 5| Step: 2
Training loss: 2.4228179454803467
Validation loss: 2.403476935560985

Epoch: 5| Step: 3
Training loss: 2.861607074737549
Validation loss: 2.393664280573527

Epoch: 5| Step: 4
Training loss: 2.84747314453125
Validation loss: 2.35865415552611

Epoch: 5| Step: 5
Training loss: 2.4377007484436035
Validation loss: 2.338530178992979

Epoch: 5| Step: 6
Training loss: 2.255197048187256
Validation loss: 2.3606979770045124

Epoch: 5| Step: 7
Training loss: 2.45381760597229
Validation loss: 2.4187481070077546

Epoch: 5| Step: 8
Training loss: 3.425523042678833
Validation loss: 2.492141872323969

Epoch: 5| Step: 9
Training loss: 3.1301703453063965
Validation loss: 2.51873625991165

Epoch: 5| Step: 10
Training loss: 2.3008310794830322
Validation loss: 2.5445260411949566

Epoch: 61| Step: 0
Training loss: 3.1090073585510254
Validation loss: 2.543720106924734

Epoch: 5| Step: 1
Training loss: 3.1743102073669434
Validation loss: 2.5360145543211248

Epoch: 5| Step: 2
Training loss: 2.1481473445892334
Validation loss: 2.4885393624664633

Epoch: 5| Step: 3
Training loss: 1.8970619440078735
Validation loss: 2.436453852602231

Epoch: 5| Step: 4
Training loss: 3.243492841720581
Validation loss: 2.3880331644447903

Epoch: 5| Step: 5
Training loss: 2.8820958137512207
Validation loss: 2.330273287270659

Epoch: 5| Step: 6
Training loss: 1.7722556591033936
Validation loss: 2.325408427946029

Epoch: 5| Step: 7
Training loss: 2.9084930419921875
Validation loss: 2.3183053296099425

Epoch: 5| Step: 8
Training loss: 2.4948830604553223
Validation loss: 2.314043826954339

Epoch: 5| Step: 9
Training loss: 2.7712152004241943
Validation loss: 2.330101308002267

Epoch: 5| Step: 10
Training loss: 2.190950870513916
Validation loss: 2.3691212349040534

Epoch: 62| Step: 0
Training loss: 2.7952311038970947
Validation loss: 2.4240161577860513

Epoch: 5| Step: 1
Training loss: 2.8386459350585938
Validation loss: 2.495032884741342

Epoch: 5| Step: 2
Training loss: 3.7870068550109863
Validation loss: 2.502866852668024

Epoch: 5| Step: 3
Training loss: 2.301663398742676
Validation loss: 2.461716810862223

Epoch: 5| Step: 4
Training loss: 2.8389580249786377
Validation loss: 2.425574751310451

Epoch: 5| Step: 5
Training loss: 2.1949455738067627
Validation loss: 2.363081180921165

Epoch: 5| Step: 6
Training loss: 2.6700310707092285
Validation loss: 2.3334720762827064

Epoch: 5| Step: 7
Training loss: 2.1157708168029785
Validation loss: 2.315468276700666

Epoch: 5| Step: 8
Training loss: 2.787259578704834
Validation loss: 2.3045674882909304

Epoch: 5| Step: 9
Training loss: 2.317932605743408
Validation loss: 2.306979710055936

Epoch: 5| Step: 10
Training loss: 2.6374197006225586
Validation loss: 2.3484941400507444

Epoch: 63| Step: 0
Training loss: 2.2746315002441406
Validation loss: 2.4381756039075952

Epoch: 5| Step: 1
Training loss: 3.12858247756958
Validation loss: 2.5538001188667874

Epoch: 5| Step: 2
Training loss: 1.8445987701416016
Validation loss: 2.623507063875916

Epoch: 5| Step: 3
Training loss: 2.8139126300811768
Validation loss: 2.627494281338107

Epoch: 5| Step: 4
Training loss: 2.8398191928863525
Validation loss: 2.533010446897117

Epoch: 5| Step: 5
Training loss: 2.798351287841797
Validation loss: 2.436114703455279

Epoch: 5| Step: 6
Training loss: 2.942352533340454
Validation loss: 2.3704245218666653

Epoch: 5| Step: 7
Training loss: 3.266237735748291
Validation loss: 2.342516335107947

Epoch: 5| Step: 8
Training loss: 2.741145610809326
Validation loss: 2.307737204336351

Epoch: 5| Step: 9
Training loss: 2.0382485389709473
Validation loss: 2.3211184573429886

Epoch: 5| Step: 10
Training loss: 2.4848530292510986
Validation loss: 2.329460209415805

Epoch: 64| Step: 0
Training loss: 2.7515716552734375
Validation loss: 2.342695031114804

Epoch: 5| Step: 1
Training loss: 2.70835018157959
Validation loss: 2.357602511682818

Epoch: 5| Step: 2
Training loss: 2.381953477859497
Validation loss: 2.387775028905561

Epoch: 5| Step: 3
Training loss: 3.273763656616211
Validation loss: 2.402445882879278

Epoch: 5| Step: 4
Training loss: 1.8935060501098633
Validation loss: 2.4055882935882895

Epoch: 5| Step: 5
Training loss: 2.74055814743042
Validation loss: 2.3851806040733092

Epoch: 5| Step: 6
Training loss: 2.3726308345794678
Validation loss: 2.3547185236407864

Epoch: 5| Step: 7
Training loss: 2.8479628562927246
Validation loss: 2.3316730812031734

Epoch: 5| Step: 8
Training loss: 2.689856767654419
Validation loss: 2.314423338059456

Epoch: 5| Step: 9
Training loss: 2.745004415512085
Validation loss: 2.307946417921333

Epoch: 5| Step: 10
Training loss: 2.918452024459839
Validation loss: 2.3008210710299912

Epoch: 65| Step: 0
Training loss: 2.366016387939453
Validation loss: 2.292872169966339

Epoch: 5| Step: 1
Training loss: 2.098451852798462
Validation loss: 2.2927741863394298

Epoch: 5| Step: 2
Training loss: 2.5788700580596924
Validation loss: 2.311274682321856

Epoch: 5| Step: 3
Training loss: 2.433490753173828
Validation loss: 2.326882194447261

Epoch: 5| Step: 4
Training loss: 2.5297017097473145
Validation loss: 2.3353779713312783

Epoch: 5| Step: 5
Training loss: 1.976401686668396
Validation loss: 2.3355332779627975

Epoch: 5| Step: 6
Training loss: 2.770153522491455
Validation loss: 2.332242486297443

Epoch: 5| Step: 7
Training loss: 2.6111130714416504
Validation loss: 2.319060271786105

Epoch: 5| Step: 8
Training loss: 2.7974624633789062
Validation loss: 2.313984255636892

Epoch: 5| Step: 9
Training loss: 3.3174872398376465
Validation loss: 2.3062359389438423

Epoch: 5| Step: 10
Training loss: 2.9804697036743164
Validation loss: 2.302019424335931

Epoch: 66| Step: 0
Training loss: 2.4415249824523926
Validation loss: 2.2989938207851943

Epoch: 5| Step: 1
Training loss: 2.8881850242614746
Validation loss: 2.2981926420683503

Epoch: 5| Step: 2
Training loss: 2.614448070526123
Validation loss: 2.2967433185987574

Epoch: 5| Step: 3
Training loss: 3.004753828048706
Validation loss: 2.290269749138945

Epoch: 5| Step: 4
Training loss: 2.1421852111816406
Validation loss: 2.2876629855043147

Epoch: 5| Step: 5
Training loss: 2.405139446258545
Validation loss: 2.291119856219138

Epoch: 5| Step: 6
Training loss: 2.5228612422943115
Validation loss: 2.288448133776265

Epoch: 5| Step: 7
Training loss: 2.51814866065979
Validation loss: 2.2904735354967016

Epoch: 5| Step: 8
Training loss: 3.0453083515167236
Validation loss: 2.288321251510292

Epoch: 5| Step: 9
Training loss: 2.3845977783203125
Validation loss: 2.3054430177134853

Epoch: 5| Step: 10
Training loss: 2.3961095809936523
Validation loss: 2.2992944512315976

Epoch: 67| Step: 0
Training loss: 2.937992572784424
Validation loss: 2.292862681932347

Epoch: 5| Step: 1
Training loss: 2.4696269035339355
Validation loss: 2.289082083650815

Epoch: 5| Step: 2
Training loss: 2.199941873550415
Validation loss: 2.2852522070689867

Epoch: 5| Step: 3
Training loss: 2.9787354469299316
Validation loss: 2.2832527442645003

Epoch: 5| Step: 4
Training loss: 2.448216199874878
Validation loss: 2.28669765944122

Epoch: 5| Step: 5
Training loss: 2.2877755165100098
Validation loss: 2.2936072811003654

Epoch: 5| Step: 6
Training loss: 2.710980176925659
Validation loss: 2.296233974477296

Epoch: 5| Step: 7
Training loss: 2.522459030151367
Validation loss: 2.289746343448598

Epoch: 5| Step: 8
Training loss: 2.520526885986328
Validation loss: 2.292853355407715

Epoch: 5| Step: 9
Training loss: 2.7174668312072754
Validation loss: 2.286828043640301

Epoch: 5| Step: 10
Training loss: 2.3485450744628906
Validation loss: 2.2908231109701176

Epoch: 68| Step: 0
Training loss: 1.7783931493759155
Validation loss: 2.2872642752944783

Epoch: 5| Step: 1
Training loss: 2.114185094833374
Validation loss: 2.290832778458954

Epoch: 5| Step: 2
Training loss: 2.135296106338501
Validation loss: 2.3026061698954594

Epoch: 5| Step: 3
Training loss: 3.108712673187256
Validation loss: 2.294705961340217

Epoch: 5| Step: 4
Training loss: 2.211932420730591
Validation loss: 2.298887660426478

Epoch: 5| Step: 5
Training loss: 2.56280517578125
Validation loss: 2.2968776072225263

Epoch: 5| Step: 6
Training loss: 2.8310773372650146
Validation loss: 2.291344154265619

Epoch: 5| Step: 7
Training loss: 2.3152050971984863
Validation loss: 2.291082787257369

Epoch: 5| Step: 8
Training loss: 2.7007088661193848
Validation loss: 2.284499486287435

Epoch: 5| Step: 9
Training loss: 2.901370048522949
Validation loss: 2.290854330985777

Epoch: 5| Step: 10
Training loss: 3.559008836746216
Validation loss: 2.2948181347180436

Epoch: 69| Step: 0
Training loss: 2.5614471435546875
Validation loss: 2.295687566521347

Epoch: 5| Step: 1
Training loss: 2.8769545555114746
Validation loss: 2.298524595076038

Epoch: 5| Step: 2
Training loss: 2.4830355644226074
Validation loss: 2.3021201138855307

Epoch: 5| Step: 3
Training loss: 2.5836403369903564
Validation loss: 2.305371786958428

Epoch: 5| Step: 4
Training loss: 2.710662364959717
Validation loss: 2.3051162124961935

Epoch: 5| Step: 5
Training loss: 2.2084429264068604
Validation loss: 2.29657648199348

Epoch: 5| Step: 6
Training loss: 2.8107707500457764
Validation loss: 2.2788853670961116

Epoch: 5| Step: 7
Training loss: 2.7794461250305176
Validation loss: 2.277682747892154

Epoch: 5| Step: 8
Training loss: 2.974912643432617
Validation loss: 2.27313498527773

Epoch: 5| Step: 9
Training loss: 1.920305609703064
Validation loss: 2.2741486334031626

Epoch: 5| Step: 10
Training loss: 2.1158230304718018
Validation loss: 2.2765831896053847

Epoch: 70| Step: 0
Training loss: 2.60461163520813
Validation loss: 2.2808152321846253

Epoch: 5| Step: 1
Training loss: 2.2198965549468994
Validation loss: 2.2974539661920197

Epoch: 5| Step: 2
Training loss: 2.602076530456543
Validation loss: 2.363984864245179

Epoch: 5| Step: 3
Training loss: 2.5909857749938965
Validation loss: 2.313468538304811

Epoch: 5| Step: 4
Training loss: 2.8776235580444336
Validation loss: 2.301252257439398

Epoch: 5| Step: 5
Training loss: 2.3362154960632324
Validation loss: 2.3053474554451565

Epoch: 5| Step: 6
Training loss: 3.021862506866455
Validation loss: 2.315139239834201

Epoch: 5| Step: 7
Training loss: 2.251326084136963
Validation loss: 2.3258338487276466

Epoch: 5| Step: 8
Training loss: 2.7856688499450684
Validation loss: 2.334207122043897

Epoch: 5| Step: 9
Training loss: 2.4668686389923096
Validation loss: 2.33439879263601

Epoch: 5| Step: 10
Training loss: 2.328503370285034
Validation loss: 2.3330826092791814

Epoch: 71| Step: 0
Training loss: 2.5514578819274902
Validation loss: 2.3236254440840853

Epoch: 5| Step: 1
Training loss: 2.757835626602173
Validation loss: 2.31769746862432

Epoch: 5| Step: 2
Training loss: 2.7124648094177246
Validation loss: 2.3039268498779624

Epoch: 5| Step: 3
Training loss: 2.505354404449463
Validation loss: 2.287021172943936

Epoch: 5| Step: 4
Training loss: 3.2284560203552246
Validation loss: 2.278194422362953

Epoch: 5| Step: 5
Training loss: 2.4388809204101562
Validation loss: 2.28375058533043

Epoch: 5| Step: 6
Training loss: 2.1611104011535645
Validation loss: 2.285900057003062

Epoch: 5| Step: 7
Training loss: 2.4312729835510254
Validation loss: 2.2911588812387116

Epoch: 5| Step: 8
Training loss: 2.220226526260376
Validation loss: 2.317633234044557

Epoch: 5| Step: 9
Training loss: 3.130178928375244
Validation loss: 2.326316879641625

Epoch: 5| Step: 10
Training loss: 1.9789230823516846
Validation loss: 2.3544284015573482

Epoch: 72| Step: 0
Training loss: 2.5457828044891357
Validation loss: 2.349463241074675

Epoch: 5| Step: 1
Training loss: 2.3263463973999023
Validation loss: 2.347709230197373

Epoch: 5| Step: 2
Training loss: 2.3125102519989014
Validation loss: 2.337653133176988

Epoch: 5| Step: 3
Training loss: 2.92279052734375
Validation loss: 2.333406630382743

Epoch: 5| Step: 4
Training loss: 3.0440988540649414
Validation loss: 2.3101056442465833

Epoch: 5| Step: 5
Training loss: 2.581258773803711
Validation loss: 2.2927452261729906

Epoch: 5| Step: 6
Training loss: 2.5321927070617676
Validation loss: 2.275173112910281

Epoch: 5| Step: 7
Training loss: 2.6597979068756104
Validation loss: 2.281251633039085

Epoch: 5| Step: 8
Training loss: 2.4118354320526123
Validation loss: 2.2757630784024476

Epoch: 5| Step: 9
Training loss: 2.3262534141540527
Validation loss: 2.273371322180635

Epoch: 5| Step: 10
Training loss: 2.3601324558258057
Validation loss: 2.2630663379546134

Epoch: 73| Step: 0
Training loss: 2.649855852127075
Validation loss: 2.264297931425033

Epoch: 5| Step: 1
Training loss: 2.3023171424865723
Validation loss: 2.2550735729996876

Epoch: 5| Step: 2
Training loss: 2.822028398513794
Validation loss: 2.2576329656826553

Epoch: 5| Step: 3
Training loss: 2.842679023742676
Validation loss: 2.2482415117243284

Epoch: 5| Step: 4
Training loss: 2.4284274578094482
Validation loss: 2.250394751948695

Epoch: 5| Step: 5
Training loss: 2.683464765548706
Validation loss: 2.252705471490019

Epoch: 5| Step: 6
Training loss: 2.056645631790161
Validation loss: 2.255046348417959

Epoch: 5| Step: 7
Training loss: 3.042889356613159
Validation loss: 2.2558698859266055

Epoch: 5| Step: 8
Training loss: 2.2816953659057617
Validation loss: 2.2525586056452926

Epoch: 5| Step: 9
Training loss: 2.872635841369629
Validation loss: 2.2535727575261104

Epoch: 5| Step: 10
Training loss: 1.7197141647338867
Validation loss: 2.2535419823021017

Epoch: 74| Step: 0
Training loss: 2.5631930828094482
Validation loss: 2.2522853420626734

Epoch: 5| Step: 1
Training loss: 2.5617799758911133
Validation loss: 2.2412887132295998

Epoch: 5| Step: 2
Training loss: 1.992134690284729
Validation loss: 2.240555594044347

Epoch: 5| Step: 3
Training loss: 3.090834856033325
Validation loss: 2.244208771695373

Epoch: 5| Step: 4
Training loss: 2.8587262630462646
Validation loss: 2.2375960529491468

Epoch: 5| Step: 5
Training loss: 2.0716612339019775
Validation loss: 2.2384561518187165

Epoch: 5| Step: 6
Training loss: 2.1841843128204346
Validation loss: 2.236854027676326

Epoch: 5| Step: 7
Training loss: 2.5003838539123535
Validation loss: 2.2361655107108493

Epoch: 5| Step: 8
Training loss: 2.546818256378174
Validation loss: 2.2473396280760407

Epoch: 5| Step: 9
Training loss: 3.0372118949890137
Validation loss: 2.250878249445269

Epoch: 5| Step: 10
Training loss: 2.327638626098633
Validation loss: 2.2564354224871566

Epoch: 75| Step: 0
Training loss: 2.2024741172790527
Validation loss: 2.258006932914898

Epoch: 5| Step: 1
Training loss: 3.0262351036071777
Validation loss: 2.2316717037590603

Epoch: 5| Step: 2
Training loss: 2.140334129333496
Validation loss: 2.234525244723084

Epoch: 5| Step: 3
Training loss: 2.1517300605773926
Validation loss: 2.236251564436061

Epoch: 5| Step: 4
Training loss: 2.9287428855895996
Validation loss: 2.2393167916164605

Epoch: 5| Step: 5
Training loss: 3.013984203338623
Validation loss: 2.2373234918040614

Epoch: 5| Step: 6
Training loss: 2.4002866744995117
Validation loss: 2.238212395739812

Epoch: 5| Step: 7
Training loss: 2.570204257965088
Validation loss: 2.23898135974843

Epoch: 5| Step: 8
Training loss: 2.554813861846924
Validation loss: 2.29430809584997

Epoch: 5| Step: 9
Training loss: 2.1839442253112793
Validation loss: 2.306398335323539

Epoch: 5| Step: 10
Training loss: 2.691699743270874
Validation loss: 2.3110453313396824

Epoch: 76| Step: 0
Training loss: 2.5594069957733154
Validation loss: 2.3369783111797866

Epoch: 5| Step: 1
Training loss: 2.5757155418395996
Validation loss: 2.3391869978238176

Epoch: 5| Step: 2
Training loss: 3.2671306133270264
Validation loss: 2.3403616310447775

Epoch: 5| Step: 3
Training loss: 2.095940589904785
Validation loss: 2.342513889394781

Epoch: 5| Step: 4
Training loss: 2.895598888397217
Validation loss: 2.3151226248792423

Epoch: 5| Step: 5
Training loss: 2.3673601150512695
Validation loss: 2.301075156017016

Epoch: 5| Step: 6
Training loss: 2.298212766647339
Validation loss: 2.298791067574614

Epoch: 5| Step: 7
Training loss: 2.792262315750122
Validation loss: 2.2919776106393464

Epoch: 5| Step: 8
Training loss: 2.095903158187866
Validation loss: 2.2972227578522055

Epoch: 5| Step: 9
Training loss: 2.880021572113037
Validation loss: 2.301213159356066

Epoch: 5| Step: 10
Training loss: 2.4842019081115723
Validation loss: 2.3018923779969573

Epoch: 77| Step: 0
Training loss: 2.3936514854431152
Validation loss: 2.308039165312244

Epoch: 5| Step: 1
Training loss: 2.278014659881592
Validation loss: 2.328755391541348

Epoch: 5| Step: 2
Training loss: 2.4515604972839355
Validation loss: 2.352019538161575

Epoch: 5| Step: 3
Training loss: 1.8489036560058594
Validation loss: 2.374101059411162

Epoch: 5| Step: 4
Training loss: 2.973284959793091
Validation loss: 2.392405197184573

Epoch: 5| Step: 5
Training loss: 2.7146730422973633
Validation loss: 2.375775514110442

Epoch: 5| Step: 6
Training loss: 3.4531402587890625
Validation loss: 2.350336438866072

Epoch: 5| Step: 7
Training loss: 2.53409743309021
Validation loss: 2.3404315158885014

Epoch: 5| Step: 8
Training loss: 2.8554158210754395
Validation loss: 2.339910399529242

Epoch: 5| Step: 9
Training loss: 2.6061947345733643
Validation loss: 2.3037966425700853

Epoch: 5| Step: 10
Training loss: 2.1314492225646973
Validation loss: 2.298059571173883

Epoch: 78| Step: 0
Training loss: 2.9874191284179688
Validation loss: 2.2844649130298245

Epoch: 5| Step: 1
Training loss: 2.483393430709839
Validation loss: 2.283409292979907

Epoch: 5| Step: 2
Training loss: 2.787243604660034
Validation loss: 2.283749090727939

Epoch: 5| Step: 3
Training loss: 2.363741397857666
Validation loss: 2.290826336030037

Epoch: 5| Step: 4
Training loss: 2.3599648475646973
Validation loss: 2.294648339671473

Epoch: 5| Step: 5
Training loss: 2.6520473957061768
Validation loss: 2.3125972632438905

Epoch: 5| Step: 6
Training loss: 2.5423362255096436
Validation loss: 2.3253588830271075

Epoch: 5| Step: 7
Training loss: 3.1887612342834473
Validation loss: 2.3287295436346405

Epoch: 5| Step: 8
Training loss: 2.123023509979248
Validation loss: 2.3221818888059227

Epoch: 5| Step: 9
Training loss: 2.6417012214660645
Validation loss: 2.3121336224258586

Epoch: 5| Step: 10
Training loss: 1.9572547674179077
Validation loss: 2.29791340520305

Epoch: 79| Step: 0
Training loss: 2.6736767292022705
Validation loss: 2.2826208171024116

Epoch: 5| Step: 1
Training loss: 3.0332493782043457
Validation loss: 2.2944072061969387

Epoch: 5| Step: 2
Training loss: 2.883664131164551
Validation loss: 2.285819871451265

Epoch: 5| Step: 3
Training loss: 2.6256957054138184
Validation loss: 2.2821928390892605

Epoch: 5| Step: 4
Training loss: 1.670863389968872
Validation loss: 2.2790611226071595

Epoch: 5| Step: 5
Training loss: 2.4193787574768066
Validation loss: 2.270637837789392

Epoch: 5| Step: 6
Training loss: 2.6579418182373047
Validation loss: 2.2643491093830397

Epoch: 5| Step: 7
Training loss: 2.5404105186462402
Validation loss: 2.262867109749907

Epoch: 5| Step: 8
Training loss: 2.566737174987793
Validation loss: 2.2606845517312326

Epoch: 5| Step: 9
Training loss: 2.324066638946533
Validation loss: 2.244010220291794

Epoch: 5| Step: 10
Training loss: 2.406550884246826
Validation loss: 2.2470887835307787

Epoch: 80| Step: 0
Training loss: 2.895357131958008
Validation loss: 2.233721187037806

Epoch: 5| Step: 1
Training loss: 2.5119080543518066
Validation loss: 2.2278918297060075

Epoch: 5| Step: 2
Training loss: 2.149754047393799
Validation loss: 2.208413120239012

Epoch: 5| Step: 3
Training loss: 2.2424399852752686
Validation loss: 2.1930096815991145

Epoch: 5| Step: 4
Training loss: 2.294642925262451
Validation loss: 2.18481860878647

Epoch: 5| Step: 5
Training loss: 2.7899231910705566
Validation loss: 2.1910786474904707

Epoch: 5| Step: 6
Training loss: 2.3919429779052734
Validation loss: 2.2010448773701987

Epoch: 5| Step: 7
Training loss: 2.634800434112549
Validation loss: 2.2335369010125437

Epoch: 5| Step: 8
Training loss: 2.883469343185425
Validation loss: 2.2154600774088213

Epoch: 5| Step: 9
Training loss: 2.3335297107696533
Validation loss: 2.205769585024926

Epoch: 5| Step: 10
Training loss: 2.249868392944336
Validation loss: 2.1885302964077202

Epoch: 81| Step: 0
Training loss: 2.585660219192505
Validation loss: 2.1918151993905344

Epoch: 5| Step: 1
Training loss: 2.1667118072509766
Validation loss: 2.1846674693528043

Epoch: 5| Step: 2
Training loss: 2.64113450050354
Validation loss: 2.179210196259201

Epoch: 5| Step: 3
Training loss: 2.683852434158325
Validation loss: 2.1834699133391022

Epoch: 5| Step: 4
Training loss: 3.2156550884246826
Validation loss: 2.203270371242236

Epoch: 5| Step: 5
Training loss: 2.348249673843384
Validation loss: 2.2094161202830653

Epoch: 5| Step: 6
Training loss: 2.013680934906006
Validation loss: 2.2088957089249805

Epoch: 5| Step: 7
Training loss: 2.754528760910034
Validation loss: 2.1857875521465013

Epoch: 5| Step: 8
Training loss: 2.439426898956299
Validation loss: 2.1741356362578688

Epoch: 5| Step: 9
Training loss: 2.1788294315338135
Validation loss: 2.1761263775569137

Epoch: 5| Step: 10
Training loss: 2.2977454662323
Validation loss: 2.175801069505753

Epoch: 82| Step: 0
Training loss: 2.3077242374420166
Validation loss: 2.179972561456824

Epoch: 5| Step: 1
Training loss: 2.836347818374634
Validation loss: 2.186464940347979

Epoch: 5| Step: 2
Training loss: 2.7391865253448486
Validation loss: 2.1811175333556307

Epoch: 5| Step: 3
Training loss: 2.4794492721557617
Validation loss: 2.1884179935660413

Epoch: 5| Step: 4
Training loss: 2.200242519378662
Validation loss: 2.1791245014436784

Epoch: 5| Step: 5
Training loss: 2.587198257446289
Validation loss: 2.1829190664393927

Epoch: 5| Step: 6
Training loss: 2.7710342407226562
Validation loss: 2.184407421337661

Epoch: 5| Step: 7
Training loss: 2.0898613929748535
Validation loss: 2.185880354655686

Epoch: 5| Step: 8
Training loss: 2.3755836486816406
Validation loss: 2.201908178226922

Epoch: 5| Step: 9
Training loss: 2.9357030391693115
Validation loss: 2.2236698391616985

Epoch: 5| Step: 10
Training loss: 2.34857439994812
Validation loss: 2.2766801670033443

Epoch: 83| Step: 0
Training loss: 2.6196866035461426
Validation loss: 2.230209332640453

Epoch: 5| Step: 1
Training loss: 2.384446382522583
Validation loss: 2.2050562135634886

Epoch: 5| Step: 2
Training loss: 3.011777400970459
Validation loss: 2.202619800003626

Epoch: 5| Step: 3
Training loss: 1.7797508239746094
Validation loss: 2.1887532036791564

Epoch: 5| Step: 4
Training loss: 2.9292831420898438
Validation loss: 2.1880858175216185

Epoch: 5| Step: 5
Training loss: 2.5453760623931885
Validation loss: 2.1773716031864123

Epoch: 5| Step: 6
Training loss: 3.0041682720184326
Validation loss: 2.180618414314844

Epoch: 5| Step: 7
Training loss: 1.876524567604065
Validation loss: 2.186905534036698

Epoch: 5| Step: 8
Training loss: 2.8466007709503174
Validation loss: 2.1913436843502905

Epoch: 5| Step: 9
Training loss: 2.243312358856201
Validation loss: 2.1987099262975875

Epoch: 5| Step: 10
Training loss: 2.1611647605895996
Validation loss: 2.2031989866687405

Epoch: 84| Step: 0
Training loss: 2.6811556816101074
Validation loss: 2.1844367955320623

Epoch: 5| Step: 1
Training loss: 2.2725112438201904
Validation loss: 2.1834532291658464

Epoch: 5| Step: 2
Training loss: 2.443220853805542
Validation loss: 2.172050982393244

Epoch: 5| Step: 3
Training loss: 2.6287474632263184
Validation loss: 2.171781788590134

Epoch: 5| Step: 4
Training loss: 3.0318026542663574
Validation loss: 2.179892114413682

Epoch: 5| Step: 5
Training loss: 2.0447583198547363
Validation loss: 2.1811092899691675

Epoch: 5| Step: 6
Training loss: 2.512563705444336
Validation loss: 2.2057403031215874

Epoch: 5| Step: 7
Training loss: 2.996595859527588
Validation loss: 2.2257642489607616

Epoch: 5| Step: 8
Training loss: 2.228065013885498
Validation loss: 2.2594810839622252

Epoch: 5| Step: 9
Training loss: 2.0894134044647217
Validation loss: 2.251275613743772

Epoch: 5| Step: 10
Training loss: 2.5491833686828613
Validation loss: 2.246069012149688

Epoch: 85| Step: 0
Training loss: 2.784083843231201
Validation loss: 2.219347793568847

Epoch: 5| Step: 1
Training loss: 2.2622625827789307
Validation loss: 2.1772458091858895

Epoch: 5| Step: 2
Training loss: 2.7718024253845215
Validation loss: 2.1471648882794123

Epoch: 5| Step: 3
Training loss: 2.238391876220703
Validation loss: 2.136062801525157

Epoch: 5| Step: 4
Training loss: 2.080747604370117
Validation loss: 2.1418476053463515

Epoch: 5| Step: 5
Training loss: 2.442491054534912
Validation loss: 2.1373739755281838

Epoch: 5| Step: 6
Training loss: 2.516197681427002
Validation loss: 2.1464624609998477

Epoch: 5| Step: 7
Training loss: 2.850154399871826
Validation loss: 2.152021377317367

Epoch: 5| Step: 8
Training loss: 2.5736846923828125
Validation loss: 2.151664718504875

Epoch: 5| Step: 9
Training loss: 2.4539973735809326
Validation loss: 2.1628766611058223

Epoch: 5| Step: 10
Training loss: 2.3925631046295166
Validation loss: 2.160202205822032

Epoch: 86| Step: 0
Training loss: 2.082504987716675
Validation loss: 2.1488592368300243

Epoch: 5| Step: 1
Training loss: 2.2802982330322266
Validation loss: 2.1415132117527786

Epoch: 5| Step: 2
Training loss: 2.2735321521759033
Validation loss: 2.135699474683372

Epoch: 5| Step: 3
Training loss: 2.447394609451294
Validation loss: 2.135394952630484

Epoch: 5| Step: 4
Training loss: 2.8467421531677246
Validation loss: 2.168617228026031

Epoch: 5| Step: 5
Training loss: 3.0854270458221436
Validation loss: 2.226076631135838

Epoch: 5| Step: 6
Training loss: 2.205620765686035
Validation loss: 2.23738871594911

Epoch: 5| Step: 7
Training loss: 2.734741687774658
Validation loss: 2.2081727597021286

Epoch: 5| Step: 8
Training loss: 2.8907630443573
Validation loss: 2.203636118160781

Epoch: 5| Step: 9
Training loss: 2.1373450756073
Validation loss: 2.189172713987289

Epoch: 5| Step: 10
Training loss: 2.248035192489624
Validation loss: 2.1802251390231553

Epoch: 87| Step: 0
Training loss: 2.801853656768799
Validation loss: 2.162083346356628

Epoch: 5| Step: 1
Training loss: 1.9215071201324463
Validation loss: 2.1581248339786323

Epoch: 5| Step: 2
Training loss: 2.5188398361206055
Validation loss: 2.1595224231802006

Epoch: 5| Step: 3
Training loss: 2.672895908355713
Validation loss: 2.1661948362986245

Epoch: 5| Step: 4
Training loss: 2.078552722930908
Validation loss: 2.1639384749115154

Epoch: 5| Step: 5
Training loss: 2.2251105308532715
Validation loss: 2.172078183902207

Epoch: 5| Step: 6
Training loss: 2.5737338066101074
Validation loss: 2.167387931577621

Epoch: 5| Step: 7
Training loss: 2.8933603763580322
Validation loss: 2.182817461670086

Epoch: 5| Step: 8
Training loss: 2.228043556213379
Validation loss: 2.202615655878539

Epoch: 5| Step: 9
Training loss: 2.7168080806732178
Validation loss: 2.1889477775942896

Epoch: 5| Step: 10
Training loss: 2.3083574771881104
Validation loss: 2.1825890079621346

Epoch: 88| Step: 0
Training loss: 2.3270795345306396
Validation loss: 2.1691845770805114

Epoch: 5| Step: 1
Training loss: 2.8068082332611084
Validation loss: 2.1687908992972424

Epoch: 5| Step: 2
Training loss: 2.4057860374450684
Validation loss: 2.1520328355091873

Epoch: 5| Step: 3
Training loss: 2.4734973907470703
Validation loss: 2.1428646349137828

Epoch: 5| Step: 4
Training loss: 2.6105713844299316
Validation loss: 2.14893477706499

Epoch: 5| Step: 5
Training loss: 2.434326171875
Validation loss: 2.143919321798509

Epoch: 5| Step: 6
Training loss: 2.2686309814453125
Validation loss: 2.1734354444729385

Epoch: 5| Step: 7
Training loss: 1.899052381515503
Validation loss: 2.237323978895782

Epoch: 5| Step: 8
Training loss: 2.7460107803344727
Validation loss: 2.2436890550839004

Epoch: 5| Step: 9
Training loss: 2.6803321838378906
Validation loss: 2.1684619149854107

Epoch: 5| Step: 10
Training loss: 2.359861135482788
Validation loss: 2.1426591668077695

Epoch: 89| Step: 0
Training loss: 2.1393675804138184
Validation loss: 2.1336506310329644

Epoch: 5| Step: 1
Training loss: 2.4021735191345215
Validation loss: 2.1326524519151255

Epoch: 5| Step: 2
Training loss: 3.063070297241211
Validation loss: 2.1591940861876293

Epoch: 5| Step: 3
Training loss: 1.9553735256195068
Validation loss: 2.1751125038311048

Epoch: 5| Step: 4
Training loss: 2.202415943145752
Validation loss: 2.2179901420429187

Epoch: 5| Step: 5
Training loss: 2.707510471343994
Validation loss: 2.2229107490149875

Epoch: 5| Step: 6
Training loss: 2.3875834941864014
Validation loss: 2.193302877487675

Epoch: 5| Step: 7
Training loss: 2.2790534496307373
Validation loss: 2.1593349082495576

Epoch: 5| Step: 8
Training loss: 2.603919267654419
Validation loss: 2.125981851290631

Epoch: 5| Step: 9
Training loss: 2.52497935295105
Validation loss: 2.1187257971814883

Epoch: 5| Step: 10
Training loss: 2.7550594806671143
Validation loss: 2.1181893566603303

Epoch: 90| Step: 0
Training loss: 1.8103818893432617
Validation loss: 2.120481493652508

Epoch: 5| Step: 1
Training loss: 2.381424903869629
Validation loss: 2.117824649298063

Epoch: 5| Step: 2
Training loss: 2.3956246376037598
Validation loss: 2.134939767981088

Epoch: 5| Step: 3
Training loss: 1.408186674118042
Validation loss: 2.1633559785863405

Epoch: 5| Step: 4
Training loss: 2.2983081340789795
Validation loss: 2.2061709921847106

Epoch: 5| Step: 5
Training loss: 2.013479709625244
Validation loss: 2.248192160360275

Epoch: 5| Step: 6
Training loss: 2.747354030609131
Validation loss: 2.26540211964679

Epoch: 5| Step: 7
Training loss: 2.8340792655944824
Validation loss: 2.2845838146824993

Epoch: 5| Step: 8
Training loss: 3.4045472145080566
Validation loss: 2.297714783299354

Epoch: 5| Step: 9
Training loss: 2.8351922035217285
Validation loss: 2.2571056465948782

Epoch: 5| Step: 10
Training loss: 3.289919137954712
Validation loss: 2.191683351352651

Epoch: 91| Step: 0
Training loss: 2.457115411758423
Validation loss: 2.130396214864587

Epoch: 5| Step: 1
Training loss: 2.2271323204040527
Validation loss: 2.1081926027933755

Epoch: 5| Step: 2
Training loss: 2.9322736263275146
Validation loss: 2.11046241944836

Epoch: 5| Step: 3
Training loss: 2.549591541290283
Validation loss: 2.1116804974053496

Epoch: 5| Step: 4
Training loss: 2.1612741947174072
Validation loss: 2.1137369909594135

Epoch: 5| Step: 5
Training loss: 2.541196346282959
Validation loss: 2.107628604417206

Epoch: 5| Step: 6
Training loss: 2.234173059463501
Validation loss: 2.111584513418136

Epoch: 5| Step: 7
Training loss: 2.5438642501831055
Validation loss: 2.1210222923627464

Epoch: 5| Step: 8
Training loss: 2.759272575378418
Validation loss: 2.1245006540770173

Epoch: 5| Step: 9
Training loss: 2.339639663696289
Validation loss: 2.130499762873496

Epoch: 5| Step: 10
Training loss: 2.181889057159424
Validation loss: 2.13492670366841

Epoch: 92| Step: 0
Training loss: 2.082338333129883
Validation loss: 2.1341469403236144

Epoch: 5| Step: 1
Training loss: 2.76330828666687
Validation loss: 2.1404185628378265

Epoch: 5| Step: 2
Training loss: 2.042160749435425
Validation loss: 2.13983586013958

Epoch: 5| Step: 3
Training loss: 1.9075632095336914
Validation loss: 2.133597722617529

Epoch: 5| Step: 4
Training loss: 3.110241651535034
Validation loss: 2.126459885669011

Epoch: 5| Step: 5
Training loss: 2.8946359157562256
Validation loss: 2.116977912123485

Epoch: 5| Step: 6
Training loss: 2.118864059448242
Validation loss: 2.1177124156746814

Epoch: 5| Step: 7
Training loss: 2.7484984397888184
Validation loss: 2.1151946898429625

Epoch: 5| Step: 8
Training loss: 2.348761558532715
Validation loss: 2.1065193632597565

Epoch: 5| Step: 9
Training loss: 2.531317710876465
Validation loss: 2.1070381454242173

Epoch: 5| Step: 10
Training loss: 2.1294822692871094
Validation loss: 2.1084542453929944

Epoch: 93| Step: 0
Training loss: 2.6823318004608154
Validation loss: 2.1113848660581853

Epoch: 5| Step: 1
Training loss: 2.692054271697998
Validation loss: 2.121105117182578

Epoch: 5| Step: 2
Training loss: 2.276726245880127
Validation loss: 2.1115201109199115

Epoch: 5| Step: 3
Training loss: 2.1147961616516113
Validation loss: 2.114112659167218

Epoch: 5| Step: 4
Training loss: 2.8175251483917236
Validation loss: 2.110476727126747

Epoch: 5| Step: 5
Training loss: 2.7210214138031006
Validation loss: 2.1285220217961136

Epoch: 5| Step: 6
Training loss: 2.6229493618011475
Validation loss: 2.1233204334012923

Epoch: 5| Step: 7
Training loss: 2.3033547401428223
Validation loss: 2.1362670788200955

Epoch: 5| Step: 8
Training loss: 2.354635715484619
Validation loss: 2.145844644115817

Epoch: 5| Step: 9
Training loss: 1.478026032447815
Validation loss: 2.1616851975840907

Epoch: 5| Step: 10
Training loss: 2.5796561241149902
Validation loss: 2.1421755052381948

Epoch: 94| Step: 0
Training loss: 2.364774227142334
Validation loss: 2.136896510278025

Epoch: 5| Step: 1
Training loss: 1.4142482280731201
Validation loss: 2.1195935049364643

Epoch: 5| Step: 2
Training loss: 3.020697832107544
Validation loss: 2.1070437610790296

Epoch: 5| Step: 3
Training loss: 2.2554173469543457
Validation loss: 2.101341885905112

Epoch: 5| Step: 4
Training loss: 2.591066837310791
Validation loss: 2.10206841140665

Epoch: 5| Step: 5
Training loss: 2.729576587677002
Validation loss: 2.096209333788964

Epoch: 5| Step: 6
Training loss: 2.6597771644592285
Validation loss: 2.0934330699264363

Epoch: 5| Step: 7
Training loss: 1.8814529180526733
Validation loss: 2.099445959573151

Epoch: 5| Step: 8
Training loss: 2.6948304176330566
Validation loss: 2.093390785237794

Epoch: 5| Step: 9
Training loss: 2.637779712677002
Validation loss: 2.095338095900833

Epoch: 5| Step: 10
Training loss: 2.4116952419281006
Validation loss: 2.093562917042804

Epoch: 95| Step: 0
Training loss: 2.857212781906128
Validation loss: 2.1031996819280807

Epoch: 5| Step: 1
Training loss: 2.4441142082214355
Validation loss: 2.115578282263971

Epoch: 5| Step: 2
Training loss: 2.8411240577697754
Validation loss: 2.1346761270235945

Epoch: 5| Step: 3
Training loss: 2.356477737426758
Validation loss: 2.1385537321849535

Epoch: 5| Step: 4
Training loss: 2.944927215576172
Validation loss: 2.139429412862306

Epoch: 5| Step: 5
Training loss: 2.1562962532043457
Validation loss: 2.1210812701973865

Epoch: 5| Step: 6
Training loss: 2.231614589691162
Validation loss: 2.103665654377271

Epoch: 5| Step: 7
Training loss: 2.2365946769714355
Validation loss: 2.0898953176313833

Epoch: 5| Step: 8
Training loss: 2.346686840057373
Validation loss: 2.0914320971376155

Epoch: 5| Step: 9
Training loss: 2.0870718955993652
Validation loss: 2.0900710628878687

Epoch: 5| Step: 10
Training loss: 2.1028711795806885
Validation loss: 2.0939962120466333

Epoch: 96| Step: 0
Training loss: 2.7149646282196045
Validation loss: 2.1015093057386336

Epoch: 5| Step: 1
Training loss: 2.447549819946289
Validation loss: 2.095209907459956

Epoch: 5| Step: 2
Training loss: 2.3163819313049316
Validation loss: 2.099149032305646

Epoch: 5| Step: 3
Training loss: 2.4437432289123535
Validation loss: 2.1092133534851896

Epoch: 5| Step: 4
Training loss: 2.407543897628784
Validation loss: 2.110628627961682

Epoch: 5| Step: 5
Training loss: 2.1756787300109863
Validation loss: 2.112355116874941

Epoch: 5| Step: 6
Training loss: 2.4458224773406982
Validation loss: 2.1341885084746988

Epoch: 5| Step: 7
Training loss: 2.837912082672119
Validation loss: 2.153076757666885

Epoch: 5| Step: 8
Training loss: 2.5912978649139404
Validation loss: 2.1733094415357037

Epoch: 5| Step: 9
Training loss: 1.8478152751922607
Validation loss: 2.1706593613470755

Epoch: 5| Step: 10
Training loss: 2.437589645385742
Validation loss: 2.1530530222000612

Epoch: 97| Step: 0
Training loss: 2.5605199337005615
Validation loss: 2.1279212018494964

Epoch: 5| Step: 1
Training loss: 1.8618625402450562
Validation loss: 2.10661143384954

Epoch: 5| Step: 2
Training loss: 1.7588694095611572
Validation loss: 2.102184708400439

Epoch: 5| Step: 3
Training loss: 2.4291961193084717
Validation loss: 2.1047995398121495

Epoch: 5| Step: 4
Training loss: 2.2994954586029053
Validation loss: 2.089396201154237

Epoch: 5| Step: 5
Training loss: 2.5568323135375977
Validation loss: 2.078508292475054

Epoch: 5| Step: 6
Training loss: 2.6268908977508545
Validation loss: 2.0781824819503294

Epoch: 5| Step: 7
Training loss: 2.2864959239959717
Validation loss: 2.0743789493396716

Epoch: 5| Step: 8
Training loss: 2.5798122882843018
Validation loss: 2.0752579730044127

Epoch: 5| Step: 9
Training loss: 2.7669265270233154
Validation loss: 2.082632480129119

Epoch: 5| Step: 10
Training loss: 2.564790725708008
Validation loss: 2.080562742807532

Epoch: 98| Step: 0
Training loss: 2.6491036415100098
Validation loss: 2.080688671399188

Epoch: 5| Step: 1
Training loss: 1.9883244037628174
Validation loss: 2.0898622094943957

Epoch: 5| Step: 2
Training loss: 2.3049063682556152
Validation loss: 2.091561213616402

Epoch: 5| Step: 3
Training loss: 3.099630832672119
Validation loss: 2.0853425405358754

Epoch: 5| Step: 4
Training loss: 2.1151914596557617
Validation loss: 2.0881140770450717

Epoch: 5| Step: 5
Training loss: 2.229140281677246
Validation loss: 2.119496194265222

Epoch: 5| Step: 6
Training loss: 2.1167194843292236
Validation loss: 2.1351696547641548

Epoch: 5| Step: 7
Training loss: 2.844986915588379
Validation loss: 2.153926263573349

Epoch: 5| Step: 8
Training loss: 2.258620023727417
Validation loss: 2.1575275082742014

Epoch: 5| Step: 9
Training loss: 2.424957275390625
Validation loss: 2.1539875333027174

Epoch: 5| Step: 10
Training loss: 2.2720391750335693
Validation loss: 2.142118820580103

Epoch: 99| Step: 0
Training loss: 1.8929760456085205
Validation loss: 2.135849061832633

Epoch: 5| Step: 1
Training loss: 2.2257513999938965
Validation loss: 2.1341774104743876

Epoch: 5| Step: 2
Training loss: 2.222014904022217
Validation loss: 2.134252498226781

Epoch: 5| Step: 3
Training loss: 2.456684112548828
Validation loss: 2.1331092426853795

Epoch: 5| Step: 4
Training loss: 2.4782967567443848
Validation loss: 2.1364688822018203

Epoch: 5| Step: 5
Training loss: 3.1406400203704834
Validation loss: 2.122761082905595

Epoch: 5| Step: 6
Training loss: 1.791399359703064
Validation loss: 2.1123344436768563

Epoch: 5| Step: 7
Training loss: 2.3648083209991455
Validation loss: 2.1039881757510606

Epoch: 5| Step: 8
Training loss: 2.805488109588623
Validation loss: 2.101156717987471

Epoch: 5| Step: 9
Training loss: 2.4619383811950684
Validation loss: 2.0962743605336835

Epoch: 5| Step: 10
Training loss: 2.287640333175659
Validation loss: 2.081176127156904

Epoch: 100| Step: 0
Training loss: 1.8386437892913818
Validation loss: 2.0820539446287256

Epoch: 5| Step: 1
Training loss: 2.1135194301605225
Validation loss: 2.081269766694756

Epoch: 5| Step: 2
Training loss: 2.105755090713501
Validation loss: 2.0828840168573524

Epoch: 5| Step: 3
Training loss: 2.454493999481201
Validation loss: 2.086608149672067

Epoch: 5| Step: 4
Training loss: 2.1533942222595215
Validation loss: 2.092388181276219

Epoch: 5| Step: 5
Training loss: 2.968355417251587
Validation loss: 2.093240950697212

Epoch: 5| Step: 6
Training loss: 2.298099994659424
Validation loss: 2.103287696838379

Epoch: 5| Step: 7
Training loss: 2.9558029174804688
Validation loss: 2.119915134163313

Epoch: 5| Step: 8
Training loss: 2.5987396240234375
Validation loss: 2.133634321151241

Epoch: 5| Step: 9
Training loss: 1.9563789367675781
Validation loss: 2.121316727771554

Epoch: 5| Step: 10
Training loss: 3.034268617630005
Validation loss: 2.1143186964014524

Epoch: 101| Step: 0
Training loss: 2.6360056400299072
Validation loss: 2.100114109695599

Epoch: 5| Step: 1
Training loss: 2.426891326904297
Validation loss: 2.100160014244818

Epoch: 5| Step: 2
Training loss: 2.1770901679992676
Validation loss: 2.1004120355011313

Epoch: 5| Step: 3
Training loss: 2.5080673694610596
Validation loss: 2.0980369455070904

Epoch: 5| Step: 4
Training loss: 1.8105499744415283
Validation loss: 2.096548403463056

Epoch: 5| Step: 5
Training loss: 2.142648935317993
Validation loss: 2.100300947825114

Epoch: 5| Step: 6
Training loss: 2.788849353790283
Validation loss: 2.1040263406692015

Epoch: 5| Step: 7
Training loss: 2.1335787773132324
Validation loss: 2.0909285711985763

Epoch: 5| Step: 8
Training loss: 1.9736435413360596
Validation loss: 2.094434056230771

Epoch: 5| Step: 9
Training loss: 2.919551372528076
Validation loss: 2.0900089984299033

Epoch: 5| Step: 10
Training loss: 2.5747642517089844
Validation loss: 2.080034445690852

Epoch: 102| Step: 0
Training loss: 2.1844635009765625
Validation loss: 2.079781001613986

Epoch: 5| Step: 1
Training loss: 2.8394534587860107
Validation loss: 2.084675200523869

Epoch: 5| Step: 2
Training loss: 1.7919600009918213
Validation loss: 2.09358504767059

Epoch: 5| Step: 3
Training loss: 2.4060235023498535
Validation loss: 2.099392852475566

Epoch: 5| Step: 4
Training loss: 2.0302226543426514
Validation loss: 2.099722895570981

Epoch: 5| Step: 5
Training loss: 2.3767178058624268
Validation loss: 2.098610629317581

Epoch: 5| Step: 6
Training loss: 2.7551350593566895
Validation loss: 2.1021291261078208

Epoch: 5| Step: 7
Training loss: 2.203218460083008
Validation loss: 2.1066674775974725

Epoch: 5| Step: 8
Training loss: 2.296020030975342
Validation loss: 2.10152070753036

Epoch: 5| Step: 9
Training loss: 2.625868320465088
Validation loss: 2.114713893141798

Epoch: 5| Step: 10
Training loss: 2.529215097427368
Validation loss: 2.090563113971423

Epoch: 103| Step: 0
Training loss: 2.2341976165771484
Validation loss: 2.0915787912184194

Epoch: 5| Step: 1
Training loss: 2.34047269821167
Validation loss: 2.0803181330362954

Epoch: 5| Step: 2
Training loss: 2.0207462310791016
Validation loss: 2.0843536110334497

Epoch: 5| Step: 3
Training loss: 2.950862169265747
Validation loss: 2.08579352337827

Epoch: 5| Step: 4
Training loss: 2.849762439727783
Validation loss: 2.0837792888764413

Epoch: 5| Step: 5
Training loss: 2.4622342586517334
Validation loss: 2.0805756174108034

Epoch: 5| Step: 6
Training loss: 2.155106544494629
Validation loss: 2.081666579810522

Epoch: 5| Step: 7
Training loss: 2.2192506790161133
Validation loss: 2.068859008050734

Epoch: 5| Step: 8
Training loss: 2.0614609718322754
Validation loss: 2.076666735833691

Epoch: 5| Step: 9
Training loss: 2.266098976135254
Validation loss: 2.077223541916058

Epoch: 5| Step: 10
Training loss: 2.2601535320281982
Validation loss: 2.080346402301583

Epoch: 104| Step: 0
Training loss: 1.6943296194076538
Validation loss: 2.0867972784144904

Epoch: 5| Step: 1
Training loss: 2.5439507961273193
Validation loss: 2.079374285154445

Epoch: 5| Step: 2
Training loss: 2.1130478382110596
Validation loss: 2.072032202956497

Epoch: 5| Step: 3
Training loss: 2.308164119720459
Validation loss: 2.0759112899021437

Epoch: 5| Step: 4
Training loss: 2.460707902908325
Validation loss: 2.081612494684035

Epoch: 5| Step: 5
Training loss: 2.134178638458252
Validation loss: 2.081381949045325

Epoch: 5| Step: 6
Training loss: 2.7085485458374023
Validation loss: 2.0733435282143216

Epoch: 5| Step: 7
Training loss: 2.561962127685547
Validation loss: 2.0822123404472106

Epoch: 5| Step: 8
Training loss: 2.9574520587921143
Validation loss: 2.0946077710838726

Epoch: 5| Step: 9
Training loss: 2.0932796001434326
Validation loss: 2.0986096525704987

Epoch: 5| Step: 10
Training loss: 2.171616315841675
Validation loss: 2.106360412413074

Epoch: 105| Step: 0
Training loss: 3.043147087097168
Validation loss: 2.1080813536079983

Epoch: 5| Step: 1
Training loss: 2.403181552886963
Validation loss: 2.0981335204134703

Epoch: 5| Step: 2
Training loss: 2.072500228881836
Validation loss: 2.079500985401933

Epoch: 5| Step: 3
Training loss: 2.412943124771118
Validation loss: 2.076267183467906

Epoch: 5| Step: 4
Training loss: 2.4601733684539795
Validation loss: 2.081115044573302

Epoch: 5| Step: 5
Training loss: 2.7651500701904297
Validation loss: 2.092069669436383

Epoch: 5| Step: 6
Training loss: 2.6213414669036865
Validation loss: 2.083978978536462

Epoch: 5| Step: 7
Training loss: 1.6818103790283203
Validation loss: 2.086178941111411

Epoch: 5| Step: 8
Training loss: 2.226557493209839
Validation loss: 2.0700236969096686

Epoch: 5| Step: 9
Training loss: 1.5695656538009644
Validation loss: 2.045652994545557

Epoch: 5| Step: 10
Training loss: 2.572458267211914
Validation loss: 2.0480232290042344

Epoch: 106| Step: 0
Training loss: 2.336724281311035
Validation loss: 2.0440216115725938

Epoch: 5| Step: 1
Training loss: 2.0658323764801025
Validation loss: 2.042965862058824

Epoch: 5| Step: 2
Training loss: 2.3827426433563232
Validation loss: 2.040852642828418

Epoch: 5| Step: 3
Training loss: 2.3442206382751465
Validation loss: 2.0370238878393687

Epoch: 5| Step: 4
Training loss: 2.05759859085083
Validation loss: 2.0392063330578547

Epoch: 5| Step: 5
Training loss: 2.6391167640686035
Validation loss: 2.0557685436741

Epoch: 5| Step: 6
Training loss: 2.243265151977539
Validation loss: 2.0618623277192474

Epoch: 5| Step: 7
Training loss: 3.0699265003204346
Validation loss: 2.0743525412774857

Epoch: 5| Step: 8
Training loss: 2.0696768760681152
Validation loss: 2.0887303711265646

Epoch: 5| Step: 9
Training loss: 2.2517120838165283
Validation loss: 2.0845749890932472

Epoch: 5| Step: 10
Training loss: 2.199676990509033
Validation loss: 2.0645178223168976

Epoch: 107| Step: 0
Training loss: 2.829280138015747
Validation loss: 2.0586140719793176

Epoch: 5| Step: 1
Training loss: 2.106738805770874
Validation loss: 2.0599906982914096

Epoch: 5| Step: 2
Training loss: 1.990267038345337
Validation loss: 2.0627422678855156

Epoch: 5| Step: 3
Training loss: 2.2130024433135986
Validation loss: 2.0590053578858734

Epoch: 5| Step: 4
Training loss: 2.0530755519866943
Validation loss: 2.0580835701316915

Epoch: 5| Step: 5
Training loss: 2.404902696609497
Validation loss: 2.0704271178091727

Epoch: 5| Step: 6
Training loss: 2.5199007987976074
Validation loss: 2.060123230821343

Epoch: 5| Step: 7
Training loss: 2.425537109375
Validation loss: 2.0688446516631753

Epoch: 5| Step: 8
Training loss: 2.4269051551818848
Validation loss: 2.064436594645182

Epoch: 5| Step: 9
Training loss: 2.3766801357269287
Validation loss: 2.0741930136116604

Epoch: 5| Step: 10
Training loss: 2.3083302974700928
Validation loss: 2.080421854090947

Epoch: 108| Step: 0
Training loss: 3.0608437061309814
Validation loss: 2.1157881393227527

Epoch: 5| Step: 1
Training loss: 2.5210511684417725
Validation loss: 2.137135554385442

Epoch: 5| Step: 2
Training loss: 2.4872801303863525
Validation loss: 2.121978836674844

Epoch: 5| Step: 3
Training loss: 1.5463340282440186
Validation loss: 2.0679015036552184

Epoch: 5| Step: 4
Training loss: 1.938858985900879
Validation loss: 2.0710661872740714

Epoch: 5| Step: 5
Training loss: 2.1523609161376953
Validation loss: 2.059306397232958

Epoch: 5| Step: 6
Training loss: 2.81221079826355
Validation loss: 2.0640754891980078

Epoch: 5| Step: 7
Training loss: 2.731400489807129
Validation loss: 2.0737032249409664

Epoch: 5| Step: 8
Training loss: 2.3886160850524902
Validation loss: 2.0812524826295915

Epoch: 5| Step: 9
Training loss: 2.7422115802764893
Validation loss: 2.0693917633384786

Epoch: 5| Step: 10
Training loss: 1.7299220561981201
Validation loss: 2.0623396404327883

Epoch: 109| Step: 0
Training loss: 2.5470738410949707
Validation loss: 2.062613925626201

Epoch: 5| Step: 1
Training loss: 1.7574808597564697
Validation loss: 2.053054630115468

Epoch: 5| Step: 2
Training loss: 2.701366901397705
Validation loss: 2.057881047648768

Epoch: 5| Step: 3
Training loss: 1.6441444158554077
Validation loss: 2.0728127264207408

Epoch: 5| Step: 4
Training loss: 2.990525484085083
Validation loss: 2.124116269491052

Epoch: 5| Step: 5
Training loss: 2.4615671634674072
Validation loss: 2.1442548190393755

Epoch: 5| Step: 6
Training loss: 2.0336623191833496
Validation loss: 2.1422667349538496

Epoch: 5| Step: 7
Training loss: 2.7432456016540527
Validation loss: 2.091836008974301

Epoch: 5| Step: 8
Training loss: 2.084531307220459
Validation loss: 2.075589579920615

Epoch: 5| Step: 9
Training loss: 2.238572835922241
Validation loss: 2.051030356396911

Epoch: 5| Step: 10
Training loss: 2.7848494052886963
Validation loss: 2.0414029449544926

Epoch: 110| Step: 0
Training loss: 2.0420279502868652
Validation loss: 2.0572585252023514

Epoch: 5| Step: 1
Training loss: 3.1328177452087402
Validation loss: 2.0658500015094714

Epoch: 5| Step: 2
Training loss: 1.8378995656967163
Validation loss: 2.084127558174954

Epoch: 5| Step: 3
Training loss: 1.869980812072754
Validation loss: 2.077318654265455

Epoch: 5| Step: 4
Training loss: 2.6231963634490967
Validation loss: 2.061356315048792

Epoch: 5| Step: 5
Training loss: 2.0300915241241455
Validation loss: 2.051730291817778

Epoch: 5| Step: 6
Training loss: 2.0462777614593506
Validation loss: 2.0568628759794336

Epoch: 5| Step: 7
Training loss: 2.201409101486206
Validation loss: 2.086293897321147

Epoch: 5| Step: 8
Training loss: 2.9427132606506348
Validation loss: 2.12303336205021

Epoch: 5| Step: 9
Training loss: 2.737985134124756
Validation loss: 2.1369178077226043

Epoch: 5| Step: 10
Training loss: 2.7731924057006836
Validation loss: 2.138900113362138

Epoch: 111| Step: 0
Training loss: 2.476008415222168
Validation loss: 2.119310099591491

Epoch: 5| Step: 1
Training loss: 2.7183971405029297
Validation loss: 2.0758435777438584

Epoch: 5| Step: 2
Training loss: 2.683211088180542
Validation loss: 2.0576329026170956

Epoch: 5| Step: 3
Training loss: 2.351008653640747
Validation loss: 2.0183766670124506

Epoch: 5| Step: 4
Training loss: 1.7566025257110596
Validation loss: 2.024597066704945

Epoch: 5| Step: 5
Training loss: 2.8567097187042236
Validation loss: 2.0250020270706504

Epoch: 5| Step: 6
Training loss: 2.359865665435791
Validation loss: 2.0306193469673075

Epoch: 5| Step: 7
Training loss: 2.2464962005615234
Validation loss: 2.0184093816306

Epoch: 5| Step: 8
Training loss: 2.2709877490997314
Validation loss: 2.0073617940307944

Epoch: 5| Step: 9
Training loss: 2.211703062057495
Validation loss: 2.0183357654079312

Epoch: 5| Step: 10
Training loss: 1.9902801513671875
Validation loss: 2.035185016611571

Epoch: 112| Step: 0
Training loss: 2.4819271564483643
Validation loss: 2.052213099695021

Epoch: 5| Step: 1
Training loss: 2.021472215652466
Validation loss: 2.075724272317784

Epoch: 5| Step: 2
Training loss: 2.749068260192871
Validation loss: 2.0848587379660657

Epoch: 5| Step: 3
Training loss: 2.872688055038452
Validation loss: 2.0702351485529253

Epoch: 5| Step: 4
Training loss: 2.856546401977539
Validation loss: 2.074607736320906

Epoch: 5| Step: 5
Training loss: 1.9289125204086304
Validation loss: 2.053864643137942

Epoch: 5| Step: 6
Training loss: 2.0741257667541504
Validation loss: 2.0212987187088176

Epoch: 5| Step: 7
Training loss: 2.1068427562713623
Validation loss: 2.001200496509511

Epoch: 5| Step: 8
Training loss: 2.3894689083099365
Validation loss: 2.010495830607671

Epoch: 5| Step: 9
Training loss: 1.8596023321151733
Validation loss: 2.0170884952750257

Epoch: 5| Step: 10
Training loss: 2.279409646987915
Validation loss: 2.0099528630574546

Epoch: 113| Step: 0
Training loss: 2.373007297515869
Validation loss: 2.0144005847233597

Epoch: 5| Step: 1
Training loss: 2.2618937492370605
Validation loss: 2.000939139755823

Epoch: 5| Step: 2
Training loss: 2.0286290645599365
Validation loss: 2.003517989189394

Epoch: 5| Step: 3
Training loss: 1.603105902671814
Validation loss: 2.015120034576744

Epoch: 5| Step: 4
Training loss: 2.5144362449645996
Validation loss: 2.023820438692647

Epoch: 5| Step: 5
Training loss: 2.651052713394165
Validation loss: 2.0477687735711374

Epoch: 5| Step: 6
Training loss: 2.084730386734009
Validation loss: 2.0525043702894643

Epoch: 5| Step: 7
Training loss: 2.614470958709717
Validation loss: 2.0656685213888846

Epoch: 5| Step: 8
Training loss: 2.6647770404815674
Validation loss: 2.0527920671688613

Epoch: 5| Step: 9
Training loss: 2.465282917022705
Validation loss: 2.044861779418043

Epoch: 5| Step: 10
Training loss: 2.3390567302703857
Validation loss: 2.056689186762738

Epoch: 114| Step: 0
Training loss: 1.659597635269165
Validation loss: 2.051493557550574

Epoch: 5| Step: 1
Training loss: 2.2455239295959473
Validation loss: 2.0765091347438034

Epoch: 5| Step: 2
Training loss: 2.187568187713623
Validation loss: 2.080483349420691

Epoch: 5| Step: 3
Training loss: 2.870774269104004
Validation loss: 2.088514874058385

Epoch: 5| Step: 4
Training loss: 2.085859775543213
Validation loss: 2.093130068112445

Epoch: 5| Step: 5
Training loss: 1.927324891090393
Validation loss: 2.0676141400491037

Epoch: 5| Step: 6
Training loss: 2.5553078651428223
Validation loss: 2.0576586928418887

Epoch: 5| Step: 7
Training loss: 3.065507173538208
Validation loss: 2.0507050893640004

Epoch: 5| Step: 8
Training loss: 2.0781548023223877
Validation loss: 2.02837997610851

Epoch: 5| Step: 9
Training loss: 2.195323944091797
Validation loss: 2.0311244944090485

Epoch: 5| Step: 10
Training loss: 2.5865373611450195
Validation loss: 2.030273304190687

Epoch: 115| Step: 0
Training loss: 1.9731037616729736
Validation loss: 2.0269948923459618

Epoch: 5| Step: 1
Training loss: 2.1834912300109863
Validation loss: 2.0177375014110277

Epoch: 5| Step: 2
Training loss: 2.828890562057495
Validation loss: 2.009047137793674

Epoch: 5| Step: 3
Training loss: 1.8380590677261353
Validation loss: 2.010764434773435

Epoch: 5| Step: 4
Training loss: 1.8654329776763916
Validation loss: 2.01458917638307

Epoch: 5| Step: 5
Training loss: 2.851644277572632
Validation loss: 2.021747322492702

Epoch: 5| Step: 6
Training loss: 2.063657283782959
Validation loss: 2.023325735522855

Epoch: 5| Step: 7
Training loss: 2.1862587928771973
Validation loss: 2.024694988804479

Epoch: 5| Step: 8
Training loss: 2.92149019241333
Validation loss: 2.004620208535143

Epoch: 5| Step: 9
Training loss: 2.7360053062438965
Validation loss: 2.0261537131442817

Epoch: 5| Step: 10
Training loss: 1.7654916048049927
Validation loss: 2.0211081774004045

Epoch: 116| Step: 0
Training loss: 2.4468934535980225
Validation loss: 2.0291484145707983

Epoch: 5| Step: 1
Training loss: 1.5624996423721313
Validation loss: 2.036367477909211

Epoch: 5| Step: 2
Training loss: 2.7297401428222656
Validation loss: 2.0460159035139185

Epoch: 5| Step: 3
Training loss: 2.467965841293335
Validation loss: 2.035418414300488

Epoch: 5| Step: 4
Training loss: 2.1744697093963623
Validation loss: 2.0259760977119528

Epoch: 5| Step: 5
Training loss: 2.8363194465637207
Validation loss: 2.0065029333996516

Epoch: 5| Step: 6
Training loss: 2.781728982925415
Validation loss: 1.9985006983562181

Epoch: 5| Step: 7
Training loss: 1.2856106758117676
Validation loss: 2.020743111128448

Epoch: 5| Step: 8
Training loss: 2.2837586402893066
Validation loss: 2.066378572935699

Epoch: 5| Step: 9
Training loss: 2.379891872406006
Validation loss: 2.110310185340143

Epoch: 5| Step: 10
Training loss: 2.753093957901001
Validation loss: 2.1174620146392495

Epoch: 117| Step: 0
Training loss: 3.090695858001709
Validation loss: 2.117596208408315

Epoch: 5| Step: 1
Training loss: 2.2356038093566895
Validation loss: 2.082284262103419

Epoch: 5| Step: 2
Training loss: 1.8743129968643188
Validation loss: 2.067046352612075

Epoch: 5| Step: 3
Training loss: 2.463498592376709
Validation loss: 2.0611952607349684

Epoch: 5| Step: 4
Training loss: 2.6501193046569824
Validation loss: 2.06009671508625

Epoch: 5| Step: 5
Training loss: 2.4886412620544434
Validation loss: 2.06525323980598

Epoch: 5| Step: 6
Training loss: 1.9201195240020752
Validation loss: 2.0782603756073983

Epoch: 5| Step: 7
Training loss: 2.245604991912842
Validation loss: 2.0727941400261334

Epoch: 5| Step: 8
Training loss: 2.5739455223083496
Validation loss: 2.0743995661376626

Epoch: 5| Step: 9
Training loss: 2.2529444694519043
Validation loss: 2.0617334804227276

Epoch: 5| Step: 10
Training loss: 2.1672205924987793
Validation loss: 2.0521038629675425

Epoch: 118| Step: 0
Training loss: 2.8476755619049072
Validation loss: 2.036746063540059

Epoch: 5| Step: 1
Training loss: 2.555676221847534
Validation loss: 2.0402172150150424

Epoch: 5| Step: 2
Training loss: 1.687978982925415
Validation loss: 2.0577463565334195

Epoch: 5| Step: 3
Training loss: 2.3642385005950928
Validation loss: 2.0876265059235277

Epoch: 5| Step: 4
Training loss: 2.390660285949707
Validation loss: 2.117173807595366

Epoch: 5| Step: 5
Training loss: 2.640964984893799
Validation loss: 2.1076880885708715

Epoch: 5| Step: 6
Training loss: 2.683238983154297
Validation loss: 2.1059523372239966

Epoch: 5| Step: 7
Training loss: 2.3207340240478516
Validation loss: 2.0832336705218077

Epoch: 5| Step: 8
Training loss: 2.0433802604675293
Validation loss: 2.0658592459976033

Epoch: 5| Step: 9
Training loss: 2.3606133460998535
Validation loss: 2.039664929912936

Epoch: 5| Step: 10
Training loss: 1.7312211990356445
Validation loss: 2.0310666394490067

Epoch: 119| Step: 0
Training loss: 1.9437885284423828
Validation loss: 2.0309291949836155

Epoch: 5| Step: 1
Training loss: 2.4408059120178223
Validation loss: 2.0330283667451594

Epoch: 5| Step: 2
Training loss: 2.9226717948913574
Validation loss: 2.031905730565389

Epoch: 5| Step: 3
Training loss: 2.5984790325164795
Validation loss: 2.0171236043335288

Epoch: 5| Step: 4
Training loss: 1.9396555423736572
Validation loss: 2.0064235553946546

Epoch: 5| Step: 5
Training loss: 2.694492816925049
Validation loss: 1.998715575023364

Epoch: 5| Step: 6
Training loss: 2.210501194000244
Validation loss: 1.996542726793597

Epoch: 5| Step: 7
Training loss: 1.6481809616088867
Validation loss: 2.00949010028634

Epoch: 5| Step: 8
Training loss: 2.2083587646484375
Validation loss: 2.007676832137569

Epoch: 5| Step: 9
Training loss: 2.8597590923309326
Validation loss: 2.000632639854185

Epoch: 5| Step: 10
Training loss: 1.9069992303848267
Validation loss: 1.9994079477043563

Epoch: 120| Step: 0
Training loss: 2.334010362625122
Validation loss: 2.004962249468732

Epoch: 5| Step: 1
Training loss: 2.719520092010498
Validation loss: 1.995418389638265

Epoch: 5| Step: 2
Training loss: 2.2847602367401123
Validation loss: 2.003004648352182

Epoch: 5| Step: 3
Training loss: 2.1939187049865723
Validation loss: 2.003181713883595

Epoch: 5| Step: 4
Training loss: 1.9355319738388062
Validation loss: 2.009678010017641

Epoch: 5| Step: 5
Training loss: 2.446671962738037
Validation loss: 2.001912736123608

Epoch: 5| Step: 6
Training loss: 2.7048683166503906
Validation loss: 1.9984272667156753

Epoch: 5| Step: 7
Training loss: 2.461219310760498
Validation loss: 2.0018901196859216

Epoch: 5| Step: 8
Training loss: 2.222388505935669
Validation loss: 2.0030840391753824

Epoch: 5| Step: 9
Training loss: 1.796992540359497
Validation loss: 2.0056044132478776

Epoch: 5| Step: 10
Training loss: 2.128542184829712
Validation loss: 2.0165379919031614

Epoch: 121| Step: 0
Training loss: 2.3072094917297363
Validation loss: 2.0159642260561705

Epoch: 5| Step: 1
Training loss: 2.790571451187134
Validation loss: 2.0295428524735155

Epoch: 5| Step: 2
Training loss: 2.274521589279175
Validation loss: 2.027540114618117

Epoch: 5| Step: 3
Training loss: 2.0084424018859863
Validation loss: 2.035084342443815

Epoch: 5| Step: 4
Training loss: 2.4806900024414062
Validation loss: 2.02764134253225

Epoch: 5| Step: 5
Training loss: 2.389824867248535
Validation loss: 2.0260438175611597

Epoch: 5| Step: 6
Training loss: 2.2912135124206543
Validation loss: 2.0090985451975176

Epoch: 5| Step: 7
Training loss: 2.3186752796173096
Validation loss: 2.010935239894416

Epoch: 5| Step: 8
Training loss: 1.864253282546997
Validation loss: 2.012869942572809

Epoch: 5| Step: 9
Training loss: 2.6888020038604736
Validation loss: 2.0144963931011897

Epoch: 5| Step: 10
Training loss: 1.7863242626190186
Validation loss: 2.017968426468552

Epoch: 122| Step: 0
Training loss: 2.0145809650421143
Validation loss: 2.0169169518255416

Epoch: 5| Step: 1
Training loss: 1.8106701374053955
Validation loss: 2.010733268594229

Epoch: 5| Step: 2
Training loss: 2.094810724258423
Validation loss: 2.022266517403305

Epoch: 5| Step: 3
Training loss: 1.688054084777832
Validation loss: 2.0255967788798834

Epoch: 5| Step: 4
Training loss: 2.0237252712249756
Validation loss: 2.0297444225639425

Epoch: 5| Step: 5
Training loss: 3.060746431350708
Validation loss: 2.0607536377445346

Epoch: 5| Step: 6
Training loss: 2.2365458011627197
Validation loss: 2.0991086049746444

Epoch: 5| Step: 7
Training loss: 3.003866672515869
Validation loss: 2.1323897941138155

Epoch: 5| Step: 8
Training loss: 2.556029796600342
Validation loss: 2.149592549570145

Epoch: 5| Step: 9
Training loss: 2.345335006713867
Validation loss: 2.1238051050452778

Epoch: 5| Step: 10
Training loss: 3.040292263031006
Validation loss: 2.1177194144136164

Epoch: 123| Step: 0
Training loss: 2.6938910484313965
Validation loss: 2.0600499106991674

Epoch: 5| Step: 1
Training loss: 2.2654929161071777
Validation loss: 2.031922895421264

Epoch: 5| Step: 2
Training loss: 1.9176108837127686
Validation loss: 2.027949014017659

Epoch: 5| Step: 3
Training loss: 2.194040060043335
Validation loss: 2.073205212111114

Epoch: 5| Step: 4
Training loss: 2.6663012504577637
Validation loss: 2.1272523838986634

Epoch: 5| Step: 5
Training loss: 2.6964755058288574
Validation loss: 2.1358869024502334

Epoch: 5| Step: 6
Training loss: 2.3776533603668213
Validation loss: 2.15370774269104

Epoch: 5| Step: 7
Training loss: 2.457927703857422
Validation loss: 2.131602798738787

Epoch: 5| Step: 8
Training loss: 2.221602439880371
Validation loss: 2.105726900921073

Epoch: 5| Step: 9
Training loss: 2.135805130004883
Validation loss: 2.0560449836074666

Epoch: 5| Step: 10
Training loss: 2.0687880516052246
Validation loss: 2.008551425831292

Epoch: 124| Step: 0
Training loss: 2.5682473182678223
Validation loss: 2.0014246176647883

Epoch: 5| Step: 1
Training loss: 1.7485710382461548
Validation loss: 1.9974862452476256

Epoch: 5| Step: 2
Training loss: 2.276172161102295
Validation loss: 2.00927294710631

Epoch: 5| Step: 3
Training loss: 2.7560083866119385
Validation loss: 2.02738207386386

Epoch: 5| Step: 4
Training loss: 2.8295860290527344
Validation loss: 2.044828176498413

Epoch: 5| Step: 5
Training loss: 2.344979763031006
Validation loss: 2.0626464582258657

Epoch: 5| Step: 6
Training loss: 1.9597885608673096
Validation loss: 2.073695154600246

Epoch: 5| Step: 7
Training loss: 2.622422695159912
Validation loss: 2.074105521684052

Epoch: 5| Step: 8
Training loss: 2.0662741661071777
Validation loss: 2.064294768917945

Epoch: 5| Step: 9
Training loss: 2.070619583129883
Validation loss: 2.0348109711882887

Epoch: 5| Step: 10
Training loss: 2.2252390384674072
Validation loss: 2.0296806366212907

Epoch: 125| Step: 0
Training loss: 2.5368406772613525
Validation loss: 2.0219958161795013

Epoch: 5| Step: 1
Training loss: 2.0270628929138184
Validation loss: 2.012191193078154

Epoch: 5| Step: 2
Training loss: 2.1781535148620605
Validation loss: 2.0128712346476894

Epoch: 5| Step: 3
Training loss: 2.069035768508911
Validation loss: 2.003171092720442

Epoch: 5| Step: 4
Training loss: 2.465791702270508
Validation loss: 1.999472169465916

Epoch: 5| Step: 5
Training loss: 2.0199577808380127
Validation loss: 1.9962113416323097

Epoch: 5| Step: 6
Training loss: 2.4505538940429688
Validation loss: 2.0068056070676414

Epoch: 5| Step: 7
Training loss: 2.853123426437378
Validation loss: 2.012576978693726

Epoch: 5| Step: 8
Training loss: 1.705012559890747
Validation loss: 2.0149234007763606

Epoch: 5| Step: 9
Training loss: 2.2825653553009033
Validation loss: 2.006452070769443

Epoch: 5| Step: 10
Training loss: 2.453016757965088
Validation loss: 2.024537491542037

Epoch: 126| Step: 0
Training loss: 2.1087746620178223
Validation loss: 2.019179677450529

Epoch: 5| Step: 1
Training loss: 1.9861503839492798
Validation loss: 2.02297915053624

Epoch: 5| Step: 2
Training loss: 1.6080776453018188
Validation loss: 2.020809268438688

Epoch: 5| Step: 3
Training loss: 2.510479688644409
Validation loss: 2.026104994999465

Epoch: 5| Step: 4
Training loss: 1.7294145822525024
Validation loss: 2.0204225714488695

Epoch: 5| Step: 5
Training loss: 2.5548620223999023
Validation loss: 2.012569704363423

Epoch: 5| Step: 6
Training loss: 2.195281744003296
Validation loss: 2.021152424555953

Epoch: 5| Step: 7
Training loss: 2.5716681480407715
Validation loss: 2.0102023373367968

Epoch: 5| Step: 8
Training loss: 2.317243814468384
Validation loss: 2.0142335212358864

Epoch: 5| Step: 9
Training loss: 2.3903541564941406
Validation loss: 2.0151294995379705

Epoch: 5| Step: 10
Training loss: 3.0250816345214844
Validation loss: 2.029833952585856

Epoch: 127| Step: 0
Training loss: 2.2844390869140625
Validation loss: 2.038570216906968

Epoch: 5| Step: 1
Training loss: 2.715235471725464
Validation loss: 2.0319615846039145

Epoch: 5| Step: 2
Training loss: 1.5868979692459106
Validation loss: 2.041215555642241

Epoch: 5| Step: 3
Training loss: 1.9107462167739868
Validation loss: 2.042261838912964

Epoch: 5| Step: 4
Training loss: 2.7790420055389404
Validation loss: 2.0602533150744695

Epoch: 5| Step: 5
Training loss: 1.6894733905792236
Validation loss: 2.0461244275493007

Epoch: 5| Step: 6
Training loss: 2.1730780601501465
Validation loss: 2.0520881965596187

Epoch: 5| Step: 7
Training loss: 2.2306065559387207
Validation loss: 2.043166213138129

Epoch: 5| Step: 8
Training loss: 2.2479705810546875
Validation loss: 2.0422562142854095

Epoch: 5| Step: 9
Training loss: 2.622272491455078
Validation loss: 2.0142601907894178

Epoch: 5| Step: 10
Training loss: 2.8775699138641357
Validation loss: 1.9980626747172365

Epoch: 128| Step: 0
Training loss: 2.232686996459961
Validation loss: 1.9830595344625495

Epoch: 5| Step: 1
Training loss: 2.332846164703369
Validation loss: 1.9836256157967351

Epoch: 5| Step: 2
Training loss: 2.0628111362457275
Validation loss: 1.9729311953308761

Epoch: 5| Step: 3
Training loss: 2.6628527641296387
Validation loss: 1.9711976153876192

Epoch: 5| Step: 4
Training loss: 2.2928969860076904
Validation loss: 1.9743424923189226

Epoch: 5| Step: 5
Training loss: 1.9118411540985107
Validation loss: 1.970439221269341

Epoch: 5| Step: 6
Training loss: 2.425499439239502
Validation loss: 1.9759672508444837

Epoch: 5| Step: 7
Training loss: 2.128866195678711
Validation loss: 1.9944860140482585

Epoch: 5| Step: 8
Training loss: 2.038578510284424
Validation loss: 1.99552527166182

Epoch: 5| Step: 9
Training loss: 2.372023820877075
Validation loss: 1.9869378305250598

Epoch: 5| Step: 10
Training loss: 2.220083236694336
Validation loss: 1.9913337025591122

Epoch: 129| Step: 0
Training loss: 2.588063955307007
Validation loss: 1.9939808614792363

Epoch: 5| Step: 1
Training loss: 1.876367211341858
Validation loss: 1.9938810768947806

Epoch: 5| Step: 2
Training loss: 2.2159976959228516
Validation loss: 2.0026411676919587

Epoch: 5| Step: 3
Training loss: 2.0672566890716553
Validation loss: 2.014465623004462

Epoch: 5| Step: 4
Training loss: 2.0922629833221436
Validation loss: 2.020833735824913

Epoch: 5| Step: 5
Training loss: 2.1517434120178223
Validation loss: 2.0068545174855057

Epoch: 5| Step: 6
Training loss: 2.3718037605285645
Validation loss: 1.998342647347399

Epoch: 5| Step: 7
Training loss: 2.4094061851501465
Validation loss: 2.002609484939165

Epoch: 5| Step: 8
Training loss: 2.3801052570343018
Validation loss: 2.0078121539085143

Epoch: 5| Step: 9
Training loss: 2.457263469696045
Validation loss: 2.0374584556907736

Epoch: 5| Step: 10
Training loss: 2.215665578842163
Validation loss: 2.04732935402983

Epoch: 130| Step: 0
Training loss: 2.7567601203918457
Validation loss: 2.065326366373288

Epoch: 5| Step: 1
Training loss: 2.161220073699951
Validation loss: 2.0706816296423636

Epoch: 5| Step: 2
Training loss: 2.613203525543213
Validation loss: 2.04785019095226

Epoch: 5| Step: 3
Training loss: 2.1165249347686768
Validation loss: 2.026357352092702

Epoch: 5| Step: 4
Training loss: 1.7103674411773682
Validation loss: 2.014248956916153

Epoch: 5| Step: 5
Training loss: 2.4077305793762207
Validation loss: 2.041397874073316

Epoch: 5| Step: 6
Training loss: 2.0258350372314453
Validation loss: 2.052626162446955

Epoch: 5| Step: 7
Training loss: 3.029475450515747
Validation loss: 2.077118710805011

Epoch: 5| Step: 8
Training loss: 2.053786277770996
Validation loss: 2.060569983656688

Epoch: 5| Step: 9
Training loss: 2.4295644760131836
Validation loss: 2.0496308111375376

Epoch: 5| Step: 10
Training loss: 2.002066135406494
Validation loss: 2.032109986069382

Epoch: 131| Step: 0
Training loss: 2.374983072280884
Validation loss: 1.9991747563885105

Epoch: 5| Step: 1
Training loss: 1.9145214557647705
Validation loss: 2.0007113718217417

Epoch: 5| Step: 2
Training loss: 2.6399712562561035
Validation loss: 1.988022687614605

Epoch: 5| Step: 3
Training loss: 2.645080089569092
Validation loss: 1.9783172940695157

Epoch: 5| Step: 4
Training loss: 1.9231336116790771
Validation loss: 1.9892368239741172

Epoch: 5| Step: 5
Training loss: 2.0973827838897705
Validation loss: 1.9998040442825646

Epoch: 5| Step: 6
Training loss: 2.667508602142334
Validation loss: 1.9829649117685133

Epoch: 5| Step: 7
Training loss: 2.1498231887817383
Validation loss: 1.9794218309463993

Epoch: 5| Step: 8
Training loss: 2.4500839710235596
Validation loss: 1.9837441239305722

Epoch: 5| Step: 9
Training loss: 1.8571159839630127
Validation loss: 1.976047747878618

Epoch: 5| Step: 10
Training loss: 1.9868420362472534
Validation loss: 1.9893228892357118

Epoch: 132| Step: 0
Training loss: 2.9215264320373535
Validation loss: 1.980763122599612

Epoch: 5| Step: 1
Training loss: 1.9220691919326782
Validation loss: 1.9781294561201526

Epoch: 5| Step: 2
Training loss: 2.459730625152588
Validation loss: 1.9713924008031045

Epoch: 5| Step: 3
Training loss: 2.128770112991333
Validation loss: 1.9865653296952606

Epoch: 5| Step: 4
Training loss: 2.086432695388794
Validation loss: 1.963217568653886

Epoch: 5| Step: 5
Training loss: 2.2009124755859375
Validation loss: 1.9689022546173425

Epoch: 5| Step: 6
Training loss: 2.350816249847412
Validation loss: 1.9766152302424114

Epoch: 5| Step: 7
Training loss: 2.1922781467437744
Validation loss: 1.9783908308193248

Epoch: 5| Step: 8
Training loss: 1.587954044342041
Validation loss: 1.9921912967517812

Epoch: 5| Step: 9
Training loss: 2.2014591693878174
Validation loss: 1.990079149123161

Epoch: 5| Step: 10
Training loss: 2.2357890605926514
Validation loss: 1.9890089829762776

Epoch: 133| Step: 0
Training loss: 1.8735955953598022
Validation loss: 1.9855893914417555

Epoch: 5| Step: 1
Training loss: 2.356715679168701
Validation loss: 2.000527548533614

Epoch: 5| Step: 2
Training loss: 2.889979124069214
Validation loss: 1.993252545274714

Epoch: 5| Step: 3
Training loss: 2.1373822689056396
Validation loss: 1.9981850231847456

Epoch: 5| Step: 4
Training loss: 2.3689255714416504
Validation loss: 1.997096073242926

Epoch: 5| Step: 5
Training loss: 2.3065686225891113
Validation loss: 1.9898781763610018

Epoch: 5| Step: 6
Training loss: 1.7406949996948242
Validation loss: 1.977369894263565

Epoch: 5| Step: 7
Training loss: 2.034827709197998
Validation loss: 1.9920813140048776

Epoch: 5| Step: 8
Training loss: 2.24623966217041
Validation loss: 2.004631253980821

Epoch: 5| Step: 9
Training loss: 2.3675484657287598
Validation loss: 1.9963756684334046

Epoch: 5| Step: 10
Training loss: 1.8610731363296509
Validation loss: 1.9833114095913467

Epoch: 134| Step: 0
Training loss: 1.5959513187408447
Validation loss: 2.003019194449148

Epoch: 5| Step: 1
Training loss: 1.7086145877838135
Validation loss: 2.0173300748230307

Epoch: 5| Step: 2
Training loss: 2.0814013481140137
Validation loss: 2.0405543440131733

Epoch: 5| Step: 3
Training loss: 2.2269222736358643
Validation loss: 2.0430304529846355

Epoch: 5| Step: 4
Training loss: 2.2818446159362793
Validation loss: 2.049911804096673

Epoch: 5| Step: 5
Training loss: 2.5131003856658936
Validation loss: 2.054631269106301

Epoch: 5| Step: 6
Training loss: 2.0240888595581055
Validation loss: 2.04338397518281

Epoch: 5| Step: 7
Training loss: 2.4061501026153564
Validation loss: 2.0464463439039005

Epoch: 5| Step: 8
Training loss: 2.2676310539245605
Validation loss: 2.0441466326354654

Epoch: 5| Step: 9
Training loss: 3.131624698638916
Validation loss: 2.0368248916441396

Epoch: 5| Step: 10
Training loss: 1.9548261165618896
Validation loss: 2.029272808823534

Epoch: 135| Step: 0
Training loss: 2.4578945636749268
Validation loss: 2.0275112518700222

Epoch: 5| Step: 1
Training loss: 2.221327066421509
Validation loss: 2.0016345734237344

Epoch: 5| Step: 2
Training loss: 2.4571588039398193
Validation loss: 1.9904555351503435

Epoch: 5| Step: 3
Training loss: 2.303752899169922
Validation loss: 2.0013709299026

Epoch: 5| Step: 4
Training loss: 1.976177453994751
Validation loss: 1.991884413585868

Epoch: 5| Step: 5
Training loss: 2.080749034881592
Validation loss: 1.974496103102161

Epoch: 5| Step: 6
Training loss: 2.6171364784240723
Validation loss: 1.9709879198381979

Epoch: 5| Step: 7
Training loss: 2.464646816253662
Validation loss: 1.9604363005648378

Epoch: 5| Step: 8
Training loss: 1.7709884643554688
Validation loss: 1.9738220848062986

Epoch: 5| Step: 9
Training loss: 1.6025034189224243
Validation loss: 1.9981739841481692

Epoch: 5| Step: 10
Training loss: 2.2130956649780273
Validation loss: 2.0424396940456924

Epoch: 136| Step: 0
Training loss: 1.9042103290557861
Validation loss: 2.0468118036946943

Epoch: 5| Step: 1
Training loss: 2.125554084777832
Validation loss: 2.0094908078511557

Epoch: 5| Step: 2
Training loss: 1.6318753957748413
Validation loss: 2.027242209321709

Epoch: 5| Step: 3
Training loss: 2.4769368171691895
Validation loss: 2.0042103105975735

Epoch: 5| Step: 4
Training loss: 2.6331424713134766
Validation loss: 1.9854878943453553

Epoch: 5| Step: 5
Training loss: 2.4370040893554688
Validation loss: 1.9760340567558043

Epoch: 5| Step: 6
Training loss: 2.634167194366455
Validation loss: 1.9806848905419792

Epoch: 5| Step: 7
Training loss: 2.605642080307007
Validation loss: 1.9954486559796076

Epoch: 5| Step: 8
Training loss: 2.3353335857391357
Validation loss: 1.9866949101930023

Epoch: 5| Step: 9
Training loss: 1.87241530418396
Validation loss: 2.0180272056210424

Epoch: 5| Step: 10
Training loss: 1.3686695098876953
Validation loss: 2.0109082870585944

Epoch: 137| Step: 0
Training loss: 2.409426212310791
Validation loss: 1.9897071725578719

Epoch: 5| Step: 1
Training loss: 2.009789228439331
Validation loss: 1.9885871807734172

Epoch: 5| Step: 2
Training loss: 2.582429885864258
Validation loss: 1.9978395687636508

Epoch: 5| Step: 3
Training loss: 2.1901328563690186
Validation loss: 1.996431343017086

Epoch: 5| Step: 4
Training loss: 2.294750928878784
Validation loss: 1.9819713561765608

Epoch: 5| Step: 5
Training loss: 2.074157953262329
Validation loss: 1.9766778510103944

Epoch: 5| Step: 6
Training loss: 2.0610477924346924
Validation loss: 1.9799492346343173

Epoch: 5| Step: 7
Training loss: 1.9616434574127197
Validation loss: 1.9623981598884828

Epoch: 5| Step: 8
Training loss: 1.9161802530288696
Validation loss: 1.9724845629866405

Epoch: 5| Step: 9
Training loss: 2.3066916465759277
Validation loss: 1.9722111443037629

Epoch: 5| Step: 10
Training loss: 2.291710376739502
Validation loss: 1.9861583261079685

Epoch: 138| Step: 0
Training loss: 1.943206787109375
Validation loss: 1.9911685169384044

Epoch: 5| Step: 1
Training loss: 1.778302788734436
Validation loss: 1.998478171645954

Epoch: 5| Step: 2
Training loss: 2.662062883377075
Validation loss: 2.0283527925450313

Epoch: 5| Step: 3
Training loss: 2.209724187850952
Validation loss: 2.011190673356415

Epoch: 5| Step: 4
Training loss: 2.2781753540039062
Validation loss: 2.031524263402467

Epoch: 5| Step: 5
Training loss: 1.9645416736602783
Validation loss: 2.0076184400948147

Epoch: 5| Step: 6
Training loss: 2.389293670654297
Validation loss: 1.9907878393767982

Epoch: 5| Step: 7
Training loss: 2.571159601211548
Validation loss: 1.9878280342266124

Epoch: 5| Step: 8
Training loss: 2.2283620834350586
Validation loss: 1.9762460903454853

Epoch: 5| Step: 9
Training loss: 1.9763288497924805
Validation loss: 1.9722400583246702

Epoch: 5| Step: 10
Training loss: 2.0253052711486816
Validation loss: 1.976576271877494

Epoch: 139| Step: 0
Training loss: 2.0573925971984863
Validation loss: 1.9812069977483442

Epoch: 5| Step: 1
Training loss: 2.3222365379333496
Validation loss: 1.984152490092862

Epoch: 5| Step: 2
Training loss: 1.7223923206329346
Validation loss: 1.9953459860176168

Epoch: 5| Step: 3
Training loss: 2.6414101123809814
Validation loss: 1.992629357563552

Epoch: 5| Step: 4
Training loss: 2.296729326248169
Validation loss: 2.009876169184203

Epoch: 5| Step: 5
Training loss: 2.0229313373565674
Validation loss: 2.0142168280898884

Epoch: 5| Step: 6
Training loss: 2.104553699493408
Validation loss: 2.0272587589038316

Epoch: 5| Step: 7
Training loss: 2.3036599159240723
Validation loss: 2.0005948543548584

Epoch: 5| Step: 8
Training loss: 2.353151798248291
Validation loss: 1.9988122627299318

Epoch: 5| Step: 9
Training loss: 1.777466058731079
Validation loss: 2.0154971922597578

Epoch: 5| Step: 10
Training loss: 2.064232349395752
Validation loss: 2.0123442924150856

Epoch: 140| Step: 0
Training loss: 1.7726428508758545
Validation loss: 2.0147278821596535

Epoch: 5| Step: 1
Training loss: 2.541231870651245
Validation loss: 2.0110808521188717

Epoch: 5| Step: 2
Training loss: 2.620027542114258
Validation loss: 2.02451503405007

Epoch: 5| Step: 3
Training loss: 1.9582653045654297
Validation loss: 2.0192032501261723

Epoch: 5| Step: 4
Training loss: 2.0487358570098877
Validation loss: 2.0240524327883156

Epoch: 5| Step: 5
Training loss: 2.2487969398498535
Validation loss: 2.0269426427861696

Epoch: 5| Step: 6
Training loss: 2.134626626968384
Validation loss: 2.0437966956887195

Epoch: 5| Step: 7
Training loss: 2.3719258308410645
Validation loss: 2.047306640173799

Epoch: 5| Step: 8
Training loss: 1.4019954204559326
Validation loss: 2.0107169253851778

Epoch: 5| Step: 9
Training loss: 2.0951805114746094
Validation loss: 1.9854436305261427

Epoch: 5| Step: 10
Training loss: 2.414487361907959
Validation loss: 1.9625176819421912

Epoch: 141| Step: 0
Training loss: 2.4310624599456787
Validation loss: 1.9595230676794564

Epoch: 5| Step: 1
Training loss: 2.6365342140197754
Validation loss: 1.970777706433368

Epoch: 5| Step: 2
Training loss: 1.57895028591156
Validation loss: 1.979548510684762

Epoch: 5| Step: 3
Training loss: 2.2479991912841797
Validation loss: 1.972584298861924

Epoch: 5| Step: 4
Training loss: 2.0442280769348145
Validation loss: 1.9751535102885256

Epoch: 5| Step: 5
Training loss: 1.7048721313476562
Validation loss: 1.9588883615309192

Epoch: 5| Step: 6
Training loss: 1.9930336475372314
Validation loss: 1.9639602797005766

Epoch: 5| Step: 7
Training loss: 2.6091129779815674
Validation loss: 1.9811441231799383

Epoch: 5| Step: 8
Training loss: 2.55206298828125
Validation loss: 2.0192974459740425

Epoch: 5| Step: 9
Training loss: 1.6698849201202393
Validation loss: 2.0164829877115067

Epoch: 5| Step: 10
Training loss: 2.309795379638672
Validation loss: 2.0066646863055486

Epoch: 142| Step: 0
Training loss: 2.310755729675293
Validation loss: 1.9925444100492744

Epoch: 5| Step: 1
Training loss: 2.878892421722412
Validation loss: 1.9987501828901229

Epoch: 5| Step: 2
Training loss: 2.534057140350342
Validation loss: 2.000042669234737

Epoch: 5| Step: 3
Training loss: 2.0461935997009277
Validation loss: 1.942993881881878

Epoch: 5| Step: 4
Training loss: 2.005403995513916
Validation loss: 1.9788351366596837

Epoch: 5| Step: 5
Training loss: 2.265423536300659
Validation loss: 2.0061094196893836

Epoch: 5| Step: 6
Training loss: 2.2316737174987793
Validation loss: 2.0100849072138467

Epoch: 5| Step: 7
Training loss: 2.593080997467041
Validation loss: 1.9850162267684937

Epoch: 5| Step: 8
Training loss: 2.3285892009735107
Validation loss: 1.974764416294713

Epoch: 5| Step: 9
Training loss: 1.477049469947815
Validation loss: 1.9785230569942023

Epoch: 5| Step: 10
Training loss: 1.500121831893921
Validation loss: 1.9912053013360629

Epoch: 143| Step: 0
Training loss: 1.8862197399139404
Validation loss: 2.01093457078421

Epoch: 5| Step: 1
Training loss: 2.977823495864868
Validation loss: 2.058165149022174

Epoch: 5| Step: 2
Training loss: 2.1429638862609863
Validation loss: 2.1056480971715783

Epoch: 5| Step: 3
Training loss: 1.901454210281372
Validation loss: 2.064163407971782

Epoch: 5| Step: 4
Training loss: 2.083019733428955
Validation loss: 2.0363604202065417

Epoch: 5| Step: 5
Training loss: 2.202500820159912
Validation loss: 2.011128674271286

Epoch: 5| Step: 6
Training loss: 1.918798804283142
Validation loss: 1.9816912630552888

Epoch: 5| Step: 7
Training loss: 2.616994857788086
Validation loss: 1.97855548192096

Epoch: 5| Step: 8
Training loss: 1.8512481451034546
Validation loss: 1.983342089960652

Epoch: 5| Step: 9
Training loss: 2.394603967666626
Validation loss: 1.9776541520190496

Epoch: 5| Step: 10
Training loss: 2.1062209606170654
Validation loss: 1.9762098699487665

Epoch: 144| Step: 0
Training loss: 1.8894134759902954
Validation loss: 1.968867580095927

Epoch: 5| Step: 1
Training loss: 2.3512282371520996
Validation loss: 1.982681805087674

Epoch: 5| Step: 2
Training loss: 2.362511157989502
Validation loss: 1.9855091135988954

Epoch: 5| Step: 3
Training loss: 2.072404384613037
Validation loss: 1.9629702106598885

Epoch: 5| Step: 4
Training loss: 2.8719780445098877
Validation loss: 1.941137226678992

Epoch: 5| Step: 5
Training loss: 1.5321959257125854
Validation loss: 1.9358605530954176

Epoch: 5| Step: 6
Training loss: 1.9707199335098267
Validation loss: 1.923914381252822

Epoch: 5| Step: 7
Training loss: 2.2623589038848877
Validation loss: 1.9402962987140944

Epoch: 5| Step: 8
Training loss: 1.9661915302276611
Validation loss: 1.9404845404368576

Epoch: 5| Step: 9
Training loss: 2.1474788188934326
Validation loss: 1.945510059274653

Epoch: 5| Step: 10
Training loss: 2.1624090671539307
Validation loss: 1.9623593861056912

Epoch: 145| Step: 0
Training loss: 2.105863571166992
Validation loss: 1.998307269106629

Epoch: 5| Step: 1
Training loss: 2.27101469039917
Validation loss: 2.0530357412112656

Epoch: 5| Step: 2
Training loss: 2.3251137733459473
Validation loss: 2.0818717659160657

Epoch: 5| Step: 3
Training loss: 2.1076738834381104
Validation loss: 2.0935727896228915

Epoch: 5| Step: 4
Training loss: 2.159965753555298
Validation loss: 2.071179884736256

Epoch: 5| Step: 5
Training loss: 2.136066436767578
Validation loss: 2.0593445454874346

Epoch: 5| Step: 6
Training loss: 2.2152798175811768
Validation loss: 2.042064392438499

Epoch: 5| Step: 7
Training loss: 2.5795845985412598
Validation loss: 2.036802646934345

Epoch: 5| Step: 8
Training loss: 1.4509085416793823
Validation loss: 2.0230161733524774

Epoch: 5| Step: 9
Training loss: 2.2494022846221924
Validation loss: 2.0065618535523773

Epoch: 5| Step: 10
Training loss: 2.156312942504883
Validation loss: 1.9837582188267862

Epoch: 146| Step: 0
Training loss: 2.1033363342285156
Validation loss: 1.9771249807009132

Epoch: 5| Step: 1
Training loss: 2.356337070465088
Validation loss: 1.9761309162262948

Epoch: 5| Step: 2
Training loss: 1.8412374258041382
Validation loss: 1.973404961247598

Epoch: 5| Step: 3
Training loss: 1.9753036499023438
Validation loss: 1.9867222039930281

Epoch: 5| Step: 4
Training loss: 1.4901537895202637
Validation loss: 1.9923826404797134

Epoch: 5| Step: 5
Training loss: 2.552058696746826
Validation loss: 1.9920150144125826

Epoch: 5| Step: 6
Training loss: 2.1092262268066406
Validation loss: 1.9847561274805376

Epoch: 5| Step: 7
Training loss: 1.4680930376052856
Validation loss: 1.9745397721567461

Epoch: 5| Step: 8
Training loss: 2.74983549118042
Validation loss: 1.975701867893178

Epoch: 5| Step: 9
Training loss: 2.332176446914673
Validation loss: 1.9724014625754407

Epoch: 5| Step: 10
Training loss: 2.37878155708313
Validation loss: 1.9774736050636537

Epoch: 147| Step: 0
Training loss: 2.0859808921813965
Validation loss: 1.9716589912291496

Epoch: 5| Step: 1
Training loss: 2.587374210357666
Validation loss: 1.9765383171778854

Epoch: 5| Step: 2
Training loss: 2.3983237743377686
Validation loss: 2.006368516593851

Epoch: 5| Step: 3
Training loss: 1.8340266942977905
Validation loss: 2.0239288499278407

Epoch: 5| Step: 4
Training loss: 2.0820021629333496
Validation loss: 2.023827414358816

Epoch: 5| Step: 5
Training loss: 1.8564980030059814
Validation loss: 2.0267646363986436

Epoch: 5| Step: 6
Training loss: 1.8999404907226562
Validation loss: 2.027919330904561

Epoch: 5| Step: 7
Training loss: 2.1492552757263184
Validation loss: 2.0285772072371615

Epoch: 5| Step: 8
Training loss: 2.045320987701416
Validation loss: 2.044370914018282

Epoch: 5| Step: 9
Training loss: 2.1037166118621826
Validation loss: 2.030584035381194

Epoch: 5| Step: 10
Training loss: 2.146202564239502
Validation loss: 2.0341809590657554

Epoch: 148| Step: 0
Training loss: 1.6660406589508057
Validation loss: 2.023863072036415

Epoch: 5| Step: 1
Training loss: 2.111711025238037
Validation loss: 2.034051384977115

Epoch: 5| Step: 2
Training loss: 2.0298447608947754
Validation loss: 2.0280178259777766

Epoch: 5| Step: 3
Training loss: 2.0166783332824707
Validation loss: 2.028428767317085

Epoch: 5| Step: 4
Training loss: 1.9444929361343384
Validation loss: 2.0336880068625174

Epoch: 5| Step: 5
Training loss: 2.480647325515747
Validation loss: 2.0442083048564132

Epoch: 5| Step: 6
Training loss: 1.191093921661377
Validation loss: 2.0381431605226252

Epoch: 5| Step: 7
Training loss: 2.737675189971924
Validation loss: 2.000722869749992

Epoch: 5| Step: 8
Training loss: 2.4384069442749023
Validation loss: 1.9994230654931837

Epoch: 5| Step: 9
Training loss: 1.8596385717391968
Validation loss: 2.0032790348094

Epoch: 5| Step: 10
Training loss: 2.2615294456481934
Validation loss: 2.0023699088763167

Epoch: 149| Step: 0
Training loss: 2.0669591426849365
Validation loss: 1.9824379285176594

Epoch: 5| Step: 1
Training loss: 2.2255232334136963
Validation loss: 2.0123115957424207

Epoch: 5| Step: 2
Training loss: 2.754152297973633
Validation loss: 2.016495435468612

Epoch: 5| Step: 3
Training loss: 2.3282790184020996
Validation loss: 2.0220850783009685

Epoch: 5| Step: 4
Training loss: 1.903119444847107
Validation loss: 2.0105577220198927

Epoch: 5| Step: 5
Training loss: 2.523719310760498
Validation loss: 2.0107974570284606

Epoch: 5| Step: 6
Training loss: 1.758296251296997
Validation loss: 2.005363659192157

Epoch: 5| Step: 7
Training loss: 1.8195712566375732
Validation loss: 1.9903090307789464

Epoch: 5| Step: 8
Training loss: 1.565675973892212
Validation loss: 1.988945488006838

Epoch: 5| Step: 9
Training loss: 2.0878665447235107
Validation loss: 1.98315937929256

Epoch: 5| Step: 10
Training loss: 1.4496159553527832
Validation loss: 1.9992604512040333

Epoch: 150| Step: 0
Training loss: 1.6709277629852295
Validation loss: 2.0059687591368154

Epoch: 5| Step: 1
Training loss: 1.8720823526382446
Validation loss: 2.0053680571176673

Epoch: 5| Step: 2
Training loss: 1.8100563287734985
Validation loss: 2.0047046061485045

Epoch: 5| Step: 3
Training loss: 2.3396575450897217
Validation loss: 2.026602739928871

Epoch: 5| Step: 4
Training loss: 2.445225238800049
Validation loss: 2.03342842799361

Epoch: 5| Step: 5
Training loss: 1.929048776626587
Validation loss: 2.04207964610028

Epoch: 5| Step: 6
Training loss: 2.7688307762145996
Validation loss: 2.038224676603912

Epoch: 5| Step: 7
Training loss: 2.103325128555298
Validation loss: 2.0197878550457697

Epoch: 5| Step: 8
Training loss: 2.1302456855773926
Validation loss: 2.006990137920585

Epoch: 5| Step: 9
Training loss: 1.801896333694458
Validation loss: 1.9905169933072981

Epoch: 5| Step: 10
Training loss: 1.7241365909576416
Validation loss: 1.9960356784123245

Epoch: 151| Step: 0
Training loss: 2.2569499015808105
Validation loss: 2.001521087461902

Epoch: 5| Step: 1
Training loss: 1.6625163555145264
Validation loss: 2.0068073990524455

Epoch: 5| Step: 2
Training loss: 1.8163954019546509
Validation loss: 1.9974312090104627

Epoch: 5| Step: 3
Training loss: 2.0500001907348633
Validation loss: 2.0092143832996325

Epoch: 5| Step: 4
Training loss: 2.353726625442505
Validation loss: 2.013698272807624

Epoch: 5| Step: 5
Training loss: 2.152794599533081
Validation loss: 2.011401125179824

Epoch: 5| Step: 6
Training loss: 1.7950546741485596
Validation loss: 2.0083348187067176

Epoch: 5| Step: 7
Training loss: 1.652126669883728
Validation loss: 1.9901305885725125

Epoch: 5| Step: 8
Training loss: 1.927512764930725
Validation loss: 1.9987585480495165

Epoch: 5| Step: 9
Training loss: 2.044905185699463
Validation loss: 2.001634277323241

Epoch: 5| Step: 10
Training loss: 2.70943546295166
Validation loss: 1.999363673630581

Epoch: 152| Step: 0
Training loss: 1.833850622177124
Validation loss: 2.0101425211916686

Epoch: 5| Step: 1
Training loss: 1.6615104675292969
Validation loss: 2.018245981585595

Epoch: 5| Step: 2
Training loss: 1.726003646850586
Validation loss: 2.054316677072997

Epoch: 5| Step: 3
Training loss: 2.7456374168395996
Validation loss: 2.085557791494554

Epoch: 5| Step: 4
Training loss: 2.092247724533081
Validation loss: 2.0667547461807088

Epoch: 5| Step: 5
Training loss: 2.086832046508789
Validation loss: 2.061743241484447

Epoch: 5| Step: 6
Training loss: 2.258575439453125
Validation loss: 2.056107303147675

Epoch: 5| Step: 7
Training loss: 1.5321779251098633
Validation loss: 2.022491478150891

Epoch: 5| Step: 8
Training loss: 2.10687518119812
Validation loss: 2.017428933933217

Epoch: 5| Step: 9
Training loss: 2.290706157684326
Validation loss: 2.011358102162679

Epoch: 5| Step: 10
Training loss: 2.050041913986206
Validation loss: 1.9936993429737706

Epoch: 153| Step: 0
Training loss: 2.549736738204956
Validation loss: 1.9846464613432526

Epoch: 5| Step: 1
Training loss: 1.785248041152954
Validation loss: 1.9690440213808449

Epoch: 5| Step: 2
Training loss: 0.9141209721565247
Validation loss: 1.9987980370880456

Epoch: 5| Step: 3
Training loss: 1.611228346824646
Validation loss: 2.0350322710570468

Epoch: 5| Step: 4
Training loss: 2.238377332687378
Validation loss: 2.0751228870884066

Epoch: 5| Step: 5
Training loss: 2.7811226844787598
Validation loss: 2.1292295609751055

Epoch: 5| Step: 6
Training loss: 2.671372890472412
Validation loss: 2.109663318562251

Epoch: 5| Step: 7
Training loss: 2.1898460388183594
Validation loss: 2.0661970671787055

Epoch: 5| Step: 8
Training loss: 1.6664135456085205
Validation loss: 2.0135903114913614

Epoch: 5| Step: 9
Training loss: 1.849391222000122
Validation loss: 1.9683251355284004

Epoch: 5| Step: 10
Training loss: 2.4173781871795654
Validation loss: 1.9542040465980448

Epoch: 154| Step: 0
Training loss: 2.4439444541931152
Validation loss: 1.9633796317602998

Epoch: 5| Step: 1
Training loss: 1.6238791942596436
Validation loss: 1.9667052761200936

Epoch: 5| Step: 2
Training loss: 1.943640112876892
Validation loss: 1.9667622658514208

Epoch: 5| Step: 3
Training loss: 2.125656843185425
Validation loss: 1.9628837288066905

Epoch: 5| Step: 4
Training loss: 2.9101414680480957
Validation loss: 2.0074101904387116

Epoch: 5| Step: 5
Training loss: 2.349506139755249
Validation loss: 2.0411760243036414

Epoch: 5| Step: 6
Training loss: 2.1379799842834473
Validation loss: 2.0672210852305093

Epoch: 5| Step: 7
Training loss: 1.7935845851898193
Validation loss: 2.1067333221435547

Epoch: 5| Step: 8
Training loss: 2.1639328002929688
Validation loss: 2.1052272499248548

Epoch: 5| Step: 9
Training loss: 1.804086685180664
Validation loss: 2.084904191314533

Epoch: 5| Step: 10
Training loss: 2.2514216899871826
Validation loss: 2.036847864427874

Epoch: 155| Step: 0
Training loss: 1.9127178192138672
Validation loss: 1.9929264360858547

Epoch: 5| Step: 1
Training loss: 1.8173574209213257
Validation loss: 1.980444323632025

Epoch: 5| Step: 2
Training loss: 2.005699396133423
Validation loss: 1.9918939708381571

Epoch: 5| Step: 3
Training loss: 1.8248285055160522
Validation loss: 2.006271349486484

Epoch: 5| Step: 4
Training loss: 2.0497164726257324
Validation loss: 2.0399601818412862

Epoch: 5| Step: 5
Training loss: 2.3500113487243652
Validation loss: 2.0853794723428707

Epoch: 5| Step: 6
Training loss: 2.41837739944458
Validation loss: 2.119560706999994

Epoch: 5| Step: 7
Training loss: 2.129027843475342
Validation loss: 2.143922157185052

Epoch: 5| Step: 8
Training loss: 1.9331910610198975
Validation loss: 2.123899262438538

Epoch: 5| Step: 9
Training loss: 2.2556662559509277
Validation loss: 2.114270592248568

Epoch: 5| Step: 10
Training loss: 2.1908886432647705
Validation loss: 2.0632800632907498

Epoch: 156| Step: 0
Training loss: 1.9709079265594482
Validation loss: 2.0268235565513693

Epoch: 5| Step: 1
Training loss: 1.2078018188476562
Validation loss: 2.0045660618812806

Epoch: 5| Step: 2
Training loss: 1.8393211364746094
Validation loss: 1.997304848445359

Epoch: 5| Step: 3
Training loss: 2.378824234008789
Validation loss: 2.027347400624265

Epoch: 5| Step: 4
Training loss: 2.4616494178771973
Validation loss: 2.040883424461529

Epoch: 5| Step: 5
Training loss: 2.121894598007202
Validation loss: 2.0302989200879167

Epoch: 5| Step: 6
Training loss: 2.2457404136657715
Validation loss: 2.04716690381368

Epoch: 5| Step: 7
Training loss: 1.8562543392181396
Validation loss: 2.027296861012777

Epoch: 5| Step: 8
Training loss: 2.158815383911133
Validation loss: 2.0410646366816696

Epoch: 5| Step: 9
Training loss: 2.0421454906463623
Validation loss: 1.981793834317115

Epoch: 5| Step: 10
Training loss: 2.6470329761505127
Validation loss: 1.9551708775181924

Epoch: 157| Step: 0
Training loss: 2.426964521408081
Validation loss: 1.9478850069866385

Epoch: 5| Step: 1
Training loss: 2.651602268218994
Validation loss: 1.967588787437767

Epoch: 5| Step: 2
Training loss: 1.6066604852676392
Validation loss: 1.99050126793564

Epoch: 5| Step: 3
Training loss: 2.4611783027648926
Validation loss: 2.0215223143177647

Epoch: 5| Step: 4
Training loss: 1.1194666624069214
Validation loss: 2.0388864727430445

Epoch: 5| Step: 5
Training loss: 2.2739908695220947
Validation loss: 2.054347035705402

Epoch: 5| Step: 6
Training loss: 1.7123067378997803
Validation loss: 2.03819384882527

Epoch: 5| Step: 7
Training loss: 1.9840991497039795
Validation loss: 2.017516830916046

Epoch: 5| Step: 8
Training loss: 1.6822865009307861
Validation loss: 1.9994056852914954

Epoch: 5| Step: 9
Training loss: 2.1927332878112793
Validation loss: 1.9737014385961718

Epoch: 5| Step: 10
Training loss: 2.14890456199646
Validation loss: 1.987063443788918

Epoch: 158| Step: 0
Training loss: 1.3100258111953735
Validation loss: 1.9859163197137977

Epoch: 5| Step: 1
Training loss: 1.4406371116638184
Validation loss: 2.003281985559771

Epoch: 5| Step: 2
Training loss: 2.0697109699249268
Validation loss: 2.0312441600266324

Epoch: 5| Step: 3
Training loss: 2.1840760707855225
Validation loss: 2.062098995331795

Epoch: 5| Step: 4
Training loss: 1.663251280784607
Validation loss: 2.0720192283712406

Epoch: 5| Step: 5
Training loss: 2.173429489135742
Validation loss: 2.082134423717376

Epoch: 5| Step: 6
Training loss: 2.074378252029419
Validation loss: 2.0692110574373634

Epoch: 5| Step: 7
Training loss: 2.3358404636383057
Validation loss: 2.0479073447565876

Epoch: 5| Step: 8
Training loss: 1.4601390361785889
Validation loss: 2.033156077067057

Epoch: 5| Step: 9
Training loss: 2.2817416191101074
Validation loss: 2.040638264789376

Epoch: 5| Step: 10
Training loss: 3.0841236114501953
Validation loss: 2.0444338219140166

Epoch: 159| Step: 0
Training loss: 1.5493338108062744
Validation loss: 2.035349005012102

Epoch: 5| Step: 1
Training loss: 1.7864773273468018
Validation loss: 2.0272818457695747

Epoch: 5| Step: 2
Training loss: 1.4517055749893188
Validation loss: 2.023681502188406

Epoch: 5| Step: 3
Training loss: 2.5049326419830322
Validation loss: 2.019654225277644

Epoch: 5| Step: 4
Training loss: 2.482584238052368
Validation loss: 1.9977626185263357

Epoch: 5| Step: 5
Training loss: 2.065647840499878
Validation loss: 1.9994682150502359

Epoch: 5| Step: 6
Training loss: 2.3693161010742188
Validation loss: 1.9999540005960772

Epoch: 5| Step: 7
Training loss: 1.7736517190933228
Validation loss: 2.0125094664994108

Epoch: 5| Step: 8
Training loss: 1.96990966796875
Validation loss: 2.052056645834318

Epoch: 5| Step: 9
Training loss: 2.077751874923706
Validation loss: 2.077083806837759

Epoch: 5| Step: 10
Training loss: 2.095017433166504
Validation loss: 2.065899948919973

Epoch: 160| Step: 0
Training loss: 1.3763989210128784
Validation loss: 2.009367997928332

Epoch: 5| Step: 1
Training loss: 1.927046775817871
Validation loss: 1.9832827250162761

Epoch: 5| Step: 2
Training loss: 2.355832576751709
Validation loss: 1.9830610444468837

Epoch: 5| Step: 3
Training loss: 2.15474271774292
Validation loss: 1.989842681474583

Epoch: 5| Step: 4
Training loss: 1.9675697088241577
Validation loss: 2.0076660648469002

Epoch: 5| Step: 5
Training loss: 1.8394111394882202
Validation loss: 2.0294760452803744

Epoch: 5| Step: 6
Training loss: 2.242854595184326
Validation loss: 2.053738909382974

Epoch: 5| Step: 7
Training loss: 1.9527575969696045
Validation loss: 2.077668279729864

Epoch: 5| Step: 8
Training loss: 2.19392991065979
Validation loss: 2.11437738069924

Epoch: 5| Step: 9
Training loss: 1.864506483078003
Validation loss: 2.1410603677072833

Epoch: 5| Step: 10
Training loss: 2.2327845096588135
Validation loss: 2.147685097109887

Epoch: 161| Step: 0
Training loss: 2.1316840648651123
Validation loss: 2.1182269139956404

Epoch: 5| Step: 1
Training loss: 2.084857702255249
Validation loss: 2.1226573682600454

Epoch: 5| Step: 2
Training loss: 1.5494886636734009
Validation loss: 2.0675638542380383

Epoch: 5| Step: 3
Training loss: 1.800596833229065
Validation loss: 2.0310154461091563

Epoch: 5| Step: 4
Training loss: 1.999370813369751
Validation loss: 1.999287671940301

Epoch: 5| Step: 5
Training loss: 2.1407082080841064
Validation loss: 1.990911304309804

Epoch: 5| Step: 6
Training loss: 1.9592580795288086
Validation loss: 1.9875988344992361

Epoch: 5| Step: 7
Training loss: 2.4250080585479736
Validation loss: 1.9726405553920294

Epoch: 5| Step: 8
Training loss: 1.8463751077651978
Validation loss: 1.979254154748814

Epoch: 5| Step: 9
Training loss: 2.3453426361083984
Validation loss: 1.9939610419734832

Epoch: 5| Step: 10
Training loss: 1.4968297481536865
Validation loss: 2.0010836124420166

Epoch: 162| Step: 0
Training loss: 1.8527412414550781
Validation loss: 2.009521952239416

Epoch: 5| Step: 1
Training loss: 1.5884778499603271
Validation loss: 2.0315862189057055

Epoch: 5| Step: 2
Training loss: 2.1970043182373047
Validation loss: 2.066929599290253

Epoch: 5| Step: 3
Training loss: 1.9274170398712158
Validation loss: 2.0840981493714037

Epoch: 5| Step: 4
Training loss: 1.8598308563232422
Validation loss: 2.1130306695097234

Epoch: 5| Step: 5
Training loss: 2.1791508197784424
Validation loss: 2.1272117501945904

Epoch: 5| Step: 6
Training loss: 1.7413625717163086
Validation loss: 2.0780323359274093

Epoch: 5| Step: 7
Training loss: 2.142808437347412
Validation loss: 2.0340238796767367

Epoch: 5| Step: 8
Training loss: 2.1241307258605957
Validation loss: 1.9939157437252741

Epoch: 5| Step: 9
Training loss: 1.925540566444397
Validation loss: 1.9731302722807853

Epoch: 5| Step: 10
Training loss: 2.191680669784546
Validation loss: 1.9808518912202568

Epoch: 163| Step: 0
Training loss: 1.7699012756347656
Validation loss: 1.9586413457829466

Epoch: 5| Step: 1
Training loss: 2.560002326965332
Validation loss: 1.9682775953764557

Epoch: 5| Step: 2
Training loss: 2.278322696685791
Validation loss: 1.949746944571054

Epoch: 5| Step: 3
Training loss: 2.0369274616241455
Validation loss: 1.9692015545342558

Epoch: 5| Step: 4
Training loss: 1.4513349533081055
Validation loss: 1.9744984449878815

Epoch: 5| Step: 5
Training loss: 2.0928101539611816
Validation loss: 1.9723287243996896

Epoch: 5| Step: 6
Training loss: 2.4952728748321533
Validation loss: 1.9971643237657444

Epoch: 5| Step: 7
Training loss: 1.5723540782928467
Validation loss: 2.0245409114386446

Epoch: 5| Step: 8
Training loss: 2.0253944396972656
Validation loss: 2.0600705274971585

Epoch: 5| Step: 9
Training loss: 1.534385085105896
Validation loss: 2.085825668868198

Epoch: 5| Step: 10
Training loss: 1.8607879877090454
Validation loss: 2.0928476895055463

Epoch: 164| Step: 0
Training loss: 1.9902480840682983
Validation loss: 2.0734181750205254

Epoch: 5| Step: 1
Training loss: 1.730385422706604
Validation loss: 2.0505991417874574

Epoch: 5| Step: 2
Training loss: 1.757894515991211
Validation loss: 2.0219417002893265

Epoch: 5| Step: 3
Training loss: 3.010145902633667
Validation loss: 1.9738454575179725

Epoch: 5| Step: 4
Training loss: 2.3219642639160156
Validation loss: 1.9763292702295447

Epoch: 5| Step: 5
Training loss: 2.525721788406372
Validation loss: 1.9967202589076052

Epoch: 5| Step: 6
Training loss: 1.6180016994476318
Validation loss: 1.9971360288640505

Epoch: 5| Step: 7
Training loss: 1.7511959075927734
Validation loss: 1.9978530201860654

Epoch: 5| Step: 8
Training loss: 1.3104418516159058
Validation loss: 2.00682738519484

Epoch: 5| Step: 9
Training loss: 1.8006538152694702
Validation loss: 2.0206289406745666

Epoch: 5| Step: 10
Training loss: 2.0293185710906982
Validation loss: 2.0251350043922343

Epoch: 165| Step: 0
Training loss: 1.7434002161026
Validation loss: 2.0428315862532584

Epoch: 5| Step: 1
Training loss: 2.2374377250671387
Validation loss: 2.0299347728811283

Epoch: 5| Step: 2
Training loss: 1.703730583190918
Validation loss: 2.021021758356402

Epoch: 5| Step: 3
Training loss: 2.199140787124634
Validation loss: 2.020725122062109

Epoch: 5| Step: 4
Training loss: 2.45230770111084
Validation loss: 2.0395231375130276

Epoch: 5| Step: 5
Training loss: 1.7368810176849365
Validation loss: 2.049937794285436

Epoch: 5| Step: 6
Training loss: 1.8304904699325562
Validation loss: 2.0198069028956915

Epoch: 5| Step: 7
Training loss: 1.6491749286651611
Validation loss: 1.9911205230220672

Epoch: 5| Step: 8
Training loss: 1.8538429737091064
Validation loss: 1.9800062923021213

Epoch: 5| Step: 9
Training loss: 2.019514560699463
Validation loss: 1.9893243287199287

Epoch: 5| Step: 10
Training loss: 1.5619899034500122
Validation loss: 1.9804318604930755

Epoch: 166| Step: 0
Training loss: 1.4963411092758179
Validation loss: 1.9776975788095945

Epoch: 5| Step: 1
Training loss: 2.364448070526123
Validation loss: 1.9866483301244757

Epoch: 5| Step: 2
Training loss: 2.0945494174957275
Validation loss: 1.997548823715538

Epoch: 5| Step: 3
Training loss: 2.4934275150299072
Validation loss: 2.038188918944328

Epoch: 5| Step: 4
Training loss: 1.998800277709961
Validation loss: 2.0651005057878393

Epoch: 5| Step: 5
Training loss: 1.7968730926513672
Validation loss: 2.033062001710297

Epoch: 5| Step: 6
Training loss: 1.7273470163345337
Validation loss: 2.02121074481677

Epoch: 5| Step: 7
Training loss: 1.7749722003936768
Validation loss: 1.9841488099867297

Epoch: 5| Step: 8
Training loss: 1.880602240562439
Validation loss: 1.9530658439923358

Epoch: 5| Step: 9
Training loss: 1.7237708568572998
Validation loss: 1.95427712445618

Epoch: 5| Step: 10
Training loss: 1.8917772769927979
Validation loss: 1.947253006760792

Epoch: 167| Step: 0
Training loss: 2.22635817527771
Validation loss: 1.956658972206936

Epoch: 5| Step: 1
Training loss: 1.8447704315185547
Validation loss: 1.9701688340915147

Epoch: 5| Step: 2
Training loss: 1.9364830255508423
Validation loss: 1.9761381482565274

Epoch: 5| Step: 3
Training loss: 1.2542928457260132
Validation loss: 1.9808789978745163

Epoch: 5| Step: 4
Training loss: 2.3002986907958984
Validation loss: 1.991369928083112

Epoch: 5| Step: 5
Training loss: 1.7031900882720947
Validation loss: 2.0260971182136127

Epoch: 5| Step: 6
Training loss: 1.9533584117889404
Validation loss: 2.0594568278199885

Epoch: 5| Step: 7
Training loss: 1.8701999187469482
Validation loss: 2.090216580257621

Epoch: 5| Step: 8
Training loss: 1.546355128288269
Validation loss: 2.091873767555401

Epoch: 5| Step: 9
Training loss: 2.048815965652466
Validation loss: 2.1033374032666607

Epoch: 5| Step: 10
Training loss: 2.0583319664001465
Validation loss: 2.109631562745699

Epoch: 168| Step: 0
Training loss: 1.6534817218780518
Validation loss: 2.0608808340564853

Epoch: 5| Step: 1
Training loss: 1.1138300895690918
Validation loss: 2.0048587117143857

Epoch: 5| Step: 2
Training loss: 1.8283027410507202
Validation loss: 1.9951771100362141

Epoch: 5| Step: 3
Training loss: 2.075502634048462
Validation loss: 1.972221077129405

Epoch: 5| Step: 4
Training loss: 2.2079572677612305
Validation loss: 1.9691734647238126

Epoch: 5| Step: 5
Training loss: 1.835846185684204
Validation loss: 1.9645355427136986

Epoch: 5| Step: 6
Training loss: 2.2254042625427246
Validation loss: 1.9695854238284531

Epoch: 5| Step: 7
Training loss: 2.122013568878174
Validation loss: 2.0138437158317974

Epoch: 5| Step: 8
Training loss: 2.083021879196167
Validation loss: 2.023534103106427

Epoch: 5| Step: 9
Training loss: 2.220167398452759
Validation loss: 2.00718516431829

Epoch: 5| Step: 10
Training loss: 1.612101435661316
Validation loss: 2.009544139267296

Epoch: 169| Step: 0
Training loss: 2.1536166667938232
Validation loss: 2.007567972265264

Epoch: 5| Step: 1
Training loss: 2.151864528656006
Validation loss: 1.9907491104577177

Epoch: 5| Step: 2
Training loss: 2.101201295852661
Validation loss: 1.9823808952044415

Epoch: 5| Step: 3
Training loss: 1.5339055061340332
Validation loss: 1.9979730498406194

Epoch: 5| Step: 4
Training loss: 1.6656363010406494
Validation loss: 1.9921809652800202

Epoch: 5| Step: 5
Training loss: 1.6315943002700806
Validation loss: 2.0067184996861283

Epoch: 5| Step: 6
Training loss: 1.5618693828582764
Validation loss: 2.015856058366837

Epoch: 5| Step: 7
Training loss: 2.313912868499756
Validation loss: 2.010077425228652

Epoch: 5| Step: 8
Training loss: 1.6911470890045166
Validation loss: 1.9966216600069435

Epoch: 5| Step: 9
Training loss: 2.237748622894287
Validation loss: 2.008832053471637

Epoch: 5| Step: 10
Training loss: 1.5048245191574097
Validation loss: 2.0095504714596655

Epoch: 170| Step: 0
Training loss: 1.8589670658111572
Validation loss: 2.01800883969953

Epoch: 5| Step: 1
Training loss: 1.7877607345581055
Validation loss: 2.009950840344993

Epoch: 5| Step: 2
Training loss: 1.9061670303344727
Validation loss: 2.0227650339885423

Epoch: 5| Step: 3
Training loss: 1.4633147716522217
Validation loss: 2.0128932845207954

Epoch: 5| Step: 4
Training loss: 1.1180305480957031
Validation loss: 2.0230254639861402

Epoch: 5| Step: 5
Training loss: 2.290574312210083
Validation loss: 2.0014472443570375

Epoch: 5| Step: 6
Training loss: 1.6918869018554688
Validation loss: 2.013098459089956

Epoch: 5| Step: 7
Training loss: 1.6833282709121704
Validation loss: 2.004610268018579

Epoch: 5| Step: 8
Training loss: 1.807686448097229
Validation loss: 2.0236512743016726

Epoch: 5| Step: 9
Training loss: 2.4625868797302246
Validation loss: 2.0030066428645963

Epoch: 5| Step: 10
Training loss: 2.3021576404571533
Validation loss: 1.9780571281269033

Epoch: 171| Step: 0
Training loss: 2.3212082386016846
Validation loss: 1.9753034243019678

Epoch: 5| Step: 1
Training loss: 1.9002195596694946
Validation loss: 1.9867848465519566

Epoch: 5| Step: 2
Training loss: 2.13769268989563
Validation loss: 1.9894600170914845

Epoch: 5| Step: 3
Training loss: 2.0620884895324707
Validation loss: 1.9501563323441373

Epoch: 5| Step: 4
Training loss: 2.1479642391204834
Validation loss: 1.9393118402009368

Epoch: 5| Step: 5
Training loss: 1.8172270059585571
Validation loss: 1.9684884778914913

Epoch: 5| Step: 6
Training loss: 1.4789396524429321
Validation loss: 1.9948746683777019

Epoch: 5| Step: 7
Training loss: 0.8451298475265503
Validation loss: 2.0377138455708823

Epoch: 5| Step: 8
Training loss: 1.6082189083099365
Validation loss: 2.088765355848497

Epoch: 5| Step: 9
Training loss: 1.6542627811431885
Validation loss: 2.0886098979621806

Epoch: 5| Step: 10
Training loss: 2.5217859745025635
Validation loss: 2.0736532108758086

Epoch: 172| Step: 0
Training loss: 2.0607972145080566
Validation loss: 2.0322986854019987

Epoch: 5| Step: 1
Training loss: 1.7757618427276611
Validation loss: 2.0115404180301133

Epoch: 5| Step: 2
Training loss: 1.3846657276153564
Validation loss: 1.9985166301009476

Epoch: 5| Step: 3
Training loss: 1.8008953332901
Validation loss: 1.9951085159855504

Epoch: 5| Step: 4
Training loss: 1.995711326599121
Validation loss: 2.027471632085821

Epoch: 5| Step: 5
Training loss: 2.3240723609924316
Validation loss: 2.043548689093641

Epoch: 5| Step: 6
Training loss: 1.155186414718628
Validation loss: 2.0650177822318128

Epoch: 5| Step: 7
Training loss: 2.417186737060547
Validation loss: 2.087865344939693

Epoch: 5| Step: 8
Training loss: 2.1436028480529785
Validation loss: 2.063547072872039

Epoch: 5| Step: 9
Training loss: 1.7440822124481201
Validation loss: 2.0663849192280925

Epoch: 5| Step: 10
Training loss: 1.6673336029052734
Validation loss: 2.020463582008116

Epoch: 173| Step: 0
Training loss: 1.6480052471160889
Validation loss: 1.9800097942352295

Epoch: 5| Step: 1
Training loss: 1.8908717632293701
Validation loss: 1.9544397836090417

Epoch: 5| Step: 2
Training loss: 1.612231969833374
Validation loss: 1.9621078019501061

Epoch: 5| Step: 3
Training loss: 2.004239082336426
Validation loss: 1.9796562015369374

Epoch: 5| Step: 4
Training loss: 1.8507461547851562
Validation loss: 2.001993167784906

Epoch: 5| Step: 5
Training loss: 1.773821234703064
Validation loss: 2.056995814846408

Epoch: 5| Step: 6
Training loss: 1.9135377407073975
Validation loss: 2.068722573659753

Epoch: 5| Step: 7
Training loss: 2.4626517295837402
Validation loss: 2.0917389956853722

Epoch: 5| Step: 8
Training loss: 1.52231764793396
Validation loss: 2.122481711449162

Epoch: 5| Step: 9
Training loss: 1.8461201190948486
Validation loss: 2.1332556304111274

Epoch: 5| Step: 10
Training loss: 1.6672654151916504
Validation loss: 2.102629059104509

Epoch: 174| Step: 0
Training loss: 1.8589500188827515
Validation loss: 2.08924755742473

Epoch: 5| Step: 1
Training loss: 2.164797306060791
Validation loss: 2.064895281227686

Epoch: 5| Step: 2
Training loss: 1.775019884109497
Validation loss: 2.005234710631832

Epoch: 5| Step: 3
Training loss: 2.456820011138916
Validation loss: 1.9960403288564375

Epoch: 5| Step: 4
Training loss: 2.094080924987793
Validation loss: 1.9856435175864928

Epoch: 5| Step: 5
Training loss: 1.2995959520339966
Validation loss: 1.9651078536946287

Epoch: 5| Step: 6
Training loss: 1.2614948749542236
Validation loss: 1.9548503237385904

Epoch: 5| Step: 7
Training loss: 1.769160509109497
Validation loss: 1.9775247907125821

Epoch: 5| Step: 8
Training loss: 2.065192699432373
Validation loss: 1.9944103481949016

Epoch: 5| Step: 9
Training loss: 1.6619319915771484
Validation loss: 2.0454920414955384

Epoch: 5| Step: 10
Training loss: 2.051326036453247
Validation loss: 2.076567760077856

Epoch: 175| Step: 0
Training loss: 1.6854677200317383
Validation loss: 2.080586284719488

Epoch: 5| Step: 1
Training loss: 1.8807464838027954
Validation loss: 2.1141257209162556

Epoch: 5| Step: 2
Training loss: 1.9345729351043701
Validation loss: 2.132269764459261

Epoch: 5| Step: 3
Training loss: 2.2951316833496094
Validation loss: 2.0879706234060307

Epoch: 5| Step: 4
Training loss: 1.3850202560424805
Validation loss: 2.051685607561501

Epoch: 5| Step: 5
Training loss: 1.370357632637024
Validation loss: 2.037710944811503

Epoch: 5| Step: 6
Training loss: 1.7438157796859741
Validation loss: 2.021314255652889

Epoch: 5| Step: 7
Training loss: 2.0271191596984863
Validation loss: 2.0077626423169206

Epoch: 5| Step: 8
Training loss: 1.973189353942871
Validation loss: 1.999785856534076

Epoch: 5| Step: 9
Training loss: 2.081794023513794
Validation loss: 2.0020569434729953

Epoch: 5| Step: 10
Training loss: 1.849189281463623
Validation loss: 1.9920048739320488

Epoch: 176| Step: 0
Training loss: 1.6824252605438232
Validation loss: 2.0291195684863674

Epoch: 5| Step: 1
Training loss: 1.491150975227356
Validation loss: 2.0745810180582027

Epoch: 5| Step: 2
Training loss: 1.9270820617675781
Validation loss: 2.1321546569947274

Epoch: 5| Step: 3
Training loss: 1.498763918876648
Validation loss: 2.139455940133782

Epoch: 5| Step: 4
Training loss: 1.4936574697494507
Validation loss: 2.0743918649611937

Epoch: 5| Step: 5
Training loss: 1.6536633968353271
Validation loss: 2.0386270451289352

Epoch: 5| Step: 6
Training loss: 2.049349784851074
Validation loss: 1.9917468909294374

Epoch: 5| Step: 7
Training loss: 1.6141834259033203
Validation loss: 1.9707958467545048

Epoch: 5| Step: 8
Training loss: 2.1919124126434326
Validation loss: 1.972963535657493

Epoch: 5| Step: 9
Training loss: 2.184267044067383
Validation loss: 1.9852304945709884

Epoch: 5| Step: 10
Training loss: 2.7208964824676514
Validation loss: 1.9786864198664182

Epoch: 177| Step: 0
Training loss: 1.8321821689605713
Validation loss: 1.9814706002512286

Epoch: 5| Step: 1
Training loss: 1.4533675909042358
Validation loss: 1.996934853574281

Epoch: 5| Step: 2
Training loss: 1.3603969812393188
Validation loss: 2.014478555289648

Epoch: 5| Step: 3
Training loss: 1.6512428522109985
Validation loss: 2.018475765823036

Epoch: 5| Step: 4
Training loss: 1.4436559677124023
Validation loss: 2.01502739614056

Epoch: 5| Step: 5
Training loss: 2.469388246536255
Validation loss: 2.0199999527264665

Epoch: 5| Step: 6
Training loss: 2.15812611579895
Validation loss: 1.9871524380099388

Epoch: 5| Step: 7
Training loss: 1.9540233612060547
Validation loss: 1.9828938643137615

Epoch: 5| Step: 8
Training loss: 1.7934859991073608
Validation loss: 1.9676298018424743

Epoch: 5| Step: 9
Training loss: 1.9662986993789673
Validation loss: 1.9740287385961062

Epoch: 5| Step: 10
Training loss: 1.5222607851028442
Validation loss: 1.9726797226936585

Epoch: 178| Step: 0
Training loss: 2.444197416305542
Validation loss: 2.0015120288377166

Epoch: 5| Step: 1
Training loss: 1.9136323928833008
Validation loss: 2.015123398073258

Epoch: 5| Step: 2
Training loss: 2.0475311279296875
Validation loss: 2.0636842097005537

Epoch: 5| Step: 3
Training loss: 1.3217335939407349
Validation loss: 2.1068610811746247

Epoch: 5| Step: 4
Training loss: 1.666609525680542
Validation loss: 2.085846717639636

Epoch: 5| Step: 5
Training loss: 1.4748746156692505
Validation loss: 2.053484944887059

Epoch: 5| Step: 6
Training loss: 1.7814815044403076
Validation loss: 2.000098789891889

Epoch: 5| Step: 7
Training loss: 1.669257402420044
Validation loss: 1.9878058356623496

Epoch: 5| Step: 8
Training loss: 2.2036454677581787
Validation loss: 1.9751357468225623

Epoch: 5| Step: 9
Training loss: 1.6534652709960938
Validation loss: 1.9950202306111653

Epoch: 5| Step: 10
Training loss: 1.508240818977356
Validation loss: 1.9585274650204567

Epoch: 179| Step: 0
Training loss: 2.0562503337860107
Validation loss: 1.9821897565677602

Epoch: 5| Step: 1
Training loss: 1.664333701133728
Validation loss: 1.9852176840587328

Epoch: 5| Step: 2
Training loss: 1.5548362731933594
Validation loss: 1.9916347406243766

Epoch: 5| Step: 3
Training loss: 1.858737587928772
Validation loss: 1.9757345568749212

Epoch: 5| Step: 4
Training loss: 1.8025095462799072
Validation loss: 2.0028183614054034

Epoch: 5| Step: 5
Training loss: 1.320609211921692
Validation loss: 2.018423130435328

Epoch: 5| Step: 6
Training loss: 1.5177271366119385
Validation loss: 2.0850050167370866

Epoch: 5| Step: 7
Training loss: 2.070073127746582
Validation loss: 2.116442747013543

Epoch: 5| Step: 8
Training loss: 2.234041690826416
Validation loss: 2.166976183973333

Epoch: 5| Step: 9
Training loss: 1.8366079330444336
Validation loss: 2.120201313367454

Epoch: 5| Step: 10
Training loss: 1.9105224609375
Validation loss: 2.10615974087869

Epoch: 180| Step: 0
Training loss: 1.4015297889709473
Validation loss: 2.03543189520477

Epoch: 5| Step: 1
Training loss: 2.5811548233032227
Validation loss: 1.9916921097745177

Epoch: 5| Step: 2
Training loss: 1.5286974906921387
Validation loss: 1.9899348930646015

Epoch: 5| Step: 3
Training loss: 1.6245250701904297
Validation loss: 1.999238161630528

Epoch: 5| Step: 4
Training loss: 2.1927006244659424
Validation loss: 2.018196091857008

Epoch: 5| Step: 5
Training loss: 2.217435836791992
Validation loss: 2.042228667966781

Epoch: 5| Step: 6
Training loss: 1.8395593166351318
Validation loss: 2.0628450455204135

Epoch: 5| Step: 7
Training loss: 1.5609986782073975
Validation loss: 2.1444778378291796

Epoch: 5| Step: 8
Training loss: 1.2835198640823364
Validation loss: 2.186350018747391

Epoch: 5| Step: 9
Training loss: 2.272848606109619
Validation loss: 2.168543308011947

Epoch: 5| Step: 10
Training loss: 1.8364309072494507
Validation loss: 2.0377878809487946

Epoch: 181| Step: 0
Training loss: 1.6229854822158813
Validation loss: 1.9777684878277522

Epoch: 5| Step: 1
Training loss: 1.599678874015808
Validation loss: 1.9436832961215769

Epoch: 5| Step: 2
Training loss: 2.561687469482422
Validation loss: 1.913768486310077

Epoch: 5| Step: 3
Training loss: 1.930559754371643
Validation loss: 1.9008559334662654

Epoch: 5| Step: 4
Training loss: 1.949933409690857
Validation loss: 1.9010007445530226

Epoch: 5| Step: 5
Training loss: 1.9618209600448608
Validation loss: 1.9037365554481425

Epoch: 5| Step: 6
Training loss: 1.8217378854751587
Validation loss: 1.918406073765088

Epoch: 5| Step: 7
Training loss: 1.9685900211334229
Validation loss: 1.9241537099243493

Epoch: 5| Step: 8
Training loss: 1.6748912334442139
Validation loss: 1.965649595824621

Epoch: 5| Step: 9
Training loss: 1.8986661434173584
Validation loss: 2.013253684966795

Epoch: 5| Step: 10
Training loss: 1.3735134601593018
Validation loss: 2.0435600614035003

Epoch: 182| Step: 0
Training loss: 2.5473384857177734
Validation loss: 2.0950272390919347

Epoch: 5| Step: 1
Training loss: 1.8502781391143799
Validation loss: 2.101150833150392

Epoch: 5| Step: 2
Training loss: 2.296807289123535
Validation loss: 2.0954533071928125

Epoch: 5| Step: 3
Training loss: 1.6054508686065674
Validation loss: 2.0877210068446335

Epoch: 5| Step: 4
Training loss: 1.4972634315490723
Validation loss: 2.0627385518884145

Epoch: 5| Step: 5
Training loss: 1.7516021728515625
Validation loss: 2.036810177628712

Epoch: 5| Step: 6
Training loss: 1.427555799484253
Validation loss: 2.025033716232546

Epoch: 5| Step: 7
Training loss: 1.9797184467315674
Validation loss: 1.992130329532008

Epoch: 5| Step: 8
Training loss: 1.8563200235366821
Validation loss: 1.9966311762409825

Epoch: 5| Step: 9
Training loss: 1.4592729806900024
Validation loss: 1.9684192954853017

Epoch: 5| Step: 10
Training loss: 1.4536042213439941
Validation loss: 1.9971402434892551

Epoch: 183| Step: 0
Training loss: 1.5884931087493896
Validation loss: 2.0488992378275883

Epoch: 5| Step: 1
Training loss: 1.6253770589828491
Validation loss: 2.067633258399143

Epoch: 5| Step: 2
Training loss: 1.533874750137329
Validation loss: 2.1146579762940765

Epoch: 5| Step: 3
Training loss: 2.103699207305908
Validation loss: 2.108248431195495

Epoch: 5| Step: 4
Training loss: 2.1667323112487793
Validation loss: 2.027699444883613

Epoch: 5| Step: 5
Training loss: 1.534219741821289
Validation loss: 1.9642465345321163

Epoch: 5| Step: 6
Training loss: 1.6952564716339111
Validation loss: 1.9384801823605773

Epoch: 5| Step: 7
Training loss: 1.3128150701522827
Validation loss: 1.9336634028342463

Epoch: 5| Step: 8
Training loss: 1.8970048427581787
Validation loss: 1.9496974816886328

Epoch: 5| Step: 9
Training loss: 2.410968780517578
Validation loss: 1.9389239049726916

Epoch: 5| Step: 10
Training loss: 1.9248684644699097
Validation loss: 1.922646403312683

Epoch: 184| Step: 0
Training loss: 2.2216739654541016
Validation loss: 1.926511456889491

Epoch: 5| Step: 1
Training loss: 1.4015268087387085
Validation loss: 1.9679455641777284

Epoch: 5| Step: 2
Training loss: 1.9964815378189087
Validation loss: 2.004900255510884

Epoch: 5| Step: 3
Training loss: 1.4526660442352295
Validation loss: 2.056442791415799

Epoch: 5| Step: 4
Training loss: 1.7066208124160767
Validation loss: 2.1226808473628056

Epoch: 5| Step: 5
Training loss: 1.8521474599838257
Validation loss: 2.1631566888542584

Epoch: 5| Step: 6
Training loss: 1.6784261465072632
Validation loss: 2.1407623649925314

Epoch: 5| Step: 7
Training loss: 1.4272390604019165
Validation loss: 2.0856124098582933

Epoch: 5| Step: 8
Training loss: 1.4069324731826782
Validation loss: 2.0120379181318384

Epoch: 5| Step: 9
Training loss: 2.164761781692505
Validation loss: 1.9875243427932903

Epoch: 5| Step: 10
Training loss: 1.920530915260315
Validation loss: 1.939744487885506

Epoch: 185| Step: 0
Training loss: 1.7710037231445312
Validation loss: 1.9439565161223054

Epoch: 5| Step: 1
Training loss: 1.8066339492797852
Validation loss: 1.9329142006494666

Epoch: 5| Step: 2
Training loss: 1.5892072916030884
Validation loss: 1.955095225764859

Epoch: 5| Step: 3
Training loss: 2.2059104442596436
Validation loss: 1.961401185681743

Epoch: 5| Step: 4
Training loss: 1.981723427772522
Validation loss: 1.9611979043611916

Epoch: 5| Step: 5
Training loss: 1.465779423713684
Validation loss: 1.9879228735482821

Epoch: 5| Step: 6
Training loss: 2.405660629272461
Validation loss: 1.9897746245066326

Epoch: 5| Step: 7
Training loss: 1.4357744455337524
Validation loss: 2.016910242777999

Epoch: 5| Step: 8
Training loss: 1.3068933486938477
Validation loss: 2.026824871699015

Epoch: 5| Step: 9
Training loss: 1.5416866540908813
Validation loss: 2.035627674031001

Epoch: 5| Step: 10
Training loss: 1.6444170475006104
Validation loss: 2.037316236444699

Epoch: 186| Step: 0
Training loss: 1.8344558477401733
Validation loss: 2.0126881778881116

Epoch: 5| Step: 1
Training loss: 1.8672049045562744
Validation loss: 1.9895712688405027

Epoch: 5| Step: 2
Training loss: 1.6442830562591553
Validation loss: 1.965634202444425

Epoch: 5| Step: 3
Training loss: 2.0600287914276123
Validation loss: 1.951915023147419

Epoch: 5| Step: 4
Training loss: 1.5988763570785522
Validation loss: 1.9563318298709007

Epoch: 5| Step: 5
Training loss: 1.4058570861816406
Validation loss: 1.9528007558597031

Epoch: 5| Step: 6
Training loss: 1.7552173137664795
Validation loss: 1.9640741630267071

Epoch: 5| Step: 7
Training loss: 1.9755589962005615
Validation loss: 1.9768319053034629

Epoch: 5| Step: 8
Training loss: 1.8894920349121094
Validation loss: 1.9975204621591875

Epoch: 5| Step: 9
Training loss: 1.6288883686065674
Validation loss: 1.9996175868536836

Epoch: 5| Step: 10
Training loss: 1.73994779586792
Validation loss: 1.9953418675289358

Epoch: 187| Step: 0
Training loss: 2.1614327430725098
Validation loss: 1.993972155355638

Epoch: 5| Step: 1
Training loss: 2.2860095500946045
Validation loss: 1.9746997689688077

Epoch: 5| Step: 2
Training loss: 1.9062941074371338
Validation loss: 2.0229969588659142

Epoch: 5| Step: 3
Training loss: 1.4814941883087158
Validation loss: 1.9873975041092082

Epoch: 5| Step: 4
Training loss: 1.5736976861953735
Validation loss: 1.9829477956218104

Epoch: 5| Step: 5
Training loss: 1.1528924703598022
Validation loss: 1.9687626079846454

Epoch: 5| Step: 6
Training loss: 1.4382259845733643
Validation loss: 1.9555923708023564

Epoch: 5| Step: 7
Training loss: 2.3659727573394775
Validation loss: 1.9549095887009815

Epoch: 5| Step: 8
Training loss: 0.8867180943489075
Validation loss: 1.9378764603727607

Epoch: 5| Step: 9
Training loss: 1.7233835458755493
Validation loss: 1.944488856100267

Epoch: 5| Step: 10
Training loss: 1.9796615839004517
Validation loss: 1.9591965726626817

Epoch: 188| Step: 0
Training loss: 1.8646996021270752
Validation loss: 2.01483275428895

Epoch: 5| Step: 1
Training loss: 1.8247959613800049
Validation loss: 2.086091305619927

Epoch: 5| Step: 2
Training loss: 1.580825686454773
Validation loss: 2.1660079661236016

Epoch: 5| Step: 3
Training loss: 2.1266846656799316
Validation loss: 2.1845246361147974

Epoch: 5| Step: 4
Training loss: 1.8361732959747314
Validation loss: 2.2477695326651297

Epoch: 5| Step: 5
Training loss: 2.2440242767333984
Validation loss: 2.2147899622558267

Epoch: 5| Step: 6
Training loss: 1.565124750137329
Validation loss: 2.12468949953715

Epoch: 5| Step: 7
Training loss: 2.022700071334839
Validation loss: 2.035684044643115

Epoch: 5| Step: 8
Training loss: 1.6103994846343994
Validation loss: 1.994777424361116

Epoch: 5| Step: 9
Training loss: 1.593511700630188
Validation loss: 1.9810455858066518

Epoch: 5| Step: 10
Training loss: 1.4482898712158203
Validation loss: 1.9541893934690824

Epoch: 189| Step: 0
Training loss: 1.381791353225708
Validation loss: 1.937996397736252

Epoch: 5| Step: 1
Training loss: 1.701375961303711
Validation loss: 1.9341132153746903

Epoch: 5| Step: 2
Training loss: 1.5782302618026733
Validation loss: 1.964089359006574

Epoch: 5| Step: 3
Training loss: 1.9460090398788452
Validation loss: 2.038426269767105

Epoch: 5| Step: 4
Training loss: 1.659428358078003
Validation loss: 2.0733388649520053

Epoch: 5| Step: 5
Training loss: 1.3884695768356323
Validation loss: 2.035110089086717

Epoch: 5| Step: 6
Training loss: 1.8886737823486328
Validation loss: 1.9919645273557274

Epoch: 5| Step: 7
Training loss: 1.6774024963378906
Validation loss: 1.9616796380730086

Epoch: 5| Step: 8
Training loss: 1.7424099445343018
Validation loss: 1.9390422387789654

Epoch: 5| Step: 9
Training loss: 1.8262321949005127
Validation loss: 1.949843361813535

Epoch: 5| Step: 10
Training loss: 1.8600846529006958
Validation loss: 1.9775090627772833

Epoch: 190| Step: 0
Training loss: 1.3791937828063965
Validation loss: 1.9686216974771151

Epoch: 5| Step: 1
Training loss: 1.6914291381835938
Validation loss: 1.9832625017371228

Epoch: 5| Step: 2
Training loss: 1.3951057195663452
Validation loss: 2.019675444531184

Epoch: 5| Step: 3
Training loss: 1.3165616989135742
Validation loss: 2.040980915869436

Epoch: 5| Step: 4
Training loss: 1.6301701068878174
Validation loss: 2.0776604119167534

Epoch: 5| Step: 5
Training loss: 1.4638545513153076
Validation loss: 2.1179638908755396

Epoch: 5| Step: 6
Training loss: 1.5912067890167236
Validation loss: 2.1083637873331704

Epoch: 5| Step: 7
Training loss: 2.220912456512451
Validation loss: 2.091704237845636

Epoch: 5| Step: 8
Training loss: 1.4369782209396362
Validation loss: 2.060235502899334

Epoch: 5| Step: 9
Training loss: 2.2831268310546875
Validation loss: 2.0320445286330355

Epoch: 5| Step: 10
Training loss: 2.252479314804077
Validation loss: 1.9979075808678903

Epoch: 191| Step: 0
Training loss: 1.802680253982544
Validation loss: 1.971002419789632

Epoch: 5| Step: 1
Training loss: 1.9453353881835938
Validation loss: 1.9725181659062703

Epoch: 5| Step: 2
Training loss: 1.7862060070037842
Validation loss: 1.9452470617909585

Epoch: 5| Step: 3
Training loss: 1.4595508575439453
Validation loss: 1.9379088340267059

Epoch: 5| Step: 4
Training loss: 2.5081915855407715
Validation loss: 1.9456544486425256

Epoch: 5| Step: 5
Training loss: 1.539947748184204
Validation loss: 1.9606711941380655

Epoch: 5| Step: 6
Training loss: 1.7353153228759766
Validation loss: 1.9422808911210747

Epoch: 5| Step: 7
Training loss: 1.240779161453247
Validation loss: 1.9427635362071376

Epoch: 5| Step: 8
Training loss: 1.6271631717681885
Validation loss: 1.9217505198653027

Epoch: 5| Step: 9
Training loss: 1.2349157333374023
Validation loss: 1.9146867464947444

Epoch: 5| Step: 10
Training loss: 1.4238063097000122
Validation loss: 1.9416842127359042

Epoch: 192| Step: 0
Training loss: 1.5365030765533447
Validation loss: 1.9685290090499385

Epoch: 5| Step: 1
Training loss: 2.2358667850494385
Validation loss: 2.0242543399974866

Epoch: 5| Step: 2
Training loss: 1.4610778093338013
Validation loss: 2.0870436699159685

Epoch: 5| Step: 3
Training loss: 1.72842538356781
Validation loss: 2.110175096860496

Epoch: 5| Step: 4
Training loss: 1.436720371246338
Validation loss: 2.0617217863759687

Epoch: 5| Step: 5
Training loss: 1.8077930212020874
Validation loss: 2.0578476959659207

Epoch: 5| Step: 6
Training loss: 1.461361289024353
Validation loss: 2.1043628749027046

Epoch: 5| Step: 7
Training loss: 2.015941619873047
Validation loss: 2.10873673295462

Epoch: 5| Step: 8
Training loss: 1.5578171014785767
Validation loss: 2.1101579935319963

Epoch: 5| Step: 9
Training loss: 1.5182304382324219
Validation loss: 2.076981288130565

Epoch: 5| Step: 10
Training loss: 2.081864356994629
Validation loss: 2.0584612610519573

Epoch: 193| Step: 0
Training loss: 1.6331955194473267
Validation loss: 2.021779526946365

Epoch: 5| Step: 1
Training loss: 1.6051565408706665
Validation loss: 2.000507398318219

Epoch: 5| Step: 2
Training loss: 2.464348554611206
Validation loss: 1.9978820944345126

Epoch: 5| Step: 3
Training loss: 1.1809666156768799
Validation loss: 1.9545564087488319

Epoch: 5| Step: 4
Training loss: 1.6035619974136353
Validation loss: 1.9658485356197561

Epoch: 5| Step: 5
Training loss: 2.030125141143799
Validation loss: 1.975657909147201

Epoch: 5| Step: 6
Training loss: 1.7285919189453125
Validation loss: 2.0214589488121772

Epoch: 5| Step: 7
Training loss: 1.0251836776733398
Validation loss: 2.0124133440756027

Epoch: 5| Step: 8
Training loss: 1.6589053869247437
Validation loss: 1.945284189716462

Epoch: 5| Step: 9
Training loss: 1.6403945684432983
Validation loss: 1.9368265008413663

Epoch: 5| Step: 10
Training loss: 1.821930170059204
Validation loss: 1.9227749198995612

Epoch: 194| Step: 0
Training loss: 1.842036247253418
Validation loss: 1.908646680975473

Epoch: 5| Step: 1
Training loss: 1.1421476602554321
Validation loss: 1.9238806309238556

Epoch: 5| Step: 2
Training loss: 1.4456491470336914
Validation loss: 1.925194896677489

Epoch: 5| Step: 3
Training loss: 2.0125322341918945
Validation loss: 1.9454085788419169

Epoch: 5| Step: 4
Training loss: 1.1761562824249268
Validation loss: 1.9426399251466155

Epoch: 5| Step: 5
Training loss: 2.1183557510375977
Validation loss: 1.9760555772371189

Epoch: 5| Step: 6
Training loss: 1.9707025289535522
Validation loss: 1.9904770261497908

Epoch: 5| Step: 7
Training loss: 1.5418920516967773
Validation loss: 2.027730620035561

Epoch: 5| Step: 8
Training loss: 1.3619439601898193
Validation loss: 2.1005437322842178

Epoch: 5| Step: 9
Training loss: 1.8676286935806274
Validation loss: 2.1418898054348525

Epoch: 5| Step: 10
Training loss: 1.8035215139389038
Validation loss: 2.1403357008452057

Epoch: 195| Step: 0
Training loss: 1.013948917388916
Validation loss: 2.123497853996933

Epoch: 5| Step: 1
Training loss: 1.7420177459716797
Validation loss: 2.039050832871468

Epoch: 5| Step: 2
Training loss: 1.8187978267669678
Validation loss: 2.02251664797465

Epoch: 5| Step: 3
Training loss: 1.7070575952529907
Validation loss: 2.0007037988273044

Epoch: 5| Step: 4
Training loss: 1.2924153804779053
Validation loss: 1.9866910493502052

Epoch: 5| Step: 5
Training loss: 2.5058066844940186
Validation loss: 1.963998116472716

Epoch: 5| Step: 6
Training loss: 1.3829667568206787
Validation loss: 1.949567546126663

Epoch: 5| Step: 7
Training loss: 2.1255059242248535
Validation loss: 1.9467475427094327

Epoch: 5| Step: 8
Training loss: 1.4157994985580444
Validation loss: 1.9311723786015664

Epoch: 5| Step: 9
Training loss: 1.542065143585205
Validation loss: 1.9262861103139899

Epoch: 5| Step: 10
Training loss: 1.2667717933654785
Validation loss: 1.9653093686667822

Epoch: 196| Step: 0
Training loss: 2.1257424354553223
Validation loss: 1.9601388490328224

Epoch: 5| Step: 1
Training loss: 1.9557355642318726
Validation loss: 2.011903500044218

Epoch: 5| Step: 2
Training loss: 2.0317814350128174
Validation loss: 2.041236849241359

Epoch: 5| Step: 3
Training loss: 1.5696170330047607
Validation loss: 2.048290983323128

Epoch: 5| Step: 4
Training loss: 1.8171701431274414
Validation loss: 2.025589443022205

Epoch: 5| Step: 5
Training loss: 0.9095619916915894
Validation loss: 1.9746901476255028

Epoch: 5| Step: 6
Training loss: 1.670698881149292
Validation loss: 1.9385186318428285

Epoch: 5| Step: 7
Training loss: 1.6166833639144897
Validation loss: 1.9232757578613937

Epoch: 5| Step: 8
Training loss: 1.37278151512146
Validation loss: 1.9309894423330984

Epoch: 5| Step: 9
Training loss: 1.521130919456482
Validation loss: 1.9432538786242086

Epoch: 5| Step: 10
Training loss: 1.3218854665756226
Validation loss: 1.959660614690473

Epoch: 197| Step: 0
Training loss: 1.1053879261016846
Validation loss: 1.9999461763648576

Epoch: 5| Step: 1
Training loss: 1.6004045009613037
Validation loss: 2.045909886719078

Epoch: 5| Step: 2
Training loss: 1.9742536544799805
Validation loss: 2.0895792284319477

Epoch: 5| Step: 3
Training loss: 2.0072054862976074
Validation loss: 2.1186245564491517

Epoch: 5| Step: 4
Training loss: 2.0989856719970703
Validation loss: 2.059668884482435

Epoch: 5| Step: 5
Training loss: 0.8399386405944824
Validation loss: 1.9780936292422715

Epoch: 5| Step: 6
Training loss: 1.4285717010498047
Validation loss: 1.956749636639831

Epoch: 5| Step: 7
Training loss: 1.3113089799880981
Validation loss: 1.9535679830017911

Epoch: 5| Step: 8
Training loss: 1.515215516090393
Validation loss: 1.9573733268245574

Epoch: 5| Step: 9
Training loss: 2.3541698455810547
Validation loss: 1.9527664748571252

Epoch: 5| Step: 10
Training loss: 1.530079960823059
Validation loss: 1.9690538478154007

Epoch: 198| Step: 0
Training loss: 1.8730671405792236
Validation loss: 1.9713443299775482

Epoch: 5| Step: 1
Training loss: 1.750282645225525
Validation loss: 1.9659073903996458

Epoch: 5| Step: 2
Training loss: 1.6681808233261108
Validation loss: 1.9922867731381488

Epoch: 5| Step: 3
Training loss: 0.9241905212402344
Validation loss: 1.9906255211881412

Epoch: 5| Step: 4
Training loss: 1.6312816143035889
Validation loss: 2.0176991801108084

Epoch: 5| Step: 5
Training loss: 1.4408457279205322
Validation loss: 2.063187837600708

Epoch: 5| Step: 6
Training loss: 1.9850499629974365
Validation loss: 2.0665422075538227

Epoch: 5| Step: 7
Training loss: 1.7780250310897827
Validation loss: 2.0112099416794313

Epoch: 5| Step: 8
Training loss: 1.4864500761032104
Validation loss: 1.967865602944487

Epoch: 5| Step: 9
Training loss: 1.5059795379638672
Validation loss: 1.943216726344119

Epoch: 5| Step: 10
Training loss: 1.3586180210113525
Validation loss: 1.904763267886254

Epoch: 199| Step: 0
Training loss: 1.8029415607452393
Validation loss: 1.9026477183065107

Epoch: 5| Step: 1
Training loss: 1.798945426940918
Validation loss: 1.88907874912344

Epoch: 5| Step: 2
Training loss: 1.7881765365600586
Validation loss: 1.8897673609436199

Epoch: 5| Step: 3
Training loss: 1.3355406522750854
Validation loss: 1.8774678796850226

Epoch: 5| Step: 4
Training loss: 1.3399312496185303
Validation loss: 1.8868252320956158

Epoch: 5| Step: 5
Training loss: 1.3119266033172607
Validation loss: 1.9052444350334905

Epoch: 5| Step: 6
Training loss: 1.0829424858093262
Validation loss: 1.940830938277706

Epoch: 5| Step: 7
Training loss: 1.5635290145874023
Validation loss: 1.9852252967896

Epoch: 5| Step: 8
Training loss: 2.161039113998413
Validation loss: 2.028174178574675

Epoch: 5| Step: 9
Training loss: 2.13960599899292
Validation loss: 2.0393134599090903

Epoch: 5| Step: 10
Training loss: 0.8606761693954468
Validation loss: 2.025025749719271

Epoch: 200| Step: 0
Training loss: 1.715855360031128
Validation loss: 2.045705291532701

Epoch: 5| Step: 1
Training loss: 2.255617380142212
Validation loss: 2.0328187993777695

Epoch: 5| Step: 2
Training loss: 2.1461219787597656
Validation loss: 2.01686038637674

Epoch: 5| Step: 3
Training loss: 1.74997079372406
Validation loss: 2.007323431712325

Epoch: 5| Step: 4
Training loss: 1.1391710042953491
Validation loss: 2.029733827037196

Epoch: 5| Step: 5
Training loss: 1.355494499206543
Validation loss: 2.0447133074524584

Epoch: 5| Step: 6
Training loss: 1.876885175704956
Validation loss: 2.0642935447795416

Epoch: 5| Step: 7
Training loss: 1.226159691810608
Validation loss: 2.0347594471387964

Epoch: 5| Step: 8
Training loss: 0.8930073976516724
Validation loss: 1.9944267067857968

Epoch: 5| Step: 9
Training loss: 1.6965450048446655
Validation loss: 2.0058280396205124

Epoch: 5| Step: 10
Training loss: 1.221055030822754
Validation loss: 1.9589258176024242

Epoch: 201| Step: 0
Training loss: 1.640167236328125
Validation loss: 1.9345994046939317

Epoch: 5| Step: 1
Training loss: 1.771522879600525
Validation loss: 1.9280417798667826

Epoch: 5| Step: 2
Training loss: 1.377825379371643
Validation loss: 1.9160606886750908

Epoch: 5| Step: 3
Training loss: 1.736194372177124
Validation loss: 1.908049286052745

Epoch: 5| Step: 4
Training loss: 1.7509028911590576
Validation loss: 1.9209748916728522

Epoch: 5| Step: 5
Training loss: 1.1955950260162354
Validation loss: 1.9256243154566774

Epoch: 5| Step: 6
Training loss: 1.19523024559021
Validation loss: 1.9548462821591286

Epoch: 5| Step: 7
Training loss: 1.3470520973205566
Validation loss: 2.0181202068123767

Epoch: 5| Step: 8
Training loss: 2.11482572555542
Validation loss: 2.0183291614696546

Epoch: 5| Step: 9
Training loss: 1.3697446584701538
Validation loss: 1.9791317319357267

Epoch: 5| Step: 10
Training loss: 1.5528839826583862
Validation loss: 1.9783156379576652

Epoch: 202| Step: 0
Training loss: 2.028576135635376
Validation loss: 1.9593669547829577

Epoch: 5| Step: 1
Training loss: 1.6162927150726318
Validation loss: 1.973342687852921

Epoch: 5| Step: 2
Training loss: 1.4309442043304443
Validation loss: 2.002133710410005

Epoch: 5| Step: 3
Training loss: 1.4713037014007568
Validation loss: 2.0243770332746607

Epoch: 5| Step: 4
Training loss: 1.5782577991485596
Validation loss: 2.0380239230330273

Epoch: 5| Step: 5
Training loss: 1.5170533657073975
Validation loss: 2.0491836224832842

Epoch: 5| Step: 6
Training loss: 1.2964046001434326
Validation loss: 2.0145136515299478

Epoch: 5| Step: 7
Training loss: 0.9673949480056763
Validation loss: 2.0361273724545716

Epoch: 5| Step: 8
Training loss: 1.4834455251693726
Validation loss: 2.0164613800664104

Epoch: 5| Step: 9
Training loss: 1.4108684062957764
Validation loss: 2.0317332039597216

Epoch: 5| Step: 10
Training loss: 2.1743292808532715
Validation loss: 1.974642712582824

Epoch: 203| Step: 0
Training loss: 1.259549856185913
Validation loss: 1.9622949912983885

Epoch: 5| Step: 1
Training loss: 2.108150005340576
Validation loss: 1.9609054327011108

Epoch: 5| Step: 2
Training loss: 1.2267690896987915
Validation loss: 1.932407211231929

Epoch: 5| Step: 3
Training loss: 1.478965401649475
Validation loss: 1.9431966556015836

Epoch: 5| Step: 4
Training loss: 1.701322317123413
Validation loss: 1.9627256470341836

Epoch: 5| Step: 5
Training loss: 0.9053251147270203
Validation loss: 1.9477030820744012

Epoch: 5| Step: 6
Training loss: 1.30821692943573
Validation loss: 1.9490652802169963

Epoch: 5| Step: 7
Training loss: 2.0700466632843018
Validation loss: 1.975845597123587

Epoch: 5| Step: 8
Training loss: 1.6902599334716797
Validation loss: 1.9662850364562003

Epoch: 5| Step: 9
Training loss: 1.7775558233261108
Validation loss: 1.960670385309445

Epoch: 5| Step: 10
Training loss: 0.8625227808952332
Validation loss: 1.9430382982377084

Epoch: 204| Step: 0
Training loss: 1.4623148441314697
Validation loss: 1.9460735577408985

Epoch: 5| Step: 1
Training loss: 1.5814194679260254
Validation loss: 1.9939440475997103

Epoch: 5| Step: 2
Training loss: 1.1559550762176514
Validation loss: 2.0130249402856313

Epoch: 5| Step: 3
Training loss: 1.1717097759246826
Validation loss: 1.9776475647444367

Epoch: 5| Step: 4
Training loss: 1.3609282970428467
Validation loss: 1.9766995342828895

Epoch: 5| Step: 5
Training loss: 1.4377912282943726
Validation loss: 1.978626625512236

Epoch: 5| Step: 6
Training loss: 2.129303216934204
Validation loss: 1.9689891774167296

Epoch: 5| Step: 7
Training loss: 1.9077659845352173
Validation loss: 1.9548622882494362

Epoch: 5| Step: 8
Training loss: 1.7448374032974243
Validation loss: 1.9495600295323197

Epoch: 5| Step: 9
Training loss: 1.1022835969924927
Validation loss: 1.943913318777597

Epoch: 5| Step: 10
Training loss: 1.370849370956421
Validation loss: 1.9575012076285578

Epoch: 205| Step: 0
Training loss: 1.5523581504821777
Validation loss: 1.9962921065668906

Epoch: 5| Step: 1
Training loss: 1.570108413696289
Validation loss: 2.0543329382455475

Epoch: 5| Step: 2
Training loss: 1.403985857963562
Validation loss: 2.076297974073759

Epoch: 5| Step: 3
Training loss: 1.119195818901062
Validation loss: 2.029263909145068

Epoch: 5| Step: 4
Training loss: 1.442091703414917
Validation loss: 1.9499488056346934

Epoch: 5| Step: 5
Training loss: 2.271773099899292
Validation loss: 1.927868978951567

Epoch: 5| Step: 6
Training loss: 0.7777343988418579
Validation loss: 1.9106376632567375

Epoch: 5| Step: 7
Training loss: 1.9913734197616577
Validation loss: 1.903704195894221

Epoch: 5| Step: 8
Training loss: 1.7021408081054688
Validation loss: 1.9031203152031027

Epoch: 5| Step: 9
Training loss: 1.9563302993774414
Validation loss: 1.920878424439379

Epoch: 5| Step: 10
Training loss: 1.0092369318008423
Validation loss: 1.9518167857200868

Epoch: 206| Step: 0
Training loss: 1.4517171382904053
Validation loss: 1.9897754551261984

Epoch: 5| Step: 1
Training loss: 0.9385932087898254
Validation loss: 2.014311062392368

Epoch: 5| Step: 2
Training loss: 1.1201810836791992
Validation loss: 2.086343098712224

Epoch: 5| Step: 3
Training loss: 1.7311217784881592
Validation loss: 2.132020014588551

Epoch: 5| Step: 4
Training loss: 1.4758472442626953
Validation loss: 2.138115308618033

Epoch: 5| Step: 5
Training loss: 1.2623692750930786
Validation loss: 2.077934662501017

Epoch: 5| Step: 6
Training loss: 2.253784656524658
Validation loss: 2.0370912487788866

Epoch: 5| Step: 7
Training loss: 1.5097471475601196
Validation loss: 1.9649902236077093

Epoch: 5| Step: 8
Training loss: 1.7694448232650757
Validation loss: 1.9283589675862303

Epoch: 5| Step: 9
Training loss: 1.7958341836929321
Validation loss: 1.9151280041663878

Epoch: 5| Step: 10
Training loss: 1.2467907667160034
Validation loss: 1.9117792229498587

Epoch: 207| Step: 0
Training loss: 1.9297109842300415
Validation loss: 1.9352013372605847

Epoch: 5| Step: 1
Training loss: 1.6903969049453735
Validation loss: 1.9439579312519362

Epoch: 5| Step: 2
Training loss: 1.7520415782928467
Validation loss: 1.9698892408801663

Epoch: 5| Step: 3
Training loss: 1.1082313060760498
Validation loss: 1.9818741659964285

Epoch: 5| Step: 4
Training loss: 1.2910687923431396
Validation loss: 2.028176733242568

Epoch: 5| Step: 5
Training loss: 1.129522442817688
Validation loss: 2.0167194156236548

Epoch: 5| Step: 6
Training loss: 1.433759331703186
Validation loss: 2.0395689754075903

Epoch: 5| Step: 7
Training loss: 1.0195224285125732
Validation loss: 2.002609675930392

Epoch: 5| Step: 8
Training loss: 1.4288922548294067
Validation loss: 1.9859779393801125

Epoch: 5| Step: 9
Training loss: 2.022251605987549
Validation loss: 1.9803024004864436

Epoch: 5| Step: 10
Training loss: 1.638192057609558
Validation loss: 1.9829393894441667

Epoch: 208| Step: 0
Training loss: 1.3202900886535645
Validation loss: 1.960222605736025

Epoch: 5| Step: 1
Training loss: 1.4574072360992432
Validation loss: 1.962818371352329

Epoch: 5| Step: 2
Training loss: 1.614522933959961
Validation loss: 1.963543035650766

Epoch: 5| Step: 3
Training loss: 1.3964513540267944
Validation loss: 1.9499211631795412

Epoch: 5| Step: 4
Training loss: 1.617725133895874
Validation loss: 1.9661126623871505

Epoch: 5| Step: 5
Training loss: 1.613541603088379
Validation loss: 1.9774554416697512

Epoch: 5| Step: 6
Training loss: 1.5604912042617798
Validation loss: 1.9153457892838346

Epoch: 5| Step: 7
Training loss: 1.6768605709075928
Validation loss: 1.8993189745051886

Epoch: 5| Step: 8
Training loss: 1.2694306373596191
Validation loss: 1.9251300519512546

Epoch: 5| Step: 9
Training loss: 1.535269856452942
Validation loss: 1.93733641921833

Epoch: 5| Step: 10
Training loss: 1.1637892723083496
Validation loss: 1.944102136037683

Epoch: 209| Step: 0
Training loss: 0.8713980913162231
Validation loss: 1.9613894980440858

Epoch: 5| Step: 1
Training loss: 1.6177104711532593
Validation loss: 1.9869804959143362

Epoch: 5| Step: 2
Training loss: 1.2886871099472046
Validation loss: 1.9938153861671366

Epoch: 5| Step: 3
Training loss: 1.2778911590576172
Validation loss: 1.9793865103875437

Epoch: 5| Step: 4
Training loss: 1.4604151248931885
Validation loss: 1.9780368779295234

Epoch: 5| Step: 5
Training loss: 1.9637577533721924
Validation loss: 2.0343530742071008

Epoch: 5| Step: 6
Training loss: 1.5305837392807007
Validation loss: 2.027051071966848

Epoch: 5| Step: 7
Training loss: 1.7894773483276367
Validation loss: 1.996768428433326

Epoch: 5| Step: 8
Training loss: 1.3130104541778564
Validation loss: 1.9815436819548249

Epoch: 5| Step: 9
Training loss: 1.6876951456069946
Validation loss: 1.975893053957211

Epoch: 5| Step: 10
Training loss: 1.3842740058898926
Validation loss: 1.9897561893668225

Epoch: 210| Step: 0
Training loss: 1.1932791471481323
Validation loss: 2.0062548473317134

Epoch: 5| Step: 1
Training loss: 1.87088143825531
Validation loss: 2.0248011850541636

Epoch: 5| Step: 2
Training loss: 1.5325108766555786
Validation loss: 2.0159422812923307

Epoch: 5| Step: 3
Training loss: 1.5970702171325684
Validation loss: 1.9861811937824372

Epoch: 5| Step: 4
Training loss: 1.4126038551330566
Validation loss: 1.9835590201039468

Epoch: 5| Step: 5
Training loss: 1.584646463394165
Validation loss: 1.9592622428812005

Epoch: 5| Step: 6
Training loss: 1.1652895212173462
Validation loss: 1.9619394028058617

Epoch: 5| Step: 7
Training loss: 1.676666259765625
Validation loss: 1.9443279850867488

Epoch: 5| Step: 8
Training loss: 1.0104268789291382
Validation loss: 1.9368837213003507

Epoch: 5| Step: 9
Training loss: 1.3716853857040405
Validation loss: 1.95618688291119

Epoch: 5| Step: 10
Training loss: 1.256307601928711
Validation loss: 1.9572489582082278

Epoch: 211| Step: 0
Training loss: 1.455115556716919
Validation loss: 1.9511825217995593

Epoch: 5| Step: 1
Training loss: 1.2798349857330322
Validation loss: 1.9625042459016204

Epoch: 5| Step: 2
Training loss: 1.3977067470550537
Validation loss: 1.9446008666869132

Epoch: 5| Step: 3
Training loss: 1.4118788242340088
Validation loss: 2.0011963280298377

Epoch: 5| Step: 4
Training loss: 1.1449830532073975
Validation loss: 1.994972009812632

Epoch: 5| Step: 5
Training loss: 0.9754925966262817
Validation loss: 1.9749525580354916

Epoch: 5| Step: 6
Training loss: 1.3080564737319946
Validation loss: 1.9599475514504217

Epoch: 5| Step: 7
Training loss: 1.8295888900756836
Validation loss: 1.9975883499268563

Epoch: 5| Step: 8
Training loss: 1.7993838787078857
Validation loss: 1.998354750294839

Epoch: 5| Step: 9
Training loss: 1.6304700374603271
Validation loss: 1.977002110532535

Epoch: 5| Step: 10
Training loss: 1.5272090435028076
Validation loss: 1.9868493259594004

Epoch: 212| Step: 0
Training loss: 1.1075007915496826
Validation loss: 1.9899797029392694

Epoch: 5| Step: 1
Training loss: 1.4236098527908325
Validation loss: 1.9648654178906513

Epoch: 5| Step: 2
Training loss: 1.725324034690857
Validation loss: 1.9516669909159343

Epoch: 5| Step: 3
Training loss: 1.432641625404358
Validation loss: 1.9250439777169177

Epoch: 5| Step: 4
Training loss: 1.1290338039398193
Validation loss: 1.9280021729007844

Epoch: 5| Step: 5
Training loss: 1.3222888708114624
Validation loss: 1.9251062780298211

Epoch: 5| Step: 6
Training loss: 1.1514841318130493
Validation loss: 1.9501803075113604

Epoch: 5| Step: 7
Training loss: 1.2167136669158936
Validation loss: 1.9927147434603782

Epoch: 5| Step: 8
Training loss: 1.4419963359832764
Validation loss: 2.0404675032502864

Epoch: 5| Step: 9
Training loss: 1.2989680767059326
Validation loss: 2.0436594691327823

Epoch: 5| Step: 10
Training loss: 2.288828134536743
Validation loss: 2.0043572815515662

Epoch: 213| Step: 0
Training loss: 1.0598084926605225
Validation loss: 1.9949164223927323

Epoch: 5| Step: 1
Training loss: 1.5692412853240967
Validation loss: 1.9706402517134143

Epoch: 5| Step: 2
Training loss: 1.3285636901855469
Validation loss: 1.9790602025165354

Epoch: 5| Step: 3
Training loss: 1.3405697345733643
Validation loss: 1.985505134828629

Epoch: 5| Step: 4
Training loss: 1.6139485836029053
Validation loss: 1.99706635936614

Epoch: 5| Step: 5
Training loss: 1.485939383506775
Validation loss: 1.9980545056763517

Epoch: 5| Step: 6
Training loss: 1.640184998512268
Validation loss: 1.9859958310281076

Epoch: 5| Step: 7
Training loss: 0.9946194887161255
Validation loss: 1.9898847790174587

Epoch: 5| Step: 8
Training loss: 1.5598795413970947
Validation loss: 1.9797850936971686

Epoch: 5| Step: 9
Training loss: 1.4450435638427734
Validation loss: 2.003208283455141

Epoch: 5| Step: 10
Training loss: 1.2012081146240234
Validation loss: 1.9850436525960122

Epoch: 214| Step: 0
Training loss: 1.391143560409546
Validation loss: 1.9775120648004676

Epoch: 5| Step: 1
Training loss: 1.4363352060317993
Validation loss: 1.9754002683906144

Epoch: 5| Step: 2
Training loss: 1.1752809286117554
Validation loss: 1.9822759859023555

Epoch: 5| Step: 3
Training loss: 0.9597806930541992
Validation loss: 1.9770306130891204

Epoch: 5| Step: 4
Training loss: 1.4359848499298096
Validation loss: 1.9995133030799128

Epoch: 5| Step: 5
Training loss: 1.7773748636245728
Validation loss: 2.0036017984472294

Epoch: 5| Step: 6
Training loss: 1.0850003957748413
Validation loss: 2.0388957967040358

Epoch: 5| Step: 7
Training loss: 1.1360383033752441
Validation loss: 1.9734381962847967

Epoch: 5| Step: 8
Training loss: 2.007523536682129
Validation loss: 1.9489892682721537

Epoch: 5| Step: 9
Training loss: 1.5633642673492432
Validation loss: 1.9311570736669725

Epoch: 5| Step: 10
Training loss: 1.3572717905044556
Validation loss: 1.9200568596522014

Epoch: 215| Step: 0
Training loss: 1.6619144678115845
Validation loss: 1.9262152833323325

Epoch: 5| Step: 1
Training loss: 1.30129873752594
Validation loss: 1.9423848659761491

Epoch: 5| Step: 2
Training loss: 1.6247844696044922
Validation loss: 1.9517265212151311

Epoch: 5| Step: 3
Training loss: 1.437761664390564
Validation loss: 1.9467062386133338

Epoch: 5| Step: 4
Training loss: 1.6079065799713135
Validation loss: 1.9500359412162536

Epoch: 5| Step: 5
Training loss: 1.0946919918060303
Validation loss: 1.97261901568341

Epoch: 5| Step: 6
Training loss: 1.2419099807739258
Validation loss: 1.9686871267134143

Epoch: 5| Step: 7
Training loss: 1.5377967357635498
Validation loss: 2.002369708912347

Epoch: 5| Step: 8
Training loss: 1.4863741397857666
Validation loss: 2.0300286790376068

Epoch: 5| Step: 9
Training loss: 0.8853748440742493
Validation loss: 2.0384614275347803

Epoch: 5| Step: 10
Training loss: 1.4333903789520264
Validation loss: 2.016136819316495

Epoch: 216| Step: 0
Training loss: 1.5756853818893433
Validation loss: 2.016676641279651

Epoch: 5| Step: 1
Training loss: 1.7143936157226562
Validation loss: 1.9813817419031614

Epoch: 5| Step: 2
Training loss: 1.1648831367492676
Validation loss: 1.9417643957240607

Epoch: 5| Step: 3
Training loss: 1.20337975025177
Validation loss: 1.9233548025931082

Epoch: 5| Step: 4
Training loss: 1.2948508262634277
Validation loss: 1.9053666104552567

Epoch: 5| Step: 5
Training loss: 1.7886947393417358
Validation loss: 1.8945391883132279

Epoch: 5| Step: 6
Training loss: 1.2838404178619385
Validation loss: 1.888941616140386

Epoch: 5| Step: 7
Training loss: 1.2218905687332153
Validation loss: 1.9233672721411592

Epoch: 5| Step: 8
Training loss: 1.3484290838241577
Validation loss: 1.953003027105844

Epoch: 5| Step: 9
Training loss: 1.6097126007080078
Validation loss: 2.0114513750999206

Epoch: 5| Step: 10
Training loss: 1.1989024877548218
Validation loss: 2.0503755846331195

Epoch: 217| Step: 0
Training loss: 1.608985185623169
Validation loss: 2.0450141801629016

Epoch: 5| Step: 1
Training loss: 1.7088842391967773
Validation loss: 2.0646915717791487

Epoch: 5| Step: 2
Training loss: 1.2357730865478516
Validation loss: 1.9757541071984075

Epoch: 5| Step: 3
Training loss: 1.1250126361846924
Validation loss: 1.9936775571556502

Epoch: 5| Step: 4
Training loss: 0.9919821619987488
Validation loss: 1.96514880529014

Epoch: 5| Step: 5
Training loss: 1.2039388418197632
Validation loss: 1.9931886067954443

Epoch: 5| Step: 6
Training loss: 1.8773990869522095
Validation loss: 2.0106432181532665

Epoch: 5| Step: 7
Training loss: 1.0317895412445068
Validation loss: 2.0452552662100842

Epoch: 5| Step: 8
Training loss: 1.320664405822754
Validation loss: 2.105088851785147

Epoch: 5| Step: 9
Training loss: 1.429405689239502
Validation loss: 2.131937708905948

Epoch: 5| Step: 10
Training loss: 1.7079578638076782
Validation loss: 2.0611272755489556

Epoch: 218| Step: 0
Training loss: 1.278024435043335
Validation loss: 2.0481164147776942

Epoch: 5| Step: 1
Training loss: 1.1847244501113892
Validation loss: 1.9999840118551766

Epoch: 5| Step: 2
Training loss: 0.9077448844909668
Validation loss: 1.9629664356990526

Epoch: 5| Step: 3
Training loss: 1.3062150478363037
Validation loss: 1.9130795130165674

Epoch: 5| Step: 4
Training loss: 1.4102003574371338
Validation loss: 1.909323694885418

Epoch: 5| Step: 5
Training loss: 1.6271854639053345
Validation loss: 1.9141732518390944

Epoch: 5| Step: 6
Training loss: 1.5813544988632202
Validation loss: 1.9454874454006073

Epoch: 5| Step: 7
Training loss: 1.4034183025360107
Validation loss: 2.036313146673223

Epoch: 5| Step: 8
Training loss: 1.2151861190795898
Validation loss: 2.056927118250119

Epoch: 5| Step: 9
Training loss: 1.626538872718811
Validation loss: 2.02390613607181

Epoch: 5| Step: 10
Training loss: 1.9411147832870483
Validation loss: 1.9922899828162244

Epoch: 219| Step: 0
Training loss: 0.9258203506469727
Validation loss: 1.9338200348679737

Epoch: 5| Step: 1
Training loss: 1.2033171653747559
Validation loss: 1.8910134069381221

Epoch: 5| Step: 2
Training loss: 1.5470681190490723
Validation loss: 1.9006393647963

Epoch: 5| Step: 3
Training loss: 1.066486120223999
Validation loss: 1.905160222002255

Epoch: 5| Step: 4
Training loss: 1.5804111957550049
Validation loss: 1.9063095943902129

Epoch: 5| Step: 5
Training loss: 1.236668586730957
Validation loss: 1.944860449401281

Epoch: 5| Step: 6
Training loss: 1.3150817155838013
Validation loss: 1.9594932038296935

Epoch: 5| Step: 7
Training loss: 1.6609493494033813
Validation loss: 1.9424816126464515

Epoch: 5| Step: 8
Training loss: 1.380366563796997
Validation loss: 1.909537169241136

Epoch: 5| Step: 9
Training loss: 0.7800477743148804
Validation loss: 1.9065842474660566

Epoch: 5| Step: 10
Training loss: 2.1422157287597656
Validation loss: 1.9086155327417518

Epoch: 220| Step: 0
Training loss: 1.3768795728683472
Validation loss: 1.947553196261006

Epoch: 5| Step: 1
Training loss: 1.67105233669281
Validation loss: 1.9796569244835966

Epoch: 5| Step: 2
Training loss: 1.1495661735534668
Validation loss: 1.9939274787902832

Epoch: 5| Step: 3
Training loss: 1.0947966575622559
Validation loss: 2.044914157159867

Epoch: 5| Step: 4
Training loss: 1.085155725479126
Validation loss: 2.040735531878728

Epoch: 5| Step: 5
Training loss: 1.5657544136047363
Validation loss: 2.0059331117137784

Epoch: 5| Step: 6
Training loss: 1.2970867156982422
Validation loss: 1.9679376156099382

Epoch: 5| Step: 7
Training loss: 1.5129016637802124
Validation loss: 1.9509170491208312

Epoch: 5| Step: 8
Training loss: 1.1647758483886719
Validation loss: 1.917449479461998

Epoch: 5| Step: 9
Training loss: 1.4498406648635864
Validation loss: 1.923752256619033

Epoch: 5| Step: 10
Training loss: 1.2643613815307617
Validation loss: 1.9132556556373514

Epoch: 221| Step: 0
Training loss: 0.7298115491867065
Validation loss: 1.8997958526816419

Epoch: 5| Step: 1
Training loss: 1.4235291481018066
Validation loss: 1.9475626971132012

Epoch: 5| Step: 2
Training loss: 1.269697904586792
Validation loss: 1.9736615457842428

Epoch: 5| Step: 3
Training loss: 1.637557029724121
Validation loss: 2.014171500359812

Epoch: 5| Step: 4
Training loss: 1.4743359088897705
Validation loss: 1.9660207507430867

Epoch: 5| Step: 5
Training loss: 1.631272554397583
Validation loss: 1.899745955262133

Epoch: 5| Step: 6
Training loss: 1.4076340198516846
Validation loss: 1.9003866975025465

Epoch: 5| Step: 7
Training loss: 1.52247154712677
Validation loss: 1.9011263975533106

Epoch: 5| Step: 8
Training loss: 1.1981607675552368
Validation loss: 1.9093576464601743

Epoch: 5| Step: 9
Training loss: 1.2313421964645386
Validation loss: 1.9752682537160895

Epoch: 5| Step: 10
Training loss: 0.9649853706359863
Validation loss: 1.985325401829135

Epoch: 222| Step: 0
Training loss: 1.265831708908081
Validation loss: 1.9984033415394444

Epoch: 5| Step: 1
Training loss: 1.4010802507400513
Validation loss: 2.0202045773947113

Epoch: 5| Step: 2
Training loss: 1.0831331014633179
Validation loss: 2.0183641833643757

Epoch: 5| Step: 3
Training loss: 1.7166105508804321
Validation loss: 2.0074715793773694

Epoch: 5| Step: 4
Training loss: 1.294568657875061
Validation loss: 1.9774561735891527

Epoch: 5| Step: 5
Training loss: 1.8589801788330078
Validation loss: 1.9759733612819383

Epoch: 5| Step: 6
Training loss: 1.011312484741211
Validation loss: 1.9521939228939753

Epoch: 5| Step: 7
Training loss: 0.899610698223114
Validation loss: 1.9453837769005888

Epoch: 5| Step: 8
Training loss: 1.353760838508606
Validation loss: 1.9199495007914882

Epoch: 5| Step: 9
Training loss: 1.0013624429702759
Validation loss: 1.9149864040395266

Epoch: 5| Step: 10
Training loss: 1.2675244808197021
Validation loss: 1.9010917550774031

Epoch: 223| Step: 0
Training loss: 1.2730796337127686
Validation loss: 1.9280167010522657

Epoch: 5| Step: 1
Training loss: 1.0740692615509033
Validation loss: 1.9231378275861022

Epoch: 5| Step: 2
Training loss: 1.3956835269927979
Validation loss: 1.9102510047215286

Epoch: 5| Step: 3
Training loss: 1.0303407907485962
Validation loss: 1.945063305157487

Epoch: 5| Step: 4
Training loss: 1.633386254310608
Validation loss: 1.9597605043841946

Epoch: 5| Step: 5
Training loss: 1.656907081604004
Validation loss: 1.9791164141829296

Epoch: 5| Step: 6
Training loss: 1.3013604879379272
Validation loss: 2.0021693193784325

Epoch: 5| Step: 7
Training loss: 1.317107915878296
Validation loss: 1.9766856483233872

Epoch: 5| Step: 8
Training loss: 0.8430002331733704
Validation loss: 1.943014588407291

Epoch: 5| Step: 9
Training loss: 1.3328343629837036
Validation loss: 1.930440846309867

Epoch: 5| Step: 10
Training loss: 1.349513053894043
Validation loss: 1.942618808438701

Epoch: 224| Step: 0
Training loss: 0.8649490475654602
Validation loss: 1.9301115594884402

Epoch: 5| Step: 1
Training loss: 1.2368324995040894
Validation loss: 1.9578010625736688

Epoch: 5| Step: 2
Training loss: 1.5831626653671265
Validation loss: 1.9559677326551048

Epoch: 5| Step: 3
Training loss: 1.053264856338501
Validation loss: 1.983763660154035

Epoch: 5| Step: 4
Training loss: 1.057671070098877
Validation loss: 2.042849612492387

Epoch: 5| Step: 5
Training loss: 1.5622625350952148
Validation loss: 2.070188796648415

Epoch: 5| Step: 6
Training loss: 1.2591034173965454
Validation loss: 2.08050097445006

Epoch: 5| Step: 7
Training loss: 1.8529064655303955
Validation loss: 2.040010086951717

Epoch: 5| Step: 8
Training loss: 0.8244856595993042
Validation loss: 2.018491598867601

Epoch: 5| Step: 9
Training loss: 1.2541818618774414
Validation loss: 2.000865609415116

Epoch: 5| Step: 10
Training loss: 1.5150028467178345
Validation loss: 1.9787961257401334

Epoch: 225| Step: 0
Training loss: 1.2062065601348877
Validation loss: 1.9834617440418532

Epoch: 5| Step: 1
Training loss: 0.982068657875061
Validation loss: 1.9566491649996849

Epoch: 5| Step: 2
Training loss: 1.1634938716888428
Validation loss: 1.9911574817472888

Epoch: 5| Step: 3
Training loss: 1.5438997745513916
Validation loss: 1.984212371610826

Epoch: 5| Step: 4
Training loss: 1.1332099437713623
Validation loss: 1.9737502400593092

Epoch: 5| Step: 5
Training loss: 1.0482810735702515
Validation loss: 1.949334329174411

Epoch: 5| Step: 6
Training loss: 1.1403343677520752
Validation loss: 1.9422959255915817

Epoch: 5| Step: 7
Training loss: 1.2149169445037842
Validation loss: 1.9437791839722665

Epoch: 5| Step: 8
Training loss: 1.3201267719268799
Validation loss: 1.9361837525521555

Epoch: 5| Step: 9
Training loss: 1.6622791290283203
Validation loss: 1.9142442505846742

Epoch: 5| Step: 10
Training loss: 1.198639988899231
Validation loss: 1.9201423224582468

Epoch: 226| Step: 0
Training loss: 0.9701018333435059
Validation loss: 1.8915126041699482

Epoch: 5| Step: 1
Training loss: 1.5982325077056885
Validation loss: 1.8751841975796608

Epoch: 5| Step: 2
Training loss: 1.2708940505981445
Validation loss: 1.8850365300332346

Epoch: 5| Step: 3
Training loss: 1.0046144723892212
Validation loss: 1.9073321729577997

Epoch: 5| Step: 4
Training loss: 1.303147315979004
Validation loss: 1.9632936831443542

Epoch: 5| Step: 5
Training loss: 1.067700743675232
Validation loss: 2.040250587207015

Epoch: 5| Step: 6
Training loss: 1.4342331886291504
Validation loss: 2.0868037490434546

Epoch: 5| Step: 7
Training loss: 1.6331748962402344
Validation loss: 2.0755521328218522

Epoch: 5| Step: 8
Training loss: 1.098220705986023
Validation loss: 2.1079229334349274

Epoch: 5| Step: 9
Training loss: 1.2815710306167603
Validation loss: 2.0829149420543382

Epoch: 5| Step: 10
Training loss: 1.2279855012893677
Validation loss: 2.0404400299954157

Epoch: 227| Step: 0
Training loss: 1.7104771137237549
Validation loss: 1.9897583197521906

Epoch: 5| Step: 1
Training loss: 1.4425512552261353
Validation loss: 1.9245851450068976

Epoch: 5| Step: 2
Training loss: 1.8845806121826172
Validation loss: 1.9178838319675897

Epoch: 5| Step: 3
Training loss: 1.4058983325958252
Validation loss: 1.8809383248770108

Epoch: 5| Step: 4
Training loss: 1.1207060813903809
Validation loss: 1.8905738348601966

Epoch: 5| Step: 5
Training loss: 1.251894235610962
Validation loss: 1.939344520209938

Epoch: 5| Step: 6
Training loss: 1.1878026723861694
Validation loss: 1.98614421198445

Epoch: 5| Step: 7
Training loss: 1.0955249071121216
Validation loss: 1.96379941509616

Epoch: 5| Step: 8
Training loss: 1.078946828842163
Validation loss: 1.9349253639098136

Epoch: 5| Step: 9
Training loss: 0.9655140042304993
Validation loss: 1.8988938331604004

Epoch: 5| Step: 10
Training loss: 0.9884883761405945
Validation loss: 1.9057750330176404

Epoch: 228| Step: 0
Training loss: 1.220657229423523
Validation loss: 1.9048685258434666

Epoch: 5| Step: 1
Training loss: 1.3291215896606445
Validation loss: 1.919025034032842

Epoch: 5| Step: 2
Training loss: 1.276005744934082
Validation loss: 1.9303066345953173

Epoch: 5| Step: 3
Training loss: 1.3438295125961304
Validation loss: 1.9415904732160671

Epoch: 5| Step: 4
Training loss: 1.256735920906067
Validation loss: 1.94045227830128

Epoch: 5| Step: 5
Training loss: 0.9798732995986938
Validation loss: 1.961907394470707

Epoch: 5| Step: 6
Training loss: 1.3615319728851318
Validation loss: 2.000930304168373

Epoch: 5| Step: 7
Training loss: 1.0080134868621826
Validation loss: 2.028305252393087

Epoch: 5| Step: 8
Training loss: 1.3797008991241455
Validation loss: 2.0208476666481263

Epoch: 5| Step: 9
Training loss: 1.191498041152954
Validation loss: 1.9808654195518904

Epoch: 5| Step: 10
Training loss: 1.054321527481079
Validation loss: 1.9419608859605686

Epoch: 229| Step: 0
Training loss: 0.985966682434082
Validation loss: 1.9128654387689406

Epoch: 5| Step: 1
Training loss: 1.4208106994628906
Validation loss: 1.8696512483781385

Epoch: 5| Step: 2
Training loss: 1.1886454820632935
Validation loss: 1.857292999503433

Epoch: 5| Step: 3
Training loss: 1.3050025701522827
Validation loss: 1.8753661673556092

Epoch: 5| Step: 4
Training loss: 1.3286606073379517
Validation loss: 1.8707226117451985

Epoch: 5| Step: 5
Training loss: 0.8150116205215454
Validation loss: 1.8988336017054896

Epoch: 5| Step: 6
Training loss: 0.748022198677063
Validation loss: 1.9341706357976443

Epoch: 5| Step: 7
Training loss: 1.4349744319915771
Validation loss: 1.967008348434202

Epoch: 5| Step: 8
Training loss: 1.613539695739746
Validation loss: 1.998519447542006

Epoch: 5| Step: 9
Training loss: 1.4619905948638916
Validation loss: 1.9496054034079275

Epoch: 5| Step: 10
Training loss: 1.0445764064788818
Validation loss: 1.9131860066485662

Epoch: 230| Step: 0
Training loss: 0.8371736407279968
Validation loss: 1.9160056550015685

Epoch: 5| Step: 1
Training loss: 1.855851173400879
Validation loss: 1.9268417742944532

Epoch: 5| Step: 2
Training loss: 1.2884681224822998
Validation loss: 1.9403811552191292

Epoch: 5| Step: 3
Training loss: 1.4731318950653076
Validation loss: 1.9632692952309885

Epoch: 5| Step: 4
Training loss: 1.0059797763824463
Validation loss: 2.058436083537276

Epoch: 5| Step: 5
Training loss: 1.6456435918807983
Validation loss: 2.0727832368625108

Epoch: 5| Step: 6
Training loss: 0.7702447175979614
Validation loss: 2.0581756996852096

Epoch: 5| Step: 7
Training loss: 0.8204050064086914
Validation loss: 1.9419731247809626

Epoch: 5| Step: 8
Training loss: 1.3953359127044678
Validation loss: 1.9019151990131666

Epoch: 5| Step: 9
Training loss: 1.20109224319458
Validation loss: 1.8570146868305821

Epoch: 5| Step: 10
Training loss: 1.4387933015823364
Validation loss: 1.836468001847626

Epoch: 231| Step: 0
Training loss: 1.2982909679412842
Validation loss: 1.8407970064429826

Epoch: 5| Step: 1
Training loss: 1.1611039638519287
Validation loss: 1.8435156524822276

Epoch: 5| Step: 2
Training loss: 1.3535720109939575
Validation loss: 1.8601062272184639

Epoch: 5| Step: 3
Training loss: 0.7584091424942017
Validation loss: 1.8523352479421964

Epoch: 5| Step: 4
Training loss: 1.375046730041504
Validation loss: 1.8426481049547914

Epoch: 5| Step: 5
Training loss: 1.2838134765625
Validation loss: 1.8377379743001794

Epoch: 5| Step: 6
Training loss: 1.2601432800292969
Validation loss: 1.8573124575358566

Epoch: 5| Step: 7
Training loss: 1.2664992809295654
Validation loss: 1.8862496845183834

Epoch: 5| Step: 8
Training loss: 1.2340854406356812
Validation loss: 1.935720415525539

Epoch: 5| Step: 9
Training loss: 1.3436778783798218
Validation loss: 1.981690506781301

Epoch: 5| Step: 10
Training loss: 1.1245181560516357
Validation loss: 1.9991756972446237

Epoch: 232| Step: 0
Training loss: 1.4255294799804688
Validation loss: 1.9966925985069686

Epoch: 5| Step: 1
Training loss: 1.3001651763916016
Validation loss: 2.0118034232047295

Epoch: 5| Step: 2
Training loss: 1.4266247749328613
Validation loss: 1.9470622539520264

Epoch: 5| Step: 3
Training loss: 0.9331618547439575
Validation loss: 1.9617286471910373

Epoch: 5| Step: 4
Training loss: 1.792636513710022
Validation loss: 1.9468361190570298

Epoch: 5| Step: 5
Training loss: 1.2268732786178589
Validation loss: 1.9715354211868779

Epoch: 5| Step: 6
Training loss: 1.0183354616165161
Validation loss: 1.9736286555567095

Epoch: 5| Step: 7
Training loss: 1.193996787071228
Validation loss: 1.9404479278031217

Epoch: 5| Step: 8
Training loss: 1.5442777872085571
Validation loss: 1.961010984195176

Epoch: 5| Step: 9
Training loss: 0.39480477571487427
Validation loss: 1.927115963351342

Epoch: 5| Step: 10
Training loss: 0.7889075875282288
Validation loss: 1.9363780008849276

Epoch: 233| Step: 0
Training loss: 1.2241907119750977
Validation loss: 1.9003130235979635

Epoch: 5| Step: 1
Training loss: 1.1324539184570312
Validation loss: 1.8858219961966238

Epoch: 5| Step: 2
Training loss: 0.657252848148346
Validation loss: 1.8954529864813692

Epoch: 5| Step: 3
Training loss: 0.8865799903869629
Validation loss: 1.9115494015396282

Epoch: 5| Step: 4
Training loss: 1.6860586404800415
Validation loss: 1.9294438016030095

Epoch: 5| Step: 5
Training loss: 1.054231882095337
Validation loss: 1.9341485461881083

Epoch: 5| Step: 6
Training loss: 0.9021528363227844
Validation loss: 1.9164900548996464

Epoch: 5| Step: 7
Training loss: 1.558609962463379
Validation loss: 1.8984319138270553

Epoch: 5| Step: 8
Training loss: 1.5456182956695557
Validation loss: 1.899045063603309

Epoch: 5| Step: 9
Training loss: 1.1676956415176392
Validation loss: 1.8940600374693513

Epoch: 5| Step: 10
Training loss: 1.124946117401123
Validation loss: 1.92464029917153

Epoch: 234| Step: 0
Training loss: 1.3134009838104248
Validation loss: 1.9170429706573486

Epoch: 5| Step: 1
Training loss: 1.219611406326294
Validation loss: 1.8952284051525978

Epoch: 5| Step: 2
Training loss: 1.100367784500122
Validation loss: 1.9194400489971202

Epoch: 5| Step: 3
Training loss: 1.3431682586669922
Validation loss: 1.932512898598948

Epoch: 5| Step: 4
Training loss: 0.8655855059623718
Validation loss: 1.8955441290332424

Epoch: 5| Step: 5
Training loss: 1.2332810163497925
Validation loss: 1.9019082336015598

Epoch: 5| Step: 6
Training loss: 1.1333166360855103
Validation loss: 1.8521119035700315

Epoch: 5| Step: 7
Training loss: 1.2981184720993042
Validation loss: 1.856970514020612

Epoch: 5| Step: 8
Training loss: 0.6701679229736328
Validation loss: 1.858358640824595

Epoch: 5| Step: 9
Training loss: 1.3041460514068604
Validation loss: 1.9161360827825402

Epoch: 5| Step: 10
Training loss: 1.242965817451477
Validation loss: 1.9320662329273839

Epoch: 235| Step: 0
Training loss: 1.2075116634368896
Validation loss: 1.9372265877262238

Epoch: 5| Step: 1
Training loss: 1.7195485830307007
Validation loss: 1.9505802034049906

Epoch: 5| Step: 2
Training loss: 1.0238463878631592
Validation loss: 1.9683424311299478

Epoch: 5| Step: 3
Training loss: 1.1675859689712524
Validation loss: 1.9683145297470914

Epoch: 5| Step: 4
Training loss: 1.299163818359375
Validation loss: 1.9704448958878875

Epoch: 5| Step: 5
Training loss: 1.2768388986587524
Validation loss: 1.9671379391865065

Epoch: 5| Step: 6
Training loss: 1.5005030632019043
Validation loss: 1.960879784758373

Epoch: 5| Step: 7
Training loss: 0.8937188982963562
Validation loss: 1.969822992560684

Epoch: 5| Step: 8
Training loss: 0.971943736076355
Validation loss: 2.003715331836413

Epoch: 5| Step: 9
Training loss: 1.0718095302581787
Validation loss: 2.05596508261978

Epoch: 5| Step: 10
Training loss: 0.8811234831809998
Validation loss: 2.000980479742891

Epoch: 236| Step: 0
Training loss: 1.8889777660369873
Validation loss: 1.9603295146778066

Epoch: 5| Step: 1
Training loss: 0.5065699815750122
Validation loss: 1.92809328468897

Epoch: 5| Step: 2
Training loss: 0.8502227067947388
Validation loss: 1.8706241935812018

Epoch: 5| Step: 3
Training loss: 1.0959943532943726
Validation loss: 1.8439778358705583

Epoch: 5| Step: 4
Training loss: 1.0423610210418701
Validation loss: 1.8875982607564619

Epoch: 5| Step: 5
Training loss: 1.2189624309539795
Validation loss: 1.9195607887801303

Epoch: 5| Step: 6
Training loss: 1.009874701499939
Validation loss: 1.926593933054196

Epoch: 5| Step: 7
Training loss: 1.2967779636383057
Validation loss: 1.997641340378792

Epoch: 5| Step: 8
Training loss: 1.7481632232666016
Validation loss: 2.0437294206311627

Epoch: 5| Step: 9
Training loss: 1.2181302309036255
Validation loss: 2.0426937431417485

Epoch: 5| Step: 10
Training loss: 1.2145581245422363
Validation loss: 2.038660713421401

Epoch: 237| Step: 0
Training loss: 1.3334200382232666
Validation loss: 1.9555242292342647

Epoch: 5| Step: 1
Training loss: 1.1363914012908936
Validation loss: 1.8934503293806506

Epoch: 5| Step: 2
Training loss: 1.1134827136993408
Validation loss: 1.8780576990496727

Epoch: 5| Step: 3
Training loss: 1.3801664113998413
Validation loss: 1.861810508594718

Epoch: 5| Step: 4
Training loss: 1.789406180381775
Validation loss: 1.867485427087353

Epoch: 5| Step: 5
Training loss: 0.6554279327392578
Validation loss: 1.8586898824220062

Epoch: 5| Step: 6
Training loss: 1.2703832387924194
Validation loss: 1.8847058255185363

Epoch: 5| Step: 7
Training loss: 0.8774725794792175
Validation loss: 1.887415765434183

Epoch: 5| Step: 8
Training loss: 1.1516506671905518
Validation loss: 1.912951268175597

Epoch: 5| Step: 9
Training loss: 0.8002209663391113
Validation loss: 1.9662756766042402

Epoch: 5| Step: 10
Training loss: 0.9865314364433289
Validation loss: 1.955037009331488

Epoch: 238| Step: 0
Training loss: 1.3884838819503784
Validation loss: 1.9783583853834419

Epoch: 5| Step: 1
Training loss: 0.9266928434371948
Validation loss: 1.960975173980959

Epoch: 5| Step: 2
Training loss: 1.5255470275878906
Validation loss: 1.9615911411982712

Epoch: 5| Step: 3
Training loss: 0.9676153063774109
Validation loss: 1.932202576309122

Epoch: 5| Step: 4
Training loss: 0.7405332326889038
Validation loss: 1.8866853380715976

Epoch: 5| Step: 5
Training loss: 1.1323812007904053
Validation loss: 1.8599927245929677

Epoch: 5| Step: 6
Training loss: 0.9723879098892212
Validation loss: 1.8572028875350952

Epoch: 5| Step: 7
Training loss: 0.9799049496650696
Validation loss: 1.867783163183479

Epoch: 5| Step: 8
Training loss: 1.4763104915618896
Validation loss: 1.8810727827010616

Epoch: 5| Step: 9
Training loss: 1.165399193763733
Validation loss: 1.9178933674289333

Epoch: 5| Step: 10
Training loss: 1.2040456533432007
Validation loss: 1.9643558109960249

Epoch: 239| Step: 0
Training loss: 1.0352891683578491
Validation loss: 1.9722577615450787

Epoch: 5| Step: 1
Training loss: 1.2452962398529053
Validation loss: 1.9843569391517228

Epoch: 5| Step: 2
Training loss: 1.0794198513031006
Validation loss: 1.977692808515282

Epoch: 5| Step: 3
Training loss: 0.9172788858413696
Validation loss: 2.0042303480127805

Epoch: 5| Step: 4
Training loss: 0.986962616443634
Validation loss: 1.9839922228167135

Epoch: 5| Step: 5
Training loss: 0.8733251690864563
Validation loss: 1.9712914164348314

Epoch: 5| Step: 6
Training loss: 1.4951837062835693
Validation loss: 1.9737697993555376

Epoch: 5| Step: 7
Training loss: 1.4159791469573975
Validation loss: 2.009482602919302

Epoch: 5| Step: 8
Training loss: 1.075188398361206
Validation loss: 2.0043233966314666

Epoch: 5| Step: 9
Training loss: 1.076265811920166
Validation loss: 2.030901212846079

Epoch: 5| Step: 10
Training loss: 1.1764222383499146
Validation loss: 1.9859820168505433

Epoch: 240| Step: 0
Training loss: 1.1539636850357056
Validation loss: 1.9869410043121667

Epoch: 5| Step: 1
Training loss: 1.3942382335662842
Validation loss: 1.940467237144388

Epoch: 5| Step: 2
Training loss: 1.0688921213150024
Validation loss: 1.9279399123243106

Epoch: 5| Step: 3
Training loss: 1.4826267957687378
Validation loss: 1.8773846331463064

Epoch: 5| Step: 4
Training loss: 1.1892033815383911
Validation loss: 1.854659185614637

Epoch: 5| Step: 5
Training loss: 0.8427959680557251
Validation loss: 1.8421872456868489

Epoch: 5| Step: 6
Training loss: 0.9903039932250977
Validation loss: 1.8462426329171786

Epoch: 5| Step: 7
Training loss: 1.0372076034545898
Validation loss: 1.9023686391051098

Epoch: 5| Step: 8
Training loss: 1.017911672592163
Validation loss: 1.9383527078936178

Epoch: 5| Step: 9
Training loss: 1.0205365419387817
Validation loss: 1.9762915513848747

Epoch: 5| Step: 10
Training loss: 1.0887060165405273
Validation loss: 1.9648692787334483

Epoch: 241| Step: 0
Training loss: 0.827182948589325
Validation loss: 2.0136503070913334

Epoch: 5| Step: 1
Training loss: 1.0520063638687134
Validation loss: 1.9840932687123616

Epoch: 5| Step: 2
Training loss: 1.5012890100479126
Validation loss: 1.9660802169512677

Epoch: 5| Step: 3
Training loss: 1.1854760646820068
Validation loss: 1.9470753092919626

Epoch: 5| Step: 4
Training loss: 1.1371132135391235
Validation loss: 1.9160535220176942

Epoch: 5| Step: 5
Training loss: 1.0642811059951782
Validation loss: 1.9012567368886804

Epoch: 5| Step: 6
Training loss: 0.7117161750793457
Validation loss: 1.8967645578486945

Epoch: 5| Step: 7
Training loss: 1.2308841943740845
Validation loss: 1.9010774409899147

Epoch: 5| Step: 8
Training loss: 0.9467779397964478
Validation loss: 1.8952618875811178

Epoch: 5| Step: 9
Training loss: 1.4672906398773193
Validation loss: 1.9074408315843152

Epoch: 5| Step: 10
Training loss: 1.031751036643982
Validation loss: 1.920438180687607

Epoch: 242| Step: 0
Training loss: 1.513146162033081
Validation loss: 1.8850723479383735

Epoch: 5| Step: 1
Training loss: 1.0990793704986572
Validation loss: 1.8616730718202488

Epoch: 5| Step: 2
Training loss: 1.265368103981018
Validation loss: 1.8550744466884161

Epoch: 5| Step: 3
Training loss: 0.7468514442443848
Validation loss: 1.881968448238988

Epoch: 5| Step: 4
Training loss: 0.7050684094429016
Validation loss: 1.8819720283631356

Epoch: 5| Step: 5
Training loss: 0.8090425729751587
Validation loss: 1.8645662338502946

Epoch: 5| Step: 6
Training loss: 1.2365882396697998
Validation loss: 1.9070208252117198

Epoch: 5| Step: 7
Training loss: 0.9664269685745239
Validation loss: 1.9234438814142698

Epoch: 5| Step: 8
Training loss: 1.3237649202346802
Validation loss: 1.9851798703593593

Epoch: 5| Step: 9
Training loss: 0.9443389177322388
Validation loss: 1.9885404468864523

Epoch: 5| Step: 10
Training loss: 1.4868961572647095
Validation loss: 1.9498351543180403

Epoch: 243| Step: 0
Training loss: 1.1636075973510742
Validation loss: 1.92503914653614

Epoch: 5| Step: 1
Training loss: 1.2508013248443604
Validation loss: 1.8849272189601776

Epoch: 5| Step: 2
Training loss: 1.1041977405548096
Validation loss: 1.8666516478343675

Epoch: 5| Step: 3
Training loss: 1.0915100574493408
Validation loss: 1.8664910716395224

Epoch: 5| Step: 4
Training loss: 0.9925857782363892
Validation loss: 1.8844305264052523

Epoch: 5| Step: 5
Training loss: 0.9260866045951843
Validation loss: 1.906205346507411

Epoch: 5| Step: 6
Training loss: 1.1483274698257446
Validation loss: 1.899678821204811

Epoch: 5| Step: 7
Training loss: 1.0360243320465088
Validation loss: 1.9075341532307286

Epoch: 5| Step: 8
Training loss: 0.9537220001220703
Validation loss: 1.9109553842134372

Epoch: 5| Step: 9
Training loss: 0.8713960647583008
Validation loss: 1.8815170590595534

Epoch: 5| Step: 10
Training loss: 1.3363947868347168
Validation loss: 1.8428986290449738

Epoch: 244| Step: 0
Training loss: 0.9236488342285156
Validation loss: 1.8322172754554338

Epoch: 5| Step: 1
Training loss: 0.9001596570014954
Validation loss: 1.869781240340202

Epoch: 5| Step: 2
Training loss: 0.967327892780304
Validation loss: 1.9146674230534544

Epoch: 5| Step: 3
Training loss: 1.1303904056549072
Validation loss: 1.9493145045413767

Epoch: 5| Step: 4
Training loss: 0.5649377107620239
Validation loss: 1.9998059657312208

Epoch: 5| Step: 5
Training loss: 1.5398759841918945
Validation loss: 1.9798916732111285

Epoch: 5| Step: 6
Training loss: 1.1370964050292969
Validation loss: 1.9547375107324252

Epoch: 5| Step: 7
Training loss: 1.0641350746154785
Validation loss: 1.9476591617830339

Epoch: 5| Step: 8
Training loss: 0.9207798838615417
Validation loss: 1.9160317592723395

Epoch: 5| Step: 9
Training loss: 1.2544400691986084
Validation loss: 1.941082723679081

Epoch: 5| Step: 10
Training loss: 1.1959924697875977
Validation loss: 1.9327262024725638

Epoch: 245| Step: 0
Training loss: 0.7173470258712769
Validation loss: 1.9401023464818155

Epoch: 5| Step: 1
Training loss: 0.8913028836250305
Validation loss: 1.9353516768383723

Epoch: 5| Step: 2
Training loss: 1.0214494466781616
Validation loss: 1.9647012115806661

Epoch: 5| Step: 3
Training loss: 0.9783423542976379
Validation loss: 1.9043388661517893

Epoch: 5| Step: 4
Training loss: 1.150145411491394
Validation loss: 1.9575838273571384

Epoch: 5| Step: 5
Training loss: 1.2266956567764282
Validation loss: 1.9538027022474556

Epoch: 5| Step: 6
Training loss: 0.8567317128181458
Validation loss: 1.9397575201526764

Epoch: 5| Step: 7
Training loss: 1.1285418272018433
Validation loss: 1.873813359968124

Epoch: 5| Step: 8
Training loss: 0.7679911255836487
Validation loss: 1.8357393100697508

Epoch: 5| Step: 9
Training loss: 1.1577436923980713
Validation loss: 1.8144036736539615

Epoch: 5| Step: 10
Training loss: 1.4469728469848633
Validation loss: 1.8484614433780793

Epoch: 246| Step: 0
Training loss: 1.08289635181427
Validation loss: 1.8289097303985267

Epoch: 5| Step: 1
Training loss: 0.8602958917617798
Validation loss: 1.8707403893111854

Epoch: 5| Step: 2
Training loss: 0.6610685586929321
Validation loss: 1.8864692488024313

Epoch: 5| Step: 3
Training loss: 1.1902925968170166
Validation loss: 1.8768637923784153

Epoch: 5| Step: 4
Training loss: 1.7474473714828491
Validation loss: 1.875386840553694

Epoch: 5| Step: 5
Training loss: 1.0839747190475464
Validation loss: 1.873912675406343

Epoch: 5| Step: 6
Training loss: 1.4589593410491943
Validation loss: 1.886639000267111

Epoch: 5| Step: 7
Training loss: 1.0312780141830444
Validation loss: 1.9155618734257196

Epoch: 5| Step: 8
Training loss: 0.8654422760009766
Validation loss: 1.9008348398311163

Epoch: 5| Step: 9
Training loss: 0.9196583032608032
Validation loss: 1.8904494854711718

Epoch: 5| Step: 10
Training loss: 0.651928722858429
Validation loss: 1.8596170781761088

Epoch: 247| Step: 0
Training loss: 1.0588935613632202
Validation loss: 1.874286308083483

Epoch: 5| Step: 1
Training loss: 1.211005449295044
Validation loss: 1.8663131101157076

Epoch: 5| Step: 2
Training loss: 1.1242821216583252
Validation loss: 1.8937997741083945

Epoch: 5| Step: 3
Training loss: 0.8097547292709351
Validation loss: 1.8968369935148506

Epoch: 5| Step: 4
Training loss: 1.1977040767669678
Validation loss: 1.8727554762235252

Epoch: 5| Step: 5
Training loss: 0.7046979069709778
Validation loss: 1.8563327045850857

Epoch: 5| Step: 6
Training loss: 0.8745203018188477
Validation loss: 1.8125446086288781

Epoch: 5| Step: 7
Training loss: 0.9992550015449524
Validation loss: 1.8161392032459218

Epoch: 5| Step: 8
Training loss: 1.0444705486297607
Validation loss: 1.803555057894799

Epoch: 5| Step: 9
Training loss: 1.152094841003418
Validation loss: 1.810982434980331

Epoch: 5| Step: 10
Training loss: 1.2030885219573975
Validation loss: 1.8607663454548005

Epoch: 248| Step: 0
Training loss: 0.903298020362854
Validation loss: 1.8965105010617165

Epoch: 5| Step: 1
Training loss: 1.1701056957244873
Validation loss: 1.8986163677707795

Epoch: 5| Step: 2
Training loss: 0.8540782928466797
Validation loss: 1.9401315284031693

Epoch: 5| Step: 3
Training loss: 1.125736951828003
Validation loss: 1.9454288623666252

Epoch: 5| Step: 4
Training loss: 1.001177430152893
Validation loss: 1.964917504659263

Epoch: 5| Step: 5
Training loss: 0.7162561416625977
Validation loss: 2.0097823514733264

Epoch: 5| Step: 6
Training loss: 0.9485395550727844
Validation loss: 2.0143168536565637

Epoch: 5| Step: 7
Training loss: 1.0857365131378174
Validation loss: 1.9969117641448975

Epoch: 5| Step: 8
Training loss: 1.2262951135635376
Validation loss: 1.9873899516238962

Epoch: 5| Step: 9
Training loss: 1.1623880863189697
Validation loss: 1.946220592785907

Epoch: 5| Step: 10
Training loss: 0.9402724504470825
Validation loss: 1.8753179786025838

Epoch: 249| Step: 0
Training loss: 1.3853778839111328
Validation loss: 1.8588897489732312

Epoch: 5| Step: 1
Training loss: 1.025538682937622
Validation loss: 1.8589380466809837

Epoch: 5| Step: 2
Training loss: 0.6077286601066589
Validation loss: 1.858574519875229

Epoch: 5| Step: 3
Training loss: 0.9257286190986633
Validation loss: 1.88375812192117

Epoch: 5| Step: 4
Training loss: 1.4418330192565918
Validation loss: 1.9134439678602322

Epoch: 5| Step: 5
Training loss: 0.7870424389839172
Validation loss: 1.9426772876452374

Epoch: 5| Step: 6
Training loss: 1.0913387537002563
Validation loss: 1.9180538833782237

Epoch: 5| Step: 7
Training loss: 0.5260453224182129
Validation loss: 1.9126850238410376

Epoch: 5| Step: 8
Training loss: 1.0251469612121582
Validation loss: 1.9414070396013157

Epoch: 5| Step: 9
Training loss: 1.183684229850769
Validation loss: 1.8981381231738674

Epoch: 5| Step: 10
Training loss: 1.102792501449585
Validation loss: 1.8564199439940914

Epoch: 250| Step: 0
Training loss: 0.9440988302230835
Validation loss: 1.8610106232345744

Epoch: 5| Step: 1
Training loss: 1.4080255031585693
Validation loss: 1.8797965934199672

Epoch: 5| Step: 2
Training loss: 1.0502071380615234
Validation loss: 1.8418599482505553

Epoch: 5| Step: 3
Training loss: 1.2545602321624756
Validation loss: 1.870227171528724

Epoch: 5| Step: 4
Training loss: 1.1109808683395386
Validation loss: 1.8720518568510651

Epoch: 5| Step: 5
Training loss: 0.7058919668197632
Validation loss: 1.8793333858572028

Epoch: 5| Step: 6
Training loss: 0.9803446531295776
Validation loss: 1.9595270669588478

Epoch: 5| Step: 7
Training loss: 0.9689953923225403
Validation loss: 1.9333432054006925

Epoch: 5| Step: 8
Training loss: 1.2056927680969238
Validation loss: 1.9137447880160423

Epoch: 5| Step: 9
Training loss: 0.5489166975021362
Validation loss: 1.858562482300625

Epoch: 5| Step: 10
Training loss: 0.9906677007675171
Validation loss: 1.8438315212085683

Testing loss: 2.2319234477149115
