Epoch: 1| Step: 0
Training loss: 6.782546802757191
Validation loss: 5.793801765844716

Epoch: 6| Step: 1
Training loss: 5.227798201795502
Validation loss: 5.772781462015016

Epoch: 6| Step: 2
Training loss: 7.138237418380122
Validation loss: 5.754558470155817

Epoch: 6| Step: 3
Training loss: 5.018958009278556
Validation loss: 5.736915242337415

Epoch: 6| Step: 4
Training loss: 5.99393442643872
Validation loss: 5.718117799853135

Epoch: 6| Step: 5
Training loss: 5.221731282327622
Validation loss: 5.696702707891721

Epoch: 6| Step: 6
Training loss: 4.253396640374217
Validation loss: 5.672820491524669

Epoch: 6| Step: 7
Training loss: 4.906778683696794
Validation loss: 5.645979497478375

Epoch: 6| Step: 8
Training loss: 6.424557907390977
Validation loss: 5.615803398588159

Epoch: 6| Step: 9
Training loss: 5.9873472954822615
Validation loss: 5.582126925439806

Epoch: 6| Step: 10
Training loss: 4.876431377277335
Validation loss: 5.544419345693002

Epoch: 6| Step: 11
Training loss: 7.032364006802401
Validation loss: 5.50360412380933

Epoch: 6| Step: 12
Training loss: 4.136246579521289
Validation loss: 5.459352669421714

Epoch: 6| Step: 13
Training loss: 5.313015722037916
Validation loss: 5.412491953899537

Epoch: 2| Step: 0
Training loss: 4.91499026323753
Validation loss: 5.364646624358932

Epoch: 6| Step: 1
Training loss: 4.203617790291533
Validation loss: 5.314654368634065

Epoch: 6| Step: 2
Training loss: 4.712438138763194
Validation loss: 5.265240554648493

Epoch: 6| Step: 3
Training loss: 6.265248732077976
Validation loss: 5.216769972609859

Epoch: 6| Step: 4
Training loss: 5.60079648620687
Validation loss: 5.168872197110828

Epoch: 6| Step: 5
Training loss: 4.727713654368788
Validation loss: 5.121588915647744

Epoch: 6| Step: 6
Training loss: 4.808616755885258
Validation loss: 5.07753964062867

Epoch: 6| Step: 7
Training loss: 5.124527327907683
Validation loss: 5.031655602681099

Epoch: 6| Step: 8
Training loss: 5.593242600939884
Validation loss: 4.9858728241940415

Epoch: 6| Step: 9
Training loss: 5.5415179966461645
Validation loss: 4.939112150721521

Epoch: 6| Step: 10
Training loss: 6.118164296313842
Validation loss: 4.889362533821963

Epoch: 6| Step: 11
Training loss: 4.754245065794346
Validation loss: 4.836274994072517

Epoch: 6| Step: 12
Training loss: 4.108121615532799
Validation loss: 4.783765231664258

Epoch: 6| Step: 13
Training loss: 4.307971290315616
Validation loss: 4.737436405137846

Epoch: 3| Step: 0
Training loss: 5.148749056985263
Validation loss: 4.703747383101621

Epoch: 6| Step: 1
Training loss: 5.206724279445568
Validation loss: 4.676795297051995

Epoch: 6| Step: 2
Training loss: 4.163262438897148
Validation loss: 4.649680119332251

Epoch: 6| Step: 3
Training loss: 5.392039061022806
Validation loss: 4.625394585386048

Epoch: 6| Step: 4
Training loss: 4.5920770414449095
Validation loss: 4.5981959568803195

Epoch: 6| Step: 5
Training loss: 4.192474598816164
Validation loss: 4.572949411633441

Epoch: 6| Step: 6
Training loss: 4.479244686896206
Validation loss: 4.549064433578205

Epoch: 6| Step: 7
Training loss: 4.302433372216621
Validation loss: 4.523953433974121

Epoch: 6| Step: 8
Training loss: 4.762074833512248
Validation loss: 4.499207177274503

Epoch: 6| Step: 9
Training loss: 4.881886240270195
Validation loss: 4.476426440468098

Epoch: 6| Step: 10
Training loss: 4.665888085584272
Validation loss: 4.453982139640629

Epoch: 6| Step: 11
Training loss: 4.418935061279546
Validation loss: 4.4321919916799954

Epoch: 6| Step: 12
Training loss: 4.152908243761655
Validation loss: 4.407925955770087

Epoch: 6| Step: 13
Training loss: 4.523900458012301
Validation loss: 4.385220577509412

Epoch: 4| Step: 0
Training loss: 4.336266967353164
Validation loss: 4.362677285596094

Epoch: 6| Step: 1
Training loss: 3.0529314930561324
Validation loss: 4.343370019820127

Epoch: 6| Step: 2
Training loss: 4.968863431967314
Validation loss: 4.328153795011993

Epoch: 6| Step: 3
Training loss: 5.790242557485111
Validation loss: 4.314849168499276

Epoch: 6| Step: 4
Training loss: 4.178113295111456
Validation loss: 4.3027942350874016

Epoch: 6| Step: 5
Training loss: 3.8713428097698652
Validation loss: 4.284905018603518

Epoch: 6| Step: 6
Training loss: 4.648588290293233
Validation loss: 4.268295530926606

Epoch: 6| Step: 7
Training loss: 5.303213462473904
Validation loss: 4.255545181752561

Epoch: 6| Step: 8
Training loss: 4.361593577484753
Validation loss: 4.24431315289886

Epoch: 6| Step: 9
Training loss: 4.042933603032614
Validation loss: 4.229997001851881

Epoch: 6| Step: 10
Training loss: 4.6955221069062505
Validation loss: 4.217723915806521

Epoch: 6| Step: 11
Training loss: 3.045090372783371
Validation loss: 4.203018313379484

Epoch: 6| Step: 12
Training loss: 4.179629316548883
Validation loss: 4.188414268005635

Epoch: 6| Step: 13
Training loss: 4.077157910730013
Validation loss: 4.176319286374019

Epoch: 5| Step: 0
Training loss: 4.168468441812967
Validation loss: 4.168339822015938

Epoch: 6| Step: 1
Training loss: 4.627898261822244
Validation loss: 4.14031648916368

Epoch: 6| Step: 2
Training loss: 4.118928081732002
Validation loss: 4.080630541581562

Epoch: 6| Step: 3
Training loss: 4.431494719254141
Validation loss: 4.047506019907898

Epoch: 6| Step: 4
Training loss: 5.301512721845773
Validation loss: 4.05429898939915

Epoch: 6| Step: 5
Training loss: 3.798827371866892
Validation loss: 4.026296962529058

Epoch: 6| Step: 6
Training loss: 3.0081907356541064
Validation loss: 4.012722388247128

Epoch: 6| Step: 7
Training loss: 3.1892931513195384
Validation loss: 4.0041522783093875

Epoch: 6| Step: 8
Training loss: 4.419405729639883
Validation loss: 3.997054708978861

Epoch: 6| Step: 9
Training loss: 4.707030642180977
Validation loss: 3.986223314979069

Epoch: 6| Step: 10
Training loss: 3.6643972020303757
Validation loss: 3.9718556324711294

Epoch: 6| Step: 11
Training loss: 4.65687239410692
Validation loss: 3.963060283039882

Epoch: 6| Step: 12
Training loss: 4.176902912965052
Validation loss: 3.9530343009611695

Epoch: 6| Step: 13
Training loss: 3.208297349472052
Validation loss: 3.937656368882056

Epoch: 6| Step: 0
Training loss: 4.569021711084584
Validation loss: 3.923815300987577

Epoch: 6| Step: 1
Training loss: 3.4568643475776875
Validation loss: 3.9078345607958465

Epoch: 6| Step: 2
Training loss: 3.9929487543980606
Validation loss: 3.9034129666297317

Epoch: 6| Step: 3
Training loss: 3.019862385071225
Validation loss: 3.8836987931643536

Epoch: 6| Step: 4
Training loss: 5.165710278665023
Validation loss: 3.8730243366160235

Epoch: 6| Step: 5
Training loss: 4.40538763170131
Validation loss: 3.860797480603374

Epoch: 6| Step: 6
Training loss: 3.9532471890469383
Validation loss: 3.845526196072043

Epoch: 6| Step: 7
Training loss: 3.7799213691889118
Validation loss: 3.833533361190892

Epoch: 6| Step: 8
Training loss: 3.184789365214166
Validation loss: 3.8249067596624897

Epoch: 6| Step: 9
Training loss: 3.5557261532016917
Validation loss: 3.826566663016823

Epoch: 6| Step: 10
Training loss: 4.384111779618696
Validation loss: 3.8135462494858943

Epoch: 6| Step: 11
Training loss: 4.700504016229727
Validation loss: 3.8088990407651213

Epoch: 6| Step: 12
Training loss: 3.1444702900729347
Validation loss: 3.807839546674946

Epoch: 6| Step: 13
Training loss: 4.5272997244273325
Validation loss: 3.8032453275364624

Epoch: 7| Step: 0
Training loss: 3.8084650418957238
Validation loss: 3.790909513169016

Epoch: 6| Step: 1
Training loss: 3.7806325361038295
Validation loss: 3.78296465546216

Epoch: 6| Step: 2
Training loss: 3.4607561808809733
Validation loss: 3.7724706321929125

Epoch: 6| Step: 3
Training loss: 4.123990715704604
Validation loss: 3.7662699082527125

Epoch: 6| Step: 4
Training loss: 3.8974816138498785
Validation loss: 3.760659592304112

Epoch: 6| Step: 5
Training loss: 4.056315012735567
Validation loss: 3.755561386815097

Epoch: 6| Step: 6
Training loss: 2.801521235437094
Validation loss: 3.7503083064727702

Epoch: 6| Step: 7
Training loss: 5.323666135974281
Validation loss: 3.7476093574857017

Epoch: 6| Step: 8
Training loss: 4.025170762130054
Validation loss: 3.74174723644066

Epoch: 6| Step: 9
Training loss: 3.8759203402400724
Validation loss: 3.7372993521011595

Epoch: 6| Step: 10
Training loss: 3.3819429544231903
Validation loss: 3.7299101411453086

Epoch: 6| Step: 11
Training loss: 3.0041532377735645
Validation loss: 3.723390825145588

Epoch: 6| Step: 12
Training loss: 4.258007584048604
Validation loss: 3.718719384403555

Epoch: 6| Step: 13
Training loss: 4.947107167196853
Validation loss: 3.715141898876434

Epoch: 8| Step: 0
Training loss: 4.488219630098113
Validation loss: 3.7129419279684255

Epoch: 6| Step: 1
Training loss: 3.718405571382193
Validation loss: 3.707415447910458

Epoch: 6| Step: 2
Training loss: 3.4801813043303853
Validation loss: 3.70636874666515

Epoch: 6| Step: 3
Training loss: 3.25123514033423
Validation loss: 3.7005321057432647

Epoch: 6| Step: 4
Training loss: 3.1863767851443336
Validation loss: 3.6950153473388485

Epoch: 6| Step: 5
Training loss: 3.758314959586173
Validation loss: 3.694090054540986

Epoch: 6| Step: 6
Training loss: 4.462419627772154
Validation loss: 3.6899643400105298

Epoch: 6| Step: 7
Training loss: 3.334220211937402
Validation loss: 3.6863159063901945

Epoch: 6| Step: 8
Training loss: 3.995651862061485
Validation loss: 3.682823969193048

Epoch: 6| Step: 9
Training loss: 3.9639432138095936
Validation loss: 3.6806409715361137

Epoch: 6| Step: 10
Training loss: 4.5686524596023785
Validation loss: 3.6765279465796836

Epoch: 6| Step: 11
Training loss: 3.1822064893512394
Validation loss: 3.6786026775184357

Epoch: 6| Step: 12
Training loss: 4.056737245704789
Validation loss: 3.6645047385570093

Epoch: 6| Step: 13
Training loss: 4.764433965216764
Validation loss: 3.658588906245089

Epoch: 9| Step: 0
Training loss: 4.285146012550442
Validation loss: 3.655414704297694

Epoch: 6| Step: 1
Training loss: 3.911015647628643
Validation loss: 3.6483852450100787

Epoch: 6| Step: 2
Training loss: 4.274952287017297
Validation loss: 3.642885894296557

Epoch: 6| Step: 3
Training loss: 2.9741632198343337
Validation loss: 3.643011229452052

Epoch: 6| Step: 4
Training loss: 3.5106936985959525
Validation loss: 3.6349822534462897

Epoch: 6| Step: 5
Training loss: 4.436360602441765
Validation loss: 3.6297853063625123

Epoch: 6| Step: 6
Training loss: 3.1080834855069224
Validation loss: 3.6211076602486534

Epoch: 6| Step: 7
Training loss: 2.8227283560430108
Validation loss: 3.6142508895969137

Epoch: 6| Step: 8
Training loss: 3.939090468092896
Validation loss: 3.614650730772967

Epoch: 6| Step: 9
Training loss: 3.7850879706335188
Validation loss: 3.59863234374541

Epoch: 6| Step: 10
Training loss: 3.741039761117582
Validation loss: 3.5919348514089102

Epoch: 6| Step: 11
Training loss: 4.6660861380843
Validation loss: 3.588916448886094

Epoch: 6| Step: 12
Training loss: 4.223214958557241
Validation loss: 3.5793139963947764

Epoch: 6| Step: 13
Training loss: 2.587064560817839
Validation loss: 3.5762627589968603

Epoch: 10| Step: 0
Training loss: 2.8502548773049377
Validation loss: 3.57368478250019

Epoch: 6| Step: 1
Training loss: 4.338801137699215
Validation loss: 3.566649374538024

Epoch: 6| Step: 2
Training loss: 4.225175048091111
Validation loss: 3.5644053897760157

Epoch: 6| Step: 3
Training loss: 4.228766862484393
Validation loss: 3.5602504908440777

Epoch: 6| Step: 4
Training loss: 3.6767885488008107
Validation loss: 3.5553948676829186

Epoch: 6| Step: 5
Training loss: 4.218221673732323
Validation loss: 3.550658638963498

Epoch: 6| Step: 6
Training loss: 3.1154745266466364
Validation loss: 3.5479846060926525

Epoch: 6| Step: 7
Training loss: 3.4977345628046703
Validation loss: 3.543477661747587

Epoch: 6| Step: 8
Training loss: 4.2665636755513425
Validation loss: 3.5432021825533875

Epoch: 6| Step: 9
Training loss: 3.625996419830154
Validation loss: 3.5389940175125263

Epoch: 6| Step: 10
Training loss: 3.262101312005438
Validation loss: 3.534748134647935

Epoch: 6| Step: 11
Training loss: 3.618866961076383
Validation loss: 3.532760551130812

Epoch: 6| Step: 12
Training loss: 3.1233693255206814
Validation loss: 3.5280363106416863

Epoch: 6| Step: 13
Training loss: 4.318967530531476
Validation loss: 3.5229747604688013

Epoch: 11| Step: 0
Training loss: 3.8887714428802496
Validation loss: 3.5214152114085144

Epoch: 6| Step: 1
Training loss: 4.510225545990799
Validation loss: 3.5178276310095775

Epoch: 6| Step: 2
Training loss: 3.2380983602417928
Validation loss: 3.5143862128949634

Epoch: 6| Step: 3
Training loss: 4.01583731123445
Validation loss: 3.5121775681501464

Epoch: 6| Step: 4
Training loss: 3.8044130198893127
Validation loss: 3.5103718608193613

Epoch: 6| Step: 5
Training loss: 3.7140521982168075
Validation loss: 3.5191453757670432

Epoch: 6| Step: 6
Training loss: 4.0047819640664475
Validation loss: 3.510967302131326

Epoch: 6| Step: 7
Training loss: 2.4471231892533214
Validation loss: 3.5016219267512056

Epoch: 6| Step: 8
Training loss: 4.148877021796643
Validation loss: 3.499437178495367

Epoch: 6| Step: 9
Training loss: 2.7248990906396333
Validation loss: 3.4972063538162224

Epoch: 6| Step: 10
Training loss: 3.5255007232634976
Validation loss: 3.49964028661971

Epoch: 6| Step: 11
Training loss: 4.293578947122191
Validation loss: 3.498496339087706

Epoch: 6| Step: 12
Training loss: 3.669152991859748
Validation loss: 3.4941022803148742

Epoch: 6| Step: 13
Training loss: 3.3489819531277694
Validation loss: 3.48895805583941

Epoch: 12| Step: 0
Training loss: 2.451080733956713
Validation loss: 3.485292325437181

Epoch: 6| Step: 1
Training loss: 3.5003103391117727
Validation loss: 3.484452936010971

Epoch: 6| Step: 2
Training loss: 3.632668900471677
Validation loss: 3.4807297175669487

Epoch: 6| Step: 3
Training loss: 3.400315040129568
Validation loss: 3.4810171105866026

Epoch: 6| Step: 4
Training loss: 4.002943148268109
Validation loss: 3.4796421791320276

Epoch: 6| Step: 5
Training loss: 4.234686695746547
Validation loss: 3.479600379873967

Epoch: 6| Step: 6
Training loss: 4.657895200776421
Validation loss: 3.476344315145155

Epoch: 6| Step: 7
Training loss: 2.9380164808378466
Validation loss: 3.4725064468273743

Epoch: 6| Step: 8
Training loss: 3.7538973582913684
Validation loss: 3.4695157106966508

Epoch: 6| Step: 9
Training loss: 3.5998054239883817
Validation loss: 3.466784083383091

Epoch: 6| Step: 10
Training loss: 3.8684230487571125
Validation loss: 3.4657129888809295

Epoch: 6| Step: 11
Training loss: 3.8273222412451866
Validation loss: 3.4702044697590355

Epoch: 6| Step: 12
Training loss: 3.814775257015234
Validation loss: 3.467230970747014

Epoch: 6| Step: 13
Training loss: 3.292220893911379
Validation loss: 3.4692745298091188

Epoch: 13| Step: 0
Training loss: 3.3777474417355964
Validation loss: 3.4896037811772396

Epoch: 6| Step: 1
Training loss: 4.393535043333779
Validation loss: 3.4541625872830024

Epoch: 6| Step: 2
Training loss: 2.160051726145752
Validation loss: 3.4588750767525083

Epoch: 6| Step: 3
Training loss: 2.871593779533547
Validation loss: 3.483283597937796

Epoch: 6| Step: 4
Training loss: 3.49544037408929
Validation loss: 3.466129250456443

Epoch: 6| Step: 5
Training loss: 3.550920909657187
Validation loss: 3.476662676737776

Epoch: 6| Step: 6
Training loss: 3.7235509831931233
Validation loss: 3.4719540366238957

Epoch: 6| Step: 7
Training loss: 3.7789264191820138
Validation loss: 3.4624826827326434

Epoch: 6| Step: 8
Training loss: 4.215785362411591
Validation loss: 3.462433466159718

Epoch: 6| Step: 9
Training loss: 4.1447903393039205
Validation loss: 3.467255950254861

Epoch: 6| Step: 10
Training loss: 3.9003999162696044
Validation loss: 3.4554563525728637

Epoch: 6| Step: 11
Training loss: 3.941252116581729
Validation loss: 3.4471108169280993

Epoch: 6| Step: 12
Training loss: 3.680458976070258
Validation loss: 3.4455139995635085

Epoch: 6| Step: 13
Training loss: 3.7915911544714334
Validation loss: 3.44575047340844

Epoch: 14| Step: 0
Training loss: 3.7827666212511777
Validation loss: 3.4439984837934445

Epoch: 6| Step: 1
Training loss: 3.3850251113208096
Validation loss: 3.4381142582977517

Epoch: 6| Step: 2
Training loss: 3.4969366836902793
Validation loss: 3.431289799754901

Epoch: 6| Step: 3
Training loss: 3.2324354465349536
Validation loss: 3.428698483817916

Epoch: 6| Step: 4
Training loss: 3.921380608389664
Validation loss: 3.424687210900935

Epoch: 6| Step: 5
Training loss: 3.4167390365999677
Validation loss: 3.420683800986862

Epoch: 6| Step: 6
Training loss: 3.1379162698422225
Validation loss: 3.420037881170893

Epoch: 6| Step: 7
Training loss: 3.518497090711281
Validation loss: 3.4135778713026506

Epoch: 6| Step: 8
Training loss: 4.047212917992387
Validation loss: 3.4128644848127117

Epoch: 6| Step: 9
Training loss: 4.597744612707587
Validation loss: 3.4098966138566014

Epoch: 6| Step: 10
Training loss: 2.855166480560086
Validation loss: 3.4070702617236566

Epoch: 6| Step: 11
Training loss: 4.021283745450671
Validation loss: 3.4027753984952076

Epoch: 6| Step: 12
Training loss: 3.4934620419541154
Validation loss: 3.400201998204787

Epoch: 6| Step: 13
Training loss: 3.819196604384474
Validation loss: 3.403115437769901

Epoch: 15| Step: 0
Training loss: 3.2562172915523755
Validation loss: 3.3988076285339104

Epoch: 6| Step: 1
Training loss: 3.563848140011507
Validation loss: 3.400068654990438

Epoch: 6| Step: 2
Training loss: 1.7313684058066228
Validation loss: 3.3960157418773167

Epoch: 6| Step: 3
Training loss: 3.853401781769979
Validation loss: 3.3956161146197044

Epoch: 6| Step: 4
Training loss: 3.7082439083218297
Validation loss: 3.39325361534448

Epoch: 6| Step: 5
Training loss: 3.70604555231911
Validation loss: 3.3898663595244143

Epoch: 6| Step: 6
Training loss: 2.884960501150871
Validation loss: 3.3855021892690784

Epoch: 6| Step: 7
Training loss: 4.369435504619369
Validation loss: 3.3813176488353744

Epoch: 6| Step: 8
Training loss: 2.501055113345701
Validation loss: 3.3789639455410048

Epoch: 6| Step: 9
Training loss: 4.112015836559036
Validation loss: 3.376006642827443

Epoch: 6| Step: 10
Training loss: 4.724071003650789
Validation loss: 3.376000049964311

Epoch: 6| Step: 11
Training loss: 3.0357670114249955
Validation loss: 3.3719744548724084

Epoch: 6| Step: 12
Training loss: 3.217478973391103
Validation loss: 3.373908045146135

Epoch: 6| Step: 13
Training loss: 5.353893624355827
Validation loss: 3.3738707191687025

Epoch: 16| Step: 0
Training loss: 3.632409251812941
Validation loss: 3.368990434649117

Epoch: 6| Step: 1
Training loss: 3.988616122273716
Validation loss: 3.373298392287746

Epoch: 6| Step: 2
Training loss: 3.477076666025421
Validation loss: 3.3734557820752413

Epoch: 6| Step: 3
Training loss: 3.1969688245144012
Validation loss: 3.3648977485473814

Epoch: 6| Step: 4
Training loss: 3.6222638294220046
Validation loss: 3.361095909351628

Epoch: 6| Step: 5
Training loss: 3.166099664889388
Validation loss: 3.358795360210635

Epoch: 6| Step: 6
Training loss: 3.662971773455914
Validation loss: 3.360421210743163

Epoch: 6| Step: 7
Training loss: 4.4723099620312965
Validation loss: 3.364877129025504

Epoch: 6| Step: 8
Training loss: 2.839049090373188
Validation loss: 3.3585112544713334

Epoch: 6| Step: 9
Training loss: 4.138114196735587
Validation loss: 3.355835707946731

Epoch: 6| Step: 10
Training loss: 3.7826100575331676
Validation loss: 3.3515199554861606

Epoch: 6| Step: 11
Training loss: 3.5771027149941004
Validation loss: 3.3530557265625878

Epoch: 6| Step: 12
Training loss: 3.3654335923875407
Validation loss: 3.3545972048044264

Epoch: 6| Step: 13
Training loss: 2.6389429276493694
Validation loss: 3.3509239374213693

Epoch: 17| Step: 0
Training loss: 3.9623293866993405
Validation loss: 3.3475899355162486

Epoch: 6| Step: 1
Training loss: 3.4819853247476233
Validation loss: 3.3458149617245656

Epoch: 6| Step: 2
Training loss: 4.207172246215523
Validation loss: 3.3470436414710654

Epoch: 6| Step: 3
Training loss: 3.8514476085805223
Validation loss: 3.3568006025862065

Epoch: 6| Step: 4
Training loss: 3.476773167774431
Validation loss: 3.3520441408876316

Epoch: 6| Step: 5
Training loss: 2.2331360269568394
Validation loss: 3.344952681080586

Epoch: 6| Step: 6
Training loss: 3.4845060999544994
Validation loss: 3.34657115224008

Epoch: 6| Step: 7
Training loss: 4.13949304618855
Validation loss: 3.372665485081529

Epoch: 6| Step: 8
Training loss: 3.3770593082641
Validation loss: 3.3433309711687644

Epoch: 6| Step: 9
Training loss: 3.1853609574616955
Validation loss: 3.3528918434259065

Epoch: 6| Step: 10
Training loss: 4.1567625719236965
Validation loss: 3.408778564398905

Epoch: 6| Step: 11
Training loss: 4.303576982152009
Validation loss: 3.3724631950798796

Epoch: 6| Step: 12
Training loss: 3.070553835636813
Validation loss: 3.389721117042193

Epoch: 6| Step: 13
Training loss: 1.724292142729414
Validation loss: 3.4176341732126727

Epoch: 18| Step: 0
Training loss: 3.46591634394289
Validation loss: 3.4449000530841216

Epoch: 6| Step: 1
Training loss: 3.233017788725697
Validation loss: 3.4438461938528206

Epoch: 6| Step: 2
Training loss: 4.420892073768062
Validation loss: 3.4150244224839055

Epoch: 6| Step: 3
Training loss: 3.4148294735245495
Validation loss: 3.369777936492674

Epoch: 6| Step: 4
Training loss: 3.506929486099085
Validation loss: 3.3485545465151567

Epoch: 6| Step: 5
Training loss: 3.51865266763558
Validation loss: 3.3950754899469437

Epoch: 6| Step: 6
Training loss: 4.047957934556806
Validation loss: 3.417486657149456

Epoch: 6| Step: 7
Training loss: 2.9813061658898685
Validation loss: 3.346191690869838

Epoch: 6| Step: 8
Training loss: 2.668494244008024
Validation loss: 3.380445411769337

Epoch: 6| Step: 9
Training loss: 4.074878555079582
Validation loss: 3.424339572259288

Epoch: 6| Step: 10
Training loss: 4.29031414953602
Validation loss: 3.4258909754762725

Epoch: 6| Step: 11
Training loss: 3.889283956411966
Validation loss: 3.4142211207405797

Epoch: 6| Step: 12
Training loss: 2.9823102749052897
Validation loss: 3.3867805710826566

Epoch: 6| Step: 13
Training loss: 4.052048370027435
Validation loss: 3.377523426099058

Epoch: 19| Step: 0
Training loss: 3.6590685291779796
Validation loss: 3.3660845142848395

Epoch: 6| Step: 1
Training loss: 2.8114816305451513
Validation loss: 3.3903378570657545

Epoch: 6| Step: 2
Training loss: 4.376670954271954
Validation loss: 3.4679581539210056

Epoch: 6| Step: 3
Training loss: 3.4590199413226537
Validation loss: 3.3928872082069232

Epoch: 6| Step: 4
Training loss: 3.150422258685337
Validation loss: 3.3639140282312785

Epoch: 6| Step: 5
Training loss: 3.7913444018787357
Validation loss: 3.32272925195392

Epoch: 6| Step: 6
Training loss: 1.8057207724793587
Validation loss: 3.328051435940199

Epoch: 6| Step: 7
Training loss: 3.5589222929087523
Validation loss: 3.350016386016212

Epoch: 6| Step: 8
Training loss: 3.7311941989323585
Validation loss: 3.3591439284276943

Epoch: 6| Step: 9
Training loss: 3.863524025288562
Validation loss: 3.3319360686041213

Epoch: 6| Step: 10
Training loss: 3.4685026888276713
Validation loss: 3.318323520944557

Epoch: 6| Step: 11
Training loss: 4.893534322105149
Validation loss: 3.3097498818241107

Epoch: 6| Step: 12
Training loss: 2.9522514867889487
Validation loss: 3.3048799012167156

Epoch: 6| Step: 13
Training loss: 3.9513683411671616
Validation loss: 3.3176205914958836

Epoch: 20| Step: 0
Training loss: 3.360368022972617
Validation loss: 3.3534084302004312

Epoch: 6| Step: 1
Training loss: 3.8726797232840906
Validation loss: 3.356121079042701

Epoch: 6| Step: 2
Training loss: 3.2052115738614404
Validation loss: 3.355818927306707

Epoch: 6| Step: 3
Training loss: 4.02464711792576
Validation loss: 3.3547277993271036

Epoch: 6| Step: 4
Training loss: 3.0468878330058273
Validation loss: 3.3464327808427052

Epoch: 6| Step: 5
Training loss: 3.4101025554192006
Validation loss: 3.3437437284186724

Epoch: 6| Step: 6
Training loss: 3.954690374511253
Validation loss: 3.3391264870586808

Epoch: 6| Step: 7
Training loss: 3.4609912325646897
Validation loss: 3.331648470515739

Epoch: 6| Step: 8
Training loss: 3.577201624169504
Validation loss: 3.329421762153563

Epoch: 6| Step: 9
Training loss: 3.098107707929807
Validation loss: 3.3232487477135555

Epoch: 6| Step: 10
Training loss: 3.1836584540970705
Validation loss: 3.311532560159165

Epoch: 6| Step: 11
Training loss: 3.891525470750764
Validation loss: 3.284867859045958

Epoch: 6| Step: 12
Training loss: 3.7981381924895845
Validation loss: 3.28348983985883

Epoch: 6| Step: 13
Training loss: 4.095452340542767
Validation loss: 3.283594568717535

Epoch: 21| Step: 0
Training loss: 3.7611801062872745
Validation loss: 3.2832784528712367

Epoch: 6| Step: 1
Training loss: 3.6978758617173555
Validation loss: 3.2841999097399968

Epoch: 6| Step: 2
Training loss: 3.2854764331000847
Validation loss: 3.2834595334656327

Epoch: 6| Step: 3
Training loss: 3.825138967146286
Validation loss: 3.2826895232567423

Epoch: 6| Step: 4
Training loss: 3.379028741457477
Validation loss: 3.2811759678643337

Epoch: 6| Step: 5
Training loss: 3.7301466238539764
Validation loss: 3.286011383168642

Epoch: 6| Step: 6
Training loss: 3.1178656966064455
Validation loss: 3.2982246495215644

Epoch: 6| Step: 7
Training loss: 2.756538248019238
Validation loss: 3.2877649293533717

Epoch: 6| Step: 8
Training loss: 3.3940257935136753
Validation loss: 3.2799118618336913

Epoch: 6| Step: 9
Training loss: 4.13717565273603
Validation loss: 3.2777589273464

Epoch: 6| Step: 10
Training loss: 3.640361989225475
Validation loss: 3.267640110073723

Epoch: 6| Step: 11
Training loss: 3.522240412117258
Validation loss: 3.2674659893302853

Epoch: 6| Step: 12
Training loss: 3.694438935915506
Validation loss: 3.2640641435885005

Epoch: 6| Step: 13
Training loss: 2.844101601128466
Validation loss: 3.260491293866552

Epoch: 22| Step: 0
Training loss: 3.5589725363974845
Validation loss: 3.2596058145698192

Epoch: 6| Step: 1
Training loss: 3.3989355665015912
Validation loss: 3.2564219674567605

Epoch: 6| Step: 2
Training loss: 3.339337726651307
Validation loss: 3.2488123006936283

Epoch: 6| Step: 3
Training loss: 3.989910275016914
Validation loss: 3.2408709877028588

Epoch: 6| Step: 4
Training loss: 3.94073498759199
Validation loss: 3.2364917225395335

Epoch: 6| Step: 5
Training loss: 3.3119309134441868
Validation loss: 3.231767745427746

Epoch: 6| Step: 6
Training loss: 3.2821075772002706
Validation loss: 3.228588935120915

Epoch: 6| Step: 7
Training loss: 3.0614078676352556
Validation loss: 3.2292823625229294

Epoch: 6| Step: 8
Training loss: 3.310275068349639
Validation loss: 3.2266729379111787

Epoch: 6| Step: 9
Training loss: 3.72686574409867
Validation loss: 3.2242847266605508

Epoch: 6| Step: 10
Training loss: 3.066677591746676
Validation loss: 3.222116381140168

Epoch: 6| Step: 11
Training loss: 3.9515536958680095
Validation loss: 3.22321666986876

Epoch: 6| Step: 12
Training loss: 3.351502033390667
Validation loss: 3.249384039193497

Epoch: 6| Step: 13
Training loss: 3.270572109279517
Validation loss: 3.2536661469939627

Epoch: 23| Step: 0
Training loss: 2.967080701017844
Validation loss: 3.256676238356581

Epoch: 6| Step: 1
Training loss: 3.977137795673714
Validation loss: 3.241554981558689

Epoch: 6| Step: 2
Training loss: 2.6566831347801885
Validation loss: 3.213737102248504

Epoch: 6| Step: 3
Training loss: 3.9429848631515796
Validation loss: 3.21330895539186

Epoch: 6| Step: 4
Training loss: 2.9709453295926234
Validation loss: 3.216115221815569

Epoch: 6| Step: 5
Training loss: 3.506814589577531
Validation loss: 3.2137007422733497

Epoch: 6| Step: 6
Training loss: 4.173421394548436
Validation loss: 3.2165343713968824

Epoch: 6| Step: 7
Training loss: 4.032596570234444
Validation loss: 3.215196691323203

Epoch: 6| Step: 8
Training loss: 3.0801199243160884
Validation loss: 3.2125965576165605

Epoch: 6| Step: 9
Training loss: 3.608457242205212
Validation loss: 3.20968220315623

Epoch: 6| Step: 10
Training loss: 3.3838979904455173
Validation loss: 3.2052533217810653

Epoch: 6| Step: 11
Training loss: 3.4416622971575497
Validation loss: 3.2023153710971686

Epoch: 6| Step: 12
Training loss: 2.638619648990467
Validation loss: 3.20113881757332

Epoch: 6| Step: 13
Training loss: 3.9784678033530563
Validation loss: 3.201676910118891

Epoch: 24| Step: 0
Training loss: 3.259453010539879
Validation loss: 3.1992514378224746

Epoch: 6| Step: 1
Training loss: 3.8574001186095317
Validation loss: 3.2006825056366974

Epoch: 6| Step: 2
Training loss: 3.077167187690811
Validation loss: 3.198401109218989

Epoch: 6| Step: 3
Training loss: 3.8859725159101655
Validation loss: 3.197800460253407

Epoch: 6| Step: 4
Training loss: 3.8170149287510777
Validation loss: 3.206434094984119

Epoch: 6| Step: 5
Training loss: 1.9564440792445823
Validation loss: 3.2036230468921247

Epoch: 6| Step: 6
Training loss: 3.0288096564286584
Validation loss: 3.2138278121316737

Epoch: 6| Step: 7
Training loss: 3.282863837689075
Validation loss: 3.219554178222398

Epoch: 6| Step: 8
Training loss: 3.302523001071669
Validation loss: 3.207418888106681

Epoch: 6| Step: 9
Training loss: 3.1814913495138173
Validation loss: 3.195701087886944

Epoch: 6| Step: 10
Training loss: 3.1259748845571096
Validation loss: 3.192002557274278

Epoch: 6| Step: 11
Training loss: 4.511812177739369
Validation loss: 3.1875916463218483

Epoch: 6| Step: 12
Training loss: 4.14292872418731
Validation loss: 3.186805362280248

Epoch: 6| Step: 13
Training loss: 3.0564248688329965
Validation loss: 3.1890279802043575

Epoch: 25| Step: 0
Training loss: 2.879295126169595
Validation loss: 3.185659687626002

Epoch: 6| Step: 1
Training loss: 2.6791977504352866
Validation loss: 3.186928583859606

Epoch: 6| Step: 2
Training loss: 3.797899900655033
Validation loss: 3.188200659475525

Epoch: 6| Step: 3
Training loss: 3.54271275648009
Validation loss: 3.1862500526990374

Epoch: 6| Step: 4
Training loss: 3.3774810431320423
Validation loss: 3.183096423807146

Epoch: 6| Step: 5
Training loss: 3.411051175035839
Validation loss: 3.183175889240538

Epoch: 6| Step: 6
Training loss: 3.8080959209895213
Validation loss: 3.1798961698221175

Epoch: 6| Step: 7
Training loss: 3.5940265051576055
Validation loss: 3.180359260811593

Epoch: 6| Step: 8
Training loss: 3.365368982635073
Validation loss: 3.1795102430056654

Epoch: 6| Step: 9
Training loss: 4.265977558475776
Validation loss: 3.1778069470781163

Epoch: 6| Step: 10
Training loss: 4.582907200279323
Validation loss: 3.175510153505862

Epoch: 6| Step: 11
Training loss: 2.968074038998448
Validation loss: 3.1762669093094

Epoch: 6| Step: 12
Training loss: 2.478831313930491
Validation loss: 3.1738414123610403

Epoch: 6| Step: 13
Training loss: 1.860354510127258
Validation loss: 3.1735185743249015

Epoch: 26| Step: 0
Training loss: 3.509171458428043
Validation loss: 3.1740595077593605

Epoch: 6| Step: 1
Training loss: 2.751386899614158
Validation loss: 3.1741534466102395

Epoch: 6| Step: 2
Training loss: 3.05500374252165
Validation loss: 3.17014174581846

Epoch: 6| Step: 3
Training loss: 3.3832783367278507
Validation loss: 3.1710215892022604

Epoch: 6| Step: 4
Training loss: 3.2640182703946703
Validation loss: 3.1692257764369485

Epoch: 6| Step: 5
Training loss: 3.8427909336879336
Validation loss: 3.1688924139118346

Epoch: 6| Step: 6
Training loss: 3.1609594882684924
Validation loss: 3.1682129022568994

Epoch: 6| Step: 7
Training loss: 4.045504658342866
Validation loss: 3.169720646169072

Epoch: 6| Step: 8
Training loss: 3.710192924891776
Validation loss: 3.1668816500508004

Epoch: 6| Step: 9
Training loss: 3.255613028229122
Validation loss: 3.1688137908758436

Epoch: 6| Step: 10
Training loss: 4.233351918177222
Validation loss: 3.165714036970373

Epoch: 6| Step: 11
Training loss: 2.7572202397745738
Validation loss: 3.1651413622104476

Epoch: 6| Step: 12
Training loss: 2.9639004901856363
Validation loss: 3.16302281288576

Epoch: 6| Step: 13
Training loss: 3.797860351301222
Validation loss: 3.1636471727824356

Epoch: 27| Step: 0
Training loss: 3.159440344975203
Validation loss: 3.16119976695651

Epoch: 6| Step: 1
Training loss: 2.3897750440574845
Validation loss: 3.160465266489552

Epoch: 6| Step: 2
Training loss: 2.226573636211186
Validation loss: 3.1600096947316305

Epoch: 6| Step: 3
Training loss: 3.9388570717580347
Validation loss: 3.1592124601384453

Epoch: 6| Step: 4
Training loss: 3.2988943270629223
Validation loss: 3.159883503879084

Epoch: 6| Step: 5
Training loss: 3.8991707091294563
Validation loss: 3.1570927808439593

Epoch: 6| Step: 6
Training loss: 3.4036338628876073
Validation loss: 3.1582163579620453

Epoch: 6| Step: 7
Training loss: 3.886492391924599
Validation loss: 3.1588849603000297

Epoch: 6| Step: 8
Training loss: 3.00702607413818
Validation loss: 3.1546625665263854

Epoch: 6| Step: 9
Training loss: 4.080592085193897
Validation loss: 3.153341408081199

Epoch: 6| Step: 10
Training loss: 3.635225802915631
Validation loss: 3.153156845416699

Epoch: 6| Step: 11
Training loss: 3.718731791988644
Validation loss: 3.153414054563614

Epoch: 6| Step: 12
Training loss: 2.9251938193246674
Validation loss: 3.1552425122030368

Epoch: 6| Step: 13
Training loss: 3.813717632025062
Validation loss: 3.1626668311226616

Epoch: 28| Step: 0
Training loss: 3.0223271502094318
Validation loss: 3.155504521822349

Epoch: 6| Step: 1
Training loss: 3.9405104013186403
Validation loss: 3.151473676247219

Epoch: 6| Step: 2
Training loss: 3.5029788283683745
Validation loss: 3.149545874921985

Epoch: 6| Step: 3
Training loss: 2.9066250466799644
Validation loss: 3.146941710886171

Epoch: 6| Step: 4
Training loss: 3.452452995538298
Validation loss: 3.1470501350221967

Epoch: 6| Step: 5
Training loss: 3.928424245380936
Validation loss: 3.1443158842767596

Epoch: 6| Step: 6
Training loss: 3.3154158804020306
Validation loss: 3.1471518236524347

Epoch: 6| Step: 7
Training loss: 3.8430620523764025
Validation loss: 3.144905157679601

Epoch: 6| Step: 8
Training loss: 2.6623878921045487
Validation loss: 3.1426112371840245

Epoch: 6| Step: 9
Training loss: 3.6928342610325156
Validation loss: 3.140191594527883

Epoch: 6| Step: 10
Training loss: 3.4908261643299157
Validation loss: 3.1384837606374103

Epoch: 6| Step: 11
Training loss: 2.616426089539918
Validation loss: 3.13752572353414

Epoch: 6| Step: 12
Training loss: 3.792017337107561
Validation loss: 3.13586672312828

Epoch: 6| Step: 13
Training loss: 3.132924370421158
Validation loss: 3.133788365509226

Epoch: 29| Step: 0
Training loss: 3.6219006146635224
Validation loss: 3.1331092984998232

Epoch: 6| Step: 1
Training loss: 3.0037136933874478
Validation loss: 3.1302106915064547

Epoch: 6| Step: 2
Training loss: 3.3434646342069883
Validation loss: 3.1290066340278644

Epoch: 6| Step: 3
Training loss: 3.2453186358346544
Validation loss: 3.130541495724699

Epoch: 6| Step: 4
Training loss: 2.3781563715425746
Validation loss: 3.1272861887760186

Epoch: 6| Step: 5
Training loss: 3.4373859733396124
Validation loss: 3.1306200014578334

Epoch: 6| Step: 6
Training loss: 3.7737141067501208
Validation loss: 3.128557879660193

Epoch: 6| Step: 7
Training loss: 3.934115211448216
Validation loss: 3.126849044620555

Epoch: 6| Step: 8
Training loss: 3.0629493228059044
Validation loss: 3.1265681755923445

Epoch: 6| Step: 9
Training loss: 3.4211639641009164
Validation loss: 3.128815927840894

Epoch: 6| Step: 10
Training loss: 4.047881601403922
Validation loss: 3.1259770873695363

Epoch: 6| Step: 11
Training loss: 3.289153689028725
Validation loss: 3.124034166286383

Epoch: 6| Step: 12
Training loss: 3.6838455195060056
Validation loss: 3.1240046673692414

Epoch: 6| Step: 13
Training loss: 2.2663998035337913
Validation loss: 3.119465006242295

Epoch: 30| Step: 0
Training loss: 4.232775171283583
Validation loss: 3.1199203692832005

Epoch: 6| Step: 1
Training loss: 3.1182177378033695
Validation loss: 3.1182194774708742

Epoch: 6| Step: 2
Training loss: 2.6830113207862247
Validation loss: 3.1172421872308296

Epoch: 6| Step: 3
Training loss: 3.543105083900149
Validation loss: 3.1155798378304653

Epoch: 6| Step: 4
Training loss: 2.7759707634455366
Validation loss: 3.115520924831966

Epoch: 6| Step: 5
Training loss: 3.3663278000004193
Validation loss: 3.1169079350327786

Epoch: 6| Step: 6
Training loss: 4.222258288803878
Validation loss: 3.116800433105748

Epoch: 6| Step: 7
Training loss: 3.473344114681017
Validation loss: 3.114305545904105

Epoch: 6| Step: 8
Training loss: 3.4201393777209006
Validation loss: 3.111845732776885

Epoch: 6| Step: 9
Training loss: 2.7849492535171136
Validation loss: 3.1142746797144483

Epoch: 6| Step: 10
Training loss: 3.615268140374465
Validation loss: 3.1151009378970747

Epoch: 6| Step: 11
Training loss: 3.3363411366609053
Validation loss: 3.112546689422599

Epoch: 6| Step: 12
Training loss: 3.319819299307375
Validation loss: 3.111834823563603

Epoch: 6| Step: 13
Training loss: 2.6638550439867283
Validation loss: 3.1095935672365718

Epoch: 31| Step: 0
Training loss: 3.321969657690481
Validation loss: 3.1073512520629456

Epoch: 6| Step: 1
Training loss: 3.896704768398934
Validation loss: 3.1062226694774506

Epoch: 6| Step: 2
Training loss: 3.910208809391697
Validation loss: 3.1085106339847943

Epoch: 6| Step: 3
Training loss: 3.452533101579894
Validation loss: 3.1063618473762196

Epoch: 6| Step: 4
Training loss: 3.872708904623317
Validation loss: 3.106356220563072

Epoch: 6| Step: 5
Training loss: 2.8902455673691927
Validation loss: 3.1057544310875103

Epoch: 6| Step: 6
Training loss: 2.5148302801363407
Validation loss: 3.1028093876659786

Epoch: 6| Step: 7
Training loss: 3.1100463142503565
Validation loss: 3.101591122134267

Epoch: 6| Step: 8
Training loss: 3.1855346005856413
Validation loss: 3.105396941743919

Epoch: 6| Step: 9
Training loss: 2.9510343710210756
Validation loss: 3.107158619392644

Epoch: 6| Step: 10
Training loss: 3.2930579484508726
Validation loss: 3.106654508486719

Epoch: 6| Step: 11
Training loss: 3.5706049759682434
Validation loss: 3.1041580654855676

Epoch: 6| Step: 12
Training loss: 3.378570928086797
Validation loss: 3.1092916811298745

Epoch: 6| Step: 13
Training loss: 3.6413561696617234
Validation loss: 3.108297425859703

Epoch: 32| Step: 0
Training loss: 2.5778160141250273
Validation loss: 3.103592695605576

Epoch: 6| Step: 1
Training loss: 2.86496109754637
Validation loss: 3.099011372854881

Epoch: 6| Step: 2
Training loss: 3.8414878080910153
Validation loss: 3.096956562048366

Epoch: 6| Step: 3
Training loss: 3.7745718504777392
Validation loss: 3.094952901858604

Epoch: 6| Step: 4
Training loss: 3.2813714867763015
Validation loss: 3.093474901981755

Epoch: 6| Step: 5
Training loss: 3.767458141071585
Validation loss: 3.0938798022227654

Epoch: 6| Step: 6
Training loss: 3.2701543763376932
Validation loss: 3.09275830150847

Epoch: 6| Step: 7
Training loss: 3.485470449910908
Validation loss: 3.0939289843792177

Epoch: 6| Step: 8
Training loss: 3.8644802905772164
Validation loss: 3.093209496320558

Epoch: 6| Step: 9
Training loss: 3.5885470998840097
Validation loss: 3.090760934195812

Epoch: 6| Step: 10
Training loss: 3.1322661801058143
Validation loss: 3.090780190714467

Epoch: 6| Step: 11
Training loss: 2.8789628953679265
Validation loss: 3.09021713435761

Epoch: 6| Step: 12
Training loss: 3.5112434719048093
Validation loss: 3.0884297768140554

Epoch: 6| Step: 13
Training loss: 2.323126117746055
Validation loss: 3.0854026171998976

Epoch: 33| Step: 0
Training loss: 3.504314760275811
Validation loss: 3.086797715784505

Epoch: 6| Step: 1
Training loss: 3.070080309137405
Validation loss: 3.0874943635890846

Epoch: 6| Step: 2
Training loss: 3.466073868269794
Validation loss: 3.099776496266335

Epoch: 6| Step: 3
Training loss: 4.016897274588884
Validation loss: 3.0906874354999965

Epoch: 6| Step: 4
Training loss: 3.186587034637731
Validation loss: 3.0913229643448945

Epoch: 6| Step: 5
Training loss: 2.088182248766841
Validation loss: 3.0812401277816237

Epoch: 6| Step: 6
Training loss: 3.9855237314639718
Validation loss: 3.082915998438663

Epoch: 6| Step: 7
Training loss: 3.3213081572425964
Validation loss: 3.080000131386247

Epoch: 6| Step: 8
Training loss: 3.72179422875432
Validation loss: 3.0818244337224527

Epoch: 6| Step: 9
Training loss: 3.0586311659588836
Validation loss: 3.080608909211949

Epoch: 6| Step: 10
Training loss: 2.9255577990126547
Validation loss: 3.081004029245561

Epoch: 6| Step: 11
Training loss: 2.5040523111528135
Validation loss: 3.0795791112186683

Epoch: 6| Step: 12
Training loss: 4.136402438626752
Validation loss: 3.079357417912363

Epoch: 6| Step: 13
Training loss: 3.288294614192372
Validation loss: 3.0771893168679267

Epoch: 34| Step: 0
Training loss: 3.0156423933881493
Validation loss: 3.077396308027261

Epoch: 6| Step: 1
Training loss: 3.977056146645015
Validation loss: 3.0756848069366285

Epoch: 6| Step: 2
Training loss: 2.8908183265165297
Validation loss: 3.075998022294351

Epoch: 6| Step: 3
Training loss: 3.667093483329613
Validation loss: 3.0761538287921124

Epoch: 6| Step: 4
Training loss: 2.991943030666674
Validation loss: 3.0754303948545085

Epoch: 6| Step: 5
Training loss: 3.6154490963044617
Validation loss: 3.073972933382719

Epoch: 6| Step: 6
Training loss: 2.8637914684395285
Validation loss: 3.071904524686094

Epoch: 6| Step: 7
Training loss: 4.015366126596083
Validation loss: 3.071817228435212

Epoch: 6| Step: 8
Training loss: 3.378769359130947
Validation loss: 3.070853354704521

Epoch: 6| Step: 9
Training loss: 3.1943922139933427
Validation loss: 3.0697274492811917

Epoch: 6| Step: 10
Training loss: 3.382987848190688
Validation loss: 3.0703302916405546

Epoch: 6| Step: 11
Training loss: 3.3404052262413444
Validation loss: 3.068411072494413

Epoch: 6| Step: 12
Training loss: 2.995734838600634
Validation loss: 3.0667820941750783

Epoch: 6| Step: 13
Training loss: 3.1258031194561124
Validation loss: 3.067049423953934

Epoch: 35| Step: 0
Training loss: 3.61399776468382
Validation loss: 3.0648158602567888

Epoch: 6| Step: 1
Training loss: 3.1791907819947376
Validation loss: 3.0654370553567634

Epoch: 6| Step: 2
Training loss: 2.6706178618910847
Validation loss: 3.0654399606792957

Epoch: 6| Step: 3
Training loss: 3.004437502549533
Validation loss: 3.0664748781465727

Epoch: 6| Step: 4
Training loss: 3.60451282463274
Validation loss: 3.0761569856777187

Epoch: 6| Step: 5
Training loss: 3.5553577503839655
Validation loss: 3.083313058610777

Epoch: 6| Step: 6
Training loss: 3.7299978228606143
Validation loss: 3.079914444671497

Epoch: 6| Step: 7
Training loss: 3.140210935711829
Validation loss: 3.064589088620639

Epoch: 6| Step: 8
Training loss: 3.149800273073502
Validation loss: 3.0601600235845363

Epoch: 6| Step: 9
Training loss: 3.541573616750233
Validation loss: 3.060349533736517

Epoch: 6| Step: 10
Training loss: 3.168444803502083
Validation loss: 3.057948470619195

Epoch: 6| Step: 11
Training loss: 2.9018450753983696
Validation loss: 3.059391598109315

Epoch: 6| Step: 12
Training loss: 3.565584687682942
Validation loss: 3.0571595892408667

Epoch: 6| Step: 13
Training loss: 3.7565340972453702
Validation loss: 3.0581819799345853

Epoch: 36| Step: 0
Training loss: 3.4257677484679068
Validation loss: 3.0569927395557523

Epoch: 6| Step: 1
Training loss: 3.8794298999823353
Validation loss: 3.055358569624774

Epoch: 6| Step: 2
Training loss: 2.9005852733506243
Validation loss: 3.0541158950745175

Epoch: 6| Step: 3
Training loss: 3.4657204259697414
Validation loss: 3.0548219680825492

Epoch: 6| Step: 4
Training loss: 3.7216288218529376
Validation loss: 3.053745196296056

Epoch: 6| Step: 5
Training loss: 3.4575848669530322
Validation loss: 3.0532912293353327

Epoch: 6| Step: 6
Training loss: 2.5273715788592965
Validation loss: 3.052365645112755

Epoch: 6| Step: 7
Training loss: 3.044790014283268
Validation loss: 3.051235550909584

Epoch: 6| Step: 8
Training loss: 4.3203999129380195
Validation loss: 3.051029701447379

Epoch: 6| Step: 9
Training loss: 2.315673712296551
Validation loss: 3.048606983993385

Epoch: 6| Step: 10
Training loss: 3.150638539823025
Validation loss: 3.0480533388007167

Epoch: 6| Step: 11
Training loss: 3.569231600090962
Validation loss: 3.0477783496297532

Epoch: 6| Step: 12
Training loss: 3.489494770501445
Validation loss: 3.045442443077879

Epoch: 6| Step: 13
Training loss: 2.162812681138861
Validation loss: 3.0452788070483097

Epoch: 37| Step: 0
Training loss: 3.2101054726263656
Validation loss: 3.0447130768966857

Epoch: 6| Step: 1
Training loss: 2.9477810418480392
Validation loss: 3.047347592034539

Epoch: 6| Step: 2
Training loss: 2.4173855424865414
Validation loss: 3.0486857689561124

Epoch: 6| Step: 3
Training loss: 3.0135685525365776
Validation loss: 3.0545272430528616

Epoch: 6| Step: 4
Training loss: 3.514921804673434
Validation loss: 3.05377004224577

Epoch: 6| Step: 5
Training loss: 3.4830358010094127
Validation loss: 3.0464806574178396

Epoch: 6| Step: 6
Training loss: 3.6356775286773297
Validation loss: 3.0413224001147463

Epoch: 6| Step: 7
Training loss: 2.503415921148836
Validation loss: 3.0410634576465942

Epoch: 6| Step: 8
Training loss: 3.249983714136254
Validation loss: 3.04240585719824

Epoch: 6| Step: 9
Training loss: 3.2850378062774066
Validation loss: 3.0425680215409954

Epoch: 6| Step: 10
Training loss: 4.252927781464843
Validation loss: 3.040263460966885

Epoch: 6| Step: 11
Training loss: 3.667016894057914
Validation loss: 3.040820378394768

Epoch: 6| Step: 12
Training loss: 3.544292972148933
Validation loss: 3.0398586702417205

Epoch: 6| Step: 13
Training loss: 3.3077302096315946
Validation loss: 3.037932328800451

Epoch: 38| Step: 0
Training loss: 2.9227856527608833
Validation loss: 3.0365317898690805

Epoch: 6| Step: 1
Training loss: 3.6991164002967434
Validation loss: 3.0370608427682533

Epoch: 6| Step: 2
Training loss: 3.4197475839903753
Validation loss: 3.0364376105330635

Epoch: 6| Step: 3
Training loss: 3.2859982966060484
Validation loss: 3.036301467049897

Epoch: 6| Step: 4
Training loss: 3.070323526687817
Validation loss: 3.035118404436544

Epoch: 6| Step: 5
Training loss: 3.7123446396709787
Validation loss: 3.033764831898

Epoch: 6| Step: 6
Training loss: 3.3781181342437168
Validation loss: 3.0342024259154434

Epoch: 6| Step: 7
Training loss: 3.767940584884627
Validation loss: 3.0324189621881956

Epoch: 6| Step: 8
Training loss: 3.2816129937794893
Validation loss: 3.0327201435331146

Epoch: 6| Step: 9
Training loss: 3.352570211086365
Validation loss: 3.0306353794304095

Epoch: 6| Step: 10
Training loss: 2.2447433525485794
Validation loss: 3.03076313770225

Epoch: 6| Step: 11
Training loss: 3.396541513814592
Validation loss: 3.0295213295511547

Epoch: 6| Step: 12
Training loss: 3.2046863751197896
Validation loss: 3.029797762530175

Epoch: 6| Step: 13
Training loss: 3.2420092430288916
Validation loss: 3.0274874398185783

Epoch: 39| Step: 0
Training loss: 3.5403557239836436
Validation loss: 3.0270739215132316

Epoch: 6| Step: 1
Training loss: 2.498987851293861
Validation loss: 3.0254118465871787

Epoch: 6| Step: 2
Training loss: 3.1422294200375336
Validation loss: 3.0263127149853184

Epoch: 6| Step: 3
Training loss: 3.841984289007119
Validation loss: 3.034217448452263

Epoch: 6| Step: 4
Training loss: 3.218952357773599
Validation loss: 3.0417761137506836

Epoch: 6| Step: 5
Training loss: 2.9714996453839753
Validation loss: 3.0446530317827163

Epoch: 6| Step: 6
Training loss: 3.181982163749112
Validation loss: 3.0568057301893887

Epoch: 6| Step: 7
Training loss: 3.5521727669085577
Validation loss: 3.0615893632582867

Epoch: 6| Step: 8
Training loss: 3.9573045430982656
Validation loss: 3.0390226093317416

Epoch: 6| Step: 9
Training loss: 2.7473654698627006
Validation loss: 3.0270536906058494

Epoch: 6| Step: 10
Training loss: 2.6645219244503253
Validation loss: 3.0176670795033966

Epoch: 6| Step: 11
Training loss: 3.4086337366759816
Validation loss: 3.0183000244196942

Epoch: 6| Step: 12
Training loss: 3.7496073199351074
Validation loss: 3.0197750666441463

Epoch: 6| Step: 13
Training loss: 3.4166721871184125
Validation loss: 3.020312881756172

Epoch: 40| Step: 0
Training loss: 3.469434241089903
Validation loss: 3.017987944517789

Epoch: 6| Step: 1
Training loss: 2.9752045184448592
Validation loss: 3.015883188843227

Epoch: 6| Step: 2
Training loss: 3.3698603737541757
Validation loss: 3.012495354007295

Epoch: 6| Step: 3
Training loss: 2.8613726199078817
Validation loss: 3.0152328485319235

Epoch: 6| Step: 4
Training loss: 3.129445080788585
Validation loss: 3.0131340861033595

Epoch: 6| Step: 5
Training loss: 3.2367094157178946
Validation loss: 3.0129013977335966

Epoch: 6| Step: 6
Training loss: 3.0495618661839923
Validation loss: 3.01395933164916

Epoch: 6| Step: 7
Training loss: 3.502664913893911
Validation loss: 3.0113619341409517

Epoch: 6| Step: 8
Training loss: 3.653026888193107
Validation loss: 3.012936175013531

Epoch: 6| Step: 9
Training loss: 3.63977093153979
Validation loss: 3.011024687624049

Epoch: 6| Step: 10
Training loss: 3.1946997019928314
Validation loss: 3.0116714923489316

Epoch: 6| Step: 11
Training loss: 3.335999821029402
Validation loss: 3.0100808926994143

Epoch: 6| Step: 12
Training loss: 3.143699090443047
Validation loss: 3.0096656352720976

Epoch: 6| Step: 13
Training loss: 3.4830675623011804
Validation loss: 3.009370691027605

Epoch: 41| Step: 0
Training loss: 2.4395201699028424
Validation loss: 3.007067492446018

Epoch: 6| Step: 1
Training loss: 3.0704637640656873
Validation loss: 3.0071645864816805

Epoch: 6| Step: 2
Training loss: 3.379807756588617
Validation loss: 3.008846510613668

Epoch: 6| Step: 3
Training loss: 2.9958199944196986
Validation loss: 3.00928607541331

Epoch: 6| Step: 4
Training loss: 3.4432992740607182
Validation loss: 3.0120810320398714

Epoch: 6| Step: 5
Training loss: 3.644186218218575
Validation loss: 3.0130454010733403

Epoch: 6| Step: 6
Training loss: 3.26367377435799
Validation loss: 3.0177721280249314

Epoch: 6| Step: 7
Training loss: 3.4998185246967517
Validation loss: 3.020887186138285

Epoch: 6| Step: 8
Training loss: 3.750715696067492
Validation loss: 3.017055579568561

Epoch: 6| Step: 9
Training loss: 3.5546968900116362
Validation loss: 3.0164710431896546

Epoch: 6| Step: 10
Training loss: 2.9797848858094174
Validation loss: 3.007812015878068

Epoch: 6| Step: 11
Training loss: 3.7940096620186305
Validation loss: 3.0054428109489244

Epoch: 6| Step: 12
Training loss: 2.8766299064235348
Validation loss: 3.001067328041249

Epoch: 6| Step: 13
Training loss: 2.826362861765486
Validation loss: 2.997885071353519

Epoch: 42| Step: 0
Training loss: 3.5758367826263946
Validation loss: 2.9987548240241155

Epoch: 6| Step: 1
Training loss: 3.713292452817166
Validation loss: 2.996859621033771

Epoch: 6| Step: 2
Training loss: 3.2639328072120475
Validation loss: 2.998978399844399

Epoch: 6| Step: 3
Training loss: 3.4209186489108188
Validation loss: 2.9961526086321326

Epoch: 6| Step: 4
Training loss: 3.2584345015668146
Validation loss: 2.996381553163019

Epoch: 6| Step: 5
Training loss: 3.25859108089977
Validation loss: 2.9947070254883923

Epoch: 6| Step: 6
Training loss: 3.1139149708883913
Validation loss: 2.9940074902319673

Epoch: 6| Step: 7
Training loss: 3.3665892740047383
Validation loss: 2.996102809725187

Epoch: 6| Step: 8
Training loss: 2.6476846260628086
Validation loss: 2.9910319407672445

Epoch: 6| Step: 9
Training loss: 3.1265648547787546
Validation loss: 2.9911531806749814

Epoch: 6| Step: 10
Training loss: 3.65698652103601
Validation loss: 2.9914235831203495

Epoch: 6| Step: 11
Training loss: 2.571597627350482
Validation loss: 2.989882101627151

Epoch: 6| Step: 12
Training loss: 3.259569019310742
Validation loss: 2.9893641123332277

Epoch: 6| Step: 13
Training loss: 3.4978680248108476
Validation loss: 2.9888424410676624

Epoch: 43| Step: 0
Training loss: 3.5221838232675613
Validation loss: 2.986508196825127

Epoch: 6| Step: 1
Training loss: 3.3600846361672247
Validation loss: 2.9871254017673428

Epoch: 6| Step: 2
Training loss: 3.2437253682812828
Validation loss: 2.9880186616088844

Epoch: 6| Step: 3
Training loss: 2.716998358138076
Validation loss: 2.9892302742663825

Epoch: 6| Step: 4
Training loss: 2.9489661910692253
Validation loss: 2.9907765627856566

Epoch: 6| Step: 5
Training loss: 2.9259051104456604
Validation loss: 2.9880899051576626

Epoch: 6| Step: 6
Training loss: 3.6837024854709486
Validation loss: 2.9834163882675164

Epoch: 6| Step: 7
Training loss: 2.589959741817119
Validation loss: 2.9818546601319085

Epoch: 6| Step: 8
Training loss: 2.947459119103955
Validation loss: 2.9818287876528204

Epoch: 6| Step: 9
Training loss: 2.9508280222415033
Validation loss: 2.980755333692609

Epoch: 6| Step: 10
Training loss: 3.2902235577815473
Validation loss: 2.980744384196517

Epoch: 6| Step: 11
Training loss: 3.8661918206066272
Validation loss: 2.980030588261583

Epoch: 6| Step: 12
Training loss: 3.916964675171392
Validation loss: 2.980319484989421

Epoch: 6| Step: 13
Training loss: 3.432478687862017
Validation loss: 2.9800515960605978

Epoch: 44| Step: 0
Training loss: 2.8915433507417365
Validation loss: 2.9776654725479403

Epoch: 6| Step: 1
Training loss: 3.2283174115840163
Validation loss: 2.9762460539707414

Epoch: 6| Step: 2
Training loss: 2.985434458950892
Validation loss: 2.9764450076322504

Epoch: 6| Step: 3
Training loss: 1.9473661436960246
Validation loss: 2.973821644452084

Epoch: 6| Step: 4
Training loss: 3.7632664302243493
Validation loss: 2.9740809470703953

Epoch: 6| Step: 5
Training loss: 3.591473994799665
Validation loss: 2.9733615163828286

Epoch: 6| Step: 6
Training loss: 3.7234809338289088
Validation loss: 2.973722131530238

Epoch: 6| Step: 7
Training loss: 3.144009261314205
Validation loss: 2.9712517965801775

Epoch: 6| Step: 8
Training loss: 3.621592268222774
Validation loss: 2.971648032619008

Epoch: 6| Step: 9
Training loss: 3.6601935092653988
Validation loss: 2.9776588715866437

Epoch: 6| Step: 10
Training loss: 3.4499184750862173
Validation loss: 2.986257885048179

Epoch: 6| Step: 11
Training loss: 2.970667490848904
Validation loss: 2.978142747756311

Epoch: 6| Step: 12
Training loss: 2.4451285101071316
Validation loss: 2.970982066640769

Epoch: 6| Step: 13
Training loss: 3.8989445847718933
Validation loss: 2.9704195514660845

Epoch: 45| Step: 0
Training loss: 2.719836401647587
Validation loss: 2.967129557939675

Epoch: 6| Step: 1
Training loss: 3.71361064802235
Validation loss: 2.968056009260491

Epoch: 6| Step: 2
Training loss: 3.859804446153824
Validation loss: 2.9672721858959124

Epoch: 6| Step: 3
Training loss: 3.1484102385218633
Validation loss: 2.965961609212959

Epoch: 6| Step: 4
Training loss: 2.7035929544934136
Validation loss: 2.966368187274045

Epoch: 6| Step: 5
Training loss: 3.8820812373360205
Validation loss: 2.9649994721566353

Epoch: 6| Step: 6
Training loss: 3.2928314723387544
Validation loss: 2.9626696847337595

Epoch: 6| Step: 7
Training loss: 3.1015046928649457
Validation loss: 2.9630895894419744

Epoch: 6| Step: 8
Training loss: 3.217972893097524
Validation loss: 2.962533272571566

Epoch: 6| Step: 9
Training loss: 3.013015487696929
Validation loss: 2.962148072313216

Epoch: 6| Step: 10
Training loss: 3.7157439576172813
Validation loss: 2.960323115774649

Epoch: 6| Step: 11
Training loss: 2.987557676389023
Validation loss: 2.960617738655565

Epoch: 6| Step: 12
Training loss: 2.7930462593047416
Validation loss: 2.96017193597818

Epoch: 6| Step: 13
Training loss: 2.73874667969663
Validation loss: 2.958969693083341

Epoch: 46| Step: 0
Training loss: 3.9466389758410183
Validation loss: 2.9609313266928003

Epoch: 6| Step: 1
Training loss: 3.4636839567321993
Validation loss: 2.9597494796356765

Epoch: 6| Step: 2
Training loss: 3.420432705638108
Validation loss: 2.9609873206289055

Epoch: 6| Step: 3
Training loss: 2.666583616235022
Validation loss: 2.9659582330445047

Epoch: 6| Step: 4
Training loss: 3.3974975689225975
Validation loss: 2.969596727363746

Epoch: 6| Step: 5
Training loss: 3.208440324725049
Validation loss: 2.96723666087493

Epoch: 6| Step: 6
Training loss: 2.2703910420241735
Validation loss: 2.9586378983833703

Epoch: 6| Step: 7
Training loss: 3.4241152880680645
Validation loss: 2.9562657653267506

Epoch: 6| Step: 8
Training loss: 3.3858345751924808
Validation loss: 2.9551054592402966

Epoch: 6| Step: 9
Training loss: 3.10920906582601
Validation loss: 2.9551239184715565

Epoch: 6| Step: 10
Training loss: 2.9925320180456416
Validation loss: 2.9535913905919853

Epoch: 6| Step: 11
Training loss: 3.2327148304746736
Validation loss: 2.952430134200057

Epoch: 6| Step: 12
Training loss: 3.3037029991313878
Validation loss: 2.950725849399376

Epoch: 6| Step: 13
Training loss: 3.2124408998507943
Validation loss: 2.950464322169739

Epoch: 47| Step: 0
Training loss: 2.965550837177353
Validation loss: 2.9508753898589415

Epoch: 6| Step: 1
Training loss: 3.291588182761109
Validation loss: 2.9476245152842453

Epoch: 6| Step: 2
Training loss: 3.431451643558463
Validation loss: 2.947666249904109

Epoch: 6| Step: 3
Training loss: 2.959397854258538
Validation loss: 2.9487082671089078

Epoch: 6| Step: 4
Training loss: 3.0236988201123034
Validation loss: 2.945255193138946

Epoch: 6| Step: 5
Training loss: 3.072592939146014
Validation loss: 2.9469865019713826

Epoch: 6| Step: 6
Training loss: 3.549766403894318
Validation loss: 2.946468663068284

Epoch: 6| Step: 7
Training loss: 3.5837717601273833
Validation loss: 2.947173121604355

Epoch: 6| Step: 8
Training loss: 2.661015264032245
Validation loss: 2.9449397008083533

Epoch: 6| Step: 9
Training loss: 3.1691847042185985
Validation loss: 2.9442028232354946

Epoch: 6| Step: 10
Training loss: 4.145978123166874
Validation loss: 2.943606808024094

Epoch: 6| Step: 11
Training loss: 3.4421385939522517
Validation loss: 2.9424153947234952

Epoch: 6| Step: 12
Training loss: 2.218307450982059
Validation loss: 2.942059242969261

Epoch: 6| Step: 13
Training loss: 3.3509570733135243
Validation loss: 2.9432475070965998

Epoch: 48| Step: 0
Training loss: 2.7926691067957314
Validation loss: 2.9407690844377274

Epoch: 6| Step: 1
Training loss: 3.476583622214627
Validation loss: 2.9430212750524527

Epoch: 6| Step: 2
Training loss: 3.232864248194381
Validation loss: 2.9443956836280583

Epoch: 6| Step: 3
Training loss: 3.044753994329645
Validation loss: 2.944588642829287

Epoch: 6| Step: 4
Training loss: 3.7201008627148773
Validation loss: 2.9471723378565313

Epoch: 6| Step: 5
Training loss: 3.023978882256699
Validation loss: 2.948462682933025

Epoch: 6| Step: 6
Training loss: 3.6350909563567084
Validation loss: 2.9476034164026084

Epoch: 6| Step: 7
Training loss: 2.756308688622357
Validation loss: 2.9400862333894033

Epoch: 6| Step: 8
Training loss: 3.0606578035098186
Validation loss: 2.937089462409927

Epoch: 6| Step: 9
Training loss: 3.7166690934747777
Validation loss: 2.9370343815219644

Epoch: 6| Step: 10
Training loss: 3.151377627955668
Validation loss: 2.9352958087749186

Epoch: 6| Step: 11
Training loss: 2.7540890896750576
Validation loss: 2.934318140518611

Epoch: 6| Step: 12
Training loss: 3.4330154296457143
Validation loss: 2.9339197630704983

Epoch: 6| Step: 13
Training loss: 3.1076185930229836
Validation loss: 2.934333726840639

Epoch: 49| Step: 0
Training loss: 2.8246271410617987
Validation loss: 2.934328572180521

Epoch: 6| Step: 1
Training loss: 3.065236639996933
Validation loss: 2.932174256824227

Epoch: 6| Step: 2
Training loss: 2.6459708190600635
Validation loss: 2.9320622375908507

Epoch: 6| Step: 3
Training loss: 3.1582479668372683
Validation loss: 2.931757405048209

Epoch: 6| Step: 4
Training loss: 3.526195047593351
Validation loss: 2.9300269740595217

Epoch: 6| Step: 5
Training loss: 3.9235667193366837
Validation loss: 2.929181152339673

Epoch: 6| Step: 6
Training loss: 2.873609953160455
Validation loss: 2.930079824341701

Epoch: 6| Step: 7
Training loss: 2.8796718619755635
Validation loss: 2.9287711091640434

Epoch: 6| Step: 8
Training loss: 2.947847686787272
Validation loss: 2.9269942397541784

Epoch: 6| Step: 9
Training loss: 3.3670094878898884
Validation loss: 2.9269258893770433

Epoch: 6| Step: 10
Training loss: 3.1947958232370426
Validation loss: 2.9272833630164268

Epoch: 6| Step: 11
Training loss: 3.280487989317913
Validation loss: 2.926789570991879

Epoch: 6| Step: 12
Training loss: 3.2100915095990645
Validation loss: 2.928395790088983

Epoch: 6| Step: 13
Training loss: 4.326196784987539
Validation loss: 2.9262369501623184

Epoch: 50| Step: 0
Training loss: 3.1747108147552936
Validation loss: 2.9279972775375636

Epoch: 6| Step: 1
Training loss: 3.185545228434967
Validation loss: 2.92443363788086

Epoch: 6| Step: 2
Training loss: 3.065573104123611
Validation loss: 2.925666791837857

Epoch: 6| Step: 3
Training loss: 3.9988406408542048
Validation loss: 2.9239647743400847

Epoch: 6| Step: 4
Training loss: 2.4597081580377145
Validation loss: 2.920279506339677

Epoch: 6| Step: 5
Training loss: 3.253895991974377
Validation loss: 2.9179827438339396

Epoch: 6| Step: 6
Training loss: 3.1737584126959324
Validation loss: 2.918148200369833

Epoch: 6| Step: 7
Training loss: 3.8439137493702504
Validation loss: 2.918278116854605

Epoch: 6| Step: 8
Training loss: 3.3846527802795663
Validation loss: 2.915050031020547

Epoch: 6| Step: 9
Training loss: 3.1281367009236547
Validation loss: 2.9180248786799474

Epoch: 6| Step: 10
Training loss: 2.7793167767646545
Validation loss: 2.91658182387

Epoch: 6| Step: 11
Training loss: 2.8948616940892484
Validation loss: 2.9169149764814564

Epoch: 6| Step: 12
Training loss: 3.3051440056665244
Validation loss: 2.9157106499832905

Epoch: 6| Step: 13
Training loss: 2.7570213501456045
Validation loss: 2.913481247075728

Epoch: 51| Step: 0
Training loss: 3.1303728835809306
Validation loss: 2.9129648921227456

Epoch: 6| Step: 1
Training loss: 2.867049959714093
Validation loss: 2.9219307404187638

Epoch: 6| Step: 2
Training loss: 3.5940211981571193
Validation loss: 2.92761707545005

Epoch: 6| Step: 3
Training loss: 3.179103188403851
Validation loss: 2.9194775784840794

Epoch: 6| Step: 4
Training loss: 2.5459343981205977
Validation loss: 2.9152721663402645

Epoch: 6| Step: 5
Training loss: 3.0454376743009792
Validation loss: 2.9121160849287477

Epoch: 6| Step: 6
Training loss: 2.309836425934788
Validation loss: 2.9087136498035826

Epoch: 6| Step: 7
Training loss: 2.9719264654763466
Validation loss: 2.9115508737312052

Epoch: 6| Step: 8
Training loss: 3.725749248959931
Validation loss: 2.912437527161833

Epoch: 6| Step: 9
Training loss: 3.6132482578730265
Validation loss: 2.9168255676253043

Epoch: 6| Step: 10
Training loss: 3.538895154621746
Validation loss: 2.925067590423909

Epoch: 6| Step: 11
Training loss: 3.743788470291895
Validation loss: 2.9196019364117816

Epoch: 6| Step: 12
Training loss: 2.7683463635521712
Validation loss: 2.919113566955616

Epoch: 6| Step: 13
Training loss: 3.6885801123520765
Validation loss: 2.9245637607810275

Epoch: 52| Step: 0
Training loss: 3.8008020759160934
Validation loss: 2.917330534192945

Epoch: 6| Step: 1
Training loss: 2.887689533040801
Validation loss: 2.9093791053115354

Epoch: 6| Step: 2
Training loss: 3.5710724871095683
Validation loss: 2.907892174944032

Epoch: 6| Step: 3
Training loss: 3.2955135770670556
Validation loss: 2.9072960188364303

Epoch: 6| Step: 4
Training loss: 3.2086003840554134
Validation loss: 2.9073717111794393

Epoch: 6| Step: 5
Training loss: 3.1391541941852115
Validation loss: 2.905462847565967

Epoch: 6| Step: 6
Training loss: 3.303018206960521
Validation loss: 2.903846253873846

Epoch: 6| Step: 7
Training loss: 2.688838802699611
Validation loss: 2.903208458585421

Epoch: 6| Step: 8
Training loss: 2.998812440426451
Validation loss: 2.901340469157418

Epoch: 6| Step: 9
Training loss: 3.1583689007396174
Validation loss: 2.90328117312684

Epoch: 6| Step: 10
Training loss: 3.2221393702440704
Validation loss: 2.9060969740811053

Epoch: 6| Step: 11
Training loss: 3.4289346967982968
Validation loss: 2.9012612696244693

Epoch: 6| Step: 12
Training loss: 3.116999646791078
Validation loss: 2.8992002073129886

Epoch: 6| Step: 13
Training loss: 2.3263841303180466
Validation loss: 2.901564132919072

Epoch: 53| Step: 0
Training loss: 3.327823822291666
Validation loss: 2.9315794060024594

Epoch: 6| Step: 1
Training loss: 2.8073892570523227
Validation loss: 2.960165274356361

Epoch: 6| Step: 2
Training loss: 3.274424547496634
Validation loss: 2.9530809360873005

Epoch: 6| Step: 3
Training loss: 2.3440641065560754
Validation loss: 2.9347315274579695

Epoch: 6| Step: 4
Training loss: 3.117132430199645
Validation loss: 2.909321435188282

Epoch: 6| Step: 5
Training loss: 3.2110666959067546
Validation loss: 2.894214320666543

Epoch: 6| Step: 6
Training loss: 3.22973742619475
Validation loss: 2.892123047081522

Epoch: 6| Step: 7
Training loss: 3.352358565678925
Validation loss: 2.8942159301305366

Epoch: 6| Step: 8
Training loss: 3.3348968812479236
Validation loss: 2.8964017350190616

Epoch: 6| Step: 9
Training loss: 3.648735475318491
Validation loss: 2.8991284895746636

Epoch: 6| Step: 10
Training loss: 2.776421287779707
Validation loss: 2.89249062634822

Epoch: 6| Step: 11
Training loss: 3.601354233022148
Validation loss: 2.88947111832889

Epoch: 6| Step: 12
Training loss: 3.1137039491118683
Validation loss: 2.8862719857210917

Epoch: 6| Step: 13
Training loss: 3.5263924736441106
Validation loss: 2.886649020574772

Epoch: 54| Step: 0
Training loss: 3.058109951609859
Validation loss: 2.8847865107397586

Epoch: 6| Step: 1
Training loss: 3.3907597246959447
Validation loss: 2.886527100156811

Epoch: 6| Step: 2
Training loss: 3.0864368662418604
Validation loss: 2.887897841948201

Epoch: 6| Step: 3
Training loss: 2.7932108314012436
Validation loss: 2.888507526642479

Epoch: 6| Step: 4
Training loss: 3.6841269114334727
Validation loss: 2.89020519716936

Epoch: 6| Step: 5
Training loss: 2.6766995601446046
Validation loss: 2.889153448465442

Epoch: 6| Step: 6
Training loss: 3.214331992890974
Validation loss: 2.889201194561858

Epoch: 6| Step: 7
Training loss: 2.9344716796548385
Validation loss: 2.8879974018680117

Epoch: 6| Step: 8
Training loss: 3.2996496303555425
Validation loss: 2.886560281770546

Epoch: 6| Step: 9
Training loss: 2.79262735907978
Validation loss: 2.8830158873212457

Epoch: 6| Step: 10
Training loss: 3.8477132570332744
Validation loss: 2.881449684550032

Epoch: 6| Step: 11
Training loss: 3.7646369112582954
Validation loss: 2.8805437742527733

Epoch: 6| Step: 12
Training loss: 3.1905269835657757
Validation loss: 2.87699498659049

Epoch: 6| Step: 13
Training loss: 1.8215133569789461
Validation loss: 2.8755182438495144

Epoch: 55| Step: 0
Training loss: 3.5358412611098777
Validation loss: 2.875989952162783

Epoch: 6| Step: 1
Training loss: 3.1755869525626492
Validation loss: 2.8811180981617075

Epoch: 6| Step: 2
Training loss: 3.5014528256509165
Validation loss: 2.876129915467391

Epoch: 6| Step: 3
Training loss: 3.565557940936563
Validation loss: 2.87478374186822

Epoch: 6| Step: 4
Training loss: 3.0105055605601487
Validation loss: 2.8713569190680563

Epoch: 6| Step: 5
Training loss: 2.3114072950200013
Validation loss: 2.8710475252409573

Epoch: 6| Step: 6
Training loss: 3.01940554496588
Validation loss: 2.871342493537911

Epoch: 6| Step: 7
Training loss: 3.6424049315813187
Validation loss: 2.8714236517148914

Epoch: 6| Step: 8
Training loss: 3.1835053788540053
Validation loss: 2.8722866508658056

Epoch: 6| Step: 9
Training loss: 3.506691122610392
Validation loss: 2.8801004110342414

Epoch: 6| Step: 10
Training loss: 3.070486748096995
Validation loss: 2.895640560617492

Epoch: 6| Step: 11
Training loss: 2.5997588632709308
Validation loss: 2.8911550810178994

Epoch: 6| Step: 12
Training loss: 2.9486924263903247
Validation loss: 2.8765973187714886

Epoch: 6| Step: 13
Training loss: 3.1373006202601568
Validation loss: 2.8713909098911055

Epoch: 56| Step: 0
Training loss: 3.1809124660734205
Validation loss: 2.87108719242997

Epoch: 6| Step: 1
Training loss: 3.150649436730298
Validation loss: 2.8694312480104784

Epoch: 6| Step: 2
Training loss: 2.581427660871121
Validation loss: 2.866632080107958

Epoch: 6| Step: 3
Training loss: 2.664098923957149
Validation loss: 2.864710462924384

Epoch: 6| Step: 4
Training loss: 3.957530345113619
Validation loss: 2.865487560999844

Epoch: 6| Step: 5
Training loss: 3.6508263684551503
Validation loss: 2.8647041789021346

Epoch: 6| Step: 6
Training loss: 3.6342599917818497
Validation loss: 2.864506425617541

Epoch: 6| Step: 7
Training loss: 2.6363593866798327
Validation loss: 2.865225604742255

Epoch: 6| Step: 8
Training loss: 3.104898729131767
Validation loss: 2.8673519098448526

Epoch: 6| Step: 9
Training loss: 3.548058400633597
Validation loss: 2.8640934595575445

Epoch: 6| Step: 10
Training loss: 2.76504510521961
Validation loss: 2.86761725679405

Epoch: 6| Step: 11
Training loss: 3.0561913108261303
Validation loss: 2.8676259875534544

Epoch: 6| Step: 12
Training loss: 3.1043307540502174
Validation loss: 2.8670863595055103

Epoch: 6| Step: 13
Training loss: 2.699996725716195
Validation loss: 2.8640311010712294

Epoch: 57| Step: 0
Training loss: 2.7566138410138694
Validation loss: 2.8730409572120403

Epoch: 6| Step: 1
Training loss: 3.3434342565038535
Validation loss: 2.8724216172227273

Epoch: 6| Step: 2
Training loss: 2.835412515435881
Validation loss: 2.8778180528934643

Epoch: 6| Step: 3
Training loss: 3.2092365298165673
Validation loss: 2.876600689310403

Epoch: 6| Step: 4
Training loss: 3.5984253035490634
Validation loss: 2.87653379825755

Epoch: 6| Step: 5
Training loss: 2.46243444055338
Validation loss: 2.8652666776265985

Epoch: 6| Step: 6
Training loss: 3.4055886282740166
Validation loss: 2.8572652084658468

Epoch: 6| Step: 7
Training loss: 2.80851284966391
Validation loss: 2.8568502785592464

Epoch: 6| Step: 8
Training loss: 3.28438338579002
Validation loss: 2.854268061381244

Epoch: 6| Step: 9
Training loss: 3.265923591360038
Validation loss: 2.8539066727720304

Epoch: 6| Step: 10
Training loss: 3.0019825106828657
Validation loss: 2.8547559853863307

Epoch: 6| Step: 11
Training loss: 3.4447710299424066
Validation loss: 2.8548462560695427

Epoch: 6| Step: 12
Training loss: 3.1698929931678714
Validation loss: 2.8525043419477973

Epoch: 6| Step: 13
Training loss: 3.750451632959939
Validation loss: 2.8542404027554484

Epoch: 58| Step: 0
Training loss: 2.6345336902467515
Validation loss: 2.854272972614048

Epoch: 6| Step: 1
Training loss: 3.0061810713576556
Validation loss: 2.8505911050922292

Epoch: 6| Step: 2
Training loss: 2.789257566325001
Validation loss: 2.8507505853691257

Epoch: 6| Step: 3
Training loss: 3.4036454908764333
Validation loss: 2.849995761300407

Epoch: 6| Step: 4
Training loss: 3.3297005089694105
Validation loss: 2.850887130613536

Epoch: 6| Step: 5
Training loss: 3.253474212577118
Validation loss: 2.8490654364952412

Epoch: 6| Step: 6
Training loss: 2.5602625871633307
Validation loss: 2.849511115732317

Epoch: 6| Step: 7
Training loss: 2.6904957951837365
Validation loss: 2.848792514893511

Epoch: 6| Step: 8
Training loss: 2.6747298130949755
Validation loss: 2.848782190272761

Epoch: 6| Step: 9
Training loss: 3.544029405131746
Validation loss: 2.8478461497264513

Epoch: 6| Step: 10
Training loss: 3.579311124279314
Validation loss: 2.848236513257508

Epoch: 6| Step: 11
Training loss: 3.1004263000242926
Validation loss: 2.8478421060101464

Epoch: 6| Step: 12
Training loss: 3.4217718796890684
Validation loss: 2.849798311560512

Epoch: 6| Step: 13
Training loss: 4.24660131654706
Validation loss: 2.8497940340225822

Epoch: 59| Step: 0
Training loss: 2.8036840657454856
Validation loss: 2.8489569420119447

Epoch: 6| Step: 1
Training loss: 2.6220637657041173
Validation loss: 2.849226249246475

Epoch: 6| Step: 2
Training loss: 3.1095073422585866
Validation loss: 2.8469512799200096

Epoch: 6| Step: 3
Training loss: 3.4234325748409917
Validation loss: 2.8481203159636514

Epoch: 6| Step: 4
Training loss: 3.5319658752209917
Validation loss: 2.854055936201489

Epoch: 6| Step: 5
Training loss: 3.4484341205257145
Validation loss: 2.8581460927366833

Epoch: 6| Step: 6
Training loss: 3.6803833127454744
Validation loss: 2.8585111470951183

Epoch: 6| Step: 7
Training loss: 3.848254657820606
Validation loss: 2.8517874572368216

Epoch: 6| Step: 8
Training loss: 3.0080442661315403
Validation loss: 2.841102629019571

Epoch: 6| Step: 9
Training loss: 3.701581931234285
Validation loss: 2.8425164137261296

Epoch: 6| Step: 10
Training loss: 2.3723111240465284
Validation loss: 2.8439966505224863

Epoch: 6| Step: 11
Training loss: 2.7400544393658453
Validation loss: 2.845049790365293

Epoch: 6| Step: 12
Training loss: 2.6937616724172955
Validation loss: 2.845306368150172

Epoch: 6| Step: 13
Training loss: 2.3662528531419547
Validation loss: 2.8438145655988034

Epoch: 60| Step: 0
Training loss: 2.3353088962032484
Validation loss: 2.8475560525242916

Epoch: 6| Step: 1
Training loss: 3.970227664790284
Validation loss: 2.8439723913550137

Epoch: 6| Step: 2
Training loss: 2.901837023606299
Validation loss: 2.8428623473307035

Epoch: 6| Step: 3
Training loss: 3.6298892493469292
Validation loss: 2.84339297457173

Epoch: 6| Step: 4
Training loss: 3.296440348967989
Validation loss: 2.8422923561734166

Epoch: 6| Step: 5
Training loss: 2.2416634296077156
Validation loss: 2.8414424840889274

Epoch: 6| Step: 6
Training loss: 3.3822401588934574
Validation loss: 2.838729934944053

Epoch: 6| Step: 7
Training loss: 3.1056092428420667
Validation loss: 2.8377494098509066

Epoch: 6| Step: 8
Training loss: 2.6980349736926685
Validation loss: 2.8369555371403807

Epoch: 6| Step: 9
Training loss: 3.4318718351961937
Validation loss: 2.835226244296654

Epoch: 6| Step: 10
Training loss: 2.5640464396325364
Validation loss: 2.832141313008894

Epoch: 6| Step: 11
Training loss: 3.8033856116894134
Validation loss: 2.8336136719659377

Epoch: 6| Step: 12
Training loss: 2.976805989876933
Validation loss: 2.832337910955308

Epoch: 6| Step: 13
Training loss: 3.135670868125813
Validation loss: 2.8308920781667064

Epoch: 61| Step: 0
Training loss: 2.546643205637823
Validation loss: 2.8304175212992004

Epoch: 6| Step: 1
Training loss: 2.8138055102627404
Validation loss: 2.8309355228296367

Epoch: 6| Step: 2
Training loss: 2.831837109455582
Validation loss: 2.8303846968573456

Epoch: 6| Step: 3
Training loss: 3.123688995022083
Validation loss: 2.8300893349343665

Epoch: 6| Step: 4
Training loss: 3.077117290236284
Validation loss: 2.8374585333540785

Epoch: 6| Step: 5
Training loss: 3.237621502455786
Validation loss: 2.8418738897101736

Epoch: 6| Step: 6
Training loss: 2.695384856648798
Validation loss: 2.847670769410748

Epoch: 6| Step: 7
Training loss: 3.2563378086075607
Validation loss: 2.8513305623678717

Epoch: 6| Step: 8
Training loss: 4.193519479069805
Validation loss: 2.847430089457

Epoch: 6| Step: 9
Training loss: 3.065341798726135
Validation loss: 2.836933361259844

Epoch: 6| Step: 10
Training loss: 3.142752766424158
Validation loss: 2.827739461997329

Epoch: 6| Step: 11
Training loss: 2.696883211090212
Validation loss: 2.8282916225548016

Epoch: 6| Step: 12
Training loss: 4.107040148096457
Validation loss: 2.8267895093623

Epoch: 6| Step: 13
Training loss: 2.235022924420859
Validation loss: 2.8246186132092466

Epoch: 62| Step: 0
Training loss: 2.5772730488950506
Validation loss: 2.8232208955001274

Epoch: 6| Step: 1
Training loss: 2.7346409259640505
Validation loss: 2.82117164716847

Epoch: 6| Step: 2
Training loss: 2.9895629527674394
Validation loss: 2.8217212797979347

Epoch: 6| Step: 3
Training loss: 3.2243840065475586
Validation loss: 2.821068880549159

Epoch: 6| Step: 4
Training loss: 3.7870491892619573
Validation loss: 2.8255195515977856

Epoch: 6| Step: 5
Training loss: 3.296960621666615
Validation loss: 2.823817212356312

Epoch: 6| Step: 6
Training loss: 3.653570252785762
Validation loss: 2.8282772937163254

Epoch: 6| Step: 7
Training loss: 3.257963693893027
Validation loss: 2.831322441975303

Epoch: 6| Step: 8
Training loss: 2.374612073838736
Validation loss: 2.828732522450611

Epoch: 6| Step: 9
Training loss: 3.4077317401004135
Validation loss: 2.8304357521051298

Epoch: 6| Step: 10
Training loss: 2.7215827128007644
Validation loss: 2.8238053247663535

Epoch: 6| Step: 11
Training loss: 2.787933719575064
Validation loss: 2.817459719318705

Epoch: 6| Step: 12
Training loss: 3.555420785243857
Validation loss: 2.8142964021140893

Epoch: 6| Step: 13
Training loss: 3.041595893628731
Validation loss: 2.813340223588055

Epoch: 63| Step: 0
Training loss: 3.1008189196423754
Validation loss: 2.8121990849572143

Epoch: 6| Step: 1
Training loss: 3.459045306228583
Validation loss: 2.809372513681544

Epoch: 6| Step: 2
Training loss: 3.101155367248859
Validation loss: 2.806625637570728

Epoch: 6| Step: 3
Training loss: 2.572010349128275
Validation loss: 2.8029770123437774

Epoch: 6| Step: 4
Training loss: 3.296838262995113
Validation loss: 2.8024392219725116

Epoch: 6| Step: 5
Training loss: 3.3088308202127155
Validation loss: 2.803071033035429

Epoch: 6| Step: 6
Training loss: 2.943683041987464
Validation loss: 2.8022106059561245

Epoch: 6| Step: 7
Training loss: 2.5305548761308496
Validation loss: 2.798363261286673

Epoch: 6| Step: 8
Training loss: 2.7666693832966285
Validation loss: 2.7974328290087613

Epoch: 6| Step: 9
Training loss: 3.552984546579456
Validation loss: 2.7959525660515436

Epoch: 6| Step: 10
Training loss: 3.1268852650643364
Validation loss: 2.793097702435346

Epoch: 6| Step: 11
Training loss: 3.203015134834597
Validation loss: 2.7900736176564656

Epoch: 6| Step: 12
Training loss: 2.913418696161866
Validation loss: 2.7951154959895126

Epoch: 6| Step: 13
Training loss: 3.86140407088155
Validation loss: 2.7943314892247706

Epoch: 64| Step: 0
Training loss: 3.8523822399561407
Validation loss: 2.7901546116047755

Epoch: 6| Step: 1
Training loss: 3.159680758659499
Validation loss: 2.7960345073841344

Epoch: 6| Step: 2
Training loss: 3.337151407046106
Validation loss: 2.8005457987797726

Epoch: 6| Step: 3
Training loss: 2.9143311732083212
Validation loss: 2.803289459829639

Epoch: 6| Step: 4
Training loss: 3.4947350275232107
Validation loss: 2.8131459322746233

Epoch: 6| Step: 5
Training loss: 2.9700186177193584
Validation loss: 2.818291701067452

Epoch: 6| Step: 6
Training loss: 1.927931878853164
Validation loss: 2.819649530795726

Epoch: 6| Step: 7
Training loss: 3.3933319677363896
Validation loss: 2.8222796646179424

Epoch: 6| Step: 8
Training loss: 3.4399081031589653
Validation loss: 2.8149572542057837

Epoch: 6| Step: 9
Training loss: 3.1095176165667975
Validation loss: 2.8097100853046824

Epoch: 6| Step: 10
Training loss: 2.67702447452978
Validation loss: 2.8068268367688503

Epoch: 6| Step: 11
Training loss: 3.120915146397477
Validation loss: 2.801511308536475

Epoch: 6| Step: 12
Training loss: 2.9859483975182157
Validation loss: 2.7995793113720326

Epoch: 6| Step: 13
Training loss: 2.818176728884445
Validation loss: 2.7986445843815506

Epoch: 65| Step: 0
Training loss: 2.945670594320441
Validation loss: 2.7964411059999876

Epoch: 6| Step: 1
Training loss: 3.5539099209628766
Validation loss: 2.7953909078557677

Epoch: 6| Step: 2
Training loss: 3.4736458534422763
Validation loss: 2.7933168026442363

Epoch: 6| Step: 3
Training loss: 2.0036273487078966
Validation loss: 2.7935897277945245

Epoch: 6| Step: 4
Training loss: 3.141476036649456
Validation loss: 2.791113568318321

Epoch: 6| Step: 5
Training loss: 3.0294523906325668
Validation loss: 2.7910890221893574

Epoch: 6| Step: 6
Training loss: 2.826434478475399
Validation loss: 2.7896760250985384

Epoch: 6| Step: 7
Training loss: 3.19144181006428
Validation loss: 2.7903209418707458

Epoch: 6| Step: 8
Training loss: 3.2245120721804867
Validation loss: 2.7932469534694224

Epoch: 6| Step: 9
Training loss: 3.673837470083808
Validation loss: 2.79107103404939

Epoch: 6| Step: 10
Training loss: 2.8819777357841723
Validation loss: 2.7935082727197122

Epoch: 6| Step: 11
Training loss: 2.982987965318149
Validation loss: 2.7943069741154574

Epoch: 6| Step: 12
Training loss: 2.8260620348925527
Validation loss: 2.7945007138524427

Epoch: 6| Step: 13
Training loss: 3.590563480922551
Validation loss: 2.7875893990750504

Epoch: 66| Step: 0
Training loss: 3.1321984352789443
Validation loss: 2.7874456815955972

Epoch: 6| Step: 1
Training loss: 2.7310659385830784
Validation loss: 2.7851586468915004

Epoch: 6| Step: 2
Training loss: 3.5608228784704217
Validation loss: 2.7853750416121468

Epoch: 6| Step: 3
Training loss: 2.8335445175753025
Validation loss: 2.780828705132023

Epoch: 6| Step: 4
Training loss: 3.6662539047496145
Validation loss: 2.7801326024751023

Epoch: 6| Step: 5
Training loss: 3.0070506530595584
Validation loss: 2.7809186624913482

Epoch: 6| Step: 6
Training loss: 2.9119873840037784
Validation loss: 2.7810599766950563

Epoch: 6| Step: 7
Training loss: 3.281100169802773
Validation loss: 2.782479622163362

Epoch: 6| Step: 8
Training loss: 3.01850777043165
Validation loss: 2.7773133296375647

Epoch: 6| Step: 9
Training loss: 2.802459596994334
Validation loss: 2.778698594219343

Epoch: 6| Step: 10
Training loss: 2.986451869319382
Validation loss: 2.7787297624021896

Epoch: 6| Step: 11
Training loss: 2.6054590502419708
Validation loss: 2.779148752912091

Epoch: 6| Step: 12
Training loss: 3.6771498431853824
Validation loss: 2.774488028233125

Epoch: 6| Step: 13
Training loss: 2.682880067946455
Validation loss: 2.776458628269279

Epoch: 67| Step: 0
Training loss: 2.8689102693222823
Validation loss: 2.777893948809042

Epoch: 6| Step: 1
Training loss: 3.5940815648252475
Validation loss: 2.7748483242602084

Epoch: 6| Step: 2
Training loss: 2.688312230351539
Validation loss: 2.777039335671132

Epoch: 6| Step: 3
Training loss: 3.35950998434294
Validation loss: 2.777811175183205

Epoch: 6| Step: 4
Training loss: 3.336276106433911
Validation loss: 2.7751297937112147

Epoch: 6| Step: 5
Training loss: 3.044794399292005
Validation loss: 2.7759064105785103

Epoch: 6| Step: 6
Training loss: 2.8832643563136338
Validation loss: 2.7745405500246236

Epoch: 6| Step: 7
Training loss: 2.9128891779008574
Validation loss: 2.77487994219509

Epoch: 6| Step: 8
Training loss: 2.7060392689756068
Validation loss: 2.7756605127719762

Epoch: 6| Step: 9
Training loss: 2.7803707661825654
Validation loss: 2.7761712376015986

Epoch: 6| Step: 10
Training loss: 3.596767054710328
Validation loss: 2.7743332771145854

Epoch: 6| Step: 11
Training loss: 3.057869037306275
Validation loss: 2.7747848397027886

Epoch: 6| Step: 12
Training loss: 3.0358361227766344
Validation loss: 2.773011244411091

Epoch: 6| Step: 13
Training loss: 3.507833026239708
Validation loss: 2.7723455294203627

Epoch: 68| Step: 0
Training loss: 2.935118663670043
Validation loss: 2.7715711096378817

Epoch: 6| Step: 1
Training loss: 3.059322655203694
Validation loss: 2.7684760369048145

Epoch: 6| Step: 2
Training loss: 3.5125303762622524
Validation loss: 2.769717080853041

Epoch: 6| Step: 3
Training loss: 3.1431404023277607
Validation loss: 2.767776445910154

Epoch: 6| Step: 4
Training loss: 3.276441265695711
Validation loss: 2.7669521470886087

Epoch: 6| Step: 5
Training loss: 3.296220181055056
Validation loss: 2.7659530041911067

Epoch: 6| Step: 6
Training loss: 3.085409925729487
Validation loss: 2.7655322573400585

Epoch: 6| Step: 7
Training loss: 3.245661260298364
Validation loss: 2.762795090281344

Epoch: 6| Step: 8
Training loss: 2.954483284996421
Validation loss: 2.7610409390416244

Epoch: 6| Step: 9
Training loss: 2.539449527293733
Validation loss: 2.7598624182448077

Epoch: 6| Step: 10
Training loss: 3.618062978302868
Validation loss: 2.7617783187640685

Epoch: 6| Step: 11
Training loss: 2.9985147614337557
Validation loss: 2.7601787301293856

Epoch: 6| Step: 12
Training loss: 2.6345457263800163
Validation loss: 2.7602726204348644

Epoch: 6| Step: 13
Training loss: 2.447485789802298
Validation loss: 2.7633890306761097

Epoch: 69| Step: 0
Training loss: 3.088254420971877
Validation loss: 2.7590195138189877

Epoch: 6| Step: 1
Training loss: 2.5023342679046854
Validation loss: 2.7587902333711476

Epoch: 6| Step: 2
Training loss: 2.294052154014672
Validation loss: 2.7631011351527768

Epoch: 6| Step: 3
Training loss: 2.758466864481763
Validation loss: 2.764676644698286

Epoch: 6| Step: 4
Training loss: 3.44021776441573
Validation loss: 2.764241610382235

Epoch: 6| Step: 5
Training loss: 3.094481410641477
Validation loss: 2.76069178232828

Epoch: 6| Step: 6
Training loss: 3.7970859798635797
Validation loss: 2.7604192980248574

Epoch: 6| Step: 7
Training loss: 2.8508631018368873
Validation loss: 2.7562498964219406

Epoch: 6| Step: 8
Training loss: 2.700137565781697
Validation loss: 2.7549343941024733

Epoch: 6| Step: 9
Training loss: 2.9489322346339004
Validation loss: 2.753798876673325

Epoch: 6| Step: 10
Training loss: 3.1208228613181612
Validation loss: 2.7517428613179686

Epoch: 6| Step: 11
Training loss: 3.7206713417277664
Validation loss: 2.755474596370234

Epoch: 6| Step: 12
Training loss: 2.929146434411997
Validation loss: 2.753131533077435

Epoch: 6| Step: 13
Training loss: 3.66199518051122
Validation loss: 2.754321408576903

Epoch: 70| Step: 0
Training loss: 2.9752444255017925
Validation loss: 2.7528944845075776

Epoch: 6| Step: 1
Training loss: 2.6797784283839463
Validation loss: 2.7514965296016705

Epoch: 6| Step: 2
Training loss: 3.1332213023293005
Validation loss: 2.7506990905203823

Epoch: 6| Step: 3
Training loss: 3.276621724231538
Validation loss: 2.751638217241148

Epoch: 6| Step: 4
Training loss: 2.4660657945566404
Validation loss: 2.7480429829571085

Epoch: 6| Step: 5
Training loss: 3.170038151797246
Validation loss: 2.7520381537912146

Epoch: 6| Step: 6
Training loss: 3.2236703837556075
Validation loss: 2.750432987190035

Epoch: 6| Step: 7
Training loss: 3.0005284479741317
Validation loss: 2.752111583516066

Epoch: 6| Step: 8
Training loss: 2.649393184929721
Validation loss: 2.752143591209416

Epoch: 6| Step: 9
Training loss: 3.2489041168069392
Validation loss: 2.754299420901727

Epoch: 6| Step: 10
Training loss: 3.7494798935380222
Validation loss: 2.7518838198781412

Epoch: 6| Step: 11
Training loss: 3.182317822104862
Validation loss: 2.7549282179474233

Epoch: 6| Step: 12
Training loss: 2.906685581174899
Validation loss: 2.7588616797316665

Epoch: 6| Step: 13
Training loss: 3.4146408184830346
Validation loss: 2.753012308743834

Epoch: 71| Step: 0
Training loss: 3.2546605658916143
Validation loss: 2.7524607789623947

Epoch: 6| Step: 1
Training loss: 2.7909387427085814
Validation loss: 2.747893935583181

Epoch: 6| Step: 2
Training loss: 2.6689921213421783
Validation loss: 2.750641220414065

Epoch: 6| Step: 3
Training loss: 2.933277585482433
Validation loss: 2.7547767540430597

Epoch: 6| Step: 4
Training loss: 3.466752310453005
Validation loss: 2.756990474940269

Epoch: 6| Step: 5
Training loss: 3.2216694748720367
Validation loss: 2.7513051371238633

Epoch: 6| Step: 6
Training loss: 2.7670302619395946
Validation loss: 2.746682898853475

Epoch: 6| Step: 7
Training loss: 2.694102228418437
Validation loss: 2.744383585221605

Epoch: 6| Step: 8
Training loss: 2.7554015084074734
Validation loss: 2.7445824500505385

Epoch: 6| Step: 9
Training loss: 3.33334156671143
Validation loss: 2.741855091325528

Epoch: 6| Step: 10
Training loss: 3.5561045745989244
Validation loss: 2.742855624833544

Epoch: 6| Step: 11
Training loss: 3.3329575962650613
Validation loss: 2.745554438800572

Epoch: 6| Step: 12
Training loss: 3.306972858752456
Validation loss: 2.7457942591324462

Epoch: 6| Step: 13
Training loss: 2.3807138675478248
Validation loss: 2.75755159764374

Epoch: 72| Step: 0
Training loss: 2.727350596558919
Validation loss: 2.7706841484085896

Epoch: 6| Step: 1
Training loss: 2.65535334992612
Validation loss: 2.771690114675103

Epoch: 6| Step: 2
Training loss: 2.8893626162927655
Validation loss: 2.7971057779448634

Epoch: 6| Step: 3
Training loss: 3.3445660317315897
Validation loss: 2.786960246014304

Epoch: 6| Step: 4
Training loss: 3.080752572846462
Validation loss: 2.7526732900488646

Epoch: 6| Step: 5
Training loss: 2.962552317225774
Validation loss: 2.7382353672212023

Epoch: 6| Step: 6
Training loss: 2.905307411828663
Validation loss: 2.7351543388230324

Epoch: 6| Step: 7
Training loss: 3.58908587769072
Validation loss: 2.732225821958188

Epoch: 6| Step: 8
Training loss: 3.552696525619577
Validation loss: 2.7327890642336765

Epoch: 6| Step: 9
Training loss: 2.8846914066176255
Validation loss: 2.732745372623885

Epoch: 6| Step: 10
Training loss: 2.307445673111892
Validation loss: 2.7352828086637975

Epoch: 6| Step: 11
Training loss: 3.250498219962367
Validation loss: 2.733898717415322

Epoch: 6| Step: 12
Training loss: 3.3517840118833573
Validation loss: 2.73774540864514

Epoch: 6| Step: 13
Training loss: 3.158237096147304
Validation loss: 2.731846574261426

Epoch: 73| Step: 0
Training loss: 3.009982983107006
Validation loss: 2.7347940009653855

Epoch: 6| Step: 1
Training loss: 3.067634482323256
Validation loss: 2.7310136470838424

Epoch: 6| Step: 2
Training loss: 3.432283361923675
Validation loss: 2.730062584892671

Epoch: 6| Step: 3
Training loss: 2.430458854083739
Validation loss: 2.730602481947206

Epoch: 6| Step: 4
Training loss: 3.618119121895327
Validation loss: 2.7289990518689797

Epoch: 6| Step: 5
Training loss: 2.769212454242133
Validation loss: 2.730764266334344

Epoch: 6| Step: 6
Training loss: 3.597780438825935
Validation loss: 2.7294097794613728

Epoch: 6| Step: 7
Training loss: 2.275384442889939
Validation loss: 2.72889059048593

Epoch: 6| Step: 8
Training loss: 2.6152956373519136
Validation loss: 2.723601986132525

Epoch: 6| Step: 9
Training loss: 3.258086195318953
Validation loss: 2.7242113685776697

Epoch: 6| Step: 10
Training loss: 3.347876026323896
Validation loss: 2.723869052315473

Epoch: 6| Step: 11
Training loss: 2.9571618639622774
Validation loss: 2.727154490570825

Epoch: 6| Step: 12
Training loss: 2.616015727074621
Validation loss: 2.7239768336777663

Epoch: 6| Step: 13
Training loss: 3.676634345951548
Validation loss: 2.7219163294678816

Epoch: 74| Step: 0
Training loss: 3.075156702530326
Validation loss: 2.724708260179491

Epoch: 6| Step: 1
Training loss: 2.6764107736316234
Validation loss: 2.724174141954824

Epoch: 6| Step: 2
Training loss: 2.4899716466798436
Validation loss: 2.7199514867377403

Epoch: 6| Step: 3
Training loss: 2.349375674325532
Validation loss: 2.720532752292198

Epoch: 6| Step: 4
Training loss: 2.7351843807688283
Validation loss: 2.7209613007569047

Epoch: 6| Step: 5
Training loss: 3.14910109273436
Validation loss: 2.7285013932449673

Epoch: 6| Step: 6
Training loss: 2.8251291498690714
Validation loss: 2.743108786689556

Epoch: 6| Step: 7
Training loss: 3.588057545790521
Validation loss: 2.7667137141131017

Epoch: 6| Step: 8
Training loss: 3.526726314879145
Validation loss: 2.7687239144551827

Epoch: 6| Step: 9
Training loss: 3.159880712164987
Validation loss: 2.748600721242632

Epoch: 6| Step: 10
Training loss: 3.110637159425325
Validation loss: 2.7495199961053314

Epoch: 6| Step: 11
Training loss: 3.3385385561892362
Validation loss: 2.7288023714850027

Epoch: 6| Step: 12
Training loss: 3.4040521653029945
Validation loss: 2.7247090006568975

Epoch: 6| Step: 13
Training loss: 3.3386426762591364
Validation loss: 2.716107377999312

Epoch: 75| Step: 0
Training loss: 2.875061366214132
Validation loss: 2.7240126541309615

Epoch: 6| Step: 1
Training loss: 2.7516848864569265
Validation loss: 2.7396301735911166

Epoch: 6| Step: 2
Training loss: 3.30233904854246
Validation loss: 2.7741267428041723

Epoch: 6| Step: 3
Training loss: 3.1380382911966835
Validation loss: 2.7374439817578065

Epoch: 6| Step: 4
Training loss: 3.0171315279351596
Validation loss: 2.7225590398373747

Epoch: 6| Step: 5
Training loss: 3.115382386521052
Validation loss: 2.7202369368216868

Epoch: 6| Step: 6
Training loss: 2.3960546529519857
Validation loss: 2.7191182321982645

Epoch: 6| Step: 7
Training loss: 2.5458518939634556
Validation loss: 2.727239873278194

Epoch: 6| Step: 8
Training loss: 3.4506758207625237
Validation loss: 2.7217574373289275

Epoch: 6| Step: 9
Training loss: 2.9598811940243914
Validation loss: 2.7321885853684873

Epoch: 6| Step: 10
Training loss: 2.95955800957855
Validation loss: 2.7381809806022686

Epoch: 6| Step: 11
Training loss: 3.5010509275574777
Validation loss: 2.754609029513305

Epoch: 6| Step: 12
Training loss: 3.245837260004361
Validation loss: 2.7496771170754375

Epoch: 6| Step: 13
Training loss: 3.8362724950385063
Validation loss: 2.7230111612586474

Epoch: 76| Step: 0
Training loss: 3.2501100374813934
Validation loss: 2.7187704656724345

Epoch: 6| Step: 1
Training loss: 3.2482409485202224
Validation loss: 2.7201727874888313

Epoch: 6| Step: 2
Training loss: 3.1790563908387677
Validation loss: 2.719536518204082

Epoch: 6| Step: 3
Training loss: 3.1956725722110106
Validation loss: 2.7192246745586344

Epoch: 6| Step: 4
Training loss: 3.6790758017310288
Validation loss: 2.7244568305907872

Epoch: 6| Step: 5
Training loss: 2.070621798461318
Validation loss: 2.727050484655353

Epoch: 6| Step: 6
Training loss: 3.1429102540173064
Validation loss: 2.7288100451031028

Epoch: 6| Step: 7
Training loss: 2.590352786571537
Validation loss: 2.7247874731853554

Epoch: 6| Step: 8
Training loss: 3.0674401745173716
Validation loss: 2.7254606103581693

Epoch: 6| Step: 9
Training loss: 2.5887097023369834
Validation loss: 2.7219879440787222

Epoch: 6| Step: 10
Training loss: 2.9766731942487215
Validation loss: 2.7221565851501155

Epoch: 6| Step: 11
Training loss: 2.7291722964939744
Validation loss: 2.7199454088149575

Epoch: 6| Step: 12
Training loss: 3.4836258018646307
Validation loss: 2.731832515639121

Epoch: 6| Step: 13
Training loss: 3.458760629630014
Validation loss: 2.749771973822441

Epoch: 77| Step: 0
Training loss: 2.432967642735543
Validation loss: 2.7935420140932123

Epoch: 6| Step: 1
Training loss: 3.8744240609668967
Validation loss: 2.7813318454138436

Epoch: 6| Step: 2
Training loss: 3.0608262139692908
Validation loss: 2.7568749297569664

Epoch: 6| Step: 3
Training loss: 3.3730528124042993
Validation loss: 2.7391046088387916

Epoch: 6| Step: 4
Training loss: 2.505417580434418
Validation loss: 2.7371848768178157

Epoch: 6| Step: 5
Training loss: 2.6355209229445173
Validation loss: 2.7274755313783676

Epoch: 6| Step: 6
Training loss: 3.341078216669335
Validation loss: 2.7185549780998026

Epoch: 6| Step: 7
Training loss: 3.0810922949864077
Validation loss: 2.7113005413445963

Epoch: 6| Step: 8
Training loss: 2.721834296744445
Validation loss: 2.708675767691823

Epoch: 6| Step: 9
Training loss: 2.7442562635499184
Validation loss: 2.7091561221664606

Epoch: 6| Step: 10
Training loss: 3.297677615850442
Validation loss: 2.7196360742340464

Epoch: 6| Step: 11
Training loss: 3.2159583568628762
Validation loss: 2.7161006463406823

Epoch: 6| Step: 12
Training loss: 3.187966106966936
Validation loss: 2.7099564307213324

Epoch: 6| Step: 13
Training loss: 2.9888264476614768
Validation loss: 2.702219799003466

Epoch: 78| Step: 0
Training loss: 2.6500842171008547
Validation loss: 2.6998905061695058

Epoch: 6| Step: 1
Training loss: 2.3746935998130714
Validation loss: 2.700599527736754

Epoch: 6| Step: 2
Training loss: 2.8560167613886667
Validation loss: 2.7011518122260787

Epoch: 6| Step: 3
Training loss: 2.556023764450565
Validation loss: 2.6990209129758633

Epoch: 6| Step: 4
Training loss: 3.1253680203219543
Validation loss: 2.7028758887187787

Epoch: 6| Step: 5
Training loss: 2.4550938571617063
Validation loss: 2.699473778153198

Epoch: 6| Step: 6
Training loss: 2.5780535138940985
Validation loss: 2.7013883752995755

Epoch: 6| Step: 7
Training loss: 3.1271422100856894
Validation loss: 2.6975491852675333

Epoch: 6| Step: 8
Training loss: 3.7171641582767956
Validation loss: 2.7009743556798664

Epoch: 6| Step: 9
Training loss: 2.6234282374715505
Validation loss: 2.7000545960303026

Epoch: 6| Step: 10
Training loss: 3.8348595994616295
Validation loss: 2.7014690625965843

Epoch: 6| Step: 11
Training loss: 3.7548849713501595
Validation loss: 2.701732785554652

Epoch: 6| Step: 12
Training loss: 3.3160660460259903
Validation loss: 2.695722094007011

Epoch: 6| Step: 13
Training loss: 2.9330007306737604
Validation loss: 2.6965447936506224

Epoch: 79| Step: 0
Training loss: 3.047596694376122
Validation loss: 2.695983019569531

Epoch: 6| Step: 1
Training loss: 2.9871768281827626
Validation loss: 2.6946350948959528

Epoch: 6| Step: 2
Training loss: 2.950213738150008
Validation loss: 2.693833868015792

Epoch: 6| Step: 3
Training loss: 3.7534885710012116
Validation loss: 2.69108313014483

Epoch: 6| Step: 4
Training loss: 2.220803183899062
Validation loss: 2.6914145503188576

Epoch: 6| Step: 5
Training loss: 3.3175370408198783
Validation loss: 2.690732255641381

Epoch: 6| Step: 6
Training loss: 2.6001655562583688
Validation loss: 2.6899970383648193

Epoch: 6| Step: 7
Training loss: 3.2264422008634672
Validation loss: 2.688676727685243

Epoch: 6| Step: 8
Training loss: 3.056455290906854
Validation loss: 2.6903399786297215

Epoch: 6| Step: 9
Training loss: 2.156196483003214
Validation loss: 2.6886538627706145

Epoch: 6| Step: 10
Training loss: 3.18126217702997
Validation loss: 2.6924793335414576

Epoch: 6| Step: 11
Training loss: 3.4162051811865486
Validation loss: 2.6913328395473624

Epoch: 6| Step: 12
Training loss: 3.2074716244733574
Validation loss: 2.6887911408734633

Epoch: 6| Step: 13
Training loss: 2.649529876033739
Validation loss: 2.6999275472772624

Epoch: 80| Step: 0
Training loss: 2.8496689453591855
Validation loss: 2.702226773958514

Epoch: 6| Step: 1
Training loss: 2.896733937537725
Validation loss: 2.707226340683616

Epoch: 6| Step: 2
Training loss: 2.5565594921833434
Validation loss: 2.7162895285360853

Epoch: 6| Step: 3
Training loss: 3.0007116745180413
Validation loss: 2.7087145787077613

Epoch: 6| Step: 4
Training loss: 2.724036240542482
Validation loss: 2.7155998555168717

Epoch: 6| Step: 5
Training loss: 3.718248990714016
Validation loss: 2.7091583099823295

Epoch: 6| Step: 6
Training loss: 3.3955196087478443
Validation loss: 2.695788809867685

Epoch: 6| Step: 7
Training loss: 3.1399255989153043
Validation loss: 2.7012432509136013

Epoch: 6| Step: 8
Training loss: 2.6492029394894625
Validation loss: 2.6971890416219457

Epoch: 6| Step: 9
Training loss: 3.6689476518824056
Validation loss: 2.6969754808064876

Epoch: 6| Step: 10
Training loss: 2.7680441410866976
Validation loss: 2.7068410796345885

Epoch: 6| Step: 11
Training loss: 2.369357986731239
Validation loss: 2.6908517933146268

Epoch: 6| Step: 12
Training loss: 2.872230522722572
Validation loss: 2.6829169693325396

Epoch: 6| Step: 13
Training loss: 3.5049194095940384
Validation loss: 2.6819097696064267

Epoch: 81| Step: 0
Training loss: 2.7360587031664454
Validation loss: 2.6860294158064906

Epoch: 6| Step: 1
Training loss: 2.4937459921744893
Validation loss: 2.6952575716042673

Epoch: 6| Step: 2
Training loss: 3.086572818304359
Validation loss: 2.6986547196917736

Epoch: 6| Step: 3
Training loss: 2.517068200152461
Validation loss: 2.7012537754886967

Epoch: 6| Step: 4
Training loss: 2.7420904680348706
Validation loss: 2.6990785240150523

Epoch: 6| Step: 5
Training loss: 3.3755638216743553
Validation loss: 2.6977428976270605

Epoch: 6| Step: 6
Training loss: 3.5973810842449265
Validation loss: 2.6970014367096233

Epoch: 6| Step: 7
Training loss: 2.8743413087678977
Validation loss: 2.6968839297390783

Epoch: 6| Step: 8
Training loss: 3.1622009075599466
Validation loss: 2.696514068327507

Epoch: 6| Step: 9
Training loss: 3.365418856939148
Validation loss: 2.692231075036657

Epoch: 6| Step: 10
Training loss: 3.01318561144044
Validation loss: 2.694508249198125

Epoch: 6| Step: 11
Training loss: 2.835234751998146
Validation loss: 2.69279536551318

Epoch: 6| Step: 12
Training loss: 3.291873410327557
Validation loss: 2.689298768507861

Epoch: 6| Step: 13
Training loss: 3.334491353744346
Validation loss: 2.688323602300665

Epoch: 82| Step: 0
Training loss: 2.9790928615862415
Validation loss: 2.6879481242246945

Epoch: 6| Step: 1
Training loss: 2.868577500685907
Validation loss: 2.6865033903406625

Epoch: 6| Step: 2
Training loss: 3.610587308666137
Validation loss: 2.684852427318956

Epoch: 6| Step: 3
Training loss: 2.878709141933679
Validation loss: 2.6771603648180893

Epoch: 6| Step: 4
Training loss: 3.4606717182000812
Validation loss: 2.674704129886172

Epoch: 6| Step: 5
Training loss: 2.9829778946131964
Validation loss: 2.676811073861177

Epoch: 6| Step: 6
Training loss: 2.8788714672042266
Validation loss: 2.6755773663194233

Epoch: 6| Step: 7
Training loss: 2.6416912747589745
Validation loss: 2.6824179683633385

Epoch: 6| Step: 8
Training loss: 3.0047883919902993
Validation loss: 2.690024231908569

Epoch: 6| Step: 9
Training loss: 3.017513494200665
Validation loss: 2.684206375945068

Epoch: 6| Step: 10
Training loss: 2.6646558710464463
Validation loss: 2.679215894997751

Epoch: 6| Step: 11
Training loss: 2.9006342621786714
Validation loss: 2.6794910902449893

Epoch: 6| Step: 12
Training loss: 3.0751418166294076
Validation loss: 2.6808896032395

Epoch: 6| Step: 13
Training loss: 3.344312816562897
Validation loss: 2.698060886147001

Epoch: 83| Step: 0
Training loss: 2.6346080780998924
Validation loss: 2.6986477725532745

Epoch: 6| Step: 1
Training loss: 3.2132120731103675
Validation loss: 2.6872810604642856

Epoch: 6| Step: 2
Training loss: 3.2961984817130126
Validation loss: 2.6729866856993496

Epoch: 6| Step: 3
Training loss: 2.6134294088699783
Validation loss: 2.6718351817766632

Epoch: 6| Step: 4
Training loss: 2.7790434581739514
Validation loss: 2.6710096866359243

Epoch: 6| Step: 5
Training loss: 3.6229719868860744
Validation loss: 2.6655093512618846

Epoch: 6| Step: 6
Training loss: 2.722891623613638
Validation loss: 2.6662048034727936

Epoch: 6| Step: 7
Training loss: 3.5026945913145804
Validation loss: 2.662182463643226

Epoch: 6| Step: 8
Training loss: 2.9160004172723837
Validation loss: 2.6631282806324292

Epoch: 6| Step: 9
Training loss: 2.6213813544357296
Validation loss: 2.6626048808681717

Epoch: 6| Step: 10
Training loss: 2.774563155285393
Validation loss: 2.6633146263109446

Epoch: 6| Step: 11
Training loss: 2.819708846733414
Validation loss: 2.6639945863843475

Epoch: 6| Step: 12
Training loss: 2.7062239330701425
Validation loss: 2.6617458973118673

Epoch: 6| Step: 13
Training loss: 3.9559012453657054
Validation loss: 2.660314875191625

Epoch: 84| Step: 0
Training loss: 3.4417458408907207
Validation loss: 2.6622059382145964

Epoch: 6| Step: 1
Training loss: 2.442113374157467
Validation loss: 2.66135517083614

Epoch: 6| Step: 2
Training loss: 3.451629591048447
Validation loss: 2.6610653944413944

Epoch: 6| Step: 3
Training loss: 2.574810602574418
Validation loss: 2.660315937145397

Epoch: 6| Step: 4
Training loss: 3.5777126557746417
Validation loss: 2.6612657187882296

Epoch: 6| Step: 5
Training loss: 3.189703983456019
Validation loss: 2.659737773591231

Epoch: 6| Step: 6
Training loss: 2.323894574293688
Validation loss: 2.6625017557345876

Epoch: 6| Step: 7
Training loss: 2.982176765007645
Validation loss: 2.6628350994027787

Epoch: 6| Step: 8
Training loss: 2.5972602714521265
Validation loss: 2.6780410320185934

Epoch: 6| Step: 9
Training loss: 2.252145380182319
Validation loss: 2.681647728048976

Epoch: 6| Step: 10
Training loss: 2.875232355430998
Validation loss: 2.6877231510025545

Epoch: 6| Step: 11
Training loss: 3.6304142737113474
Validation loss: 2.6682777389811303

Epoch: 6| Step: 12
Training loss: 3.0615039684887337
Validation loss: 2.661185839402134

Epoch: 6| Step: 13
Training loss: 3.2506650097597367
Validation loss: 2.659642906880182

Epoch: 85| Step: 0
Training loss: 3.1715265092001945
Validation loss: 2.6602089070339403

Epoch: 6| Step: 1
Training loss: 3.5027728677087167
Validation loss: 2.659797732357493

Epoch: 6| Step: 2
Training loss: 3.374510835590338
Validation loss: 2.66166993028829

Epoch: 6| Step: 3
Training loss: 2.9973340905019996
Validation loss: 2.6719078508588496

Epoch: 6| Step: 4
Training loss: 3.0697878323779038
Validation loss: 2.660998678929683

Epoch: 6| Step: 5
Training loss: 3.455725885699664
Validation loss: 2.6619885432664465

Epoch: 6| Step: 6
Training loss: 2.3698950664612974
Validation loss: 2.654651259648172

Epoch: 6| Step: 7
Training loss: 2.8236269086712853
Validation loss: 2.6545037935334337

Epoch: 6| Step: 8
Training loss: 2.855839445628725
Validation loss: 2.654183132667701

Epoch: 6| Step: 9
Training loss: 2.215885731322756
Validation loss: 2.6548393697372377

Epoch: 6| Step: 10
Training loss: 2.7671614005410468
Validation loss: 2.654779218834674

Epoch: 6| Step: 11
Training loss: 2.7965873698229458
Validation loss: 2.6553241291166167

Epoch: 6| Step: 12
Training loss: 3.140319809390283
Validation loss: 2.657425733990315

Epoch: 6| Step: 13
Training loss: 3.2880273490288103
Validation loss: 2.6598388131682706

Epoch: 86| Step: 0
Training loss: 2.8127921058704586
Validation loss: 2.656786911306546

Epoch: 6| Step: 1
Training loss: 2.737503877401872
Validation loss: 2.65306290697683

Epoch: 6| Step: 2
Training loss: 2.7663085437618036
Validation loss: 2.652071020070708

Epoch: 6| Step: 3
Training loss: 3.1680072824413714
Validation loss: 2.6507624838508015

Epoch: 6| Step: 4
Training loss: 2.861414114535553
Validation loss: 2.650667733076334

Epoch: 6| Step: 5
Training loss: 2.538503074639626
Validation loss: 2.6532598865700456

Epoch: 6| Step: 6
Training loss: 3.4112270286516284
Validation loss: 2.6522916859120906

Epoch: 6| Step: 7
Training loss: 3.201368939127701
Validation loss: 2.65681631383831

Epoch: 6| Step: 8
Training loss: 2.5071123993870716
Validation loss: 2.6657142531025158

Epoch: 6| Step: 9
Training loss: 3.0275010984814115
Validation loss: 2.675244793919893

Epoch: 6| Step: 10
Training loss: 3.500998899423164
Validation loss: 2.67977064880199

Epoch: 6| Step: 11
Training loss: 2.866732111634767
Validation loss: 2.664810808363165

Epoch: 6| Step: 12
Training loss: 3.2511169274950906
Validation loss: 2.654327117381338

Epoch: 6| Step: 13
Training loss: 3.275185785047118
Validation loss: 2.6485692226603126

Epoch: 87| Step: 0
Training loss: 2.851869665872809
Validation loss: 2.649132886570321

Epoch: 6| Step: 1
Training loss: 3.076574874395823
Validation loss: 2.649994905064074

Epoch: 6| Step: 2
Training loss: 2.8399485236862128
Validation loss: 2.649152288482224

Epoch: 6| Step: 3
Training loss: 3.035846018136856
Validation loss: 2.64958931110125

Epoch: 6| Step: 4
Training loss: 2.8982338229691784
Validation loss: 2.64953219532969

Epoch: 6| Step: 5
Training loss: 2.1730173523478213
Validation loss: 2.6464877441249186

Epoch: 6| Step: 6
Training loss: 3.484256485775264
Validation loss: 2.644096894435301

Epoch: 6| Step: 7
Training loss: 3.2265524506123766
Validation loss: 2.643590438807524

Epoch: 6| Step: 8
Training loss: 3.045706500445016
Validation loss: 2.645304925456837

Epoch: 6| Step: 9
Training loss: 2.9156975543939274
Validation loss: 2.649944567163467

Epoch: 6| Step: 10
Training loss: 2.865865376581645
Validation loss: 2.6626084106071906

Epoch: 6| Step: 11
Training loss: 2.920596572342525
Validation loss: 2.6666415896569697

Epoch: 6| Step: 12
Training loss: 3.223700115029409
Validation loss: 2.681571336303719

Epoch: 6| Step: 13
Training loss: 3.345265553059039
Validation loss: 2.694306886372122

Epoch: 88| Step: 0
Training loss: 3.431826261342073
Validation loss: 2.6686320605683447

Epoch: 6| Step: 1
Training loss: 3.360928056704539
Validation loss: 2.6574937821947766

Epoch: 6| Step: 2
Training loss: 2.163356404154545
Validation loss: 2.641277730845592

Epoch: 6| Step: 3
Training loss: 3.1686368301317036
Validation loss: 2.6466692501167195

Epoch: 6| Step: 4
Training loss: 3.0855102243261787
Validation loss: 2.6609211163114614

Epoch: 6| Step: 5
Training loss: 2.6497497008534316
Validation loss: 2.6823481788659596

Epoch: 6| Step: 6
Training loss: 2.7658722330568213
Validation loss: 2.7099133643080404

Epoch: 6| Step: 7
Training loss: 3.501072583019007
Validation loss: 2.6846543031931054

Epoch: 6| Step: 8
Training loss: 2.9948802813259663
Validation loss: 2.6689841076482597

Epoch: 6| Step: 9
Training loss: 3.2775708598399476
Validation loss: 2.6862339577675196

Epoch: 6| Step: 10
Training loss: 2.167330151231241
Validation loss: 2.6542756707436665

Epoch: 6| Step: 11
Training loss: 3.187274102078801
Validation loss: 2.659007030099563

Epoch: 6| Step: 12
Training loss: 3.059026499957365
Validation loss: 2.672489741517774

Epoch: 6| Step: 13
Training loss: 2.7413262647742984
Validation loss: 2.6954306470916984

Epoch: 89| Step: 0
Training loss: 3.2945357426012762
Validation loss: 2.7091258190316436

Epoch: 6| Step: 1
Training loss: 3.253103974757194
Validation loss: 2.6966501895537998

Epoch: 6| Step: 2
Training loss: 2.449954955017788
Validation loss: 2.6630900355313982

Epoch: 6| Step: 3
Training loss: 2.4921170885429547
Validation loss: 2.6554226845825553

Epoch: 6| Step: 4
Training loss: 3.220541298191491
Validation loss: 2.6531523911213637

Epoch: 6| Step: 5
Training loss: 2.8461913643662076
Validation loss: 2.6507807693768006

Epoch: 6| Step: 6
Training loss: 3.185792952060513
Validation loss: 2.640224400430226

Epoch: 6| Step: 7
Training loss: 2.466463406238569
Validation loss: 2.642463433907205

Epoch: 6| Step: 8
Training loss: 3.512402222925266
Validation loss: 2.6394008879910005

Epoch: 6| Step: 9
Training loss: 3.2203702829832292
Validation loss: 2.6365928342128226

Epoch: 6| Step: 10
Training loss: 3.1314088335698016
Validation loss: 2.6455954484402104

Epoch: 6| Step: 11
Training loss: 2.86268199358768
Validation loss: 2.6572925594268826

Epoch: 6| Step: 12
Training loss: 2.994971511527013
Validation loss: 2.647219030433726

Epoch: 6| Step: 13
Training loss: 2.5344706638404637
Validation loss: 2.649847364605749

Epoch: 90| Step: 0
Training loss: 2.4401320893852163
Validation loss: 2.6714276765270846

Epoch: 6| Step: 1
Training loss: 3.3548502413075854
Validation loss: 2.744240969978998

Epoch: 6| Step: 2
Training loss: 3.3712872464021673
Validation loss: 2.8248381019175715

Epoch: 6| Step: 3
Training loss: 3.846846163135723
Validation loss: 2.9872927991296776

Epoch: 6| Step: 4
Training loss: 3.2648320307616
Validation loss: 2.925706487834854

Epoch: 6| Step: 5
Training loss: 3.8472885343404237
Validation loss: 2.860035779212743

Epoch: 6| Step: 6
Training loss: 3.1797489844523854
Validation loss: 2.771056556145021

Epoch: 6| Step: 7
Training loss: 3.1945286467875795
Validation loss: 2.709553601900152

Epoch: 6| Step: 8
Training loss: 2.390796331112877
Validation loss: 2.674823423025576

Epoch: 6| Step: 9
Training loss: 2.8874482715811776
Validation loss: 2.6612366823500238

Epoch: 6| Step: 10
Training loss: 2.98638432950707
Validation loss: 2.649385377086443

Epoch: 6| Step: 11
Training loss: 2.2674809713522044
Validation loss: 2.645688323708645

Epoch: 6| Step: 12
Training loss: 2.8751451206898855
Validation loss: 2.6602112738776054

Epoch: 6| Step: 13
Training loss: 2.590240402111117
Validation loss: 2.6621436974541157

Epoch: 91| Step: 0
Training loss: 2.56221313731728
Validation loss: 2.6732477253769997

Epoch: 6| Step: 1
Training loss: 2.6343638210579834
Validation loss: 2.6652024393300917

Epoch: 6| Step: 2
Training loss: 3.5013069709846802
Validation loss: 2.650960869314068

Epoch: 6| Step: 3
Training loss: 3.454205788335986
Validation loss: 2.6476162874993445

Epoch: 6| Step: 4
Training loss: 3.0378817345890226
Validation loss: 2.6468620380462404

Epoch: 6| Step: 5
Training loss: 2.4962591794016644
Validation loss: 2.6508614439172273

Epoch: 6| Step: 6
Training loss: 3.2876277884243112
Validation loss: 2.6565256823826773

Epoch: 6| Step: 7
Training loss: 2.982972459615445
Validation loss: 2.666686018237788

Epoch: 6| Step: 8
Training loss: 3.0109447469262816
Validation loss: 2.6629501761760945

Epoch: 6| Step: 9
Training loss: 2.740665893945544
Validation loss: 2.659446561047748

Epoch: 6| Step: 10
Training loss: 2.903784906224325
Validation loss: 2.6357584033823427

Epoch: 6| Step: 11
Training loss: 2.9664246135361285
Validation loss: 2.633483533429594

Epoch: 6| Step: 12
Training loss: 3.07523237141254
Validation loss: 2.630398861321724

Epoch: 6| Step: 13
Training loss: 2.9962205922160066
Validation loss: 2.624767189620609

Epoch: 92| Step: 0
Training loss: 2.7529608652677577
Validation loss: 2.621956110804838

Epoch: 6| Step: 1
Training loss: 2.8687078202747434
Validation loss: 2.6197015296722896

Epoch: 6| Step: 2
Training loss: 3.0731307822594545
Validation loss: 2.6205596382081793

Epoch: 6| Step: 3
Training loss: 3.4759992850492774
Validation loss: 2.6184983510665134

Epoch: 6| Step: 4
Training loss: 2.624511491642432
Validation loss: 2.6193086822379112

Epoch: 6| Step: 5
Training loss: 3.52032129902085
Validation loss: 2.6186197289059487

Epoch: 6| Step: 6
Training loss: 2.163308022423999
Validation loss: 2.617544076376877

Epoch: 6| Step: 7
Training loss: 2.912616442534238
Validation loss: 2.6179395172866333

Epoch: 6| Step: 8
Training loss: 3.2966628164558824
Validation loss: 2.6187071006676286

Epoch: 6| Step: 9
Training loss: 3.036597971161865
Validation loss: 2.6155503700663267

Epoch: 6| Step: 10
Training loss: 2.8950323373836553
Validation loss: 2.6192052599107467

Epoch: 6| Step: 11
Training loss: 2.5448082337144022
Validation loss: 2.6162558800099203

Epoch: 6| Step: 12
Training loss: 3.186870737231932
Validation loss: 2.614655824159743

Epoch: 6| Step: 13
Training loss: 2.9783371168332082
Validation loss: 2.6177006622009187

Epoch: 93| Step: 0
Training loss: 3.0750549807711773
Validation loss: 2.616882574849574

Epoch: 6| Step: 1
Training loss: 3.014004128436202
Validation loss: 2.6264361541526102

Epoch: 6| Step: 2
Training loss: 2.573938473159535
Validation loss: 2.6294390505051

Epoch: 6| Step: 3
Training loss: 3.552581230163727
Validation loss: 2.6327798419673645

Epoch: 6| Step: 4
Training loss: 3.4645267930791617
Validation loss: 2.6216183613872968

Epoch: 6| Step: 5
Training loss: 2.3399385105107338
Validation loss: 2.616938841677126

Epoch: 6| Step: 6
Training loss: 2.8300483022820497
Validation loss: 2.6158636779246125

Epoch: 6| Step: 7
Training loss: 3.1960018692106624
Validation loss: 2.614774493942799

Epoch: 6| Step: 8
Training loss: 2.946664676866967
Validation loss: 2.6144232330572366

Epoch: 6| Step: 9
Training loss: 2.7000999502826026
Validation loss: 2.614563111421219

Epoch: 6| Step: 10
Training loss: 3.203307355946756
Validation loss: 2.6154419706932472

Epoch: 6| Step: 11
Training loss: 2.5312426531649748
Validation loss: 2.614660002018993

Epoch: 6| Step: 12
Training loss: 2.612704408670717
Validation loss: 2.615723325160561

Epoch: 6| Step: 13
Training loss: 3.441537739799657
Validation loss: 2.6188124026406046

Epoch: 94| Step: 0
Training loss: 2.456247565581302
Validation loss: 2.624152762184451

Epoch: 6| Step: 1
Training loss: 2.7985654868757806
Validation loss: 2.621563839833589

Epoch: 6| Step: 2
Training loss: 2.9494295764876566
Validation loss: 2.628012993072003

Epoch: 6| Step: 3
Training loss: 3.3902586286345118
Validation loss: 2.634941953425331

Epoch: 6| Step: 4
Training loss: 3.4140499298073794
Validation loss: 2.6155282145846273

Epoch: 6| Step: 5
Training loss: 3.019031715279548
Validation loss: 2.6128810529111157

Epoch: 6| Step: 6
Training loss: 2.915531882284296
Validation loss: 2.6113993726978983

Epoch: 6| Step: 7
Training loss: 2.8094571925817737
Validation loss: 2.6107342472139066

Epoch: 6| Step: 8
Training loss: 2.749427562435778
Validation loss: 2.6142692467144437

Epoch: 6| Step: 9
Training loss: 3.0004323012093814
Validation loss: 2.6141764280829642

Epoch: 6| Step: 10
Training loss: 2.8429631412678256
Validation loss: 2.613387821211578

Epoch: 6| Step: 11
Training loss: 2.4678984513373483
Validation loss: 2.6157831853475955

Epoch: 6| Step: 12
Training loss: 3.4448455009641137
Validation loss: 2.6120498836263915

Epoch: 6| Step: 13
Training loss: 3.1900389787929333
Validation loss: 2.61559922633731

Epoch: 95| Step: 0
Training loss: 2.848664951502793
Validation loss: 2.6191742909483335

Epoch: 6| Step: 1
Training loss: 2.936370957287875
Validation loss: 2.609028189507666

Epoch: 6| Step: 2
Training loss: 2.846854056355625
Validation loss: 2.610516623681706

Epoch: 6| Step: 3
Training loss: 2.8529963820548505
Validation loss: 2.611504966390516

Epoch: 6| Step: 4
Training loss: 2.9567932274992694
Validation loss: 2.6124840622612178

Epoch: 6| Step: 5
Training loss: 2.380804898371836
Validation loss: 2.6141435715570216

Epoch: 6| Step: 6
Training loss: 3.1628050766303617
Validation loss: 2.6117844108066643

Epoch: 6| Step: 7
Training loss: 3.578454814519544
Validation loss: 2.612695683638326

Epoch: 6| Step: 8
Training loss: 3.1144305205520624
Validation loss: 2.615545244839082

Epoch: 6| Step: 9
Training loss: 3.007041138662212
Validation loss: 2.619868986313543

Epoch: 6| Step: 10
Training loss: 2.6454258902909618
Validation loss: 2.625828797212382

Epoch: 6| Step: 11
Training loss: 3.084914257521159
Validation loss: 2.6522840248221997

Epoch: 6| Step: 12
Training loss: 2.965774329780185
Validation loss: 2.6909709188824444

Epoch: 6| Step: 13
Training loss: 2.8046772141121887
Validation loss: 2.6650621069312828

Epoch: 96| Step: 0
Training loss: 2.5326972874036056
Validation loss: 2.6128528043322357

Epoch: 6| Step: 1
Training loss: 3.6893172877736773
Validation loss: 2.602448739392205

Epoch: 6| Step: 2
Training loss: 3.36621872845958
Validation loss: 2.605771673630175

Epoch: 6| Step: 3
Training loss: 2.403346998182047
Validation loss: 2.6320344472641257

Epoch: 6| Step: 4
Training loss: 3.1518183652081198
Validation loss: 2.613273740399852

Epoch: 6| Step: 5
Training loss: 2.9646967473232175
Validation loss: 2.6040925840279536

Epoch: 6| Step: 6
Training loss: 3.286217698337141
Validation loss: 2.602913497803925

Epoch: 6| Step: 7
Training loss: 2.910604844305112
Validation loss: 2.60088504158361

Epoch: 6| Step: 8
Training loss: 2.475895837050269
Validation loss: 2.5994124759977995

Epoch: 6| Step: 9
Training loss: 2.6376053739352407
Validation loss: 2.5998622644036047

Epoch: 6| Step: 10
Training loss: 3.0512488638107267
Validation loss: 2.6038429114789277

Epoch: 6| Step: 11
Training loss: 2.7622741399755095
Validation loss: 2.6098364680538517

Epoch: 6| Step: 12
Training loss: 2.8009686906093623
Validation loss: 2.610071702427293

Epoch: 6| Step: 13
Training loss: 3.320210821053421
Validation loss: 2.615074125051194

Epoch: 97| Step: 0
Training loss: 2.1500000975852767
Validation loss: 2.615472747624873

Epoch: 6| Step: 1
Training loss: 2.57838780768693
Validation loss: 2.6094309492758803

Epoch: 6| Step: 2
Training loss: 2.777348900641321
Validation loss: 2.6142310605576187

Epoch: 6| Step: 3
Training loss: 2.926321308321445
Validation loss: 2.617598966659047

Epoch: 6| Step: 4
Training loss: 2.450039909971942
Validation loss: 2.6109695185270203

Epoch: 6| Step: 5
Training loss: 3.505260601286953
Validation loss: 2.6053877660472797

Epoch: 6| Step: 6
Training loss: 3.5520871219260557
Validation loss: 2.6035272737877313

Epoch: 6| Step: 7
Training loss: 3.077052825246175
Validation loss: 2.598163772214728

Epoch: 6| Step: 8
Training loss: 2.9434199640205483
Validation loss: 2.5978415318954404

Epoch: 6| Step: 9
Training loss: 3.2388566521737387
Validation loss: 2.5958270688842955

Epoch: 6| Step: 10
Training loss: 2.866615342264778
Validation loss: 2.5959562882818994

Epoch: 6| Step: 11
Training loss: 3.075963844652339
Validation loss: 2.5949788449859743

Epoch: 6| Step: 12
Training loss: 3.0134062041133403
Validation loss: 2.595619230859766

Epoch: 6| Step: 13
Training loss: 2.857651488125851
Validation loss: 2.601211887354058

Epoch: 98| Step: 0
Training loss: 2.829349147509148
Validation loss: 2.5915946490537447

Epoch: 6| Step: 1
Training loss: 3.413191834909384
Validation loss: 2.588983230000624

Epoch: 6| Step: 2
Training loss: 2.89799261663219
Validation loss: 2.5875847738625337

Epoch: 6| Step: 3
Training loss: 2.886249591865362
Validation loss: 2.592177858383994

Epoch: 6| Step: 4
Training loss: 3.23078121717556
Validation loss: 2.590360177549728

Epoch: 6| Step: 5
Training loss: 3.111038759692113
Validation loss: 2.58939288863332

Epoch: 6| Step: 6
Training loss: 2.681283014267628
Validation loss: 2.5900277507152247

Epoch: 6| Step: 7
Training loss: 3.1582405687328876
Validation loss: 2.5888759195605355

Epoch: 6| Step: 8
Training loss: 2.9637220670814868
Validation loss: 2.5880737690618707

Epoch: 6| Step: 9
Training loss: 2.7492189165068153
Validation loss: 2.5891514812498

Epoch: 6| Step: 10
Training loss: 2.3666593761958628
Validation loss: 2.5884315482320837

Epoch: 6| Step: 11
Training loss: 3.0782836253543953
Validation loss: 2.591784185338035

Epoch: 6| Step: 12
Training loss: 2.885194037670563
Validation loss: 2.5948673247947744

Epoch: 6| Step: 13
Training loss: 2.8855179494624394
Validation loss: 2.596033706230637

Epoch: 99| Step: 0
Training loss: 3.0226239038759397
Validation loss: 2.596578296180897

Epoch: 6| Step: 1
Training loss: 2.8776146982037676
Validation loss: 2.6004754769957623

Epoch: 6| Step: 2
Training loss: 3.084111776975805
Validation loss: 2.5947757673843275

Epoch: 6| Step: 3
Training loss: 2.9707252757433547
Validation loss: 2.6009227987715713

Epoch: 6| Step: 4
Training loss: 2.2645804266280747
Validation loss: 2.6047457720938207

Epoch: 6| Step: 5
Training loss: 2.5741234444788716
Validation loss: 2.60059570275178

Epoch: 6| Step: 6
Training loss: 2.895704929789165
Validation loss: 2.5969238018412364

Epoch: 6| Step: 7
Training loss: 3.553419352260239
Validation loss: 2.5913998705252244

Epoch: 6| Step: 8
Training loss: 2.6566054162495574
Validation loss: 2.5996788887562023

Epoch: 6| Step: 9
Training loss: 3.3407776357896064
Validation loss: 2.5913371746329887

Epoch: 6| Step: 10
Training loss: 2.838839472742683
Validation loss: 2.5959524299151577

Epoch: 6| Step: 11
Training loss: 2.9196086396578305
Validation loss: 2.6010053519000293

Epoch: 6| Step: 12
Training loss: 3.1197511461244978
Validation loss: 2.5898762872286856

Epoch: 6| Step: 13
Training loss: 2.7021655546417547
Validation loss: 2.5847724034946804

Epoch: 100| Step: 0
Training loss: 2.7823780643859792
Validation loss: 2.584898289739376

Epoch: 6| Step: 1
Training loss: 2.64169948770088
Validation loss: 2.5814413548233075

Epoch: 6| Step: 2
Training loss: 3.0884011007725225
Validation loss: 2.5841607155865782

Epoch: 6| Step: 3
Training loss: 3.497573965407115
Validation loss: 2.5815808683108554

Epoch: 6| Step: 4
Training loss: 3.086882395885109
Validation loss: 2.583518738763811

Epoch: 6| Step: 5
Training loss: 3.2107527556722024
Validation loss: 2.5837242718505826

Epoch: 6| Step: 6
Training loss: 3.1878775578705354
Validation loss: 2.5896501301873474

Epoch: 6| Step: 7
Training loss: 2.988368692552335
Validation loss: 2.585027277431188

Epoch: 6| Step: 8
Training loss: 1.9104806823432714
Validation loss: 2.586229010062984

Epoch: 6| Step: 9
Training loss: 3.080335723612934
Validation loss: 2.5830570153221637

Epoch: 6| Step: 10
Training loss: 2.6576463507244146
Validation loss: 2.5821374827244803

Epoch: 6| Step: 11
Training loss: 3.0362862504952144
Validation loss: 2.583444305825635

Epoch: 6| Step: 12
Training loss: 2.8679371199478223
Validation loss: 2.582350238349448

Epoch: 6| Step: 13
Training loss: 2.89279176076374
Validation loss: 2.582894347169689

Epoch: 101| Step: 0
Training loss: 3.030413168003834
Validation loss: 2.5806299891718045

Epoch: 6| Step: 1
Training loss: 3.277116042400526
Validation loss: 2.582256192476844

Epoch: 6| Step: 2
Training loss: 3.225501673513347
Validation loss: 2.587311454071265

Epoch: 6| Step: 3
Training loss: 2.367855770847981
Validation loss: 2.589490837348863

Epoch: 6| Step: 4
Training loss: 2.4066215327390514
Validation loss: 2.5975278682165794

Epoch: 6| Step: 5
Training loss: 2.8046509466737963
Validation loss: 2.6231770345593635

Epoch: 6| Step: 6
Training loss: 3.179644910072568
Validation loss: 2.6179955302978786

Epoch: 6| Step: 7
Training loss: 3.2709201064211784
Validation loss: 2.642657767477987

Epoch: 6| Step: 8
Training loss: 3.4616998732664914
Validation loss: 2.6313672930569814

Epoch: 6| Step: 9
Training loss: 2.8078362686263554
Validation loss: 2.6059585988737464

Epoch: 6| Step: 10
Training loss: 3.150839067151384
Validation loss: 2.5896290207667128

Epoch: 6| Step: 11
Training loss: 2.4759884719580265
Validation loss: 2.582678282773258

Epoch: 6| Step: 12
Training loss: 2.4490523821772765
Validation loss: 2.5769382225024704

Epoch: 6| Step: 13
Training loss: 2.8098942871843713
Validation loss: 2.5731831439546893

Epoch: 102| Step: 0
Training loss: 3.188004098561714
Validation loss: 2.5764569994379336

Epoch: 6| Step: 1
Training loss: 3.532776089277759
Validation loss: 2.5745587634857845

Epoch: 6| Step: 2
Training loss: 3.3424100954209193
Validation loss: 2.5745700125531585

Epoch: 6| Step: 3
Training loss: 3.014988649261516
Validation loss: 2.5744406597499165

Epoch: 6| Step: 4
Training loss: 3.1795861230383995
Validation loss: 2.57407529590778

Epoch: 6| Step: 5
Training loss: 2.382817702991246
Validation loss: 2.571815055280455

Epoch: 6| Step: 6
Training loss: 3.0829714657245337
Validation loss: 2.5758456339290134

Epoch: 6| Step: 7
Training loss: 2.8192029973853088
Validation loss: 2.5793001312717707

Epoch: 6| Step: 8
Training loss: 2.551146500098695
Validation loss: 2.592063301516815

Epoch: 6| Step: 9
Training loss: 2.3153090041303197
Validation loss: 2.6078167873645612

Epoch: 6| Step: 10
Training loss: 2.4971050667311605
Validation loss: 2.6157053737959983

Epoch: 6| Step: 11
Training loss: 2.674560357445937
Validation loss: 2.631769823347414

Epoch: 6| Step: 12
Training loss: 3.086306315727509
Validation loss: 2.623993748606512

Epoch: 6| Step: 13
Training loss: 3.321571308942228
Validation loss: 2.6557287786962553

Epoch: 103| Step: 0
Training loss: 3.0605619876880383
Validation loss: 2.696004348424934

Epoch: 6| Step: 1
Training loss: 3.264384202821845
Validation loss: 2.7121693223157273

Epoch: 6| Step: 2
Training loss: 2.9707530441955567
Validation loss: 2.717032931704239

Epoch: 6| Step: 3
Training loss: 3.3777745462982156
Validation loss: 2.6892189248418883

Epoch: 6| Step: 4
Training loss: 3.0428907117520656
Validation loss: 2.6674896685953042

Epoch: 6| Step: 5
Training loss: 2.299138724735816
Validation loss: 2.6485636289628736

Epoch: 6| Step: 6
Training loss: 3.410938221349915
Validation loss: 2.6500031977189393

Epoch: 6| Step: 7
Training loss: 2.6288892000050743
Validation loss: 2.6349464323511835

Epoch: 6| Step: 8
Training loss: 2.5350014473273306
Validation loss: 2.635590705408695

Epoch: 6| Step: 9
Training loss: 2.5694736398865388
Validation loss: 2.6325789938037167

Epoch: 6| Step: 10
Training loss: 2.611957665326715
Validation loss: 2.6347563755964

Epoch: 6| Step: 11
Training loss: 2.5378052401054227
Validation loss: 2.646264432965718

Epoch: 6| Step: 12
Training loss: 3.8132716164118476
Validation loss: 2.6488932371930853

Epoch: 6| Step: 13
Training loss: 3.529822001737855
Validation loss: 2.6310003292987947

Epoch: 104| Step: 0
Training loss: 2.7516944173441336
Validation loss: 2.6251188584318172

Epoch: 6| Step: 1
Training loss: 2.9608576217787497
Validation loss: 2.624571675925696

Epoch: 6| Step: 2
Training loss: 3.462389363748851
Validation loss: 2.6221190336012863

Epoch: 6| Step: 3
Training loss: 3.417199690264608
Validation loss: 2.622303005475781

Epoch: 6| Step: 4
Training loss: 3.2568557029478935
Validation loss: 2.620622771714748

Epoch: 6| Step: 5
Training loss: 3.3818814800301182
Validation loss: 2.6173111660005723

Epoch: 6| Step: 6
Training loss: 2.5448932075203285
Validation loss: 2.6198230308433472

Epoch: 6| Step: 7
Training loss: 2.8741536760649553
Validation loss: 2.617389267729442

Epoch: 6| Step: 8
Training loss: 2.3686128360219136
Validation loss: 2.6176646611106635

Epoch: 6| Step: 9
Training loss: 3.1750666153294778
Validation loss: 2.6200391807873524

Epoch: 6| Step: 10
Training loss: 3.180512192461536
Validation loss: 2.6246476588832808

Epoch: 6| Step: 11
Training loss: 2.659923212764371
Validation loss: 2.632281179959221

Epoch: 6| Step: 12
Training loss: 2.328801204100035
Validation loss: 2.637546505693236

Epoch: 6| Step: 13
Training loss: 2.603275685797539
Validation loss: 2.624300027897489

Epoch: 105| Step: 0
Training loss: 2.775152573386283
Validation loss: 2.623474828482165

Epoch: 6| Step: 1
Training loss: 2.511009009244458
Validation loss: 2.625375687591382

Epoch: 6| Step: 2
Training loss: 2.861868849558406
Validation loss: 2.6179613487940623

Epoch: 6| Step: 3
Training loss: 2.976484482911705
Validation loss: 2.6299433466374436

Epoch: 6| Step: 4
Training loss: 3.08925726300218
Validation loss: 2.626772269095905

Epoch: 6| Step: 5
Training loss: 2.8227203319633434
Validation loss: 2.6275571506317332

Epoch: 6| Step: 6
Training loss: 3.512299724041424
Validation loss: 2.6265433853185036

Epoch: 6| Step: 7
Training loss: 2.1166074739524814
Validation loss: 2.6194137349241733

Epoch: 6| Step: 8
Training loss: 3.52588292961488
Validation loss: 2.6331663948230197

Epoch: 6| Step: 9
Training loss: 3.28982803243136
Validation loss: 2.6390070649308046

Epoch: 6| Step: 10
Training loss: 2.4521130460906786
Validation loss: 2.6546027058735486

Epoch: 6| Step: 11
Training loss: 2.9535291284222955
Validation loss: 2.6568605622453414

Epoch: 6| Step: 12
Training loss: 3.0496075236961206
Validation loss: 2.6370395814320173

Epoch: 6| Step: 13
Training loss: 3.3121359283178293
Validation loss: 2.6138544577089937

Epoch: 106| Step: 0
Training loss: 2.7719824184173927
Validation loss: 2.611775481479025

Epoch: 6| Step: 1
Training loss: 3.2517871344648457
Validation loss: 2.6075717520545334

Epoch: 6| Step: 2
Training loss: 3.0376575821553327
Validation loss: 2.6049170619287674

Epoch: 6| Step: 3
Training loss: 3.1973061905642854
Validation loss: 2.60411612151941

Epoch: 6| Step: 4
Training loss: 3.3418655076328188
Validation loss: 2.6058443571146808

Epoch: 6| Step: 5
Training loss: 2.429949289428554
Validation loss: 2.6020828421914657

Epoch: 6| Step: 6
Training loss: 3.188675158918513
Validation loss: 2.5969007737068686

Epoch: 6| Step: 7
Training loss: 3.1574124754360273
Validation loss: 2.597751544811565

Epoch: 6| Step: 8
Training loss: 3.2831084301855564
Validation loss: 2.5916565335168

Epoch: 6| Step: 9
Training loss: 2.7824586106724
Validation loss: 2.5820647221644952

Epoch: 6| Step: 10
Training loss: 2.1145156949755886
Validation loss: 2.577653835743384

Epoch: 6| Step: 11
Training loss: 3.330291615911327
Validation loss: 2.5831849849181707

Epoch: 6| Step: 12
Training loss: 2.4006610714904504
Validation loss: 2.578367900126552

Epoch: 6| Step: 13
Training loss: 2.3185333726565314
Validation loss: 2.575017180177918

Epoch: 107| Step: 0
Training loss: 3.2658497126166033
Validation loss: 2.5854059578998525

Epoch: 6| Step: 1
Training loss: 3.6595676074985333
Validation loss: 2.576139472182271

Epoch: 6| Step: 2
Training loss: 2.9171090653371645
Validation loss: 2.573033752673471

Epoch: 6| Step: 3
Training loss: 2.86344128586909
Validation loss: 2.5779496188902447

Epoch: 6| Step: 4
Training loss: 2.9248798443494795
Validation loss: 2.5829709407844326

Epoch: 6| Step: 5
Training loss: 2.8150521460898514
Validation loss: 2.5911554237534937

Epoch: 6| Step: 6
Training loss: 3.0432261993447707
Validation loss: 2.600812175146967

Epoch: 6| Step: 7
Training loss: 3.218895325574349
Validation loss: 2.6153436279365696

Epoch: 6| Step: 8
Training loss: 2.704016742361029
Validation loss: 2.633113914547357

Epoch: 6| Step: 9
Training loss: 2.442627624176101
Validation loss: 2.627382196603922

Epoch: 6| Step: 10
Training loss: 2.251487981660413
Validation loss: 2.63506314735162

Epoch: 6| Step: 11
Training loss: 2.870099078339008
Validation loss: 2.62524534798717

Epoch: 6| Step: 12
Training loss: 2.7338675763835774
Validation loss: 2.6305563465074235

Epoch: 6| Step: 13
Training loss: 2.848248622907682
Validation loss: 2.6215036930907534

Epoch: 108| Step: 0
Training loss: 3.1733952529326457
Validation loss: 2.5944029155155275

Epoch: 6| Step: 1
Training loss: 2.9407869170768546
Validation loss: 2.5828118335439214

Epoch: 6| Step: 2
Training loss: 3.1819742214038618
Validation loss: 2.5718301231906633

Epoch: 6| Step: 3
Training loss: 2.645342793885485
Validation loss: 2.561356245972055

Epoch: 6| Step: 4
Training loss: 2.2582935493972043
Validation loss: 2.556403985936397

Epoch: 6| Step: 5
Training loss: 3.7891069232656847
Validation loss: 2.557330171068689

Epoch: 6| Step: 6
Training loss: 2.1725851311372297
Validation loss: 2.5538857717202488

Epoch: 6| Step: 7
Training loss: 2.813617060608127
Validation loss: 2.553987032024224

Epoch: 6| Step: 8
Training loss: 2.950957294895815
Validation loss: 2.5521811105976058

Epoch: 6| Step: 9
Training loss: 3.004265454943536
Validation loss: 2.552135152753184

Epoch: 6| Step: 10
Training loss: 3.410475463608911
Validation loss: 2.5533114821769916

Epoch: 6| Step: 11
Training loss: 2.933675670876815
Validation loss: 2.5594785020875257

Epoch: 6| Step: 12
Training loss: 2.5710363789094903
Validation loss: 2.561965656068321

Epoch: 6| Step: 13
Training loss: 2.210171408414183
Validation loss: 2.5698875766458134

Epoch: 109| Step: 0
Training loss: 3.3673135331147663
Validation loss: 2.5813092864424467

Epoch: 6| Step: 1
Training loss: 2.773867549597266
Validation loss: 2.587918603195979

Epoch: 6| Step: 2
Training loss: 3.3986025013823467
Validation loss: 2.595167743906543

Epoch: 6| Step: 3
Training loss: 2.856295568991663
Validation loss: 2.578850772708278

Epoch: 6| Step: 4
Training loss: 2.7924272345724748
Validation loss: 2.57736615709219

Epoch: 6| Step: 5
Training loss: 2.9301994995316725
Validation loss: 2.570830241299989

Epoch: 6| Step: 6
Training loss: 3.3276040112685505
Validation loss: 2.563236202849264

Epoch: 6| Step: 7
Training loss: 3.0693673190807447
Validation loss: 2.554064140221984

Epoch: 6| Step: 8
Training loss: 1.6900098996747135
Validation loss: 2.554289322502111

Epoch: 6| Step: 9
Training loss: 2.6678197771652115
Validation loss: 2.5525241691225524

Epoch: 6| Step: 10
Training loss: 2.9192476750912024
Validation loss: 2.5516331235173295

Epoch: 6| Step: 11
Training loss: 2.950234426461996
Validation loss: 2.555202372413135

Epoch: 6| Step: 12
Training loss: 2.9226242981413018
Validation loss: 2.558678555548907

Epoch: 6| Step: 13
Training loss: 2.609530781190315
Validation loss: 2.5650383327379704

Epoch: 110| Step: 0
Training loss: 2.9614585880937354
Validation loss: 2.568960935166028

Epoch: 6| Step: 1
Training loss: 3.430597484364997
Validation loss: 2.583820301750947

Epoch: 6| Step: 2
Training loss: 2.401400646148821
Validation loss: 2.5811523482591987

Epoch: 6| Step: 3
Training loss: 2.7900026590751636
Validation loss: 2.582662118756615

Epoch: 6| Step: 4
Training loss: 3.376520732601894
Validation loss: 2.5827575250934904

Epoch: 6| Step: 5
Training loss: 2.6748191273227433
Validation loss: 2.571144485757016

Epoch: 6| Step: 6
Training loss: 2.5096128662168695
Validation loss: 2.559361144869041

Epoch: 6| Step: 7
Training loss: 2.5169806766609413
Validation loss: 2.559122011530226

Epoch: 6| Step: 8
Training loss: 3.104312782347644
Validation loss: 2.5577677969431063

Epoch: 6| Step: 9
Training loss: 2.904567764876013
Validation loss: 2.55597411645993

Epoch: 6| Step: 10
Training loss: 2.4584181711676703
Validation loss: 2.5567760532090826

Epoch: 6| Step: 11
Training loss: 3.2437164010896886
Validation loss: 2.5562891090879964

Epoch: 6| Step: 12
Training loss: 2.656776106848559
Validation loss: 2.5593863237765957

Epoch: 6| Step: 13
Training loss: 3.5917150955888553
Validation loss: 2.560807386144415

Epoch: 111| Step: 0
Training loss: 3.312861296905468
Validation loss: 2.5590132074453362

Epoch: 6| Step: 1
Training loss: 2.8627835995310824
Validation loss: 2.5595856067372225

Epoch: 6| Step: 2
Training loss: 3.056461531294833
Validation loss: 2.5642548711664164

Epoch: 6| Step: 3
Training loss: 2.443469440716385
Validation loss: 2.575493047279771

Epoch: 6| Step: 4
Training loss: 2.575877926984616
Validation loss: 2.567334514546146

Epoch: 6| Step: 5
Training loss: 3.073713985820082
Validation loss: 2.5596728342250166

Epoch: 6| Step: 6
Training loss: 3.0067017721366756
Validation loss: 2.551630523337357

Epoch: 6| Step: 7
Training loss: 3.087115022079012
Validation loss: 2.55255707459619

Epoch: 6| Step: 8
Training loss: 3.040306013415821
Validation loss: 2.5502532380833034

Epoch: 6| Step: 9
Training loss: 2.6591533277131814
Validation loss: 2.5516186255712396

Epoch: 6| Step: 10
Training loss: 3.1454145813857264
Validation loss: 2.5517309307585347

Epoch: 6| Step: 11
Training loss: 2.6093910810694596
Validation loss: 2.549605942169209

Epoch: 6| Step: 12
Training loss: 2.8212183292827078
Validation loss: 2.5509786063555833

Epoch: 6| Step: 13
Training loss: 2.4499934916507145
Validation loss: 2.551129332372741

Epoch: 112| Step: 0
Training loss: 2.474895505914897
Validation loss: 2.550441690258896

Epoch: 6| Step: 1
Training loss: 2.572909727100069
Validation loss: 2.5542746609798024

Epoch: 6| Step: 2
Training loss: 2.667288072027408
Validation loss: 2.552453551939508

Epoch: 6| Step: 3
Training loss: 2.9483872612017237
Validation loss: 2.555098931850044

Epoch: 6| Step: 4
Training loss: 3.315919083218871
Validation loss: 2.55349914240959

Epoch: 6| Step: 5
Training loss: 3.617044862114085
Validation loss: 2.5553257555615922

Epoch: 6| Step: 6
Training loss: 2.6110957519494358
Validation loss: 2.557117102741538

Epoch: 6| Step: 7
Training loss: 2.7211101416489227
Validation loss: 2.551268573126299

Epoch: 6| Step: 8
Training loss: 2.7903836751484397
Validation loss: 2.552435109394539

Epoch: 6| Step: 9
Training loss: 2.559402827110437
Validation loss: 2.5585048995457558

Epoch: 6| Step: 10
Training loss: 3.120209034984206
Validation loss: 2.5543748701241933

Epoch: 6| Step: 11
Training loss: 2.9075921353857104
Validation loss: 2.5688004202560464

Epoch: 6| Step: 12
Training loss: 3.114298999953023
Validation loss: 2.5845122705401127

Epoch: 6| Step: 13
Training loss: 2.647582869921277
Validation loss: 2.6109236175216544

Epoch: 113| Step: 0
Training loss: 2.756398819346349
Validation loss: 2.656445997270963

Epoch: 6| Step: 1
Training loss: 3.4953174602966173
Validation loss: 2.6609620757290373

Epoch: 6| Step: 2
Training loss: 2.824645035309833
Validation loss: 2.672847501495323

Epoch: 6| Step: 3
Training loss: 3.046570278482175
Validation loss: 2.6195932913101068

Epoch: 6| Step: 4
Training loss: 2.6409435192974384
Validation loss: 2.5656681095289717

Epoch: 6| Step: 5
Training loss: 2.9670612551412305
Validation loss: 2.5479351016437795

Epoch: 6| Step: 6
Training loss: 2.4621090961149297
Validation loss: 2.543228001361685

Epoch: 6| Step: 7
Training loss: 2.773923847377098
Validation loss: 2.5529016381155962

Epoch: 6| Step: 8
Training loss: 3.1253451347497143
Validation loss: 2.5604083741180914

Epoch: 6| Step: 9
Training loss: 3.3174487880269745
Validation loss: 2.5656650484480226

Epoch: 6| Step: 10
Training loss: 3.0627206216869256
Validation loss: 2.559605748517282

Epoch: 6| Step: 11
Training loss: 2.275495613524757
Validation loss: 2.562156950415311

Epoch: 6| Step: 12
Training loss: 2.9782410541990223
Validation loss: 2.555786048146849

Epoch: 6| Step: 13
Training loss: 3.148911811938409
Validation loss: 2.551721958059064

Epoch: 114| Step: 0
Training loss: 2.1688400030011814
Validation loss: 2.545129125892417

Epoch: 6| Step: 1
Training loss: 2.3978459625912047
Validation loss: 2.540836675463181

Epoch: 6| Step: 2
Training loss: 2.9003416320567483
Validation loss: 2.5533740776158176

Epoch: 6| Step: 3
Training loss: 3.2229477259284525
Validation loss: 2.5691148670911645

Epoch: 6| Step: 4
Training loss: 2.8532975444450637
Validation loss: 2.587100825214393

Epoch: 6| Step: 5
Training loss: 2.9679251076948105
Validation loss: 2.6044771904340207

Epoch: 6| Step: 6
Training loss: 2.740392287497135
Validation loss: 2.6124240783942225

Epoch: 6| Step: 7
Training loss: 2.9439203427671248
Validation loss: 2.5929996350482165

Epoch: 6| Step: 8
Training loss: 3.59203835236225
Validation loss: 2.586391744040231

Epoch: 6| Step: 9
Training loss: 3.133029235800843
Validation loss: 2.5793926425158147

Epoch: 6| Step: 10
Training loss: 3.190278880207198
Validation loss: 2.563511373491559

Epoch: 6| Step: 11
Training loss: 2.5114194415791538
Validation loss: 2.558459045275909

Epoch: 6| Step: 12
Training loss: 2.860156843513067
Validation loss: 2.550604513385747

Epoch: 6| Step: 13
Training loss: 2.683273096375974
Validation loss: 2.5426780907958864

Epoch: 115| Step: 0
Training loss: 2.71179959444006
Validation loss: 2.5367777313498636

Epoch: 6| Step: 1
Training loss: 2.9110520590632127
Validation loss: 2.533737806390643

Epoch: 6| Step: 2
Training loss: 2.534906078156199
Validation loss: 2.5401771843666614

Epoch: 6| Step: 3
Training loss: 3.165708815283178
Validation loss: 2.535241851683625

Epoch: 6| Step: 4
Training loss: 3.6467783257256565
Validation loss: 2.5376074148652172

Epoch: 6| Step: 5
Training loss: 2.9808037445872073
Validation loss: 2.5374345001216394

Epoch: 6| Step: 6
Training loss: 3.3020937144279756
Validation loss: 2.5352894626530476

Epoch: 6| Step: 7
Training loss: 2.3670317847273763
Validation loss: 2.5371396622656994

Epoch: 6| Step: 8
Training loss: 2.822880218007793
Validation loss: 2.5444353363047956

Epoch: 6| Step: 9
Training loss: 2.065269691276439
Validation loss: 2.5477738386323057

Epoch: 6| Step: 10
Training loss: 2.890727768179515
Validation loss: 2.5604771228753362

Epoch: 6| Step: 11
Training loss: 2.2679480908826446
Validation loss: 2.5820584010843364

Epoch: 6| Step: 12
Training loss: 3.6237797492004575
Validation loss: 2.597622069298096

Epoch: 6| Step: 13
Training loss: 2.4986082017518907
Validation loss: 2.5512119653135024

Epoch: 116| Step: 0
Training loss: 3.097763386782193
Validation loss: 2.560993836422844

Epoch: 6| Step: 1
Training loss: 3.197024010609564
Validation loss: 2.565080684298068

Epoch: 6| Step: 2
Training loss: 3.828254043583941
Validation loss: 2.5674059905619275

Epoch: 6| Step: 3
Training loss: 2.7979212674017653
Validation loss: 2.5571346834176816

Epoch: 6| Step: 4
Training loss: 2.7281227347767656
Validation loss: 2.5467232863375004

Epoch: 6| Step: 5
Training loss: 2.09614676324244
Validation loss: 2.54415977817467

Epoch: 6| Step: 6
Training loss: 2.3444084768363656
Validation loss: 2.5389849210613824

Epoch: 6| Step: 7
Training loss: 3.144503651373453
Validation loss: 2.54900539311219

Epoch: 6| Step: 8
Training loss: 2.9744894663537167
Validation loss: 2.5544297870221166

Epoch: 6| Step: 9
Training loss: 2.7496114803175544
Validation loss: 2.556977839584913

Epoch: 6| Step: 10
Training loss: 2.7421249860718424
Validation loss: 2.5516177213307087

Epoch: 6| Step: 11
Training loss: 2.8982404040340053
Validation loss: 2.549597619593621

Epoch: 6| Step: 12
Training loss: 2.5212784261240513
Validation loss: 2.5406646727032607

Epoch: 6| Step: 13
Training loss: 2.868235217346012
Validation loss: 2.5387410328752336

Epoch: 117| Step: 0
Training loss: 2.539960121532586
Validation loss: 2.537314054064391

Epoch: 6| Step: 1
Training loss: 2.957247969271061
Validation loss: 2.5291017840447894

Epoch: 6| Step: 2
Training loss: 2.521113881875093
Validation loss: 2.5344364412154192

Epoch: 6| Step: 3
Training loss: 3.2752363046904724
Validation loss: 2.5311414015998785

Epoch: 6| Step: 4
Training loss: 2.7602419432038876
Validation loss: 2.530421571262919

Epoch: 6| Step: 5
Training loss: 2.9121254217574317
Validation loss: 2.5276941298519806

Epoch: 6| Step: 6
Training loss: 2.23448725064956
Validation loss: 2.532153668239559

Epoch: 6| Step: 7
Training loss: 3.4536904264787087
Validation loss: 2.528174157699493

Epoch: 6| Step: 8
Training loss: 2.7270292303451273
Validation loss: 2.527327783896829

Epoch: 6| Step: 9
Training loss: 2.8487161722890595
Validation loss: 2.5289701198068926

Epoch: 6| Step: 10
Training loss: 3.0608989656679855
Validation loss: 2.52991266445444

Epoch: 6| Step: 11
Training loss: 3.3292131391264848
Validation loss: 2.53029735164425

Epoch: 6| Step: 12
Training loss: 2.4451807736148092
Validation loss: 2.541361863291026

Epoch: 6| Step: 13
Training loss: 3.0577219844904207
Validation loss: 2.562378509066554

Epoch: 118| Step: 0
Training loss: 2.4523244146707097
Validation loss: 2.5639742300457886

Epoch: 6| Step: 1
Training loss: 2.7294996995088936
Validation loss: 2.582535325888113

Epoch: 6| Step: 2
Training loss: 2.3970296996325287
Validation loss: 2.5760397812794404

Epoch: 6| Step: 3
Training loss: 2.8805061356529307
Validation loss: 2.549984603190321

Epoch: 6| Step: 4
Training loss: 2.871882199349994
Validation loss: 2.5432732371462703

Epoch: 6| Step: 5
Training loss: 3.0019326342725363
Validation loss: 2.537260213094421

Epoch: 6| Step: 6
Training loss: 3.270490316558905
Validation loss: 2.5357838564577593

Epoch: 6| Step: 7
Training loss: 2.4707900684121884
Validation loss: 2.52005103764707

Epoch: 6| Step: 8
Training loss: 2.5829891672885656
Validation loss: 2.5236080519303843

Epoch: 6| Step: 9
Training loss: 3.2619529411621566
Validation loss: 2.5250367303981207

Epoch: 6| Step: 10
Training loss: 2.8044012662143376
Validation loss: 2.526503814312599

Epoch: 6| Step: 11
Training loss: 3.4006201739453124
Validation loss: 2.529305071795098

Epoch: 6| Step: 12
Training loss: 2.9107488451284325
Validation loss: 2.5258273954930632

Epoch: 6| Step: 13
Training loss: 3.292854207536721
Validation loss: 2.525727621909047

Epoch: 119| Step: 0
Training loss: 3.332866318094248
Validation loss: 2.522378795742974

Epoch: 6| Step: 1
Training loss: 3.1741655469675276
Validation loss: 2.5207008622611893

Epoch: 6| Step: 2
Training loss: 2.3336086337850803
Validation loss: 2.521319670321233

Epoch: 6| Step: 3
Training loss: 3.183209242740547
Validation loss: 2.5198496820897454

Epoch: 6| Step: 4
Training loss: 2.748487316588793
Validation loss: 2.5217084386901623

Epoch: 6| Step: 5
Training loss: 2.8779200776052654
Validation loss: 2.527051760283176

Epoch: 6| Step: 6
Training loss: 3.283782708128926
Validation loss: 2.5395594330339306

Epoch: 6| Step: 7
Training loss: 2.9938464632998447
Validation loss: 2.5650432600468656

Epoch: 6| Step: 8
Training loss: 2.845010499046543
Validation loss: 2.5640683830651514

Epoch: 6| Step: 9
Training loss: 2.7804545432979464
Validation loss: 2.5829968969390222

Epoch: 6| Step: 10
Training loss: 2.7414148008224615
Validation loss: 2.546917787463362

Epoch: 6| Step: 11
Training loss: 2.1366861679131466
Validation loss: 2.5421622116162528

Epoch: 6| Step: 12
Training loss: 2.7996107818655336
Validation loss: 2.543461014607978

Epoch: 6| Step: 13
Training loss: 2.51834707894688
Validation loss: 2.5421975464109967

Epoch: 120| Step: 0
Training loss: 2.865569861494135
Validation loss: 2.5392575869144425

Epoch: 6| Step: 1
Training loss: 2.9589373191390433
Validation loss: 2.5319878543292305

Epoch: 6| Step: 2
Training loss: 3.1983636964036246
Validation loss: 2.518039619416444

Epoch: 6| Step: 3
Training loss: 2.7437492770322227
Validation loss: 2.5145584216813592

Epoch: 6| Step: 4
Training loss: 2.023440327881711
Validation loss: 2.519824987142857

Epoch: 6| Step: 5
Training loss: 2.434603412768868
Validation loss: 2.5186409725155916

Epoch: 6| Step: 6
Training loss: 2.7191082948511665
Validation loss: 2.5203971604091735

Epoch: 6| Step: 7
Training loss: 2.8716866017374936
Validation loss: 2.5206902108326505

Epoch: 6| Step: 8
Training loss: 3.2935903376584186
Validation loss: 2.5202959074757603

Epoch: 6| Step: 9
Training loss: 2.6995381278129087
Validation loss: 2.527446827331254

Epoch: 6| Step: 10
Training loss: 2.6489764090063943
Validation loss: 2.5289876721232347

Epoch: 6| Step: 11
Training loss: 3.195900412945136
Validation loss: 2.5322298720521093

Epoch: 6| Step: 12
Training loss: 3.3283734296033622
Validation loss: 2.551497018418934

Epoch: 6| Step: 13
Training loss: 2.7852846519972365
Validation loss: 2.562916179388747

Epoch: 121| Step: 0
Training loss: 2.8136220601099664
Validation loss: 2.584519811137967

Epoch: 6| Step: 1
Training loss: 2.999994595840673
Validation loss: 2.604492352864909

Epoch: 6| Step: 2
Training loss: 3.2208834494129324
Validation loss: 2.6125648242813115

Epoch: 6| Step: 3
Training loss: 2.904446770520273
Validation loss: 2.555513914930319

Epoch: 6| Step: 4
Training loss: 2.948892618298498
Validation loss: 2.541761811760322

Epoch: 6| Step: 5
Training loss: 3.4144384670346626
Validation loss: 2.5265992977039864

Epoch: 6| Step: 6
Training loss: 2.5399383442822243
Validation loss: 2.514398111447494

Epoch: 6| Step: 7
Training loss: 2.972953631129601
Validation loss: 2.518336523433829

Epoch: 6| Step: 8
Training loss: 2.7620778585477432
Validation loss: 2.518409920439424

Epoch: 6| Step: 9
Training loss: 2.5943504465770504
Validation loss: 2.518074703233307

Epoch: 6| Step: 10
Training loss: 2.770855284486788
Validation loss: 2.5146979176071387

Epoch: 6| Step: 11
Training loss: 2.6455331366739654
Validation loss: 2.5159158112467517

Epoch: 6| Step: 12
Training loss: 2.2796280202760353
Validation loss: 2.514354815450443

Epoch: 6| Step: 13
Training loss: 3.265670118978457
Validation loss: 2.5276409445539514

Epoch: 122| Step: 0
Training loss: 1.9483542809231844
Validation loss: 2.535876476200177

Epoch: 6| Step: 1
Training loss: 3.265454447549902
Validation loss: 2.54702539513908

Epoch: 6| Step: 2
Training loss: 3.1197820205836546
Validation loss: 2.56929569558431

Epoch: 6| Step: 3
Training loss: 2.692745766788407
Validation loss: 2.595819775442865

Epoch: 6| Step: 4
Training loss: 3.130421627519213
Validation loss: 2.641831154278157

Epoch: 6| Step: 5
Training loss: 3.265908990950362
Validation loss: 2.6290127709577034

Epoch: 6| Step: 6
Training loss: 2.945200788974825
Validation loss: 2.609674805062453

Epoch: 6| Step: 7
Training loss: 2.562625230659946
Validation loss: 2.589996609061799

Epoch: 6| Step: 8
Training loss: 3.1442799722486985
Validation loss: 2.590591690156299

Epoch: 6| Step: 9
Training loss: 2.9481999740787943
Validation loss: 2.571750861165972

Epoch: 6| Step: 10
Training loss: 2.7765310308232665
Validation loss: 2.5747176956929163

Epoch: 6| Step: 11
Training loss: 2.6855751951631763
Validation loss: 2.5591761704175715

Epoch: 6| Step: 12
Training loss: 2.8795844305411062
Validation loss: 2.5517436216843636

Epoch: 6| Step: 13
Training loss: 2.9550156772668847
Validation loss: 2.541057570843342

Epoch: 123| Step: 0
Training loss: 3.0115341347639797
Validation loss: 2.5403898640733384

Epoch: 6| Step: 1
Training loss: 3.1965076104915915
Validation loss: 2.5319101132968274

Epoch: 6| Step: 2
Training loss: 2.5128579411396563
Validation loss: 2.525015065064878

Epoch: 6| Step: 3
Training loss: 2.3659358476726995
Validation loss: 2.5308298319023264

Epoch: 6| Step: 4
Training loss: 2.92032096457441
Validation loss: 2.53615154341398

Epoch: 6| Step: 5
Training loss: 2.4764230008954473
Validation loss: 2.549286621154061

Epoch: 6| Step: 6
Training loss: 2.576762723806005
Validation loss: 2.5523071026887836

Epoch: 6| Step: 7
Training loss: 3.4766980091217095
Validation loss: 2.558992369748146

Epoch: 6| Step: 8
Training loss: 2.77791369635461
Validation loss: 2.56284430557049

Epoch: 6| Step: 9
Training loss: 2.5115193099461086
Validation loss: 2.5744330562703395

Epoch: 6| Step: 10
Training loss: 2.7437691759556
Validation loss: 2.549912039630913

Epoch: 6| Step: 11
Training loss: 3.406678619015424
Validation loss: 2.5312517460602195

Epoch: 6| Step: 12
Training loss: 2.5504757755208254
Validation loss: 2.519867690640437

Epoch: 6| Step: 13
Training loss: 3.6929721639386193
Validation loss: 2.520874033448249

Epoch: 124| Step: 0
Training loss: 3.2518111830884315
Validation loss: 2.5194202874027742

Epoch: 6| Step: 1
Training loss: 2.719004739687774
Validation loss: 2.522064666583283

Epoch: 6| Step: 2
Training loss: 2.933069012032568
Validation loss: 2.518341533974135

Epoch: 6| Step: 3
Training loss: 2.468051183760256
Validation loss: 2.5240094805179076

Epoch: 6| Step: 4
Training loss: 2.830323434416675
Validation loss: 2.527837969690499

Epoch: 6| Step: 5
Training loss: 3.385174285819496
Validation loss: 2.521989378489376

Epoch: 6| Step: 6
Training loss: 2.962260330742361
Validation loss: 2.525142143567256

Epoch: 6| Step: 7
Training loss: 3.1753004397521867
Validation loss: 2.5207998066232626

Epoch: 6| Step: 8
Training loss: 2.8246138047088762
Validation loss: 2.527964077758035

Epoch: 6| Step: 9
Training loss: 2.2688236151067507
Validation loss: 2.5368150339508073

Epoch: 6| Step: 10
Training loss: 2.7972858489485017
Validation loss: 2.5361785185173993

Epoch: 6| Step: 11
Training loss: 2.5752706737290256
Validation loss: 2.53855549106862

Epoch: 6| Step: 12
Training loss: 3.1445970611319796
Validation loss: 2.553168004075009

Epoch: 6| Step: 13
Training loss: 2.3204561439517484
Validation loss: 2.5616850909058115

Epoch: 125| Step: 0
Training loss: 3.176577234867295
Validation loss: 2.5580706879186326

Epoch: 6| Step: 1
Training loss: 2.51643102776386
Validation loss: 2.556361930878356

Epoch: 6| Step: 2
Training loss: 3.014491209051817
Validation loss: 2.5609311038878784

Epoch: 6| Step: 3
Training loss: 2.693127263214938
Validation loss: 2.539449896780267

Epoch: 6| Step: 4
Training loss: 2.410429062697425
Validation loss: 2.530798613158555

Epoch: 6| Step: 5
Training loss: 3.007609571076547
Validation loss: 2.519073798383842

Epoch: 6| Step: 6
Training loss: 2.8591188409849284
Validation loss: 2.506721464471016

Epoch: 6| Step: 7
Training loss: 3.0362085116407385
Validation loss: 2.5162847733067206

Epoch: 6| Step: 8
Training loss: 2.452822235278618
Validation loss: 2.5126412403950455

Epoch: 6| Step: 9
Training loss: 3.14990427386441
Validation loss: 2.5089113009967

Epoch: 6| Step: 10
Training loss: 2.4602888917704844
Validation loss: 2.5072885484188365

Epoch: 6| Step: 11
Training loss: 2.9399890499819334
Validation loss: 2.5093719220866957

Epoch: 6| Step: 12
Training loss: 2.767320878073976
Validation loss: 2.514812466920286

Epoch: 6| Step: 13
Training loss: 3.4529577706696375
Validation loss: 2.510046381740617

Epoch: 126| Step: 0
Training loss: 3.230989757808507
Validation loss: 2.511274114149661

Epoch: 6| Step: 1
Training loss: 2.507468511929486
Validation loss: 2.5108859437520366

Epoch: 6| Step: 2
Training loss: 3.0143577007925977
Validation loss: 2.5081127591283114

Epoch: 6| Step: 3
Training loss: 2.493558118125675
Validation loss: 2.5152284664692397

Epoch: 6| Step: 4
Training loss: 3.109357210808095
Validation loss: 2.5098529486221897

Epoch: 6| Step: 5
Training loss: 2.3985200053882307
Validation loss: 2.5133110272014543

Epoch: 6| Step: 6
Training loss: 2.897223123087204
Validation loss: 2.5166096855329587

Epoch: 6| Step: 7
Training loss: 2.294862241578938
Validation loss: 2.5094428812108074

Epoch: 6| Step: 8
Training loss: 3.132401665364177
Validation loss: 2.5140150061179316

Epoch: 6| Step: 9
Training loss: 2.8833235621057076
Validation loss: 2.5141147530265022

Epoch: 6| Step: 10
Training loss: 3.0017183468902635
Validation loss: 2.524081839590972

Epoch: 6| Step: 11
Training loss: 2.561681849431166
Validation loss: 2.533204249348887

Epoch: 6| Step: 12
Training loss: 3.0366819810812644
Validation loss: 2.539542824974635

Epoch: 6| Step: 13
Training loss: 3.0611787398156953
Validation loss: 2.5512187888854716

Epoch: 127| Step: 0
Training loss: 2.2784774863407624
Validation loss: 2.5533088686454914

Epoch: 6| Step: 1
Training loss: 2.588579378422608
Validation loss: 2.5787805573360885

Epoch: 6| Step: 2
Training loss: 2.83627292131196
Validation loss: 2.6134162660839193

Epoch: 6| Step: 3
Training loss: 3.0625314516281974
Validation loss: 2.5678573449011526

Epoch: 6| Step: 4
Training loss: 3.314564043840489
Validation loss: 2.5499552566991053

Epoch: 6| Step: 5
Training loss: 3.172274259046556
Validation loss: 2.540898418936926

Epoch: 6| Step: 6
Training loss: 2.973696472789426
Validation loss: 2.530090134152546

Epoch: 6| Step: 7
Training loss: 3.139415906775936
Validation loss: 2.515235011049712

Epoch: 6| Step: 8
Training loss: 2.5982129411127417
Validation loss: 2.5108372186214583

Epoch: 6| Step: 9
Training loss: 2.8160952159541455
Validation loss: 2.509588181884952

Epoch: 6| Step: 10
Training loss: 2.3214154945256733
Validation loss: 2.5093882466020494

Epoch: 6| Step: 11
Training loss: 2.972413703557709
Validation loss: 2.5070398506622875

Epoch: 6| Step: 12
Training loss: 2.7226142168563148
Validation loss: 2.5079405288745895

Epoch: 6| Step: 13
Training loss: 2.80139800321195
Validation loss: 2.5048838779188376

Epoch: 128| Step: 0
Training loss: 2.807835759155194
Validation loss: 2.507568851514082

Epoch: 6| Step: 1
Training loss: 2.90937030599279
Validation loss: 2.505673940838988

Epoch: 6| Step: 2
Training loss: 3.1678790398441645
Validation loss: 2.5056964808950077

Epoch: 6| Step: 3
Training loss: 2.5784149931601634
Validation loss: 2.508100138742546

Epoch: 6| Step: 4
Training loss: 2.6288755055141793
Validation loss: 2.524041811618432

Epoch: 6| Step: 5
Training loss: 2.553502919347979
Validation loss: 2.554998433031725

Epoch: 6| Step: 6
Training loss: 3.000673536350286
Validation loss: 2.5758778394026787

Epoch: 6| Step: 7
Training loss: 3.265737869283385
Validation loss: 2.5371773899886865

Epoch: 6| Step: 8
Training loss: 2.490470845083797
Validation loss: 2.5265246652742084

Epoch: 6| Step: 9
Training loss: 2.832228912821847
Validation loss: 2.515028559604286

Epoch: 6| Step: 10
Training loss: 2.8037599182633763
Validation loss: 2.511091413685958

Epoch: 6| Step: 11
Training loss: 3.125368935741358
Validation loss: 2.5177744235007746

Epoch: 6| Step: 12
Training loss: 2.7355647523244913
Validation loss: 2.53161639305623

Epoch: 6| Step: 13
Training loss: 2.7804095252027414
Validation loss: 2.520351555744325

Epoch: 129| Step: 0
Training loss: 2.848269047362294
Validation loss: 2.510611961086003

Epoch: 6| Step: 1
Training loss: 2.9540318302720188
Validation loss: 2.499560133887028

Epoch: 6| Step: 2
Training loss: 2.569176883914349
Validation loss: 2.5048066927291335

Epoch: 6| Step: 3
Training loss: 2.5008287009993193
Validation loss: 2.5071893142037767

Epoch: 6| Step: 4
Training loss: 2.9569335276331152
Validation loss: 2.5033732339922814

Epoch: 6| Step: 5
Training loss: 2.7641892666640824
Validation loss: 2.5022931769344816

Epoch: 6| Step: 6
Training loss: 2.6412555009574312
Validation loss: 2.500685171351738

Epoch: 6| Step: 7
Training loss: 3.405190399268951
Validation loss: 2.501097093861894

Epoch: 6| Step: 8
Training loss: 2.789404840055465
Validation loss: 2.5077149211791143

Epoch: 6| Step: 9
Training loss: 2.66178281912407
Validation loss: 2.512231919964496

Epoch: 6| Step: 10
Training loss: 2.9744939549997538
Validation loss: 2.5305744952557143

Epoch: 6| Step: 11
Training loss: 3.124902952594651
Validation loss: 2.5647974447528257

Epoch: 6| Step: 12
Training loss: 2.7805486073271117
Validation loss: 2.5459421717990973

Epoch: 6| Step: 13
Training loss: 2.6213618907414227
Validation loss: 2.5466121465217735

Epoch: 130| Step: 0
Training loss: 2.992626665919467
Validation loss: 2.563970770493629

Epoch: 6| Step: 1
Training loss: 2.7621981839973437
Validation loss: 2.5425139231628346

Epoch: 6| Step: 2
Training loss: 3.0833129538472583
Validation loss: 2.530845322107211

Epoch: 6| Step: 3
Training loss: 2.7990395465440776
Validation loss: 2.514399794780476

Epoch: 6| Step: 4
Training loss: 3.1106572406700654
Validation loss: 2.511056437509575

Epoch: 6| Step: 5
Training loss: 2.950350310652348
Validation loss: 2.500601978018615

Epoch: 6| Step: 6
Training loss: 2.5125802136422575
Validation loss: 2.5064722645027673

Epoch: 6| Step: 7
Training loss: 3.0338477575319014
Validation loss: 2.5054455648377862

Epoch: 6| Step: 8
Training loss: 3.3503777248316124
Validation loss: 2.517250644540617

Epoch: 6| Step: 9
Training loss: 3.156767094621499
Validation loss: 2.517094026191699

Epoch: 6| Step: 10
Training loss: 1.7601926837914297
Validation loss: 2.518557214948197

Epoch: 6| Step: 11
Training loss: 2.709220408392872
Validation loss: 2.540434644818275

Epoch: 6| Step: 12
Training loss: 2.683119197459759
Validation loss: 2.6266629879006813

Epoch: 6| Step: 13
Training loss: 2.4911536102099094
Validation loss: 2.7440914021912217

Epoch: 131| Step: 0
Training loss: 3.189502012552074
Validation loss: 2.7797194746280853

Epoch: 6| Step: 1
Training loss: 2.7578913431541374
Validation loss: 2.733024711453253

Epoch: 6| Step: 2
Training loss: 2.0716716407640465
Validation loss: 2.6693890778857856

Epoch: 6| Step: 3
Training loss: 3.2532564134832835
Validation loss: 2.601221332908017

Epoch: 6| Step: 4
Training loss: 2.407851342761149
Validation loss: 2.5610725955269054

Epoch: 6| Step: 5
Training loss: 2.3520485005081584
Validation loss: 2.5327343413802934

Epoch: 6| Step: 6
Training loss: 3.277040378865411
Validation loss: 2.503298348450163

Epoch: 6| Step: 7
Training loss: 2.945738905742609
Validation loss: 2.4926019828537282

Epoch: 6| Step: 8
Training loss: 3.117222835942811
Validation loss: 2.494045266056195

Epoch: 6| Step: 9
Training loss: 2.5370879491733866
Validation loss: 2.5008639924342666

Epoch: 6| Step: 10
Training loss: 2.9221664528144355
Validation loss: 2.50666208337593

Epoch: 6| Step: 11
Training loss: 2.9630913059818877
Validation loss: 2.5159381754826042

Epoch: 6| Step: 12
Training loss: 3.158618453818726
Validation loss: 2.5076802342505404

Epoch: 6| Step: 13
Training loss: 3.0849057561244755
Validation loss: 2.4951951162705637

Epoch: 132| Step: 0
Training loss: 2.789980098967862
Validation loss: 2.493973823606499

Epoch: 6| Step: 1
Training loss: 3.1273349431161908
Validation loss: 2.49954032671238

Epoch: 6| Step: 2
Training loss: 2.86005764509675
Validation loss: 2.508115907315399

Epoch: 6| Step: 3
Training loss: 2.6574010711084375
Validation loss: 2.5422347876377254

Epoch: 6| Step: 4
Training loss: 3.0070184625604957
Validation loss: 2.544729742922605

Epoch: 6| Step: 5
Training loss: 2.693327418767774
Validation loss: 2.56527581826097

Epoch: 6| Step: 6
Training loss: 2.7830561227625807
Validation loss: 2.556427010827706

Epoch: 6| Step: 7
Training loss: 3.2612628915165685
Validation loss: 2.5496893283119073

Epoch: 6| Step: 8
Training loss: 2.579759299412973
Validation loss: 2.528365948844341

Epoch: 6| Step: 9
Training loss: 2.9384736415738226
Validation loss: 2.5183677337865635

Epoch: 6| Step: 10
Training loss: 2.630881668370189
Validation loss: 2.5022416862546955

Epoch: 6| Step: 11
Training loss: 2.7636116587410737
Validation loss: 2.4994913998977792

Epoch: 6| Step: 12
Training loss: 2.733276320847557
Validation loss: 2.4929157193145204

Epoch: 6| Step: 13
Training loss: 2.8900307534241403
Validation loss: 2.4921457870479227

Epoch: 133| Step: 0
Training loss: 2.3966004732918593
Validation loss: 2.4879079237212633

Epoch: 6| Step: 1
Training loss: 2.447701648981501
Validation loss: 2.4908555955127025

Epoch: 6| Step: 2
Training loss: 2.9351275989148444
Validation loss: 2.4942960241434924

Epoch: 6| Step: 3
Training loss: 3.0585582044151
Validation loss: 2.4933635282155038

Epoch: 6| Step: 4
Training loss: 2.921182152511523
Validation loss: 2.4998552193301027

Epoch: 6| Step: 5
Training loss: 2.658528506330095
Validation loss: 2.5040387140711675

Epoch: 6| Step: 6
Training loss: 2.9354317059389974
Validation loss: 2.5095028973045057

Epoch: 6| Step: 7
Training loss: 2.957185083618273
Validation loss: 2.506834666333399

Epoch: 6| Step: 8
Training loss: 2.569889207670901
Validation loss: 2.5180515017470597

Epoch: 6| Step: 9
Training loss: 3.210640478202665
Validation loss: 2.530264436328989

Epoch: 6| Step: 10
Training loss: 2.723444426413399
Validation loss: 2.5411477062600785

Epoch: 6| Step: 11
Training loss: 2.7674713006465566
Validation loss: 2.546512881249531

Epoch: 6| Step: 12
Training loss: 3.005315204661587
Validation loss: 2.539442672602107

Epoch: 6| Step: 13
Training loss: 2.7825654594350984
Validation loss: 2.535272865047231

Epoch: 134| Step: 0
Training loss: 3.104618133553302
Validation loss: 2.526553793319817

Epoch: 6| Step: 1
Training loss: 2.7616633257234664
Validation loss: 2.5208765275536527

Epoch: 6| Step: 2
Training loss: 2.7430841876331677
Validation loss: 2.5081518965369898

Epoch: 6| Step: 3
Training loss: 3.157031576245807
Validation loss: 2.5021902375467855

Epoch: 6| Step: 4
Training loss: 2.5188577860825707
Validation loss: 2.4959640801759546

Epoch: 6| Step: 5
Training loss: 2.8613732864930017
Validation loss: 2.503261327800725

Epoch: 6| Step: 6
Training loss: 3.1128290822047284
Validation loss: 2.499632499714559

Epoch: 6| Step: 7
Training loss: 2.865973025688164
Validation loss: 2.506864800887375

Epoch: 6| Step: 8
Training loss: 2.9821500623108532
Validation loss: 2.516028979492979

Epoch: 6| Step: 9
Training loss: 3.230165405053795
Validation loss: 2.531468624921615

Epoch: 6| Step: 10
Training loss: 2.022563730940346
Validation loss: 2.53001725028141

Epoch: 6| Step: 11
Training loss: 2.7311053100250495
Validation loss: 2.5248243809961854

Epoch: 6| Step: 12
Training loss: 2.425559704871635
Validation loss: 2.5338002196317198

Epoch: 6| Step: 13
Training loss: 2.4102020506626225
Validation loss: 2.5292470348327205

Epoch: 135| Step: 0
Training loss: 2.0198549346956467
Validation loss: 2.5188831042264916

Epoch: 6| Step: 1
Training loss: 2.8199286794098195
Validation loss: 2.4995393585034646

Epoch: 6| Step: 2
Training loss: 3.1025478229633165
Validation loss: 2.4991411215546364

Epoch: 6| Step: 3
Training loss: 2.829898341479409
Validation loss: 2.485912458930829

Epoch: 6| Step: 4
Training loss: 3.1632446739171836
Validation loss: 2.4953618945869307

Epoch: 6| Step: 5
Training loss: 2.699343113994646
Validation loss: 2.4965126253201504

Epoch: 6| Step: 6
Training loss: 2.9306544628195828
Validation loss: 2.493456492973805

Epoch: 6| Step: 7
Training loss: 3.193225729475949
Validation loss: 2.498909064139785

Epoch: 6| Step: 8
Training loss: 2.6282790457521985
Validation loss: 2.492145472269354

Epoch: 6| Step: 9
Training loss: 2.5153742126181533
Validation loss: 2.4985873620211723

Epoch: 6| Step: 10
Training loss: 3.077722823306155
Validation loss: 2.5137794433941085

Epoch: 6| Step: 11
Training loss: 3.297105247810072
Validation loss: 2.51852194852074

Epoch: 6| Step: 12
Training loss: 2.7807302096409523
Validation loss: 2.526533344922038

Epoch: 6| Step: 13
Training loss: 1.1829729623937475
Validation loss: 2.5460536026564085

Epoch: 136| Step: 0
Training loss: 2.9942829971654747
Validation loss: 2.548436287046546

Epoch: 6| Step: 1
Training loss: 2.592780426073444
Validation loss: 2.5511725087221517

Epoch: 6| Step: 2
Training loss: 3.0501170589308786
Validation loss: 2.535990522784881

Epoch: 6| Step: 3
Training loss: 2.7094571251835684
Validation loss: 2.532734057963511

Epoch: 6| Step: 4
Training loss: 2.4507581627645716
Validation loss: 2.519865370015825

Epoch: 6| Step: 5
Training loss: 2.7669258291204266
Validation loss: 2.511702090538736

Epoch: 6| Step: 6
Training loss: 3.0555259549026883
Validation loss: 2.503506510665501

Epoch: 6| Step: 7
Training loss: 2.922185707911706
Validation loss: 2.4997624171586432

Epoch: 6| Step: 8
Training loss: 2.343863726081973
Validation loss: 2.490877206999387

Epoch: 6| Step: 9
Training loss: 2.519065257900154
Validation loss: 2.4883371377363135

Epoch: 6| Step: 10
Training loss: 3.09276326174518
Validation loss: 2.49114976241036

Epoch: 6| Step: 11
Training loss: 2.899046142505661
Validation loss: 2.4952018197346533

Epoch: 6| Step: 12
Training loss: 3.1391549536845402
Validation loss: 2.485344692699169

Epoch: 6| Step: 13
Training loss: 2.8255430627935807
Validation loss: 2.48844881826927

Epoch: 137| Step: 0
Training loss: 3.079442705540888
Validation loss: 2.493923363868944

Epoch: 6| Step: 1
Training loss: 2.7947233650732546
Validation loss: 2.5112006831506597

Epoch: 6| Step: 2
Training loss: 3.354197073536031
Validation loss: 2.5477986782484696

Epoch: 6| Step: 3
Training loss: 2.849976315316282
Validation loss: 2.5712649283886875

Epoch: 6| Step: 4
Training loss: 2.0064476510012654
Validation loss: 2.584520313050171

Epoch: 6| Step: 5
Training loss: 2.7991862204405233
Validation loss: 2.5983539476727806

Epoch: 6| Step: 6
Training loss: 2.7849331588531503
Validation loss: 2.5505744232004552

Epoch: 6| Step: 7
Training loss: 2.3386365932124438
Validation loss: 2.5353453096539287

Epoch: 6| Step: 8
Training loss: 3.0265904430700576
Validation loss: 2.506247957719927

Epoch: 6| Step: 9
Training loss: 2.6913942023950237
Validation loss: 2.4907682316522535

Epoch: 6| Step: 10
Training loss: 2.9173197605449617
Validation loss: 2.4876793543457665

Epoch: 6| Step: 11
Training loss: 2.8569232038805477
Validation loss: 2.493094847796985

Epoch: 6| Step: 12
Training loss: 3.0491265218725703
Validation loss: 2.5003317171927995

Epoch: 6| Step: 13
Training loss: 2.7338382739138503
Validation loss: 2.4999753335535746

Epoch: 138| Step: 0
Training loss: 2.5745395582060064
Validation loss: 2.5042658312438224

Epoch: 6| Step: 1
Training loss: 3.401108527390429
Validation loss: 2.5033902345949492

Epoch: 6| Step: 2
Training loss: 2.820402106977646
Validation loss: 2.5058451610969605

Epoch: 6| Step: 3
Training loss: 3.2230995197039785
Validation loss: 2.5093087010046147

Epoch: 6| Step: 4
Training loss: 2.5437987301819485
Validation loss: 2.5051609932203944

Epoch: 6| Step: 5
Training loss: 2.873514538012797
Validation loss: 2.502384806987618

Epoch: 6| Step: 6
Training loss: 2.642185449853211
Validation loss: 2.490860401969664

Epoch: 6| Step: 7
Training loss: 2.70776797531511
Validation loss: 2.4886886379866353

Epoch: 6| Step: 8
Training loss: 2.627664485323501
Validation loss: 2.502967078708573

Epoch: 6| Step: 9
Training loss: 3.3202560599522895
Validation loss: 2.525049111810448

Epoch: 6| Step: 10
Training loss: 3.060828706561451
Validation loss: 2.5651110460634596

Epoch: 6| Step: 11
Training loss: 2.4968768639014476
Validation loss: 2.603808770638448

Epoch: 6| Step: 12
Training loss: 3.1693648003361594
Validation loss: 2.5789191849043798

Epoch: 6| Step: 13
Training loss: 1.817512421493376
Validation loss: 2.5477557385439624

Epoch: 139| Step: 0
Training loss: 2.8903717754900176
Validation loss: 2.525489291220279

Epoch: 6| Step: 1
Training loss: 2.8867164374356435
Validation loss: 2.5054182982363775

Epoch: 6| Step: 2
Training loss: 2.987297504537376
Validation loss: 2.5023303829989154

Epoch: 6| Step: 3
Training loss: 2.7780826835713572
Validation loss: 2.51164601791191

Epoch: 6| Step: 4
Training loss: 2.932831483595577
Validation loss: 2.521691967221616

Epoch: 6| Step: 5
Training loss: 2.1972326386412857
Validation loss: 2.509675378885865

Epoch: 6| Step: 6
Training loss: 2.2075893540405103
Validation loss: 2.5017177740738035

Epoch: 6| Step: 7
Training loss: 3.1651517523713695
Validation loss: 2.488253262131055

Epoch: 6| Step: 8
Training loss: 3.193884644777502
Validation loss: 2.4944305319530975

Epoch: 6| Step: 9
Training loss: 2.470789682432658
Validation loss: 2.490800567609496

Epoch: 6| Step: 10
Training loss: 3.009314065635204
Validation loss: 2.488000716232884

Epoch: 6| Step: 11
Training loss: 2.7485847299252257
Validation loss: 2.492869121361264

Epoch: 6| Step: 12
Training loss: 2.77853192158777
Validation loss: 2.4817601794118005

Epoch: 6| Step: 13
Training loss: 2.961249584167374
Validation loss: 2.4906426920708706

Epoch: 140| Step: 0
Training loss: 2.6427997008454995
Validation loss: 2.499050193758506

Epoch: 6| Step: 1
Training loss: 2.568770760779472
Validation loss: 2.4992062857138757

Epoch: 6| Step: 2
Training loss: 3.2739641953959078
Validation loss: 2.5044217680517242

Epoch: 6| Step: 3
Training loss: 3.0968096467329316
Validation loss: 2.5022225795804656

Epoch: 6| Step: 4
Training loss: 3.104999166049323
Validation loss: 2.4963869232754625

Epoch: 6| Step: 5
Training loss: 3.1594122728814895
Validation loss: 2.4995714435574574

Epoch: 6| Step: 6
Training loss: 2.172346763693807
Validation loss: 2.5090864848870527

Epoch: 6| Step: 7
Training loss: 2.5349687174836313
Validation loss: 2.5079773220134634

Epoch: 6| Step: 8
Training loss: 2.6446064384736916
Validation loss: 2.5215622097251784

Epoch: 6| Step: 9
Training loss: 2.695300646769679
Validation loss: 2.525497700348657

Epoch: 6| Step: 10
Training loss: 3.3715879358768897
Validation loss: 2.532310507765388

Epoch: 6| Step: 11
Training loss: 2.5715714823656013
Validation loss: 2.54517239294962

Epoch: 6| Step: 12
Training loss: 2.565844981047444
Validation loss: 2.562252326839432

Epoch: 6| Step: 13
Training loss: 2.253378239340318
Validation loss: 2.561653636219215

Epoch: 141| Step: 0
Training loss: 3.304953129330695
Validation loss: 2.5697147010708714

Epoch: 6| Step: 1
Training loss: 2.9997725400525326
Validation loss: 2.554230376810057

Epoch: 6| Step: 2
Training loss: 2.4233730482216655
Validation loss: 2.514524452091087

Epoch: 6| Step: 3
Training loss: 2.589558535329516
Validation loss: 2.514270365005307

Epoch: 6| Step: 4
Training loss: 2.7011333029772673
Validation loss: 2.510170464758388

Epoch: 6| Step: 5
Training loss: 2.3301247834284875
Validation loss: 2.503204050147675

Epoch: 6| Step: 6
Training loss: 2.804104375123746
Validation loss: 2.5181210027387224

Epoch: 6| Step: 7
Training loss: 2.680938161931488
Validation loss: 2.525802638208003

Epoch: 6| Step: 8
Training loss: 3.041083049087972
Validation loss: 2.5301493838721005

Epoch: 6| Step: 9
Training loss: 2.9509663437695366
Validation loss: 2.524449788905073

Epoch: 6| Step: 10
Training loss: 3.315114123421116
Validation loss: 2.5370978148371637

Epoch: 6| Step: 11
Training loss: 2.3342726270092338
Validation loss: 2.5525094954525454

Epoch: 6| Step: 12
Training loss: 2.912168976796172
Validation loss: 2.547113248018063

Epoch: 6| Step: 13
Training loss: 3.0771588198511775
Validation loss: 2.563879302640744

Epoch: 142| Step: 0
Training loss: 3.3232282693746895
Validation loss: 2.566878459099165

Epoch: 6| Step: 1
Training loss: 2.760192794838606
Validation loss: 2.6127506404551983

Epoch: 6| Step: 2
Training loss: 2.5793830345330004
Validation loss: 2.611883166329603

Epoch: 6| Step: 3
Training loss: 2.55505088531526
Validation loss: 2.591875975031021

Epoch: 6| Step: 4
Training loss: 2.6151638121198433
Validation loss: 2.54867967094605

Epoch: 6| Step: 5
Training loss: 3.0842159829314997
Validation loss: 2.5256126043644125

Epoch: 6| Step: 6
Training loss: 2.8276661874786524
Validation loss: 2.5131826874114735

Epoch: 6| Step: 7
Training loss: 2.7747505625748197
Validation loss: 2.514335512275521

Epoch: 6| Step: 8
Training loss: 2.6166477842520295
Validation loss: 2.5092044749957316

Epoch: 6| Step: 9
Training loss: 3.3917621164848484
Validation loss: 2.506298149889592

Epoch: 6| Step: 10
Training loss: 3.0109966911670214
Validation loss: 2.5102758710638398

Epoch: 6| Step: 11
Training loss: 2.950310228490546
Validation loss: 2.5091966263256213

Epoch: 6| Step: 12
Training loss: 2.6899707880525714
Validation loss: 2.5269468143219673

Epoch: 6| Step: 13
Training loss: 2.169554094655169
Validation loss: 2.540858699778092

Epoch: 143| Step: 0
Training loss: 2.5884605615038243
Validation loss: 2.6279449828881303

Epoch: 6| Step: 1
Training loss: 2.7409186837660955
Validation loss: 2.652830426094327

Epoch: 6| Step: 2
Training loss: 2.3304068628445167
Validation loss: 2.6294319551058387

Epoch: 6| Step: 3
Training loss: 3.040404349590493
Validation loss: 2.5634220154286833

Epoch: 6| Step: 4
Training loss: 2.892369748993475
Validation loss: 2.5193108921044973

Epoch: 6| Step: 5
Training loss: 2.923012252045884
Validation loss: 2.5089014241233527

Epoch: 6| Step: 6
Training loss: 2.887431096827805
Validation loss: 2.5145017867510147

Epoch: 6| Step: 7
Training loss: 3.0091925291395363
Validation loss: 2.5432077147520946

Epoch: 6| Step: 8
Training loss: 3.0670331763583536
Validation loss: 2.552372520056097

Epoch: 6| Step: 9
Training loss: 2.9129986904991236
Validation loss: 2.5569449619264177

Epoch: 6| Step: 10
Training loss: 3.0663023718471902
Validation loss: 2.5971154387006448

Epoch: 6| Step: 11
Training loss: 3.3209779319409027
Validation loss: 2.6311788484889647

Epoch: 6| Step: 12
Training loss: 2.5568142592274796
Validation loss: 2.595734310781475

Epoch: 6| Step: 13
Training loss: 2.8528745376271645
Validation loss: 2.586862257773972

Epoch: 144| Step: 0
Training loss: 3.0977763168329084
Validation loss: 2.5712124220055

Epoch: 6| Step: 1
Training loss: 2.3201713133734065
Validation loss: 2.552074437547607

Epoch: 6| Step: 2
Training loss: 2.8328713059042108
Validation loss: 2.524511296444302

Epoch: 6| Step: 3
Training loss: 2.5760784002066455
Validation loss: 2.5115636357499227

Epoch: 6| Step: 4
Training loss: 2.3489475856177053
Validation loss: 2.508520272384364

Epoch: 6| Step: 5
Training loss: 3.217253253666857
Validation loss: 2.5125074636370637

Epoch: 6| Step: 6
Training loss: 3.0044328999281875
Validation loss: 2.4984990772440803

Epoch: 6| Step: 7
Training loss: 2.8397979102967317
Validation loss: 2.518316447578985

Epoch: 6| Step: 8
Training loss: 2.7097450294058385
Validation loss: 2.525704299899845

Epoch: 6| Step: 9
Training loss: 2.608502544809116
Validation loss: 2.5531609161104347

Epoch: 6| Step: 10
Training loss: 2.953051046424373
Validation loss: 2.568261754824973

Epoch: 6| Step: 11
Training loss: 3.031810905236721
Validation loss: 2.570042795717383

Epoch: 6| Step: 12
Training loss: 2.9817175092746036
Validation loss: 2.5427446915159084

Epoch: 6| Step: 13
Training loss: 2.748052080552106
Validation loss: 2.4972007102352594

Epoch: 145| Step: 0
Training loss: 2.9463277427958943
Validation loss: 2.4918287190433657

Epoch: 6| Step: 1
Training loss: 2.983940372474687
Validation loss: 2.487000899801638

Epoch: 6| Step: 2
Training loss: 3.4595664863003175
Validation loss: 2.4882665622034477

Epoch: 6| Step: 3
Training loss: 2.4716586590991096
Validation loss: 2.4904682922203305

Epoch: 6| Step: 4
Training loss: 2.483453543738286
Validation loss: 2.497314329296317

Epoch: 6| Step: 5
Training loss: 2.9903099603649146
Validation loss: 2.49391783346568

Epoch: 6| Step: 6
Training loss: 3.2106744885914384
Validation loss: 2.4946335297066202

Epoch: 6| Step: 7
Training loss: 2.720786723915289
Validation loss: 2.4903103122316534

Epoch: 6| Step: 8
Training loss: 2.8843483904006866
Validation loss: 2.4948750869731735

Epoch: 6| Step: 9
Training loss: 2.4280354565540616
Validation loss: 2.4970767162796133

Epoch: 6| Step: 10
Training loss: 2.918918031352522
Validation loss: 2.5139453018715714

Epoch: 6| Step: 11
Training loss: 2.938047642081992
Validation loss: 2.515043589050478

Epoch: 6| Step: 12
Training loss: 2.005149411083025
Validation loss: 2.5221820912341197

Epoch: 6| Step: 13
Training loss: 2.4556995658398475
Validation loss: 2.5457382377999243

Epoch: 146| Step: 0
Training loss: 1.983476029666873
Validation loss: 2.5204033752332564

Epoch: 6| Step: 1
Training loss: 2.8646095598349612
Validation loss: 2.5266632915345166

Epoch: 6| Step: 2
Training loss: 2.9927428205826385
Validation loss: 2.5115084144059505

Epoch: 6| Step: 3
Training loss: 2.993272549777413
Validation loss: 2.5078296729152725

Epoch: 6| Step: 4
Training loss: 3.0501509832314553
Validation loss: 2.4958711512982568

Epoch: 6| Step: 5
Training loss: 2.715036860122704
Validation loss: 2.4919481353141264

Epoch: 6| Step: 6
Training loss: 2.6736122417585175
Validation loss: 2.492955552922166

Epoch: 6| Step: 7
Training loss: 2.760195386162672
Validation loss: 2.4894047804943065

Epoch: 6| Step: 8
Training loss: 2.989549076180895
Validation loss: 2.485942349007289

Epoch: 6| Step: 9
Training loss: 2.402873754575139
Validation loss: 2.496517873742843

Epoch: 6| Step: 10
Training loss: 3.1801748441217144
Validation loss: 2.4970769631905463

Epoch: 6| Step: 11
Training loss: 2.7606145439960397
Validation loss: 2.4993643803785237

Epoch: 6| Step: 12
Training loss: 2.5896065950052205
Validation loss: 2.493118936553755

Epoch: 6| Step: 13
Training loss: 2.8056749396108334
Validation loss: 2.49589609762969

Epoch: 147| Step: 0
Training loss: 3.082372532890623
Validation loss: 2.49680026184311

Epoch: 6| Step: 1
Training loss: 3.05839528186503
Validation loss: 2.5000882379280314

Epoch: 6| Step: 2
Training loss: 3.1057299234219915
Validation loss: 2.5122235817445135

Epoch: 6| Step: 3
Training loss: 2.6974745772386126
Validation loss: 2.5058736814086786

Epoch: 6| Step: 4
Training loss: 2.7195826165340695
Validation loss: 2.509998486007759

Epoch: 6| Step: 5
Training loss: 2.71511580387102
Validation loss: 2.5168812287135034

Epoch: 6| Step: 6
Training loss: 3.22285096476155
Validation loss: 2.512519290502893

Epoch: 6| Step: 7
Training loss: 2.4270342602223334
Validation loss: 2.522843781528225

Epoch: 6| Step: 8
Training loss: 2.0815142764450196
Validation loss: 2.5242660819610903

Epoch: 6| Step: 9
Training loss: 3.3659858418085866
Validation loss: 2.5284348692353884

Epoch: 6| Step: 10
Training loss: 1.9484998948447396
Validation loss: 2.513396033645767

Epoch: 6| Step: 11
Training loss: 1.9647322332994066
Validation loss: 2.5080668559652217

Epoch: 6| Step: 12
Training loss: 3.284127563099218
Validation loss: 2.4886155820422156

Epoch: 6| Step: 13
Training loss: 2.761453100482746
Validation loss: 2.4823306606120825

Epoch: 148| Step: 0
Training loss: 2.377443963482528
Validation loss: 2.4770805459122536

Epoch: 6| Step: 1
Training loss: 2.6610326457639126
Validation loss: 2.472507988880666

Epoch: 6| Step: 2
Training loss: 3.027389427578788
Validation loss: 2.469023188237986

Epoch: 6| Step: 3
Training loss: 3.0289566960732555
Validation loss: 2.475003680287253

Epoch: 6| Step: 4
Training loss: 2.9866426650286333
Validation loss: 2.4771611533150812

Epoch: 6| Step: 5
Training loss: 2.8984523063343177
Validation loss: 2.4711740041413863

Epoch: 6| Step: 6
Training loss: 2.8505707152621143
Validation loss: 2.4708675307934733

Epoch: 6| Step: 7
Training loss: 2.8047191224932133
Validation loss: 2.4709143973743264

Epoch: 6| Step: 8
Training loss: 2.690162581738606
Validation loss: 2.4779421321763015

Epoch: 6| Step: 9
Training loss: 2.934262216043829
Validation loss: 2.4730316920613755

Epoch: 6| Step: 10
Training loss: 3.0844296405130383
Validation loss: 2.484432975911391

Epoch: 6| Step: 11
Training loss: 2.6879401622764973
Validation loss: 2.5045840157617363

Epoch: 6| Step: 12
Training loss: 2.470204178560318
Validation loss: 2.524585309044447

Epoch: 6| Step: 13
Training loss: 1.8728754722922036
Validation loss: 2.5467224055249065

Epoch: 149| Step: 0
Training loss: 2.5246467645406487
Validation loss: 2.5388754413064274

Epoch: 6| Step: 1
Training loss: 2.8247675065776723
Validation loss: 2.530100755127813

Epoch: 6| Step: 2
Training loss: 3.1244408679481657
Validation loss: 2.513222880176248

Epoch: 6| Step: 3
Training loss: 2.7362268770860694
Validation loss: 2.492566188746759

Epoch: 6| Step: 4
Training loss: 2.900749990889176
Validation loss: 2.4673103547209725

Epoch: 6| Step: 5
Training loss: 2.6764752678315493
Validation loss: 2.467134117445632

Epoch: 6| Step: 6
Training loss: 2.6957956074625455
Validation loss: 2.4624752242692614

Epoch: 6| Step: 7
Training loss: 3.227188456041969
Validation loss: 2.471825509155206

Epoch: 6| Step: 8
Training loss: 2.723053693838068
Validation loss: 2.4683886017251857

Epoch: 6| Step: 9
Training loss: 2.1162682821674936
Validation loss: 2.4758081700030883

Epoch: 6| Step: 10
Training loss: 2.8810460744587716
Validation loss: 2.4871472023237375

Epoch: 6| Step: 11
Training loss: 2.8049759995356807
Validation loss: 2.515058660198832

Epoch: 6| Step: 12
Training loss: 2.49027956454096
Validation loss: 2.515266844926435

Epoch: 6| Step: 13
Training loss: 3.3408184570021886
Validation loss: 2.521662716934391

Epoch: 150| Step: 0
Training loss: 2.835776248267274
Validation loss: 2.5321652038960365

Epoch: 6| Step: 1
Training loss: 3.136915758912825
Validation loss: 2.4858087071338635

Epoch: 6| Step: 2
Training loss: 2.6335382112244448
Validation loss: 2.471684286466468

Epoch: 6| Step: 3
Training loss: 3.0796285142673736
Validation loss: 2.460343858639927

Epoch: 6| Step: 4
Training loss: 3.47940365713223
Validation loss: 2.457937473261295

Epoch: 6| Step: 5
Training loss: 2.1316862940636523
Validation loss: 2.460672883422104

Epoch: 6| Step: 6
Training loss: 2.8620397939094744
Validation loss: 2.4712073786936504

Epoch: 6| Step: 7
Training loss: 2.437438475003521
Validation loss: 2.478987477307791

Epoch: 6| Step: 8
Training loss: 2.0849715721698923
Validation loss: 2.482355060373541

Epoch: 6| Step: 9
Training loss: 3.50674197847359
Validation loss: 2.482735002063087

Epoch: 6| Step: 10
Training loss: 2.3047119139331897
Validation loss: 2.4770995360342285

Epoch: 6| Step: 11
Training loss: 2.8237309331364178
Validation loss: 2.48410780874491

Epoch: 6| Step: 12
Training loss: 2.3578730975454167
Validation loss: 2.4934862597176237

Epoch: 6| Step: 13
Training loss: 3.1838450701222873
Validation loss: 2.49796326436001

Epoch: 151| Step: 0
Training loss: 2.6860111459485174
Validation loss: 2.511054142433011

Epoch: 6| Step: 1
Training loss: 2.5126627665315953
Validation loss: 2.5248905144745972

Epoch: 6| Step: 2
Training loss: 2.866507550932106
Validation loss: 2.54416512782053

Epoch: 6| Step: 3
Training loss: 2.177256222906888
Validation loss: 2.5624935791351366

Epoch: 6| Step: 4
Training loss: 3.1150947754771567
Validation loss: 2.637953445925817

Epoch: 6| Step: 5
Training loss: 2.7274121378899943
Validation loss: 2.6494707879706816

Epoch: 6| Step: 6
Training loss: 2.552528051956368
Validation loss: 2.6101579734878397

Epoch: 6| Step: 7
Training loss: 2.9835437196111365
Validation loss: 2.5557690349647113

Epoch: 6| Step: 8
Training loss: 2.9236239334594445
Validation loss: 2.5055073823605714

Epoch: 6| Step: 9
Training loss: 3.2520496067706994
Validation loss: 2.483179617060489

Epoch: 6| Step: 10
Training loss: 2.5502693632385665
Validation loss: 2.4775578970000023

Epoch: 6| Step: 11
Training loss: 3.520361663705326
Validation loss: 2.48095674346833

Epoch: 6| Step: 12
Training loss: 2.1034507918571923
Validation loss: 2.4896413252554157

Epoch: 6| Step: 13
Training loss: 3.5369029751089403
Validation loss: 2.495016364626876

Epoch: 152| Step: 0
Training loss: 2.5506436601482942
Validation loss: 2.498232087181064

Epoch: 6| Step: 1
Training loss: 2.5000596992994057
Validation loss: 2.4991675908685362

Epoch: 6| Step: 2
Training loss: 2.8997569409818578
Validation loss: 2.5005383414366675

Epoch: 6| Step: 3
Training loss: 2.882267267206387
Validation loss: 2.496398075310044

Epoch: 6| Step: 4
Training loss: 2.091732020579297
Validation loss: 2.4871268118350325

Epoch: 6| Step: 5
Training loss: 3.3098993709054088
Validation loss: 2.487270301374925

Epoch: 6| Step: 6
Training loss: 2.838991312699633
Validation loss: 2.4827387684224114

Epoch: 6| Step: 7
Training loss: 2.768016234014016
Validation loss: 2.481627540612446

Epoch: 6| Step: 8
Training loss: 2.981275296853661
Validation loss: 2.494930190443179

Epoch: 6| Step: 9
Training loss: 3.259982257864947
Validation loss: 2.5055576384784106

Epoch: 6| Step: 10
Training loss: 2.276383107382127
Validation loss: 2.5284000620009928

Epoch: 6| Step: 11
Training loss: 2.782719427541079
Validation loss: 2.634227448541115

Epoch: 6| Step: 12
Training loss: 3.0946743287541265
Validation loss: 2.736073888808636

Epoch: 6| Step: 13
Training loss: 3.5642825569206558
Validation loss: 2.719945897989985

Epoch: 153| Step: 0
Training loss: 2.9602248005947374
Validation loss: 2.6719583295545806

Epoch: 6| Step: 1
Training loss: 2.9897789088131557
Validation loss: 2.61439062870245

Epoch: 6| Step: 2
Training loss: 3.208905767591308
Validation loss: 2.5593338792094267

Epoch: 6| Step: 3
Training loss: 2.8449273658960297
Validation loss: 2.544415738413928

Epoch: 6| Step: 4
Training loss: 2.0542759936515984
Validation loss: 2.5289975607698985

Epoch: 6| Step: 5
Training loss: 2.827191615063205
Validation loss: 2.529951031940683

Epoch: 6| Step: 6
Training loss: 2.8638655624483897
Validation loss: 2.5342863581224955

Epoch: 6| Step: 7
Training loss: 2.855347178072085
Validation loss: 2.5470880685664503

Epoch: 6| Step: 8
Training loss: 3.119873572257786
Validation loss: 2.5557051359679437

Epoch: 6| Step: 9
Training loss: 2.730316114184221
Validation loss: 2.584863283769146

Epoch: 6| Step: 10
Training loss: 3.048663431199948
Validation loss: 2.595360765896559

Epoch: 6| Step: 11
Training loss: 2.34258566863598
Validation loss: 2.6037933275601906

Epoch: 6| Step: 12
Training loss: 2.647516411144194
Validation loss: 2.607043559861258

Epoch: 6| Step: 13
Training loss: 2.9545772150640084
Validation loss: 2.5959419539316917

Epoch: 154| Step: 0
Training loss: 2.119761573771605
Validation loss: 2.56525066518112

Epoch: 6| Step: 1
Training loss: 2.9899189369669856
Validation loss: 2.559212705781929

Epoch: 6| Step: 2
Training loss: 2.5172439957192023
Validation loss: 2.5625645339006913

Epoch: 6| Step: 3
Training loss: 2.8509728226987017
Validation loss: 2.5478990102846124

Epoch: 6| Step: 4
Training loss: 2.588560312819276
Validation loss: 2.531936027914529

Epoch: 6| Step: 5
Training loss: 2.659291489541693
Validation loss: 2.5283006343100243

Epoch: 6| Step: 6
Training loss: 3.194158443603228
Validation loss: 2.5381762319767627

Epoch: 6| Step: 7
Training loss: 2.7503956596806285
Validation loss: 2.5448611791023836

Epoch: 6| Step: 8
Training loss: 2.6396390439853206
Validation loss: 2.559387761161505

Epoch: 6| Step: 9
Training loss: 3.006016579049914
Validation loss: 2.562203951185758

Epoch: 6| Step: 10
Training loss: 3.231327408651035
Validation loss: 2.5689697548474535

Epoch: 6| Step: 11
Training loss: 2.9488895459890254
Validation loss: 2.5753493331811477

Epoch: 6| Step: 12
Training loss: 3.128915393830272
Validation loss: 2.569937351873012

Epoch: 6| Step: 13
Training loss: 2.8041234206274823
Validation loss: 2.5591869271273318

Epoch: 155| Step: 0
Training loss: 2.815129301445353
Validation loss: 2.538133525420807

Epoch: 6| Step: 1
Training loss: 2.5202932698792675
Validation loss: 2.536145379310879

Epoch: 6| Step: 2
Training loss: 2.6097420988148734
Validation loss: 2.522347511024001

Epoch: 6| Step: 3
Training loss: 2.8460171224544153
Validation loss: 2.5117709241619894

Epoch: 6| Step: 4
Training loss: 2.5361884650468736
Validation loss: 2.5139920047664823

Epoch: 6| Step: 5
Training loss: 3.4633260024002026
Validation loss: 2.5077495646918337

Epoch: 6| Step: 6
Training loss: 2.8336602938621174
Validation loss: 2.50931098746109

Epoch: 6| Step: 7
Training loss: 2.825367378720429
Validation loss: 2.5039482031915963

Epoch: 6| Step: 8
Training loss: 2.048013268718354
Validation loss: 2.503459335669537

Epoch: 6| Step: 9
Training loss: 3.1618258636028718
Validation loss: 2.4930540271777617

Epoch: 6| Step: 10
Training loss: 2.697788328753806
Validation loss: 2.5039891134290997

Epoch: 6| Step: 11
Training loss: 2.6446001277727094
Validation loss: 2.4987538359499415

Epoch: 6| Step: 12
Training loss: 3.000115392373052
Validation loss: 2.507159444294901

Epoch: 6| Step: 13
Training loss: 3.1078317157348847
Validation loss: 2.531643556226636

Epoch: 156| Step: 0
Training loss: 2.5956570152624843
Validation loss: 2.5271676937917813

Epoch: 6| Step: 1
Training loss: 2.819282829860043
Validation loss: 2.5336589018172737

Epoch: 6| Step: 2
Training loss: 2.779515100357477
Validation loss: 2.5237958912577567

Epoch: 6| Step: 3
Training loss: 3.1010558822010434
Validation loss: 2.5285307014819

Epoch: 6| Step: 4
Training loss: 2.3790385392712516
Validation loss: 2.526546547995275

Epoch: 6| Step: 5
Training loss: 2.6841633510085523
Validation loss: 2.5415143166211687

Epoch: 6| Step: 6
Training loss: 2.414810015548604
Validation loss: 2.5216352942595743

Epoch: 6| Step: 7
Training loss: 2.675229292695049
Validation loss: 2.534756805690449

Epoch: 6| Step: 8
Training loss: 3.098660050256508
Validation loss: 2.5316836300795695

Epoch: 6| Step: 9
Training loss: 3.0348699918298925
Validation loss: 2.53887045462945

Epoch: 6| Step: 10
Training loss: 2.8037111075735757
Validation loss: 2.5313861214798994

Epoch: 6| Step: 11
Training loss: 3.19287105641392
Validation loss: 2.529457951801824

Epoch: 6| Step: 12
Training loss: 3.2416594661315603
Validation loss: 2.519737355415327

Epoch: 6| Step: 13
Training loss: 1.8798594763161955
Validation loss: 2.51721544077421

Epoch: 157| Step: 0
Training loss: 2.649587555944089
Validation loss: 2.5073899708058804

Epoch: 6| Step: 1
Training loss: 2.749307545265642
Validation loss: 2.5158722265010987

Epoch: 6| Step: 2
Training loss: 2.2478824823824866
Validation loss: 2.5089807363828927

Epoch: 6| Step: 3
Training loss: 2.80214727014443
Validation loss: 2.500299841835003

Epoch: 6| Step: 4
Training loss: 2.7918026070211024
Validation loss: 2.5059117100321173

Epoch: 6| Step: 5
Training loss: 3.13124863554112
Validation loss: 2.5002718757134144

Epoch: 6| Step: 6
Training loss: 3.5846878567079306
Validation loss: 2.491267236478392

Epoch: 6| Step: 7
Training loss: 2.389529706579922
Validation loss: 2.485265611259546

Epoch: 6| Step: 8
Training loss: 2.610070963804661
Validation loss: 2.4750029811134753

Epoch: 6| Step: 9
Training loss: 2.8083620784959917
Validation loss: 2.48331776827636

Epoch: 6| Step: 10
Training loss: 2.997238795820233
Validation loss: 2.4720369956848254

Epoch: 6| Step: 11
Training loss: 2.2682101529562098
Validation loss: 2.474156987364699

Epoch: 6| Step: 12
Training loss: 2.691682621423383
Validation loss: 2.4792079458490894

Epoch: 6| Step: 13
Training loss: 2.68891461423998
Validation loss: 2.4835329244261506

Epoch: 158| Step: 0
Training loss: 3.5476124538800464
Validation loss: 2.4894859424320352

Epoch: 6| Step: 1
Training loss: 2.5285070180193965
Validation loss: 2.473982348668234

Epoch: 6| Step: 2
Training loss: 2.650425257839541
Validation loss: 2.482945626482091

Epoch: 6| Step: 3
Training loss: 2.7530156853198173
Validation loss: 2.484558412397736

Epoch: 6| Step: 4
Training loss: 2.59328530066888
Validation loss: 2.4749823657563894

Epoch: 6| Step: 5
Training loss: 2.6568455645524143
Validation loss: 2.474293829163332

Epoch: 6| Step: 6
Training loss: 2.922647139579158
Validation loss: 2.4735031778300356

Epoch: 6| Step: 7
Training loss: 2.6082013625944134
Validation loss: 2.4675621174905635

Epoch: 6| Step: 8
Training loss: 2.7064670784028153
Validation loss: 2.471765567689747

Epoch: 6| Step: 9
Training loss: 2.88104508140855
Validation loss: 2.465330099678802

Epoch: 6| Step: 10
Training loss: 2.8812092610621454
Validation loss: 2.478300187399102

Epoch: 6| Step: 11
Training loss: 2.654364421509928
Validation loss: 2.4751318650238456

Epoch: 6| Step: 12
Training loss: 2.7688920718699137
Validation loss: 2.4736213562527087

Epoch: 6| Step: 13
Training loss: 1.7146994979769565
Validation loss: 2.481133650049014

Epoch: 159| Step: 0
Training loss: 2.6450835740095004
Validation loss: 2.4837067976574216

Epoch: 6| Step: 1
Training loss: 2.881673282801761
Validation loss: 2.5069502007792335

Epoch: 6| Step: 2
Training loss: 2.9452823870103524
Validation loss: 2.5152459566976377

Epoch: 6| Step: 3
Training loss: 2.870814054190942
Validation loss: 2.5019583835277412

Epoch: 6| Step: 4
Training loss: 2.5448131054976986
Validation loss: 2.5008921108235604

Epoch: 6| Step: 5
Training loss: 2.0992628938315976
Validation loss: 2.4947966313257597

Epoch: 6| Step: 6
Training loss: 3.305462685428214
Validation loss: 2.481659105196645

Epoch: 6| Step: 7
Training loss: 2.866505887453856
Validation loss: 2.475970037094483

Epoch: 6| Step: 8
Training loss: 2.240442001978024
Validation loss: 2.4708615389535886

Epoch: 6| Step: 9
Training loss: 2.490695040111678
Validation loss: 2.4721507591401397

Epoch: 6| Step: 10
Training loss: 2.882709780467982
Validation loss: 2.471016043888103

Epoch: 6| Step: 11
Training loss: 2.935199892167895
Validation loss: 2.460114172090094

Epoch: 6| Step: 12
Training loss: 3.0263114104250164
Validation loss: 2.4643938628984494

Epoch: 6| Step: 13
Training loss: 2.2007893836724586
Validation loss: 2.463846735452207

Epoch: 160| Step: 0
Training loss: 3.2040445636026598
Validation loss: 2.4650241872934573

Epoch: 6| Step: 1
Training loss: 2.5866027160814324
Validation loss: 2.4647001322764286

Epoch: 6| Step: 2
Training loss: 2.868472442829709
Validation loss: 2.4660341946358897

Epoch: 6| Step: 3
Training loss: 2.567786276809813
Validation loss: 2.4772518481256705

Epoch: 6| Step: 4
Training loss: 2.7365271246116585
Validation loss: 2.4941894789598886

Epoch: 6| Step: 5
Training loss: 2.5217767216512854
Validation loss: 2.503158314545048

Epoch: 6| Step: 6
Training loss: 2.131404985179013
Validation loss: 2.5145446795442705

Epoch: 6| Step: 7
Training loss: 3.191601974854251
Validation loss: 2.514270930393418

Epoch: 6| Step: 8
Training loss: 2.763960170199406
Validation loss: 2.4978732035285587

Epoch: 6| Step: 9
Training loss: 2.828140933165796
Validation loss: 2.4993296257664004

Epoch: 6| Step: 10
Training loss: 2.8203299144090996
Validation loss: 2.485092906554235

Epoch: 6| Step: 11
Training loss: 2.6329594692786316
Validation loss: 2.4896881710273853

Epoch: 6| Step: 12
Training loss: 2.471346105810967
Validation loss: 2.478573651084116

Epoch: 6| Step: 13
Training loss: 2.9907560983461896
Validation loss: 2.472655059757661

Epoch: 161| Step: 0
Training loss: 2.520950840084463
Validation loss: 2.462957383720735

Epoch: 6| Step: 1
Training loss: 3.141166071045699
Validation loss: 2.462859116536879

Epoch: 6| Step: 2
Training loss: 2.458522325998953
Validation loss: 2.4588696817790976

Epoch: 6| Step: 3
Training loss: 2.505183948760343
Validation loss: 2.4611636436666493

Epoch: 6| Step: 4
Training loss: 2.747624324800757
Validation loss: 2.464847678388144

Epoch: 6| Step: 5
Training loss: 3.297343288628214
Validation loss: 2.4727333501483293

Epoch: 6| Step: 6
Training loss: 2.3016142446342993
Validation loss: 2.4883386918869275

Epoch: 6| Step: 7
Training loss: 3.3142286864199146
Validation loss: 2.482984890070561

Epoch: 6| Step: 8
Training loss: 3.261825322220401
Validation loss: 2.496537909245995

Epoch: 6| Step: 9
Training loss: 1.7139113548217393
Validation loss: 2.4861861205959492

Epoch: 6| Step: 10
Training loss: 2.481985802695147
Validation loss: 2.472965608045758

Epoch: 6| Step: 11
Training loss: 2.7350441250214246
Validation loss: 2.4651426806810237

Epoch: 6| Step: 12
Training loss: 2.7542944235514195
Validation loss: 2.4601879691445485

Epoch: 6| Step: 13
Training loss: 2.6150001609029045
Validation loss: 2.453761618871826

Epoch: 162| Step: 0
Training loss: 3.0543587354051747
Validation loss: 2.461251315701791

Epoch: 6| Step: 1
Training loss: 2.1868015809230137
Validation loss: 2.4733944226990565

Epoch: 6| Step: 2
Training loss: 2.4583810273624795
Validation loss: 2.49080741412876

Epoch: 6| Step: 3
Training loss: 3.2657315907581834
Validation loss: 2.4985728117619903

Epoch: 6| Step: 4
Training loss: 2.5106608059727433
Validation loss: 2.496161480675287

Epoch: 6| Step: 5
Training loss: 2.406801532108478
Validation loss: 2.5013915906000657

Epoch: 6| Step: 6
Training loss: 2.014605242016025
Validation loss: 2.5002117600535034

Epoch: 6| Step: 7
Training loss: 2.7898094395194426
Validation loss: 2.501447244352674

Epoch: 6| Step: 8
Training loss: 2.6253659129558304
Validation loss: 2.490960129227498

Epoch: 6| Step: 9
Training loss: 3.402573307321142
Validation loss: 2.4760526711571083

Epoch: 6| Step: 10
Training loss: 2.6285772018487683
Validation loss: 2.4738265849050993

Epoch: 6| Step: 11
Training loss: 2.812160980136867
Validation loss: 2.4555177897869593

Epoch: 6| Step: 12
Training loss: 2.6888159258149784
Validation loss: 2.4542749135726143

Epoch: 6| Step: 13
Training loss: 3.370276501232975
Validation loss: 2.4567638251487702

Epoch: 163| Step: 0
Training loss: 3.1011516769795078
Validation loss: 2.4589652470632157

Epoch: 6| Step: 1
Training loss: 2.8394383871840323
Validation loss: 2.4525626866404675

Epoch: 6| Step: 2
Training loss: 2.936010754266735
Validation loss: 2.451403897494273

Epoch: 6| Step: 3
Training loss: 3.0210836547967
Validation loss: 2.4484110950566715

Epoch: 6| Step: 4
Training loss: 2.374030467454112
Validation loss: 2.4518268139854884

Epoch: 6| Step: 5
Training loss: 2.8303948666782097
Validation loss: 2.462190043721184

Epoch: 6| Step: 6
Training loss: 3.14025542708533
Validation loss: 2.4636733971141482

Epoch: 6| Step: 7
Training loss: 2.4957208250370146
Validation loss: 2.4797774231523504

Epoch: 6| Step: 8
Training loss: 2.451895824988631
Validation loss: 2.482604735692393

Epoch: 6| Step: 9
Training loss: 2.4667645933284605
Validation loss: 2.4831636312900276

Epoch: 6| Step: 10
Training loss: 2.656146776774218
Validation loss: 2.516948979556681

Epoch: 6| Step: 11
Training loss: 3.0542630342179016
Validation loss: 2.494807831572719

Epoch: 6| Step: 12
Training loss: 2.7932458273292182
Validation loss: 2.477908635206053

Epoch: 6| Step: 13
Training loss: 1.2711809912661758
Validation loss: 2.465313034194512

Epoch: 164| Step: 0
Training loss: 2.8055109286981796
Validation loss: 2.4651389659543583

Epoch: 6| Step: 1
Training loss: 2.533101099646493
Validation loss: 2.4670290812784037

Epoch: 6| Step: 2
Training loss: 2.9619937512462573
Validation loss: 2.454794157081065

Epoch: 6| Step: 3
Training loss: 2.778051701920776
Validation loss: 2.4618413522905547

Epoch: 6| Step: 4
Training loss: 2.5316392575710416
Validation loss: 2.460371504943416

Epoch: 6| Step: 5
Training loss: 2.5587624064761094
Validation loss: 2.463431334642181

Epoch: 6| Step: 6
Training loss: 2.6449717122460012
Validation loss: 2.4668372581922373

Epoch: 6| Step: 7
Training loss: 2.553129415146408
Validation loss: 2.462379325140672

Epoch: 6| Step: 8
Training loss: 2.501486050487772
Validation loss: 2.4671492864267925

Epoch: 6| Step: 9
Training loss: 2.541490632094898
Validation loss: 2.481656426535526

Epoch: 6| Step: 10
Training loss: 2.64669436364211
Validation loss: 2.4890291765401975

Epoch: 6| Step: 11
Training loss: 3.046328138524062
Validation loss: 2.511755500041954

Epoch: 6| Step: 12
Training loss: 3.32853445480459
Validation loss: 2.5216302800974497

Epoch: 6| Step: 13
Training loss: 2.812010913285069
Validation loss: 2.5094657955386657

Epoch: 165| Step: 0
Training loss: 2.398908040862172
Validation loss: 2.4945787726933353

Epoch: 6| Step: 1
Training loss: 3.079284449601501
Validation loss: 2.4834339766319053

Epoch: 6| Step: 2
Training loss: 3.165168324072885
Validation loss: 2.4729505499004674

Epoch: 6| Step: 3
Training loss: 2.6034892510854695
Validation loss: 2.471758536705574

Epoch: 6| Step: 4
Training loss: 3.3033707252128632
Validation loss: 2.485012786492968

Epoch: 6| Step: 5
Training loss: 2.214430136299686
Validation loss: 2.4961209741584467

Epoch: 6| Step: 6
Training loss: 2.4139264015918642
Validation loss: 2.5090916099428737

Epoch: 6| Step: 7
Training loss: 2.8333324731563683
Validation loss: 2.5153286137084216

Epoch: 6| Step: 8
Training loss: 3.0512322985031326
Validation loss: 2.482081258285775

Epoch: 6| Step: 9
Training loss: 2.4083803332889406
Validation loss: 2.4671640573377966

Epoch: 6| Step: 10
Training loss: 2.4430358818938678
Validation loss: 2.456848927612554

Epoch: 6| Step: 11
Training loss: 2.037237527241515
Validation loss: 2.450400825553891

Epoch: 6| Step: 12
Training loss: 3.0705151673032263
Validation loss: 2.4508571055118735

Epoch: 6| Step: 13
Training loss: 2.731714665672174
Validation loss: 2.4459871872798336

Epoch: 166| Step: 0
Training loss: 2.9061479448017087
Validation loss: 2.441078938912749

Epoch: 6| Step: 1
Training loss: 2.9151376985510775
Validation loss: 2.448904101099804

Epoch: 6| Step: 2
Training loss: 3.2192129154094125
Validation loss: 2.4621474019080485

Epoch: 6| Step: 3
Training loss: 3.150834073040813
Validation loss: 2.470161148906702

Epoch: 6| Step: 4
Training loss: 2.69598990510924
Validation loss: 2.501055505929727

Epoch: 6| Step: 5
Training loss: 2.9059300400358934
Validation loss: 2.527541941399479

Epoch: 6| Step: 6
Training loss: 2.823502952437684
Validation loss: 2.50656080540782

Epoch: 6| Step: 7
Training loss: 2.7076122106404434
Validation loss: 2.521814795103016

Epoch: 6| Step: 8
Training loss: 2.1945873433946725
Validation loss: 2.501289305934274

Epoch: 6| Step: 9
Training loss: 2.19460678975515
Validation loss: 2.4722481882897

Epoch: 6| Step: 10
Training loss: 2.5810339035946672
Validation loss: 2.4683275387021495

Epoch: 6| Step: 11
Training loss: 2.4475798896009513
Validation loss: 2.4653959323873877

Epoch: 6| Step: 12
Training loss: 2.623677601826336
Validation loss: 2.4603473591850067

Epoch: 6| Step: 13
Training loss: 2.6221055012478183
Validation loss: 2.456985073319867

Epoch: 167| Step: 0
Training loss: 3.3970961455764006
Validation loss: 2.460785168869822

Epoch: 6| Step: 1
Training loss: 2.3086861787162962
Validation loss: 2.4666844609984246

Epoch: 6| Step: 2
Training loss: 2.853423047244809
Validation loss: 2.4593759494550387

Epoch: 6| Step: 3
Training loss: 2.4227310144524696
Validation loss: 2.4452378692346013

Epoch: 6| Step: 4
Training loss: 3.1505760332240023
Validation loss: 2.4503096349058273

Epoch: 6| Step: 5
Training loss: 2.3588830296008463
Validation loss: 2.4553067618929045

Epoch: 6| Step: 6
Training loss: 2.130251622090496
Validation loss: 2.4516219684109943

Epoch: 6| Step: 7
Training loss: 3.16634002473229
Validation loss: 2.469014822464958

Epoch: 6| Step: 8
Training loss: 2.85268064550422
Validation loss: 2.49253832304582

Epoch: 6| Step: 9
Training loss: 2.4973540609218845
Validation loss: 2.518306681907032

Epoch: 6| Step: 10
Training loss: 2.3820656528409496
Validation loss: 2.5231345654678825

Epoch: 6| Step: 11
Training loss: 2.8314794384282043
Validation loss: 2.539654065201473

Epoch: 6| Step: 12
Training loss: 2.703441535189136
Validation loss: 2.537665852622061

Epoch: 6| Step: 13
Training loss: 3.0782498561884193
Validation loss: 2.5285244508700155

Epoch: 168| Step: 0
Training loss: 2.582021369857468
Validation loss: 2.4889881151731568

Epoch: 6| Step: 1
Training loss: 2.9891963978602125
Validation loss: 2.475766453418714

Epoch: 6| Step: 2
Training loss: 2.8036634015312347
Validation loss: 2.477869652261336

Epoch: 6| Step: 3
Training loss: 2.57350808783921
Validation loss: 2.4828170273781356

Epoch: 6| Step: 4
Training loss: 3.4146990499076826
Validation loss: 2.47572430742974

Epoch: 6| Step: 5
Training loss: 2.7171052364204984
Validation loss: 2.4968768988105703

Epoch: 6| Step: 6
Training loss: 2.6242401294796998
Validation loss: 2.4787267734325806

Epoch: 6| Step: 7
Training loss: 2.8980554704221166
Validation loss: 2.477632125389807

Epoch: 6| Step: 8
Training loss: 2.514758416891115
Validation loss: 2.475876494962685

Epoch: 6| Step: 9
Training loss: 2.51018347916852
Validation loss: 2.4635301451075526

Epoch: 6| Step: 10
Training loss: 2.5496330071942728
Validation loss: 2.478070761838068

Epoch: 6| Step: 11
Training loss: 2.8974087681202456
Validation loss: 2.4933797035799063

Epoch: 6| Step: 12
Training loss: 2.2849060443284515
Validation loss: 2.48769139302647

Epoch: 6| Step: 13
Training loss: 2.099760963822809
Validation loss: 2.5166918678817467

Epoch: 169| Step: 0
Training loss: 2.9954010362827983
Validation loss: 2.5350181225570236

Epoch: 6| Step: 1
Training loss: 2.3442263309910722
Validation loss: 2.5601237694881847

Epoch: 6| Step: 2
Training loss: 2.4407911334476573
Validation loss: 2.5740685941767465

Epoch: 6| Step: 3
Training loss: 3.1617533228260952
Validation loss: 2.6108281834022384

Epoch: 6| Step: 4
Training loss: 2.243959902665216
Validation loss: 2.599937437186675

Epoch: 6| Step: 5
Training loss: 2.925046943222647
Validation loss: 2.5855300989361196

Epoch: 6| Step: 6
Training loss: 2.925022490325278
Validation loss: 2.5504809380262308

Epoch: 6| Step: 7
Training loss: 3.0084053545191694
Validation loss: 2.5111398715111175

Epoch: 6| Step: 8
Training loss: 2.6136027367882577
Validation loss: 2.477575741113194

Epoch: 6| Step: 9
Training loss: 3.0690377964788604
Validation loss: 2.4585114719204695

Epoch: 6| Step: 10
Training loss: 2.789042154873712
Validation loss: 2.4348048067387493

Epoch: 6| Step: 11
Training loss: 2.5273669564598213
Validation loss: 2.4446857231896377

Epoch: 6| Step: 12
Training loss: 2.7939206508600063
Validation loss: 2.439893428298087

Epoch: 6| Step: 13
Training loss: 1.9089601980808966
Validation loss: 2.4314710437761002

Epoch: 170| Step: 0
Training loss: 3.1477980047077962
Validation loss: 2.4359731254079233

Epoch: 6| Step: 1
Training loss: 2.57360517630728
Validation loss: 2.4317160483863653

Epoch: 6| Step: 2
Training loss: 2.6440593349129906
Validation loss: 2.4429008907731173

Epoch: 6| Step: 3
Training loss: 2.739940798878666
Validation loss: 2.4596176491207475

Epoch: 6| Step: 4
Training loss: 3.0671000285023093
Validation loss: 2.478659343092904

Epoch: 6| Step: 5
Training loss: 2.51224095921271
Validation loss: 2.535174074989926

Epoch: 6| Step: 6
Training loss: 2.742350255586694
Validation loss: 2.6056338371386527

Epoch: 6| Step: 7
Training loss: 2.4531162529078725
Validation loss: 2.6460013154990434

Epoch: 6| Step: 8
Training loss: 3.546690679793941
Validation loss: 2.7419748961543506

Epoch: 6| Step: 9
Training loss: 2.633434912577438
Validation loss: 2.67299119534699

Epoch: 6| Step: 10
Training loss: 2.622274527953008
Validation loss: 2.6716652623365187

Epoch: 6| Step: 11
Training loss: 2.7251634041326094
Validation loss: 2.6145280398205912

Epoch: 6| Step: 12
Training loss: 2.8313509419954075
Validation loss: 2.5311968154819366

Epoch: 6| Step: 13
Training loss: 2.4473145305742903
Validation loss: 2.476583156031788

Epoch: 171| Step: 0
Training loss: 3.376393207223163
Validation loss: 2.4502921258209724

Epoch: 6| Step: 1
Training loss: 2.463079386290947
Validation loss: 2.4600960491757116

Epoch: 6| Step: 2
Training loss: 2.898830829264926
Validation loss: 2.458756675441521

Epoch: 6| Step: 3
Training loss: 2.7108740015865784
Validation loss: 2.483571100039609

Epoch: 6| Step: 4
Training loss: 3.0686235514458726
Validation loss: 2.4882999465246924

Epoch: 6| Step: 5
Training loss: 3.550803273618443
Validation loss: 2.5003670238448716

Epoch: 6| Step: 6
Training loss: 1.9350895808181634
Validation loss: 2.5015484874911116

Epoch: 6| Step: 7
Training loss: 2.514015962633487
Validation loss: 2.519826387068865

Epoch: 6| Step: 8
Training loss: 2.77167620542731
Validation loss: 2.527219281714641

Epoch: 6| Step: 9
Training loss: 2.0581568447954397
Validation loss: 2.5762518975955015

Epoch: 6| Step: 10
Training loss: 2.6648347244400625
Validation loss: 2.638532764632305

Epoch: 6| Step: 11
Training loss: 2.854921969601735
Validation loss: 2.6548797557312103

Epoch: 6| Step: 12
Training loss: 2.5099907562571984
Validation loss: 2.651221094567367

Epoch: 6| Step: 13
Training loss: 3.4933310051053663
Validation loss: 2.6257000579062173

Epoch: 172| Step: 0
Training loss: 2.7316300047050626
Validation loss: 2.573515583975623

Epoch: 6| Step: 1
Training loss: 2.5899107681279743
Validation loss: 2.5262974465695898

Epoch: 6| Step: 2
Training loss: 2.61559864609726
Validation loss: 2.504574408426944

Epoch: 6| Step: 3
Training loss: 2.564547209455573
Validation loss: 2.4704774322144782

Epoch: 6| Step: 4
Training loss: 2.3023829430595812
Validation loss: 2.454094952040173

Epoch: 6| Step: 5
Training loss: 3.1641747725547607
Validation loss: 2.44955502894009

Epoch: 6| Step: 6
Training loss: 2.9581449923312237
Validation loss: 2.45414517353873

Epoch: 6| Step: 7
Training loss: 2.753138571802087
Validation loss: 2.4509777910507076

Epoch: 6| Step: 8
Training loss: 2.959925979513545
Validation loss: 2.4552714264504947

Epoch: 6| Step: 9
Training loss: 2.396130275292455
Validation loss: 2.4582268347874074

Epoch: 6| Step: 10
Training loss: 2.117922722102796
Validation loss: 2.4704497526855427

Epoch: 6| Step: 11
Training loss: 3.2645033959049576
Validation loss: 2.474282412240652

Epoch: 6| Step: 12
Training loss: 2.8043637739704548
Validation loss: 2.4797684258106054

Epoch: 6| Step: 13
Training loss: 2.3537028258018258
Validation loss: 2.486117546881509

Epoch: 173| Step: 0
Training loss: 2.3277683881005293
Validation loss: 2.498190673213476

Epoch: 6| Step: 1
Training loss: 2.798520674925783
Validation loss: 2.5188558645150283

Epoch: 6| Step: 2
Training loss: 2.7212742454559655
Validation loss: 2.5308247944251288

Epoch: 6| Step: 3
Training loss: 3.0522965149535772
Validation loss: 2.5590709359966772

Epoch: 6| Step: 4
Training loss: 3.319984904565159
Validation loss: 2.56196875158894

Epoch: 6| Step: 5
Training loss: 3.169665539543306
Validation loss: 2.573663481021359

Epoch: 6| Step: 6
Training loss: 2.993185569100957
Validation loss: 2.5509469477959112

Epoch: 6| Step: 7
Training loss: 2.56448120194788
Validation loss: 2.5134066078673403

Epoch: 6| Step: 8
Training loss: 2.7490794635165634
Validation loss: 2.483065890168094

Epoch: 6| Step: 9
Training loss: 1.9550015399273126
Validation loss: 2.476393354110565

Epoch: 6| Step: 10
Training loss: 2.4661265086806936
Validation loss: 2.4745711947757596

Epoch: 6| Step: 11
Training loss: 2.836757404775277
Validation loss: 2.4782614816397213

Epoch: 6| Step: 12
Training loss: 2.0685348076126675
Validation loss: 2.473254016213828

Epoch: 6| Step: 13
Training loss: 2.8317000412466347
Validation loss: 2.473562745535082

Epoch: 174| Step: 0
Training loss: 2.72825915169542
Validation loss: 2.4881532130996304

Epoch: 6| Step: 1
Training loss: 2.8537305141323417
Validation loss: 2.4819280020273813

Epoch: 6| Step: 2
Training loss: 2.6253442084476446
Validation loss: 2.480500336564534

Epoch: 6| Step: 3
Training loss: 2.9795952513107045
Validation loss: 2.461417015225042

Epoch: 6| Step: 4
Training loss: 3.016302003123668
Validation loss: 2.4484826037026797

Epoch: 6| Step: 5
Training loss: 2.9043274129404932
Validation loss: 2.4714043100827325

Epoch: 6| Step: 6
Training loss: 2.779178233506259
Validation loss: 2.476885618884516

Epoch: 6| Step: 7
Training loss: 2.7868210791132153
Validation loss: 2.4954745710809627

Epoch: 6| Step: 8
Training loss: 2.3555262417838656
Validation loss: 2.502752116188838

Epoch: 6| Step: 9
Training loss: 2.224521169680498
Validation loss: 2.525765946393403

Epoch: 6| Step: 10
Training loss: 2.2864721438281186
Validation loss: 2.532868908135099

Epoch: 6| Step: 11
Training loss: 3.016140118023009
Validation loss: 2.5332203555160153

Epoch: 6| Step: 12
Training loss: 2.9819258781446973
Validation loss: 2.5293202834844224

Epoch: 6| Step: 13
Training loss: 2.5153817953696516
Validation loss: 2.5177419034772854

Epoch: 175| Step: 0
Training loss: 2.7523945873285447
Validation loss: 2.511080920577917

Epoch: 6| Step: 1
Training loss: 2.9627708858468087
Validation loss: 2.4880627168027707

Epoch: 6| Step: 2
Training loss: 2.95708994637088
Validation loss: 2.479751116458442

Epoch: 6| Step: 3
Training loss: 2.2807178660517367
Validation loss: 2.463754787061972

Epoch: 6| Step: 4
Training loss: 2.7859887033358097
Validation loss: 2.4580602954833863

Epoch: 6| Step: 5
Training loss: 2.8374359123621975
Validation loss: 2.4628899057330056

Epoch: 6| Step: 6
Training loss: 2.725774875326184
Validation loss: 2.4578671695588694

Epoch: 6| Step: 7
Training loss: 2.9138206402018985
Validation loss: 2.452796250922102

Epoch: 6| Step: 8
Training loss: 2.5940842930106154
Validation loss: 2.463077685578307

Epoch: 6| Step: 9
Training loss: 2.4388244160805637
Validation loss: 2.4709154898901153

Epoch: 6| Step: 10
Training loss: 2.0252128677571166
Validation loss: 2.4734571231359572

Epoch: 6| Step: 11
Training loss: 2.736243955310124
Validation loss: 2.4766972628942034

Epoch: 6| Step: 12
Training loss: 2.8937430396109596
Validation loss: 2.4761301842560473

Epoch: 6| Step: 13
Training loss: 2.3293380137445467
Validation loss: 2.4816790726492215

Epoch: 176| Step: 0
Training loss: 2.337145642842862
Validation loss: 2.5024646177498444

Epoch: 6| Step: 1
Training loss: 2.3514108197032644
Validation loss: 2.50145975174901

Epoch: 6| Step: 2
Training loss: 2.4880493630912373
Validation loss: 2.5066831280202275

Epoch: 6| Step: 3
Training loss: 2.4952238235530024
Validation loss: 2.500201560683265

Epoch: 6| Step: 4
Training loss: 3.4088637097105887
Validation loss: 2.502209934609179

Epoch: 6| Step: 5
Training loss: 2.9012207487341843
Validation loss: 2.4949677041062315

Epoch: 6| Step: 6
Training loss: 2.7591383559298155
Validation loss: 2.5011971898881167

Epoch: 6| Step: 7
Training loss: 2.396484474486805
Validation loss: 2.5011362467515443

Epoch: 6| Step: 8
Training loss: 3.1450852942613037
Validation loss: 2.5125601632164583

Epoch: 6| Step: 9
Training loss: 2.423733103055324
Validation loss: 2.514545245380465

Epoch: 6| Step: 10
Training loss: 2.6632869184393972
Validation loss: 2.512609105931586

Epoch: 6| Step: 11
Training loss: 2.2012424948465275
Validation loss: 2.509119956952498

Epoch: 6| Step: 12
Training loss: 3.0117567483011474
Validation loss: 2.5139223243570092

Epoch: 6| Step: 13
Training loss: 2.7591787957566516
Validation loss: 2.5188393693036857

Epoch: 177| Step: 0
Training loss: 2.3855170238545464
Validation loss: 2.5141929403008847

Epoch: 6| Step: 1
Training loss: 2.5047430821163412
Validation loss: 2.5229791450813837

Epoch: 6| Step: 2
Training loss: 2.388559683459929
Validation loss: 2.518734680664976

Epoch: 6| Step: 3
Training loss: 2.291711309749526
Validation loss: 2.5312626548581405

Epoch: 6| Step: 4
Training loss: 1.8146665055505895
Validation loss: 2.5358490692370026

Epoch: 6| Step: 5
Training loss: 3.0304660373251746
Validation loss: 2.5633166962840086

Epoch: 6| Step: 6
Training loss: 3.1558889050287857
Validation loss: 2.5501355437789988

Epoch: 6| Step: 7
Training loss: 3.1765698794510477
Validation loss: 2.555201208582103

Epoch: 6| Step: 8
Training loss: 2.7710235836329153
Validation loss: 2.5465652475755776

Epoch: 6| Step: 9
Training loss: 2.533932430134205
Validation loss: 2.5312013397340274

Epoch: 6| Step: 10
Training loss: 2.730875271508231
Validation loss: 2.527651598133742

Epoch: 6| Step: 11
Training loss: 3.0902076246511574
Validation loss: 2.5294670916530975

Epoch: 6| Step: 12
Training loss: 3.122375454278045
Validation loss: 2.516770238917582

Epoch: 6| Step: 13
Training loss: 1.5687816236735688
Validation loss: 2.52215562915961

Epoch: 178| Step: 0
Training loss: 2.712457148481545
Validation loss: 2.5464668553359657

Epoch: 6| Step: 1
Training loss: 2.8065950924890455
Validation loss: 2.5441608916355096

Epoch: 6| Step: 2
Training loss: 2.699892790749842
Validation loss: 2.5803976821547456

Epoch: 6| Step: 3
Training loss: 2.510655867918875
Validation loss: 2.6032364993385277

Epoch: 6| Step: 4
Training loss: 3.1351644387080015
Validation loss: 2.6066312728074323

Epoch: 6| Step: 5
Training loss: 2.6295562439390916
Validation loss: 2.58297216951926

Epoch: 6| Step: 6
Training loss: 2.5373287913625413
Validation loss: 2.5522403798472086

Epoch: 6| Step: 7
Training loss: 2.806150177197593
Validation loss: 2.544304497800342

Epoch: 6| Step: 8
Training loss: 2.311323124175974
Validation loss: 2.5158653269318907

Epoch: 6| Step: 9
Training loss: 2.848688553352055
Validation loss: 2.5004968590396857

Epoch: 6| Step: 10
Training loss: 2.8494974262087367
Validation loss: 2.496445378607126

Epoch: 6| Step: 11
Training loss: 2.6295054689485755
Validation loss: 2.483406979862535

Epoch: 6| Step: 12
Training loss: 2.1617225087212084
Validation loss: 2.4781361278073106

Epoch: 6| Step: 13
Training loss: 2.7366421265456284
Validation loss: 2.47322859272856

Epoch: 179| Step: 0
Training loss: 3.359194728538845
Validation loss: 2.478541153541371

Epoch: 6| Step: 1
Training loss: 2.0563964698825017
Validation loss: 2.469451154667317

Epoch: 6| Step: 2
Training loss: 2.5969815632867457
Validation loss: 2.4668067292333173

Epoch: 6| Step: 3
Training loss: 2.9680711471996197
Validation loss: 2.468904034819737

Epoch: 6| Step: 4
Training loss: 2.486045707491137
Validation loss: 2.46888304508042

Epoch: 6| Step: 5
Training loss: 2.3383426595743417
Validation loss: 2.469687717181738

Epoch: 6| Step: 6
Training loss: 2.352371026130886
Validation loss: 2.4765605921977496

Epoch: 6| Step: 7
Training loss: 2.913747980157192
Validation loss: 2.474143829558893

Epoch: 6| Step: 8
Training loss: 2.766587601723071
Validation loss: 2.4856932373807727

Epoch: 6| Step: 9
Training loss: 2.3311119631893096
Validation loss: 2.5084664516293116

Epoch: 6| Step: 10
Training loss: 3.0097417019754142
Validation loss: 2.5270386440517183

Epoch: 6| Step: 11
Training loss: 2.1700663548533607
Validation loss: 2.530470251589173

Epoch: 6| Step: 12
Training loss: 2.581902805198039
Validation loss: 2.5298717802443673

Epoch: 6| Step: 13
Training loss: 3.167694644381997
Validation loss: 2.532918163885391

Epoch: 180| Step: 0
Training loss: 2.5054008320047334
Validation loss: 2.5149808229718187

Epoch: 6| Step: 1
Training loss: 3.0367983349066976
Validation loss: 2.489984769751938

Epoch: 6| Step: 2
Training loss: 3.063947063257672
Validation loss: 2.4845091895162326

Epoch: 6| Step: 3
Training loss: 2.249815403465451
Validation loss: 2.484820986745816

Epoch: 6| Step: 4
Training loss: 3.026874648635091
Validation loss: 2.485672099084515

Epoch: 6| Step: 5
Training loss: 2.7985876370043172
Validation loss: 2.4778057888046794

Epoch: 6| Step: 6
Training loss: 2.359809582835537
Validation loss: 2.48646881393985

Epoch: 6| Step: 7
Training loss: 2.350766272099385
Validation loss: 2.4860263051580915

Epoch: 6| Step: 8
Training loss: 2.47109632416554
Validation loss: 2.4963249060866284

Epoch: 6| Step: 9
Training loss: 2.511699480662137
Validation loss: 2.51027760413896

Epoch: 6| Step: 10
Training loss: 1.8059912261918747
Validation loss: 2.529697749971244

Epoch: 6| Step: 11
Training loss: 2.536311234759139
Validation loss: 2.53471800524292

Epoch: 6| Step: 12
Training loss: 3.469341880545422
Validation loss: 2.5331283946547503

Epoch: 6| Step: 13
Training loss: 2.125423837916497
Validation loss: 2.54223620043388

Epoch: 181| Step: 0
Training loss: 2.643839758393141
Validation loss: 2.527367424076216

Epoch: 6| Step: 1
Training loss: 1.8889137909999258
Validation loss: 2.520552345371289

Epoch: 6| Step: 2
Training loss: 2.7916336816765375
Validation loss: 2.508271688066901

Epoch: 6| Step: 3
Training loss: 2.4281308992724147
Validation loss: 2.50994264292733

Epoch: 6| Step: 4
Training loss: 2.546947922862036
Validation loss: 2.500963926604718

Epoch: 6| Step: 5
Training loss: 2.8451804451461236
Validation loss: 2.505830934836454

Epoch: 6| Step: 6
Training loss: 3.241270519328458
Validation loss: 2.507687183942392

Epoch: 6| Step: 7
Training loss: 2.616078520439278
Validation loss: 2.5143970612755284

Epoch: 6| Step: 8
Training loss: 3.010679627299674
Validation loss: 2.5018510364656477

Epoch: 6| Step: 9
Training loss: 2.9347462834614877
Validation loss: 2.4914476956168397

Epoch: 6| Step: 10
Training loss: 2.6163162831067486
Validation loss: 2.5162621543876855

Epoch: 6| Step: 11
Training loss: 2.7310826998871796
Validation loss: 2.523145559146787

Epoch: 6| Step: 12
Training loss: 2.5284098951515737
Validation loss: 2.55338485374812

Epoch: 6| Step: 13
Training loss: 2.22207145841773
Validation loss: 2.5676168571787517

Epoch: 182| Step: 0
Training loss: 3.1954612790565475
Validation loss: 2.6049601773770137

Epoch: 6| Step: 1
Training loss: 2.6746463791460364
Validation loss: 2.630884790479336

Epoch: 6| Step: 2
Training loss: 2.3151603036832005
Validation loss: 2.6370326897371257

Epoch: 6| Step: 3
Training loss: 2.8376862989932734
Validation loss: 2.631297625596196

Epoch: 6| Step: 4
Training loss: 2.8004788670449963
Validation loss: 2.5955038376658495

Epoch: 6| Step: 5
Training loss: 2.677879591105931
Validation loss: 2.5894433056887447

Epoch: 6| Step: 6
Training loss: 2.708299216031103
Validation loss: 2.579087564879309

Epoch: 6| Step: 7
Training loss: 2.894164851135276
Validation loss: 2.5576959909428827

Epoch: 6| Step: 8
Training loss: 2.4670797564877844
Validation loss: 2.5331728432934804

Epoch: 6| Step: 9
Training loss: 2.537294024296112
Validation loss: 2.51984290837526

Epoch: 6| Step: 10
Training loss: 2.740029553720403
Validation loss: 2.511892529702346

Epoch: 6| Step: 11
Training loss: 1.9817060409026483
Validation loss: 2.5006059301977013

Epoch: 6| Step: 12
Training loss: 2.213254543457056
Validation loss: 2.4961273059126508

Epoch: 6| Step: 13
Training loss: 3.1572329057699964
Validation loss: 2.4984741917892315

Epoch: 183| Step: 0
Training loss: 2.7289512685168895
Validation loss: 2.510203322873602

Epoch: 6| Step: 1
Training loss: 2.570135788799859
Validation loss: 2.5017845122160547

Epoch: 6| Step: 2
Training loss: 2.6566380834378007
Validation loss: 2.491236865915911

Epoch: 6| Step: 3
Training loss: 2.685488191830434
Validation loss: 2.48690117665017

Epoch: 6| Step: 4
Training loss: 3.105459997776582
Validation loss: 2.472247623142433

Epoch: 6| Step: 5
Training loss: 2.3993168812355803
Validation loss: 2.4640255852335002

Epoch: 6| Step: 6
Training loss: 2.399125289463019
Validation loss: 2.458384292419202

Epoch: 6| Step: 7
Training loss: 2.3907959322188415
Validation loss: 2.461518991436621

Epoch: 6| Step: 8
Training loss: 3.408614711447839
Validation loss: 2.479881790137753

Epoch: 6| Step: 9
Training loss: 2.7405688951027907
Validation loss: 2.5015662383610717

Epoch: 6| Step: 10
Training loss: 2.086257281419265
Validation loss: 2.5207721152245774

Epoch: 6| Step: 11
Training loss: 2.8208293071438235
Validation loss: 2.5701560618565686

Epoch: 6| Step: 12
Training loss: 2.1257060504862215
Validation loss: 2.6277675103274714

Epoch: 6| Step: 13
Training loss: 2.844236898135393
Validation loss: 2.612503425276781

Epoch: 184| Step: 0
Training loss: 2.44728783721464
Validation loss: 2.6010318722325865

Epoch: 6| Step: 1
Training loss: 2.3890692940934093
Validation loss: 2.552961987205418

Epoch: 6| Step: 2
Training loss: 2.4116002831311296
Validation loss: 2.4982849411486674

Epoch: 6| Step: 3
Training loss: 2.58719367089096
Validation loss: 2.4551885586563604

Epoch: 6| Step: 4
Training loss: 2.8856380850511987
Validation loss: 2.441588644060453

Epoch: 6| Step: 5
Training loss: 2.1631736720356467
Validation loss: 2.4421015275515527

Epoch: 6| Step: 6
Training loss: 2.986005088244815
Validation loss: 2.442758992358541

Epoch: 6| Step: 7
Training loss: 2.643110200556836
Validation loss: 2.448277146907045

Epoch: 6| Step: 8
Training loss: 2.3470865532706076
Validation loss: 2.4506211072597277

Epoch: 6| Step: 9
Training loss: 2.90320501473888
Validation loss: 2.4606761068895486

Epoch: 6| Step: 10
Training loss: 3.33612060044381
Validation loss: 2.4542577717392615

Epoch: 6| Step: 11
Training loss: 2.369108119656697
Validation loss: 2.4577019285403465

Epoch: 6| Step: 12
Training loss: 3.2058995581472467
Validation loss: 2.456067772596826

Epoch: 6| Step: 13
Training loss: 1.9716305322740588
Validation loss: 2.4633368308737844

Epoch: 185| Step: 0
Training loss: 2.186879424215782
Validation loss: 2.4726527280007566

Epoch: 6| Step: 1
Training loss: 2.3768832118865237
Validation loss: 2.4830000757896986

Epoch: 6| Step: 2
Training loss: 2.5660517199470783
Validation loss: 2.4845333135345724

Epoch: 6| Step: 3
Training loss: 2.6642302071594193
Validation loss: 2.4898741223579037

Epoch: 6| Step: 4
Training loss: 2.761492815717351
Validation loss: 2.498947818386224

Epoch: 6| Step: 5
Training loss: 2.5248713243386827
Validation loss: 2.516389183864259

Epoch: 6| Step: 6
Training loss: 2.5095020912832062
Validation loss: 2.524358406293563

Epoch: 6| Step: 7
Training loss: 2.6483462157595317
Validation loss: 2.5273010896454204

Epoch: 6| Step: 8
Training loss: 2.92216400512349
Validation loss: 2.5370600136817423

Epoch: 6| Step: 9
Training loss: 2.5917132550270603
Validation loss: 2.550902128484437

Epoch: 6| Step: 10
Training loss: 2.6150131075003586
Validation loss: 2.5557630646259692

Epoch: 6| Step: 11
Training loss: 3.0074746474721925
Validation loss: 2.568944260716132

Epoch: 6| Step: 12
Training loss: 2.2303481729120476
Validation loss: 2.585391851623404

Epoch: 6| Step: 13
Training loss: 2.90197817321393
Validation loss: 2.5686223844030223

Epoch: 186| Step: 0
Training loss: 2.6719946583506022
Validation loss: 2.550194658509987

Epoch: 6| Step: 1
Training loss: 1.6676716238346316
Validation loss: 2.541914296573335

Epoch: 6| Step: 2
Training loss: 2.8549361665073256
Validation loss: 2.513577230506083

Epoch: 6| Step: 3
Training loss: 2.6025892642906743
Validation loss: 2.5047265569099366

Epoch: 6| Step: 4
Training loss: 2.057660638742389
Validation loss: 2.495823019488723

Epoch: 6| Step: 5
Training loss: 2.897210779245694
Validation loss: 2.4848096367631847

Epoch: 6| Step: 6
Training loss: 3.0529430510891222
Validation loss: 2.4657917193161474

Epoch: 6| Step: 7
Training loss: 2.5599290930345604
Validation loss: 2.4628640869274303

Epoch: 6| Step: 8
Training loss: 2.502102254075531
Validation loss: 2.4597780188092666

Epoch: 6| Step: 9
Training loss: 2.829761516376069
Validation loss: 2.46209971038106

Epoch: 6| Step: 10
Training loss: 2.383994887864949
Validation loss: 2.45859565051413

Epoch: 6| Step: 11
Training loss: 2.8951713482314165
Validation loss: 2.4703172781830616

Epoch: 6| Step: 12
Training loss: 2.7355412203305294
Validation loss: 2.4732865085961695

Epoch: 6| Step: 13
Training loss: 2.2681591725343933
Validation loss: 2.486161709453101

Epoch: 187| Step: 0
Training loss: 2.4654426149471935
Validation loss: 2.501625236219593

Epoch: 6| Step: 1
Training loss: 2.9544932914343973
Validation loss: 2.508618285880788

Epoch: 6| Step: 2
Training loss: 2.7476892299587217
Validation loss: 2.5281640802642276

Epoch: 6| Step: 3
Training loss: 2.984489079237335
Validation loss: 2.527927350383417

Epoch: 6| Step: 4
Training loss: 2.0962484455500956
Validation loss: 2.5615262338078226

Epoch: 6| Step: 5
Training loss: 2.726609893649254
Validation loss: 2.5672541271138343

Epoch: 6| Step: 6
Training loss: 2.686238369781183
Validation loss: 2.5682076048617137

Epoch: 6| Step: 7
Training loss: 2.9448928331652624
Validation loss: 2.5403596095029637

Epoch: 6| Step: 8
Training loss: 2.2081658881661594
Validation loss: 2.507971782735327

Epoch: 6| Step: 9
Training loss: 2.6449546756718996
Validation loss: 2.528850437436337

Epoch: 6| Step: 10
Training loss: 2.1761903771959594
Validation loss: 2.5264990492820822

Epoch: 6| Step: 11
Training loss: 1.756120333517455
Validation loss: 2.5176403665771896

Epoch: 6| Step: 12
Training loss: 2.816794444088276
Validation loss: 2.5234037840430354

Epoch: 6| Step: 13
Training loss: 2.544242668711792
Validation loss: 2.522626812581145

Epoch: 188| Step: 0
Training loss: 2.6682131475210613
Validation loss: 2.536943327184373

Epoch: 6| Step: 1
Training loss: 2.138416794148897
Validation loss: 2.540101016113221

Epoch: 6| Step: 2
Training loss: 2.5400287374237474
Validation loss: 2.5390149749271083

Epoch: 6| Step: 3
Training loss: 2.455185431879501
Validation loss: 2.523386148184048

Epoch: 6| Step: 4
Training loss: 1.8492136031330202
Validation loss: 2.535640328854514

Epoch: 6| Step: 5
Training loss: 2.4396814219634964
Validation loss: 2.541085163760362

Epoch: 6| Step: 6
Training loss: 2.8030067444419764
Validation loss: 2.5580775117354597

Epoch: 6| Step: 7
Training loss: 2.3443802049864324
Validation loss: 2.5578833690929987

Epoch: 6| Step: 8
Training loss: 2.7592233825710375
Validation loss: 2.5605430053272205

Epoch: 6| Step: 9
Training loss: 2.8287823160831356
Validation loss: 2.5479415169375224

Epoch: 6| Step: 10
Training loss: 2.6291129270483244
Validation loss: 2.569653708854945

Epoch: 6| Step: 11
Training loss: 2.646771022010885
Validation loss: 2.5664533707338575

Epoch: 6| Step: 12
Training loss: 2.2844818424230464
Validation loss: 2.562398371268131

Epoch: 6| Step: 13
Training loss: 3.6242126399007426
Validation loss: 2.571881725827947

Epoch: 189| Step: 0
Training loss: 2.688094938208111
Validation loss: 2.582365127146878

Epoch: 6| Step: 1
Training loss: 1.8683566977712824
Validation loss: 2.5794142973685035

Epoch: 6| Step: 2
Training loss: 3.5304715809279976
Validation loss: 2.5611109456560004

Epoch: 6| Step: 3
Training loss: 2.2226804923024397
Validation loss: 2.552284429352552

Epoch: 6| Step: 4
Training loss: 2.0428002253328925
Validation loss: 2.536397809214504

Epoch: 6| Step: 5
Training loss: 2.985941690375134
Validation loss: 2.5188006351060936

Epoch: 6| Step: 6
Training loss: 2.3222640850039573
Validation loss: 2.5059646137909564

Epoch: 6| Step: 7
Training loss: 2.4150127034613376
Validation loss: 2.5240794263518427

Epoch: 6| Step: 8
Training loss: 2.1473785565002257
Validation loss: 2.5448480312566537

Epoch: 6| Step: 9
Training loss: 2.405645220169318
Validation loss: 2.559402420438158

Epoch: 6| Step: 10
Training loss: 2.53538401657643
Validation loss: 2.5380754590278336

Epoch: 6| Step: 11
Training loss: 2.4182745966579784
Validation loss: 2.527861112792312

Epoch: 6| Step: 12
Training loss: 3.038794498345327
Validation loss: 2.5083627578546115

Epoch: 6| Step: 13
Training loss: 2.9471510756815005
Validation loss: 2.491049305879594

Epoch: 190| Step: 0
Training loss: 1.998688685160803
Validation loss: 2.4866313288840445

Epoch: 6| Step: 1
Training loss: 3.2296495794350233
Validation loss: 2.504787747886901

Epoch: 6| Step: 2
Training loss: 2.860881804461114
Validation loss: 2.493756686726552

Epoch: 6| Step: 3
Training loss: 2.688075336706192
Validation loss: 2.496487916201672

Epoch: 6| Step: 4
Training loss: 2.706617976096788
Validation loss: 2.5007239308785696

Epoch: 6| Step: 5
Training loss: 2.226704803737914
Validation loss: 2.4950080860090837

Epoch: 6| Step: 6
Training loss: 2.908060801797845
Validation loss: 2.495586868561496

Epoch: 6| Step: 7
Training loss: 2.1574952220311308
Validation loss: 2.51615662595134

Epoch: 6| Step: 8
Training loss: 2.350672353781263
Validation loss: 2.5248989966712596

Epoch: 6| Step: 9
Training loss: 2.39131384007074
Validation loss: 2.524996779496738

Epoch: 6| Step: 10
Training loss: 1.8674360931778284
Validation loss: 2.5173855068753586

Epoch: 6| Step: 11
Training loss: 2.6358335464321474
Validation loss: 2.5233114278302566

Epoch: 6| Step: 12
Training loss: 2.6043662236365392
Validation loss: 2.5351741751015595

Epoch: 6| Step: 13
Training loss: 2.227814546547489
Validation loss: 2.5360081114266118

Epoch: 191| Step: 0
Training loss: 3.6129806146046217
Validation loss: 2.5449016774453255

Epoch: 6| Step: 1
Training loss: 2.8988189857502307
Validation loss: 2.560076854700039

Epoch: 6| Step: 2
Training loss: 2.285674520555369
Validation loss: 2.569766680388673

Epoch: 6| Step: 3
Training loss: 1.8961633946878755
Validation loss: 2.543091841592496

Epoch: 6| Step: 4
Training loss: 2.194615480810263
Validation loss: 2.5629873025007566

Epoch: 6| Step: 5
Training loss: 3.0515804635968005
Validation loss: 2.5595782040173107

Epoch: 6| Step: 6
Training loss: 2.355751741784541
Validation loss: 2.5623059603229694

Epoch: 6| Step: 7
Training loss: 2.626362764750961
Validation loss: 2.5569490866961035

Epoch: 6| Step: 8
Training loss: 2.096099218815662
Validation loss: 2.5541163095700874

Epoch: 6| Step: 9
Training loss: 2.5558750763693165
Validation loss: 2.5519783552593482

Epoch: 6| Step: 10
Training loss: 1.9145243184898089
Validation loss: 2.549495010471713

Epoch: 6| Step: 11
Training loss: 2.573213279605176
Validation loss: 2.5426861315312888

Epoch: 6| Step: 12
Training loss: 2.270783333417493
Validation loss: 2.532128565805303

Epoch: 6| Step: 13
Training loss: 2.2237284509516395
Validation loss: 2.5446628108190494

Epoch: 192| Step: 0
Training loss: 2.334978193716296
Validation loss: 2.5476401859497777

Epoch: 6| Step: 1
Training loss: 2.2566690156249196
Validation loss: 2.5477036552953143

Epoch: 6| Step: 2
Training loss: 2.3013538108008933
Validation loss: 2.5620262694541074

Epoch: 6| Step: 3
Training loss: 2.7991076886829913
Validation loss: 2.545190292332721

Epoch: 6| Step: 4
Training loss: 2.2960957353550238
Validation loss: 2.5548450102424907

Epoch: 6| Step: 5
Training loss: 3.20546015776176
Validation loss: 2.568011589557378

Epoch: 6| Step: 6
Training loss: 2.5120712673622796
Validation loss: 2.5488292223401086

Epoch: 6| Step: 7
Training loss: 2.320317740386286
Validation loss: 2.5530504873182776

Epoch: 6| Step: 8
Training loss: 2.5452122789747706
Validation loss: 2.55384464791093

Epoch: 6| Step: 9
Training loss: 2.8880032583836486
Validation loss: 2.565005652347025

Epoch: 6| Step: 10
Training loss: 2.127456815574932
Validation loss: 2.5656518438412097

Epoch: 6| Step: 11
Training loss: 2.8942225159026074
Validation loss: 2.5584264732348903

Epoch: 6| Step: 12
Training loss: 2.1832177891138964
Validation loss: 2.54209823582274

Epoch: 6| Step: 13
Training loss: 2.381897297186527
Validation loss: 2.5209622398888896

Epoch: 193| Step: 0
Training loss: 2.4872906927487133
Validation loss: 2.5001145490429475

Epoch: 6| Step: 1
Training loss: 2.4733101942757107
Validation loss: 2.5068331395009014

Epoch: 6| Step: 2
Training loss: 2.4221092849129504
Validation loss: 2.5293046592699993

Epoch: 6| Step: 3
Training loss: 2.4701470393843357
Validation loss: 2.5129575707486578

Epoch: 6| Step: 4
Training loss: 2.094751033328801
Validation loss: 2.499376990512009

Epoch: 6| Step: 5
Training loss: 2.2921834767520184
Validation loss: 2.4966796524238286

Epoch: 6| Step: 6
Training loss: 1.9530447981580097
Validation loss: 2.5141381805049443

Epoch: 6| Step: 7
Training loss: 3.0787125234921056
Validation loss: 2.5286341248135766

Epoch: 6| Step: 8
Training loss: 2.5550892365282105
Validation loss: 2.5150278318035335

Epoch: 6| Step: 9
Training loss: 2.4367342014929707
Validation loss: 2.536215573184965

Epoch: 6| Step: 10
Training loss: 2.5108217622186686
Validation loss: 2.531020039218146

Epoch: 6| Step: 11
Training loss: 2.7680990930801825
Validation loss: 2.547778119121389

Epoch: 6| Step: 12
Training loss: 2.5054207207525194
Validation loss: 2.540354614133971

Epoch: 6| Step: 13
Training loss: 2.664951567648117
Validation loss: 2.5506926902489937

Epoch: 194| Step: 0
Training loss: 2.6639457967931617
Validation loss: 2.5746259554456326

Epoch: 6| Step: 1
Training loss: 2.9057961386409783
Validation loss: 2.606544675526653

Epoch: 6| Step: 2
Training loss: 2.484146587500117
Validation loss: 2.5822569628825236

Epoch: 6| Step: 3
Training loss: 2.4177094106303363
Validation loss: 2.536933579656782

Epoch: 6| Step: 4
Training loss: 2.539918444217764
Validation loss: 2.510943511741899

Epoch: 6| Step: 5
Training loss: 2.4594429442970296
Validation loss: 2.5071548480275014

Epoch: 6| Step: 6
Training loss: 2.457923811946178
Validation loss: 2.511099754644432

Epoch: 6| Step: 7
Training loss: 2.2525444478551333
Validation loss: 2.51953919162947

Epoch: 6| Step: 8
Training loss: 2.1578653891211887
Validation loss: 2.5317167244025085

Epoch: 6| Step: 9
Training loss: 2.0634878856025107
Validation loss: 2.5342408374966787

Epoch: 6| Step: 10
Training loss: 2.30985882430908
Validation loss: 2.539519880194707

Epoch: 6| Step: 11
Training loss: 2.8692277099190275
Validation loss: 2.527334837802624

Epoch: 6| Step: 12
Training loss: 2.627407151023563
Validation loss: 2.544227939217727

Epoch: 6| Step: 13
Training loss: 2.123951260447516
Validation loss: 2.5528294948951813

Epoch: 195| Step: 0
Training loss: 2.4570029155510515
Validation loss: 2.55290714116175

Epoch: 6| Step: 1
Training loss: 2.031054208562666
Validation loss: 2.5320527426720076

Epoch: 6| Step: 2
Training loss: 2.3814648428689944
Validation loss: 2.524636194748625

Epoch: 6| Step: 3
Training loss: 2.083958061645616
Validation loss: 2.516546243887162

Epoch: 6| Step: 4
Training loss: 1.7082354664875872
Validation loss: 2.4990951756747637

Epoch: 6| Step: 5
Training loss: 2.4019437627505984
Validation loss: 2.48966010938933

Epoch: 6| Step: 6
Training loss: 2.491309223456836
Validation loss: 2.4812858705207823

Epoch: 6| Step: 7
Training loss: 2.9892734451159355
Validation loss: 2.4794800469729235

Epoch: 6| Step: 8
Training loss: 2.9286498813554815
Validation loss: 2.4701896852861127

Epoch: 6| Step: 9
Training loss: 2.639552152389785
Validation loss: 2.463143669037039

Epoch: 6| Step: 10
Training loss: 2.8261187270939887
Validation loss: 2.457875787096083

Epoch: 6| Step: 11
Training loss: 2.552368418022916
Validation loss: 2.451600988609537

Epoch: 6| Step: 12
Training loss: 2.4753777109790174
Validation loss: 2.4615609421854168

Epoch: 6| Step: 13
Training loss: 2.2351723695378416
Validation loss: 2.4735284337005905

Epoch: 196| Step: 0
Training loss: 2.0185778376151933
Validation loss: 2.4836193856779363

Epoch: 6| Step: 1
Training loss: 2.2332131092488243
Validation loss: 2.495275795007349

Epoch: 6| Step: 2
Training loss: 1.6428318258668642
Validation loss: 2.520987700621879

Epoch: 6| Step: 3
Training loss: 2.67878961673551
Validation loss: 2.515806632445526

Epoch: 6| Step: 4
Training loss: 2.221879927445969
Validation loss: 2.514751124839549

Epoch: 6| Step: 5
Training loss: 2.2345994956604325
Validation loss: 2.502785845054546

Epoch: 6| Step: 6
Training loss: 2.251189870926248
Validation loss: 2.509267323751296

Epoch: 6| Step: 7
Training loss: 2.9992552468617335
Validation loss: 2.5109066599673797

Epoch: 6| Step: 8
Training loss: 2.6961344916759233
Validation loss: 2.523720916891066

Epoch: 6| Step: 9
Training loss: 2.2004430151427745
Validation loss: 2.5173661556530456

Epoch: 6| Step: 10
Training loss: 2.4376954220415006
Validation loss: 2.501316678527944

Epoch: 6| Step: 11
Training loss: 2.8299520923886403
Validation loss: 2.490029588032564

Epoch: 6| Step: 12
Training loss: 2.7180933543012338
Validation loss: 2.4831985120176157

Epoch: 6| Step: 13
Training loss: 2.7091621500112746
Validation loss: 2.482037259123769

Epoch: 197| Step: 0
Training loss: 2.589481564335551
Validation loss: 2.4724673208867096

Epoch: 6| Step: 1
Training loss: 2.064763763067783
Validation loss: 2.4828466841936634

Epoch: 6| Step: 2
Training loss: 2.6124784550850735
Validation loss: 2.4768393258858765

Epoch: 6| Step: 3
Training loss: 2.948688707025952
Validation loss: 2.4627362234330423

Epoch: 6| Step: 4
Training loss: 2.2450023885599526
Validation loss: 2.4713178441989374

Epoch: 6| Step: 5
Training loss: 2.8540571614070056
Validation loss: 2.474056139287988

Epoch: 6| Step: 6
Training loss: 2.551079211277438
Validation loss: 2.485533466061107

Epoch: 6| Step: 7
Training loss: 2.4230551520733106
Validation loss: 2.4837181588728288

Epoch: 6| Step: 8
Training loss: 1.7660022433861797
Validation loss: 2.519296594840413

Epoch: 6| Step: 9
Training loss: 2.4880070078588576
Validation loss: 2.5177246108158053

Epoch: 6| Step: 10
Training loss: 2.3784475902262647
Validation loss: 2.533248074278297

Epoch: 6| Step: 11
Training loss: 2.2348510661842553
Validation loss: 2.5485939733975873

Epoch: 6| Step: 12
Training loss: 2.2364539231812257
Validation loss: 2.5521018119044254

Epoch: 6| Step: 13
Training loss: 1.8274859754282555
Validation loss: 2.593076172394436

Epoch: 198| Step: 0
Training loss: 2.6147411243095866
Validation loss: 2.6344274859434886

Epoch: 6| Step: 1
Training loss: 2.50971508643182
Validation loss: 2.677242354929772

Epoch: 6| Step: 2
Training loss: 2.598246709502379
Validation loss: 2.6584105553296964

Epoch: 6| Step: 3
Training loss: 2.9234135294940247
Validation loss: 2.624947181635147

Epoch: 6| Step: 4
Training loss: 1.5223051117436894
Validation loss: 2.584427912941524

Epoch: 6| Step: 5
Training loss: 2.483833493891734
Validation loss: 2.563499631872643

Epoch: 6| Step: 6
Training loss: 2.066568004139923
Validation loss: 2.5444789607424485

Epoch: 6| Step: 7
Training loss: 2.7111798708522197
Validation loss: 2.519173613649051

Epoch: 6| Step: 8
Training loss: 2.2786822564983304
Validation loss: 2.5131464978681812

Epoch: 6| Step: 9
Training loss: 2.352740832172205
Validation loss: 2.5193713569320186

Epoch: 6| Step: 10
Training loss: 2.169844522136123
Validation loss: 2.5061598885879164

Epoch: 6| Step: 11
Training loss: 2.639059742756155
Validation loss: 2.506380354286615

Epoch: 6| Step: 12
Training loss: 2.1723868226661893
Validation loss: 2.5079229948537325

Epoch: 6| Step: 13
Training loss: 2.2158604463159697
Validation loss: 2.5059528501081423

Epoch: 199| Step: 0
Training loss: 2.826450842934155
Validation loss: 2.5059223178813004

Epoch: 6| Step: 1
Training loss: 2.5848640910857896
Validation loss: 2.508141386020491

Epoch: 6| Step: 2
Training loss: 2.895008454516358
Validation loss: 2.535230863943149

Epoch: 6| Step: 3
Training loss: 2.397996197090601
Validation loss: 2.579564838692319

Epoch: 6| Step: 4
Training loss: 2.1524722412304365
Validation loss: 2.5690888385387103

Epoch: 6| Step: 5
Training loss: 2.1341594313509176
Validation loss: 2.592333993606675

Epoch: 6| Step: 6
Training loss: 2.136631937721722
Validation loss: 2.5768985589303273

Epoch: 6| Step: 7
Training loss: 2.3118392412731112
Validation loss: 2.528723819018805

Epoch: 6| Step: 8
Training loss: 2.6882624764356464
Validation loss: 2.5156886799000113

Epoch: 6| Step: 9
Training loss: 2.319594866303277
Validation loss: 2.4793507459478317

Epoch: 6| Step: 10
Training loss: 2.156210746960704
Validation loss: 2.4720958956119654

Epoch: 6| Step: 11
Training loss: 2.283346910737966
Validation loss: 2.4586237622357077

Epoch: 6| Step: 12
Training loss: 2.246772889004228
Validation loss: 2.4596390441625626

Epoch: 6| Step: 13
Training loss: 2.134898189466755
Validation loss: 2.4651739301295024

Epoch: 200| Step: 0
Training loss: 2.656579748891277
Validation loss: 2.47231455953055

Epoch: 6| Step: 1
Training loss: 2.705267437531701
Validation loss: 2.4652303359982968

Epoch: 6| Step: 2
Training loss: 2.3689232433246272
Validation loss: 2.477864030158089

Epoch: 6| Step: 3
Training loss: 2.540528329133842
Validation loss: 2.473932397228268

Epoch: 6| Step: 4
Training loss: 2.3345038566108136
Validation loss: 2.4833306787491387

Epoch: 6| Step: 5
Training loss: 2.185918945059239
Validation loss: 2.5204234426023313

Epoch: 6| Step: 6
Training loss: 2.0024268208632736
Validation loss: 2.5382532649810607

Epoch: 6| Step: 7
Training loss: 1.5661908617598959
Validation loss: 2.5465748615926844

Epoch: 6| Step: 8
Training loss: 2.482443196394962
Validation loss: 2.5896830861200946

Epoch: 6| Step: 9
Training loss: 2.7360167887825098
Validation loss: 2.5527575073052744

Epoch: 6| Step: 10
Training loss: 2.371985379391105
Validation loss: 2.5129621472212387

Epoch: 6| Step: 11
Training loss: 2.516544150429229
Validation loss: 2.4747695496118762

Epoch: 6| Step: 12
Training loss: 2.282415223067065
Validation loss: 2.484516321652718

Epoch: 6| Step: 13
Training loss: 2.5692319134859467
Validation loss: 2.4757942438434233

Epoch: 201| Step: 0
Training loss: 2.0389270956748433
Validation loss: 2.48233150437318

Epoch: 6| Step: 1
Training loss: 2.136526151411797
Validation loss: 2.503203271798349

Epoch: 6| Step: 2
Training loss: 2.1752565254558105
Validation loss: 2.5142314457069075

Epoch: 6| Step: 3
Training loss: 2.4416014570396847
Validation loss: 2.5291610305636025

Epoch: 6| Step: 4
Training loss: 2.5868408837917807
Validation loss: 2.5438590321944776

Epoch: 6| Step: 5
Training loss: 2.6294238642311143
Validation loss: 2.55881928207105

Epoch: 6| Step: 6
Training loss: 2.4735258239668845
Validation loss: 2.5517626951269903

Epoch: 6| Step: 7
Training loss: 2.3962269888077943
Validation loss: 2.546488576755322

Epoch: 6| Step: 8
Training loss: 2.5711700029404896
Validation loss: 2.5520754250024478

Epoch: 6| Step: 9
Training loss: 2.4364394790770154
Validation loss: 2.5727006006872783

Epoch: 6| Step: 10
Training loss: 1.9368342824855407
Validation loss: 2.5826230592693302

Epoch: 6| Step: 11
Training loss: 2.2194896056294273
Validation loss: 2.5851967961516666

Epoch: 6| Step: 12
Training loss: 2.567728987811251
Validation loss: 2.56580273802206

Epoch: 6| Step: 13
Training loss: 2.4652163168061865
Validation loss: 2.540944298527106

Epoch: 202| Step: 0
Training loss: 2.408139960457621
Validation loss: 2.5292547847938742

Epoch: 6| Step: 1
Training loss: 2.4801625941412966
Validation loss: 2.53571205929716

Epoch: 6| Step: 2
Training loss: 2.3940963972565283
Validation loss: 2.5158839142527567

Epoch: 6| Step: 3
Training loss: 2.0268742306143506
Validation loss: 2.5186490396047634

Epoch: 6| Step: 4
Training loss: 2.4975083332094576
Validation loss: 2.479416791611135

Epoch: 6| Step: 5
Training loss: 2.698791028373917
Validation loss: 2.4488280272628447

Epoch: 6| Step: 6
Training loss: 2.332713680639938
Validation loss: 2.4490327569019823

Epoch: 6| Step: 7
Training loss: 2.663124971065239
Validation loss: 2.428284906193618

Epoch: 6| Step: 8
Training loss: 2.2945322558225794
Validation loss: 2.4299108284370443

Epoch: 6| Step: 9
Training loss: 1.861915583736463
Validation loss: 2.4134304526627917

Epoch: 6| Step: 10
Training loss: 1.9092440621140219
Validation loss: 2.4171577615167545

Epoch: 6| Step: 11
Training loss: 2.267372562313972
Validation loss: 2.407861166733032

Epoch: 6| Step: 12
Training loss: 2.2798606090433426
Validation loss: 2.4397376574922167

Epoch: 6| Step: 13
Training loss: 2.600312903722478
Validation loss: 2.4654491388305604

Epoch: 203| Step: 0
Training loss: 2.861292128613168
Validation loss: 2.4896663849801635

Epoch: 6| Step: 1
Training loss: 2.3537078905517164
Validation loss: 2.4986566179797642

Epoch: 6| Step: 2
Training loss: 2.6976596508562585
Validation loss: 2.5102572493668105

Epoch: 6| Step: 3
Training loss: 2.479595072513416
Validation loss: 2.525032077326854

Epoch: 6| Step: 4
Training loss: 2.2180411052558275
Validation loss: 2.5170709236270774

Epoch: 6| Step: 5
Training loss: 2.208922961230455
Validation loss: 2.506589662758498

Epoch: 6| Step: 6
Training loss: 1.9536626457264532
Validation loss: 2.500282760749561

Epoch: 6| Step: 7
Training loss: 2.1429526489409483
Validation loss: 2.514875286641216

Epoch: 6| Step: 8
Training loss: 2.0559486608960436
Validation loss: 2.5182963267718352

Epoch: 6| Step: 9
Training loss: 2.1753499067499176
Validation loss: 2.5202517566153544

Epoch: 6| Step: 10
Training loss: 2.3342965272431884
Validation loss: 2.520018916286134

Epoch: 6| Step: 11
Training loss: 2.4227216655777575
Validation loss: 2.5203412008733066

Epoch: 6| Step: 12
Training loss: 2.094997660560485
Validation loss: 2.5186196359046122

Epoch: 6| Step: 13
Training loss: 1.6066511491894095
Validation loss: 2.533424031251037

Epoch: 204| Step: 0
Training loss: 2.65937979817658
Validation loss: 2.545500574132262

Epoch: 6| Step: 1
Training loss: 2.5371567367115153
Validation loss: 2.533842423531781

Epoch: 6| Step: 2
Training loss: 2.1218963846693715
Validation loss: 2.5296681975232302

Epoch: 6| Step: 3
Training loss: 2.6342253473928854
Validation loss: 2.533460236734899

Epoch: 6| Step: 4
Training loss: 1.8321161636813017
Validation loss: 2.54508042476927

Epoch: 6| Step: 5
Training loss: 2.033757701219117
Validation loss: 2.5216580611955206

Epoch: 6| Step: 6
Training loss: 2.2017995756789404
Validation loss: 2.496953290096212

Epoch: 6| Step: 7
Training loss: 2.1242764306944393
Validation loss: 2.4901507336835613

Epoch: 6| Step: 8
Training loss: 2.2510705096650443
Validation loss: 2.490429200142277

Epoch: 6| Step: 9
Training loss: 1.8582895781265378
Validation loss: 2.4743261721624132

Epoch: 6| Step: 10
Training loss: 2.0441754426183327
Validation loss: 2.4579817859646966

Epoch: 6| Step: 11
Training loss: 2.578093372497764
Validation loss: 2.475262558331936

Epoch: 6| Step: 12
Training loss: 2.139942589462121
Validation loss: 2.4675474528566563

Epoch: 6| Step: 13
Training loss: 2.413847188390634
Validation loss: 2.488196861986965

Epoch: 205| Step: 0
Training loss: 1.5266700292880633
Validation loss: 2.4770676463316836

Epoch: 6| Step: 1
Training loss: 2.3613573045718295
Validation loss: 2.494002408233

Epoch: 6| Step: 2
Training loss: 2.3254950088713158
Validation loss: 2.517643536453388

Epoch: 6| Step: 3
Training loss: 2.6832278694925598
Validation loss: 2.5610580989644793

Epoch: 6| Step: 4
Training loss: 2.2369898720700863
Validation loss: 2.584788263711841

Epoch: 6| Step: 5
Training loss: 2.219202774485619
Validation loss: 2.5640835394914743

Epoch: 6| Step: 6
Training loss: 2.197897804022628
Validation loss: 2.5270396098404384

Epoch: 6| Step: 7
Training loss: 2.357361193036314
Validation loss: 2.517500101924036

Epoch: 6| Step: 8
Training loss: 2.0163265456387416
Validation loss: 2.499002695611651

Epoch: 6| Step: 9
Training loss: 1.976322928524096
Validation loss: 2.5021311823142405

Epoch: 6| Step: 10
Training loss: 2.3224495958457614
Validation loss: 2.5073633638659953

Epoch: 6| Step: 11
Training loss: 2.3976474914689123
Validation loss: 2.4916733913459153

Epoch: 6| Step: 12
Training loss: 2.262107064705909
Validation loss: 2.4898102785122105

Epoch: 6| Step: 13
Training loss: 2.6987561327682155
Validation loss: 2.474251964783698

Epoch: 206| Step: 0
Training loss: 1.9330206744276928
Validation loss: 2.4769965856599643

Epoch: 6| Step: 1
Training loss: 2.5399682879533345
Validation loss: 2.5028365706590794

Epoch: 6| Step: 2
Training loss: 1.678278274213857
Validation loss: 2.5331383926303412

Epoch: 6| Step: 3
Training loss: 2.502212975473448
Validation loss: 2.547049499247171

Epoch: 6| Step: 4
Training loss: 2.727360736987435
Validation loss: 2.5775387994659895

Epoch: 6| Step: 5
Training loss: 2.4535104242277908
Validation loss: 2.552571130325744

Epoch: 6| Step: 6
Training loss: 2.307185484177299
Validation loss: 2.5252641386794865

Epoch: 6| Step: 7
Training loss: 1.770170992980867
Validation loss: 2.5190264488122356

Epoch: 6| Step: 8
Training loss: 2.453923963927926
Validation loss: 2.530150529842738

Epoch: 6| Step: 9
Training loss: 2.143039316426385
Validation loss: 2.5181831911936645

Epoch: 6| Step: 10
Training loss: 1.9015901235989172
Validation loss: 2.4974902650552515

Epoch: 6| Step: 11
Training loss: 2.482074656240543
Validation loss: 2.4659625685903004

Epoch: 6| Step: 12
Training loss: 2.2599757829567073
Validation loss: 2.4453476229021898

Epoch: 6| Step: 13
Training loss: 1.7329846557184418
Validation loss: 2.451894074172902

Epoch: 207| Step: 0
Training loss: 1.4813427119474643
Validation loss: 2.4578932212973847

Epoch: 6| Step: 1
Training loss: 2.1253771727686073
Validation loss: 2.473173164851651

Epoch: 6| Step: 2
Training loss: 2.4449183722289773
Validation loss: 2.495989470314652

Epoch: 6| Step: 3
Training loss: 2.7116562827610364
Validation loss: 2.5094251298694354

Epoch: 6| Step: 4
Training loss: 2.362398547057969
Validation loss: 2.515291878160759

Epoch: 6| Step: 5
Training loss: 2.417722427565946
Validation loss: 2.4937060796970965

Epoch: 6| Step: 6
Training loss: 2.353476116434463
Validation loss: 2.500469841952692

Epoch: 6| Step: 7
Training loss: 2.018222288714759
Validation loss: 2.4900307895314997

Epoch: 6| Step: 8
Training loss: 2.713257426325639
Validation loss: 2.4880957566269872

Epoch: 6| Step: 9
Training loss: 2.2169704554150256
Validation loss: 2.4858461898316087

Epoch: 6| Step: 10
Training loss: 1.1780361718807795
Validation loss: 2.478498957506083

Epoch: 6| Step: 11
Training loss: 2.301142251363601
Validation loss: 2.466501366892089

Epoch: 6| Step: 12
Training loss: 2.4719611421759313
Validation loss: 2.4602216042276446

Epoch: 6| Step: 13
Training loss: 1.5674497405882013
Validation loss: 2.4686528959501195

Epoch: 208| Step: 0
Training loss: 2.1437376461284776
Validation loss: 2.476476662971662

Epoch: 6| Step: 1
Training loss: 2.0239521093922357
Validation loss: 2.477206056131934

Epoch: 6| Step: 2
Training loss: 2.2045797320331504
Validation loss: 2.4678023926112465

Epoch: 6| Step: 3
Training loss: 2.1401112629140027
Validation loss: 2.5159315043419315

Epoch: 6| Step: 4
Training loss: 1.8641234599759193
Validation loss: 2.5143070874383135

Epoch: 6| Step: 5
Training loss: 2.8378625646517928
Validation loss: 2.5054708998209505

Epoch: 6| Step: 6
Training loss: 2.110899536785357
Validation loss: 2.5289455260849674

Epoch: 6| Step: 7
Training loss: 2.402336306676731
Validation loss: 2.542183955698014

Epoch: 6| Step: 8
Training loss: 2.3268465974126067
Validation loss: 2.5453671012168826

Epoch: 6| Step: 9
Training loss: 2.1872621679443918
Validation loss: 2.555669449254819

Epoch: 6| Step: 10
Training loss: 2.118763917410273
Validation loss: 2.548200090338742

Epoch: 6| Step: 11
Training loss: 2.1225439351525406
Validation loss: 2.550979305810151

Epoch: 6| Step: 12
Training loss: 2.145778272595191
Validation loss: 2.5491197473843137

Epoch: 6| Step: 13
Training loss: 1.1901299315932259
Validation loss: 2.545328950999704

Epoch: 209| Step: 0
Training loss: 2.0665711191096556
Validation loss: 2.538210109252752

Epoch: 6| Step: 1
Training loss: 2.6177985090173532
Validation loss: 2.5170011379890203

Epoch: 6| Step: 2
Training loss: 2.5066696843000607
Validation loss: 2.5155760808025245

Epoch: 6| Step: 3
Training loss: 1.8747258303781154
Validation loss: 2.5179567866826593

Epoch: 6| Step: 4
Training loss: 2.395102502783614
Validation loss: 2.54362270273242

Epoch: 6| Step: 5
Training loss: 2.4635573232743324
Validation loss: 2.5497089485097524

Epoch: 6| Step: 6
Training loss: 2.1700025212145806
Validation loss: 2.5493296175334237

Epoch: 6| Step: 7
Training loss: 1.6506710017480657
Validation loss: 2.5401940486598615

Epoch: 6| Step: 8
Training loss: 2.5499935598853076
Validation loss: 2.5389840446322087

Epoch: 6| Step: 9
Training loss: 2.1803627198865323
Validation loss: 2.4804452380983797

Epoch: 6| Step: 10
Training loss: 2.142165360729358
Validation loss: 2.45785977443204

Epoch: 6| Step: 11
Training loss: 1.754721471197792
Validation loss: 2.447490045100152

Epoch: 6| Step: 12
Training loss: 1.579731039018873
Validation loss: 2.448411284575065

Epoch: 6| Step: 13
Training loss: 1.9630261122977621
Validation loss: 2.4679301239944444

Epoch: 210| Step: 0
Training loss: 2.1165249058668176
Validation loss: 2.495585382101878

Epoch: 6| Step: 1
Training loss: 2.0949368884793227
Validation loss: 2.521908231821929

Epoch: 6| Step: 2
Training loss: 2.185758060618912
Validation loss: 2.5430884998043033

Epoch: 6| Step: 3
Training loss: 2.351390540847253
Validation loss: 2.5588059529688008

Epoch: 6| Step: 4
Training loss: 2.3369356912392334
Validation loss: 2.5732379095186686

Epoch: 6| Step: 5
Training loss: 2.501575355091697
Validation loss: 2.576757008055909

Epoch: 6| Step: 6
Training loss: 2.049000459156199
Validation loss: 2.533018797900504

Epoch: 6| Step: 7
Training loss: 2.1776280672272814
Validation loss: 2.4950564061573925

Epoch: 6| Step: 8
Training loss: 2.164206820196142
Validation loss: 2.4544237172667906

Epoch: 6| Step: 9
Training loss: 2.4637407110882
Validation loss: 2.4388626566160014

Epoch: 6| Step: 10
Training loss: 2.333020075705526
Validation loss: 2.4115172344668596

Epoch: 6| Step: 11
Training loss: 2.201958421853384
Validation loss: 2.403656389443493

Epoch: 6| Step: 12
Training loss: 1.4114939930295127
Validation loss: 2.405400849100899

Epoch: 6| Step: 13
Training loss: 2.3743613538879607
Validation loss: 2.426920330839932

Epoch: 211| Step: 0
Training loss: 2.480456735176364
Validation loss: 2.4276432432114556

Epoch: 6| Step: 1
Training loss: 2.114756409525896
Validation loss: 2.4422206848878294

Epoch: 6| Step: 2
Training loss: 2.6469736020076478
Validation loss: 2.4473410591820355

Epoch: 6| Step: 3
Training loss: 2.5827480596591013
Validation loss: 2.452699264683932

Epoch: 6| Step: 4
Training loss: 2.1173933428821026
Validation loss: 2.4196553644550516

Epoch: 6| Step: 5
Training loss: 2.367801397810352
Validation loss: 2.4332824043302494

Epoch: 6| Step: 6
Training loss: 1.8846641710874545
Validation loss: 2.450985489351979

Epoch: 6| Step: 7
Training loss: 2.185907383589279
Validation loss: 2.466845009885379

Epoch: 6| Step: 8
Training loss: 1.9902207184118061
Validation loss: 2.5108749454040327

Epoch: 6| Step: 9
Training loss: 2.48210222420754
Validation loss: 2.549440021464293

Epoch: 6| Step: 10
Training loss: 1.4220502137601618
Validation loss: 2.5648362649418046

Epoch: 6| Step: 11
Training loss: 2.0549793108713117
Validation loss: 2.5953190003250994

Epoch: 6| Step: 12
Training loss: 1.7102109158815872
Validation loss: 2.602171356378831

Epoch: 6| Step: 13
Training loss: 2.1423348607770643
Validation loss: 2.570762990020847

Epoch: 212| Step: 0
Training loss: 2.3216102130796696
Validation loss: 2.519176121140932

Epoch: 6| Step: 1
Training loss: 1.5576340246934812
Validation loss: 2.4421940607697628

Epoch: 6| Step: 2
Training loss: 1.9314654726975837
Validation loss: 2.422329790944265

Epoch: 6| Step: 3
Training loss: 2.5082243108872033
Validation loss: 2.424717895756625

Epoch: 6| Step: 4
Training loss: 2.44762800963201
Validation loss: 2.419826922145003

Epoch: 6| Step: 5
Training loss: 1.7523978018789779
Validation loss: 2.4285440779049203

Epoch: 6| Step: 6
Training loss: 1.7227662066531997
Validation loss: 2.435518852170237

Epoch: 6| Step: 7
Training loss: 2.143441122952692
Validation loss: 2.4287699729793957

Epoch: 6| Step: 8
Training loss: 1.9598506636072983
Validation loss: 2.4324560952808607

Epoch: 6| Step: 9
Training loss: 1.976061429528357
Validation loss: 2.435898211661196

Epoch: 6| Step: 10
Training loss: 2.5538112059067792
Validation loss: 2.4306494948305666

Epoch: 6| Step: 11
Training loss: 1.977450687647208
Validation loss: 2.4211250056889937

Epoch: 6| Step: 12
Training loss: 2.641119916233693
Validation loss: 2.441233086726909

Epoch: 6| Step: 13
Training loss: 2.490907633407004
Validation loss: 2.450239148960849

Epoch: 213| Step: 0
Training loss: 1.9436452684061418
Validation loss: 2.4680313532720075

Epoch: 6| Step: 1
Training loss: 2.1000837491002264
Validation loss: 2.5095382823038133

Epoch: 6| Step: 2
Training loss: 1.5493781903700703
Validation loss: 2.5623891692926115

Epoch: 6| Step: 3
Training loss: 2.3233599959621847
Validation loss: 2.5915884476663567

Epoch: 6| Step: 4
Training loss: 1.6094035914575726
Validation loss: 2.62884451491923

Epoch: 6| Step: 5
Training loss: 1.9115677749388889
Validation loss: 2.6377978835272216

Epoch: 6| Step: 6
Training loss: 2.3010715890794984
Validation loss: 2.6073238708186115

Epoch: 6| Step: 7
Training loss: 1.82460779129969
Validation loss: 2.580069863954662

Epoch: 6| Step: 8
Training loss: 2.364386484520065
Validation loss: 2.553052534775304

Epoch: 6| Step: 9
Training loss: 2.7681245876784804
Validation loss: 2.523650282027521

Epoch: 6| Step: 10
Training loss: 2.1641898548096776
Validation loss: 2.5079585871626127

Epoch: 6| Step: 11
Training loss: 2.1960812780351113
Validation loss: 2.4771355267232495

Epoch: 6| Step: 12
Training loss: 2.20811114602989
Validation loss: 2.464416103819547

Epoch: 6| Step: 13
Training loss: 2.195717770782635
Validation loss: 2.455301980852066

Epoch: 214| Step: 0
Training loss: 2.0449380810231164
Validation loss: 2.4808554618803904

Epoch: 6| Step: 1
Training loss: 2.016645306350618
Validation loss: 2.4816255478618454

Epoch: 6| Step: 2
Training loss: 2.384934178049862
Validation loss: 2.4728095480095824

Epoch: 6| Step: 3
Training loss: 1.384435746214252
Validation loss: 2.4880115838578623

Epoch: 6| Step: 4
Training loss: 1.8716801817426694
Validation loss: 2.496696640076346

Epoch: 6| Step: 5
Training loss: 1.796767720876183
Validation loss: 2.50416382266024

Epoch: 6| Step: 6
Training loss: 2.2557407892938155
Validation loss: 2.489735320704409

Epoch: 6| Step: 7
Training loss: 2.2566267549637584
Validation loss: 2.477563535836439

Epoch: 6| Step: 8
Training loss: 1.943088102337
Validation loss: 2.482783025168842

Epoch: 6| Step: 9
Training loss: 1.857385677141369
Validation loss: 2.4970660652065715

Epoch: 6| Step: 10
Training loss: 2.520191194910622
Validation loss: 2.4838112988554437

Epoch: 6| Step: 11
Training loss: 1.4833814005975239
Validation loss: 2.5011708747874186

Epoch: 6| Step: 12
Training loss: 2.5229445409980586
Validation loss: 2.50784612400598

Epoch: 6| Step: 13
Training loss: 2.4894463941721634
Validation loss: 2.516373466116185

Epoch: 215| Step: 0
Training loss: 1.9249849665661645
Validation loss: 2.49170096423147

Epoch: 6| Step: 1
Training loss: 1.7729702640714238
Validation loss: 2.486659230881455

Epoch: 6| Step: 2
Training loss: 1.9283427135642723
Validation loss: 2.4836667248825677

Epoch: 6| Step: 3
Training loss: 2.5062492465733945
Validation loss: 2.4736842737560854

Epoch: 6| Step: 4
Training loss: 2.05811838528346
Validation loss: 2.462877690652911

Epoch: 6| Step: 5
Training loss: 2.74564658549208
Validation loss: 2.4508850716894295

Epoch: 6| Step: 6
Training loss: 1.799688773269852
Validation loss: 2.4696002138450677

Epoch: 6| Step: 7
Training loss: 2.0185989795802803
Validation loss: 2.4521923195454636

Epoch: 6| Step: 8
Training loss: 1.5080253174171816
Validation loss: 2.4665937517969185

Epoch: 6| Step: 9
Training loss: 1.6514667320815886
Validation loss: 2.450535506053649

Epoch: 6| Step: 10
Training loss: 2.0345673688420676
Validation loss: 2.460597099465185

Epoch: 6| Step: 11
Training loss: 1.2024402403703842
Validation loss: 2.459812012286064

Epoch: 6| Step: 12
Training loss: 2.4651646714986364
Validation loss: 2.486142442593316

Epoch: 6| Step: 13
Training loss: 2.423364390506976
Validation loss: 2.521142146586247

Epoch: 216| Step: 0
Training loss: 2.4020281328496087
Validation loss: 2.562586550047549

Epoch: 6| Step: 1
Training loss: 1.7199504474776488
Validation loss: 2.6517844490529225

Epoch: 6| Step: 2
Training loss: 2.2475352032273253
Validation loss: 2.6716197381920956

Epoch: 6| Step: 3
Training loss: 2.3113416915374203
Validation loss: 2.6904054310288092

Epoch: 6| Step: 4
Training loss: 1.8238070102955584
Validation loss: 2.6675115808700185

Epoch: 6| Step: 5
Training loss: 1.9361325637538616
Validation loss: 2.607324501079189

Epoch: 6| Step: 6
Training loss: 2.0084257265526073
Validation loss: 2.5756156893384548

Epoch: 6| Step: 7
Training loss: 1.4172909800845428
Validation loss: 2.5405998791894393

Epoch: 6| Step: 8
Training loss: 2.1952932770997244
Validation loss: 2.5035510843214994

Epoch: 6| Step: 9
Training loss: 1.9470722863915038
Validation loss: 2.4833184279447154

Epoch: 6| Step: 10
Training loss: 2.0387250248299
Validation loss: 2.4529170626229733

Epoch: 6| Step: 11
Training loss: 1.7294190540499745
Validation loss: 2.4434161050405296

Epoch: 6| Step: 12
Training loss: 2.420391194275255
Validation loss: 2.4457220495747105

Epoch: 6| Step: 13
Training loss: 1.9789140305816064
Validation loss: 2.435216341392488

Epoch: 217| Step: 0
Training loss: 1.5646294388494377
Validation loss: 2.4175314885189376

Epoch: 6| Step: 1
Training loss: 2.0849762605555195
Validation loss: 2.413495072062292

Epoch: 6| Step: 2
Training loss: 2.113052214728829
Validation loss: 2.4170676914560323

Epoch: 6| Step: 3
Training loss: 1.8803466858687568
Validation loss: 2.4408534362364187

Epoch: 6| Step: 4
Training loss: 1.4757941128850252
Validation loss: 2.498908170064348

Epoch: 6| Step: 5
Training loss: 1.8026931113235223
Validation loss: 2.539453070727952

Epoch: 6| Step: 6
Training loss: 2.0947313428704195
Validation loss: 2.551270726517605

Epoch: 6| Step: 7
Training loss: 2.3382901493289343
Validation loss: 2.5484005327468937

Epoch: 6| Step: 8
Training loss: 2.1229659050150103
Validation loss: 2.5585179175917276

Epoch: 6| Step: 9
Training loss: 2.3420550511875184
Validation loss: 2.555880591068035

Epoch: 6| Step: 10
Training loss: 2.171066902271928
Validation loss: 2.52919283512072

Epoch: 6| Step: 11
Training loss: 2.4676028133411543
Validation loss: 2.4949666103060792

Epoch: 6| Step: 12
Training loss: 1.256027471466679
Validation loss: 2.4737782630519822

Epoch: 6| Step: 13
Training loss: 2.401316551862952
Validation loss: 2.4613851811634335

Epoch: 218| Step: 0
Training loss: 2.156852085253779
Validation loss: 2.4449723619246573

Epoch: 6| Step: 1
Training loss: 2.186528235256014
Validation loss: 2.428498011946264

Epoch: 6| Step: 2
Training loss: 1.8390224429737416
Validation loss: 2.4398583813380226

Epoch: 6| Step: 3
Training loss: 1.878359011068675
Validation loss: 2.4333920608976536

Epoch: 6| Step: 4
Training loss: 1.97505715685842
Validation loss: 2.4584347975286995

Epoch: 6| Step: 5
Training loss: 1.5943132788877452
Validation loss: 2.4776069993024534

Epoch: 6| Step: 6
Training loss: 2.0360930002102977
Validation loss: 2.5050839025325216

Epoch: 6| Step: 7
Training loss: 2.1819629892065286
Validation loss: 2.508193060173145

Epoch: 6| Step: 8
Training loss: 2.063431731647411
Validation loss: 2.5280133165095995

Epoch: 6| Step: 9
Training loss: 2.000300742426035
Validation loss: 2.560641513461361

Epoch: 6| Step: 10
Training loss: 2.099430747307002
Validation loss: 2.584008855617469

Epoch: 6| Step: 11
Training loss: 2.1136878110827357
Validation loss: 2.6262062243939734

Epoch: 6| Step: 12
Training loss: 2.1936701268275716
Validation loss: 2.6233241488473715

Epoch: 6| Step: 13
Training loss: 2.1191662764864536
Validation loss: 2.6003045925976656

Epoch: 219| Step: 0
Training loss: 1.6794072826762294
Validation loss: 2.5279106425776963

Epoch: 6| Step: 1
Training loss: 2.2686007195744065
Validation loss: 2.4737764121731236

Epoch: 6| Step: 2
Training loss: 2.113933695205365
Validation loss: 2.443289718919689

Epoch: 6| Step: 3
Training loss: 1.6321599651178185
Validation loss: 2.4276581890212765

Epoch: 6| Step: 4
Training loss: 2.2366887630540413
Validation loss: 2.410065560864986

Epoch: 6| Step: 5
Training loss: 1.219099581539998
Validation loss: 2.4066361116327366

Epoch: 6| Step: 6
Training loss: 1.575788373273826
Validation loss: 2.394644637015266

Epoch: 6| Step: 7
Training loss: 2.7956492545808875
Validation loss: 2.3876534726458747

Epoch: 6| Step: 8
Training loss: 1.6180990847224828
Validation loss: 2.388727372081322

Epoch: 6| Step: 9
Training loss: 1.9257187281860946
Validation loss: 2.4152235804531506

Epoch: 6| Step: 10
Training loss: 1.849864196947889
Validation loss: 2.4423289345571475

Epoch: 6| Step: 11
Training loss: 2.3174401174501855
Validation loss: 2.4864853341862383

Epoch: 6| Step: 12
Training loss: 2.491926604100897
Validation loss: 2.526182513829197

Epoch: 6| Step: 13
Training loss: 2.1623549352070324
Validation loss: 2.5485174048537935

Epoch: 220| Step: 0
Training loss: 2.1253784067159947
Validation loss: 2.574398475116932

Epoch: 6| Step: 1
Training loss: 1.9647301703628375
Validation loss: 2.5964965022644875

Epoch: 6| Step: 2
Training loss: 1.8231450909595264
Validation loss: 2.58819243336886

Epoch: 6| Step: 3
Training loss: 1.952479202316041
Validation loss: 2.5839519213302875

Epoch: 6| Step: 4
Training loss: 2.015179843686087
Validation loss: 2.583498787386307

Epoch: 6| Step: 5
Training loss: 1.8810155373904536
Validation loss: 2.5961608673235417

Epoch: 6| Step: 6
Training loss: 2.577346406757781
Validation loss: 2.578208907555881

Epoch: 6| Step: 7
Training loss: 1.411773430631362
Validation loss: 2.5586681493860355

Epoch: 6| Step: 8
Training loss: 2.3869843530289896
Validation loss: 2.5298802041926827

Epoch: 6| Step: 9
Training loss: 1.8828229468597948
Validation loss: 2.5195298712776637

Epoch: 6| Step: 10
Training loss: 1.2366464696161992
Validation loss: 2.5212188672674585

Epoch: 6| Step: 11
Training loss: 1.9243154150673036
Validation loss: 2.5092330771727416

Epoch: 6| Step: 12
Training loss: 1.9783833074430834
Validation loss: 2.5114407087008344

Epoch: 6| Step: 13
Training loss: 1.9529313868879494
Validation loss: 2.4931837229051945

Epoch: 221| Step: 0
Training loss: 2.1119601761935844
Validation loss: 2.5091508814337042

Epoch: 6| Step: 1
Training loss: 1.715987256547431
Validation loss: 2.5136036242946105

Epoch: 6| Step: 2
Training loss: 1.332898749616347
Validation loss: 2.5112087419835682

Epoch: 6| Step: 3
Training loss: 2.3736419810646385
Validation loss: 2.5240669579129165

Epoch: 6| Step: 4
Training loss: 1.6735708602067918
Validation loss: 2.5346115115846897

Epoch: 6| Step: 5
Training loss: 2.0670035928474433
Validation loss: 2.5440004938400778

Epoch: 6| Step: 6
Training loss: 1.9488231433308496
Validation loss: 2.556948294628547

Epoch: 6| Step: 7
Training loss: 1.4665188989471762
Validation loss: 2.55285735121686

Epoch: 6| Step: 8
Training loss: 2.0573590102621693
Validation loss: 2.5723783213726947

Epoch: 6| Step: 9
Training loss: 2.0469036537086738
Validation loss: 2.560209876165406

Epoch: 6| Step: 10
Training loss: 1.5672198915034146
Validation loss: 2.533138915855632

Epoch: 6| Step: 11
Training loss: 2.1382972702747516
Validation loss: 2.4932438013458507

Epoch: 6| Step: 12
Training loss: 2.027641495025349
Validation loss: 2.48067280604473

Epoch: 6| Step: 13
Training loss: 2.0986562153331
Validation loss: 2.4511198720664273

Epoch: 222| Step: 0
Training loss: 1.9136632386118015
Validation loss: 2.4419149514127265

Epoch: 6| Step: 1
Training loss: 1.673519573460779
Validation loss: 2.4148976846252697

Epoch: 6| Step: 2
Training loss: 1.7891945602784594
Validation loss: 2.4349422460719907

Epoch: 6| Step: 3
Training loss: 2.1580353132227597
Validation loss: 2.4417143559785077

Epoch: 6| Step: 4
Training loss: 2.232187761127575
Validation loss: 2.4604219619677186

Epoch: 6| Step: 5
Training loss: 1.8846793515714406
Validation loss: 2.4873503878848733

Epoch: 6| Step: 6
Training loss: 1.9267318267539368
Validation loss: 2.5273866997370305

Epoch: 6| Step: 7
Training loss: 1.373820362389104
Validation loss: 2.5447030639845445

Epoch: 6| Step: 8
Training loss: 1.7054974891243746
Validation loss: 2.5727069412716657

Epoch: 6| Step: 9
Training loss: 1.6276044514973709
Validation loss: 2.581358932798279

Epoch: 6| Step: 10
Training loss: 1.9541336506845044
Validation loss: 2.5753830793331134

Epoch: 6| Step: 11
Training loss: 1.7829227958348597
Validation loss: 2.582266074699271

Epoch: 6| Step: 12
Training loss: 2.0683870394750494
Validation loss: 2.5408170114736914

Epoch: 6| Step: 13
Training loss: 2.5248224101547865
Validation loss: 2.5408148552765555

Epoch: 223| Step: 0
Training loss: 1.387768501214762
Validation loss: 2.5077537402210037

Epoch: 6| Step: 1
Training loss: 1.7748815899964427
Validation loss: 2.4910585063819295

Epoch: 6| Step: 2
Training loss: 1.6476463118606606
Validation loss: 2.4820367881315484

Epoch: 6| Step: 3
Training loss: 1.8987931283418638
Validation loss: 2.4677996043752946

Epoch: 6| Step: 4
Training loss: 2.10269735673283
Validation loss: 2.4659691909004393

Epoch: 6| Step: 5
Training loss: 2.205375874287013
Validation loss: 2.4710357124393707

Epoch: 6| Step: 6
Training loss: 1.3569817797000545
Validation loss: 2.48159160370771

Epoch: 6| Step: 7
Training loss: 1.5609678003923382
Validation loss: 2.4810912180878937

Epoch: 6| Step: 8
Training loss: 1.7432180871792817
Validation loss: 2.4848722751036916

Epoch: 6| Step: 9
Training loss: 1.9888880315289819
Validation loss: 2.5048902581408945

Epoch: 6| Step: 10
Training loss: 2.162427374000604
Validation loss: 2.4940592455197614

Epoch: 6| Step: 11
Training loss: 2.3319128571941454
Validation loss: 2.5131181320098746

Epoch: 6| Step: 12
Training loss: 1.965396083001282
Validation loss: 2.5092897176141635

Epoch: 6| Step: 13
Training loss: 1.6050329800363587
Validation loss: 2.5292874902603457

Epoch: 224| Step: 0
Training loss: 1.3736399079379165
Validation loss: 2.51616355732558

Epoch: 6| Step: 1
Training loss: 1.70726797177822
Validation loss: 2.52235174318892

Epoch: 6| Step: 2
Training loss: 1.831872864080646
Validation loss: 2.528022552851869

Epoch: 6| Step: 3
Training loss: 1.6183232543950985
Validation loss: 2.5319490671377674

Epoch: 6| Step: 4
Training loss: 1.7655125134850267
Validation loss: 2.5303495976349213

Epoch: 6| Step: 5
Training loss: 1.9544195538874958
Validation loss: 2.5315025393005275

Epoch: 6| Step: 6
Training loss: 1.378189722042153
Validation loss: 2.5134373276309336

Epoch: 6| Step: 7
Training loss: 2.1012719389560437
Validation loss: 2.5004085606855755

Epoch: 6| Step: 8
Training loss: 2.1542989777514103
Validation loss: 2.497459002179488

Epoch: 6| Step: 9
Training loss: 1.481998830550295
Validation loss: 2.490429635577219

Epoch: 6| Step: 10
Training loss: 2.194343977719471
Validation loss: 2.4750053189426517

Epoch: 6| Step: 11
Training loss: 2.1870791439113897
Validation loss: 2.47904014488606

Epoch: 6| Step: 12
Training loss: 1.73426392345605
Validation loss: 2.4688922046200514

Epoch: 6| Step: 13
Training loss: 2.031214082840504
Validation loss: 2.4836564771804577

Epoch: 225| Step: 0
Training loss: 1.9762261145907876
Validation loss: 2.4492714265488846

Epoch: 6| Step: 1
Training loss: 1.818826945142149
Validation loss: 2.4355927844822873

Epoch: 6| Step: 2
Training loss: 1.5675727895479068
Validation loss: 2.4403518451422466

Epoch: 6| Step: 3
Training loss: 1.6650949776397612
Validation loss: 2.4419923460640898

Epoch: 6| Step: 4
Training loss: 1.7761053780532239
Validation loss: 2.447436055951091

Epoch: 6| Step: 5
Training loss: 2.016072777978503
Validation loss: 2.4508225144986913

Epoch: 6| Step: 6
Training loss: 1.6151991705419517
Validation loss: 2.4493572310246705

Epoch: 6| Step: 7
Training loss: 2.01367424299691
Validation loss: 2.4749763926828967

Epoch: 6| Step: 8
Training loss: 1.7551465650909504
Validation loss: 2.4695315491412404

Epoch: 6| Step: 9
Training loss: 2.5245559150788037
Validation loss: 2.490653213129348

Epoch: 6| Step: 10
Training loss: 1.263089406881881
Validation loss: 2.5114662608572953

Epoch: 6| Step: 11
Training loss: 1.9441023283427308
Validation loss: 2.5217723929606835

Epoch: 6| Step: 12
Training loss: 1.6935718231513297
Validation loss: 2.561057726589332

Epoch: 6| Step: 13
Training loss: 1.6220727377361837
Validation loss: 2.5775019653885085

Epoch: 226| Step: 0
Training loss: 1.1980582720224071
Validation loss: 2.5706402760102325

Epoch: 6| Step: 1
Training loss: 1.5580833574553374
Validation loss: 2.5705247079468037

Epoch: 6| Step: 2
Training loss: 1.2177566000991171
Validation loss: 2.535781631277762

Epoch: 6| Step: 3
Training loss: 1.5712699438512134
Validation loss: 2.51833983647912

Epoch: 6| Step: 4
Training loss: 1.8907190725078697
Validation loss: 2.5189429238951946

Epoch: 6| Step: 5
Training loss: 1.6747669627219928
Validation loss: 2.495378737106981

Epoch: 6| Step: 6
Training loss: 2.420672210303896
Validation loss: 2.4999901279131493

Epoch: 6| Step: 7
Training loss: 2.2850475318021757
Validation loss: 2.4933465281357767

Epoch: 6| Step: 8
Training loss: 2.079369423356875
Validation loss: 2.500558947559746

Epoch: 6| Step: 9
Training loss: 1.8784257746336706
Validation loss: 2.4858533511334637

Epoch: 6| Step: 10
Training loss: 1.963426507326786
Validation loss: 2.5065534659839788

Epoch: 6| Step: 11
Training loss: 1.979439432187366
Validation loss: 2.5071424835662364

Epoch: 6| Step: 12
Training loss: 1.4164826142671134
Validation loss: 2.5089069419344856

Epoch: 6| Step: 13
Training loss: 2.274963495988684
Validation loss: 2.501684735846747

Epoch: 227| Step: 0
Training loss: 1.7475309665539382
Validation loss: 2.447526669684648

Epoch: 6| Step: 1
Training loss: 1.2036216998627995
Validation loss: 2.4197058160403118

Epoch: 6| Step: 2
Training loss: 1.703894904867162
Validation loss: 2.4074500481740215

Epoch: 6| Step: 3
Training loss: 1.7434788865741069
Validation loss: 2.4026741078810243

Epoch: 6| Step: 4
Training loss: 1.334477167439434
Validation loss: 2.433001886993138

Epoch: 6| Step: 5
Training loss: 2.151194963388445
Validation loss: 2.45987902339078

Epoch: 6| Step: 6
Training loss: 2.7019893487738718
Validation loss: 2.4499428847274682

Epoch: 6| Step: 7
Training loss: 1.8665678520387756
Validation loss: 2.446106578745721

Epoch: 6| Step: 8
Training loss: 1.7440791103198843
Validation loss: 2.3921252588744473

Epoch: 6| Step: 9
Training loss: 2.180392790414035
Validation loss: 2.3877408729566794

Epoch: 6| Step: 10
Training loss: 1.9282087459337767
Validation loss: 2.418203250103632

Epoch: 6| Step: 11
Training loss: 1.5792847705785746
Validation loss: 2.4390194271881525

Epoch: 6| Step: 12
Training loss: 1.7434586476398783
Validation loss: 2.47209397502939

Epoch: 6| Step: 13
Training loss: 2.0593072859842723
Validation loss: 2.513803106517717

Epoch: 228| Step: 0
Training loss: 1.6640136425027598
Validation loss: 2.522766864850042

Epoch: 6| Step: 1
Training loss: 1.123903375836986
Validation loss: 2.5166596211339747

Epoch: 6| Step: 2
Training loss: 2.0193857992834494
Validation loss: 2.5242432613615184

Epoch: 6| Step: 3
Training loss: 2.155273879984096
Validation loss: 2.528051656033333

Epoch: 6| Step: 4
Training loss: 1.4099115809319898
Validation loss: 2.5256979641364237

Epoch: 6| Step: 5
Training loss: 1.9794419615837602
Validation loss: 2.5075500681159886

Epoch: 6| Step: 6
Training loss: 1.9170120867854088
Validation loss: 2.493235963097833

Epoch: 6| Step: 7
Training loss: 1.8256441547207762
Validation loss: 2.4792410907516604

Epoch: 6| Step: 8
Training loss: 2.3135429298732926
Validation loss: 2.4377280602676614

Epoch: 6| Step: 9
Training loss: 2.0053743632224688
Validation loss: 2.427053125404648

Epoch: 6| Step: 10
Training loss: 1.6347541763105307
Validation loss: 2.415955067111556

Epoch: 6| Step: 11
Training loss: 2.1079037657166566
Validation loss: 2.4614499700676533

Epoch: 6| Step: 12
Training loss: 1.6985319306092883
Validation loss: 2.462609218392626

Epoch: 6| Step: 13
Training loss: 1.6273754803535003
Validation loss: 2.4985416445159223

Epoch: 229| Step: 0
Training loss: 2.4287749413560897
Validation loss: 2.5120596465759517

Epoch: 6| Step: 1
Training loss: 1.7738575038900548
Validation loss: 2.463192427966242

Epoch: 6| Step: 2
Training loss: 1.9672371637621475
Validation loss: 2.4303614110410634

Epoch: 6| Step: 3
Training loss: 1.9142378746187738
Validation loss: 2.407744801144068

Epoch: 6| Step: 4
Training loss: 1.7572757834044772
Validation loss: 2.3895920788660105

Epoch: 6| Step: 5
Training loss: 1.6738224986459187
Validation loss: 2.4040273248697734

Epoch: 6| Step: 6
Training loss: 1.2487021861502245
Validation loss: 2.433036749278626

Epoch: 6| Step: 7
Training loss: 1.7960971641425114
Validation loss: 2.438553390295677

Epoch: 6| Step: 8
Training loss: 1.941928601367738
Validation loss: 2.4234738304619374

Epoch: 6| Step: 9
Training loss: 1.6412433004133584
Validation loss: 2.4012344265536605

Epoch: 6| Step: 10
Training loss: 1.5326237646909495
Validation loss: 2.3788224554459365

Epoch: 6| Step: 11
Training loss: 2.523847800518947
Validation loss: 2.368058168973984

Epoch: 6| Step: 12
Training loss: 1.2794037519465835
Validation loss: 2.38657504994928

Epoch: 6| Step: 13
Training loss: 1.7039290463804169
Validation loss: 2.3847186789658306

Epoch: 230| Step: 0
Training loss: 1.991638167694794
Validation loss: 2.3913096311451594

Epoch: 6| Step: 1
Training loss: 1.7821171306300707
Validation loss: 2.403967368244756

Epoch: 6| Step: 2
Training loss: 1.5962952877302754
Validation loss: 2.4108963529049836

Epoch: 6| Step: 3
Training loss: 2.3641603962659685
Validation loss: 2.4245740085226086

Epoch: 6| Step: 4
Training loss: 1.011719810455827
Validation loss: 2.439259200607901

Epoch: 6| Step: 5
Training loss: 1.7031900935901325
Validation loss: 2.4285750852142645

Epoch: 6| Step: 6
Training loss: 1.921598833292433
Validation loss: 2.4403930913960785

Epoch: 6| Step: 7
Training loss: 2.120239760318477
Validation loss: 2.419115532282183

Epoch: 6| Step: 8
Training loss: 1.213360435913243
Validation loss: 2.4123790018839224

Epoch: 6| Step: 9
Training loss: 1.376926200008252
Validation loss: 2.4063883138259894

Epoch: 6| Step: 10
Training loss: 1.4429111636515206
Validation loss: 2.4133163787457783

Epoch: 6| Step: 11
Training loss: 1.5290735308204244
Validation loss: 2.41865471957517

Epoch: 6| Step: 12
Training loss: 1.8872621121085473
Validation loss: 2.4040093752567118

Epoch: 6| Step: 13
Training loss: 2.102073635637228
Validation loss: 2.422267883803404

Epoch: 231| Step: 0
Training loss: 1.6669687315280062
Validation loss: 2.414207714043531

Epoch: 6| Step: 1
Training loss: 1.5406181876939191
Validation loss: 2.4362398418245315

Epoch: 6| Step: 2
Training loss: 1.5822975217180577
Validation loss: 2.4491588895762226

Epoch: 6| Step: 3
Training loss: 1.4314520947231537
Validation loss: 2.453992044690776

Epoch: 6| Step: 4
Training loss: 1.504169391548598
Validation loss: 2.4759990433784136

Epoch: 6| Step: 5
Training loss: 2.173943063279904
Validation loss: 2.4891054461339666

Epoch: 6| Step: 6
Training loss: 1.9155056864933613
Validation loss: 2.509219942382446

Epoch: 6| Step: 7
Training loss: 1.1272769244631884
Validation loss: 2.510194134328275

Epoch: 6| Step: 8
Training loss: 1.4492885850393011
Validation loss: 2.539753447137069

Epoch: 6| Step: 9
Training loss: 1.837648544016424
Validation loss: 2.5312997693337187

Epoch: 6| Step: 10
Training loss: 1.7754036511571774
Validation loss: 2.5237142307694347

Epoch: 6| Step: 11
Training loss: 2.284137100794751
Validation loss: 2.511118961203925

Epoch: 6| Step: 12
Training loss: 1.919636733340004
Validation loss: 2.500746539641696

Epoch: 6| Step: 13
Training loss: 1.2637441340309388
Validation loss: 2.5033451301586553

Epoch: 232| Step: 0
Training loss: 1.3705013984442016
Validation loss: 2.4802373327117846

Epoch: 6| Step: 1
Training loss: 1.7803646363520038
Validation loss: 2.4561320467993655

Epoch: 6| Step: 2
Training loss: 1.8701969936463767
Validation loss: 2.4769771590189653

Epoch: 6| Step: 3
Training loss: 1.6477680745349648
Validation loss: 2.4512944108055583

Epoch: 6| Step: 4
Training loss: 1.3566306463391382
Validation loss: 2.4316049467018486

Epoch: 6| Step: 5
Training loss: 2.2689188198195627
Validation loss: 2.4384557692303623

Epoch: 6| Step: 6
Training loss: 1.6219788858001343
Validation loss: 2.425577286796056

Epoch: 6| Step: 7
Training loss: 1.4048210513368942
Validation loss: 2.431112729699972

Epoch: 6| Step: 8
Training loss: 1.291150061551837
Validation loss: 2.4286369329179567

Epoch: 6| Step: 9
Training loss: 2.066866327711102
Validation loss: 2.4499847375638377

Epoch: 6| Step: 10
Training loss: 1.4983697615379388
Validation loss: 2.458281066141455

Epoch: 6| Step: 11
Training loss: 1.3022691619511948
Validation loss: 2.461190017789825

Epoch: 6| Step: 12
Training loss: 2.014827955109365
Validation loss: 2.475993358527644

Epoch: 6| Step: 13
Training loss: 1.8258916792897413
Validation loss: 2.4785123916349274

Epoch: 233| Step: 0
Training loss: 1.7526055421488458
Validation loss: 2.509359669691213

Epoch: 6| Step: 1
Training loss: 1.5439301018927767
Validation loss: 2.5094608684139583

Epoch: 6| Step: 2
Training loss: 1.9615890818604744
Validation loss: 2.4852659279410396

Epoch: 6| Step: 3
Training loss: 1.278409693939375
Validation loss: 2.4872071147804142

Epoch: 6| Step: 4
Training loss: 1.954974466142472
Validation loss: 2.4796093453910757

Epoch: 6| Step: 5
Training loss: 1.9384036264222686
Validation loss: 2.4849457072696826

Epoch: 6| Step: 6
Training loss: 1.519145534171002
Validation loss: 2.4720296128726065

Epoch: 6| Step: 7
Training loss: 1.6733697644228238
Validation loss: 2.452376417150692

Epoch: 6| Step: 8
Training loss: 1.768408615003136
Validation loss: 2.4887735047942487

Epoch: 6| Step: 9
Training loss: 1.2459861206641
Validation loss: 2.480520471471761

Epoch: 6| Step: 10
Training loss: 1.8536629010327856
Validation loss: 2.4716432315198698

Epoch: 6| Step: 11
Training loss: 1.664474078218633
Validation loss: 2.4619084227037957

Epoch: 6| Step: 12
Training loss: 1.194764653737222
Validation loss: 2.473657294946518

Epoch: 6| Step: 13
Training loss: 1.6881331209780426
Validation loss: 2.473196936097099

Epoch: 234| Step: 0
Training loss: 1.3710842295259074
Validation loss: 2.4693261633757175

Epoch: 6| Step: 1
Training loss: 1.7414222713125371
Validation loss: 2.4770954925341626

Epoch: 6| Step: 2
Training loss: 1.0939535224114745
Validation loss: 2.4649529843151394

Epoch: 6| Step: 3
Training loss: 1.5522446345886112
Validation loss: 2.4735001016706004

Epoch: 6| Step: 4
Training loss: 1.4771987916544298
Validation loss: 2.4804657010825233

Epoch: 6| Step: 5
Training loss: 1.9939028666377667
Validation loss: 2.481354123170274

Epoch: 6| Step: 6
Training loss: 1.9322046704171787
Validation loss: 2.504771828377077

Epoch: 6| Step: 7
Training loss: 1.9124643310013119
Validation loss: 2.5072461040869913

Epoch: 6| Step: 8
Training loss: 1.555930556024953
Validation loss: 2.4953810846127964

Epoch: 6| Step: 9
Training loss: 1.4828232534679886
Validation loss: 2.5121331555378443

Epoch: 6| Step: 10
Training loss: 1.4941639218976237
Validation loss: 2.492787385674042

Epoch: 6| Step: 11
Training loss: 1.7857241739271774
Validation loss: 2.477153235200499

Epoch: 6| Step: 12
Training loss: 1.4056652972804429
Validation loss: 2.4963216875733205

Epoch: 6| Step: 13
Training loss: 1.896655655422774
Validation loss: 2.4721939491178326

Epoch: 235| Step: 0
Training loss: 1.4222247353836213
Validation loss: 2.4627677220178974

Epoch: 6| Step: 1
Training loss: 1.7515965399722544
Validation loss: 2.4192341018958374

Epoch: 6| Step: 2
Training loss: 1.4011026484986544
Validation loss: 2.4338328782053034

Epoch: 6| Step: 3
Training loss: 1.624655466969086
Validation loss: 2.40780168568042

Epoch: 6| Step: 4
Training loss: 1.4285030774386127
Validation loss: 2.4004375518225123

Epoch: 6| Step: 5
Training loss: 1.869569926453649
Validation loss: 2.393001058975044

Epoch: 6| Step: 6
Training loss: 1.4393502642501657
Validation loss: 2.402878238777239

Epoch: 6| Step: 7
Training loss: 1.590116960074418
Validation loss: 2.4224124011855492

Epoch: 6| Step: 8
Training loss: 1.7695794846316453
Validation loss: 2.4316834211876808

Epoch: 6| Step: 9
Training loss: 1.9620876510787553
Validation loss: 2.435881904550087

Epoch: 6| Step: 10
Training loss: 1.6704747405804243
Validation loss: 2.4894626886997804

Epoch: 6| Step: 11
Training loss: 1.4688987656593266
Validation loss: 2.4859410094066003

Epoch: 6| Step: 12
Training loss: 1.4860271695555323
Validation loss: 2.514331907952988

Epoch: 6| Step: 13
Training loss: 1.8143458996842834
Validation loss: 2.5292801123851634

Epoch: 236| Step: 0
Training loss: 1.5951959371249114
Validation loss: 2.5458283937913593

Epoch: 6| Step: 1
Training loss: 1.360798189410598
Validation loss: 2.5497509599699524

Epoch: 6| Step: 2
Training loss: 1.8784459555484314
Validation loss: 2.5287083224079407

Epoch: 6| Step: 3
Training loss: 1.871848637008344
Validation loss: 2.5031364854524

Epoch: 6| Step: 4
Training loss: 1.8711351617041134
Validation loss: 2.4959864485730123

Epoch: 6| Step: 5
Training loss: 1.3292392320266742
Validation loss: 2.482403404777915

Epoch: 6| Step: 6
Training loss: 1.950483626523072
Validation loss: 2.465548742888808

Epoch: 6| Step: 7
Training loss: 1.0242193598858191
Validation loss: 2.463651487678565

Epoch: 6| Step: 8
Training loss: 1.6428952449621337
Validation loss: 2.4395700714349706

Epoch: 6| Step: 9
Training loss: 1.569089194782783
Validation loss: 2.4560329136441577

Epoch: 6| Step: 10
Training loss: 1.5535927756961643
Validation loss: 2.457315869130383

Epoch: 6| Step: 11
Training loss: 1.1893328526015514
Validation loss: 2.478670600227287

Epoch: 6| Step: 12
Training loss: 1.6618377427726911
Validation loss: 2.47609817853371

Epoch: 6| Step: 13
Training loss: 1.8800336663295667
Validation loss: 2.4749944843236165

Epoch: 237| Step: 0
Training loss: 1.589873292540707
Validation loss: 2.479691275599114

Epoch: 6| Step: 1
Training loss: 1.247168289912162
Validation loss: 2.4800065244006007

Epoch: 6| Step: 2
Training loss: 1.7996145842443463
Validation loss: 2.5010268225330163

Epoch: 6| Step: 3
Training loss: 1.7090682178094065
Validation loss: 2.4788487382971187

Epoch: 6| Step: 4
Training loss: 1.3764098482218088
Validation loss: 2.4691146741164003

Epoch: 6| Step: 5
Training loss: 1.5137298375999049
Validation loss: 2.484748419628083

Epoch: 6| Step: 6
Training loss: 1.769332167182103
Validation loss: 2.4743081365062425

Epoch: 6| Step: 7
Training loss: 1.573692366292347
Validation loss: 2.464156119045618

Epoch: 6| Step: 8
Training loss: 1.7691575891612554
Validation loss: 2.4412022942781215

Epoch: 6| Step: 9
Training loss: 2.21194952458466
Validation loss: 2.4452224668217455

Epoch: 6| Step: 10
Training loss: 1.8652401269953849
Validation loss: 2.4472260229830574

Epoch: 6| Step: 11
Training loss: 1.3411751851940785
Validation loss: 2.4668709003015743

Epoch: 6| Step: 12
Training loss: 0.6680987939789166
Validation loss: 2.4874810529591107

Epoch: 6| Step: 13
Training loss: 0.9557281653514194
Validation loss: 2.4712534374498

Epoch: 238| Step: 0
Training loss: 1.281508256889352
Validation loss: 2.498159823430285

Epoch: 6| Step: 1
Training loss: 1.9889355015871875
Validation loss: 2.501915874387854

Epoch: 6| Step: 2
Training loss: 2.088087709579736
Validation loss: 2.4740852918361287

Epoch: 6| Step: 3
Training loss: 1.7763602082050909
Validation loss: 2.486042885061774

Epoch: 6| Step: 4
Training loss: 1.5234946998226062
Validation loss: 2.4910887072551122

Epoch: 6| Step: 5
Training loss: 0.6949675486556097
Validation loss: 2.476440658566373

Epoch: 6| Step: 6
Training loss: 1.5709666697258495
Validation loss: 2.4824685740483385

Epoch: 6| Step: 7
Training loss: 1.6432303677013944
Validation loss: 2.4891947613245518

Epoch: 6| Step: 8
Training loss: 1.1541455164783565
Validation loss: 2.4619086799104397

Epoch: 6| Step: 9
Training loss: 1.386213656569084
Validation loss: 2.4542089757982946

Epoch: 6| Step: 10
Training loss: 1.8485552997731987
Validation loss: 2.454613383461757

Epoch: 6| Step: 11
Training loss: 1.6084338649236567
Validation loss: 2.451997689049031

Epoch: 6| Step: 12
Training loss: 1.446364066621579
Validation loss: 2.4233674721237777

Epoch: 6| Step: 13
Training loss: 1.5654392825169918
Validation loss: 2.386801939737774

Epoch: 239| Step: 0
Training loss: 1.6972240447294553
Validation loss: 2.3907718333197074

Epoch: 6| Step: 1
Training loss: 1.15175010778196
Validation loss: 2.3841905922771716

Epoch: 6| Step: 2
Training loss: 1.8369338558252117
Validation loss: 2.4025307101787203

Epoch: 6| Step: 3
Training loss: 1.4890540812235369
Validation loss: 2.3855354188888853

Epoch: 6| Step: 4
Training loss: 1.5270675838780683
Validation loss: 2.394876802954544

Epoch: 6| Step: 5
Training loss: 1.9037426577330663
Validation loss: 2.3797173414490382

Epoch: 6| Step: 6
Training loss: 1.4202227372109684
Validation loss: 2.3869137799845617

Epoch: 6| Step: 7
Training loss: 1.6647258027577123
Validation loss: 2.4171879280109523

Epoch: 6| Step: 8
Training loss: 1.499786838644362
Validation loss: 2.433012084626854

Epoch: 6| Step: 9
Training loss: 1.7678332402868933
Validation loss: 2.46875155973145

Epoch: 6| Step: 10
Training loss: 1.1112248216829665
Validation loss: 2.491959509365528

Epoch: 6| Step: 11
Training loss: 1.3176804892672784
Validation loss: 2.5240735181720626

Epoch: 6| Step: 12
Training loss: 1.8091171528937222
Validation loss: 2.524000728709326

Epoch: 6| Step: 13
Training loss: 1.0112482103442753
Validation loss: 2.515150044334575

Epoch: 240| Step: 0
Training loss: 1.5060932061987586
Validation loss: 2.527726668897011

Epoch: 6| Step: 1
Training loss: 1.6679084284503753
Validation loss: 2.5184360431942046

Epoch: 6| Step: 2
Training loss: 1.749968869068633
Validation loss: 2.5052754730839606

Epoch: 6| Step: 3
Training loss: 1.3214716140261737
Validation loss: 2.4922958084577034

Epoch: 6| Step: 4
Training loss: 1.316397058471829
Validation loss: 2.4961213582750554

Epoch: 6| Step: 5
Training loss: 1.2504012417543655
Validation loss: 2.476256558970607

Epoch: 6| Step: 6
Training loss: 1.3559811198121408
Validation loss: 2.4787170762195294

Epoch: 6| Step: 7
Training loss: 1.4952555168240147
Validation loss: 2.4408794983662325

Epoch: 6| Step: 8
Training loss: 1.3388064625976426
Validation loss: 2.4224747374670894

Epoch: 6| Step: 9
Training loss: 1.5537150806729014
Validation loss: 2.423828368266967

Epoch: 6| Step: 10
Training loss: 1.437736160118845
Validation loss: 2.3994606825521716

Epoch: 6| Step: 11
Training loss: 1.973634503725772
Validation loss: 2.406591975215125

Epoch: 6| Step: 12
Training loss: 1.93266209207559
Validation loss: 2.410571904407046

Epoch: 6| Step: 13
Training loss: 0.9832756321890681
Validation loss: 2.451394164356953

Epoch: 241| Step: 0
Training loss: 1.2163087897681495
Validation loss: 2.463564051949795

Epoch: 6| Step: 1
Training loss: 2.098106861553133
Validation loss: 2.472602622171141

Epoch: 6| Step: 2
Training loss: 1.3467604161354159
Validation loss: 2.4929470268251683

Epoch: 6| Step: 3
Training loss: 1.1571496092886941
Validation loss: 2.490713830708738

Epoch: 6| Step: 4
Training loss: 1.733711115614887
Validation loss: 2.492753785829884

Epoch: 6| Step: 5
Training loss: 1.7097539422427213
Validation loss: 2.478607218708687

Epoch: 6| Step: 6
Training loss: 1.3799272598915704
Validation loss: 2.460295035441809

Epoch: 6| Step: 7
Training loss: 1.570469407170752
Validation loss: 2.4538046362592794

Epoch: 6| Step: 8
Training loss: 1.5629682220821144
Validation loss: 2.4422306340855413

Epoch: 6| Step: 9
Training loss: 1.927539633950765
Validation loss: 2.426299293361661

Epoch: 6| Step: 10
Training loss: 1.3408168006400887
Validation loss: 2.3925317051502772

Epoch: 6| Step: 11
Training loss: 1.5631964847855104
Validation loss: 2.3922914137584748

Epoch: 6| Step: 12
Training loss: 1.1841789787953512
Validation loss: 2.3940489595654437

Epoch: 6| Step: 13
Training loss: 0.9984532255029794
Validation loss: 2.4305273885506056

Epoch: 242| Step: 0
Training loss: 1.731919070522523
Validation loss: 2.431844108124045

Epoch: 6| Step: 1
Training loss: 1.3881898625594913
Validation loss: 2.4418470914153296

Epoch: 6| Step: 2
Training loss: 1.554201826596147
Validation loss: 2.440192755373471

Epoch: 6| Step: 3
Training loss: 1.7361617636179103
Validation loss: 2.4573074259426075

Epoch: 6| Step: 4
Training loss: 1.5931594352846712
Validation loss: 2.4717477200071425

Epoch: 6| Step: 5
Training loss: 1.190302102666198
Validation loss: 2.4760262907216366

Epoch: 6| Step: 6
Training loss: 1.7522317416023163
Validation loss: 2.471062531052503

Epoch: 6| Step: 7
Training loss: 1.5818987002004656
Validation loss: 2.477238924600035

Epoch: 6| Step: 8
Training loss: 1.8400531495752286
Validation loss: 2.4976646395613944

Epoch: 6| Step: 9
Training loss: 1.2977838663625363
Validation loss: 2.465619415023594

Epoch: 6| Step: 10
Training loss: 0.8766989222697781
Validation loss: 2.461442193052033

Epoch: 6| Step: 11
Training loss: 1.1959821533128268
Validation loss: 2.421603819781801

Epoch: 6| Step: 12
Training loss: 1.688396215871381
Validation loss: 2.409938250146187

Epoch: 6| Step: 13
Training loss: 1.2595897936279374
Validation loss: 2.411268288203059

Epoch: 243| Step: 0
Training loss: 1.2046949868767383
Validation loss: 2.4156883799956046

Epoch: 6| Step: 1
Training loss: 1.4723691786989324
Validation loss: 2.4436324475119413

Epoch: 6| Step: 2
Training loss: 1.4050856538368846
Validation loss: 2.444432777326912

Epoch: 6| Step: 3
Training loss: 1.516026394576537
Validation loss: 2.471654737387308

Epoch: 6| Step: 4
Training loss: 1.8625877897322958
Validation loss: 2.5086916220658

Epoch: 6| Step: 5
Training loss: 1.5532342454033616
Validation loss: 2.496849948822534

Epoch: 6| Step: 6
Training loss: 1.2317601768672504
Validation loss: 2.49492958624957

Epoch: 6| Step: 7
Training loss: 1.6474654961360684
Validation loss: 2.49253213696812

Epoch: 6| Step: 8
Training loss: 1.9228765467642663
Validation loss: 2.496981574700549

Epoch: 6| Step: 9
Training loss: 1.3521564038736418
Validation loss: 2.4965887546078744

Epoch: 6| Step: 10
Training loss: 0.9208425138772479
Validation loss: 2.4952280051452687

Epoch: 6| Step: 11
Training loss: 1.648609893606983
Validation loss: 2.492138347564709

Epoch: 6| Step: 12
Training loss: 1.299511997621053
Validation loss: 2.467036701434927

Epoch: 6| Step: 13
Training loss: 1.41525715476099
Validation loss: 2.462334348200773

Epoch: 244| Step: 0
Training loss: 1.6557845415293408
Validation loss: 2.4718512644344517

Epoch: 6| Step: 1
Training loss: 1.7632175337705425
Validation loss: 2.4451710524017685

Epoch: 6| Step: 2
Training loss: 1.052638231745828
Validation loss: 2.438485444109518

Epoch: 6| Step: 3
Training loss: 1.4712610085852547
Validation loss: 2.4377701396402887

Epoch: 6| Step: 4
Training loss: 1.0161349850141836
Validation loss: 2.4167821978180193

Epoch: 6| Step: 5
Training loss: 1.2713564853837205
Validation loss: 2.423152107079679

Epoch: 6| Step: 6
Training loss: 0.9547034154586137
Validation loss: 2.4347532407710544

Epoch: 6| Step: 7
Training loss: 2.1247686372355425
Validation loss: 2.4422171368417023

Epoch: 6| Step: 8
Training loss: 0.9895907686188429
Validation loss: 2.432579156517046

Epoch: 6| Step: 9
Training loss: 1.6470358435245835
Validation loss: 2.4440837274397818

Epoch: 6| Step: 10
Training loss: 1.8421334761058095
Validation loss: 2.457001870062482

Epoch: 6| Step: 11
Training loss: 1.3853014943524484
Validation loss: 2.4685361117130173

Epoch: 6| Step: 12
Training loss: 1.6302081058327351
Validation loss: 2.4863313100505855

Epoch: 6| Step: 13
Training loss: 0.7166034323126498
Validation loss: 2.4886443487394514

Epoch: 245| Step: 0
Training loss: 1.365992083413459
Validation loss: 2.4840935833865836

Epoch: 6| Step: 1
Training loss: 1.002051989936899
Validation loss: 2.5031364808436294

Epoch: 6| Step: 2
Training loss: 1.7837500177502381
Validation loss: 2.497029684178206

Epoch: 6| Step: 3
Training loss: 1.0170072685927187
Validation loss: 2.4826235895889943

Epoch: 6| Step: 4
Training loss: 1.2495644287344823
Validation loss: 2.470178220335064

Epoch: 6| Step: 5
Training loss: 1.4670745546135533
Validation loss: 2.4594828759864646

Epoch: 6| Step: 6
Training loss: 1.7783457855293936
Validation loss: 2.4536202769862623

Epoch: 6| Step: 7
Training loss: 1.5285432988037169
Validation loss: 2.41881026572133

Epoch: 6| Step: 8
Training loss: 1.4162007388430444
Validation loss: 2.4479008813967407

Epoch: 6| Step: 9
Training loss: 1.6989816083625506
Validation loss: 2.433465967751087

Epoch: 6| Step: 10
Training loss: 1.3298551173638093
Validation loss: 2.4369835760079765

Epoch: 6| Step: 11
Training loss: 1.5460336111592485
Validation loss: 2.4509502077132064

Epoch: 6| Step: 12
Training loss: 0.8925279732602576
Validation loss: 2.477763742687686

Epoch: 6| Step: 13
Training loss: 2.11381323811723
Validation loss: 2.4628419974982223

Epoch: 246| Step: 0
Training loss: 1.311473172290449
Validation loss: 2.448661576357884

Epoch: 6| Step: 1
Training loss: 1.204609141293795
Validation loss: 2.4718749586809836

Epoch: 6| Step: 2
Training loss: 1.2850614008353574
Validation loss: 2.4572538095104473

Epoch: 6| Step: 3
Training loss: 1.285384230407972
Validation loss: 2.4344049413060986

Epoch: 6| Step: 4
Training loss: 1.4596211423921748
Validation loss: 2.4334140678927207

Epoch: 6| Step: 5
Training loss: 1.1852847065522054
Validation loss: 2.4131275021251364

Epoch: 6| Step: 6
Training loss: 1.9269046872475484
Validation loss: 2.428989592546003

Epoch: 6| Step: 7
Training loss: 1.5050293531121737
Validation loss: 2.426026522773021

Epoch: 6| Step: 8
Training loss: 1.1266901248167658
Validation loss: 2.4173444211968773

Epoch: 6| Step: 9
Training loss: 1.078386910732364
Validation loss: 2.435749485544547

Epoch: 6| Step: 10
Training loss: 1.61530433881502
Validation loss: 2.4400926006308876

Epoch: 6| Step: 11
Training loss: 1.250817937271209
Validation loss: 2.453149943149496

Epoch: 6| Step: 12
Training loss: 1.7617734236596592
Validation loss: 2.4480587403368994

Epoch: 6| Step: 13
Training loss: 2.15770208143926
Validation loss: 2.4691520250388352

Epoch: 247| Step: 0
Training loss: 1.828861707611827
Validation loss: 2.4730838479199484

Epoch: 6| Step: 1
Training loss: 1.5215572393596322
Validation loss: 2.520385135545645

Epoch: 6| Step: 2
Training loss: 1.9621521732645388
Validation loss: 2.531732061340911

Epoch: 6| Step: 3
Training loss: 1.6180152433264399
Validation loss: 2.539307295213247

Epoch: 6| Step: 4
Training loss: 1.5013061241058028
Validation loss: 2.545229750506793

Epoch: 6| Step: 5
Training loss: 1.4665319048496335
Validation loss: 2.514117244660101

Epoch: 6| Step: 6
Training loss: 0.9248273095462769
Validation loss: 2.505122562277571

Epoch: 6| Step: 7
Training loss: 1.6072307486948385
Validation loss: 2.4772953072290402

Epoch: 6| Step: 8
Training loss: 1.198680645126743
Validation loss: 2.4564813127929983

Epoch: 6| Step: 9
Training loss: 1.1166180313014176
Validation loss: 2.462668234499904

Epoch: 6| Step: 10
Training loss: 1.5526129909069681
Validation loss: 2.4536026891313325

Epoch: 6| Step: 11
Training loss: 1.2572102496890556
Validation loss: 2.4316833774356503

Epoch: 6| Step: 12
Training loss: 0.9308203839113094
Validation loss: 2.4359619687919785

Epoch: 6| Step: 13
Training loss: 1.0583739668387284
Validation loss: 2.4211597578655324

Epoch: 248| Step: 0
Training loss: 1.7044060465129107
Validation loss: 2.432960166656562

Epoch: 6| Step: 1
Training loss: 1.258375101259424
Validation loss: 2.42377052821413

Epoch: 6| Step: 2
Training loss: 1.7747201188480792
Validation loss: 2.4089852714391577

Epoch: 6| Step: 3
Training loss: 1.2340389711789113
Validation loss: 2.4399549807001786

Epoch: 6| Step: 4
Training loss: 1.4145233920641882
Validation loss: 2.4563921429735394

Epoch: 6| Step: 5
Training loss: 1.714640611856003
Validation loss: 2.4394600998659643

Epoch: 6| Step: 6
Training loss: 1.2084734057213735
Validation loss: 2.463760910124483

Epoch: 6| Step: 7
Training loss: 1.0503246917970401
Validation loss: 2.4556487424368942

Epoch: 6| Step: 8
Training loss: 0.9679940258109744
Validation loss: 2.470972900759545

Epoch: 6| Step: 9
Training loss: 1.4892518890763347
Validation loss: 2.4579696309755876

Epoch: 6| Step: 10
Training loss: 1.5937284580345608
Validation loss: 2.4483144178223637

Epoch: 6| Step: 11
Training loss: 1.475194549661361
Validation loss: 2.427572289224137

Epoch: 6| Step: 12
Training loss: 0.9277182808534109
Validation loss: 2.4453130021786533

Epoch: 6| Step: 13
Training loss: 1.9374192744019605
Validation loss: 2.434229067287779

Epoch: 249| Step: 0
Training loss: 1.2381617732125707
Validation loss: 2.4598342717061654

Epoch: 6| Step: 1
Training loss: 1.1118287365162234
Validation loss: 2.4754453094170428

Epoch: 6| Step: 2
Training loss: 1.731729637937144
Validation loss: 2.4852729795093746

Epoch: 6| Step: 3
Training loss: 1.478207030651295
Validation loss: 2.474774584651456

Epoch: 6| Step: 4
Training loss: 0.7582033466887114
Validation loss: 2.452052332094512

Epoch: 6| Step: 5
Training loss: 1.5700561921578486
Validation loss: 2.5031555057780808

Epoch: 6| Step: 6
Training loss: 1.4910732722862468
Validation loss: 2.4878464067040893

Epoch: 6| Step: 7
Training loss: 1.6872157104643424
Validation loss: 2.5071246689002864

Epoch: 6| Step: 8
Training loss: 1.1674932322009868
Validation loss: 2.5039092355637114

Epoch: 6| Step: 9
Training loss: 1.4749944525145613
Validation loss: 2.505888662946464

Epoch: 6| Step: 10
Training loss: 1.303464030341288
Validation loss: 2.4706247931028167

Epoch: 6| Step: 11
Training loss: 1.3567544517577608
Validation loss: 2.4810726026002325

Epoch: 6| Step: 12
Training loss: 1.6680482224553712
Validation loss: 2.5053190876649616

Epoch: 6| Step: 13
Training loss: 0.9855209824966809
Validation loss: 2.480876859772577

Epoch: 250| Step: 0
Training loss: 1.4326339127826095
Validation loss: 2.459974665662649

Epoch: 6| Step: 1
Training loss: 1.1905188085102847
Validation loss: 2.462978253256405

Epoch: 6| Step: 2
Training loss: 1.0850482840276117
Validation loss: 2.473659006003759

Epoch: 6| Step: 3
Training loss: 1.4916495906484668
Validation loss: 2.4701095343356556

Epoch: 6| Step: 4
Training loss: 1.3768853353492545
Validation loss: 2.4745837054063373

Epoch: 6| Step: 5
Training loss: 1.5850695410073028
Validation loss: 2.493298129608656

Epoch: 6| Step: 6
Training loss: 1.6551991133756185
Validation loss: 2.478455561917602

Epoch: 6| Step: 7
Training loss: 1.618223660004079
Validation loss: 2.482545295104413

Epoch: 6| Step: 8
Training loss: 1.4579459992966937
Validation loss: 2.482679448244742

Epoch: 6| Step: 9
Training loss: 1.3754157391513924
Validation loss: 2.483213875033541

Epoch: 6| Step: 10
Training loss: 0.9716672963641456
Validation loss: 2.484534646155461

Epoch: 6| Step: 11
Training loss: 1.2559267206956237
Validation loss: 2.506145168498726

Epoch: 6| Step: 12
Training loss: 1.444179276229537
Validation loss: 2.492281524914091

Epoch: 6| Step: 13
Training loss: 1.5017357161661657
Validation loss: 2.4860074801613914

Epoch: 251| Step: 0
Training loss: 1.4111733189877278
Validation loss: 2.4762954120184792

Epoch: 6| Step: 1
Training loss: 1.931744980572656
Validation loss: 2.4753614397286854

Epoch: 6| Step: 2
Training loss: 1.1619297433712952
Validation loss: 2.4583574804500468

Epoch: 6| Step: 3
Training loss: 1.2152321246821267
Validation loss: 2.4693697183619556

Epoch: 6| Step: 4
Training loss: 1.1857098588351997
Validation loss: 2.475423216264945

Epoch: 6| Step: 5
Training loss: 1.1227454270189243
Validation loss: 2.501894026257443

Epoch: 6| Step: 6
Training loss: 1.5903259595802504
Validation loss: 2.5206886659497045

Epoch: 6| Step: 7
Training loss: 1.1347690391817453
Validation loss: 2.5141644934581966

Epoch: 6| Step: 8
Training loss: 1.5611075491014226
Validation loss: 2.5248869099892937

Epoch: 6| Step: 9
Training loss: 0.7159656829814913
Validation loss: 2.538034997214616

Epoch: 6| Step: 10
Training loss: 1.6462479644507915
Validation loss: 2.532385308814112

Epoch: 6| Step: 11
Training loss: 1.5590498407507132
Validation loss: 2.540478720410196

Epoch: 6| Step: 12
Training loss: 1.3126973503334223
Validation loss: 2.5227413097817912

Epoch: 6| Step: 13
Training loss: 1.3369560151522268
Validation loss: 2.513940121445475

Epoch: 252| Step: 0
Training loss: 1.4979177168133715
Validation loss: 2.4955016951545264

Epoch: 6| Step: 1
Training loss: 1.6487556620537491
Validation loss: 2.508769885109437

Epoch: 6| Step: 2
Training loss: 0.9941833726726877
Validation loss: 2.4907210068349324

Epoch: 6| Step: 3
Training loss: 1.6985366329120242
Validation loss: 2.4770290123897665

Epoch: 6| Step: 4
Training loss: 1.422384233775474
Validation loss: 2.4713555145199484

Epoch: 6| Step: 5
Training loss: 1.3053349698621124
Validation loss: 2.4530371294965048

Epoch: 6| Step: 6
Training loss: 0.965545738695496
Validation loss: 2.4451969961699658

Epoch: 6| Step: 7
Training loss: 1.1810919378382556
Validation loss: 2.440080665416283

Epoch: 6| Step: 8
Training loss: 1.7028965228054265
Validation loss: 2.4454551098759647

Epoch: 6| Step: 9
Training loss: 1.3162930493682574
Validation loss: 2.4513971202772993

Epoch: 6| Step: 10
Training loss: 1.197989862389571
Validation loss: 2.442150172015354

Epoch: 6| Step: 11
Training loss: 1.079219538941184
Validation loss: 2.4508258251901363

Epoch: 6| Step: 12
Training loss: 1.3620095866533914
Validation loss: 2.4546631243751937

Epoch: 6| Step: 13
Training loss: 1.0608560522443062
Validation loss: 2.4878714819324768

Epoch: 253| Step: 0
Training loss: 1.6303588830171292
Validation loss: 2.4712956882135124

Epoch: 6| Step: 1
Training loss: 1.0236572728530846
Validation loss: 2.4747198233195205

Epoch: 6| Step: 2
Training loss: 1.7712992410538746
Validation loss: 2.4866342588971544

Epoch: 6| Step: 3
Training loss: 1.41643666288924
Validation loss: 2.476657614966816

Epoch: 6| Step: 4
Training loss: 1.2191350768701605
Validation loss: 2.504959548107124

Epoch: 6| Step: 5
Training loss: 1.172962243847317
Validation loss: 2.489028080645355

Epoch: 6| Step: 6
Training loss: 0.735720679867771
Validation loss: 2.49476095810902

Epoch: 6| Step: 7
Training loss: 1.182266246281504
Validation loss: 2.481344147971709

Epoch: 6| Step: 8
Training loss: 0.961003898249489
Validation loss: 2.479876083691322

Epoch: 6| Step: 9
Training loss: 1.089361049718167
Validation loss: 2.4781740689692695

Epoch: 6| Step: 10
Training loss: 1.3389026239270139
Validation loss: 2.4973929332258784

Epoch: 6| Step: 11
Training loss: 1.6109231705865406
Validation loss: 2.49452342406015

Epoch: 6| Step: 12
Training loss: 1.5948942975741591
Validation loss: 2.514860817367112

Epoch: 6| Step: 13
Training loss: 1.4160376816708888
Validation loss: 2.505417839313837

Epoch: 254| Step: 0
Training loss: 1.1321615519275887
Validation loss: 2.5181493356573674

Epoch: 6| Step: 1
Training loss: 1.4223744280319748
Validation loss: 2.4935481537079607

Epoch: 6| Step: 2
Training loss: 1.1549297734168333
Validation loss: 2.482993175219633

Epoch: 6| Step: 3
Training loss: 1.4794386850887102
Validation loss: 2.4705247959856815

Epoch: 6| Step: 4
Training loss: 1.5847854564122663
Validation loss: 2.4578828739599827

Epoch: 6| Step: 5
Training loss: 1.7672403423797158
Validation loss: 2.452141765319579

Epoch: 6| Step: 6
Training loss: 1.244479865230446
Validation loss: 2.4420800754432386

Epoch: 6| Step: 7
Training loss: 1.5038796162414345
Validation loss: 2.4294241132109713

Epoch: 6| Step: 8
Training loss: 0.784418205195961
Validation loss: 2.4389544413353366

Epoch: 6| Step: 9
Training loss: 1.2031144476093394
Validation loss: 2.436886369671065

Epoch: 6| Step: 10
Training loss: 1.4651537757861595
Validation loss: 2.4366280652965826

Epoch: 6| Step: 11
Training loss: 0.9733085742886702
Validation loss: 2.46734982140051

Epoch: 6| Step: 12
Training loss: 1.0513617177924086
Validation loss: 2.4749463266647767

Epoch: 6| Step: 13
Training loss: 1.284897149122307
Validation loss: 2.479680329120724

Epoch: 255| Step: 0
Training loss: 1.4980338244012692
Validation loss: 2.477334032223242

Epoch: 6| Step: 1
Training loss: 1.1327864019084237
Validation loss: 2.492997990670862

Epoch: 6| Step: 2
Training loss: 1.3279232096244042
Validation loss: 2.4670688881012244

Epoch: 6| Step: 3
Training loss: 1.1329804920729154
Validation loss: 2.4558285431330598

Epoch: 6| Step: 4
Training loss: 1.1163317730929647
Validation loss: 2.4763359674527767

Epoch: 6| Step: 5
Training loss: 1.0682235715147013
Validation loss: 2.493583367239041

Epoch: 6| Step: 6
Training loss: 1.348299354027617
Validation loss: 2.48889387931863

Epoch: 6| Step: 7
Training loss: 1.2046381365091556
Validation loss: 2.488630642750245

Epoch: 6| Step: 8
Training loss: 1.0239144298704654
Validation loss: 2.5104173649980237

Epoch: 6| Step: 9
Training loss: 1.3105332761874802
Validation loss: 2.4868344545367345

Epoch: 6| Step: 10
Training loss: 1.1413219882952341
Validation loss: 2.5159507117175828

Epoch: 6| Step: 11
Training loss: 2.0464409520857267
Validation loss: 2.506500131782789

Epoch: 6| Step: 12
Training loss: 1.0893425558120817
Validation loss: 2.5074395910794256

Epoch: 6| Step: 13
Training loss: 1.4821945237233187
Validation loss: 2.511171787928346

Epoch: 256| Step: 0
Training loss: 1.4756104967760972
Validation loss: 2.4999587958026925

Epoch: 6| Step: 1
Training loss: 1.2528987651764365
Validation loss: 2.508426885795682

Epoch: 6| Step: 2
Training loss: 1.6311108058429078
Validation loss: 2.512609565071122

Epoch: 6| Step: 3
Training loss: 1.035920289415918
Validation loss: 2.5036693491196855

Epoch: 6| Step: 4
Training loss: 0.8867749771910977
Validation loss: 2.51323405797979

Epoch: 6| Step: 5
Training loss: 1.450816792600685
Validation loss: 2.503659277494206

Epoch: 6| Step: 6
Training loss: 1.6939119803475378
Validation loss: 2.4687740075016396

Epoch: 6| Step: 7
Training loss: 1.5082872661208586
Validation loss: 2.4962837634383908

Epoch: 6| Step: 8
Training loss: 0.8330379717645413
Validation loss: 2.4493772461939356

Epoch: 6| Step: 9
Training loss: 1.184706463894695
Validation loss: 2.467697749016075

Epoch: 6| Step: 10
Training loss: 0.9020161880512287
Validation loss: 2.458261488470718

Epoch: 6| Step: 11
Training loss: 1.2420075964058046
Validation loss: 2.459619871808159

Epoch: 6| Step: 12
Training loss: 1.1273777523715636
Validation loss: 2.467824847456988

Epoch: 6| Step: 13
Training loss: 1.516300640722888
Validation loss: 2.4357844858495903

Epoch: 257| Step: 0
Training loss: 1.020398060130687
Validation loss: 2.429518573851299

Epoch: 6| Step: 1
Training loss: 0.5376609882743484
Validation loss: 2.4221948820604324

Epoch: 6| Step: 2
Training loss: 1.2324463952190041
Validation loss: 2.4076210870649835

Epoch: 6| Step: 3
Training loss: 1.4413251983267146
Validation loss: 2.401544746488464

Epoch: 6| Step: 4
Training loss: 1.4547440727861787
Validation loss: 2.4257090335544684

Epoch: 6| Step: 5
Training loss: 1.4211747677500828
Validation loss: 2.429181174940247

Epoch: 6| Step: 6
Training loss: 1.1919383377345087
Validation loss: 2.4430139573758787

Epoch: 6| Step: 7
Training loss: 2.100523738037744
Validation loss: 2.4584959514121874

Epoch: 6| Step: 8
Training loss: 1.1224813878612736
Validation loss: 2.4866764627652613

Epoch: 6| Step: 9
Training loss: 1.020670229020018
Validation loss: 2.5083748689689616

Epoch: 6| Step: 10
Training loss: 0.811864127247095
Validation loss: 2.4983647381979592

Epoch: 6| Step: 11
Training loss: 1.4260844705128668
Validation loss: 2.5180868322853622

Epoch: 6| Step: 12
Training loss: 1.0848780891382388
Validation loss: 2.516170164681308

Epoch: 6| Step: 13
Training loss: 1.0748227172869913
Validation loss: 2.4950960730456435

Epoch: 258| Step: 0
Training loss: 1.275922258460287
Validation loss: 2.4811439453679682

Epoch: 6| Step: 1
Training loss: 1.6387307994191993
Validation loss: 2.4579811773822793

Epoch: 6| Step: 2
Training loss: 0.8698124036011119
Validation loss: 2.438176640951014

Epoch: 6| Step: 3
Training loss: 1.3650142726920533
Validation loss: 2.4320306325415157

Epoch: 6| Step: 4
Training loss: 0.8936940569141875
Validation loss: 2.4288495628925424

Epoch: 6| Step: 5
Training loss: 1.2115517811747514
Validation loss: 2.449584191551354

Epoch: 6| Step: 6
Training loss: 1.2579054709247228
Validation loss: 2.434882177858928

Epoch: 6| Step: 7
Training loss: 1.5742375299360576
Validation loss: 2.4531415263802088

Epoch: 6| Step: 8
Training loss: 1.151583973905637
Validation loss: 2.452722979846248

Epoch: 6| Step: 9
Training loss: 0.8321258419514529
Validation loss: 2.495351267529084

Epoch: 6| Step: 10
Training loss: 1.2004128143414685
Validation loss: 2.5112866481462466

Epoch: 6| Step: 11
Training loss: 0.964728777131795
Validation loss: 2.4921712767792115

Epoch: 6| Step: 12
Training loss: 1.511592731595438
Validation loss: 2.529095341235434

Epoch: 6| Step: 13
Training loss: 1.711885720783826
Validation loss: 2.516159857810116

Epoch: 259| Step: 0
Training loss: 1.9044723977602211
Validation loss: 2.5162882912888747

Epoch: 6| Step: 1
Training loss: 1.0794647848296475
Validation loss: 2.4742717806438113

Epoch: 6| Step: 2
Training loss: 1.1182108107210553
Validation loss: 2.4611140518416583

Epoch: 6| Step: 3
Training loss: 0.7117661896858457
Validation loss: 2.4409765803442025

Epoch: 6| Step: 4
Training loss: 1.4244755867512668
Validation loss: 2.4488630610092863

Epoch: 6| Step: 5
Training loss: 1.3673719881106343
Validation loss: 2.4444325434518412

Epoch: 6| Step: 6
Training loss: 1.3020071948360994
Validation loss: 2.4442254167916

Epoch: 6| Step: 7
Training loss: 0.9339669730536867
Validation loss: 2.4447070617254303

Epoch: 6| Step: 8
Training loss: 1.2214891024340382
Validation loss: 2.467159953911736

Epoch: 6| Step: 9
Training loss: 1.2176057383465986
Validation loss: 2.481917787430345

Epoch: 6| Step: 10
Training loss: 1.1953286063910522
Validation loss: 2.5198103794383044

Epoch: 6| Step: 11
Training loss: 1.2833074472136818
Validation loss: 2.4876354572897434

Epoch: 6| Step: 12
Training loss: 1.203916710295093
Validation loss: 2.5065473876238014

Epoch: 6| Step: 13
Training loss: 1.0474555270602797
Validation loss: 2.467272384694046

Epoch: 260| Step: 0
Training loss: 1.4840373408100138
Validation loss: 2.4921668591195707

Epoch: 6| Step: 1
Training loss: 1.5416793650886005
Validation loss: 2.4687440725961256

Epoch: 6| Step: 2
Training loss: 1.0780552274821484
Validation loss: 2.4542663450211752

Epoch: 6| Step: 3
Training loss: 1.2340678545134611
Validation loss: 2.4665904882530474

Epoch: 6| Step: 4
Training loss: 1.148898492789776
Validation loss: 2.4677200526195455

Epoch: 6| Step: 5
Training loss: 0.917419334108592
Validation loss: 2.480851047321498

Epoch: 6| Step: 6
Training loss: 0.8598048782227106
Validation loss: 2.471678677261294

Epoch: 6| Step: 7
Training loss: 1.2703374562269572
Validation loss: 2.473321471610268

Epoch: 6| Step: 8
Training loss: 1.369947775102905
Validation loss: 2.4829425042010094

Epoch: 6| Step: 9
Training loss: 1.004582396329751
Validation loss: 2.4706050714726744

Epoch: 6| Step: 10
Training loss: 1.1971375737624794
Validation loss: 2.4744919120013513

Epoch: 6| Step: 11
Training loss: 1.6877735763889836
Validation loss: 2.4759614685559015

Epoch: 6| Step: 12
Training loss: 1.0579034447842242
Validation loss: 2.4803560553851733

Epoch: 6| Step: 13
Training loss: 1.1344101261974218
Validation loss: 2.5058942712811216

Epoch: 261| Step: 0
Training loss: 1.3281737374731712
Validation loss: 2.476234656304281

Epoch: 6| Step: 1
Training loss: 0.8651153964868423
Validation loss: 2.4901182297112903

Epoch: 6| Step: 2
Training loss: 1.363659125918365
Validation loss: 2.4972556545977405

Epoch: 6| Step: 3
Training loss: 0.5258967857898762
Validation loss: 2.5008919837123407

Epoch: 6| Step: 4
Training loss: 1.7301871111458422
Validation loss: 2.5088105787711577

Epoch: 6| Step: 5
Training loss: 1.296057569885222
Validation loss: 2.5216661547236088

Epoch: 6| Step: 6
Training loss: 0.9978964854663919
Validation loss: 2.4842539214941195

Epoch: 6| Step: 7
Training loss: 1.217889824561778
Validation loss: 2.4850774824259005

Epoch: 6| Step: 8
Training loss: 0.9512705976885352
Validation loss: 2.45475704094376

Epoch: 6| Step: 9
Training loss: 1.161220845574062
Validation loss: 2.4508001496932534

Epoch: 6| Step: 10
Training loss: 1.26051358042161
Validation loss: 2.4617199861030783

Epoch: 6| Step: 11
Training loss: 1.5212179594654394
Validation loss: 2.4433746622015438

Epoch: 6| Step: 12
Training loss: 1.2773058591116488
Validation loss: 2.450689585234918

Epoch: 6| Step: 13
Training loss: 1.218035464022629
Validation loss: 2.4538471785791574

Epoch: 262| Step: 0
Training loss: 1.2946545078899638
Validation loss: 2.4678347661477824

Epoch: 6| Step: 1
Training loss: 0.8495299203485857
Validation loss: 2.470168976309804

Epoch: 6| Step: 2
Training loss: 1.2468333665211822
Validation loss: 2.4900133734028183

Epoch: 6| Step: 3
Training loss: 1.5324952647896772
Validation loss: 2.4802215160987653

Epoch: 6| Step: 4
Training loss: 1.466887246508649
Validation loss: 2.5019539544586857

Epoch: 6| Step: 5
Training loss: 1.3867792680456577
Validation loss: 2.4765065385701566

Epoch: 6| Step: 6
Training loss: 0.8833736560423201
Validation loss: 2.500145859206256

Epoch: 6| Step: 7
Training loss: 1.4251342141374101
Validation loss: 2.5168852531132

Epoch: 6| Step: 8
Training loss: 1.3661618118233998
Validation loss: 2.5232192379123144

Epoch: 6| Step: 9
Training loss: 1.16009803908506
Validation loss: 2.5241625883296654

Epoch: 6| Step: 10
Training loss: 1.0578339161810906
Validation loss: 2.511544886821453

Epoch: 6| Step: 11
Training loss: 1.0976602683214371
Validation loss: 2.4956035873189597

Epoch: 6| Step: 12
Training loss: 0.9170030424635407
Validation loss: 2.4911553375499245

Epoch: 6| Step: 13
Training loss: 0.8596608466811364
Validation loss: 2.488896532679953

Epoch: 263| Step: 0
Training loss: 1.2165966083439828
Validation loss: 2.4924085124763757

Epoch: 6| Step: 1
Training loss: 1.103033503987612
Validation loss: 2.4697617835125056

Epoch: 6| Step: 2
Training loss: 1.7932729691529206
Validation loss: 2.4774390153995096

Epoch: 6| Step: 3
Training loss: 1.2738396413329898
Validation loss: 2.4791908104426574

Epoch: 6| Step: 4
Training loss: 1.3640153979441938
Validation loss: 2.4627950866004413

Epoch: 6| Step: 5
Training loss: 1.3068234895892406
Validation loss: 2.4745602297921456

Epoch: 6| Step: 6
Training loss: 0.4771491957544086
Validation loss: 2.474209079092586

Epoch: 6| Step: 7
Training loss: 1.5918672698199814
Validation loss: 2.486841914010276

Epoch: 6| Step: 8
Training loss: 1.1514262021691828
Validation loss: 2.481420846970631

Epoch: 6| Step: 9
Training loss: 0.7917364156682081
Validation loss: 2.477637670415903

Epoch: 6| Step: 10
Training loss: 0.45885131205761615
Validation loss: 2.495696887742576

Epoch: 6| Step: 11
Training loss: 1.347633074132695
Validation loss: 2.482454223633751

Epoch: 6| Step: 12
Training loss: 1.1939778574834488
Validation loss: 2.506527694729961

Epoch: 6| Step: 13
Training loss: 0.6755806288851107
Validation loss: 2.5015982523274167

Epoch: 264| Step: 0
Training loss: 1.0833204831070364
Validation loss: 2.5093702016672266

Epoch: 6| Step: 1
Training loss: 1.3677791514175863
Validation loss: 2.457477934529256

Epoch: 6| Step: 2
Training loss: 1.0953772293097737
Validation loss: 2.4669955374498707

Epoch: 6| Step: 3
Training loss: 1.5597040719780069
Validation loss: 2.450634971432012

Epoch: 6| Step: 4
Training loss: 1.2014734401362792
Validation loss: 2.454973237168489

Epoch: 6| Step: 5
Training loss: 1.1567909934004563
Validation loss: 2.429528556071995

Epoch: 6| Step: 6
Training loss: 1.1568090788341208
Validation loss: 2.436692919607039

Epoch: 6| Step: 7
Training loss: 1.6704171500328597
Validation loss: 2.4489427746551025

Epoch: 6| Step: 8
Training loss: 1.0988113461707483
Validation loss: 2.4355220257738712

Epoch: 6| Step: 9
Training loss: 0.7989930819664288
Validation loss: 2.4477955823356883

Epoch: 6| Step: 10
Training loss: 1.1062791098520113
Validation loss: 2.473329120060022

Epoch: 6| Step: 11
Training loss: 0.8653053616235847
Validation loss: 2.4911021764012857

Epoch: 6| Step: 12
Training loss: 1.0568232634078207
Validation loss: 2.5166209929467738

Epoch: 6| Step: 13
Training loss: 0.9150330045615571
Validation loss: 2.5288079930887792

Epoch: 265| Step: 0
Training loss: 1.7076050516321446
Validation loss: 2.530168092208452

Epoch: 6| Step: 1
Training loss: 1.0083182197152731
Validation loss: 2.5054821695086003

Epoch: 6| Step: 2
Training loss: 1.60650638359884
Validation loss: 2.512775235504584

Epoch: 6| Step: 3
Training loss: 1.2098969942181201
Validation loss: 2.490659354467256

Epoch: 6| Step: 4
Training loss: 0.940050850974027
Validation loss: 2.4678110445372146

Epoch: 6| Step: 5
Training loss: 1.2223577653017272
Validation loss: 2.4361883996248044

Epoch: 6| Step: 6
Training loss: 0.9047647670500996
Validation loss: 2.445458015317071

Epoch: 6| Step: 7
Training loss: 0.9651191719866358
Validation loss: 2.428085667497787

Epoch: 6| Step: 8
Training loss: 1.18548769858167
Validation loss: 2.443239337240857

Epoch: 6| Step: 9
Training loss: 1.2789611841892785
Validation loss: 2.4673639396455154

Epoch: 6| Step: 10
Training loss: 0.99046666056191
Validation loss: 2.462223425516977

Epoch: 6| Step: 11
Training loss: 1.0076441661212496
Validation loss: 2.486337186246834

Epoch: 6| Step: 12
Training loss: 0.9569815486536305
Validation loss: 2.5243388556477973

Epoch: 6| Step: 13
Training loss: 1.3903756507461151
Validation loss: 2.500721722684255

Epoch: 266| Step: 0
Training loss: 1.0771404691455038
Validation loss: 2.5485683760323163

Epoch: 6| Step: 1
Training loss: 1.0926591610579932
Validation loss: 2.510060511083003

Epoch: 6| Step: 2
Training loss: 0.6054838855451323
Validation loss: 2.488393985430635

Epoch: 6| Step: 3
Training loss: 1.5535952310978056
Validation loss: 2.4854880912110735

Epoch: 6| Step: 4
Training loss: 1.4057440801363885
Validation loss: 2.481267046754258

Epoch: 6| Step: 5
Training loss: 1.0160335012679713
Validation loss: 2.483877268230394

Epoch: 6| Step: 6
Training loss: 1.0681524268078253
Validation loss: 2.4544582439494516

Epoch: 6| Step: 7
Training loss: 1.1943131801030953
Validation loss: 2.487467708492448

Epoch: 6| Step: 8
Training loss: 1.3426606841864803
Validation loss: 2.4563135133403597

Epoch: 6| Step: 9
Training loss: 1.231965090681261
Validation loss: 2.466032374849855

Epoch: 6| Step: 10
Training loss: 1.0576492544228282
Validation loss: 2.481253276250496

Epoch: 6| Step: 11
Training loss: 0.9411179350345725
Validation loss: 2.497846059021846

Epoch: 6| Step: 12
Training loss: 1.2663160721466922
Validation loss: 2.4912744120395462

Epoch: 6| Step: 13
Training loss: 1.198636637509555
Validation loss: 2.4780668916551605

Epoch: 267| Step: 0
Training loss: 0.9534209683015623
Validation loss: 2.5060275223163324

Epoch: 6| Step: 1
Training loss: 1.0789058456033422
Validation loss: 2.514909034365358

Epoch: 6| Step: 2
Training loss: 1.264786336442807
Validation loss: 2.496388564839184

Epoch: 6| Step: 3
Training loss: 1.3377895344877309
Validation loss: 2.499026752041703

Epoch: 6| Step: 4
Training loss: 0.7639627902571309
Validation loss: 2.477351512653523

Epoch: 6| Step: 5
Training loss: 0.8210215093046251
Validation loss: 2.4727477714919206

Epoch: 6| Step: 6
Training loss: 1.7523505909310433
Validation loss: 2.4620235694531516

Epoch: 6| Step: 7
Training loss: 1.067622179726852
Validation loss: 2.4800866883502506

Epoch: 6| Step: 8
Training loss: 0.9343695190677197
Validation loss: 2.490474009395607

Epoch: 6| Step: 9
Training loss: 1.0669131349386312
Validation loss: 2.4722922081984846

Epoch: 6| Step: 10
Training loss: 1.261249939358032
Validation loss: 2.457136023897439

Epoch: 6| Step: 11
Training loss: 1.3435681242173179
Validation loss: 2.4709057692839442

Epoch: 6| Step: 12
Training loss: 1.0480224242541292
Validation loss: 2.461467320629048

Epoch: 6| Step: 13
Training loss: 0.980728965971297
Validation loss: 2.47003843643515

Epoch: 268| Step: 0
Training loss: 1.483273147404962
Validation loss: 2.451207785152751

Epoch: 6| Step: 1
Training loss: 0.788158919158865
Validation loss: 2.4729999805584773

Epoch: 6| Step: 2
Training loss: 1.1305803603706366
Validation loss: 2.4876326263585424

Epoch: 6| Step: 3
Training loss: 1.4579193435881312
Validation loss: 2.481407381063488

Epoch: 6| Step: 4
Training loss: 1.154169633955647
Validation loss: 2.4749425116746755

Epoch: 6| Step: 5
Training loss: 0.9501134478440503
Validation loss: 2.4662734185346387

Epoch: 6| Step: 6
Training loss: 1.3147601694343738
Validation loss: 2.459261184324744

Epoch: 6| Step: 7
Training loss: 1.2740899035472995
Validation loss: 2.4747086000103744

Epoch: 6| Step: 8
Training loss: 1.23960853465559
Validation loss: 2.503756358044327

Epoch: 6| Step: 9
Training loss: 1.0672458794684716
Validation loss: 2.491271370172176

Epoch: 6| Step: 10
Training loss: 1.022013889871558
Validation loss: 2.4804237972078402

Epoch: 6| Step: 11
Training loss: 1.1206676989461157
Validation loss: 2.5032279105336723

Epoch: 6| Step: 12
Training loss: 0.8874815630005124
Validation loss: 2.487968469596825

Epoch: 6| Step: 13
Training loss: 0.6008663608302156
Validation loss: 2.4870597298438284

Epoch: 269| Step: 0
Training loss: 1.035044077427632
Validation loss: 2.479729167120519

Epoch: 6| Step: 1
Training loss: 0.9111352329692193
Validation loss: 2.4704365035313964

Epoch: 6| Step: 2
Training loss: 1.252152544585201
Validation loss: 2.486607563896453

Epoch: 6| Step: 3
Training loss: 0.81216394370463
Validation loss: 2.463594349492931

Epoch: 6| Step: 4
Training loss: 1.3231113721085348
Validation loss: 2.4807561830423355

Epoch: 6| Step: 5
Training loss: 0.9477052278119086
Validation loss: 2.460521404862161

Epoch: 6| Step: 6
Training loss: 0.8114550546784737
Validation loss: 2.4666548135694932

Epoch: 6| Step: 7
Training loss: 0.9129373194872644
Validation loss: 2.470077443336344

Epoch: 6| Step: 8
Training loss: 1.1262154900516812
Validation loss: 2.4807786100256752

Epoch: 6| Step: 9
Training loss: 1.327507638496219
Validation loss: 2.4753399283936806

Epoch: 6| Step: 10
Training loss: 1.0979257164617755
Validation loss: 2.47169856768601

Epoch: 6| Step: 11
Training loss: 1.752281336835741
Validation loss: 2.473000347014969

Epoch: 6| Step: 12
Training loss: 1.0178368764786188
Validation loss: 2.4782007130916823

Epoch: 6| Step: 13
Training loss: 1.1800892126982425
Validation loss: 2.4602027130759536

Epoch: 270| Step: 0
Training loss: 1.2497167266305067
Validation loss: 2.4508889555068505

Epoch: 6| Step: 1
Training loss: 1.701798928949591
Validation loss: 2.47022695664714

Epoch: 6| Step: 2
Training loss: 0.7646320677426404
Validation loss: 2.457125124047833

Epoch: 6| Step: 3
Training loss: 1.100649516207901
Validation loss: 2.460292086564848

Epoch: 6| Step: 4
Training loss: 0.7049764839944331
Validation loss: 2.481650522727286

Epoch: 6| Step: 5
Training loss: 1.592269958217679
Validation loss: 2.480240418603709

Epoch: 6| Step: 6
Training loss: 1.4020403265438726
Validation loss: 2.4845326350997374

Epoch: 6| Step: 7
Training loss: 1.457535480047791
Validation loss: 2.4866327701787503

Epoch: 6| Step: 8
Training loss: 0.7056760920500437
Validation loss: 2.4884765278439085

Epoch: 6| Step: 9
Training loss: 1.164912176137237
Validation loss: 2.5031222023182145

Epoch: 6| Step: 10
Training loss: 0.8071420141172286
Validation loss: 2.4869747622905725

Epoch: 6| Step: 11
Training loss: 0.6621948907141793
Validation loss: 2.486365237958431

Epoch: 6| Step: 12
Training loss: 0.8898284428513253
Validation loss: 2.472234342662963

Epoch: 6| Step: 13
Training loss: 0.3574682111878615
Validation loss: 2.4815597138789647

Epoch: 271| Step: 0
Training loss: 1.102645882364112
Validation loss: 2.4626659547061776

Epoch: 6| Step: 1
Training loss: 1.0260770698029238
Validation loss: 2.475081556651782

Epoch: 6| Step: 2
Training loss: 1.2331012962912995
Validation loss: 2.4691792638400165

Epoch: 6| Step: 3
Training loss: 1.1368958640005975
Validation loss: 2.470975965540117

Epoch: 6| Step: 4
Training loss: 1.63821830428484
Validation loss: 2.446026974689139

Epoch: 6| Step: 5
Training loss: 0.8061280919845465
Validation loss: 2.4542321572163623

Epoch: 6| Step: 6
Training loss: 0.9342624073383698
Validation loss: 2.465770974442858

Epoch: 6| Step: 7
Training loss: 1.3230431663927484
Validation loss: 2.4402688515287565

Epoch: 6| Step: 8
Training loss: 1.0370018969806327
Validation loss: 2.4508068678907438

Epoch: 6| Step: 9
Training loss: 0.9972235163081375
Validation loss: 2.4584362626535925

Epoch: 6| Step: 10
Training loss: 1.324305123632092
Validation loss: 2.4635542118020446

Epoch: 6| Step: 11
Training loss: 1.2280230724950572
Validation loss: 2.4800004590214675

Epoch: 6| Step: 12
Training loss: 0.9597957620325659
Validation loss: 2.482334214321204

Epoch: 6| Step: 13
Training loss: 0.843754132578584
Validation loss: 2.46458826079567

Epoch: 272| Step: 0
Training loss: 1.0836186522336295
Validation loss: 2.4294427239898146

Epoch: 6| Step: 1
Training loss: 1.52327911336109
Validation loss: 2.45495196854763

Epoch: 6| Step: 2
Training loss: 1.3241573083177565
Validation loss: 2.433293835570417

Epoch: 6| Step: 3
Training loss: 0.9591598816296645
Validation loss: 2.4332051951689357

Epoch: 6| Step: 4
Training loss: 0.8057740662354218
Validation loss: 2.438717864162747

Epoch: 6| Step: 5
Training loss: 1.1024715379254604
Validation loss: 2.40213866973776

Epoch: 6| Step: 6
Training loss: 0.8304353910046013
Validation loss: 2.4177103432161524

Epoch: 6| Step: 7
Training loss: 1.3109458622989678
Validation loss: 2.4435889572952716

Epoch: 6| Step: 8
Training loss: 0.8978299284165195
Validation loss: 2.4445640353935256

Epoch: 6| Step: 9
Training loss: 1.046720464886953
Validation loss: 2.457143893836326

Epoch: 6| Step: 10
Training loss: 1.1334803224125185
Validation loss: 2.46444419907972

Epoch: 6| Step: 11
Training loss: 0.6144693371282478
Validation loss: 2.47708441297898

Epoch: 6| Step: 12
Training loss: 1.1714916365125896
Validation loss: 2.4675333315058454

Epoch: 6| Step: 13
Training loss: 1.3886644923876368
Validation loss: 2.4581469732330214

Epoch: 273| Step: 0
Training loss: 1.2349243390308566
Validation loss: 2.4377163984750814

Epoch: 6| Step: 1
Training loss: 1.0810816484929864
Validation loss: 2.462538909604707

Epoch: 6| Step: 2
Training loss: 1.0175214228143947
Validation loss: 2.440774307073626

Epoch: 6| Step: 3
Training loss: 0.9767257859094554
Validation loss: 2.429781114768781

Epoch: 6| Step: 4
Training loss: 1.3159305154347365
Validation loss: 2.450024523098541

Epoch: 6| Step: 5
Training loss: 1.0834730987377936
Validation loss: 2.461364506951654

Epoch: 6| Step: 6
Training loss: 1.2019825254556966
Validation loss: 2.4363465368411146

Epoch: 6| Step: 7
Training loss: 0.6445555711261166
Validation loss: 2.430806992314867

Epoch: 6| Step: 8
Training loss: 0.9448923485610743
Validation loss: 2.4408971705459566

Epoch: 6| Step: 9
Training loss: 1.4907148993871642
Validation loss: 2.442505089156286

Epoch: 6| Step: 10
Training loss: 1.045738286313217
Validation loss: 2.4667051093293946

Epoch: 6| Step: 11
Training loss: 0.8575467516218539
Validation loss: 2.461696859575556

Epoch: 6| Step: 12
Training loss: 0.8936116518300884
Validation loss: 2.462961961502353

Epoch: 6| Step: 13
Training loss: 1.459667776011687
Validation loss: 2.458167025817266

Epoch: 274| Step: 0
Training loss: 0.8329699956039879
Validation loss: 2.4819539664782138

Epoch: 6| Step: 1
Training loss: 1.3133065606468883
Validation loss: 2.484074637444057

Epoch: 6| Step: 2
Training loss: 1.1260518349121666
Validation loss: 2.467642818689342

Epoch: 6| Step: 3
Training loss: 1.3915469510254637
Validation loss: 2.4525822104999224

Epoch: 6| Step: 4
Training loss: 1.0603684754778555
Validation loss: 2.457038391990826

Epoch: 6| Step: 5
Training loss: 1.1322427303310776
Validation loss: 2.465004330373572

Epoch: 6| Step: 6
Training loss: 1.183042089234319
Validation loss: 2.5028606394052

Epoch: 6| Step: 7
Training loss: 1.0249350271334132
Validation loss: 2.4752383201380868

Epoch: 6| Step: 8
Training loss: 1.039744390015305
Validation loss: 2.465585753758612

Epoch: 6| Step: 9
Training loss: 0.9243153744876703
Validation loss: 2.4631249460095326

Epoch: 6| Step: 10
Training loss: 1.0497773774609065
Validation loss: 2.446521204367125

Epoch: 6| Step: 11
Training loss: 0.7585493614968043
Validation loss: 2.4549928086898976

Epoch: 6| Step: 12
Training loss: 0.45786063426208157
Validation loss: 2.4303278627016494

Epoch: 6| Step: 13
Training loss: 1.7708419425605484
Validation loss: 2.428396589440474

Epoch: 275| Step: 0
Training loss: 1.0797103614429375
Validation loss: 2.466961241831219

Epoch: 6| Step: 1
Training loss: 1.085600437024787
Validation loss: 2.4562500778198646

Epoch: 6| Step: 2
Training loss: 1.0400868579466642
Validation loss: 2.486397613649111

Epoch: 6| Step: 3
Training loss: 1.3815996271273183
Validation loss: 2.4862811411632393

Epoch: 6| Step: 4
Training loss: 1.2333972293609234
Validation loss: 2.478357169634457

Epoch: 6| Step: 5
Training loss: 1.561692830453173
Validation loss: 2.475481427717939

Epoch: 6| Step: 6
Training loss: 1.0651314630096334
Validation loss: 2.485294274123719

Epoch: 6| Step: 7
Training loss: 0.6686701521933177
Validation loss: 2.4597279055447427

Epoch: 6| Step: 8
Training loss: 0.5925980486000522
Validation loss: 2.4898774377533597

Epoch: 6| Step: 9
Training loss: 1.18453322790454
Validation loss: 2.477538830715348

Epoch: 6| Step: 10
Training loss: 0.9860763379504384
Validation loss: 2.4423147471694535

Epoch: 6| Step: 11
Training loss: 0.6065094893893247
Validation loss: 2.4620468022445383

Epoch: 6| Step: 12
Training loss: 0.9957321707498665
Validation loss: 2.4434955546809736

Epoch: 6| Step: 13
Training loss: 0.6677219760431392
Validation loss: 2.461182826390267

Epoch: 276| Step: 0
Training loss: 1.2053482519558578
Validation loss: 2.445410222128182

Epoch: 6| Step: 1
Training loss: 0.8900684156803199
Validation loss: 2.4657348157936285

Epoch: 6| Step: 2
Training loss: 0.8596264557986284
Validation loss: 2.492097239699063

Epoch: 6| Step: 3
Training loss: 0.6136671176582736
Validation loss: 2.506891112463387

Epoch: 6| Step: 4
Training loss: 0.9827401042043105
Validation loss: 2.4808028514424474

Epoch: 6| Step: 5
Training loss: 1.1446880975211935
Validation loss: 2.485378640264263

Epoch: 6| Step: 6
Training loss: 1.375311989501359
Validation loss: 2.47352454708267

Epoch: 6| Step: 7
Training loss: 1.1701529502338222
Validation loss: 2.471398296204466

Epoch: 6| Step: 8
Training loss: 1.19888977111047
Validation loss: 2.459272948270583

Epoch: 6| Step: 9
Training loss: 0.6169961318771192
Validation loss: 2.4293860011115753

Epoch: 6| Step: 10
Training loss: 1.192327224722907
Validation loss: 2.4572298762063856

Epoch: 6| Step: 11
Training loss: 1.0463541927435749
Validation loss: 2.4366913919597346

Epoch: 6| Step: 12
Training loss: 1.1675023196930479
Validation loss: 2.4471568142904743

Epoch: 6| Step: 13
Training loss: 1.0316987650679104
Validation loss: 2.423744586737421

Epoch: 277| Step: 0
Training loss: 0.8429611545110954
Validation loss: 2.3917171432069573

Epoch: 6| Step: 1
Training loss: 0.878626766273068
Validation loss: 2.392448963247515

Epoch: 6| Step: 2
Training loss: 1.0792464905505705
Validation loss: 2.408264662367531

Epoch: 6| Step: 3
Training loss: 1.035802675337208
Validation loss: 2.419690338512526

Epoch: 6| Step: 4
Training loss: 1.1721169285593451
Validation loss: 2.413217849383837

Epoch: 6| Step: 5
Training loss: 0.8160380212934338
Validation loss: 2.4142753947116353

Epoch: 6| Step: 6
Training loss: 1.2130006995140128
Validation loss: 2.4085103948326423

Epoch: 6| Step: 7
Training loss: 0.9110524100167356
Validation loss: 2.4571954959305793

Epoch: 6| Step: 8
Training loss: 1.2376336170078022
Validation loss: 2.4513424474621877

Epoch: 6| Step: 9
Training loss: 1.059757620432876
Validation loss: 2.478753626737117

Epoch: 6| Step: 10
Training loss: 1.4573111993854464
Validation loss: 2.4736396992813456

Epoch: 6| Step: 11
Training loss: 0.8969791351898392
Validation loss: 2.4990529717479197

Epoch: 6| Step: 12
Training loss: 1.3779948304997052
Validation loss: 2.490588665120493

Epoch: 6| Step: 13
Training loss: 0.6065909783558104
Validation loss: 2.491751453027008

Epoch: 278| Step: 0
Training loss: 0.8976617200400916
Validation loss: 2.5109989548068072

Epoch: 6| Step: 1
Training loss: 0.5034575719638456
Validation loss: 2.487163437700485

Epoch: 6| Step: 2
Training loss: 0.8111263547695848
Validation loss: 2.482381820210336

Epoch: 6| Step: 3
Training loss: 1.2132412561824317
Validation loss: 2.4812848269983014

Epoch: 6| Step: 4
Training loss: 1.1663864287361336
Validation loss: 2.448390046906028

Epoch: 6| Step: 5
Training loss: 0.9445754401358576
Validation loss: 2.450837445524805

Epoch: 6| Step: 6
Training loss: 1.2962669877619353
Validation loss: 2.465556281318639

Epoch: 6| Step: 7
Training loss: 1.0292563385192632
Validation loss: 2.433576838044268

Epoch: 6| Step: 8
Training loss: 1.0953906152490014
Validation loss: 2.465345354630571

Epoch: 6| Step: 9
Training loss: 1.3786028130994459
Validation loss: 2.4549341636243964

Epoch: 6| Step: 10
Training loss: 1.0419052931529849
Validation loss: 2.4703287611686493

Epoch: 6| Step: 11
Training loss: 0.6035453764362857
Validation loss: 2.4660725215855637

Epoch: 6| Step: 12
Training loss: 0.8735324951267809
Validation loss: 2.502050832214387

Epoch: 6| Step: 13
Training loss: 1.3442928193679016
Validation loss: 2.48744819769798

Epoch: 279| Step: 0
Training loss: 1.4017353066153437
Validation loss: 2.487107429274351

Epoch: 6| Step: 1
Training loss: 1.10549959065582
Validation loss: 2.4903076655239142

Epoch: 6| Step: 2
Training loss: 0.5990620454200448
Validation loss: 2.502682624770125

Epoch: 6| Step: 3
Training loss: 1.2117544064419044
Validation loss: 2.490072606892869

Epoch: 6| Step: 4
Training loss: 0.7207257026919555
Validation loss: 2.461419865371317

Epoch: 6| Step: 5
Training loss: 1.0575255462590967
Validation loss: 2.473200214764413

Epoch: 6| Step: 6
Training loss: 0.598748275300411
Validation loss: 2.4656195689073606

Epoch: 6| Step: 7
Training loss: 0.9405552987162622
Validation loss: 2.44575869277298

Epoch: 6| Step: 8
Training loss: 0.39997201762074325
Validation loss: 2.4705571592716438

Epoch: 6| Step: 9
Training loss: 1.1004677059976202
Validation loss: 2.439356251434379

Epoch: 6| Step: 10
Training loss: 1.145518271161894
Validation loss: 2.458657850395084

Epoch: 6| Step: 11
Training loss: 1.1916886792228356
Validation loss: 2.43367488656499

Epoch: 6| Step: 12
Training loss: 1.125459683069421
Validation loss: 2.4342671114603185

Epoch: 6| Step: 13
Training loss: 1.159071701149045
Validation loss: 2.445679005327112

Epoch: 280| Step: 0
Training loss: 0.4474963796458499
Validation loss: 2.4843724264259395

Epoch: 6| Step: 1
Training loss: 0.8460263169909612
Validation loss: 2.469654689564949

Epoch: 6| Step: 2
Training loss: 0.9806257631336596
Validation loss: 2.429628800196561

Epoch: 6| Step: 3
Training loss: 1.051289602071235
Validation loss: 2.4157569636635325

Epoch: 6| Step: 4
Training loss: 1.1575084745290496
Validation loss: 2.4017258062861724

Epoch: 6| Step: 5
Training loss: 0.5349054514593783
Validation loss: 2.405409633286514

Epoch: 6| Step: 6
Training loss: 1.3470885919495224
Validation loss: 2.413137288682053

Epoch: 6| Step: 7
Training loss: 1.285312492357621
Validation loss: 2.411874020394276

Epoch: 6| Step: 8
Training loss: 0.8039499995687795
Validation loss: 2.4434235166025418

Epoch: 6| Step: 9
Training loss: 1.0562092293539596
Validation loss: 2.414690903821632

Epoch: 6| Step: 10
Training loss: 1.2017969505450392
Validation loss: 2.442298472929254

Epoch: 6| Step: 11
Training loss: 0.9366677722947009
Validation loss: 2.430278943363297

Epoch: 6| Step: 12
Training loss: 0.48233778989104337
Validation loss: 2.4192564930633162

Epoch: 6| Step: 13
Training loss: 1.5177484954288663
Validation loss: 2.4119203810068868

Epoch: 281| Step: 0
Training loss: 0.8464979000797802
Validation loss: 2.4012871639142683

Epoch: 6| Step: 1
Training loss: 1.0733217690616879
Validation loss: 2.4319387130067107

Epoch: 6| Step: 2
Training loss: 0.97212848362808
Validation loss: 2.4198726435941977

Epoch: 6| Step: 3
Training loss: 0.7425097920192749
Validation loss: 2.414946173501145

Epoch: 6| Step: 4
Training loss: 0.8334514693128984
Validation loss: 2.428415835698445

Epoch: 6| Step: 5
Training loss: 1.1377992508852084
Validation loss: 2.4282104626227863

Epoch: 6| Step: 6
Training loss: 1.0152401121475725
Validation loss: 2.4391057436679047

Epoch: 6| Step: 7
Training loss: 0.9236451304455893
Validation loss: 2.4261978803810433

Epoch: 6| Step: 8
Training loss: 0.882080078125
Validation loss: 2.4362753896358833

Epoch: 6| Step: 9
Training loss: 0.9913212757052855
Validation loss: 2.437084230902527

Epoch: 6| Step: 10
Training loss: 1.258245073890555
Validation loss: 2.4222818986162635

Epoch: 6| Step: 11
Training loss: 1.2045474870314552
Validation loss: 2.415092999387299

Epoch: 6| Step: 12
Training loss: 0.710141753163107
Validation loss: 2.396142102034073

Epoch: 6| Step: 13
Training loss: 1.1061507099658523
Validation loss: 2.4147510761814615

Epoch: 282| Step: 0
Training loss: 0.8158470684592897
Validation loss: 2.4087701222204174

Epoch: 6| Step: 1
Training loss: 0.7495634079794632
Validation loss: 2.4274007529909833

Epoch: 6| Step: 2
Training loss: 0.86469356952463
Validation loss: 2.4307757835602852

Epoch: 6| Step: 3
Training loss: 0.7222131556365683
Validation loss: 2.4556761268430574

Epoch: 6| Step: 4
Training loss: 1.341050519303125
Validation loss: 2.4594100699264683

Epoch: 6| Step: 5
Training loss: 0.6216475219267259
Validation loss: 2.4687592856836256

Epoch: 6| Step: 6
Training loss: 1.2035152248343521
Validation loss: 2.4750874864867067

Epoch: 6| Step: 7
Training loss: 1.0490237715966875
Validation loss: 2.486699991524422

Epoch: 6| Step: 8
Training loss: 0.9374841052933176
Validation loss: 2.4812968378121885

Epoch: 6| Step: 9
Training loss: 1.2056192577298481
Validation loss: 2.472981515123918

Epoch: 6| Step: 10
Training loss: 1.22869891086672
Validation loss: 2.4713341498524115

Epoch: 6| Step: 11
Training loss: 0.9858519056015917
Validation loss: 2.464357769346927

Epoch: 6| Step: 12
Training loss: 1.10686143691263
Validation loss: 2.437691977833936

Epoch: 6| Step: 13
Training loss: 0.3737583266641607
Validation loss: 2.4110809284571886

Epoch: 283| Step: 0
Training loss: 1.3020765482407852
Validation loss: 2.3889101813597104

Epoch: 6| Step: 1
Training loss: 0.7698365975681211
Validation loss: 2.3938833057725626

Epoch: 6| Step: 2
Training loss: 0.7539881133070947
Validation loss: 2.3908122010366277

Epoch: 6| Step: 3
Training loss: 0.7591446248430335
Validation loss: 2.3959309751098314

Epoch: 6| Step: 4
Training loss: 1.1657608750744335
Validation loss: 2.4104395334420854

Epoch: 6| Step: 5
Training loss: 1.382754610218452
Validation loss: 2.393133224440049

Epoch: 6| Step: 6
Training loss: 0.9674803504624183
Validation loss: 2.4190551653912045

Epoch: 6| Step: 7
Training loss: 1.037418872464932
Validation loss: 2.430968515460255

Epoch: 6| Step: 8
Training loss: 1.3686170678929268
Validation loss: 2.441318531060232

Epoch: 6| Step: 9
Training loss: 0.6577580699012385
Validation loss: 2.4288267456038146

Epoch: 6| Step: 10
Training loss: 0.6675934657549055
Validation loss: 2.438958058246229

Epoch: 6| Step: 11
Training loss: 0.8572524127030705
Validation loss: 2.4327238559284488

Epoch: 6| Step: 12
Training loss: 0.5129032839442553
Validation loss: 2.452705116932922

Epoch: 6| Step: 13
Training loss: 0.7684329177577103
Validation loss: 2.419936585642534

Epoch: 284| Step: 0
Training loss: 0.9750796847915124
Validation loss: 2.4220721278047987

Epoch: 6| Step: 1
Training loss: 0.6056095574834209
Validation loss: 2.4263140329604957

Epoch: 6| Step: 2
Training loss: 1.4397666310248838
Validation loss: 2.4233449327515943

Epoch: 6| Step: 3
Training loss: 0.7158417119552424
Validation loss: 2.433680394803493

Epoch: 6| Step: 4
Training loss: 0.7197328564641691
Validation loss: 2.4206903456043345

Epoch: 6| Step: 5
Training loss: 0.9602492123724486
Validation loss: 2.420561913953895

Epoch: 6| Step: 6
Training loss: 1.020775280813401
Validation loss: 2.434354683781271

Epoch: 6| Step: 7
Training loss: 1.0364024021003062
Validation loss: 2.430675583047299

Epoch: 6| Step: 8
Training loss: 1.1801795691104655
Validation loss: 2.4327694762013277

Epoch: 6| Step: 9
Training loss: 0.9263781140539815
Validation loss: 2.4312572074336427

Epoch: 6| Step: 10
Training loss: 1.0788459026190442
Validation loss: 2.474672807632103

Epoch: 6| Step: 11
Training loss: 0.8525468928620927
Validation loss: 2.4387116976704273

Epoch: 6| Step: 12
Training loss: 0.5675382942773709
Validation loss: 2.4569099467145965

Epoch: 6| Step: 13
Training loss: 1.0874212543434527
Validation loss: 2.44170527560135

Epoch: 285| Step: 0
Training loss: 0.5103327494035931
Validation loss: 2.4455365439994345

Epoch: 6| Step: 1
Training loss: 1.3058508979688819
Validation loss: 2.421911681152491

Epoch: 6| Step: 2
Training loss: 0.9625570404193151
Validation loss: 2.4238062245268326

Epoch: 6| Step: 3
Training loss: 1.0334380663330076
Validation loss: 2.400020543902669

Epoch: 6| Step: 4
Training loss: 0.6810024301594801
Validation loss: 2.394752373124765

Epoch: 6| Step: 5
Training loss: 1.10911127098767
Validation loss: 2.4191610011859734

Epoch: 6| Step: 6
Training loss: 1.0086151593548855
Validation loss: 2.4208701429159025

Epoch: 6| Step: 7
Training loss: 0.7428732665245683
Validation loss: 2.4335703108870272

Epoch: 6| Step: 8
Training loss: 1.1163492859602029
Validation loss: 2.4177825955209067

Epoch: 6| Step: 9
Training loss: 1.239373240044018
Validation loss: 2.436348720254621

Epoch: 6| Step: 10
Training loss: 0.8831483995235765
Validation loss: 2.4566006463692487

Epoch: 6| Step: 11
Training loss: 0.7383064790481979
Validation loss: 2.435591685595214

Epoch: 6| Step: 12
Training loss: 0.7401881140593881
Validation loss: 2.434272573073532

Epoch: 6| Step: 13
Training loss: 0.9376506684348043
Validation loss: 2.4734472104077603

Epoch: 286| Step: 0
Training loss: 0.8451225984107894
Validation loss: 2.478376718896314

Epoch: 6| Step: 1
Training loss: 1.1178256259794885
Validation loss: 2.465196001783191

Epoch: 6| Step: 2
Training loss: 0.37940423233806575
Validation loss: 2.4721508384712663

Epoch: 6| Step: 3
Training loss: 1.0608067764849722
Validation loss: 2.466912801607618

Epoch: 6| Step: 4
Training loss: 0.9822422113573391
Validation loss: 2.4650520218643877

Epoch: 6| Step: 5
Training loss: 0.5900649104538324
Validation loss: 2.458220637974468

Epoch: 6| Step: 6
Training loss: 0.906117462463645
Validation loss: 2.442464264825449

Epoch: 6| Step: 7
Training loss: 0.9690519293067401
Validation loss: 2.467345260072118

Epoch: 6| Step: 8
Training loss: 0.48514348257468365
Validation loss: 2.448093597643741

Epoch: 6| Step: 9
Training loss: 1.519325222767608
Validation loss: 2.422680534333171

Epoch: 6| Step: 10
Training loss: 0.9007874315749483
Validation loss: 2.417814856820878

Epoch: 6| Step: 11
Training loss: 0.9809676037337804
Validation loss: 2.4201800885555196

Epoch: 6| Step: 12
Training loss: 0.914827043362862
Validation loss: 2.38756284574658

Epoch: 6| Step: 13
Training loss: 0.9013900340647216
Validation loss: 2.419263339653893

Epoch: 287| Step: 0
Training loss: 0.7655632227672261
Validation loss: 2.4258092801646036

Epoch: 6| Step: 1
Training loss: 0.6027156132208846
Validation loss: 2.4509327173253115

Epoch: 6| Step: 2
Training loss: 1.1220954912114631
Validation loss: 2.453165168294873

Epoch: 6| Step: 3
Training loss: 0.742927182676378
Validation loss: 2.4325411776342083

Epoch: 6| Step: 4
Training loss: 0.6865450989953678
Validation loss: 2.4435573415809766

Epoch: 6| Step: 5
Training loss: 0.7890674855291911
Validation loss: 2.4409945689948773

Epoch: 6| Step: 6
Training loss: 0.9949697997431733
Validation loss: 2.4538149271385676

Epoch: 6| Step: 7
Training loss: 1.1613526003940478
Validation loss: 2.457292635427475

Epoch: 6| Step: 8
Training loss: 0.7717733493852649
Validation loss: 2.4521309258627286

Epoch: 6| Step: 9
Training loss: 0.9309544625582482
Validation loss: 2.4323369517986224

Epoch: 6| Step: 10
Training loss: 0.9495868675486427
Validation loss: 2.4272664206296626

Epoch: 6| Step: 11
Training loss: 1.1557846679471935
Validation loss: 2.428432900776285

Epoch: 6| Step: 12
Training loss: 1.1864736538713667
Validation loss: 2.3984727984163055

Epoch: 6| Step: 13
Training loss: 0.6767984353295968
Validation loss: 2.4386300800580596

Epoch: 288| Step: 0
Training loss: 0.6356137991324352
Validation loss: 2.42183947211282

Epoch: 6| Step: 1
Training loss: 0.8463289619018395
Validation loss: 2.4285414050517815

Epoch: 6| Step: 2
Training loss: 0.6084467836523049
Validation loss: 2.431917966091381

Epoch: 6| Step: 3
Training loss: 0.9956029543019376
Validation loss: 2.4245189227620014

Epoch: 6| Step: 4
Training loss: 0.928608308049275
Validation loss: 2.4232559823832647

Epoch: 6| Step: 5
Training loss: 0.7278660391495578
Validation loss: 2.4096880438873605

Epoch: 6| Step: 6
Training loss: 1.2866909985308743
Validation loss: 2.3970552521634825

Epoch: 6| Step: 7
Training loss: 0.8504991103834268
Validation loss: 2.421906281638726

Epoch: 6| Step: 8
Training loss: 1.1043971498920289
Validation loss: 2.4279079910261543

Epoch: 6| Step: 9
Training loss: 0.5435204207611926
Validation loss: 2.428594886890194

Epoch: 6| Step: 10
Training loss: 0.7098305436857494
Validation loss: 2.432429582977686

Epoch: 6| Step: 11
Training loss: 1.0298165270900315
Validation loss: 2.430736488213785

Epoch: 6| Step: 12
Training loss: 1.168531658564789
Validation loss: 2.3904507416880008

Epoch: 6| Step: 13
Training loss: 1.050427742526049
Validation loss: 2.434034143185534

Epoch: 289| Step: 0
Training loss: 0.7961378615028178
Validation loss: 2.406803314128781

Epoch: 6| Step: 1
Training loss: 0.6437582987648567
Validation loss: 2.4117765476918995

Epoch: 6| Step: 2
Training loss: 1.1028506275481507
Validation loss: 2.4088360543583085

Epoch: 6| Step: 3
Training loss: 0.6593511965825766
Validation loss: 2.3994813553930867

Epoch: 6| Step: 4
Training loss: 0.9179294009601691
Validation loss: 2.3803883664850987

Epoch: 6| Step: 5
Training loss: 0.8691824570779236
Validation loss: 2.428286797025529

Epoch: 6| Step: 6
Training loss: 0.9174648443965484
Validation loss: 2.4246678344649224

Epoch: 6| Step: 7
Training loss: 0.5915030829751551
Validation loss: 2.429330360161202

Epoch: 6| Step: 8
Training loss: 0.7381391035213541
Validation loss: 2.423127816850359

Epoch: 6| Step: 9
Training loss: 0.6317794750992689
Validation loss: 2.46252397301003

Epoch: 6| Step: 10
Training loss: 1.0524286452545635
Validation loss: 2.4546779119352715

Epoch: 6| Step: 11
Training loss: 1.1049358579738966
Validation loss: 2.4443754048990742

Epoch: 6| Step: 12
Training loss: 1.2863341154392853
Validation loss: 2.4784999339342857

Epoch: 6| Step: 13
Training loss: 1.1624834756804776
Validation loss: 2.4221769607090295

Epoch: 290| Step: 0
Training loss: 1.1588515320937252
Validation loss: 2.4275522526819815

Epoch: 6| Step: 1
Training loss: 1.2932458678555063
Validation loss: 2.3988753543042267

Epoch: 6| Step: 2
Training loss: 1.1486702507986726
Validation loss: 2.4229619736408

Epoch: 6| Step: 3
Training loss: 0.8434898540562737
Validation loss: 2.400512545898852

Epoch: 6| Step: 4
Training loss: 0.6165551193189969
Validation loss: 2.4130424258244028

Epoch: 6| Step: 5
Training loss: 0.5113210515872837
Validation loss: 2.3906425948879213

Epoch: 6| Step: 6
Training loss: 0.610651952447396
Validation loss: 2.409837858208896

Epoch: 6| Step: 7
Training loss: 0.7608942117460603
Validation loss: 2.3846340275662206

Epoch: 6| Step: 8
Training loss: 0.6843210111948091
Validation loss: 2.4088031108648216

Epoch: 6| Step: 9
Training loss: 0.931027128445115
Validation loss: 2.3990272266469463

Epoch: 6| Step: 10
Training loss: 1.2698230584102692
Validation loss: 2.4253308898960126

Epoch: 6| Step: 11
Training loss: 0.8246775430451904
Validation loss: 2.434360335283738

Epoch: 6| Step: 12
Training loss: 0.7552736758322249
Validation loss: 2.4618336317030938

Epoch: 6| Step: 13
Training loss: 0.5009060042219626
Validation loss: 2.4500314772866814

Epoch: 291| Step: 0
Training loss: 1.0448080696093718
Validation loss: 2.4210225563705507

Epoch: 6| Step: 1
Training loss: 0.7475337168256276
Validation loss: 2.445247735912052

Epoch: 6| Step: 2
Training loss: 0.986409884548395
Validation loss: 2.4326412891840583

Epoch: 6| Step: 3
Training loss: 0.8083642090147523
Validation loss: 2.437668112233912

Epoch: 6| Step: 4
Training loss: 0.5153842421745477
Validation loss: 2.414060508821986

Epoch: 6| Step: 5
Training loss: 0.7830301602743418
Validation loss: 2.407198330862323

Epoch: 6| Step: 6
Training loss: 0.8945041302563758
Validation loss: 2.406133183580428

Epoch: 6| Step: 7
Training loss: 0.8657971827168846
Validation loss: 2.4173900904423102

Epoch: 6| Step: 8
Training loss: 1.2167098747489162
Validation loss: 2.4169784962819567

Epoch: 6| Step: 9
Training loss: 0.8255117678620846
Validation loss: 2.432122091133536

Epoch: 6| Step: 10
Training loss: 1.081935506502732
Validation loss: 2.4104815377410915

Epoch: 6| Step: 11
Training loss: 0.9585018769923912
Validation loss: 2.4239740363730387

Epoch: 6| Step: 12
Training loss: 0.7852069971186751
Validation loss: 2.413871528464913

Epoch: 6| Step: 13
Training loss: 0.681692782704649
Validation loss: 2.4135754333479627

Epoch: 292| Step: 0
Training loss: 0.8528036469488909
Validation loss: 2.431281104330283

Epoch: 6| Step: 1
Training loss: 0.7937933481950273
Validation loss: 2.4448332047040346

Epoch: 6| Step: 2
Training loss: 0.5333845786966017
Validation loss: 2.4055100573652455

Epoch: 6| Step: 3
Training loss: 0.969569136796096
Validation loss: 2.442003126067477

Epoch: 6| Step: 4
Training loss: 0.9959660167699078
Validation loss: 2.4358035132292613

Epoch: 6| Step: 5
Training loss: 0.5988496322402659
Validation loss: 2.4360574634985652

Epoch: 6| Step: 6
Training loss: 1.1308390297649016
Validation loss: 2.457426602300862

Epoch: 6| Step: 7
Training loss: 0.9505137334410387
Validation loss: 2.451573938277069

Epoch: 6| Step: 8
Training loss: 0.789647895535404
Validation loss: 2.4204724175285994

Epoch: 6| Step: 9
Training loss: 0.9877415566823344
Validation loss: 2.4292340886459924

Epoch: 6| Step: 10
Training loss: 1.0428621616261424
Validation loss: 2.4530982768563554

Epoch: 6| Step: 11
Training loss: 0.19632152269998301
Validation loss: 2.450689367648293

Epoch: 6| Step: 12
Training loss: 1.0090474686812925
Validation loss: 2.434068692621568

Epoch: 6| Step: 13
Training loss: 1.1215784174952665
Validation loss: 2.4561446012509056

Epoch: 293| Step: 0
Training loss: 0.9521937589373951
Validation loss: 2.4688163697519414

Epoch: 6| Step: 1
Training loss: 0.8892237029392652
Validation loss: 2.466938947994523

Epoch: 6| Step: 2
Training loss: 0.6364031986844317
Validation loss: 2.4671414681472865

Epoch: 6| Step: 3
Training loss: 1.1780191712948616
Validation loss: 2.45725481524663

Epoch: 6| Step: 4
Training loss: 1.0208006224289554
Validation loss: 2.437444517452324

Epoch: 6| Step: 5
Training loss: 0.6091214899783552
Validation loss: 2.4432227391587444

Epoch: 6| Step: 6
Training loss: 0.46218506039278
Validation loss: 2.4274830005649917

Epoch: 6| Step: 7
Training loss: 1.1181683269569336
Validation loss: 2.4466889775636367

Epoch: 6| Step: 8
Training loss: 0.6064828071736134
Validation loss: 2.4180775764566826

Epoch: 6| Step: 9
Training loss: 0.870657225571756
Validation loss: 2.4150236946560004

Epoch: 6| Step: 10
Training loss: 0.6997406572779222
Validation loss: 2.4134458699545127

Epoch: 6| Step: 11
Training loss: 1.0665672655778717
Validation loss: 2.3991288649057907

Epoch: 6| Step: 12
Training loss: 0.9067141561015462
Validation loss: 2.425411840442007

Epoch: 6| Step: 13
Training loss: 0.9533727667784753
Validation loss: 2.4288887837461894

Epoch: 294| Step: 0
Training loss: 0.6230087986136508
Validation loss: 2.4299842261038704

Epoch: 6| Step: 1
Training loss: 0.38161307853373233
Validation loss: 2.4215081610905225

Epoch: 6| Step: 2
Training loss: 1.1206965257803372
Validation loss: 2.443851767873322

Epoch: 6| Step: 3
Training loss: 0.6372974317010773
Validation loss: 2.4429844728756427

Epoch: 6| Step: 4
Training loss: 1.3117891839152773
Validation loss: 2.42245400262715

Epoch: 6| Step: 5
Training loss: 1.0449729835631891
Validation loss: 2.4096702928337908

Epoch: 6| Step: 6
Training loss: 0.8200815874891366
Validation loss: 2.414988953966333

Epoch: 6| Step: 7
Training loss: 0.8159037964900967
Validation loss: 2.4154310575456512

Epoch: 6| Step: 8
Training loss: 0.6726982484614656
Validation loss: 2.396223062398116

Epoch: 6| Step: 9
Training loss: 0.9222886402145672
Validation loss: 2.412513961296781

Epoch: 6| Step: 10
Training loss: 1.058266001284118
Validation loss: 2.4531118270972847

Epoch: 6| Step: 11
Training loss: 0.888939919761932
Validation loss: 2.4508468534680623

Epoch: 6| Step: 12
Training loss: 0.7687459511378903
Validation loss: 2.4501058317685622

Epoch: 6| Step: 13
Training loss: 0.3038641245852259
Validation loss: 2.4555946022404567

Epoch: 295| Step: 0
Training loss: 0.748221832611906
Validation loss: 2.447410046881289

Epoch: 6| Step: 1
Training loss: 0.8484281901205303
Validation loss: 2.459123602963731

Epoch: 6| Step: 2
Training loss: 0.41931907502638666
Validation loss: 2.453940516268519

Epoch: 6| Step: 3
Training loss: 1.1831140332890067
Validation loss: 2.4217585043091816

Epoch: 6| Step: 4
Training loss: 1.1119945921114598
Validation loss: 2.406089853029632

Epoch: 6| Step: 5
Training loss: 0.6851304357139406
Validation loss: 2.4232472576003548

Epoch: 6| Step: 6
Training loss: 0.5620297479596189
Validation loss: 2.424589278826314

Epoch: 6| Step: 7
Training loss: 1.1323112694319386
Validation loss: 2.400290806731614

Epoch: 6| Step: 8
Training loss: 0.8232194528574177
Validation loss: 2.404733958798964

Epoch: 6| Step: 9
Training loss: 1.174551894592755
Validation loss: 2.41765538047932

Epoch: 6| Step: 10
Training loss: 0.851188997724064
Validation loss: 2.429841948982317

Epoch: 6| Step: 11
Training loss: 0.723277304525898
Validation loss: 2.4682444040054614

Epoch: 6| Step: 12
Training loss: 0.542287715038196
Validation loss: 2.430828508050714

Epoch: 6| Step: 13
Training loss: 0.8204614776480819
Validation loss: 2.461560944268356

Epoch: 296| Step: 0
Training loss: 0.5476057347659867
Validation loss: 2.4636226664064127

Epoch: 6| Step: 1
Training loss: 0.7713482314110484
Validation loss: 2.479049738457268

Epoch: 6| Step: 2
Training loss: 0.8882612684111134
Validation loss: 2.464800821264648

Epoch: 6| Step: 3
Training loss: 0.8030556363087004
Validation loss: 2.444098261713074

Epoch: 6| Step: 4
Training loss: 0.9676081788651343
Validation loss: 2.444251561486729

Epoch: 6| Step: 5
Training loss: 0.5904537608658503
Validation loss: 2.421033602875684

Epoch: 6| Step: 6
Training loss: 1.0744984210691926
Validation loss: 2.389287574633873

Epoch: 6| Step: 7
Training loss: 1.0512095432910842
Validation loss: 2.4032617932617852

Epoch: 6| Step: 8
Training loss: 0.7075245016593441
Validation loss: 2.3723913329381308

Epoch: 6| Step: 9
Training loss: 0.9044938336421029
Validation loss: 2.4042532975624975

Epoch: 6| Step: 10
Training loss: 0.794283373791029
Validation loss: 2.4294130431251784

Epoch: 6| Step: 11
Training loss: 0.9168080885485399
Validation loss: 2.399226468374756

Epoch: 6| Step: 12
Training loss: 0.8450163768558222
Validation loss: 2.4215915647717754

Epoch: 6| Step: 13
Training loss: 0.8518521227601983
Validation loss: 2.455182134898085

Epoch: 297| Step: 0
Training loss: 0.33387754639140454
Validation loss: 2.4416292205389576

Epoch: 6| Step: 1
Training loss: 0.4219216744776634
Validation loss: 2.4395763408430757

Epoch: 6| Step: 2
Training loss: 0.8397268879337002
Validation loss: 2.4601408898847716

Epoch: 6| Step: 3
Training loss: 0.7867874357967691
Validation loss: 2.4239396085197065

Epoch: 6| Step: 4
Training loss: 0.8516296920165588
Validation loss: 2.421689819073272

Epoch: 6| Step: 5
Training loss: 0.8160136981099535
Validation loss: 2.4296237607599314

Epoch: 6| Step: 6
Training loss: 0.7178302353165539
Validation loss: 2.398087085018558

Epoch: 6| Step: 7
Training loss: 1.0843908699039655
Validation loss: 2.414213724905674

Epoch: 6| Step: 8
Training loss: 0.5583270843592668
Validation loss: 2.405268083771379

Epoch: 6| Step: 9
Training loss: 1.204449853080447
Validation loss: 2.378334103635826

Epoch: 6| Step: 10
Training loss: 0.9191438012609304
Validation loss: 2.4089016781915853

Epoch: 6| Step: 11
Training loss: 1.009503151520736
Validation loss: 2.4099074737722224

Epoch: 6| Step: 12
Training loss: 0.754345583022152
Validation loss: 2.4150896949105105

Epoch: 6| Step: 13
Training loss: 1.1182781844225667
Validation loss: 2.4294558326503157

Epoch: 298| Step: 0
Training loss: 0.6608688977217549
Validation loss: 2.447300391992112

Epoch: 6| Step: 1
Training loss: 0.37028344680194997
Validation loss: 2.409618024078531

Epoch: 6| Step: 2
Training loss: 0.9959340285356513
Validation loss: 2.4337695582725303

Epoch: 6| Step: 3
Training loss: 0.5688820235058327
Validation loss: 2.425461577742219

Epoch: 6| Step: 4
Training loss: 1.139064557527586
Validation loss: 2.42867145093657

Epoch: 6| Step: 5
Training loss: 0.5987505898044684
Validation loss: 2.3953541844112833

Epoch: 6| Step: 6
Training loss: 0.9456673263587394
Validation loss: 2.388363890525149

Epoch: 6| Step: 7
Training loss: 0.328055465233281
Validation loss: 2.4023789888870977

Epoch: 6| Step: 8
Training loss: 0.7819622988795873
Validation loss: 2.413577031390438

Epoch: 6| Step: 9
Training loss: 1.3111226256901212
Validation loss: 2.397804656958176

Epoch: 6| Step: 10
Training loss: 1.01343605664833
Validation loss: 2.3972701748306227

Epoch: 6| Step: 11
Training loss: 0.6773808241469019
Validation loss: 2.42359758049638

Epoch: 6| Step: 12
Training loss: 0.9651683925305167
Validation loss: 2.417724340443051

Epoch: 6| Step: 13
Training loss: 0.5701852944007472
Validation loss: 2.395969413398912

Epoch: 299| Step: 0
Training loss: 0.8560090122662045
Validation loss: 2.428807002815968

Epoch: 6| Step: 1
Training loss: 0.7740906163800891
Validation loss: 2.442365865359989

Epoch: 6| Step: 2
Training loss: 0.7162521329651608
Validation loss: 2.434239965396863

Epoch: 6| Step: 3
Training loss: 0.8557588268363067
Validation loss: 2.421438491549328

Epoch: 6| Step: 4
Training loss: 0.4736871117996576
Validation loss: 2.449791728474426

Epoch: 6| Step: 5
Training loss: 0.8987152002147034
Validation loss: 2.437368542429122

Epoch: 6| Step: 6
Training loss: 1.0400311536891196
Validation loss: 2.422488375398318

Epoch: 6| Step: 7
Training loss: 0.7263042442168357
Validation loss: 2.447598171176451

Epoch: 6| Step: 8
Training loss: 0.7251996209478676
Validation loss: 2.4648675407303036

Epoch: 6| Step: 9
Training loss: 1.147281609989827
Validation loss: 2.4599712964182556

Epoch: 6| Step: 10
Training loss: 1.0290688654855924
Validation loss: 2.4757987533638843

Epoch: 6| Step: 11
Training loss: 0.49515506215794164
Validation loss: 2.480357698773126

Epoch: 6| Step: 12
Training loss: 0.7256464772491856
Validation loss: 2.475045724609854

Epoch: 6| Step: 13
Training loss: 0.6090592275329016
Validation loss: 2.4180981240638144

Epoch: 300| Step: 0
Training loss: 0.6400504210473776
Validation loss: 2.4275083793322403

Epoch: 6| Step: 1
Training loss: 0.9360006422546009
Validation loss: 2.3967351034051414

Epoch: 6| Step: 2
Training loss: 0.7591630365122302
Validation loss: 2.3983235622229393

Epoch: 6| Step: 3
Training loss: 0.5883288350307044
Validation loss: 2.411613586044823

Epoch: 6| Step: 4
Training loss: 0.7220786595913267
Validation loss: 2.3861300339502516

Epoch: 6| Step: 5
Training loss: 0.5607247950807319
Validation loss: 2.386060719574318

Epoch: 6| Step: 6
Training loss: 1.035358222115325
Validation loss: 2.398488869797843

Epoch: 6| Step: 7
Training loss: 0.7536094753420889
Validation loss: 2.4176961582236016

Epoch: 6| Step: 8
Training loss: 0.8936520716229369
Validation loss: 2.4127029109181537

Epoch: 6| Step: 9
Training loss: 0.8389401920334808
Validation loss: 2.404250370050801

Epoch: 6| Step: 10
Training loss: 1.034966908538635
Validation loss: 2.4021470250870505

Epoch: 6| Step: 11
Training loss: 0.8352434717635127
Validation loss: 2.4227407802050847

Epoch: 6| Step: 12
Training loss: 1.0022662233146744
Validation loss: 2.4138170481182244

Epoch: 6| Step: 13
Training loss: 0.197592737902659
Validation loss: 2.4106414732490267

Testing loss: 2.414908789225729
