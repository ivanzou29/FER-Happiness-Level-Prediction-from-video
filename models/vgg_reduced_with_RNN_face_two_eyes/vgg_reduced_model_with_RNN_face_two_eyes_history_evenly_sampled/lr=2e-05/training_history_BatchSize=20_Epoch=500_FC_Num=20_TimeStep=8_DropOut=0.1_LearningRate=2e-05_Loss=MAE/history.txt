Epoch: 1| Step: 0
Training loss: 4.936702251434326
Validation loss: 5.2579591043533815

Epoch: 5| Step: 1
Training loss: 5.786881446838379
Validation loss: 5.235647375865649

Epoch: 5| Step: 2
Training loss: 4.623725891113281
Validation loss: 5.215012370899159

Epoch: 5| Step: 3
Training loss: 5.405327796936035
Validation loss: 5.1929303035941174

Epoch: 5| Step: 4
Training loss: 4.493403434753418
Validation loss: 5.167438235334171

Epoch: 5| Step: 5
Training loss: 5.9037346839904785
Validation loss: 5.138147379762383

Epoch: 5| Step: 6
Training loss: 5.744238376617432
Validation loss: 5.104507851344283

Epoch: 5| Step: 7
Training loss: 4.3464531898498535
Validation loss: 5.067422887330414

Epoch: 5| Step: 8
Training loss: 4.151444435119629
Validation loss: 5.02715403033841

Epoch: 5| Step: 9
Training loss: 4.214607238769531
Validation loss: 4.982958762876449

Epoch: 5| Step: 10
Training loss: 4.404103755950928
Validation loss: 4.935810929985457

Epoch: 2| Step: 0
Training loss: 3.7186381816864014
Validation loss: 4.885730040970669

Epoch: 5| Step: 1
Training loss: 4.1331377029418945
Validation loss: 4.83089510087044

Epoch: 5| Step: 2
Training loss: 5.3552117347717285
Validation loss: 4.772605608868343

Epoch: 5| Step: 3
Training loss: 4.932173728942871
Validation loss: 4.711895881160613

Epoch: 5| Step: 4
Training loss: 5.846125602722168
Validation loss: 4.648124746097031

Epoch: 5| Step: 5
Training loss: 3.6441307067871094
Validation loss: 4.582381704802154

Epoch: 5| Step: 6
Training loss: 3.498511552810669
Validation loss: 4.512350236215899

Epoch: 5| Step: 7
Training loss: 3.1779420375823975
Validation loss: 4.440712390407439

Epoch: 5| Step: 8
Training loss: 5.041085243225098
Validation loss: 4.36737552765877

Epoch: 5| Step: 9
Training loss: 5.039547443389893
Validation loss: 4.2931260088438625

Epoch: 5| Step: 10
Training loss: 3.5918726921081543
Validation loss: 4.2155833141778105

Epoch: 3| Step: 0
Training loss: 4.139550685882568
Validation loss: 4.1372714247754825

Epoch: 5| Step: 1
Training loss: 4.306332588195801
Validation loss: 4.066071633369692

Epoch: 5| Step: 2
Training loss: 3.4404349327087402
Validation loss: 4.005969893547796

Epoch: 5| Step: 3
Training loss: 4.346176624298096
Validation loss: 3.953716221676078

Epoch: 5| Step: 4
Training loss: 3.829003095626831
Validation loss: 3.9113360630568637

Epoch: 5| Step: 5
Training loss: 3.7492759227752686
Validation loss: 3.8755185732277493

Epoch: 5| Step: 6
Training loss: 3.535076856613159
Validation loss: 3.8421419205204135

Epoch: 5| Step: 7
Training loss: 3.936509370803833
Validation loss: 3.812221360462968

Epoch: 5| Step: 8
Training loss: 4.0710649490356445
Validation loss: 3.780043932699388

Epoch: 5| Step: 9
Training loss: 2.6996896266937256
Validation loss: 3.750812051116779

Epoch: 5| Step: 10
Training loss: 3.2789807319641113
Validation loss: 3.7267133241058676

Epoch: 4| Step: 0
Training loss: 3.438387632369995
Validation loss: 3.703859529187602

Epoch: 5| Step: 1
Training loss: 3.1714026927948
Validation loss: 3.683879611312702

Epoch: 5| Step: 2
Training loss: 4.048786640167236
Validation loss: 3.668137288862659

Epoch: 5| Step: 3
Training loss: 3.3875339031219482
Validation loss: 3.6534844675371723

Epoch: 5| Step: 4
Training loss: 2.783831834793091
Validation loss: 3.639558089676724

Epoch: 5| Step: 5
Training loss: 3.7025210857391357
Validation loss: 3.623810706600066

Epoch: 5| Step: 6
Training loss: 3.2326531410217285
Validation loss: 3.604504995448615

Epoch: 5| Step: 7
Training loss: 4.004284381866455
Validation loss: 3.5859088256794918

Epoch: 5| Step: 8
Training loss: 3.318436861038208
Validation loss: 3.566607988008889

Epoch: 5| Step: 9
Training loss: 4.718577861785889
Validation loss: 3.547232230504354

Epoch: 5| Step: 10
Training loss: 3.0352344512939453
Validation loss: 3.5246673732675533

Epoch: 5| Step: 0
Training loss: 3.056868076324463
Validation loss: 3.503387169171405

Epoch: 5| Step: 1
Training loss: 2.885119676589966
Validation loss: 3.487718169407178

Epoch: 5| Step: 2
Training loss: 2.318897247314453
Validation loss: 3.472368896648448

Epoch: 5| Step: 3
Training loss: 3.627917528152466
Validation loss: 3.4594439434748825

Epoch: 5| Step: 4
Training loss: 3.307797908782959
Validation loss: 3.4429523970491145

Epoch: 5| Step: 5
Training loss: 3.814815044403076
Validation loss: 3.425584057325958

Epoch: 5| Step: 6
Training loss: 3.545126438140869
Validation loss: 3.4108146288061656

Epoch: 5| Step: 7
Training loss: 3.2482898235321045
Validation loss: 3.3974080085754395

Epoch: 5| Step: 8
Training loss: 3.7841153144836426
Validation loss: 3.3851685472714004

Epoch: 5| Step: 9
Training loss: 3.7054226398468018
Validation loss: 3.3659008497832925

Epoch: 5| Step: 10
Training loss: 3.8608007431030273
Validation loss: 3.3512108864322787

Epoch: 6| Step: 0
Training loss: 3.7134928703308105
Validation loss: 3.340048864323606

Epoch: 5| Step: 1
Training loss: 2.395915985107422
Validation loss: 3.3318779647991223

Epoch: 5| Step: 2
Training loss: 3.0318543910980225
Validation loss: 3.3203008431260304

Epoch: 5| Step: 3
Training loss: 3.561230421066284
Validation loss: 3.309663652091898

Epoch: 5| Step: 4
Training loss: 4.138736724853516
Validation loss: 3.298932085755051

Epoch: 5| Step: 5
Training loss: 3.044377326965332
Validation loss: 3.290127149192236

Epoch: 5| Step: 6
Training loss: 3.4372050762176514
Validation loss: 3.279638736478744

Epoch: 5| Step: 7
Training loss: 3.239166259765625
Validation loss: 3.288612929723596

Epoch: 5| Step: 8
Training loss: 3.08868670463562
Validation loss: 3.2651905705851894

Epoch: 5| Step: 9
Training loss: 2.719921588897705
Validation loss: 3.2590046800592893

Epoch: 5| Step: 10
Training loss: 3.602733850479126
Validation loss: 3.263909098922565

Epoch: 7| Step: 0
Training loss: 2.9029476642608643
Validation loss: 3.2587577527569187

Epoch: 5| Step: 1
Training loss: 2.40415620803833
Validation loss: 3.2580284175052436

Epoch: 5| Step: 2
Training loss: 3.1208739280700684
Validation loss: 3.237417690215572

Epoch: 5| Step: 3
Training loss: 2.9430105686187744
Validation loss: 3.2226996216722714

Epoch: 5| Step: 4
Training loss: 2.512901782989502
Validation loss: 3.2167798370443363

Epoch: 5| Step: 5
Training loss: 2.6311769485473633
Validation loss: 3.2164419030630462

Epoch: 5| Step: 6
Training loss: 4.107501983642578
Validation loss: 3.218952404555454

Epoch: 5| Step: 7
Training loss: 3.524587631225586
Validation loss: 3.200122571760608

Epoch: 5| Step: 8
Training loss: 4.156245231628418
Validation loss: 3.1934366944015666

Epoch: 5| Step: 9
Training loss: 3.7035961151123047
Validation loss: 3.1868557109627673

Epoch: 5| Step: 10
Training loss: 3.281850576400757
Validation loss: 3.180059540656305

Epoch: 8| Step: 0
Training loss: 3.0851242542266846
Validation loss: 3.178629982856012

Epoch: 5| Step: 1
Training loss: 3.0295753479003906
Validation loss: 3.169124105925201

Epoch: 5| Step: 2
Training loss: 4.176458835601807
Validation loss: 3.1648750382085002

Epoch: 5| Step: 3
Training loss: 3.3547611236572266
Validation loss: 3.159351082258327

Epoch: 5| Step: 4
Training loss: 3.198467969894409
Validation loss: 3.1451557374769643

Epoch: 5| Step: 5
Training loss: 3.168769598007202
Validation loss: 3.1413680250926683

Epoch: 5| Step: 6
Training loss: 3.6585609912872314
Validation loss: 3.1372663205669773

Epoch: 5| Step: 7
Training loss: 2.5893898010253906
Validation loss: 3.130874918353173

Epoch: 5| Step: 8
Training loss: 3.626218318939209
Validation loss: 3.1311946222859044

Epoch: 5| Step: 9
Training loss: 2.343567371368408
Validation loss: 3.1306743057825233

Epoch: 5| Step: 10
Training loss: 2.438148021697998
Validation loss: 3.1281028742431314

Epoch: 9| Step: 0
Training loss: 2.5460851192474365
Validation loss: 3.123601590433428

Epoch: 5| Step: 1
Training loss: 3.596724271774292
Validation loss: 3.1210554235724994

Epoch: 5| Step: 2
Training loss: 3.3975017070770264
Validation loss: 3.1140869843062533

Epoch: 5| Step: 3
Training loss: 3.4096062183380127
Validation loss: 3.1083549607184624

Epoch: 5| Step: 4
Training loss: 3.3842010498046875
Validation loss: 3.1079630646654355

Epoch: 5| Step: 5
Training loss: 3.412557601928711
Validation loss: 3.099037524192564

Epoch: 5| Step: 6
Training loss: 2.676969289779663
Validation loss: 3.0937451419009956

Epoch: 5| Step: 7
Training loss: 2.46518611907959
Validation loss: 3.090953052684825

Epoch: 5| Step: 8
Training loss: 3.9583396911621094
Validation loss: 3.0852744963861283

Epoch: 5| Step: 9
Training loss: 2.7372636795043945
Validation loss: 3.0802183715246056

Epoch: 5| Step: 10
Training loss: 2.7915220260620117
Validation loss: 3.0778002303133727

Epoch: 10| Step: 0
Training loss: 3.0733752250671387
Validation loss: 3.07361251308072

Epoch: 5| Step: 1
Training loss: 2.767518997192383
Validation loss: 3.0715695683674147

Epoch: 5| Step: 2
Training loss: 3.3909554481506348
Validation loss: 3.070082741398965

Epoch: 5| Step: 3
Training loss: 3.5510268211364746
Validation loss: 3.067318393338111

Epoch: 5| Step: 4
Training loss: 3.0975093841552734
Validation loss: 3.0646949250211

Epoch: 5| Step: 5
Training loss: 3.262620449066162
Validation loss: 3.063063390793339

Epoch: 5| Step: 6
Training loss: 3.5640456676483154
Validation loss: 3.056794138364894

Epoch: 5| Step: 7
Training loss: 3.3759331703186035
Validation loss: 3.0507779685399865

Epoch: 5| Step: 8
Training loss: 2.533259630203247
Validation loss: 3.0473469521409724

Epoch: 5| Step: 9
Training loss: 2.809587001800537
Validation loss: 3.0439224089345625

Epoch: 5| Step: 10
Training loss: 2.6693966388702393
Validation loss: 3.0402410491820304

Epoch: 11| Step: 0
Training loss: 2.2819080352783203
Validation loss: 3.037194393014395

Epoch: 5| Step: 1
Training loss: 3.1498804092407227
Validation loss: 3.03282694919135

Epoch: 5| Step: 2
Training loss: 3.987579822540283
Validation loss: 3.031018172540972

Epoch: 5| Step: 3
Training loss: 2.5400290489196777
Validation loss: 3.0272032112203617

Epoch: 5| Step: 4
Training loss: 3.6638832092285156
Validation loss: 3.023917152035621

Epoch: 5| Step: 5
Training loss: 2.4168028831481934
Validation loss: 3.0194686664048063

Epoch: 5| Step: 6
Training loss: 2.407843828201294
Validation loss: 3.0159066595057005

Epoch: 5| Step: 7
Training loss: 2.853933572769165
Validation loss: 3.0155641776259228

Epoch: 5| Step: 8
Training loss: 3.264503002166748
Validation loss: 3.0125497259119505

Epoch: 5| Step: 9
Training loss: 4.016448020935059
Validation loss: 3.0101554060495026

Epoch: 5| Step: 10
Training loss: 3.3584022521972656
Validation loss: 3.006177004947457

Epoch: 12| Step: 0
Training loss: 3.268594264984131
Validation loss: 3.0029709287869033

Epoch: 5| Step: 1
Training loss: 2.716672420501709
Validation loss: 2.9965507984161377

Epoch: 5| Step: 2
Training loss: 2.636624574661255
Validation loss: 2.9932730249179307

Epoch: 5| Step: 3
Training loss: 2.8663361072540283
Validation loss: 2.9904815766119186

Epoch: 5| Step: 4
Training loss: 3.06042218208313
Validation loss: 2.9872669302007204

Epoch: 5| Step: 5
Training loss: 3.066314697265625
Validation loss: 2.9863240923932803

Epoch: 5| Step: 6
Training loss: 3.440736770629883
Validation loss: 2.9881629302937496

Epoch: 5| Step: 7
Training loss: 2.995509386062622
Validation loss: 2.9762711396781345

Epoch: 5| Step: 8
Training loss: 2.8098690509796143
Validation loss: 2.972151840886762

Epoch: 5| Step: 9
Training loss: 3.632547378540039
Validation loss: 2.9829710068241244

Epoch: 5| Step: 10
Training loss: 3.097194194793701
Validation loss: 2.978740225556076

Epoch: 13| Step: 0
Training loss: 2.8908681869506836
Validation loss: 2.9759294191996255

Epoch: 5| Step: 1
Training loss: 2.894655704498291
Validation loss: 2.9641369696586364

Epoch: 5| Step: 2
Training loss: 3.1276485919952393
Validation loss: 2.9658360353080173

Epoch: 5| Step: 3
Training loss: 2.8304998874664307
Validation loss: 2.9612044724085

Epoch: 5| Step: 4
Training loss: 3.2148919105529785
Validation loss: 2.956866241270496

Epoch: 5| Step: 5
Training loss: 2.784313440322876
Validation loss: 2.9574393277527182

Epoch: 5| Step: 6
Training loss: 4.085121154785156
Validation loss: 2.952234965498729

Epoch: 5| Step: 7
Training loss: 3.1838130950927734
Validation loss: 2.950907125267931

Epoch: 5| Step: 8
Training loss: 2.787759780883789
Validation loss: 2.9474347176090365

Epoch: 5| Step: 9
Training loss: 2.7464516162872314
Validation loss: 2.95666164992958

Epoch: 5| Step: 10
Training loss: 2.8352832794189453
Validation loss: 2.946566381762105

Epoch: 14| Step: 0
Training loss: 2.4188804626464844
Validation loss: 2.9414645318062074

Epoch: 5| Step: 1
Training loss: 3.1983981132507324
Validation loss: 2.9416557153066

Epoch: 5| Step: 2
Training loss: 3.3118183612823486
Validation loss: 2.9436025004233084

Epoch: 5| Step: 3
Training loss: 3.4254150390625
Validation loss: 2.943643416127851

Epoch: 5| Step: 4
Training loss: 2.656599521636963
Validation loss: 2.9414915653967086

Epoch: 5| Step: 5
Training loss: 3.374108076095581
Validation loss: 2.944285741416357

Epoch: 5| Step: 6
Training loss: 3.065964698791504
Validation loss: 2.9483751020123883

Epoch: 5| Step: 7
Training loss: 2.500910997390747
Validation loss: 2.9317245662853284

Epoch: 5| Step: 8
Training loss: 2.8804686069488525
Validation loss: 2.9380203652125534

Epoch: 5| Step: 9
Training loss: 3.070122241973877
Validation loss: 2.9369409007410847

Epoch: 5| Step: 10
Training loss: 3.422203779220581
Validation loss: 2.9275747781158774

Epoch: 15| Step: 0
Training loss: 3.883817195892334
Validation loss: 2.92346590821461

Epoch: 5| Step: 1
Training loss: 3.1254520416259766
Validation loss: 2.920327305793762

Epoch: 5| Step: 2
Training loss: 2.7997848987579346
Validation loss: 2.920261726584486

Epoch: 5| Step: 3
Training loss: 2.397822141647339
Validation loss: 2.918684677411151

Epoch: 5| Step: 4
Training loss: 2.8436532020568848
Validation loss: 2.915118214904621

Epoch: 5| Step: 5
Training loss: 3.1630656719207764
Validation loss: 2.908971881353727

Epoch: 5| Step: 6
Training loss: 2.5603249073028564
Validation loss: 2.9081718665297314

Epoch: 5| Step: 7
Training loss: 3.611807346343994
Validation loss: 2.9112796527083202

Epoch: 5| Step: 8
Training loss: 3.5543875694274902
Validation loss: 2.9121238082967777

Epoch: 5| Step: 9
Training loss: 2.496199369430542
Validation loss: 2.904474760896416

Epoch: 5| Step: 10
Training loss: 2.6058149337768555
Validation loss: 2.897841784261888

Epoch: 16| Step: 0
Training loss: 3.2790629863739014
Validation loss: 2.8938382415361303

Epoch: 5| Step: 1
Training loss: 2.9874770641326904
Validation loss: 2.891970890824513

Epoch: 5| Step: 2
Training loss: 2.4577012062072754
Validation loss: 2.8901560768004386

Epoch: 5| Step: 3
Training loss: 2.7382590770721436
Validation loss: 2.888947930387271

Epoch: 5| Step: 4
Training loss: 2.968839168548584
Validation loss: 2.8898214601701304

Epoch: 5| Step: 5
Training loss: 3.339064836502075
Validation loss: 2.8886755922789216

Epoch: 5| Step: 6
Training loss: 3.2015578746795654
Validation loss: 2.888924519220988

Epoch: 5| Step: 7
Training loss: 2.72678279876709
Validation loss: 2.8845692680728052

Epoch: 5| Step: 8
Training loss: 2.9126622676849365
Validation loss: 2.8811381606645483

Epoch: 5| Step: 9
Training loss: 3.840491533279419
Validation loss: 2.8793392540306173

Epoch: 5| Step: 10
Training loss: 2.3613131046295166
Validation loss: 2.877170885762861

Epoch: 17| Step: 0
Training loss: 2.705484628677368
Validation loss: 2.876438756142893

Epoch: 5| Step: 1
Training loss: 2.2676005363464355
Validation loss: 2.8776479433941584

Epoch: 5| Step: 2
Training loss: 3.8117499351501465
Validation loss: 2.875697200016309

Epoch: 5| Step: 3
Training loss: 2.96553897857666
Validation loss: 2.8719258513501895

Epoch: 5| Step: 4
Training loss: 3.1091034412384033
Validation loss: 2.869631472454276

Epoch: 5| Step: 5
Training loss: 3.126267433166504
Validation loss: 2.869476895178518

Epoch: 5| Step: 6
Training loss: 2.527238130569458
Validation loss: 2.867998412860337

Epoch: 5| Step: 7
Training loss: 3.3469386100769043
Validation loss: 2.8684322731469267

Epoch: 5| Step: 8
Training loss: 2.613337993621826
Validation loss: 2.866159592905352

Epoch: 5| Step: 9
Training loss: 3.0414977073669434
Validation loss: 2.864887801549768

Epoch: 5| Step: 10
Training loss: 3.312769889831543
Validation loss: 2.8624575958457044

Epoch: 18| Step: 0
Training loss: 3.3022637367248535
Validation loss: 2.862950824922131

Epoch: 5| Step: 1
Training loss: 2.8531875610351562
Validation loss: 2.9059695761690856

Epoch: 5| Step: 2
Training loss: 2.319223403930664
Validation loss: 2.9181729285947737

Epoch: 5| Step: 3
Training loss: 3.004554033279419
Validation loss: 2.9266713511559272

Epoch: 5| Step: 4
Training loss: 3.995190143585205
Validation loss: 2.920592846408967

Epoch: 5| Step: 5
Training loss: 2.3707401752471924
Validation loss: 2.916479120972336

Epoch: 5| Step: 6
Training loss: 3.3852362632751465
Validation loss: 2.91417593853448

Epoch: 5| Step: 7
Training loss: 2.8297510147094727
Validation loss: 2.9165776775729273

Epoch: 5| Step: 8
Training loss: 2.979656934738159
Validation loss: 2.9194600710304837

Epoch: 5| Step: 9
Training loss: 3.449446201324463
Validation loss: 2.9238899215575187

Epoch: 5| Step: 10
Training loss: 2.498061180114746
Validation loss: 2.9390670407202935

Epoch: 19| Step: 0
Training loss: 2.695204734802246
Validation loss: 2.9302429793983378

Epoch: 5| Step: 1
Training loss: 3.001650333404541
Validation loss: 2.9053119254368607

Epoch: 5| Step: 2
Training loss: 2.572505474090576
Validation loss: 2.902805474496657

Epoch: 5| Step: 3
Training loss: 3.4432461261749268
Validation loss: 2.9086513006558983

Epoch: 5| Step: 4
Training loss: 2.64762806892395
Validation loss: 2.9136511228417836

Epoch: 5| Step: 5
Training loss: 3.2235825061798096
Validation loss: 2.907043754413564

Epoch: 5| Step: 6
Training loss: 3.431960344314575
Validation loss: 2.9005329250007548

Epoch: 5| Step: 7
Training loss: 3.032151699066162
Validation loss: 2.895137377964553

Epoch: 5| Step: 8
Training loss: 3.151313304901123
Validation loss: 2.8714312891806326

Epoch: 5| Step: 9
Training loss: 2.721963882446289
Validation loss: 2.846695807672316

Epoch: 5| Step: 10
Training loss: 3.0752110481262207
Validation loss: 2.8470966046856296

Epoch: 20| Step: 0
Training loss: 2.90004301071167
Validation loss: 2.8611515901421987

Epoch: 5| Step: 1
Training loss: 2.570995807647705
Validation loss: 2.874869138963761

Epoch: 5| Step: 2
Training loss: 3.297744035720825
Validation loss: 2.8718526440282024

Epoch: 5| Step: 3
Training loss: 3.138420820236206
Validation loss: 2.857672127344275

Epoch: 5| Step: 4
Training loss: 2.876626491546631
Validation loss: 2.851408299579415

Epoch: 5| Step: 5
Training loss: 2.3163681030273438
Validation loss: 2.845914679188882

Epoch: 5| Step: 6
Training loss: 2.6202754974365234
Validation loss: 2.84566927981633

Epoch: 5| Step: 7
Training loss: 3.156583309173584
Validation loss: 2.8497621064545005

Epoch: 5| Step: 8
Training loss: 3.368879795074463
Validation loss: 2.8610541307797996

Epoch: 5| Step: 9
Training loss: 3.3092873096466064
Validation loss: 2.850822707658173

Epoch: 5| Step: 10
Training loss: 3.1632003784179688
Validation loss: 2.8328666071737967

Epoch: 21| Step: 0
Training loss: 2.724768877029419
Validation loss: 2.829980363128006

Epoch: 5| Step: 1
Training loss: 2.89621639251709
Validation loss: 2.831764098136656

Epoch: 5| Step: 2
Training loss: 3.1601853370666504
Validation loss: 2.8437981400438535

Epoch: 5| Step: 3
Training loss: 2.807779312133789
Validation loss: 2.8628486202609156

Epoch: 5| Step: 4
Training loss: 3.5358738899230957
Validation loss: 2.843008556673604

Epoch: 5| Step: 5
Training loss: 3.909733533859253
Validation loss: 2.842437587758546

Epoch: 5| Step: 6
Training loss: 2.30647611618042
Validation loss: 2.837746153595627

Epoch: 5| Step: 7
Training loss: 2.7676374912261963
Validation loss: 2.834771006338058

Epoch: 5| Step: 8
Training loss: 3.3005268573760986
Validation loss: 2.8350304147248626

Epoch: 5| Step: 9
Training loss: 2.2581982612609863
Validation loss: 2.8318711814060005

Epoch: 5| Step: 10
Training loss: 2.8251872062683105
Validation loss: 2.8289002244190504

Epoch: 22| Step: 0
Training loss: 3.531372547149658
Validation loss: 2.827620252486198

Epoch: 5| Step: 1
Training loss: 2.894918918609619
Validation loss: 2.824677736528458

Epoch: 5| Step: 2
Training loss: 3.1010046005249023
Validation loss: 2.8220903232533443

Epoch: 5| Step: 3
Training loss: 2.894387722015381
Validation loss: 2.8190111678133727

Epoch: 5| Step: 4
Training loss: 2.6976661682128906
Validation loss: 2.8192606433745353

Epoch: 5| Step: 5
Training loss: 2.022772789001465
Validation loss: 2.815800977009599

Epoch: 5| Step: 6
Training loss: 2.7369492053985596
Validation loss: 2.8152761869533087

Epoch: 5| Step: 7
Training loss: 3.581185817718506
Validation loss: 2.813844093712427

Epoch: 5| Step: 8
Training loss: 3.198824644088745
Validation loss: 2.814843172668129

Epoch: 5| Step: 9
Training loss: 2.684619903564453
Validation loss: 2.8191471330581175

Epoch: 5| Step: 10
Training loss: 3.098585367202759
Validation loss: 2.827145068876205

Epoch: 23| Step: 0
Training loss: 2.617706537246704
Validation loss: 2.813088014561643

Epoch: 5| Step: 1
Training loss: 2.951334238052368
Validation loss: 2.811511916498984

Epoch: 5| Step: 2
Training loss: 3.5180087089538574
Validation loss: 2.809293944348571

Epoch: 5| Step: 3
Training loss: 2.598005771636963
Validation loss: 2.8093662159417265

Epoch: 5| Step: 4
Training loss: 3.0264618396759033
Validation loss: 2.8071184158325195

Epoch: 5| Step: 5
Training loss: 2.878370761871338
Validation loss: 2.8082144183497273

Epoch: 5| Step: 6
Training loss: 2.8890833854675293
Validation loss: 2.812726900141726

Epoch: 5| Step: 7
Training loss: 2.586120843887329
Validation loss: 2.81301728628015

Epoch: 5| Step: 8
Training loss: 3.3844094276428223
Validation loss: 2.8216429320714806

Epoch: 5| Step: 9
Training loss: 2.339817762374878
Validation loss: 2.8051033071292344

Epoch: 5| Step: 10
Training loss: 3.6514945030212402
Validation loss: 2.8017125052790486

Epoch: 24| Step: 0
Training loss: 3.688080310821533
Validation loss: 2.8013346220857356

Epoch: 5| Step: 1
Training loss: 2.302886486053467
Validation loss: 2.7996462750178512

Epoch: 5| Step: 2
Training loss: 2.8274104595184326
Validation loss: 2.799883001594133

Epoch: 5| Step: 3
Training loss: 2.038379430770874
Validation loss: 2.801088748439666

Epoch: 5| Step: 4
Training loss: 2.810269832611084
Validation loss: 2.805856353493147

Epoch: 5| Step: 5
Training loss: 3.2054343223571777
Validation loss: 2.80129333208966

Epoch: 5| Step: 6
Training loss: 2.469367504119873
Validation loss: 2.8016536594719015

Epoch: 5| Step: 7
Training loss: 3.734055280685425
Validation loss: 2.798527486862675

Epoch: 5| Step: 8
Training loss: 2.842020034790039
Validation loss: 2.796399280589114

Epoch: 5| Step: 9
Training loss: 2.859961986541748
Validation loss: 2.795553148433726

Epoch: 5| Step: 10
Training loss: 3.6008968353271484
Validation loss: 2.7952523385324786

Epoch: 25| Step: 0
Training loss: 2.9523375034332275
Validation loss: 2.7945085699840257

Epoch: 5| Step: 1
Training loss: 2.7148327827453613
Validation loss: 2.7929060459136963

Epoch: 5| Step: 2
Training loss: 2.447249174118042
Validation loss: 2.7901205939631306

Epoch: 5| Step: 3
Training loss: 3.485614776611328
Validation loss: 2.7908676003897064

Epoch: 5| Step: 4
Training loss: 3.0075347423553467
Validation loss: 2.7914139788637877

Epoch: 5| Step: 5
Training loss: 3.071723222732544
Validation loss: 2.7899312665385585

Epoch: 5| Step: 6
Training loss: 3.2040305137634277
Validation loss: 2.788795772419181

Epoch: 5| Step: 7
Training loss: 2.7631077766418457
Validation loss: 2.7863854182663785

Epoch: 5| Step: 8
Training loss: 2.8158984184265137
Validation loss: 2.787061486192929

Epoch: 5| Step: 9
Training loss: 2.616209030151367
Validation loss: 2.784040927886963

Epoch: 5| Step: 10
Training loss: 3.1574063301086426
Validation loss: 2.786947299075383

Epoch: 26| Step: 0
Training loss: 2.2920472621917725
Validation loss: 2.786353034357871

Epoch: 5| Step: 1
Training loss: 3.147444248199463
Validation loss: 2.7884872908233316

Epoch: 5| Step: 2
Training loss: 2.7546963691711426
Validation loss: 2.7852685579689602

Epoch: 5| Step: 3
Training loss: 3.497077465057373
Validation loss: 2.781738909341956

Epoch: 5| Step: 4
Training loss: 3.5347015857696533
Validation loss: 2.7803068494284027

Epoch: 5| Step: 5
Training loss: 2.6128857135772705
Validation loss: 2.7802317193759385

Epoch: 5| Step: 6
Training loss: 2.5593934059143066
Validation loss: 2.779980008320142

Epoch: 5| Step: 7
Training loss: 2.5736937522888184
Validation loss: 2.7801990150123514

Epoch: 5| Step: 8
Training loss: 3.3436837196350098
Validation loss: 2.7773152884616645

Epoch: 5| Step: 9
Training loss: 2.826312303543091
Validation loss: 2.7832785883257465

Epoch: 5| Step: 10
Training loss: 3.03935170173645
Validation loss: 2.779516348274805

Epoch: 27| Step: 0
Training loss: 2.8721394538879395
Validation loss: 2.7805779416074037

Epoch: 5| Step: 1
Training loss: 2.95479154586792
Validation loss: 2.778532451198947

Epoch: 5| Step: 2
Training loss: 2.5647552013397217
Validation loss: 2.7750274750494186

Epoch: 5| Step: 3
Training loss: 2.5661959648132324
Validation loss: 2.775483041681269

Epoch: 5| Step: 4
Training loss: 1.9069750308990479
Validation loss: 2.771508944931851

Epoch: 5| Step: 5
Training loss: 3.002864122390747
Validation loss: 2.7700894750574583

Epoch: 5| Step: 6
Training loss: 3.911299228668213
Validation loss: 2.768999304822696

Epoch: 5| Step: 7
Training loss: 3.060678482055664
Validation loss: 2.768334545114989

Epoch: 5| Step: 8
Training loss: 2.734177350997925
Validation loss: 2.769994233244209

Epoch: 5| Step: 9
Training loss: 3.2843475341796875
Validation loss: 2.7717459637631654

Epoch: 5| Step: 10
Training loss: 3.281646251678467
Validation loss: 2.769432460108111

Epoch: 28| Step: 0
Training loss: 3.277484893798828
Validation loss: 2.769688570371238

Epoch: 5| Step: 1
Training loss: 2.7226626873016357
Validation loss: 2.767198060148506

Epoch: 5| Step: 2
Training loss: 2.798069953918457
Validation loss: 2.766981194096227

Epoch: 5| Step: 3
Training loss: 2.4223742485046387
Validation loss: 2.7644924066400014

Epoch: 5| Step: 4
Training loss: 3.3824667930603027
Validation loss: 2.763848950785975

Epoch: 5| Step: 5
Training loss: 3.1222333908081055
Validation loss: 2.763379155948598

Epoch: 5| Step: 6
Training loss: 2.646860361099243
Validation loss: 2.7636587260871806

Epoch: 5| Step: 7
Training loss: 3.380823850631714
Validation loss: 2.7645723255731727

Epoch: 5| Step: 8
Training loss: 2.9285027980804443
Validation loss: 2.7630217588076027

Epoch: 5| Step: 9
Training loss: 2.6063385009765625
Validation loss: 2.7637012004852295

Epoch: 5| Step: 10
Training loss: 2.743084669113159
Validation loss: 2.7612227701371714

Epoch: 29| Step: 0
Training loss: 2.3866708278656006
Validation loss: 2.7600831036926596

Epoch: 5| Step: 1
Training loss: 2.8256916999816895
Validation loss: 2.7605228424072266

Epoch: 5| Step: 2
Training loss: 2.305009365081787
Validation loss: 2.760391443006454

Epoch: 5| Step: 3
Training loss: 3.3983852863311768
Validation loss: 2.7613140844529673

Epoch: 5| Step: 4
Training loss: 3.4097137451171875
Validation loss: 2.758393359440629

Epoch: 5| Step: 5
Training loss: 3.0432422161102295
Validation loss: 2.7592076511793238

Epoch: 5| Step: 6
Training loss: 3.511284351348877
Validation loss: 2.7598716981949343

Epoch: 5| Step: 7
Training loss: 2.9749932289123535
Validation loss: 2.758766346080329

Epoch: 5| Step: 8
Training loss: 2.7573838233947754
Validation loss: 2.756792635046026

Epoch: 5| Step: 9
Training loss: 2.947740077972412
Validation loss: 2.763339219554778

Epoch: 5| Step: 10
Training loss: 2.2942028045654297
Validation loss: 2.760715902492564

Epoch: 30| Step: 0
Training loss: 2.4626171588897705
Validation loss: 2.756260792414347

Epoch: 5| Step: 1
Training loss: 3.1023759841918945
Validation loss: 2.753778962678807

Epoch: 5| Step: 2
Training loss: 2.7684683799743652
Validation loss: 2.7557268757973947

Epoch: 5| Step: 3
Training loss: 2.8479866981506348
Validation loss: 2.7498021894885647

Epoch: 5| Step: 4
Training loss: 2.953704595565796
Validation loss: 2.7503789291586926

Epoch: 5| Step: 5
Training loss: 3.111480712890625
Validation loss: 2.7503373366530224

Epoch: 5| Step: 6
Training loss: 3.561812162399292
Validation loss: 2.7523116168155464

Epoch: 5| Step: 7
Training loss: 3.1669352054595947
Validation loss: 2.7537975618916173

Epoch: 5| Step: 8
Training loss: 2.6058897972106934
Validation loss: 2.7520657739331646

Epoch: 5| Step: 9
Training loss: 2.6919848918914795
Validation loss: 2.7538933959058536

Epoch: 5| Step: 10
Training loss: 2.6544229984283447
Validation loss: 2.7536911605506815

Epoch: 31| Step: 0
Training loss: 2.764197826385498
Validation loss: 2.753667245629013

Epoch: 5| Step: 1
Training loss: 3.243558168411255
Validation loss: 2.750449213930356

Epoch: 5| Step: 2
Training loss: 3.08351731300354
Validation loss: 2.7474869271760345

Epoch: 5| Step: 3
Training loss: 2.9659361839294434
Validation loss: 2.745840072631836

Epoch: 5| Step: 4
Training loss: 2.6571125984191895
Validation loss: 2.744454686359693

Epoch: 5| Step: 5
Training loss: 2.256213426589966
Validation loss: 2.7437201212811213

Epoch: 5| Step: 6
Training loss: 3.4770140647888184
Validation loss: 2.742011962398406

Epoch: 5| Step: 7
Training loss: 2.672119140625
Validation loss: 2.7424928757452194

Epoch: 5| Step: 8
Training loss: 3.061188220977783
Validation loss: 2.7431019121600735

Epoch: 5| Step: 9
Training loss: 2.8816442489624023
Validation loss: 2.746726930782359

Epoch: 5| Step: 10
Training loss: 2.795315742492676
Validation loss: 2.739671802008024

Epoch: 32| Step: 0
Training loss: 2.930368661880493
Validation loss: 2.7420270186598583

Epoch: 5| Step: 1
Training loss: 2.3049349784851074
Validation loss: 2.74013860764042

Epoch: 5| Step: 2
Training loss: 2.7584786415100098
Validation loss: 2.7392470913548626

Epoch: 5| Step: 3
Training loss: 3.1799216270446777
Validation loss: 2.7385680726779404

Epoch: 5| Step: 4
Training loss: 2.4864420890808105
Validation loss: 2.7356691565564883

Epoch: 5| Step: 5
Training loss: 3.2690792083740234
Validation loss: 2.7350824930334605

Epoch: 5| Step: 6
Training loss: 2.7206108570098877
Validation loss: 2.7352322327193392

Epoch: 5| Step: 7
Training loss: 3.5474791526794434
Validation loss: 2.7408279911164315

Epoch: 5| Step: 8
Training loss: 2.8112645149230957
Validation loss: 2.7590761159055974

Epoch: 5| Step: 9
Training loss: 2.8759865760803223
Validation loss: 2.7581910779399257

Epoch: 5| Step: 10
Training loss: 2.933349609375
Validation loss: 2.771417051233271

Epoch: 33| Step: 0
Training loss: 2.7631921768188477
Validation loss: 2.792809763262349

Epoch: 5| Step: 1
Training loss: 3.677161455154419
Validation loss: 2.763489023331673

Epoch: 5| Step: 2
Training loss: 2.3100078105926514
Validation loss: 2.7303482870901785

Epoch: 5| Step: 3
Training loss: 2.562995433807373
Validation loss: 2.7284088134765625

Epoch: 5| Step: 4
Training loss: 2.7502312660217285
Validation loss: 2.730223999228529

Epoch: 5| Step: 5
Training loss: 3.115243434906006
Validation loss: 2.737613690796719

Epoch: 5| Step: 6
Training loss: 2.7116332054138184
Validation loss: 2.7398003044948784

Epoch: 5| Step: 7
Training loss: 3.5383286476135254
Validation loss: 2.7430276255453787

Epoch: 5| Step: 8
Training loss: 3.0095107555389404
Validation loss: 2.734957984698716

Epoch: 5| Step: 9
Training loss: 2.8223044872283936
Validation loss: 2.7378814579338155

Epoch: 5| Step: 10
Training loss: 2.4559755325317383
Validation loss: 2.742853690219182

Epoch: 34| Step: 0
Training loss: 1.6274560689926147
Validation loss: 2.7499648653050905

Epoch: 5| Step: 1
Training loss: 3.6862664222717285
Validation loss: 2.7545872067892425

Epoch: 5| Step: 2
Training loss: 2.3438143730163574
Validation loss: 2.753187338511149

Epoch: 5| Step: 3
Training loss: 2.6474521160125732
Validation loss: 2.747085891744142

Epoch: 5| Step: 4
Training loss: 4.152794361114502
Validation loss: 2.7361297838149534

Epoch: 5| Step: 5
Training loss: 2.8075547218322754
Validation loss: 2.731873027739986

Epoch: 5| Step: 6
Training loss: 2.775256633758545
Validation loss: 2.7344953219095864

Epoch: 5| Step: 7
Training loss: 2.615337371826172
Validation loss: 2.72623469239922

Epoch: 5| Step: 8
Training loss: 3.1021807193756104
Validation loss: 2.729779299869332

Epoch: 5| Step: 9
Training loss: 3.071714401245117
Validation loss: 2.732021975260909

Epoch: 5| Step: 10
Training loss: 2.820378065109253
Validation loss: 2.739782366701352

Epoch: 35| Step: 0
Training loss: 3.9323744773864746
Validation loss: 2.7438962972292336

Epoch: 5| Step: 1
Training loss: 3.25262713432312
Validation loss: 2.7388349656135804

Epoch: 5| Step: 2
Training loss: 3.00872802734375
Validation loss: 2.732740274039648

Epoch: 5| Step: 3
Training loss: 2.5415878295898438
Validation loss: 2.7330392278650755

Epoch: 5| Step: 4
Training loss: 2.806391477584839
Validation loss: 2.732341125447263

Epoch: 5| Step: 5
Training loss: 2.9464592933654785
Validation loss: 2.7371800868741927

Epoch: 5| Step: 6
Training loss: 2.2998592853546143
Validation loss: 2.7569755866963375

Epoch: 5| Step: 7
Training loss: 2.124704599380493
Validation loss: 2.7370940075125745

Epoch: 5| Step: 8
Training loss: 2.7487685680389404
Validation loss: 2.7296938383451073

Epoch: 5| Step: 9
Training loss: 2.835782527923584
Validation loss: 2.7366906263495006

Epoch: 5| Step: 10
Training loss: 3.3057470321655273
Validation loss: 2.7510137711801836

Epoch: 36| Step: 0
Training loss: 1.6104081869125366
Validation loss: 2.726832271904074

Epoch: 5| Step: 1
Training loss: 3.125314712524414
Validation loss: 2.715379076619302

Epoch: 5| Step: 2
Training loss: 3.271336078643799
Validation loss: 2.7164276774211595

Epoch: 5| Step: 3
Training loss: 3.0649449825286865
Validation loss: 2.7218805013164395

Epoch: 5| Step: 4
Training loss: 3.4462058544158936
Validation loss: 2.7283283151606077

Epoch: 5| Step: 5
Training loss: 2.789217710494995
Validation loss: 2.727153503766624

Epoch: 5| Step: 6
Training loss: 3.0919189453125
Validation loss: 2.7198658630412114

Epoch: 5| Step: 7
Training loss: 2.849316120147705
Validation loss: 2.7299268373879055

Epoch: 5| Step: 8
Training loss: 2.8333213329315186
Validation loss: 2.725403985669536

Epoch: 5| Step: 9
Training loss: 2.7132515907287598
Validation loss: 2.7209931624832975

Epoch: 5| Step: 10
Training loss: 2.7932567596435547
Validation loss: 2.722290010862453

Epoch: 37| Step: 0
Training loss: 2.741157054901123
Validation loss: 2.7166962110868065

Epoch: 5| Step: 1
Training loss: 3.054006814956665
Validation loss: 2.718944634160688

Epoch: 5| Step: 2
Training loss: 2.7188048362731934
Validation loss: 2.7157977242623605

Epoch: 5| Step: 3
Training loss: 2.5786805152893066
Validation loss: 2.712027713816653

Epoch: 5| Step: 4
Training loss: 2.7846016883850098
Validation loss: 2.7093054350986274

Epoch: 5| Step: 5
Training loss: 2.7678189277648926
Validation loss: 2.715206907641503

Epoch: 5| Step: 6
Training loss: 3.1115400791168213
Validation loss: 2.715243636920888

Epoch: 5| Step: 7
Training loss: 3.711608409881592
Validation loss: 2.7098224650147142

Epoch: 5| Step: 8
Training loss: 2.6337785720825195
Validation loss: 2.709445689314155

Epoch: 5| Step: 9
Training loss: 2.551483631134033
Validation loss: 2.72160872849085

Epoch: 5| Step: 10
Training loss: 2.715893030166626
Validation loss: 2.7386784604800645

Epoch: 38| Step: 0
Training loss: 2.706453323364258
Validation loss: 2.7787185715090845

Epoch: 5| Step: 1
Training loss: 1.849224328994751
Validation loss: 2.754133862833823

Epoch: 5| Step: 2
Training loss: 3.185507297515869
Validation loss: 2.740724668707899

Epoch: 5| Step: 3
Training loss: 3.1568377017974854
Validation loss: 2.7177134611273326

Epoch: 5| Step: 4
Training loss: 2.032161235809326
Validation loss: 2.7074729319541686

Epoch: 5| Step: 5
Training loss: 3.0606024265289307
Validation loss: 2.7379308182706117

Epoch: 5| Step: 6
Training loss: 3.2295641899108887
Validation loss: 2.728442494587232

Epoch: 5| Step: 7
Training loss: 3.2827019691467285
Validation loss: 2.7187406119479927

Epoch: 5| Step: 8
Training loss: 3.2033042907714844
Validation loss: 2.70068468329727

Epoch: 5| Step: 9
Training loss: 2.4371516704559326
Validation loss: 2.698552249580301

Epoch: 5| Step: 10
Training loss: 3.446899890899658
Validation loss: 2.7089662833880355

Epoch: 39| Step: 0
Training loss: 2.0070624351501465
Validation loss: 2.7267145649079354

Epoch: 5| Step: 1
Training loss: 2.838392734527588
Validation loss: 2.7686558231230705

Epoch: 5| Step: 2
Training loss: 3.4179470539093018
Validation loss: 2.726299878089659

Epoch: 5| Step: 3
Training loss: 2.8242645263671875
Validation loss: 2.7015176665398384

Epoch: 5| Step: 4
Training loss: 3.2617506980895996
Validation loss: 2.7003490771016767

Epoch: 5| Step: 5
Training loss: 1.9305992126464844
Validation loss: 2.695835713417299

Epoch: 5| Step: 6
Training loss: 3.3392677307128906
Validation loss: 2.690008350597915

Epoch: 5| Step: 7
Training loss: 2.7496256828308105
Validation loss: 2.6904553174972534

Epoch: 5| Step: 8
Training loss: 2.6334927082061768
Validation loss: 2.71847286019274

Epoch: 5| Step: 9
Training loss: 3.588567018508911
Validation loss: 2.721856814558788

Epoch: 5| Step: 10
Training loss: 2.9617083072662354
Validation loss: 2.7243907913084953

Epoch: 40| Step: 0
Training loss: 3.098747968673706
Validation loss: 2.7225766669037523

Epoch: 5| Step: 1
Training loss: 3.0336055755615234
Validation loss: 2.722861638633154

Epoch: 5| Step: 2
Training loss: 2.630030870437622
Validation loss: 2.7258656640206613

Epoch: 5| Step: 3
Training loss: 3.0552978515625
Validation loss: 2.729483383958058

Epoch: 5| Step: 4
Training loss: 2.483936309814453
Validation loss: 2.725601593653361

Epoch: 5| Step: 5
Training loss: 2.6148879528045654
Validation loss: 2.7222573500807568

Epoch: 5| Step: 6
Training loss: 2.8800134658813477
Validation loss: 2.716094728439085

Epoch: 5| Step: 7
Training loss: 2.7960333824157715
Validation loss: 2.7159699522038943

Epoch: 5| Step: 8
Training loss: 3.3175740242004395
Validation loss: 2.7223994039720103

Epoch: 5| Step: 9
Training loss: 2.856151580810547
Validation loss: 2.7247627191646124

Epoch: 5| Step: 10
Training loss: 2.7509939670562744
Validation loss: 2.7309669704847437

Epoch: 41| Step: 0
Training loss: 3.182828426361084
Validation loss: 2.717945514186736

Epoch: 5| Step: 1
Training loss: 2.54758620262146
Validation loss: 2.6862868467966714

Epoch: 5| Step: 2
Training loss: 2.8436691761016846
Validation loss: 2.6827420996081446

Epoch: 5| Step: 3
Training loss: 2.634915590286255
Validation loss: 2.666808943594656

Epoch: 5| Step: 4
Training loss: 2.8149361610412598
Validation loss: 2.661060607561501

Epoch: 5| Step: 5
Training loss: 2.7224109172821045
Validation loss: 2.6631307730110745

Epoch: 5| Step: 6
Training loss: 2.613839626312256
Validation loss: 2.671904315230667

Epoch: 5| Step: 7
Training loss: 3.7570090293884277
Validation loss: 2.6791313668733

Epoch: 5| Step: 8
Training loss: 2.625598192214966
Validation loss: 2.6822804763752925

Epoch: 5| Step: 9
Training loss: 2.2498621940612793
Validation loss: 2.6770481986384236

Epoch: 5| Step: 10
Training loss: 3.215541362762451
Validation loss: 2.68941468064503

Epoch: 42| Step: 0
Training loss: 3.0588221549987793
Validation loss: 2.695554453839538

Epoch: 5| Step: 1
Training loss: 2.430905342102051
Validation loss: 2.680759888823314

Epoch: 5| Step: 2
Training loss: 3.6625068187713623
Validation loss: 2.666985534852551

Epoch: 5| Step: 3
Training loss: 2.3805785179138184
Validation loss: 2.664469452314479

Epoch: 5| Step: 4
Training loss: 2.778764486312866
Validation loss: 2.668427659619239

Epoch: 5| Step: 5
Training loss: 2.678492307662964
Validation loss: 2.6643828909884215

Epoch: 5| Step: 6
Training loss: 3.16424822807312
Validation loss: 2.662584735501197

Epoch: 5| Step: 7
Training loss: 2.7338809967041016
Validation loss: 2.662570494477467

Epoch: 5| Step: 8
Training loss: 3.0631256103515625
Validation loss: 2.669176850267636

Epoch: 5| Step: 9
Training loss: 2.333083391189575
Validation loss: 2.6593530331888506

Epoch: 5| Step: 10
Training loss: 3.0033674240112305
Validation loss: 2.6517068160477506

Epoch: 43| Step: 0
Training loss: 3.2959041595458984
Validation loss: 2.657189466620004

Epoch: 5| Step: 1
Training loss: 2.909508228302002
Validation loss: 2.684051513671875

Epoch: 5| Step: 2
Training loss: 2.177917718887329
Validation loss: 2.6574483276695333

Epoch: 5| Step: 3
Training loss: 3.993767499923706
Validation loss: 2.6461050305315243

Epoch: 5| Step: 4
Training loss: 2.6753907203674316
Validation loss: 2.6477900217938166

Epoch: 5| Step: 5
Training loss: 2.721482038497925
Validation loss: 2.6501673959916636

Epoch: 5| Step: 6
Training loss: 3.3488380908966064
Validation loss: 2.647174068676528

Epoch: 5| Step: 7
Training loss: 2.478909492492676
Validation loss: 2.6572569929143435

Epoch: 5| Step: 8
Training loss: 2.6611523628234863
Validation loss: 2.6568201049681632

Epoch: 5| Step: 9
Training loss: 2.3806068897247314
Validation loss: 2.672247771293886

Epoch: 5| Step: 10
Training loss: 2.3674278259277344
Validation loss: 2.7126611740358415

Epoch: 44| Step: 0
Training loss: 3.005619525909424
Validation loss: 2.683601628067673

Epoch: 5| Step: 1
Training loss: 3.187040328979492
Validation loss: 2.67419106729569

Epoch: 5| Step: 2
Training loss: 2.5916025638580322
Validation loss: 2.67060613119474

Epoch: 5| Step: 3
Training loss: 2.6481103897094727
Validation loss: 2.653777781353202

Epoch: 5| Step: 4
Training loss: 2.2957379817962646
Validation loss: 2.6435743378054712

Epoch: 5| Step: 5
Training loss: 2.243427276611328
Validation loss: 2.6405071468763452

Epoch: 5| Step: 6
Training loss: 3.6204617023468018
Validation loss: 2.643926825574649

Epoch: 5| Step: 7
Training loss: 2.974714756011963
Validation loss: 2.6482428760938745

Epoch: 5| Step: 8
Training loss: 2.5926320552825928
Validation loss: 2.6536294209059847

Epoch: 5| Step: 9
Training loss: 2.4807918071746826
Validation loss: 2.655586515703509

Epoch: 5| Step: 10
Training loss: 3.4524788856506348
Validation loss: 2.657932125112062

Epoch: 45| Step: 0
Training loss: 3.230283737182617
Validation loss: 2.6428081527833016

Epoch: 5| Step: 1
Training loss: 3.0445103645324707
Validation loss: 2.638851716954221

Epoch: 5| Step: 2
Training loss: 3.289564609527588
Validation loss: 2.631447207543158

Epoch: 5| Step: 3
Training loss: 3.3678696155548096
Validation loss: 2.6270828144524687

Epoch: 5| Step: 4
Training loss: 2.8965413570404053
Validation loss: 2.6259228183377172

Epoch: 5| Step: 5
Training loss: 2.1246631145477295
Validation loss: 2.6257245976437806

Epoch: 5| Step: 6
Training loss: 2.3800108432769775
Validation loss: 2.624218745898175

Epoch: 5| Step: 7
Training loss: 2.946342945098877
Validation loss: 2.6193020215598484

Epoch: 5| Step: 8
Training loss: 2.2917351722717285
Validation loss: 2.6200298006816576

Epoch: 5| Step: 9
Training loss: 2.5470337867736816
Validation loss: 2.6182780291444514

Epoch: 5| Step: 10
Training loss: 2.6125524044036865
Validation loss: 2.617988722298735

Epoch: 46| Step: 0
Training loss: 2.753105878829956
Validation loss: 2.6170177408443984

Epoch: 5| Step: 1
Training loss: 2.5837767124176025
Validation loss: 2.617115769335019

Epoch: 5| Step: 2
Training loss: 2.6644632816314697
Validation loss: 2.6220075609863445

Epoch: 5| Step: 3
Training loss: 2.179234743118286
Validation loss: 2.621987109543175

Epoch: 5| Step: 4
Training loss: 2.668196201324463
Validation loss: 2.625108888072352

Epoch: 5| Step: 5
Training loss: 2.863136053085327
Validation loss: 2.6209096062567925

Epoch: 5| Step: 6
Training loss: 2.737609386444092
Validation loss: 2.6234555218809392

Epoch: 5| Step: 7
Training loss: 2.733865261077881
Validation loss: 2.625845520727096

Epoch: 5| Step: 8
Training loss: 3.3942718505859375
Validation loss: 2.634993940271357

Epoch: 5| Step: 9
Training loss: 2.9626173973083496
Validation loss: 2.644337164458408

Epoch: 5| Step: 10
Training loss: 3.126298427581787
Validation loss: 2.635053957662275

Epoch: 47| Step: 0
Training loss: 1.736962914466858
Validation loss: 2.6298294144292034

Epoch: 5| Step: 1
Training loss: 2.352222442626953
Validation loss: 2.6343398119813655

Epoch: 5| Step: 2
Training loss: 2.5141570568084717
Validation loss: 2.6228351695563203

Epoch: 5| Step: 3
Training loss: 2.784726142883301
Validation loss: 2.6120582319075063

Epoch: 5| Step: 4
Training loss: 2.8904166221618652
Validation loss: 2.608943098334856

Epoch: 5| Step: 5
Training loss: 3.3045201301574707
Validation loss: 2.607412028056319

Epoch: 5| Step: 6
Training loss: 3.365260362625122
Validation loss: 2.605070657627557

Epoch: 5| Step: 7
Training loss: 3.049832820892334
Validation loss: 2.609472638817244

Epoch: 5| Step: 8
Training loss: 2.23796010017395
Validation loss: 2.6055839318101124

Epoch: 5| Step: 9
Training loss: 3.909031391143799
Validation loss: 2.610721911153486

Epoch: 5| Step: 10
Training loss: 2.4443702697753906
Validation loss: 2.611830711364746

Epoch: 48| Step: 0
Training loss: 2.86887526512146
Validation loss: 2.600979212791689

Epoch: 5| Step: 1
Training loss: 2.44651460647583
Validation loss: 2.600016204259729

Epoch: 5| Step: 2
Training loss: 3.6355197429656982
Validation loss: 2.6071762602816344

Epoch: 5| Step: 3
Training loss: 2.6114368438720703
Validation loss: 2.6116265686609412

Epoch: 5| Step: 4
Training loss: 2.1702120304107666
Validation loss: 2.6094735566005913

Epoch: 5| Step: 5
Training loss: 3.0182101726531982
Validation loss: 2.613747740304598

Epoch: 5| Step: 6
Training loss: 2.7091526985168457
Validation loss: 2.613158077322027

Epoch: 5| Step: 7
Training loss: 3.2943947315216064
Validation loss: 2.6154425323650403

Epoch: 5| Step: 8
Training loss: 2.279703378677368
Validation loss: 2.614250462542298

Epoch: 5| Step: 9
Training loss: 3.4787864685058594
Validation loss: 2.6073512684914375

Epoch: 5| Step: 10
Training loss: 2.0463953018188477
Validation loss: 2.599771507324711

Epoch: 49| Step: 0
Training loss: 2.6784439086914062
Validation loss: 2.594264740584999

Epoch: 5| Step: 1
Training loss: 3.4154746532440186
Validation loss: 2.6002243513702066

Epoch: 5| Step: 2
Training loss: 2.7185113430023193
Validation loss: 2.59861800747533

Epoch: 5| Step: 3
Training loss: 2.3998494148254395
Validation loss: 2.5972278887225735

Epoch: 5| Step: 4
Training loss: 2.7690062522888184
Validation loss: 2.593150605437576

Epoch: 5| Step: 5
Training loss: 2.8928399085998535
Validation loss: 2.5953037431163173

Epoch: 5| Step: 6
Training loss: 2.9304585456848145
Validation loss: 2.5954367524834088

Epoch: 5| Step: 7
Training loss: 3.1355185508728027
Validation loss: 2.596895005113335

Epoch: 5| Step: 8
Training loss: 2.741650104522705
Validation loss: 2.5978786048068794

Epoch: 5| Step: 9
Training loss: 2.6917080879211426
Validation loss: 2.597370165650563

Epoch: 5| Step: 10
Training loss: 2.000437021255493
Validation loss: 2.601669414069063

Epoch: 50| Step: 0
Training loss: 2.645386219024658
Validation loss: 2.590401775093489

Epoch: 5| Step: 1
Training loss: 2.874178171157837
Validation loss: 2.586373121507706

Epoch: 5| Step: 2
Training loss: 2.242013454437256
Validation loss: 2.5857960536915767

Epoch: 5| Step: 3
Training loss: 3.0053436756134033
Validation loss: 2.5852542666978735

Epoch: 5| Step: 4
Training loss: 2.689345598220825
Validation loss: 2.5826662202035227

Epoch: 5| Step: 5
Training loss: 2.190413236618042
Validation loss: 2.5817217724297636

Epoch: 5| Step: 6
Training loss: 3.639556884765625
Validation loss: 2.586614324200538

Epoch: 5| Step: 7
Training loss: 2.58662748336792
Validation loss: 2.5858184009469967

Epoch: 5| Step: 8
Training loss: 2.9409127235412598
Validation loss: 2.589878951349566

Epoch: 5| Step: 9
Training loss: 3.243971347808838
Validation loss: 2.595795154571533

Epoch: 5| Step: 10
Training loss: 2.197199583053589
Validation loss: 2.5968730424040105

Epoch: 51| Step: 0
Training loss: 2.970777988433838
Validation loss: 2.5900711756880566

Epoch: 5| Step: 1
Training loss: 2.701977491378784
Validation loss: 2.598684416022352

Epoch: 5| Step: 2
Training loss: 2.00614333152771
Validation loss: 2.6027379215404554

Epoch: 5| Step: 3
Training loss: 3.02610182762146
Validation loss: 2.5933019115078833

Epoch: 5| Step: 4
Training loss: 3.2972099781036377
Validation loss: 2.5846830362914712

Epoch: 5| Step: 5
Training loss: 3.6116108894348145
Validation loss: 2.582399550304618

Epoch: 5| Step: 6
Training loss: 2.3587357997894287
Validation loss: 2.5732041200002036

Epoch: 5| Step: 7
Training loss: 1.9275543689727783
Validation loss: 2.573785222986693

Epoch: 5| Step: 8
Training loss: 2.067009687423706
Validation loss: 2.570718349949006

Epoch: 5| Step: 9
Training loss: 3.462355136871338
Validation loss: 2.571948351398591

Epoch: 5| Step: 10
Training loss: 2.9737789630889893
Validation loss: 2.5706430968417915

Epoch: 52| Step: 0
Training loss: 3.230708360671997
Validation loss: 2.5715520689564366

Epoch: 5| Step: 1
Training loss: 2.0528228282928467
Validation loss: 2.5669624523449968

Epoch: 5| Step: 2
Training loss: 3.7122230529785156
Validation loss: 2.573834175704628

Epoch: 5| Step: 3
Training loss: 3.2803688049316406
Validation loss: 2.5704864301989154

Epoch: 5| Step: 4
Training loss: 2.5961952209472656
Validation loss: 2.5731029228497575

Epoch: 5| Step: 5
Training loss: 3.2655303478240967
Validation loss: 2.5739841999546176

Epoch: 5| Step: 6
Training loss: 2.367799997329712
Validation loss: 2.587088297772151

Epoch: 5| Step: 7
Training loss: 1.8995392322540283
Validation loss: 2.6038117075479157

Epoch: 5| Step: 8
Training loss: 2.5940439701080322
Validation loss: 2.596410861579321

Epoch: 5| Step: 9
Training loss: 2.4320220947265625
Validation loss: 2.575628226803195

Epoch: 5| Step: 10
Training loss: 2.82706618309021
Validation loss: 2.561932420217863

Epoch: 53| Step: 0
Training loss: 2.6523101329803467
Validation loss: 2.5733601893148115

Epoch: 5| Step: 1
Training loss: 2.26084303855896
Validation loss: 2.596010003038632

Epoch: 5| Step: 2
Training loss: 3.00927996635437
Validation loss: 2.6338903878324773

Epoch: 5| Step: 3
Training loss: 2.6084859371185303
Validation loss: 2.6901272394323863

Epoch: 5| Step: 4
Training loss: 3.048290729522705
Validation loss: 2.681259403946579

Epoch: 5| Step: 5
Training loss: 3.2935791015625
Validation loss: 2.6599504922025945

Epoch: 5| Step: 6
Training loss: 2.8250956535339355
Validation loss: 2.6105217446563063

Epoch: 5| Step: 7
Training loss: 2.354915142059326
Validation loss: 2.591022153054514

Epoch: 5| Step: 8
Training loss: 2.7690911293029785
Validation loss: 2.5678540968125865

Epoch: 5| Step: 9
Training loss: 3.3848488330841064
Validation loss: 2.557507227825862

Epoch: 5| Step: 10
Training loss: 2.318737268447876
Validation loss: 2.5704497163013746

Epoch: 54| Step: 0
Training loss: 3.2426724433898926
Validation loss: 2.621029817929832

Epoch: 5| Step: 1
Training loss: 2.828275203704834
Validation loss: 2.652762113078948

Epoch: 5| Step: 2
Training loss: 3.4701695442199707
Validation loss: 2.6285896788361254

Epoch: 5| Step: 3
Training loss: 2.4650321006774902
Validation loss: 2.577599892052271

Epoch: 5| Step: 4
Training loss: 2.391202449798584
Validation loss: 2.5585255289590485

Epoch: 5| Step: 5
Training loss: 2.6928763389587402
Validation loss: 2.5528610496110815

Epoch: 5| Step: 6
Training loss: 3.1808204650878906
Validation loss: 2.5460753569038967

Epoch: 5| Step: 7
Training loss: 2.7283833026885986
Validation loss: 2.5543952142038653

Epoch: 5| Step: 8
Training loss: 2.556986093521118
Validation loss: 2.575182371242072

Epoch: 5| Step: 9
Training loss: 2.6645452976226807
Validation loss: 2.591286846386489

Epoch: 5| Step: 10
Training loss: 1.916849970817566
Validation loss: 2.599093557685934

Epoch: 55| Step: 0
Training loss: 2.6165292263031006
Validation loss: 2.5814492394847255

Epoch: 5| Step: 1
Training loss: 3.3226230144500732
Validation loss: 2.5756550553024455

Epoch: 5| Step: 2
Training loss: 2.304910659790039
Validation loss: 2.552922761568459

Epoch: 5| Step: 3
Training loss: 2.6652393341064453
Validation loss: 2.546137338043541

Epoch: 5| Step: 4
Training loss: 2.927922487258911
Validation loss: 2.5447335473952757

Epoch: 5| Step: 5
Training loss: 2.9976119995117188
Validation loss: 2.548791257284021

Epoch: 5| Step: 6
Training loss: 2.502915859222412
Validation loss: 2.548292247197961

Epoch: 5| Step: 7
Training loss: 2.536904811859131
Validation loss: 2.5515198912671817

Epoch: 5| Step: 8
Training loss: 2.436579465866089
Validation loss: 2.5503026644388833

Epoch: 5| Step: 9
Training loss: 3.145246982574463
Validation loss: 2.5485575122217976

Epoch: 5| Step: 10
Training loss: 2.7191758155822754
Validation loss: 2.545247567597256

Epoch: 56| Step: 0
Training loss: 3.220499038696289
Validation loss: 2.546743118634788

Epoch: 5| Step: 1
Training loss: 2.729954481124878
Validation loss: 2.5460453802539456

Epoch: 5| Step: 2
Training loss: 2.767055034637451
Validation loss: 2.5435078784983647

Epoch: 5| Step: 3
Training loss: 2.3119585514068604
Validation loss: 2.5436596126966577

Epoch: 5| Step: 4
Training loss: 2.7004165649414062
Validation loss: 2.5379040625787552

Epoch: 5| Step: 5
Training loss: 2.7129459381103516
Validation loss: 2.5382393662647535

Epoch: 5| Step: 6
Training loss: 2.6050801277160645
Validation loss: 2.539025927102694

Epoch: 5| Step: 7
Training loss: 2.4485766887664795
Validation loss: 2.5405542619766726

Epoch: 5| Step: 8
Training loss: 2.5100440979003906
Validation loss: 2.536908067682738

Epoch: 5| Step: 9
Training loss: 2.9115049839019775
Validation loss: 2.535197409250403

Epoch: 5| Step: 10
Training loss: 3.127380609512329
Validation loss: 2.5333866739785798

Epoch: 57| Step: 0
Training loss: 2.6743388175964355
Validation loss: 2.5357008903257308

Epoch: 5| Step: 1
Training loss: 3.135023832321167
Validation loss: 2.537845673099641

Epoch: 5| Step: 2
Training loss: 2.445484161376953
Validation loss: 2.5352867034173783

Epoch: 5| Step: 3
Training loss: 2.561286449432373
Validation loss: 2.528734440444618

Epoch: 5| Step: 4
Training loss: 2.948878765106201
Validation loss: 2.53198831055754

Epoch: 5| Step: 5
Training loss: 2.5702409744262695
Validation loss: 2.532840362159155

Epoch: 5| Step: 6
Training loss: 2.3187499046325684
Validation loss: 2.5360180434360298

Epoch: 5| Step: 7
Training loss: 2.7033889293670654
Validation loss: 2.536084600674209

Epoch: 5| Step: 8
Training loss: 2.942242383956909
Validation loss: 2.5383649872195337

Epoch: 5| Step: 9
Training loss: 2.6704001426696777
Validation loss: 2.5449613089202554

Epoch: 5| Step: 10
Training loss: 3.0715391635894775
Validation loss: 2.5499234789161274

Epoch: 58| Step: 0
Training loss: 2.396266222000122
Validation loss: 2.5595082057419645

Epoch: 5| Step: 1
Training loss: 2.5979695320129395
Validation loss: 2.553019731275497

Epoch: 5| Step: 2
Training loss: 2.662065029144287
Validation loss: 2.5424060180623043

Epoch: 5| Step: 3
Training loss: 2.1650938987731934
Validation loss: 2.5319558881944224

Epoch: 5| Step: 4
Training loss: 2.4817824363708496
Validation loss: 2.537928347946495

Epoch: 5| Step: 5
Training loss: 3.5477070808410645
Validation loss: 2.541135900764055

Epoch: 5| Step: 6
Training loss: 2.432387590408325
Validation loss: 2.5434758329904206

Epoch: 5| Step: 7
Training loss: 2.7440688610076904
Validation loss: 2.5407296739598757

Epoch: 5| Step: 8
Training loss: 2.778313398361206
Validation loss: 2.5436547443430912

Epoch: 5| Step: 9
Training loss: 3.014000415802002
Validation loss: 2.536757335867933

Epoch: 5| Step: 10
Training loss: 3.2727909088134766
Validation loss: 2.5373137253586964

Epoch: 59| Step: 0
Training loss: 2.3268356323242188
Validation loss: 2.539355457469981

Epoch: 5| Step: 1
Training loss: 2.7088308334350586
Validation loss: 2.5358870695996028

Epoch: 5| Step: 2
Training loss: 2.4798743724823
Validation loss: 2.5395855775443454

Epoch: 5| Step: 3
Training loss: 2.5508646965026855
Validation loss: 2.540015264223981

Epoch: 5| Step: 4
Training loss: 2.187540054321289
Validation loss: 2.5450494571398665

Epoch: 5| Step: 5
Training loss: 3.515300750732422
Validation loss: 2.543063473957841

Epoch: 5| Step: 6
Training loss: 2.546408176422119
Validation loss: 2.544526425741052

Epoch: 5| Step: 7
Training loss: 3.277676820755005
Validation loss: 2.549187001361642

Epoch: 5| Step: 8
Training loss: 2.499382257461548
Validation loss: 2.5450641544916297

Epoch: 5| Step: 9
Training loss: 2.853541851043701
Validation loss: 2.5275853013479583

Epoch: 5| Step: 10
Training loss: 2.891098976135254
Validation loss: 2.5195243973885812

Epoch: 60| Step: 0
Training loss: 2.663550853729248
Validation loss: 2.5154456246283745

Epoch: 5| Step: 1
Training loss: 2.8173975944519043
Validation loss: 2.5171198434727167

Epoch: 5| Step: 2
Training loss: 2.431530237197876
Validation loss: 2.517535368601481

Epoch: 5| Step: 3
Training loss: 2.87016224861145
Validation loss: 2.513318346392724

Epoch: 5| Step: 4
Training loss: 2.133714199066162
Validation loss: 2.5127266068612375

Epoch: 5| Step: 5
Training loss: 2.227479934692383
Validation loss: 2.511425887384722

Epoch: 5| Step: 6
Training loss: 2.71606183052063
Validation loss: 2.517527113678635

Epoch: 5| Step: 7
Training loss: 2.9746899604797363
Validation loss: 2.5240240455955587

Epoch: 5| Step: 8
Training loss: 3.203174114227295
Validation loss: 2.5250922403027936

Epoch: 5| Step: 9
Training loss: 2.8144619464874268
Validation loss: 2.5273455830030542

Epoch: 5| Step: 10
Training loss: 3.038770914077759
Validation loss: 2.5266814821509906

Epoch: 61| Step: 0
Training loss: 2.6130242347717285
Validation loss: 2.5198507437141995

Epoch: 5| Step: 1
Training loss: 2.367558479309082
Validation loss: 2.5156115331957416

Epoch: 5| Step: 2
Training loss: 2.5577712059020996
Validation loss: 2.516891405146609

Epoch: 5| Step: 3
Training loss: 2.730271100997925
Validation loss: 2.516340345464727

Epoch: 5| Step: 4
Training loss: 2.5838708877563477
Validation loss: 2.516458519043461

Epoch: 5| Step: 5
Training loss: 2.4258296489715576
Validation loss: 2.511507664957354

Epoch: 5| Step: 6
Training loss: 2.5644092559814453
Validation loss: 2.516046511229648

Epoch: 5| Step: 7
Training loss: 2.950007915496826
Validation loss: 2.508447188203053

Epoch: 5| Step: 8
Training loss: 2.6205153465270996
Validation loss: 2.5127174572278093

Epoch: 5| Step: 9
Training loss: 3.2635834217071533
Validation loss: 2.5107540392106578

Epoch: 5| Step: 10
Training loss: 3.0906848907470703
Validation loss: 2.5081722018539265

Epoch: 62| Step: 0
Training loss: 2.463628053665161
Validation loss: 2.5050963406921714

Epoch: 5| Step: 1
Training loss: 2.6855649948120117
Validation loss: 2.5089930744581324

Epoch: 5| Step: 2
Training loss: 2.8693628311157227
Validation loss: 2.5120427185489285

Epoch: 5| Step: 3
Training loss: 3.235881805419922
Validation loss: 2.5193640980669247

Epoch: 5| Step: 4
Training loss: 2.0784382820129395
Validation loss: 2.5106189174036824

Epoch: 5| Step: 5
Training loss: 2.4021999835968018
Validation loss: 2.5104583617179625

Epoch: 5| Step: 6
Training loss: 3.096494197845459
Validation loss: 2.5093404990370556

Epoch: 5| Step: 7
Training loss: 2.5958759784698486
Validation loss: 2.5203703449618433

Epoch: 5| Step: 8
Training loss: 2.8979039192199707
Validation loss: 2.5443960953784246

Epoch: 5| Step: 9
Training loss: 2.990220308303833
Validation loss: 2.549522833157611

Epoch: 5| Step: 10
Training loss: 2.349846839904785
Validation loss: 2.519000061096684

Epoch: 63| Step: 0
Training loss: 2.407742977142334
Validation loss: 2.5198546737752934

Epoch: 5| Step: 1
Training loss: 2.619450330734253
Validation loss: 2.5355683706140004

Epoch: 5| Step: 2
Training loss: 2.4904673099517822
Validation loss: 2.5225983550471645

Epoch: 5| Step: 3
Training loss: 3.1274032592773438
Validation loss: 2.5067978443637973

Epoch: 5| Step: 4
Training loss: 2.4842257499694824
Validation loss: 2.495457490285238

Epoch: 5| Step: 5
Training loss: 2.737502098083496
Validation loss: 2.497678144003755

Epoch: 5| Step: 6
Training loss: 2.2388978004455566
Validation loss: 2.5158386743196877

Epoch: 5| Step: 7
Training loss: 3.566673755645752
Validation loss: 2.5165882443868988

Epoch: 5| Step: 8
Training loss: 3.301058530807495
Validation loss: 2.5167846500232653

Epoch: 5| Step: 9
Training loss: 1.8513771295547485
Validation loss: 2.50931284248188

Epoch: 5| Step: 10
Training loss: 2.9910736083984375
Validation loss: 2.506943948807255

Epoch: 64| Step: 0
Training loss: 2.497258424758911
Validation loss: 2.502402769621982

Epoch: 5| Step: 1
Training loss: 2.7651331424713135
Validation loss: 2.499220645555886

Epoch: 5| Step: 2
Training loss: 2.7599730491638184
Validation loss: 2.501461336689611

Epoch: 5| Step: 3
Training loss: 2.3126559257507324
Validation loss: 2.514411372523154

Epoch: 5| Step: 4
Training loss: 2.7980120182037354
Validation loss: 2.5289330046664

Epoch: 5| Step: 5
Training loss: 3.2320144176483154
Validation loss: 2.528176610187818

Epoch: 5| Step: 6
Training loss: 2.2892813682556152
Validation loss: 2.53870068570619

Epoch: 5| Step: 7
Training loss: 2.3367204666137695
Validation loss: 2.5455224026915846

Epoch: 5| Step: 8
Training loss: 2.4933905601501465
Validation loss: 2.52428162482477

Epoch: 5| Step: 9
Training loss: 3.6514086723327637
Validation loss: 2.50673766802716

Epoch: 5| Step: 10
Training loss: 2.5020833015441895
Validation loss: 2.5075643318955616

Epoch: 65| Step: 0
Training loss: 2.588630199432373
Validation loss: 2.5246658581559376

Epoch: 5| Step: 1
Training loss: 2.884913682937622
Validation loss: 2.538401452443933

Epoch: 5| Step: 2
Training loss: 3.438636064529419
Validation loss: 2.5487020066989365

Epoch: 5| Step: 3
Training loss: 2.4378950595855713
Validation loss: 2.547033361209336

Epoch: 5| Step: 4
Training loss: 3.8348827362060547
Validation loss: 2.529106540064658

Epoch: 5| Step: 5
Training loss: 2.1500754356384277
Validation loss: 2.504363641943983

Epoch: 5| Step: 6
Training loss: 1.7534236907958984
Validation loss: 2.4931177913501696

Epoch: 5| Step: 7
Training loss: 2.366339921951294
Validation loss: 2.490132657430505

Epoch: 5| Step: 8
Training loss: 3.0123238563537598
Validation loss: 2.4840643764823995

Epoch: 5| Step: 9
Training loss: 2.5541303157806396
Validation loss: 2.4940266314373223

Epoch: 5| Step: 10
Training loss: 2.763634204864502
Validation loss: 2.5137307105525846

Epoch: 66| Step: 0
Training loss: 2.5614798069000244
Validation loss: 2.529537534201017

Epoch: 5| Step: 1
Training loss: 2.306623935699463
Validation loss: 2.532944517750894

Epoch: 5| Step: 2
Training loss: 2.6890335083007812
Validation loss: 2.514533737654327

Epoch: 5| Step: 3
Training loss: 3.1524219512939453
Validation loss: 2.4948608260000906

Epoch: 5| Step: 4
Training loss: 2.628720760345459
Validation loss: 2.482489670476606

Epoch: 5| Step: 5
Training loss: 2.888343572616577
Validation loss: 2.479346893166983

Epoch: 5| Step: 6
Training loss: 3.2371602058410645
Validation loss: 2.4820740966386694

Epoch: 5| Step: 7
Training loss: 2.5210766792297363
Validation loss: 2.4992636685730307

Epoch: 5| Step: 8
Training loss: 2.6539132595062256
Validation loss: 2.5122222874754216

Epoch: 5| Step: 9
Training loss: 2.107626438140869
Validation loss: 2.5140812371366765

Epoch: 5| Step: 10
Training loss: 2.9774281978607178
Validation loss: 2.5106006027549825

Epoch: 67| Step: 0
Training loss: 2.9033615589141846
Validation loss: 2.493642145587552

Epoch: 5| Step: 1
Training loss: 2.6741702556610107
Validation loss: 2.4787841843020533

Epoch: 5| Step: 2
Training loss: 2.857158660888672
Validation loss: 2.4712015813396824

Epoch: 5| Step: 3
Training loss: 2.6162233352661133
Validation loss: 2.4732125138723724

Epoch: 5| Step: 4
Training loss: 3.061988353729248
Validation loss: 2.48419859076059

Epoch: 5| Step: 5
Training loss: 2.500129222869873
Validation loss: 2.492432109771236

Epoch: 5| Step: 6
Training loss: 2.5804286003112793
Validation loss: 2.503708090833438

Epoch: 5| Step: 7
Training loss: 2.461646318435669
Validation loss: 2.5033013102828816

Epoch: 5| Step: 8
Training loss: 2.0772924423217773
Validation loss: 2.5003150329794934

Epoch: 5| Step: 9
Training loss: 3.0751070976257324
Validation loss: 2.5008938056166454

Epoch: 5| Step: 10
Training loss: 2.931065797805786
Validation loss: 2.495034597253287

Epoch: 68| Step: 0
Training loss: 2.1366829872131348
Validation loss: 2.487808891521987

Epoch: 5| Step: 1
Training loss: 2.7881836891174316
Validation loss: 2.4802076688376804

Epoch: 5| Step: 2
Training loss: 2.216324806213379
Validation loss: 2.472683746327636

Epoch: 5| Step: 3
Training loss: 2.8170034885406494
Validation loss: 2.4699013874094975

Epoch: 5| Step: 4
Training loss: 3.515394926071167
Validation loss: 2.4699696494686987

Epoch: 5| Step: 5
Training loss: 2.7565042972564697
Validation loss: 2.4800143818701468

Epoch: 5| Step: 6
Training loss: 2.5830516815185547
Validation loss: 2.490009482188891

Epoch: 5| Step: 7
Training loss: 2.4855682849884033
Validation loss: 2.4976214952366327

Epoch: 5| Step: 8
Training loss: 3.348724365234375
Validation loss: 2.4944491386413574

Epoch: 5| Step: 9
Training loss: 2.2670109272003174
Validation loss: 2.483868255410143

Epoch: 5| Step: 10
Training loss: 2.6210529804229736
Validation loss: 2.477289976612214

Epoch: 69| Step: 0
Training loss: 2.6470682621002197
Validation loss: 2.471041146145072

Epoch: 5| Step: 1
Training loss: 2.045025587081909
Validation loss: 2.469817555078896

Epoch: 5| Step: 2
Training loss: 3.000082015991211
Validation loss: 2.513342626633183

Epoch: 5| Step: 3
Training loss: 2.82140851020813
Validation loss: 2.5611374737114034

Epoch: 5| Step: 4
Training loss: 2.889498710632324
Validation loss: 2.560965707225184

Epoch: 5| Step: 5
Training loss: 3.474295139312744
Validation loss: 2.5016577089986494

Epoch: 5| Step: 6
Training loss: 2.4361767768859863
Validation loss: 2.48142675686908

Epoch: 5| Step: 7
Training loss: 2.7635703086853027
Validation loss: 2.4660032692775933

Epoch: 5| Step: 8
Training loss: 1.893811821937561
Validation loss: 2.4699299745662238

Epoch: 5| Step: 9
Training loss: 2.5795111656188965
Validation loss: 2.4832513614367415

Epoch: 5| Step: 10
Training loss: 3.3007094860076904
Validation loss: 2.5139603999353226

Epoch: 70| Step: 0
Training loss: 2.6186420917510986
Validation loss: 2.507399623112012

Epoch: 5| Step: 1
Training loss: 2.379387378692627
Validation loss: 2.4935769291334253

Epoch: 5| Step: 2
Training loss: 2.708172559738159
Validation loss: 2.478129320247199

Epoch: 5| Step: 3
Training loss: 2.7360239028930664
Validation loss: 2.4625066775147633

Epoch: 5| Step: 4
Training loss: 2.4278106689453125
Validation loss: 2.466063750687466

Epoch: 5| Step: 5
Training loss: 2.8507885932922363
Validation loss: 2.463998709955523

Epoch: 5| Step: 6
Training loss: 2.5321850776672363
Validation loss: 2.46134881050356

Epoch: 5| Step: 7
Training loss: 2.5341076850891113
Validation loss: 2.4619315670382593

Epoch: 5| Step: 8
Training loss: 2.880481004714966
Validation loss: 2.459999510037002

Epoch: 5| Step: 9
Training loss: 3.06120228767395
Validation loss: 2.462075195004863

Epoch: 5| Step: 10
Training loss: 2.7694711685180664
Validation loss: 2.4603503904035016

Epoch: 71| Step: 0
Training loss: 2.1023640632629395
Validation loss: 2.4563381389905046

Epoch: 5| Step: 1
Training loss: 2.694068431854248
Validation loss: 2.4623954757567375

Epoch: 5| Step: 2
Training loss: 2.673468828201294
Validation loss: 2.464393554195281

Epoch: 5| Step: 3
Training loss: 2.9936647415161133
Validation loss: 2.4697448950941845

Epoch: 5| Step: 4
Training loss: 2.6577157974243164
Validation loss: 2.4724534403893257

Epoch: 5| Step: 5
Training loss: 2.918827772140503
Validation loss: 2.476967589829558

Epoch: 5| Step: 6
Training loss: 2.6063075065612793
Validation loss: 2.47359472961836

Epoch: 5| Step: 7
Training loss: 2.899205446243286
Validation loss: 2.4740850694717897

Epoch: 5| Step: 8
Training loss: 2.120448589324951
Validation loss: 2.4803872005913847

Epoch: 5| Step: 9
Training loss: 2.465888500213623
Validation loss: 2.45836946528445

Epoch: 5| Step: 10
Training loss: 3.387192726135254
Validation loss: 2.4482008795584402

Epoch: 72| Step: 0
Training loss: 2.7727725505828857
Validation loss: 2.447641190662179

Epoch: 5| Step: 1
Training loss: 3.0578174591064453
Validation loss: 2.4478942860839186

Epoch: 5| Step: 2
Training loss: 2.369046688079834
Validation loss: 2.448825615708546

Epoch: 5| Step: 3
Training loss: 2.7374987602233887
Validation loss: 2.451021058585054

Epoch: 5| Step: 4
Training loss: 3.1045327186584473
Validation loss: 2.4538167112617084

Epoch: 5| Step: 5
Training loss: 2.446887493133545
Validation loss: 2.4528786507985925

Epoch: 5| Step: 6
Training loss: 2.5960745811462402
Validation loss: 2.4516659193141486

Epoch: 5| Step: 7
Training loss: 2.710745334625244
Validation loss: 2.4531455475796937

Epoch: 5| Step: 8
Training loss: 2.8367106914520264
Validation loss: 2.4521217525646253

Epoch: 5| Step: 9
Training loss: 2.3545312881469727
Validation loss: 2.4505317493151595

Epoch: 5| Step: 10
Training loss: 2.4912755489349365
Validation loss: 2.4442525935429398

Epoch: 73| Step: 0
Training loss: 2.659696578979492
Validation loss: 2.4434539259120984

Epoch: 5| Step: 1
Training loss: 2.7177329063415527
Validation loss: 2.4421647876821537

Epoch: 5| Step: 2
Training loss: 2.311828136444092
Validation loss: 2.445895605189826

Epoch: 5| Step: 3
Training loss: 2.9372916221618652
Validation loss: 2.45356781764697

Epoch: 5| Step: 4
Training loss: 2.861604690551758
Validation loss: 2.4686122991705455

Epoch: 5| Step: 5
Training loss: 2.6274800300598145
Validation loss: 2.468896645371632

Epoch: 5| Step: 6
Training loss: 3.159379482269287
Validation loss: 2.4655743824538363

Epoch: 5| Step: 7
Training loss: 2.7202200889587402
Validation loss: 2.467626743419196

Epoch: 5| Step: 8
Training loss: 2.7248470783233643
Validation loss: 2.475044975998581

Epoch: 5| Step: 9
Training loss: 2.320025682449341
Validation loss: 2.472488590466079

Epoch: 5| Step: 10
Training loss: 2.2155513763427734
Validation loss: 2.4692694705019713

Epoch: 74| Step: 0
Training loss: 2.6929097175598145
Validation loss: 2.457163305692775

Epoch: 5| Step: 1
Training loss: 2.404994249343872
Validation loss: 2.4496210082884757

Epoch: 5| Step: 2
Training loss: 2.2223215103149414
Validation loss: 2.44330572184696

Epoch: 5| Step: 3
Training loss: 3.2798728942871094
Validation loss: 2.4349216517581733

Epoch: 5| Step: 4
Training loss: 3.0034523010253906
Validation loss: 2.435672470318374

Epoch: 5| Step: 5
Training loss: 3.342608690261841
Validation loss: 2.4399609796462522

Epoch: 5| Step: 6
Training loss: 2.663285732269287
Validation loss: 2.4432394402001494

Epoch: 5| Step: 7
Training loss: 2.415883779525757
Validation loss: 2.448348924677859

Epoch: 5| Step: 8
Training loss: 2.544281244277954
Validation loss: 2.4556726050633255

Epoch: 5| Step: 9
Training loss: 2.0302188396453857
Validation loss: 2.448650760035361

Epoch: 5| Step: 10
Training loss: 2.873070001602173
Validation loss: 2.4422490212225143

Epoch: 75| Step: 0
Training loss: 2.334521770477295
Validation loss: 2.436932163853799

Epoch: 5| Step: 1
Training loss: 2.703885555267334
Validation loss: 2.4321972426547798

Epoch: 5| Step: 2
Training loss: 2.524442195892334
Validation loss: 2.435928298581031

Epoch: 5| Step: 3
Training loss: 2.6598432064056396
Validation loss: 2.467821418598134

Epoch: 5| Step: 4
Training loss: 2.9369940757751465
Validation loss: 2.520234328444286

Epoch: 5| Step: 5
Training loss: 2.7502248287200928
Validation loss: 2.5252918889445644

Epoch: 5| Step: 6
Training loss: 3.2442519664764404
Validation loss: 2.4901346545065604

Epoch: 5| Step: 7
Training loss: 2.0839619636535645
Validation loss: 2.4638733581830095

Epoch: 5| Step: 8
Training loss: 2.8389194011688232
Validation loss: 2.4395640870576263

Epoch: 5| Step: 9
Training loss: 2.930516004562378
Validation loss: 2.4322497165331276

Epoch: 5| Step: 10
Training loss: 2.5363967418670654
Validation loss: 2.4320467031130226

Epoch: 76| Step: 0
Training loss: 2.6835906505584717
Validation loss: 2.43475309495003

Epoch: 5| Step: 1
Training loss: 2.4780592918395996
Validation loss: 2.4357097430895736

Epoch: 5| Step: 2
Training loss: 2.7132863998413086
Validation loss: 2.439854444996003

Epoch: 5| Step: 3
Training loss: 2.1210715770721436
Validation loss: 2.4486186735091673

Epoch: 5| Step: 4
Training loss: 2.6700170040130615
Validation loss: 2.451978001543271

Epoch: 5| Step: 5
Training loss: 2.669593334197998
Validation loss: 2.4642475471701673

Epoch: 5| Step: 6
Training loss: 3.325798749923706
Validation loss: 2.4513723875886653

Epoch: 5| Step: 7
Training loss: 2.2164082527160645
Validation loss: 2.451021191894367

Epoch: 5| Step: 8
Training loss: 2.6105024814605713
Validation loss: 2.4448611300478698

Epoch: 5| Step: 9
Training loss: 2.7822630405426025
Validation loss: 2.438376562569731

Epoch: 5| Step: 10
Training loss: 3.2698025703430176
Validation loss: 2.4337751275749615

Epoch: 77| Step: 0
Training loss: 1.8437011241912842
Validation loss: 2.435685352612567

Epoch: 5| Step: 1
Training loss: 2.5563735961914062
Validation loss: 2.4431324056399766

Epoch: 5| Step: 2
Training loss: 2.3537564277648926
Validation loss: 2.463131081673407

Epoch: 5| Step: 3
Training loss: 2.5835018157958984
Validation loss: 2.478426907652168

Epoch: 5| Step: 4
Training loss: 2.953432083129883
Validation loss: 2.4964865997273433

Epoch: 5| Step: 5
Training loss: 2.665668487548828
Validation loss: 2.4954622894205074

Epoch: 5| Step: 6
Training loss: 2.566535472869873
Validation loss: 2.4949595518009637

Epoch: 5| Step: 7
Training loss: 3.6717476844787598
Validation loss: 2.4830723885566957

Epoch: 5| Step: 8
Training loss: 2.7254302501678467
Validation loss: 2.459951895539479

Epoch: 5| Step: 9
Training loss: 2.955595016479492
Validation loss: 2.448035470900997

Epoch: 5| Step: 10
Training loss: 2.505138635635376
Validation loss: 2.4346249308637393

Epoch: 78| Step: 0
Training loss: 2.1805996894836426
Validation loss: 2.4280321059688443

Epoch: 5| Step: 1
Training loss: 2.496619462966919
Validation loss: 2.428633619380254

Epoch: 5| Step: 2
Training loss: 2.83473539352417
Validation loss: 2.4250325054250736

Epoch: 5| Step: 3
Training loss: 2.5744404792785645
Validation loss: 2.4267785292799755

Epoch: 5| Step: 4
Training loss: 2.570517063140869
Validation loss: 2.4337712103320706

Epoch: 5| Step: 5
Training loss: 1.928053617477417
Validation loss: 2.4386128251270582

Epoch: 5| Step: 6
Training loss: 3.317901134490967
Validation loss: 2.4490491292809926

Epoch: 5| Step: 7
Training loss: 2.3112082481384277
Validation loss: 2.436589241027832

Epoch: 5| Step: 8
Training loss: 2.996901035308838
Validation loss: 2.4405437566900767

Epoch: 5| Step: 9
Training loss: 2.8915176391601562
Validation loss: 2.4328149339204193

Epoch: 5| Step: 10
Training loss: 3.211636781692505
Validation loss: 2.4313957255373717

Epoch: 79| Step: 0
Training loss: 3.0075058937072754
Validation loss: 2.421449879164337

Epoch: 5| Step: 1
Training loss: 2.9347076416015625
Validation loss: 2.413039397167903

Epoch: 5| Step: 2
Training loss: 2.954850673675537
Validation loss: 2.4148433798102924

Epoch: 5| Step: 3
Training loss: 2.2125542163848877
Validation loss: 2.4168026908751457

Epoch: 5| Step: 4
Training loss: 2.148002862930298
Validation loss: 2.4146403394719607

Epoch: 5| Step: 5
Training loss: 3.1598165035247803
Validation loss: 2.4140020237174085

Epoch: 5| Step: 6
Training loss: 2.6489388942718506
Validation loss: 2.4131017090171896

Epoch: 5| Step: 7
Training loss: 2.105897903442383
Validation loss: 2.4125813514955583

Epoch: 5| Step: 8
Training loss: 2.848670244216919
Validation loss: 2.4209547555574806

Epoch: 5| Step: 9
Training loss: 2.3921422958374023
Validation loss: 2.4246719139878468

Epoch: 5| Step: 10
Training loss: 2.8089191913604736
Validation loss: 2.4130668383772655

Epoch: 80| Step: 0
Training loss: 2.7730965614318848
Validation loss: 2.4099295549495245

Epoch: 5| Step: 1
Training loss: 2.9229462146759033
Validation loss: 2.407454462461574

Epoch: 5| Step: 2
Training loss: 2.663741111755371
Validation loss: 2.4090378463909192

Epoch: 5| Step: 3
Training loss: 3.0686001777648926
Validation loss: 2.4058426990303943

Epoch: 5| Step: 4
Training loss: 2.7261624336242676
Validation loss: 2.407450404218448

Epoch: 5| Step: 5
Training loss: 2.641723155975342
Validation loss: 2.408607711074173

Epoch: 5| Step: 6
Training loss: 2.330029249191284
Validation loss: 2.4134353771004626

Epoch: 5| Step: 7
Training loss: 2.534327745437622
Validation loss: 2.4107040564219155

Epoch: 5| Step: 8
Training loss: 2.245288372039795
Validation loss: 2.409273934620683

Epoch: 5| Step: 9
Training loss: 2.631155490875244
Validation loss: 2.412145194186959

Epoch: 5| Step: 10
Training loss: 2.609403610229492
Validation loss: 2.415027441516999

Epoch: 81| Step: 0
Training loss: 2.615292549133301
Validation loss: 2.412152398017145

Epoch: 5| Step: 1
Training loss: 1.7021602392196655
Validation loss: 2.4052988252332135

Epoch: 5| Step: 2
Training loss: 2.528627872467041
Validation loss: 2.4052106770136024

Epoch: 5| Step: 3
Training loss: 2.5478978157043457
Validation loss: 2.407083926662322

Epoch: 5| Step: 4
Training loss: 2.568730354309082
Validation loss: 2.4063714499114663

Epoch: 5| Step: 5
Training loss: 3.0300512313842773
Validation loss: 2.405552871765629

Epoch: 5| Step: 6
Training loss: 2.9968833923339844
Validation loss: 2.403578876167215

Epoch: 5| Step: 7
Training loss: 2.625072717666626
Validation loss: 2.402138597221785

Epoch: 5| Step: 8
Training loss: 2.9152603149414062
Validation loss: 2.4066349383323424

Epoch: 5| Step: 9
Training loss: 2.512653350830078
Validation loss: 2.411513646443685

Epoch: 5| Step: 10
Training loss: 3.1151208877563477
Validation loss: 2.4172725241671325

Epoch: 82| Step: 0
Training loss: 2.1615922451019287
Validation loss: 2.4163851994340138

Epoch: 5| Step: 1
Training loss: 3.162003755569458
Validation loss: 2.421175919553285

Epoch: 5| Step: 2
Training loss: 2.2916722297668457
Validation loss: 2.417944985051309

Epoch: 5| Step: 3
Training loss: 2.3129687309265137
Validation loss: 2.418319458602577

Epoch: 5| Step: 4
Training loss: 2.078522205352783
Validation loss: 2.4249649945125786

Epoch: 5| Step: 5
Training loss: 2.0457324981689453
Validation loss: 2.431441678795763

Epoch: 5| Step: 6
Training loss: 2.9370968341827393
Validation loss: 2.438987995988579

Epoch: 5| Step: 7
Training loss: 3.133394718170166
Validation loss: 2.4479216965295936

Epoch: 5| Step: 8
Training loss: 3.2337775230407715
Validation loss: 2.4250289829828406

Epoch: 5| Step: 9
Training loss: 2.563396692276001
Validation loss: 2.407521919537616

Epoch: 5| Step: 10
Training loss: 3.2092576026916504
Validation loss: 2.4107239759096535

Epoch: 83| Step: 0
Training loss: 2.5308964252471924
Validation loss: 2.4119318582678355

Epoch: 5| Step: 1
Training loss: 2.9856770038604736
Validation loss: 2.4132708682808826

Epoch: 5| Step: 2
Training loss: 2.403587818145752
Validation loss: 2.4128850326743176

Epoch: 5| Step: 3
Training loss: 2.7656679153442383
Validation loss: 2.425844156613914

Epoch: 5| Step: 4
Training loss: 2.7012104988098145
Validation loss: 2.4217892821117113

Epoch: 5| Step: 5
Training loss: 2.523200511932373
Validation loss: 2.417532241472634

Epoch: 5| Step: 6
Training loss: 2.582523822784424
Validation loss: 2.4138086508679133

Epoch: 5| Step: 7
Training loss: 2.753387451171875
Validation loss: 2.409012172811775

Epoch: 5| Step: 8
Training loss: 2.9107823371887207
Validation loss: 2.3982381564314648

Epoch: 5| Step: 9
Training loss: 2.6081345081329346
Validation loss: 2.387846052005727

Epoch: 5| Step: 10
Training loss: 2.3831570148468018
Validation loss: 2.3903731633258123

Epoch: 84| Step: 0
Training loss: 2.9476752281188965
Validation loss: 2.394133747264903

Epoch: 5| Step: 1
Training loss: 2.447727918624878
Validation loss: 2.3951697477730374

Epoch: 5| Step: 2
Training loss: 2.110255479812622
Validation loss: 2.3988215795127292

Epoch: 5| Step: 3
Training loss: 2.5969200134277344
Validation loss: 2.4084753810718493

Epoch: 5| Step: 4
Training loss: 2.4755806922912598
Validation loss: 2.4031866340227026

Epoch: 5| Step: 5
Training loss: 2.8539397716522217
Validation loss: 2.397767274610458

Epoch: 5| Step: 6
Training loss: 2.005326747894287
Validation loss: 2.3891093218198387

Epoch: 5| Step: 7
Training loss: 2.1752727031707764
Validation loss: 2.3885637560198383

Epoch: 5| Step: 8
Training loss: 2.755725860595703
Validation loss: 2.3842526456361175

Epoch: 5| Step: 9
Training loss: 3.6869194507598877
Validation loss: 2.3854954781070834

Epoch: 5| Step: 10
Training loss: 3.019536256790161
Validation loss: 2.387736251277308

Epoch: 85| Step: 0
Training loss: 2.6385488510131836
Validation loss: 2.383940624934371

Epoch: 5| Step: 1
Training loss: 2.771577835083008
Validation loss: 2.387712114600725

Epoch: 5| Step: 2
Training loss: 2.1645748615264893
Validation loss: 2.3872660872756795

Epoch: 5| Step: 3
Training loss: 2.3581080436706543
Validation loss: 2.392469906037854

Epoch: 5| Step: 4
Training loss: 2.8136348724365234
Validation loss: 2.394094136453444

Epoch: 5| Step: 5
Training loss: 2.7869632244110107
Validation loss: 2.410744728580598

Epoch: 5| Step: 6
Training loss: 2.3090310096740723
Validation loss: 2.4337835773344962

Epoch: 5| Step: 7
Training loss: 2.377392530441284
Validation loss: 2.4484956931042414

Epoch: 5| Step: 8
Training loss: 3.493483066558838
Validation loss: 2.443288572372929

Epoch: 5| Step: 9
Training loss: 2.891068935394287
Validation loss: 2.407401596346209

Epoch: 5| Step: 10
Training loss: 2.3555307388305664
Validation loss: 2.3938337115831274

Epoch: 86| Step: 0
Training loss: 2.9275710582733154
Validation loss: 2.3866594491466397

Epoch: 5| Step: 1
Training loss: 3.022963285446167
Validation loss: 2.376345455005605

Epoch: 5| Step: 2
Training loss: 1.9473240375518799
Validation loss: 2.3765814663261495

Epoch: 5| Step: 3
Training loss: 2.8170716762542725
Validation loss: 2.3791842178631852

Epoch: 5| Step: 4
Training loss: 2.7625679969787598
Validation loss: 2.3848566598789667

Epoch: 5| Step: 5
Training loss: 2.4943976402282715
Validation loss: 2.3845277268399476

Epoch: 5| Step: 6
Training loss: 2.923816680908203
Validation loss: 2.382476815613367

Epoch: 5| Step: 7
Training loss: 2.8736140727996826
Validation loss: 2.3879005883329656

Epoch: 5| Step: 8
Training loss: 2.3179256916046143
Validation loss: 2.3998994211996756

Epoch: 5| Step: 9
Training loss: 2.3617045879364014
Validation loss: 2.4042295845605994

Epoch: 5| Step: 10
Training loss: 2.466299533843994
Validation loss: 2.3955620155539563

Epoch: 87| Step: 0
Training loss: 2.369558811187744
Validation loss: 2.3896460353687243

Epoch: 5| Step: 1
Training loss: 2.8155112266540527
Validation loss: 2.390572755567489

Epoch: 5| Step: 2
Training loss: 2.59987473487854
Validation loss: 2.404974681074901

Epoch: 5| Step: 3
Training loss: 2.5593483448028564
Validation loss: 2.4123433712990052

Epoch: 5| Step: 4
Training loss: 2.2848289012908936
Validation loss: 2.415293421796573

Epoch: 5| Step: 5
Training loss: 3.1008362770080566
Validation loss: 2.4284303239596787

Epoch: 5| Step: 6
Training loss: 2.6131062507629395
Validation loss: 2.427646529289984

Epoch: 5| Step: 7
Training loss: 2.731682300567627
Validation loss: 2.409389316394765

Epoch: 5| Step: 8
Training loss: 1.9716424942016602
Validation loss: 2.3976700613575597

Epoch: 5| Step: 9
Training loss: 2.9916796684265137
Validation loss: 2.3874433553347023

Epoch: 5| Step: 10
Training loss: 2.867539167404175
Validation loss: 2.380011717478434

Epoch: 88| Step: 0
Training loss: 2.536029100418091
Validation loss: 2.3716663570814234

Epoch: 5| Step: 1
Training loss: 2.5571835041046143
Validation loss: 2.3707908686771186

Epoch: 5| Step: 2
Training loss: 3.016674757003784
Validation loss: 2.363853657117454

Epoch: 5| Step: 3
Training loss: 2.3511288166046143
Validation loss: 2.3673066221257693

Epoch: 5| Step: 4
Training loss: 2.956723213195801
Validation loss: 2.374807982034581

Epoch: 5| Step: 5
Training loss: 2.4832725524902344
Validation loss: 2.3839741496629614

Epoch: 5| Step: 6
Training loss: 2.478972911834717
Validation loss: 2.375246663247385

Epoch: 5| Step: 7
Training loss: 2.4700756072998047
Validation loss: 2.365822733089488

Epoch: 5| Step: 8
Training loss: 2.9840378761291504
Validation loss: 2.3622524046128794

Epoch: 5| Step: 9
Training loss: 2.6234161853790283
Validation loss: 2.3571450812842256

Epoch: 5| Step: 10
Training loss: 2.5050418376922607
Validation loss: 2.361859375430692

Epoch: 89| Step: 0
Training loss: 3.0305986404418945
Validation loss: 2.371134183740103

Epoch: 5| Step: 1
Training loss: 2.855093002319336
Validation loss: 2.3694764465414067

Epoch: 5| Step: 2
Training loss: 2.3438401222229004
Validation loss: 2.3768038544603574

Epoch: 5| Step: 3
Training loss: 2.4199752807617188
Validation loss: 2.392702318006946

Epoch: 5| Step: 4
Training loss: 2.2209153175354004
Validation loss: 2.3980691304770847

Epoch: 5| Step: 5
Training loss: 2.8292040824890137
Validation loss: 2.4226598995988087

Epoch: 5| Step: 6
Training loss: 2.5414671897888184
Validation loss: 2.429962883713425

Epoch: 5| Step: 7
Training loss: 2.540684223175049
Validation loss: 2.419799183004646

Epoch: 5| Step: 8
Training loss: 2.330798864364624
Validation loss: 2.3948437167752172

Epoch: 5| Step: 9
Training loss: 2.7755355834960938
Validation loss: 2.376041334162476

Epoch: 5| Step: 10
Training loss: 3.0112078189849854
Validation loss: 2.3689866065979004

Epoch: 90| Step: 0
Training loss: 3.03825044631958
Validation loss: 2.362392379391578

Epoch: 5| Step: 1
Training loss: 3.453953981399536
Validation loss: 2.3589162980356524

Epoch: 5| Step: 2
Training loss: 1.7502456903457642
Validation loss: 2.3561278722619496

Epoch: 5| Step: 3
Training loss: 2.825885772705078
Validation loss: 2.3543880549810265

Epoch: 5| Step: 4
Training loss: 2.197061061859131
Validation loss: 2.362053358426658

Epoch: 5| Step: 5
Training loss: 2.231096029281616
Validation loss: 2.3633609484600764

Epoch: 5| Step: 6
Training loss: 2.7221813201904297
Validation loss: 2.365970698736047

Epoch: 5| Step: 7
Training loss: 2.09478497505188
Validation loss: 2.365725299363495

Epoch: 5| Step: 8
Training loss: 3.064178466796875
Validation loss: 2.3724950718623337

Epoch: 5| Step: 9
Training loss: 2.4242584705352783
Validation loss: 2.3732951405227825

Epoch: 5| Step: 10
Training loss: 3.0046491622924805
Validation loss: 2.374476586618731

Epoch: 91| Step: 0
Training loss: 2.682392120361328
Validation loss: 2.3841120914746354

Epoch: 5| Step: 1
Training loss: 2.616668224334717
Validation loss: 2.3858446100706696

Epoch: 5| Step: 2
Training loss: 2.176241874694824
Validation loss: 2.402171593840404

Epoch: 5| Step: 3
Training loss: 3.7411694526672363
Validation loss: 2.396673640897197

Epoch: 5| Step: 4
Training loss: 2.718640089035034
Validation loss: 2.39475070276568

Epoch: 5| Step: 5
Training loss: 2.6338140964508057
Validation loss: 2.3900316992113666

Epoch: 5| Step: 6
Training loss: 2.631356716156006
Validation loss: 2.392552242484144

Epoch: 5| Step: 7
Training loss: 2.492429256439209
Validation loss: 2.398199540312572

Epoch: 5| Step: 8
Training loss: 2.1474881172180176
Validation loss: 2.400803255778487

Epoch: 5| Step: 9
Training loss: 2.6018126010894775
Validation loss: 2.44504052336498

Epoch: 5| Step: 10
Training loss: 2.228151321411133
Validation loss: 2.467851156829506

Epoch: 92| Step: 0
Training loss: 2.2243380546569824
Validation loss: 2.4598185990446355

Epoch: 5| Step: 1
Training loss: 1.9394725561141968
Validation loss: 2.4596409707941036

Epoch: 5| Step: 2
Training loss: 3.025658130645752
Validation loss: 2.4647768338521323

Epoch: 5| Step: 3
Training loss: 3.286233425140381
Validation loss: 2.4179438211584605

Epoch: 5| Step: 4
Training loss: 2.963919162750244
Validation loss: 2.3627692832741687

Epoch: 5| Step: 5
Training loss: 2.0353941917419434
Validation loss: 2.349087930494739

Epoch: 5| Step: 6
Training loss: 2.9775986671447754
Validation loss: 2.34839371455613

Epoch: 5| Step: 7
Training loss: 2.8409504890441895
Validation loss: 2.353043443413191

Epoch: 5| Step: 8
Training loss: 3.120535373687744
Validation loss: 2.360806054966424

Epoch: 5| Step: 9
Training loss: 1.7274153232574463
Validation loss: 2.3639584997648835

Epoch: 5| Step: 10
Training loss: 2.7434237003326416
Validation loss: 2.3804678250384588

Epoch: 93| Step: 0
Training loss: 2.8438351154327393
Validation loss: 2.3879510689807195

Epoch: 5| Step: 1
Training loss: 3.41340708732605
Validation loss: 2.3957348228782736

Epoch: 5| Step: 2
Training loss: 2.5799245834350586
Validation loss: 2.4048967335813787

Epoch: 5| Step: 3
Training loss: 2.6745591163635254
Validation loss: 2.4183136340110534

Epoch: 5| Step: 4
Training loss: 1.844175934791565
Validation loss: 2.4098287987452682

Epoch: 5| Step: 5
Training loss: 2.6860032081604004
Validation loss: 2.3752655393333844

Epoch: 5| Step: 6
Training loss: 2.0844902992248535
Validation loss: 2.359737926913846

Epoch: 5| Step: 7
Training loss: 2.758610963821411
Validation loss: 2.3462106643184537

Epoch: 5| Step: 8
Training loss: 2.310258626937866
Validation loss: 2.3391652440512054

Epoch: 5| Step: 9
Training loss: 2.4057865142822266
Validation loss: 2.3399505256324686

Epoch: 5| Step: 10
Training loss: 3.1992411613464355
Validation loss: 2.3395757905898558

Epoch: 94| Step: 0
Training loss: 3.0270705223083496
Validation loss: 2.341543528341478

Epoch: 5| Step: 1
Training loss: 2.2656378746032715
Validation loss: 2.340318283727092

Epoch: 5| Step: 2
Training loss: 2.265223741531372
Validation loss: 2.347854730903461

Epoch: 5| Step: 3
Training loss: 3.012096881866455
Validation loss: 2.344984059692711

Epoch: 5| Step: 4
Training loss: 2.1844918727874756
Validation loss: 2.354125743271202

Epoch: 5| Step: 5
Training loss: 2.8339669704437256
Validation loss: 2.3574263562438307

Epoch: 5| Step: 6
Training loss: 2.7147977352142334
Validation loss: 2.3632799938160884

Epoch: 5| Step: 7
Training loss: 2.5426440238952637
Validation loss: 2.359332858875234

Epoch: 5| Step: 8
Training loss: 2.543552875518799
Validation loss: 2.3534615937099663

Epoch: 5| Step: 9
Training loss: 2.430358409881592
Validation loss: 2.3535466322334866

Epoch: 5| Step: 10
Training loss: 2.779937267303467
Validation loss: 2.3673307024022585

Epoch: 95| Step: 0
Training loss: 1.777385950088501
Validation loss: 2.369333367193899

Epoch: 5| Step: 1
Training loss: 2.935917615890503
Validation loss: 2.3833998557059997

Epoch: 5| Step: 2
Training loss: 2.7692062854766846
Validation loss: 2.387299919641146

Epoch: 5| Step: 3
Training loss: 2.722473382949829
Validation loss: 2.3862173916191183

Epoch: 5| Step: 4
Training loss: 2.90459942817688
Validation loss: 2.389430753646358

Epoch: 5| Step: 5
Training loss: 2.1574718952178955
Validation loss: 2.3580598138993785

Epoch: 5| Step: 6
Training loss: 2.894711971282959
Validation loss: 2.347146752060101

Epoch: 5| Step: 7
Training loss: 3.197207450866699
Validation loss: 2.3363744546008367

Epoch: 5| Step: 8
Training loss: 2.479001522064209
Validation loss: 2.3484551137493503

Epoch: 5| Step: 9
Training loss: 2.6134185791015625
Validation loss: 2.3479629191019202

Epoch: 5| Step: 10
Training loss: 2.371020555496216
Validation loss: 2.348246077055572

Epoch: 96| Step: 0
Training loss: 2.9515068531036377
Validation loss: 2.3424593197402133

Epoch: 5| Step: 1
Training loss: 2.8449645042419434
Validation loss: 2.341734722096433

Epoch: 5| Step: 2
Training loss: 2.4875526428222656
Validation loss: 2.3387199678728656

Epoch: 5| Step: 3
Training loss: 2.638032913208008
Validation loss: 2.340773928549982

Epoch: 5| Step: 4
Training loss: 2.3999476432800293
Validation loss: 2.335397329381717

Epoch: 5| Step: 5
Training loss: 2.6085939407348633
Validation loss: 2.339834684966713

Epoch: 5| Step: 6
Training loss: 2.0907630920410156
Validation loss: 2.3496153200826337

Epoch: 5| Step: 7
Training loss: 2.7879536151885986
Validation loss: 2.3369329924224527

Epoch: 5| Step: 8
Training loss: 2.4642772674560547
Validation loss: 2.333386477603707

Epoch: 5| Step: 9
Training loss: 2.3700990676879883
Validation loss: 2.328039974294683

Epoch: 5| Step: 10
Training loss: 2.9484331607818604
Validation loss: 2.3253717191757692

Epoch: 97| Step: 0
Training loss: 1.9954137802124023
Validation loss: 2.3287757545389156

Epoch: 5| Step: 1
Training loss: 2.280073881149292
Validation loss: 2.329495219774144

Epoch: 5| Step: 2
Training loss: 2.467087745666504
Validation loss: 2.3340627711306334

Epoch: 5| Step: 3
Training loss: 2.4654481410980225
Validation loss: 2.3385323747511833

Epoch: 5| Step: 4
Training loss: 2.834766149520874
Validation loss: 2.3484383654850784

Epoch: 5| Step: 5
Training loss: 3.087899684906006
Validation loss: 2.360566269966864

Epoch: 5| Step: 6
Training loss: 3.2776482105255127
Validation loss: 2.3607518057669363

Epoch: 5| Step: 7
Training loss: 2.865917682647705
Validation loss: 2.358523181689683

Epoch: 5| Step: 8
Training loss: 2.1009349822998047
Validation loss: 2.3457597532579975

Epoch: 5| Step: 9
Training loss: 2.508939743041992
Validation loss: 2.3423729353053595

Epoch: 5| Step: 10
Training loss: 2.6114542484283447
Validation loss: 2.332938891585155

Epoch: 98| Step: 0
Training loss: 2.725476026535034
Validation loss: 2.337106502184304

Epoch: 5| Step: 1
Training loss: 2.3049895763397217
Validation loss: 2.335488816743256

Epoch: 5| Step: 2
Training loss: 2.650620937347412
Validation loss: 2.3452041841322377

Epoch: 5| Step: 3
Training loss: 2.7144904136657715
Validation loss: 2.369263287513487

Epoch: 5| Step: 4
Training loss: 3.006588935852051
Validation loss: 2.3930172253680486

Epoch: 5| Step: 5
Training loss: 2.549001455307007
Validation loss: 2.4042253263535036

Epoch: 5| Step: 6
Training loss: 3.0135865211486816
Validation loss: 2.3792294840658865

Epoch: 5| Step: 7
Training loss: 2.1222147941589355
Validation loss: 2.3456073114948888

Epoch: 5| Step: 8
Training loss: 2.079312562942505
Validation loss: 2.336372701070642

Epoch: 5| Step: 9
Training loss: 2.482316493988037
Validation loss: 2.338738951631772

Epoch: 5| Step: 10
Training loss: 3.044896364212036
Validation loss: 2.358191756791966

Epoch: 99| Step: 0
Training loss: 2.2300162315368652
Validation loss: 2.3454829159603325

Epoch: 5| Step: 1
Training loss: 2.2230935096740723
Validation loss: 2.334461232667328

Epoch: 5| Step: 2
Training loss: 2.4079220294952393
Validation loss: 2.328470560812181

Epoch: 5| Step: 3
Training loss: 2.553847074508667
Validation loss: 2.3314079187249623

Epoch: 5| Step: 4
Training loss: 2.0306365489959717
Validation loss: 2.318323016166687

Epoch: 5| Step: 5
Training loss: 2.7749626636505127
Validation loss: 2.342257656076903

Epoch: 5| Step: 6
Training loss: 3.2293472290039062
Validation loss: 2.3790925446377007

Epoch: 5| Step: 7
Training loss: 2.677218198776245
Validation loss: 2.390379798027777

Epoch: 5| Step: 8
Training loss: 3.0426101684570312
Validation loss: 2.365183817443027

Epoch: 5| Step: 9
Training loss: 2.90274715423584
Validation loss: 2.347181107408257

Epoch: 5| Step: 10
Training loss: 2.4838619232177734
Validation loss: 2.333822924603698

Epoch: 100| Step: 0
Training loss: 2.9741809368133545
Validation loss: 2.32649661648658

Epoch: 5| Step: 1
Training loss: 2.7691657543182373
Validation loss: 2.3218380097419984

Epoch: 5| Step: 2
Training loss: 2.5859694480895996
Validation loss: 2.3185615385732343

Epoch: 5| Step: 3
Training loss: 2.9310028553009033
Validation loss: 2.3225750384792203

Epoch: 5| Step: 4
Training loss: 2.539531707763672
Validation loss: 2.315886228315292

Epoch: 5| Step: 5
Training loss: 2.3124682903289795
Validation loss: 2.3135045472011773

Epoch: 5| Step: 6
Training loss: 2.0956034660339355
Validation loss: 2.314334423311295

Epoch: 5| Step: 7
Training loss: 2.9178953170776367
Validation loss: 2.3185248785121466

Epoch: 5| Step: 8
Training loss: 3.136744499206543
Validation loss: 2.320524820717432

Epoch: 5| Step: 9
Training loss: 1.973663330078125
Validation loss: 2.314044390955279

Epoch: 5| Step: 10
Training loss: 2.0942282676696777
Validation loss: 2.316600720087687

Epoch: 101| Step: 0
Training loss: 1.9895827770233154
Validation loss: 2.3280338497572046

Epoch: 5| Step: 1
Training loss: 3.06475567817688
Validation loss: 2.3336373247126097

Epoch: 5| Step: 2
Training loss: 2.530947208404541
Validation loss: 2.3346819851988103

Epoch: 5| Step: 3
Training loss: 2.952540397644043
Validation loss: 2.347717779938893

Epoch: 5| Step: 4
Training loss: 2.89837908744812
Validation loss: 2.3444877311747563

Epoch: 5| Step: 5
Training loss: 2.274484157562256
Validation loss: 2.342849692990703

Epoch: 5| Step: 6
Training loss: 2.5117013454437256
Validation loss: 2.3290918745020384

Epoch: 5| Step: 7
Training loss: 2.8211989402770996
Validation loss: 2.3284436989856023

Epoch: 5| Step: 8
Training loss: 2.289269208908081
Validation loss: 2.3300556931444394

Epoch: 5| Step: 9
Training loss: 2.463247776031494
Validation loss: 2.3172850403734433

Epoch: 5| Step: 10
Training loss: 2.457275390625
Validation loss: 2.306882994149321

Epoch: 102| Step: 0
Training loss: 2.660756826400757
Validation loss: 2.3088744660859466

Epoch: 5| Step: 1
Training loss: 2.1632699966430664
Validation loss: 2.31416303624389

Epoch: 5| Step: 2
Training loss: 2.7617244720458984
Validation loss: 2.3270608263631023

Epoch: 5| Step: 3
Training loss: 2.8193135261535645
Validation loss: 2.3311534748282483

Epoch: 5| Step: 4
Training loss: 2.872434616088867
Validation loss: 2.3368305544699393

Epoch: 5| Step: 5
Training loss: 2.6636576652526855
Validation loss: 2.342052823753767

Epoch: 5| Step: 6
Training loss: 2.4259400367736816
Validation loss: 2.326570987701416

Epoch: 5| Step: 7
Training loss: 2.4307806491851807
Validation loss: 2.310547621019425

Epoch: 5| Step: 8
Training loss: 2.4516804218292236
Validation loss: 2.3229172845040598

Epoch: 5| Step: 9
Training loss: 2.5012197494506836
Validation loss: 2.3326513177605084

Epoch: 5| Step: 10
Training loss: 2.7066361904144287
Validation loss: 2.3702156261731218

Epoch: 103| Step: 0
Training loss: 2.7184290885925293
Validation loss: 2.3812098554385606

Epoch: 5| Step: 1
Training loss: 2.6156725883483887
Validation loss: 2.4088143174366285

Epoch: 5| Step: 2
Training loss: 2.339317798614502
Validation loss: 2.3918400400428363

Epoch: 5| Step: 3
Training loss: 2.1065754890441895
Validation loss: 2.3658133642647856

Epoch: 5| Step: 4
Training loss: 2.4336483478546143
Validation loss: 2.3379385291889148

Epoch: 5| Step: 5
Training loss: 3.014024257659912
Validation loss: 2.317308307975851

Epoch: 5| Step: 6
Training loss: 2.5484297275543213
Validation loss: 2.3003053101160194

Epoch: 5| Step: 7
Training loss: 2.5645384788513184
Validation loss: 2.301767497934321

Epoch: 5| Step: 8
Training loss: 3.199188709259033
Validation loss: 2.3089769578749135

Epoch: 5| Step: 9
Training loss: 2.6431679725646973
Validation loss: 2.3041546037120204

Epoch: 5| Step: 10
Training loss: 2.248978614807129
Validation loss: 2.2945482833411104

Epoch: 104| Step: 0
Training loss: 2.808521270751953
Validation loss: 2.298035593443019

Epoch: 5| Step: 1
Training loss: 2.7043240070343018
Validation loss: 2.305650018876599

Epoch: 5| Step: 2
Training loss: 2.5427985191345215
Validation loss: 2.3095294096136607

Epoch: 5| Step: 3
Training loss: 2.363643169403076
Validation loss: 2.3197607686442714

Epoch: 5| Step: 4
Training loss: 2.3350167274475098
Validation loss: 2.317822920378818

Epoch: 5| Step: 5
Training loss: 2.4083590507507324
Validation loss: 2.333096460629535

Epoch: 5| Step: 6
Training loss: 2.6392738819122314
Validation loss: 2.3327192593646306

Epoch: 5| Step: 7
Training loss: 3.3321139812469482
Validation loss: 2.3364956814755677

Epoch: 5| Step: 8
Training loss: 2.7968239784240723
Validation loss: 2.338221752515403

Epoch: 5| Step: 9
Training loss: 1.9875633716583252
Validation loss: 2.3263321461216098

Epoch: 5| Step: 10
Training loss: 2.178837299346924
Validation loss: 2.3156489172289447

Epoch: 105| Step: 0
Training loss: 2.595275402069092
Validation loss: 2.311106415205104

Epoch: 5| Step: 1
Training loss: 2.232491970062256
Validation loss: 2.307723335040513

Epoch: 5| Step: 2
Training loss: 2.503605365753174
Validation loss: 2.315062742079458

Epoch: 5| Step: 3
Training loss: 2.932281970977783
Validation loss: 2.3173131865839802

Epoch: 5| Step: 4
Training loss: 2.883802652359009
Validation loss: 2.317748826037171

Epoch: 5| Step: 5
Training loss: 1.9319660663604736
Validation loss: 2.316888366976092

Epoch: 5| Step: 6
Training loss: 2.701687812805176
Validation loss: 2.3297253936849613

Epoch: 5| Step: 7
Training loss: 2.290902853012085
Validation loss: 2.3085510269288094

Epoch: 5| Step: 8
Training loss: 2.725083112716675
Validation loss: 2.3181623181989117

Epoch: 5| Step: 9
Training loss: 2.292013645172119
Validation loss: 2.312543192217427

Epoch: 5| Step: 10
Training loss: 3.111780881881714
Validation loss: 2.3168508596317743

Epoch: 106| Step: 0
Training loss: 2.508322238922119
Validation loss: 2.317628845091789

Epoch: 5| Step: 1
Training loss: 2.4116902351379395
Validation loss: 2.3234919296797885

Epoch: 5| Step: 2
Training loss: 2.6894888877868652
Validation loss: 2.3188851264215287

Epoch: 5| Step: 3
Training loss: 2.2973809242248535
Validation loss: 2.3009125878733974

Epoch: 5| Step: 4
Training loss: 2.4276931285858154
Validation loss: 2.292633628332487

Epoch: 5| Step: 5
Training loss: 2.755274534225464
Validation loss: 2.2838097515926568

Epoch: 5| Step: 6
Training loss: 2.997653007507324
Validation loss: 2.2868454969057472

Epoch: 5| Step: 7
Training loss: 2.4306507110595703
Validation loss: 2.283428294684297

Epoch: 5| Step: 8
Training loss: 2.493600845336914
Validation loss: 2.2799483114673245

Epoch: 5| Step: 9
Training loss: 2.743027448654175
Validation loss: 2.279249769385143

Epoch: 5| Step: 10
Training loss: 2.3539717197418213
Validation loss: 2.2812024701026177

Epoch: 107| Step: 0
Training loss: 2.7193050384521484
Validation loss: 2.284558944804694

Epoch: 5| Step: 1
Training loss: 2.249276638031006
Validation loss: 2.291570722415883

Epoch: 5| Step: 2
Training loss: 2.5589303970336914
Validation loss: 2.3012922322878273

Epoch: 5| Step: 3
Training loss: 2.2900168895721436
Validation loss: 2.315442467248568

Epoch: 5| Step: 4
Training loss: 2.133366107940674
Validation loss: 2.3359519281694965

Epoch: 5| Step: 5
Training loss: 3.3461556434631348
Validation loss: 2.335065882693055

Epoch: 5| Step: 6
Training loss: 2.0573463439941406
Validation loss: 2.3030989810984623

Epoch: 5| Step: 7
Training loss: 2.4904894828796387
Validation loss: 2.291576129133983

Epoch: 5| Step: 8
Training loss: 2.9667270183563232
Validation loss: 2.2752591409990863

Epoch: 5| Step: 9
Training loss: 2.3132331371307373
Validation loss: 2.2657126047277965

Epoch: 5| Step: 10
Training loss: 2.9148104190826416
Validation loss: 2.2768947796155046

Epoch: 108| Step: 0
Training loss: 2.540581464767456
Validation loss: 2.2732449526427896

Epoch: 5| Step: 1
Training loss: 2.7958030700683594
Validation loss: 2.2812500512728127

Epoch: 5| Step: 2
Training loss: 2.3904924392700195
Validation loss: 2.2881466163102018

Epoch: 5| Step: 3
Training loss: 3.054206371307373
Validation loss: 2.2765817872939573

Epoch: 5| Step: 4
Training loss: 2.0202279090881348
Validation loss: 2.274700387831657

Epoch: 5| Step: 5
Training loss: 2.5654149055480957
Validation loss: 2.272308470100485

Epoch: 5| Step: 6
Training loss: 2.2048065662384033
Validation loss: 2.279585381989838

Epoch: 5| Step: 7
Training loss: 2.8408215045928955
Validation loss: 2.284993574183474

Epoch: 5| Step: 8
Training loss: 3.05785870552063
Validation loss: 2.295725058483821

Epoch: 5| Step: 9
Training loss: 2.14438533782959
Validation loss: 2.307155170748311

Epoch: 5| Step: 10
Training loss: 2.294893264770508
Validation loss: 2.326227411147087

Epoch: 109| Step: 0
Training loss: 2.5300753116607666
Validation loss: 2.353376842314197

Epoch: 5| Step: 1
Training loss: 2.4737801551818848
Validation loss: 2.367107755394392

Epoch: 5| Step: 2
Training loss: 2.8789114952087402
Validation loss: 2.3754238672153924

Epoch: 5| Step: 3
Training loss: 2.5304760932922363
Validation loss: 2.379320806072604

Epoch: 5| Step: 4
Training loss: 2.087871551513672
Validation loss: 2.3482806990223546

Epoch: 5| Step: 5
Training loss: 2.714052677154541
Validation loss: 2.321598035033031

Epoch: 5| Step: 6
Training loss: 2.8274474143981934
Validation loss: 2.303317872426843

Epoch: 5| Step: 7
Training loss: 2.1900904178619385
Validation loss: 2.30094394376201

Epoch: 5| Step: 8
Training loss: 2.8862857818603516
Validation loss: 2.2975066656707437

Epoch: 5| Step: 9
Training loss: 2.090691566467285
Validation loss: 2.284140266397948

Epoch: 5| Step: 10
Training loss: 2.9153099060058594
Validation loss: 2.27696164449056

Epoch: 110| Step: 0
Training loss: 1.95537531375885
Validation loss: 2.271611655912092

Epoch: 5| Step: 1
Training loss: 2.6617774963378906
Validation loss: 2.276988439662482

Epoch: 5| Step: 2
Training loss: 1.7724027633666992
Validation loss: 2.2687057128516575

Epoch: 5| Step: 3
Training loss: 3.241602659225464
Validation loss: 2.2664156754811606

Epoch: 5| Step: 4
Training loss: 2.4920125007629395
Validation loss: 2.2632543681770243

Epoch: 5| Step: 5
Training loss: 2.43333101272583
Validation loss: 2.2636990790726035

Epoch: 5| Step: 6
Training loss: 2.4646878242492676
Validation loss: 2.270198170856763

Epoch: 5| Step: 7
Training loss: 2.625018358230591
Validation loss: 2.267058874971123

Epoch: 5| Step: 8
Training loss: 2.8553779125213623
Validation loss: 2.258071368740451

Epoch: 5| Step: 9
Training loss: 2.8123409748077393
Validation loss: 2.2607862693007275

Epoch: 5| Step: 10
Training loss: 2.6086413860321045
Validation loss: 2.2597213457989436

Epoch: 111| Step: 0
Training loss: 2.878796339035034
Validation loss: 2.261783371689499

Epoch: 5| Step: 1
Training loss: 2.058504581451416
Validation loss: 2.2840874195098877

Epoch: 5| Step: 2
Training loss: 2.2052559852600098
Validation loss: 2.307127570593229

Epoch: 5| Step: 3
Training loss: 2.8810176849365234
Validation loss: 2.3375408546898955

Epoch: 5| Step: 4
Training loss: 2.432887554168701
Validation loss: 2.319204698326767

Epoch: 5| Step: 5
Training loss: 2.3115193843841553
Validation loss: 2.3074800993806575

Epoch: 5| Step: 6
Training loss: 2.872814178466797
Validation loss: 2.2632356753913303

Epoch: 5| Step: 7
Training loss: 2.9216887950897217
Validation loss: 2.2538151151390484

Epoch: 5| Step: 8
Training loss: 2.504526138305664
Validation loss: 2.2514612200439617

Epoch: 5| Step: 9
Training loss: 2.1774661540985107
Validation loss: 2.2603224028823194

Epoch: 5| Step: 10
Training loss: 2.5895893573760986
Validation loss: 2.265193264971497

Epoch: 112| Step: 0
Training loss: 2.0012338161468506
Validation loss: 2.2548130378928235

Epoch: 5| Step: 1
Training loss: 2.1428487300872803
Validation loss: 2.247302214304606

Epoch: 5| Step: 2
Training loss: 2.254103183746338
Validation loss: 2.2481487361333703

Epoch: 5| Step: 3
Training loss: 3.1514744758605957
Validation loss: 2.260842248957644

Epoch: 5| Step: 4
Training loss: 2.5911412239074707
Validation loss: 2.2757824415801675

Epoch: 5| Step: 5
Training loss: 2.4961185455322266
Validation loss: 2.2885557246464554

Epoch: 5| Step: 6
Training loss: 2.657829999923706
Validation loss: 2.2816357894610335

Epoch: 5| Step: 7
Training loss: 2.207683801651001
Validation loss: 2.3006220325346916

Epoch: 5| Step: 8
Training loss: 2.8211400508880615
Validation loss: 2.295758124320738

Epoch: 5| Step: 9
Training loss: 2.3246212005615234
Validation loss: 2.284703464918239

Epoch: 5| Step: 10
Training loss: 3.2799134254455566
Validation loss: 2.287010041616296

Epoch: 113| Step: 0
Training loss: 2.8139431476593018
Validation loss: 2.269979799947431

Epoch: 5| Step: 1
Training loss: 1.9932887554168701
Validation loss: 2.2682335863831224

Epoch: 5| Step: 2
Training loss: 3.115352153778076
Validation loss: 2.2646956751423497

Epoch: 5| Step: 3
Training loss: 2.5681443214416504
Validation loss: 2.263081968471568

Epoch: 5| Step: 4
Training loss: 2.9336788654327393
Validation loss: 2.287966976883591

Epoch: 5| Step: 5
Training loss: 2.3203768730163574
Validation loss: 2.3027352133104877

Epoch: 5| Step: 6
Training loss: 2.2086520195007324
Validation loss: 2.2972748484662784

Epoch: 5| Step: 7
Training loss: 2.8145577907562256
Validation loss: 2.2954812549775645

Epoch: 5| Step: 8
Training loss: 2.2388246059417725
Validation loss: 2.284198784059094

Epoch: 5| Step: 9
Training loss: 2.197645664215088
Validation loss: 2.277547041575114

Epoch: 5| Step: 10
Training loss: 2.4541051387786865
Validation loss: 2.2781250951110676

Epoch: 114| Step: 0
Training loss: 2.3527653217315674
Validation loss: 2.2665134001803655

Epoch: 5| Step: 1
Training loss: 2.867366075515747
Validation loss: 2.253698492562899

Epoch: 5| Step: 2
Training loss: 1.8229598999023438
Validation loss: 2.248729352028139

Epoch: 5| Step: 3
Training loss: 2.942939043045044
Validation loss: 2.2515485325167255

Epoch: 5| Step: 4
Training loss: 2.3891048431396484
Validation loss: 2.2510952975160334

Epoch: 5| Step: 5
Training loss: 2.5108187198638916
Validation loss: 2.2358007866849183

Epoch: 5| Step: 6
Training loss: 2.423888921737671
Validation loss: 2.2389053478035876

Epoch: 5| Step: 7
Training loss: 2.338275194168091
Validation loss: 2.2358646623549925

Epoch: 5| Step: 8
Training loss: 2.3622403144836426
Validation loss: 2.238532781600952

Epoch: 5| Step: 9
Training loss: 2.846811294555664
Validation loss: 2.2461026253238803

Epoch: 5| Step: 10
Training loss: 2.9835312366485596
Validation loss: 2.2432672874901884

Epoch: 115| Step: 0
Training loss: 3.2642009258270264
Validation loss: 2.252928977371544

Epoch: 5| Step: 1
Training loss: 2.0822033882141113
Validation loss: 2.2606802781422934

Epoch: 5| Step: 2
Training loss: 2.321837902069092
Validation loss: 2.2728592580364597

Epoch: 5| Step: 3
Training loss: 1.932790756225586
Validation loss: 2.2853826835591304

Epoch: 5| Step: 4
Training loss: 2.391796112060547
Validation loss: 2.280485919726792

Epoch: 5| Step: 5
Training loss: 2.4503586292266846
Validation loss: 2.282187359307402

Epoch: 5| Step: 6
Training loss: 3.426598072052002
Validation loss: 2.278755235415633

Epoch: 5| Step: 7
Training loss: 2.2266077995300293
Validation loss: 2.280994934420432

Epoch: 5| Step: 8
Training loss: 2.3374552726745605
Validation loss: 2.2700801459691857

Epoch: 5| Step: 9
Training loss: 2.7216358184814453
Validation loss: 2.260311213872766

Epoch: 5| Step: 10
Training loss: 2.3084020614624023
Validation loss: 2.2499260312767437

Epoch: 116| Step: 0
Training loss: 1.8783628940582275
Validation loss: 2.2533917580881426

Epoch: 5| Step: 1
Training loss: 2.1366612911224365
Validation loss: 2.2507222980581303

Epoch: 5| Step: 2
Training loss: 2.344773769378662
Validation loss: 2.23890515553054

Epoch: 5| Step: 3
Training loss: 3.183042287826538
Validation loss: 2.250763754690847

Epoch: 5| Step: 4
Training loss: 3.072317123413086
Validation loss: 2.2423343427719606

Epoch: 5| Step: 5
Training loss: 2.086172580718994
Validation loss: 2.258656814534177

Epoch: 5| Step: 6
Training loss: 1.8906753063201904
Validation loss: 2.245698780141851

Epoch: 5| Step: 7
Training loss: 2.9672250747680664
Validation loss: 2.2514058441244145

Epoch: 5| Step: 8
Training loss: 2.187344789505005
Validation loss: 2.2555807252084055

Epoch: 5| Step: 9
Training loss: 2.4288265705108643
Validation loss: 2.2732537228574037

Epoch: 5| Step: 10
Training loss: 3.513232946395874
Validation loss: 2.2950243385889197

Epoch: 117| Step: 0
Training loss: 2.3959624767303467
Validation loss: 2.3028982839276715

Epoch: 5| Step: 1
Training loss: 2.2014389038085938
Validation loss: 2.299710032760456

Epoch: 5| Step: 2
Training loss: 2.966269016265869
Validation loss: 2.316735695767146

Epoch: 5| Step: 3
Training loss: 2.8854527473449707
Validation loss: 2.3144592597920406

Epoch: 5| Step: 4
Training loss: 1.9791018962860107
Validation loss: 2.310550953752251

Epoch: 5| Step: 5
Training loss: 2.3601317405700684
Validation loss: 2.3069559527981665

Epoch: 5| Step: 6
Training loss: 2.104133129119873
Validation loss: 2.2867069244384766

Epoch: 5| Step: 7
Training loss: 2.758906364440918
Validation loss: 2.2589316483466857

Epoch: 5| Step: 8
Training loss: 2.880992889404297
Validation loss: 2.246029423129174

Epoch: 5| Step: 9
Training loss: 3.0648069381713867
Validation loss: 2.2300522096695437

Epoch: 5| Step: 10
Training loss: 2.01688814163208
Validation loss: 2.2245932650822464

Epoch: 118| Step: 0
Training loss: 1.7939602136611938
Validation loss: 2.2258346683235577

Epoch: 5| Step: 1
Training loss: 2.889446258544922
Validation loss: 2.250908613204956

Epoch: 5| Step: 2
Training loss: 2.63385009765625
Validation loss: 2.284500370743454

Epoch: 5| Step: 3
Training loss: 2.8223977088928223
Validation loss: 2.311048456417617

Epoch: 5| Step: 4
Training loss: 2.4979825019836426
Validation loss: 2.3310126181571715

Epoch: 5| Step: 5
Training loss: 2.3195574283599854
Validation loss: 2.3532220599471882

Epoch: 5| Step: 6
Training loss: 2.5469658374786377
Validation loss: 2.344174156906784

Epoch: 5| Step: 7
Training loss: 2.764662265777588
Validation loss: 2.258003222045078

Epoch: 5| Step: 8
Training loss: 2.6433491706848145
Validation loss: 2.206593692943614

Epoch: 5| Step: 9
Training loss: 2.3574044704437256
Validation loss: 2.22297998141217

Epoch: 5| Step: 10
Training loss: 2.5445730686187744
Validation loss: 2.239645693891792

Epoch: 119| Step: 0
Training loss: 3.1375858783721924
Validation loss: 2.2830588894505657

Epoch: 5| Step: 1
Training loss: 2.7502663135528564
Validation loss: 2.3234994590923352

Epoch: 5| Step: 2
Training loss: 2.589292287826538
Validation loss: 2.365863569321171

Epoch: 5| Step: 3
Training loss: 2.4084086418151855
Validation loss: 2.357356649573131

Epoch: 5| Step: 4
Training loss: 2.053893566131592
Validation loss: 2.344930156584709

Epoch: 5| Step: 5
Training loss: 2.0150272846221924
Validation loss: 2.363947009527555

Epoch: 5| Step: 6
Training loss: 2.970491886138916
Validation loss: 2.3716681798299155

Epoch: 5| Step: 7
Training loss: 3.3342673778533936
Validation loss: 2.3462004353923183

Epoch: 5| Step: 8
Training loss: 2.074556350708008
Validation loss: 2.2979313417147567

Epoch: 5| Step: 9
Training loss: 2.438528299331665
Validation loss: 2.2988326857166905

Epoch: 5| Step: 10
Training loss: 2.6698758602142334
Validation loss: 2.3056766897119503

Epoch: 120| Step: 0
Training loss: 2.512704372406006
Validation loss: 2.289358162110852

Epoch: 5| Step: 1
Training loss: 2.381290912628174
Validation loss: 2.299356916899322

Epoch: 5| Step: 2
Training loss: 2.5073506832122803
Validation loss: 2.300207209843461

Epoch: 5| Step: 3
Training loss: 2.291513442993164
Validation loss: 2.271009555426977

Epoch: 5| Step: 4
Training loss: 2.5951454639434814
Validation loss: 2.251273815349866

Epoch: 5| Step: 5
Training loss: 2.180198907852173
Validation loss: 2.251680689473306

Epoch: 5| Step: 6
Training loss: 2.7010059356689453
Validation loss: 2.250298000151111

Epoch: 5| Step: 7
Training loss: 1.789489507675171
Validation loss: 2.23062192240069

Epoch: 5| Step: 8
Training loss: 3.1566810607910156
Validation loss: 2.2263548348539617

Epoch: 5| Step: 9
Training loss: 3.2747836112976074
Validation loss: 2.216178127514419

Epoch: 5| Step: 10
Training loss: 1.9982719421386719
Validation loss: 2.2076965019267094

Epoch: 121| Step: 0
Training loss: 2.984516143798828
Validation loss: 2.1993519003673265

Epoch: 5| Step: 1
Training loss: 2.8170278072357178
Validation loss: 2.2063559639838433

Epoch: 5| Step: 2
Training loss: 2.5820982456207275
Validation loss: 2.2079259195635395

Epoch: 5| Step: 3
Training loss: 1.9713481664657593
Validation loss: 2.208231956728043

Epoch: 5| Step: 4
Training loss: 2.6729893684387207
Validation loss: 2.2125535703474477

Epoch: 5| Step: 5
Training loss: 2.670964002609253
Validation loss: 2.227847468468451

Epoch: 5| Step: 6
Training loss: 2.556138277053833
Validation loss: 2.2332560221354165

Epoch: 5| Step: 7
Training loss: 2.0742177963256836
Validation loss: 2.225753370151725

Epoch: 5| Step: 8
Training loss: 3.0538744926452637
Validation loss: 2.2183200133744108

Epoch: 5| Step: 9
Training loss: 1.7093356847763062
Validation loss: 2.2034297502169045

Epoch: 5| Step: 10
Training loss: 2.269176483154297
Validation loss: 2.214976138966058

Epoch: 122| Step: 0
Training loss: 2.500119686126709
Validation loss: 2.225896659717765

Epoch: 5| Step: 1
Training loss: 1.8084299564361572
Validation loss: 2.226295437864078

Epoch: 5| Step: 2
Training loss: 2.2413628101348877
Validation loss: 2.232171284255161

Epoch: 5| Step: 3
Training loss: 2.5696258544921875
Validation loss: 2.223897600686678

Epoch: 5| Step: 4
Training loss: 3.0803236961364746
Validation loss: 2.228821018690704

Epoch: 5| Step: 5
Training loss: 2.976426601409912
Validation loss: 2.231507014202815

Epoch: 5| Step: 6
Training loss: 2.114509105682373
Validation loss: 2.230339269484243

Epoch: 5| Step: 7
Training loss: 2.652545928955078
Validation loss: 2.2334250750080233

Epoch: 5| Step: 8
Training loss: 2.279690742492676
Validation loss: 2.2262230201434066

Epoch: 5| Step: 9
Training loss: 2.496786117553711
Validation loss: 2.226560009423123

Epoch: 5| Step: 10
Training loss: 2.4816839694976807
Validation loss: 2.2235706903601207

Epoch: 123| Step: 0
Training loss: 2.288658857345581
Validation loss: 2.208620450829947

Epoch: 5| Step: 1
Training loss: 2.6927971839904785
Validation loss: 2.1945043404897056

Epoch: 5| Step: 2
Training loss: 2.385767698287964
Validation loss: 2.186295820820716

Epoch: 5| Step: 3
Training loss: 1.640972375869751
Validation loss: 2.1801310893028014

Epoch: 5| Step: 4
Training loss: 2.7156691551208496
Validation loss: 2.179026337080104

Epoch: 5| Step: 5
Training loss: 3.257038116455078
Validation loss: 2.18271707206644

Epoch: 5| Step: 6
Training loss: 2.9660656452178955
Validation loss: 2.1828764869320776

Epoch: 5| Step: 7
Training loss: 2.612842082977295
Validation loss: 2.1889350414276123

Epoch: 5| Step: 8
Training loss: 1.7838459014892578
Validation loss: 2.195195879987491

Epoch: 5| Step: 9
Training loss: 2.4608266353607178
Validation loss: 2.2050385449522283

Epoch: 5| Step: 10
Training loss: 2.3537628650665283
Validation loss: 2.200473799500414

Epoch: 124| Step: 0
Training loss: 2.71860933303833
Validation loss: 2.2081106067985616

Epoch: 5| Step: 1
Training loss: 2.7307932376861572
Validation loss: 2.2025435022128526

Epoch: 5| Step: 2
Training loss: 2.229884147644043
Validation loss: 2.1873739432263117

Epoch: 5| Step: 3
Training loss: 2.867250442504883
Validation loss: 2.18521874694414

Epoch: 5| Step: 4
Training loss: 2.5764670372009277
Validation loss: 2.1804099313674437

Epoch: 5| Step: 5
Training loss: 2.480426549911499
Validation loss: 2.1788645918651293

Epoch: 5| Step: 6
Training loss: 2.5075149536132812
Validation loss: 2.183786492193899

Epoch: 5| Step: 7
Training loss: 2.5297300815582275
Validation loss: 2.192726127562984

Epoch: 5| Step: 8
Training loss: 2.049666166305542
Validation loss: 2.1993939145918815

Epoch: 5| Step: 9
Training loss: 2.263888120651245
Validation loss: 2.1888748715000768

Epoch: 5| Step: 10
Training loss: 2.072896957397461
Validation loss: 2.1754821064651653

Epoch: 125| Step: 0
Training loss: 2.409606456756592
Validation loss: 2.181947395365725

Epoch: 5| Step: 1
Training loss: 2.5719425678253174
Validation loss: 2.175231989993844

Epoch: 5| Step: 2
Training loss: 2.743558883666992
Validation loss: 2.1675818376643683

Epoch: 5| Step: 3
Training loss: 2.30676531791687
Validation loss: 2.1734739170279553

Epoch: 5| Step: 4
Training loss: 2.866644859313965
Validation loss: 2.1728004614512124

Epoch: 5| Step: 5
Training loss: 1.4810794591903687
Validation loss: 2.1644692062049784

Epoch: 5| Step: 6
Training loss: 2.361952781677246
Validation loss: 2.1684766995009555

Epoch: 5| Step: 7
Training loss: 2.497934341430664
Validation loss: 2.179454234338576

Epoch: 5| Step: 8
Training loss: 2.41365122795105
Validation loss: 2.2158801529997136

Epoch: 5| Step: 9
Training loss: 2.571263074874878
Validation loss: 2.2738431294759116

Epoch: 5| Step: 10
Training loss: 2.89534068107605
Validation loss: 2.3232627068796465

Epoch: 126| Step: 0
Training loss: 2.849236249923706
Validation loss: 2.3621224946873163

Epoch: 5| Step: 1
Training loss: 1.98659348487854
Validation loss: 2.3443926585617887

Epoch: 5| Step: 2
Training loss: 2.154618740081787
Validation loss: 2.3049916451977146

Epoch: 5| Step: 3
Training loss: 2.541682481765747
Validation loss: 2.2569743151305826

Epoch: 5| Step: 4
Training loss: 2.927454948425293
Validation loss: 2.2016151694841284

Epoch: 5| Step: 5
Training loss: 2.370612859725952
Validation loss: 2.1871282439078055

Epoch: 5| Step: 6
Training loss: 1.8962767124176025
Validation loss: 2.1803226624765704

Epoch: 5| Step: 7
Training loss: 2.4979007244110107
Validation loss: 2.1959610959535003

Epoch: 5| Step: 8
Training loss: 2.9466023445129395
Validation loss: 2.1967599981574604

Epoch: 5| Step: 9
Training loss: 2.510077476501465
Validation loss: 2.201586514390925

Epoch: 5| Step: 10
Training loss: 2.4796621799468994
Validation loss: 2.212786300207979

Epoch: 127| Step: 0
Training loss: 2.932499408721924
Validation loss: 2.2178403741569928

Epoch: 5| Step: 1
Training loss: 2.565573215484619
Validation loss: 2.21629588578337

Epoch: 5| Step: 2
Training loss: 2.3319902420043945
Validation loss: 2.214391282809678

Epoch: 5| Step: 3
Training loss: 2.110755205154419
Validation loss: 2.1922050701674594

Epoch: 5| Step: 4
Training loss: 2.6360676288604736
Validation loss: 2.1825384375869588

Epoch: 5| Step: 5
Training loss: 2.890282154083252
Validation loss: 2.202774777207323

Epoch: 5| Step: 6
Training loss: 2.511247396469116
Validation loss: 2.2381001390436643

Epoch: 5| Step: 7
Training loss: 2.6740853786468506
Validation loss: 2.275978301161079

Epoch: 5| Step: 8
Training loss: 2.5367071628570557
Validation loss: 2.245864124708278

Epoch: 5| Step: 9
Training loss: 1.766095519065857
Validation loss: 2.219606694354806

Epoch: 5| Step: 10
Training loss: 2.3352794647216797
Validation loss: 2.2043354049805672

Epoch: 128| Step: 0
Training loss: 2.194643020629883
Validation loss: 2.1909477505632626

Epoch: 5| Step: 1
Training loss: 2.5995445251464844
Validation loss: 2.192915501133088

Epoch: 5| Step: 2
Training loss: 2.6832706928253174
Validation loss: 2.2120410806389263

Epoch: 5| Step: 3
Training loss: 2.664419174194336
Validation loss: 2.204301352142006

Epoch: 5| Step: 4
Training loss: 2.0213241577148438
Validation loss: 2.200702118617232

Epoch: 5| Step: 5
Training loss: 2.548274517059326
Validation loss: 2.1831718362787718

Epoch: 5| Step: 6
Training loss: 2.7266416549682617
Validation loss: 2.1837931871414185

Epoch: 5| Step: 7
Training loss: 2.0466537475585938
Validation loss: 2.185976134833469

Epoch: 5| Step: 8
Training loss: 2.488682508468628
Validation loss: 2.195356256218367

Epoch: 5| Step: 9
Training loss: 2.343611001968384
Validation loss: 2.1986787037182878

Epoch: 5| Step: 10
Training loss: 2.709613561630249
Validation loss: 2.2026775934362925

Epoch: 129| Step: 0
Training loss: 1.543650507926941
Validation loss: 2.188598625121578

Epoch: 5| Step: 1
Training loss: 2.261814594268799
Validation loss: 2.1800075025968653

Epoch: 5| Step: 2
Training loss: 2.4066665172576904
Validation loss: 2.1686517089925785

Epoch: 5| Step: 3
Training loss: 2.528968334197998
Validation loss: 2.186494952888899

Epoch: 5| Step: 4
Training loss: 2.4521031379699707
Validation loss: 2.17939499116713

Epoch: 5| Step: 5
Training loss: 2.257009744644165
Validation loss: 2.1751845216238372

Epoch: 5| Step: 6
Training loss: 3.1766905784606934
Validation loss: 2.2002605417723298

Epoch: 5| Step: 7
Training loss: 2.6650099754333496
Validation loss: 2.2031536948296333

Epoch: 5| Step: 8
Training loss: 2.8703811168670654
Validation loss: 2.22086767227419

Epoch: 5| Step: 9
Training loss: 2.3354594707489014
Validation loss: 2.1848552803839407

Epoch: 5| Step: 10
Training loss: 2.3471381664276123
Validation loss: 2.1883332344793502

Epoch: 130| Step: 0
Training loss: 3.3825035095214844
Validation loss: 2.1848463191780993

Epoch: 5| Step: 1
Training loss: 2.8111515045166016
Validation loss: 2.216090379222747

Epoch: 5| Step: 2
Training loss: 2.514850616455078
Validation loss: 2.261705649796353

Epoch: 5| Step: 3
Training loss: 1.9727462530136108
Validation loss: 2.245537006726829

Epoch: 5| Step: 4
Training loss: 2.1885437965393066
Validation loss: 2.2275023819297872

Epoch: 5| Step: 5
Training loss: 2.591724157333374
Validation loss: 2.1857686324786116

Epoch: 5| Step: 6
Training loss: 2.585139751434326
Validation loss: 2.1842326810283046

Epoch: 5| Step: 7
Training loss: 2.4029555320739746
Validation loss: 2.1886900432648195

Epoch: 5| Step: 8
Training loss: 1.7736648321151733
Validation loss: 2.214151700337728

Epoch: 5| Step: 9
Training loss: 2.502593517303467
Validation loss: 2.2048514453313683

Epoch: 5| Step: 10
Training loss: 2.258636713027954
Validation loss: 2.198280975382815

Epoch: 131| Step: 0
Training loss: 2.644434690475464
Validation loss: 2.1929706758068455

Epoch: 5| Step: 1
Training loss: 2.436002016067505
Validation loss: 2.165923862047093

Epoch: 5| Step: 2
Training loss: 2.299835205078125
Validation loss: 2.1667834071702856

Epoch: 5| Step: 3
Training loss: 3.028528928756714
Validation loss: 2.1867026975077968

Epoch: 5| Step: 4
Training loss: 2.767016887664795
Validation loss: 2.232675060149162

Epoch: 5| Step: 5
Training loss: 2.361551284790039
Validation loss: 2.2503070985117266

Epoch: 5| Step: 6
Training loss: 2.327141523361206
Validation loss: 2.2391047195721696

Epoch: 5| Step: 7
Training loss: 1.6065590381622314
Validation loss: 2.2248493420180453

Epoch: 5| Step: 8
Training loss: 2.161120653152466
Validation loss: 2.1917179399921047

Epoch: 5| Step: 9
Training loss: 2.980926990509033
Validation loss: 2.18689085847588

Epoch: 5| Step: 10
Training loss: 2.3562982082366943
Validation loss: 2.167874297788066

Epoch: 132| Step: 0
Training loss: 2.129110336303711
Validation loss: 2.1634260915940806

Epoch: 5| Step: 1
Training loss: 2.1999518871307373
Validation loss: 2.161986412540559

Epoch: 5| Step: 2
Training loss: 3.0920794010162354
Validation loss: 2.1538068607289302

Epoch: 5| Step: 3
Training loss: 2.3060545921325684
Validation loss: 2.144713040321104

Epoch: 5| Step: 4
Training loss: 2.4841792583465576
Validation loss: 2.1508118311564126

Epoch: 5| Step: 5
Training loss: 2.2736411094665527
Validation loss: 2.143091845256026

Epoch: 5| Step: 6
Training loss: 2.5235610008239746
Validation loss: 2.1402256527254657

Epoch: 5| Step: 7
Training loss: 2.532240152359009
Validation loss: 2.1439067573957544

Epoch: 5| Step: 8
Training loss: 2.671764612197876
Validation loss: 2.1486423502686205

Epoch: 5| Step: 9
Training loss: 2.19460129737854
Validation loss: 2.150181988234161

Epoch: 5| Step: 10
Training loss: 2.139406204223633
Validation loss: 2.158450622712412

Epoch: 133| Step: 0
Training loss: 1.9449920654296875
Validation loss: 2.158346276129446

Epoch: 5| Step: 1
Training loss: 2.530527114868164
Validation loss: 2.151572258241715

Epoch: 5| Step: 2
Training loss: 2.5491783618927
Validation loss: 2.1602034902059906

Epoch: 5| Step: 3
Training loss: 2.9429380893707275
Validation loss: 2.173084646142939

Epoch: 5| Step: 4
Training loss: 2.5711216926574707
Validation loss: 2.169373563540879

Epoch: 5| Step: 5
Training loss: 2.8162336349487305
Validation loss: 2.175802899945167

Epoch: 5| Step: 6
Training loss: 2.017483711242676
Validation loss: 2.1820544747896093

Epoch: 5| Step: 7
Training loss: 2.4832024574279785
Validation loss: 2.183256515892603

Epoch: 5| Step: 8
Training loss: 2.465796709060669
Validation loss: 2.175504033283521

Epoch: 5| Step: 9
Training loss: 1.916592001914978
Validation loss: 2.1639112298206618

Epoch: 5| Step: 10
Training loss: 2.2460665702819824
Validation loss: 2.1591027436717862

Epoch: 134| Step: 0
Training loss: 2.426013946533203
Validation loss: 2.1531666376257457

Epoch: 5| Step: 1
Training loss: 2.345592498779297
Validation loss: 2.144613314700383

Epoch: 5| Step: 2
Training loss: 2.3834948539733887
Validation loss: 2.140260834847727

Epoch: 5| Step: 3
Training loss: 2.0227243900299072
Validation loss: 2.1429341672569193

Epoch: 5| Step: 4
Training loss: 2.3968849182128906
Validation loss: 2.1549028478642946

Epoch: 5| Step: 5
Training loss: 2.5641839504241943
Validation loss: 2.1540634016836844

Epoch: 5| Step: 6
Training loss: 2.548100471496582
Validation loss: 2.156534861492854

Epoch: 5| Step: 7
Training loss: 2.0228350162506104
Validation loss: 2.165164993655297

Epoch: 5| Step: 8
Training loss: 2.6000418663024902
Validation loss: 2.1492902668573524

Epoch: 5| Step: 9
Training loss: 2.823469638824463
Validation loss: 2.179981206053047

Epoch: 5| Step: 10
Training loss: 2.2860422134399414
Validation loss: 2.1787473565788678

Epoch: 135| Step: 0
Training loss: 2.244274854660034
Validation loss: 2.1736119870216615

Epoch: 5| Step: 1
Training loss: 2.0055670738220215
Validation loss: 2.1710502242529266

Epoch: 5| Step: 2
Training loss: 2.107811689376831
Validation loss: 2.170095471925633

Epoch: 5| Step: 3
Training loss: 2.337463855743408
Validation loss: 2.168042318795317

Epoch: 5| Step: 4
Training loss: 2.2331414222717285
Validation loss: 2.1569110167923795

Epoch: 5| Step: 5
Training loss: 2.31343674659729
Validation loss: 2.1540068580258276

Epoch: 5| Step: 6
Training loss: 2.797159194946289
Validation loss: 2.1572973189815396

Epoch: 5| Step: 7
Training loss: 2.686938762664795
Validation loss: 2.142728885014852

Epoch: 5| Step: 8
Training loss: 2.7871415615081787
Validation loss: 2.1359927372265886

Epoch: 5| Step: 9
Training loss: 2.8021364212036133
Validation loss: 2.146007368641515

Epoch: 5| Step: 10
Training loss: 1.9717106819152832
Validation loss: 2.139774994183612

Epoch: 136| Step: 0
Training loss: 2.723594903945923
Validation loss: 2.1487647077088714

Epoch: 5| Step: 1
Training loss: 2.6043877601623535
Validation loss: 2.1417170109287387

Epoch: 5| Step: 2
Training loss: 2.535539150238037
Validation loss: 2.1430055582395164

Epoch: 5| Step: 3
Training loss: 2.7047624588012695
Validation loss: 2.1364804929302585

Epoch: 5| Step: 4
Training loss: 2.4760382175445557
Validation loss: 2.133664995111445

Epoch: 5| Step: 5
Training loss: 2.2849812507629395
Validation loss: 2.1297306629919235

Epoch: 5| Step: 6
Training loss: 2.0876235961914062
Validation loss: 2.1321038123100036

Epoch: 5| Step: 7
Training loss: 2.816746950149536
Validation loss: 2.1337951024373374

Epoch: 5| Step: 8
Training loss: 1.7822551727294922
Validation loss: 2.1395493425348753

Epoch: 5| Step: 9
Training loss: 2.4912941455841064
Validation loss: 2.1404705714153986

Epoch: 5| Step: 10
Training loss: 1.694408655166626
Validation loss: 2.1458355739552486

Epoch: 137| Step: 0
Training loss: 1.6848119497299194
Validation loss: 2.154743209961922

Epoch: 5| Step: 1
Training loss: 2.694157600402832
Validation loss: 2.1467230191794773

Epoch: 5| Step: 2
Training loss: 2.3710391521453857
Validation loss: 2.1429512603308565

Epoch: 5| Step: 3
Training loss: 2.0088348388671875
Validation loss: 2.140110429897103

Epoch: 5| Step: 4
Training loss: 2.385709047317505
Validation loss: 2.1469629477429133

Epoch: 5| Step: 5
Training loss: 3.1586947441101074
Validation loss: 2.1430467995264197

Epoch: 5| Step: 6
Training loss: 2.4776928424835205
Validation loss: 2.147028862789113

Epoch: 5| Step: 7
Training loss: 3.114718198776245
Validation loss: 2.1365232698379026

Epoch: 5| Step: 8
Training loss: 1.8413654565811157
Validation loss: 2.1353606562460623

Epoch: 5| Step: 9
Training loss: 2.2077078819274902
Validation loss: 2.139623301003569

Epoch: 5| Step: 10
Training loss: 2.147597312927246
Validation loss: 2.138924703803114

Epoch: 138| Step: 0
Training loss: 2.506028413772583
Validation loss: 2.142623483493764

Epoch: 5| Step: 1
Training loss: 2.471494197845459
Validation loss: 2.1404328884616977

Epoch: 5| Step: 2
Training loss: 2.0372467041015625
Validation loss: 2.1420562626213155

Epoch: 5| Step: 3
Training loss: 2.1268115043640137
Validation loss: 2.134945405426846

Epoch: 5| Step: 4
Training loss: 2.702882766723633
Validation loss: 2.1424168937949726

Epoch: 5| Step: 5
Training loss: 2.372685670852661
Validation loss: 2.151496059151106

Epoch: 5| Step: 6
Training loss: 2.1341776847839355
Validation loss: 2.1532247976590226

Epoch: 5| Step: 7
Training loss: 2.0769429206848145
Validation loss: 2.1498946810281403

Epoch: 5| Step: 8
Training loss: 2.6649580001831055
Validation loss: 2.14600400001772

Epoch: 5| Step: 9
Training loss: 2.651602268218994
Validation loss: 2.1278490443383493

Epoch: 5| Step: 10
Training loss: 2.3536388874053955
Validation loss: 2.1372740550707747

Epoch: 139| Step: 0
Training loss: 2.4350380897521973
Validation loss: 2.141670911542831

Epoch: 5| Step: 1
Training loss: 2.343791961669922
Validation loss: 2.1482798643009637

Epoch: 5| Step: 2
Training loss: 2.563634157180786
Validation loss: 2.1433300177256265

Epoch: 5| Step: 3
Training loss: 2.621349573135376
Validation loss: 2.1327534721743677

Epoch: 5| Step: 4
Training loss: 1.9830658435821533
Validation loss: 2.1272074048237135

Epoch: 5| Step: 5
Training loss: 2.182034730911255
Validation loss: 2.1350701688438334

Epoch: 5| Step: 6
Training loss: 2.5368340015411377
Validation loss: 2.1345770077038835

Epoch: 5| Step: 7
Training loss: 1.9220714569091797
Validation loss: 2.1246028459200295

Epoch: 5| Step: 8
Training loss: 2.3055810928344727
Validation loss: 2.113117487199845

Epoch: 5| Step: 9
Training loss: 2.5849156379699707
Validation loss: 2.1161573638198194

Epoch: 5| Step: 10
Training loss: 2.737936019897461
Validation loss: 2.1140064142083608

Epoch: 140| Step: 0
Training loss: 2.4982473850250244
Validation loss: 2.1175866947379163

Epoch: 5| Step: 1
Training loss: 2.6534597873687744
Validation loss: 2.1134692674042075

Epoch: 5| Step: 2
Training loss: 2.4087090492248535
Validation loss: 2.114502601726081

Epoch: 5| Step: 3
Training loss: 1.314403772354126
Validation loss: 2.1234055103794223

Epoch: 5| Step: 4
Training loss: 2.213618040084839
Validation loss: 2.132512725809569

Epoch: 5| Step: 5
Training loss: 2.642831802368164
Validation loss: 2.136317858131983

Epoch: 5| Step: 6
Training loss: 2.2754361629486084
Validation loss: 2.135119985508662

Epoch: 5| Step: 7
Training loss: 2.1028616428375244
Validation loss: 2.142801441172118

Epoch: 5| Step: 8
Training loss: 2.4369747638702393
Validation loss: 2.1321175226601223

Epoch: 5| Step: 9
Training loss: 2.3095288276672363
Validation loss: 2.1279213428497314

Epoch: 5| Step: 10
Training loss: 3.25264573097229
Validation loss: 2.1300166550502984

Epoch: 141| Step: 0
Training loss: 1.862222671508789
Validation loss: 2.1249938062442246

Epoch: 5| Step: 1
Training loss: 2.0332276821136475
Validation loss: 2.1269101430011053

Epoch: 5| Step: 2
Training loss: 2.5223641395568848
Validation loss: 2.1182545961872226

Epoch: 5| Step: 3
Training loss: 2.4184927940368652
Validation loss: 2.1252500562257666

Epoch: 5| Step: 4
Training loss: 2.1199095249176025
Validation loss: 2.1247995463750695

Epoch: 5| Step: 5
Training loss: 2.567171096801758
Validation loss: 2.1395967391229447

Epoch: 5| Step: 6
Training loss: 2.8108315467834473
Validation loss: 2.133559837136217

Epoch: 5| Step: 7
Training loss: 2.7565646171569824
Validation loss: 2.139584715648364

Epoch: 5| Step: 8
Training loss: 2.2528679370880127
Validation loss: 2.1268977272895073

Epoch: 5| Step: 9
Training loss: 2.484968900680542
Validation loss: 2.145486398409772

Epoch: 5| Step: 10
Training loss: 2.0380773544311523
Validation loss: 2.1900808375368834

Epoch: 142| Step: 0
Training loss: 1.46812903881073
Validation loss: 2.2330456933667584

Epoch: 5| Step: 1
Training loss: 2.2562153339385986
Validation loss: 2.2609140539682038

Epoch: 5| Step: 2
Training loss: 2.77409029006958
Validation loss: 2.2035533728138095

Epoch: 5| Step: 3
Training loss: 2.599884510040283
Validation loss: 2.161216443584811

Epoch: 5| Step: 4
Training loss: 2.4598021507263184
Validation loss: 2.133310710230181

Epoch: 5| Step: 5
Training loss: 1.9626048803329468
Validation loss: 2.1446170396702264

Epoch: 5| Step: 6
Training loss: 2.2958500385284424
Validation loss: 2.1565018469287502

Epoch: 5| Step: 7
Training loss: 2.3117611408233643
Validation loss: 2.148472570603894

Epoch: 5| Step: 8
Training loss: 2.9927468299865723
Validation loss: 2.1372273968112085

Epoch: 5| Step: 9
Training loss: 2.8080739974975586
Validation loss: 2.1392636273496892

Epoch: 5| Step: 10
Training loss: 2.4474868774414062
Validation loss: 2.151179507214536

Epoch: 143| Step: 0
Training loss: 2.3875162601470947
Validation loss: 2.147922526123703

Epoch: 5| Step: 1
Training loss: 2.2119555473327637
Validation loss: 2.13964137851551

Epoch: 5| Step: 2
Training loss: 2.4399333000183105
Validation loss: 2.1167358019018687

Epoch: 5| Step: 3
Training loss: 1.5492197275161743
Validation loss: 2.111894812635196

Epoch: 5| Step: 4
Training loss: 2.7166996002197266
Validation loss: 2.1102427462095856

Epoch: 5| Step: 5
Training loss: 2.3082611560821533
Validation loss: 2.1249559797266477

Epoch: 5| Step: 6
Training loss: 2.1606364250183105
Validation loss: 2.138443922483793

Epoch: 5| Step: 7
Training loss: 2.5834906101226807
Validation loss: 2.1355255855027067

Epoch: 5| Step: 8
Training loss: 3.271472454071045
Validation loss: 2.1360604199030067

Epoch: 5| Step: 9
Training loss: 2.2848780155181885
Validation loss: 2.120541621279973

Epoch: 5| Step: 10
Training loss: 2.228963851928711
Validation loss: 2.1060124776696645

Epoch: 144| Step: 0
Training loss: 1.8888604640960693
Validation loss: 2.113260240964992

Epoch: 5| Step: 1
Training loss: 2.206587553024292
Validation loss: 2.126996050598801

Epoch: 5| Step: 2
Training loss: 3.259478807449341
Validation loss: 2.1841636088586625

Epoch: 5| Step: 3
Training loss: 2.322972297668457
Validation loss: 2.2221790693139516

Epoch: 5| Step: 4
Training loss: 2.0224971771240234
Validation loss: 2.1854712424739713

Epoch: 5| Step: 5
Training loss: 2.6376240253448486
Validation loss: 2.1268558912379767

Epoch: 5| Step: 6
Training loss: 2.390033006668091
Validation loss: 2.0983274008638118

Epoch: 5| Step: 7
Training loss: 2.763981342315674
Validation loss: 2.1144986626922444

Epoch: 5| Step: 8
Training loss: 2.278087615966797
Validation loss: 2.154812532086526

Epoch: 5| Step: 9
Training loss: 2.6099114418029785
Validation loss: 2.1909463918337257

Epoch: 5| Step: 10
Training loss: 2.3411214351654053
Validation loss: 2.252751806730865

Epoch: 145| Step: 0
Training loss: 2.5016396045684814
Validation loss: 2.2661484031267065

Epoch: 5| Step: 1
Training loss: 1.97567880153656
Validation loss: 2.2528605538029827

Epoch: 5| Step: 2
Training loss: 2.2794456481933594
Validation loss: 2.202136634498514

Epoch: 5| Step: 3
Training loss: 1.4590951204299927
Validation loss: 2.1541554517643426

Epoch: 5| Step: 4
Training loss: 2.451099157333374
Validation loss: 2.13553988036289

Epoch: 5| Step: 5
Training loss: 2.055243968963623
Validation loss: 2.1518902240260953

Epoch: 5| Step: 6
Training loss: 2.704353094100952
Validation loss: 2.1981751893156316

Epoch: 5| Step: 7
Training loss: 3.2984726428985596
Validation loss: 2.2486448441782305

Epoch: 5| Step: 8
Training loss: 2.5044240951538086
Validation loss: 2.3028471982607277

Epoch: 5| Step: 9
Training loss: 2.195112705230713
Validation loss: 2.273648569660802

Epoch: 5| Step: 10
Training loss: 3.41009521484375
Validation loss: 2.19914770895435

Epoch: 146| Step: 0
Training loss: 1.8962867259979248
Validation loss: 2.1584278216926

Epoch: 5| Step: 1
Training loss: 2.3290257453918457
Validation loss: 2.185941841012688

Epoch: 5| Step: 2
Training loss: 2.8453996181488037
Validation loss: 2.1901697727941696

Epoch: 5| Step: 3
Training loss: 2.616802453994751
Validation loss: 2.2133468786875405

Epoch: 5| Step: 4
Training loss: 2.9373779296875
Validation loss: 2.2240908658632668

Epoch: 5| Step: 5
Training loss: 2.707801342010498
Validation loss: 2.220042851663405

Epoch: 5| Step: 6
Training loss: 2.518789052963257
Validation loss: 2.214537259071104

Epoch: 5| Step: 7
Training loss: 2.110631227493286
Validation loss: 2.2002237458382883

Epoch: 5| Step: 8
Training loss: 2.215327024459839
Validation loss: 2.177404116558772

Epoch: 5| Step: 9
Training loss: 2.3826751708984375
Validation loss: 2.160987456639608

Epoch: 5| Step: 10
Training loss: 2.349548816680908
Validation loss: 2.123047092909454

Epoch: 147| Step: 0
Training loss: 2.1284420490264893
Validation loss: 2.117124219094553

Epoch: 5| Step: 1
Training loss: 2.1027815341949463
Validation loss: 2.09089135354565

Epoch: 5| Step: 2
Training loss: 2.060529947280884
Validation loss: 2.083975330475838

Epoch: 5| Step: 3
Training loss: 2.703366756439209
Validation loss: 2.1011002320115284

Epoch: 5| Step: 4
Training loss: 2.406764268875122
Validation loss: 2.1326194758056314

Epoch: 5| Step: 5
Training loss: 2.520310163497925
Validation loss: 2.1433703079018542

Epoch: 5| Step: 6
Training loss: 2.1819167137145996
Validation loss: 2.129962077704809

Epoch: 5| Step: 7
Training loss: 2.4926295280456543
Validation loss: 2.110485399923017

Epoch: 5| Step: 8
Training loss: 2.629990339279175
Validation loss: 2.085729550289851

Epoch: 5| Step: 9
Training loss: 2.5144896507263184
Validation loss: 2.0895397419570596

Epoch: 5| Step: 10
Training loss: 2.431103467941284
Validation loss: 2.079464522741174

Epoch: 148| Step: 0
Training loss: 2.724679470062256
Validation loss: 2.0751772144789338

Epoch: 5| Step: 1
Training loss: 2.4902448654174805
Validation loss: 2.0748557839342343

Epoch: 5| Step: 2
Training loss: 2.09934139251709
Validation loss: 2.080440452021937

Epoch: 5| Step: 3
Training loss: 2.3902997970581055
Validation loss: 2.0874121060935398

Epoch: 5| Step: 4
Training loss: 2.4820988178253174
Validation loss: 2.1033800468649915

Epoch: 5| Step: 5
Training loss: 2.134289264678955
Validation loss: 2.11688147821734

Epoch: 5| Step: 6
Training loss: 2.159972667694092
Validation loss: 2.1159940893932054

Epoch: 5| Step: 7
Training loss: 2.1360721588134766
Validation loss: 2.122105416431222

Epoch: 5| Step: 8
Training loss: 2.6660218238830566
Validation loss: 2.1421358021356727

Epoch: 5| Step: 9
Training loss: 2.533235788345337
Validation loss: 2.1544180300927933

Epoch: 5| Step: 10
Training loss: 1.9384585618972778
Validation loss: 2.1601041196494974

Epoch: 149| Step: 0
Training loss: 2.3743839263916016
Validation loss: 2.13460866097481

Epoch: 5| Step: 1
Training loss: 2.7887961864471436
Validation loss: 2.1394502680788756

Epoch: 5| Step: 2
Training loss: 2.0147194862365723
Validation loss: 2.1360273848297777

Epoch: 5| Step: 3
Training loss: 1.4869464635849
Validation loss: 2.1180939289831344

Epoch: 5| Step: 4
Training loss: 2.226464033126831
Validation loss: 2.0948982110587497

Epoch: 5| Step: 5
Training loss: 2.69854736328125
Validation loss: 2.083808027287965

Epoch: 5| Step: 6
Training loss: 2.4555978775024414
Validation loss: 2.094421480291633

Epoch: 5| Step: 7
Training loss: 2.4235050678253174
Validation loss: 2.1041810666361163

Epoch: 5| Step: 8
Training loss: 2.0791049003601074
Validation loss: 2.144656717136342

Epoch: 5| Step: 9
Training loss: 2.5589349269866943
Validation loss: 2.1710993679620887

Epoch: 5| Step: 10
Training loss: 2.6727232933044434
Validation loss: 2.1843718892784527

Epoch: 150| Step: 0
Training loss: 2.1599864959716797
Validation loss: 2.1682747999827066

Epoch: 5| Step: 1
Training loss: 2.5647780895233154
Validation loss: 2.146676581393006

Epoch: 5| Step: 2
Training loss: 2.407602071762085
Validation loss: 2.0984194740172355

Epoch: 5| Step: 3
Training loss: 2.644026517868042
Validation loss: 2.1332465000050043

Epoch: 5| Step: 4
Training loss: 2.1238853931427
Validation loss: 2.1714433521352787

Epoch: 5| Step: 5
Training loss: 2.0778470039367676
Validation loss: 2.226545500498946

Epoch: 5| Step: 6
Training loss: 2.9605555534362793
Validation loss: 2.2351300434399675

Epoch: 5| Step: 7
Training loss: 2.6701908111572266
Validation loss: 2.2547596385402064

Epoch: 5| Step: 8
Training loss: 2.383030414581299
Validation loss: 2.2171819953508276

Epoch: 5| Step: 9
Training loss: 2.10762095451355
Validation loss: 2.177584860914497

Epoch: 5| Step: 10
Training loss: 2.076362371444702
Validation loss: 2.1688306459816555

Epoch: 151| Step: 0
Training loss: 2.311436176300049
Validation loss: 2.1354404816063504

Epoch: 5| Step: 1
Training loss: 2.536675453186035
Validation loss: 2.10889652082997

Epoch: 5| Step: 2
Training loss: 2.228024959564209
Validation loss: 2.078649687510665

Epoch: 5| Step: 3
Training loss: 2.620457887649536
Validation loss: 2.074731626818257

Epoch: 5| Step: 4
Training loss: 1.8992974758148193
Validation loss: 2.091787892003213

Epoch: 5| Step: 5
Training loss: 2.7782301902770996
Validation loss: 2.094001167563982

Epoch: 5| Step: 6
Training loss: 2.9944701194763184
Validation loss: 2.107265813376314

Epoch: 5| Step: 7
Training loss: 1.7365373373031616
Validation loss: 2.1107110618263163

Epoch: 5| Step: 8
Training loss: 1.6725715398788452
Validation loss: 2.115677951484598

Epoch: 5| Step: 9
Training loss: 2.7251811027526855
Validation loss: 2.1156534533346854

Epoch: 5| Step: 10
Training loss: 2.198312759399414
Validation loss: 2.0924396463619765

Epoch: 152| Step: 0
Training loss: 2.4479196071624756
Validation loss: 2.080209885874102

Epoch: 5| Step: 1
Training loss: 2.134361982345581
Validation loss: 2.103540855069314

Epoch: 5| Step: 2
Training loss: 1.9225337505340576
Validation loss: 2.13052535569796

Epoch: 5| Step: 3
Training loss: 2.1634278297424316
Validation loss: 2.153358451781734

Epoch: 5| Step: 4
Training loss: 2.294212818145752
Validation loss: 2.1702500312559065

Epoch: 5| Step: 5
Training loss: 2.542776584625244
Validation loss: 2.119688264785274

Epoch: 5| Step: 6
Training loss: 2.3604254722595215
Validation loss: 2.0895534817890455

Epoch: 5| Step: 7
Training loss: 2.870820999145508
Validation loss: 2.0792143883243686

Epoch: 5| Step: 8
Training loss: 2.1161599159240723
Validation loss: 2.086378921744644

Epoch: 5| Step: 9
Training loss: 2.478919267654419
Validation loss: 2.1006951050091813

Epoch: 5| Step: 10
Training loss: 2.2684738636016846
Validation loss: 2.136674209307599

Epoch: 153| Step: 0
Training loss: 2.160918951034546
Validation loss: 2.1733387695845736

Epoch: 5| Step: 1
Training loss: 2.161416530609131
Validation loss: 2.1956847611294

Epoch: 5| Step: 2
Training loss: 2.132103443145752
Validation loss: 2.222717535111212

Epoch: 5| Step: 3
Training loss: 2.6680383682250977
Validation loss: 2.206390952551237

Epoch: 5| Step: 4
Training loss: 2.3239235877990723
Validation loss: 2.1658569920447563

Epoch: 5| Step: 5
Training loss: 2.269577741622925
Validation loss: 2.138344964673442

Epoch: 5| Step: 6
Training loss: 2.95902681350708
Validation loss: 2.1414754441989365

Epoch: 5| Step: 7
Training loss: 2.690779209136963
Validation loss: 2.2031426391293927

Epoch: 5| Step: 8
Training loss: 2.0626299381256104
Validation loss: 2.2450280522787445

Epoch: 5| Step: 9
Training loss: 2.5555808544158936
Validation loss: 2.2725767730384745

Epoch: 5| Step: 10
Training loss: 1.8516684770584106
Validation loss: 2.284265151587866

Epoch: 154| Step: 0
Training loss: 2.9429121017456055
Validation loss: 2.2965012340135473

Epoch: 5| Step: 1
Training loss: 2.3557801246643066
Validation loss: 2.2885656472175353

Epoch: 5| Step: 2
Training loss: 3.0161595344543457
Validation loss: 2.2235924992510068

Epoch: 5| Step: 3
Training loss: 1.7986633777618408
Validation loss: 2.1764013818515244

Epoch: 5| Step: 4
Training loss: 2.714162826538086
Validation loss: 2.164439534628263

Epoch: 5| Step: 5
Training loss: 1.8589069843292236
Validation loss: 2.1654030853702175

Epoch: 5| Step: 6
Training loss: 1.89517343044281
Validation loss: 2.1871248675930883

Epoch: 5| Step: 7
Training loss: 2.2351744174957275
Validation loss: 2.185970457651282

Epoch: 5| Step: 8
Training loss: 2.639477252960205
Validation loss: 2.1809586863363943

Epoch: 5| Step: 9
Training loss: 2.081765651702881
Validation loss: 2.1499067916665027

Epoch: 5| Step: 10
Training loss: 1.9919629096984863
Validation loss: 2.109232016789016

Epoch: 155| Step: 0
Training loss: 2.7312729358673096
Validation loss: 2.0979937481623825

Epoch: 5| Step: 1
Training loss: 3.074817657470703
Validation loss: 2.0875138749358473

Epoch: 5| Step: 2
Training loss: 2.611778736114502
Validation loss: 2.087703107505716

Epoch: 5| Step: 3
Training loss: 1.878962516784668
Validation loss: 2.0991512947185065

Epoch: 5| Step: 4
Training loss: 2.6713919639587402
Validation loss: 2.110263434789514

Epoch: 5| Step: 5
Training loss: 2.1435399055480957
Validation loss: 2.1098319907342233

Epoch: 5| Step: 6
Training loss: 2.4523587226867676
Validation loss: 2.1236468925270984

Epoch: 5| Step: 7
Training loss: 1.202894687652588
Validation loss: 2.1192731216389644

Epoch: 5| Step: 8
Training loss: 2.6009955406188965
Validation loss: 2.1075499057769775

Epoch: 5| Step: 9
Training loss: 1.8456615209579468
Validation loss: 2.1091516325550694

Epoch: 5| Step: 10
Training loss: 2.0040926933288574
Validation loss: 2.1076412559837423

Epoch: 156| Step: 0
Training loss: 2.486660957336426
Validation loss: 2.096591982790219

Epoch: 5| Step: 1
Training loss: 2.3462843894958496
Validation loss: 2.111345562883603

Epoch: 5| Step: 2
Training loss: 2.5543768405914307
Validation loss: 2.1136315356018724

Epoch: 5| Step: 3
Training loss: 1.8359498977661133
Validation loss: 2.112099761603981

Epoch: 5| Step: 4
Training loss: 2.624321460723877
Validation loss: 2.097443784436872

Epoch: 5| Step: 5
Training loss: 1.7694129943847656
Validation loss: 2.1068813390629266

Epoch: 5| Step: 6
Training loss: 2.5124683380126953
Validation loss: 2.0974286064024894

Epoch: 5| Step: 7
Training loss: 2.298600673675537
Validation loss: 2.1175313521456975

Epoch: 5| Step: 8
Training loss: 2.602193832397461
Validation loss: 2.1267261274399294

Epoch: 5| Step: 9
Training loss: 1.8880935907363892
Validation loss: 2.1299329739744945

Epoch: 5| Step: 10
Training loss: 2.0968308448791504
Validation loss: 2.1329492369005756

Epoch: 157| Step: 0
Training loss: 2.7940433025360107
Validation loss: 2.135154672848281

Epoch: 5| Step: 1
Training loss: 1.8414382934570312
Validation loss: 2.140459975888652

Epoch: 5| Step: 2
Training loss: 2.871324062347412
Validation loss: 2.1227169857230237

Epoch: 5| Step: 3
Training loss: 2.0923542976379395
Validation loss: 2.1294959668190248

Epoch: 5| Step: 4
Training loss: 2.464951992034912
Validation loss: 2.1229130965407177

Epoch: 5| Step: 5
Training loss: 1.3433940410614014
Validation loss: 2.1114406970239457

Epoch: 5| Step: 6
Training loss: 2.583566188812256
Validation loss: 2.119463595010901

Epoch: 5| Step: 7
Training loss: 2.303748607635498
Validation loss: 2.1321686634453396

Epoch: 5| Step: 8
Training loss: 2.260206699371338
Validation loss: 2.1356628197495655

Epoch: 5| Step: 9
Training loss: 2.08442759513855
Validation loss: 2.133077882951306

Epoch: 5| Step: 10
Training loss: 2.1805248260498047
Validation loss: 2.141160927793031

Epoch: 158| Step: 0
Training loss: 1.5721651315689087
Validation loss: 2.146804953134188

Epoch: 5| Step: 1
Training loss: 2.635490894317627
Validation loss: 2.171916748887749

Epoch: 5| Step: 2
Training loss: 2.4432332515716553
Validation loss: 2.174273060214135

Epoch: 5| Step: 3
Training loss: 3.0647284984588623
Validation loss: 2.1551374799461773

Epoch: 5| Step: 4
Training loss: 2.7746124267578125
Validation loss: 2.154907857218096

Epoch: 5| Step: 5
Training loss: 1.3387609720230103
Validation loss: 2.1530919190376037

Epoch: 5| Step: 6
Training loss: 2.9187889099121094
Validation loss: 2.1500168205589376

Epoch: 5| Step: 7
Training loss: 2.032797336578369
Validation loss: 2.136453604185453

Epoch: 5| Step: 8
Training loss: 1.877135992050171
Validation loss: 2.124928500062676

Epoch: 5| Step: 9
Training loss: 2.192894458770752
Validation loss: 2.110693803397558

Epoch: 5| Step: 10
Training loss: 1.5640002489089966
Validation loss: 2.117988283916186

Epoch: 159| Step: 0
Training loss: 2.582953929901123
Validation loss: 2.095282176489471

Epoch: 5| Step: 1
Training loss: 1.715266466140747
Validation loss: 2.0957143101640927

Epoch: 5| Step: 2
Training loss: 1.8175491094589233
Validation loss: 2.0853092285894577

Epoch: 5| Step: 3
Training loss: 2.7749478816986084
Validation loss: 2.105136033027403

Epoch: 5| Step: 4
Training loss: 2.6084914207458496
Validation loss: 2.1126657532107447

Epoch: 5| Step: 5
Training loss: 2.409710645675659
Validation loss: 2.1118986298961024

Epoch: 5| Step: 6
Training loss: 2.2795464992523193
Validation loss: 2.111189894778754

Epoch: 5| Step: 7
Training loss: 2.1804862022399902
Validation loss: 2.12703533839154

Epoch: 5| Step: 8
Training loss: 1.9374958276748657
Validation loss: 2.1122897671115015

Epoch: 5| Step: 9
Training loss: 2.2334728240966797
Validation loss: 2.1105584175355974

Epoch: 5| Step: 10
Training loss: 1.9671218395233154
Validation loss: 2.1070379159783803

Epoch: 160| Step: 0
Training loss: 2.419100284576416
Validation loss: 2.11631683124009

Epoch: 5| Step: 1
Training loss: 2.2002205848693848
Validation loss: 2.114722751802014

Epoch: 5| Step: 2
Training loss: 2.2803456783294678
Validation loss: 2.108037543553178

Epoch: 5| Step: 3
Training loss: 2.3167574405670166
Validation loss: 2.1254766448851554

Epoch: 5| Step: 4
Training loss: 2.223404884338379
Validation loss: 2.13518694139296

Epoch: 5| Step: 5
Training loss: 1.8892230987548828
Validation loss: 2.154607526717647

Epoch: 5| Step: 6
Training loss: 2.665694236755371
Validation loss: 2.1748842859780915

Epoch: 5| Step: 7
Training loss: 2.0475382804870605
Validation loss: 2.1841343795099566

Epoch: 5| Step: 8
Training loss: 2.267430067062378
Validation loss: 2.1437051847416866

Epoch: 5| Step: 9
Training loss: 2.015730619430542
Validation loss: 2.122880356286162

Epoch: 5| Step: 10
Training loss: 2.2287981510162354
Validation loss: 2.105674102742185

Epoch: 161| Step: 0
Training loss: 2.5301690101623535
Validation loss: 2.094849007104033

Epoch: 5| Step: 1
Training loss: 2.349350929260254
Validation loss: 2.084387069107384

Epoch: 5| Step: 2
Training loss: 1.9367046356201172
Validation loss: 2.080951807319477

Epoch: 5| Step: 3
Training loss: 2.4026684761047363
Validation loss: 2.0729966804545414

Epoch: 5| Step: 4
Training loss: 2.392284870147705
Validation loss: 2.077492014054329

Epoch: 5| Step: 5
Training loss: 2.408869504928589
Validation loss: 2.07177524541014

Epoch: 5| Step: 6
Training loss: 2.383270502090454
Validation loss: 2.062714058865783

Epoch: 5| Step: 7
Training loss: 2.119117021560669
Validation loss: 2.0582618598015077

Epoch: 5| Step: 8
Training loss: 2.2250616550445557
Validation loss: 2.056209594972672

Epoch: 5| Step: 9
Training loss: 1.993757963180542
Validation loss: 2.0695529830071235

Epoch: 5| Step: 10
Training loss: 1.8781050443649292
Validation loss: 2.0745147389750325

Epoch: 162| Step: 0
Training loss: 1.9044605493545532
Validation loss: 2.0855170193538872

Epoch: 5| Step: 1
Training loss: 2.1086907386779785
Validation loss: 2.095883842437498

Epoch: 5| Step: 2
Training loss: 2.7834792137145996
Validation loss: 2.112642393317274

Epoch: 5| Step: 3
Training loss: 2.771190881729126
Validation loss: 2.1276692421205583

Epoch: 5| Step: 4
Training loss: 1.9980980157852173
Validation loss: 2.123404138831682

Epoch: 5| Step: 5
Training loss: 2.5694241523742676
Validation loss: 2.1514109744820544

Epoch: 5| Step: 6
Training loss: 1.7208410501480103
Validation loss: 2.146069529236004

Epoch: 5| Step: 7
Training loss: 2.264648914337158
Validation loss: 2.155223624680632

Epoch: 5| Step: 8
Training loss: 2.8141276836395264
Validation loss: 2.1630349159240723

Epoch: 5| Step: 9
Training loss: 1.5587178468704224
Validation loss: 2.142610808854462

Epoch: 5| Step: 10
Training loss: 1.8547325134277344
Validation loss: 2.12845128966916

Epoch: 163| Step: 0
Training loss: 2.3407187461853027
Validation loss: 2.111367984484601

Epoch: 5| Step: 1
Training loss: 2.4154982566833496
Validation loss: 2.1002035243536836

Epoch: 5| Step: 2
Training loss: 2.0583677291870117
Validation loss: 2.1012543785956597

Epoch: 5| Step: 3
Training loss: 2.1194324493408203
Validation loss: 2.1029341425946964

Epoch: 5| Step: 4
Training loss: 2.2317535877227783
Validation loss: 2.123810109271798

Epoch: 5| Step: 5
Training loss: 2.07969331741333
Validation loss: 2.1258749192760837

Epoch: 5| Step: 6
Training loss: 2.029052972793579
Validation loss: 2.1500855069006644

Epoch: 5| Step: 7
Training loss: 2.683750629425049
Validation loss: 2.153578427530104

Epoch: 5| Step: 8
Training loss: 1.851477026939392
Validation loss: 2.1342513227975495

Epoch: 5| Step: 9
Training loss: 2.353381395339966
Validation loss: 2.091547655802901

Epoch: 5| Step: 10
Training loss: 1.9712663888931274
Validation loss: 2.0849285664096957

Epoch: 164| Step: 0
Training loss: 1.8454116582870483
Validation loss: 2.0932424170996553

Epoch: 5| Step: 1
Training loss: 2.320194721221924
Validation loss: 2.0970209106322257

Epoch: 5| Step: 2
Training loss: 2.218449115753174
Validation loss: 2.095017651075958

Epoch: 5| Step: 3
Training loss: 2.353783369064331
Validation loss: 2.0761932429446968

Epoch: 5| Step: 4
Training loss: 2.631108283996582
Validation loss: 2.072974189635246

Epoch: 5| Step: 5
Training loss: 2.2796387672424316
Validation loss: 2.065910040691335

Epoch: 5| Step: 6
Training loss: 1.890237808227539
Validation loss: 2.0654180178078274

Epoch: 5| Step: 7
Training loss: 2.1761186122894287
Validation loss: 2.0671571621330838

Epoch: 5| Step: 8
Training loss: 2.126865863800049
Validation loss: 2.0738153765278478

Epoch: 5| Step: 9
Training loss: 2.1993980407714844
Validation loss: 2.0856572325511644

Epoch: 5| Step: 10
Training loss: 2.4703285694122314
Validation loss: 2.086507284513084

Epoch: 165| Step: 0
Training loss: 1.7857751846313477
Validation loss: 2.0790707603577645

Epoch: 5| Step: 1
Training loss: 2.380652666091919
Validation loss: 2.0747102691281225

Epoch: 5| Step: 2
Training loss: 1.9088283777236938
Validation loss: 2.085658670753561

Epoch: 5| Step: 3
Training loss: 2.5688815116882324
Validation loss: 2.0752872228622437

Epoch: 5| Step: 4
Training loss: 1.8847033977508545
Validation loss: 2.0872812296754573

Epoch: 5| Step: 5
Training loss: 2.183570384979248
Validation loss: 2.095139152260237

Epoch: 5| Step: 6
Training loss: 2.2958741188049316
Validation loss: 2.0863009947602467

Epoch: 5| Step: 7
Training loss: 2.176908016204834
Validation loss: 2.0820269405200915

Epoch: 5| Step: 8
Training loss: 2.703697681427002
Validation loss: 2.104630590766989

Epoch: 5| Step: 9
Training loss: 2.13856840133667
Validation loss: 2.0956071704946537

Epoch: 5| Step: 10
Training loss: 2.3138277530670166
Validation loss: 2.0994035608025006

Epoch: 166| Step: 0
Training loss: 1.8884834051132202
Validation loss: 2.1058109344974643

Epoch: 5| Step: 1
Training loss: 2.241877794265747
Validation loss: 2.1077660129916285

Epoch: 5| Step: 2
Training loss: 2.5431549549102783
Validation loss: 2.113165097851907

Epoch: 5| Step: 3
Training loss: 1.9875733852386475
Validation loss: 2.121831058174051

Epoch: 5| Step: 4
Training loss: 1.924721121788025
Validation loss: 2.1484972994814635

Epoch: 5| Step: 5
Training loss: 2.2142081260681152
Validation loss: 2.1436662584222774

Epoch: 5| Step: 6
Training loss: 2.177873134613037
Validation loss: 2.1389030359124623

Epoch: 5| Step: 7
Training loss: 2.4330055713653564
Validation loss: 2.130325284055484

Epoch: 5| Step: 8
Training loss: 1.8400100469589233
Validation loss: 2.128599468097892

Epoch: 5| Step: 9
Training loss: 2.2431540489196777
Validation loss: 2.1063980953667754

Epoch: 5| Step: 10
Training loss: 2.4039885997772217
Validation loss: 2.0875203250556864

Epoch: 167| Step: 0
Training loss: 2.583446502685547
Validation loss: 2.089000981341126

Epoch: 5| Step: 1
Training loss: 1.7228809595108032
Validation loss: 2.0817966768818517

Epoch: 5| Step: 2
Training loss: 2.655304431915283
Validation loss: 2.0982190511559926

Epoch: 5| Step: 3
Training loss: 1.6752803325653076
Validation loss: 2.0967476547405286

Epoch: 5| Step: 4
Training loss: 1.7760913372039795
Validation loss: 2.1048888467973277

Epoch: 5| Step: 5
Training loss: 2.6689603328704834
Validation loss: 2.137262625079001

Epoch: 5| Step: 6
Training loss: 2.093581438064575
Validation loss: 2.1402325873733847

Epoch: 5| Step: 7
Training loss: 2.000887632369995
Validation loss: 2.140006572969498

Epoch: 5| Step: 8
Training loss: 2.3690435886383057
Validation loss: 2.145833833243257

Epoch: 5| Step: 9
Training loss: 2.177210569381714
Validation loss: 2.1477656261895293

Epoch: 5| Step: 10
Training loss: 1.8469109535217285
Validation loss: 2.1724671048502766

Epoch: 168| Step: 0
Training loss: 2.2880547046661377
Validation loss: 2.182557570037021

Epoch: 5| Step: 1
Training loss: 2.2003371715545654
Validation loss: 2.1904189509730183

Epoch: 5| Step: 2
Training loss: 2.4169869422912598
Validation loss: 2.1928969249930432

Epoch: 5| Step: 3
Training loss: 1.5811437368392944
Validation loss: 2.1599359640511135

Epoch: 5| Step: 4
Training loss: 1.8259437084197998
Validation loss: 2.1439580071356987

Epoch: 5| Step: 5
Training loss: 2.1061806678771973
Validation loss: 2.120536267116506

Epoch: 5| Step: 6
Training loss: 1.9907222986221313
Validation loss: 2.109149771351968

Epoch: 5| Step: 7
Training loss: 2.85172176361084
Validation loss: 2.090832605156847

Epoch: 5| Step: 8
Training loss: 2.1769325733184814
Validation loss: 2.0869032541910806

Epoch: 5| Step: 9
Training loss: 1.7882696390151978
Validation loss: 2.074670091752083

Epoch: 5| Step: 10
Training loss: 2.328315258026123
Validation loss: 2.0796712034492084

Epoch: 169| Step: 0
Training loss: 2.5730228424072266
Validation loss: 2.094362340947633

Epoch: 5| Step: 1
Training loss: 1.850885033607483
Validation loss: 2.0952701491694294

Epoch: 5| Step: 2
Training loss: 2.5506210327148438
Validation loss: 2.09910398913968

Epoch: 5| Step: 3
Training loss: 1.9505119323730469
Validation loss: 2.1041537933452155

Epoch: 5| Step: 4
Training loss: 1.8787117004394531
Validation loss: 2.1119240201929563

Epoch: 5| Step: 5
Training loss: 1.7508186101913452
Validation loss: 2.1112508235439176

Epoch: 5| Step: 6
Training loss: 1.795357346534729
Validation loss: 2.113079196663313

Epoch: 5| Step: 7
Training loss: 2.3893113136291504
Validation loss: 2.1147849072692213

Epoch: 5| Step: 8
Training loss: 2.0580947399139404
Validation loss: 2.115432439311858

Epoch: 5| Step: 9
Training loss: 2.6757190227508545
Validation loss: 2.1393762173191195

Epoch: 5| Step: 10
Training loss: 1.7996611595153809
Validation loss: 2.141768863124232

Epoch: 170| Step: 0
Training loss: 1.9655685424804688
Validation loss: 2.1420689167514926

Epoch: 5| Step: 1
Training loss: 2.0287299156188965
Validation loss: 2.150361676369944

Epoch: 5| Step: 2
Training loss: 2.3335981369018555
Validation loss: 2.143088927832983

Epoch: 5| Step: 3
Training loss: 2.049801826477051
Validation loss: 2.128849826833253

Epoch: 5| Step: 4
Training loss: 1.8219178915023804
Validation loss: 2.121216699641238

Epoch: 5| Step: 5
Training loss: 2.3645050525665283
Validation loss: 2.1310483037784533

Epoch: 5| Step: 6
Training loss: 2.252516508102417
Validation loss: 2.1296755652273855

Epoch: 5| Step: 7
Training loss: 1.7003341913223267
Validation loss: 2.135775089263916

Epoch: 5| Step: 8
Training loss: 2.2130227088928223
Validation loss: 2.1356195993320917

Epoch: 5| Step: 9
Training loss: 1.8343614339828491
Validation loss: 2.1120873228196175

Epoch: 5| Step: 10
Training loss: 2.484680414199829
Validation loss: 2.1083342131747993

Epoch: 171| Step: 0
Training loss: 2.353100061416626
Validation loss: 2.091447468726866

Epoch: 5| Step: 1
Training loss: 1.5583347082138062
Validation loss: 2.102128626197897

Epoch: 5| Step: 2
Training loss: 2.322141170501709
Validation loss: 2.0901652510448168

Epoch: 5| Step: 3
Training loss: 1.5399667024612427
Validation loss: 2.0963416355912403

Epoch: 5| Step: 4
Training loss: 2.0343575477600098
Validation loss: 2.1060265148839643

Epoch: 5| Step: 5
Training loss: 2.5818846225738525
Validation loss: 2.119823521183383

Epoch: 5| Step: 6
Training loss: 2.045973062515259
Validation loss: 2.1181903180255683

Epoch: 5| Step: 7
Training loss: 2.643087863922119
Validation loss: 2.1376337159064507

Epoch: 5| Step: 8
Training loss: 1.9256610870361328
Validation loss: 2.1191744599291074

Epoch: 5| Step: 9
Training loss: 2.1999871730804443
Validation loss: 2.1322994488541798

Epoch: 5| Step: 10
Training loss: 1.6538465023040771
Validation loss: 2.133601306587137

Epoch: 172| Step: 0
Training loss: 1.935882806777954
Validation loss: 2.1352755908043153

Epoch: 5| Step: 1
Training loss: 2.394787549972534
Validation loss: 2.131952880531229

Epoch: 5| Step: 2
Training loss: 2.3220338821411133
Validation loss: 2.1351216967387865

Epoch: 5| Step: 3
Training loss: 2.0703036785125732
Validation loss: 2.1881181681027977

Epoch: 5| Step: 4
Training loss: 1.9632384777069092
Validation loss: 2.178080766431747

Epoch: 5| Step: 5
Training loss: 2.1592140197753906
Validation loss: 2.170293956674555

Epoch: 5| Step: 6
Training loss: 1.8964788913726807
Validation loss: 2.1399554514115855

Epoch: 5| Step: 7
Training loss: 1.763100028038025
Validation loss: 2.1279527089929067

Epoch: 5| Step: 8
Training loss: 2.0550174713134766
Validation loss: 2.1129742283974924

Epoch: 5| Step: 9
Training loss: 2.346613645553589
Validation loss: 2.1224298451536443

Epoch: 5| Step: 10
Training loss: 1.6974493265151978
Validation loss: 2.10242324490701

Epoch: 173| Step: 0
Training loss: 2.185537815093994
Validation loss: 2.100549174893287

Epoch: 5| Step: 1
Training loss: 1.3880342245101929
Validation loss: 2.0942497150872343

Epoch: 5| Step: 2
Training loss: 2.3060173988342285
Validation loss: 2.0847790677060365

Epoch: 5| Step: 3
Training loss: 1.9344213008880615
Validation loss: 2.1126817400737474

Epoch: 5| Step: 4
Training loss: 2.7292087078094482
Validation loss: 2.1077050931992067

Epoch: 5| Step: 5
Training loss: 2.1187312602996826
Validation loss: 2.087953326522663

Epoch: 5| Step: 6
Training loss: 1.9451824426651
Validation loss: 2.0934960226858816

Epoch: 5| Step: 7
Training loss: 2.2646279335021973
Validation loss: 2.095128297805786

Epoch: 5| Step: 8
Training loss: 1.7320448160171509
Validation loss: 2.0901231432473786

Epoch: 5| Step: 9
Training loss: 1.9132598638534546
Validation loss: 2.0948718196602276

Epoch: 5| Step: 10
Training loss: 1.9686869382858276
Validation loss: 2.0981026593075005

Epoch: 174| Step: 0
Training loss: 1.8267886638641357
Validation loss: 2.1039038345377934

Epoch: 5| Step: 1
Training loss: 1.8577800989151
Validation loss: 2.123390466936173

Epoch: 5| Step: 2
Training loss: 2.3660929203033447
Validation loss: 2.1336936796865156

Epoch: 5| Step: 3
Training loss: 2.280172824859619
Validation loss: 2.1264550814064602

Epoch: 5| Step: 4
Training loss: 2.091193199157715
Validation loss: 2.121152465061475

Epoch: 5| Step: 5
Training loss: 1.9287288188934326
Validation loss: 2.131347007648919

Epoch: 5| Step: 6
Training loss: 1.5418287515640259
Validation loss: 2.1063481646199382

Epoch: 5| Step: 7
Training loss: 2.4435062408447266
Validation loss: 2.0896624288251324

Epoch: 5| Step: 8
Training loss: 2.1625640392303467
Validation loss: 2.078769042927732

Epoch: 5| Step: 9
Training loss: 1.9591724872589111
Validation loss: 2.0726673679967083

Epoch: 5| Step: 10
Training loss: 1.9622106552124023
Validation loss: 2.0466725826263428

Epoch: 175| Step: 0
Training loss: 1.6774446964263916
Validation loss: 2.0378348494088776

Epoch: 5| Step: 1
Training loss: 1.458865761756897
Validation loss: 2.0331782128221247

Epoch: 5| Step: 2
Training loss: 2.689661979675293
Validation loss: 2.032398173885961

Epoch: 5| Step: 3
Training loss: 3.017026901245117
Validation loss: 2.03877499283001

Epoch: 5| Step: 4
Training loss: 1.6556898355484009
Validation loss: 2.0514948060435634

Epoch: 5| Step: 5
Training loss: 2.466545343399048
Validation loss: 2.085047661617238

Epoch: 5| Step: 6
Training loss: 2.1393351554870605
Validation loss: 2.106354293002877

Epoch: 5| Step: 7
Training loss: 2.035918712615967
Validation loss: 2.1243272071243613

Epoch: 5| Step: 8
Training loss: 1.5915324687957764
Validation loss: 2.1252074600547872

Epoch: 5| Step: 9
Training loss: 1.5367317199707031
Validation loss: 2.094687964326592

Epoch: 5| Step: 10
Training loss: 2.413761615753174
Validation loss: 2.1004479033972627

Epoch: 176| Step: 0
Training loss: 2.1635422706604004
Validation loss: 2.11480591886787

Epoch: 5| Step: 1
Training loss: 2.4212582111358643
Validation loss: 2.119466913643704

Epoch: 5| Step: 2
Training loss: 2.0507171154022217
Validation loss: 2.129818506138299

Epoch: 5| Step: 3
Training loss: 1.021681308746338
Validation loss: 2.12443874215567

Epoch: 5| Step: 4
Training loss: 1.9597431421279907
Validation loss: 2.119661613177228

Epoch: 5| Step: 5
Training loss: 2.3840889930725098
Validation loss: 2.1276822295240176

Epoch: 5| Step: 6
Training loss: 2.0752930641174316
Validation loss: 2.1499244936050905

Epoch: 5| Step: 7
Training loss: 2.1346707344055176
Validation loss: 2.170533750646858

Epoch: 5| Step: 8
Training loss: 2.4997811317443848
Validation loss: 2.199783230340609

Epoch: 5| Step: 9
Training loss: 1.7506577968597412
Validation loss: 2.1665503850547214

Epoch: 5| Step: 10
Training loss: 2.383561611175537
Validation loss: 2.1047535762991956

Epoch: 177| Step: 0
Training loss: 1.9681953191757202
Validation loss: 2.0723456746788433

Epoch: 5| Step: 1
Training loss: 2.337667942047119
Validation loss: 2.069394682043342

Epoch: 5| Step: 2
Training loss: 1.5840460062026978
Validation loss: 2.086227363155734

Epoch: 5| Step: 3
Training loss: 2.124596118927002
Validation loss: 2.098715236110072

Epoch: 5| Step: 4
Training loss: 2.5243237018585205
Validation loss: 2.0998232185199694

Epoch: 5| Step: 5
Training loss: 1.7023462057113647
Validation loss: 2.1084094611547326

Epoch: 5| Step: 6
Training loss: 2.596590995788574
Validation loss: 2.091826328667261

Epoch: 5| Step: 7
Training loss: 1.6260881423950195
Validation loss: 2.089128166116694

Epoch: 5| Step: 8
Training loss: 2.2929632663726807
Validation loss: 2.0950890920495473

Epoch: 5| Step: 9
Training loss: 1.652121901512146
Validation loss: 2.139360499638383

Epoch: 5| Step: 10
Training loss: 1.9302955865859985
Validation loss: 2.1427340738234983

Epoch: 178| Step: 0
Training loss: 2.231696128845215
Validation loss: 2.1005880781399306

Epoch: 5| Step: 1
Training loss: 2.4288315773010254
Validation loss: 2.0845348104353874

Epoch: 5| Step: 2
Training loss: 1.799298644065857
Validation loss: 2.0782637570493963

Epoch: 5| Step: 3
Training loss: 2.2775774002075195
Validation loss: 2.079083809288599

Epoch: 5| Step: 4
Training loss: 1.8363758325576782
Validation loss: 2.066840963978921

Epoch: 5| Step: 5
Training loss: 2.1104342937469482
Validation loss: 2.050389733365787

Epoch: 5| Step: 6
Training loss: 2.2327301502227783
Validation loss: 2.0331332119562293

Epoch: 5| Step: 7
Training loss: 1.3161884546279907
Validation loss: 2.034350082438479

Epoch: 5| Step: 8
Training loss: 1.8728004693984985
Validation loss: 2.041216154252329

Epoch: 5| Step: 9
Training loss: 2.0667176246643066
Validation loss: 2.026363447148313

Epoch: 5| Step: 10
Training loss: 2.0328571796417236
Validation loss: 2.0273963161694106

Epoch: 179| Step: 0
Training loss: 1.8030202388763428
Validation loss: 2.0631919855712564

Epoch: 5| Step: 1
Training loss: 2.256420612335205
Validation loss: 2.0901864497892317

Epoch: 5| Step: 2
Training loss: 1.5337094068527222
Validation loss: 2.1369547254295758

Epoch: 5| Step: 3
Training loss: 1.2919256687164307
Validation loss: 2.1766830234117407

Epoch: 5| Step: 4
Training loss: 1.9368396997451782
Validation loss: 2.1744681968483874

Epoch: 5| Step: 5
Training loss: 1.509421944618225
Validation loss: 2.159499119686824

Epoch: 5| Step: 6
Training loss: 1.7381407022476196
Validation loss: 2.1626871734537105

Epoch: 5| Step: 7
Training loss: 1.9638195037841797
Validation loss: 2.1760284182845906

Epoch: 5| Step: 8
Training loss: 2.8926053047180176
Validation loss: 2.1848950232228925

Epoch: 5| Step: 9
Training loss: 2.158242702484131
Validation loss: 2.185759764845653

Epoch: 5| Step: 10
Training loss: 3.3856050968170166
Validation loss: 2.1752198075735443

Epoch: 180| Step: 0
Training loss: 2.0660293102264404
Validation loss: 2.149334846004363

Epoch: 5| Step: 1
Training loss: 2.3142647743225098
Validation loss: 2.109200907009904

Epoch: 5| Step: 2
Training loss: 1.1063969135284424
Validation loss: 2.1006614418439966

Epoch: 5| Step: 3
Training loss: 2.226426362991333
Validation loss: 2.095457746136573

Epoch: 5| Step: 4
Training loss: 1.1390440464019775
Validation loss: 2.094923820546878

Epoch: 5| Step: 5
Training loss: 1.7851974964141846
Validation loss: 2.082897655425533

Epoch: 5| Step: 6
Training loss: 2.6218998432159424
Validation loss: 2.0600644747416177

Epoch: 5| Step: 7
Training loss: 2.215430498123169
Validation loss: 2.048209027577472

Epoch: 5| Step: 8
Training loss: 2.3129303455352783
Validation loss: 2.0343999439670193

Epoch: 5| Step: 9
Training loss: 2.2059733867645264
Validation loss: 2.026707767158426

Epoch: 5| Step: 10
Training loss: 2.206921339035034
Validation loss: 2.0315090840862644

Epoch: 181| Step: 0
Training loss: 2.0558600425720215
Validation loss: 2.0638232833595684

Epoch: 5| Step: 1
Training loss: 1.7534936666488647
Validation loss: 2.078546649666243

Epoch: 5| Step: 2
Training loss: 2.210165023803711
Validation loss: 2.064622538064116

Epoch: 5| Step: 3
Training loss: 1.7097399234771729
Validation loss: 2.0535505381963586

Epoch: 5| Step: 4
Training loss: 2.3064472675323486
Validation loss: 2.076998508104714

Epoch: 5| Step: 5
Training loss: 2.237914800643921
Validation loss: 2.0843407620665846

Epoch: 5| Step: 6
Training loss: 1.8742008209228516
Validation loss: 2.112791176765196

Epoch: 5| Step: 7
Training loss: 2.2408828735351562
Validation loss: 2.1459662555366434

Epoch: 5| Step: 8
Training loss: 2.0186586380004883
Validation loss: 2.152494148541522

Epoch: 5| Step: 9
Training loss: 1.451161503791809
Validation loss: 2.1257073046058736

Epoch: 5| Step: 10
Training loss: 2.059499979019165
Validation loss: 2.1307549027986425

Epoch: 182| Step: 0
Training loss: 1.8865712881088257
Validation loss: 2.1382425446664133

Epoch: 5| Step: 1
Training loss: 1.7405927181243896
Validation loss: 2.1206607293057185

Epoch: 5| Step: 2
Training loss: 2.594029188156128
Validation loss: 2.1206003312141664

Epoch: 5| Step: 3
Training loss: 2.050665855407715
Validation loss: 2.088163318172578

Epoch: 5| Step: 4
Training loss: 2.030557632446289
Validation loss: 2.084158069343977

Epoch: 5| Step: 5
Training loss: 1.855277419090271
Validation loss: 2.0747102640008412

Epoch: 5| Step: 6
Training loss: 1.8977069854736328
Validation loss: 2.087734221130289

Epoch: 5| Step: 7
Training loss: 1.5591245889663696
Validation loss: 2.101996152631698

Epoch: 5| Step: 8
Training loss: 1.8418724536895752
Validation loss: 2.1034002368168165

Epoch: 5| Step: 9
Training loss: 2.4969897270202637
Validation loss: 2.1168586746338875

Epoch: 5| Step: 10
Training loss: 2.0675907135009766
Validation loss: 2.1407150658228065

Epoch: 183| Step: 0
Training loss: 2.1070094108581543
Validation loss: 2.1435775795290546

Epoch: 5| Step: 1
Training loss: 2.053419828414917
Validation loss: 2.1412960021726546

Epoch: 5| Step: 2
Training loss: 2.007969379425049
Validation loss: 2.1242965165004937

Epoch: 5| Step: 3
Training loss: 2.164696216583252
Validation loss: 2.1273510622721847

Epoch: 5| Step: 4
Training loss: 1.734869360923767
Validation loss: 2.1259706045991633

Epoch: 5| Step: 5
Training loss: 1.949149489402771
Validation loss: 2.1222897627020396

Epoch: 5| Step: 6
Training loss: 1.953515648841858
Validation loss: 2.1195019188747612

Epoch: 5| Step: 7
Training loss: 1.9470371007919312
Validation loss: 2.1178689490082445

Epoch: 5| Step: 8
Training loss: 1.5994958877563477
Validation loss: 2.1129516619507984

Epoch: 5| Step: 9
Training loss: 1.7603117227554321
Validation loss: 2.111224297554262

Epoch: 5| Step: 10
Training loss: 2.2825469970703125
Validation loss: 2.1135102728361725

Epoch: 184| Step: 0
Training loss: 2.979015827178955
Validation loss: 2.121553260792968

Epoch: 5| Step: 1
Training loss: 2.1959662437438965
Validation loss: 2.1165309721423733

Epoch: 5| Step: 2
Training loss: 1.918657898902893
Validation loss: 2.0854571032267746

Epoch: 5| Step: 3
Training loss: 2.0994715690612793
Validation loss: 2.089802416422034

Epoch: 5| Step: 4
Training loss: 1.8222482204437256
Validation loss: 2.0869761564398326

Epoch: 5| Step: 5
Training loss: 1.6777575016021729
Validation loss: 2.0634094310063187

Epoch: 5| Step: 6
Training loss: 1.6143327951431274
Validation loss: 2.0776878326169905

Epoch: 5| Step: 7
Training loss: 2.2197766304016113
Validation loss: 2.084319837631718

Epoch: 5| Step: 8
Training loss: 1.4039161205291748
Validation loss: 2.0753452700953328

Epoch: 5| Step: 9
Training loss: 1.6283607482910156
Validation loss: 2.100880272926823

Epoch: 5| Step: 10
Training loss: 1.8842782974243164
Validation loss: 2.1286932140268306

Epoch: 185| Step: 0
Training loss: 2.100424289703369
Validation loss: 2.1348086018716135

Epoch: 5| Step: 1
Training loss: 1.9549071788787842
Validation loss: 2.1061252163302515

Epoch: 5| Step: 2
Training loss: 1.5770766735076904
Validation loss: 2.12133833541665

Epoch: 5| Step: 3
Training loss: 2.087404727935791
Validation loss: 2.1161443982073056

Epoch: 5| Step: 4
Training loss: 1.9352824687957764
Validation loss: 2.1258848456926245

Epoch: 5| Step: 5
Training loss: 1.6786826848983765
Validation loss: 2.116147565585311

Epoch: 5| Step: 6
Training loss: 1.8571363687515259
Validation loss: 2.1434771886435886

Epoch: 5| Step: 7
Training loss: 1.6709823608398438
Validation loss: 2.11717616486293

Epoch: 5| Step: 8
Training loss: 2.1144802570343018
Validation loss: 2.1093916098276773

Epoch: 5| Step: 9
Training loss: 1.7994663715362549
Validation loss: 2.1109830794795865

Epoch: 5| Step: 10
Training loss: 2.494277000427246
Validation loss: 2.094420631726583

Epoch: 186| Step: 0
Training loss: 2.1091742515563965
Validation loss: 2.0823293193694083

Epoch: 5| Step: 1
Training loss: 1.9804697036743164
Validation loss: 2.067192292982532

Epoch: 5| Step: 2
Training loss: 2.171933889389038
Validation loss: 2.098010109316918

Epoch: 5| Step: 3
Training loss: 2.075087070465088
Validation loss: 2.1217925497280654

Epoch: 5| Step: 4
Training loss: 1.5439175367355347
Validation loss: 2.1333582452548447

Epoch: 5| Step: 5
Training loss: 1.7036120891571045
Validation loss: 2.1363643138639388

Epoch: 5| Step: 6
Training loss: 1.646307349205017
Validation loss: 2.139966577611944

Epoch: 5| Step: 7
Training loss: 1.4918705224990845
Validation loss: 2.1131182280919885

Epoch: 5| Step: 8
Training loss: 2.200542688369751
Validation loss: 2.1021075863992014

Epoch: 5| Step: 9
Training loss: 2.3260438442230225
Validation loss: 2.117560622512653

Epoch: 5| Step: 10
Training loss: 1.802247166633606
Validation loss: 2.111714163134175

Epoch: 187| Step: 0
Training loss: 1.8347556591033936
Validation loss: 2.0960871147853073

Epoch: 5| Step: 1
Training loss: 2.5911507606506348
Validation loss: 2.1054175643510717

Epoch: 5| Step: 2
Training loss: 1.5986545085906982
Validation loss: 2.0919686261043755

Epoch: 5| Step: 3
Training loss: 2.1832308769226074
Validation loss: 2.0909513606820056

Epoch: 5| Step: 4
Training loss: 1.3416876792907715
Validation loss: 2.1353933298459618

Epoch: 5| Step: 5
Training loss: 2.3547770977020264
Validation loss: 2.1755223428049395

Epoch: 5| Step: 6
Training loss: 2.0193705558776855
Validation loss: 2.1603160083934827

Epoch: 5| Step: 7
Training loss: 1.8373435735702515
Validation loss: 2.092382977085729

Epoch: 5| Step: 8
Training loss: 1.3322298526763916
Validation loss: 2.0549303472682996

Epoch: 5| Step: 9
Training loss: 2.0903258323669434
Validation loss: 2.0431342150575373

Epoch: 5| Step: 10
Training loss: 2.3992867469787598
Validation loss: 2.0627077638462024

Epoch: 188| Step: 0
Training loss: 1.3632832765579224
Validation loss: 2.058892006515175

Epoch: 5| Step: 1
Training loss: 2.301173686981201
Validation loss: 2.040644468799714

Epoch: 5| Step: 2
Training loss: 2.166273593902588
Validation loss: 2.0497029673668647

Epoch: 5| Step: 3
Training loss: 1.4810574054718018
Validation loss: 2.0690738795905985

Epoch: 5| Step: 4
Training loss: 2.2378201484680176
Validation loss: 2.1117184931232083

Epoch: 5| Step: 5
Training loss: 1.9381183385849
Validation loss: 2.1514544179362636

Epoch: 5| Step: 6
Training loss: 2.193923234939575
Validation loss: 2.1392731076927594

Epoch: 5| Step: 7
Training loss: 2.3584463596343994
Validation loss: 2.128192094064528

Epoch: 5| Step: 8
Training loss: 2.30757212638855
Validation loss: 2.1577948767651796

Epoch: 5| Step: 9
Training loss: 1.5769942998886108
Validation loss: 2.1453308008050405

Epoch: 5| Step: 10
Training loss: 1.2279399633407593
Validation loss: 2.1264951088095225

Epoch: 189| Step: 0
Training loss: 1.8738609552383423
Validation loss: 2.107749959473969

Epoch: 5| Step: 1
Training loss: 1.3980454206466675
Validation loss: 2.091388069173341

Epoch: 5| Step: 2
Training loss: 1.900452971458435
Validation loss: 2.0629891785242225

Epoch: 5| Step: 3
Training loss: 2.1196208000183105
Validation loss: 2.0302865274490847

Epoch: 5| Step: 4
Training loss: 2.2590935230255127
Validation loss: 2.01443911111483

Epoch: 5| Step: 5
Training loss: 2.1034858226776123
Validation loss: 2.008656951688951

Epoch: 5| Step: 6
Training loss: 2.066025733947754
Validation loss: 1.9851995591194398

Epoch: 5| Step: 7
Training loss: 1.99123215675354
Validation loss: 1.97795989436488

Epoch: 5| Step: 8
Training loss: 1.6386563777923584
Validation loss: 1.987221008987837

Epoch: 5| Step: 9
Training loss: 1.8976185321807861
Validation loss: 1.9985393670297438

Epoch: 5| Step: 10
Training loss: 2.279871940612793
Validation loss: 2.0321724427643644

Epoch: 190| Step: 0
Training loss: 1.6045951843261719
Validation loss: 2.0526193136809976

Epoch: 5| Step: 1
Training loss: 2.4694881439208984
Validation loss: 2.09511742156039

Epoch: 5| Step: 2
Training loss: 2.4137871265411377
Validation loss: 2.1422124370451896

Epoch: 5| Step: 3
Training loss: 1.9463565349578857
Validation loss: 2.142281457942019

Epoch: 5| Step: 4
Training loss: 1.977447509765625
Validation loss: 2.152405179956908

Epoch: 5| Step: 5
Training loss: 1.8364503383636475
Validation loss: 2.1584156482450423

Epoch: 5| Step: 6
Training loss: 1.5401747226715088
Validation loss: 2.167439317190519

Epoch: 5| Step: 7
Training loss: 2.108055353164673
Validation loss: 2.147662383253856

Epoch: 5| Step: 8
Training loss: 1.7167106866836548
Validation loss: 2.1607003878521662

Epoch: 5| Step: 9
Training loss: 1.7812671661376953
Validation loss: 2.1578554440570135

Epoch: 5| Step: 10
Training loss: 2.039170742034912
Validation loss: 2.139585200176444

Epoch: 191| Step: 0
Training loss: 1.4504998922348022
Validation loss: 2.1092271471536286

Epoch: 5| Step: 1
Training loss: 2.8315036296844482
Validation loss: 2.0694779093547533

Epoch: 5| Step: 2
Training loss: 2.0222651958465576
Validation loss: 2.0271048007472867

Epoch: 5| Step: 3
Training loss: 2.0011513233184814
Validation loss: 2.034873644510905

Epoch: 5| Step: 4
Training loss: 1.8984365463256836
Validation loss: 2.028677048221711

Epoch: 5| Step: 5
Training loss: 1.9340603351593018
Validation loss: 2.0241783113889795

Epoch: 5| Step: 6
Training loss: 2.107262134552002
Validation loss: 2.0401447306397142

Epoch: 5| Step: 7
Training loss: 1.7608855962753296
Validation loss: 2.0158090078702537

Epoch: 5| Step: 8
Training loss: 1.60184645652771
Validation loss: 2.025190382875422

Epoch: 5| Step: 9
Training loss: 1.9567861557006836
Validation loss: 2.016243427030502

Epoch: 5| Step: 10
Training loss: 1.4096447229385376
Validation loss: 2.041820869650892

Epoch: 192| Step: 0
Training loss: 1.700293779373169
Validation loss: 2.0652855852598786

Epoch: 5| Step: 1
Training loss: 2.110342025756836
Validation loss: 2.0816211931167112

Epoch: 5| Step: 2
Training loss: 2.2275452613830566
Validation loss: 2.099828734192797

Epoch: 5| Step: 3
Training loss: 2.223057270050049
Validation loss: 2.103664311029578

Epoch: 5| Step: 4
Training loss: 1.3694751262664795
Validation loss: 2.0987856003545944

Epoch: 5| Step: 5
Training loss: 2.0950095653533936
Validation loss: 2.1122278167355444

Epoch: 5| Step: 6
Training loss: 2.0384573936462402
Validation loss: 2.086916405667541

Epoch: 5| Step: 7
Training loss: 1.8549652099609375
Validation loss: 2.0800087041752313

Epoch: 5| Step: 8
Training loss: 1.5225398540496826
Validation loss: 2.0587490950861285

Epoch: 5| Step: 9
Training loss: 1.9491955041885376
Validation loss: 2.053582672149904

Epoch: 5| Step: 10
Training loss: 1.3988990783691406
Validation loss: 2.05308711144232

Epoch: 193| Step: 0
Training loss: 2.022535800933838
Validation loss: 2.0538792969078146

Epoch: 5| Step: 1
Training loss: 1.3011486530303955
Validation loss: 2.027458903610065

Epoch: 5| Step: 2
Training loss: 2.1127753257751465
Validation loss: 2.070279118835285

Epoch: 5| Step: 3
Training loss: 1.5646257400512695
Validation loss: 2.0745102026129283

Epoch: 5| Step: 4
Training loss: 1.677917718887329
Validation loss: 2.090677633080431

Epoch: 5| Step: 5
Training loss: 1.8902171850204468
Validation loss: 2.074638253899031

Epoch: 5| Step: 6
Training loss: 1.8551397323608398
Validation loss: 2.058714082164149

Epoch: 5| Step: 7
Training loss: 1.8079026937484741
Validation loss: 2.0558980357262397

Epoch: 5| Step: 8
Training loss: 1.9411389827728271
Validation loss: 2.0630174042076193

Epoch: 5| Step: 9
Training loss: 1.9881283044815063
Validation loss: 2.0664999741379932

Epoch: 5| Step: 10
Training loss: 1.9997841119766235
Validation loss: 2.070853897320327

Epoch: 194| Step: 0
Training loss: 2.434021472930908
Validation loss: 2.0828369355970815

Epoch: 5| Step: 1
Training loss: 2.533294200897217
Validation loss: 2.0584533342751126

Epoch: 5| Step: 2
Training loss: 0.9537948369979858
Validation loss: 2.0673717862816265

Epoch: 5| Step: 3
Training loss: 1.6565008163452148
Validation loss: 2.0661790012031473

Epoch: 5| Step: 4
Training loss: 1.3956528902053833
Validation loss: 2.0692545008915726

Epoch: 5| Step: 5
Training loss: 1.5328361988067627
Validation loss: 2.079770190741426

Epoch: 5| Step: 6
Training loss: 1.6521251201629639
Validation loss: 2.0967250575301466

Epoch: 5| Step: 7
Training loss: 1.7453880310058594
Validation loss: 2.0929780467864005

Epoch: 5| Step: 8
Training loss: 1.9099931716918945
Validation loss: 2.0922013739103913

Epoch: 5| Step: 9
Training loss: 2.1928579807281494
Validation loss: 2.077683082190893

Epoch: 5| Step: 10
Training loss: 1.8813174962997437
Validation loss: 2.070679787666567

Epoch: 195| Step: 0
Training loss: 2.1104207038879395
Validation loss: 2.081785371226649

Epoch: 5| Step: 1
Training loss: 1.2621854543685913
Validation loss: 2.097524999290384

Epoch: 5| Step: 2
Training loss: 1.5990126132965088
Validation loss: 2.0821366976666194

Epoch: 5| Step: 3
Training loss: 1.6418437957763672
Validation loss: 2.091542748994725

Epoch: 5| Step: 4
Training loss: 1.5011026859283447
Validation loss: 2.076412985401769

Epoch: 5| Step: 5
Training loss: 2.3189139366149902
Validation loss: 2.0676302474032164

Epoch: 5| Step: 6
Training loss: 1.731432318687439
Validation loss: 2.085485936493002

Epoch: 5| Step: 7
Training loss: 1.876641035079956
Validation loss: 2.093460157353391

Epoch: 5| Step: 8
Training loss: 1.6525859832763672
Validation loss: 2.099685938127579

Epoch: 5| Step: 9
Training loss: 2.0714433193206787
Validation loss: 2.1343638845669326

Epoch: 5| Step: 10
Training loss: 1.964055061340332
Validation loss: 2.1370948668449157

Epoch: 196| Step: 0
Training loss: 1.7548811435699463
Validation loss: 2.118781884511312

Epoch: 5| Step: 1
Training loss: 1.2868925333023071
Validation loss: 2.102631704781645

Epoch: 5| Step: 2
Training loss: 1.76083242893219
Validation loss: 2.103286197108607

Epoch: 5| Step: 3
Training loss: 2.0677990913391113
Validation loss: 2.0919432050438336

Epoch: 5| Step: 4
Training loss: 1.8685789108276367
Validation loss: 2.112919508769948

Epoch: 5| Step: 5
Training loss: 2.03248929977417
Validation loss: 2.093602067680769

Epoch: 5| Step: 6
Training loss: 1.685468316078186
Validation loss: 2.112944896503161

Epoch: 5| Step: 7
Training loss: 1.883062720298767
Validation loss: 2.093185802941681

Epoch: 5| Step: 8
Training loss: 2.600109100341797
Validation loss: 2.0844826916212678

Epoch: 5| Step: 9
Training loss: 1.800079107284546
Validation loss: 2.072130290410852

Epoch: 5| Step: 10
Training loss: 1.177321434020996
Validation loss: 2.0656838391416814

Epoch: 197| Step: 0
Training loss: 1.9073994159698486
Validation loss: 2.0710633134329193

Epoch: 5| Step: 1
Training loss: 1.3634828329086304
Validation loss: 2.077487426419412

Epoch: 5| Step: 2
Training loss: 1.675548791885376
Validation loss: 2.0683647227543656

Epoch: 5| Step: 3
Training loss: 1.877976417541504
Validation loss: 2.0649401321206042

Epoch: 5| Step: 4
Training loss: 2.176022529602051
Validation loss: 2.074804062484413

Epoch: 5| Step: 5
Training loss: 1.662682294845581
Validation loss: 2.0796593645567536

Epoch: 5| Step: 6
Training loss: 1.90854811668396
Validation loss: 2.0802622328522387

Epoch: 5| Step: 7
Training loss: 1.8321254253387451
Validation loss: 2.0888080186741327

Epoch: 5| Step: 8
Training loss: 1.9235246181488037
Validation loss: 2.118587265732468

Epoch: 5| Step: 9
Training loss: 1.8668228387832642
Validation loss: 2.104104898309195

Epoch: 5| Step: 10
Training loss: 1.3962416648864746
Validation loss: 2.1119638489138697

Epoch: 198| Step: 0
Training loss: 1.6921815872192383
Validation loss: 2.0954437371223205

Epoch: 5| Step: 1
Training loss: 1.849328637123108
Validation loss: 2.0688191934298445

Epoch: 5| Step: 2
Training loss: 1.5512573719024658
Validation loss: 2.0411149173654537

Epoch: 5| Step: 3
Training loss: 1.926652193069458
Validation loss: 2.0447547230669247

Epoch: 5| Step: 4
Training loss: 2.202071189880371
Validation loss: 2.026529248042773

Epoch: 5| Step: 5
Training loss: 2.027196168899536
Validation loss: 2.0274238432607343

Epoch: 5| Step: 6
Training loss: 1.426450490951538
Validation loss: 2.0332655829768025

Epoch: 5| Step: 7
Training loss: 1.6688764095306396
Validation loss: 2.043856942525474

Epoch: 5| Step: 8
Training loss: 1.8075441122055054
Validation loss: 2.0604397302032798

Epoch: 5| Step: 9
Training loss: 1.6131614446640015
Validation loss: 2.0658378319073747

Epoch: 5| Step: 10
Training loss: 1.8207898139953613
Validation loss: 2.0983512350308

Epoch: 199| Step: 0
Training loss: 1.3199809789657593
Validation loss: 2.1109611347157466

Epoch: 5| Step: 1
Training loss: 2.0304558277130127
Validation loss: 2.128168980280558

Epoch: 5| Step: 2
Training loss: 1.6310522556304932
Validation loss: 2.1238507378485894

Epoch: 5| Step: 3
Training loss: 2.037121295928955
Validation loss: 2.1467743509559223

Epoch: 5| Step: 4
Training loss: 1.6248403787612915
Validation loss: 2.166477800697409

Epoch: 5| Step: 5
Training loss: 1.4476017951965332
Validation loss: 2.1403482908843667

Epoch: 5| Step: 6
Training loss: 1.9317443370819092
Validation loss: 2.1236066613146054

Epoch: 5| Step: 7
Training loss: 1.7440134286880493
Validation loss: 2.1030015894161758

Epoch: 5| Step: 8
Training loss: 1.5129196643829346
Validation loss: 2.0860003015046478

Epoch: 5| Step: 9
Training loss: 2.1191141605377197
Validation loss: 2.0538263128649805

Epoch: 5| Step: 10
Training loss: 2.171882152557373
Validation loss: 2.0444587994647283

Epoch: 200| Step: 0
Training loss: 1.9166719913482666
Validation loss: 2.027535616710622

Epoch: 5| Step: 1
Training loss: 1.5761648416519165
Validation loss: 2.0252493350736556

Epoch: 5| Step: 2
Training loss: 1.804878830909729
Validation loss: 2.044441182126281

Epoch: 5| Step: 3
Training loss: 1.2811492681503296
Validation loss: 2.105316323618735

Epoch: 5| Step: 4
Training loss: 1.6580365896224976
Validation loss: 2.125859668177943

Epoch: 5| Step: 5
Training loss: 2.157761812210083
Validation loss: 2.170453957332078

Epoch: 5| Step: 6
Training loss: 2.18205189704895
Validation loss: 2.1301941820370254

Epoch: 5| Step: 7
Training loss: 1.3075754642486572
Validation loss: 2.081711256375877

Epoch: 5| Step: 8
Training loss: 2.05106782913208
Validation loss: 2.0928465166399555

Epoch: 5| Step: 9
Training loss: 2.524869203567505
Validation loss: 2.1001334164732244

Epoch: 5| Step: 10
Training loss: 1.560237169265747
Validation loss: 2.078598207043063

Epoch: 201| Step: 0
Training loss: 1.3867871761322021
Validation loss: 2.0468162016202043

Epoch: 5| Step: 1
Training loss: 1.7868436574935913
Validation loss: 2.0528765134913947

Epoch: 5| Step: 2
Training loss: 2.090519666671753
Validation loss: 2.0525603396918184

Epoch: 5| Step: 3
Training loss: 1.9029567241668701
Validation loss: 2.041055835703368

Epoch: 5| Step: 4
Training loss: 1.2343995571136475
Validation loss: 2.081763667445029

Epoch: 5| Step: 5
Training loss: 2.1381940841674805
Validation loss: 2.0956752351535264

Epoch: 5| Step: 6
Training loss: 2.2813498973846436
Validation loss: 2.109021315010645

Epoch: 5| Step: 7
Training loss: 1.7595850229263306
Validation loss: 2.1216567113835323

Epoch: 5| Step: 8
Training loss: 1.8910191059112549
Validation loss: 2.0987902379805043

Epoch: 5| Step: 9
Training loss: 1.470999002456665
Validation loss: 2.098350494138656

Epoch: 5| Step: 10
Training loss: 1.5584367513656616
Validation loss: 2.089702570310203

Epoch: 202| Step: 0
Training loss: 1.669290542602539
Validation loss: 2.1095578773047334

Epoch: 5| Step: 1
Training loss: 2.0027098655700684
Validation loss: 2.1293805799176617

Epoch: 5| Step: 2
Training loss: 1.562583088874817
Validation loss: 2.1440886271897184

Epoch: 5| Step: 3
Training loss: 1.8835041522979736
Validation loss: 2.1336781696606706

Epoch: 5| Step: 4
Training loss: 1.7749830484390259
Validation loss: 2.102753746894098

Epoch: 5| Step: 5
Training loss: 1.8396570682525635
Validation loss: 2.0894643465677896

Epoch: 5| Step: 6
Training loss: 1.3187839984893799
Validation loss: 2.0860278965324484

Epoch: 5| Step: 7
Training loss: 1.4150478839874268
Validation loss: 2.063556889052032

Epoch: 5| Step: 8
Training loss: 1.9924125671386719
Validation loss: 2.067703595725439

Epoch: 5| Step: 9
Training loss: 1.8878101110458374
Validation loss: 2.070160706837972

Epoch: 5| Step: 10
Training loss: 1.5816055536270142
Validation loss: 2.058819829776723

Epoch: 203| Step: 0
Training loss: 1.750563383102417
Validation loss: 2.0692466382057435

Epoch: 5| Step: 1
Training loss: 1.6088966131210327
Validation loss: 2.105691252216216

Epoch: 5| Step: 2
Training loss: 1.5908076763153076
Validation loss: 2.0964785314375356

Epoch: 5| Step: 3
Training loss: 1.4646987915039062
Validation loss: 2.1290559396948865

Epoch: 5| Step: 4
Training loss: 1.7088686227798462
Validation loss: 2.128047611123772

Epoch: 5| Step: 5
Training loss: 2.1475777626037598
Validation loss: 2.118097011760999

Epoch: 5| Step: 6
Training loss: 1.6939092874526978
Validation loss: 2.1193890994594944

Epoch: 5| Step: 7
Training loss: 1.9145845174789429
Validation loss: 2.1397590329570155

Epoch: 5| Step: 8
Training loss: 1.6584457159042358
Validation loss: 2.1083348951032086

Epoch: 5| Step: 9
Training loss: 1.5058521032333374
Validation loss: 2.090175405625374

Epoch: 5| Step: 10
Training loss: 1.5242327451705933
Validation loss: 2.0986770071009153

Epoch: 204| Step: 0
Training loss: 2.196074962615967
Validation loss: 2.1043236512009815

Epoch: 5| Step: 1
Training loss: 1.2459235191345215
Validation loss: 2.0814357444804203

Epoch: 5| Step: 2
Training loss: 1.8290631771087646
Validation loss: 2.109337963083739

Epoch: 5| Step: 3
Training loss: 1.9377464056015015
Validation loss: 2.0855674333469842

Epoch: 5| Step: 4
Training loss: 1.573061466217041
Validation loss: 2.095147389237599

Epoch: 5| Step: 5
Training loss: 2.1755013465881348
Validation loss: 2.080065614433699

Epoch: 5| Step: 6
Training loss: 1.2254594564437866
Validation loss: 2.0520819899856404

Epoch: 5| Step: 7
Training loss: 1.5110371112823486
Validation loss: 2.04041866589618

Epoch: 5| Step: 8
Training loss: 1.148710012435913
Validation loss: 2.049906164087275

Epoch: 5| Step: 9
Training loss: 1.9684034585952759
Validation loss: 2.0103968958700857

Epoch: 5| Step: 10
Training loss: 1.8865666389465332
Validation loss: 2.034845716209822

Epoch: 205| Step: 0
Training loss: 1.1498430967330933
Validation loss: 2.033503145299932

Epoch: 5| Step: 1
Training loss: 1.4435904026031494
Validation loss: 2.030163839299192

Epoch: 5| Step: 2
Training loss: 1.2873380184173584
Validation loss: 2.037530673447476

Epoch: 5| Step: 3
Training loss: 1.8123403787612915
Validation loss: 2.0298204524542696

Epoch: 5| Step: 4
Training loss: 1.6125571727752686
Validation loss: 2.0323955615361533

Epoch: 5| Step: 5
Training loss: 1.82291579246521
Validation loss: 2.047882754315612

Epoch: 5| Step: 6
Training loss: 1.9388611316680908
Validation loss: 2.0755036107955442

Epoch: 5| Step: 7
Training loss: 2.0649237632751465
Validation loss: 2.106142641395651

Epoch: 5| Step: 8
Training loss: 1.74881112575531
Validation loss: 2.12753475353282

Epoch: 5| Step: 9
Training loss: 1.8823057413101196
Validation loss: 2.1107875967538483

Epoch: 5| Step: 10
Training loss: 2.0459585189819336
Validation loss: 2.099108528065425

Epoch: 206| Step: 0
Training loss: 1.4342917203903198
Validation loss: 2.0659384906932874

Epoch: 5| Step: 1
Training loss: 2.0192184448242188
Validation loss: 2.0681506690158638

Epoch: 5| Step: 2
Training loss: 1.7997760772705078
Validation loss: 2.082206832465305

Epoch: 5| Step: 3
Training loss: 1.6907535791397095
Validation loss: 2.072247225751159

Epoch: 5| Step: 4
Training loss: 1.7523704767227173
Validation loss: 2.095530456112277

Epoch: 5| Step: 5
Training loss: 1.8520965576171875
Validation loss: 2.0876675933919926

Epoch: 5| Step: 6
Training loss: 1.4441063404083252
Validation loss: 2.082577133691439

Epoch: 5| Step: 7
Training loss: 1.2517368793487549
Validation loss: 2.0941908744073685

Epoch: 5| Step: 8
Training loss: 1.7668383121490479
Validation loss: 2.081618450021231

Epoch: 5| Step: 9
Training loss: 1.3074378967285156
Validation loss: 2.0917699862551946

Epoch: 5| Step: 10
Training loss: 2.380807876586914
Validation loss: 2.1146533925046205

Epoch: 207| Step: 0
Training loss: 1.8622859716415405
Validation loss: 2.1113107858165616

Epoch: 5| Step: 1
Training loss: 1.7233797311782837
Validation loss: 2.09930419921875

Epoch: 5| Step: 2
Training loss: 1.4911363124847412
Validation loss: 2.0936171611150107

Epoch: 5| Step: 3
Training loss: 1.7421505451202393
Validation loss: 2.0998377697442168

Epoch: 5| Step: 4
Training loss: 1.595929503440857
Validation loss: 2.0806582076575166

Epoch: 5| Step: 5
Training loss: 2.4297096729278564
Validation loss: 2.06851254868251

Epoch: 5| Step: 6
Training loss: 1.0250990390777588
Validation loss: 2.078469794283631

Epoch: 5| Step: 7
Training loss: 1.642269492149353
Validation loss: 2.090371137024254

Epoch: 5| Step: 8
Training loss: 1.4466227293014526
Validation loss: 2.094150794449673

Epoch: 5| Step: 9
Training loss: 2.297305107116699
Validation loss: 2.088561237499278

Epoch: 5| Step: 10
Training loss: 0.8711497783660889
Validation loss: 2.0889764447366037

Epoch: 208| Step: 0
Training loss: 2.386012554168701
Validation loss: 2.1256477140611216

Epoch: 5| Step: 1
Training loss: 1.6500478982925415
Validation loss: 2.123952252890474

Epoch: 5| Step: 2
Training loss: 1.9303795099258423
Validation loss: 2.1271407270944245

Epoch: 5| Step: 3
Training loss: 1.0843814611434937
Validation loss: 2.1146027695748115

Epoch: 5| Step: 4
Training loss: 1.0742191076278687
Validation loss: 2.126512753066196

Epoch: 5| Step: 5
Training loss: 1.6678917407989502
Validation loss: 2.1438973539619037

Epoch: 5| Step: 6
Training loss: 1.528541922569275
Validation loss: 2.134691017930226

Epoch: 5| Step: 7
Training loss: 1.508162260055542
Validation loss: 2.1244915557164017

Epoch: 5| Step: 8
Training loss: 1.7952229976654053
Validation loss: 2.1156921771264847

Epoch: 5| Step: 9
Training loss: 1.5938183069229126
Validation loss: 2.1051891721704954

Epoch: 5| Step: 10
Training loss: 1.9317904710769653
Validation loss: 2.1035981152647283

Epoch: 209| Step: 0
Training loss: 1.7731860876083374
Validation loss: 2.1010252826957294

Epoch: 5| Step: 1
Training loss: 1.6312916278839111
Validation loss: 2.099771168924147

Epoch: 5| Step: 2
Training loss: 1.521166205406189
Validation loss: 2.086891246098344

Epoch: 5| Step: 3
Training loss: 1.6723911762237549
Validation loss: 2.0881145769549954

Epoch: 5| Step: 4
Training loss: 1.6747655868530273
Validation loss: 2.1019008249364872

Epoch: 5| Step: 5
Training loss: 1.5667144060134888
Validation loss: 2.115914890843053

Epoch: 5| Step: 6
Training loss: 1.623208999633789
Validation loss: 2.131932250915035

Epoch: 5| Step: 7
Training loss: 2.2863998413085938
Validation loss: 2.152902833877071

Epoch: 5| Step: 8
Training loss: 1.174621820449829
Validation loss: 2.1562159881796887

Epoch: 5| Step: 9
Training loss: 0.8747121691703796
Validation loss: 2.153652967945222

Epoch: 5| Step: 10
Training loss: 2.2474730014801025
Validation loss: 2.1380665763731925

Epoch: 210| Step: 0
Training loss: 2.016893148422241
Validation loss: 2.1168836291118334

Epoch: 5| Step: 1
Training loss: 1.5077217817306519
Validation loss: 2.1190344800231276

Epoch: 5| Step: 2
Training loss: 1.649212121963501
Validation loss: 2.110362874564304

Epoch: 5| Step: 3
Training loss: 1.2843554019927979
Validation loss: 2.095022072074234

Epoch: 5| Step: 4
Training loss: 1.6147096157073975
Validation loss: 2.1141196873880204

Epoch: 5| Step: 5
Training loss: 1.6399586200714111
Validation loss: 2.1075871567572317

Epoch: 5| Step: 6
Training loss: 1.3867508172988892
Validation loss: 2.0889423790798394

Epoch: 5| Step: 7
Training loss: 1.5435746908187866
Validation loss: 2.0704770190741426

Epoch: 5| Step: 8
Training loss: 1.0647351741790771
Validation loss: 2.076016108194987

Epoch: 5| Step: 9
Training loss: 1.8570743799209595
Validation loss: 2.0537885068565287

Epoch: 5| Step: 10
Training loss: 2.0314900875091553
Validation loss: 2.0878302051175024

Epoch: 211| Step: 0
Training loss: 2.3110768795013428
Validation loss: 2.0684171774054088

Epoch: 5| Step: 1
Training loss: 1.505384087562561
Validation loss: 2.089390452190112

Epoch: 5| Step: 2
Training loss: 1.5936064720153809
Validation loss: 2.089757534765428

Epoch: 5| Step: 3
Training loss: 1.5352777242660522
Validation loss: 2.097474951897898

Epoch: 5| Step: 4
Training loss: 1.2975854873657227
Validation loss: 2.0909405011002735

Epoch: 5| Step: 5
Training loss: 1.6538289785385132
Validation loss: 2.092519583240632

Epoch: 5| Step: 6
Training loss: 1.3969213962554932
Validation loss: 2.0843237087290776

Epoch: 5| Step: 7
Training loss: 1.6056255102157593
Validation loss: 2.098715561692433

Epoch: 5| Step: 8
Training loss: 1.6660206317901611
Validation loss: 2.0645227470705585

Epoch: 5| Step: 9
Training loss: 1.2038980722427368
Validation loss: 2.0541892936152797

Epoch: 5| Step: 10
Training loss: 1.500741958618164
Validation loss: 2.070002499447074

Epoch: 212| Step: 0
Training loss: 1.630631685256958
Validation loss: 2.0436037061034993

Epoch: 5| Step: 1
Training loss: 1.2347157001495361
Validation loss: 2.05987649579202

Epoch: 5| Step: 2
Training loss: 1.5065515041351318
Validation loss: 2.0751040494570168

Epoch: 5| Step: 3
Training loss: 1.5907249450683594
Validation loss: 2.0758748131413616

Epoch: 5| Step: 4
Training loss: 1.9184544086456299
Validation loss: 2.0822678894125004

Epoch: 5| Step: 5
Training loss: 1.610513687133789
Validation loss: 2.058841129784943

Epoch: 5| Step: 6
Training loss: 1.7121591567993164
Validation loss: 2.0723786815520255

Epoch: 5| Step: 7
Training loss: 1.7326993942260742
Validation loss: 2.0612055024793072

Epoch: 5| Step: 8
Training loss: 1.2556660175323486
Validation loss: 2.0601839609043573

Epoch: 5| Step: 9
Training loss: 1.0345975160598755
Validation loss: 2.02534830698403

Epoch: 5| Step: 10
Training loss: 2.0629591941833496
Validation loss: 2.0531646205532934

Epoch: 213| Step: 0
Training loss: 1.9119899272918701
Validation loss: 2.0462167673213507

Epoch: 5| Step: 1
Training loss: 1.3568298816680908
Validation loss: 2.0620155411381877

Epoch: 5| Step: 2
Training loss: 1.40411376953125
Validation loss: 2.057837672131036

Epoch: 5| Step: 3
Training loss: 0.8217458724975586
Validation loss: 2.0730928964512323

Epoch: 5| Step: 4
Training loss: 1.3635084629058838
Validation loss: 2.042441791103732

Epoch: 5| Step: 5
Training loss: 1.8067519664764404
Validation loss: 2.0605976966119584

Epoch: 5| Step: 6
Training loss: 1.8247617483139038
Validation loss: 2.046592579093031

Epoch: 5| Step: 7
Training loss: 1.7601314783096313
Validation loss: 2.062841066750147

Epoch: 5| Step: 8
Training loss: 1.6825940608978271
Validation loss: 2.0455877486095635

Epoch: 5| Step: 9
Training loss: 1.5951817035675049
Validation loss: 2.0739172094611713

Epoch: 5| Step: 10
Training loss: 1.6558871269226074
Validation loss: 2.0756138832338396

Epoch: 214| Step: 0
Training loss: 1.525322675704956
Validation loss: 2.0694539111147643

Epoch: 5| Step: 1
Training loss: 1.7022953033447266
Validation loss: 2.0668127511137273

Epoch: 5| Step: 2
Training loss: 1.1545337438583374
Validation loss: 2.0831037849508305

Epoch: 5| Step: 3
Training loss: 1.659844994544983
Validation loss: 2.0921733379364014

Epoch: 5| Step: 4
Training loss: 1.2219094038009644
Validation loss: 2.093385418256124

Epoch: 5| Step: 5
Training loss: 1.3731586933135986
Validation loss: 2.0608302649631294

Epoch: 5| Step: 6
Training loss: 1.8376363515853882
Validation loss: 2.0702955671536025

Epoch: 5| Step: 7
Training loss: 1.8992421627044678
Validation loss: 2.0462517264068767

Epoch: 5| Step: 8
Training loss: 1.1027467250823975
Validation loss: 2.0388051617530083

Epoch: 5| Step: 9
Training loss: 1.8040424585342407
Validation loss: 2.029251557524486

Epoch: 5| Step: 10
Training loss: 1.5034016370773315
Validation loss: 2.0218795525130404

Epoch: 215| Step: 0
Training loss: 1.5554184913635254
Validation loss: 2.0187941469171995

Epoch: 5| Step: 1
Training loss: 1.853737473487854
Validation loss: 2.0197883447011313

Epoch: 5| Step: 2
Training loss: 1.622984528541565
Validation loss: 2.038545593138664

Epoch: 5| Step: 3
Training loss: 1.1124006509780884
Validation loss: 2.0547900071708103

Epoch: 5| Step: 4
Training loss: 1.675214171409607
Validation loss: 2.0648227507068264

Epoch: 5| Step: 5
Training loss: 1.1570336818695068
Validation loss: 2.0566622813542685

Epoch: 5| Step: 6
Training loss: 1.6484512090682983
Validation loss: 2.058933227292953

Epoch: 5| Step: 7
Training loss: 1.1923706531524658
Validation loss: 2.09144603308811

Epoch: 5| Step: 8
Training loss: 1.2766401767730713
Validation loss: 2.0719022507308633

Epoch: 5| Step: 9
Training loss: 1.8736448287963867
Validation loss: 2.0576836678289596

Epoch: 5| Step: 10
Training loss: 1.8935773372650146
Validation loss: 2.026470873945503

Epoch: 216| Step: 0
Training loss: 1.7574418783187866
Validation loss: 2.0249128931312153

Epoch: 5| Step: 1
Training loss: 1.6574440002441406
Validation loss: 2.043531761374525

Epoch: 5| Step: 2
Training loss: 1.7006006240844727
Validation loss: 2.0602115456775953

Epoch: 5| Step: 3
Training loss: 1.4207996129989624
Validation loss: 2.0767139196395874

Epoch: 5| Step: 4
Training loss: 1.5682480335235596
Validation loss: 2.054466256531336

Epoch: 5| Step: 5
Training loss: 1.21257746219635
Validation loss: 2.125387039235843

Epoch: 5| Step: 6
Training loss: 1.687261939048767
Validation loss: 2.1537219555147233

Epoch: 5| Step: 7
Training loss: 1.594401478767395
Validation loss: 2.157288518003238

Epoch: 5| Step: 8
Training loss: 1.8255083560943604
Validation loss: 2.1795654924966956

Epoch: 5| Step: 9
Training loss: 1.4068059921264648
Validation loss: 2.1259055368361937

Epoch: 5| Step: 10
Training loss: 1.7159003019332886
Validation loss: 2.0822160807988976

Epoch: 217| Step: 0
Training loss: 1.5471346378326416
Validation loss: 2.098134922724898

Epoch: 5| Step: 1
Training loss: 1.7249208688735962
Validation loss: 2.116636545427384

Epoch: 5| Step: 2
Training loss: 1.9107162952423096
Validation loss: 2.128386337270019

Epoch: 5| Step: 3
Training loss: 1.5927236080169678
Validation loss: 2.081837797677645

Epoch: 5| Step: 4
Training loss: 1.9005086421966553
Validation loss: 2.045333223958169

Epoch: 5| Step: 5
Training loss: 1.2992559671401978
Validation loss: 2.028656821097097

Epoch: 5| Step: 6
Training loss: 0.995520293712616
Validation loss: 2.0489478777813654

Epoch: 5| Step: 7
Training loss: 0.8942233920097351
Validation loss: 2.0354601490882134

Epoch: 5| Step: 8
Training loss: 1.702016830444336
Validation loss: 2.0534233482935096

Epoch: 5| Step: 9
Training loss: 1.4509344100952148
Validation loss: 2.052588055210729

Epoch: 5| Step: 10
Training loss: 1.8908218145370483
Validation loss: 2.061147642391984

Epoch: 218| Step: 0
Training loss: 1.796301245689392
Validation loss: 2.082967705624078

Epoch: 5| Step: 1
Training loss: 1.5877938270568848
Validation loss: 2.063210830893568

Epoch: 5| Step: 2
Training loss: 1.4910070896148682
Validation loss: 2.052889520122159

Epoch: 5| Step: 3
Training loss: 1.494153380393982
Validation loss: 2.0352188130860687

Epoch: 5| Step: 4
Training loss: 1.5734834671020508
Validation loss: 2.054159466938306

Epoch: 5| Step: 5
Training loss: 1.5381519794464111
Validation loss: 2.0540698574435328

Epoch: 5| Step: 6
Training loss: 1.7030693292617798
Validation loss: 2.0323461973538963

Epoch: 5| Step: 7
Training loss: 1.1177126169204712
Validation loss: 2.0458904504776

Epoch: 5| Step: 8
Training loss: 1.8126726150512695
Validation loss: 2.04071456386197

Epoch: 5| Step: 9
Training loss: 1.1963332891464233
Validation loss: 2.0759344998226372

Epoch: 5| Step: 10
Training loss: 1.3424755334854126
Validation loss: 2.086835233114099

Epoch: 219| Step: 0
Training loss: 1.764531135559082
Validation loss: 2.09344910037133

Epoch: 5| Step: 1
Training loss: 1.2202050685882568
Validation loss: 2.0726940196047545

Epoch: 5| Step: 2
Training loss: 2.052110195159912
Validation loss: 2.049491951542516

Epoch: 5| Step: 3
Training loss: 1.2660657167434692
Validation loss: 2.025791305367665

Epoch: 5| Step: 4
Training loss: 1.4615551233291626
Validation loss: 2.009629390572989

Epoch: 5| Step: 5
Training loss: 1.7082664966583252
Validation loss: 2.0202667354255595

Epoch: 5| Step: 6
Training loss: 1.4158589839935303
Validation loss: 2.028950887341653

Epoch: 5| Step: 7
Training loss: 1.4146525859832764
Validation loss: 2.0272297449009393

Epoch: 5| Step: 8
Training loss: 1.1753796339035034
Validation loss: 2.0838918403912614

Epoch: 5| Step: 9
Training loss: 1.4349285364151
Validation loss: 2.098508055492114

Epoch: 5| Step: 10
Training loss: 1.6915298700332642
Validation loss: 2.1430772632680912

Epoch: 220| Step: 0
Training loss: 1.6953884363174438
Validation loss: 2.117319626192893

Epoch: 5| Step: 1
Training loss: 1.5831435918807983
Validation loss: 2.0957267643303

Epoch: 5| Step: 2
Training loss: 1.2661101818084717
Validation loss: 2.093844644484981

Epoch: 5| Step: 3
Training loss: 1.6623413562774658
Validation loss: 2.088325472288234

Epoch: 5| Step: 4
Training loss: 1.600071668624878
Validation loss: 2.0898023548946587

Epoch: 5| Step: 5
Training loss: 1.4141619205474854
Validation loss: 2.0594592735331547

Epoch: 5| Step: 6
Training loss: 1.3058063983917236
Validation loss: 2.0212271098167665

Epoch: 5| Step: 7
Training loss: 1.4697012901306152
Validation loss: 2.009935939183799

Epoch: 5| Step: 8
Training loss: 1.2841259241104126
Validation loss: 2.008159573360156

Epoch: 5| Step: 9
Training loss: 1.5230190753936768
Validation loss: 1.9912044617437548

Epoch: 5| Step: 10
Training loss: 1.4923511743545532
Validation loss: 2.0513972877174296

Epoch: 221| Step: 0
Training loss: 1.5136890411376953
Validation loss: 2.0519151674803866

Epoch: 5| Step: 1
Training loss: 1.178930401802063
Validation loss: 2.0305713556146108

Epoch: 5| Step: 2
Training loss: 2.2002904415130615
Validation loss: 2.0441379841937812

Epoch: 5| Step: 3
Training loss: 1.1709258556365967
Validation loss: 2.0370321555804183

Epoch: 5| Step: 4
Training loss: 1.3640871047973633
Validation loss: 2.054905893982098

Epoch: 5| Step: 5
Training loss: 2.105044364929199
Validation loss: 2.071302793359244

Epoch: 5| Step: 6
Training loss: 1.3621938228607178
Validation loss: 2.06832411725034

Epoch: 5| Step: 7
Training loss: 1.4125185012817383
Validation loss: 2.0724224710977204

Epoch: 5| Step: 8
Training loss: 1.105786681175232
Validation loss: 2.0383305831622054

Epoch: 5| Step: 9
Training loss: 1.5019534826278687
Validation loss: 2.035372882760981

Epoch: 5| Step: 10
Training loss: 1.0721204280853271
Validation loss: 2.0404926923013504

Epoch: 222| Step: 0
Training loss: 2.26271390914917
Validation loss: 2.0348290140910814

Epoch: 5| Step: 1
Training loss: 1.1179702281951904
Validation loss: 2.001917249412947

Epoch: 5| Step: 2
Training loss: 1.2750208377838135
Validation loss: 2.0219127772956766

Epoch: 5| Step: 3
Training loss: 1.417706847190857
Validation loss: 2.0001978399933025

Epoch: 5| Step: 4
Training loss: 0.9180238842964172
Validation loss: 2.0211290620988414

Epoch: 5| Step: 5
Training loss: 1.3325564861297607
Validation loss: 2.028007750870079

Epoch: 5| Step: 6
Training loss: 1.7119899988174438
Validation loss: 2.0361054789635444

Epoch: 5| Step: 7
Training loss: 1.7472225427627563
Validation loss: 2.0235837480073333

Epoch: 5| Step: 8
Training loss: 0.9245136976242065
Validation loss: 2.041418307571001

Epoch: 5| Step: 9
Training loss: 1.5889976024627686
Validation loss: 2.022715994106826

Epoch: 5| Step: 10
Training loss: 1.673938512802124
Validation loss: 2.0299487626680763

Epoch: 223| Step: 0
Training loss: 1.0322484970092773
Validation loss: 2.0340501595568914

Epoch: 5| Step: 1
Training loss: 1.3425652980804443
Validation loss: 2.0437565170308596

Epoch: 5| Step: 2
Training loss: 1.7566760778427124
Validation loss: 2.069766931636359

Epoch: 5| Step: 3
Training loss: 1.6146507263183594
Validation loss: 2.0492908646983485

Epoch: 5| Step: 4
Training loss: 1.5092976093292236
Validation loss: 2.0392804299631426

Epoch: 5| Step: 5
Training loss: 1.3097139596939087
Validation loss: 2.057320879351708

Epoch: 5| Step: 6
Training loss: 1.6145731210708618
Validation loss: 2.058020886554513

Epoch: 5| Step: 7
Training loss: 1.2108442783355713
Validation loss: 2.059638318195138

Epoch: 5| Step: 8
Training loss: 1.4807361364364624
Validation loss: 2.0716165470820602

Epoch: 5| Step: 9
Training loss: 1.5634511709213257
Validation loss: 2.0830093993935535

Epoch: 5| Step: 10
Training loss: 1.3765671253204346
Validation loss: 2.0887931649402907

Epoch: 224| Step: 0
Training loss: 1.6719764471054077
Validation loss: 2.095856958819974

Epoch: 5| Step: 1
Training loss: 1.2313451766967773
Validation loss: 2.057402790233653

Epoch: 5| Step: 2
Training loss: 1.2213712930679321
Validation loss: 2.059320834375197

Epoch: 5| Step: 3
Training loss: 1.7950977087020874
Validation loss: 2.043307105700175

Epoch: 5| Step: 4
Training loss: 1.977012276649475
Validation loss: 2.0274176123321697

Epoch: 5| Step: 5
Training loss: 1.2671661376953125
Validation loss: 2.0018181313750563

Epoch: 5| Step: 6
Training loss: 1.6461570262908936
Validation loss: 1.982701027265159

Epoch: 5| Step: 7
Training loss: 1.0551292896270752
Validation loss: 1.970775693975469

Epoch: 5| Step: 8
Training loss: 1.4326879978179932
Validation loss: 1.9840919151101062

Epoch: 5| Step: 9
Training loss: 1.488573431968689
Validation loss: 1.9924360962324246

Epoch: 5| Step: 10
Training loss: 1.029308557510376
Validation loss: 1.9962509242437219

Epoch: 225| Step: 0
Training loss: 1.2337872982025146
Validation loss: 1.9947900285003006

Epoch: 5| Step: 1
Training loss: 1.1610043048858643
Validation loss: 2.0165755056565806

Epoch: 5| Step: 2
Training loss: 1.359627604484558
Validation loss: 2.0569261889303885

Epoch: 5| Step: 3
Training loss: 1.591436743736267
Validation loss: 2.0556995714864423

Epoch: 5| Step: 4
Training loss: 1.503777027130127
Validation loss: 2.0540188063857374

Epoch: 5| Step: 5
Training loss: 0.8934375643730164
Validation loss: 2.0539979306600427

Epoch: 5| Step: 6
Training loss: 1.4005286693572998
Validation loss: 2.052668385608222

Epoch: 5| Step: 7
Training loss: 1.600538969039917
Validation loss: 2.065720486384566

Epoch: 5| Step: 8
Training loss: 1.7551590204238892
Validation loss: 2.0573651790618896

Epoch: 5| Step: 9
Training loss: 1.3071656227111816
Validation loss: 2.072421858387609

Epoch: 5| Step: 10
Training loss: 2.086210012435913
Validation loss: 2.0305099589850313

Epoch: 226| Step: 0
Training loss: 1.028896689414978
Validation loss: 2.008441138011153

Epoch: 5| Step: 1
Training loss: 1.7934930324554443
Validation loss: 2.0062078301624586

Epoch: 5| Step: 2
Training loss: 1.320926547050476
Validation loss: 2.0091771643648864

Epoch: 5| Step: 3
Training loss: 1.0452126264572144
Validation loss: 1.9988796787877237

Epoch: 5| Step: 4
Training loss: 1.6064956188201904
Validation loss: 1.9675281945095267

Epoch: 5| Step: 5
Training loss: 1.1299911737442017
Validation loss: 1.9606021181229623

Epoch: 5| Step: 6
Training loss: 1.4566847085952759
Validation loss: 1.9780173711879279

Epoch: 5| Step: 7
Training loss: 1.266625165939331
Validation loss: 1.9838589558037378

Epoch: 5| Step: 8
Training loss: 1.2529261112213135
Validation loss: 2.0297203153692265

Epoch: 5| Step: 9
Training loss: 1.8345661163330078
Validation loss: 2.0718771488435808

Epoch: 5| Step: 10
Training loss: 1.7628133296966553
Validation loss: 2.041260883372317

Epoch: 227| Step: 0
Training loss: 2.061629056930542
Validation loss: 2.0448960924661286

Epoch: 5| Step: 1
Training loss: 1.5880701541900635
Validation loss: 2.0270865219895557

Epoch: 5| Step: 2
Training loss: 1.2181888818740845
Validation loss: 2.0409009213088662

Epoch: 5| Step: 3
Training loss: 1.3912776708602905
Validation loss: 2.0007952387614916

Epoch: 5| Step: 4
Training loss: 1.5869638919830322
Validation loss: 1.9885380306551534

Epoch: 5| Step: 5
Training loss: 1.2811601161956787
Validation loss: 1.9773020026504353

Epoch: 5| Step: 6
Training loss: 0.8537880182266235
Validation loss: 1.9837185195697251

Epoch: 5| Step: 7
Training loss: 1.3820165395736694
Validation loss: 2.00012695148427

Epoch: 5| Step: 8
Training loss: 1.4541094303131104
Validation loss: 2.009612706399733

Epoch: 5| Step: 9
Training loss: 1.445106029510498
Validation loss: 2.004694431058822

Epoch: 5| Step: 10
Training loss: 0.8990092873573303
Validation loss: 2.016825338845612

Epoch: 228| Step: 0
Training loss: 0.8049627542495728
Validation loss: 2.0207218764930643

Epoch: 5| Step: 1
Training loss: 1.2980149984359741
Validation loss: 2.0339593643783243

Epoch: 5| Step: 2
Training loss: 1.9418493509292603
Validation loss: 2.043496652316022

Epoch: 5| Step: 3
Training loss: 1.5006225109100342
Validation loss: 2.070901355435771

Epoch: 5| Step: 4
Training loss: 1.5332324504852295
Validation loss: 2.074477905868202

Epoch: 5| Step: 5
Training loss: 1.380550742149353
Validation loss: 2.085294549183179

Epoch: 5| Step: 6
Training loss: 1.488229751586914
Validation loss: 2.0485372363880114

Epoch: 5| Step: 7
Training loss: 1.2001672983169556
Validation loss: 2.0587129515986287

Epoch: 5| Step: 8
Training loss: 1.5164731740951538
Validation loss: 2.046893594085529

Epoch: 5| Step: 9
Training loss: 0.71666419506073
Validation loss: 2.0156810155478855

Epoch: 5| Step: 10
Training loss: 1.8374923467636108
Validation loss: 2.0279415807416363

Epoch: 229| Step: 0
Training loss: 1.2879718542099
Validation loss: 2.0147118747875257

Epoch: 5| Step: 1
Training loss: 1.4532074928283691
Validation loss: 2.0181052838602374

Epoch: 5| Step: 2
Training loss: 1.1875511407852173
Validation loss: 2.0105265468679447

Epoch: 5| Step: 3
Training loss: 1.2316607236862183
Validation loss: 2.0022583059085313

Epoch: 5| Step: 4
Training loss: 1.5035972595214844
Validation loss: 2.0238786128259476

Epoch: 5| Step: 5
Training loss: 1.1380975246429443
Validation loss: 2.040140549982748

Epoch: 5| Step: 6
Training loss: 1.111541748046875
Validation loss: 2.0199815919322353

Epoch: 5| Step: 7
Training loss: 0.9064496755599976
Validation loss: 2.0129496397510653

Epoch: 5| Step: 8
Training loss: 1.7594051361083984
Validation loss: 1.9916205931735296

Epoch: 5| Step: 9
Training loss: 1.7156251668930054
Validation loss: 1.998874682252125

Epoch: 5| Step: 10
Training loss: 1.7230507135391235
Validation loss: 1.989800137858237

Epoch: 230| Step: 0
Training loss: 1.3009570837020874
Validation loss: 2.0016282079040364

Epoch: 5| Step: 1
Training loss: 1.3173227310180664
Validation loss: 2.0009162836177374

Epoch: 5| Step: 2
Training loss: 1.1989772319793701
Validation loss: 1.9780143666011032

Epoch: 5| Step: 3
Training loss: 0.9314948916435242
Validation loss: 1.9861828434851863

Epoch: 5| Step: 4
Training loss: 1.2328482866287231
Validation loss: 1.9960402801472654

Epoch: 5| Step: 5
Training loss: 1.196134090423584
Validation loss: 2.006208365963351

Epoch: 5| Step: 6
Training loss: 1.3136072158813477
Validation loss: 2.019059229922551

Epoch: 5| Step: 7
Training loss: 1.460746169090271
Validation loss: 2.0221092367684967

Epoch: 5| Step: 8
Training loss: 1.7943637371063232
Validation loss: 1.986423655222821

Epoch: 5| Step: 9
Training loss: 1.5122488737106323
Validation loss: 1.9764999792140017

Epoch: 5| Step: 10
Training loss: 1.8351044654846191
Validation loss: 2.0165536583110852

Epoch: 231| Step: 0
Training loss: 1.4361318349838257
Validation loss: 2.010635560558688

Epoch: 5| Step: 1
Training loss: 1.4833141565322876
Validation loss: 1.979780549644142

Epoch: 5| Step: 2
Training loss: 1.6694393157958984
Validation loss: 1.981260609883134

Epoch: 5| Step: 3
Training loss: 0.7031216621398926
Validation loss: 1.9683807793483938

Epoch: 5| Step: 4
Training loss: 1.8334029912948608
Validation loss: 1.9945260247876566

Epoch: 5| Step: 5
Training loss: 1.5903375148773193
Validation loss: 1.9787778674915273

Epoch: 5| Step: 6
Training loss: 0.7784448862075806
Validation loss: 1.9824417637240501

Epoch: 5| Step: 7
Training loss: 1.2894212007522583
Validation loss: 1.9478206762703516

Epoch: 5| Step: 8
Training loss: 1.4078575372695923
Validation loss: 1.9465615159721785

Epoch: 5| Step: 9
Training loss: 1.395519495010376
Validation loss: 1.9668712974876486

Epoch: 5| Step: 10
Training loss: 1.2699869871139526
Validation loss: 1.9708486680061585

Epoch: 232| Step: 0
Training loss: 1.4421765804290771
Validation loss: 1.976554819332656

Epoch: 5| Step: 1
Training loss: 1.353082299232483
Validation loss: 1.9743248608804518

Epoch: 5| Step: 2
Training loss: 1.3128135204315186
Validation loss: 2.0043571866968626

Epoch: 5| Step: 3
Training loss: 1.1918041706085205
Validation loss: 2.0101937658043316

Epoch: 5| Step: 4
Training loss: 1.651253342628479
Validation loss: 2.010786174446024

Epoch: 5| Step: 5
Training loss: 0.9475916028022766
Validation loss: 2.0116179207319855

Epoch: 5| Step: 6
Training loss: 1.5489633083343506
Validation loss: 2.0170661249468402

Epoch: 5| Step: 7
Training loss: 1.1461820602416992
Validation loss: 2.000601150656259

Epoch: 5| Step: 8
Training loss: 1.1967499256134033
Validation loss: 1.9968154148388935

Epoch: 5| Step: 9
Training loss: 1.4256393909454346
Validation loss: 1.9728809992472331

Epoch: 5| Step: 10
Training loss: 1.486410140991211
Validation loss: 1.9889374881662347

Epoch: 233| Step: 0
Training loss: 1.743636131286621
Validation loss: 2.0080377517207975

Epoch: 5| Step: 1
Training loss: 1.5241367816925049
Validation loss: 2.045088670587027

Epoch: 5| Step: 2
Training loss: 1.3150819540023804
Validation loss: 2.0564545892900035

Epoch: 5| Step: 3
Training loss: 0.9867690801620483
Validation loss: 2.0619216119089434

Epoch: 5| Step: 4
Training loss: 1.8259871006011963
Validation loss: 2.0598732527866157

Epoch: 5| Step: 5
Training loss: 1.34568190574646
Validation loss: 1.9739479954524706

Epoch: 5| Step: 6
Training loss: 1.3499056100845337
Validation loss: 1.9608514424293273

Epoch: 5| Step: 7
Training loss: 0.985107421875
Validation loss: 2.009555173176591

Epoch: 5| Step: 8
Training loss: 1.441207766532898
Validation loss: 1.97455507709134

Epoch: 5| Step: 9
Training loss: 0.8515775799751282
Validation loss: 1.9626333687895088

Epoch: 5| Step: 10
Training loss: 1.3154375553131104
Validation loss: 1.9847328303962626

Epoch: 234| Step: 0
Training loss: 1.342908263206482
Validation loss: 1.9718309333247523

Epoch: 5| Step: 1
Training loss: 1.3099673986434937
Validation loss: 1.9716887871424358

Epoch: 5| Step: 2
Training loss: 1.5399904251098633
Validation loss: 2.005026735285277

Epoch: 5| Step: 3
Training loss: 1.040928602218628
Validation loss: 1.9867408070512997

Epoch: 5| Step: 4
Training loss: 1.4561779499053955
Validation loss: 2.0141628967818392

Epoch: 5| Step: 5
Training loss: 1.3992042541503906
Validation loss: 1.9723590266320012

Epoch: 5| Step: 6
Training loss: 1.2603174448013306
Validation loss: 1.9577622221362205

Epoch: 5| Step: 7
Training loss: 1.0881013870239258
Validation loss: 1.9684187853208153

Epoch: 5| Step: 8
Training loss: 0.926602840423584
Validation loss: 1.932775084690381

Epoch: 5| Step: 9
Training loss: 1.451664924621582
Validation loss: 1.9257593436907696

Epoch: 5| Step: 10
Training loss: 1.681235432624817
Validation loss: 1.9212572728433917

Epoch: 235| Step: 0
Training loss: 1.2932509183883667
Validation loss: 1.9239090668257846

Epoch: 5| Step: 1
Training loss: 1.3237059116363525
Validation loss: 1.944459161450786

Epoch: 5| Step: 2
Training loss: 1.1625597476959229
Validation loss: 1.9789734630174534

Epoch: 5| Step: 3
Training loss: 1.4685337543487549
Validation loss: 1.9895957849359

Epoch: 5| Step: 4
Training loss: 1.354596495628357
Validation loss: 2.0098668452232116

Epoch: 5| Step: 5
Training loss: 1.4631373882293701
Validation loss: 2.004963415925221

Epoch: 5| Step: 6
Training loss: 0.9384000897407532
Validation loss: 1.994016440965796

Epoch: 5| Step: 7
Training loss: 1.6729605197906494
Validation loss: 2.003910523588939

Epoch: 5| Step: 8
Training loss: 0.8714615106582642
Validation loss: 1.9962907350191506

Epoch: 5| Step: 9
Training loss: 1.0618194341659546
Validation loss: 1.9941624877273396

Epoch: 5| Step: 10
Training loss: 1.8169504404067993
Validation loss: 1.9638184526915192

Epoch: 236| Step: 0
Training loss: 1.3498691320419312
Validation loss: 1.9624238552585724

Epoch: 5| Step: 1
Training loss: 1.3826367855072021
Validation loss: 1.9498762661410916

Epoch: 5| Step: 2
Training loss: 1.225743055343628
Validation loss: 1.9191816769620424

Epoch: 5| Step: 3
Training loss: 1.504944086074829
Validation loss: 1.9546973769382765

Epoch: 5| Step: 4
Training loss: 0.9949710965156555
Validation loss: 1.965065166514407

Epoch: 5| Step: 5
Training loss: 1.1725451946258545
Validation loss: 1.9558384956852082

Epoch: 5| Step: 6
Training loss: 1.627785325050354
Validation loss: 1.9357825825291295

Epoch: 5| Step: 7
Training loss: 1.5553299188613892
Validation loss: 1.9135405632757372

Epoch: 5| Step: 8
Training loss: 1.274364709854126
Validation loss: 1.8970914886843773

Epoch: 5| Step: 9
Training loss: 1.0328967571258545
Validation loss: 1.89454153660805

Epoch: 5| Step: 10
Training loss: 1.24624502658844
Validation loss: 1.9097844862168836

Epoch: 237| Step: 0
Training loss: 0.9265782237052917
Validation loss: 1.923773116962884

Epoch: 5| Step: 1
Training loss: 1.3796364068984985
Validation loss: 1.935030145029868

Epoch: 5| Step: 2
Training loss: 1.747030258178711
Validation loss: 1.9224003207299016

Epoch: 5| Step: 3
Training loss: 1.818887710571289
Validation loss: 1.9569176268833939

Epoch: 5| Step: 4
Training loss: 1.2596142292022705
Validation loss: 1.9607640774019304

Epoch: 5| Step: 5
Training loss: 1.2567756175994873
Validation loss: 1.9660218992540914

Epoch: 5| Step: 6
Training loss: 1.2636305093765259
Validation loss: 1.9414570613573956

Epoch: 5| Step: 7
Training loss: 0.731464147567749
Validation loss: 1.9586255294020458

Epoch: 5| Step: 8
Training loss: 1.2466576099395752
Validation loss: 1.9225408210549304

Epoch: 5| Step: 9
Training loss: 1.338498830795288
Validation loss: 1.9258675549619941

Epoch: 5| Step: 10
Training loss: 1.1096765995025635
Validation loss: 1.940907080968221

Epoch: 238| Step: 0
Training loss: 1.0966212749481201
Validation loss: 1.9460255087062877

Epoch: 5| Step: 1
Training loss: 0.9957897067070007
Validation loss: 1.9552599281393073

Epoch: 5| Step: 2
Training loss: 0.9617688059806824
Validation loss: 1.9587998518379786

Epoch: 5| Step: 3
Training loss: 0.9983003735542297
Validation loss: 1.9795786462804323

Epoch: 5| Step: 4
Training loss: 1.2497161626815796
Validation loss: 1.9890574601388746

Epoch: 5| Step: 5
Training loss: 1.1480494737625122
Validation loss: 1.9843126907143542

Epoch: 5| Step: 6
Training loss: 0.8721364140510559
Validation loss: 1.9629500809536184

Epoch: 5| Step: 7
Training loss: 1.360537052154541
Validation loss: 1.925029662347609

Epoch: 5| Step: 8
Training loss: 1.5193475484848022
Validation loss: 1.8990092815891388

Epoch: 5| Step: 9
Training loss: 2.300983428955078
Validation loss: 1.9026480336343088

Epoch: 5| Step: 10
Training loss: 1.295650601387024
Validation loss: 1.8905981522734447

Epoch: 239| Step: 0
Training loss: 1.4167604446411133
Validation loss: 1.8694081152639082

Epoch: 5| Step: 1
Training loss: 1.6026111841201782
Validation loss: 1.8990028109601749

Epoch: 5| Step: 2
Training loss: 1.1104536056518555
Validation loss: 1.9223462766216648

Epoch: 5| Step: 3
Training loss: 0.9600679278373718
Validation loss: 1.932612032018682

Epoch: 5| Step: 4
Training loss: 1.0735013484954834
Validation loss: 1.965529380306121

Epoch: 5| Step: 5
Training loss: 1.65243399143219
Validation loss: 1.9679162476652412

Epoch: 5| Step: 6
Training loss: 1.1964908838272095
Validation loss: 1.9503202745991368

Epoch: 5| Step: 7
Training loss: 1.0262196063995361
Validation loss: 1.9203907071903188

Epoch: 5| Step: 8
Training loss: 1.1247082948684692
Validation loss: 1.926403086672547

Epoch: 5| Step: 9
Training loss: 1.391461968421936
Validation loss: 1.9369342827027844

Epoch: 5| Step: 10
Training loss: 1.3730427026748657
Validation loss: 1.9232291060109292

Epoch: 240| Step: 0
Training loss: 1.3030247688293457
Validation loss: 1.8981205276263657

Epoch: 5| Step: 1
Training loss: 1.1935726404190063
Validation loss: 1.8996700817538845

Epoch: 5| Step: 2
Training loss: 0.7923555970191956
Validation loss: 1.9238910136684295

Epoch: 5| Step: 3
Training loss: 1.7598568201065063
Validation loss: 1.9186321150872014

Epoch: 5| Step: 4
Training loss: 1.4768375158309937
Validation loss: 1.9202287876477806

Epoch: 5| Step: 5
Training loss: 1.391732096672058
Validation loss: 1.9526080713477185

Epoch: 5| Step: 6
Training loss: 1.5904009342193604
Validation loss: 1.9474004673701462

Epoch: 5| Step: 7
Training loss: 1.078168511390686
Validation loss: 1.9228978708226194

Epoch: 5| Step: 8
Training loss: 0.9564000964164734
Validation loss: 1.9311571505761915

Epoch: 5| Step: 9
Training loss: 0.8252174258232117
Validation loss: 1.938040025772587

Epoch: 5| Step: 10
Training loss: 1.3833016157150269
Validation loss: 1.931340120171988

Epoch: 241| Step: 0
Training loss: 1.7799440622329712
Validation loss: 1.9595321250218216

Epoch: 5| Step: 1
Training loss: 0.8468562960624695
Validation loss: 1.9431993512697117

Epoch: 5| Step: 2
Training loss: 0.8835784792900085
Validation loss: 1.9537115199591524

Epoch: 5| Step: 3
Training loss: 1.7707548141479492
Validation loss: 1.9508174298911967

Epoch: 5| Step: 4
Training loss: 1.2635396718978882
Validation loss: 1.9513288415888304

Epoch: 5| Step: 5
Training loss: 0.9717456102371216
Validation loss: 1.9736408648952362

Epoch: 5| Step: 6
Training loss: 1.0922596454620361
Validation loss: 1.9521926282554545

Epoch: 5| Step: 7
Training loss: 1.1022757291793823
Validation loss: 1.9409488503650953

Epoch: 5| Step: 8
Training loss: 1.206655740737915
Validation loss: 1.9372308715697257

Epoch: 5| Step: 9
Training loss: 1.597508192062378
Validation loss: 1.912145794078868

Epoch: 5| Step: 10
Training loss: 1.239823818206787
Validation loss: 1.908551675017162

Epoch: 242| Step: 0
Training loss: 0.7922245264053345
Validation loss: 1.8887464820697744

Epoch: 5| Step: 1
Training loss: 1.5447330474853516
Validation loss: 1.8871839539979094

Epoch: 5| Step: 2
Training loss: 1.0309146642684937
Validation loss: 1.9111745113967566

Epoch: 5| Step: 3
Training loss: 1.5304304361343384
Validation loss: 1.929239805026721

Epoch: 5| Step: 4
Training loss: 1.4608662128448486
Validation loss: 1.9171239817014305

Epoch: 5| Step: 5
Training loss: 1.2402875423431396
Validation loss: 1.9267710396038589

Epoch: 5| Step: 6
Training loss: 0.6841976046562195
Validation loss: 1.9247899465663458

Epoch: 5| Step: 7
Training loss: 0.9202070236206055
Validation loss: 1.9634204064646075

Epoch: 5| Step: 8
Training loss: 1.4866477251052856
Validation loss: 1.9919873796483523

Epoch: 5| Step: 9
Training loss: 1.8218953609466553
Validation loss: 1.9727295919131207

Epoch: 5| Step: 10
Training loss: 1.00001859664917
Validation loss: 1.9693187026567356

Epoch: 243| Step: 0
Training loss: 1.5722750425338745
Validation loss: 1.9370651655299689

Epoch: 5| Step: 1
Training loss: 0.7611778378486633
Validation loss: 1.945428845702961

Epoch: 5| Step: 2
Training loss: 1.5981906652450562
Validation loss: 1.8900942558883338

Epoch: 5| Step: 3
Training loss: 0.9957731366157532
Validation loss: 1.852355707076288

Epoch: 5| Step: 4
Training loss: 1.2480623722076416
Validation loss: 1.8461010225357548

Epoch: 5| Step: 5
Training loss: 0.9341278076171875
Validation loss: 1.921509365881643

Epoch: 5| Step: 6
Training loss: 1.5986231565475464
Validation loss: 1.9101209089320192

Epoch: 5| Step: 7
Training loss: 1.194284200668335
Validation loss: 1.9168286208183534

Epoch: 5| Step: 8
Training loss: 1.6165359020233154
Validation loss: 1.886745220871382

Epoch: 5| Step: 9
Training loss: 0.8931818008422852
Validation loss: 1.8624954185178202

Epoch: 5| Step: 10
Training loss: 1.3766947984695435
Validation loss: 1.8845055872394192

Epoch: 244| Step: 0
Training loss: 1.36141037940979
Validation loss: 1.8909576862089095

Epoch: 5| Step: 1
Training loss: 1.298393726348877
Validation loss: 1.919697065507212

Epoch: 5| Step: 2
Training loss: 1.1684904098510742
Validation loss: 1.9276299873987834

Epoch: 5| Step: 3
Training loss: 1.0258342027664185
Validation loss: 1.951781508743122

Epoch: 5| Step: 4
Training loss: 1.9010999202728271
Validation loss: 1.9636775985840829

Epoch: 5| Step: 5
Training loss: 0.7845463156700134
Validation loss: 1.9983876418041926

Epoch: 5| Step: 6
Training loss: 1.3568172454833984
Validation loss: 2.0181582845667356

Epoch: 5| Step: 7
Training loss: 0.9279842376708984
Validation loss: 1.987220691096398

Epoch: 5| Step: 8
Training loss: 1.1076656579971313
Validation loss: 1.9377105928236438

Epoch: 5| Step: 9
Training loss: 1.5024486780166626
Validation loss: 1.9064393325518536

Epoch: 5| Step: 10
Training loss: 1.1155558824539185
Validation loss: 1.8992969323230047

Epoch: 245| Step: 0
Training loss: 1.2482221126556396
Validation loss: 1.8874106278983496

Epoch: 5| Step: 1
Training loss: 1.3971246480941772
Validation loss: 1.866271121527559

Epoch: 5| Step: 2
Training loss: 1.0658109188079834
Validation loss: 1.889580031876923

Epoch: 5| Step: 3
Training loss: 1.3110733032226562
Validation loss: 1.9037122085530271

Epoch: 5| Step: 4
Training loss: 1.0844967365264893
Validation loss: 1.9231109080776092

Epoch: 5| Step: 5
Training loss: 1.293238878250122
Validation loss: 1.9004116122440626

Epoch: 5| Step: 6
Training loss: 1.5643947124481201
Validation loss: 1.8916579549030592

Epoch: 5| Step: 7
Training loss: 1.119921326637268
Validation loss: 1.8843278718251053

Epoch: 5| Step: 8
Training loss: 1.4377859830856323
Validation loss: 1.9026475491062287

Epoch: 5| Step: 9
Training loss: 0.8377216458320618
Validation loss: 1.91907783092991

Epoch: 5| Step: 10
Training loss: 1.2368143796920776
Validation loss: 1.96192805997787

Epoch: 246| Step: 0
Training loss: 0.7773592472076416
Validation loss: 1.9804846740538073

Epoch: 5| Step: 1
Training loss: 1.1449415683746338
Validation loss: 1.9705398903098157

Epoch: 5| Step: 2
Training loss: 1.1669868230819702
Validation loss: 1.9911360189478884

Epoch: 5| Step: 3
Training loss: 1.3691784143447876
Validation loss: 1.960297446097097

Epoch: 5| Step: 4
Training loss: 1.2514498233795166
Validation loss: 1.9611214335246752

Epoch: 5| Step: 5
Training loss: 1.508228063583374
Validation loss: 1.938139086128563

Epoch: 5| Step: 6
Training loss: 1.3209152221679688
Validation loss: 1.9333460266872118

Epoch: 5| Step: 7
Training loss: 0.9285006523132324
Validation loss: 1.9298112828244445

Epoch: 5| Step: 8
Training loss: 1.0543140172958374
Validation loss: 1.915673137992941

Epoch: 5| Step: 9
Training loss: 1.282982587814331
Validation loss: 1.8874413454404442

Epoch: 5| Step: 10
Training loss: 1.1379588842391968
Validation loss: 1.8837832199629916

Epoch: 247| Step: 0
Training loss: 1.237038254737854
Validation loss: 1.8899158277819235

Epoch: 5| Step: 1
Training loss: 1.2461687326431274
Validation loss: 1.8753772499740764

Epoch: 5| Step: 2
Training loss: 1.3974562883377075
Validation loss: 1.9011458248220465

Epoch: 5| Step: 3
Training loss: 0.9428528547286987
Validation loss: 1.885731138208861

Epoch: 5| Step: 4
Training loss: 1.1474008560180664
Validation loss: 1.959909164777366

Epoch: 5| Step: 5
Training loss: 1.952309012413025
Validation loss: 1.9880324999491374

Epoch: 5| Step: 6
Training loss: 1.146982192993164
Validation loss: 2.017199491941801

Epoch: 5| Step: 7
Training loss: 1.274712324142456
Validation loss: 2.0167679825136737

Epoch: 5| Step: 8
Training loss: 0.9723424911499023
Validation loss: 2.0018183691527254

Epoch: 5| Step: 9
Training loss: 1.0302625894546509
Validation loss: 1.9754491006174395

Epoch: 5| Step: 10
Training loss: 0.6781627535820007
Validation loss: 1.9503805970632901

Epoch: 248| Step: 0
Training loss: 1.036741018295288
Validation loss: 1.9226081768671672

Epoch: 5| Step: 1
Training loss: 1.2389910221099854
Validation loss: 1.9060698760453092

Epoch: 5| Step: 2
Training loss: 0.8431224822998047
Validation loss: 1.8855720463619436

Epoch: 5| Step: 3
Training loss: 1.1312364339828491
Validation loss: 1.8687858966089064

Epoch: 5| Step: 4
Training loss: 1.321706771850586
Validation loss: 1.8663766409761162

Epoch: 5| Step: 5
Training loss: 0.9078639149665833
Validation loss: 1.845960920856845

Epoch: 5| Step: 6
Training loss: 1.546325445175171
Validation loss: 1.8361100009692612

Epoch: 5| Step: 7
Training loss: 1.2355775833129883
Validation loss: 1.860871858494256

Epoch: 5| Step: 8
Training loss: 1.1306779384613037
Validation loss: 1.8738823001102736

Epoch: 5| Step: 9
Training loss: 1.5977518558502197
Validation loss: 1.937071269558322

Epoch: 5| Step: 10
Training loss: 1.1304893493652344
Validation loss: 1.9597989718119304

Epoch: 249| Step: 0
Training loss: 1.5025526285171509
Validation loss: 1.9626201557856735

Epoch: 5| Step: 1
Training loss: 1.246034026145935
Validation loss: 1.9460773147562498

Epoch: 5| Step: 2
Training loss: 1.1825937032699585
Validation loss: 1.9226434640986945

Epoch: 5| Step: 3
Training loss: 0.9957534670829773
Validation loss: 1.900362480071283

Epoch: 5| Step: 4
Training loss: 1.4517457485198975
Validation loss: 1.8564625683651175

Epoch: 5| Step: 5
Training loss: 1.3985248804092407
Validation loss: 1.8500010941618232

Epoch: 5| Step: 6
Training loss: 1.2037181854248047
Validation loss: 1.8557057290948846

Epoch: 5| Step: 7
Training loss: 1.547294020652771
Validation loss: 1.8513039440237067

Epoch: 5| Step: 8
Training loss: 0.7821844220161438
Validation loss: 1.869678258895874

Epoch: 5| Step: 9
Training loss: 1.139172077178955
Validation loss: 1.8834091360851

Epoch: 5| Step: 10
Training loss: 0.8195436000823975
Validation loss: 1.8922496764890608

Epoch: 250| Step: 0
Training loss: 1.4122397899627686
Validation loss: 1.9358210909751155

Epoch: 5| Step: 1
Training loss: 1.0513883829116821
Validation loss: 1.999959473968834

Epoch: 5| Step: 2
Training loss: 1.2845561504364014
Validation loss: 2.032823752331477

Epoch: 5| Step: 3
Training loss: 1.4897491931915283
Validation loss: 2.015153879760414

Epoch: 5| Step: 4
Training loss: 1.207727074623108
Validation loss: 2.01389560391826

Epoch: 5| Step: 5
Training loss: 1.078324317932129
Validation loss: 2.0046848802156347

Epoch: 5| Step: 6
Training loss: 1.292535662651062
Validation loss: 1.9883283133147864

Epoch: 5| Step: 7
Training loss: 1.0223039388656616
Validation loss: 1.9359086944210915

Epoch: 5| Step: 8
Training loss: 1.32016921043396
Validation loss: 1.8956708651716991

Epoch: 5| Step: 9
Training loss: 0.7700153589248657
Validation loss: 1.8507127787477227

Epoch: 5| Step: 10
Training loss: 1.467739224433899
Validation loss: 1.851485712553865

Epoch: 251| Step: 0
Training loss: 0.7487190961837769
Validation loss: 1.8799664051302019

Epoch: 5| Step: 1
Training loss: 0.6127868890762329
Validation loss: 1.8649047625962125

Epoch: 5| Step: 2
Training loss: 1.140451192855835
Validation loss: 1.8681912268361738

Epoch: 5| Step: 3
Training loss: 1.2245395183563232
Validation loss: 1.8961636135655064

Epoch: 5| Step: 4
Training loss: 1.2944072484970093
Validation loss: 1.939460337802928

Epoch: 5| Step: 5
Training loss: 1.685951828956604
Validation loss: 1.933882405680995

Epoch: 5| Step: 6
Training loss: 0.9513952136039734
Validation loss: 1.9551366772702945

Epoch: 5| Step: 7
Training loss: 1.2627348899841309
Validation loss: 1.9673011687494093

Epoch: 5| Step: 8
Training loss: 1.1489026546478271
Validation loss: 1.9492656466781453

Epoch: 5| Step: 9
Training loss: 1.4695346355438232
Validation loss: 1.9342735608418782

Epoch: 5| Step: 10
Training loss: 1.238835096359253
Validation loss: 1.9418380157921904

Epoch: 252| Step: 0
Training loss: 1.2736823558807373
Validation loss: 1.9316355951370732

Epoch: 5| Step: 1
Training loss: 1.0351307392120361
Validation loss: 1.9505033787860666

Epoch: 5| Step: 2
Training loss: 0.8054904937744141
Validation loss: 1.9278966431976647

Epoch: 5| Step: 3
Training loss: 0.9743314981460571
Validation loss: 1.9355990258596276

Epoch: 5| Step: 4
Training loss: 1.5134626626968384
Validation loss: 1.9322130257083523

Epoch: 5| Step: 5
Training loss: 0.7112228870391846
Validation loss: 1.918965890843381

Epoch: 5| Step: 6
Training loss: 1.0288113355636597
Validation loss: 1.9372908274332683

Epoch: 5| Step: 7
Training loss: 1.3375457525253296
Validation loss: 1.9077370858961535

Epoch: 5| Step: 8
Training loss: 1.3484861850738525
Validation loss: 1.8984759007730792

Epoch: 5| Step: 9
Training loss: 1.5841728448867798
Validation loss: 1.8623704961551133

Epoch: 5| Step: 10
Training loss: 0.9867083430290222
Validation loss: 1.85241630641363

Epoch: 253| Step: 0
Training loss: 1.5322751998901367
Validation loss: 1.8212247330655333

Epoch: 5| Step: 1
Training loss: 1.1660168170928955
Validation loss: 1.8303199288665608

Epoch: 5| Step: 2
Training loss: 0.7433520555496216
Validation loss: 1.8382501127899333

Epoch: 5| Step: 3
Training loss: 0.8327144384384155
Validation loss: 1.8591482511130712

Epoch: 5| Step: 4
Training loss: 0.9415260553359985
Validation loss: 1.8563159460662513

Epoch: 5| Step: 5
Training loss: 0.8467544317245483
Validation loss: 1.8685568801818355

Epoch: 5| Step: 6
Training loss: 1.1307744979858398
Validation loss: 1.8709549121959235

Epoch: 5| Step: 7
Training loss: 1.5167417526245117
Validation loss: 1.8868570539259142

Epoch: 5| Step: 8
Training loss: 1.2368654012680054
Validation loss: 1.9056110202625234

Epoch: 5| Step: 9
Training loss: 1.4744189977645874
Validation loss: 1.9293798990147089

Epoch: 5| Step: 10
Training loss: 0.9075716733932495
Validation loss: 1.9446380933125813

Epoch: 254| Step: 0
Training loss: 0.5885348320007324
Validation loss: 1.9419533078388502

Epoch: 5| Step: 1
Training loss: 1.4006829261779785
Validation loss: 1.9641854442575926

Epoch: 5| Step: 2
Training loss: 1.6557681560516357
Validation loss: 1.9738156103318738

Epoch: 5| Step: 3
Training loss: 1.3592593669891357
Validation loss: 1.9589786196267733

Epoch: 5| Step: 4
Training loss: 0.9560235738754272
Validation loss: 1.9326182027016916

Epoch: 5| Step: 5
Training loss: 1.0198862552642822
Validation loss: 1.8829804902435632

Epoch: 5| Step: 6
Training loss: 0.7874822616577148
Validation loss: 1.8821814367848058

Epoch: 5| Step: 7
Training loss: 1.2324812412261963
Validation loss: 1.88705216428285

Epoch: 5| Step: 8
Training loss: 1.3585758209228516
Validation loss: 1.8661775806898713

Epoch: 5| Step: 9
Training loss: 1.0607963800430298
Validation loss: 1.894128905829563

Epoch: 5| Step: 10
Training loss: 0.9459412693977356
Validation loss: 1.880100078480218

Epoch: 255| Step: 0
Training loss: 1.3429107666015625
Validation loss: 1.9237619369260726

Epoch: 5| Step: 1
Training loss: 1.399125337600708
Validation loss: 1.8936444149222424

Epoch: 5| Step: 2
Training loss: 0.9232832789421082
Validation loss: 1.9053326870805474

Epoch: 5| Step: 3
Training loss: 1.2855533361434937
Validation loss: 1.8512762849048903

Epoch: 5| Step: 4
Training loss: 0.9191843867301941
Validation loss: 1.8811046333723171

Epoch: 5| Step: 5
Training loss: 0.8676126599311829
Validation loss: 1.8827627986989997

Epoch: 5| Step: 6
Training loss: 1.1430453062057495
Validation loss: 1.8952368536303121

Epoch: 5| Step: 7
Training loss: 1.1983743906021118
Validation loss: 1.9124288469232538

Epoch: 5| Step: 8
Training loss: 1.181551218032837
Validation loss: 1.9145024925149896

Epoch: 5| Step: 9
Training loss: 0.9753518104553223
Validation loss: 1.9180144571488904

Epoch: 5| Step: 10
Training loss: 1.0971055030822754
Validation loss: 1.9198000943788918

Epoch: 256| Step: 0
Training loss: 1.0398344993591309
Validation loss: 1.9480612918894777

Epoch: 5| Step: 1
Training loss: 0.9716669321060181
Validation loss: 1.9363952285499983

Epoch: 5| Step: 2
Training loss: 1.139201045036316
Validation loss: 1.934869295807295

Epoch: 5| Step: 3
Training loss: 0.9590771794319153
Validation loss: 1.9227252224440217

Epoch: 5| Step: 4
Training loss: 1.0342254638671875
Validation loss: 1.9230158880192747

Epoch: 5| Step: 5
Training loss: 1.1303409337997437
Validation loss: 1.9015572417166926

Epoch: 5| Step: 6
Training loss: 1.4182649850845337
Validation loss: 1.9039806614639938

Epoch: 5| Step: 7
Training loss: 0.6118888854980469
Validation loss: 1.8819861642775997

Epoch: 5| Step: 8
Training loss: 1.011790156364441
Validation loss: 1.840373654519358

Epoch: 5| Step: 9
Training loss: 1.4563015699386597
Validation loss: 1.8376851517667052

Epoch: 5| Step: 10
Training loss: 1.4595518112182617
Validation loss: 1.851221034603734

Epoch: 257| Step: 0
Training loss: 0.9300368428230286
Validation loss: 1.8761890485722532

Epoch: 5| Step: 1
Training loss: 0.5084716081619263
Validation loss: 1.86157988989225

Epoch: 5| Step: 2
Training loss: 1.3287408351898193
Validation loss: 1.8233830057164675

Epoch: 5| Step: 3
Training loss: 1.2224416732788086
Validation loss: 1.8477772217924877

Epoch: 5| Step: 4
Training loss: 0.9368775486946106
Validation loss: 1.8797581349649737

Epoch: 5| Step: 5
Training loss: 1.0696463584899902
Validation loss: 1.9064603967051352

Epoch: 5| Step: 6
Training loss: 1.4495073556900024
Validation loss: 1.9442296540865334

Epoch: 5| Step: 7
Training loss: 1.2674412727355957
Validation loss: 1.8914274592553415

Epoch: 5| Step: 8
Training loss: 1.4594615697860718
Validation loss: 1.926812356518161

Epoch: 5| Step: 9
Training loss: 0.952933669090271
Validation loss: 1.9053631931222894

Epoch: 5| Step: 10
Training loss: 1.1300816535949707
Validation loss: 1.9127518566705848

Epoch: 258| Step: 0
Training loss: 1.1616569757461548
Validation loss: 1.929291009902954

Epoch: 5| Step: 1
Training loss: 1.224435567855835
Validation loss: 1.9421731143869378

Epoch: 5| Step: 2
Training loss: 0.9722601175308228
Validation loss: 1.96129027746057

Epoch: 5| Step: 3
Training loss: 1.2344847917556763
Validation loss: 1.9908482772047802

Epoch: 5| Step: 4
Training loss: 1.1641182899475098
Validation loss: 1.9723323429784467

Epoch: 5| Step: 5
Training loss: 0.8472447395324707
Validation loss: 1.9348831599758518

Epoch: 5| Step: 6
Training loss: 1.0540255308151245
Validation loss: 1.9128145774205525

Epoch: 5| Step: 7
Training loss: 1.3070865869522095
Validation loss: 1.8855788066822996

Epoch: 5| Step: 8
Training loss: 1.1919243335723877
Validation loss: 1.8838584615338234

Epoch: 5| Step: 9
Training loss: 1.0083258152008057
Validation loss: 1.8966560453496955

Epoch: 5| Step: 10
Training loss: 0.8071829080581665
Validation loss: 1.8800806409569197

Epoch: 259| Step: 0
Training loss: 0.8612858057022095
Validation loss: 1.8970560835253807

Epoch: 5| Step: 1
Training loss: 1.148648977279663
Validation loss: 1.8893627453875799

Epoch: 5| Step: 2
Training loss: 1.0240451097488403
Validation loss: 1.8823664778022355

Epoch: 5| Step: 3
Training loss: 0.9508498907089233
Validation loss: 1.8802586601626488

Epoch: 5| Step: 4
Training loss: 1.0382453203201294
Validation loss: 1.8661706921874837

Epoch: 5| Step: 5
Training loss: 1.3193775415420532
Validation loss: 1.8649489828335342

Epoch: 5| Step: 6
Training loss: 1.0641573667526245
Validation loss: 1.8812236555161015

Epoch: 5| Step: 7
Training loss: 0.9174844026565552
Validation loss: 1.9007557861266597

Epoch: 5| Step: 8
Training loss: 1.3003711700439453
Validation loss: 1.933043776019927

Epoch: 5| Step: 9
Training loss: 1.0428882837295532
Validation loss: 1.9148212248279202

Epoch: 5| Step: 10
Training loss: 1.067603349685669
Validation loss: 1.9433294111682522

Epoch: 260| Step: 0
Training loss: 0.9714488983154297
Validation loss: 1.913864420306298

Epoch: 5| Step: 1
Training loss: 1.3074787855148315
Validation loss: 1.8978760242462158

Epoch: 5| Step: 2
Training loss: 0.9429916143417358
Validation loss: 1.8768059592093191

Epoch: 5| Step: 3
Training loss: 0.9541058540344238
Validation loss: 1.8743629250475156

Epoch: 5| Step: 4
Training loss: 1.45937979221344
Validation loss: 1.8683858943241898

Epoch: 5| Step: 5
Training loss: 0.7832618951797485
Validation loss: 1.8525723129190423

Epoch: 5| Step: 6
Training loss: 1.0604097843170166
Validation loss: 1.8414674881965882

Epoch: 5| Step: 7
Training loss: 1.1394404172897339
Validation loss: 1.8439751414842502

Epoch: 5| Step: 8
Training loss: 0.817768931388855
Validation loss: 1.8340100293518395

Epoch: 5| Step: 9
Training loss: 1.3705085515975952
Validation loss: 1.8550499100838937

Epoch: 5| Step: 10
Training loss: 1.0513325929641724
Validation loss: 1.8474598674363987

Epoch: 261| Step: 0
Training loss: 0.4351016879081726
Validation loss: 1.8799754547816452

Epoch: 5| Step: 1
Training loss: 1.267972469329834
Validation loss: 1.9211602339180567

Epoch: 5| Step: 2
Training loss: 0.8706022500991821
Validation loss: 1.9278213016448482

Epoch: 5| Step: 3
Training loss: 0.826696515083313
Validation loss: 1.970496851910827

Epoch: 5| Step: 4
Training loss: 1.1231341361999512
Validation loss: 1.963898710025254

Epoch: 5| Step: 5
Training loss: 1.2954199314117432
Validation loss: 1.9792073977890836

Epoch: 5| Step: 6
Training loss: 1.093406081199646
Validation loss: 1.975271837685698

Epoch: 5| Step: 7
Training loss: 1.3146231174468994
Validation loss: 1.934013593581415

Epoch: 5| Step: 8
Training loss: 1.5397318601608276
Validation loss: 1.8815206866110525

Epoch: 5| Step: 9
Training loss: 1.015291452407837
Validation loss: 1.851157626798076

Epoch: 5| Step: 10
Training loss: 0.8997445106506348
Validation loss: 1.8020238876342773

Epoch: 262| Step: 0
Training loss: 1.4236949682235718
Validation loss: 1.8356958012427054

Epoch: 5| Step: 1
Training loss: 1.0899555683135986
Validation loss: 1.8775839959421465

Epoch: 5| Step: 2
Training loss: 0.7910036444664001
Validation loss: 1.8948210631647417

Epoch: 5| Step: 3
Training loss: 1.1900286674499512
Validation loss: 1.8733344078063965

Epoch: 5| Step: 4
Training loss: 0.9982598423957825
Validation loss: 1.8745679727164648

Epoch: 5| Step: 5
Training loss: 0.910892128944397
Validation loss: 1.8575441375855477

Epoch: 5| Step: 6
Training loss: 1.071642518043518
Validation loss: 1.8699019211594776

Epoch: 5| Step: 7
Training loss: 1.199449062347412
Validation loss: 1.9025263901679748

Epoch: 5| Step: 8
Training loss: 1.1206333637237549
Validation loss: 1.9387246870225476

Epoch: 5| Step: 9
Training loss: 1.198799967765808
Validation loss: 1.941847566635378

Epoch: 5| Step: 10
Training loss: 1.1375131607055664
Validation loss: 1.9404689599108953

Epoch: 263| Step: 0
Training loss: 1.0648607015609741
Validation loss: 1.9294825830767233

Epoch: 5| Step: 1
Training loss: 0.9361467361450195
Validation loss: 1.9394553220400246

Epoch: 5| Step: 2
Training loss: 1.1120250225067139
Validation loss: 1.9360161263455626

Epoch: 5| Step: 3
Training loss: 0.8586575388908386
Validation loss: 1.9148674190685313

Epoch: 5| Step: 4
Training loss: 1.3195290565490723
Validation loss: 1.8776448260071457

Epoch: 5| Step: 5
Training loss: 0.5090250968933105
Validation loss: 1.870635591527467

Epoch: 5| Step: 6
Training loss: 1.4130626916885376
Validation loss: 1.8295441109647033

Epoch: 5| Step: 7
Training loss: 0.8901020884513855
Validation loss: 1.8104140732877998

Epoch: 5| Step: 8
Training loss: 0.8352473378181458
Validation loss: 1.8268886548216625

Epoch: 5| Step: 9
Training loss: 1.329938292503357
Validation loss: 1.8519689447136336

Epoch: 5| Step: 10
Training loss: 1.3474007844924927
Validation loss: 1.8059976767468195

Epoch: 264| Step: 0
Training loss: 1.227048635482788
Validation loss: 1.8469932335679249

Epoch: 5| Step: 1
Training loss: 0.5996029376983643
Validation loss: 1.8232910902269426

Epoch: 5| Step: 2
Training loss: 0.9366017580032349
Validation loss: 1.8511911848539948

Epoch: 5| Step: 3
Training loss: 1.2886381149291992
Validation loss: 1.851441994790108

Epoch: 5| Step: 4
Training loss: 0.9581152200698853
Validation loss: 1.8517392168762863

Epoch: 5| Step: 5
Training loss: 0.7583370804786682
Validation loss: 1.8692393995100451

Epoch: 5| Step: 6
Training loss: 0.7564910054206848
Validation loss: 1.870494629747124

Epoch: 5| Step: 7
Training loss: 1.189645528793335
Validation loss: 1.8585930332060783

Epoch: 5| Step: 8
Training loss: 1.1562148332595825
Validation loss: 1.9041138874587191

Epoch: 5| Step: 9
Training loss: 1.093742847442627
Validation loss: 1.8937566716183898

Epoch: 5| Step: 10
Training loss: 1.2402925491333008
Validation loss: 1.844725570371074

Epoch: 265| Step: 0
Training loss: 1.0294610261917114
Validation loss: 1.8638827006022136

Epoch: 5| Step: 1
Training loss: 0.5190245509147644
Validation loss: 1.8412258445575673

Epoch: 5| Step: 2
Training loss: 1.0509960651397705
Validation loss: 1.841950834438365

Epoch: 5| Step: 3
Training loss: 1.0621473789215088
Validation loss: 1.8139073579542098

Epoch: 5| Step: 4
Training loss: 0.7112168669700623
Validation loss: 1.8375515578895487

Epoch: 5| Step: 5
Training loss: 1.0847941637039185
Validation loss: 1.8420275462571012

Epoch: 5| Step: 6
Training loss: 1.1315821409225464
Validation loss: 1.8503494390877344

Epoch: 5| Step: 7
Training loss: 1.7029924392700195
Validation loss: 1.8654737126442693

Epoch: 5| Step: 8
Training loss: 1.0786627531051636
Validation loss: 1.8989594521061066

Epoch: 5| Step: 9
Training loss: 0.7700830698013306
Validation loss: 1.927443688915622

Epoch: 5| Step: 10
Training loss: 0.7787210941314697
Validation loss: 1.958253865600914

Epoch: 266| Step: 0
Training loss: 0.9522154927253723
Validation loss: 1.9541623669285928

Epoch: 5| Step: 1
Training loss: 1.2098171710968018
Validation loss: 1.9796656870072888

Epoch: 5| Step: 2
Training loss: 0.9876920580863953
Validation loss: 1.992126811576146

Epoch: 5| Step: 3
Training loss: 0.7610095739364624
Validation loss: 1.965711949973978

Epoch: 5| Step: 4
Training loss: 0.9187678098678589
Validation loss: 1.9361175926782752

Epoch: 5| Step: 5
Training loss: 1.6401185989379883
Validation loss: 1.897722780063588

Epoch: 5| Step: 6
Training loss: 0.7043195962905884
Validation loss: 1.8784943024317424

Epoch: 5| Step: 7
Training loss: 0.9760425686836243
Validation loss: 1.841054634381366

Epoch: 5| Step: 8
Training loss: 1.0361042022705078
Validation loss: 1.806770428534477

Epoch: 5| Step: 9
Training loss: 0.9941765666007996
Validation loss: 1.7847758877661921

Epoch: 5| Step: 10
Training loss: 0.8361383080482483
Validation loss: 1.801321929500949

Epoch: 267| Step: 0
Training loss: 0.6193814277648926
Validation loss: 1.8179369998234574

Epoch: 5| Step: 1
Training loss: 1.128791332244873
Validation loss: 1.8356439887836415

Epoch: 5| Step: 2
Training loss: 1.2330141067504883
Validation loss: 1.8621630822458575

Epoch: 5| Step: 3
Training loss: 0.9276766777038574
Validation loss: 1.902331349670246

Epoch: 5| Step: 4
Training loss: 1.045581340789795
Validation loss: 1.9113695672763291

Epoch: 5| Step: 5
Training loss: 0.9470981359481812
Validation loss: 1.8862670570291498

Epoch: 5| Step: 6
Training loss: 1.0273969173431396
Validation loss: 1.8852109524511522

Epoch: 5| Step: 7
Training loss: 1.3568525314331055
Validation loss: 1.8789505984193535

Epoch: 5| Step: 8
Training loss: 0.9190581440925598
Validation loss: 1.9062018727743497

Epoch: 5| Step: 9
Training loss: 0.5543845891952515
Validation loss: 1.9036149927364883

Epoch: 5| Step: 10
Training loss: 1.4209604263305664
Validation loss: 1.8707304129036524

Epoch: 268| Step: 0
Training loss: 0.6605746150016785
Validation loss: 1.849187881715836

Epoch: 5| Step: 1
Training loss: 1.4425299167633057
Validation loss: 1.8690201825993036

Epoch: 5| Step: 2
Training loss: 0.6887915730476379
Validation loss: 1.8956360637500722

Epoch: 5| Step: 3
Training loss: 1.0747735500335693
Validation loss: 1.9136273296930457

Epoch: 5| Step: 4
Training loss: 1.206101894378662
Validation loss: 1.9324751669360745

Epoch: 5| Step: 5
Training loss: 1.4226067066192627
Validation loss: 1.8989214089608961

Epoch: 5| Step: 6
Training loss: 0.8562371134757996
Validation loss: 1.9009614785512288

Epoch: 5| Step: 7
Training loss: 0.8403550982475281
Validation loss: 1.896496271574369

Epoch: 5| Step: 8
Training loss: 0.7234633564949036
Validation loss: 1.8570040631037887

Epoch: 5| Step: 9
Training loss: 0.7295451164245605
Validation loss: 1.874272552869653

Epoch: 5| Step: 10
Training loss: 1.2264580726623535
Validation loss: 1.834681039215416

Epoch: 269| Step: 0
Training loss: 1.0502421855926514
Validation loss: 1.8438477387992285

Epoch: 5| Step: 1
Training loss: 1.2664353847503662
Validation loss: 1.8175495106686828

Epoch: 5| Step: 2
Training loss: 1.1230090856552124
Validation loss: 1.825648694910029

Epoch: 5| Step: 3
Training loss: 1.3352842330932617
Validation loss: 1.8446191856938023

Epoch: 5| Step: 4
Training loss: 0.7534126043319702
Validation loss: 1.8181848731092227

Epoch: 5| Step: 5
Training loss: 0.7053106427192688
Validation loss: 1.8560954780988796

Epoch: 5| Step: 6
Training loss: 0.8606202006340027
Validation loss: 1.8406635125478108

Epoch: 5| Step: 7
Training loss: 0.8610076904296875
Validation loss: 1.8778037589083436

Epoch: 5| Step: 8
Training loss: 0.9026235342025757
Validation loss: 1.861750800122497

Epoch: 5| Step: 9
Training loss: 1.020524501800537
Validation loss: 1.8741160490179574

Epoch: 5| Step: 10
Training loss: 1.227467656135559
Validation loss: 1.8100076349832679

Epoch: 270| Step: 0
Training loss: 0.8028866052627563
Validation loss: 1.812645576333487

Epoch: 5| Step: 1
Training loss: 1.074792504310608
Validation loss: 1.801540623429001

Epoch: 5| Step: 2
Training loss: 1.2265191078186035
Validation loss: 1.7679644989710983

Epoch: 5| Step: 3
Training loss: 1.2596849203109741
Validation loss: 1.7856577852720856

Epoch: 5| Step: 4
Training loss: 0.7997849583625793
Validation loss: 1.8259428521638275

Epoch: 5| Step: 5
Training loss: 1.2353624105453491
Validation loss: 1.7679382549819125

Epoch: 5| Step: 6
Training loss: 0.5908606648445129
Validation loss: 1.7954441885794363

Epoch: 5| Step: 7
Training loss: 0.7400404810905457
Validation loss: 1.7993872050316102

Epoch: 5| Step: 8
Training loss: 1.2364962100982666
Validation loss: 1.866962795616478

Epoch: 5| Step: 9
Training loss: 0.8324514627456665
Validation loss: 1.9045980797019055

Epoch: 5| Step: 10
Training loss: 1.000706672668457
Validation loss: 1.8990224676747476

Epoch: 271| Step: 0
Training loss: 0.7583392262458801
Validation loss: 1.9110762278238933

Epoch: 5| Step: 1
Training loss: 0.930233359336853
Validation loss: 1.9135058272269465

Epoch: 5| Step: 2
Training loss: 1.350098967552185
Validation loss: 1.9197767972946167

Epoch: 5| Step: 3
Training loss: 1.0249285697937012
Validation loss: 1.910164830505207

Epoch: 5| Step: 4
Training loss: 0.9224729537963867
Validation loss: 1.8695943355560303

Epoch: 5| Step: 5
Training loss: 0.9575551152229309
Validation loss: 1.8474495487828408

Epoch: 5| Step: 6
Training loss: 0.7711998224258423
Validation loss: 1.8320320549831595

Epoch: 5| Step: 7
Training loss: 1.0724831819534302
Validation loss: 1.8375645760566957

Epoch: 5| Step: 8
Training loss: 1.1634480953216553
Validation loss: 1.8387355342988045

Epoch: 5| Step: 9
Training loss: 0.7709989547729492
Validation loss: 1.8694531097207019

Epoch: 5| Step: 10
Training loss: 1.1593271493911743
Validation loss: 1.8504339982104558

Epoch: 272| Step: 0
Training loss: 0.9109851121902466
Validation loss: 1.8183337526936685

Epoch: 5| Step: 1
Training loss: 1.0810587406158447
Validation loss: 1.845338383028584

Epoch: 5| Step: 2
Training loss: 0.7627160549163818
Validation loss: 1.8666911740456857

Epoch: 5| Step: 3
Training loss: 1.48271906375885
Validation loss: 1.8869192292613368

Epoch: 5| Step: 4
Training loss: 0.968025803565979
Validation loss: 1.8880932202903173

Epoch: 5| Step: 5
Training loss: 1.0969728231430054
Validation loss: 1.8978374363273702

Epoch: 5| Step: 6
Training loss: 0.8694710731506348
Validation loss: 1.8796244000875821

Epoch: 5| Step: 7
Training loss: 1.179564356803894
Validation loss: 1.8654504642691663

Epoch: 5| Step: 8
Training loss: 0.7511169910430908
Validation loss: 1.8178843426448044

Epoch: 5| Step: 9
Training loss: 1.095931053161621
Validation loss: 1.806327933906227

Epoch: 5| Step: 10
Training loss: 0.5205514430999756
Validation loss: 1.8134536871346094

Epoch: 273| Step: 0
Training loss: 1.103246808052063
Validation loss: 1.8103144399581417

Epoch: 5| Step: 1
Training loss: 1.1641814708709717
Validation loss: 1.8189956552238875

Epoch: 5| Step: 2
Training loss: 1.0440359115600586
Validation loss: 1.8279993867361417

Epoch: 5| Step: 3
Training loss: 0.9162604212760925
Validation loss: 1.8224824756704352

Epoch: 5| Step: 4
Training loss: 0.7023560404777527
Validation loss: 1.868517537270823

Epoch: 5| Step: 5
Training loss: 1.1351981163024902
Validation loss: 1.8417567694058983

Epoch: 5| Step: 6
Training loss: 1.2928425073623657
Validation loss: 1.8267350914657756

Epoch: 5| Step: 7
Training loss: 0.6468089818954468
Validation loss: 1.832590877368886

Epoch: 5| Step: 8
Training loss: 0.789802074432373
Validation loss: 1.8465033615789106

Epoch: 5| Step: 9
Training loss: 0.8684844970703125
Validation loss: 1.8464381951157764

Epoch: 5| Step: 10
Training loss: 0.4498845040798187
Validation loss: 1.8743827573714718

Epoch: 274| Step: 0
Training loss: 0.7569864392280579
Validation loss: 1.9029739018409484

Epoch: 5| Step: 1
Training loss: 0.8855596780776978
Validation loss: 1.8874870448984125

Epoch: 5| Step: 2
Training loss: 0.9656285047531128
Validation loss: 1.867223798587758

Epoch: 5| Step: 3
Training loss: 0.7474592924118042
Validation loss: 1.8617563683499572

Epoch: 5| Step: 4
Training loss: 1.0285162925720215
Validation loss: 1.8620258403080765

Epoch: 5| Step: 5
Training loss: 0.8458626866340637
Validation loss: 1.8016342719395955

Epoch: 5| Step: 6
Training loss: 0.533306896686554
Validation loss: 1.8244812527010519

Epoch: 5| Step: 7
Training loss: 1.0546765327453613
Validation loss: 1.7995456034137356

Epoch: 5| Step: 8
Training loss: 1.4390009641647339
Validation loss: 1.8236789562368905

Epoch: 5| Step: 9
Training loss: 1.2260541915893555
Validation loss: 1.8301595551993257

Epoch: 5| Step: 10
Training loss: 0.5762168765068054
Validation loss: 1.8309600353240967

Epoch: 275| Step: 0
Training loss: 1.091174840927124
Validation loss: 1.8565888122845722

Epoch: 5| Step: 1
Training loss: 1.1231868267059326
Validation loss: 1.8506625954822828

Epoch: 5| Step: 2
Training loss: 0.6323434114456177
Validation loss: 1.8550524814154512

Epoch: 5| Step: 3
Training loss: 1.3298879861831665
Validation loss: 1.8190048035754953

Epoch: 5| Step: 4
Training loss: 1.1366822719573975
Validation loss: 1.8194759250969015

Epoch: 5| Step: 5
Training loss: 0.6296941637992859
Validation loss: 1.8486083810047438

Epoch: 5| Step: 6
Training loss: 1.1318116188049316
Validation loss: 1.8549106197972451

Epoch: 5| Step: 7
Training loss: 0.6643709540367126
Validation loss: 1.8232464559616581

Epoch: 5| Step: 8
Training loss: 0.7784906625747681
Validation loss: 1.8205810375111078

Epoch: 5| Step: 9
Training loss: 0.653443455696106
Validation loss: 1.807586016193513

Epoch: 5| Step: 10
Training loss: 0.8457233309745789
Validation loss: 1.7779155597891858

Epoch: 276| Step: 0
Training loss: 0.909313976764679
Validation loss: 1.7819891475862073

Epoch: 5| Step: 1
Training loss: 0.8750312924385071
Validation loss: 1.7662937538598174

Epoch: 5| Step: 2
Training loss: 1.3069472312927246
Validation loss: 1.787981992126793

Epoch: 5| Step: 3
Training loss: 0.8851621747016907
Validation loss: 1.7685685388503536

Epoch: 5| Step: 4
Training loss: 1.2612653970718384
Validation loss: 1.770065967754651

Epoch: 5| Step: 5
Training loss: 0.5484653115272522
Validation loss: 1.7559786124895977

Epoch: 5| Step: 6
Training loss: 0.8064018487930298
Validation loss: 1.7964808376886512

Epoch: 5| Step: 7
Training loss: 0.9069199562072754
Validation loss: 1.7738733637717463

Epoch: 5| Step: 8
Training loss: 0.9327220916748047
Validation loss: 1.813847598209176

Epoch: 5| Step: 9
Training loss: 0.7454909086227417
Validation loss: 1.813753189579133

Epoch: 5| Step: 10
Training loss: 0.686569094657898
Validation loss: 1.8258611412458523

Epoch: 277| Step: 0
Training loss: 0.8431970477104187
Validation loss: 1.8355327139618576

Epoch: 5| Step: 1
Training loss: 0.8163641691207886
Validation loss: 1.8568755657442155

Epoch: 5| Step: 2
Training loss: 1.0313441753387451
Validation loss: 1.8774533489699006

Epoch: 5| Step: 3
Training loss: 0.9477978944778442
Validation loss: 1.87831711769104

Epoch: 5| Step: 4
Training loss: 0.954898476600647
Validation loss: 1.866387995340491

Epoch: 5| Step: 5
Training loss: 0.7291426062583923
Validation loss: 1.8806685299001715

Epoch: 5| Step: 6
Training loss: 1.2038190364837646
Validation loss: 1.8565654677729453

Epoch: 5| Step: 7
Training loss: 0.7405590415000916
Validation loss: 1.8365712524742208

Epoch: 5| Step: 8
Training loss: 0.9786176681518555
Validation loss: 1.8234599508265013

Epoch: 5| Step: 9
Training loss: 0.8811296224594116
Validation loss: 1.795866858574652

Epoch: 5| Step: 10
Training loss: 0.8395945429801941
Validation loss: 1.774321920128279

Epoch: 278| Step: 0
Training loss: 0.4054085314273834
Validation loss: 1.7802677782632972

Epoch: 5| Step: 1
Training loss: 1.1726282835006714
Validation loss: 1.8167679399572394

Epoch: 5| Step: 2
Training loss: 0.7099834084510803
Validation loss: 1.8111388580773466

Epoch: 5| Step: 3
Training loss: 1.5914595127105713
Validation loss: 1.7981921190856605

Epoch: 5| Step: 4
Training loss: 0.6334630250930786
Validation loss: 1.818104419656979

Epoch: 5| Step: 5
Training loss: 0.8447619676589966
Validation loss: 1.8652636158850886

Epoch: 5| Step: 6
Training loss: 1.058734655380249
Validation loss: 1.9132017358656852

Epoch: 5| Step: 7
Training loss: 1.0547012090682983
Validation loss: 1.9063092188168598

Epoch: 5| Step: 8
Training loss: 0.7220922112464905
Validation loss: 1.8966636734624063

Epoch: 5| Step: 9
Training loss: 0.9254182577133179
Validation loss: 1.9189237548458962

Epoch: 5| Step: 10
Training loss: 0.9647291898727417
Validation loss: 1.904431507151614

Epoch: 279| Step: 0
Training loss: 1.2243822813034058
Validation loss: 1.8718372609025689

Epoch: 5| Step: 1
Training loss: 0.6259201765060425
Validation loss: 1.8640317429778397

Epoch: 5| Step: 2
Training loss: 0.7122288346290588
Validation loss: 1.8659208871984994

Epoch: 5| Step: 3
Training loss: 1.3183643817901611
Validation loss: 1.8383193054506857

Epoch: 5| Step: 4
Training loss: 0.6929788589477539
Validation loss: 1.8554040898558914

Epoch: 5| Step: 5
Training loss: 0.7091647386550903
Validation loss: 1.8348845320363198

Epoch: 5| Step: 6
Training loss: 0.8711847066879272
Validation loss: 1.862396494034798

Epoch: 5| Step: 7
Training loss: 0.6963662505149841
Validation loss: 1.8120021755977342

Epoch: 5| Step: 8
Training loss: 0.8224668502807617
Validation loss: 1.8034302457686393

Epoch: 5| Step: 9
Training loss: 1.0513489246368408
Validation loss: 1.821060348582524

Epoch: 5| Step: 10
Training loss: 0.8850448727607727
Validation loss: 1.836248520881899

Epoch: 280| Step: 0
Training loss: 1.3129476308822632
Validation loss: 1.8607608759275047

Epoch: 5| Step: 1
Training loss: 0.5244067311286926
Validation loss: 1.8937455210634457

Epoch: 5| Step: 2
Training loss: 0.9492688179016113
Validation loss: 1.8685967281300535

Epoch: 5| Step: 3
Training loss: 0.7286627292633057
Validation loss: 1.8741739385871476

Epoch: 5| Step: 4
Training loss: 0.7068857550621033
Validation loss: 1.8467761265334262

Epoch: 5| Step: 5
Training loss: 0.7724210619926453
Validation loss: 1.8110542528090938

Epoch: 5| Step: 6
Training loss: 0.9293206930160522
Validation loss: 1.7891132703391455

Epoch: 5| Step: 7
Training loss: 0.8715212941169739
Validation loss: 1.7947242362524873

Epoch: 5| Step: 8
Training loss: 0.9405433535575867
Validation loss: 1.7767381943682188

Epoch: 5| Step: 9
Training loss: 0.8396950960159302
Validation loss: 1.800317261808662

Epoch: 5| Step: 10
Training loss: 0.9870989322662354
Validation loss: 1.7713148670811807

Epoch: 281| Step: 0
Training loss: 0.4773283898830414
Validation loss: 1.8003048268697595

Epoch: 5| Step: 1
Training loss: 0.7801238894462585
Validation loss: 1.814891371675717

Epoch: 5| Step: 2
Training loss: 0.7558383941650391
Validation loss: 1.8210121239385297

Epoch: 5| Step: 3
Training loss: 0.5955897569656372
Validation loss: 1.8092680003053399

Epoch: 5| Step: 4
Training loss: 0.8518575429916382
Validation loss: 1.8402785126880934

Epoch: 5| Step: 5
Training loss: 0.8790677785873413
Validation loss: 1.820102765995969

Epoch: 5| Step: 6
Training loss: 1.0764617919921875
Validation loss: 1.8271967723805418

Epoch: 5| Step: 7
Training loss: 0.8598197102546692
Validation loss: 1.8045699955314718

Epoch: 5| Step: 8
Training loss: 1.1472593545913696
Validation loss: 1.7923953815173077

Epoch: 5| Step: 9
Training loss: 1.3359053134918213
Validation loss: 1.779461085155446

Epoch: 5| Step: 10
Training loss: 0.5507360100746155
Validation loss: 1.77698996374684

Epoch: 282| Step: 0
Training loss: 0.6826637983322144
Validation loss: 1.7808045507759176

Epoch: 5| Step: 1
Training loss: 0.7940583825111389
Validation loss: 1.7995020625411824

Epoch: 5| Step: 2
Training loss: 0.9544790983200073
Validation loss: 1.7785170065459384

Epoch: 5| Step: 3
Training loss: 1.164374589920044
Validation loss: 1.83557693676282

Epoch: 5| Step: 4
Training loss: 0.7579144239425659
Validation loss: 1.824396574369041

Epoch: 5| Step: 5
Training loss: 0.863815188407898
Validation loss: 1.8088347322197371

Epoch: 5| Step: 6
Training loss: 0.8691486120223999
Validation loss: 1.7769626186740013

Epoch: 5| Step: 7
Training loss: 0.9773271679878235
Validation loss: 1.7810534482361169

Epoch: 5| Step: 8
Training loss: 1.153045892715454
Validation loss: 1.761223130328681

Epoch: 5| Step: 9
Training loss: 0.4441916048526764
Validation loss: 1.7778047989773493

Epoch: 5| Step: 10
Training loss: 0.8554437756538391
Validation loss: 1.8563246432171072

Epoch: 283| Step: 0
Training loss: 0.8437191247940063
Validation loss: 1.8673811048589728

Epoch: 5| Step: 1
Training loss: 1.0391583442687988
Validation loss: 1.9021464099166214

Epoch: 5| Step: 2
Training loss: 1.1679970026016235
Validation loss: 1.8916055002520162

Epoch: 5| Step: 3
Training loss: 0.85246741771698
Validation loss: 1.8735414769059868

Epoch: 5| Step: 4
Training loss: 0.652426540851593
Validation loss: 1.8679287459260674

Epoch: 5| Step: 5
Training loss: 0.8568905591964722
Validation loss: 1.8513134269304172

Epoch: 5| Step: 6
Training loss: 0.736068606376648
Validation loss: 1.7834049053089593

Epoch: 5| Step: 7
Training loss: 1.1533989906311035
Validation loss: 1.7881289348807385

Epoch: 5| Step: 8
Training loss: 0.710728645324707
Validation loss: 1.7675762266241095

Epoch: 5| Step: 9
Training loss: 0.5571407079696655
Validation loss: 1.7560177374911565

Epoch: 5| Step: 10
Training loss: 0.9767076969146729
Validation loss: 1.7856564816608225

Epoch: 284| Step: 0
Training loss: 1.0969997644424438
Validation loss: 1.7704854139717676

Epoch: 5| Step: 1
Training loss: 0.935302734375
Validation loss: 1.7896803015021867

Epoch: 5| Step: 2
Training loss: 0.560375452041626
Validation loss: 1.80409832667279

Epoch: 5| Step: 3
Training loss: 0.8683894872665405
Validation loss: 1.812522344691779

Epoch: 5| Step: 4
Training loss: 1.0533854961395264
Validation loss: 1.8181857582061522

Epoch: 5| Step: 5
Training loss: 0.9720722436904907
Validation loss: 1.8347476349082044

Epoch: 5| Step: 6
Training loss: 0.7622746229171753
Validation loss: 1.8252039878599104

Epoch: 5| Step: 7
Training loss: 0.695793628692627
Validation loss: 1.8380575564599806

Epoch: 5| Step: 8
Training loss: 0.8025131225585938
Validation loss: 1.821588949490619

Epoch: 5| Step: 9
Training loss: 0.8557804822921753
Validation loss: 1.8646798774760256

Epoch: 5| Step: 10
Training loss: 0.9572517275810242
Validation loss: 1.8600920220857025

Epoch: 285| Step: 0
Training loss: 0.921548068523407
Validation loss: 1.9012872903577742

Epoch: 5| Step: 1
Training loss: 1.2896028757095337
Validation loss: 1.9104985985704648

Epoch: 5| Step: 2
Training loss: 0.7430898547172546
Validation loss: 1.909377847948382

Epoch: 5| Step: 3
Training loss: 0.6498210430145264
Validation loss: 1.890019050208471

Epoch: 5| Step: 4
Training loss: 0.8020356297492981
Validation loss: 1.8602136129974036

Epoch: 5| Step: 5
Training loss: 0.583838164806366
Validation loss: 1.8428192292490313

Epoch: 5| Step: 6
Training loss: 0.8486219644546509
Validation loss: 1.8496531914639216

Epoch: 5| Step: 7
Training loss: 0.4994787275791168
Validation loss: 1.8594471344383814

Epoch: 5| Step: 8
Training loss: 1.185010313987732
Validation loss: 1.8518511518355338

Epoch: 5| Step: 9
Training loss: 1.074385643005371
Validation loss: 1.840596431045122

Epoch: 5| Step: 10
Training loss: 0.7518954277038574
Validation loss: 1.875740194833407

Epoch: 286| Step: 0
Training loss: 0.6482622027397156
Validation loss: 1.8862104569711993

Epoch: 5| Step: 1
Training loss: 0.7828158140182495
Validation loss: 1.841154585602463

Epoch: 5| Step: 2
Training loss: 0.5381701588630676
Validation loss: 1.8572155967835458

Epoch: 5| Step: 3
Training loss: 0.7283259034156799
Validation loss: 1.8832808707350044

Epoch: 5| Step: 4
Training loss: 0.6567138433456421
Validation loss: 1.8445845867997857

Epoch: 5| Step: 5
Training loss: 0.8778461217880249
Validation loss: 1.8449830650001444

Epoch: 5| Step: 6
Training loss: 1.2340412139892578
Validation loss: 1.8234827685099777

Epoch: 5| Step: 7
Training loss: 0.6658579707145691
Validation loss: 1.8005665566331597

Epoch: 5| Step: 8
Training loss: 1.0090128183364868
Validation loss: 1.7990132454902894

Epoch: 5| Step: 9
Training loss: 0.7402065992355347
Validation loss: 1.8157506758166897

Epoch: 5| Step: 10
Training loss: 1.1029465198516846
Validation loss: 1.794182926095942

Epoch: 287| Step: 0
Training loss: 0.8083094358444214
Validation loss: 1.8000337141816334

Epoch: 5| Step: 1
Training loss: 0.8669489622116089
Validation loss: 1.8307632400143532

Epoch: 5| Step: 2
Training loss: 0.8761757016181946
Validation loss: 1.856039777878792

Epoch: 5| Step: 3
Training loss: 0.8989164233207703
Validation loss: 1.8445228094695716

Epoch: 5| Step: 4
Training loss: 0.5927969217300415
Validation loss: 1.8295555473655782

Epoch: 5| Step: 5
Training loss: 0.8420500755310059
Validation loss: 1.779508081815576

Epoch: 5| Step: 6
Training loss: 0.8408111333847046
Validation loss: 1.805779387873988

Epoch: 5| Step: 7
Training loss: 0.6876835823059082
Validation loss: 1.806649665678701

Epoch: 5| Step: 8
Training loss: 0.8452665209770203
Validation loss: 1.809906304523509

Epoch: 5| Step: 9
Training loss: 0.7887621521949768
Validation loss: 1.807939080781834

Epoch: 5| Step: 10
Training loss: 0.973517119884491
Validation loss: 1.7981272025774884

Epoch: 288| Step: 0
Training loss: 0.8329693078994751
Validation loss: 1.8269036521193802

Epoch: 5| Step: 1
Training loss: 1.121460199356079
Validation loss: 1.8702590619364092

Epoch: 5| Step: 2
Training loss: 0.6451142430305481
Validation loss: 1.8432008374121882

Epoch: 5| Step: 3
Training loss: 0.5889937281608582
Validation loss: 1.8098521860696937

Epoch: 5| Step: 4
Training loss: 1.5281956195831299
Validation loss: 1.7990902521276986

Epoch: 5| Step: 5
Training loss: 0.7963591814041138
Validation loss: 1.7491448040931457

Epoch: 5| Step: 6
Training loss: 0.5757625102996826
Validation loss: 1.7625630260795675

Epoch: 5| Step: 7
Training loss: 0.6248773336410522
Validation loss: 1.8036157725959696

Epoch: 5| Step: 8
Training loss: 1.2881821393966675
Validation loss: 1.8119298001771331

Epoch: 5| Step: 9
Training loss: 0.6944951415061951
Validation loss: 1.8318893499271844

Epoch: 5| Step: 10
Training loss: 0.36340489983558655
Validation loss: 1.8342973359169499

Epoch: 289| Step: 0
Training loss: 1.0119483470916748
Validation loss: 1.8392086144416564

Epoch: 5| Step: 1
Training loss: 0.9511374235153198
Validation loss: 1.8359068568034838

Epoch: 5| Step: 2
Training loss: 0.6341112852096558
Validation loss: 1.7981320529855707

Epoch: 5| Step: 3
Training loss: 1.2101835012435913
Validation loss: 1.8036411205927532

Epoch: 5| Step: 4
Training loss: 0.8319843411445618
Validation loss: 1.8092476193622877

Epoch: 5| Step: 5
Training loss: 0.8673723936080933
Validation loss: 1.8108191182536464

Epoch: 5| Step: 6
Training loss: 0.331953763961792
Validation loss: 1.7386489151626505

Epoch: 5| Step: 7
Training loss: 0.8116508722305298
Validation loss: 1.764368469997119

Epoch: 5| Step: 8
Training loss: 0.550194501876831
Validation loss: 1.7854772934349634

Epoch: 5| Step: 9
Training loss: 0.5437452793121338
Validation loss: 1.7841350237528484

Epoch: 5| Step: 10
Training loss: 1.0256370306015015
Validation loss: 1.7881342967351277

Epoch: 290| Step: 0
Training loss: 0.723568320274353
Validation loss: 1.7934138851781045

Epoch: 5| Step: 1
Training loss: 0.9454377293586731
Validation loss: 1.8376386191255303

Epoch: 5| Step: 2
Training loss: 1.181369423866272
Validation loss: 1.8399602072213286

Epoch: 5| Step: 3
Training loss: 0.664232611656189
Validation loss: 1.8492189786767448

Epoch: 5| Step: 4
Training loss: 0.9370290637016296
Validation loss: 1.7924488449609408

Epoch: 5| Step: 5
Training loss: 0.6111623644828796
Validation loss: 1.825454109458513

Epoch: 5| Step: 6
Training loss: 0.7401925325393677
Validation loss: 1.7989440041203653

Epoch: 5| Step: 7
Training loss: 0.7642715573310852
Validation loss: 1.7615627229854625

Epoch: 5| Step: 8
Training loss: 0.8557785153388977
Validation loss: 1.7465559333883307

Epoch: 5| Step: 9
Training loss: 0.7736973762512207
Validation loss: 1.759170985990955

Epoch: 5| Step: 10
Training loss: 0.4743692874908447
Validation loss: 1.7461410594242874

Epoch: 291| Step: 0
Training loss: 1.0725499391555786
Validation loss: 1.7526486419862317

Epoch: 5| Step: 1
Training loss: 0.5835158228874207
Validation loss: 1.792780307031447

Epoch: 5| Step: 2
Training loss: 0.5363473296165466
Validation loss: 1.8018235583459177

Epoch: 5| Step: 3
Training loss: 0.6960254907608032
Validation loss: 1.7714133288270684

Epoch: 5| Step: 4
Training loss: 1.1695228815078735
Validation loss: 1.7827814778973978

Epoch: 5| Step: 5
Training loss: 0.7526065111160278
Validation loss: 1.7410256760094756

Epoch: 5| Step: 6
Training loss: 0.9217731356620789
Validation loss: 1.738659062693196

Epoch: 5| Step: 7
Training loss: 1.0874278545379639
Validation loss: 1.7698952164701236

Epoch: 5| Step: 8
Training loss: 0.37968340516090393
Validation loss: 1.795736720485072

Epoch: 5| Step: 9
Training loss: 0.4757968783378601
Validation loss: 1.8028502336112402

Epoch: 5| Step: 10
Training loss: 1.0739778280258179
Validation loss: 1.8072008381607712

Epoch: 292| Step: 0
Training loss: 0.8682206273078918
Validation loss: 1.8135926313297723

Epoch: 5| Step: 1
Training loss: 0.5664755702018738
Validation loss: 1.8251100791397916

Epoch: 5| Step: 2
Training loss: 0.36959657073020935
Validation loss: 1.800484872633411

Epoch: 5| Step: 3
Training loss: 0.7478844523429871
Validation loss: 1.8237111286450458

Epoch: 5| Step: 4
Training loss: 0.8755921125411987
Validation loss: 1.813807491333254

Epoch: 5| Step: 5
Training loss: 1.2244969606399536
Validation loss: 1.786604178849087

Epoch: 5| Step: 6
Training loss: 0.8385790586471558
Validation loss: 1.757225210948657

Epoch: 5| Step: 7
Training loss: 1.0973992347717285
Validation loss: 1.734649924821751

Epoch: 5| Step: 8
Training loss: 0.6660044193267822
Validation loss: 1.714829014193627

Epoch: 5| Step: 9
Training loss: 0.6593901515007019
Validation loss: 1.7062525826115762

Epoch: 5| Step: 10
Training loss: 0.5392748117446899
Validation loss: 1.7443838452780118

Epoch: 293| Step: 0
Training loss: 0.6239500045776367
Validation loss: 1.7714420531385688

Epoch: 5| Step: 1
Training loss: 0.6213987469673157
Validation loss: 1.7961054924995667

Epoch: 5| Step: 2
Training loss: 0.9529733657836914
Validation loss: 1.8327936946704824

Epoch: 5| Step: 3
Training loss: 0.8722497820854187
Validation loss: 1.8680189835127963

Epoch: 5| Step: 4
Training loss: 0.9567595720291138
Validation loss: 1.8578618777695524

Epoch: 5| Step: 5
Training loss: 0.8506165742874146
Validation loss: 1.8966038201444892

Epoch: 5| Step: 6
Training loss: 1.091407060623169
Validation loss: 1.8997586657924037

Epoch: 5| Step: 7
Training loss: 0.5730273723602295
Validation loss: 1.8337918891701648

Epoch: 5| Step: 8
Training loss: 0.5329026579856873
Validation loss: 1.787599245707194

Epoch: 5| Step: 9
Training loss: 0.8001097440719604
Validation loss: 1.7778742826113136

Epoch: 5| Step: 10
Training loss: 0.7771232724189758
Validation loss: 1.7587645976774153

Epoch: 294| Step: 0
Training loss: 0.8448896408081055
Validation loss: 1.7383536343933434

Epoch: 5| Step: 1
Training loss: 1.0039899349212646
Validation loss: 1.7486824963682441

Epoch: 5| Step: 2
Training loss: 0.6410156488418579
Validation loss: 1.7799725250531269

Epoch: 5| Step: 3
Training loss: 0.693130373954773
Validation loss: 1.7612740250043972

Epoch: 5| Step: 4
Training loss: 0.6634228825569153
Validation loss: 1.7805862439576017

Epoch: 5| Step: 5
Training loss: 0.7597497701644897
Validation loss: 1.7785302951771726

Epoch: 5| Step: 6
Training loss: 0.6176687479019165
Validation loss: 1.7722621938233734

Epoch: 5| Step: 7
Training loss: 0.6966312527656555
Validation loss: 1.7771069785600067

Epoch: 5| Step: 8
Training loss: 0.6503567695617676
Validation loss: 1.8018577047573623

Epoch: 5| Step: 9
Training loss: 1.1143181324005127
Validation loss: 1.7780682912436865

Epoch: 5| Step: 10
Training loss: 0.7345285415649414
Validation loss: 1.8171174385214364

Epoch: 295| Step: 0
Training loss: 0.6017271876335144
Validation loss: 1.8099871681582542

Epoch: 5| Step: 1
Training loss: 1.1866573095321655
Validation loss: 1.8555463103837864

Epoch: 5| Step: 2
Training loss: 0.864303708076477
Validation loss: 1.8376506579819547

Epoch: 5| Step: 3
Training loss: 0.9302870035171509
Validation loss: 1.8248249676919752

Epoch: 5| Step: 4
Training loss: 0.7876507043838501
Validation loss: 1.7784678602731356

Epoch: 5| Step: 5
Training loss: 0.6302996873855591
Validation loss: 1.794840274318572

Epoch: 5| Step: 6
Training loss: 1.2587448358535767
Validation loss: 1.786328564408005

Epoch: 5| Step: 7
Training loss: 0.6822830438613892
Validation loss: 1.7563690421401814

Epoch: 5| Step: 8
Training loss: 0.2944164574146271
Validation loss: 1.7355737750248244

Epoch: 5| Step: 9
Training loss: 0.6128929853439331
Validation loss: 1.7377163684496315

Epoch: 5| Step: 10
Training loss: 0.6166474223136902
Validation loss: 1.7372361178039222

Epoch: 296| Step: 0
Training loss: 1.2825406789779663
Validation loss: 1.7633839679020706

Epoch: 5| Step: 1
Training loss: 0.5515435338020325
Validation loss: 1.812742180721734

Epoch: 5| Step: 2
Training loss: 0.493783563375473
Validation loss: 1.80622350400494

Epoch: 5| Step: 3
Training loss: 0.5965560674667358
Validation loss: 1.7886638564448203

Epoch: 5| Step: 4
Training loss: 0.7653976678848267
Validation loss: 1.7414979293782225

Epoch: 5| Step: 5
Training loss: 0.573650062084198
Validation loss: 1.7489805234375821

Epoch: 5| Step: 6
Training loss: 0.8551548719406128
Validation loss: 1.7317071973636586

Epoch: 5| Step: 7
Training loss: 0.4225153923034668
Validation loss: 1.7608727844812537

Epoch: 5| Step: 8
Training loss: 1.037685751914978
Validation loss: 1.7229674067548526

Epoch: 5| Step: 9
Training loss: 1.0127573013305664
Validation loss: 1.7355651547831874

Epoch: 5| Step: 10
Training loss: 0.817434549331665
Validation loss: 1.732673974447353

Epoch: 297| Step: 0
Training loss: 0.6225368976593018
Validation loss: 1.7786710223843973

Epoch: 5| Step: 1
Training loss: 0.993611216545105
Validation loss: 1.7822043882903231

Epoch: 5| Step: 2
Training loss: 0.6967113614082336
Validation loss: 1.7783304491350729

Epoch: 5| Step: 3
Training loss: 0.564874529838562
Validation loss: 1.7940092676429338

Epoch: 5| Step: 4
Training loss: 0.9793955087661743
Validation loss: 1.7620123573528823

Epoch: 5| Step: 5
Training loss: 0.6344626545906067
Validation loss: 1.7314384919340893

Epoch: 5| Step: 6
Training loss: 0.5997648239135742
Validation loss: 1.7282769577477568

Epoch: 5| Step: 7
Training loss: 0.5418741106987
Validation loss: 1.7181690828774565

Epoch: 5| Step: 8
Training loss: 1.02079176902771
Validation loss: 1.703239898527822

Epoch: 5| Step: 9
Training loss: 1.0078681707382202
Validation loss: 1.7093056312171362

Epoch: 5| Step: 10
Training loss: 0.954207718372345
Validation loss: 1.7148761697994765

Epoch: 298| Step: 0
Training loss: 0.5347622036933899
Validation loss: 1.75804933937647

Epoch: 5| Step: 1
Training loss: 0.8159443736076355
Validation loss: 1.7540690706622215

Epoch: 5| Step: 2
Training loss: 0.4499083161354065
Validation loss: 1.7421279350916545

Epoch: 5| Step: 3
Training loss: 0.9721993207931519
Validation loss: 1.7035414326575495

Epoch: 5| Step: 4
Training loss: 0.5530554056167603
Validation loss: 1.725912772199159

Epoch: 5| Step: 5
Training loss: 1.2552225589752197
Validation loss: 1.7200240409502419

Epoch: 5| Step: 6
Training loss: 0.758762776851654
Validation loss: 1.7090598613985124

Epoch: 5| Step: 7
Training loss: 0.8232388496398926
Validation loss: 1.747515005450095

Epoch: 5| Step: 8
Training loss: 0.5944918394088745
Validation loss: 1.7578437097610966

Epoch: 5| Step: 9
Training loss: 0.71064293384552
Validation loss: 1.7883998245321295

Epoch: 5| Step: 10
Training loss: 0.8160012364387512
Validation loss: 1.8196059414135513

Epoch: 299| Step: 0
Training loss: 0.7421510815620422
Validation loss: 1.8492728202573714

Epoch: 5| Step: 1
Training loss: 0.9172662496566772
Validation loss: 1.8362276425925634

Epoch: 5| Step: 2
Training loss: 0.8164318203926086
Validation loss: 1.83569759450933

Epoch: 5| Step: 3
Training loss: 0.6077378988265991
Validation loss: 1.790905233352415

Epoch: 5| Step: 4
Training loss: 0.6374005675315857
Validation loss: 1.7955108714360062

Epoch: 5| Step: 5
Training loss: 0.600371241569519
Validation loss: 1.758399357077896

Epoch: 5| Step: 6
Training loss: 0.7156902551651001
Validation loss: 1.7275808626605618

Epoch: 5| Step: 7
Training loss: 0.8194945454597473
Validation loss: 1.7512728821846746

Epoch: 5| Step: 8
Training loss: 0.6004635095596313
Validation loss: 1.7560132549655052

Epoch: 5| Step: 9
Training loss: 1.0302753448486328
Validation loss: 1.7966628561737716

Epoch: 5| Step: 10
Training loss: 0.7588025331497192
Validation loss: 1.759473910895727

Epoch: 300| Step: 0
Training loss: 0.8477236032485962
Validation loss: 1.7675271111149942

Epoch: 5| Step: 1
Training loss: 0.3828426003456116
Validation loss: 1.7414514364734772

Epoch: 5| Step: 2
Training loss: 0.9178396463394165
Validation loss: 1.7768221080944102

Epoch: 5| Step: 3
Training loss: 0.8862028121948242
Validation loss: 1.7519551836034304

Epoch: 5| Step: 4
Training loss: 0.7258747816085815
Validation loss: 1.736516212904325

Epoch: 5| Step: 5
Training loss: 0.5554944276809692
Validation loss: 1.756807811798588

Epoch: 5| Step: 6
Training loss: 0.7838016152381897
Validation loss: 1.7739893813287058

Epoch: 5| Step: 7
Training loss: 0.4464929699897766
Validation loss: 1.7460007923905567

Epoch: 5| Step: 8
Training loss: 0.7063010931015015
Validation loss: 1.7470016197491718

Epoch: 5| Step: 9
Training loss: 0.9390700459480286
Validation loss: 1.7819517530420774

Epoch: 5| Step: 10
Training loss: 0.9082934260368347
Validation loss: 1.7903497013994443

Epoch: 301| Step: 0
Training loss: 0.6356281042098999
Validation loss: 1.7595751106098134

Epoch: 5| Step: 1
Training loss: 0.5577723383903503
Validation loss: 1.7338856843210035

Epoch: 5| Step: 2
Training loss: 0.4604945182800293
Validation loss: 1.7239397930842575

Epoch: 5| Step: 3
Training loss: 0.7102453112602234
Validation loss: 1.6884813693261915

Epoch: 5| Step: 4
Training loss: 1.0913587808609009
Validation loss: 1.7211431213604507

Epoch: 5| Step: 5
Training loss: 0.4460614323616028
Validation loss: 1.7108245844482093

Epoch: 5| Step: 6
Training loss: 1.0644381046295166
Validation loss: 1.6989668940985074

Epoch: 5| Step: 7
Training loss: 0.9988428950309753
Validation loss: 1.673825926678155

Epoch: 5| Step: 8
Training loss: 0.6211602091789246
Validation loss: 1.6855469506273988

Epoch: 5| Step: 9
Training loss: 0.8240200877189636
Validation loss: 1.7038968186224661

Epoch: 5| Step: 10
Training loss: 0.4884583055973053
Validation loss: 1.6932329580348024

Epoch: 302| Step: 0
Training loss: 0.5113872289657593
Validation loss: 1.7629180877439437

Epoch: 5| Step: 1
Training loss: 0.8707626461982727
Validation loss: 1.7991895650022773

Epoch: 5| Step: 2
Training loss: 1.0812286138534546
Validation loss: 1.7892508019683182

Epoch: 5| Step: 3
Training loss: 0.8732948303222656
Validation loss: 1.801002803669181

Epoch: 5| Step: 4
Training loss: 0.47705039381980896
Validation loss: 1.8304414185144569

Epoch: 5| Step: 5
Training loss: 0.5492934584617615
Validation loss: 1.7710464923612532

Epoch: 5| Step: 6
Training loss: 0.9183114767074585
Validation loss: 1.7253459204909622

Epoch: 5| Step: 7
Training loss: 0.680597186088562
Validation loss: 1.7438464408279748

Epoch: 5| Step: 8
Training loss: 0.66671222448349
Validation loss: 1.7289845725541473

Epoch: 5| Step: 9
Training loss: 0.6488653421401978
Validation loss: 1.7335403965365501

Epoch: 5| Step: 10
Training loss: 0.6901920437812805
Validation loss: 1.7403388292558732

Epoch: 303| Step: 0
Training loss: 0.5954077243804932
Validation loss: 1.745165978708575

Epoch: 5| Step: 1
Training loss: 0.9728752374649048
Validation loss: 1.7533681136305614

Epoch: 5| Step: 2
Training loss: 0.7638176679611206
Validation loss: 1.7331460560521772

Epoch: 5| Step: 3
Training loss: 0.5842119455337524
Validation loss: 1.716860302032963

Epoch: 5| Step: 4
Training loss: 0.8844429850578308
Validation loss: 1.7128633401727165

Epoch: 5| Step: 5
Training loss: 0.46492689847946167
Validation loss: 1.7199005003898375

Epoch: 5| Step: 6
Training loss: 0.5892723798751831
Validation loss: 1.7092703465492494

Epoch: 5| Step: 7
Training loss: 0.6871819496154785
Validation loss: 1.7728141161703295

Epoch: 5| Step: 8
Training loss: 1.2292760610580444
Validation loss: 1.8174649592368834

Epoch: 5| Step: 9
Training loss: 0.6848583221435547
Validation loss: 1.8461325117336806

Epoch: 5| Step: 10
Training loss: 1.0251859426498413
Validation loss: 1.8429298272696875

Epoch: 304| Step: 0
Training loss: 0.6363128423690796
Validation loss: 1.787115473901072

Epoch: 5| Step: 1
Training loss: 0.8592031598091125
Validation loss: 1.7502300905924972

Epoch: 5| Step: 2
Training loss: 0.8250541687011719
Validation loss: 1.7693556457437494

Epoch: 5| Step: 3
Training loss: 1.1327779293060303
Validation loss: 1.7394006021561161

Epoch: 5| Step: 4
Training loss: 0.4506980776786804
Validation loss: 1.720685573034389

Epoch: 5| Step: 5
Training loss: 0.81053227186203
Validation loss: 1.73788337169155

Epoch: 5| Step: 6
Training loss: 0.607083797454834
Validation loss: 1.7330560120203162

Epoch: 5| Step: 7
Training loss: 0.8982070088386536
Validation loss: 1.7386254110643942

Epoch: 5| Step: 8
Training loss: 0.6659712791442871
Validation loss: 1.7740406195322673

Epoch: 5| Step: 9
Training loss: 0.6266965270042419
Validation loss: 1.744144872952533

Epoch: 5| Step: 10
Training loss: 0.7960128784179688
Validation loss: 1.758072647997128

Epoch: 305| Step: 0
Training loss: 0.7324451804161072
Validation loss: 1.8078411266367922

Epoch: 5| Step: 1
Training loss: 0.7215646505355835
Validation loss: 1.805169746439944

Epoch: 5| Step: 2
Training loss: 0.5384188294410706
Validation loss: 1.804818235417848

Epoch: 5| Step: 3
Training loss: 0.8040048480033875
Validation loss: 1.8089340527852376

Epoch: 5| Step: 4
Training loss: 0.9070366621017456
Validation loss: 1.7840173513658586

Epoch: 5| Step: 5
Training loss: 0.5788253545761108
Validation loss: 1.773521093912022

Epoch: 5| Step: 6
Training loss: 0.7795048952102661
Validation loss: 1.7497979594815163

Epoch: 5| Step: 7
Training loss: 0.5708304643630981
Validation loss: 1.786372019398597

Epoch: 5| Step: 8
Training loss: 0.8753989934921265
Validation loss: 1.8310999767754668

Epoch: 5| Step: 9
Training loss: 0.7329371571540833
Validation loss: 1.866929095278504

Epoch: 5| Step: 10
Training loss: 1.0151097774505615
Validation loss: 1.8896346220406153

Epoch: 306| Step: 0
Training loss: 0.7493921518325806
Validation loss: 1.8650489571273967

Epoch: 5| Step: 1
Training loss: 0.3837450444698334
Validation loss: 1.8535844177328131

Epoch: 5| Step: 2
Training loss: 0.9295188784599304
Validation loss: 1.7877653337294055

Epoch: 5| Step: 3
Training loss: 0.72604900598526
Validation loss: 1.7654090401946858

Epoch: 5| Step: 4
Training loss: 0.37474575638771057
Validation loss: 1.7348393189009799

Epoch: 5| Step: 5
Training loss: 0.7685061693191528
Validation loss: 1.6997547559840704

Epoch: 5| Step: 6
Training loss: 1.2757631540298462
Validation loss: 1.7334618952966505

Epoch: 5| Step: 7
Training loss: 0.42835086584091187
Validation loss: 1.7715409801852318

Epoch: 5| Step: 8
Training loss: 0.8605667948722839
Validation loss: 1.7912678032793024

Epoch: 5| Step: 9
Training loss: 0.8686014413833618
Validation loss: 1.7767550727372527

Epoch: 5| Step: 10
Training loss: 0.6554326415061951
Validation loss: 1.7952535203708115

Epoch: 307| Step: 0
Training loss: 1.0150705575942993
Validation loss: 1.7978497115514611

Epoch: 5| Step: 1
Training loss: 1.0102239847183228
Validation loss: 1.7918285054545249

Epoch: 5| Step: 2
Training loss: 0.5878849029541016
Validation loss: 1.8172721683338124

Epoch: 5| Step: 3
Training loss: 1.0916829109191895
Validation loss: 1.7698733665609871

Epoch: 5| Step: 4
Training loss: 0.6064708828926086
Validation loss: 1.7426191260737758

Epoch: 5| Step: 5
Training loss: 0.5893453359603882
Validation loss: 1.7295237677071684

Epoch: 5| Step: 6
Training loss: 0.7181005477905273
Validation loss: 1.7281750120142454

Epoch: 5| Step: 7
Training loss: 0.7778301239013672
Validation loss: 1.766980678804459

Epoch: 5| Step: 8
Training loss: 0.6071077585220337
Validation loss: 1.7561625037142026

Epoch: 5| Step: 9
Training loss: 0.511183500289917
Validation loss: 1.724215583134723

Epoch: 5| Step: 10
Training loss: 0.6013392210006714
Validation loss: 1.773619383893987

Epoch: 308| Step: 0
Training loss: 0.6897045969963074
Validation loss: 1.7502366291579379

Epoch: 5| Step: 1
Training loss: 0.6630270481109619
Validation loss: 1.7519222382576234

Epoch: 5| Step: 2
Training loss: 0.4495529532432556
Validation loss: 1.7365616188254407

Epoch: 5| Step: 3
Training loss: 0.7281485795974731
Validation loss: 1.7301709267400927

Epoch: 5| Step: 4
Training loss: 0.846017062664032
Validation loss: 1.7051815935360488

Epoch: 5| Step: 5
Training loss: 0.9718874096870422
Validation loss: 1.6999874755900393

Epoch: 5| Step: 6
Training loss: 0.9614338874816895
Validation loss: 1.6998713644601966

Epoch: 5| Step: 7
Training loss: 0.5867171883583069
Validation loss: 1.7102917061057141

Epoch: 5| Step: 8
Training loss: 0.6306992769241333
Validation loss: 1.7340184078421643

Epoch: 5| Step: 9
Training loss: 0.4236327111721039
Validation loss: 1.720370602864091

Epoch: 5| Step: 10
Training loss: 0.7970253229141235
Validation loss: 1.7404564965155818

Epoch: 309| Step: 0
Training loss: 0.7971296310424805
Validation loss: 1.7581429302051503

Epoch: 5| Step: 1
Training loss: 0.6065040826797485
Validation loss: 1.777404764647125

Epoch: 5| Step: 2
Training loss: 0.9607334136962891
Validation loss: 1.7765433429389872

Epoch: 5| Step: 3
Training loss: 0.7692012786865234
Validation loss: 1.7708624486000306

Epoch: 5| Step: 4
Training loss: 0.5612646341323853
Validation loss: 1.7999740095548733

Epoch: 5| Step: 5
Training loss: 0.5251611471176147
Validation loss: 1.7539053386257542

Epoch: 5| Step: 6
Training loss: 0.3634454607963562
Validation loss: 1.760259679568711

Epoch: 5| Step: 7
Training loss: 0.8488165140151978
Validation loss: 1.7282183926592591

Epoch: 5| Step: 8
Training loss: 0.7156000733375549
Validation loss: 1.7518590214431926

Epoch: 5| Step: 9
Training loss: 0.592690110206604
Validation loss: 1.7272340174644225

Epoch: 5| Step: 10
Training loss: 0.8719973564147949
Validation loss: 1.7081869315075617

Epoch: 310| Step: 0
Training loss: 0.7245251536369324
Validation loss: 1.7016122071973738

Epoch: 5| Step: 1
Training loss: 0.41344016790390015
Validation loss: 1.6913278948876165

Epoch: 5| Step: 2
Training loss: 0.6250523328781128
Validation loss: 1.7101984241957306

Epoch: 5| Step: 3
Training loss: 0.8520366549491882
Validation loss: 1.7498571718892744

Epoch: 5| Step: 4
Training loss: 0.7534845471382141
Validation loss: 1.7035581911763837

Epoch: 5| Step: 5
Training loss: 0.6579576730728149
Validation loss: 1.7328743562903455

Epoch: 5| Step: 6
Training loss: 0.5004981756210327
Validation loss: 1.7379002571105957

Epoch: 5| Step: 7
Training loss: 0.7902863025665283
Validation loss: 1.7307393320145146

Epoch: 5| Step: 8
Training loss: 0.8103033304214478
Validation loss: 1.7045052102817002

Epoch: 5| Step: 9
Training loss: 0.712997317314148
Validation loss: 1.6888411173256495

Epoch: 5| Step: 10
Training loss: 0.40395092964172363
Validation loss: 1.7126058641300406

Epoch: 311| Step: 0
Training loss: 0.46901217103004456
Validation loss: 1.7357338147778665

Epoch: 5| Step: 1
Training loss: 0.9116884469985962
Validation loss: 1.7540263693819764

Epoch: 5| Step: 2
Training loss: 1.0118296146392822
Validation loss: 1.7621828971370574

Epoch: 5| Step: 3
Training loss: 0.4108298420906067
Validation loss: 1.7959237521694553

Epoch: 5| Step: 4
Training loss: 0.7208752632141113
Validation loss: 1.7690903115016159

Epoch: 5| Step: 5
Training loss: 0.7376313209533691
Validation loss: 1.7669633908938336

Epoch: 5| Step: 6
Training loss: 0.8982386589050293
Validation loss: 1.8157876909420054

Epoch: 5| Step: 7
Training loss: 0.88725745677948
Validation loss: 1.7961514149942706

Epoch: 5| Step: 8
Training loss: 0.3221947252750397
Validation loss: 1.7733972187965148

Epoch: 5| Step: 9
Training loss: 0.5537717342376709
Validation loss: 1.7383965484557613

Epoch: 5| Step: 10
Training loss: 0.4364442825317383
Validation loss: 1.7376188449962164

Epoch: 312| Step: 0
Training loss: 0.8727079629898071
Validation loss: 1.6894661367580455

Epoch: 5| Step: 1
Training loss: 0.875289797782898
Validation loss: 1.6628158118135186

Epoch: 5| Step: 2
Training loss: 0.914544939994812
Validation loss: 1.6826747630232124

Epoch: 5| Step: 3
Training loss: 0.6087384223937988
Validation loss: 1.6592867323147353

Epoch: 5| Step: 4
Training loss: 0.3822481036186218
Validation loss: 1.6897105113152535

Epoch: 5| Step: 5
Training loss: 0.749836802482605
Validation loss: 1.6883608269435104

Epoch: 5| Step: 6
Training loss: 0.5829877853393555
Validation loss: 1.711058420519675

Epoch: 5| Step: 7
Training loss: 0.6815952062606812
Validation loss: 1.7501167199944938

Epoch: 5| Step: 8
Training loss: 0.48415613174438477
Validation loss: 1.8001579148795015

Epoch: 5| Step: 9
Training loss: 0.7013367414474487
Validation loss: 1.8452275722257552

Epoch: 5| Step: 10
Training loss: 0.42293882369995117
Validation loss: 1.837595446135408

Epoch: 313| Step: 0
Training loss: 0.5088361501693726
Validation loss: 1.8530566923079952

Epoch: 5| Step: 1
Training loss: 0.6441227197647095
Validation loss: 1.8389177758206603

Epoch: 5| Step: 2
Training loss: 0.9671796560287476
Validation loss: 1.80168245684716

Epoch: 5| Step: 3
Training loss: 0.513598620891571
Validation loss: 1.7842338123629171

Epoch: 5| Step: 4
Training loss: 0.3477911949157715
Validation loss: 1.78906467781272

Epoch: 5| Step: 5
Training loss: 0.8079586029052734
Validation loss: 1.7504386235308904

Epoch: 5| Step: 6
Training loss: 0.7634145617485046
Validation loss: 1.72619580453442

Epoch: 5| Step: 7
Training loss: 0.6422628164291382
Validation loss: 1.684878699241146

Epoch: 5| Step: 8
Training loss: 0.846694827079773
Validation loss: 1.6581835785219747

Epoch: 5| Step: 9
Training loss: 0.8253836631774902
Validation loss: 1.6843931546775244

Epoch: 5| Step: 10
Training loss: 0.5655207633972168
Validation loss: 1.6736403895962624

Epoch: 314| Step: 0
Training loss: 0.566303551197052
Validation loss: 1.692434472422446

Epoch: 5| Step: 1
Training loss: 0.7979249358177185
Validation loss: 1.7191957286609116

Epoch: 5| Step: 2
Training loss: 0.4891701340675354
Validation loss: 1.717443666150493

Epoch: 5| Step: 3
Training loss: 0.7847534418106079
Validation loss: 1.7445106390983827

Epoch: 5| Step: 4
Training loss: 0.7976838946342468
Validation loss: 1.7751212684057092

Epoch: 5| Step: 5
Training loss: 0.7420176863670349
Validation loss: 1.7485854548792685

Epoch: 5| Step: 6
Training loss: 0.7358213663101196
Validation loss: 1.7481386840984385

Epoch: 5| Step: 7
Training loss: 0.7548575401306152
Validation loss: 1.737975251290106

Epoch: 5| Step: 8
Training loss: 0.5627390742301941
Validation loss: 1.7679471328694334

Epoch: 5| Step: 9
Training loss: 0.5225616693496704
Validation loss: 1.7563142917489494

Epoch: 5| Step: 10
Training loss: 0.6282386779785156
Validation loss: 1.7530592115976478

Epoch: 315| Step: 0
Training loss: 0.32302334904670715
Validation loss: 1.7108901034119308

Epoch: 5| Step: 1
Training loss: 1.1229501962661743
Validation loss: 1.6930812840820642

Epoch: 5| Step: 2
Training loss: 0.5846258997917175
Validation loss: 1.6599864857171172

Epoch: 5| Step: 3
Training loss: 0.6422401070594788
Validation loss: 1.6671479068776613

Epoch: 5| Step: 4
Training loss: 0.647193968296051
Validation loss: 1.628511748006267

Epoch: 5| Step: 5
Training loss: 0.6584572792053223
Validation loss: 1.650658070400197

Epoch: 5| Step: 6
Training loss: 0.6276082396507263
Validation loss: 1.703036271115785

Epoch: 5| Step: 7
Training loss: 0.5370718836784363
Validation loss: 1.747814901413456

Epoch: 5| Step: 8
Training loss: 0.4524434506893158
Validation loss: 1.7599959347837715

Epoch: 5| Step: 9
Training loss: 0.8532482981681824
Validation loss: 1.7359963937472271

Epoch: 5| Step: 10
Training loss: 0.7087315917015076
Validation loss: 1.740792933330741

Epoch: 316| Step: 0
Training loss: 0.6972795128822327
Validation loss: 1.7537078242148123

Epoch: 5| Step: 1
Training loss: 0.7324877977371216
Validation loss: 1.725366751352946

Epoch: 5| Step: 2
Training loss: 0.77534019947052
Validation loss: 1.714887990746447

Epoch: 5| Step: 3
Training loss: 0.5572198033332825
Validation loss: 1.7144401509274718

Epoch: 5| Step: 4
Training loss: 0.5481541752815247
Validation loss: 1.7041095161950717

Epoch: 5| Step: 5
Training loss: 0.6280907988548279
Validation loss: 1.6940636788645098

Epoch: 5| Step: 6
Training loss: 0.5646575689315796
Validation loss: 1.6816481236488587

Epoch: 5| Step: 7
Training loss: 0.6007586121559143
Validation loss: 1.7118672529856365

Epoch: 5| Step: 8
Training loss: 0.7612029314041138
Validation loss: 1.7363980367619505

Epoch: 5| Step: 9
Training loss: 0.42219677567481995
Validation loss: 1.7430684053769676

Epoch: 5| Step: 10
Training loss: 0.8217151761054993
Validation loss: 1.7515318996162825

Epoch: 317| Step: 0
Training loss: 0.9416772127151489
Validation loss: 1.793475353589622

Epoch: 5| Step: 1
Training loss: 0.7372803688049316
Validation loss: 1.7662791885355467

Epoch: 5| Step: 2
Training loss: 0.5578058362007141
Validation loss: 1.790676623262385

Epoch: 5| Step: 3
Training loss: 0.7244192361831665
Validation loss: 1.8191965626132103

Epoch: 5| Step: 4
Training loss: 0.34854599833488464
Validation loss: 1.7234674910063386

Epoch: 5| Step: 5
Training loss: 0.48494043946266174
Validation loss: 1.7079474195357291

Epoch: 5| Step: 6
Training loss: 0.7209186553955078
Validation loss: 1.6703832034141786

Epoch: 5| Step: 7
Training loss: 0.8820846676826477
Validation loss: 1.6763822455560007

Epoch: 5| Step: 8
Training loss: 0.7323981523513794
Validation loss: 1.6639119271309144

Epoch: 5| Step: 9
Training loss: 0.6794494390487671
Validation loss: 1.6523991361741097

Epoch: 5| Step: 10
Training loss: 0.4437781572341919
Validation loss: 1.6658243940722557

Epoch: 318| Step: 0
Training loss: 0.8953876495361328
Validation loss: 1.7185860410813363

Epoch: 5| Step: 1
Training loss: 0.5841398239135742
Validation loss: 1.727654633983489

Epoch: 5| Step: 2
Training loss: 0.8114197850227356
Validation loss: 1.7118670068761355

Epoch: 5| Step: 3
Training loss: 0.5972303152084351
Validation loss: 1.7445080972486926

Epoch: 5| Step: 4
Training loss: 0.8462222814559937
Validation loss: 1.7975217347503991

Epoch: 5| Step: 5
Training loss: 0.5793926119804382
Validation loss: 1.8244433403015137

Epoch: 5| Step: 6
Training loss: 0.5247527956962585
Validation loss: 1.8648175680509178

Epoch: 5| Step: 7
Training loss: 0.8717015385627747
Validation loss: 1.8565469275238693

Epoch: 5| Step: 8
Training loss: 0.7541894912719727
Validation loss: 1.830719446623197

Epoch: 5| Step: 9
Training loss: 0.43081074953079224
Validation loss: 1.7921026329840384

Epoch: 5| Step: 10
Training loss: 0.5777336955070496
Validation loss: 1.7286437583226029

Epoch: 319| Step: 0
Training loss: 0.5280910730361938
Validation loss: 1.6830228426123177

Epoch: 5| Step: 1
Training loss: 0.4798715114593506
Validation loss: 1.7154558063835226

Epoch: 5| Step: 2
Training loss: 0.5209426879882812
Validation loss: 1.759754462908673

Epoch: 5| Step: 3
Training loss: 0.6966630220413208
Validation loss: 1.793431999862835

Epoch: 5| Step: 4
Training loss: 0.953952431678772
Validation loss: 1.819768641584663

Epoch: 5| Step: 5
Training loss: 1.0706965923309326
Validation loss: 1.7433785776938162

Epoch: 5| Step: 6
Training loss: 0.4167490005493164
Validation loss: 1.7177228235429334

Epoch: 5| Step: 7
Training loss: 0.8795410990715027
Validation loss: 1.7290063519631662

Epoch: 5| Step: 8
Training loss: 0.4943895936012268
Validation loss: 1.7264974681279992

Epoch: 5| Step: 9
Training loss: 0.6331871151924133
Validation loss: 1.7702098277307325

Epoch: 5| Step: 10
Training loss: 0.7187879681587219
Validation loss: 1.782420728796272

Epoch: 320| Step: 0
Training loss: 0.8382226824760437
Validation loss: 1.7871754502737394

Epoch: 5| Step: 1
Training loss: 0.4634246230125427
Validation loss: 1.7863244190010974

Epoch: 5| Step: 2
Training loss: 0.4368043541908264
Validation loss: 1.7419552700493925

Epoch: 5| Step: 3
Training loss: 0.550313413143158
Validation loss: 1.739479777633503

Epoch: 5| Step: 4
Training loss: 0.5884822607040405
Validation loss: 1.7552378382734073

Epoch: 5| Step: 5
Training loss: 0.8798189163208008
Validation loss: 1.731612023486886

Epoch: 5| Step: 6
Training loss: 1.054075837135315
Validation loss: 1.727836191013295

Epoch: 5| Step: 7
Training loss: 0.5104604363441467
Validation loss: 1.7084982587445168

Epoch: 5| Step: 8
Training loss: 0.6575025916099548
Validation loss: 1.6896240890667003

Epoch: 5| Step: 9
Training loss: 0.43262195587158203
Validation loss: 1.684818471631696

Epoch: 5| Step: 10
Training loss: 0.9534090757369995
Validation loss: 1.709828189624253

Epoch: 321| Step: 0
Training loss: 0.589025616645813
Validation loss: 1.6973414292899511

Epoch: 5| Step: 1
Training loss: 0.739565372467041
Validation loss: 1.7455630725429905

Epoch: 5| Step: 2
Training loss: 0.8888260722160339
Validation loss: 1.7820178885613718

Epoch: 5| Step: 3
Training loss: 0.6150521039962769
Validation loss: 1.8118399381637573

Epoch: 5| Step: 4
Training loss: 0.7899154424667358
Validation loss: 1.838909549097861

Epoch: 5| Step: 5
Training loss: 0.544771671295166
Validation loss: 1.8180805739536081

Epoch: 5| Step: 6
Training loss: 0.44975823163986206
Validation loss: 1.8177043648176296

Epoch: 5| Step: 7
Training loss: 0.6313984990119934
Validation loss: 1.8424805723210818

Epoch: 5| Step: 8
Training loss: 0.6789758205413818
Validation loss: 1.7756858948738343

Epoch: 5| Step: 9
Training loss: 0.5157145261764526
Validation loss: 1.7702226036338395

Epoch: 5| Step: 10
Training loss: 0.8837123513221741
Validation loss: 1.7036125288214734

Epoch: 322| Step: 0
Training loss: 0.42640480399131775
Validation loss: 1.6783629463564964

Epoch: 5| Step: 1
Training loss: 0.7276495695114136
Validation loss: 1.70129539761492

Epoch: 5| Step: 2
Training loss: 1.064286231994629
Validation loss: 1.7306190934232486

Epoch: 5| Step: 3
Training loss: 0.7644838690757751
Validation loss: 1.7684314404764483

Epoch: 5| Step: 4
Training loss: 0.7824256420135498
Validation loss: 1.7385700325812063

Epoch: 5| Step: 5
Training loss: 0.6744759678840637
Validation loss: 1.7614676503724949

Epoch: 5| Step: 6
Training loss: 0.800918459892273
Validation loss: 1.794269541258453

Epoch: 5| Step: 7
Training loss: 0.5824823379516602
Validation loss: 1.7512816921357186

Epoch: 5| Step: 8
Training loss: 0.46106845140457153
Validation loss: 1.7381172692903908

Epoch: 5| Step: 9
Training loss: 0.5175066590309143
Validation loss: 1.7588617635029618

Epoch: 5| Step: 10
Training loss: 0.5129479765892029
Validation loss: 1.7806457857931814

Epoch: 323| Step: 0
Training loss: 0.44081562757492065
Validation loss: 1.787336161059718

Epoch: 5| Step: 1
Training loss: 0.6242191195487976
Validation loss: 1.793200477477043

Epoch: 5| Step: 2
Training loss: 0.7724393606185913
Validation loss: 1.7383790221265567

Epoch: 5| Step: 3
Training loss: 0.6036869287490845
Validation loss: 1.704363335845291

Epoch: 5| Step: 4
Training loss: 0.45424193143844604
Validation loss: 1.711223260048897

Epoch: 5| Step: 5
Training loss: 0.8562607765197754
Validation loss: 1.7187010011365336

Epoch: 5| Step: 6
Training loss: 0.7852514386177063
Validation loss: 1.7183154706032044

Epoch: 5| Step: 7
Training loss: 0.7801406979560852
Validation loss: 1.7365450794978807

Epoch: 5| Step: 8
Training loss: 0.6802345514297485
Validation loss: 1.700275759543142

Epoch: 5| Step: 9
Training loss: 0.6135693788528442
Validation loss: 1.696735776880736

Epoch: 5| Step: 10
Training loss: 0.49334239959716797
Validation loss: 1.6841365496317546

Epoch: 324| Step: 0
Training loss: 0.6304583549499512
Validation loss: 1.712954951870826

Epoch: 5| Step: 1
Training loss: 0.7052487134933472
Validation loss: 1.7457890651559318

Epoch: 5| Step: 2
Training loss: 0.7857502698898315
Validation loss: 1.754779508036952

Epoch: 5| Step: 3
Training loss: 0.5087966918945312
Validation loss: 1.7439688213409916

Epoch: 5| Step: 4
Training loss: 0.5261238813400269
Validation loss: 1.7268703509402532

Epoch: 5| Step: 5
Training loss: 0.7210463285446167
Validation loss: 1.7306978125726022

Epoch: 5| Step: 6
Training loss: 0.6881210803985596
Validation loss: 1.7422387689672492

Epoch: 5| Step: 7
Training loss: 0.5330840945243835
Validation loss: 1.775026157338132

Epoch: 5| Step: 8
Training loss: 0.6163709163665771
Validation loss: 1.7690948440182594

Epoch: 5| Step: 9
Training loss: 0.8623512983322144
Validation loss: 1.759507006214511

Epoch: 5| Step: 10
Training loss: 0.6753397583961487
Validation loss: 1.7034385486315655

Epoch: 325| Step: 0
Training loss: 0.6143687963485718
Validation loss: 1.6722899662551058

Epoch: 5| Step: 1
Training loss: 0.9389301538467407
Validation loss: 1.71430572899439

Epoch: 5| Step: 2
Training loss: 0.5850961804389954
Validation loss: 1.6860927881733063

Epoch: 5| Step: 3
Training loss: 0.6327534914016724
Validation loss: 1.7065825218795447

Epoch: 5| Step: 4
Training loss: 0.8541685938835144
Validation loss: 1.6984178814836728

Epoch: 5| Step: 5
Training loss: 0.4140802025794983
Validation loss: 1.6924910045439197

Epoch: 5| Step: 6
Training loss: 0.476492315530777
Validation loss: 1.73108793586813

Epoch: 5| Step: 7
Training loss: 0.6392019391059875
Validation loss: 1.7970946681114934

Epoch: 5| Step: 8
Training loss: 0.5248321294784546
Validation loss: 1.796207603587899

Epoch: 5| Step: 9
Training loss: 0.7464360594749451
Validation loss: 1.7493728040367045

Epoch: 5| Step: 10
Training loss: 0.5598859786987305
Validation loss: 1.7324943170752576

Epoch: 326| Step: 0
Training loss: 0.8390709757804871
Validation loss: 1.715305010477702

Epoch: 5| Step: 1
Training loss: 0.3945821523666382
Validation loss: 1.6671261723323534

Epoch: 5| Step: 2
Training loss: 0.9373937845230103
Validation loss: 1.6780311740854734

Epoch: 5| Step: 3
Training loss: 0.4533326029777527
Validation loss: 1.6952228725597422

Epoch: 5| Step: 4
Training loss: 0.7333309650421143
Validation loss: 1.6913836989351498

Epoch: 5| Step: 5
Training loss: 0.6834461092948914
Validation loss: 1.6797680354887439

Epoch: 5| Step: 6
Training loss: 0.6044371128082275
Validation loss: 1.70045337113001

Epoch: 5| Step: 7
Training loss: 0.644880473613739
Validation loss: 1.7017218912801435

Epoch: 5| Step: 8
Training loss: 0.628285825252533
Validation loss: 1.7224313725707352

Epoch: 5| Step: 9
Training loss: 0.6616427302360535
Validation loss: 1.744677911522568

Epoch: 5| Step: 10
Training loss: 0.46685707569122314
Validation loss: 1.7419681664436095

Epoch: 327| Step: 0
Training loss: 0.5301623344421387
Validation loss: 1.7948024683101202

Epoch: 5| Step: 1
Training loss: 0.4619347155094147
Validation loss: 1.816585099825295

Epoch: 5| Step: 2
Training loss: 0.7536412477493286
Validation loss: 1.790265578095631

Epoch: 5| Step: 3
Training loss: 0.8047380447387695
Validation loss: 1.8018118373809322

Epoch: 5| Step: 4
Training loss: 0.7060018181800842
Validation loss: 1.8223338742409982

Epoch: 5| Step: 5
Training loss: 0.46154290437698364
Validation loss: 1.7904056733654392

Epoch: 5| Step: 6
Training loss: 0.7834181785583496
Validation loss: 1.771486336185086

Epoch: 5| Step: 7
Training loss: 0.389550119638443
Validation loss: 1.732941303201901

Epoch: 5| Step: 8
Training loss: 0.6625139117240906
Validation loss: 1.7175285200918875

Epoch: 5| Step: 9
Training loss: 0.45675063133239746
Validation loss: 1.7063543437629618

Epoch: 5| Step: 10
Training loss: 0.759588360786438
Validation loss: 1.6723204069240118

Epoch: 328| Step: 0
Training loss: 1.1026428937911987
Validation loss: 1.6806392900405391

Epoch: 5| Step: 1
Training loss: 0.6387585401535034
Validation loss: 1.6961335802590976

Epoch: 5| Step: 2
Training loss: 0.3853549063205719
Validation loss: 1.6840081163631972

Epoch: 5| Step: 3
Training loss: 0.5193696022033691
Validation loss: 1.720482067395282

Epoch: 5| Step: 4
Training loss: 0.45995283126831055
Validation loss: 1.7601176513138639

Epoch: 5| Step: 5
Training loss: 0.8796695470809937
Validation loss: 1.762420477405671

Epoch: 5| Step: 6
Training loss: 0.5107678771018982
Validation loss: 1.7607008564856745

Epoch: 5| Step: 7
Training loss: 0.7205389142036438
Validation loss: 1.7783604180941017

Epoch: 5| Step: 8
Training loss: 0.4356228709220886
Validation loss: 1.7862507784238426

Epoch: 5| Step: 9
Training loss: 0.3742094933986664
Validation loss: 1.747062175504623

Epoch: 5| Step: 10
Training loss: 0.5059646368026733
Validation loss: 1.7221459611769645

Epoch: 329| Step: 0
Training loss: 0.4132619798183441
Validation loss: 1.6976408291888494

Epoch: 5| Step: 1
Training loss: 0.7820174694061279
Validation loss: 1.7138829141534784

Epoch: 5| Step: 2
Training loss: 0.41554126143455505
Validation loss: 1.6764528046372116

Epoch: 5| Step: 3
Training loss: 0.5572377443313599
Validation loss: 1.668150617230323

Epoch: 5| Step: 4
Training loss: 0.6702414751052856
Validation loss: 1.6666174050300353

Epoch: 5| Step: 5
Training loss: 0.8963099718093872
Validation loss: 1.6707217078055105

Epoch: 5| Step: 6
Training loss: 0.7515722513198853
Validation loss: 1.6486622620654363

Epoch: 5| Step: 7
Training loss: 0.5921868085861206
Validation loss: 1.6581659778471916

Epoch: 5| Step: 8
Training loss: 0.3750104308128357
Validation loss: 1.6656098878511818

Epoch: 5| Step: 9
Training loss: 0.8341554403305054
Validation loss: 1.6494080392263268

Epoch: 5| Step: 10
Training loss: 0.3833754062652588
Validation loss: 1.687771713861855

Epoch: 330| Step: 0
Training loss: 0.681707501411438
Validation loss: 1.7185470506709108

Epoch: 5| Step: 1
Training loss: 0.6091650724411011
Validation loss: 1.7326870605509768

Epoch: 5| Step: 2
Training loss: 0.4982849061489105
Validation loss: 1.7865961751630228

Epoch: 5| Step: 3
Training loss: 0.5934045910835266
Validation loss: 1.7533219809173255

Epoch: 5| Step: 4
Training loss: 0.697595477104187
Validation loss: 1.7628737957246843

Epoch: 5| Step: 5
Training loss: 0.5004860162734985
Validation loss: 1.7254703352528233

Epoch: 5| Step: 6
Training loss: 0.4522172510623932
Validation loss: 1.6963523382781653

Epoch: 5| Step: 7
Training loss: 0.627570629119873
Validation loss: 1.6998406135907738

Epoch: 5| Step: 8
Training loss: 0.38043665885925293
Validation loss: 1.6958042396012174

Epoch: 5| Step: 9
Training loss: 0.5033682584762573
Validation loss: 1.6765962621217132

Epoch: 5| Step: 10
Training loss: 0.9433596134185791
Validation loss: 1.6782179224875666

Epoch: 331| Step: 0
Training loss: 0.5059348344802856
Validation loss: 1.69707614632063

Epoch: 5| Step: 1
Training loss: 0.6364551782608032
Validation loss: 1.7186131349173925

Epoch: 5| Step: 2
Training loss: 0.6055260896682739
Validation loss: 1.7072969226426975

Epoch: 5| Step: 3
Training loss: 0.4683154225349426
Validation loss: 1.7548634467586395

Epoch: 5| Step: 4
Training loss: 0.627659261226654
Validation loss: 1.7421835443024993

Epoch: 5| Step: 5
Training loss: 0.3895123302936554
Validation loss: 1.7803071814198648

Epoch: 5| Step: 6
Training loss: 0.7014192342758179
Validation loss: 1.7380972728934339

Epoch: 5| Step: 7
Training loss: 0.5740145444869995
Validation loss: 1.701545726227504

Epoch: 5| Step: 8
Training loss: 0.6125651001930237
Validation loss: 1.708646458964194

Epoch: 5| Step: 9
Training loss: 0.5539987683296204
Validation loss: 1.70841464688701

Epoch: 5| Step: 10
Training loss: 0.9488407373428345
Validation loss: 1.7031461551625242

Epoch: 332| Step: 0
Training loss: 0.8190954327583313
Validation loss: 1.687476695224803

Epoch: 5| Step: 1
Training loss: 0.7808109521865845
Validation loss: 1.6879836654150358

Epoch: 5| Step: 2
Training loss: 0.803805947303772
Validation loss: 1.7031706533124369

Epoch: 5| Step: 3
Training loss: 0.2735153138637543
Validation loss: 1.7111153833327755

Epoch: 5| Step: 4
Training loss: 0.41522836685180664
Validation loss: 1.7420074991000596

Epoch: 5| Step: 5
Training loss: 0.5609434843063354
Validation loss: 1.7786713928304694

Epoch: 5| Step: 6
Training loss: 0.5772212147712708
Validation loss: 1.794214601157814

Epoch: 5| Step: 7
Training loss: 0.5814694166183472
Validation loss: 1.7659774634145922

Epoch: 5| Step: 8
Training loss: 0.692340075969696
Validation loss: 1.7781291738633187

Epoch: 5| Step: 9
Training loss: 0.5615569353103638
Validation loss: 1.7474992775147962

Epoch: 5| Step: 10
Training loss: 0.4741491973400116
Validation loss: 1.7352968095451273

Epoch: 333| Step: 0
Training loss: 0.6050459146499634
Validation loss: 1.6985372651007868

Epoch: 5| Step: 1
Training loss: 0.6882379055023193
Validation loss: 1.7107131968262375

Epoch: 5| Step: 2
Training loss: 0.6514108777046204
Validation loss: 1.695075406823107

Epoch: 5| Step: 3
Training loss: 0.5863515138626099
Validation loss: 1.6980169075791554

Epoch: 5| Step: 4
Training loss: 0.5804126858711243
Validation loss: 1.7096987667904104

Epoch: 5| Step: 5
Training loss: 0.6912329196929932
Validation loss: 1.740505781224979

Epoch: 5| Step: 6
Training loss: 0.526342511177063
Validation loss: 1.7306819936280609

Epoch: 5| Step: 7
Training loss: 0.23078426718711853
Validation loss: 1.7560453414916992

Epoch: 5| Step: 8
Training loss: 0.49291738867759705
Validation loss: 1.791528986346337

Epoch: 5| Step: 9
Training loss: 0.7341347336769104
Validation loss: 1.8191654169431297

Epoch: 5| Step: 10
Training loss: 0.6273625493049622
Validation loss: 1.7931643378350042

Epoch: 334| Step: 0
Training loss: 0.5156893730163574
Validation loss: 1.8137396971384685

Epoch: 5| Step: 1
Training loss: 0.4959065020084381
Validation loss: 1.7754668856179843

Epoch: 5| Step: 2
Training loss: 0.4563263952732086
Validation loss: 1.7897811961430374

Epoch: 5| Step: 3
Training loss: 0.7025825381278992
Validation loss: 1.8056579648807485

Epoch: 5| Step: 4
Training loss: 0.6766182780265808
Validation loss: 1.7800943261833602

Epoch: 5| Step: 5
Training loss: 0.6539241075515747
Validation loss: 1.7505628332015006

Epoch: 5| Step: 6
Training loss: 0.5502694845199585
Validation loss: 1.7258332455030052

Epoch: 5| Step: 7
Training loss: 0.5256386399269104
Validation loss: 1.7258735190155685

Epoch: 5| Step: 8
Training loss: 0.6741814613342285
Validation loss: 1.6801156100406442

Epoch: 5| Step: 9
Training loss: 0.5798859596252441
Validation loss: 1.6692907630756337

Epoch: 5| Step: 10
Training loss: 0.3977624773979187
Validation loss: 1.6818939101311468

Epoch: 335| Step: 0
Training loss: 0.8118712306022644
Validation loss: 1.6705998310478785

Epoch: 5| Step: 1
Training loss: 0.28402677178382874
Validation loss: 1.7077921359769759

Epoch: 5| Step: 2
Training loss: 0.6086944341659546
Validation loss: 1.666588858891559

Epoch: 5| Step: 3
Training loss: 0.5882377624511719
Validation loss: 1.6953069061361334

Epoch: 5| Step: 4
Training loss: 0.7537086009979248
Validation loss: 1.713698100018245

Epoch: 5| Step: 5
Training loss: 0.312070369720459
Validation loss: 1.667637719902941

Epoch: 5| Step: 6
Training loss: 0.6348075866699219
Validation loss: 1.6964144886180919

Epoch: 5| Step: 7
Training loss: 0.6717931032180786
Validation loss: 1.681271795303591

Epoch: 5| Step: 8
Training loss: 0.47529512643814087
Validation loss: 1.7081778369924074

Epoch: 5| Step: 9
Training loss: 0.314675509929657
Validation loss: 1.696207166999899

Epoch: 5| Step: 10
Training loss: 0.6128251552581787
Validation loss: 1.7383437759132796

Epoch: 336| Step: 0
Training loss: 0.4049370288848877
Validation loss: 1.771417656252461

Epoch: 5| Step: 1
Training loss: 0.4702947735786438
Validation loss: 1.782364147965626

Epoch: 5| Step: 2
Training loss: 0.579206645488739
Validation loss: 1.815421050594699

Epoch: 5| Step: 3
Training loss: 0.576583206653595
Validation loss: 1.8277943108671455

Epoch: 5| Step: 4
Training loss: 0.9030603170394897
Validation loss: 1.81093632277622

Epoch: 5| Step: 5
Training loss: 0.7515535354614258
Validation loss: 1.749511012467005

Epoch: 5| Step: 6
Training loss: 0.34207338094711304
Validation loss: 1.7209130390997855

Epoch: 5| Step: 7
Training loss: 0.4309307932853699
Validation loss: 1.6751749919306846

Epoch: 5| Step: 8
Training loss: 0.5575094819068909
Validation loss: 1.67245086034139

Epoch: 5| Step: 9
Training loss: 0.4760502278804779
Validation loss: 1.6826057280263593

Epoch: 5| Step: 10
Training loss: 0.38960686326026917
Validation loss: 1.7102150852962206

Epoch: 337| Step: 0
Training loss: 0.6203936338424683
Validation loss: 1.7162240089908722

Epoch: 5| Step: 1
Training loss: 0.4056006968021393
Validation loss: 1.7630375405793548

Epoch: 5| Step: 2
Training loss: 0.7985595464706421
Validation loss: 1.7829163702585364

Epoch: 5| Step: 3
Training loss: 0.720750629901886
Validation loss: 1.762951054880696

Epoch: 5| Step: 4
Training loss: 0.6710788607597351
Validation loss: 1.7201248407363892

Epoch: 5| Step: 5
Training loss: 0.501508355140686
Validation loss: 1.6723471072412306

Epoch: 5| Step: 6
Training loss: 0.4064607620239258
Validation loss: 1.6617659548277497

Epoch: 5| Step: 7
Training loss: 0.40344706177711487
Validation loss: 1.6647190996395644

Epoch: 5| Step: 8
Training loss: 0.8037401437759399
Validation loss: 1.6890834198203137

Epoch: 5| Step: 9
Training loss: 0.5319020748138428
Validation loss: 1.6479980830223329

Epoch: 5| Step: 10
Training loss: 0.17362532019615173
Validation loss: 1.6997314242906467

Epoch: 338| Step: 0
Training loss: 0.5004528760910034
Validation loss: 1.6578290283039052

Epoch: 5| Step: 1
Training loss: 0.5297619104385376
Validation loss: 1.6702346096756637

Epoch: 5| Step: 2
Training loss: 0.639173150062561
Validation loss: 1.6986918321219824

Epoch: 5| Step: 3
Training loss: 0.6128391027450562
Validation loss: 1.714923212605138

Epoch: 5| Step: 4
Training loss: 0.5185413360595703
Validation loss: 1.664888434512641

Epoch: 5| Step: 5
Training loss: 0.623181939125061
Validation loss: 1.651661637008831

Epoch: 5| Step: 6
Training loss: 0.5512670278549194
Validation loss: 1.6522518755287252

Epoch: 5| Step: 7
Training loss: 0.3780255615711212
Validation loss: 1.6353911417786793

Epoch: 5| Step: 8
Training loss: 0.5694940686225891
Validation loss: 1.6823882120911793

Epoch: 5| Step: 9
Training loss: 0.5166257619857788
Validation loss: 1.7217233283545381

Epoch: 5| Step: 10
Training loss: 0.3520001173019409
Validation loss: 1.763475589854743

Epoch: 339| Step: 0
Training loss: 0.5881160497665405
Validation loss: 1.7806097679240729

Epoch: 5| Step: 1
Training loss: 0.7727378606796265
Validation loss: 1.8027639440310899

Epoch: 5| Step: 2
Training loss: 0.6172758340835571
Validation loss: 1.774330864670456

Epoch: 5| Step: 3
Training loss: 0.40700969099998474
Validation loss: 1.7574256017643919

Epoch: 5| Step: 4
Training loss: 0.3364488482475281
Validation loss: 1.734493254333414

Epoch: 5| Step: 5
Training loss: 0.5051299333572388
Validation loss: 1.7251088478231942

Epoch: 5| Step: 6
Training loss: 0.5277607440948486
Validation loss: 1.6984554452280844

Epoch: 5| Step: 7
Training loss: 0.5629309415817261
Validation loss: 1.695975225458863

Epoch: 5| Step: 8
Training loss: 0.5276870727539062
Validation loss: 1.6834332084143033

Epoch: 5| Step: 9
Training loss: 0.5185120701789856
Validation loss: 1.6709141744080411

Epoch: 5| Step: 10
Training loss: 0.8553833961486816
Validation loss: 1.6829276264354747

Epoch: 340| Step: 0
Training loss: 0.6055157780647278
Validation loss: 1.6467198287287066

Epoch: 5| Step: 1
Training loss: 0.5327039957046509
Validation loss: 1.701790484048987

Epoch: 5| Step: 2
Training loss: 0.6922050714492798
Validation loss: 1.7293875371256182

Epoch: 5| Step: 3
Training loss: 0.3558664321899414
Validation loss: 1.745601495107015

Epoch: 5| Step: 4
Training loss: 0.4778478145599365
Validation loss: 1.743319301195042

Epoch: 5| Step: 5
Training loss: 0.6427959203720093
Validation loss: 1.766300356516274

Epoch: 5| Step: 6
Training loss: 0.5106621980667114
Validation loss: 1.8002049858852098

Epoch: 5| Step: 7
Training loss: 0.45440053939819336
Validation loss: 1.8052295843760173

Epoch: 5| Step: 8
Training loss: 0.46464499831199646
Validation loss: 1.7833803058952413

Epoch: 5| Step: 9
Training loss: 0.6456594467163086
Validation loss: 1.7742183413556827

Epoch: 5| Step: 10
Training loss: 0.4674516022205353
Validation loss: 1.784746587917369

Epoch: 341| Step: 0
Training loss: 0.5898825526237488
Validation loss: 1.7159895602092947

Epoch: 5| Step: 1
Training loss: 0.46154823899269104
Validation loss: 1.6950289434002292

Epoch: 5| Step: 2
Training loss: 0.43662214279174805
Validation loss: 1.697462357500548

Epoch: 5| Step: 3
Training loss: 0.7048035860061646
Validation loss: 1.6749791022269958

Epoch: 5| Step: 4
Training loss: 0.6080698370933533
Validation loss: 1.6869605177192277

Epoch: 5| Step: 5
Training loss: 0.3171592354774475
Validation loss: 1.659483317405947

Epoch: 5| Step: 6
Training loss: 0.4296492040157318
Validation loss: 1.6632911748783563

Epoch: 5| Step: 7
Training loss: 0.524763822555542
Validation loss: 1.68696439907115

Epoch: 5| Step: 8
Training loss: 0.6314105987548828
Validation loss: 1.7253615048623854

Epoch: 5| Step: 9
Training loss: 0.45010194182395935
Validation loss: 1.7086770739606632

Epoch: 5| Step: 10
Training loss: 0.6204575300216675
Validation loss: 1.6801113723426737

Epoch: 342| Step: 0
Training loss: 0.49915361404418945
Validation loss: 1.6699106257448915

Epoch: 5| Step: 1
Training loss: 0.5818806290626526
Validation loss: 1.6622518557374195

Epoch: 5| Step: 2
Training loss: 0.5522798299789429
Validation loss: 1.6867371733470629

Epoch: 5| Step: 3
Training loss: 0.3491930365562439
Validation loss: 1.648804744084676

Epoch: 5| Step: 4
Training loss: 0.4855738580226898
Validation loss: 1.6809517619430379

Epoch: 5| Step: 5
Training loss: 0.5654417276382446
Validation loss: 1.6721645606461393

Epoch: 5| Step: 6
Training loss: 0.43285685777664185
Validation loss: 1.675696869050303

Epoch: 5| Step: 7
Training loss: 0.7642439603805542
Validation loss: 1.6493324566912908

Epoch: 5| Step: 8
Training loss: 0.4193241000175476
Validation loss: 1.7104879040871896

Epoch: 5| Step: 9
Training loss: 0.36940938234329224
Validation loss: 1.7091017205228087

Epoch: 5| Step: 10
Training loss: 0.5221995115280151
Validation loss: 1.7279517086603309

Epoch: 343| Step: 0
Training loss: 0.4227469563484192
Validation loss: 1.7355005330936883

Epoch: 5| Step: 1
Training loss: 0.4272688031196594
Validation loss: 1.7091851644618536

Epoch: 5| Step: 2
Training loss: 0.5224882960319519
Validation loss: 1.7202457151105326

Epoch: 5| Step: 3
Training loss: 0.49109992384910583
Validation loss: 1.7427511445937618

Epoch: 5| Step: 4
Training loss: 0.45570963621139526
Validation loss: 1.7152882404224847

Epoch: 5| Step: 5
Training loss: 0.4576175808906555
Validation loss: 1.7184521427718542

Epoch: 5| Step: 6
Training loss: 0.5285247564315796
Validation loss: 1.7185326904378913

Epoch: 5| Step: 7
Training loss: 0.3033166527748108
Validation loss: 1.6379474106655325

Epoch: 5| Step: 8
Training loss: 0.7817965745925903
Validation loss: 1.6517064699562647

Epoch: 5| Step: 9
Training loss: 0.5339472889900208
Validation loss: 1.623781068350679

Epoch: 5| Step: 10
Training loss: 0.7318781018257141
Validation loss: 1.6330991733458735

Epoch: 344| Step: 0
Training loss: 0.6135661602020264
Validation loss: 1.6409478213197441

Epoch: 5| Step: 1
Training loss: 0.4064381718635559
Validation loss: 1.6280124033651044

Epoch: 5| Step: 2
Training loss: 0.5435088276863098
Validation loss: 1.6106705434860722

Epoch: 5| Step: 3
Training loss: 0.7814706563949585
Validation loss: 1.6119384355442499

Epoch: 5| Step: 4
Training loss: 0.42757225036621094
Validation loss: 1.6120160574554114

Epoch: 5| Step: 5
Training loss: 0.549210786819458
Validation loss: 1.6387067341035413

Epoch: 5| Step: 6
Training loss: 0.30211904644966125
Validation loss: 1.6828142263556038

Epoch: 5| Step: 7
Training loss: 0.7177377939224243
Validation loss: 1.7192795968824817

Epoch: 5| Step: 8
Training loss: 0.6171824336051941
Validation loss: 1.7519787639699957

Epoch: 5| Step: 9
Training loss: 0.6652010679244995
Validation loss: 1.754677414894104

Epoch: 5| Step: 10
Training loss: 0.3135208785533905
Validation loss: 1.7483228944963025

Epoch: 345| Step: 0
Training loss: 0.4882672429084778
Validation loss: 1.7517791512191936

Epoch: 5| Step: 1
Training loss: 0.4533909261226654
Validation loss: 1.6861700396383963

Epoch: 5| Step: 2
Training loss: 0.7122036814689636
Validation loss: 1.6796045111071678

Epoch: 5| Step: 3
Training loss: 0.4486512243747711
Validation loss: 1.6686015052180136

Epoch: 5| Step: 4
Training loss: 0.6335517168045044
Validation loss: 1.647195311002834

Epoch: 5| Step: 5
Training loss: 0.6742226481437683
Validation loss: 1.6387143263252832

Epoch: 5| Step: 6
Training loss: 0.3093396723270416
Validation loss: 1.6577257981864355

Epoch: 5| Step: 7
Training loss: 0.5785725712776184
Validation loss: 1.5901836682391424

Epoch: 5| Step: 8
Training loss: 0.5928964614868164
Validation loss: 1.593359565222135

Epoch: 5| Step: 9
Training loss: 0.4796432554721832
Validation loss: 1.580779299941114

Epoch: 5| Step: 10
Training loss: 0.31989040970802307
Validation loss: 1.6074146269470133

Epoch: 346| Step: 0
Training loss: 0.7584021687507629
Validation loss: 1.5781858954378354

Epoch: 5| Step: 1
Training loss: 0.43463650345802307
Validation loss: 1.6121845232543124

Epoch: 5| Step: 2
Training loss: 0.6150951385498047
Validation loss: 1.631118574450093

Epoch: 5| Step: 3
Training loss: 0.35086068511009216
Validation loss: 1.6230120312783025

Epoch: 5| Step: 4
Training loss: 0.46172675490379333
Validation loss: 1.6550547986902215

Epoch: 5| Step: 5
Training loss: 0.4453619420528412
Validation loss: 1.7000822918389433

Epoch: 5| Step: 6
Training loss: 0.6961188912391663
Validation loss: 1.68884422573992

Epoch: 5| Step: 7
Training loss: 0.3808445930480957
Validation loss: 1.712954621161184

Epoch: 5| Step: 8
Training loss: 0.7009265422821045
Validation loss: 1.6820955455944102

Epoch: 5| Step: 9
Training loss: 0.3582347333431244
Validation loss: 1.7059964697848085

Epoch: 5| Step: 10
Training loss: 0.4378257989883423
Validation loss: 1.6732292636748283

Epoch: 347| Step: 0
Training loss: 0.6028897166252136
Validation loss: 1.6661928110225226

Epoch: 5| Step: 1
Training loss: 0.4782574772834778
Validation loss: 1.6342128214015756

Epoch: 5| Step: 2
Training loss: 0.6621829271316528
Validation loss: 1.6265884048195296

Epoch: 5| Step: 3
Training loss: 0.29594674706459045
Validation loss: 1.6292237735563708

Epoch: 5| Step: 4
Training loss: 0.5467585325241089
Validation loss: 1.602607286104592

Epoch: 5| Step: 5
Training loss: 0.4362570345401764
Validation loss: 1.6283590896155244

Epoch: 5| Step: 6
Training loss: 0.2897430956363678
Validation loss: 1.629984159623423

Epoch: 5| Step: 7
Training loss: 0.37045907974243164
Validation loss: 1.6500361068274385

Epoch: 5| Step: 8
Training loss: 0.5167648792266846
Validation loss: 1.6576298526538316

Epoch: 5| Step: 9
Training loss: 0.7300229072570801
Validation loss: 1.638760325729206

Epoch: 5| Step: 10
Training loss: 0.6365795135498047
Validation loss: 1.6564937150606545

Epoch: 348| Step: 0
Training loss: 0.5245978832244873
Validation loss: 1.690788963789581

Epoch: 5| Step: 1
Training loss: 0.5956454873085022
Validation loss: 1.6955076597070182

Epoch: 5| Step: 2
Training loss: 0.7123895883560181
Validation loss: 1.7094551555572017

Epoch: 5| Step: 3
Training loss: 0.4718039929866791
Validation loss: 1.7353240482268795

Epoch: 5| Step: 4
Training loss: 0.33903416991233826
Validation loss: 1.730875575414268

Epoch: 5| Step: 5
Training loss: 0.5967450141906738
Validation loss: 1.7507445094405965

Epoch: 5| Step: 6
Training loss: 0.5518233180046082
Validation loss: 1.7635035899377638

Epoch: 5| Step: 7
Training loss: 0.48876795172691345
Validation loss: 1.7287367056774836

Epoch: 5| Step: 8
Training loss: 0.2659265697002411
Validation loss: 1.7185829236943235

Epoch: 5| Step: 9
Training loss: 0.37410351634025574
Validation loss: 1.7173649598193426

Epoch: 5| Step: 10
Training loss: 0.7409302592277527
Validation loss: 1.6941666295451503

Epoch: 349| Step: 0
Training loss: 0.5498584508895874
Validation loss: 1.6878976578353553

Epoch: 5| Step: 1
Training loss: 0.6148491501808167
Validation loss: 1.7109237178679435

Epoch: 5| Step: 2
Training loss: 0.33329516649246216
Validation loss: 1.7253642723124514

Epoch: 5| Step: 3
Training loss: 0.4468814730644226
Validation loss: 1.6755676948896019

Epoch: 5| Step: 4
Training loss: 0.677559494972229
Validation loss: 1.69303774064587

Epoch: 5| Step: 5
Training loss: 0.5527642965316772
Validation loss: 1.685837048356251

Epoch: 5| Step: 6
Training loss: 0.4060753881931305
Validation loss: 1.7412957593958864

Epoch: 5| Step: 7
Training loss: 0.5379440784454346
Validation loss: 1.7595618053149151

Epoch: 5| Step: 8
Training loss: 0.5046505331993103
Validation loss: 1.7756374125839562

Epoch: 5| Step: 9
Training loss: 0.5267401933670044
Validation loss: 1.716387173180939

Epoch: 5| Step: 10
Training loss: 0.40392521023750305
Validation loss: 1.7344385975150651

Epoch: 350| Step: 0
Training loss: 0.3336527943611145
Validation loss: 1.7170282974038074

Epoch: 5| Step: 1
Training loss: 0.5496515035629272
Validation loss: 1.7135210575595978

Epoch: 5| Step: 2
Training loss: 0.6266433000564575
Validation loss: 1.734010103569236

Epoch: 5| Step: 3
Training loss: 0.43620747327804565
Validation loss: 1.7555551939113165

Epoch: 5| Step: 4
Training loss: 0.62806236743927
Validation loss: 1.7170926819565475

Epoch: 5| Step: 5
Training loss: 0.5119274854660034
Validation loss: 1.7529385782057239

Epoch: 5| Step: 6
Training loss: 0.8710033297538757
Validation loss: 1.7430837385116085

Epoch: 5| Step: 7
Training loss: 0.3070845305919647
Validation loss: 1.7214734861927647

Epoch: 5| Step: 8
Training loss: 0.4526553153991699
Validation loss: 1.694780295894992

Epoch: 5| Step: 9
Training loss: 0.37232160568237305
Validation loss: 1.6647377180796799

Epoch: 5| Step: 10
Training loss: 0.3714284896850586
Validation loss: 1.6771322552875807

Epoch: 351| Step: 0
Training loss: 0.5522569417953491
Validation loss: 1.6677926330156223

Epoch: 5| Step: 1
Training loss: 0.28046998381614685
Validation loss: 1.66621789240068

Epoch: 5| Step: 2
Training loss: 0.45989179611206055
Validation loss: 1.6619674697999032

Epoch: 5| Step: 3
Training loss: 0.365112841129303
Validation loss: 1.688886470692132

Epoch: 5| Step: 4
Training loss: 0.32155197858810425
Validation loss: 1.720106537624072

Epoch: 5| Step: 5
Training loss: 0.6428428888320923
Validation loss: 1.7610558822590818

Epoch: 5| Step: 6
Training loss: 0.4798300862312317
Validation loss: 1.757351880432457

Epoch: 5| Step: 7
Training loss: 0.7547883987426758
Validation loss: 1.7659830995785293

Epoch: 5| Step: 8
Training loss: 0.49715456366539
Validation loss: 1.777636166541807

Epoch: 5| Step: 9
Training loss: 0.7983136177062988
Validation loss: 1.7527167732997606

Epoch: 5| Step: 10
Training loss: 0.4993942975997925
Validation loss: 1.7285171356252444

Epoch: 352| Step: 0
Training loss: 0.44432392716407776
Validation loss: 1.6917989074542958

Epoch: 5| Step: 1
Training loss: 0.32137200236320496
Validation loss: 1.644553348582278

Epoch: 5| Step: 2
Training loss: 0.49675360321998596
Validation loss: 1.6562789255572903

Epoch: 5| Step: 3
Training loss: 0.48530349135398865
Validation loss: 1.6170246754923174

Epoch: 5| Step: 4
Training loss: 0.7338455319404602
Validation loss: 1.657282397311221

Epoch: 5| Step: 5
Training loss: 0.4128146767616272
Validation loss: 1.628115205354588

Epoch: 5| Step: 6
Training loss: 0.506266713142395
Validation loss: 1.66443778750717

Epoch: 5| Step: 7
Training loss: 0.4574025273323059
Validation loss: 1.6799335825827815

Epoch: 5| Step: 8
Training loss: 0.574943482875824
Validation loss: 1.6391947064348447

Epoch: 5| Step: 9
Training loss: 0.713655948638916
Validation loss: 1.591047312623711

Epoch: 5| Step: 10
Training loss: 0.3925847113132477
Validation loss: 1.5729987121397448

Epoch: 353| Step: 0
Training loss: 0.43700122833251953
Validation loss: 1.6133210530845068

Epoch: 5| Step: 1
Training loss: 0.6742455363273621
Validation loss: 1.6164081942650579

Epoch: 5| Step: 2
Training loss: 0.515518069267273
Validation loss: 1.6542587152091406

Epoch: 5| Step: 3
Training loss: 0.6574617624282837
Validation loss: 1.631357446793587

Epoch: 5| Step: 4
Training loss: 0.3237365782260895
Validation loss: 1.6849116266414683

Epoch: 5| Step: 5
Training loss: 0.416678249835968
Validation loss: 1.7384349300015358

Epoch: 5| Step: 6
Training loss: 0.5629926919937134
Validation loss: 1.8018914422681254

Epoch: 5| Step: 7
Training loss: 0.7805464863777161
Validation loss: 1.8639462199262393

Epoch: 5| Step: 8
Training loss: 0.588342547416687
Validation loss: 1.8260977832219933

Epoch: 5| Step: 9
Training loss: 0.4827747941017151
Validation loss: 1.7520899939280685

Epoch: 5| Step: 10
Training loss: 0.22668620944023132
Validation loss: 1.6919631291461248

Epoch: 354| Step: 0
Training loss: 0.600489616394043
Validation loss: 1.6935782086464666

Epoch: 5| Step: 1
Training loss: 0.49765294790267944
Validation loss: 1.6767951173167075

Epoch: 5| Step: 2
Training loss: 0.5668333172798157
Validation loss: 1.685379981994629

Epoch: 5| Step: 3
Training loss: 0.38936418294906616
Validation loss: 1.7020550979081022

Epoch: 5| Step: 4
Training loss: 0.6061747670173645
Validation loss: 1.6858340719694733

Epoch: 5| Step: 5
Training loss: 0.576924741268158
Validation loss: 1.7133398171394103

Epoch: 5| Step: 6
Training loss: 0.44436296820640564
Validation loss: 1.683878497410846

Epoch: 5| Step: 7
Training loss: 0.460472047328949
Validation loss: 1.7335091713936097

Epoch: 5| Step: 8
Training loss: 0.5920547246932983
Validation loss: 1.79229615324287

Epoch: 5| Step: 9
Training loss: 0.6075206995010376
Validation loss: 1.8425251847954207

Epoch: 5| Step: 10
Training loss: 0.8018206357955933
Validation loss: 1.8973532992024575

Epoch: 355| Step: 0
Training loss: 0.5222855806350708
Validation loss: 1.8533256207742999

Epoch: 5| Step: 1
Training loss: 0.6122311353683472
Validation loss: 1.7626185904267013

Epoch: 5| Step: 2
Training loss: 0.4351778030395508
Validation loss: 1.7260950534574446

Epoch: 5| Step: 3
Training loss: 0.5317625403404236
Validation loss: 1.7133140038418513

Epoch: 5| Step: 4
Training loss: 0.6279310584068298
Validation loss: 1.7199096846324142

Epoch: 5| Step: 5
Training loss: 0.5560345649719238
Validation loss: 1.7076231920590965

Epoch: 5| Step: 6
Training loss: 0.37610480189323425
Validation loss: 1.6960727707032235

Epoch: 5| Step: 7
Training loss: 0.5645390152931213
Validation loss: 1.6827794838977117

Epoch: 5| Step: 8
Training loss: 0.41921767592430115
Validation loss: 1.6580286936093402

Epoch: 5| Step: 9
Training loss: 0.5527745485305786
Validation loss: 1.6285279232968566

Epoch: 5| Step: 10
Training loss: 0.4603285491466522
Validation loss: 1.6740797463283743

Epoch: 356| Step: 0
Training loss: 0.40681520104408264
Validation loss: 1.726726693491782

Epoch: 5| Step: 1
Training loss: 0.6429245471954346
Validation loss: 1.779244968968053

Epoch: 5| Step: 2
Training loss: 0.6119864583015442
Validation loss: 1.7946979461177703

Epoch: 5| Step: 3
Training loss: 0.2951810956001282
Validation loss: 1.7404865603293143

Epoch: 5| Step: 4
Training loss: 0.57151859998703
Validation loss: 1.691901563316263

Epoch: 5| Step: 5
Training loss: 0.22530806064605713
Validation loss: 1.6957134431408298

Epoch: 5| Step: 6
Training loss: 0.35108494758605957
Validation loss: 1.619954433492435

Epoch: 5| Step: 7
Training loss: 0.39275598526000977
Validation loss: 1.6512539309840049

Epoch: 5| Step: 8
Training loss: 0.5778405666351318
Validation loss: 1.6438036695603402

Epoch: 5| Step: 9
Training loss: 0.6518380045890808
Validation loss: 1.6340540160414994

Epoch: 5| Step: 10
Training loss: 0.6631101965904236
Validation loss: 1.6636873727203698

Epoch: 357| Step: 0
Training loss: 0.5658755302429199
Validation loss: 1.6605275023368098

Epoch: 5| Step: 1
Training loss: 0.3270151913166046
Validation loss: 1.7407608775682346

Epoch: 5| Step: 2
Training loss: 0.5628801584243774
Validation loss: 1.7703765758904078

Epoch: 5| Step: 3
Training loss: 0.531194269657135
Validation loss: 1.7493913853040306

Epoch: 5| Step: 4
Training loss: 0.6956239938735962
Validation loss: 1.6978567569486556

Epoch: 5| Step: 5
Training loss: 0.3380892276763916
Validation loss: 1.6888594089015838

Epoch: 5| Step: 6
Training loss: 0.4771602153778076
Validation loss: 1.6343421013124528

Epoch: 5| Step: 7
Training loss: 0.42235714197158813
Validation loss: 1.682688884837653

Epoch: 5| Step: 8
Training loss: 0.4016435742378235
Validation loss: 1.6628129507905693

Epoch: 5| Step: 9
Training loss: 0.4925493597984314
Validation loss: 1.671630919620555

Epoch: 5| Step: 10
Training loss: 0.5352644920349121
Validation loss: 1.6608520682140062

Epoch: 358| Step: 0
Training loss: 0.5105463266372681
Validation loss: 1.6677028107386764

Epoch: 5| Step: 1
Training loss: 0.3807888627052307
Validation loss: 1.6520354183771278

Epoch: 5| Step: 2
Training loss: 0.40057238936424255
Validation loss: 1.6998134492546

Epoch: 5| Step: 3
Training loss: 0.6524708867073059
Validation loss: 1.6914891440381286

Epoch: 5| Step: 4
Training loss: 0.5547488927841187
Validation loss: 1.6837903709821804

Epoch: 5| Step: 5
Training loss: 0.4170261025428772
Validation loss: 1.6961722502144434

Epoch: 5| Step: 6
Training loss: 0.53828364610672
Validation loss: 1.713311565819607

Epoch: 5| Step: 7
Training loss: 0.1598266065120697
Validation loss: 1.723085912325049

Epoch: 5| Step: 8
Training loss: 0.30323439836502075
Validation loss: 1.7023700821784236

Epoch: 5| Step: 9
Training loss: 0.378398060798645
Validation loss: 1.7167137066523235

Epoch: 5| Step: 10
Training loss: 0.5644614696502686
Validation loss: 1.6994164900113178

Epoch: 359| Step: 0
Training loss: 0.47779059410095215
Validation loss: 1.6976159208564348

Epoch: 5| Step: 1
Training loss: 0.44856777787208557
Validation loss: 1.6803366676453622

Epoch: 5| Step: 2
Training loss: 0.19577503204345703
Validation loss: 1.6878312569792553

Epoch: 5| Step: 3
Training loss: 0.5023216605186462
Validation loss: 1.668938862380161

Epoch: 5| Step: 4
Training loss: 0.42826899886131287
Validation loss: 1.6943899354627054

Epoch: 5| Step: 5
Training loss: 0.7632107734680176
Validation loss: 1.6803588008367887

Epoch: 5| Step: 6
Training loss: 0.3144480586051941
Validation loss: 1.6755263779752998

Epoch: 5| Step: 7
Training loss: 0.2574777901172638
Validation loss: 1.6486922399972075

Epoch: 5| Step: 8
Training loss: 0.5245678424835205
Validation loss: 1.6176596636413245

Epoch: 5| Step: 9
Training loss: 0.4574165344238281
Validation loss: 1.6295877900174869

Epoch: 5| Step: 10
Training loss: 0.4930594861507416
Validation loss: 1.6371713915178854

Epoch: 360| Step: 0
Training loss: 0.37882086634635925
Validation loss: 1.6384596350372478

Epoch: 5| Step: 1
Training loss: 0.29464730620384216
Validation loss: 1.6320627979052964

Epoch: 5| Step: 2
Training loss: 0.25675511360168457
Validation loss: 1.6937746732465682

Epoch: 5| Step: 3
Training loss: 0.5059065818786621
Validation loss: 1.6445676818970711

Epoch: 5| Step: 4
Training loss: 0.6034082174301147
Validation loss: 1.68852101731044

Epoch: 5| Step: 5
Training loss: 0.620502233505249
Validation loss: 1.6642549550661476

Epoch: 5| Step: 6
Training loss: 0.42798590660095215
Validation loss: 1.6610273571424587

Epoch: 5| Step: 7
Training loss: 0.25502362847328186
Validation loss: 1.668621684915276

Epoch: 5| Step: 8
Training loss: 0.41161832213401794
Validation loss: 1.670367249878504

Epoch: 5| Step: 9
Training loss: 0.5893467664718628
Validation loss: 1.6628767918514948

Epoch: 5| Step: 10
Training loss: 0.3651990592479706
Validation loss: 1.645858992812454

Epoch: 361| Step: 0
Training loss: 0.4401935935020447
Validation loss: 1.6811455635614292

Epoch: 5| Step: 1
Training loss: 0.46900567412376404
Validation loss: 1.6517850557963054

Epoch: 5| Step: 2
Training loss: 0.5386008024215698
Validation loss: 1.6468184955658451

Epoch: 5| Step: 3
Training loss: 0.3436657786369324
Validation loss: 1.6555697648755965

Epoch: 5| Step: 4
Training loss: 0.5113760232925415
Validation loss: 1.6995544305411718

Epoch: 5| Step: 5
Training loss: 0.4210028052330017
Validation loss: 1.7160955846950572

Epoch: 5| Step: 6
Training loss: 0.5290156602859497
Validation loss: 1.6907670702985538

Epoch: 5| Step: 7
Training loss: 0.23836493492126465
Validation loss: 1.6782340580417263

Epoch: 5| Step: 8
Training loss: 0.5245535969734192
Validation loss: 1.653784595510011

Epoch: 5| Step: 9
Training loss: 0.5332980155944824
Validation loss: 1.635431472973157

Epoch: 5| Step: 10
Training loss: 0.23098193109035492
Validation loss: 1.6244504849116008

Epoch: 362| Step: 0
Training loss: 0.5003236532211304
Validation loss: 1.6270825593702254

Epoch: 5| Step: 1
Training loss: 0.30330175161361694
Validation loss: 1.6256597759903118

Epoch: 5| Step: 2
Training loss: 0.40251684188842773
Validation loss: 1.623870256767478

Epoch: 5| Step: 3
Training loss: 0.29283246397972107
Validation loss: 1.6460981112654491

Epoch: 5| Step: 4
Training loss: 0.5568920373916626
Validation loss: 1.609952857417445

Epoch: 5| Step: 5
Training loss: 0.3337758183479309
Validation loss: 1.629846196020803

Epoch: 5| Step: 6
Training loss: 0.47822314500808716
Validation loss: 1.6141716023927093

Epoch: 5| Step: 7
Training loss: 0.4982872009277344
Validation loss: 1.666093840393969

Epoch: 5| Step: 8
Training loss: 0.23702016472816467
Validation loss: 1.6832861631147322

Epoch: 5| Step: 9
Training loss: 0.5441198348999023
Validation loss: 1.688120134415165

Epoch: 5| Step: 10
Training loss: 0.4722323715686798
Validation loss: 1.6996688458227343

Epoch: 363| Step: 0
Training loss: 0.42684489488601685
Validation loss: 1.7039561284485685

Epoch: 5| Step: 1
Training loss: 0.32727256417274475
Validation loss: 1.7204500987965574

Epoch: 5| Step: 2
Training loss: 0.4512940049171448
Validation loss: 1.680034178559498

Epoch: 5| Step: 3
Training loss: 0.422614187002182
Validation loss: 1.6818351745605469

Epoch: 5| Step: 4
Training loss: 0.5437934994697571
Validation loss: 1.671085798612205

Epoch: 5| Step: 5
Training loss: 0.179397314786911
Validation loss: 1.7088325703015892

Epoch: 5| Step: 6
Training loss: 0.37914618849754333
Validation loss: 1.662057786859492

Epoch: 5| Step: 7
Training loss: 0.5194922685623169
Validation loss: 1.689945779820924

Epoch: 5| Step: 8
Training loss: 0.19466952979564667
Validation loss: 1.6431746803304201

Epoch: 5| Step: 9
Training loss: 0.4842170774936676
Validation loss: 1.625702928471309

Epoch: 5| Step: 10
Training loss: 0.6700568795204163
Validation loss: 1.6010048017706922

Epoch: 364| Step: 0
Training loss: 0.25392070412635803
Validation loss: 1.5873108217793126

Epoch: 5| Step: 1
Training loss: 0.4502878189086914
Validation loss: 1.5765537023544312

Epoch: 5| Step: 2
Training loss: 0.4994816780090332
Validation loss: 1.606020914610996

Epoch: 5| Step: 3
Training loss: 0.4848558008670807
Validation loss: 1.5862908632524553

Epoch: 5| Step: 4
Training loss: 0.5592379570007324
Validation loss: 1.593594886923349

Epoch: 5| Step: 5
Training loss: 0.24983835220336914
Validation loss: 1.5856724041764454

Epoch: 5| Step: 6
Training loss: 0.3358905613422394
Validation loss: 1.5490805987388856

Epoch: 5| Step: 7
Training loss: 0.3321884274482727
Validation loss: 1.5850871019465949

Epoch: 5| Step: 8
Training loss: 0.637842059135437
Validation loss: 1.582431213830107

Epoch: 5| Step: 9
Training loss: 0.31126904487609863
Validation loss: 1.5606713679529005

Epoch: 5| Step: 10
Training loss: 0.2949914038181305
Validation loss: 1.612500854717788

Epoch: 365| Step: 0
Training loss: 0.3774372935295105
Validation loss: 1.5692956601419756

Epoch: 5| Step: 1
Training loss: 0.32336410880088806
Validation loss: 1.5608713549952353

Epoch: 5| Step: 2
Training loss: 0.45708662271499634
Validation loss: 1.5886466157051824

Epoch: 5| Step: 3
Training loss: 0.3416973948478699
Validation loss: 1.6095618842750468

Epoch: 5| Step: 4
Training loss: 0.20482876896858215
Validation loss: 1.6069453788060013

Epoch: 5| Step: 5
Training loss: 0.41684389114379883
Validation loss: 1.6296543062374156

Epoch: 5| Step: 6
Training loss: 0.37227508425712585
Validation loss: 1.6448197826262443

Epoch: 5| Step: 7
Training loss: 0.3510659337043762
Validation loss: 1.6729971375516666

Epoch: 5| Step: 8
Training loss: 0.7531090974807739
Validation loss: 1.6395361397856025

Epoch: 5| Step: 9
Training loss: 0.39002978801727295
Validation loss: 1.6215906059870155

Epoch: 5| Step: 10
Training loss: 0.44550085067749023
Validation loss: 1.6477083544577322

Epoch: 366| Step: 0
Training loss: 0.33531084656715393
Validation loss: 1.6233568665801839

Epoch: 5| Step: 1
Training loss: 0.4188191890716553
Validation loss: 1.644951916510059

Epoch: 5| Step: 2
Training loss: 0.6327848434448242
Validation loss: 1.6464335469789402

Epoch: 5| Step: 3
Training loss: 0.6361344456672668
Validation loss: 1.6335572145318473

Epoch: 5| Step: 4
Training loss: 0.38670778274536133
Validation loss: 1.6287288999044767

Epoch: 5| Step: 5
Training loss: 0.32336655259132385
Validation loss: 1.6422546166245655

Epoch: 5| Step: 6
Training loss: 0.46449679136276245
Validation loss: 1.6705603240638651

Epoch: 5| Step: 7
Training loss: 0.5683906674385071
Validation loss: 1.6978302207044376

Epoch: 5| Step: 8
Training loss: 0.197361022233963
Validation loss: 1.68059794492619

Epoch: 5| Step: 9
Training loss: 0.44844573736190796
Validation loss: 1.6704718669255574

Epoch: 5| Step: 10
Training loss: 0.15640971064567566
Validation loss: 1.633847455824575

Epoch: 367| Step: 0
Training loss: 0.2719268798828125
Validation loss: 1.597198381218859

Epoch: 5| Step: 1
Training loss: 0.423562228679657
Validation loss: 1.571516162605696

Epoch: 5| Step: 2
Training loss: 0.3178870677947998
Validation loss: 1.5867359138304187

Epoch: 5| Step: 3
Training loss: 0.5092126131057739
Validation loss: 1.5948926876950007

Epoch: 5| Step: 4
Training loss: 0.5282052755355835
Validation loss: 1.5993858152820217

Epoch: 5| Step: 5
Training loss: 0.3826681077480316
Validation loss: 1.6064940793539888

Epoch: 5| Step: 6
Training loss: 0.24359074234962463
Validation loss: 1.6559657640354608

Epoch: 5| Step: 7
Training loss: 0.43106478452682495
Validation loss: 1.6416846218929495

Epoch: 5| Step: 8
Training loss: 0.303577184677124
Validation loss: 1.69803862930626

Epoch: 5| Step: 9
Training loss: 0.45998963713645935
Validation loss: 1.6716789481460408

Epoch: 5| Step: 10
Training loss: 0.6432315111160278
Validation loss: 1.7001089613924745

Epoch: 368| Step: 0
Training loss: 0.45928293466567993
Validation loss: 1.6570728799348236

Epoch: 5| Step: 1
Training loss: 0.30797746777534485
Validation loss: 1.603170080851483

Epoch: 5| Step: 2
Training loss: 0.4217950701713562
Validation loss: 1.56578101265815

Epoch: 5| Step: 3
Training loss: 0.4135932922363281
Validation loss: 1.5707257524613412

Epoch: 5| Step: 4
Training loss: 0.5850575566291809
Validation loss: 1.594478758432532

Epoch: 5| Step: 5
Training loss: 0.6023600101470947
Validation loss: 1.5633537846226846

Epoch: 5| Step: 6
Training loss: 0.24852032959461212
Validation loss: 1.6252422999310236

Epoch: 5| Step: 7
Training loss: 0.3904007375240326
Validation loss: 1.6355729128724785

Epoch: 5| Step: 8
Training loss: 0.3910636007785797
Validation loss: 1.6425254601304249

Epoch: 5| Step: 9
Training loss: 0.42091184854507446
Validation loss: 1.6726005384998937

Epoch: 5| Step: 10
Training loss: 0.3103318214416504
Validation loss: 1.7019425169114144

Epoch: 369| Step: 0
Training loss: 0.4045446515083313
Validation loss: 1.6682812398479832

Epoch: 5| Step: 1
Training loss: 0.41102248430252075
Validation loss: 1.6850129289011802

Epoch: 5| Step: 2
Training loss: 0.5003345608711243
Validation loss: 1.65836246936552

Epoch: 5| Step: 3
Training loss: 0.29899072647094727
Validation loss: 1.6754744693797121

Epoch: 5| Step: 4
Training loss: 0.45266109704971313
Validation loss: 1.677891562061925

Epoch: 5| Step: 5
Training loss: 0.38429805636405945
Validation loss: 1.7128859181557932

Epoch: 5| Step: 6
Training loss: 0.4019346833229065
Validation loss: 1.6605436340455086

Epoch: 5| Step: 7
Training loss: 0.33861032128334045
Validation loss: 1.659864039831264

Epoch: 5| Step: 8
Training loss: 0.375041127204895
Validation loss: 1.6637211409948205

Epoch: 5| Step: 9
Training loss: 0.39288249611854553
Validation loss: 1.6498156286055041

Epoch: 5| Step: 10
Training loss: 0.3708341121673584
Validation loss: 1.6322804368952268

Epoch: 370| Step: 0
Training loss: 0.33785146474838257
Validation loss: 1.6405018914130427

Epoch: 5| Step: 1
Training loss: 0.3230976462364197
Validation loss: 1.6527459653474952

Epoch: 5| Step: 2
Training loss: 0.6880550384521484
Validation loss: 1.6581568615410918

Epoch: 5| Step: 3
Training loss: 0.30566757917404175
Validation loss: 1.6476396963160524

Epoch: 5| Step: 4
Training loss: 0.5031442046165466
Validation loss: 1.6558246304911952

Epoch: 5| Step: 5
Training loss: 0.35943904519081116
Validation loss: 1.6122677992748957

Epoch: 5| Step: 6
Training loss: 0.3266654908657074
Validation loss: 1.6411616045941588

Epoch: 5| Step: 7
Training loss: 0.3691709339618683
Validation loss: 1.6584371187353646

Epoch: 5| Step: 8
Training loss: 0.25196975469589233
Validation loss: 1.6776109895398539

Epoch: 5| Step: 9
Training loss: 0.394369512796402
Validation loss: 1.7141223466524513

Epoch: 5| Step: 10
Training loss: 0.5497443079948425
Validation loss: 1.7482369586985598

Epoch: 371| Step: 0
Training loss: 0.7349935173988342
Validation loss: 1.7889673440687117

Epoch: 5| Step: 1
Training loss: 0.38078588247299194
Validation loss: 1.7623705492224744

Epoch: 5| Step: 2
Training loss: 0.26074832677841187
Validation loss: 1.7588428669078375

Epoch: 5| Step: 3
Training loss: 0.44253331422805786
Validation loss: 1.738051575358196

Epoch: 5| Step: 4
Training loss: 0.41600728034973145
Validation loss: 1.7323472038392098

Epoch: 5| Step: 5
Training loss: 0.4103856086730957
Validation loss: 1.691049059232076

Epoch: 5| Step: 6
Training loss: 0.49186402559280396
Validation loss: 1.6723968431513796

Epoch: 5| Step: 7
Training loss: 0.18088696897029877
Validation loss: 1.6378664214123961

Epoch: 5| Step: 8
Training loss: 0.3899523615837097
Validation loss: 1.6038616152219876

Epoch: 5| Step: 9
Training loss: 0.4517896771430969
Validation loss: 1.5972607545955206

Epoch: 5| Step: 10
Training loss: 0.3948216438293457
Validation loss: 1.5950825598932081

Epoch: 372| Step: 0
Training loss: 0.580278754234314
Validation loss: 1.6022155246426981

Epoch: 5| Step: 1
Training loss: 0.4468371272087097
Validation loss: 1.6685386139859435

Epoch: 5| Step: 2
Training loss: 0.3790021538734436
Validation loss: 1.6428526332301479

Epoch: 5| Step: 3
Training loss: 0.308917760848999
Validation loss: 1.6672662253020911

Epoch: 5| Step: 4
Training loss: 0.6164959669113159
Validation loss: 1.7019902044726956

Epoch: 5| Step: 5
Training loss: 0.21558794379234314
Validation loss: 1.6899533887063303

Epoch: 5| Step: 6
Training loss: 0.4210544526576996
Validation loss: 1.6827445337849278

Epoch: 5| Step: 7
Training loss: 0.44222956895828247
Validation loss: 1.6663079800144318

Epoch: 5| Step: 8
Training loss: 0.29105958342552185
Validation loss: 1.6546197411834553

Epoch: 5| Step: 9
Training loss: 0.4623386859893799
Validation loss: 1.6350796709778488

Epoch: 5| Step: 10
Training loss: 0.3203495740890503
Validation loss: 1.679772553905364

Epoch: 373| Step: 0
Training loss: 0.5868666768074036
Validation loss: 1.6982205606275989

Epoch: 5| Step: 1
Training loss: 0.5078092813491821
Validation loss: 1.695981070559512

Epoch: 5| Step: 2
Training loss: 0.38314443826675415
Validation loss: 1.6944022986196703

Epoch: 5| Step: 3
Training loss: 0.4805905222892761
Validation loss: 1.6565553501088133

Epoch: 5| Step: 4
Training loss: 0.26388585567474365
Validation loss: 1.6886528691937845

Epoch: 5| Step: 5
Training loss: 0.5954717397689819
Validation loss: 1.6569850451202803

Epoch: 5| Step: 6
Training loss: 0.3560783863067627
Validation loss: 1.6508443925970344

Epoch: 5| Step: 7
Training loss: 0.37471505999565125
Validation loss: 1.6859271500700264

Epoch: 5| Step: 8
Training loss: 0.2565491199493408
Validation loss: 1.6660713329110095

Epoch: 5| Step: 9
Training loss: 0.45674562454223633
Validation loss: 1.6776540279388428

Epoch: 5| Step: 10
Training loss: 0.4051373302936554
Validation loss: 1.6920019144652991

Epoch: 374| Step: 0
Training loss: 0.49192094802856445
Validation loss: 1.708267823342354

Epoch: 5| Step: 1
Training loss: 0.49059543013572693
Validation loss: 1.7386051788124988

Epoch: 5| Step: 2
Training loss: 0.3747386932373047
Validation loss: 1.7675942643996208

Epoch: 5| Step: 3
Training loss: 0.3904825747013092
Validation loss: 1.7425858307910222

Epoch: 5| Step: 4
Training loss: 0.3817247748374939
Validation loss: 1.69090102564904

Epoch: 5| Step: 5
Training loss: 0.3151816725730896
Validation loss: 1.6352662655615038

Epoch: 5| Step: 6
Training loss: 0.39529091119766235
Validation loss: 1.6316351736745527

Epoch: 5| Step: 7
Training loss: 0.37688180804252625
Validation loss: 1.6287771296757523

Epoch: 5| Step: 8
Training loss: 0.43211841583251953
Validation loss: 1.616355978032594

Epoch: 5| Step: 9
Training loss: 0.6490353345870972
Validation loss: 1.6795368220216484

Epoch: 5| Step: 10
Training loss: 0.5213857293128967
Validation loss: 1.6570911997108049

Epoch: 375| Step: 0
Training loss: 0.2707183361053467
Validation loss: 1.653382726894912

Epoch: 5| Step: 1
Training loss: 0.3008604645729065
Validation loss: 1.6980808486220658

Epoch: 5| Step: 2
Training loss: 0.32956522703170776
Validation loss: 1.742024875456287

Epoch: 5| Step: 3
Training loss: 0.4101681709289551
Validation loss: 1.734967541951005

Epoch: 5| Step: 4
Training loss: 0.4607819616794586
Validation loss: 1.679736683445592

Epoch: 5| Step: 5
Training loss: 0.3907202184200287
Validation loss: 1.6371139505858063

Epoch: 5| Step: 6
Training loss: 0.4812278747558594
Validation loss: 1.591474340808007

Epoch: 5| Step: 7
Training loss: 0.5014141201972961
Validation loss: 1.5735431986470376

Epoch: 5| Step: 8
Training loss: 0.48224061727523804
Validation loss: 1.562087410239763

Epoch: 5| Step: 9
Training loss: 0.4004502296447754
Validation loss: 1.5572376943403674

Epoch: 5| Step: 10
Training loss: 0.48968881368637085
Validation loss: 1.5614629125082364

Epoch: 376| Step: 0
Training loss: 0.36324846744537354
Validation loss: 1.5535359344174784

Epoch: 5| Step: 1
Training loss: 0.28069573640823364
Validation loss: 1.6008901185886835

Epoch: 5| Step: 2
Training loss: 0.3497540354728699
Validation loss: 1.6060982929762972

Epoch: 5| Step: 3
Training loss: 0.4930421710014343
Validation loss: 1.6712470349445139

Epoch: 5| Step: 4
Training loss: 0.30350980162620544
Validation loss: 1.6819812136311685

Epoch: 5| Step: 5
Training loss: 0.4305668771266937
Validation loss: 1.6760743330883723

Epoch: 5| Step: 6
Training loss: 0.2293684482574463
Validation loss: 1.6728095790391326

Epoch: 5| Step: 7
Training loss: 0.3209295868873596
Validation loss: 1.6687578770422167

Epoch: 5| Step: 8
Training loss: 0.4625684320926666
Validation loss: 1.642701022086605

Epoch: 5| Step: 9
Training loss: 0.43669193983078003
Validation loss: 1.6481691944983698

Epoch: 5| Step: 10
Training loss: 0.6978802680969238
Validation loss: 1.6429606829920123

Epoch: 377| Step: 0
Training loss: 0.3250870704650879
Validation loss: 1.6384601067471247

Epoch: 5| Step: 1
Training loss: 0.5325449705123901
Validation loss: 1.6295522477037163

Epoch: 5| Step: 2
Training loss: 0.3319603502750397
Validation loss: 1.6589248911026986

Epoch: 5| Step: 3
Training loss: 0.2761915624141693
Validation loss: 1.6483612188728907

Epoch: 5| Step: 4
Training loss: 0.4611886441707611
Validation loss: 1.6284328135111

Epoch: 5| Step: 5
Training loss: 0.5794404745101929
Validation loss: 1.6139692824373963

Epoch: 5| Step: 6
Training loss: 0.34696853160858154
Validation loss: 1.6344816902632355

Epoch: 5| Step: 7
Training loss: 0.3256479799747467
Validation loss: 1.637430150021789

Epoch: 5| Step: 8
Training loss: 0.26962417364120483
Validation loss: 1.6303725588706233

Epoch: 5| Step: 9
Training loss: 0.33478084206581116
Validation loss: 1.668641374957177

Epoch: 5| Step: 10
Training loss: 0.42327964305877686
Validation loss: 1.6883880015342467

Epoch: 378| Step: 0
Training loss: 0.3137059211730957
Validation loss: 1.7103406690782117

Epoch: 5| Step: 1
Training loss: 0.5069642066955566
Validation loss: 1.7146709644666283

Epoch: 5| Step: 2
Training loss: 0.6427829265594482
Validation loss: 1.6936910934345697

Epoch: 5| Step: 3
Training loss: 0.4407840371131897
Validation loss: 1.697903965109138

Epoch: 5| Step: 4
Training loss: 0.4715004861354828
Validation loss: 1.6624965513906171

Epoch: 5| Step: 5
Training loss: 0.3073011636734009
Validation loss: 1.606831701852942

Epoch: 5| Step: 6
Training loss: 0.33755144476890564
Validation loss: 1.6208188867056241

Epoch: 5| Step: 7
Training loss: 0.36356058716773987
Validation loss: 1.5889020389126194

Epoch: 5| Step: 8
Training loss: 0.2580762207508087
Validation loss: 1.6425234848453152

Epoch: 5| Step: 9
Training loss: 0.26073870062828064
Validation loss: 1.6106103850949196

Epoch: 5| Step: 10
Training loss: 0.3488553762435913
Validation loss: 1.6468710155897244

Epoch: 379| Step: 0
Training loss: 0.245757058262825
Validation loss: 1.6567636330922444

Epoch: 5| Step: 1
Training loss: 0.2665446102619171
Validation loss: 1.695678908337829

Epoch: 5| Step: 2
Training loss: 0.47595691680908203
Validation loss: 1.7212946555947746

Epoch: 5| Step: 3
Training loss: 0.27268123626708984
Validation loss: 1.7076734650519587

Epoch: 5| Step: 4
Training loss: 0.24615755677223206
Validation loss: 1.6867261958378617

Epoch: 5| Step: 5
Training loss: 0.6114073395729065
Validation loss: 1.6682688113181823

Epoch: 5| Step: 6
Training loss: 0.5216933488845825
Validation loss: 1.6756518348570792

Epoch: 5| Step: 7
Training loss: 0.5557918548583984
Validation loss: 1.6086031788138933

Epoch: 5| Step: 8
Training loss: 0.4297500252723694
Validation loss: 1.5935822981660084

Epoch: 5| Step: 9
Training loss: 0.4448321461677551
Validation loss: 1.585791052028697

Epoch: 5| Step: 10
Training loss: 0.38741669058799744
Validation loss: 1.590929131354055

Epoch: 380| Step: 0
Training loss: 0.33667629957199097
Validation loss: 1.6269632449714087

Epoch: 5| Step: 1
Training loss: 0.3499707579612732
Validation loss: 1.6335745678153089

Epoch: 5| Step: 2
Training loss: 0.32942068576812744
Validation loss: 1.6963290347847888

Epoch: 5| Step: 3
Training loss: 0.41217952966690063
Validation loss: 1.713525475994233

Epoch: 5| Step: 4
Training loss: 0.45497092604637146
Validation loss: 1.7215300183142386

Epoch: 5| Step: 5
Training loss: 0.5530083775520325
Validation loss: 1.685379805103425

Epoch: 5| Step: 6
Training loss: 0.27060872316360474
Validation loss: 1.6938538628239785

Epoch: 5| Step: 7
Training loss: 0.4820586144924164
Validation loss: 1.6496070508033998

Epoch: 5| Step: 8
Training loss: 0.3938215970993042
Validation loss: 1.6832562351739535

Epoch: 5| Step: 9
Training loss: 0.445437490940094
Validation loss: 1.6917675669475267

Epoch: 5| Step: 10
Training loss: 0.3116415739059448
Validation loss: 1.6794224336583128

Epoch: 381| Step: 0
Training loss: 0.3262980878353119
Validation loss: 1.6918347612504037

Epoch: 5| Step: 1
Training loss: 0.21992227435112
Validation loss: 1.6693069960481377

Epoch: 5| Step: 2
Training loss: 0.3965817093849182
Validation loss: 1.701154399943608

Epoch: 5| Step: 3
Training loss: 0.3886714577674866
Validation loss: 1.6318087821365685

Epoch: 5| Step: 4
Training loss: 0.23595936596393585
Validation loss: 1.6632716476276357

Epoch: 5| Step: 5
Training loss: 0.692132294178009
Validation loss: 1.5997661288066576

Epoch: 5| Step: 6
Training loss: 0.25396528840065
Validation loss: 1.617925505484304

Epoch: 5| Step: 7
Training loss: 0.37267085909843445
Validation loss: 1.6080928380771349

Epoch: 5| Step: 8
Training loss: 0.4586615562438965
Validation loss: 1.5988226449617775

Epoch: 5| Step: 9
Training loss: 0.24632136523723602
Validation loss: 1.6481929081742481

Epoch: 5| Step: 10
Training loss: 0.1546992063522339
Validation loss: 1.6535938901285971

Epoch: 382| Step: 0
Training loss: 0.6489014625549316
Validation loss: 1.685799350020706

Epoch: 5| Step: 1
Training loss: 0.42152899503707886
Validation loss: 1.688744620610309

Epoch: 5| Step: 2
Training loss: 0.30742114782333374
Validation loss: 1.7061004689944688

Epoch: 5| Step: 3
Training loss: 0.3674914240837097
Validation loss: 1.6790404204399354

Epoch: 5| Step: 4
Training loss: 0.3747160732746124
Validation loss: 1.660050489569223

Epoch: 5| Step: 5
Training loss: 0.345588743686676
Validation loss: 1.655179205761161

Epoch: 5| Step: 6
Training loss: 0.30483099818229675
Validation loss: 1.6397969363838114

Epoch: 5| Step: 7
Training loss: 0.38652610778808594
Validation loss: 1.6366951824516378

Epoch: 5| Step: 8
Training loss: 0.2660079300403595
Validation loss: 1.6145109797036776

Epoch: 5| Step: 9
Training loss: 0.17103683948516846
Validation loss: 1.6436669134324597

Epoch: 5| Step: 10
Training loss: 0.3067858815193176
Validation loss: 1.6225612458362375

Epoch: 383| Step: 0
Training loss: 0.5442144274711609
Validation loss: 1.6089363803145706

Epoch: 5| Step: 1
Training loss: 0.24841400980949402
Validation loss: 1.650432651401848

Epoch: 5| Step: 2
Training loss: 0.2136811465024948
Validation loss: 1.6538273826722176

Epoch: 5| Step: 3
Training loss: 0.2147536724805832
Validation loss: 1.6492782703009985

Epoch: 5| Step: 4
Training loss: 0.309725284576416
Validation loss: 1.644703088268157

Epoch: 5| Step: 5
Training loss: 0.3863973617553711
Validation loss: 1.665753229971855

Epoch: 5| Step: 6
Training loss: 0.5258349180221558
Validation loss: 1.6622281215524162

Epoch: 5| Step: 7
Training loss: 0.1537850946187973
Validation loss: 1.6557047264550322

Epoch: 5| Step: 8
Training loss: 0.3184428811073303
Validation loss: 1.6646585118386052

Epoch: 5| Step: 9
Training loss: 0.5235109329223633
Validation loss: 1.5928571224212646

Epoch: 5| Step: 10
Training loss: 0.39203786849975586
Validation loss: 1.5740624115031252

Epoch: 384| Step: 0
Training loss: 0.24192920327186584
Validation loss: 1.5997862828675138

Epoch: 5| Step: 1
Training loss: 0.35147759318351746
Validation loss: 1.584307038655845

Epoch: 5| Step: 2
Training loss: 0.39872345328330994
Validation loss: 1.5923402155599287

Epoch: 5| Step: 3
Training loss: 0.3755676746368408
Validation loss: 1.5666621987537672

Epoch: 5| Step: 4
Training loss: 0.31832587718963623
Validation loss: 1.6049054322704193

Epoch: 5| Step: 5
Training loss: 0.2559620440006256
Validation loss: 1.570977367380614

Epoch: 5| Step: 6
Training loss: 0.5417418479919434
Validation loss: 1.6108106708013883

Epoch: 5| Step: 7
Training loss: 0.38389459252357483
Validation loss: 1.5959686886879705

Epoch: 5| Step: 8
Training loss: 0.39876145124435425
Validation loss: 1.5950546533830705

Epoch: 5| Step: 9
Training loss: 0.3009629547595978
Validation loss: 1.658989837092738

Epoch: 5| Step: 10
Training loss: 0.35409364104270935
Validation loss: 1.6819873368868263

Epoch: 385| Step: 0
Training loss: 0.3274818956851959
Validation loss: 1.675715931000248

Epoch: 5| Step: 1
Training loss: 0.35813969373703003
Validation loss: 1.6134105600336546

Epoch: 5| Step: 2
Training loss: 0.3061693608760834
Validation loss: 1.6566217560921945

Epoch: 5| Step: 3
Training loss: 0.3489932715892792
Validation loss: 1.6225900060387068

Epoch: 5| Step: 4
Training loss: 0.14424702525138855
Validation loss: 1.6654650549734793

Epoch: 5| Step: 5
Training loss: 0.29633691906929016
Validation loss: 1.6892250635290658

Epoch: 5| Step: 6
Training loss: 0.4746730327606201
Validation loss: 1.6944335942627282

Epoch: 5| Step: 7
Training loss: 0.4707697927951813
Validation loss: 1.6666785568319342

Epoch: 5| Step: 8
Training loss: 0.5829727649688721
Validation loss: 1.6274475102783532

Epoch: 5| Step: 9
Training loss: 0.3117835521697998
Validation loss: 1.608217530353095

Epoch: 5| Step: 10
Training loss: 0.391382098197937
Validation loss: 1.5855926031707435

Epoch: 386| Step: 0
Training loss: 0.3803827166557312
Validation loss: 1.608574354520408

Epoch: 5| Step: 1
Training loss: 0.34020185470581055
Validation loss: 1.5897044763770154

Epoch: 5| Step: 2
Training loss: 0.48859459161758423
Validation loss: 1.6420943275574715

Epoch: 5| Step: 3
Training loss: 0.4720073640346527
Validation loss: 1.6667301449724423

Epoch: 5| Step: 4
Training loss: 0.2223617136478424
Validation loss: 1.7016786798354118

Epoch: 5| Step: 5
Training loss: 0.3356218934059143
Validation loss: 1.7165152360034246

Epoch: 5| Step: 6
Training loss: 0.1688743531703949
Validation loss: 1.6747772283451532

Epoch: 5| Step: 7
Training loss: 0.41059017181396484
Validation loss: 1.6870026396166893

Epoch: 5| Step: 8
Training loss: 0.4416438043117523
Validation loss: 1.6472301034517185

Epoch: 5| Step: 9
Training loss: 0.3498319089412689
Validation loss: 1.617829167714683

Epoch: 5| Step: 10
Training loss: 0.3499552607536316
Validation loss: 1.622900870538527

Epoch: 387| Step: 0
Training loss: 0.23347941040992737
Validation loss: 1.5984546087121452

Epoch: 5| Step: 1
Training loss: 0.2705494463443756
Validation loss: 1.61320395751666

Epoch: 5| Step: 2
Training loss: 0.48954883217811584
Validation loss: 1.6599803586159982

Epoch: 5| Step: 3
Training loss: 0.4505147933959961
Validation loss: 1.7281752004418323

Epoch: 5| Step: 4
Training loss: 0.33387747406959534
Validation loss: 1.727302050077787

Epoch: 5| Step: 5
Training loss: 0.5145641565322876
Validation loss: 1.7389410900813278

Epoch: 5| Step: 6
Training loss: 0.4334748685359955
Validation loss: 1.7225329542672763

Epoch: 5| Step: 7
Training loss: 0.279874712228775
Validation loss: 1.6988780613868468

Epoch: 5| Step: 8
Training loss: 0.39214152097702026
Validation loss: 1.6736368979177167

Epoch: 5| Step: 9
Training loss: 0.13057133555412292
Validation loss: 1.6115964933108258

Epoch: 5| Step: 10
Training loss: 0.40323182940483093
Validation loss: 1.575352063743017

Epoch: 388| Step: 0
Training loss: 0.5126829147338867
Validation loss: 1.5883902977871638

Epoch: 5| Step: 1
Training loss: 0.4443468153476715
Validation loss: 1.5632224749493342

Epoch: 5| Step: 2
Training loss: 0.25416359305381775
Validation loss: 1.5815604861064623

Epoch: 5| Step: 3
Training loss: 0.32808756828308105
Validation loss: 1.5866712254862632

Epoch: 5| Step: 4
Training loss: 0.29256853461265564
Validation loss: 1.5718002152699295

Epoch: 5| Step: 5
Training loss: 0.37871330976486206
Validation loss: 1.6204576261581913

Epoch: 5| Step: 6
Training loss: 0.2735792100429535
Validation loss: 1.6324727830066477

Epoch: 5| Step: 7
Training loss: 0.2990477979183197
Validation loss: 1.634665593024223

Epoch: 5| Step: 8
Training loss: 0.37804466485977173
Validation loss: 1.6787721764656804

Epoch: 5| Step: 9
Training loss: 0.4044681191444397
Validation loss: 1.679722571885714

Epoch: 5| Step: 10
Training loss: 0.2523943781852722
Validation loss: 1.6106414384739374

Epoch: 389| Step: 0
Training loss: 0.25933536887168884
Validation loss: 1.565174723184237

Epoch: 5| Step: 1
Training loss: 0.35862234234809875
Validation loss: 1.5467375222072806

Epoch: 5| Step: 2
Training loss: 0.3204452097415924
Validation loss: 1.5289089269535516

Epoch: 5| Step: 3
Training loss: 0.35190948843955994
Validation loss: 1.565916452356564

Epoch: 5| Step: 4
Training loss: 0.31207817792892456
Validation loss: 1.5437355169685938

Epoch: 5| Step: 5
Training loss: 0.4008566737174988
Validation loss: 1.5576113013811008

Epoch: 5| Step: 6
Training loss: 0.29968222975730896
Validation loss: 1.591969149087065

Epoch: 5| Step: 7
Training loss: 0.3988038897514343
Validation loss: 1.5780538730723883

Epoch: 5| Step: 8
Training loss: 0.5147340893745422
Validation loss: 1.6085894441091886

Epoch: 5| Step: 9
Training loss: 0.3001730442047119
Validation loss: 1.6358454458175167

Epoch: 5| Step: 10
Training loss: 0.43329569697380066
Validation loss: 1.6362394312376618

Epoch: 390| Step: 0
Training loss: 0.1918419897556305
Validation loss: 1.6398942509005148

Epoch: 5| Step: 1
Training loss: 0.3728225827217102
Validation loss: 1.6403139034907024

Epoch: 5| Step: 2
Training loss: 0.3540376126766205
Validation loss: 1.6261637005754697

Epoch: 5| Step: 3
Training loss: 0.3830457329750061
Validation loss: 1.5968220221099032

Epoch: 5| Step: 4
Training loss: 0.4915462136268616
Validation loss: 1.5873349417922318

Epoch: 5| Step: 5
Training loss: 0.28412777185440063
Validation loss: 1.5866526865190076

Epoch: 5| Step: 6
Training loss: 0.47479113936424255
Validation loss: 1.6300131300444245

Epoch: 5| Step: 7
Training loss: 0.17537924647331238
Validation loss: 1.6257698356464345

Epoch: 5| Step: 8
Training loss: 0.23381972312927246
Validation loss: 1.6383888439465595

Epoch: 5| Step: 9
Training loss: 0.2902962863445282
Validation loss: 1.643342996156344

Epoch: 5| Step: 10
Training loss: 0.4765067994594574
Validation loss: 1.6350124677022297

Epoch: 391| Step: 0
Training loss: 0.37972813844680786
Validation loss: 1.6614469392325288

Epoch: 5| Step: 1
Training loss: 0.20233285427093506
Validation loss: 1.614976579143155

Epoch: 5| Step: 2
Training loss: 0.2804349958896637
Validation loss: 1.6728340759072253

Epoch: 5| Step: 3
Training loss: 0.49040260910987854
Validation loss: 1.6983761390050252

Epoch: 5| Step: 4
Training loss: 0.22815632820129395
Validation loss: 1.7189889902709632

Epoch: 5| Step: 5
Training loss: 0.24509887397289276
Validation loss: 1.689006709283398

Epoch: 5| Step: 6
Training loss: 0.22466182708740234
Validation loss: 1.6726183109385993

Epoch: 5| Step: 7
Training loss: 0.5171685218811035
Validation loss: 1.6192767363722607

Epoch: 5| Step: 8
Training loss: 0.3998018205165863
Validation loss: 1.671503310562462

Epoch: 5| Step: 9
Training loss: 0.2369472235441208
Validation loss: 1.6686929323339974

Epoch: 5| Step: 10
Training loss: 0.31639590859413147
Validation loss: 1.7004596930678173

Epoch: 392| Step: 0
Training loss: 0.4055091440677643
Validation loss: 1.686627266227558

Epoch: 5| Step: 1
Training loss: 0.2632276117801666
Validation loss: 1.7032015528730167

Epoch: 5| Step: 2
Training loss: 0.49985629320144653
Validation loss: 1.696080914107702

Epoch: 5| Step: 3
Training loss: 0.28869128227233887
Validation loss: 1.6810990174611409

Epoch: 5| Step: 4
Training loss: 0.42420682311058044
Validation loss: 1.6652706502586283

Epoch: 5| Step: 5
Training loss: 0.41791972517967224
Validation loss: 1.6275513569513957

Epoch: 5| Step: 6
Training loss: 0.2890518307685852
Validation loss: 1.6193400070231447

Epoch: 5| Step: 7
Training loss: 0.20279550552368164
Validation loss: 1.6101701477522492

Epoch: 5| Step: 8
Training loss: 0.3192409574985504
Validation loss: 1.5789525944699523

Epoch: 5| Step: 9
Training loss: 0.3043271005153656
Validation loss: 1.5875940649740157

Epoch: 5| Step: 10
Training loss: 0.2516016364097595
Validation loss: 1.5780559227030764

Epoch: 393| Step: 0
Training loss: 0.2926613688468933
Validation loss: 1.5260719298034586

Epoch: 5| Step: 1
Training loss: 0.411293089389801
Validation loss: 1.5531501398291638

Epoch: 5| Step: 2
Training loss: 0.4787737727165222
Validation loss: 1.5391738824946906

Epoch: 5| Step: 3
Training loss: 0.3526046872138977
Validation loss: 1.569210413963564

Epoch: 5| Step: 4
Training loss: 0.30382388830184937
Validation loss: 1.5297944917473743

Epoch: 5| Step: 5
Training loss: 0.28978949785232544
Validation loss: 1.56116957049216

Epoch: 5| Step: 6
Training loss: 0.34386616945266724
Validation loss: 1.5744439780071218

Epoch: 5| Step: 7
Training loss: 0.20777621865272522
Validation loss: 1.6011103968466482

Epoch: 5| Step: 8
Training loss: 0.5062203407287598
Validation loss: 1.639786998430888

Epoch: 5| Step: 9
Training loss: 0.2629120349884033
Validation loss: 1.6686629095385153

Epoch: 5| Step: 10
Training loss: 0.2581775188446045
Validation loss: 1.6810149108209917

Epoch: 394| Step: 0
Training loss: 0.35397225618362427
Validation loss: 1.7126664743628552

Epoch: 5| Step: 1
Training loss: 0.4244932532310486
Validation loss: 1.756307150727959

Epoch: 5| Step: 2
Training loss: 0.6604160070419312
Validation loss: 1.7332117121706727

Epoch: 5| Step: 3
Training loss: 0.266669362783432
Validation loss: 1.6562635872953682

Epoch: 5| Step: 4
Training loss: 0.2537977695465088
Validation loss: 1.6253864713894424

Epoch: 5| Step: 5
Training loss: 0.435453325510025
Validation loss: 1.591638111299084

Epoch: 5| Step: 6
Training loss: 0.2460564821958542
Validation loss: 1.6015279549424366

Epoch: 5| Step: 7
Training loss: 0.26879653334617615
Validation loss: 1.5758618872652772

Epoch: 5| Step: 8
Training loss: 0.33666032552719116
Validation loss: 1.5586237868955057

Epoch: 5| Step: 9
Training loss: 0.45873814821243286
Validation loss: 1.5354339397081764

Epoch: 5| Step: 10
Training loss: 0.24711757898330688
Validation loss: 1.5436841742966765

Epoch: 395| Step: 0
Training loss: 0.37319719791412354
Validation loss: 1.5642623286093436

Epoch: 5| Step: 1
Training loss: 0.3978434205055237
Validation loss: 1.5844979850194787

Epoch: 5| Step: 2
Training loss: 0.42029324173927307
Validation loss: 1.6004597422897175

Epoch: 5| Step: 3
Training loss: 0.2693599760532379
Validation loss: 1.6519438656427528

Epoch: 5| Step: 4
Training loss: 0.3979066014289856
Validation loss: 1.6911466179355499

Epoch: 5| Step: 5
Training loss: 0.38699665665626526
Validation loss: 1.7058001564395042

Epoch: 5| Step: 6
Training loss: 0.29045066237449646
Validation loss: 1.693288262172412

Epoch: 5| Step: 7
Training loss: 0.32199668884277344
Validation loss: 1.7199278826354651

Epoch: 5| Step: 8
Training loss: 0.28444090485572815
Validation loss: 1.7105592040605442

Epoch: 5| Step: 9
Training loss: 0.27112919092178345
Validation loss: 1.6885687317899478

Epoch: 5| Step: 10
Training loss: 0.4212758243083954
Validation loss: 1.7067630214075888

Epoch: 396| Step: 0
Training loss: 0.2769470810890198
Validation loss: 1.6678499931930213

Epoch: 5| Step: 1
Training loss: 0.3091152608394623
Validation loss: 1.6642370787999963

Epoch: 5| Step: 2
Training loss: 0.4710226058959961
Validation loss: 1.6262475675152195

Epoch: 5| Step: 3
Training loss: 0.39499473571777344
Validation loss: 1.6166371043010423

Epoch: 5| Step: 4
Training loss: 0.20558634400367737
Validation loss: 1.6034630678033317

Epoch: 5| Step: 5
Training loss: 0.25238460302352905
Validation loss: 1.613605623604149

Epoch: 5| Step: 6
Training loss: 0.37135443091392517
Validation loss: 1.5812659135428808

Epoch: 5| Step: 7
Training loss: 0.4185832440853119
Validation loss: 1.604386096359581

Epoch: 5| Step: 8
Training loss: 0.28411027789115906
Validation loss: 1.6423380246726416

Epoch: 5| Step: 9
Training loss: 0.2857050895690918
Validation loss: 1.636079389561889

Epoch: 5| Step: 10
Training loss: 0.31403055787086487
Validation loss: 1.6317121713392195

Epoch: 397| Step: 0
Training loss: 0.35164695978164673
Validation loss: 1.6233818479763564

Epoch: 5| Step: 1
Training loss: 0.3827686607837677
Validation loss: 1.6043963893767326

Epoch: 5| Step: 2
Training loss: 0.33482474088668823
Validation loss: 1.6280434849441692

Epoch: 5| Step: 3
Training loss: 0.23557226359844208
Validation loss: 1.6124043951752365

Epoch: 5| Step: 4
Training loss: 0.34615761041641235
Validation loss: 1.623356250024611

Epoch: 5| Step: 5
Training loss: 0.4366161823272705
Validation loss: 1.6124600620679959

Epoch: 5| Step: 6
Training loss: 0.16942045092582703
Validation loss: 1.626871459586646

Epoch: 5| Step: 7
Training loss: 0.2600131928920746
Validation loss: 1.590610606696016

Epoch: 5| Step: 8
Training loss: 0.2825087606906891
Validation loss: 1.5966429428387714

Epoch: 5| Step: 9
Training loss: 0.3747168183326721
Validation loss: 1.5768139695608487

Epoch: 5| Step: 10
Training loss: 0.3921669125556946
Validation loss: 1.559927402004119

Epoch: 398| Step: 0
Training loss: 0.18167071044445038
Validation loss: 1.6020276616978388

Epoch: 5| Step: 1
Training loss: 0.26840800046920776
Validation loss: 1.592986652928014

Epoch: 5| Step: 2
Training loss: 0.30102232098579407
Validation loss: 1.6425791318698595

Epoch: 5| Step: 3
Training loss: 0.22862835228443146
Validation loss: 1.6639890350321287

Epoch: 5| Step: 4
Training loss: 0.33133548498153687
Validation loss: 1.689246041800386

Epoch: 5| Step: 5
Training loss: 0.42940568923950195
Validation loss: 1.665559971204368

Epoch: 5| Step: 6
Training loss: 0.3597920835018158
Validation loss: 1.6843568804443523

Epoch: 5| Step: 7
Training loss: 0.34536296129226685
Validation loss: 1.7358786111236901

Epoch: 5| Step: 8
Training loss: 0.5096118450164795
Validation loss: 1.6761782861525012

Epoch: 5| Step: 9
Training loss: 0.2547490894794464
Validation loss: 1.6711782140116538

Epoch: 5| Step: 10
Training loss: 0.33193549513816833
Validation loss: 1.6583622424833235

Epoch: 399| Step: 0
Training loss: 0.2947465777397156
Validation loss: 1.6822930612871725

Epoch: 5| Step: 1
Training loss: 0.21787795424461365
Validation loss: 1.6628648978407665

Epoch: 5| Step: 2
Training loss: 0.27351298928260803
Validation loss: 1.6696895207128217

Epoch: 5| Step: 3
Training loss: 0.46897000074386597
Validation loss: 1.6677854740491478

Epoch: 5| Step: 4
Training loss: 0.4857989251613617
Validation loss: 1.6747687144946026

Epoch: 5| Step: 5
Training loss: 0.21308425068855286
Validation loss: 1.6193541621649137

Epoch: 5| Step: 6
Training loss: 0.42955368757247925
Validation loss: 1.6166747718728998

Epoch: 5| Step: 7
Training loss: 0.268854022026062
Validation loss: 1.5944602925290343

Epoch: 5| Step: 8
Training loss: 0.20709633827209473
Validation loss: 1.5513588869443504

Epoch: 5| Step: 9
Training loss: 0.3364677429199219
Validation loss: 1.5761598310162943

Epoch: 5| Step: 10
Training loss: 0.23811635375022888
Validation loss: 1.6132110318829935

Epoch: 400| Step: 0
Training loss: 0.409907728433609
Validation loss: 1.5971232973119265

Epoch: 5| Step: 1
Training loss: 0.13141879439353943
Validation loss: 1.638302985058036

Epoch: 5| Step: 2
Training loss: 0.3784124255180359
Validation loss: 1.650141796758098

Epoch: 5| Step: 3
Training loss: 0.17146968841552734
Validation loss: 1.618022398282123

Epoch: 5| Step: 4
Training loss: 0.3961053490638733
Validation loss: 1.6230745751370665

Epoch: 5| Step: 5
Training loss: 0.18193542957305908
Validation loss: 1.5937826056634226

Epoch: 5| Step: 6
Training loss: 0.3354695737361908
Validation loss: 1.55893523205993

Epoch: 5| Step: 7
Training loss: 0.22755885124206543
Validation loss: 1.575490177318614

Epoch: 5| Step: 8
Training loss: 0.35881075263023376
Validation loss: 1.551933205255898

Epoch: 5| Step: 9
Training loss: 0.4275302290916443
Validation loss: 1.5817508851328204

Epoch: 5| Step: 10
Training loss: 0.40465453267097473
Validation loss: 1.5532426898197462

Epoch: 401| Step: 0
Training loss: 0.18538884818553925
Validation loss: 1.538549728291009

Epoch: 5| Step: 1
Training loss: 0.31761735677719116
Validation loss: 1.582487544705791

Epoch: 5| Step: 2
Training loss: 0.29118436574935913
Validation loss: 1.6040978905975178

Epoch: 5| Step: 3
Training loss: 0.33368197083473206
Validation loss: 1.5837571063349325

Epoch: 5| Step: 4
Training loss: 0.4689575135707855
Validation loss: 1.6136500271417762

Epoch: 5| Step: 5
Training loss: 0.22358474135398865
Validation loss: 1.6375477313995361

Epoch: 5| Step: 6
Training loss: 0.24475283920764923
Validation loss: 1.6518876796127648

Epoch: 5| Step: 7
Training loss: 0.33124247193336487
Validation loss: 1.6242975291385446

Epoch: 5| Step: 8
Training loss: 0.29878416657447815
Validation loss: 1.6134654341205474

Epoch: 5| Step: 9
Training loss: 0.23141634464263916
Validation loss: 1.6246290347909416

Epoch: 5| Step: 10
Training loss: 0.3837496340274811
Validation loss: 1.603189928557283

Epoch: 402| Step: 0
Training loss: 0.06499259173870087
Validation loss: 1.6295223312993203

Epoch: 5| Step: 1
Training loss: 0.3550085127353668
Validation loss: 1.6378112800659672

Epoch: 5| Step: 2
Training loss: 0.3589300215244293
Validation loss: 1.6591319396931639

Epoch: 5| Step: 3
Training loss: 0.20422370731830597
Validation loss: 1.6539187328789824

Epoch: 5| Step: 4
Training loss: 0.3928697109222412
Validation loss: 1.713689322112709

Epoch: 5| Step: 5
Training loss: 0.32613199949264526
Validation loss: 1.6399679171141757

Epoch: 5| Step: 6
Training loss: 0.29357776045799255
Validation loss: 1.6385903448186896

Epoch: 5| Step: 7
Training loss: 0.3079060912132263
Validation loss: 1.5691782518099713

Epoch: 5| Step: 8
Training loss: 0.33058154582977295
Validation loss: 1.5854725914616739

Epoch: 5| Step: 9
Training loss: 0.32591772079467773
Validation loss: 1.6075447708047845

Epoch: 5| Step: 10
Training loss: 0.5170565843582153
Validation loss: 1.6386673540197394

Epoch: 403| Step: 0
Training loss: 0.19319702684879303
Validation loss: 1.6920757191155547

Epoch: 5| Step: 1
Training loss: 0.3929416835308075
Validation loss: 1.6767243672442693

Epoch: 5| Step: 2
Training loss: 0.29878348112106323
Validation loss: 1.71825239991629

Epoch: 5| Step: 3
Training loss: 0.35991376638412476
Validation loss: 1.6577994003090808

Epoch: 5| Step: 4
Training loss: 0.37256303429603577
Validation loss: 1.6816960944924304

Epoch: 5| Step: 5
Training loss: 0.24900922179222107
Validation loss: 1.6611733231493222

Epoch: 5| Step: 6
Training loss: 0.4211800992488861
Validation loss: 1.6660133331052718

Epoch: 5| Step: 7
Training loss: 0.3497384190559387
Validation loss: 1.6391960331188735

Epoch: 5| Step: 8
Training loss: 0.39851686358451843
Validation loss: 1.6542413760257024

Epoch: 5| Step: 9
Training loss: 0.23715659976005554
Validation loss: 1.6385838908533896

Epoch: 5| Step: 10
Training loss: 0.18980608880519867
Validation loss: 1.6365105067529986

Epoch: 404| Step: 0
Training loss: 0.212078258395195
Validation loss: 1.6209490132588211

Epoch: 5| Step: 1
Training loss: 0.26140114665031433
Validation loss: 1.6617498346554336

Epoch: 5| Step: 2
Training loss: 0.39146658778190613
Validation loss: 1.716728807777487

Epoch: 5| Step: 3
Training loss: 0.4076910614967346
Validation loss: 1.7300734853231778

Epoch: 5| Step: 4
Training loss: 0.23290987312793732
Validation loss: 1.7461190774876585

Epoch: 5| Step: 5
Training loss: 0.5218756198883057
Validation loss: 1.7577300917717718

Epoch: 5| Step: 6
Training loss: 0.388621985912323
Validation loss: 1.741044698222991

Epoch: 5| Step: 7
Training loss: 0.27440840005874634
Validation loss: 1.7427528622329875

Epoch: 5| Step: 8
Training loss: 0.32697343826293945
Validation loss: 1.7506208214708554

Epoch: 5| Step: 9
Training loss: 0.29835331439971924
Validation loss: 1.6660346190134685

Epoch: 5| Step: 10
Training loss: 0.3864452838897705
Validation loss: 1.6831890088255688

Epoch: 405| Step: 0
Training loss: 0.3527880609035492
Validation loss: 1.66531115962613

Epoch: 5| Step: 1
Training loss: 0.2849598526954651
Validation loss: 1.6381703961280085

Epoch: 5| Step: 2
Training loss: 0.1295439898967743
Validation loss: 1.604128747858027

Epoch: 5| Step: 3
Training loss: 0.4148179590702057
Validation loss: 1.5624241931464082

Epoch: 5| Step: 4
Training loss: 0.4828566908836365
Validation loss: 1.557304988625229

Epoch: 5| Step: 5
Training loss: 0.3328664004802704
Validation loss: 1.5927896576543008

Epoch: 5| Step: 6
Training loss: 0.2688837945461273
Validation loss: 1.6080798128599763

Epoch: 5| Step: 7
Training loss: 0.3646000027656555
Validation loss: 1.5580307847710066

Epoch: 5| Step: 8
Training loss: 0.11243452876806259
Validation loss: 1.6052229340358446

Epoch: 5| Step: 9
Training loss: 0.17994424700737
Validation loss: 1.6637870573228406

Epoch: 5| Step: 10
Training loss: 0.36044013500213623
Validation loss: 1.65501191026421

Epoch: 406| Step: 0
Training loss: 0.2930085361003876
Validation loss: 1.6687998310212167

Epoch: 5| Step: 1
Training loss: 0.34460073709487915
Validation loss: 1.6678712816648587

Epoch: 5| Step: 2
Training loss: 0.2653140425682068
Validation loss: 1.6379166315960627

Epoch: 5| Step: 3
Training loss: 0.4071609079837799
Validation loss: 1.6248824019585886

Epoch: 5| Step: 4
Training loss: 0.220627099275589
Validation loss: 1.5980633125510266

Epoch: 5| Step: 5
Training loss: 0.3263956904411316
Validation loss: 1.5626636269272014

Epoch: 5| Step: 6
Training loss: 0.3813874125480652
Validation loss: 1.5639337826800603

Epoch: 5| Step: 7
Training loss: 0.25404253602027893
Validation loss: 1.5881798312228212

Epoch: 5| Step: 8
Training loss: 0.2713000476360321
Validation loss: 1.6007500758735083

Epoch: 5| Step: 9
Training loss: 0.2941446900367737
Validation loss: 1.6412621839072115

Epoch: 5| Step: 10
Training loss: 0.34421902894973755
Validation loss: 1.6832994953278573

Epoch: 407| Step: 0
Training loss: 0.2590439021587372
Validation loss: 1.6262539766168083

Epoch: 5| Step: 1
Training loss: 0.36677980422973633
Validation loss: 1.608816926197339

Epoch: 5| Step: 2
Training loss: 0.18236638605594635
Validation loss: 1.61661026811087

Epoch: 5| Step: 3
Training loss: 0.3503638207912445
Validation loss: 1.6122530455230384

Epoch: 5| Step: 4
Training loss: 0.4946727752685547
Validation loss: 1.643592425571975

Epoch: 5| Step: 5
Training loss: 0.36102956533432007
Validation loss: 1.600063157337968

Epoch: 5| Step: 6
Training loss: 0.2864212393760681
Validation loss: 1.6119659382809874

Epoch: 5| Step: 7
Training loss: 0.19129882752895355
Validation loss: 1.5934708669621458

Epoch: 5| Step: 8
Training loss: 0.4021260738372803
Validation loss: 1.6457387772939538

Epoch: 5| Step: 9
Training loss: 0.239085391163826
Validation loss: 1.6374553493274155

Epoch: 5| Step: 10
Training loss: 0.3237578570842743
Validation loss: 1.6545267938285746

Epoch: 408| Step: 0
Training loss: 0.22872066497802734
Validation loss: 1.6221212533212477

Epoch: 5| Step: 1
Training loss: 0.25210681557655334
Validation loss: 1.5847447392761067

Epoch: 5| Step: 2
Training loss: 0.37759560346603394
Validation loss: 1.5577114858934957

Epoch: 5| Step: 3
Training loss: 0.22699923813343048
Validation loss: 1.5343622956224667

Epoch: 5| Step: 4
Training loss: 0.18645527958869934
Validation loss: 1.5507993403301443

Epoch: 5| Step: 5
Training loss: 0.25578561425209045
Validation loss: 1.5766602754592896

Epoch: 5| Step: 6
Training loss: 0.2981801927089691
Validation loss: 1.5831256258872248

Epoch: 5| Step: 7
Training loss: 0.38036370277404785
Validation loss: 1.5852965180591871

Epoch: 5| Step: 8
Training loss: 0.2741478383541107
Validation loss: 1.5828299163490214

Epoch: 5| Step: 9
Training loss: 0.3934447765350342
Validation loss: 1.6221884758241716

Epoch: 5| Step: 10
Training loss: 0.23519708216190338
Validation loss: 1.6722862823035127

Epoch: 409| Step: 0
Training loss: 0.36755621433258057
Validation loss: 1.6352135968464676

Epoch: 5| Step: 1
Training loss: 0.3613448739051819
Validation loss: 1.685168057359675

Epoch: 5| Step: 2
Training loss: 0.35696396231651306
Validation loss: 1.67935682881263

Epoch: 5| Step: 3
Training loss: 0.26495060324668884
Validation loss: 1.6349554433617541

Epoch: 5| Step: 4
Training loss: 0.26395949721336365
Validation loss: 1.6107119834551247

Epoch: 5| Step: 5
Training loss: 0.23198704421520233
Validation loss: 1.596128144571858

Epoch: 5| Step: 6
Training loss: 0.19259515404701233
Validation loss: 1.5628354344316708

Epoch: 5| Step: 7
Training loss: 0.31778717041015625
Validation loss: 1.566315657349043

Epoch: 5| Step: 8
Training loss: 0.1351572722196579
Validation loss: 1.533887376067459

Epoch: 5| Step: 9
Training loss: 0.33742350339889526
Validation loss: 1.5525562904214347

Epoch: 5| Step: 10
Training loss: 0.36317747831344604
Validation loss: 1.5524764240428965

Epoch: 410| Step: 0
Training loss: 0.18312165141105652
Validation loss: 1.5964026989475373

Epoch: 5| Step: 1
Training loss: 0.2913762927055359
Validation loss: 1.5804827905470324

Epoch: 5| Step: 2
Training loss: 0.3505377471446991
Validation loss: 1.5794771153439757

Epoch: 5| Step: 3
Training loss: 0.2237064391374588
Validation loss: 1.6272011495405627

Epoch: 5| Step: 4
Training loss: 0.1727207601070404
Validation loss: 1.6430750226461759

Epoch: 5| Step: 5
Training loss: 0.24819831550121307
Validation loss: 1.6602898784863052

Epoch: 5| Step: 6
Training loss: 0.41928786039352417
Validation loss: 1.664654568959308

Epoch: 5| Step: 7
Training loss: 0.3101481795310974
Validation loss: 1.6529966374879241

Epoch: 5| Step: 8
Training loss: 0.264403760433197
Validation loss: 1.6558538739399244

Epoch: 5| Step: 9
Training loss: 0.4241282343864441
Validation loss: 1.6092562316566386

Epoch: 5| Step: 10
Training loss: 0.2572939395904541
Validation loss: 1.6264676522183161

Epoch: 411| Step: 0
Training loss: 0.33761754631996155
Validation loss: 1.6104251133498324

Epoch: 5| Step: 1
Training loss: 0.20123572647571564
Validation loss: 1.5791876533980012

Epoch: 5| Step: 2
Training loss: 0.30028921365737915
Validation loss: 1.601319412390391

Epoch: 5| Step: 3
Training loss: 0.17152675986289978
Validation loss: 1.5558945933977764

Epoch: 5| Step: 4
Training loss: 0.24859032034873962
Validation loss: 1.5502026978359427

Epoch: 5| Step: 5
Training loss: 0.35296371579170227
Validation loss: 1.569536546225189

Epoch: 5| Step: 6
Training loss: 0.27871376276016235
Validation loss: 1.5845775565793436

Epoch: 5| Step: 7
Training loss: 0.35776615142822266
Validation loss: 1.5693372616203882

Epoch: 5| Step: 8
Training loss: 0.2775120735168457
Validation loss: 1.6042323996943813

Epoch: 5| Step: 9
Training loss: 0.20210282504558563
Validation loss: 1.61228697787049

Epoch: 5| Step: 10
Training loss: 0.33860543370246887
Validation loss: 1.5786805178529473

Epoch: 412| Step: 0
Training loss: 0.2205846756696701
Validation loss: 1.5850093877443703

Epoch: 5| Step: 1
Training loss: 0.38403359055519104
Validation loss: 1.6083055491088538

Epoch: 5| Step: 2
Training loss: 0.2966509461402893
Validation loss: 1.6088488037868212

Epoch: 5| Step: 3
Training loss: 0.1605047881603241
Validation loss: 1.6692531480584094

Epoch: 5| Step: 4
Training loss: 0.2876582741737366
Validation loss: 1.585374859071547

Epoch: 5| Step: 5
Training loss: 0.27793481945991516
Validation loss: 1.5587998077433596

Epoch: 5| Step: 6
Training loss: 0.3479084074497223
Validation loss: 1.5910528417556518

Epoch: 5| Step: 7
Training loss: 0.23539145290851593
Validation loss: 1.583255648612976

Epoch: 5| Step: 8
Training loss: 0.2251029759645462
Validation loss: 1.5970222334707938

Epoch: 5| Step: 9
Training loss: 0.13013403117656708
Validation loss: 1.5771108327373382

Epoch: 5| Step: 10
Training loss: 0.2874339818954468
Validation loss: 1.549190200785155

Epoch: 413| Step: 0
Training loss: 0.19927361607551575
Validation loss: 1.5703326207335278

Epoch: 5| Step: 1
Training loss: 0.2873186767101288
Validation loss: 1.5975681722805064

Epoch: 5| Step: 2
Training loss: 0.2636949419975281
Validation loss: 1.5805863283013786

Epoch: 5| Step: 3
Training loss: 0.1639634668827057
Validation loss: 1.606842170479477

Epoch: 5| Step: 4
Training loss: 0.23677603900432587
Validation loss: 1.6334409124107772

Epoch: 5| Step: 5
Training loss: 0.3297128975391388
Validation loss: 1.6858167263769335

Epoch: 5| Step: 6
Training loss: 0.23634064197540283
Validation loss: 1.7021035968616445

Epoch: 5| Step: 7
Training loss: 0.1639830470085144
Validation loss: 1.6753284662000594

Epoch: 5| Step: 8
Training loss: 0.4454053044319153
Validation loss: 1.6732536259517874

Epoch: 5| Step: 9
Training loss: 0.38986605405807495
Validation loss: 1.6591616522881292

Epoch: 5| Step: 10
Training loss: 0.20733997225761414
Validation loss: 1.638263524219554

Epoch: 414| Step: 0
Training loss: 0.3205052316188812
Validation loss: 1.6303913747110674

Epoch: 5| Step: 1
Training loss: 0.09418220818042755
Validation loss: 1.599954669193555

Epoch: 5| Step: 2
Training loss: 0.2498435080051422
Validation loss: 1.598636023459896

Epoch: 5| Step: 3
Training loss: 0.27293992042541504
Validation loss: 1.6322621555738552

Epoch: 5| Step: 4
Training loss: 0.4200383126735687
Validation loss: 1.6349696484945153

Epoch: 5| Step: 5
Training loss: 0.24776515364646912
Validation loss: 1.6541128991752543

Epoch: 5| Step: 6
Training loss: 0.4142675995826721
Validation loss: 1.6555365279156675

Epoch: 5| Step: 7
Training loss: 0.22986459732055664
Validation loss: 1.658852033717658

Epoch: 5| Step: 8
Training loss: 0.2975679636001587
Validation loss: 1.6504947805917392

Epoch: 5| Step: 9
Training loss: 0.22958779335021973
Validation loss: 1.6209756943487352

Epoch: 5| Step: 10
Training loss: 0.38367152214050293
Validation loss: 1.6092840138302054

Epoch: 415| Step: 0
Training loss: 0.2779162526130676
Validation loss: 1.611738298528938

Epoch: 5| Step: 1
Training loss: 0.13723063468933105
Validation loss: 1.5664092225413169

Epoch: 5| Step: 2
Training loss: 0.33116304874420166
Validation loss: 1.5849771999543714

Epoch: 5| Step: 3
Training loss: 0.22725501656532288
Validation loss: 1.5966569480075632

Epoch: 5| Step: 4
Training loss: 0.18063244223594666
Validation loss: 1.6146494714162682

Epoch: 5| Step: 5
Training loss: 0.27523258328437805
Validation loss: 1.6122716357631068

Epoch: 5| Step: 6
Training loss: 0.23675599694252014
Validation loss: 1.6309284625514862

Epoch: 5| Step: 7
Training loss: 0.5083061456680298
Validation loss: 1.6462312731691586

Epoch: 5| Step: 8
Training loss: 0.2548530101776123
Validation loss: 1.5947004531019477

Epoch: 5| Step: 9
Training loss: 0.3135344386100769
Validation loss: 1.6323985079283356

Epoch: 5| Step: 10
Training loss: 0.17525742948055267
Validation loss: 1.6308810595543153

Epoch: 416| Step: 0
Training loss: 0.26498812437057495
Validation loss: 1.6261028833286737

Epoch: 5| Step: 1
Training loss: 0.2180376797914505
Validation loss: 1.5691277634712957

Epoch: 5| Step: 2
Training loss: 0.31583458185195923
Validation loss: 1.6428598921786073

Epoch: 5| Step: 3
Training loss: 0.19176079332828522
Validation loss: 1.5831696730788036

Epoch: 5| Step: 4
Training loss: 0.3062359094619751
Validation loss: 1.5408854631967441

Epoch: 5| Step: 5
Training loss: 0.3551298677921295
Validation loss: 1.5471827599310106

Epoch: 5| Step: 6
Training loss: 0.3506482243537903
Validation loss: 1.5322624342415923

Epoch: 5| Step: 7
Training loss: 0.29339727759361267
Validation loss: 1.5555429022799256

Epoch: 5| Step: 8
Training loss: 0.19909925758838654
Validation loss: 1.5404489591557493

Epoch: 5| Step: 9
Training loss: 0.25618407130241394
Validation loss: 1.5829240839968446

Epoch: 5| Step: 10
Training loss: 0.21331912279129028
Validation loss: 1.6057211224750807

Epoch: 417| Step: 0
Training loss: 0.29172173142433167
Validation loss: 1.6375697389725716

Epoch: 5| Step: 1
Training loss: 0.3544084429740906
Validation loss: 1.6729217767715454

Epoch: 5| Step: 2
Training loss: 0.2245783805847168
Validation loss: 1.6570621703260688

Epoch: 5| Step: 3
Training loss: 0.22747564315795898
Validation loss: 1.6299167230565061

Epoch: 5| Step: 4
Training loss: 0.38144534826278687
Validation loss: 1.656606961322087

Epoch: 5| Step: 5
Training loss: 0.283100426197052
Validation loss: 1.6442062085674656

Epoch: 5| Step: 6
Training loss: 0.1536782681941986
Validation loss: 1.6331404934647262

Epoch: 5| Step: 7
Training loss: 0.2614405155181885
Validation loss: 1.6186847699585782

Epoch: 5| Step: 8
Training loss: 0.29059308767318726
Validation loss: 1.5454525832206971

Epoch: 5| Step: 9
Training loss: 0.22447852790355682
Validation loss: 1.5386802175993561

Epoch: 5| Step: 10
Training loss: 0.1794072389602661
Validation loss: 1.5677498668752692

Epoch: 418| Step: 0
Training loss: 0.22456379234790802
Validation loss: 1.532580166734675

Epoch: 5| Step: 1
Training loss: 0.3679293990135193
Validation loss: 1.5506646966421476

Epoch: 5| Step: 2
Training loss: 0.18856170773506165
Validation loss: 1.5689297824777582

Epoch: 5| Step: 3
Training loss: 0.3317304253578186
Validation loss: 1.5672931607051561

Epoch: 5| Step: 4
Training loss: 0.19684135913848877
Validation loss: 1.6002982713842904

Epoch: 5| Step: 5
Training loss: 0.22295908629894257
Validation loss: 1.6300470470100321

Epoch: 5| Step: 6
Training loss: 0.13269373774528503
Validation loss: 1.655003692514153

Epoch: 5| Step: 7
Training loss: 0.4579622149467468
Validation loss: 1.6947762248336629

Epoch: 5| Step: 8
Training loss: 0.2472272366285324
Validation loss: 1.7018685686972834

Epoch: 5| Step: 9
Training loss: 0.3327729403972626
Validation loss: 1.670446700947259

Epoch: 5| Step: 10
Training loss: 0.25366103649139404
Validation loss: 1.6741290066831855

Epoch: 419| Step: 0
Training loss: 0.31080499291419983
Validation loss: 1.6355738165558025

Epoch: 5| Step: 1
Training loss: 0.2453017681837082
Validation loss: 1.632579570175499

Epoch: 5| Step: 2
Training loss: 0.32122576236724854
Validation loss: 1.590010824382946

Epoch: 5| Step: 3
Training loss: 0.33360934257507324
Validation loss: 1.601065807445075

Epoch: 5| Step: 4
Training loss: 0.20387256145477295
Validation loss: 1.577621865016158

Epoch: 5| Step: 5
Training loss: 0.3165234923362732
Validation loss: 1.6295707841073312

Epoch: 5| Step: 6
Training loss: 0.22753167152404785
Validation loss: 1.643632032537973

Epoch: 5| Step: 7
Training loss: 0.4507113993167877
Validation loss: 1.6282316574486353

Epoch: 5| Step: 8
Training loss: 0.3304993212223053
Validation loss: 1.6099225513396724

Epoch: 5| Step: 9
Training loss: 0.19639143347740173
Validation loss: 1.555891603551885

Epoch: 5| Step: 10
Training loss: 0.27901315689086914
Validation loss: 1.5417522320183374

Epoch: 420| Step: 0
Training loss: 0.27341610193252563
Validation loss: 1.5717029263896327

Epoch: 5| Step: 1
Training loss: 0.297678142786026
Validation loss: 1.55038881814608

Epoch: 5| Step: 2
Training loss: 0.22735580801963806
Validation loss: 1.5732784591695315

Epoch: 5| Step: 3
Training loss: 0.2314567118883133
Validation loss: 1.6043822252622215

Epoch: 5| Step: 4
Training loss: 0.37467843294143677
Validation loss: 1.6480792376302904

Epoch: 5| Step: 5
Training loss: 0.5239086151123047
Validation loss: 1.6885697636553036

Epoch: 5| Step: 6
Training loss: 0.34635061025619507
Validation loss: 1.68773155507221

Epoch: 5| Step: 7
Training loss: 0.45702725648880005
Validation loss: 1.62350320687858

Epoch: 5| Step: 8
Training loss: 0.12633177638053894
Validation loss: 1.5877190456595471

Epoch: 5| Step: 9
Training loss: 0.21767839789390564
Validation loss: 1.6654225959572742

Epoch: 5| Step: 10
Training loss: 0.2628421485424042
Validation loss: 1.6558228500427739

Epoch: 421| Step: 0
Training loss: 0.201178640127182
Validation loss: 1.6520134813042098

Epoch: 5| Step: 1
Training loss: 0.2605225443840027
Validation loss: 1.6916935213150517

Epoch: 5| Step: 2
Training loss: 0.2097461223602295
Validation loss: 1.6965415759753155

Epoch: 5| Step: 3
Training loss: 0.40245962142944336
Validation loss: 1.694221709364204

Epoch: 5| Step: 4
Training loss: 0.1686265468597412
Validation loss: 1.681504161127152

Epoch: 5| Step: 5
Training loss: 0.2627522945404053
Validation loss: 1.6948870055137142

Epoch: 5| Step: 6
Training loss: 0.43158191442489624
Validation loss: 1.6485215463945944

Epoch: 5| Step: 7
Training loss: 0.3192995488643646
Validation loss: 1.6355326816599856

Epoch: 5| Step: 8
Training loss: 0.32629790902137756
Validation loss: 1.6272452005776026

Epoch: 5| Step: 9
Training loss: 0.30953481793403625
Validation loss: 1.6108998560136365

Epoch: 5| Step: 10
Training loss: 0.2575394809246063
Validation loss: 1.6077754766710344

Epoch: 422| Step: 0
Training loss: 0.35480746626853943
Validation loss: 1.5607075870677989

Epoch: 5| Step: 1
Training loss: 0.5125495791435242
Validation loss: 1.5354641714403707

Epoch: 5| Step: 2
Training loss: 0.35568225383758545
Validation loss: 1.4988864506444624

Epoch: 5| Step: 3
Training loss: 0.27477189898490906
Validation loss: 1.5331767566742436

Epoch: 5| Step: 4
Training loss: 0.147681325674057
Validation loss: 1.5438078718800698

Epoch: 5| Step: 5
Training loss: 0.22125491499900818
Validation loss: 1.573314465502257

Epoch: 5| Step: 6
Training loss: 0.2411917895078659
Validation loss: 1.613459793470239

Epoch: 5| Step: 7
Training loss: 0.25452399253845215
Validation loss: 1.6270408604734687

Epoch: 5| Step: 8
Training loss: 0.3323976397514343
Validation loss: 1.6383075906384377

Epoch: 5| Step: 9
Training loss: 0.24793854355812073
Validation loss: 1.666166349123883

Epoch: 5| Step: 10
Training loss: 0.3159051239490509
Validation loss: 1.6598103700145599

Epoch: 423| Step: 0
Training loss: 0.30323782563209534
Validation loss: 1.6383399745469451

Epoch: 5| Step: 1
Training loss: 0.4390488266944885
Validation loss: 1.6455975835041334

Epoch: 5| Step: 2
Training loss: 0.22174862027168274
Validation loss: 1.6049570242563884

Epoch: 5| Step: 3
Training loss: 0.26272591948509216
Validation loss: 1.5993735700525262

Epoch: 5| Step: 4
Training loss: 0.27011698484420776
Validation loss: 1.5626685696263467

Epoch: 5| Step: 5
Training loss: 0.29934030771255493
Validation loss: 1.499893790932112

Epoch: 5| Step: 6
Training loss: 0.27653247117996216
Validation loss: 1.54067523184643

Epoch: 5| Step: 7
Training loss: 0.24367038905620575
Validation loss: 1.5280167325850456

Epoch: 5| Step: 8
Training loss: 0.29545363783836365
Validation loss: 1.530816537077709

Epoch: 5| Step: 9
Training loss: 0.3250810503959656
Validation loss: 1.5179429989989086

Epoch: 5| Step: 10
Training loss: 0.23978003859519958
Validation loss: 1.5303697893696446

Epoch: 424| Step: 0
Training loss: 0.23791036009788513
Validation loss: 1.5785652770791003

Epoch: 5| Step: 1
Training loss: 0.25431451201438904
Validation loss: 1.6271049502075359

Epoch: 5| Step: 2
Training loss: 0.36829984188079834
Validation loss: 1.6444214608079644

Epoch: 5| Step: 3
Training loss: 0.3262619376182556
Validation loss: 1.7205715025624921

Epoch: 5| Step: 4
Training loss: 0.263028085231781
Validation loss: 1.6984174469465851

Epoch: 5| Step: 5
Training loss: 0.18262527883052826
Validation loss: 1.6933165891196138

Epoch: 5| Step: 6
Training loss: 0.2924094498157501
Validation loss: 1.6367017479353054

Epoch: 5| Step: 7
Training loss: 0.2688825726509094
Validation loss: 1.5963960437364475

Epoch: 5| Step: 8
Training loss: 0.5675479173660278
Validation loss: 1.5783276288740096

Epoch: 5| Step: 9
Training loss: 0.2461339682340622
Validation loss: 1.5575456760262931

Epoch: 5| Step: 10
Training loss: 0.2826681137084961
Validation loss: 1.5618557865901659

Epoch: 425| Step: 0
Training loss: 0.31675824522972107
Validation loss: 1.5723339280774515

Epoch: 5| Step: 1
Training loss: 0.3063618540763855
Validation loss: 1.5529583474641204

Epoch: 5| Step: 2
Training loss: 0.4446719288825989
Validation loss: 1.5746891498565674

Epoch: 5| Step: 3
Training loss: 0.36992427706718445
Validation loss: 1.5934320329337992

Epoch: 5| Step: 4
Training loss: 0.2663239538669586
Validation loss: 1.6247558145112888

Epoch: 5| Step: 5
Training loss: 0.15962862968444824
Validation loss: 1.6513318348956365

Epoch: 5| Step: 6
Training loss: 0.23420973122119904
Validation loss: 1.622345611613284

Epoch: 5| Step: 7
Training loss: 0.17295131087303162
Validation loss: 1.6358284860528924

Epoch: 5| Step: 8
Training loss: 0.3604554235935211
Validation loss: 1.611248908504363

Epoch: 5| Step: 9
Training loss: 0.21401795744895935
Validation loss: 1.6476972090300692

Epoch: 5| Step: 10
Training loss: 0.27983927726745605
Validation loss: 1.6563597956011373

Epoch: 426| Step: 0
Training loss: 0.20889893174171448
Validation loss: 1.6132694252075688

Epoch: 5| Step: 1
Training loss: 0.28526216745376587
Validation loss: 1.5839523218011344

Epoch: 5| Step: 2
Training loss: 0.19751112163066864
Validation loss: 1.5550925577840498

Epoch: 5| Step: 3
Training loss: 0.28563690185546875
Validation loss: 1.5499079406902354

Epoch: 5| Step: 4
Training loss: 0.40052658319473267
Validation loss: 1.5398997273496402

Epoch: 5| Step: 5
Training loss: 0.26567918062210083
Validation loss: 1.542466619963287

Epoch: 5| Step: 6
Training loss: 0.2994499206542969
Validation loss: 1.5645026109551872

Epoch: 5| Step: 7
Training loss: 0.22715552151203156
Validation loss: 1.5492726679771178

Epoch: 5| Step: 8
Training loss: 0.4279363751411438
Validation loss: 1.584544627897201

Epoch: 5| Step: 9
Training loss: 0.39546260237693787
Validation loss: 1.6105940739313762

Epoch: 5| Step: 10
Training loss: 0.19849836826324463
Validation loss: 1.6183364852782218

Epoch: 427| Step: 0
Training loss: 0.2967222034931183
Validation loss: 1.6517982995638283

Epoch: 5| Step: 1
Training loss: 0.3741319179534912
Validation loss: 1.7042847192415627

Epoch: 5| Step: 2
Training loss: 0.27225470542907715
Validation loss: 1.69032625485492

Epoch: 5| Step: 3
Training loss: 0.324452668428421
Validation loss: 1.6861735716942818

Epoch: 5| Step: 4
Training loss: 0.3202553689479828
Validation loss: 1.7039748635343326

Epoch: 5| Step: 5
Training loss: 0.15457171201705933
Validation loss: 1.6958130200703938

Epoch: 5| Step: 6
Training loss: 0.2824612259864807
Validation loss: 1.6529341590019964

Epoch: 5| Step: 7
Training loss: 0.22726814448833466
Validation loss: 1.6270068409622356

Epoch: 5| Step: 8
Training loss: 0.31260547041893005
Validation loss: 1.61855500231507

Epoch: 5| Step: 9
Training loss: 0.35641318559646606
Validation loss: 1.6389178845190233

Epoch: 5| Step: 10
Training loss: 0.25268498063087463
Validation loss: 1.6461503313433739

Epoch: 428| Step: 0
Training loss: 0.2888145446777344
Validation loss: 1.6799377343987907

Epoch: 5| Step: 1
Training loss: 0.3656405508518219
Validation loss: 1.7059202348032305

Epoch: 5| Step: 2
Training loss: 0.47070178389549255
Validation loss: 1.7243578613445323

Epoch: 5| Step: 3
Training loss: 0.48427075147628784
Validation loss: 1.680792554732292

Epoch: 5| Step: 4
Training loss: 0.15830953419208527
Validation loss: 1.6371582605505501

Epoch: 5| Step: 5
Training loss: 0.15786120295524597
Validation loss: 1.6102835350139166

Epoch: 5| Step: 6
Training loss: 0.30186927318573
Validation loss: 1.5939906617646575

Epoch: 5| Step: 7
Training loss: 0.283531129360199
Validation loss: 1.5790012254509875

Epoch: 5| Step: 8
Training loss: 0.2867560386657715
Validation loss: 1.6059391062746766

Epoch: 5| Step: 9
Training loss: 0.3210694491863251
Validation loss: 1.6198888876104867

Epoch: 5| Step: 10
Training loss: 0.2668375074863434
Validation loss: 1.6337185290551954

Epoch: 429| Step: 0
Training loss: 0.23514428734779358
Validation loss: 1.6248144808635916

Epoch: 5| Step: 1
Training loss: 0.2738070487976074
Validation loss: 1.6499883397932975

Epoch: 5| Step: 2
Training loss: 0.3068521022796631
Validation loss: 1.6888155527012323

Epoch: 5| Step: 3
Training loss: 0.2849968373775482
Validation loss: 1.6776822818222867

Epoch: 5| Step: 4
Training loss: 0.19084495306015015
Validation loss: 1.6593331765103083

Epoch: 5| Step: 5
Training loss: 0.2622038424015045
Validation loss: 1.5756989256028207

Epoch: 5| Step: 6
Training loss: 0.23386278748512268
Validation loss: 1.5757778190797376

Epoch: 5| Step: 7
Training loss: 0.38315314054489136
Validation loss: 1.5449138213229436

Epoch: 5| Step: 8
Training loss: 0.2866949141025543
Validation loss: 1.5402399955257293

Epoch: 5| Step: 9
Training loss: 0.19424262642860413
Validation loss: 1.4806709340823594

Epoch: 5| Step: 10
Training loss: 0.3329501450061798
Validation loss: 1.4958103779823548

Epoch: 430| Step: 0
Training loss: 0.29458338022232056
Validation loss: 1.5247086094271751

Epoch: 5| Step: 1
Training loss: 0.2974548935890198
Validation loss: 1.4935075134359381

Epoch: 5| Step: 2
Training loss: 0.304861843585968
Validation loss: 1.5338415663729432

Epoch: 5| Step: 3
Training loss: 0.3251052498817444
Validation loss: 1.576856336285991

Epoch: 5| Step: 4
Training loss: 0.2735806107521057
Validation loss: 1.610764168923901

Epoch: 5| Step: 5
Training loss: 0.19981162250041962
Validation loss: 1.6498214352515437

Epoch: 5| Step: 6
Training loss: 0.3758765161037445
Validation loss: 1.6080026947041994

Epoch: 5| Step: 7
Training loss: 0.16473868489265442
Validation loss: 1.5932395201857372

Epoch: 5| Step: 8
Training loss: 0.2567058503627777
Validation loss: 1.5745537229763564

Epoch: 5| Step: 9
Training loss: 0.20315508544445038
Validation loss: 1.5773865721559013

Epoch: 5| Step: 10
Training loss: 0.23717588186264038
Validation loss: 1.5605567078436575

Epoch: 431| Step: 0
Training loss: 0.2512573301792145
Validation loss: 1.5219890661137079

Epoch: 5| Step: 1
Training loss: 0.2818269431591034
Validation loss: 1.530299928880507

Epoch: 5| Step: 2
Training loss: 0.3765471279621124
Validation loss: 1.5591994498365669

Epoch: 5| Step: 3
Training loss: 0.1862289160490036
Validation loss: 1.5467525002776936

Epoch: 5| Step: 4
Training loss: 0.19387874007225037
Validation loss: 1.554889004717591

Epoch: 5| Step: 5
Training loss: 0.16984181106090546
Validation loss: 1.5527817151879753

Epoch: 5| Step: 6
Training loss: 0.3141365349292755
Validation loss: 1.5877400957128054

Epoch: 5| Step: 7
Training loss: 0.38825517892837524
Validation loss: 1.6042677471714635

Epoch: 5| Step: 8
Training loss: 0.280529260635376
Validation loss: 1.5839920813037502

Epoch: 5| Step: 9
Training loss: 0.19620931148529053
Validation loss: 1.5983493661367765

Epoch: 5| Step: 10
Training loss: 0.15606190264225006
Validation loss: 1.57902180956256

Epoch: 432| Step: 0
Training loss: 0.23556289076805115
Validation loss: 1.6211675238865677

Epoch: 5| Step: 1
Training loss: 0.2332754135131836
Validation loss: 1.6092154338795652

Epoch: 5| Step: 2
Training loss: 0.34940290451049805
Validation loss: 1.6035514608506234

Epoch: 5| Step: 3
Training loss: 0.21514561772346497
Validation loss: 1.5819343238748529

Epoch: 5| Step: 4
Training loss: 0.3340032696723938
Validation loss: 1.5930591911397955

Epoch: 5| Step: 5
Training loss: 0.27367815375328064
Validation loss: 1.6095936272733955

Epoch: 5| Step: 6
Training loss: 0.2101326435804367
Validation loss: 1.588824866920389

Epoch: 5| Step: 7
Training loss: 0.2846592962741852
Validation loss: 1.5843282598321156

Epoch: 5| Step: 8
Training loss: 0.22031430900096893
Validation loss: 1.6035093979168964

Epoch: 5| Step: 9
Training loss: 0.2128535956144333
Validation loss: 1.61526571935223

Epoch: 5| Step: 10
Training loss: 0.226812481880188
Validation loss: 1.579214584442877

Epoch: 433| Step: 0
Training loss: 0.22359053790569305
Validation loss: 1.6229756493722238

Epoch: 5| Step: 1
Training loss: 0.2696508467197418
Validation loss: 1.6115804256931427

Epoch: 5| Step: 2
Training loss: 0.21045294404029846
Validation loss: 1.600518803442678

Epoch: 5| Step: 3
Training loss: 0.20087487995624542
Validation loss: 1.6189105100529169

Epoch: 5| Step: 4
Training loss: 0.27652430534362793
Validation loss: 1.5941149637263308

Epoch: 5| Step: 5
Training loss: 0.21978962421417236
Validation loss: 1.5339648082692137

Epoch: 5| Step: 6
Training loss: 0.17654743790626526
Validation loss: 1.5573523506041496

Epoch: 5| Step: 7
Training loss: 0.3161434531211853
Validation loss: 1.5711173319047498

Epoch: 5| Step: 8
Training loss: 0.3190533220767975
Validation loss: 1.549048577585528

Epoch: 5| Step: 9
Training loss: 0.1529342234134674
Validation loss: 1.5592748362530944

Epoch: 5| Step: 10
Training loss: 0.25603973865509033
Validation loss: 1.556774684177932

Epoch: 434| Step: 0
Training loss: 0.32689157128334045
Validation loss: 1.6371028064399638

Epoch: 5| Step: 1
Training loss: 0.3889561593532562
Validation loss: 1.618120764532397

Epoch: 5| Step: 2
Training loss: 0.21899692714214325
Validation loss: 1.6236437392491165

Epoch: 5| Step: 3
Training loss: 0.1927877515554428
Validation loss: 1.6189397047924738

Epoch: 5| Step: 4
Training loss: 0.25590333342552185
Validation loss: 1.632582103052447

Epoch: 5| Step: 5
Training loss: 0.3508473038673401
Validation loss: 1.579647784592003

Epoch: 5| Step: 6
Training loss: 0.20055988430976868
Validation loss: 1.590512949933288

Epoch: 5| Step: 7
Training loss: 0.1611194759607315
Validation loss: 1.578653549635282

Epoch: 5| Step: 8
Training loss: 0.21799488365650177
Validation loss: 1.5793434266121156

Epoch: 5| Step: 9
Training loss: 0.19737739861011505
Validation loss: 1.5804286464568107

Epoch: 5| Step: 10
Training loss: 0.28538036346435547
Validation loss: 1.5584386343597083

Epoch: 435| Step: 0
Training loss: 0.5427826046943665
Validation loss: 1.547240880227858

Epoch: 5| Step: 1
Training loss: 0.12388843297958374
Validation loss: 1.5503298672296668

Epoch: 5| Step: 2
Training loss: 0.21907004714012146
Validation loss: 1.5961749425498388

Epoch: 5| Step: 3
Training loss: 0.22206619381904602
Validation loss: 1.5744048267282464

Epoch: 5| Step: 4
Training loss: 0.4580596387386322
Validation loss: 1.5714920336200344

Epoch: 5| Step: 5
Training loss: 0.28102225065231323
Validation loss: 1.6211875696336069

Epoch: 5| Step: 6
Training loss: 0.367644727230072
Validation loss: 1.5767822573261876

Epoch: 5| Step: 7
Training loss: 0.12109716236591339
Validation loss: 1.5574837987140944

Epoch: 5| Step: 8
Training loss: 0.25679630041122437
Validation loss: 1.595649537219796

Epoch: 5| Step: 9
Training loss: 0.13800498843193054
Validation loss: 1.5824435449415637

Epoch: 5| Step: 10
Training loss: 0.2770273983478546
Validation loss: 1.552652762782189

Epoch: 436| Step: 0
Training loss: 0.3135243356227875
Validation loss: 1.5689745205704884

Epoch: 5| Step: 1
Training loss: 0.29696258902549744
Validation loss: 1.5504842073686662

Epoch: 5| Step: 2
Training loss: 0.21408028900623322
Validation loss: 1.5537296290038733

Epoch: 5| Step: 3
Training loss: 0.23798421025276184
Validation loss: 1.5718704910688504

Epoch: 5| Step: 4
Training loss: 0.15817704796791077
Validation loss: 1.5703849689934843

Epoch: 5| Step: 5
Training loss: 0.23275551199913025
Validation loss: 1.593087911605835

Epoch: 5| Step: 6
Training loss: 0.2263411581516266
Validation loss: 1.627249761294293

Epoch: 5| Step: 7
Training loss: 0.383768230676651
Validation loss: 1.6473920832398117

Epoch: 5| Step: 8
Training loss: 0.3469126224517822
Validation loss: 1.6552909548564623

Epoch: 5| Step: 9
Training loss: 0.3223174214363098
Validation loss: 1.6785026288801623

Epoch: 5| Step: 10
Training loss: 0.21241618692874908
Validation loss: 1.6773572826898226

Epoch: 437| Step: 0
Training loss: 0.25759783387184143
Validation loss: 1.6881832563748924

Epoch: 5| Step: 1
Training loss: 0.2521708309650421
Validation loss: 1.6274495765727053

Epoch: 5| Step: 2
Training loss: 0.11554966866970062
Validation loss: 1.613215002962338

Epoch: 5| Step: 3
Training loss: 0.24053151905536652
Validation loss: 1.5780065021207255

Epoch: 5| Step: 4
Training loss: 0.24503616988658905
Validation loss: 1.5844025022240096

Epoch: 5| Step: 5
Training loss: 0.21592628955841064
Validation loss: 1.5912228681707894

Epoch: 5| Step: 6
Training loss: 0.19103606045246124
Validation loss: 1.5913686470318866

Epoch: 5| Step: 7
Training loss: 0.4728476107120514
Validation loss: 1.637163621123119

Epoch: 5| Step: 8
Training loss: 0.4621694087982178
Validation loss: 1.622532142105923

Epoch: 5| Step: 9
Training loss: 0.2104906588792801
Validation loss: 1.6055285443541825

Epoch: 5| Step: 10
Training loss: 0.3152367174625397
Validation loss: 1.601390928350469

Epoch: 438| Step: 0
Training loss: 0.3051393926143646
Validation loss: 1.6093735259066346

Epoch: 5| Step: 1
Training loss: 0.21347078680992126
Validation loss: 1.6296330780111334

Epoch: 5| Step: 2
Training loss: 0.1482262909412384
Validation loss: 1.593932996514023

Epoch: 5| Step: 3
Training loss: 0.28363925218582153
Validation loss: 1.6259200662694953

Epoch: 5| Step: 4
Training loss: 0.23219338059425354
Validation loss: 1.5982670527632519

Epoch: 5| Step: 5
Training loss: 0.3027496933937073
Validation loss: 1.6078186945248676

Epoch: 5| Step: 6
Training loss: 0.255746066570282
Validation loss: 1.5586645244270243

Epoch: 5| Step: 7
Training loss: 0.21577084064483643
Validation loss: 1.5944309888347503

Epoch: 5| Step: 8
Training loss: 0.2703818082809448
Validation loss: 1.612350021639178

Epoch: 5| Step: 9
Training loss: 0.34444019198417664
Validation loss: 1.6124056667409918

Epoch: 5| Step: 10
Training loss: 0.21303853392601013
Validation loss: 1.6067464928473196

Epoch: 439| Step: 0
Training loss: 0.24535684287548065
Validation loss: 1.580791530429676

Epoch: 5| Step: 1
Training loss: 0.40781229734420776
Validation loss: 1.5691352441746702

Epoch: 5| Step: 2
Training loss: 0.25524359941482544
Validation loss: 1.6010311880419332

Epoch: 5| Step: 3
Training loss: 0.1575753390789032
Validation loss: 1.5794534349954257

Epoch: 5| Step: 4
Training loss: 0.1573207676410675
Validation loss: 1.592291441015018

Epoch: 5| Step: 5
Training loss: 0.21848487854003906
Validation loss: 1.6345899925437024

Epoch: 5| Step: 6
Training loss: 0.1835942566394806
Validation loss: 1.587036822431831

Epoch: 5| Step: 7
Training loss: 0.20213428139686584
Validation loss: 1.6611809704893379

Epoch: 5| Step: 8
Training loss: 0.2513206899166107
Validation loss: 1.6795150426126295

Epoch: 5| Step: 9
Training loss: 0.20907747745513916
Validation loss: 1.6731547065960464

Epoch: 5| Step: 10
Training loss: 0.23880894482135773
Validation loss: 1.6280680548760198

Epoch: 440| Step: 0
Training loss: 0.20065109431743622
Validation loss: 1.6294992559699601

Epoch: 5| Step: 1
Training loss: 0.2071543186903
Validation loss: 1.5662919148322074

Epoch: 5| Step: 2
Training loss: 0.3902348577976227
Validation loss: 1.589686680865544

Epoch: 5| Step: 3
Training loss: 0.1706121563911438
Validation loss: 1.5343741627149685

Epoch: 5| Step: 4
Training loss: 0.26788848638534546
Validation loss: 1.4973311334527948

Epoch: 5| Step: 5
Training loss: 0.24611540138721466
Validation loss: 1.544142734619879

Epoch: 5| Step: 6
Training loss: 0.11582362651824951
Validation loss: 1.5467257666331466

Epoch: 5| Step: 7
Training loss: 0.25243276357650757
Validation loss: 1.5529919542292112

Epoch: 5| Step: 8
Training loss: 0.23242032527923584
Validation loss: 1.5973582985580608

Epoch: 5| Step: 9
Training loss: 0.3096844553947449
Validation loss: 1.6477965283137497

Epoch: 5| Step: 10
Training loss: 0.26988232135772705
Validation loss: 1.6702663411376297

Epoch: 441| Step: 0
Training loss: 0.3512302041053772
Validation loss: 1.696752323899218

Epoch: 5| Step: 1
Training loss: 0.26471805572509766
Validation loss: 1.748046878845461

Epoch: 5| Step: 2
Training loss: 0.310485303401947
Validation loss: 1.7131111775675127

Epoch: 5| Step: 3
Training loss: 0.3734968602657318
Validation loss: 1.6494009353781258

Epoch: 5| Step: 4
Training loss: 0.28201937675476074
Validation loss: 1.5835974767643919

Epoch: 5| Step: 5
Training loss: 0.15753474831581116
Validation loss: 1.5647413948530793

Epoch: 5| Step: 6
Training loss: 0.23325641453266144
Validation loss: 1.534393556656376

Epoch: 5| Step: 7
Training loss: 0.15720079839229584
Validation loss: 1.5174192267079507

Epoch: 5| Step: 8
Training loss: 0.27803856134414673
Validation loss: 1.500116281611945

Epoch: 5| Step: 9
Training loss: 0.14744505286216736
Validation loss: 1.4943833722863147

Epoch: 5| Step: 10
Training loss: 0.23164750635623932
Validation loss: 1.5128960071071502

Epoch: 442| Step: 0
Training loss: 0.23355212807655334
Validation loss: 1.547033727809947

Epoch: 5| Step: 1
Training loss: 0.26091551780700684
Validation loss: 1.6027082012545677

Epoch: 5| Step: 2
Training loss: 0.21202678978443146
Validation loss: 1.616384611334852

Epoch: 5| Step: 3
Training loss: 0.30340710282325745
Validation loss: 1.6502448076842933

Epoch: 5| Step: 4
Training loss: 0.3615066111087799
Validation loss: 1.6671355437206965

Epoch: 5| Step: 5
Training loss: 0.20745877921581268
Validation loss: 1.6406504236241823

Epoch: 5| Step: 6
Training loss: 0.258113294839859
Validation loss: 1.6548924933197677

Epoch: 5| Step: 7
Training loss: 0.20086371898651123
Validation loss: 1.6492749350045317

Epoch: 5| Step: 8
Training loss: 0.1796991527080536
Validation loss: 1.6434974144863825

Epoch: 5| Step: 9
Training loss: 0.2645629048347473
Validation loss: 1.5925014083103468

Epoch: 5| Step: 10
Training loss: 0.2534800171852112
Validation loss: 1.55459810585104

Epoch: 443| Step: 0
Training loss: 0.2698970139026642
Validation loss: 1.564173245942721

Epoch: 5| Step: 1
Training loss: 0.18739286065101624
Validation loss: 1.575351652278695

Epoch: 5| Step: 2
Training loss: 0.297660768032074
Validation loss: 1.5331135424234534

Epoch: 5| Step: 3
Training loss: 0.2645065486431122
Validation loss: 1.5920988167485883

Epoch: 5| Step: 4
Training loss: 0.23159575462341309
Validation loss: 1.5742507224441857

Epoch: 5| Step: 5
Training loss: 0.186672642827034
Validation loss: 1.5871664644569479

Epoch: 5| Step: 6
Training loss: 0.32627108693122864
Validation loss: 1.6034972411330028

Epoch: 5| Step: 7
Training loss: 0.28224578499794006
Validation loss: 1.6034745823952459

Epoch: 5| Step: 8
Training loss: 0.22473323345184326
Validation loss: 1.6064744713485881

Epoch: 5| Step: 9
Training loss: 0.131967693567276
Validation loss: 1.556884834843297

Epoch: 5| Step: 10
Training loss: 0.14344052970409393
Validation loss: 1.5673739192306355

Epoch: 444| Step: 0
Training loss: 0.11158083379268646
Validation loss: 1.5582052879436041

Epoch: 5| Step: 1
Training loss: 0.27561795711517334
Validation loss: 1.5417518538813437

Epoch: 5| Step: 2
Training loss: 0.18856965005397797
Validation loss: 1.6216310519044117

Epoch: 5| Step: 3
Training loss: 0.18840369582176208
Validation loss: 1.6095349327210458

Epoch: 5| Step: 4
Training loss: 0.3465802073478699
Validation loss: 1.6411786451134631

Epoch: 5| Step: 5
Training loss: 0.29101139307022095
Validation loss: 1.6300796936917048

Epoch: 5| Step: 6
Training loss: 0.555482029914856
Validation loss: 1.6732855701959262

Epoch: 5| Step: 7
Training loss: 0.2942137122154236
Validation loss: 1.6561284321610645

Epoch: 5| Step: 8
Training loss: 0.13518480956554413
Validation loss: 1.6018843381635604

Epoch: 5| Step: 9
Training loss: 0.2560007572174072
Validation loss: 1.5813241197216896

Epoch: 5| Step: 10
Training loss: 0.22520312666893005
Validation loss: 1.5846773603911042

Epoch: 445| Step: 0
Training loss: 0.2677415907382965
Validation loss: 1.6053814080453688

Epoch: 5| Step: 1
Training loss: 0.17428834736347198
Validation loss: 1.6346894976913289

Epoch: 5| Step: 2
Training loss: 0.32301855087280273
Validation loss: 1.61851163577008

Epoch: 5| Step: 3
Training loss: 0.2508312165737152
Validation loss: 1.626759902123482

Epoch: 5| Step: 4
Training loss: 0.2329438030719757
Validation loss: 1.6515887950056343

Epoch: 5| Step: 5
Training loss: 0.24326948821544647
Validation loss: 1.6557228744670909

Epoch: 5| Step: 6
Training loss: 0.2818913161754608
Validation loss: 1.6846414830095024

Epoch: 5| Step: 7
Training loss: 0.27589982748031616
Validation loss: 1.645966799028458

Epoch: 5| Step: 8
Training loss: 0.20571212470531464
Validation loss: 1.632097594199642

Epoch: 5| Step: 9
Training loss: 0.3716835081577301
Validation loss: 1.5717470210085633

Epoch: 5| Step: 10
Training loss: 0.22798296809196472
Validation loss: 1.5919829401918637

Epoch: 446| Step: 0
Training loss: 0.23135574162006378
Validation loss: 1.5777958875061364

Epoch: 5| Step: 1
Training loss: 0.4126652777194977
Validation loss: 1.6103020393720238

Epoch: 5| Step: 2
Training loss: 0.25259262323379517
Validation loss: 1.6252872136331373

Epoch: 5| Step: 3
Training loss: 0.20807072520256042
Validation loss: 1.6132951974868774

Epoch: 5| Step: 4
Training loss: 0.30312076210975647
Validation loss: 1.6465530472417031

Epoch: 5| Step: 5
Training loss: 0.2662466764450073
Validation loss: 1.6592605562620266

Epoch: 5| Step: 6
Training loss: 0.11578770726919174
Validation loss: 1.6516408420378161

Epoch: 5| Step: 7
Training loss: 0.23691506683826447
Validation loss: 1.70880260006074

Epoch: 5| Step: 8
Training loss: 0.2520705759525299
Validation loss: 1.6771717404806485

Epoch: 5| Step: 9
Training loss: 0.18726733326911926
Validation loss: 1.6339883317229569

Epoch: 5| Step: 10
Training loss: 0.2626117467880249
Validation loss: 1.6320234133351235

Epoch: 447| Step: 0
Training loss: 0.3097909688949585
Validation loss: 1.6092832062834053

Epoch: 5| Step: 1
Training loss: 0.18137669563293457
Validation loss: 1.5854048536669823

Epoch: 5| Step: 2
Training loss: 0.27720242738723755
Validation loss: 1.5908757871197117

Epoch: 5| Step: 3
Training loss: 0.3535749912261963
Validation loss: 1.5415305194034372

Epoch: 5| Step: 4
Training loss: 0.1449834108352661
Validation loss: 1.5613885566752443

Epoch: 5| Step: 5
Training loss: 0.27921241521835327
Validation loss: 1.557915105614611

Epoch: 5| Step: 6
Training loss: 0.14049117267131805
Validation loss: 1.5615565443551669

Epoch: 5| Step: 7
Training loss: 0.19113478064537048
Validation loss: 1.5561456167569725

Epoch: 5| Step: 8
Training loss: 0.1963919848203659
Validation loss: 1.5407508406587826

Epoch: 5| Step: 9
Training loss: 0.292785108089447
Validation loss: 1.5750904442161642

Epoch: 5| Step: 10
Training loss: 0.23164111375808716
Validation loss: 1.6064770221710205

Epoch: 448| Step: 0
Training loss: 0.12569470703601837
Validation loss: 1.586777747318309

Epoch: 5| Step: 1
Training loss: 0.3544626832008362
Validation loss: 1.605563002247964

Epoch: 5| Step: 2
Training loss: 0.18899396061897278
Validation loss: 1.626708758774624

Epoch: 5| Step: 3
Training loss: 0.1405288279056549
Validation loss: 1.6122383776531424

Epoch: 5| Step: 4
Training loss: 0.2027970254421234
Validation loss: 1.5847796329887964

Epoch: 5| Step: 5
Training loss: 0.23149116337299347
Validation loss: 1.6054438314130228

Epoch: 5| Step: 6
Training loss: 0.33098143339157104
Validation loss: 1.6051147650646906

Epoch: 5| Step: 7
Training loss: 0.23679156601428986
Validation loss: 1.5789419848431823

Epoch: 5| Step: 8
Training loss: 0.14187335968017578
Validation loss: 1.5757052680497527

Epoch: 5| Step: 9
Training loss: 0.22477273643016815
Validation loss: 1.5587367601292108

Epoch: 5| Step: 10
Training loss: 0.24511635303497314
Validation loss: 1.5586203400806715

Epoch: 449| Step: 0
Training loss: 0.27792730927467346
Validation loss: 1.5344428106020855

Epoch: 5| Step: 1
Training loss: 0.2532048225402832
Validation loss: 1.5402037982017762

Epoch: 5| Step: 2
Training loss: 0.15066316723823547
Validation loss: 1.57031560585063

Epoch: 5| Step: 3
Training loss: 0.08649269491434097
Validation loss: 1.5695625761503815

Epoch: 5| Step: 4
Training loss: 0.33975839614868164
Validation loss: 1.5972837517338414

Epoch: 5| Step: 5
Training loss: 0.25189629197120667
Validation loss: 1.684630806728076

Epoch: 5| Step: 6
Training loss: 0.2146884649991989
Validation loss: 1.6975700470709032

Epoch: 5| Step: 7
Training loss: 0.24553582072257996
Validation loss: 1.72221173778657

Epoch: 5| Step: 8
Training loss: 0.14920710027217865
Validation loss: 1.724502521176492

Epoch: 5| Step: 9
Training loss: 0.382901132106781
Validation loss: 1.6575872295646257

Epoch: 5| Step: 10
Training loss: 0.2434493452310562
Validation loss: 1.67723479834936

Epoch: 450| Step: 0
Training loss: 0.13760241866111755
Validation loss: 1.6297370631207702

Epoch: 5| Step: 1
Training loss: 0.2779395282268524
Validation loss: 1.6378209757548507

Epoch: 5| Step: 2
Training loss: 0.330466091632843
Validation loss: 1.6163576815717964

Epoch: 5| Step: 3
Training loss: 0.19584783911705017
Validation loss: 1.5718557680806806

Epoch: 5| Step: 4
Training loss: 0.2804555296897888
Validation loss: 1.556193256890902

Epoch: 5| Step: 5
Training loss: 0.22611352801322937
Validation loss: 1.5303518182487899

Epoch: 5| Step: 6
Training loss: 0.1567206084728241
Validation loss: 1.5537529530063752

Epoch: 5| Step: 7
Training loss: 0.24463319778442383
Validation loss: 1.546531041463216

Epoch: 5| Step: 8
Training loss: 0.2773459553718567
Validation loss: 1.584828463933801

Epoch: 5| Step: 9
Training loss: 0.15188923478126526
Validation loss: 1.5955964070494457

Epoch: 5| Step: 10
Training loss: 0.1917133778333664
Validation loss: 1.6312517094355758

Epoch: 451| Step: 0
Training loss: 0.31975555419921875
Validation loss: 1.658226115729219

Epoch: 5| Step: 1
Training loss: 0.2022942751646042
Validation loss: 1.6599743712332942

Epoch: 5| Step: 2
Training loss: 0.21870669722557068
Validation loss: 1.6621303532713203

Epoch: 5| Step: 3
Training loss: 0.1924377828836441
Validation loss: 1.641405600373463

Epoch: 5| Step: 4
Training loss: 0.24410350620746613
Validation loss: 1.5927840612267936

Epoch: 5| Step: 5
Training loss: 0.2609018385410309
Validation loss: 1.5504950836140623

Epoch: 5| Step: 6
Training loss: 0.129755437374115
Validation loss: 1.5411575904456518

Epoch: 5| Step: 7
Training loss: 0.22215799987316132
Validation loss: 1.525974912028159

Epoch: 5| Step: 8
Training loss: 0.29218730330467224
Validation loss: 1.5114362406474289

Epoch: 5| Step: 9
Training loss: 0.18080195784568787
Validation loss: 1.504084628115418

Epoch: 5| Step: 10
Training loss: 0.3319769501686096
Validation loss: 1.4955686830705213

Epoch: 452| Step: 0
Training loss: 0.3451158404350281
Validation loss: 1.508284616213973

Epoch: 5| Step: 1
Training loss: 0.3103734254837036
Validation loss: 1.528342439282325

Epoch: 5| Step: 2
Training loss: 0.23277080059051514
Validation loss: 1.58462195627151

Epoch: 5| Step: 3
Training loss: 0.2120477259159088
Validation loss: 1.6424962397544616

Epoch: 5| Step: 4
Training loss: 0.22055093944072723
Validation loss: 1.6625219160510647

Epoch: 5| Step: 5
Training loss: 0.26104554533958435
Validation loss: 1.7050650696600638

Epoch: 5| Step: 6
Training loss: 0.30193543434143066
Validation loss: 1.6893227754100677

Epoch: 5| Step: 7
Training loss: 0.2841712236404419
Validation loss: 1.6829699136877572

Epoch: 5| Step: 8
Training loss: 0.22590363025665283
Validation loss: 1.6351463076888875

Epoch: 5| Step: 9
Training loss: 0.23332123458385468
Validation loss: 1.6330384580037927

Epoch: 5| Step: 10
Training loss: 0.21242022514343262
Validation loss: 1.6385029362094017

Epoch: 453| Step: 0
Training loss: 0.19555911421775818
Validation loss: 1.567157082660224

Epoch: 5| Step: 1
Training loss: 0.19965603947639465
Validation loss: 1.5506826754539245

Epoch: 5| Step: 2
Training loss: 0.2573695182800293
Validation loss: 1.542534302639705

Epoch: 5| Step: 3
Training loss: 0.19466517865657806
Validation loss: 1.5390975571447802

Epoch: 5| Step: 4
Training loss: 0.1585765779018402
Validation loss: 1.5854133149628997

Epoch: 5| Step: 5
Training loss: 0.24727725982666016
Validation loss: 1.5721146047756236

Epoch: 5| Step: 6
Training loss: 0.26571905612945557
Validation loss: 1.5922205037968133

Epoch: 5| Step: 7
Training loss: 0.23053574562072754
Validation loss: 1.5905874493301555

Epoch: 5| Step: 8
Training loss: 0.344946950674057
Validation loss: 1.621322048607693

Epoch: 5| Step: 9
Training loss: 0.323880136013031
Validation loss: 1.6205714159114386

Epoch: 5| Step: 10
Training loss: 0.18860343098640442
Validation loss: 1.6291920126125377

Epoch: 454| Step: 0
Training loss: 0.2795083522796631
Validation loss: 1.668301390063378

Epoch: 5| Step: 1
Training loss: 0.2059626579284668
Validation loss: 1.6306479041294386

Epoch: 5| Step: 2
Training loss: 0.25261202454566956
Validation loss: 1.6232104301452637

Epoch: 5| Step: 3
Training loss: 0.14224091172218323
Validation loss: 1.6175325262931086

Epoch: 5| Step: 4
Training loss: 0.2602437436580658
Validation loss: 1.6309523608094902

Epoch: 5| Step: 5
Training loss: 0.25037169456481934
Validation loss: 1.6067318762502363

Epoch: 5| Step: 6
Training loss: 0.24648192524909973
Validation loss: 1.559750315963581

Epoch: 5| Step: 7
Training loss: 0.23393726348876953
Validation loss: 1.557216614805242

Epoch: 5| Step: 8
Training loss: 0.24797117710113525
Validation loss: 1.550418702504968

Epoch: 5| Step: 9
Training loss: 0.2115509808063507
Validation loss: 1.563497547180422

Epoch: 5| Step: 10
Training loss: 0.2106383889913559
Validation loss: 1.5820117753039125

Epoch: 455| Step: 0
Training loss: 0.1837395876646042
Validation loss: 1.5684553653963151

Epoch: 5| Step: 1
Training loss: 0.2496689110994339
Validation loss: 1.583907255562403

Epoch: 5| Step: 2
Training loss: 0.2861625850200653
Validation loss: 1.555050802487199

Epoch: 5| Step: 3
Training loss: 0.17272183299064636
Validation loss: 1.567700183519753

Epoch: 5| Step: 4
Training loss: 0.1472582370042801
Validation loss: 1.5514707321761756

Epoch: 5| Step: 5
Training loss: 0.18990716338157654
Validation loss: 1.5279613053926857

Epoch: 5| Step: 6
Training loss: 0.186194509267807
Validation loss: 1.4879640994533416

Epoch: 5| Step: 7
Training loss: 0.16907984018325806
Validation loss: 1.484534659693318

Epoch: 5| Step: 8
Training loss: 0.38977956771850586
Validation loss: 1.5384817879687074

Epoch: 5| Step: 9
Training loss: 0.24833229184150696
Validation loss: 1.5368859075730847

Epoch: 5| Step: 10
Training loss: 0.3476000726222992
Validation loss: 1.5144351143990793

Epoch: 456| Step: 0
Training loss: 0.2105555534362793
Validation loss: 1.5348692940127464

Epoch: 5| Step: 1
Training loss: 0.21049776673316956
Validation loss: 1.5358644762346823

Epoch: 5| Step: 2
Training loss: 0.38888052105903625
Validation loss: 1.5390687886104788

Epoch: 5| Step: 3
Training loss: 0.27924641966819763
Validation loss: 1.5347737355898785

Epoch: 5| Step: 4
Training loss: 0.2831348478794098
Validation loss: 1.5051918452785862

Epoch: 5| Step: 5
Training loss: 0.19475212693214417
Validation loss: 1.5336769050167454

Epoch: 5| Step: 6
Training loss: 0.18155810236930847
Validation loss: 1.5755896376025291

Epoch: 5| Step: 7
Training loss: 0.15207375586032867
Validation loss: 1.5502100490754651

Epoch: 5| Step: 8
Training loss: 0.3016800880432129
Validation loss: 1.5416964356617262

Epoch: 5| Step: 9
Training loss: 0.14733344316482544
Validation loss: 1.556070307249664

Epoch: 5| Step: 10
Training loss: 0.18110530078411102
Validation loss: 1.5822263148523146

Epoch: 457| Step: 0
Training loss: 0.39879751205444336
Validation loss: 1.5537433201266873

Epoch: 5| Step: 1
Training loss: 0.14047794044017792
Validation loss: 1.589071459667657

Epoch: 5| Step: 2
Training loss: 0.14350096881389618
Validation loss: 1.5755215626890942

Epoch: 5| Step: 3
Training loss: 0.18369054794311523
Validation loss: 1.571879941930053

Epoch: 5| Step: 4
Training loss: 0.209152489900589
Validation loss: 1.5783993210843814

Epoch: 5| Step: 5
Training loss: 0.2280290126800537
Validation loss: 1.5252681368140764

Epoch: 5| Step: 6
Training loss: 0.32605481147766113
Validation loss: 1.5276800881149948

Epoch: 5| Step: 7
Training loss: 0.10878784954547882
Validation loss: 1.5410703818003337

Epoch: 5| Step: 8
Training loss: 0.2272799015045166
Validation loss: 1.5843808907334522

Epoch: 5| Step: 9
Training loss: 0.19646930694580078
Validation loss: 1.5866264245843376

Epoch: 5| Step: 10
Training loss: 0.15892398357391357
Validation loss: 1.591114692790534

Epoch: 458| Step: 0
Training loss: 0.17415094375610352
Validation loss: 1.6198284010733328

Epoch: 5| Step: 1
Training loss: 0.26297736167907715
Validation loss: 1.6094242065183577

Epoch: 5| Step: 2
Training loss: 0.24343590438365936
Validation loss: 1.6044390970660793

Epoch: 5| Step: 3
Training loss: 0.19061653316020966
Validation loss: 1.6108366673992527

Epoch: 5| Step: 4
Training loss: 0.20236936211585999
Validation loss: 1.5963716545412618

Epoch: 5| Step: 5
Training loss: 0.1842145472764969
Validation loss: 1.593180364178073

Epoch: 5| Step: 6
Training loss: 0.2973557710647583
Validation loss: 1.5230637397817386

Epoch: 5| Step: 7
Training loss: 0.30688896775245667
Validation loss: 1.5110617978598482

Epoch: 5| Step: 8
Training loss: 0.15695013105869293
Validation loss: 1.504599070036283

Epoch: 5| Step: 9
Training loss: 0.18788297474384308
Validation loss: 1.4912653969180198

Epoch: 5| Step: 10
Training loss: 0.13706927001476288
Validation loss: 1.5182924565448557

Epoch: 459| Step: 0
Training loss: 0.18173594772815704
Validation loss: 1.5099604565610167

Epoch: 5| Step: 1
Training loss: 0.19769209623336792
Validation loss: 1.5666356612277288

Epoch: 5| Step: 2
Training loss: 0.38380539417266846
Validation loss: 1.6218068715064757

Epoch: 5| Step: 3
Training loss: 0.282296746969223
Validation loss: 1.6219201754498225

Epoch: 5| Step: 4
Training loss: 0.3411383330821991
Validation loss: 1.5841177484040618

Epoch: 5| Step: 5
Training loss: 0.17772167921066284
Validation loss: 1.544501063644245

Epoch: 5| Step: 6
Training loss: 0.1769670695066452
Validation loss: 1.5801292798852409

Epoch: 5| Step: 7
Training loss: 0.4428604245185852
Validation loss: 1.5430375811874226

Epoch: 5| Step: 8
Training loss: 0.2897496819496155
Validation loss: 1.5624964121849305

Epoch: 5| Step: 9
Training loss: 0.2053035944700241
Validation loss: 1.578637005180441

Epoch: 5| Step: 10
Training loss: 0.2106984257698059
Validation loss: 1.5409444788450837

Epoch: 460| Step: 0
Training loss: 0.43037113547325134
Validation loss: 1.5409179515736078

Epoch: 5| Step: 1
Training loss: 0.22063174843788147
Validation loss: 1.557563627919843

Epoch: 5| Step: 2
Training loss: 0.2757740616798401
Validation loss: 1.558501430737075

Epoch: 5| Step: 3
Training loss: 0.17753061652183533
Validation loss: 1.5677044301904657

Epoch: 5| Step: 4
Training loss: 0.20730182528495789
Validation loss: 1.6402029555330995

Epoch: 5| Step: 5
Training loss: 0.1392509639263153
Validation loss: 1.6330461591802619

Epoch: 5| Step: 6
Training loss: 0.23511585593223572
Validation loss: 1.6075231041959537

Epoch: 5| Step: 7
Training loss: 0.2018921673297882
Validation loss: 1.570662206859999

Epoch: 5| Step: 8
Training loss: 0.17017525434494019
Validation loss: 1.582798614296862

Epoch: 5| Step: 9
Training loss: 0.24287991225719452
Validation loss: 1.5898721814155579

Epoch: 5| Step: 10
Training loss: 0.3113380968570709
Validation loss: 1.5637429061756338

Epoch: 461| Step: 0
Training loss: 0.22577790915966034
Validation loss: 1.516821321620736

Epoch: 5| Step: 1
Training loss: 0.16560301184654236
Validation loss: 1.5216578616890857

Epoch: 5| Step: 2
Training loss: 0.2134585678577423
Validation loss: 1.5527402406097741

Epoch: 5| Step: 3
Training loss: 0.21701069176197052
Validation loss: 1.5785774518084783

Epoch: 5| Step: 4
Training loss: 0.10526703298091888
Validation loss: 1.5678138476546093

Epoch: 5| Step: 5
Training loss: 0.2043449878692627
Validation loss: 1.5896519114894252

Epoch: 5| Step: 6
Training loss: 0.1413440853357315
Validation loss: 1.6037546838483503

Epoch: 5| Step: 7
Training loss: 0.28627559542655945
Validation loss: 1.6355415672384284

Epoch: 5| Step: 8
Training loss: 0.23267845809459686
Validation loss: 1.6862487921150782

Epoch: 5| Step: 9
Training loss: 0.21240314841270447
Validation loss: 1.6788093454094344

Epoch: 5| Step: 10
Training loss: 0.28336501121520996
Validation loss: 1.6523559151157257

Epoch: 462| Step: 0
Training loss: 0.11302755773067474
Validation loss: 1.6453472952688895

Epoch: 5| Step: 1
Training loss: 0.24588003754615784
Validation loss: 1.6172449640048447

Epoch: 5| Step: 2
Training loss: 0.12026085704565048
Validation loss: 1.6207089193405644

Epoch: 5| Step: 3
Training loss: 0.15052974224090576
Validation loss: 1.577427488501354

Epoch: 5| Step: 4
Training loss: 0.17737367749214172
Validation loss: 1.572277311355837

Epoch: 5| Step: 5
Training loss: 0.1958926022052765
Validation loss: 1.5382233806835708

Epoch: 5| Step: 6
Training loss: 0.3211444318294525
Validation loss: 1.5858735704934726

Epoch: 5| Step: 7
Training loss: 0.2721276581287384
Validation loss: 1.6040629545847576

Epoch: 5| Step: 8
Training loss: 0.18541131913661957
Validation loss: 1.5946973113603489

Epoch: 5| Step: 9
Training loss: 0.3096601366996765
Validation loss: 1.5894424530767626

Epoch: 5| Step: 10
Training loss: 0.1533772200345993
Validation loss: 1.5916417080868956

Epoch: 463| Step: 0
Training loss: 0.2554989457130432
Validation loss: 1.615205946788993

Epoch: 5| Step: 1
Training loss: 0.1821994036436081
Validation loss: 1.6079336199709164

Epoch: 5| Step: 2
Training loss: 0.1999664604663849
Validation loss: 1.6192937602279007

Epoch: 5| Step: 3
Training loss: 0.20973718166351318
Validation loss: 1.5728282723375546

Epoch: 5| Step: 4
Training loss: 0.2406158447265625
Validation loss: 1.581352271059508

Epoch: 5| Step: 5
Training loss: 0.1665019989013672
Validation loss: 1.5774390800024873

Epoch: 5| Step: 6
Training loss: 0.1557946652173996
Validation loss: 1.6311724916581185

Epoch: 5| Step: 7
Training loss: 0.30750778317451477
Validation loss: 1.59893169454349

Epoch: 5| Step: 8
Training loss: 0.21154984831809998
Validation loss: 1.588457574126541

Epoch: 5| Step: 9
Training loss: 0.2322475165128708
Validation loss: 1.5730399098447574

Epoch: 5| Step: 10
Training loss: 0.08906278759241104
Validation loss: 1.5582365694866385

Epoch: 464| Step: 0
Training loss: 0.2319439947605133
Validation loss: 1.505818437504512

Epoch: 5| Step: 1
Training loss: 0.15565600991249084
Validation loss: 1.5319356328697615

Epoch: 5| Step: 2
Training loss: 0.20297303795814514
Validation loss: 1.5410807440357823

Epoch: 5| Step: 3
Training loss: 0.2413279116153717
Validation loss: 1.5515573986114994

Epoch: 5| Step: 4
Training loss: 0.22996774315834045
Validation loss: 1.5623794653082406

Epoch: 5| Step: 5
Training loss: 0.19616882503032684
Validation loss: 1.5878749996103265

Epoch: 5| Step: 6
Training loss: 0.2630690038204193
Validation loss: 1.5828819710721251

Epoch: 5| Step: 7
Training loss: 0.17822228372097015
Validation loss: 1.5641463648888372

Epoch: 5| Step: 8
Training loss: 0.20771436393260956
Validation loss: 1.6062652321272

Epoch: 5| Step: 9
Training loss: 0.12829336524009705
Validation loss: 1.6002814487744403

Epoch: 5| Step: 10
Training loss: 0.21522706747055054
Validation loss: 1.6236345575701805

Epoch: 465| Step: 0
Training loss: 0.20554523169994354
Validation loss: 1.626312917278659

Epoch: 5| Step: 1
Training loss: 0.2591492533683777
Validation loss: 1.6230224665775095

Epoch: 5| Step: 2
Training loss: 0.3509369492530823
Validation loss: 1.5897148591215893

Epoch: 5| Step: 3
Training loss: 0.1745644211769104
Validation loss: 1.5442886044902187

Epoch: 5| Step: 4
Training loss: 0.18512989580631256
Validation loss: 1.5687508608705254

Epoch: 5| Step: 5
Training loss: 0.25840359926223755
Validation loss: 1.5574512263779998

Epoch: 5| Step: 6
Training loss: 0.19731415808200836
Validation loss: 1.5172794224113546

Epoch: 5| Step: 7
Training loss: 0.18638008832931519
Validation loss: 1.5048445783635622

Epoch: 5| Step: 8
Training loss: 0.20382174849510193
Validation loss: 1.4941134709183888

Epoch: 5| Step: 9
Training loss: 0.4021798074245453
Validation loss: 1.4718726873397827

Epoch: 5| Step: 10
Training loss: 0.22061245143413544
Validation loss: 1.4997970160617624

Epoch: 466| Step: 0
Training loss: 0.24709780514240265
Validation loss: 1.4824987130780374

Epoch: 5| Step: 1
Training loss: 0.2095259130001068
Validation loss: 1.5263286252175607

Epoch: 5| Step: 2
Training loss: 0.22588121891021729
Validation loss: 1.5374259128365466

Epoch: 5| Step: 3
Training loss: 0.3193371891975403
Validation loss: 1.5742960835015902

Epoch: 5| Step: 4
Training loss: 0.19588497281074524
Validation loss: 1.5563134506184568

Epoch: 5| Step: 5
Training loss: 0.20947179198265076
Validation loss: 1.5978714125130766

Epoch: 5| Step: 6
Training loss: 0.22372014820575714
Validation loss: 1.6140795292392853

Epoch: 5| Step: 7
Training loss: 0.2405203878879547
Validation loss: 1.5979213265962497

Epoch: 5| Step: 8
Training loss: 0.15455012023448944
Validation loss: 1.563237133846488

Epoch: 5| Step: 9
Training loss: 0.16023151576519012
Validation loss: 1.5181944972725325

Epoch: 5| Step: 10
Training loss: 0.24954739212989807
Validation loss: 1.5337225801201277

Epoch: 467| Step: 0
Training loss: 0.2828257083892822
Validation loss: 1.5073899312685894

Epoch: 5| Step: 1
Training loss: 0.2753585875034332
Validation loss: 1.5022160737745223

Epoch: 5| Step: 2
Training loss: 0.23344913125038147
Validation loss: 1.537417434876965

Epoch: 5| Step: 3
Training loss: 0.2033114731311798
Validation loss: 1.500581331150506

Epoch: 5| Step: 4
Training loss: 0.214448019862175
Validation loss: 1.4942111866448515

Epoch: 5| Step: 5
Training loss: 0.2712539732456207
Validation loss: 1.5376219884041817

Epoch: 5| Step: 6
Training loss: 0.20673903822898865
Validation loss: 1.5672355698001

Epoch: 5| Step: 7
Training loss: 0.22317638993263245
Validation loss: 1.6005462638793453

Epoch: 5| Step: 8
Training loss: 0.21697862446308136
Validation loss: 1.612407599726031

Epoch: 5| Step: 9
Training loss: 0.14628204703330994
Validation loss: 1.5911606178488782

Epoch: 5| Step: 10
Training loss: 0.15294264256954193
Validation loss: 1.6125776780548917

Epoch: 468| Step: 0
Training loss: 0.17009100317955017
Validation loss: 1.5774160687641432

Epoch: 5| Step: 1
Training loss: 0.1487918198108673
Validation loss: 1.5833311568024337

Epoch: 5| Step: 2
Training loss: 0.2523733973503113
Validation loss: 1.556352037255482

Epoch: 5| Step: 3
Training loss: 0.1930369883775711
Validation loss: 1.5794476424494097

Epoch: 5| Step: 4
Training loss: 0.21068623661994934
Validation loss: 1.5601273800737114

Epoch: 5| Step: 5
Training loss: 0.11316607147455215
Validation loss: 1.5779218673706055

Epoch: 5| Step: 6
Training loss: 0.29197806119918823
Validation loss: 1.6312946478525798

Epoch: 5| Step: 7
Training loss: 0.19638574123382568
Validation loss: 1.6370359082375803

Epoch: 5| Step: 8
Training loss: 0.19812431931495667
Validation loss: 1.6138205233440603

Epoch: 5| Step: 9
Training loss: 0.24588055908679962
Validation loss: 1.654406759046739

Epoch: 5| Step: 10
Training loss: 0.1776677370071411
Validation loss: 1.6392314305869482

Epoch: 469| Step: 0
Training loss: 0.12595437467098236
Validation loss: 1.6075655529575963

Epoch: 5| Step: 1
Training loss: 0.24665836989879608
Validation loss: 1.5738536939826062

Epoch: 5| Step: 2
Training loss: 0.2193698137998581
Validation loss: 1.563026064185686

Epoch: 5| Step: 3
Training loss: 0.16385211050510406
Validation loss: 1.5631176989565614

Epoch: 5| Step: 4
Training loss: 0.2063019573688507
Validation loss: 1.56355909891026

Epoch: 5| Step: 5
Training loss: 0.3303454518318176
Validation loss: 1.5609665070810625

Epoch: 5| Step: 6
Training loss: 0.16202804446220398
Validation loss: 1.5762276828929942

Epoch: 5| Step: 7
Training loss: 0.36412936449050903
Validation loss: 1.5968930452100691

Epoch: 5| Step: 8
Training loss: 0.1533171385526657
Validation loss: 1.6119646872243574

Epoch: 5| Step: 9
Training loss: 0.141808420419693
Validation loss: 1.6480364773863105

Epoch: 5| Step: 10
Training loss: 0.20386528968811035
Validation loss: 1.640825117788007

Epoch: 470| Step: 0
Training loss: 0.18236565589904785
Validation loss: 1.6527224868856452

Epoch: 5| Step: 1
Training loss: 0.1757424771785736
Validation loss: 1.6110355149033249

Epoch: 5| Step: 2
Training loss: 0.1572989523410797
Validation loss: 1.5813181707935948

Epoch: 5| Step: 3
Training loss: 0.2614021897315979
Validation loss: 1.5799151928194108

Epoch: 5| Step: 4
Training loss: 0.25386905670166016
Validation loss: 1.5718301880744197

Epoch: 5| Step: 5
Training loss: 0.18524345755577087
Validation loss: 1.5611093210917648

Epoch: 5| Step: 6
Training loss: 0.2178678959608078
Validation loss: 1.5699314327650173

Epoch: 5| Step: 7
Training loss: 0.21080391108989716
Validation loss: 1.580739257156208

Epoch: 5| Step: 8
Training loss: 0.0951848030090332
Validation loss: 1.5616163515275525

Epoch: 5| Step: 9
Training loss: 0.23593613505363464
Validation loss: 1.5651053792686873

Epoch: 5| Step: 10
Training loss: 0.19302940368652344
Validation loss: 1.5832602977752686

Epoch: 471| Step: 0
Training loss: 0.1400851607322693
Validation loss: 1.5775700499934535

Epoch: 5| Step: 1
Training loss: 0.14424660801887512
Validation loss: 1.6060161693121797

Epoch: 5| Step: 2
Training loss: 0.21025505661964417
Validation loss: 1.6128896692747712

Epoch: 5| Step: 3
Training loss: 0.29784679412841797
Validation loss: 1.6057175461963942

Epoch: 5| Step: 4
Training loss: 0.1592126041650772
Validation loss: 1.6086304174956454

Epoch: 5| Step: 5
Training loss: 0.21452338993549347
Validation loss: 1.5994047041862243

Epoch: 5| Step: 6
Training loss: 0.16173429787158966
Validation loss: 1.6047330748650335

Epoch: 5| Step: 7
Training loss: 0.30248650908470154
Validation loss: 1.5663347897991058

Epoch: 5| Step: 8
Training loss: 0.1682906150817871
Validation loss: 1.5744895332603044

Epoch: 5| Step: 9
Training loss: 0.17267806828022003
Validation loss: 1.5439740457842428

Epoch: 5| Step: 10
Training loss: 0.16128899157047272
Validation loss: 1.5138735014905211

Epoch: 472| Step: 0
Training loss: 0.24857473373413086
Validation loss: 1.5310820187291792

Epoch: 5| Step: 1
Training loss: 0.12074253708124161
Validation loss: 1.569989740207631

Epoch: 5| Step: 2
Training loss: 0.17664769291877747
Validation loss: 1.5976727944548412

Epoch: 5| Step: 3
Training loss: 0.2748397886753082
Validation loss: 1.6336757034383795

Epoch: 5| Step: 4
Training loss: 0.2718600332736969
Validation loss: 1.6322606552031733

Epoch: 5| Step: 5
Training loss: 0.2124738246202469
Validation loss: 1.6128163799162833

Epoch: 5| Step: 6
Training loss: 0.215612530708313
Validation loss: 1.5551541261775519

Epoch: 5| Step: 7
Training loss: 0.2291760891675949
Validation loss: 1.5515204424499183

Epoch: 5| Step: 8
Training loss: 0.10870079696178436
Validation loss: 1.5291811009889007

Epoch: 5| Step: 9
Training loss: 0.16441145539283752
Validation loss: 1.5643101930618286

Epoch: 5| Step: 10
Training loss: 0.2620440721511841
Validation loss: 1.5592928419830978

Epoch: 473| Step: 0
Training loss: 0.18758738040924072
Validation loss: 1.5715167227611746

Epoch: 5| Step: 1
Training loss: 0.2041780650615692
Validation loss: 1.5823095972819994

Epoch: 5| Step: 2
Training loss: 0.21286001801490784
Validation loss: 1.605522487753181

Epoch: 5| Step: 3
Training loss: 0.20425021648406982
Validation loss: 1.5597663335902716

Epoch: 5| Step: 4
Training loss: 0.1350947618484497
Validation loss: 1.6104600224443661

Epoch: 5| Step: 5
Training loss: 0.2600290775299072
Validation loss: 1.6328752117772256

Epoch: 5| Step: 6
Training loss: 0.26471003890037537
Validation loss: 1.636495259500319

Epoch: 5| Step: 7
Training loss: 0.26588401198387146
Validation loss: 1.6358720903755517

Epoch: 5| Step: 8
Training loss: 0.19501788914203644
Validation loss: 1.5941521518973893

Epoch: 5| Step: 9
Training loss: 0.2048420011997223
Validation loss: 1.5662322621191702

Epoch: 5| Step: 10
Training loss: 0.2919076085090637
Validation loss: 1.5339396781818841

Epoch: 474| Step: 0
Training loss: 0.1827843189239502
Validation loss: 1.5320277008959042

Epoch: 5| Step: 1
Training loss: 0.29534903168678284
Validation loss: 1.5211367017479354

Epoch: 5| Step: 2
Training loss: 0.19084742665290833
Validation loss: 1.4840383632208711

Epoch: 5| Step: 3
Training loss: 0.22290821373462677
Validation loss: 1.4896624972743373

Epoch: 5| Step: 4
Training loss: 0.21924062073230743
Validation loss: 1.5033798358773673

Epoch: 5| Step: 5
Training loss: 0.0969516783952713
Validation loss: 1.5082821679371659

Epoch: 5| Step: 6
Training loss: 0.23055820167064667
Validation loss: 1.5517783664887952

Epoch: 5| Step: 7
Training loss: 0.1852777749300003
Validation loss: 1.5581329420048704

Epoch: 5| Step: 8
Training loss: 0.19510135054588318
Validation loss: 1.564414490935623

Epoch: 5| Step: 9
Training loss: 0.3234785199165344
Validation loss: 1.5981197562268985

Epoch: 5| Step: 10
Training loss: 0.20241807401180267
Validation loss: 1.5922365009143788

Epoch: 475| Step: 0
Training loss: 0.2127537727355957
Validation loss: 1.5876077144376692

Epoch: 5| Step: 1
Training loss: 0.15466348826885223
Validation loss: 1.584297808267737

Epoch: 5| Step: 2
Training loss: 0.1295633316040039
Validation loss: 1.5562891524325135

Epoch: 5| Step: 3
Training loss: 0.20100335776805878
Validation loss: 1.557661687174151

Epoch: 5| Step: 4
Training loss: 0.14761635661125183
Validation loss: 1.5178066248534827

Epoch: 5| Step: 5
Training loss: 0.13914009928703308
Validation loss: 1.5205779819078342

Epoch: 5| Step: 6
Training loss: 0.21241497993469238
Validation loss: 1.5032836320579692

Epoch: 5| Step: 7
Training loss: 0.29217272996902466
Validation loss: 1.510931045778336

Epoch: 5| Step: 8
Training loss: 0.22283101081848145
Validation loss: 1.5074171084229664

Epoch: 5| Step: 9
Training loss: 0.14373594522476196
Validation loss: 1.530786947537494

Epoch: 5| Step: 10
Training loss: 0.2214423418045044
Validation loss: 1.5324892741377636

Epoch: 476| Step: 0
Training loss: 0.1224232092499733
Validation loss: 1.5355762986726658

Epoch: 5| Step: 1
Training loss: 0.22841548919677734
Validation loss: 1.5675715887418358

Epoch: 5| Step: 2
Training loss: 0.21691513061523438
Validation loss: 1.5887102234748103

Epoch: 5| Step: 3
Training loss: 0.2673681378364563
Validation loss: 1.5919770630457069

Epoch: 5| Step: 4
Training loss: 0.27126404643058777
Validation loss: 1.604881953167659

Epoch: 5| Step: 5
Training loss: 0.18233220279216766
Validation loss: 1.5502359610731884

Epoch: 5| Step: 6
Training loss: 0.18001660704612732
Validation loss: 1.5289067504226521

Epoch: 5| Step: 7
Training loss: 0.18495866656303406
Validation loss: 1.5452897792221398

Epoch: 5| Step: 8
Training loss: 0.18154877424240112
Validation loss: 1.5334701512449531

Epoch: 5| Step: 9
Training loss: 0.18889650702476501
Validation loss: 1.500621453408272

Epoch: 5| Step: 10
Training loss: 0.22760234773159027
Validation loss: 1.531148369594287

Epoch: 477| Step: 0
Training loss: 0.32560428977012634
Validation loss: 1.5282441505821802

Epoch: 5| Step: 1
Training loss: 0.08846767991781235
Validation loss: 1.5433329254068353

Epoch: 5| Step: 2
Training loss: 0.16037525236606598
Validation loss: 1.5963820577949606

Epoch: 5| Step: 3
Training loss: 0.08571488410234451
Validation loss: 1.5835379977380075

Epoch: 5| Step: 4
Training loss: 0.41132888197898865
Validation loss: 1.6778841313495432

Epoch: 5| Step: 5
Training loss: 0.38248586654663086
Validation loss: 1.678260463540272

Epoch: 5| Step: 6
Training loss: 0.12734895944595337
Validation loss: 1.6174235292660293

Epoch: 5| Step: 7
Training loss: 0.10613180696964264
Validation loss: 1.6271596095895255

Epoch: 5| Step: 8
Training loss: 0.14713311195373535
Validation loss: 1.600388055206627

Epoch: 5| Step: 9
Training loss: 0.13624337315559387
Validation loss: 1.615880189403411

Epoch: 5| Step: 10
Training loss: 0.27235695719718933
Validation loss: 1.6058247191931612

Epoch: 478| Step: 0
Training loss: 0.1341058909893036
Validation loss: 1.5924076675086893

Epoch: 5| Step: 1
Training loss: 0.17355993390083313
Validation loss: 1.5854504839066537

Epoch: 5| Step: 2
Training loss: 0.20532448589801788
Validation loss: 1.5648714547516198

Epoch: 5| Step: 3
Training loss: 0.18076202273368835
Validation loss: 1.5869870634489163

Epoch: 5| Step: 4
Training loss: 0.23382623493671417
Validation loss: 1.5917446446675125

Epoch: 5| Step: 5
Training loss: 0.2131289690732956
Validation loss: 1.6381577484069332

Epoch: 5| Step: 6
Training loss: 0.41136401891708374
Validation loss: 1.703532588097357

Epoch: 5| Step: 7
Training loss: 0.13724814355373383
Validation loss: 1.6656431703157322

Epoch: 5| Step: 8
Training loss: 0.16049343347549438
Validation loss: 1.6081969712370185

Epoch: 5| Step: 9
Training loss: 0.17079436779022217
Validation loss: 1.6247871857817455

Epoch: 5| Step: 10
Training loss: 0.22817891836166382
Validation loss: 1.6162598133087158

Epoch: 479| Step: 0
Training loss: 0.15574902296066284
Validation loss: 1.597711265728038

Epoch: 5| Step: 1
Training loss: 0.22926349937915802
Validation loss: 1.5681878905142508

Epoch: 5| Step: 2
Training loss: 0.18047666549682617
Validation loss: 1.583367968118319

Epoch: 5| Step: 3
Training loss: 0.2689207196235657
Validation loss: 1.591617859819884

Epoch: 5| Step: 4
Training loss: 0.17866499722003937
Validation loss: 1.5994135051645257

Epoch: 5| Step: 5
Training loss: 0.16453643143177032
Validation loss: 1.5881285744328653

Epoch: 5| Step: 6
Training loss: 0.1911526620388031
Validation loss: 1.5827307290928339

Epoch: 5| Step: 7
Training loss: 0.32623666524887085
Validation loss: 1.5624560117721558

Epoch: 5| Step: 8
Training loss: 0.2598273456096649
Validation loss: 1.5883038864340833

Epoch: 5| Step: 9
Training loss: 0.17158560454845428
Validation loss: 1.5705948157977032

Epoch: 5| Step: 10
Training loss: 0.19104860723018646
Validation loss: 1.575980168516918

Epoch: 480| Step: 0
Training loss: 0.22623014450073242
Validation loss: 1.5201951034607426

Epoch: 5| Step: 1
Training loss: 0.14937548339366913
Validation loss: 1.495113024147608

Epoch: 5| Step: 2
Training loss: 0.27979379892349243
Validation loss: 1.5060260552231983

Epoch: 5| Step: 3
Training loss: 0.20502415299415588
Validation loss: 1.5098491182891272

Epoch: 5| Step: 4
Training loss: 0.2874199450016022
Validation loss: 1.4825312937459638

Epoch: 5| Step: 5
Training loss: 0.301042377948761
Validation loss: 1.5234466201515608

Epoch: 5| Step: 6
Training loss: 0.2181912362575531
Validation loss: 1.5398643350088468

Epoch: 5| Step: 7
Training loss: 0.20405268669128418
Validation loss: 1.5607318352627497

Epoch: 5| Step: 8
Training loss: 0.2139522135257721
Validation loss: 1.5570019598930114

Epoch: 5| Step: 9
Training loss: 0.13379845023155212
Validation loss: 1.6026091806350216

Epoch: 5| Step: 10
Training loss: 0.31216296553611755
Validation loss: 1.6200934866423249

Epoch: 481| Step: 0
Training loss: 0.28704458475112915
Validation loss: 1.6070790989424593

Epoch: 5| Step: 1
Training loss: 0.17766442894935608
Validation loss: 1.5760628395183112

Epoch: 5| Step: 2
Training loss: 0.20651964843273163
Validation loss: 1.5706356584384877

Epoch: 5| Step: 3
Training loss: 0.16719460487365723
Validation loss: 1.5589310417893112

Epoch: 5| Step: 4
Training loss: 0.17015668749809265
Validation loss: 1.5489339533672537

Epoch: 5| Step: 5
Training loss: 0.1961040496826172
Validation loss: 1.5523432172754759

Epoch: 5| Step: 6
Training loss: 0.18936701118946075
Validation loss: 1.5673226592361287

Epoch: 5| Step: 7
Training loss: 0.21764083206653595
Validation loss: 1.5631489997269006

Epoch: 5| Step: 8
Training loss: 0.19288262724876404
Validation loss: 1.5498261913176505

Epoch: 5| Step: 9
Training loss: 0.2553751468658447
Validation loss: 1.5496312790019537

Epoch: 5| Step: 10
Training loss: 0.18839514255523682
Validation loss: 1.5727794631834953

Epoch: 482| Step: 0
Training loss: 0.16132095456123352
Validation loss: 1.605168463081442

Epoch: 5| Step: 1
Training loss: 0.18009573221206665
Validation loss: 1.637398619805613

Epoch: 5| Step: 2
Training loss: 0.1787150651216507
Validation loss: 1.6627425698823826

Epoch: 5| Step: 3
Training loss: 0.19832369685173035
Validation loss: 1.6806890785053212

Epoch: 5| Step: 4
Training loss: 0.21111467480659485
Validation loss: 1.6334127559456775

Epoch: 5| Step: 5
Training loss: 0.13513340055942535
Validation loss: 1.6179846422646635

Epoch: 5| Step: 6
Training loss: 0.2064243108034134
Validation loss: 1.5676112021169355

Epoch: 5| Step: 7
Training loss: 0.3736782670021057
Validation loss: 1.565531111532642

Epoch: 5| Step: 8
Training loss: 0.18172048032283783
Validation loss: 1.5707347489172412

Epoch: 5| Step: 9
Training loss: 0.19245918095111847
Validation loss: 1.580494729421472

Epoch: 5| Step: 10
Training loss: 0.2258622944355011
Validation loss: 1.579515549444383

Epoch: 483| Step: 0
Training loss: 0.28820928931236267
Validation loss: 1.5784109766765306

Epoch: 5| Step: 1
Training loss: 0.14590942859649658
Validation loss: 1.6246944415953852

Epoch: 5| Step: 2
Training loss: 0.20207086205482483
Validation loss: 1.6170178100626955

Epoch: 5| Step: 3
Training loss: 0.2320283204317093
Validation loss: 1.594460013092205

Epoch: 5| Step: 4
Training loss: 0.14121736586093903
Validation loss: 1.5979092710761613

Epoch: 5| Step: 5
Training loss: 0.12550798058509827
Validation loss: 1.5846102929884387

Epoch: 5| Step: 6
Training loss: 0.19570213556289673
Validation loss: 1.5687437557405042

Epoch: 5| Step: 7
Training loss: 0.14466220140457153
Validation loss: 1.5205706396410543

Epoch: 5| Step: 8
Training loss: 0.15308472514152527
Validation loss: 1.5273891572029359

Epoch: 5| Step: 9
Training loss: 0.18295426666736603
Validation loss: 1.540135819424865

Epoch: 5| Step: 10
Training loss: 0.25576063990592957
Validation loss: 1.5112916590065084

Epoch: 484| Step: 0
Training loss: 0.10878672450780869
Validation loss: 1.5426717265959708

Epoch: 5| Step: 1
Training loss: 0.08423544466495514
Validation loss: 1.5627543439147293

Epoch: 5| Step: 2
Training loss: 0.0942731648683548
Validation loss: 1.5447658236308763

Epoch: 5| Step: 3
Training loss: 0.17842653393745422
Validation loss: 1.5481521570554344

Epoch: 5| Step: 4
Training loss: 0.32697951793670654
Validation loss: 1.5654227297793153

Epoch: 5| Step: 5
Training loss: 0.1958874762058258
Validation loss: 1.6022868412797169

Epoch: 5| Step: 6
Training loss: 0.2817179560661316
Validation loss: 1.5877585411071777

Epoch: 5| Step: 7
Training loss: 0.22365924715995789
Validation loss: 1.605672372284756

Epoch: 5| Step: 8
Training loss: 0.19491052627563477
Validation loss: 1.6222319051783571

Epoch: 5| Step: 9
Training loss: 0.20946738123893738
Validation loss: 1.610122649900375

Epoch: 5| Step: 10
Training loss: 0.13199013471603394
Validation loss: 1.5686054216918124

Epoch: 485| Step: 0
Training loss: 0.13740858435630798
Validation loss: 1.5441314789556688

Epoch: 5| Step: 1
Training loss: 0.21076086163520813
Validation loss: 1.5597798439764208

Epoch: 5| Step: 2
Training loss: 0.2358286827802658
Validation loss: 1.5523912252918366

Epoch: 5| Step: 3
Training loss: 0.18718193471431732
Validation loss: 1.5785647182054416

Epoch: 5| Step: 4
Training loss: 0.18682625889778137
Validation loss: 1.5814774754226848

Epoch: 5| Step: 5
Training loss: 0.18697595596313477
Validation loss: 1.5756271769923549

Epoch: 5| Step: 6
Training loss: 0.28315281867980957
Validation loss: 1.5674518923605643

Epoch: 5| Step: 7
Training loss: 0.187393456697464
Validation loss: 1.6234499126352289

Epoch: 5| Step: 8
Training loss: 0.09942043572664261
Validation loss: 1.5997293033907491

Epoch: 5| Step: 9
Training loss: 0.1963982880115509
Validation loss: 1.5516318454537341

Epoch: 5| Step: 10
Training loss: 0.10675948858261108
Validation loss: 1.5421736035295712

Epoch: 486| Step: 0
Training loss: 0.12214789539575577
Validation loss: 1.599221589744732

Epoch: 5| Step: 1
Training loss: 0.11763998121023178
Validation loss: 1.6058282095898864

Epoch: 5| Step: 2
Training loss: 0.16806696355342865
Validation loss: 1.567217799925035

Epoch: 5| Step: 3
Training loss: 0.19185109436511993
Validation loss: 1.5462381519297117

Epoch: 5| Step: 4
Training loss: 0.2155774086713791
Validation loss: 1.5098371249373241

Epoch: 5| Step: 5
Training loss: 0.26451051235198975
Validation loss: 1.543878859089267

Epoch: 5| Step: 6
Training loss: 0.1767590492963791
Validation loss: 1.5159430298753964

Epoch: 5| Step: 7
Training loss: 0.24901151657104492
Validation loss: 1.5087478314676592

Epoch: 5| Step: 8
Training loss: 0.23775851726531982
Validation loss: 1.5447768357492262

Epoch: 5| Step: 9
Training loss: 0.15069083869457245
Validation loss: 1.5625164983093098

Epoch: 5| Step: 10
Training loss: 0.26175403594970703
Validation loss: 1.5960999534976097

Epoch: 487| Step: 0
Training loss: 0.1597132384777069
Validation loss: 1.6037632444853425

Epoch: 5| Step: 1
Training loss: 0.1861543357372284
Validation loss: 1.6393227077299548

Epoch: 5| Step: 2
Training loss: 0.21602661907672882
Validation loss: 1.6674843078018518

Epoch: 5| Step: 3
Training loss: 0.1773415505886078
Validation loss: 1.6627933613715633

Epoch: 5| Step: 4
Training loss: 0.18244986236095428
Validation loss: 1.6120640129171393

Epoch: 5| Step: 5
Training loss: 0.3393775522708893
Validation loss: 1.5935106751739339

Epoch: 5| Step: 6
Training loss: 0.17110343277454376
Validation loss: 1.6074763408271215

Epoch: 5| Step: 7
Training loss: 0.16901949048042297
Validation loss: 1.5834608424094416

Epoch: 5| Step: 8
Training loss: 0.168498694896698
Validation loss: 1.549518790296329

Epoch: 5| Step: 9
Training loss: 0.19291505217552185
Validation loss: 1.5362156885926441

Epoch: 5| Step: 10
Training loss: 0.18214833736419678
Validation loss: 1.5194717184189828

Epoch: 488| Step: 0
Training loss: 0.20194140076637268
Validation loss: 1.5565826540352197

Epoch: 5| Step: 1
Training loss: 0.21691489219665527
Validation loss: 1.5408268013308126

Epoch: 5| Step: 2
Training loss: 0.2168910950422287
Validation loss: 1.5594962335401965

Epoch: 5| Step: 3
Training loss: 0.11021026223897934
Validation loss: 1.540254492272613

Epoch: 5| Step: 4
Training loss: 0.22762593626976013
Validation loss: 1.5898112417549215

Epoch: 5| Step: 5
Training loss: 0.29140764474868774
Validation loss: 1.5708532307737617

Epoch: 5| Step: 6
Training loss: 0.19037096202373505
Validation loss: 1.6114805898358744

Epoch: 5| Step: 7
Training loss: 0.16740566492080688
Validation loss: 1.6189528255052463

Epoch: 5| Step: 8
Training loss: 0.12716148793697357
Validation loss: 1.6242593026930285

Epoch: 5| Step: 9
Training loss: 0.2029884308576584
Validation loss: 1.599791403739683

Epoch: 5| Step: 10
Training loss: 0.17520135641098022
Validation loss: 1.5740982986265613

Epoch: 489| Step: 0
Training loss: 0.1572991907596588
Validation loss: 1.5647803685998405

Epoch: 5| Step: 1
Training loss: 0.14828264713287354
Validation loss: 1.5604271337550173

Epoch: 5| Step: 2
Training loss: 0.22590985894203186
Validation loss: 1.597788877384637

Epoch: 5| Step: 3
Training loss: 0.27424314618110657
Validation loss: 1.5850054967787959

Epoch: 5| Step: 4
Training loss: 0.18128825724124908
Validation loss: 1.5534108582363333

Epoch: 5| Step: 5
Training loss: 0.12489935010671616
Validation loss: 1.534103689655181

Epoch: 5| Step: 6
Training loss: 0.25400248169898987
Validation loss: 1.5163714385801745

Epoch: 5| Step: 7
Training loss: 0.1260184645652771
Validation loss: 1.568088294357382

Epoch: 5| Step: 8
Training loss: 0.15975406765937805
Validation loss: 1.517097685926704

Epoch: 5| Step: 9
Training loss: 0.10589703172445297
Validation loss: 1.581307436830254

Epoch: 5| Step: 10
Training loss: 0.24915167689323425
Validation loss: 1.5970935590805546

Epoch: 490| Step: 0
Training loss: 0.20510438084602356
Validation loss: 1.6219755705966745

Epoch: 5| Step: 1
Training loss: 0.11243468523025513
Validation loss: 1.5998991804738198

Epoch: 5| Step: 2
Training loss: 0.12856736779212952
Validation loss: 1.6289284588188253

Epoch: 5| Step: 3
Training loss: 0.2641029953956604
Validation loss: 1.618750299176862

Epoch: 5| Step: 4
Training loss: 0.11733856052160263
Validation loss: 1.586734620473718

Epoch: 5| Step: 5
Training loss: 0.14587584137916565
Validation loss: 1.5880157280993719

Epoch: 5| Step: 6
Training loss: 0.16290633380413055
Validation loss: 1.6056491431369577

Epoch: 5| Step: 7
Training loss: 0.1472150683403015
Validation loss: 1.5877334558835594

Epoch: 5| Step: 8
Training loss: 0.10342057049274445
Validation loss: 1.5527801872581564

Epoch: 5| Step: 9
Training loss: 0.27154746651649475
Validation loss: 1.5364406147310812

Epoch: 5| Step: 10
Training loss: 0.20186370611190796
Validation loss: 1.5597004005985875

Epoch: 491| Step: 0
Training loss: 0.2265067994594574
Validation loss: 1.5401886547765424

Epoch: 5| Step: 1
Training loss: 0.19309814274311066
Validation loss: 1.5438190942169518

Epoch: 5| Step: 2
Training loss: 0.1498500406742096
Validation loss: 1.4945894364387757

Epoch: 5| Step: 3
Training loss: 0.11675465106964111
Validation loss: 1.5065056265041392

Epoch: 5| Step: 4
Training loss: 0.11794338375329971
Validation loss: 1.5130407899938605

Epoch: 5| Step: 5
Training loss: 0.21779115498065948
Validation loss: 1.5091338337108653

Epoch: 5| Step: 6
Training loss: 0.18162301182746887
Validation loss: 1.519818114978011

Epoch: 5| Step: 7
Training loss: 0.12992718815803528
Validation loss: 1.5267979739814677

Epoch: 5| Step: 8
Training loss: 0.1746043711900711
Validation loss: 1.5350499306955645

Epoch: 5| Step: 9
Training loss: 0.19038300216197968
Validation loss: 1.5579246679941814

Epoch: 5| Step: 10
Training loss: 0.09644338488578796
Validation loss: 1.5808788563615532

Epoch: 492| Step: 0
Training loss: 0.14555269479751587
Validation loss: 1.5906948594636814

Epoch: 5| Step: 1
Training loss: 0.33199653029441833
Validation loss: 1.5584929207319855

Epoch: 5| Step: 2
Training loss: 0.14800705015659332
Validation loss: 1.5777699549992878

Epoch: 5| Step: 3
Training loss: 0.19061343371868134
Validation loss: 1.5892510907624358

Epoch: 5| Step: 4
Training loss: 0.15272603929042816
Validation loss: 1.5667370480875815

Epoch: 5| Step: 5
Training loss: 0.20126847922801971
Validation loss: 1.577439033856956

Epoch: 5| Step: 6
Training loss: 0.17592276632785797
Validation loss: 1.525258897453226

Epoch: 5| Step: 7
Training loss: 0.1741453856229782
Validation loss: 1.5634830100561983

Epoch: 5| Step: 8
Training loss: 0.12091487646102905
Validation loss: 1.5518852459487094

Epoch: 5| Step: 9
Training loss: 0.13472256064414978
Validation loss: 1.547892503840949

Epoch: 5| Step: 10
Training loss: 0.11742616444826126
Validation loss: 1.560964612550633

Epoch: 493| Step: 0
Training loss: 0.11285527050495148
Validation loss: 1.5750163473108763

Epoch: 5| Step: 1
Training loss: 0.11794189363718033
Validation loss: 1.5850630421792307

Epoch: 5| Step: 2
Training loss: 0.21988575160503387
Validation loss: 1.6165654146543114

Epoch: 5| Step: 3
Training loss: 0.21828308701515198
Validation loss: 1.6111374362822501

Epoch: 5| Step: 4
Training loss: 0.2184041440486908
Validation loss: 1.5597589349233976

Epoch: 5| Step: 5
Training loss: 0.2149968445301056
Validation loss: 1.5731043533612323

Epoch: 5| Step: 6
Training loss: 0.12180930376052856
Validation loss: 1.5481616450894264

Epoch: 5| Step: 7
Training loss: 0.258387953042984
Validation loss: 1.5737772782643635

Epoch: 5| Step: 8
Training loss: 0.20790281891822815
Validation loss: 1.5629681118073002

Epoch: 5| Step: 9
Training loss: 0.1227799654006958
Validation loss: 1.5771971735903012

Epoch: 5| Step: 10
Training loss: 0.15209943056106567
Validation loss: 1.5911803578817716

Epoch: 494| Step: 0
Training loss: 0.19793422520160675
Validation loss: 1.5870963937492781

Epoch: 5| Step: 1
Training loss: 0.16003964841365814
Validation loss: 1.6000573045463973

Epoch: 5| Step: 2
Training loss: 0.16548985242843628
Validation loss: 1.6237368404224355

Epoch: 5| Step: 3
Training loss: 0.195601224899292
Validation loss: 1.577815596775342

Epoch: 5| Step: 4
Training loss: 0.128921240568161
Validation loss: 1.5840245651942428

Epoch: 5| Step: 5
Training loss: 0.17051663994789124
Validation loss: 1.5818286377896544

Epoch: 5| Step: 6
Training loss: 0.09425173699855804
Validation loss: 1.591889985146061

Epoch: 5| Step: 7
Training loss: 0.20352931320667267
Validation loss: 1.5466427136492986

Epoch: 5| Step: 8
Training loss: 0.14657267928123474
Validation loss: 1.5432649466299242

Epoch: 5| Step: 9
Training loss: 0.3027147054672241
Validation loss: 1.5563805410938878

Epoch: 5| Step: 10
Training loss: 0.21570990979671478
Validation loss: 1.5539587825857184

Epoch: 495| Step: 0
Training loss: 0.2219226360321045
Validation loss: 1.5275426628769084

Epoch: 5| Step: 1
Training loss: 0.10851442813873291
Validation loss: 1.5414240219259774

Epoch: 5| Step: 2
Training loss: 0.254239946603775
Validation loss: 1.5575203837886933

Epoch: 5| Step: 3
Training loss: 0.1294938325881958
Validation loss: 1.5547227782587851

Epoch: 5| Step: 4
Training loss: 0.11022289842367172
Validation loss: 1.5457206874765375

Epoch: 5| Step: 5
Training loss: 0.14801359176635742
Validation loss: 1.560677147039803

Epoch: 5| Step: 6
Training loss: 0.15576915442943573
Validation loss: 1.595923553230942

Epoch: 5| Step: 7
Training loss: 0.1231783777475357
Validation loss: 1.588809876031773

Epoch: 5| Step: 8
Training loss: 0.21201591193675995
Validation loss: 1.5761138354578326

Epoch: 5| Step: 9
Training loss: 0.13084512948989868
Validation loss: 1.557848858576949

Epoch: 5| Step: 10
Training loss: 0.14191263914108276
Validation loss: 1.5660472531472482

Epoch: 496| Step: 0
Training loss: 0.15837180614471436
Validation loss: 1.560506586105593

Epoch: 5| Step: 1
Training loss: 0.10728617757558823
Validation loss: 1.5491072747015184

Epoch: 5| Step: 2
Training loss: 0.18690195679664612
Validation loss: 1.562016083348182

Epoch: 5| Step: 3
Training loss: 0.12804538011550903
Validation loss: 1.5598598577642953

Epoch: 5| Step: 4
Training loss: 0.17427276074886322
Validation loss: 1.5495562450860136

Epoch: 5| Step: 5
Training loss: 0.1274692714214325
Validation loss: 1.5740516544670187

Epoch: 5| Step: 6
Training loss: 0.07267379760742188
Validation loss: 1.5593884683424426

Epoch: 5| Step: 7
Training loss: 0.16239044070243835
Validation loss: 1.6087691905677959

Epoch: 5| Step: 8
Training loss: 0.15488186478614807
Validation loss: 1.5786841338680637

Epoch: 5| Step: 9
Training loss: 0.23206576704978943
Validation loss: 1.5957295458803895

Epoch: 5| Step: 10
Training loss: 0.24243293702602386
Validation loss: 1.6364149201300837

Epoch: 497| Step: 0
Training loss: 0.20355406403541565
Validation loss: 1.6065913964343328

Epoch: 5| Step: 1
Training loss: 0.28001755475997925
Validation loss: 1.6183263794068368

Epoch: 5| Step: 2
Training loss: 0.1888352334499359
Validation loss: 1.5850597036782132

Epoch: 5| Step: 3
Training loss: 0.14795854687690735
Validation loss: 1.6062110175368607

Epoch: 5| Step: 4
Training loss: 0.14447021484375
Validation loss: 1.5878206235106274

Epoch: 5| Step: 5
Training loss: 0.08999086916446686
Validation loss: 1.5775252234551214

Epoch: 5| Step: 6
Training loss: 0.11909157037734985
Validation loss: 1.5987686726354784

Epoch: 5| Step: 7
Training loss: 0.29110345244407654
Validation loss: 1.5816372043343

Epoch: 5| Step: 8
Training loss: 0.10034038871526718
Validation loss: 1.5581177678159488

Epoch: 5| Step: 9
Training loss: 0.13597217202186584
Validation loss: 1.5664661571543703

Epoch: 5| Step: 10
Training loss: 0.1398366242647171
Validation loss: 1.5785003580072874

Epoch: 498| Step: 0
Training loss: 0.4399549067020416
Validation loss: 1.571556592500338

Epoch: 5| Step: 1
Training loss: 0.11518730223178864
Validation loss: 1.6017583236899426

Epoch: 5| Step: 2
Training loss: 0.17990033328533173
Validation loss: 1.5742507621806154

Epoch: 5| Step: 3
Training loss: 0.1397593468427658
Validation loss: 1.5297162673806632

Epoch: 5| Step: 4
Training loss: 0.10658178478479385
Validation loss: 1.5263005866799304

Epoch: 5| Step: 5
Training loss: 0.12405413389205933
Validation loss: 1.4913716803314865

Epoch: 5| Step: 6
Training loss: 0.21530234813690186
Validation loss: 1.5373464592041508

Epoch: 5| Step: 7
Training loss: 0.20405757427215576
Validation loss: 1.5331116978840162

Epoch: 5| Step: 8
Training loss: 0.20964090526103973
Validation loss: 1.533487505810235

Epoch: 5| Step: 9
Training loss: 0.1649472415447235
Validation loss: 1.5281163601465122

Epoch: 5| Step: 10
Training loss: 0.1954466551542282
Validation loss: 1.5724184359273603

Epoch: 499| Step: 0
Training loss: 0.17412744462490082
Validation loss: 1.5685423138321086

Epoch: 5| Step: 1
Training loss: 0.09279090911149979
Validation loss: 1.5361838635577951

Epoch: 5| Step: 2
Training loss: 0.20009195804595947
Validation loss: 1.5401394674854894

Epoch: 5| Step: 3
Training loss: 0.22727611660957336
Validation loss: 1.527241847367697

Epoch: 5| Step: 4
Training loss: 0.14914295077323914
Validation loss: 1.560578998698983

Epoch: 5| Step: 5
Training loss: 0.17182675004005432
Validation loss: 1.6028974184425928

Epoch: 5| Step: 6
Training loss: 0.12124589830636978
Validation loss: 1.5981467244445637

Epoch: 5| Step: 7
Training loss: 0.16172799468040466
Validation loss: 1.5617595449570687

Epoch: 5| Step: 8
Training loss: 0.18707679212093353
Validation loss: 1.5615674577733523

Epoch: 5| Step: 9
Training loss: 0.3408166766166687
Validation loss: 1.5344164243308447

Epoch: 5| Step: 10
Training loss: 0.12418662756681442
Validation loss: 1.5597707866340556

Epoch: 500| Step: 0
Training loss: 0.28373709321022034
Validation loss: 1.5741345831142959

Epoch: 5| Step: 1
Training loss: 0.16022764146327972
Validation loss: 1.551927710092196

Epoch: 5| Step: 2
Training loss: 0.16834349930286407
Validation loss: 1.5592675388500254

Epoch: 5| Step: 3
Training loss: 0.0928528755903244
Validation loss: 1.576619925037507

Epoch: 5| Step: 4
Training loss: 0.19647231698036194
Validation loss: 1.6235406398773193

Epoch: 5| Step: 5
Training loss: 0.24936659634113312
Validation loss: 1.6118783809805428

Epoch: 5| Step: 6
Training loss: 0.3174232840538025
Validation loss: 1.6337448063717093

Epoch: 5| Step: 7
Training loss: 0.20789070427417755
Validation loss: 1.6128858174047163

Epoch: 5| Step: 8
Training loss: 0.11263749748468399
Validation loss: 1.5988627838832077

Epoch: 5| Step: 9
Training loss: 0.11019941419363022
Validation loss: 1.574680737269822

Epoch: 5| Step: 10
Training loss: 0.1646548956632614
Validation loss: 1.6084412695259176

Testing loss: 1.976441012488471
