Epoch: 1| Step: 0
Training loss: 5.1154375076293945
Validation loss: 5.252194179001675

Epoch: 5| Step: 1
Training loss: 6.11565637588501
Validation loss: 5.23814030103786

Epoch: 5| Step: 2
Training loss: 5.181143760681152
Validation loss: 5.225116581045171

Epoch: 5| Step: 3
Training loss: 4.592301368713379
Validation loss: 5.211407538383238

Epoch: 5| Step: 4
Training loss: 5.983283042907715
Validation loss: 5.196840901528636

Epoch: 5| Step: 5
Training loss: 5.2963972091674805
Validation loss: 5.179710716329595

Epoch: 5| Step: 6
Training loss: 4.329987525939941
Validation loss: 5.160178651091873

Epoch: 5| Step: 7
Training loss: 5.105646133422852
Validation loss: 5.1377820199535735

Epoch: 5| Step: 8
Training loss: 4.083021640777588
Validation loss: 5.111711286729382

Epoch: 5| Step: 9
Training loss: 4.394850730895996
Validation loss: 5.0805354169619985

Epoch: 5| Step: 10
Training loss: 4.332089900970459
Validation loss: 5.045822830610378

Epoch: 2| Step: 0
Training loss: 4.950748920440674
Validation loss: 5.007041515842561

Epoch: 5| Step: 1
Training loss: 5.067242622375488
Validation loss: 4.9630125978941555

Epoch: 5| Step: 2
Training loss: 5.088709831237793
Validation loss: 4.914521417310161

Epoch: 5| Step: 3
Training loss: 3.6550230979919434
Validation loss: 4.861110794928766

Epoch: 5| Step: 4
Training loss: 4.40174674987793
Validation loss: 4.802072196878413

Epoch: 5| Step: 5
Training loss: 5.238043785095215
Validation loss: 4.7396186961922595

Epoch: 5| Step: 6
Training loss: 4.453847885131836
Validation loss: 4.672731030371882

Epoch: 5| Step: 7
Training loss: 4.043704032897949
Validation loss: 4.6030851897373

Epoch: 5| Step: 8
Training loss: 4.453666687011719
Validation loss: 4.533116402164582

Epoch: 5| Step: 9
Training loss: 3.3412132263183594
Validation loss: 4.464864577016523

Epoch: 5| Step: 10
Training loss: 5.057725429534912
Validation loss: 4.396799241342852

Epoch: 3| Step: 0
Training loss: 3.2939865589141846
Validation loss: 4.335740332962365

Epoch: 5| Step: 1
Training loss: 4.9640793800354
Validation loss: 4.277106941387218

Epoch: 5| Step: 2
Training loss: 4.259591102600098
Validation loss: 4.222792048608103

Epoch: 5| Step: 3
Training loss: 4.478289604187012
Validation loss: 4.1726076936209076

Epoch: 5| Step: 4
Training loss: 4.163724422454834
Validation loss: 4.124597041837631

Epoch: 5| Step: 5
Training loss: 3.7645156383514404
Validation loss: 4.082334703014743

Epoch: 5| Step: 6
Training loss: 3.764549732208252
Validation loss: 4.041217727045859

Epoch: 5| Step: 7
Training loss: 2.9725255966186523
Validation loss: 4.0040211985188146

Epoch: 5| Step: 8
Training loss: 2.6501567363739014
Validation loss: 3.970035245341639

Epoch: 5| Step: 9
Training loss: 5.314085483551025
Validation loss: 3.939336745969711

Epoch: 5| Step: 10
Training loss: 3.591660499572754
Validation loss: 3.9064994063428653

Epoch: 4| Step: 0
Training loss: 4.225577354431152
Validation loss: 3.880678351207446

Epoch: 5| Step: 1
Training loss: 3.3882153034210205
Validation loss: 3.8559399804761334

Epoch: 5| Step: 2
Training loss: 3.0951523780822754
Validation loss: 3.8334928738173617

Epoch: 5| Step: 3
Training loss: 4.34323263168335
Validation loss: 3.810844124004405

Epoch: 5| Step: 4
Training loss: 4.060548305511475
Validation loss: 3.787454920430337

Epoch: 5| Step: 5
Training loss: 2.8225245475769043
Validation loss: 3.770016670227051

Epoch: 5| Step: 6
Training loss: 4.050745010375977
Validation loss: 3.751739501953125

Epoch: 5| Step: 7
Training loss: 3.30176043510437
Validation loss: 3.735198764390843

Epoch: 5| Step: 8
Training loss: 3.5812652111053467
Validation loss: 3.713079280750726

Epoch: 5| Step: 9
Training loss: 4.051650047302246
Validation loss: 3.6923429043062272

Epoch: 5| Step: 10
Training loss: 3.2928249835968018
Validation loss: 3.6712030467166694

Epoch: 5| Step: 0
Training loss: 3.59916615486145
Validation loss: 3.656453094174785

Epoch: 5| Step: 1
Training loss: 3.376645565032959
Validation loss: 3.641361654445689

Epoch: 5| Step: 2
Training loss: 4.0221381187438965
Validation loss: 3.6306577190276115

Epoch: 5| Step: 3
Training loss: 3.6178462505340576
Validation loss: 3.622836797468124

Epoch: 5| Step: 4
Training loss: 3.488393783569336
Validation loss: 3.611477067393641

Epoch: 5| Step: 5
Training loss: 3.0726966857910156
Validation loss: 3.6014232994407736

Epoch: 5| Step: 6
Training loss: 2.783310651779175
Validation loss: 3.588705237193774

Epoch: 5| Step: 7
Training loss: 3.762126922607422
Validation loss: 3.5742016043714298

Epoch: 5| Step: 8
Training loss: 3.6697139739990234
Validation loss: 3.559512189639512

Epoch: 5| Step: 9
Training loss: 3.9056637287139893
Validation loss: 3.5496201105015253

Epoch: 5| Step: 10
Training loss: 3.4312877655029297
Validation loss: 3.5352870033633326

Epoch: 6| Step: 0
Training loss: 3.2828032970428467
Validation loss: 3.5237345259676696

Epoch: 5| Step: 1
Training loss: 4.032925605773926
Validation loss: 3.511281972290367

Epoch: 5| Step: 2
Training loss: 3.987776279449463
Validation loss: 3.49781919294788

Epoch: 5| Step: 3
Training loss: 3.150683641433716
Validation loss: 3.4841335665795112

Epoch: 5| Step: 4
Training loss: 3.486799955368042
Validation loss: 3.4647870525237052

Epoch: 5| Step: 5
Training loss: 2.6456284523010254
Validation loss: 3.4482151667277017

Epoch: 5| Step: 6
Training loss: 3.934450626373291
Validation loss: 3.4335476634322957

Epoch: 5| Step: 7
Training loss: 3.8956940174102783
Validation loss: 3.4200649440929456

Epoch: 5| Step: 8
Training loss: 3.418647050857544
Validation loss: 3.408036462722286

Epoch: 5| Step: 9
Training loss: 3.0851023197174072
Validation loss: 3.3954284729496127

Epoch: 5| Step: 10
Training loss: 2.3640995025634766
Validation loss: 3.392300272500643

Epoch: 7| Step: 0
Training loss: 3.10254168510437
Validation loss: 3.384746533568187

Epoch: 5| Step: 1
Training loss: 3.6727333068847656
Validation loss: 3.3809940840608332

Epoch: 5| Step: 2
Training loss: 3.205359697341919
Validation loss: 3.3716047451060307

Epoch: 5| Step: 3
Training loss: 2.9677071571350098
Validation loss: 3.34782434791647

Epoch: 5| Step: 4
Training loss: 3.113647937774658
Validation loss: 3.3338553238940496

Epoch: 5| Step: 5
Training loss: 3.621147871017456
Validation loss: 3.3314959695262294

Epoch: 5| Step: 6
Training loss: 4.039697647094727
Validation loss: 3.312347581309657

Epoch: 5| Step: 7
Training loss: 2.888118267059326
Validation loss: 3.302096918065061

Epoch: 5| Step: 8
Training loss: 3.4617438316345215
Validation loss: 3.289702741048669

Epoch: 5| Step: 9
Training loss: 2.9921481609344482
Validation loss: 3.286316761406519

Epoch: 5| Step: 10
Training loss: 3.1519269943237305
Validation loss: 3.2724533645055627

Epoch: 8| Step: 0
Training loss: 3.441633701324463
Validation loss: 3.2511000581966933

Epoch: 5| Step: 1
Training loss: 3.140293836593628
Validation loss: 3.240654806936941

Epoch: 5| Step: 2
Training loss: 3.1152074337005615
Validation loss: 3.251024458997993

Epoch: 5| Step: 3
Training loss: 4.178811073303223
Validation loss: 3.218414132313062

Epoch: 5| Step: 4
Training loss: 3.8864684104919434
Validation loss: 3.2119576700272097

Epoch: 5| Step: 5
Training loss: 2.0524423122406006
Validation loss: 3.205628897554131

Epoch: 5| Step: 6
Training loss: 3.59393048286438
Validation loss: 3.208644349087951

Epoch: 5| Step: 7
Training loss: 3.2502150535583496
Validation loss: 3.1927310061711136

Epoch: 5| Step: 8
Training loss: 2.5730159282684326
Validation loss: 3.1837697285477833

Epoch: 5| Step: 9
Training loss: 3.24303936958313
Validation loss: 3.1761781784795944

Epoch: 5| Step: 10
Training loss: 2.71270751953125
Validation loss: 3.1672041211076962

Epoch: 9| Step: 0
Training loss: 2.9911258220672607
Validation loss: 3.16354735179614

Epoch: 5| Step: 1
Training loss: 3.024047374725342
Validation loss: 3.1592939130721556

Epoch: 5| Step: 2
Training loss: 3.0492987632751465
Validation loss: 3.144926042966945

Epoch: 5| Step: 3
Training loss: 3.646315097808838
Validation loss: 3.142359907909106

Epoch: 5| Step: 4
Training loss: 3.0345053672790527
Validation loss: 3.129118655317573

Epoch: 5| Step: 5
Training loss: 2.4677255153656006
Validation loss: 3.111209943730344

Epoch: 5| Step: 6
Training loss: 3.2264435291290283
Validation loss: 3.109209096559914

Epoch: 5| Step: 7
Training loss: 3.367863416671753
Validation loss: 3.1246345376455658

Epoch: 5| Step: 8
Training loss: 3.120603322982788
Validation loss: 3.089560595891809

Epoch: 5| Step: 9
Training loss: 3.4196178913116455
Validation loss: 3.0986087424780733

Epoch: 5| Step: 10
Training loss: 3.240293502807617
Validation loss: 3.084309216468565

Epoch: 10| Step: 0
Training loss: 3.400904417037964
Validation loss: 3.0818322320138254

Epoch: 5| Step: 1
Training loss: 2.5798277854919434
Validation loss: 3.0771450150397515

Epoch: 5| Step: 2
Training loss: 2.687206268310547
Validation loss: 3.072938408902896

Epoch: 5| Step: 3
Training loss: 3.244628429412842
Validation loss: 3.0679806073506675

Epoch: 5| Step: 4
Training loss: 3.606976270675659
Validation loss: 3.063458918243326

Epoch: 5| Step: 5
Training loss: 2.0510165691375732
Validation loss: 3.0444833719602196

Epoch: 5| Step: 6
Training loss: 3.210930347442627
Validation loss: 3.048271556054392

Epoch: 5| Step: 7
Training loss: 2.97314453125
Validation loss: 3.0358609230287614

Epoch: 5| Step: 8
Training loss: 3.083188533782959
Validation loss: 3.0328541827458206

Epoch: 5| Step: 9
Training loss: 3.6497223377227783
Validation loss: 3.03097193215483

Epoch: 5| Step: 10
Training loss: 3.6371166706085205
Validation loss: 3.020023360047289

Epoch: 11| Step: 0
Training loss: 2.702730655670166
Validation loss: 3.00951325508856

Epoch: 5| Step: 1
Training loss: 3.7695720195770264
Validation loss: 3.005810183863486

Epoch: 5| Step: 2
Training loss: 3.1868515014648438
Validation loss: 3.001619077497913

Epoch: 5| Step: 3
Training loss: 3.207209825515747
Validation loss: 2.999071305797946

Epoch: 5| Step: 4
Training loss: 2.931473970413208
Validation loss: 2.991629877398091

Epoch: 5| Step: 5
Training loss: 2.8815557956695557
Validation loss: 2.9886671317520963

Epoch: 5| Step: 6
Training loss: 2.8724732398986816
Validation loss: 2.984621532501713

Epoch: 5| Step: 7
Training loss: 4.860715389251709
Validation loss: 2.9794617417038127

Epoch: 5| Step: 8
Training loss: 2.19386625289917
Validation loss: 2.977452778047131

Epoch: 5| Step: 9
Training loss: 2.845722198486328
Validation loss: 2.997480530892649

Epoch: 5| Step: 10
Training loss: 2.095771312713623
Validation loss: 3.013712703540761

Epoch: 12| Step: 0
Training loss: 2.8546738624572754
Validation loss: 3.011214840796686

Epoch: 5| Step: 1
Training loss: 2.282379150390625
Validation loss: 3.0117730530359412

Epoch: 5| Step: 2
Training loss: 4.019643306732178
Validation loss: 3.0425679734958115

Epoch: 5| Step: 3
Training loss: 2.94097638130188
Validation loss: 2.9994170409376903

Epoch: 5| Step: 4
Training loss: 3.3330929279327393
Validation loss: 3.004026469363961

Epoch: 5| Step: 5
Training loss: 2.8667473793029785
Validation loss: 3.0063729875831195

Epoch: 5| Step: 6
Training loss: 3.069427967071533
Validation loss: 3.003755223366522

Epoch: 5| Step: 7
Training loss: 3.43864369392395
Validation loss: 3.001057119779689

Epoch: 5| Step: 8
Training loss: 3.55854868888855
Validation loss: 2.9922412595441266

Epoch: 5| Step: 9
Training loss: 2.4343647956848145
Validation loss: 2.9684390739728044

Epoch: 5| Step: 10
Training loss: 2.9796016216278076
Validation loss: 2.9563424535976943

Epoch: 13| Step: 0
Training loss: 3.2025933265686035
Validation loss: 2.9522639961652857

Epoch: 5| Step: 1
Training loss: 3.8387539386749268
Validation loss: 2.9547522939661497

Epoch: 5| Step: 2
Training loss: 1.783352255821228
Validation loss: 2.9500181187865553

Epoch: 5| Step: 3
Training loss: 2.959604024887085
Validation loss: 2.9498896316815446

Epoch: 5| Step: 4
Training loss: 3.2235825061798096
Validation loss: 2.9486835310536046

Epoch: 5| Step: 5
Training loss: 3.815727710723877
Validation loss: 2.9511621664929133

Epoch: 5| Step: 6
Training loss: 2.271451234817505
Validation loss: 2.951471915809057

Epoch: 5| Step: 7
Training loss: 2.9060349464416504
Validation loss: 2.9495151248029483

Epoch: 5| Step: 8
Training loss: 3.085514783859253
Validation loss: 2.9456681795017694

Epoch: 5| Step: 9
Training loss: 3.101536512374878
Validation loss: 2.9451890837761665

Epoch: 5| Step: 10
Training loss: 3.1701104640960693
Validation loss: 2.9406537855825117

Epoch: 14| Step: 0
Training loss: 2.854365825653076
Validation loss: 2.930684599825131

Epoch: 5| Step: 1
Training loss: 3.3144359588623047
Validation loss: 2.9252089685009373

Epoch: 5| Step: 2
Training loss: 3.6273581981658936
Validation loss: 2.9338304253034693

Epoch: 5| Step: 3
Training loss: 2.5476021766662598
Validation loss: 2.937140880092498

Epoch: 5| Step: 4
Training loss: 2.4517662525177
Validation loss: 2.94488121873589

Epoch: 5| Step: 5
Training loss: 2.29022216796875
Validation loss: 2.9438639071679886

Epoch: 5| Step: 6
Training loss: 4.083338737487793
Validation loss: 2.934419811412852

Epoch: 5| Step: 7
Training loss: 3.251202344894409
Validation loss: 2.918841049235354

Epoch: 5| Step: 8
Training loss: 2.437180757522583
Validation loss: 2.9155251851645847

Epoch: 5| Step: 9
Training loss: 3.4331653118133545
Validation loss: 2.9224367269905667

Epoch: 5| Step: 10
Training loss: 2.878082752227783
Validation loss: 2.928303705748691

Epoch: 15| Step: 0
Training loss: 2.647813558578491
Validation loss: 2.922405286501813

Epoch: 5| Step: 1
Training loss: 2.804413080215454
Validation loss: 2.912864218475998

Epoch: 5| Step: 2
Training loss: 2.5861384868621826
Validation loss: 2.908053275077574

Epoch: 5| Step: 3
Training loss: 3.4131088256835938
Validation loss: 2.9067224123144664

Epoch: 5| Step: 4
Training loss: 3.551487684249878
Validation loss: 2.9109940477596816

Epoch: 5| Step: 5
Training loss: 3.2413489818573
Validation loss: 2.9067533503296556

Epoch: 5| Step: 6
Training loss: 2.9264960289001465
Validation loss: 2.9055061801787345

Epoch: 5| Step: 7
Training loss: 2.837311029434204
Validation loss: 2.9032975781348442

Epoch: 5| Step: 8
Training loss: 3.1077001094818115
Validation loss: 2.8993643329989527

Epoch: 5| Step: 9
Training loss: 3.084352970123291
Validation loss: 2.898549715677897

Epoch: 5| Step: 10
Training loss: 2.8630964756011963
Validation loss: 2.8987689146431546

Epoch: 16| Step: 0
Training loss: 2.5299105644226074
Validation loss: 2.9006519573991016

Epoch: 5| Step: 1
Training loss: 2.741712808609009
Validation loss: 2.9013450863540813

Epoch: 5| Step: 2
Training loss: 3.570709228515625
Validation loss: 2.9004202068492932

Epoch: 5| Step: 3
Training loss: 2.988356113433838
Validation loss: 2.8982531870565107

Epoch: 5| Step: 4
Training loss: 3.1467742919921875
Validation loss: 2.894676080314062

Epoch: 5| Step: 5
Training loss: 3.070533037185669
Validation loss: 2.8934766015698834

Epoch: 5| Step: 6
Training loss: 2.4866909980773926
Validation loss: 2.904057313037175

Epoch: 5| Step: 7
Training loss: 3.408093214035034
Validation loss: 2.915953469532792

Epoch: 5| Step: 8
Training loss: 3.153052806854248
Validation loss: 2.9238206801875943

Epoch: 5| Step: 9
Training loss: 2.7702527046203613
Validation loss: 2.941539700313281

Epoch: 5| Step: 10
Training loss: 3.0876829624176025
Validation loss: 2.9565995431715444

Epoch: 17| Step: 0
Training loss: 3.1718838214874268
Validation loss: 2.9226861922971663

Epoch: 5| Step: 1
Training loss: 2.7948784828186035
Validation loss: 2.883170768778811

Epoch: 5| Step: 2
Training loss: 2.6820499897003174
Validation loss: 2.87893190691548

Epoch: 5| Step: 3
Training loss: 2.6711528301239014
Validation loss: 2.8795822769083004

Epoch: 5| Step: 4
Training loss: 2.104959011077881
Validation loss: 2.878860899197158

Epoch: 5| Step: 5
Training loss: 3.075671672821045
Validation loss: 2.886300007502238

Epoch: 5| Step: 6
Training loss: 2.382002353668213
Validation loss: 2.8737639252857496

Epoch: 5| Step: 7
Training loss: 3.282052516937256
Validation loss: 2.8741886385025515

Epoch: 5| Step: 8
Training loss: 4.511918544769287
Validation loss: 2.8875357027976745

Epoch: 5| Step: 9
Training loss: 3.3491885662078857
Validation loss: 2.8929139285959224

Epoch: 5| Step: 10
Training loss: 2.74705171585083
Validation loss: 2.886444663488737

Epoch: 18| Step: 0
Training loss: 2.893230438232422
Validation loss: 2.8640428563599944

Epoch: 5| Step: 1
Training loss: 2.8402462005615234
Validation loss: 2.854229957826676

Epoch: 5| Step: 2
Training loss: 3.5653977394104004
Validation loss: 2.842119493792134

Epoch: 5| Step: 3
Training loss: 2.6089248657226562
Validation loss: 2.843605374777189

Epoch: 5| Step: 4
Training loss: 2.612349271774292
Validation loss: 2.8397762006328953

Epoch: 5| Step: 5
Training loss: 2.629035472869873
Validation loss: 2.8437620875655965

Epoch: 5| Step: 6
Training loss: 3.7659308910369873
Validation loss: 2.937424600765269

Epoch: 5| Step: 7
Training loss: 2.494880199432373
Validation loss: 2.978286148399435

Epoch: 5| Step: 8
Training loss: 3.3919994831085205
Validation loss: 2.8682830282436904

Epoch: 5| Step: 9
Training loss: 2.8342199325561523
Validation loss: 2.822275528343775

Epoch: 5| Step: 10
Training loss: 2.8294899463653564
Validation loss: 2.827689734838342

Epoch: 19| Step: 0
Training loss: 3.2060859203338623
Validation loss: 2.8431163218713578

Epoch: 5| Step: 1
Training loss: 3.102781295776367
Validation loss: 2.845671838329684

Epoch: 5| Step: 2
Training loss: 3.366478681564331
Validation loss: 2.831864277521769

Epoch: 5| Step: 3
Training loss: 2.756059408187866
Validation loss: 2.8271412464880172

Epoch: 5| Step: 4
Training loss: 3.4740471839904785
Validation loss: 2.8221288496448147

Epoch: 5| Step: 5
Training loss: 2.7474045753479004
Validation loss: 2.8277152353717434

Epoch: 5| Step: 6
Training loss: 2.760608434677124
Validation loss: 2.829630995309481

Epoch: 5| Step: 7
Training loss: 2.7444345951080322
Validation loss: 2.8350972667817147

Epoch: 5| Step: 8
Training loss: 2.682814836502075
Validation loss: 2.850454525281024

Epoch: 5| Step: 9
Training loss: 2.489741325378418
Validation loss: 2.847504113310127

Epoch: 5| Step: 10
Training loss: 2.9782302379608154
Validation loss: 2.836863210124354

Epoch: 20| Step: 0
Training loss: 3.0692200660705566
Validation loss: 2.815609811454691

Epoch: 5| Step: 1
Training loss: 2.605313777923584
Validation loss: 2.79427170753479

Epoch: 5| Step: 2
Training loss: 3.594460964202881
Validation loss: 2.7988211365156275

Epoch: 5| Step: 3
Training loss: 3.580355167388916
Validation loss: 2.7969423058212444

Epoch: 5| Step: 4
Training loss: 2.4901041984558105
Validation loss: 2.7994711988715717

Epoch: 5| Step: 5
Training loss: 3.130171060562134
Validation loss: 2.7930378324242047

Epoch: 5| Step: 6
Training loss: 2.7857937812805176
Validation loss: 2.787669938097718

Epoch: 5| Step: 7
Training loss: 2.212582588195801
Validation loss: 2.778591817425143

Epoch: 5| Step: 8
Training loss: 3.250825881958008
Validation loss: 2.779789355493361

Epoch: 5| Step: 9
Training loss: 2.482400417327881
Validation loss: 2.7817046180848153

Epoch: 5| Step: 10
Training loss: 2.671997308731079
Validation loss: 2.8083201223804104

Epoch: 21| Step: 0
Training loss: 3.1320793628692627
Validation loss: 2.8846319542136243

Epoch: 5| Step: 1
Training loss: 3.550508499145508
Validation loss: 2.7814856754836215

Epoch: 5| Step: 2
Training loss: 3.4469730854034424
Validation loss: 2.766296696919267

Epoch: 5| Step: 3
Training loss: 2.585353374481201
Validation loss: 2.76692634244119

Epoch: 5| Step: 4
Training loss: 2.6339404582977295
Validation loss: 2.7778249094563146

Epoch: 5| Step: 5
Training loss: 2.4990947246551514
Validation loss: 2.787569640785135

Epoch: 5| Step: 6
Training loss: 3.5824036598205566
Validation loss: 2.7852458236038045

Epoch: 5| Step: 7
Training loss: 2.009495258331299
Validation loss: 2.7668249914723058

Epoch: 5| Step: 8
Training loss: 3.2001328468322754
Validation loss: 2.7544781546438895

Epoch: 5| Step: 9
Training loss: 2.4274017810821533
Validation loss: 2.752043883005778

Epoch: 5| Step: 10
Training loss: 2.852928400039673
Validation loss: 2.757577642317741

Epoch: 22| Step: 0
Training loss: 1.673082709312439
Validation loss: 2.7818628024029475

Epoch: 5| Step: 1
Training loss: 3.3917007446289062
Validation loss: 2.8866083365614696

Epoch: 5| Step: 2
Training loss: 2.389630079269409
Validation loss: 2.899410686185283

Epoch: 5| Step: 3
Training loss: 3.003873109817505
Validation loss: 2.8495961619961645

Epoch: 5| Step: 4
Training loss: 2.2422103881835938
Validation loss: 2.7648765079436766

Epoch: 5| Step: 5
Training loss: 3.129296064376831
Validation loss: 2.7353653061774468

Epoch: 5| Step: 6
Training loss: 3.429441452026367
Validation loss: 2.7297029418330037

Epoch: 5| Step: 7
Training loss: 3.5798587799072266
Validation loss: 2.730834586645967

Epoch: 5| Step: 8
Training loss: 2.5386548042297363
Validation loss: 2.726271995934107

Epoch: 5| Step: 9
Training loss: 3.6252315044403076
Validation loss: 2.723293201897734

Epoch: 5| Step: 10
Training loss: 2.689234972000122
Validation loss: 2.725784691431189

Epoch: 23| Step: 0
Training loss: 3.667128801345825
Validation loss: 2.7225072332607803

Epoch: 5| Step: 1
Training loss: 2.359208822250366
Validation loss: 2.7209700692084526

Epoch: 5| Step: 2
Training loss: 2.657888174057007
Validation loss: 2.714032978139898

Epoch: 5| Step: 3
Training loss: 2.9396800994873047
Validation loss: 2.7130840055404173

Epoch: 5| Step: 4
Training loss: 3.232897996902466
Validation loss: 2.719961735510057

Epoch: 5| Step: 5
Training loss: 2.515144109725952
Validation loss: 2.7102893385835873

Epoch: 5| Step: 6
Training loss: 2.5074350833892822
Validation loss: 2.709407937142157

Epoch: 5| Step: 7
Training loss: 3.136033296585083
Validation loss: 2.706430645399196

Epoch: 5| Step: 8
Training loss: 3.0684139728546143
Validation loss: 2.705724452131538

Epoch: 5| Step: 9
Training loss: 2.461399555206299
Validation loss: 2.7001895981450237

Epoch: 5| Step: 10
Training loss: 2.6472911834716797
Validation loss: 2.700584985876596

Epoch: 24| Step: 0
Training loss: 3.114149808883667
Validation loss: 2.702225395428237

Epoch: 5| Step: 1
Training loss: 2.7417941093444824
Validation loss: 2.697909785855201

Epoch: 5| Step: 2
Training loss: 2.394268751144409
Validation loss: 2.699615616952219

Epoch: 5| Step: 3
Training loss: 3.5518717765808105
Validation loss: 2.6982966981908327

Epoch: 5| Step: 4
Training loss: 2.912522077560425
Validation loss: 2.6978480149340887

Epoch: 5| Step: 5
Training loss: 2.6821463108062744
Validation loss: 2.6935976730879916

Epoch: 5| Step: 6
Training loss: 2.735485553741455
Validation loss: 2.694537144835277

Epoch: 5| Step: 7
Training loss: 2.605940341949463
Validation loss: 2.698096864966936

Epoch: 5| Step: 8
Training loss: 3.5159740447998047
Validation loss: 2.7232579672208397

Epoch: 5| Step: 9
Training loss: 1.5883697271347046
Validation loss: 2.769363808375533

Epoch: 5| Step: 10
Training loss: 3.369652032852173
Validation loss: 2.8347356216881865

Epoch: 25| Step: 0
Training loss: 2.6007533073425293
Validation loss: 2.7913628906332035

Epoch: 5| Step: 1
Training loss: 2.3243908882141113
Validation loss: 2.77283888734797

Epoch: 5| Step: 2
Training loss: 2.7388834953308105
Validation loss: 2.7669824477164977

Epoch: 5| Step: 3
Training loss: 2.5849075317382812
Validation loss: 2.7893718006790325

Epoch: 5| Step: 4
Training loss: 3.5436031818389893
Validation loss: 2.8073768256812968

Epoch: 5| Step: 5
Training loss: 3.2556662559509277
Validation loss: 2.7856694267642115

Epoch: 5| Step: 6
Training loss: 3.2359957695007324
Validation loss: 2.7670867750721593

Epoch: 5| Step: 7
Training loss: 2.7315425872802734
Validation loss: 2.757929704522574

Epoch: 5| Step: 8
Training loss: 2.1316611766815186
Validation loss: 2.766259454911755

Epoch: 5| Step: 9
Training loss: 3.7889716625213623
Validation loss: 2.796561735932545

Epoch: 5| Step: 10
Training loss: 2.823615550994873
Validation loss: 2.8395833430751676

Epoch: 26| Step: 0
Training loss: 3.2044975757598877
Validation loss: 2.8543043598051994

Epoch: 5| Step: 1
Training loss: 2.927407741546631
Validation loss: 2.827659692815555

Epoch: 5| Step: 2
Training loss: 3.047560214996338
Validation loss: 2.7791954419946157

Epoch: 5| Step: 3
Training loss: 2.2614288330078125
Validation loss: 2.75742293173267

Epoch: 5| Step: 4
Training loss: 3.064345359802246
Validation loss: 2.7446587649724816

Epoch: 5| Step: 5
Training loss: 3.8984291553497314
Validation loss: 2.695676585679413

Epoch: 5| Step: 6
Training loss: 2.7647809982299805
Validation loss: 2.685560036731023

Epoch: 5| Step: 7
Training loss: 2.469226598739624
Validation loss: 2.6934027723086778

Epoch: 5| Step: 8
Training loss: 2.6173272132873535
Validation loss: 2.7212130459406043

Epoch: 5| Step: 9
Training loss: 2.475571632385254
Validation loss: 2.744861602783203

Epoch: 5| Step: 10
Training loss: 2.6672468185424805
Validation loss: 2.752220804973315

Epoch: 27| Step: 0
Training loss: 2.9688985347747803
Validation loss: 2.7489129061340005

Epoch: 5| Step: 1
Training loss: 2.2819411754608154
Validation loss: 2.7316345732699157

Epoch: 5| Step: 2
Training loss: 3.8682141304016113
Validation loss: 2.6961509027788715

Epoch: 5| Step: 3
Training loss: 2.961714267730713
Validation loss: 2.6732743042771534

Epoch: 5| Step: 4
Training loss: 2.8583426475524902
Validation loss: 2.680797799941032

Epoch: 5| Step: 5
Training loss: 2.50671124458313
Validation loss: 2.702340736184069

Epoch: 5| Step: 6
Training loss: 2.830724000930786
Validation loss: 2.7305185923012356

Epoch: 5| Step: 7
Training loss: 2.5226938724517822
Validation loss: 2.7617020940267913

Epoch: 5| Step: 8
Training loss: 3.157562732696533
Validation loss: 2.739567067033501

Epoch: 5| Step: 9
Training loss: 2.752849817276001
Validation loss: 2.693264917660785

Epoch: 5| Step: 10
Training loss: 2.4333319664001465
Validation loss: 2.6671186621471117

Epoch: 28| Step: 0
Training loss: 1.733709692955017
Validation loss: 2.6617773066284838

Epoch: 5| Step: 1
Training loss: 3.3718276023864746
Validation loss: 2.6639528351445354

Epoch: 5| Step: 2
Training loss: 2.1929705142974854
Validation loss: 2.6658643343115367

Epoch: 5| Step: 3
Training loss: 2.8852133750915527
Validation loss: 2.663433131351266

Epoch: 5| Step: 4
Training loss: 2.76570725440979
Validation loss: 2.662705695757302

Epoch: 5| Step: 5
Training loss: 2.9374217987060547
Validation loss: 2.657022476196289

Epoch: 5| Step: 6
Training loss: 2.228546619415283
Validation loss: 2.654901317370835

Epoch: 5| Step: 7
Training loss: 3.203568935394287
Validation loss: 2.6542002078025573

Epoch: 5| Step: 8
Training loss: 3.1920056343078613
Validation loss: 2.6523471673329673

Epoch: 5| Step: 9
Training loss: 3.1381678581237793
Validation loss: 2.652627004090176

Epoch: 5| Step: 10
Training loss: 3.2113940715789795
Validation loss: 2.6572665245302263

Epoch: 29| Step: 0
Training loss: 3.3721795082092285
Validation loss: 2.6542129952420472

Epoch: 5| Step: 1
Training loss: 2.8375582695007324
Validation loss: 2.6616765991333993

Epoch: 5| Step: 2
Training loss: 3.0569941997528076
Validation loss: 2.666874154921501

Epoch: 5| Step: 3
Training loss: 1.9694360494613647
Validation loss: 2.6679823911318215

Epoch: 5| Step: 4
Training loss: 2.8634555339813232
Validation loss: 2.6651031945341375

Epoch: 5| Step: 5
Training loss: 2.108473300933838
Validation loss: 2.655966922801028

Epoch: 5| Step: 6
Training loss: 2.9513442516326904
Validation loss: 2.6679108988854194

Epoch: 5| Step: 7
Training loss: 2.9657275676727295
Validation loss: 2.6540283246706893

Epoch: 5| Step: 8
Training loss: 3.234467029571533
Validation loss: 2.648304987979192

Epoch: 5| Step: 9
Training loss: 2.686276912689209
Validation loss: 2.6410490825612056

Epoch: 5| Step: 10
Training loss: 2.73395037651062
Validation loss: 2.6357824417852584

Epoch: 30| Step: 0
Training loss: 2.580972194671631
Validation loss: 2.6425656426337456

Epoch: 5| Step: 1
Training loss: 2.093960762023926
Validation loss: 2.6417936548109977

Epoch: 5| Step: 2
Training loss: 2.73948073387146
Validation loss: 2.6407867144512873

Epoch: 5| Step: 3
Training loss: 2.5781805515289307
Validation loss: 2.640151628883936

Epoch: 5| Step: 4
Training loss: 2.691248655319214
Validation loss: 2.6358978876503567

Epoch: 5| Step: 5
Training loss: 2.5683085918426514
Validation loss: 2.6404951618563746

Epoch: 5| Step: 6
Training loss: 3.268254518508911
Validation loss: 2.6350964884604178

Epoch: 5| Step: 7
Training loss: 2.9851016998291016
Validation loss: 2.6352820934787875

Epoch: 5| Step: 8
Training loss: 2.7922251224517822
Validation loss: 2.6338676201399935

Epoch: 5| Step: 9
Training loss: 3.5860111713409424
Validation loss: 2.6327292508976434

Epoch: 5| Step: 10
Training loss: 2.776493787765503
Validation loss: 2.6322924449879634

Epoch: 31| Step: 0
Training loss: 3.3519186973571777
Validation loss: 2.6320850387696297

Epoch: 5| Step: 1
Training loss: 2.4845080375671387
Validation loss: 2.6297773443242556

Epoch: 5| Step: 2
Training loss: 3.4838852882385254
Validation loss: 2.628477370867165

Epoch: 5| Step: 3
Training loss: 3.19061279296875
Validation loss: 2.6280152797698975

Epoch: 5| Step: 4
Training loss: 3.5235581398010254
Validation loss: 2.626425717466621

Epoch: 5| Step: 5
Training loss: 2.0174853801727295
Validation loss: 2.6258974895682385

Epoch: 5| Step: 6
Training loss: 2.6526055335998535
Validation loss: 2.620164014959848

Epoch: 5| Step: 7
Training loss: 2.1387133598327637
Validation loss: 2.6232697297168035

Epoch: 5| Step: 8
Training loss: 2.8108725547790527
Validation loss: 2.620656410853068

Epoch: 5| Step: 9
Training loss: 2.31526517868042
Validation loss: 2.620215062172182

Epoch: 5| Step: 10
Training loss: 2.5192058086395264
Validation loss: 2.6245167588674896

Epoch: 32| Step: 0
Training loss: 2.7745728492736816
Validation loss: 2.6223940516030915

Epoch: 5| Step: 1
Training loss: 2.4225049018859863
Validation loss: 2.625472181586809

Epoch: 5| Step: 2
Training loss: 3.262561321258545
Validation loss: 2.6278617228231123

Epoch: 5| Step: 3
Training loss: 1.9887558221817017
Validation loss: 2.624273956462901

Epoch: 5| Step: 4
Training loss: 3.7418739795684814
Validation loss: 2.6221730632166707

Epoch: 5| Step: 5
Training loss: 2.4233455657958984
Validation loss: 2.618384922704389

Epoch: 5| Step: 6
Training loss: 2.6153805255889893
Validation loss: 2.6246808831409743

Epoch: 5| Step: 7
Training loss: 2.789543867111206
Validation loss: 2.649528052217217

Epoch: 5| Step: 8
Training loss: 2.5807223320007324
Validation loss: 2.6415362768275763

Epoch: 5| Step: 9
Training loss: 3.330188274383545
Validation loss: 2.6197565050535303

Epoch: 5| Step: 10
Training loss: 2.5519440174102783
Validation loss: 2.6095092514509797

Epoch: 33| Step: 0
Training loss: 3.3033835887908936
Validation loss: 2.6098489633170505

Epoch: 5| Step: 1
Training loss: 2.626279830932617
Validation loss: 2.618548734213716

Epoch: 5| Step: 2
Training loss: 2.8947865962982178
Validation loss: 2.6521713528581845

Epoch: 5| Step: 3
Training loss: 2.5011816024780273
Validation loss: 2.6652975338761524

Epoch: 5| Step: 4
Training loss: 2.8014841079711914
Validation loss: 2.6170120367439846

Epoch: 5| Step: 5
Training loss: 3.19716215133667
Validation loss: 2.6073155608228458

Epoch: 5| Step: 6
Training loss: 2.780428409576416
Validation loss: 2.61588111487768

Epoch: 5| Step: 7
Training loss: 2.1695072650909424
Validation loss: 2.630876851338212

Epoch: 5| Step: 8
Training loss: 2.956855535507202
Validation loss: 2.6457348254419144

Epoch: 5| Step: 9
Training loss: 2.5666401386260986
Validation loss: 2.657251445196008

Epoch: 5| Step: 10
Training loss: 2.9031801223754883
Validation loss: 2.656830656913019

Epoch: 34| Step: 0
Training loss: 2.4598751068115234
Validation loss: 2.629305898502309

Epoch: 5| Step: 1
Training loss: 3.1781392097473145
Validation loss: 2.609312965023902

Epoch: 5| Step: 2
Training loss: 1.862582802772522
Validation loss: 2.6048548811225483

Epoch: 5| Step: 3
Training loss: 2.5331525802612305
Validation loss: 2.5993619888059554

Epoch: 5| Step: 4
Training loss: 2.759124517440796
Validation loss: 2.6098911685328328

Epoch: 5| Step: 5
Training loss: 3.2076122760772705
Validation loss: 2.6239627868898454

Epoch: 5| Step: 6
Training loss: 2.8683695793151855
Validation loss: 2.6306899837268296

Epoch: 5| Step: 7
Training loss: 3.048877716064453
Validation loss: 2.6376701503671627

Epoch: 5| Step: 8
Training loss: 3.054391860961914
Validation loss: 2.649569934414279

Epoch: 5| Step: 9
Training loss: 2.832843780517578
Validation loss: 2.6339375229292017

Epoch: 5| Step: 10
Training loss: 2.7098240852355957
Validation loss: 2.615999726838963

Epoch: 35| Step: 0
Training loss: 2.0318140983581543
Validation loss: 2.595792603749101

Epoch: 5| Step: 1
Training loss: 2.667654037475586
Validation loss: 2.5926192140066497

Epoch: 5| Step: 2
Training loss: 3.1382617950439453
Validation loss: 2.598694296293361

Epoch: 5| Step: 3
Training loss: 2.5904197692871094
Validation loss: 2.608487029229441

Epoch: 5| Step: 4
Training loss: 2.0042717456817627
Validation loss: 2.635788763723066

Epoch: 5| Step: 5
Training loss: 2.7786667346954346
Validation loss: 2.6576208401751775

Epoch: 5| Step: 6
Training loss: 3.1614112854003906
Validation loss: 2.635635345212875

Epoch: 5| Step: 7
Training loss: 3.270169496536255
Validation loss: 2.6175128157420824

Epoch: 5| Step: 8
Training loss: 3.302135467529297
Validation loss: 2.5996244235705306

Epoch: 5| Step: 9
Training loss: 2.7717738151550293
Validation loss: 2.5883247108869654

Epoch: 5| Step: 10
Training loss: 2.84177827835083
Validation loss: 2.601039550637686

Epoch: 36| Step: 0
Training loss: 2.3359951972961426
Validation loss: 2.6643964731565086

Epoch: 5| Step: 1
Training loss: 2.5485305786132812
Validation loss: 2.7098182298803843

Epoch: 5| Step: 2
Training loss: 2.248542547225952
Validation loss: 2.668791550461964

Epoch: 5| Step: 3
Training loss: 2.599947452545166
Validation loss: 2.647280236726166

Epoch: 5| Step: 4
Training loss: 2.6582117080688477
Validation loss: 2.6415954251443186

Epoch: 5| Step: 5
Training loss: 2.3192341327667236
Validation loss: 2.6200322028129333

Epoch: 5| Step: 6
Training loss: 3.370885133743286
Validation loss: 2.5954944254249654

Epoch: 5| Step: 7
Training loss: 2.876659870147705
Validation loss: 2.584571228232435

Epoch: 5| Step: 8
Training loss: 3.1695289611816406
Validation loss: 2.578256396837132

Epoch: 5| Step: 9
Training loss: 3.5071308612823486
Validation loss: 2.5846280820908083

Epoch: 5| Step: 10
Training loss: 2.8997323513031006
Validation loss: 2.593225448362289

Epoch: 37| Step: 0
Training loss: 3.324111223220825
Validation loss: 2.6062436078184392

Epoch: 5| Step: 1
Training loss: 2.6003119945526123
Validation loss: 2.629674485934678

Epoch: 5| Step: 2
Training loss: 2.465778350830078
Validation loss: 2.613536227133966

Epoch: 5| Step: 3
Training loss: 3.0969479084014893
Validation loss: 2.5976530403219242

Epoch: 5| Step: 4
Training loss: 2.220287799835205
Validation loss: 2.5930587630118094

Epoch: 5| Step: 5
Training loss: 2.8173813819885254
Validation loss: 2.5872380682217178

Epoch: 5| Step: 6
Training loss: 2.0815236568450928
Validation loss: 2.58231109188449

Epoch: 5| Step: 7
Training loss: 2.524291515350342
Validation loss: 2.5785392894539783

Epoch: 5| Step: 8
Training loss: 3.159135341644287
Validation loss: 2.5819278506822485

Epoch: 5| Step: 9
Training loss: 3.4139950275421143
Validation loss: 2.5892802233337076

Epoch: 5| Step: 10
Training loss: 2.7206294536590576
Validation loss: 2.606305945304132

Epoch: 38| Step: 0
Training loss: 2.9944803714752197
Validation loss: 2.657828284848121

Epoch: 5| Step: 1
Training loss: 2.7041468620300293
Validation loss: 2.598363768669867

Epoch: 5| Step: 2
Training loss: 2.6909339427948
Validation loss: 2.5934630235036216

Epoch: 5| Step: 3
Training loss: 2.71099853515625
Validation loss: 2.593489147001697

Epoch: 5| Step: 4
Training loss: 2.9313912391662598
Validation loss: 2.5917042147728706

Epoch: 5| Step: 5
Training loss: 2.8218843936920166
Validation loss: 2.582776079895676

Epoch: 5| Step: 6
Training loss: 2.3492271900177
Validation loss: 2.5809022636823755

Epoch: 5| Step: 7
Training loss: 3.0653462409973145
Validation loss: 2.57722363164348

Epoch: 5| Step: 8
Training loss: 3.086686849594116
Validation loss: 2.577144609984531

Epoch: 5| Step: 9
Training loss: 2.825721025466919
Validation loss: 2.581403583608648

Epoch: 5| Step: 10
Training loss: 2.091883659362793
Validation loss: 2.583251086614465

Epoch: 39| Step: 0
Training loss: 3.2624599933624268
Validation loss: 2.5925948081477994

Epoch: 5| Step: 1
Training loss: 2.3658647537231445
Validation loss: 2.578138905186807

Epoch: 5| Step: 2
Training loss: 2.035038709640503
Validation loss: 2.5836129214174006

Epoch: 5| Step: 3
Training loss: 2.5219998359680176
Validation loss: 2.5757832245160173

Epoch: 5| Step: 4
Training loss: 2.9169692993164062
Validation loss: 2.576711421371788

Epoch: 5| Step: 5
Training loss: 2.8511292934417725
Validation loss: 2.573482682628016

Epoch: 5| Step: 6
Training loss: 2.6897194385528564
Validation loss: 2.570771501910302

Epoch: 5| Step: 7
Training loss: 2.8500559329986572
Validation loss: 2.5778335473870717

Epoch: 5| Step: 8
Training loss: 2.885361909866333
Validation loss: 2.600777572201144

Epoch: 5| Step: 9
Training loss: 2.7467615604400635
Validation loss: 2.615873182973554

Epoch: 5| Step: 10
Training loss: 3.128476858139038
Validation loss: 2.594305897271761

Epoch: 40| Step: 0
Training loss: 2.4067633152008057
Validation loss: 2.571061062556441

Epoch: 5| Step: 1
Training loss: 2.7729787826538086
Validation loss: 2.5674683816971315

Epoch: 5| Step: 2
Training loss: 3.2182679176330566
Validation loss: 2.5610225713381203

Epoch: 5| Step: 3
Training loss: 2.767427444458008
Validation loss: 2.556056486662998

Epoch: 5| Step: 4
Training loss: 2.5528934001922607
Validation loss: 2.5565820278659945

Epoch: 5| Step: 5
Training loss: 2.7491989135742188
Validation loss: 2.5628384236366517

Epoch: 5| Step: 6
Training loss: 2.8580076694488525
Validation loss: 2.5603572014839417

Epoch: 5| Step: 7
Training loss: 2.4762842655181885
Validation loss: 2.571573575337728

Epoch: 5| Step: 8
Training loss: 2.8950374126434326
Validation loss: 2.5598446297389206

Epoch: 5| Step: 9
Training loss: 2.653949022293091
Validation loss: 2.554075684598697

Epoch: 5| Step: 10
Training loss: 2.680941581726074
Validation loss: 2.5487434120588404

Epoch: 41| Step: 0
Training loss: 2.3238768577575684
Validation loss: 2.55278322773595

Epoch: 5| Step: 1
Training loss: 2.564699172973633
Validation loss: 2.5493696940842496

Epoch: 5| Step: 2
Training loss: 3.060077428817749
Validation loss: 2.552671259449374

Epoch: 5| Step: 3
Training loss: 2.5433261394500732
Validation loss: 2.5505220915681575

Epoch: 5| Step: 4
Training loss: 3.372464418411255
Validation loss: 2.5545444334706953

Epoch: 5| Step: 5
Training loss: 3.2062695026397705
Validation loss: 2.5644948841423116

Epoch: 5| Step: 6
Training loss: 2.2675118446350098
Validation loss: 2.5559943927231656

Epoch: 5| Step: 7
Training loss: 2.3508121967315674
Validation loss: 2.5459332696853147

Epoch: 5| Step: 8
Training loss: 2.723501682281494
Validation loss: 2.5446688385419947

Epoch: 5| Step: 9
Training loss: 3.0462701320648193
Validation loss: 2.546163094941006

Epoch: 5| Step: 10
Training loss: 2.539705276489258
Validation loss: 2.5534343206754295

Epoch: 42| Step: 0
Training loss: 1.802830696105957
Validation loss: 2.5681036749193744

Epoch: 5| Step: 1
Training loss: 3.120677947998047
Validation loss: 2.553520938401581

Epoch: 5| Step: 2
Training loss: 2.954552173614502
Validation loss: 2.549758977787469

Epoch: 5| Step: 3
Training loss: 2.8476898670196533
Validation loss: 2.554368721541538

Epoch: 5| Step: 4
Training loss: 2.6980252265930176
Validation loss: 2.5698933844925254

Epoch: 5| Step: 5
Training loss: 2.5329155921936035
Validation loss: 2.5394009005638862

Epoch: 5| Step: 6
Training loss: 2.3424086570739746
Validation loss: 2.5748232333890853

Epoch: 5| Step: 7
Training loss: 2.5842058658599854
Validation loss: 2.6046028624298754

Epoch: 5| Step: 8
Training loss: 3.2509677410125732
Validation loss: 2.5963999379065728

Epoch: 5| Step: 9
Training loss: 2.623467206954956
Validation loss: 2.6006790540551625

Epoch: 5| Step: 10
Training loss: 3.4499363899230957
Validation loss: 2.5948273187042563

Epoch: 43| Step: 0
Training loss: 2.7957465648651123
Validation loss: 2.5732304024439987

Epoch: 5| Step: 1
Training loss: 2.410884380340576
Validation loss: 2.5556398771142446

Epoch: 5| Step: 2
Training loss: 3.175227165222168
Validation loss: 2.5550723229685137

Epoch: 5| Step: 3
Training loss: 2.5352909564971924
Validation loss: 2.5462939687954482

Epoch: 5| Step: 4
Training loss: 1.9837833642959595
Validation loss: 2.5408235006434943

Epoch: 5| Step: 5
Training loss: 2.906811237335205
Validation loss: 2.543181106608401

Epoch: 5| Step: 6
Training loss: 3.3915703296661377
Validation loss: 2.5394473870595298

Epoch: 5| Step: 7
Training loss: 2.551427125930786
Validation loss: 2.5373064036010415

Epoch: 5| Step: 8
Training loss: 2.6535747051239014
Validation loss: 2.5348999192637782

Epoch: 5| Step: 9
Training loss: 2.577657699584961
Validation loss: 2.5386534249910744

Epoch: 5| Step: 10
Training loss: 2.976360321044922
Validation loss: 2.5421289526006228

Epoch: 44| Step: 0
Training loss: 2.0813400745391846
Validation loss: 2.541170638094666

Epoch: 5| Step: 1
Training loss: 2.483818292617798
Validation loss: 2.5516801752069944

Epoch: 5| Step: 2
Training loss: 3.1801297664642334
Validation loss: 2.552426245904738

Epoch: 5| Step: 3
Training loss: 2.9611287117004395
Validation loss: 2.5433321152963946

Epoch: 5| Step: 4
Training loss: 3.079718828201294
Validation loss: 2.525809508497997

Epoch: 5| Step: 5
Training loss: 2.4614956378936768
Validation loss: 2.5243579879883797

Epoch: 5| Step: 6
Training loss: 2.580209732055664
Validation loss: 2.5235504155517905

Epoch: 5| Step: 7
Training loss: 2.58023738861084
Validation loss: 2.5258028481596257

Epoch: 5| Step: 8
Training loss: 3.4815163612365723
Validation loss: 2.522353979849046

Epoch: 5| Step: 9
Training loss: 2.4558987617492676
Validation loss: 2.5225231416763796

Epoch: 5| Step: 10
Training loss: 2.5903003215789795
Validation loss: 2.5357651069600093

Epoch: 45| Step: 0
Training loss: 2.2987401485443115
Validation loss: 2.5473127647112777

Epoch: 5| Step: 1
Training loss: 3.5862457752227783
Validation loss: 2.559256684395575

Epoch: 5| Step: 2
Training loss: 2.809302806854248
Validation loss: 2.567170455891599

Epoch: 5| Step: 3
Training loss: 3.067885637283325
Validation loss: 2.532415674578759

Epoch: 5| Step: 4
Training loss: 2.498265266418457
Validation loss: 2.518508823969031

Epoch: 5| Step: 5
Training loss: 2.491387128829956
Validation loss: 2.519471522300474

Epoch: 5| Step: 6
Training loss: 3.5247559547424316
Validation loss: 2.523172437503774

Epoch: 5| Step: 7
Training loss: 2.305647373199463
Validation loss: 2.5314498409148185

Epoch: 5| Step: 8
Training loss: 2.442749500274658
Validation loss: 2.537498261338921

Epoch: 5| Step: 9
Training loss: 2.364147663116455
Validation loss: 2.5349847398778445

Epoch: 5| Step: 10
Training loss: 2.728978157043457
Validation loss: 2.5321044204055623

Epoch: 46| Step: 0
Training loss: 2.5871217250823975
Validation loss: 2.5282767665001655

Epoch: 5| Step: 1
Training loss: 2.719226360321045
Validation loss: 2.5180307639542447

Epoch: 5| Step: 2
Training loss: 2.7986855506896973
Validation loss: 2.5126814252586773

Epoch: 5| Step: 3
Training loss: 2.7626733779907227
Validation loss: 2.5126400352806173

Epoch: 5| Step: 4
Training loss: 2.1852755546569824
Validation loss: 2.521723565234933

Epoch: 5| Step: 5
Training loss: 3.392366886138916
Validation loss: 2.5224316068874892

Epoch: 5| Step: 6
Training loss: 2.93989634513855
Validation loss: 2.5357664092894523

Epoch: 5| Step: 7
Training loss: 2.9025721549987793
Validation loss: 2.558315610372892

Epoch: 5| Step: 8
Training loss: 2.1765494346618652
Validation loss: 2.567590964737759

Epoch: 5| Step: 9
Training loss: 2.543109655380249
Validation loss: 2.5557976563771567

Epoch: 5| Step: 10
Training loss: 2.808999538421631
Validation loss: 2.5466765024328746

Epoch: 47| Step: 0
Training loss: 2.8395776748657227
Validation loss: 2.530715775746171

Epoch: 5| Step: 1
Training loss: 1.931398630142212
Validation loss: 2.5175941298084874

Epoch: 5| Step: 2
Training loss: 3.4185471534729004
Validation loss: 2.5011955076648342

Epoch: 5| Step: 3
Training loss: 3.3009629249572754
Validation loss: 2.5037609787397486

Epoch: 5| Step: 4
Training loss: 2.5425772666931152
Validation loss: 2.508196105239212

Epoch: 5| Step: 5
Training loss: 2.7165350914001465
Validation loss: 2.5081220185884865

Epoch: 5| Step: 6
Training loss: 2.721461772918701
Validation loss: 2.5146672212949364

Epoch: 5| Step: 7
Training loss: 2.4947235584259033
Validation loss: 2.5138345021073536

Epoch: 5| Step: 8
Training loss: 2.678917646408081
Validation loss: 2.511001792005313

Epoch: 5| Step: 9
Training loss: 2.482651710510254
Validation loss: 2.512341389092066

Epoch: 5| Step: 10
Training loss: 2.6965370178222656
Validation loss: 2.5100595720352663

Epoch: 48| Step: 0
Training loss: 2.8117547035217285
Validation loss: 2.5042272331894084

Epoch: 5| Step: 1
Training loss: 2.4747326374053955
Validation loss: 2.503387169171405

Epoch: 5| Step: 2
Training loss: 3.8926281929016113
Validation loss: 2.503483162131361

Epoch: 5| Step: 3
Training loss: 2.5034637451171875
Validation loss: 2.5003789855587866

Epoch: 5| Step: 4
Training loss: 2.824930191040039
Validation loss: 2.498966975878644

Epoch: 5| Step: 5
Training loss: 2.738333225250244
Validation loss: 2.4964298073963453

Epoch: 5| Step: 6
Training loss: 2.4625916481018066
Validation loss: 2.494458839457522

Epoch: 5| Step: 7
Training loss: 2.465885877609253
Validation loss: 2.498523812140188

Epoch: 5| Step: 8
Training loss: 2.633068799972534
Validation loss: 2.4981799305126233

Epoch: 5| Step: 9
Training loss: 2.368596315383911
Validation loss: 2.5069426234050463

Epoch: 5| Step: 10
Training loss: 2.6155428886413574
Validation loss: 2.530302878349058

Epoch: 49| Step: 0
Training loss: 2.1690077781677246
Validation loss: 2.5259849025357153

Epoch: 5| Step: 1
Training loss: 2.4648640155792236
Validation loss: 2.5207983704023462

Epoch: 5| Step: 2
Training loss: 2.0236363410949707
Validation loss: 2.509839678323397

Epoch: 5| Step: 3
Training loss: 2.590667247772217
Validation loss: 2.508913945126277

Epoch: 5| Step: 4
Training loss: 3.037950038909912
Validation loss: 2.5212942656650337

Epoch: 5| Step: 5
Training loss: 3.1196112632751465
Validation loss: 2.5061885874758483

Epoch: 5| Step: 6
Training loss: 2.7198071479797363
Validation loss: 2.4992005543042253

Epoch: 5| Step: 7
Training loss: 2.9602925777435303
Validation loss: 2.4937384769480717

Epoch: 5| Step: 8
Training loss: 2.8157854080200195
Validation loss: 2.498117152080741

Epoch: 5| Step: 9
Training loss: 3.151231288909912
Validation loss: 2.4909298419952393

Epoch: 5| Step: 10
Training loss: 2.5749704837799072
Validation loss: 2.492180165424142

Epoch: 50| Step: 0
Training loss: 3.06589412689209
Validation loss: 2.494458777930147

Epoch: 5| Step: 1
Training loss: 2.5757319927215576
Validation loss: 2.494895694076374

Epoch: 5| Step: 2
Training loss: 3.188192844390869
Validation loss: 2.5011484084590787

Epoch: 5| Step: 3
Training loss: 2.2264153957366943
Validation loss: 2.5067646426539265

Epoch: 5| Step: 4
Training loss: 3.1148529052734375
Validation loss: 2.511595179957728

Epoch: 5| Step: 5
Training loss: 2.950533628463745
Validation loss: 2.524246879803237

Epoch: 5| Step: 6
Training loss: 2.700892210006714
Validation loss: 2.532160717953918

Epoch: 5| Step: 7
Training loss: 2.4278550148010254
Validation loss: 2.53216411477776

Epoch: 5| Step: 8
Training loss: 2.189911365509033
Validation loss: 2.5221560078282512

Epoch: 5| Step: 9
Training loss: 2.8350777626037598
Validation loss: 2.523090963722557

Epoch: 5| Step: 10
Training loss: 2.35225510597229
Validation loss: 2.5039371008514077

Epoch: 51| Step: 0
Training loss: 2.4943463802337646
Validation loss: 2.485533469466753

Epoch: 5| Step: 1
Training loss: 2.7019686698913574
Validation loss: 2.483565112595917

Epoch: 5| Step: 2
Training loss: 2.929962158203125
Validation loss: 2.478950854270689

Epoch: 5| Step: 3
Training loss: 2.5638556480407715
Validation loss: 2.485870228018812

Epoch: 5| Step: 4
Training loss: 2.057849645614624
Validation loss: 2.4914791994197394

Epoch: 5| Step: 5
Training loss: 3.1625888347625732
Validation loss: 2.528686800310689

Epoch: 5| Step: 6
Training loss: 1.987485647201538
Validation loss: 2.53573416894482

Epoch: 5| Step: 7
Training loss: 2.941984176635742
Validation loss: 2.5175873899972565

Epoch: 5| Step: 8
Training loss: 3.23344349861145
Validation loss: 2.5274966301456576

Epoch: 5| Step: 9
Training loss: 2.745147228240967
Validation loss: 2.5269230283716673

Epoch: 5| Step: 10
Training loss: 3.0065407752990723
Validation loss: 2.4947783870081746

Epoch: 52| Step: 0
Training loss: 2.8712518215179443
Validation loss: 2.4863069929102415

Epoch: 5| Step: 1
Training loss: 2.7798104286193848
Validation loss: 2.507206488681096

Epoch: 5| Step: 2
Training loss: 2.7800028324127197
Validation loss: 2.5118147096326275

Epoch: 5| Step: 3
Training loss: 3.057065725326538
Validation loss: 2.512952717401648

Epoch: 5| Step: 4
Training loss: 2.1466939449310303
Validation loss: 2.4992986391949397

Epoch: 5| Step: 5
Training loss: 2.698540210723877
Validation loss: 2.4913799506361767

Epoch: 5| Step: 6
Training loss: 2.646170139312744
Validation loss: 2.517624044931063

Epoch: 5| Step: 7
Training loss: 2.3481497764587402
Validation loss: 2.5250057302495486

Epoch: 5| Step: 8
Training loss: 2.532728672027588
Validation loss: 2.517479186416954

Epoch: 5| Step: 9
Training loss: 2.736330270767212
Validation loss: 2.5133341755918277

Epoch: 5| Step: 10
Training loss: 3.4168426990509033
Validation loss: 2.494691361663162

Epoch: 53| Step: 0
Training loss: 2.9073314666748047
Validation loss: 2.4846862669914

Epoch: 5| Step: 1
Training loss: 2.676604986190796
Validation loss: 2.4793222899078042

Epoch: 5| Step: 2
Training loss: 3.033224105834961
Validation loss: 2.473526777759675

Epoch: 5| Step: 3
Training loss: 2.1728134155273438
Validation loss: 2.472514287117989

Epoch: 5| Step: 4
Training loss: 2.85532808303833
Validation loss: 2.4739928040453183

Epoch: 5| Step: 5
Training loss: 2.7349278926849365
Validation loss: 2.4728240325886715

Epoch: 5| Step: 6
Training loss: 2.575847864151001
Validation loss: 2.4813161562847834

Epoch: 5| Step: 7
Training loss: 2.791553020477295
Validation loss: 2.4994505041389057

Epoch: 5| Step: 8
Training loss: 1.8301982879638672
Validation loss: 2.5150883889967397

Epoch: 5| Step: 9
Training loss: 3.0923662185668945
Validation loss: 2.5280842665703065

Epoch: 5| Step: 10
Training loss: 2.9520015716552734
Validation loss: 2.568805730471047

Epoch: 54| Step: 0
Training loss: 3.4293580055236816
Validation loss: 2.5290533342669086

Epoch: 5| Step: 1
Training loss: 2.643854856491089
Validation loss: 2.489874985910231

Epoch: 5| Step: 2
Training loss: 2.032454490661621
Validation loss: 2.473953611107283

Epoch: 5| Step: 3
Training loss: 2.626556158065796
Validation loss: 2.470974910643793

Epoch: 5| Step: 4
Training loss: 3.2290635108947754
Validation loss: 2.4762313494118313

Epoch: 5| Step: 5
Training loss: 2.197626829147339
Validation loss: 2.480799659605949

Epoch: 5| Step: 6
Training loss: 2.5234429836273193
Validation loss: 2.482661925336366

Epoch: 5| Step: 7
Training loss: 2.2356557846069336
Validation loss: 2.4806478151711087

Epoch: 5| Step: 8
Training loss: 2.8504443168640137
Validation loss: 2.4737095140641734

Epoch: 5| Step: 9
Training loss: 2.81028413772583
Validation loss: 2.4715519387234925

Epoch: 5| Step: 10
Training loss: 3.1513173580169678
Validation loss: 2.46940101603026

Epoch: 55| Step: 0
Training loss: 2.4542946815490723
Validation loss: 2.461285262979487

Epoch: 5| Step: 1
Training loss: 2.9784018993377686
Validation loss: 2.455668633983981

Epoch: 5| Step: 2
Training loss: 1.797130823135376
Validation loss: 2.4587010619460896

Epoch: 5| Step: 3
Training loss: 2.7175631523132324
Validation loss: 2.459625382577219

Epoch: 5| Step: 4
Training loss: 2.0075316429138184
Validation loss: 2.4799200206674556

Epoch: 5| Step: 5
Training loss: 2.8873684406280518
Validation loss: 2.518319211980348

Epoch: 5| Step: 6
Training loss: 2.7335543632507324
Validation loss: 2.5462871648932017

Epoch: 5| Step: 7
Training loss: 3.2040908336639404
Validation loss: 2.513490471788632

Epoch: 5| Step: 8
Training loss: 3.1968185901641846
Validation loss: 2.481107319554975

Epoch: 5| Step: 9
Training loss: 2.483213424682617
Validation loss: 2.464675505956014

Epoch: 5| Step: 10
Training loss: 3.2425618171691895
Validation loss: 2.4575411555587605

Epoch: 56| Step: 0
Training loss: 2.7287774085998535
Validation loss: 2.462000669971589

Epoch: 5| Step: 1
Training loss: 2.7638120651245117
Validation loss: 2.4609527177708124

Epoch: 5| Step: 2
Training loss: 2.225508213043213
Validation loss: 2.4687156049154138

Epoch: 5| Step: 3
Training loss: 2.5341053009033203
Validation loss: 2.47090486813617

Epoch: 5| Step: 4
Training loss: 2.8715057373046875
Validation loss: 2.4727429471990114

Epoch: 5| Step: 5
Training loss: 2.1999220848083496
Validation loss: 2.4761335862580167

Epoch: 5| Step: 6
Training loss: 2.6133155822753906
Validation loss: 2.4798419014100106

Epoch: 5| Step: 7
Training loss: 2.4853291511535645
Validation loss: 2.474791016629947

Epoch: 5| Step: 8
Training loss: 3.0484635829925537
Validation loss: 2.47449174234944

Epoch: 5| Step: 9
Training loss: 3.4561266899108887
Validation loss: 2.462984500392791

Epoch: 5| Step: 10
Training loss: 2.69154691696167
Validation loss: 2.4593803318597938

Epoch: 57| Step: 0
Training loss: 3.100569009780884
Validation loss: 2.454674087544923

Epoch: 5| Step: 1
Training loss: 1.958587408065796
Validation loss: 2.452429038222118

Epoch: 5| Step: 2
Training loss: 1.9223295450210571
Validation loss: 2.4525371315658733

Epoch: 5| Step: 3
Training loss: 3.333141803741455
Validation loss: 2.4500022447237404

Epoch: 5| Step: 4
Training loss: 2.4095325469970703
Validation loss: 2.4573150809093187

Epoch: 5| Step: 5
Training loss: 3.0347094535827637
Validation loss: 2.456560642488541

Epoch: 5| Step: 6
Training loss: 3.0819058418273926
Validation loss: 2.458375084784723

Epoch: 5| Step: 7
Training loss: 2.9514248371124268
Validation loss: 2.4667825878307386

Epoch: 5| Step: 8
Training loss: 2.7584338188171387
Validation loss: 2.465680017266222

Epoch: 5| Step: 9
Training loss: 2.4689033031463623
Validation loss: 2.4700939245121454

Epoch: 5| Step: 10
Training loss: 2.3731882572174072
Validation loss: 2.4705982054433515

Epoch: 58| Step: 0
Training loss: 2.4640376567840576
Validation loss: 2.4793041342048237

Epoch: 5| Step: 1
Training loss: 2.3258602619171143
Validation loss: 2.483064087488318

Epoch: 5| Step: 2
Training loss: 2.843114137649536
Validation loss: 2.47699059209516

Epoch: 5| Step: 3
Training loss: 2.486133098602295
Validation loss: 2.4690270731526036

Epoch: 5| Step: 4
Training loss: 2.4013466835021973
Validation loss: 2.4504638282201623

Epoch: 5| Step: 5
Training loss: 3.043186664581299
Validation loss: 2.449605700790241

Epoch: 5| Step: 6
Training loss: 2.6060328483581543
Validation loss: 2.4445499656020955

Epoch: 5| Step: 7
Training loss: 2.670405149459839
Validation loss: 2.446058693752494

Epoch: 5| Step: 8
Training loss: 2.860057830810547
Validation loss: 2.443957292905418

Epoch: 5| Step: 9
Training loss: 2.934481143951416
Validation loss: 2.4457630085688766

Epoch: 5| Step: 10
Training loss: 2.7667274475097656
Validation loss: 2.4467349949703423

Epoch: 59| Step: 0
Training loss: 2.060699701309204
Validation loss: 2.4491442300940074

Epoch: 5| Step: 1
Training loss: 3.484118938446045
Validation loss: 2.439961974338819

Epoch: 5| Step: 2
Training loss: 2.172203540802002
Validation loss: 2.4467677172794136

Epoch: 5| Step: 3
Training loss: 2.6147665977478027
Validation loss: 2.4469510970577115

Epoch: 5| Step: 4
Training loss: 2.2877352237701416
Validation loss: 2.450120541357225

Epoch: 5| Step: 5
Training loss: 3.14306378364563
Validation loss: 2.457814880596694

Epoch: 5| Step: 6
Training loss: 2.4723081588745117
Validation loss: 2.467856830166232

Epoch: 5| Step: 7
Training loss: 3.0796704292297363
Validation loss: 2.482444635001562

Epoch: 5| Step: 8
Training loss: 2.5814461708068848
Validation loss: 2.478006701315603

Epoch: 5| Step: 9
Training loss: 2.884852409362793
Validation loss: 2.4874987115142164

Epoch: 5| Step: 10
Training loss: 2.555124282836914
Validation loss: 2.4698612331062235

Epoch: 60| Step: 0
Training loss: 2.4343628883361816
Validation loss: 2.4590960112951135

Epoch: 5| Step: 1
Training loss: 2.976198196411133
Validation loss: 2.4558391212135233

Epoch: 5| Step: 2
Training loss: 3.243598461151123
Validation loss: 2.4406794322434293

Epoch: 5| Step: 3
Training loss: 2.7160837650299072
Validation loss: 2.440772794908093

Epoch: 5| Step: 4
Training loss: 2.6188578605651855
Validation loss: 2.4409383830203804

Epoch: 5| Step: 5
Training loss: 3.052525043487549
Validation loss: 2.4390041981973956

Epoch: 5| Step: 6
Training loss: 2.186079978942871
Validation loss: 2.4348357057058685

Epoch: 5| Step: 7
Training loss: 2.3655407428741455
Validation loss: 2.4329100808789654

Epoch: 5| Step: 8
Training loss: 2.8838672637939453
Validation loss: 2.438162347321869

Epoch: 5| Step: 9
Training loss: 2.410886764526367
Validation loss: 2.4355988041047127

Epoch: 5| Step: 10
Training loss: 2.37515926361084
Validation loss: 2.4383584043031097

Epoch: 61| Step: 0
Training loss: 2.847686767578125
Validation loss: 2.438163500960155

Epoch: 5| Step: 1
Training loss: 2.9749302864074707
Validation loss: 2.438691246894098

Epoch: 5| Step: 2
Training loss: 2.9535269737243652
Validation loss: 2.4466707732087825

Epoch: 5| Step: 3
Training loss: 2.5527093410491943
Validation loss: 2.4397177004045054

Epoch: 5| Step: 4
Training loss: 2.0230793952941895
Validation loss: 2.435654773507067

Epoch: 5| Step: 5
Training loss: 2.6372451782226562
Validation loss: 2.430854379489858

Epoch: 5| Step: 6
Training loss: 1.9955976009368896
Validation loss: 2.432460605457265

Epoch: 5| Step: 7
Training loss: 3.697744846343994
Validation loss: 2.434427558734853

Epoch: 5| Step: 8
Training loss: 2.6944432258605957
Validation loss: 2.4365515837105374

Epoch: 5| Step: 9
Training loss: 2.0105013847351074
Validation loss: 2.438566957750628

Epoch: 5| Step: 10
Training loss: 2.9352283477783203
Validation loss: 2.4407980108773835

Epoch: 62| Step: 0
Training loss: 2.9404594898223877
Validation loss: 2.4402474177780973

Epoch: 5| Step: 1
Training loss: 3.322432279586792
Validation loss: 2.4383835023449314

Epoch: 5| Step: 2
Training loss: 2.8276658058166504
Validation loss: 2.4393330979090866

Epoch: 5| Step: 3
Training loss: 2.5327391624450684
Validation loss: 2.4352173100235643

Epoch: 5| Step: 4
Training loss: 2.506547212600708
Validation loss: 2.4354935230747348

Epoch: 5| Step: 5
Training loss: 3.025902271270752
Validation loss: 2.434055241205359

Epoch: 5| Step: 6
Training loss: 1.9591877460479736
Validation loss: 2.4302254902419222

Epoch: 5| Step: 7
Training loss: 2.6983237266540527
Validation loss: 2.4205088666690293

Epoch: 5| Step: 8
Training loss: 2.5136070251464844
Validation loss: 2.420126699632214

Epoch: 5| Step: 9
Training loss: 2.3886637687683105
Validation loss: 2.4208475056514946

Epoch: 5| Step: 10
Training loss: 2.677255153656006
Validation loss: 2.4214736876949186

Epoch: 63| Step: 0
Training loss: 2.540409564971924
Validation loss: 2.4218103680559384

Epoch: 5| Step: 1
Training loss: 1.8519551753997803
Validation loss: 2.422769461908648

Epoch: 5| Step: 2
Training loss: 2.2710607051849365
Validation loss: 2.4188732716345016

Epoch: 5| Step: 3
Training loss: 2.4606761932373047
Validation loss: 2.430434573081232

Epoch: 5| Step: 4
Training loss: 2.989339828491211
Validation loss: 2.4289887207810597

Epoch: 5| Step: 5
Training loss: 3.301319122314453
Validation loss: 2.4385470318537887

Epoch: 5| Step: 6
Training loss: 2.905390977859497
Validation loss: 2.441737274969778

Epoch: 5| Step: 7
Training loss: 2.8075432777404785
Validation loss: 2.426566703345186

Epoch: 5| Step: 8
Training loss: 2.8415863513946533
Validation loss: 2.4237170732149513

Epoch: 5| Step: 9
Training loss: 2.830599546432495
Validation loss: 2.418386527287063

Epoch: 5| Step: 10
Training loss: 2.3583970069885254
Validation loss: 2.421123707166282

Epoch: 64| Step: 0
Training loss: 2.9331393241882324
Validation loss: 2.419227712897844

Epoch: 5| Step: 1
Training loss: 2.2415053844451904
Validation loss: 2.4179722211694203

Epoch: 5| Step: 2
Training loss: 2.5441527366638184
Validation loss: 2.4188577513540945

Epoch: 5| Step: 3
Training loss: 3.2481231689453125
Validation loss: 2.415907174028376

Epoch: 5| Step: 4
Training loss: 2.27398943901062
Validation loss: 2.417906645805605

Epoch: 5| Step: 5
Training loss: 2.419055461883545
Validation loss: 2.4157289176858883

Epoch: 5| Step: 6
Training loss: 2.9320809841156006
Validation loss: 2.4263937370751494

Epoch: 5| Step: 7
Training loss: 2.665834903717041
Validation loss: 2.4303245903343282

Epoch: 5| Step: 8
Training loss: 2.7364745140075684
Validation loss: 2.4244670201373357

Epoch: 5| Step: 9
Training loss: 2.535444736480713
Validation loss: 2.4215094299726587

Epoch: 5| Step: 10
Training loss: 2.728214979171753
Validation loss: 2.4111440361187024

Epoch: 65| Step: 0
Training loss: 2.9875857830047607
Validation loss: 2.412763049525599

Epoch: 5| Step: 1
Training loss: 2.1660959720611572
Validation loss: 2.41592300322748

Epoch: 5| Step: 2
Training loss: 2.591663360595703
Validation loss: 2.4199140751233665

Epoch: 5| Step: 3
Training loss: 2.550666332244873
Validation loss: 2.41891981709388

Epoch: 5| Step: 4
Training loss: 2.0546011924743652
Validation loss: 2.422236419493152

Epoch: 5| Step: 5
Training loss: 2.5361928939819336
Validation loss: 2.426302371486541

Epoch: 5| Step: 6
Training loss: 2.8871352672576904
Validation loss: 2.4491295147967596

Epoch: 5| Step: 7
Training loss: 3.175551652908325
Validation loss: 2.4659716262612292

Epoch: 5| Step: 8
Training loss: 2.5174434185028076
Validation loss: 2.471209687571372

Epoch: 5| Step: 9
Training loss: 2.8978209495544434
Validation loss: 2.492222862858926

Epoch: 5| Step: 10
Training loss: 2.8810291290283203
Validation loss: 2.4797449060665664

Epoch: 66| Step: 0
Training loss: 3.432049512863159
Validation loss: 2.4356016471821773

Epoch: 5| Step: 1
Training loss: 2.792757511138916
Validation loss: 2.410466019825269

Epoch: 5| Step: 2
Training loss: 2.8374416828155518
Validation loss: 2.4123262513068413

Epoch: 5| Step: 3
Training loss: 2.7373604774475098
Validation loss: 2.411681411086872

Epoch: 5| Step: 4
Training loss: 2.921630382537842
Validation loss: 2.418930757430292

Epoch: 5| Step: 5
Training loss: 2.217775821685791
Validation loss: 2.4170792769360285

Epoch: 5| Step: 6
Training loss: 2.7235794067382812
Validation loss: 2.422058697669737

Epoch: 5| Step: 7
Training loss: 2.2984113693237305
Validation loss: 2.418152860415879

Epoch: 5| Step: 8
Training loss: 1.9921153783798218
Validation loss: 2.413083573823334

Epoch: 5| Step: 9
Training loss: 2.672306776046753
Validation loss: 2.410517320838026

Epoch: 5| Step: 10
Training loss: 2.7166264057159424
Validation loss: 2.4063346052682526

Epoch: 67| Step: 0
Training loss: 2.9652702808380127
Validation loss: 2.401156579294512

Epoch: 5| Step: 1
Training loss: 2.717690944671631
Validation loss: 2.4092453269548315

Epoch: 5| Step: 2
Training loss: 1.5209248065948486
Validation loss: 2.432517146551481

Epoch: 5| Step: 3
Training loss: 2.095747709274292
Validation loss: 2.4512731695687897

Epoch: 5| Step: 4
Training loss: 3.105710983276367
Validation loss: 2.4819843845982708

Epoch: 5| Step: 5
Training loss: 2.920231342315674
Validation loss: 2.498871377719346

Epoch: 5| Step: 6
Training loss: 2.7293496131896973
Validation loss: 2.4635466119294525

Epoch: 5| Step: 7
Training loss: 2.476541519165039
Validation loss: 2.4456824359073432

Epoch: 5| Step: 8
Training loss: 2.433354616165161
Validation loss: 2.413770378276866

Epoch: 5| Step: 9
Training loss: 3.2393646240234375
Validation loss: 2.4160260513264644

Epoch: 5| Step: 10
Training loss: 3.149789810180664
Validation loss: 2.4061364845563005

Epoch: 68| Step: 0
Training loss: 2.160674810409546
Validation loss: 2.4049268204678773

Epoch: 5| Step: 1
Training loss: 3.1753246784210205
Validation loss: 2.3940022299366612

Epoch: 5| Step: 2
Training loss: 2.6302390098571777
Validation loss: 2.3949184161360546

Epoch: 5| Step: 3
Training loss: 2.9442901611328125
Validation loss: 2.395444259848646

Epoch: 5| Step: 4
Training loss: 3.0267913341522217
Validation loss: 2.3933790986255934

Epoch: 5| Step: 5
Training loss: 2.3433897495269775
Validation loss: 2.3971050964888705

Epoch: 5| Step: 6
Training loss: 2.306854009628296
Validation loss: 2.39506108273742

Epoch: 5| Step: 7
Training loss: 2.286149501800537
Validation loss: 2.3896033827976515

Epoch: 5| Step: 8
Training loss: 2.526583194732666
Validation loss: 2.3919297136286253

Epoch: 5| Step: 9
Training loss: 2.628511667251587
Validation loss: 2.3936992281226703

Epoch: 5| Step: 10
Training loss: 3.100163698196411
Validation loss: 2.402259562605171

Epoch: 69| Step: 0
Training loss: 2.681793689727783
Validation loss: 2.4110446668440297

Epoch: 5| Step: 1
Training loss: 2.668524980545044
Validation loss: 2.4355828838963665

Epoch: 5| Step: 2
Training loss: 2.6003260612487793
Validation loss: 2.457544852328557

Epoch: 5| Step: 3
Training loss: 2.6912739276885986
Validation loss: 2.450100962833692

Epoch: 5| Step: 4
Training loss: 3.0927088260650635
Validation loss: 2.4414330092809533

Epoch: 5| Step: 5
Training loss: 2.8624520301818848
Validation loss: 2.4244600419075257

Epoch: 5| Step: 6
Training loss: 2.294095277786255
Validation loss: 2.424856665313885

Epoch: 5| Step: 7
Training loss: 2.6840662956237793
Validation loss: 2.4174053489520984

Epoch: 5| Step: 8
Training loss: 3.027204990386963
Validation loss: 2.400675663384058

Epoch: 5| Step: 9
Training loss: 2.4251906871795654
Validation loss: 2.4004199940671205

Epoch: 5| Step: 10
Training loss: 1.9955428838729858
Validation loss: 2.3878625310877317

Epoch: 70| Step: 0
Training loss: 2.4453532695770264
Validation loss: 2.394157476322625

Epoch: 5| Step: 1
Training loss: 2.4149529933929443
Validation loss: 2.3863181555142967

Epoch: 5| Step: 2
Training loss: 2.2518954277038574
Validation loss: 2.387551651206068

Epoch: 5| Step: 3
Training loss: 2.017969846725464
Validation loss: 2.390407613528672

Epoch: 5| Step: 4
Training loss: 3.0797438621520996
Validation loss: 2.3861592969586773

Epoch: 5| Step: 5
Training loss: 2.259878158569336
Validation loss: 2.3903603758863223

Epoch: 5| Step: 6
Training loss: 3.4202170372009277
Validation loss: 2.393048986311882

Epoch: 5| Step: 7
Training loss: 2.44838809967041
Validation loss: 2.3888122625248407

Epoch: 5| Step: 8
Training loss: 2.546355724334717
Validation loss: 2.3794647775670534

Epoch: 5| Step: 9
Training loss: 2.9650964736938477
Validation loss: 2.3735201333158757

Epoch: 5| Step: 10
Training loss: 3.116440534591675
Validation loss: 2.366558746625018

Epoch: 71| Step: 0
Training loss: 2.444089412689209
Validation loss: 2.3762170063552035

Epoch: 5| Step: 1
Training loss: 2.77555775642395
Validation loss: 2.360047068647159

Epoch: 5| Step: 2
Training loss: 2.7008371353149414
Validation loss: 2.3661434778603176

Epoch: 5| Step: 3
Training loss: 2.735605001449585
Validation loss: 2.378645622602073

Epoch: 5| Step: 4
Training loss: 2.444899082183838
Validation loss: 2.398191354608023

Epoch: 5| Step: 5
Training loss: 3.00543475151062
Validation loss: 2.4135233074106197

Epoch: 5| Step: 6
Training loss: 2.5140433311462402
Validation loss: 2.405676967354231

Epoch: 5| Step: 7
Training loss: 2.5721843242645264
Validation loss: 2.3876551197421167

Epoch: 5| Step: 8
Training loss: 2.811497926712036
Validation loss: 2.38217939612686

Epoch: 5| Step: 9
Training loss: 2.742307186126709
Validation loss: 2.3626765025559293

Epoch: 5| Step: 10
Training loss: 2.1074047088623047
Validation loss: 2.353003163491526

Epoch: 72| Step: 0
Training loss: 2.867657423019409
Validation loss: 2.391321151487289

Epoch: 5| Step: 1
Training loss: 2.8754806518554688
Validation loss: 2.3596976623740247

Epoch: 5| Step: 2
Training loss: 2.513784408569336
Validation loss: 2.3518699343486498

Epoch: 5| Step: 3
Training loss: 2.8347415924072266
Validation loss: 2.3441737954334547

Epoch: 5| Step: 4
Training loss: 2.406557559967041
Validation loss: 2.348936644933557

Epoch: 5| Step: 5
Training loss: 2.942481517791748
Validation loss: 2.3530695899840324

Epoch: 5| Step: 6
Training loss: 2.2112174034118652
Validation loss: 2.3673125774629655

Epoch: 5| Step: 7
Training loss: 2.228397846221924
Validation loss: 2.377464807161721

Epoch: 5| Step: 8
Training loss: 2.3465778827667236
Validation loss: 2.4377107645875666

Epoch: 5| Step: 9
Training loss: 3.0342276096343994
Validation loss: 2.455901389480919

Epoch: 5| Step: 10
Training loss: 2.456724166870117
Validation loss: 2.501466340916131

Epoch: 73| Step: 0
Training loss: 2.867628574371338
Validation loss: 2.5274091920545025

Epoch: 5| Step: 1
Training loss: 2.8480396270751953
Validation loss: 2.4938708095140356

Epoch: 5| Step: 2
Training loss: 3.235516309738159
Validation loss: 2.4328484381398847

Epoch: 5| Step: 3
Training loss: 2.3575568199157715
Validation loss: 2.4220950552212295

Epoch: 5| Step: 4
Training loss: 2.2079062461853027
Validation loss: 2.3926907816240863

Epoch: 5| Step: 5
Training loss: 2.7879257202148438
Validation loss: 2.371990324348532

Epoch: 5| Step: 6
Training loss: 2.5814850330352783
Validation loss: 2.365305223772603

Epoch: 5| Step: 7
Training loss: 2.655902147293091
Validation loss: 2.3580205901976554

Epoch: 5| Step: 8
Training loss: 1.4953049421310425
Validation loss: 2.3486795284414805

Epoch: 5| Step: 9
Training loss: 3.065688133239746
Validation loss: 2.3485697507858276

Epoch: 5| Step: 10
Training loss: 2.689208984375
Validation loss: 2.340634561354114

Epoch: 74| Step: 0
Training loss: 2.901442050933838
Validation loss: 2.3439914872569423

Epoch: 5| Step: 1
Training loss: 2.639848470687866
Validation loss: 2.351401416204309

Epoch: 5| Step: 2
Training loss: 3.0848565101623535
Validation loss: 2.353356769008021

Epoch: 5| Step: 3
Training loss: 3.2919814586639404
Validation loss: 2.3567559770358506

Epoch: 5| Step: 4
Training loss: 1.8313432931900024
Validation loss: 2.379668694670482

Epoch: 5| Step: 5
Training loss: 2.541851758956909
Validation loss: 2.390864351744293

Epoch: 5| Step: 6
Training loss: 2.8649423122406006
Validation loss: 2.401710187235186

Epoch: 5| Step: 7
Training loss: 2.0637688636779785
Validation loss: 2.4211080920311714

Epoch: 5| Step: 8
Training loss: 2.0115129947662354
Validation loss: 2.4175927997917257

Epoch: 5| Step: 9
Training loss: 2.953000068664551
Validation loss: 2.4165754087509645

Epoch: 5| Step: 10
Training loss: 2.5701801776885986
Validation loss: 2.4144114012359292

Epoch: 75| Step: 0
Training loss: 1.6425453424453735
Validation loss: 2.3967745073380007

Epoch: 5| Step: 1
Training loss: 2.5386157035827637
Validation loss: 2.353445282546423

Epoch: 5| Step: 2
Training loss: 2.958242416381836
Validation loss: 2.3408359622442596

Epoch: 5| Step: 3
Training loss: 3.1045444011688232
Validation loss: 2.329309986483666

Epoch: 5| Step: 4
Training loss: 2.3704707622528076
Validation loss: 2.326468675367294

Epoch: 5| Step: 5
Training loss: 3.1868622303009033
Validation loss: 2.326831638172109

Epoch: 5| Step: 6
Training loss: 2.370736598968506
Validation loss: 2.3260866454852525

Epoch: 5| Step: 7
Training loss: 2.6260933876037598
Validation loss: 2.3267023512112197

Epoch: 5| Step: 8
Training loss: 2.6756155490875244
Validation loss: 2.325227327244256

Epoch: 5| Step: 9
Training loss: 2.3697848320007324
Validation loss: 2.326651245035151

Epoch: 5| Step: 10
Training loss: 2.843809127807617
Validation loss: 2.3222527888513382

Epoch: 76| Step: 0
Training loss: 3.126424551010132
Validation loss: 2.3283555917842413

Epoch: 5| Step: 1
Training loss: 2.2175114154815674
Validation loss: 2.324751656542542

Epoch: 5| Step: 2
Training loss: 1.990920066833496
Validation loss: 2.3307105315628873

Epoch: 5| Step: 3
Training loss: 2.5456109046936035
Validation loss: 2.34166298502235

Epoch: 5| Step: 4
Training loss: 2.3888871669769287
Validation loss: 2.4009134077256724

Epoch: 5| Step: 5
Training loss: 2.840055465698242
Validation loss: 2.488700302698279

Epoch: 5| Step: 6
Training loss: 3.456352710723877
Validation loss: 2.4860241131115983

Epoch: 5| Step: 7
Training loss: 2.190718412399292
Validation loss: 2.388341637067897

Epoch: 5| Step: 8
Training loss: 2.880053997039795
Validation loss: 2.3571966924974994

Epoch: 5| Step: 9
Training loss: 2.6313929557800293
Validation loss: 2.3471911902068765

Epoch: 5| Step: 10
Training loss: 2.5279078483581543
Validation loss: 2.334325510968444

Epoch: 77| Step: 0
Training loss: 2.377803325653076
Validation loss: 2.324375226933469

Epoch: 5| Step: 1
Training loss: 2.7254223823547363
Validation loss: 2.3239540169315953

Epoch: 5| Step: 2
Training loss: 3.0350427627563477
Validation loss: 2.3182916051598004

Epoch: 5| Step: 3
Training loss: 2.5794777870178223
Validation loss: 2.314476046510922

Epoch: 5| Step: 4
Training loss: 2.3220136165618896
Validation loss: 2.3136359594201528

Epoch: 5| Step: 5
Training loss: 2.011735677719116
Validation loss: 2.3105694478557957

Epoch: 5| Step: 6
Training loss: 2.5970611572265625
Validation loss: 2.3117197072634132

Epoch: 5| Step: 7
Training loss: 2.564415216445923
Validation loss: 2.31252618246181

Epoch: 5| Step: 8
Training loss: 2.8354365825653076
Validation loss: 2.308573179347541

Epoch: 5| Step: 9
Training loss: 3.1781413555145264
Validation loss: 2.310715695863129

Epoch: 5| Step: 10
Training loss: 2.2743592262268066
Validation loss: 2.312799681899368

Epoch: 78| Step: 0
Training loss: 2.783689022064209
Validation loss: 2.316555480803213

Epoch: 5| Step: 1
Training loss: 2.52091908454895
Validation loss: 2.3238747350631224

Epoch: 5| Step: 2
Training loss: 1.9679858684539795
Validation loss: 2.326271777511925

Epoch: 5| Step: 3
Training loss: 3.0027527809143066
Validation loss: 2.3344187992875294

Epoch: 5| Step: 4
Training loss: 2.8153395652770996
Validation loss: 2.3260814092492543

Epoch: 5| Step: 5
Training loss: 2.6996817588806152
Validation loss: 2.3375012720784833

Epoch: 5| Step: 6
Training loss: 2.3702943325042725
Validation loss: 2.3357780030978623

Epoch: 5| Step: 7
Training loss: 3.1730964183807373
Validation loss: 2.340625096392888

Epoch: 5| Step: 8
Training loss: 2.6485090255737305
Validation loss: 2.3276787393836567

Epoch: 5| Step: 9
Training loss: 1.658736228942871
Validation loss: 2.348111883286507

Epoch: 5| Step: 10
Training loss: 2.7454535961151123
Validation loss: 2.362670943301211

Epoch: 79| Step: 0
Training loss: 3.2782230377197266
Validation loss: 2.3864230391799763

Epoch: 5| Step: 1
Training loss: 3.071896553039551
Validation loss: 2.395151376724243

Epoch: 5| Step: 2
Training loss: 2.2504689693450928
Validation loss: 2.3962883359642437

Epoch: 5| Step: 3
Training loss: 3.4689128398895264
Validation loss: 2.391153968790526

Epoch: 5| Step: 4
Training loss: 2.361023426055908
Validation loss: 2.3832645441896174

Epoch: 5| Step: 5
Training loss: 1.9190433025360107
Validation loss: 2.382720624246905

Epoch: 5| Step: 6
Training loss: 2.7244977951049805
Validation loss: 2.3926633250328804

Epoch: 5| Step: 7
Training loss: 2.718470811843872
Validation loss: 2.3906158183210637

Epoch: 5| Step: 8
Training loss: 2.3498895168304443
Validation loss: 2.395719797380509

Epoch: 5| Step: 9
Training loss: 2.4123873710632324
Validation loss: 2.3980079389387563

Epoch: 5| Step: 10
Training loss: 2.2218549251556396
Validation loss: 2.3946964381843485

Epoch: 80| Step: 0
Training loss: 2.708307981491089
Validation loss: 2.3940369518854285

Epoch: 5| Step: 1
Training loss: 2.3048691749572754
Validation loss: 2.396441746783513

Epoch: 5| Step: 2
Training loss: 2.276047468185425
Validation loss: 2.4098448753356934

Epoch: 5| Step: 3
Training loss: 2.5294508934020996
Validation loss: 2.422338157571772

Epoch: 5| Step: 4
Training loss: 2.786526918411255
Validation loss: 2.4124881067583637

Epoch: 5| Step: 5
Training loss: 2.3557543754577637
Validation loss: 2.3913559067633843

Epoch: 5| Step: 6
Training loss: 3.025300979614258
Validation loss: 2.38444294083503

Epoch: 5| Step: 7
Training loss: 2.650092363357544
Validation loss: 2.378295108836184

Epoch: 5| Step: 8
Training loss: 2.8974859714508057
Validation loss: 2.378119789144044

Epoch: 5| Step: 9
Training loss: 2.4521918296813965
Validation loss: 2.376387667912309

Epoch: 5| Step: 10
Training loss: 2.694719076156616
Validation loss: 2.3583516972039336

Epoch: 81| Step: 0
Training loss: 2.596165418624878
Validation loss: 2.3478047488838114

Epoch: 5| Step: 1
Training loss: 2.8752124309539795
Validation loss: 2.3432413608797136

Epoch: 5| Step: 2
Training loss: 2.6909525394439697
Validation loss: 2.336551107386107

Epoch: 5| Step: 3
Training loss: 2.3755955696105957
Validation loss: 2.3317058983669487

Epoch: 5| Step: 4
Training loss: 2.4053385257720947
Validation loss: 2.3219819735455256

Epoch: 5| Step: 5
Training loss: 2.9514589309692383
Validation loss: 2.3153320358645533

Epoch: 5| Step: 6
Training loss: 3.3525493144989014
Validation loss: 2.309379721200594

Epoch: 5| Step: 7
Training loss: 2.5208964347839355
Validation loss: 2.3066782694990917

Epoch: 5| Step: 8
Training loss: 2.1168315410614014
Validation loss: 2.3018855664037887

Epoch: 5| Step: 9
Training loss: 2.709162950515747
Validation loss: 2.306470524880194

Epoch: 5| Step: 10
Training loss: 1.719156265258789
Validation loss: 2.3089701180816977

Epoch: 82| Step: 0
Training loss: 2.4177348613739014
Validation loss: 2.3057302121193177

Epoch: 5| Step: 1
Training loss: 2.8956055641174316
Validation loss: 2.34307466014739

Epoch: 5| Step: 2
Training loss: 3.0807509422302246
Validation loss: 2.385572248889554

Epoch: 5| Step: 3
Training loss: 2.1965982913970947
Validation loss: 2.362986223672026

Epoch: 5| Step: 4
Training loss: 2.1605021953582764
Validation loss: 2.3380904607875372

Epoch: 5| Step: 5
Training loss: 2.7740800380706787
Validation loss: 2.310426640254195

Epoch: 5| Step: 6
Training loss: 2.273559808731079
Validation loss: 2.290412284994638

Epoch: 5| Step: 7
Training loss: 3.04498028755188
Validation loss: 2.2906876251261723

Epoch: 5| Step: 8
Training loss: 2.292591094970703
Validation loss: 2.29106838985156

Epoch: 5| Step: 9
Training loss: 2.8090929985046387
Validation loss: 2.289372290334394

Epoch: 5| Step: 10
Training loss: 2.3979458808898926
Validation loss: 2.2882229846010924

Epoch: 83| Step: 0
Training loss: 2.6718575954437256
Validation loss: 2.3012970493685816

Epoch: 5| Step: 1
Training loss: 2.171873092651367
Validation loss: 2.3079762125527985

Epoch: 5| Step: 2
Training loss: 2.6514368057250977
Validation loss: 2.3190447822693856

Epoch: 5| Step: 3
Training loss: 2.1191110610961914
Validation loss: 2.3316991893194055

Epoch: 5| Step: 4
Training loss: 2.4197421073913574
Validation loss: 2.3135731681700675

Epoch: 5| Step: 5
Training loss: 3.4864115715026855
Validation loss: 2.308070795510405

Epoch: 5| Step: 6
Training loss: 3.418170928955078
Validation loss: 2.300512990643901

Epoch: 5| Step: 7
Training loss: 2.2521724700927734
Validation loss: 2.294103681400258

Epoch: 5| Step: 8
Training loss: 2.053809404373169
Validation loss: 2.2874394078408518

Epoch: 5| Step: 9
Training loss: 2.5613627433776855
Validation loss: 2.278073000651534

Epoch: 5| Step: 10
Training loss: 2.7912437915802
Validation loss: 2.283331355740947

Epoch: 84| Step: 0
Training loss: 1.8113685846328735
Validation loss: 2.28271415669431

Epoch: 5| Step: 1
Training loss: 2.6699280738830566
Validation loss: 2.2761644317257788

Epoch: 5| Step: 2
Training loss: 2.6409249305725098
Validation loss: 2.276752056614045

Epoch: 5| Step: 3
Training loss: 2.7311222553253174
Validation loss: 2.2877074556965984

Epoch: 5| Step: 4
Training loss: 2.9992098808288574
Validation loss: 2.302448721342189

Epoch: 5| Step: 5
Training loss: 2.9677798748016357
Validation loss: 2.310019157266104

Epoch: 5| Step: 6
Training loss: 2.446894645690918
Validation loss: 2.3067535764427594

Epoch: 5| Step: 7
Training loss: 2.605215311050415
Validation loss: 2.356866903202508

Epoch: 5| Step: 8
Training loss: 2.678795337677002
Validation loss: 2.423924366633097

Epoch: 5| Step: 9
Training loss: 2.629924774169922
Validation loss: 2.480069327098067

Epoch: 5| Step: 10
Training loss: 2.2638537883758545
Validation loss: 2.420115537540887

Epoch: 85| Step: 0
Training loss: 2.7199859619140625
Validation loss: 2.363796877604659

Epoch: 5| Step: 1
Training loss: 2.1282191276550293
Validation loss: 2.331412502514419

Epoch: 5| Step: 2
Training loss: 2.5390589237213135
Validation loss: 2.2859094040368193

Epoch: 5| Step: 3
Training loss: 2.3214306831359863
Validation loss: 2.27379899127509

Epoch: 5| Step: 4
Training loss: 2.4003090858459473
Validation loss: 2.2731971368994763

Epoch: 5| Step: 5
Training loss: 3.044513463973999
Validation loss: 2.280518421562769

Epoch: 5| Step: 6
Training loss: 1.8219608068466187
Validation loss: 2.2746291724584435

Epoch: 5| Step: 7
Training loss: 2.740908145904541
Validation loss: 2.2623476084842475

Epoch: 5| Step: 8
Training loss: 2.360461950302124
Validation loss: 2.26533870286839

Epoch: 5| Step: 9
Training loss: 2.7705116271972656
Validation loss: 2.26548864764552

Epoch: 5| Step: 10
Training loss: 3.6362380981445312
Validation loss: 2.2633192885306572

Epoch: 86| Step: 0
Training loss: 2.7333574295043945
Validation loss: 2.272438795335831

Epoch: 5| Step: 1
Training loss: 2.219860553741455
Validation loss: 2.270399232064524

Epoch: 5| Step: 2
Training loss: 3.2918038368225098
Validation loss: 2.266937689114642

Epoch: 5| Step: 3
Training loss: 2.4367799758911133
Validation loss: 2.27342999622386

Epoch: 5| Step: 4
Training loss: 2.1576154232025146
Validation loss: 2.283509344182989

Epoch: 5| Step: 5
Training loss: 3.2861199378967285
Validation loss: 2.31509978284118

Epoch: 5| Step: 6
Training loss: 2.4797964096069336
Validation loss: 2.354984810275416

Epoch: 5| Step: 7
Training loss: 2.4414377212524414
Validation loss: 2.358923763357183

Epoch: 5| Step: 8
Training loss: 2.232203960418701
Validation loss: 2.3191774814359603

Epoch: 5| Step: 9
Training loss: 2.135348081588745
Validation loss: 2.308224283238893

Epoch: 5| Step: 10
Training loss: 2.7820358276367188
Validation loss: 2.3158833262740925

Epoch: 87| Step: 0
Training loss: 2.165060043334961
Validation loss: 2.32348346453841

Epoch: 5| Step: 1
Training loss: 2.486598491668701
Validation loss: 2.335341292042886

Epoch: 5| Step: 2
Training loss: 2.8781676292419434
Validation loss: 2.363691545301868

Epoch: 5| Step: 3
Training loss: 1.8151617050170898
Validation loss: 2.3679465273375153

Epoch: 5| Step: 4
Training loss: 2.218966007232666
Validation loss: 2.3728686122484106

Epoch: 5| Step: 5
Training loss: 3.0024969577789307
Validation loss: 2.3758830306350545

Epoch: 5| Step: 6
Training loss: 3.0326170921325684
Validation loss: 2.3801145579225276

Epoch: 5| Step: 7
Training loss: 2.729949474334717
Validation loss: 2.3795376490521174

Epoch: 5| Step: 8
Training loss: 2.912343740463257
Validation loss: 2.331617063091647

Epoch: 5| Step: 9
Training loss: 2.4441323280334473
Validation loss: 2.298271676545502

Epoch: 5| Step: 10
Training loss: 2.5635483264923096
Validation loss: 2.271026690800985

Epoch: 88| Step: 0
Training loss: 3.0153489112854004
Validation loss: 2.2766108179605133

Epoch: 5| Step: 1
Training loss: 2.1637330055236816
Validation loss: 2.2962106991839666

Epoch: 5| Step: 2
Training loss: 2.8208560943603516
Validation loss: 2.3106591804053194

Epoch: 5| Step: 3
Training loss: 3.315030574798584
Validation loss: 2.2813475695989465

Epoch: 5| Step: 4
Training loss: 2.8866641521453857
Validation loss: 2.2694287146291425

Epoch: 5| Step: 5
Training loss: 2.2320163249969482
Validation loss: 2.2692392077497257

Epoch: 5| Step: 6
Training loss: 3.0742859840393066
Validation loss: 2.28937759963415

Epoch: 5| Step: 7
Training loss: 2.4342288970947266
Validation loss: 2.2959426449191187

Epoch: 5| Step: 8
Training loss: 2.086310863494873
Validation loss: 2.2985694075143464

Epoch: 5| Step: 9
Training loss: 2.3121800422668457
Validation loss: 2.3210125225846485

Epoch: 5| Step: 10
Training loss: 1.7146227359771729
Validation loss: 2.379654005009641

Epoch: 89| Step: 0
Training loss: 3.2415664196014404
Validation loss: 2.4603842894236245

Epoch: 5| Step: 1
Training loss: 3.3568453788757324
Validation loss: 2.5048226592361287

Epoch: 5| Step: 2
Training loss: 2.9143593311309814
Validation loss: 2.520424699270597

Epoch: 5| Step: 3
Training loss: 2.74613881111145
Validation loss: 2.4828008759406304

Epoch: 5| Step: 4
Training loss: 3.0422170162200928
Validation loss: 2.4481044712887017

Epoch: 5| Step: 5
Training loss: 2.2876203060150146
Validation loss: 2.3546440319348405

Epoch: 5| Step: 6
Training loss: 2.3657772541046143
Validation loss: 2.293967990465062

Epoch: 5| Step: 7
Training loss: 2.5728111267089844
Validation loss: 2.2721244058301373

Epoch: 5| Step: 8
Training loss: 2.0756328105926514
Validation loss: 2.285124763365715

Epoch: 5| Step: 9
Training loss: 2.130967378616333
Validation loss: 2.311874043556952

Epoch: 5| Step: 10
Training loss: 2.166996479034424
Validation loss: 2.3616858707961215

Epoch: 90| Step: 0
Training loss: 2.6109111309051514
Validation loss: 2.3989356102481967

Epoch: 5| Step: 1
Training loss: 3.1831846237182617
Validation loss: 2.3581893264606433

Epoch: 5| Step: 2
Training loss: 2.5384910106658936
Validation loss: 2.3333626460003596

Epoch: 5| Step: 3
Training loss: 2.640913486480713
Validation loss: 2.3091538875333724

Epoch: 5| Step: 4
Training loss: 2.080482006072998
Validation loss: 2.3022678757226593

Epoch: 5| Step: 5
Training loss: 2.6005947589874268
Validation loss: 2.3331820605903544

Epoch: 5| Step: 6
Training loss: 2.8538284301757812
Validation loss: 2.3889973599423646

Epoch: 5| Step: 7
Training loss: 3.1414668560028076
Validation loss: 2.4356251737122894

Epoch: 5| Step: 8
Training loss: 2.6969497203826904
Validation loss: 2.3834063609441123

Epoch: 5| Step: 9
Training loss: 1.8503961563110352
Validation loss: 2.3367220817073697

Epoch: 5| Step: 10
Training loss: 2.503775119781494
Validation loss: 2.2971725258775937

Epoch: 91| Step: 0
Training loss: 2.7376022338867188
Validation loss: 2.2885748545328775

Epoch: 5| Step: 1
Training loss: 2.4783756732940674
Validation loss: 2.2762363572274484

Epoch: 5| Step: 2
Training loss: 3.490940570831299
Validation loss: 2.292079710191296

Epoch: 5| Step: 3
Training loss: 2.6885132789611816
Validation loss: 2.2707115783486316

Epoch: 5| Step: 4
Training loss: 2.4036989212036133
Validation loss: 2.2559352767082954

Epoch: 5| Step: 5
Training loss: 1.695068359375
Validation loss: 2.247619734015516

Epoch: 5| Step: 6
Training loss: 2.703517198562622
Validation loss: 2.2499519753199753

Epoch: 5| Step: 7
Training loss: 2.2650694847106934
Validation loss: 2.243399074000697

Epoch: 5| Step: 8
Training loss: 2.9398136138916016
Validation loss: 2.251661931314776

Epoch: 5| Step: 9
Training loss: 2.593616485595703
Validation loss: 2.2469849176304315

Epoch: 5| Step: 10
Training loss: 2.118968963623047
Validation loss: 2.2479494105103197

Epoch: 92| Step: 0
Training loss: 2.6594619750976562
Validation loss: 2.2439660410727225

Epoch: 5| Step: 1
Training loss: 2.585482597351074
Validation loss: 2.233900782882526

Epoch: 5| Step: 2
Training loss: 2.521080493927002
Validation loss: 2.2394367238526702

Epoch: 5| Step: 3
Training loss: 2.416842222213745
Validation loss: 2.2347497286335116

Epoch: 5| Step: 4
Training loss: 2.796478748321533
Validation loss: 2.2376261834175355

Epoch: 5| Step: 5
Training loss: 2.4495511054992676
Validation loss: 2.245631883221288

Epoch: 5| Step: 6
Training loss: 2.470393657684326
Validation loss: 2.256911232907285

Epoch: 5| Step: 7
Training loss: 2.2928431034088135
Validation loss: 2.2488234376394622

Epoch: 5| Step: 8
Training loss: 2.314162015914917
Validation loss: 2.263404070690114

Epoch: 5| Step: 9
Training loss: 2.310807943344116
Validation loss: 2.2734855682619157

Epoch: 5| Step: 10
Training loss: 3.1089208126068115
Validation loss: 2.2857494072247575

Epoch: 93| Step: 0
Training loss: 2.285048246383667
Validation loss: 2.316404010659905

Epoch: 5| Step: 1
Training loss: 2.80541729927063
Validation loss: 2.3134234592478764

Epoch: 5| Step: 2
Training loss: 3.2356185913085938
Validation loss: 2.31154804588646

Epoch: 5| Step: 3
Training loss: 2.539966583251953
Validation loss: 2.2753837800795034

Epoch: 5| Step: 4
Training loss: 2.216153621673584
Validation loss: 2.261300915031023

Epoch: 5| Step: 5
Training loss: 2.0099949836730957
Validation loss: 2.257142522001779

Epoch: 5| Step: 6
Training loss: 2.8867695331573486
Validation loss: 2.2398380118031658

Epoch: 5| Step: 7
Training loss: 2.631734848022461
Validation loss: 2.235180224141767

Epoch: 5| Step: 8
Training loss: 2.9742307662963867
Validation loss: 2.239240136197818

Epoch: 5| Step: 9
Training loss: 2.342696189880371
Validation loss: 2.2369146206045665

Epoch: 5| Step: 10
Training loss: 1.92523193359375
Validation loss: 2.2366424568237795

Epoch: 94| Step: 0
Training loss: 2.340855121612549
Validation loss: 2.2459953228632608

Epoch: 5| Step: 1
Training loss: 2.2037179470062256
Validation loss: 2.266461656939599

Epoch: 5| Step: 2
Training loss: 2.605876922607422
Validation loss: 2.276410336135536

Epoch: 5| Step: 3
Training loss: 2.0476577281951904
Validation loss: 2.2760878916709655

Epoch: 5| Step: 4
Training loss: 1.866210699081421
Validation loss: 2.2627328903444353

Epoch: 5| Step: 5
Training loss: 2.938225269317627
Validation loss: 2.2555317724904707

Epoch: 5| Step: 6
Training loss: 2.9214682579040527
Validation loss: 2.265885255670035

Epoch: 5| Step: 7
Training loss: 2.9126594066619873
Validation loss: 2.2644788347264773

Epoch: 5| Step: 8
Training loss: 2.4210169315338135
Validation loss: 2.2641854645103536

Epoch: 5| Step: 9
Training loss: 2.3898096084594727
Validation loss: 2.2583917546015915

Epoch: 5| Step: 10
Training loss: 3.337386131286621
Validation loss: 2.261017809632004

Epoch: 95| Step: 0
Training loss: 2.305044174194336
Validation loss: 2.249384175064743

Epoch: 5| Step: 1
Training loss: 2.3944365978240967
Validation loss: 2.2457564210378997

Epoch: 5| Step: 2
Training loss: 1.7833064794540405
Validation loss: 2.2669127064366497

Epoch: 5| Step: 3
Training loss: 2.699816942214966
Validation loss: 2.288555666964541

Epoch: 5| Step: 4
Training loss: 2.863656759262085
Validation loss: 2.288461249361756

Epoch: 5| Step: 5
Training loss: 2.3128318786621094
Validation loss: 2.274626480635776

Epoch: 5| Step: 6
Training loss: 2.655000686645508
Validation loss: 2.258091136973391

Epoch: 5| Step: 7
Training loss: 3.0846874713897705
Validation loss: 2.232765369517829

Epoch: 5| Step: 8
Training loss: 2.8302791118621826
Validation loss: 2.231154123942057

Epoch: 5| Step: 9
Training loss: 2.4288578033447266
Validation loss: 2.2302370686684885

Epoch: 5| Step: 10
Training loss: 2.518136978149414
Validation loss: 2.235675570785358

Epoch: 96| Step: 0
Training loss: 2.4383537769317627
Validation loss: 2.2315757274627686

Epoch: 5| Step: 1
Training loss: 1.7856616973876953
Validation loss: 2.227304167644952

Epoch: 5| Step: 2
Training loss: 2.8814315795898438
Validation loss: 2.2344705007409535

Epoch: 5| Step: 3
Training loss: 2.815927743911743
Validation loss: 2.2644916042204826

Epoch: 5| Step: 4
Training loss: 3.3496322631835938
Validation loss: 2.3259399962681595

Epoch: 5| Step: 5
Training loss: 2.278207302093506
Validation loss: 2.349369587436799

Epoch: 5| Step: 6
Training loss: 2.6015753746032715
Validation loss: 2.347124284313571

Epoch: 5| Step: 7
Training loss: 2.0919761657714844
Validation loss: 2.3283551610926145

Epoch: 5| Step: 8
Training loss: 2.4296915531158447
Validation loss: 2.3039917856134395

Epoch: 5| Step: 9
Training loss: 2.5279133319854736
Validation loss: 2.312092417029924

Epoch: 5| Step: 10
Training loss: 2.6949241161346436
Validation loss: 2.2855122679023334

Epoch: 97| Step: 0
Training loss: 2.5017080307006836
Validation loss: 2.2604714926852973

Epoch: 5| Step: 1
Training loss: 2.5857906341552734
Validation loss: 2.257223331800071

Epoch: 5| Step: 2
Training loss: 2.7050862312316895
Validation loss: 2.2288821153743292

Epoch: 5| Step: 3
Training loss: 2.742129325866699
Validation loss: 2.2213878670046405

Epoch: 5| Step: 4
Training loss: 2.9314682483673096
Validation loss: 2.218465200034521

Epoch: 5| Step: 5
Training loss: 2.7413601875305176
Validation loss: 2.2184238100564606

Epoch: 5| Step: 6
Training loss: 2.296414852142334
Validation loss: 2.216357292667512

Epoch: 5| Step: 7
Training loss: 2.6251614093780518
Validation loss: 2.2116021097347303

Epoch: 5| Step: 8
Training loss: 2.2539467811584473
Validation loss: 2.211912937061761

Epoch: 5| Step: 9
Training loss: 2.0504653453826904
Validation loss: 2.2153244608192035

Epoch: 5| Step: 10
Training loss: 2.5515754222869873
Validation loss: 2.202083026209185

Epoch: 98| Step: 0
Training loss: 2.2130956649780273
Validation loss: 2.194626933784895

Epoch: 5| Step: 1
Training loss: 3.1734495162963867
Validation loss: 2.2039670162303473

Epoch: 5| Step: 2
Training loss: 1.659849762916565
Validation loss: 2.218880958454583

Epoch: 5| Step: 3
Training loss: 2.5341296195983887
Validation loss: 2.224229728021929

Epoch: 5| Step: 4
Training loss: 3.402510404586792
Validation loss: 2.220686120371665

Epoch: 5| Step: 5
Training loss: 2.9562621116638184
Validation loss: 2.2364036293439966

Epoch: 5| Step: 6
Training loss: 2.038909912109375
Validation loss: 2.220238349770987

Epoch: 5| Step: 7
Training loss: 2.533583879470825
Validation loss: 2.2062413205382643

Epoch: 5| Step: 8
Training loss: 2.553870439529419
Validation loss: 2.2118121885484263

Epoch: 5| Step: 9
Training loss: 2.2898802757263184
Validation loss: 2.2097019828775877

Epoch: 5| Step: 10
Training loss: 2.16487455368042
Validation loss: 2.2127737640052714

Epoch: 99| Step: 0
Training loss: 2.264094829559326
Validation loss: 2.2046083455444663

Epoch: 5| Step: 1
Training loss: 2.483887195587158
Validation loss: 2.22009361943891

Epoch: 5| Step: 2
Training loss: 2.9109675884246826
Validation loss: 2.2194938762213594

Epoch: 5| Step: 3
Training loss: 2.2472457885742188
Validation loss: 2.228899273821103

Epoch: 5| Step: 4
Training loss: 2.939535140991211
Validation loss: 2.2360928084260676

Epoch: 5| Step: 5
Training loss: 2.2754809856414795
Validation loss: 2.242023321890062

Epoch: 5| Step: 6
Training loss: 2.2289364337921143
Validation loss: 2.2625013730859243

Epoch: 5| Step: 7
Training loss: 1.9667469263076782
Validation loss: 2.2637012209943546

Epoch: 5| Step: 8
Training loss: 2.626556396484375
Validation loss: 2.274454618013033

Epoch: 5| Step: 9
Training loss: 2.663196563720703
Validation loss: 2.2808024729451826

Epoch: 5| Step: 10
Training loss: 3.1056532859802246
Validation loss: 2.27332482799407

Epoch: 100| Step: 0
Training loss: 2.566763401031494
Validation loss: 2.232237490274573

Epoch: 5| Step: 1
Training loss: 3.003420114517212
Validation loss: 2.235667828590639

Epoch: 5| Step: 2
Training loss: 2.5312302112579346
Validation loss: 2.216268531737789

Epoch: 5| Step: 3
Training loss: 2.2282559871673584
Validation loss: 2.210535808276105

Epoch: 5| Step: 4
Training loss: 2.326777935028076
Validation loss: 2.206018317130304

Epoch: 5| Step: 5
Training loss: 2.5799248218536377
Validation loss: 2.211532638918969

Epoch: 5| Step: 6
Training loss: 2.433332920074463
Validation loss: 2.2186268350129486

Epoch: 5| Step: 7
Training loss: 1.9697265625
Validation loss: 2.2143873873577324

Epoch: 5| Step: 8
Training loss: 3.137892961502075
Validation loss: 2.2057629195592736

Epoch: 5| Step: 9
Training loss: 2.0637478828430176
Validation loss: 2.200976038491854

Epoch: 5| Step: 10
Training loss: 2.984853982925415
Validation loss: 2.1973339972957486

Epoch: 101| Step: 0
Training loss: 2.2442209720611572
Validation loss: 2.215217387804421

Epoch: 5| Step: 1
Training loss: 2.740154504776001
Validation loss: 2.2103729363410705

Epoch: 5| Step: 2
Training loss: 2.476200819015503
Validation loss: 2.2175980434622815

Epoch: 5| Step: 3
Training loss: 2.5206215381622314
Validation loss: 2.22970643607519

Epoch: 5| Step: 4
Training loss: 3.0246267318725586
Validation loss: 2.2417749615125757

Epoch: 5| Step: 5
Training loss: 1.9207290410995483
Validation loss: 2.250786313446619

Epoch: 5| Step: 6
Training loss: 2.8472187519073486
Validation loss: 2.2581072468911447

Epoch: 5| Step: 7
Training loss: 2.4486186504364014
Validation loss: 2.264130151400002

Epoch: 5| Step: 8
Training loss: 2.9053099155426025
Validation loss: 2.2554909054951002

Epoch: 5| Step: 9
Training loss: 2.650850772857666
Validation loss: 2.2252978560745076

Epoch: 5| Step: 10
Training loss: 1.6503560543060303
Validation loss: 2.220257984694614

Epoch: 102| Step: 0
Training loss: 2.2526843547821045
Validation loss: 2.216108329834477

Epoch: 5| Step: 1
Training loss: 2.771289825439453
Validation loss: 2.199788024348597

Epoch: 5| Step: 2
Training loss: 1.9208619594573975
Validation loss: 2.186600510792066

Epoch: 5| Step: 3
Training loss: 3.05088210105896
Validation loss: 2.19138890312564

Epoch: 5| Step: 4
Training loss: 2.4562582969665527
Validation loss: 2.189921017616026

Epoch: 5| Step: 5
Training loss: 2.4470791816711426
Validation loss: 2.2028933673776607

Epoch: 5| Step: 6
Training loss: 3.0349414348602295
Validation loss: 2.204862333113147

Epoch: 5| Step: 7
Training loss: 1.9683786630630493
Validation loss: 2.2158815963293916

Epoch: 5| Step: 8
Training loss: 2.4706501960754395
Validation loss: 2.2108341058095298

Epoch: 5| Step: 9
Training loss: 2.321613073348999
Validation loss: 2.20861142681491

Epoch: 5| Step: 10
Training loss: 2.798279047012329
Validation loss: 2.2001450830890286

Epoch: 103| Step: 0
Training loss: 2.3330304622650146
Validation loss: 2.2065686077199955

Epoch: 5| Step: 1
Training loss: 2.5556998252868652
Validation loss: 2.2200500478026686

Epoch: 5| Step: 2
Training loss: 2.569746971130371
Validation loss: 2.203257321029581

Epoch: 5| Step: 3
Training loss: 2.454709529876709
Validation loss: 2.192483232867333

Epoch: 5| Step: 4
Training loss: 3.0612709522247314
Validation loss: 2.1974193370470436

Epoch: 5| Step: 5
Training loss: 2.9395298957824707
Validation loss: 2.195009229003742

Epoch: 5| Step: 6
Training loss: 2.57454252243042
Validation loss: 2.196195989526728

Epoch: 5| Step: 7
Training loss: 1.9837270975112915
Validation loss: 2.1863409460231824

Epoch: 5| Step: 8
Training loss: 2.514458656311035
Validation loss: 2.189072282083573

Epoch: 5| Step: 9
Training loss: 2.178107738494873
Validation loss: 2.189066248555337

Epoch: 5| Step: 10
Training loss: 2.0710272789001465
Validation loss: 2.200021682247039

Epoch: 104| Step: 0
Training loss: 2.4266152381896973
Validation loss: 2.2166777144196215

Epoch: 5| Step: 1
Training loss: 2.543858289718628
Validation loss: 2.239702893841651

Epoch: 5| Step: 2
Training loss: 2.699094772338867
Validation loss: 2.2531847940978182

Epoch: 5| Step: 3
Training loss: 3.265432834625244
Validation loss: 2.2369503513459237

Epoch: 5| Step: 4
Training loss: 2.744508743286133
Validation loss: 2.2351900249399166

Epoch: 5| Step: 5
Training loss: 2.211869716644287
Validation loss: 2.198913199927217

Epoch: 5| Step: 6
Training loss: 2.103942632675171
Validation loss: 2.184732888334541

Epoch: 5| Step: 7
Training loss: 1.928537368774414
Validation loss: 2.1835526240769254

Epoch: 5| Step: 8
Training loss: 2.8200478553771973
Validation loss: 2.1745735829876316

Epoch: 5| Step: 9
Training loss: 2.282644748687744
Validation loss: 2.184636083982324

Epoch: 5| Step: 10
Training loss: 2.356518268585205
Validation loss: 2.178875873165746

Epoch: 105| Step: 0
Training loss: 2.908290147781372
Validation loss: 2.185856480752268

Epoch: 5| Step: 1
Training loss: 2.6184535026550293
Validation loss: 2.1887750087245816

Epoch: 5| Step: 2
Training loss: 2.4274866580963135
Validation loss: 2.189373985413582

Epoch: 5| Step: 3
Training loss: 2.4745140075683594
Validation loss: 2.2108736832936606

Epoch: 5| Step: 4
Training loss: 2.3937995433807373
Validation loss: 2.256705609701013

Epoch: 5| Step: 5
Training loss: 2.6496479511260986
Validation loss: 2.283901893964378

Epoch: 5| Step: 6
Training loss: 2.9397239685058594
Validation loss: 2.3118129468733266

Epoch: 5| Step: 7
Training loss: 2.2252230644226074
Validation loss: 2.31729188529394

Epoch: 5| Step: 8
Training loss: 2.5706241130828857
Validation loss: 2.283487004618491

Epoch: 5| Step: 9
Training loss: 2.1628849506378174
Validation loss: 2.266512422151463

Epoch: 5| Step: 10
Training loss: 2.0499327182769775
Validation loss: 2.2220764339611097

Epoch: 106| Step: 0
Training loss: 2.1450164318084717
Validation loss: 2.200783694944074

Epoch: 5| Step: 1
Training loss: 2.879645824432373
Validation loss: 2.1926955420483827

Epoch: 5| Step: 2
Training loss: 3.0393457412719727
Validation loss: 2.188262093451715

Epoch: 5| Step: 3
Training loss: 1.9596545696258545
Validation loss: 2.2028099516386628

Epoch: 5| Step: 4
Training loss: 2.5509915351867676
Validation loss: 2.197489689755183

Epoch: 5| Step: 5
Training loss: 2.5893797874450684
Validation loss: 2.19498094179297

Epoch: 5| Step: 6
Training loss: 2.1196017265319824
Validation loss: 2.1936109373646397

Epoch: 5| Step: 7
Training loss: 2.6910877227783203
Validation loss: 2.1873293948429886

Epoch: 5| Step: 8
Training loss: 2.118781328201294
Validation loss: 2.1955907178181473

Epoch: 5| Step: 9
Training loss: 2.224905014038086
Validation loss: 2.191870697083012

Epoch: 5| Step: 10
Training loss: 2.8640823364257812
Validation loss: 2.189261746662919

Epoch: 107| Step: 0
Training loss: 2.624211311340332
Validation loss: 2.1987212524619153

Epoch: 5| Step: 1
Training loss: 3.1066901683807373
Validation loss: 2.1953497240620274

Epoch: 5| Step: 2
Training loss: 2.5705084800720215
Validation loss: 2.19229293382296

Epoch: 5| Step: 3
Training loss: 3.046187162399292
Validation loss: 2.189645810793805

Epoch: 5| Step: 4
Training loss: 2.082568645477295
Validation loss: 2.1791502685957056

Epoch: 5| Step: 5
Training loss: 2.4788851737976074
Validation loss: 2.170444378288843

Epoch: 5| Step: 6
Training loss: 2.320692539215088
Validation loss: 2.1830637352440947

Epoch: 5| Step: 7
Training loss: 2.3745298385620117
Validation loss: 2.1784277282735354

Epoch: 5| Step: 8
Training loss: 2.0343546867370605
Validation loss: 2.178391202803581

Epoch: 5| Step: 9
Training loss: 2.4436306953430176
Validation loss: 2.1758622302803943

Epoch: 5| Step: 10
Training loss: 2.017408847808838
Validation loss: 2.1945222680286696

Epoch: 108| Step: 0
Training loss: 2.1647162437438965
Validation loss: 2.2037820534039567

Epoch: 5| Step: 1
Training loss: 2.751898765563965
Validation loss: 2.193475710448398

Epoch: 5| Step: 2
Training loss: 2.887955665588379
Validation loss: 2.1886775724349485

Epoch: 5| Step: 3
Training loss: 3.0816476345062256
Validation loss: 2.1803629911074074

Epoch: 5| Step: 4
Training loss: 1.9405384063720703
Validation loss: 2.189275003248645

Epoch: 5| Step: 5
Training loss: 2.058907985687256
Validation loss: 2.183815727951706

Epoch: 5| Step: 6
Training loss: 3.166022777557373
Validation loss: 2.1718761767110517

Epoch: 5| Step: 7
Training loss: 1.8894784450531006
Validation loss: 2.1732068702738774

Epoch: 5| Step: 8
Training loss: 2.603919506072998
Validation loss: 2.1834785246079966

Epoch: 5| Step: 9
Training loss: 2.0176637172698975
Validation loss: 2.20548758199138

Epoch: 5| Step: 10
Training loss: 2.446586847305298
Validation loss: 2.2319389004861154

Epoch: 109| Step: 0
Training loss: 2.1394357681274414
Validation loss: 2.2620201469749532

Epoch: 5| Step: 1
Training loss: 2.7129409313201904
Validation loss: 2.3229501401224444

Epoch: 5| Step: 2
Training loss: 2.3451943397521973
Validation loss: 2.3503762496415006

Epoch: 5| Step: 3
Training loss: 2.269833564758301
Validation loss: 2.3331501663372083

Epoch: 5| Step: 4
Training loss: 1.8209238052368164
Validation loss: 2.3366403259256834

Epoch: 5| Step: 5
Training loss: 2.775725841522217
Validation loss: 2.2405535828682686

Epoch: 5| Step: 6
Training loss: 3.1621031761169434
Validation loss: 2.196428652732603

Epoch: 5| Step: 7
Training loss: 2.5475525856018066
Validation loss: 2.1901311412934334

Epoch: 5| Step: 8
Training loss: 2.976773262023926
Validation loss: 2.209672389491912

Epoch: 5| Step: 9
Training loss: 2.436628580093384
Validation loss: 2.2178155888793287

Epoch: 5| Step: 10
Training loss: 2.5275843143463135
Validation loss: 2.203932877509825

Epoch: 110| Step: 0
Training loss: 1.9021888971328735
Validation loss: 2.2024293586771977

Epoch: 5| Step: 1
Training loss: 2.4404847621917725
Validation loss: 2.19152436717864

Epoch: 5| Step: 2
Training loss: 2.0979182720184326
Validation loss: 2.172743361483338

Epoch: 5| Step: 3
Training loss: 3.3926384449005127
Validation loss: 2.168740754486412

Epoch: 5| Step: 4
Training loss: 2.19661283493042
Validation loss: 2.1799088293506252

Epoch: 5| Step: 5
Training loss: 2.4462482929229736
Validation loss: 2.2524258705877487

Epoch: 5| Step: 6
Training loss: 2.5377962589263916
Validation loss: 2.29489440174513

Epoch: 5| Step: 7
Training loss: 2.2869999408721924
Validation loss: 2.3498165017815045

Epoch: 5| Step: 8
Training loss: 3.060296058654785
Validation loss: 2.375348990963351

Epoch: 5| Step: 9
Training loss: 2.774016857147217
Validation loss: 2.291081872037662

Epoch: 5| Step: 10
Training loss: 2.3768677711486816
Validation loss: 2.260798465821051

Epoch: 111| Step: 0
Training loss: 2.095646381378174
Validation loss: 2.217354643729425

Epoch: 5| Step: 1
Training loss: 2.4688446521759033
Validation loss: 2.2028679822080877

Epoch: 5| Step: 2
Training loss: 1.7707582712173462
Validation loss: 2.2081119988554265

Epoch: 5| Step: 3
Training loss: 2.6152119636535645
Validation loss: 2.217901873332198

Epoch: 5| Step: 4
Training loss: 2.8329272270202637
Validation loss: 2.2016750817657798

Epoch: 5| Step: 5
Training loss: 2.0025088787078857
Validation loss: 2.195024674938571

Epoch: 5| Step: 6
Training loss: 2.817415714263916
Validation loss: 2.1849051175578946

Epoch: 5| Step: 7
Training loss: 2.2425272464752197
Validation loss: 2.1763400877675703

Epoch: 5| Step: 8
Training loss: 2.364327907562256
Validation loss: 2.174178851548062

Epoch: 5| Step: 9
Training loss: 2.9248173236846924
Validation loss: 2.17152855601362

Epoch: 5| Step: 10
Training loss: 2.8078272342681885
Validation loss: 2.17042814787998

Epoch: 112| Step: 0
Training loss: 2.4299283027648926
Validation loss: 2.160306005067723

Epoch: 5| Step: 1
Training loss: 2.5822575092315674
Validation loss: 2.1647715440360447

Epoch: 5| Step: 2
Training loss: 2.5626633167266846
Validation loss: 2.161770820617676

Epoch: 5| Step: 3
Training loss: 2.527515172958374
Validation loss: 2.162453789864817

Epoch: 5| Step: 4
Training loss: 1.2620805501937866
Validation loss: 2.1660146892711682

Epoch: 5| Step: 5
Training loss: 2.725476026535034
Validation loss: 2.168289166624828

Epoch: 5| Step: 6
Training loss: 2.4949657917022705
Validation loss: 2.1805206421882875

Epoch: 5| Step: 7
Training loss: 3.111246109008789
Validation loss: 2.2150872343329975

Epoch: 5| Step: 8
Training loss: 2.5642056465148926
Validation loss: 2.23701415523406

Epoch: 5| Step: 9
Training loss: 2.3194375038146973
Validation loss: 2.225607492590463

Epoch: 5| Step: 10
Training loss: 2.637019157409668
Validation loss: 2.235619755201442

Epoch: 113| Step: 0
Training loss: 2.3807454109191895
Validation loss: 2.1884209468800533

Epoch: 5| Step: 1
Training loss: 2.18574857711792
Validation loss: 2.166146630881935

Epoch: 5| Step: 2
Training loss: 2.2748425006866455
Validation loss: 2.15802292413609

Epoch: 5| Step: 3
Training loss: 2.425018072128296
Validation loss: 2.1573500056420603

Epoch: 5| Step: 4
Training loss: 2.6679539680480957
Validation loss: 2.1525593688411098

Epoch: 5| Step: 5
Training loss: 3.0567054748535156
Validation loss: 2.1522336954711587

Epoch: 5| Step: 6
Training loss: 2.515406608581543
Validation loss: 2.148604286614285

Epoch: 5| Step: 7
Training loss: 2.380178928375244
Validation loss: 2.14912913691613

Epoch: 5| Step: 8
Training loss: 2.289444923400879
Validation loss: 2.1521579142539733

Epoch: 5| Step: 9
Training loss: 2.5280919075012207
Validation loss: 2.1504005514165407

Epoch: 5| Step: 10
Training loss: 2.239255905151367
Validation loss: 2.1532720109467864

Epoch: 114| Step: 0
Training loss: 2.6100518703460693
Validation loss: 2.1414391917567097

Epoch: 5| Step: 1
Training loss: 2.784320592880249
Validation loss: 2.1646445874244935

Epoch: 5| Step: 2
Training loss: 1.937401533126831
Validation loss: 2.173105478286743

Epoch: 5| Step: 3
Training loss: 2.049346446990967
Validation loss: 2.1719929249055925

Epoch: 5| Step: 4
Training loss: 1.916775107383728
Validation loss: 2.15964949259194

Epoch: 5| Step: 5
Training loss: 2.3447794914245605
Validation loss: 2.151585045681205

Epoch: 5| Step: 6
Training loss: 2.785022497177124
Validation loss: 2.1630322753742175

Epoch: 5| Step: 7
Training loss: 2.3448684215545654
Validation loss: 2.1634964404567594

Epoch: 5| Step: 8
Training loss: 2.9128143787384033
Validation loss: 2.175350599391486

Epoch: 5| Step: 9
Training loss: 2.5481929779052734
Validation loss: 2.17817775664791

Epoch: 5| Step: 10
Training loss: 2.6385083198547363
Validation loss: 2.194615948584772

Epoch: 115| Step: 0
Training loss: 2.5017929077148438
Validation loss: 2.193096786416987

Epoch: 5| Step: 1
Training loss: 2.5315933227539062
Validation loss: 2.17548805411144

Epoch: 5| Step: 2
Training loss: 2.4108974933624268
Validation loss: 2.1668211747241277

Epoch: 5| Step: 3
Training loss: 2.481377124786377
Validation loss: 2.133324210361768

Epoch: 5| Step: 4
Training loss: 2.1392054557800293
Validation loss: 2.136478865018455

Epoch: 5| Step: 5
Training loss: 2.1050333976745605
Validation loss: 2.1449986939789145

Epoch: 5| Step: 6
Training loss: 2.1604740619659424
Validation loss: 2.13169966718202

Epoch: 5| Step: 7
Training loss: 2.6515607833862305
Validation loss: 2.1408875796102707

Epoch: 5| Step: 8
Training loss: 2.4999215602874756
Validation loss: 2.1402793930422876

Epoch: 5| Step: 9
Training loss: 2.442700147628784
Validation loss: 2.1352761022506224

Epoch: 5| Step: 10
Training loss: 3.0802760124206543
Validation loss: 2.1470287717798704

Epoch: 116| Step: 0
Training loss: 2.226886510848999
Validation loss: 2.141091033976565

Epoch: 5| Step: 1
Training loss: 1.918410301208496
Validation loss: 2.147263788407849

Epoch: 5| Step: 2
Training loss: 2.4102535247802734
Validation loss: 2.1931910412285918

Epoch: 5| Step: 3
Training loss: 2.730318307876587
Validation loss: 2.2539452929650583

Epoch: 5| Step: 4
Training loss: 3.617835283279419
Validation loss: 2.314837036594268

Epoch: 5| Step: 5
Training loss: 2.5024971961975098
Validation loss: 2.358169630009641

Epoch: 5| Step: 6
Training loss: 2.1957364082336426
Validation loss: 2.3743870976150676

Epoch: 5| Step: 7
Training loss: 2.4764416217803955
Validation loss: 2.3255301649852465

Epoch: 5| Step: 8
Training loss: 2.2224860191345215
Validation loss: 2.1788668235143027

Epoch: 5| Step: 9
Training loss: 2.7681069374084473
Validation loss: 2.143596200532811

Epoch: 5| Step: 10
Training loss: 2.175630569458008
Validation loss: 2.1476547192501765

Epoch: 117| Step: 0
Training loss: 2.2335400581359863
Validation loss: 2.158855240832093

Epoch: 5| Step: 1
Training loss: 2.404074192047119
Validation loss: 2.156574838904924

Epoch: 5| Step: 2
Training loss: 2.407879114151001
Validation loss: 2.146289325529529

Epoch: 5| Step: 3
Training loss: 3.400669813156128
Validation loss: 2.14691246709516

Epoch: 5| Step: 4
Training loss: 2.5704588890075684
Validation loss: 2.137470112052015

Epoch: 5| Step: 5
Training loss: 2.690974473953247
Validation loss: 2.1206055379682973

Epoch: 5| Step: 6
Training loss: 2.7361998558044434
Validation loss: 2.1237118859444895

Epoch: 5| Step: 7
Training loss: 1.8871726989746094
Validation loss: 2.1502610739841255

Epoch: 5| Step: 8
Training loss: 2.0990655422210693
Validation loss: 2.1826199600773473

Epoch: 5| Step: 9
Training loss: 2.051435708999634
Validation loss: 2.2333587523429625

Epoch: 5| Step: 10
Training loss: 2.490769386291504
Validation loss: 2.2987980919499553

Epoch: 118| Step: 0
Training loss: 2.737165927886963
Validation loss: 2.3027958767388457

Epoch: 5| Step: 1
Training loss: 2.2878975868225098
Validation loss: 2.3669726899875108

Epoch: 5| Step: 2
Training loss: 2.555734157562256
Validation loss: 2.385082960128784

Epoch: 5| Step: 3
Training loss: 2.192554473876953
Validation loss: 2.292922435268279

Epoch: 5| Step: 4
Training loss: 2.920305013656616
Validation loss: 2.2498109058667253

Epoch: 5| Step: 5
Training loss: 2.763275146484375
Validation loss: 2.1998199698745564

Epoch: 5| Step: 6
Training loss: 2.4689784049987793
Validation loss: 2.1580510036919707

Epoch: 5| Step: 7
Training loss: 1.8333642482757568
Validation loss: 2.1265596420534196

Epoch: 5| Step: 8
Training loss: 2.3657243251800537
Validation loss: 2.113061305015318

Epoch: 5| Step: 9
Training loss: 1.952741265296936
Validation loss: 2.110034623453694

Epoch: 5| Step: 10
Training loss: 3.2775635719299316
Validation loss: 2.1134871295703355

Epoch: 119| Step: 0
Training loss: 2.6909537315368652
Validation loss: 2.1122948251744753

Epoch: 5| Step: 1
Training loss: 2.355396270751953
Validation loss: 2.107759675671977

Epoch: 5| Step: 2
Training loss: 2.9695539474487305
Validation loss: 2.1061017897821244

Epoch: 5| Step: 3
Training loss: 2.4281210899353027
Validation loss: 2.1185747141479165

Epoch: 5| Step: 4
Training loss: 2.168095111846924
Validation loss: 2.131872207887711

Epoch: 5| Step: 5
Training loss: 2.6284048557281494
Validation loss: 2.1338857450792865

Epoch: 5| Step: 6
Training loss: 2.332587718963623
Validation loss: 2.128261822526173

Epoch: 5| Step: 7
Training loss: 2.2008674144744873
Validation loss: 2.13340308461138

Epoch: 5| Step: 8
Training loss: 2.658047676086426
Validation loss: 2.1150131738314064

Epoch: 5| Step: 9
Training loss: 2.271136522293091
Validation loss: 2.116269967889273

Epoch: 5| Step: 10
Training loss: 2.3017523288726807
Validation loss: 2.117743984345467

Epoch: 120| Step: 0
Training loss: 1.8573449850082397
Validation loss: 2.107364236667592

Epoch: 5| Step: 1
Training loss: 2.9504141807556152
Validation loss: 2.108649884500811

Epoch: 5| Step: 2
Training loss: 2.5381832122802734
Validation loss: 2.1261770366340556

Epoch: 5| Step: 3
Training loss: 2.8426342010498047
Validation loss: 2.123983035805405

Epoch: 5| Step: 4
Training loss: 2.1559128761291504
Validation loss: 2.1328294418191396

Epoch: 5| Step: 5
Training loss: 2.6633265018463135
Validation loss: 2.129883381628221

Epoch: 5| Step: 6
Training loss: 3.004976272583008
Validation loss: 2.1294993380064606

Epoch: 5| Step: 7
Training loss: 2.3979766368865967
Validation loss: 2.1412279439228836

Epoch: 5| Step: 8
Training loss: 2.6987252235412598
Validation loss: 2.1302575975336056

Epoch: 5| Step: 9
Training loss: 1.6638662815093994
Validation loss: 2.1331097848953737

Epoch: 5| Step: 10
Training loss: 1.7746134996414185
Validation loss: 2.1369293453872844

Epoch: 121| Step: 0
Training loss: 2.421731948852539
Validation loss: 2.1540821970150037

Epoch: 5| Step: 1
Training loss: 2.278843641281128
Validation loss: 2.181376561041801

Epoch: 5| Step: 2
Training loss: 1.5633872747421265
Validation loss: 2.2140071033149638

Epoch: 5| Step: 3
Training loss: 3.236863613128662
Validation loss: 2.2472922161061275

Epoch: 5| Step: 4
Training loss: 2.976813554763794
Validation loss: 2.284435449108001

Epoch: 5| Step: 5
Training loss: 2.4132206439971924
Validation loss: 2.2535856975022184

Epoch: 5| Step: 6
Training loss: 2.447223424911499
Validation loss: 2.1994259998362553

Epoch: 5| Step: 7
Training loss: 2.1940741539001465
Validation loss: 2.180042992356003

Epoch: 5| Step: 8
Training loss: 2.2383182048797607
Validation loss: 2.1594114008770195

Epoch: 5| Step: 9
Training loss: 2.353766918182373
Validation loss: 2.1484768544473956

Epoch: 5| Step: 10
Training loss: 2.5388219356536865
Validation loss: 2.136335811307353

Epoch: 122| Step: 0
Training loss: 2.4974303245544434
Validation loss: 2.140342071492185

Epoch: 5| Step: 1
Training loss: 2.3837108612060547
Validation loss: 2.142700013294015

Epoch: 5| Step: 2
Training loss: 2.8239779472351074
Validation loss: 2.1477979934343727

Epoch: 5| Step: 3
Training loss: 2.5182907581329346
Validation loss: 2.154153097060419

Epoch: 5| Step: 4
Training loss: 2.4082694053649902
Validation loss: 2.1567550051596855

Epoch: 5| Step: 5
Training loss: 2.4768130779266357
Validation loss: 2.1651854489439275

Epoch: 5| Step: 6
Training loss: 2.2218213081359863
Validation loss: 2.1558199467197543

Epoch: 5| Step: 7
Training loss: 2.565800428390503
Validation loss: 2.1584814081909838

Epoch: 5| Step: 8
Training loss: 2.3792848587036133
Validation loss: 2.1460620639144734

Epoch: 5| Step: 9
Training loss: 2.258319139480591
Validation loss: 2.143769843603975

Epoch: 5| Step: 10
Training loss: 2.005554437637329
Validation loss: 2.135916079244306

Epoch: 123| Step: 0
Training loss: 2.9995505809783936
Validation loss: 2.1522450190718456

Epoch: 5| Step: 1
Training loss: 2.4427096843719482
Validation loss: 2.166227768826228

Epoch: 5| Step: 2
Training loss: 2.373363971710205
Validation loss: 2.170052033598705

Epoch: 5| Step: 3
Training loss: 1.759537935256958
Validation loss: 2.2017607227448495

Epoch: 5| Step: 4
Training loss: 1.808407187461853
Validation loss: 2.21311677399502

Epoch: 5| Step: 5
Training loss: 3.3034229278564453
Validation loss: 2.2141905984570904

Epoch: 5| Step: 6
Training loss: 2.3626434803009033
Validation loss: 2.203597330277966

Epoch: 5| Step: 7
Training loss: 1.9498488903045654
Validation loss: 2.195379267456711

Epoch: 5| Step: 8
Training loss: 2.1901421546936035
Validation loss: 2.137023748890046

Epoch: 5| Step: 9
Training loss: 3.0561702251434326
Validation loss: 2.121339376254748

Epoch: 5| Step: 10
Training loss: 2.226191520690918
Validation loss: 2.1191573245550996

Epoch: 124| Step: 0
Training loss: 3.226701021194458
Validation loss: 2.113453657396378

Epoch: 5| Step: 1
Training loss: 2.80672025680542
Validation loss: 2.1101635425321517

Epoch: 5| Step: 2
Training loss: 2.7165474891662598
Validation loss: 2.1205204315083

Epoch: 5| Step: 3
Training loss: 2.5051047801971436
Validation loss: 2.113631493301802

Epoch: 5| Step: 4
Training loss: 1.9966812133789062
Validation loss: 2.11802609761556

Epoch: 5| Step: 5
Training loss: 2.3062965869903564
Validation loss: 2.1126837140770367

Epoch: 5| Step: 6
Training loss: 1.9302746057510376
Validation loss: 2.1273162608505576

Epoch: 5| Step: 7
Training loss: 2.129828929901123
Validation loss: 2.1472518828607376

Epoch: 5| Step: 8
Training loss: 2.266230344772339
Validation loss: 2.169288391708046

Epoch: 5| Step: 9
Training loss: 2.0907397270202637
Validation loss: 2.1651306536889847

Epoch: 5| Step: 10
Training loss: 2.3894553184509277
Validation loss: 2.199555520088442

Epoch: 125| Step: 0
Training loss: 2.624472141265869
Validation loss: 2.2106429274364183

Epoch: 5| Step: 1
Training loss: 1.9571082592010498
Validation loss: 2.2482962864701466

Epoch: 5| Step: 2
Training loss: 2.357487440109253
Validation loss: 2.2513196878535773

Epoch: 5| Step: 3
Training loss: 2.7211928367614746
Validation loss: 2.247995283014031

Epoch: 5| Step: 4
Training loss: 3.2246830463409424
Validation loss: 2.260310975454187

Epoch: 5| Step: 5
Training loss: 2.399334669113159
Validation loss: 2.2399916738592167

Epoch: 5| Step: 6
Training loss: 2.2235958576202393
Validation loss: 2.2319738762353056

Epoch: 5| Step: 7
Training loss: 2.033745050430298
Validation loss: 2.1872560619026102

Epoch: 5| Step: 8
Training loss: 1.8673350811004639
Validation loss: 2.153108250710272

Epoch: 5| Step: 9
Training loss: 2.495509624481201
Validation loss: 2.145601834020307

Epoch: 5| Step: 10
Training loss: 2.4083876609802246
Validation loss: 2.130953682366238

Epoch: 126| Step: 0
Training loss: 2.5723609924316406
Validation loss: 2.1182029003738077

Epoch: 5| Step: 1
Training loss: 2.259040355682373
Validation loss: 2.1271536273341023

Epoch: 5| Step: 2
Training loss: 2.9617812633514404
Validation loss: 2.122310999901064

Epoch: 5| Step: 3
Training loss: 2.7933847904205322
Validation loss: 2.1268971709794897

Epoch: 5| Step: 4
Training loss: 2.2141051292419434
Validation loss: 2.135893076978704

Epoch: 5| Step: 5
Training loss: 1.8398948907852173
Validation loss: 2.1467724679618754

Epoch: 5| Step: 6
Training loss: 2.046069622039795
Validation loss: 2.1525086587475193

Epoch: 5| Step: 7
Training loss: 2.1592628955841064
Validation loss: 2.1672433909549507

Epoch: 5| Step: 8
Training loss: 3.05352520942688
Validation loss: 2.153225438569182

Epoch: 5| Step: 9
Training loss: 2.1105799674987793
Validation loss: 2.1509376854024906

Epoch: 5| Step: 10
Training loss: 2.3574328422546387
Validation loss: 2.149529431455879

Epoch: 127| Step: 0
Training loss: 2.440739870071411
Validation loss: 2.1487174880120063

Epoch: 5| Step: 1
Training loss: 2.61067533493042
Validation loss: 2.1682850942816785

Epoch: 5| Step: 2
Training loss: 2.549551486968994
Validation loss: 2.197448674068656

Epoch: 5| Step: 3
Training loss: 2.398786783218384
Validation loss: 2.2638384513957526

Epoch: 5| Step: 4
Training loss: 2.2354342937469482
Validation loss: 2.311891243021975

Epoch: 5| Step: 5
Training loss: 2.0348780155181885
Validation loss: 2.3019527030247513

Epoch: 5| Step: 6
Training loss: 3.248392105102539
Validation loss: 2.2191000446196525

Epoch: 5| Step: 7
Training loss: 1.8144359588623047
Validation loss: 2.11581160688913

Epoch: 5| Step: 8
Training loss: 2.557312488555908
Validation loss: 2.0987183842607724

Epoch: 5| Step: 9
Training loss: 2.0926461219787598
Validation loss: 2.1071298032678585

Epoch: 5| Step: 10
Training loss: 2.667172908782959
Validation loss: 2.1256495880824264

Epoch: 128| Step: 0
Training loss: 2.030147075653076
Validation loss: 2.130695399417672

Epoch: 5| Step: 1
Training loss: 2.945683002471924
Validation loss: 2.1173496374519925

Epoch: 5| Step: 2
Training loss: 2.178445816040039
Validation loss: 2.114861131996237

Epoch: 5| Step: 3
Training loss: 2.52583909034729
Validation loss: 2.1047401633313907

Epoch: 5| Step: 4
Training loss: 2.4171314239501953
Validation loss: 2.1074865659077964

Epoch: 5| Step: 5
Training loss: 2.7066164016723633
Validation loss: 2.113157228756976

Epoch: 5| Step: 6
Training loss: 2.2963461875915527
Validation loss: 2.143336699854943

Epoch: 5| Step: 7
Training loss: 2.354897975921631
Validation loss: 2.1750980141342326

Epoch: 5| Step: 8
Training loss: 2.0860085487365723
Validation loss: 2.1997835277229227

Epoch: 5| Step: 9
Training loss: 2.5679264068603516
Validation loss: 2.2106058187382196

Epoch: 5| Step: 10
Training loss: 2.574747085571289
Validation loss: 2.18598109932356

Epoch: 129| Step: 0
Training loss: 2.1504640579223633
Validation loss: 2.2133837976763324

Epoch: 5| Step: 1
Training loss: 3.159766674041748
Validation loss: 2.2187367536688365

Epoch: 5| Step: 2
Training loss: 1.811094880104065
Validation loss: 2.2035441808803107

Epoch: 5| Step: 3
Training loss: 2.367873191833496
Validation loss: 2.1821465210248063

Epoch: 5| Step: 4
Training loss: 2.1300928592681885
Validation loss: 2.170666392131518

Epoch: 5| Step: 5
Training loss: 3.0120365619659424
Validation loss: 2.1311490510099675

Epoch: 5| Step: 6
Training loss: 2.17720365524292
Validation loss: 2.1063340684419036

Epoch: 5| Step: 7
Training loss: 2.495187282562256
Validation loss: 2.1047241751865675

Epoch: 5| Step: 8
Training loss: 2.472752809524536
Validation loss: 2.1072438301578647

Epoch: 5| Step: 9
Training loss: 2.371891498565674
Validation loss: 2.1103125836259577

Epoch: 5| Step: 10
Training loss: 2.2377638816833496
Validation loss: 2.1061112880706787

Epoch: 130| Step: 0
Training loss: 2.0805680751800537
Validation loss: 2.1055725851366596

Epoch: 5| Step: 1
Training loss: 2.328339099884033
Validation loss: 2.106050225996202

Epoch: 5| Step: 2
Training loss: 2.3223395347595215
Validation loss: 2.122049247064898

Epoch: 5| Step: 3
Training loss: 2.623116970062256
Validation loss: 2.1376561144346833

Epoch: 5| Step: 4
Training loss: 2.1843647956848145
Validation loss: 2.156834354964636

Epoch: 5| Step: 5
Training loss: 2.8163325786590576
Validation loss: 2.1619017034448604

Epoch: 5| Step: 6
Training loss: 1.9827817678451538
Validation loss: 2.150273608905013

Epoch: 5| Step: 7
Training loss: 2.3275458812713623
Validation loss: 2.1609727105786725

Epoch: 5| Step: 8
Training loss: 2.2257015705108643
Validation loss: 2.1687481416169034

Epoch: 5| Step: 9
Training loss: 2.239879846572876
Validation loss: 2.1944913838499334

Epoch: 5| Step: 10
Training loss: 2.8764047622680664
Validation loss: 2.231101641090967

Epoch: 131| Step: 0
Training loss: 2.6468300819396973
Validation loss: 2.2954959792475544

Epoch: 5| Step: 1
Training loss: 1.8569881916046143
Validation loss: 2.350821316883128

Epoch: 5| Step: 2
Training loss: 2.6343822479248047
Validation loss: 2.504633424102619

Epoch: 5| Step: 3
Training loss: 2.1693313121795654
Validation loss: 2.4805133932380268

Epoch: 5| Step: 4
Training loss: 2.675295829772949
Validation loss: 2.312407893519248

Epoch: 5| Step: 5
Training loss: 2.5679593086242676
Validation loss: 2.180598399972403

Epoch: 5| Step: 6
Training loss: 2.3303122520446777
Validation loss: 2.110966977252755

Epoch: 5| Step: 7
Training loss: 3.0315423011779785
Validation loss: 2.1038861428537676

Epoch: 5| Step: 8
Training loss: 2.7768421173095703
Validation loss: 2.1308604901836765

Epoch: 5| Step: 9
Training loss: 2.828627109527588
Validation loss: 2.133364127528283

Epoch: 5| Step: 10
Training loss: 1.6579104661941528
Validation loss: 2.124981214923243

Epoch: 132| Step: 0
Training loss: 2.1705098152160645
Validation loss: 2.1103168431148736

Epoch: 5| Step: 1
Training loss: 2.8793158531188965
Validation loss: 2.1125997292098178

Epoch: 5| Step: 2
Training loss: 2.453303813934326
Validation loss: 2.108845514635886

Epoch: 5| Step: 3
Training loss: 2.0421817302703857
Validation loss: 2.1003337880616546

Epoch: 5| Step: 4
Training loss: 2.7891197204589844
Validation loss: 2.1070246927199827

Epoch: 5| Step: 5
Training loss: 2.5769598484039307
Validation loss: 2.1469324583648355

Epoch: 5| Step: 6
Training loss: 2.2490592002868652
Validation loss: 2.1986034429201515

Epoch: 5| Step: 7
Training loss: 2.531841993331909
Validation loss: 2.23169586735387

Epoch: 5| Step: 8
Training loss: 2.6559555530548096
Validation loss: 2.2323555074712282

Epoch: 5| Step: 9
Training loss: 1.4280176162719727
Validation loss: 2.267321999355029

Epoch: 5| Step: 10
Training loss: 3.049820899963379
Validation loss: 2.1964434885209605

Epoch: 133| Step: 0
Training loss: 2.89433217048645
Validation loss: 2.1095726182383876

Epoch: 5| Step: 1
Training loss: 2.193786144256592
Validation loss: 2.082849253890335

Epoch: 5| Step: 2
Training loss: 2.170854091644287
Validation loss: 2.0670459321750108

Epoch: 5| Step: 3
Training loss: 2.401360511779785
Validation loss: 2.0789848719873736

Epoch: 5| Step: 4
Training loss: 2.7685256004333496
Validation loss: 2.080259588456923

Epoch: 5| Step: 5
Training loss: 2.7333569526672363
Validation loss: 2.0823700299827

Epoch: 5| Step: 6
Training loss: 2.4009640216827393
Validation loss: 2.0784689329003774

Epoch: 5| Step: 7
Training loss: 2.4674782752990723
Validation loss: 2.078088193811396

Epoch: 5| Step: 8
Training loss: 1.9606914520263672
Validation loss: 2.07206573793965

Epoch: 5| Step: 9
Training loss: 2.642320156097412
Validation loss: 2.0676504873460337

Epoch: 5| Step: 10
Training loss: 1.9133296012878418
Validation loss: 2.068371626638597

Epoch: 134| Step: 0
Training loss: 2.465170383453369
Validation loss: 2.0681376047031854

Epoch: 5| Step: 1
Training loss: 2.688441753387451
Validation loss: 2.0774929420922392

Epoch: 5| Step: 2
Training loss: 3.210444688796997
Validation loss: 2.111006244536369

Epoch: 5| Step: 3
Training loss: 2.450491428375244
Validation loss: 2.136106014251709

Epoch: 5| Step: 4
Training loss: 2.0690462589263916
Validation loss: 2.2142556008472236

Epoch: 5| Step: 5
Training loss: 2.201920986175537
Validation loss: 2.2269644839789278

Epoch: 5| Step: 6
Training loss: 1.782767653465271
Validation loss: 2.2827434065521404

Epoch: 5| Step: 7
Training loss: 2.4177322387695312
Validation loss: 2.264527104234183

Epoch: 5| Step: 8
Training loss: 2.504918098449707
Validation loss: 2.233544877780381

Epoch: 5| Step: 9
Training loss: 2.2648799419403076
Validation loss: 2.212248771421371

Epoch: 5| Step: 10
Training loss: 2.138023853302002
Validation loss: 2.1672710154646184

Epoch: 135| Step: 0
Training loss: 2.264000654220581
Validation loss: 2.142577612271873

Epoch: 5| Step: 1
Training loss: 2.670175075531006
Validation loss: 2.1010913207966793

Epoch: 5| Step: 2
Training loss: 2.2699151039123535
Validation loss: 2.0792436804822696

Epoch: 5| Step: 3
Training loss: 2.4204437732696533
Validation loss: 2.0723550627308507

Epoch: 5| Step: 4
Training loss: 2.282015085220337
Validation loss: 2.0708861145921933

Epoch: 5| Step: 5
Training loss: 2.583874464035034
Validation loss: 2.0806943524268364

Epoch: 5| Step: 6
Training loss: 2.3050031661987305
Validation loss: 2.089244765620078

Epoch: 5| Step: 7
Training loss: 2.451162815093994
Validation loss: 2.111320457150859

Epoch: 5| Step: 8
Training loss: 1.7407125234603882
Validation loss: 2.11885045677103

Epoch: 5| Step: 9
Training loss: 2.4374682903289795
Validation loss: 2.1573645735299714

Epoch: 5| Step: 10
Training loss: 2.6518824100494385
Validation loss: 2.179434827578965

Epoch: 136| Step: 0
Training loss: 1.9237260818481445
Validation loss: 2.2032227080355407

Epoch: 5| Step: 1
Training loss: 2.0906357765197754
Validation loss: 2.228303147900489

Epoch: 5| Step: 2
Training loss: 2.4382922649383545
Validation loss: 2.2360032989132788

Epoch: 5| Step: 3
Training loss: 2.5521645545959473
Validation loss: 2.1845986048380532

Epoch: 5| Step: 4
Training loss: 2.677133798599243
Validation loss: 2.144992025949622

Epoch: 5| Step: 5
Training loss: 2.270512819290161
Validation loss: 2.1231428295053463

Epoch: 5| Step: 6
Training loss: 2.4043593406677246
Validation loss: 2.0927580530925463

Epoch: 5| Step: 7
Training loss: 2.5182323455810547
Validation loss: 2.081307529121317

Epoch: 5| Step: 8
Training loss: 2.5923972129821777
Validation loss: 2.080732536572282

Epoch: 5| Step: 9
Training loss: 2.1695644855499268
Validation loss: 2.073248759392769

Epoch: 5| Step: 10
Training loss: 2.5243380069732666
Validation loss: 2.07781494304698

Epoch: 137| Step: 0
Training loss: 2.549220323562622
Validation loss: 2.076437647624682

Epoch: 5| Step: 1
Training loss: 2.1621041297912598
Validation loss: 2.0754992372246197

Epoch: 5| Step: 2
Training loss: 2.487762928009033
Validation loss: 2.0957274436950684

Epoch: 5| Step: 3
Training loss: 2.191868305206299
Validation loss: 2.095389658404935

Epoch: 5| Step: 4
Training loss: 2.0475969314575195
Validation loss: 2.1107922241251957

Epoch: 5| Step: 5
Training loss: 2.3580172061920166
Validation loss: 2.13508871293837

Epoch: 5| Step: 6
Training loss: 2.2669529914855957
Validation loss: 2.1722625096639

Epoch: 5| Step: 7
Training loss: 2.33231782913208
Validation loss: 2.194700643580447

Epoch: 5| Step: 8
Training loss: 2.6281585693359375
Validation loss: 2.221482135916269

Epoch: 5| Step: 9
Training loss: 2.0594494342803955
Validation loss: 2.3342694826023553

Epoch: 5| Step: 10
Training loss: 2.9075379371643066
Validation loss: 2.3856378421988538

Epoch: 138| Step: 0
Training loss: 2.2110111713409424
Validation loss: 2.3807737852937434

Epoch: 5| Step: 1
Training loss: 2.5857176780700684
Validation loss: 2.246896738647133

Epoch: 5| Step: 2
Training loss: 2.3280811309814453
Validation loss: 2.1593237064218007

Epoch: 5| Step: 3
Training loss: 2.035209894180298
Validation loss: 2.126772875426918

Epoch: 5| Step: 4
Training loss: 2.666752576828003
Validation loss: 2.0952239216014905

Epoch: 5| Step: 5
Training loss: 2.3209972381591797
Validation loss: 2.0934085589583202

Epoch: 5| Step: 6
Training loss: 1.8755054473876953
Validation loss: 2.113489274055727

Epoch: 5| Step: 7
Training loss: 2.6025807857513428
Validation loss: 2.1022799963592202

Epoch: 5| Step: 8
Training loss: 2.5327820777893066
Validation loss: 2.094000301053447

Epoch: 5| Step: 9
Training loss: 2.6827123165130615
Validation loss: 2.090235230743244

Epoch: 5| Step: 10
Training loss: 2.396300792694092
Validation loss: 2.0790348052978516

Epoch: 139| Step: 0
Training loss: 1.7290436029434204
Validation loss: 2.088172533178842

Epoch: 5| Step: 1
Training loss: 2.7988147735595703
Validation loss: 2.093613819409442

Epoch: 5| Step: 2
Training loss: 2.943291664123535
Validation loss: 2.1125970604599162

Epoch: 5| Step: 3
Training loss: 2.1131248474121094
Validation loss: 2.139716112485496

Epoch: 5| Step: 4
Training loss: 2.4638900756835938
Validation loss: 2.1766565807404055

Epoch: 5| Step: 5
Training loss: 2.592836856842041
Validation loss: 2.218390490419121

Epoch: 5| Step: 6
Training loss: 2.3584275245666504
Validation loss: 2.23226261138916

Epoch: 5| Step: 7
Training loss: 2.400756359100342
Validation loss: 2.2253704776046095

Epoch: 5| Step: 8
Training loss: 1.980085015296936
Validation loss: 2.202123370221866

Epoch: 5| Step: 9
Training loss: 1.7730541229248047
Validation loss: 2.181870114418768

Epoch: 5| Step: 10
Training loss: 2.736693859100342
Validation loss: 2.186681385963194

Epoch: 140| Step: 0
Training loss: 2.631133556365967
Validation loss: 2.2374064409604637

Epoch: 5| Step: 1
Training loss: 2.68125057220459
Validation loss: 2.2422529984545965

Epoch: 5| Step: 2
Training loss: 1.8279006481170654
Validation loss: 2.2396989740351194

Epoch: 5| Step: 3
Training loss: 2.1000030040740967
Validation loss: 2.2441031176556825

Epoch: 5| Step: 4
Training loss: 2.7887794971466064
Validation loss: 2.1885095027185257

Epoch: 5| Step: 5
Training loss: 2.4969918727874756
Validation loss: 2.1552300940277758

Epoch: 5| Step: 6
Training loss: 2.9130032062530518
Validation loss: 2.1135339890756915

Epoch: 5| Step: 7
Training loss: 1.8589082956314087
Validation loss: 2.0993851730900426

Epoch: 5| Step: 8
Training loss: 2.333895444869995
Validation loss: 2.097218621161676

Epoch: 5| Step: 9
Training loss: 1.9952080249786377
Validation loss: 2.1189591756431003

Epoch: 5| Step: 10
Training loss: 2.3561596870422363
Validation loss: 2.107563364890314

Epoch: 141| Step: 0
Training loss: 2.327780246734619
Validation loss: 2.106338357412687

Epoch: 5| Step: 1
Training loss: 2.8189103603363037
Validation loss: 2.087914805258474

Epoch: 5| Step: 2
Training loss: 1.7919127941131592
Validation loss: 2.112026329963438

Epoch: 5| Step: 3
Training loss: 1.9118127822875977
Validation loss: 2.0946498327357794

Epoch: 5| Step: 4
Training loss: 1.831557035446167
Validation loss: 2.0877203851617794

Epoch: 5| Step: 5
Training loss: 2.6634469032287598
Validation loss: 2.1244389472469205

Epoch: 5| Step: 6
Training loss: 2.638568878173828
Validation loss: 2.1364882620432044

Epoch: 5| Step: 7
Training loss: 2.7080721855163574
Validation loss: 2.1410769916349843

Epoch: 5| Step: 8
Training loss: 2.289374828338623
Validation loss: 2.165782287556638

Epoch: 5| Step: 9
Training loss: 2.70701003074646
Validation loss: 2.139814956213838

Epoch: 5| Step: 10
Training loss: 2.0006871223449707
Validation loss: 2.151408677460045

Epoch: 142| Step: 0
Training loss: 2.808947801589966
Validation loss: 2.137855663094469

Epoch: 5| Step: 1
Training loss: 2.2325406074523926
Validation loss: 2.142113877880958

Epoch: 5| Step: 2
Training loss: 1.619725227355957
Validation loss: 2.1433727664332234

Epoch: 5| Step: 3
Training loss: 2.187429904937744
Validation loss: 2.158750098238709

Epoch: 5| Step: 4
Training loss: 2.6663601398468018
Validation loss: 2.153858530905939

Epoch: 5| Step: 5
Training loss: 2.757498264312744
Validation loss: 2.1270434766687374

Epoch: 5| Step: 6
Training loss: 2.022493839263916
Validation loss: 2.1041027166510142

Epoch: 5| Step: 7
Training loss: 2.1883111000061035
Validation loss: 2.082118434290732

Epoch: 5| Step: 8
Training loss: 2.242891311645508
Validation loss: 2.0636355620558544

Epoch: 5| Step: 9
Training loss: 2.7403461933135986
Validation loss: 2.065514536314113

Epoch: 5| Step: 10
Training loss: 2.355325698852539
Validation loss: 2.0614158235570437

Epoch: 143| Step: 0
Training loss: 2.752948760986328
Validation loss: 2.0634845802860875

Epoch: 5| Step: 1
Training loss: 2.469310998916626
Validation loss: 2.059880268189215

Epoch: 5| Step: 2
Training loss: 3.3474583625793457
Validation loss: 2.0751887111253637

Epoch: 5| Step: 3
Training loss: 2.361750841140747
Validation loss: 2.1064252827757146

Epoch: 5| Step: 4
Training loss: 1.8328567743301392
Validation loss: 2.120166077408739

Epoch: 5| Step: 5
Training loss: 1.5428450107574463
Validation loss: 2.1447789053763113

Epoch: 5| Step: 6
Training loss: 2.4732279777526855
Validation loss: 2.1729357960403606

Epoch: 5| Step: 7
Training loss: 2.426001787185669
Validation loss: 2.1881361789600824

Epoch: 5| Step: 8
Training loss: 2.5995547771453857
Validation loss: 2.1565261925420454

Epoch: 5| Step: 9
Training loss: 1.6721611022949219
Validation loss: 2.125156610242782

Epoch: 5| Step: 10
Training loss: 1.802638292312622
Validation loss: 2.1023318229183072

Epoch: 144| Step: 0
Training loss: 2.270676374435425
Validation loss: 2.0821425325127056

Epoch: 5| Step: 1
Training loss: 2.86930251121521
Validation loss: 2.0726561392507246

Epoch: 5| Step: 2
Training loss: 2.524064302444458
Validation loss: 2.0666010238791026

Epoch: 5| Step: 3
Training loss: 1.9018837213516235
Validation loss: 2.053474956943143

Epoch: 5| Step: 4
Training loss: 2.114805221557617
Validation loss: 2.059881329536438

Epoch: 5| Step: 5
Training loss: 2.2914366722106934
Validation loss: 2.0835145622171383

Epoch: 5| Step: 6
Training loss: 2.5340263843536377
Validation loss: 2.1455012803436606

Epoch: 5| Step: 7
Training loss: 2.2425270080566406
Validation loss: 2.2124493019555205

Epoch: 5| Step: 8
Training loss: 2.8152198791503906
Validation loss: 2.2504952492252475

Epoch: 5| Step: 9
Training loss: 1.9500176906585693
Validation loss: 2.256665365670317

Epoch: 5| Step: 10
Training loss: 1.6155472993850708
Validation loss: 2.2490063431442424

Epoch: 145| Step: 0
Training loss: 3.2469451427459717
Validation loss: 2.1944628300205355

Epoch: 5| Step: 1
Training loss: 2.1773335933685303
Validation loss: 2.129413970055119

Epoch: 5| Step: 2
Training loss: 1.963046669960022
Validation loss: 2.083757613294868

Epoch: 5| Step: 3
Training loss: 2.578655242919922
Validation loss: 2.064579822683847

Epoch: 5| Step: 4
Training loss: 2.1944801807403564
Validation loss: 2.05397064967822

Epoch: 5| Step: 5
Training loss: 2.1547021865844727
Validation loss: 2.055646624616397

Epoch: 5| Step: 6
Training loss: 2.260249376296997
Validation loss: 2.086530420087999

Epoch: 5| Step: 7
Training loss: 2.344510555267334
Validation loss: 2.099432768360261

Epoch: 5| Step: 8
Training loss: 2.0059750080108643
Validation loss: 2.1142774628054712

Epoch: 5| Step: 9
Training loss: 1.7496999502182007
Validation loss: 2.1260491776210007

Epoch: 5| Step: 10
Training loss: 2.6848695278167725
Validation loss: 2.1085778577353365

Epoch: 146| Step: 0
Training loss: 2.4217755794525146
Validation loss: 2.1235677452497583

Epoch: 5| Step: 1
Training loss: 2.0252113342285156
Validation loss: 2.126176271387326

Epoch: 5| Step: 2
Training loss: 2.005624294281006
Validation loss: 2.123210317345076

Epoch: 5| Step: 3
Training loss: 2.1206188201904297
Validation loss: 2.122534110981931

Epoch: 5| Step: 4
Training loss: 2.8195700645446777
Validation loss: 2.124667972646734

Epoch: 5| Step: 5
Training loss: 2.764167308807373
Validation loss: 2.1078473637180943

Epoch: 5| Step: 6
Training loss: 2.3636651039123535
Validation loss: 2.1148103821662163

Epoch: 5| Step: 7
Training loss: 1.9031909704208374
Validation loss: 2.1290324862285326

Epoch: 5| Step: 8
Training loss: 2.3410401344299316
Validation loss: 2.1640262962669454

Epoch: 5| Step: 9
Training loss: 1.9495055675506592
Validation loss: 2.1551148942721787

Epoch: 5| Step: 10
Training loss: 2.289546251296997
Validation loss: 2.164547430571689

Epoch: 147| Step: 0
Training loss: 2.794842481613159
Validation loss: 2.1344502933563723

Epoch: 5| Step: 1
Training loss: 2.238450288772583
Validation loss: 2.110579864953154

Epoch: 5| Step: 2
Training loss: 1.8673789501190186
Validation loss: 2.1061300334110054

Epoch: 5| Step: 3
Training loss: 1.6517412662506104
Validation loss: 2.093879186978904

Epoch: 5| Step: 4
Training loss: 2.3699426651000977
Validation loss: 2.093156063428489

Epoch: 5| Step: 5
Training loss: 2.4329323768615723
Validation loss: 2.124205631594504

Epoch: 5| Step: 6
Training loss: 1.9619709253311157
Validation loss: 2.131654408670241

Epoch: 5| Step: 7
Training loss: 2.755312442779541
Validation loss: 2.149853206449939

Epoch: 5| Step: 8
Training loss: 2.549384355545044
Validation loss: 2.167172988255819

Epoch: 5| Step: 9
Training loss: 1.8472042083740234
Validation loss: 2.1360211756921585

Epoch: 5| Step: 10
Training loss: 2.6501872539520264
Validation loss: 2.1417458083039973

Epoch: 148| Step: 0
Training loss: 2.5762271881103516
Validation loss: 2.1307457300924484

Epoch: 5| Step: 1
Training loss: 1.6840852499008179
Validation loss: 2.107566882205266

Epoch: 5| Step: 2
Training loss: 2.419520854949951
Validation loss: 2.1343957121654222

Epoch: 5| Step: 3
Training loss: 2.2685415744781494
Validation loss: 2.132943502036474

Epoch: 5| Step: 4
Training loss: 2.505669593811035
Validation loss: 2.1527196143263128

Epoch: 5| Step: 5
Training loss: 2.2286641597747803
Validation loss: 2.1410165397069787

Epoch: 5| Step: 6
Training loss: 2.543626070022583
Validation loss: 2.145000575691141

Epoch: 5| Step: 7
Training loss: 1.905256986618042
Validation loss: 2.0750919875278266

Epoch: 5| Step: 8
Training loss: 2.7847163677215576
Validation loss: 2.0339467422936552

Epoch: 5| Step: 9
Training loss: 1.547493577003479
Validation loss: 2.035586867281186

Epoch: 5| Step: 10
Training loss: 2.3152213096618652
Validation loss: 2.0239357922666814

Epoch: 149| Step: 0
Training loss: 2.4411418437957764
Validation loss: 2.028469809921839

Epoch: 5| Step: 1
Training loss: 2.025144100189209
Validation loss: 2.0465247938709874

Epoch: 5| Step: 2
Training loss: 2.781879425048828
Validation loss: 2.086836523907159

Epoch: 5| Step: 3
Training loss: 1.8109210729599
Validation loss: 2.156152122764177

Epoch: 5| Step: 4
Training loss: 2.205111265182495
Validation loss: 2.2212069508849934

Epoch: 5| Step: 5
Training loss: 2.430755615234375
Validation loss: 2.2219388331136396

Epoch: 5| Step: 6
Training loss: 2.155162811279297
Validation loss: 2.1916271896772486

Epoch: 5| Step: 7
Training loss: 1.8446846008300781
Validation loss: 2.1137609122901835

Epoch: 5| Step: 8
Training loss: 2.263051748275757
Validation loss: 2.0398811806914625

Epoch: 5| Step: 9
Training loss: 2.3669075965881348
Validation loss: 2.0258678108133297

Epoch: 5| Step: 10
Training loss: 2.4109249114990234
Validation loss: 2.038379023152013

Epoch: 150| Step: 0
Training loss: 2.2352795600891113
Validation loss: 2.019394782281691

Epoch: 5| Step: 1
Training loss: 2.482422351837158
Validation loss: 2.0374091466267905

Epoch: 5| Step: 2
Training loss: 2.15031361579895
Validation loss: 2.04970387745929

Epoch: 5| Step: 3
Training loss: 1.6399074792861938
Validation loss: 2.06070517211832

Epoch: 5| Step: 4
Training loss: 1.498228669166565
Validation loss: 2.109111019360122

Epoch: 5| Step: 5
Training loss: 2.603926420211792
Validation loss: 2.114379914858008

Epoch: 5| Step: 6
Training loss: 2.7560276985168457
Validation loss: 2.132868081010798

Epoch: 5| Step: 7
Training loss: 2.295510768890381
Validation loss: 2.1760547238011516

Epoch: 5| Step: 8
Training loss: 2.0714340209960938
Validation loss: 2.18202845896444

Epoch: 5| Step: 9
Training loss: 2.3393402099609375
Validation loss: 2.1868977905601583

Epoch: 5| Step: 10
Training loss: 2.4859914779663086
Validation loss: 2.162163616508566

Epoch: 151| Step: 0
Training loss: 1.7202869653701782
Validation loss: 2.1718124343502905

Epoch: 5| Step: 1
Training loss: 2.03299617767334
Validation loss: 2.173684702124647

Epoch: 5| Step: 2
Training loss: 2.489253044128418
Validation loss: 2.1603374814474456

Epoch: 5| Step: 3
Training loss: 2.2909083366394043
Validation loss: 2.1245378089207474

Epoch: 5| Step: 4
Training loss: 2.4104175567626953
Validation loss: 2.096358706874232

Epoch: 5| Step: 5
Training loss: 2.2530500888824463
Validation loss: 2.087126378090151

Epoch: 5| Step: 6
Training loss: 1.5321403741836548
Validation loss: 2.0794020852734967

Epoch: 5| Step: 7
Training loss: 2.8790154457092285
Validation loss: 2.1001431467712566

Epoch: 5| Step: 8
Training loss: 1.9260514974594116
Validation loss: 2.130070191557689

Epoch: 5| Step: 9
Training loss: 1.7676398754119873
Validation loss: 2.1306412155910204

Epoch: 5| Step: 10
Training loss: 3.368567705154419
Validation loss: 2.1398220395529144

Epoch: 152| Step: 0
Training loss: 2.4141788482666016
Validation loss: 2.1410541329332577

Epoch: 5| Step: 1
Training loss: 1.8368103504180908
Validation loss: 2.0913284106921126

Epoch: 5| Step: 2
Training loss: 2.5073466300964355
Validation loss: 2.0973057054704234

Epoch: 5| Step: 3
Training loss: 2.3519017696380615
Validation loss: 2.1014036696444274

Epoch: 5| Step: 4
Training loss: 1.9239448308944702
Validation loss: 2.100235190442813

Epoch: 5| Step: 5
Training loss: 2.0232388973236084
Validation loss: 2.129712256052161

Epoch: 5| Step: 6
Training loss: 2.45686411857605
Validation loss: 2.0962948081313924

Epoch: 5| Step: 7
Training loss: 2.1151583194732666
Validation loss: 2.0565595652467463

Epoch: 5| Step: 8
Training loss: 1.637533187866211
Validation loss: 2.0371744658357356

Epoch: 5| Step: 9
Training loss: 2.186556339263916
Validation loss: 2.0187610182710873

Epoch: 5| Step: 10
Training loss: 2.6690874099731445
Validation loss: 2.0322495429746565

Epoch: 153| Step: 0
Training loss: 2.235159158706665
Validation loss: 2.0313574242335495

Epoch: 5| Step: 1
Training loss: 2.467254638671875
Validation loss: 2.0368856281362553

Epoch: 5| Step: 2
Training loss: 2.40977144241333
Validation loss: 2.061396191197057

Epoch: 5| Step: 3
Training loss: 2.3594658374786377
Validation loss: 2.097635640892931

Epoch: 5| Step: 4
Training loss: 2.0344502925872803
Validation loss: 2.1370570070000103

Epoch: 5| Step: 5
Training loss: 2.3555712699890137
Validation loss: 2.0984636481090257

Epoch: 5| Step: 6
Training loss: 1.8356664180755615
Validation loss: 2.101202654582198

Epoch: 5| Step: 7
Training loss: 1.89999258518219
Validation loss: 2.106586092261858

Epoch: 5| Step: 8
Training loss: 2.1629014015197754
Validation loss: 2.1483562402827765

Epoch: 5| Step: 9
Training loss: 1.757830023765564
Validation loss: 2.1737020900172572

Epoch: 5| Step: 10
Training loss: 2.449922561645508
Validation loss: 2.189256698854508

Epoch: 154| Step: 0
Training loss: 1.9461034536361694
Validation loss: 2.165171374556839

Epoch: 5| Step: 1
Training loss: 2.089651584625244
Validation loss: 2.1494340537696757

Epoch: 5| Step: 2
Training loss: 1.5162941217422485
Validation loss: 2.1363824490577943

Epoch: 5| Step: 3
Training loss: 2.191901683807373
Validation loss: 2.106662593862062

Epoch: 5| Step: 4
Training loss: 2.8294854164123535
Validation loss: 2.077124995570029

Epoch: 5| Step: 5
Training loss: 2.1131908893585205
Validation loss: 2.0910462358946442

Epoch: 5| Step: 6
Training loss: 2.173419237136841
Validation loss: 2.10759114450024

Epoch: 5| Step: 7
Training loss: 2.323774814605713
Validation loss: 2.1776983276490243

Epoch: 5| Step: 8
Training loss: 1.8901469707489014
Validation loss: 2.211758103421939

Epoch: 5| Step: 9
Training loss: 2.3914172649383545
Validation loss: 2.193628502148454

Epoch: 5| Step: 10
Training loss: 2.2133126258850098
Validation loss: 2.1385876747869674

Epoch: 155| Step: 0
Training loss: 1.9750429391860962
Validation loss: 2.1125125628645702

Epoch: 5| Step: 1
Training loss: 2.342827558517456
Validation loss: 2.12046379427756

Epoch: 5| Step: 2
Training loss: 1.8668460845947266
Validation loss: 2.0950292028406614

Epoch: 5| Step: 3
Training loss: 2.6717076301574707
Validation loss: 2.0872225530685915

Epoch: 5| Step: 4
Training loss: 1.9251750707626343
Validation loss: 2.059207348413365

Epoch: 5| Step: 5
Training loss: 1.9536311626434326
Validation loss: 2.0380496722395702

Epoch: 5| Step: 6
Training loss: 2.4651827812194824
Validation loss: 2.038732421013617

Epoch: 5| Step: 7
Training loss: 2.078007936477661
Validation loss: 2.0370251004413893

Epoch: 5| Step: 8
Training loss: 2.3329620361328125
Validation loss: 2.035073576434966

Epoch: 5| Step: 9
Training loss: 2.318422317504883
Validation loss: 2.0982484458595194

Epoch: 5| Step: 10
Training loss: 1.6808956861495972
Validation loss: 2.190342532691135

Epoch: 156| Step: 0
Training loss: 2.2509007453918457
Validation loss: 2.2437019450690157

Epoch: 5| Step: 1
Training loss: 2.507899045944214
Validation loss: 2.295212878975817

Epoch: 5| Step: 2
Training loss: 2.0576000213623047
Validation loss: 2.2966626408279582

Epoch: 5| Step: 3
Training loss: 1.8981711864471436
Validation loss: 2.172531371475548

Epoch: 5| Step: 4
Training loss: 2.1267921924591064
Validation loss: 2.0552985873273624

Epoch: 5| Step: 5
Training loss: 1.651288628578186
Validation loss: 2.025322902587152

Epoch: 5| Step: 6
Training loss: 2.715909481048584
Validation loss: 2.033774486152075

Epoch: 5| Step: 7
Training loss: 1.913733720779419
Validation loss: 2.0310593894732896

Epoch: 5| Step: 8
Training loss: 2.179068088531494
Validation loss: 2.0371697333551224

Epoch: 5| Step: 9
Training loss: 2.43477201461792
Validation loss: 2.0203926896536224

Epoch: 5| Step: 10
Training loss: 2.3601574897766113
Validation loss: 2.0360162937512962

Epoch: 157| Step: 0
Training loss: 2.366957664489746
Validation loss: 2.053967091345018

Epoch: 5| Step: 1
Training loss: 2.3804078102111816
Validation loss: 2.1099415286894767

Epoch: 5| Step: 2
Training loss: 1.7932296991348267
Validation loss: 2.1923869899524155

Epoch: 5| Step: 3
Training loss: 1.8255828619003296
Validation loss: 2.2442997219741985

Epoch: 5| Step: 4
Training loss: 2.4560420513153076
Validation loss: 2.2084021440116306

Epoch: 5| Step: 5
Training loss: 2.493285894393921
Validation loss: 2.239536803255799

Epoch: 5| Step: 6
Training loss: 2.2536017894744873
Validation loss: 2.2497208900349115

Epoch: 5| Step: 7
Training loss: 1.642065405845642
Validation loss: 2.194082454968524

Epoch: 5| Step: 8
Training loss: 2.763709545135498
Validation loss: 2.114066796918069

Epoch: 5| Step: 9
Training loss: 2.4612045288085938
Validation loss: 2.040826439857483

Epoch: 5| Step: 10
Training loss: 1.5560184717178345
Validation loss: 2.0349871086817917

Epoch: 158| Step: 0
Training loss: 2.325003147125244
Validation loss: 2.0311466493914203

Epoch: 5| Step: 1
Training loss: 2.2489497661590576
Validation loss: 2.0301485830737698

Epoch: 5| Step: 2
Training loss: 2.5807571411132812
Validation loss: 2.0341615138515348

Epoch: 5| Step: 3
Training loss: 2.262422561645508
Validation loss: 2.0369301560104534

Epoch: 5| Step: 4
Training loss: 1.5000540018081665
Validation loss: 2.0464678169578634

Epoch: 5| Step: 5
Training loss: 2.0767292976379395
Validation loss: 2.063590984190664

Epoch: 5| Step: 6
Training loss: 2.3468587398529053
Validation loss: 2.0918730164086945

Epoch: 5| Step: 7
Training loss: 2.4271187782287598
Validation loss: 2.0933120045610654

Epoch: 5| Step: 8
Training loss: 2.0726561546325684
Validation loss: 2.088413838417299

Epoch: 5| Step: 9
Training loss: 1.6728683710098267
Validation loss: 2.0987678702159593

Epoch: 5| Step: 10
Training loss: 2.1117541790008545
Validation loss: 2.084940923157559

Epoch: 159| Step: 0
Training loss: 2.5294668674468994
Validation loss: 2.0621771286892634

Epoch: 5| Step: 1
Training loss: 1.544967532157898
Validation loss: 2.0452869989538707

Epoch: 5| Step: 2
Training loss: 2.550447940826416
Validation loss: 2.038986570091658

Epoch: 5| Step: 3
Training loss: 1.875819444656372
Validation loss: 2.022320896066645

Epoch: 5| Step: 4
Training loss: 1.7811580896377563
Validation loss: 2.040893631596719

Epoch: 5| Step: 5
Training loss: 2.0568203926086426
Validation loss: 2.0429328974857124

Epoch: 5| Step: 6
Training loss: 3.112264633178711
Validation loss: 2.0249878668016

Epoch: 5| Step: 7
Training loss: 1.8359390497207642
Validation loss: 2.0035888623165827

Epoch: 5| Step: 8
Training loss: 1.7077436447143555
Validation loss: 2.064994663320562

Epoch: 5| Step: 9
Training loss: 2.043508291244507
Validation loss: 2.086921972613181

Epoch: 5| Step: 10
Training loss: 2.1452019214630127
Validation loss: 2.1011214307559434

Epoch: 160| Step: 0
Training loss: 2.0215539932250977
Validation loss: 2.139664824290942

Epoch: 5| Step: 1
Training loss: 1.7879638671875
Validation loss: 2.1517690535514586

Epoch: 5| Step: 2
Training loss: 2.256992816925049
Validation loss: 2.0927953117637226

Epoch: 5| Step: 3
Training loss: 1.983411192893982
Validation loss: 2.0392784969781035

Epoch: 5| Step: 4
Training loss: 2.1384499073028564
Validation loss: 2.0159600819310834

Epoch: 5| Step: 5
Training loss: 2.0673089027404785
Validation loss: 1.9844535140581028

Epoch: 5| Step: 6
Training loss: 2.389008045196533
Validation loss: 1.9879487842641852

Epoch: 5| Step: 7
Training loss: 1.8013861179351807
Validation loss: 2.016656987128719

Epoch: 5| Step: 8
Training loss: 2.452793836593628
Validation loss: 2.0619432387813443

Epoch: 5| Step: 9
Training loss: 2.300124406814575
Validation loss: 2.0771018356405277

Epoch: 5| Step: 10
Training loss: 1.9689302444458008
Validation loss: 2.0788041366043912

Epoch: 161| Step: 0
Training loss: 1.563405990600586
Validation loss: 2.068805548452562

Epoch: 5| Step: 1
Training loss: 2.579829454421997
Validation loss: 2.061041296169322

Epoch: 5| Step: 2
Training loss: 1.9162132740020752
Validation loss: 2.053269769555779

Epoch: 5| Step: 3
Training loss: 2.1650147438049316
Validation loss: 2.056815446064036

Epoch: 5| Step: 4
Training loss: 2.2156128883361816
Validation loss: 2.0522358302147157

Epoch: 5| Step: 5
Training loss: 2.161684513092041
Validation loss: 2.0331948598225913

Epoch: 5| Step: 6
Training loss: 1.3912181854248047
Validation loss: 2.0209347176295456

Epoch: 5| Step: 7
Training loss: 2.296508312225342
Validation loss: 2.0372679592460714

Epoch: 5| Step: 8
Training loss: 1.921207070350647
Validation loss: 2.0633501993712557

Epoch: 5| Step: 9
Training loss: 2.4470577239990234
Validation loss: 2.1031200808863484

Epoch: 5| Step: 10
Training loss: 2.223050594329834
Validation loss: 2.1294837626077796

Epoch: 162| Step: 0
Training loss: 1.9117705821990967
Validation loss: 2.16846703585758

Epoch: 5| Step: 1
Training loss: 1.9325456619262695
Validation loss: 2.181221628701815

Epoch: 5| Step: 2
Training loss: 1.835381269454956
Validation loss: 2.13637694492135

Epoch: 5| Step: 3
Training loss: 1.575616478919983
Validation loss: 2.0750061491484284

Epoch: 5| Step: 4
Training loss: 1.8796436786651611
Validation loss: 2.0330877906532696

Epoch: 5| Step: 5
Training loss: 1.8969051837921143
Validation loss: 2.0085302078595726

Epoch: 5| Step: 6
Training loss: 2.5748205184936523
Validation loss: 2.011086553655645

Epoch: 5| Step: 7
Training loss: 2.6512482166290283
Validation loss: 2.0345602291886524

Epoch: 5| Step: 8
Training loss: 1.8973009586334229
Validation loss: 2.0507522013879593

Epoch: 5| Step: 9
Training loss: 2.597977876663208
Validation loss: 2.04656328949877

Epoch: 5| Step: 10
Training loss: 2.5302188396453857
Validation loss: 2.0447875838125906

Epoch: 163| Step: 0
Training loss: 2.0880331993103027
Validation loss: 2.0994575523561045

Epoch: 5| Step: 1
Training loss: 2.4111087322235107
Validation loss: 2.124303769039851

Epoch: 5| Step: 2
Training loss: 2.542792320251465
Validation loss: 2.1419533132224955

Epoch: 5| Step: 3
Training loss: 1.8727658987045288
Validation loss: 2.1289149945782078

Epoch: 5| Step: 4
Training loss: 1.6503467559814453
Validation loss: 2.115087222027522

Epoch: 5| Step: 5
Training loss: 1.9236743450164795
Validation loss: 2.0879819341885146

Epoch: 5| Step: 6
Training loss: 1.6036767959594727
Validation loss: 2.066098969469788

Epoch: 5| Step: 7
Training loss: 1.6704254150390625
Validation loss: 2.068038131601067

Epoch: 5| Step: 8
Training loss: 2.2188751697540283
Validation loss: 2.0661097085604103

Epoch: 5| Step: 9
Training loss: 2.5113143920898438
Validation loss: 2.0746234245197748

Epoch: 5| Step: 10
Training loss: 2.29412841796875
Validation loss: 2.07553586652202

Epoch: 164| Step: 0
Training loss: 2.3715527057647705
Validation loss: 2.077435488341957

Epoch: 5| Step: 1
Training loss: 2.369605541229248
Validation loss: 2.088843012368807

Epoch: 5| Step: 2
Training loss: 2.4366281032562256
Validation loss: 2.1332697791437947

Epoch: 5| Step: 3
Training loss: 2.0114693641662598
Validation loss: 2.115068345941523

Epoch: 5| Step: 4
Training loss: 2.3180339336395264
Validation loss: 2.0964001788887927

Epoch: 5| Step: 5
Training loss: 1.8151687383651733
Validation loss: 2.103032683813444

Epoch: 5| Step: 6
Training loss: 1.5881491899490356
Validation loss: 2.055473473764235

Epoch: 5| Step: 7
Training loss: 1.5800765752792358
Validation loss: 2.0421933512533865

Epoch: 5| Step: 8
Training loss: 2.2383193969726562
Validation loss: 2.0275753108404015

Epoch: 5| Step: 9
Training loss: 1.7390772104263306
Validation loss: 2.0379224913094633

Epoch: 5| Step: 10
Training loss: 1.8216019868850708
Validation loss: 2.050293184095813

Epoch: 165| Step: 0
Training loss: 1.9823124408721924
Validation loss: 2.0362086949809903

Epoch: 5| Step: 1
Training loss: 2.4024271965026855
Validation loss: 2.049826119535713

Epoch: 5| Step: 2
Training loss: 1.6782324314117432
Validation loss: 2.084342570715053

Epoch: 5| Step: 3
Training loss: 2.062678813934326
Validation loss: 2.078254194669826

Epoch: 5| Step: 4
Training loss: 2.2454285621643066
Validation loss: 2.090698908734065

Epoch: 5| Step: 5
Training loss: 2.1604208946228027
Validation loss: 2.110321452540736

Epoch: 5| Step: 6
Training loss: 1.8824946880340576
Validation loss: 2.0733358039650867

Epoch: 5| Step: 7
Training loss: 2.5099573135375977
Validation loss: 2.078235628784344

Epoch: 5| Step: 8
Training loss: 2.064063787460327
Validation loss: 2.0507772430296867

Epoch: 5| Step: 9
Training loss: 1.3156170845031738
Validation loss: 2.048498103695531

Epoch: 5| Step: 10
Training loss: 1.8516058921813965
Validation loss: 2.0441468954086304

Epoch: 166| Step: 0
Training loss: 2.5974981784820557
Validation loss: 2.0338569418076546

Epoch: 5| Step: 1
Training loss: 1.943566918373108
Validation loss: 2.0639946896542787

Epoch: 5| Step: 2
Training loss: 2.5245587825775146
Validation loss: 2.056993620370024

Epoch: 5| Step: 3
Training loss: 1.9463990926742554
Validation loss: 2.072778103172138

Epoch: 5| Step: 4
Training loss: 1.593071699142456
Validation loss: 2.05957055476404

Epoch: 5| Step: 5
Training loss: 2.186210870742798
Validation loss: 2.0539786866916123

Epoch: 5| Step: 6
Training loss: 2.201413154602051
Validation loss: 2.0485840920479066

Epoch: 5| Step: 7
Training loss: 2.0750670433044434
Validation loss: 2.043302776992962

Epoch: 5| Step: 8
Training loss: 1.9729770421981812
Validation loss: 2.016882606731948

Epoch: 5| Step: 9
Training loss: 1.313668131828308
Validation loss: 2.025068429208571

Epoch: 5| Step: 10
Training loss: 1.7369569540023804
Validation loss: 2.045657960317468

Epoch: 167| Step: 0
Training loss: 1.9983590841293335
Validation loss: 2.093060208905128

Epoch: 5| Step: 1
Training loss: 2.5532851219177246
Validation loss: 2.1222368953048543

Epoch: 5| Step: 2
Training loss: 1.9700403213500977
Validation loss: 2.0969949383889475

Epoch: 5| Step: 3
Training loss: 2.3802285194396973
Validation loss: 2.048699894259053

Epoch: 5| Step: 4
Training loss: 1.540486216545105
Validation loss: 2.0458192645862536

Epoch: 5| Step: 5
Training loss: 2.210364580154419
Validation loss: 2.0401211092548985

Epoch: 5| Step: 6
Training loss: 1.9201428890228271
Validation loss: 2.039868429142942

Epoch: 5| Step: 7
Training loss: 2.4220919609069824
Validation loss: 2.054803027901598

Epoch: 5| Step: 8
Training loss: 1.76958429813385
Validation loss: 2.0907091632966073

Epoch: 5| Step: 9
Training loss: 1.8996978998184204
Validation loss: 2.0946143929676344

Epoch: 5| Step: 10
Training loss: 1.324423909187317
Validation loss: 2.069577691375568

Epoch: 168| Step: 0
Training loss: 2.8526055812835693
Validation loss: 2.058971505011282

Epoch: 5| Step: 1
Training loss: 2.2796683311462402
Validation loss: 2.038817619764677

Epoch: 5| Step: 2
Training loss: 2.3150992393493652
Validation loss: 2.0261626705046623

Epoch: 5| Step: 3
Training loss: 1.1734857559204102
Validation loss: 2.0350064359685427

Epoch: 5| Step: 4
Training loss: 1.7810245752334595
Validation loss: 2.0400630863763953

Epoch: 5| Step: 5
Training loss: 2.428123712539673
Validation loss: 2.0644517957523303

Epoch: 5| Step: 6
Training loss: 1.4898035526275635
Validation loss: 2.053680896759033

Epoch: 5| Step: 7
Training loss: 1.6696048974990845
Validation loss: 2.0557264589494273

Epoch: 5| Step: 8
Training loss: 1.7889972925186157
Validation loss: 2.0811732879248996

Epoch: 5| Step: 9
Training loss: 2.0180537700653076
Validation loss: 2.068541706249278

Epoch: 5| Step: 10
Training loss: 2.1379547119140625
Validation loss: 2.073865267538255

Epoch: 169| Step: 0
Training loss: 1.6502838134765625
Validation loss: 2.062474363593645

Epoch: 5| Step: 1
Training loss: 1.780129075050354
Validation loss: 2.041396403825411

Epoch: 5| Step: 2
Training loss: 2.286379337310791
Validation loss: 2.038905874375374

Epoch: 5| Step: 3
Training loss: 2.5361549854278564
Validation loss: 2.033829335243471

Epoch: 5| Step: 4
Training loss: 2.5192270278930664
Validation loss: 2.0284404690547655

Epoch: 5| Step: 5
Training loss: 1.9136730432510376
Validation loss: 2.0247474614010064

Epoch: 5| Step: 6
Training loss: 2.0861105918884277
Validation loss: 2.0510829738391343

Epoch: 5| Step: 7
Training loss: 1.646606206893921
Validation loss: 2.046133125981977

Epoch: 5| Step: 8
Training loss: 1.8977611064910889
Validation loss: 2.0766889049160864

Epoch: 5| Step: 9
Training loss: 1.5043318271636963
Validation loss: 2.0977697987710275

Epoch: 5| Step: 10
Training loss: 1.9732915163040161
Validation loss: 2.081890367692517

Epoch: 170| Step: 0
Training loss: 2.141080141067505
Validation loss: 2.061884582683604

Epoch: 5| Step: 1
Training loss: 1.849783182144165
Validation loss: 2.0246655671827254

Epoch: 5| Step: 2
Training loss: 2.20978045463562
Validation loss: 2.027886567577239

Epoch: 5| Step: 3
Training loss: 1.957298994064331
Validation loss: 2.0188209600346063

Epoch: 5| Step: 4
Training loss: 2.270146131515503
Validation loss: 2.003605540080737

Epoch: 5| Step: 5
Training loss: 2.2134616374969482
Validation loss: 2.0100816270356536

Epoch: 5| Step: 6
Training loss: 1.8699016571044922
Validation loss: 2.012474965023738

Epoch: 5| Step: 7
Training loss: 1.9024169445037842
Validation loss: 2.029698415469098

Epoch: 5| Step: 8
Training loss: 2.06024169921875
Validation loss: 2.072377395886247

Epoch: 5| Step: 9
Training loss: 1.6921371221542358
Validation loss: 2.1414452419486096

Epoch: 5| Step: 10
Training loss: 1.6746584177017212
Validation loss: 2.164029167544457

Epoch: 171| Step: 0
Training loss: 2.142082691192627
Validation loss: 2.1259618882210023

Epoch: 5| Step: 1
Training loss: 2.1108338832855225
Validation loss: 2.1258052433690717

Epoch: 5| Step: 2
Training loss: 1.7001771926879883
Validation loss: 2.099909564500214

Epoch: 5| Step: 3
Training loss: 2.1217620372772217
Validation loss: 2.0707479215437368

Epoch: 5| Step: 4
Training loss: 1.5315611362457275
Validation loss: 2.0452159066354074

Epoch: 5| Step: 5
Training loss: 1.6368612051010132
Validation loss: 1.9884733666655838

Epoch: 5| Step: 6
Training loss: 2.0394973754882812
Validation loss: 1.990183509806151

Epoch: 5| Step: 7
Training loss: 1.392735242843628
Validation loss: 2.0111869996593845

Epoch: 5| Step: 8
Training loss: 2.566459894180298
Validation loss: 2.0189841780611264

Epoch: 5| Step: 9
Training loss: 2.1277732849121094
Validation loss: 2.020695230012299

Epoch: 5| Step: 10
Training loss: 2.266547441482544
Validation loss: 2.0295373829462195

Epoch: 172| Step: 0
Training loss: 1.9457895755767822
Validation loss: 2.04541366587403

Epoch: 5| Step: 1
Training loss: 1.9858372211456299
Validation loss: 2.076839138102788

Epoch: 5| Step: 2
Training loss: 2.226893424987793
Validation loss: 2.080809885455716

Epoch: 5| Step: 3
Training loss: 2.3802051544189453
Validation loss: 2.094030944249963

Epoch: 5| Step: 4
Training loss: 1.762879729270935
Validation loss: 2.0541552497494604

Epoch: 5| Step: 5
Training loss: 1.7851375341415405
Validation loss: 2.05577023952238

Epoch: 5| Step: 6
Training loss: 2.227492570877075
Validation loss: 2.0439111007157194

Epoch: 5| Step: 7
Training loss: 1.6125885248184204
Validation loss: 2.0455953613404305

Epoch: 5| Step: 8
Training loss: 2.2577595710754395
Validation loss: 2.040147950572352

Epoch: 5| Step: 9
Training loss: 1.5486671924591064
Validation loss: 2.0337578814516784

Epoch: 5| Step: 10
Training loss: 1.7877997159957886
Validation loss: 2.02044334975622

Epoch: 173| Step: 0
Training loss: 1.9142528772354126
Validation loss: 2.041716762768325

Epoch: 5| Step: 1
Training loss: 1.8940207958221436
Validation loss: 2.0554963209295787

Epoch: 5| Step: 2
Training loss: 2.1209311485290527
Validation loss: 2.048137113612185

Epoch: 5| Step: 3
Training loss: 2.2907323837280273
Validation loss: 2.0528372667169057

Epoch: 5| Step: 4
Training loss: 2.4816508293151855
Validation loss: 2.094990458539737

Epoch: 5| Step: 5
Training loss: 1.7295846939086914
Validation loss: 2.086863584415887

Epoch: 5| Step: 6
Training loss: 1.835303544998169
Validation loss: 2.0819061545915503

Epoch: 5| Step: 7
Training loss: 1.5820194482803345
Validation loss: 2.0882505191269742

Epoch: 5| Step: 8
Training loss: 1.3278758525848389
Validation loss: 2.0497196592310423

Epoch: 5| Step: 9
Training loss: 2.547753095626831
Validation loss: 2.0283805708731375

Epoch: 5| Step: 10
Training loss: 1.716312050819397
Validation loss: 2.0155920482450917

Epoch: 174| Step: 0
Training loss: 1.959621787071228
Validation loss: 1.9906958931235856

Epoch: 5| Step: 1
Training loss: 2.164811611175537
Validation loss: 1.978808279960386

Epoch: 5| Step: 2
Training loss: 2.0036709308624268
Validation loss: 1.9935136559189006

Epoch: 5| Step: 3
Training loss: 2.1349244117736816
Validation loss: 2.0265397987058087

Epoch: 5| Step: 4
Training loss: 1.7730979919433594
Validation loss: 2.065900202720396

Epoch: 5| Step: 5
Training loss: 1.5215939283370972
Validation loss: 2.131227536868024

Epoch: 5| Step: 6
Training loss: 2.233403444290161
Validation loss: 2.091759979083974

Epoch: 5| Step: 7
Training loss: 1.4532699584960938
Validation loss: 2.036293637367987

Epoch: 5| Step: 8
Training loss: 2.1704654693603516
Validation loss: 1.9948125936651742

Epoch: 5| Step: 9
Training loss: 1.7326265573501587
Validation loss: 2.003804135066207

Epoch: 5| Step: 10
Training loss: 2.4241745471954346
Validation loss: 1.9958822227293445

Epoch: 175| Step: 0
Training loss: 2.0477137565612793
Validation loss: 1.9870274079743253

Epoch: 5| Step: 1
Training loss: 1.7661113739013672
Validation loss: 1.9890005665440713

Epoch: 5| Step: 2
Training loss: 2.149496078491211
Validation loss: 1.9915944568572506

Epoch: 5| Step: 3
Training loss: 1.820250153541565
Validation loss: 2.0112938419465096

Epoch: 5| Step: 4
Training loss: 1.8957380056381226
Validation loss: 2.0377377194743

Epoch: 5| Step: 5
Training loss: 1.932543158531189
Validation loss: 2.0331062398931032

Epoch: 5| Step: 6
Training loss: 2.491334915161133
Validation loss: 2.0615728798732964

Epoch: 5| Step: 7
Training loss: 2.01884388923645
Validation loss: 2.0464942609110186

Epoch: 5| Step: 8
Training loss: 1.3265167474746704
Validation loss: 2.050112683285949

Epoch: 5| Step: 9
Training loss: 1.856469750404358
Validation loss: 2.0163231921452347

Epoch: 5| Step: 10
Training loss: 2.039071559906006
Validation loss: 2.003489590460254

Epoch: 176| Step: 0
Training loss: 2.0451343059539795
Validation loss: 1.9998164382032169

Epoch: 5| Step: 1
Training loss: 1.619911551475525
Validation loss: 2.0214446078064623

Epoch: 5| Step: 2
Training loss: 2.4030518531799316
Validation loss: 2.041525040903399

Epoch: 5| Step: 3
Training loss: 1.6028461456298828
Validation loss: 2.0645972272401214

Epoch: 5| Step: 4
Training loss: 2.3473589420318604
Validation loss: 2.0448854328483663

Epoch: 5| Step: 5
Training loss: 1.5120964050292969
Validation loss: 2.035987179766419

Epoch: 5| Step: 6
Training loss: 2.1366794109344482
Validation loss: 2.0280681463979904

Epoch: 5| Step: 7
Training loss: 2.151028633117676
Validation loss: 2.0139092604319253

Epoch: 5| Step: 8
Training loss: 1.7515846490859985
Validation loss: 2.001829303720946

Epoch: 5| Step: 9
Training loss: 1.3852888345718384
Validation loss: 1.9895260116105438

Epoch: 5| Step: 10
Training loss: 2.175433397293091
Validation loss: 1.9924849246137886

Epoch: 177| Step: 0
Training loss: 1.7795099020004272
Validation loss: 1.9691210023818477

Epoch: 5| Step: 1
Training loss: 1.2612202167510986
Validation loss: 1.9769635790137834

Epoch: 5| Step: 2
Training loss: 1.611353874206543
Validation loss: 1.9937125123957151

Epoch: 5| Step: 3
Training loss: 2.2187247276306152
Validation loss: 2.0147389878508863

Epoch: 5| Step: 4
Training loss: 1.8645588159561157
Validation loss: 2.0176391588744296

Epoch: 5| Step: 5
Training loss: 1.9224803447723389
Validation loss: 2.0098343677418207

Epoch: 5| Step: 6
Training loss: 2.416269540786743
Validation loss: 1.9933233889200355

Epoch: 5| Step: 7
Training loss: 2.277884006500244
Validation loss: 1.9952785238142936

Epoch: 5| Step: 8
Training loss: 2.138348340988159
Validation loss: 2.0071844772625993

Epoch: 5| Step: 9
Training loss: 2.049936294555664
Validation loss: 2.0251112573890278

Epoch: 5| Step: 10
Training loss: 1.4587299823760986
Validation loss: 2.0319976217003277

Epoch: 178| Step: 0
Training loss: 1.9953101873397827
Validation loss: 2.046376725678803

Epoch: 5| Step: 1
Training loss: 1.8676178455352783
Validation loss: 2.012268797043831

Epoch: 5| Step: 2
Training loss: 2.3340442180633545
Validation loss: 2.0525887563664424

Epoch: 5| Step: 3
Training loss: 1.6109498739242554
Validation loss: 2.0416283863846973

Epoch: 5| Step: 4
Training loss: 2.18955659866333
Validation loss: 2.034647468597658

Epoch: 5| Step: 5
Training loss: 1.5826694965362549
Validation loss: 2.040754359255555

Epoch: 5| Step: 6
Training loss: 1.712599515914917
Validation loss: 2.0485430084249026

Epoch: 5| Step: 7
Training loss: 2.343712329864502
Validation loss: 2.0600340430454542

Epoch: 5| Step: 8
Training loss: 2.087448835372925
Validation loss: 2.077668538657568

Epoch: 5| Step: 9
Training loss: 1.5936352014541626
Validation loss: 2.0286474484269337

Epoch: 5| Step: 10
Training loss: 1.5880036354064941
Validation loss: 2.0178194584385043

Epoch: 179| Step: 0
Training loss: 1.818556547164917
Validation loss: 2.004863034012497

Epoch: 5| Step: 1
Training loss: 2.3049190044403076
Validation loss: 1.9859429444036176

Epoch: 5| Step: 2
Training loss: 1.7135432958602905
Validation loss: 1.9737804192368702

Epoch: 5| Step: 3
Training loss: 1.122776985168457
Validation loss: 1.993899683798513

Epoch: 5| Step: 4
Training loss: 2.6381094455718994
Validation loss: 1.9909493256640691

Epoch: 5| Step: 5
Training loss: 2.191263198852539
Validation loss: 2.003533378724129

Epoch: 5| Step: 6
Training loss: 1.7314417362213135
Validation loss: 2.0094222586642028

Epoch: 5| Step: 7
Training loss: 1.7918930053710938
Validation loss: 1.9836381455903411

Epoch: 5| Step: 8
Training loss: 2.0113322734832764
Validation loss: 1.9507792957367436

Epoch: 5| Step: 9
Training loss: 1.839817762374878
Validation loss: 1.9725991192684378

Epoch: 5| Step: 10
Training loss: 1.6799594163894653
Validation loss: 1.9926741123199463

Epoch: 180| Step: 0
Training loss: 1.699281096458435
Validation loss: 2.0345523947028705

Epoch: 5| Step: 1
Training loss: 2.478118419647217
Validation loss: 2.090708481368198

Epoch: 5| Step: 2
Training loss: 1.8265669345855713
Validation loss: 2.1620417339827425

Epoch: 5| Step: 3
Training loss: 2.059779167175293
Validation loss: 2.145050561556252

Epoch: 5| Step: 4
Training loss: 2.0342469215393066
Validation loss: 2.0674276134019256

Epoch: 5| Step: 5
Training loss: 1.2719300985336304
Validation loss: 2.032065991432436

Epoch: 5| Step: 6
Training loss: 1.4563556909561157
Validation loss: 2.0090948907277917

Epoch: 5| Step: 7
Training loss: 1.7921727895736694
Validation loss: 2.0082951655951877

Epoch: 5| Step: 8
Training loss: 2.1178765296936035
Validation loss: 2.0103491890814995

Epoch: 5| Step: 9
Training loss: 1.8088394403457642
Validation loss: 2.007561324745096

Epoch: 5| Step: 10
Training loss: 2.3419384956359863
Validation loss: 2.026654625451693

Epoch: 181| Step: 0
Training loss: 1.4587370157241821
Validation loss: 2.010059820708408

Epoch: 5| Step: 1
Training loss: 1.662559151649475
Validation loss: 2.005539773612894

Epoch: 5| Step: 2
Training loss: 1.8582435846328735
Validation loss: 2.028345481041939

Epoch: 5| Step: 3
Training loss: 2.3606486320495605
Validation loss: 2.0841741074797926

Epoch: 5| Step: 4
Training loss: 1.8831470012664795
Validation loss: 2.173009994209454

Epoch: 5| Step: 5
Training loss: 2.2805256843566895
Validation loss: 2.117497285207113

Epoch: 5| Step: 6
Training loss: 1.8585426807403564
Validation loss: 2.0691366977589105

Epoch: 5| Step: 7
Training loss: 1.6671355962753296
Validation loss: 2.029309775239678

Epoch: 5| Step: 8
Training loss: 1.75454843044281
Validation loss: 1.9948882441366873

Epoch: 5| Step: 9
Training loss: 1.8388859033584595
Validation loss: 1.959551549726917

Epoch: 5| Step: 10
Training loss: 2.2876062393188477
Validation loss: 1.9574896686820573

Epoch: 182| Step: 0
Training loss: 1.6687507629394531
Validation loss: 1.9532263663507277

Epoch: 5| Step: 1
Training loss: 1.9853794574737549
Validation loss: 1.9473402115606493

Epoch: 5| Step: 2
Training loss: 1.861342191696167
Validation loss: 1.9507812505127282

Epoch: 5| Step: 3
Training loss: 2.263221025466919
Validation loss: 1.9774951140085857

Epoch: 5| Step: 4
Training loss: 2.184513568878174
Validation loss: 2.0039943443831576

Epoch: 5| Step: 5
Training loss: 1.938118577003479
Validation loss: 2.033367262091688

Epoch: 5| Step: 6
Training loss: 1.1614019870758057
Validation loss: 2.0448599066785587

Epoch: 5| Step: 7
Training loss: 2.3917360305786133
Validation loss: 2.0517839718890447

Epoch: 5| Step: 8
Training loss: 1.3283789157867432
Validation loss: 2.0300731864026798

Epoch: 5| Step: 9
Training loss: 2.1474411487579346
Validation loss: 2.0213893869871735

Epoch: 5| Step: 10
Training loss: 1.9074630737304688
Validation loss: 2.002968672783144

Epoch: 183| Step: 0
Training loss: 1.7373631000518799
Validation loss: 1.995420745624009

Epoch: 5| Step: 1
Training loss: 1.6315311193466187
Validation loss: 1.9869272144891883

Epoch: 5| Step: 2
Training loss: 1.8300526142120361
Validation loss: 1.988089729380864

Epoch: 5| Step: 3
Training loss: 1.8058311939239502
Validation loss: 2.012647162201584

Epoch: 5| Step: 4
Training loss: 2.147394895553589
Validation loss: 2.0311481901394424

Epoch: 5| Step: 5
Training loss: 1.824716329574585
Validation loss: 2.0640460893672

Epoch: 5| Step: 6
Training loss: 1.7121318578720093
Validation loss: 2.0394304631858744

Epoch: 5| Step: 7
Training loss: 2.1330761909484863
Validation loss: 2.019401534911125

Epoch: 5| Step: 8
Training loss: 2.2313485145568848
Validation loss: 1.997398648210751

Epoch: 5| Step: 9
Training loss: 1.5721204280853271
Validation loss: 1.9695190280996344

Epoch: 5| Step: 10
Training loss: 2.0656793117523193
Validation loss: 1.9702276875895839

Epoch: 184| Step: 0
Training loss: 2.091140031814575
Validation loss: 1.9982103019632318

Epoch: 5| Step: 1
Training loss: 1.8296245336532593
Validation loss: 2.0085875654733307

Epoch: 5| Step: 2
Training loss: 2.7260406017303467
Validation loss: 1.990728134750038

Epoch: 5| Step: 3
Training loss: 1.8338792324066162
Validation loss: 2.0067521320876254

Epoch: 5| Step: 4
Training loss: 2.328094959259033
Validation loss: 1.9682299001242525

Epoch: 5| Step: 5
Training loss: 1.586263656616211
Validation loss: 1.98784698465819

Epoch: 5| Step: 6
Training loss: 1.2975810766220093
Validation loss: 2.0226900410908524

Epoch: 5| Step: 7
Training loss: 1.7381359338760376
Validation loss: 2.1099312292632235

Epoch: 5| Step: 8
Training loss: 1.786808729171753
Validation loss: 2.254118355371619

Epoch: 5| Step: 9
Training loss: 2.240269899368286
Validation loss: 2.3137780620205786

Epoch: 5| Step: 10
Training loss: 1.934397578239441
Validation loss: 2.20700652112243

Epoch: 185| Step: 0
Training loss: 1.93771231174469
Validation loss: 2.0995399336661063

Epoch: 5| Step: 1
Training loss: 2.1245124340057373
Validation loss: 2.0182083447774253

Epoch: 5| Step: 2
Training loss: 2.149627685546875
Validation loss: 1.956635937895826

Epoch: 5| Step: 3
Training loss: 2.379913330078125
Validation loss: 1.939572234307566

Epoch: 5| Step: 4
Training loss: 1.9603430032730103
Validation loss: 1.9568644069856214

Epoch: 5| Step: 5
Training loss: 1.8193647861480713
Validation loss: 1.9686572013362762

Epoch: 5| Step: 6
Training loss: 1.5780012607574463
Validation loss: 1.955181666599807

Epoch: 5| Step: 7
Training loss: 1.9725239276885986
Validation loss: 1.9637175452324651

Epoch: 5| Step: 8
Training loss: 2.3669981956481934
Validation loss: 1.9809205442346551

Epoch: 5| Step: 9
Training loss: 1.4666268825531006
Validation loss: 2.0134009110030306

Epoch: 5| Step: 10
Training loss: 1.1829619407653809
Validation loss: 2.0262821643583235

Epoch: 186| Step: 0
Training loss: 1.8059533834457397
Validation loss: 2.0630808312405824

Epoch: 5| Step: 1
Training loss: 1.68325936794281
Validation loss: 2.0162465354447723

Epoch: 5| Step: 2
Training loss: 2.214677095413208
Validation loss: 1.977626081435911

Epoch: 5| Step: 3
Training loss: 1.5685378313064575
Validation loss: 1.9488571920702535

Epoch: 5| Step: 4
Training loss: 2.4252560138702393
Validation loss: 1.939207624363643

Epoch: 5| Step: 5
Training loss: 1.7107408046722412
Validation loss: 1.9442671755308747

Epoch: 5| Step: 6
Training loss: 1.8051130771636963
Validation loss: 1.9517588435962636

Epoch: 5| Step: 7
Training loss: 1.9315941333770752
Validation loss: 1.9361157135296894

Epoch: 5| Step: 8
Training loss: 1.8657146692276
Validation loss: 1.9398704895409205

Epoch: 5| Step: 9
Training loss: 1.9740769863128662
Validation loss: 1.9957728591016544

Epoch: 5| Step: 10
Training loss: 1.9576023817062378
Validation loss: 2.0357095221037507

Epoch: 187| Step: 0
Training loss: 1.9653005599975586
Validation loss: 2.0502125665705693

Epoch: 5| Step: 1
Training loss: 1.8835468292236328
Validation loss: 2.05038647754218

Epoch: 5| Step: 2
Training loss: 1.8278357982635498
Validation loss: 2.0439605097616873

Epoch: 5| Step: 3
Training loss: 1.7357200384140015
Validation loss: 2.0223306430283414

Epoch: 5| Step: 4
Training loss: 1.403124451637268
Validation loss: 1.9919779223780478

Epoch: 5| Step: 5
Training loss: 1.9333069324493408
Validation loss: 1.9836919781982258

Epoch: 5| Step: 6
Training loss: 2.060236692428589
Validation loss: 1.9892830746148222

Epoch: 5| Step: 7
Training loss: 2.087834119796753
Validation loss: 1.9903748291794972

Epoch: 5| Step: 8
Training loss: 1.5800681114196777
Validation loss: 1.9997883125018048

Epoch: 5| Step: 9
Training loss: 1.756353735923767
Validation loss: 2.0146147794620965

Epoch: 5| Step: 10
Training loss: 2.2064340114593506
Validation loss: 2.020006154173164

Epoch: 188| Step: 0
Training loss: 1.7301762104034424
Validation loss: 2.033730540224301

Epoch: 5| Step: 1
Training loss: 1.5037357807159424
Validation loss: 2.0161814099998883

Epoch: 5| Step: 2
Training loss: 2.0738775730133057
Validation loss: 2.0066554033628075

Epoch: 5| Step: 3
Training loss: 1.0483330488204956
Validation loss: 1.9969033528399724

Epoch: 5| Step: 4
Training loss: 2.105302333831787
Validation loss: 1.999721598881547

Epoch: 5| Step: 5
Training loss: 1.5485109090805054
Validation loss: 1.9847488403320312

Epoch: 5| Step: 6
Training loss: 2.1939728260040283
Validation loss: 1.9758567810058594

Epoch: 5| Step: 7
Training loss: 2.3512790203094482
Validation loss: 1.9892580650186027

Epoch: 5| Step: 8
Training loss: 1.872593641281128
Validation loss: 1.9735945078634447

Epoch: 5| Step: 9
Training loss: 1.657274842262268
Validation loss: 1.9876967860806374

Epoch: 5| Step: 10
Training loss: 2.098630905151367
Validation loss: 2.020967023347014

Epoch: 189| Step: 0
Training loss: 1.3489677906036377
Validation loss: 2.0198945665872223

Epoch: 5| Step: 1
Training loss: 1.7532615661621094
Validation loss: 2.0134070227223058

Epoch: 5| Step: 2
Training loss: 1.9290058612823486
Validation loss: 2.0406625296479914

Epoch: 5| Step: 3
Training loss: 1.9526605606079102
Validation loss: 2.0236014140549528

Epoch: 5| Step: 4
Training loss: 1.622567892074585
Validation loss: 1.999518411133879

Epoch: 5| Step: 5
Training loss: 2.003366708755493
Validation loss: 1.9554354093408073

Epoch: 5| Step: 6
Training loss: 1.3260148763656616
Validation loss: 1.9692843114176104

Epoch: 5| Step: 7
Training loss: 2.2088027000427246
Validation loss: 1.9628296231710782

Epoch: 5| Step: 8
Training loss: 1.975590467453003
Validation loss: 1.9580668813438826

Epoch: 5| Step: 9
Training loss: 1.9351274967193604
Validation loss: 2.0015617673115065

Epoch: 5| Step: 10
Training loss: 2.0633792877197266
Validation loss: 2.0098467514079106

Epoch: 190| Step: 0
Training loss: 1.6360061168670654
Validation loss: 2.022096554438273

Epoch: 5| Step: 1
Training loss: 1.9297215938568115
Validation loss: 2.019713532540106

Epoch: 5| Step: 2
Training loss: 1.1647332906723022
Validation loss: 2.028828195346299

Epoch: 5| Step: 3
Training loss: 1.9477914571762085
Validation loss: 2.036963928130365

Epoch: 5| Step: 4
Training loss: 1.8276506662368774
Validation loss: 2.0077573612172115

Epoch: 5| Step: 5
Training loss: 1.7704969644546509
Validation loss: 1.9943550017572218

Epoch: 5| Step: 6
Training loss: 1.968644380569458
Validation loss: 1.9645714708553847

Epoch: 5| Step: 7
Training loss: 1.7714707851409912
Validation loss: 1.929651791049588

Epoch: 5| Step: 8
Training loss: 2.1104679107666016
Validation loss: 1.9490035669777983

Epoch: 5| Step: 9
Training loss: 2.0466184616088867
Validation loss: 1.9582801275355841

Epoch: 5| Step: 10
Training loss: 1.8323180675506592
Validation loss: 1.9491205215454102

Epoch: 191| Step: 0
Training loss: 1.3551915884017944
Validation loss: 1.9848643208062777

Epoch: 5| Step: 1
Training loss: 1.689134955406189
Validation loss: 2.002979019636749

Epoch: 5| Step: 2
Training loss: 1.7264630794525146
Validation loss: 2.0309740497219946

Epoch: 5| Step: 3
Training loss: 1.4834191799163818
Validation loss: 2.0431642083711523

Epoch: 5| Step: 4
Training loss: 1.7584861516952515
Validation loss: 2.0360185177095476

Epoch: 5| Step: 5
Training loss: 1.873782753944397
Validation loss: 2.0011137993104997

Epoch: 5| Step: 6
Training loss: 2.4934298992156982
Validation loss: 1.969105041155251

Epoch: 5| Step: 7
Training loss: 1.8162368535995483
Validation loss: 1.965982473024758

Epoch: 5| Step: 8
Training loss: 1.776320219039917
Validation loss: 1.9623821909709642

Epoch: 5| Step: 9
Training loss: 1.3826966285705566
Validation loss: 1.9431689811009232

Epoch: 5| Step: 10
Training loss: 2.5913820266723633
Validation loss: 1.9607672255526307

Epoch: 192| Step: 0
Training loss: 1.9578964710235596
Validation loss: 1.9719452088879001

Epoch: 5| Step: 1
Training loss: 1.577517032623291
Validation loss: 2.0030498991730394

Epoch: 5| Step: 2
Training loss: 1.5694177150726318
Validation loss: 2.00435205428831

Epoch: 5| Step: 3
Training loss: 1.9638572931289673
Validation loss: 2.0138985867141397

Epoch: 5| Step: 4
Training loss: 2.0746965408325195
Validation loss: 2.0124557761735815

Epoch: 5| Step: 5
Training loss: 2.017063617706299
Validation loss: 2.0502309953012774

Epoch: 5| Step: 6
Training loss: 1.66672682762146
Validation loss: 2.028892283798546

Epoch: 5| Step: 7
Training loss: 1.582024335861206
Validation loss: 1.9956634365102297

Epoch: 5| Step: 8
Training loss: 1.4652841091156006
Validation loss: 1.9943433346286896

Epoch: 5| Step: 9
Training loss: 1.8580220937728882
Validation loss: 1.9683891034895373

Epoch: 5| Step: 10
Training loss: 2.0061194896698
Validation loss: 1.9339981297011017

Epoch: 193| Step: 0
Training loss: 1.9526774883270264
Validation loss: 1.9550283672989055

Epoch: 5| Step: 1
Training loss: 1.5306068658828735
Validation loss: 1.9639503135476062

Epoch: 5| Step: 2
Training loss: 2.2354393005371094
Validation loss: 1.9279606778134581

Epoch: 5| Step: 3
Training loss: 1.9929622411727905
Validation loss: 1.926278139955254

Epoch: 5| Step: 4
Training loss: 1.9663394689559937
Validation loss: 1.9405786016935944

Epoch: 5| Step: 5
Training loss: 2.013347625732422
Validation loss: 1.9407894252448954

Epoch: 5| Step: 6
Training loss: 1.0445001125335693
Validation loss: 1.931581510010586

Epoch: 5| Step: 7
Training loss: 1.4480948448181152
Validation loss: 1.9541135167562833

Epoch: 5| Step: 8
Training loss: 1.9290825128555298
Validation loss: 1.9637329398944814

Epoch: 5| Step: 9
Training loss: 1.589758276939392
Validation loss: 1.9795203234559746

Epoch: 5| Step: 10
Training loss: 1.82308828830719
Validation loss: 2.033180970017628

Epoch: 194| Step: 0
Training loss: 2.0038130283355713
Validation loss: 2.031670311445831

Epoch: 5| Step: 1
Training loss: 1.7485311031341553
Validation loss: 2.0252412801147788

Epoch: 5| Step: 2
Training loss: 1.798842191696167
Validation loss: 2.01227903878817

Epoch: 5| Step: 3
Training loss: 1.497705340385437
Validation loss: 2.0061691063706593

Epoch: 5| Step: 4
Training loss: 2.03214168548584
Validation loss: 2.0031608150851343

Epoch: 5| Step: 5
Training loss: 1.725783348083496
Validation loss: 1.9959834493616575

Epoch: 5| Step: 6
Training loss: 1.831825613975525
Validation loss: 1.9815844207681634

Epoch: 5| Step: 7
Training loss: 1.6462417840957642
Validation loss: 1.988018822926347

Epoch: 5| Step: 8
Training loss: 1.815749168395996
Validation loss: 1.9991866760356451

Epoch: 5| Step: 9
Training loss: 1.5133979320526123
Validation loss: 1.9940725590593071

Epoch: 5| Step: 10
Training loss: 1.8995565176010132
Validation loss: 1.9937787055969238

Epoch: 195| Step: 0
Training loss: 1.8214572668075562
Validation loss: 2.00314357332004

Epoch: 5| Step: 1
Training loss: 1.2468767166137695
Validation loss: 1.9715346097946167

Epoch: 5| Step: 2
Training loss: 1.2802692651748657
Validation loss: 1.9724826146197576

Epoch: 5| Step: 3
Training loss: 2.4389491081237793
Validation loss: 1.9714972216595885

Epoch: 5| Step: 4
Training loss: 1.4118248224258423
Validation loss: 1.9456630317113732

Epoch: 5| Step: 5
Training loss: 2.2578678131103516
Validation loss: 1.9506558974583943

Epoch: 5| Step: 6
Training loss: 2.462289571762085
Validation loss: 1.9264106750488281

Epoch: 5| Step: 7
Training loss: 1.4349067211151123
Validation loss: 1.9302557065922727

Epoch: 5| Step: 8
Training loss: 1.9451239109039307
Validation loss: 1.9355161343851397

Epoch: 5| Step: 9
Training loss: 1.3477319478988647
Validation loss: 1.9527680745688818

Epoch: 5| Step: 10
Training loss: 1.6478828191757202
Validation loss: 1.9897169297741306

Epoch: 196| Step: 0
Training loss: 1.53497314453125
Validation loss: 2.0413402562500327

Epoch: 5| Step: 1
Training loss: 2.044909954071045
Validation loss: 2.0018974734890844

Epoch: 5| Step: 2
Training loss: 1.8799406290054321
Validation loss: 1.9784836769104004

Epoch: 5| Step: 3
Training loss: 2.1246840953826904
Validation loss: 1.98622332080718

Epoch: 5| Step: 4
Training loss: 1.0710939168930054
Validation loss: 1.9959531035474551

Epoch: 5| Step: 5
Training loss: 1.6226593255996704
Validation loss: 2.0070112546284995

Epoch: 5| Step: 6
Training loss: 1.8306245803833008
Validation loss: 2.0114238544176986

Epoch: 5| Step: 7
Training loss: 1.8365414142608643
Validation loss: 1.9987046231505692

Epoch: 5| Step: 8
Training loss: 1.594298005104065
Validation loss: 1.9869545377710813

Epoch: 5| Step: 9
Training loss: 1.611925721168518
Validation loss: 1.9683212798128846

Epoch: 5| Step: 10
Training loss: 2.336745023727417
Validation loss: 1.967624682252125

Epoch: 197| Step: 0
Training loss: 1.4108041524887085
Validation loss: 1.9471972732133762

Epoch: 5| Step: 1
Training loss: 1.8998098373413086
Validation loss: 1.9819130218157204

Epoch: 5| Step: 2
Training loss: 2.019469976425171
Validation loss: 1.9739575668047833

Epoch: 5| Step: 3
Training loss: 2.3481204509735107
Validation loss: 1.9712303787149408

Epoch: 5| Step: 4
Training loss: 2.084639072418213
Validation loss: 1.9914055947334535

Epoch: 5| Step: 5
Training loss: 1.4546434879302979
Validation loss: 2.071240032872846

Epoch: 5| Step: 6
Training loss: 1.8076549768447876
Validation loss: 2.0555822041726883

Epoch: 5| Step: 7
Training loss: 1.5716588497161865
Validation loss: 2.022631323465737

Epoch: 5| Step: 8
Training loss: 1.567878246307373
Validation loss: 2.0067774890571513

Epoch: 5| Step: 9
Training loss: 1.4148279428482056
Validation loss: 1.963610843945575

Epoch: 5| Step: 10
Training loss: 1.3666609525680542
Validation loss: 1.9434647226846347

Epoch: 198| Step: 0
Training loss: 1.718862533569336
Validation loss: 1.9375355294955674

Epoch: 5| Step: 1
Training loss: 1.9708690643310547
Validation loss: 1.951925467419368

Epoch: 5| Step: 2
Training loss: 1.5581638813018799
Validation loss: 1.9640674283427577

Epoch: 5| Step: 3
Training loss: 1.4374688863754272
Validation loss: 2.023803634028281

Epoch: 5| Step: 4
Training loss: 1.4605882167816162
Validation loss: 2.089108669629661

Epoch: 5| Step: 5
Training loss: 1.9908883571624756
Validation loss: 2.1537829278617777

Epoch: 5| Step: 6
Training loss: 2.096961736679077
Validation loss: 2.101528598416236

Epoch: 5| Step: 7
Training loss: 1.7508646249771118
Validation loss: 2.086167161182691

Epoch: 5| Step: 8
Training loss: 2.1820638179779053
Validation loss: 2.0390034465379614

Epoch: 5| Step: 9
Training loss: 1.411180853843689
Validation loss: 2.0121340572193103

Epoch: 5| Step: 10
Training loss: 1.9721760749816895
Validation loss: 2.0106702081618772

Epoch: 199| Step: 0
Training loss: 2.0935099124908447
Validation loss: 1.9718811717084659

Epoch: 5| Step: 1
Training loss: 2.2371139526367188
Validation loss: 1.945455652411266

Epoch: 5| Step: 2
Training loss: 1.560411810874939
Validation loss: 1.9341926138888124

Epoch: 5| Step: 3
Training loss: 1.6802196502685547
Validation loss: 1.9262114186440744

Epoch: 5| Step: 4
Training loss: 1.8954498767852783
Validation loss: 1.9537326020579184

Epoch: 5| Step: 5
Training loss: 1.0231282711029053
Validation loss: 1.9828705505658222

Epoch: 5| Step: 6
Training loss: 1.6069505214691162
Validation loss: 1.9914202305578417

Epoch: 5| Step: 7
Training loss: 1.4630738496780396
Validation loss: 1.9724282628746443

Epoch: 5| Step: 8
Training loss: 1.6398671865463257
Validation loss: 1.9592114981784616

Epoch: 5| Step: 9
Training loss: 1.9976478815078735
Validation loss: 1.9488387851304905

Epoch: 5| Step: 10
Training loss: 1.8598188161849976
Validation loss: 1.9786780470161027

Epoch: 200| Step: 0
Training loss: 1.6687896251678467
Validation loss: 2.01438239056577

Epoch: 5| Step: 1
Training loss: 2.1598477363586426
Validation loss: 2.010848476040748

Epoch: 5| Step: 2
Training loss: 1.4539110660552979
Validation loss: 2.0160918774143344

Epoch: 5| Step: 3
Training loss: 1.8105905055999756
Validation loss: 2.0105635414841356

Epoch: 5| Step: 4
Training loss: 1.688192367553711
Validation loss: 1.9963553977268997

Epoch: 5| Step: 5
Training loss: 2.234830617904663
Validation loss: 1.98907317397415

Epoch: 5| Step: 6
Training loss: 1.7020708322525024
Validation loss: 2.0063807836142917

Epoch: 5| Step: 7
Training loss: 1.7921960353851318
Validation loss: 2.0242144676946823

Epoch: 5| Step: 8
Training loss: 0.8377692103385925
Validation loss: 2.0119604577300367

Epoch: 5| Step: 9
Training loss: 1.3802255392074585
Validation loss: 2.0445193270201325

Epoch: 5| Step: 10
Training loss: 1.8794001340866089
Validation loss: 2.0875262727019606

Epoch: 201| Step: 0
Training loss: 1.7190755605697632
Validation loss: 2.0883272437639135

Epoch: 5| Step: 1
Training loss: 1.8723323345184326
Validation loss: 2.109372446613927

Epoch: 5| Step: 2
Training loss: 1.3167016506195068
Validation loss: 2.1115674062441756

Epoch: 5| Step: 3
Training loss: 1.2118700742721558
Validation loss: 2.1340313034672893

Epoch: 5| Step: 4
Training loss: 1.8299095630645752
Validation loss: 2.0480270257560154

Epoch: 5| Step: 5
Training loss: 1.5993096828460693
Validation loss: 1.9735479867586525

Epoch: 5| Step: 6
Training loss: 2.024773359298706
Validation loss: 1.9812537623989968

Epoch: 5| Step: 7
Training loss: 1.5384347438812256
Validation loss: 1.9755353196974723

Epoch: 5| Step: 8
Training loss: 2.7044835090637207
Validation loss: 1.9798118401599187

Epoch: 5| Step: 9
Training loss: 1.6591899394989014
Validation loss: 1.9457529770430697

Epoch: 5| Step: 10
Training loss: 2.113839626312256
Validation loss: 1.9227944497139222

Epoch: 202| Step: 0
Training loss: 1.7523136138916016
Validation loss: 1.9586814757316344

Epoch: 5| Step: 1
Training loss: 2.2698636054992676
Validation loss: 2.0287231142802904

Epoch: 5| Step: 2
Training loss: 1.6800295114517212
Validation loss: 2.0778632804911625

Epoch: 5| Step: 3
Training loss: 1.6501432657241821
Validation loss: 2.110927916342212

Epoch: 5| Step: 4
Training loss: 2.129960536956787
Validation loss: 2.044597233495405

Epoch: 5| Step: 5
Training loss: 1.3082993030548096
Validation loss: 2.028791981358682

Epoch: 5| Step: 6
Training loss: 1.8498165607452393
Validation loss: 1.9704724332337737

Epoch: 5| Step: 7
Training loss: 1.5370125770568848
Validation loss: 1.9353103124967186

Epoch: 5| Step: 8
Training loss: 1.8714698553085327
Validation loss: 1.9364478459922216

Epoch: 5| Step: 9
Training loss: 1.403563141822815
Validation loss: 1.944589957114189

Epoch: 5| Step: 10
Training loss: 1.4740409851074219
Validation loss: 1.9592153397939538

Epoch: 203| Step: 0
Training loss: 1.822954535484314
Validation loss: 1.9372766197368663

Epoch: 5| Step: 1
Training loss: 1.4331200122833252
Validation loss: 1.9867645950727566

Epoch: 5| Step: 2
Training loss: 1.6226584911346436
Validation loss: 1.9770535551091677

Epoch: 5| Step: 3
Training loss: 1.707479476928711
Validation loss: 2.0041048680582354

Epoch: 5| Step: 4
Training loss: 1.6284456253051758
Validation loss: 2.008143017368932

Epoch: 5| Step: 5
Training loss: 1.9427871704101562
Validation loss: 2.073886484228155

Epoch: 5| Step: 6
Training loss: 1.3081080913543701
Validation loss: 2.0647400861145346

Epoch: 5| Step: 7
Training loss: 1.3901363611221313
Validation loss: 2.0606947970646683

Epoch: 5| Step: 8
Training loss: 2.261798143386841
Validation loss: 2.03879810917762

Epoch: 5| Step: 9
Training loss: 1.7057340145111084
Validation loss: 2.000042676925659

Epoch: 5| Step: 10
Training loss: 1.7207636833190918
Validation loss: 1.9767188282423123

Epoch: 204| Step: 0
Training loss: 1.326612949371338
Validation loss: 1.937186211668035

Epoch: 5| Step: 1
Training loss: 1.5953651666641235
Validation loss: 1.943740047434325

Epoch: 5| Step: 2
Training loss: 1.5417959690093994
Validation loss: 1.9281310022518199

Epoch: 5| Step: 3
Training loss: 2.408590316772461
Validation loss: 1.9256279532627394

Epoch: 5| Step: 4
Training loss: 1.4256995916366577
Validation loss: 1.9362094261312996

Epoch: 5| Step: 5
Training loss: 1.6891098022460938
Validation loss: 1.9593262800606348

Epoch: 5| Step: 6
Training loss: 1.5803581476211548
Validation loss: 1.9846681446157477

Epoch: 5| Step: 7
Training loss: 1.5531657934188843
Validation loss: 2.019652751184279

Epoch: 5| Step: 8
Training loss: 2.042997360229492
Validation loss: 2.0522267972269366

Epoch: 5| Step: 9
Training loss: 1.5643622875213623
Validation loss: 2.0922236109292633

Epoch: 5| Step: 10
Training loss: 1.7136619091033936
Validation loss: 2.14007705385967

Epoch: 205| Step: 0
Training loss: 1.8681137561798096
Validation loss: 2.1793034602237005

Epoch: 5| Step: 1
Training loss: 2.0718555450439453
Validation loss: 2.190719304546233

Epoch: 5| Step: 2
Training loss: 1.493971586227417
Validation loss: 2.128697864470943

Epoch: 5| Step: 3
Training loss: 1.9534976482391357
Validation loss: 2.081514511057126

Epoch: 5| Step: 4
Training loss: 1.5691183805465698
Validation loss: 2.02131389546138

Epoch: 5| Step: 5
Training loss: 1.1639254093170166
Validation loss: 1.9512862697724374

Epoch: 5| Step: 6
Training loss: 1.5413200855255127
Validation loss: 1.9388213824200373

Epoch: 5| Step: 7
Training loss: 1.588680386543274
Validation loss: 1.8969670572588522

Epoch: 5| Step: 8
Training loss: 2.075657844543457
Validation loss: 1.9232121962372974

Epoch: 5| Step: 9
Training loss: 1.4297174215316772
Validation loss: 1.952931288749941

Epoch: 5| Step: 10
Training loss: 1.8570469617843628
Validation loss: 1.9780036569923483

Epoch: 206| Step: 0
Training loss: 1.5862537622451782
Validation loss: 2.0917578589531685

Epoch: 5| Step: 1
Training loss: 1.7909510135650635
Validation loss: 2.1204197740042083

Epoch: 5| Step: 2
Training loss: 1.720947504043579
Validation loss: 2.113840969659949

Epoch: 5| Step: 3
Training loss: 1.692413330078125
Validation loss: 2.0806051146599556

Epoch: 5| Step: 4
Training loss: 1.804161787033081
Validation loss: 2.032229314568222

Epoch: 5| Step: 5
Training loss: 1.4806687831878662
Validation loss: 1.989831837274695

Epoch: 5| Step: 6
Training loss: 1.6673345565795898
Validation loss: 1.970819914212791

Epoch: 5| Step: 7
Training loss: 1.5748411417007446
Validation loss: 2.0037886199130805

Epoch: 5| Step: 8
Training loss: 1.7947213649749756
Validation loss: 2.0422463622144473

Epoch: 5| Step: 9
Training loss: 1.442442774772644
Validation loss: 2.055210218634657

Epoch: 5| Step: 10
Training loss: 2.2760753631591797
Validation loss: 2.0488816948347193

Epoch: 207| Step: 0
Training loss: 1.3245195150375366
Validation loss: 2.0362418697726343

Epoch: 5| Step: 1
Training loss: 1.2865276336669922
Validation loss: 1.9882829740483274

Epoch: 5| Step: 2
Training loss: 1.8811111450195312
Validation loss: 2.0082173706382833

Epoch: 5| Step: 3
Training loss: 1.411014199256897
Validation loss: 2.0425558423483245

Epoch: 5| Step: 4
Training loss: 0.8557817339897156
Validation loss: 2.0348340567722114

Epoch: 5| Step: 5
Training loss: 2.1370623111724854
Validation loss: 2.0369164969331477

Epoch: 5| Step: 6
Training loss: 2.378072500228882
Validation loss: 2.0161211605994933

Epoch: 5| Step: 7
Training loss: 1.1121981143951416
Validation loss: 1.9686659587326871

Epoch: 5| Step: 8
Training loss: 1.4144632816314697
Validation loss: 1.985712682047198

Epoch: 5| Step: 9
Training loss: 2.431643009185791
Validation loss: 1.9876644098630516

Epoch: 5| Step: 10
Training loss: 1.8307008743286133
Validation loss: 1.9775540726159209

Epoch: 208| Step: 0
Training loss: 1.6116104125976562
Validation loss: 1.9303549002575617

Epoch: 5| Step: 1
Training loss: 1.519439458847046
Validation loss: 1.9254975972637054

Epoch: 5| Step: 2
Training loss: 1.3637365102767944
Validation loss: 1.9429820352985012

Epoch: 5| Step: 3
Training loss: 1.7808339595794678
Validation loss: 1.9588465190702868

Epoch: 5| Step: 4
Training loss: 1.1118028163909912
Validation loss: 1.9718840173495713

Epoch: 5| Step: 5
Training loss: 0.9911178350448608
Validation loss: 1.9991479945439163

Epoch: 5| Step: 6
Training loss: 2.098193407058716
Validation loss: 2.0351295009736092

Epoch: 5| Step: 7
Training loss: 1.3912367820739746
Validation loss: 2.0592284484576155

Epoch: 5| Step: 8
Training loss: 1.7213729619979858
Validation loss: 2.068145672480265

Epoch: 5| Step: 9
Training loss: 2.1870760917663574
Validation loss: 2.0955032276850876

Epoch: 5| Step: 10
Training loss: 2.0010008811950684
Validation loss: 2.069734199072725

Epoch: 209| Step: 0
Training loss: 1.488818883895874
Validation loss: 1.9914982370150986

Epoch: 5| Step: 1
Training loss: 2.0411057472229004
Validation loss: 1.9725043889014953

Epoch: 5| Step: 2
Training loss: 1.5596082210540771
Validation loss: 1.9704007794780116

Epoch: 5| Step: 3
Training loss: 1.9407787322998047
Validation loss: 1.9577227753977622

Epoch: 5| Step: 4
Training loss: 2.1457576751708984
Validation loss: 1.9462171562256352

Epoch: 5| Step: 5
Training loss: 2.0453879833221436
Validation loss: 1.9608467368669407

Epoch: 5| Step: 6
Training loss: 1.2503811120986938
Validation loss: 2.070479573742036

Epoch: 5| Step: 7
Training loss: 1.5996878147125244
Validation loss: 2.192796084188646

Epoch: 5| Step: 8
Training loss: 2.13812255859375
Validation loss: 2.213591011621619

Epoch: 5| Step: 9
Training loss: 1.2327232360839844
Validation loss: 2.138035064102501

Epoch: 5| Step: 10
Training loss: 1.0870529413223267
Validation loss: 2.031651771196755

Epoch: 210| Step: 0
Training loss: 1.2892916202545166
Validation loss: 1.9870650101733465

Epoch: 5| Step: 1
Training loss: 1.4828405380249023
Validation loss: 1.9614613722729426

Epoch: 5| Step: 2
Training loss: 1.4369994401931763
Validation loss: 1.9700419313164168

Epoch: 5| Step: 3
Training loss: 1.4879522323608398
Validation loss: 1.9765244658275316

Epoch: 5| Step: 4
Training loss: 1.6184310913085938
Validation loss: 1.9739722564656248

Epoch: 5| Step: 5
Training loss: 1.8786767721176147
Validation loss: 1.9680103999312206

Epoch: 5| Step: 6
Training loss: 1.7362182140350342
Validation loss: 1.9465158831688665

Epoch: 5| Step: 7
Training loss: 1.4735690355300903
Validation loss: 1.9588125392954836

Epoch: 5| Step: 8
Training loss: 1.0848122835159302
Validation loss: 1.9454167466009817

Epoch: 5| Step: 9
Training loss: 1.827796220779419
Validation loss: 1.9646992529592207

Epoch: 5| Step: 10
Training loss: 2.2619287967681885
Validation loss: 2.0235071387342227

Epoch: 211| Step: 0
Training loss: 1.5472805500030518
Validation loss: 2.092289618266526

Epoch: 5| Step: 1
Training loss: 2.2353310585021973
Validation loss: 2.151612643272646

Epoch: 5| Step: 2
Training loss: 1.6100295782089233
Validation loss: 2.1523582371332313

Epoch: 5| Step: 3
Training loss: 1.5488932132720947
Validation loss: 2.0922793854949293

Epoch: 5| Step: 4
Training loss: 1.4910328388214111
Validation loss: 2.039317674534295

Epoch: 5| Step: 5
Training loss: 1.5968917608261108
Validation loss: 1.9954252140496367

Epoch: 5| Step: 6
Training loss: 1.5224586725234985
Validation loss: 1.9537690044731222

Epoch: 5| Step: 7
Training loss: 1.3292906284332275
Validation loss: 1.9090266125176543

Epoch: 5| Step: 8
Training loss: 1.4766199588775635
Validation loss: 1.8858636181841615

Epoch: 5| Step: 9
Training loss: 1.379718542098999
Validation loss: 1.8909001068402362

Epoch: 5| Step: 10
Training loss: 2.032413959503174
Validation loss: 1.8855410698921449

Epoch: 212| Step: 0
Training loss: 1.6133610010147095
Validation loss: 1.8727471584914832

Epoch: 5| Step: 1
Training loss: 1.571732759475708
Validation loss: 1.8838767108096872

Epoch: 5| Step: 2
Training loss: 0.7094604969024658
Validation loss: 1.915808101495107

Epoch: 5| Step: 3
Training loss: 1.6428375244140625
Validation loss: 1.9801605952683317

Epoch: 5| Step: 4
Training loss: 2.313192367553711
Validation loss: 2.1244152258801203

Epoch: 5| Step: 5
Training loss: 1.8498197793960571
Validation loss: 2.1771714969347884

Epoch: 5| Step: 6
Training loss: 2.0315613746643066
Validation loss: 2.149229327837626

Epoch: 5| Step: 7
Training loss: 1.190859317779541
Validation loss: 1.9981240713468162

Epoch: 5| Step: 8
Training loss: 1.0829616785049438
Validation loss: 1.8767930512787194

Epoch: 5| Step: 9
Training loss: 1.484992265701294
Validation loss: 1.8781739511797506

Epoch: 5| Step: 10
Training loss: 2.6215693950653076
Validation loss: 1.9191676801250828

Epoch: 213| Step: 0
Training loss: 1.5759378671646118
Validation loss: 1.9449249185541624

Epoch: 5| Step: 1
Training loss: 1.9991099834442139
Validation loss: 1.9325568163266746

Epoch: 5| Step: 2
Training loss: 1.9249961376190186
Validation loss: 1.9124455580147364

Epoch: 5| Step: 3
Training loss: 1.7547279596328735
Validation loss: 1.8752377827962239

Epoch: 5| Step: 4
Training loss: 1.8678096532821655
Validation loss: 1.8945085451167116

Epoch: 5| Step: 5
Training loss: 1.741593599319458
Validation loss: 1.9667293333238172

Epoch: 5| Step: 6
Training loss: 1.6920764446258545
Validation loss: 2.0328727024857716

Epoch: 5| Step: 7
Training loss: 1.529498815536499
Validation loss: 2.1442041666276994

Epoch: 5| Step: 8
Training loss: 1.647070288658142
Validation loss: 2.1831777134249286

Epoch: 5| Step: 9
Training loss: 1.0160036087036133
Validation loss: 2.155714991272137

Epoch: 5| Step: 10
Training loss: 1.3460761308670044
Validation loss: 2.1482314025202105

Epoch: 214| Step: 0
Training loss: 1.33223295211792
Validation loss: 2.098044095500823

Epoch: 5| Step: 1
Training loss: 1.5125548839569092
Validation loss: 2.057986943952499

Epoch: 5| Step: 2
Training loss: 1.5071616172790527
Validation loss: 2.00934128351109

Epoch: 5| Step: 3
Training loss: 1.1196677684783936
Validation loss: 1.9649479748100362

Epoch: 5| Step: 4
Training loss: 1.7908779382705688
Validation loss: 1.9830268916263376

Epoch: 5| Step: 5
Training loss: 2.2816860675811768
Validation loss: 1.9514443207812566

Epoch: 5| Step: 6
Training loss: 1.3623305559158325
Validation loss: 1.931581658701743

Epoch: 5| Step: 7
Training loss: 1.6286388635635376
Validation loss: 1.9550930351339362

Epoch: 5| Step: 8
Training loss: 1.9962265491485596
Validation loss: 1.9430966877168225

Epoch: 5| Step: 9
Training loss: 1.8426662683486938
Validation loss: 1.9608005772354782

Epoch: 5| Step: 10
Training loss: 1.5905494689941406
Validation loss: 1.9477166462970037

Epoch: 215| Step: 0
Training loss: 1.3775686025619507
Validation loss: 1.9223598549442906

Epoch: 5| Step: 1
Training loss: 1.9145164489746094
Validation loss: 1.8934639320578626

Epoch: 5| Step: 2
Training loss: 1.2917324304580688
Validation loss: 1.8878137334700553

Epoch: 5| Step: 3
Training loss: 1.6325531005859375
Validation loss: 1.904693498406359

Epoch: 5| Step: 4
Training loss: 1.6432348489761353
Validation loss: 1.9254857083802581

Epoch: 5| Step: 5
Training loss: 1.943735122680664
Validation loss: 1.9442806987352268

Epoch: 5| Step: 6
Training loss: 1.709712028503418
Validation loss: 1.9648190749588834

Epoch: 5| Step: 7
Training loss: 1.7081092596054077
Validation loss: 2.016140023867289

Epoch: 5| Step: 8
Training loss: 1.4847790002822876
Validation loss: 2.0634421892063592

Epoch: 5| Step: 9
Training loss: 1.6999130249023438
Validation loss: 2.132377614257156

Epoch: 5| Step: 10
Training loss: 0.8525106906890869
Validation loss: 2.093424709894324

Epoch: 216| Step: 0
Training loss: 1.0599030256271362
Validation loss: 2.0454138363561323

Epoch: 5| Step: 1
Training loss: 1.3185094594955444
Validation loss: 1.9822997944329375

Epoch: 5| Step: 2
Training loss: 1.8786420822143555
Validation loss: 1.9186154129684612

Epoch: 5| Step: 3
Training loss: 1.5168582201004028
Validation loss: 1.8544772748024232

Epoch: 5| Step: 4
Training loss: 2.0692906379699707
Validation loss: 1.8581604034669938

Epoch: 5| Step: 5
Training loss: 1.9169620275497437
Validation loss: 1.8522093975415794

Epoch: 5| Step: 6
Training loss: 2.1170835494995117
Validation loss: 1.861311428008541

Epoch: 5| Step: 7
Training loss: 1.6471245288848877
Validation loss: 1.8821691992462322

Epoch: 5| Step: 8
Training loss: 0.8248348236083984
Validation loss: 1.9166168602564002

Epoch: 5| Step: 9
Training loss: 1.3886525630950928
Validation loss: 1.9603241412870345

Epoch: 5| Step: 10
Training loss: 1.5282410383224487
Validation loss: 2.022392354985719

Epoch: 217| Step: 0
Training loss: 1.6537578105926514
Validation loss: 2.047889291599233

Epoch: 5| Step: 1
Training loss: 1.5530911684036255
Validation loss: 2.098333610001431

Epoch: 5| Step: 2
Training loss: 1.4194753170013428
Validation loss: 2.095430843291744

Epoch: 5| Step: 3
Training loss: 1.1453123092651367
Validation loss: 2.083254396274526

Epoch: 5| Step: 4
Training loss: 1.2696259021759033
Validation loss: 2.043796670052313

Epoch: 5| Step: 5
Training loss: 1.2433949708938599
Validation loss: 2.0223524673010713

Epoch: 5| Step: 6
Training loss: 1.3884220123291016
Validation loss: 1.9457157504174016

Epoch: 5| Step: 7
Training loss: 1.5227463245391846
Validation loss: 1.9220855825690812

Epoch: 5| Step: 8
Training loss: 1.8300584554672241
Validation loss: 1.8828604618708293

Epoch: 5| Step: 9
Training loss: 2.7298502922058105
Validation loss: 1.842132068449451

Epoch: 5| Step: 10
Training loss: 0.8755174279212952
Validation loss: 1.8404164365542832

Epoch: 218| Step: 0
Training loss: 1.3094640970230103
Validation loss: 1.8386200986882693

Epoch: 5| Step: 1
Training loss: 1.2999541759490967
Validation loss: 1.8624504138064641

Epoch: 5| Step: 2
Training loss: 1.510599970817566
Validation loss: 1.8673473840118737

Epoch: 5| Step: 3
Training loss: 1.8558191061019897
Validation loss: 1.8902963489614508

Epoch: 5| Step: 4
Training loss: 1.4405735731124878
Validation loss: 1.9385263086647115

Epoch: 5| Step: 5
Training loss: 1.303005337715149
Validation loss: 1.972925034902429

Epoch: 5| Step: 6
Training loss: 1.8431596755981445
Validation loss: 2.0254753712684876

Epoch: 5| Step: 7
Training loss: 1.7838751077651978
Validation loss: 2.04761520765161

Epoch: 5| Step: 8
Training loss: 1.0948693752288818
Validation loss: 2.0190328769786383

Epoch: 5| Step: 9
Training loss: 2.140774965286255
Validation loss: 1.974660518348858

Epoch: 5| Step: 10
Training loss: 1.0623283386230469
Validation loss: 1.9025060220431256

Epoch: 219| Step: 0
Training loss: 1.3366472721099854
Validation loss: 1.8650251319331508

Epoch: 5| Step: 1
Training loss: 1.6741364002227783
Validation loss: 1.842657967280316

Epoch: 5| Step: 2
Training loss: 1.0627756118774414
Validation loss: 1.859877250527823

Epoch: 5| Step: 3
Training loss: 1.9615209102630615
Validation loss: 1.879704108802221

Epoch: 5| Step: 4
Training loss: 1.9130150079727173
Validation loss: 1.8474924487452353

Epoch: 5| Step: 5
Training loss: 1.4623613357543945
Validation loss: 1.8545406826080815

Epoch: 5| Step: 6
Training loss: 1.256179690361023
Validation loss: 1.8471208977442917

Epoch: 5| Step: 7
Training loss: 1.1298401355743408
Validation loss: 1.8858830698074833

Epoch: 5| Step: 8
Training loss: 1.762708067893982
Validation loss: 1.92717396572072

Epoch: 5| Step: 9
Training loss: 1.1653947830200195
Validation loss: 1.9839995548289309

Epoch: 5| Step: 10
Training loss: 1.6846086978912354
Validation loss: 2.0417126147977767

Epoch: 220| Step: 0
Training loss: 2.012953281402588
Validation loss: 2.1099206606547036

Epoch: 5| Step: 1
Training loss: 1.6181821823120117
Validation loss: 2.1035373467271046

Epoch: 5| Step: 2
Training loss: 1.4110395908355713
Validation loss: 2.0851174964699695

Epoch: 5| Step: 3
Training loss: 1.2063158750534058
Validation loss: 2.0096935866981425

Epoch: 5| Step: 4
Training loss: 1.3982551097869873
Validation loss: 1.9557080307314474

Epoch: 5| Step: 5
Training loss: 1.4993107318878174
Validation loss: 1.9056670306831278

Epoch: 5| Step: 6
Training loss: 1.7066504955291748
Validation loss: 1.880120877296694

Epoch: 5| Step: 7
Training loss: 1.4890917539596558
Validation loss: 1.8894167843685354

Epoch: 5| Step: 8
Training loss: 0.7600003480911255
Validation loss: 1.848998410727388

Epoch: 5| Step: 9
Training loss: 1.6843585968017578
Validation loss: 1.8269470571189799

Epoch: 5| Step: 10
Training loss: 1.8321112394332886
Validation loss: 1.8231127415933917

Epoch: 221| Step: 0
Training loss: 1.3670721054077148
Validation loss: 1.819809115061196

Epoch: 5| Step: 1
Training loss: 1.7121772766113281
Validation loss: 1.834872958480671

Epoch: 5| Step: 2
Training loss: 1.2941457033157349
Validation loss: 1.825133982525077

Epoch: 5| Step: 3
Training loss: 1.53873610496521
Validation loss: 1.854631781578064

Epoch: 5| Step: 4
Training loss: 1.2368546724319458
Validation loss: 1.9353355335932907

Epoch: 5| Step: 5
Training loss: 0.9916311502456665
Validation loss: 1.9490942519198182

Epoch: 5| Step: 6
Training loss: 1.8655229806900024
Validation loss: 2.010574484384188

Epoch: 5| Step: 7
Training loss: 1.6219675540924072
Validation loss: 1.966016669427195

Epoch: 5| Step: 8
Training loss: 1.594438076019287
Validation loss: 1.9375877854644612

Epoch: 5| Step: 9
Training loss: 1.9460155963897705
Validation loss: 1.9182336612414288

Epoch: 5| Step: 10
Training loss: 1.2297379970550537
Validation loss: 1.9290912971701673

Epoch: 222| Step: 0
Training loss: 1.3064507246017456
Validation loss: 1.930600102229785

Epoch: 5| Step: 1
Training loss: 1.5130572319030762
Validation loss: 1.9438851315488097

Epoch: 5| Step: 2
Training loss: 1.6283042430877686
Validation loss: 1.9469186746945946

Epoch: 5| Step: 3
Training loss: 1.1001865863800049
Validation loss: 1.9551341495206278

Epoch: 5| Step: 4
Training loss: 1.338240385055542
Validation loss: 1.9658088043171873

Epoch: 5| Step: 5
Training loss: 1.3720942735671997
Validation loss: 1.9560592482166905

Epoch: 5| Step: 6
Training loss: 1.6129436492919922
Validation loss: 1.960211787172543

Epoch: 5| Step: 7
Training loss: 1.602513313293457
Validation loss: 1.9666532560061383

Epoch: 5| Step: 8
Training loss: 1.3789864778518677
Validation loss: 1.9556371576042586

Epoch: 5| Step: 9
Training loss: 1.6165142059326172
Validation loss: 1.8979029142728416

Epoch: 5| Step: 10
Training loss: 1.423744797706604
Validation loss: 1.8713049016973025

Epoch: 223| Step: 0
Training loss: 1.1689822673797607
Validation loss: 1.8646220596887733

Epoch: 5| Step: 1
Training loss: 1.1853268146514893
Validation loss: 1.860296731354088

Epoch: 5| Step: 2
Training loss: 1.4467278718948364
Validation loss: 1.833687287504955

Epoch: 5| Step: 3
Training loss: 1.5432828664779663
Validation loss: 1.8704827524000598

Epoch: 5| Step: 4
Training loss: 1.0917705297470093
Validation loss: 1.8565988950831915

Epoch: 5| Step: 5
Training loss: 1.7286765575408936
Validation loss: 1.9080915912505119

Epoch: 5| Step: 6
Training loss: 1.3965120315551758
Validation loss: 1.93835525871605

Epoch: 5| Step: 7
Training loss: 1.1398770809173584
Validation loss: 2.0252466124873005

Epoch: 5| Step: 8
Training loss: 1.276798129081726
Validation loss: 2.0380271070746967

Epoch: 5| Step: 9
Training loss: 2.202486753463745
Validation loss: 2.0889835101301952

Epoch: 5| Step: 10
Training loss: 1.5030946731567383
Validation loss: 2.036437790880921

Epoch: 224| Step: 0
Training loss: 1.2550432682037354
Validation loss: 1.9446232472696612

Epoch: 5| Step: 1
Training loss: 1.6886297464370728
Validation loss: 1.8851541191019037

Epoch: 5| Step: 2
Training loss: 1.2460825443267822
Validation loss: 1.8674397596748926

Epoch: 5| Step: 3
Training loss: 1.4785048961639404
Validation loss: 1.8495444097826559

Epoch: 5| Step: 4
Training loss: 1.7425206899642944
Validation loss: 1.8121902686293407

Epoch: 5| Step: 5
Training loss: 1.4761641025543213
Validation loss: 1.8445578159824494

Epoch: 5| Step: 6
Training loss: 1.4099371433258057
Validation loss: 1.8483197086600847

Epoch: 5| Step: 7
Training loss: 1.4107024669647217
Validation loss: 1.8777017260110507

Epoch: 5| Step: 8
Training loss: 1.042229413986206
Validation loss: 1.9521303638335197

Epoch: 5| Step: 9
Training loss: 1.5889191627502441
Validation loss: 1.9866409096666562

Epoch: 5| Step: 10
Training loss: 1.6131048202514648
Validation loss: 1.9976530280164493

Epoch: 225| Step: 0
Training loss: 1.5673763751983643
Validation loss: 1.9148507874499086

Epoch: 5| Step: 1
Training loss: 1.6566412448883057
Validation loss: 1.8517989984122656

Epoch: 5| Step: 2
Training loss: 1.3188081979751587
Validation loss: 1.8162623438783871

Epoch: 5| Step: 3
Training loss: 1.1565574407577515
Validation loss: 1.8125915552980156

Epoch: 5| Step: 4
Training loss: 0.8276911973953247
Validation loss: 1.8067992143733527

Epoch: 5| Step: 5
Training loss: 1.6660547256469727
Validation loss: 1.802451055536988

Epoch: 5| Step: 6
Training loss: 1.4913619756698608
Validation loss: 1.7986703995735414

Epoch: 5| Step: 7
Training loss: 1.677477240562439
Validation loss: 1.8235141256804108

Epoch: 5| Step: 8
Training loss: 1.5271741151809692
Validation loss: 1.8570120821716964

Epoch: 5| Step: 9
Training loss: 1.447349190711975
Validation loss: 1.8841239790762625

Epoch: 5| Step: 10
Training loss: 1.1088953018188477
Validation loss: 1.9142305312618133

Epoch: 226| Step: 0
Training loss: 1.545474648475647
Validation loss: 1.933320313371638

Epoch: 5| Step: 1
Training loss: 1.3363592624664307
Validation loss: 1.961957207290075

Epoch: 5| Step: 2
Training loss: 1.1741230487823486
Validation loss: 1.940898455599303

Epoch: 5| Step: 3
Training loss: 1.6383726596832275
Validation loss: 1.9318892545597528

Epoch: 5| Step: 4
Training loss: 1.2767627239227295
Validation loss: 1.9309790621521652

Epoch: 5| Step: 5
Training loss: 1.5552088022232056
Validation loss: 1.912392311198737

Epoch: 5| Step: 6
Training loss: 1.7764625549316406
Validation loss: 1.8797571248905633

Epoch: 5| Step: 7
Training loss: 1.1457628011703491
Validation loss: 1.8425523414406726

Epoch: 5| Step: 8
Training loss: 1.4532090425491333
Validation loss: 1.8496427433465117

Epoch: 5| Step: 9
Training loss: 1.2167370319366455
Validation loss: 1.8849502455803655

Epoch: 5| Step: 10
Training loss: 0.933556079864502
Validation loss: 1.8766964456086517

Epoch: 227| Step: 0
Training loss: 1.1905195713043213
Validation loss: 1.8825470132212485

Epoch: 5| Step: 1
Training loss: 1.4456299543380737
Validation loss: 1.868754695820552

Epoch: 5| Step: 2
Training loss: 0.8620488047599792
Validation loss: 1.842137413640176

Epoch: 5| Step: 3
Training loss: 1.934303641319275
Validation loss: 1.840262492497762

Epoch: 5| Step: 4
Training loss: 1.425074577331543
Validation loss: 1.8443868737066946

Epoch: 5| Step: 5
Training loss: 1.4580647945404053
Validation loss: 1.8706955576455722

Epoch: 5| Step: 6
Training loss: 1.5385674238204956
Validation loss: 1.9127177320500857

Epoch: 5| Step: 7
Training loss: 1.4490705728530884
Validation loss: 1.9170856450193672

Epoch: 5| Step: 8
Training loss: 1.3271185159683228
Validation loss: 1.9138848025311705

Epoch: 5| Step: 9
Training loss: 1.3801560401916504
Validation loss: 1.88674549518093

Epoch: 5| Step: 10
Training loss: 0.8371542096138
Validation loss: 1.864243495848871

Epoch: 228| Step: 0
Training loss: 1.5700887441635132
Validation loss: 1.8595521988407258

Epoch: 5| Step: 1
Training loss: 1.8220669031143188
Validation loss: 1.8342639938477547

Epoch: 5| Step: 2
Training loss: 1.624429702758789
Validation loss: 1.8364906798126877

Epoch: 5| Step: 3
Training loss: 1.3245395421981812
Validation loss: 1.8424326386502994

Epoch: 5| Step: 4
Training loss: 1.6558482646942139
Validation loss: 1.835837851288498

Epoch: 5| Step: 5
Training loss: 1.3332473039627075
Validation loss: 1.8473005833164338

Epoch: 5| Step: 6
Training loss: 0.9578242301940918
Validation loss: 1.8485915891585811

Epoch: 5| Step: 7
Training loss: 1.5330750942230225
Validation loss: 1.8537868171609857

Epoch: 5| Step: 8
Training loss: 0.8529163599014282
Validation loss: 1.862519794894803

Epoch: 5| Step: 9
Training loss: 1.0589683055877686
Validation loss: 1.8773839383996942

Epoch: 5| Step: 10
Training loss: 1.0098990201950073
Validation loss: 1.8808232545852661

Epoch: 229| Step: 0
Training loss: 1.979448676109314
Validation loss: 1.8585308059569328

Epoch: 5| Step: 1
Training loss: 1.3592010736465454
Validation loss: 1.8684347086055304

Epoch: 5| Step: 2
Training loss: 0.9423049688339233
Validation loss: 1.8803057080955916

Epoch: 5| Step: 3
Training loss: 1.0355355739593506
Validation loss: 1.8719013801185034

Epoch: 5| Step: 4
Training loss: 1.3655606508255005
Validation loss: 1.8831807157044769

Epoch: 5| Step: 5
Training loss: 1.174363374710083
Validation loss: 1.8954539222102011

Epoch: 5| Step: 6
Training loss: 1.1876399517059326
Validation loss: 1.919671853383382

Epoch: 5| Step: 7
Training loss: 1.114325761795044
Validation loss: 1.9354010102569417

Epoch: 5| Step: 8
Training loss: 1.476980209350586
Validation loss: 1.9284367369067283

Epoch: 5| Step: 9
Training loss: 1.4855033159255981
Validation loss: 1.967034734705443

Epoch: 5| Step: 10
Training loss: 1.9790115356445312
Validation loss: 1.9089724633001512

Epoch: 230| Step: 0
Training loss: 0.9905325174331665
Validation loss: 1.872473451399034

Epoch: 5| Step: 1
Training loss: 0.8431965112686157
Validation loss: 1.8276579123671337

Epoch: 5| Step: 2
Training loss: 1.6687288284301758
Validation loss: 1.7861187329856298

Epoch: 5| Step: 3
Training loss: 1.609585165977478
Validation loss: 1.7703044824702765

Epoch: 5| Step: 4
Training loss: 1.2065385580062866
Validation loss: 1.7785489482264365

Epoch: 5| Step: 5
Training loss: 1.2719860076904297
Validation loss: 1.7887868342861053

Epoch: 5| Step: 6
Training loss: 1.543918490409851
Validation loss: 1.7969372785219582

Epoch: 5| Step: 7
Training loss: 1.81498122215271
Validation loss: 1.7877747243450535

Epoch: 5| Step: 8
Training loss: 1.3590188026428223
Validation loss: 1.820130548169536

Epoch: 5| Step: 9
Training loss: 1.1085295677185059
Validation loss: 1.8499870556657032

Epoch: 5| Step: 10
Training loss: 1.5463236570358276
Validation loss: 1.8814888013306486

Epoch: 231| Step: 0
Training loss: 1.494270920753479
Validation loss: 1.9550945002545592

Epoch: 5| Step: 1
Training loss: 1.3801658153533936
Validation loss: 1.963725750164319

Epoch: 5| Step: 2
Training loss: 1.6043217182159424
Validation loss: 1.9419557343247116

Epoch: 5| Step: 3
Training loss: 1.2746083736419678
Validation loss: 1.9426710400530087

Epoch: 5| Step: 4
Training loss: 0.8674321174621582
Validation loss: 1.8940244310645646

Epoch: 5| Step: 5
Training loss: 1.0571058988571167
Validation loss: 1.8996219622191561

Epoch: 5| Step: 6
Training loss: 1.069687008857727
Validation loss: 1.8585441407336984

Epoch: 5| Step: 7
Training loss: 1.5386598110198975
Validation loss: 1.8475823376768379

Epoch: 5| Step: 8
Training loss: 1.0578092336654663
Validation loss: 1.848060288736897

Epoch: 5| Step: 9
Training loss: 1.596970796585083
Validation loss: 1.8458571946749123

Epoch: 5| Step: 10
Training loss: 1.567769169807434
Validation loss: 1.833963894074963

Epoch: 232| Step: 0
Training loss: 1.1533825397491455
Validation loss: 1.8149150110060168

Epoch: 5| Step: 1
Training loss: 1.2861407995224
Validation loss: 1.8204002021461405

Epoch: 5| Step: 2
Training loss: 1.3524855375289917
Validation loss: 1.8364019368284492

Epoch: 5| Step: 3
Training loss: 0.838738739490509
Validation loss: 1.8454105623306767

Epoch: 5| Step: 4
Training loss: 1.008917212486267
Validation loss: 1.8675728356966408

Epoch: 5| Step: 5
Training loss: 0.9891942143440247
Validation loss: 1.8977490983983523

Epoch: 5| Step: 6
Training loss: 1.4512789249420166
Validation loss: 1.9059487914526334

Epoch: 5| Step: 7
Training loss: 1.6471645832061768
Validation loss: 1.8515629819644395

Epoch: 5| Step: 8
Training loss: 1.185630440711975
Validation loss: 1.831992514671818

Epoch: 5| Step: 9
Training loss: 1.6865513324737549
Validation loss: 1.778195119673206

Epoch: 5| Step: 10
Training loss: 1.7112855911254883
Validation loss: 1.7802747705931306

Epoch: 233| Step: 0
Training loss: 1.249509572982788
Validation loss: 1.7775772950982536

Epoch: 5| Step: 1
Training loss: 1.4229860305786133
Validation loss: 1.784547209739685

Epoch: 5| Step: 2
Training loss: 0.723966121673584
Validation loss: 1.8303998131905832

Epoch: 5| Step: 3
Training loss: 1.1254918575286865
Validation loss: 1.8208044267469836

Epoch: 5| Step: 4
Training loss: 1.2814857959747314
Validation loss: 1.8598452306562854

Epoch: 5| Step: 5
Training loss: 1.483406662940979
Validation loss: 1.9180560945182719

Epoch: 5| Step: 6
Training loss: 1.4847235679626465
Validation loss: 1.919937063288945

Epoch: 5| Step: 7
Training loss: 1.1406891345977783
Validation loss: 1.8897856538013746

Epoch: 5| Step: 8
Training loss: 1.8596652746200562
Validation loss: 1.8776188409456642

Epoch: 5| Step: 9
Training loss: 0.861883282661438
Validation loss: 1.8685940209255423

Epoch: 5| Step: 10
Training loss: 1.6241846084594727
Validation loss: 1.8184638741195842

Epoch: 234| Step: 0
Training loss: 1.0307433605194092
Validation loss: 1.812394219060098

Epoch: 5| Step: 1
Training loss: 1.0134575366973877
Validation loss: 1.807594282652742

Epoch: 5| Step: 2
Training loss: 1.6518694162368774
Validation loss: 1.7800517338578419

Epoch: 5| Step: 3
Training loss: 0.9805196523666382
Validation loss: 1.7779273807361562

Epoch: 5| Step: 4
Training loss: 1.5057411193847656
Validation loss: 1.789715741270332

Epoch: 5| Step: 5
Training loss: 1.741045355796814
Validation loss: 1.808921738337445

Epoch: 5| Step: 6
Training loss: 1.6750930547714233
Validation loss: 1.8522588847785868

Epoch: 5| Step: 7
Training loss: 0.8661621809005737
Validation loss: 1.8818088962185768

Epoch: 5| Step: 8
Training loss: 0.8171392679214478
Validation loss: 1.894725179159513

Epoch: 5| Step: 9
Training loss: 1.2799955606460571
Validation loss: 1.89124132228154

Epoch: 5| Step: 10
Training loss: 1.428481936454773
Validation loss: 1.9000888998790453

Epoch: 235| Step: 0
Training loss: 1.2116024494171143
Validation loss: 1.8725756906693982

Epoch: 5| Step: 1
Training loss: 1.1131190061569214
Validation loss: 1.850502403833533

Epoch: 5| Step: 2
Training loss: 0.9095430374145508
Validation loss: 1.8161642282239852

Epoch: 5| Step: 3
Training loss: 1.268833041191101
Validation loss: 1.8023889449334913

Epoch: 5| Step: 4
Training loss: 1.397417664527893
Validation loss: 1.8222433969538698

Epoch: 5| Step: 5
Training loss: 1.1375516653060913
Validation loss: 1.8338099013092697

Epoch: 5| Step: 6
Training loss: 1.1114249229431152
Validation loss: 1.8406136676829348

Epoch: 5| Step: 7
Training loss: 1.3276758193969727
Validation loss: 1.8139239818819108

Epoch: 5| Step: 8
Training loss: 1.299108624458313
Validation loss: 1.8514656354022283

Epoch: 5| Step: 9
Training loss: 1.6899011135101318
Validation loss: 1.8717112182289042

Epoch: 5| Step: 10
Training loss: 1.3715276718139648
Validation loss: 1.8780437246445687

Epoch: 236| Step: 0
Training loss: 1.1018294095993042
Validation loss: 1.8845898758980535

Epoch: 5| Step: 1
Training loss: 1.1109570264816284
Validation loss: 1.9275788978863788

Epoch: 5| Step: 2
Training loss: 1.8780567646026611
Validation loss: 1.8913917297958045

Epoch: 5| Step: 3
Training loss: 1.0579822063446045
Validation loss: 1.9278676176583895

Epoch: 5| Step: 4
Training loss: 1.3850281238555908
Validation loss: 1.9104679233284407

Epoch: 5| Step: 5
Training loss: 1.5356630086898804
Validation loss: 1.881456236685476

Epoch: 5| Step: 6
Training loss: 0.923247218132019
Validation loss: 1.8384740916631555

Epoch: 5| Step: 7
Training loss: 1.0670180320739746
Validation loss: 1.8356074517773044

Epoch: 5| Step: 8
Training loss: 1.396532654762268
Validation loss: 1.8266409161270305

Epoch: 5| Step: 9
Training loss: 1.3280799388885498
Validation loss: 1.842476507668854

Epoch: 5| Step: 10
Training loss: 0.7762324213981628
Validation loss: 1.8439544811043689

Epoch: 237| Step: 0
Training loss: 1.067510962486267
Validation loss: 1.8202259668739893

Epoch: 5| Step: 1
Training loss: 1.4266704320907593
Validation loss: 1.821829024181571

Epoch: 5| Step: 2
Training loss: 1.7628370523452759
Validation loss: 1.8425933186725905

Epoch: 5| Step: 3
Training loss: 1.5737005472183228
Validation loss: 1.8673442820067048

Epoch: 5| Step: 4
Training loss: 1.1059097051620483
Validation loss: 1.890287535164946

Epoch: 5| Step: 5
Training loss: 1.030171275138855
Validation loss: 1.8743231334993917

Epoch: 5| Step: 6
Training loss: 1.0586986541748047
Validation loss: 1.875041760424132

Epoch: 5| Step: 7
Training loss: 1.4800657033920288
Validation loss: 1.8280357417239939

Epoch: 5| Step: 8
Training loss: 0.746014416217804
Validation loss: 1.79559963492937

Epoch: 5| Step: 9
Training loss: 1.0683704614639282
Validation loss: 1.8050021445879372

Epoch: 5| Step: 10
Training loss: 1.4013195037841797
Validation loss: 1.7835205780562533

Epoch: 238| Step: 0
Training loss: 1.3439431190490723
Validation loss: 1.778947844300219

Epoch: 5| Step: 1
Training loss: 1.32499098777771
Validation loss: 1.7561788776869416

Epoch: 5| Step: 2
Training loss: 1.171710729598999
Validation loss: 1.7653450568517048

Epoch: 5| Step: 3
Training loss: 1.7151644229888916
Validation loss: 1.7794116043275403

Epoch: 5| Step: 4
Training loss: 1.6317898035049438
Validation loss: 1.793069826659336

Epoch: 5| Step: 5
Training loss: 1.1811625957489014
Validation loss: 1.8351890758801532

Epoch: 5| Step: 6
Training loss: 1.0077285766601562
Validation loss: 1.8601715205818095

Epoch: 5| Step: 7
Training loss: 0.7105683088302612
Validation loss: 1.8595221324633526

Epoch: 5| Step: 8
Training loss: 1.0576869249343872
Validation loss: 1.9081478349624141

Epoch: 5| Step: 9
Training loss: 1.2983554601669312
Validation loss: 1.8895149602684924

Epoch: 5| Step: 10
Training loss: 1.2565479278564453
Validation loss: 1.88693271657472

Epoch: 239| Step: 0
Training loss: 1.6791822910308838
Validation loss: 1.879916529501638

Epoch: 5| Step: 1
Training loss: 0.7176425457000732
Validation loss: 1.863378576053086

Epoch: 5| Step: 2
Training loss: 1.3871115446090698
Validation loss: 1.8789274718171807

Epoch: 5| Step: 3
Training loss: 1.3484976291656494
Validation loss: 1.860120592578765

Epoch: 5| Step: 4
Training loss: 0.9612346887588501
Validation loss: 1.8538640763169976

Epoch: 5| Step: 5
Training loss: 1.03117036819458
Validation loss: 1.849499507616925

Epoch: 5| Step: 6
Training loss: 2.0473504066467285
Validation loss: 1.83960767715208

Epoch: 5| Step: 7
Training loss: 0.8587180376052856
Validation loss: 1.8521319807216685

Epoch: 5| Step: 8
Training loss: 1.6019970178604126
Validation loss: 1.847310555878506

Epoch: 5| Step: 9
Training loss: 0.8645351529121399
Validation loss: 1.8623330721291163

Epoch: 5| Step: 10
Training loss: 1.0373175144195557
Validation loss: 1.8657255031729256

Epoch: 240| Step: 0
Training loss: 1.1004537343978882
Validation loss: 1.855324109395345

Epoch: 5| Step: 1
Training loss: 1.086606502532959
Validation loss: 1.867753908198367

Epoch: 5| Step: 2
Training loss: 1.4725909233093262
Validation loss: 1.8864290175899383

Epoch: 5| Step: 3
Training loss: 1.7233397960662842
Validation loss: 1.881844655159981

Epoch: 5| Step: 4
Training loss: 0.7231875658035278
Validation loss: 1.8331704908801663

Epoch: 5| Step: 5
Training loss: 1.16460120677948
Validation loss: 1.811019028386762

Epoch: 5| Step: 6
Training loss: 1.336744785308838
Validation loss: 1.8083325868011804

Epoch: 5| Step: 7
Training loss: 0.8398181200027466
Validation loss: 1.8052739366408317

Epoch: 5| Step: 8
Training loss: 1.2557108402252197
Validation loss: 1.8192537279539212

Epoch: 5| Step: 9
Training loss: 1.587585687637329
Validation loss: 1.8527581179013817

Epoch: 5| Step: 10
Training loss: 1.3870275020599365
Validation loss: 1.8910866424601565

Epoch: 241| Step: 0
Training loss: 0.856318473815918
Validation loss: 1.8255815839254728

Epoch: 5| Step: 1
Training loss: 1.3829612731933594
Validation loss: 1.786098866052525

Epoch: 5| Step: 2
Training loss: 1.434829592704773
Validation loss: 1.7611068423076341

Epoch: 5| Step: 3
Training loss: 0.805249035358429
Validation loss: 1.7871088443263885

Epoch: 5| Step: 4
Training loss: 1.5295579433441162
Validation loss: 1.7951032192476335

Epoch: 5| Step: 5
Training loss: 1.5048000812530518
Validation loss: 1.7988646850791028

Epoch: 5| Step: 6
Training loss: 1.3467581272125244
Validation loss: 1.806013871264714

Epoch: 5| Step: 7
Training loss: 1.3536707162857056
Validation loss: 1.8153555226582352

Epoch: 5| Step: 8
Training loss: 1.025293231010437
Validation loss: 1.8231119494284354

Epoch: 5| Step: 9
Training loss: 1.3394306898117065
Validation loss: 1.8622442381356352

Epoch: 5| Step: 10
Training loss: 1.0058075189590454
Validation loss: 1.8713988386174685

Epoch: 242| Step: 0
Training loss: 1.2983965873718262
Validation loss: 1.8420148049631426

Epoch: 5| Step: 1
Training loss: 0.9084450602531433
Validation loss: 1.8060866953224264

Epoch: 5| Step: 2
Training loss: 1.187608242034912
Validation loss: 1.765258135334138

Epoch: 5| Step: 3
Training loss: 0.5256264209747314
Validation loss: 1.7923985142861643

Epoch: 5| Step: 4
Training loss: 1.2728018760681152
Validation loss: 1.8008166384953324

Epoch: 5| Step: 5
Training loss: 1.3020541667938232
Validation loss: 1.8225829037286903

Epoch: 5| Step: 6
Training loss: 1.7499110698699951
Validation loss: 1.829986503047328

Epoch: 5| Step: 7
Training loss: 1.163569450378418
Validation loss: 1.828583825019098

Epoch: 5| Step: 8
Training loss: 1.622941255569458
Validation loss: 1.8155043407153058

Epoch: 5| Step: 9
Training loss: 1.0714460611343384
Validation loss: 1.8191247499117287

Epoch: 5| Step: 10
Training loss: 1.6358349323272705
Validation loss: 1.839701585872199

Epoch: 243| Step: 0
Training loss: 0.9903775453567505
Validation loss: 1.857156930431243

Epoch: 5| Step: 1
Training loss: 1.1708498001098633
Validation loss: 1.8812321950030584

Epoch: 5| Step: 2
Training loss: 1.1038763523101807
Validation loss: 1.9195964797850578

Epoch: 5| Step: 3
Training loss: 0.9579439163208008
Validation loss: 1.9036131622970744

Epoch: 5| Step: 4
Training loss: 1.3834457397460938
Validation loss: 1.9189764440700572

Epoch: 5| Step: 5
Training loss: 1.2513716220855713
Validation loss: 1.915175159772237

Epoch: 5| Step: 6
Training loss: 1.6561672687530518
Validation loss: 1.8961312642661474

Epoch: 5| Step: 7
Training loss: 1.6122719049453735
Validation loss: 1.890548844491282

Epoch: 5| Step: 8
Training loss: 0.8896614909172058
Validation loss: 1.8901010123632287

Epoch: 5| Step: 9
Training loss: 1.149914026260376
Validation loss: 1.9073437618952926

Epoch: 5| Step: 10
Training loss: 1.1899515390396118
Validation loss: 1.90031526934716

Epoch: 244| Step: 0
Training loss: 1.523097038269043
Validation loss: 1.874201117023345

Epoch: 5| Step: 1
Training loss: 1.1542978286743164
Validation loss: 1.8511583317992508

Epoch: 5| Step: 2
Training loss: 0.9397441744804382
Validation loss: 1.846270122835713

Epoch: 5| Step: 3
Training loss: 1.5700215101242065
Validation loss: 1.850741768396029

Epoch: 5| Step: 4
Training loss: 1.1818735599517822
Validation loss: 1.835338754038657

Epoch: 5| Step: 5
Training loss: 0.8221508264541626
Validation loss: 1.8655590485501032

Epoch: 5| Step: 6
Training loss: 1.1087257862091064
Validation loss: 1.8794539756672357

Epoch: 5| Step: 7
Training loss: 1.0166821479797363
Validation loss: 1.8257854792379564

Epoch: 5| Step: 8
Training loss: 1.3622651100158691
Validation loss: 1.802765651415753

Epoch: 5| Step: 9
Training loss: 1.2430516481399536
Validation loss: 1.787215398203942

Epoch: 5| Step: 10
Training loss: 1.0345224142074585
Validation loss: 1.801040005940263

Epoch: 245| Step: 0
Training loss: 1.2427606582641602
Validation loss: 1.7847772746957757

Epoch: 5| Step: 1
Training loss: 1.0700191259384155
Validation loss: 1.7781521261379283

Epoch: 5| Step: 2
Training loss: 1.0638389587402344
Validation loss: 1.8240705920803932

Epoch: 5| Step: 3
Training loss: 1.196338176727295
Validation loss: 1.8346599237893217

Epoch: 5| Step: 4
Training loss: 0.7147337198257446
Validation loss: 1.8518544179137035

Epoch: 5| Step: 5
Training loss: 1.0777008533477783
Validation loss: 1.8098243013505013

Epoch: 5| Step: 6
Training loss: 1.278761625289917
Validation loss: 1.7900755405426025

Epoch: 5| Step: 7
Training loss: 1.794968843460083
Validation loss: 1.756669972532539

Epoch: 5| Step: 8
Training loss: 1.4005439281463623
Validation loss: 1.7319602479216873

Epoch: 5| Step: 9
Training loss: 0.8719064593315125
Validation loss: 1.73392564763305

Epoch: 5| Step: 10
Training loss: 1.4007028341293335
Validation loss: 1.7434233824412029

Epoch: 246| Step: 0
Training loss: 1.1941354274749756
Validation loss: 1.7612207653701946

Epoch: 5| Step: 1
Training loss: 1.6547740697860718
Validation loss: 1.7865488772751184

Epoch: 5| Step: 2
Training loss: 1.24116849899292
Validation loss: 1.7978963954474336

Epoch: 5| Step: 3
Training loss: 1.0305325984954834
Validation loss: 1.8013091138614121

Epoch: 5| Step: 4
Training loss: 0.5960336923599243
Validation loss: 1.8091928984529229

Epoch: 5| Step: 5
Training loss: 0.9000530242919922
Validation loss: 1.8288565912554342

Epoch: 5| Step: 6
Training loss: 1.0176750421524048
Validation loss: 1.8166812158400012

Epoch: 5| Step: 7
Training loss: 1.123610496520996
Validation loss: 1.8192560262577508

Epoch: 5| Step: 8
Training loss: 1.276171088218689
Validation loss: 1.8470758443237634

Epoch: 5| Step: 9
Training loss: 1.4253489971160889
Validation loss: 1.8644341704665974

Epoch: 5| Step: 10
Training loss: 1.1919984817504883
Validation loss: 1.8220963426815566

Epoch: 247| Step: 0
Training loss: 1.1582947969436646
Validation loss: 1.80424202001223

Epoch: 5| Step: 1
Training loss: 1.4854257106781006
Validation loss: 1.7894852712590208

Epoch: 5| Step: 2
Training loss: 1.1664087772369385
Validation loss: 1.7619384360569779

Epoch: 5| Step: 3
Training loss: 1.2443397045135498
Validation loss: 1.7639286197641844

Epoch: 5| Step: 4
Training loss: 0.7259088158607483
Validation loss: 1.8019025005320066

Epoch: 5| Step: 5
Training loss: 1.2031173706054688
Validation loss: 1.8450506964037496

Epoch: 5| Step: 6
Training loss: 1.2414333820343018
Validation loss: 1.8436360487373926

Epoch: 5| Step: 7
Training loss: 1.3523547649383545
Validation loss: 1.8426856584446405

Epoch: 5| Step: 8
Training loss: 1.1972362995147705
Validation loss: 1.8271323404004496

Epoch: 5| Step: 9
Training loss: 1.0827802419662476
Validation loss: 1.7984724557527931

Epoch: 5| Step: 10
Training loss: 1.0400004386901855
Validation loss: 1.7875128010267853

Epoch: 248| Step: 0
Training loss: 1.0584388971328735
Validation loss: 1.7943300444592711

Epoch: 5| Step: 1
Training loss: 1.2765164375305176
Validation loss: 1.7908522749459872

Epoch: 5| Step: 2
Training loss: 0.7583287358283997
Validation loss: 1.7731502466304327

Epoch: 5| Step: 3
Training loss: 1.7756723165512085
Validation loss: 1.7704981680839293

Epoch: 5| Step: 4
Training loss: 1.8124297857284546
Validation loss: 1.7944936226773005

Epoch: 5| Step: 5
Training loss: 1.1044833660125732
Validation loss: 1.791933592929635

Epoch: 5| Step: 6
Training loss: 1.2905725240707397
Validation loss: 1.8026086040722427

Epoch: 5| Step: 7
Training loss: 0.817010760307312
Validation loss: 1.7966116397611556

Epoch: 5| Step: 8
Training loss: 0.9294202923774719
Validation loss: 1.8249278606907013

Epoch: 5| Step: 9
Training loss: 1.1097925901412964
Validation loss: 1.8714559437126241

Epoch: 5| Step: 10
Training loss: 0.8228200078010559
Validation loss: 1.8822081973475795

Epoch: 249| Step: 0
Training loss: 1.0503599643707275
Validation loss: 1.8780082964128064

Epoch: 5| Step: 1
Training loss: 0.8298110961914062
Validation loss: 1.808403274064423

Epoch: 5| Step: 2
Training loss: 1.0428211688995361
Validation loss: 1.812408713884251

Epoch: 5| Step: 3
Training loss: 1.613299012184143
Validation loss: 1.8271732894323205

Epoch: 5| Step: 4
Training loss: 0.7635860443115234
Validation loss: 1.8412723246441092

Epoch: 5| Step: 5
Training loss: 1.690798044204712
Validation loss: 1.8256758156643118

Epoch: 5| Step: 6
Training loss: 0.9330979585647583
Validation loss: 1.8259046539183585

Epoch: 5| Step: 7
Training loss: 1.4263570308685303
Validation loss: 1.8394402368094331

Epoch: 5| Step: 8
Training loss: 1.0132802724838257
Validation loss: 1.8177897455871745

Epoch: 5| Step: 9
Training loss: 1.261759638786316
Validation loss: 1.8136104691413142

Epoch: 5| Step: 10
Training loss: 1.0764110088348389
Validation loss: 1.7893504365797965

Epoch: 250| Step: 0
Training loss: 1.4365944862365723
Validation loss: 1.8000893528743456

Epoch: 5| Step: 1
Training loss: 1.0086276531219482
Validation loss: 1.7825085847608504

Epoch: 5| Step: 2
Training loss: 1.5337458848953247
Validation loss: 1.807689944903056

Epoch: 5| Step: 3
Training loss: 0.858939528465271
Validation loss: 1.8284156066115185

Epoch: 5| Step: 4
Training loss: 1.1678276062011719
Validation loss: 1.8213405404039609

Epoch: 5| Step: 5
Training loss: 1.3887794017791748
Validation loss: 1.7771209324559858

Epoch: 5| Step: 6
Training loss: 0.972019374370575
Validation loss: 1.7755289193122619

Epoch: 5| Step: 7
Training loss: 1.0131222009658813
Validation loss: 1.7617597413319412

Epoch: 5| Step: 8
Training loss: 0.8268702626228333
Validation loss: 1.7396227287989792

Epoch: 5| Step: 9
Training loss: 1.1122130155563354
Validation loss: 1.7293281503902969

Epoch: 5| Step: 10
Training loss: 1.1980793476104736
Validation loss: 1.7564541473183581

Epoch: 251| Step: 0
Training loss: 1.225121259689331
Validation loss: 1.774655520275075

Epoch: 5| Step: 1
Training loss: 1.072595238685608
Validation loss: 1.843423076855239

Epoch: 5| Step: 2
Training loss: 0.757454514503479
Validation loss: 1.888296651583846

Epoch: 5| Step: 3
Training loss: 1.6729408502578735
Validation loss: 1.9175294368497786

Epoch: 5| Step: 4
Training loss: 0.8765621185302734
Validation loss: 1.8525247484125116

Epoch: 5| Step: 5
Training loss: 1.7166553735733032
Validation loss: 1.8042856057484944

Epoch: 5| Step: 6
Training loss: 1.2146244049072266
Validation loss: 1.7852629333414056

Epoch: 5| Step: 7
Training loss: 1.2931134700775146
Validation loss: 1.7643027767058341

Epoch: 5| Step: 8
Training loss: 1.0803334712982178
Validation loss: 1.7824865720605338

Epoch: 5| Step: 9
Training loss: 0.8362768292427063
Validation loss: 1.7536689414772937

Epoch: 5| Step: 10
Training loss: 0.797939121723175
Validation loss: 1.798163349910449

Epoch: 252| Step: 0
Training loss: 0.8792640566825867
Validation loss: 1.8510602622903802

Epoch: 5| Step: 1
Training loss: 1.1829283237457275
Validation loss: 1.8877001436807777

Epoch: 5| Step: 2
Training loss: 1.282781720161438
Validation loss: 1.9180116935442852

Epoch: 5| Step: 3
Training loss: 1.3703750371932983
Validation loss: 1.907397788058045

Epoch: 5| Step: 4
Training loss: 1.389268159866333
Validation loss: 1.8064469188772223

Epoch: 5| Step: 5
Training loss: 0.7139230370521545
Validation loss: 1.761964996655782

Epoch: 5| Step: 6
Training loss: 0.895533561706543
Validation loss: 1.746917123435646

Epoch: 5| Step: 7
Training loss: 1.2148983478546143
Validation loss: 1.7278852129495272

Epoch: 5| Step: 8
Training loss: 1.6469440460205078
Validation loss: 1.739158002279138

Epoch: 5| Step: 9
Training loss: 1.046425700187683
Validation loss: 1.7181487506435764

Epoch: 5| Step: 10
Training loss: 1.0552152395248413
Validation loss: 1.7374424895932596

Epoch: 253| Step: 0
Training loss: 0.7928262948989868
Validation loss: 1.780489760060464

Epoch: 5| Step: 1
Training loss: 1.2715585231781006
Validation loss: 1.846080328828545

Epoch: 5| Step: 2
Training loss: 0.9344738125801086
Validation loss: 1.854958721386489

Epoch: 5| Step: 3
Training loss: 0.9121447801589966
Validation loss: 1.8718899321812454

Epoch: 5| Step: 4
Training loss: 1.1502115726470947
Validation loss: 1.8479470206845192

Epoch: 5| Step: 5
Training loss: 1.5857079029083252
Validation loss: 1.8044357517714142

Epoch: 5| Step: 6
Training loss: 0.8962363004684448
Validation loss: 1.8012310356222174

Epoch: 5| Step: 7
Training loss: 0.6986321210861206
Validation loss: 1.7523602388238395

Epoch: 5| Step: 8
Training loss: 1.487597107887268
Validation loss: 1.7715504477100987

Epoch: 5| Step: 9
Training loss: 1.4780610799789429
Validation loss: 1.78423531721997

Epoch: 5| Step: 10
Training loss: 0.8735601305961609
Validation loss: 1.7627839478113319

Epoch: 254| Step: 0
Training loss: 1.244947075843811
Validation loss: 1.7898771365483601

Epoch: 5| Step: 1
Training loss: 1.0474917888641357
Validation loss: 1.785252522396785

Epoch: 5| Step: 2
Training loss: 1.3431661128997803
Validation loss: 1.8213039521248109

Epoch: 5| Step: 3
Training loss: 0.9029111862182617
Validation loss: 1.8461215226880965

Epoch: 5| Step: 4
Training loss: 0.8507949709892273
Validation loss: 1.9179340357421546

Epoch: 5| Step: 5
Training loss: 0.9063926935195923
Validation loss: 1.9684828481366556

Epoch: 5| Step: 6
Training loss: 1.2703158855438232
Validation loss: 1.9414902438399613

Epoch: 5| Step: 7
Training loss: 0.7982565760612488
Validation loss: 1.868683099746704

Epoch: 5| Step: 8
Training loss: 1.3782812356948853
Validation loss: 1.7845183034096994

Epoch: 5| Step: 9
Training loss: 1.4556620121002197
Validation loss: 1.7200180676675612

Epoch: 5| Step: 10
Training loss: 0.9826277494430542
Validation loss: 1.7204377753760225

Epoch: 255| Step: 0
Training loss: 1.199135422706604
Validation loss: 1.7343386885940388

Epoch: 5| Step: 1
Training loss: 0.8299786448478699
Validation loss: 1.7185757865187943

Epoch: 5| Step: 2
Training loss: 1.3671340942382812
Validation loss: 1.70455890317117

Epoch: 5| Step: 3
Training loss: 1.0792046785354614
Validation loss: 1.730908199023175

Epoch: 5| Step: 4
Training loss: 1.112352967262268
Validation loss: 1.7551840530928744

Epoch: 5| Step: 5
Training loss: 0.5969196557998657
Validation loss: 1.811606507147512

Epoch: 5| Step: 6
Training loss: 1.2136955261230469
Validation loss: 1.8584349924518215

Epoch: 5| Step: 7
Training loss: 1.4849843978881836
Validation loss: 1.8368610579480407

Epoch: 5| Step: 8
Training loss: 1.2008806467056274
Validation loss: 1.8321037471935313

Epoch: 5| Step: 9
Training loss: 0.8552829623222351
Validation loss: 1.7914745166737547

Epoch: 5| Step: 10
Training loss: 1.5373342037200928
Validation loss: 1.76958812949478

Epoch: 256| Step: 0
Training loss: 1.399407982826233
Validation loss: 1.7266920420431322

Epoch: 5| Step: 1
Training loss: 0.745219349861145
Validation loss: 1.7400211006082513

Epoch: 5| Step: 2
Training loss: 0.9409720301628113
Validation loss: 1.719748293199847

Epoch: 5| Step: 3
Training loss: 1.1404632329940796
Validation loss: 1.7370624247417654

Epoch: 5| Step: 4
Training loss: 1.2049684524536133
Validation loss: 1.730867458928016

Epoch: 5| Step: 5
Training loss: 1.2420947551727295
Validation loss: 1.7513091461632841

Epoch: 5| Step: 6
Training loss: 0.7869299650192261
Validation loss: 1.7542804646235641

Epoch: 5| Step: 7
Training loss: 1.3578983545303345
Validation loss: 1.7975915298667005

Epoch: 5| Step: 8
Training loss: 1.1077497005462646
Validation loss: 1.7693621702091669

Epoch: 5| Step: 9
Training loss: 0.708922266960144
Validation loss: 1.7989644042907222

Epoch: 5| Step: 10
Training loss: 1.2789883613586426
Validation loss: 1.8083492068834202

Epoch: 257| Step: 0
Training loss: 1.3057746887207031
Validation loss: 1.7788439950635355

Epoch: 5| Step: 1
Training loss: 1.2695735692977905
Validation loss: 1.7695863644282024

Epoch: 5| Step: 2
Training loss: 1.310473084449768
Validation loss: 1.7607742201897405

Epoch: 5| Step: 3
Training loss: 1.2208601236343384
Validation loss: 1.7657744833218154

Epoch: 5| Step: 4
Training loss: 0.5625156760215759
Validation loss: 1.7948247027653519

Epoch: 5| Step: 5
Training loss: 0.8947452306747437
Validation loss: 1.8143406978217504

Epoch: 5| Step: 6
Training loss: 1.4584349393844604
Validation loss: 1.8043941438839

Epoch: 5| Step: 7
Training loss: 0.6740398406982422
Validation loss: 1.8323430771468787

Epoch: 5| Step: 8
Training loss: 0.9923223257064819
Validation loss: 1.8584178647687357

Epoch: 5| Step: 9
Training loss: 0.9461342096328735
Validation loss: 1.8493007947039861

Epoch: 5| Step: 10
Training loss: 1.1791739463806152
Validation loss: 1.8477886415296985

Epoch: 258| Step: 0
Training loss: 0.5203521847724915
Validation loss: 1.8269159947672198

Epoch: 5| Step: 1
Training loss: 1.0386202335357666
Validation loss: 1.7972085463103427

Epoch: 5| Step: 2
Training loss: 0.49232083559036255
Validation loss: 1.761398098802054

Epoch: 5| Step: 3
Training loss: 1.232417345046997
Validation loss: 1.738322683559951

Epoch: 5| Step: 4
Training loss: 1.2641167640686035
Validation loss: 1.7555502281394055

Epoch: 5| Step: 5
Training loss: 1.1435140371322632
Validation loss: 1.7438907020835466

Epoch: 5| Step: 6
Training loss: 1.2915810346603394
Validation loss: 1.7438324651410502

Epoch: 5| Step: 7
Training loss: 1.1418030261993408
Validation loss: 1.7682893007032332

Epoch: 5| Step: 8
Training loss: 1.3296908140182495
Validation loss: 1.766229876907923

Epoch: 5| Step: 9
Training loss: 1.3163862228393555
Validation loss: 1.8064515949577413

Epoch: 5| Step: 10
Training loss: 0.8337470889091492
Validation loss: 1.8416096612971316

Epoch: 259| Step: 0
Training loss: 0.6887657046318054
Validation loss: 1.8440282024363035

Epoch: 5| Step: 1
Training loss: 1.0174567699432373
Validation loss: 1.8079800080227595

Epoch: 5| Step: 2
Training loss: 1.1786998510360718
Validation loss: 1.7912392180453065

Epoch: 5| Step: 3
Training loss: 1.271462321281433
Validation loss: 1.744102531863797

Epoch: 5| Step: 4
Training loss: 1.0269109010696411
Validation loss: 1.7582352968954271

Epoch: 5| Step: 5
Training loss: 0.88909512758255
Validation loss: 1.760872176898423

Epoch: 5| Step: 6
Training loss: 1.502691626548767
Validation loss: 1.7528165399387319

Epoch: 5| Step: 7
Training loss: 1.1186540126800537
Validation loss: 1.7739207501052527

Epoch: 5| Step: 8
Training loss: 1.2595165967941284
Validation loss: 1.775668603117748

Epoch: 5| Step: 9
Training loss: 0.7407139539718628
Validation loss: 1.7974564747143817

Epoch: 5| Step: 10
Training loss: 0.9353610873222351
Validation loss: 1.8032783897974158

Epoch: 260| Step: 0
Training loss: 0.9069916009902954
Validation loss: 1.8359369936809744

Epoch: 5| Step: 1
Training loss: 1.35599946975708
Validation loss: 1.8349464234485422

Epoch: 5| Step: 2
Training loss: 0.7632988095283508
Validation loss: 1.7962201872179586

Epoch: 5| Step: 3
Training loss: 0.9784559011459351
Validation loss: 1.7774649089382542

Epoch: 5| Step: 4
Training loss: 1.1883927583694458
Validation loss: 1.7293370795506302

Epoch: 5| Step: 5
Training loss: 1.1225860118865967
Validation loss: 1.7464480271903418

Epoch: 5| Step: 6
Training loss: 1.0629780292510986
Validation loss: 1.7458664871031238

Epoch: 5| Step: 7
Training loss: 1.4883817434310913
Validation loss: 1.7583838688429965

Epoch: 5| Step: 8
Training loss: 1.0573481321334839
Validation loss: 1.831229163754371

Epoch: 5| Step: 9
Training loss: 0.9154791831970215
Validation loss: 1.9165222516623877

Epoch: 5| Step: 10
Training loss: 0.746566891670227
Validation loss: 1.9257765200830275

Epoch: 261| Step: 0
Training loss: 1.4200141429901123
Validation loss: 1.8915099943837812

Epoch: 5| Step: 1
Training loss: 1.3913977146148682
Validation loss: 1.857498324045571

Epoch: 5| Step: 2
Training loss: 1.5069586038589478
Validation loss: 1.8011834993157336

Epoch: 5| Step: 3
Training loss: 1.154730200767517
Validation loss: 1.773420169789304

Epoch: 5| Step: 4
Training loss: 0.7779672145843506
Validation loss: 1.771506497936864

Epoch: 5| Step: 5
Training loss: 0.6238819360733032
Validation loss: 1.7337674299875896

Epoch: 5| Step: 6
Training loss: 1.2165977954864502
Validation loss: 1.741796507630297

Epoch: 5| Step: 7
Training loss: 0.5928928256034851
Validation loss: 1.7786448386407667

Epoch: 5| Step: 8
Training loss: 0.8548518419265747
Validation loss: 1.835573233583922

Epoch: 5| Step: 9
Training loss: 0.862749457359314
Validation loss: 1.8726347774587653

Epoch: 5| Step: 10
Training loss: 1.0922646522521973
Validation loss: 1.891469362602439

Epoch: 262| Step: 0
Training loss: 0.6165930032730103
Validation loss: 1.8417662548762497

Epoch: 5| Step: 1
Training loss: 0.44414886832237244
Validation loss: 1.8058193627224173

Epoch: 5| Step: 2
Training loss: 0.8267828822135925
Validation loss: 1.7364010964670489

Epoch: 5| Step: 3
Training loss: 0.9546548128128052
Validation loss: 1.729938257125116

Epoch: 5| Step: 4
Training loss: 1.101759672164917
Validation loss: 1.7283684592093191

Epoch: 5| Step: 5
Training loss: 1.2826683521270752
Validation loss: 1.7217814242967995

Epoch: 5| Step: 6
Training loss: 1.2202085256576538
Validation loss: 1.729065490025346

Epoch: 5| Step: 7
Training loss: 1.5935407876968384
Validation loss: 1.7717582307836062

Epoch: 5| Step: 8
Training loss: 1.4708621501922607
Validation loss: 1.8388336781532533

Epoch: 5| Step: 9
Training loss: 1.1177841424942017
Validation loss: 1.8778491302203106

Epoch: 5| Step: 10
Training loss: 0.5197123289108276
Validation loss: 1.9350656847799979

Epoch: 263| Step: 0
Training loss: 1.7573697566986084
Validation loss: 1.9699652476977276

Epoch: 5| Step: 1
Training loss: 1.0046303272247314
Validation loss: 1.8673317714404034

Epoch: 5| Step: 2
Training loss: 0.8089431524276733
Validation loss: 1.7959496718581005

Epoch: 5| Step: 3
Training loss: 1.4870052337646484
Validation loss: 1.7739130694379088

Epoch: 5| Step: 4
Training loss: 1.0500280857086182
Validation loss: 1.7505023120551981

Epoch: 5| Step: 5
Training loss: 1.0461353063583374
Validation loss: 1.763227496095883

Epoch: 5| Step: 6
Training loss: 0.9512300491333008
Validation loss: 1.7320401386548114

Epoch: 5| Step: 7
Training loss: 1.0849909782409668
Validation loss: 1.7288138494696668

Epoch: 5| Step: 8
Training loss: 0.9210525751113892
Validation loss: 1.74974528948466

Epoch: 5| Step: 9
Training loss: 0.5434788465499878
Validation loss: 1.7955527587603497

Epoch: 5| Step: 10
Training loss: 1.1420387029647827
Validation loss: 1.8852057200606152

Epoch: 264| Step: 0
Training loss: 1.4747135639190674
Validation loss: 1.943547861550444

Epoch: 5| Step: 1
Training loss: 1.1749088764190674
Validation loss: 1.907032738449753

Epoch: 5| Step: 2
Training loss: 1.363843321800232
Validation loss: 1.8651354069350867

Epoch: 5| Step: 3
Training loss: 1.4504673480987549
Validation loss: 1.800390931867784

Epoch: 5| Step: 4
Training loss: 0.9815686941146851
Validation loss: 1.756820232637467

Epoch: 5| Step: 5
Training loss: 0.9323298335075378
Validation loss: 1.7160123778927712

Epoch: 5| Step: 6
Training loss: 1.093030333518982
Validation loss: 1.7071907469021377

Epoch: 5| Step: 7
Training loss: 0.6978169679641724
Validation loss: 1.716785797508814

Epoch: 5| Step: 8
Training loss: 0.4733920097351074
Validation loss: 1.7371831914430023

Epoch: 5| Step: 9
Training loss: 1.0698907375335693
Validation loss: 1.7715346979838547

Epoch: 5| Step: 10
Training loss: 0.7768282294273376
Validation loss: 1.8079583080866004

Epoch: 265| Step: 0
Training loss: 1.494972586631775
Validation loss: 1.775971911286795

Epoch: 5| Step: 1
Training loss: 1.0598033666610718
Validation loss: 1.791264618596723

Epoch: 5| Step: 2
Training loss: 1.0978071689605713
Validation loss: 1.777532067350162

Epoch: 5| Step: 3
Training loss: 1.1951959133148193
Validation loss: 1.7702352205912273

Epoch: 5| Step: 4
Training loss: 0.9000422358512878
Validation loss: 1.8042713942066315

Epoch: 5| Step: 5
Training loss: 0.8228806257247925
Validation loss: 1.8138139914440852

Epoch: 5| Step: 6
Training loss: 1.300094485282898
Validation loss: 1.811230408248081

Epoch: 5| Step: 7
Training loss: 0.9089805483818054
Validation loss: 1.798020879427592

Epoch: 5| Step: 8
Training loss: 0.8532800674438477
Validation loss: 1.8057954208825224

Epoch: 5| Step: 9
Training loss: 0.9313990473747253
Validation loss: 1.786509644600653

Epoch: 5| Step: 10
Training loss: 0.6305700540542603
Validation loss: 1.7758970465711368

Epoch: 266| Step: 0
Training loss: 1.1180989742279053
Validation loss: 1.7575723266088834

Epoch: 5| Step: 1
Training loss: 1.0378243923187256
Validation loss: 1.7545093708140875

Epoch: 5| Step: 2
Training loss: 0.7538420557975769
Validation loss: 1.7310979827757804

Epoch: 5| Step: 3
Training loss: 0.7285600900650024
Validation loss: 1.738220428907743

Epoch: 5| Step: 4
Training loss: 1.3264641761779785
Validation loss: 1.764703199427615

Epoch: 5| Step: 5
Training loss: 0.7473868131637573
Validation loss: 1.7665257274463613

Epoch: 5| Step: 6
Training loss: 0.9115837216377258
Validation loss: 1.7830568154652913

Epoch: 5| Step: 7
Training loss: 0.9949096441268921
Validation loss: 1.8022232017209452

Epoch: 5| Step: 8
Training loss: 1.5753896236419678
Validation loss: 1.8159636720534293

Epoch: 5| Step: 9
Training loss: 0.9541300535202026
Validation loss: 1.8193700082840458

Epoch: 5| Step: 10
Training loss: 0.855559766292572
Validation loss: 1.8326016062049455

Epoch: 267| Step: 0
Training loss: 1.1037981510162354
Validation loss: 1.8049578769232637

Epoch: 5| Step: 1
Training loss: 1.097458004951477
Validation loss: 1.80795088378332

Epoch: 5| Step: 2
Training loss: 1.0269229412078857
Validation loss: 1.8070635359774354

Epoch: 5| Step: 3
Training loss: 1.4473621845245361
Validation loss: 1.825064686036879

Epoch: 5| Step: 4
Training loss: 0.7209258079528809
Validation loss: 1.7957984401333718

Epoch: 5| Step: 5
Training loss: 1.0984164476394653
Validation loss: 1.7586957177808207

Epoch: 5| Step: 6
Training loss: 0.7147395014762878
Validation loss: 1.7058814341022122

Epoch: 5| Step: 7
Training loss: 1.4245314598083496
Validation loss: 1.7063893746304255

Epoch: 5| Step: 8
Training loss: 0.9519211053848267
Validation loss: 1.6975573801225232

Epoch: 5| Step: 9
Training loss: 0.8207892179489136
Validation loss: 1.720172732107101

Epoch: 5| Step: 10
Training loss: 0.586995542049408
Validation loss: 1.7201368347291024

Epoch: 268| Step: 0
Training loss: 0.930693507194519
Validation loss: 1.7425264017556303

Epoch: 5| Step: 1
Training loss: 0.9818404912948608
Validation loss: 1.777434092695995

Epoch: 5| Step: 2
Training loss: 1.5260010957717896
Validation loss: 1.8234363089325607

Epoch: 5| Step: 3
Training loss: 1.125136375427246
Validation loss: 1.787386586589198

Epoch: 5| Step: 4
Training loss: 0.8402559161186218
Validation loss: 1.7740852166247625

Epoch: 5| Step: 5
Training loss: 0.8020223379135132
Validation loss: 1.7619400383323751

Epoch: 5| Step: 6
Training loss: 0.8202263712882996
Validation loss: 1.7490844380471013

Epoch: 5| Step: 7
Training loss: 1.1451069116592407
Validation loss: 1.742215512901224

Epoch: 5| Step: 8
Training loss: 1.2000631093978882
Validation loss: 1.7596884709532543

Epoch: 5| Step: 9
Training loss: 0.7626992464065552
Validation loss: 1.7348550981090916

Epoch: 5| Step: 10
Training loss: 0.6702268123626709
Validation loss: 1.7241670470083914

Epoch: 269| Step: 0
Training loss: 0.9743314981460571
Validation loss: 1.732563276444712

Epoch: 5| Step: 1
Training loss: 1.1625754833221436
Validation loss: 1.7199819677619523

Epoch: 5| Step: 2
Training loss: 1.1931583881378174
Validation loss: 1.7429879250064972

Epoch: 5| Step: 3
Training loss: 1.1199276447296143
Validation loss: 1.7929403269162743

Epoch: 5| Step: 4
Training loss: 1.1881530284881592
Validation loss: 1.8001515583325458

Epoch: 5| Step: 5
Training loss: 0.5678192377090454
Validation loss: 1.8356248870972665

Epoch: 5| Step: 6
Training loss: 0.5309323072433472
Validation loss: 1.8224448388622654

Epoch: 5| Step: 7
Training loss: 1.122917652130127
Validation loss: 1.778064348364389

Epoch: 5| Step: 8
Training loss: 0.8145679235458374
Validation loss: 1.7584019040548673

Epoch: 5| Step: 9
Training loss: 1.1602299213409424
Validation loss: 1.7344341201166953

Epoch: 5| Step: 10
Training loss: 0.7072452306747437
Validation loss: 1.7513921363379366

Epoch: 270| Step: 0
Training loss: 1.1788438558578491
Validation loss: 1.7620413149556806

Epoch: 5| Step: 1
Training loss: 0.7882213592529297
Validation loss: 1.7646196298701788

Epoch: 5| Step: 2
Training loss: 1.1641738414764404
Validation loss: 1.7827817983524774

Epoch: 5| Step: 3
Training loss: 0.5582855939865112
Validation loss: 1.8308711308304981

Epoch: 5| Step: 4
Training loss: 0.6079244017601013
Validation loss: 1.8509120018251481

Epoch: 5| Step: 5
Training loss: 1.0560952425003052
Validation loss: 1.8531442124356505

Epoch: 5| Step: 6
Training loss: 1.1122080087661743
Validation loss: 1.837100141791887

Epoch: 5| Step: 7
Training loss: 1.0616945028305054
Validation loss: 1.7872873096055881

Epoch: 5| Step: 8
Training loss: 1.1741306781768799
Validation loss: 1.7544621959809334

Epoch: 5| Step: 9
Training loss: 0.7576741576194763
Validation loss: 1.7430599556174329

Epoch: 5| Step: 10
Training loss: 1.4563071727752686
Validation loss: 1.6965088677662674

Epoch: 271| Step: 0
Training loss: 0.996656060218811
Validation loss: 1.6889311395665652

Epoch: 5| Step: 1
Training loss: 1.8169037103652954
Validation loss: 1.7103078865235852

Epoch: 5| Step: 2
Training loss: 1.0995289087295532
Validation loss: 1.7286063765966764

Epoch: 5| Step: 3
Training loss: 0.5703741312026978
Validation loss: 1.7326771328526158

Epoch: 5| Step: 4
Training loss: 1.080331802368164
Validation loss: 1.776363206166093

Epoch: 5| Step: 5
Training loss: 0.6455105543136597
Validation loss: 1.7828972557539582

Epoch: 5| Step: 6
Training loss: 1.0308786630630493
Validation loss: 1.7997050977522326

Epoch: 5| Step: 7
Training loss: 1.2844188213348389
Validation loss: 1.7932537909476989

Epoch: 5| Step: 8
Training loss: 0.804669201374054
Validation loss: 1.8351732402719476

Epoch: 5| Step: 9
Training loss: 0.4330398440361023
Validation loss: 1.8115222530980264

Epoch: 5| Step: 10
Training loss: 0.8108938932418823
Validation loss: 1.7682877535461097

Epoch: 272| Step: 0
Training loss: 0.9107666015625
Validation loss: 1.7581286507268106

Epoch: 5| Step: 1
Training loss: 0.9112092852592468
Validation loss: 1.720664930599992

Epoch: 5| Step: 2
Training loss: 1.192681074142456
Validation loss: 1.7243121400956185

Epoch: 5| Step: 3
Training loss: 1.0649983882904053
Validation loss: 1.7344961961110432

Epoch: 5| Step: 4
Training loss: 1.0781080722808838
Validation loss: 1.718655796461208

Epoch: 5| Step: 5
Training loss: 0.5839473605155945
Validation loss: 1.7011066034276

Epoch: 5| Step: 6
Training loss: 0.9054841995239258
Validation loss: 1.7448217022803523

Epoch: 5| Step: 7
Training loss: 1.3285424709320068
Validation loss: 1.776232921948997

Epoch: 5| Step: 8
Training loss: 0.8703494071960449
Validation loss: 1.778393712095035

Epoch: 5| Step: 9
Training loss: 1.0748223066329956
Validation loss: 1.8160011704250048

Epoch: 5| Step: 10
Training loss: 0.8497966527938843
Validation loss: 1.8623919422908495

Epoch: 273| Step: 0
Training loss: 0.8983039855957031
Validation loss: 1.8427605257239392

Epoch: 5| Step: 1
Training loss: 1.0911970138549805
Validation loss: 1.8994515211351457

Epoch: 5| Step: 2
Training loss: 0.9217093586921692
Validation loss: 1.823444377991461

Epoch: 5| Step: 3
Training loss: 1.019470453262329
Validation loss: 1.7760469964755479

Epoch: 5| Step: 4
Training loss: 1.1299299001693726
Validation loss: 1.7327158592080558

Epoch: 5| Step: 5
Training loss: 0.8428508639335632
Validation loss: 1.7287958770669916

Epoch: 5| Step: 6
Training loss: 1.1830089092254639
Validation loss: 1.7338932124517297

Epoch: 5| Step: 7
Training loss: 0.7651340365409851
Validation loss: 1.7466135294206682

Epoch: 5| Step: 8
Training loss: 1.057098388671875
Validation loss: 1.7351014485923193

Epoch: 5| Step: 9
Training loss: 0.7755235433578491
Validation loss: 1.7751490505792762

Epoch: 5| Step: 10
Training loss: 0.9835817813873291
Validation loss: 1.7707990433580132

Epoch: 274| Step: 0
Training loss: 1.0060726404190063
Validation loss: 1.7517216615779425

Epoch: 5| Step: 1
Training loss: 0.4039694666862488
Validation loss: 1.7512239781759118

Epoch: 5| Step: 2
Training loss: 1.2185852527618408
Validation loss: 1.7456919057394868

Epoch: 5| Step: 3
Training loss: 0.7105718851089478
Validation loss: 1.7475530921771962

Epoch: 5| Step: 4
Training loss: 0.6903649568557739
Validation loss: 1.749068228147363

Epoch: 5| Step: 5
Training loss: 0.76031494140625
Validation loss: 1.747478892726283

Epoch: 5| Step: 6
Training loss: 1.7943861484527588
Validation loss: 1.815168406373711

Epoch: 5| Step: 7
Training loss: 0.7423087358474731
Validation loss: 1.8100487045062486

Epoch: 5| Step: 8
Training loss: 1.0459972620010376
Validation loss: 1.8598330892542356

Epoch: 5| Step: 9
Training loss: 0.7452861070632935
Validation loss: 1.848518802273658

Epoch: 5| Step: 10
Training loss: 1.3744310140609741
Validation loss: 1.8505792784434494

Epoch: 275| Step: 0
Training loss: 0.7395985722541809
Validation loss: 1.7944401592336676

Epoch: 5| Step: 1
Training loss: 1.1505943536758423
Validation loss: 1.7575425922229726

Epoch: 5| Step: 2
Training loss: 1.0911281108856201
Validation loss: 1.7549134659510788

Epoch: 5| Step: 3
Training loss: 1.3692142963409424
Validation loss: 1.7367986197112708

Epoch: 5| Step: 4
Training loss: 0.9111676216125488
Validation loss: 1.7433268703440183

Epoch: 5| Step: 5
Training loss: 0.8894616365432739
Validation loss: 1.7966157928589852

Epoch: 5| Step: 6
Training loss: 0.9368329048156738
Validation loss: 1.8243223710726666

Epoch: 5| Step: 7
Training loss: 1.2875995635986328
Validation loss: 1.8298788724407073

Epoch: 5| Step: 8
Training loss: 0.5981000065803528
Validation loss: 1.833669004901763

Epoch: 5| Step: 9
Training loss: 0.954546332359314
Validation loss: 1.7976564771385604

Epoch: 5| Step: 10
Training loss: 0.6092414259910583
Validation loss: 1.7589709117848387

Epoch: 276| Step: 0
Training loss: 0.826996922492981
Validation loss: 1.7146133684342908

Epoch: 5| Step: 1
Training loss: 0.8941748738288879
Validation loss: 1.6949175955146871

Epoch: 5| Step: 2
Training loss: 0.8555801510810852
Validation loss: 1.6969560141204505

Epoch: 5| Step: 3
Training loss: 1.390391230583191
Validation loss: 1.685116792237887

Epoch: 5| Step: 4
Training loss: 0.7631179094314575
Validation loss: 1.7009290713135914

Epoch: 5| Step: 5
Training loss: 0.7240902781486511
Validation loss: 1.7194293365683606

Epoch: 5| Step: 6
Training loss: 1.2998290061950684
Validation loss: 1.7391346539220502

Epoch: 5| Step: 7
Training loss: 0.7253949046134949
Validation loss: 1.7472841919109385

Epoch: 5| Step: 8
Training loss: 1.1916873455047607
Validation loss: 1.7467793597969958

Epoch: 5| Step: 9
Training loss: 0.7048881649971008
Validation loss: 1.7483871342033468

Epoch: 5| Step: 10
Training loss: 0.9644923210144043
Validation loss: 1.7681107033965409

Epoch: 277| Step: 0
Training loss: 1.0659302473068237
Validation loss: 1.82396629933388

Epoch: 5| Step: 1
Training loss: 0.9311541318893433
Validation loss: 1.8059006942215787

Epoch: 5| Step: 2
Training loss: 1.1138055324554443
Validation loss: 1.7986226325394006

Epoch: 5| Step: 3
Training loss: 0.8958300352096558
Validation loss: 1.7891198012136644

Epoch: 5| Step: 4
Training loss: 1.0649144649505615
Validation loss: 1.7689467309623637

Epoch: 5| Step: 5
Training loss: 1.0139422416687012
Validation loss: 1.7562618345342658

Epoch: 5| Step: 6
Training loss: 1.0639499425888062
Validation loss: 1.791525867677504

Epoch: 5| Step: 7
Training loss: 0.35392218828201294
Validation loss: 1.7705985628148562

Epoch: 5| Step: 8
Training loss: 0.7192683219909668
Validation loss: 1.7640493441653509

Epoch: 5| Step: 9
Training loss: 0.7655695676803589
Validation loss: 1.7774555952318254

Epoch: 5| Step: 10
Training loss: 0.9576196074485779
Validation loss: 1.763965565671203

Epoch: 278| Step: 0
Training loss: 0.5387987494468689
Validation loss: 1.7897388781270673

Epoch: 5| Step: 1
Training loss: 0.9464603662490845
Validation loss: 1.7489059625133392

Epoch: 5| Step: 2
Training loss: 0.9365440607070923
Validation loss: 1.7178167130357476

Epoch: 5| Step: 3
Training loss: 0.9477804899215698
Validation loss: 1.724047577509316

Epoch: 5| Step: 4
Training loss: 0.9310911297798157
Validation loss: 1.719518966572259

Epoch: 5| Step: 5
Training loss: 0.9909566044807434
Validation loss: 1.7717393367521224

Epoch: 5| Step: 6
Training loss: 1.0791208744049072
Validation loss: 1.7660229090721375

Epoch: 5| Step: 7
Training loss: 0.8938258290290833
Validation loss: 1.8215818123150898

Epoch: 5| Step: 8
Training loss: 0.8511913418769836
Validation loss: 1.8079184896202498

Epoch: 5| Step: 9
Training loss: 0.9137094616889954
Validation loss: 1.781972764640726

Epoch: 5| Step: 10
Training loss: 1.1419074535369873
Validation loss: 1.7484242775106942

Epoch: 279| Step: 0
Training loss: 0.837569534778595
Validation loss: 1.7107346416801534

Epoch: 5| Step: 1
Training loss: 1.251416563987732
Validation loss: 1.6706849939079695

Epoch: 5| Step: 2
Training loss: 0.6876259446144104
Validation loss: 1.707888077664119

Epoch: 5| Step: 3
Training loss: 1.3326727151870728
Validation loss: 1.672148778874387

Epoch: 5| Step: 4
Training loss: 0.9443565607070923
Validation loss: 1.7050925550922271

Epoch: 5| Step: 5
Training loss: 1.1714327335357666
Validation loss: 1.7276847593245968

Epoch: 5| Step: 6
Training loss: 0.9428712725639343
Validation loss: 1.7624668946830175

Epoch: 5| Step: 7
Training loss: 0.6283934116363525
Validation loss: 1.7848036968579857

Epoch: 5| Step: 8
Training loss: 0.8436039686203003
Validation loss: 1.7588684251231532

Epoch: 5| Step: 9
Training loss: 0.770175039768219
Validation loss: 1.7624359182132188

Epoch: 5| Step: 10
Training loss: 0.7669012546539307
Validation loss: 1.7788852671141266

Epoch: 280| Step: 0
Training loss: 1.3314266204833984
Validation loss: 1.7519874893208986

Epoch: 5| Step: 1
Training loss: 0.7418451309204102
Validation loss: 1.7828611840483963

Epoch: 5| Step: 2
Training loss: 0.7903686165809631
Validation loss: 1.7488147533068092

Epoch: 5| Step: 3
Training loss: 0.8005844354629517
Validation loss: 1.781176947778271

Epoch: 5| Step: 4
Training loss: 0.7460706233978271
Validation loss: 1.8163188067815637

Epoch: 5| Step: 5
Training loss: 0.9935470819473267
Validation loss: 1.825912207685491

Epoch: 5| Step: 6
Training loss: 0.6952741146087646
Validation loss: 1.8310085919595533

Epoch: 5| Step: 7
Training loss: 1.0892665386199951
Validation loss: 1.8318196009564143

Epoch: 5| Step: 8
Training loss: 1.1082723140716553
Validation loss: 1.8388466886294785

Epoch: 5| Step: 9
Training loss: 0.7506310939788818
Validation loss: 1.826770794007086

Epoch: 5| Step: 10
Training loss: 1.0012071132659912
Validation loss: 1.7381966742136146

Epoch: 281| Step: 0
Training loss: 1.1196309328079224
Validation loss: 1.7302204793499363

Epoch: 5| Step: 1
Training loss: 0.9617651104927063
Validation loss: 1.673130613501354

Epoch: 5| Step: 2
Training loss: 0.9400237798690796
Validation loss: 1.6782550837403984

Epoch: 5| Step: 3
Training loss: 0.8838080167770386
Validation loss: 1.6787408026315833

Epoch: 5| Step: 4
Training loss: 1.072636365890503
Validation loss: 1.6688156909840082

Epoch: 5| Step: 5
Training loss: 1.0467456579208374
Validation loss: 1.714814070732363

Epoch: 5| Step: 6
Training loss: 1.0538160800933838
Validation loss: 1.759920871385964

Epoch: 5| Step: 7
Training loss: 0.5355566143989563
Validation loss: 1.7907620155683128

Epoch: 5| Step: 8
Training loss: 0.673675000667572
Validation loss: 1.8411553585401146

Epoch: 5| Step: 9
Training loss: 0.9463189244270325
Validation loss: 1.8213138452140234

Epoch: 5| Step: 10
Training loss: 0.8918961882591248
Validation loss: 1.8357059468505204

Epoch: 282| Step: 0
Training loss: 1.1041183471679688
Validation loss: 1.8166486268402429

Epoch: 5| Step: 1
Training loss: 0.4869542717933655
Validation loss: 1.7728688729706632

Epoch: 5| Step: 2
Training loss: 1.2732185125350952
Validation loss: 1.7396488663970784

Epoch: 5| Step: 3
Training loss: 0.9662092328071594
Validation loss: 1.696808667593105

Epoch: 5| Step: 4
Training loss: 0.626721203327179
Validation loss: 1.6947943036274244

Epoch: 5| Step: 5
Training loss: 0.8250828981399536
Validation loss: 1.696776984840311

Epoch: 5| Step: 6
Training loss: 0.8461475372314453
Validation loss: 1.7103996917765627

Epoch: 5| Step: 7
Training loss: 0.6974620819091797
Validation loss: 1.7560740170940277

Epoch: 5| Step: 8
Training loss: 0.7156505584716797
Validation loss: 1.799087001431373

Epoch: 5| Step: 9
Training loss: 1.105769395828247
Validation loss: 1.852655755576267

Epoch: 5| Step: 10
Training loss: 1.3149958848953247
Validation loss: 1.8354901575273084

Epoch: 283| Step: 0
Training loss: 0.981694221496582
Validation loss: 1.8151415560835151

Epoch: 5| Step: 1
Training loss: 0.6044318675994873
Validation loss: 1.795189074290696

Epoch: 5| Step: 2
Training loss: 1.4721190929412842
Validation loss: 1.7730972343875515

Epoch: 5| Step: 3
Training loss: 0.4933745861053467
Validation loss: 1.7353659176057386

Epoch: 5| Step: 4
Training loss: 1.0468391180038452
Validation loss: 1.7065386387609667

Epoch: 5| Step: 5
Training loss: 0.929532527923584
Validation loss: 1.70199187596639

Epoch: 5| Step: 6
Training loss: 1.0355494022369385
Validation loss: 1.6952680182713333

Epoch: 5| Step: 7
Training loss: 0.6447415947914124
Validation loss: 1.6642984305658648

Epoch: 5| Step: 8
Training loss: 0.7833825349807739
Validation loss: 1.6934572522358229

Epoch: 5| Step: 9
Training loss: 0.8502553701400757
Validation loss: 1.713719210317058

Epoch: 5| Step: 10
Training loss: 0.7979719042778015
Validation loss: 1.6990425932791926

Epoch: 284| Step: 0
Training loss: 0.8940168619155884
Validation loss: 1.7258886855135682

Epoch: 5| Step: 1
Training loss: 0.9550851583480835
Validation loss: 1.736952894477434

Epoch: 5| Step: 2
Training loss: 0.6602461934089661
Validation loss: 1.725663500447427

Epoch: 5| Step: 3
Training loss: 0.9470806121826172
Validation loss: 1.7212256923798592

Epoch: 5| Step: 4
Training loss: 0.9935854077339172
Validation loss: 1.7232794146383963

Epoch: 5| Step: 5
Training loss: 0.8210667371749878
Validation loss: 1.7312131158767208

Epoch: 5| Step: 6
Training loss: 0.6723764538764954
Validation loss: 1.7449676272689656

Epoch: 5| Step: 7
Training loss: 0.6026821136474609
Validation loss: 1.699023892802577

Epoch: 5| Step: 8
Training loss: 0.8485622406005859
Validation loss: 1.6765070474275978

Epoch: 5| Step: 9
Training loss: 1.426346778869629
Validation loss: 1.6905182702566988

Epoch: 5| Step: 10
Training loss: 0.7878077030181885
Validation loss: 1.7192616860071819

Epoch: 285| Step: 0
Training loss: 1.0856908559799194
Validation loss: 1.7432521209921887

Epoch: 5| Step: 1
Training loss: 1.0973427295684814
Validation loss: 1.7930934826533

Epoch: 5| Step: 2
Training loss: 0.7463447451591492
Validation loss: 1.8035351486616238

Epoch: 5| Step: 3
Training loss: 0.8103559613227844
Validation loss: 1.8502753421824465

Epoch: 5| Step: 4
Training loss: 0.8762861490249634
Validation loss: 1.8679620117269538

Epoch: 5| Step: 5
Training loss: 0.8974277377128601
Validation loss: 1.8395493645821848

Epoch: 5| Step: 6
Training loss: 1.013741135597229
Validation loss: 1.8148986754878875

Epoch: 5| Step: 7
Training loss: 0.7348273992538452
Validation loss: 1.7436804643241308

Epoch: 5| Step: 8
Training loss: 1.096097707748413
Validation loss: 1.6768885145905197

Epoch: 5| Step: 9
Training loss: 0.5614689588546753
Validation loss: 1.6836708591830345

Epoch: 5| Step: 10
Training loss: 0.7174326777458191
Validation loss: 1.65419848503605

Epoch: 286| Step: 0
Training loss: 0.5459933280944824
Validation loss: 1.6567937930425007

Epoch: 5| Step: 1
Training loss: 0.7518380284309387
Validation loss: 1.6337982749426236

Epoch: 5| Step: 2
Training loss: 0.682874321937561
Validation loss: 1.6726783334567983

Epoch: 5| Step: 3
Training loss: 0.9346952438354492
Validation loss: 1.6941585386953046

Epoch: 5| Step: 4
Training loss: 1.1486817598342896
Validation loss: 1.6915987922299294

Epoch: 5| Step: 5
Training loss: 0.9009628295898438
Validation loss: 1.7345805527061544

Epoch: 5| Step: 6
Training loss: 1.1921159029006958
Validation loss: 1.7411732724917832

Epoch: 5| Step: 7
Training loss: 0.6932333111763
Validation loss: 1.7394914351483828

Epoch: 5| Step: 8
Training loss: 1.0494581460952759
Validation loss: 1.7352274284567883

Epoch: 5| Step: 9
Training loss: 0.9765531420707703
Validation loss: 1.7284070496918054

Epoch: 5| Step: 10
Training loss: 0.6643474102020264
Validation loss: 1.7462054798679967

Epoch: 287| Step: 0
Training loss: 0.34780073165893555
Validation loss: 1.740689722440576

Epoch: 5| Step: 1
Training loss: 0.7493683099746704
Validation loss: 1.7618215994168354

Epoch: 5| Step: 2
Training loss: 0.7355972528457642
Validation loss: 1.7406924501542123

Epoch: 5| Step: 3
Training loss: 1.304310917854309
Validation loss: 1.7601022451154646

Epoch: 5| Step: 4
Training loss: 0.8248387575149536
Validation loss: 1.7336637243147819

Epoch: 5| Step: 5
Training loss: 0.6917592287063599
Validation loss: 1.7446390749305807

Epoch: 5| Step: 6
Training loss: 0.559695303440094
Validation loss: 1.751657534671086

Epoch: 5| Step: 7
Training loss: 0.8590953946113586
Validation loss: 1.7402257957766134

Epoch: 5| Step: 8
Training loss: 0.9778308868408203
Validation loss: 1.7171516110820155

Epoch: 5| Step: 9
Training loss: 1.096229910850525
Validation loss: 1.7029167682893815

Epoch: 5| Step: 10
Training loss: 1.163421869277954
Validation loss: 1.6816501181612733

Epoch: 288| Step: 0
Training loss: 0.7614431381225586
Validation loss: 1.6783305214297386

Epoch: 5| Step: 1
Training loss: 0.9004896283149719
Validation loss: 1.6742833968131774

Epoch: 5| Step: 2
Training loss: 1.1428829431533813
Validation loss: 1.6176465172921457

Epoch: 5| Step: 3
Training loss: 0.6681815385818481
Validation loss: 1.6200270460497948

Epoch: 5| Step: 4
Training loss: 1.0337169170379639
Validation loss: 1.645706469012845

Epoch: 5| Step: 5
Training loss: 0.29649490118026733
Validation loss: 1.701893921821348

Epoch: 5| Step: 6
Training loss: 1.1900044679641724
Validation loss: 1.7057912054882254

Epoch: 5| Step: 7
Training loss: 1.1916135549545288
Validation loss: 1.7108345826466878

Epoch: 5| Step: 8
Training loss: 0.7579754590988159
Validation loss: 1.7288095951080322

Epoch: 5| Step: 9
Training loss: 0.8000506162643433
Validation loss: 1.7309322767360236

Epoch: 5| Step: 10
Training loss: 0.6580778956413269
Validation loss: 1.7330749265609249

Epoch: 289| Step: 0
Training loss: 0.8106067776679993
Validation loss: 1.7141965909670758

Epoch: 5| Step: 1
Training loss: 0.7401506900787354
Validation loss: 1.6882275753123785

Epoch: 5| Step: 2
Training loss: 0.6588139533996582
Validation loss: 1.6685941270602647

Epoch: 5| Step: 3
Training loss: 1.0165252685546875
Validation loss: 1.6826344074741486

Epoch: 5| Step: 4
Training loss: 0.7470722794532776
Validation loss: 1.6495591645599694

Epoch: 5| Step: 5
Training loss: 0.734366238117218
Validation loss: 1.654057877038115

Epoch: 5| Step: 6
Training loss: 1.0009034872055054
Validation loss: 1.6683464563021095

Epoch: 5| Step: 7
Training loss: 0.6829001903533936
Validation loss: 1.6997388165484193

Epoch: 5| Step: 8
Training loss: 1.1526696681976318
Validation loss: 1.6974783084725822

Epoch: 5| Step: 9
Training loss: 0.9403999447822571
Validation loss: 1.7613607465579946

Epoch: 5| Step: 10
Training loss: 0.5985351800918579
Validation loss: 1.7821190049571376

Epoch: 290| Step: 0
Training loss: 1.0046201944351196
Validation loss: 1.8084366219018095

Epoch: 5| Step: 1
Training loss: 1.0865064859390259
Validation loss: 1.723651550149405

Epoch: 5| Step: 2
Training loss: 0.48964715003967285
Validation loss: 1.71344163597271

Epoch: 5| Step: 3
Training loss: 0.7527223229408264
Validation loss: 1.699042409978887

Epoch: 5| Step: 4
Training loss: 0.8677385449409485
Validation loss: 1.6803337835496472

Epoch: 5| Step: 5
Training loss: 1.0737316608428955
Validation loss: 1.6822158828858407

Epoch: 5| Step: 6
Training loss: 1.0560144186019897
Validation loss: 1.6475001304380354

Epoch: 5| Step: 7
Training loss: 0.44322317838668823
Validation loss: 1.6455824125197627

Epoch: 5| Step: 8
Training loss: 0.8826525807380676
Validation loss: 1.656151463908534

Epoch: 5| Step: 9
Training loss: 0.9253751039505005
Validation loss: 1.6703080515707693

Epoch: 5| Step: 10
Training loss: 0.47400468587875366
Validation loss: 1.713706963805742

Epoch: 291| Step: 0
Training loss: 1.0310304164886475
Validation loss: 1.7770788067130632

Epoch: 5| Step: 1
Training loss: 0.9349150657653809
Validation loss: 1.7812265734518729

Epoch: 5| Step: 2
Training loss: 0.8720188140869141
Validation loss: 1.7787754689493487

Epoch: 5| Step: 3
Training loss: 1.044033408164978
Validation loss: 1.7560044488599222

Epoch: 5| Step: 4
Training loss: 0.765468418598175
Validation loss: 1.7134755862656461

Epoch: 5| Step: 5
Training loss: 0.7449597120285034
Validation loss: 1.7061000357392013

Epoch: 5| Step: 6
Training loss: 0.7746951580047607
Validation loss: 1.7158408728978967

Epoch: 5| Step: 7
Training loss: 0.5450888872146606
Validation loss: 1.7046633894725511

Epoch: 5| Step: 8
Training loss: 1.0124999284744263
Validation loss: 1.6853888598821496

Epoch: 5| Step: 9
Training loss: 0.746186375617981
Validation loss: 1.7067504903321624

Epoch: 5| Step: 10
Training loss: 0.7788844704627991
Validation loss: 1.7218318370080763

Epoch: 292| Step: 0
Training loss: 0.6453288793563843
Validation loss: 1.7602298849372453

Epoch: 5| Step: 1
Training loss: 0.6858018040657043
Validation loss: 1.7783661785946097

Epoch: 5| Step: 2
Training loss: 1.156075358390808
Validation loss: 1.759260428849087

Epoch: 5| Step: 3
Training loss: 0.7344141006469727
Validation loss: 1.794835109864512

Epoch: 5| Step: 4
Training loss: 0.6769540309906006
Validation loss: 1.7766375567323418

Epoch: 5| Step: 5
Training loss: 0.8503502607345581
Validation loss: 1.7506873787090342

Epoch: 5| Step: 6
Training loss: 0.9434175491333008
Validation loss: 1.6978020373211111

Epoch: 5| Step: 7
Training loss: 0.8187251091003418
Validation loss: 1.6760879165382796

Epoch: 5| Step: 8
Training loss: 0.7866342663764954
Validation loss: 1.6830234104587185

Epoch: 5| Step: 9
Training loss: 0.9436612129211426
Validation loss: 1.7210806377472416

Epoch: 5| Step: 10
Training loss: 0.6333910822868347
Validation loss: 1.7081973732158702

Epoch: 293| Step: 0
Training loss: 0.7822939157485962
Validation loss: 1.7077613312710997

Epoch: 5| Step: 1
Training loss: 1.1271427869796753
Validation loss: 1.7308235091547812

Epoch: 5| Step: 2
Training loss: 0.8047049641609192
Validation loss: 1.7504787342522734

Epoch: 5| Step: 3
Training loss: 0.6694864630699158
Validation loss: 1.7597418151875979

Epoch: 5| Step: 4
Training loss: 0.9856351613998413
Validation loss: 1.7225361780453754

Epoch: 5| Step: 5
Training loss: 1.2887823581695557
Validation loss: 1.707058665572956

Epoch: 5| Step: 6
Training loss: 0.4064280390739441
Validation loss: 1.6938323564426874

Epoch: 5| Step: 7
Training loss: 0.37819379568099976
Validation loss: 1.7147413223020491

Epoch: 5| Step: 8
Training loss: 0.7439104914665222
Validation loss: 1.715291682110038

Epoch: 5| Step: 9
Training loss: 0.9244288206100464
Validation loss: 1.7330892662848196

Epoch: 5| Step: 10
Training loss: 0.5503036379814148
Validation loss: 1.7551247996668662

Epoch: 294| Step: 0
Training loss: 0.9937525987625122
Validation loss: 1.7648461147021222

Epoch: 5| Step: 1
Training loss: 0.8207271695137024
Validation loss: 1.7353513022904754

Epoch: 5| Step: 2
Training loss: 0.867989182472229
Validation loss: 1.7324375696079706

Epoch: 5| Step: 3
Training loss: 0.7190996408462524
Validation loss: 1.6788249143990137

Epoch: 5| Step: 4
Training loss: 0.8180831670761108
Validation loss: 1.691714943096202

Epoch: 5| Step: 5
Training loss: 0.4607210159301758
Validation loss: 1.7032263202051963

Epoch: 5| Step: 6
Training loss: 0.7625496983528137
Validation loss: 1.741880424561039

Epoch: 5| Step: 7
Training loss: 0.5305473208427429
Validation loss: 1.7519131463061097

Epoch: 5| Step: 8
Training loss: 1.279652714729309
Validation loss: 1.7441317830034482

Epoch: 5| Step: 9
Training loss: 0.7951534986495972
Validation loss: 1.704249898592631

Epoch: 5| Step: 10
Training loss: 0.808487594127655
Validation loss: 1.6972837371210898

Epoch: 295| Step: 0
Training loss: 1.0848783254623413
Validation loss: 1.7016612804064186

Epoch: 5| Step: 1
Training loss: 0.8983647227287292
Validation loss: 1.7108048815881052

Epoch: 5| Step: 2
Training loss: 0.8535745739936829
Validation loss: 1.7234528603092316

Epoch: 5| Step: 3
Training loss: 0.5035829544067383
Validation loss: 1.7368701017031105

Epoch: 5| Step: 4
Training loss: 0.6741407513618469
Validation loss: 1.7343882001856321

Epoch: 5| Step: 5
Training loss: 0.8015695810317993
Validation loss: 1.7861608792376775

Epoch: 5| Step: 6
Training loss: 0.6931582689285278
Validation loss: 1.767648180325826

Epoch: 5| Step: 7
Training loss: 0.8636407852172852
Validation loss: 1.7437925236199492

Epoch: 5| Step: 8
Training loss: 1.2440364360809326
Validation loss: 1.7253114664426414

Epoch: 5| Step: 9
Training loss: 0.3788197636604309
Validation loss: 1.7011998571375364

Epoch: 5| Step: 10
Training loss: 0.573631763458252
Validation loss: 1.6874453124179636

Epoch: 296| Step: 0
Training loss: 0.768262505531311
Validation loss: 1.6878354241771083

Epoch: 5| Step: 1
Training loss: 0.5950417518615723
Validation loss: 1.6963333070919078

Epoch: 5| Step: 2
Training loss: 0.5250356793403625
Validation loss: 1.744688662149573

Epoch: 5| Step: 3
Training loss: 1.1814165115356445
Validation loss: 1.7481531917407949

Epoch: 5| Step: 4
Training loss: 0.7151943445205688
Validation loss: 1.7734622096502652

Epoch: 5| Step: 5
Training loss: 0.958622932434082
Validation loss: 1.741658369700114

Epoch: 5| Step: 6
Training loss: 0.6436972618103027
Validation loss: 1.705836437081778

Epoch: 5| Step: 7
Training loss: 0.7864952087402344
Validation loss: 1.6953163634064377

Epoch: 5| Step: 8
Training loss: 0.9407880902290344
Validation loss: 1.6732587942513086

Epoch: 5| Step: 9
Training loss: 0.6671360731124878
Validation loss: 1.6768448327177314

Epoch: 5| Step: 10
Training loss: 0.702240526676178
Validation loss: 1.6562199169589626

Epoch: 297| Step: 0
Training loss: 1.2734333276748657
Validation loss: 1.656080106253265

Epoch: 5| Step: 1
Training loss: 0.6278442144393921
Validation loss: 1.6819862152940483

Epoch: 5| Step: 2
Training loss: 0.5421518683433533
Validation loss: 1.6781767914372105

Epoch: 5| Step: 3
Training loss: 0.6371068358421326
Validation loss: 1.6587318938265565

Epoch: 5| Step: 4
Training loss: 0.6276897192001343
Validation loss: 1.7311174766991728

Epoch: 5| Step: 5
Training loss: 0.9720617532730103
Validation loss: 1.702786014926049

Epoch: 5| Step: 6
Training loss: 0.6559116244316101
Validation loss: 1.6775511541674215

Epoch: 5| Step: 7
Training loss: 0.5806735754013062
Validation loss: 1.6971055205150316

Epoch: 5| Step: 8
Training loss: 0.8979439735412598
Validation loss: 1.7273027217516335

Epoch: 5| Step: 9
Training loss: 0.6655510067939758
Validation loss: 1.7349112200480636

Epoch: 5| Step: 10
Training loss: 1.0251721143722534
Validation loss: 1.7520936330159504

Epoch: 298| Step: 0
Training loss: 0.9701766967773438
Validation loss: 1.7590034815572924

Epoch: 5| Step: 1
Training loss: 0.7487203478813171
Validation loss: 1.7503242313220937

Epoch: 5| Step: 2
Training loss: 1.0873130559921265
Validation loss: 1.7632706716496458

Epoch: 5| Step: 3
Training loss: 0.6381977796554565
Validation loss: 1.7777243198886994

Epoch: 5| Step: 4
Training loss: 0.704203724861145
Validation loss: 1.7573917232533938

Epoch: 5| Step: 5
Training loss: 0.7888106107711792
Validation loss: 1.7122786455256964

Epoch: 5| Step: 6
Training loss: 0.6075283288955688
Validation loss: 1.6733517416061894

Epoch: 5| Step: 7
Training loss: 1.0106890201568604
Validation loss: 1.6573362042826991

Epoch: 5| Step: 8
Training loss: 0.6178303956985474
Validation loss: 1.6580541505608508

Epoch: 5| Step: 9
Training loss: 0.8694667816162109
Validation loss: 1.6671744392764183

Epoch: 5| Step: 10
Training loss: 0.44056034088134766
Validation loss: 1.6679278650591451

Epoch: 299| Step: 0
Training loss: 0.7576724290847778
Validation loss: 1.716596741830149

Epoch: 5| Step: 1
Training loss: 0.7229846119880676
Validation loss: 1.7530615073378368

Epoch: 5| Step: 2
Training loss: 0.6780957579612732
Validation loss: 1.7396018940915343

Epoch: 5| Step: 3
Training loss: 0.37858134508132935
Validation loss: 1.7627777617464784

Epoch: 5| Step: 4
Training loss: 0.8004482388496399
Validation loss: 1.7562810759390555

Epoch: 5| Step: 5
Training loss: 0.9528566598892212
Validation loss: 1.7302032337393811

Epoch: 5| Step: 6
Training loss: 0.8482667803764343
Validation loss: 1.7335697732945925

Epoch: 5| Step: 7
Training loss: 0.7063160538673401
Validation loss: 1.7269688242225236

Epoch: 5| Step: 8
Training loss: 1.137925386428833
Validation loss: 1.7425432756382933

Epoch: 5| Step: 9
Training loss: 0.8295823335647583
Validation loss: 1.742963901130102

Epoch: 5| Step: 10
Training loss: 1.0201539993286133
Validation loss: 1.723114731491253

Epoch: 300| Step: 0
Training loss: 0.7849239110946655
Validation loss: 1.7280918526393112

Epoch: 5| Step: 1
Training loss: 0.5827574133872986
Validation loss: 1.7325366979004235

Epoch: 5| Step: 2
Training loss: 0.624447226524353
Validation loss: 1.7618633559955064

Epoch: 5| Step: 3
Training loss: 0.8160616159439087
Validation loss: 1.747877178653594

Epoch: 5| Step: 4
Training loss: 0.8396602869033813
Validation loss: 1.7424492066906345

Epoch: 5| Step: 5
Training loss: 0.9722038507461548
Validation loss: 1.7478768556348738

Epoch: 5| Step: 6
Training loss: 0.989358127117157
Validation loss: 1.7449369251087148

Epoch: 5| Step: 7
Training loss: 0.5920177698135376
Validation loss: 1.7197590668996174

Epoch: 5| Step: 8
Training loss: 0.6196389198303223
Validation loss: 1.7123862299867856

Epoch: 5| Step: 9
Training loss: 0.8590971827507019
Validation loss: 1.7195101104756838

Epoch: 5| Step: 10
Training loss: 0.5612543225288391
Validation loss: 1.7143692431911346

Epoch: 301| Step: 0
Training loss: 0.7481680512428284
Validation loss: 1.701746843194449

Epoch: 5| Step: 1
Training loss: 0.9055256843566895
Validation loss: 1.7002223999269548

Epoch: 5| Step: 2
Training loss: 0.39393189549446106
Validation loss: 1.7170702590737292

Epoch: 5| Step: 3
Training loss: 1.0756337642669678
Validation loss: 1.7360012633826143

Epoch: 5| Step: 4
Training loss: 0.6201504468917847
Validation loss: 1.7252855941813479

Epoch: 5| Step: 5
Training loss: 0.9507881999015808
Validation loss: 1.7397123588028776

Epoch: 5| Step: 6
Training loss: 0.9223200678825378
Validation loss: 1.7623085347555016

Epoch: 5| Step: 7
Training loss: 0.43242016434669495
Validation loss: 1.759337600841317

Epoch: 5| Step: 8
Training loss: 0.7666503190994263
Validation loss: 1.6988941879682644

Epoch: 5| Step: 9
Training loss: 0.8196318745613098
Validation loss: 1.6618827671133063

Epoch: 5| Step: 10
Training loss: 0.6242956519126892
Validation loss: 1.6664792811998757

Epoch: 302| Step: 0
Training loss: 0.6634314656257629
Validation loss: 1.6293752770270071

Epoch: 5| Step: 1
Training loss: 0.8273391723632812
Validation loss: 1.659379348959974

Epoch: 5| Step: 2
Training loss: 0.7268692255020142
Validation loss: 1.698369005674957

Epoch: 5| Step: 3
Training loss: 1.1638939380645752
Validation loss: 1.7132176917086366

Epoch: 5| Step: 4
Training loss: 0.7751674056053162
Validation loss: 1.7431051782382432

Epoch: 5| Step: 5
Training loss: 0.8496764898300171
Validation loss: 1.7650808736842165

Epoch: 5| Step: 6
Training loss: 0.706354022026062
Validation loss: 1.7551986530262937

Epoch: 5| Step: 7
Training loss: 0.7471219897270203
Validation loss: 1.7499656343972811

Epoch: 5| Step: 8
Training loss: 0.6700319647789001
Validation loss: 1.73342897558725

Epoch: 5| Step: 9
Training loss: 0.7474986910820007
Validation loss: 1.6887236410571682

Epoch: 5| Step: 10
Training loss: 0.7345026731491089
Validation loss: 1.6826777894009826

Epoch: 303| Step: 0
Training loss: 0.6355075836181641
Validation loss: 1.6695215061146726

Epoch: 5| Step: 1
Training loss: 0.8031848669052124
Validation loss: 1.6752352714538574

Epoch: 5| Step: 2
Training loss: 0.9173498153686523
Validation loss: 1.6762397526412882

Epoch: 5| Step: 3
Training loss: 0.4400949478149414
Validation loss: 1.666889170164703

Epoch: 5| Step: 4
Training loss: 0.9740270376205444
Validation loss: 1.6613353997148492

Epoch: 5| Step: 5
Training loss: 0.6803343296051025
Validation loss: 1.7007753823393135

Epoch: 5| Step: 6
Training loss: 0.7398577928543091
Validation loss: 1.6757547406740085

Epoch: 5| Step: 7
Training loss: 1.179015874862671
Validation loss: 1.6978654002630582

Epoch: 5| Step: 8
Training loss: 0.7426275014877319
Validation loss: 1.6939928429101103

Epoch: 5| Step: 9
Training loss: 0.8592290878295898
Validation loss: 1.7111166830985778

Epoch: 5| Step: 10
Training loss: 0.4761768877506256
Validation loss: 1.7327676434670725

Epoch: 304| Step: 0
Training loss: 0.5443201065063477
Validation loss: 1.7607427168917913

Epoch: 5| Step: 1
Training loss: 1.0956412553787231
Validation loss: 1.7646144538797357

Epoch: 5| Step: 2
Training loss: 0.38310903310775757
Validation loss: 1.7341754897948234

Epoch: 5| Step: 3
Training loss: 1.1149876117706299
Validation loss: 1.7377069496339368

Epoch: 5| Step: 4
Training loss: 0.7559090852737427
Validation loss: 1.741854013935212

Epoch: 5| Step: 5
Training loss: 0.8981000781059265
Validation loss: 1.696103274181325

Epoch: 5| Step: 6
Training loss: 0.9722806811332703
Validation loss: 1.7201937347330072

Epoch: 5| Step: 7
Training loss: 0.8257451057434082
Validation loss: 1.68961501121521

Epoch: 5| Step: 8
Training loss: 0.34579089283943176
Validation loss: 1.6861030901632001

Epoch: 5| Step: 9
Training loss: 0.5298876762390137
Validation loss: 1.7108288298371017

Epoch: 5| Step: 10
Training loss: 0.7626821994781494
Validation loss: 1.7106173076937277

Epoch: 305| Step: 0
Training loss: 0.8155612945556641
Validation loss: 1.7088536575276365

Epoch: 5| Step: 1
Training loss: 0.2784401476383209
Validation loss: 1.690554021507181

Epoch: 5| Step: 2
Training loss: 0.774410605430603
Validation loss: 1.7154390247919227

Epoch: 5| Step: 3
Training loss: 0.9567853212356567
Validation loss: 1.724378449942476

Epoch: 5| Step: 4
Training loss: 1.0341724157333374
Validation loss: 1.6813005016696068

Epoch: 5| Step: 5
Training loss: 1.0981838703155518
Validation loss: 1.682212656544101

Epoch: 5| Step: 6
Training loss: 0.849983811378479
Validation loss: 1.6725115993971467

Epoch: 5| Step: 7
Training loss: 0.4995341897010803
Validation loss: 1.649855818799747

Epoch: 5| Step: 8
Training loss: 0.5161163210868835
Validation loss: 1.6550174336279593

Epoch: 5| Step: 9
Training loss: 0.8074361085891724
Validation loss: 1.6079764571241153

Epoch: 5| Step: 10
Training loss: 0.5970270037651062
Validation loss: 1.626216406463295

Epoch: 306| Step: 0
Training loss: 0.2858562469482422
Validation loss: 1.6314077966956682

Epoch: 5| Step: 1
Training loss: 0.7859721183776855
Validation loss: 1.6325015303909138

Epoch: 5| Step: 2
Training loss: 0.826956570148468
Validation loss: 1.6456966079691404

Epoch: 5| Step: 3
Training loss: 0.618971049785614
Validation loss: 1.6716370800490021

Epoch: 5| Step: 4
Training loss: 1.084368109703064
Validation loss: 1.6770411575994184

Epoch: 5| Step: 5
Training loss: 0.574579119682312
Validation loss: 1.6908259007238573

Epoch: 5| Step: 6
Training loss: 0.44360241293907166
Validation loss: 1.700097865955804

Epoch: 5| Step: 7
Training loss: 0.35790807008743286
Validation loss: 1.6515089234998148

Epoch: 5| Step: 8
Training loss: 0.787563681602478
Validation loss: 1.6714150162153347

Epoch: 5| Step: 9
Training loss: 0.944139838218689
Validation loss: 1.6581959801335489

Epoch: 5| Step: 10
Training loss: 1.406666874885559
Validation loss: 1.645062420957832

Epoch: 307| Step: 0
Training loss: 0.5739091634750366
Validation loss: 1.6595307960305163

Epoch: 5| Step: 1
Training loss: 0.7481712102890015
Validation loss: 1.6602527172334733

Epoch: 5| Step: 2
Training loss: 0.5904449820518494
Validation loss: 1.6731563768079203

Epoch: 5| Step: 3
Training loss: 0.9833003282546997
Validation loss: 1.7158327871753323

Epoch: 5| Step: 4
Training loss: 0.8961547613143921
Validation loss: 1.7430489217081377

Epoch: 5| Step: 5
Training loss: 0.6896875500679016
Validation loss: 1.8152952617214573

Epoch: 5| Step: 6
Training loss: 0.7178683280944824
Validation loss: 1.8171771982664704

Epoch: 5| Step: 7
Training loss: 1.2106702327728271
Validation loss: 1.8017045169748285

Epoch: 5| Step: 8
Training loss: 0.5302516222000122
Validation loss: 1.7630512329839891

Epoch: 5| Step: 9
Training loss: 0.8433278203010559
Validation loss: 1.7621165462719497

Epoch: 5| Step: 10
Training loss: 0.5343617796897888
Validation loss: 1.709211762233447

Epoch: 308| Step: 0
Training loss: 0.9045597314834595
Validation loss: 1.7242064129921697

Epoch: 5| Step: 1
Training loss: 0.6166008114814758
Validation loss: 1.7044528863763297

Epoch: 5| Step: 2
Training loss: 0.509273886680603
Validation loss: 1.6970641818097842

Epoch: 5| Step: 3
Training loss: 0.49812132120132446
Validation loss: 1.6953621263145118

Epoch: 5| Step: 4
Training loss: 1.054512619972229
Validation loss: 1.691431200632485

Epoch: 5| Step: 5
Training loss: 0.7878100275993347
Validation loss: 1.7432768152606102

Epoch: 5| Step: 6
Training loss: 0.6359573602676392
Validation loss: 1.7520497716883177

Epoch: 5| Step: 7
Training loss: 0.5759450793266296
Validation loss: 1.7190330169534171

Epoch: 5| Step: 8
Training loss: 0.7391505837440491
Validation loss: 1.71935393733363

Epoch: 5| Step: 9
Training loss: 0.8368221521377563
Validation loss: 1.7007071459165184

Epoch: 5| Step: 10
Training loss: 0.9260779023170471
Validation loss: 1.6900106655654086

Epoch: 309| Step: 0
Training loss: 1.1512492895126343
Validation loss: 1.6588007346276314

Epoch: 5| Step: 1
Training loss: 0.9018479585647583
Validation loss: 1.6795195187291792

Epoch: 5| Step: 2
Training loss: 0.4756128787994385
Validation loss: 1.6427237244062527

Epoch: 5| Step: 3
Training loss: 0.4726334512233734
Validation loss: 1.6391586231929

Epoch: 5| Step: 4
Training loss: 0.7219883799552917
Validation loss: 1.6168354051087492

Epoch: 5| Step: 5
Training loss: 0.921830952167511
Validation loss: 1.6672311290617912

Epoch: 5| Step: 6
Training loss: 0.6823374032974243
Validation loss: 1.6889906557657386

Epoch: 5| Step: 7
Training loss: 0.44443479180336
Validation loss: 1.715943051922706

Epoch: 5| Step: 8
Training loss: 0.7460652589797974
Validation loss: 1.728586193053953

Epoch: 5| Step: 9
Training loss: 0.90392005443573
Validation loss: 1.697878704276136

Epoch: 5| Step: 10
Training loss: 0.5733180642127991
Validation loss: 1.6727599559291717

Epoch: 310| Step: 0
Training loss: 0.8576258420944214
Validation loss: 1.6527848756441506

Epoch: 5| Step: 1
Training loss: 0.6468880772590637
Validation loss: 1.6255263474679762

Epoch: 5| Step: 2
Training loss: 0.8051154017448425
Validation loss: 1.6196700667822233

Epoch: 5| Step: 3
Training loss: 0.67900550365448
Validation loss: 1.608777037230871

Epoch: 5| Step: 4
Training loss: 0.9213759303092957
Validation loss: 1.6017691409716042

Epoch: 5| Step: 5
Training loss: 0.7293731570243835
Validation loss: 1.588972371111634

Epoch: 5| Step: 6
Training loss: 0.7138962745666504
Validation loss: 1.6007859424878192

Epoch: 5| Step: 7
Training loss: 0.715813159942627
Validation loss: 1.6483631031487578

Epoch: 5| Step: 8
Training loss: 0.5806940793991089
Validation loss: 1.6572187010959913

Epoch: 5| Step: 9
Training loss: 0.8890773057937622
Validation loss: 1.7102360174220095

Epoch: 5| Step: 10
Training loss: 0.38411879539489746
Validation loss: 1.6878680695769608

Epoch: 311| Step: 0
Training loss: 0.6829191446304321
Validation loss: 1.6754301619786087

Epoch: 5| Step: 1
Training loss: 0.714387059211731
Validation loss: 1.6945137593054003

Epoch: 5| Step: 2
Training loss: 0.59263676404953
Validation loss: 1.6876829695957962

Epoch: 5| Step: 3
Training loss: 1.099022626876831
Validation loss: 1.7057656062546598

Epoch: 5| Step: 4
Training loss: 0.5842491388320923
Validation loss: 1.7023345655010593

Epoch: 5| Step: 5
Training loss: 0.5049511194229126
Validation loss: 1.7560078174837175

Epoch: 5| Step: 6
Training loss: 0.6551059484481812
Validation loss: 1.769835813071138

Epoch: 5| Step: 7
Training loss: 0.8879343271255493
Validation loss: 1.7706879403001519

Epoch: 5| Step: 8
Training loss: 0.662571370601654
Validation loss: 1.749768135368183

Epoch: 5| Step: 9
Training loss: 0.6132550835609436
Validation loss: 1.7332331557427683

Epoch: 5| Step: 10
Training loss: 0.8921191692352295
Validation loss: 1.733125441817827

Epoch: 312| Step: 0
Training loss: 0.6848868131637573
Validation loss: 1.6897837628600418

Epoch: 5| Step: 1
Training loss: 1.1853454113006592
Validation loss: 1.6657914397537068

Epoch: 5| Step: 2
Training loss: 0.7249341607093811
Validation loss: 1.6521835045147968

Epoch: 5| Step: 3
Training loss: 1.0246562957763672
Validation loss: 1.6742530304898497

Epoch: 5| Step: 4
Training loss: 0.6164505481719971
Validation loss: 1.6821705807921707

Epoch: 5| Step: 5
Training loss: 0.46430811285972595
Validation loss: 1.6782149845553982

Epoch: 5| Step: 6
Training loss: 0.6013702154159546
Validation loss: 1.6962149297037432

Epoch: 5| Step: 7
Training loss: 0.8863325119018555
Validation loss: 1.690490202237201

Epoch: 5| Step: 8
Training loss: 0.760412335395813
Validation loss: 1.6981655705359675

Epoch: 5| Step: 9
Training loss: 0.3410626947879791
Validation loss: 1.706561501308154

Epoch: 5| Step: 10
Training loss: 0.5574139952659607
Validation loss: 1.751049518585205

Epoch: 313| Step: 0
Training loss: 0.9279093742370605
Validation loss: 1.7668187425982567

Epoch: 5| Step: 1
Training loss: 0.7790977954864502
Validation loss: 1.7711741514103387

Epoch: 5| Step: 2
Training loss: 0.5096142292022705
Validation loss: 1.7734691442981843

Epoch: 5| Step: 3
Training loss: 0.5533526539802551
Validation loss: 1.732119406423261

Epoch: 5| Step: 4
Training loss: 0.7282568216323853
Validation loss: 1.7100804698082708

Epoch: 5| Step: 5
Training loss: 0.6474518775939941
Validation loss: 1.6529950339307067

Epoch: 5| Step: 6
Training loss: 0.7392812967300415
Validation loss: 1.616620599582631

Epoch: 5| Step: 7
Training loss: 0.717495322227478
Validation loss: 1.6233824529955465

Epoch: 5| Step: 8
Training loss: 0.44150200486183167
Validation loss: 1.679680820434324

Epoch: 5| Step: 9
Training loss: 1.3230292797088623
Validation loss: 1.7556507920706144

Epoch: 5| Step: 10
Training loss: 0.7867020964622498
Validation loss: 1.7418557315744378

Epoch: 314| Step: 0
Training loss: 0.9956649541854858
Validation loss: 1.7300074100494385

Epoch: 5| Step: 1
Training loss: 0.5511366128921509
Validation loss: 1.673495138845136

Epoch: 5| Step: 2
Training loss: 0.8395696878433228
Validation loss: 1.6300949576080486

Epoch: 5| Step: 3
Training loss: 0.7727417945861816
Validation loss: 1.6156038148428804

Epoch: 5| Step: 4
Training loss: 0.6257967948913574
Validation loss: 1.6186284775375037

Epoch: 5| Step: 5
Training loss: 0.4044267535209656
Validation loss: 1.6470731483992709

Epoch: 5| Step: 6
Training loss: 0.49012574553489685
Validation loss: 1.6557559774767967

Epoch: 5| Step: 7
Training loss: 0.6501771211624146
Validation loss: 1.6939143608975153

Epoch: 5| Step: 8
Training loss: 1.0867763757705688
Validation loss: 1.660868497305019

Epoch: 5| Step: 9
Training loss: 0.9320605993270874
Validation loss: 1.6681936492202103

Epoch: 5| Step: 10
Training loss: 0.42903193831443787
Validation loss: 1.6849868451395342

Epoch: 315| Step: 0
Training loss: 0.5065880417823792
Validation loss: 1.6949088611910421

Epoch: 5| Step: 1
Training loss: 0.7091968655586243
Validation loss: 1.7080219586690266

Epoch: 5| Step: 2
Training loss: 0.556073784828186
Validation loss: 1.7361720364580873

Epoch: 5| Step: 3
Training loss: 1.1516207456588745
Validation loss: 1.7214698048048123

Epoch: 5| Step: 4
Training loss: 0.43182238936424255
Validation loss: 1.7132346822369484

Epoch: 5| Step: 5
Training loss: 0.551525354385376
Validation loss: 1.6811529628692135

Epoch: 5| Step: 6
Training loss: 0.4698207974433899
Validation loss: 1.688702223121479

Epoch: 5| Step: 7
Training loss: 1.0184357166290283
Validation loss: 1.7075961289867279

Epoch: 5| Step: 8
Training loss: 0.6453975439071655
Validation loss: 1.6897758373650171

Epoch: 5| Step: 9
Training loss: 0.8063744306564331
Validation loss: 1.7212985356648762

Epoch: 5| Step: 10
Training loss: 0.5471410155296326
Validation loss: 1.6905862016062583

Epoch: 316| Step: 0
Training loss: 0.8575506210327148
Validation loss: 1.6897889644868913

Epoch: 5| Step: 1
Training loss: 0.5076370239257812
Validation loss: 1.7009985498202744

Epoch: 5| Step: 2
Training loss: 0.39757609367370605
Validation loss: 1.7015843070963377

Epoch: 5| Step: 3
Training loss: 0.5813702344894409
Validation loss: 1.704323907052317

Epoch: 5| Step: 4
Training loss: 1.1100633144378662
Validation loss: 1.6955647404475878

Epoch: 5| Step: 5
Training loss: 0.9635049700737
Validation loss: 1.7068248218105686

Epoch: 5| Step: 6
Training loss: 0.8148593902587891
Validation loss: 1.694780695822931

Epoch: 5| Step: 7
Training loss: 0.5965818166732788
Validation loss: 1.6696915011252127

Epoch: 5| Step: 8
Training loss: 0.4189256727695465
Validation loss: 1.6318844338899017

Epoch: 5| Step: 9
Training loss: 0.4290314316749573
Validation loss: 1.6365067497376473

Epoch: 5| Step: 10
Training loss: 0.6208744049072266
Validation loss: 1.6316938118268085

Epoch: 317| Step: 0
Training loss: 0.5909746289253235
Validation loss: 1.6582911258102746

Epoch: 5| Step: 1
Training loss: 0.6875470876693726
Validation loss: 1.6724086384619437

Epoch: 5| Step: 2
Training loss: 0.574923038482666
Validation loss: 1.6901364153431309

Epoch: 5| Step: 3
Training loss: 0.7727866172790527
Validation loss: 1.7375884030454902

Epoch: 5| Step: 4
Training loss: 0.7594426274299622
Validation loss: 1.7280272706862418

Epoch: 5| Step: 5
Training loss: 0.6113954782485962
Validation loss: 1.7396035322579004

Epoch: 5| Step: 6
Training loss: 0.9925478100776672
Validation loss: 1.6866745397608767

Epoch: 5| Step: 7
Training loss: 0.9003331065177917
Validation loss: 1.6400237378253733

Epoch: 5| Step: 8
Training loss: 0.7023093104362488
Validation loss: 1.625741768908757

Epoch: 5| Step: 9
Training loss: 0.4500853419303894
Validation loss: 1.6083898018765193

Epoch: 5| Step: 10
Training loss: 0.8990764021873474
Validation loss: 1.6012884352796821

Epoch: 318| Step: 0
Training loss: 0.7233525514602661
Validation loss: 1.644643824587586

Epoch: 5| Step: 1
Training loss: 0.9059110879898071
Validation loss: 1.667085463000882

Epoch: 5| Step: 2
Training loss: 0.6661839485168457
Validation loss: 1.639759329057509

Epoch: 5| Step: 3
Training loss: 0.619045615196228
Validation loss: 1.6614853182146627

Epoch: 5| Step: 4
Training loss: 0.742818295955658
Validation loss: 1.638299843316437

Epoch: 5| Step: 5
Training loss: 0.5161046385765076
Validation loss: 1.6611860567523586

Epoch: 5| Step: 6
Training loss: 0.5149803161621094
Validation loss: 1.637773621466852

Epoch: 5| Step: 7
Training loss: 0.8229371905326843
Validation loss: 1.6714267743531095

Epoch: 5| Step: 8
Training loss: 0.3225899636745453
Validation loss: 1.6761282490145775

Epoch: 5| Step: 9
Training loss: 0.6283553838729858
Validation loss: 1.6763793678693875

Epoch: 5| Step: 10
Training loss: 0.7968142628669739
Validation loss: 1.7082942980591969

Epoch: 319| Step: 0
Training loss: 0.5654519200325012
Validation loss: 1.6996647978341708

Epoch: 5| Step: 1
Training loss: 0.42464131116867065
Validation loss: 1.7081735236670381

Epoch: 5| Step: 2
Training loss: 0.3026992678642273
Validation loss: 1.6958690381819201

Epoch: 5| Step: 3
Training loss: 0.4118071496486664
Validation loss: 1.698630694420107

Epoch: 5| Step: 4
Training loss: 0.9269773364067078
Validation loss: 1.6824962695439656

Epoch: 5| Step: 5
Training loss: 0.8276687860488892
Validation loss: 1.6726160664712229

Epoch: 5| Step: 6
Training loss: 0.6817607283592224
Validation loss: 1.7173618449959704

Epoch: 5| Step: 7
Training loss: 0.6050422191619873
Validation loss: 1.7173952505152712

Epoch: 5| Step: 8
Training loss: 0.5683149695396423
Validation loss: 1.7172536350065661

Epoch: 5| Step: 9
Training loss: 1.1269562244415283
Validation loss: 1.7510304822716662

Epoch: 5| Step: 10
Training loss: 0.8391640186309814
Validation loss: 1.743615053033316

Epoch: 320| Step: 0
Training loss: 0.26025253534317017
Validation loss: 1.781598262889411

Epoch: 5| Step: 1
Training loss: 0.7931108474731445
Validation loss: 1.7895241270783127

Epoch: 5| Step: 2
Training loss: 0.6496294736862183
Validation loss: 1.7459739177457747

Epoch: 5| Step: 3
Training loss: 0.826688289642334
Validation loss: 1.722212246669236

Epoch: 5| Step: 4
Training loss: 0.7476973533630371
Validation loss: 1.6651168600205453

Epoch: 5| Step: 5
Training loss: 0.6656273007392883
Validation loss: 1.6209628030817995

Epoch: 5| Step: 6
Training loss: 0.8898521661758423
Validation loss: 1.630639132633004

Epoch: 5| Step: 7
Training loss: 0.6398912668228149
Validation loss: 1.6308632166154924

Epoch: 5| Step: 8
Training loss: 0.25627169013023376
Validation loss: 1.6356887894292031

Epoch: 5| Step: 9
Training loss: 0.7313721179962158
Validation loss: 1.655575579212558

Epoch: 5| Step: 10
Training loss: 0.6271965503692627
Validation loss: 1.6221608474690428

Epoch: 321| Step: 0
Training loss: 0.3754839301109314
Validation loss: 1.612790907582929

Epoch: 5| Step: 1
Training loss: 0.8680535554885864
Validation loss: 1.6173493926243117

Epoch: 5| Step: 2
Training loss: 0.7604748606681824
Validation loss: 1.6230241457621257

Epoch: 5| Step: 3
Training loss: 0.5037508010864258
Validation loss: 1.6225658898712487

Epoch: 5| Step: 4
Training loss: 0.7186997532844543
Validation loss: 1.6265924015352804

Epoch: 5| Step: 5
Training loss: 0.5266046524047852
Validation loss: 1.6246492862701416

Epoch: 5| Step: 6
Training loss: 0.602413535118103
Validation loss: 1.6273053205141457

Epoch: 5| Step: 7
Training loss: 0.629163384437561
Validation loss: 1.6643990996063396

Epoch: 5| Step: 8
Training loss: 0.7864682078361511
Validation loss: 1.6961326124847576

Epoch: 5| Step: 9
Training loss: 0.6431294083595276
Validation loss: 1.6739924665420287

Epoch: 5| Step: 10
Training loss: 0.4489502012729645
Validation loss: 1.6263302679984801

Epoch: 322| Step: 0
Training loss: 0.45933738350868225
Validation loss: 1.6647806385511994

Epoch: 5| Step: 1
Training loss: 0.7718359231948853
Validation loss: 1.6618027840891192

Epoch: 5| Step: 2
Training loss: 0.4686010479927063
Validation loss: 1.660388538914342

Epoch: 5| Step: 3
Training loss: 0.6133500933647156
Validation loss: 1.6716501879435715

Epoch: 5| Step: 4
Training loss: 0.4058859944343567
Validation loss: 1.6450561861838064

Epoch: 5| Step: 5
Training loss: 0.7049868106842041
Validation loss: 1.660943506866373

Epoch: 5| Step: 6
Training loss: 0.9384014010429382
Validation loss: 1.6471786729751094

Epoch: 5| Step: 7
Training loss: 0.6186569333076477
Validation loss: 1.6762710437979749

Epoch: 5| Step: 8
Training loss: 0.8320327997207642
Validation loss: 1.682588783643579

Epoch: 5| Step: 9
Training loss: 0.2938126027584076
Validation loss: 1.7001490349410682

Epoch: 5| Step: 10
Training loss: 0.635084867477417
Validation loss: 1.6702010990470968

Epoch: 323| Step: 0
Training loss: 0.5187766551971436
Validation loss: 1.704254340100032

Epoch: 5| Step: 1
Training loss: 0.5749906301498413
Validation loss: 1.7029507262732393

Epoch: 5| Step: 2
Training loss: 0.26236599683761597
Validation loss: 1.7061366893911873

Epoch: 5| Step: 3
Training loss: 0.3405100405216217
Validation loss: 1.7106997877038934

Epoch: 5| Step: 4
Training loss: 0.8019058108329773
Validation loss: 1.751176030405106

Epoch: 5| Step: 5
Training loss: 0.7263599634170532
Validation loss: 1.7294602765831897

Epoch: 5| Step: 6
Training loss: 0.6086523532867432
Validation loss: 1.7093977466706307

Epoch: 5| Step: 7
Training loss: 0.809949517250061
Validation loss: 1.7003024662694624

Epoch: 5| Step: 8
Training loss: 0.7378214597702026
Validation loss: 1.6961128378427157

Epoch: 5| Step: 9
Training loss: 0.7484567761421204
Validation loss: 1.6748580676253124

Epoch: 5| Step: 10
Training loss: 0.8925612568855286
Validation loss: 1.6965224691616592

Epoch: 324| Step: 0
Training loss: 0.47451385855674744
Validation loss: 1.6975262664979505

Epoch: 5| Step: 1
Training loss: 0.559598982334137
Validation loss: 1.7261081754520375

Epoch: 5| Step: 2
Training loss: 0.43886899948120117
Validation loss: 1.7444765734416183

Epoch: 5| Step: 3
Training loss: 0.3137494921684265
Validation loss: 1.718452117776358

Epoch: 5| Step: 4
Training loss: 0.8147412538528442
Validation loss: 1.7793693619389688

Epoch: 5| Step: 5
Training loss: 0.6665293574333191
Validation loss: 1.761351817397661

Epoch: 5| Step: 6
Training loss: 0.6048505902290344
Validation loss: 1.7145914018795054

Epoch: 5| Step: 7
Training loss: 0.6567269563674927
Validation loss: 1.7166333096001738

Epoch: 5| Step: 8
Training loss: 0.7953938245773315
Validation loss: 1.6885992878226823

Epoch: 5| Step: 9
Training loss: 0.7241106629371643
Validation loss: 1.6945607534018896

Epoch: 5| Step: 10
Training loss: 0.8570808172225952
Validation loss: 1.6941321844695716

Epoch: 325| Step: 0
Training loss: 0.8997184634208679
Validation loss: 1.6985913502272738

Epoch: 5| Step: 1
Training loss: 0.7832672595977783
Validation loss: 1.7035032472302836

Epoch: 5| Step: 2
Training loss: 0.43625888228416443
Validation loss: 1.7235425890132945

Epoch: 5| Step: 3
Training loss: 0.38061970472335815
Validation loss: 1.7399763830246464

Epoch: 5| Step: 4
Training loss: 0.5284361243247986
Validation loss: 1.7775279219432543

Epoch: 5| Step: 5
Training loss: 0.6197187304496765
Validation loss: 1.766424523886814

Epoch: 5| Step: 6
Training loss: 0.9111883044242859
Validation loss: 1.7908387337961504

Epoch: 5| Step: 7
Training loss: 0.5195455551147461
Validation loss: 1.7984005405056862

Epoch: 5| Step: 8
Training loss: 0.46194711327552795
Validation loss: 1.777077567192816

Epoch: 5| Step: 9
Training loss: 0.7947256565093994
Validation loss: 1.7421736665951308

Epoch: 5| Step: 10
Training loss: 0.6628409028053284
Validation loss: 1.721474588558238

Epoch: 326| Step: 0
Training loss: 0.5271127223968506
Validation loss: 1.7226734802287111

Epoch: 5| Step: 1
Training loss: 0.3994307816028595
Validation loss: 1.6683790747837355

Epoch: 5| Step: 2
Training loss: 0.49812406301498413
Validation loss: 1.6740195546098935

Epoch: 5| Step: 3
Training loss: 0.46410122513771057
Validation loss: 1.6707218577784877

Epoch: 5| Step: 4
Training loss: 0.8031197786331177
Validation loss: 1.6854056722374373

Epoch: 5| Step: 5
Training loss: 1.3071935176849365
Validation loss: 1.6438158673624839

Epoch: 5| Step: 6
Training loss: 0.38600462675094604
Validation loss: 1.6618116350584133

Epoch: 5| Step: 7
Training loss: 0.5594283938407898
Validation loss: 1.6322865255417363

Epoch: 5| Step: 8
Training loss: 0.4958438277244568
Validation loss: 1.6530404308790803

Epoch: 5| Step: 9
Training loss: 0.6739919185638428
Validation loss: 1.6990943467745216

Epoch: 5| Step: 10
Training loss: 0.9845930933952332
Validation loss: 1.6832584783595095

Epoch: 327| Step: 0
Training loss: 0.42623478174209595
Validation loss: 1.7156023556186306

Epoch: 5| Step: 1
Training loss: 0.5964543223381042
Validation loss: 1.6978721477652108

Epoch: 5| Step: 2
Training loss: 0.6495848894119263
Validation loss: 1.710722836115027

Epoch: 5| Step: 3
Training loss: 1.3175822496414185
Validation loss: 1.7114291037282636

Epoch: 5| Step: 4
Training loss: 0.5672188997268677
Validation loss: 1.7215680230048396

Epoch: 5| Step: 5
Training loss: 0.6854368448257446
Validation loss: 1.7388645282355688

Epoch: 5| Step: 6
Training loss: 0.5884013175964355
Validation loss: 1.7143085374627063

Epoch: 5| Step: 7
Training loss: 0.40380024909973145
Validation loss: 1.6704807460948985

Epoch: 5| Step: 8
Training loss: 0.5880338549613953
Validation loss: 1.6303124491886427

Epoch: 5| Step: 9
Training loss: 0.44470423460006714
Validation loss: 1.659892851306546

Epoch: 5| Step: 10
Training loss: 0.582628607749939
Validation loss: 1.6500732001437937

Epoch: 328| Step: 0
Training loss: 0.36072981357574463
Validation loss: 1.6566243607510802

Epoch: 5| Step: 1
Training loss: 0.8878997564315796
Validation loss: 1.663455556797725

Epoch: 5| Step: 2
Training loss: 0.9186698198318481
Validation loss: 1.689977620237617

Epoch: 5| Step: 3
Training loss: 0.6271776556968689
Validation loss: 1.6755983867952902

Epoch: 5| Step: 4
Training loss: 0.3225633502006531
Validation loss: 1.6752947338165776

Epoch: 5| Step: 5
Training loss: 0.3226543366909027
Validation loss: 1.6863897667136243

Epoch: 5| Step: 6
Training loss: 0.5748871564865112
Validation loss: 1.683464252820579

Epoch: 5| Step: 7
Training loss: 0.9272181391716003
Validation loss: 1.6750892003377278

Epoch: 5| Step: 8
Training loss: 0.4771824777126312
Validation loss: 1.6778243728863296

Epoch: 5| Step: 9
Training loss: 0.7969844341278076
Validation loss: 1.6765634577761415

Epoch: 5| Step: 10
Training loss: 0.46052873134613037
Validation loss: 1.6666598525098575

Epoch: 329| Step: 0
Training loss: 0.5831451416015625
Validation loss: 1.6656503228731052

Epoch: 5| Step: 1
Training loss: 0.6205806732177734
Validation loss: 1.6464448872432913

Epoch: 5| Step: 2
Training loss: 0.5417393445968628
Validation loss: 1.6376521215643933

Epoch: 5| Step: 3
Training loss: 0.7896483540534973
Validation loss: 1.6350878451460151

Epoch: 5| Step: 4
Training loss: 0.5039371252059937
Validation loss: 1.6382682541365265

Epoch: 5| Step: 5
Training loss: 0.821112334728241
Validation loss: 1.6344171826557448

Epoch: 5| Step: 6
Training loss: 0.510418713092804
Validation loss: 1.6350796748233098

Epoch: 5| Step: 7
Training loss: 0.5981930494308472
Validation loss: 1.6669765890285533

Epoch: 5| Step: 8
Training loss: 0.423098623752594
Validation loss: 1.6727931499481201

Epoch: 5| Step: 9
Training loss: 0.8547903299331665
Validation loss: 1.6794070761690858

Epoch: 5| Step: 10
Training loss: 0.7007171511650085
Validation loss: 1.6996528551142702

Epoch: 330| Step: 0
Training loss: 0.6391280293464661
Validation loss: 1.6151114279224026

Epoch: 5| Step: 1
Training loss: 0.5711473822593689
Validation loss: 1.5941863444543654

Epoch: 5| Step: 2
Training loss: 0.9318151473999023
Validation loss: 1.5814493458758119

Epoch: 5| Step: 3
Training loss: 0.6378272771835327
Validation loss: 1.5920463544066235

Epoch: 5| Step: 4
Training loss: 0.5571713447570801
Validation loss: 1.5903822862973778

Epoch: 5| Step: 5
Training loss: 0.31927210092544556
Validation loss: 1.5922493678267284

Epoch: 5| Step: 6
Training loss: 0.7450252771377563
Validation loss: 1.5989056825637817

Epoch: 5| Step: 7
Training loss: 0.5290579199790955
Validation loss: 1.6587564124855945

Epoch: 5| Step: 8
Training loss: 0.6675519943237305
Validation loss: 1.6930700322633148

Epoch: 5| Step: 9
Training loss: 0.598334789276123
Validation loss: 1.6860409314914415

Epoch: 5| Step: 10
Training loss: 1.0043933391571045
Validation loss: 1.6750584584410473

Epoch: 331| Step: 0
Training loss: 0.3613741993904114
Validation loss: 1.6299542573190504

Epoch: 5| Step: 1
Training loss: 0.5438638925552368
Validation loss: 1.612061522340262

Epoch: 5| Step: 2
Training loss: 0.5126814842224121
Validation loss: 1.6111409676972257

Epoch: 5| Step: 3
Training loss: 0.9364185333251953
Validation loss: 1.581718260242093

Epoch: 5| Step: 4
Training loss: 0.37124043703079224
Validation loss: 1.6021198265014156

Epoch: 5| Step: 5
Training loss: 0.6501579284667969
Validation loss: 1.610659517267699

Epoch: 5| Step: 6
Training loss: 0.532363772392273
Validation loss: 1.6039220235681022

Epoch: 5| Step: 7
Training loss: 0.9190340042114258
Validation loss: 1.6250903375687138

Epoch: 5| Step: 8
Training loss: 0.3611336052417755
Validation loss: 1.663853891434208

Epoch: 5| Step: 9
Training loss: 0.8033771514892578
Validation loss: 1.722901185353597

Epoch: 5| Step: 10
Training loss: 0.495784193277359
Validation loss: 1.7693331728699386

Epoch: 332| Step: 0
Training loss: 0.576056182384491
Validation loss: 1.7705871212867

Epoch: 5| Step: 1
Training loss: 0.3650202453136444
Validation loss: 1.726028734637845

Epoch: 5| Step: 2
Training loss: 0.6228016018867493
Validation loss: 1.687493170461347

Epoch: 5| Step: 3
Training loss: 0.5132699608802795
Validation loss: 1.6621502817318003

Epoch: 5| Step: 4
Training loss: 0.752894937992096
Validation loss: 1.677868232932142

Epoch: 5| Step: 5
Training loss: 0.4996374249458313
Validation loss: 1.6989941750803301

Epoch: 5| Step: 6
Training loss: 0.5963786840438843
Validation loss: 1.6810737553463186

Epoch: 5| Step: 7
Training loss: 0.7993429899215698
Validation loss: 1.6805996830745409

Epoch: 5| Step: 8
Training loss: 0.8271692395210266
Validation loss: 1.7016667332700504

Epoch: 5| Step: 9
Training loss: 0.5145951509475708
Validation loss: 1.7044518923246732

Epoch: 5| Step: 10
Training loss: 0.5856927037239075
Validation loss: 1.703594365427571

Epoch: 333| Step: 0
Training loss: 0.7699931263923645
Validation loss: 1.6897008534400695

Epoch: 5| Step: 1
Training loss: 0.45930805802345276
Validation loss: 1.684704255032283

Epoch: 5| Step: 2
Training loss: 0.5398611426353455
Validation loss: 1.6774037986673334

Epoch: 5| Step: 3
Training loss: 0.4344845712184906
Validation loss: 1.6405218711463354

Epoch: 5| Step: 4
Training loss: 0.8266351819038391
Validation loss: 1.673720827666662

Epoch: 5| Step: 5
Training loss: 0.44358396530151367
Validation loss: 1.6727390225215624

Epoch: 5| Step: 6
Training loss: 0.5098029375076294
Validation loss: 1.6580495949714416

Epoch: 5| Step: 7
Training loss: 0.606725811958313
Validation loss: 1.6962639324126705

Epoch: 5| Step: 8
Training loss: 0.5745814442634583
Validation loss: 1.6754936928390174

Epoch: 5| Step: 9
Training loss: 0.6434040665626526
Validation loss: 1.6816182380081506

Epoch: 5| Step: 10
Training loss: 0.6034842729568481
Validation loss: 1.7028410678268762

Epoch: 334| Step: 0
Training loss: 1.0116382837295532
Validation loss: 1.7400758343358194

Epoch: 5| Step: 1
Training loss: 0.4911055564880371
Validation loss: 1.776149675410281

Epoch: 5| Step: 2
Training loss: 0.5978202223777771
Validation loss: 1.7870480873251473

Epoch: 5| Step: 3
Training loss: 0.5824199914932251
Validation loss: 1.7652530798348047

Epoch: 5| Step: 4
Training loss: 0.5022913813591003
Validation loss: 1.7348099523975002

Epoch: 5| Step: 5
Training loss: 0.6730127930641174
Validation loss: 1.686077581938877

Epoch: 5| Step: 6
Training loss: 0.7160650491714478
Validation loss: 1.682143925338663

Epoch: 5| Step: 7
Training loss: 0.4629581868648529
Validation loss: 1.6646165822141914

Epoch: 5| Step: 8
Training loss: 0.41506892442703247
Validation loss: 1.6885658656397173

Epoch: 5| Step: 9
Training loss: 0.7814109921455383
Validation loss: 1.685270022320491

Epoch: 5| Step: 10
Training loss: 0.4171515107154846
Validation loss: 1.6757535626811366

Epoch: 335| Step: 0
Training loss: 0.3960433602333069
Validation loss: 1.7112030982971191

Epoch: 5| Step: 1
Training loss: 0.6125678420066833
Validation loss: 1.6917172619091567

Epoch: 5| Step: 2
Training loss: 0.7583469152450562
Validation loss: 1.7326191266377766

Epoch: 5| Step: 3
Training loss: 0.6191326975822449
Validation loss: 1.7050655580336047

Epoch: 5| Step: 4
Training loss: 0.6466575860977173
Validation loss: 1.6947031380027853

Epoch: 5| Step: 5
Training loss: 0.5703427791595459
Validation loss: 1.6742013769765054

Epoch: 5| Step: 6
Training loss: 0.31440526247024536
Validation loss: 1.6975814078443794

Epoch: 5| Step: 7
Training loss: 0.7634680271148682
Validation loss: 1.6851456075586297

Epoch: 5| Step: 8
Training loss: 0.5794480443000793
Validation loss: 1.6858937150688582

Epoch: 5| Step: 9
Training loss: 0.6155613660812378
Validation loss: 1.671578029150604

Epoch: 5| Step: 10
Training loss: 0.21929563581943512
Validation loss: 1.7094034533346854

Epoch: 336| Step: 0
Training loss: 0.777054488658905
Validation loss: 1.706900640200543

Epoch: 5| Step: 1
Training loss: 0.5218690633773804
Validation loss: 1.6798315202036211

Epoch: 5| Step: 2
Training loss: 0.6242680549621582
Validation loss: 1.6667824483686877

Epoch: 5| Step: 3
Training loss: 0.4045030176639557
Validation loss: 1.6663019426407353

Epoch: 5| Step: 4
Training loss: 0.7751814723014832
Validation loss: 1.6616641475308327

Epoch: 5| Step: 5
Training loss: 0.5597365498542786
Validation loss: 1.6635628836129301

Epoch: 5| Step: 6
Training loss: 0.45501500368118286
Validation loss: 1.6667268660760695

Epoch: 5| Step: 7
Training loss: 0.5358603000640869
Validation loss: 1.6869889100392659

Epoch: 5| Step: 8
Training loss: 0.3418465852737427
Validation loss: 1.6974661145158993

Epoch: 5| Step: 9
Training loss: 0.3851083219051361
Validation loss: 1.700500144753405

Epoch: 5| Step: 10
Training loss: 0.7225479483604431
Validation loss: 1.7015521616064093

Epoch: 337| Step: 0
Training loss: 0.7219602465629578
Validation loss: 1.7226916384953324

Epoch: 5| Step: 1
Training loss: 0.41936102509498596
Validation loss: 1.698460922446302

Epoch: 5| Step: 2
Training loss: 0.23355941474437714
Validation loss: 1.6855612044693322

Epoch: 5| Step: 3
Training loss: 0.6909320950508118
Validation loss: 1.662604562697872

Epoch: 5| Step: 4
Training loss: 0.4434677064418793
Validation loss: 1.6897864316099434

Epoch: 5| Step: 5
Training loss: 0.9411700367927551
Validation loss: 1.6874785320733183

Epoch: 5| Step: 6
Training loss: 0.5850732326507568
Validation loss: 1.6988961081351004

Epoch: 5| Step: 7
Training loss: 0.5158915519714355
Validation loss: 1.6991165773842924

Epoch: 5| Step: 8
Training loss: 0.694608211517334
Validation loss: 1.6869356978324153

Epoch: 5| Step: 9
Training loss: 0.8981539011001587
Validation loss: 1.701491569959989

Epoch: 5| Step: 10
Training loss: 0.19090983271598816
Validation loss: 1.7303781150489725

Epoch: 338| Step: 0
Training loss: 0.629726231098175
Validation loss: 1.7325069827418174

Epoch: 5| Step: 1
Training loss: 0.2178664654493332
Validation loss: 1.71497626842991

Epoch: 5| Step: 2
Training loss: 0.7271258234977722
Validation loss: 1.710423142679276

Epoch: 5| Step: 3
Training loss: 0.4802778363227844
Validation loss: 1.7338725520718483

Epoch: 5| Step: 4
Training loss: 0.5130645036697388
Validation loss: 1.7082446813583374

Epoch: 5| Step: 5
Training loss: 0.6217861175537109
Validation loss: 1.6972713931914298

Epoch: 5| Step: 6
Training loss: 0.5891443490982056
Validation loss: 1.6696604336461713

Epoch: 5| Step: 7
Training loss: 0.5788764953613281
Validation loss: 1.6812330548481276

Epoch: 5| Step: 8
Training loss: 0.5613811016082764
Validation loss: 1.701746380457314

Epoch: 5| Step: 9
Training loss: 0.568080484867096
Validation loss: 1.6689216449696531

Epoch: 5| Step: 10
Training loss: 0.6275835037231445
Validation loss: 1.6843034016188754

Epoch: 339| Step: 0
Training loss: 0.3733920156955719
Validation loss: 1.6748206359083935

Epoch: 5| Step: 1
Training loss: 0.33204007148742676
Validation loss: 1.6821790766972367

Epoch: 5| Step: 2
Training loss: 0.46193742752075195
Validation loss: 1.7128645450838151

Epoch: 5| Step: 3
Training loss: 0.7954120635986328
Validation loss: 1.650645217587871

Epoch: 5| Step: 4
Training loss: 0.5193795561790466
Validation loss: 1.6590519592326174

Epoch: 5| Step: 5
Training loss: 0.5514731407165527
Validation loss: 1.6788436994757703

Epoch: 5| Step: 6
Training loss: 0.7153456211090088
Validation loss: 1.6757639274802258

Epoch: 5| Step: 7
Training loss: 0.5862821340560913
Validation loss: 1.705400986056174

Epoch: 5| Step: 8
Training loss: 0.36251839995384216
Validation loss: 1.7096386827448362

Epoch: 5| Step: 9
Training loss: 0.857962965965271
Validation loss: 1.720429862699201

Epoch: 5| Step: 10
Training loss: 0.47650381922721863
Validation loss: 1.7026056179436304

Epoch: 340| Step: 0
Training loss: 0.6617807149887085
Validation loss: 1.7310064351686867

Epoch: 5| Step: 1
Training loss: 0.4498668313026428
Validation loss: 1.7030566200133292

Epoch: 5| Step: 2
Training loss: 0.523004412651062
Validation loss: 1.701620489038447

Epoch: 5| Step: 3
Training loss: 0.5939358472824097
Validation loss: 1.6660123204672208

Epoch: 5| Step: 4
Training loss: 0.3610333800315857
Validation loss: 1.6613319176499561

Epoch: 5| Step: 5
Training loss: 0.4497767388820648
Validation loss: 1.650385868164801

Epoch: 5| Step: 6
Training loss: 0.6789748668670654
Validation loss: 1.643308784372063

Epoch: 5| Step: 7
Training loss: 0.5074979066848755
Validation loss: 1.6480790197208364

Epoch: 5| Step: 8
Training loss: 0.4726560711860657
Validation loss: 1.6711858203334193

Epoch: 5| Step: 9
Training loss: 0.7514419555664062
Validation loss: 1.6981398520931121

Epoch: 5| Step: 10
Training loss: 0.46887755393981934
Validation loss: 1.695493625056359

Epoch: 341| Step: 0
Training loss: 0.6558952331542969
Validation loss: 1.69527018198403

Epoch: 5| Step: 1
Training loss: 0.8775326609611511
Validation loss: 1.7434711148661952

Epoch: 5| Step: 2
Training loss: 0.6706615686416626
Validation loss: 1.7485167262374715

Epoch: 5| Step: 3
Training loss: 0.559814453125
Validation loss: 1.7371792293364001

Epoch: 5| Step: 4
Training loss: 0.35623791813850403
Validation loss: 1.6890043904704433

Epoch: 5| Step: 5
Training loss: 0.675493597984314
Validation loss: 1.6634949599542925

Epoch: 5| Step: 6
Training loss: 0.411104291677475
Validation loss: 1.6145398418108623

Epoch: 5| Step: 7
Training loss: 0.3317570388317108
Validation loss: 1.6290668261948453

Epoch: 5| Step: 8
Training loss: 0.6083137392997742
Validation loss: 1.626856191183931

Epoch: 5| Step: 9
Training loss: 0.6605671644210815
Validation loss: 1.6468625376301427

Epoch: 5| Step: 10
Training loss: 0.5176686644554138
Validation loss: 1.6094524988564112

Epoch: 342| Step: 0
Training loss: 0.6003513336181641
Validation loss: 1.6466686981980518

Epoch: 5| Step: 1
Training loss: 0.5233920812606812
Validation loss: 1.654849088320168

Epoch: 5| Step: 2
Training loss: 0.4901256561279297
Validation loss: 1.6776639658917663

Epoch: 5| Step: 3
Training loss: 0.4598202705383301
Validation loss: 1.7214316398866716

Epoch: 5| Step: 4
Training loss: 0.6091435551643372
Validation loss: 1.7174289482896046

Epoch: 5| Step: 5
Training loss: 0.5442324876785278
Validation loss: 1.705612624845197

Epoch: 5| Step: 6
Training loss: 0.6969685554504395
Validation loss: 1.702579939237205

Epoch: 5| Step: 7
Training loss: 0.56963050365448
Validation loss: 1.6325406682106756

Epoch: 5| Step: 8
Training loss: 0.3875698447227478
Validation loss: 1.630426171005413

Epoch: 5| Step: 9
Training loss: 0.7812821269035339
Validation loss: 1.6213720383182648

Epoch: 5| Step: 10
Training loss: 0.3026711940765381
Validation loss: 1.6292248387490549

Epoch: 343| Step: 0
Training loss: 0.3362988531589508
Validation loss: 1.6264555582436182

Epoch: 5| Step: 1
Training loss: 0.22155968844890594
Validation loss: 1.6166135534163444

Epoch: 5| Step: 2
Training loss: 0.34690818190574646
Validation loss: 1.6656859651688607

Epoch: 5| Step: 3
Training loss: 0.6235589385032654
Validation loss: 1.6631296296273508

Epoch: 5| Step: 4
Training loss: 0.6852803230285645
Validation loss: 1.681813750215756

Epoch: 5| Step: 5
Training loss: 0.7576944828033447
Validation loss: 1.6756141172942294

Epoch: 5| Step: 6
Training loss: 0.6100020408630371
Validation loss: 1.647313905018632

Epoch: 5| Step: 7
Training loss: 0.5127665400505066
Validation loss: 1.605780456655769

Epoch: 5| Step: 8
Training loss: 0.5528393387794495
Validation loss: 1.5732641297001992

Epoch: 5| Step: 9
Training loss: 0.4937313199043274
Validation loss: 1.5980952375678605

Epoch: 5| Step: 10
Training loss: 0.9806151390075684
Validation loss: 1.610128584728446

Epoch: 344| Step: 0
Training loss: 0.8211878538131714
Validation loss: 1.6320584666344427

Epoch: 5| Step: 1
Training loss: 0.5291458964347839
Validation loss: 1.6499470792790896

Epoch: 5| Step: 2
Training loss: 0.3265255391597748
Validation loss: 1.6485209811118342

Epoch: 5| Step: 3
Training loss: 0.5289991497993469
Validation loss: 1.6923728886471

Epoch: 5| Step: 4
Training loss: 0.3814140558242798
Validation loss: 1.7357684322582778

Epoch: 5| Step: 5
Training loss: 0.5621870160102844
Validation loss: 1.7326182678181639

Epoch: 5| Step: 6
Training loss: 0.6265276074409485
Validation loss: 1.7210631050089353

Epoch: 5| Step: 7
Training loss: 0.5374312400817871
Validation loss: 1.7048512453673987

Epoch: 5| Step: 8
Training loss: 0.2529614567756653
Validation loss: 1.6521559710143714

Epoch: 5| Step: 9
Training loss: 0.5970810651779175
Validation loss: 1.6164845651195896

Epoch: 5| Step: 10
Training loss: 0.8294743895530701
Validation loss: 1.600051317163693

Epoch: 345| Step: 0
Training loss: 0.5375038385391235
Validation loss: 1.5778320297118156

Epoch: 5| Step: 1
Training loss: 0.615886390209198
Validation loss: 1.5829286043361952

Epoch: 5| Step: 2
Training loss: 0.4750277101993561
Validation loss: 1.5661245904942995

Epoch: 5| Step: 3
Training loss: 0.580835223197937
Validation loss: 1.5952331430168563

Epoch: 5| Step: 4
Training loss: 0.5157040357589722
Validation loss: 1.5791952712561494

Epoch: 5| Step: 5
Training loss: 0.27528849244117737
Validation loss: 1.6229335056838168

Epoch: 5| Step: 6
Training loss: 0.6302605867385864
Validation loss: 1.6339496207493607

Epoch: 5| Step: 7
Training loss: 0.4238280653953552
Validation loss: 1.6160813787932038

Epoch: 5| Step: 8
Training loss: 0.6573969125747681
Validation loss: 1.6262209543617823

Epoch: 5| Step: 9
Training loss: 0.4272548258304596
Validation loss: 1.6107972783427085

Epoch: 5| Step: 10
Training loss: 0.9453469514846802
Validation loss: 1.6071793622868036

Epoch: 346| Step: 0
Training loss: 0.6371362805366516
Validation loss: 1.5962911754526117

Epoch: 5| Step: 1
Training loss: 0.9178613424301147
Validation loss: 1.5817581325448968

Epoch: 5| Step: 2
Training loss: 0.41494274139404297
Validation loss: 1.5618830214264572

Epoch: 5| Step: 3
Training loss: 0.4470699429512024
Validation loss: 1.5799409042122543

Epoch: 5| Step: 4
Training loss: 0.8680405616760254
Validation loss: 1.5738291086689118

Epoch: 5| Step: 5
Training loss: 0.4238179624080658
Validation loss: 1.579264147307283

Epoch: 5| Step: 6
Training loss: 0.2829812467098236
Validation loss: 1.5963149506558654

Epoch: 5| Step: 7
Training loss: 0.47925981879234314
Validation loss: 1.6092416676141883

Epoch: 5| Step: 8
Training loss: 0.4312472939491272
Validation loss: 1.610937596649252

Epoch: 5| Step: 9
Training loss: 0.3736196458339691
Validation loss: 1.6417074447037072

Epoch: 5| Step: 10
Training loss: 0.21772299706935883
Validation loss: 1.6380441355448898

Epoch: 347| Step: 0
Training loss: 0.6377458572387695
Validation loss: 1.6570716622055217

Epoch: 5| Step: 1
Training loss: 0.6008518934249878
Validation loss: 1.661368255974144

Epoch: 5| Step: 2
Training loss: 0.43965330719947815
Validation loss: 1.6562279642269175

Epoch: 5| Step: 3
Training loss: 0.5479120016098022
Validation loss: 1.6414203733526251

Epoch: 5| Step: 4
Training loss: 0.5487034320831299
Validation loss: 1.6408220337283226

Epoch: 5| Step: 5
Training loss: 0.3980339765548706
Validation loss: 1.6221487919489543

Epoch: 5| Step: 6
Training loss: 0.28203409910202026
Validation loss: 1.607877662104945

Epoch: 5| Step: 7
Training loss: 0.4962430000305176
Validation loss: 1.6262101511801443

Epoch: 5| Step: 8
Training loss: 0.507533073425293
Validation loss: 1.6023986595933155

Epoch: 5| Step: 9
Training loss: 0.4459436535835266
Validation loss: 1.6285827211154404

Epoch: 5| Step: 10
Training loss: 0.4693560302257538
Validation loss: 1.6185886616347938

Epoch: 348| Step: 0
Training loss: 0.33228424191474915
Validation loss: 1.6130764279314267

Epoch: 5| Step: 1
Training loss: 0.437974750995636
Validation loss: 1.6206809884758406

Epoch: 5| Step: 2
Training loss: 0.5813276767730713
Validation loss: 1.5990343709145822

Epoch: 5| Step: 3
Training loss: 0.49316462874412537
Validation loss: 1.6186301669766825

Epoch: 5| Step: 4
Training loss: 0.700255274772644
Validation loss: 1.6049297253290813

Epoch: 5| Step: 5
Training loss: 0.4606027603149414
Validation loss: 1.6062561504302486

Epoch: 5| Step: 6
Training loss: 0.3134552836418152
Validation loss: 1.610368881174313

Epoch: 5| Step: 7
Training loss: 0.3374837040901184
Validation loss: 1.6233258952376663

Epoch: 5| Step: 8
Training loss: 0.4731670022010803
Validation loss: 1.6221907356733918

Epoch: 5| Step: 9
Training loss: 0.8905537724494934
Validation loss: 1.6320145335248721

Epoch: 5| Step: 10
Training loss: 0.269825279712677
Validation loss: 1.660067658270559

Epoch: 349| Step: 0
Training loss: 0.5988423228263855
Validation loss: 1.6809274804207586

Epoch: 5| Step: 1
Training loss: 0.30789774656295776
Validation loss: 1.6754837971861645

Epoch: 5| Step: 2
Training loss: 0.5500161051750183
Validation loss: 1.6977801451119043

Epoch: 5| Step: 3
Training loss: 0.2089337408542633
Validation loss: 1.6847139379029632

Epoch: 5| Step: 4
Training loss: 0.5466222763061523
Validation loss: 1.6341236233711243

Epoch: 5| Step: 5
Training loss: 0.44825273752212524
Validation loss: 1.6487628875240203

Epoch: 5| Step: 6
Training loss: 0.6205474138259888
Validation loss: 1.6598846079200826

Epoch: 5| Step: 7
Training loss: 0.6183949708938599
Validation loss: 1.6447917671613796

Epoch: 5| Step: 8
Training loss: 0.3568406105041504
Validation loss: 1.6660231851762342

Epoch: 5| Step: 9
Training loss: 0.5707203149795532
Validation loss: 1.6565826503179406

Epoch: 5| Step: 10
Training loss: 0.7359580993652344
Validation loss: 1.6683826664442658

Epoch: 350| Step: 0
Training loss: 0.6505826711654663
Validation loss: 1.659473515325977

Epoch: 5| Step: 1
Training loss: 0.20686396956443787
Validation loss: 1.6459977165345223

Epoch: 5| Step: 2
Training loss: 0.40045323967933655
Validation loss: 1.654967168326019

Epoch: 5| Step: 3
Training loss: 0.5603398084640503
Validation loss: 1.6632751059788529

Epoch: 5| Step: 4
Training loss: 0.6447331309318542
Validation loss: 1.680192155222739

Epoch: 5| Step: 5
Training loss: 0.4491385519504547
Validation loss: 1.6926598318161503

Epoch: 5| Step: 6
Training loss: 0.6886033415794373
Validation loss: 1.7003535455273044

Epoch: 5| Step: 7
Training loss: 0.5808002352714539
Validation loss: 1.6805577034591346

Epoch: 5| Step: 8
Training loss: 0.5734028816223145
Validation loss: 1.6717000122993224

Epoch: 5| Step: 9
Training loss: 0.5460232496261597
Validation loss: 1.68996718365659

Epoch: 5| Step: 10
Training loss: 0.26505246758461
Validation loss: 1.6791086683991134

Epoch: 351| Step: 0
Training loss: 0.31251081824302673
Validation loss: 1.6775688778969549

Epoch: 5| Step: 1
Training loss: 0.5445832014083862
Validation loss: 1.6568617077283962

Epoch: 5| Step: 2
Training loss: 0.49748435616493225
Validation loss: 1.6202191383607927

Epoch: 5| Step: 3
Training loss: 0.6558108925819397
Validation loss: 1.6397367741471978

Epoch: 5| Step: 4
Training loss: 0.46515846252441406
Validation loss: 1.64180584620404

Epoch: 5| Step: 5
Training loss: 0.520046591758728
Validation loss: 1.628936057449669

Epoch: 5| Step: 6
Training loss: 0.4080875813961029
Validation loss: 1.6379059450600737

Epoch: 5| Step: 7
Training loss: 0.5535054206848145
Validation loss: 1.6568820976441907

Epoch: 5| Step: 8
Training loss: 0.49377602338790894
Validation loss: 1.6840743576326678

Epoch: 5| Step: 9
Training loss: 0.8875113725662231
Validation loss: 1.6654180929224978

Epoch: 5| Step: 10
Training loss: 0.19991753995418549
Validation loss: 1.6717382284902758

Epoch: 352| Step: 0
Training loss: 0.575472354888916
Validation loss: 1.6637185196722708

Epoch: 5| Step: 1
Training loss: 0.35432177782058716
Validation loss: 1.6558713515599568

Epoch: 5| Step: 2
Training loss: 0.6536918878555298
Validation loss: 1.6348463027707991

Epoch: 5| Step: 3
Training loss: 1.0046422481536865
Validation loss: 1.6008734767154982

Epoch: 5| Step: 4
Training loss: 0.53680819272995
Validation loss: 1.6088143202566332

Epoch: 5| Step: 5
Training loss: 0.4258464276790619
Validation loss: 1.6249403735642791

Epoch: 5| Step: 6
Training loss: 0.43113985657691956
Validation loss: 1.6154023665253834

Epoch: 5| Step: 7
Training loss: 0.2275676727294922
Validation loss: 1.6439190731253674

Epoch: 5| Step: 8
Training loss: 0.37923917174339294
Validation loss: 1.6029650652280418

Epoch: 5| Step: 9
Training loss: 0.661820113658905
Validation loss: 1.602597585288427

Epoch: 5| Step: 10
Training loss: 0.2597019076347351
Validation loss: 1.6138521035512288

Epoch: 353| Step: 0
Training loss: 0.5908137559890747
Validation loss: 1.606801120183801

Epoch: 5| Step: 1
Training loss: 0.6469420194625854
Validation loss: 1.6206958704097296

Epoch: 5| Step: 2
Training loss: 0.5728961229324341
Validation loss: 1.5744506005317933

Epoch: 5| Step: 3
Training loss: 0.471196711063385
Validation loss: 1.5960731865257345

Epoch: 5| Step: 4
Training loss: 0.2973824441432953
Validation loss: 1.6185400793629308

Epoch: 5| Step: 5
Training loss: 0.4963468909263611
Validation loss: 1.627684913655763

Epoch: 5| Step: 6
Training loss: 0.46179312467575073
Validation loss: 1.6225758457696566

Epoch: 5| Step: 7
Training loss: 0.40576761960983276
Validation loss: 1.6623461784855011

Epoch: 5| Step: 8
Training loss: 0.5306567549705505
Validation loss: 1.630715424014676

Epoch: 5| Step: 9
Training loss: 0.49020567536354065
Validation loss: 1.6696230288474792

Epoch: 5| Step: 10
Training loss: 0.29163798689842224
Validation loss: 1.6865433903150662

Epoch: 354| Step: 0
Training loss: 0.6343580484390259
Validation loss: 1.6999663870821717

Epoch: 5| Step: 1
Training loss: 0.38483676314353943
Validation loss: 1.6995425672941311

Epoch: 5| Step: 2
Training loss: 0.31647989153862
Validation loss: 1.6847706046155704

Epoch: 5| Step: 3
Training loss: 0.43572068214416504
Validation loss: 1.6264436693601712

Epoch: 5| Step: 4
Training loss: 0.6983286738395691
Validation loss: 1.597351340837376

Epoch: 5| Step: 5
Training loss: 0.5280631184577942
Validation loss: 1.6221602834681028

Epoch: 5| Step: 6
Training loss: 0.43585461378097534
Validation loss: 1.650588543184342

Epoch: 5| Step: 7
Training loss: 0.5940110087394714
Validation loss: 1.6485004463503439

Epoch: 5| Step: 8
Training loss: 0.4121161997318268
Validation loss: 1.6539255983086043

Epoch: 5| Step: 9
Training loss: 0.6286498308181763
Validation loss: 1.6807922778591033

Epoch: 5| Step: 10
Training loss: 0.39580395817756653
Validation loss: 1.6810676602907078

Epoch: 355| Step: 0
Training loss: 0.2576809823513031
Validation loss: 1.679019788260101

Epoch: 5| Step: 1
Training loss: 0.5366418957710266
Validation loss: 1.6760736409054007

Epoch: 5| Step: 2
Training loss: 0.5816318392753601
Validation loss: 1.6856758927786222

Epoch: 5| Step: 3
Training loss: 0.3623258173465729
Validation loss: 1.6879425382101407

Epoch: 5| Step: 4
Training loss: 0.855595588684082
Validation loss: 1.6432112660459293

Epoch: 5| Step: 5
Training loss: 0.4474850296974182
Validation loss: 1.6098281542460124

Epoch: 5| Step: 6
Training loss: 0.4219115674495697
Validation loss: 1.6188409059278426

Epoch: 5| Step: 7
Training loss: 0.3882722854614258
Validation loss: 1.6254871353026359

Epoch: 5| Step: 8
Training loss: 0.4860672950744629
Validation loss: 1.6250551028918194

Epoch: 5| Step: 9
Training loss: 0.3333796262741089
Validation loss: 1.6312383554315055

Epoch: 5| Step: 10
Training loss: 0.5117235779762268
Validation loss: 1.6140846731842204

Epoch: 356| Step: 0
Training loss: 0.42486947774887085
Validation loss: 1.6611874731638099

Epoch: 5| Step: 1
Training loss: 0.4806864261627197
Validation loss: 1.7098640908477127

Epoch: 5| Step: 2
Training loss: 0.6123774647712708
Validation loss: 1.686499011132025

Epoch: 5| Step: 3
Training loss: 0.45373597741127014
Validation loss: 1.7084065970554148

Epoch: 5| Step: 4
Training loss: 0.2800785005092621
Validation loss: 1.7023379661703621

Epoch: 5| Step: 5
Training loss: 0.378258615732193
Validation loss: 1.7009583801351569

Epoch: 5| Step: 6
Training loss: 0.48603230714797974
Validation loss: 1.725463572368827

Epoch: 5| Step: 7
Training loss: 0.8099279403686523
Validation loss: 1.69902209056321

Epoch: 5| Step: 8
Training loss: 0.623374342918396
Validation loss: 1.6990282715007823

Epoch: 5| Step: 9
Training loss: 0.35051193833351135
Validation loss: 1.6994683665613974

Epoch: 5| Step: 10
Training loss: 0.3853744864463806
Validation loss: 1.7022741648458666

Epoch: 357| Step: 0
Training loss: 0.5395880937576294
Validation loss: 1.710233833200188

Epoch: 5| Step: 1
Training loss: 0.36365807056427
Validation loss: 1.7224609595473095

Epoch: 5| Step: 2
Training loss: 0.20945310592651367
Validation loss: 1.6742220924746605

Epoch: 5| Step: 3
Training loss: 0.45425739884376526
Validation loss: 1.6447825367732714

Epoch: 5| Step: 4
Training loss: 0.7568708658218384
Validation loss: 1.6113399805561188

Epoch: 5| Step: 5
Training loss: 0.37569737434387207
Validation loss: 1.612731469574795

Epoch: 5| Step: 6
Training loss: 0.544739842414856
Validation loss: 1.6140704731787405

Epoch: 5| Step: 7
Training loss: 0.37989744544029236
Validation loss: 1.6126615911401727

Epoch: 5| Step: 8
Training loss: 0.5295718312263489
Validation loss: 1.6120931307474773

Epoch: 5| Step: 9
Training loss: 0.46943753957748413
Validation loss: 1.5880797037514307

Epoch: 5| Step: 10
Training loss: 0.46004512906074524
Validation loss: 1.658213665408473

Epoch: 358| Step: 0
Training loss: 0.5263260006904602
Validation loss: 1.6592788837289298

Epoch: 5| Step: 1
Training loss: 0.26229938864707947
Validation loss: 1.6454397965502996

Epoch: 5| Step: 2
Training loss: 0.6728464961051941
Validation loss: 1.6377803689690047

Epoch: 5| Step: 3
Training loss: 0.588962733745575
Validation loss: 1.638358167422715

Epoch: 5| Step: 4
Training loss: 0.33156371116638184
Validation loss: 1.5977970118163733

Epoch: 5| Step: 5
Training loss: 0.5277806520462036
Validation loss: 1.593759193215319

Epoch: 5| Step: 6
Training loss: 0.5661444067955017
Validation loss: 1.6237196960756857

Epoch: 5| Step: 7
Training loss: 0.5082522034645081
Validation loss: 1.5910342162655247

Epoch: 5| Step: 8
Training loss: 0.3310471177101135
Validation loss: 1.6093927314204555

Epoch: 5| Step: 9
Training loss: 0.3136295676231384
Validation loss: 1.617651383082072

Epoch: 5| Step: 10
Training loss: 0.3907930254936218
Validation loss: 1.6488340887972104

Epoch: 359| Step: 0
Training loss: 0.29275575280189514
Validation loss: 1.6728607941699285

Epoch: 5| Step: 1
Training loss: 0.6112073659896851
Validation loss: 1.6467603919326619

Epoch: 5| Step: 2
Training loss: 0.44239336252212524
Validation loss: 1.6488174084694154

Epoch: 5| Step: 3
Training loss: 0.4754887521266937
Validation loss: 1.636418237481066

Epoch: 5| Step: 4
Training loss: 0.5767557621002197
Validation loss: 1.6232352359320528

Epoch: 5| Step: 5
Training loss: 0.3212946057319641
Validation loss: 1.6445943001777894

Epoch: 5| Step: 6
Training loss: 0.507030189037323
Validation loss: 1.6538841762850363

Epoch: 5| Step: 7
Training loss: 0.42716747522354126
Validation loss: 1.6672628118145851

Epoch: 5| Step: 8
Training loss: 0.3110326826572418
Validation loss: 1.6297729162759678

Epoch: 5| Step: 9
Training loss: 0.39690104126930237
Validation loss: 1.6177537133616786

Epoch: 5| Step: 10
Training loss: 0.6045889258384705
Validation loss: 1.620531625645135

Epoch: 360| Step: 0
Training loss: 0.3349672257900238
Validation loss: 1.6217738710423952

Epoch: 5| Step: 1
Training loss: 0.6917455196380615
Validation loss: 1.6462313180328698

Epoch: 5| Step: 2
Training loss: 0.44619616866111755
Validation loss: 1.6242096552284815

Epoch: 5| Step: 3
Training loss: 0.30938541889190674
Validation loss: 1.5963785827800792

Epoch: 5| Step: 4
Training loss: 0.3037724494934082
Validation loss: 1.6309769615050285

Epoch: 5| Step: 5
Training loss: 0.5771182179450989
Validation loss: 1.642665155472294

Epoch: 5| Step: 6
Training loss: 0.4323903024196625
Validation loss: 1.6409932746682117

Epoch: 5| Step: 7
Training loss: 0.3915254473686218
Validation loss: 1.6421240055432884

Epoch: 5| Step: 8
Training loss: 0.39514580368995667
Validation loss: 1.6064025407196374

Epoch: 5| Step: 9
Training loss: 0.5997920036315918
Validation loss: 1.5941352728874452

Epoch: 5| Step: 10
Training loss: 0.3960139751434326
Validation loss: 1.6221986816775413

Epoch: 361| Step: 0
Training loss: 0.6062405705451965
Validation loss: 1.6056160234635877

Epoch: 5| Step: 1
Training loss: 0.5016984343528748
Validation loss: 1.5686963245432863

Epoch: 5| Step: 2
Training loss: 0.2930282652378082
Validation loss: 1.5782980816338652

Epoch: 5| Step: 3
Training loss: 0.5680416822433472
Validation loss: 1.5803353030194518

Epoch: 5| Step: 4
Training loss: 0.632829487323761
Validation loss: 1.6027357783368839

Epoch: 5| Step: 5
Training loss: 0.26235780119895935
Validation loss: 1.5925996393285773

Epoch: 5| Step: 6
Training loss: 0.34568771719932556
Validation loss: 1.5887355368624452

Epoch: 5| Step: 7
Training loss: 0.4482094347476959
Validation loss: 1.6235426215715305

Epoch: 5| Step: 8
Training loss: 0.38984647393226624
Validation loss: 1.6285450868709113

Epoch: 5| Step: 9
Training loss: 0.4304911494255066
Validation loss: 1.631470585382113

Epoch: 5| Step: 10
Training loss: 0.4640786051750183
Validation loss: 1.6443947950998943

Epoch: 362| Step: 0
Training loss: 0.29401540756225586
Validation loss: 1.6118561183252642

Epoch: 5| Step: 1
Training loss: 0.28565874695777893
Validation loss: 1.627279766144291

Epoch: 5| Step: 2
Training loss: 0.5452368855476379
Validation loss: 1.6174484722075924

Epoch: 5| Step: 3
Training loss: 0.3622288107872009
Validation loss: 1.653356590578633

Epoch: 5| Step: 4
Training loss: 0.3245540261268616
Validation loss: 1.6558774491792083

Epoch: 5| Step: 5
Training loss: 0.45793890953063965
Validation loss: 1.6543574333190918

Epoch: 5| Step: 6
Training loss: 0.5785037279129028
Validation loss: 1.6894568538153043

Epoch: 5| Step: 7
Training loss: 0.4148206114768982
Validation loss: 1.6668423978231286

Epoch: 5| Step: 8
Training loss: 0.6330262422561646
Validation loss: 1.6795863977042578

Epoch: 5| Step: 9
Training loss: 0.506260871887207
Validation loss: 1.7020505218095676

Epoch: 5| Step: 10
Training loss: 0.35359370708465576
Validation loss: 1.6798768312700334

Epoch: 363| Step: 0
Training loss: 0.797452449798584
Validation loss: 1.687395829026417

Epoch: 5| Step: 1
Training loss: 0.4855281412601471
Validation loss: 1.6689878432981429

Epoch: 5| Step: 2
Training loss: 0.4321441054344177
Validation loss: 1.6417915654438797

Epoch: 5| Step: 3
Training loss: 0.5563583374023438
Validation loss: 1.6274167978635399

Epoch: 5| Step: 4
Training loss: 0.20631758868694305
Validation loss: 1.6151084771720312

Epoch: 5| Step: 5
Training loss: 0.431417316198349
Validation loss: 1.6344230187836515

Epoch: 5| Step: 6
Training loss: 0.3758004903793335
Validation loss: 1.6285000026866954

Epoch: 5| Step: 7
Training loss: 0.2708583474159241
Validation loss: 1.585102540190502

Epoch: 5| Step: 8
Training loss: 0.5099915266036987
Validation loss: 1.602724454736197

Epoch: 5| Step: 9
Training loss: 0.47984910011291504
Validation loss: 1.6362804840969782

Epoch: 5| Step: 10
Training loss: 0.27197203040122986
Validation loss: 1.6559055530896751

Epoch: 364| Step: 0
Training loss: 0.33077365159988403
Validation loss: 1.6708257839243899

Epoch: 5| Step: 1
Training loss: 0.530269205570221
Validation loss: 1.6793859286974835

Epoch: 5| Step: 2
Training loss: 0.31008970737457275
Validation loss: 1.6347857457335278

Epoch: 5| Step: 3
Training loss: 0.3864152729511261
Validation loss: 1.6203797145556378

Epoch: 5| Step: 4
Training loss: 0.6410857439041138
Validation loss: 1.628531156047698

Epoch: 5| Step: 5
Training loss: 0.7567474246025085
Validation loss: 1.6311172208478373

Epoch: 5| Step: 6
Training loss: 0.3216472268104553
Validation loss: 1.6275071264595113

Epoch: 5| Step: 7
Training loss: 0.3498378396034241
Validation loss: 1.6223492801830333

Epoch: 5| Step: 8
Training loss: 0.6108227968215942
Validation loss: 1.6399681875782628

Epoch: 5| Step: 9
Training loss: 0.3688139319419861
Validation loss: 1.6218052500037736

Epoch: 5| Step: 10
Training loss: 0.37966370582580566
Validation loss: 1.65619493556279

Epoch: 365| Step: 0
Training loss: 0.5539804697036743
Validation loss: 1.647785243167672

Epoch: 5| Step: 1
Training loss: 0.2516056001186371
Validation loss: 1.6664956718362787

Epoch: 5| Step: 2
Training loss: 0.49461817741394043
Validation loss: 1.6946451202515633

Epoch: 5| Step: 3
Training loss: 0.40446925163269043
Validation loss: 1.6819117761427356

Epoch: 5| Step: 4
Training loss: 0.2888675332069397
Validation loss: 1.6659185527473368

Epoch: 5| Step: 5
Training loss: 0.3239278495311737
Validation loss: 1.6676786753439135

Epoch: 5| Step: 6
Training loss: 0.4102246165275574
Validation loss: 1.5826482042189567

Epoch: 5| Step: 7
Training loss: 0.7401338815689087
Validation loss: 1.606710789024189

Epoch: 5| Step: 8
Training loss: 0.49354010820388794
Validation loss: 1.5972205349194106

Epoch: 5| Step: 9
Training loss: 0.3529373109340668
Validation loss: 1.5990960636446554

Epoch: 5| Step: 10
Training loss: 0.3760814666748047
Validation loss: 1.5985538510866062

Epoch: 366| Step: 0
Training loss: 0.5788832902908325
Validation loss: 1.6035328065195391

Epoch: 5| Step: 1
Training loss: 0.5644385814666748
Validation loss: 1.6137464277205928

Epoch: 5| Step: 2
Training loss: 0.4435862898826599
Validation loss: 1.6283485850980204

Epoch: 5| Step: 3
Training loss: 0.26938313245773315
Validation loss: 1.633327543094594

Epoch: 5| Step: 4
Training loss: 0.27721551060676575
Validation loss: 1.6110833473103021

Epoch: 5| Step: 5
Training loss: 0.5474019050598145
Validation loss: 1.6509296919709893

Epoch: 5| Step: 6
Training loss: 0.5137630701065063
Validation loss: 1.6692445444804367

Epoch: 5| Step: 7
Training loss: 0.6104799509048462
Validation loss: 1.6766849487058577

Epoch: 5| Step: 8
Training loss: 0.424032598733902
Validation loss: 1.6680403999103013

Epoch: 5| Step: 9
Training loss: 0.28644034266471863
Validation loss: 1.681645579235528

Epoch: 5| Step: 10
Training loss: 0.0728049948811531
Validation loss: 1.6640236864807785

Epoch: 367| Step: 0
Training loss: 0.7137327194213867
Validation loss: 1.6340651435236777

Epoch: 5| Step: 1
Training loss: 0.4434192180633545
Validation loss: 1.6275811451737598

Epoch: 5| Step: 2
Training loss: 0.26761898398399353
Validation loss: 1.6163300121984174

Epoch: 5| Step: 3
Training loss: 0.6178171038627625
Validation loss: 1.622249932699306

Epoch: 5| Step: 4
Training loss: 0.3482465147972107
Validation loss: 1.6562272938348914

Epoch: 5| Step: 5
Training loss: 0.3719766139984131
Validation loss: 1.6577803934774091

Epoch: 5| Step: 6
Training loss: 0.36570441722869873
Validation loss: 1.699775613764281

Epoch: 5| Step: 7
Training loss: 0.32985609769821167
Validation loss: 1.7325224543130526

Epoch: 5| Step: 8
Training loss: 0.2433241307735443
Validation loss: 1.7753328866856073

Epoch: 5| Step: 9
Training loss: 0.4937240481376648
Validation loss: 1.7363265534882903

Epoch: 5| Step: 10
Training loss: 0.5200647711753845
Validation loss: 1.7141980663422616

Epoch: 368| Step: 0
Training loss: 0.5109074711799622
Validation loss: 1.6778675561310143

Epoch: 5| Step: 1
Training loss: 0.44761958718299866
Validation loss: 1.644252811708758

Epoch: 5| Step: 2
Training loss: 0.4371815621852875
Validation loss: 1.6688411710082844

Epoch: 5| Step: 3
Training loss: 0.43097177147865295
Validation loss: 1.637394384671283

Epoch: 5| Step: 4
Training loss: 0.256681889295578
Validation loss: 1.6300456728986514

Epoch: 5| Step: 5
Training loss: 0.32798951864242554
Validation loss: 1.6306658919139574

Epoch: 5| Step: 6
Training loss: 0.6756558418273926
Validation loss: 1.65039526390773

Epoch: 5| Step: 7
Training loss: 0.11406079679727554
Validation loss: 1.6212784481304947

Epoch: 5| Step: 8
Training loss: 0.36296242475509644
Validation loss: 1.6225079003200735

Epoch: 5| Step: 9
Training loss: 0.5558351874351501
Validation loss: 1.602719203118355

Epoch: 5| Step: 10
Training loss: 0.32961374521255493
Validation loss: 1.5975147011459514

Epoch: 369| Step: 0
Training loss: 0.3392007350921631
Validation loss: 1.5813801019422469

Epoch: 5| Step: 1
Training loss: 0.5101121664047241
Validation loss: 1.5916133644760295

Epoch: 5| Step: 2
Training loss: 0.44447341561317444
Validation loss: 1.6196407771879626

Epoch: 5| Step: 3
Training loss: 0.27843159437179565
Validation loss: 1.588799141427522

Epoch: 5| Step: 4
Training loss: 0.528162956237793
Validation loss: 1.6269114325123448

Epoch: 5| Step: 5
Training loss: 0.43199044466018677
Validation loss: 1.637751974085326

Epoch: 5| Step: 6
Training loss: 0.4868079721927643
Validation loss: 1.635265955360987

Epoch: 5| Step: 7
Training loss: 0.2900952398777008
Validation loss: 1.6441259922519806

Epoch: 5| Step: 8
Training loss: 0.4031405448913574
Validation loss: 1.660815392771075

Epoch: 5| Step: 9
Training loss: 0.2925543487071991
Validation loss: 1.6620178056019608

Epoch: 5| Step: 10
Training loss: 0.6537111401557922
Validation loss: 1.6617673238118489

Epoch: 370| Step: 0
Training loss: 0.5898560285568237
Validation loss: 1.6436700064648864

Epoch: 5| Step: 1
Training loss: 0.39141273498535156
Validation loss: 1.6264519563285254

Epoch: 5| Step: 2
Training loss: 0.3344247341156006
Validation loss: 1.601512162916122

Epoch: 5| Step: 3
Training loss: 0.3884105384349823
Validation loss: 1.5999017723145024

Epoch: 5| Step: 4
Training loss: 0.45909276604652405
Validation loss: 1.609826204597309

Epoch: 5| Step: 5
Training loss: 0.30975109338760376
Validation loss: 1.5879203568222702

Epoch: 5| Step: 6
Training loss: 0.48254841566085815
Validation loss: 1.610805880638861

Epoch: 5| Step: 7
Training loss: 0.4521564543247223
Validation loss: 1.6016479640878656

Epoch: 5| Step: 8
Training loss: 0.36964452266693115
Validation loss: 1.613725225130717

Epoch: 5| Step: 9
Training loss: 0.3393089771270752
Validation loss: 1.6090611924407303

Epoch: 5| Step: 10
Training loss: 0.5502369403839111
Validation loss: 1.623632925812916

Epoch: 371| Step: 0
Training loss: 0.14653238654136658
Validation loss: 1.6468491887533536

Epoch: 5| Step: 1
Training loss: 0.162271648645401
Validation loss: 1.665283428725376

Epoch: 5| Step: 2
Training loss: 0.36263319849967957
Validation loss: 1.6724717065852175

Epoch: 5| Step: 3
Training loss: 0.9965936541557312
Validation loss: 1.6529280613827448

Epoch: 5| Step: 4
Training loss: 0.3896827697753906
Validation loss: 1.641391368322475

Epoch: 5| Step: 5
Training loss: 0.3775973618030548
Validation loss: 1.6486697709688576

Epoch: 5| Step: 6
Training loss: 0.5525404214859009
Validation loss: 1.6130192472088722

Epoch: 5| Step: 7
Training loss: 0.33952444791793823
Validation loss: 1.5995564204390331

Epoch: 5| Step: 8
Training loss: 0.49932020902633667
Validation loss: 1.6069016354058379

Epoch: 5| Step: 9
Training loss: 0.5400859713554382
Validation loss: 1.6193941664952103

Epoch: 5| Step: 10
Training loss: 0.3445177674293518
Validation loss: 1.602813534839179

Epoch: 372| Step: 0
Training loss: 0.3036118149757385
Validation loss: 1.6000627497191071

Epoch: 5| Step: 1
Training loss: 0.3238063156604767
Validation loss: 1.6250265631624448

Epoch: 5| Step: 2
Training loss: 0.3873422145843506
Validation loss: 1.6320283707752024

Epoch: 5| Step: 3
Training loss: 0.6580894589424133
Validation loss: 1.6491652893763717

Epoch: 5| Step: 4
Training loss: 0.42724162340164185
Validation loss: 1.6671409017296248

Epoch: 5| Step: 5
Training loss: 0.40293630957603455
Validation loss: 1.6852901635631439

Epoch: 5| Step: 6
Training loss: 0.2930750548839569
Validation loss: 1.660619125571302

Epoch: 5| Step: 7
Training loss: 0.5635343194007874
Validation loss: 1.66308226636661

Epoch: 5| Step: 8
Training loss: 0.3363495469093323
Validation loss: 1.6365902103403562

Epoch: 5| Step: 9
Training loss: 0.31665536761283875
Validation loss: 1.626046146115949

Epoch: 5| Step: 10
Training loss: 0.4344974756240845
Validation loss: 1.6130818538768317

Epoch: 373| Step: 0
Training loss: 0.24452564120292664
Validation loss: 1.5961197781306442

Epoch: 5| Step: 1
Training loss: 0.3280709683895111
Validation loss: 1.5775958722637546

Epoch: 5| Step: 2
Training loss: 0.3919987082481384
Validation loss: 1.5799296171434465

Epoch: 5| Step: 3
Training loss: 0.4115089774131775
Validation loss: 1.5714481440923547

Epoch: 5| Step: 4
Training loss: 0.36003684997558594
Validation loss: 1.6066261645286315

Epoch: 5| Step: 5
Training loss: 0.38331303000450134
Validation loss: 1.595177169769041

Epoch: 5| Step: 6
Training loss: 0.6205064058303833
Validation loss: 1.6314351353594052

Epoch: 5| Step: 7
Training loss: 0.3012416362762451
Validation loss: 1.6587307690292277

Epoch: 5| Step: 8
Training loss: 0.3723452687263489
Validation loss: 1.6505717731291247

Epoch: 5| Step: 9
Training loss: 0.6974126696586609
Validation loss: 1.652448285010553

Epoch: 5| Step: 10
Training loss: 0.3217203617095947
Validation loss: 1.632262473465294

Epoch: 374| Step: 0
Training loss: 0.31549134850502014
Validation loss: 1.6166382092301563

Epoch: 5| Step: 1
Training loss: 0.3517315983772278
Validation loss: 1.6325150510316253

Epoch: 5| Step: 2
Training loss: 0.4102516174316406
Validation loss: 1.6580393109270322

Epoch: 5| Step: 3
Training loss: 0.5921512842178345
Validation loss: 1.6752104413124822

Epoch: 5| Step: 4
Training loss: 0.29525670409202576
Validation loss: 1.6400288048610892

Epoch: 5| Step: 5
Training loss: 0.4366745352745056
Validation loss: 1.6425875079247259

Epoch: 5| Step: 6
Training loss: 0.6725513935089111
Validation loss: 1.6085228343163767

Epoch: 5| Step: 7
Training loss: 0.3804205060005188
Validation loss: 1.6070602593883392

Epoch: 5| Step: 8
Training loss: 0.3941841125488281
Validation loss: 1.571545054835658

Epoch: 5| Step: 9
Training loss: 0.3136045038700104
Validation loss: 1.590309678867299

Epoch: 5| Step: 10
Training loss: 0.2575478255748749
Validation loss: 1.5730525242385043

Epoch: 375| Step: 0
Training loss: 0.28509050607681274
Validation loss: 1.5761655607531149

Epoch: 5| Step: 1
Training loss: 0.7291865348815918
Validation loss: 1.6035414588066839

Epoch: 5| Step: 2
Training loss: 0.39532527327537537
Validation loss: 1.5978467310628583

Epoch: 5| Step: 3
Training loss: 0.3274517059326172
Validation loss: 1.6133197161459154

Epoch: 5| Step: 4
Training loss: 0.5033601522445679
Validation loss: 1.6164739567746398

Epoch: 5| Step: 5
Training loss: 0.48256024718284607
Validation loss: 1.6292398591195383

Epoch: 5| Step: 6
Training loss: 0.4000677168369293
Validation loss: 1.5929204212721957

Epoch: 5| Step: 7
Training loss: 0.24726024270057678
Validation loss: 1.6466380101378246

Epoch: 5| Step: 8
Training loss: 0.5129562020301819
Validation loss: 1.6278591514915548

Epoch: 5| Step: 9
Training loss: 0.23821964859962463
Validation loss: 1.6404559637910576

Epoch: 5| Step: 10
Training loss: 0.3868899643421173
Validation loss: 1.6099108008928196

Epoch: 376| Step: 0
Training loss: 0.32417863607406616
Validation loss: 1.6186818025445426

Epoch: 5| Step: 1
Training loss: 0.2364472895860672
Validation loss: 1.63171600526379

Epoch: 5| Step: 2
Training loss: 0.3068349063396454
Validation loss: 1.6327935611048052

Epoch: 5| Step: 3
Training loss: 0.5318595170974731
Validation loss: 1.6363982795387186

Epoch: 5| Step: 4
Training loss: 0.505678653717041
Validation loss: 1.6128596580156715

Epoch: 5| Step: 5
Training loss: 0.47746872901916504
Validation loss: 1.6436149702277234

Epoch: 5| Step: 6
Training loss: 0.27143654227256775
Validation loss: 1.642318194912326

Epoch: 5| Step: 7
Training loss: 0.3046577572822571
Validation loss: 1.6648175562581708

Epoch: 5| Step: 8
Training loss: 0.33602434396743774
Validation loss: 1.674314486083164

Epoch: 5| Step: 9
Training loss: 0.6622791290283203
Validation loss: 1.6758982186676354

Epoch: 5| Step: 10
Training loss: 0.4008699357509613
Validation loss: 1.6522814227688698

Epoch: 377| Step: 0
Training loss: 0.1260276734828949
Validation loss: 1.6664683959817375

Epoch: 5| Step: 1
Training loss: 0.19374552369117737
Validation loss: 1.6283729089203702

Epoch: 5| Step: 2
Training loss: 0.23660893738269806
Validation loss: 1.629748664876466

Epoch: 5| Step: 3
Training loss: 0.40586400032043457
Validation loss: 1.6216586366776498

Epoch: 5| Step: 4
Training loss: 0.24906668066978455
Validation loss: 1.6104021168524218

Epoch: 5| Step: 5
Training loss: 0.2231670320034027
Validation loss: 1.6088593416316535

Epoch: 5| Step: 6
Training loss: 0.5246367454528809
Validation loss: 1.6049702359784035

Epoch: 5| Step: 7
Training loss: 0.5124444961547852
Validation loss: 1.6406333292684248

Epoch: 5| Step: 8
Training loss: 0.5689563751220703
Validation loss: 1.6523735061768563

Epoch: 5| Step: 9
Training loss: 0.7049252390861511
Validation loss: 1.6594347876887168

Epoch: 5| Step: 10
Training loss: 0.5624145269393921
Validation loss: 1.6435056514637445

Epoch: 378| Step: 0
Training loss: 0.4281481206417084
Validation loss: 1.6620893965485275

Epoch: 5| Step: 1
Training loss: 0.16444149613380432
Validation loss: 1.6699258742793914

Epoch: 5| Step: 2
Training loss: 0.2913454473018646
Validation loss: 1.6922306373555174

Epoch: 5| Step: 3
Training loss: 0.5291697978973389
Validation loss: 1.666656909450408

Epoch: 5| Step: 4
Training loss: 0.4006483554840088
Validation loss: 1.6652985939415552

Epoch: 5| Step: 5
Training loss: 0.5396722555160522
Validation loss: 1.619350997350549

Epoch: 5| Step: 6
Training loss: 0.6413137316703796
Validation loss: 1.6092890244658276

Epoch: 5| Step: 7
Training loss: 0.5008190870285034
Validation loss: 1.5923320221644577

Epoch: 5| Step: 8
Training loss: 0.29919537901878357
Validation loss: 1.5566487543044552

Epoch: 5| Step: 9
Training loss: 0.21844330430030823
Validation loss: 1.595247850623182

Epoch: 5| Step: 10
Training loss: 0.241022527217865
Validation loss: 1.5910164425449986

Epoch: 379| Step: 0
Training loss: 0.571532130241394
Validation loss: 1.6008743970624861

Epoch: 5| Step: 1
Training loss: 0.44209781289100647
Validation loss: 1.653952169161971

Epoch: 5| Step: 2
Training loss: 0.31091398000717163
Validation loss: 1.6016848189856416

Epoch: 5| Step: 3
Training loss: 0.3927638828754425
Validation loss: 1.6492919306601248

Epoch: 5| Step: 4
Training loss: 0.34308916330337524
Validation loss: 1.6265373781163206

Epoch: 5| Step: 5
Training loss: 0.38653644919395447
Validation loss: 1.5955807662779284

Epoch: 5| Step: 6
Training loss: 0.22576279938220978
Validation loss: 1.5759029792201134

Epoch: 5| Step: 7
Training loss: 0.5218032002449036
Validation loss: 1.5718718587711293

Epoch: 5| Step: 8
Training loss: 0.383046954870224
Validation loss: 1.6005943834140737

Epoch: 5| Step: 9
Training loss: 0.4830626845359802
Validation loss: 1.553478746004002

Epoch: 5| Step: 10
Training loss: 0.4459020793437958
Validation loss: 1.5812241531187488

Epoch: 380| Step: 0
Training loss: 0.24118070304393768
Validation loss: 1.587434313630545

Epoch: 5| Step: 1
Training loss: 0.5397394895553589
Validation loss: 1.6328841114556918

Epoch: 5| Step: 2
Training loss: 0.3583917021751404
Validation loss: 1.6350781340752878

Epoch: 5| Step: 3
Training loss: 0.3597795069217682
Validation loss: 1.6580695567592498

Epoch: 5| Step: 4
Training loss: 0.5644901394844055
Validation loss: 1.669495581298746

Epoch: 5| Step: 5
Training loss: 0.3273243308067322
Validation loss: 1.6982401635057183

Epoch: 5| Step: 6
Training loss: 0.3954930007457733
Validation loss: 1.6695616091451337

Epoch: 5| Step: 7
Training loss: 0.27699607610702515
Validation loss: 1.6639236596322828

Epoch: 5| Step: 8
Training loss: 0.20124006271362305
Validation loss: 1.6529577034775929

Epoch: 5| Step: 9
Training loss: 0.5803230404853821
Validation loss: 1.6465338494188042

Epoch: 5| Step: 10
Training loss: 0.321636825799942
Validation loss: 1.6466022358145764

Epoch: 381| Step: 0
Training loss: 0.3287612497806549
Validation loss: 1.6495409742478402

Epoch: 5| Step: 1
Training loss: 0.385500967502594
Validation loss: 1.677499036635122

Epoch: 5| Step: 2
Training loss: 0.40791672468185425
Validation loss: 1.6736424328178487

Epoch: 5| Step: 3
Training loss: 0.4290817677974701
Validation loss: 1.6605904756053802

Epoch: 5| Step: 4
Training loss: 0.4170714318752289
Validation loss: 1.6708357667410245

Epoch: 5| Step: 5
Training loss: 0.23852679133415222
Validation loss: 1.6822624975635159

Epoch: 5| Step: 6
Training loss: 0.3567003607749939
Validation loss: 1.6639040413723196

Epoch: 5| Step: 7
Training loss: 0.29926204681396484
Validation loss: 1.6499213608362342

Epoch: 5| Step: 8
Training loss: 0.25668758153915405
Validation loss: 1.666176772886707

Epoch: 5| Step: 9
Training loss: 0.5264493227005005
Validation loss: 1.6588203291739188

Epoch: 5| Step: 10
Training loss: 0.3130190372467041
Validation loss: 1.6535318679707025

Epoch: 382| Step: 0
Training loss: 0.27116915583610535
Validation loss: 1.6346011469441075

Epoch: 5| Step: 1
Training loss: 0.35994964838027954
Validation loss: 1.6213053810981013

Epoch: 5| Step: 2
Training loss: 0.14183218777179718
Validation loss: 1.6034626730026738

Epoch: 5| Step: 3
Training loss: 0.4067886471748352
Validation loss: 1.6043484287877237

Epoch: 5| Step: 4
Training loss: 0.494286447763443
Validation loss: 1.6401337961996756

Epoch: 5| Step: 5
Training loss: 0.4242924749851227
Validation loss: 1.6374234871197773

Epoch: 5| Step: 6
Training loss: 0.32166045904159546
Validation loss: 1.6512794930447814

Epoch: 5| Step: 7
Training loss: 0.7747395634651184
Validation loss: 1.64783844383814

Epoch: 5| Step: 8
Training loss: 0.32490992546081543
Validation loss: 1.679569839149393

Epoch: 5| Step: 9
Training loss: 0.5860167741775513
Validation loss: 1.664675622858027

Epoch: 5| Step: 10
Training loss: 0.1963135004043579
Validation loss: 1.6456887247741863

Epoch: 383| Step: 0
Training loss: 0.40064993500709534
Validation loss: 1.6545827504127257

Epoch: 5| Step: 1
Training loss: 0.22784562408924103
Validation loss: 1.644020665076471

Epoch: 5| Step: 2
Training loss: 0.46600574254989624
Validation loss: 1.6168256549425022

Epoch: 5| Step: 3
Training loss: 0.39126020669937134
Validation loss: 1.6272735672612344

Epoch: 5| Step: 4
Training loss: 0.5084086656570435
Validation loss: 1.6073546076333651

Epoch: 5| Step: 5
Training loss: 0.6731911897659302
Validation loss: 1.6320902121964322

Epoch: 5| Step: 6
Training loss: 0.28312772512435913
Validation loss: 1.590336799621582

Epoch: 5| Step: 7
Training loss: 0.25829780101776123
Validation loss: 1.601292606322996

Epoch: 5| Step: 8
Training loss: 0.4893629550933838
Validation loss: 1.6421422266191052

Epoch: 5| Step: 9
Training loss: 0.25916844606399536
Validation loss: 1.642949027399863

Epoch: 5| Step: 10
Training loss: 0.23371896147727966
Validation loss: 1.6137344337278796

Epoch: 384| Step: 0
Training loss: 0.3046819269657135
Validation loss: 1.6422177245540004

Epoch: 5| Step: 1
Training loss: 0.38007229566574097
Validation loss: 1.619869687223947

Epoch: 5| Step: 2
Training loss: 0.43945854902267456
Validation loss: 1.6536254934085313

Epoch: 5| Step: 3
Training loss: 0.3573741018772125
Validation loss: 1.5988583654485724

Epoch: 5| Step: 4
Training loss: 0.5275987982749939
Validation loss: 1.5842257520203948

Epoch: 5| Step: 5
Training loss: 0.22922153770923615
Validation loss: 1.5871634867883497

Epoch: 5| Step: 6
Training loss: 0.48815011978149414
Validation loss: 1.5837954193033197

Epoch: 5| Step: 7
Training loss: 0.4630557596683502
Validation loss: 1.5792458993132397

Epoch: 5| Step: 8
Training loss: 0.2908708453178406
Validation loss: 1.608002349894534

Epoch: 5| Step: 9
Training loss: 0.2486691027879715
Validation loss: 1.6639656712931972

Epoch: 5| Step: 10
Training loss: 0.38497498631477356
Validation loss: 1.635868740338151

Epoch: 385| Step: 0
Training loss: 0.2695063054561615
Validation loss: 1.646469070065406

Epoch: 5| Step: 1
Training loss: 0.26113948225975037
Validation loss: 1.646433259851189

Epoch: 5| Step: 2
Training loss: 0.28790968656539917
Validation loss: 1.6458187474999377

Epoch: 5| Step: 3
Training loss: 0.2522103190422058
Validation loss: 1.6646805963208597

Epoch: 5| Step: 4
Training loss: 0.40461477637290955
Validation loss: 1.6441227479647564

Epoch: 5| Step: 5
Training loss: 0.24277658760547638
Validation loss: 1.6725124351439937

Epoch: 5| Step: 6
Training loss: 0.4761642515659332
Validation loss: 1.6721938322949153

Epoch: 5| Step: 7
Training loss: 0.5131492018699646
Validation loss: 1.6724555876947218

Epoch: 5| Step: 8
Training loss: 0.33461230993270874
Validation loss: 1.667969144800658

Epoch: 5| Step: 9
Training loss: 0.4343147277832031
Validation loss: 1.6299750689537293

Epoch: 5| Step: 10
Training loss: 0.6142225861549377
Validation loss: 1.6603672735152706

Epoch: 386| Step: 0
Training loss: 0.34231019020080566
Validation loss: 1.6770142611636911

Epoch: 5| Step: 1
Training loss: 0.27934619784355164
Validation loss: 1.6426884346110846

Epoch: 5| Step: 2
Training loss: 0.5630086660385132
Validation loss: 1.6436275179668138

Epoch: 5| Step: 3
Training loss: 0.32517382502555847
Validation loss: 1.6208101664820025

Epoch: 5| Step: 4
Training loss: 0.28575408458709717
Validation loss: 1.6581556207390242

Epoch: 5| Step: 5
Training loss: 0.3186708390712738
Validation loss: 1.6511940328023766

Epoch: 5| Step: 6
Training loss: 0.48770707845687866
Validation loss: 1.671670913696289

Epoch: 5| Step: 7
Training loss: 0.40966254472732544
Validation loss: 1.7023668263548164

Epoch: 5| Step: 8
Training loss: 0.41325968503952026
Validation loss: 1.6434372176406205

Epoch: 5| Step: 9
Training loss: 0.34312164783477783
Validation loss: 1.6584889017125612

Epoch: 5| Step: 10
Training loss: 0.2906666100025177
Validation loss: 1.6819509075533958

Epoch: 387| Step: 0
Training loss: 0.09109202027320862
Validation loss: 1.6779903416992517

Epoch: 5| Step: 1
Training loss: 0.3052947521209717
Validation loss: 1.6887168474094842

Epoch: 5| Step: 2
Training loss: 0.4213298261165619
Validation loss: 1.6819671584713844

Epoch: 5| Step: 3
Training loss: 0.4500732421875
Validation loss: 1.6494528414100729

Epoch: 5| Step: 4
Training loss: 0.2615172863006592
Validation loss: 1.5985808731407247

Epoch: 5| Step: 5
Training loss: 0.3739483058452606
Validation loss: 1.6131882641905098

Epoch: 5| Step: 6
Training loss: 0.45442405343055725
Validation loss: 1.6074507621026808

Epoch: 5| Step: 7
Training loss: 0.3829258978366852
Validation loss: 1.6391534984752696

Epoch: 5| Step: 8
Training loss: 0.5800455212593079
Validation loss: 1.5988024357826478

Epoch: 5| Step: 9
Training loss: 0.5167979001998901
Validation loss: 1.5859581347434752

Epoch: 5| Step: 10
Training loss: 0.3473008871078491
Validation loss: 1.5992626105585406

Epoch: 388| Step: 0
Training loss: 0.38950344920158386
Validation loss: 1.6169094770185408

Epoch: 5| Step: 1
Training loss: 0.386190265417099
Validation loss: 1.6025737447123374

Epoch: 5| Step: 2
Training loss: 0.30669790506362915
Validation loss: 1.5992370228613577

Epoch: 5| Step: 3
Training loss: 0.44142842292785645
Validation loss: 1.6328746823854343

Epoch: 5| Step: 4
Training loss: 0.21985845267772675
Validation loss: 1.5996647496377268

Epoch: 5| Step: 5
Training loss: 0.3562133312225342
Validation loss: 1.5897821431518884

Epoch: 5| Step: 6
Training loss: 0.4892506003379822
Validation loss: 1.613645399770429

Epoch: 5| Step: 7
Training loss: 0.436390221118927
Validation loss: 1.5756008766030754

Epoch: 5| Step: 8
Training loss: 0.4480900168418884
Validation loss: 1.5859246023239628

Epoch: 5| Step: 9
Training loss: 0.46727195382118225
Validation loss: 1.6188390985611947

Epoch: 5| Step: 10
Training loss: 0.3807471692562103
Validation loss: 1.6269841681244552

Epoch: 389| Step: 0
Training loss: 0.5938417315483093
Validation loss: 1.5820830509226809

Epoch: 5| Step: 1
Training loss: 0.7583376169204712
Validation loss: 1.6037424046506163

Epoch: 5| Step: 2
Training loss: 0.29949676990509033
Validation loss: 1.640871504301666

Epoch: 5| Step: 3
Training loss: 0.44610387086868286
Validation loss: 1.6578111264013475

Epoch: 5| Step: 4
Training loss: 0.3836222290992737
Validation loss: 1.660428693217616

Epoch: 5| Step: 5
Training loss: 0.455930233001709
Validation loss: 1.603365530249893

Epoch: 5| Step: 6
Training loss: 0.15415088832378387
Validation loss: 1.5936202028746247

Epoch: 5| Step: 7
Training loss: 0.294058620929718
Validation loss: 1.577185957662521

Epoch: 5| Step: 8
Training loss: 0.40761369466781616
Validation loss: 1.544777790705363

Epoch: 5| Step: 9
Training loss: 0.21155285835266113
Validation loss: 1.5613887310028076

Epoch: 5| Step: 10
Training loss: 0.388225257396698
Validation loss: 1.5565603061388897

Epoch: 390| Step: 0
Training loss: 0.7194846272468567
Validation loss: 1.5746596295346496

Epoch: 5| Step: 1
Training loss: 0.4036893844604492
Validation loss: 1.6130526578554543

Epoch: 5| Step: 2
Training loss: 0.4039734899997711
Validation loss: 1.5995397862567697

Epoch: 5| Step: 3
Training loss: 0.2959845960140228
Validation loss: 1.6214102724547028

Epoch: 5| Step: 4
Training loss: 0.24670931696891785
Validation loss: 1.6352820524605371

Epoch: 5| Step: 5
Training loss: 0.27883392572402954
Validation loss: 1.6357399661053893

Epoch: 5| Step: 6
Training loss: 0.24269333481788635
Validation loss: 1.6192484209614415

Epoch: 5| Step: 7
Training loss: 0.43315547704696655
Validation loss: 1.628902663466751

Epoch: 5| Step: 8
Training loss: 0.4990292489528656
Validation loss: 1.5952200928042013

Epoch: 5| Step: 9
Training loss: 0.4503495693206787
Validation loss: 1.5759250720342

Epoch: 5| Step: 10
Training loss: 0.30412009358406067
Validation loss: 1.584179434084123

Epoch: 391| Step: 0
Training loss: 0.4937313497066498
Validation loss: 1.5745926390412033

Epoch: 5| Step: 1
Training loss: 0.4530795216560364
Validation loss: 1.5639152462764452

Epoch: 5| Step: 2
Training loss: 0.40626877546310425
Validation loss: 1.5912650413410638

Epoch: 5| Step: 3
Training loss: 0.2940412163734436
Validation loss: 1.5880015075847667

Epoch: 5| Step: 4
Training loss: 0.2858414053916931
Validation loss: 1.5983547997731034

Epoch: 5| Step: 5
Training loss: 0.32276028394699097
Validation loss: 1.605118449016284

Epoch: 5| Step: 6
Training loss: 0.4367891848087311
Validation loss: 1.5953577718427103

Epoch: 5| Step: 7
Training loss: 0.35774150490760803
Validation loss: 1.609663627480948

Epoch: 5| Step: 8
Training loss: 0.24975410103797913
Validation loss: 1.6099916952912525

Epoch: 5| Step: 9
Training loss: 0.6297491788864136
Validation loss: 1.6078115676039009

Epoch: 5| Step: 10
Training loss: 0.2676689326763153
Validation loss: 1.5996796418261785

Epoch: 392| Step: 0
Training loss: 0.3001733720302582
Validation loss: 1.5964809310051702

Epoch: 5| Step: 1
Training loss: 0.0985073670744896
Validation loss: 1.5636160873597669

Epoch: 5| Step: 2
Training loss: 0.7204743027687073
Validation loss: 1.5368003973396875

Epoch: 5| Step: 3
Training loss: 0.35358065366744995
Validation loss: 1.5772542581763318

Epoch: 5| Step: 4
Training loss: 0.4033152461051941
Validation loss: 1.5661108865532825

Epoch: 5| Step: 5
Training loss: 0.296965628862381
Validation loss: 1.554610675381076

Epoch: 5| Step: 6
Training loss: 0.33347806334495544
Validation loss: 1.5999188897430257

Epoch: 5| Step: 7
Training loss: 0.32336896657943726
Validation loss: 1.5848437099046604

Epoch: 5| Step: 8
Training loss: 0.45489072799682617
Validation loss: 1.6135654539190314

Epoch: 5| Step: 9
Training loss: 0.5495772957801819
Validation loss: 1.6481677280959262

Epoch: 5| Step: 10
Training loss: 0.21785913407802582
Validation loss: 1.6678113065740114

Epoch: 393| Step: 0
Training loss: 0.41226595640182495
Validation loss: 1.6679779765426472

Epoch: 5| Step: 1
Training loss: 0.2774975001811981
Validation loss: 1.6487550773928243

Epoch: 5| Step: 2
Training loss: 0.3134933114051819
Validation loss: 1.610625284974293

Epoch: 5| Step: 3
Training loss: 0.24676911532878876
Validation loss: 1.623851107012841

Epoch: 5| Step: 4
Training loss: 0.16960911452770233
Validation loss: 1.5931955293942524

Epoch: 5| Step: 5
Training loss: 0.3248259127140045
Validation loss: 1.5870320015056159

Epoch: 5| Step: 6
Training loss: 0.29393261671066284
Validation loss: 1.6004553866642777

Epoch: 5| Step: 7
Training loss: 0.32513538002967834
Validation loss: 1.6289552245088803

Epoch: 5| Step: 8
Training loss: 0.555955171585083
Validation loss: 1.5922020161023704

Epoch: 5| Step: 9
Training loss: 0.4039396345615387
Validation loss: 1.6088014418079006

Epoch: 5| Step: 10
Training loss: 0.8509523272514343
Validation loss: 1.6264837441905853

Epoch: 394| Step: 0
Training loss: 0.316775918006897
Validation loss: 1.6271736468038251

Epoch: 5| Step: 1
Training loss: 0.3923972547054291
Validation loss: 1.6600734533802155

Epoch: 5| Step: 2
Training loss: 0.29228895902633667
Validation loss: 1.6592535523958103

Epoch: 5| Step: 3
Training loss: 0.23289556801319122
Validation loss: 1.6337815318056332

Epoch: 5| Step: 4
Training loss: 0.3005257546901703
Validation loss: 1.611279490173504

Epoch: 5| Step: 5
Training loss: 0.30857211351394653
Validation loss: 1.6120056862472205

Epoch: 5| Step: 6
Training loss: 0.36099714040756226
Validation loss: 1.5755919589791247

Epoch: 5| Step: 7
Training loss: 0.5122500061988831
Validation loss: 1.5995776396925732

Epoch: 5| Step: 8
Training loss: 0.6764659881591797
Validation loss: 1.5652357724405104

Epoch: 5| Step: 9
Training loss: 0.22766821086406708
Validation loss: 1.5601548648649646

Epoch: 5| Step: 10
Training loss: 0.34205424785614014
Validation loss: 1.6001786493485974

Epoch: 395| Step: 0
Training loss: 0.5650902390480042
Validation loss: 1.601988684746527

Epoch: 5| Step: 1
Training loss: 0.347412645816803
Validation loss: 1.5922920139887

Epoch: 5| Step: 2
Training loss: 0.4802553653717041
Validation loss: 1.6113608114181026

Epoch: 5| Step: 3
Training loss: 0.3100208044052124
Validation loss: 1.612792957213617

Epoch: 5| Step: 4
Training loss: 0.3215329647064209
Validation loss: 1.6097113650332215

Epoch: 5| Step: 5
Training loss: 0.27515363693237305
Validation loss: 1.6156507525392758

Epoch: 5| Step: 6
Training loss: 0.34301477670669556
Validation loss: 1.6264525100749025

Epoch: 5| Step: 7
Training loss: 0.34998732805252075
Validation loss: 1.6511006483467676

Epoch: 5| Step: 8
Training loss: 0.4791492819786072
Validation loss: 1.6862814170058056

Epoch: 5| Step: 9
Training loss: 0.37278223037719727
Validation loss: 1.6711542478171728

Epoch: 5| Step: 10
Training loss: 0.593708336353302
Validation loss: 1.6739746639805455

Epoch: 396| Step: 0
Training loss: 0.5502995848655701
Validation loss: 1.6701112242155178

Epoch: 5| Step: 1
Training loss: 0.3693966269493103
Validation loss: 1.6846971922023322

Epoch: 5| Step: 2
Training loss: 0.4183341860771179
Validation loss: 1.634446927296218

Epoch: 5| Step: 3
Training loss: 0.23138046264648438
Validation loss: 1.6235785317677323

Epoch: 5| Step: 4
Training loss: 0.2892572283744812
Validation loss: 1.6319077668651458

Epoch: 5| Step: 5
Training loss: 0.3922062814235687
Validation loss: 1.5991047774591753

Epoch: 5| Step: 6
Training loss: 0.3268586993217468
Validation loss: 1.593294817914245

Epoch: 5| Step: 7
Training loss: 0.39368298649787903
Validation loss: 1.6208233551312519

Epoch: 5| Step: 8
Training loss: 0.6120678782463074
Validation loss: 1.609234481729487

Epoch: 5| Step: 9
Training loss: 0.4168754518032074
Validation loss: 1.6348359443808114

Epoch: 5| Step: 10
Training loss: 0.1566469669342041
Validation loss: 1.6189668896377727

Epoch: 397| Step: 0
Training loss: 0.4161759912967682
Validation loss: 1.613943596040049

Epoch: 5| Step: 1
Training loss: 0.3808995187282562
Validation loss: 1.6101174675008303

Epoch: 5| Step: 2
Training loss: 0.335316002368927
Validation loss: 1.6040962588402532

Epoch: 5| Step: 3
Training loss: 0.3730936646461487
Validation loss: 1.6198544707349551

Epoch: 5| Step: 4
Training loss: 0.3052225708961487
Validation loss: 1.6459478216786538

Epoch: 5| Step: 5
Training loss: 0.29341191053390503
Validation loss: 1.6383829091184883

Epoch: 5| Step: 6
Training loss: 0.39880985021591187
Validation loss: 1.649687215846072

Epoch: 5| Step: 7
Training loss: 0.2587798237800598
Validation loss: 1.6089413178864347

Epoch: 5| Step: 8
Training loss: 0.4617334306240082
Validation loss: 1.617016460305901

Epoch: 5| Step: 9
Training loss: 0.2522445619106293
Validation loss: 1.605051811023425

Epoch: 5| Step: 10
Training loss: 0.6379340887069702
Validation loss: 1.596193003398116

Epoch: 398| Step: 0
Training loss: 0.3315622806549072
Validation loss: 1.5841847677384653

Epoch: 5| Step: 1
Training loss: 0.4210415482521057
Validation loss: 1.637751954858021

Epoch: 5| Step: 2
Training loss: 0.395020067691803
Validation loss: 1.6272971783914874

Epoch: 5| Step: 3
Training loss: 0.30716532468795776
Validation loss: 1.6453817941809212

Epoch: 5| Step: 4
Training loss: 0.20527806878089905
Validation loss: 1.645025001418206

Epoch: 5| Step: 5
Training loss: 0.4422042965888977
Validation loss: 1.632582260716346

Epoch: 5| Step: 6
Training loss: 0.21637502312660217
Validation loss: 1.6498718966719925

Epoch: 5| Step: 7
Training loss: 0.4067300856113434
Validation loss: 1.6313964090039652

Epoch: 5| Step: 8
Training loss: 0.34325695037841797
Validation loss: 1.6317902534238753

Epoch: 5| Step: 9
Training loss: 0.19696854054927826
Validation loss: 1.6311143085520754

Epoch: 5| Step: 10
Training loss: 0.6453307271003723
Validation loss: 1.6535232759291125

Epoch: 399| Step: 0
Training loss: 0.23990249633789062
Validation loss: 1.6458360149014382

Epoch: 5| Step: 1
Training loss: 0.5365479588508606
Validation loss: 1.64208887597566

Epoch: 5| Step: 2
Training loss: 0.24002572894096375
Validation loss: 1.6439280689403575

Epoch: 5| Step: 3
Training loss: 0.4324813783168793
Validation loss: 1.6587328628827167

Epoch: 5| Step: 4
Training loss: 0.30825275182724
Validation loss: 1.6316430055966942

Epoch: 5| Step: 5
Training loss: 0.3291186988353729
Validation loss: 1.6268834657566522

Epoch: 5| Step: 6
Training loss: 0.2526107132434845
Validation loss: 1.6041387652838102

Epoch: 5| Step: 7
Training loss: 0.31036365032196045
Validation loss: 1.6308459312685075

Epoch: 5| Step: 8
Training loss: 0.4756956994533539
Validation loss: 1.5968354837868803

Epoch: 5| Step: 9
Training loss: 0.18235141038894653
Validation loss: 1.596089942480928

Epoch: 5| Step: 10
Training loss: 0.44435709714889526
Validation loss: 1.599485723562138

Epoch: 400| Step: 0
Training loss: 0.31152135133743286
Validation loss: 1.6302545173193819

Epoch: 5| Step: 1
Training loss: 0.34028932452201843
Validation loss: 1.5754093559839393

Epoch: 5| Step: 2
Training loss: 0.2672134041786194
Validation loss: 1.6014060820302656

Epoch: 5| Step: 3
Training loss: 0.3562230169773102
Validation loss: 1.5797741605389504

Epoch: 5| Step: 4
Training loss: 0.542849600315094
Validation loss: 1.5779435044975691

Epoch: 5| Step: 5
Training loss: 0.3970213234424591
Validation loss: 1.5633406818553965

Epoch: 5| Step: 6
Training loss: 0.24178488552570343
Validation loss: 1.594530188909141

Epoch: 5| Step: 7
Training loss: 0.4271889328956604
Validation loss: 1.567469508417191

Epoch: 5| Step: 8
Training loss: 0.26421862840652466
Validation loss: 1.5717729137789818

Epoch: 5| Step: 9
Training loss: 0.36519283056259155
Validation loss: 1.5784898009351505

Epoch: 5| Step: 10
Training loss: 0.24012349545955658
Validation loss: 1.5730536753131497

Epoch: 401| Step: 0
Training loss: 0.2464331090450287
Validation loss: 1.607920600521949

Epoch: 5| Step: 1
Training loss: 0.26254406571388245
Validation loss: 1.611514118409926

Epoch: 5| Step: 2
Training loss: 0.4891992211341858
Validation loss: 1.6396122465851486

Epoch: 5| Step: 3
Training loss: 0.2693675458431244
Validation loss: 1.6135914312895907

Epoch: 5| Step: 4
Training loss: 0.1993962824344635
Validation loss: 1.6147703727086384

Epoch: 5| Step: 5
Training loss: 0.38753557205200195
Validation loss: 1.6016503200736096

Epoch: 5| Step: 6
Training loss: 0.23842033743858337
Validation loss: 1.6254566279790734

Epoch: 5| Step: 7
Training loss: 0.2603517174720764
Validation loss: 1.5942705844038276

Epoch: 5| Step: 8
Training loss: 0.7521616816520691
Validation loss: 1.6077535767709055

Epoch: 5| Step: 9
Training loss: 0.21402719616889954
Validation loss: 1.5849681349210842

Epoch: 5| Step: 10
Training loss: 0.4326210618019104
Validation loss: 1.5644196297532769

Epoch: 402| Step: 0
Training loss: 0.2010514736175537
Validation loss: 1.5707673847034413

Epoch: 5| Step: 1
Training loss: 0.23725371062755585
Validation loss: 1.5838605447482037

Epoch: 5| Step: 2
Training loss: 0.38151445984840393
Validation loss: 1.588588108298599

Epoch: 5| Step: 3
Training loss: 0.57264244556427
Validation loss: 1.5888349830463369

Epoch: 5| Step: 4
Training loss: 0.3948832154273987
Validation loss: 1.6018003161235521

Epoch: 5| Step: 5
Training loss: 0.15782323479652405
Validation loss: 1.6007733421940957

Epoch: 5| Step: 6
Training loss: 0.3612230718135834
Validation loss: 1.6234321594238281

Epoch: 5| Step: 7
Training loss: 0.38373878598213196
Validation loss: 1.6100997783804452

Epoch: 5| Step: 8
Training loss: 0.3201949894428253
Validation loss: 1.641713729468725

Epoch: 5| Step: 9
Training loss: 0.26304301619529724
Validation loss: 1.6157516920438377

Epoch: 5| Step: 10
Training loss: 0.32822346687316895
Validation loss: 1.634807009850779

Epoch: 403| Step: 0
Training loss: 0.2807016968727112
Validation loss: 1.6033269154128207

Epoch: 5| Step: 1
Training loss: 0.32003673911094666
Validation loss: 1.6125106119340467

Epoch: 5| Step: 2
Training loss: 0.26447758078575134
Validation loss: 1.6032228687758088

Epoch: 5| Step: 3
Training loss: 0.23774150013923645
Validation loss: 1.6045695017742854

Epoch: 5| Step: 4
Training loss: 0.168222114443779
Validation loss: 1.5945731875717

Epoch: 5| Step: 5
Training loss: 0.6121553182601929
Validation loss: 1.5907449658199022

Epoch: 5| Step: 6
Training loss: 0.4803822934627533
Validation loss: 1.601833785733869

Epoch: 5| Step: 7
Training loss: 0.19946560263633728
Validation loss: 1.6041373309268747

Epoch: 5| Step: 8
Training loss: 0.3670366704463959
Validation loss: 1.5973790409744426

Epoch: 5| Step: 9
Training loss: 0.35233792662620544
Validation loss: 1.6158849654659149

Epoch: 5| Step: 10
Training loss: 0.22409765422344208
Validation loss: 1.627106560173855

Epoch: 404| Step: 0
Training loss: 0.34163060784339905
Validation loss: 1.6034554832725114

Epoch: 5| Step: 1
Training loss: 0.2617779076099396
Validation loss: 1.5943575213032384

Epoch: 5| Step: 2
Training loss: 0.2722877860069275
Validation loss: 1.5798193254778463

Epoch: 5| Step: 3
Training loss: 0.5368576049804688
Validation loss: 1.5766668063338085

Epoch: 5| Step: 4
Training loss: 0.2938843369483948
Validation loss: 1.5723743900176017

Epoch: 5| Step: 5
Training loss: 0.29705408215522766
Validation loss: 1.5713075553217242

Epoch: 5| Step: 6
Training loss: 0.36651137471199036
Validation loss: 1.56071808004892

Epoch: 5| Step: 7
Training loss: 0.1994675099849701
Validation loss: 1.580416759496094

Epoch: 5| Step: 8
Training loss: 0.4410873353481293
Validation loss: 1.6043132248745169

Epoch: 5| Step: 9
Training loss: 0.36928778886795044
Validation loss: 1.6337335237892725

Epoch: 5| Step: 10
Training loss: 0.4211905002593994
Validation loss: 1.6282279222242293

Epoch: 405| Step: 0
Training loss: 0.19743822515010834
Validation loss: 1.6042860015746085

Epoch: 5| Step: 1
Training loss: 0.44026249647140503
Validation loss: 1.599166634262249

Epoch: 5| Step: 2
Training loss: 0.282673180103302
Validation loss: 1.5818840425501588

Epoch: 5| Step: 3
Training loss: 0.29278069734573364
Validation loss: 1.5708662797045965

Epoch: 5| Step: 4
Training loss: 0.17837277054786682
Validation loss: 1.5860238754621117

Epoch: 5| Step: 5
Training loss: 0.26913437247276306
Validation loss: 1.6138727357310634

Epoch: 5| Step: 6
Training loss: 0.3502804636955261
Validation loss: 1.5804394381020659

Epoch: 5| Step: 7
Training loss: 0.2504901885986328
Validation loss: 1.582229414293843

Epoch: 5| Step: 8
Training loss: 0.5291571021080017
Validation loss: 1.561958839816432

Epoch: 5| Step: 9
Training loss: 0.22021043300628662
Validation loss: 1.6190195493800665

Epoch: 5| Step: 10
Training loss: 0.5720625519752502
Validation loss: 1.6230742162273777

Epoch: 406| Step: 0
Training loss: 0.23818178474903107
Validation loss: 1.6314079992232784

Epoch: 5| Step: 1
Training loss: 0.4661484658718109
Validation loss: 1.6702815576266217

Epoch: 5| Step: 2
Training loss: 0.35720258951187134
Validation loss: 1.705809639346215

Epoch: 5| Step: 3
Training loss: 0.31014853715896606
Validation loss: 1.675200282886464

Epoch: 5| Step: 4
Training loss: 0.27988314628601074
Validation loss: 1.619360436675369

Epoch: 5| Step: 5
Training loss: 0.45102185010910034
Validation loss: 1.591363597941655

Epoch: 5| Step: 6
Training loss: 0.20370778441429138
Validation loss: 1.5717486886567966

Epoch: 5| Step: 7
Training loss: 0.5355110168457031
Validation loss: 1.6138999500582296

Epoch: 5| Step: 8
Training loss: 0.40821027755737305
Validation loss: 1.5997142599474998

Epoch: 5| Step: 9
Training loss: 0.45538491010665894
Validation loss: 1.607373006882206

Epoch: 5| Step: 10
Training loss: 0.08398722112178802
Validation loss: 1.5778716853869859

Epoch: 407| Step: 0
Training loss: 0.6643843054771423
Validation loss: 1.607482350000771

Epoch: 5| Step: 1
Training loss: 0.38209426403045654
Validation loss: 1.6444857479423605

Epoch: 5| Step: 2
Training loss: 0.3847181797027588
Validation loss: 1.6413007128623225

Epoch: 5| Step: 3
Training loss: 0.30844148993492126
Validation loss: 1.6634807843033985

Epoch: 5| Step: 4
Training loss: 0.31686079502105713
Validation loss: 1.69458342623967

Epoch: 5| Step: 5
Training loss: 0.25493213534355164
Validation loss: 1.6434703103957637

Epoch: 5| Step: 6
Training loss: 0.39555421471595764
Validation loss: 1.638662927894182

Epoch: 5| Step: 7
Training loss: 0.19205732643604279
Validation loss: 1.5968972175352034

Epoch: 5| Step: 8
Training loss: 0.11629383265972137
Validation loss: 1.6023166512930265

Epoch: 5| Step: 9
Training loss: 0.4319058954715729
Validation loss: 1.5616088041695215

Epoch: 5| Step: 10
Training loss: 0.37485578656196594
Validation loss: 1.596518370413011

Epoch: 408| Step: 0
Training loss: 0.3928681015968323
Validation loss: 1.5736239366633917

Epoch: 5| Step: 1
Training loss: 0.3850552439689636
Validation loss: 1.6341388533192296

Epoch: 5| Step: 2
Training loss: 0.3581767976284027
Validation loss: 1.6537384884331816

Epoch: 5| Step: 3
Training loss: 0.35090214014053345
Validation loss: 1.6797356643984396

Epoch: 5| Step: 4
Training loss: 0.2185879498720169
Validation loss: 1.6832625609572216

Epoch: 5| Step: 5
Training loss: 0.3305507302284241
Validation loss: 1.6731377429859613

Epoch: 5| Step: 6
Training loss: 0.28720492124557495
Validation loss: 1.6488106866036691

Epoch: 5| Step: 7
Training loss: 0.3336728513240814
Validation loss: 1.6564933061599731

Epoch: 5| Step: 8
Training loss: 0.3377727270126343
Validation loss: 1.6435016611570954

Epoch: 5| Step: 9
Training loss: 0.5200831890106201
Validation loss: 1.6022958947766213

Epoch: 5| Step: 10
Training loss: 0.2957260012626648
Validation loss: 1.6017698728910057

Epoch: 409| Step: 0
Training loss: 0.2760485112667084
Validation loss: 1.6045990502962502

Epoch: 5| Step: 1
Training loss: 0.2432590276002884
Validation loss: 1.5840076297842047

Epoch: 5| Step: 2
Training loss: 0.10294538736343384
Validation loss: 1.5977067101386286

Epoch: 5| Step: 3
Training loss: 0.36252933740615845
Validation loss: 1.6038198317250898

Epoch: 5| Step: 4
Training loss: 0.2904723286628723
Validation loss: 1.5901828222377326

Epoch: 5| Step: 5
Training loss: 0.4467509388923645
Validation loss: 1.5935178097858225

Epoch: 5| Step: 6
Training loss: 0.27328166365623474
Validation loss: 1.608483786224037

Epoch: 5| Step: 7
Training loss: 0.4388304650783539
Validation loss: 1.625618734667378

Epoch: 5| Step: 8
Training loss: 0.6565184593200684
Validation loss: 1.6296843713329685

Epoch: 5| Step: 9
Training loss: 0.2677031457424164
Validation loss: 1.6162048693626159

Epoch: 5| Step: 10
Training loss: 0.17114509642124176
Validation loss: 1.5973611480446273

Epoch: 410| Step: 0
Training loss: 0.2956385910511017
Validation loss: 1.5986385191640546

Epoch: 5| Step: 1
Training loss: 0.27949586510658264
Validation loss: 1.5710048534536873

Epoch: 5| Step: 2
Training loss: 0.23210862278938293
Validation loss: 1.58739770484227

Epoch: 5| Step: 3
Training loss: 0.39223483204841614
Validation loss: 1.589682391894761

Epoch: 5| Step: 4
Training loss: 0.19542419910430908
Validation loss: 1.619771461973908

Epoch: 5| Step: 5
Training loss: 0.20725759863853455
Validation loss: 1.6223019963951522

Epoch: 5| Step: 6
Training loss: 0.46118825674057007
Validation loss: 1.6393658550836707

Epoch: 5| Step: 7
Training loss: 0.2642682194709778
Validation loss: 1.6213550580445157

Epoch: 5| Step: 8
Training loss: 0.4594731330871582
Validation loss: 1.6508566884584324

Epoch: 5| Step: 9
Training loss: 0.31913432478904724
Validation loss: 1.6064950048282582

Epoch: 5| Step: 10
Training loss: 0.2742973864078522
Validation loss: 1.6215949878897717

Epoch: 411| Step: 0
Training loss: 0.29675236344337463
Validation loss: 1.5970092229945685

Epoch: 5| Step: 1
Training loss: 0.5180651545524597
Validation loss: 1.5907533322611163

Epoch: 5| Step: 2
Training loss: 0.3878747820854187
Validation loss: 1.5883515137498097

Epoch: 5| Step: 3
Training loss: 0.1906769722700119
Validation loss: 1.5992728382028558

Epoch: 5| Step: 4
Training loss: 0.10021007061004639
Validation loss: 1.595874842777047

Epoch: 5| Step: 5
Training loss: 0.2294730246067047
Validation loss: 1.6371050957710511

Epoch: 5| Step: 6
Training loss: 0.27008765935897827
Validation loss: 1.6640519583097069

Epoch: 5| Step: 7
Training loss: 0.44933003187179565
Validation loss: 1.699027056335121

Epoch: 5| Step: 8
Training loss: 0.518001914024353
Validation loss: 1.69548414855875

Epoch: 5| Step: 9
Training loss: 0.4378378987312317
Validation loss: 1.6800484580378379

Epoch: 5| Step: 10
Training loss: 0.20263420045375824
Validation loss: 1.6612003682762064

Epoch: 412| Step: 0
Training loss: 0.2906845211982727
Validation loss: 1.651789616512996

Epoch: 5| Step: 1
Training loss: 0.7201061248779297
Validation loss: 1.6542349092421993

Epoch: 5| Step: 2
Training loss: 0.17744767665863037
Validation loss: 1.6267829941165062

Epoch: 5| Step: 3
Training loss: 0.14925511181354523
Validation loss: 1.6309530273560555

Epoch: 5| Step: 4
Training loss: 0.36798352003097534
Validation loss: 1.636680410754296

Epoch: 5| Step: 5
Training loss: 0.17560987174510956
Validation loss: 1.6333148915280578

Epoch: 5| Step: 6
Training loss: 0.4299728274345398
Validation loss: 1.6661036822103685

Epoch: 5| Step: 7
Training loss: 0.3249644637107849
Validation loss: 1.6751912088804348

Epoch: 5| Step: 8
Training loss: 0.20207706093788147
Validation loss: 1.6872088755330732

Epoch: 5| Step: 9
Training loss: 0.27511754631996155
Validation loss: 1.6855914926016202

Epoch: 5| Step: 10
Training loss: 0.26522937417030334
Validation loss: 1.6472606120571014

Epoch: 413| Step: 0
Training loss: 0.18720673024654388
Validation loss: 1.61491604774229

Epoch: 5| Step: 1
Training loss: 0.2701539397239685
Validation loss: 1.6179176293393618

Epoch: 5| Step: 2
Training loss: 0.24718418717384338
Validation loss: 1.6233918679657804

Epoch: 5| Step: 3
Training loss: 0.4037903845310211
Validation loss: 1.6264795411017634

Epoch: 5| Step: 4
Training loss: 0.14675605297088623
Validation loss: 1.6421424522194812

Epoch: 5| Step: 5
Training loss: 0.28509271144866943
Validation loss: 1.6477248399488387

Epoch: 5| Step: 6
Training loss: 0.2851831316947937
Validation loss: 1.6819605699149511

Epoch: 5| Step: 7
Training loss: 0.6729069352149963
Validation loss: 1.6880154058497439

Epoch: 5| Step: 8
Training loss: 0.2726540267467499
Validation loss: 1.7149658549216487

Epoch: 5| Step: 9
Training loss: 0.3727169632911682
Validation loss: 1.6682635379093949

Epoch: 5| Step: 10
Training loss: 0.3157285749912262
Validation loss: 1.7004519579231099

Epoch: 414| Step: 0
Training loss: 0.17694154381752014
Validation loss: 1.6730777294405046

Epoch: 5| Step: 1
Training loss: 0.43437233567237854
Validation loss: 1.6520282722288562

Epoch: 5| Step: 2
Training loss: 0.3808748722076416
Validation loss: 1.6402573175327753

Epoch: 5| Step: 3
Training loss: 0.26426172256469727
Validation loss: 1.580388952327031

Epoch: 5| Step: 4
Training loss: 0.2419285774230957
Validation loss: 1.627273985134658

Epoch: 5| Step: 5
Training loss: 0.26643961668014526
Validation loss: 1.6300479148023872

Epoch: 5| Step: 6
Training loss: 0.4328266680240631
Validation loss: 1.599053548228356

Epoch: 5| Step: 7
Training loss: 0.5775971412658691
Validation loss: 1.6170847518469698

Epoch: 5| Step: 8
Training loss: 0.37874481081962585
Validation loss: 1.6487254109433902

Epoch: 5| Step: 9
Training loss: 0.16388921439647675
Validation loss: 1.6423113064099384

Epoch: 5| Step: 10
Training loss: 0.3080967366695404
Validation loss: 1.6780133478103145

Epoch: 415| Step: 0
Training loss: 0.43135395646095276
Validation loss: 1.6377241124388993

Epoch: 5| Step: 1
Training loss: 0.323131263256073
Validation loss: 1.6154156551566174

Epoch: 5| Step: 2
Training loss: 0.19877435266971588
Validation loss: 1.6254868558658067

Epoch: 5| Step: 3
Training loss: 0.30953747034072876
Validation loss: 1.5989548775457567

Epoch: 5| Step: 4
Training loss: 0.2898634672164917
Validation loss: 1.5908019978513

Epoch: 5| Step: 5
Training loss: 0.24505896866321564
Validation loss: 1.5958403515559372

Epoch: 5| Step: 6
Training loss: 0.1423790603876114
Validation loss: 1.5988694185851722

Epoch: 5| Step: 7
Training loss: 0.19495296478271484
Validation loss: 1.5923739351252073

Epoch: 5| Step: 8
Training loss: 0.3105189800262451
Validation loss: 1.6049656060434156

Epoch: 5| Step: 9
Training loss: 0.2514062523841858
Validation loss: 1.643011135439719

Epoch: 5| Step: 10
Training loss: 0.6946132779121399
Validation loss: 1.6572008632844495

Epoch: 416| Step: 0
Training loss: 0.6128281354904175
Validation loss: 1.6559574552761611

Epoch: 5| Step: 1
Training loss: 0.09704039245843887
Validation loss: 1.642188851551343

Epoch: 5| Step: 2
Training loss: 0.30317145586013794
Validation loss: 1.6272045361098422

Epoch: 5| Step: 3
Training loss: 0.25382199883461
Validation loss: 1.6395687595490487

Epoch: 5| Step: 4
Training loss: 0.2300778329372406
Validation loss: 1.6489708885069816

Epoch: 5| Step: 5
Training loss: 0.2555409073829651
Validation loss: 1.6406185844893098

Epoch: 5| Step: 6
Training loss: 0.2020447701215744
Validation loss: 1.6398892325739707

Epoch: 5| Step: 7
Training loss: 0.4723814129829407
Validation loss: 1.6440634714659823

Epoch: 5| Step: 8
Training loss: 0.2739100456237793
Validation loss: 1.6232955558325655

Epoch: 5| Step: 9
Training loss: 0.36125648021698
Validation loss: 1.6119688480131087

Epoch: 5| Step: 10
Training loss: 0.1723242551088333
Validation loss: 1.6413637438128073

Epoch: 417| Step: 0
Training loss: 0.6016069650650024
Validation loss: 1.654185542496302

Epoch: 5| Step: 1
Training loss: 0.25676900148391724
Validation loss: 1.6273637253751037

Epoch: 5| Step: 2
Training loss: 0.30534976720809937
Validation loss: 1.6256877094186761

Epoch: 5| Step: 3
Training loss: 0.5423144698143005
Validation loss: 1.6615855104179793

Epoch: 5| Step: 4
Training loss: 0.1694699376821518
Validation loss: 1.6455268462498982

Epoch: 5| Step: 5
Training loss: 0.2666417956352234
Validation loss: 1.6683104589421263

Epoch: 5| Step: 6
Training loss: 0.16341136395931244
Validation loss: 1.6552842201725129

Epoch: 5| Step: 7
Training loss: 0.2346188724040985
Validation loss: 1.6493571958234232

Epoch: 5| Step: 8
Training loss: 0.12123193591833115
Validation loss: 1.6246205427313363

Epoch: 5| Step: 9
Training loss: 0.30278974771499634
Validation loss: 1.6490278051745506

Epoch: 5| Step: 10
Training loss: 0.17288894951343536
Validation loss: 1.6301407275661346

Epoch: 418| Step: 0
Training loss: 0.18175004422664642
Validation loss: 1.6108057755295948

Epoch: 5| Step: 1
Training loss: 0.3924133777618408
Validation loss: 1.608528947317472

Epoch: 5| Step: 2
Training loss: 0.2102094143629074
Validation loss: 1.6316363350037606

Epoch: 5| Step: 3
Training loss: 0.22490735352039337
Validation loss: 1.6144150841620661

Epoch: 5| Step: 4
Training loss: 0.3532150089740753
Validation loss: 1.5978723213236818

Epoch: 5| Step: 5
Training loss: 0.4522519111633301
Validation loss: 1.5881579409363449

Epoch: 5| Step: 6
Training loss: 0.46042340993881226
Validation loss: 1.635064798016702

Epoch: 5| Step: 7
Training loss: 0.3455508053302765
Validation loss: 1.6077138505956179

Epoch: 5| Step: 8
Training loss: 0.2835097014904022
Validation loss: 1.6071610963472756

Epoch: 5| Step: 9
Training loss: 0.33710160851478577
Validation loss: 1.6004227694644724

Epoch: 5| Step: 10
Training loss: 0.21489137411117554
Validation loss: 1.6031622232929352

Epoch: 419| Step: 0
Training loss: 0.17915768921375275
Validation loss: 1.580983741309053

Epoch: 5| Step: 1
Training loss: 0.20054273307323456
Validation loss: 1.5913901771268537

Epoch: 5| Step: 2
Training loss: 0.38499873876571655
Validation loss: 1.6084620644969325

Epoch: 5| Step: 3
Training loss: 0.24100792407989502
Validation loss: 1.6165258499883837

Epoch: 5| Step: 4
Training loss: 0.15806952118873596
Validation loss: 1.602718109725624

Epoch: 5| Step: 5
Training loss: 0.41561609506607056
Validation loss: 1.6162296277220531

Epoch: 5| Step: 6
Training loss: 0.23564180731773376
Validation loss: 1.6388034756465624

Epoch: 5| Step: 7
Training loss: 0.4691201150417328
Validation loss: 1.604813874408763

Epoch: 5| Step: 8
Training loss: 0.3990752398967743
Validation loss: 1.581033678464992

Epoch: 5| Step: 9
Training loss: 0.20165996253490448
Validation loss: 1.6204607525179464

Epoch: 5| Step: 10
Training loss: 0.3407280445098877
Validation loss: 1.6319822137073805

Epoch: 420| Step: 0
Training loss: 0.14250630140304565
Validation loss: 1.6283132312118367

Epoch: 5| Step: 1
Training loss: 0.34873390197753906
Validation loss: 1.6359391930282756

Epoch: 5| Step: 2
Training loss: 0.21480564773082733
Validation loss: 1.6277838740297543

Epoch: 5| Step: 3
Training loss: 0.3253890872001648
Validation loss: 1.6452999755900393

Epoch: 5| Step: 4
Training loss: 0.545452892780304
Validation loss: 1.6283307383137364

Epoch: 5| Step: 5
Training loss: 0.2891825735569
Validation loss: 1.634508539271611

Epoch: 5| Step: 6
Training loss: 0.25146013498306274
Validation loss: 1.6178110414935696

Epoch: 5| Step: 7
Training loss: 0.6147449016571045
Validation loss: 1.6145271665306502

Epoch: 5| Step: 8
Training loss: 0.13155534863471985
Validation loss: 1.627000420324264

Epoch: 5| Step: 9
Training loss: 0.15750250220298767
Validation loss: 1.6257673719877839

Epoch: 5| Step: 10
Training loss: 0.16385097801685333
Validation loss: 1.6325792625386228

Epoch: 421| Step: 0
Training loss: 0.22744961082935333
Validation loss: 1.5994719638619372

Epoch: 5| Step: 1
Training loss: 0.13007785379886627
Validation loss: 1.5908768689760597

Epoch: 5| Step: 2
Training loss: 0.19171789288520813
Validation loss: 1.5765306744524228

Epoch: 5| Step: 3
Training loss: 0.22885873913764954
Validation loss: 1.5752353040120934

Epoch: 5| Step: 4
Training loss: 0.2295532524585724
Validation loss: 1.6085107557235225

Epoch: 5| Step: 5
Training loss: 0.119384765625
Validation loss: 1.601592799668671

Epoch: 5| Step: 6
Training loss: 0.6520414352416992
Validation loss: 1.5634394115017307

Epoch: 5| Step: 7
Training loss: 0.187405526638031
Validation loss: 1.5370231783518227

Epoch: 5| Step: 8
Training loss: 0.40902644395828247
Validation loss: 1.55089509102606

Epoch: 5| Step: 9
Training loss: 0.3749155104160309
Validation loss: 1.5838309090624574

Epoch: 5| Step: 10
Training loss: 0.2595151364803314
Validation loss: 1.5797913651312552

Epoch: 422| Step: 0
Training loss: 0.22553157806396484
Validation loss: 1.5506830625636603

Epoch: 5| Step: 1
Training loss: 0.27107033133506775
Validation loss: 1.5452362260510843

Epoch: 5| Step: 2
Training loss: 0.41444191336631775
Validation loss: 1.5771222409381662

Epoch: 5| Step: 3
Training loss: 0.285356342792511
Validation loss: 1.5954063951328237

Epoch: 5| Step: 4
Training loss: 0.353423148393631
Validation loss: 1.55622899147772

Epoch: 5| Step: 5
Training loss: 0.27762410044670105
Validation loss: 1.5656285330813418

Epoch: 5| Step: 6
Training loss: 0.3339311480522156
Validation loss: 1.5579339791369695

Epoch: 5| Step: 7
Training loss: 0.24295742809772491
Validation loss: 1.557043916435652

Epoch: 5| Step: 8
Training loss: 0.16026511788368225
Validation loss: 1.5788294717829714

Epoch: 5| Step: 9
Training loss: 0.29457998275756836
Validation loss: 1.5800292953368156

Epoch: 5| Step: 10
Training loss: 0.27048900723457336
Validation loss: 1.6208176894854474

Epoch: 423| Step: 0
Training loss: 0.3010662794113159
Validation loss: 1.6134145298311788

Epoch: 5| Step: 1
Training loss: 0.2620972692966461
Validation loss: 1.6295163592984598

Epoch: 5| Step: 2
Training loss: 0.3363357484340668
Validation loss: 1.5992363883603005

Epoch: 5| Step: 3
Training loss: 0.22246232628822327
Validation loss: 1.5906025607098815

Epoch: 5| Step: 4
Training loss: 0.2710438072681427
Validation loss: 1.6078888139417093

Epoch: 5| Step: 5
Training loss: 0.166701078414917
Validation loss: 1.5967242576742684

Epoch: 5| Step: 6
Training loss: 0.42087817192077637
Validation loss: 1.6251160649843113

Epoch: 5| Step: 7
Training loss: 0.1938183456659317
Validation loss: 1.5998521799682288

Epoch: 5| Step: 8
Training loss: 0.2507392466068268
Validation loss: 1.5829684042161511

Epoch: 5| Step: 9
Training loss: 0.09360536932945251
Validation loss: 1.5976052002240253

Epoch: 5| Step: 10
Training loss: 0.5262306928634644
Validation loss: 1.634598485885128

Epoch: 424| Step: 0
Training loss: 0.3086305856704712
Validation loss: 1.6004264944343156

Epoch: 5| Step: 1
Training loss: 0.256460040807724
Validation loss: 1.6124303135820615

Epoch: 5| Step: 2
Training loss: 0.1325223445892334
Validation loss: 1.6006131928454164

Epoch: 5| Step: 3
Training loss: 0.30435627698898315
Validation loss: 1.6405074647677842

Epoch: 5| Step: 4
Training loss: 0.4584464132785797
Validation loss: 1.6335660898557274

Epoch: 5| Step: 5
Training loss: 0.35597798228263855
Validation loss: 1.6367698997579596

Epoch: 5| Step: 6
Training loss: 0.18259625136852264
Validation loss: 1.6293646597093152

Epoch: 5| Step: 7
Training loss: 0.28347262740135193
Validation loss: 1.6362864650705808

Epoch: 5| Step: 8
Training loss: 0.2635597586631775
Validation loss: 1.6374494439812117

Epoch: 5| Step: 9
Training loss: 0.188736230134964
Validation loss: 1.6274802530965498

Epoch: 5| Step: 10
Training loss: 0.3083074688911438
Validation loss: 1.6356371512977026

Epoch: 425| Step: 0
Training loss: 0.3015437722206116
Validation loss: 1.6148497853227841

Epoch: 5| Step: 1
Training loss: 0.3038158714771271
Validation loss: 1.6156631772236159

Epoch: 5| Step: 2
Training loss: 0.24184218049049377
Validation loss: 1.5884654964170148

Epoch: 5| Step: 3
Training loss: 0.2186974734067917
Validation loss: 1.6006821881058395

Epoch: 5| Step: 4
Training loss: 0.17046692967414856
Validation loss: 1.6121648037305443

Epoch: 5| Step: 5
Training loss: 0.3487568497657776
Validation loss: 1.5743324320803407

Epoch: 5| Step: 6
Training loss: 0.24330627918243408
Validation loss: 1.6190394560496013

Epoch: 5| Step: 7
Training loss: 0.31942635774612427
Validation loss: 1.63362640975624

Epoch: 5| Step: 8
Training loss: 0.4469425082206726
Validation loss: 1.5908961385808966

Epoch: 5| Step: 9
Training loss: 0.2332582175731659
Validation loss: 1.6778221104734687

Epoch: 5| Step: 10
Training loss: 0.2622249722480774
Validation loss: 1.6740790643999655

Epoch: 426| Step: 0
Training loss: 0.26197248697280884
Validation loss: 1.689366115036831

Epoch: 5| Step: 1
Training loss: 0.5685907006263733
Validation loss: 1.6505039520161127

Epoch: 5| Step: 2
Training loss: 0.29017239809036255
Validation loss: 1.6524109020028064

Epoch: 5| Step: 3
Training loss: 0.18658149242401123
Validation loss: 1.6395525534947712

Epoch: 5| Step: 4
Training loss: 0.321873277425766
Validation loss: 1.6559492887989167

Epoch: 5| Step: 5
Training loss: 0.2870962917804718
Validation loss: 1.6741254765500304

Epoch: 5| Step: 6
Training loss: 0.1901465207338333
Validation loss: 1.6881479383796774

Epoch: 5| Step: 7
Training loss: 0.24807171523571014
Validation loss: 1.658806400914346

Epoch: 5| Step: 8
Training loss: 0.3700539469718933
Validation loss: 1.6574301796574746

Epoch: 5| Step: 9
Training loss: 0.1974194496870041
Validation loss: 1.6470463634819112

Epoch: 5| Step: 10
Training loss: 0.20743505656719208
Validation loss: 1.6610428261500534

Epoch: 427| Step: 0
Training loss: 0.29694685339927673
Validation loss: 1.6221200958375008

Epoch: 5| Step: 1
Training loss: 0.22779694199562073
Validation loss: 1.6039912175106745

Epoch: 5| Step: 2
Training loss: 0.29075226187705994
Validation loss: 1.6005351107607606

Epoch: 5| Step: 3
Training loss: 0.40338143706321716
Validation loss: 1.6030181748892671

Epoch: 5| Step: 4
Training loss: 0.34976285696029663
Validation loss: 1.56813544483595

Epoch: 5| Step: 5
Training loss: 0.14301517605781555
Validation loss: 1.556096963984992

Epoch: 5| Step: 6
Training loss: 0.4133155941963196
Validation loss: 1.5539336230165215

Epoch: 5| Step: 7
Training loss: 0.3612087666988373
Validation loss: 1.5951582436920495

Epoch: 5| Step: 8
Training loss: 0.07545420527458191
Validation loss: 1.6355805653397755

Epoch: 5| Step: 9
Training loss: 0.19224533438682556
Validation loss: 1.6363321529921664

Epoch: 5| Step: 10
Training loss: 0.21443071961402893
Validation loss: 1.620440157510901

Epoch: 428| Step: 0
Training loss: 0.17459706962108612
Validation loss: 1.6390664513393114

Epoch: 5| Step: 1
Training loss: 0.673812747001648
Validation loss: 1.6270436112598707

Epoch: 5| Step: 2
Training loss: 0.17180214822292328
Validation loss: 1.6171806153430734

Epoch: 5| Step: 3
Training loss: 0.16433456540107727
Validation loss: 1.6528153842495334

Epoch: 5| Step: 4
Training loss: 0.17939092218875885
Validation loss: 1.624530170553474

Epoch: 5| Step: 5
Training loss: 0.28895169496536255
Validation loss: 1.6179373866768294

Epoch: 5| Step: 6
Training loss: 0.3046506345272064
Validation loss: 1.6205957474247101

Epoch: 5| Step: 7
Training loss: 0.3615974485874176
Validation loss: 1.6014341397952008

Epoch: 5| Step: 8
Training loss: 0.2713193893432617
Validation loss: 1.6386426828240837

Epoch: 5| Step: 9
Training loss: 0.26382797956466675
Validation loss: 1.6194997013256114

Epoch: 5| Step: 10
Training loss: 0.16278071701526642
Validation loss: 1.624326870005618

Epoch: 429| Step: 0
Training loss: 0.20437636971473694
Validation loss: 1.6443492853513328

Epoch: 5| Step: 1
Training loss: 0.22817964851856232
Validation loss: 1.671823666941735

Epoch: 5| Step: 2
Training loss: 0.5304818749427795
Validation loss: 1.6486541007154731

Epoch: 5| Step: 3
Training loss: 0.20668527483940125
Validation loss: 1.6613646143226213

Epoch: 5| Step: 4
Training loss: 0.28330618143081665
Validation loss: 1.6579087203548801

Epoch: 5| Step: 5
Training loss: 0.2980839014053345
Validation loss: 1.6357249816258748

Epoch: 5| Step: 6
Training loss: 0.2759397327899933
Validation loss: 1.615159276993044

Epoch: 5| Step: 7
Training loss: 0.17221172153949738
Validation loss: 1.6120135194511824

Epoch: 5| Step: 8
Training loss: 0.39556413888931274
Validation loss: 1.6143659686529508

Epoch: 5| Step: 9
Training loss: 0.24493232369422913
Validation loss: 1.591220704458093

Epoch: 5| Step: 10
Training loss: 0.16942474246025085
Validation loss: 1.5819219914815759

Epoch: 430| Step: 0
Training loss: 0.3198624551296234
Validation loss: 1.5951726128978114

Epoch: 5| Step: 1
Training loss: 0.2830810844898224
Validation loss: 1.5938257927535682

Epoch: 5| Step: 2
Training loss: 0.2024259865283966
Validation loss: 1.6335731283310921

Epoch: 5| Step: 3
Training loss: 0.37823471426963806
Validation loss: 1.6036187423172819

Epoch: 5| Step: 4
Training loss: 0.26776018738746643
Validation loss: 1.5844955162335468

Epoch: 5| Step: 5
Training loss: 0.18322475254535675
Validation loss: 1.602558752541901

Epoch: 5| Step: 6
Training loss: 0.20401158928871155
Validation loss: 1.5859216720827165

Epoch: 5| Step: 7
Training loss: 0.2173204869031906
Validation loss: 1.5993044607100948

Epoch: 5| Step: 8
Training loss: 0.3352058529853821
Validation loss: 1.5960136831447642

Epoch: 5| Step: 9
Training loss: 0.3624921143054962
Validation loss: 1.6005086744985273

Epoch: 5| Step: 10
Training loss: 0.3339126706123352
Validation loss: 1.5987960805175125

Epoch: 431| Step: 0
Training loss: 0.26205000281333923
Validation loss: 1.6201089146316692

Epoch: 5| Step: 1
Training loss: 0.2986697554588318
Validation loss: 1.6335033319329704

Epoch: 5| Step: 2
Training loss: 0.34843358397483826
Validation loss: 1.6288723945617676

Epoch: 5| Step: 3
Training loss: 0.28807783126831055
Validation loss: 1.620037148075719

Epoch: 5| Step: 4
Training loss: 0.266756147146225
Validation loss: 1.64809190329685

Epoch: 5| Step: 5
Training loss: 0.22170372307300568
Validation loss: 1.580789969813439

Epoch: 5| Step: 6
Training loss: 0.2645573019981384
Validation loss: 1.5884074825112537

Epoch: 5| Step: 7
Training loss: 0.16957822442054749
Validation loss: 1.5986041125430857

Epoch: 5| Step: 8
Training loss: 0.14759674668312073
Validation loss: 1.5829667698952459

Epoch: 5| Step: 9
Training loss: 0.31442761421203613
Validation loss: 1.5575195666282409

Epoch: 5| Step: 10
Training loss: 0.5887038707733154
Validation loss: 1.561839658726928

Epoch: 432| Step: 0
Training loss: 0.22997181117534637
Validation loss: 1.5613911078181317

Epoch: 5| Step: 1
Training loss: 0.30007874965667725
Validation loss: 1.5678507845888856

Epoch: 5| Step: 2
Training loss: 0.28452369570732117
Validation loss: 1.554025146269029

Epoch: 5| Step: 3
Training loss: 0.24012279510498047
Validation loss: 1.565517940828877

Epoch: 5| Step: 4
Training loss: 0.2394355982542038
Validation loss: 1.5869486408848916

Epoch: 5| Step: 5
Training loss: 0.34038692712783813
Validation loss: 1.5483339089219288

Epoch: 5| Step: 6
Training loss: 0.1743018925189972
Validation loss: 1.5851902346457205

Epoch: 5| Step: 7
Training loss: 0.11483614146709442
Validation loss: 1.5841945794320875

Epoch: 5| Step: 8
Training loss: 0.1563471108675003
Validation loss: 1.6091611013617566

Epoch: 5| Step: 9
Training loss: 0.24479444324970245
Validation loss: 1.6179877891335437

Epoch: 5| Step: 10
Training loss: 0.6576159596443176
Validation loss: 1.590995705255898

Epoch: 433| Step: 0
Training loss: 0.08643690496683121
Validation loss: 1.615718774898078

Epoch: 5| Step: 1
Training loss: 0.40625014901161194
Validation loss: 1.6305137462513422

Epoch: 5| Step: 2
Training loss: 0.49248918890953064
Validation loss: 1.6190369359908565

Epoch: 5| Step: 3
Training loss: 0.24145789444446564
Validation loss: 1.62857404575553

Epoch: 5| Step: 4
Training loss: 0.16539084911346436
Validation loss: 1.658919011392901

Epoch: 5| Step: 5
Training loss: 0.29087620973587036
Validation loss: 1.629582756309099

Epoch: 5| Step: 6
Training loss: 0.10428335517644882
Validation loss: 1.6558803499385875

Epoch: 5| Step: 7
Training loss: 0.2613266408443451
Validation loss: 1.667417731336368

Epoch: 5| Step: 8
Training loss: 0.22743038833141327
Validation loss: 1.677469802159135

Epoch: 5| Step: 9
Training loss: 0.3572663366794586
Validation loss: 1.6906051430650937

Epoch: 5| Step: 10
Training loss: 0.31116223335266113
Validation loss: 1.689056711812173

Epoch: 434| Step: 0
Training loss: 0.1601782590150833
Validation loss: 1.6923202712048766

Epoch: 5| Step: 1
Training loss: 0.3599731922149658
Validation loss: 1.6712496639579855

Epoch: 5| Step: 2
Training loss: 0.2277805060148239
Validation loss: 1.7058755441378521

Epoch: 5| Step: 3
Training loss: 0.24941548705101013
Validation loss: 1.7164266635012884

Epoch: 5| Step: 4
Training loss: 0.3001752495765686
Validation loss: 1.7010574648457188

Epoch: 5| Step: 5
Training loss: 0.20967765152454376
Validation loss: 1.6986896555910829

Epoch: 5| Step: 6
Training loss: 0.45428961515426636
Validation loss: 1.6758275711408226

Epoch: 5| Step: 7
Training loss: 0.2356119453907013
Validation loss: 1.6432168573461554

Epoch: 5| Step: 8
Training loss: 0.25715622305870056
Validation loss: 1.5830610074022764

Epoch: 5| Step: 9
Training loss: 0.10772134363651276
Validation loss: 1.6057285211419547

Epoch: 5| Step: 10
Training loss: 0.17677630484104156
Validation loss: 1.5822652283535208

Epoch: 435| Step: 0
Training loss: 0.14522726833820343
Validation loss: 1.5742635650019492

Epoch: 5| Step: 1
Training loss: 0.21752047538757324
Validation loss: 1.5949816831978418

Epoch: 5| Step: 2
Training loss: 0.3437786102294922
Validation loss: 1.6358619556632092

Epoch: 5| Step: 3
Training loss: 0.35599225759506226
Validation loss: 1.7012037564349431

Epoch: 5| Step: 4
Training loss: 0.32405462861061096
Validation loss: 1.7067898986160115

Epoch: 5| Step: 5
Training loss: 0.32759469747543335
Validation loss: 1.7337627449343282

Epoch: 5| Step: 6
Training loss: 0.2903887629508972
Validation loss: 1.6478580633799236

Epoch: 5| Step: 7
Training loss: 0.5655567049980164
Validation loss: 1.6358864115130516

Epoch: 5| Step: 8
Training loss: 0.23747634887695312
Validation loss: 1.5896934514404626

Epoch: 5| Step: 9
Training loss: 0.27132847905158997
Validation loss: 1.5923667095040763

Epoch: 5| Step: 10
Training loss: 0.24384018778800964
Validation loss: 1.5904964157330093

Epoch: 436| Step: 0
Training loss: 0.48025497794151306
Validation loss: 1.5789851001513902

Epoch: 5| Step: 1
Training loss: 0.1829378306865692
Validation loss: 1.5351758477508382

Epoch: 5| Step: 2
Training loss: 0.3311658799648285
Validation loss: 1.5454599011328913

Epoch: 5| Step: 3
Training loss: 0.38316863775253296
Validation loss: 1.5769473173285042

Epoch: 5| Step: 4
Training loss: 0.21573786437511444
Validation loss: 1.5898655563272455

Epoch: 5| Step: 5
Training loss: 0.20877961814403534
Validation loss: 1.6105185388236918

Epoch: 5| Step: 6
Training loss: 0.19979611039161682
Validation loss: 1.6202993431398947

Epoch: 5| Step: 7
Training loss: 0.3034721910953522
Validation loss: 1.613261785558475

Epoch: 5| Step: 8
Training loss: 0.2396450787782669
Validation loss: 1.5958578496850946

Epoch: 5| Step: 9
Training loss: 0.26338696479797363
Validation loss: 1.59326159825889

Epoch: 5| Step: 10
Training loss: 0.24718685448169708
Validation loss: 1.6056142417333459

Epoch: 437| Step: 0
Training loss: 0.4794497489929199
Validation loss: 1.604539478978803

Epoch: 5| Step: 1
Training loss: 0.14629985392093658
Validation loss: 1.6716149417302941

Epoch: 5| Step: 2
Training loss: 0.21395286917686462
Validation loss: 1.6561157523944814

Epoch: 5| Step: 3
Training loss: 0.21656806766986847
Validation loss: 1.652266679271575

Epoch: 5| Step: 4
Training loss: 0.2751176357269287
Validation loss: 1.6563597674010901

Epoch: 5| Step: 5
Training loss: 0.22864027321338654
Validation loss: 1.6420906807786675

Epoch: 5| Step: 6
Training loss: 0.32603174448013306
Validation loss: 1.599955185767143

Epoch: 5| Step: 7
Training loss: 0.34526902437210083
Validation loss: 1.587640397010311

Epoch: 5| Step: 8
Training loss: 0.21518346667289734
Validation loss: 1.5762127496862923

Epoch: 5| Step: 9
Training loss: 0.1408856213092804
Validation loss: 1.5848346576895764

Epoch: 5| Step: 10
Training loss: 0.3439634442329407
Validation loss: 1.598918790458351

Epoch: 438| Step: 0
Training loss: 0.2679763436317444
Validation loss: 1.6085862049492456

Epoch: 5| Step: 1
Training loss: 0.2447604238986969
Validation loss: 1.614153121107368

Epoch: 5| Step: 2
Training loss: 0.2896490693092346
Validation loss: 1.6154985197128788

Epoch: 5| Step: 3
Training loss: 0.294132798910141
Validation loss: 1.6215565973712551

Epoch: 5| Step: 4
Training loss: 0.17143623530864716
Validation loss: 1.6142277076680174

Epoch: 5| Step: 5
Training loss: 0.2556392550468445
Validation loss: 1.6312871838128695

Epoch: 5| Step: 6
Training loss: 0.1259220391511917
Validation loss: 1.6232829452842794

Epoch: 5| Step: 7
Training loss: 0.36640363931655884
Validation loss: 1.5938465364517704

Epoch: 5| Step: 8
Training loss: 0.42977848649024963
Validation loss: 1.6142820606949508

Epoch: 5| Step: 9
Training loss: 0.1436115950345993
Validation loss: 1.6185637315114338

Epoch: 5| Step: 10
Training loss: 0.24671706557273865
Validation loss: 1.6500780582427979

Epoch: 439| Step: 0
Training loss: 0.21348366141319275
Validation loss: 1.6738471331134919

Epoch: 5| Step: 1
Training loss: 0.2629580497741699
Validation loss: 1.664763883877826

Epoch: 5| Step: 2
Training loss: 0.324758380651474
Validation loss: 1.643659822402462

Epoch: 5| Step: 3
Training loss: 0.15843167901039124
Validation loss: 1.6216212716153873

Epoch: 5| Step: 4
Training loss: 0.24221262335777283
Validation loss: 1.6145552537774528

Epoch: 5| Step: 5
Training loss: 0.4238629937171936
Validation loss: 1.620793983500491

Epoch: 5| Step: 6
Training loss: 0.24474087357521057
Validation loss: 1.6144392977478683

Epoch: 5| Step: 7
Training loss: 0.27855753898620605
Validation loss: 1.6255639291578723

Epoch: 5| Step: 8
Training loss: 0.17491576075553894
Validation loss: 1.6447770134095223

Epoch: 5| Step: 9
Training loss: 0.28416338562965393
Validation loss: 1.6879013892143004

Epoch: 5| Step: 10
Training loss: 0.5113496780395508
Validation loss: 1.712105970228872

Epoch: 440| Step: 0
Training loss: 0.23579291999340057
Validation loss: 1.7143247204442178

Epoch: 5| Step: 1
Training loss: 0.20442330837249756
Validation loss: 1.6598523803936538

Epoch: 5| Step: 2
Training loss: 0.1695447415113449
Validation loss: 1.6217226110478884

Epoch: 5| Step: 3
Training loss: 0.3322801887989044
Validation loss: 1.5762440171293033

Epoch: 5| Step: 4
Training loss: 0.21403560042381287
Validation loss: 1.5780374324449928

Epoch: 5| Step: 5
Training loss: 0.20512337982654572
Validation loss: 1.5641959444169076

Epoch: 5| Step: 6
Training loss: 0.7280364036560059
Validation loss: 1.5660407530364169

Epoch: 5| Step: 7
Training loss: 0.24399395287036896
Validation loss: 1.5621072592273835

Epoch: 5| Step: 8
Training loss: 0.26820608973503113
Validation loss: 1.577823083887818

Epoch: 5| Step: 9
Training loss: 0.24697792530059814
Validation loss: 1.6272153123732536

Epoch: 5| Step: 10
Training loss: 0.3409423828125
Validation loss: 1.593171158144551

Epoch: 441| Step: 0
Training loss: 0.2206588089466095
Validation loss: 1.602426254621116

Epoch: 5| Step: 1
Training loss: 0.2135346382856369
Validation loss: 1.610219947753414

Epoch: 5| Step: 2
Training loss: 0.485440731048584
Validation loss: 1.594738769274886

Epoch: 5| Step: 3
Training loss: 0.21437375247478485
Validation loss: 1.5856937593029392

Epoch: 5| Step: 4
Training loss: 0.2522074580192566
Validation loss: 1.5946487111430014

Epoch: 5| Step: 5
Training loss: 0.24780675768852234
Validation loss: 1.5661977189843372

Epoch: 5| Step: 6
Training loss: 0.32742953300476074
Validation loss: 1.5665624705694055

Epoch: 5| Step: 7
Training loss: 0.2428038865327835
Validation loss: 1.5448759063597648

Epoch: 5| Step: 8
Training loss: 0.24277560412883759
Validation loss: 1.5496363332194667

Epoch: 5| Step: 9
Training loss: 0.3408493101596832
Validation loss: 1.5419910530890188

Epoch: 5| Step: 10
Training loss: 0.17471498250961304
Validation loss: 1.6004131199211202

Epoch: 442| Step: 0
Training loss: 0.29425176978111267
Validation loss: 1.5863168085775068

Epoch: 5| Step: 1
Training loss: 0.15744976699352264
Validation loss: 1.597394662518655

Epoch: 5| Step: 2
Training loss: 0.521325409412384
Validation loss: 1.6027572129362373

Epoch: 5| Step: 3
Training loss: 0.23479337990283966
Validation loss: 1.6246436411334622

Epoch: 5| Step: 4
Training loss: 0.1982213407754898
Validation loss: 1.5981470538723854

Epoch: 5| Step: 5
Training loss: 0.18158411979675293
Validation loss: 1.5924887336710447

Epoch: 5| Step: 6
Training loss: 0.1651465892791748
Validation loss: 1.5891786339462444

Epoch: 5| Step: 7
Training loss: 0.1932496577501297
Validation loss: 1.5885171646712928

Epoch: 5| Step: 8
Training loss: 0.2445329874753952
Validation loss: 1.614733297337768

Epoch: 5| Step: 9
Training loss: 0.3246876299381256
Validation loss: 1.6095568415939168

Epoch: 5| Step: 10
Training loss: 0.1266259104013443
Validation loss: 1.5931274762717627

Epoch: 443| Step: 0
Training loss: 0.31060880422592163
Validation loss: 1.5858909609497234

Epoch: 5| Step: 1
Training loss: 0.20150217413902283
Validation loss: 1.5908781507963776

Epoch: 5| Step: 2
Training loss: 0.5299823880195618
Validation loss: 1.6126733902961976

Epoch: 5| Step: 3
Training loss: 0.30240288376808167
Validation loss: 1.6075963973999023

Epoch: 5| Step: 4
Training loss: 0.17012600600719452
Validation loss: 1.604974708249492

Epoch: 5| Step: 5
Training loss: 0.2685319781303406
Validation loss: 1.6036224724144064

Epoch: 5| Step: 6
Training loss: 0.19811436533927917
Validation loss: 1.6062766800644577

Epoch: 5| Step: 7
Training loss: 0.15783089399337769
Validation loss: 1.6535784403483074

Epoch: 5| Step: 8
Training loss: 0.23958034813404083
Validation loss: 1.6548962387987363

Epoch: 5| Step: 9
Training loss: 0.13297827541828156
Validation loss: 1.6537623520820373

Epoch: 5| Step: 10
Training loss: 0.2836878001689911
Validation loss: 1.647139855610427

Epoch: 444| Step: 0
Training loss: 0.1901671588420868
Validation loss: 1.6999682303397887

Epoch: 5| Step: 1
Training loss: 0.16830193996429443
Validation loss: 1.7094699682727936

Epoch: 5| Step: 2
Training loss: 0.279624879360199
Validation loss: 1.6733380094651253

Epoch: 5| Step: 3
Training loss: 0.24256673455238342
Validation loss: 1.6810232670076433

Epoch: 5| Step: 4
Training loss: 0.17017415165901184
Validation loss: 1.648405259655368

Epoch: 5| Step: 5
Training loss: 0.18902596831321716
Validation loss: 1.6578979940824612

Epoch: 5| Step: 6
Training loss: 0.2906225323677063
Validation loss: 1.5999907806355467

Epoch: 5| Step: 7
Training loss: 0.2713608145713806
Validation loss: 1.614172181775493

Epoch: 5| Step: 8
Training loss: 0.5608335733413696
Validation loss: 1.5642972633402834

Epoch: 5| Step: 9
Training loss: 0.21694719791412354
Validation loss: 1.559444155744327

Epoch: 5| Step: 10
Training loss: 0.26813146471977234
Validation loss: 1.5325866553091234

Epoch: 445| Step: 0
Training loss: 0.3380524516105652
Validation loss: 1.550064775251573

Epoch: 5| Step: 1
Training loss: 0.24427470564842224
Validation loss: 1.5265922982205626

Epoch: 5| Step: 2
Training loss: 0.16142123937606812
Validation loss: 1.5716967057156306

Epoch: 5| Step: 3
Training loss: 0.5400587320327759
Validation loss: 1.5871379452366983

Epoch: 5| Step: 4
Training loss: 0.3058984875679016
Validation loss: 1.585395138750794

Epoch: 5| Step: 5
Training loss: 0.25802284479141235
Validation loss: 1.6192329942539174

Epoch: 5| Step: 6
Training loss: 0.21001052856445312
Validation loss: 1.606105371188092

Epoch: 5| Step: 7
Training loss: 0.32133811712265015
Validation loss: 1.5908394628955471

Epoch: 5| Step: 8
Training loss: 0.4513057768344879
Validation loss: 1.5921848307373703

Epoch: 5| Step: 9
Training loss: 0.184393972158432
Validation loss: 1.6064692043489026

Epoch: 5| Step: 10
Training loss: 0.19944946467876434
Validation loss: 1.5853144866164013

Epoch: 446| Step: 0
Training loss: 0.5678049325942993
Validation loss: 1.5750407980334373

Epoch: 5| Step: 1
Training loss: 0.13616812229156494
Validation loss: 1.5777664556298205

Epoch: 5| Step: 2
Training loss: 0.30229493975639343
Validation loss: 1.5840527588321316

Epoch: 5| Step: 3
Training loss: 0.24096255004405975
Validation loss: 1.5805591908834313

Epoch: 5| Step: 4
Training loss: 0.20197518169879913
Validation loss: 1.5838952308060021

Epoch: 5| Step: 5
Training loss: 0.3220023214817047
Validation loss: 1.6012874803235453

Epoch: 5| Step: 6
Training loss: 0.16090980172157288
Validation loss: 1.6286961391407957

Epoch: 5| Step: 7
Training loss: 0.23341874778270721
Validation loss: 1.624705078781292

Epoch: 5| Step: 8
Training loss: 0.2514435946941376
Validation loss: 1.6592747229401783

Epoch: 5| Step: 9
Training loss: 0.33601370453834534
Validation loss: 1.6941748306315432

Epoch: 5| Step: 10
Training loss: 0.2534840404987335
Validation loss: 1.6908699299699517

Epoch: 447| Step: 0
Training loss: 0.19922897219657898
Validation loss: 1.6555514450996154

Epoch: 5| Step: 1
Training loss: 0.18264195322990417
Validation loss: 1.6339685839991416

Epoch: 5| Step: 2
Training loss: 0.5469989776611328
Validation loss: 1.6188845596005839

Epoch: 5| Step: 3
Training loss: 0.3755432963371277
Validation loss: 1.6248987432449096

Epoch: 5| Step: 4
Training loss: 0.24582023918628693
Validation loss: 1.581055792429114

Epoch: 5| Step: 5
Training loss: 0.20742526650428772
Validation loss: 1.6026975877823368

Epoch: 5| Step: 6
Training loss: 0.31588324904441833
Validation loss: 1.5753667495583976

Epoch: 5| Step: 7
Training loss: 0.2792227864265442
Validation loss: 1.5810940547655987

Epoch: 5| Step: 8
Training loss: 0.19955380260944366
Validation loss: 1.5783750677621493

Epoch: 5| Step: 9
Training loss: 0.2072133719921112
Validation loss: 1.5866796047456804

Epoch: 5| Step: 10
Training loss: 0.25326913595199585
Validation loss: 1.5994858754578458

Epoch: 448| Step: 0
Training loss: 0.294859379529953
Validation loss: 1.5912844839916434

Epoch: 5| Step: 1
Training loss: 0.3722483217716217
Validation loss: 1.5586725524676743

Epoch: 5| Step: 2
Training loss: 0.1967240571975708
Validation loss: 1.5633926160873906

Epoch: 5| Step: 3
Training loss: 0.22951838374137878
Validation loss: 1.5909142930020568

Epoch: 5| Step: 4
Training loss: 0.4565763473510742
Validation loss: 1.5410112411745134

Epoch: 5| Step: 5
Training loss: 0.20423635840415955
Validation loss: 1.56933533248081

Epoch: 5| Step: 6
Training loss: 0.36575809121131897
Validation loss: 1.5494513537294121

Epoch: 5| Step: 7
Training loss: 0.3126050531864166
Validation loss: 1.53764352362643

Epoch: 5| Step: 8
Training loss: 0.20125822722911835
Validation loss: 1.5586235548860283

Epoch: 5| Step: 9
Training loss: 0.2581396698951721
Validation loss: 1.5511974288571266

Epoch: 5| Step: 10
Training loss: 0.14482367038726807
Validation loss: 1.5786064171021985

Epoch: 449| Step: 0
Training loss: 0.4802749752998352
Validation loss: 1.6392043944328063

Epoch: 5| Step: 1
Training loss: 0.3113589286804199
Validation loss: 1.6781995136250731

Epoch: 5| Step: 2
Training loss: 0.26193830370903015
Validation loss: 1.687784271855508

Epoch: 5| Step: 3
Training loss: 0.26720696687698364
Validation loss: 1.7005203526507142

Epoch: 5| Step: 4
Training loss: 0.16018910706043243
Validation loss: 1.7109892419589463

Epoch: 5| Step: 5
Training loss: 0.4058839678764343
Validation loss: 1.6963780112163995

Epoch: 5| Step: 6
Training loss: 0.20553982257843018
Validation loss: 1.6867298618439706

Epoch: 5| Step: 7
Training loss: 0.2089128941297531
Validation loss: 1.6877632602568595

Epoch: 5| Step: 8
Training loss: 0.16252866387367249
Validation loss: 1.690230356749668

Epoch: 5| Step: 9
Training loss: 0.1758042871952057
Validation loss: 1.6733109528018582

Epoch: 5| Step: 10
Training loss: 0.15103475749492645
Validation loss: 1.650318125242828

Epoch: 450| Step: 0
Training loss: 0.21823528409004211
Validation loss: 1.6293205676540252

Epoch: 5| Step: 1
Training loss: 0.16943566501140594
Validation loss: 1.6285225396515222

Epoch: 5| Step: 2
Training loss: 0.22415801882743835
Validation loss: 1.6315130431164977

Epoch: 5| Step: 3
Training loss: 0.265408992767334
Validation loss: 1.634001116598806

Epoch: 5| Step: 4
Training loss: 0.17345300316810608
Validation loss: 1.655892756677443

Epoch: 5| Step: 5
Training loss: 0.3162991404533386
Validation loss: 1.6128505391459311

Epoch: 5| Step: 6
Training loss: 0.5283521413803101
Validation loss: 1.6155724307542205

Epoch: 5| Step: 7
Training loss: 0.09939181059598923
Validation loss: 1.5829814236651185

Epoch: 5| Step: 8
Training loss: 0.159017875790596
Validation loss: 1.5838475624720256

Epoch: 5| Step: 9
Training loss: 0.29012930393218994
Validation loss: 1.5354575469929685

Epoch: 5| Step: 10
Training loss: 0.24872863292694092
Validation loss: 1.5224471963861936

Epoch: 451| Step: 0
Training loss: 0.17012318968772888
Validation loss: 1.5025286251498806

Epoch: 5| Step: 1
Training loss: 0.33545857667922974
Validation loss: 1.5392601957885168

Epoch: 5| Step: 2
Training loss: 0.25283920764923096
Validation loss: 1.5260609631897302

Epoch: 5| Step: 3
Training loss: 0.36279040575027466
Validation loss: 1.5205876365784676

Epoch: 5| Step: 4
Training loss: 0.30560484528541565
Validation loss: 1.5419809613176572

Epoch: 5| Step: 5
Training loss: 0.21482881903648376
Validation loss: 1.537328758547383

Epoch: 5| Step: 6
Training loss: 0.16200998425483704
Validation loss: 1.5883628206868325

Epoch: 5| Step: 7
Training loss: 0.46608519554138184
Validation loss: 1.5736991538796374

Epoch: 5| Step: 8
Training loss: 0.10179848968982697
Validation loss: 1.5603312856407576

Epoch: 5| Step: 9
Training loss: 0.28161460161209106
Validation loss: 1.5697697606138004

Epoch: 5| Step: 10
Training loss: 0.23593324422836304
Validation loss: 1.5886090840062788

Epoch: 452| Step: 0
Training loss: 0.2066139429807663
Validation loss: 1.5805207670375865

Epoch: 5| Step: 1
Training loss: 0.24161548912525177
Validation loss: 1.5613467308782762

Epoch: 5| Step: 2
Training loss: 0.2491540014743805
Validation loss: 1.5826345066870413

Epoch: 5| Step: 3
Training loss: 0.43334704637527466
Validation loss: 1.5484382696049188

Epoch: 5| Step: 4
Training loss: 0.15815849602222443
Validation loss: 1.571648701544731

Epoch: 5| Step: 5
Training loss: 0.2261538952589035
Validation loss: 1.5765345775952904

Epoch: 5| Step: 6
Training loss: 0.22398808598518372
Validation loss: 1.590337291840584

Epoch: 5| Step: 7
Training loss: 0.2744141221046448
Validation loss: 1.5942809709938623

Epoch: 5| Step: 8
Training loss: 0.22312280535697937
Validation loss: 1.6113318461243824

Epoch: 5| Step: 9
Training loss: 0.30997174978256226
Validation loss: 1.6112016580438102

Epoch: 5| Step: 10
Training loss: 0.1640676110982895
Validation loss: 1.620762509684409

Epoch: 453| Step: 0
Training loss: 0.1907750815153122
Validation loss: 1.6072348298565033

Epoch: 5| Step: 1
Training loss: 0.5090395212173462
Validation loss: 1.6072076328339115

Epoch: 5| Step: 2
Training loss: 0.1477469801902771
Validation loss: 1.5900613389989382

Epoch: 5| Step: 3
Training loss: 0.25292468070983887
Validation loss: 1.5817248052166355

Epoch: 5| Step: 4
Training loss: 0.18928948044776917
Validation loss: 1.5815188666825652

Epoch: 5| Step: 5
Training loss: 0.1696065217256546
Validation loss: 1.6259725593751477

Epoch: 5| Step: 6
Training loss: 0.28078585863113403
Validation loss: 1.6063510538429342

Epoch: 5| Step: 7
Training loss: 0.25477954745292664
Validation loss: 1.599576835991234

Epoch: 5| Step: 8
Training loss: 0.23690219223499298
Validation loss: 1.568993563934039

Epoch: 5| Step: 9
Training loss: 0.14675262570381165
Validation loss: 1.6154282650639933

Epoch: 5| Step: 10
Training loss: 0.2211913764476776
Validation loss: 1.5708497954953102

Epoch: 454| Step: 0
Training loss: 0.20688295364379883
Validation loss: 1.6110041038964384

Epoch: 5| Step: 1
Training loss: 0.20511193573474884
Validation loss: 1.5923508136503157

Epoch: 5| Step: 2
Training loss: 0.1539027988910675
Validation loss: 1.6040971381689912

Epoch: 5| Step: 3
Training loss: 0.21672466397285461
Validation loss: 1.6286500256548646

Epoch: 5| Step: 4
Training loss: 0.14594297111034393
Validation loss: 1.6131765022072742

Epoch: 5| Step: 5
Training loss: 0.5604814291000366
Validation loss: 1.6160913411007132

Epoch: 5| Step: 6
Training loss: 0.16427627205848694
Validation loss: 1.5817851738263202

Epoch: 5| Step: 7
Training loss: 0.26286420226097107
Validation loss: 1.5992584843789377

Epoch: 5| Step: 8
Training loss: 0.3637143075466156
Validation loss: 1.6128326449342953

Epoch: 5| Step: 9
Training loss: 0.17764434218406677
Validation loss: 1.6225898804203156

Epoch: 5| Step: 10
Training loss: 0.2380463033914566
Validation loss: 1.5957039133194955

Epoch: 455| Step: 0
Training loss: 0.2893657088279724
Validation loss: 1.5736687606380833

Epoch: 5| Step: 1
Training loss: 0.16643169522285461
Validation loss: 1.5946505185096496

Epoch: 5| Step: 2
Training loss: 0.21583834290504456
Validation loss: 1.6111790557061472

Epoch: 5| Step: 3
Training loss: 0.5656668543815613
Validation loss: 1.5900073538544357

Epoch: 5| Step: 4
Training loss: 0.1504589021205902
Validation loss: 1.5947645030995852

Epoch: 5| Step: 5
Training loss: 0.15555165708065033
Validation loss: 1.6224822716046405

Epoch: 5| Step: 6
Training loss: 0.282611608505249
Validation loss: 1.6369161452016523

Epoch: 5| Step: 7
Training loss: 0.16422155499458313
Validation loss: 1.6243411007747854

Epoch: 5| Step: 8
Training loss: 0.18641169369220734
Validation loss: 1.638911001143917

Epoch: 5| Step: 9
Training loss: 0.18511171638965607
Validation loss: 1.6397022726715251

Epoch: 5| Step: 10
Training loss: 0.2351188361644745
Validation loss: 1.6436953006252166

Epoch: 456| Step: 0
Training loss: 0.19935907423496246
Validation loss: 1.6438220034363449

Epoch: 5| Step: 1
Training loss: 0.2867949604988098
Validation loss: 1.669452881300321

Epoch: 5| Step: 2
Training loss: 0.3160870373249054
Validation loss: 1.6823669966831003

Epoch: 5| Step: 3
Training loss: 0.1781812608242035
Validation loss: 1.6651297858966294

Epoch: 5| Step: 4
Training loss: 0.14856643974781036
Validation loss: 1.6452495897969892

Epoch: 5| Step: 5
Training loss: 0.435377299785614
Validation loss: 1.5995739929137691

Epoch: 5| Step: 6
Training loss: 0.22037439048290253
Validation loss: 1.641516638058488

Epoch: 5| Step: 7
Training loss: 0.13795605301856995
Validation loss: 1.5988324560144895

Epoch: 5| Step: 8
Training loss: 0.14313820004463196
Validation loss: 1.5976792689292663

Epoch: 5| Step: 9
Training loss: 0.1324121654033661
Validation loss: 1.5689826562840452

Epoch: 5| Step: 10
Training loss: 0.24258743226528168
Validation loss: 1.566846618729253

Epoch: 457| Step: 0
Training loss: 0.22161321341991425
Validation loss: 1.5542641967855475

Epoch: 5| Step: 1
Training loss: 0.12121765315532684
Validation loss: 1.576574158924882

Epoch: 5| Step: 2
Training loss: 0.5573056936264038
Validation loss: 1.5819439785454863

Epoch: 5| Step: 3
Training loss: 0.16521760821342468
Validation loss: 1.5573776127189718

Epoch: 5| Step: 4
Training loss: 0.2686002552509308
Validation loss: 1.5620368244827434

Epoch: 5| Step: 5
Training loss: 0.2337939292192459
Validation loss: 1.568669399907512

Epoch: 5| Step: 6
Training loss: 0.10396803915500641
Validation loss: 1.5373075123756164

Epoch: 5| Step: 7
Training loss: 0.18992602825164795
Validation loss: 1.5817741617079704

Epoch: 5| Step: 8
Training loss: 0.2124445140361786
Validation loss: 1.5718314429765106

Epoch: 5| Step: 9
Training loss: 0.1882377415895462
Validation loss: 1.5629295059429702

Epoch: 5| Step: 10
Training loss: 0.15330706536769867
Validation loss: 1.5696856603827527

Epoch: 458| Step: 0
Training loss: 0.17037083208560944
Validation loss: 1.580371585584456

Epoch: 5| Step: 1
Training loss: 0.3484271764755249
Validation loss: 1.5850500881030996

Epoch: 5| Step: 2
Training loss: 0.186914324760437
Validation loss: 1.5806144040117982

Epoch: 5| Step: 3
Training loss: 0.404022216796875
Validation loss: 1.6084687338080457

Epoch: 5| Step: 4
Training loss: 0.13006873428821564
Validation loss: 1.5987621340700375

Epoch: 5| Step: 5
Training loss: 0.26175886392593384
Validation loss: 1.6104530006326654

Epoch: 5| Step: 6
Training loss: 0.1458377093076706
Validation loss: 1.6140172366173036

Epoch: 5| Step: 7
Training loss: 0.26498642563819885
Validation loss: 1.6313198074217765

Epoch: 5| Step: 8
Training loss: 0.2509235739707947
Validation loss: 1.6290871026695415

Epoch: 5| Step: 9
Training loss: 0.1919199526309967
Validation loss: 1.6272794738892586

Epoch: 5| Step: 10
Training loss: 0.1264449805021286
Validation loss: 1.629483502398255

Epoch: 459| Step: 0
Training loss: 0.24804167449474335
Validation loss: 1.6367701753493278

Epoch: 5| Step: 1
Training loss: 0.22631719708442688
Validation loss: 1.6117922208642448

Epoch: 5| Step: 2
Training loss: 0.2961133122444153
Validation loss: 1.5921936855521253

Epoch: 5| Step: 3
Training loss: 0.21951420605182648
Validation loss: 1.6098930528087

Epoch: 5| Step: 4
Training loss: 0.20397600531578064
Validation loss: 1.600412525156493

Epoch: 5| Step: 5
Training loss: 0.2960464358329773
Validation loss: 1.5894650925872147

Epoch: 5| Step: 6
Training loss: 0.16996411979198456
Validation loss: 1.5989397328387025

Epoch: 5| Step: 7
Training loss: 0.23396046459674835
Validation loss: 1.5607175083570584

Epoch: 5| Step: 8
Training loss: 0.41663700342178345
Validation loss: 1.5989143438236688

Epoch: 5| Step: 9
Training loss: 0.1400996297597885
Validation loss: 1.6004174755465599

Epoch: 5| Step: 10
Training loss: 0.13994969427585602
Validation loss: 1.5999493188755487

Epoch: 460| Step: 0
Training loss: 0.37791329622268677
Validation loss: 1.5603394136633923

Epoch: 5| Step: 1
Training loss: 0.08085491508245468
Validation loss: 1.5370585226243543

Epoch: 5| Step: 2
Training loss: 0.3016952872276306
Validation loss: 1.53097641083502

Epoch: 5| Step: 3
Training loss: 0.20444588363170624
Validation loss: 1.5447598785482428

Epoch: 5| Step: 4
Training loss: 0.15322470664978027
Validation loss: 1.5199996886714813

Epoch: 5| Step: 5
Training loss: 0.18116430938243866
Validation loss: 1.5515531762953727

Epoch: 5| Step: 6
Training loss: 0.27014973759651184
Validation loss: 1.5279127628572526

Epoch: 5| Step: 7
Training loss: 0.16334374248981476
Validation loss: 1.5328336723389164

Epoch: 5| Step: 8
Training loss: 0.25693193078041077
Validation loss: 1.5504659337382163

Epoch: 5| Step: 9
Training loss: 0.25084787607192993
Validation loss: 1.5410767268109065

Epoch: 5| Step: 10
Training loss: 0.22517183423042297
Validation loss: 1.5491944384831253

Epoch: 461| Step: 0
Training loss: 0.24744871258735657
Validation loss: 1.5744407253880655

Epoch: 5| Step: 1
Training loss: 0.2649124264717102
Validation loss: 1.5856004979020806

Epoch: 5| Step: 2
Training loss: 0.15792055428028107
Validation loss: 1.5710868694448983

Epoch: 5| Step: 3
Training loss: 0.14519639313220978
Validation loss: 1.5686753206355597

Epoch: 5| Step: 4
Training loss: 0.23110580444335938
Validation loss: 1.5485801043048981

Epoch: 5| Step: 5
Training loss: 0.37541961669921875
Validation loss: 1.5164544915640226

Epoch: 5| Step: 6
Training loss: 0.3241581916809082
Validation loss: 1.5606964236946517

Epoch: 5| Step: 7
Training loss: 0.22148814797401428
Validation loss: 1.511297886089612

Epoch: 5| Step: 8
Training loss: 0.1547498106956482
Validation loss: 1.5409809838059128

Epoch: 5| Step: 9
Training loss: 0.23226003348827362
Validation loss: 1.5219793499156993

Epoch: 5| Step: 10
Training loss: 0.520596444606781
Validation loss: 1.5371865072558004

Epoch: 462| Step: 0
Training loss: 0.2881946861743927
Validation loss: 1.5328965481891428

Epoch: 5| Step: 1
Training loss: 0.27934885025024414
Validation loss: 1.5599787696715324

Epoch: 5| Step: 2
Training loss: 0.1397666186094284
Validation loss: 1.5798936582380725

Epoch: 5| Step: 3
Training loss: 0.1603396236896515
Validation loss: 1.6437624757007887

Epoch: 5| Step: 4
Training loss: 0.3099172115325928
Validation loss: 1.6309289047794957

Epoch: 5| Step: 5
Training loss: 0.24285385012626648
Validation loss: 1.6499874752054933

Epoch: 5| Step: 6
Training loss: 0.22239546477794647
Validation loss: 1.6461035884836668

Epoch: 5| Step: 7
Training loss: 0.5070714354515076
Validation loss: 1.620017005551246

Epoch: 5| Step: 8
Training loss: 0.19796118140220642
Validation loss: 1.6223966242164694

Epoch: 5| Step: 9
Training loss: 0.1794734001159668
Validation loss: 1.5985987135159072

Epoch: 5| Step: 10
Training loss: 0.20253412425518036
Validation loss: 1.575216229243945

Epoch: 463| Step: 0
Training loss: 0.26055678725242615
Validation loss: 1.5955614351457166

Epoch: 5| Step: 1
Training loss: 0.26541048288345337
Validation loss: 1.5981743438269502

Epoch: 5| Step: 2
Training loss: 0.16576024889945984
Validation loss: 1.593996573519963

Epoch: 5| Step: 3
Training loss: 0.28983113169670105
Validation loss: 1.599327633457799

Epoch: 5| Step: 4
Training loss: 0.2666938304901123
Validation loss: 1.6306240827806535

Epoch: 5| Step: 5
Training loss: 0.19865623116493225
Validation loss: 1.6138608853022258

Epoch: 5| Step: 6
Training loss: 0.4463334083557129
Validation loss: 1.6376969416936238

Epoch: 5| Step: 7
Training loss: 0.20510311424732208
Validation loss: 1.6397796984641784

Epoch: 5| Step: 8
Training loss: 0.19643929600715637
Validation loss: 1.6316798194762199

Epoch: 5| Step: 9
Training loss: 0.19478820264339447
Validation loss: 1.6031641857598418

Epoch: 5| Step: 10
Training loss: 0.1751476377248764
Validation loss: 1.6181741734986663

Epoch: 464| Step: 0
Training loss: 0.223760724067688
Validation loss: 1.642347340942711

Epoch: 5| Step: 1
Training loss: 0.2272251546382904
Validation loss: 1.6436297073159167

Epoch: 5| Step: 2
Training loss: 0.3633800446987152
Validation loss: 1.612344846930555

Epoch: 5| Step: 3
Training loss: 0.2072780877351761
Validation loss: 1.6395805330686672

Epoch: 5| Step: 4
Training loss: 0.34023675322532654
Validation loss: 1.6357483684375722

Epoch: 5| Step: 5
Training loss: 0.1353362798690796
Validation loss: 1.639442962984885

Epoch: 5| Step: 6
Training loss: 0.17810194194316864
Validation loss: 1.6330156377566758

Epoch: 5| Step: 7
Training loss: 0.2211061716079712
Validation loss: 1.6271006676458544

Epoch: 5| Step: 8
Training loss: 0.25998741388320923
Validation loss: 1.6209371461663196

Epoch: 5| Step: 9
Training loss: 0.10695500671863556
Validation loss: 1.6035194884064377

Epoch: 5| Step: 10
Training loss: 0.1790923923254013
Validation loss: 1.6137026074112102

Epoch: 465| Step: 0
Training loss: 0.44917792081832886
Validation loss: 1.6180179670292845

Epoch: 5| Step: 1
Training loss: 0.18884797394275665
Validation loss: 1.6169078721795032

Epoch: 5| Step: 2
Training loss: 0.1625850647687912
Validation loss: 1.623035910309002

Epoch: 5| Step: 3
Training loss: 0.1578252613544464
Validation loss: 1.598797340546885

Epoch: 5| Step: 4
Training loss: 0.2936691641807556
Validation loss: 1.602989589014361

Epoch: 5| Step: 5
Training loss: 0.2589431405067444
Validation loss: 1.580704431379995

Epoch: 5| Step: 6
Training loss: 0.25800377130508423
Validation loss: 1.5951244433720906

Epoch: 5| Step: 7
Training loss: 0.2534252107143402
Validation loss: 1.5931565184747019

Epoch: 5| Step: 8
Training loss: 0.1290396749973297
Validation loss: 1.5792873290277296

Epoch: 5| Step: 9
Training loss: 0.15059341490268707
Validation loss: 1.6282856669477237

Epoch: 5| Step: 10
Training loss: 0.15303589403629303
Validation loss: 1.6288019277716195

Epoch: 466| Step: 0
Training loss: 0.23150329291820526
Validation loss: 1.6230832197332894

Epoch: 5| Step: 1
Training loss: 0.13960953056812286
Validation loss: 1.6128511249378163

Epoch: 5| Step: 2
Training loss: 0.18990781903266907
Validation loss: 1.618941125049386

Epoch: 5| Step: 3
Training loss: 0.13200485706329346
Validation loss: 1.6134461164474487

Epoch: 5| Step: 4
Training loss: 0.2526315152645111
Validation loss: 1.6098670741563201

Epoch: 5| Step: 5
Training loss: 0.23426365852355957
Validation loss: 1.629581125833655

Epoch: 5| Step: 6
Training loss: 0.18069550395011902
Validation loss: 1.6219530605500745

Epoch: 5| Step: 7
Training loss: 0.4286181330680847
Validation loss: 1.6245551487450958

Epoch: 5| Step: 8
Training loss: 0.23510055243968964
Validation loss: 1.6450294410028765

Epoch: 5| Step: 9
Training loss: 0.16509033739566803
Validation loss: 1.6419465939203899

Epoch: 5| Step: 10
Training loss: 0.2478581666946411
Validation loss: 1.620809449944445

Epoch: 467| Step: 0
Training loss: 0.17576178908348083
Validation loss: 1.6151648170204573

Epoch: 5| Step: 1
Training loss: 0.2824029326438904
Validation loss: 1.631803015226959

Epoch: 5| Step: 2
Training loss: 0.3107094168663025
Validation loss: 1.6275124024319392

Epoch: 5| Step: 3
Training loss: 0.16744586825370789
Validation loss: 1.59463833737117

Epoch: 5| Step: 4
Training loss: 0.3687802255153656
Validation loss: 1.5879965828311058

Epoch: 5| Step: 5
Training loss: 0.21072645485401154
Validation loss: 1.57607989926492

Epoch: 5| Step: 6
Training loss: 0.17326071858406067
Validation loss: 1.5827571589459655

Epoch: 5| Step: 7
Training loss: 0.19307443499565125
Validation loss: 1.5960654725310623

Epoch: 5| Step: 8
Training loss: 0.23852410912513733
Validation loss: 1.6045193223543064

Epoch: 5| Step: 9
Training loss: 0.2659323811531067
Validation loss: 1.581884535410071

Epoch: 5| Step: 10
Training loss: 0.16547945141792297
Validation loss: 1.583961755998673

Epoch: 468| Step: 0
Training loss: 0.2318669855594635
Validation loss: 1.58921439801493

Epoch: 5| Step: 1
Training loss: 0.22981944680213928
Validation loss: 1.6033456197348974

Epoch: 5| Step: 2
Training loss: 0.2552299499511719
Validation loss: 1.6093371068277667

Epoch: 5| Step: 3
Training loss: 0.19138136506080627
Validation loss: 1.589115931141761

Epoch: 5| Step: 4
Training loss: 0.17859646677970886
Validation loss: 1.5792482796535696

Epoch: 5| Step: 5
Training loss: 0.23733648657798767
Validation loss: 1.552197056431924

Epoch: 5| Step: 6
Training loss: 0.23405277729034424
Validation loss: 1.5583371718724568

Epoch: 5| Step: 7
Training loss: 0.32775822281837463
Validation loss: 1.5562983046295822

Epoch: 5| Step: 8
Training loss: 0.13906510174274445
Validation loss: 1.5876970970502464

Epoch: 5| Step: 9
Training loss: 0.3721669912338257
Validation loss: 1.565408193936912

Epoch: 5| Step: 10
Training loss: 0.22892136871814728
Validation loss: 1.5583367373353691

Epoch: 469| Step: 0
Training loss: 0.3030838072299957
Validation loss: 1.585842146668383

Epoch: 5| Step: 1
Training loss: 0.16848400235176086
Validation loss: 1.5946642237324868

Epoch: 5| Step: 2
Training loss: 0.12590079009532928
Validation loss: 1.6081492580393308

Epoch: 5| Step: 3
Training loss: 0.21186666190624237
Validation loss: 1.6023449218401344

Epoch: 5| Step: 4
Training loss: 0.15762634575366974
Validation loss: 1.6179874186874719

Epoch: 5| Step: 5
Training loss: 0.1448441594839096
Validation loss: 1.6276031719741

Epoch: 5| Step: 6
Training loss: 0.20541028678417206
Validation loss: 1.6353077644942908

Epoch: 5| Step: 7
Training loss: 0.18177154660224915
Validation loss: 1.635600314345411

Epoch: 5| Step: 8
Training loss: 0.5004156827926636
Validation loss: 1.6487560990036174

Epoch: 5| Step: 9
Training loss: 0.26367130875587463
Validation loss: 1.639822006225586

Epoch: 5| Step: 10
Training loss: 0.35570839047431946
Validation loss: 1.600875868592211

Epoch: 470| Step: 0
Training loss: 0.1292235404253006
Validation loss: 1.6319321188875424

Epoch: 5| Step: 1
Training loss: 0.12236881256103516
Validation loss: 1.6073343535905242

Epoch: 5| Step: 2
Training loss: 0.1446896344423294
Validation loss: 1.6088390145250546

Epoch: 5| Step: 3
Training loss: 0.14322297275066376
Validation loss: 1.6201300313395839

Epoch: 5| Step: 4
Training loss: 0.2270796298980713
Validation loss: 1.6199401322231497

Epoch: 5| Step: 5
Training loss: 0.26184970140457153
Validation loss: 1.6181645521553614

Epoch: 5| Step: 6
Training loss: 0.1715914011001587
Validation loss: 1.6003605101698188

Epoch: 5| Step: 7
Training loss: 0.2250048816204071
Validation loss: 1.6026019101501794

Epoch: 5| Step: 8
Training loss: 0.45847004652023315
Validation loss: 1.6361917750809782

Epoch: 5| Step: 9
Training loss: 0.22531655430793762
Validation loss: 1.6160496191311908

Epoch: 5| Step: 10
Training loss: 0.38402050733566284
Validation loss: 1.5776467771940335

Epoch: 471| Step: 0
Training loss: 0.15101651847362518
Validation loss: 1.5326735806721512

Epoch: 5| Step: 1
Training loss: 0.4781048893928528
Validation loss: 1.5546877563640635

Epoch: 5| Step: 2
Training loss: 0.16857793927192688
Validation loss: 1.5397758509523125

Epoch: 5| Step: 3
Training loss: 0.2074788361787796
Validation loss: 1.554953154697213

Epoch: 5| Step: 4
Training loss: 0.2790919840335846
Validation loss: 1.5427156302236742

Epoch: 5| Step: 5
Training loss: 0.2833244204521179
Validation loss: 1.551878103645899

Epoch: 5| Step: 6
Training loss: 0.24741551280021667
Validation loss: 1.5559072494506836

Epoch: 5| Step: 7
Training loss: 0.1776755154132843
Validation loss: 1.5675998733889671

Epoch: 5| Step: 8
Training loss: 0.13723377883434296
Validation loss: 1.5722725775934034

Epoch: 5| Step: 9
Training loss: 0.17845265567302704
Validation loss: 1.5571540978647047

Epoch: 5| Step: 10
Training loss: 0.15163575112819672
Validation loss: 1.5606528353947464

Epoch: 472| Step: 0
Training loss: 0.1257215440273285
Validation loss: 1.548145733853822

Epoch: 5| Step: 1
Training loss: 0.4881269037723541
Validation loss: 1.5602625249534525

Epoch: 5| Step: 2
Training loss: 0.2507034242153168
Validation loss: 1.553637498168535

Epoch: 5| Step: 3
Training loss: 0.12438080459833145
Validation loss: 1.536017999854139

Epoch: 5| Step: 4
Training loss: 0.22832922637462616
Validation loss: 1.5388348358933643

Epoch: 5| Step: 5
Training loss: 0.29368722438812256
Validation loss: 1.5532046466745355

Epoch: 5| Step: 6
Training loss: 0.21853551268577576
Validation loss: 1.5545492467059885

Epoch: 5| Step: 7
Training loss: 0.10465769469738007
Validation loss: 1.5271621365700998

Epoch: 5| Step: 8
Training loss: 0.1235559731721878
Validation loss: 1.5423211352799528

Epoch: 5| Step: 9
Training loss: 0.22353622317314148
Validation loss: 1.5454696762946345

Epoch: 5| Step: 10
Training loss: 0.07608918100595474
Validation loss: 1.526963395457114

Epoch: 473| Step: 0
Training loss: 0.2497953474521637
Validation loss: 1.6050254093703402

Epoch: 5| Step: 1
Training loss: 0.26601576805114746
Validation loss: 1.5830654815960956

Epoch: 5| Step: 2
Training loss: 0.44686803221702576
Validation loss: 1.559275076594404

Epoch: 5| Step: 3
Training loss: 0.2364765703678131
Validation loss: 1.5724715417431248

Epoch: 5| Step: 4
Training loss: 0.3021355867385864
Validation loss: 1.5816961770416589

Epoch: 5| Step: 5
Training loss: 0.12093635648488998
Validation loss: 1.5970586294768958

Epoch: 5| Step: 6
Training loss: 0.22572597861289978
Validation loss: 1.5959215817912933

Epoch: 5| Step: 7
Training loss: 0.2876926064491272
Validation loss: 1.579454920625174

Epoch: 5| Step: 8
Training loss: 0.18627338111400604
Validation loss: 1.6011596020831858

Epoch: 5| Step: 9
Training loss: 0.283747136592865
Validation loss: 1.5928266150977022

Epoch: 5| Step: 10
Training loss: 0.2055031806230545
Validation loss: 1.5632663183314826

Epoch: 474| Step: 0
Training loss: 0.16821520030498505
Validation loss: 1.5741120743495163

Epoch: 5| Step: 1
Training loss: 0.13105323910713196
Validation loss: 1.5793413474995603

Epoch: 5| Step: 2
Training loss: 0.20853081345558167
Validation loss: 1.585536673504819

Epoch: 5| Step: 3
Training loss: 0.23247075080871582
Validation loss: 1.565036654472351

Epoch: 5| Step: 4
Training loss: 0.28721779584884644
Validation loss: 1.566780440268978

Epoch: 5| Step: 5
Training loss: 0.2098967581987381
Validation loss: 1.6050272744189027

Epoch: 5| Step: 6
Training loss: 0.18738405406475067
Validation loss: 1.6358918515584802

Epoch: 5| Step: 7
Training loss: 0.41479700803756714
Validation loss: 1.6331085646024315

Epoch: 5| Step: 8
Training loss: 0.1948697715997696
Validation loss: 1.6435355076225855

Epoch: 5| Step: 9
Training loss: 0.23348745703697205
Validation loss: 1.6667983660133936

Epoch: 5| Step: 10
Training loss: 0.36702415347099304
Validation loss: 1.6228814817244006

Epoch: 475| Step: 0
Training loss: 0.20822080969810486
Validation loss: 1.6236572643761993

Epoch: 5| Step: 1
Training loss: 0.2610960602760315
Validation loss: 1.6226199852522982

Epoch: 5| Step: 2
Training loss: 0.18777000904083252
Validation loss: 1.6164059241612752

Epoch: 5| Step: 3
Training loss: 0.13652434945106506
Validation loss: 1.572208401977375

Epoch: 5| Step: 4
Training loss: 0.20208735764026642
Validation loss: 1.5736277962243685

Epoch: 5| Step: 5
Training loss: 0.4554091989994049
Validation loss: 1.561396232215307

Epoch: 5| Step: 6
Training loss: 0.21631865203380585
Validation loss: 1.5792446431293283

Epoch: 5| Step: 7
Training loss: 0.13652363419532776
Validation loss: 1.583791584096929

Epoch: 5| Step: 8
Training loss: 0.17523901164531708
Validation loss: 1.5820165244481896

Epoch: 5| Step: 9
Training loss: 0.15445271134376526
Validation loss: 1.5472681586460402

Epoch: 5| Step: 10
Training loss: 0.31109505891799927
Validation loss: 1.5744034961987567

Epoch: 476| Step: 0
Training loss: 0.1987268030643463
Validation loss: 1.5824699081400389

Epoch: 5| Step: 1
Training loss: 0.24986740946769714
Validation loss: 1.563624362791738

Epoch: 5| Step: 2
Training loss: 0.19264265894889832
Validation loss: 1.6093845469977266

Epoch: 5| Step: 3
Training loss: 0.14443695545196533
Validation loss: 1.5942854817195604

Epoch: 5| Step: 4
Training loss: 0.11680476367473602
Validation loss: 1.5612772690352572

Epoch: 5| Step: 5
Training loss: 0.1118670329451561
Validation loss: 1.5908740246167747

Epoch: 5| Step: 6
Training loss: 0.3055526614189148
Validation loss: 1.5508599037765174

Epoch: 5| Step: 7
Training loss: 0.38117045164108276
Validation loss: 1.5083427121562343

Epoch: 5| Step: 8
Training loss: 0.12309608608484268
Validation loss: 1.5592674978317753

Epoch: 5| Step: 9
Training loss: 0.23490023612976074
Validation loss: 1.5482713201994538

Epoch: 5| Step: 10
Training loss: 0.2588934004306793
Validation loss: 1.5341526359640143

Epoch: 477| Step: 0
Training loss: 0.16603270173072815
Validation loss: 1.5656311332538564

Epoch: 5| Step: 1
Training loss: 0.08995119482278824
Validation loss: 1.5607902426873483

Epoch: 5| Step: 2
Training loss: 0.28818279504776
Validation loss: 1.574978882266629

Epoch: 5| Step: 3
Training loss: 0.4167807698249817
Validation loss: 1.6117954523332658

Epoch: 5| Step: 4
Training loss: 0.13779526948928833
Validation loss: 1.6172704658200663

Epoch: 5| Step: 5
Training loss: 0.11639956384897232
Validation loss: 1.6180652418444235

Epoch: 5| Step: 6
Training loss: 0.1902758777141571
Validation loss: 1.634660813116258

Epoch: 5| Step: 7
Training loss: 0.19322796165943146
Validation loss: 1.6173793782470047

Epoch: 5| Step: 8
Training loss: 0.13123977184295654
Validation loss: 1.6187222933256498

Epoch: 5| Step: 9
Training loss: 0.21599987149238586
Validation loss: 1.6343438958608976

Epoch: 5| Step: 10
Training loss: 0.3536216616630554
Validation loss: 1.6070383248790618

Epoch: 478| Step: 0
Training loss: 0.17230109870433807
Validation loss: 1.6009774900251819

Epoch: 5| Step: 1
Training loss: 0.1380663961172104
Validation loss: 1.6166247142258512

Epoch: 5| Step: 2
Training loss: 0.26343029737472534
Validation loss: 1.608654991272957

Epoch: 5| Step: 3
Training loss: 0.1926179975271225
Validation loss: 1.6165193819230603

Epoch: 5| Step: 4
Training loss: 0.1409953385591507
Validation loss: 1.5990901666302835

Epoch: 5| Step: 5
Training loss: 0.21291513741016388
Validation loss: 1.5868932944472118

Epoch: 5| Step: 6
Training loss: 0.22487211227416992
Validation loss: 1.5784265713025165

Epoch: 5| Step: 7
Training loss: 0.15193650126457214
Validation loss: 1.5861870729795067

Epoch: 5| Step: 8
Training loss: 0.14189520478248596
Validation loss: 1.5544851338991554

Epoch: 5| Step: 9
Training loss: 0.547718346118927
Validation loss: 1.5732088858081448

Epoch: 5| Step: 10
Training loss: 0.19195692241191864
Validation loss: 1.5563262803580171

Epoch: 479| Step: 0
Training loss: 0.29296356439590454
Validation loss: 1.570371009970224

Epoch: 5| Step: 1
Training loss: 0.4167686402797699
Validation loss: 1.5506182729556997

Epoch: 5| Step: 2
Training loss: 0.2615290582180023
Validation loss: 1.543695709397716

Epoch: 5| Step: 3
Training loss: 0.14441968500614166
Validation loss: 1.5605905709728118

Epoch: 5| Step: 4
Training loss: 0.11823694407939911
Validation loss: 1.5533846373199134

Epoch: 5| Step: 5
Training loss: 0.08733955770730972
Validation loss: 1.5537825560057035

Epoch: 5| Step: 6
Training loss: 0.08383619040250778
Validation loss: 1.5742745117474628

Epoch: 5| Step: 7
Training loss: 0.16523249447345734
Validation loss: 1.5584089627829931

Epoch: 5| Step: 8
Training loss: 0.22888138890266418
Validation loss: 1.5789360961606425

Epoch: 5| Step: 9
Training loss: 0.270168274641037
Validation loss: 1.5472741075741347

Epoch: 5| Step: 10
Training loss: 0.1260383427143097
Validation loss: 1.5382646770887478

Epoch: 480| Step: 0
Training loss: 0.15625359117984772
Validation loss: 1.577241675828093

Epoch: 5| Step: 1
Training loss: 0.1825961172580719
Validation loss: 1.5794566190370949

Epoch: 5| Step: 2
Training loss: 0.15948621928691864
Validation loss: 1.5522114282013268

Epoch: 5| Step: 3
Training loss: 0.17451068758964539
Validation loss: 1.5732410197616906

Epoch: 5| Step: 4
Training loss: 0.14752371609210968
Validation loss: 1.5467769868912236

Epoch: 5| Step: 5
Training loss: 0.2009260207414627
Validation loss: 1.5589179518402263

Epoch: 5| Step: 6
Training loss: 0.2416984587907791
Validation loss: 1.546223235386674

Epoch: 5| Step: 7
Training loss: 0.3210225999355316
Validation loss: 1.520555038605967

Epoch: 5| Step: 8
Training loss: 0.41295748949050903
Validation loss: 1.5554765847421461

Epoch: 5| Step: 9
Training loss: 0.09942669421434402
Validation loss: 1.5550430551651986

Epoch: 5| Step: 10
Training loss: 0.14361128211021423
Validation loss: 1.5467135726764638

Epoch: 481| Step: 0
Training loss: 0.2313307821750641
Validation loss: 1.5750133375967703

Epoch: 5| Step: 1
Training loss: 0.10551873594522476
Validation loss: 1.5472738025008992

Epoch: 5| Step: 2
Training loss: 0.1714632362127304
Validation loss: 1.5373780894023117

Epoch: 5| Step: 3
Training loss: 0.14139923453330994
Validation loss: 1.5699781756247244

Epoch: 5| Step: 4
Training loss: 0.12994113564491272
Validation loss: 1.5544000671755882

Epoch: 5| Step: 5
Training loss: 0.29502779245376587
Validation loss: 1.5557566586361136

Epoch: 5| Step: 6
Training loss: 0.0910012274980545
Validation loss: 1.5670198253405991

Epoch: 5| Step: 7
Training loss: 0.46207207441329956
Validation loss: 1.57562118704601

Epoch: 5| Step: 8
Training loss: 0.20884351432323456
Validation loss: 1.5851817925771077

Epoch: 5| Step: 9
Training loss: 0.18605944514274597
Validation loss: 1.5661941215556154

Epoch: 5| Step: 10
Training loss: 0.1479150801897049
Validation loss: 1.5549856065421976

Epoch: 482| Step: 0
Training loss: 0.15600556135177612
Validation loss: 1.5608242673258628

Epoch: 5| Step: 1
Training loss: 0.42098236083984375
Validation loss: 1.5610971091895975

Epoch: 5| Step: 2
Training loss: 0.16987687349319458
Validation loss: 1.5525344405122983

Epoch: 5| Step: 3
Training loss: 0.21607866883277893
Validation loss: 1.5302600194049139

Epoch: 5| Step: 4
Training loss: 0.2610969841480255
Validation loss: 1.5337741195514638

Epoch: 5| Step: 5
Training loss: 0.17148979008197784
Validation loss: 1.531096378962199

Epoch: 5| Step: 6
Training loss: 0.1604377031326294
Validation loss: 1.525294944804202

Epoch: 5| Step: 7
Training loss: 0.18783928453922272
Validation loss: 1.5329480427567677

Epoch: 5| Step: 8
Training loss: 0.07863054424524307
Validation loss: 1.5573645945518249

Epoch: 5| Step: 9
Training loss: 0.21256928145885468
Validation loss: 1.5471042651002125

Epoch: 5| Step: 10
Training loss: 0.16826806962490082
Validation loss: 1.5356761063298872

Epoch: 483| Step: 0
Training loss: 0.2238040417432785
Validation loss: 1.5572928382504372

Epoch: 5| Step: 1
Training loss: 0.2134043276309967
Validation loss: 1.5710734295588669

Epoch: 5| Step: 2
Training loss: 0.14717493951320648
Validation loss: 1.5528998310847948

Epoch: 5| Step: 3
Training loss: 0.1582736223936081
Validation loss: 1.5317585916929348

Epoch: 5| Step: 4
Training loss: 0.4945722222328186
Validation loss: 1.5488005850904731

Epoch: 5| Step: 5
Training loss: 0.07533158361911774
Validation loss: 1.4831570912432928

Epoch: 5| Step: 6
Training loss: 0.13356247544288635
Validation loss: 1.5157343703572468

Epoch: 5| Step: 7
Training loss: 0.1745445728302002
Validation loss: 1.5078497791803012

Epoch: 5| Step: 8
Training loss: 0.2079584300518036
Validation loss: 1.5287297143731067

Epoch: 5| Step: 9
Training loss: 0.17034944891929626
Validation loss: 1.5104680958614554

Epoch: 5| Step: 10
Training loss: 0.22279265522956848
Validation loss: 1.5591545451071955

Epoch: 484| Step: 0
Training loss: 0.16116595268249512
Validation loss: 1.574513098245026

Epoch: 5| Step: 1
Training loss: 0.16340163350105286
Validation loss: 1.583820576308876

Epoch: 5| Step: 2
Training loss: 0.4010031819343567
Validation loss: 1.5927476908570977

Epoch: 5| Step: 3
Training loss: 0.18422099947929382
Validation loss: 1.5998214060260403

Epoch: 5| Step: 4
Training loss: 0.2225746214389801
Validation loss: 1.612781117039342

Epoch: 5| Step: 5
Training loss: 0.180799663066864
Validation loss: 1.5785046123689221

Epoch: 5| Step: 6
Training loss: 0.22378408908843994
Validation loss: 1.559402201765327

Epoch: 5| Step: 7
Training loss: 0.09684064984321594
Validation loss: 1.5575584519294001

Epoch: 5| Step: 8
Training loss: 0.19096550345420837
Validation loss: 1.5257550183162893

Epoch: 5| Step: 9
Training loss: 0.1447668820619583
Validation loss: 1.54194349627341

Epoch: 5| Step: 10
Training loss: 0.3107949495315552
Validation loss: 1.515405539543398

Epoch: 485| Step: 0
Training loss: 0.18543574213981628
Validation loss: 1.5261040887525004

Epoch: 5| Step: 1
Training loss: 0.21529045701026917
Validation loss: 1.5366298165372623

Epoch: 5| Step: 2
Training loss: 0.15837445855140686
Validation loss: 1.5568741752255348

Epoch: 5| Step: 3
Training loss: 0.12570814788341522
Validation loss: 1.5514243930898688

Epoch: 5| Step: 4
Training loss: 0.2572709918022156
Validation loss: 1.573356398972132

Epoch: 5| Step: 5
Training loss: 0.11377082020044327
Validation loss: 1.5820325741203882

Epoch: 5| Step: 6
Training loss: 0.17162595689296722
Validation loss: 1.5985989339890019

Epoch: 5| Step: 7
Training loss: 0.14870861172676086
Validation loss: 1.6061511142279512

Epoch: 5| Step: 8
Training loss: 0.510514497756958
Validation loss: 1.6372684189068374

Epoch: 5| Step: 9
Training loss: 0.18849128484725952
Validation loss: 1.6339858078187512

Epoch: 5| Step: 10
Training loss: 0.26439547538757324
Validation loss: 1.594257559827579

Epoch: 486| Step: 0
Training loss: 0.09541304409503937
Validation loss: 1.6146970820683304

Epoch: 5| Step: 1
Training loss: 0.20248985290527344
Validation loss: 1.5927332114147883

Epoch: 5| Step: 2
Training loss: 0.20567485690116882
Validation loss: 1.583421358498194

Epoch: 5| Step: 3
Training loss: 0.3809724748134613
Validation loss: 1.5883902888144217

Epoch: 5| Step: 4
Training loss: 0.21657733619213104
Validation loss: 1.5917886021316692

Epoch: 5| Step: 5
Training loss: 0.18282295763492584
Validation loss: 1.6088340820804719

Epoch: 5| Step: 6
Training loss: 0.20974507927894592
Validation loss: 1.5843587780511508

Epoch: 5| Step: 7
Training loss: 0.1874806135892868
Validation loss: 1.6143023416560183

Epoch: 5| Step: 8
Training loss: 0.26172319054603577
Validation loss: 1.6090007674309514

Epoch: 5| Step: 9
Training loss: 0.15171608328819275
Validation loss: 1.6300423658022316

Epoch: 5| Step: 10
Training loss: 0.22434280812740326
Validation loss: 1.6296873323379024

Epoch: 487| Step: 0
Training loss: 0.18731780350208282
Validation loss: 1.665560728760176

Epoch: 5| Step: 1
Training loss: 0.23419828712940216
Validation loss: 1.6778737088685394

Epoch: 5| Step: 2
Training loss: 0.24962261319160461
Validation loss: 1.643229901790619

Epoch: 5| Step: 3
Training loss: 0.19729574024677277
Validation loss: 1.5837488059074647

Epoch: 5| Step: 4
Training loss: 0.22367504239082336
Validation loss: 1.555334291150493

Epoch: 5| Step: 5
Training loss: 0.18012192845344543
Validation loss: 1.530553985667485

Epoch: 5| Step: 6
Training loss: 0.20889969170093536
Validation loss: 1.4979525996792702

Epoch: 5| Step: 7
Training loss: 0.1623474657535553
Validation loss: 1.5032004861421482

Epoch: 5| Step: 8
Training loss: 0.12856361269950867
Validation loss: 1.4812355528595627

Epoch: 5| Step: 9
Training loss: 0.2060638964176178
Validation loss: 1.4920137274649836

Epoch: 5| Step: 10
Training loss: 0.5187391638755798
Validation loss: 1.4898551638408373

Epoch: 488| Step: 0
Training loss: 0.2047353982925415
Validation loss: 1.4970828243481216

Epoch: 5| Step: 1
Training loss: 0.2554561495780945
Validation loss: 1.5088796993737579

Epoch: 5| Step: 2
Training loss: 0.42844516038894653
Validation loss: 1.5321443439811788

Epoch: 5| Step: 3
Training loss: 0.20408539474010468
Validation loss: 1.533410422263607

Epoch: 5| Step: 4
Training loss: 0.1792796552181244
Validation loss: 1.5327972571055095

Epoch: 5| Step: 5
Training loss: 0.16840282082557678
Validation loss: 1.560898450113112

Epoch: 5| Step: 6
Training loss: 0.1784420907497406
Validation loss: 1.5242990652720134

Epoch: 5| Step: 7
Training loss: 0.19733352959156036
Validation loss: 1.5417784772893435

Epoch: 5| Step: 8
Training loss: 0.15401513874530792
Validation loss: 1.5385022035209082

Epoch: 5| Step: 9
Training loss: 0.12234945595264435
Validation loss: 1.550364464841863

Epoch: 5| Step: 10
Training loss: 0.25324785709381104
Validation loss: 1.5594632664034445

Epoch: 489| Step: 0
Training loss: 0.1163647398352623
Validation loss: 1.5788103572783931

Epoch: 5| Step: 1
Training loss: 0.1608685553073883
Validation loss: 1.5576912626143424

Epoch: 5| Step: 2
Training loss: 0.15223972499370575
Validation loss: 1.6252423512038363

Epoch: 5| Step: 3
Training loss: 0.2045675814151764
Validation loss: 1.6068269539904851

Epoch: 5| Step: 4
Training loss: 0.17931920289993286
Validation loss: 1.6208858323353592

Epoch: 5| Step: 5
Training loss: 0.42594796419143677
Validation loss: 1.6013989346001738

Epoch: 5| Step: 6
Training loss: 0.1501602679491043
Validation loss: 1.5962446351205148

Epoch: 5| Step: 7
Training loss: 0.18220075964927673
Validation loss: 1.5929501877036145

Epoch: 5| Step: 8
Training loss: 0.1366415023803711
Validation loss: 1.5503477242685133

Epoch: 5| Step: 9
Training loss: 0.1602807343006134
Validation loss: 1.5610502484024211

Epoch: 5| Step: 10
Training loss: 0.3623412251472473
Validation loss: 1.5898740253140848

Epoch: 490| Step: 0
Training loss: 0.22135284543037415
Validation loss: 1.589091794465178

Epoch: 5| Step: 1
Training loss: 0.1541963517665863
Validation loss: 1.5986161014085174

Epoch: 5| Step: 2
Training loss: 0.21073749661445618
Validation loss: 1.5967780326002388

Epoch: 5| Step: 3
Training loss: 0.4670119285583496
Validation loss: 1.630765115061114

Epoch: 5| Step: 4
Training loss: 0.22981806099414825
Validation loss: 1.563540522770215

Epoch: 5| Step: 5
Training loss: 0.2173675000667572
Validation loss: 1.556848846456056

Epoch: 5| Step: 6
Training loss: 0.19158415496349335
Validation loss: 1.54826650440052

Epoch: 5| Step: 7
Training loss: 0.13348472118377686
Validation loss: 1.5189562856510122

Epoch: 5| Step: 8
Training loss: 0.19545266032218933
Validation loss: 1.5379169089819795

Epoch: 5| Step: 9
Training loss: 0.2661171853542328
Validation loss: 1.535285649761077

Epoch: 5| Step: 10
Training loss: 0.21975916624069214
Validation loss: 1.5070726102398289

Epoch: 491| Step: 0
Training loss: 0.44474300742149353
Validation loss: 1.5291639656148932

Epoch: 5| Step: 1
Training loss: 0.14208519458770752
Validation loss: 1.508989469979399

Epoch: 5| Step: 2
Training loss: 0.16226598620414734
Validation loss: 1.5458571193038777

Epoch: 5| Step: 3
Training loss: 0.26360031962394714
Validation loss: 1.5289042483093918

Epoch: 5| Step: 4
Training loss: 0.18941235542297363
Validation loss: 1.6024717182241461

Epoch: 5| Step: 5
Training loss: 0.2503042221069336
Validation loss: 1.6413777066815285

Epoch: 5| Step: 6
Training loss: 0.30959251523017883
Validation loss: 1.6638937932188793

Epoch: 5| Step: 7
Training loss: 0.2583887577056885
Validation loss: 1.6392705857112844

Epoch: 5| Step: 8
Training loss: 0.26973146200180054
Validation loss: 1.618947873833359

Epoch: 5| Step: 9
Training loss: 0.15040811896324158
Validation loss: 1.570664841641662

Epoch: 5| Step: 10
Training loss: 0.16902278363704681
Validation loss: 1.5925943889925558

Epoch: 492| Step: 0
Training loss: 0.18887600302696228
Validation loss: 1.5737099647521973

Epoch: 5| Step: 1
Training loss: 0.3276505470275879
Validation loss: 1.6160919538108252

Epoch: 5| Step: 2
Training loss: 0.24405090510845184
Validation loss: 1.6068755042168401

Epoch: 5| Step: 3
Training loss: 0.14867781102657318
Validation loss: 1.5717238431335778

Epoch: 5| Step: 4
Training loss: 0.33485206961631775
Validation loss: 1.5479128501748527

Epoch: 5| Step: 5
Training loss: 0.2049872875213623
Validation loss: 1.5330373651237899

Epoch: 5| Step: 6
Training loss: 0.21305188536643982
Validation loss: 1.5117745950657835

Epoch: 5| Step: 7
Training loss: 0.19258847832679749
Validation loss: 1.5305788414452666

Epoch: 5| Step: 8
Training loss: 0.1537812054157257
Validation loss: 1.5150478552746516

Epoch: 5| Step: 9
Training loss: 0.4169643819332123
Validation loss: 1.5542431877505394

Epoch: 5| Step: 10
Training loss: 0.1831972301006317
Validation loss: 1.5635421558093

Epoch: 493| Step: 0
Training loss: 0.2146589308977127
Validation loss: 1.557429144459386

Epoch: 5| Step: 1
Training loss: 0.2712527811527252
Validation loss: 1.5777027824873566

Epoch: 5| Step: 2
Training loss: 0.11091537773609161
Validation loss: 1.5412850931126585

Epoch: 5| Step: 3
Training loss: 0.14139221608638763
Validation loss: 1.5393045871488509

Epoch: 5| Step: 4
Training loss: 0.4269554018974304
Validation loss: 1.5182010960835282

Epoch: 5| Step: 5
Training loss: 0.24477772414684296
Validation loss: 1.5038406695089033

Epoch: 5| Step: 6
Training loss: 0.13088712096214294
Validation loss: 1.4972073993375223

Epoch: 5| Step: 7
Training loss: 0.19508138298988342
Validation loss: 1.5142367783413138

Epoch: 5| Step: 8
Training loss: 0.21594461798667908
Validation loss: 1.5375382131145847

Epoch: 5| Step: 9
Training loss: 0.27339911460876465
Validation loss: 1.5243389760294268

Epoch: 5| Step: 10
Training loss: 0.2060168981552124
Validation loss: 1.5179550442644345

Epoch: 494| Step: 0
Training loss: 0.19211648404598236
Validation loss: 1.5210677039238714

Epoch: 5| Step: 1
Training loss: 0.13652612268924713
Validation loss: 1.553828643214318

Epoch: 5| Step: 2
Training loss: 0.17132586240768433
Validation loss: 1.5746882115640948

Epoch: 5| Step: 3
Training loss: 0.19021932780742645
Validation loss: 1.603539720658333

Epoch: 5| Step: 4
Training loss: 0.17107176780700684
Validation loss: 1.6267155139676985

Epoch: 5| Step: 5
Training loss: 0.18092060089111328
Validation loss: 1.620350335233955

Epoch: 5| Step: 6
Training loss: 0.15148356556892395
Validation loss: 1.6096819805842575

Epoch: 5| Step: 7
Training loss: 0.39058059453964233
Validation loss: 1.5770818328344693

Epoch: 5| Step: 8
Training loss: 0.20203474164009094
Validation loss: 1.5775116387233938

Epoch: 5| Step: 9
Training loss: 0.147375226020813
Validation loss: 1.5259313737192461

Epoch: 5| Step: 10
Training loss: 0.20956291258335114
Validation loss: 1.4947560538527787

Epoch: 495| Step: 0
Training loss: 0.12756675481796265
Validation loss: 1.4876666812486545

Epoch: 5| Step: 1
Training loss: 0.17420808970928192
Validation loss: 1.4799901452115787

Epoch: 5| Step: 2
Training loss: 0.22329604625701904
Validation loss: 1.4677360916650424

Epoch: 5| Step: 3
Training loss: 0.1807563155889511
Validation loss: 1.4556729088547409

Epoch: 5| Step: 4
Training loss: 0.15328797698020935
Validation loss: 1.4714072391551027

Epoch: 5| Step: 5
Training loss: 0.29760226607322693
Validation loss: 1.4749225326763686

Epoch: 5| Step: 6
Training loss: 0.10426151752471924
Validation loss: 1.4648259173157394

Epoch: 5| Step: 7
Training loss: 0.17303302884101868
Validation loss: 1.463328610184372

Epoch: 5| Step: 8
Training loss: 0.45040005445480347
Validation loss: 1.4849928130385697

Epoch: 5| Step: 9
Training loss: 0.13268177211284637
Validation loss: 1.4971664515874719

Epoch: 5| Step: 10
Training loss: 0.08938009291887283
Validation loss: 1.513498995893745

Epoch: 496| Step: 0
Training loss: 0.11734552681446075
Validation loss: 1.5302267625767698

Epoch: 5| Step: 1
Training loss: 0.11926126480102539
Validation loss: 1.525115752732882

Epoch: 5| Step: 2
Training loss: 0.2112969607114792
Validation loss: 1.5383159319559734

Epoch: 5| Step: 3
Training loss: 0.10923914611339569
Validation loss: 1.5224237288198164

Epoch: 5| Step: 4
Training loss: 0.1688501536846161
Validation loss: 1.547922290781493

Epoch: 5| Step: 5
Training loss: 0.33669430017471313
Validation loss: 1.5695373473628875

Epoch: 5| Step: 6
Training loss: 0.16369763016700745
Validation loss: 1.5846205014054493

Epoch: 5| Step: 7
Training loss: 0.12958475947380066
Validation loss: 1.5864389314446399

Epoch: 5| Step: 8
Training loss: 0.3809766173362732
Validation loss: 1.555324988980447

Epoch: 5| Step: 9
Training loss: 0.1581791639328003
Validation loss: 1.538967635041924

Epoch: 5| Step: 10
Training loss: 0.17310655117034912
Validation loss: 1.5483304838980398

Epoch: 497| Step: 0
Training loss: 0.26459336280822754
Validation loss: 1.5322969434081868

Epoch: 5| Step: 1
Training loss: 0.18819968402385712
Validation loss: 1.555204790125611

Epoch: 5| Step: 2
Training loss: 0.13951906561851501
Validation loss: 1.5366230613441878

Epoch: 5| Step: 3
Training loss: 0.14012494683265686
Validation loss: 1.5595290917222218

Epoch: 5| Step: 4
Training loss: 0.15804019570350647
Validation loss: 1.545986936938378

Epoch: 5| Step: 5
Training loss: 0.1268889307975769
Validation loss: 1.552330837454847

Epoch: 5| Step: 6
Training loss: 0.1462567299604416
Validation loss: 1.552221537918173

Epoch: 5| Step: 7
Training loss: 0.448904812335968
Validation loss: 1.5175119689715806

Epoch: 5| Step: 8
Training loss: 0.13662651181221008
Validation loss: 1.5477741226073234

Epoch: 5| Step: 9
Training loss: 0.09057757258415222
Validation loss: 1.5280240581881614

Epoch: 5| Step: 10
Training loss: 0.18151690065860748
Validation loss: 1.5204212281011766

Epoch: 498| Step: 0
Training loss: 0.12588746845722198
Validation loss: 1.512339335615917

Epoch: 5| Step: 1
Training loss: 0.08500523865222931
Validation loss: 1.5630966469805727

Epoch: 5| Step: 2
Training loss: 0.43240785598754883
Validation loss: 1.5679008294177312

Epoch: 5| Step: 3
Training loss: 0.3001556992530823
Validation loss: 1.5649091018143522

Epoch: 5| Step: 4
Training loss: 0.11912951618432999
Validation loss: 1.5547401501286415

Epoch: 5| Step: 5
Training loss: 0.15991562604904175
Validation loss: 1.5559009992948143

Epoch: 5| Step: 6
Training loss: 0.2208661139011383
Validation loss: 1.5101454745056808

Epoch: 5| Step: 7
Training loss: 0.14445798099040985
Validation loss: 1.5081716647712133

Epoch: 5| Step: 8
Training loss: 0.14026176929473877
Validation loss: 1.555312047722519

Epoch: 5| Step: 9
Training loss: 0.1162177175283432
Validation loss: 1.533385738249748

Epoch: 5| Step: 10
Training loss: 0.2314290851354599
Validation loss: 1.5155714429834837

Epoch: 499| Step: 0
Training loss: 0.1332477480173111
Validation loss: 1.5430214892151535

Epoch: 5| Step: 1
Training loss: 0.1620475798845291
Validation loss: 1.5597570057838195

Epoch: 5| Step: 2
Training loss: 0.11176536232233047
Validation loss: 1.5594238030013217

Epoch: 5| Step: 3
Training loss: 0.410074383020401
Validation loss: 1.5420695133106683

Epoch: 5| Step: 4
Training loss: 0.20931978523731232
Validation loss: 1.5755452558558474

Epoch: 5| Step: 5
Training loss: 0.14942124485969543
Validation loss: 1.5902423820187968

Epoch: 5| Step: 6
Training loss: 0.13496184349060059
Validation loss: 1.5754590047303068

Epoch: 5| Step: 7
Training loss: 0.13392546772956848
Validation loss: 1.5887601631943897

Epoch: 5| Step: 8
Training loss: 0.2375795841217041
Validation loss: 1.6187822434210009

Epoch: 5| Step: 9
Training loss: 0.1456669270992279
Validation loss: 1.5838504004222091

Epoch: 5| Step: 10
Training loss: 0.2034720480442047
Validation loss: 1.572238867000867

Epoch: 500| Step: 0
Training loss: 0.1535186469554901
Validation loss: 1.574181358660421

Epoch: 5| Step: 1
Training loss: 0.25736474990844727
Validation loss: 1.5635440580306514

Epoch: 5| Step: 2
Training loss: 0.17108254134655
Validation loss: 1.556958999685062

Epoch: 5| Step: 3
Training loss: 0.17956319451332092
Validation loss: 1.5592455248678885

Epoch: 5| Step: 4
Training loss: 0.1578489989042282
Validation loss: 1.576026479403178

Epoch: 5| Step: 5
Training loss: 0.16538336873054504
Validation loss: 1.5693224463411557

Epoch: 5| Step: 6
Training loss: 0.2341109812259674
Validation loss: 1.585701141306149

Epoch: 5| Step: 7
Training loss: 0.2535780966281891
Validation loss: 1.559247056002258

Epoch: 5| Step: 8
Training loss: 0.07027316093444824
Validation loss: 1.5349032212329168

Epoch: 5| Step: 9
Training loss: 0.32576990127563477
Validation loss: 1.5802728181244226

Epoch: 5| Step: 10
Training loss: 0.17931132018566132
Validation loss: 1.565838316435455

Epoch: 501| Step: 0
Training loss: 0.14665253460407257
Validation loss: 1.521222729836741

Epoch: 5| Step: 1
Training loss: 0.2577342987060547
Validation loss: 1.554316379690683

Epoch: 5| Step: 2
Training loss: 0.17276641726493835
Validation loss: 1.5589238238591019

Epoch: 5| Step: 3
Training loss: 0.08700773119926453
Validation loss: 1.5571228291398735

Epoch: 5| Step: 4
Training loss: 0.39618420600891113
Validation loss: 1.5329360654277187

Epoch: 5| Step: 5
Training loss: 0.1575292944908142
Validation loss: 1.5277961774538922

Epoch: 5| Step: 6
Training loss: 0.1446811556816101
Validation loss: 1.5066389268444431

Epoch: 5| Step: 7
Training loss: 0.13867950439453125
Validation loss: 1.5276226817920644

Epoch: 5| Step: 8
Training loss: 0.18462491035461426
Validation loss: 1.5048343802011142

Epoch: 5| Step: 9
Training loss: 0.22729036211967468
Validation loss: 1.5214867168857205

Epoch: 5| Step: 10
Training loss: 0.1214955672621727
Validation loss: 1.4934705726562008

Epoch: 502| Step: 0
Training loss: 0.18441490828990936
Validation loss: 1.5289999464506745

Epoch: 5| Step: 1
Training loss: 0.13334132730960846
Validation loss: 1.5153630677089895

Epoch: 5| Step: 2
Training loss: 0.0929635763168335
Validation loss: 1.5011149926852154

Epoch: 5| Step: 3
Training loss: 0.11650799214839935
Validation loss: 1.5234868859732023

Epoch: 5| Step: 4
Training loss: 0.16970638930797577
Validation loss: 1.5073642051348122

Epoch: 5| Step: 5
Training loss: 0.15290702879428864
Validation loss: 1.5467578685411842

Epoch: 5| Step: 6
Training loss: 0.16668611764907837
Validation loss: 1.5413704520912581

Epoch: 5| Step: 7
Training loss: 0.36387020349502563
Validation loss: 1.556368597092167

Epoch: 5| Step: 8
Training loss: 0.16814763844013214
Validation loss: 1.574273342727333

Epoch: 5| Step: 9
Training loss: 0.1712304949760437
Validation loss: 1.5668246425608152

Epoch: 5| Step: 10
Training loss: 0.13105030357837677
Validation loss: 1.5647224046850716

Epoch: 503| Step: 0
Training loss: 0.23547033965587616
Validation loss: 1.5630473295847576

Epoch: 5| Step: 1
Training loss: 0.1165643110871315
Validation loss: 1.5641181725327686

Epoch: 5| Step: 2
Training loss: 0.08266458660364151
Validation loss: 1.5966116471957135

Epoch: 5| Step: 3
Training loss: 0.16116975247859955
Validation loss: 1.5623072988243514

Epoch: 5| Step: 4
Training loss: 0.1022685170173645
Validation loss: 1.531715585339454

Epoch: 5| Step: 5
Training loss: 0.17469675838947296
Validation loss: 1.530113035632718

Epoch: 5| Step: 6
Training loss: 0.173851877450943
Validation loss: 1.5717738507896342

Epoch: 5| Step: 7
Training loss: 0.43101319670677185
Validation loss: 1.5461831682471818

Epoch: 5| Step: 8
Training loss: 0.15356868505477905
Validation loss: 1.5310031393522858

Epoch: 5| Step: 9
Training loss: 0.10742193460464478
Validation loss: 1.5365318418830953

Epoch: 5| Step: 10
Training loss: 0.15608955919742584
Validation loss: 1.545755579907407

Epoch: 504| Step: 0
Training loss: 0.17588846385478973
Validation loss: 1.5391551204906997

Epoch: 5| Step: 1
Training loss: 0.17169639468193054
Validation loss: 1.5617166578128774

Epoch: 5| Step: 2
Training loss: 0.13141512870788574
Validation loss: 1.5353966169459845

Epoch: 5| Step: 3
Training loss: 0.1059197410941124
Validation loss: 1.5361223989917385

Epoch: 5| Step: 4
Training loss: 0.17006781697273254
Validation loss: 1.512842066826359

Epoch: 5| Step: 5
Training loss: 0.17533080279827118
Validation loss: 1.5311103405490998

Epoch: 5| Step: 6
Training loss: 0.07729271799325943
Validation loss: 1.5191101104982438

Epoch: 5| Step: 7
Training loss: 0.13542024791240692
Validation loss: 1.5131117490030104

Epoch: 5| Step: 8
Training loss: 0.3376012146472931
Validation loss: 1.5002203628581057

Epoch: 5| Step: 9
Training loss: 0.21616101264953613
Validation loss: 1.5006032015687676

Epoch: 5| Step: 10
Training loss: 0.276553213596344
Validation loss: 1.502139933647648

Epoch: 505| Step: 0
Training loss: 0.17516236007213593
Validation loss: 1.5308133889270086

Epoch: 5| Step: 1
Training loss: 0.13573041558265686
Validation loss: 1.477986313963449

Epoch: 5| Step: 2
Training loss: 0.24303483963012695
Validation loss: 1.4975963266946937

Epoch: 5| Step: 3
Training loss: 0.1566791832447052
Validation loss: 1.4928514585700086

Epoch: 5| Step: 4
Training loss: 0.32686424255371094
Validation loss: 1.4727893516581545

Epoch: 5| Step: 5
Training loss: 0.0807136669754982
Validation loss: 1.4886692749556674

Epoch: 5| Step: 6
Training loss: 0.19012200832366943
Validation loss: 1.49596958134764

Epoch: 5| Step: 7
Training loss: 0.1653362512588501
Validation loss: 1.516392118187361

Epoch: 5| Step: 8
Training loss: 0.1491289734840393
Validation loss: 1.4980964827281174

Epoch: 5| Step: 9
Training loss: 0.1850060373544693
Validation loss: 1.497481515330653

Epoch: 5| Step: 10
Training loss: 0.1274934709072113
Validation loss: 1.5315338744912097

Epoch: 506| Step: 0
Training loss: 0.12763693928718567
Validation loss: 1.5013838788514495

Epoch: 5| Step: 1
Training loss: 0.3327127695083618
Validation loss: 1.5039660110268542

Epoch: 5| Step: 2
Training loss: 0.15124666690826416
Validation loss: 1.504672727277202

Epoch: 5| Step: 3
Training loss: 0.08544650673866272
Validation loss: 1.5162790308716476

Epoch: 5| Step: 4
Training loss: 0.1581607609987259
Validation loss: 1.5419415850793161

Epoch: 5| Step: 5
Training loss: 0.16522595286369324
Validation loss: 1.568136098564312

Epoch: 5| Step: 6
Training loss: 0.1043279618024826
Validation loss: 1.5635886371776622

Epoch: 5| Step: 7
Training loss: 0.15782980620861053
Validation loss: 1.5814890566692557

Epoch: 5| Step: 8
Training loss: 0.24915452301502228
Validation loss: 1.5998551038003737

Epoch: 5| Step: 9
Training loss: 0.14703896641731262
Validation loss: 1.5727387320610784

Epoch: 5| Step: 10
Training loss: 0.1147555559873581
Validation loss: 1.5500090378586964

Epoch: 507| Step: 0
Training loss: 0.07284197211265564
Validation loss: 1.5487620253716745

Epoch: 5| Step: 1
Training loss: 0.20844483375549316
Validation loss: 1.5700958095571047

Epoch: 5| Step: 2
Training loss: 0.10203492641448975
Validation loss: 1.5538662889952302

Epoch: 5| Step: 3
Training loss: 0.10955703258514404
Validation loss: 1.51729977515436

Epoch: 5| Step: 4
Training loss: 0.34635716676712036
Validation loss: 1.5398973175274429

Epoch: 5| Step: 5
Training loss: 0.10229046642780304
Validation loss: 1.545783846609054

Epoch: 5| Step: 6
Training loss: 0.12205711752176285
Validation loss: 1.5424607492262317

Epoch: 5| Step: 7
Training loss: 0.13890866935253143
Validation loss: 1.5514037647554952

Epoch: 5| Step: 8
Training loss: 0.2686944305896759
Validation loss: 1.579597479553633

Epoch: 5| Step: 9
Training loss: 0.18102213740348816
Validation loss: 1.5652543049986645

Epoch: 5| Step: 10
Training loss: 0.22868819534778595
Validation loss: 1.554049547000598

Epoch: 508| Step: 0
Training loss: 0.09474124014377594
Validation loss: 1.5359428454470891

Epoch: 5| Step: 1
Training loss: 0.15494929254055023
Validation loss: 1.5488329074716056

Epoch: 5| Step: 2
Training loss: 0.15026429295539856
Validation loss: 1.552749651734547

Epoch: 5| Step: 3
Training loss: 0.16210898756980896
Validation loss: 1.5339469461030857

Epoch: 5| Step: 4
Training loss: 0.1843850314617157
Validation loss: 1.5388083752765451

Epoch: 5| Step: 5
Training loss: 0.20217113196849823
Validation loss: 1.5481981692775604

Epoch: 5| Step: 6
Training loss: 0.3322049081325531
Validation loss: 1.5196567312363656

Epoch: 5| Step: 7
Training loss: 0.1150193065404892
Validation loss: 1.5097989061827302

Epoch: 5| Step: 8
Training loss: 0.17494909465312958
Validation loss: 1.534688252274708

Epoch: 5| Step: 9
Training loss: 0.15710921585559845
Validation loss: 1.4866298270481888

Epoch: 5| Step: 10
Training loss: 0.12566913664340973
Validation loss: 1.5146840157047394

Epoch: 509| Step: 0
Training loss: 0.3607059121131897
Validation loss: 1.5017942818262244

Epoch: 5| Step: 1
Training loss: 0.11810008436441422
Validation loss: 1.523721379618491

Epoch: 5| Step: 2
Training loss: 0.12625806033611298
Validation loss: 1.538943236873996

Epoch: 5| Step: 3
Training loss: 0.11904975026845932
Validation loss: 1.5165568051799652

Epoch: 5| Step: 4
Training loss: 0.25483614206314087
Validation loss: 1.517961299547585

Epoch: 5| Step: 5
Training loss: 0.18644540011882782
Validation loss: 1.5443396209388651

Epoch: 5| Step: 6
Training loss: 0.22516226768493652
Validation loss: 1.5152684578331568

Epoch: 5| Step: 7
Training loss: 0.0714162215590477
Validation loss: 1.5263087031661824

Epoch: 5| Step: 8
Training loss: 0.12918716669082642
Validation loss: 1.494951964706503

Epoch: 5| Step: 9
Training loss: 0.14633077383041382
Validation loss: 1.5176235309211157

Epoch: 5| Step: 10
Training loss: 0.13958005607128143
Validation loss: 1.506367447555706

Epoch: 510| Step: 0
Training loss: 0.14641563594341278
Validation loss: 1.5038506830892255

Epoch: 5| Step: 1
Training loss: 0.09386833012104034
Validation loss: 1.500287199533114

Epoch: 5| Step: 2
Training loss: 0.16097573935985565
Validation loss: 1.5134505379584529

Epoch: 5| Step: 3
Training loss: 0.08543382585048676
Validation loss: 1.529448183633948

Epoch: 5| Step: 4
Training loss: 0.10856501758098602
Validation loss: 1.5387224663970291

Epoch: 5| Step: 5
Training loss: 0.15572889149188995
Validation loss: 1.514445782989584

Epoch: 5| Step: 6
Training loss: 0.15253202617168427
Validation loss: 1.533712565257985

Epoch: 5| Step: 7
Training loss: 0.3370484709739685
Validation loss: 1.5367539210986065

Epoch: 5| Step: 8
Training loss: 0.21277084946632385
Validation loss: 1.556870347710066

Epoch: 5| Step: 9
Training loss: 0.16585296392440796
Validation loss: 1.5307834712407922

Epoch: 5| Step: 10
Training loss: 0.1782572865486145
Validation loss: 1.5243702896179692

Epoch: 511| Step: 0
Training loss: 0.14311999082565308
Validation loss: 1.5355886233750211

Epoch: 5| Step: 1
Training loss: 0.07344372570514679
Validation loss: 1.5395036743533226

Epoch: 5| Step: 2
Training loss: 0.08160382509231567
Validation loss: 1.5424941329545871

Epoch: 5| Step: 3
Training loss: 0.0936373770236969
Validation loss: 1.5512677700288835

Epoch: 5| Step: 4
Training loss: 0.15292295813560486
Validation loss: 1.5520144662549418

Epoch: 5| Step: 5
Training loss: 0.13443367183208466
Validation loss: 1.5421533828140588

Epoch: 5| Step: 6
Training loss: 0.25137558579444885
Validation loss: 1.554019610087077

Epoch: 5| Step: 7
Training loss: 0.11925466358661652
Validation loss: 1.5471466946345505

Epoch: 5| Step: 8
Training loss: 0.18723103404045105
Validation loss: 1.5736315763124855

Epoch: 5| Step: 9
Training loss: 0.2041800320148468
Validation loss: 1.5599822792955624

Epoch: 5| Step: 10
Training loss: 0.41193917393684387
Validation loss: 1.5649982293446858

Epoch: 512| Step: 0
Training loss: 0.3598251938819885
Validation loss: 1.595293128362266

Epoch: 5| Step: 1
Training loss: 0.09695407748222351
Validation loss: 1.5154487061244186

Epoch: 5| Step: 2
Training loss: 0.17478637397289276
Validation loss: 1.563106442010531

Epoch: 5| Step: 3
Training loss: 0.09772869199514389
Validation loss: 1.5388265976341822

Epoch: 5| Step: 4
Training loss: 0.11703191697597504
Validation loss: 1.5345522165298462

Epoch: 5| Step: 5
Training loss: 0.1425345242023468
Validation loss: 1.5174694189461329

Epoch: 5| Step: 6
Training loss: 0.20758303999900818
Validation loss: 1.5327293885651456

Epoch: 5| Step: 7
Training loss: 0.18838882446289062
Validation loss: 1.51098080219761

Epoch: 5| Step: 8
Training loss: 0.16442875564098358
Validation loss: 1.525354080302741

Epoch: 5| Step: 9
Training loss: 0.07088584452867508
Validation loss: 1.5392799454350625

Epoch: 5| Step: 10
Training loss: 0.18683002889156342
Validation loss: 1.5115440686543782

Epoch: 513| Step: 0
Training loss: 0.08451396971940994
Validation loss: 1.5253702440569479

Epoch: 5| Step: 1
Training loss: 0.10988505929708481
Validation loss: 1.5116128331871443

Epoch: 5| Step: 2
Training loss: 0.3013317286968231
Validation loss: 1.5262655558124665

Epoch: 5| Step: 3
Training loss: 0.18139882385730743
Validation loss: 1.485761345073741

Epoch: 5| Step: 4
Training loss: 0.1458154022693634
Validation loss: 1.4828020013788694

Epoch: 5| Step: 5
Training loss: 0.14490796625614166
Validation loss: 1.49426507565283

Epoch: 5| Step: 6
Training loss: 0.2874455451965332
Validation loss: 1.4781279474176385

Epoch: 5| Step: 7
Training loss: 0.09813226759433746
Validation loss: 1.496101490912899

Epoch: 5| Step: 8
Training loss: 0.11786399036645889
Validation loss: 1.5260876737615114

Epoch: 5| Step: 9
Training loss: 0.09515511244535446
Validation loss: 1.5033572450760873

Epoch: 5| Step: 10
Training loss: 0.13374201953411102
Validation loss: 1.5211377297678301

Epoch: 514| Step: 0
Training loss: 0.15049800276756287
Validation loss: 1.5356444902317499

Epoch: 5| Step: 1
Training loss: 0.18096283078193665
Validation loss: 1.5293712423693748

Epoch: 5| Step: 2
Training loss: 0.12206923961639404
Validation loss: 1.5158678754683463

Epoch: 5| Step: 3
Training loss: 0.12305574119091034
Validation loss: 1.5075692284491755

Epoch: 5| Step: 4
Training loss: 0.08015285432338715
Validation loss: 1.506010820788722

Epoch: 5| Step: 5
Training loss: 0.35872843861579895
Validation loss: 1.5116135548519831

Epoch: 5| Step: 6
Training loss: 0.16866150498390198
Validation loss: 1.5137015875949655

Epoch: 5| Step: 7
Training loss: 0.19868791103363037
Validation loss: 1.5205405783909622

Epoch: 5| Step: 8
Training loss: 0.1360625922679901
Validation loss: 1.5131840032915915

Epoch: 5| Step: 9
Training loss: 0.2020806521177292
Validation loss: 1.5343336418110838

Epoch: 5| Step: 10
Training loss: 0.09953349828720093
Validation loss: 1.5466836312765717

Epoch: 515| Step: 0
Training loss: 0.18261492252349854
Validation loss: 1.5505696727383522

Epoch: 5| Step: 1
Training loss: 0.16017860174179077
Validation loss: 1.5699974260022562

Epoch: 5| Step: 2
Training loss: 0.0971880629658699
Validation loss: 1.570989542109992

Epoch: 5| Step: 3
Training loss: 0.06534408777952194
Validation loss: 1.568285051212516

Epoch: 5| Step: 4
Training loss: 0.35324710607528687
Validation loss: 1.5523979612576064

Epoch: 5| Step: 5
Training loss: 0.17432714998722076
Validation loss: 1.5874214377454532

Epoch: 5| Step: 6
Training loss: 0.14331793785095215
Validation loss: 1.565801683292594

Epoch: 5| Step: 7
Training loss: 0.09525132179260254
Validation loss: 1.5690959999638219

Epoch: 5| Step: 8
Training loss: 0.16379980742931366
Validation loss: 1.5614567725889144

Epoch: 5| Step: 9
Training loss: 0.2652052342891693
Validation loss: 1.575904692372968

Epoch: 5| Step: 10
Training loss: 0.18208108842372894
Validation loss: 1.5758385248081659

Epoch: 516| Step: 0
Training loss: 0.17603877186775208
Validation loss: 1.5813194820957799

Epoch: 5| Step: 1
Training loss: 0.15347149968147278
Validation loss: 1.5819544997266544

Epoch: 5| Step: 2
Training loss: 0.16943934559822083
Validation loss: 1.5587153742390294

Epoch: 5| Step: 3
Training loss: 0.31555551290512085
Validation loss: 1.5542463000102709

Epoch: 5| Step: 4
Training loss: 0.15141436457633972
Validation loss: 1.5597120010724632

Epoch: 5| Step: 5
Training loss: 0.3577888607978821
Validation loss: 1.5656350761331537

Epoch: 5| Step: 6
Training loss: 0.11753926426172256
Validation loss: 1.5295051259379233

Epoch: 5| Step: 7
Training loss: 0.14238831400871277
Validation loss: 1.5294325499124424

Epoch: 5| Step: 8
Training loss: 0.2937690317630768
Validation loss: 1.549689947276987

Epoch: 5| Step: 9
Training loss: 0.15536831319332123
Validation loss: 1.5234173113299954

Epoch: 5| Step: 10
Training loss: 0.14978766441345215
Validation loss: 1.503160411311734

Epoch: 517| Step: 0
Training loss: 0.2365448921918869
Validation loss: 1.503299742616633

Epoch: 5| Step: 1
Training loss: 0.13443848490715027
Validation loss: 1.5105751765671598

Epoch: 5| Step: 2
Training loss: 0.16719773411750793
Validation loss: 1.4962817866315123

Epoch: 5| Step: 3
Training loss: 0.24788334965705872
Validation loss: 1.4988947453037385

Epoch: 5| Step: 4
Training loss: 0.13508997857570648
Validation loss: 1.4883627891540527

Epoch: 5| Step: 5
Training loss: 0.19332660734653473
Validation loss: 1.4928960095169723

Epoch: 5| Step: 6
Training loss: 0.16456769406795502
Validation loss: 1.5339596534288058

Epoch: 5| Step: 7
Training loss: 0.16996663808822632
Validation loss: 1.532707247682797

Epoch: 5| Step: 8
Training loss: 0.23104850947856903
Validation loss: 1.5527379820423741

Epoch: 5| Step: 9
Training loss: 0.4164353311061859
Validation loss: 1.575109561284383

Epoch: 5| Step: 10
Training loss: 0.12430338561534882
Validation loss: 1.5807958559323383

Epoch: 518| Step: 0
Training loss: 0.1592320203781128
Validation loss: 1.5589945265041885

Epoch: 5| Step: 1
Training loss: 0.08213163912296295
Validation loss: 1.5810038979335497

Epoch: 5| Step: 2
Training loss: 0.17090460658073425
Validation loss: 1.580506504222911

Epoch: 5| Step: 3
Training loss: 0.16164647042751312
Validation loss: 1.5346675508765764

Epoch: 5| Step: 4
Training loss: 0.3744553327560425
Validation loss: 1.5392826077758626

Epoch: 5| Step: 5
Training loss: 0.16306081414222717
Validation loss: 1.5549718013373754

Epoch: 5| Step: 6
Training loss: 0.23952606320381165
Validation loss: 1.5161707209002586

Epoch: 5| Step: 7
Training loss: 0.24003276228904724
Validation loss: 1.5580966549534951

Epoch: 5| Step: 8
Training loss: 0.13198232650756836
Validation loss: 1.557420519090468

Epoch: 5| Step: 9
Training loss: 0.11601583659648895
Validation loss: 1.5603505321728286

Epoch: 5| Step: 10
Training loss: 0.15322670340538025
Validation loss: 1.5208746976749872

Epoch: 519| Step: 0
Training loss: 0.07493804395198822
Validation loss: 1.5195232399048344

Epoch: 5| Step: 1
Training loss: 0.16317486763000488
Validation loss: 1.5306840481296662

Epoch: 5| Step: 2
Training loss: 0.3547634482383728
Validation loss: 1.5218589677605578

Epoch: 5| Step: 3
Training loss: 0.1255221664905548
Validation loss: 1.5317024441175564

Epoch: 5| Step: 4
Training loss: 0.1734270453453064
Validation loss: 1.5221042863784298

Epoch: 5| Step: 5
Training loss: 0.12312636524438858
Validation loss: 1.5129728932534494

Epoch: 5| Step: 6
Training loss: 0.16330793499946594
Validation loss: 1.5224745222317275

Epoch: 5| Step: 7
Training loss: 0.09010062366724014
Validation loss: 1.5037278142026675

Epoch: 5| Step: 8
Training loss: 0.14578011631965637
Validation loss: 1.49891782576038

Epoch: 5| Step: 9
Training loss: 0.22524921596050262
Validation loss: 1.5170727173487346

Epoch: 5| Step: 10
Training loss: 0.06200387328863144
Validation loss: 1.5212801605142572

Epoch: 520| Step: 0
Training loss: 0.14185012876987457
Validation loss: 1.523853257138242

Epoch: 5| Step: 1
Training loss: 0.1050037369132042
Validation loss: 1.5213184407962266

Epoch: 5| Step: 2
Training loss: 0.3065841794013977
Validation loss: 1.544062957968763

Epoch: 5| Step: 3
Training loss: 0.1319006234407425
Validation loss: 1.5625204745159353

Epoch: 5| Step: 4
Training loss: 0.18009284138679504
Validation loss: 1.5628455018484464

Epoch: 5| Step: 5
Training loss: 0.20407989621162415
Validation loss: 1.554938203545027

Epoch: 5| Step: 6
Training loss: 0.12084245681762695
Validation loss: 1.5662365562172347

Epoch: 5| Step: 7
Training loss: 0.14600935578346252
Validation loss: 1.5412125651554396

Epoch: 5| Step: 8
Training loss: 0.16899356245994568
Validation loss: 1.5439106700240925

Epoch: 5| Step: 9
Training loss: 0.1380009949207306
Validation loss: 1.5628046733076855

Epoch: 5| Step: 10
Training loss: 0.17019161581993103
Validation loss: 1.5743607718457457

Epoch: 521| Step: 0
Training loss: 0.14291633665561676
Validation loss: 1.5834963526777042

Epoch: 5| Step: 1
Training loss: 0.23762622475624084
Validation loss: 1.5716174635835873

Epoch: 5| Step: 2
Training loss: 0.09489760547876358
Validation loss: 1.5641643283187703

Epoch: 5| Step: 3
Training loss: 0.1081869825720787
Validation loss: 1.553236820364511

Epoch: 5| Step: 4
Training loss: 0.1336163580417633
Validation loss: 1.554815625631681

Epoch: 5| Step: 5
Training loss: 0.13092313706874847
Validation loss: 1.5562053765020063

Epoch: 5| Step: 6
Training loss: 0.3196858763694763
Validation loss: 1.5364461996222054

Epoch: 5| Step: 7
Training loss: 0.2162751704454422
Validation loss: 1.5496232663431475

Epoch: 5| Step: 8
Training loss: 0.1081853061914444
Validation loss: 1.5418607598991805

Epoch: 5| Step: 9
Training loss: 0.10446350276470184
Validation loss: 1.5559738323252688

Epoch: 5| Step: 10
Training loss: 0.21013613045215607
Validation loss: 1.528861597020139

Epoch: 522| Step: 0
Training loss: 0.14609220623970032
Validation loss: 1.5572651342679096

Epoch: 5| Step: 1
Training loss: 0.19967283308506012
Validation loss: 1.5404622317642294

Epoch: 5| Step: 2
Training loss: 0.12227380275726318
Validation loss: 1.551708709809088

Epoch: 5| Step: 3
Training loss: 0.1467878371477127
Validation loss: 1.583376298668564

Epoch: 5| Step: 4
Training loss: 0.13199904561042786
Validation loss: 1.5852338312774577

Epoch: 5| Step: 5
Training loss: 0.30546462535858154
Validation loss: 1.5689929890376266

Epoch: 5| Step: 6
Training loss: 0.11750199645757675
Validation loss: 1.5789665688750565

Epoch: 5| Step: 7
Training loss: 0.10586915165185928
Validation loss: 1.5695226115565146

Epoch: 5| Step: 8
Training loss: 0.23608331382274628
Validation loss: 1.606291514570995

Epoch: 5| Step: 9
Training loss: 0.14247842133045197
Validation loss: 1.5778669875155213

Epoch: 5| Step: 10
Training loss: 0.1768249273300171
Validation loss: 1.5514082472811463

Epoch: 523| Step: 0
Training loss: 0.11450302600860596
Validation loss: 1.5568955175338253

Epoch: 5| Step: 1
Training loss: 0.11419429630041122
Validation loss: 1.5448735029466691

Epoch: 5| Step: 2
Training loss: 0.1583862006664276
Validation loss: 1.5257498602713309

Epoch: 5| Step: 3
Training loss: 0.20224881172180176
Validation loss: 1.5496895608081613

Epoch: 5| Step: 4
Training loss: 0.13439254462718964
Validation loss: 1.5177361337087487

Epoch: 5| Step: 5
Training loss: 0.07163076102733612
Validation loss: 1.5037482451367121

Epoch: 5| Step: 6
Training loss: 0.12661099433898926
Validation loss: 1.509895674643978

Epoch: 5| Step: 7
Training loss: 0.2707544267177582
Validation loss: 1.491991252027532

Epoch: 5| Step: 8
Training loss: 0.12142150104045868
Validation loss: 1.5010092271271573

Epoch: 5| Step: 9
Training loss: 0.34653225541114807
Validation loss: 1.5190615436082244

Epoch: 5| Step: 10
Training loss: 0.20129241049289703
Validation loss: 1.5132818702728517

Epoch: 524| Step: 0
Training loss: 0.16473807394504547
Validation loss: 1.522048319539716

Epoch: 5| Step: 1
Training loss: 0.13982252776622772
Validation loss: 1.537398769009498

Epoch: 5| Step: 2
Training loss: 0.3640013635158539
Validation loss: 1.5400297462299306

Epoch: 5| Step: 3
Training loss: 0.10612048208713531
Validation loss: 1.5532127067606936

Epoch: 5| Step: 4
Training loss: 0.11516020447015762
Validation loss: 1.5596604872775335

Epoch: 5| Step: 5
Training loss: 0.13922861218452454
Validation loss: 1.554339353756238

Epoch: 5| Step: 6
Training loss: 0.12716415524482727
Validation loss: 1.55435743383182

Epoch: 5| Step: 7
Training loss: 0.2022715061903
Validation loss: 1.5657531958754345

Epoch: 5| Step: 8
Training loss: 0.12956435978412628
Validation loss: 1.5447688128358574

Epoch: 5| Step: 9
Training loss: 0.185284823179245
Validation loss: 1.5742209624218684

Epoch: 5| Step: 10
Training loss: 0.11270803213119507
Validation loss: 1.5474616058411137

Epoch: 525| Step: 0
Training loss: 0.0948401689529419
Validation loss: 1.5244386747319212

Epoch: 5| Step: 1
Training loss: 0.16274356842041016
Validation loss: 1.5331221101104573

Epoch: 5| Step: 2
Training loss: 0.16640649735927582
Validation loss: 1.5483332859572543

Epoch: 5| Step: 3
Training loss: 0.11374358087778091
Validation loss: 1.493899103133909

Epoch: 5| Step: 4
Training loss: 0.07522691786289215
Validation loss: 1.494423423403053

Epoch: 5| Step: 5
Training loss: 0.3508761525154114
Validation loss: 1.4970593131998533

Epoch: 5| Step: 6
Training loss: 0.10647226870059967
Validation loss: 1.512367263917

Epoch: 5| Step: 7
Training loss: 0.07084425538778305
Validation loss: 1.5074873701218636

Epoch: 5| Step: 8
Training loss: 0.14645157754421234
Validation loss: 1.5004366097911712

Epoch: 5| Step: 9
Training loss: 0.14747676253318787
Validation loss: 1.5455772287102156

Epoch: 5| Step: 10
Training loss: 0.1429983377456665
Validation loss: 1.5174831344235329

Epoch: 526| Step: 0
Training loss: 0.17356853187084198
Validation loss: 1.565870254270492

Epoch: 5| Step: 1
Training loss: 0.11800500005483627
Validation loss: 1.561877404489825

Epoch: 5| Step: 2
Training loss: 0.07619881629943848
Validation loss: 1.5277310866181568

Epoch: 5| Step: 3
Training loss: 0.11924874782562256
Validation loss: 1.5376845123947307

Epoch: 5| Step: 4
Training loss: 0.1379067599773407
Validation loss: 1.5193191766738892

Epoch: 5| Step: 5
Training loss: 0.29145950078964233
Validation loss: 1.5736379418321835

Epoch: 5| Step: 6
Training loss: 0.08019502460956573
Validation loss: 1.569006335350775

Epoch: 5| Step: 7
Training loss: 0.14051289856433868
Validation loss: 1.528744218170002

Epoch: 5| Step: 8
Training loss: 0.25767025351524353
Validation loss: 1.5354734095194007

Epoch: 5| Step: 9
Training loss: 0.19302888214588165
Validation loss: 1.5575580904560704

Epoch: 5| Step: 10
Training loss: 0.09532848745584488
Validation loss: 1.5526004491313812

Epoch: 527| Step: 0
Training loss: 0.12174233049154282
Validation loss: 1.575545948038819

Epoch: 5| Step: 1
Training loss: 0.08343150466680527
Validation loss: 1.5782821396345734

Epoch: 5| Step: 2
Training loss: 0.1320367306470871
Validation loss: 1.549461450628055

Epoch: 5| Step: 3
Training loss: 0.1114780455827713
Validation loss: 1.5753945612138318

Epoch: 5| Step: 4
Training loss: 0.16083674132823944
Validation loss: 1.569734308027452

Epoch: 5| Step: 5
Training loss: 0.10098837316036224
Validation loss: 1.584240714708964

Epoch: 5| Step: 6
Training loss: 0.13962700963020325
Validation loss: 1.592091848773341

Epoch: 5| Step: 7
Training loss: 0.3896161913871765
Validation loss: 1.5450553560769686

Epoch: 5| Step: 8
Training loss: 0.1867254078388214
Validation loss: 1.5317906359190583

Epoch: 5| Step: 9
Training loss: 0.09656022489070892
Validation loss: 1.5289493991482643

Epoch: 5| Step: 10
Training loss: 0.08965501934289932
Validation loss: 1.5174509133062055

Epoch: 528| Step: 0
Training loss: 0.34351667761802673
Validation loss: 1.5164614800483949

Epoch: 5| Step: 1
Training loss: 0.09433037787675858
Validation loss: 1.4912179990481305

Epoch: 5| Step: 2
Training loss: 0.15537256002426147
Validation loss: 1.4975539317695044

Epoch: 5| Step: 3
Training loss: 0.15608108043670654
Validation loss: 1.5138924749948646

Epoch: 5| Step: 4
Training loss: 0.11362634599208832
Validation loss: 1.4941661357879639

Epoch: 5| Step: 5
Training loss: 0.09871037304401398
Validation loss: 1.4992382167488016

Epoch: 5| Step: 6
Training loss: 0.14981427788734436
Validation loss: 1.499014610885292

Epoch: 5| Step: 7
Training loss: 0.19233229756355286
Validation loss: 1.5170454273941696

Epoch: 5| Step: 8
Training loss: 0.16234910488128662
Validation loss: 1.523837217720606

Epoch: 5| Step: 9
Training loss: 0.19700442254543304
Validation loss: 1.5508028012450024

Epoch: 5| Step: 10
Training loss: 0.12086248397827148
Validation loss: 1.524382265665198

Epoch: 529| Step: 0
Training loss: 0.14585737884044647
Validation loss: 1.526659547641713

Epoch: 5| Step: 1
Training loss: 0.18566663563251495
Validation loss: 1.5232369976658975

Epoch: 5| Step: 2
Training loss: 0.1578548699617386
Validation loss: 1.4911678914100892

Epoch: 5| Step: 3
Training loss: 0.1256278157234192
Validation loss: 1.503802207208449

Epoch: 5| Step: 4
Training loss: 0.06334788352251053
Validation loss: 1.523256096788632

Epoch: 5| Step: 5
Training loss: 0.21502551436424255
Validation loss: 1.5332824068684732

Epoch: 5| Step: 6
Training loss: 0.14596226811408997
Validation loss: 1.5466954861917803

Epoch: 5| Step: 7
Training loss: 0.16200171411037445
Validation loss: 1.5395832202767814

Epoch: 5| Step: 8
Training loss: 0.1213560476899147
Validation loss: 1.556069884248959

Epoch: 5| Step: 9
Training loss: 0.124350406229496
Validation loss: 1.5380603895392468

Epoch: 5| Step: 10
Training loss: 0.40149614214897156
Validation loss: 1.5307857721082625

Epoch: 530| Step: 0
Training loss: 0.12390563637018204
Validation loss: 1.5570679653075434

Epoch: 5| Step: 1
Training loss: 0.16592934727668762
Validation loss: 1.5846932767539896

Epoch: 5| Step: 2
Training loss: 0.3179571032524109
Validation loss: 1.5784596473939958

Epoch: 5| Step: 3
Training loss: 0.20708557963371277
Validation loss: 1.5683359920337636

Epoch: 5| Step: 4
Training loss: 0.16912226378917694
Validation loss: 1.5946982650346653

Epoch: 5| Step: 5
Training loss: 0.09337873756885529
Validation loss: 1.5723922259064131

Epoch: 5| Step: 6
Training loss: 0.1761879026889801
Validation loss: 1.5958175761725313

Epoch: 5| Step: 7
Training loss: 0.10421769320964813
Validation loss: 1.5821625468551472

Epoch: 5| Step: 8
Training loss: 0.11943162977695465
Validation loss: 1.5637061429280106

Epoch: 5| Step: 9
Training loss: 0.1547054499387741
Validation loss: 1.5649851906684138

Epoch: 5| Step: 10
Training loss: 0.16228622198104858
Validation loss: 1.5669266446944206

Epoch: 531| Step: 0
Training loss: 0.16595974564552307
Validation loss: 1.5709032268934353

Epoch: 5| Step: 1
Training loss: 0.15053950250148773
Validation loss: 1.58927523192539

Epoch: 5| Step: 2
Training loss: 0.1265043318271637
Validation loss: 1.5704691237018955

Epoch: 5| Step: 3
Training loss: 0.14367106556892395
Validation loss: 1.5335134959989978

Epoch: 5| Step: 4
Training loss: 0.09587915241718292
Validation loss: 1.5361633352054063

Epoch: 5| Step: 5
Training loss: 0.32473933696746826
Validation loss: 1.538190444310506

Epoch: 5| Step: 6
Training loss: 0.12816396355628967
Validation loss: 1.567458870590374

Epoch: 5| Step: 7
Training loss: 0.21227428317070007
Validation loss: 1.5360414930569228

Epoch: 5| Step: 8
Training loss: 0.13593561947345734
Validation loss: 1.5437278350194295

Epoch: 5| Step: 9
Training loss: 0.16296115517616272
Validation loss: 1.551713200025661

Epoch: 5| Step: 10
Training loss: 0.18532294034957886
Validation loss: 1.5530536623411282

Epoch: 532| Step: 0
Training loss: 0.13921456038951874
Validation loss: 1.5403546440985896

Epoch: 5| Step: 1
Training loss: 0.08336445689201355
Validation loss: 1.544669646088795

Epoch: 5| Step: 2
Training loss: 0.14559891819953918
Validation loss: 1.5490568786539056

Epoch: 5| Step: 3
Training loss: 0.11316237598657608
Validation loss: 1.5751552235695623

Epoch: 5| Step: 4
Training loss: 0.12896662950515747
Validation loss: 1.5516311045615905

Epoch: 5| Step: 5
Training loss: 0.11007704585790634
Validation loss: 1.5659809830368205

Epoch: 5| Step: 6
Training loss: 0.09758851677179337
Validation loss: 1.543834747806672

Epoch: 5| Step: 7
Training loss: 0.15589527785778046
Validation loss: 1.5797162568697365

Epoch: 5| Step: 8
Training loss: 0.3446388840675354
Validation loss: 1.5630536630589476

Epoch: 5| Step: 9
Training loss: 0.1280183494091034
Validation loss: 1.538098830048756

Epoch: 5| Step: 10
Training loss: 0.2821238934993744
Validation loss: 1.553201534414804

Epoch: 533| Step: 0
Training loss: 0.14513066411018372
Validation loss: 1.5468384822209675

Epoch: 5| Step: 1
Training loss: 0.1532207727432251
Validation loss: 1.5366462033282045

Epoch: 5| Step: 2
Training loss: 0.09483964741230011
Validation loss: 1.559517914249051

Epoch: 5| Step: 3
Training loss: 0.36208540201187134
Validation loss: 1.5654977495952318

Epoch: 5| Step: 4
Training loss: 0.11375246196985245
Validation loss: 1.5467139854226062

Epoch: 5| Step: 5
Training loss: 0.1683192253112793
Validation loss: 1.607793160664138

Epoch: 5| Step: 6
Training loss: 0.10908738523721695
Validation loss: 1.5592454300131848

Epoch: 5| Step: 7
Training loss: 0.14501571655273438
Validation loss: 1.555757664865063

Epoch: 5| Step: 8
Training loss: 0.12666383385658264
Validation loss: 1.55301498341304

Epoch: 5| Step: 9
Training loss: 0.13205961883068085
Validation loss: 1.5646316646247782

Epoch: 5| Step: 10
Training loss: 0.13649363815784454
Validation loss: 1.5242208498780445

Epoch: 534| Step: 0
Training loss: 0.11848215758800507
Validation loss: 1.5513954598416564

Epoch: 5| Step: 1
Training loss: 0.10940758138895035
Validation loss: 1.4817614760450137

Epoch: 5| Step: 2
Training loss: 0.13933102786540985
Validation loss: 1.4857249285585137

Epoch: 5| Step: 3
Training loss: 0.1140841692686081
Validation loss: 1.5119146787992088

Epoch: 5| Step: 4
Training loss: 0.12856194376945496
Validation loss: 1.4864263226909022

Epoch: 5| Step: 5
Training loss: 0.11111988872289658
Validation loss: 1.4902996369587478

Epoch: 5| Step: 6
Training loss: 0.12958404421806335
Validation loss: 1.4928525263263333

Epoch: 5| Step: 7
Training loss: 0.1140536218881607
Validation loss: 1.4885680713961202

Epoch: 5| Step: 8
Training loss: 0.10800745338201523
Validation loss: 1.4618980519233211

Epoch: 5| Step: 9
Training loss: 0.11702553927898407
Validation loss: 1.4917436966332056

Epoch: 5| Step: 10
Training loss: 0.44423189759254456
Validation loss: 1.4975334918627174

Epoch: 535| Step: 0
Training loss: 0.09941808879375458
Validation loss: 1.5171356431899532

Epoch: 5| Step: 1
Training loss: 0.14178666472434998
Validation loss: 1.5240682683965212

Epoch: 5| Step: 2
Training loss: 0.16672813892364502
Validation loss: 1.5231743909979378

Epoch: 5| Step: 3
Training loss: 0.16181638836860657
Validation loss: 1.5166964736036075

Epoch: 5| Step: 4
Training loss: 0.08808519691228867
Validation loss: 1.5216221629932363

Epoch: 5| Step: 5
Training loss: 0.19233746826648712
Validation loss: 1.50566267454496

Epoch: 5| Step: 6
Training loss: 0.15292976796627045
Validation loss: 1.5312436972894976

Epoch: 5| Step: 7
Training loss: 0.08159737288951874
Validation loss: 1.5246714891925934

Epoch: 5| Step: 8
Training loss: 0.12917855381965637
Validation loss: 1.5270060749464138

Epoch: 5| Step: 9
Training loss: 0.25882044434547424
Validation loss: 1.5006453298753308

Epoch: 5| Step: 10
Training loss: 0.13586090505123138
Validation loss: 1.4954711596171062

Epoch: 536| Step: 0
Training loss: 0.10532353073358536
Validation loss: 1.5311040762932069

Epoch: 5| Step: 1
Training loss: 0.14304934442043304
Validation loss: 1.5035391264064337

Epoch: 5| Step: 2
Training loss: 0.1599237024784088
Validation loss: 1.5084670858998452

Epoch: 5| Step: 3
Training loss: 0.11339852958917618
Validation loss: 1.5374026554887013

Epoch: 5| Step: 4
Training loss: 0.1379823535680771
Validation loss: 1.520883511471492

Epoch: 5| Step: 5
Training loss: 0.16536018252372742
Validation loss: 1.530126433218679

Epoch: 5| Step: 6
Training loss: 0.16980990767478943
Validation loss: 1.5274468942355084

Epoch: 5| Step: 7
Training loss: 0.13129281997680664
Validation loss: 1.5155605975017752

Epoch: 5| Step: 8
Training loss: 0.2926746904850006
Validation loss: 1.5256932448315363

Epoch: 5| Step: 9
Training loss: 0.1710147112607956
Validation loss: 1.5416559891034198

Epoch: 5| Step: 10
Training loss: 0.13264235854148865
Validation loss: 1.582049245475441

Epoch: 537| Step: 0
Training loss: 0.1122373715043068
Validation loss: 1.5648022197907971

Epoch: 5| Step: 1
Training loss: 0.2060094177722931
Validation loss: 1.563708031690249

Epoch: 5| Step: 2
Training loss: 0.09099147468805313
Validation loss: 1.5721751310492074

Epoch: 5| Step: 3
Training loss: 0.19382309913635254
Validation loss: 1.567326549560793

Epoch: 5| Step: 4
Training loss: 0.12003936618566513
Validation loss: 1.574168791694026

Epoch: 5| Step: 5
Training loss: 0.09829305112361908
Validation loss: 1.5259891299791233

Epoch: 5| Step: 6
Training loss: 0.10769052803516388
Validation loss: 1.547253793285739

Epoch: 5| Step: 7
Training loss: 0.09897664189338684
Validation loss: 1.535594500521178

Epoch: 5| Step: 8
Training loss: 0.3114736080169678
Validation loss: 1.5341261984199606

Epoch: 5| Step: 9
Training loss: 0.08797988295555115
Validation loss: 1.5101665232771186

Epoch: 5| Step: 10
Training loss: 0.2143024504184723
Validation loss: 1.4753054226598432

Epoch: 538| Step: 0
Training loss: 0.15399523079395294
Validation loss: 1.4888594406907276

Epoch: 5| Step: 1
Training loss: 0.14878149330615997
Validation loss: 1.467116077740987

Epoch: 5| Step: 2
Training loss: 0.14690569043159485
Validation loss: 1.5030434862259896

Epoch: 5| Step: 3
Training loss: 0.06881658732891083
Validation loss: 1.5304766624204573

Epoch: 5| Step: 4
Training loss: 0.18935520946979523
Validation loss: 1.524228206244848

Epoch: 5| Step: 5
Training loss: 0.11558926105499268
Validation loss: 1.5218809317517024

Epoch: 5| Step: 6
Training loss: 0.21219894289970398
Validation loss: 1.5522605373013405

Epoch: 5| Step: 7
Training loss: 0.1744251549243927
Validation loss: 1.526658176093973

Epoch: 5| Step: 8
Training loss: 0.12025207281112671
Validation loss: 1.4937410905796995

Epoch: 5| Step: 9
Training loss: 0.14158733189105988
Validation loss: 1.5168012829237087

Epoch: 5| Step: 10
Training loss: 0.34696540236473083
Validation loss: 1.521681902229145

Epoch: 539| Step: 0
Training loss: 0.18315398693084717
Validation loss: 1.467301005958229

Epoch: 5| Step: 1
Training loss: 0.16496601700782776
Validation loss: 1.4832663369435135

Epoch: 5| Step: 2
Training loss: 0.3025757670402527
Validation loss: 1.4793608983357747

Epoch: 5| Step: 3
Training loss: 0.09822757542133331
Validation loss: 1.4957250792493102

Epoch: 5| Step: 4
Training loss: 0.15400080382823944
Validation loss: 1.513147332335031

Epoch: 5| Step: 5
Training loss: 0.08621992915868759
Validation loss: 1.5480150682951814

Epoch: 5| Step: 6
Training loss: 0.2943723201751709
Validation loss: 1.5591759220246346

Epoch: 5| Step: 7
Training loss: 0.14927467703819275
Validation loss: 1.5534753055982693

Epoch: 5| Step: 8
Training loss: 0.10932264477014542
Validation loss: 1.5787143079183434

Epoch: 5| Step: 9
Training loss: 0.11045008897781372
Validation loss: 1.5640315035338044

Epoch: 5| Step: 10
Training loss: 0.11688987910747528
Validation loss: 1.5641299511796685

Epoch: 540| Step: 0
Training loss: 0.07046189159154892
Validation loss: 1.5268455564334829

Epoch: 5| Step: 1
Training loss: 0.1765279769897461
Validation loss: 1.5551561450445524

Epoch: 5| Step: 2
Training loss: 0.3065639138221741
Validation loss: 1.5220272476955126

Epoch: 5| Step: 3
Training loss: 0.13196514546871185
Validation loss: 1.4990226043167936

Epoch: 5| Step: 4
Training loss: 0.18405987322330475
Validation loss: 1.4893172043626026

Epoch: 5| Step: 5
Training loss: 0.16555488109588623
Validation loss: 1.4973352032323037

Epoch: 5| Step: 6
Training loss: 0.10598859935998917
Validation loss: 1.4781518905393538

Epoch: 5| Step: 7
Training loss: 0.08422516286373138
Validation loss: 1.4877491484406173

Epoch: 5| Step: 8
Training loss: 0.08272762596607208
Validation loss: 1.4415183733868342

Epoch: 5| Step: 9
Training loss: 0.142136350274086
Validation loss: 1.494606666667487

Epoch: 5| Step: 10
Training loss: 0.14576800167560577
Validation loss: 1.48209172807714

Epoch: 541| Step: 0
Training loss: 0.17075017094612122
Validation loss: 1.5151490331977926

Epoch: 5| Step: 1
Training loss: 0.1295250952243805
Validation loss: 1.4880689997826853

Epoch: 5| Step: 2
Training loss: 0.14093652367591858
Validation loss: 1.5012369373793244

Epoch: 5| Step: 3
Training loss: 0.09460277110338211
Validation loss: 1.5084008029712144

Epoch: 5| Step: 4
Training loss: 0.29847729206085205
Validation loss: 1.51209795026369

Epoch: 5| Step: 5
Training loss: 0.07144395262002945
Validation loss: 1.530494002885716

Epoch: 5| Step: 6
Training loss: 0.1677139699459076
Validation loss: 1.5103220362817087

Epoch: 5| Step: 7
Training loss: 0.14828069508075714
Validation loss: 1.5029538177674817

Epoch: 5| Step: 8
Training loss: 0.16189193725585938
Validation loss: 1.5049622046050204

Epoch: 5| Step: 9
Training loss: 0.24472077190876007
Validation loss: 1.5171071592197622

Epoch: 5| Step: 10
Training loss: 0.11305452883243561
Validation loss: 1.5245642687684746

Epoch: 542| Step: 0
Training loss: 0.09800533205270767
Validation loss: 1.507520297522186

Epoch: 5| Step: 1
Training loss: 0.09650213271379471
Validation loss: 1.5423724061699324

Epoch: 5| Step: 2
Training loss: 0.11019669473171234
Validation loss: 1.5437790860411942

Epoch: 5| Step: 3
Training loss: 0.13368578255176544
Validation loss: 1.5434811820266068

Epoch: 5| Step: 4
Training loss: 0.09856525808572769
Validation loss: 1.539209383790211

Epoch: 5| Step: 5
Training loss: 0.13255168497562408
Validation loss: 1.5513223345561693

Epoch: 5| Step: 6
Training loss: 0.2969702184200287
Validation loss: 1.5382349414210166

Epoch: 5| Step: 7
Training loss: 0.16274932026863098
Validation loss: 1.505711514462707

Epoch: 5| Step: 8
Training loss: 0.16741494834423065
Validation loss: 1.5167017547033166

Epoch: 5| Step: 9
Training loss: 0.12047801166772842
Validation loss: 1.5408746234832271

Epoch: 5| Step: 10
Training loss: 0.1880163550376892
Validation loss: 1.5159368233014179

Epoch: 543| Step: 0
Training loss: 0.16525278985500336
Validation loss: 1.5401243202147945

Epoch: 5| Step: 1
Training loss: 0.10800445079803467
Validation loss: 1.5055818173193163

Epoch: 5| Step: 2
Training loss: 0.09618046879768372
Validation loss: 1.5353524210632488

Epoch: 5| Step: 3
Training loss: 0.4008418023586273
Validation loss: 1.5244009994691419

Epoch: 5| Step: 4
Training loss: 0.12967528402805328
Validation loss: 1.52909731095837

Epoch: 5| Step: 5
Training loss: 0.14603562653064728
Validation loss: 1.4964168123019639

Epoch: 5| Step: 6
Training loss: 0.08434563875198364
Validation loss: 1.5231557712760022

Epoch: 5| Step: 7
Training loss: 0.13362303376197815
Validation loss: 1.4943904607526717

Epoch: 5| Step: 8
Training loss: 0.1416672170162201
Validation loss: 1.4981245328021306

Epoch: 5| Step: 9
Training loss: 0.11816363036632538
Validation loss: 1.4836271539811166

Epoch: 5| Step: 10
Training loss: 0.12658417224884033
Validation loss: 1.4856754272214827

Epoch: 544| Step: 0
Training loss: 0.18013723194599152
Validation loss: 1.4605679031341308

Epoch: 5| Step: 1
Training loss: 0.13252821564674377
Validation loss: 1.4901477893193562

Epoch: 5| Step: 2
Training loss: 0.18705041706562042
Validation loss: 1.5066453154369066

Epoch: 5| Step: 3
Training loss: 0.1327415406703949
Validation loss: 1.4960206016417472

Epoch: 5| Step: 4
Training loss: 0.17793788015842438
Validation loss: 1.4887233024002404

Epoch: 5| Step: 5
Training loss: 0.09546618163585663
Validation loss: 1.5022672889053181

Epoch: 5| Step: 6
Training loss: 0.13739006221294403
Validation loss: 1.5109535199339672

Epoch: 5| Step: 7
Training loss: 0.17188845574855804
Validation loss: 1.4980002487859418

Epoch: 5| Step: 8
Training loss: 0.3271964192390442
Validation loss: 1.4988076904768586

Epoch: 5| Step: 9
Training loss: 0.14440549910068512
Validation loss: 1.5176290888940134

Epoch: 5| Step: 10
Training loss: 0.12684151530265808
Validation loss: 1.5026337728705457

Epoch: 545| Step: 0
Training loss: 0.15956853330135345
Validation loss: 1.5084178313132255

Epoch: 5| Step: 1
Training loss: 0.11015008389949799
Validation loss: 1.546827103502007

Epoch: 5| Step: 2
Training loss: 0.3197878301143646
Validation loss: 1.5548777118805917

Epoch: 5| Step: 3
Training loss: 0.15749701857566833
Validation loss: 1.5376248769862677

Epoch: 5| Step: 4
Training loss: 0.12067835032939911
Validation loss: 1.5160228411356609

Epoch: 5| Step: 5
Training loss: 0.17518223822116852
Validation loss: 1.501890868268987

Epoch: 5| Step: 6
Training loss: 0.09689006209373474
Validation loss: 1.5431301555325907

Epoch: 5| Step: 7
Training loss: 0.13122816383838654
Validation loss: 1.519643481059741

Epoch: 5| Step: 8
Training loss: 0.1552463322877884
Validation loss: 1.53324903275377

Epoch: 5| Step: 9
Training loss: 0.10457070171833038
Validation loss: 1.497965076918243

Epoch: 5| Step: 10
Training loss: 0.18561260402202606
Validation loss: 1.5285193010043072

Epoch: 546| Step: 0
Training loss: 0.15603576600551605
Validation loss: 1.5204521558618034

Epoch: 5| Step: 1
Training loss: 0.1534544676542282
Validation loss: 1.551187071748959

Epoch: 5| Step: 2
Training loss: 0.1298341453075409
Validation loss: 1.5295807110366

Epoch: 5| Step: 3
Training loss: 0.14122185111045837
Validation loss: 1.522607015025231

Epoch: 5| Step: 4
Training loss: 0.14687645435333252
Validation loss: 1.5384600495779386

Epoch: 5| Step: 5
Training loss: 0.160414919257164
Validation loss: 1.5321994058547481

Epoch: 5| Step: 6
Training loss: 0.1371515691280365
Validation loss: 1.5459606737218878

Epoch: 5| Step: 7
Training loss: 0.08776253461837769
Validation loss: 1.5612765512158793

Epoch: 5| Step: 8
Training loss: 0.29748156666755676
Validation loss: 1.6008814227196477

Epoch: 5| Step: 9
Training loss: 0.19344472885131836
Validation loss: 1.6193470749803769

Epoch: 5| Step: 10
Training loss: 0.1304430216550827
Validation loss: 1.587296417964402

Epoch: 547| Step: 0
Training loss: 0.1833922415971756
Validation loss: 1.5769637374467746

Epoch: 5| Step: 1
Training loss: 0.13609685003757477
Validation loss: 1.5516795624968827

Epoch: 5| Step: 2
Training loss: 0.13626226782798767
Validation loss: 1.5663262926122195

Epoch: 5| Step: 3
Training loss: 0.10662402212619781
Validation loss: 1.535257230522812

Epoch: 5| Step: 4
Training loss: 0.31676429510116577
Validation loss: 1.483178715552053

Epoch: 5| Step: 5
Training loss: 0.10048822313547134
Validation loss: 1.473398075308851

Epoch: 5| Step: 6
Training loss: 0.10186443477869034
Validation loss: 1.4808892409006755

Epoch: 5| Step: 7
Training loss: 0.09732119739055634
Validation loss: 1.4624967536618632

Epoch: 5| Step: 8
Training loss: 0.11937656253576279
Validation loss: 1.492221196492513

Epoch: 5| Step: 9
Training loss: 0.15316477417945862
Validation loss: 1.4833969480247908

Epoch: 5| Step: 10
Training loss: 0.07920011878013611
Validation loss: 1.4737012373503817

Epoch: 548| Step: 0
Training loss: 0.19474220275878906
Validation loss: 1.5092336657226726

Epoch: 5| Step: 1
Training loss: 0.2976010739803314
Validation loss: 1.5346776919980203

Epoch: 5| Step: 2
Training loss: 0.23641876876354218
Validation loss: 1.5014851221474268

Epoch: 5| Step: 3
Training loss: 0.08331944048404694
Validation loss: 1.5414977676124983

Epoch: 5| Step: 4
Training loss: 0.121609166264534
Validation loss: 1.5543909201058008

Epoch: 5| Step: 5
Training loss: 0.12774410843849182
Validation loss: 1.559874806352841

Epoch: 5| Step: 6
Training loss: 0.077880859375
Validation loss: 1.5394443177407788

Epoch: 5| Step: 7
Training loss: 0.09006410837173462
Validation loss: 1.552640800834984

Epoch: 5| Step: 8
Training loss: 0.09823360294103622
Validation loss: 1.5314549887052147

Epoch: 5| Step: 9
Training loss: 0.16712747514247894
Validation loss: 1.547715042227058

Epoch: 5| Step: 10
Training loss: 0.12227309495210648
Validation loss: 1.5487374426216207

Epoch: 549| Step: 0
Training loss: 0.12673309445381165
Validation loss: 1.5164393045568978

Epoch: 5| Step: 1
Training loss: 0.1342170238494873
Validation loss: 1.5275409478013233

Epoch: 5| Step: 2
Training loss: 0.12474942207336426
Validation loss: 1.5261116809742425

Epoch: 5| Step: 3
Training loss: 0.11376190185546875
Validation loss: 1.529942213848073

Epoch: 5| Step: 4
Training loss: 0.10462701320648193
Validation loss: 1.5237232164670063

Epoch: 5| Step: 5
Training loss: 0.1527957171201706
Validation loss: 1.5572099813850977

Epoch: 5| Step: 6
Training loss: 0.09700743854045868
Validation loss: 1.551899794609316

Epoch: 5| Step: 7
Training loss: 0.2002890557050705
Validation loss: 1.5501326066191479

Epoch: 5| Step: 8
Training loss: 0.30317312479019165
Validation loss: 1.579182509453066

Epoch: 5| Step: 9
Training loss: 0.09253736585378647
Validation loss: 1.5910819333086732

Epoch: 5| Step: 10
Training loss: 0.1858729124069214
Validation loss: 1.5604865307449012

Epoch: 550| Step: 0
Training loss: 0.11967388540506363
Validation loss: 1.557888287369923

Epoch: 5| Step: 1
Training loss: 0.12171176820993423
Validation loss: 1.5683581662434403

Epoch: 5| Step: 2
Training loss: 0.36289864778518677
Validation loss: 1.535368255389634

Epoch: 5| Step: 3
Training loss: 0.08089490234851837
Validation loss: 1.5214705005768807

Epoch: 5| Step: 4
Training loss: 0.16232255101203918
Validation loss: 1.529263291307675

Epoch: 5| Step: 5
Training loss: 0.14230866730213165
Validation loss: 1.4999901197289909

Epoch: 5| Step: 6
Training loss: 0.13572828471660614
Validation loss: 1.5244354970993534

Epoch: 5| Step: 7
Training loss: 0.11552594602108002
Validation loss: 1.4877121986881379

Epoch: 5| Step: 8
Training loss: 0.13239765167236328
Validation loss: 1.5043996764767555

Epoch: 5| Step: 9
Training loss: 0.13478529453277588
Validation loss: 1.4907385200582526

Epoch: 5| Step: 10
Training loss: 0.20166665315628052
Validation loss: 1.5036142641498196

Epoch: 551| Step: 0
Training loss: 0.1363796442747116
Validation loss: 1.5464516480763753

Epoch: 5| Step: 1
Training loss: 0.11748957633972168
Validation loss: 1.5172647039095561

Epoch: 5| Step: 2
Training loss: 0.12124607712030411
Validation loss: 1.5411992201241114

Epoch: 5| Step: 3
Training loss: 0.12429174035787582
Validation loss: 1.4964910245710803

Epoch: 5| Step: 4
Training loss: 0.12134039402008057
Validation loss: 1.5335007790596253

Epoch: 5| Step: 5
Training loss: 0.18412135541439056
Validation loss: 1.5374985933303833

Epoch: 5| Step: 6
Training loss: 0.12561191618442535
Validation loss: 1.5065538434572117

Epoch: 5| Step: 7
Training loss: 0.19028368592262268
Validation loss: 1.50630340268535

Epoch: 5| Step: 8
Training loss: 0.12853477895259857
Validation loss: 1.4695555625423309

Epoch: 5| Step: 9
Training loss: 0.17604199051856995
Validation loss: 1.4614511125831193

Epoch: 5| Step: 10
Training loss: 0.34519699215888977
Validation loss: 1.4880832446518766

Epoch: 552| Step: 0
Training loss: 0.19844964146614075
Validation loss: 1.51574690880314

Epoch: 5| Step: 1
Training loss: 0.22625601291656494
Validation loss: 1.4850337607886201

Epoch: 5| Step: 2
Training loss: 0.11728332191705704
Validation loss: 1.533936107030479

Epoch: 5| Step: 3
Training loss: 0.10796650499105453
Validation loss: 1.4963610954182123

Epoch: 5| Step: 4
Training loss: 0.09930133074522018
Validation loss: 1.5257600289519115

Epoch: 5| Step: 5
Training loss: 0.14982332289218903
Validation loss: 1.5090313278218752

Epoch: 5| Step: 6
Training loss: 0.1730976104736328
Validation loss: 1.4907260300010763

Epoch: 5| Step: 7
Training loss: 0.31170958280563354
Validation loss: 1.5140218106649255

Epoch: 5| Step: 8
Training loss: 0.10222301632165909
Validation loss: 1.541650040175325

Epoch: 5| Step: 9
Training loss: 0.16719013452529907
Validation loss: 1.5232877385231756

Epoch: 5| Step: 10
Training loss: 0.16498854756355286
Validation loss: 1.510887921497386

Epoch: 553| Step: 0
Training loss: 0.23211070895195007
Validation loss: 1.5032048443312287

Epoch: 5| Step: 1
Training loss: 0.10458557307720184
Validation loss: 1.4833146372149069

Epoch: 5| Step: 2
Training loss: 0.13285210728645325
Validation loss: 1.495099554779709

Epoch: 5| Step: 3
Training loss: 0.09497156739234924
Validation loss: 1.5035117800517748

Epoch: 5| Step: 4
Training loss: 0.28272342681884766
Validation loss: 1.5040631755705802

Epoch: 5| Step: 5
Training loss: 0.12744593620300293
Validation loss: 1.4949265199322854

Epoch: 5| Step: 6
Training loss: 0.10661916434764862
Validation loss: 1.4649415708357287

Epoch: 5| Step: 7
Training loss: 0.15870164334774017
Validation loss: 1.4665140285286853

Epoch: 5| Step: 8
Training loss: 0.13000443577766418
Validation loss: 1.493116041665436

Epoch: 5| Step: 9
Training loss: 0.12274764478206635
Validation loss: 1.4785736004511516

Epoch: 5| Step: 10
Training loss: 0.12635362148284912
Validation loss: 1.50954867434758

Epoch: 554| Step: 0
Training loss: 0.09679653495550156
Validation loss: 1.5306066069551694

Epoch: 5| Step: 1
Training loss: 0.11372995376586914
Validation loss: 1.5216180752682429

Epoch: 5| Step: 2
Training loss: 0.16655078530311584
Validation loss: 1.5254334083167456

Epoch: 5| Step: 3
Training loss: 0.15747377276420593
Validation loss: 1.509979062823839

Epoch: 5| Step: 4
Training loss: 0.06924919039011002
Validation loss: 1.5261866866901357

Epoch: 5| Step: 5
Training loss: 0.07990680634975433
Validation loss: 1.5468335920764553

Epoch: 5| Step: 6
Training loss: 0.12802860140800476
Validation loss: 1.4985378980636597

Epoch: 5| Step: 7
Training loss: 0.3229086995124817
Validation loss: 1.5315744005223757

Epoch: 5| Step: 8
Training loss: 0.07309876382350922
Validation loss: 1.5615998057908909

Epoch: 5| Step: 9
Training loss: 0.12212927639484406
Validation loss: 1.538241215931472

Epoch: 5| Step: 10
Training loss: 0.15043175220489502
Validation loss: 1.545078068651179

Epoch: 555| Step: 0
Training loss: 0.08294793218374252
Validation loss: 1.5174236528335079

Epoch: 5| Step: 1
Training loss: 0.14843830466270447
Validation loss: 1.5364194006048224

Epoch: 5| Step: 2
Training loss: 0.29797273874282837
Validation loss: 1.5403172905727098

Epoch: 5| Step: 3
Training loss: 0.11627985537052155
Validation loss: 1.517375780690101

Epoch: 5| Step: 4
Training loss: 0.13011789321899414
Validation loss: 1.540735924115745

Epoch: 5| Step: 5
Training loss: 0.14988115429878235
Validation loss: 1.552201251829824

Epoch: 5| Step: 6
Training loss: 0.19407837092876434
Validation loss: 1.556734877247964

Epoch: 5| Step: 7
Training loss: 0.09277822077274323
Validation loss: 1.5353922664478261

Epoch: 5| Step: 8
Training loss: 0.13109606504440308
Validation loss: 1.5665081829153082

Epoch: 5| Step: 9
Training loss: 0.20520786941051483
Validation loss: 1.5930212082401398

Epoch: 5| Step: 10
Training loss: 0.09558738023042679
Validation loss: 1.5600533664867442

Epoch: 556| Step: 0
Training loss: 0.10577116161584854
Validation loss: 1.5722361533872542

Epoch: 5| Step: 1
Training loss: 0.19710561633110046
Validation loss: 1.5474897994790027

Epoch: 5| Step: 2
Training loss: 0.09149238467216492
Validation loss: 1.5277958595624535

Epoch: 5| Step: 3
Training loss: 0.14091524481773376
Validation loss: 1.5203239546027234

Epoch: 5| Step: 4
Training loss: 0.09567291289567947
Validation loss: 1.5328381753736926

Epoch: 5| Step: 5
Training loss: 0.10594041645526886
Validation loss: 1.548894259237474

Epoch: 5| Step: 6
Training loss: 0.10664670169353485
Validation loss: 1.5477604526345448

Epoch: 5| Step: 7
Training loss: 0.10365209728479385
Validation loss: 1.5543932799370057

Epoch: 5| Step: 8
Training loss: 0.11643693596124649
Validation loss: 1.5205234417351343

Epoch: 5| Step: 9
Training loss: 0.08824608474969864
Validation loss: 1.5098825500857445

Epoch: 5| Step: 10
Training loss: 0.3578185737133026
Validation loss: 1.522225426089379

Epoch: 557| Step: 0
Training loss: 0.2102174460887909
Validation loss: 1.5236513076290008

Epoch: 5| Step: 1
Training loss: 0.14056535065174103
Validation loss: 1.542070351621156

Epoch: 5| Step: 2
Training loss: 0.28099650144577026
Validation loss: 1.5430761550062446

Epoch: 5| Step: 3
Training loss: 0.08454332500696182
Validation loss: 1.5275240226458477

Epoch: 5| Step: 4
Training loss: 0.11213842779397964
Validation loss: 1.517975676444269

Epoch: 5| Step: 5
Training loss: 0.09643016010522842
Validation loss: 1.53677870381263

Epoch: 5| Step: 6
Training loss: 0.0650796890258789
Validation loss: 1.547982536336427

Epoch: 5| Step: 7
Training loss: 0.11987932026386261
Validation loss: 1.5421454175826041

Epoch: 5| Step: 8
Training loss: 0.13921764492988586
Validation loss: 1.4951074200291787

Epoch: 5| Step: 9
Training loss: 0.11204153299331665
Validation loss: 1.510637052597538

Epoch: 5| Step: 10
Training loss: 0.13968932628631592
Validation loss: 1.477738470159551

Epoch: 558| Step: 0
Training loss: 0.13923004269599915
Validation loss: 1.4926913207577122

Epoch: 5| Step: 1
Training loss: 0.08405257761478424
Validation loss: 1.4832920771773144

Epoch: 5| Step: 2
Training loss: 0.30125734210014343
Validation loss: 1.5116834499502694

Epoch: 5| Step: 3
Training loss: 0.0987686961889267
Validation loss: 1.4953270701951877

Epoch: 5| Step: 4
Training loss: 0.14293646812438965
Validation loss: 1.4981380111427718

Epoch: 5| Step: 5
Training loss: 0.12824289500713348
Validation loss: 1.481717009698191

Epoch: 5| Step: 6
Training loss: 0.1049702912569046
Validation loss: 1.4783218163315968

Epoch: 5| Step: 7
Training loss: 0.11199168860912323
Validation loss: 1.4777289520027816

Epoch: 5| Step: 8
Training loss: 0.053395044058561325
Validation loss: 1.4828601191120763

Epoch: 5| Step: 9
Training loss: 0.07119442522525787
Validation loss: 1.5337388336017568

Epoch: 5| Step: 10
Training loss: 0.16031311452388763
Validation loss: 1.520491421863597

Epoch: 559| Step: 0
Training loss: 0.1499936729669571
Validation loss: 1.5185400542392526

Epoch: 5| Step: 1
Training loss: 0.15287911891937256
Validation loss: 1.525393618050442

Epoch: 5| Step: 2
Training loss: 0.3422190248966217
Validation loss: 1.53908416276337

Epoch: 5| Step: 3
Training loss: 0.09047454595565796
Validation loss: 1.5316386030566307

Epoch: 5| Step: 4
Training loss: 0.08054188638925552
Validation loss: 1.529981162599338

Epoch: 5| Step: 5
Training loss: 0.09491201490163803
Validation loss: 1.5501830911123624

Epoch: 5| Step: 6
Training loss: 0.14018575847148895
Validation loss: 1.4919783915242841

Epoch: 5| Step: 7
Training loss: 0.14812928438186646
Validation loss: 1.5068692673919022

Epoch: 5| Step: 8
Training loss: 0.09849165380001068
Validation loss: 1.520122314012179

Epoch: 5| Step: 9
Training loss: 0.09120742976665497
Validation loss: 1.4973591457131088

Epoch: 5| Step: 10
Training loss: 0.1312006562948227
Validation loss: 1.5048372002058132

Epoch: 560| Step: 0
Training loss: 0.10120274871587753
Validation loss: 1.49792896034897

Epoch: 5| Step: 1
Training loss: 0.3981497585773468
Validation loss: 1.5442515278375277

Epoch: 5| Step: 2
Training loss: 0.27996084094047546
Validation loss: 1.5577069482495707

Epoch: 5| Step: 3
Training loss: 0.1501552015542984
Validation loss: 1.5643762837174118

Epoch: 5| Step: 4
Training loss: 0.1259404718875885
Validation loss: 1.5031552481394943

Epoch: 5| Step: 5
Training loss: 0.12885306775569916
Validation loss: 1.502879810589616

Epoch: 5| Step: 6
Training loss: 0.14346525073051453
Validation loss: 1.5191883310194938

Epoch: 5| Step: 7
Training loss: 0.13105842471122742
Validation loss: 1.536924369873539

Epoch: 5| Step: 8
Training loss: 0.1989147961139679
Validation loss: 1.5424689586444567

Epoch: 5| Step: 9
Training loss: 0.08514139801263809
Validation loss: 1.5370243069946126

Epoch: 5| Step: 10
Training loss: 0.16947947442531586
Validation loss: 1.5176075312399095

Epoch: 561| Step: 0
Training loss: 0.1048642247915268
Validation loss: 1.5047597218585271

Epoch: 5| Step: 1
Training loss: 0.07361746579408646
Validation loss: 1.4886042860246473

Epoch: 5| Step: 2
Training loss: 0.28665396571159363
Validation loss: 1.4924282066283687

Epoch: 5| Step: 3
Training loss: 0.1448778212070465
Validation loss: 1.5092032006991807

Epoch: 5| Step: 4
Training loss: 0.11568055301904678
Validation loss: 1.5130551912451302

Epoch: 5| Step: 5
Training loss: 0.10747222602367401
Validation loss: 1.5156827460053146

Epoch: 5| Step: 6
Training loss: 0.1679360419511795
Validation loss: 1.5003331874006538

Epoch: 5| Step: 7
Training loss: 0.17028877139091492
Validation loss: 1.5491898687936927

Epoch: 5| Step: 8
Training loss: 0.2184034287929535
Validation loss: 1.5154520106571976

Epoch: 5| Step: 9
Training loss: 0.11870472133159637
Validation loss: 1.5351264938231437

Epoch: 5| Step: 10
Training loss: 0.15450559556484222
Validation loss: 1.5579388513359973

Epoch: 562| Step: 0
Training loss: 0.2897607386112213
Validation loss: 1.5339691895310597

Epoch: 5| Step: 1
Training loss: 0.13230839371681213
Validation loss: 1.5412187576293945

Epoch: 5| Step: 2
Training loss: 0.12009427696466446
Validation loss: 1.5309643360876268

Epoch: 5| Step: 3
Training loss: 0.10433206707239151
Validation loss: 1.5267304861417381

Epoch: 5| Step: 4
Training loss: 0.12359698116779327
Validation loss: 1.5237518625874673

Epoch: 5| Step: 5
Training loss: 0.12265044450759888
Validation loss: 1.5084244128196471

Epoch: 5| Step: 6
Training loss: 0.11200819164514542
Validation loss: 1.5122071184137815

Epoch: 5| Step: 7
Training loss: 0.11995558440685272
Validation loss: 1.5530119711352932

Epoch: 5| Step: 8
Training loss: 0.11167898029088974
Validation loss: 1.5267811385534142

Epoch: 5| Step: 9
Training loss: 0.12296470254659653
Validation loss: 1.5552919116071475

Epoch: 5| Step: 10
Training loss: 0.12722018361091614
Validation loss: 1.567669290368275

Epoch: 563| Step: 0
Training loss: 0.10894646495580673
Validation loss: 1.5602031805182015

Epoch: 5| Step: 1
Training loss: 0.3067095875740051
Validation loss: 1.5455392964424626

Epoch: 5| Step: 2
Training loss: 0.10959529876708984
Validation loss: 1.5514569782441663

Epoch: 5| Step: 3
Training loss: 0.10868711769580841
Validation loss: 1.533222580468783

Epoch: 5| Step: 4
Training loss: 0.14881493151187897
Validation loss: 1.5326559005245086

Epoch: 5| Step: 5
Training loss: 0.13893941044807434
Validation loss: 1.52869124309991

Epoch: 5| Step: 6
Training loss: 0.10048067569732666
Validation loss: 1.544692293290169

Epoch: 5| Step: 7
Training loss: 0.0944443941116333
Validation loss: 1.509497768135481

Epoch: 5| Step: 8
Training loss: 0.20187640190124512
Validation loss: 1.537330178804295

Epoch: 5| Step: 9
Training loss: 0.0830734446644783
Validation loss: 1.5174348226157568

Epoch: 5| Step: 10
Training loss: 0.0974411740899086
Validation loss: 1.5367637590695453

Epoch: 564| Step: 0
Training loss: 0.059625934809446335
Validation loss: 1.521281361579895

Epoch: 5| Step: 1
Training loss: 0.1054491177201271
Validation loss: 1.5454658154518373

Epoch: 5| Step: 2
Training loss: 0.17968323826789856
Validation loss: 1.5313935202936972

Epoch: 5| Step: 3
Training loss: 0.12217569351196289
Validation loss: 1.5332708986856605

Epoch: 5| Step: 4
Training loss: 0.10282354056835175
Validation loss: 1.5202854961477301

Epoch: 5| Step: 5
Training loss: 0.1111079677939415
Validation loss: 1.4965691643376504

Epoch: 5| Step: 6
Training loss: 0.1244596391916275
Validation loss: 1.4704407197172924

Epoch: 5| Step: 7
Training loss: 0.1520933210849762
Validation loss: 1.4777555927153556

Epoch: 5| Step: 8
Training loss: 0.13760346174240112
Validation loss: 1.4867901058607205

Epoch: 5| Step: 9
Training loss: 0.31192827224731445
Validation loss: 1.4806429429720807

Epoch: 5| Step: 10
Training loss: 0.10842233896255493
Validation loss: 1.449839900898677

Epoch: 565| Step: 0
Training loss: 0.1195637434720993
Validation loss: 1.464157695411354

Epoch: 5| Step: 1
Training loss: 0.11225227266550064
Validation loss: 1.4567229734954013

Epoch: 5| Step: 2
Training loss: 0.1255018711090088
Validation loss: 1.4810535471926454

Epoch: 5| Step: 3
Training loss: 0.08615469187498093
Validation loss: 1.4824175796201151

Epoch: 5| Step: 4
Training loss: 0.14697295427322388
Validation loss: 1.4857731506388674

Epoch: 5| Step: 5
Training loss: 0.09253256022930145
Validation loss: 1.5192291454602314

Epoch: 5| Step: 6
Training loss: 0.24498596787452698
Validation loss: 1.5265241053796583

Epoch: 5| Step: 7
Training loss: 0.13250727951526642
Validation loss: 1.5251710363613662

Epoch: 5| Step: 8
Training loss: 0.09770602732896805
Validation loss: 1.5066272417704265

Epoch: 5| Step: 9
Training loss: 0.15819019079208374
Validation loss: 1.5083965268186343

Epoch: 5| Step: 10
Training loss: 0.07104986906051636
Validation loss: 1.5131973810093378

Epoch: 566| Step: 0
Training loss: 0.08416338264942169
Validation loss: 1.530066506837004

Epoch: 5| Step: 1
Training loss: 0.09451483190059662
Validation loss: 1.5193319551406368

Epoch: 5| Step: 2
Training loss: 0.06874401122331619
Validation loss: 1.48546439473347

Epoch: 5| Step: 3
Training loss: 0.10120397806167603
Validation loss: 1.4966330964078185

Epoch: 5| Step: 4
Training loss: 0.2824057340621948
Validation loss: 1.488729530124254

Epoch: 5| Step: 5
Training loss: 0.10068821907043457
Validation loss: 1.4986134036894767

Epoch: 5| Step: 6
Training loss: 0.11560273170471191
Validation loss: 1.4945907567137031

Epoch: 5| Step: 7
Training loss: 0.1133321076631546
Validation loss: 1.501062471379516

Epoch: 5| Step: 8
Training loss: 0.17404702305793762
Validation loss: 1.4934617498869538

Epoch: 5| Step: 9
Training loss: 0.096854567527771
Validation loss: 1.5239634642037012

Epoch: 5| Step: 10
Training loss: 0.12189550697803497
Validation loss: 1.4920384947971632

Epoch: 567| Step: 0
Training loss: 0.19642455875873566
Validation loss: 1.5157766342163086

Epoch: 5| Step: 1
Training loss: 0.06420835107564926
Validation loss: 1.4994764994549494

Epoch: 5| Step: 2
Training loss: 0.1025412306189537
Validation loss: 1.495431004032012

Epoch: 5| Step: 3
Training loss: 0.06278441846370697
Validation loss: 1.4826683728925643

Epoch: 5| Step: 4
Training loss: 0.3018258810043335
Validation loss: 1.4724991859928254

Epoch: 5| Step: 5
Training loss: 0.10170193761587143
Validation loss: 1.4897308670064455

Epoch: 5| Step: 6
Training loss: 0.08313089609146118
Validation loss: 1.483448568210807

Epoch: 5| Step: 7
Training loss: 0.09436755627393723
Validation loss: 1.499073366965017

Epoch: 5| Step: 8
Training loss: 0.12790735065937042
Validation loss: 1.467971622302968

Epoch: 5| Step: 9
Training loss: 0.10550197213888168
Validation loss: 1.492850668968693

Epoch: 5| Step: 10
Training loss: 0.04635162279009819
Validation loss: 1.506412415094273

Epoch: 568| Step: 0
Training loss: 0.10273908078670502
Validation loss: 1.488896418643254

Epoch: 5| Step: 1
Training loss: 0.06502314656972885
Validation loss: 1.4673326438473118

Epoch: 5| Step: 2
Training loss: 0.07306215912103653
Validation loss: 1.4897399525488577

Epoch: 5| Step: 3
Training loss: 0.24325332045555115
Validation loss: 1.5147526764100598

Epoch: 5| Step: 4
Training loss: 0.07016464322805405
Validation loss: 1.4948076330205446

Epoch: 5| Step: 5
Training loss: 0.17168207466602325
Validation loss: 1.4913578635902816

Epoch: 5| Step: 6
Training loss: 0.09446381032466888
Validation loss: 1.5033784335659397

Epoch: 5| Step: 7
Training loss: 0.2345716953277588
Validation loss: 1.4761576101344118

Epoch: 5| Step: 8
Training loss: 0.09518613666296005
Validation loss: 1.4866932245992845

Epoch: 5| Step: 9
Training loss: 0.07173851132392883
Validation loss: 1.4998637450638639

Epoch: 5| Step: 10
Training loss: 0.10632816702127457
Validation loss: 1.454514762406708

Epoch: 569| Step: 0
Training loss: 0.09146583825349808
Validation loss: 1.4794218847828526

Epoch: 5| Step: 1
Training loss: 0.08564595878124237
Validation loss: 1.4706587714533652

Epoch: 5| Step: 2
Training loss: 0.2706732153892517
Validation loss: 1.4766059613996936

Epoch: 5| Step: 3
Training loss: 0.11349198967218399
Validation loss: 1.492578003996162

Epoch: 5| Step: 4
Training loss: 0.18522658944129944
Validation loss: 1.4778644871968094

Epoch: 5| Step: 5
Training loss: 0.075467050075531
Validation loss: 1.4705603058620165

Epoch: 5| Step: 6
Training loss: 0.12093591690063477
Validation loss: 1.5405735995179863

Epoch: 5| Step: 7
Training loss: 0.12261607497930527
Validation loss: 1.5188887901203607

Epoch: 5| Step: 8
Training loss: 0.1251777708530426
Validation loss: 1.5314827747242425

Epoch: 5| Step: 9
Training loss: 0.0904243066906929
Validation loss: 1.5562451129318566

Epoch: 5| Step: 10
Training loss: 0.09547187387943268
Validation loss: 1.5125629235339422

Epoch: 570| Step: 0
Training loss: 0.1372653692960739
Validation loss: 1.5437468738966091

Epoch: 5| Step: 1
Training loss: 0.12944698333740234
Validation loss: 1.521697336627591

Epoch: 5| Step: 2
Training loss: 0.07652086019515991
Validation loss: 1.514912804608704

Epoch: 5| Step: 3
Training loss: 0.15309183299541473
Validation loss: 1.499133458701513

Epoch: 5| Step: 4
Training loss: 0.11237084865570068
Validation loss: 1.4826559251354587

Epoch: 5| Step: 5
Training loss: 0.07618416100740433
Validation loss: 1.4789299695722518

Epoch: 5| Step: 6
Training loss: 0.11554501205682755
Validation loss: 1.4909261349708802

Epoch: 5| Step: 7
Training loss: 0.07344194501638412
Validation loss: 1.4858185950145926

Epoch: 5| Step: 8
Training loss: 0.3277534544467926
Validation loss: 1.5164927231368197

Epoch: 5| Step: 9
Training loss: 0.2219437062740326
Validation loss: 1.476892053440053

Epoch: 5| Step: 10
Training loss: 0.08426174521446228
Validation loss: 1.5030158488981185

Epoch: 571| Step: 0
Training loss: 0.1298520565032959
Validation loss: 1.4739747290970178

Epoch: 5| Step: 1
Training loss: 0.138137087225914
Validation loss: 1.4858349670646012

Epoch: 5| Step: 2
Training loss: 0.10005172342061996
Validation loss: 1.460071374011296

Epoch: 5| Step: 3
Training loss: 0.2714152932167053
Validation loss: 1.497678368322311

Epoch: 5| Step: 4
Training loss: 0.08928043395280838
Validation loss: 1.4692932200688187

Epoch: 5| Step: 5
Training loss: 0.14720644056797028
Validation loss: 1.4807977804573633

Epoch: 5| Step: 6
Training loss: 0.0823173075914383
Validation loss: 1.4678357544765677

Epoch: 5| Step: 7
Training loss: 0.12452676147222519
Validation loss: 1.503725500516994

Epoch: 5| Step: 8
Training loss: 0.1372906118631363
Validation loss: 1.4999252750027565

Epoch: 5| Step: 9
Training loss: 0.12961365282535553
Validation loss: 1.486429278568555

Epoch: 5| Step: 10
Training loss: 0.07400825619697571
Validation loss: 1.5047164655500842

Epoch: 572| Step: 0
Training loss: 0.12367552518844604
Validation loss: 1.4956941707159883

Epoch: 5| Step: 1
Training loss: 0.1256691962480545
Validation loss: 1.4903333507558352

Epoch: 5| Step: 2
Training loss: 0.1335480958223343
Validation loss: 1.481655022149445

Epoch: 5| Step: 3
Training loss: 0.09254150092601776
Validation loss: 1.5019479285004318

Epoch: 5| Step: 4
Training loss: 0.07186989486217499
Validation loss: 1.4862056291231545

Epoch: 5| Step: 5
Training loss: 0.08132605254650116
Validation loss: 1.4721276817783233

Epoch: 5| Step: 6
Training loss: 0.26811736822128296
Validation loss: 1.4881098565234934

Epoch: 5| Step: 7
Training loss: 0.060304194688797
Validation loss: 1.5029596141589585

Epoch: 5| Step: 8
Training loss: 0.11325715482234955
Validation loss: 1.4660111242725002

Epoch: 5| Step: 9
Training loss: 0.15049581229686737
Validation loss: 1.4744308501161554

Epoch: 5| Step: 10
Training loss: 0.1444934457540512
Validation loss: 1.5128038942172963

Epoch: 573| Step: 0
Training loss: 0.2622058689594269
Validation loss: 1.5152043040080736

Epoch: 5| Step: 1
Training loss: 0.0763549879193306
Validation loss: 1.51182327219235

Epoch: 5| Step: 2
Training loss: 0.10388632118701935
Validation loss: 1.5141453525071502

Epoch: 5| Step: 3
Training loss: 0.12703759968280792
Validation loss: 1.5084024693376274

Epoch: 5| Step: 4
Training loss: 0.1451687514781952
Validation loss: 1.5240163598009335

Epoch: 5| Step: 5
Training loss: 0.115788534283638
Validation loss: 1.5082372542350524

Epoch: 5| Step: 6
Training loss: 0.09691338986158371
Validation loss: 1.4964497653386926

Epoch: 5| Step: 7
Training loss: 0.08575816452503204
Validation loss: 1.519475777943929

Epoch: 5| Step: 8
Training loss: 0.13489453494548798
Validation loss: 1.4956320421670073

Epoch: 5| Step: 9
Training loss: 0.09331375360488892
Validation loss: 1.51100766786965

Epoch: 5| Step: 10
Training loss: 0.11504616588354111
Validation loss: 1.5150204602108206

Epoch: 574| Step: 0
Training loss: 0.1975042074918747
Validation loss: 1.499343724660976

Epoch: 5| Step: 1
Training loss: 0.11742395162582397
Validation loss: 1.5024470936867498

Epoch: 5| Step: 2
Training loss: 0.11992422491312027
Validation loss: 1.5014592127133441

Epoch: 5| Step: 3
Training loss: 0.09030160307884216
Validation loss: 1.5223603428051036

Epoch: 5| Step: 4
Training loss: 0.10239335149526596
Validation loss: 1.5075147010946786

Epoch: 5| Step: 5
Training loss: 0.0734340026974678
Validation loss: 1.49860877759995

Epoch: 5| Step: 6
Training loss: 0.092389315366745
Validation loss: 1.4982507510851788

Epoch: 5| Step: 7
Training loss: 0.10948667675256729
Validation loss: 1.4936563404657508

Epoch: 5| Step: 8
Training loss: 0.24240942299365997
Validation loss: 1.5109261774247693

Epoch: 5| Step: 9
Training loss: 0.11756975948810577
Validation loss: 1.5053554170875139

Epoch: 5| Step: 10
Training loss: 0.07085766643285751
Validation loss: 1.5400635394998776

Epoch: 575| Step: 0
Training loss: 0.1228073388338089
Validation loss: 1.5261824028466338

Epoch: 5| Step: 1
Training loss: 0.15542596578598022
Validation loss: 1.5149453968130133

Epoch: 5| Step: 2
Training loss: 0.08351507037878036
Validation loss: 1.5096826309798865

Epoch: 5| Step: 3
Training loss: 0.12007280439138412
Validation loss: 1.4821698063163347

Epoch: 5| Step: 4
Training loss: 0.10585419833660126
Validation loss: 1.4821743144783923

Epoch: 5| Step: 5
Training loss: 0.23520012199878693
Validation loss: 1.4821830129110685

Epoch: 5| Step: 6
Training loss: 0.09219689667224884
Validation loss: 1.494504197951286

Epoch: 5| Step: 7
Training loss: 0.08317814767360687
Validation loss: 1.4863374502428117

Epoch: 5| Step: 8
Training loss: 0.18554656207561493
Validation loss: 1.44368972316865

Epoch: 5| Step: 9
Training loss: 0.13932044804096222
Validation loss: 1.4520695171048563

Epoch: 5| Step: 10
Training loss: 0.08099145442247391
Validation loss: 1.4389770133520967

Epoch: 576| Step: 0
Training loss: 0.11147947609424591
Validation loss: 1.4813478057102492

Epoch: 5| Step: 1
Training loss: 0.07949282228946686
Validation loss: 1.51240425596955

Epoch: 5| Step: 2
Training loss: 0.07185147702693939
Validation loss: 1.4908091701487058

Epoch: 5| Step: 3
Training loss: 0.0861121192574501
Validation loss: 1.5043655364744124

Epoch: 5| Step: 4
Training loss: 0.11193199455738068
Validation loss: 1.5047956564093148

Epoch: 5| Step: 5
Training loss: 0.07693346589803696
Validation loss: 1.508077290750319

Epoch: 5| Step: 6
Training loss: 0.26568928360939026
Validation loss: 1.5096126525632796

Epoch: 5| Step: 7
Training loss: 0.15407249331474304
Validation loss: 1.5110493193390548

Epoch: 5| Step: 8
Training loss: 0.1041632667183876
Validation loss: 1.5093313724763933

Epoch: 5| Step: 9
Training loss: 0.09235423058271408
Validation loss: 1.5119994699314077

Epoch: 5| Step: 10
Training loss: 0.1531783640384674
Validation loss: 1.4901940655964676

Epoch: 577| Step: 0
Training loss: 0.11979806423187256
Validation loss: 1.4812433411998134

Epoch: 5| Step: 1
Training loss: 0.31221336126327515
Validation loss: 1.4968595479124336

Epoch: 5| Step: 2
Training loss: 0.07005568593740463
Validation loss: 1.5195791900798838

Epoch: 5| Step: 3
Training loss: 0.09681706130504608
Validation loss: 1.517536268439344

Epoch: 5| Step: 4
Training loss: 0.10087589174509048
Validation loss: 1.5228691921439221

Epoch: 5| Step: 5
Training loss: 0.13690757751464844
Validation loss: 1.514339707231009

Epoch: 5| Step: 6
Training loss: 0.07870413362979889
Validation loss: 1.5430807759684901

Epoch: 5| Step: 7
Training loss: 0.12020187079906464
Validation loss: 1.5460748070029802

Epoch: 5| Step: 8
Training loss: 0.14664213359355927
Validation loss: 1.5392570726333126

Epoch: 5| Step: 9
Training loss: 0.06666602194309235
Validation loss: 1.525702118232686

Epoch: 5| Step: 10
Training loss: 0.06271565705537796
Validation loss: 1.5271191173984158

Epoch: 578| Step: 0
Training loss: 0.3251950740814209
Validation loss: 1.5556169222759944

Epoch: 5| Step: 1
Training loss: 0.09981833398342133
Validation loss: 1.5448128395183112

Epoch: 5| Step: 2
Training loss: 0.08058780431747437
Validation loss: 1.5419637541617117

Epoch: 5| Step: 3
Training loss: 0.08958879858255386
Validation loss: 1.514768567136539

Epoch: 5| Step: 4
Training loss: 0.11661424487829208
Validation loss: 1.5228978914599265

Epoch: 5| Step: 5
Training loss: 0.1373899132013321
Validation loss: 1.5002125078631985

Epoch: 5| Step: 6
Training loss: 0.09816708415746689
Validation loss: 1.4830623313944826

Epoch: 5| Step: 7
Training loss: 0.08415870368480682
Validation loss: 1.4764990934761621

Epoch: 5| Step: 8
Training loss: 0.07677926123142242
Validation loss: 1.4952071443680794

Epoch: 5| Step: 9
Training loss: 0.10490542650222778
Validation loss: 1.4613636514191986

Epoch: 5| Step: 10
Training loss: 0.15065939724445343
Validation loss: 1.4594521650704004

Epoch: 579| Step: 0
Training loss: 0.14239372313022614
Validation loss: 1.473709757610034

Epoch: 5| Step: 1
Training loss: 0.14565832912921906
Validation loss: 1.4879407177689254

Epoch: 5| Step: 2
Training loss: 0.1057857871055603
Validation loss: 1.4796410555480628

Epoch: 5| Step: 3
Training loss: 0.07741321623325348
Validation loss: 1.493216811969716

Epoch: 5| Step: 4
Training loss: 0.09494731575250626
Validation loss: 1.488174287221765

Epoch: 5| Step: 5
Training loss: 0.07720942795276642
Validation loss: 1.4472189526404104

Epoch: 5| Step: 6
Training loss: 0.3601866364479065
Validation loss: 1.4739477672884542

Epoch: 5| Step: 7
Training loss: 0.113824263215065
Validation loss: 1.434949412781705

Epoch: 5| Step: 8
Training loss: 0.16912804543972015
Validation loss: 1.424207470750296

Epoch: 5| Step: 9
Training loss: 0.09677734225988388
Validation loss: 1.4661650683290215

Epoch: 5| Step: 10
Training loss: 0.07231312990188599
Validation loss: 1.4327525195255075

Epoch: 580| Step: 0
Training loss: 0.09492429345846176
Validation loss: 1.465331434562642

Epoch: 5| Step: 1
Training loss: 0.20689840614795685
Validation loss: 1.5282017569388113

Epoch: 5| Step: 2
Training loss: 0.07467429339885712
Validation loss: 1.5559383002660607

Epoch: 5| Step: 3
Training loss: 0.12216383218765259
Validation loss: 1.578537726915011

Epoch: 5| Step: 4
Training loss: 0.12818215787410736
Validation loss: 1.5900207950222878

Epoch: 5| Step: 5
Training loss: 0.16609369218349457
Validation loss: 1.5751140297100108

Epoch: 5| Step: 6
Training loss: 0.3340228497982025
Validation loss: 1.5960718124143538

Epoch: 5| Step: 7
Training loss: 0.11078043282032013
Validation loss: 1.5590877866232267

Epoch: 5| Step: 8
Training loss: 0.17246660590171814
Validation loss: 1.5449672078573575

Epoch: 5| Step: 9
Training loss: 0.273204505443573
Validation loss: 1.5405040415384437

Epoch: 5| Step: 10
Training loss: 0.11536102741956711
Validation loss: 1.5131434727740545

Epoch: 581| Step: 0
Training loss: 0.0741649717092514
Validation loss: 1.493866971744004

Epoch: 5| Step: 1
Training loss: 0.10279180854558945
Validation loss: 1.4942239779298023

Epoch: 5| Step: 2
Training loss: 0.32860124111175537
Validation loss: 1.4845794323951966

Epoch: 5| Step: 3
Training loss: 0.2338462620973587
Validation loss: 1.499055995736071

Epoch: 5| Step: 4
Training loss: 0.15565669536590576
Validation loss: 1.491666446449936

Epoch: 5| Step: 5
Training loss: 0.26355814933776855
Validation loss: 1.4878313560639658

Epoch: 5| Step: 6
Training loss: 0.1220867782831192
Validation loss: 1.456663731605776

Epoch: 5| Step: 7
Training loss: 0.10863916575908661
Validation loss: 1.4423849569853915

Epoch: 5| Step: 8
Training loss: 0.1452198177576065
Validation loss: 1.4632848052568332

Epoch: 5| Step: 9
Training loss: 0.1466526985168457
Validation loss: 1.4751280520551948

Epoch: 5| Step: 10
Training loss: 0.09800612181425095
Validation loss: 1.5003615784388717

Epoch: 582| Step: 0
Training loss: 0.1341879665851593
Validation loss: 1.4848019294841315

Epoch: 5| Step: 1
Training loss: 0.17727814614772797
Validation loss: 1.4828310910091604

Epoch: 5| Step: 2
Training loss: 0.1570369005203247
Validation loss: 1.5037772360668387

Epoch: 5| Step: 3
Training loss: 0.19032692909240723
Validation loss: 1.51079862348495

Epoch: 5| Step: 4
Training loss: 0.3152867257595062
Validation loss: 1.495727974881408

Epoch: 5| Step: 5
Training loss: 0.11408022791147232
Validation loss: 1.516353686650594

Epoch: 5| Step: 6
Training loss: 0.19482174515724182
Validation loss: 1.5096928560605614

Epoch: 5| Step: 7
Training loss: 0.09810622036457062
Validation loss: 1.4521193779924864

Epoch: 5| Step: 8
Training loss: 0.13666675984859467
Validation loss: 1.4962330966867425

Epoch: 5| Step: 9
Training loss: 0.12297780811786652
Validation loss: 1.472534792397612

Epoch: 5| Step: 10
Training loss: 0.1338874250650406
Validation loss: 1.449626294515466

Epoch: 583| Step: 0
Training loss: 0.08585480600595474
Validation loss: 1.4713264024385841

Epoch: 5| Step: 1
Training loss: 0.13120844960212708
Validation loss: 1.4743896421565805

Epoch: 5| Step: 2
Training loss: 0.2823289632797241
Validation loss: 1.504115290539239

Epoch: 5| Step: 3
Training loss: 0.13140764832496643
Validation loss: 1.5310747110715477

Epoch: 5| Step: 4
Training loss: 0.1647026091814041
Validation loss: 1.542648958903487

Epoch: 5| Step: 5
Training loss: 0.13650664687156677
Validation loss: 1.521956467500297

Epoch: 5| Step: 6
Training loss: 0.14930406212806702
Validation loss: 1.531220378414277

Epoch: 5| Step: 7
Training loss: 0.06968982517719269
Validation loss: 1.5216225930439529

Epoch: 5| Step: 8
Training loss: 0.14986322820186615
Validation loss: 1.520673862067602

Epoch: 5| Step: 9
Training loss: 0.09989143908023834
Validation loss: 1.5250281768460427

Epoch: 5| Step: 10
Training loss: 0.1323772370815277
Validation loss: 1.513796684562519

Epoch: 584| Step: 0
Training loss: 0.10340187698602676
Validation loss: 1.4784809068966938

Epoch: 5| Step: 1
Training loss: 0.10040495544672012
Validation loss: 1.4970766434105494

Epoch: 5| Step: 2
Training loss: 0.10332182794809341
Validation loss: 1.487597994906928

Epoch: 5| Step: 3
Training loss: 0.1092887669801712
Validation loss: 1.4796825788354362

Epoch: 5| Step: 4
Training loss: 0.11438373476266861
Validation loss: 1.4645453486391293

Epoch: 5| Step: 5
Training loss: 0.11962039768695831
Validation loss: 1.4420198843043337

Epoch: 5| Step: 6
Training loss: 0.2528872787952423
Validation loss: 1.4587205738149664

Epoch: 5| Step: 7
Training loss: 0.13159389793872833
Validation loss: 1.4550160002964798

Epoch: 5| Step: 8
Training loss: 0.11339932680130005
Validation loss: 1.4493755704613143

Epoch: 5| Step: 9
Training loss: 0.1992337852716446
Validation loss: 1.4391071604144188

Epoch: 5| Step: 10
Training loss: 0.13042494654655457
Validation loss: 1.455327062196629

Epoch: 585| Step: 0
Training loss: 0.10494060814380646
Validation loss: 1.4608589180054203

Epoch: 5| Step: 1
Training loss: 0.1372336447238922
Validation loss: 1.4620244637612374

Epoch: 5| Step: 2
Training loss: 0.06901568174362183
Validation loss: 1.4872043799328547

Epoch: 5| Step: 3
Training loss: 0.09392374753952026
Validation loss: 1.4631908016820108

Epoch: 5| Step: 4
Training loss: 0.2655016779899597
Validation loss: 1.4774242370359358

Epoch: 5| Step: 5
Training loss: 0.10366610437631607
Validation loss: 1.4789290005160916

Epoch: 5| Step: 6
Training loss: 0.06977866590023041
Validation loss: 1.4862226279832984

Epoch: 5| Step: 7
Training loss: 0.16351205110549927
Validation loss: 1.4791454551040486

Epoch: 5| Step: 8
Training loss: 0.11176647245883942
Validation loss: 1.4741495988702262

Epoch: 5| Step: 9
Training loss: 0.12479861080646515
Validation loss: 1.4985972412170903

Epoch: 5| Step: 10
Training loss: 0.13753974437713623
Validation loss: 1.499557513062672

Epoch: 586| Step: 0
Training loss: 0.11276733875274658
Validation loss: 1.4710851702638852

Epoch: 5| Step: 1
Training loss: 0.22706465423107147
Validation loss: 1.4845364651372355

Epoch: 5| Step: 2
Training loss: 0.08270677179098129
Validation loss: 1.4690786407839866

Epoch: 5| Step: 3
Training loss: 0.12077387422323227
Validation loss: 1.4940435239063796

Epoch: 5| Step: 4
Training loss: 0.07772288471460342
Validation loss: 1.489622272470946

Epoch: 5| Step: 5
Training loss: 0.07335154712200165
Validation loss: 1.4921220823000836

Epoch: 5| Step: 6
Training loss: 0.17053106427192688
Validation loss: 1.501298790336937

Epoch: 5| Step: 7
Training loss: 0.09081624448299408
Validation loss: 1.5240614234760244

Epoch: 5| Step: 8
Training loss: 0.1443161815404892
Validation loss: 1.5081896397375292

Epoch: 5| Step: 9
Training loss: 0.09170752018690109
Validation loss: 1.5157155695781912

Epoch: 5| Step: 10
Training loss: 0.05075810104608536
Validation loss: 1.4882765893013246

Epoch: 587| Step: 0
Training loss: 0.1321178674697876
Validation loss: 1.5034030188796341

Epoch: 5| Step: 1
Training loss: 0.06579593569040298
Validation loss: 1.4725290959881199

Epoch: 5| Step: 2
Training loss: 0.10438285022974014
Validation loss: 1.4721388086195915

Epoch: 5| Step: 3
Training loss: 0.09484636038541794
Validation loss: 1.493751806597556

Epoch: 5| Step: 4
Training loss: 0.23965568840503693
Validation loss: 1.4956727130438692

Epoch: 5| Step: 5
Training loss: 0.09410562366247177
Validation loss: 1.4598447994519306

Epoch: 5| Step: 6
Training loss: 0.08077941089868546
Validation loss: 1.459464438499943

Epoch: 5| Step: 7
Training loss: 0.12915559113025665
Validation loss: 1.4444979839427496

Epoch: 5| Step: 8
Training loss: 0.07701712846755981
Validation loss: 1.4827356159046132

Epoch: 5| Step: 9
Training loss: 0.09379493445158005
Validation loss: 1.4890297984564176

Epoch: 5| Step: 10
Training loss: 0.09948435425758362
Validation loss: 1.5086766904400242

Epoch: 588| Step: 0
Training loss: 0.10474133491516113
Validation loss: 1.5217408775001444

Epoch: 5| Step: 1
Training loss: 0.09425552189350128
Validation loss: 1.5373197614505727

Epoch: 5| Step: 2
Training loss: 0.06386713683605194
Validation loss: 1.5414678512081024

Epoch: 5| Step: 3
Training loss: 0.08788726478815079
Validation loss: 1.5384843221274755

Epoch: 5| Step: 4
Training loss: 0.09109748899936676
Validation loss: 1.5597950630290534

Epoch: 5| Step: 5
Training loss: 0.0915718823671341
Validation loss: 1.5576282457638813

Epoch: 5| Step: 6
Training loss: 0.09726107865571976
Validation loss: 1.54919913635459

Epoch: 5| Step: 7
Training loss: 0.11792536079883575
Validation loss: 1.5368878110762565

Epoch: 5| Step: 8
Training loss: 0.12579593062400818
Validation loss: 1.5416109305556103

Epoch: 5| Step: 9
Training loss: 0.3281901478767395
Validation loss: 1.531348034899722

Epoch: 5| Step: 10
Training loss: 0.19901594519615173
Validation loss: 1.5346354797322264

Epoch: 589| Step: 0
Training loss: 0.07006820291280746
Validation loss: 1.519554744484604

Epoch: 5| Step: 1
Training loss: 0.14080747961997986
Validation loss: 1.5066618816826933

Epoch: 5| Step: 2
Training loss: 0.08495093882083893
Validation loss: 1.4967917780722342

Epoch: 5| Step: 3
Training loss: 0.2753681540489197
Validation loss: 1.4930452390383648

Epoch: 5| Step: 4
Training loss: 0.19766917824745178
Validation loss: 1.482907783600592

Epoch: 5| Step: 5
Training loss: 0.12039061635732651
Validation loss: 1.4952649685644335

Epoch: 5| Step: 6
Training loss: 0.08729951083660126
Validation loss: 1.4662884332800423

Epoch: 5| Step: 7
Training loss: 0.05174228549003601
Validation loss: 1.4704510191435456

Epoch: 5| Step: 8
Training loss: 0.13936753571033478
Validation loss: 1.4916456207152335

Epoch: 5| Step: 9
Training loss: 0.08318611234426498
Validation loss: 1.467715863258608

Epoch: 5| Step: 10
Training loss: 0.12017685920000076
Validation loss: 1.5063011325815672

Epoch: 590| Step: 0
Training loss: 0.1681309938430786
Validation loss: 1.473673011666985

Epoch: 5| Step: 1
Training loss: 0.14936253428459167
Validation loss: 1.489778184762565

Epoch: 5| Step: 2
Training loss: 0.10796754062175751
Validation loss: 1.493335562367593

Epoch: 5| Step: 3
Training loss: 0.1009405106306076
Validation loss: 1.4823806439676592

Epoch: 5| Step: 4
Training loss: 0.3529472351074219
Validation loss: 1.5126173239882275

Epoch: 5| Step: 5
Training loss: 0.11711128801107407
Validation loss: 1.4693690115405666

Epoch: 5| Step: 6
Training loss: 0.19751791656017303
Validation loss: 1.4838564383086337

Epoch: 5| Step: 7
Training loss: 0.08699333667755127
Validation loss: 1.4801888658154396

Epoch: 5| Step: 8
Training loss: 0.10423707962036133
Validation loss: 1.490017452547627

Epoch: 5| Step: 9
Training loss: 0.1554095447063446
Validation loss: 1.4906030579279828

Epoch: 5| Step: 10
Training loss: 0.06965381652116776
Validation loss: 1.4846702173192015

Epoch: 591| Step: 0
Training loss: 0.09133656322956085
Validation loss: 1.4832856802530185

Epoch: 5| Step: 1
Training loss: 0.15651068091392517
Validation loss: 1.4458309937548894

Epoch: 5| Step: 2
Training loss: 0.11542229354381561
Validation loss: 1.484006720204507

Epoch: 5| Step: 3
Training loss: 0.12364121526479721
Validation loss: 1.439688979938466

Epoch: 5| Step: 4
Training loss: 0.10696657001972198
Validation loss: 1.44654175543016

Epoch: 5| Step: 5
Training loss: 0.1334550827741623
Validation loss: 1.4660973497616347

Epoch: 5| Step: 6
Training loss: 0.05622311308979988
Validation loss: 1.458498941954746

Epoch: 5| Step: 7
Training loss: 0.25602030754089355
Validation loss: 1.4680193662643433

Epoch: 5| Step: 8
Training loss: 0.10880281776189804
Validation loss: 1.5073935536928074

Epoch: 5| Step: 9
Training loss: 0.1069449782371521
Validation loss: 1.5154654338795652

Epoch: 5| Step: 10
Training loss: 0.18191730976104736
Validation loss: 1.4948664865186136

Epoch: 592| Step: 0
Training loss: 0.10539598762989044
Validation loss: 1.4911899733287033

Epoch: 5| Step: 1
Training loss: 0.09310202300548553
Validation loss: 1.4823426854225896

Epoch: 5| Step: 2
Training loss: 0.08956544101238251
Validation loss: 1.5232050803399855

Epoch: 5| Step: 3
Training loss: 0.09151948988437653
Validation loss: 1.4988456515855686

Epoch: 5| Step: 4
Training loss: 0.12284286320209503
Validation loss: 1.5121337380460513

Epoch: 5| Step: 5
Training loss: 0.17577815055847168
Validation loss: 1.5153299954629713

Epoch: 5| Step: 6
Training loss: 0.0810355693101883
Validation loss: 1.5036291691564745

Epoch: 5| Step: 7
Training loss: 0.07818286120891571
Validation loss: 1.5050181201709214

Epoch: 5| Step: 8
Training loss: 0.08682094514369965
Validation loss: 1.4981687402212491

Epoch: 5| Step: 9
Training loss: 0.32633012533187866
Validation loss: 1.476979677395154

Epoch: 5| Step: 10
Training loss: 0.11256586760282516
Validation loss: 1.5065711749497281

Epoch: 593| Step: 0
Training loss: 0.08905038982629776
Validation loss: 1.4986861207151925

Epoch: 5| Step: 1
Training loss: 0.08191579580307007
Validation loss: 1.4959688891646683

Epoch: 5| Step: 2
Training loss: 0.13012556731700897
Validation loss: 1.519593645167607

Epoch: 5| Step: 3
Training loss: 0.15479353070259094
Validation loss: 1.5270220272002681

Epoch: 5| Step: 4
Training loss: 0.17863082885742188
Validation loss: 1.5156925006579327

Epoch: 5| Step: 5
Training loss: 0.1113029271364212
Validation loss: 1.4766536707519202

Epoch: 5| Step: 6
Training loss: 0.11733722686767578
Validation loss: 1.4835110851513442

Epoch: 5| Step: 7
Training loss: 0.3253377079963684
Validation loss: 1.486898773459978

Epoch: 5| Step: 8
Training loss: 0.09181781113147736
Validation loss: 1.4882010259935934

Epoch: 5| Step: 9
Training loss: 0.12749798595905304
Validation loss: 1.4785362353888891

Epoch: 5| Step: 10
Training loss: 0.08066876977682114
Validation loss: 1.4820182374728623

Epoch: 594| Step: 0
Training loss: 0.2602435052394867
Validation loss: 1.4972094310227262

Epoch: 5| Step: 1
Training loss: 0.10691298544406891
Validation loss: 1.5163971480502878

Epoch: 5| Step: 2
Training loss: 0.16088318824768066
Validation loss: 1.4971075641211642

Epoch: 5| Step: 3
Training loss: 0.07373601198196411
Validation loss: 1.526035157583093

Epoch: 5| Step: 4
Training loss: 0.1606566309928894
Validation loss: 1.563326435704385

Epoch: 5| Step: 5
Training loss: 0.13803929090499878
Validation loss: 1.5296107620321295

Epoch: 5| Step: 6
Training loss: 0.15156500041484833
Validation loss: 1.5347669662967804

Epoch: 5| Step: 7
Training loss: 0.09180276840925217
Validation loss: 1.5059116066143077

Epoch: 5| Step: 8
Training loss: 0.10661711543798447
Validation loss: 1.5149840949684061

Epoch: 5| Step: 9
Training loss: 0.17754137516021729
Validation loss: 1.495285234143657

Epoch: 5| Step: 10
Training loss: 0.11368487030267715
Validation loss: 1.4849952343971498

Epoch: 595| Step: 0
Training loss: 0.15217258036136627
Validation loss: 1.5063708379704466

Epoch: 5| Step: 1
Training loss: 0.15912184119224548
Validation loss: 1.4951977101705407

Epoch: 5| Step: 2
Training loss: 0.09998209774494171
Validation loss: 1.4621214841001777

Epoch: 5| Step: 3
Training loss: 0.06967562437057495
Validation loss: 1.4759594112314203

Epoch: 5| Step: 4
Training loss: 0.15656933188438416
Validation loss: 1.490017326929236

Epoch: 5| Step: 5
Training loss: 0.28150659799575806
Validation loss: 1.4925948573696999

Epoch: 5| Step: 6
Training loss: 0.1404889076948166
Validation loss: 1.5128570141330842

Epoch: 5| Step: 7
Training loss: 0.18217246234416962
Validation loss: 1.4713614832970403

Epoch: 5| Step: 8
Training loss: 0.09827257692813873
Validation loss: 1.4708852755126132

Epoch: 5| Step: 9
Training loss: 0.09581699967384338
Validation loss: 1.4629893277281074

Epoch: 5| Step: 10
Training loss: 0.11570442467927933
Validation loss: 1.437865553363677

Epoch: 596| Step: 0
Training loss: 0.09018804132938385
Validation loss: 1.426648380935833

Epoch: 5| Step: 1
Training loss: 0.13167449831962585
Validation loss: 1.407580587171739

Epoch: 5| Step: 2
Training loss: 0.17154523730278015
Validation loss: 1.3703436902774278

Epoch: 5| Step: 3
Training loss: 0.0680108293890953
Validation loss: 1.4082213396667151

Epoch: 5| Step: 4
Training loss: 0.16288617253303528
Validation loss: 1.3834462294014551

Epoch: 5| Step: 5
Training loss: 0.11835511028766632
Validation loss: 1.4075483481089275

Epoch: 5| Step: 6
Training loss: 0.10973280668258667
Validation loss: 1.3656699567712762

Epoch: 5| Step: 7
Training loss: 0.1158706396818161
Validation loss: 1.4105941710933563

Epoch: 5| Step: 8
Training loss: 0.12331292778253555
Validation loss: 1.395493725294708

Epoch: 5| Step: 9
Training loss: 0.3206166625022888
Validation loss: 1.4437275484044065

Epoch: 5| Step: 10
Training loss: 0.09185239672660828
Validation loss: 1.457943042119344

Epoch: 597| Step: 0
Training loss: 0.16091576218605042
Validation loss: 1.458817030793877

Epoch: 5| Step: 1
Training loss: 0.15830537676811218
Validation loss: 1.4742132040762133

Epoch: 5| Step: 2
Training loss: 0.08207941055297852
Validation loss: 1.5051624813387472

Epoch: 5| Step: 3
Training loss: 0.08739107847213745
Validation loss: 1.4964917923814507

Epoch: 5| Step: 4
Training loss: 0.1179378479719162
Validation loss: 1.5027604256906817

Epoch: 5| Step: 5
Training loss: 0.10958299785852432
Validation loss: 1.5047052086040538

Epoch: 5| Step: 6
Training loss: 0.11412136256694794
Validation loss: 1.5086664845866542

Epoch: 5| Step: 7
Training loss: 0.17203345894813538
Validation loss: 1.5016291500419698

Epoch: 5| Step: 8
Training loss: 0.10703036934137344
Validation loss: 1.5170457952766008

Epoch: 5| Step: 9
Training loss: 0.07765667140483856
Validation loss: 1.5270727116574523

Epoch: 5| Step: 10
Training loss: 0.286937952041626
Validation loss: 1.535751845247002

Epoch: 598| Step: 0
Training loss: 0.08095163851976395
Validation loss: 1.5427309595128542

Epoch: 5| Step: 1
Training loss: 0.08970833569765091
Validation loss: 1.5725591003253896

Epoch: 5| Step: 2
Training loss: 0.21524253487586975
Validation loss: 1.5517781972885132

Epoch: 5| Step: 3
Training loss: 0.18403823673725128
Validation loss: 1.567248910985967

Epoch: 5| Step: 4
Training loss: 0.1645827740430832
Validation loss: 1.5346327699640745

Epoch: 5| Step: 5
Training loss: 0.14057496190071106
Validation loss: 1.4904400199972174

Epoch: 5| Step: 6
Training loss: 0.1015550047159195
Validation loss: 1.45921076497724

Epoch: 5| Step: 7
Training loss: 0.1551111787557602
Validation loss: 1.4519491605861212

Epoch: 5| Step: 8
Training loss: 0.2827027440071106
Validation loss: 1.442054303743506

Epoch: 5| Step: 9
Training loss: 0.18340516090393066
Validation loss: 1.4691719393576346

Epoch: 5| Step: 10
Training loss: 0.17033296823501587
Validation loss: 1.473783557133008

Epoch: 599| Step: 0
Training loss: 0.11300686746835709
Validation loss: 1.4737876371670795

Epoch: 5| Step: 1
Training loss: 0.13656234741210938
Validation loss: 1.4675065881462508

Epoch: 5| Step: 2
Training loss: 0.16437630355358124
Validation loss: 1.5068278710047405

Epoch: 5| Step: 3
Training loss: 0.24672921001911163
Validation loss: 1.490019500896495

Epoch: 5| Step: 4
Training loss: 0.19615595042705536
Validation loss: 1.4917647466864636

Epoch: 5| Step: 5
Training loss: 0.10608859360218048
Validation loss: 1.5081929327339254

Epoch: 5| Step: 6
Training loss: 0.16260966658592224
Validation loss: 1.517378782713285

Epoch: 5| Step: 7
Training loss: 0.08204251527786255
Validation loss: 1.514628585948739

Epoch: 5| Step: 8
Training loss: 0.10925684124231339
Validation loss: 1.521369045780551

Epoch: 5| Step: 9
Training loss: 0.08221016824245453
Validation loss: 1.4747178605807725

Epoch: 5| Step: 10
Training loss: 0.14275841414928436
Validation loss: 1.4951876722356325

Epoch: 600| Step: 0
Training loss: 0.25267666578292847
Validation loss: 1.4808830009993685

Epoch: 5| Step: 1
Training loss: 0.16788887977600098
Validation loss: 1.4946802521264682

Epoch: 5| Step: 2
Training loss: 0.09470565617084503
Validation loss: 1.4885816586914884

Epoch: 5| Step: 3
Training loss: 0.1465892791748047
Validation loss: 1.4808061199803506

Epoch: 5| Step: 4
Training loss: 0.07534812390804291
Validation loss: 1.4892764706765451

Epoch: 5| Step: 5
Training loss: 0.2057936191558838
Validation loss: 1.4933546884085542

Epoch: 5| Step: 6
Training loss: 0.12759555876255035
Validation loss: 1.507192216893678

Epoch: 5| Step: 7
Training loss: 0.15377740561962128
Validation loss: 1.5410112360472321

Epoch: 5| Step: 8
Training loss: 0.10263583809137344
Validation loss: 1.5138720068880307

Epoch: 5| Step: 9
Training loss: 0.14334583282470703
Validation loss: 1.5473793873222925

Epoch: 5| Step: 10
Training loss: 0.0802554190158844
Validation loss: 1.5016541199017597

Testing loss: 2.5048993958367243
