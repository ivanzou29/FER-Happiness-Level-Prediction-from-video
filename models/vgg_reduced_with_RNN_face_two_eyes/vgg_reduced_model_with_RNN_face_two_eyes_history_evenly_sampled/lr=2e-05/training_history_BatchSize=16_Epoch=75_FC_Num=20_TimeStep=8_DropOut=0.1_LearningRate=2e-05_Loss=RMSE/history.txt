Epoch: 1| Step: 0
Training loss: 5.6189968712603315
Validation loss: 5.795614768216756

Epoch: 6| Step: 1
Training loss: 5.887106575749119
Validation loss: 5.779415505825719

Epoch: 6| Step: 2
Training loss: 6.219341307472048
Validation loss: 5.768465838188865

Epoch: 6| Step: 3
Training loss: 5.935600539100119
Validation loss: 5.757052182265787

Epoch: 6| Step: 4
Training loss: 5.179700572369911
Validation loss: 5.7449588086586525

Epoch: 6| Step: 5
Training loss: 6.875280755986101
Validation loss: 5.73086252956678

Epoch: 6| Step: 6
Training loss: 4.886495486006881
Validation loss: 5.715157853576445

Epoch: 6| Step: 7
Training loss: 5.349522735128092
Validation loss: 5.697489358357785

Epoch: 6| Step: 8
Training loss: 6.342026349501666
Validation loss: 5.678335464213092

Epoch: 6| Step: 9
Training loss: 4.882311302402219
Validation loss: 5.655537029776236

Epoch: 6| Step: 10
Training loss: 5.6398820467038515
Validation loss: 5.631971274733236

Epoch: 6| Step: 11
Training loss: 5.200039518646315
Validation loss: 5.60532232408225

Epoch: 6| Step: 12
Training loss: 5.956614995702782
Validation loss: 5.576823941481168

Epoch: 6| Step: 13
Training loss: 6.097788250292901
Validation loss: 5.5447716068304445

Epoch: 2| Step: 0
Training loss: 6.343348598465198
Validation loss: 5.512600914463462

Epoch: 6| Step: 1
Training loss: 4.829494245125082
Validation loss: 5.477893418297559

Epoch: 6| Step: 2
Training loss: 5.901364197857301
Validation loss: 5.441430304250128

Epoch: 6| Step: 3
Training loss: 5.316198161339079
Validation loss: 5.404584055247405

Epoch: 6| Step: 4
Training loss: 5.672183025812929
Validation loss: 5.3681168207294645

Epoch: 6| Step: 5
Training loss: 6.171575843224474
Validation loss: 5.330648970835675

Epoch: 6| Step: 6
Training loss: 4.6098020194150555
Validation loss: 5.294580501130184

Epoch: 6| Step: 7
Training loss: 5.358401552105209
Validation loss: 5.257906166564551

Epoch: 6| Step: 8
Training loss: 4.857317031814847
Validation loss: 5.220096488362303

Epoch: 6| Step: 9
Training loss: 4.902381100455325
Validation loss: 5.177968074045532

Epoch: 6| Step: 10
Training loss: 4.675014091919248
Validation loss: 5.1318821991961086

Epoch: 6| Step: 11
Training loss: 5.15845012542849
Validation loss: 5.07831312817104

Epoch: 6| Step: 12
Training loss: 5.128818856952509
Validation loss: 5.020773675082734

Epoch: 6| Step: 13
Training loss: 5.396947365227597
Validation loss: 4.958148988375156

Epoch: 3| Step: 0
Training loss: 5.39740430823943
Validation loss: 4.905619020359295

Epoch: 6| Step: 1
Training loss: 4.207813923322378
Validation loss: 4.859341991143496

Epoch: 6| Step: 2
Training loss: 6.237001864737751
Validation loss: 4.816292431760173

Epoch: 6| Step: 3
Training loss: 4.867767054555108
Validation loss: 4.779087513533709

Epoch: 6| Step: 4
Training loss: 4.85589946331041
Validation loss: 4.744279967606577

Epoch: 6| Step: 5
Training loss: 4.341185766569231
Validation loss: 4.715905192349682

Epoch: 6| Step: 6
Training loss: 5.408261669058355
Validation loss: 4.6881179172591585

Epoch: 6| Step: 7
Training loss: 3.976706631489752
Validation loss: 4.65638613014952

Epoch: 6| Step: 8
Training loss: 3.2527839767725646
Validation loss: 4.621388500588754

Epoch: 6| Step: 9
Training loss: 4.62466346959768
Validation loss: 4.600113522313432

Epoch: 6| Step: 10
Training loss: 5.061514864543916
Validation loss: 4.587812595715545

Epoch: 6| Step: 11
Training loss: 4.386589394867616
Validation loss: 4.55406646358585

Epoch: 6| Step: 12
Training loss: 5.342385101011053
Validation loss: 4.5309541022208295

Epoch: 6| Step: 13
Training loss: 3.987342118632474
Validation loss: 4.51013513892514

Epoch: 4| Step: 0
Training loss: 5.103715941581537
Validation loss: 4.489485745763273

Epoch: 6| Step: 1
Training loss: 4.3865052576332495
Validation loss: 4.479921351865325

Epoch: 6| Step: 2
Training loss: 4.025276430482368
Validation loss: 4.459416082126438

Epoch: 6| Step: 3
Training loss: 3.9634308500834923
Validation loss: 4.434924133571581

Epoch: 6| Step: 4
Training loss: 4.34842392004033
Validation loss: 4.413066519695402

Epoch: 6| Step: 5
Training loss: 4.419952298075256
Validation loss: 4.398726184402384

Epoch: 6| Step: 6
Training loss: 5.283445003705228
Validation loss: 4.390647169067482

Epoch: 6| Step: 7
Training loss: 4.076593454929905
Validation loss: 4.3768039599667405

Epoch: 6| Step: 8
Training loss: 5.449986645043485
Validation loss: 4.377070144311942

Epoch: 6| Step: 9
Training loss: 4.9543909807598325
Validation loss: 4.36812576058499

Epoch: 6| Step: 10
Training loss: 3.57903508102478
Validation loss: 4.349642760596346

Epoch: 6| Step: 11
Training loss: 3.6552396503163944
Validation loss: 4.332988434610673

Epoch: 6| Step: 12
Training loss: 4.511947877028228
Validation loss: 4.316348134803454

Epoch: 6| Step: 13
Training loss: 5.149381930104327
Validation loss: 4.305554704316516

Epoch: 5| Step: 0
Training loss: 3.194987758559295
Validation loss: 4.292836646360078

Epoch: 6| Step: 1
Training loss: 4.905729035338587
Validation loss: 4.280179899519642

Epoch: 6| Step: 2
Training loss: 4.13050082479094
Validation loss: 4.266691903615219

Epoch: 6| Step: 3
Training loss: 4.9588724479048505
Validation loss: 4.264488381603681

Epoch: 6| Step: 4
Training loss: 4.692769864857705
Validation loss: 4.242172346033469

Epoch: 6| Step: 5
Training loss: 4.61315018534714
Validation loss: 4.231098356846948

Epoch: 6| Step: 6
Training loss: 3.6313594414244186
Validation loss: 4.21360950432347

Epoch: 6| Step: 7
Training loss: 5.1277787653650115
Validation loss: 4.1990395986083335

Epoch: 6| Step: 8
Training loss: 5.4623597220908575
Validation loss: 4.1795444406157145

Epoch: 6| Step: 9
Training loss: 3.8852581711146787
Validation loss: 4.162828877397968

Epoch: 6| Step: 10
Training loss: 3.7040795492276937
Validation loss: 4.143271671977758

Epoch: 6| Step: 11
Training loss: 3.5484108981399793
Validation loss: 4.126427211821374

Epoch: 6| Step: 12
Training loss: 4.021882758618439
Validation loss: 4.10192817210343

Epoch: 6| Step: 13
Training loss: 4.068343434918365
Validation loss: 4.064137939977211

Epoch: 6| Step: 0
Training loss: 3.7564697404462972
Validation loss: 4.026568229728167

Epoch: 6| Step: 1
Training loss: 4.684035992204749
Validation loss: 4.004202559036892

Epoch: 6| Step: 2
Training loss: 4.19353448851296
Validation loss: 3.9904885507567727

Epoch: 6| Step: 3
Training loss: 4.639450181415881
Validation loss: 3.9839790741081433

Epoch: 6| Step: 4
Training loss: 3.998706847014952
Validation loss: 3.975130772698411

Epoch: 6| Step: 5
Training loss: 4.6990957648339196
Validation loss: 3.9606079733399273

Epoch: 6| Step: 6
Training loss: 3.9110728284257874
Validation loss: 3.9503748595276336

Epoch: 6| Step: 7
Training loss: 4.534446693658109
Validation loss: 3.9287982072167202

Epoch: 6| Step: 8
Training loss: 4.339548837442532
Validation loss: 3.918144140275574

Epoch: 6| Step: 9
Training loss: 4.238251097963023
Validation loss: 3.914621356276338

Epoch: 6| Step: 10
Training loss: 3.369173176926078
Validation loss: 3.901209499440421

Epoch: 6| Step: 11
Training loss: 3.422762820934156
Validation loss: 3.8929403286462265

Epoch: 6| Step: 12
Training loss: 3.726765561119506
Validation loss: 3.8820690216465006

Epoch: 6| Step: 13
Training loss: 3.3390841150008157
Validation loss: 3.8740219485589464

Epoch: 7| Step: 0
Training loss: 4.240823150480617
Validation loss: 3.8651605896973242

Epoch: 6| Step: 1
Training loss: 3.315446946291603
Validation loss: 3.8582951735298465

Epoch: 6| Step: 2
Training loss: 4.4475898473712085
Validation loss: 3.8501116829782167

Epoch: 6| Step: 3
Training loss: 3.7299395280696763
Validation loss: 3.841128456016626

Epoch: 6| Step: 4
Training loss: 3.0185587946833916
Validation loss: 3.828597616253528

Epoch: 6| Step: 5
Training loss: 4.451328276513985
Validation loss: 3.817904094040803

Epoch: 6| Step: 6
Training loss: 4.430818066979932
Validation loss: 3.807777643221557

Epoch: 6| Step: 7
Training loss: 3.856198381916231
Validation loss: 3.7962081433626644

Epoch: 6| Step: 8
Training loss: 4.616503359847621
Validation loss: 3.785481825914681

Epoch: 6| Step: 9
Training loss: 3.6223733527854654
Validation loss: 3.7714104929943377

Epoch: 6| Step: 10
Training loss: 4.223097080365938
Validation loss: 3.7635911028767324

Epoch: 6| Step: 11
Training loss: 3.799950880435902
Validation loss: 3.751690011351025

Epoch: 6| Step: 12
Training loss: 3.9501831205389726
Validation loss: 3.749402103136063

Epoch: 6| Step: 13
Training loss: 3.340580231069507
Validation loss: 3.7392671161003106

Epoch: 8| Step: 0
Training loss: 3.5836925917924742
Validation loss: 3.7324507723419673

Epoch: 6| Step: 1
Training loss: 3.822881104237194
Validation loss: 3.7266509910515184

Epoch: 6| Step: 2
Training loss: 3.812852436722884
Validation loss: 3.721768586709331

Epoch: 6| Step: 3
Training loss: 4.4221268976396555
Validation loss: 3.7107988291263982

Epoch: 6| Step: 4
Training loss: 3.7791931611253586
Validation loss: 3.7025594643350472

Epoch: 6| Step: 5
Training loss: 4.049870976406176
Validation loss: 3.6920412395001323

Epoch: 6| Step: 6
Training loss: 3.4405487412430507
Validation loss: 3.6880590822518373

Epoch: 6| Step: 7
Training loss: 4.024540959120757
Validation loss: 3.678241025410426

Epoch: 6| Step: 8
Training loss: 2.6887492447926955
Validation loss: 3.6751370425996246

Epoch: 6| Step: 9
Training loss: 4.384090679191527
Validation loss: 3.6668208519594945

Epoch: 6| Step: 10
Training loss: 3.7898849381265234
Validation loss: 3.660037891391958

Epoch: 6| Step: 11
Training loss: 4.380796026417259
Validation loss: 3.6545768522633573

Epoch: 6| Step: 12
Training loss: 3.713519095860069
Validation loss: 3.647167315926813

Epoch: 6| Step: 13
Training loss: 4.089760037123802
Validation loss: 3.64603438753246

Epoch: 9| Step: 0
Training loss: 3.9106891280408314
Validation loss: 3.636164416638644

Epoch: 6| Step: 1
Training loss: 2.864017740535667
Validation loss: 3.6262213799633463

Epoch: 6| Step: 2
Training loss: 4.150279180489064
Validation loss: 3.6241037620821013

Epoch: 6| Step: 3
Training loss: 3.8355128408651438
Validation loss: 3.6186017057432007

Epoch: 6| Step: 4
Training loss: 3.686947538726353
Validation loss: 3.6105283554615117

Epoch: 6| Step: 5
Training loss: 4.210882919042721
Validation loss: 3.610063175885643

Epoch: 6| Step: 6
Training loss: 3.41034305580843
Validation loss: 3.607530541390083

Epoch: 6| Step: 7
Training loss: 4.085224855320729
Validation loss: 3.5989144374831663

Epoch: 6| Step: 8
Training loss: 3.4485285620339674
Validation loss: 3.5932594738543004

Epoch: 6| Step: 9
Training loss: 4.5379320007313595
Validation loss: 3.586245071854444

Epoch: 6| Step: 10
Training loss: 3.5609762044881266
Validation loss: 3.5818815407254077

Epoch: 6| Step: 11
Training loss: 3.054137821937344
Validation loss: 3.57847086349926

Epoch: 6| Step: 12
Training loss: 4.256990853921476
Validation loss: 3.5719490047981246

Epoch: 6| Step: 13
Training loss: 3.9011485242617474
Validation loss: 3.5676643519171547

Epoch: 10| Step: 0
Training loss: 3.3422484547039875
Validation loss: 3.562024874793875

Epoch: 6| Step: 1
Training loss: 2.7309577733186683
Validation loss: 3.5564528679126406

Epoch: 6| Step: 2
Training loss: 4.105548193659281
Validation loss: 3.55298803452954

Epoch: 6| Step: 3
Training loss: 4.335496704790132
Validation loss: 3.5496533908240884

Epoch: 6| Step: 4
Training loss: 4.537367486201
Validation loss: 3.5430026237673014

Epoch: 6| Step: 5
Training loss: 4.143568842223348
Validation loss: 3.5386849873697073

Epoch: 6| Step: 6
Training loss: 3.4224510230606695
Validation loss: 3.5328825424687627

Epoch: 6| Step: 7
Training loss: 3.8446262260291433
Validation loss: 3.5284702178164076

Epoch: 6| Step: 8
Training loss: 3.5310807989313333
Validation loss: 3.5243084104515523

Epoch: 6| Step: 9
Training loss: 4.082032885391419
Validation loss: 3.5170149872151004

Epoch: 6| Step: 10
Training loss: 2.593652654452686
Validation loss: 3.5151217054116226

Epoch: 6| Step: 11
Training loss: 3.2736679396626047
Validation loss: 3.509371604169381

Epoch: 6| Step: 12
Training loss: 3.9549189782795624
Validation loss: 3.5061403371557964

Epoch: 6| Step: 13
Training loss: 4.0415371484093345
Validation loss: 3.5008571735348553

Epoch: 11| Step: 0
Training loss: 2.7352764278662622
Validation loss: 3.49754531469191

Epoch: 6| Step: 1
Training loss: 3.3316358217608855
Validation loss: 3.494422982767081

Epoch: 6| Step: 2
Training loss: 3.4938668601703586
Validation loss: 3.49027764226031

Epoch: 6| Step: 3
Training loss: 4.079261592167031
Validation loss: 3.483976674204323

Epoch: 6| Step: 4
Training loss: 3.8292797604623665
Validation loss: 3.4809832596323065

Epoch: 6| Step: 5
Training loss: 3.9076746669592914
Validation loss: 3.480382141948599

Epoch: 6| Step: 6
Training loss: 3.047866738137083
Validation loss: 3.4750788779671073

Epoch: 6| Step: 7
Training loss: 4.454513386909973
Validation loss: 3.468732458925928

Epoch: 6| Step: 8
Training loss: 3.5188705721807625
Validation loss: 3.4668623246273422

Epoch: 6| Step: 9
Training loss: 4.290785146504298
Validation loss: 3.461722810210079

Epoch: 6| Step: 10
Training loss: 4.127256296542961
Validation loss: 3.459025972767877

Epoch: 6| Step: 11
Training loss: 3.6332558638220167
Validation loss: 3.4536604571232314

Epoch: 6| Step: 12
Training loss: 3.5607677062706604
Validation loss: 3.447759986774707

Epoch: 6| Step: 13
Training loss: 2.8265312298531144
Validation loss: 3.4440506107814954

Epoch: 12| Step: 0
Training loss: 3.125923935680482
Validation loss: 3.4406112276460132

Epoch: 6| Step: 1
Training loss: 3.4765852680960916
Validation loss: 3.440721726722982

Epoch: 6| Step: 2
Training loss: 3.492540175275802
Validation loss: 3.439162215459885

Epoch: 6| Step: 3
Training loss: 4.220292777079284
Validation loss: 3.430672983426549

Epoch: 6| Step: 4
Training loss: 3.9327797828862363
Validation loss: 3.421627829706874

Epoch: 6| Step: 5
Training loss: 3.09471654724831
Validation loss: 3.418851763459322

Epoch: 6| Step: 6
Training loss: 3.4401448565301918
Validation loss: 3.4206256639496777

Epoch: 6| Step: 7
Training loss: 3.1440356509684406
Validation loss: 3.4106197681400516

Epoch: 6| Step: 8
Training loss: 3.675198613203997
Validation loss: 3.4081215888637417

Epoch: 6| Step: 9
Training loss: 3.5712205662781193
Validation loss: 3.4065834131353188

Epoch: 6| Step: 10
Training loss: 4.607464721014748
Validation loss: 3.4073539819654917

Epoch: 6| Step: 11
Training loss: 4.497603520065553
Validation loss: 3.3980228761900033

Epoch: 6| Step: 12
Training loss: 2.743167104478333
Validation loss: 3.384230954353654

Epoch: 6| Step: 13
Training loss: 3.191485736655483
Validation loss: 3.38671048616086

Epoch: 13| Step: 0
Training loss: 2.479518438007212
Validation loss: 3.425461117205639

Epoch: 6| Step: 1
Training loss: 2.790085377907928
Validation loss: 3.3809590480208276

Epoch: 6| Step: 2
Training loss: 3.774012298717584
Validation loss: 3.368736924543641

Epoch: 6| Step: 3
Training loss: 3.996542986455961
Validation loss: 3.365075058725817

Epoch: 6| Step: 4
Training loss: 3.7058564104157004
Validation loss: 3.3588123656434288

Epoch: 6| Step: 5
Training loss: 4.584519851153989
Validation loss: 3.3592198489877796

Epoch: 6| Step: 6
Training loss: 2.6515155561042247
Validation loss: 3.354197894403036

Epoch: 6| Step: 7
Training loss: 3.601869383871614
Validation loss: 3.3521922547443923

Epoch: 6| Step: 8
Training loss: 2.8173393153596344
Validation loss: 3.3469331617341753

Epoch: 6| Step: 9
Training loss: 3.9728769786808065
Validation loss: 3.3448464059792937

Epoch: 6| Step: 10
Training loss: 3.7258586738718384
Validation loss: 3.3423333972471543

Epoch: 6| Step: 11
Training loss: 3.951112860834311
Validation loss: 3.3388731795423436

Epoch: 6| Step: 12
Training loss: 3.337382162349826
Validation loss: 3.331145658218968

Epoch: 6| Step: 13
Training loss: 4.493100280905974
Validation loss: 3.3297497195346186

Epoch: 14| Step: 0
Training loss: 3.1064499174753673
Validation loss: 3.327620898752742

Epoch: 6| Step: 1
Training loss: 3.5046179143330116
Validation loss: 3.3254923402708454

Epoch: 6| Step: 2
Training loss: 3.0332754388112058
Validation loss: 3.321451360453803

Epoch: 6| Step: 3
Training loss: 3.928446336711546
Validation loss: 3.3191261738465405

Epoch: 6| Step: 4
Training loss: 3.126335469038123
Validation loss: 3.31745759455626

Epoch: 6| Step: 5
Training loss: 3.8569181089166467
Validation loss: 3.3146942016385443

Epoch: 6| Step: 6
Training loss: 3.591932683122757
Validation loss: 3.310719527565639

Epoch: 6| Step: 7
Training loss: 3.666362244077549
Validation loss: 3.315286375746335

Epoch: 6| Step: 8
Training loss: 2.8194635439655418
Validation loss: 3.303359360452088

Epoch: 6| Step: 9
Training loss: 4.501229859878836
Validation loss: 3.3044808112041357

Epoch: 6| Step: 10
Training loss: 3.3012518733465965
Validation loss: 3.3074234262888327

Epoch: 6| Step: 11
Training loss: 3.410580183772463
Validation loss: 3.3094608359933617

Epoch: 6| Step: 12
Training loss: 3.5649439141996555
Validation loss: 3.301807701961998

Epoch: 6| Step: 13
Training loss: 4.318899299481017
Validation loss: 3.3000815887657073

Epoch: 15| Step: 0
Training loss: 3.3047768150146095
Validation loss: 3.2925567814957954

Epoch: 6| Step: 1
Training loss: 3.556115569941076
Validation loss: 3.2876160152194016

Epoch: 6| Step: 2
Training loss: 3.5604501816786907
Validation loss: 3.285291797644592

Epoch: 6| Step: 3
Training loss: 3.5555176153410475
Validation loss: 3.2808276895473187

Epoch: 6| Step: 4
Training loss: 2.994607847902581
Validation loss: 3.2783171250737224

Epoch: 6| Step: 5
Training loss: 3.5505471734675016
Validation loss: 3.2762450644425445

Epoch: 6| Step: 6
Training loss: 4.047962175245317
Validation loss: 3.2823857074021303

Epoch: 6| Step: 7
Training loss: 3.6872522303213495
Validation loss: 3.271726607916163

Epoch: 6| Step: 8
Training loss: 3.7075692721973637
Validation loss: 3.269364295088319

Epoch: 6| Step: 9
Training loss: 3.3902435791368895
Validation loss: 3.262273383553275

Epoch: 6| Step: 10
Training loss: 3.2888461877725708
Validation loss: 3.2578146357025317

Epoch: 6| Step: 11
Training loss: 3.622606473823036
Validation loss: 3.254937700338537

Epoch: 6| Step: 12
Training loss: 3.8355117219704282
Validation loss: 3.2547734373257833

Epoch: 6| Step: 13
Training loss: 2.619741076568075
Validation loss: 3.2520244168443337

Epoch: 16| Step: 0
Training loss: 3.341143867014393
Validation loss: 3.254995910932808

Epoch: 6| Step: 1
Training loss: 4.39580949291737
Validation loss: 3.258849851446869

Epoch: 6| Step: 2
Training loss: 4.019563991758048
Validation loss: 3.2563468402395084

Epoch: 6| Step: 3
Training loss: 2.406424875221379
Validation loss: 3.250504400143854

Epoch: 6| Step: 4
Training loss: 3.4736302043056697
Validation loss: 3.2525983131042255

Epoch: 6| Step: 5
Training loss: 4.272271089532027
Validation loss: 3.244533413913955

Epoch: 6| Step: 6
Training loss: 3.103779728132949
Validation loss: 3.243918480134103

Epoch: 6| Step: 7
Training loss: 3.3105869167010593
Validation loss: 3.246122876282156

Epoch: 6| Step: 8
Training loss: 3.57022141355021
Validation loss: 3.2532950421377436

Epoch: 6| Step: 9
Training loss: 3.4947844200608706
Validation loss: 3.255354415404976

Epoch: 6| Step: 10
Training loss: 3.407684304171167
Validation loss: 3.234837315163208

Epoch: 6| Step: 11
Training loss: 2.9475121821571566
Validation loss: 3.2191440394049167

Epoch: 6| Step: 12
Training loss: 3.0971349828395778
Validation loss: 3.2206673578822347

Epoch: 6| Step: 13
Training loss: 3.7403211937133305
Validation loss: 3.2186429294356373

Epoch: 17| Step: 0
Training loss: 3.3897407187272823
Validation loss: 3.218402224504714

Epoch: 6| Step: 1
Training loss: 4.183441928705311
Validation loss: 3.2244360854043146

Epoch: 6| Step: 2
Training loss: 2.5151977176189986
Validation loss: 3.2259264474515597

Epoch: 6| Step: 3
Training loss: 2.915270843748009
Validation loss: 3.2283032001518843

Epoch: 6| Step: 4
Training loss: 3.9127212023131994
Validation loss: 3.2599791028382037

Epoch: 6| Step: 5
Training loss: 3.916750048027153
Validation loss: 3.1982373026798245

Epoch: 6| Step: 6
Training loss: 3.6678830787801906
Validation loss: 3.2071633514251885

Epoch: 6| Step: 7
Training loss: 3.7455137756526162
Validation loss: 3.2049600222582892

Epoch: 6| Step: 8
Training loss: 3.589256329880455
Validation loss: 3.2011244406335306

Epoch: 6| Step: 9
Training loss: 2.597968657788347
Validation loss: 3.1866226339994403

Epoch: 6| Step: 10
Training loss: 3.8522676205466957
Validation loss: 3.184197073204555

Epoch: 6| Step: 11
Training loss: 3.0893781192986824
Validation loss: 3.183564148274625

Epoch: 6| Step: 12
Training loss: 3.7966219342828227
Validation loss: 3.189211068250893

Epoch: 6| Step: 13
Training loss: 2.334916622135407
Validation loss: 3.202119567727142

Epoch: 18| Step: 0
Training loss: 3.725534485227933
Validation loss: 3.2079484751628073

Epoch: 6| Step: 1
Training loss: 3.102796486851556
Validation loss: 3.1715132784239963

Epoch: 6| Step: 2
Training loss: 4.096011403514962
Validation loss: 3.1642491406998654

Epoch: 6| Step: 3
Training loss: 3.4477682552301077
Validation loss: 3.163290410325406

Epoch: 6| Step: 4
Training loss: 3.605138761519053
Validation loss: 3.166381553245381

Epoch: 6| Step: 5
Training loss: 4.061140566566985
Validation loss: 3.169147808820907

Epoch: 6| Step: 6
Training loss: 2.269257047966063
Validation loss: 3.164192781813407

Epoch: 6| Step: 7
Training loss: 2.6581966671945803
Validation loss: 3.1643419918866518

Epoch: 6| Step: 8
Training loss: 3.6880929761077117
Validation loss: 3.1541011549316265

Epoch: 6| Step: 9
Training loss: 3.1524142383886526
Validation loss: 3.1491126283187065

Epoch: 6| Step: 10
Training loss: 3.590818984565977
Validation loss: 3.1524058393288357

Epoch: 6| Step: 11
Training loss: 2.8914274184517095
Validation loss: 3.1606912814437904

Epoch: 6| Step: 12
Training loss: 3.8031462694637495
Validation loss: 3.1501547351392802

Epoch: 6| Step: 13
Training loss: 3.416673024489527
Validation loss: 3.1493642514763547

Epoch: 19| Step: 0
Training loss: 3.4451918115908065
Validation loss: 3.1429626192511684

Epoch: 6| Step: 1
Training loss: 3.44544674704793
Validation loss: 3.1413102867286935

Epoch: 6| Step: 2
Training loss: 3.0241094429052096
Validation loss: 3.1444539957372384

Epoch: 6| Step: 3
Training loss: 3.0541393832193298
Validation loss: 3.1471411590128024

Epoch: 6| Step: 4
Training loss: 2.7129823739210055
Validation loss: 3.1468500945649516

Epoch: 6| Step: 5
Training loss: 3.0020614534984214
Validation loss: 3.1443035549017466

Epoch: 6| Step: 6
Training loss: 3.465552153307597
Validation loss: 3.1417524884906514

Epoch: 6| Step: 7
Training loss: 3.5229739541859457
Validation loss: 3.140858587187001

Epoch: 6| Step: 8
Training loss: 3.7954079890419807
Validation loss: 3.143157155330039

Epoch: 6| Step: 9
Training loss: 3.4566066675181113
Validation loss: 3.1439956701155407

Epoch: 6| Step: 10
Training loss: 3.126626316317191
Validation loss: 3.1366180602773586

Epoch: 6| Step: 11
Training loss: 2.991308655918942
Validation loss: 3.133472871280624

Epoch: 6| Step: 12
Training loss: 4.811886042284828
Validation loss: 3.1340262103379244

Epoch: 6| Step: 13
Training loss: 3.421171351160515
Validation loss: 3.1307838730785167

Epoch: 20| Step: 0
Training loss: 3.4108286191483823
Validation loss: 3.1292716513953858

Epoch: 6| Step: 1
Training loss: 3.221013726779286
Validation loss: 3.122833779279847

Epoch: 6| Step: 2
Training loss: 3.1221495789221985
Validation loss: 3.124490032629076

Epoch: 6| Step: 3
Training loss: 3.5345853734500503
Validation loss: 3.1207503236457868

Epoch: 6| Step: 4
Training loss: 3.7849153770753046
Validation loss: 3.1212611681459737

Epoch: 6| Step: 5
Training loss: 3.5200430681021424
Validation loss: 3.1203198652504907

Epoch: 6| Step: 6
Training loss: 3.255546385441502
Validation loss: 3.117234477981567

Epoch: 6| Step: 7
Training loss: 4.214997155311864
Validation loss: 3.1151324641462943

Epoch: 6| Step: 8
Training loss: 2.9610400823774405
Validation loss: 3.1085776068571946

Epoch: 6| Step: 9
Training loss: 3.4883471372731916
Validation loss: 3.1095323486222632

Epoch: 6| Step: 10
Training loss: 3.685502497290124
Validation loss: 3.1055388081746633

Epoch: 6| Step: 11
Training loss: 3.0874353564209445
Validation loss: 3.1004380067871957

Epoch: 6| Step: 12
Training loss: 2.7876448247262853
Validation loss: 3.1016947028256054

Epoch: 6| Step: 13
Training loss: 2.8700771478259353
Validation loss: 3.115146726895841

Epoch: 21| Step: 0
Training loss: 2.8228013318889387
Validation loss: 3.1766414814524744

Epoch: 6| Step: 1
Training loss: 4.043237413703199
Validation loss: 3.1941130223804084

Epoch: 6| Step: 2
Training loss: 2.383264217397126
Validation loss: 3.1866819750390283

Epoch: 6| Step: 3
Training loss: 2.9509123732904823
Validation loss: 3.184435551024097

Epoch: 6| Step: 4
Training loss: 3.49799384796317
Validation loss: 3.1781143223628545

Epoch: 6| Step: 5
Training loss: 2.760057092435484
Validation loss: 3.1727862259283333

Epoch: 6| Step: 6
Training loss: 4.531602727381185
Validation loss: 3.1682306895054193

Epoch: 6| Step: 7
Training loss: 3.8121033759255107
Validation loss: 3.164723231173423

Epoch: 6| Step: 8
Training loss: 3.4473010355830023
Validation loss: 3.1605358576460993

Epoch: 6| Step: 9
Training loss: 3.578974327334268
Validation loss: 3.1605326658041304

Epoch: 6| Step: 10
Training loss: 3.416825283059351
Validation loss: 3.159305501547766

Epoch: 6| Step: 11
Training loss: 3.601112056210114
Validation loss: 3.159758043061724

Epoch: 6| Step: 12
Training loss: 3.088859623222243
Validation loss: 3.1557085946994787

Epoch: 6| Step: 13
Training loss: 3.5335518415531078
Validation loss: 3.1583086397307056

Epoch: 22| Step: 0
Training loss: 3.4716636174469837
Validation loss: 3.1648264078372828

Epoch: 6| Step: 1
Training loss: 3.105730691095149
Validation loss: 3.153977173477898

Epoch: 6| Step: 2
Training loss: 2.721051349249305
Validation loss: 3.1449200818248575

Epoch: 6| Step: 3
Training loss: 3.556598929129905
Validation loss: 3.142650317106864

Epoch: 6| Step: 4
Training loss: 3.192085856772088
Validation loss: 3.1402400856414183

Epoch: 6| Step: 5
Training loss: 2.9870733874270647
Validation loss: 3.135879870492602

Epoch: 6| Step: 6
Training loss: 3.4464382140436256
Validation loss: 3.133928522981293

Epoch: 6| Step: 7
Training loss: 3.7788242093798843
Validation loss: 3.1316438514958405

Epoch: 6| Step: 8
Training loss: 3.08276404890374
Validation loss: 3.1294399132722805

Epoch: 6| Step: 9
Training loss: 3.3206048814281495
Validation loss: 3.1280593040217215

Epoch: 6| Step: 10
Training loss: 3.7533978644922263
Validation loss: 3.131156790935214

Epoch: 6| Step: 11
Training loss: 3.315475566922984
Validation loss: 3.1311886615102678

Epoch: 6| Step: 12
Training loss: 3.685484125020593
Validation loss: 3.1278904892258907

Epoch: 6| Step: 13
Training loss: 4.340812073775927
Validation loss: 3.129459512597347

Epoch: 23| Step: 0
Training loss: 2.6012885605292584
Validation loss: 3.13021980204237

Epoch: 6| Step: 1
Training loss: 3.3268719673895393
Validation loss: 3.1229295397705523

Epoch: 6| Step: 2
Training loss: 3.4272758329334634
Validation loss: 3.118621604841658

Epoch: 6| Step: 3
Training loss: 4.293002960651904
Validation loss: 3.114268094185271

Epoch: 6| Step: 4
Training loss: 2.8140861277247593
Validation loss: 3.1180909121122915

Epoch: 6| Step: 5
Training loss: 4.263114889323335
Validation loss: 3.1129721235900796

Epoch: 6| Step: 6
Training loss: 3.1209435647630728
Validation loss: 3.080799583830182

Epoch: 6| Step: 7
Training loss: 3.0540902024533723
Validation loss: 3.044638981903831

Epoch: 6| Step: 8
Training loss: 3.481082198586444
Validation loss: 3.0447391938614623

Epoch: 6| Step: 9
Training loss: 3.4204877715252557
Validation loss: 3.054805026041014

Epoch: 6| Step: 10
Training loss: 3.1526542803700575
Validation loss: 3.043265772084884

Epoch: 6| Step: 11
Training loss: 2.924266142770675
Validation loss: 3.044841799587242

Epoch: 6| Step: 12
Training loss: 3.094588657338788
Validation loss: 3.0473873426012057

Epoch: 6| Step: 13
Training loss: 3.785345208615546
Validation loss: 3.046344873562222

Epoch: 24| Step: 0
Training loss: 3.7551145643289434
Validation loss: 3.0445974078263487

Epoch: 6| Step: 1
Training loss: 2.3707003573472063
Validation loss: 3.041903983947096

Epoch: 6| Step: 2
Training loss: 2.9447103436286453
Validation loss: 3.045291922061413

Epoch: 6| Step: 3
Training loss: 2.9138643335455896
Validation loss: 3.0555186520831126

Epoch: 6| Step: 4
Training loss: 2.802382177892887
Validation loss: 3.0546683449416436

Epoch: 6| Step: 5
Training loss: 3.5624172803410414
Validation loss: 3.048214035348818

Epoch: 6| Step: 6
Training loss: 3.3518032174263466
Validation loss: 3.0378606220540747

Epoch: 6| Step: 7
Training loss: 3.7319603938610677
Validation loss: 3.028598167988088

Epoch: 6| Step: 8
Training loss: 3.8366770604376996
Validation loss: 3.024442336537734

Epoch: 6| Step: 9
Training loss: 2.8150817042091854
Validation loss: 3.0248902408325584

Epoch: 6| Step: 10
Training loss: 3.785447746209453
Validation loss: 3.0220642931176194

Epoch: 6| Step: 11
Training loss: 3.1379769012203984
Validation loss: 3.0230618724435057

Epoch: 6| Step: 12
Training loss: 3.727838773523705
Validation loss: 3.0205694018953193

Epoch: 6| Step: 13
Training loss: 3.099843507323791
Validation loss: 3.021347097824463

Epoch: 25| Step: 0
Training loss: 2.4935344057893456
Validation loss: 3.017843549246664

Epoch: 6| Step: 1
Training loss: 3.540675723999521
Validation loss: 3.016023045434048

Epoch: 6| Step: 2
Training loss: 3.226190060602274
Validation loss: 3.0168524005145168

Epoch: 6| Step: 3
Training loss: 3.0811085449928295
Validation loss: 3.0147619868465148

Epoch: 6| Step: 4
Training loss: 2.9032705477886878
Validation loss: 3.014014491840654

Epoch: 6| Step: 5
Training loss: 3.650763413532424
Validation loss: 3.012516017975566

Epoch: 6| Step: 6
Training loss: 3.561893076813145
Validation loss: 3.019668292206977

Epoch: 6| Step: 7
Training loss: 3.5558334347963525
Validation loss: 3.0105714505188543

Epoch: 6| Step: 8
Training loss: 2.9155287748201353
Validation loss: 3.0118480282376727

Epoch: 6| Step: 9
Training loss: 3.7121553049073075
Validation loss: 3.01757131654687

Epoch: 6| Step: 10
Training loss: 3.3106111143288004
Validation loss: 3.01028857657826

Epoch: 6| Step: 11
Training loss: 3.620059889408637
Validation loss: 3.0070731601162404

Epoch: 6| Step: 12
Training loss: 3.4123748868147623
Validation loss: 3.0047199862443863

Epoch: 6| Step: 13
Training loss: 2.5654732737125805
Validation loss: 3.0038779482341744

Epoch: 26| Step: 0
Training loss: 3.2796202472335807
Validation loss: 3.0051300237105165

Epoch: 6| Step: 1
Training loss: 3.1310043634550575
Validation loss: 3.0065799569495972

Epoch: 6| Step: 2
Training loss: 3.626251793814593
Validation loss: 3.014566779807504

Epoch: 6| Step: 3
Training loss: 2.842138483548606
Validation loss: 3.008815975251038

Epoch: 6| Step: 4
Training loss: 2.7399376663023136
Validation loss: 3.004450156735392

Epoch: 6| Step: 5
Training loss: 4.340963004720221
Validation loss: 3.0017834048837897

Epoch: 6| Step: 6
Training loss: 3.36105687821897
Validation loss: 2.996330526006873

Epoch: 6| Step: 7
Training loss: 3.065718847115721
Validation loss: 2.996396732804242

Epoch: 6| Step: 8
Training loss: 3.62243917052149
Validation loss: 2.995534655984981

Epoch: 6| Step: 9
Training loss: 2.9619937512462573
Validation loss: 2.9959569472154604

Epoch: 6| Step: 10
Training loss: 3.1047245693441563
Validation loss: 2.998545066552788

Epoch: 6| Step: 11
Training loss: 3.382202657302409
Validation loss: 2.9972742235504857

Epoch: 6| Step: 12
Training loss: 2.6591761908086173
Validation loss: 2.9987333573652712

Epoch: 6| Step: 13
Training loss: 3.750583348995683
Validation loss: 3.004260015790289

Epoch: 27| Step: 0
Training loss: 3.1418610982319852
Validation loss: 2.9986113116591264

Epoch: 6| Step: 1
Training loss: 3.0334335799647265
Validation loss: 2.9907469324194405

Epoch: 6| Step: 2
Training loss: 3.7501368179793726
Validation loss: 2.987944935900026

Epoch: 6| Step: 3
Training loss: 3.698698077673764
Validation loss: 2.9871632323062185

Epoch: 6| Step: 4
Training loss: 2.9093578497916908
Validation loss: 2.9872083742914537

Epoch: 6| Step: 5
Training loss: 3.0472383722622842
Validation loss: 2.9895570315152704

Epoch: 6| Step: 6
Training loss: 3.6101691623267786
Validation loss: 2.9912817090668447

Epoch: 6| Step: 7
Training loss: 3.4412244560382774
Validation loss: 2.997878048855639

Epoch: 6| Step: 8
Training loss: 3.149496274363023
Validation loss: 2.985562739793033

Epoch: 6| Step: 9
Training loss: 3.2667875274046434
Validation loss: 2.9832337855123305

Epoch: 6| Step: 10
Training loss: 2.4760144707375518
Validation loss: 2.9820227067061875

Epoch: 6| Step: 11
Training loss: 3.0468751565003966
Validation loss: 2.982814781928827

Epoch: 6| Step: 12
Training loss: 3.4835058933086103
Validation loss: 2.9836198233242164

Epoch: 6| Step: 13
Training loss: 3.7105013621175735
Validation loss: 2.982163991379257

Epoch: 28| Step: 0
Training loss: 2.798159086093506
Validation loss: 2.9809476601809775

Epoch: 6| Step: 1
Training loss: 3.0595548832099784
Validation loss: 2.979334657767234

Epoch: 6| Step: 2
Training loss: 3.427787097840611
Validation loss: 2.97934538872178

Epoch: 6| Step: 3
Training loss: 2.8801212309117363
Validation loss: 2.9769727920282656

Epoch: 6| Step: 4
Training loss: 3.134695348219259
Validation loss: 2.9756831102076426

Epoch: 6| Step: 5
Training loss: 4.17922566081606
Validation loss: 2.9760713653051423

Epoch: 6| Step: 6
Training loss: 3.1845503978697316
Validation loss: 2.975312916117087

Epoch: 6| Step: 7
Training loss: 3.6836123905944045
Validation loss: 2.9743135091946415

Epoch: 6| Step: 8
Training loss: 3.669496585713893
Validation loss: 2.9715765027164283

Epoch: 6| Step: 9
Training loss: 3.662441521395808
Validation loss: 2.9725579356597462

Epoch: 6| Step: 10
Training loss: 3.110030368767051
Validation loss: 2.9722555330076337

Epoch: 6| Step: 11
Training loss: 2.6809511458297193
Validation loss: 2.971720899677656

Epoch: 6| Step: 12
Training loss: 2.511724730109279
Validation loss: 2.9712606706192584

Epoch: 6| Step: 13
Training loss: 3.232045979843157
Validation loss: 2.9700865849300504

Epoch: 29| Step: 0
Training loss: 2.916410998083297
Validation loss: 2.974012674619245

Epoch: 6| Step: 1
Training loss: 3.1209207995338315
Validation loss: 2.979809193875217

Epoch: 6| Step: 2
Training loss: 3.4096710104548404
Validation loss: 2.975496914799803

Epoch: 6| Step: 3
Training loss: 3.7766993859656246
Validation loss: 2.967084765402505

Epoch: 6| Step: 4
Training loss: 2.866975781682061
Validation loss: 2.969722315266903

Epoch: 6| Step: 5
Training loss: 3.268920987326968
Validation loss: 2.978717942839783

Epoch: 6| Step: 6
Training loss: 4.006093390821218
Validation loss: 3.005297200439852

Epoch: 6| Step: 7
Training loss: 3.444429383877332
Validation loss: 2.9699010416999427

Epoch: 6| Step: 8
Training loss: 3.158587355115419
Validation loss: 2.9703664855164567

Epoch: 6| Step: 9
Training loss: 2.9800137113729366
Validation loss: 2.973768533606332

Epoch: 6| Step: 10
Training loss: 2.4367572924472642
Validation loss: 3.0047450225731436

Epoch: 6| Step: 11
Training loss: 3.3881361304253192
Validation loss: 3.066818570962166

Epoch: 6| Step: 12
Training loss: 2.931901669808901
Validation loss: 3.080333875994872

Epoch: 6| Step: 13
Training loss: 4.086009387811677
Validation loss: 3.0274956824436834

Epoch: 30| Step: 0
Training loss: 3.1843835892341534
Validation loss: 2.9796439314254197

Epoch: 6| Step: 1
Training loss: 3.0511574409445266
Validation loss: 2.971697811715101

Epoch: 6| Step: 2
Training loss: 3.0678492947085823
Validation loss: 2.9757946909125645

Epoch: 6| Step: 3
Training loss: 2.961123820459106
Validation loss: 2.974630181495228

Epoch: 6| Step: 4
Training loss: 2.105349846987538
Validation loss: 2.970001450880065

Epoch: 6| Step: 5
Training loss: 3.1996293508925784
Validation loss: 2.970404198941465

Epoch: 6| Step: 6
Training loss: 3.921762776383977
Validation loss: 2.9675394056443993

Epoch: 6| Step: 7
Training loss: 3.418366048337961
Validation loss: 2.9727083070397984

Epoch: 6| Step: 8
Training loss: 3.7199430715655417
Validation loss: 2.960930821918305

Epoch: 6| Step: 9
Training loss: 3.4353095271374325
Validation loss: 2.975450981677236

Epoch: 6| Step: 10
Training loss: 3.2882846084544948
Validation loss: 3.0028323574985443

Epoch: 6| Step: 11
Training loss: 3.160264587431445
Validation loss: 3.0006059150936317

Epoch: 6| Step: 12
Training loss: 3.354550325869914
Validation loss: 2.9575302689781493

Epoch: 6| Step: 13
Training loss: 3.661314497067351
Validation loss: 2.958419598077475

Epoch: 31| Step: 0
Training loss: 2.674052104388099
Validation loss: 2.964648011150132

Epoch: 6| Step: 1
Training loss: 2.679520404377086
Validation loss: 2.964767073523206

Epoch: 6| Step: 2
Training loss: 3.0306120525641305
Validation loss: 2.9662478478205507

Epoch: 6| Step: 3
Training loss: 2.7260800347393404
Validation loss: 2.973041688331247

Epoch: 6| Step: 4
Training loss: 3.9535970896007364
Validation loss: 2.966602338314907

Epoch: 6| Step: 5
Training loss: 3.1915045621523492
Validation loss: 2.9655621954752394

Epoch: 6| Step: 6
Training loss: 3.7539000258061694
Validation loss: 2.959973760175096

Epoch: 6| Step: 7
Training loss: 3.1288110001790312
Validation loss: 2.960274130929754

Epoch: 6| Step: 8
Training loss: 3.2564798460690656
Validation loss: 2.9569766948989136

Epoch: 6| Step: 9
Training loss: 3.4897889641295152
Validation loss: 2.9652038240565135

Epoch: 6| Step: 10
Training loss: 3.672213794418362
Validation loss: 2.9706513167453603

Epoch: 6| Step: 11
Training loss: 3.479622238088469
Validation loss: 2.9664086945786745

Epoch: 6| Step: 12
Training loss: 3.081773793112347
Validation loss: 2.963805018371669

Epoch: 6| Step: 13
Training loss: 3.0664900652856524
Validation loss: 2.9534532076292175

Epoch: 32| Step: 0
Training loss: 3.522991414389109
Validation loss: 2.949887857240071

Epoch: 6| Step: 1
Training loss: 3.1617328120343795
Validation loss: 2.946454332073312

Epoch: 6| Step: 2
Training loss: 3.6523692084256436
Validation loss: 2.9425192135213107

Epoch: 6| Step: 3
Training loss: 3.370360824104114
Validation loss: 2.9391365650211085

Epoch: 6| Step: 4
Training loss: 3.538192675815415
Validation loss: 2.9370139441409586

Epoch: 6| Step: 5
Training loss: 3.02931859729881
Validation loss: 2.935705800779712

Epoch: 6| Step: 6
Training loss: 3.2197969085904097
Validation loss: 2.9335359380573234

Epoch: 6| Step: 7
Training loss: 3.0966790715664794
Validation loss: 2.932035468452398

Epoch: 6| Step: 8
Training loss: 2.9472607713056456
Validation loss: 2.9309876392389196

Epoch: 6| Step: 9
Training loss: 2.6877106872300693
Validation loss: 2.92991372824458

Epoch: 6| Step: 10
Training loss: 2.6536854649592585
Validation loss: 2.9303643677586138

Epoch: 6| Step: 11
Training loss: 2.9231386766976293
Validation loss: 2.930633758754446

Epoch: 6| Step: 12
Training loss: 3.752423075803065
Validation loss: 2.930116698406986

Epoch: 6| Step: 13
Training loss: 3.613617620534038
Validation loss: 2.9310100507673704

Epoch: 33| Step: 0
Training loss: 2.935379886509581
Validation loss: 2.9326930838578456

Epoch: 6| Step: 1
Training loss: 3.235267405476172
Validation loss: 2.9313628564729766

Epoch: 6| Step: 2
Training loss: 3.2019682493523947
Validation loss: 2.9309171095488264

Epoch: 6| Step: 3
Training loss: 3.249069520825873
Validation loss: 2.9325390022581757

Epoch: 6| Step: 4
Training loss: 3.853430861610521
Validation loss: 2.931715473688315

Epoch: 6| Step: 5
Training loss: 3.5878943462487505
Validation loss: 2.9386832691073743

Epoch: 6| Step: 6
Training loss: 2.939578193715931
Validation loss: 2.9348889573999712

Epoch: 6| Step: 7
Training loss: 3.2709230220347068
Validation loss: 2.9376526092355744

Epoch: 6| Step: 8
Training loss: 3.2510975671664104
Validation loss: 2.9323578482471757

Epoch: 6| Step: 9
Training loss: 2.8636054757063873
Validation loss: 2.9288072801940963

Epoch: 6| Step: 10
Training loss: 3.32632039175916
Validation loss: 2.926378717892198

Epoch: 6| Step: 11
Training loss: 3.399897399925046
Validation loss: 2.9257748220114546

Epoch: 6| Step: 12
Training loss: 2.4562177660819295
Validation loss: 2.9238136453300347

Epoch: 6| Step: 13
Training loss: 3.258217912143492
Validation loss: 2.919345657859049

Epoch: 34| Step: 0
Training loss: 2.7252521153284244
Validation loss: 2.9235199259566067

Epoch: 6| Step: 1
Training loss: 3.069294146678987
Validation loss: 2.919232981256406

Epoch: 6| Step: 2
Training loss: 3.0440606054721706
Validation loss: 2.919267031111043

Epoch: 6| Step: 3
Training loss: 3.8214089784005316
Validation loss: 2.918066982168633

Epoch: 6| Step: 4
Training loss: 2.826268972799671
Validation loss: 2.9201701789967145

Epoch: 6| Step: 5
Training loss: 3.011315621832423
Validation loss: 2.9199645060125152

Epoch: 6| Step: 6
Training loss: 2.848602514462204
Validation loss: 2.918166559544828

Epoch: 6| Step: 7
Training loss: 4.066011525105412
Validation loss: 2.9170644450796037

Epoch: 6| Step: 8
Training loss: 1.9369637762492382
Validation loss: 2.9169064741096515

Epoch: 6| Step: 9
Training loss: 2.89930897076089
Validation loss: 2.913368333983282

Epoch: 6| Step: 10
Training loss: 3.8186187421901083
Validation loss: 2.9157353902345777

Epoch: 6| Step: 11
Training loss: 3.252520537491156
Validation loss: 2.913139160249122

Epoch: 6| Step: 12
Training loss: 3.3240293993516223
Validation loss: 2.915909454098891

Epoch: 6| Step: 13
Training loss: 3.989410330239297
Validation loss: 2.922750495731197

Epoch: 35| Step: 0
Training loss: 2.7098715497645167
Validation loss: 2.9224116028027534

Epoch: 6| Step: 1
Training loss: 3.4347412136272863
Validation loss: 2.9335194281402144

Epoch: 6| Step: 2
Training loss: 2.9445221748728385
Validation loss: 2.9395861246893404

Epoch: 6| Step: 3
Training loss: 3.044356650303247
Validation loss: 2.94022828287402

Epoch: 6| Step: 4
Training loss: 2.826615663179259
Validation loss: 2.9277541512572647

Epoch: 6| Step: 5
Training loss: 3.2972239811317774
Validation loss: 2.9168758534129147

Epoch: 6| Step: 6
Training loss: 3.0788294571827155
Validation loss: 2.910255606508483

Epoch: 6| Step: 7
Training loss: 3.4399119844931456
Validation loss: 2.908040848418199

Epoch: 6| Step: 8
Training loss: 2.5182019415997514
Validation loss: 2.9090821801290736

Epoch: 6| Step: 9
Training loss: 3.5196385510141743
Validation loss: 2.9076550796761937

Epoch: 6| Step: 10
Training loss: 3.6063182487178187
Validation loss: 2.9089763854116284

Epoch: 6| Step: 11
Training loss: 3.4994258409674384
Validation loss: 2.9072739350652883

Epoch: 6| Step: 12
Training loss: 3.177514535794149
Validation loss: 2.906459275516536

Epoch: 6| Step: 13
Training loss: 3.828295022730993
Validation loss: 2.907364519433436

Epoch: 36| Step: 0
Training loss: 3.627916281099052
Validation loss: 2.9059059238423712

Epoch: 6| Step: 1
Training loss: 3.49491785828818
Validation loss: 2.905125774885539

Epoch: 6| Step: 2
Training loss: 3.3587569266994253
Validation loss: 2.902839654162677

Epoch: 6| Step: 3
Training loss: 3.037679244667127
Validation loss: 2.902975445780085

Epoch: 6| Step: 4
Training loss: 3.1903196840731294
Validation loss: 2.904312315254466

Epoch: 6| Step: 5
Training loss: 2.847064256292008
Validation loss: 2.911517993656869

Epoch: 6| Step: 6
Training loss: 3.3037220511840113
Validation loss: 2.910091945006275

Epoch: 6| Step: 7
Training loss: 3.2615070571273344
Validation loss: 2.9178019908377544

Epoch: 6| Step: 8
Training loss: 3.716286107467528
Validation loss: 2.91913737643621

Epoch: 6| Step: 9
Training loss: 3.287752810428495
Validation loss: 2.9045134618217765

Epoch: 6| Step: 10
Training loss: 2.7636574680775103
Validation loss: 2.8988852688364983

Epoch: 6| Step: 11
Training loss: 3.1225761168512425
Validation loss: 2.898503820113148

Epoch: 6| Step: 12
Training loss: 2.2327952101981037
Validation loss: 2.8971548233774094

Epoch: 6| Step: 13
Training loss: 3.1492797633671894
Validation loss: 2.895934379291957

Epoch: 37| Step: 0
Training loss: 3.0454285929802074
Validation loss: 2.897536554092963

Epoch: 6| Step: 1
Training loss: 3.7820822060061414
Validation loss: 2.902004800878546

Epoch: 6| Step: 2
Training loss: 2.7483985746315294
Validation loss: 2.8988918837964905

Epoch: 6| Step: 3
Training loss: 3.2500752660398984
Validation loss: 2.897657391087903

Epoch: 6| Step: 4
Training loss: 3.120139041639035
Validation loss: 2.897350841152971

Epoch: 6| Step: 5
Training loss: 2.5474514923119482
Validation loss: 2.8940574534226196

Epoch: 6| Step: 6
Training loss: 3.2205408540079077
Validation loss: 2.8938167157780565

Epoch: 6| Step: 7
Training loss: 3.0979810354441617
Validation loss: 2.8938398554694236

Epoch: 6| Step: 8
Training loss: 3.163313110522744
Validation loss: 2.8940090247343617

Epoch: 6| Step: 9
Training loss: 3.338354588512517
Validation loss: 2.8926048959176205

Epoch: 6| Step: 10
Training loss: 3.4758021519744777
Validation loss: 2.893059170524701

Epoch: 6| Step: 11
Training loss: 3.304562541502013
Validation loss: 2.891616879042533

Epoch: 6| Step: 12
Training loss: 2.414182197047686
Validation loss: 2.892553651098541

Epoch: 6| Step: 13
Training loss: 4.258147788189082
Validation loss: 2.891836248847867

Epoch: 38| Step: 0
Training loss: 3.2827551886209805
Validation loss: 2.891992238418366

Epoch: 6| Step: 1
Training loss: 2.897425060866528
Validation loss: 2.8913758583957647

Epoch: 6| Step: 2
Training loss: 3.998750372240026
Validation loss: 2.8903647507679113

Epoch: 6| Step: 3
Training loss: 3.065876870108455
Validation loss: 2.8888319561141387

Epoch: 6| Step: 4
Training loss: 3.195393978656311
Validation loss: 2.8882849412096703

Epoch: 6| Step: 5
Training loss: 3.2375387299920044
Validation loss: 2.887056696621577

Epoch: 6| Step: 6
Training loss: 3.596646675664752
Validation loss: 2.8837907124527375

Epoch: 6| Step: 7
Training loss: 3.2617102708535
Validation loss: 2.8831056893235028

Epoch: 6| Step: 8
Training loss: 3.09487278148381
Validation loss: 2.882235649654975

Epoch: 6| Step: 9
Training loss: 2.1252323472398587
Validation loss: 2.8820157198726757

Epoch: 6| Step: 10
Training loss: 3.1018173920175975
Validation loss: 2.8814883677807654

Epoch: 6| Step: 11
Training loss: 3.198945384287652
Validation loss: 2.8807404319662804

Epoch: 6| Step: 12
Training loss: 2.9093281841506404
Validation loss: 2.8794761186420486

Epoch: 6| Step: 13
Training loss: 3.2413289231689193
Validation loss: 2.8780921128488304

Epoch: 39| Step: 0
Training loss: 3.41186145215857
Validation loss: 2.8793647416491024

Epoch: 6| Step: 1
Training loss: 3.3617495638893238
Validation loss: 2.8800508717603845

Epoch: 6| Step: 2
Training loss: 2.757604920785319
Validation loss: 2.8783849929773915

Epoch: 6| Step: 3
Training loss: 2.9539186733159144
Validation loss: 2.8771052096344123

Epoch: 6| Step: 4
Training loss: 3.2120810743957273
Validation loss: 2.8747891602465123

Epoch: 6| Step: 5
Training loss: 3.3843981966613286
Validation loss: 2.8773868242440246

Epoch: 6| Step: 6
Training loss: 3.1340274880572503
Validation loss: 2.8735985730966216

Epoch: 6| Step: 7
Training loss: 3.9965994208254085
Validation loss: 2.8747901822107265

Epoch: 6| Step: 8
Training loss: 2.122608072789267
Validation loss: 2.873476160513559

Epoch: 6| Step: 9
Training loss: 3.2497573175055186
Validation loss: 2.872591034003542

Epoch: 6| Step: 10
Training loss: 3.2043855001248907
Validation loss: 2.8732166207374092

Epoch: 6| Step: 11
Training loss: 3.032685559312102
Validation loss: 2.869995977030107

Epoch: 6| Step: 12
Training loss: 3.019763695774938
Validation loss: 2.868643822106852

Epoch: 6| Step: 13
Training loss: 3.191819200448172
Validation loss: 2.8692756473127394

Epoch: 40| Step: 0
Training loss: 2.4624232091403555
Validation loss: 2.869686399846277

Epoch: 6| Step: 1
Training loss: 3.6152703825951966
Validation loss: 2.871293659406399

Epoch: 6| Step: 2
Training loss: 3.101024359997649
Validation loss: 2.8699829470777516

Epoch: 6| Step: 3
Training loss: 3.622749155978586
Validation loss: 2.8677919420230804

Epoch: 6| Step: 4
Training loss: 2.608050529903192
Validation loss: 2.865864080388128

Epoch: 6| Step: 5
Training loss: 3.372694853066226
Validation loss: 2.867166974260026

Epoch: 6| Step: 6
Training loss: 3.1644625940617956
Validation loss: 2.8668902629992363

Epoch: 6| Step: 7
Training loss: 3.2151807235303176
Validation loss: 2.8670062047791505

Epoch: 6| Step: 8
Training loss: 3.1153629479737064
Validation loss: 2.8694548255743135

Epoch: 6| Step: 9
Training loss: 3.696323377482724
Validation loss: 2.8706285280724613

Epoch: 6| Step: 10
Training loss: 3.033189605270095
Validation loss: 2.8696561445281006

Epoch: 6| Step: 11
Training loss: 2.9300110498421787
Validation loss: 2.8682512146086707

Epoch: 6| Step: 12
Training loss: 2.67191524363767
Validation loss: 2.866021214308924

Epoch: 6| Step: 13
Training loss: 3.6601192509135823
Validation loss: 2.865455884449131

Epoch: 41| Step: 0
Training loss: 3.428153909510908
Validation loss: 2.8658573095789244

Epoch: 6| Step: 1
Training loss: 2.817571517997938
Validation loss: 2.8650559886542823

Epoch: 6| Step: 2
Training loss: 3.0871369553842
Validation loss: 2.8636119805800018

Epoch: 6| Step: 3
Training loss: 3.0218624773525433
Validation loss: 2.8650040569082345

Epoch: 6| Step: 4
Training loss: 2.8233197101623144
Validation loss: 2.864606945727329

Epoch: 6| Step: 5
Training loss: 2.9407285438980058
Validation loss: 2.8625112837222315

Epoch: 6| Step: 6
Training loss: 3.135555141766463
Validation loss: 2.861597544149993

Epoch: 6| Step: 7
Training loss: 3.602845995539932
Validation loss: 2.860319508203378

Epoch: 6| Step: 8
Training loss: 2.8227434750364044
Validation loss: 2.8618394674137586

Epoch: 6| Step: 9
Training loss: 4.010151141735861
Validation loss: 2.861180866308525

Epoch: 6| Step: 10
Training loss: 3.1906686628531773
Validation loss: 2.8659223494773203

Epoch: 6| Step: 11
Training loss: 2.879395152262206
Validation loss: 2.862009775747007

Epoch: 6| Step: 12
Training loss: 2.7360677656515207
Validation loss: 2.858059402999345

Epoch: 6| Step: 13
Training loss: 3.8153299553448656
Validation loss: 2.8562140424395714

Epoch: 42| Step: 0
Training loss: 3.0827377534554556
Validation loss: 2.8540911381944287

Epoch: 6| Step: 1
Training loss: 3.6471547520415633
Validation loss: 2.854604008665578

Epoch: 6| Step: 2
Training loss: 3.546979054004393
Validation loss: 2.8519664155248052

Epoch: 6| Step: 3
Training loss: 3.3460293425409495
Validation loss: 2.8511361210593056

Epoch: 6| Step: 4
Training loss: 3.0287229091363157
Validation loss: 2.8495703993552057

Epoch: 6| Step: 5
Training loss: 3.2020196263452227
Validation loss: 2.850426719626418

Epoch: 6| Step: 6
Training loss: 2.6602826193483895
Validation loss: 2.847317828088839

Epoch: 6| Step: 7
Training loss: 2.502928925453454
Validation loss: 2.849412580464604

Epoch: 6| Step: 8
Training loss: 3.459186188353174
Validation loss: 2.847245142061024

Epoch: 6| Step: 9
Training loss: 2.9363253253549413
Validation loss: 2.8461858140826966

Epoch: 6| Step: 10
Training loss: 2.739984828600683
Validation loss: 2.8469112494204243

Epoch: 6| Step: 11
Training loss: 3.719980757468713
Validation loss: 2.847536640296128

Epoch: 6| Step: 12
Training loss: 2.558249227609614
Validation loss: 2.860010385033354

Epoch: 6| Step: 13
Training loss: 3.3849239675527842
Validation loss: 2.875429491417835

Epoch: 43| Step: 0
Training loss: 3.8218105008163854
Validation loss: 2.8748246460913864

Epoch: 6| Step: 1
Training loss: 3.751752316821747
Validation loss: 2.849894462262032

Epoch: 6| Step: 2
Training loss: 2.7480664825282193
Validation loss: 2.840036754676511

Epoch: 6| Step: 3
Training loss: 2.7357139578864964
Validation loss: 2.8420749072868268

Epoch: 6| Step: 4
Training loss: 3.2004112098652957
Validation loss: 2.8464717512894526

Epoch: 6| Step: 5
Training loss: 2.899188579298518
Validation loss: 2.8552466058188264

Epoch: 6| Step: 6
Training loss: 3.5013551813225012
Validation loss: 2.860726147386343

Epoch: 6| Step: 7
Training loss: 3.634574872832528
Validation loss: 2.8485061419523126

Epoch: 6| Step: 8
Training loss: 3.0200509121373855
Validation loss: 2.842801825425525

Epoch: 6| Step: 9
Training loss: 3.03196031565601
Validation loss: 2.8416495009221907

Epoch: 6| Step: 10
Training loss: 2.953125
Validation loss: 2.839590433460175

Epoch: 6| Step: 11
Training loss: 2.6724194423713423
Validation loss: 2.8408920385123015

Epoch: 6| Step: 12
Training loss: 2.8135103742056717
Validation loss: 2.8463557026177093

Epoch: 6| Step: 13
Training loss: 2.8816085823990325
Validation loss: 2.8734880121281434

Epoch: 44| Step: 0
Training loss: 3.1628892018259736
Validation loss: 2.8929958422025153

Epoch: 6| Step: 1
Training loss: 4.051377314209311
Validation loss: 2.87818512006631

Epoch: 6| Step: 2
Training loss: 3.456552866794788
Validation loss: 2.8509912457784368

Epoch: 6| Step: 3
Training loss: 3.4662677027913684
Validation loss: 2.833566005232848

Epoch: 6| Step: 4
Training loss: 3.114927309023909
Validation loss: 2.833639776775813

Epoch: 6| Step: 5
Training loss: 2.895251721126597
Validation loss: 2.830829658463774

Epoch: 6| Step: 6
Training loss: 3.161764030613025
Validation loss: 2.8333564044970974

Epoch: 6| Step: 7
Training loss: 2.893879476002907
Validation loss: 2.83432734936303

Epoch: 6| Step: 8
Training loss: 3.213882914539156
Validation loss: 2.836243577711248

Epoch: 6| Step: 9
Training loss: 2.2963758691835183
Validation loss: 2.835781110162682

Epoch: 6| Step: 10
Training loss: 3.7341940608541826
Validation loss: 2.8409696435450704

Epoch: 6| Step: 11
Training loss: 2.677973696909268
Validation loss: 2.84981955162274

Epoch: 6| Step: 12
Training loss: 2.1375119482230707
Validation loss: 2.853174676882624

Epoch: 6| Step: 13
Training loss: 3.48210747669397
Validation loss: 2.8362366195889006

Epoch: 45| Step: 0
Training loss: 2.842272364108067
Validation loss: 2.8305426981257233

Epoch: 6| Step: 1
Training loss: 2.797061423796408
Validation loss: 2.8299241761777285

Epoch: 6| Step: 2
Training loss: 2.9414323499111794
Validation loss: 2.826417910747596

Epoch: 6| Step: 3
Training loss: 3.039004759252248
Validation loss: 2.824900563259887

Epoch: 6| Step: 4
Training loss: 3.4404769491413894
Validation loss: 2.82367801619848

Epoch: 6| Step: 5
Training loss: 2.9441594059848595
Validation loss: 2.8236237127745056

Epoch: 6| Step: 6
Training loss: 3.358693324279193
Validation loss: 2.8251126225809395

Epoch: 6| Step: 7
Training loss: 3.4757793787485833
Validation loss: 2.8220933723874038

Epoch: 6| Step: 8
Training loss: 2.7566360687654976
Validation loss: 2.8303124672527895

Epoch: 6| Step: 9
Training loss: 2.912704683241565
Validation loss: 2.8234324499247694

Epoch: 6| Step: 10
Training loss: 3.0280526198800124
Validation loss: 2.822113372048928

Epoch: 6| Step: 11
Training loss: 3.689831271565418
Validation loss: 2.8296949060516785

Epoch: 6| Step: 12
Training loss: 2.977111765728188
Validation loss: 2.8243540554704505

Epoch: 6| Step: 13
Training loss: 3.6814749682973136
Validation loss: 2.822702700705112

Epoch: 46| Step: 0
Training loss: 3.0979696454407466
Validation loss: 2.821236823989865

Epoch: 6| Step: 1
Training loss: 3.2147215290406326
Validation loss: 2.8240205791719037

Epoch: 6| Step: 2
Training loss: 3.3588165528745773
Validation loss: 2.8208365286592705

Epoch: 6| Step: 3
Training loss: 3.494598580421112
Validation loss: 2.8194307847615447

Epoch: 6| Step: 4
Training loss: 3.252934085106604
Validation loss: 2.8201590998439507

Epoch: 6| Step: 5
Training loss: 2.4465946821317286
Validation loss: 2.8181563210364673

Epoch: 6| Step: 6
Training loss: 3.503170757011882
Validation loss: 2.8178566787158856

Epoch: 6| Step: 7
Training loss: 3.4157769199939105
Validation loss: 2.81638813227734

Epoch: 6| Step: 8
Training loss: 2.91535164388784
Validation loss: 2.8197803569653734

Epoch: 6| Step: 9
Training loss: 2.556917762743763
Validation loss: 2.821060625470466

Epoch: 6| Step: 10
Training loss: 2.959621328154481
Validation loss: 2.823739895824715

Epoch: 6| Step: 11
Training loss: 3.3846131921641045
Validation loss: 2.814027174287292

Epoch: 6| Step: 12
Training loss: 2.960732002474813
Validation loss: 2.8146190112366223

Epoch: 6| Step: 13
Training loss: 2.9666044814489556
Validation loss: 2.816228807083392

Epoch: 47| Step: 0
Training loss: 3.2338908104897297
Validation loss: 2.8155584097573016

Epoch: 6| Step: 1
Training loss: 3.228798597134757
Validation loss: 2.8140579502638565

Epoch: 6| Step: 2
Training loss: 2.6344816536994897
Validation loss: 2.8160113438863004

Epoch: 6| Step: 3
Training loss: 2.3924563505362415
Validation loss: 2.8147586663121205

Epoch: 6| Step: 4
Training loss: 3.2458716361283693
Validation loss: 2.8135902697965647

Epoch: 6| Step: 5
Training loss: 3.56730114174751
Validation loss: 2.8107845183665674

Epoch: 6| Step: 6
Training loss: 2.9718127062633672
Validation loss: 2.8114658984076355

Epoch: 6| Step: 7
Training loss: 3.639647913452471
Validation loss: 2.808459336538463

Epoch: 6| Step: 8
Training loss: 2.6032047987632856
Validation loss: 2.8065014702907756

Epoch: 6| Step: 9
Training loss: 2.7520135963569823
Validation loss: 2.8070826834599996

Epoch: 6| Step: 10
Training loss: 3.4501235829208725
Validation loss: 2.812911393899396

Epoch: 6| Step: 11
Training loss: 3.2640413523747225
Validation loss: 2.8139747927684216

Epoch: 6| Step: 12
Training loss: 3.1453810781477687
Validation loss: 2.822801255600957

Epoch: 6| Step: 13
Training loss: 3.444791793400282
Validation loss: 2.825170728552131

Epoch: 48| Step: 0
Training loss: 3.109354450407126
Validation loss: 2.809421309961901

Epoch: 6| Step: 1
Training loss: 2.9060286570932448
Validation loss: 2.8059117466313275

Epoch: 6| Step: 2
Training loss: 3.5142856335390724
Validation loss: 2.8031856571869382

Epoch: 6| Step: 3
Training loss: 2.993534273088055
Validation loss: 2.804599036292861

Epoch: 6| Step: 4
Training loss: 3.07433523420319
Validation loss: 2.8043798430505085

Epoch: 6| Step: 5
Training loss: 2.119272704337297
Validation loss: 2.8036070142155864

Epoch: 6| Step: 6
Training loss: 2.439927579555455
Validation loss: 2.804368154627645

Epoch: 6| Step: 7
Training loss: 3.0612447852156097
Validation loss: 2.804022787556262

Epoch: 6| Step: 8
Training loss: 3.134646366500945
Validation loss: 2.8041263324790524

Epoch: 6| Step: 9
Training loss: 2.5559571637069896
Validation loss: 2.802450260709901

Epoch: 6| Step: 10
Training loss: 3.1696530531905376
Validation loss: 2.8012347604848515

Epoch: 6| Step: 11
Training loss: 4.220345202604923
Validation loss: 2.8014178541205226

Epoch: 6| Step: 12
Training loss: 3.6383323162902816
Validation loss: 2.799771945502577

Epoch: 6| Step: 13
Training loss: 3.156738243486562
Validation loss: 2.800721262254812

Epoch: 49| Step: 0
Training loss: 2.6811262444521677
Validation loss: 2.801806439449494

Epoch: 6| Step: 1
Training loss: 3.160184164595886
Validation loss: 2.8055056926912907

Epoch: 6| Step: 2
Training loss: 2.9979988417365524
Validation loss: 2.8042612233170066

Epoch: 6| Step: 3
Training loss: 3.048448048959035
Validation loss: 2.802600290650497

Epoch: 6| Step: 4
Training loss: 3.309319894996468
Validation loss: 2.799799446315571

Epoch: 6| Step: 5
Training loss: 3.355208967497579
Validation loss: 2.7970970195387777

Epoch: 6| Step: 6
Training loss: 3.1169080107023013
Validation loss: 2.79739971489888

Epoch: 6| Step: 7
Training loss: 3.7020782407698043
Validation loss: 2.795192575233183

Epoch: 6| Step: 8
Training loss: 3.2852337586538685
Validation loss: 2.7952613816125007

Epoch: 6| Step: 9
Training loss: 2.9943052919698343
Validation loss: 2.795193973902822

Epoch: 6| Step: 10
Training loss: 2.893100317905152
Validation loss: 2.7976479941606467

Epoch: 6| Step: 11
Training loss: 3.0345851208647825
Validation loss: 2.794353223371454

Epoch: 6| Step: 12
Training loss: 3.191866557847917
Validation loss: 2.793470477345627

Epoch: 6| Step: 13
Training loss: 2.2622493457521338
Validation loss: 2.7910997760730565

Epoch: 50| Step: 0
Training loss: 3.402292314703418
Validation loss: 2.7931623595270545

Epoch: 6| Step: 1
Training loss: 3.602951609400634
Validation loss: 2.7917187709901774

Epoch: 6| Step: 2
Training loss: 2.6458804409208865
Validation loss: 2.800759787247082

Epoch: 6| Step: 3
Training loss: 3.3387079460326214
Validation loss: 2.8184902519591564

Epoch: 6| Step: 4
Training loss: 3.5671160055407314
Validation loss: 2.840275317216577

Epoch: 6| Step: 5
Training loss: 3.494544409444189
Validation loss: 2.8553796185885867

Epoch: 6| Step: 6
Training loss: 3.450210791519905
Validation loss: 2.823530292934352

Epoch: 6| Step: 7
Training loss: 2.3143139503579744
Validation loss: 2.816854553693784

Epoch: 6| Step: 8
Training loss: 2.969909602115655
Validation loss: 2.798121387439292

Epoch: 6| Step: 9
Training loss: 2.48574023851774
Validation loss: 2.786219601797476

Epoch: 6| Step: 10
Training loss: 2.6289550413957588
Validation loss: 2.7872683908898304

Epoch: 6| Step: 11
Training loss: 3.020306999568598
Validation loss: 2.8002401586603622

Epoch: 6| Step: 12
Training loss: 3.6269311693684547
Validation loss: 2.812748684479318

Epoch: 6| Step: 13
Training loss: 2.100969535813759
Validation loss: 2.8185760048896564

Epoch: 51| Step: 0
Training loss: 3.68590938077116
Validation loss: 2.8236241858037743

Epoch: 6| Step: 1
Training loss: 2.884120076032909
Validation loss: 2.807573097114652

Epoch: 6| Step: 2
Training loss: 2.7886607845164413
Validation loss: 2.7950113512544994

Epoch: 6| Step: 3
Training loss: 3.1340676549682156
Validation loss: 2.7866067912165446

Epoch: 6| Step: 4
Training loss: 3.1140014887458904
Validation loss: 2.783875429464063

Epoch: 6| Step: 5
Training loss: 3.645465825041152
Validation loss: 2.7828937340562026

Epoch: 6| Step: 6
Training loss: 3.170662182981477
Validation loss: 2.779307213309326

Epoch: 6| Step: 7
Training loss: 2.946752059815411
Validation loss: 2.7790571543536964

Epoch: 6| Step: 8
Training loss: 1.8582232458353638
Validation loss: 2.784964982638131

Epoch: 6| Step: 9
Training loss: 2.512837257334455
Validation loss: 2.790758258489551

Epoch: 6| Step: 10
Training loss: 3.7460519989201004
Validation loss: 2.8109869164929018

Epoch: 6| Step: 11
Training loss: 2.6526313816793907
Validation loss: 2.8182582205311157

Epoch: 6| Step: 12
Training loss: 3.1273486657429204
Validation loss: 2.816078390760345

Epoch: 6| Step: 13
Training loss: 4.249009634077499
Validation loss: 2.857127277563251

Epoch: 52| Step: 0
Training loss: 2.7246445520242615
Validation loss: 2.777417113431017

Epoch: 6| Step: 1
Training loss: 3.5098565142394804
Validation loss: 2.784108080540746

Epoch: 6| Step: 2
Training loss: 2.9132504392771046
Validation loss: 2.883786247977149

Epoch: 6| Step: 3
Training loss: 4.348723055324869
Validation loss: 3.2366476968903606

Epoch: 6| Step: 4
Training loss: 3.5751882436849676
Validation loss: 3.2208878111793204

Epoch: 6| Step: 5
Training loss: 3.1570016702400454
Validation loss: 3.127689523353452

Epoch: 6| Step: 6
Training loss: 3.5649389651773076
Validation loss: 3.1429023548648947

Epoch: 6| Step: 7
Training loss: 3.4584916473062797
Validation loss: 3.135900028805491

Epoch: 6| Step: 8
Training loss: 2.8942035690343606
Validation loss: 3.075521469619756

Epoch: 6| Step: 9
Training loss: 2.7120107675411758
Validation loss: 3.011040202974398

Epoch: 6| Step: 10
Training loss: 2.8974824961807495
Validation loss: 2.914016916380973

Epoch: 6| Step: 11
Training loss: 3.7820790540561644
Validation loss: 2.8302632947427724

Epoch: 6| Step: 12
Training loss: 2.908028827309218
Validation loss: 2.8194158825984417

Epoch: 6| Step: 13
Training loss: 3.409504726609706
Validation loss: 2.8299297819083256

Epoch: 53| Step: 0
Training loss: 3.4311669011293757
Validation loss: 2.8687975411342284

Epoch: 6| Step: 1
Training loss: 3.3888733729717773
Validation loss: 2.9142322142812316

Epoch: 6| Step: 2
Training loss: 3.211145398911301
Validation loss: 2.9302892912112055

Epoch: 6| Step: 3
Training loss: 3.5090335343531334
Validation loss: 2.9174700467045427

Epoch: 6| Step: 4
Training loss: 3.1466648611235963
Validation loss: 2.916857203106581

Epoch: 6| Step: 5
Training loss: 3.4166261313910398
Validation loss: 2.9251030543995684

Epoch: 6| Step: 6
Training loss: 3.108861526188272
Validation loss: 2.8809090071557275

Epoch: 6| Step: 7
Training loss: 3.0451905900912783
Validation loss: 2.839315937462452

Epoch: 6| Step: 8
Training loss: 2.3695570162344763
Validation loss: 2.8079696665429843

Epoch: 6| Step: 9
Training loss: 2.9685803816676204
Validation loss: 2.7915527682944976

Epoch: 6| Step: 10
Training loss: 2.9098288537523787
Validation loss: 2.7855232007506796

Epoch: 6| Step: 11
Training loss: 2.8498859650401647
Validation loss: 2.7778288495759274

Epoch: 6| Step: 12
Training loss: 2.949086814101846
Validation loss: 2.778275534800654

Epoch: 6| Step: 13
Training loss: 3.7534247971858825
Validation loss: 2.7774473166699725

Epoch: 54| Step: 0
Training loss: 3.413959981745247
Validation loss: 2.7768536984805205

Epoch: 6| Step: 1
Training loss: 3.0308327928496634
Validation loss: 2.7753671738926693

Epoch: 6| Step: 2
Training loss: 3.043615857562074
Validation loss: 2.776705309418949

Epoch: 6| Step: 3
Training loss: 3.1355905748636617
Validation loss: 2.77344804317233

Epoch: 6| Step: 4
Training loss: 2.3934958181063792
Validation loss: 2.7728915869534614

Epoch: 6| Step: 5
Training loss: 3.23716814262376
Validation loss: 2.772338179743865

Epoch: 6| Step: 6
Training loss: 2.989431202348403
Validation loss: 2.7695293042647755

Epoch: 6| Step: 7
Training loss: 3.2554457595705477
Validation loss: 2.7680907615338435

Epoch: 6| Step: 8
Training loss: 3.5116207121847767
Validation loss: 2.770274844722067

Epoch: 6| Step: 9
Training loss: 3.0935124778119802
Validation loss: 2.7679877126061085

Epoch: 6| Step: 10
Training loss: 3.2670398914154095
Validation loss: 2.764858863924006

Epoch: 6| Step: 11
Training loss: 3.3210403901136334
Validation loss: 2.7646528421408045

Epoch: 6| Step: 12
Training loss: 2.9038211969128085
Validation loss: 2.7641284680970384

Epoch: 6| Step: 13
Training loss: 2.172047560169366
Validation loss: 2.761876892351029

Epoch: 55| Step: 0
Training loss: 3.399520526063772
Validation loss: 2.7593607797210855

Epoch: 6| Step: 1
Training loss: 3.186860263429046
Validation loss: 2.7605642479335315

Epoch: 6| Step: 2
Training loss: 2.763705605884041
Validation loss: 2.7596188160520825

Epoch: 6| Step: 3
Training loss: 2.9888336269496434
Validation loss: 2.7572524280473267

Epoch: 6| Step: 4
Training loss: 1.8837298299396839
Validation loss: 2.760025121712132

Epoch: 6| Step: 5
Training loss: 3.0066654544779947
Validation loss: 2.7851638640813823

Epoch: 6| Step: 6
Training loss: 3.3766146435610387
Validation loss: 2.8214107798919006

Epoch: 6| Step: 7
Training loss: 3.0801700827466427
Validation loss: 2.905575719356742

Epoch: 6| Step: 8
Training loss: 2.921764188082974
Validation loss: 2.9382870487468127

Epoch: 6| Step: 9
Training loss: 3.0956450544139393
Validation loss: 2.9404622887498344

Epoch: 6| Step: 10
Training loss: 3.399675095685702
Validation loss: 2.919307802068746

Epoch: 6| Step: 11
Training loss: 3.9087145545555178
Validation loss: 2.8852116167003126

Epoch: 6| Step: 12
Training loss: 3.468017913270509
Validation loss: 2.8663287062890856

Epoch: 6| Step: 13
Training loss: 3.0242656983003355
Validation loss: 2.827617359712931

Epoch: 56| Step: 0
Training loss: 3.163919177164826
Validation loss: 2.7957739872790643

Epoch: 6| Step: 1
Training loss: 2.9993189992444145
Validation loss: 2.763026065726165

Epoch: 6| Step: 2
Training loss: 3.4614112822489576
Validation loss: 2.7857727262288363

Epoch: 6| Step: 3
Training loss: 3.055966316896324
Validation loss: 2.795944180884695

Epoch: 6| Step: 4
Training loss: 2.6893705024300427
Validation loss: 2.783998096561359

Epoch: 6| Step: 5
Training loss: 3.5136538256467347
Validation loss: 2.786097648092778

Epoch: 6| Step: 6
Training loss: 3.293839489989673
Validation loss: 2.7892877056891616

Epoch: 6| Step: 7
Training loss: 3.2397331047803863
Validation loss: 2.7784435893157426

Epoch: 6| Step: 8
Training loss: 2.943397607789179
Validation loss: 2.7751289013287184

Epoch: 6| Step: 9
Training loss: 3.0395102673630294
Validation loss: 2.7683914500185427

Epoch: 6| Step: 10
Training loss: 2.7240009681375046
Validation loss: 2.7820149284989566

Epoch: 6| Step: 11
Training loss: 2.3006443572324637
Validation loss: 2.7861093082677812

Epoch: 6| Step: 12
Training loss: 3.7424588990996543
Validation loss: 2.797330710006551

Epoch: 6| Step: 13
Training loss: 3.085632772731437
Validation loss: 2.8303743567170154

Epoch: 57| Step: 0
Training loss: 3.8416135479501885
Validation loss: 2.8440038997475203

Epoch: 6| Step: 1
Training loss: 2.868478593474796
Validation loss: 2.8322180182088115

Epoch: 6| Step: 2
Training loss: 3.2139324690460405
Validation loss: 2.8212627207378906

Epoch: 6| Step: 3
Training loss: 3.4801480095179653
Validation loss: 2.777431136536096

Epoch: 6| Step: 4
Training loss: 3.5665376770604977
Validation loss: 2.750131924579421

Epoch: 6| Step: 5
Training loss: 2.504987319640085
Validation loss: 2.753298965855283

Epoch: 6| Step: 6
Training loss: 2.924496866627249
Validation loss: 2.7561653473001986

Epoch: 6| Step: 7
Training loss: 2.904703364500786
Validation loss: 2.756348457519057

Epoch: 6| Step: 8
Training loss: 3.030042584815583
Validation loss: 2.759236712576714

Epoch: 6| Step: 9
Training loss: 2.446616802989419
Validation loss: 2.7557708639274745

Epoch: 6| Step: 10
Training loss: 2.6192545001985397
Validation loss: 2.7576048008589122

Epoch: 6| Step: 11
Training loss: 3.056938571241615
Validation loss: 2.763015948561866

Epoch: 6| Step: 12
Training loss: 3.49107025503265
Validation loss: 2.7647766829312084

Epoch: 6| Step: 13
Training loss: 3.1860306288880667
Validation loss: 2.7585019926440744

Epoch: 58| Step: 0
Training loss: 3.4562670191644154
Validation loss: 2.7518746683414825

Epoch: 6| Step: 1
Training loss: 3.332612213969872
Validation loss: 2.750587179752411

Epoch: 6| Step: 2
Training loss: 3.235706294930178
Validation loss: 2.746133709770263

Epoch: 6| Step: 3
Training loss: 2.9632140896480745
Validation loss: 2.7445054972275913

Epoch: 6| Step: 4
Training loss: 3.029062642056442
Validation loss: 2.7431806713802596

Epoch: 6| Step: 5
Training loss: 3.1610668930897194
Validation loss: 2.7413911825116597

Epoch: 6| Step: 6
Training loss: 2.7175702571823543
Validation loss: 2.7402898622196563

Epoch: 6| Step: 7
Training loss: 3.379158848488101
Validation loss: 2.7411541137606408

Epoch: 6| Step: 8
Training loss: 3.0160073151638858
Validation loss: 2.7380621689058255

Epoch: 6| Step: 9
Training loss: 2.6408263361091717
Validation loss: 2.738684017021035

Epoch: 6| Step: 10
Training loss: 3.3696747198944155
Validation loss: 2.7416050556525184

Epoch: 6| Step: 11
Training loss: 2.3891423433482957
Validation loss: 2.740073971230027

Epoch: 6| Step: 12
Training loss: 3.0292801896502124
Validation loss: 2.7373586522930435

Epoch: 6| Step: 13
Training loss: 3.150607059656972
Validation loss: 2.7364609016897843

Epoch: 59| Step: 0
Training loss: 3.3904050412884508
Validation loss: 2.735956273072753

Epoch: 6| Step: 1
Training loss: 2.949378488016784
Validation loss: 2.7369669162714976

Epoch: 6| Step: 2
Training loss: 3.089953163804331
Validation loss: 2.736256783583433

Epoch: 6| Step: 3
Training loss: 2.6910061698057506
Validation loss: 2.7369847654374353

Epoch: 6| Step: 4
Training loss: 2.761026816442702
Validation loss: 2.736045075650993

Epoch: 6| Step: 5
Training loss: 2.740407077733283
Validation loss: 2.7384406372492265

Epoch: 6| Step: 6
Training loss: 3.3697717932341593
Validation loss: 2.7357938164790334

Epoch: 6| Step: 7
Training loss: 2.872133567551899
Validation loss: 2.7379161644059815

Epoch: 6| Step: 8
Training loss: 2.5505845839671153
Validation loss: 2.735102781605998

Epoch: 6| Step: 9
Training loss: 3.5663918101090477
Validation loss: 2.739181719006343

Epoch: 6| Step: 10
Training loss: 3.049264137424824
Validation loss: 2.7356976588380255

Epoch: 6| Step: 11
Training loss: 3.36833691727191
Validation loss: 2.7385411358539486

Epoch: 6| Step: 12
Training loss: 2.9489186519502897
Validation loss: 2.738442156649553

Epoch: 6| Step: 13
Training loss: 3.516558035909812
Validation loss: 2.736063238160661

Epoch: 60| Step: 0
Training loss: 3.0559171655323407
Validation loss: 2.7356328974380055

Epoch: 6| Step: 1
Training loss: 2.999404212283184
Validation loss: 2.7361136744729264

Epoch: 6| Step: 2
Training loss: 3.1371972656098004
Validation loss: 2.735916426086532

Epoch: 6| Step: 3
Training loss: 3.360282172207487
Validation loss: 2.729111951216744

Epoch: 6| Step: 4
Training loss: 2.2854454444411054
Validation loss: 2.7350221023495855

Epoch: 6| Step: 5
Training loss: 2.6053217856438557
Validation loss: 2.7323261485138044

Epoch: 6| Step: 6
Training loss: 3.1992947635772686
Validation loss: 2.731380909245719

Epoch: 6| Step: 7
Training loss: 2.827462556086817
Validation loss: 2.7294533347369176

Epoch: 6| Step: 8
Training loss: 3.5715906705854312
Validation loss: 2.7301327341085306

Epoch: 6| Step: 9
Training loss: 2.9579160870661965
Validation loss: 2.7263584034130304

Epoch: 6| Step: 10
Training loss: 2.8563388067750917
Validation loss: 2.729112047971654

Epoch: 6| Step: 11
Training loss: 3.797322815910876
Validation loss: 2.727225810179092

Epoch: 6| Step: 12
Training loss: 2.7095137933470443
Validation loss: 2.731159143871919

Epoch: 6| Step: 13
Training loss: 3.0760661564175154
Validation loss: 2.731121893677621

Epoch: 61| Step: 0
Training loss: 2.9592109417179113
Validation loss: 2.734662758588532

Epoch: 6| Step: 1
Training loss: 2.867728283682609
Validation loss: 2.730539078434412

Epoch: 6| Step: 2
Training loss: 3.1281807542952134
Validation loss: 2.73119857216662

Epoch: 6| Step: 3
Training loss: 3.361417211740714
Validation loss: 2.733148954494593

Epoch: 6| Step: 4
Training loss: 2.6356622232219804
Validation loss: 2.7257708442625814

Epoch: 6| Step: 5
Training loss: 3.5311600665227956
Validation loss: 2.7209537896719995

Epoch: 6| Step: 6
Training loss: 3.804113074458245
Validation loss: 2.723740699215053

Epoch: 6| Step: 7
Training loss: 2.6001824278287673
Validation loss: 2.721531474032816

Epoch: 6| Step: 8
Training loss: 2.5952190237648605
Validation loss: 2.71793338032815

Epoch: 6| Step: 9
Training loss: 2.3655911845079403
Validation loss: 2.7201167042368173

Epoch: 6| Step: 10
Training loss: 3.157123558093946
Validation loss: 2.7215360662036847

Epoch: 6| Step: 11
Training loss: 2.8265858039295955
Validation loss: 2.7195996776764813

Epoch: 6| Step: 12
Training loss: 3.4411371582685573
Validation loss: 2.726839039245912

Epoch: 6| Step: 13
Training loss: 3.075432078700995
Validation loss: 2.7251215658235113

Epoch: 62| Step: 0
Training loss: 2.7944076992810167
Validation loss: 2.719160019571027

Epoch: 6| Step: 1
Training loss: 3.2954980948987735
Validation loss: 2.715785554524495

Epoch: 6| Step: 2
Training loss: 2.8119680113458396
Validation loss: 2.7162793288441622

Epoch: 6| Step: 3
Training loss: 3.3053644447396158
Validation loss: 2.7170488964250232

Epoch: 6| Step: 4
Training loss: 2.377586963559295
Validation loss: 2.7203835141651473

Epoch: 6| Step: 5
Training loss: 2.41637588812435
Validation loss: 2.72002675015556

Epoch: 6| Step: 6
Training loss: 3.5352677975754156
Validation loss: 2.721030425884466

Epoch: 6| Step: 7
Training loss: 3.303668214418553
Validation loss: 2.7179418712856984

Epoch: 6| Step: 8
Training loss: 3.1293256195237675
Validation loss: 2.71744529338419

Epoch: 6| Step: 9
Training loss: 2.9472683754232527
Validation loss: 2.719193719023207

Epoch: 6| Step: 10
Training loss: 3.141910422774069
Validation loss: 2.7131713806014917

Epoch: 6| Step: 11
Training loss: 2.866016949355272
Validation loss: 2.7115244055009855

Epoch: 6| Step: 12
Training loss: 2.9845563424023545
Validation loss: 2.7129520672214484

Epoch: 6| Step: 13
Training loss: 3.6068215854347043
Validation loss: 2.711420694952662

Epoch: 63| Step: 0
Training loss: 3.1734439370838055
Validation loss: 2.711491403037713

Epoch: 6| Step: 1
Training loss: 2.714374836555632
Validation loss: 2.714882321753954

Epoch: 6| Step: 2
Training loss: 2.607930131731095
Validation loss: 2.7134784231885174

Epoch: 6| Step: 3
Training loss: 3.712227494741841
Validation loss: 2.717055667249907

Epoch: 6| Step: 4
Training loss: 3.062746310546885
Validation loss: 2.722487864934949

Epoch: 6| Step: 5
Training loss: 2.0254833821877076
Validation loss: 2.7286218388840515

Epoch: 6| Step: 6
Training loss: 3.3358262912340155
Validation loss: 2.7219937353642907

Epoch: 6| Step: 7
Training loss: 3.3340111202336007
Validation loss: 2.72064069032554

Epoch: 6| Step: 8
Training loss: 3.756056535914864
Validation loss: 2.713127498744852

Epoch: 6| Step: 9
Training loss: 3.0539543657472037
Validation loss: 2.7093061045872

Epoch: 6| Step: 10
Training loss: 3.27585732689876
Validation loss: 2.7073817440610677

Epoch: 6| Step: 11
Training loss: 2.113151278350727
Validation loss: 2.708501766700422

Epoch: 6| Step: 12
Training loss: 2.6176829310402963
Validation loss: 2.705743486301249

Epoch: 6| Step: 13
Training loss: 3.2535943915681544
Validation loss: 2.7059497924311895

Epoch: 64| Step: 0
Training loss: 2.5640546223242215
Validation loss: 2.708835828435662

Epoch: 6| Step: 1
Training loss: 3.2895233483831827
Validation loss: 2.7064913510042556

Epoch: 6| Step: 2
Training loss: 3.250303400989872
Validation loss: 2.7061920558058814

Epoch: 6| Step: 3
Training loss: 2.4697964538845314
Validation loss: 2.7031475319659184

Epoch: 6| Step: 4
Training loss: 3.1574212346706947
Validation loss: 2.704480358425745

Epoch: 6| Step: 5
Training loss: 3.4195024460818515
Validation loss: 2.7037693630615927

Epoch: 6| Step: 6
Training loss: 3.412864212889244
Validation loss: 2.7030952940880626

Epoch: 6| Step: 7
Training loss: 3.083209954619954
Validation loss: 2.7023368092715123

Epoch: 6| Step: 8
Training loss: 3.0999659505635413
Validation loss: 2.699683605951382

Epoch: 6| Step: 9
Training loss: 2.0971822362909607
Validation loss: 2.700206526169075

Epoch: 6| Step: 10
Training loss: 2.997983413670766
Validation loss: 2.7012943345085474

Epoch: 6| Step: 11
Training loss: 2.5508059256559146
Validation loss: 2.696213605691408

Epoch: 6| Step: 12
Training loss: 3.671491367509167
Validation loss: 2.700453500858281

Epoch: 6| Step: 13
Training loss: 3.0688499481022666
Validation loss: 2.701406364645544

Epoch: 65| Step: 0
Training loss: 2.869309806639829
Validation loss: 2.7038879863615475

Epoch: 6| Step: 1
Training loss: 3.4027779057993617
Validation loss: 2.7046288588966148

Epoch: 6| Step: 2
Training loss: 3.3178563985716694
Validation loss: 2.711177382081437

Epoch: 6| Step: 3
Training loss: 2.776968414225916
Validation loss: 2.7001281339472323

Epoch: 6| Step: 4
Training loss: 2.9469006048811397
Validation loss: 2.6979152007785325

Epoch: 6| Step: 5
Training loss: 1.9683038720755897
Validation loss: 2.6946254421067772

Epoch: 6| Step: 6
Training loss: 3.309748100307302
Validation loss: 2.693808006261839

Epoch: 6| Step: 7
Training loss: 2.5661175941465593
Validation loss: 2.6941821671546644

Epoch: 6| Step: 8
Training loss: 3.257199016961689
Validation loss: 2.693978664507837

Epoch: 6| Step: 9
Training loss: 2.8724333875085475
Validation loss: 2.6922350696657165

Epoch: 6| Step: 10
Training loss: 3.4549253439669654
Validation loss: 2.6919554798852228

Epoch: 6| Step: 11
Training loss: 3.0086007806838944
Validation loss: 2.69185755341179

Epoch: 6| Step: 12
Training loss: 3.249914608347095
Validation loss: 2.6903015895917854

Epoch: 6| Step: 13
Training loss: 3.167586410536087
Validation loss: 2.6907563167091464

Epoch: 66| Step: 0
Training loss: 3.0204726080534114
Validation loss: 2.689680178150314

Epoch: 6| Step: 1
Training loss: 3.2748102846596616
Validation loss: 2.6910566465481103

Epoch: 6| Step: 2
Training loss: 3.13528200453896
Validation loss: 2.693085018595465

Epoch: 6| Step: 3
Training loss: 3.0020601828055553
Validation loss: 2.6886765388931657

Epoch: 6| Step: 4
Training loss: 3.062971740512588
Validation loss: 2.6889152720934546

Epoch: 6| Step: 5
Training loss: 2.6162348137791605
Validation loss: 2.68940472386334

Epoch: 6| Step: 6
Training loss: 3.1668348435031137
Validation loss: 2.6897902921119976

Epoch: 6| Step: 7
Training loss: 3.3019246124404833
Validation loss: 2.688866195782392

Epoch: 6| Step: 8
Training loss: 2.8484141907023344
Validation loss: 2.6876978781087995

Epoch: 6| Step: 9
Training loss: 3.617520211986501
Validation loss: 2.686853745587234

Epoch: 6| Step: 10
Training loss: 2.686528141041184
Validation loss: 2.6856147676688145

Epoch: 6| Step: 11
Training loss: 2.5529045392667715
Validation loss: 2.6834884230972733

Epoch: 6| Step: 12
Training loss: 2.8674396123405845
Validation loss: 2.684510840183111

Epoch: 6| Step: 13
Training loss: 3.0681719513294565
Validation loss: 2.684142712203745

Epoch: 67| Step: 0
Training loss: 3.3482608494018513
Validation loss: 2.6839666593938984

Epoch: 6| Step: 1
Training loss: 3.242089106893667
Validation loss: 2.6838314079351546

Epoch: 6| Step: 2
Training loss: 3.0671404500219963
Validation loss: 2.6858707095656293

Epoch: 6| Step: 3
Training loss: 3.403092066637879
Validation loss: 2.687262123685895

Epoch: 6| Step: 4
Training loss: 2.76582490877403
Validation loss: 2.6887724283057866

Epoch: 6| Step: 5
Training loss: 2.791751537646074
Validation loss: 2.688983045393527

Epoch: 6| Step: 6
Training loss: 2.526410787034395
Validation loss: 2.6929578980651616

Epoch: 6| Step: 7
Training loss: 3.1225803926257276
Validation loss: 2.6936781655603514

Epoch: 6| Step: 8
Training loss: 2.6648245250195197
Validation loss: 2.707989952210417

Epoch: 6| Step: 9
Training loss: 3.1696613272852194
Validation loss: 2.717286204901817

Epoch: 6| Step: 10
Training loss: 2.763728207934044
Validation loss: 2.7250783100901055

Epoch: 6| Step: 11
Training loss: 3.156227338350731
Validation loss: 2.7195375777712156

Epoch: 6| Step: 12
Training loss: 2.936624924200326
Validation loss: 2.738893278284653

Epoch: 6| Step: 13
Training loss: 3.304051836350707
Validation loss: 2.726955806799023

Epoch: 68| Step: 0
Training loss: 2.961366164447842
Validation loss: 2.740830191554562

Epoch: 6| Step: 1
Training loss: 2.520046163771907
Validation loss: 2.737637088699633

Epoch: 6| Step: 2
Training loss: 3.4455461141744053
Validation loss: 2.7474318209162596

Epoch: 6| Step: 3
Training loss: 2.8112220403859176
Validation loss: 2.7082320397100412

Epoch: 6| Step: 4
Training loss: 2.4878572255409903
Validation loss: 2.6950125293279488

Epoch: 6| Step: 5
Training loss: 3.453035241250708
Validation loss: 2.6859794124884817

Epoch: 6| Step: 6
Training loss: 3.1102402599787173
Validation loss: 2.678604184920683

Epoch: 6| Step: 7
Training loss: 3.4434949444650202
Validation loss: 2.670857525838907

Epoch: 6| Step: 8
Training loss: 2.704145205921504
Validation loss: 2.672948969133158

Epoch: 6| Step: 9
Training loss: 3.0904119188624466
Validation loss: 2.676190609805546

Epoch: 6| Step: 10
Training loss: 3.229704945318299
Validation loss: 2.6754339426428704

Epoch: 6| Step: 11
Training loss: 2.465883933275793
Validation loss: 2.6761539385014914

Epoch: 6| Step: 12
Training loss: 3.5696021777841858
Validation loss: 2.676267024862364

Epoch: 6| Step: 13
Training loss: 2.494917853767113
Validation loss: 2.680551323269326

Epoch: 69| Step: 0
Training loss: 2.744000045053465
Validation loss: 2.6807729354265164

Epoch: 6| Step: 1
Training loss: 2.9387334303751826
Validation loss: 2.683731959435098

Epoch: 6| Step: 2
Training loss: 3.2889729032296255
Validation loss: 2.689332461793153

Epoch: 6| Step: 3
Training loss: 2.9476555123367416
Validation loss: 2.6893920343397633

Epoch: 6| Step: 4
Training loss: 2.8935721554906424
Validation loss: 2.6869708363249885

Epoch: 6| Step: 5
Training loss: 3.2662339806264233
Validation loss: 2.6848332289666064

Epoch: 6| Step: 6
Training loss: 3.2715852363183346
Validation loss: 2.6821522870136647

Epoch: 6| Step: 7
Training loss: 3.4454475774257634
Validation loss: 2.6733188523926383

Epoch: 6| Step: 8
Training loss: 3.1543865179309263
Validation loss: 2.672129473741216

Epoch: 6| Step: 9
Training loss: 2.988163485731002
Validation loss: 2.6693518070131486

Epoch: 6| Step: 10
Training loss: 2.8629956278606024
Validation loss: 2.6672994932446246

Epoch: 6| Step: 11
Training loss: 2.7623465551507422
Validation loss: 2.6668595954364003

Epoch: 6| Step: 12
Training loss: 2.437775229540899
Validation loss: 2.6662527142475767

Epoch: 6| Step: 13
Training loss: 3.255670588923508
Validation loss: 2.667169701970484

Epoch: 70| Step: 0
Training loss: 3.16580988352553
Validation loss: 2.666613205891699

Epoch: 6| Step: 1
Training loss: 3.2939971367847294
Validation loss: 2.6705439241461004

Epoch: 6| Step: 2
Training loss: 3.0970792485543814
Validation loss: 2.676792396782037

Epoch: 6| Step: 3
Training loss: 3.287191189378455
Validation loss: 2.680123441421835

Epoch: 6| Step: 4
Training loss: 3.281146965225677
Validation loss: 2.6810806256485513

Epoch: 6| Step: 5
Training loss: 2.859721178455316
Validation loss: 2.6832543711227745

Epoch: 6| Step: 6
Training loss: 2.915325964733936
Validation loss: 2.669359321157986

Epoch: 6| Step: 7
Training loss: 3.0643533820506814
Validation loss: 2.663853306890385

Epoch: 6| Step: 8
Training loss: 2.8694482356691955
Validation loss: 2.6610606613079395

Epoch: 6| Step: 9
Training loss: 2.9514171364622994
Validation loss: 2.658835985194811

Epoch: 6| Step: 10
Training loss: 2.8752676797729078
Validation loss: 2.662979673353598

Epoch: 6| Step: 11
Training loss: 2.6032259551732624
Validation loss: 2.665341285025717

Epoch: 6| Step: 12
Training loss: 3.2574887194844373
Validation loss: 2.6649472714243334

Epoch: 6| Step: 13
Training loss: 2.0232360032546186
Validation loss: 2.6651243901568162

Epoch: 71| Step: 0
Training loss: 2.954787981976476
Validation loss: 2.664969868367944

Epoch: 6| Step: 1
Training loss: 3.130358869558198
Validation loss: 2.664661823494966

Epoch: 6| Step: 2
Training loss: 2.6317459798807348
Validation loss: 2.661963982368575

Epoch: 6| Step: 3
Training loss: 3.016040200226098
Validation loss: 2.6626268622273055

Epoch: 6| Step: 4
Training loss: 2.800541781053362
Validation loss: 2.6609746223991277

Epoch: 6| Step: 5
Training loss: 3.0184527959691767
Validation loss: 2.659987066804796

Epoch: 6| Step: 6
Training loss: 3.1297775369872975
Validation loss: 2.6598999320131638

Epoch: 6| Step: 7
Training loss: 2.881666994846811
Validation loss: 2.658494969410641

Epoch: 6| Step: 8
Training loss: 3.1001739084008015
Validation loss: 2.6593934801854324

Epoch: 6| Step: 9
Training loss: 3.404755570745277
Validation loss: 2.6610791795362347

Epoch: 6| Step: 10
Training loss: 2.881049219115548
Validation loss: 2.658720132520079

Epoch: 6| Step: 11
Training loss: 3.218172484503379
Validation loss: 2.6617539530236654

Epoch: 6| Step: 12
Training loss: 3.0029908212781242
Validation loss: 2.6567562559427764

Epoch: 6| Step: 13
Training loss: 2.7649687942206356
Validation loss: 2.6567105091335383

Epoch: 72| Step: 0
Training loss: 2.9158677959849464
Validation loss: 2.655888281266906

Epoch: 6| Step: 1
Training loss: 3.478134245744534
Validation loss: 2.654850244844045

Epoch: 6| Step: 2
Training loss: 3.265080018632954
Validation loss: 2.6539321563483207

Epoch: 6| Step: 3
Training loss: 2.582697472200365
Validation loss: 2.654230125545524

Epoch: 6| Step: 4
Training loss: 2.477520008487531
Validation loss: 2.6527180362070513

Epoch: 6| Step: 5
Training loss: 3.1923575693499524
Validation loss: 2.654285103249203

Epoch: 6| Step: 6
Training loss: 3.2558986247259276
Validation loss: 2.6517172090362937

Epoch: 6| Step: 7
Training loss: 3.0270772312117677
Validation loss: 2.6520182604225027

Epoch: 6| Step: 8
Training loss: 2.746952622567838
Validation loss: 2.6509098012366095

Epoch: 6| Step: 9
Training loss: 3.2983857801783607
Validation loss: 2.65061477817277

Epoch: 6| Step: 10
Training loss: 2.7949596645058405
Validation loss: 2.65515311537792

Epoch: 6| Step: 11
Training loss: 2.99493186733081
Validation loss: 2.654288868128906

Epoch: 6| Step: 12
Training loss: 2.6164533354018467
Validation loss: 2.655687796484448

Epoch: 6| Step: 13
Training loss: 3.231504926826207
Validation loss: 2.6609620005817916

Epoch: 73| Step: 0
Training loss: 3.069028784991348
Validation loss: 2.664856095764831

Epoch: 6| Step: 1
Training loss: 3.1062692438216466
Validation loss: 2.6579286949430148

Epoch: 6| Step: 2
Training loss: 3.144504561222145
Validation loss: 2.6615826743242916

Epoch: 6| Step: 3
Training loss: 2.974577634946387
Validation loss: 2.661077882821292

Epoch: 6| Step: 4
Training loss: 2.7293713810754556
Validation loss: 2.6615596903089664

Epoch: 6| Step: 5
Training loss: 3.163491129207217
Validation loss: 2.650879253919124

Epoch: 6| Step: 6
Training loss: 3.105493010420174
Validation loss: 2.6532901378724123

Epoch: 6| Step: 7
Training loss: 3.761142706413546
Validation loss: 2.6542476009697067

Epoch: 6| Step: 8
Training loss: 2.36820171522902
Validation loss: 2.653152526398056

Epoch: 6| Step: 9
Training loss: 2.627150789786881
Validation loss: 2.651151800878838

Epoch: 6| Step: 10
Training loss: 2.7578478586669632
Validation loss: 2.6542584635303057

Epoch: 6| Step: 11
Training loss: 3.0212354896585216
Validation loss: 2.6567331163077332

Epoch: 6| Step: 12
Training loss: 3.0198434369765095
Validation loss: 2.647840712325515

Epoch: 6| Step: 13
Training loss: 2.7013208619884574
Validation loss: 2.6487480279424562

Epoch: 74| Step: 0
Training loss: 3.4615356755041664
Validation loss: 2.645095531122442

Epoch: 6| Step: 1
Training loss: 3.2122519371352856
Validation loss: 2.646053732975578

Epoch: 6| Step: 2
Training loss: 3.1903923226309088
Validation loss: 2.648840026147858

Epoch: 6| Step: 3
Training loss: 2.9405826058813105
Validation loss: 2.6457809651057698

Epoch: 6| Step: 4
Training loss: 2.516187901040923
Validation loss: 2.6465649819295094

Epoch: 6| Step: 5
Training loss: 3.3002690928013587
Validation loss: 2.649041555645825

Epoch: 6| Step: 6
Training loss: 3.1368616434995955
Validation loss: 2.644902791809084

Epoch: 6| Step: 7
Training loss: 2.883347541759374
Validation loss: 2.6439116513370067

Epoch: 6| Step: 8
Training loss: 2.9221901137212103
Validation loss: 2.64010657454124

Epoch: 6| Step: 9
Training loss: 2.882808695638157
Validation loss: 2.644802022024331

Epoch: 6| Step: 10
Training loss: 2.3428965731369775
Validation loss: 2.6408811103883925

Epoch: 6| Step: 11
Training loss: 3.0449533515952445
Validation loss: 2.6411741107737434

Epoch: 6| Step: 12
Training loss: 2.6351350676575542
Validation loss: 2.6453022942714033

Epoch: 6| Step: 13
Training loss: 3.236324146846152
Validation loss: 2.6434060718535335

Epoch: 75| Step: 0
Training loss: 3.4229007385465304
Validation loss: 2.648618997239039

Epoch: 6| Step: 1
Training loss: 3.4284201259379694
Validation loss: 2.6482448761322464

Epoch: 6| Step: 2
Training loss: 3.253073925896273
Validation loss: 2.6621315337910967

Epoch: 6| Step: 3
Training loss: 2.370750641232703
Validation loss: 2.6655593827255606

Epoch: 6| Step: 4
Training loss: 2.936945112048661
Validation loss: 2.6729403103127267

Epoch: 6| Step: 5
Training loss: 2.8439543933564932
Validation loss: 2.6726572354545857

Epoch: 6| Step: 6
Training loss: 2.6765085832874016
Validation loss: 2.6665034904341227

Epoch: 6| Step: 7
Training loss: 3.153555749330546
Validation loss: 2.661459231400076

Epoch: 6| Step: 8
Training loss: 2.5789171331315255
Validation loss: 2.6646707266475533

Epoch: 6| Step: 9
Training loss: 2.9895227583398385
Validation loss: 2.659985030338227

Epoch: 6| Step: 10
Training loss: 3.1093058362773354
Validation loss: 2.6509546810840705

Epoch: 6| Step: 11
Training loss: 2.9360737686244684
Validation loss: 2.6367343006716113

Epoch: 6| Step: 12
Training loss: 2.8582092577044875
Validation loss: 2.638154864450631

Epoch: 6| Step: 13
Training loss: 3.0142975885083745
Validation loss: 2.6343840523570594

Testing loss: 2.8701531544285284
