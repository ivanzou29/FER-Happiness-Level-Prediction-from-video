Epoch: 1| Step: 0
Training loss: 4.749635696411133
Validation loss: 5.192885768028997

Epoch: 6| Step: 1
Training loss: 5.470363616943359
Validation loss: 5.1643810733672115

Epoch: 6| Step: 2
Training loss: 5.277912139892578
Validation loss: 5.135002684849565

Epoch: 6| Step: 3
Training loss: 4.181707859039307
Validation loss: 5.104231619065808

Epoch: 6| Step: 4
Training loss: 4.467870712280273
Validation loss: 5.070585076526929

Epoch: 6| Step: 5
Training loss: 4.907346725463867
Validation loss: 5.032649383750013

Epoch: 6| Step: 6
Training loss: 5.140447616577148
Validation loss: 4.990229601501136

Epoch: 6| Step: 7
Training loss: 4.594501972198486
Validation loss: 4.944405453179472

Epoch: 6| Step: 8
Training loss: 4.0889434814453125
Validation loss: 4.893091765783167

Epoch: 6| Step: 9
Training loss: 4.381597518920898
Validation loss: 4.837893116858698

Epoch: 6| Step: 10
Training loss: 4.690759658813477
Validation loss: 4.77969184998543

Epoch: 6| Step: 11
Training loss: 5.186055660247803
Validation loss: 4.719117374830349

Epoch: 6| Step: 12
Training loss: 5.116351127624512
Validation loss: 4.655018139910954

Epoch: 6| Step: 13
Training loss: 3.668086051940918
Validation loss: 4.591170111010151

Epoch: 2| Step: 0
Training loss: 4.9364447593688965
Validation loss: 4.527796678645636

Epoch: 6| Step: 1
Training loss: 3.2174232006073
Validation loss: 4.464229593994797

Epoch: 6| Step: 2
Training loss: 3.289151191711426
Validation loss: 4.407094227370395

Epoch: 6| Step: 3
Training loss: 5.1013383865356445
Validation loss: 4.353934405952372

Epoch: 6| Step: 4
Training loss: 4.717716217041016
Validation loss: 4.30589166507926

Epoch: 6| Step: 5
Training loss: 2.9311628341674805
Validation loss: 4.2588345312303115

Epoch: 6| Step: 6
Training loss: 3.968188762664795
Validation loss: 4.213144620259603

Epoch: 6| Step: 7
Training loss: 4.103371620178223
Validation loss: 4.17035299219111

Epoch: 6| Step: 8
Training loss: 3.218447208404541
Validation loss: 4.1276087299469975

Epoch: 6| Step: 9
Training loss: 3.7445003986358643
Validation loss: 4.0889827923108175

Epoch: 6| Step: 10
Training loss: 3.916785955429077
Validation loss: 4.0517928472129245

Epoch: 6| Step: 11
Training loss: 4.431357383728027
Validation loss: 4.0175062738439085

Epoch: 6| Step: 12
Training loss: 3.8217387199401855
Validation loss: 3.9831683251165573

Epoch: 6| Step: 13
Training loss: 5.7184157371521
Validation loss: 3.9507938995156238

Epoch: 3| Step: 0
Training loss: 3.670969009399414
Validation loss: 3.916467410261913

Epoch: 6| Step: 1
Training loss: 2.367302179336548
Validation loss: 3.8836306500178512

Epoch: 6| Step: 2
Training loss: 3.7445435523986816
Validation loss: 3.848154708903323

Epoch: 6| Step: 3
Training loss: 3.9066860675811768
Validation loss: 3.812468892784529

Epoch: 6| Step: 4
Training loss: 2.6410388946533203
Validation loss: 3.7784806938581568

Epoch: 6| Step: 5
Training loss: 4.046509265899658
Validation loss: 3.7585599832637335

Epoch: 6| Step: 6
Training loss: 4.221738815307617
Validation loss: 3.735510085218696

Epoch: 6| Step: 7
Training loss: 3.141772508621216
Validation loss: 3.7094603507749495

Epoch: 6| Step: 8
Training loss: 3.201780080795288
Validation loss: 3.6864721031599146

Epoch: 6| Step: 9
Training loss: 4.538738250732422
Validation loss: 3.6650917760787474

Epoch: 6| Step: 10
Training loss: 4.295932292938232
Validation loss: 3.637960221177788

Epoch: 6| Step: 11
Training loss: 3.647080659866333
Validation loss: 3.6174484888712564

Epoch: 6| Step: 12
Training loss: 4.284272193908691
Validation loss: 3.6017754590639504

Epoch: 6| Step: 13
Training loss: 2.526850938796997
Validation loss: 3.5830080637367825

Epoch: 4| Step: 0
Training loss: 3.4328439235687256
Validation loss: 3.5600864195054576

Epoch: 6| Step: 1
Training loss: 3.460841655731201
Validation loss: 3.542620474292386

Epoch: 6| Step: 2
Training loss: 2.732027530670166
Validation loss: 3.5180499656226045

Epoch: 6| Step: 3
Training loss: 4.318483352661133
Validation loss: 3.4953570340269353

Epoch: 6| Step: 4
Training loss: 3.6001460552215576
Validation loss: 3.472752568542316

Epoch: 6| Step: 5
Training loss: 3.8313231468200684
Validation loss: 3.4591908762531896

Epoch: 6| Step: 6
Training loss: 2.796786308288574
Validation loss: 3.4403554983036493

Epoch: 6| Step: 7
Training loss: 3.6622629165649414
Validation loss: 3.4423706864797943

Epoch: 6| Step: 8
Training loss: 3.6148624420166016
Validation loss: 3.4105813605811006

Epoch: 6| Step: 9
Training loss: 2.589599132537842
Validation loss: 3.4020983583183697

Epoch: 6| Step: 10
Training loss: 2.8835813999176025
Validation loss: 3.3974192680851107

Epoch: 6| Step: 11
Training loss: 3.7826852798461914
Validation loss: 3.383344563104773

Epoch: 6| Step: 12
Training loss: 3.024460792541504
Validation loss: 3.358312370956585

Epoch: 6| Step: 13
Training loss: 4.015514373779297
Validation loss: 3.348004223198019

Epoch: 5| Step: 0
Training loss: 2.3520584106445312
Validation loss: 3.3311472503087853

Epoch: 6| Step: 1
Training loss: 3.1858527660369873
Validation loss: 3.319298287873627

Epoch: 6| Step: 2
Training loss: 2.584259510040283
Validation loss: 3.309206303729806

Epoch: 6| Step: 3
Training loss: 4.563189506530762
Validation loss: 3.2998685606064333

Epoch: 6| Step: 4
Training loss: 2.5849356651306152
Validation loss: 3.290443040991342

Epoch: 6| Step: 5
Training loss: 3.229663848876953
Validation loss: 3.2822546446195213

Epoch: 6| Step: 6
Training loss: 2.8279318809509277
Validation loss: 3.3340112804084696

Epoch: 6| Step: 7
Training loss: 3.4171900749206543
Validation loss: 3.3474885776478756

Epoch: 6| Step: 8
Training loss: 2.922086238861084
Validation loss: 3.2773964199968564

Epoch: 6| Step: 9
Training loss: 3.3425045013427734
Validation loss: 3.255405902862549

Epoch: 6| Step: 10
Training loss: 4.255853652954102
Validation loss: 3.2600480023250786

Epoch: 6| Step: 11
Training loss: 3.4728024005889893
Validation loss: 3.2740246019055768

Epoch: 6| Step: 12
Training loss: 4.139586448669434
Validation loss: 3.295097202383062

Epoch: 6| Step: 13
Training loss: 2.5738868713378906
Validation loss: 3.285638052930114

Epoch: 6| Step: 0
Training loss: 3.2755846977233887
Validation loss: 3.241460874516477

Epoch: 6| Step: 1
Training loss: 2.4345903396606445
Validation loss: 3.2157454670116468

Epoch: 6| Step: 2
Training loss: 3.5274505615234375
Validation loss: 3.211506151383923

Epoch: 6| Step: 3
Training loss: 3.702484130859375
Validation loss: 3.2123753178504204

Epoch: 6| Step: 4
Training loss: 2.693554401397705
Validation loss: 3.217900030074581

Epoch: 6| Step: 5
Training loss: 4.085312843322754
Validation loss: 3.19907316084831

Epoch: 6| Step: 6
Training loss: 3.882185935974121
Validation loss: 3.1949085368905017

Epoch: 6| Step: 7
Training loss: 3.019655227661133
Validation loss: 3.1900426341641333

Epoch: 6| Step: 8
Training loss: 3.1251754760742188
Validation loss: 3.188226176846412

Epoch: 6| Step: 9
Training loss: 2.542201280593872
Validation loss: 3.1818363281988327

Epoch: 6| Step: 10
Training loss: 3.330899953842163
Validation loss: 3.175265953104983

Epoch: 6| Step: 11
Training loss: 2.6539225578308105
Validation loss: 3.1617709693088325

Epoch: 6| Step: 12
Training loss: 3.778592109680176
Validation loss: 3.1480033090037685

Epoch: 6| Step: 13
Training loss: 2.3274598121643066
Validation loss: 3.1434222395702074

Epoch: 7| Step: 0
Training loss: 2.236673593521118
Validation loss: 3.1386929840169926

Epoch: 6| Step: 1
Training loss: 3.2914936542510986
Validation loss: 3.131839680415328

Epoch: 6| Step: 2
Training loss: 4.290587425231934
Validation loss: 3.1274956580131286

Epoch: 6| Step: 3
Training loss: 3.3152966499328613
Validation loss: 3.1207093269594255

Epoch: 6| Step: 4
Training loss: 3.2543203830718994
Validation loss: 3.114428186929354

Epoch: 6| Step: 5
Training loss: 3.3851544857025146
Validation loss: 3.1054372556747927

Epoch: 6| Step: 6
Training loss: 3.7564244270324707
Validation loss: 3.1006458625998548

Epoch: 6| Step: 7
Training loss: 3.1986076831817627
Validation loss: 3.0884205654103267

Epoch: 6| Step: 8
Training loss: 2.097355365753174
Validation loss: 3.0879460560378207

Epoch: 6| Step: 9
Training loss: 2.905087471008301
Validation loss: 3.0865928050010436

Epoch: 6| Step: 10
Training loss: 3.324228286743164
Validation loss: 3.078259209150909

Epoch: 6| Step: 11
Training loss: 3.203883409500122
Validation loss: 3.074945890775291

Epoch: 6| Step: 12
Training loss: 2.698411703109741
Validation loss: 3.070867764052524

Epoch: 6| Step: 13
Training loss: 2.5998640060424805
Validation loss: 3.062199156771424

Epoch: 8| Step: 0
Training loss: 2.855069398880005
Validation loss: 3.071389772558725

Epoch: 6| Step: 1
Training loss: 2.817350149154663
Validation loss: 3.0602847401813795

Epoch: 6| Step: 2
Training loss: 3.4029157161712646
Validation loss: 3.050339288609002

Epoch: 6| Step: 3
Training loss: 3.0025382041931152
Validation loss: 3.0447664568501134

Epoch: 6| Step: 4
Training loss: 3.4415814876556396
Validation loss: 3.0381402943723943

Epoch: 6| Step: 5
Training loss: 3.034926414489746
Validation loss: 3.032826159590034

Epoch: 6| Step: 6
Training loss: 3.2495882511138916
Validation loss: 3.0277446623771422

Epoch: 6| Step: 7
Training loss: 3.7593164443969727
Validation loss: 3.0246816399276897

Epoch: 6| Step: 8
Training loss: 3.5431394577026367
Validation loss: 3.021392245446482

Epoch: 6| Step: 9
Training loss: 2.718759536743164
Validation loss: 3.015218219449443

Epoch: 6| Step: 10
Training loss: 2.1871533393859863
Validation loss: 3.0119400280778126

Epoch: 6| Step: 11
Training loss: 2.3562278747558594
Validation loss: 3.005485624395391

Epoch: 6| Step: 12
Training loss: 4.512630939483643
Validation loss: 3.002061305507537

Epoch: 6| Step: 13
Training loss: 1.7023675441741943
Validation loss: 2.999126675308392

Epoch: 9| Step: 0
Training loss: 2.3391623497009277
Validation loss: 2.99511803350141

Epoch: 6| Step: 1
Training loss: 3.157296657562256
Validation loss: 2.993439297522268

Epoch: 6| Step: 2
Training loss: 2.725341796875
Validation loss: 2.9885178945397817

Epoch: 6| Step: 3
Training loss: 3.4228644371032715
Validation loss: 2.9855023302057737

Epoch: 6| Step: 4
Training loss: 2.6291916370391846
Validation loss: 2.986586980922248

Epoch: 6| Step: 5
Training loss: 3.7033751010894775
Validation loss: 2.984315815792289

Epoch: 6| Step: 6
Training loss: 3.907034397125244
Validation loss: 2.9739018845301803

Epoch: 6| Step: 7
Training loss: 3.180647850036621
Validation loss: 2.9848885074738534

Epoch: 6| Step: 8
Training loss: 2.327960968017578
Validation loss: 2.998045454743088

Epoch: 6| Step: 9
Training loss: 2.814685821533203
Validation loss: 2.991605161338724

Epoch: 6| Step: 10
Training loss: 2.757356882095337
Validation loss: 2.96646975445491

Epoch: 6| Step: 11
Training loss: 3.4510304927825928
Validation loss: 2.961741698685513

Epoch: 6| Step: 12
Training loss: 3.4637436866760254
Validation loss: 2.9641565840731383

Epoch: 6| Step: 13
Training loss: 2.794644355773926
Validation loss: 2.9737875359032744

Epoch: 10| Step: 0
Training loss: 3.1334939002990723
Validation loss: 2.9662150259940856

Epoch: 6| Step: 1
Training loss: 3.2550296783447266
Validation loss: 2.9664575822891726

Epoch: 6| Step: 2
Training loss: 2.7298266887664795
Validation loss: 2.9643926851211058

Epoch: 6| Step: 3
Training loss: 3.2093505859375
Validation loss: 2.9598336322333223

Epoch: 6| Step: 4
Training loss: 2.2544474601745605
Validation loss: 2.9594148256445445

Epoch: 6| Step: 5
Training loss: 3.1332292556762695
Validation loss: 2.9591704594191683

Epoch: 6| Step: 6
Training loss: 2.7799882888793945
Validation loss: 2.9548267984902985

Epoch: 6| Step: 7
Training loss: 3.7906150817871094
Validation loss: 2.9486956442556074

Epoch: 6| Step: 8
Training loss: 2.3846426010131836
Validation loss: 2.9394437574571177

Epoch: 6| Step: 9
Training loss: 3.87185001373291
Validation loss: 2.933759438094272

Epoch: 6| Step: 10
Training loss: 3.297105312347412
Validation loss: 2.9313090078292356

Epoch: 6| Step: 11
Training loss: 2.2582435607910156
Validation loss: 2.928470960227392

Epoch: 6| Step: 12
Training loss: 3.3229928016662598
Validation loss: 2.9218194612892727

Epoch: 6| Step: 13
Training loss: 2.926032066345215
Validation loss: 2.921638737442673

Epoch: 11| Step: 0
Training loss: 3.0080323219299316
Validation loss: 2.9169683405148086

Epoch: 6| Step: 1
Training loss: 2.763786554336548
Validation loss: 2.917802431250131

Epoch: 6| Step: 2
Training loss: 2.3481101989746094
Validation loss: 2.91581795805244

Epoch: 6| Step: 3
Training loss: 3.2710886001586914
Validation loss: 2.9150923452069684

Epoch: 6| Step: 4
Training loss: 3.0428929328918457
Validation loss: 2.9082678133441555

Epoch: 6| Step: 5
Training loss: 2.516273021697998
Validation loss: 2.90553891786965

Epoch: 6| Step: 6
Training loss: 3.5508875846862793
Validation loss: 2.900824869832685

Epoch: 6| Step: 7
Training loss: 2.5995194911956787
Validation loss: 2.900524003531343

Epoch: 6| Step: 8
Training loss: 2.9134795665740967
Validation loss: 2.8975953581512615

Epoch: 6| Step: 9
Training loss: 2.694181442260742
Validation loss: 2.896674871444702

Epoch: 6| Step: 10
Training loss: 3.3036797046661377
Validation loss: 2.893946986044607

Epoch: 6| Step: 11
Training loss: 2.746824264526367
Validation loss: 2.8912787206711306

Epoch: 6| Step: 12
Training loss: 4.0454912185668945
Validation loss: 2.888957033875168

Epoch: 6| Step: 13
Training loss: 3.3621456623077393
Validation loss: 2.887850002575946

Epoch: 12| Step: 0
Training loss: 3.7776529788970947
Validation loss: 2.8847308005056074

Epoch: 6| Step: 1
Training loss: 2.508652687072754
Validation loss: 2.880015660357732

Epoch: 6| Step: 2
Training loss: 3.2764534950256348
Validation loss: 2.8773152828216553

Epoch: 6| Step: 3
Training loss: 2.1443538665771484
Validation loss: 2.873052176608834

Epoch: 6| Step: 4
Training loss: 3.219858407974243
Validation loss: 2.8710202068410893

Epoch: 6| Step: 5
Training loss: 2.803961753845215
Validation loss: 2.869858572559972

Epoch: 6| Step: 6
Training loss: 3.236923933029175
Validation loss: 2.868916585881223

Epoch: 6| Step: 7
Training loss: 2.889611005783081
Validation loss: 2.8695488437529533

Epoch: 6| Step: 8
Training loss: 2.6734302043914795
Validation loss: 2.8645752860653784

Epoch: 6| Step: 9
Training loss: 2.9528167247772217
Validation loss: 2.86295090183135

Epoch: 6| Step: 10
Training loss: 3.641831636428833
Validation loss: 2.859856267129221

Epoch: 6| Step: 11
Training loss: 2.261057138442993
Validation loss: 2.858819597510881

Epoch: 6| Step: 12
Training loss: 3.1545262336730957
Validation loss: 2.8610524695406676

Epoch: 6| Step: 13
Training loss: 3.2952933311462402
Validation loss: 2.865024143649686

Epoch: 13| Step: 0
Training loss: 2.9030966758728027
Validation loss: 2.8653275761553036

Epoch: 6| Step: 1
Training loss: 2.9609436988830566
Validation loss: 2.860275255736484

Epoch: 6| Step: 2
Training loss: 2.611453056335449
Validation loss: 2.855418694916592

Epoch: 6| Step: 3
Training loss: 2.782301425933838
Validation loss: 2.8506008783976235

Epoch: 6| Step: 4
Training loss: 3.437408924102783
Validation loss: 2.848693819456203

Epoch: 6| Step: 5
Training loss: 2.930532932281494
Validation loss: 2.845529002528037

Epoch: 6| Step: 6
Training loss: 3.5076608657836914
Validation loss: 2.8508721192677817

Epoch: 6| Step: 7
Training loss: 1.5883327722549438
Validation loss: 2.846775439477736

Epoch: 6| Step: 8
Training loss: 3.2139642238616943
Validation loss: 2.846452671994445

Epoch: 6| Step: 9
Training loss: 3.6842966079711914
Validation loss: 2.8426237362687305

Epoch: 6| Step: 10
Training loss: 2.8420300483703613
Validation loss: 2.842555594700639

Epoch: 6| Step: 11
Training loss: 3.0968017578125
Validation loss: 2.8431106049527406

Epoch: 6| Step: 12
Training loss: 3.3546276092529297
Validation loss: 2.8410491122994372

Epoch: 6| Step: 13
Training loss: 2.283160924911499
Validation loss: 2.8377647322993123

Epoch: 14| Step: 0
Training loss: 2.806154251098633
Validation loss: 2.836199660455027

Epoch: 6| Step: 1
Training loss: 2.6021790504455566
Validation loss: 2.8362115993294665

Epoch: 6| Step: 2
Training loss: 2.2066259384155273
Validation loss: 2.8337830625554568

Epoch: 6| Step: 3
Training loss: 3.069754123687744
Validation loss: 2.835455415069416

Epoch: 6| Step: 4
Training loss: 3.0535969734191895
Validation loss: 2.833317800234723

Epoch: 6| Step: 5
Training loss: 3.2419378757476807
Validation loss: 2.8326051171107958

Epoch: 6| Step: 6
Training loss: 2.9178316593170166
Validation loss: 2.8320741422714724

Epoch: 6| Step: 7
Training loss: 3.2662510871887207
Validation loss: 2.829975361465126

Epoch: 6| Step: 8
Training loss: 3.499796152114868
Validation loss: 2.8298593310899633

Epoch: 6| Step: 9
Training loss: 3.4985885620117188
Validation loss: 2.8272942599429878

Epoch: 6| Step: 10
Training loss: 2.043545961380005
Validation loss: 2.8281481496749388

Epoch: 6| Step: 11
Training loss: 3.552600622177124
Validation loss: 2.826962632517661

Epoch: 6| Step: 12
Training loss: 2.888946771621704
Validation loss: 2.8259987446569625

Epoch: 6| Step: 13
Training loss: 2.4458134174346924
Validation loss: 2.825742280611428

Epoch: 15| Step: 0
Training loss: 3.8158464431762695
Validation loss: 2.825194976663077

Epoch: 6| Step: 1
Training loss: 3.206727981567383
Validation loss: 2.8236724535624185

Epoch: 6| Step: 2
Training loss: 3.9286460876464844
Validation loss: 2.8317542460656937

Epoch: 6| Step: 3
Training loss: 2.5633275508880615
Validation loss: 2.817194510531682

Epoch: 6| Step: 4
Training loss: 2.942230224609375
Validation loss: 2.818986755545421

Epoch: 6| Step: 5
Training loss: 2.18091082572937
Validation loss: 2.8181408579631517

Epoch: 6| Step: 6
Training loss: 3.4849352836608887
Validation loss: 2.81825687039283

Epoch: 6| Step: 7
Training loss: 2.198575973510742
Validation loss: 2.821312209611298

Epoch: 6| Step: 8
Training loss: 3.0064191818237305
Validation loss: 2.8214290936787925

Epoch: 6| Step: 9
Training loss: 2.469432830810547
Validation loss: 2.8154506068075857

Epoch: 6| Step: 10
Training loss: 2.970984935760498
Validation loss: 2.81638575625676

Epoch: 6| Step: 11
Training loss: 3.250943660736084
Validation loss: 2.813687345033051

Epoch: 6| Step: 12
Training loss: 2.3757400512695312
Validation loss: 2.8131979973085466

Epoch: 6| Step: 13
Training loss: 2.7787933349609375
Validation loss: 2.8128094378338067

Epoch: 16| Step: 0
Training loss: 2.7247390747070312
Validation loss: 2.814972864684238

Epoch: 6| Step: 1
Training loss: 2.9923949241638184
Validation loss: 2.812844422555739

Epoch: 6| Step: 2
Training loss: 3.7645328044891357
Validation loss: 2.8116783557399625

Epoch: 6| Step: 3
Training loss: 3.2438557147979736
Validation loss: 2.809488232417773

Epoch: 6| Step: 4
Training loss: 3.827073335647583
Validation loss: 2.806243893920734

Epoch: 6| Step: 5
Training loss: 2.8376479148864746
Validation loss: 2.80513265825087

Epoch: 6| Step: 6
Training loss: 2.7032577991485596
Validation loss: 2.806396286974671

Epoch: 6| Step: 7
Training loss: 4.224771976470947
Validation loss: 2.8046822855549474

Epoch: 6| Step: 8
Training loss: 1.5057358741760254
Validation loss: 2.803664861186858

Epoch: 6| Step: 9
Training loss: 1.9964849948883057
Validation loss: 2.804927756709437

Epoch: 6| Step: 10
Training loss: 2.4375953674316406
Validation loss: 2.7994060977812736

Epoch: 6| Step: 11
Training loss: 2.7511539459228516
Validation loss: 2.801603432624571

Epoch: 6| Step: 12
Training loss: 2.442826747894287
Validation loss: 2.803109271551973

Epoch: 6| Step: 13
Training loss: 4.212737560272217
Validation loss: 2.8015802188586165

Epoch: 17| Step: 0
Training loss: 2.5122570991516113
Validation loss: 2.798502532384729

Epoch: 6| Step: 1
Training loss: 2.2313854694366455
Validation loss: 2.7997551425810783

Epoch: 6| Step: 2
Training loss: 3.5953943729400635
Validation loss: 2.7935049149297897

Epoch: 6| Step: 3
Training loss: 3.201274871826172
Validation loss: 2.7937913428070726

Epoch: 6| Step: 4
Training loss: 2.0035338401794434
Validation loss: 2.792615521338678

Epoch: 6| Step: 5
Training loss: 3.001020908355713
Validation loss: 2.7969379758322113

Epoch: 6| Step: 6
Training loss: 2.9123740196228027
Validation loss: 2.7963946147631575

Epoch: 6| Step: 7
Training loss: 2.755479335784912
Validation loss: 2.7918049725153113

Epoch: 6| Step: 8
Training loss: 3.6497254371643066
Validation loss: 2.7890436469867663

Epoch: 6| Step: 9
Training loss: 3.01255464553833
Validation loss: 2.791052472206854

Epoch: 6| Step: 10
Training loss: 2.4857490062713623
Validation loss: 2.786855456649616

Epoch: 6| Step: 11
Training loss: 4.170197486877441
Validation loss: 2.787691629061135

Epoch: 6| Step: 12
Training loss: 2.4200737476348877
Validation loss: 2.7856617948060394

Epoch: 6| Step: 13
Training loss: 3.1407692432403564
Validation loss: 2.7850005985588155

Epoch: 18| Step: 0
Training loss: 3.134601354598999
Validation loss: 2.781713257553757

Epoch: 6| Step: 1
Training loss: 2.942955493927002
Validation loss: 2.7808854144106627

Epoch: 6| Step: 2
Training loss: 2.440502643585205
Validation loss: 2.7821739283941125

Epoch: 6| Step: 3
Training loss: 3.271911382675171
Validation loss: 2.7814708832771546

Epoch: 6| Step: 4
Training loss: 3.09780216217041
Validation loss: 2.7795732610969135

Epoch: 6| Step: 5
Training loss: 3.5132155418395996
Validation loss: 2.778723455244495

Epoch: 6| Step: 6
Training loss: 2.842794179916382
Validation loss: 2.77745000649524

Epoch: 6| Step: 7
Training loss: 3.5507164001464844
Validation loss: 2.778399493104668

Epoch: 6| Step: 8
Training loss: 2.643493413925171
Validation loss: 2.777134959415723

Epoch: 6| Step: 9
Training loss: 2.672713041305542
Validation loss: 2.778545992348784

Epoch: 6| Step: 10
Training loss: 2.9892749786376953
Validation loss: 2.783715727508709

Epoch: 6| Step: 11
Training loss: 2.462303876876831
Validation loss: 2.7851469337299304

Epoch: 6| Step: 12
Training loss: 2.787473201751709
Validation loss: 2.7742368123864614

Epoch: 6| Step: 13
Training loss: 2.158644914627075
Validation loss: 2.7723735532452984

Epoch: 19| Step: 0
Training loss: 3.279167652130127
Validation loss: 2.775585735997846

Epoch: 6| Step: 1
Training loss: 2.752354383468628
Validation loss: 2.7744359406091834

Epoch: 6| Step: 2
Training loss: 2.0497026443481445
Validation loss: 2.772952413046232

Epoch: 6| Step: 3
Training loss: 2.2686970233917236
Validation loss: 2.7686779063235045

Epoch: 6| Step: 4
Training loss: 3.654275417327881
Validation loss: 2.768772030389437

Epoch: 6| Step: 5
Training loss: 2.451868772506714
Validation loss: 2.770319168285657

Epoch: 6| Step: 6
Training loss: 2.1373496055603027
Validation loss: 2.771108353009788

Epoch: 6| Step: 7
Training loss: 3.8784701824188232
Validation loss: 2.7688576226593344

Epoch: 6| Step: 8
Training loss: 3.690195083618164
Validation loss: 2.7656653978491343

Epoch: 6| Step: 9
Training loss: 2.879283905029297
Validation loss: 2.7631980629377466

Epoch: 6| Step: 10
Training loss: 3.0481204986572266
Validation loss: 2.768490422156549

Epoch: 6| Step: 11
Training loss: 2.923687219619751
Validation loss: 2.7795967850633847

Epoch: 6| Step: 12
Training loss: 2.612762212753296
Validation loss: 2.7663107995064027

Epoch: 6| Step: 13
Training loss: 3.270028591156006
Validation loss: 2.7695656591846096

Epoch: 20| Step: 0
Training loss: 2.585897922515869
Validation loss: 2.7689102670197845

Epoch: 6| Step: 1
Training loss: 3.261486530303955
Validation loss: 2.761671866140058

Epoch: 6| Step: 2
Training loss: 2.7764251232147217
Validation loss: 2.771672479567989

Epoch: 6| Step: 3
Training loss: 3.552976131439209
Validation loss: 2.7734355183057886

Epoch: 6| Step: 4
Training loss: 3.9372520446777344
Validation loss: 2.760090781796363

Epoch: 6| Step: 5
Training loss: 2.7479922771453857
Validation loss: 2.7626628004094607

Epoch: 6| Step: 6
Training loss: 2.7791738510131836
Validation loss: 2.7618762139351136

Epoch: 6| Step: 7
Training loss: 2.881430149078369
Validation loss: 2.7632580880195863

Epoch: 6| Step: 8
Training loss: 2.6225600242614746
Validation loss: 2.7686611631865143

Epoch: 6| Step: 9
Training loss: 2.4687676429748535
Validation loss: 2.762244055348058

Epoch: 6| Step: 10
Training loss: 2.85548734664917
Validation loss: 2.7590711603882494

Epoch: 6| Step: 11
Training loss: 3.054922103881836
Validation loss: 2.760908105040109

Epoch: 6| Step: 12
Training loss: 2.5530498027801514
Validation loss: 2.7593531429126696

Epoch: 6| Step: 13
Training loss: 2.265322685241699
Validation loss: 2.758393656822943

Epoch: 21| Step: 0
Training loss: 2.466308116912842
Validation loss: 2.8094941441730787

Epoch: 6| Step: 1
Training loss: 3.6112680435180664
Validation loss: 2.9398478923305387

Epoch: 6| Step: 2
Training loss: 2.1250741481781006
Validation loss: 2.9292925916692263

Epoch: 6| Step: 3
Training loss: 3.3009235858917236
Validation loss: 2.935554455685359

Epoch: 6| Step: 4
Training loss: 3.281679630279541
Validation loss: 2.862636225197905

Epoch: 6| Step: 5
Training loss: 3.5467162132263184
Validation loss: 2.814980419733191

Epoch: 6| Step: 6
Training loss: 2.721813678741455
Validation loss: 2.7592965069637505

Epoch: 6| Step: 7
Training loss: 2.6927313804626465
Validation loss: 2.789665332404516

Epoch: 6| Step: 8
Training loss: 3.07267427444458
Validation loss: 2.841942761534004

Epoch: 6| Step: 9
Training loss: 2.9670729637145996
Validation loss: 2.906310737773936

Epoch: 6| Step: 10
Training loss: 2.674323081970215
Validation loss: 2.853581408018707

Epoch: 6| Step: 11
Training loss: 2.915736198425293
Validation loss: 2.780496874163228

Epoch: 6| Step: 12
Training loss: 3.1830906867980957
Validation loss: 2.7799651853499876

Epoch: 6| Step: 13
Training loss: 2.8377456665039062
Validation loss: 2.822400221260645

Epoch: 22| Step: 0
Training loss: 2.432178020477295
Validation loss: 2.864376142460813

Epoch: 6| Step: 1
Training loss: 3.540339469909668
Validation loss: 2.8947232077198644

Epoch: 6| Step: 2
Training loss: 3.071333408355713
Validation loss: 2.9211689861871863

Epoch: 6| Step: 3
Training loss: 3.131779909133911
Validation loss: 2.875506995826639

Epoch: 6| Step: 4
Training loss: 2.648242473602295
Validation loss: 2.8369214432213896

Epoch: 6| Step: 5
Training loss: 3.1403770446777344
Validation loss: 2.830792793663599

Epoch: 6| Step: 6
Training loss: 3.1595280170440674
Validation loss: 2.8127100518954697

Epoch: 6| Step: 7
Training loss: 2.7763867378234863
Validation loss: 2.8240494215360252

Epoch: 6| Step: 8
Training loss: 2.4240479469299316
Validation loss: 2.826027783014441

Epoch: 6| Step: 9
Training loss: 3.1176860332489014
Validation loss: 2.8215112250338317

Epoch: 6| Step: 10
Training loss: 3.7090353965759277
Validation loss: 2.8225258140153784

Epoch: 6| Step: 11
Training loss: 2.6345043182373047
Validation loss: 2.820921185196087

Epoch: 6| Step: 12
Training loss: 2.5142695903778076
Validation loss: 2.823308111518942

Epoch: 6| Step: 13
Training loss: 3.2188291549682617
Validation loss: 2.8202251567635486

Epoch: 23| Step: 0
Training loss: 3.0238900184631348
Validation loss: 2.817735372051116

Epoch: 6| Step: 1
Training loss: 2.820012331008911
Validation loss: 2.809200002301124

Epoch: 6| Step: 2
Training loss: 3.3069448471069336
Validation loss: 2.809773463074879

Epoch: 6| Step: 3
Training loss: 2.983257293701172
Validation loss: 2.808400459187005

Epoch: 6| Step: 4
Training loss: 2.201815605163574
Validation loss: 2.7949968127794165

Epoch: 6| Step: 5
Training loss: 2.8830103874206543
Validation loss: 2.807082906846077

Epoch: 6| Step: 6
Training loss: 3.2938332557678223
Validation loss: 2.8068072744595107

Epoch: 6| Step: 7
Training loss: 2.988955020904541
Validation loss: 2.810368235393237

Epoch: 6| Step: 8
Training loss: 2.958955764770508
Validation loss: 2.8153400600597425

Epoch: 6| Step: 9
Training loss: 2.4061717987060547
Validation loss: 2.82789945602417

Epoch: 6| Step: 10
Training loss: 3.5711824893951416
Validation loss: 2.850433898228471

Epoch: 6| Step: 11
Training loss: 2.798185110092163
Validation loss: 2.8340426209152385

Epoch: 6| Step: 12
Training loss: 2.8122799396514893
Validation loss: 2.811351340304139

Epoch: 6| Step: 13
Training loss: 3.2585947513580322
Validation loss: 2.807446259324269

Epoch: 24| Step: 0
Training loss: 2.261702060699463
Validation loss: 2.8002509532436246

Epoch: 6| Step: 1
Training loss: 2.288990020751953
Validation loss: 2.800677312317715

Epoch: 6| Step: 2
Training loss: 2.9318532943725586
Validation loss: 2.7941948239521315

Epoch: 6| Step: 3
Training loss: 2.8872971534729004
Validation loss: 2.798492762350267

Epoch: 6| Step: 4
Training loss: 3.320274829864502
Validation loss: 2.797708552370789

Epoch: 6| Step: 5
Training loss: 2.8440961837768555
Validation loss: 2.7952658540459088

Epoch: 6| Step: 6
Training loss: 3.0462448596954346
Validation loss: 2.7955715374280046

Epoch: 6| Step: 7
Training loss: 3.508648633956909
Validation loss: 2.794245796818887

Epoch: 6| Step: 8
Training loss: 3.1947429180145264
Validation loss: 2.795991164381786

Epoch: 6| Step: 9
Training loss: 2.991868495941162
Validation loss: 2.799876992420484

Epoch: 6| Step: 10
Training loss: 2.647132158279419
Validation loss: 2.7939256391217633

Epoch: 6| Step: 11
Training loss: 2.1806223392486572
Validation loss: 2.796960025705317

Epoch: 6| Step: 12
Training loss: 4.110410690307617
Validation loss: 2.794524610683482

Epoch: 6| Step: 13
Training loss: 2.584409236907959
Validation loss: 2.7912985278714086

Epoch: 25| Step: 0
Training loss: 3.3035404682159424
Validation loss: 2.7884746597659205

Epoch: 6| Step: 1
Training loss: 2.221057415008545
Validation loss: 2.7888839757570656

Epoch: 6| Step: 2
Training loss: 2.8435943126678467
Validation loss: 2.7812153011239986

Epoch: 6| Step: 3
Training loss: 3.5263237953186035
Validation loss: 2.778960281802762

Epoch: 6| Step: 4
Training loss: 2.925818920135498
Validation loss: 2.7592058130489883

Epoch: 6| Step: 5
Training loss: 3.101475715637207
Validation loss: 2.754213099838585

Epoch: 6| Step: 6
Training loss: 2.4636361598968506
Validation loss: 2.835437059402466

Epoch: 6| Step: 7
Training loss: 3.526801586151123
Validation loss: 2.9562770858887704

Epoch: 6| Step: 8
Training loss: 2.521428346633911
Validation loss: 2.8909192905631116

Epoch: 6| Step: 9
Training loss: 3.047407627105713
Validation loss: 2.7722945828591623

Epoch: 6| Step: 10
Training loss: 2.9464902877807617
Validation loss: 2.7287773086178686

Epoch: 6| Step: 11
Training loss: 2.8412864208221436
Validation loss: 2.7145025268677743

Epoch: 6| Step: 12
Training loss: 2.6932077407836914
Validation loss: 2.729972393281998

Epoch: 6| Step: 13
Training loss: 3.2490575313568115
Validation loss: 2.783680042912883

Epoch: 26| Step: 0
Training loss: 2.3933165073394775
Validation loss: 2.845770305202853

Epoch: 6| Step: 1
Training loss: 2.830029249191284
Validation loss: 2.8978992662122174

Epoch: 6| Step: 2
Training loss: 2.1362338066101074
Validation loss: 2.8941004635185323

Epoch: 6| Step: 3
Training loss: 2.886014938354492
Validation loss: 2.8820084346238004

Epoch: 6| Step: 4
Training loss: 2.7798638343811035
Validation loss: 2.886023767532841

Epoch: 6| Step: 5
Training loss: 3.715933322906494
Validation loss: 2.876051405424713

Epoch: 6| Step: 6
Training loss: 3.2543857097625732
Validation loss: 2.851339099227741

Epoch: 6| Step: 7
Training loss: 2.853031635284424
Validation loss: 2.814127004274758

Epoch: 6| Step: 8
Training loss: 2.219137191772461
Validation loss: 2.769222479994579

Epoch: 6| Step: 9
Training loss: 2.4796395301818848
Validation loss: 2.709113590178951

Epoch: 6| Step: 10
Training loss: 3.6814911365509033
Validation loss: 2.7163525345504924

Epoch: 6| Step: 11
Training loss: 3.210439682006836
Validation loss: 2.7308293106735393

Epoch: 6| Step: 12
Training loss: 3.1585240364074707
Validation loss: 2.7323145866394043

Epoch: 6| Step: 13
Training loss: 3.5141961574554443
Validation loss: 2.7270893435324393

Epoch: 27| Step: 0
Training loss: 1.8986281156539917
Validation loss: 2.725695458791589

Epoch: 6| Step: 1
Training loss: 3.5818963050842285
Validation loss: 2.7082809402096655

Epoch: 6| Step: 2
Training loss: 2.926990032196045
Validation loss: 2.690268883141138

Epoch: 6| Step: 3
Training loss: 3.3645710945129395
Validation loss: 2.6912343168771393

Epoch: 6| Step: 4
Training loss: 2.617476224899292
Validation loss: 2.6996570966577016

Epoch: 6| Step: 5
Training loss: 3.3914928436279297
Validation loss: 2.709823813489688

Epoch: 6| Step: 6
Training loss: 3.172978639602661
Validation loss: 2.7197306797068608

Epoch: 6| Step: 7
Training loss: 2.4489216804504395
Validation loss: 2.7041177288178475

Epoch: 6| Step: 8
Training loss: 2.060032844543457
Validation loss: 2.7085453592320925

Epoch: 6| Step: 9
Training loss: 2.6144754886627197
Validation loss: 2.689208730574577

Epoch: 6| Step: 10
Training loss: 2.758429527282715
Validation loss: 2.679611313727594

Epoch: 6| Step: 11
Training loss: 2.9079203605651855
Validation loss: 2.6875685876415623

Epoch: 6| Step: 12
Training loss: 3.2636559009552
Validation loss: 2.692640842929963

Epoch: 6| Step: 13
Training loss: 3.3051342964172363
Validation loss: 2.6969333694827173

Epoch: 28| Step: 0
Training loss: 2.509277105331421
Validation loss: 2.705824969917215

Epoch: 6| Step: 1
Training loss: 3.1190805435180664
Validation loss: 2.726468970698695

Epoch: 6| Step: 2
Training loss: 3.6216354370117188
Validation loss: 2.719328893128262

Epoch: 6| Step: 3
Training loss: 3.4453232288360596
Validation loss: 2.695739266692951

Epoch: 6| Step: 4
Training loss: 2.594912528991699
Validation loss: 2.685577674578595

Epoch: 6| Step: 5
Training loss: 2.668567180633545
Validation loss: 2.683998579620033

Epoch: 6| Step: 6
Training loss: 2.9665675163269043
Validation loss: 2.6786765693336405

Epoch: 6| Step: 7
Training loss: 2.53940486907959
Validation loss: 2.677271601974323

Epoch: 6| Step: 8
Training loss: 3.319958448410034
Validation loss: 2.674136256658903

Epoch: 6| Step: 9
Training loss: 2.746734857559204
Validation loss: 2.67983405820785

Epoch: 6| Step: 10
Training loss: 2.975419521331787
Validation loss: 2.675513529008435

Epoch: 6| Step: 11
Training loss: 2.45993709564209
Validation loss: 2.6697916933285293

Epoch: 6| Step: 12
Training loss: 2.445249557495117
Validation loss: 2.6705961868327153

Epoch: 6| Step: 13
Training loss: 2.345813035964966
Validation loss: 2.6704308320117254

Epoch: 29| Step: 0
Training loss: 2.867746353149414
Validation loss: 2.669420357673399

Epoch: 6| Step: 1
Training loss: 2.3330001831054688
Validation loss: 2.6658791957363004

Epoch: 6| Step: 2
Training loss: 2.382638454437256
Validation loss: 2.6654567974869923

Epoch: 6| Step: 3
Training loss: 2.1833689212799072
Validation loss: 2.660548492144513

Epoch: 6| Step: 4
Training loss: 2.7361698150634766
Validation loss: 2.660603279708534

Epoch: 6| Step: 5
Training loss: 3.180250883102417
Validation loss: 2.6584630653422368

Epoch: 6| Step: 6
Training loss: 3.5559704303741455
Validation loss: 2.6561551247873614

Epoch: 6| Step: 7
Training loss: 3.2796335220336914
Validation loss: 2.6496389245474212

Epoch: 6| Step: 8
Training loss: 3.45867657661438
Validation loss: 2.648898075985652

Epoch: 6| Step: 9
Training loss: 2.1440701484680176
Validation loss: 2.6443032192927536

Epoch: 6| Step: 10
Training loss: 2.584045648574829
Validation loss: 2.6444473753693285

Epoch: 6| Step: 11
Training loss: 3.601856231689453
Validation loss: 2.6410922875968357

Epoch: 6| Step: 12
Training loss: 2.2779006958007812
Validation loss: 2.6408771699474705

Epoch: 6| Step: 13
Training loss: 3.1630659103393555
Validation loss: 2.6443957090377808

Epoch: 30| Step: 0
Training loss: 3.2285921573638916
Validation loss: 2.6451834119776243

Epoch: 6| Step: 1
Training loss: 2.885718822479248
Validation loss: 2.650092960685812

Epoch: 6| Step: 2
Training loss: 3.153229236602783
Validation loss: 2.658698404988935

Epoch: 6| Step: 3
Training loss: 3.49812650680542
Validation loss: 2.6689881509350193

Epoch: 6| Step: 4
Training loss: 2.517347812652588
Validation loss: 2.657793650063135

Epoch: 6| Step: 5
Training loss: 2.818812608718872
Validation loss: 2.649945210385066

Epoch: 6| Step: 6
Training loss: 3.154275417327881
Validation loss: 2.6379729983627156

Epoch: 6| Step: 7
Training loss: 2.684670925140381
Validation loss: 2.6322776348360124

Epoch: 6| Step: 8
Training loss: 2.2090272903442383
Validation loss: 2.6339112968855005

Epoch: 6| Step: 9
Training loss: 2.3837809562683105
Validation loss: 2.63560031049995

Epoch: 6| Step: 10
Training loss: 2.5650582313537598
Validation loss: 2.639468087944933

Epoch: 6| Step: 11
Training loss: 2.261650800704956
Validation loss: 2.641773259767922

Epoch: 6| Step: 12
Training loss: 3.1377484798431396
Validation loss: 2.6345943609873452

Epoch: 6| Step: 13
Training loss: 3.245918035507202
Validation loss: 2.627837760474092

Epoch: 31| Step: 0
Training loss: 2.4500691890716553
Validation loss: 2.626556811794158

Epoch: 6| Step: 1
Training loss: 3.2467594146728516
Validation loss: 2.633488262853315

Epoch: 6| Step: 2
Training loss: 3.2215688228607178
Validation loss: 2.6421554678229877

Epoch: 6| Step: 3
Training loss: 2.566525459289551
Validation loss: 2.6267672584902857

Epoch: 6| Step: 4
Training loss: 2.6298980712890625
Validation loss: 2.6212455534165904

Epoch: 6| Step: 5
Training loss: 2.8284811973571777
Validation loss: 2.6212158946580786

Epoch: 6| Step: 6
Training loss: 2.802316665649414
Validation loss: 2.6193845169518584

Epoch: 6| Step: 7
Training loss: 3.5377910137176514
Validation loss: 2.621274940429195

Epoch: 6| Step: 8
Training loss: 3.117872476577759
Validation loss: 2.6207080605209514

Epoch: 6| Step: 9
Training loss: 2.6696953773498535
Validation loss: 2.6183169400820168

Epoch: 6| Step: 10
Training loss: 2.71384596824646
Validation loss: 2.6185140866105274

Epoch: 6| Step: 11
Training loss: 1.6841442584991455
Validation loss: 2.622468897091445

Epoch: 6| Step: 12
Training loss: 2.8338048458099365
Validation loss: 2.621720032025409

Epoch: 6| Step: 13
Training loss: 3.066805839538574
Validation loss: 2.6286873996898694

Epoch: 32| Step: 0
Training loss: 2.345592975616455
Validation loss: 2.6216044656692015

Epoch: 6| Step: 1
Training loss: 2.275225877761841
Validation loss: 2.6156000039910756

Epoch: 6| Step: 2
Training loss: 3.388352155685425
Validation loss: 2.6150332266284573

Epoch: 6| Step: 3
Training loss: 2.03208589553833
Validation loss: 2.615706459168465

Epoch: 6| Step: 4
Training loss: 3.340057849884033
Validation loss: 2.6257869889659267

Epoch: 6| Step: 5
Training loss: 3.1834003925323486
Validation loss: 2.6306684811909995

Epoch: 6| Step: 6
Training loss: 3.1895828247070312
Validation loss: 2.6323010536932174

Epoch: 6| Step: 7
Training loss: 2.5161919593811035
Validation loss: 2.624351745010704

Epoch: 6| Step: 8
Training loss: 3.1245412826538086
Validation loss: 2.6117268480280393

Epoch: 6| Step: 9
Training loss: 2.611957550048828
Validation loss: 2.617725323605281

Epoch: 6| Step: 10
Training loss: 2.3600401878356934
Validation loss: 2.6235750311164447

Epoch: 6| Step: 11
Training loss: 2.9624619483947754
Validation loss: 2.6167426698951313

Epoch: 6| Step: 12
Training loss: 2.554961681365967
Validation loss: 2.6215345218617427

Epoch: 6| Step: 13
Training loss: 3.663309335708618
Validation loss: 2.6246378934511574

Epoch: 33| Step: 0
Training loss: 3.1903960704803467
Validation loss: 2.610618063198623

Epoch: 6| Step: 1
Training loss: 2.993314266204834
Validation loss: 2.6093554419855916

Epoch: 6| Step: 2
Training loss: 2.9965767860412598
Validation loss: 2.6043593524604716

Epoch: 6| Step: 3
Training loss: 3.0871405601501465
Validation loss: 2.601889569272277

Epoch: 6| Step: 4
Training loss: 2.8173866271972656
Validation loss: 2.6017593235097904

Epoch: 6| Step: 5
Training loss: 2.946181058883667
Validation loss: 2.6037212135971233

Epoch: 6| Step: 6
Training loss: 2.936908006668091
Validation loss: 2.6075386924128376

Epoch: 6| Step: 7
Training loss: 2.812373161315918
Validation loss: 2.6053134446503012

Epoch: 6| Step: 8
Training loss: 2.263836622238159
Validation loss: 2.6036740118457424

Epoch: 6| Step: 9
Training loss: 2.937070608139038
Validation loss: 2.6015895771723923

Epoch: 6| Step: 10
Training loss: 2.5212769508361816
Validation loss: 2.5965545100550496

Epoch: 6| Step: 11
Training loss: 2.4026923179626465
Validation loss: 2.5957507882066952

Epoch: 6| Step: 12
Training loss: 2.817983627319336
Validation loss: 2.6185875759329846

Epoch: 6| Step: 13
Training loss: 1.8312115669250488
Validation loss: 2.6387330332110004

Epoch: 34| Step: 0
Training loss: 3.1096529960632324
Validation loss: 2.680558850688319

Epoch: 6| Step: 1
Training loss: 2.5919084548950195
Validation loss: 2.7208454634553645

Epoch: 6| Step: 2
Training loss: 3.266885757446289
Validation loss: 2.713600968801847

Epoch: 6| Step: 3
Training loss: 2.0252175331115723
Validation loss: 2.6876279333586335

Epoch: 6| Step: 4
Training loss: 2.941408395767212
Validation loss: 2.675617884564143

Epoch: 6| Step: 5
Training loss: 2.7695629596710205
Validation loss: 2.667897896100116

Epoch: 6| Step: 6
Training loss: 2.895033597946167
Validation loss: 2.6109002226142475

Epoch: 6| Step: 7
Training loss: 2.9009618759155273
Validation loss: 2.5953743329612156

Epoch: 6| Step: 8
Training loss: 2.6335458755493164
Validation loss: 2.629161834716797

Epoch: 6| Step: 9
Training loss: 2.2700750827789307
Validation loss: 2.655861667407456

Epoch: 6| Step: 10
Training loss: 3.731081485748291
Validation loss: 2.6936268703911894

Epoch: 6| Step: 11
Training loss: 2.292424201965332
Validation loss: 2.6882624139067945

Epoch: 6| Step: 12
Training loss: 3.126232862472534
Validation loss: 2.691427259035008

Epoch: 6| Step: 13
Training loss: 3.3726420402526855
Validation loss: 2.6501383730160293

Epoch: 35| Step: 0
Training loss: 3.0996203422546387
Validation loss: 2.610953518139419

Epoch: 6| Step: 1
Training loss: 3.1604366302490234
Validation loss: 2.5893426505468224

Epoch: 6| Step: 2
Training loss: 2.4983372688293457
Validation loss: 2.5946277520989858

Epoch: 6| Step: 3
Training loss: 3.2778830528259277
Validation loss: 2.620183088446176

Epoch: 6| Step: 4
Training loss: 2.9751882553100586
Validation loss: 2.632683830876504

Epoch: 6| Step: 5
Training loss: 2.395106792449951
Validation loss: 2.6129110346558275

Epoch: 6| Step: 6
Training loss: 2.637277603149414
Validation loss: 2.587225870419574

Epoch: 6| Step: 7
Training loss: 2.965641975402832
Validation loss: 2.5788950381740445

Epoch: 6| Step: 8
Training loss: 2.1780824661254883
Validation loss: 2.5922780908564085

Epoch: 6| Step: 9
Training loss: 2.5059549808502197
Validation loss: 2.601138371293263

Epoch: 6| Step: 10
Training loss: 2.447293519973755
Validation loss: 2.6056934146470923

Epoch: 6| Step: 11
Training loss: 2.877798318862915
Validation loss: 2.6208962009799097

Epoch: 6| Step: 12
Training loss: 3.1019158363342285
Validation loss: 2.6312537372753186

Epoch: 6| Step: 13
Training loss: 3.155787467956543
Validation loss: 2.631243154566775

Epoch: 36| Step: 0
Training loss: 2.855950355529785
Validation loss: 2.6260959204807075

Epoch: 6| Step: 1
Training loss: 2.313552141189575
Validation loss: 2.6145674849069245

Epoch: 6| Step: 2
Training loss: 3.1216797828674316
Validation loss: 2.607146078540433

Epoch: 6| Step: 3
Training loss: 2.4972729682922363
Validation loss: 2.5965676230769

Epoch: 6| Step: 4
Training loss: 3.0451011657714844
Validation loss: 2.589558493706488

Epoch: 6| Step: 5
Training loss: 3.153182029724121
Validation loss: 2.585455871397449

Epoch: 6| Step: 6
Training loss: 3.596308469772339
Validation loss: 2.574871604160596

Epoch: 6| Step: 7
Training loss: 2.499640941619873
Validation loss: 2.5717408067436627

Epoch: 6| Step: 8
Training loss: 3.2299845218658447
Validation loss: 2.573480118987381

Epoch: 6| Step: 9
Training loss: 2.450911045074463
Validation loss: 2.5745619214991087

Epoch: 6| Step: 10
Training loss: 2.4353699684143066
Validation loss: 2.573149022235665

Epoch: 6| Step: 11
Training loss: 2.893955707550049
Validation loss: 2.567847862038561

Epoch: 6| Step: 12
Training loss: 1.7080811262130737
Validation loss: 2.5744611140220397

Epoch: 6| Step: 13
Training loss: 3.1335415840148926
Validation loss: 2.5803996926994732

Epoch: 37| Step: 0
Training loss: 2.9545257091522217
Validation loss: 2.581780997655725

Epoch: 6| Step: 1
Training loss: 1.8925912380218506
Validation loss: 2.574955504427674

Epoch: 6| Step: 2
Training loss: 2.3990635871887207
Validation loss: 2.565019246070616

Epoch: 6| Step: 3
Training loss: 2.3115620613098145
Validation loss: 2.561059016053395

Epoch: 6| Step: 4
Training loss: 2.555295705795288
Validation loss: 2.5677576911064888

Epoch: 6| Step: 5
Training loss: 2.5969886779785156
Validation loss: 2.5714057645490094

Epoch: 6| Step: 6
Training loss: 3.104376792907715
Validation loss: 2.566509034043999

Epoch: 6| Step: 7
Training loss: 3.3591196537017822
Validation loss: 2.5710610266654723

Epoch: 6| Step: 8
Training loss: 2.9550323486328125
Validation loss: 2.5658560235013246

Epoch: 6| Step: 9
Training loss: 2.875256299972534
Validation loss: 2.5636777108715427

Epoch: 6| Step: 10
Training loss: 2.5701522827148438
Validation loss: 2.5592919165088284

Epoch: 6| Step: 11
Training loss: 2.817955493927002
Validation loss: 2.557022871509675

Epoch: 6| Step: 12
Training loss: 2.712094783782959
Validation loss: 2.559617039977863

Epoch: 6| Step: 13
Training loss: 4.303016185760498
Validation loss: 2.5631443403100453

Epoch: 38| Step: 0
Training loss: 2.042175054550171
Validation loss: 2.5607042927895822

Epoch: 6| Step: 1
Training loss: 2.2948663234710693
Validation loss: 2.5600289119187223

Epoch: 6| Step: 2
Training loss: 3.2663583755493164
Validation loss: 2.556089042335428

Epoch: 6| Step: 3
Training loss: 2.7111878395080566
Validation loss: 2.5548502322166198

Epoch: 6| Step: 4
Training loss: 1.6078119277954102
Validation loss: 2.5542213968051377

Epoch: 6| Step: 5
Training loss: 3.279387950897217
Validation loss: 2.553016380597186

Epoch: 6| Step: 6
Training loss: 2.4700756072998047
Validation loss: 2.55542415700933

Epoch: 6| Step: 7
Training loss: 3.0928893089294434
Validation loss: 2.550914377294561

Epoch: 6| Step: 8
Training loss: 2.467925548553467
Validation loss: 2.548911189520231

Epoch: 6| Step: 9
Training loss: 2.877610206604004
Validation loss: 2.5449726620028095

Epoch: 6| Step: 10
Training loss: 3.1610026359558105
Validation loss: 2.5496829940426733

Epoch: 6| Step: 11
Training loss: 3.150289297103882
Validation loss: 2.5490816229133197

Epoch: 6| Step: 12
Training loss: 3.252387523651123
Validation loss: 2.550563763546687

Epoch: 6| Step: 13
Training loss: 2.679548501968384
Validation loss: 2.5530182648730535

Epoch: 39| Step: 0
Training loss: 2.6045660972595215
Validation loss: 2.551870779324603

Epoch: 6| Step: 1
Training loss: 2.216236114501953
Validation loss: 2.551294183218351

Epoch: 6| Step: 2
Training loss: 2.6759676933288574
Validation loss: 2.5506502659090105

Epoch: 6| Step: 3
Training loss: 2.725220203399658
Validation loss: 2.549884086014122

Epoch: 6| Step: 4
Training loss: 2.741759777069092
Validation loss: 2.5429445235959944

Epoch: 6| Step: 5
Training loss: 3.131471633911133
Validation loss: 2.5416975072635117

Epoch: 6| Step: 6
Training loss: 2.3484902381896973
Validation loss: 2.536097462459277

Epoch: 6| Step: 7
Training loss: 2.3318986892700195
Validation loss: 2.5350712268583235

Epoch: 6| Step: 8
Training loss: 2.38328218460083
Validation loss: 2.5421578884124756

Epoch: 6| Step: 9
Training loss: 3.1836771965026855
Validation loss: 2.541865702598326

Epoch: 6| Step: 10
Training loss: 3.1922638416290283
Validation loss: 2.538895550594535

Epoch: 6| Step: 11
Training loss: 3.2722482681274414
Validation loss: 2.5314714985509075

Epoch: 6| Step: 12
Training loss: 2.7391750812530518
Validation loss: 2.5325895073593303

Epoch: 6| Step: 13
Training loss: 2.833559274673462
Validation loss: 2.5300873735899567

Epoch: 40| Step: 0
Training loss: 2.526494026184082
Validation loss: 2.528235230394589

Epoch: 6| Step: 1
Training loss: 3.1537656784057617
Validation loss: 2.532045154161351

Epoch: 6| Step: 2
Training loss: 2.0941996574401855
Validation loss: 2.53159838081688

Epoch: 6| Step: 3
Training loss: 2.1537928581237793
Validation loss: 2.530117419458205

Epoch: 6| Step: 4
Training loss: 2.8081789016723633
Validation loss: 2.5323261919841973

Epoch: 6| Step: 5
Training loss: 2.1152539253234863
Validation loss: 2.534203644721739

Epoch: 6| Step: 6
Training loss: 3.6166467666625977
Validation loss: 2.5396005440783758

Epoch: 6| Step: 7
Training loss: 2.9489760398864746
Validation loss: 2.533295644226895

Epoch: 6| Step: 8
Training loss: 2.928609848022461
Validation loss: 2.5319592081090456

Epoch: 6| Step: 9
Training loss: 2.3805196285247803
Validation loss: 2.533747265415807

Epoch: 6| Step: 10
Training loss: 2.961590528488159
Validation loss: 2.5401558337673062

Epoch: 6| Step: 11
Training loss: 2.5430920124053955
Validation loss: 2.5421338132632676

Epoch: 6| Step: 12
Training loss: 2.6277008056640625
Validation loss: 2.5404938779851443

Epoch: 6| Step: 13
Training loss: 3.8427700996398926
Validation loss: 2.5411636085920435

Epoch: 41| Step: 0
Training loss: 2.6994268894195557
Validation loss: 2.5363737844651744

Epoch: 6| Step: 1
Training loss: 3.198934316635132
Validation loss: 2.5518908039216073

Epoch: 6| Step: 2
Training loss: 3.410151720046997
Validation loss: 2.5494735933119252

Epoch: 6| Step: 3
Training loss: 2.0624685287475586
Validation loss: 2.5403421425050303

Epoch: 6| Step: 4
Training loss: 2.2528223991394043
Validation loss: 2.5306807051422777

Epoch: 6| Step: 5
Training loss: 2.8222827911376953
Validation loss: 2.5248809783689437

Epoch: 6| Step: 6
Training loss: 1.940995454788208
Validation loss: 2.5296884505979476

Epoch: 6| Step: 7
Training loss: 3.230485200881958
Validation loss: 2.5261613245933288

Epoch: 6| Step: 8
Training loss: 2.950455665588379
Validation loss: 2.5265991354501374

Epoch: 6| Step: 9
Training loss: 3.326345682144165
Validation loss: 2.5205716932973554

Epoch: 6| Step: 10
Training loss: 2.005171537399292
Validation loss: 2.5137517298421552

Epoch: 6| Step: 11
Training loss: 3.012603521347046
Validation loss: 2.5211196791741157

Epoch: 6| Step: 12
Training loss: 2.2985458374023438
Validation loss: 2.541236780023062

Epoch: 6| Step: 13
Training loss: 3.050497531890869
Validation loss: 2.556907400008171

Epoch: 42| Step: 0
Training loss: 2.8167848587036133
Validation loss: 2.5624964647395636

Epoch: 6| Step: 1
Training loss: 2.010509490966797
Validation loss: 2.550511439641317

Epoch: 6| Step: 2
Training loss: 2.166079521179199
Validation loss: 2.5513318072083178

Epoch: 6| Step: 3
Training loss: 3.0570015907287598
Validation loss: 2.529325387811148

Epoch: 6| Step: 4
Training loss: 2.4885411262512207
Validation loss: 2.518594939221618

Epoch: 6| Step: 5
Training loss: 2.854111909866333
Validation loss: 2.509546226070773

Epoch: 6| Step: 6
Training loss: 3.685689687728882
Validation loss: 2.5180571130526963

Epoch: 6| Step: 7
Training loss: 2.5875205993652344
Validation loss: 2.544534408917991

Epoch: 6| Step: 8
Training loss: 3.423330545425415
Validation loss: 2.574362939403903

Epoch: 6| Step: 9
Training loss: 2.916438579559326
Validation loss: 2.594470106145387

Epoch: 6| Step: 10
Training loss: 2.073502540588379
Validation loss: 2.559606723887946

Epoch: 6| Step: 11
Training loss: 2.1118643283843994
Validation loss: 2.5260911756946194

Epoch: 6| Step: 12
Training loss: 3.3392298221588135
Validation loss: 2.494014811772172

Epoch: 6| Step: 13
Training loss: 2.6455156803131104
Validation loss: 2.489522636577647

Epoch: 43| Step: 0
Training loss: 2.6877121925354004
Validation loss: 2.493696815224104

Epoch: 6| Step: 1
Training loss: 2.2548904418945312
Validation loss: 2.50154624959474

Epoch: 6| Step: 2
Training loss: 2.252380847930908
Validation loss: 2.4959297257085002

Epoch: 6| Step: 3
Training loss: 2.9142448902130127
Validation loss: 2.500478166405873

Epoch: 6| Step: 4
Training loss: 2.8290584087371826
Validation loss: 2.5024156954980667

Epoch: 6| Step: 5
Training loss: 2.0538556575775146
Validation loss: 2.503672392137589

Epoch: 6| Step: 6
Training loss: 2.965679407119751
Validation loss: 2.511122934279903

Epoch: 6| Step: 7
Training loss: 3.796353816986084
Validation loss: 2.509537563529066

Epoch: 6| Step: 8
Training loss: 2.5665652751922607
Validation loss: 2.5165153805927565

Epoch: 6| Step: 9
Training loss: 2.8172624111175537
Validation loss: 2.529660365914786

Epoch: 6| Step: 10
Training loss: 2.522566318511963
Validation loss: 2.535699459814256

Epoch: 6| Step: 11
Training loss: 2.7203757762908936
Validation loss: 2.5292215936927387

Epoch: 6| Step: 12
Training loss: 2.6494650840759277
Validation loss: 2.5253130902526197

Epoch: 6| Step: 13
Training loss: 2.9820592403411865
Validation loss: 2.5096432624324674

Epoch: 44| Step: 0
Training loss: 2.958065986633301
Validation loss: 2.5006358649141047

Epoch: 6| Step: 1
Training loss: 2.538022756576538
Validation loss: 2.497119492100131

Epoch: 6| Step: 2
Training loss: 3.365241050720215
Validation loss: 2.523288106405607

Epoch: 6| Step: 3
Training loss: 3.00778865814209
Validation loss: 2.6327686002177577

Epoch: 6| Step: 4
Training loss: 3.146939754486084
Validation loss: 2.7493802424400084

Epoch: 6| Step: 5
Training loss: 2.7060909271240234
Validation loss: 2.717338505611625

Epoch: 6| Step: 6
Training loss: 2.9732666015625
Validation loss: 2.6089805736336658

Epoch: 6| Step: 7
Training loss: 2.362992525100708
Validation loss: 2.5673157553518973

Epoch: 6| Step: 8
Training loss: 3.2481446266174316
Validation loss: 2.5468556342586393

Epoch: 6| Step: 9
Training loss: 2.515989303588867
Validation loss: 2.51990540822347

Epoch: 6| Step: 10
Training loss: 1.780139446258545
Validation loss: 2.5015440987002466

Epoch: 6| Step: 11
Training loss: 2.3936104774475098
Validation loss: 2.492575681337746

Epoch: 6| Step: 12
Training loss: 2.960824489593506
Validation loss: 2.513589597517444

Epoch: 6| Step: 13
Training loss: 2.484431266784668
Validation loss: 2.559597125617407

Epoch: 45| Step: 0
Training loss: 2.261857271194458
Validation loss: 2.5995307968508814

Epoch: 6| Step: 1
Training loss: 2.4812328815460205
Validation loss: 2.5751657844871603

Epoch: 6| Step: 2
Training loss: 2.95912766456604
Validation loss: 2.5575324540497153

Epoch: 6| Step: 3
Training loss: 3.3283281326293945
Validation loss: 2.535254778400544

Epoch: 6| Step: 4
Training loss: 2.9104833602905273
Validation loss: 2.537225087483724

Epoch: 6| Step: 5
Training loss: 2.5181617736816406
Validation loss: 2.492146538149926

Epoch: 6| Step: 6
Training loss: 2.903398275375366
Validation loss: 2.4797725908217894

Epoch: 6| Step: 7
Training loss: 2.704406261444092
Validation loss: 2.4669889660291773

Epoch: 6| Step: 8
Training loss: 2.7644402980804443
Validation loss: 2.466920527078772

Epoch: 6| Step: 9
Training loss: 2.452430009841919
Validation loss: 2.4741588023401078

Epoch: 6| Step: 10
Training loss: 2.3835902214050293
Validation loss: 2.481800297255157

Epoch: 6| Step: 11
Training loss: 2.514831066131592
Validation loss: 2.484344836204283

Epoch: 6| Step: 12
Training loss: 2.750382423400879
Validation loss: 2.4813985132401988

Epoch: 6| Step: 13
Training loss: 3.0708775520324707
Validation loss: 2.4811685700570383

Epoch: 46| Step: 0
Training loss: 3.1523334980010986
Validation loss: 2.47106610831394

Epoch: 6| Step: 1
Training loss: 2.6903786659240723
Validation loss: 2.4616502100421536

Epoch: 6| Step: 2
Training loss: 2.686269521713257
Validation loss: 2.459555910479638

Epoch: 6| Step: 3
Training loss: 2.3283843994140625
Validation loss: 2.4744792920286938

Epoch: 6| Step: 4
Training loss: 3.0561156272888184
Validation loss: 2.4747782291904574

Epoch: 6| Step: 5
Training loss: 2.1982853412628174
Validation loss: 2.4762232508710635

Epoch: 6| Step: 6
Training loss: 3.0809383392333984
Validation loss: 2.503108163033762

Epoch: 6| Step: 7
Training loss: 2.5277085304260254
Validation loss: 2.548318488623506

Epoch: 6| Step: 8
Training loss: 2.6365818977355957
Validation loss: 2.5856409277967227

Epoch: 6| Step: 9
Training loss: 2.399548053741455
Validation loss: 2.600300801697598

Epoch: 6| Step: 10
Training loss: 2.2239174842834473
Validation loss: 2.5851233851525093

Epoch: 6| Step: 11
Training loss: 2.677917003631592
Validation loss: 2.550140796169158

Epoch: 6| Step: 12
Training loss: 3.3047966957092285
Validation loss: 2.5311295447811

Epoch: 6| Step: 13
Training loss: 3.167609930038452
Validation loss: 2.4995457920976865

Epoch: 47| Step: 0
Training loss: 2.491821527481079
Validation loss: 2.4797008934841362

Epoch: 6| Step: 1
Training loss: 3.2067742347717285
Validation loss: 2.4661418801994732

Epoch: 6| Step: 2
Training loss: 2.4164624214172363
Validation loss: 2.4622687498728433

Epoch: 6| Step: 3
Training loss: 3.164799451828003
Validation loss: 2.462100403283232

Epoch: 6| Step: 4
Training loss: 2.4370062351226807
Validation loss: 2.4583129139356714

Epoch: 6| Step: 5
Training loss: 3.0129497051239014
Validation loss: 2.453615293707899

Epoch: 6| Step: 6
Training loss: 2.143786907196045
Validation loss: 2.455993885635048

Epoch: 6| Step: 7
Training loss: 2.9300177097320557
Validation loss: 2.451875748172883

Epoch: 6| Step: 8
Training loss: 2.353351354598999
Validation loss: 2.4549749717917493

Epoch: 6| Step: 9
Training loss: 2.6458120346069336
Validation loss: 2.455489589321998

Epoch: 6| Step: 10
Training loss: 2.460949420928955
Validation loss: 2.4576795152438584

Epoch: 6| Step: 11
Training loss: 2.6690120697021484
Validation loss: 2.454810045098746

Epoch: 6| Step: 12
Training loss: 3.1350629329681396
Validation loss: 2.457354760939075

Epoch: 6| Step: 13
Training loss: 2.4508841037750244
Validation loss: 2.456307352230113

Epoch: 48| Step: 0
Training loss: 2.4785189628601074
Validation loss: 2.4584087274407826

Epoch: 6| Step: 1
Training loss: 2.925154685974121
Validation loss: 2.471944700005234

Epoch: 6| Step: 2
Training loss: 2.564272880554199
Validation loss: 2.484230649086737

Epoch: 6| Step: 3
Training loss: 3.3317530155181885
Validation loss: 2.478005334895144

Epoch: 6| Step: 4
Training loss: 2.479377031326294
Validation loss: 2.455074376957391

Epoch: 6| Step: 5
Training loss: 2.5408382415771484
Validation loss: 2.448532712075018

Epoch: 6| Step: 6
Training loss: 2.2060608863830566
Validation loss: 2.447756903145903

Epoch: 6| Step: 7
Training loss: 2.4495062828063965
Validation loss: 2.449731793454898

Epoch: 6| Step: 8
Training loss: 2.674170970916748
Validation loss: 2.4530215981186076

Epoch: 6| Step: 9
Training loss: 3.20678448677063
Validation loss: 2.457830987950807

Epoch: 6| Step: 10
Training loss: 2.730252265930176
Validation loss: 2.4673789137153217

Epoch: 6| Step: 11
Training loss: 2.6341068744659424
Validation loss: 2.4601346138984925

Epoch: 6| Step: 12
Training loss: 2.7168807983398438
Validation loss: 2.458701361892044

Epoch: 6| Step: 13
Training loss: 2.6701834201812744
Validation loss: 2.461457437084567

Epoch: 49| Step: 0
Training loss: 2.264366388320923
Validation loss: 2.4581365508417927

Epoch: 6| Step: 1
Training loss: 2.3317136764526367
Validation loss: 2.462030315911898

Epoch: 6| Step: 2
Training loss: 2.7024779319763184
Validation loss: 2.455821567966092

Epoch: 6| Step: 3
Training loss: 2.6829216480255127
Validation loss: 2.453302324459117

Epoch: 6| Step: 4
Training loss: 2.611447811126709
Validation loss: 2.4452164916582007

Epoch: 6| Step: 5
Training loss: 3.0576000213623047
Validation loss: 2.4404146184203444

Epoch: 6| Step: 6
Training loss: 1.9871174097061157
Validation loss: 2.4393019701844905

Epoch: 6| Step: 7
Training loss: 2.3235015869140625
Validation loss: 2.4398739543012393

Epoch: 6| Step: 8
Training loss: 2.9334888458251953
Validation loss: 2.439630316149804

Epoch: 6| Step: 9
Training loss: 3.6426894664764404
Validation loss: 2.4357508177398355

Epoch: 6| Step: 10
Training loss: 2.7404944896698
Validation loss: 2.436921411944974

Epoch: 6| Step: 11
Training loss: 2.640249729156494
Validation loss: 2.436596155166626

Epoch: 6| Step: 12
Training loss: 2.8743515014648438
Validation loss: 2.439593397161012

Epoch: 6| Step: 13
Training loss: 2.6763041019439697
Validation loss: 2.4378314120795137

Epoch: 50| Step: 0
Training loss: 2.569969415664673
Validation loss: 2.4413095187115412

Epoch: 6| Step: 1
Training loss: 2.9023585319519043
Validation loss: 2.435189785495881

Epoch: 6| Step: 2
Training loss: 3.1642019748687744
Validation loss: 2.4369444642015683

Epoch: 6| Step: 3
Training loss: 2.490809917449951
Validation loss: 2.4403334407396216

Epoch: 6| Step: 4
Training loss: 2.9718401432037354
Validation loss: 2.4428751122566963

Epoch: 6| Step: 5
Training loss: 2.110301971435547
Validation loss: 2.443830966949463

Epoch: 6| Step: 6
Training loss: 2.2688229084014893
Validation loss: 2.447487813170238

Epoch: 6| Step: 7
Training loss: 2.9093189239501953
Validation loss: 2.458540437042072

Epoch: 6| Step: 8
Training loss: 2.545504570007324
Validation loss: 2.4981925846428

Epoch: 6| Step: 9
Training loss: 2.4630508422851562
Validation loss: 2.539290210252167

Epoch: 6| Step: 10
Training loss: 2.835571765899658
Validation loss: 2.5762042383993826

Epoch: 6| Step: 11
Training loss: 2.6563775539398193
Validation loss: 2.6076868118778354

Epoch: 6| Step: 12
Training loss: 3.129817008972168
Validation loss: 2.5340338342933246

Epoch: 6| Step: 13
Training loss: 2.466614246368408
Validation loss: 2.4762231893436883

Epoch: 51| Step: 0
Training loss: 2.2780067920684814
Validation loss: 2.4432937816907

Epoch: 6| Step: 1
Training loss: 2.8988230228424072
Validation loss: 2.4287944968028734

Epoch: 6| Step: 2
Training loss: 2.502318859100342
Validation loss: 2.429147838264383

Epoch: 6| Step: 3
Training loss: 2.477083683013916
Validation loss: 2.4427635797890286

Epoch: 6| Step: 4
Training loss: 2.611773729324341
Validation loss: 2.4563296789764077

Epoch: 6| Step: 5
Training loss: 3.0893101692199707
Validation loss: 2.475073073499946

Epoch: 6| Step: 6
Training loss: 3.4655730724334717
Validation loss: 2.4856409821459042

Epoch: 6| Step: 7
Training loss: 2.855628490447998
Validation loss: 2.4935035269747496

Epoch: 6| Step: 8
Training loss: 1.8259260654449463
Validation loss: 2.4974221132134877

Epoch: 6| Step: 9
Training loss: 2.4676430225372314
Validation loss: 2.526505620248856

Epoch: 6| Step: 10
Training loss: 4.032561302185059
Validation loss: 2.6024945448803645

Epoch: 6| Step: 11
Training loss: 2.42293119430542
Validation loss: 2.5408288586524224

Epoch: 6| Step: 12
Training loss: 2.209845542907715
Validation loss: 2.4625309513461207

Epoch: 6| Step: 13
Training loss: 2.9166617393493652
Validation loss: 2.438116579927424

Epoch: 52| Step: 0
Training loss: 2.839940071105957
Validation loss: 2.4277221746342157

Epoch: 6| Step: 1
Training loss: 2.258652687072754
Validation loss: 2.4213207896037767

Epoch: 6| Step: 2
Training loss: 3.6528258323669434
Validation loss: 2.433764491029965

Epoch: 6| Step: 3
Training loss: 2.4662182331085205
Validation loss: 2.457872231801351

Epoch: 6| Step: 4
Training loss: 2.8612380027770996
Validation loss: 2.5039882147183983

Epoch: 6| Step: 5
Training loss: 2.1035470962524414
Validation loss: 2.530234880344842

Epoch: 6| Step: 6
Training loss: 3.239804267883301
Validation loss: 2.510196901136829

Epoch: 6| Step: 7
Training loss: 1.605034351348877
Validation loss: 2.5001088291086178

Epoch: 6| Step: 8
Training loss: 2.335315704345703
Validation loss: 2.499773276749478

Epoch: 6| Step: 9
Training loss: 3.105316162109375
Validation loss: 2.450087426811136

Epoch: 6| Step: 10
Training loss: 2.8578453063964844
Validation loss: 2.433016764220371

Epoch: 6| Step: 11
Training loss: 2.670004367828369
Validation loss: 2.4243949664536344

Epoch: 6| Step: 12
Training loss: 2.9033186435699463
Validation loss: 2.41687806447347

Epoch: 6| Step: 13
Training loss: 2.6691317558288574
Validation loss: 2.421905966215236

Epoch: 53| Step: 0
Training loss: 2.8459696769714355
Validation loss: 2.421295222415719

Epoch: 6| Step: 1
Training loss: 2.8296735286712646
Validation loss: 2.420099710905424

Epoch: 6| Step: 2
Training loss: 2.0990021228790283
Validation loss: 2.4213746158025597

Epoch: 6| Step: 3
Training loss: 2.362208843231201
Validation loss: 2.4223330918178765

Epoch: 6| Step: 4
Training loss: 2.90061092376709
Validation loss: 2.4136427961369997

Epoch: 6| Step: 5
Training loss: 2.2399044036865234
Validation loss: 2.4172564680858324

Epoch: 6| Step: 6
Training loss: 2.2039403915405273
Validation loss: 2.4142937942217757

Epoch: 6| Step: 7
Training loss: 2.892185688018799
Validation loss: 2.4165135814297583

Epoch: 6| Step: 8
Training loss: 2.771461248397827
Validation loss: 2.4180416394305486

Epoch: 6| Step: 9
Training loss: 2.667196750640869
Validation loss: 2.414424611676124

Epoch: 6| Step: 10
Training loss: 2.0963807106018066
Validation loss: 2.4157790342966714

Epoch: 6| Step: 11
Training loss: 2.701599597930908
Validation loss: 2.4125651236503356

Epoch: 6| Step: 12
Training loss: 3.4024882316589355
Validation loss: 2.412217546534795

Epoch: 6| Step: 13
Training loss: 3.5617587566375732
Validation loss: 2.418189884513937

Epoch: 54| Step: 0
Training loss: 2.602168083190918
Validation loss: 2.4216818142962713

Epoch: 6| Step: 1
Training loss: 2.5314273834228516
Validation loss: 2.4240091129015853

Epoch: 6| Step: 2
Training loss: 2.605865478515625
Validation loss: 2.4285365663548952

Epoch: 6| Step: 3
Training loss: 3.5984463691711426
Validation loss: 2.446477323450068

Epoch: 6| Step: 4
Training loss: 2.916367530822754
Validation loss: 2.4736702493442

Epoch: 6| Step: 5
Training loss: 2.377809524536133
Validation loss: 2.5056783640256493

Epoch: 6| Step: 6
Training loss: 2.4317688941955566
Validation loss: 2.5285730233756443

Epoch: 6| Step: 7
Training loss: 2.1584291458129883
Validation loss: 2.499957997311828

Epoch: 6| Step: 8
Training loss: 2.6844875812530518
Validation loss: 2.4595478170661518

Epoch: 6| Step: 9
Training loss: 2.616427421569824
Validation loss: 2.4409063041851087

Epoch: 6| Step: 10
Training loss: 2.456414222717285
Validation loss: 2.4290653633814987

Epoch: 6| Step: 11
Training loss: 2.2858314514160156
Validation loss: 2.4199749603066394

Epoch: 6| Step: 12
Training loss: 2.7594361305236816
Validation loss: 2.411054480460382

Epoch: 6| Step: 13
Training loss: 3.7325541973114014
Validation loss: 2.3983028973302534

Epoch: 55| Step: 0
Training loss: 2.8606648445129395
Validation loss: 2.3990161470187608

Epoch: 6| Step: 1
Training loss: 3.118530035018921
Validation loss: 2.3952022393544516

Epoch: 6| Step: 2
Training loss: 2.7636704444885254
Validation loss: 2.395222517751878

Epoch: 6| Step: 3
Training loss: 2.2797155380249023
Validation loss: 2.393731019830191

Epoch: 6| Step: 4
Training loss: 2.3492867946624756
Validation loss: 2.3940855303118305

Epoch: 6| Step: 5
Training loss: 2.5969862937927246
Validation loss: 2.3980354288572907

Epoch: 6| Step: 6
Training loss: 3.0961010456085205
Validation loss: 2.409308825769732

Epoch: 6| Step: 7
Training loss: 2.741217613220215
Validation loss: 2.4210146396390853

Epoch: 6| Step: 8
Training loss: 2.0463521480560303
Validation loss: 2.4350221772347727

Epoch: 6| Step: 9
Training loss: 2.646307945251465
Validation loss: 2.4463618391303608

Epoch: 6| Step: 10
Training loss: 2.689408779144287
Validation loss: 2.4711150764137186

Epoch: 6| Step: 11
Training loss: 2.48561429977417
Validation loss: 2.505416780389765

Epoch: 6| Step: 12
Training loss: 2.6827549934387207
Validation loss: 2.507971812320012

Epoch: 6| Step: 13
Training loss: 3.2400474548339844
Validation loss: 2.5271079219797605

Epoch: 56| Step: 0
Training loss: 2.937408447265625
Validation loss: 2.500074730124525

Epoch: 6| Step: 1
Training loss: 2.170238733291626
Validation loss: 2.443052350833852

Epoch: 6| Step: 2
Training loss: 2.2374038696289062
Validation loss: 2.398591113346879

Epoch: 6| Step: 3
Training loss: 2.7639143466949463
Validation loss: 2.3869728503688687

Epoch: 6| Step: 4
Training loss: 2.2075300216674805
Validation loss: 2.3946735500007548

Epoch: 6| Step: 5
Training loss: 3.0575547218322754
Validation loss: 2.4011284561567408

Epoch: 6| Step: 6
Training loss: 2.2753989696502686
Validation loss: 2.4178406346228813

Epoch: 6| Step: 7
Training loss: 2.728670597076416
Validation loss: 2.42092546596322

Epoch: 6| Step: 8
Training loss: 2.6234869956970215
Validation loss: 2.4234288405346613

Epoch: 6| Step: 9
Training loss: 3.288774013519287
Validation loss: 2.415370125924387

Epoch: 6| Step: 10
Training loss: 2.808530807495117
Validation loss: 2.4041119237099924

Epoch: 6| Step: 11
Training loss: 2.3388619422912598
Validation loss: 2.403662943070935

Epoch: 6| Step: 12
Training loss: 2.5671849250793457
Validation loss: 2.3975877172203472

Epoch: 6| Step: 13
Training loss: 4.079845428466797
Validation loss: 2.396019156261157

Epoch: 57| Step: 0
Training loss: 1.6140714883804321
Validation loss: 2.400349945150396

Epoch: 6| Step: 1
Training loss: 3.2785980701446533
Validation loss: 2.3957582878810104

Epoch: 6| Step: 2
Training loss: 3.4466404914855957
Validation loss: 2.392828369653353

Epoch: 6| Step: 3
Training loss: 3.0522689819335938
Validation loss: 2.3890454435861237

Epoch: 6| Step: 4
Training loss: 2.101560115814209
Validation loss: 2.3859719358464724

Epoch: 6| Step: 5
Training loss: 2.485089063644409
Validation loss: 2.389067849805278

Epoch: 6| Step: 6
Training loss: 3.082918167114258
Validation loss: 2.3974920626609557

Epoch: 6| Step: 7
Training loss: 2.3522145748138428
Validation loss: 2.3980390256451023

Epoch: 6| Step: 8
Training loss: 2.5614256858825684
Validation loss: 2.410138063533332

Epoch: 6| Step: 9
Training loss: 2.948777675628662
Validation loss: 2.410922178658106

Epoch: 6| Step: 10
Training loss: 2.5378530025482178
Validation loss: 2.4128660437881306

Epoch: 6| Step: 11
Training loss: 1.8909674882888794
Validation loss: 2.395760525939285

Epoch: 6| Step: 12
Training loss: 3.2988271713256836
Validation loss: 2.4008978361724527

Epoch: 6| Step: 13
Training loss: 2.1977880001068115
Validation loss: 2.3977352624298423

Epoch: 58| Step: 0
Training loss: 2.1887245178222656
Validation loss: 2.4043652267866236

Epoch: 6| Step: 1
Training loss: 2.1297006607055664
Validation loss: 2.4058514705268284

Epoch: 6| Step: 2
Training loss: 2.89017391204834
Validation loss: 2.4087360494880268

Epoch: 6| Step: 3
Training loss: 2.2737207412719727
Validation loss: 2.4015956591534358

Epoch: 6| Step: 4
Training loss: 2.276054859161377
Validation loss: 2.403424434764411

Epoch: 6| Step: 5
Training loss: 2.581768274307251
Validation loss: 2.42742185823379

Epoch: 6| Step: 6
Training loss: 1.995932698249817
Validation loss: 2.4447577435483216

Epoch: 6| Step: 7
Training loss: 3.309943675994873
Validation loss: 2.449723341131723

Epoch: 6| Step: 8
Training loss: 2.672910690307617
Validation loss: 2.4574297423003824

Epoch: 6| Step: 9
Training loss: 3.2415099143981934
Validation loss: 2.4584116269183416

Epoch: 6| Step: 10
Training loss: 2.9795308113098145
Validation loss: 2.4293212993170625

Epoch: 6| Step: 11
Training loss: 2.6439623832702637
Validation loss: 2.403854408571797

Epoch: 6| Step: 12
Training loss: 2.630164384841919
Validation loss: 2.38691085128374

Epoch: 6| Step: 13
Training loss: 3.470810651779175
Validation loss: 2.380392448876494

Epoch: 59| Step: 0
Training loss: 3.175133228302002
Validation loss: 2.3767758107954458

Epoch: 6| Step: 1
Training loss: 2.448791265487671
Validation loss: 2.368312986948157

Epoch: 6| Step: 2
Training loss: 2.7176461219787598
Validation loss: 2.364542188182954

Epoch: 6| Step: 3
Training loss: 2.5439016819000244
Validation loss: 2.362593214998963

Epoch: 6| Step: 4
Training loss: 2.637141704559326
Validation loss: 2.3596769173940024

Epoch: 6| Step: 5
Training loss: 2.8467466831207275
Validation loss: 2.3642565973343386

Epoch: 6| Step: 6
Training loss: 3.0966954231262207
Validation loss: 2.3606828925430134

Epoch: 6| Step: 7
Training loss: 2.36747407913208
Validation loss: 2.367904811777094

Epoch: 6| Step: 8
Training loss: 2.139324188232422
Validation loss: 2.364141279651273

Epoch: 6| Step: 9
Training loss: 2.378786563873291
Validation loss: 2.368216742751419

Epoch: 6| Step: 10
Training loss: 2.5730369091033936
Validation loss: 2.3919092121944634

Epoch: 6| Step: 11
Training loss: 2.1121578216552734
Validation loss: 2.393626161800918

Epoch: 6| Step: 12
Training loss: 3.0012452602386475
Validation loss: 2.4167795873457387

Epoch: 6| Step: 13
Training loss: 3.1151113510131836
Validation loss: 2.3887008287573375

Epoch: 60| Step: 0
Training loss: 3.4947376251220703
Validation loss: 2.369882006799021

Epoch: 6| Step: 1
Training loss: 2.500302791595459
Validation loss: 2.3600900609006166

Epoch: 6| Step: 2
Training loss: 2.9422619342803955
Validation loss: 2.357491147133612

Epoch: 6| Step: 3
Training loss: 2.705122947692871
Validation loss: 2.3560120059597875

Epoch: 6| Step: 4
Training loss: 2.6171622276306152
Validation loss: 2.3520510811959543

Epoch: 6| Step: 5
Training loss: 2.247462272644043
Validation loss: 2.356199450390313

Epoch: 6| Step: 6
Training loss: 2.1826674938201904
Validation loss: 2.353966151514361

Epoch: 6| Step: 7
Training loss: 2.2795586585998535
Validation loss: 2.3540280685629895

Epoch: 6| Step: 8
Training loss: 3.039393901824951
Validation loss: 2.3569275127944125

Epoch: 6| Step: 9
Training loss: 1.8738901615142822
Validation loss: 2.352870605325186

Epoch: 6| Step: 10
Training loss: 2.8114540576934814
Validation loss: 2.3512818813323975

Epoch: 6| Step: 11
Training loss: 2.416947364807129
Validation loss: 2.359229318557247

Epoch: 6| Step: 12
Training loss: 2.643728494644165
Validation loss: 2.369344965104134

Epoch: 6| Step: 13
Training loss: 3.2670514583587646
Validation loss: 2.3760932440398843

Epoch: 61| Step: 0
Training loss: 2.89689564704895
Validation loss: 2.376461754563034

Epoch: 6| Step: 1
Training loss: 2.6471152305603027
Validation loss: 2.3745848337809243

Epoch: 6| Step: 2
Training loss: 2.9466917514801025
Validation loss: 2.361548098184729

Epoch: 6| Step: 3
Training loss: 2.279928207397461
Validation loss: 2.348412408623644

Epoch: 6| Step: 4
Training loss: 2.332885980606079
Validation loss: 2.3447362710070867

Epoch: 6| Step: 5
Training loss: 2.0174715518951416
Validation loss: 2.3419710513084167

Epoch: 6| Step: 6
Training loss: 2.214489459991455
Validation loss: 2.344527954696327

Epoch: 6| Step: 7
Training loss: 2.555082321166992
Validation loss: 2.3401575857593166

Epoch: 6| Step: 8
Training loss: 3.2268929481506348
Validation loss: 2.347022689798827

Epoch: 6| Step: 9
Training loss: 2.914181709289551
Validation loss: 2.343382973824778

Epoch: 6| Step: 10
Training loss: 3.238521099090576
Validation loss: 2.3444881695573048

Epoch: 6| Step: 11
Training loss: 1.7918071746826172
Validation loss: 2.3433484313308552

Epoch: 6| Step: 12
Training loss: 3.200411081314087
Validation loss: 2.3391146659851074

Epoch: 6| Step: 13
Training loss: 2.5176408290863037
Validation loss: 2.343585665507983

Epoch: 62| Step: 0
Training loss: 2.5991294384002686
Validation loss: 2.345661865767612

Epoch: 6| Step: 1
Training loss: 2.798330307006836
Validation loss: 2.349568731041365

Epoch: 6| Step: 2
Training loss: 2.748931407928467
Validation loss: 2.360233191520937

Epoch: 6| Step: 3
Training loss: 2.2336177825927734
Validation loss: 2.3769892261874292

Epoch: 6| Step: 4
Training loss: 2.7080037593841553
Validation loss: 2.414836582317147

Epoch: 6| Step: 5
Training loss: 2.1290621757507324
Validation loss: 2.3893846055512786

Epoch: 6| Step: 6
Training loss: 2.680274248123169
Validation loss: 2.3888450155976

Epoch: 6| Step: 7
Training loss: 2.827974796295166
Validation loss: 2.3604396158649075

Epoch: 6| Step: 8
Training loss: 2.5915400981903076
Validation loss: 2.343617485415551

Epoch: 6| Step: 9
Training loss: 2.6609480381011963
Validation loss: 2.3369090710916827

Epoch: 6| Step: 10
Training loss: 2.6622681617736816
Validation loss: 2.3332664517946142

Epoch: 6| Step: 11
Training loss: 2.5679595470428467
Validation loss: 2.337475338289815

Epoch: 6| Step: 12
Training loss: 3.089926242828369
Validation loss: 2.3367029877119165

Epoch: 6| Step: 13
Training loss: 2.2231757640838623
Validation loss: 2.334118127822876

Epoch: 63| Step: 0
Training loss: 4.020877838134766
Validation loss: 2.3372653812490483

Epoch: 6| Step: 1
Training loss: 2.9716458320617676
Validation loss: 2.3417895378605014

Epoch: 6| Step: 2
Training loss: 2.788379192352295
Validation loss: 2.3389072084939606

Epoch: 6| Step: 3
Training loss: 3.298093557357788
Validation loss: 2.352005071537469

Epoch: 6| Step: 4
Training loss: 2.384091854095459
Validation loss: 2.3581526561449935

Epoch: 6| Step: 5
Training loss: 1.6612744331359863
Validation loss: 2.3560016898698706

Epoch: 6| Step: 6
Training loss: 2.5098488330841064
Validation loss: 2.357281210601971

Epoch: 6| Step: 7
Training loss: 3.134235143661499
Validation loss: 2.3633891433797856

Epoch: 6| Step: 8
Training loss: 1.7229185104370117
Validation loss: 2.3602063296943583

Epoch: 6| Step: 9
Training loss: 2.5709855556488037
Validation loss: 2.3516270140165925

Epoch: 6| Step: 10
Training loss: 2.60809326171875
Validation loss: 2.3382161791606615

Epoch: 6| Step: 11
Training loss: 2.141639232635498
Validation loss: 2.3350378569736274

Epoch: 6| Step: 12
Training loss: 2.494307518005371
Validation loss: 2.3286493850010697

Epoch: 6| Step: 13
Training loss: 2.0436885356903076
Validation loss: 2.326930340900216

Epoch: 64| Step: 0
Training loss: 1.9217770099639893
Validation loss: 2.330366180789086

Epoch: 6| Step: 1
Training loss: 2.8557639122009277
Validation loss: 2.3305435744665

Epoch: 6| Step: 2
Training loss: 2.3152451515197754
Validation loss: 2.3404906642052437

Epoch: 6| Step: 3
Training loss: 2.6838674545288086
Validation loss: 2.3408488560748357

Epoch: 6| Step: 4
Training loss: 2.965430736541748
Validation loss: 2.3412357453377015

Epoch: 6| Step: 5
Training loss: 2.9228506088256836
Validation loss: 2.3411063609584684

Epoch: 6| Step: 6
Training loss: 2.360614538192749
Validation loss: 2.3452323482882593

Epoch: 6| Step: 7
Training loss: 3.742767095565796
Validation loss: 2.357760403745918

Epoch: 6| Step: 8
Training loss: 2.6482372283935547
Validation loss: 2.3708207197086786

Epoch: 6| Step: 9
Training loss: 2.9691789150238037
Validation loss: 2.370629419562637

Epoch: 6| Step: 10
Training loss: 2.6979260444641113
Validation loss: 2.350675070157615

Epoch: 6| Step: 11
Training loss: 1.7789958715438843
Validation loss: 2.3328008562005977

Epoch: 6| Step: 12
Training loss: 2.2294106483459473
Validation loss: 2.3325547031176987

Epoch: 6| Step: 13
Training loss: 2.3481597900390625
Validation loss: 2.32601228837044

Epoch: 65| Step: 0
Training loss: 2.4191341400146484
Validation loss: 2.331884020118303

Epoch: 6| Step: 1
Training loss: 2.7291102409362793
Validation loss: 2.348479244016832

Epoch: 6| Step: 2
Training loss: 2.115190029144287
Validation loss: 2.3726738011965187

Epoch: 6| Step: 3
Training loss: 2.7116715908050537
Validation loss: 2.4407995541890464

Epoch: 6| Step: 4
Training loss: 2.562976121902466
Validation loss: 2.4926051426959295

Epoch: 6| Step: 5
Training loss: 3.3230671882629395
Validation loss: 2.5172225044619654

Epoch: 6| Step: 6
Training loss: 2.7355642318725586
Validation loss: 2.4876346306134294

Epoch: 6| Step: 7
Training loss: 2.3932857513427734
Validation loss: 2.4260241267501668

Epoch: 6| Step: 8
Training loss: 2.370650291442871
Validation loss: 2.351378240892964

Epoch: 6| Step: 9
Training loss: 2.2645344734191895
Validation loss: 2.3178623568627144

Epoch: 6| Step: 10
Training loss: 3.0806822776794434
Validation loss: 2.3329032159620717

Epoch: 6| Step: 11
Training loss: 2.9837870597839355
Validation loss: 2.3488467560019544

Epoch: 6| Step: 12
Training loss: 3.242382287979126
Validation loss: 2.374444373192326

Epoch: 6| Step: 13
Training loss: 1.8041911125183105
Validation loss: 2.3868023323756393

Epoch: 66| Step: 0
Training loss: 2.8868041038513184
Validation loss: 2.437321957721505

Epoch: 6| Step: 1
Training loss: 2.0957415103912354
Validation loss: 2.4253339613637617

Epoch: 6| Step: 2
Training loss: 2.521024227142334
Validation loss: 2.4718062211108465

Epoch: 6| Step: 3
Training loss: 2.8374228477478027
Validation loss: 2.411178122284592

Epoch: 6| Step: 4
Training loss: 3.2756309509277344
Validation loss: 2.368355838201379

Epoch: 6| Step: 5
Training loss: 2.505481004714966
Validation loss: 2.3412370886853946

Epoch: 6| Step: 6
Training loss: 2.842561960220337
Validation loss: 2.3292494409827778

Epoch: 6| Step: 7
Training loss: 3.2763819694519043
Validation loss: 2.321791310464182

Epoch: 6| Step: 8
Training loss: 2.775935649871826
Validation loss: 2.3171039037807013

Epoch: 6| Step: 9
Training loss: 2.194554328918457
Validation loss: 2.313105408863355

Epoch: 6| Step: 10
Training loss: 1.695851445198059
Validation loss: 2.3115713955253683

Epoch: 6| Step: 11
Training loss: 2.326030969619751
Validation loss: 2.3126000024939097

Epoch: 6| Step: 12
Training loss: 3.136812686920166
Validation loss: 2.3143737957041752

Epoch: 6| Step: 13
Training loss: 2.569265604019165
Validation loss: 2.3135899497616674

Epoch: 67| Step: 0
Training loss: 1.7343709468841553
Validation loss: 2.318744118495654

Epoch: 6| Step: 1
Training loss: 2.1479616165161133
Validation loss: 2.320663829003611

Epoch: 6| Step: 2
Training loss: 2.9341988563537598
Validation loss: 2.3110353844140166

Epoch: 6| Step: 3
Training loss: 2.755974054336548
Validation loss: 2.3154160181681314

Epoch: 6| Step: 4
Training loss: 2.5178799629211426
Validation loss: 2.310781181499522

Epoch: 6| Step: 5
Training loss: 3.2554850578308105
Validation loss: 2.303182683965211

Epoch: 6| Step: 6
Training loss: 2.319114923477173
Validation loss: 2.311356395803472

Epoch: 6| Step: 7
Training loss: 2.452854633331299
Validation loss: 2.307042071896215

Epoch: 6| Step: 8
Training loss: 2.874542236328125
Validation loss: 2.3149354457855225

Epoch: 6| Step: 9
Training loss: 2.6047635078430176
Validation loss: 2.31321786039619

Epoch: 6| Step: 10
Training loss: 2.835554599761963
Validation loss: 2.3190173872055544

Epoch: 6| Step: 11
Training loss: 2.820185899734497
Validation loss: 2.317182784439415

Epoch: 6| Step: 12
Training loss: 2.615910053253174
Validation loss: 2.3252035879319712

Epoch: 6| Step: 13
Training loss: 2.302338123321533
Validation loss: 2.33790313043902

Epoch: 68| Step: 0
Training loss: 2.123955249786377
Validation loss: 2.3559610318112116

Epoch: 6| Step: 1
Training loss: 2.975442886352539
Validation loss: 2.374914751257948

Epoch: 6| Step: 2
Training loss: 2.5131630897521973
Validation loss: 2.3977848893852642

Epoch: 6| Step: 3
Training loss: 1.3922216892242432
Validation loss: 2.395729951961066

Epoch: 6| Step: 4
Training loss: 2.965367317199707
Validation loss: 2.381181142663443

Epoch: 6| Step: 5
Training loss: 2.205777645111084
Validation loss: 2.358004064970119

Epoch: 6| Step: 6
Training loss: 3.025484323501587
Validation loss: 2.354499809203609

Epoch: 6| Step: 7
Training loss: 3.0609030723571777
Validation loss: 2.336320592511085

Epoch: 6| Step: 8
Training loss: 3.116790771484375
Validation loss: 2.31684906764697

Epoch: 6| Step: 9
Training loss: 2.0621519088745117
Validation loss: 2.30990328327302

Epoch: 6| Step: 10
Training loss: 2.9017562866210938
Validation loss: 2.2971360965441634

Epoch: 6| Step: 11
Training loss: 2.9237897396087646
Validation loss: 2.3009643503414687

Epoch: 6| Step: 12
Training loss: 2.504697561264038
Validation loss: 2.312260099636611

Epoch: 6| Step: 13
Training loss: 2.612938642501831
Validation loss: 2.3236005011425225

Epoch: 69| Step: 0
Training loss: 2.187706470489502
Validation loss: 2.333043670141569

Epoch: 6| Step: 1
Training loss: 2.563652753829956
Validation loss: 2.3561791399473786

Epoch: 6| Step: 2
Training loss: 3.1612648963928223
Validation loss: 2.367227056975006

Epoch: 6| Step: 3
Training loss: 1.8613778352737427
Validation loss: 2.403484195791265

Epoch: 6| Step: 4
Training loss: 2.4289438724517822
Validation loss: 2.405165510792886

Epoch: 6| Step: 5
Training loss: 2.5236501693725586
Validation loss: 2.3803218680043376

Epoch: 6| Step: 6
Training loss: 1.8921408653259277
Validation loss: 2.327130961161788

Epoch: 6| Step: 7
Training loss: 3.061910390853882
Validation loss: 2.3008598332764

Epoch: 6| Step: 8
Training loss: 3.503993511199951
Validation loss: 2.2920758083302486

Epoch: 6| Step: 9
Training loss: 2.5961666107177734
Validation loss: 2.2982554692094044

Epoch: 6| Step: 10
Training loss: 2.5925581455230713
Validation loss: 2.3106756159054336

Epoch: 6| Step: 11
Training loss: 2.7185564041137695
Validation loss: 2.3448332560959684

Epoch: 6| Step: 12
Training loss: 2.5327279567718506
Validation loss: 2.334526720867362

Epoch: 6| Step: 13
Training loss: 3.064361095428467
Validation loss: 2.346893722011197

Epoch: 70| Step: 0
Training loss: 2.620840549468994
Validation loss: 2.3616203851597284

Epoch: 6| Step: 1
Training loss: 2.6466798782348633
Validation loss: 2.3713599840799966

Epoch: 6| Step: 2
Training loss: 3.3717799186706543
Validation loss: 2.3527686262643464

Epoch: 6| Step: 3
Training loss: 2.6391348838806152
Validation loss: 2.351716431238318

Epoch: 6| Step: 4
Training loss: 2.6846485137939453
Validation loss: 2.3333314977666384

Epoch: 6| Step: 5
Training loss: 2.552687168121338
Validation loss: 2.3339146439747145

Epoch: 6| Step: 6
Training loss: 2.0406625270843506
Validation loss: 2.3412384884331816

Epoch: 6| Step: 7
Training loss: 2.2452759742736816
Validation loss: 2.3365584624710904

Epoch: 6| Step: 8
Training loss: 2.458587408065796
Validation loss: 2.330538244657619

Epoch: 6| Step: 9
Training loss: 2.6420278549194336
Validation loss: 2.3098147940892044

Epoch: 6| Step: 10
Training loss: 2.667369842529297
Validation loss: 2.3058500956463557

Epoch: 6| Step: 11
Training loss: 1.9893814325332642
Validation loss: 2.291304426808511

Epoch: 6| Step: 12
Training loss: 3.2596445083618164
Validation loss: 2.289656123807353

Epoch: 6| Step: 13
Training loss: 2.3447108268737793
Validation loss: 2.2915468267215195

Epoch: 71| Step: 0
Training loss: 2.815126895904541
Validation loss: 2.293118547367793

Epoch: 6| Step: 1
Training loss: 2.0186920166015625
Validation loss: 2.2849513176948792

Epoch: 6| Step: 2
Training loss: 2.604567050933838
Validation loss: 2.293066358053556

Epoch: 6| Step: 3
Training loss: 3.0463016033172607
Validation loss: 2.305106352734309

Epoch: 6| Step: 4
Training loss: 2.045961856842041
Validation loss: 2.298891052123039

Epoch: 6| Step: 5
Training loss: 2.174034357070923
Validation loss: 2.302424705156716

Epoch: 6| Step: 6
Training loss: 3.0617246627807617
Validation loss: 2.3067267146161807

Epoch: 6| Step: 7
Training loss: 2.356112003326416
Validation loss: 2.2920278708140054

Epoch: 6| Step: 8
Training loss: 2.6898193359375
Validation loss: 2.3001899847420315

Epoch: 6| Step: 9
Training loss: 2.322392463684082
Validation loss: 2.2904731714597313

Epoch: 6| Step: 10
Training loss: 1.6262092590332031
Validation loss: 2.2897735359848186

Epoch: 6| Step: 11
Training loss: 3.0734519958496094
Validation loss: 2.286201725723923

Epoch: 6| Step: 12
Training loss: 3.379929542541504
Validation loss: 2.2911131971625873

Epoch: 6| Step: 13
Training loss: 2.9791831970214844
Validation loss: 2.2866749660943144

Epoch: 72| Step: 0
Training loss: 2.410245418548584
Validation loss: 2.2829405184715026

Epoch: 6| Step: 1
Training loss: 2.2525734901428223
Validation loss: 2.2792450997137252

Epoch: 6| Step: 2
Training loss: 2.0546975135803223
Validation loss: 2.2840220312918387

Epoch: 6| Step: 3
Training loss: 3.4325919151306152
Validation loss: 2.280042335551272

Epoch: 6| Step: 4
Training loss: 2.555856466293335
Validation loss: 2.2777601621484243

Epoch: 6| Step: 5
Training loss: 2.4104113578796387
Validation loss: 2.2833296996290966

Epoch: 6| Step: 6
Training loss: 2.922670364379883
Validation loss: 2.2830353577931723

Epoch: 6| Step: 7
Training loss: 2.541269540786743
Validation loss: 2.278734081534929

Epoch: 6| Step: 8
Training loss: 2.762899398803711
Validation loss: 2.286822654867685

Epoch: 6| Step: 9
Training loss: 2.1264138221740723
Validation loss: 2.2829391674328874

Epoch: 6| Step: 10
Training loss: 2.9777286052703857
Validation loss: 2.2870317735979633

Epoch: 6| Step: 11
Training loss: 2.6598286628723145
Validation loss: 2.2863432707325106

Epoch: 6| Step: 12
Training loss: 2.690730333328247
Validation loss: 2.285281947863999

Epoch: 6| Step: 13
Training loss: 2.08364200592041
Validation loss: 2.2927398963641097

Epoch: 73| Step: 0
Training loss: 2.3698806762695312
Validation loss: 2.2876415175776326

Epoch: 6| Step: 1
Training loss: 1.750295639038086
Validation loss: 2.2897248345036663

Epoch: 6| Step: 2
Training loss: 2.5307135581970215
Validation loss: 2.28987314111443

Epoch: 6| Step: 3
Training loss: 2.512406349182129
Validation loss: 2.287207124053791

Epoch: 6| Step: 4
Training loss: 2.322781801223755
Validation loss: 2.288512360665106

Epoch: 6| Step: 5
Training loss: 3.1471357345581055
Validation loss: 2.2922748340073453

Epoch: 6| Step: 6
Training loss: 3.0295310020446777
Validation loss: 2.3054639831666024

Epoch: 6| Step: 7
Training loss: 2.6415224075317383
Validation loss: 2.309445522164786

Epoch: 6| Step: 8
Training loss: 2.2426536083221436
Validation loss: 2.3064053596988803

Epoch: 6| Step: 9
Training loss: 2.7545948028564453
Validation loss: 2.295886435816365

Epoch: 6| Step: 10
Training loss: 2.101658582687378
Validation loss: 2.28992675324922

Epoch: 6| Step: 11
Training loss: 2.2636399269104004
Validation loss: 2.280694960266031

Epoch: 6| Step: 12
Training loss: 3.0119848251342773
Validation loss: 2.2770975174442416

Epoch: 6| Step: 13
Training loss: 3.649878978729248
Validation loss: 2.2706325028532293

Epoch: 74| Step: 0
Training loss: 2.714601993560791
Validation loss: 2.265468825576126

Epoch: 6| Step: 1
Training loss: 2.6979665756225586
Validation loss: 2.269081425923173

Epoch: 6| Step: 2
Training loss: 2.583667278289795
Validation loss: 2.2649850255699566

Epoch: 6| Step: 3
Training loss: 2.4351449012756348
Validation loss: 2.262367525408345

Epoch: 6| Step: 4
Training loss: 1.9222604036331177
Validation loss: 2.260481490883776

Epoch: 6| Step: 5
Training loss: 2.493255853652954
Validation loss: 2.266462315795242

Epoch: 6| Step: 6
Training loss: 2.5976014137268066
Validation loss: 2.267681178226266

Epoch: 6| Step: 7
Training loss: 3.1403799057006836
Validation loss: 2.273290907183001

Epoch: 6| Step: 8
Training loss: 2.946539878845215
Validation loss: 2.2757359166299143

Epoch: 6| Step: 9
Training loss: 2.3305978775024414
Validation loss: 2.282790687776381

Epoch: 6| Step: 10
Training loss: 2.445347785949707
Validation loss: 2.300709932081161

Epoch: 6| Step: 11
Training loss: 2.865676164627075
Validation loss: 2.318369879517504

Epoch: 6| Step: 12
Training loss: 2.3722100257873535
Validation loss: 2.318186536911995

Epoch: 6| Step: 13
Training loss: 1.7884281873703003
Validation loss: 2.33556088068152

Epoch: 75| Step: 0
Training loss: 2.2488856315612793
Validation loss: 2.3412215837868313

Epoch: 6| Step: 1
Training loss: 2.651900053024292
Validation loss: 2.3612280507241525

Epoch: 6| Step: 2
Training loss: 3.0653398036956787
Validation loss: 2.377180048214492

Epoch: 6| Step: 3
Training loss: 2.9234776496887207
Validation loss: 2.3703669142979447

Epoch: 6| Step: 4
Training loss: 2.4209442138671875
Validation loss: 2.3266197455826627

Epoch: 6| Step: 5
Training loss: 2.5300545692443848
Validation loss: 2.298945789696068

Epoch: 6| Step: 6
Training loss: 2.451732635498047
Validation loss: 2.27424378548899

Epoch: 6| Step: 7
Training loss: 2.4746952056884766
Validation loss: 2.2631762361013763

Epoch: 6| Step: 8
Training loss: 3.1876161098480225
Validation loss: 2.2560293956469466

Epoch: 6| Step: 9
Training loss: 2.4181723594665527
Validation loss: 2.2485280780382055

Epoch: 6| Step: 10
Training loss: 2.3997883796691895
Validation loss: 2.254128271533597

Epoch: 6| Step: 11
Training loss: 1.8435945510864258
Validation loss: 2.2511730758092736

Epoch: 6| Step: 12
Training loss: 2.624079704284668
Validation loss: 2.2546655080651723

Epoch: 6| Step: 13
Training loss: 2.9385123252868652
Validation loss: 2.264496951974848

Epoch: 76| Step: 0
Training loss: 1.518725872039795
Validation loss: 2.2596202024849514

Epoch: 6| Step: 1
Training loss: 2.280170202255249
Validation loss: 2.2655776880120717

Epoch: 6| Step: 2
Training loss: 2.3097729682922363
Validation loss: 2.2681626530103784

Epoch: 6| Step: 3
Training loss: 2.339534282684326
Validation loss: 2.280481899938276

Epoch: 6| Step: 4
Training loss: 2.671048402786255
Validation loss: 2.291974393270349

Epoch: 6| Step: 5
Training loss: 3.130110263824463
Validation loss: 2.293373474510767

Epoch: 6| Step: 6
Training loss: 3.2064547538757324
Validation loss: 2.308108206718199

Epoch: 6| Step: 7
Training loss: 3.342148780822754
Validation loss: 2.306459926789807

Epoch: 6| Step: 8
Training loss: 2.0815670490264893
Validation loss: 2.326886087335566

Epoch: 6| Step: 9
Training loss: 2.942600965499878
Validation loss: 2.3267346582105084

Epoch: 6| Step: 10
Training loss: 2.385739803314209
Validation loss: 2.3109593622146116

Epoch: 6| Step: 11
Training loss: 1.9750765562057495
Validation loss: 2.2982764756807716

Epoch: 6| Step: 12
Training loss: 2.359894037246704
Validation loss: 2.2861027820135957

Epoch: 6| Step: 13
Training loss: 3.59828782081604
Validation loss: 2.2894225556363343

Epoch: 77| Step: 0
Training loss: 2.077976703643799
Validation loss: 2.291627981329477

Epoch: 6| Step: 1
Training loss: 3.147128105163574
Validation loss: 2.3010357964423394

Epoch: 6| Step: 2
Training loss: 2.2913475036621094
Validation loss: 2.302443032623619

Epoch: 6| Step: 3
Training loss: 2.669677257537842
Validation loss: 2.297518232817291

Epoch: 6| Step: 4
Training loss: 3.0435738563537598
Validation loss: 2.28274340527032

Epoch: 6| Step: 5
Training loss: 2.5718517303466797
Validation loss: 2.2659735397625993

Epoch: 6| Step: 6
Training loss: 1.6385080814361572
Validation loss: 2.2520156111768497

Epoch: 6| Step: 7
Training loss: 2.7856462001800537
Validation loss: 2.2483580753367436

Epoch: 6| Step: 8
Training loss: 2.5508155822753906
Validation loss: 2.249226749584239

Epoch: 6| Step: 9
Training loss: 2.7344272136688232
Validation loss: 2.242182611137308

Epoch: 6| Step: 10
Training loss: 2.8334693908691406
Validation loss: 2.2432092287207164

Epoch: 6| Step: 11
Training loss: 1.9569389820098877
Validation loss: 2.246428058993432

Epoch: 6| Step: 12
Training loss: 3.409623146057129
Validation loss: 2.245731792142314

Epoch: 6| Step: 13
Training loss: 1.8977885246276855
Validation loss: 2.2460336659544256

Epoch: 78| Step: 0
Training loss: 2.667389154434204
Validation loss: 2.255186865406652

Epoch: 6| Step: 1
Training loss: 1.9989126920700073
Validation loss: 2.2731502133031047

Epoch: 6| Step: 2
Training loss: 2.4252688884735107
Validation loss: 2.2802059291511454

Epoch: 6| Step: 3
Training loss: 3.2037181854248047
Validation loss: 2.292210109772221

Epoch: 6| Step: 4
Training loss: 3.165943145751953
Validation loss: 2.274645315703525

Epoch: 6| Step: 5
Training loss: 2.4433043003082275
Validation loss: 2.265947486764641

Epoch: 6| Step: 6
Training loss: 2.436673641204834
Validation loss: 2.2476898880415064

Epoch: 6| Step: 7
Training loss: 2.606013536453247
Validation loss: 2.2441408762367825

Epoch: 6| Step: 8
Training loss: 2.1902859210968018
Validation loss: 2.244990938453264

Epoch: 6| Step: 9
Training loss: 1.8999080657958984
Validation loss: 2.245301215879379

Epoch: 6| Step: 10
Training loss: 2.5670113563537598
Validation loss: 2.2454861261511363

Epoch: 6| Step: 11
Training loss: 2.906798839569092
Validation loss: 2.244716500723234

Epoch: 6| Step: 12
Training loss: 2.3894858360290527
Validation loss: 2.2404452446968324

Epoch: 6| Step: 13
Training loss: 2.9363722801208496
Validation loss: 2.2506597618902884

Epoch: 79| Step: 0
Training loss: 3.066673517227173
Validation loss: 2.261510302943568

Epoch: 6| Step: 1
Training loss: 2.2886195182800293
Validation loss: 2.282917648233393

Epoch: 6| Step: 2
Training loss: 2.2759077548980713
Validation loss: 2.2964350946487917

Epoch: 6| Step: 3
Training loss: 2.5717782974243164
Validation loss: 2.3252773541276173

Epoch: 6| Step: 4
Training loss: 1.7510327100753784
Validation loss: 2.358422830540647

Epoch: 6| Step: 5
Training loss: 2.865626335144043
Validation loss: 2.357759902554174

Epoch: 6| Step: 6
Training loss: 2.6575841903686523
Validation loss: 2.358026248152538

Epoch: 6| Step: 7
Training loss: 2.582218647003174
Validation loss: 2.3199315058287753

Epoch: 6| Step: 8
Training loss: 2.89738130569458
Validation loss: 2.273348787779449

Epoch: 6| Step: 9
Training loss: 3.2072529792785645
Validation loss: 2.239559999076269

Epoch: 6| Step: 10
Training loss: 2.457761764526367
Validation loss: 2.2347590795127292

Epoch: 6| Step: 11
Training loss: 2.240344285964966
Validation loss: 2.237519987167851

Epoch: 6| Step: 12
Training loss: 2.2158596515655518
Validation loss: 2.2380806194838656

Epoch: 6| Step: 13
Training loss: 2.7605247497558594
Validation loss: 2.2408747467943417

Epoch: 80| Step: 0
Training loss: 2.3194475173950195
Validation loss: 2.2402245895836943

Epoch: 6| Step: 1
Training loss: 3.5560531616210938
Validation loss: 2.2416429904199417

Epoch: 6| Step: 2
Training loss: 2.529632091522217
Validation loss: 2.2413948684610348

Epoch: 6| Step: 3
Training loss: 2.2628402709960938
Validation loss: 2.2444290807170253

Epoch: 6| Step: 4
Training loss: 2.2534923553466797
Validation loss: 2.241209599279588

Epoch: 6| Step: 5
Training loss: 2.4973526000976562
Validation loss: 2.23884383837382

Epoch: 6| Step: 6
Training loss: 2.7234978675842285
Validation loss: 2.2326093232759865

Epoch: 6| Step: 7
Training loss: 2.118483543395996
Validation loss: 2.2322691473909604

Epoch: 6| Step: 8
Training loss: 2.782780647277832
Validation loss: 2.2337702102558588

Epoch: 6| Step: 9
Training loss: 2.580212354660034
Validation loss: 2.2340970039367676

Epoch: 6| Step: 10
Training loss: 2.876145839691162
Validation loss: 2.2366193622671147

Epoch: 6| Step: 11
Training loss: 2.519448757171631
Validation loss: 2.2469802338589906

Epoch: 6| Step: 12
Training loss: 2.4482810497283936
Validation loss: 2.261551469884893

Epoch: 6| Step: 13
Training loss: 1.8221791982650757
Validation loss: 2.273651381974579

Epoch: 81| Step: 0
Training loss: 3.187187671661377
Validation loss: 2.294853020739812

Epoch: 6| Step: 1
Training loss: 2.6289191246032715
Validation loss: 2.3026037267459336

Epoch: 6| Step: 2
Training loss: 2.369150400161743
Validation loss: 2.31819551221786

Epoch: 6| Step: 3
Training loss: 2.671704053878784
Validation loss: 2.3163516393271824

Epoch: 6| Step: 4
Training loss: 2.7800910472869873
Validation loss: 2.2880386588394

Epoch: 6| Step: 5
Training loss: 2.572204351425171
Validation loss: 2.2627466391491633

Epoch: 6| Step: 6
Training loss: 2.2349584102630615
Validation loss: 2.2407311162640973

Epoch: 6| Step: 7
Training loss: 2.0347952842712402
Validation loss: 2.233546046800511

Epoch: 6| Step: 8
Training loss: 1.9761821031570435
Validation loss: 2.2247167556516585

Epoch: 6| Step: 9
Training loss: 2.597957134246826
Validation loss: 2.221061450178905

Epoch: 6| Step: 10
Training loss: 2.488957405090332
Validation loss: 2.2137832615965154

Epoch: 6| Step: 11
Training loss: 2.7424728870391846
Validation loss: 2.214116391315255

Epoch: 6| Step: 12
Training loss: 2.453474998474121
Validation loss: 2.2186743751648934

Epoch: 6| Step: 13
Training loss: 3.055050849914551
Validation loss: 2.215352019956035

Epoch: 82| Step: 0
Training loss: 2.8363261222839355
Validation loss: 2.2244345013813307

Epoch: 6| Step: 1
Training loss: 2.418370246887207
Validation loss: 2.217599638046757

Epoch: 6| Step: 2
Training loss: 2.883647918701172
Validation loss: 2.2233168284098306

Epoch: 6| Step: 3
Training loss: 2.1778125762939453
Validation loss: 2.2179200623625066

Epoch: 6| Step: 4
Training loss: 2.172116756439209
Validation loss: 2.228833939439507

Epoch: 6| Step: 5
Training loss: 1.7407857179641724
Validation loss: 2.224726544913425

Epoch: 6| Step: 6
Training loss: 2.5829501152038574
Validation loss: 2.2268644353394866

Epoch: 6| Step: 7
Training loss: 2.705495834350586
Validation loss: 2.2292264520481067

Epoch: 6| Step: 8
Training loss: 2.7956812381744385
Validation loss: 2.231817058337632

Epoch: 6| Step: 9
Training loss: 3.129347801208496
Validation loss: 2.238957128217143

Epoch: 6| Step: 10
Training loss: 2.047884464263916
Validation loss: 2.245686802812802

Epoch: 6| Step: 11
Training loss: 2.817596197128296
Validation loss: 2.2509606935644664

Epoch: 6| Step: 12
Training loss: 2.413583755493164
Validation loss: 2.2528976881375877

Epoch: 6| Step: 13
Training loss: 2.9186935424804688
Validation loss: 2.2628466019066433

Epoch: 83| Step: 0
Training loss: 2.1975584030151367
Validation loss: 2.2918184495741323

Epoch: 6| Step: 1
Training loss: 2.4955894947052
Validation loss: 2.319063304572977

Epoch: 6| Step: 2
Training loss: 2.9844846725463867
Validation loss: 2.3591734799005653

Epoch: 6| Step: 3
Training loss: 2.9195573329925537
Validation loss: 2.397108124148461

Epoch: 6| Step: 4
Training loss: 1.9475889205932617
Validation loss: 2.404952854238531

Epoch: 6| Step: 5
Training loss: 1.6892815828323364
Validation loss: 2.4099293370400705

Epoch: 6| Step: 6
Training loss: 2.5328550338745117
Validation loss: 2.412398594681935

Epoch: 6| Step: 7
Training loss: 2.4064137935638428
Validation loss: 2.444066304032521

Epoch: 6| Step: 8
Training loss: 2.755251407623291
Validation loss: 2.4907396865147415

Epoch: 6| Step: 9
Training loss: 3.7266621589660645
Validation loss: 2.5604913696166007

Epoch: 6| Step: 10
Training loss: 3.2808034420013428
Validation loss: 2.601696830923839

Epoch: 6| Step: 11
Training loss: 2.321063995361328
Validation loss: 2.6151008452138593

Epoch: 6| Step: 12
Training loss: 3.13673734664917
Validation loss: 2.5989991464922504

Epoch: 6| Step: 13
Training loss: 2.8387324810028076
Validation loss: 2.514871361435101

Epoch: 84| Step: 0
Training loss: 2.589920997619629
Validation loss: 2.4272118947839223

Epoch: 6| Step: 1
Training loss: 3.2937817573547363
Validation loss: 2.3357698545661023

Epoch: 6| Step: 2
Training loss: 2.9160563945770264
Validation loss: 2.2745367673135575

Epoch: 6| Step: 3
Training loss: 2.439121723175049
Validation loss: 2.2563317873144664

Epoch: 6| Step: 4
Training loss: 2.6247811317443848
Validation loss: 2.2712653067804154

Epoch: 6| Step: 5
Training loss: 2.3614749908447266
Validation loss: 2.2948765139425955

Epoch: 6| Step: 6
Training loss: 2.1734695434570312
Validation loss: 2.2896390191970335

Epoch: 6| Step: 7
Training loss: 2.7791128158569336
Validation loss: 2.273633095525926

Epoch: 6| Step: 8
Training loss: 2.1723241806030273
Validation loss: 2.2231662709225892

Epoch: 6| Step: 9
Training loss: 2.2339653968811035
Validation loss: 2.2034271917035504

Epoch: 6| Step: 10
Training loss: 2.4640021324157715
Validation loss: 2.186153011937295

Epoch: 6| Step: 11
Training loss: 1.881920337677002
Validation loss: 2.197953515155341

Epoch: 6| Step: 12
Training loss: 2.847468852996826
Validation loss: 2.211775751524074

Epoch: 6| Step: 13
Training loss: 3.2588562965393066
Validation loss: 2.2310240294343684

Epoch: 85| Step: 0
Training loss: 2.745737075805664
Validation loss: 2.249564496419763

Epoch: 6| Step: 1
Training loss: 2.186650514602661
Validation loss: 2.262403160013178

Epoch: 6| Step: 2
Training loss: 2.5755865573883057
Validation loss: 2.28804107891616

Epoch: 6| Step: 3
Training loss: 2.359726667404175
Validation loss: 2.296536366144816

Epoch: 6| Step: 4
Training loss: 3.3451666831970215
Validation loss: 2.2801458835601807

Epoch: 6| Step: 5
Training loss: 2.3717987537384033
Validation loss: 2.2587219745882097

Epoch: 6| Step: 6
Training loss: 3.322683334350586
Validation loss: 2.2407661522588422

Epoch: 6| Step: 7
Training loss: 1.8815405368804932
Validation loss: 2.2219329803220687

Epoch: 6| Step: 8
Training loss: 2.6563034057617188
Validation loss: 2.2072619315116637

Epoch: 6| Step: 9
Training loss: 2.200385093688965
Validation loss: 2.2005879571360927

Epoch: 6| Step: 10
Training loss: 2.6484720706939697
Validation loss: 2.1976584234545307

Epoch: 6| Step: 11
Training loss: 2.566227436065674
Validation loss: 2.193939821694487

Epoch: 6| Step: 12
Training loss: 1.9848036766052246
Validation loss: 2.2004838707626506

Epoch: 6| Step: 13
Training loss: 2.6053268909454346
Validation loss: 2.1922391768424743

Epoch: 86| Step: 0
Training loss: 1.9764653444290161
Validation loss: 2.1905883422461887

Epoch: 6| Step: 1
Training loss: 2.0082056522369385
Validation loss: 2.1859139421934723

Epoch: 6| Step: 2
Training loss: 3.2536354064941406
Validation loss: 2.1951438303916686

Epoch: 6| Step: 3
Training loss: 2.559915542602539
Validation loss: 2.213689696404242

Epoch: 6| Step: 4
Training loss: 2.3630530834198
Validation loss: 2.2398038320643927

Epoch: 6| Step: 5
Training loss: 2.505493640899658
Validation loss: 2.291456817298807

Epoch: 6| Step: 6
Training loss: 2.637376308441162
Validation loss: 2.31541794858953

Epoch: 6| Step: 7
Training loss: 3.0288827419281006
Validation loss: 2.3527514652539323

Epoch: 6| Step: 8
Training loss: 2.186502456665039
Validation loss: 2.3416620069934475

Epoch: 6| Step: 9
Training loss: 3.2638158798217773
Validation loss: 2.3314104721110356

Epoch: 6| Step: 10
Training loss: 2.1405062675476074
Validation loss: 2.275968805436165

Epoch: 6| Step: 11
Training loss: 2.0594518184661865
Validation loss: 2.2020376728427027

Epoch: 6| Step: 12
Training loss: 2.834650993347168
Validation loss: 2.181179982359691

Epoch: 6| Step: 13
Training loss: 2.669307231903076
Validation loss: 2.1843857406288065

Epoch: 87| Step: 0
Training loss: 2.757877826690674
Validation loss: 2.208462417766612

Epoch: 6| Step: 1
Training loss: 2.108452796936035
Validation loss: 2.257643912428169

Epoch: 6| Step: 2
Training loss: 3.1578848361968994
Validation loss: 2.310116301300705

Epoch: 6| Step: 3
Training loss: 3.455232620239258
Validation loss: 2.3011292667799097

Epoch: 6| Step: 4
Training loss: 2.365187168121338
Validation loss: 2.2541676541810394

Epoch: 6| Step: 5
Training loss: 2.457796096801758
Validation loss: 2.2116310301647393

Epoch: 6| Step: 6
Training loss: 2.2247447967529297
Validation loss: 2.1993358519769486

Epoch: 6| Step: 7
Training loss: 2.848609447479248
Validation loss: 2.191187907290715

Epoch: 6| Step: 8
Training loss: 2.637859344482422
Validation loss: 2.188850261831796

Epoch: 6| Step: 9
Training loss: 2.426236391067505
Validation loss: 2.1978442310005106

Epoch: 6| Step: 10
Training loss: 2.458651304244995
Validation loss: 2.2242610403286514

Epoch: 6| Step: 11
Training loss: 1.8229753971099854
Validation loss: 2.234001264777235

Epoch: 6| Step: 12
Training loss: 2.2285943031311035
Validation loss: 2.2660960664031324

Epoch: 6| Step: 13
Training loss: 2.922633171081543
Validation loss: 2.307677927837577

Epoch: 88| Step: 0
Training loss: 2.613779067993164
Validation loss: 2.331174382599451

Epoch: 6| Step: 1
Training loss: 2.1094093322753906
Validation loss: 2.3256752926816224

Epoch: 6| Step: 2
Training loss: 2.67623233795166
Validation loss: 2.31405468140879

Epoch: 6| Step: 3
Training loss: 2.4894495010375977
Validation loss: 2.3013406825321976

Epoch: 6| Step: 4
Training loss: 2.7506957054138184
Validation loss: 2.2593461698101414

Epoch: 6| Step: 5
Training loss: 2.379354476928711
Validation loss: 2.2363881629000426

Epoch: 6| Step: 6
Training loss: 2.499511480331421
Validation loss: 2.2406546531185025

Epoch: 6| Step: 7
Training loss: 2.688657760620117
Validation loss: 2.250360709364696

Epoch: 6| Step: 8
Training loss: 3.2769856452941895
Validation loss: 2.2623274416051884

Epoch: 6| Step: 9
Training loss: 1.8563168048858643
Validation loss: 2.2691586504700365

Epoch: 6| Step: 10
Training loss: 2.3667945861816406
Validation loss: 2.2699106790686168

Epoch: 6| Step: 11
Training loss: 2.79733943939209
Validation loss: 2.2762322310478456

Epoch: 6| Step: 12
Training loss: 3.129978656768799
Validation loss: 2.264208657767183

Epoch: 6| Step: 13
Training loss: 1.7433127164840698
Validation loss: 2.2502959518022436

Epoch: 89| Step: 0
Training loss: 3.0537025928497314
Validation loss: 2.2298480003110823

Epoch: 6| Step: 1
Training loss: 2.3312854766845703
Validation loss: 2.2135753503409763

Epoch: 6| Step: 2
Training loss: 2.6034955978393555
Validation loss: 2.202898862541363

Epoch: 6| Step: 3
Training loss: 2.4867467880249023
Validation loss: 2.194608585808867

Epoch: 6| Step: 4
Training loss: 1.8231160640716553
Validation loss: 2.1922557507791827

Epoch: 6| Step: 5
Training loss: 2.5199830532073975
Validation loss: 2.196275867441649

Epoch: 6| Step: 6
Training loss: 2.2150886058807373
Validation loss: 2.231864506198514

Epoch: 6| Step: 7
Training loss: 2.1625378131866455
Validation loss: 2.270144248521456

Epoch: 6| Step: 8
Training loss: 2.680129051208496
Validation loss: 2.29939075439207

Epoch: 6| Step: 9
Training loss: 2.7409379482269287
Validation loss: 2.3330606388789352

Epoch: 6| Step: 10
Training loss: 2.767716407775879
Validation loss: 2.2869888915810535

Epoch: 6| Step: 11
Training loss: 2.9152350425720215
Validation loss: 2.2530494633541314

Epoch: 6| Step: 12
Training loss: 2.544334650039673
Validation loss: 2.219683575373824

Epoch: 6| Step: 13
Training loss: 2.348973035812378
Validation loss: 2.203014011024147

Epoch: 90| Step: 0
Training loss: 2.010263442993164
Validation loss: 2.1940897382715696

Epoch: 6| Step: 1
Training loss: 3.01332426071167
Validation loss: 2.1862305236119095

Epoch: 6| Step: 2
Training loss: 2.924077033996582
Validation loss: 2.181918672336045

Epoch: 6| Step: 3
Training loss: 2.062303066253662
Validation loss: 2.182597262884981

Epoch: 6| Step: 4
Training loss: 2.1217479705810547
Validation loss: 2.1836415183159614

Epoch: 6| Step: 5
Training loss: 2.518622875213623
Validation loss: 2.1812957845708376

Epoch: 6| Step: 6
Training loss: 2.2433154582977295
Validation loss: 2.176006181265718

Epoch: 6| Step: 7
Training loss: 2.4964516162872314
Validation loss: 2.1714249554500786

Epoch: 6| Step: 8
Training loss: 2.3803701400756836
Validation loss: 2.173909353953536

Epoch: 6| Step: 9
Training loss: 2.0286102294921875
Validation loss: 2.163999237040038

Epoch: 6| Step: 10
Training loss: 2.5093326568603516
Validation loss: 2.1791835318329515

Epoch: 6| Step: 11
Training loss: 3.1121695041656494
Validation loss: 2.1809911843269103

Epoch: 6| Step: 12
Training loss: 2.5232186317443848
Validation loss: 2.1925523050369753

Epoch: 6| Step: 13
Training loss: 3.2228386402130127
Validation loss: 2.2124242013500584

Epoch: 91| Step: 0
Training loss: 2.7954764366149902
Validation loss: 2.2197717082115913

Epoch: 6| Step: 1
Training loss: 2.0911049842834473
Validation loss: 2.2326853095844226

Epoch: 6| Step: 2
Training loss: 2.211394786834717
Validation loss: 2.2374094173472416

Epoch: 6| Step: 3
Training loss: 2.024735927581787
Validation loss: 2.218605746505081

Epoch: 6| Step: 4
Training loss: 2.655923843383789
Validation loss: 2.230935219795473

Epoch: 6| Step: 5
Training loss: 2.3532626628875732
Validation loss: 2.2296075462013163

Epoch: 6| Step: 6
Training loss: 2.3376245498657227
Validation loss: 2.23940098157493

Epoch: 6| Step: 7
Training loss: 3.059922218322754
Validation loss: 2.236728178557529

Epoch: 6| Step: 8
Training loss: 2.2316956520080566
Validation loss: 2.236934866956485

Epoch: 6| Step: 9
Training loss: 2.8810298442840576
Validation loss: 2.2160660887277253

Epoch: 6| Step: 10
Training loss: 2.718046188354492
Validation loss: 2.2192822989597114

Epoch: 6| Step: 11
Training loss: 2.9977612495422363
Validation loss: 2.213246396792832

Epoch: 6| Step: 12
Training loss: 2.64833927154541
Validation loss: 2.20866096532473

Epoch: 6| Step: 13
Training loss: 1.9626960754394531
Validation loss: 2.2098821055504585

Epoch: 92| Step: 0
Training loss: 1.9949865341186523
Validation loss: 2.211368509518203

Epoch: 6| Step: 1
Training loss: 2.2036550045013428
Validation loss: 2.19862546202957

Epoch: 6| Step: 2
Training loss: 2.628990650177002
Validation loss: 2.198679380519416

Epoch: 6| Step: 3
Training loss: 2.152606725692749
Validation loss: 2.2010262563664424

Epoch: 6| Step: 4
Training loss: 2.4774088859558105
Validation loss: 2.199166541458458

Epoch: 6| Step: 5
Training loss: 3.002318859100342
Validation loss: 2.192936433258877

Epoch: 6| Step: 6
Training loss: 2.1034035682678223
Validation loss: 2.198148530016663

Epoch: 6| Step: 7
Training loss: 2.3816909790039062
Validation loss: 2.18920152161711

Epoch: 6| Step: 8
Training loss: 2.06717586517334
Validation loss: 2.1895548489785965

Epoch: 6| Step: 9
Training loss: 2.8165464401245117
Validation loss: 2.201754331588745

Epoch: 6| Step: 10
Training loss: 2.7960801124572754
Validation loss: 2.1933866188090336

Epoch: 6| Step: 11
Training loss: 2.426003932952881
Validation loss: 2.2025365034739175

Epoch: 6| Step: 12
Training loss: 3.132336139678955
Validation loss: 2.2172540772345757

Epoch: 6| Step: 13
Training loss: 2.489943265914917
Validation loss: 2.2172165301538285

Epoch: 93| Step: 0
Training loss: 3.2102129459381104
Validation loss: 2.2267685321069535

Epoch: 6| Step: 1
Training loss: 2.7755982875823975
Validation loss: 2.234761620080599

Epoch: 6| Step: 2
Training loss: 2.4549367427825928
Validation loss: 2.245212137058217

Epoch: 6| Step: 3
Training loss: 2.393367290496826
Validation loss: 2.2286678514172955

Epoch: 6| Step: 4
Training loss: 2.5719754695892334
Validation loss: 2.2265895976815173

Epoch: 6| Step: 5
Training loss: 2.11156964302063
Validation loss: 2.21973075917972

Epoch: 6| Step: 6
Training loss: 2.226513147354126
Validation loss: 2.19566455195027

Epoch: 6| Step: 7
Training loss: 2.2221808433532715
Validation loss: 2.1811768777908815

Epoch: 6| Step: 8
Training loss: 3.0250420570373535
Validation loss: 2.1815698249365694

Epoch: 6| Step: 9
Training loss: 2.704939842224121
Validation loss: 2.175477791857976

Epoch: 6| Step: 10
Training loss: 2.133751392364502
Validation loss: 2.179605601936258

Epoch: 6| Step: 11
Training loss: 2.1616058349609375
Validation loss: 2.17322055626941

Epoch: 6| Step: 12
Training loss: 1.9627283811569214
Validation loss: 2.166876769834949

Epoch: 6| Step: 13
Training loss: 2.7581379413604736
Validation loss: 2.1666125738492577

Epoch: 94| Step: 0
Training loss: 2.139072895050049
Validation loss: 2.161177528801785

Epoch: 6| Step: 1
Training loss: 1.848222017288208
Validation loss: 2.1635796459772254

Epoch: 6| Step: 2
Training loss: 2.495042562484741
Validation loss: 2.163548490052582

Epoch: 6| Step: 3
Training loss: 2.2733211517333984
Validation loss: 2.163609826436607

Epoch: 6| Step: 4
Training loss: 2.3047378063201904
Validation loss: 2.1639518917247815

Epoch: 6| Step: 5
Training loss: 2.9507250785827637
Validation loss: 2.1675083996147237

Epoch: 6| Step: 6
Training loss: 2.9790632724761963
Validation loss: 2.1659227981362292

Epoch: 6| Step: 7
Training loss: 2.4911670684814453
Validation loss: 2.152451087069768

Epoch: 6| Step: 8
Training loss: 1.7293040752410889
Validation loss: 2.1516356827110372

Epoch: 6| Step: 9
Training loss: 2.4068121910095215
Validation loss: 2.154070390168057

Epoch: 6| Step: 10
Training loss: 2.27746319770813
Validation loss: 2.156158111428702

Epoch: 6| Step: 11
Training loss: 3.0717740058898926
Validation loss: 2.1592244948110273

Epoch: 6| Step: 12
Training loss: 2.8604161739349365
Validation loss: 2.160698697131167

Epoch: 6| Step: 13
Training loss: 2.773714542388916
Validation loss: 2.159043473582114

Epoch: 95| Step: 0
Training loss: 2.563872814178467
Validation loss: 2.17716625941697

Epoch: 6| Step: 1
Training loss: 3.261085033416748
Validation loss: 2.1774881642351867

Epoch: 6| Step: 2
Training loss: 2.5311384201049805
Validation loss: 2.1753496111080213

Epoch: 6| Step: 3
Training loss: 2.4607958793640137
Validation loss: 2.176580600841071

Epoch: 6| Step: 4
Training loss: 2.310215950012207
Validation loss: 2.17436521924952

Epoch: 6| Step: 5
Training loss: 2.2803046703338623
Validation loss: 2.165109005025638

Epoch: 6| Step: 6
Training loss: 2.4011929035186768
Validation loss: 2.1685651502301617

Epoch: 6| Step: 7
Training loss: 2.453244209289551
Validation loss: 2.176748555193665

Epoch: 6| Step: 8
Training loss: 1.7556593418121338
Validation loss: 2.1698273202424407

Epoch: 6| Step: 9
Training loss: 2.8423755168914795
Validation loss: 2.184676439531388

Epoch: 6| Step: 10
Training loss: 1.8173103332519531
Validation loss: 2.1960529447883688

Epoch: 6| Step: 11
Training loss: 2.5963549613952637
Validation loss: 2.185868893900225

Epoch: 6| Step: 12
Training loss: 2.8955888748168945
Validation loss: 2.1890051134171022

Epoch: 6| Step: 13
Training loss: 1.9099756479263306
Validation loss: 2.1892432038502028

Epoch: 96| Step: 0
Training loss: 2.6121559143066406
Validation loss: 2.1870799167181856

Epoch: 6| Step: 1
Training loss: 2.817267656326294
Validation loss: 2.174701388164233

Epoch: 6| Step: 2
Training loss: 2.514369487762451
Validation loss: 2.1764609249689246

Epoch: 6| Step: 3
Training loss: 2.524155616760254
Validation loss: 2.1716174041071246

Epoch: 6| Step: 4
Training loss: 2.4974288940429688
Validation loss: 2.1700061264858452

Epoch: 6| Step: 5
Training loss: 1.9310762882232666
Validation loss: 2.1697559523326095

Epoch: 6| Step: 6
Training loss: 2.6963775157928467
Validation loss: 2.1702717388829877

Epoch: 6| Step: 7
Training loss: 2.289626121520996
Validation loss: 2.1718507171959005

Epoch: 6| Step: 8
Training loss: 3.1775712966918945
Validation loss: 2.1653215295525006

Epoch: 6| Step: 9
Training loss: 2.2086100578308105
Validation loss: 2.1650363937500985

Epoch: 6| Step: 10
Training loss: 2.16597843170166
Validation loss: 2.1718546536660965

Epoch: 6| Step: 11
Training loss: 2.1902971267700195
Validation loss: 2.167419623303157

Epoch: 6| Step: 12
Training loss: 2.5920403003692627
Validation loss: 2.178327465570101

Epoch: 6| Step: 13
Training loss: 1.6303563117980957
Validation loss: 2.1665991198632026

Epoch: 97| Step: 0
Training loss: 2.4948644638061523
Validation loss: 2.1774591092140443

Epoch: 6| Step: 1
Training loss: 2.350602626800537
Validation loss: 2.190147146101921

Epoch: 6| Step: 2
Training loss: 2.2607786655426025
Validation loss: 2.179703366371893

Epoch: 6| Step: 3
Training loss: 1.6421289443969727
Validation loss: 2.186318682086083

Epoch: 6| Step: 4
Training loss: 2.585583209991455
Validation loss: 2.1868067582448325

Epoch: 6| Step: 5
Training loss: 3.009582042694092
Validation loss: 2.183269851951189

Epoch: 6| Step: 6
Training loss: 2.47390079498291
Validation loss: 2.2017757790063017

Epoch: 6| Step: 7
Training loss: 2.6469924449920654
Validation loss: 2.1898224815245597

Epoch: 6| Step: 8
Training loss: 2.935457229614258
Validation loss: 2.1772989996017946

Epoch: 6| Step: 9
Training loss: 2.407623291015625
Validation loss: 2.1792878732886365

Epoch: 6| Step: 10
Training loss: 2.714080810546875
Validation loss: 2.180078233441999

Epoch: 6| Step: 11
Training loss: 1.721542239189148
Validation loss: 2.165040426356818

Epoch: 6| Step: 12
Training loss: 2.6171767711639404
Validation loss: 2.155694256546677

Epoch: 6| Step: 13
Training loss: 2.3740663528442383
Validation loss: 2.1611543522086194

Epoch: 98| Step: 0
Training loss: 2.2114667892456055
Validation loss: 2.1750738364393993

Epoch: 6| Step: 1
Training loss: 2.2420551776885986
Validation loss: 2.176936129088043

Epoch: 6| Step: 2
Training loss: 2.8510971069335938
Validation loss: 2.19575834274292

Epoch: 6| Step: 3
Training loss: 3.055189847946167
Validation loss: 2.2089870283680577

Epoch: 6| Step: 4
Training loss: 2.830744743347168
Validation loss: 2.223284741883637

Epoch: 6| Step: 5
Training loss: 2.409877300262451
Validation loss: 2.2234648325109996

Epoch: 6| Step: 6
Training loss: 2.078273296356201
Validation loss: 2.22846100407262

Epoch: 6| Step: 7
Training loss: 2.3233118057250977
Validation loss: 2.214158294021442

Epoch: 6| Step: 8
Training loss: 1.5724833011627197
Validation loss: 2.2120682449751

Epoch: 6| Step: 9
Training loss: 2.670170307159424
Validation loss: 2.2025642254019298

Epoch: 6| Step: 10
Training loss: 1.8838204145431519
Validation loss: 2.1944884292541014

Epoch: 6| Step: 11
Training loss: 2.9071719646453857
Validation loss: 2.188692372332337

Epoch: 6| Step: 12
Training loss: 2.8846006393432617
Validation loss: 2.175184162714148

Epoch: 6| Step: 13
Training loss: 2.069314479827881
Validation loss: 2.17069395126835

Epoch: 99| Step: 0
Training loss: 2.7538836002349854
Validation loss: 2.1799351553763113

Epoch: 6| Step: 1
Training loss: 2.1442465782165527
Validation loss: 2.183841029802958

Epoch: 6| Step: 2
Training loss: 1.880883812904358
Validation loss: 2.184584879106091

Epoch: 6| Step: 3
Training loss: 2.5937769412994385
Validation loss: 2.1974313143760926

Epoch: 6| Step: 4
Training loss: 2.537118434906006
Validation loss: 2.2072474853966826

Epoch: 6| Step: 5
Training loss: 1.8616926670074463
Validation loss: 2.218846704370232

Epoch: 6| Step: 6
Training loss: 3.1044907569885254
Validation loss: 2.2186950047810874

Epoch: 6| Step: 7
Training loss: 2.4044394493103027
Validation loss: 2.2145303654414352

Epoch: 6| Step: 8
Training loss: 2.7096011638641357
Validation loss: 2.197608495271334

Epoch: 6| Step: 9
Training loss: 2.543539524078369
Validation loss: 2.1966651998540407

Epoch: 6| Step: 10
Training loss: 2.3903794288635254
Validation loss: 2.2112493976469962

Epoch: 6| Step: 11
Training loss: 1.8630156517028809
Validation loss: 2.1929946150830997

Epoch: 6| Step: 12
Training loss: 2.8264689445495605
Validation loss: 2.200189371262827

Epoch: 6| Step: 13
Training loss: 2.3082714080810547
Validation loss: 2.195864410810573

Epoch: 100| Step: 0
Training loss: 3.081658124923706
Validation loss: 2.199755955767888

Epoch: 6| Step: 1
Training loss: 2.6184563636779785
Validation loss: 2.175978575983355

Epoch: 6| Step: 2
Training loss: 2.6563260555267334
Validation loss: 2.1774486085420013

Epoch: 6| Step: 3
Training loss: 2.2962710857391357
Validation loss: 2.1704240973277757

Epoch: 6| Step: 4
Training loss: 3.2115697860717773
Validation loss: 2.1645898242150583

Epoch: 6| Step: 5
Training loss: 2.065232038497925
Validation loss: 2.163957175388131

Epoch: 6| Step: 6
Training loss: 2.24747371673584
Validation loss: 2.187788804372152

Epoch: 6| Step: 7
Training loss: 1.7119240760803223
Validation loss: 2.2152473593270905

Epoch: 6| Step: 8
Training loss: 2.530301094055176
Validation loss: 2.2150862947587044

Epoch: 6| Step: 9
Training loss: 2.6366915702819824
Validation loss: 2.2122902075449624

Epoch: 6| Step: 10
Training loss: 2.1008267402648926
Validation loss: 2.2000932078207693

Epoch: 6| Step: 11
Training loss: 2.207075357437134
Validation loss: 2.2049355852988457

Epoch: 6| Step: 12
Training loss: 2.5508501529693604
Validation loss: 2.1877975822776876

Epoch: 6| Step: 13
Training loss: 2.460164785385132
Validation loss: 2.191232035236974

Epoch: 101| Step: 0
Training loss: 2.807896375656128
Validation loss: 2.1664412457455873

Epoch: 6| Step: 1
Training loss: 1.8294517993927002
Validation loss: 2.176985263824463

Epoch: 6| Step: 2
Training loss: 2.1274662017822266
Validation loss: 2.2046764025124173

Epoch: 6| Step: 3
Training loss: 3.1428089141845703
Validation loss: 2.240438033175725

Epoch: 6| Step: 4
Training loss: 1.5506680011749268
Validation loss: 2.2557350435564594

Epoch: 6| Step: 5
Training loss: 2.6035752296447754
Validation loss: 2.2656874848950292

Epoch: 6| Step: 6
Training loss: 2.3802337646484375
Validation loss: 2.2848981734245055

Epoch: 6| Step: 7
Training loss: 2.4329192638397217
Validation loss: 2.258059240156604

Epoch: 6| Step: 8
Training loss: 2.5311665534973145
Validation loss: 2.2187407503845873

Epoch: 6| Step: 9
Training loss: 3.2121543884277344
Validation loss: 2.1920498532633625

Epoch: 6| Step: 10
Training loss: 2.6307778358459473
Validation loss: 2.174256593950333

Epoch: 6| Step: 11
Training loss: 2.513129711151123
Validation loss: 2.1327293367796045

Epoch: 6| Step: 12
Training loss: 1.684889316558838
Validation loss: 2.129546239811887

Epoch: 6| Step: 13
Training loss: 2.8861098289489746
Validation loss: 2.125447206599738

Epoch: 102| Step: 0
Training loss: 2.0202832221984863
Validation loss: 2.123250158884192

Epoch: 6| Step: 1
Training loss: 1.967293620109558
Validation loss: 2.135748355619369

Epoch: 6| Step: 2
Training loss: 2.572606086730957
Validation loss: 2.153189536063902

Epoch: 6| Step: 3
Training loss: 2.594252824783325
Validation loss: 2.1780297140921316

Epoch: 6| Step: 4
Training loss: 1.9507852792739868
Validation loss: 2.2024268411820933

Epoch: 6| Step: 5
Training loss: 3.3951468467712402
Validation loss: 2.2313249546994447

Epoch: 6| Step: 6
Training loss: 2.2126376628875732
Validation loss: 2.2228843653073875

Epoch: 6| Step: 7
Training loss: 2.404559850692749
Validation loss: 2.2448741825678016

Epoch: 6| Step: 8
Training loss: 3.1813552379608154
Validation loss: 2.2410534210102533

Epoch: 6| Step: 9
Training loss: 3.1056599617004395
Validation loss: 2.1897413961348997

Epoch: 6| Step: 10
Training loss: 1.8642728328704834
Validation loss: 2.16434161637419

Epoch: 6| Step: 11
Training loss: 2.1509783267974854
Validation loss: 2.1413602521342616

Epoch: 6| Step: 12
Training loss: 2.7291781902313232
Validation loss: 2.1388198791011686

Epoch: 6| Step: 13
Training loss: 1.8676825761795044
Validation loss: 2.1825669170707784

Epoch: 103| Step: 0
Training loss: 2.5470409393310547
Validation loss: 2.2611180633626957

Epoch: 6| Step: 1
Training loss: 1.9359177350997925
Validation loss: 2.366715162031112

Epoch: 6| Step: 2
Training loss: 2.494356155395508
Validation loss: 2.3572464066167034

Epoch: 6| Step: 3
Training loss: 2.582475185394287
Validation loss: 2.3709860309477775

Epoch: 6| Step: 4
Training loss: 2.372036933898926
Validation loss: 2.35420649538758

Epoch: 6| Step: 5
Training loss: 2.286039113998413
Validation loss: 2.3173047265698834

Epoch: 6| Step: 6
Training loss: 2.200472354888916
Validation loss: 2.27659954819628

Epoch: 6| Step: 7
Training loss: 3.248584270477295
Validation loss: 2.215865488975279

Epoch: 6| Step: 8
Training loss: 2.6882424354553223
Validation loss: 2.169220510349479

Epoch: 6| Step: 9
Training loss: 2.3002185821533203
Validation loss: 2.161285103008311

Epoch: 6| Step: 10
Training loss: 2.4253649711608887
Validation loss: 2.1483980840252292

Epoch: 6| Step: 11
Training loss: 2.3632328510284424
Validation loss: 2.1497950374439196

Epoch: 6| Step: 12
Training loss: 2.612090826034546
Validation loss: 2.2030247565238708

Epoch: 6| Step: 13
Training loss: 2.126187324523926
Validation loss: 2.2720253903378724

Epoch: 104| Step: 0
Training loss: 2.823002338409424
Validation loss: 2.255994491679694

Epoch: 6| Step: 1
Training loss: 2.839994192123413
Validation loss: 2.2125796784636793

Epoch: 6| Step: 2
Training loss: 2.3581955432891846
Validation loss: 2.169074294387653

Epoch: 6| Step: 3
Training loss: 1.9297070503234863
Validation loss: 2.145195257279181

Epoch: 6| Step: 4
Training loss: 2.1972851753234863
Validation loss: 2.1339180084966842

Epoch: 6| Step: 5
Training loss: 2.4227538108825684
Validation loss: 2.123820827853295

Epoch: 6| Step: 6
Training loss: 2.5568008422851562
Validation loss: 2.116081355720438

Epoch: 6| Step: 7
Training loss: 3.059190273284912
Validation loss: 2.12473044600538

Epoch: 6| Step: 8
Training loss: 2.1431140899658203
Validation loss: 2.1161076074005454

Epoch: 6| Step: 9
Training loss: 2.3448753356933594
Validation loss: 2.1272507457322973

Epoch: 6| Step: 10
Training loss: 2.1634621620178223
Validation loss: 2.1279600538233274

Epoch: 6| Step: 11
Training loss: 2.5094757080078125
Validation loss: 2.137034518744356

Epoch: 6| Step: 12
Training loss: 2.4690377712249756
Validation loss: 2.1387122369581655

Epoch: 6| Step: 13
Training loss: 2.2040891647338867
Validation loss: 2.1617152742160264

Epoch: 105| Step: 0
Training loss: 2.315458297729492
Validation loss: 2.178621176750429

Epoch: 6| Step: 1
Training loss: 2.0332632064819336
Validation loss: 2.188421840308815

Epoch: 6| Step: 2
Training loss: 3.2000887393951416
Validation loss: 2.21856717653172

Epoch: 6| Step: 3
Training loss: 2.482581615447998
Validation loss: 2.2313936013047413

Epoch: 6| Step: 4
Training loss: 2.59114933013916
Validation loss: 2.2201465945090018

Epoch: 6| Step: 5
Training loss: 1.9966049194335938
Validation loss: 2.214717318934779

Epoch: 6| Step: 6
Training loss: 2.5538923740386963
Validation loss: 2.202364190932243

Epoch: 6| Step: 7
Training loss: 2.985231637954712
Validation loss: 2.1739460678510767

Epoch: 6| Step: 8
Training loss: 2.4384748935699463
Validation loss: 2.147987678486814

Epoch: 6| Step: 9
Training loss: 2.0263726711273193
Validation loss: 2.1279109549778763

Epoch: 6| Step: 10
Training loss: 1.7976386547088623
Validation loss: 2.122647403388895

Epoch: 6| Step: 11
Training loss: 2.529867172241211
Validation loss: 2.114783638267107

Epoch: 6| Step: 12
Training loss: 2.0718178749084473
Validation loss: 2.1149829869629233

Epoch: 6| Step: 13
Training loss: 2.886474847793579
Validation loss: 2.140565706837562

Epoch: 106| Step: 0
Training loss: 2.8525006771087646
Validation loss: 2.191250570358769

Epoch: 6| Step: 1
Training loss: 3.2634291648864746
Validation loss: 2.2885733009666525

Epoch: 6| Step: 2
Training loss: 2.302079439163208
Validation loss: 2.43974797443677

Epoch: 6| Step: 3
Training loss: 2.114830493927002
Validation loss: 2.4750473050660986

Epoch: 6| Step: 4
Training loss: 2.977294445037842
Validation loss: 2.3177185930231565

Epoch: 6| Step: 5
Training loss: 2.4222514629364014
Validation loss: 2.2297867805727067

Epoch: 6| Step: 6
Training loss: 2.9037866592407227
Validation loss: 2.187390873509069

Epoch: 6| Step: 7
Training loss: 1.9444868564605713
Validation loss: 2.1485141297822357

Epoch: 6| Step: 8
Training loss: 1.6750340461730957
Validation loss: 2.130523955950173

Epoch: 6| Step: 9
Training loss: 2.8512802124023438
Validation loss: 2.1275640995271745

Epoch: 6| Step: 10
Training loss: 2.428514242172241
Validation loss: 2.129827353262132

Epoch: 6| Step: 11
Training loss: 1.7059873342514038
Validation loss: 2.154346953156174

Epoch: 6| Step: 12
Training loss: 2.1860687732696533
Validation loss: 2.1751228878574986

Epoch: 6| Step: 13
Training loss: 2.5258684158325195
Validation loss: 2.202819324308826

Epoch: 107| Step: 0
Training loss: 2.1353464126586914
Validation loss: 2.2611049913590953

Epoch: 6| Step: 1
Training loss: 2.137882947921753
Validation loss: 2.32602200969573

Epoch: 6| Step: 2
Training loss: 2.359417200088501
Validation loss: 2.304961990284663

Epoch: 6| Step: 3
Training loss: 2.395159959793091
Validation loss: 2.267121094529347

Epoch: 6| Step: 4
Training loss: 3.3013663291931152
Validation loss: 2.1933957069150862

Epoch: 6| Step: 5
Training loss: 2.628756046295166
Validation loss: 2.148187272010311

Epoch: 6| Step: 6
Training loss: 2.8368794918060303
Validation loss: 2.1167597398963025

Epoch: 6| Step: 7
Training loss: 3.259765148162842
Validation loss: 2.1084672763783443

Epoch: 6| Step: 8
Training loss: 2.575958251953125
Validation loss: 2.102394498804564

Epoch: 6| Step: 9
Training loss: 1.995155930519104
Validation loss: 2.109436704266456

Epoch: 6| Step: 10
Training loss: 2.113738775253296
Validation loss: 2.1069550591130413

Epoch: 6| Step: 11
Training loss: 1.8233243227005005
Validation loss: 2.1114491211470736

Epoch: 6| Step: 12
Training loss: 2.4354963302612305
Validation loss: 2.108434013141099

Epoch: 6| Step: 13
Training loss: 2.384888172149658
Validation loss: 2.10720548834852

Epoch: 108| Step: 0
Training loss: 2.937039613723755
Validation loss: 2.102864001386909

Epoch: 6| Step: 1
Training loss: 2.4856653213500977
Validation loss: 2.111034584301774

Epoch: 6| Step: 2
Training loss: 2.963604211807251
Validation loss: 2.1151333957590084

Epoch: 6| Step: 3
Training loss: 2.1723921298980713
Validation loss: 2.120162025574715

Epoch: 6| Step: 4
Training loss: 2.6001970767974854
Validation loss: 2.1235112323555896

Epoch: 6| Step: 5
Training loss: 1.919416904449463
Validation loss: 2.1300077002535582

Epoch: 6| Step: 6
Training loss: 2.278017997741699
Validation loss: 2.1312116653688493

Epoch: 6| Step: 7
Training loss: 2.2610273361206055
Validation loss: 2.126267494693879

Epoch: 6| Step: 8
Training loss: 2.1472957134246826
Validation loss: 2.1349754692405782

Epoch: 6| Step: 9
Training loss: 2.2042288780212402
Validation loss: 2.1634189749276764

Epoch: 6| Step: 10
Training loss: 1.7194395065307617
Validation loss: 2.1568301467485327

Epoch: 6| Step: 11
Training loss: 2.8395605087280273
Validation loss: 2.165543394704019

Epoch: 6| Step: 12
Training loss: 2.2957143783569336
Validation loss: 2.1817970455333753

Epoch: 6| Step: 13
Training loss: 2.7609548568725586
Validation loss: 2.1925324752766597

Epoch: 109| Step: 0
Training loss: 2.4205322265625
Validation loss: 2.1926024895842358

Epoch: 6| Step: 1
Training loss: 2.3391494750976562
Validation loss: 2.207161908508629

Epoch: 6| Step: 2
Training loss: 2.7564635276794434
Validation loss: 2.210250032845364

Epoch: 6| Step: 3
Training loss: 2.9184036254882812
Validation loss: 2.2089179126165246

Epoch: 6| Step: 4
Training loss: 2.4033102989196777
Validation loss: 2.188248825329606

Epoch: 6| Step: 5
Training loss: 2.072679281234741
Validation loss: 2.1838660111991306

Epoch: 6| Step: 6
Training loss: 2.69830060005188
Validation loss: 2.175396104012766

Epoch: 6| Step: 7
Training loss: 1.4434397220611572
Validation loss: 2.1659701819060952

Epoch: 6| Step: 8
Training loss: 2.4970343112945557
Validation loss: 2.174824409587409

Epoch: 6| Step: 9
Training loss: 1.9448859691619873
Validation loss: 2.1693629551959295

Epoch: 6| Step: 10
Training loss: 2.5995700359344482
Validation loss: 2.1749310032013924

Epoch: 6| Step: 11
Training loss: 2.8546433448791504
Validation loss: 2.1915994587764946

Epoch: 6| Step: 12
Training loss: 2.064678192138672
Validation loss: 2.192685978386992

Epoch: 6| Step: 13
Training loss: 2.416844367980957
Validation loss: 2.1712293676150742

Epoch: 110| Step: 0
Training loss: 2.4434361457824707
Validation loss: 2.1285999410895893

Epoch: 6| Step: 1
Training loss: 2.1564455032348633
Validation loss: 2.126718041717365

Epoch: 6| Step: 2
Training loss: 1.658990502357483
Validation loss: 2.1152216901061354

Epoch: 6| Step: 3
Training loss: 2.6262924671173096
Validation loss: 2.111099563619142

Epoch: 6| Step: 4
Training loss: 3.3271729946136475
Validation loss: 2.1151652900121545

Epoch: 6| Step: 5
Training loss: 2.358912467956543
Validation loss: 2.1056740514693724

Epoch: 6| Step: 6
Training loss: 2.4396812915802
Validation loss: 2.1159212358536257

Epoch: 6| Step: 7
Training loss: 2.9107446670532227
Validation loss: 2.101650793065307

Epoch: 6| Step: 8
Training loss: 2.066628932952881
Validation loss: 2.118872175934494

Epoch: 6| Step: 9
Training loss: 2.1545088291168213
Validation loss: 2.1048021008891444

Epoch: 6| Step: 10
Training loss: 2.4850311279296875
Validation loss: 2.1127321463759228

Epoch: 6| Step: 11
Training loss: 1.9259772300720215
Validation loss: 2.104171501692905

Epoch: 6| Step: 12
Training loss: 2.781693458557129
Validation loss: 2.08390232311782

Epoch: 6| Step: 13
Training loss: 1.9861454963684082
Validation loss: 2.0826347489510812

Epoch: 111| Step: 0
Training loss: 2.598863124847412
Validation loss: 2.0783023911137737

Epoch: 6| Step: 1
Training loss: 2.015563488006592
Validation loss: 2.086892799664569

Epoch: 6| Step: 2
Training loss: 1.4672112464904785
Validation loss: 2.092517457982545

Epoch: 6| Step: 3
Training loss: 2.4565305709838867
Validation loss: 2.0931399612016577

Epoch: 6| Step: 4
Training loss: 2.653012275695801
Validation loss: 2.089597386698569

Epoch: 6| Step: 5
Training loss: 2.164379358291626
Validation loss: 2.101734866378128

Epoch: 6| Step: 6
Training loss: 2.9228882789611816
Validation loss: 2.103155148926602

Epoch: 6| Step: 7
Training loss: 2.308215379714966
Validation loss: 2.098580395021746

Epoch: 6| Step: 8
Training loss: 2.4207396507263184
Validation loss: 2.0992791204042334

Epoch: 6| Step: 9
Training loss: 2.040653705596924
Validation loss: 2.105000695874614

Epoch: 6| Step: 10
Training loss: 2.4638233184814453
Validation loss: 2.0997616898628975

Epoch: 6| Step: 11
Training loss: 2.315965175628662
Validation loss: 2.100712755674957

Epoch: 6| Step: 12
Training loss: 2.4432411193847656
Validation loss: 2.08764063542889

Epoch: 6| Step: 13
Training loss: 2.883577585220337
Validation loss: 2.0927618575352493

Epoch: 112| Step: 0
Training loss: 2.226536273956299
Validation loss: 2.101872626171317

Epoch: 6| Step: 1
Training loss: 2.0634005069732666
Validation loss: 2.102988822485811

Epoch: 6| Step: 2
Training loss: 2.844635009765625
Validation loss: 2.112858303131596

Epoch: 6| Step: 3
Training loss: 2.86867094039917
Validation loss: 2.1317657834740094

Epoch: 6| Step: 4
Training loss: 3.123178720474243
Validation loss: 2.1355908122113956

Epoch: 6| Step: 5
Training loss: 1.9965016841888428
Validation loss: 2.1492896772200063

Epoch: 6| Step: 6
Training loss: 1.6167652606964111
Validation loss: 2.199254225659114

Epoch: 6| Step: 7
Training loss: 2.089900016784668
Validation loss: 2.2282943648676716

Epoch: 6| Step: 8
Training loss: 2.0857181549072266
Validation loss: 2.248182145498132

Epoch: 6| Step: 9
Training loss: 2.347029685974121
Validation loss: 2.256209176073792

Epoch: 6| Step: 10
Training loss: 2.8160147666931152
Validation loss: 2.240941495023748

Epoch: 6| Step: 11
Training loss: 2.2046520709991455
Validation loss: 2.2458388446479716

Epoch: 6| Step: 12
Training loss: 2.545442581176758
Validation loss: 2.2267939608584166

Epoch: 6| Step: 13
Training loss: 2.3201136589050293
Validation loss: 2.1928206464295745

Epoch: 113| Step: 0
Training loss: 2.7488515377044678
Validation loss: 2.171104828516642

Epoch: 6| Step: 1
Training loss: 2.730358600616455
Validation loss: 2.2212525080609065

Epoch: 6| Step: 2
Training loss: 1.9651658535003662
Validation loss: 2.2645941242094962

Epoch: 6| Step: 3
Training loss: 3.1424694061279297
Validation loss: 2.3269202247742684

Epoch: 6| Step: 4
Training loss: 1.7757608890533447
Validation loss: 2.3317382322844638

Epoch: 6| Step: 5
Training loss: 2.500065803527832
Validation loss: 2.2791788693397277

Epoch: 6| Step: 6
Training loss: 2.6998138427734375
Validation loss: 2.204635686771844

Epoch: 6| Step: 7
Training loss: 2.5745046138763428
Validation loss: 2.1554035294440483

Epoch: 6| Step: 8
Training loss: 2.0705678462982178
Validation loss: 2.1143332142983713

Epoch: 6| Step: 9
Training loss: 2.0217130184173584
Validation loss: 2.095140769917478

Epoch: 6| Step: 10
Training loss: 2.795327663421631
Validation loss: 2.115978644740197

Epoch: 6| Step: 11
Training loss: 1.7082356214523315
Validation loss: 2.1200602490414857

Epoch: 6| Step: 12
Training loss: 2.3829872608184814
Validation loss: 2.1604519762018675

Epoch: 6| Step: 13
Training loss: 3.349637985229492
Validation loss: 2.1829088516132806

Epoch: 114| Step: 0
Training loss: 2.722515344619751
Validation loss: 2.1474514545932895

Epoch: 6| Step: 1
Training loss: 2.5197672843933105
Validation loss: 2.1254656366122666

Epoch: 6| Step: 2
Training loss: 2.181490421295166
Validation loss: 2.117417891820272

Epoch: 6| Step: 3
Training loss: 2.378291368484497
Validation loss: 2.093545672714069

Epoch: 6| Step: 4
Training loss: 3.0439109802246094
Validation loss: 2.0890608397863244

Epoch: 6| Step: 5
Training loss: 2.0112295150756836
Validation loss: 2.0787121980421004

Epoch: 6| Step: 6
Training loss: 2.0037736892700195
Validation loss: 2.0757454543985348

Epoch: 6| Step: 7
Training loss: 2.430767297744751
Validation loss: 2.0635040165275655

Epoch: 6| Step: 8
Training loss: 1.1172826290130615
Validation loss: 2.0779242964201075

Epoch: 6| Step: 9
Training loss: 2.878580093383789
Validation loss: 2.0943874518076577

Epoch: 6| Step: 10
Training loss: 2.828805923461914
Validation loss: 2.097046717520683

Epoch: 6| Step: 11
Training loss: 1.88380765914917
Validation loss: 2.0938268784553773

Epoch: 6| Step: 12
Training loss: 2.4797091484069824
Validation loss: 2.091718286596319

Epoch: 6| Step: 13
Training loss: 2.564488410949707
Validation loss: 2.083612876553689

Epoch: 115| Step: 0
Training loss: 2.9611687660217285
Validation loss: 2.0916937512736165

Epoch: 6| Step: 1
Training loss: 1.83841073513031
Validation loss: 2.090324068582186

Epoch: 6| Step: 2
Training loss: 2.3255631923675537
Validation loss: 2.1001476241696264

Epoch: 6| Step: 3
Training loss: 2.0094246864318848
Validation loss: 2.080086346595518

Epoch: 6| Step: 4
Training loss: 1.7842340469360352
Validation loss: 2.084645450756114

Epoch: 6| Step: 5
Training loss: 3.0646543502807617
Validation loss: 2.086679973909932

Epoch: 6| Step: 6
Training loss: 2.798968553543091
Validation loss: 2.0883704487995436

Epoch: 6| Step: 7
Training loss: 1.9009010791778564
Validation loss: 2.0948411546727663

Epoch: 6| Step: 8
Training loss: 2.1627919673919678
Validation loss: 2.110217571258545

Epoch: 6| Step: 9
Training loss: 1.8933372497558594
Validation loss: 2.112746971909718

Epoch: 6| Step: 10
Training loss: 3.3449549674987793
Validation loss: 2.1184432455288467

Epoch: 6| Step: 11
Training loss: 2.416696786880493
Validation loss: 2.1251914578099407

Epoch: 6| Step: 12
Training loss: 1.918457269668579
Validation loss: 2.116402054345736

Epoch: 6| Step: 13
Training loss: 2.302574872970581
Validation loss: 2.128262973600818

Epoch: 116| Step: 0
Training loss: 3.2582437992095947
Validation loss: 2.127160008235644

Epoch: 6| Step: 1
Training loss: 2.3629844188690186
Validation loss: 2.1406510619707007

Epoch: 6| Step: 2
Training loss: 2.9552736282348633
Validation loss: 2.153517448773948

Epoch: 6| Step: 3
Training loss: 2.3462905883789062
Validation loss: 2.1220523465064263

Epoch: 6| Step: 4
Training loss: 2.102168083190918
Validation loss: 2.123911352567775

Epoch: 6| Step: 5
Training loss: 2.2277650833129883
Validation loss: 2.1209365424289497

Epoch: 6| Step: 6
Training loss: 2.6581645011901855
Validation loss: 2.1095548522087837

Epoch: 6| Step: 7
Training loss: 1.706784963607788
Validation loss: 2.1130721902334564

Epoch: 6| Step: 8
Training loss: 1.9529722929000854
Validation loss: 2.1208808191360964

Epoch: 6| Step: 9
Training loss: 2.0972583293914795
Validation loss: 2.1223799990069483

Epoch: 6| Step: 10
Training loss: 1.9536030292510986
Validation loss: 2.125594949209562

Epoch: 6| Step: 11
Training loss: 1.7085047960281372
Validation loss: 2.1250214269084315

Epoch: 6| Step: 12
Training loss: 2.78562593460083
Validation loss: 2.1297438529229935

Epoch: 6| Step: 13
Training loss: 2.5571959018707275
Validation loss: 2.1286700707609936

Epoch: 117| Step: 0
Training loss: 2.46846866607666
Validation loss: 2.1320893226131314

Epoch: 6| Step: 1
Training loss: 2.4238007068634033
Validation loss: 2.112067207213371

Epoch: 6| Step: 2
Training loss: 1.7626937627792358
Validation loss: 2.113185085276122

Epoch: 6| Step: 3
Training loss: 2.434628486633301
Validation loss: 2.100514499090051

Epoch: 6| Step: 4
Training loss: 1.3875099420547485
Validation loss: 2.0965410355598695

Epoch: 6| Step: 5
Training loss: 2.191971778869629
Validation loss: 2.1071702408534225

Epoch: 6| Step: 6
Training loss: 2.5241281986236572
Validation loss: 2.0990570450341828

Epoch: 6| Step: 7
Training loss: 2.3263580799102783
Validation loss: 2.090213337252217

Epoch: 6| Step: 8
Training loss: 2.2238810062408447
Validation loss: 2.099481628787133

Epoch: 6| Step: 9
Training loss: 2.5700573921203613
Validation loss: 2.1078632595718547

Epoch: 6| Step: 10
Training loss: 2.7130002975463867
Validation loss: 2.1070615271086335

Epoch: 6| Step: 11
Training loss: 2.3970985412597656
Validation loss: 2.1362917679612354

Epoch: 6| Step: 12
Training loss: 2.219942092895508
Validation loss: 2.1306118939512517

Epoch: 6| Step: 13
Training loss: 2.6998894214630127
Validation loss: 2.1208671523678686

Epoch: 118| Step: 0
Training loss: 1.60732102394104
Validation loss: 2.1102259210360947

Epoch: 6| Step: 1
Training loss: 2.059337854385376
Validation loss: 2.109726652022331

Epoch: 6| Step: 2
Training loss: 3.454371452331543
Validation loss: 2.1179273384873585

Epoch: 6| Step: 3
Training loss: 2.224153757095337
Validation loss: 2.138745912941553

Epoch: 6| Step: 4
Training loss: 2.1892032623291016
Validation loss: 2.1579831313061457

Epoch: 6| Step: 5
Training loss: 2.024064540863037
Validation loss: 2.1446495184334378

Epoch: 6| Step: 6
Training loss: 2.549262523651123
Validation loss: 2.148296453619516

Epoch: 6| Step: 7
Training loss: 2.519683837890625
Validation loss: 2.1213018663467897

Epoch: 6| Step: 8
Training loss: 2.4663820266723633
Validation loss: 2.1229146372887397

Epoch: 6| Step: 9
Training loss: 2.7122411727905273
Validation loss: 2.100116704099922

Epoch: 6| Step: 10
Training loss: 1.8852074146270752
Validation loss: 2.085800249089477

Epoch: 6| Step: 11
Training loss: 1.980370283126831
Validation loss: 2.0747973316459247

Epoch: 6| Step: 12
Training loss: 2.5942187309265137
Validation loss: 2.0798834088028118

Epoch: 6| Step: 13
Training loss: 1.7690911293029785
Validation loss: 2.1000611705164753

Epoch: 119| Step: 0
Training loss: 2.0265746116638184
Validation loss: 2.108777082094582

Epoch: 6| Step: 1
Training loss: 2.970979690551758
Validation loss: 2.1061551622165147

Epoch: 6| Step: 2
Training loss: 2.399085760116577
Validation loss: 2.124342146740165

Epoch: 6| Step: 3
Training loss: 1.9111149311065674
Validation loss: 2.1271300110765683

Epoch: 6| Step: 4
Training loss: 2.315857172012329
Validation loss: 2.1080669497930877

Epoch: 6| Step: 5
Training loss: 1.7390490770339966
Validation loss: 2.0958522699212514

Epoch: 6| Step: 6
Training loss: 2.4535088539123535
Validation loss: 2.088024257331766

Epoch: 6| Step: 7
Training loss: 2.8635342121124268
Validation loss: 2.076779216848394

Epoch: 6| Step: 8
Training loss: 2.3804221153259277
Validation loss: 2.077259035520656

Epoch: 6| Step: 9
Training loss: 2.101422071456909
Validation loss: 2.0758176388279086

Epoch: 6| Step: 10
Training loss: 2.319434404373169
Validation loss: 2.071269676249514

Epoch: 6| Step: 11
Training loss: 2.2498741149902344
Validation loss: 2.0821071760628813

Epoch: 6| Step: 12
Training loss: 2.108091354370117
Validation loss: 2.0801018668759252

Epoch: 6| Step: 13
Training loss: 2.346713066101074
Validation loss: 2.075362152950738

Epoch: 120| Step: 0
Training loss: 2.2589383125305176
Validation loss: 2.0795343537484445

Epoch: 6| Step: 1
Training loss: 2.2691521644592285
Validation loss: 2.0810405951674267

Epoch: 6| Step: 2
Training loss: 2.00158429145813
Validation loss: 2.0669396974707164

Epoch: 6| Step: 3
Training loss: 1.7735508680343628
Validation loss: 2.066429263801985

Epoch: 6| Step: 4
Training loss: 1.8237030506134033
Validation loss: 2.066762373011599

Epoch: 6| Step: 5
Training loss: 1.8802156448364258
Validation loss: 2.0737655547357376

Epoch: 6| Step: 6
Training loss: 2.487152099609375
Validation loss: 2.072814113350325

Epoch: 6| Step: 7
Training loss: 2.4205873012542725
Validation loss: 2.0700921781601442

Epoch: 6| Step: 8
Training loss: 2.6475231647491455
Validation loss: 2.0871461309412473

Epoch: 6| Step: 9
Training loss: 2.160750389099121
Validation loss: 2.098941126177388

Epoch: 6| Step: 10
Training loss: 2.445735454559326
Validation loss: 2.1047168367652485

Epoch: 6| Step: 11
Training loss: 2.5719120502471924
Validation loss: 2.1204993904277845

Epoch: 6| Step: 12
Training loss: 2.3147382736206055
Validation loss: 2.117587317702591

Epoch: 6| Step: 13
Training loss: 2.852449655532837
Validation loss: 2.12226245480199

Epoch: 121| Step: 0
Training loss: 1.3831274509429932
Validation loss: 2.145966601628129

Epoch: 6| Step: 1
Training loss: 2.2391576766967773
Validation loss: 2.157329587526219

Epoch: 6| Step: 2
Training loss: 2.7688703536987305
Validation loss: 2.1440924931597967

Epoch: 6| Step: 3
Training loss: 3.1151280403137207
Validation loss: 2.1514305555692284

Epoch: 6| Step: 4
Training loss: 1.9303810596466064
Validation loss: 2.137397543076546

Epoch: 6| Step: 5
Training loss: 2.314666748046875
Validation loss: 2.13860692644632

Epoch: 6| Step: 6
Training loss: 3.0210375785827637
Validation loss: 2.138466614548878

Epoch: 6| Step: 7
Training loss: 2.1896064281463623
Validation loss: 2.11638520866312

Epoch: 6| Step: 8
Training loss: 2.39420485496521
Validation loss: 2.109988994495843

Epoch: 6| Step: 9
Training loss: 2.2055654525756836
Validation loss: 2.093163353140636

Epoch: 6| Step: 10
Training loss: 2.2344970703125
Validation loss: 2.073445640584474

Epoch: 6| Step: 11
Training loss: 1.8050885200500488
Validation loss: 2.0700538953145347

Epoch: 6| Step: 12
Training loss: 2.1850900650024414
Validation loss: 2.0652239091934694

Epoch: 6| Step: 13
Training loss: 2.367865800857544
Validation loss: 2.063668954756952

Epoch: 122| Step: 0
Training loss: 2.099246025085449
Validation loss: 2.080067506400488

Epoch: 6| Step: 1
Training loss: 2.2915687561035156
Validation loss: 2.0730762443234845

Epoch: 6| Step: 2
Training loss: 2.289912700653076
Validation loss: 2.0665662045119912

Epoch: 6| Step: 3
Training loss: 2.563300132751465
Validation loss: 2.0531085024597826

Epoch: 6| Step: 4
Training loss: 1.8368630409240723
Validation loss: 2.0626439612398864

Epoch: 6| Step: 5
Training loss: 1.6607298851013184
Validation loss: 2.0517679491350727

Epoch: 6| Step: 6
Training loss: 1.7850316762924194
Validation loss: 2.0656513129511187

Epoch: 6| Step: 7
Training loss: 2.169940948486328
Validation loss: 2.0744229439766175

Epoch: 6| Step: 8
Training loss: 3.9556496143341064
Validation loss: 2.0776778856913247

Epoch: 6| Step: 9
Training loss: 2.26186466217041
Validation loss: 2.086858823735227

Epoch: 6| Step: 10
Training loss: 2.3658668994903564
Validation loss: 2.065097249964232

Epoch: 6| Step: 11
Training loss: 2.2222108840942383
Validation loss: 2.0729606613036125

Epoch: 6| Step: 12
Training loss: 2.358053207397461
Validation loss: 2.0815286585079726

Epoch: 6| Step: 13
Training loss: 1.651634931564331
Validation loss: 2.071544842053485

Epoch: 123| Step: 0
Training loss: 2.671083688735962
Validation loss: 2.1008080590155815

Epoch: 6| Step: 1
Training loss: 2.217968463897705
Validation loss: 2.0996625449067805

Epoch: 6| Step: 2
Training loss: 1.9148385524749756
Validation loss: 2.1223417379522838

Epoch: 6| Step: 3
Training loss: 1.6379141807556152
Validation loss: 2.1342861831829114

Epoch: 6| Step: 4
Training loss: 2.3246564865112305
Validation loss: 2.1287534134362334

Epoch: 6| Step: 5
Training loss: 2.063323974609375
Validation loss: 2.1249049684052825

Epoch: 6| Step: 6
Training loss: 2.4470489025115967
Validation loss: 2.1212562002161497

Epoch: 6| Step: 7
Training loss: 2.8466269969940186
Validation loss: 2.133067120787918

Epoch: 6| Step: 8
Training loss: 2.207343578338623
Validation loss: 2.114934149608817

Epoch: 6| Step: 9
Training loss: 1.9633488655090332
Validation loss: 2.130523021503161

Epoch: 6| Step: 10
Training loss: 2.092315673828125
Validation loss: 2.118275455249253

Epoch: 6| Step: 11
Training loss: 2.2972512245178223
Validation loss: 2.132647528443285

Epoch: 6| Step: 12
Training loss: 2.0641889572143555
Validation loss: 2.1033665339152017

Epoch: 6| Step: 13
Training loss: 2.7874386310577393
Validation loss: 2.105734484170073

Epoch: 124| Step: 0
Training loss: 2.269777536392212
Validation loss: 2.087049416316453

Epoch: 6| Step: 1
Training loss: 1.3763232231140137
Validation loss: 2.065084990634713

Epoch: 6| Step: 2
Training loss: 1.9014958143234253
Validation loss: 2.0713472814970117

Epoch: 6| Step: 3
Training loss: 2.8830790519714355
Validation loss: 2.058268062530025

Epoch: 6| Step: 4
Training loss: 2.9735589027404785
Validation loss: 2.0490629621731338

Epoch: 6| Step: 5
Training loss: 1.877524733543396
Validation loss: 2.04161024349992

Epoch: 6| Step: 6
Training loss: 2.121654510498047
Validation loss: 2.0419182008312595

Epoch: 6| Step: 7
Training loss: 1.9562911987304688
Validation loss: 2.048501750474335

Epoch: 6| Step: 8
Training loss: 2.445997714996338
Validation loss: 2.051140175070814

Epoch: 6| Step: 9
Training loss: 2.552786350250244
Validation loss: 2.048968707361529

Epoch: 6| Step: 10
Training loss: 1.6819121837615967
Validation loss: 2.06531983934423

Epoch: 6| Step: 11
Training loss: 2.6369032859802246
Validation loss: 2.087165686392015

Epoch: 6| Step: 12
Training loss: 2.2696990966796875
Validation loss: 2.0746895087662565

Epoch: 6| Step: 13
Training loss: 2.162449598312378
Validation loss: 2.0795671991122666

Epoch: 125| Step: 0
Training loss: 2.302400827407837
Validation loss: 2.1027453689165014

Epoch: 6| Step: 1
Training loss: 1.9249062538146973
Validation loss: 2.1038742065429688

Epoch: 6| Step: 2
Training loss: 1.5291528701782227
Validation loss: 2.092813117529756

Epoch: 6| Step: 3
Training loss: 2.739454746246338
Validation loss: 2.0912909277023806

Epoch: 6| Step: 4
Training loss: 2.3549563884735107
Validation loss: 2.0956163150008007

Epoch: 6| Step: 5
Training loss: 2.5062403678894043
Validation loss: 2.092807428811186

Epoch: 6| Step: 6
Training loss: 2.2811994552612305
Validation loss: 2.1062073246125252

Epoch: 6| Step: 7
Training loss: 1.8457962274551392
Validation loss: 2.0970936398352347

Epoch: 6| Step: 8
Training loss: 2.2182459831237793
Validation loss: 2.0989794359412244

Epoch: 6| Step: 9
Training loss: 2.166245460510254
Validation loss: 2.1067645883047454

Epoch: 6| Step: 10
Training loss: 1.9105695486068726
Validation loss: 2.1106359727921022

Epoch: 6| Step: 11
Training loss: 2.0040390491485596
Validation loss: 2.110101274264756

Epoch: 6| Step: 12
Training loss: 2.2632522583007812
Validation loss: 2.1069115861769645

Epoch: 6| Step: 13
Training loss: 2.8833093643188477
Validation loss: 2.0996103991744337

Epoch: 126| Step: 0
Training loss: 1.7116049528121948
Validation loss: 2.0820611933226227

Epoch: 6| Step: 1
Training loss: 2.1601340770721436
Validation loss: 2.0826109558023433

Epoch: 6| Step: 2
Training loss: 1.860697627067566
Validation loss: 2.078706472150741

Epoch: 6| Step: 3
Training loss: 2.0979061126708984
Validation loss: 2.067394710356189

Epoch: 6| Step: 4
Training loss: 2.981405258178711
Validation loss: 2.0620423055464223

Epoch: 6| Step: 5
Training loss: 1.8680781126022339
Validation loss: 2.0798113781918763

Epoch: 6| Step: 6
Training loss: 1.706466555595398
Validation loss: 2.0645882878252255

Epoch: 6| Step: 7
Training loss: 2.412388324737549
Validation loss: 2.080964039730769

Epoch: 6| Step: 8
Training loss: 1.8599369525909424
Validation loss: 2.068690615315591

Epoch: 6| Step: 9
Training loss: 1.7473108768463135
Validation loss: 2.060815170247068

Epoch: 6| Step: 10
Training loss: 2.4182941913604736
Validation loss: 2.085568893340326

Epoch: 6| Step: 11
Training loss: 2.709312677383423
Validation loss: 2.0845331940599667

Epoch: 6| Step: 12
Training loss: 2.614748001098633
Validation loss: 2.0953543711734075

Epoch: 6| Step: 13
Training loss: 2.8692593574523926
Validation loss: 2.1100543186228764

Epoch: 127| Step: 0
Training loss: 2.4082651138305664
Validation loss: 2.0751691813110025

Epoch: 6| Step: 1
Training loss: 2.259249210357666
Validation loss: 2.0699537531022103

Epoch: 6| Step: 2
Training loss: 2.220841884613037
Validation loss: 2.059732893461822

Epoch: 6| Step: 3
Training loss: 2.1584229469299316
Validation loss: 2.055299799929383

Epoch: 6| Step: 4
Training loss: 2.4001784324645996
Validation loss: 2.0489212031005533

Epoch: 6| Step: 5
Training loss: 2.0814497470855713
Validation loss: 2.0613288930667344

Epoch: 6| Step: 6
Training loss: 1.9932230710983276
Validation loss: 2.05628889606845

Epoch: 6| Step: 7
Training loss: 2.1796109676361084
Validation loss: 2.061922936029332

Epoch: 6| Step: 8
Training loss: 2.1005680561065674
Validation loss: 2.0574905692890124

Epoch: 6| Step: 9
Training loss: 1.901793360710144
Validation loss: 2.079488985000118

Epoch: 6| Step: 10
Training loss: 1.9473446607589722
Validation loss: 2.1071152687072754

Epoch: 6| Step: 11
Training loss: 2.5858020782470703
Validation loss: 2.1414671892760904

Epoch: 6| Step: 12
Training loss: 2.4719531536102295
Validation loss: 2.1586975923148533

Epoch: 6| Step: 13
Training loss: 1.7458322048187256
Validation loss: 2.158906488008397

Epoch: 128| Step: 0
Training loss: 2.3199148178100586
Validation loss: 2.159663477251607

Epoch: 6| Step: 1
Training loss: 1.8294155597686768
Validation loss: 2.1824897822513374

Epoch: 6| Step: 2
Training loss: 2.03794527053833
Validation loss: 2.2015368861536824

Epoch: 6| Step: 3
Training loss: 2.324871778488159
Validation loss: 2.206728866023402

Epoch: 6| Step: 4
Training loss: 2.137824296951294
Validation loss: 2.167738563270979

Epoch: 6| Step: 5
Training loss: 2.2962403297424316
Validation loss: 2.1555785235538276

Epoch: 6| Step: 6
Training loss: 2.3355884552001953
Validation loss: 2.170818737758103

Epoch: 6| Step: 7
Training loss: 2.365020751953125
Validation loss: 2.1664153555388093

Epoch: 6| Step: 8
Training loss: 2.191218852996826
Validation loss: 2.1362113875727498

Epoch: 6| Step: 9
Training loss: 2.1017839908599854
Validation loss: 2.137360453605652

Epoch: 6| Step: 10
Training loss: 2.6843225955963135
Validation loss: 2.1330419714732836

Epoch: 6| Step: 11
Training loss: 1.7712063789367676
Validation loss: 2.1256800082422074

Epoch: 6| Step: 12
Training loss: 2.4870219230651855
Validation loss: 2.132090348069386

Epoch: 6| Step: 13
Training loss: 1.9260398149490356
Validation loss: 2.0835952540879608

Epoch: 129| Step: 0
Training loss: 2.285287857055664
Validation loss: 2.0702298072076615

Epoch: 6| Step: 1
Training loss: 2.771465301513672
Validation loss: 2.0657162653502597

Epoch: 6| Step: 2
Training loss: 2.579134941101074
Validation loss: 2.0654503773617487

Epoch: 6| Step: 3
Training loss: 2.1072494983673096
Validation loss: 2.0649802838602374

Epoch: 6| Step: 4
Training loss: 2.469038486480713
Validation loss: 2.075843229088732

Epoch: 6| Step: 5
Training loss: 2.0130181312561035
Validation loss: 2.074660502454286

Epoch: 6| Step: 6
Training loss: 2.8838884830474854
Validation loss: 2.0694475558496292

Epoch: 6| Step: 7
Training loss: 1.6538609266281128
Validation loss: 2.0863996116063928

Epoch: 6| Step: 8
Training loss: 2.012054443359375
Validation loss: 2.081809207957278

Epoch: 6| Step: 9
Training loss: 1.5660598278045654
Validation loss: 2.08227635711752

Epoch: 6| Step: 10
Training loss: 1.7758982181549072
Validation loss: 2.0909522553925872

Epoch: 6| Step: 11
Training loss: 1.6089166402816772
Validation loss: 2.096500431337664

Epoch: 6| Step: 12
Training loss: 2.1042025089263916
Validation loss: 2.0870552203988515

Epoch: 6| Step: 13
Training loss: 2.891228199005127
Validation loss: 2.070489063057848

Epoch: 130| Step: 0
Training loss: 2.4172492027282715
Validation loss: 2.075489378744556

Epoch: 6| Step: 1
Training loss: 1.7766783237457275
Validation loss: 2.0663734969272407

Epoch: 6| Step: 2
Training loss: 1.7743791341781616
Validation loss: 2.0886138741688063

Epoch: 6| Step: 3
Training loss: 2.410609483718872
Validation loss: 2.0629016481420046

Epoch: 6| Step: 4
Training loss: 2.355353832244873
Validation loss: 2.0661577588768414

Epoch: 6| Step: 5
Training loss: 1.8633642196655273
Validation loss: 2.074826311039668

Epoch: 6| Step: 6
Training loss: 1.9623534679412842
Validation loss: 2.0827795049195648

Epoch: 6| Step: 7
Training loss: 2.289748430252075
Validation loss: 2.09986973321566

Epoch: 6| Step: 8
Training loss: 3.204857349395752
Validation loss: 2.1309579162187475

Epoch: 6| Step: 9
Training loss: 1.9497586488723755
Validation loss: 2.126411246997054

Epoch: 6| Step: 10
Training loss: 2.667405605316162
Validation loss: 2.0980844523317073

Epoch: 6| Step: 11
Training loss: 1.5619233846664429
Validation loss: 2.0785597601244525

Epoch: 6| Step: 12
Training loss: 2.630128860473633
Validation loss: 2.084332889126193

Epoch: 6| Step: 13
Training loss: 1.134035587310791
Validation loss: 2.0768801845530027

Epoch: 131| Step: 0
Training loss: 2.324253797531128
Validation loss: 2.076657461863692

Epoch: 6| Step: 1
Training loss: 2.4402594566345215
Validation loss: 2.0662001973839215

Epoch: 6| Step: 2
Training loss: 1.9642208814620972
Validation loss: 2.0555790034673547

Epoch: 6| Step: 3
Training loss: 2.8681764602661133
Validation loss: 2.058369598081035

Epoch: 6| Step: 4
Training loss: 1.8538920879364014
Validation loss: 2.0656097127545263

Epoch: 6| Step: 5
Training loss: 1.5807461738586426
Validation loss: 2.0610841064042944

Epoch: 6| Step: 6
Training loss: 2.6732003688812256
Validation loss: 2.064349587245654

Epoch: 6| Step: 7
Training loss: 2.345046281814575
Validation loss: 2.0809257363760345

Epoch: 6| Step: 8
Training loss: 2.31951904296875
Validation loss: 2.106159646023986

Epoch: 6| Step: 9
Training loss: 1.5889731645584106
Validation loss: 2.1025028382578204

Epoch: 6| Step: 10
Training loss: 2.029452323913574
Validation loss: 2.087759002562492

Epoch: 6| Step: 11
Training loss: 2.2400527000427246
Validation loss: 2.0787498617684967

Epoch: 6| Step: 12
Training loss: 1.8158031702041626
Validation loss: 2.089005207502714

Epoch: 6| Step: 13
Training loss: 1.9522204399108887
Validation loss: 2.0885977719419744

Epoch: 132| Step: 0
Training loss: 2.2658681869506836
Validation loss: 2.0952425720871135

Epoch: 6| Step: 1
Training loss: 2.0332069396972656
Validation loss: 2.096879268205294

Epoch: 6| Step: 2
Training loss: 2.272705078125
Validation loss: 2.0852649160610732

Epoch: 6| Step: 3
Training loss: 1.8117387294769287
Validation loss: 2.0829708832566456

Epoch: 6| Step: 4
Training loss: 1.0014123916625977
Validation loss: 2.0904457774213565

Epoch: 6| Step: 5
Training loss: 2.564629077911377
Validation loss: 2.123845882313226

Epoch: 6| Step: 6
Training loss: 1.780792474746704
Validation loss: 2.1515382848760134

Epoch: 6| Step: 7
Training loss: 1.7820225954055786
Validation loss: 2.173719818874072

Epoch: 6| Step: 8
Training loss: 2.3875436782836914
Validation loss: 2.187951659643522

Epoch: 6| Step: 9
Training loss: 2.31557297706604
Validation loss: 2.1993343202016686

Epoch: 6| Step: 10
Training loss: 2.5947623252868652
Validation loss: 2.16953585737495

Epoch: 6| Step: 11
Training loss: 2.6788833141326904
Validation loss: 2.167711921917495

Epoch: 6| Step: 12
Training loss: 2.8177733421325684
Validation loss: 2.14919158335655

Epoch: 6| Step: 13
Training loss: 2.4611265659332275
Validation loss: 2.1456648675344323

Epoch: 133| Step: 0
Training loss: 2.1046273708343506
Validation loss: 2.1372435169835247

Epoch: 6| Step: 1
Training loss: 1.9496511220932007
Validation loss: 2.1178474682633595

Epoch: 6| Step: 2
Training loss: 2.6136536598205566
Validation loss: 2.1116391920274302

Epoch: 6| Step: 3
Training loss: 1.6260052919387817
Validation loss: 2.084324288111861

Epoch: 6| Step: 4
Training loss: 2.908264636993408
Validation loss: 2.0621362245211037

Epoch: 6| Step: 5
Training loss: 2.601051092147827
Validation loss: 2.069942420528781

Epoch: 6| Step: 6
Training loss: 1.7597131729125977
Validation loss: 2.075757767564507

Epoch: 6| Step: 7
Training loss: 1.892500877380371
Validation loss: 2.0975200348002936

Epoch: 6| Step: 8
Training loss: 2.644763231277466
Validation loss: 2.1239584107552805

Epoch: 6| Step: 9
Training loss: 2.173581123352051
Validation loss: 2.0921903092374086

Epoch: 6| Step: 10
Training loss: 1.7594985961914062
Validation loss: 2.0770056068256335

Epoch: 6| Step: 11
Training loss: 2.7201809883117676
Validation loss: 2.0678591446209977

Epoch: 6| Step: 12
Training loss: 1.9580005407333374
Validation loss: 2.056514407998772

Epoch: 6| Step: 13
Training loss: 1.5324264764785767
Validation loss: 2.0541468435718166

Epoch: 134| Step: 0
Training loss: 2.1802666187286377
Validation loss: 2.0305324780043734

Epoch: 6| Step: 1
Training loss: 2.404599666595459
Validation loss: 2.0603274811980543

Epoch: 6| Step: 2
Training loss: 1.7055740356445312
Validation loss: 2.0689336240932508

Epoch: 6| Step: 3
Training loss: 2.2784605026245117
Validation loss: 2.0809737456742154

Epoch: 6| Step: 4
Training loss: 2.326352119445801
Validation loss: 2.081606231709962

Epoch: 6| Step: 5
Training loss: 2.180473804473877
Validation loss: 2.0450427557832453

Epoch: 6| Step: 6
Training loss: 1.9014077186584473
Validation loss: 2.02937957291962

Epoch: 6| Step: 7
Training loss: 1.6688671112060547
Validation loss: 2.0304672359138407

Epoch: 6| Step: 8
Training loss: 2.3224129676818848
Validation loss: 2.026907661909698

Epoch: 6| Step: 9
Training loss: 3.0190529823303223
Validation loss: 2.034578328491539

Epoch: 6| Step: 10
Training loss: 2.499420166015625
Validation loss: 2.0304281045031805

Epoch: 6| Step: 11
Training loss: 1.7006168365478516
Validation loss: 2.0319571110510055

Epoch: 6| Step: 12
Training loss: 2.035236358642578
Validation loss: 2.041448526484992

Epoch: 6| Step: 13
Training loss: 1.8206411600112915
Validation loss: 2.046646502710158

Epoch: 135| Step: 0
Training loss: 2.033700942993164
Validation loss: 2.0448275714792232

Epoch: 6| Step: 1
Training loss: 2.2446188926696777
Validation loss: 2.045326095755382

Epoch: 6| Step: 2
Training loss: 2.0453102588653564
Validation loss: 2.0548102214772213

Epoch: 6| Step: 3
Training loss: 2.1854963302612305
Validation loss: 2.0474221834572415

Epoch: 6| Step: 4
Training loss: 2.0607223510742188
Validation loss: 2.0367912643699237

Epoch: 6| Step: 5
Training loss: 2.0606138706207275
Validation loss: 2.0416249575153476

Epoch: 6| Step: 6
Training loss: 2.3822152614593506
Validation loss: 2.0270404174763668

Epoch: 6| Step: 7
Training loss: 1.8098270893096924
Validation loss: 2.0287071722809986

Epoch: 6| Step: 8
Training loss: 1.7340980768203735
Validation loss: 2.032571182456068

Epoch: 6| Step: 9
Training loss: 2.1635923385620117
Validation loss: 2.036462694086054

Epoch: 6| Step: 10
Training loss: 2.550694465637207
Validation loss: 2.0364294193124257

Epoch: 6| Step: 11
Training loss: 2.478505849838257
Validation loss: 2.032389483144206

Epoch: 6| Step: 12
Training loss: 1.583207368850708
Validation loss: 2.0408295354535504

Epoch: 6| Step: 13
Training loss: 1.9367234706878662
Validation loss: 2.0559223390394643

Epoch: 136| Step: 0
Training loss: 1.8411540985107422
Validation loss: 2.089752002428937

Epoch: 6| Step: 1
Training loss: 2.0935182571411133
Validation loss: 2.1185706738502748

Epoch: 6| Step: 2
Training loss: 2.821216583251953
Validation loss: 2.11249606327344

Epoch: 6| Step: 3
Training loss: 2.332679271697998
Validation loss: 2.091422547576248

Epoch: 6| Step: 4
Training loss: 1.711974859237671
Validation loss: 2.072470316322901

Epoch: 6| Step: 5
Training loss: 2.461945056915283
Validation loss: 2.0521910113673054

Epoch: 6| Step: 6
Training loss: 2.115553379058838
Validation loss: 2.0673746908864667

Epoch: 6| Step: 7
Training loss: 2.3628437519073486
Validation loss: 2.0728012720743814

Epoch: 6| Step: 8
Training loss: 2.119576930999756
Validation loss: 2.078294466900569

Epoch: 6| Step: 9
Training loss: 1.9455519914627075
Validation loss: 2.08468299142776

Epoch: 6| Step: 10
Training loss: 1.5424613952636719
Validation loss: 2.092241402595274

Epoch: 6| Step: 11
Training loss: 2.282240390777588
Validation loss: 2.0864539274605374

Epoch: 6| Step: 12
Training loss: 1.8327205181121826
Validation loss: 2.0934983581625004

Epoch: 6| Step: 13
Training loss: 2.564936876296997
Validation loss: 2.08926591309168

Epoch: 137| Step: 0
Training loss: 2.5677003860473633
Validation loss: 2.0968661282652166

Epoch: 6| Step: 1
Training loss: 2.393622398376465
Validation loss: 2.096584504650485

Epoch: 6| Step: 2
Training loss: 2.119859218597412
Validation loss: 2.0841550891117384

Epoch: 6| Step: 3
Training loss: 2.4206247329711914
Validation loss: 2.078198545722551

Epoch: 6| Step: 4
Training loss: 1.6249537467956543
Validation loss: 2.0759383222108245

Epoch: 6| Step: 5
Training loss: 2.209005355834961
Validation loss: 2.0616189254227506

Epoch: 6| Step: 6
Training loss: 1.9585539102554321
Validation loss: 2.051936106015277

Epoch: 6| Step: 7
Training loss: 2.0602762699127197
Validation loss: 2.0632548357850764

Epoch: 6| Step: 8
Training loss: 2.993307113647461
Validation loss: 2.0585275862806585

Epoch: 6| Step: 9
Training loss: 2.076089859008789
Validation loss: 2.0551106365778113

Epoch: 6| Step: 10
Training loss: 1.7472898960113525
Validation loss: 2.0411726813162527

Epoch: 6| Step: 11
Training loss: 1.745525598526001
Validation loss: 2.037846211464174

Epoch: 6| Step: 12
Training loss: 1.5288677215576172
Validation loss: 2.025635596244566

Epoch: 6| Step: 13
Training loss: 1.72019362449646
Validation loss: 2.028702320591096

Epoch: 138| Step: 0
Training loss: 2.6930320262908936
Validation loss: 2.02257413377044

Epoch: 6| Step: 1
Training loss: 2.1028215885162354
Validation loss: 2.0388117682549263

Epoch: 6| Step: 2
Training loss: 2.2660980224609375
Validation loss: 2.0501982935013308

Epoch: 6| Step: 3
Training loss: 2.3019373416900635
Validation loss: 2.0607796612606255

Epoch: 6| Step: 4
Training loss: 1.9492299556732178
Validation loss: 2.081177317967979

Epoch: 6| Step: 5
Training loss: 2.2269887924194336
Validation loss: 2.094897844458139

Epoch: 6| Step: 6
Training loss: 1.8692222833633423
Validation loss: 2.119807222838043

Epoch: 6| Step: 7
Training loss: 1.876347541809082
Validation loss: 2.1377749776327484

Epoch: 6| Step: 8
Training loss: 2.4184155464172363
Validation loss: 2.1493633229245424

Epoch: 6| Step: 9
Training loss: 1.519411325454712
Validation loss: 2.1258133457553003

Epoch: 6| Step: 10
Training loss: 1.1969726085662842
Validation loss: 2.090683893490863

Epoch: 6| Step: 11
Training loss: 2.0336523056030273
Validation loss: 2.070828035313596

Epoch: 6| Step: 12
Training loss: 2.708512306213379
Validation loss: 2.062073184597877

Epoch: 6| Step: 13
Training loss: 2.4854319095611572
Validation loss: 2.0867801507314048

Epoch: 139| Step: 0
Training loss: 2.7203187942504883
Validation loss: 2.1078112868852514

Epoch: 6| Step: 1
Training loss: 2.4267735481262207
Validation loss: 2.1290731173689648

Epoch: 6| Step: 2
Training loss: 2.262406826019287
Validation loss: 2.1151945872973372

Epoch: 6| Step: 3
Training loss: 2.27510142326355
Validation loss: 2.106493983217465

Epoch: 6| Step: 4
Training loss: 1.6057868003845215
Validation loss: 2.096950259259952

Epoch: 6| Step: 5
Training loss: 2.169494867324829
Validation loss: 2.096231646435235

Epoch: 6| Step: 6
Training loss: 1.4333994388580322
Validation loss: 2.1242105499390633

Epoch: 6| Step: 7
Training loss: 2.849743604660034
Validation loss: 2.14619840088711

Epoch: 6| Step: 8
Training loss: 2.48246431350708
Validation loss: 2.1718429186010875

Epoch: 6| Step: 9
Training loss: 2.3712387084960938
Validation loss: 2.1884391166830577

Epoch: 6| Step: 10
Training loss: 1.5429160594940186
Validation loss: 2.2033887909304712

Epoch: 6| Step: 11
Training loss: 1.7306649684906006
Validation loss: 2.182861699852892

Epoch: 6| Step: 12
Training loss: 1.8923962116241455
Validation loss: 2.1345459620157876

Epoch: 6| Step: 13
Training loss: 2.2211766242980957
Validation loss: 2.101171220502546

Epoch: 140| Step: 0
Training loss: 2.6071410179138184
Validation loss: 2.055967536023868

Epoch: 6| Step: 1
Training loss: 2.0101680755615234
Validation loss: 2.049136454059232

Epoch: 6| Step: 2
Training loss: 1.6020077466964722
Validation loss: 2.0375946606359174

Epoch: 6| Step: 3
Training loss: 1.8645340204238892
Validation loss: 2.040882843796925

Epoch: 6| Step: 4
Training loss: 2.031153917312622
Validation loss: 2.0313545093741467

Epoch: 6| Step: 5
Training loss: 3.079376459121704
Validation loss: 2.030947110986197

Epoch: 6| Step: 6
Training loss: 1.5876593589782715
Validation loss: 2.0370505984111498

Epoch: 6| Step: 7
Training loss: 1.8754349946975708
Validation loss: 2.0259926754941224

Epoch: 6| Step: 8
Training loss: 2.1524062156677246
Validation loss: 2.032478173573812

Epoch: 6| Step: 9
Training loss: 2.5241849422454834
Validation loss: 2.042482570935321

Epoch: 6| Step: 10
Training loss: 2.3102355003356934
Validation loss: 2.042961605133549

Epoch: 6| Step: 11
Training loss: 1.6821035146713257
Validation loss: 2.0640634734143495

Epoch: 6| Step: 12
Training loss: 1.8973352909088135
Validation loss: 2.075171468078449

Epoch: 6| Step: 13
Training loss: 1.9628418684005737
Validation loss: 2.0772953033447266

Epoch: 141| Step: 0
Training loss: 2.1132216453552246
Validation loss: 2.11234099377868

Epoch: 6| Step: 1
Training loss: 2.2271716594696045
Validation loss: 2.1633692095356603

Epoch: 6| Step: 2
Training loss: 2.704930067062378
Validation loss: 2.2030687229607695

Epoch: 6| Step: 3
Training loss: 2.308784246444702
Validation loss: 2.1996095385602725

Epoch: 6| Step: 4
Training loss: 1.8426687717437744
Validation loss: 2.1955038655188774

Epoch: 6| Step: 5
Training loss: 2.1835708618164062
Validation loss: 2.196772893269857

Epoch: 6| Step: 6
Training loss: 2.5405266284942627
Validation loss: 2.2049033475178543

Epoch: 6| Step: 7
Training loss: 2.5223031044006348
Validation loss: 2.1972845062132804

Epoch: 6| Step: 8
Training loss: 1.9166661500930786
Validation loss: 2.1777557865265877

Epoch: 6| Step: 9
Training loss: 1.6185550689697266
Validation loss: 2.165819239872758

Epoch: 6| Step: 10
Training loss: 1.6243062019348145
Validation loss: 2.145907776330107

Epoch: 6| Step: 11
Training loss: 1.9278804063796997
Validation loss: 2.1243829368263163

Epoch: 6| Step: 12
Training loss: 1.9257638454437256
Validation loss: 2.071115668101977

Epoch: 6| Step: 13
Training loss: 2.2050621509552
Validation loss: 2.0692083694601573

Epoch: 142| Step: 0
Training loss: 1.9795883893966675
Validation loss: 2.047223569244467

Epoch: 6| Step: 1
Training loss: 2.5382721424102783
Validation loss: 2.0349844066045617

Epoch: 6| Step: 2
Training loss: 2.1253890991210938
Validation loss: 2.0311706373768468

Epoch: 6| Step: 3
Training loss: 2.5756287574768066
Validation loss: 2.043493993820683

Epoch: 6| Step: 4
Training loss: 2.9699246883392334
Validation loss: 2.0390981205048098

Epoch: 6| Step: 5
Training loss: 2.0066497325897217
Validation loss: 2.0501390759662916

Epoch: 6| Step: 6
Training loss: 2.3888049125671387
Validation loss: 2.0352053424363494

Epoch: 6| Step: 7
Training loss: 1.4334059953689575
Validation loss: 2.0338195703362905

Epoch: 6| Step: 8
Training loss: 2.7875754833221436
Validation loss: 2.020722266166441

Epoch: 6| Step: 9
Training loss: 1.8428919315338135
Validation loss: 2.0175503966628865

Epoch: 6| Step: 10
Training loss: 1.7296717166900635
Validation loss: 2.0054913259321645

Epoch: 6| Step: 11
Training loss: 1.102707862854004
Validation loss: 2.006465260700513

Epoch: 6| Step: 12
Training loss: 2.165050983428955
Validation loss: 1.9912405924130512

Epoch: 6| Step: 13
Training loss: 2.2120139598846436
Validation loss: 2.0174396730238393

Epoch: 143| Step: 0
Training loss: 2.667635917663574
Validation loss: 2.022819131933233

Epoch: 6| Step: 1
Training loss: 2.0946695804595947
Validation loss: 2.041277482945432

Epoch: 6| Step: 2
Training loss: 2.113492488861084
Validation loss: 2.059413533056936

Epoch: 6| Step: 3
Training loss: 1.784069538116455
Validation loss: 2.0788315855046755

Epoch: 6| Step: 4
Training loss: 2.5422635078430176
Validation loss: 2.1010623901121077

Epoch: 6| Step: 5
Training loss: 1.377790093421936
Validation loss: 2.1102752121545936

Epoch: 6| Step: 6
Training loss: 2.396940231323242
Validation loss: 2.116223330138832

Epoch: 6| Step: 7
Training loss: 2.4728307723999023
Validation loss: 2.112395704433482

Epoch: 6| Step: 8
Training loss: 2.3216140270233154
Validation loss: 2.115282036924875

Epoch: 6| Step: 9
Training loss: 1.0329906940460205
Validation loss: 2.1152078823376725

Epoch: 6| Step: 10
Training loss: 2.123605251312256
Validation loss: 2.099336790782149

Epoch: 6| Step: 11
Training loss: 2.1201982498168945
Validation loss: 2.059445401673676

Epoch: 6| Step: 12
Training loss: 2.028074264526367
Validation loss: 2.046053001957555

Epoch: 6| Step: 13
Training loss: 1.8187108039855957
Validation loss: 2.042594232866841

Epoch: 144| Step: 0
Training loss: 2.247002601623535
Validation loss: 2.0300936109276226

Epoch: 6| Step: 1
Training loss: 2.036533832550049
Validation loss: 2.01573452513705

Epoch: 6| Step: 2
Training loss: 1.8054078817367554
Validation loss: 2.0000523546690583

Epoch: 6| Step: 3
Training loss: 1.5921947956085205
Validation loss: 1.9949075291233678

Epoch: 6| Step: 4
Training loss: 2.1830289363861084
Validation loss: 1.9880241322261032

Epoch: 6| Step: 5
Training loss: 1.8318307399749756
Validation loss: 1.9916779559145692

Epoch: 6| Step: 6
Training loss: 2.5291013717651367
Validation loss: 1.9840433213018602

Epoch: 6| Step: 7
Training loss: 1.6099977493286133
Validation loss: 1.979335718257453

Epoch: 6| Step: 8
Training loss: 2.0045242309570312
Validation loss: 1.9916126369148173

Epoch: 6| Step: 9
Training loss: 2.0908751487731934
Validation loss: 2.0055820570197156

Epoch: 6| Step: 10
Training loss: 1.6582773923873901
Validation loss: 1.999674891912809

Epoch: 6| Step: 11
Training loss: 1.9557197093963623
Validation loss: 2.0092460814342705

Epoch: 6| Step: 12
Training loss: 2.770049571990967
Validation loss: 2.0187203038123345

Epoch: 6| Step: 13
Training loss: 2.7429940700531006
Validation loss: 2.037636944042739

Epoch: 145| Step: 0
Training loss: 1.5897796154022217
Validation loss: 2.0572214767497075

Epoch: 6| Step: 1
Training loss: 1.5960261821746826
Validation loss: 2.084882228605209

Epoch: 6| Step: 2
Training loss: 2.3529317378997803
Validation loss: 2.1195716486182263

Epoch: 6| Step: 3
Training loss: 1.7444040775299072
Validation loss: 2.1100017486080045

Epoch: 6| Step: 4
Training loss: 2.9035465717315674
Validation loss: 2.12158981702661

Epoch: 6| Step: 5
Training loss: 1.6192152500152588
Validation loss: 2.1307536568692935

Epoch: 6| Step: 6
Training loss: 2.1347079277038574
Validation loss: 2.1196831785222536

Epoch: 6| Step: 7
Training loss: 1.8264586925506592
Validation loss: 2.114757586550969

Epoch: 6| Step: 8
Training loss: 1.8912935256958008
Validation loss: 2.1386045768696773

Epoch: 6| Step: 9
Training loss: 2.3277783393859863
Validation loss: 2.1237341216815415

Epoch: 6| Step: 10
Training loss: 2.3279199600219727
Validation loss: 2.1091722942167714

Epoch: 6| Step: 11
Training loss: 1.8809034824371338
Validation loss: 2.098031877189554

Epoch: 6| Step: 12
Training loss: 2.041898250579834
Validation loss: 2.0884581970912155

Epoch: 6| Step: 13
Training loss: 2.7003469467163086
Validation loss: 2.0803820048609087

Epoch: 146| Step: 0
Training loss: 1.5776304006576538
Validation loss: 2.0607658784876586

Epoch: 6| Step: 1
Training loss: 2.0426955223083496
Validation loss: 2.051557607548211

Epoch: 6| Step: 2
Training loss: 2.8005447387695312
Validation loss: 2.0475633118742254

Epoch: 6| Step: 3
Training loss: 1.8999484777450562
Validation loss: 2.0464788944490495

Epoch: 6| Step: 4
Training loss: 1.893707513809204
Validation loss: 2.0332614273153324

Epoch: 6| Step: 5
Training loss: 2.2539548873901367
Validation loss: 2.030696976569391

Epoch: 6| Step: 6
Training loss: 1.6453025341033936
Validation loss: 2.0186129693062074

Epoch: 6| Step: 7
Training loss: 1.793583631515503
Validation loss: 2.0351786639100764

Epoch: 6| Step: 8
Training loss: 1.520233392715454
Validation loss: 2.029981022240013

Epoch: 6| Step: 9
Training loss: 1.844225525856018
Validation loss: 2.0188281510465886

Epoch: 6| Step: 10
Training loss: 2.356703996658325
Validation loss: 2.0177006567678144

Epoch: 6| Step: 11
Training loss: 2.1097769737243652
Validation loss: 2.032231198844089

Epoch: 6| Step: 12
Training loss: 2.327361583709717
Validation loss: 2.0412765805439284

Epoch: 6| Step: 13
Training loss: 1.7163453102111816
Validation loss: 2.0432023848256757

Epoch: 147| Step: 0
Training loss: 1.4309073686599731
Validation loss: 2.0540259012611966

Epoch: 6| Step: 1
Training loss: 2.420961380004883
Validation loss: 2.069616893286346

Epoch: 6| Step: 2
Training loss: 2.012967824935913
Validation loss: 2.0956878457018124

Epoch: 6| Step: 3
Training loss: 2.3453540802001953
Validation loss: 2.113789886556646

Epoch: 6| Step: 4
Training loss: 1.6382849216461182
Validation loss: 2.1216197321491856

Epoch: 6| Step: 5
Training loss: 1.7840275764465332
Validation loss: 2.098310439817367

Epoch: 6| Step: 6
Training loss: 2.327691078186035
Validation loss: 2.083038071150421

Epoch: 6| Step: 7
Training loss: 2.041712760925293
Validation loss: 2.0487413034644177

Epoch: 6| Step: 8
Training loss: 2.53198504447937
Validation loss: 2.0471012848679737

Epoch: 6| Step: 9
Training loss: 2.3830490112304688
Validation loss: 2.0407543836101407

Epoch: 6| Step: 10
Training loss: 2.0162501335144043
Validation loss: 2.036196747133809

Epoch: 6| Step: 11
Training loss: 1.7125731706619263
Validation loss: 2.031599716473651

Epoch: 6| Step: 12
Training loss: 1.6871998310089111
Validation loss: 2.026350680217948

Epoch: 6| Step: 13
Training loss: 1.6964049339294434
Validation loss: 2.009832492438696

Epoch: 148| Step: 0
Training loss: 0.9752843379974365
Validation loss: 2.0160376538512526

Epoch: 6| Step: 1
Training loss: 1.8739279508590698
Validation loss: 2.004695859006656

Epoch: 6| Step: 2
Training loss: 2.5297200679779053
Validation loss: 2.0289222143029653

Epoch: 6| Step: 3
Training loss: 2.059688091278076
Validation loss: 2.03065893214236

Epoch: 6| Step: 4
Training loss: 1.147582769393921
Validation loss: 2.0510615943580546

Epoch: 6| Step: 5
Training loss: 2.418513298034668
Validation loss: 2.05948555597695

Epoch: 6| Step: 6
Training loss: 2.392697811126709
Validation loss: 2.057845748880858

Epoch: 6| Step: 7
Training loss: 2.005229949951172
Validation loss: 2.051043730910106

Epoch: 6| Step: 8
Training loss: 1.4330625534057617
Validation loss: 2.070986273468182

Epoch: 6| Step: 9
Training loss: 2.5613417625427246
Validation loss: 2.097294133196595

Epoch: 6| Step: 10
Training loss: 1.531336784362793
Validation loss: 2.1109256975112425

Epoch: 6| Step: 11
Training loss: 2.2090935707092285
Validation loss: 2.1091304184288107

Epoch: 6| Step: 12
Training loss: 2.304671287536621
Validation loss: 2.096862062331169

Epoch: 6| Step: 13
Training loss: 2.735379934310913
Validation loss: 2.0916481787158596

Epoch: 149| Step: 0
Training loss: 1.8830420970916748
Validation loss: 2.0747136531337613

Epoch: 6| Step: 1
Training loss: 1.656916618347168
Validation loss: 2.0707203816342097

Epoch: 6| Step: 2
Training loss: 1.7307806015014648
Validation loss: 2.0318670401009182

Epoch: 6| Step: 3
Training loss: 2.184772253036499
Validation loss: 2.0225820836200508

Epoch: 6| Step: 4
Training loss: 1.62235689163208
Validation loss: 2.03311377058747

Epoch: 6| Step: 5
Training loss: 1.9966576099395752
Validation loss: 2.0215052250892884

Epoch: 6| Step: 6
Training loss: 2.579434394836426
Validation loss: 2.02137424612558

Epoch: 6| Step: 7
Training loss: 2.078472852706909
Validation loss: 2.03597600998417

Epoch: 6| Step: 8
Training loss: 2.5766866207122803
Validation loss: 2.0182772810741136

Epoch: 6| Step: 9
Training loss: 1.1561126708984375
Validation loss: 2.024978978659517

Epoch: 6| Step: 10
Training loss: 2.656315326690674
Validation loss: 2.0311957969460437

Epoch: 6| Step: 11
Training loss: 1.4596410989761353
Validation loss: 2.01405833613488

Epoch: 6| Step: 12
Training loss: 1.9639194011688232
Validation loss: 2.0015087332776798

Epoch: 6| Step: 13
Training loss: 1.9252382516860962
Validation loss: 2.0188278793006815

Epoch: 150| Step: 0
Training loss: 1.7957639694213867
Validation loss: 2.024036338252406

Epoch: 6| Step: 1
Training loss: 2.2790091037750244
Validation loss: 2.021880717687709

Epoch: 6| Step: 2
Training loss: 1.5411802530288696
Validation loss: 2.0394214763436267

Epoch: 6| Step: 3
Training loss: 2.1447601318359375
Validation loss: 2.0343714516649962

Epoch: 6| Step: 4
Training loss: 2.16843318939209
Validation loss: 2.028345707924135

Epoch: 6| Step: 5
Training loss: 2.1448864936828613
Validation loss: 2.0289565158146683

Epoch: 6| Step: 6
Training loss: 1.616382360458374
Validation loss: 2.0175367580947055

Epoch: 6| Step: 7
Training loss: 1.860006332397461
Validation loss: 2.029838269756686

Epoch: 6| Step: 8
Training loss: 2.0078468322753906
Validation loss: 2.0441410900444112

Epoch: 6| Step: 9
Training loss: 2.1177477836608887
Validation loss: 2.052937110265096

Epoch: 6| Step: 10
Training loss: 1.8104610443115234
Validation loss: 2.0388511662842124

Epoch: 6| Step: 11
Training loss: 2.375575542449951
Validation loss: 2.053525663191272

Epoch: 6| Step: 12
Training loss: 2.030651092529297
Validation loss: 2.061983432821048

Epoch: 6| Step: 13
Training loss: 1.0608320236206055
Validation loss: 2.065594260410596

Epoch: 151| Step: 0
Training loss: 1.9479167461395264
Validation loss: 2.0577797376981346

Epoch: 6| Step: 1
Training loss: 1.9801652431488037
Validation loss: 2.04650128528636

Epoch: 6| Step: 2
Training loss: 1.9850642681121826
Validation loss: 2.040891162810787

Epoch: 6| Step: 3
Training loss: 2.2119698524475098
Validation loss: 2.0559605629213396

Epoch: 6| Step: 4
Training loss: 1.6007893085479736
Validation loss: 2.037277490861954

Epoch: 6| Step: 5
Training loss: 1.8714444637298584
Validation loss: 2.030950757765001

Epoch: 6| Step: 6
Training loss: 1.8899352550506592
Validation loss: 2.035613109988551

Epoch: 6| Step: 7
Training loss: 1.790571928024292
Validation loss: 2.0343602934191303

Epoch: 6| Step: 8
Training loss: 2.4129140377044678
Validation loss: 2.020483200268079

Epoch: 6| Step: 9
Training loss: 2.2395710945129395
Validation loss: 2.0230496685992003

Epoch: 6| Step: 10
Training loss: 1.9620862007141113
Validation loss: 2.048774652583625

Epoch: 6| Step: 11
Training loss: 2.0985755920410156
Validation loss: 2.0318969680416967

Epoch: 6| Step: 12
Training loss: 1.4412453174591064
Validation loss: 2.0368927678754254

Epoch: 6| Step: 13
Training loss: 1.334020733833313
Validation loss: 2.0379589885793705

Epoch: 152| Step: 0
Training loss: 1.7579772472381592
Validation loss: 2.0442598122422413

Epoch: 6| Step: 1
Training loss: 2.1921608448028564
Validation loss: 2.04610038060014

Epoch: 6| Step: 2
Training loss: 2.9689230918884277
Validation loss: 2.064900331599738

Epoch: 6| Step: 3
Training loss: 2.066323757171631
Validation loss: 2.0642033507747035

Epoch: 6| Step: 4
Training loss: 1.2130963802337646
Validation loss: 2.0439270798878004

Epoch: 6| Step: 5
Training loss: 2.3420095443725586
Validation loss: 2.0604532675076555

Epoch: 6| Step: 6
Training loss: 1.3085317611694336
Validation loss: 2.0398438925384195

Epoch: 6| Step: 7
Training loss: 2.0987119674682617
Validation loss: 2.0681466466637066

Epoch: 6| Step: 8
Training loss: 2.3486006259918213
Validation loss: 2.07021092343074

Epoch: 6| Step: 9
Training loss: 2.72904634475708
Validation loss: 2.0608931292769728

Epoch: 6| Step: 10
Training loss: 1.2561314105987549
Validation loss: 2.078430160399406

Epoch: 6| Step: 11
Training loss: 1.189344882965088
Validation loss: 2.065831086968863

Epoch: 6| Step: 12
Training loss: 1.9814165830612183
Validation loss: 2.0331892941587713

Epoch: 6| Step: 13
Training loss: 0.9769169688224792
Validation loss: 2.0315321953065935

Epoch: 153| Step: 0
Training loss: 1.8111872673034668
Validation loss: 2.032513057031939

Epoch: 6| Step: 1
Training loss: 1.7411445379257202
Validation loss: 2.0433515220560055

Epoch: 6| Step: 2
Training loss: 2.0164084434509277
Validation loss: 2.0391612540009203

Epoch: 6| Step: 3
Training loss: 2.102985382080078
Validation loss: 2.056109277150964

Epoch: 6| Step: 4
Training loss: 2.355508804321289
Validation loss: 2.0559847072888444

Epoch: 6| Step: 5
Training loss: 1.9026490449905396
Validation loss: 2.0657131671905518

Epoch: 6| Step: 6
Training loss: 1.7406530380249023
Validation loss: 2.0573764706170685

Epoch: 6| Step: 7
Training loss: 1.5070618391036987
Validation loss: 2.0756829297670754

Epoch: 6| Step: 8
Training loss: 1.7527192831039429
Validation loss: 2.087099608554635

Epoch: 6| Step: 9
Training loss: 1.5918982028961182
Validation loss: 2.0837918840428835

Epoch: 6| Step: 10
Training loss: 2.5353622436523438
Validation loss: 2.0790898287168114

Epoch: 6| Step: 11
Training loss: 1.5780818462371826
Validation loss: 2.080189968950005

Epoch: 6| Step: 12
Training loss: 1.8322563171386719
Validation loss: 2.078100158322242

Epoch: 6| Step: 13
Training loss: 2.2870242595672607
Validation loss: 2.0756550399206017

Epoch: 154| Step: 0
Training loss: 2.353130340576172
Validation loss: 2.0646376250892557

Epoch: 6| Step: 1
Training loss: 1.4026188850402832
Validation loss: 2.0749535099152596

Epoch: 6| Step: 2
Training loss: 1.6944584846496582
Validation loss: 2.0610918896172636

Epoch: 6| Step: 3
Training loss: 2.035648822784424
Validation loss: 2.0771289640857327

Epoch: 6| Step: 4
Training loss: 2.2608914375305176
Validation loss: 2.0814560408233316

Epoch: 6| Step: 5
Training loss: 1.627225637435913
Validation loss: 2.0902570960342244

Epoch: 6| Step: 6
Training loss: 1.5278022289276123
Validation loss: 2.0755134192846154

Epoch: 6| Step: 7
Training loss: 1.7433668375015259
Validation loss: 2.0563795489649617

Epoch: 6| Step: 8
Training loss: 2.1505279541015625
Validation loss: 2.024405158976073

Epoch: 6| Step: 9
Training loss: 2.5315017700195312
Validation loss: 2.0328166254105104

Epoch: 6| Step: 10
Training loss: 2.172987222671509
Validation loss: 2.039229909578959

Epoch: 6| Step: 11
Training loss: 1.7599161863327026
Validation loss: 2.038774639047602

Epoch: 6| Step: 12
Training loss: 1.3669180870056152
Validation loss: 2.036422912792493

Epoch: 6| Step: 13
Training loss: 1.688592553138733
Validation loss: 2.0183400313059487

Epoch: 155| Step: 0
Training loss: 1.6811643838882446
Validation loss: 2.0262651392208633

Epoch: 6| Step: 1
Training loss: 1.8614658117294312
Validation loss: 2.0401427438182216

Epoch: 6| Step: 2
Training loss: 1.8422307968139648
Validation loss: 2.0316749003625687

Epoch: 6| Step: 3
Training loss: 1.806166648864746
Validation loss: 2.0430525759214997

Epoch: 6| Step: 4
Training loss: 1.7411937713623047
Validation loss: 2.0528386664646927

Epoch: 6| Step: 5
Training loss: 2.1882002353668213
Validation loss: 2.0440546735640495

Epoch: 6| Step: 6
Training loss: 2.4330477714538574
Validation loss: 2.07287206316507

Epoch: 6| Step: 7
Training loss: 1.510249137878418
Validation loss: 2.0689967498984387

Epoch: 6| Step: 8
Training loss: 1.7421427965164185
Validation loss: 2.0670514696387836

Epoch: 6| Step: 9
Training loss: 1.6609950065612793
Validation loss: 2.068180960993613

Epoch: 6| Step: 10
Training loss: 2.223952293395996
Validation loss: 2.0695231550483295

Epoch: 6| Step: 11
Training loss: 1.5678551197052002
Validation loss: 2.060025417676536

Epoch: 6| Step: 12
Training loss: 1.9469044208526611
Validation loss: 2.063801691096316

Epoch: 6| Step: 13
Training loss: 2.0998740196228027
Validation loss: 2.0493344824801207

Epoch: 156| Step: 0
Training loss: 2.0894060134887695
Validation loss: 2.061618253748904

Epoch: 6| Step: 1
Training loss: 1.0033838748931885
Validation loss: 2.081710523174655

Epoch: 6| Step: 2
Training loss: 2.1470491886138916
Validation loss: 2.0847354653061076

Epoch: 6| Step: 3
Training loss: 2.2754786014556885
Validation loss: 2.0788643962593487

Epoch: 6| Step: 4
Training loss: 1.3966612815856934
Validation loss: 2.0898645680437804

Epoch: 6| Step: 5
Training loss: 2.4956393241882324
Validation loss: 2.07404556838415

Epoch: 6| Step: 6
Training loss: 1.2890903949737549
Validation loss: 2.0549524291869132

Epoch: 6| Step: 7
Training loss: 2.665142059326172
Validation loss: 2.045287270699778

Epoch: 6| Step: 8
Training loss: 1.6096515655517578
Validation loss: 2.0318436545710408

Epoch: 6| Step: 9
Training loss: 2.1172447204589844
Validation loss: 2.0246415932973227

Epoch: 6| Step: 10
Training loss: 1.7494624853134155
Validation loss: 2.034945018829838

Epoch: 6| Step: 11
Training loss: 2.096709728240967
Validation loss: 2.016044987145291

Epoch: 6| Step: 12
Training loss: 1.2843077182769775
Validation loss: 2.0157652208881993

Epoch: 6| Step: 13
Training loss: 1.4872030019760132
Validation loss: 2.015712594473234

Epoch: 157| Step: 0
Training loss: 2.201474666595459
Validation loss: 2.0273457406669535

Epoch: 6| Step: 1
Training loss: 1.3503590822219849
Validation loss: 2.014061530431112

Epoch: 6| Step: 2
Training loss: 1.8531553745269775
Validation loss: 2.0231644081813034

Epoch: 6| Step: 3
Training loss: 1.5233893394470215
Validation loss: 2.0263200562487365

Epoch: 6| Step: 4
Training loss: 1.9931237697601318
Validation loss: 2.0500196718400523

Epoch: 6| Step: 5
Training loss: 2.233621835708618
Validation loss: 2.0793111093582644

Epoch: 6| Step: 6
Training loss: 1.5056805610656738
Validation loss: 2.0619357811507357

Epoch: 6| Step: 7
Training loss: 1.8250263929367065
Validation loss: 2.0532053106574604

Epoch: 6| Step: 8
Training loss: 1.7398838996887207
Validation loss: 2.044091741243998

Epoch: 6| Step: 9
Training loss: 2.068753242492676
Validation loss: 2.035983520169412

Epoch: 6| Step: 10
Training loss: 1.8729493618011475
Validation loss: 2.0313055540925715

Epoch: 6| Step: 11
Training loss: 2.199207305908203
Validation loss: 2.0055605160292758

Epoch: 6| Step: 12
Training loss: 1.2375342845916748
Validation loss: 1.995886710382277

Epoch: 6| Step: 13
Training loss: 2.4119458198547363
Validation loss: 1.9903435245636971

Epoch: 158| Step: 0
Training loss: 1.838090419769287
Validation loss: 1.9985128064309396

Epoch: 6| Step: 1
Training loss: 1.667163372039795
Validation loss: 2.0042279074268956

Epoch: 6| Step: 2
Training loss: 2.321671962738037
Validation loss: 2.0085992018381753

Epoch: 6| Step: 3
Training loss: 1.181403398513794
Validation loss: 2.019031447748984

Epoch: 6| Step: 4
Training loss: 1.8416622877120972
Validation loss: 2.0002953993376864

Epoch: 6| Step: 5
Training loss: 1.8172800540924072
Validation loss: 2.0323562109342186

Epoch: 6| Step: 6
Training loss: 1.576425552368164
Validation loss: 2.046077298861678

Epoch: 6| Step: 7
Training loss: 1.5851612091064453
Validation loss: 2.060617378962937

Epoch: 6| Step: 8
Training loss: 1.991002082824707
Validation loss: 2.0639957817651893

Epoch: 6| Step: 9
Training loss: 1.8679324388504028
Validation loss: 2.0606435242519585

Epoch: 6| Step: 10
Training loss: 1.722834587097168
Validation loss: 2.0512313868409846

Epoch: 6| Step: 11
Training loss: 1.8066941499710083
Validation loss: 2.060734825749551

Epoch: 6| Step: 12
Training loss: 2.014183759689331
Validation loss: 2.0735667777317826

Epoch: 6| Step: 13
Training loss: 2.5001800060272217
Validation loss: 2.0588280180449128

Epoch: 159| Step: 0
Training loss: 1.4836575984954834
Validation loss: 2.0432569775530087

Epoch: 6| Step: 1
Training loss: 2.13173246383667
Validation loss: 2.023202326989943

Epoch: 6| Step: 2
Training loss: 1.3065612316131592
Validation loss: 2.0187400489725094

Epoch: 6| Step: 3
Training loss: 2.950982093811035
Validation loss: 2.0250672524975193

Epoch: 6| Step: 4
Training loss: 1.689541220664978
Validation loss: 2.027641970624206

Epoch: 6| Step: 5
Training loss: 1.0260066986083984
Validation loss: 2.038985243407629

Epoch: 6| Step: 6
Training loss: 1.941673755645752
Validation loss: 2.0134181925045547

Epoch: 6| Step: 7
Training loss: 1.7430107593536377
Validation loss: 2.0350174621869157

Epoch: 6| Step: 8
Training loss: 1.9589086771011353
Validation loss: 2.062305784994556

Epoch: 6| Step: 9
Training loss: 1.8134230375289917
Validation loss: 2.0921682503915604

Epoch: 6| Step: 10
Training loss: 2.171379566192627
Validation loss: 2.126178031326622

Epoch: 6| Step: 11
Training loss: 1.5269464254379272
Validation loss: 2.1938545037341375

Epoch: 6| Step: 12
Training loss: 1.8315261602401733
Validation loss: 2.2056199004573207

Epoch: 6| Step: 13
Training loss: 2.381561517715454
Validation loss: 2.2212699254353843

Epoch: 160| Step: 0
Training loss: 1.499375581741333
Validation loss: 2.2287903703669065

Epoch: 6| Step: 1
Training loss: 2.2553348541259766
Validation loss: 2.196748564320226

Epoch: 6| Step: 2
Training loss: 2.0031399726867676
Validation loss: 2.1325599429427937

Epoch: 6| Step: 3
Training loss: 2.0798137187957764
Validation loss: 2.0694251765487013

Epoch: 6| Step: 4
Training loss: 1.5303807258605957
Validation loss: 2.049733666963475

Epoch: 6| Step: 5
Training loss: 1.6395370960235596
Validation loss: 2.035434580618335

Epoch: 6| Step: 6
Training loss: 2.0906617641448975
Validation loss: 2.001874477632584

Epoch: 6| Step: 7
Training loss: 1.3612087965011597
Validation loss: 2.021939581440341

Epoch: 6| Step: 8
Training loss: 2.1375513076782227
Validation loss: 2.003436993527156

Epoch: 6| Step: 9
Training loss: 1.3329846858978271
Validation loss: 1.9890251441668438

Epoch: 6| Step: 10
Training loss: 1.8899297714233398
Validation loss: 1.9820328322790002

Epoch: 6| Step: 11
Training loss: 2.4773688316345215
Validation loss: 2.0238898748992593

Epoch: 6| Step: 12
Training loss: 2.0955002307891846
Validation loss: 2.0933550198872886

Epoch: 6| Step: 13
Training loss: 1.741463303565979
Validation loss: 2.1362178197471042

Epoch: 161| Step: 0
Training loss: 2.148952007293701
Validation loss: 2.110932837250412

Epoch: 6| Step: 1
Training loss: 2.6189358234405518
Validation loss: 2.049091366029555

Epoch: 6| Step: 2
Training loss: 1.5748093128204346
Validation loss: 1.9955091937895744

Epoch: 6| Step: 3
Training loss: 1.7008755207061768
Validation loss: 1.9667050428287958

Epoch: 6| Step: 4
Training loss: 1.6602115631103516
Validation loss: 1.960662446996217

Epoch: 6| Step: 5
Training loss: 1.3381288051605225
Validation loss: 2.00738283382949

Epoch: 6| Step: 6
Training loss: 1.7377126216888428
Validation loss: 2.016206649041945

Epoch: 6| Step: 7
Training loss: 1.7034497261047363
Validation loss: 2.0136201714956634

Epoch: 6| Step: 8
Training loss: 2.384072780609131
Validation loss: 2.0146113108563166

Epoch: 6| Step: 9
Training loss: 1.6470164060592651
Validation loss: 2.0068531292741016

Epoch: 6| Step: 10
Training loss: 1.739323616027832
Validation loss: 2.0086972867288897

Epoch: 6| Step: 11
Training loss: 1.6461000442504883
Validation loss: 2.0453808743466615

Epoch: 6| Step: 12
Training loss: 2.6239047050476074
Validation loss: 2.1098882664916334

Epoch: 6| Step: 13
Training loss: 1.277503490447998
Validation loss: 2.183549501562631

Epoch: 162| Step: 0
Training loss: 1.5293077230453491
Validation loss: 2.198102378076123

Epoch: 6| Step: 1
Training loss: 1.4870102405548096
Validation loss: 2.1987507112564577

Epoch: 6| Step: 2
Training loss: 2.788266897201538
Validation loss: 2.1315613305696877

Epoch: 6| Step: 3
Training loss: 2.0452075004577637
Validation loss: 2.086791087222356

Epoch: 6| Step: 4
Training loss: 1.753807783126831
Validation loss: 2.043706196610646

Epoch: 6| Step: 5
Training loss: 2.0201199054718018
Validation loss: 2.039108330203641

Epoch: 6| Step: 6
Training loss: 1.3214168548583984
Validation loss: 2.031653058144354

Epoch: 6| Step: 7
Training loss: 2.407337188720703
Validation loss: 2.025876839955648

Epoch: 6| Step: 8
Training loss: 2.1110315322875977
Validation loss: 2.0305386897056334

Epoch: 6| Step: 9
Training loss: 1.5203452110290527
Validation loss: 2.019806259421892

Epoch: 6| Step: 10
Training loss: 1.7746317386627197
Validation loss: 2.0094258195610455

Epoch: 6| Step: 11
Training loss: 1.7544896602630615
Validation loss: 1.9925035738175916

Epoch: 6| Step: 12
Training loss: 1.7640001773834229
Validation loss: 2.002221143373879

Epoch: 6| Step: 13
Training loss: 1.375293493270874
Validation loss: 2.0210368325633388

Epoch: 163| Step: 0
Training loss: 1.7047231197357178
Validation loss: 2.0428736363687823

Epoch: 6| Step: 1
Training loss: 1.9706361293792725
Validation loss: 2.0203834246563654

Epoch: 6| Step: 2
Training loss: 1.8486695289611816
Validation loss: 2.053686676486846

Epoch: 6| Step: 3
Training loss: 1.6078135967254639
Validation loss: 2.068261041436144

Epoch: 6| Step: 4
Training loss: 1.941145658493042
Validation loss: 2.0875967061647804

Epoch: 6| Step: 5
Training loss: 2.4125070571899414
Validation loss: 2.07677992825867

Epoch: 6| Step: 6
Training loss: 1.8542742729187012
Validation loss: 2.057114621644379

Epoch: 6| Step: 7
Training loss: 1.3089485168457031
Validation loss: 2.022194027900696

Epoch: 6| Step: 8
Training loss: 1.2539228200912476
Validation loss: 2.010187243902555

Epoch: 6| Step: 9
Training loss: 2.080415964126587
Validation loss: 2.0245783277737197

Epoch: 6| Step: 10
Training loss: 1.610756278038025
Validation loss: 2.0083975163839196

Epoch: 6| Step: 11
Training loss: 1.7949726581573486
Validation loss: 1.9966484500515846

Epoch: 6| Step: 12
Training loss: 1.5318143367767334
Validation loss: 2.0029741525650024

Epoch: 6| Step: 13
Training loss: 2.275773048400879
Validation loss: 2.0227091261135635

Epoch: 164| Step: 0
Training loss: 1.49003005027771
Validation loss: 2.029369188893226

Epoch: 6| Step: 1
Training loss: 2.0091967582702637
Validation loss: 2.052020929192984

Epoch: 6| Step: 2
Training loss: 2.060894727706909
Validation loss: 2.101977990519616

Epoch: 6| Step: 3
Training loss: 1.6874966621398926
Validation loss: 2.104135774797009

Epoch: 6| Step: 4
Training loss: 1.2358161211013794
Validation loss: 2.105251386601438

Epoch: 6| Step: 5
Training loss: 1.8196187019348145
Validation loss: 2.096574365451772

Epoch: 6| Step: 6
Training loss: 2.032222270965576
Validation loss: 2.092339587467973

Epoch: 6| Step: 7
Training loss: 1.7256791591644287
Validation loss: 2.0802432452478716

Epoch: 6| Step: 8
Training loss: 2.200545072555542
Validation loss: 2.0762268574007097

Epoch: 6| Step: 9
Training loss: 1.5904096364974976
Validation loss: 2.057942900606381

Epoch: 6| Step: 10
Training loss: 1.3776458501815796
Validation loss: 2.0063762395612654

Epoch: 6| Step: 11
Training loss: 1.2982876300811768
Validation loss: 2.0093834656541065

Epoch: 6| Step: 12
Training loss: 2.3595163822174072
Validation loss: 2.0083289043877715

Epoch: 6| Step: 13
Training loss: 1.8514881134033203
Validation loss: 2.0172034309756373

Epoch: 165| Step: 0
Training loss: 1.5738903284072876
Validation loss: 2.038308976798929

Epoch: 6| Step: 1
Training loss: 1.9448347091674805
Validation loss: 2.052155171671221

Epoch: 6| Step: 2
Training loss: 1.4211840629577637
Validation loss: 2.088705714030932

Epoch: 6| Step: 3
Training loss: 1.8552746772766113
Validation loss: 2.082710252013258

Epoch: 6| Step: 4
Training loss: 2.0989022254943848
Validation loss: 2.033213646181168

Epoch: 6| Step: 5
Training loss: 2.1909215450286865
Validation loss: 2.0231397228856243

Epoch: 6| Step: 6
Training loss: 1.6770844459533691
Validation loss: 2.00261595941359

Epoch: 6| Step: 7
Training loss: 1.3949215412139893
Validation loss: 1.9976342185851066

Epoch: 6| Step: 8
Training loss: 0.6797919869422913
Validation loss: 1.9817609876714728

Epoch: 6| Step: 9
Training loss: 1.6426962614059448
Validation loss: 2.00204788484881

Epoch: 6| Step: 10
Training loss: 1.9960157871246338
Validation loss: 2.0150485295121388

Epoch: 6| Step: 11
Training loss: 1.7084406614303589
Validation loss: 2.0183870882116337

Epoch: 6| Step: 12
Training loss: 2.286426067352295
Validation loss: 2.0394263088062243

Epoch: 6| Step: 13
Training loss: 2.003109931945801
Validation loss: 2.0507228041207917

Epoch: 166| Step: 0
Training loss: 2.1194067001342773
Validation loss: 2.0905505957142

Epoch: 6| Step: 1
Training loss: 1.5036649703979492
Validation loss: 2.091467370269119

Epoch: 6| Step: 2
Training loss: 1.7318841218948364
Validation loss: 2.117749990955476

Epoch: 6| Step: 3
Training loss: 1.3926365375518799
Validation loss: 2.1282541213497037

Epoch: 6| Step: 4
Training loss: 1.9537383317947388
Validation loss: 2.1107377416344097

Epoch: 6| Step: 5
Training loss: 1.3703453540802002
Validation loss: 2.069749996226321

Epoch: 6| Step: 6
Training loss: 1.6136515140533447
Validation loss: 2.057051594539355

Epoch: 6| Step: 7
Training loss: 1.846008062362671
Validation loss: 2.0514106442851405

Epoch: 6| Step: 8
Training loss: 1.8189013004302979
Validation loss: 2.0155433531730407

Epoch: 6| Step: 9
Training loss: 1.7595124244689941
Validation loss: 2.0111221241694626

Epoch: 6| Step: 10
Training loss: 1.6419748067855835
Validation loss: 1.9905784335187686

Epoch: 6| Step: 11
Training loss: 1.3655802011489868
Validation loss: 2.0080177937784502

Epoch: 6| Step: 12
Training loss: 1.8532055616378784
Validation loss: 2.0154038988133913

Epoch: 6| Step: 13
Training loss: 2.5063416957855225
Validation loss: 1.996207574362396

Epoch: 167| Step: 0
Training loss: 2.2934956550598145
Validation loss: 1.9902115073255313

Epoch: 6| Step: 1
Training loss: 1.2320479154586792
Validation loss: 1.9772883281912854

Epoch: 6| Step: 2
Training loss: 1.6186954975128174
Validation loss: 1.9643020988792501

Epoch: 6| Step: 3
Training loss: 1.7038192749023438
Validation loss: 1.9595192529821908

Epoch: 6| Step: 4
Training loss: 1.651010513305664
Validation loss: 1.9683996938890027

Epoch: 6| Step: 5
Training loss: 1.2939249277114868
Validation loss: 1.9769762985167965

Epoch: 6| Step: 6
Training loss: 2.1072425842285156
Validation loss: 1.9925210117011942

Epoch: 6| Step: 7
Training loss: 1.6370632648468018
Validation loss: 2.025331089573522

Epoch: 6| Step: 8
Training loss: 1.2397749423980713
Validation loss: 2.054716646030385

Epoch: 6| Step: 9
Training loss: 1.1473960876464844
Validation loss: 2.0821812704045284

Epoch: 6| Step: 10
Training loss: 2.2209134101867676
Validation loss: 2.1092528015054683

Epoch: 6| Step: 11
Training loss: 2.4164321422576904
Validation loss: 2.1409663718233825

Epoch: 6| Step: 12
Training loss: 1.6825414896011353
Validation loss: 2.124474799761208

Epoch: 6| Step: 13
Training loss: 2.1103765964508057
Validation loss: 2.132420442437613

Epoch: 168| Step: 0
Training loss: 1.992548942565918
Validation loss: 2.0975738443354124

Epoch: 6| Step: 1
Training loss: 1.5790393352508545
Validation loss: 2.081710030955653

Epoch: 6| Step: 2
Training loss: 2.0498249530792236
Validation loss: 2.046378622772873

Epoch: 6| Step: 3
Training loss: 1.9980213642120361
Validation loss: 2.0404405657963087

Epoch: 6| Step: 4
Training loss: 1.497584581375122
Validation loss: 2.0297355780037503

Epoch: 6| Step: 5
Training loss: 2.205324649810791
Validation loss: 2.019913907973997

Epoch: 6| Step: 6
Training loss: 1.4466912746429443
Validation loss: 2.016885374182014

Epoch: 6| Step: 7
Training loss: 1.3110849857330322
Validation loss: 2.042072408942766

Epoch: 6| Step: 8
Training loss: 1.5595145225524902
Validation loss: 2.0341674704705515

Epoch: 6| Step: 9
Training loss: 1.2525875568389893
Validation loss: 2.0288352363853046

Epoch: 6| Step: 10
Training loss: 2.0355024337768555
Validation loss: 2.0431269881545857

Epoch: 6| Step: 11
Training loss: 1.4104490280151367
Validation loss: 2.050011911699849

Epoch: 6| Step: 12
Training loss: 1.6603929996490479
Validation loss: 2.04634460326164

Epoch: 6| Step: 13
Training loss: 1.8668501377105713
Validation loss: 2.0591219227801085

Epoch: 169| Step: 0
Training loss: 1.6354336738586426
Validation loss: 2.059712331782105

Epoch: 6| Step: 1
Training loss: 1.200035810470581
Validation loss: 2.0752657357082573

Epoch: 6| Step: 2
Training loss: 1.0098137855529785
Validation loss: 2.0710305116509877

Epoch: 6| Step: 3
Training loss: 1.231000542640686
Validation loss: 2.081641850932952

Epoch: 6| Step: 4
Training loss: 2.134742498397827
Validation loss: 2.068304446435744

Epoch: 6| Step: 5
Training loss: 1.3377556800842285
Validation loss: 2.0930117560971166

Epoch: 6| Step: 6
Training loss: 1.942222237586975
Validation loss: 2.0970783746370705

Epoch: 6| Step: 7
Training loss: 1.908494234085083
Validation loss: 2.074326597234254

Epoch: 6| Step: 8
Training loss: 1.8696973323822021
Validation loss: 2.088994937558328

Epoch: 6| Step: 9
Training loss: 2.165849447250366
Validation loss: 2.0532746186820408

Epoch: 6| Step: 10
Training loss: 1.7794103622436523
Validation loss: 2.0144720615879184

Epoch: 6| Step: 11
Training loss: 1.8999673128128052
Validation loss: 2.0074239418070805

Epoch: 6| Step: 12
Training loss: 1.6248202323913574
Validation loss: 1.980604144834703

Epoch: 6| Step: 13
Training loss: 2.014525890350342
Validation loss: 1.9946783255505305

Epoch: 170| Step: 0
Training loss: 2.115704298019409
Validation loss: 1.9817330760340537

Epoch: 6| Step: 1
Training loss: 1.5341782569885254
Validation loss: 1.9950134984908565

Epoch: 6| Step: 2
Training loss: 1.3491171598434448
Validation loss: 2.0081821180159047

Epoch: 6| Step: 3
Training loss: 1.7707650661468506
Validation loss: 2.046315041921472

Epoch: 6| Step: 4
Training loss: 1.517210841178894
Validation loss: 2.0759105477281796

Epoch: 6| Step: 5
Training loss: 1.31403648853302
Validation loss: 2.1069734352891163

Epoch: 6| Step: 6
Training loss: 1.7090870141983032
Validation loss: 2.089902400970459

Epoch: 6| Step: 7
Training loss: 2.595391273498535
Validation loss: 2.1214845154875066

Epoch: 6| Step: 8
Training loss: 1.4984267950057983
Validation loss: 2.114990713775799

Epoch: 6| Step: 9
Training loss: 1.1763957738876343
Validation loss: 2.0608275551949777

Epoch: 6| Step: 10
Training loss: 1.6640980243682861
Validation loss: 2.064781605556447

Epoch: 6| Step: 11
Training loss: 1.9829492568969727
Validation loss: 2.0537311351427467

Epoch: 6| Step: 12
Training loss: 1.706714153289795
Validation loss: 2.0452954640952488

Epoch: 6| Step: 13
Training loss: 1.8740506172180176
Validation loss: 2.034657783405755

Epoch: 171| Step: 0
Training loss: 1.6823797225952148
Validation loss: 2.0302183217899774

Epoch: 6| Step: 1
Training loss: 1.5727150440216064
Validation loss: 2.070436521243024

Epoch: 6| Step: 2
Training loss: 1.919677495956421
Validation loss: 2.0408466400638705

Epoch: 6| Step: 3
Training loss: 1.629798412322998
Validation loss: 1.9937978226651427

Epoch: 6| Step: 4
Training loss: 1.8612912893295288
Validation loss: 1.9414522006947508

Epoch: 6| Step: 5
Training loss: 1.7124290466308594
Validation loss: 1.9478510169572727

Epoch: 6| Step: 6
Training loss: 1.5124497413635254
Validation loss: 1.9461719810321767

Epoch: 6| Step: 7
Training loss: 2.2621536254882812
Validation loss: 1.9453671363092238

Epoch: 6| Step: 8
Training loss: 2.0454695224761963
Validation loss: 1.9621136034688642

Epoch: 6| Step: 9
Training loss: 1.6029306650161743
Validation loss: 1.9648914106430546

Epoch: 6| Step: 10
Training loss: 1.3226428031921387
Validation loss: 1.9896446402354906

Epoch: 6| Step: 11
Training loss: 1.6813125610351562
Validation loss: 2.0045407664391304

Epoch: 6| Step: 12
Training loss: 1.4440289735794067
Validation loss: 2.0114341987076627

Epoch: 6| Step: 13
Training loss: 1.6098531484603882
Validation loss: 2.051433760632751

Epoch: 172| Step: 0
Training loss: 1.6897027492523193
Validation loss: 2.120856317140723

Epoch: 6| Step: 1
Training loss: 2.1894540786743164
Validation loss: 2.1573515848446916

Epoch: 6| Step: 2
Training loss: 1.6032871007919312
Validation loss: 2.1687716489197104

Epoch: 6| Step: 3
Training loss: 1.9397239685058594
Validation loss: 2.163075021518174

Epoch: 6| Step: 4
Training loss: 1.4914586544036865
Validation loss: 2.1473264348122383

Epoch: 6| Step: 5
Training loss: 1.752737283706665
Validation loss: 2.1383484922429568

Epoch: 6| Step: 6
Training loss: 1.696781873703003
Validation loss: 2.095210693215811

Epoch: 6| Step: 7
Training loss: 1.997942566871643
Validation loss: 2.0634904087230725

Epoch: 6| Step: 8
Training loss: 1.4375858306884766
Validation loss: 2.075922900630582

Epoch: 6| Step: 9
Training loss: 1.4009346961975098
Validation loss: 2.0544038100909163

Epoch: 6| Step: 10
Training loss: 1.1048393249511719
Validation loss: 2.0531126735030965

Epoch: 6| Step: 11
Training loss: 1.890157699584961
Validation loss: 2.036499971984535

Epoch: 6| Step: 12
Training loss: 1.5534441471099854
Validation loss: 2.030154102592058

Epoch: 6| Step: 13
Training loss: 1.56547212600708
Validation loss: 2.0203501832100654

Epoch: 173| Step: 0
Training loss: 0.7567152976989746
Validation loss: 2.009408299640943

Epoch: 6| Step: 1
Training loss: 1.865032434463501
Validation loss: 2.0006789417677027

Epoch: 6| Step: 2
Training loss: 2.074475049972534
Validation loss: 2.000866723316972

Epoch: 6| Step: 3
Training loss: 1.831552505493164
Validation loss: 1.9859243580090102

Epoch: 6| Step: 4
Training loss: 1.583338975906372
Validation loss: 1.9757776183466758

Epoch: 6| Step: 5
Training loss: 1.797269582748413
Validation loss: 1.9806459975498978

Epoch: 6| Step: 6
Training loss: 1.8712812662124634
Validation loss: 1.9896650147694412

Epoch: 6| Step: 7
Training loss: 1.6727104187011719
Validation loss: 2.0265395461872058

Epoch: 6| Step: 8
Training loss: 1.7259914875030518
Validation loss: 2.0278095147942983

Epoch: 6| Step: 9
Training loss: 1.8358392715454102
Validation loss: 2.0379808820703977

Epoch: 6| Step: 10
Training loss: 1.4031625986099243
Validation loss: 2.07039951509045

Epoch: 6| Step: 11
Training loss: 1.2980047464370728
Validation loss: 2.087912456963652

Epoch: 6| Step: 12
Training loss: 1.5669026374816895
Validation loss: 2.109235167503357

Epoch: 6| Step: 13
Training loss: 1.2639412879943848
Validation loss: 2.0984137173621886

Epoch: 174| Step: 0
Training loss: 1.7997448444366455
Validation loss: 2.067800865378431

Epoch: 6| Step: 1
Training loss: 1.5962620973587036
Validation loss: 2.047988255818685

Epoch: 6| Step: 2
Training loss: 1.6005465984344482
Validation loss: 2.0356246732896373

Epoch: 6| Step: 3
Training loss: 1.8452622890472412
Validation loss: 2.036240677679739

Epoch: 6| Step: 4
Training loss: 1.694206714630127
Validation loss: 2.0287415007109284

Epoch: 6| Step: 5
Training loss: 1.8016600608825684
Validation loss: 2.0229731157261837

Epoch: 6| Step: 6
Training loss: 1.405574917793274
Validation loss: 2.0203926435080906

Epoch: 6| Step: 7
Training loss: 2.3184804916381836
Validation loss: 2.015034037251626

Epoch: 6| Step: 8
Training loss: 0.9648290276527405
Validation loss: 2.019097570450075

Epoch: 6| Step: 9
Training loss: 2.086444616317749
Validation loss: 2.0411623934263825

Epoch: 6| Step: 10
Training loss: 1.7215101718902588
Validation loss: 2.0613060253922657

Epoch: 6| Step: 11
Training loss: 0.9224828481674194
Validation loss: 2.094133266838648

Epoch: 6| Step: 12
Training loss: 1.4625484943389893
Validation loss: 2.12464782755862

Epoch: 6| Step: 13
Training loss: 1.3078367710113525
Validation loss: 2.1589729042463404

Epoch: 175| Step: 0
Training loss: 1.4351425170898438
Validation loss: 2.1706610725771998

Epoch: 6| Step: 1
Training loss: 1.5348598957061768
Validation loss: 2.1570560368158485

Epoch: 6| Step: 2
Training loss: 2.116018295288086
Validation loss: 2.1109583108655867

Epoch: 6| Step: 3
Training loss: 2.069957733154297
Validation loss: 2.071545163790385

Epoch: 6| Step: 4
Training loss: 1.358505368232727
Validation loss: 2.0049933489932807

Epoch: 6| Step: 5
Training loss: 1.1564912796020508
Validation loss: 1.9864941655948598

Epoch: 6| Step: 6
Training loss: 1.7852990627288818
Validation loss: 1.9908177570630146

Epoch: 6| Step: 7
Training loss: 1.7879804372787476
Validation loss: 1.9959448140154603

Epoch: 6| Step: 8
Training loss: 1.5965166091918945
Validation loss: 1.9822871723482687

Epoch: 6| Step: 9
Training loss: 1.3548142910003662
Validation loss: 2.0052434513645787

Epoch: 6| Step: 10
Training loss: 1.6766924858093262
Validation loss: 2.021152659129071

Epoch: 6| Step: 11
Training loss: 1.2777321338653564
Validation loss: 2.0228869504826044

Epoch: 6| Step: 12
Training loss: 1.465649127960205
Validation loss: 2.027564584567983

Epoch: 6| Step: 13
Training loss: 2.2354354858398438
Validation loss: 2.0678820968956075

Epoch: 176| Step: 0
Training loss: 1.6532880067825317
Validation loss: 2.0657993452523344

Epoch: 6| Step: 1
Training loss: 1.309234619140625
Validation loss: 2.0609725470184

Epoch: 6| Step: 2
Training loss: 1.3215930461883545
Validation loss: 2.0820728835239204

Epoch: 6| Step: 3
Training loss: 1.8860973119735718
Validation loss: 2.0746881910549697

Epoch: 6| Step: 4
Training loss: 1.7313432693481445
Validation loss: 2.060627498934346

Epoch: 6| Step: 5
Training loss: 1.1672797203063965
Validation loss: 2.035730787502822

Epoch: 6| Step: 6
Training loss: 1.9197899103164673
Validation loss: 2.0308222950145765

Epoch: 6| Step: 7
Training loss: 2.1830527782440186
Validation loss: 2.0134202203442975

Epoch: 6| Step: 8
Training loss: 1.5435431003570557
Validation loss: 2.0070559427302372

Epoch: 6| Step: 9
Training loss: 1.6256439685821533
Validation loss: 2.0071057927223945

Epoch: 6| Step: 10
Training loss: 1.4949923753738403
Validation loss: 1.9999977824508504

Epoch: 6| Step: 11
Training loss: 1.5440312623977661
Validation loss: 1.9822554306317401

Epoch: 6| Step: 12
Training loss: 1.579888105392456
Validation loss: 1.9967227046207716

Epoch: 6| Step: 13
Training loss: 1.118177056312561
Validation loss: 2.0050638747471634

Epoch: 177| Step: 0
Training loss: 1.553321123123169
Validation loss: 2.0079769908740954

Epoch: 6| Step: 1
Training loss: 0.936397910118103
Validation loss: 2.039232402719477

Epoch: 6| Step: 2
Training loss: 1.4412623643875122
Validation loss: 2.054036109678207

Epoch: 6| Step: 3
Training loss: 1.2675408124923706
Validation loss: 2.070835336562126

Epoch: 6| Step: 4
Training loss: 2.3259711265563965
Validation loss: 2.0705625857076337

Epoch: 6| Step: 5
Training loss: 1.1496888399124146
Validation loss: 2.0725098374069377

Epoch: 6| Step: 6
Training loss: 1.902066946029663
Validation loss: 2.113784525984077

Epoch: 6| Step: 7
Training loss: 1.596221685409546
Validation loss: 2.1315295619349324

Epoch: 6| Step: 8
Training loss: 2.2352852821350098
Validation loss: 2.163176408378027

Epoch: 6| Step: 9
Training loss: 1.3501241207122803
Validation loss: 2.1235636357338197

Epoch: 6| Step: 10
Training loss: 1.3608359098434448
Validation loss: 2.0830644446034587

Epoch: 6| Step: 11
Training loss: 1.8270981311798096
Validation loss: 2.0567503975283716

Epoch: 6| Step: 12
Training loss: 1.3938148021697998
Validation loss: 2.0597014452821467

Epoch: 6| Step: 13
Training loss: 1.5713902711868286
Validation loss: 2.0376111153633363

Epoch: 178| Step: 0
Training loss: 1.3019719123840332
Validation loss: 2.0087726603272142

Epoch: 6| Step: 1
Training loss: 1.6951712369918823
Validation loss: 2.004858542514104

Epoch: 6| Step: 2
Training loss: 1.9393870830535889
Validation loss: 1.9955901766336093

Epoch: 6| Step: 3
Training loss: 2.4574813842773438
Validation loss: 1.9991899216046898

Epoch: 6| Step: 4
Training loss: 1.5001620054244995
Validation loss: 2.0079137535505396

Epoch: 6| Step: 5
Training loss: 1.7515535354614258
Validation loss: 2.037833736788842

Epoch: 6| Step: 6
Training loss: 1.916095495223999
Validation loss: 2.0367354257132417

Epoch: 6| Step: 7
Training loss: 1.4998760223388672
Validation loss: 2.050142102344062

Epoch: 6| Step: 8
Training loss: 1.5751469135284424
Validation loss: 2.023442506790161

Epoch: 6| Step: 9
Training loss: 1.1858850717544556
Validation loss: 2.006375574296521

Epoch: 6| Step: 10
Training loss: 1.6652374267578125
Validation loss: 2.0179715438555648

Epoch: 6| Step: 11
Training loss: 0.8426400423049927
Validation loss: 2.009298565567181

Epoch: 6| Step: 12
Training loss: 1.4284329414367676
Validation loss: 2.012068199855025

Epoch: 6| Step: 13
Training loss: 0.9332997798919678
Validation loss: 2.014006209629838

Epoch: 179| Step: 0
Training loss: 1.4392439126968384
Validation loss: 2.004291234477874

Epoch: 6| Step: 1
Training loss: 1.7363247871398926
Validation loss: 1.999255730259803

Epoch: 6| Step: 2
Training loss: 2.22417950630188
Validation loss: 2.0184831337262223

Epoch: 6| Step: 3
Training loss: 1.477813482284546
Validation loss: 2.009669580767232

Epoch: 6| Step: 4
Training loss: 1.9739456176757812
Validation loss: 2.0117693306297384

Epoch: 6| Step: 5
Training loss: 1.2429227828979492
Validation loss: 2.049281943228937

Epoch: 6| Step: 6
Training loss: 1.269600749015808
Validation loss: 2.079278434476545

Epoch: 6| Step: 7
Training loss: 1.2455707788467407
Validation loss: 2.0856653541646977

Epoch: 6| Step: 8
Training loss: 1.2262866497039795
Validation loss: 2.057852270782635

Epoch: 6| Step: 9
Training loss: 1.5618723630905151
Validation loss: 2.0306510258746404

Epoch: 6| Step: 10
Training loss: 1.296234130859375
Validation loss: 2.0035369703846593

Epoch: 6| Step: 11
Training loss: 1.2172694206237793
Validation loss: 1.9976344236763575

Epoch: 6| Step: 12
Training loss: 1.9644187688827515
Validation loss: 2.006110927110077

Epoch: 6| Step: 13
Training loss: 1.4920614957809448
Validation loss: 1.9985726597488567

Epoch: 180| Step: 0
Training loss: 1.791902780532837
Validation loss: 2.0340633110333513

Epoch: 6| Step: 1
Training loss: 1.4444174766540527
Validation loss: 2.033142366716939

Epoch: 6| Step: 2
Training loss: 1.4375903606414795
Validation loss: 2.0296333528334096

Epoch: 6| Step: 3
Training loss: 1.4537231922149658
Validation loss: 2.0230051291886197

Epoch: 6| Step: 4
Training loss: 1.1388318538665771
Validation loss: 2.040892852249966

Epoch: 6| Step: 5
Training loss: 1.0969135761260986
Validation loss: 2.0910413162682646

Epoch: 6| Step: 6
Training loss: 1.028794527053833
Validation loss: 2.141937924969581

Epoch: 6| Step: 7
Training loss: 1.8058058023452759
Validation loss: 2.1812625802973264

Epoch: 6| Step: 8
Training loss: 1.6306486129760742
Validation loss: 2.169995733486709

Epoch: 6| Step: 9
Training loss: 1.6981720924377441
Validation loss: 2.1409472496278825

Epoch: 6| Step: 10
Training loss: 1.7681047916412354
Validation loss: 2.111412268812938

Epoch: 6| Step: 11
Training loss: 2.1941184997558594
Validation loss: 2.0619901739140993

Epoch: 6| Step: 12
Training loss: 1.7225297689437866
Validation loss: 2.0307672075046006

Epoch: 6| Step: 13
Training loss: 1.95090651512146
Validation loss: 2.0196593653771187

Epoch: 181| Step: 0
Training loss: 1.332751750946045
Validation loss: 2.0102376553320114

Epoch: 6| Step: 1
Training loss: 0.9379069805145264
Validation loss: 2.0361550982280443

Epoch: 6| Step: 2
Training loss: 1.5108678340911865
Validation loss: 2.059319726882442

Epoch: 6| Step: 3
Training loss: 1.501520037651062
Validation loss: 2.0657239895994945

Epoch: 6| Step: 4
Training loss: 2.00447416305542
Validation loss: 2.0671237476410402

Epoch: 6| Step: 5
Training loss: 1.5699024200439453
Validation loss: 2.0846496679449595

Epoch: 6| Step: 6
Training loss: 0.7870774269104004
Validation loss: 2.0506978201609787

Epoch: 6| Step: 7
Training loss: 1.6979233026504517
Validation loss: 2.016533115858673

Epoch: 6| Step: 8
Training loss: 1.7400602102279663
Validation loss: 2.0243033516791558

Epoch: 6| Step: 9
Training loss: 1.6400477886199951
Validation loss: 2.0365013589141188

Epoch: 6| Step: 10
Training loss: 1.738899827003479
Validation loss: 2.0354265935959353

Epoch: 6| Step: 11
Training loss: 1.722596287727356
Validation loss: 2.0150928548587266

Epoch: 6| Step: 12
Training loss: 1.3167468309402466
Validation loss: 1.9955414674615348

Epoch: 6| Step: 13
Training loss: 1.6684507131576538
Validation loss: 1.990067312794347

Epoch: 182| Step: 0
Training loss: 1.7974399328231812
Validation loss: 2.006030487757857

Epoch: 6| Step: 1
Training loss: 1.4308944940567017
Validation loss: 2.0132319491396666

Epoch: 6| Step: 2
Training loss: 1.4293371438980103
Validation loss: 2.04271274997342

Epoch: 6| Step: 3
Training loss: 1.9525175094604492
Validation loss: 2.0602147976557412

Epoch: 6| Step: 4
Training loss: 0.9049973487854004
Validation loss: 2.034011528056155

Epoch: 6| Step: 5
Training loss: 1.9858498573303223
Validation loss: 2.0592487281368625

Epoch: 6| Step: 6
Training loss: 1.5614855289459229
Validation loss: 2.029068362328314

Epoch: 6| Step: 7
Training loss: 1.8191900253295898
Validation loss: 2.033722521156393

Epoch: 6| Step: 8
Training loss: 1.3880579471588135
Validation loss: 2.022823526013282

Epoch: 6| Step: 9
Training loss: 1.0150256156921387
Validation loss: 2.042003963583259

Epoch: 6| Step: 10
Training loss: 1.9526821374893188
Validation loss: 2.0600329957982546

Epoch: 6| Step: 11
Training loss: 1.0539252758026123
Validation loss: 2.0680714627747894

Epoch: 6| Step: 12
Training loss: 1.2702698707580566
Validation loss: 2.0621789193922475

Epoch: 6| Step: 13
Training loss: 0.6357359290122986
Validation loss: 2.083179155985514

Epoch: 183| Step: 0
Training loss: 1.258007287979126
Validation loss: 2.0768562337403655

Epoch: 6| Step: 1
Training loss: 1.84507155418396
Validation loss: 2.0382155423523276

Epoch: 6| Step: 2
Training loss: 2.0076990127563477
Validation loss: 2.0160358208481983

Epoch: 6| Step: 3
Training loss: 1.2612595558166504
Validation loss: 2.0416853068977274

Epoch: 6| Step: 4
Training loss: 1.6745400428771973
Validation loss: 2.018119136492411

Epoch: 6| Step: 5
Training loss: 1.174459457397461
Validation loss: 2.001504553261624

Epoch: 6| Step: 6
Training loss: 1.3924689292907715
Validation loss: 1.997601632148989

Epoch: 6| Step: 7
Training loss: 1.4612524509429932
Validation loss: 2.0303832843739498

Epoch: 6| Step: 8
Training loss: 1.4370613098144531
Validation loss: 2.0250729604433944

Epoch: 6| Step: 9
Training loss: 1.1808675527572632
Validation loss: 2.0525127931307723

Epoch: 6| Step: 10
Training loss: 1.6781748533248901
Validation loss: 2.04834573243254

Epoch: 6| Step: 11
Training loss: 1.9115345478057861
Validation loss: 2.048358227616997

Epoch: 6| Step: 12
Training loss: 1.1099172830581665
Validation loss: 2.0737211922163605

Epoch: 6| Step: 13
Training loss: 0.9380340576171875
Validation loss: 2.0777278459200295

Epoch: 184| Step: 0
Training loss: 1.5267150402069092
Validation loss: 2.1011847296068744

Epoch: 6| Step: 1
Training loss: 1.0410465002059937
Validation loss: 2.115610473899431

Epoch: 6| Step: 2
Training loss: 1.4587538242340088
Validation loss: 2.1341907029510825

Epoch: 6| Step: 3
Training loss: 1.6283807754516602
Validation loss: 2.1119786206112114

Epoch: 6| Step: 4
Training loss: 1.3124972581863403
Validation loss: 2.093389385490007

Epoch: 6| Step: 5
Training loss: 1.5223321914672852
Validation loss: 2.0880413337420394

Epoch: 6| Step: 6
Training loss: 0.998586118221283
Validation loss: 2.0533485130597184

Epoch: 6| Step: 7
Training loss: 1.2462666034698486
Validation loss: 2.0422059054015786

Epoch: 6| Step: 8
Training loss: 1.7851769924163818
Validation loss: 1.9966164814528597

Epoch: 6| Step: 9
Training loss: 1.905764102935791
Validation loss: 1.9882937182662308

Epoch: 6| Step: 10
Training loss: 1.1857423782348633
Validation loss: 1.9598598005951091

Epoch: 6| Step: 11
Training loss: 1.5938990116119385
Validation loss: 1.9619002406315138

Epoch: 6| Step: 12
Training loss: 1.7072560787200928
Validation loss: 1.953773142189108

Epoch: 6| Step: 13
Training loss: 1.5200341939926147
Validation loss: 1.9785805786809614

Epoch: 185| Step: 0
Training loss: 1.194665789604187
Validation loss: 1.9832244637191936

Epoch: 6| Step: 1
Training loss: 1.5354793071746826
Validation loss: 2.0181757070684947

Epoch: 6| Step: 2
Training loss: 1.6087465286254883
Validation loss: 2.0257718204170145

Epoch: 6| Step: 3
Training loss: 1.664801001548767
Validation loss: 2.042849617619668

Epoch: 6| Step: 4
Training loss: 1.2843035459518433
Validation loss: 2.0491049546067432

Epoch: 6| Step: 5
Training loss: 0.9976897239685059
Validation loss: 2.0546537291619087

Epoch: 6| Step: 6
Training loss: 1.533862829208374
Validation loss: 2.0443329657277753

Epoch: 6| Step: 7
Training loss: 1.234055757522583
Validation loss: 2.0559269664108113

Epoch: 6| Step: 8
Training loss: 1.6024487018585205
Validation loss: 2.0620643323467625

Epoch: 6| Step: 9
Training loss: 1.2941040992736816
Validation loss: 2.033324400583903

Epoch: 6| Step: 10
Training loss: 1.3595201969146729
Validation loss: 2.0059333821778655

Epoch: 6| Step: 11
Training loss: 1.6134302616119385
Validation loss: 1.9928313532183248

Epoch: 6| Step: 12
Training loss: 1.9486163854599
Validation loss: 1.9942985465449672

Epoch: 6| Step: 13
Training loss: 0.9294688105583191
Validation loss: 2.007070897727884

Epoch: 186| Step: 0
Training loss: 1.1908323764801025
Validation loss: 2.018534116847541

Epoch: 6| Step: 1
Training loss: 1.934051513671875
Validation loss: 2.0480286152132097

Epoch: 6| Step: 2
Training loss: 1.6706103086471558
Validation loss: 2.0694987568804013

Epoch: 6| Step: 3
Training loss: 1.539689302444458
Validation loss: 2.0463645048038934

Epoch: 6| Step: 4
Training loss: 1.950391173362732
Validation loss: 2.0368196964263916

Epoch: 6| Step: 5
Training loss: 1.7951717376708984
Validation loss: 2.036953374903689

Epoch: 6| Step: 6
Training loss: 1.2815550565719604
Validation loss: 1.9986559421785417

Epoch: 6| Step: 7
Training loss: 0.7952765226364136
Validation loss: 1.9633292318672262

Epoch: 6| Step: 8
Training loss: 1.0671244859695435
Validation loss: 1.97240452484418

Epoch: 6| Step: 9
Training loss: 1.943629503250122
Validation loss: 1.9908124477632585

Epoch: 6| Step: 10
Training loss: 1.5493505001068115
Validation loss: 2.0110526623264438

Epoch: 6| Step: 11
Training loss: 1.051969289779663
Validation loss: 2.0419620108860794

Epoch: 6| Step: 12
Training loss: 1.479914903640747
Validation loss: 2.0372929265422206

Epoch: 6| Step: 13
Training loss: 0.8879156112670898
Validation loss: 2.085520972487747

Epoch: 187| Step: 0
Training loss: 1.4549888372421265
Validation loss: 2.082189944482619

Epoch: 6| Step: 1
Training loss: 1.4667309522628784
Validation loss: 2.0674587821447723

Epoch: 6| Step: 2
Training loss: 1.42352294921875
Validation loss: 2.065180937449137

Epoch: 6| Step: 3
Training loss: 1.2090612649917603
Validation loss: 2.0581665295426563

Epoch: 6| Step: 4
Training loss: 1.4808694124221802
Validation loss: 2.0086698660286526

Epoch: 6| Step: 5
Training loss: 1.3916351795196533
Validation loss: 2.009718379666728

Epoch: 6| Step: 6
Training loss: 1.3517167568206787
Validation loss: 1.974658493072756

Epoch: 6| Step: 7
Training loss: 1.6003077030181885
Validation loss: 1.9857279177634948

Epoch: 6| Step: 8
Training loss: 1.2295644283294678
Validation loss: 1.985153313606016

Epoch: 6| Step: 9
Training loss: 1.9595617055892944
Validation loss: 1.996751739132789

Epoch: 6| Step: 10
Training loss: 1.3069205284118652
Validation loss: 2.0190023876005605

Epoch: 6| Step: 11
Training loss: 1.1023603677749634
Validation loss: 2.0486607102937597

Epoch: 6| Step: 12
Training loss: 1.0416443347930908
Validation loss: 2.0505212417212864

Epoch: 6| Step: 13
Training loss: 2.476074695587158
Validation loss: 2.055706080570016

Epoch: 188| Step: 0
Training loss: 1.2702449560165405
Validation loss: 2.050472911968026

Epoch: 6| Step: 1
Training loss: 1.3969601392745972
Validation loss: 2.064902618367185

Epoch: 6| Step: 2
Training loss: 1.7101852893829346
Validation loss: 2.0764325818707867

Epoch: 6| Step: 3
Training loss: 1.8873471021652222
Validation loss: 2.06984809906252

Epoch: 6| Step: 4
Training loss: 1.1167371273040771
Validation loss: 2.0660829223612303

Epoch: 6| Step: 5
Training loss: 1.6922338008880615
Validation loss: 2.0805373345651934

Epoch: 6| Step: 6
Training loss: 2.0224642753601074
Validation loss: 2.07251331626728

Epoch: 6| Step: 7
Training loss: 1.740679144859314
Validation loss: 2.0744749064086587

Epoch: 6| Step: 8
Training loss: 0.8579833507537842
Validation loss: 2.0662298792151996

Epoch: 6| Step: 9
Training loss: 1.3705267906188965
Validation loss: 2.0610473232884563

Epoch: 6| Step: 10
Training loss: 1.8897249698638916
Validation loss: 2.0507004581471926

Epoch: 6| Step: 11
Training loss: 1.578229308128357
Validation loss: 2.04280783155913

Epoch: 6| Step: 12
Training loss: 0.6532160043716431
Validation loss: 2.0430504019542406

Epoch: 6| Step: 13
Training loss: 1.0154966115951538
Validation loss: 2.036176819955149

Epoch: 189| Step: 0
Training loss: 1.1276189088821411
Validation loss: 2.032061561461418

Epoch: 6| Step: 1
Training loss: 1.6846288442611694
Validation loss: 1.9979053428096156

Epoch: 6| Step: 2
Training loss: 1.6952157020568848
Validation loss: 1.9928748633271904

Epoch: 6| Step: 3
Training loss: 0.9932543039321899
Validation loss: 1.9808723054906374

Epoch: 6| Step: 4
Training loss: 0.9201659560203552
Validation loss: 1.975279656789636

Epoch: 6| Step: 5
Training loss: 1.3247348070144653
Validation loss: 1.9934205496183006

Epoch: 6| Step: 6
Training loss: 1.7415275573730469
Validation loss: 2.0056843680720173

Epoch: 6| Step: 7
Training loss: 0.9042626023292542
Validation loss: 2.0357619844457155

Epoch: 6| Step: 8
Training loss: 1.3407468795776367
Validation loss: 2.068276934726264

Epoch: 6| Step: 9
Training loss: 1.5394504070281982
Validation loss: 2.095849976744703

Epoch: 6| Step: 10
Training loss: 1.496397852897644
Validation loss: 2.081590542229273

Epoch: 6| Step: 11
Training loss: 1.865071415901184
Validation loss: 2.1114140941250708

Epoch: 6| Step: 12
Training loss: 1.7380926609039307
Validation loss: 2.0488164758169525

Epoch: 6| Step: 13
Training loss: 1.7267858982086182
Validation loss: 2.048283007837111

Epoch: 190| Step: 0
Training loss: 2.1604905128479004
Validation loss: 2.0363929745971516

Epoch: 6| Step: 1
Training loss: 1.6458981037139893
Validation loss: 2.029772371374151

Epoch: 6| Step: 2
Training loss: 1.7851314544677734
Validation loss: 2.0500906077764367

Epoch: 6| Step: 3
Training loss: 1.853208303451538
Validation loss: 2.0741128947145198

Epoch: 6| Step: 4
Training loss: 1.0607635974884033
Validation loss: 2.058237039914695

Epoch: 6| Step: 5
Training loss: 1.213129997253418
Validation loss: 2.0991055401422645

Epoch: 6| Step: 6
Training loss: 1.2020776271820068
Validation loss: 2.0655169256271853

Epoch: 6| Step: 7
Training loss: 1.2378003597259521
Validation loss: 2.0699844206533125

Epoch: 6| Step: 8
Training loss: 1.8654975891113281
Validation loss: 2.0693231833878385

Epoch: 6| Step: 9
Training loss: 1.3678596019744873
Validation loss: 2.021841190194571

Epoch: 6| Step: 10
Training loss: 1.3727097511291504
Validation loss: 2.04845057892543

Epoch: 6| Step: 11
Training loss: 0.8044332265853882
Validation loss: 2.0109782013841855

Epoch: 6| Step: 12
Training loss: 1.1992989778518677
Validation loss: 2.007904480862361

Epoch: 6| Step: 13
Training loss: 0.9803569316864014
Validation loss: 2.0015636105691232

Epoch: 191| Step: 0
Training loss: 1.380575180053711
Validation loss: 1.98174851171432

Epoch: 6| Step: 1
Training loss: 1.321131944656372
Validation loss: 1.976936089095249

Epoch: 6| Step: 2
Training loss: 1.3620288372039795
Validation loss: 2.007837495496196

Epoch: 6| Step: 3
Training loss: 1.229357123374939
Validation loss: 2.0203995832832913

Epoch: 6| Step: 4
Training loss: 1.062363862991333
Validation loss: 2.0549238651029524

Epoch: 6| Step: 5
Training loss: 1.4946870803833008
Validation loss: 2.1117805537357124

Epoch: 6| Step: 6
Training loss: 1.6305527687072754
Validation loss: 2.1436294073699624

Epoch: 6| Step: 7
Training loss: 1.7379108667373657
Validation loss: 2.1592867400056575

Epoch: 6| Step: 8
Training loss: 1.5868607759475708
Validation loss: 2.1659485524700535

Epoch: 6| Step: 9
Training loss: 0.8493972420692444
Validation loss: 2.135534022444038

Epoch: 6| Step: 10
Training loss: 1.8937668800354004
Validation loss: 2.0789443780017156

Epoch: 6| Step: 11
Training loss: 1.6758625507354736
Validation loss: 2.0637689790418072

Epoch: 6| Step: 12
Training loss: 1.265058994293213
Validation loss: 2.012436588605245

Epoch: 6| Step: 13
Training loss: 1.4054044485092163
Validation loss: 1.9891274231736378

Epoch: 192| Step: 0
Training loss: 0.8217182755470276
Validation loss: 1.9920815011506439

Epoch: 6| Step: 1
Training loss: 1.4497170448303223
Validation loss: 1.9700439745380032

Epoch: 6| Step: 2
Training loss: 1.6386299133300781
Validation loss: 1.970108570591096

Epoch: 6| Step: 3
Training loss: 2.1337013244628906
Validation loss: 1.978314047218651

Epoch: 6| Step: 4
Training loss: 0.8749586939811707
Validation loss: 2.0164983452007337

Epoch: 6| Step: 5
Training loss: 1.6762762069702148
Validation loss: 2.050735972260916

Epoch: 6| Step: 6
Training loss: 1.176805019378662
Validation loss: 2.0524326665427095

Epoch: 6| Step: 7
Training loss: 1.7011710405349731
Validation loss: 2.0878409147262573

Epoch: 6| Step: 8
Training loss: 1.4515657424926758
Validation loss: 2.0445012764264177

Epoch: 6| Step: 9
Training loss: 1.2792954444885254
Validation loss: 2.008173886165824

Epoch: 6| Step: 10
Training loss: 1.291577935218811
Validation loss: 2.0326590666206936

Epoch: 6| Step: 11
Training loss: 1.378461480140686
Validation loss: 2.010841813138736

Epoch: 6| Step: 12
Training loss: 1.5467840433120728
Validation loss: 2.025206922202982

Epoch: 6| Step: 13
Training loss: 1.1307930946350098
Validation loss: 2.0467674065661687

Epoch: 193| Step: 0
Training loss: 1.417104959487915
Validation loss: 2.019782845691968

Epoch: 6| Step: 1
Training loss: 1.0269439220428467
Validation loss: 2.060404077652962

Epoch: 6| Step: 2
Training loss: 1.2736378908157349
Validation loss: 2.084991842187861

Epoch: 6| Step: 3
Training loss: 1.1903862953186035
Validation loss: 2.094098142398301

Epoch: 6| Step: 4
Training loss: 1.6393322944641113
Validation loss: 2.0918064809614614

Epoch: 6| Step: 5
Training loss: 1.4394316673278809
Validation loss: 2.096586387644532

Epoch: 6| Step: 6
Training loss: 1.239372730255127
Validation loss: 2.076304389584449

Epoch: 6| Step: 7
Training loss: 1.1181612014770508
Validation loss: 2.0122336982398905

Epoch: 6| Step: 8
Training loss: 1.188480257987976
Validation loss: 1.990025992034584

Epoch: 6| Step: 9
Training loss: 2.095284938812256
Validation loss: 1.9832828070527764

Epoch: 6| Step: 10
Training loss: 1.5459307432174683
Validation loss: 1.986440138150287

Epoch: 6| Step: 11
Training loss: 1.2509746551513672
Validation loss: 1.9889652677761611

Epoch: 6| Step: 12
Training loss: 1.266995906829834
Validation loss: 1.9865222387416388

Epoch: 6| Step: 13
Training loss: 1.3917977809906006
Validation loss: 1.9662098256490563

Epoch: 194| Step: 0
Training loss: 1.1927623748779297
Validation loss: 1.9901552533590665

Epoch: 6| Step: 1
Training loss: 1.5061054229736328
Validation loss: 2.0064022156500045

Epoch: 6| Step: 2
Training loss: 1.1111801862716675
Validation loss: 2.024008083087142

Epoch: 6| Step: 3
Training loss: 1.46466064453125
Validation loss: 2.0231633006885485

Epoch: 6| Step: 4
Training loss: 1.4094650745391846
Validation loss: 2.0147021047530638

Epoch: 6| Step: 5
Training loss: 1.569413661956787
Validation loss: 2.04245263273998

Epoch: 6| Step: 6
Training loss: 1.4512046575546265
Validation loss: 2.054903584141885

Epoch: 6| Step: 7
Training loss: 1.0894407033920288
Validation loss: 2.0775938623694965

Epoch: 6| Step: 8
Training loss: 1.2317873239517212
Validation loss: 2.0886478500981487

Epoch: 6| Step: 9
Training loss: 1.1374696493148804
Validation loss: 2.086209317689301

Epoch: 6| Step: 10
Training loss: 1.1706228256225586
Validation loss: 2.0840072080653202

Epoch: 6| Step: 11
Training loss: 1.2253355979919434
Validation loss: 2.030170889310939

Epoch: 6| Step: 12
Training loss: 1.3667361736297607
Validation loss: 2.004545073355398

Epoch: 6| Step: 13
Training loss: 1.5578651428222656
Validation loss: 1.9801625487624959

Epoch: 195| Step: 0
Training loss: 1.370082974433899
Validation loss: 1.9752889525505803

Epoch: 6| Step: 1
Training loss: 1.1900556087493896
Validation loss: 1.9473525811267156

Epoch: 6| Step: 2
Training loss: 1.729676604270935
Validation loss: 1.9385331484579271

Epoch: 6| Step: 3
Training loss: 1.9150118827819824
Validation loss: 1.9203810435469433

Epoch: 6| Step: 4
Training loss: 1.117558479309082
Validation loss: 1.949612650820004

Epoch: 6| Step: 5
Training loss: 1.4664366245269775
Validation loss: 1.9782037183802614

Epoch: 6| Step: 6
Training loss: 1.2863633632659912
Validation loss: 1.997534736510246

Epoch: 6| Step: 7
Training loss: 1.0968992710113525
Validation loss: 2.0166907643759124

Epoch: 6| Step: 8
Training loss: 0.7788079977035522
Validation loss: 2.0425132551500873

Epoch: 6| Step: 9
Training loss: 1.2919447422027588
Validation loss: 2.0077388760864094

Epoch: 6| Step: 10
Training loss: 1.2230916023254395
Validation loss: 2.003296885439145

Epoch: 6| Step: 11
Training loss: 1.3875921964645386
Validation loss: 2.037131094163464

Epoch: 6| Step: 12
Training loss: 1.108607530593872
Validation loss: 2.0052186840323993

Epoch: 6| Step: 13
Training loss: 1.6197052001953125
Validation loss: 2.0353667915508313

Epoch: 196| Step: 0
Training loss: 1.2698895931243896
Validation loss: 2.055335267897575

Epoch: 6| Step: 1
Training loss: 1.703918218612671
Validation loss: 2.047396849560481

Epoch: 6| Step: 2
Training loss: 1.319138765335083
Validation loss: 2.078687519155523

Epoch: 6| Step: 3
Training loss: 1.2108075618743896
Validation loss: 2.0759761205283542

Epoch: 6| Step: 4
Training loss: 1.5604933500289917
Validation loss: 2.0785921696693666

Epoch: 6| Step: 5
Training loss: 1.6879408359527588
Validation loss: 2.0268068287962224

Epoch: 6| Step: 6
Training loss: 1.522231101989746
Validation loss: 1.9856426536395986

Epoch: 6| Step: 7
Training loss: 1.3314979076385498
Validation loss: 1.9520949112471713

Epoch: 6| Step: 8
Training loss: 1.4548170566558838
Validation loss: 1.9207121800350886

Epoch: 6| Step: 9
Training loss: 1.087149977684021
Validation loss: 1.93901353497659

Epoch: 6| Step: 10
Training loss: 0.824539303779602
Validation loss: 1.9274616395273516

Epoch: 6| Step: 11
Training loss: 1.4398741722106934
Validation loss: 1.9173689990915277

Epoch: 6| Step: 12
Training loss: 1.3155922889709473
Validation loss: 1.8654921798295871

Epoch: 6| Step: 13
Training loss: 0.8137058615684509
Validation loss: 1.9033788904067008

Epoch: 197| Step: 0
Training loss: 1.1306885480880737
Validation loss: 1.9315994144767843

Epoch: 6| Step: 1
Training loss: 1.0558243989944458
Validation loss: 1.9278191956140662

Epoch: 6| Step: 2
Training loss: 1.1593397855758667
Validation loss: 1.9642423878433883

Epoch: 6| Step: 3
Training loss: 1.2382044792175293
Validation loss: 2.0093362587754444

Epoch: 6| Step: 4
Training loss: 1.1237868070602417
Validation loss: 2.019392377586775

Epoch: 6| Step: 5
Training loss: 1.3683900833129883
Validation loss: 2.0268551072766705

Epoch: 6| Step: 6
Training loss: 1.8642146587371826
Validation loss: 2.0096958016836517

Epoch: 6| Step: 7
Training loss: 1.2141921520233154
Validation loss: 1.972637446977759

Epoch: 6| Step: 8
Training loss: 1.321488857269287
Validation loss: 1.987829585229197

Epoch: 6| Step: 9
Training loss: 1.7242305278778076
Validation loss: 1.9563819746817313

Epoch: 6| Step: 10
Training loss: 1.3767147064208984
Validation loss: 1.9531182858251757

Epoch: 6| Step: 11
Training loss: 1.2943048477172852
Validation loss: 1.9324630280976653

Epoch: 6| Step: 12
Training loss: 1.1869677305221558
Validation loss: 1.9205907390963646

Epoch: 6| Step: 13
Training loss: 1.399273157119751
Validation loss: 1.9699685547941475

Epoch: 198| Step: 0
Training loss: 1.3612494468688965
Validation loss: 1.9900167513919134

Epoch: 6| Step: 1
Training loss: 1.0284161567687988
Validation loss: 1.9838870110050324

Epoch: 6| Step: 2
Training loss: 0.971779465675354
Validation loss: 1.9536538508630568

Epoch: 6| Step: 3
Training loss: 2.0384929180145264
Validation loss: 1.9442627532507784

Epoch: 6| Step: 4
Training loss: 1.6993457078933716
Validation loss: 1.9333860758812196

Epoch: 6| Step: 5
Training loss: 1.2846031188964844
Validation loss: 1.9313081618278258

Epoch: 6| Step: 6
Training loss: 1.2439223527908325
Validation loss: 1.9118241135792067

Epoch: 6| Step: 7
Training loss: 1.4103033542633057
Validation loss: 1.9332949294838855

Epoch: 6| Step: 8
Training loss: 0.7062546610832214
Validation loss: 1.9276603396220873

Epoch: 6| Step: 9
Training loss: 1.1019415855407715
Validation loss: 1.9331658899143178

Epoch: 6| Step: 10
Training loss: 1.3332252502441406
Validation loss: 1.9493501570916945

Epoch: 6| Step: 11
Training loss: 1.539486289024353
Validation loss: 1.9682881396303895

Epoch: 6| Step: 12
Training loss: 0.7436959743499756
Validation loss: 2.0402485773127568

Epoch: 6| Step: 13
Training loss: 2.106461524963379
Validation loss: 2.076498055970797

Epoch: 199| Step: 0
Training loss: 1.4653306007385254
Validation loss: 2.0641758800834737

Epoch: 6| Step: 1
Training loss: 1.4762260913848877
Validation loss: 2.080288657578089

Epoch: 6| Step: 2
Training loss: 1.2613401412963867
Validation loss: 2.077670738261233

Epoch: 6| Step: 3
Training loss: 1.7199556827545166
Validation loss: 2.0529487427844795

Epoch: 6| Step: 4
Training loss: 1.277866005897522
Validation loss: 1.9944891852717246

Epoch: 6| Step: 5
Training loss: 1.0750095844268799
Validation loss: 1.9742696285247803

Epoch: 6| Step: 6
Training loss: 1.4271507263183594
Validation loss: 1.9281872831365114

Epoch: 6| Step: 7
Training loss: 1.3371086120605469
Validation loss: 1.9346159517124135

Epoch: 6| Step: 8
Training loss: 0.9566787481307983
Validation loss: 1.9255887680156256

Epoch: 6| Step: 9
Training loss: 1.4484994411468506
Validation loss: 1.933395662615376

Epoch: 6| Step: 10
Training loss: 1.2017879486083984
Validation loss: 1.9367305950451923

Epoch: 6| Step: 11
Training loss: 1.182283639907837
Validation loss: 1.9436226544841644

Epoch: 6| Step: 12
Training loss: 0.9099438786506653
Validation loss: 1.934833102328803

Epoch: 6| Step: 13
Training loss: 1.430104374885559
Validation loss: 1.9442564518220964

Epoch: 200| Step: 0
Training loss: 1.6384742259979248
Validation loss: 1.93769327158569

Epoch: 6| Step: 1
Training loss: 1.0421515703201294
Validation loss: 1.9604480663935344

Epoch: 6| Step: 2
Training loss: 1.4505424499511719
Validation loss: 1.962052927222303

Epoch: 6| Step: 3
Training loss: 1.3581632375717163
Validation loss: 1.9885734742687595

Epoch: 6| Step: 4
Training loss: 1.6686272621154785
Validation loss: 1.9538747661857194

Epoch: 6| Step: 5
Training loss: 1.597225546836853
Validation loss: 1.9561411590986355

Epoch: 6| Step: 6
Training loss: 1.237936019897461
Validation loss: 1.9525521583454584

Epoch: 6| Step: 7
Training loss: 0.9197461605072021
Validation loss: 1.966717355994768

Epoch: 6| Step: 8
Training loss: 0.8156245946884155
Validation loss: 1.9218207315732074

Epoch: 6| Step: 9
Training loss: 1.3755619525909424
Validation loss: 1.923579377512778

Epoch: 6| Step: 10
Training loss: 0.8700470924377441
Validation loss: 1.913014570871989

Epoch: 6| Step: 11
Training loss: 1.2645502090454102
Validation loss: 1.903619299652756

Epoch: 6| Step: 12
Training loss: 1.2289150953292847
Validation loss: 1.8975852561253372

Epoch: 6| Step: 13
Training loss: 0.9049738645553589
Validation loss: 1.9325832910435174

Epoch: 201| Step: 0
Training loss: 1.0994236469268799
Validation loss: 1.9659436146418254

Epoch: 6| Step: 1
Training loss: 0.9231408834457397
Validation loss: 2.0108817264597905

Epoch: 6| Step: 2
Training loss: 1.244301676750183
Validation loss: 1.9900459474132908

Epoch: 6| Step: 3
Training loss: 1.5886706113815308
Validation loss: 1.9927636679782663

Epoch: 6| Step: 4
Training loss: 1.6098740100860596
Validation loss: 1.9775562363286172

Epoch: 6| Step: 5
Training loss: 1.1086516380310059
Validation loss: 1.955702982923036

Epoch: 6| Step: 6
Training loss: 1.2600209712982178
Validation loss: 1.9597523943070443

Epoch: 6| Step: 7
Training loss: 0.841856062412262
Validation loss: 1.956850113407258

Epoch: 6| Step: 8
Training loss: 1.1614221334457397
Validation loss: 1.9227381624201292

Epoch: 6| Step: 9
Training loss: 1.8498201370239258
Validation loss: 1.8921404743707309

Epoch: 6| Step: 10
Training loss: 0.9208226203918457
Validation loss: 1.8840527867758146

Epoch: 6| Step: 11
Training loss: 1.1524173021316528
Validation loss: 1.8615719746517878

Epoch: 6| Step: 12
Training loss: 0.9916948080062866
Validation loss: 1.8592854610053442

Epoch: 6| Step: 13
Training loss: 1.4260889291763306
Validation loss: 1.8802060375931442

Epoch: 202| Step: 0
Training loss: 1.5984108448028564
Validation loss: 1.884202491852545

Epoch: 6| Step: 1
Training loss: 1.4627976417541504
Validation loss: 1.9209269836384764

Epoch: 6| Step: 2
Training loss: 1.131880760192871
Validation loss: 1.9407470328833467

Epoch: 6| Step: 3
Training loss: 1.1812719106674194
Validation loss: 1.9416029953187512

Epoch: 6| Step: 4
Training loss: 1.1224775314331055
Validation loss: 1.948486307615875

Epoch: 6| Step: 5
Training loss: 1.4453625679016113
Validation loss: 1.9572959100046465

Epoch: 6| Step: 6
Training loss: 1.3876214027404785
Validation loss: 1.945441948470249

Epoch: 6| Step: 7
Training loss: 0.9503965377807617
Validation loss: 1.966618517393707

Epoch: 6| Step: 8
Training loss: 1.3530051708221436
Validation loss: 1.9341266603880032

Epoch: 6| Step: 9
Training loss: 1.310847282409668
Validation loss: 1.922326676307186

Epoch: 6| Step: 10
Training loss: 1.511178970336914
Validation loss: 1.9173630565725348

Epoch: 6| Step: 11
Training loss: 0.739325761795044
Validation loss: 1.8946724399443595

Epoch: 6| Step: 12
Training loss: 0.795751690864563
Validation loss: 1.8929009078651347

Epoch: 6| Step: 13
Training loss: 0.7425342798233032
Validation loss: 1.8834267508599065

Epoch: 203| Step: 0
Training loss: 1.5918574333190918
Validation loss: 1.9083794868120583

Epoch: 6| Step: 1
Training loss: 1.3973889350891113
Validation loss: 1.9035780647749543

Epoch: 6| Step: 2
Training loss: 1.2623353004455566
Validation loss: 1.9265933100895216

Epoch: 6| Step: 3
Training loss: 1.1418917179107666
Validation loss: 1.9319090010017477

Epoch: 6| Step: 4
Training loss: 1.9755579233169556
Validation loss: 1.9596555425274758

Epoch: 6| Step: 5
Training loss: 1.138713002204895
Validation loss: 1.9727492204276464

Epoch: 6| Step: 6
Training loss: 1.1089982986450195
Validation loss: 1.985211697957849

Epoch: 6| Step: 7
Training loss: 1.2322101593017578
Validation loss: 1.983947084796044

Epoch: 6| Step: 8
Training loss: 0.9863100647926331
Validation loss: 1.9500185751145886

Epoch: 6| Step: 9
Training loss: 0.5604802370071411
Validation loss: 1.8921119154140513

Epoch: 6| Step: 10
Training loss: 1.2037616968154907
Validation loss: 1.8847222610186505

Epoch: 6| Step: 11
Training loss: 1.0590846538543701
Validation loss: 1.9090209058535996

Epoch: 6| Step: 12
Training loss: 1.07314133644104
Validation loss: 1.9104685168112479

Epoch: 6| Step: 13
Training loss: 1.279631495475769
Validation loss: 1.920102370682583

Epoch: 204| Step: 0
Training loss: 1.062721610069275
Validation loss: 1.9649461776979509

Epoch: 6| Step: 1
Training loss: 1.560032606124878
Validation loss: 1.9752166899301673

Epoch: 6| Step: 2
Training loss: 1.3976984024047852
Validation loss: 2.006399731482229

Epoch: 6| Step: 3
Training loss: 1.7960851192474365
Validation loss: 2.0094799636512675

Epoch: 6| Step: 4
Training loss: 1.487298846244812
Validation loss: 2.0117708393322524

Epoch: 6| Step: 5
Training loss: 0.8050708174705505
Validation loss: 1.979715565199493

Epoch: 6| Step: 6
Training loss: 1.0409706830978394
Validation loss: 1.9360098620896697

Epoch: 6| Step: 7
Training loss: 1.2227301597595215
Validation loss: 1.970027756947343

Epoch: 6| Step: 8
Training loss: 1.1427438259124756
Validation loss: 1.9397553000398862

Epoch: 6| Step: 9
Training loss: 0.7249246835708618
Validation loss: 1.9453183797097975

Epoch: 6| Step: 10
Training loss: 0.8455461263656616
Validation loss: 1.9812925541272728

Epoch: 6| Step: 11
Training loss: 1.2111666202545166
Validation loss: 2.005869674426253

Epoch: 6| Step: 12
Training loss: 0.8108665943145752
Validation loss: 2.0091402043578444

Epoch: 6| Step: 13
Training loss: 1.513123631477356
Validation loss: 2.016131991981178

Epoch: 205| Step: 0
Training loss: 1.2339653968811035
Validation loss: 1.977807999939047

Epoch: 6| Step: 1
Training loss: 0.7194475531578064
Validation loss: 1.9774949922356555

Epoch: 6| Step: 2
Training loss: 1.5331190824508667
Validation loss: 1.9672014918378604

Epoch: 6| Step: 3
Training loss: 0.8842052221298218
Validation loss: 1.9711251463941348

Epoch: 6| Step: 4
Training loss: 1.0450310707092285
Validation loss: 1.9419554061787103

Epoch: 6| Step: 5
Training loss: 1.8022583723068237
Validation loss: 1.9683879319057669

Epoch: 6| Step: 6
Training loss: 1.0167592763900757
Validation loss: 1.9373409068712624

Epoch: 6| Step: 7
Training loss: 1.002334475517273
Validation loss: 1.94410200272837

Epoch: 6| Step: 8
Training loss: 1.2305153608322144
Validation loss: 1.8875230973766697

Epoch: 6| Step: 9
Training loss: 0.9004389643669128
Validation loss: 1.863771036107053

Epoch: 6| Step: 10
Training loss: 1.3331923484802246
Validation loss: 1.837334353436706

Epoch: 6| Step: 11
Training loss: 1.4424371719360352
Validation loss: 1.8416133670396702

Epoch: 6| Step: 12
Training loss: 1.5148100852966309
Validation loss: 1.8667515657281364

Epoch: 6| Step: 13
Training loss: 1.0719324350357056
Validation loss: 1.8998239732557727

Epoch: 206| Step: 0
Training loss: 1.7948660850524902
Validation loss: 1.9263492912374518

Epoch: 6| Step: 1
Training loss: 1.186110496520996
Validation loss: 1.9667890148778115

Epoch: 6| Step: 2
Training loss: 1.6254531145095825
Validation loss: 1.9884619892284434

Epoch: 6| Step: 3
Training loss: 0.5102766752243042
Validation loss: 1.9788236784678634

Epoch: 6| Step: 4
Training loss: 0.943678617477417
Validation loss: 1.9633796343239405

Epoch: 6| Step: 5
Training loss: 0.9740089774131775
Validation loss: 1.9733248961869108

Epoch: 6| Step: 6
Training loss: 1.538023829460144
Validation loss: 1.9355435653399395

Epoch: 6| Step: 7
Training loss: 1.4945321083068848
Validation loss: 1.926575820933106

Epoch: 6| Step: 8
Training loss: 1.0706901550292969
Validation loss: 1.9205974455802672

Epoch: 6| Step: 9
Training loss: 0.9255654811859131
Validation loss: 1.9216879234519055

Epoch: 6| Step: 10
Training loss: 1.1754214763641357
Validation loss: 1.8938685168502152

Epoch: 6| Step: 11
Training loss: 0.9200971722602844
Validation loss: 1.911999362771229

Epoch: 6| Step: 12
Training loss: 1.2335567474365234
Validation loss: 1.8849695241579445

Epoch: 6| Step: 13
Training loss: 1.094704508781433
Validation loss: 1.936485816073674

Epoch: 207| Step: 0
Training loss: 1.0607904195785522
Validation loss: 1.9168313600683724

Epoch: 6| Step: 1
Training loss: 0.9992474317550659
Validation loss: 1.9307196576108214

Epoch: 6| Step: 2
Training loss: 0.8348895311355591
Validation loss: 1.928973097955027

Epoch: 6| Step: 3
Training loss: 1.375
Validation loss: 1.9097876112948182

Epoch: 6| Step: 4
Training loss: 1.1255683898925781
Validation loss: 1.9258281851327548

Epoch: 6| Step: 5
Training loss: 1.4336330890655518
Validation loss: 1.9168982492980136

Epoch: 6| Step: 6
Training loss: 1.1502609252929688
Validation loss: 1.9026086240686395

Epoch: 6| Step: 7
Training loss: 1.4733785390853882
Validation loss: 1.9351640285984162

Epoch: 6| Step: 8
Training loss: 0.9344878792762756
Validation loss: 1.9343638676469044

Epoch: 6| Step: 9
Training loss: 1.2282525300979614
Validation loss: 1.9498259277753933

Epoch: 6| Step: 10
Training loss: 1.575424313545227
Validation loss: 1.9746257541000203

Epoch: 6| Step: 11
Training loss: 0.6962581276893616
Validation loss: 1.967807154501638

Epoch: 6| Step: 12
Training loss: 1.173210859298706
Validation loss: 1.9780395415521437

Epoch: 6| Step: 13
Training loss: 1.4637603759765625
Validation loss: 1.998899588020899

Epoch: 208| Step: 0
Training loss: 1.212249517440796
Validation loss: 2.0261133793861634

Epoch: 6| Step: 1
Training loss: 1.2526007890701294
Validation loss: 2.015577103502007

Epoch: 6| Step: 2
Training loss: 1.5279603004455566
Validation loss: 2.012364705403646

Epoch: 6| Step: 3
Training loss: 0.8393047451972961
Validation loss: 1.963930595305658

Epoch: 6| Step: 4
Training loss: 0.796220064163208
Validation loss: 1.9650455405635219

Epoch: 6| Step: 5
Training loss: 0.5799878835678101
Validation loss: 1.915350821710402

Epoch: 6| Step: 6
Training loss: 1.1481016874313354
Validation loss: 1.9046929023599113

Epoch: 6| Step: 7
Training loss: 1.4176459312438965
Validation loss: 1.8998270380881526

Epoch: 6| Step: 8
Training loss: 1.2202283143997192
Validation loss: 1.873200039709768

Epoch: 6| Step: 9
Training loss: 0.7091704607009888
Validation loss: 1.8865130909027592

Epoch: 6| Step: 10
Training loss: 1.4693620204925537
Validation loss: 1.918653493286461

Epoch: 6| Step: 11
Training loss: 1.3033881187438965
Validation loss: 1.9258083566542594

Epoch: 6| Step: 12
Training loss: 1.5366063117980957
Validation loss: 1.9392151294216033

Epoch: 6| Step: 13
Training loss: 1.352363109588623
Validation loss: 1.9424390895392305

Epoch: 209| Step: 0
Training loss: 1.0448663234710693
Validation loss: 1.901911126670017

Epoch: 6| Step: 1
Training loss: 0.735661506652832
Validation loss: 1.8717369494899627

Epoch: 6| Step: 2
Training loss: 1.0944790840148926
Validation loss: 1.8973147946019326

Epoch: 6| Step: 3
Training loss: 1.223442792892456
Validation loss: 1.8785367781116116

Epoch: 6| Step: 4
Training loss: 1.444908618927002
Validation loss: 1.888273201962953

Epoch: 6| Step: 5
Training loss: 0.9220229387283325
Validation loss: 1.89001973085506

Epoch: 6| Step: 6
Training loss: 0.6789222955703735
Validation loss: 1.9058954074818601

Epoch: 6| Step: 7
Training loss: 1.5475971698760986
Validation loss: 1.8986271196796047

Epoch: 6| Step: 8
Training loss: 1.7394684553146362
Validation loss: 1.9345049217183103

Epoch: 6| Step: 9
Training loss: 1.3014624118804932
Validation loss: 1.9640410369442356

Epoch: 6| Step: 10
Training loss: 1.2816435098648071
Validation loss: 1.9514531089413552

Epoch: 6| Step: 11
Training loss: 0.996343731880188
Validation loss: 1.9406901803067935

Epoch: 6| Step: 12
Training loss: 1.4595351219177246
Validation loss: 1.925636718350072

Epoch: 6| Step: 13
Training loss: 0.4305400848388672
Validation loss: 1.9040916658216906

Epoch: 210| Step: 0
Training loss: 1.2891125679016113
Validation loss: 1.9023151166977421

Epoch: 6| Step: 1
Training loss: 0.7960907816886902
Validation loss: 1.8836659116129721

Epoch: 6| Step: 2
Training loss: 1.829953670501709
Validation loss: 1.8722588785233036

Epoch: 6| Step: 3
Training loss: 0.9483487606048584
Validation loss: 1.8998776340997348

Epoch: 6| Step: 4
Training loss: 0.647502601146698
Validation loss: 1.8700659198145713

Epoch: 6| Step: 5
Training loss: 1.3367011547088623
Validation loss: 1.8710866615336428

Epoch: 6| Step: 6
Training loss: 1.0512926578521729
Validation loss: 1.8624351332264562

Epoch: 6| Step: 7
Training loss: 1.6121976375579834
Validation loss: 1.8929681598499257

Epoch: 6| Step: 8
Training loss: 0.8961114287376404
Validation loss: 1.8937201910121466

Epoch: 6| Step: 9
Training loss: 1.4851646423339844
Validation loss: 1.9019781568998932

Epoch: 6| Step: 10
Training loss: 0.6668987274169922
Validation loss: 1.9083332297622517

Epoch: 6| Step: 11
Training loss: 1.5211682319641113
Validation loss: 1.9020228398743497

Epoch: 6| Step: 12
Training loss: 0.6949714422225952
Validation loss: 1.9154922167460124

Epoch: 6| Step: 13
Training loss: 1.3604590892791748
Validation loss: 1.895932835917319

Epoch: 211| Step: 0
Training loss: 1.0973033905029297
Validation loss: 1.8813299594386932

Epoch: 6| Step: 1
Training loss: 1.3326990604400635
Validation loss: 1.8952307329382947

Epoch: 6| Step: 2
Training loss: 1.2039427757263184
Validation loss: 1.9199659298825007

Epoch: 6| Step: 3
Training loss: 1.6319139003753662
Validation loss: 1.9123537040525866

Epoch: 6| Step: 4
Training loss: 1.0478663444519043
Validation loss: 1.908461884785724

Epoch: 6| Step: 5
Training loss: 0.5493601560592651
Validation loss: 1.882088315102362

Epoch: 6| Step: 6
Training loss: 1.7370493412017822
Validation loss: 1.8964246139731458

Epoch: 6| Step: 7
Training loss: 1.2043201923370361
Validation loss: 1.8623511457955966

Epoch: 6| Step: 8
Training loss: 0.8278139233589172
Validation loss: 1.8403704217685166

Epoch: 6| Step: 9
Training loss: 0.9408214092254639
Validation loss: 1.868955450673257

Epoch: 6| Step: 10
Training loss: 1.1875784397125244
Validation loss: 1.8426820488386257

Epoch: 6| Step: 11
Training loss: 1.0282211303710938
Validation loss: 1.8440657751534575

Epoch: 6| Step: 12
Training loss: 1.0980536937713623
Validation loss: 1.8610334063089022

Epoch: 6| Step: 13
Training loss: 0.7485875487327576
Validation loss: 1.8941374594165432

Epoch: 212| Step: 0
Training loss: 1.0412160158157349
Validation loss: 1.8800366360654113

Epoch: 6| Step: 1
Training loss: 0.8329329490661621
Validation loss: 1.9033886335229362

Epoch: 6| Step: 2
Training loss: 1.2647414207458496
Validation loss: 1.9127492635480818

Epoch: 6| Step: 3
Training loss: 1.0918610095977783
Validation loss: 1.899267065909601

Epoch: 6| Step: 4
Training loss: 0.9802452325820923
Validation loss: 1.8957420882358347

Epoch: 6| Step: 5
Training loss: 0.8525894284248352
Validation loss: 1.8905922725636473

Epoch: 6| Step: 6
Training loss: 0.906133770942688
Validation loss: 1.8835780992302844

Epoch: 6| Step: 7
Training loss: 1.487542748451233
Validation loss: 1.870086157193748

Epoch: 6| Step: 8
Training loss: 1.316972017288208
Validation loss: 1.8408478588186286

Epoch: 6| Step: 9
Training loss: 1.1612799167633057
Validation loss: 1.8418233779168898

Epoch: 6| Step: 10
Training loss: 1.017999291419983
Validation loss: 1.8259990061483076

Epoch: 6| Step: 11
Training loss: 1.2316029071807861
Validation loss: 1.8324834415989537

Epoch: 6| Step: 12
Training loss: 1.4417064189910889
Validation loss: 1.8490349144063971

Epoch: 6| Step: 13
Training loss: 1.3347532749176025
Validation loss: 1.863096220518953

Epoch: 213| Step: 0
Training loss: 0.6934775710105896
Validation loss: 1.8712247546001146

Epoch: 6| Step: 1
Training loss: 1.1060208082199097
Validation loss: 1.8948495054757724

Epoch: 6| Step: 2
Training loss: 1.5654103755950928
Validation loss: 1.9048186527785433

Epoch: 6| Step: 3
Training loss: 0.8717383742332458
Validation loss: 1.8914043608532156

Epoch: 6| Step: 4
Training loss: 1.4213722944259644
Validation loss: 1.8863785113057783

Epoch: 6| Step: 5
Training loss: 1.127811312675476
Validation loss: 1.890892885064566

Epoch: 6| Step: 6
Training loss: 1.3292343616485596
Validation loss: 1.887248759628624

Epoch: 6| Step: 7
Training loss: 1.2196869850158691
Validation loss: 1.9117084972320064

Epoch: 6| Step: 8
Training loss: 1.3365479707717896
Validation loss: 1.9205922157533708

Epoch: 6| Step: 9
Training loss: 1.23373281955719
Validation loss: 1.9440163156037689

Epoch: 6| Step: 10
Training loss: 0.9077470898628235
Validation loss: 1.9728744593999719

Epoch: 6| Step: 11
Training loss: 1.1352849006652832
Validation loss: 1.9640349444522653

Epoch: 6| Step: 12
Training loss: 0.6907882690429688
Validation loss: 1.9691246850516206

Epoch: 6| Step: 13
Training loss: 1.202399730682373
Validation loss: 1.9339593123364192

Epoch: 214| Step: 0
Training loss: 1.3873553276062012
Validation loss: 1.9243205157659387

Epoch: 6| Step: 1
Training loss: 1.3002979755401611
Validation loss: 1.9155155022939045

Epoch: 6| Step: 2
Training loss: 0.7325624227523804
Validation loss: 1.9077593318877681

Epoch: 6| Step: 3
Training loss: 1.3486669063568115
Validation loss: 1.8913283758265997

Epoch: 6| Step: 4
Training loss: 1.3068469762802124
Validation loss: 1.8711143347524828

Epoch: 6| Step: 5
Training loss: 1.114737629890442
Validation loss: 1.8402022507882887

Epoch: 6| Step: 6
Training loss: 0.8491564989089966
Validation loss: 1.8586107402719476

Epoch: 6| Step: 7
Training loss: 1.255433201789856
Validation loss: 1.874928964081631

Epoch: 6| Step: 8
Training loss: 0.8862295746803284
Validation loss: 1.8653416031150407

Epoch: 6| Step: 9
Training loss: 1.413726806640625
Validation loss: 1.8492010549832416

Epoch: 6| Step: 10
Training loss: 0.789452075958252
Validation loss: 1.9011925715272144

Epoch: 6| Step: 11
Training loss: 0.9724568128585815
Validation loss: 1.9698035870828936

Epoch: 6| Step: 12
Training loss: 1.2310585975646973
Validation loss: 1.986756286313457

Epoch: 6| Step: 13
Training loss: 0.9358911514282227
Validation loss: 1.9953376093218405

Epoch: 215| Step: 0
Training loss: 0.7971378564834595
Validation loss: 1.9683375332945137

Epoch: 6| Step: 1
Training loss: 1.2710013389587402
Validation loss: 1.9407067234798143

Epoch: 6| Step: 2
Training loss: 1.2546734809875488
Validation loss: 1.9401711686964958

Epoch: 6| Step: 3
Training loss: 1.442692518234253
Validation loss: 1.9361648739025157

Epoch: 6| Step: 4
Training loss: 1.1897470951080322
Validation loss: 1.9286940136263448

Epoch: 6| Step: 5
Training loss: 0.6192888021469116
Validation loss: 1.8999305848152406

Epoch: 6| Step: 6
Training loss: 1.021891713142395
Validation loss: 1.8939466912259337

Epoch: 6| Step: 7
Training loss: 1.1507885456085205
Validation loss: 1.9054271328833796

Epoch: 6| Step: 8
Training loss: 0.7245852947235107
Validation loss: 1.931282768967331

Epoch: 6| Step: 9
Training loss: 0.9503408074378967
Validation loss: 1.9393650652259908

Epoch: 6| Step: 10
Training loss: 1.9462273120880127
Validation loss: 1.964328791505547

Epoch: 6| Step: 11
Training loss: 1.0853464603424072
Validation loss: 1.9470497126220374

Epoch: 6| Step: 12
Training loss: 0.9983649253845215
Validation loss: 1.9319029649098713

Epoch: 6| Step: 13
Training loss: 1.2208555936813354
Validation loss: 1.936153801538611

Epoch: 216| Step: 0
Training loss: 1.682992696762085
Validation loss: 1.9159783778652069

Epoch: 6| Step: 1
Training loss: 1.1808006763458252
Validation loss: 1.9072494147926249

Epoch: 6| Step: 2
Training loss: 1.206099510192871
Validation loss: 1.9150150424690657

Epoch: 6| Step: 3
Training loss: 0.8555222749710083
Validation loss: 1.8609544936046805

Epoch: 6| Step: 4
Training loss: 1.5006506443023682
Validation loss: 1.8694113198147024

Epoch: 6| Step: 5
Training loss: 1.0059893131256104
Validation loss: 1.9254649416092904

Epoch: 6| Step: 6
Training loss: 0.6964004635810852
Validation loss: 1.9285344205876833

Epoch: 6| Step: 7
Training loss: 0.8694431781768799
Validation loss: 1.945208752027122

Epoch: 6| Step: 8
Training loss: 1.3303395509719849
Validation loss: 1.9167336827965193

Epoch: 6| Step: 9
Training loss: 1.0787417888641357
Validation loss: 1.9325343857529342

Epoch: 6| Step: 10
Training loss: 1.0425760746002197
Validation loss: 1.9322050771405619

Epoch: 6| Step: 11
Training loss: 1.1292163133621216
Validation loss: 1.93951065053222

Epoch: 6| Step: 12
Training loss: 0.9814786911010742
Validation loss: 1.966998428426763

Epoch: 6| Step: 13
Training loss: 1.0341311693191528
Validation loss: 1.9508262308694984

Epoch: 217| Step: 0
Training loss: 1.141361951828003
Validation loss: 1.9631047992296116

Epoch: 6| Step: 1
Training loss: 0.5920401811599731
Validation loss: 1.9069757435911445

Epoch: 6| Step: 2
Training loss: 0.6137118339538574
Validation loss: 1.8523776813219952

Epoch: 6| Step: 3
Training loss: 1.5856130123138428
Validation loss: 1.8769487193835679

Epoch: 6| Step: 4
Training loss: 0.6973681449890137
Validation loss: 1.873158888150287

Epoch: 6| Step: 5
Training loss: 1.1442761421203613
Validation loss: 1.8711338273940548

Epoch: 6| Step: 6
Training loss: 1.0922702550888062
Validation loss: 1.900573709959625

Epoch: 6| Step: 7
Training loss: 1.3441256284713745
Validation loss: 1.931444634673416

Epoch: 6| Step: 8
Training loss: 1.1559849977493286
Validation loss: 1.9180016748366817

Epoch: 6| Step: 9
Training loss: 1.4169026613235474
Validation loss: 1.9760281475641395

Epoch: 6| Step: 10
Training loss: 0.8006397485733032
Validation loss: 2.0085879269466607

Epoch: 6| Step: 11
Training loss: 1.0389539003372192
Validation loss: 1.980137094374626

Epoch: 6| Step: 12
Training loss: 1.5227015018463135
Validation loss: 2.0184347527001494

Epoch: 6| Step: 13
Training loss: 1.6955846548080444
Validation loss: 2.0360520475654194

Epoch: 218| Step: 0
Training loss: 0.960309624671936
Validation loss: 1.9817040274220128

Epoch: 6| Step: 1
Training loss: 1.0788428783416748
Validation loss: 1.9653138614469958

Epoch: 6| Step: 2
Training loss: 0.7517565488815308
Validation loss: 1.8994612578422791

Epoch: 6| Step: 3
Training loss: 1.2085485458374023
Validation loss: 1.8572926880210958

Epoch: 6| Step: 4
Training loss: 1.214309811592102
Validation loss: 1.8656669932027017

Epoch: 6| Step: 5
Training loss: 1.395551323890686
Validation loss: 1.8591428725950179

Epoch: 6| Step: 6
Training loss: 1.2119210958480835
Validation loss: 1.854910409578713

Epoch: 6| Step: 7
Training loss: 1.2360453605651855
Validation loss: 1.8634187406109226

Epoch: 6| Step: 8
Training loss: 0.9724379181861877
Validation loss: 1.8581126018237042

Epoch: 6| Step: 9
Training loss: 1.1682372093200684
Validation loss: 1.8484654541938537

Epoch: 6| Step: 10
Training loss: 1.1948808431625366
Validation loss: 1.8435091831350838

Epoch: 6| Step: 11
Training loss: 1.288535475730896
Validation loss: 1.8731211141873432

Epoch: 6| Step: 12
Training loss: 1.038236141204834
Validation loss: 1.8746467290386077

Epoch: 6| Step: 13
Training loss: 1.0519808530807495
Validation loss: 1.8436292397078646

Epoch: 219| Step: 0
Training loss: 1.0809102058410645
Validation loss: 1.8408796300170243

Epoch: 6| Step: 1
Training loss: 0.8233877420425415
Validation loss: 1.8602858986905826

Epoch: 6| Step: 2
Training loss: 0.8650984764099121
Validation loss: 1.8447132328505158

Epoch: 6| Step: 3
Training loss: 1.0607411861419678
Validation loss: 1.8484835137603104

Epoch: 6| Step: 4
Training loss: 1.243404507637024
Validation loss: 1.8526752174541514

Epoch: 6| Step: 5
Training loss: 1.1420960426330566
Validation loss: 1.8085392021363782

Epoch: 6| Step: 6
Training loss: 0.5897776484489441
Validation loss: 1.8316480831433368

Epoch: 6| Step: 7
Training loss: 1.0736777782440186
Validation loss: 1.8319652516354796

Epoch: 6| Step: 8
Training loss: 1.2641304731369019
Validation loss: 1.829917420623123

Epoch: 6| Step: 9
Training loss: 1.299862027168274
Validation loss: 1.8276849562121975

Epoch: 6| Step: 10
Training loss: 0.9858952164649963
Validation loss: 1.8322955959586686

Epoch: 6| Step: 11
Training loss: 0.9117900729179382
Validation loss: 1.8641118144476285

Epoch: 6| Step: 12
Training loss: 0.9716813564300537
Validation loss: 1.8323692813996346

Epoch: 6| Step: 13
Training loss: 1.2878687381744385
Validation loss: 1.8542341339972712

Epoch: 220| Step: 0
Training loss: 1.262455940246582
Validation loss: 1.8753684131048058

Epoch: 6| Step: 1
Training loss: 1.2624777555465698
Validation loss: 1.9086091390220068

Epoch: 6| Step: 2
Training loss: 0.9632399678230286
Validation loss: 1.9194305660904094

Epoch: 6| Step: 3
Training loss: 0.9066867828369141
Validation loss: 1.8841368934159637

Epoch: 6| Step: 4
Training loss: 1.0013500452041626
Validation loss: 1.8826728584945842

Epoch: 6| Step: 5
Training loss: 1.1395243406295776
Validation loss: 1.8574569584220968

Epoch: 6| Step: 6
Training loss: 0.5765573978424072
Validation loss: 1.82378440390351

Epoch: 6| Step: 7
Training loss: 1.3650057315826416
Validation loss: 1.8443949145655478

Epoch: 6| Step: 8
Training loss: 1.048916220664978
Validation loss: 1.847142078543222

Epoch: 6| Step: 9
Training loss: 1.1868996620178223
Validation loss: 1.8576967805944464

Epoch: 6| Step: 10
Training loss: 1.1181254386901855
Validation loss: 1.8667605051430323

Epoch: 6| Step: 11
Training loss: 0.7381263971328735
Validation loss: 1.8581110277483541

Epoch: 6| Step: 12
Training loss: 0.8897429704666138
Validation loss: 1.8934452533721924

Epoch: 6| Step: 13
Training loss: 1.1527049541473389
Validation loss: 1.900959781421128

Epoch: 221| Step: 0
Training loss: 1.0367649793624878
Validation loss: 1.8944610306011733

Epoch: 6| Step: 1
Training loss: 1.1379531621932983
Validation loss: 1.8595473138234948

Epoch: 6| Step: 2
Training loss: 0.7900710105895996
Validation loss: 1.8724259432925974

Epoch: 6| Step: 3
Training loss: 1.3153018951416016
Validation loss: 1.8451531625563098

Epoch: 6| Step: 4
Training loss: 0.9948469996452332
Validation loss: 1.8214245047620548

Epoch: 6| Step: 5
Training loss: 0.6411565542221069
Validation loss: 1.8183098480265627

Epoch: 6| Step: 6
Training loss: 0.9483128190040588
Validation loss: 1.8291772578352241

Epoch: 6| Step: 7
Training loss: 1.1945216655731201
Validation loss: 1.8095527207979591

Epoch: 6| Step: 8
Training loss: 1.3266077041625977
Validation loss: 1.827648651215338

Epoch: 6| Step: 9
Training loss: 1.1239336729049683
Validation loss: 1.8211037753730692

Epoch: 6| Step: 10
Training loss: 0.8028193712234497
Validation loss: 1.8554350945257372

Epoch: 6| Step: 11
Training loss: 1.072063684463501
Validation loss: 1.870629769499584

Epoch: 6| Step: 12
Training loss: 0.7951258420944214
Validation loss: 1.860219483734459

Epoch: 6| Step: 13
Training loss: 1.3179545402526855
Validation loss: 1.8874942538558797

Epoch: 222| Step: 0
Training loss: 1.2412877082824707
Validation loss: 1.8936033556538243

Epoch: 6| Step: 1
Training loss: 1.2262712717056274
Validation loss: 1.8916942624635593

Epoch: 6| Step: 2
Training loss: 0.5881421566009521
Validation loss: 1.8659026456135575

Epoch: 6| Step: 3
Training loss: 0.8432804346084595
Validation loss: 1.8758816539600331

Epoch: 6| Step: 4
Training loss: 1.192094326019287
Validation loss: 1.8573178193902458

Epoch: 6| Step: 5
Training loss: 0.7697080373764038
Validation loss: 1.8766166625484344

Epoch: 6| Step: 6
Training loss: 0.9496150612831116
Validation loss: 1.8760301759166103

Epoch: 6| Step: 7
Training loss: 1.1454696655273438
Validation loss: 1.842731778339673

Epoch: 6| Step: 8
Training loss: 1.4984190464019775
Validation loss: 1.8268353413510066

Epoch: 6| Step: 9
Training loss: 0.8683223724365234
Validation loss: 1.8194309562765143

Epoch: 6| Step: 10
Training loss: 1.0596235990524292
Validation loss: 1.7768671486967353

Epoch: 6| Step: 11
Training loss: 0.8711995482444763
Validation loss: 1.7982111304037032

Epoch: 6| Step: 12
Training loss: 0.6968832015991211
Validation loss: 1.7618011787373533

Epoch: 6| Step: 13
Training loss: 1.487633466720581
Validation loss: 1.7972302718829083

Epoch: 223| Step: 0
Training loss: 1.0853829383850098
Validation loss: 1.7886579062349053

Epoch: 6| Step: 1
Training loss: 0.8897214531898499
Validation loss: 1.7931016055486535

Epoch: 6| Step: 2
Training loss: 0.8544088006019592
Validation loss: 1.7808915517663444

Epoch: 6| Step: 3
Training loss: 1.2238918542861938
Validation loss: 1.8093398873524

Epoch: 6| Step: 4
Training loss: 0.9029593467712402
Validation loss: 1.7866029598379647

Epoch: 6| Step: 5
Training loss: 0.9938698410987854
Validation loss: 1.8075269973406227

Epoch: 6| Step: 6
Training loss: 0.6937882900238037
Validation loss: 1.790638751881097

Epoch: 6| Step: 7
Training loss: 1.0083260536193848
Validation loss: 1.8220910295363395

Epoch: 6| Step: 8
Training loss: 1.070590853691101
Validation loss: 1.8368498330475183

Epoch: 6| Step: 9
Training loss: 1.4232206344604492
Validation loss: 1.7988806219511135

Epoch: 6| Step: 10
Training loss: 1.1824402809143066
Validation loss: 1.8395511181123796

Epoch: 6| Step: 11
Training loss: 0.9005864858627319
Validation loss: 1.83788291997807

Epoch: 6| Step: 12
Training loss: 0.9105916619300842
Validation loss: 1.8412755458585677

Epoch: 6| Step: 13
Training loss: 1.0933384895324707
Validation loss: 1.8514860496726087

Epoch: 224| Step: 0
Training loss: 0.6419718265533447
Validation loss: 1.8492951085490565

Epoch: 6| Step: 1
Training loss: 0.9729505181312561
Validation loss: 1.8673724999991796

Epoch: 6| Step: 2
Training loss: 1.030961513519287
Validation loss: 1.8661083905927596

Epoch: 6| Step: 3
Training loss: 0.5328785181045532
Validation loss: 1.8679530838484406

Epoch: 6| Step: 4
Training loss: 0.9989757537841797
Validation loss: 1.846612068914598

Epoch: 6| Step: 5
Training loss: 1.1658697128295898
Validation loss: 1.808763337391679

Epoch: 6| Step: 6
Training loss: 1.0506641864776611
Validation loss: 1.8181132424262263

Epoch: 6| Step: 7
Training loss: 1.1948859691619873
Validation loss: 1.7926700551022765

Epoch: 6| Step: 8
Training loss: 1.0744116306304932
Validation loss: 1.7948218776333718

Epoch: 6| Step: 9
Training loss: 0.946934700012207
Validation loss: 1.7866953739555933

Epoch: 6| Step: 10
Training loss: 0.8014636039733887
Validation loss: 1.7845856105127642

Epoch: 6| Step: 11
Training loss: 0.9558740258216858
Validation loss: 1.7949557483837169

Epoch: 6| Step: 12
Training loss: 1.4521145820617676
Validation loss: 1.8164849153129004

Epoch: 6| Step: 13
Training loss: 0.6643519997596741
Validation loss: 1.8373226939990956

Epoch: 225| Step: 0
Training loss: 1.0672178268432617
Validation loss: 1.8475214742845105

Epoch: 6| Step: 1
Training loss: 0.6927216053009033
Validation loss: 1.8941064675649006

Epoch: 6| Step: 2
Training loss: 1.5617082118988037
Validation loss: 1.8951746494539323

Epoch: 6| Step: 3
Training loss: 0.7605606317520142
Validation loss: 1.894932649468863

Epoch: 6| Step: 4
Training loss: 1.1006256341934204
Validation loss: 1.9479466638257426

Epoch: 6| Step: 5
Training loss: 0.7901474237442017
Validation loss: 1.8942790185251543

Epoch: 6| Step: 6
Training loss: 0.6989073753356934
Validation loss: 1.8977142303220687

Epoch: 6| Step: 7
Training loss: 1.1578140258789062
Validation loss: 1.885379429786436

Epoch: 6| Step: 8
Training loss: 0.6690251231193542
Validation loss: 1.8333766498873312

Epoch: 6| Step: 9
Training loss: 1.0880059003829956
Validation loss: 1.8220950582975983

Epoch: 6| Step: 10
Training loss: 0.9959266185760498
Validation loss: 1.812987385257598

Epoch: 6| Step: 11
Training loss: 1.1339213848114014
Validation loss: 1.8230375141225836

Epoch: 6| Step: 12
Training loss: 0.9127885103225708
Validation loss: 1.8304089038602767

Epoch: 6| Step: 13
Training loss: 0.869234025478363
Validation loss: 1.8125945214302308

Epoch: 226| Step: 0
Training loss: 0.8849819302558899
Validation loss: 1.8013833735578804

Epoch: 6| Step: 1
Training loss: 1.0506978034973145
Validation loss: 1.81270416321293

Epoch: 6| Step: 2
Training loss: 1.0185246467590332
Validation loss: 1.8115911791401524

Epoch: 6| Step: 3
Training loss: 1.2293317317962646
Validation loss: 1.811381470772528

Epoch: 6| Step: 4
Training loss: 1.0144636631011963
Validation loss: 1.8557068442785611

Epoch: 6| Step: 5
Training loss: 0.7653819918632507
Validation loss: 1.8410517143946823

Epoch: 6| Step: 6
Training loss: 0.6489715576171875
Validation loss: 1.8777843752214987

Epoch: 6| Step: 7
Training loss: 0.8603163957595825
Validation loss: 1.8577871476450274

Epoch: 6| Step: 8
Training loss: 1.15321683883667
Validation loss: 1.8904235786007297

Epoch: 6| Step: 9
Training loss: 0.8348677158355713
Validation loss: 1.9006040698738509

Epoch: 6| Step: 10
Training loss: 0.9837056398391724
Validation loss: 1.900687192075996

Epoch: 6| Step: 11
Training loss: 0.848076343536377
Validation loss: 1.8972072742318595

Epoch: 6| Step: 12
Training loss: 1.1206943988800049
Validation loss: 1.8921519351261917

Epoch: 6| Step: 13
Training loss: 1.2624002695083618
Validation loss: 1.8590104503016318

Epoch: 227| Step: 0
Training loss: 0.8488879799842834
Validation loss: 1.8501007403096845

Epoch: 6| Step: 1
Training loss: 0.8416474461555481
Validation loss: 1.844979904031241

Epoch: 6| Step: 2
Training loss: 0.9377367496490479
Validation loss: 1.841226626467961

Epoch: 6| Step: 3
Training loss: 0.9032339453697205
Validation loss: 1.836577788476021

Epoch: 6| Step: 4
Training loss: 0.9681954979896545
Validation loss: 1.858891079502721

Epoch: 6| Step: 5
Training loss: 1.147190809249878
Validation loss: 1.8800073631348149

Epoch: 6| Step: 6
Training loss: 1.02833890914917
Validation loss: 1.8998627585749472

Epoch: 6| Step: 7
Training loss: 1.2683738470077515
Validation loss: 1.8835771276104836

Epoch: 6| Step: 8
Training loss: 0.9062150120735168
Validation loss: 1.9164362287008634

Epoch: 6| Step: 9
Training loss: 0.7045934796333313
Validation loss: 1.8698928638171124

Epoch: 6| Step: 10
Training loss: 0.8983865976333618
Validation loss: 1.875454302757017

Epoch: 6| Step: 11
Training loss: 0.7367011904716492
Validation loss: 1.8876776669615059

Epoch: 6| Step: 12
Training loss: 1.1185163259506226
Validation loss: 1.8892495042534285

Epoch: 6| Step: 13
Training loss: 1.4590857028961182
Validation loss: 1.9268618014550978

Epoch: 228| Step: 0
Training loss: 0.8368966579437256
Validation loss: 1.9491420997086393

Epoch: 6| Step: 1
Training loss: 0.9265106916427612
Validation loss: 1.9342011469666676

Epoch: 6| Step: 2
Training loss: 0.9687397480010986
Validation loss: 1.9271833230090398

Epoch: 6| Step: 3
Training loss: 0.8325274586677551
Validation loss: 1.9371428105138964

Epoch: 6| Step: 4
Training loss: 0.9962846636772156
Validation loss: 1.9235132099479757

Epoch: 6| Step: 5
Training loss: 1.1060092449188232
Validation loss: 1.9105556113745576

Epoch: 6| Step: 6
Training loss: 1.0540165901184082
Validation loss: 1.8781892227870163

Epoch: 6| Step: 7
Training loss: 0.8233022689819336
Validation loss: 1.863981262330086

Epoch: 6| Step: 8
Training loss: 1.1454615592956543
Validation loss: 1.8376028307022587

Epoch: 6| Step: 9
Training loss: 1.1512939929962158
Validation loss: 1.859215174951861

Epoch: 6| Step: 10
Training loss: 0.7466857433319092
Validation loss: 1.8117346814883653

Epoch: 6| Step: 11
Training loss: 0.9674320816993713
Validation loss: 1.8105582473098591

Epoch: 6| Step: 12
Training loss: 0.9176821708679199
Validation loss: 1.7831219691102222

Epoch: 6| Step: 13
Training loss: 1.1424691677093506
Validation loss: 1.8073033389224802

Epoch: 229| Step: 0
Training loss: 1.027543544769287
Validation loss: 1.8069657843600038

Epoch: 6| Step: 1
Training loss: 0.7924562096595764
Validation loss: 1.8128017123027513

Epoch: 6| Step: 2
Training loss: 0.9207563400268555
Validation loss: 1.8465446913114159

Epoch: 6| Step: 3
Training loss: 0.8755460977554321
Validation loss: 1.8562708798275198

Epoch: 6| Step: 4
Training loss: 1.147453784942627
Validation loss: 1.8574908523149387

Epoch: 6| Step: 5
Training loss: 1.3633612394332886
Validation loss: 1.8657654639213317

Epoch: 6| Step: 6
Training loss: 1.0103009939193726
Validation loss: 1.9049128511900544

Epoch: 6| Step: 7
Training loss: 1.1012449264526367
Validation loss: 1.930347381099578

Epoch: 6| Step: 8
Training loss: 1.4374699592590332
Validation loss: 1.9283240636189778

Epoch: 6| Step: 9
Training loss: 0.8280501961708069
Validation loss: 1.9140605170239684

Epoch: 6| Step: 10
Training loss: 1.4199283123016357
Validation loss: 1.885961909447947

Epoch: 6| Step: 11
Training loss: 0.5242355465888977
Validation loss: 1.813819585307952

Epoch: 6| Step: 12
Training loss: 0.5789117813110352
Validation loss: 1.7920159909033007

Epoch: 6| Step: 13
Training loss: 0.8641972541809082
Validation loss: 1.827029940902546

Epoch: 230| Step: 0
Training loss: 1.2452722787857056
Validation loss: 1.8181461736720095

Epoch: 6| Step: 1
Training loss: 1.1175792217254639
Validation loss: 1.8050487900293002

Epoch: 6| Step: 2
Training loss: 1.0753870010375977
Validation loss: 1.7796451917258642

Epoch: 6| Step: 3
Training loss: 1.1019281148910522
Validation loss: 1.7962373559192946

Epoch: 6| Step: 4
Training loss: 0.7581406831741333
Validation loss: 1.7994946766925115

Epoch: 6| Step: 5
Training loss: 0.8887658715248108
Validation loss: 1.8789795778130973

Epoch: 6| Step: 6
Training loss: 1.3008958101272583
Validation loss: 1.904978939281997

Epoch: 6| Step: 7
Training loss: 1.0045632123947144
Validation loss: 1.908185080815387

Epoch: 6| Step: 8
Training loss: 1.388911247253418
Validation loss: 1.893365160111458

Epoch: 6| Step: 9
Training loss: 0.9119176864624023
Validation loss: 1.8586514098669893

Epoch: 6| Step: 10
Training loss: 0.9942874312400818
Validation loss: 1.886349694703215

Epoch: 6| Step: 11
Training loss: 0.6699303388595581
Validation loss: 1.8512794894556845

Epoch: 6| Step: 12
Training loss: 0.891507625579834
Validation loss: 1.8778856415902414

Epoch: 6| Step: 13
Training loss: 1.024208664894104
Validation loss: 1.8683569328759306

Epoch: 231| Step: 0
Training loss: 1.2719755172729492
Validation loss: 1.8386062870743454

Epoch: 6| Step: 1
Training loss: 1.3302984237670898
Validation loss: 1.8248417300562705

Epoch: 6| Step: 2
Training loss: 0.8644026517868042
Validation loss: 1.7950042806645876

Epoch: 6| Step: 3
Training loss: 1.2440727949142456
Validation loss: 1.7771082155166134

Epoch: 6| Step: 4
Training loss: 0.8876675367355347
Validation loss: 1.795404420104078

Epoch: 6| Step: 5
Training loss: 1.1934959888458252
Validation loss: 1.8100351531018493

Epoch: 6| Step: 6
Training loss: 0.6625874042510986
Validation loss: 1.8024489110515964

Epoch: 6| Step: 7
Training loss: 0.7164006233215332
Validation loss: 1.8038058139944588

Epoch: 6| Step: 8
Training loss: 0.7482427358627319
Validation loss: 1.7777720958955827

Epoch: 6| Step: 9
Training loss: 0.5854687094688416
Validation loss: 1.783639338708693

Epoch: 6| Step: 10
Training loss: 0.5902038812637329
Validation loss: 1.7943367970887052

Epoch: 6| Step: 11
Training loss: 1.0271574258804321
Validation loss: 1.8456355833238172

Epoch: 6| Step: 12
Training loss: 1.3667640686035156
Validation loss: 1.8202916165833831

Epoch: 6| Step: 13
Training loss: 0.8204030394554138
Validation loss: 1.8439516239268805

Epoch: 232| Step: 0
Training loss: 0.9614965319633484
Validation loss: 1.8759901613317511

Epoch: 6| Step: 1
Training loss: 0.965195894241333
Validation loss: 1.9225857809025755

Epoch: 6| Step: 2
Training loss: 1.2209134101867676
Validation loss: 1.9034505813352522

Epoch: 6| Step: 3
Training loss: 0.8142205476760864
Validation loss: 1.9086180194731681

Epoch: 6| Step: 4
Training loss: 0.7984257340431213
Validation loss: 1.9003944217517812

Epoch: 6| Step: 5
Training loss: 0.9927928447723389
Validation loss: 1.9069129831047469

Epoch: 6| Step: 6
Training loss: 1.34104585647583
Validation loss: 1.9156177813006985

Epoch: 6| Step: 7
Training loss: 0.7536405324935913
Validation loss: 1.8924555413184627

Epoch: 6| Step: 8
Training loss: 1.0246870517730713
Validation loss: 1.8848441364944621

Epoch: 6| Step: 9
Training loss: 0.6379368305206299
Validation loss: 1.8729159729455107

Epoch: 6| Step: 10
Training loss: 1.0437744855880737
Validation loss: 1.8352780278011034

Epoch: 6| Step: 11
Training loss: 0.8321832418441772
Validation loss: 1.814392416707931

Epoch: 6| Step: 12
Training loss: 0.779494047164917
Validation loss: 1.8135791491436701

Epoch: 6| Step: 13
Training loss: 0.7890913486480713
Validation loss: 1.7861051892721524

Epoch: 233| Step: 0
Training loss: 1.035592794418335
Validation loss: 1.790835326717746

Epoch: 6| Step: 1
Training loss: 0.9606825113296509
Validation loss: 1.7854462669741722

Epoch: 6| Step: 2
Training loss: 1.093491792678833
Validation loss: 1.7933508048775375

Epoch: 6| Step: 3
Training loss: 0.34106796979904175
Validation loss: 1.7885421450420091

Epoch: 6| Step: 4
Training loss: 1.5049413442611694
Validation loss: 1.8031367922341952

Epoch: 6| Step: 5
Training loss: 0.9708794355392456
Validation loss: 1.8089504024033904

Epoch: 6| Step: 6
Training loss: 0.8048503398895264
Validation loss: 1.8162203117083477

Epoch: 6| Step: 7
Training loss: 1.080223798751831
Validation loss: 1.8040957720048967

Epoch: 6| Step: 8
Training loss: 1.013285517692566
Validation loss: 1.8497454530449324

Epoch: 6| Step: 9
Training loss: 0.7443244457244873
Validation loss: 1.834060017780591

Epoch: 6| Step: 10
Training loss: 0.4029889404773712
Validation loss: 1.8441792482970862

Epoch: 6| Step: 11
Training loss: 1.0276212692260742
Validation loss: 1.8426717083941224

Epoch: 6| Step: 12
Training loss: 0.7670159339904785
Validation loss: 1.845473958599952

Epoch: 6| Step: 13
Training loss: 0.9840973615646362
Validation loss: 1.8442412217458088

Epoch: 234| Step: 0
Training loss: 0.8538427948951721
Validation loss: 1.8106023650015555

Epoch: 6| Step: 1
Training loss: 0.9732085466384888
Validation loss: 1.8090356857545915

Epoch: 6| Step: 2
Training loss: 1.2771748304367065
Validation loss: 1.7955938090560257

Epoch: 6| Step: 3
Training loss: 1.1318848133087158
Validation loss: 1.7604235564508746

Epoch: 6| Step: 4
Training loss: 0.9730318784713745
Validation loss: 1.7725399130134172

Epoch: 6| Step: 5
Training loss: 0.6482566595077515
Validation loss: 1.7498691299910187

Epoch: 6| Step: 6
Training loss: 1.4342010021209717
Validation loss: 1.7684646575681624

Epoch: 6| Step: 7
Training loss: 0.9985541105270386
Validation loss: 1.759218660734033

Epoch: 6| Step: 8
Training loss: 0.80815589427948
Validation loss: 1.7727623678022815

Epoch: 6| Step: 9
Training loss: 0.6299217939376831
Validation loss: 1.793024686075026

Epoch: 6| Step: 10
Training loss: 0.9497178792953491
Validation loss: 1.7959832478595037

Epoch: 6| Step: 11
Training loss: 0.5039202570915222
Validation loss: 1.823568368470797

Epoch: 6| Step: 12
Training loss: 0.6080919504165649
Validation loss: 1.7981302840735323

Epoch: 6| Step: 13
Training loss: 0.6379222273826599
Validation loss: 1.826241567570676

Epoch: 235| Step: 0
Training loss: 0.8523688912391663
Validation loss: 1.8143291011933358

Epoch: 6| Step: 1
Training loss: 0.8181124925613403
Validation loss: 1.875060937737906

Epoch: 6| Step: 2
Training loss: 0.7877234220504761
Validation loss: 1.873914207822533

Epoch: 6| Step: 3
Training loss: 0.8145115971565247
Validation loss: 1.862917629621362

Epoch: 6| Step: 4
Training loss: 1.232709288597107
Validation loss: 1.8672612354319582

Epoch: 6| Step: 5
Training loss: 1.1777000427246094
Validation loss: 1.875829363381991

Epoch: 6| Step: 6
Training loss: 0.6678051948547363
Validation loss: 1.8722958231485018

Epoch: 6| Step: 7
Training loss: 1.1369433403015137
Validation loss: 1.8492713833367953

Epoch: 6| Step: 8
Training loss: 0.9542986750602722
Validation loss: 1.835530073412003

Epoch: 6| Step: 9
Training loss: 1.1977159976959229
Validation loss: 1.810212569852029

Epoch: 6| Step: 10
Training loss: 0.8460700511932373
Validation loss: 1.7925345538764872

Epoch: 6| Step: 11
Training loss: 1.0856451988220215
Validation loss: 1.814204821022608

Epoch: 6| Step: 12
Training loss: 0.6327710151672363
Validation loss: 1.817019220321409

Epoch: 6| Step: 13
Training loss: 0.5570489764213562
Validation loss: 1.8515010931158578

Epoch: 236| Step: 0
Training loss: 0.963288426399231
Validation loss: 1.8741944195121847

Epoch: 6| Step: 1
Training loss: 1.3356205224990845
Validation loss: 1.8556443209289222

Epoch: 6| Step: 2
Training loss: 0.6852449774742126
Validation loss: 1.8783713309995589

Epoch: 6| Step: 3
Training loss: 0.9263696074485779
Validation loss: 1.8791154981941305

Epoch: 6| Step: 4
Training loss: 0.8189560174942017
Validation loss: 1.8998208943233694

Epoch: 6| Step: 5
Training loss: 0.8298430442810059
Validation loss: 1.8852509157631987

Epoch: 6| Step: 6
Training loss: 0.8632081747055054
Validation loss: 1.9036733194064068

Epoch: 6| Step: 7
Training loss: 1.1743271350860596
Validation loss: 1.878323402456058

Epoch: 6| Step: 8
Training loss: 0.9193414449691772
Validation loss: 1.8666086171263008

Epoch: 6| Step: 9
Training loss: 0.5531302094459534
Validation loss: 1.8986245893662976

Epoch: 6| Step: 10
Training loss: 0.8424928188323975
Validation loss: 1.8639782551796205

Epoch: 6| Step: 11
Training loss: 0.8197037577629089
Validation loss: 1.8813565828466927

Epoch: 6| Step: 12
Training loss: 1.2175660133361816
Validation loss: 1.849225753097124

Epoch: 6| Step: 13
Training loss: 0.7720921039581299
Validation loss: 1.8296979729847243

Epoch: 237| Step: 0
Training loss: 0.6873530745506287
Validation loss: 1.7942276000976562

Epoch: 6| Step: 1
Training loss: 0.7956955432891846
Validation loss: 1.8375510784887499

Epoch: 6| Step: 2
Training loss: 0.8488942980766296
Validation loss: 1.798995864006781

Epoch: 6| Step: 3
Training loss: 1.0068691968917847
Validation loss: 1.8231436257721276

Epoch: 6| Step: 4
Training loss: 0.640419602394104
Validation loss: 1.8344265530186314

Epoch: 6| Step: 5
Training loss: 0.7115483283996582
Validation loss: 1.8199049375390495

Epoch: 6| Step: 6
Training loss: 0.9045671820640564
Validation loss: 1.8540933337262882

Epoch: 6| Step: 7
Training loss: 1.293277621269226
Validation loss: 1.8706195867189797

Epoch: 6| Step: 8
Training loss: 0.7613829374313354
Validation loss: 1.8406549038425568

Epoch: 6| Step: 9
Training loss: 1.0972379446029663
Validation loss: 1.8837390650985062

Epoch: 6| Step: 10
Training loss: 0.9365668296813965
Validation loss: 1.8884817169558616

Epoch: 6| Step: 11
Training loss: 1.0616170167922974
Validation loss: 1.9027650894657258

Epoch: 6| Step: 12
Training loss: 1.0543431043624878
Validation loss: 1.8816691598584574

Epoch: 6| Step: 13
Training loss: 0.7453381419181824
Validation loss: 1.868864728558448

Epoch: 238| Step: 0
Training loss: 1.2345151901245117
Validation loss: 1.8236506844079623

Epoch: 6| Step: 1
Training loss: 1.0781452655792236
Validation loss: 1.792447172185426

Epoch: 6| Step: 2
Training loss: 0.663872241973877
Validation loss: 1.8103387881350774

Epoch: 6| Step: 3
Training loss: 0.7228920459747314
Validation loss: 1.8488314972128919

Epoch: 6| Step: 4
Training loss: 0.8829228281974792
Validation loss: 1.8659832887752081

Epoch: 6| Step: 5
Training loss: 0.960590124130249
Validation loss: 1.8614788721966486

Epoch: 6| Step: 6
Training loss: 1.044288158416748
Validation loss: 1.8453199965979463

Epoch: 6| Step: 7
Training loss: 0.7418999671936035
Validation loss: 1.8557572134079472

Epoch: 6| Step: 8
Training loss: 0.6140835285186768
Validation loss: 1.840901001807182

Epoch: 6| Step: 9
Training loss: 0.7157454490661621
Validation loss: 1.8541190521691435

Epoch: 6| Step: 10
Training loss: 0.9678352475166321
Validation loss: 1.8716287241187146

Epoch: 6| Step: 11
Training loss: 1.1388206481933594
Validation loss: 1.8823633347788165

Epoch: 6| Step: 12
Training loss: 0.8195436596870422
Validation loss: 1.869657926661994

Epoch: 6| Step: 13
Training loss: 1.1389778852462769
Validation loss: 1.8656379356179187

Epoch: 239| Step: 0
Training loss: 0.8520448803901672
Validation loss: 1.852648497909628

Epoch: 6| Step: 1
Training loss: 1.0046303272247314
Validation loss: 1.8803743188099196

Epoch: 6| Step: 2
Training loss: 1.0668394565582275
Validation loss: 1.8758214084050988

Epoch: 6| Step: 3
Training loss: 0.6972708702087402
Validation loss: 1.852565356480178

Epoch: 6| Step: 4
Training loss: 0.6612878441810608
Validation loss: 1.8371760845184326

Epoch: 6| Step: 5
Training loss: 0.8204715251922607
Validation loss: 1.8123791384440597

Epoch: 6| Step: 6
Training loss: 0.7712401151657104
Validation loss: 1.8043631968959686

Epoch: 6| Step: 7
Training loss: 0.8678213953971863
Validation loss: 1.7954216669964533

Epoch: 6| Step: 8
Training loss: 1.0320402383804321
Validation loss: 1.7920017832068986

Epoch: 6| Step: 9
Training loss: 1.110379695892334
Validation loss: 1.7801020235143683

Epoch: 6| Step: 10
Training loss: 0.5418409109115601
Validation loss: 1.7685061321463635

Epoch: 6| Step: 11
Training loss: 1.0274658203125
Validation loss: 1.7765878323585755

Epoch: 6| Step: 12
Training loss: 0.7324684858322144
Validation loss: 1.7932077159163773

Epoch: 6| Step: 13
Training loss: 0.8529770374298096
Validation loss: 1.7860899381740118

Epoch: 240| Step: 0
Training loss: 0.5964623689651489
Validation loss: 1.8186033066882883

Epoch: 6| Step: 1
Training loss: 1.1217095851898193
Validation loss: 1.7975015153167069

Epoch: 6| Step: 2
Training loss: 1.0640634298324585
Validation loss: 1.8127632346204532

Epoch: 6| Step: 3
Training loss: 0.8822384476661682
Validation loss: 1.7830399890099802

Epoch: 6| Step: 4
Training loss: 0.8291438817977905
Validation loss: 1.795675600728681

Epoch: 6| Step: 5
Training loss: 0.9438967108726501
Validation loss: 1.7777448649047523

Epoch: 6| Step: 6
Training loss: 0.9120873212814331
Validation loss: 1.7882111995450911

Epoch: 6| Step: 7
Training loss: 0.708748459815979
Validation loss: 1.7837370326442104

Epoch: 6| Step: 8
Training loss: 0.9637552499771118
Validation loss: 1.760752539480886

Epoch: 6| Step: 9
Training loss: 0.839072585105896
Validation loss: 1.7526845483369724

Epoch: 6| Step: 10
Training loss: 0.6593470573425293
Validation loss: 1.7526140738559026

Epoch: 6| Step: 11
Training loss: 0.8427294492721558
Validation loss: 1.7346765738661571

Epoch: 6| Step: 12
Training loss: 0.4658586382865906
Validation loss: 1.7490981573699622

Epoch: 6| Step: 13
Training loss: 0.8266704678535461
Validation loss: 1.763308068757416

Epoch: 241| Step: 0
Training loss: 0.621321439743042
Validation loss: 1.7611862369762954

Epoch: 6| Step: 1
Training loss: 0.8003826141357422
Validation loss: 1.7978011318432388

Epoch: 6| Step: 2
Training loss: 1.2281816005706787
Validation loss: 1.8255743724043652

Epoch: 6| Step: 3
Training loss: 1.0579969882965088
Validation loss: 1.8338459935239566

Epoch: 6| Step: 4
Training loss: 0.9241030216217041
Validation loss: 1.8124032648660804

Epoch: 6| Step: 5
Training loss: 0.7423890233039856
Validation loss: 1.8365055566192956

Epoch: 6| Step: 6
Training loss: 0.7537825703620911
Validation loss: 1.8478254272091774

Epoch: 6| Step: 7
Training loss: 0.9922999143600464
Validation loss: 1.8697438265687676

Epoch: 6| Step: 8
Training loss: 0.8882601261138916
Validation loss: 1.8543282503722816

Epoch: 6| Step: 9
Training loss: 0.9408098459243774
Validation loss: 1.8543827379903486

Epoch: 6| Step: 10
Training loss: 0.5135538578033447
Validation loss: 1.85091584215882

Epoch: 6| Step: 11
Training loss: 0.8334708213806152
Validation loss: 1.845771440895655

Epoch: 6| Step: 12
Training loss: 0.7608929872512817
Validation loss: 1.865692146362797

Epoch: 6| Step: 13
Training loss: 0.5331481099128723
Validation loss: 1.8364533647414176

Epoch: 242| Step: 0
Training loss: 1.0158400535583496
Validation loss: 1.7976870024076073

Epoch: 6| Step: 1
Training loss: 0.8545377850532532
Validation loss: 1.785308781490531

Epoch: 6| Step: 2
Training loss: 0.8946278095245361
Validation loss: 1.8012463405568113

Epoch: 6| Step: 3
Training loss: 1.0553923845291138
Validation loss: 1.7945614425084924

Epoch: 6| Step: 4
Training loss: 0.918135404586792
Validation loss: 1.800494022266839

Epoch: 6| Step: 5
Training loss: 0.48095858097076416
Validation loss: 1.780219513882873

Epoch: 6| Step: 6
Training loss: 0.75975501537323
Validation loss: 1.7886058245935748

Epoch: 6| Step: 7
Training loss: 0.3284136652946472
Validation loss: 1.8247906943803192

Epoch: 6| Step: 8
Training loss: 0.6637388467788696
Validation loss: 1.8262399909316853

Epoch: 6| Step: 9
Training loss: 0.6203086376190186
Validation loss: 1.8376824176439674

Epoch: 6| Step: 10
Training loss: 1.0698274374008179
Validation loss: 1.8544169420837073

Epoch: 6| Step: 11
Training loss: 1.3418458700180054
Validation loss: 1.8843471516845047

Epoch: 6| Step: 12
Training loss: 1.0305705070495605
Validation loss: 1.8945454115508704

Epoch: 6| Step: 13
Training loss: 0.609309732913971
Validation loss: 1.8603504191162765

Epoch: 243| Step: 0
Training loss: 1.2744141817092896
Validation loss: 1.844493337856826

Epoch: 6| Step: 1
Training loss: 0.8177666664123535
Validation loss: 1.8319366042331984

Epoch: 6| Step: 2
Training loss: 0.9724338054656982
Validation loss: 1.7722438279018606

Epoch: 6| Step: 3
Training loss: 0.6961515545845032
Validation loss: 1.8156972354458225

Epoch: 6| Step: 4
Training loss: 1.2310080528259277
Validation loss: 1.8443833025552894

Epoch: 6| Step: 5
Training loss: 0.7173553705215454
Validation loss: 1.866104648959252

Epoch: 6| Step: 6
Training loss: 0.6655153036117554
Validation loss: 1.8273311661135765

Epoch: 6| Step: 7
Training loss: 0.5774984359741211
Validation loss: 1.793429365722082

Epoch: 6| Step: 8
Training loss: 1.1036006212234497
Validation loss: 1.783282478650411

Epoch: 6| Step: 9
Training loss: 0.5878663659095764
Validation loss: 1.8158036265321957

Epoch: 6| Step: 10
Training loss: 0.975483775138855
Validation loss: 1.7986218544744677

Epoch: 6| Step: 11
Training loss: 0.6005258560180664
Validation loss: 1.8349981897620744

Epoch: 6| Step: 12
Training loss: 0.989331066608429
Validation loss: 1.784879966448712

Epoch: 6| Step: 13
Training loss: 0.67375648021698
Validation loss: 1.8202875186038274

Epoch: 244| Step: 0
Training loss: 0.6855290532112122
Validation loss: 1.8341169447027228

Epoch: 6| Step: 1
Training loss: 0.7607893943786621
Validation loss: 1.8399395417141657

Epoch: 6| Step: 2
Training loss: 0.9128419160842896
Validation loss: 1.8304185534036288

Epoch: 6| Step: 3
Training loss: 0.5777386426925659
Validation loss: 1.8183037529709518

Epoch: 6| Step: 4
Training loss: 1.0504753589630127
Validation loss: 1.792566264829328

Epoch: 6| Step: 5
Training loss: 1.0367631912231445
Validation loss: 1.7919858514621694

Epoch: 6| Step: 6
Training loss: 0.7956960201263428
Validation loss: 1.7972238422721944

Epoch: 6| Step: 7
Training loss: 0.6821691989898682
Validation loss: 1.783791708689864

Epoch: 6| Step: 8
Training loss: 0.8648508191108704
Validation loss: 1.8011557530331355

Epoch: 6| Step: 9
Training loss: 0.7681435346603394
Validation loss: 1.7995004218111756

Epoch: 6| Step: 10
Training loss: 1.2449939250946045
Validation loss: 1.8067478749059862

Epoch: 6| Step: 11
Training loss: 0.5817347764968872
Validation loss: 1.7956791334254767

Epoch: 6| Step: 12
Training loss: 0.9937712550163269
Validation loss: 1.7816798712617608

Epoch: 6| Step: 13
Training loss: 0.5226848721504211
Validation loss: 1.7904519342607068

Epoch: 245| Step: 0
Training loss: 0.637723445892334
Validation loss: 1.8276980102703135

Epoch: 6| Step: 1
Training loss: 1.3312262296676636
Validation loss: 1.8490098086736535

Epoch: 6| Step: 2
Training loss: 1.1982048749923706
Validation loss: 1.8248749548389065

Epoch: 6| Step: 3
Training loss: 0.9295395016670227
Validation loss: 1.8316293890758226

Epoch: 6| Step: 4
Training loss: 0.9488219618797302
Validation loss: 1.8227589066310594

Epoch: 6| Step: 5
Training loss: 0.7377794981002808
Validation loss: 1.8212346338456677

Epoch: 6| Step: 6
Training loss: 0.6018648147583008
Validation loss: 1.7920036854282502

Epoch: 6| Step: 7
Training loss: 0.7400026917457581
Validation loss: 1.7846960444604196

Epoch: 6| Step: 8
Training loss: 0.5344438552856445
Validation loss: 1.782319761091663

Epoch: 6| Step: 9
Training loss: 0.4583924412727356
Validation loss: 1.7628581690531906

Epoch: 6| Step: 10
Training loss: 0.7912473678588867
Validation loss: 1.7911476140381188

Epoch: 6| Step: 11
Training loss: 1.0702707767486572
Validation loss: 1.8272853705190844

Epoch: 6| Step: 12
Training loss: 0.6157083511352539
Validation loss: 1.811039549048229

Epoch: 6| Step: 13
Training loss: 1.1102663278579712
Validation loss: 1.8289731805042555

Epoch: 246| Step: 0
Training loss: 0.6387060880661011
Validation loss: 1.8130199088845202

Epoch: 6| Step: 1
Training loss: 0.8157373666763306
Validation loss: 1.8189375964544152

Epoch: 6| Step: 2
Training loss: 0.46951282024383545
Validation loss: 1.8322916184702227

Epoch: 6| Step: 3
Training loss: 0.9988066554069519
Validation loss: 1.8294826079440374

Epoch: 6| Step: 4
Training loss: 0.8503726124763489
Validation loss: 1.8374678665591824

Epoch: 6| Step: 5
Training loss: 0.6545472145080566
Validation loss: 1.8142155690859723

Epoch: 6| Step: 6
Training loss: 0.8229073882102966
Validation loss: 1.8346702873065908

Epoch: 6| Step: 7
Training loss: 1.0925984382629395
Validation loss: 1.8251394392341695

Epoch: 6| Step: 8
Training loss: 0.6206514835357666
Validation loss: 1.8579124865993377

Epoch: 6| Step: 9
Training loss: 1.0429773330688477
Validation loss: 1.8349789547663864

Epoch: 6| Step: 10
Training loss: 0.6914151906967163
Validation loss: 1.836314949938046

Epoch: 6| Step: 11
Training loss: 0.7638043165206909
Validation loss: 1.8166995715069514

Epoch: 6| Step: 12
Training loss: 0.7384657859802246
Validation loss: 1.8046925811357395

Epoch: 6| Step: 13
Training loss: 0.6900727152824402
Validation loss: 1.8119482635169901

Epoch: 247| Step: 0
Training loss: 0.5183520317077637
Validation loss: 1.8013874920465613

Epoch: 6| Step: 1
Training loss: 0.6818034648895264
Validation loss: 1.8118291388275802

Epoch: 6| Step: 2
Training loss: 0.8655602931976318
Validation loss: 1.7984359097737137

Epoch: 6| Step: 3
Training loss: 0.5931345820426941
Validation loss: 1.7914632533186226

Epoch: 6| Step: 4
Training loss: 0.7326754331588745
Validation loss: 1.7797494319177443

Epoch: 6| Step: 5
Training loss: 0.6620789766311646
Validation loss: 1.7968573480524042

Epoch: 6| Step: 6
Training loss: 1.0425918102264404
Validation loss: 1.7833952698656308

Epoch: 6| Step: 7
Training loss: 0.8236417770385742
Validation loss: 1.814263093856073

Epoch: 6| Step: 8
Training loss: 0.8082133531570435
Validation loss: 1.827078898747762

Epoch: 6| Step: 9
Training loss: 0.8781867623329163
Validation loss: 1.7994419041500296

Epoch: 6| Step: 10
Training loss: 1.262911319732666
Validation loss: 1.7775780077903502

Epoch: 6| Step: 11
Training loss: 0.873681902885437
Validation loss: 1.8263528071424013

Epoch: 6| Step: 12
Training loss: 0.5882856845855713
Validation loss: 1.8536163171132405

Epoch: 6| Step: 13
Training loss: 0.7780646085739136
Validation loss: 1.8515580149107083

Epoch: 248| Step: 0
Training loss: 0.5995668172836304
Validation loss: 1.8877156344793176

Epoch: 6| Step: 1
Training loss: 0.8373653292655945
Validation loss: 1.867855527067697

Epoch: 6| Step: 2
Training loss: 1.1100205183029175
Validation loss: 1.806316743614853

Epoch: 6| Step: 3
Training loss: 0.9159703254699707
Validation loss: 1.7598113885489843

Epoch: 6| Step: 4
Training loss: 0.5609851479530334
Validation loss: 1.7529941374255764

Epoch: 6| Step: 5
Training loss: 0.629080057144165
Validation loss: 1.7773080564314319

Epoch: 6| Step: 6
Training loss: 0.8727989196777344
Validation loss: 1.7808232025433612

Epoch: 6| Step: 7
Training loss: 0.5808480381965637
Validation loss: 1.7990268520129624

Epoch: 6| Step: 8
Training loss: 0.4617322087287903
Validation loss: 1.8023745706004481

Epoch: 6| Step: 9
Training loss: 0.932219386100769
Validation loss: 1.805221216652983

Epoch: 6| Step: 10
Training loss: 0.4264562129974365
Validation loss: 1.794073530422744

Epoch: 6| Step: 11
Training loss: 1.1709327697753906
Validation loss: 1.7980539337281258

Epoch: 6| Step: 12
Training loss: 0.9699869155883789
Validation loss: 1.8102512731347034

Epoch: 6| Step: 13
Training loss: 1.0084352493286133
Validation loss: 1.7912995840913506

Epoch: 249| Step: 0
Training loss: 0.6251616477966309
Validation loss: 1.8039155096136115

Epoch: 6| Step: 1
Training loss: 0.45524078607559204
Validation loss: 1.7714938335521246

Epoch: 6| Step: 2
Training loss: 0.5809474587440491
Validation loss: 1.7958977940262004

Epoch: 6| Step: 3
Training loss: 0.6978971362113953
Validation loss: 1.7553673713437972

Epoch: 6| Step: 4
Training loss: 0.4505605697631836
Validation loss: 1.772052870001844

Epoch: 6| Step: 5
Training loss: 0.5890449285507202
Validation loss: 1.7710357801888579

Epoch: 6| Step: 6
Training loss: 1.0603433847427368
Validation loss: 1.7826552903780373

Epoch: 6| Step: 7
Training loss: 1.0756957530975342
Validation loss: 1.7728281495391682

Epoch: 6| Step: 8
Training loss: 0.9011027812957764
Validation loss: 1.76503667395602

Epoch: 6| Step: 9
Training loss: 0.9371945261955261
Validation loss: 1.7706268307983235

Epoch: 6| Step: 10
Training loss: 0.7342749238014221
Validation loss: 1.7731185472139748

Epoch: 6| Step: 11
Training loss: 0.7791756391525269
Validation loss: 1.7926381249581613

Epoch: 6| Step: 12
Training loss: 0.8781187534332275
Validation loss: 1.807631975861006

Epoch: 6| Step: 13
Training loss: 1.1443315744400024
Validation loss: 1.7716407391332811

Epoch: 250| Step: 0
Training loss: 0.5912790894508362
Validation loss: 1.7702807687943982

Epoch: 6| Step: 1
Training loss: 0.8668208718299866
Validation loss: 1.7721755273880497

Epoch: 6| Step: 2
Training loss: 1.145047664642334
Validation loss: 1.7502392197168002

Epoch: 6| Step: 3
Training loss: 1.0612897872924805
Validation loss: 1.7752303743875155

Epoch: 6| Step: 4
Training loss: 0.3631587624549866
Validation loss: 1.7649636345524942

Epoch: 6| Step: 5
Training loss: 1.0164586305618286
Validation loss: 1.7647981553949335

Epoch: 6| Step: 6
Training loss: 0.5090674161911011
Validation loss: 1.7425294127515567

Epoch: 6| Step: 7
Training loss: 0.7480953931808472
Validation loss: 1.7582275059915358

Epoch: 6| Step: 8
Training loss: 0.9301463961601257
Validation loss: 1.7484769590439335

Epoch: 6| Step: 9
Training loss: 0.44118231534957886
Validation loss: 1.7929799454186552

Epoch: 6| Step: 10
Training loss: 0.7521487474441528
Validation loss: 1.7937709016184653

Epoch: 6| Step: 11
Training loss: 0.8232983946800232
Validation loss: 1.780390017776079

Epoch: 6| Step: 12
Training loss: 0.6372931003570557
Validation loss: 1.7998064320574525

Epoch: 6| Step: 13
Training loss: 0.401673823595047
Validation loss: 1.7937129389855169

Epoch: 251| Step: 0
Training loss: 0.6441529393196106
Validation loss: 1.8123554850137362

Epoch: 6| Step: 1
Training loss: 1.0133527517318726
Validation loss: 1.7988313231416928

Epoch: 6| Step: 2
Training loss: 1.0611543655395508
Validation loss: 1.7729034757101407

Epoch: 6| Step: 3
Training loss: 0.7007831931114197
Validation loss: 1.7702701078948153

Epoch: 6| Step: 4
Training loss: 0.5441699624061584
Validation loss: 1.7773170304554764

Epoch: 6| Step: 5
Training loss: 0.839158833026886
Validation loss: 1.773765766492454

Epoch: 6| Step: 6
Training loss: 0.9603679776191711
Validation loss: 1.7805003671235935

Epoch: 6| Step: 7
Training loss: 1.0419511795043945
Validation loss: 1.7720371625756706

Epoch: 6| Step: 8
Training loss: 0.535891056060791
Validation loss: 1.7802754820034068

Epoch: 6| Step: 9
Training loss: 0.5864733457565308
Validation loss: 1.7827083872210594

Epoch: 6| Step: 10
Training loss: 0.38587599992752075
Validation loss: 1.8121547660519999

Epoch: 6| Step: 11
Training loss: 0.7141445875167847
Validation loss: 1.7927845985658708

Epoch: 6| Step: 12
Training loss: 0.5800395011901855
Validation loss: 1.7950662528314898

Epoch: 6| Step: 13
Training loss: 0.5963411331176758
Validation loss: 1.791819405812089

Epoch: 252| Step: 0
Training loss: 0.6370749473571777
Validation loss: 1.7984996277798888

Epoch: 6| Step: 1
Training loss: 0.7793207764625549
Validation loss: 1.8051941779352003

Epoch: 6| Step: 2
Training loss: 0.5591603517532349
Validation loss: 1.799385901420347

Epoch: 6| Step: 3
Training loss: 0.6251370906829834
Validation loss: 1.7828135259689823

Epoch: 6| Step: 4
Training loss: 0.4598747491836548
Validation loss: 1.7892001303293372

Epoch: 6| Step: 5
Training loss: 1.174446940422058
Validation loss: 1.7601918905012068

Epoch: 6| Step: 6
Training loss: 0.5528635382652283
Validation loss: 1.7627082973398187

Epoch: 6| Step: 7
Training loss: 0.8058508634567261
Validation loss: 1.7662776336875012

Epoch: 6| Step: 8
Training loss: 0.7706502676010132
Validation loss: 1.747972160257319

Epoch: 6| Step: 9
Training loss: 0.7723107933998108
Validation loss: 1.7657246769115489

Epoch: 6| Step: 10
Training loss: 1.1163984537124634
Validation loss: 1.787456407341906

Epoch: 6| Step: 11
Training loss: 0.9544960260391235
Validation loss: 1.7915338393180602

Epoch: 6| Step: 12
Training loss: 0.4313124418258667
Validation loss: 1.7819506609311668

Epoch: 6| Step: 13
Training loss: 0.39544427394866943
Validation loss: 1.788027258329494

Epoch: 253| Step: 0
Training loss: 0.5843623876571655
Validation loss: 1.8250364949626308

Epoch: 6| Step: 1
Training loss: 0.4913247227668762
Validation loss: 1.8044896330884708

Epoch: 6| Step: 2
Training loss: 0.5940467119216919
Validation loss: 1.7896356608278008

Epoch: 6| Step: 3
Training loss: 1.0449635982513428
Validation loss: 1.79169846862875

Epoch: 6| Step: 4
Training loss: 0.8389438390731812
Validation loss: 1.7723727764621857

Epoch: 6| Step: 5
Training loss: 0.6623634696006775
Validation loss: 1.7553327839861634

Epoch: 6| Step: 6
Training loss: 0.6177865862846375
Validation loss: 1.7331840915064658

Epoch: 6| Step: 7
Training loss: 0.9348724484443665
Validation loss: 1.7501224420403922

Epoch: 6| Step: 8
Training loss: 0.6987082958221436
Validation loss: 1.7703644408974597

Epoch: 6| Step: 9
Training loss: 0.510290265083313
Validation loss: 1.7437074235690537

Epoch: 6| Step: 10
Training loss: 0.8150651454925537
Validation loss: 1.745095872109936

Epoch: 6| Step: 11
Training loss: 0.9128668904304504
Validation loss: 1.7590990117801133

Epoch: 6| Step: 12
Training loss: 0.8301441669464111
Validation loss: 1.7545819820896271

Epoch: 6| Step: 13
Training loss: 0.837681233882904
Validation loss: 1.7633063190726823

Epoch: 254| Step: 0
Training loss: 0.7412459850311279
Validation loss: 1.7415234094024987

Epoch: 6| Step: 1
Training loss: 0.6170093417167664
Validation loss: 1.7569005745713429

Epoch: 6| Step: 2
Training loss: 0.6772946119308472
Validation loss: 1.7719887815495974

Epoch: 6| Step: 3
Training loss: 0.415063738822937
Validation loss: 1.7777309263906171

Epoch: 6| Step: 4
Training loss: 0.9272675514221191
Validation loss: 1.7965015570322673

Epoch: 6| Step: 5
Training loss: 0.5950820446014404
Validation loss: 1.8091425870054512

Epoch: 6| Step: 6
Training loss: 0.5035243034362793
Validation loss: 1.7773176957202215

Epoch: 6| Step: 7
Training loss: 0.9128760099411011
Validation loss: 1.7749579234789776

Epoch: 6| Step: 8
Training loss: 0.9040207266807556
Validation loss: 1.796091902640558

Epoch: 6| Step: 9
Training loss: 0.810788094997406
Validation loss: 1.7734062889570832

Epoch: 6| Step: 10
Training loss: 0.7739711403846741
Validation loss: 1.8003361071309736

Epoch: 6| Step: 11
Training loss: 0.4963996112346649
Validation loss: 1.7875023541911956

Epoch: 6| Step: 12
Training loss: 0.8670998215675354
Validation loss: 1.7735835711161296

Epoch: 6| Step: 13
Training loss: 1.1536225080490112
Validation loss: 1.8228564493117794

Epoch: 255| Step: 0
Training loss: 0.9359152913093567
Validation loss: 1.8199764041490452

Epoch: 6| Step: 1
Training loss: 0.6854751706123352
Validation loss: 1.7972975110494962

Epoch: 6| Step: 2
Training loss: 0.6182644963264465
Validation loss: 1.8216459622947119

Epoch: 6| Step: 3
Training loss: 0.7523854374885559
Validation loss: 1.8002046564573884

Epoch: 6| Step: 4
Training loss: 0.6812970638275146
Validation loss: 1.8266574900637391

Epoch: 6| Step: 5
Training loss: 0.6366691589355469
Validation loss: 1.8147776472953059

Epoch: 6| Step: 6
Training loss: 0.7800546288490295
Validation loss: 1.8043878181006319

Epoch: 6| Step: 7
Training loss: 1.2078559398651123
Validation loss: 1.7920514037532191

Epoch: 6| Step: 8
Training loss: 0.7697776556015015
Validation loss: 1.7761469400057228

Epoch: 6| Step: 9
Training loss: 0.7731196880340576
Validation loss: 1.7793432615136588

Epoch: 6| Step: 10
Training loss: 0.3456299901008606
Validation loss: 1.787713896843695

Epoch: 6| Step: 11
Training loss: 0.7154713273048401
Validation loss: 1.792550854785468

Epoch: 6| Step: 12
Training loss: 0.5776118636131287
Validation loss: 1.7833099083233905

Epoch: 6| Step: 13
Training loss: 0.7420983910560608
Validation loss: 1.786788180310239

Epoch: 256| Step: 0
Training loss: 0.4478549361228943
Validation loss: 1.7556681658632012

Epoch: 6| Step: 1
Training loss: 0.5013217926025391
Validation loss: 1.7915028192663704

Epoch: 6| Step: 2
Training loss: 0.6009791493415833
Validation loss: 1.7530404470300163

Epoch: 6| Step: 3
Training loss: 1.1092190742492676
Validation loss: 1.7729708276769167

Epoch: 6| Step: 4
Training loss: 0.6919618248939514
Validation loss: 1.7902566989262898

Epoch: 6| Step: 5
Training loss: 0.4030676484107971
Validation loss: 1.7719514344328193

Epoch: 6| Step: 6
Training loss: 0.877892255783081
Validation loss: 1.7918674253648328

Epoch: 6| Step: 7
Training loss: 0.30062389373779297
Validation loss: 1.798283964075068

Epoch: 6| Step: 8
Training loss: 1.0199894905090332
Validation loss: 1.8153602846207157

Epoch: 6| Step: 9
Training loss: 0.4828888773918152
Validation loss: 1.8322358259590723

Epoch: 6| Step: 10
Training loss: 0.6899169683456421
Validation loss: 1.8138241665337675

Epoch: 6| Step: 11
Training loss: 0.7619476318359375
Validation loss: 1.8511252608350528

Epoch: 6| Step: 12
Training loss: 1.0518982410430908
Validation loss: 1.881726199580777

Epoch: 6| Step: 13
Training loss: 0.960480809211731
Validation loss: 1.8821062951959588

Epoch: 257| Step: 0
Training loss: 0.6263549327850342
Validation loss: 1.8743714799163163

Epoch: 6| Step: 1
Training loss: 0.9405153393745422
Validation loss: 1.8586363882146857

Epoch: 6| Step: 2
Training loss: 0.6125688552856445
Validation loss: 1.8176076194291473

Epoch: 6| Step: 3
Training loss: 0.45241817831993103
Validation loss: 1.815105817651236

Epoch: 6| Step: 4
Training loss: 0.8116234540939331
Validation loss: 1.7580774740506244

Epoch: 6| Step: 5
Training loss: 0.5368821024894714
Validation loss: 1.7617065137432468

Epoch: 6| Step: 6
Training loss: 0.6508969664573669
Validation loss: 1.7459038919018162

Epoch: 6| Step: 7
Training loss: 0.735413670539856
Validation loss: 1.7407672456515733

Epoch: 6| Step: 8
Training loss: 1.2850154638290405
Validation loss: 1.764031566599364

Epoch: 6| Step: 9
Training loss: 0.6877051591873169
Validation loss: 1.7841724644425094

Epoch: 6| Step: 10
Training loss: 0.7382974624633789
Validation loss: 1.7651726699644519

Epoch: 6| Step: 11
Training loss: 0.4843159317970276
Validation loss: 1.7529143594926404

Epoch: 6| Step: 12
Training loss: 0.8335815668106079
Validation loss: 1.758731831786453

Epoch: 6| Step: 13
Training loss: 0.4997091293334961
Validation loss: 1.7481609185536702

Epoch: 258| Step: 0
Training loss: 0.7868722677230835
Validation loss: 1.7795726227503952

Epoch: 6| Step: 1
Training loss: 0.6166147589683533
Validation loss: 1.7660535753414195

Epoch: 6| Step: 2
Training loss: 0.9594075679779053
Validation loss: 1.791772969307438

Epoch: 6| Step: 3
Training loss: 0.46364760398864746
Validation loss: 1.7737150781898088

Epoch: 6| Step: 4
Training loss: 0.7792471647262573
Validation loss: 1.775532368690737

Epoch: 6| Step: 5
Training loss: 0.8352525234222412
Validation loss: 1.7755820110280027

Epoch: 6| Step: 6
Training loss: 0.5458685159683228
Validation loss: 1.7483220433676114

Epoch: 6| Step: 7
Training loss: 0.7025240659713745
Validation loss: 1.753195999771036

Epoch: 6| Step: 8
Training loss: 0.7510289549827576
Validation loss: 1.7834558307483632

Epoch: 6| Step: 9
Training loss: 0.38050252199172974
Validation loss: 1.7762392951596169

Epoch: 6| Step: 10
Training loss: 0.5059793591499329
Validation loss: 1.7605194660925096

Epoch: 6| Step: 11
Training loss: 0.9836826324462891
Validation loss: 1.7814396337796283

Epoch: 6| Step: 12
Training loss: 0.7401232719421387
Validation loss: 1.7610406401336833

Epoch: 6| Step: 13
Training loss: 0.4521870017051697
Validation loss: 1.7309465677507463

Epoch: 259| Step: 0
Training loss: 0.9275506138801575
Validation loss: 1.7415133830039733

Epoch: 6| Step: 1
Training loss: 0.6260825991630554
Validation loss: 1.7306123497665569

Epoch: 6| Step: 2
Training loss: 0.7697170972824097
Validation loss: 1.7354456417022213

Epoch: 6| Step: 3
Training loss: 0.8374459743499756
Validation loss: 1.7257857540602326

Epoch: 6| Step: 4
Training loss: 1.035796046257019
Validation loss: 1.7575950750740625

Epoch: 6| Step: 5
Training loss: 0.4727572500705719
Validation loss: 1.749928984590756

Epoch: 6| Step: 6
Training loss: 0.41047826409339905
Validation loss: 1.7601361569537912

Epoch: 6| Step: 7
Training loss: 0.5876805782318115
Validation loss: 1.7569104599696335

Epoch: 6| Step: 8
Training loss: 0.7013318538665771
Validation loss: 1.7622086181435535

Epoch: 6| Step: 9
Training loss: 0.47700491547584534
Validation loss: 1.7802420636659027

Epoch: 6| Step: 10
Training loss: 0.686789870262146
Validation loss: 1.787861793271957

Epoch: 6| Step: 11
Training loss: 0.5144553184509277
Validation loss: 1.7620922673133113

Epoch: 6| Step: 12
Training loss: 0.7415883541107178
Validation loss: 1.7750199353823097

Epoch: 6| Step: 13
Training loss: 0.9659053087234497
Validation loss: 1.7738633155822754

Epoch: 260| Step: 0
Training loss: 0.6052480340003967
Validation loss: 1.7308185741465578

Epoch: 6| Step: 1
Training loss: 0.38969334959983826
Validation loss: 1.719323185182387

Epoch: 6| Step: 2
Training loss: 0.5389178395271301
Validation loss: 1.7105699950648892

Epoch: 6| Step: 3
Training loss: 0.9030930399894714
Validation loss: 1.7641302103637366

Epoch: 6| Step: 4
Training loss: 0.7279502153396606
Validation loss: 1.7315474851157076

Epoch: 6| Step: 5
Training loss: 0.5547248721122742
Validation loss: 1.7345839085117463

Epoch: 6| Step: 6
Training loss: 0.7141379714012146
Validation loss: 1.7253673345811906

Epoch: 6| Step: 7
Training loss: 0.7007204294204712
Validation loss: 1.74350017886008

Epoch: 6| Step: 8
Training loss: 0.5175250172615051
Validation loss: 1.7379150262442968

Epoch: 6| Step: 9
Training loss: 0.6976948976516724
Validation loss: 1.7546380078920754

Epoch: 6| Step: 10
Training loss: 0.6030727624893188
Validation loss: 1.7474006311867827

Epoch: 6| Step: 11
Training loss: 0.8736428618431091
Validation loss: 1.7317993640899658

Epoch: 6| Step: 12
Training loss: 0.8004700541496277
Validation loss: 1.7317405439192248

Epoch: 6| Step: 13
Training loss: 0.6365366578102112
Validation loss: 1.7181914544874621

Epoch: 261| Step: 0
Training loss: 0.469931036233902
Validation loss: 1.7379232209215882

Epoch: 6| Step: 1
Training loss: 0.5650496482849121
Validation loss: 1.7623988633514733

Epoch: 6| Step: 2
Training loss: 0.302890807390213
Validation loss: 1.7446760798013339

Epoch: 6| Step: 3
Training loss: 0.8541967868804932
Validation loss: 1.7715717951456706

Epoch: 6| Step: 4
Training loss: 0.8514308929443359
Validation loss: 1.7448381813623572

Epoch: 6| Step: 5
Training loss: 0.7923508286476135
Validation loss: 1.7241789640918854

Epoch: 6| Step: 6
Training loss: 0.888695478439331
Validation loss: 1.7444235073622836

Epoch: 6| Step: 7
Training loss: 0.6291114091873169
Validation loss: 1.7388806278987596

Epoch: 6| Step: 8
Training loss: 0.8309915065765381
Validation loss: 1.7285601759469638

Epoch: 6| Step: 9
Training loss: 0.6151131391525269
Validation loss: 1.747332008936072

Epoch: 6| Step: 10
Training loss: 0.7724727392196655
Validation loss: 1.7826990517236854

Epoch: 6| Step: 11
Training loss: 0.6058910489082336
Validation loss: 1.7254584809785247

Epoch: 6| Step: 12
Training loss: 0.5111641883850098
Validation loss: 1.7572469660030898

Epoch: 6| Step: 13
Training loss: 0.45375606417655945
Validation loss: 1.73750485656082

Epoch: 262| Step: 0
Training loss: 0.37236055731773376
Validation loss: 1.7410624309252667

Epoch: 6| Step: 1
Training loss: 0.5248848795890808
Validation loss: 1.7225390813683952

Epoch: 6| Step: 2
Training loss: 0.5937515497207642
Validation loss: 1.7262195246193999

Epoch: 6| Step: 3
Training loss: 1.0289626121520996
Validation loss: 1.713881754106091

Epoch: 6| Step: 4
Training loss: 0.7949623465538025
Validation loss: 1.7391420205434163

Epoch: 6| Step: 5
Training loss: 0.8724149465560913
Validation loss: 1.7241978324869627

Epoch: 6| Step: 6
Training loss: 0.8294557332992554
Validation loss: 1.746928648282123

Epoch: 6| Step: 7
Training loss: 0.5566058158874512
Validation loss: 1.7005469799041748

Epoch: 6| Step: 8
Training loss: 0.6508239507675171
Validation loss: 1.7282845563786005

Epoch: 6| Step: 9
Training loss: 0.5059365034103394
Validation loss: 1.7341734773369246

Epoch: 6| Step: 10
Training loss: 0.6193325519561768
Validation loss: 1.692811236586622

Epoch: 6| Step: 11
Training loss: 0.7533528804779053
Validation loss: 1.7326727195452618

Epoch: 6| Step: 12
Training loss: 0.8240327835083008
Validation loss: 1.7219752009196947

Epoch: 6| Step: 13
Training loss: 0.39801257848739624
Validation loss: 1.7035110368523547

Epoch: 263| Step: 0
Training loss: 0.6469959020614624
Validation loss: 1.735948065275787

Epoch: 6| Step: 1
Training loss: 0.7564207315444946
Validation loss: 1.7374437675681165

Epoch: 6| Step: 2
Training loss: 0.38990235328674316
Validation loss: 1.7324783789214266

Epoch: 6| Step: 3
Training loss: 0.4944103956222534
Validation loss: 1.7044519198838102

Epoch: 6| Step: 4
Training loss: 0.7074950933456421
Validation loss: 1.7391753260807326

Epoch: 6| Step: 5
Training loss: 0.4154531955718994
Validation loss: 1.7454142570495605

Epoch: 6| Step: 6
Training loss: 0.7199370265007019
Validation loss: 1.734538608981717

Epoch: 6| Step: 7
Training loss: 0.7060480117797852
Validation loss: 1.734556499347892

Epoch: 6| Step: 8
Training loss: 0.3692203164100647
Validation loss: 1.7303139278965611

Epoch: 6| Step: 9
Training loss: 1.235107183456421
Validation loss: 1.753734935996353

Epoch: 6| Step: 10
Training loss: 0.8357073068618774
Validation loss: 1.738343499040091

Epoch: 6| Step: 11
Training loss: 0.6615603566169739
Validation loss: 1.7562936749509586

Epoch: 6| Step: 12
Training loss: 0.8296592831611633
Validation loss: 1.7209611310753772

Epoch: 6| Step: 13
Training loss: 0.40375351905822754
Validation loss: 1.7150930960973103

Epoch: 264| Step: 0
Training loss: 0.5850415229797363
Validation loss: 1.7298919513661375

Epoch: 6| Step: 1
Training loss: 0.5902314186096191
Validation loss: 1.7330974417348062

Epoch: 6| Step: 2
Training loss: 0.7248872518539429
Validation loss: 1.7424579333233576

Epoch: 6| Step: 3
Training loss: 0.4043619632720947
Validation loss: 1.738824623887257

Epoch: 6| Step: 4
Training loss: 0.7016604542732239
Validation loss: 1.7224120875840545

Epoch: 6| Step: 5
Training loss: 1.1453030109405518
Validation loss: 1.7013802041289627

Epoch: 6| Step: 6
Training loss: 0.7083367109298706
Validation loss: 1.7035050289605254

Epoch: 6| Step: 7
Training loss: 0.37309354543685913
Validation loss: 1.754666091293417

Epoch: 6| Step: 8
Training loss: 0.8056349158287048
Validation loss: 1.7630606614133364

Epoch: 6| Step: 9
Training loss: 0.7799074649810791
Validation loss: 1.7838194985543527

Epoch: 6| Step: 10
Training loss: 0.6036356687545776
Validation loss: 1.7981860189027683

Epoch: 6| Step: 11
Training loss: 0.8839813470840454
Validation loss: 1.7860465870108655

Epoch: 6| Step: 12
Training loss: 0.4900982975959778
Validation loss: 1.7575511855463828

Epoch: 6| Step: 13
Training loss: 0.35171017050743103
Validation loss: 1.7484298008744434

Epoch: 265| Step: 0
Training loss: 0.3396812677383423
Validation loss: 1.7403010501656482

Epoch: 6| Step: 1
Training loss: 0.46652209758758545
Validation loss: 1.7236296066673853

Epoch: 6| Step: 2
Training loss: 0.3863779306411743
Validation loss: 1.7225411168990596

Epoch: 6| Step: 3
Training loss: 0.6806943416595459
Validation loss: 1.7000259904451267

Epoch: 6| Step: 4
Training loss: 0.7692002654075623
Validation loss: 1.7185192556791409

Epoch: 6| Step: 5
Training loss: 0.5953726768493652
Validation loss: 1.7018549391018447

Epoch: 6| Step: 6
Training loss: 0.7640732526779175
Validation loss: 1.728006657733712

Epoch: 6| Step: 7
Training loss: 0.9672678709030151
Validation loss: 1.7547410700910835

Epoch: 6| Step: 8
Training loss: 0.8233093619346619
Validation loss: 1.753510808431974

Epoch: 6| Step: 9
Training loss: 0.424872487783432
Validation loss: 1.7637454335407545

Epoch: 6| Step: 10
Training loss: 0.6672563552856445
Validation loss: 1.7877484560012817

Epoch: 6| Step: 11
Training loss: 0.49215051531791687
Validation loss: 1.8082046560061875

Epoch: 6| Step: 12
Training loss: 0.814781904220581
Validation loss: 1.7945394439081992

Epoch: 6| Step: 13
Training loss: 0.7381041049957275
Validation loss: 1.7928872634005804

Epoch: 266| Step: 0
Training loss: 0.7889589071273804
Validation loss: 1.792320232237539

Epoch: 6| Step: 1
Training loss: 0.7735089063644409
Validation loss: 1.802072367360515

Epoch: 6| Step: 2
Training loss: 0.6027765274047852
Validation loss: 1.7629173494154406

Epoch: 6| Step: 3
Training loss: 0.5178238153457642
Validation loss: 1.7782038104149602

Epoch: 6| Step: 4
Training loss: 1.1175694465637207
Validation loss: 1.7779929843000186

Epoch: 6| Step: 5
Training loss: 0.5607055425643921
Validation loss: 1.7486954068624845

Epoch: 6| Step: 6
Training loss: 0.8916563987731934
Validation loss: 1.7417986751884542

Epoch: 6| Step: 7
Training loss: 0.6174050569534302
Validation loss: 1.7310142978545158

Epoch: 6| Step: 8
Training loss: 0.7245391011238098
Validation loss: 1.7519982681479505

Epoch: 6| Step: 9
Training loss: 0.4084446430206299
Validation loss: 1.7563668245910316

Epoch: 6| Step: 10
Training loss: 0.4332876205444336
Validation loss: 1.7467740171699113

Epoch: 6| Step: 11
Training loss: 0.4742974638938904
Validation loss: 1.722058674340607

Epoch: 6| Step: 12
Training loss: 0.44766247272491455
Validation loss: 1.771164164748243

Epoch: 6| Step: 13
Training loss: 0.31595808267593384
Validation loss: 1.772242194862776

Epoch: 267| Step: 0
Training loss: 1.046580195426941
Validation loss: 1.7826464945270168

Epoch: 6| Step: 1
Training loss: 0.6420383453369141
Validation loss: 1.7718390021272885

Epoch: 6| Step: 2
Training loss: 0.40784502029418945
Validation loss: 1.8119726040030038

Epoch: 6| Step: 3
Training loss: 0.5720692873001099
Validation loss: 1.8051891775541409

Epoch: 6| Step: 4
Training loss: 0.6251946091651917
Validation loss: 1.8034689093148837

Epoch: 6| Step: 5
Training loss: 0.5944328308105469
Validation loss: 1.7646605865929716

Epoch: 6| Step: 6
Training loss: 0.6036534309387207
Validation loss: 1.8098724811307845

Epoch: 6| Step: 7
Training loss: 0.6778386831283569
Validation loss: 1.795496747057925

Epoch: 6| Step: 8
Training loss: 0.5650174021720886
Validation loss: 1.7741786164622153

Epoch: 6| Step: 9
Training loss: 0.7810399532318115
Validation loss: 1.7822656182832615

Epoch: 6| Step: 10
Training loss: 0.5088127851486206
Validation loss: 1.7614949185361144

Epoch: 6| Step: 11
Training loss: 0.7350426912307739
Validation loss: 1.7525551844668645

Epoch: 6| Step: 12
Training loss: 0.7107993364334106
Validation loss: 1.7529188753456197

Epoch: 6| Step: 13
Training loss: 0.3199714422225952
Validation loss: 1.7389252634458645

Epoch: 268| Step: 0
Training loss: 0.45013001561164856
Validation loss: 1.7436167873362058

Epoch: 6| Step: 1
Training loss: 0.9227248430252075
Validation loss: 1.705077593044568

Epoch: 6| Step: 2
Training loss: 0.9233251810073853
Validation loss: 1.6983914118941112

Epoch: 6| Step: 3
Training loss: 0.4650724530220032
Validation loss: 1.6910837696444603

Epoch: 6| Step: 4
Training loss: 0.4533286690711975
Validation loss: 1.680459342977052

Epoch: 6| Step: 5
Training loss: 1.0374138355255127
Validation loss: 1.7068222607335737

Epoch: 6| Step: 6
Training loss: 0.470721960067749
Validation loss: 1.6871187276737665

Epoch: 6| Step: 7
Training loss: 0.6971043348312378
Validation loss: 1.6999262481607416

Epoch: 6| Step: 8
Training loss: 0.7579373717308044
Validation loss: 1.7294522639243834

Epoch: 6| Step: 9
Training loss: 0.8081820011138916
Validation loss: 1.7425807881098923

Epoch: 6| Step: 10
Training loss: 0.22734808921813965
Validation loss: 1.719621818552735

Epoch: 6| Step: 11
Training loss: 0.5791864991188049
Validation loss: 1.7369445895635953

Epoch: 6| Step: 12
Training loss: 0.5706021785736084
Validation loss: 1.7719291281956497

Epoch: 6| Step: 13
Training loss: 0.6934476494789124
Validation loss: 1.746777666512356

Epoch: 269| Step: 0
Training loss: 0.5390040874481201
Validation loss: 1.7268903422099289

Epoch: 6| Step: 1
Training loss: 0.5813958644866943
Validation loss: 1.7185684609156784

Epoch: 6| Step: 2
Training loss: 0.5918154716491699
Validation loss: 1.7054287682297409

Epoch: 6| Step: 3
Training loss: 0.6440111398696899
Validation loss: 1.6808694536967943

Epoch: 6| Step: 4
Training loss: 0.9073208570480347
Validation loss: 1.6685836930428781

Epoch: 6| Step: 5
Training loss: 0.5322579145431519
Validation loss: 1.663485264265409

Epoch: 6| Step: 6
Training loss: 0.7849462032318115
Validation loss: 1.6592262021956905

Epoch: 6| Step: 7
Training loss: 0.8052892088890076
Validation loss: 1.6920412919854606

Epoch: 6| Step: 8
Training loss: 0.451160192489624
Validation loss: 1.6812559891772527

Epoch: 6| Step: 9
Training loss: 0.4629974365234375
Validation loss: 1.6839763400375203

Epoch: 6| Step: 10
Training loss: 0.6770060062408447
Validation loss: 1.7099513789658904

Epoch: 6| Step: 11
Training loss: 0.5990099310874939
Validation loss: 1.7328679548796786

Epoch: 6| Step: 12
Training loss: 0.4687345325946808
Validation loss: 1.7696041471214705

Epoch: 6| Step: 13
Training loss: 0.9253854751586914
Validation loss: 1.7900912864233858

Epoch: 270| Step: 0
Training loss: 0.5620185732841492
Validation loss: 1.7962782100964618

Epoch: 6| Step: 1
Training loss: 0.7182579636573792
Validation loss: 1.8362103969820085

Epoch: 6| Step: 2
Training loss: 0.663421630859375
Validation loss: 1.8166808287302654

Epoch: 6| Step: 3
Training loss: 0.720876932144165
Validation loss: 1.8021463014746224

Epoch: 6| Step: 4
Training loss: 0.5628828406333923
Validation loss: 1.8252891904564315

Epoch: 6| Step: 5
Training loss: 0.6667963266372681
Validation loss: 1.811418205179194

Epoch: 6| Step: 6
Training loss: 0.3877181112766266
Validation loss: 1.801544920090706

Epoch: 6| Step: 7
Training loss: 0.3579893708229065
Validation loss: 1.7880901867343533

Epoch: 6| Step: 8
Training loss: 0.8849052786827087
Validation loss: 1.7421312101425663

Epoch: 6| Step: 9
Training loss: 0.5305296182632446
Validation loss: 1.722558823964929

Epoch: 6| Step: 10
Training loss: 0.9589028358459473
Validation loss: 1.7599661632250714

Epoch: 6| Step: 11
Training loss: 1.0093493461608887
Validation loss: 1.7297454034128497

Epoch: 6| Step: 12
Training loss: 0.47426077723503113
Validation loss: 1.7366127044923845

Epoch: 6| Step: 13
Training loss: 0.42315083742141724
Validation loss: 1.7226065974081717

Epoch: 271| Step: 0
Training loss: 0.6042282581329346
Validation loss: 1.7023092213497366

Epoch: 6| Step: 1
Training loss: 0.5385740399360657
Validation loss: 1.736017107963562

Epoch: 6| Step: 2
Training loss: 0.8404422998428345
Validation loss: 1.7452286148584017

Epoch: 6| Step: 3
Training loss: 0.44846582412719727
Validation loss: 1.7351623824847642

Epoch: 6| Step: 4
Training loss: 0.38729435205459595
Validation loss: 1.7915071108007943

Epoch: 6| Step: 5
Training loss: 0.8164223432540894
Validation loss: 1.7560572842115998

Epoch: 6| Step: 6
Training loss: 0.6827785968780518
Validation loss: 1.804032810272709

Epoch: 6| Step: 7
Training loss: 0.5875829458236694
Validation loss: 1.7929179283880419

Epoch: 6| Step: 8
Training loss: 0.6570309400558472
Validation loss: 1.8222565740667365

Epoch: 6| Step: 9
Training loss: 0.987449049949646
Validation loss: 1.7606981826084915

Epoch: 6| Step: 10
Training loss: 0.6829500198364258
Validation loss: 1.7541458299083095

Epoch: 6| Step: 11
Training loss: 0.7507615089416504
Validation loss: 1.7226396606814476

Epoch: 6| Step: 12
Training loss: 0.49160030484199524
Validation loss: 1.7203411184331423

Epoch: 6| Step: 13
Training loss: 0.30435100197792053
Validation loss: 1.7198435721858856

Epoch: 272| Step: 0
Training loss: 0.6836901903152466
Validation loss: 1.707487121705086

Epoch: 6| Step: 1
Training loss: 0.45325228571891785
Validation loss: 1.7104691907923708

Epoch: 6| Step: 2
Training loss: 0.8945744037628174
Validation loss: 1.7164769275214082

Epoch: 6| Step: 3
Training loss: 0.3277471363544464
Validation loss: 1.6881129549395653

Epoch: 6| Step: 4
Training loss: 0.6287770867347717
Validation loss: 1.6842502291484545

Epoch: 6| Step: 5
Training loss: 0.6459288597106934
Validation loss: 1.6940143544186828

Epoch: 6| Step: 6
Training loss: 0.5310903191566467
Validation loss: 1.712120093325133

Epoch: 6| Step: 7
Training loss: 0.5105614066123962
Validation loss: 1.7081172825187765

Epoch: 6| Step: 8
Training loss: 0.576386570930481
Validation loss: 1.7270743013710104

Epoch: 6| Step: 9
Training loss: 0.5164563655853271
Validation loss: 1.721435821184548

Epoch: 6| Step: 10
Training loss: 0.9156493544578552
Validation loss: 1.7293487876974127

Epoch: 6| Step: 11
Training loss: 0.44520390033721924
Validation loss: 1.7833274436253372

Epoch: 6| Step: 12
Training loss: 0.754143238067627
Validation loss: 1.7485996856484363

Epoch: 6| Step: 13
Training loss: 0.5195534229278564
Validation loss: 1.7576675184311406

Epoch: 273| Step: 0
Training loss: 0.5225756168365479
Validation loss: 1.7927833757092875

Epoch: 6| Step: 1
Training loss: 0.5465368032455444
Validation loss: 1.8426634342439714

Epoch: 6| Step: 2
Training loss: 0.4236401319503784
Validation loss: 1.8611079210876136

Epoch: 6| Step: 3
Training loss: 0.9275271892547607
Validation loss: 1.8234565616935812

Epoch: 6| Step: 4
Training loss: 0.6290674209594727
Validation loss: 1.799359727931279

Epoch: 6| Step: 5
Training loss: 0.6981950402259827
Validation loss: 1.7411767359702819

Epoch: 6| Step: 6
Training loss: 1.0599197149276733
Validation loss: 1.7411590365953342

Epoch: 6| Step: 7
Training loss: 0.8443689346313477
Validation loss: 1.705893813922841

Epoch: 6| Step: 8
Training loss: 0.7996459007263184
Validation loss: 1.716497944247338

Epoch: 6| Step: 9
Training loss: 0.4172969162464142
Validation loss: 1.6870658577129405

Epoch: 6| Step: 10
Training loss: 0.5309489965438843
Validation loss: 1.6823181580471736

Epoch: 6| Step: 11
Training loss: 0.5578873157501221
Validation loss: 1.6831957447913386

Epoch: 6| Step: 12
Training loss: 0.48493680357933044
Validation loss: 1.6974303491653935

Epoch: 6| Step: 13
Training loss: 0.6737625598907471
Validation loss: 1.7021772861480713

Epoch: 274| Step: 0
Training loss: 0.46646052598953247
Validation loss: 1.7162662782976705

Epoch: 6| Step: 1
Training loss: 0.48462626338005066
Validation loss: 1.665560769778426

Epoch: 6| Step: 2
Training loss: 0.5596722960472107
Validation loss: 1.6902620741116103

Epoch: 6| Step: 3
Training loss: 0.6100876927375793
Validation loss: 1.691566413448703

Epoch: 6| Step: 4
Training loss: 0.7452160120010376
Validation loss: 1.7269299350759035

Epoch: 6| Step: 5
Training loss: 0.46864792704582214
Validation loss: 1.7103513466414584

Epoch: 6| Step: 6
Training loss: 0.9235107898712158
Validation loss: 1.710607135167686

Epoch: 6| Step: 7
Training loss: 0.40469229221343994
Validation loss: 1.7255286478227185

Epoch: 6| Step: 8
Training loss: 0.4504176378250122
Validation loss: 1.711125514840567

Epoch: 6| Step: 9
Training loss: 0.6856735944747925
Validation loss: 1.7150240828914027

Epoch: 6| Step: 10
Training loss: 0.5981345772743225
Validation loss: 1.7491424647710656

Epoch: 6| Step: 11
Training loss: 0.6927887201309204
Validation loss: 1.7599425444038965

Epoch: 6| Step: 12
Training loss: 0.8117399215698242
Validation loss: 1.7697832674108527

Epoch: 6| Step: 13
Training loss: 0.8103456497192383
Validation loss: 1.7845084103204871

Epoch: 275| Step: 0
Training loss: 0.5300633907318115
Validation loss: 1.743446862184873

Epoch: 6| Step: 1
Training loss: 0.9988293051719666
Validation loss: 1.7238484595411567

Epoch: 6| Step: 2
Training loss: 0.423807293176651
Validation loss: 1.7384626942296182

Epoch: 6| Step: 3
Training loss: 0.642946720123291
Validation loss: 1.7097727714046356

Epoch: 6| Step: 4
Training loss: 0.7796274423599243
Validation loss: 1.7142561097298898

Epoch: 6| Step: 5
Training loss: 0.3534676432609558
Validation loss: 1.6978563698389197

Epoch: 6| Step: 6
Training loss: 0.591740608215332
Validation loss: 1.7167259339363343

Epoch: 6| Step: 7
Training loss: 0.5747750401496887
Validation loss: 1.716886830586259

Epoch: 6| Step: 8
Training loss: 0.42504894733428955
Validation loss: 1.742384285055181

Epoch: 6| Step: 9
Training loss: 0.6465631127357483
Validation loss: 1.7381367657774238

Epoch: 6| Step: 10
Training loss: 0.4667501747608185
Validation loss: 1.7298739392270324

Epoch: 6| Step: 11
Training loss: 0.5149259567260742
Validation loss: 1.735018193080861

Epoch: 6| Step: 12
Training loss: 0.9448228478431702
Validation loss: 1.7116968298471102

Epoch: 6| Step: 13
Training loss: 0.6461472511291504
Validation loss: 1.758365705449094

Epoch: 276| Step: 0
Training loss: 0.6786632537841797
Validation loss: 1.757426102956136

Epoch: 6| Step: 1
Training loss: 0.6040281653404236
Validation loss: 1.7770236512666107

Epoch: 6| Step: 2
Training loss: 0.20889247953891754
Validation loss: 1.7560300532207693

Epoch: 6| Step: 3
Training loss: 0.42957228422164917
Validation loss: 1.738745213836752

Epoch: 6| Step: 4
Training loss: 0.8274905681610107
Validation loss: 1.7420797527477305

Epoch: 6| Step: 5
Training loss: 0.4442620873451233
Validation loss: 1.7314473864852742

Epoch: 6| Step: 6
Training loss: 0.4539312720298767
Validation loss: 1.7023224510172361

Epoch: 6| Step: 7
Training loss: 0.3937697410583496
Validation loss: 1.7019801960196546

Epoch: 6| Step: 8
Training loss: 0.6896648406982422
Validation loss: 1.7283887068430583

Epoch: 6| Step: 9
Training loss: 0.8915352821350098
Validation loss: 1.71427123777328

Epoch: 6| Step: 10
Training loss: 0.5747594833374023
Validation loss: 1.705329820673953

Epoch: 6| Step: 11
Training loss: 0.7151628136634827
Validation loss: 1.7004784076444563

Epoch: 6| Step: 12
Training loss: 0.6306295990943909
Validation loss: 1.7025292547800208

Epoch: 6| Step: 13
Training loss: 0.5818647742271423
Validation loss: 1.7305968153861262

Epoch: 277| Step: 0
Training loss: 0.3677661120891571
Validation loss: 1.7154283626105196

Epoch: 6| Step: 1
Training loss: 0.5032410025596619
Validation loss: 1.7263425332243725

Epoch: 6| Step: 2
Training loss: 0.5142917633056641
Validation loss: 1.7283996382067282

Epoch: 6| Step: 3
Training loss: 0.4043644070625305
Validation loss: 1.7018762621828305

Epoch: 6| Step: 4
Training loss: 1.0159951448440552
Validation loss: 1.7158815886384697

Epoch: 6| Step: 5
Training loss: 0.5251301527023315
Validation loss: 1.7011777982916882

Epoch: 6| Step: 6
Training loss: 0.2085690200328827
Validation loss: 1.6875980387451828

Epoch: 6| Step: 7
Training loss: 0.5441995859146118
Validation loss: 1.6990555986281364

Epoch: 6| Step: 8
Training loss: 0.37388452887535095
Validation loss: 1.6922445617696291

Epoch: 6| Step: 9
Training loss: 0.8481476306915283
Validation loss: 1.6754264382905857

Epoch: 6| Step: 10
Training loss: 0.815272331237793
Validation loss: 1.6902176052011468

Epoch: 6| Step: 11
Training loss: 0.7318384647369385
Validation loss: 1.7110326174766786

Epoch: 6| Step: 12
Training loss: 0.5247431397438049
Validation loss: 1.6776465805627967

Epoch: 6| Step: 13
Training loss: 0.779123067855835
Validation loss: 1.7089237141352829

Epoch: 278| Step: 0
Training loss: 0.45686352252960205
Validation loss: 1.684386464857286

Epoch: 6| Step: 1
Training loss: 0.5614941716194153
Validation loss: 1.6884953834677254

Epoch: 6| Step: 2
Training loss: 0.2316575050354004
Validation loss: 1.6719789440913866

Epoch: 6| Step: 3
Training loss: 0.6193233132362366
Validation loss: 1.718912588652744

Epoch: 6| Step: 4
Training loss: 0.4458705186843872
Validation loss: 1.7184154295152234

Epoch: 6| Step: 5
Training loss: 0.6887544989585876
Validation loss: 1.6585639933104157

Epoch: 6| Step: 6
Training loss: 0.3962068259716034
Validation loss: 1.6893552580187399

Epoch: 6| Step: 7
Training loss: 0.7565838098526001
Validation loss: 1.682485867572087

Epoch: 6| Step: 8
Training loss: 0.406872421503067
Validation loss: 1.6636978669833111

Epoch: 6| Step: 9
Training loss: 0.43118226528167725
Validation loss: 1.6781593817536549

Epoch: 6| Step: 10
Training loss: 0.646038293838501
Validation loss: 1.6937447901695006

Epoch: 6| Step: 11
Training loss: 0.8273042440414429
Validation loss: 1.6992379542320006

Epoch: 6| Step: 12
Training loss: 0.48579856753349304
Validation loss: 1.7274700210940452

Epoch: 6| Step: 13
Training loss: 0.8088852167129517
Validation loss: 1.723469526537003

Epoch: 279| Step: 0
Training loss: 0.30118903517723083
Validation loss: 1.728163796086465

Epoch: 6| Step: 1
Training loss: 0.624718189239502
Validation loss: 1.7260339734374837

Epoch: 6| Step: 2
Training loss: 0.3982084393501282
Validation loss: 1.7214270560972151

Epoch: 6| Step: 3
Training loss: 0.44701269268989563
Validation loss: 1.7104107461949831

Epoch: 6| Step: 4
Training loss: 0.3586060404777527
Validation loss: 1.7415556279561852

Epoch: 6| Step: 5
Training loss: 0.5952497720718384
Validation loss: 1.7289800413193241

Epoch: 6| Step: 6
Training loss: 0.9672418236732483
Validation loss: 1.7279777014127342

Epoch: 6| Step: 7
Training loss: 0.5580588579177856
Validation loss: 1.7295140130545503

Epoch: 6| Step: 8
Training loss: 0.5748617053031921
Validation loss: 1.743241984357116

Epoch: 6| Step: 9
Training loss: 0.7238984107971191
Validation loss: 1.7139546589184833

Epoch: 6| Step: 10
Training loss: 0.5083342790603638
Validation loss: 1.6997791054428264

Epoch: 6| Step: 11
Training loss: 0.6457703113555908
Validation loss: 1.7123836804461736

Epoch: 6| Step: 12
Training loss: 0.5233870148658752
Validation loss: 1.6757536498449181

Epoch: 6| Step: 13
Training loss: 1.0525012016296387
Validation loss: 1.6851396265850271

Epoch: 280| Step: 0
Training loss: 0.5781850814819336
Validation loss: 1.6754726235584547

Epoch: 6| Step: 1
Training loss: 0.6407677531242371
Validation loss: 1.7131781462700135

Epoch: 6| Step: 2
Training loss: 0.6066411137580872
Validation loss: 1.7194431161367765

Epoch: 6| Step: 3
Training loss: 0.43608716130256653
Validation loss: 1.7477447114964968

Epoch: 6| Step: 4
Training loss: 0.6047402620315552
Validation loss: 1.7388271003641107

Epoch: 6| Step: 5
Training loss: 0.6426888704299927
Validation loss: 1.763842459647886

Epoch: 6| Step: 6
Training loss: 0.3865956962108612
Validation loss: 1.799017842097949

Epoch: 6| Step: 7
Training loss: 1.174726128578186
Validation loss: 1.7980838847416702

Epoch: 6| Step: 8
Training loss: 0.47711485624313354
Validation loss: 1.802229319849322

Epoch: 6| Step: 9
Training loss: 0.6406747698783875
Validation loss: 1.8288135079927341

Epoch: 6| Step: 10
Training loss: 0.515511155128479
Validation loss: 1.8108739083813084

Epoch: 6| Step: 11
Training loss: 0.5808795690536499
Validation loss: 1.7305123485544676

Epoch: 6| Step: 12
Training loss: 0.3810745179653168
Validation loss: 1.7498247866989465

Epoch: 6| Step: 13
Training loss: 0.704727292060852
Validation loss: 1.7266764358807636

Epoch: 281| Step: 0
Training loss: 0.4336198568344116
Validation loss: 1.7384526703947334

Epoch: 6| Step: 1
Training loss: 0.5770643949508667
Validation loss: 1.7486205152285996

Epoch: 6| Step: 2
Training loss: 0.5008441805839539
Validation loss: 1.7320488293965657

Epoch: 6| Step: 3
Training loss: 0.4369067847728729
Validation loss: 1.7281049015701457

Epoch: 6| Step: 4
Training loss: 0.8690007328987122
Validation loss: 1.7475296489654049

Epoch: 6| Step: 5
Training loss: 0.44989705085754395
Validation loss: 1.7455342174858175

Epoch: 6| Step: 6
Training loss: 0.493481308221817
Validation loss: 1.7585522308144519

Epoch: 6| Step: 7
Training loss: 0.4265657067298889
Validation loss: 1.7543333512480541

Epoch: 6| Step: 8
Training loss: 0.4019361138343811
Validation loss: 1.7677617355059552

Epoch: 6| Step: 9
Training loss: 0.6670162677764893
Validation loss: 1.7838299428263018

Epoch: 6| Step: 10
Training loss: 0.5339717268943787
Validation loss: 1.7686585482730661

Epoch: 6| Step: 11
Training loss: 1.0210342407226562
Validation loss: 1.774908645178682

Epoch: 6| Step: 12
Training loss: 0.4573064148426056
Validation loss: 1.7487630587752148

Epoch: 6| Step: 13
Training loss: 0.5781526565551758
Validation loss: 1.7912342599643174

Epoch: 282| Step: 0
Training loss: 0.2293340265750885
Validation loss: 1.8193510681070306

Epoch: 6| Step: 1
Training loss: 1.1131559610366821
Validation loss: 1.8137403739395963

Epoch: 6| Step: 2
Training loss: 0.6417394876480103
Validation loss: 1.8196766094494892

Epoch: 6| Step: 3
Training loss: 0.6732959151268005
Validation loss: 1.8220575958169916

Epoch: 6| Step: 4
Training loss: 0.753894567489624
Validation loss: 1.8045284953168643

Epoch: 6| Step: 5
Training loss: 0.3675304055213928
Validation loss: 1.7977118530581075

Epoch: 6| Step: 6
Training loss: 0.32908689975738525
Validation loss: 1.7625841991875761

Epoch: 6| Step: 7
Training loss: 0.5939534902572632
Validation loss: 1.7505933289886804

Epoch: 6| Step: 8
Training loss: 0.602844774723053
Validation loss: 1.6924360849524056

Epoch: 6| Step: 9
Training loss: 0.6235677003860474
Validation loss: 1.7103181436497679

Epoch: 6| Step: 10
Training loss: 0.3458484411239624
Validation loss: 1.6887520949045818

Epoch: 6| Step: 11
Training loss: 0.5433646440505981
Validation loss: 1.701493009444206

Epoch: 6| Step: 12
Training loss: 0.46526196599006653
Validation loss: 1.6651207939271004

Epoch: 6| Step: 13
Training loss: 0.6962204575538635
Validation loss: 1.683705004312659

Epoch: 283| Step: 0
Training loss: 0.4063720703125
Validation loss: 1.6843507520614132

Epoch: 6| Step: 1
Training loss: 0.8370434045791626
Validation loss: 1.701082775669713

Epoch: 6| Step: 2
Training loss: 0.5161632299423218
Validation loss: 1.7375454466830018

Epoch: 6| Step: 3
Training loss: 0.8632121682167053
Validation loss: 1.7328772121860134

Epoch: 6| Step: 4
Training loss: 0.4192470908164978
Validation loss: 1.7443114288391606

Epoch: 6| Step: 5
Training loss: 0.6585263609886169
Validation loss: 1.7523985960150277

Epoch: 6| Step: 6
Training loss: 0.38527151942253113
Validation loss: 1.7504113502399896

Epoch: 6| Step: 7
Training loss: 0.3820067048072815
Validation loss: 1.7635554921242498

Epoch: 6| Step: 8
Training loss: 0.6158452033996582
Validation loss: 1.732851900080199

Epoch: 6| Step: 9
Training loss: 0.8599275946617126
Validation loss: 1.7440272979838873

Epoch: 6| Step: 10
Training loss: 0.3428182005882263
Validation loss: 1.7170595135740054

Epoch: 6| Step: 11
Training loss: 0.3844442069530487
Validation loss: 1.7420683701833088

Epoch: 6| Step: 12
Training loss: 0.4802511930465698
Validation loss: 1.7388541070363854

Epoch: 6| Step: 13
Training loss: 0.801508367061615
Validation loss: 1.709470764283211

Epoch: 284| Step: 0
Training loss: 0.6182584762573242
Validation loss: 1.720233021243926

Epoch: 6| Step: 1
Training loss: 0.4459494650363922
Validation loss: 1.7258698389094362

Epoch: 6| Step: 2
Training loss: 0.5532644987106323
Validation loss: 1.7523368891849314

Epoch: 6| Step: 3
Training loss: 0.7760077118873596
Validation loss: 1.7061895631974744

Epoch: 6| Step: 4
Training loss: 0.43462806940078735
Validation loss: 1.682321999662666

Epoch: 6| Step: 5
Training loss: 0.7203470468521118
Validation loss: 1.685684319465391

Epoch: 6| Step: 6
Training loss: 0.3863712549209595
Validation loss: 1.696998889728259

Epoch: 6| Step: 7
Training loss: 0.5911273956298828
Validation loss: 1.6929542813249814

Epoch: 6| Step: 8
Training loss: 0.3600403070449829
Validation loss: 1.701245387395223

Epoch: 6| Step: 9
Training loss: 0.5852768421173096
Validation loss: 1.7269754909699964

Epoch: 6| Step: 10
Training loss: 0.3890828490257263
Validation loss: 1.7336838668392551

Epoch: 6| Step: 11
Training loss: 0.5154017210006714
Validation loss: 1.7064452735326623

Epoch: 6| Step: 12
Training loss: 0.7800726294517517
Validation loss: 1.7072435463628461

Epoch: 6| Step: 13
Training loss: 0.5022367835044861
Validation loss: 1.6944133171471216

Epoch: 285| Step: 0
Training loss: 0.5073092579841614
Validation loss: 1.709967013328306

Epoch: 6| Step: 1
Training loss: 0.7578913569450378
Validation loss: 1.7280747993018037

Epoch: 6| Step: 2
Training loss: 0.5597530603408813
Validation loss: 1.6925903892004361

Epoch: 6| Step: 3
Training loss: 0.7670528888702393
Validation loss: 1.665800335586712

Epoch: 6| Step: 4
Training loss: 0.4286792278289795
Validation loss: 1.6981432668624385

Epoch: 6| Step: 5
Training loss: 0.7005808353424072
Validation loss: 1.6869996401571459

Epoch: 6| Step: 6
Training loss: 0.46695682406425476
Validation loss: 1.6722193738465667

Epoch: 6| Step: 7
Training loss: 0.3389040529727936
Validation loss: 1.7065180629812262

Epoch: 6| Step: 8
Training loss: 0.5795613527297974
Validation loss: 1.6814133903031707

Epoch: 6| Step: 9
Training loss: 0.6112531423568726
Validation loss: 1.6916638497383363

Epoch: 6| Step: 10
Training loss: 0.6777356863021851
Validation loss: 1.7103811028183147

Epoch: 6| Step: 11
Training loss: 0.4506981670856476
Validation loss: 1.7444158407949633

Epoch: 6| Step: 12
Training loss: 0.4232726991176605
Validation loss: 1.7065326065145514

Epoch: 6| Step: 13
Training loss: 0.39698949456214905
Validation loss: 1.7257994990194998

Epoch: 286| Step: 0
Training loss: 0.6451013088226318
Validation loss: 1.6850417531946653

Epoch: 6| Step: 1
Training loss: 0.40046459436416626
Validation loss: 1.6710601737422328

Epoch: 6| Step: 2
Training loss: 0.7523308396339417
Validation loss: 1.6882765113666494

Epoch: 6| Step: 3
Training loss: 0.432749480009079
Validation loss: 1.7119909140371508

Epoch: 6| Step: 4
Training loss: 0.6486039161682129
Validation loss: 1.7254467356589533

Epoch: 6| Step: 5
Training loss: 0.8002674579620361
Validation loss: 1.7318950019856936

Epoch: 6| Step: 6
Training loss: 0.6132680773735046
Validation loss: 1.7121593862451532

Epoch: 6| Step: 7
Training loss: 0.5819138288497925
Validation loss: 1.6806312709726312

Epoch: 6| Step: 8
Training loss: 0.521303653717041
Validation loss: 1.6721625404973184

Epoch: 6| Step: 9
Training loss: 0.36283764243125916
Validation loss: 1.6686549186706543

Epoch: 6| Step: 10
Training loss: 0.12825870513916016
Validation loss: 1.6981313792608117

Epoch: 6| Step: 11
Training loss: 0.20544809103012085
Validation loss: 1.7072837096388622

Epoch: 6| Step: 12
Training loss: 1.0454094409942627
Validation loss: 1.6850845711205595

Epoch: 6| Step: 13
Training loss: 0.6708700060844421
Validation loss: 1.683747765838459

Epoch: 287| Step: 0
Training loss: 0.5595155954360962
Validation loss: 1.6476386747052592

Epoch: 6| Step: 1
Training loss: 0.5076119899749756
Validation loss: 1.6388500211059407

Epoch: 6| Step: 2
Training loss: 0.5589186549186707
Validation loss: 1.6576778888702393

Epoch: 6| Step: 3
Training loss: 0.3940367102622986
Validation loss: 1.649246802894018

Epoch: 6| Step: 4
Training loss: 0.6023837327957153
Validation loss: 1.6630720130858883

Epoch: 6| Step: 5
Training loss: 0.5299606323242188
Validation loss: 1.6829462359028478

Epoch: 6| Step: 6
Training loss: 0.6299670934677124
Validation loss: 1.7006497780481975

Epoch: 6| Step: 7
Training loss: 0.36609986424446106
Validation loss: 1.7189031134369552

Epoch: 6| Step: 8
Training loss: 0.7520574331283569
Validation loss: 1.7138242029374646

Epoch: 6| Step: 9
Training loss: 0.336029589176178
Validation loss: 1.7266417267501994

Epoch: 6| Step: 10
Training loss: 0.531532883644104
Validation loss: 1.732752166768556

Epoch: 6| Step: 11
Training loss: 0.4692268669605255
Validation loss: 1.7283143292191208

Epoch: 6| Step: 12
Training loss: 0.5895164012908936
Validation loss: 1.715917362961718

Epoch: 6| Step: 13
Training loss: 0.4564815163612366
Validation loss: 1.6925876191867295

Epoch: 288| Step: 0
Training loss: 0.6027085781097412
Validation loss: 1.655285668629472

Epoch: 6| Step: 1
Training loss: 0.5910748243331909
Validation loss: 1.6719325152776574

Epoch: 6| Step: 2
Training loss: 0.7430201768875122
Validation loss: 1.6629121367649367

Epoch: 6| Step: 3
Training loss: 0.5668990612030029
Validation loss: 1.6382897976906068

Epoch: 6| Step: 4
Training loss: 0.681169867515564
Validation loss: 1.6297002953867759

Epoch: 6| Step: 5
Training loss: 0.39706242084503174
Validation loss: 1.631995516438638

Epoch: 6| Step: 6
Training loss: 0.31361472606658936
Validation loss: 1.6888986377305881

Epoch: 6| Step: 7
Training loss: 0.5122807025909424
Validation loss: 1.664498274044324

Epoch: 6| Step: 8
Training loss: 0.503384530544281
Validation loss: 1.6957212212265178

Epoch: 6| Step: 9
Training loss: 0.3480420708656311
Validation loss: 1.704620143418671

Epoch: 6| Step: 10
Training loss: 0.48423752188682556
Validation loss: 1.7092345324895715

Epoch: 6| Step: 11
Training loss: 0.42375287413597107
Validation loss: 1.7415979498176164

Epoch: 6| Step: 12
Training loss: 0.6006718873977661
Validation loss: 1.6962044777408722

Epoch: 6| Step: 13
Training loss: 0.48836618661880493
Validation loss: 1.7254273122356785

Epoch: 289| Step: 0
Training loss: 0.5164410471916199
Validation loss: 1.722527596258348

Epoch: 6| Step: 1
Training loss: 0.25146737694740295
Validation loss: 1.7083975807312997

Epoch: 6| Step: 2
Training loss: 0.7126358151435852
Validation loss: 1.674594945805047

Epoch: 6| Step: 3
Training loss: 0.5303709506988525
Validation loss: 1.693695722087737

Epoch: 6| Step: 4
Training loss: 0.38805678486824036
Validation loss: 1.6765439574436476

Epoch: 6| Step: 5
Training loss: 0.39839935302734375
Validation loss: 1.6979649912926458

Epoch: 6| Step: 6
Training loss: 0.5616378784179688
Validation loss: 1.681946853155731

Epoch: 6| Step: 7
Training loss: 0.6356784105300903
Validation loss: 1.6739123687949231

Epoch: 6| Step: 8
Training loss: 0.43465521931648254
Validation loss: 1.6732276383266653

Epoch: 6| Step: 9
Training loss: 0.32781779766082764
Validation loss: 1.6782909362546858

Epoch: 6| Step: 10
Training loss: 0.5691872835159302
Validation loss: 1.6737913559841853

Epoch: 6| Step: 11
Training loss: 0.5036901235580444
Validation loss: 1.6715140111984745

Epoch: 6| Step: 12
Training loss: 0.6054501533508301
Validation loss: 1.6855180571156163

Epoch: 6| Step: 13
Training loss: 0.2590276002883911
Validation loss: 1.666106302251098

Epoch: 290| Step: 0
Training loss: 0.342292457818985
Validation loss: 1.6807714418698383

Epoch: 6| Step: 1
Training loss: 0.6851056218147278
Validation loss: 1.671730226086032

Epoch: 6| Step: 2
Training loss: 0.5782252550125122
Validation loss: 1.6593652386819162

Epoch: 6| Step: 3
Training loss: 0.35203057527542114
Validation loss: 1.6725065656887588

Epoch: 6| Step: 4
Training loss: 0.41653814911842346
Validation loss: 1.686465819676717

Epoch: 6| Step: 5
Training loss: 0.5146582126617432
Validation loss: 1.6958361325725433

Epoch: 6| Step: 6
Training loss: 0.608676552772522
Validation loss: 1.6893726202749437

Epoch: 6| Step: 7
Training loss: 0.5577459335327148
Validation loss: 1.7141622074188725

Epoch: 6| Step: 8
Training loss: 0.47103437781333923
Validation loss: 1.7172784728388633

Epoch: 6| Step: 9
Training loss: 0.45096099376678467
Validation loss: 1.7108566927653488

Epoch: 6| Step: 10
Training loss: 0.31534191966056824
Validation loss: 1.7273595538190616

Epoch: 6| Step: 11
Training loss: 0.6349223256111145
Validation loss: 1.7138452170997538

Epoch: 6| Step: 12
Training loss: 0.6655109524726868
Validation loss: 1.7142066212110623

Epoch: 6| Step: 13
Training loss: 0.23333559930324554
Validation loss: 1.707086391346429

Epoch: 291| Step: 0
Training loss: 0.34520938992500305
Validation loss: 1.7164711452299548

Epoch: 6| Step: 1
Training loss: 0.4077489972114563
Validation loss: 1.6749161571584723

Epoch: 6| Step: 2
Training loss: 0.5188010334968567
Validation loss: 1.7106642338537401

Epoch: 6| Step: 3
Training loss: 0.5332779884338379
Validation loss: 1.676187563967961

Epoch: 6| Step: 4
Training loss: 0.29602813720703125
Validation loss: 1.708733791946083

Epoch: 6| Step: 5
Training loss: 0.4798455536365509
Validation loss: 1.6640814876043668

Epoch: 6| Step: 6
Training loss: 0.5648066997528076
Validation loss: 1.7119407410262732

Epoch: 6| Step: 7
Training loss: 0.4445435106754303
Validation loss: 1.6607415112116004

Epoch: 6| Step: 8
Training loss: 0.3400224447250366
Validation loss: 1.6818308496987948

Epoch: 6| Step: 9
Training loss: 0.3581535220146179
Validation loss: 1.6618895979337795

Epoch: 6| Step: 10
Training loss: 0.6657587289810181
Validation loss: 1.6772226787382556

Epoch: 6| Step: 11
Training loss: 0.5260971784591675
Validation loss: 1.6559304729584725

Epoch: 6| Step: 12
Training loss: 0.5267912149429321
Validation loss: 1.6820916642424881

Epoch: 6| Step: 13
Training loss: 0.5894614458084106
Validation loss: 1.6821595520101569

Epoch: 292| Step: 0
Training loss: 0.44801807403564453
Validation loss: 1.685339104744696

Epoch: 6| Step: 1
Training loss: 0.489950567483902
Validation loss: 1.7053737384016796

Epoch: 6| Step: 2
Training loss: 0.4190603494644165
Validation loss: 1.7109603676744687

Epoch: 6| Step: 3
Training loss: 0.7541354894638062
Validation loss: 1.6993483228068198

Epoch: 6| Step: 4
Training loss: 0.4069962203502655
Validation loss: 1.7309760085998043

Epoch: 6| Step: 5
Training loss: 0.2946631908416748
Validation loss: 1.6890730345120994

Epoch: 6| Step: 6
Training loss: 0.5803579092025757
Validation loss: 1.69110627840924

Epoch: 6| Step: 7
Training loss: 0.2930268347263336
Validation loss: 1.7069041472609325

Epoch: 6| Step: 8
Training loss: 0.5801969766616821
Validation loss: 1.6695444891529698

Epoch: 6| Step: 9
Training loss: 0.3615714907646179
Validation loss: 1.6674198027580016

Epoch: 6| Step: 10
Training loss: 0.5181759595870972
Validation loss: 1.6801210020178108

Epoch: 6| Step: 11
Training loss: 0.6804640293121338
Validation loss: 1.6356388138186546

Epoch: 6| Step: 12
Training loss: 0.35845616459846497
Validation loss: 1.6243589847318587

Epoch: 6| Step: 13
Training loss: 0.512955904006958
Validation loss: 1.6085927063418972

Epoch: 293| Step: 0
Training loss: 0.732850193977356
Validation loss: 1.6302889059948664

Epoch: 6| Step: 1
Training loss: 0.31072670221328735
Validation loss: 1.6255874492788827

Epoch: 6| Step: 2
Training loss: 0.398609459400177
Validation loss: 1.6527179030961887

Epoch: 6| Step: 3
Training loss: 0.5830070972442627
Validation loss: 1.6923026051572574

Epoch: 6| Step: 4
Training loss: 0.30087190866470337
Validation loss: 1.6562914873964043

Epoch: 6| Step: 5
Training loss: 0.7734672427177429
Validation loss: 1.6832228258091917

Epoch: 6| Step: 6
Training loss: 0.36408531665802
Validation loss: 1.6993528514780023

Epoch: 6| Step: 7
Training loss: 0.5188161730766296
Validation loss: 1.6808586428242345

Epoch: 6| Step: 8
Training loss: 0.38969454169273376
Validation loss: 1.6841661019991803

Epoch: 6| Step: 9
Training loss: 0.5006546378135681
Validation loss: 1.6697550409583635

Epoch: 6| Step: 10
Training loss: 0.5814076662063599
Validation loss: 1.7016416518918929

Epoch: 6| Step: 11
Training loss: 0.3880658745765686
Validation loss: 1.6969614695477229

Epoch: 6| Step: 12
Training loss: 0.3956723213195801
Validation loss: 1.6803699667735765

Epoch: 6| Step: 13
Training loss: 0.3450023829936981
Validation loss: 1.7145056737366544

Epoch: 294| Step: 0
Training loss: 0.41925543546676636
Validation loss: 1.6682693176372076

Epoch: 6| Step: 1
Training loss: 0.43066832423210144
Validation loss: 1.6456759706620248

Epoch: 6| Step: 2
Training loss: 0.359716534614563
Validation loss: 1.6478111846472627

Epoch: 6| Step: 3
Training loss: 0.5851866006851196
Validation loss: 1.677947675028155

Epoch: 6| Step: 4
Training loss: 0.29825857281684875
Validation loss: 1.684535785387921

Epoch: 6| Step: 5
Training loss: 0.4929351210594177
Validation loss: 1.6795660090702835

Epoch: 6| Step: 6
Training loss: 0.352813720703125
Validation loss: 1.641726706617622

Epoch: 6| Step: 7
Training loss: 0.6291435956954956
Validation loss: 1.6110389668454406

Epoch: 6| Step: 8
Training loss: 0.8428882360458374
Validation loss: 1.6812661437578098

Epoch: 6| Step: 9
Training loss: 0.5851524472236633
Validation loss: 1.6733232204632094

Epoch: 6| Step: 10
Training loss: 0.5392694473266602
Validation loss: 1.6780203170673822

Epoch: 6| Step: 11
Training loss: 0.6052951216697693
Validation loss: 1.7099230609914309

Epoch: 6| Step: 12
Training loss: 0.4147831201553345
Validation loss: 1.6658276396413003

Epoch: 6| Step: 13
Training loss: 0.405947208404541
Validation loss: 1.7007752644118441

Epoch: 295| Step: 0
Training loss: 0.42423877120018005
Validation loss: 1.6927455612408218

Epoch: 6| Step: 1
Training loss: 0.5117949843406677
Validation loss: 1.7042636493200898

Epoch: 6| Step: 2
Training loss: 0.3887217938899994
Validation loss: 1.6935647187694427

Epoch: 6| Step: 3
Training loss: 0.4903814196586609
Validation loss: 1.707000890085774

Epoch: 6| Step: 4
Training loss: 0.5659389495849609
Validation loss: 1.6803336495994239

Epoch: 6| Step: 5
Training loss: 0.5691124200820923
Validation loss: 1.717571299563172

Epoch: 6| Step: 6
Training loss: 0.4100402593612671
Validation loss: 1.7089575259916243

Epoch: 6| Step: 7
Training loss: 0.3953419029712677
Validation loss: 1.7270549933115642

Epoch: 6| Step: 8
Training loss: 0.5730931162834167
Validation loss: 1.727201045200389

Epoch: 6| Step: 9
Training loss: 1.0614356994628906
Validation loss: 1.7060920692259265

Epoch: 6| Step: 10
Training loss: 0.5545212030410767
Validation loss: 1.6394143848009006

Epoch: 6| Step: 11
Training loss: 0.45109638571739197
Validation loss: 1.6470315661481632

Epoch: 6| Step: 12
Training loss: 0.44075554609298706
Validation loss: 1.6763458880045081

Epoch: 6| Step: 13
Training loss: 0.2447744756937027
Validation loss: 1.6433685633444017

Epoch: 296| Step: 0
Training loss: 0.4298751950263977
Validation loss: 1.6468611878733481

Epoch: 6| Step: 1
Training loss: 0.31822383403778076
Validation loss: 1.658967935910789

Epoch: 6| Step: 2
Training loss: 0.4941854178905487
Validation loss: 1.6463753126000846

Epoch: 6| Step: 3
Training loss: 0.5865843296051025
Validation loss: 1.6784845577773226

Epoch: 6| Step: 4
Training loss: 0.4634285271167755
Validation loss: 1.6676069946699246

Epoch: 6| Step: 5
Training loss: 0.5428706407546997
Validation loss: 1.6730025096606183

Epoch: 6| Step: 6
Training loss: 0.39157429337501526
Validation loss: 1.6515657581308836

Epoch: 6| Step: 7
Training loss: 0.27559223771095276
Validation loss: 1.6772797466606222

Epoch: 6| Step: 8
Training loss: 0.552126407623291
Validation loss: 1.6909303972798009

Epoch: 6| Step: 9
Training loss: 0.532752513885498
Validation loss: 1.6710652112960815

Epoch: 6| Step: 10
Training loss: 0.4723408818244934
Validation loss: 1.7124206532714188

Epoch: 6| Step: 11
Training loss: 0.5225359201431274
Validation loss: 1.754402135008125

Epoch: 6| Step: 12
Training loss: 0.47064104676246643
Validation loss: 1.7051218402001165

Epoch: 6| Step: 13
Training loss: 0.5857837796211243
Validation loss: 1.7386683020540463

Epoch: 297| Step: 0
Training loss: 0.4749961793422699
Validation loss: 1.7194088223159953

Epoch: 6| Step: 1
Training loss: 0.5156456232070923
Validation loss: 1.7671591915110105

Epoch: 6| Step: 2
Training loss: 0.2733002305030823
Validation loss: 1.7566034947672198

Epoch: 6| Step: 3
Training loss: 0.7680932879447937
Validation loss: 1.6865800760125602

Epoch: 6| Step: 4
Training loss: 0.5255975723266602
Validation loss: 1.7024916013081868

Epoch: 6| Step: 5
Training loss: 0.28999629616737366
Validation loss: 1.606482127020436

Epoch: 6| Step: 6
Training loss: 0.39160072803497314
Validation loss: 1.6730156713916409

Epoch: 6| Step: 7
Training loss: 0.3074514865875244
Validation loss: 1.6490178210760957

Epoch: 6| Step: 8
Training loss: 0.5456186532974243
Validation loss: 1.6351516503159718

Epoch: 6| Step: 9
Training loss: 0.5342035293579102
Validation loss: 1.6293799300347604

Epoch: 6| Step: 10
Training loss: 0.399391770362854
Validation loss: 1.5979263987592471

Epoch: 6| Step: 11
Training loss: 0.6200675964355469
Validation loss: 1.638234257698059

Epoch: 6| Step: 12
Training loss: 0.5525444746017456
Validation loss: 1.6505915785348544

Epoch: 6| Step: 13
Training loss: 0.20557913184165955
Validation loss: 1.6567548398048646

Epoch: 298| Step: 0
Training loss: 0.4192679226398468
Validation loss: 1.6914297976801473

Epoch: 6| Step: 1
Training loss: 0.6128624677658081
Validation loss: 1.6875005101644864

Epoch: 6| Step: 2
Training loss: 0.3649788498878479
Validation loss: 1.6837464968363445

Epoch: 6| Step: 3
Training loss: 0.3961981534957886
Validation loss: 1.6357954112432336

Epoch: 6| Step: 4
Training loss: 0.22742532193660736
Validation loss: 1.6758524141004008

Epoch: 6| Step: 5
Training loss: 0.8428921699523926
Validation loss: 1.6608362146603164

Epoch: 6| Step: 6
Training loss: 0.4896138310432434
Validation loss: 1.6856353385474092

Epoch: 6| Step: 7
Training loss: 0.47384506464004517
Validation loss: 1.6907429374674314

Epoch: 6| Step: 8
Training loss: 0.5299708247184753
Validation loss: 1.6942211761269519

Epoch: 6| Step: 9
Training loss: 0.5070386528968811
Validation loss: 1.702983307582076

Epoch: 6| Step: 10
Training loss: 0.29054856300354004
Validation loss: 1.7060960159506848

Epoch: 6| Step: 11
Training loss: 0.2962629795074463
Validation loss: 1.668290966300554

Epoch: 6| Step: 12
Training loss: 0.6381380558013916
Validation loss: 1.6735090427501227

Epoch: 6| Step: 13
Training loss: 0.8663129806518555
Validation loss: 1.681860940430754

Epoch: 299| Step: 0
Training loss: 0.3699289560317993
Validation loss: 1.6684957499145179

Epoch: 6| Step: 1
Training loss: 0.48733294010162354
Validation loss: 1.6861972180745934

Epoch: 6| Step: 2
Training loss: 0.6021393537521362
Validation loss: 1.6247209105440366

Epoch: 6| Step: 3
Training loss: 0.42117854952812195
Validation loss: 1.6526907054326867

Epoch: 6| Step: 4
Training loss: 0.826621949672699
Validation loss: 1.6451697118820683

Epoch: 6| Step: 5
Training loss: 0.17359304428100586
Validation loss: 1.6271253580688148

Epoch: 6| Step: 6
Training loss: 0.4455817937850952
Validation loss: 1.5997760129231278

Epoch: 6| Step: 7
Training loss: 0.30885201692581177
Validation loss: 1.6392762225161317

Epoch: 6| Step: 8
Training loss: 0.4677470326423645
Validation loss: 1.624590289208197

Epoch: 6| Step: 9
Training loss: 0.4545157551765442
Validation loss: 1.6156060221374675

Epoch: 6| Step: 10
Training loss: 0.5131186246871948
Validation loss: 1.6235570766592538

Epoch: 6| Step: 11
Training loss: 0.38199836015701294
Validation loss: 1.6700997583327755

Epoch: 6| Step: 12
Training loss: 0.36519724130630493
Validation loss: 1.6148962807911698

Epoch: 6| Step: 13
Training loss: 0.3854473829269409
Validation loss: 1.6475061985754198

Epoch: 300| Step: 0
Training loss: 0.49738115072250366
Validation loss: 1.6401162224431192

Epoch: 6| Step: 1
Training loss: 0.3107413351535797
Validation loss: 1.6829544972347956

Epoch: 6| Step: 2
Training loss: 0.4054096043109894
Validation loss: 1.6690265427353561

Epoch: 6| Step: 3
Training loss: 0.5505201816558838
Validation loss: 1.698159921553827

Epoch: 6| Step: 4
Training loss: 0.35809558629989624
Validation loss: 1.647185294858871

Epoch: 6| Step: 5
Training loss: 0.7530704140663147
Validation loss: 1.6771190397201046

Epoch: 6| Step: 6
Training loss: 0.45063892006874084
Validation loss: 1.6585744683460524

Epoch: 6| Step: 7
Training loss: 0.5127379894256592
Validation loss: 1.6747802752320484

Epoch: 6| Step: 8
Training loss: 0.2104380875825882
Validation loss: 1.6549856098749305

Epoch: 6| Step: 9
Training loss: 0.46700790524482727
Validation loss: 1.6779170420862013

Epoch: 6| Step: 10
Training loss: 0.513418436050415
Validation loss: 1.6484070375401487

Epoch: 6| Step: 11
Training loss: 0.37252068519592285
Validation loss: 1.6677596671606905

Epoch: 6| Step: 12
Training loss: 0.3172960579395294
Validation loss: 1.6854620684859574

Epoch: 6| Step: 13
Training loss: 0.34310320019721985
Validation loss: 1.6679053075851933

Epoch: 301| Step: 0
Training loss: 0.5278977155685425
Validation loss: 1.6677625269018195

Epoch: 6| Step: 1
Training loss: 0.46854063868522644
Validation loss: 1.6634265517675748

Epoch: 6| Step: 2
Training loss: 0.43149685859680176
Validation loss: 1.6585824220411238

Epoch: 6| Step: 3
Training loss: 0.28003114461898804
Validation loss: 1.6864237836612168

Epoch: 6| Step: 4
Training loss: 0.4786457121372223
Validation loss: 1.6324390493413454

Epoch: 6| Step: 5
Training loss: 0.2841700315475464
Validation loss: 1.644500183802779

Epoch: 6| Step: 6
Training loss: 0.35757094621658325
Validation loss: 1.6540435001414309

Epoch: 6| Step: 7
Training loss: 0.4407200217247009
Validation loss: 1.644984209409324

Epoch: 6| Step: 8
Training loss: 0.48505187034606934
Validation loss: 1.6442184794333674

Epoch: 6| Step: 9
Training loss: 0.3355448544025421
Validation loss: 1.646935882106904

Epoch: 6| Step: 10
Training loss: 0.6314511895179749
Validation loss: 1.6075825216949626

Epoch: 6| Step: 11
Training loss: 0.5139090418815613
Validation loss: 1.6111779187315254

Epoch: 6| Step: 12
Training loss: 0.5534783005714417
Validation loss: 1.6486504872639973

Epoch: 6| Step: 13
Training loss: 0.3785278797149658
Validation loss: 1.586826547499626

Epoch: 302| Step: 0
Training loss: 0.4267910122871399
Validation loss: 1.602633366020777

Epoch: 6| Step: 1
Training loss: 0.3547590672969818
Validation loss: 1.5972045647200717

Epoch: 6| Step: 2
Training loss: 0.18259237706661224
Validation loss: 1.6431717334255096

Epoch: 6| Step: 3
Training loss: 0.5642754435539246
Validation loss: 1.6417399132123558

Epoch: 6| Step: 4
Training loss: 0.4312283396720886
Validation loss: 1.6485850298276512

Epoch: 6| Step: 5
Training loss: 0.4588407576084137
Validation loss: 1.6412583807463288

Epoch: 6| Step: 6
Training loss: 0.41093581914901733
Validation loss: 1.6270024622640302

Epoch: 6| Step: 7
Training loss: 0.5130846500396729
Validation loss: 1.6088911993529207

Epoch: 6| Step: 8
Training loss: 0.44465720653533936
Validation loss: 1.603925698546953

Epoch: 6| Step: 9
Training loss: 0.4537624418735504
Validation loss: 1.616431652858693

Epoch: 6| Step: 10
Training loss: 0.44876784086227417
Validation loss: 1.6099710618295977

Epoch: 6| Step: 11
Training loss: 0.5651059150695801
Validation loss: 1.5925660620453537

Epoch: 6| Step: 12
Training loss: 0.3787018060684204
Validation loss: 1.6340942754540393

Epoch: 6| Step: 13
Training loss: 0.539194643497467
Validation loss: 1.6055869017877886

Epoch: 303| Step: 0
Training loss: 0.4499964416027069
Validation loss: 1.6416419424036497

Epoch: 6| Step: 1
Training loss: 0.4833073914051056
Validation loss: 1.6215714959688083

Epoch: 6| Step: 2
Training loss: 0.5019174218177795
Validation loss: 1.6331439723250687

Epoch: 6| Step: 3
Training loss: 0.39974746108055115
Validation loss: 1.629363085633965

Epoch: 6| Step: 4
Training loss: 0.3997143507003784
Validation loss: 1.6343150151673185

Epoch: 6| Step: 5
Training loss: 0.39783257246017456
Validation loss: 1.6194955943733134

Epoch: 6| Step: 6
Training loss: 0.7055162191390991
Validation loss: 1.6647117701909875

Epoch: 6| Step: 7
Training loss: 0.26904669404029846
Validation loss: 1.640975950866617

Epoch: 6| Step: 8
Training loss: 0.43977195024490356
Validation loss: 1.6365465835858417

Epoch: 6| Step: 9
Training loss: 0.3256181478500366
Validation loss: 1.6118471558376024

Epoch: 6| Step: 10
Training loss: 0.45876604318618774
Validation loss: 1.572950073467788

Epoch: 6| Step: 11
Training loss: 0.2799530029296875
Validation loss: 1.6301659063626361

Epoch: 6| Step: 12
Training loss: 0.44818976521492004
Validation loss: 1.6139072346430954

Epoch: 6| Step: 13
Training loss: 0.4623151421546936
Validation loss: 1.6452106006683842

Epoch: 304| Step: 0
Training loss: 0.632362425327301
Validation loss: 1.6356576027408722

Epoch: 6| Step: 1
Training loss: 0.5117592811584473
Validation loss: 1.6388396396431872

Epoch: 6| Step: 2
Training loss: 0.4090389013290405
Validation loss: 1.6460265780007968

Epoch: 6| Step: 3
Training loss: 0.28801557421684265
Validation loss: 1.6352580772933138

Epoch: 6| Step: 4
Training loss: 0.5453509092330933
Validation loss: 1.6389567179064597

Epoch: 6| Step: 5
Training loss: 0.4750553071498871
Validation loss: 1.6488677365805513

Epoch: 6| Step: 6
Training loss: 0.39469167590141296
Validation loss: 1.6692761913422616

Epoch: 6| Step: 7
Training loss: 0.48654189705848694
Validation loss: 1.6378695298266668

Epoch: 6| Step: 8
Training loss: 0.3708243668079376
Validation loss: 1.6333289236150763

Epoch: 6| Step: 9
Training loss: 0.4436018168926239
Validation loss: 1.634643800797001

Epoch: 6| Step: 10
Training loss: 0.3179396986961365
Validation loss: 1.6349652057052941

Epoch: 6| Step: 11
Training loss: 0.6496962308883667
Validation loss: 1.6301630427760463

Epoch: 6| Step: 12
Training loss: 0.3427339792251587
Validation loss: 1.6282689225289129

Epoch: 6| Step: 13
Training loss: 0.14106495678424835
Validation loss: 1.6400455082616499

Epoch: 305| Step: 0
Training loss: 0.32887861132621765
Validation loss: 1.6395972672329153

Epoch: 6| Step: 1
Training loss: 0.20177868008613586
Validation loss: 1.6431887893266575

Epoch: 6| Step: 2
Training loss: 0.6163879632949829
Validation loss: 1.6776900778534591

Epoch: 6| Step: 3
Training loss: 0.3559913635253906
Validation loss: 1.6903554098580473

Epoch: 6| Step: 4
Training loss: 0.5636049509048462
Validation loss: 1.7044884632992487

Epoch: 6| Step: 5
Training loss: 0.40302130579948425
Validation loss: 1.712945822746523

Epoch: 6| Step: 6
Training loss: 0.531821072101593
Validation loss: 1.6907305743104668

Epoch: 6| Step: 7
Training loss: 0.4452293813228607
Validation loss: 1.702602824857158

Epoch: 6| Step: 8
Training loss: 0.3915784955024719
Validation loss: 1.676734314169935

Epoch: 6| Step: 9
Training loss: 0.4710894525051117
Validation loss: 1.6609147043638333

Epoch: 6| Step: 10
Training loss: 0.5318048000335693
Validation loss: 1.6601716754257039

Epoch: 6| Step: 11
Training loss: 0.3386434316635132
Validation loss: 1.6565735724664503

Epoch: 6| Step: 12
Training loss: 0.39754435420036316
Validation loss: 1.6482760662673621

Epoch: 6| Step: 13
Training loss: 0.3577679991722107
Validation loss: 1.630903906719659

Epoch: 306| Step: 0
Training loss: 0.44688066840171814
Validation loss: 1.64051192550249

Epoch: 6| Step: 1
Training loss: 0.2979534864425659
Validation loss: 1.6411903673602688

Epoch: 6| Step: 2
Training loss: 0.4213094115257263
Validation loss: 1.62668348896888

Epoch: 6| Step: 3
Training loss: 0.29388943314552307
Validation loss: 1.6395228806362356

Epoch: 6| Step: 4
Training loss: 0.3417910635471344
Validation loss: 1.6643630868645125

Epoch: 6| Step: 5
Training loss: 0.20819595456123352
Validation loss: 1.6567474360107093

Epoch: 6| Step: 6
Training loss: 0.485409677028656
Validation loss: 1.65627731046369

Epoch: 6| Step: 7
Training loss: 0.3657095432281494
Validation loss: 1.6521047148653256

Epoch: 6| Step: 8
Training loss: 0.35859715938568115
Validation loss: 1.6714487857716058

Epoch: 6| Step: 9
Training loss: 0.6321452856063843
Validation loss: 1.6758307833825388

Epoch: 6| Step: 10
Training loss: 0.43282240629196167
Validation loss: 1.6850717554810226

Epoch: 6| Step: 11
Training loss: 0.6664605140686035
Validation loss: 1.7149665804319485

Epoch: 6| Step: 12
Training loss: 0.3275544047355652
Validation loss: 1.6496967782256424

Epoch: 6| Step: 13
Training loss: 0.6384910941123962
Validation loss: 1.6509455070700696

Epoch: 307| Step: 0
Training loss: 0.37733936309814453
Validation loss: 1.6417956352233887

Epoch: 6| Step: 1
Training loss: 0.1536518633365631
Validation loss: 1.6340737099288611

Epoch: 6| Step: 2
Training loss: 0.4568729102611542
Validation loss: 1.6446327035145094

Epoch: 6| Step: 3
Training loss: 0.47392797470092773
Validation loss: 1.6508923486996723

Epoch: 6| Step: 4
Training loss: 0.5614069700241089
Validation loss: 1.6891580845720024

Epoch: 6| Step: 5
Training loss: 0.5344033241271973
Validation loss: 1.6457303929072555

Epoch: 6| Step: 6
Training loss: 0.44440796971321106
Validation loss: 1.6231609954628894

Epoch: 6| Step: 7
Training loss: 0.2828904986381531
Validation loss: 1.6139164240129533

Epoch: 6| Step: 8
Training loss: 0.2980220317840576
Validation loss: 1.6318554814143846

Epoch: 6| Step: 9
Training loss: 0.3624121844768524
Validation loss: 1.63254766438597

Epoch: 6| Step: 10
Training loss: 0.6887917518615723
Validation loss: 1.5899205605189006

Epoch: 6| Step: 11
Training loss: 0.2981047034263611
Validation loss: 1.6400729751074186

Epoch: 6| Step: 12
Training loss: 0.38888776302337646
Validation loss: 1.6630962984536284

Epoch: 6| Step: 13
Training loss: 0.28276193141937256
Validation loss: 1.6463181959685458

Epoch: 308| Step: 0
Training loss: 0.3461506962776184
Validation loss: 1.648210713940282

Epoch: 6| Step: 1
Training loss: 0.3575325608253479
Validation loss: 1.6628369105759488

Epoch: 6| Step: 2
Training loss: 0.5584492683410645
Validation loss: 1.6454721330314555

Epoch: 6| Step: 3
Training loss: 0.36628976464271545
Validation loss: 1.6512419600640573

Epoch: 6| Step: 4
Training loss: 0.3762857913970947
Validation loss: 1.6283152962243685

Epoch: 6| Step: 5
Training loss: 0.3234458863735199
Validation loss: 1.6483014886097243

Epoch: 6| Step: 6
Training loss: 0.41478028893470764
Validation loss: 1.6383493843898977

Epoch: 6| Step: 7
Training loss: 0.38339918851852417
Validation loss: 1.638947852196232

Epoch: 6| Step: 8
Training loss: 0.411396861076355
Validation loss: 1.6228899353293962

Epoch: 6| Step: 9
Training loss: 0.2841033935546875
Validation loss: 1.618025650260269

Epoch: 6| Step: 10
Training loss: 0.5427794456481934
Validation loss: 1.6182827071477008

Epoch: 6| Step: 11
Training loss: 0.27752405405044556
Validation loss: 1.595690345251432

Epoch: 6| Step: 12
Training loss: 0.4535733163356781
Validation loss: 1.6010007473730272

Epoch: 6| Step: 13
Training loss: 0.3074730336666107
Validation loss: 1.5704848945781749

Epoch: 309| Step: 0
Training loss: 0.3235551118850708
Validation loss: 1.5657620147992206

Epoch: 6| Step: 1
Training loss: 0.25793972611427307
Validation loss: 1.6009475915662703

Epoch: 6| Step: 2
Training loss: 0.28361940383911133
Validation loss: 1.5958072331643873

Epoch: 6| Step: 3
Training loss: 0.5131770372390747
Validation loss: 1.6014517199608587

Epoch: 6| Step: 4
Training loss: 0.2612369954586029
Validation loss: 1.6461004525102594

Epoch: 6| Step: 5
Training loss: 0.36742353439331055
Validation loss: 1.652457820471897

Epoch: 6| Step: 6
Training loss: 0.7820655107498169
Validation loss: 1.6608933723101051

Epoch: 6| Step: 7
Training loss: 0.2590905725955963
Validation loss: 1.6708810431982881

Epoch: 6| Step: 8
Training loss: 0.4661000370979309
Validation loss: 1.614717298938382

Epoch: 6| Step: 9
Training loss: 0.6249555945396423
Validation loss: 1.6293208868272844

Epoch: 6| Step: 10
Training loss: 0.3642891049385071
Validation loss: 1.5869804043923654

Epoch: 6| Step: 11
Training loss: 0.26044145226478577
Validation loss: 1.6085337746527888

Epoch: 6| Step: 12
Training loss: 0.3559141755104065
Validation loss: 1.5976262066953926

Epoch: 6| Step: 13
Training loss: 0.4217633903026581
Validation loss: 1.5895504618203768

Epoch: 310| Step: 0
Training loss: 0.4559897482395172
Validation loss: 1.5889348849173515

Epoch: 6| Step: 1
Training loss: 0.37704700231552124
Validation loss: 1.6031793535396617

Epoch: 6| Step: 2
Training loss: 0.3811472952365875
Validation loss: 1.6144410987054147

Epoch: 6| Step: 3
Training loss: 0.2766416072845459
Validation loss: 1.60761212148974

Epoch: 6| Step: 4
Training loss: 0.45098409056663513
Validation loss: 1.6530804582821426

Epoch: 6| Step: 5
Training loss: 0.43203601241111755
Validation loss: 1.6659040335685975

Epoch: 6| Step: 6
Training loss: 0.6383057832717896
Validation loss: 1.6733831385130524

Epoch: 6| Step: 7
Training loss: 0.34597551822662354
Validation loss: 1.6995297285818285

Epoch: 6| Step: 8
Training loss: 0.5835689306259155
Validation loss: 1.6749295239807458

Epoch: 6| Step: 9
Training loss: 0.5004031658172607
Validation loss: 1.6707634515659784

Epoch: 6| Step: 10
Training loss: 0.3172420263290405
Validation loss: 1.6587365365797473

Epoch: 6| Step: 11
Training loss: 0.5538674592971802
Validation loss: 1.6295550433538293

Epoch: 6| Step: 12
Training loss: 0.3481253981590271
Validation loss: 1.6432545197907316

Epoch: 6| Step: 13
Training loss: 0.3586549162864685
Validation loss: 1.5950431593002812

Epoch: 311| Step: 0
Training loss: 0.6270962953567505
Validation loss: 1.5856441105565717

Epoch: 6| Step: 1
Training loss: 0.5647798776626587
Validation loss: 1.5945140828368485

Epoch: 6| Step: 2
Training loss: 0.41945940256118774
Validation loss: 1.6181378877291115

Epoch: 6| Step: 3
Training loss: 0.26784345507621765
Validation loss: 1.6615345798512942

Epoch: 6| Step: 4
Training loss: 0.40450096130371094
Validation loss: 1.7065910190664313

Epoch: 6| Step: 5
Training loss: 0.37914422154426575
Validation loss: 1.6742334699118009

Epoch: 6| Step: 6
Training loss: 0.5703206062316895
Validation loss: 1.6648891702775033

Epoch: 6| Step: 7
Training loss: 0.3881767988204956
Validation loss: 1.6565942879646056

Epoch: 6| Step: 8
Training loss: 0.21258193254470825
Validation loss: 1.657192155879031

Epoch: 6| Step: 9
Training loss: 0.5696922540664673
Validation loss: 1.6246249560386903

Epoch: 6| Step: 10
Training loss: 0.43710047006607056
Validation loss: 1.6320437141644057

Epoch: 6| Step: 11
Training loss: 0.3379351496696472
Validation loss: 1.6588763408763434

Epoch: 6| Step: 12
Training loss: 0.41726142168045044
Validation loss: 1.635990869614386

Epoch: 6| Step: 13
Training loss: 0.5708297491073608
Validation loss: 1.5981214713024836

Epoch: 312| Step: 0
Training loss: 0.4707961082458496
Validation loss: 1.6179527339114939

Epoch: 6| Step: 1
Training loss: 0.27423954010009766
Validation loss: 1.6248733176979968

Epoch: 6| Step: 2
Training loss: 0.50177001953125
Validation loss: 1.6082386752610565

Epoch: 6| Step: 3
Training loss: 0.23955336213111877
Validation loss: 1.6309800635101974

Epoch: 6| Step: 4
Training loss: 0.3531961143016815
Validation loss: 1.6220212610819007

Epoch: 6| Step: 5
Training loss: 0.49485933780670166
Validation loss: 1.5901171520192137

Epoch: 6| Step: 6
Training loss: 0.39571845531463623
Validation loss: 1.6200384862961308

Epoch: 6| Step: 7
Training loss: 0.3050907850265503
Validation loss: 1.6352377527503557

Epoch: 6| Step: 8
Training loss: 0.38473445177078247
Validation loss: 1.5894115958162534

Epoch: 6| Step: 9
Training loss: 0.6581720113754272
Validation loss: 1.6433718345498527

Epoch: 6| Step: 10
Training loss: 0.3158506155014038
Validation loss: 1.6521112585580477

Epoch: 6| Step: 11
Training loss: 0.2271633893251419
Validation loss: 1.6465187316299768

Epoch: 6| Step: 12
Training loss: 0.6337481737136841
Validation loss: 1.701933148086712

Epoch: 6| Step: 13
Training loss: 0.4411393404006958
Validation loss: 1.6628665911254061

Epoch: 313| Step: 0
Training loss: 0.40541142225265503
Validation loss: 1.6962354875379992

Epoch: 6| Step: 1
Training loss: 0.3103359341621399
Validation loss: 1.699026560270658

Epoch: 6| Step: 2
Training loss: 0.32997214794158936
Validation loss: 1.68204491753732

Epoch: 6| Step: 3
Training loss: 0.5929133296012878
Validation loss: 1.6780737523109681

Epoch: 6| Step: 4
Training loss: 0.3326209485530853
Validation loss: 1.6779158192296182

Epoch: 6| Step: 5
Training loss: 0.331356942653656
Validation loss: 1.6461031577920402

Epoch: 6| Step: 6
Training loss: 0.4469563364982605
Validation loss: 1.6136891418887722

Epoch: 6| Step: 7
Training loss: 0.4190370440483093
Validation loss: 1.6085833669990621

Epoch: 6| Step: 8
Training loss: 0.5857496857643127
Validation loss: 1.589687047466155

Epoch: 6| Step: 9
Training loss: 0.3284316062927246
Validation loss: 1.6194863293760566

Epoch: 6| Step: 10
Training loss: 0.4069398045539856
Validation loss: 1.6326878122104111

Epoch: 6| Step: 11
Training loss: 0.3386008143424988
Validation loss: 1.6107344409470916

Epoch: 6| Step: 12
Training loss: 0.352668821811676
Validation loss: 1.6333171648363913

Epoch: 6| Step: 13
Training loss: 0.6526627540588379
Validation loss: 1.648732058463558

Epoch: 314| Step: 0
Training loss: 0.34670352935791016
Validation loss: 1.6320198261609642

Epoch: 6| Step: 1
Training loss: 0.37339383363723755
Validation loss: 1.6292601926352388

Epoch: 6| Step: 2
Training loss: 0.3715137243270874
Validation loss: 1.6494824373593895

Epoch: 6| Step: 3
Training loss: 0.2953847646713257
Validation loss: 1.635749460548483

Epoch: 6| Step: 4
Training loss: 0.36162692308425903
Validation loss: 1.651316051842064

Epoch: 6| Step: 5
Training loss: 0.2805677354335785
Validation loss: 1.6759344352188932

Epoch: 6| Step: 6
Training loss: 0.45452141761779785
Validation loss: 1.6488118940784084

Epoch: 6| Step: 7
Training loss: 0.4610121250152588
Validation loss: 1.6514385156734015

Epoch: 6| Step: 8
Training loss: 0.3509123921394348
Validation loss: 1.6394024959174536

Epoch: 6| Step: 9
Training loss: 0.38035210967063904
Validation loss: 1.6130044152659755

Epoch: 6| Step: 10
Training loss: 0.4573580026626587
Validation loss: 1.6136930629771242

Epoch: 6| Step: 11
Training loss: 0.6446057558059692
Validation loss: 1.6333985546583771

Epoch: 6| Step: 12
Training loss: 0.38034528493881226
Validation loss: 1.6237543436788744

Epoch: 6| Step: 13
Training loss: 0.10989076644182205
Validation loss: 1.6318654244945896

Epoch: 315| Step: 0
Training loss: 0.19265176355838776
Validation loss: 1.6057506402333577

Epoch: 6| Step: 1
Training loss: 0.2961878478527069
Validation loss: 1.6138249943333287

Epoch: 6| Step: 2
Training loss: 0.39046064019203186
Validation loss: 1.5963585351103096

Epoch: 6| Step: 3
Training loss: 0.2740185558795929
Validation loss: 1.5754636192834506

Epoch: 6| Step: 4
Training loss: 0.5432016849517822
Validation loss: 1.5912941143076906

Epoch: 6| Step: 5
Training loss: 0.5629719495773315
Validation loss: 1.571178142742444

Epoch: 6| Step: 6
Training loss: 0.3451334834098816
Validation loss: 1.58680933906186

Epoch: 6| Step: 7
Training loss: 0.36223104596138
Validation loss: 1.5885200244124218

Epoch: 6| Step: 8
Training loss: 0.28050386905670166
Validation loss: 1.5849033145494358

Epoch: 6| Step: 9
Training loss: 0.43771448731422424
Validation loss: 1.623037056256366

Epoch: 6| Step: 10
Training loss: 0.42416438460350037
Validation loss: 1.630037570512423

Epoch: 6| Step: 11
Training loss: 0.43392038345336914
Validation loss: 1.651067800419305

Epoch: 6| Step: 12
Training loss: 0.28691622614860535
Validation loss: 1.6554539511280675

Epoch: 6| Step: 13
Training loss: 0.2071012705564499
Validation loss: 1.6449673765449113

Epoch: 316| Step: 0
Training loss: 0.3054998219013214
Validation loss: 1.6415079229621476

Epoch: 6| Step: 1
Training loss: 0.451596736907959
Validation loss: 1.5981166990854407

Epoch: 6| Step: 2
Training loss: 0.17711569368839264
Validation loss: 1.6159774206017936

Epoch: 6| Step: 3
Training loss: 0.08973141014575958
Validation loss: 1.5819611549377441

Epoch: 6| Step: 4
Training loss: 0.501457929611206
Validation loss: 1.5902935612586238

Epoch: 6| Step: 5
Training loss: 0.41495785117149353
Validation loss: 1.563860031866258

Epoch: 6| Step: 6
Training loss: 0.3744106888771057
Validation loss: 1.5903221375198775

Epoch: 6| Step: 7
Training loss: 0.5636608600616455
Validation loss: 1.6096630865527737

Epoch: 6| Step: 8
Training loss: 0.28752440214157104
Validation loss: 1.5708425314195695

Epoch: 6| Step: 9
Training loss: 0.2690126299858093
Validation loss: 1.5679847309666295

Epoch: 6| Step: 10
Training loss: 0.4740350842475891
Validation loss: 1.57885726036564

Epoch: 6| Step: 11
Training loss: 0.3974810242652893
Validation loss: 1.5648050141590897

Epoch: 6| Step: 12
Training loss: 0.38578203320503235
Validation loss: 1.6135494952560754

Epoch: 6| Step: 13
Training loss: 0.4550133943557739
Validation loss: 1.595083200803367

Epoch: 317| Step: 0
Training loss: 0.3047388792037964
Validation loss: 1.5813304198685514

Epoch: 6| Step: 1
Training loss: 0.405191034078598
Validation loss: 1.5618068287449498

Epoch: 6| Step: 2
Training loss: 0.4118485450744629
Validation loss: 1.5548838607726558

Epoch: 6| Step: 3
Training loss: 0.2921796143054962
Validation loss: 1.5334278396380845

Epoch: 6| Step: 4
Training loss: 0.551550030708313
Validation loss: 1.5470154862250052

Epoch: 6| Step: 5
Training loss: 0.2570587694644928
Validation loss: 1.5204786921060214

Epoch: 6| Step: 6
Training loss: 0.512097179889679
Validation loss: 1.54222152310033

Epoch: 6| Step: 7
Training loss: 0.33163049817085266
Validation loss: 1.5666866071762577

Epoch: 6| Step: 8
Training loss: 0.19566920399665833
Validation loss: 1.5885036171123545

Epoch: 6| Step: 9
Training loss: 0.4314199388027191
Validation loss: 1.5983124843207739

Epoch: 6| Step: 10
Training loss: 0.39421799778938293
Validation loss: 1.625075642780591

Epoch: 6| Step: 11
Training loss: 0.42184561491012573
Validation loss: 1.6179230751529816

Epoch: 6| Step: 12
Training loss: 0.3648903965950012
Validation loss: 1.613015987539804

Epoch: 6| Step: 13
Training loss: 0.3786991238594055
Validation loss: 1.5716542466994254

Epoch: 318| Step: 0
Training loss: 0.5741162896156311
Validation loss: 1.5588667713185793

Epoch: 6| Step: 1
Training loss: 0.315890371799469
Validation loss: 1.5705300428534066

Epoch: 6| Step: 2
Training loss: 0.5471262335777283
Validation loss: 1.5527242909195602

Epoch: 6| Step: 3
Training loss: 0.19774237275123596
Validation loss: 1.521732585404509

Epoch: 6| Step: 4
Training loss: 0.47448262572288513
Validation loss: 1.5546011911925448

Epoch: 6| Step: 5
Training loss: 0.280855268239975
Validation loss: 1.5731421362969182

Epoch: 6| Step: 6
Training loss: 0.20815476775169373
Validation loss: 1.5447314529008762

Epoch: 6| Step: 7
Training loss: 0.2883896827697754
Validation loss: 1.5583413057429816

Epoch: 6| Step: 8
Training loss: 0.3939414918422699
Validation loss: 1.5642065873710058

Epoch: 6| Step: 9
Training loss: 0.28815263509750366
Validation loss: 1.5838020245234172

Epoch: 6| Step: 10
Training loss: 0.3231818377971649
Validation loss: 1.5997100940314672

Epoch: 6| Step: 11
Training loss: 0.20035886764526367
Validation loss: 1.6165291801575692

Epoch: 6| Step: 12
Training loss: 0.5455597639083862
Validation loss: 1.618028716374469

Epoch: 6| Step: 13
Training loss: 0.54365074634552
Validation loss: 1.5933704914585236

Epoch: 319| Step: 0
Training loss: 0.6756983399391174
Validation loss: 1.5913034485232445

Epoch: 6| Step: 1
Training loss: 0.34917333722114563
Validation loss: 1.6041716670477262

Epoch: 6| Step: 2
Training loss: 0.2551349997520447
Validation loss: 1.5975358845085226

Epoch: 6| Step: 3
Training loss: 0.3581051230430603
Validation loss: 1.6325821338161346

Epoch: 6| Step: 4
Training loss: 0.44266247749328613
Validation loss: 1.6070420870216944

Epoch: 6| Step: 5
Training loss: 0.23473069071769714
Validation loss: 1.6243856850490774

Epoch: 6| Step: 6
Training loss: 0.22289636731147766
Validation loss: 1.6072898603254748

Epoch: 6| Step: 7
Training loss: 0.37129950523376465
Validation loss: 1.6126842037323983

Epoch: 6| Step: 8
Training loss: 0.3879896402359009
Validation loss: 1.597919362847523

Epoch: 6| Step: 9
Training loss: 0.4589366912841797
Validation loss: 1.6091875927422636

Epoch: 6| Step: 10
Training loss: 0.31161344051361084
Validation loss: 1.6175538186104066

Epoch: 6| Step: 11
Training loss: 0.3135840892791748
Validation loss: 1.6228091537311513

Epoch: 6| Step: 12
Training loss: 0.4092477262020111
Validation loss: 1.6011829991494455

Epoch: 6| Step: 13
Training loss: 0.11039689928293228
Validation loss: 1.5836718633610716

Epoch: 320| Step: 0
Training loss: 0.40008679032325745
Validation loss: 1.593592495046636

Epoch: 6| Step: 1
Training loss: 0.3373236358165741
Validation loss: 1.614301637936664

Epoch: 6| Step: 2
Training loss: 0.3908957242965698
Validation loss: 1.6163656019395398

Epoch: 6| Step: 3
Training loss: 0.4114477038383484
Validation loss: 1.6080995400746663

Epoch: 6| Step: 4
Training loss: 0.43475133180618286
Validation loss: 1.6035818066648257

Epoch: 6| Step: 5
Training loss: 0.47699761390686035
Validation loss: 1.6051601350948375

Epoch: 6| Step: 6
Training loss: 0.26359209418296814
Validation loss: 1.6196003383205784

Epoch: 6| Step: 7
Training loss: 0.26102688908576965
Validation loss: 1.6357109982480285

Epoch: 6| Step: 8
Training loss: 0.6615358591079712
Validation loss: 1.651576329303044

Epoch: 6| Step: 9
Training loss: 0.40583696961402893
Validation loss: 1.6413675251827444

Epoch: 6| Step: 10
Training loss: 0.19415438175201416
Validation loss: 1.6301109201164656

Epoch: 6| Step: 11
Training loss: 0.31453490257263184
Validation loss: 1.5974661278468307

Epoch: 6| Step: 12
Training loss: 0.40591850876808167
Validation loss: 1.6293832166220552

Epoch: 6| Step: 13
Training loss: 0.41673824191093445
Validation loss: 1.5984262907376854

Epoch: 321| Step: 0
Training loss: 0.20078043639659882
Validation loss: 1.6219004700260777

Epoch: 6| Step: 1
Training loss: 0.5213941335678101
Validation loss: 1.6293071008497668

Epoch: 6| Step: 2
Training loss: 0.334772527217865
Validation loss: 1.6093153056278025

Epoch: 6| Step: 3
Training loss: 0.330787718296051
Validation loss: 1.608192322074726

Epoch: 6| Step: 4
Training loss: 0.3700864613056183
Validation loss: 1.6425436363425305

Epoch: 6| Step: 5
Training loss: 0.38261663913726807
Validation loss: 1.582282627782514

Epoch: 6| Step: 6
Training loss: 0.5123214721679688
Validation loss: 1.6036067278154436

Epoch: 6| Step: 7
Training loss: 0.28884392976760864
Validation loss: 1.592368523279826

Epoch: 6| Step: 8
Training loss: 0.42860257625579834
Validation loss: 1.5898673585666123

Epoch: 6| Step: 9
Training loss: 0.1423339545726776
Validation loss: 1.616561661484421

Epoch: 6| Step: 10
Training loss: 0.5518236756324768
Validation loss: 1.6148173373232606

Epoch: 6| Step: 11
Training loss: 0.45312631130218506
Validation loss: 1.6263863066191315

Epoch: 6| Step: 12
Training loss: 0.48194241523742676
Validation loss: 1.6178370073277464

Epoch: 6| Step: 13
Training loss: 0.2010558843612671
Validation loss: 1.6135477071167321

Epoch: 322| Step: 0
Training loss: 0.30537572503089905
Validation loss: 1.5931193405582058

Epoch: 6| Step: 1
Training loss: 0.30938422679901123
Validation loss: 1.600128525046892

Epoch: 6| Step: 2
Training loss: 0.18343102931976318
Validation loss: 1.6011337105945875

Epoch: 6| Step: 3
Training loss: 0.33810827136039734
Validation loss: 1.5771119338209911

Epoch: 6| Step: 4
Training loss: 0.19107523560523987
Validation loss: 1.5808080832163494

Epoch: 6| Step: 5
Training loss: 0.382924884557724
Validation loss: 1.569253615153733

Epoch: 6| Step: 6
Training loss: 0.23583418130874634
Validation loss: 1.6061854285578574

Epoch: 6| Step: 7
Training loss: 0.5802363157272339
Validation loss: 1.5719846346045052

Epoch: 6| Step: 8
Training loss: 0.4189828932285309
Validation loss: 1.6077796643780125

Epoch: 6| Step: 9
Training loss: 0.5325855612754822
Validation loss: 1.589920182381907

Epoch: 6| Step: 10
Training loss: 0.27214866876602173
Validation loss: 1.6111511235596032

Epoch: 6| Step: 11
Training loss: 0.46758005023002625
Validation loss: 1.5745731835724206

Epoch: 6| Step: 12
Training loss: 0.27084919810295105
Validation loss: 1.5966179127334266

Epoch: 6| Step: 13
Training loss: 0.4811401963233948
Validation loss: 1.5795095043797647

Epoch: 323| Step: 0
Training loss: 0.49062907695770264
Validation loss: 1.523885867928946

Epoch: 6| Step: 1
Training loss: 0.4351261258125305
Validation loss: 1.5865621835954729

Epoch: 6| Step: 2
Training loss: 0.38515329360961914
Validation loss: 1.5640458240303943

Epoch: 6| Step: 3
Training loss: 0.29022589325904846
Validation loss: 1.616416774770265

Epoch: 6| Step: 4
Training loss: 0.5022193193435669
Validation loss: 1.6037040782231156

Epoch: 6| Step: 5
Training loss: 0.2313336431980133
Validation loss: 1.5649906909593971

Epoch: 6| Step: 6
Training loss: 0.25951939821243286
Validation loss: 1.5334610067388064

Epoch: 6| Step: 7
Training loss: 0.24777716398239136
Validation loss: 1.5659539597008818

Epoch: 6| Step: 8
Training loss: 0.32341140508651733
Validation loss: 1.545086735038347

Epoch: 6| Step: 9
Training loss: 0.20590195059776306
Validation loss: 1.5719916897435342

Epoch: 6| Step: 10
Training loss: 0.45511868596076965
Validation loss: 1.533793403256324

Epoch: 6| Step: 11
Training loss: 0.3186151385307312
Validation loss: 1.5775497344232374

Epoch: 6| Step: 12
Training loss: 0.3173881769180298
Validation loss: 1.6019667707463747

Epoch: 6| Step: 13
Training loss: 0.44771915674209595
Validation loss: 1.5475884329888128

Epoch: 324| Step: 0
Training loss: 0.4491763710975647
Validation loss: 1.6113468703403269

Epoch: 6| Step: 1
Training loss: 0.4669308364391327
Validation loss: 1.5744854045170609

Epoch: 6| Step: 2
Training loss: 0.35535305738449097
Validation loss: 1.6145863699656662

Epoch: 6| Step: 3
Training loss: 0.43879231810569763
Validation loss: 1.6094701905404367

Epoch: 6| Step: 4
Training loss: 0.2605668008327484
Validation loss: 1.5929484046915525

Epoch: 6| Step: 5
Training loss: 0.27951884269714355
Validation loss: 1.5770166830349994

Epoch: 6| Step: 6
Training loss: 0.3073299825191498
Validation loss: 1.5570522200676702

Epoch: 6| Step: 7
Training loss: 0.12869450449943542
Validation loss: 1.5625628476501794

Epoch: 6| Step: 8
Training loss: 0.26255935430526733
Validation loss: 1.5647408116248347

Epoch: 6| Step: 9
Training loss: 0.18761003017425537
Validation loss: 1.5861118147450108

Epoch: 6| Step: 10
Training loss: 0.27481767535209656
Validation loss: 1.6112376874493015

Epoch: 6| Step: 11
Training loss: 0.2329397201538086
Validation loss: 1.5598345777039886

Epoch: 6| Step: 12
Training loss: 0.4409290552139282
Validation loss: 1.5790610954325686

Epoch: 6| Step: 13
Training loss: 0.6341979503631592
Validation loss: 1.5534824414919781

Epoch: 325| Step: 0
Training loss: 0.39785319566726685
Validation loss: 1.5470530204875494

Epoch: 6| Step: 1
Training loss: 0.20965442061424255
Validation loss: 1.5876534779866536

Epoch: 6| Step: 2
Training loss: 0.2853171229362488
Validation loss: 1.543145413039833

Epoch: 6| Step: 3
Training loss: 0.269997775554657
Validation loss: 1.5311428526396393

Epoch: 6| Step: 4
Training loss: 0.2911826968193054
Validation loss: 1.5449378272538543

Epoch: 6| Step: 5
Training loss: 0.5541640520095825
Validation loss: 1.5464137036313292

Epoch: 6| Step: 6
Training loss: 0.17343787848949432
Validation loss: 1.535326676983987

Epoch: 6| Step: 7
Training loss: 0.3092889189720154
Validation loss: 1.5386670981684039

Epoch: 6| Step: 8
Training loss: 0.3791137933731079
Validation loss: 1.5817127702056721

Epoch: 6| Step: 9
Training loss: 0.37278950214385986
Validation loss: 1.5309270274254583

Epoch: 6| Step: 10
Training loss: 0.4066580533981323
Validation loss: 1.5658506795924196

Epoch: 6| Step: 11
Training loss: 0.37138399481773376
Validation loss: 1.5619330649734826

Epoch: 6| Step: 12
Training loss: 0.3629857897758484
Validation loss: 1.588747153999985

Epoch: 6| Step: 13
Training loss: 0.42833438515663147
Validation loss: 1.5690366786013368

Epoch: 326| Step: 0
Training loss: 0.3024705946445465
Validation loss: 1.5494669483553978

Epoch: 6| Step: 1
Training loss: 0.3748704791069031
Validation loss: 1.6077752395342755

Epoch: 6| Step: 2
Training loss: 0.5896052718162537
Validation loss: 1.6321409876628588

Epoch: 6| Step: 3
Training loss: 0.2874337434768677
Validation loss: 1.6310293680878096

Epoch: 6| Step: 4
Training loss: 0.28468284010887146
Validation loss: 1.5792674544037029

Epoch: 6| Step: 5
Training loss: 0.41551563143730164
Validation loss: 1.5565663768399147

Epoch: 6| Step: 6
Training loss: 0.4108028709888458
Validation loss: 1.5267353801317112

Epoch: 6| Step: 7
Training loss: 0.32771795988082886
Validation loss: 1.5544337123952887

Epoch: 6| Step: 8
Training loss: 0.3414878249168396
Validation loss: 1.558513440111632

Epoch: 6| Step: 9
Training loss: 0.5192352533340454
Validation loss: 1.5533644332680652

Epoch: 6| Step: 10
Training loss: 0.3688836693763733
Validation loss: 1.526441297223491

Epoch: 6| Step: 11
Training loss: 0.25277605652809143
Validation loss: 1.5395837471049318

Epoch: 6| Step: 12
Training loss: 0.4709785580635071
Validation loss: 1.5146833094217445

Epoch: 6| Step: 13
Training loss: 0.48287269473075867
Validation loss: 1.5422083280419792

Epoch: 327| Step: 0
Training loss: 0.28397271037101746
Validation loss: 1.5901432075808126

Epoch: 6| Step: 1
Training loss: 0.3560085892677307
Validation loss: 1.602166134824035

Epoch: 6| Step: 2
Training loss: 0.42148277163505554
Validation loss: 1.6159811122443086

Epoch: 6| Step: 3
Training loss: 0.5855807065963745
Validation loss: 1.6105446495035642

Epoch: 6| Step: 4
Training loss: 0.19299142062664032
Validation loss: 1.5647126333687895

Epoch: 6| Step: 5
Training loss: 0.2605130672454834
Validation loss: 1.5933187341177335

Epoch: 6| Step: 6
Training loss: 0.29773446917533875
Validation loss: 1.585110407362702

Epoch: 6| Step: 7
Training loss: 0.4066695272922516
Validation loss: 1.6060466817630235

Epoch: 6| Step: 8
Training loss: 0.24988599121570587
Validation loss: 1.5903497460067912

Epoch: 6| Step: 9
Training loss: 0.3389362096786499
Validation loss: 1.5955463776024439

Epoch: 6| Step: 10
Training loss: 0.288756400346756
Validation loss: 1.6050310365615352

Epoch: 6| Step: 11
Training loss: 0.43888306617736816
Validation loss: 1.6029675442685363

Epoch: 6| Step: 12
Training loss: 0.2785967290401459
Validation loss: 1.5995546374269711

Epoch: 6| Step: 13
Training loss: 0.4457056224346161
Validation loss: 1.5862161805552821

Epoch: 328| Step: 0
Training loss: 0.5380987524986267
Validation loss: 1.6386826679270754

Epoch: 6| Step: 1
Training loss: 0.4736981689929962
Validation loss: 1.5887773421502882

Epoch: 6| Step: 2
Training loss: 0.2778830826282501
Validation loss: 1.6187364183446413

Epoch: 6| Step: 3
Training loss: 0.2832484245300293
Validation loss: 1.5910505428109118

Epoch: 6| Step: 4
Training loss: 0.38899680972099304
Validation loss: 1.5829669121773011

Epoch: 6| Step: 5
Training loss: 0.3147950768470764
Validation loss: 1.5865314673351985

Epoch: 6| Step: 6
Training loss: 0.272132009267807
Validation loss: 1.5631649314716298

Epoch: 6| Step: 7
Training loss: 0.29382258653640747
Validation loss: 1.5681787447262836

Epoch: 6| Step: 8
Training loss: 0.380843847990036
Validation loss: 1.5627209012226393

Epoch: 6| Step: 9
Training loss: 0.46262919902801514
Validation loss: 1.590074791703173

Epoch: 6| Step: 10
Training loss: 0.1746608018875122
Validation loss: 1.5822434374081191

Epoch: 6| Step: 11
Training loss: 0.3183363080024719
Validation loss: 1.5877013616664435

Epoch: 6| Step: 12
Training loss: 0.21945203840732574
Validation loss: 1.5855942682553363

Epoch: 6| Step: 13
Training loss: 0.40835320949554443
Validation loss: 1.55365490528845

Epoch: 329| Step: 0
Training loss: 0.4842692017555237
Validation loss: 1.6072176207778275

Epoch: 6| Step: 1
Training loss: 0.47313374280929565
Validation loss: 1.6082929129241614

Epoch: 6| Step: 2
Training loss: 0.32413941621780396
Validation loss: 1.6223940708303963

Epoch: 6| Step: 3
Training loss: 0.34642404317855835
Validation loss: 1.651632878088182

Epoch: 6| Step: 4
Training loss: 0.22371822595596313
Validation loss: 1.6389408111572266

Epoch: 6| Step: 5
Training loss: 0.284939169883728
Validation loss: 1.6539794347619499

Epoch: 6| Step: 6
Training loss: 0.28882279992103577
Validation loss: 1.6205528500259563

Epoch: 6| Step: 7
Training loss: 0.30621206760406494
Validation loss: 1.595929826459577

Epoch: 6| Step: 8
Training loss: 0.44180411100387573
Validation loss: 1.609267637293826

Epoch: 6| Step: 9
Training loss: 0.27812615036964417
Validation loss: 1.5886947788218015

Epoch: 6| Step: 10
Training loss: 0.2479887753725052
Validation loss: 1.5631670580115369

Epoch: 6| Step: 11
Training loss: 0.34752020239830017
Validation loss: 1.603607275152719

Epoch: 6| Step: 12
Training loss: 0.1782093048095703
Validation loss: 1.6018573314912858

Epoch: 6| Step: 13
Training loss: 0.5813602209091187
Validation loss: 1.5969965906553372

Epoch: 330| Step: 0
Training loss: 0.33654049038887024
Validation loss: 1.6104296650937808

Epoch: 6| Step: 1
Training loss: 0.3271353840827942
Validation loss: 1.6531473898118543

Epoch: 6| Step: 2
Training loss: 0.34235262870788574
Validation loss: 1.6389987071355183

Epoch: 6| Step: 3
Training loss: 0.4899651110172272
Validation loss: 1.6404116294717277

Epoch: 6| Step: 4
Training loss: 0.24724511802196503
Validation loss: 1.609010273410428

Epoch: 6| Step: 5
Training loss: 0.3463430404663086
Validation loss: 1.6241874079550467

Epoch: 6| Step: 6
Training loss: 0.2403797209262848
Validation loss: 1.6362834694564983

Epoch: 6| Step: 7
Training loss: 0.29653528332710266
Validation loss: 1.6345785625519291

Epoch: 6| Step: 8
Training loss: 0.4573862850666046
Validation loss: 1.663242850252377

Epoch: 6| Step: 9
Training loss: 0.20948085188865662
Validation loss: 1.61555693739204

Epoch: 6| Step: 10
Training loss: 0.3249167501926422
Validation loss: 1.5884465094535583

Epoch: 6| Step: 11
Training loss: 0.22770535945892334
Validation loss: 1.5682727175374185

Epoch: 6| Step: 12
Training loss: 0.5182552933692932
Validation loss: 1.5423387545411305

Epoch: 6| Step: 13
Training loss: 0.4159232974052429
Validation loss: 1.557935578848726

Epoch: 331| Step: 0
Training loss: 0.3137928247451782
Validation loss: 1.5393824372240292

Epoch: 6| Step: 1
Training loss: 0.17110277712345123
Validation loss: 1.5641009461495183

Epoch: 6| Step: 2
Training loss: 0.3862924575805664
Validation loss: 1.57335066282621

Epoch: 6| Step: 3
Training loss: 0.49679380655288696
Validation loss: 1.5634673539028372

Epoch: 6| Step: 4
Training loss: 0.3092533349990845
Validation loss: 1.5579898665028233

Epoch: 6| Step: 5
Training loss: 0.2172280251979828
Validation loss: 1.577115346026677

Epoch: 6| Step: 6
Training loss: 0.19284403324127197
Validation loss: 1.5969555711233487

Epoch: 6| Step: 7
Training loss: 0.17170850932598114
Validation loss: 1.5822729641391384

Epoch: 6| Step: 8
Training loss: 0.3667234182357788
Validation loss: 1.6151896381890902

Epoch: 6| Step: 9
Training loss: 0.4051284193992615
Validation loss: 1.5744871875291229

Epoch: 6| Step: 10
Training loss: 0.38639968633651733
Validation loss: 1.5970226577533189

Epoch: 6| Step: 11
Training loss: 0.35602545738220215
Validation loss: 1.5790647332386305

Epoch: 6| Step: 12
Training loss: 0.2870336174964905
Validation loss: 1.5404612684762606

Epoch: 6| Step: 13
Training loss: 0.3734521269798279
Validation loss: 1.5470716132912585

Epoch: 332| Step: 0
Training loss: 0.2065550535917282
Validation loss: 1.5464602106360978

Epoch: 6| Step: 1
Training loss: 0.32261043787002563
Validation loss: 1.5530749469675043

Epoch: 6| Step: 2
Training loss: 0.31044989824295044
Validation loss: 1.5701259105436263

Epoch: 6| Step: 3
Training loss: 0.3636730909347534
Validation loss: 1.5825356283495504

Epoch: 6| Step: 4
Training loss: 0.40997937321662903
Validation loss: 1.6123370585903045

Epoch: 6| Step: 5
Training loss: 0.3864213228225708
Validation loss: 1.6004301655677058

Epoch: 6| Step: 6
Training loss: 0.2633075416088104
Validation loss: 1.6044091332343318

Epoch: 6| Step: 7
Training loss: 0.1924728900194168
Validation loss: 1.5799372144924697

Epoch: 6| Step: 8
Training loss: 0.4746224880218506
Validation loss: 1.607164308588992

Epoch: 6| Step: 9
Training loss: 0.2912679612636566
Validation loss: 1.6223999223401468

Epoch: 6| Step: 10
Training loss: 0.3439132571220398
Validation loss: 1.6301660089082615

Epoch: 6| Step: 11
Training loss: 0.22006037831306458
Validation loss: 1.6322079550835393

Epoch: 6| Step: 12
Training loss: 0.3400605618953705
Validation loss: 1.6344906783873034

Epoch: 6| Step: 13
Training loss: 0.2985345125198364
Validation loss: 1.6144374673084547

Epoch: 333| Step: 0
Training loss: 0.18751178681850433
Validation loss: 1.5995517315403107

Epoch: 6| Step: 1
Training loss: 0.2969639301300049
Validation loss: 1.6123507304858136

Epoch: 6| Step: 2
Training loss: 0.23098468780517578
Validation loss: 1.5693008066505514

Epoch: 6| Step: 3
Training loss: 0.42455989122390747
Validation loss: 1.6224840917894918

Epoch: 6| Step: 4
Training loss: 0.2745340168476105
Validation loss: 1.5667346895381968

Epoch: 6| Step: 5
Training loss: 0.26690956950187683
Validation loss: 1.5935663766758417

Epoch: 6| Step: 6
Training loss: 0.16110776364803314
Validation loss: 1.5758594402702906

Epoch: 6| Step: 7
Training loss: 0.36080265045166016
Validation loss: 1.5740839230116976

Epoch: 6| Step: 8
Training loss: 0.2718964219093323
Validation loss: 1.5808992975501603

Epoch: 6| Step: 9
Training loss: 0.5500410795211792
Validation loss: 1.584964039505169

Epoch: 6| Step: 10
Training loss: 0.18507692217826843
Validation loss: 1.5580583451896586

Epoch: 6| Step: 11
Training loss: 0.2805728614330292
Validation loss: 1.535686069919217

Epoch: 6| Step: 12
Training loss: 0.4628693461418152
Validation loss: 1.5702858971011253

Epoch: 6| Step: 13
Training loss: 0.3626304864883423
Validation loss: 1.5542238937911166

Epoch: 334| Step: 0
Training loss: 0.2737007141113281
Validation loss: 1.5623532033735705

Epoch: 6| Step: 1
Training loss: 0.40990278124809265
Validation loss: 1.57129120057629

Epoch: 6| Step: 2
Training loss: 0.27154064178466797
Validation loss: 1.5668006071480371

Epoch: 6| Step: 3
Training loss: 0.2809228301048279
Validation loss: 1.6105347551325315

Epoch: 6| Step: 4
Training loss: 0.2332201451063156
Validation loss: 1.5965682204051683

Epoch: 6| Step: 5
Training loss: 0.3678496181964874
Validation loss: 1.6188373117036716

Epoch: 6| Step: 6
Training loss: 0.17452572286128998
Validation loss: 1.5986616457662275

Epoch: 6| Step: 7
Training loss: 0.43474334478378296
Validation loss: 1.5954078346170404

Epoch: 6| Step: 8
Training loss: 0.2324497103691101
Validation loss: 1.5711029473171438

Epoch: 6| Step: 9
Training loss: 0.34200137853622437
Validation loss: 1.5482356394490888

Epoch: 6| Step: 10
Training loss: 0.3230111598968506
Validation loss: 1.5920873213839788

Epoch: 6| Step: 11
Training loss: 0.25544244050979614
Validation loss: 1.5185423974067933

Epoch: 6| Step: 12
Training loss: 0.3599039316177368
Validation loss: 1.5621513910191034

Epoch: 6| Step: 13
Training loss: 0.25422757863998413
Validation loss: 1.5377116741672638

Epoch: 335| Step: 0
Training loss: 0.16424649953842163
Validation loss: 1.5733401634359871

Epoch: 6| Step: 1
Training loss: 0.3889111876487732
Validation loss: 1.6143349498830817

Epoch: 6| Step: 2
Training loss: 0.3296244740486145
Validation loss: 1.6194274669052453

Epoch: 6| Step: 3
Training loss: 0.17037786543369293
Validation loss: 1.6047468441788868

Epoch: 6| Step: 4
Training loss: 0.2988891303539276
Validation loss: 1.5417826098780478

Epoch: 6| Step: 5
Training loss: 0.4226093292236328
Validation loss: 1.5675799462103075

Epoch: 6| Step: 6
Training loss: 0.22540265321731567
Validation loss: 1.5547833032505487

Epoch: 6| Step: 7
Training loss: 0.3027955889701843
Validation loss: 1.5431653863640242

Epoch: 6| Step: 8
Training loss: 0.3493257164955139
Validation loss: 1.539899637622218

Epoch: 6| Step: 9
Training loss: 0.19014552235603333
Validation loss: 1.5513816290004279

Epoch: 6| Step: 10
Training loss: 0.32201290130615234
Validation loss: 1.5301820360204226

Epoch: 6| Step: 11
Training loss: 0.4679464101791382
Validation loss: 1.5823321957742014

Epoch: 6| Step: 12
Training loss: 0.3288646340370178
Validation loss: 1.5803382063424716

Epoch: 6| Step: 13
Training loss: 0.5330430269241333
Validation loss: 1.5865630744605936

Epoch: 336| Step: 0
Training loss: 0.4269725978374481
Validation loss: 1.5932951845148557

Epoch: 6| Step: 1
Training loss: 0.5363936424255371
Validation loss: 1.5921844769549627

Epoch: 6| Step: 2
Training loss: 0.35398799180984497
Validation loss: 1.5843278156813754

Epoch: 6| Step: 3
Training loss: 0.31121090054512024
Validation loss: 1.5571600955019715

Epoch: 6| Step: 4
Training loss: 0.2203294336795807
Validation loss: 1.5470979611078899

Epoch: 6| Step: 5
Training loss: 0.21464397013187408
Validation loss: 1.564859869659588

Epoch: 6| Step: 6
Training loss: 0.22475990653038025
Validation loss: 1.5617191483897548

Epoch: 6| Step: 7
Training loss: 0.2752271592617035
Validation loss: 1.5536691142666725

Epoch: 6| Step: 8
Training loss: 0.20127040147781372
Validation loss: 1.536923659745083

Epoch: 6| Step: 9
Training loss: 0.24906253814697266
Validation loss: 1.5494598675799627

Epoch: 6| Step: 10
Training loss: 0.36709412932395935
Validation loss: 1.5642304638380646

Epoch: 6| Step: 11
Training loss: 0.2427673041820526
Validation loss: 1.591990165812995

Epoch: 6| Step: 12
Training loss: 0.33107858896255493
Validation loss: 1.5701466728282232

Epoch: 6| Step: 13
Training loss: 0.3319045305252075
Validation loss: 1.5643130540847778

Epoch: 337| Step: 0
Training loss: 0.4671434164047241
Validation loss: 1.5563488647501955

Epoch: 6| Step: 1
Training loss: 0.20883573591709137
Validation loss: 1.5165625297895042

Epoch: 6| Step: 2
Training loss: 0.28930217027664185
Validation loss: 1.5435809255928121

Epoch: 6| Step: 3
Training loss: 0.21642063558101654
Validation loss: 1.5475566797359015

Epoch: 6| Step: 4
Training loss: 0.32777243852615356
Validation loss: 1.5604249482513757

Epoch: 6| Step: 5
Training loss: 0.2580367624759674
Validation loss: 1.5522927122731363

Epoch: 6| Step: 6
Training loss: 0.3978917598724365
Validation loss: 1.5441832516783027

Epoch: 6| Step: 7
Training loss: 0.18409395217895508
Validation loss: 1.5481203012568976

Epoch: 6| Step: 8
Training loss: 0.2867490351200104
Validation loss: 1.5344422286556614

Epoch: 6| Step: 9
Training loss: 0.19810712337493896
Validation loss: 1.5563916743442576

Epoch: 6| Step: 10
Training loss: 0.4140506684780121
Validation loss: 1.5528175497567782

Epoch: 6| Step: 11
Training loss: 0.3615294098854065
Validation loss: 1.5349794472417524

Epoch: 6| Step: 12
Training loss: 0.24825027585029602
Validation loss: 1.5490439848233295

Epoch: 6| Step: 13
Training loss: 0.3279677629470825
Validation loss: 1.5638951665611678

Epoch: 338| Step: 0
Training loss: 0.33178335428237915
Validation loss: 1.5712371410862092

Epoch: 6| Step: 1
Training loss: 0.20841719210147858
Validation loss: 1.5833103733678018

Epoch: 6| Step: 2
Training loss: 0.2384040653705597
Validation loss: 1.5888470039572766

Epoch: 6| Step: 3
Training loss: 0.31305110454559326
Validation loss: 1.5821962664204259

Epoch: 6| Step: 4
Training loss: 0.4853011965751648
Validation loss: 1.6170996395490502

Epoch: 6| Step: 5
Training loss: 0.16215580701828003
Validation loss: 1.5818168104335826

Epoch: 6| Step: 6
Training loss: 0.312669575214386
Validation loss: 1.6212755300665413

Epoch: 6| Step: 7
Training loss: 0.22855523228645325
Validation loss: 1.675178591923047

Epoch: 6| Step: 8
Training loss: 0.23772087693214417
Validation loss: 1.6634731664452502

Epoch: 6| Step: 9
Training loss: 0.44721609354019165
Validation loss: 1.6539471482717862

Epoch: 6| Step: 10
Training loss: 0.29208511114120483
Validation loss: 1.6657328887652325

Epoch: 6| Step: 11
Training loss: 0.2833687663078308
Validation loss: 1.6472744659710956

Epoch: 6| Step: 12
Training loss: 0.25038883090019226
Validation loss: 1.6159011869020359

Epoch: 6| Step: 13
Training loss: 0.12214411795139313
Validation loss: 1.6019737361579813

Epoch: 339| Step: 0
Training loss: 0.23237816989421844
Validation loss: 1.5805933513948995

Epoch: 6| Step: 1
Training loss: 0.19224591553211212
Validation loss: 1.5959400259038454

Epoch: 6| Step: 2
Training loss: 0.3690377175807953
Validation loss: 1.5743978972076087

Epoch: 6| Step: 3
Training loss: 0.45071980357170105
Validation loss: 1.5802915878193353

Epoch: 6| Step: 4
Training loss: 0.14704424142837524
Validation loss: 1.5509680035293743

Epoch: 6| Step: 5
Training loss: 0.41774696111679077
Validation loss: 1.547822513887959

Epoch: 6| Step: 6
Training loss: 0.41531509160995483
Validation loss: 1.5651022407316393

Epoch: 6| Step: 7
Training loss: 0.2799760699272156
Validation loss: 1.5976875853794876

Epoch: 6| Step: 8
Training loss: 0.2667351961135864
Validation loss: 1.5743648505979968

Epoch: 6| Step: 9
Training loss: 0.24106988310813904
Validation loss: 1.5731685353863625

Epoch: 6| Step: 10
Training loss: 0.16377468407154083
Validation loss: 1.5659386855299755

Epoch: 6| Step: 11
Training loss: 0.28334808349609375
Validation loss: 1.584164031090275

Epoch: 6| Step: 12
Training loss: 0.47160792350769043
Validation loss: 1.6214185260957288

Epoch: 6| Step: 13
Training loss: 0.34297338128089905
Validation loss: 1.6135539854726484

Epoch: 340| Step: 0
Training loss: 0.1199173852801323
Validation loss: 1.614241966637232

Epoch: 6| Step: 1
Training loss: 0.21736295521259308
Validation loss: 1.6128834338598355

Epoch: 6| Step: 2
Training loss: 0.2901497781276703
Validation loss: 1.6554342059678928

Epoch: 6| Step: 3
Training loss: 0.3591461479663849
Validation loss: 1.65494736548393

Epoch: 6| Step: 4
Training loss: 0.19449296593666077
Validation loss: 1.6138635719976118

Epoch: 6| Step: 5
Training loss: 0.22628577053546906
Validation loss: 1.6257943543054725

Epoch: 6| Step: 6
Training loss: 0.30360838770866394
Validation loss: 1.6070299840742541

Epoch: 6| Step: 7
Training loss: 0.42862915992736816
Validation loss: 1.5789721306934152

Epoch: 6| Step: 8
Training loss: 0.49319005012512207
Validation loss: 1.5898482171438073

Epoch: 6| Step: 9
Training loss: 0.4266417324542999
Validation loss: 1.5841839826235207

Epoch: 6| Step: 10
Training loss: 0.25183629989624023
Validation loss: 1.582109720476212

Epoch: 6| Step: 11
Training loss: 0.2564083933830261
Validation loss: 1.5817306400627218

Epoch: 6| Step: 12
Training loss: 0.24258291721343994
Validation loss: 1.5865472606433335

Epoch: 6| Step: 13
Training loss: 0.25970250368118286
Validation loss: 1.574720891573096

Epoch: 341| Step: 0
Training loss: 0.18404464423656464
Validation loss: 1.594091203904921

Epoch: 6| Step: 1
Training loss: 0.291454553604126
Validation loss: 1.6025255059683194

Epoch: 6| Step: 2
Training loss: 0.37200576066970825
Validation loss: 1.5890794172081897

Epoch: 6| Step: 3
Training loss: 0.439967542886734
Validation loss: 1.6300829225970852

Epoch: 6| Step: 4
Training loss: 0.23717939853668213
Validation loss: 1.6176892057541878

Epoch: 6| Step: 5
Training loss: 0.3447338342666626
Validation loss: 1.6040042549051263

Epoch: 6| Step: 6
Training loss: 0.42512232065200806
Validation loss: 1.5915134030003701

Epoch: 6| Step: 7
Training loss: 0.24383006989955902
Validation loss: 1.5906422035668486

Epoch: 6| Step: 8
Training loss: 0.2925252318382263
Validation loss: 1.5477091227808306

Epoch: 6| Step: 9
Training loss: 0.19590172171592712
Validation loss: 1.5610347396583968

Epoch: 6| Step: 10
Training loss: 0.439691424369812
Validation loss: 1.580959471323157

Epoch: 6| Step: 11
Training loss: 0.2837153971195221
Validation loss: 1.5439884278082079

Epoch: 6| Step: 12
Training loss: 0.2920709550380707
Validation loss: 1.5540602950639621

Epoch: 6| Step: 13
Training loss: 0.19542263448238373
Validation loss: 1.5787565515887352

Epoch: 342| Step: 0
Training loss: 0.21212753653526306
Validation loss: 1.5876588462501444

Epoch: 6| Step: 1
Training loss: 0.2659807801246643
Validation loss: 1.5854408933270363

Epoch: 6| Step: 2
Training loss: 0.3075926899909973
Validation loss: 1.5318029003758584

Epoch: 6| Step: 3
Training loss: 0.21230509877204895
Validation loss: 1.5598142018882177

Epoch: 6| Step: 4
Training loss: 0.2024606615304947
Validation loss: 1.567676233348026

Epoch: 6| Step: 5
Training loss: 0.38725489377975464
Validation loss: 1.5609245672020862

Epoch: 6| Step: 6
Training loss: 0.13356223702430725
Validation loss: 1.5447517171982796

Epoch: 6| Step: 7
Training loss: 0.4845467209815979
Validation loss: 1.578935165559092

Epoch: 6| Step: 8
Training loss: 0.5446306467056274
Validation loss: 1.6129640699714742

Epoch: 6| Step: 9
Training loss: 0.2886706292629242
Validation loss: 1.6065075243673017

Epoch: 6| Step: 10
Training loss: 0.2189551293849945
Validation loss: 1.5708844930894914

Epoch: 6| Step: 11
Training loss: 0.48070892691612244
Validation loss: 1.5794206819226664

Epoch: 6| Step: 12
Training loss: 0.2589842975139618
Validation loss: 1.5746619739840109

Epoch: 6| Step: 13
Training loss: 0.2767118811607361
Validation loss: 1.5753060335754066

Epoch: 343| Step: 0
Training loss: 0.1998613476753235
Validation loss: 1.600326399649343

Epoch: 6| Step: 1
Training loss: 0.3306380808353424
Validation loss: 1.591378842630694

Epoch: 6| Step: 2
Training loss: 0.4946373403072357
Validation loss: 1.6029342066857122

Epoch: 6| Step: 3
Training loss: 0.3112776279449463
Validation loss: 1.584655172081404

Epoch: 6| Step: 4
Training loss: 0.347969114780426
Validation loss: 1.577864231601838

Epoch: 6| Step: 5
Training loss: 0.287284791469574
Validation loss: 1.615672170474965

Epoch: 6| Step: 6
Training loss: 0.24896401166915894
Validation loss: 1.6074759614083074

Epoch: 6| Step: 7
Training loss: 0.33497896790504456
Validation loss: 1.6177153587341309

Epoch: 6| Step: 8
Training loss: 0.3897938132286072
Validation loss: 1.6262613496472758

Epoch: 6| Step: 9
Training loss: 0.14851491153240204
Validation loss: 1.6633158665831371

Epoch: 6| Step: 10
Training loss: 0.30793628096580505
Validation loss: 1.6416780987093527

Epoch: 6| Step: 11
Training loss: 0.295814573764801
Validation loss: 1.6292062446635256

Epoch: 6| Step: 12
Training loss: 0.24719658493995667
Validation loss: 1.581719329280238

Epoch: 6| Step: 13
Training loss: 0.3697318434715271
Validation loss: 1.5789426244715208

Epoch: 344| Step: 0
Training loss: 0.29138803482055664
Validation loss: 1.5811102467198526

Epoch: 6| Step: 1
Training loss: 0.36780214309692383
Validation loss: 1.5350315993832004

Epoch: 6| Step: 2
Training loss: 0.3501918911933899
Validation loss: 1.5570882520368021

Epoch: 6| Step: 3
Training loss: 0.16869185864925385
Validation loss: 1.525984981367665

Epoch: 6| Step: 4
Training loss: 0.4243452548980713
Validation loss: 1.5671037499622633

Epoch: 6| Step: 5
Training loss: 0.18262892961502075
Validation loss: 1.5689435543552521

Epoch: 6| Step: 6
Training loss: 0.33195561170578003
Validation loss: 1.5151327835616244

Epoch: 6| Step: 7
Training loss: 0.24989725649356842
Validation loss: 1.5931486365615681

Epoch: 6| Step: 8
Training loss: 0.15916752815246582
Validation loss: 1.5488165655443746

Epoch: 6| Step: 9
Training loss: 0.14132489264011383
Validation loss: 1.5641955380798669

Epoch: 6| Step: 10
Training loss: 0.2287105768918991
Validation loss: 1.570854889449253

Epoch: 6| Step: 11
Training loss: 0.22603081166744232
Validation loss: 1.5961024761199951

Epoch: 6| Step: 12
Training loss: 0.35363173484802246
Validation loss: 1.567144129865913

Epoch: 6| Step: 13
Training loss: 0.37405073642730713
Validation loss: 1.5993718985588319

Epoch: 345| Step: 0
Training loss: 0.32841062545776367
Validation loss: 1.568711523086794

Epoch: 6| Step: 1
Training loss: 0.2988011837005615
Validation loss: 1.5692563672219553

Epoch: 6| Step: 2
Training loss: 0.22881117463111877
Validation loss: 1.5663019546898462

Epoch: 6| Step: 3
Training loss: 0.32225656509399414
Validation loss: 1.5673505170370943

Epoch: 6| Step: 4
Training loss: 0.28635135293006897
Validation loss: 1.5622250008326706

Epoch: 6| Step: 5
Training loss: 0.2591138482093811
Validation loss: 1.534912847703503

Epoch: 6| Step: 6
Training loss: 0.21907435357570648
Validation loss: 1.546364131794181

Epoch: 6| Step: 7
Training loss: 0.2516402304172516
Validation loss: 1.5533085753840785

Epoch: 6| Step: 8
Training loss: 0.2548896372318268
Validation loss: 1.575814926496116

Epoch: 6| Step: 9
Training loss: 0.3537081480026245
Validation loss: 1.5912684009921165

Epoch: 6| Step: 10
Training loss: 0.2591678202152252
Validation loss: 1.5978616142785678

Epoch: 6| Step: 11
Training loss: 0.3148677349090576
Validation loss: 1.6002483226919686

Epoch: 6| Step: 12
Training loss: 0.30367064476013184
Validation loss: 1.5808948150245092

Epoch: 6| Step: 13
Training loss: 0.35310372710227966
Validation loss: 1.5978036324183147

Epoch: 346| Step: 0
Training loss: 0.2872470021247864
Validation loss: 1.5994914090761574

Epoch: 6| Step: 1
Training loss: 0.255187451839447
Validation loss: 1.57528902381979

Epoch: 6| Step: 2
Training loss: 0.3352552354335785
Validation loss: 1.6069465196260841

Epoch: 6| Step: 3
Training loss: 0.3698015511035919
Validation loss: 1.5742054370141798

Epoch: 6| Step: 4
Training loss: 0.2309970259666443
Validation loss: 1.5932612085855136

Epoch: 6| Step: 5
Training loss: 0.3284851908683777
Validation loss: 1.5714816688209452

Epoch: 6| Step: 6
Training loss: 0.46670782566070557
Validation loss: 1.5890251308359125

Epoch: 6| Step: 7
Training loss: 0.2424744814634323
Validation loss: 1.5630333346705283

Epoch: 6| Step: 8
Training loss: 0.2629287838935852
Validation loss: 1.540175860927951

Epoch: 6| Step: 9
Training loss: 0.38036611676216125
Validation loss: 1.5691794336483043

Epoch: 6| Step: 10
Training loss: 0.2687219977378845
Validation loss: 1.5245236318598512

Epoch: 6| Step: 11
Training loss: 0.14702048897743225
Validation loss: 1.5400022281113492

Epoch: 6| Step: 12
Training loss: 0.238979309797287
Validation loss: 1.5141597870857484

Epoch: 6| Step: 13
Training loss: 0.25944197177886963
Validation loss: 1.5454322086867465

Epoch: 347| Step: 0
Training loss: 0.38083410263061523
Validation loss: 1.584251420472258

Epoch: 6| Step: 1
Training loss: 0.2823440432548523
Validation loss: 1.5654490981050717

Epoch: 6| Step: 2
Training loss: 0.3637315630912781
Validation loss: 1.5927016247985184

Epoch: 6| Step: 3
Training loss: 0.35077014565467834
Validation loss: 1.5461602236634941

Epoch: 6| Step: 4
Training loss: 0.2373259961605072
Validation loss: 1.5663352858635686

Epoch: 6| Step: 5
Training loss: 0.26825302839279175
Validation loss: 1.6017454420366595

Epoch: 6| Step: 6
Training loss: 0.11228608340024948
Validation loss: 1.5560168373969294

Epoch: 6| Step: 7
Training loss: 0.25432318449020386
Validation loss: 1.551007971968702

Epoch: 6| Step: 8
Training loss: 0.23525521159172058
Validation loss: 1.564330917532726

Epoch: 6| Step: 9
Training loss: 0.3684653043746948
Validation loss: 1.537340514121517

Epoch: 6| Step: 10
Training loss: 0.14866678416728973
Validation loss: 1.558270037815135

Epoch: 6| Step: 11
Training loss: 0.29182225465774536
Validation loss: 1.530896850811538

Epoch: 6| Step: 12
Training loss: 0.4639692008495331
Validation loss: 1.5459822506032965

Epoch: 6| Step: 13
Training loss: 0.39148643612861633
Validation loss: 1.572362921571219

Epoch: 348| Step: 0
Training loss: 0.21707776188850403
Validation loss: 1.576357304408986

Epoch: 6| Step: 1
Training loss: 0.41557008028030396
Validation loss: 1.5608969420515082

Epoch: 6| Step: 2
Training loss: 0.43357008695602417
Validation loss: 1.5777307300157444

Epoch: 6| Step: 3
Training loss: 0.1858731210231781
Validation loss: 1.5912213351136895

Epoch: 6| Step: 4
Training loss: 0.32668447494506836
Validation loss: 1.5923407987881733

Epoch: 6| Step: 5
Training loss: 0.22063913941383362
Validation loss: 1.6075228721864763

Epoch: 6| Step: 6
Training loss: 0.17074331641197205
Validation loss: 1.5653293017418153

Epoch: 6| Step: 7
Training loss: 0.30273717641830444
Validation loss: 1.5828267989620086

Epoch: 6| Step: 8
Training loss: 0.25166288018226624
Validation loss: 1.5985877552340109

Epoch: 6| Step: 9
Training loss: 0.25093621015548706
Validation loss: 1.5598564993950628

Epoch: 6| Step: 10
Training loss: 0.3522491753101349
Validation loss: 1.565257486476693

Epoch: 6| Step: 11
Training loss: 0.24401356279850006
Validation loss: 1.5694971161503946

Epoch: 6| Step: 12
Training loss: 0.29796236753463745
Validation loss: 1.567527424904608

Epoch: 6| Step: 13
Training loss: 0.18774516880512238
Validation loss: 1.5302371248122184

Epoch: 349| Step: 0
Training loss: 0.4473932087421417
Validation loss: 1.5279043310432023

Epoch: 6| Step: 1
Training loss: 0.2920738756656647
Validation loss: 1.5533924089964999

Epoch: 6| Step: 2
Training loss: 0.26424598693847656
Validation loss: 1.5470758843165573

Epoch: 6| Step: 3
Training loss: 0.14766138792037964
Validation loss: 1.5862743649431454

Epoch: 6| Step: 4
Training loss: 0.21046799421310425
Validation loss: 1.5693073272705078

Epoch: 6| Step: 5
Training loss: 0.2988142967224121
Validation loss: 1.593099219824678

Epoch: 6| Step: 6
Training loss: 0.18764933943748474
Validation loss: 1.5970793270295667

Epoch: 6| Step: 7
Training loss: 0.3346327841281891
Validation loss: 1.600348711013794

Epoch: 6| Step: 8
Training loss: 0.27511709928512573
Validation loss: 1.604698763098768

Epoch: 6| Step: 9
Training loss: 0.2601168155670166
Validation loss: 1.6575028537422098

Epoch: 6| Step: 10
Training loss: 0.3404732346534729
Validation loss: 1.590278394760624

Epoch: 6| Step: 11
Training loss: 0.46092888712882996
Validation loss: 1.6059099192260413

Epoch: 6| Step: 12
Training loss: 0.2799283266067505
Validation loss: 1.5890466846445555

Epoch: 6| Step: 13
Training loss: 0.20656444132328033
Validation loss: 1.6045565259072088

Epoch: 350| Step: 0
Training loss: 0.15138015151023865
Validation loss: 1.6348293853062454

Epoch: 6| Step: 1
Training loss: 0.3594817519187927
Validation loss: 1.594350363618584

Epoch: 6| Step: 2
Training loss: 0.15745015442371368
Validation loss: 1.5952863936783166

Epoch: 6| Step: 3
Training loss: 0.3597070276737213
Validation loss: 1.5739842320001254

Epoch: 6| Step: 4
Training loss: 0.2883790135383606
Validation loss: 1.6167091323483376

Epoch: 6| Step: 5
Training loss: 0.32740211486816406
Validation loss: 1.6024562133255826

Epoch: 6| Step: 6
Training loss: 0.20362994074821472
Validation loss: 1.5694859668772707

Epoch: 6| Step: 7
Training loss: 0.25368475914001465
Validation loss: 1.573396655821031

Epoch: 6| Step: 8
Training loss: 0.27222126722335815
Validation loss: 1.5939660418418147

Epoch: 6| Step: 9
Training loss: 0.3972454071044922
Validation loss: 1.57430737762041

Epoch: 6| Step: 10
Training loss: 0.25035491585731506
Validation loss: 1.6029678595963346

Epoch: 6| Step: 11
Training loss: 0.4356814920902252
Validation loss: 1.5498851601795485

Epoch: 6| Step: 12
Training loss: 0.3665921688079834
Validation loss: 1.5982475819126252

Epoch: 6| Step: 13
Training loss: 0.36332347989082336
Validation loss: 1.5640570348308933

Testing loss: 2.0643445703718397
