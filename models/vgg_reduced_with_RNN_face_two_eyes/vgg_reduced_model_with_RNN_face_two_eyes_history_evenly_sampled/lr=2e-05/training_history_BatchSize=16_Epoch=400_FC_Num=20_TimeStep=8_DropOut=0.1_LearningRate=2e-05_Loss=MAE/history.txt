Epoch: 1| Step: 0
Training loss: 4.877867698669434
Validation loss: 5.195790844578897

Epoch: 6| Step: 1
Training loss: 5.501962661743164
Validation loss: 5.1827809426092335

Epoch: 6| Step: 2
Training loss: 4.874128818511963
Validation loss: 5.169371517755652

Epoch: 6| Step: 3
Training loss: 4.821952819824219
Validation loss: 5.154673202063448

Epoch: 6| Step: 4
Training loss: 5.869320869445801
Validation loss: 5.138130213624688

Epoch: 6| Step: 5
Training loss: 5.1580352783203125
Validation loss: 5.119525099313387

Epoch: 6| Step: 6
Training loss: 3.960969924926758
Validation loss: 5.098453670419673

Epoch: 6| Step: 7
Training loss: 4.378389358520508
Validation loss: 5.07377597337128

Epoch: 6| Step: 8
Training loss: 3.6133952140808105
Validation loss: 5.045409571739935

Epoch: 6| Step: 9
Training loss: 5.018746376037598
Validation loss: 5.013341575540522

Epoch: 6| Step: 10
Training loss: 5.614616394042969
Validation loss: 4.976650417491954

Epoch: 6| Step: 11
Training loss: 4.978656768798828
Validation loss: 4.934935159580682

Epoch: 6| Step: 12
Training loss: 4.309750556945801
Validation loss: 4.887557639870592

Epoch: 6| Step: 13
Training loss: 5.223503112792969
Validation loss: 4.836801129002725

Epoch: 2| Step: 0
Training loss: 5.314600467681885
Validation loss: 4.7801970307545

Epoch: 6| Step: 1
Training loss: 3.7253353595733643
Validation loss: 4.720815112513881

Epoch: 6| Step: 2
Training loss: 4.070518970489502
Validation loss: 4.66116835481377

Epoch: 6| Step: 3
Training loss: 3.6966166496276855
Validation loss: 4.6013278653544765

Epoch: 6| Step: 4
Training loss: 4.899248123168945
Validation loss: 4.540393126908169

Epoch: 6| Step: 5
Training loss: 4.333294868469238
Validation loss: 4.482154887209656

Epoch: 6| Step: 6
Training loss: 5.708956718444824
Validation loss: 4.429065396708827

Epoch: 6| Step: 7
Training loss: 3.2563557624816895
Validation loss: 4.376571183563561

Epoch: 6| Step: 8
Training loss: 4.2551422119140625
Validation loss: 4.329593468737858

Epoch: 6| Step: 9
Training loss: 3.706880569458008
Validation loss: 4.286252893427367

Epoch: 6| Step: 10
Training loss: 5.085057258605957
Validation loss: 4.238240575277677

Epoch: 6| Step: 11
Training loss: 3.4026968479156494
Validation loss: 4.185573060025451

Epoch: 6| Step: 12
Training loss: 4.312655448913574
Validation loss: 4.134302941701746

Epoch: 6| Step: 13
Training loss: 2.711886167526245
Validation loss: 4.090624229882353

Epoch: 3| Step: 0
Training loss: 3.754559278488159
Validation loss: 4.055198664306312

Epoch: 6| Step: 1
Training loss: 3.368959426879883
Validation loss: 4.020846815519436

Epoch: 6| Step: 2
Training loss: 4.756678104400635
Validation loss: 3.992249324757566

Epoch: 6| Step: 3
Training loss: 3.7061192989349365
Validation loss: 3.966750019340105

Epoch: 6| Step: 4
Training loss: 4.798327445983887
Validation loss: 3.942018829366212

Epoch: 6| Step: 5
Training loss: 4.217705726623535
Validation loss: 3.919023080538678

Epoch: 6| Step: 6
Training loss: 3.014069080352783
Validation loss: 3.9006296280891664

Epoch: 6| Step: 7
Training loss: 4.317193984985352
Validation loss: 3.882641120623517

Epoch: 6| Step: 8
Training loss: 3.227962017059326
Validation loss: 3.862179776673676

Epoch: 6| Step: 9
Training loss: 4.474031448364258
Validation loss: 3.8450699724176878

Epoch: 6| Step: 10
Training loss: 3.768935203552246
Validation loss: 3.833019282228203

Epoch: 6| Step: 11
Training loss: 3.3370206356048584
Validation loss: 3.8166946134259625

Epoch: 6| Step: 12
Training loss: 2.971825122833252
Validation loss: 3.8021897680015972

Epoch: 6| Step: 13
Training loss: 2.7579143047332764
Validation loss: 3.7900833417010564

Epoch: 4| Step: 0
Training loss: 3.0307185649871826
Validation loss: 3.777372396120461

Epoch: 6| Step: 1
Training loss: 3.8117527961730957
Validation loss: 3.7623711760326097

Epoch: 6| Step: 2
Training loss: 3.1846113204956055
Validation loss: 3.744209361332719

Epoch: 6| Step: 3
Training loss: 5.426941394805908
Validation loss: 3.739949000779019

Epoch: 6| Step: 4
Training loss: 3.022251605987549
Validation loss: 3.72634700036818

Epoch: 6| Step: 5
Training loss: 3.167018413543701
Validation loss: 3.715017395634805

Epoch: 6| Step: 6
Training loss: 4.79323673248291
Validation loss: 3.710957896324896

Epoch: 6| Step: 7
Training loss: 3.466613292694092
Validation loss: 3.7031787877441733

Epoch: 6| Step: 8
Training loss: 3.0943479537963867
Validation loss: 3.6892505614988265

Epoch: 6| Step: 9
Training loss: 3.713042736053467
Validation loss: 3.679243410787275

Epoch: 6| Step: 10
Training loss: 3.0988903045654297
Validation loss: 3.672809426502515

Epoch: 6| Step: 11
Training loss: 3.9452686309814453
Validation loss: 3.6595021883646646

Epoch: 6| Step: 12
Training loss: 3.6667308807373047
Validation loss: 3.6539516961702736

Epoch: 6| Step: 13
Training loss: 2.721195936203003
Validation loss: 3.6407335496717885

Epoch: 5| Step: 0
Training loss: 3.8581366539001465
Validation loss: 3.6332627419502503

Epoch: 6| Step: 1
Training loss: 3.0607123374938965
Validation loss: 3.621366698254821

Epoch: 6| Step: 2
Training loss: 3.4005260467529297
Validation loss: 3.6103437331414994

Epoch: 6| Step: 3
Training loss: 4.555788516998291
Validation loss: 3.597258142245713

Epoch: 6| Step: 4
Training loss: 3.81209659576416
Validation loss: 3.583258303262854

Epoch: 6| Step: 5
Training loss: 3.7760472297668457
Validation loss: 3.5707710225095033

Epoch: 6| Step: 6
Training loss: 4.0801849365234375
Validation loss: 3.5581744204285326

Epoch: 6| Step: 7
Training loss: 3.2989773750305176
Validation loss: 3.5494825199086177

Epoch: 6| Step: 8
Training loss: 3.0809812545776367
Validation loss: 3.5349924538725164

Epoch: 6| Step: 9
Training loss: 3.195626974105835
Validation loss: 3.52806322292615

Epoch: 6| Step: 10
Training loss: 3.51519775390625
Validation loss: 3.518704660477177

Epoch: 6| Step: 11
Training loss: 3.016327381134033
Validation loss: 3.5073390571019982

Epoch: 6| Step: 12
Training loss: 3.0700480937957764
Validation loss: 3.5015700658162436

Epoch: 6| Step: 13
Training loss: 2.818209648132324
Validation loss: 3.490637569017308

Epoch: 6| Step: 0
Training loss: 2.920405864715576
Validation loss: 3.467789360271987

Epoch: 6| Step: 1
Training loss: 2.3922739028930664
Validation loss: 3.447935858080464

Epoch: 6| Step: 2
Training loss: 3.4853200912475586
Validation loss: 3.4601790161542993

Epoch: 6| Step: 3
Training loss: 2.9745137691497803
Validation loss: 3.420810789190313

Epoch: 6| Step: 4
Training loss: 3.9015302658081055
Validation loss: 3.4157969977266047

Epoch: 6| Step: 5
Training loss: 3.39337158203125
Validation loss: 3.422215066930299

Epoch: 6| Step: 6
Training loss: 3.403824806213379
Validation loss: 3.402607246111798

Epoch: 6| Step: 7
Training loss: 3.367724657058716
Validation loss: 3.3905988201018302

Epoch: 6| Step: 8
Training loss: 3.427145481109619
Validation loss: 3.3833647440838557

Epoch: 6| Step: 9
Training loss: 3.8901829719543457
Validation loss: 3.37011040923416

Epoch: 6| Step: 10
Training loss: 4.049784183502197
Validation loss: 3.35904961247598

Epoch: 6| Step: 11
Training loss: 3.3689944744110107
Validation loss: 3.341660576481973

Epoch: 6| Step: 12
Training loss: 3.3404955863952637
Validation loss: 3.3293650791209233

Epoch: 6| Step: 13
Training loss: 2.558603525161743
Validation loss: 3.315504333024384

Epoch: 7| Step: 0
Training loss: 2.4018545150756836
Validation loss: 3.316391142465735

Epoch: 6| Step: 1
Training loss: 3.5576095581054688
Validation loss: 3.3037826527831373

Epoch: 6| Step: 2
Training loss: 2.8068652153015137
Validation loss: 3.2882629338131157

Epoch: 6| Step: 3
Training loss: 3.2200136184692383
Validation loss: 3.2847537789293515

Epoch: 6| Step: 4
Training loss: 4.746486663818359
Validation loss: 3.277683268311203

Epoch: 6| Step: 5
Training loss: 3.568077802658081
Validation loss: 3.260879114109983

Epoch: 6| Step: 6
Training loss: 3.5907959938049316
Validation loss: 3.2607412927894184

Epoch: 6| Step: 7
Training loss: 2.824448585510254
Validation loss: 3.268234742585049

Epoch: 6| Step: 8
Training loss: 3.24238657951355
Validation loss: 3.27472420148952

Epoch: 6| Step: 9
Training loss: 2.723568916320801
Validation loss: 3.265959434611823

Epoch: 6| Step: 10
Training loss: 3.1335878372192383
Validation loss: 3.2552292090590282

Epoch: 6| Step: 11
Training loss: 3.565347194671631
Validation loss: 3.236298115022721

Epoch: 6| Step: 12
Training loss: 2.610045909881592
Validation loss: 3.2246818081025155

Epoch: 6| Step: 13
Training loss: 3.58351469039917
Validation loss: 3.210461272988268

Epoch: 8| Step: 0
Training loss: 3.4814579486846924
Validation loss: 3.2014942246098674

Epoch: 6| Step: 1
Training loss: 4.559023857116699
Validation loss: 3.192680005104311

Epoch: 6| Step: 2
Training loss: 2.1186068058013916
Validation loss: 3.1771700356596257

Epoch: 6| Step: 3
Training loss: 3.515859365463257
Validation loss: 3.178364117940267

Epoch: 6| Step: 4
Training loss: 2.8495097160339355
Validation loss: 3.1682911406281176

Epoch: 6| Step: 5
Training loss: 2.4961485862731934
Validation loss: 3.1580099777508805

Epoch: 6| Step: 6
Training loss: 2.2854580879211426
Validation loss: 3.149198209085772

Epoch: 6| Step: 7
Training loss: 3.6596291065216064
Validation loss: 3.138704261472148

Epoch: 6| Step: 8
Training loss: 3.004385471343994
Validation loss: 3.1279148004388295

Epoch: 6| Step: 9
Training loss: 3.48814058303833
Validation loss: 3.12135225213984

Epoch: 6| Step: 10
Training loss: 3.198624610900879
Validation loss: 3.117630292010564

Epoch: 6| Step: 11
Training loss: 3.75545334815979
Validation loss: 3.1124991191330778

Epoch: 6| Step: 12
Training loss: 2.7767434120178223
Validation loss: 3.09798841322622

Epoch: 6| Step: 13
Training loss: 2.8597335815429688
Validation loss: 3.088697261707757

Epoch: 9| Step: 0
Training loss: 2.7445507049560547
Validation loss: 3.089449510779432

Epoch: 6| Step: 1
Training loss: 3.382497549057007
Validation loss: 3.075583880947482

Epoch: 6| Step: 2
Training loss: 2.1404500007629395
Validation loss: 3.070169964144307

Epoch: 6| Step: 3
Training loss: 3.6936588287353516
Validation loss: 3.071467827725154

Epoch: 6| Step: 4
Training loss: 2.7332911491394043
Validation loss: 3.0596357186635337

Epoch: 6| Step: 5
Training loss: 3.614047050476074
Validation loss: 3.048363962481099

Epoch: 6| Step: 6
Training loss: 3.7104287147521973
Validation loss: 3.0447851560449086

Epoch: 6| Step: 7
Training loss: 3.0161375999450684
Validation loss: 3.0867058256621003

Epoch: 6| Step: 8
Training loss: 3.1169896125793457
Validation loss: 3.0703673157640683

Epoch: 6| Step: 9
Training loss: 3.6996660232543945
Validation loss: 3.019037610741072

Epoch: 6| Step: 10
Training loss: 2.109442949295044
Validation loss: 3.0332396671336186

Epoch: 6| Step: 11
Training loss: 3.185007095336914
Validation loss: 3.0400269364797943

Epoch: 6| Step: 12
Training loss: 2.6970441341400146
Validation loss: 3.0514087446274294

Epoch: 6| Step: 13
Training loss: 3.9803733825683594
Validation loss: 3.057946535848802

Epoch: 10| Step: 0
Training loss: 3.238461971282959
Validation loss: 3.052767143454603

Epoch: 6| Step: 1
Training loss: 2.5988879203796387
Validation loss: 3.035445482500138

Epoch: 6| Step: 2
Training loss: 2.8122737407684326
Validation loss: 3.030743060573455

Epoch: 6| Step: 3
Training loss: 3.5410919189453125
Validation loss: 3.0215615739104567

Epoch: 6| Step: 4
Training loss: 2.0483736991882324
Validation loss: 3.002384965137769

Epoch: 6| Step: 5
Training loss: 2.9353888034820557
Validation loss: 2.9944069641892628

Epoch: 6| Step: 6
Training loss: 3.2309861183166504
Validation loss: 2.9889834670610327

Epoch: 6| Step: 7
Training loss: 3.5849435329437256
Validation loss: 2.9866061851542485

Epoch: 6| Step: 8
Training loss: 2.7638955116271973
Validation loss: 2.97929137240174

Epoch: 6| Step: 9
Training loss: 2.8813047409057617
Validation loss: 2.9749000815935034

Epoch: 6| Step: 10
Training loss: 3.728616952896118
Validation loss: 2.9648067182110203

Epoch: 6| Step: 11
Training loss: 3.613518238067627
Validation loss: 2.959814453637728

Epoch: 6| Step: 12
Training loss: 2.9128971099853516
Validation loss: 2.9547448209536973

Epoch: 6| Step: 13
Training loss: 2.8621816635131836
Validation loss: 2.953418847053282

Epoch: 11| Step: 0
Training loss: 2.840231418609619
Validation loss: 2.9451430407903527

Epoch: 6| Step: 1
Training loss: 2.0617358684539795
Validation loss: 2.9355290064247708

Epoch: 6| Step: 2
Training loss: 3.2013158798217773
Validation loss: 2.928598188584851

Epoch: 6| Step: 3
Training loss: 3.1269495487213135
Validation loss: 2.9235575378582044

Epoch: 6| Step: 4
Training loss: 3.687553882598877
Validation loss: 2.9185289695698726

Epoch: 6| Step: 5
Training loss: 3.136183023452759
Validation loss: 2.9133249072618383

Epoch: 6| Step: 6
Training loss: 3.092672348022461
Validation loss: 2.9063590777817594

Epoch: 6| Step: 7
Training loss: 3.044070243835449
Validation loss: 2.901922136224726

Epoch: 6| Step: 8
Training loss: 3.1098670959472656
Validation loss: 2.8966448794129076

Epoch: 6| Step: 9
Training loss: 3.316033124923706
Validation loss: 2.893232463508524

Epoch: 6| Step: 10
Training loss: 2.4838733673095703
Validation loss: 2.8850606256915676

Epoch: 6| Step: 11
Training loss: 3.0354034900665283
Validation loss: 2.884359816069244

Epoch: 6| Step: 12
Training loss: 3.06972599029541
Validation loss: 2.8779532806847685

Epoch: 6| Step: 13
Training loss: 2.787015199661255
Validation loss: 2.8717866815546507

Epoch: 12| Step: 0
Training loss: 3.279369831085205
Validation loss: 2.8622341822552424

Epoch: 6| Step: 1
Training loss: 2.741583824157715
Validation loss: 2.8523886075583835

Epoch: 6| Step: 2
Training loss: 2.8223514556884766
Validation loss: 2.8606699846124135

Epoch: 6| Step: 3
Training loss: 3.6201698780059814
Validation loss: 2.855245195409303

Epoch: 6| Step: 4
Training loss: 1.8274825811386108
Validation loss: 2.857010820860504

Epoch: 6| Step: 5
Training loss: 2.959639072418213
Validation loss: 2.8584006576127905

Epoch: 6| Step: 6
Training loss: 3.463988780975342
Validation loss: 2.8493261414189495

Epoch: 6| Step: 7
Training loss: 3.1295812129974365
Validation loss: 2.846384043334633

Epoch: 6| Step: 8
Training loss: 3.62441086769104
Validation loss: 2.8405870904204664

Epoch: 6| Step: 9
Training loss: 3.34287691116333
Validation loss: 2.83633767661228

Epoch: 6| Step: 10
Training loss: 2.584799289703369
Validation loss: 2.8304390010013374

Epoch: 6| Step: 11
Training loss: 2.801542282104492
Validation loss: 2.824330891332319

Epoch: 6| Step: 12
Training loss: 2.956106185913086
Validation loss: 2.8195908223429034

Epoch: 6| Step: 13
Training loss: 1.7649617195129395
Validation loss: 2.8210368310251543

Epoch: 13| Step: 0
Training loss: 3.224669933319092
Validation loss: 2.816164239760368

Epoch: 6| Step: 1
Training loss: 3.5509886741638184
Validation loss: 2.808424865045855

Epoch: 6| Step: 2
Training loss: 3.0937857627868652
Validation loss: 2.802938468994633

Epoch: 6| Step: 3
Training loss: 2.612210273742676
Validation loss: 2.803100186009561

Epoch: 6| Step: 4
Training loss: 3.8061580657958984
Validation loss: 2.848137750420519

Epoch: 6| Step: 5
Training loss: 2.3532214164733887
Validation loss: 2.851290210600822

Epoch: 6| Step: 6
Training loss: 2.9205899238586426
Validation loss: 2.850150103210121

Epoch: 6| Step: 7
Training loss: 3.3916518688201904
Validation loss: 2.846965423194311

Epoch: 6| Step: 8
Training loss: 1.9678893089294434
Validation loss: 2.8385363881305983

Epoch: 6| Step: 9
Training loss: 3.0738112926483154
Validation loss: 2.8416974852162022

Epoch: 6| Step: 10
Training loss: 2.517822742462158
Validation loss: 2.8371783456494732

Epoch: 6| Step: 11
Training loss: 2.6527535915374756
Validation loss: 2.8278788366625385

Epoch: 6| Step: 12
Training loss: 3.253134250640869
Validation loss: 2.8185654891434537

Epoch: 6| Step: 13
Training loss: 2.901012420654297
Validation loss: 2.815011739730835

Epoch: 14| Step: 0
Training loss: 2.5561037063598633
Validation loss: 2.8153915712910313

Epoch: 6| Step: 1
Training loss: 3.457608222961426
Validation loss: 2.8104416196064284

Epoch: 6| Step: 2
Training loss: 3.042891025543213
Validation loss: 2.8076104041068786

Epoch: 6| Step: 3
Training loss: 3.0516676902770996
Validation loss: 2.8004787865505425

Epoch: 6| Step: 4
Training loss: 2.871877670288086
Validation loss: 2.796054950324438

Epoch: 6| Step: 5
Training loss: 2.8622918128967285
Validation loss: 2.7965724160594325

Epoch: 6| Step: 6
Training loss: 3.538132429122925
Validation loss: 2.7914428813483125

Epoch: 6| Step: 7
Training loss: 3.620422124862671
Validation loss: 2.78741862440622

Epoch: 6| Step: 8
Training loss: 2.4159042835235596
Validation loss: 2.7837381311642226

Epoch: 6| Step: 9
Training loss: 2.779677152633667
Validation loss: 2.781505666753297

Epoch: 6| Step: 10
Training loss: 2.2993345260620117
Validation loss: 2.783934372727589

Epoch: 6| Step: 11
Training loss: 2.735285758972168
Validation loss: 2.777351712667814

Epoch: 6| Step: 12
Training loss: 2.9995341300964355
Validation loss: 2.773674229139923

Epoch: 6| Step: 13
Training loss: 2.6771674156188965
Validation loss: 2.771608942298479

Epoch: 15| Step: 0
Training loss: 2.4542741775512695
Validation loss: 2.7712951270482873

Epoch: 6| Step: 1
Training loss: 1.746634840965271
Validation loss: 2.7711646710672686

Epoch: 6| Step: 2
Training loss: 2.789478302001953
Validation loss: 2.76986284922528

Epoch: 6| Step: 3
Training loss: 3.569796562194824
Validation loss: 2.767697875217725

Epoch: 6| Step: 4
Training loss: 3.0726981163024902
Validation loss: 2.7676082862320768

Epoch: 6| Step: 5
Training loss: 3.7946548461914062
Validation loss: 2.763700262192757

Epoch: 6| Step: 6
Training loss: 2.851442575454712
Validation loss: 2.760910500762283

Epoch: 6| Step: 7
Training loss: 3.6467385292053223
Validation loss: 2.759369456639854

Epoch: 6| Step: 8
Training loss: 3.0118842124938965
Validation loss: 2.7604022154244046

Epoch: 6| Step: 9
Training loss: 2.712999105453491
Validation loss: 2.760984533576555

Epoch: 6| Step: 10
Training loss: 2.2321667671203613
Validation loss: 2.7561962450704267

Epoch: 6| Step: 11
Training loss: 3.5883634090423584
Validation loss: 2.7578903680206626

Epoch: 6| Step: 12
Training loss: 1.8758349418640137
Validation loss: 2.752076538660193

Epoch: 6| Step: 13
Training loss: 3.73483943939209
Validation loss: 2.752995391045847

Epoch: 16| Step: 0
Training loss: 2.4438345432281494
Validation loss: 2.7555201053619385

Epoch: 6| Step: 1
Training loss: 2.834869861602783
Validation loss: 2.753913761467062

Epoch: 6| Step: 2
Training loss: 3.135679006576538
Validation loss: 2.7499265414412304

Epoch: 6| Step: 3
Training loss: 3.624640464782715
Validation loss: 2.746851513462682

Epoch: 6| Step: 4
Training loss: 3.7975478172302246
Validation loss: 2.743764582500663

Epoch: 6| Step: 5
Training loss: 2.1157150268554688
Validation loss: 2.741914221035537

Epoch: 6| Step: 6
Training loss: 3.0076546669006348
Validation loss: 2.742536449945101

Epoch: 6| Step: 7
Training loss: 3.128403663635254
Validation loss: 2.7386477326834076

Epoch: 6| Step: 8
Training loss: 2.480551242828369
Validation loss: 2.7347448282344367

Epoch: 6| Step: 9
Training loss: 3.109679698944092
Validation loss: 2.740458380791449

Epoch: 6| Step: 10
Training loss: 2.922405242919922
Validation loss: 2.7929498662230787

Epoch: 6| Step: 11
Training loss: 2.655280590057373
Validation loss: 2.7918793616756314

Epoch: 6| Step: 12
Training loss: 2.827613353729248
Validation loss: 2.801752854419011

Epoch: 6| Step: 13
Training loss: 2.3188068866729736
Validation loss: 2.8286172728384695

Epoch: 17| Step: 0
Training loss: 3.1654272079467773
Validation loss: 2.7535757223765054

Epoch: 6| Step: 1
Training loss: 2.491368293762207
Validation loss: 2.736145229749782

Epoch: 6| Step: 2
Training loss: 2.638378620147705
Validation loss: 2.7877993045314664

Epoch: 6| Step: 3
Training loss: 2.866002321243286
Validation loss: 2.8570538797686176

Epoch: 6| Step: 4
Training loss: 3.2462148666381836
Validation loss: 2.868894015589068

Epoch: 6| Step: 5
Training loss: 2.3025665283203125
Validation loss: 2.8705692855260705

Epoch: 6| Step: 6
Training loss: 3.164417266845703
Validation loss: 2.8812936018872004

Epoch: 6| Step: 7
Training loss: 3.291841506958008
Validation loss: 2.8353274406925326

Epoch: 6| Step: 8
Training loss: 3.348968982696533
Validation loss: 2.7698521921711583

Epoch: 6| Step: 9
Training loss: 3.3443193435668945
Validation loss: 2.750264334422286

Epoch: 6| Step: 10
Training loss: 3.349975109100342
Validation loss: 2.7534429591189147

Epoch: 6| Step: 11
Training loss: 2.5065736770629883
Validation loss: 2.7630468414675806

Epoch: 6| Step: 12
Training loss: 2.4672868251800537
Validation loss: 2.7718416490862445

Epoch: 6| Step: 13
Training loss: 2.8163280487060547
Validation loss: 2.7540146176533034

Epoch: 18| Step: 0
Training loss: 2.7967491149902344
Validation loss: 2.7429411231830554

Epoch: 6| Step: 1
Training loss: 2.6177566051483154
Validation loss: 2.73802916208903

Epoch: 6| Step: 2
Training loss: 2.9671268463134766
Validation loss: 2.734597690643803

Epoch: 6| Step: 3
Training loss: 3.2829065322875977
Validation loss: 2.7334841271882415

Epoch: 6| Step: 4
Training loss: 2.920506000518799
Validation loss: 2.7286219596862793

Epoch: 6| Step: 5
Training loss: 2.238211154937744
Validation loss: 2.709757230615103

Epoch: 6| Step: 6
Training loss: 3.056091070175171
Validation loss: 2.711847707789431

Epoch: 6| Step: 7
Training loss: 3.488335609436035
Validation loss: 2.7062654649057696

Epoch: 6| Step: 8
Training loss: 3.094588279724121
Validation loss: 2.6903352609244724

Epoch: 6| Step: 9
Training loss: 2.9653103351593018
Validation loss: 2.687009631946523

Epoch: 6| Step: 10
Training loss: 2.9568917751312256
Validation loss: 2.688593203021634

Epoch: 6| Step: 11
Training loss: 2.606858253479004
Validation loss: 2.6923251126402166

Epoch: 6| Step: 12
Training loss: 2.641239643096924
Validation loss: 2.6964954945348922

Epoch: 6| Step: 13
Training loss: 2.3616034984588623
Validation loss: 2.683319401997392

Epoch: 19| Step: 0
Training loss: 3.1180601119995117
Validation loss: 2.6755299439994236

Epoch: 6| Step: 1
Training loss: 2.462467670440674
Validation loss: 2.6759094371590564

Epoch: 6| Step: 2
Training loss: 3.421782970428467
Validation loss: 2.6733584993629047

Epoch: 6| Step: 3
Training loss: 3.3907880783081055
Validation loss: 2.6747350667112615

Epoch: 6| Step: 4
Training loss: 2.8092401027679443
Validation loss: 2.671379038082656

Epoch: 6| Step: 5
Training loss: 2.189767360687256
Validation loss: 2.6698460245645173

Epoch: 6| Step: 6
Training loss: 2.6827597618103027
Validation loss: 2.666061967931768

Epoch: 6| Step: 7
Training loss: 2.9149527549743652
Validation loss: 2.6641281394548315

Epoch: 6| Step: 8
Training loss: 2.6064419746398926
Validation loss: 2.661721193662254

Epoch: 6| Step: 9
Training loss: 2.774338722229004
Validation loss: 2.6608772944378596

Epoch: 6| Step: 10
Training loss: 3.361581802368164
Validation loss: 2.6569602463835027

Epoch: 6| Step: 11
Training loss: 2.6473007202148438
Validation loss: 2.6532368429245485

Epoch: 6| Step: 12
Training loss: 2.3818933963775635
Validation loss: 2.6563316955361316

Epoch: 6| Step: 13
Training loss: 3.343899965286255
Validation loss: 2.6562265452518257

Epoch: 20| Step: 0
Training loss: 3.3453316688537598
Validation loss: 2.656091146571662

Epoch: 6| Step: 1
Training loss: 2.715914011001587
Validation loss: 2.6568611642365814

Epoch: 6| Step: 2
Training loss: 2.672041416168213
Validation loss: 2.6596025420773413

Epoch: 6| Step: 3
Training loss: 3.0645816326141357
Validation loss: 2.6526947175302813

Epoch: 6| Step: 4
Training loss: 2.6737468242645264
Validation loss: 2.649500844299152

Epoch: 6| Step: 5
Training loss: 2.3689584732055664
Validation loss: 2.6474748529413694

Epoch: 6| Step: 6
Training loss: 3.3351593017578125
Validation loss: 2.6457118808582263

Epoch: 6| Step: 7
Training loss: 2.9870400428771973
Validation loss: 2.6460246732158046

Epoch: 6| Step: 8
Training loss: 2.24739933013916
Validation loss: 2.6493047616815053

Epoch: 6| Step: 9
Training loss: 2.712963819503784
Validation loss: 2.6458661479334675

Epoch: 6| Step: 10
Training loss: 2.7109646797180176
Validation loss: 2.651930885930215

Epoch: 6| Step: 11
Training loss: 2.690213918685913
Validation loss: 2.649699366220864

Epoch: 6| Step: 12
Training loss: 3.2885894775390625
Validation loss: 2.6427331521946895

Epoch: 6| Step: 13
Training loss: 2.8275251388549805
Validation loss: 2.649543090533185

Epoch: 21| Step: 0
Training loss: 2.635849952697754
Validation loss: 2.6496025772504908

Epoch: 6| Step: 1
Training loss: 2.3928980827331543
Validation loss: 2.6534930121514106

Epoch: 6| Step: 2
Training loss: 3.339564085006714
Validation loss: 2.6519026858832246

Epoch: 6| Step: 3
Training loss: 3.155792236328125
Validation loss: 2.6488873958587646

Epoch: 6| Step: 4
Training loss: 3.3035330772399902
Validation loss: 2.643787061014483

Epoch: 6| Step: 5
Training loss: 1.9682424068450928
Validation loss: 2.641742783208047

Epoch: 6| Step: 6
Training loss: 3.340494155883789
Validation loss: 2.6402308787069013

Epoch: 6| Step: 7
Training loss: 2.9101474285125732
Validation loss: 2.646468911119687

Epoch: 6| Step: 8
Training loss: 2.0932154655456543
Validation loss: 2.640866179620066

Epoch: 6| Step: 9
Training loss: 2.957155704498291
Validation loss: 2.6395986874898276

Epoch: 6| Step: 10
Training loss: 2.5854227542877197
Validation loss: 2.6408764521280923

Epoch: 6| Step: 11
Training loss: 2.8177642822265625
Validation loss: 2.6352713108062744

Epoch: 6| Step: 12
Training loss: 3.4754741191864014
Validation loss: 2.6332029783597557

Epoch: 6| Step: 13
Training loss: 2.4912402629852295
Validation loss: 2.633350056986655

Epoch: 22| Step: 0
Training loss: 2.2377185821533203
Validation loss: 2.632025716125324

Epoch: 6| Step: 1
Training loss: 3.7454895973205566
Validation loss: 2.628683646519979

Epoch: 6| Step: 2
Training loss: 2.661393642425537
Validation loss: 2.6291689821468887

Epoch: 6| Step: 3
Training loss: 2.4947071075439453
Validation loss: 2.6260723849778533

Epoch: 6| Step: 4
Training loss: 3.402127265930176
Validation loss: 2.625567102944979

Epoch: 6| Step: 5
Training loss: 3.0617780685424805
Validation loss: 2.6249713436249764

Epoch: 6| Step: 6
Training loss: 2.906459331512451
Validation loss: 2.633104103867726

Epoch: 6| Step: 7
Training loss: 2.540231704711914
Validation loss: 2.678242701356129

Epoch: 6| Step: 8
Training loss: 2.1743452548980713
Validation loss: 2.714172378663094

Epoch: 6| Step: 9
Training loss: 3.2452168464660645
Validation loss: 2.7549734320691837

Epoch: 6| Step: 10
Training loss: 2.720188617706299
Validation loss: 2.736737351263723

Epoch: 6| Step: 11
Training loss: 3.129566192626953
Validation loss: 2.719890771373626

Epoch: 6| Step: 12
Training loss: 3.2076544761657715
Validation loss: 2.7090050148707565

Epoch: 6| Step: 13
Training loss: 1.563222050666809
Validation loss: 2.699967586865989

Epoch: 23| Step: 0
Training loss: 3.227254867553711
Validation loss: 2.7069413892684446

Epoch: 6| Step: 1
Training loss: 2.599370002746582
Validation loss: 2.7037859193740355

Epoch: 6| Step: 2
Training loss: 2.7695279121398926
Validation loss: 2.7008246567941483

Epoch: 6| Step: 3
Training loss: 2.824127197265625
Validation loss: 2.7005648664248887

Epoch: 6| Step: 4
Training loss: 2.217006206512451
Validation loss: 2.690376984175815

Epoch: 6| Step: 5
Training loss: 2.7801010608673096
Validation loss: 2.6850156348238707

Epoch: 6| Step: 6
Training loss: 2.5822978019714355
Validation loss: 2.683923218839912

Epoch: 6| Step: 7
Training loss: 2.5033416748046875
Validation loss: 2.6910664266155613

Epoch: 6| Step: 8
Training loss: 2.868762493133545
Validation loss: 2.70542045562498

Epoch: 6| Step: 9
Training loss: 3.3749873638153076
Validation loss: 2.7457116316723567

Epoch: 6| Step: 10
Training loss: 4.066308498382568
Validation loss: 2.7626168522783505

Epoch: 6| Step: 11
Training loss: 2.8154525756835938
Validation loss: 2.705206947941934

Epoch: 6| Step: 12
Training loss: 2.7791566848754883
Validation loss: 2.680610649047359

Epoch: 6| Step: 13
Training loss: 2.6042418479919434
Validation loss: 2.7279233086493706

Epoch: 24| Step: 0
Training loss: 3.012052536010742
Validation loss: 2.7393792829205914

Epoch: 6| Step: 1
Training loss: 2.213804244995117
Validation loss: 2.7464820979743876

Epoch: 6| Step: 2
Training loss: 3.61016845703125
Validation loss: 2.7262869060680432

Epoch: 6| Step: 3
Training loss: 1.9800403118133545
Validation loss: 2.7217627827839186

Epoch: 6| Step: 4
Training loss: 3.1708858013153076
Validation loss: 2.7227701012806227

Epoch: 6| Step: 5
Training loss: 2.9066860675811768
Validation loss: 2.728642499575051

Epoch: 6| Step: 6
Training loss: 2.7093498706817627
Validation loss: 2.7165857950846353

Epoch: 6| Step: 7
Training loss: 2.1857552528381348
Validation loss: 2.7116859946199643

Epoch: 6| Step: 8
Training loss: 3.9997718334198
Validation loss: 2.7301394272876043

Epoch: 6| Step: 9
Training loss: 3.307375192642212
Validation loss: 2.6730284947220997

Epoch: 6| Step: 10
Training loss: 2.6513960361480713
Validation loss: 2.6476920881579

Epoch: 6| Step: 11
Training loss: 2.953824520111084
Validation loss: 2.632110834121704

Epoch: 6| Step: 12
Training loss: 2.6204771995544434
Validation loss: 2.623026350493072

Epoch: 6| Step: 13
Training loss: 2.6877925395965576
Validation loss: 2.621622834154355

Epoch: 25| Step: 0
Training loss: 2.9922285079956055
Validation loss: 2.63315946825089

Epoch: 6| Step: 1
Training loss: 3.821317195892334
Validation loss: 2.641989710510418

Epoch: 6| Step: 2
Training loss: 2.8574724197387695
Validation loss: 2.69011785650766

Epoch: 6| Step: 3
Training loss: 2.8783299922943115
Validation loss: 2.7413921612565235

Epoch: 6| Step: 4
Training loss: 2.9689948558807373
Validation loss: 2.792738413298002

Epoch: 6| Step: 5
Training loss: 2.258788824081421
Validation loss: 2.7991983198350474

Epoch: 6| Step: 6
Training loss: 1.9998626708984375
Validation loss: 2.7869464787103797

Epoch: 6| Step: 7
Training loss: 3.0431408882141113
Validation loss: 2.7849335209015877

Epoch: 6| Step: 8
Training loss: 3.1906189918518066
Validation loss: 2.716341664714198

Epoch: 6| Step: 9
Training loss: 2.6281046867370605
Validation loss: 2.630955808906145

Epoch: 6| Step: 10
Training loss: 2.6087779998779297
Validation loss: 2.6055257781859367

Epoch: 6| Step: 11
Training loss: 2.5922904014587402
Validation loss: 2.6099400020414785

Epoch: 6| Step: 12
Training loss: 2.5605173110961914
Validation loss: 2.629282351463072

Epoch: 6| Step: 13
Training loss: 3.6349635124206543
Validation loss: 2.665409352189751

Epoch: 26| Step: 0
Training loss: 2.876596212387085
Validation loss: 2.7075823635183354

Epoch: 6| Step: 1
Training loss: 3.884077787399292
Validation loss: 2.689386772853072

Epoch: 6| Step: 2
Training loss: 2.6449637413024902
Validation loss: 2.6476111360775527

Epoch: 6| Step: 3
Training loss: 2.410501003265381
Validation loss: 2.6182746297569683

Epoch: 6| Step: 4
Training loss: 2.1284899711608887
Validation loss: 2.5900445471527758

Epoch: 6| Step: 5
Training loss: 2.4205474853515625
Validation loss: 2.5829586726362987

Epoch: 6| Step: 6
Training loss: 3.3340344429016113
Validation loss: 2.5844773323305192

Epoch: 6| Step: 7
Training loss: 3.0480504035949707
Validation loss: 2.5894755240409606

Epoch: 6| Step: 8
Training loss: 2.287107229232788
Validation loss: 2.5855135738208728

Epoch: 6| Step: 9
Training loss: 2.676694869995117
Validation loss: 2.5885915320406676

Epoch: 6| Step: 10
Training loss: 3.015000104904175
Validation loss: 2.5912500658342914

Epoch: 6| Step: 11
Training loss: 3.0658624172210693
Validation loss: 2.591075820307578

Epoch: 6| Step: 12
Training loss: 2.5108063220977783
Validation loss: 2.5928505184829875

Epoch: 6| Step: 13
Training loss: 3.44968318939209
Validation loss: 2.591311267627183

Epoch: 27| Step: 0
Training loss: 3.6899890899658203
Validation loss: 2.5869817067218084

Epoch: 6| Step: 1
Training loss: 2.3356916904449463
Validation loss: 2.5806592433683333

Epoch: 6| Step: 2
Training loss: 1.9664859771728516
Validation loss: 2.585862892930226

Epoch: 6| Step: 3
Training loss: 2.67732572555542
Validation loss: 2.58658419885943

Epoch: 6| Step: 4
Training loss: 2.596737861633301
Validation loss: 2.6064415336937032

Epoch: 6| Step: 5
Training loss: 3.012683868408203
Validation loss: 2.6135299718508156

Epoch: 6| Step: 6
Training loss: 2.5893375873565674
Validation loss: 2.6007978608531337

Epoch: 6| Step: 7
Training loss: 2.4551515579223633
Validation loss: 2.5779938108177594

Epoch: 6| Step: 8
Training loss: 2.9182729721069336
Validation loss: 2.5613151006801154

Epoch: 6| Step: 9
Training loss: 2.778332233428955
Validation loss: 2.5637556968196744

Epoch: 6| Step: 10
Training loss: 3.031022548675537
Validation loss: 2.5667245131666943

Epoch: 6| Step: 11
Training loss: 2.907379150390625
Validation loss: 2.585077876685768

Epoch: 6| Step: 12
Training loss: 3.3462979793548584
Validation loss: 2.6063619095792054

Epoch: 6| Step: 13
Training loss: 2.5960614681243896
Validation loss: 2.5809720511077554

Epoch: 28| Step: 0
Training loss: 3.2839229106903076
Validation loss: 2.5543782147028113

Epoch: 6| Step: 1
Training loss: 2.8694653511047363
Validation loss: 2.542547374643305

Epoch: 6| Step: 2
Training loss: 2.9130001068115234
Validation loss: 2.542096835310741

Epoch: 6| Step: 3
Training loss: 2.5529632568359375
Validation loss: 2.5519337038840018

Epoch: 6| Step: 4
Training loss: 2.865661144256592
Validation loss: 2.594726739391204

Epoch: 6| Step: 5
Training loss: 2.505539894104004
Validation loss: 2.6222100668056036

Epoch: 6| Step: 6
Training loss: 2.7643303871154785
Validation loss: 2.614687835016558

Epoch: 6| Step: 7
Training loss: 2.645286798477173
Validation loss: 2.581280077657392

Epoch: 6| Step: 8
Training loss: 1.815935730934143
Validation loss: 2.5355561035935597

Epoch: 6| Step: 9
Training loss: 3.3139266967773438
Validation loss: 2.5306898393938617

Epoch: 6| Step: 10
Training loss: 2.558452606201172
Validation loss: 2.5367494911275883

Epoch: 6| Step: 11
Training loss: 2.7044029235839844
Validation loss: 2.5723810503559728

Epoch: 6| Step: 12
Training loss: 3.152863025665283
Validation loss: 2.6548245696611303

Epoch: 6| Step: 13
Training loss: 3.159262180328369
Validation loss: 2.6452871676414245

Epoch: 29| Step: 0
Training loss: 3.6396846771240234
Validation loss: 2.654173033211821

Epoch: 6| Step: 1
Training loss: 2.2805142402648926
Validation loss: 2.6214138948789207

Epoch: 6| Step: 2
Training loss: 2.518173933029175
Validation loss: 2.5748834020348004

Epoch: 6| Step: 3
Training loss: 2.8935940265655518
Validation loss: 2.5448667118626256

Epoch: 6| Step: 4
Training loss: 3.042985677719116
Validation loss: 2.541244537599625

Epoch: 6| Step: 5
Training loss: 3.143794059753418
Validation loss: 2.5408818055224676

Epoch: 6| Step: 6
Training loss: 3.419947385787964
Validation loss: 2.5420826365870814

Epoch: 6| Step: 7
Training loss: 2.374873399734497
Validation loss: 2.5478793831281763

Epoch: 6| Step: 8
Training loss: 3.552377939224243
Validation loss: 2.5522685050964355

Epoch: 6| Step: 9
Training loss: 2.579841136932373
Validation loss: 2.548217801637547

Epoch: 6| Step: 10
Training loss: 2.0923547744750977
Validation loss: 2.5427055666523595

Epoch: 6| Step: 11
Training loss: 2.2170612812042236
Validation loss: 2.540686945761404

Epoch: 6| Step: 12
Training loss: 2.561922311782837
Validation loss: 2.538056960669897

Epoch: 6| Step: 13
Training loss: 2.106182098388672
Validation loss: 2.545265784827612

Epoch: 30| Step: 0
Training loss: 2.9895293712615967
Validation loss: 2.5455312882700274

Epoch: 6| Step: 1
Training loss: 4.025283336639404
Validation loss: 2.5562481008550173

Epoch: 6| Step: 2
Training loss: 3.1516518592834473
Validation loss: 2.5600245409114386

Epoch: 6| Step: 3
Training loss: 2.66717529296875
Validation loss: 2.5655183176840506

Epoch: 6| Step: 4
Training loss: 2.0198705196380615
Validation loss: 2.5613903819873767

Epoch: 6| Step: 5
Training loss: 3.1904096603393555
Validation loss: 2.5547209042374805

Epoch: 6| Step: 6
Training loss: 2.4730429649353027
Validation loss: 2.5571420474718978

Epoch: 6| Step: 7
Training loss: 2.6522529125213623
Validation loss: 2.5500183823288127

Epoch: 6| Step: 8
Training loss: 2.670954704284668
Validation loss: 2.537707803069904

Epoch: 6| Step: 9
Training loss: 2.383270025253296
Validation loss: 2.529717440246254

Epoch: 6| Step: 10
Training loss: 2.6885793209075928
Validation loss: 2.5350873342124363

Epoch: 6| Step: 11
Training loss: 3.0523979663848877
Validation loss: 2.546998470060287

Epoch: 6| Step: 12
Training loss: 2.110736608505249
Validation loss: 2.521130100373299

Epoch: 6| Step: 13
Training loss: 2.070246696472168
Validation loss: 2.515173642866073

Epoch: 31| Step: 0
Training loss: 2.9912867546081543
Validation loss: 2.517322829974595

Epoch: 6| Step: 1
Training loss: 2.2992842197418213
Validation loss: 2.512539694386144

Epoch: 6| Step: 2
Training loss: 2.66365385055542
Validation loss: 2.511332304246964

Epoch: 6| Step: 3
Training loss: 3.1598172187805176
Validation loss: 2.5184465377561507

Epoch: 6| Step: 4
Training loss: 2.421621799468994
Validation loss: 2.5239192285845355

Epoch: 6| Step: 5
Training loss: 2.6424686908721924
Validation loss: 2.54563069856295

Epoch: 6| Step: 6
Training loss: 3.374696969985962
Validation loss: 2.545469104602773

Epoch: 6| Step: 7
Training loss: 2.882138729095459
Validation loss: 2.5302120203612954

Epoch: 6| Step: 8
Training loss: 2.3746562004089355
Validation loss: 2.5289258777454333

Epoch: 6| Step: 9
Training loss: 2.880645990371704
Validation loss: 2.5337055960009174

Epoch: 6| Step: 10
Training loss: 2.1904163360595703
Validation loss: 2.510362755867743

Epoch: 6| Step: 11
Training loss: 2.7222466468811035
Validation loss: 2.5134849779067503

Epoch: 6| Step: 12
Training loss: 2.9197134971618652
Validation loss: 2.515309533765239

Epoch: 6| Step: 13
Training loss: 2.634218215942383
Validation loss: 2.5092143794541717

Epoch: 32| Step: 0
Training loss: 2.78299617767334
Validation loss: 2.502588438731368

Epoch: 6| Step: 1
Training loss: 3.4650955200195312
Validation loss: 2.50027972139338

Epoch: 6| Step: 2
Training loss: 2.2223873138427734
Validation loss: 2.500569361512379

Epoch: 6| Step: 3
Training loss: 2.2426912784576416
Validation loss: 2.4995182765427457

Epoch: 6| Step: 4
Training loss: 2.880629062652588
Validation loss: 2.5065022591621644

Epoch: 6| Step: 5
Training loss: 1.8912683725357056
Validation loss: 2.505579807425058

Epoch: 6| Step: 6
Training loss: 2.559718370437622
Validation loss: 2.5267585733885407

Epoch: 6| Step: 7
Training loss: 2.974116802215576
Validation loss: 2.556858024289531

Epoch: 6| Step: 8
Training loss: 2.8641557693481445
Validation loss: 2.5831681554035475

Epoch: 6| Step: 9
Training loss: 3.4655206203460693
Validation loss: 2.5610801430158716

Epoch: 6| Step: 10
Training loss: 2.574894428253174
Validation loss: 2.5532643154103267

Epoch: 6| Step: 11
Training loss: 3.0048744678497314
Validation loss: 2.5156465807268695

Epoch: 6| Step: 12
Training loss: 2.827120542526245
Validation loss: 2.489361721982238

Epoch: 6| Step: 13
Training loss: 2.2698850631713867
Validation loss: 2.495246200151341

Epoch: 33| Step: 0
Training loss: 2.7535433769226074
Validation loss: 2.493771432548441

Epoch: 6| Step: 1
Training loss: 2.543026924133301
Validation loss: 2.4968288842067925

Epoch: 6| Step: 2
Training loss: 2.295053005218506
Validation loss: 2.4994855388518302

Epoch: 6| Step: 3
Training loss: 2.712327003479004
Validation loss: 2.504264047068934

Epoch: 6| Step: 4
Training loss: 2.9670469760894775
Validation loss: 2.4977611777602986

Epoch: 6| Step: 5
Training loss: 2.714146137237549
Validation loss: 2.494672252285865

Epoch: 6| Step: 6
Training loss: 2.469404935836792
Validation loss: 2.497632393272974

Epoch: 6| Step: 7
Training loss: 3.2169108390808105
Validation loss: 2.4970925008097002

Epoch: 6| Step: 8
Training loss: 3.0468153953552246
Validation loss: 2.5012324369081886

Epoch: 6| Step: 9
Training loss: 2.4379448890686035
Validation loss: 2.498795942593646

Epoch: 6| Step: 10
Training loss: 2.5634026527404785
Validation loss: 2.4914010493986067

Epoch: 6| Step: 11
Training loss: 3.1798272132873535
Validation loss: 2.4933940287559264

Epoch: 6| Step: 12
Training loss: 2.4055843353271484
Validation loss: 2.489958852849981

Epoch: 6| Step: 13
Training loss: 2.6247029304504395
Validation loss: 2.485085492493004

Epoch: 34| Step: 0
Training loss: 2.990792751312256
Validation loss: 2.489314002375449

Epoch: 6| Step: 1
Training loss: 1.8267486095428467
Validation loss: 2.4891901836600354

Epoch: 6| Step: 2
Training loss: 2.9549760818481445
Validation loss: 2.5061427700904106

Epoch: 6| Step: 3
Training loss: 2.6704084873199463
Validation loss: 2.50826015780049

Epoch: 6| Step: 4
Training loss: 3.102332830429077
Validation loss: 2.492473122894123

Epoch: 6| Step: 5
Training loss: 1.9686861038208008
Validation loss: 2.4829651130143033

Epoch: 6| Step: 6
Training loss: 2.5480549335479736
Validation loss: 2.4799982886160574

Epoch: 6| Step: 7
Training loss: 2.7890095710754395
Validation loss: 2.482719231677312

Epoch: 6| Step: 8
Training loss: 3.2684054374694824
Validation loss: 2.487698496028941

Epoch: 6| Step: 9
Training loss: 2.852396249771118
Validation loss: 2.4847123622894287

Epoch: 6| Step: 10
Training loss: 3.1139495372772217
Validation loss: 2.4892481334747805

Epoch: 6| Step: 11
Training loss: 2.474992275238037
Validation loss: 2.484747968694215

Epoch: 6| Step: 12
Training loss: 3.1129698753356934
Validation loss: 2.4808400907824115

Epoch: 6| Step: 13
Training loss: 1.8935786485671997
Validation loss: 2.472891628101308

Epoch: 35| Step: 0
Training loss: 1.7234559059143066
Validation loss: 2.4746194142167286

Epoch: 6| Step: 1
Training loss: 3.0159502029418945
Validation loss: 2.4856440021145727

Epoch: 6| Step: 2
Training loss: 2.5330567359924316
Validation loss: 2.5010417840814076

Epoch: 6| Step: 3
Training loss: 1.840989589691162
Validation loss: 2.5108517908280894

Epoch: 6| Step: 4
Training loss: 3.456725597381592
Validation loss: 2.5156622394438712

Epoch: 6| Step: 5
Training loss: 2.533987045288086
Validation loss: 2.5016639386453936

Epoch: 6| Step: 6
Training loss: 2.683556079864502
Validation loss: 2.5027063251823507

Epoch: 6| Step: 7
Training loss: 3.2061381340026855
Validation loss: 2.492236650118264

Epoch: 6| Step: 8
Training loss: 3.095781087875366
Validation loss: 2.4849387612394107

Epoch: 6| Step: 9
Training loss: 3.169757127761841
Validation loss: 2.47867319660802

Epoch: 6| Step: 10
Training loss: 2.6017494201660156
Validation loss: 2.474474622357276

Epoch: 6| Step: 11
Training loss: 3.118605136871338
Validation loss: 2.474110003440611

Epoch: 6| Step: 12
Training loss: 2.2448794841766357
Validation loss: 2.471830937170213

Epoch: 6| Step: 13
Training loss: 2.259470224380493
Validation loss: 2.479218670116958

Epoch: 36| Step: 0
Training loss: 2.088399887084961
Validation loss: 2.4784040451049805

Epoch: 6| Step: 1
Training loss: 2.714667320251465
Validation loss: 2.474902896470921

Epoch: 6| Step: 2
Training loss: 3.1938116550445557
Validation loss: 2.471718067763954

Epoch: 6| Step: 3
Training loss: 2.9111666679382324
Validation loss: 2.4770377682101343

Epoch: 6| Step: 4
Training loss: 2.8716001510620117
Validation loss: 2.4845372271794144

Epoch: 6| Step: 5
Training loss: 2.5926899909973145
Validation loss: 2.4839042412337435

Epoch: 6| Step: 6
Training loss: 2.9791035652160645
Validation loss: 2.4836898029491468

Epoch: 6| Step: 7
Training loss: 2.431762218475342
Validation loss: 2.489919893203243

Epoch: 6| Step: 8
Training loss: 2.277477264404297
Validation loss: 2.488832119972475

Epoch: 6| Step: 9
Training loss: 2.3833351135253906
Validation loss: 2.491804840744183

Epoch: 6| Step: 10
Training loss: 2.3623099327087402
Validation loss: 2.502451822321902

Epoch: 6| Step: 11
Training loss: 3.1274032592773438
Validation loss: 2.502983759808284

Epoch: 6| Step: 12
Training loss: 3.7110910415649414
Validation loss: 2.4881994211545555

Epoch: 6| Step: 13
Training loss: 1.6996510028839111
Validation loss: 2.4727777178569506

Epoch: 37| Step: 0
Training loss: 2.886551856994629
Validation loss: 2.46658230340609

Epoch: 6| Step: 1
Training loss: 3.033341407775879
Validation loss: 2.4598030915824314

Epoch: 6| Step: 2
Training loss: 3.2394661903381348
Validation loss: 2.4561100647013676

Epoch: 6| Step: 3
Training loss: 2.477804660797119
Validation loss: 2.4607533562567925

Epoch: 6| Step: 4
Training loss: 3.2981581687927246
Validation loss: 2.471250246929866

Epoch: 6| Step: 5
Training loss: 1.3177425861358643
Validation loss: 2.4771769687693608

Epoch: 6| Step: 6
Training loss: 3.285076856613159
Validation loss: 2.5044994713157736

Epoch: 6| Step: 7
Training loss: 2.6578893661499023
Validation loss: 2.5088380485452633

Epoch: 6| Step: 8
Training loss: 2.479562282562256
Validation loss: 2.515454033369659

Epoch: 6| Step: 9
Training loss: 2.4107794761657715
Validation loss: 2.5070421721345637

Epoch: 6| Step: 10
Training loss: 3.2118897438049316
Validation loss: 2.479556324661419

Epoch: 6| Step: 11
Training loss: 1.9681000709533691
Validation loss: 2.461985695746637

Epoch: 6| Step: 12
Training loss: 2.662680149078369
Validation loss: 2.4559158548232047

Epoch: 6| Step: 13
Training loss: 2.8001327514648438
Validation loss: 2.4699820779984996

Epoch: 38| Step: 0
Training loss: 2.5924882888793945
Validation loss: 2.492247999355357

Epoch: 6| Step: 1
Training loss: 3.0802135467529297
Validation loss: 2.537058994334231

Epoch: 6| Step: 2
Training loss: 3.127950429916382
Validation loss: 2.5046393640579714

Epoch: 6| Step: 3
Training loss: 2.0699543952941895
Validation loss: 2.490008513132731

Epoch: 6| Step: 4
Training loss: 2.147129535675049
Validation loss: 2.4651469825416483

Epoch: 6| Step: 5
Training loss: 2.676708221435547
Validation loss: 2.4637100388926845

Epoch: 6| Step: 6
Training loss: 3.0990023612976074
Validation loss: 2.4669883840827533

Epoch: 6| Step: 7
Training loss: 2.740325450897217
Validation loss: 2.475372096543671

Epoch: 6| Step: 8
Training loss: 2.630845546722412
Validation loss: 2.491538296463669

Epoch: 6| Step: 9
Training loss: 2.8468689918518066
Validation loss: 2.5019724574140323

Epoch: 6| Step: 10
Training loss: 3.5578653812408447
Validation loss: 2.5138180704527002

Epoch: 6| Step: 11
Training loss: 2.2057509422302246
Validation loss: 2.5029549111602125

Epoch: 6| Step: 12
Training loss: 2.767047643661499
Validation loss: 2.4915982189998833

Epoch: 6| Step: 13
Training loss: 2.125094175338745
Validation loss: 2.480526101204657

Epoch: 39| Step: 0
Training loss: 3.0532491207122803
Validation loss: 2.469646530766641

Epoch: 6| Step: 1
Training loss: 3.1207339763641357
Validation loss: 2.4691036157710577

Epoch: 6| Step: 2
Training loss: 3.3222246170043945
Validation loss: 2.4694011057576826

Epoch: 6| Step: 3
Training loss: 1.8136711120605469
Validation loss: 2.452463726843557

Epoch: 6| Step: 4
Training loss: 3.004229784011841
Validation loss: 2.452942914860223

Epoch: 6| Step: 5
Training loss: 2.5528664588928223
Validation loss: 2.450827455007902

Epoch: 6| Step: 6
Training loss: 2.7221741676330566
Validation loss: 2.445484443377423

Epoch: 6| Step: 7
Training loss: 2.2544639110565186
Validation loss: 2.4460703865174325

Epoch: 6| Step: 8
Training loss: 3.2055985927581787
Validation loss: 2.4467618106513895

Epoch: 6| Step: 9
Training loss: 2.689228057861328
Validation loss: 2.4457196420238865

Epoch: 6| Step: 10
Training loss: 1.994966983795166
Validation loss: 2.4470040875096477

Epoch: 6| Step: 11
Training loss: 2.717686653137207
Validation loss: 2.4502795332221576

Epoch: 6| Step: 12
Training loss: 2.7382211685180664
Validation loss: 2.45370049886806

Epoch: 6| Step: 13
Training loss: 2.110748291015625
Validation loss: 2.45512544467885

Epoch: 40| Step: 0
Training loss: 2.779324531555176
Validation loss: 2.471075475856822

Epoch: 6| Step: 1
Training loss: 2.7186403274536133
Validation loss: 2.4672882633824504

Epoch: 6| Step: 2
Training loss: 1.867565631866455
Validation loss: 2.473063694533481

Epoch: 6| Step: 3
Training loss: 2.3856661319732666
Validation loss: 2.4720391868263163

Epoch: 6| Step: 4
Training loss: 2.658637285232544
Validation loss: 2.446591538767661

Epoch: 6| Step: 5
Training loss: 2.8410799503326416
Validation loss: 2.446794666269774

Epoch: 6| Step: 6
Training loss: 2.8001744747161865
Validation loss: 2.4456807951773367

Epoch: 6| Step: 7
Training loss: 3.45186710357666
Validation loss: 2.446277677371938

Epoch: 6| Step: 8
Training loss: 2.7052931785583496
Validation loss: 2.448995964501494

Epoch: 6| Step: 9
Training loss: 2.494143009185791
Validation loss: 2.447153737468104

Epoch: 6| Step: 10
Training loss: 2.3484771251678467
Validation loss: 2.438059896551153

Epoch: 6| Step: 11
Training loss: 2.6820149421691895
Validation loss: 2.449030573650073

Epoch: 6| Step: 12
Training loss: 3.0956966876983643
Validation loss: 2.45783523590334

Epoch: 6| Step: 13
Training loss: 2.5652167797088623
Validation loss: 2.4639320014625468

Epoch: 41| Step: 0
Training loss: 2.304368019104004
Validation loss: 2.463622672583467

Epoch: 6| Step: 1
Training loss: 3.097461223602295
Validation loss: 2.4694321360639346

Epoch: 6| Step: 2
Training loss: 2.3393664360046387
Validation loss: 2.4735513938370572

Epoch: 6| Step: 3
Training loss: 2.7894186973571777
Validation loss: 2.48277005328927

Epoch: 6| Step: 4
Training loss: 2.770580768585205
Validation loss: 2.495752321776523

Epoch: 6| Step: 5
Training loss: 2.4286255836486816
Validation loss: 2.477195232145248

Epoch: 6| Step: 6
Training loss: 2.4619297981262207
Validation loss: 2.453503134430096

Epoch: 6| Step: 7
Training loss: 2.051274538040161
Validation loss: 2.441743594343944

Epoch: 6| Step: 8
Training loss: 3.2676615715026855
Validation loss: 2.439762492333689

Epoch: 6| Step: 9
Training loss: 2.5951833724975586
Validation loss: 2.4447337453083327

Epoch: 6| Step: 10
Training loss: 2.574617385864258
Validation loss: 2.4451979283363587

Epoch: 6| Step: 11
Training loss: 2.5569732189178467
Validation loss: 2.447431307966991

Epoch: 6| Step: 12
Training loss: 3.130615472793579
Validation loss: 2.451328351933469

Epoch: 6| Step: 13
Training loss: 3.2743093967437744
Validation loss: 2.450452612292382

Epoch: 42| Step: 0
Training loss: 2.1412272453308105
Validation loss: 2.451898444083429

Epoch: 6| Step: 1
Training loss: 2.411052703857422
Validation loss: 2.4530783571222776

Epoch: 6| Step: 2
Training loss: 1.5753252506256104
Validation loss: 2.4606038139712427

Epoch: 6| Step: 3
Training loss: 3.188659191131592
Validation loss: 2.4623940836998726

Epoch: 6| Step: 4
Training loss: 2.5876426696777344
Validation loss: 2.4581249862588863

Epoch: 6| Step: 5
Training loss: 2.935202121734619
Validation loss: 2.450560171117065

Epoch: 6| Step: 6
Training loss: 3.101128101348877
Validation loss: 2.4413493115414857

Epoch: 6| Step: 7
Training loss: 2.419565439224243
Validation loss: 2.4358612670693347

Epoch: 6| Step: 8
Training loss: 2.9757988452911377
Validation loss: 2.4350033037124144

Epoch: 6| Step: 9
Training loss: 2.9874720573425293
Validation loss: 2.4298647244771323

Epoch: 6| Step: 10
Training loss: 2.825192451477051
Validation loss: 2.427753520268266

Epoch: 6| Step: 11
Training loss: 2.8994929790496826
Validation loss: 2.4235496110813592

Epoch: 6| Step: 12
Training loss: 2.3932952880859375
Validation loss: 2.4306590249461513

Epoch: 6| Step: 13
Training loss: 3.43361234664917
Validation loss: 2.4527658749652166

Epoch: 43| Step: 0
Training loss: 2.743515968322754
Validation loss: 2.500183936088316

Epoch: 6| Step: 1
Training loss: 2.2285571098327637
Validation loss: 2.5102137647649294

Epoch: 6| Step: 2
Training loss: 2.8187499046325684
Validation loss: 2.5212116344000703

Epoch: 6| Step: 3
Training loss: 2.9980690479278564
Validation loss: 2.5059784099619877

Epoch: 6| Step: 4
Training loss: 2.6774659156799316
Validation loss: 2.513570398412725

Epoch: 6| Step: 5
Training loss: 2.3951878547668457
Validation loss: 2.4950137240912325

Epoch: 6| Step: 6
Training loss: 2.9652771949768066
Validation loss: 2.477525431622741

Epoch: 6| Step: 7
Training loss: 3.1917622089385986
Validation loss: 2.4534233667517222

Epoch: 6| Step: 8
Training loss: 2.4757089614868164
Validation loss: 2.441742358669158

Epoch: 6| Step: 9
Training loss: 3.351773500442505
Validation loss: 2.431441207085886

Epoch: 6| Step: 10
Training loss: 2.190457344055176
Validation loss: 2.4206134273159887

Epoch: 6| Step: 11
Training loss: 2.6783618927001953
Validation loss: 2.411261773878528

Epoch: 6| Step: 12
Training loss: 2.120312213897705
Validation loss: 2.4118252313265236

Epoch: 6| Step: 13
Training loss: 2.7635960578918457
Validation loss: 2.418473874368975

Epoch: 44| Step: 0
Training loss: 2.9701108932495117
Validation loss: 2.4188226397319506

Epoch: 6| Step: 1
Training loss: 2.7063777446746826
Validation loss: 2.4188622249070035

Epoch: 6| Step: 2
Training loss: 2.429684638977051
Validation loss: 2.4121446994043167

Epoch: 6| Step: 3
Training loss: 2.6600966453552246
Validation loss: 2.409959803345383

Epoch: 6| Step: 4
Training loss: 1.8403517007827759
Validation loss: 2.4132541379620953

Epoch: 6| Step: 5
Training loss: 3.2556939125061035
Validation loss: 2.420015814483807

Epoch: 6| Step: 6
Training loss: 2.9342894554138184
Validation loss: 2.416389129495108

Epoch: 6| Step: 7
Training loss: 2.58699369430542
Validation loss: 2.4153551773358415

Epoch: 6| Step: 8
Training loss: 3.0181026458740234
Validation loss: 2.413774718520462

Epoch: 6| Step: 9
Training loss: 2.1988024711608887
Validation loss: 2.4140852676924838

Epoch: 6| Step: 10
Training loss: 2.950873374938965
Validation loss: 2.4095805896225797

Epoch: 6| Step: 11
Training loss: 2.7243425846099854
Validation loss: 2.4068846318029586

Epoch: 6| Step: 12
Training loss: 2.4547829627990723
Validation loss: 2.402615608707551

Epoch: 6| Step: 13
Training loss: 2.3916866779327393
Validation loss: 2.409194600197577

Epoch: 45| Step: 0
Training loss: 2.3571197986602783
Validation loss: 2.4058028959458873

Epoch: 6| Step: 1
Training loss: 2.2847490310668945
Validation loss: 2.406324160996304

Epoch: 6| Step: 2
Training loss: 3.0015110969543457
Validation loss: 2.4095938462083057

Epoch: 6| Step: 3
Training loss: 1.7980003356933594
Validation loss: 2.4082571626991354

Epoch: 6| Step: 4
Training loss: 2.234422445297241
Validation loss: 2.4071326589071624

Epoch: 6| Step: 5
Training loss: 2.9124369621276855
Validation loss: 2.4079006128413702

Epoch: 6| Step: 6
Training loss: 3.262974262237549
Validation loss: 2.4111217657725015

Epoch: 6| Step: 7
Training loss: 2.7705819606781006
Validation loss: 2.414465332543978

Epoch: 6| Step: 8
Training loss: 2.70628023147583
Validation loss: 2.418632871361189

Epoch: 6| Step: 9
Training loss: 2.9563398361206055
Validation loss: 2.4201785749004734

Epoch: 6| Step: 10
Training loss: 2.8943140506744385
Validation loss: 2.4289817810058594

Epoch: 6| Step: 11
Training loss: 2.868774890899658
Validation loss: 2.438003760512157

Epoch: 6| Step: 12
Training loss: 2.5113637447357178
Validation loss: 2.4404839725904566

Epoch: 6| Step: 13
Training loss: 2.5116047859191895
Validation loss: 2.460465149212909

Epoch: 46| Step: 0
Training loss: 2.721367359161377
Validation loss: 2.4481198685143584

Epoch: 6| Step: 1
Training loss: 2.274028778076172
Validation loss: 2.4222649579407065

Epoch: 6| Step: 2
Training loss: 3.142991065979004
Validation loss: 2.414013880555348

Epoch: 6| Step: 3
Training loss: 2.968029022216797
Validation loss: 2.409582409807431

Epoch: 6| Step: 4
Training loss: 1.6656765937805176
Validation loss: 2.403481524477723

Epoch: 6| Step: 5
Training loss: 2.701528549194336
Validation loss: 2.402610812135922

Epoch: 6| Step: 6
Training loss: 2.3939208984375
Validation loss: 2.3989946047465005

Epoch: 6| Step: 7
Training loss: 2.0018529891967773
Validation loss: 2.3983972944239134

Epoch: 6| Step: 8
Training loss: 2.663029193878174
Validation loss: 2.3922585133583314

Epoch: 6| Step: 9
Training loss: 2.746932029724121
Validation loss: 2.3970996948980514

Epoch: 6| Step: 10
Training loss: 3.050837278366089
Validation loss: 2.408879454417895

Epoch: 6| Step: 11
Training loss: 3.090341567993164
Validation loss: 2.427937869102724

Epoch: 6| Step: 12
Training loss: 2.9881887435913086
Validation loss: 2.432988594937068

Epoch: 6| Step: 13
Training loss: 3.0440590381622314
Validation loss: 2.4366306053694857

Epoch: 47| Step: 0
Training loss: 2.2635037899017334
Validation loss: 2.4404213864316224

Epoch: 6| Step: 1
Training loss: 2.316286087036133
Validation loss: 2.446045583294284

Epoch: 6| Step: 2
Training loss: 2.248253107070923
Validation loss: 2.465610014495029

Epoch: 6| Step: 3
Training loss: 2.356999158859253
Validation loss: 2.47642715771993

Epoch: 6| Step: 4
Training loss: 2.5849881172180176
Validation loss: 2.4996143592301237

Epoch: 6| Step: 5
Training loss: 1.8993172645568848
Validation loss: 2.518167080417756

Epoch: 6| Step: 6
Training loss: 3.309176206588745
Validation loss: 2.4979116121927896

Epoch: 6| Step: 7
Training loss: 3.0623960494995117
Validation loss: 2.456350354738133

Epoch: 6| Step: 8
Training loss: 3.5239174365997314
Validation loss: 2.4105752565527476

Epoch: 6| Step: 9
Training loss: 2.755772590637207
Validation loss: 2.3956065306099514

Epoch: 6| Step: 10
Training loss: 2.5455915927886963
Validation loss: 2.4019648772414013

Epoch: 6| Step: 11
Training loss: 3.4293487071990967
Validation loss: 2.4045688118985904

Epoch: 6| Step: 12
Training loss: 2.7902259826660156
Validation loss: 2.391117657384565

Epoch: 6| Step: 13
Training loss: 1.568032145500183
Validation loss: 2.3932163433362077

Epoch: 48| Step: 0
Training loss: 2.726309061050415
Validation loss: 2.4010555872353176

Epoch: 6| Step: 1
Training loss: 2.546002149581909
Validation loss: 2.4022151270220355

Epoch: 6| Step: 2
Training loss: 2.075509548187256
Validation loss: 2.4006069321786203

Epoch: 6| Step: 3
Training loss: 2.711622953414917
Validation loss: 2.383328014804471

Epoch: 6| Step: 4
Training loss: 2.586068868637085
Validation loss: 2.378234750481062

Epoch: 6| Step: 5
Training loss: 2.9853768348693848
Validation loss: 2.3755687462386263

Epoch: 6| Step: 6
Training loss: 2.6284608840942383
Validation loss: 2.3806208513116323

Epoch: 6| Step: 7
Training loss: 2.9361395835876465
Validation loss: 2.386367905524469

Epoch: 6| Step: 8
Training loss: 2.47298526763916
Validation loss: 2.3940616346174672

Epoch: 6| Step: 9
Training loss: 2.534644603729248
Validation loss: 2.40754000858594

Epoch: 6| Step: 10
Training loss: 2.6828055381774902
Validation loss: 2.4264217371581704

Epoch: 6| Step: 11
Training loss: 2.787059783935547
Validation loss: 2.424259167845531

Epoch: 6| Step: 12
Training loss: 2.71848201751709
Validation loss: 2.41120788615237

Epoch: 6| Step: 13
Training loss: 2.7544267177581787
Validation loss: 2.4000733283258255

Epoch: 49| Step: 0
Training loss: 2.5531582832336426
Validation loss: 2.39318670252318

Epoch: 6| Step: 1
Training loss: 2.2901201248168945
Validation loss: 2.3960213558648222

Epoch: 6| Step: 2
Training loss: 2.706521511077881
Validation loss: 2.4053856147232877

Epoch: 6| Step: 3
Training loss: 2.475428342819214
Validation loss: 2.4083931753712315

Epoch: 6| Step: 4
Training loss: 3.334207057952881
Validation loss: 2.4039388625852522

Epoch: 6| Step: 5
Training loss: 3.614156723022461
Validation loss: 2.388513121553647

Epoch: 6| Step: 6
Training loss: 2.00131893157959
Validation loss: 2.3797503517520044

Epoch: 6| Step: 7
Training loss: 3.159276008605957
Validation loss: 2.381541713591545

Epoch: 6| Step: 8
Training loss: 3.3872642517089844
Validation loss: 2.3725637107767086

Epoch: 6| Step: 9
Training loss: 2.124495267868042
Validation loss: 2.3708188482510146

Epoch: 6| Step: 10
Training loss: 1.9425208568572998
Validation loss: 2.371959242769467

Epoch: 6| Step: 11
Training loss: 2.0283920764923096
Validation loss: 2.3707532421235116

Epoch: 6| Step: 12
Training loss: 2.388347864151001
Validation loss: 2.3721870760763846

Epoch: 6| Step: 13
Training loss: 2.942103862762451
Validation loss: 2.3724606037139893

Epoch: 50| Step: 0
Training loss: 2.4714622497558594
Validation loss: 2.368232742432625

Epoch: 6| Step: 1
Training loss: 2.7196383476257324
Validation loss: 2.3691721321434103

Epoch: 6| Step: 2
Training loss: 3.08064341545105
Validation loss: 2.366155357771022

Epoch: 6| Step: 3
Training loss: 2.123994827270508
Validation loss: 2.3645449005147463

Epoch: 6| Step: 4
Training loss: 2.9113006591796875
Validation loss: 2.367517750750306

Epoch: 6| Step: 5
Training loss: 2.7905242443084717
Validation loss: 2.368289775745843

Epoch: 6| Step: 6
Training loss: 2.652263641357422
Validation loss: 2.368414609662948

Epoch: 6| Step: 7
Training loss: 2.2408416271209717
Validation loss: 2.369319559425436

Epoch: 6| Step: 8
Training loss: 2.3955657482147217
Validation loss: 2.3705207609361216

Epoch: 6| Step: 9
Training loss: 2.5051276683807373
Validation loss: 2.3689440322178665

Epoch: 6| Step: 10
Training loss: 2.9085676670074463
Validation loss: 2.369501949638449

Epoch: 6| Step: 11
Training loss: 2.580599784851074
Validation loss: 2.367838507057518

Epoch: 6| Step: 12
Training loss: 2.861360549926758
Validation loss: 2.369750160042958

Epoch: 6| Step: 13
Training loss: 2.5448484420776367
Validation loss: 2.3695355102580082

Epoch: 51| Step: 0
Training loss: 2.7116782665252686
Validation loss: 2.3715642318930676

Epoch: 6| Step: 1
Training loss: 2.6694483757019043
Validation loss: 2.3747019549851776

Epoch: 6| Step: 2
Training loss: 2.128849744796753
Validation loss: 2.3744443103831303

Epoch: 6| Step: 3
Training loss: 3.1568233966827393
Validation loss: 2.3695541299799436

Epoch: 6| Step: 4
Training loss: 2.7910990715026855
Validation loss: 2.365750269223285

Epoch: 6| Step: 5
Training loss: 2.6402478218078613
Validation loss: 2.364190342605755

Epoch: 6| Step: 6
Training loss: 2.456268787384033
Validation loss: 2.3642267309209353

Epoch: 6| Step: 7
Training loss: 2.088700294494629
Validation loss: 2.363252347515475

Epoch: 6| Step: 8
Training loss: 3.260990619659424
Validation loss: 2.367308862747685

Epoch: 6| Step: 9
Training loss: 3.5931756496429443
Validation loss: 2.3607485037977978

Epoch: 6| Step: 10
Training loss: 2.3944602012634277
Validation loss: 2.361877574715563

Epoch: 6| Step: 11
Training loss: 2.09958553314209
Validation loss: 2.3631697059959493

Epoch: 6| Step: 12
Training loss: 2.056913137435913
Validation loss: 2.373831031143024

Epoch: 6| Step: 13
Training loss: 2.678746223449707
Validation loss: 2.401900153006277

Epoch: 52| Step: 0
Training loss: 2.4223763942718506
Validation loss: 2.4063362203618532

Epoch: 6| Step: 1
Training loss: 2.2435147762298584
Validation loss: 2.399050627985308

Epoch: 6| Step: 2
Training loss: 2.863461494445801
Validation loss: 2.383553789507958

Epoch: 6| Step: 3
Training loss: 2.0771093368530273
Validation loss: 2.379127020476967

Epoch: 6| Step: 4
Training loss: 3.5050268173217773
Validation loss: 2.369324694397629

Epoch: 6| Step: 5
Training loss: 2.2747182846069336
Validation loss: 2.3595414546228226

Epoch: 6| Step: 6
Training loss: 3.1270244121551514
Validation loss: 2.3516099914427726

Epoch: 6| Step: 7
Training loss: 2.3360767364501953
Validation loss: 2.351650802038049

Epoch: 6| Step: 8
Training loss: 2.5492093563079834
Validation loss: 2.3546757185330955

Epoch: 6| Step: 9
Training loss: 2.5960869789123535
Validation loss: 2.369842690806235

Epoch: 6| Step: 10
Training loss: 2.9748730659484863
Validation loss: 2.368064526588686

Epoch: 6| Step: 11
Training loss: 2.382812738418579
Validation loss: 2.3659218485637377

Epoch: 6| Step: 12
Training loss: 3.024853229522705
Validation loss: 2.359773107754287

Epoch: 6| Step: 13
Training loss: 2.40421724319458
Validation loss: 2.3562595562268327

Epoch: 53| Step: 0
Training loss: 2.8567991256713867
Validation loss: 2.351720044689794

Epoch: 6| Step: 1
Training loss: 2.8169548511505127
Validation loss: 2.33763986761852

Epoch: 6| Step: 2
Training loss: 2.575287342071533
Validation loss: 2.363577814512355

Epoch: 6| Step: 3
Training loss: 2.3682119846343994
Validation loss: 2.3826485936359694

Epoch: 6| Step: 4
Training loss: 2.5325798988342285
Validation loss: 2.390077083341537

Epoch: 6| Step: 5
Training loss: 2.105273962020874
Validation loss: 2.384146564750261

Epoch: 6| Step: 6
Training loss: 2.815563678741455
Validation loss: 2.3843015778449272

Epoch: 6| Step: 7
Training loss: 2.56610107421875
Validation loss: 2.3706894279808126

Epoch: 6| Step: 8
Training loss: 2.845578193664551
Validation loss: 2.363025103845904

Epoch: 6| Step: 9
Training loss: 2.732490062713623
Validation loss: 2.3527996681069814

Epoch: 6| Step: 10
Training loss: 2.5464987754821777
Validation loss: 2.34547431238236

Epoch: 6| Step: 11
Training loss: 2.907991647720337
Validation loss: 2.3443733620387253

Epoch: 6| Step: 12
Training loss: 2.296947956085205
Validation loss: 2.347270652812014

Epoch: 6| Step: 13
Training loss: 2.981450080871582
Validation loss: 2.3529491219469296

Epoch: 54| Step: 0
Training loss: 3.049590587615967
Validation loss: 2.3596282518038185

Epoch: 6| Step: 1
Training loss: 3.3572463989257812
Validation loss: 2.3602841233694427

Epoch: 6| Step: 2
Training loss: 3.0861856937408447
Validation loss: 2.358922561009725

Epoch: 6| Step: 3
Training loss: 2.1880431175231934
Validation loss: 2.351864068738876

Epoch: 6| Step: 4
Training loss: 2.7598109245300293
Validation loss: 2.342806380282166

Epoch: 6| Step: 5
Training loss: 2.3800601959228516
Validation loss: 2.3361875164893364

Epoch: 6| Step: 6
Training loss: 3.7291417121887207
Validation loss: 2.3451333251050723

Epoch: 6| Step: 7
Training loss: 2.3783254623413086
Validation loss: 2.385152041271169

Epoch: 6| Step: 8
Training loss: 2.7355635166168213
Validation loss: 2.42101034297738

Epoch: 6| Step: 9
Training loss: 2.6843013763427734
Validation loss: 2.425560648723315

Epoch: 6| Step: 10
Training loss: 2.1528234481811523
Validation loss: 2.443532589943178

Epoch: 6| Step: 11
Training loss: 1.3691048622131348
Validation loss: 2.4097628157625914

Epoch: 6| Step: 12
Training loss: 2.882213592529297
Validation loss: 2.4062039288141395

Epoch: 6| Step: 13
Training loss: 1.708573818206787
Validation loss: 2.3888400446984077

Epoch: 55| Step: 0
Training loss: 2.4843595027923584
Validation loss: 2.3832526617152716

Epoch: 6| Step: 1
Training loss: 2.1340465545654297
Validation loss: 2.368903818950858

Epoch: 6| Step: 2
Training loss: 3.3053932189941406
Validation loss: 2.3490976300290836

Epoch: 6| Step: 3
Training loss: 3.122675895690918
Validation loss: 2.334889283744238

Epoch: 6| Step: 4
Training loss: 3.315641403198242
Validation loss: 2.325945419649924

Epoch: 6| Step: 5
Training loss: 2.7534101009368896
Validation loss: 2.338428140968405

Epoch: 6| Step: 6
Training loss: 2.6907331943511963
Validation loss: 2.3510506024924656

Epoch: 6| Step: 7
Training loss: 2.592359781265259
Validation loss: 2.3640969171318957

Epoch: 6| Step: 8
Training loss: 2.7642645835876465
Validation loss: 2.3728718962720645

Epoch: 6| Step: 9
Training loss: 1.9497264623641968
Validation loss: 2.3651491826580417

Epoch: 6| Step: 10
Training loss: 2.3993279933929443
Validation loss: 2.359510919099213

Epoch: 6| Step: 11
Training loss: 2.0657448768615723
Validation loss: 2.351374101895158

Epoch: 6| Step: 12
Training loss: 2.919501781463623
Validation loss: 2.346759473123858

Epoch: 6| Step: 13
Training loss: 2.4572386741638184
Validation loss: 2.3420232521590365

Epoch: 56| Step: 0
Training loss: 2.8274269104003906
Validation loss: 2.334066447391305

Epoch: 6| Step: 1
Training loss: 2.9256391525268555
Validation loss: 2.3254225523241105

Epoch: 6| Step: 2
Training loss: 2.3284640312194824
Validation loss: 2.319946668481314

Epoch: 6| Step: 3
Training loss: 2.0382156372070312
Validation loss: 2.3355922570792575

Epoch: 6| Step: 4
Training loss: 2.3164401054382324
Validation loss: 2.3633056661134124

Epoch: 6| Step: 5
Training loss: 2.705580711364746
Validation loss: 2.41313261114141

Epoch: 6| Step: 6
Training loss: 3.546144485473633
Validation loss: 2.430560378618138

Epoch: 6| Step: 7
Training loss: 2.061203718185425
Validation loss: 2.4337955264634985

Epoch: 6| Step: 8
Training loss: 2.4117445945739746
Validation loss: 2.4086540642605034

Epoch: 6| Step: 9
Training loss: 2.5395755767822266
Validation loss: 2.377056655063424

Epoch: 6| Step: 10
Training loss: 3.0620579719543457
Validation loss: 2.3769306546898297

Epoch: 6| Step: 11
Training loss: 3.436797618865967
Validation loss: 2.3555233965637865

Epoch: 6| Step: 12
Training loss: 2.196434259414673
Validation loss: 2.340916641296879

Epoch: 6| Step: 13
Training loss: 1.9734255075454712
Validation loss: 2.3349354600393646

Epoch: 57| Step: 0
Training loss: 1.999223232269287
Validation loss: 2.3167016454922256

Epoch: 6| Step: 1
Training loss: 2.1366755962371826
Validation loss: 2.316354690059539

Epoch: 6| Step: 2
Training loss: 2.5850844383239746
Validation loss: 2.3120424798739854

Epoch: 6| Step: 3
Training loss: 3.0719807147979736
Validation loss: 2.3128150265703917

Epoch: 6| Step: 4
Training loss: 2.98488712310791
Validation loss: 2.3087703181851293

Epoch: 6| Step: 5
Training loss: 2.935441017150879
Validation loss: 2.316827997084587

Epoch: 6| Step: 6
Training loss: 2.7880284786224365
Validation loss: 2.3171246654243878

Epoch: 6| Step: 7
Training loss: 3.007657289505005
Validation loss: 2.3165688283981813

Epoch: 6| Step: 8
Training loss: 2.2273576259613037
Validation loss: 2.3153661015213176

Epoch: 6| Step: 9
Training loss: 2.4379701614379883
Validation loss: 2.311576707388765

Epoch: 6| Step: 10
Training loss: 2.2224526405334473
Validation loss: 2.3144093251997426

Epoch: 6| Step: 11
Training loss: 2.6014151573181152
Validation loss: 2.3365862600265013

Epoch: 6| Step: 12
Training loss: 2.560990333557129
Validation loss: 2.345323342148976

Epoch: 6| Step: 13
Training loss: 2.96688175201416
Validation loss: 2.3461684744845153

Epoch: 58| Step: 0
Training loss: 2.8491897583007812
Validation loss: 2.3356656720561366

Epoch: 6| Step: 1
Training loss: 2.117218255996704
Validation loss: 2.3381223383770195

Epoch: 6| Step: 2
Training loss: 2.327228546142578
Validation loss: 2.3322013488379856

Epoch: 6| Step: 3
Training loss: 3.0535941123962402
Validation loss: 2.3359876089198615

Epoch: 6| Step: 4
Training loss: 2.6507506370544434
Validation loss: 2.3541074850225963

Epoch: 6| Step: 5
Training loss: 2.388906955718994
Validation loss: 2.361732203473327

Epoch: 6| Step: 6
Training loss: 2.578934669494629
Validation loss: 2.3640786396559847

Epoch: 6| Step: 7
Training loss: 2.4566566944122314
Validation loss: 2.354274885628813

Epoch: 6| Step: 8
Training loss: 2.403648853302002
Validation loss: 2.3683079904125584

Epoch: 6| Step: 9
Training loss: 2.4316980838775635
Validation loss: 2.374244487413796

Epoch: 6| Step: 10
Training loss: 3.2259633541107178
Validation loss: 2.363277328911648

Epoch: 6| Step: 11
Training loss: 2.674663543701172
Validation loss: 2.3258119808730258

Epoch: 6| Step: 12
Training loss: 2.3840136528015137
Validation loss: 2.3058149045513523

Epoch: 6| Step: 13
Training loss: 2.7586801052093506
Validation loss: 2.304881300977481

Epoch: 59| Step: 0
Training loss: 2.393467426300049
Validation loss: 2.3130113258156726

Epoch: 6| Step: 1
Training loss: 3.6063852310180664
Validation loss: 2.318934891813545

Epoch: 6| Step: 2
Training loss: 3.0745317935943604
Validation loss: 2.3200404541466826

Epoch: 6| Step: 3
Training loss: 2.598540782928467
Validation loss: 2.3173392177909933

Epoch: 6| Step: 4
Training loss: 2.2066102027893066
Validation loss: 2.32547656695048

Epoch: 6| Step: 5
Training loss: 2.440150260925293
Validation loss: 2.3235773399312007

Epoch: 6| Step: 6
Training loss: 1.904343605041504
Validation loss: 2.3317937594588085

Epoch: 6| Step: 7
Training loss: 2.1032824516296387
Validation loss: 2.3080140108703286

Epoch: 6| Step: 8
Training loss: 3.0651187896728516
Validation loss: 2.293622644998694

Epoch: 6| Step: 9
Training loss: 2.550499439239502
Validation loss: 2.2877813821197837

Epoch: 6| Step: 10
Training loss: 3.0244410037994385
Validation loss: 2.3074347049959245

Epoch: 6| Step: 11
Training loss: 2.5946712493896484
Validation loss: 2.3365575549423054

Epoch: 6| Step: 12
Training loss: 1.6751453876495361
Validation loss: 2.382853361868089

Epoch: 6| Step: 13
Training loss: 3.6595678329467773
Validation loss: 2.4867202927989345

Epoch: 60| Step: 0
Training loss: 2.3416037559509277
Validation loss: 2.553834725451726

Epoch: 6| Step: 1
Training loss: 2.3795523643493652
Validation loss: 2.502269209072154

Epoch: 6| Step: 2
Training loss: 2.936800956726074
Validation loss: 2.409340491858862

Epoch: 6| Step: 3
Training loss: 1.8520396947860718
Validation loss: 2.3416129158389185

Epoch: 6| Step: 4
Training loss: 2.9696450233459473
Validation loss: 2.3076724929194294

Epoch: 6| Step: 5
Training loss: 2.501633882522583
Validation loss: 2.2961785113939674

Epoch: 6| Step: 6
Training loss: 2.997044563293457
Validation loss: 2.2912567174562843

Epoch: 6| Step: 7
Training loss: 2.7371153831481934
Validation loss: 2.294531924750215

Epoch: 6| Step: 8
Training loss: 2.2142539024353027
Validation loss: 2.2990881858333463

Epoch: 6| Step: 9
Training loss: 3.13439679145813
Validation loss: 2.305276639999882

Epoch: 6| Step: 10
Training loss: 2.432518720626831
Validation loss: 2.305150193552817

Epoch: 6| Step: 11
Training loss: 2.8724331855773926
Validation loss: 2.3205071854335007

Epoch: 6| Step: 12
Training loss: 2.8153023719787598
Validation loss: 2.3247523794892015

Epoch: 6| Step: 13
Training loss: 2.393588066101074
Validation loss: 2.336428596127418

Epoch: 61| Step: 0
Training loss: 2.7502248287200928
Validation loss: 2.3400879777887815

Epoch: 6| Step: 1
Training loss: 3.4429588317871094
Validation loss: 2.345402204862205

Epoch: 6| Step: 2
Training loss: 2.4423577785491943
Validation loss: 2.347824063352359

Epoch: 6| Step: 3
Training loss: 2.6136977672576904
Validation loss: 2.325789605417559

Epoch: 6| Step: 4
Training loss: 2.109358310699463
Validation loss: 2.316015928022323

Epoch: 6| Step: 5
Training loss: 2.311403274536133
Validation loss: 2.304044892711024

Epoch: 6| Step: 6
Training loss: 2.6433980464935303
Validation loss: 2.303205454221336

Epoch: 6| Step: 7
Training loss: 2.658226490020752
Validation loss: 2.3023871273122807

Epoch: 6| Step: 8
Training loss: 3.0130205154418945
Validation loss: 2.3006062584538616

Epoch: 6| Step: 9
Training loss: 2.7962775230407715
Validation loss: 2.3008920556755474

Epoch: 6| Step: 10
Training loss: 2.521286964416504
Validation loss: 2.298507575065859

Epoch: 6| Step: 11
Training loss: 2.3271758556365967
Validation loss: 2.296078062826587

Epoch: 6| Step: 12
Training loss: 2.010411024093628
Validation loss: 2.2956682200072915

Epoch: 6| Step: 13
Training loss: 2.842200994491577
Validation loss: 2.2951077286915114

Epoch: 62| Step: 0
Training loss: 2.0533742904663086
Validation loss: 2.2922756543723484

Epoch: 6| Step: 1
Training loss: 3.468876838684082
Validation loss: 2.289545330950009

Epoch: 6| Step: 2
Training loss: 2.630481004714966
Validation loss: 2.2941901965807845

Epoch: 6| Step: 3
Training loss: 2.64819598197937
Validation loss: 2.309487447943739

Epoch: 6| Step: 4
Training loss: 3.034359931945801
Validation loss: 2.3281886680151826

Epoch: 6| Step: 5
Training loss: 2.3220055103302
Validation loss: 2.3502940080499135

Epoch: 6| Step: 6
Training loss: 2.418078899383545
Validation loss: 2.3586518508131786

Epoch: 6| Step: 7
Training loss: 2.9074182510375977
Validation loss: 2.3780512732844197

Epoch: 6| Step: 8
Training loss: 2.6184914112091064
Validation loss: 2.3786420181233394

Epoch: 6| Step: 9
Training loss: 2.6747031211853027
Validation loss: 2.376172932245398

Epoch: 6| Step: 10
Training loss: 2.188727617263794
Validation loss: 2.3437906285767913

Epoch: 6| Step: 11
Training loss: 2.17337703704834
Validation loss: 2.3319286095198763

Epoch: 6| Step: 12
Training loss: 2.6345577239990234
Validation loss: 2.3278576815000145

Epoch: 6| Step: 13
Training loss: 2.502364158630371
Validation loss: 2.3135129149242113

Epoch: 63| Step: 0
Training loss: 2.7189416885375977
Validation loss: 2.2993314971206007

Epoch: 6| Step: 1
Training loss: 2.559694528579712
Validation loss: 2.2916028166329987

Epoch: 6| Step: 2
Training loss: 3.2957992553710938
Validation loss: 2.2865836902331282

Epoch: 6| Step: 3
Training loss: 2.4684767723083496
Validation loss: 2.286153552352741

Epoch: 6| Step: 4
Training loss: 2.574115514755249
Validation loss: 2.3047656807848202

Epoch: 6| Step: 5
Training loss: 2.310366630554199
Validation loss: 2.319023673252393

Epoch: 6| Step: 6
Training loss: 2.0870535373687744
Validation loss: 2.3197472351853565

Epoch: 6| Step: 7
Training loss: 2.5685930252075195
Validation loss: 2.3140945408933904

Epoch: 6| Step: 8
Training loss: 2.3758742809295654
Validation loss: 2.3006786787381737

Epoch: 6| Step: 9
Training loss: 2.760873794555664
Validation loss: 2.2865446664953746

Epoch: 6| Step: 10
Training loss: 2.6723694801330566
Validation loss: 2.2802687511649182

Epoch: 6| Step: 11
Training loss: 2.9602901935577393
Validation loss: 2.277248723532564

Epoch: 6| Step: 12
Training loss: 2.3605427742004395
Validation loss: 2.2751584796495337

Epoch: 6| Step: 13
Training loss: 2.355757236480713
Validation loss: 2.2737559990216325

Epoch: 64| Step: 0
Training loss: 2.502681255340576
Validation loss: 2.2783973524647374

Epoch: 6| Step: 1
Training loss: 2.6682538986206055
Validation loss: 2.2929581660096363

Epoch: 6| Step: 2
Training loss: 2.8749916553497314
Validation loss: 2.292243637064452

Epoch: 6| Step: 3
Training loss: 2.591036081314087
Validation loss: 2.3067236561929025

Epoch: 6| Step: 4
Training loss: 2.2746405601501465
Validation loss: 2.3250331058297107

Epoch: 6| Step: 5
Training loss: 2.5700016021728516
Validation loss: 2.338710202965685

Epoch: 6| Step: 6
Training loss: 2.46239972114563
Validation loss: 2.3335821346570085

Epoch: 6| Step: 7
Training loss: 2.01704740524292
Validation loss: 2.2998529967441352

Epoch: 6| Step: 8
Training loss: 2.6274070739746094
Validation loss: 2.2916581220524286

Epoch: 6| Step: 9
Training loss: 3.0166969299316406
Validation loss: 2.2780887196140904

Epoch: 6| Step: 10
Training loss: 2.2105917930603027
Validation loss: 2.279514697290236

Epoch: 6| Step: 11
Training loss: 2.2866742610931396
Validation loss: 2.2818911575501963

Epoch: 6| Step: 12
Training loss: 2.6854848861694336
Validation loss: 2.2830097316413798

Epoch: 6| Step: 13
Training loss: 3.603302478790283
Validation loss: 2.288532313480172

Epoch: 65| Step: 0
Training loss: 2.5280237197875977
Validation loss: 2.291089552705006

Epoch: 6| Step: 1
Training loss: 3.107870101928711
Validation loss: 2.2888976091979654

Epoch: 6| Step: 2
Training loss: 3.0552215576171875
Validation loss: 2.288142232484715

Epoch: 6| Step: 3
Training loss: 2.795577049255371
Validation loss: 2.2807652591377177

Epoch: 6| Step: 4
Training loss: 2.6209352016448975
Validation loss: 2.277198829958516

Epoch: 6| Step: 5
Training loss: 2.788494110107422
Validation loss: 2.2759835156061317

Epoch: 6| Step: 6
Training loss: 2.0179522037506104
Validation loss: 2.2655557201754664

Epoch: 6| Step: 7
Training loss: 2.3746328353881836
Validation loss: 2.268043683421227

Epoch: 6| Step: 8
Training loss: 2.170252561569214
Validation loss: 2.2648840591471684

Epoch: 6| Step: 9
Training loss: 2.5695109367370605
Validation loss: 2.276822013239707

Epoch: 6| Step: 10
Training loss: 2.4136128425598145
Validation loss: 2.285907881234282

Epoch: 6| Step: 11
Training loss: 3.0529541969299316
Validation loss: 2.3187289468703733

Epoch: 6| Step: 12
Training loss: 2.334961175918579
Validation loss: 2.3444062484207975

Epoch: 6| Step: 13
Training loss: 1.7455779314041138
Validation loss: 2.3616251919859197

Epoch: 66| Step: 0
Training loss: 2.494680881500244
Validation loss: 2.391331462449925

Epoch: 6| Step: 1
Training loss: 2.2974326610565186
Validation loss: 2.407249196883171

Epoch: 6| Step: 2
Training loss: 2.692816734313965
Validation loss: 2.4747791931193364

Epoch: 6| Step: 3
Training loss: 2.997422695159912
Validation loss: 2.4910797739541657

Epoch: 6| Step: 4
Training loss: 2.1801939010620117
Validation loss: 2.4772470228133665

Epoch: 6| Step: 5
Training loss: 2.5404515266418457
Validation loss: 2.399513070301343

Epoch: 6| Step: 6
Training loss: 2.457007646560669
Validation loss: 2.3379902993479083

Epoch: 6| Step: 7
Training loss: 2.859449625015259
Validation loss: 2.2795068499862507

Epoch: 6| Step: 8
Training loss: 2.8410449028015137
Validation loss: 2.2963843038005214

Epoch: 6| Step: 9
Training loss: 2.575349807739258
Validation loss: 2.334819680900984

Epoch: 6| Step: 10
Training loss: 3.1636133193969727
Validation loss: 2.380286665372951

Epoch: 6| Step: 11
Training loss: 2.719688653945923
Validation loss: 2.4092926107427126

Epoch: 6| Step: 12
Training loss: 2.2387335300445557
Validation loss: 2.453330127141809

Epoch: 6| Step: 13
Training loss: 2.5246405601501465
Validation loss: 2.472892310029717

Epoch: 67| Step: 0
Training loss: 2.69911527633667
Validation loss: 2.483102442115866

Epoch: 6| Step: 1
Training loss: 2.5129001140594482
Validation loss: 2.4455962193909513

Epoch: 6| Step: 2
Training loss: 2.768404722213745
Validation loss: 2.405123077413087

Epoch: 6| Step: 3
Training loss: 2.4823379516601562
Validation loss: 2.36206478200933

Epoch: 6| Step: 4
Training loss: 2.539118766784668
Validation loss: 2.2919180508582824

Epoch: 6| Step: 5
Training loss: 2.8338499069213867
Validation loss: 2.2594000575362996

Epoch: 6| Step: 6
Training loss: 3.0047767162323
Validation loss: 2.2731535255268054

Epoch: 6| Step: 7
Training loss: 2.1130800247192383
Validation loss: 2.2778603774245068

Epoch: 6| Step: 8
Training loss: 2.3262686729431152
Validation loss: 2.2969820294328915

Epoch: 6| Step: 9
Training loss: 2.4282195568084717
Validation loss: 2.3219653931997155

Epoch: 6| Step: 10
Training loss: 2.603652000427246
Validation loss: 2.351836665984123

Epoch: 6| Step: 11
Training loss: 2.5439696311950684
Validation loss: 2.356749424370386

Epoch: 6| Step: 12
Training loss: 3.2029385566711426
Validation loss: 2.346707369691582

Epoch: 6| Step: 13
Training loss: 2.344228744506836
Validation loss: 2.3162442766210085

Epoch: 68| Step: 0
Training loss: 3.183563709259033
Validation loss: 2.319583482639764

Epoch: 6| Step: 1
Training loss: 2.8669309616088867
Validation loss: 2.3002892835165865

Epoch: 6| Step: 2
Training loss: 2.5934271812438965
Validation loss: 2.3070780628470966

Epoch: 6| Step: 3
Training loss: 2.440868377685547
Validation loss: 2.3121114789798694

Epoch: 6| Step: 4
Training loss: 2.518692970275879
Validation loss: 2.3136102243136336

Epoch: 6| Step: 5
Training loss: 2.760467052459717
Validation loss: 2.3058564316841865

Epoch: 6| Step: 6
Training loss: 2.0578627586364746
Validation loss: 2.2931071199396604

Epoch: 6| Step: 7
Training loss: 2.3318064212799072
Validation loss: 2.30500901386302

Epoch: 6| Step: 8
Training loss: 2.5596604347229004
Validation loss: 2.2901895789689917

Epoch: 6| Step: 9
Training loss: 2.8638174533843994
Validation loss: 2.263412385858515

Epoch: 6| Step: 10
Training loss: 1.6248096227645874
Validation loss: 2.2570541597181752

Epoch: 6| Step: 11
Training loss: 3.1232011318206787
Validation loss: 2.2438564121082263

Epoch: 6| Step: 12
Training loss: 2.0168190002441406
Validation loss: 2.2310962805183987

Epoch: 6| Step: 13
Training loss: 2.807415008544922
Validation loss: 2.2305951785015803

Epoch: 69| Step: 0
Training loss: 2.983344078063965
Validation loss: 2.23541074158043

Epoch: 6| Step: 1
Training loss: 1.9944593906402588
Validation loss: 2.2344137930100962

Epoch: 6| Step: 2
Training loss: 2.97326922416687
Validation loss: 2.245013439527122

Epoch: 6| Step: 3
Training loss: 2.617314338684082
Validation loss: 2.248852324742143

Epoch: 6| Step: 4
Training loss: 2.302544116973877
Validation loss: 2.251556637466595

Epoch: 6| Step: 5
Training loss: 2.214468240737915
Validation loss: 2.2679262853437856

Epoch: 6| Step: 6
Training loss: 2.289618968963623
Validation loss: 2.3209246922564764

Epoch: 6| Step: 7
Training loss: 2.841071605682373
Validation loss: 2.3592418214326263

Epoch: 6| Step: 8
Training loss: 2.3891031742095947
Validation loss: 2.4164953462539183

Epoch: 6| Step: 9
Training loss: 2.647153854370117
Validation loss: 2.4318037109990276

Epoch: 6| Step: 10
Training loss: 2.877095937728882
Validation loss: 2.4446601329311246

Epoch: 6| Step: 11
Training loss: 2.733703851699829
Validation loss: 2.4427831198579524

Epoch: 6| Step: 12
Training loss: 3.132150888442993
Validation loss: 2.442764236081031

Epoch: 6| Step: 13
Training loss: 1.6097488403320312
Validation loss: 2.4015830896234

Epoch: 70| Step: 0
Training loss: 2.6522059440612793
Validation loss: 2.3852036230025755

Epoch: 6| Step: 1
Training loss: 2.66865873336792
Validation loss: 2.3564415875301568

Epoch: 6| Step: 2
Training loss: 2.4782590866088867
Validation loss: 2.3149047256797872

Epoch: 6| Step: 3
Training loss: 2.819457530975342
Validation loss: 2.2998032480157833

Epoch: 6| Step: 4
Training loss: 2.932103395462036
Validation loss: 2.28360814432944

Epoch: 6| Step: 5
Training loss: 2.400526523590088
Validation loss: 2.2667219972097747

Epoch: 6| Step: 6
Training loss: 3.3759636878967285
Validation loss: 2.260240288190944

Epoch: 6| Step: 7
Training loss: 2.384829044342041
Validation loss: 2.254512312591717

Epoch: 6| Step: 8
Training loss: 1.5651626586914062
Validation loss: 2.2479716988020044

Epoch: 6| Step: 9
Training loss: 2.076699733734131
Validation loss: 2.2505044808951755

Epoch: 6| Step: 10
Training loss: 3.4340009689331055
Validation loss: 2.2344981624234106

Epoch: 6| Step: 11
Training loss: 2.0455527305603027
Validation loss: 2.230312496103266

Epoch: 6| Step: 12
Training loss: 2.5668270587921143
Validation loss: 2.232896304899646

Epoch: 6| Step: 13
Training loss: 2.066681146621704
Validation loss: 2.22852591032623

Epoch: 71| Step: 0
Training loss: 2.8698856830596924
Validation loss: 2.2293562171279744

Epoch: 6| Step: 1
Training loss: 2.026845932006836
Validation loss: 2.226534597335323

Epoch: 6| Step: 2
Training loss: 2.7618050575256348
Validation loss: 2.22258117634763

Epoch: 6| Step: 3
Training loss: 2.4713897705078125
Validation loss: 2.233238381724204

Epoch: 6| Step: 4
Training loss: 3.0196235179901123
Validation loss: 2.245304952385605

Epoch: 6| Step: 5
Training loss: 2.6028823852539062
Validation loss: 2.252942431357599

Epoch: 6| Step: 6
Training loss: 2.593804359436035
Validation loss: 2.280017768183062

Epoch: 6| Step: 7
Training loss: 2.536851167678833
Validation loss: 2.287608814495866

Epoch: 6| Step: 8
Training loss: 2.3560473918914795
Validation loss: 2.2740392966936995

Epoch: 6| Step: 9
Training loss: 2.179466962814331
Validation loss: 2.249762254376565

Epoch: 6| Step: 10
Training loss: 2.315349578857422
Validation loss: 2.2452461732331144

Epoch: 6| Step: 11
Training loss: 2.2999391555786133
Validation loss: 2.2403132864224014

Epoch: 6| Step: 12
Training loss: 2.857980728149414
Validation loss: 2.2376629870424987

Epoch: 6| Step: 13
Training loss: 2.5778627395629883
Validation loss: 2.23900870866673

Epoch: 72| Step: 0
Training loss: 2.8174169063568115
Validation loss: 2.250484722916798

Epoch: 6| Step: 1
Training loss: 1.8881781101226807
Validation loss: 2.2417283468349005

Epoch: 6| Step: 2
Training loss: 2.0220682621002197
Validation loss: 2.257924300368114

Epoch: 6| Step: 3
Training loss: 2.228450298309326
Validation loss: 2.2879911597057054

Epoch: 6| Step: 4
Training loss: 2.1030712127685547
Validation loss: 2.300793640075191

Epoch: 6| Step: 5
Training loss: 2.804932117462158
Validation loss: 2.330943517787482

Epoch: 6| Step: 6
Training loss: 2.832095146179199
Validation loss: 2.340146553131842

Epoch: 6| Step: 7
Training loss: 2.954652786254883
Validation loss: 2.3623834066493536

Epoch: 6| Step: 8
Training loss: 2.7391345500946045
Validation loss: 2.388144335439128

Epoch: 6| Step: 9
Training loss: 2.11167573928833
Validation loss: 2.4120080573584444

Epoch: 6| Step: 10
Training loss: 2.7482683658599854
Validation loss: 2.4174429985784713

Epoch: 6| Step: 11
Training loss: 2.601658344268799
Validation loss: 2.424597388954573

Epoch: 6| Step: 12
Training loss: 3.3221607208251953
Validation loss: 2.3844324670812136

Epoch: 6| Step: 13
Training loss: 2.8597309589385986
Validation loss: 2.3768429243436424

Epoch: 73| Step: 0
Training loss: 3.2297112941741943
Validation loss: 2.3500192549920853

Epoch: 6| Step: 1
Training loss: 2.9359378814697266
Validation loss: 2.282406142962876

Epoch: 6| Step: 2
Training loss: 2.8756840229034424
Validation loss: 2.254788068033034

Epoch: 6| Step: 3
Training loss: 1.7949849367141724
Validation loss: 2.2279949829142582

Epoch: 6| Step: 4
Training loss: 2.103095054626465
Validation loss: 2.2339014801927792

Epoch: 6| Step: 5
Training loss: 2.003215789794922
Validation loss: 2.2353275411872455

Epoch: 6| Step: 6
Training loss: 2.3038344383239746
Validation loss: 2.2501323223114014

Epoch: 6| Step: 7
Training loss: 3.3311429023742676
Validation loss: 2.2617629240917903

Epoch: 6| Step: 8
Training loss: 2.1970200538635254
Validation loss: 2.264551362683696

Epoch: 6| Step: 9
Training loss: 2.437741279602051
Validation loss: 2.269190785705402

Epoch: 6| Step: 10
Training loss: 2.8081130981445312
Validation loss: 2.2610666649315947

Epoch: 6| Step: 11
Training loss: 3.32797908782959
Validation loss: 2.237973831033194

Epoch: 6| Step: 12
Training loss: 1.9687217473983765
Validation loss: 2.222945805518858

Epoch: 6| Step: 13
Training loss: 2.409609794616699
Validation loss: 2.2306029770963933

Epoch: 74| Step: 0
Training loss: 2.3705637454986572
Validation loss: 2.2391848820512013

Epoch: 6| Step: 1
Training loss: 2.244818687438965
Validation loss: 2.2874367493455128

Epoch: 6| Step: 2
Training loss: 2.075033187866211
Validation loss: 2.368381525880547

Epoch: 6| Step: 3
Training loss: 2.2554006576538086
Validation loss: 2.3988307086370324

Epoch: 6| Step: 4
Training loss: 2.653998374938965
Validation loss: 2.3950401480479906

Epoch: 6| Step: 5
Training loss: 3.0513408184051514
Validation loss: 2.313866365340448

Epoch: 6| Step: 6
Training loss: 2.9846181869506836
Validation loss: 2.245923206370364

Epoch: 6| Step: 7
Training loss: 3.0152482986450195
Validation loss: 2.206827120114398

Epoch: 6| Step: 8
Training loss: 2.693218231201172
Validation loss: 2.2106794234245055

Epoch: 6| Step: 9
Training loss: 2.776276111602783
Validation loss: 2.229759672636627

Epoch: 6| Step: 10
Training loss: 3.443114757537842
Validation loss: 2.2572429667236986

Epoch: 6| Step: 11
Training loss: 2.1132662296295166
Validation loss: 2.2767656439094135

Epoch: 6| Step: 12
Training loss: 1.8250820636749268
Validation loss: 2.2502417102936776

Epoch: 6| Step: 13
Training loss: 2.5113115310668945
Validation loss: 2.226734494650236

Epoch: 75| Step: 0
Training loss: 2.6617813110351562
Validation loss: 2.2142945694667038

Epoch: 6| Step: 1
Training loss: 2.790419101715088
Validation loss: 2.2014090348315496

Epoch: 6| Step: 2
Training loss: 1.9333863258361816
Validation loss: 2.189945096610695

Epoch: 6| Step: 3
Training loss: 2.2520487308502197
Validation loss: 2.1865946605641353

Epoch: 6| Step: 4
Training loss: 2.243997097015381
Validation loss: 2.182324163375362

Epoch: 6| Step: 5
Training loss: 3.006166696548462
Validation loss: 2.1840507573978876

Epoch: 6| Step: 6
Training loss: 2.4982237815856934
Validation loss: 2.191403527413645

Epoch: 6| Step: 7
Training loss: 2.346083164215088
Validation loss: 2.223070139526039

Epoch: 6| Step: 8
Training loss: 2.8564963340759277
Validation loss: 2.2758472260608467

Epoch: 6| Step: 9
Training loss: 2.5759072303771973
Validation loss: 2.335732675367786

Epoch: 6| Step: 10
Training loss: 2.5921549797058105
Validation loss: 2.4108855878153155

Epoch: 6| Step: 11
Training loss: 2.9173951148986816
Validation loss: 2.5406522879036526

Epoch: 6| Step: 12
Training loss: 2.556865930557251
Validation loss: 2.574004424515591

Epoch: 6| Step: 13
Training loss: 2.274986743927002
Validation loss: 2.5015773081010386

Epoch: 76| Step: 0
Training loss: 2.55462646484375
Validation loss: 2.42391526058156

Epoch: 6| Step: 1
Training loss: 2.274050712585449
Validation loss: 2.368512225407426

Epoch: 6| Step: 2
Training loss: 2.380199432373047
Validation loss: 2.3069832196799656

Epoch: 6| Step: 3
Training loss: 2.365558624267578
Validation loss: 2.286421049025751

Epoch: 6| Step: 4
Training loss: 2.5941731929779053
Validation loss: 2.2679685136323333

Epoch: 6| Step: 5
Training loss: 2.537632465362549
Validation loss: 2.2469795596215034

Epoch: 6| Step: 6
Training loss: 2.621065855026245
Validation loss: 2.2435453014989055

Epoch: 6| Step: 7
Training loss: 2.7105119228363037
Validation loss: 2.2349110675114456

Epoch: 6| Step: 8
Training loss: 1.947343349456787
Validation loss: 2.237184234844741

Epoch: 6| Step: 9
Training loss: 2.805140495300293
Validation loss: 2.22890309620929

Epoch: 6| Step: 10
Training loss: 2.7138381004333496
Validation loss: 2.2258654512384886

Epoch: 6| Step: 11
Training loss: 2.9301071166992188
Validation loss: 2.216954673490217

Epoch: 6| Step: 12
Training loss: 2.4695968627929688
Validation loss: 2.2070580656810472

Epoch: 6| Step: 13
Training loss: 2.3561270236968994
Validation loss: 2.2123998518913024

Epoch: 77| Step: 0
Training loss: 3.1457295417785645
Validation loss: 2.2322795647446827

Epoch: 6| Step: 1
Training loss: 2.418368101119995
Validation loss: 2.267132305329846

Epoch: 6| Step: 2
Training loss: 2.6677732467651367
Validation loss: 2.334353421324043

Epoch: 6| Step: 3
Training loss: 1.870919942855835
Validation loss: 2.377606794398318

Epoch: 6| Step: 4
Training loss: 1.8692327737808228
Validation loss: 2.3735950146951983

Epoch: 6| Step: 5
Training loss: 3.002953290939331
Validation loss: 2.39019605933979

Epoch: 6| Step: 6
Training loss: 3.2559988498687744
Validation loss: 2.3621562655254076

Epoch: 6| Step: 7
Training loss: 2.6732640266418457
Validation loss: 2.314920784324728

Epoch: 6| Step: 8
Training loss: 2.5193793773651123
Validation loss: 2.2468411768636396

Epoch: 6| Step: 9
Training loss: 2.7248375415802
Validation loss: 2.1925884651881393

Epoch: 6| Step: 10
Training loss: 2.0843098163604736
Validation loss: 2.1720931478725967

Epoch: 6| Step: 11
Training loss: 2.712876319885254
Validation loss: 2.1812654361929944

Epoch: 6| Step: 12
Training loss: 2.105555295944214
Validation loss: 2.199802621718376

Epoch: 6| Step: 13
Training loss: 2.80708909034729
Validation loss: 2.2287785058380454

Epoch: 78| Step: 0
Training loss: 2.528914213180542
Validation loss: 2.2536527443957586

Epoch: 6| Step: 1
Training loss: 1.6410317420959473
Validation loss: 2.279159712535079

Epoch: 6| Step: 2
Training loss: 2.5305237770080566
Validation loss: 2.3003871492160264

Epoch: 6| Step: 3
Training loss: 2.911982536315918
Validation loss: 2.376199055743474

Epoch: 6| Step: 4
Training loss: 2.4449174404144287
Validation loss: 2.407223601495066

Epoch: 6| Step: 5
Training loss: 2.148486614227295
Validation loss: 2.497926837654524

Epoch: 6| Step: 6
Training loss: 3.338639259338379
Validation loss: 2.644368023000738

Epoch: 6| Step: 7
Training loss: 2.566133975982666
Validation loss: 2.7131266824660765

Epoch: 6| Step: 8
Training loss: 3.0605227947235107
Validation loss: 2.6932605748535483

Epoch: 6| Step: 9
Training loss: 3.1684558391571045
Validation loss: 2.6295226594453216

Epoch: 6| Step: 10
Training loss: 3.2083587646484375
Validation loss: 2.624202653925906

Epoch: 6| Step: 11
Training loss: 2.568556308746338
Validation loss: 2.61121730906989

Epoch: 6| Step: 12
Training loss: 3.1158082485198975
Validation loss: 2.5929895190782446

Epoch: 6| Step: 13
Training loss: 2.1091928482055664
Validation loss: 2.5680840963958413

Epoch: 79| Step: 0
Training loss: 1.9599547386169434
Validation loss: 2.5590377597398657

Epoch: 6| Step: 1
Training loss: 2.5235257148742676
Validation loss: 2.5435818420943392

Epoch: 6| Step: 2
Training loss: 3.4020872116088867
Validation loss: 2.479440499377507

Epoch: 6| Step: 3
Training loss: 3.002272844314575
Validation loss: 2.4289500251893075

Epoch: 6| Step: 4
Training loss: 1.907705307006836
Validation loss: 2.358119405725951

Epoch: 6| Step: 5
Training loss: 2.272737979888916
Validation loss: 2.3032905081267

Epoch: 6| Step: 6
Training loss: 2.847026824951172
Validation loss: 2.279971138123543

Epoch: 6| Step: 7
Training loss: 2.7910103797912598
Validation loss: 2.262409858806159

Epoch: 6| Step: 8
Training loss: 2.41300106048584
Validation loss: 2.2256922926954044

Epoch: 6| Step: 9
Training loss: 2.9901833534240723
Validation loss: 2.223290986912225

Epoch: 6| Step: 10
Training loss: 2.833983898162842
Validation loss: 2.220010285736412

Epoch: 6| Step: 11
Training loss: 2.293219566345215
Validation loss: 2.2250428071586033

Epoch: 6| Step: 12
Training loss: 2.2194712162017822
Validation loss: 2.2391442842380975

Epoch: 6| Step: 13
Training loss: 2.4690158367156982
Validation loss: 2.265244963348553

Epoch: 80| Step: 0
Training loss: 1.4932260513305664
Validation loss: 2.28042632790022

Epoch: 6| Step: 1
Training loss: 2.7083306312561035
Validation loss: 2.2928194563875914

Epoch: 6| Step: 2
Training loss: 2.109785556793213
Validation loss: 2.273768481387887

Epoch: 6| Step: 3
Training loss: 3.115771770477295
Validation loss: 2.2644978492490706

Epoch: 6| Step: 4
Training loss: 2.405423164367676
Validation loss: 2.2554824429173626

Epoch: 6| Step: 5
Training loss: 2.5182485580444336
Validation loss: 2.217987829639066

Epoch: 6| Step: 6
Training loss: 2.7650818824768066
Validation loss: 2.1881220725274857

Epoch: 6| Step: 7
Training loss: 2.5789175033569336
Validation loss: 2.1661509288254606

Epoch: 6| Step: 8
Training loss: 2.2533135414123535
Validation loss: 2.166964082307713

Epoch: 6| Step: 9
Training loss: 2.332521438598633
Validation loss: 2.1770971821200464

Epoch: 6| Step: 10
Training loss: 3.093646764755249
Validation loss: 2.213449780659009

Epoch: 6| Step: 11
Training loss: 3.337658405303955
Validation loss: 2.2351540942345896

Epoch: 6| Step: 12
Training loss: 2.398998737335205
Validation loss: 2.2352804317269275

Epoch: 6| Step: 13
Training loss: 2.5224905014038086
Validation loss: 2.2397047858084402

Epoch: 81| Step: 0
Training loss: 2.504300117492676
Validation loss: 2.258612076441447

Epoch: 6| Step: 1
Training loss: 2.367032289505005
Validation loss: 2.278550007010019

Epoch: 6| Step: 2
Training loss: 2.3656063079833984
Validation loss: 2.303752835078906

Epoch: 6| Step: 3
Training loss: 2.232287883758545
Validation loss: 2.303078423264206

Epoch: 6| Step: 4
Training loss: 2.8594608306884766
Validation loss: 2.3162422039175548

Epoch: 6| Step: 5
Training loss: 2.078359842300415
Validation loss: 2.317210469194638

Epoch: 6| Step: 6
Training loss: 2.725238084793091
Validation loss: 2.3089466992244927

Epoch: 6| Step: 7
Training loss: 2.636723756790161
Validation loss: 2.2947715764404624

Epoch: 6| Step: 8
Training loss: 1.8832952976226807
Validation loss: 2.2826594921850387

Epoch: 6| Step: 9
Training loss: 2.504469394683838
Validation loss: 2.2691172656192573

Epoch: 6| Step: 10
Training loss: 3.4056663513183594
Validation loss: 2.275256203066918

Epoch: 6| Step: 11
Training loss: 3.0185487270355225
Validation loss: 2.2204001821497434

Epoch: 6| Step: 12
Training loss: 2.2844743728637695
Validation loss: 2.168884613180673

Epoch: 6| Step: 13
Training loss: 1.827331304550171
Validation loss: 2.138732156445903

Epoch: 82| Step: 0
Training loss: 3.022580862045288
Validation loss: 2.133999655323644

Epoch: 6| Step: 1
Training loss: 2.219733715057373
Validation loss: 2.1438331475821872

Epoch: 6| Step: 2
Training loss: 2.310250759124756
Validation loss: 2.1494044027020855

Epoch: 6| Step: 3
Training loss: 2.8234105110168457
Validation loss: 2.158315896987915

Epoch: 6| Step: 4
Training loss: 2.525775909423828
Validation loss: 2.1658323605855307

Epoch: 6| Step: 5
Training loss: 2.3184895515441895
Validation loss: 2.1625107975416284

Epoch: 6| Step: 6
Training loss: 2.066713571548462
Validation loss: 2.153517602592386

Epoch: 6| Step: 7
Training loss: 3.003019332885742
Validation loss: 2.1477278432538434

Epoch: 6| Step: 8
Training loss: 1.9512401819229126
Validation loss: 2.1459958425132175

Epoch: 6| Step: 9
Training loss: 2.7622220516204834
Validation loss: 2.1342541415204286

Epoch: 6| Step: 10
Training loss: 2.2595479488372803
Validation loss: 2.1255156660592682

Epoch: 6| Step: 11
Training loss: 2.6552278995513916
Validation loss: 2.141700324191842

Epoch: 6| Step: 12
Training loss: 2.557271957397461
Validation loss: 2.161840574715727

Epoch: 6| Step: 13
Training loss: 2.670193910598755
Validation loss: 2.2022157792122132

Epoch: 83| Step: 0
Training loss: 2.9777114391326904
Validation loss: 2.263434179367558

Epoch: 6| Step: 1
Training loss: 2.4265811443328857
Validation loss: 2.280632863762558

Epoch: 6| Step: 2
Training loss: 2.5320887565612793
Validation loss: 2.244877717828238

Epoch: 6| Step: 3
Training loss: 2.495664596557617
Validation loss: 2.2015626366420458

Epoch: 6| Step: 4
Training loss: 1.590285062789917
Validation loss: 2.14408480223789

Epoch: 6| Step: 5
Training loss: 2.1730313301086426
Validation loss: 2.1259115678007885

Epoch: 6| Step: 6
Training loss: 2.796876907348633
Validation loss: 2.1267594163135817

Epoch: 6| Step: 7
Training loss: 2.6214818954467773
Validation loss: 2.131380204231508

Epoch: 6| Step: 8
Training loss: 1.92954421043396
Validation loss: 2.145824529791391

Epoch: 6| Step: 9
Training loss: 2.553096294403076
Validation loss: 2.147381051894157

Epoch: 6| Step: 10
Training loss: 2.434976577758789
Validation loss: 2.145020205487487

Epoch: 6| Step: 11
Training loss: 2.523672342300415
Validation loss: 2.1515928776033464

Epoch: 6| Step: 12
Training loss: 3.087716579437256
Validation loss: 2.148626647969728

Epoch: 6| Step: 13
Training loss: 3.0190467834472656
Validation loss: 2.1461093477023545

Epoch: 84| Step: 0
Training loss: 3.5601518154144287
Validation loss: 2.1501051225969867

Epoch: 6| Step: 1
Training loss: 2.2003090381622314
Validation loss: 2.1414968044527116

Epoch: 6| Step: 2
Training loss: 2.2656335830688477
Validation loss: 2.1419786714738414

Epoch: 6| Step: 3
Training loss: 1.9602408409118652
Validation loss: 2.133070684248401

Epoch: 6| Step: 4
Training loss: 2.469517230987549
Validation loss: 2.1344185618944067

Epoch: 6| Step: 5
Training loss: 2.4185872077941895
Validation loss: 2.1347216111357494

Epoch: 6| Step: 6
Training loss: 1.9781662225723267
Validation loss: 2.1315492007040207

Epoch: 6| Step: 7
Training loss: 2.3978331089019775
Validation loss: 2.1345294726792203

Epoch: 6| Step: 8
Training loss: 2.6067867279052734
Validation loss: 2.1508051451816352

Epoch: 6| Step: 9
Training loss: 2.1975605487823486
Validation loss: 2.1730265540461384

Epoch: 6| Step: 10
Training loss: 2.4597976207733154
Validation loss: 2.1999272428533083

Epoch: 6| Step: 11
Training loss: 3.1006643772125244
Validation loss: 2.2420424133218746

Epoch: 6| Step: 12
Training loss: 2.3655972480773926
Validation loss: 2.2579608425017326

Epoch: 6| Step: 13
Training loss: 3.0421440601348877
Validation loss: 2.2709096529150523

Epoch: 85| Step: 0
Training loss: 3.558217763900757
Validation loss: 2.2670198012423772

Epoch: 6| Step: 1
Training loss: 2.230685234069824
Validation loss: 2.2593104454778854

Epoch: 6| Step: 2
Training loss: 1.6307203769683838
Validation loss: 2.241213995923278

Epoch: 6| Step: 3
Training loss: 2.2458481788635254
Validation loss: 2.1982585512181765

Epoch: 6| Step: 4
Training loss: 2.775200843811035
Validation loss: 2.1610602973609843

Epoch: 6| Step: 5
Training loss: 2.6777167320251465
Validation loss: 2.1415854320731214

Epoch: 6| Step: 6
Training loss: 2.445927619934082
Validation loss: 2.1313737130934194

Epoch: 6| Step: 7
Training loss: 2.55226469039917
Validation loss: 2.129634726432062

Epoch: 6| Step: 8
Training loss: 1.8335826396942139
Validation loss: 2.123169652877315

Epoch: 6| Step: 9
Training loss: 2.8701672554016113
Validation loss: 2.1264373128132155

Epoch: 6| Step: 10
Training loss: 3.0996437072753906
Validation loss: 2.1309633306277695

Epoch: 6| Step: 11
Training loss: 2.717118740081787
Validation loss: 2.1289982616260485

Epoch: 6| Step: 12
Training loss: 1.4601771831512451
Validation loss: 2.1346729724637923

Epoch: 6| Step: 13
Training loss: 2.947857618331909
Validation loss: 2.1370385872420443

Epoch: 86| Step: 0
Training loss: 1.8097184896469116
Validation loss: 2.144920072247905

Epoch: 6| Step: 1
Training loss: 2.2460901737213135
Validation loss: 2.148395974148986

Epoch: 6| Step: 2
Training loss: 2.3971729278564453
Validation loss: 2.136870002233854

Epoch: 6| Step: 3
Training loss: 2.555309534072876
Validation loss: 2.131501805397772

Epoch: 6| Step: 4
Training loss: 3.054884672164917
Validation loss: 2.1324160175938762

Epoch: 6| Step: 5
Training loss: 2.6498146057128906
Validation loss: 2.129929401541269

Epoch: 6| Step: 6
Training loss: 2.3336634635925293
Validation loss: 2.1271768641728226

Epoch: 6| Step: 7
Training loss: 2.5832362174987793
Validation loss: 2.1197190720547914

Epoch: 6| Step: 8
Training loss: 2.2539234161376953
Validation loss: 2.126180894913212

Epoch: 6| Step: 9
Training loss: 2.5568363666534424
Validation loss: 2.1227352465352705

Epoch: 6| Step: 10
Training loss: 2.3469080924987793
Validation loss: 2.1225885703999507

Epoch: 6| Step: 11
Training loss: 2.3313355445861816
Validation loss: 2.1291537361760295

Epoch: 6| Step: 12
Training loss: 2.7175495624542236
Validation loss: 2.125035749968662

Epoch: 6| Step: 13
Training loss: 3.0884056091308594
Validation loss: 2.1261734449735252

Epoch: 87| Step: 0
Training loss: 3.1214609146118164
Validation loss: 2.1244483596535138

Epoch: 6| Step: 1
Training loss: 2.5378923416137695
Validation loss: 2.125841616302408

Epoch: 6| Step: 2
Training loss: 2.4655375480651855
Validation loss: 2.119785608783845

Epoch: 6| Step: 3
Training loss: 2.2056925296783447
Validation loss: 2.122490582927581

Epoch: 6| Step: 4
Training loss: 3.033496379852295
Validation loss: 2.120006686897688

Epoch: 6| Step: 5
Training loss: 2.054292678833008
Validation loss: 2.114235178116829

Epoch: 6| Step: 6
Training loss: 1.9777151346206665
Validation loss: 2.1112456501171155

Epoch: 6| Step: 7
Training loss: 2.9997408390045166
Validation loss: 2.123792914934056

Epoch: 6| Step: 8
Training loss: 2.289173126220703
Validation loss: 2.134980547812677

Epoch: 6| Step: 9
Training loss: 1.9857916831970215
Validation loss: 2.161427370963558

Epoch: 6| Step: 10
Training loss: 2.6156976222991943
Validation loss: 2.186476504930886

Epoch: 6| Step: 11
Training loss: 2.77689528465271
Validation loss: 2.2154736339405017

Epoch: 6| Step: 12
Training loss: 2.0839271545410156
Validation loss: 2.222920366512832

Epoch: 6| Step: 13
Training loss: 1.9079229831695557
Validation loss: 2.248784798447804

Epoch: 88| Step: 0
Training loss: 2.7202086448669434
Validation loss: 2.2768096872555312

Epoch: 6| Step: 1
Training loss: 2.559330463409424
Validation loss: 2.2259496411969586

Epoch: 6| Step: 2
Training loss: 2.406367063522339
Validation loss: 2.1659124769190305

Epoch: 6| Step: 3
Training loss: 2.622070789337158
Validation loss: 2.1541217719354937

Epoch: 6| Step: 4
Training loss: 2.4979774951934814
Validation loss: 2.144460138454232

Epoch: 6| Step: 5
Training loss: 2.552701711654663
Validation loss: 2.1401666812999274

Epoch: 6| Step: 6
Training loss: 2.19773530960083
Validation loss: 2.1501247600842546

Epoch: 6| Step: 7
Training loss: 2.704904556274414
Validation loss: 2.173454446177329

Epoch: 6| Step: 8
Training loss: 1.4117181301116943
Validation loss: 2.197000229230491

Epoch: 6| Step: 9
Training loss: 2.1455936431884766
Validation loss: 2.1808520029949885

Epoch: 6| Step: 10
Training loss: 2.640961170196533
Validation loss: 2.188591395654986

Epoch: 6| Step: 11
Training loss: 2.3116588592529297
Validation loss: 2.182156073149814

Epoch: 6| Step: 12
Training loss: 2.816318988800049
Validation loss: 2.18206516901652

Epoch: 6| Step: 13
Training loss: 3.56699800491333
Validation loss: 2.156819147448386

Epoch: 89| Step: 0
Training loss: 2.003563642501831
Validation loss: 2.1500139262086604

Epoch: 6| Step: 1
Training loss: 2.4653563499450684
Validation loss: 2.1349008314071165

Epoch: 6| Step: 2
Training loss: 2.2345473766326904
Validation loss: 2.1288295766358734

Epoch: 6| Step: 3
Training loss: 3.345445156097412
Validation loss: 2.1434267618322886

Epoch: 6| Step: 4
Training loss: 1.363335132598877
Validation loss: 2.1589936671718473

Epoch: 6| Step: 5
Training loss: 2.5697994232177734
Validation loss: 2.1757431953184065

Epoch: 6| Step: 6
Training loss: 3.233356475830078
Validation loss: 2.195919144538141

Epoch: 6| Step: 7
Training loss: 2.7870452404022217
Validation loss: 2.205269564864456

Epoch: 6| Step: 8
Training loss: 1.8661361932754517
Validation loss: 2.177017419568954

Epoch: 6| Step: 9
Training loss: 2.261361837387085
Validation loss: 2.155363179022266

Epoch: 6| Step: 10
Training loss: 2.1968979835510254
Validation loss: 2.138120779427149

Epoch: 6| Step: 11
Training loss: 2.609485626220703
Validation loss: 2.124016290069908

Epoch: 6| Step: 12
Training loss: 2.6350841522216797
Validation loss: 2.115332011253603

Epoch: 6| Step: 13
Training loss: 3.163313627243042
Validation loss: 2.1029865177728797

Epoch: 90| Step: 0
Training loss: 2.5118675231933594
Validation loss: 2.108418882534068

Epoch: 6| Step: 1
Training loss: 1.778303861618042
Validation loss: 2.0980792250684512

Epoch: 6| Step: 2
Training loss: 2.286503314971924
Validation loss: 2.0979273524335635

Epoch: 6| Step: 3
Training loss: 3.290361166000366
Validation loss: 2.1005796745259273

Epoch: 6| Step: 4
Training loss: 2.490797519683838
Validation loss: 2.0987652194115425

Epoch: 6| Step: 5
Training loss: 2.441723108291626
Validation loss: 2.1234910616310696

Epoch: 6| Step: 6
Training loss: 3.2526936531066895
Validation loss: 2.17467523518429

Epoch: 6| Step: 7
Training loss: 1.937708854675293
Validation loss: 2.1954152814803587

Epoch: 6| Step: 8
Training loss: 2.6492247581481934
Validation loss: 2.236695904885569

Epoch: 6| Step: 9
Training loss: 2.4812231063842773
Validation loss: 2.266653537750244

Epoch: 6| Step: 10
Training loss: 2.1121320724487305
Validation loss: 2.294527861379808

Epoch: 6| Step: 11
Training loss: 2.673903465270996
Validation loss: 2.2722546182652956

Epoch: 6| Step: 12
Training loss: 2.0626721382141113
Validation loss: 2.2591122350385113

Epoch: 6| Step: 13
Training loss: 2.7723851203918457
Validation loss: 2.230958543797975

Epoch: 91| Step: 0
Training loss: 1.8925235271453857
Validation loss: 2.1909539315008346

Epoch: 6| Step: 1
Training loss: 2.491633176803589
Validation loss: 2.1752308543010423

Epoch: 6| Step: 2
Training loss: 2.7265710830688477
Validation loss: 2.1722266033131588

Epoch: 6| Step: 3
Training loss: 1.8525171279907227
Validation loss: 2.1710829568165604

Epoch: 6| Step: 4
Training loss: 2.385279893875122
Validation loss: 2.157033719042296

Epoch: 6| Step: 5
Training loss: 2.6211156845092773
Validation loss: 2.1449504731803812

Epoch: 6| Step: 6
Training loss: 3.2248575687408447
Validation loss: 2.1475194397793023

Epoch: 6| Step: 7
Training loss: 1.9933931827545166
Validation loss: 2.156457649764194

Epoch: 6| Step: 8
Training loss: 2.724698066711426
Validation loss: 2.1507564898460143

Epoch: 6| Step: 9
Training loss: 1.898718237876892
Validation loss: 2.1408825561564457

Epoch: 6| Step: 10
Training loss: 2.451411724090576
Validation loss: 2.1287800701715613

Epoch: 6| Step: 11
Training loss: 2.491180896759033
Validation loss: 2.124030306775083

Epoch: 6| Step: 12
Training loss: 2.975348949432373
Validation loss: 2.125841586820541

Epoch: 6| Step: 13
Training loss: 2.326307773590088
Validation loss: 2.141431382907334

Epoch: 92| Step: 0
Training loss: 2.1999480724334717
Validation loss: 2.1420609335745535

Epoch: 6| Step: 1
Training loss: 2.21596097946167
Validation loss: 2.167492587079284

Epoch: 6| Step: 2
Training loss: 2.624833822250366
Validation loss: 2.1728639243751444

Epoch: 6| Step: 3
Training loss: 2.609865665435791
Validation loss: 2.1782105635571223

Epoch: 6| Step: 4
Training loss: 2.8383872509002686
Validation loss: 2.200451725272722

Epoch: 6| Step: 5
Training loss: 1.8948146104812622
Validation loss: 2.198962624355029

Epoch: 6| Step: 6
Training loss: 2.2198374271392822
Validation loss: 2.197666306649485

Epoch: 6| Step: 7
Training loss: 2.1003270149230957
Validation loss: 2.199302460557671

Epoch: 6| Step: 8
Training loss: 2.5951952934265137
Validation loss: 2.1766020072403776

Epoch: 6| Step: 9
Training loss: 2.855712890625
Validation loss: 2.155795595979178

Epoch: 6| Step: 10
Training loss: 2.3123602867126465
Validation loss: 2.1357766325755785

Epoch: 6| Step: 11
Training loss: 2.8951783180236816
Validation loss: 2.130956397261671

Epoch: 6| Step: 12
Training loss: 2.2435569763183594
Validation loss: 2.110150903783819

Epoch: 6| Step: 13
Training loss: 2.840717077255249
Validation loss: 2.10692173434842

Epoch: 93| Step: 0
Training loss: 2.9081320762634277
Validation loss: 2.099692206228933

Epoch: 6| Step: 1
Training loss: 1.6241669654846191
Validation loss: 2.112999273884681

Epoch: 6| Step: 2
Training loss: 1.913048505783081
Validation loss: 2.1314778174123457

Epoch: 6| Step: 3
Training loss: 3.1097540855407715
Validation loss: 2.1738384333989953

Epoch: 6| Step: 4
Training loss: 2.7973334789276123
Validation loss: 2.1860009944567116

Epoch: 6| Step: 5
Training loss: 2.0296106338500977
Validation loss: 2.155259109312488

Epoch: 6| Step: 6
Training loss: 2.462320327758789
Validation loss: 2.1150756728264595

Epoch: 6| Step: 7
Training loss: 3.0976219177246094
Validation loss: 2.1026850028704573

Epoch: 6| Step: 8
Training loss: 2.313309907913208
Validation loss: 2.0833569367726645

Epoch: 6| Step: 9
Training loss: 2.9329702854156494
Validation loss: 2.078729127043037

Epoch: 6| Step: 10
Training loss: 2.559730052947998
Validation loss: 2.0828317762703024

Epoch: 6| Step: 11
Training loss: 2.4396307468414307
Validation loss: 2.0868811863724903

Epoch: 6| Step: 12
Training loss: 2.022752046585083
Validation loss: 2.0918501384796633

Epoch: 6| Step: 13
Training loss: 2.3327131271362305
Validation loss: 2.0993423897732972

Epoch: 94| Step: 0
Training loss: 2.4990038871765137
Validation loss: 2.1173856950575307

Epoch: 6| Step: 1
Training loss: 1.8549540042877197
Validation loss: 2.1132397497853925

Epoch: 6| Step: 2
Training loss: 2.388357162475586
Validation loss: 2.1145845895172446

Epoch: 6| Step: 3
Training loss: 2.5576186180114746
Validation loss: 2.1375869576649

Epoch: 6| Step: 4
Training loss: 2.1769866943359375
Validation loss: 2.134099006652832

Epoch: 6| Step: 5
Training loss: 3.120469570159912
Validation loss: 2.1557305833344818

Epoch: 6| Step: 6
Training loss: 2.641845226287842
Validation loss: 2.1620887582020094

Epoch: 6| Step: 7
Training loss: 2.3618133068084717
Validation loss: 2.1459630702131536

Epoch: 6| Step: 8
Training loss: 2.2489399909973145
Validation loss: 2.150184295510733

Epoch: 6| Step: 9
Training loss: 2.0110976696014404
Validation loss: 2.1603368482282086

Epoch: 6| Step: 10
Training loss: 2.6693973541259766
Validation loss: 2.193540588501961

Epoch: 6| Step: 11
Training loss: 2.9629616737365723
Validation loss: 2.2128004822679745

Epoch: 6| Step: 12
Training loss: 1.9091482162475586
Validation loss: 2.225277236712876

Epoch: 6| Step: 13
Training loss: 3.1064891815185547
Validation loss: 2.263597580694383

Epoch: 95| Step: 0
Training loss: 2.938765048980713
Validation loss: 2.2796964132657616

Epoch: 6| Step: 1
Training loss: 3.274785041809082
Validation loss: 2.313930506347328

Epoch: 6| Step: 2
Training loss: 2.3644142150878906
Validation loss: 2.3140941742927796

Epoch: 6| Step: 3
Training loss: 3.1065754890441895
Validation loss: 2.27029675053012

Epoch: 6| Step: 4
Training loss: 1.8350553512573242
Validation loss: 2.2418419494423816

Epoch: 6| Step: 5
Training loss: 3.014040946960449
Validation loss: 2.2113305676367974

Epoch: 6| Step: 6
Training loss: 2.2618627548217773
Validation loss: 2.1808526336505847

Epoch: 6| Step: 7
Training loss: 2.332704782485962
Validation loss: 2.151827645558183

Epoch: 6| Step: 8
Training loss: 2.0746402740478516
Validation loss: 2.138006994801183

Epoch: 6| Step: 9
Training loss: 1.6350109577178955
Validation loss: 2.1147736272504254

Epoch: 6| Step: 10
Training loss: 1.9271552562713623
Validation loss: 2.1177427845616497

Epoch: 6| Step: 11
Training loss: 2.6201837062835693
Validation loss: 2.101850745498493

Epoch: 6| Step: 12
Training loss: 2.5327510833740234
Validation loss: 2.096938881822812

Epoch: 6| Step: 13
Training loss: 2.6130588054656982
Validation loss: 2.097749302464147

Epoch: 96| Step: 0
Training loss: 2.4068267345428467
Validation loss: 2.0965070519396054

Epoch: 6| Step: 1
Training loss: 2.152135133743286
Validation loss: 2.1093603513574086

Epoch: 6| Step: 2
Training loss: 2.3418211936950684
Validation loss: 2.1222785108832904

Epoch: 6| Step: 3
Training loss: 2.6113545894622803
Validation loss: 2.11783480387862

Epoch: 6| Step: 4
Training loss: 2.352156639099121
Validation loss: 2.10870962501854

Epoch: 6| Step: 5
Training loss: 2.2768144607543945
Validation loss: 2.0933041867389472

Epoch: 6| Step: 6
Training loss: 2.4743001461029053
Validation loss: 2.074286186566917

Epoch: 6| Step: 7
Training loss: 1.9667942523956299
Validation loss: 2.0766109176861343

Epoch: 6| Step: 8
Training loss: 2.8614182472229004
Validation loss: 2.072408337746897

Epoch: 6| Step: 9
Training loss: 2.016937732696533
Validation loss: 2.0836964653384302

Epoch: 6| Step: 10
Training loss: 2.509437322616577
Validation loss: 2.0957730572710753

Epoch: 6| Step: 11
Training loss: 2.2248873710632324
Validation loss: 2.0994120797803326

Epoch: 6| Step: 12
Training loss: 3.0338094234466553
Validation loss: 2.126125463875391

Epoch: 6| Step: 13
Training loss: 2.963108539581299
Validation loss: 2.1246084628566617

Epoch: 97| Step: 0
Training loss: 2.5175533294677734
Validation loss: 2.1158888442541963

Epoch: 6| Step: 1
Training loss: 2.802363872528076
Validation loss: 2.1107861688060146

Epoch: 6| Step: 2
Training loss: 2.5990922451019287
Validation loss: 2.1017001880112516

Epoch: 6| Step: 3
Training loss: 3.203270435333252
Validation loss: 2.101643490534957

Epoch: 6| Step: 4
Training loss: 2.4689886569976807
Validation loss: 2.114658642840642

Epoch: 6| Step: 5
Training loss: 2.54691743850708
Validation loss: 2.1367442710425264

Epoch: 6| Step: 6
Training loss: 2.2915472984313965
Validation loss: 2.141808554690371

Epoch: 6| Step: 7
Training loss: 2.7390284538269043
Validation loss: 2.135510686905153

Epoch: 6| Step: 8
Training loss: 2.7012343406677246
Validation loss: 2.1438573073315363

Epoch: 6| Step: 9
Training loss: 2.2170114517211914
Validation loss: 2.1556068287100842

Epoch: 6| Step: 10
Training loss: 2.2702524662017822
Validation loss: 2.149648509999757

Epoch: 6| Step: 11
Training loss: 1.4469630718231201
Validation loss: 2.136548255079536

Epoch: 6| Step: 12
Training loss: 2.1320528984069824
Validation loss: 2.134303594148287

Epoch: 6| Step: 13
Training loss: 1.6239798069000244
Validation loss: 2.1376870268134662

Epoch: 98| Step: 0
Training loss: 1.7130353450775146
Validation loss: 2.1324119772962344

Epoch: 6| Step: 1
Training loss: 2.589005947113037
Validation loss: 2.131785677325341

Epoch: 6| Step: 2
Training loss: 1.9748469591140747
Validation loss: 2.117063560793477

Epoch: 6| Step: 3
Training loss: 1.3630008697509766
Validation loss: 2.1115204031749437

Epoch: 6| Step: 4
Training loss: 3.0706722736358643
Validation loss: 2.1097676574542956

Epoch: 6| Step: 5
Training loss: 2.3263020515441895
Validation loss: 2.1062246676414245

Epoch: 6| Step: 6
Training loss: 2.323956251144409
Validation loss: 2.1230182980978363

Epoch: 6| Step: 7
Training loss: 3.0848798751831055
Validation loss: 2.1100796345741517

Epoch: 6| Step: 8
Training loss: 2.2349324226379395
Validation loss: 2.1333572146713093

Epoch: 6| Step: 9
Training loss: 2.7499475479125977
Validation loss: 2.1526710064180437

Epoch: 6| Step: 10
Training loss: 2.379789113998413
Validation loss: 2.194014726146575

Epoch: 6| Step: 11
Training loss: 2.854973793029785
Validation loss: 2.184285820171397

Epoch: 6| Step: 12
Training loss: 2.3090808391571045
Validation loss: 2.195208385426511

Epoch: 6| Step: 13
Training loss: 2.42431640625
Validation loss: 2.1477157633791686

Epoch: 99| Step: 0
Training loss: 2.1936423778533936
Validation loss: 2.1088629717467935

Epoch: 6| Step: 1
Training loss: 2.42378306388855
Validation loss: 2.0969644695199947

Epoch: 6| Step: 2
Training loss: 3.0637195110321045
Validation loss: 2.0699662752048944

Epoch: 6| Step: 3
Training loss: 2.698376178741455
Validation loss: 2.0634204059518795

Epoch: 6| Step: 4
Training loss: 1.7501941919326782
Validation loss: 2.0484621499174382

Epoch: 6| Step: 5
Training loss: 2.7059004306793213
Validation loss: 2.047910242952326

Epoch: 6| Step: 6
Training loss: 2.697502613067627
Validation loss: 2.0484886092524373

Epoch: 6| Step: 7
Training loss: 2.2178330421447754
Validation loss: 2.0393622190721574

Epoch: 6| Step: 8
Training loss: 2.1207542419433594
Validation loss: 2.047348767198542

Epoch: 6| Step: 9
Training loss: 2.5717811584472656
Validation loss: 2.0477330184751943

Epoch: 6| Step: 10
Training loss: 1.6601617336273193
Validation loss: 2.060626818287757

Epoch: 6| Step: 11
Training loss: 2.477576732635498
Validation loss: 2.069548145417244

Epoch: 6| Step: 12
Training loss: 2.3194260597229004
Validation loss: 2.0910353288855603

Epoch: 6| Step: 13
Training loss: 2.8090410232543945
Validation loss: 2.1026873562925603

Epoch: 100| Step: 0
Training loss: 2.436929225921631
Validation loss: 2.128700681912002

Epoch: 6| Step: 1
Training loss: 2.207765579223633
Validation loss: 2.1493483140904415

Epoch: 6| Step: 2
Training loss: 2.6313393115997314
Validation loss: 2.157763497803801

Epoch: 6| Step: 3
Training loss: 2.6214170455932617
Validation loss: 2.1496386592106154

Epoch: 6| Step: 4
Training loss: 2.1602349281311035
Validation loss: 2.1232144268610145

Epoch: 6| Step: 5
Training loss: 2.4399290084838867
Validation loss: 2.1141142678517166

Epoch: 6| Step: 6
Training loss: 2.463514804840088
Validation loss: 2.073015779577276

Epoch: 6| Step: 7
Training loss: 2.2380666732788086
Validation loss: 2.0604032777970835

Epoch: 6| Step: 8
Training loss: 1.4822115898132324
Validation loss: 2.046208502143942

Epoch: 6| Step: 9
Training loss: 2.5317912101745605
Validation loss: 2.0503917970964984

Epoch: 6| Step: 10
Training loss: 2.1940507888793945
Validation loss: 2.0483597658013784

Epoch: 6| Step: 11
Training loss: 2.870081901550293
Validation loss: 2.064695099348663

Epoch: 6| Step: 12
Training loss: 2.314828634262085
Validation loss: 2.080063014902094

Epoch: 6| Step: 13
Training loss: 3.1129708290100098
Validation loss: 2.1174595099623486

Epoch: 101| Step: 0
Training loss: 2.7146778106689453
Validation loss: 2.1219473884951685

Epoch: 6| Step: 1
Training loss: 2.5189530849456787
Validation loss: 2.137113096893475

Epoch: 6| Step: 2
Training loss: 2.595834732055664
Validation loss: 2.1602801302427888

Epoch: 6| Step: 3
Training loss: 2.1867332458496094
Validation loss: 2.1742098715997513

Epoch: 6| Step: 4
Training loss: 2.9052681922912598
Validation loss: 2.178981875860563

Epoch: 6| Step: 5
Training loss: 2.5157389640808105
Validation loss: 2.177222969711468

Epoch: 6| Step: 6
Training loss: 2.651219606399536
Validation loss: 2.1626667361105643

Epoch: 6| Step: 7
Training loss: 2.25068998336792
Validation loss: 2.1469035558803107

Epoch: 6| Step: 8
Training loss: 2.4722542762756348
Validation loss: 2.1219851483580885

Epoch: 6| Step: 9
Training loss: 2.4117209911346436
Validation loss: 2.1177752697339622

Epoch: 6| Step: 10
Training loss: 1.571885108947754
Validation loss: 2.117933986007526

Epoch: 6| Step: 11
Training loss: 2.00864839553833
Validation loss: 2.105515477477863

Epoch: 6| Step: 12
Training loss: 2.3425354957580566
Validation loss: 2.116258974998228

Epoch: 6| Step: 13
Training loss: 2.1284492015838623
Validation loss: 2.1236620333886917

Epoch: 102| Step: 0
Training loss: 2.008808135986328
Validation loss: 2.1191592024218653

Epoch: 6| Step: 1
Training loss: 3.132371664047241
Validation loss: 2.124343326014857

Epoch: 6| Step: 2
Training loss: 1.723400592803955
Validation loss: 2.117786850980533

Epoch: 6| Step: 3
Training loss: 2.489114284515381
Validation loss: 2.1138773759206138

Epoch: 6| Step: 4
Training loss: 2.64717435836792
Validation loss: 2.100522397666849

Epoch: 6| Step: 5
Training loss: 2.0419418811798096
Validation loss: 2.0787955509719027

Epoch: 6| Step: 6
Training loss: 2.3197903633117676
Validation loss: 2.0647845973250685

Epoch: 6| Step: 7
Training loss: 2.136349678039551
Validation loss: 2.076785559295326

Epoch: 6| Step: 8
Training loss: 2.314763069152832
Validation loss: 2.0722723878839964

Epoch: 6| Step: 9
Training loss: 2.8472342491149902
Validation loss: 2.0789923744816936

Epoch: 6| Step: 10
Training loss: 1.9122610092163086
Validation loss: 2.0763274354319416

Epoch: 6| Step: 11
Training loss: 2.5396132469177246
Validation loss: 2.0708006415315854

Epoch: 6| Step: 12
Training loss: 3.1400768756866455
Validation loss: 2.0793686861632974

Epoch: 6| Step: 13
Training loss: 2.0203917026519775
Validation loss: 2.0743663413550264

Epoch: 103| Step: 0
Training loss: 2.8072617053985596
Validation loss: 2.0820425838552494

Epoch: 6| Step: 1
Training loss: 1.869702696800232
Validation loss: 2.082775012139351

Epoch: 6| Step: 2
Training loss: 2.531855583190918
Validation loss: 2.075503085249214

Epoch: 6| Step: 3
Training loss: 2.034878969192505
Validation loss: 2.076863088915425

Epoch: 6| Step: 4
Training loss: 2.1540398597717285
Validation loss: 2.083655693197763

Epoch: 6| Step: 5
Training loss: 2.1570305824279785
Validation loss: 2.087934055636006

Epoch: 6| Step: 6
Training loss: 3.0582118034362793
Validation loss: 2.078317790903071

Epoch: 6| Step: 7
Training loss: 1.681708574295044
Validation loss: 2.0825961046321417

Epoch: 6| Step: 8
Training loss: 2.5546669960021973
Validation loss: 2.101725391162339

Epoch: 6| Step: 9
Training loss: 1.887387990951538
Validation loss: 2.0965439683647564

Epoch: 6| Step: 10
Training loss: 3.063366413116455
Validation loss: 2.100677841453142

Epoch: 6| Step: 11
Training loss: 2.057187557220459
Validation loss: 2.0976489179877826

Epoch: 6| Step: 12
Training loss: 2.34688663482666
Validation loss: 2.096202847778156

Epoch: 6| Step: 13
Training loss: 3.473623514175415
Validation loss: 2.1122379777252034

Epoch: 104| Step: 0
Training loss: 2.7662668228149414
Validation loss: 2.126368545716809

Epoch: 6| Step: 1
Training loss: 2.289403200149536
Validation loss: 2.1328516865289338

Epoch: 6| Step: 2
Training loss: 2.306055784225464
Validation loss: 2.125048009298181

Epoch: 6| Step: 3
Training loss: 1.9385466575622559
Validation loss: 2.1171558313472296

Epoch: 6| Step: 4
Training loss: 1.7699695825576782
Validation loss: 2.113987366358439

Epoch: 6| Step: 5
Training loss: 2.2273340225219727
Validation loss: 2.0938981322832007

Epoch: 6| Step: 6
Training loss: 2.1438708305358887
Validation loss: 2.0914444256854314

Epoch: 6| Step: 7
Training loss: 2.7339553833007812
Validation loss: 2.1082310702211116

Epoch: 6| Step: 8
Training loss: 2.7224695682525635
Validation loss: 2.1241177974208707

Epoch: 6| Step: 9
Training loss: 2.419957160949707
Validation loss: 2.1309129499620005

Epoch: 6| Step: 10
Training loss: 2.245509147644043
Validation loss: 2.1284834556682135

Epoch: 6| Step: 11
Training loss: 2.191800117492676
Validation loss: 2.126793904971051

Epoch: 6| Step: 12
Training loss: 3.242222547531128
Validation loss: 2.0993661906129573

Epoch: 6| Step: 13
Training loss: 2.3056278228759766
Validation loss: 2.0966278096681

Epoch: 105| Step: 0
Training loss: 2.74775767326355
Validation loss: 2.0889457066853843

Epoch: 6| Step: 1
Training loss: 2.0207979679107666
Validation loss: 2.0918493911784184

Epoch: 6| Step: 2
Training loss: 2.688231945037842
Validation loss: 2.1135709260099675

Epoch: 6| Step: 3
Training loss: 1.9350364208221436
Validation loss: 2.1130087196186023

Epoch: 6| Step: 4
Training loss: 2.4626052379608154
Validation loss: 2.1251186324704077

Epoch: 6| Step: 5
Training loss: 2.4645116329193115
Validation loss: 2.132475435092885

Epoch: 6| Step: 6
Training loss: 3.0915584564208984
Validation loss: 2.124576891622236

Epoch: 6| Step: 7
Training loss: 1.4796552658081055
Validation loss: 2.1243673140002834

Epoch: 6| Step: 8
Training loss: 2.4659197330474854
Validation loss: 2.116805011226285

Epoch: 6| Step: 9
Training loss: 2.1266989707946777
Validation loss: 2.1456521172677316

Epoch: 6| Step: 10
Training loss: 2.0838770866394043
Validation loss: 2.1424652786665064

Epoch: 6| Step: 11
Training loss: 1.907225251197815
Validation loss: 2.1340832992266585

Epoch: 6| Step: 12
Training loss: 2.1665377616882324
Validation loss: 2.141746610723516

Epoch: 6| Step: 13
Training loss: 3.9369747638702393
Validation loss: 2.1286352039665304

Epoch: 106| Step: 0
Training loss: 2.775099754333496
Validation loss: 2.1368800414505826

Epoch: 6| Step: 1
Training loss: 2.4532930850982666
Validation loss: 2.1398635320765997

Epoch: 6| Step: 2
Training loss: 2.077521324157715
Validation loss: 2.1353712953546995

Epoch: 6| Step: 3
Training loss: 3.0269017219543457
Validation loss: 2.132013428595758

Epoch: 6| Step: 4
Training loss: 2.784184694290161
Validation loss: 2.1258309964210755

Epoch: 6| Step: 5
Training loss: 1.9127347469329834
Validation loss: 2.1232570063683296

Epoch: 6| Step: 6
Training loss: 1.7731879949569702
Validation loss: 2.1196612491402576

Epoch: 6| Step: 7
Training loss: 2.3272483348846436
Validation loss: 2.1407409201386156

Epoch: 6| Step: 8
Training loss: 2.3762669563293457
Validation loss: 2.160002972490044

Epoch: 6| Step: 9
Training loss: 2.595553398132324
Validation loss: 2.145849447096548

Epoch: 6| Step: 10
Training loss: 2.050387144088745
Validation loss: 2.1317236320946806

Epoch: 6| Step: 11
Training loss: 2.323544502258301
Validation loss: 2.1212155767666396

Epoch: 6| Step: 12
Training loss: 1.9831962585449219
Validation loss: 2.0911415699989564

Epoch: 6| Step: 13
Training loss: 2.0147054195404053
Validation loss: 2.095559468833349

Epoch: 107| Step: 0
Training loss: 2.585376262664795
Validation loss: 2.112393331784074

Epoch: 6| Step: 1
Training loss: 2.0579118728637695
Validation loss: 2.1064970749680714

Epoch: 6| Step: 2
Training loss: 2.628920078277588
Validation loss: 2.1027789820906935

Epoch: 6| Step: 3
Training loss: 2.39670467376709
Validation loss: 2.0986205275340746

Epoch: 6| Step: 4
Training loss: 2.7760257720947266
Validation loss: 2.0852255846864436

Epoch: 6| Step: 5
Training loss: 2.0565943717956543
Validation loss: 2.085983678858767

Epoch: 6| Step: 6
Training loss: 2.7301511764526367
Validation loss: 2.08017014175333

Epoch: 6| Step: 7
Training loss: 1.6383473873138428
Validation loss: 2.084548866876992

Epoch: 6| Step: 8
Training loss: 2.622762441635132
Validation loss: 2.0859610367846746

Epoch: 6| Step: 9
Training loss: 2.5255751609802246
Validation loss: 2.0899427219103743

Epoch: 6| Step: 10
Training loss: 1.6380674839019775
Validation loss: 2.0945583492197017

Epoch: 6| Step: 11
Training loss: 2.3404653072357178
Validation loss: 2.0996780651871876

Epoch: 6| Step: 12
Training loss: 2.601362705230713
Validation loss: 2.110900640487671

Epoch: 6| Step: 13
Training loss: 2.0085978507995605
Validation loss: 2.11783331183977

Epoch: 108| Step: 0
Training loss: 2.612544059753418
Validation loss: 2.1197984628779913

Epoch: 6| Step: 1
Training loss: 2.052456855773926
Validation loss: 2.0977619847943707

Epoch: 6| Step: 2
Training loss: 2.441819190979004
Validation loss: 2.1015514353270173

Epoch: 6| Step: 3
Training loss: 1.5909651517868042
Validation loss: 2.106670264274843

Epoch: 6| Step: 4
Training loss: 1.876475214958191
Validation loss: 2.101268317109795

Epoch: 6| Step: 5
Training loss: 2.1525330543518066
Validation loss: 2.0834006699182654

Epoch: 6| Step: 6
Training loss: 2.7361912727355957
Validation loss: 2.089577792793192

Epoch: 6| Step: 7
Training loss: 2.957153797149658
Validation loss: 2.076858253889186

Epoch: 6| Step: 8
Training loss: 2.397608518600464
Validation loss: 2.0642009832525767

Epoch: 6| Step: 9
Training loss: 2.5604941844940186
Validation loss: 2.0673080593027096

Epoch: 6| Step: 10
Training loss: 2.7493810653686523
Validation loss: 2.058180102738001

Epoch: 6| Step: 11
Training loss: 1.6119463443756104
Validation loss: 2.05731765813725

Epoch: 6| Step: 12
Training loss: 2.627774238586426
Validation loss: 2.0485887014737694

Epoch: 6| Step: 13
Training loss: 1.9304368495941162
Validation loss: 2.0543676986489245

Epoch: 109| Step: 0
Training loss: 1.943860411643982
Validation loss: 2.051222188498384

Epoch: 6| Step: 1
Training loss: 2.3674826622009277
Validation loss: 2.0519971911625197

Epoch: 6| Step: 2
Training loss: 2.7003087997436523
Validation loss: 2.042968434672202

Epoch: 6| Step: 3
Training loss: 2.2452640533447266
Validation loss: 2.041818575192523

Epoch: 6| Step: 4
Training loss: 2.339520215988159
Validation loss: 2.028151514709637

Epoch: 6| Step: 5
Training loss: 2.221897602081299
Validation loss: 2.0343778658938665

Epoch: 6| Step: 6
Training loss: 2.729968786239624
Validation loss: 2.0272478185674196

Epoch: 6| Step: 7
Training loss: 2.430056571960449
Validation loss: 2.0209335357912126

Epoch: 6| Step: 8
Training loss: 2.0140819549560547
Validation loss: 2.0282273215632283

Epoch: 6| Step: 9
Training loss: 2.170497417449951
Validation loss: 2.0283927866207656

Epoch: 6| Step: 10
Training loss: 2.549393653869629
Validation loss: 2.0282120012467906

Epoch: 6| Step: 11
Training loss: 2.936060905456543
Validation loss: 2.0354788918648996

Epoch: 6| Step: 12
Training loss: 1.672417163848877
Validation loss: 2.045078936443534

Epoch: 6| Step: 13
Training loss: 2.104869842529297
Validation loss: 2.0572158700676373

Epoch: 110| Step: 0
Training loss: 1.8420594930648804
Validation loss: 2.07804637570535

Epoch: 6| Step: 1
Training loss: 2.523003578186035
Validation loss: 2.0732976813470163

Epoch: 6| Step: 2
Training loss: 2.7111928462982178
Validation loss: 2.0732513909698813

Epoch: 6| Step: 3
Training loss: 2.241772174835205
Validation loss: 2.0691165642071794

Epoch: 6| Step: 4
Training loss: 1.3911826610565186
Validation loss: 2.081001809848252

Epoch: 6| Step: 5
Training loss: 2.8059422969818115
Validation loss: 2.068600800729567

Epoch: 6| Step: 6
Training loss: 2.2288217544555664
Validation loss: 2.0788721115358415

Epoch: 6| Step: 7
Training loss: 2.5796337127685547
Validation loss: 2.076927197876797

Epoch: 6| Step: 8
Training loss: 2.7410624027252197
Validation loss: 2.081152105844149

Epoch: 6| Step: 9
Training loss: 2.3303911685943604
Validation loss: 2.109369739409416

Epoch: 6| Step: 10
Training loss: 1.9209411144256592
Validation loss: 2.123946879499702

Epoch: 6| Step: 11
Training loss: 2.3866875171661377
Validation loss: 2.136775116766653

Epoch: 6| Step: 12
Training loss: 2.498788833618164
Validation loss: 2.1252750606947046

Epoch: 6| Step: 13
Training loss: 2.1094484329223633
Validation loss: 2.0880904710420998

Epoch: 111| Step: 0
Training loss: 2.2258362770080566
Validation loss: 2.0527824471073766

Epoch: 6| Step: 1
Training loss: 2.4707794189453125
Validation loss: 2.0475301845099336

Epoch: 6| Step: 2
Training loss: 1.8546429872512817
Validation loss: 2.0467434954899613

Epoch: 6| Step: 3
Training loss: 2.1723432540893555
Validation loss: 2.034965838155439

Epoch: 6| Step: 4
Training loss: 2.148900270462036
Validation loss: 2.028790512392598

Epoch: 6| Step: 5
Training loss: 2.191342830657959
Validation loss: 2.040378624393094

Epoch: 6| Step: 6
Training loss: 2.3285646438598633
Validation loss: 2.0344727270064817

Epoch: 6| Step: 7
Training loss: 2.100322723388672
Validation loss: 2.045455022524762

Epoch: 6| Step: 8
Training loss: 2.1866674423217773
Validation loss: 2.0364448537108717

Epoch: 6| Step: 9
Training loss: 2.426701068878174
Validation loss: 2.050160164474159

Epoch: 6| Step: 10
Training loss: 2.3032524585723877
Validation loss: 2.0474307716533704

Epoch: 6| Step: 11
Training loss: 2.573528289794922
Validation loss: 2.0392449876313568

Epoch: 6| Step: 12
Training loss: 2.129897117614746
Validation loss: 2.0431181923035653

Epoch: 6| Step: 13
Training loss: 3.30934476852417
Validation loss: 2.0624519035380375

Epoch: 112| Step: 0
Training loss: 1.760817527770996
Validation loss: 2.051177527314873

Epoch: 6| Step: 1
Training loss: 2.1030027866363525
Validation loss: 2.044603043986905

Epoch: 6| Step: 2
Training loss: 1.8339028358459473
Validation loss: 2.0499694424290813

Epoch: 6| Step: 3
Training loss: 2.395021915435791
Validation loss: 2.0532808611469884

Epoch: 6| Step: 4
Training loss: 2.9851064682006836
Validation loss: 2.0367835747298373

Epoch: 6| Step: 5
Training loss: 2.3191356658935547
Validation loss: 2.0422096636987503

Epoch: 6| Step: 6
Training loss: 1.6663589477539062
Validation loss: 2.048525887150918

Epoch: 6| Step: 7
Training loss: 1.9980781078338623
Validation loss: 2.0485029194944646

Epoch: 6| Step: 8
Training loss: 2.0318193435668945
Validation loss: 2.057619551176666

Epoch: 6| Step: 9
Training loss: 3.1186699867248535
Validation loss: 2.0620357221172703

Epoch: 6| Step: 10
Training loss: 2.685302495956421
Validation loss: 2.0593209497390257

Epoch: 6| Step: 11
Training loss: 2.3320655822753906
Validation loss: 2.081543122568438

Epoch: 6| Step: 12
Training loss: 2.028829574584961
Validation loss: 2.102783300543344

Epoch: 6| Step: 13
Training loss: 2.6447882652282715
Validation loss: 2.1313727107099307

Epoch: 113| Step: 0
Training loss: 2.317253589630127
Validation loss: 2.1730601685021513

Epoch: 6| Step: 1
Training loss: 2.360623836517334
Validation loss: 2.2135394439902356

Epoch: 6| Step: 2
Training loss: 2.0826475620269775
Validation loss: 2.2318963645606913

Epoch: 6| Step: 3
Training loss: 2.0514791011810303
Validation loss: 2.2492908047091578

Epoch: 6| Step: 4
Training loss: 3.018369674682617
Validation loss: 2.238582521356562

Epoch: 6| Step: 5
Training loss: 1.5350890159606934
Validation loss: 2.208900169659686

Epoch: 6| Step: 6
Training loss: 2.9372968673706055
Validation loss: 2.1859752542229107

Epoch: 6| Step: 7
Training loss: 1.8967489004135132
Validation loss: 2.1464353223000803

Epoch: 6| Step: 8
Training loss: 2.650691509246826
Validation loss: 2.124922207606736

Epoch: 6| Step: 9
Training loss: 2.4416003227233887
Validation loss: 2.086434692464849

Epoch: 6| Step: 10
Training loss: 2.1026268005371094
Validation loss: 2.0496695362111574

Epoch: 6| Step: 11
Training loss: 2.0562422275543213
Validation loss: 2.0455775901835453

Epoch: 6| Step: 12
Training loss: 2.2138161659240723
Validation loss: 2.0490155976305724

Epoch: 6| Step: 13
Training loss: 2.455848217010498
Validation loss: 2.0550812239288003

Epoch: 114| Step: 0
Training loss: 1.6546677350997925
Validation loss: 2.0692230181027482

Epoch: 6| Step: 1
Training loss: 2.872067928314209
Validation loss: 2.106276099399854

Epoch: 6| Step: 2
Training loss: 2.703986167907715
Validation loss: 2.1350451182293635

Epoch: 6| Step: 3
Training loss: 2.2803049087524414
Validation loss: 2.1255212342867287

Epoch: 6| Step: 4
Training loss: 1.7503724098205566
Validation loss: 2.102778068152807

Epoch: 6| Step: 5
Training loss: 3.030294418334961
Validation loss: 2.11224465985452

Epoch: 6| Step: 6
Training loss: 1.7652655839920044
Validation loss: 2.0954392238329818

Epoch: 6| Step: 7
Training loss: 2.4406511783599854
Validation loss: 2.0731378319442912

Epoch: 6| Step: 8
Training loss: 1.6628596782684326
Validation loss: 2.0462178594322613

Epoch: 6| Step: 9
Training loss: 2.8809173107147217
Validation loss: 2.0441142230905514

Epoch: 6| Step: 10
Training loss: 2.0514400005340576
Validation loss: 2.039732620280276

Epoch: 6| Step: 11
Training loss: 2.393214464187622
Validation loss: 2.0391422035873576

Epoch: 6| Step: 12
Training loss: 2.923485517501831
Validation loss: 2.032755435154002

Epoch: 6| Step: 13
Training loss: 1.8123259544372559
Validation loss: 2.0463701281496274

Epoch: 115| Step: 0
Training loss: 3.3060545921325684
Validation loss: 2.0526716068226802

Epoch: 6| Step: 1
Training loss: 2.380505084991455
Validation loss: 2.069420281276908

Epoch: 6| Step: 2
Training loss: 1.8679651021957397
Validation loss: 2.1080605650460846

Epoch: 6| Step: 3
Training loss: 1.9389100074768066
Validation loss: 2.1269866612649735

Epoch: 6| Step: 4
Training loss: 1.9335932731628418
Validation loss: 2.143362440088744

Epoch: 6| Step: 5
Training loss: 1.8451182842254639
Validation loss: 2.147129697184409

Epoch: 6| Step: 6
Training loss: 2.3991475105285645
Validation loss: 2.132944635165635

Epoch: 6| Step: 7
Training loss: 1.9315428733825684
Validation loss: 2.10048250485492

Epoch: 6| Step: 8
Training loss: 2.229930877685547
Validation loss: 2.116694361932816

Epoch: 6| Step: 9
Training loss: 2.2972710132598877
Validation loss: 2.134419714250872

Epoch: 6| Step: 10
Training loss: 2.2049078941345215
Validation loss: 2.172960291626633

Epoch: 6| Step: 11
Training loss: 2.150331974029541
Validation loss: 2.2078739891770067

Epoch: 6| Step: 12
Training loss: 2.9691319465637207
Validation loss: 2.1948835106306177

Epoch: 6| Step: 13
Training loss: 2.990330696105957
Validation loss: 2.1646637967837754

Epoch: 116| Step: 0
Training loss: 1.863946557044983
Validation loss: 2.15088290040211

Epoch: 6| Step: 1
Training loss: 2.636063814163208
Validation loss: 2.1204556701003865

Epoch: 6| Step: 2
Training loss: 2.141728639602661
Validation loss: 2.0963451580334733

Epoch: 6| Step: 3
Training loss: 2.491427421569824
Validation loss: 2.0815298147098993

Epoch: 6| Step: 4
Training loss: 1.6966652870178223
Validation loss: 2.0459267144562094

Epoch: 6| Step: 5
Training loss: 2.4004385471343994
Validation loss: 2.034272446427294

Epoch: 6| Step: 6
Training loss: 2.5460152626037598
Validation loss: 2.01954500649565

Epoch: 6| Step: 7
Training loss: 2.015514373779297
Validation loss: 1.9988993649841638

Epoch: 6| Step: 8
Training loss: 2.4560811519622803
Validation loss: 1.9968528875740625

Epoch: 6| Step: 9
Training loss: 2.5761005878448486
Validation loss: 2.0063841060925554

Epoch: 6| Step: 10
Training loss: 2.22116756439209
Validation loss: 2.0077772448139806

Epoch: 6| Step: 11
Training loss: 2.8449172973632812
Validation loss: 2.0087374692322104

Epoch: 6| Step: 12
Training loss: 1.9565902948379517
Validation loss: 2.023300245244016

Epoch: 6| Step: 13
Training loss: 1.8876584768295288
Validation loss: 2.0244765050949587

Epoch: 117| Step: 0
Training loss: 1.4780831336975098
Validation loss: 2.033006404035835

Epoch: 6| Step: 1
Training loss: 2.593109130859375
Validation loss: 2.0657955779824206

Epoch: 6| Step: 2
Training loss: 2.269057512283325
Validation loss: 2.0720760424931846

Epoch: 6| Step: 3
Training loss: 3.0863900184631348
Validation loss: 2.070940790637847

Epoch: 6| Step: 4
Training loss: 2.701000690460205
Validation loss: 2.0646725905838834

Epoch: 6| Step: 5
Training loss: 2.2908992767333984
Validation loss: 2.064074424005324

Epoch: 6| Step: 6
Training loss: 1.7823176383972168
Validation loss: 2.0561522565862185

Epoch: 6| Step: 7
Training loss: 2.1121654510498047
Validation loss: 2.0560613524529243

Epoch: 6| Step: 8
Training loss: 1.9513466358184814
Validation loss: 2.0818622214819795

Epoch: 6| Step: 9
Training loss: 2.31248140335083
Validation loss: 2.089895348395071

Epoch: 6| Step: 10
Training loss: 2.0530169010162354
Validation loss: 2.1460892103051625

Epoch: 6| Step: 11
Training loss: 2.4026384353637695
Validation loss: 2.140383484543011

Epoch: 6| Step: 12
Training loss: 2.5788679122924805
Validation loss: 2.1406120638693533

Epoch: 6| Step: 13
Training loss: 1.5474821329116821
Validation loss: 2.130377238796603

Epoch: 118| Step: 0
Training loss: 2.7837283611297607
Validation loss: 2.144620374966693

Epoch: 6| Step: 1
Training loss: 2.5693535804748535
Validation loss: 2.1574769378990255

Epoch: 6| Step: 2
Training loss: 1.8517558574676514
Validation loss: 2.144117101546257

Epoch: 6| Step: 3
Training loss: 2.34787654876709
Validation loss: 2.116697993329776

Epoch: 6| Step: 4
Training loss: 1.7139356136322021
Validation loss: 2.1260852018992105

Epoch: 6| Step: 5
Training loss: 2.374448299407959
Validation loss: 2.1384708855741765

Epoch: 6| Step: 6
Training loss: 2.781726121902466
Validation loss: 2.165767890150829

Epoch: 6| Step: 7
Training loss: 1.9468586444854736
Validation loss: 2.2008006905996673

Epoch: 6| Step: 8
Training loss: 1.946793556213379
Validation loss: 2.224942002245175

Epoch: 6| Step: 9
Training loss: 1.6672632694244385
Validation loss: 2.2113258223379813

Epoch: 6| Step: 10
Training loss: 2.9478330612182617
Validation loss: 2.2088963959806707

Epoch: 6| Step: 11
Training loss: 2.2294399738311768
Validation loss: 2.1598179237816924

Epoch: 6| Step: 12
Training loss: 2.7642998695373535
Validation loss: 2.1415027623535483

Epoch: 6| Step: 13
Training loss: 2.1787853240966797
Validation loss: 2.1292689333679857

Epoch: 119| Step: 0
Training loss: 1.971509575843811
Validation loss: 2.1221520644362255

Epoch: 6| Step: 1
Training loss: 2.3898682594299316
Validation loss: 2.133071953250516

Epoch: 6| Step: 2
Training loss: 1.6913341283798218
Validation loss: 2.167894273675898

Epoch: 6| Step: 3
Training loss: 2.3140742778778076
Validation loss: 2.177191344640588

Epoch: 6| Step: 4
Training loss: 2.1301467418670654
Validation loss: 2.163307741124143

Epoch: 6| Step: 5
Training loss: 2.6810531616210938
Validation loss: 2.1470763298772995

Epoch: 6| Step: 6
Training loss: 2.6895174980163574
Validation loss: 2.1208343095676874

Epoch: 6| Step: 7
Training loss: 2.3597989082336426
Validation loss: 2.1161959684023293

Epoch: 6| Step: 8
Training loss: 1.621520757675171
Validation loss: 2.108283619726858

Epoch: 6| Step: 9
Training loss: 1.8823821544647217
Validation loss: 2.130163654204338

Epoch: 6| Step: 10
Training loss: 2.6442432403564453
Validation loss: 2.1364216445594706

Epoch: 6| Step: 11
Training loss: 2.608816385269165
Validation loss: 2.1467778862163587

Epoch: 6| Step: 12
Training loss: 2.121095657348633
Validation loss: 2.1232256017705446

Epoch: 6| Step: 13
Training loss: 2.5333495140075684
Validation loss: 2.118415847901375

Epoch: 120| Step: 0
Training loss: 1.5478296279907227
Validation loss: 2.126334999197273

Epoch: 6| Step: 1
Training loss: 3.011353015899658
Validation loss: 2.1386962949588733

Epoch: 6| Step: 2
Training loss: 2.606295108795166
Validation loss: 2.1009153935217086

Epoch: 6| Step: 3
Training loss: 2.4319961071014404
Validation loss: 2.092738491232677

Epoch: 6| Step: 4
Training loss: 2.311549663543701
Validation loss: 2.0873373541780698

Epoch: 6| Step: 5
Training loss: 1.5920161008834839
Validation loss: 2.0622720051837224

Epoch: 6| Step: 6
Training loss: 2.2994604110717773
Validation loss: 2.0561913828695975

Epoch: 6| Step: 7
Training loss: 2.038271903991699
Validation loss: 2.049193856536701

Epoch: 6| Step: 8
Training loss: 2.0432794094085693
Validation loss: 2.0452035909057944

Epoch: 6| Step: 9
Training loss: 2.7430739402770996
Validation loss: 2.0352830707385974

Epoch: 6| Step: 10
Training loss: 2.0639967918395996
Validation loss: 2.028575135815528

Epoch: 6| Step: 11
Training loss: 2.8172998428344727
Validation loss: 2.0345212592873523

Epoch: 6| Step: 12
Training loss: 1.6705691814422607
Validation loss: 2.0357072943000385

Epoch: 6| Step: 13
Training loss: 1.748976707458496
Validation loss: 2.045114049347498

Epoch: 121| Step: 0
Training loss: 1.6695188283920288
Validation loss: 2.051905575618949

Epoch: 6| Step: 1
Training loss: 2.4959912300109863
Validation loss: 2.0782705840244087

Epoch: 6| Step: 2
Training loss: 1.7925834655761719
Validation loss: 2.0998941672745572

Epoch: 6| Step: 3
Training loss: 2.998425245285034
Validation loss: 2.103328779179563

Epoch: 6| Step: 4
Training loss: 2.0066585540771484
Validation loss: 2.1053936622476064

Epoch: 6| Step: 5
Training loss: 2.1333649158477783
Validation loss: 2.0818420712665846

Epoch: 6| Step: 6
Training loss: 1.955407977104187
Validation loss: 2.0849133165933753

Epoch: 6| Step: 7
Training loss: 2.167609691619873
Validation loss: 2.0611141932907926

Epoch: 6| Step: 8
Training loss: 2.245877742767334
Validation loss: 2.049828226848315

Epoch: 6| Step: 9
Training loss: 2.523682117462158
Validation loss: 2.068542621468985

Epoch: 6| Step: 10
Training loss: 2.3603994846343994
Validation loss: 2.074386865861954

Epoch: 6| Step: 11
Training loss: 1.950606107711792
Validation loss: 2.0700623873741395

Epoch: 6| Step: 12
Training loss: 2.4939932823181152
Validation loss: 2.0782314077500375

Epoch: 6| Step: 13
Training loss: 1.7877066135406494
Validation loss: 2.077227300213229

Epoch: 122| Step: 0
Training loss: 2.3269200325012207
Validation loss: 2.0822451806837514

Epoch: 6| Step: 1
Training loss: 2.6078734397888184
Validation loss: 2.082458351248054

Epoch: 6| Step: 2
Training loss: 2.50815486907959
Validation loss: 2.092598017825875

Epoch: 6| Step: 3
Training loss: 2.1868433952331543
Validation loss: 2.095673289350284

Epoch: 6| Step: 4
Training loss: 1.8066948652267456
Validation loss: 2.0966955769446587

Epoch: 6| Step: 5
Training loss: 1.509425401687622
Validation loss: 2.0760708598680395

Epoch: 6| Step: 6
Training loss: 2.416630744934082
Validation loss: 2.0747849992526475

Epoch: 6| Step: 7
Training loss: 2.0015549659729004
Validation loss: 2.070415860863142

Epoch: 6| Step: 8
Training loss: 2.490281105041504
Validation loss: 2.093259044872817

Epoch: 6| Step: 9
Training loss: 2.096912145614624
Validation loss: 2.094058821278234

Epoch: 6| Step: 10
Training loss: 2.513615608215332
Validation loss: 2.073212919696685

Epoch: 6| Step: 11
Training loss: 1.906797170639038
Validation loss: 2.0746026859488538

Epoch: 6| Step: 12
Training loss: 1.9334458112716675
Validation loss: 2.0811385262397026

Epoch: 6| Step: 13
Training loss: 2.2905213832855225
Validation loss: 2.0692902265056485

Epoch: 123| Step: 0
Training loss: 2.387787342071533
Validation loss: 2.072793331197513

Epoch: 6| Step: 1
Training loss: 2.033076286315918
Validation loss: 2.0692217760188605

Epoch: 6| Step: 2
Training loss: 2.224062204360962
Validation loss: 2.0805083705532934

Epoch: 6| Step: 3
Training loss: 2.544036388397217
Validation loss: 2.077098746453562

Epoch: 6| Step: 4
Training loss: 2.5913877487182617
Validation loss: 2.069521145154071

Epoch: 6| Step: 5
Training loss: 1.7424647808074951
Validation loss: 2.0586441447657924

Epoch: 6| Step: 6
Training loss: 1.9495598077774048
Validation loss: 2.0577739771976264

Epoch: 6| Step: 7
Training loss: 2.3149144649505615
Validation loss: 2.0975894902342107

Epoch: 6| Step: 8
Training loss: 2.1215264797210693
Validation loss: 2.154708164994435

Epoch: 6| Step: 9
Training loss: 1.8725861310958862
Validation loss: 2.168747153333438

Epoch: 6| Step: 10
Training loss: 2.7985992431640625
Validation loss: 2.177126697314683

Epoch: 6| Step: 11
Training loss: 3.0613555908203125
Validation loss: 2.16837808393663

Epoch: 6| Step: 12
Training loss: 1.644594430923462
Validation loss: 2.1580757248786187

Epoch: 6| Step: 13
Training loss: 1.3712365627288818
Validation loss: 2.1131133956293904

Epoch: 124| Step: 0
Training loss: 2.116201400756836
Validation loss: 2.104261734152353

Epoch: 6| Step: 1
Training loss: 1.8936372995376587
Validation loss: 2.107588594959628

Epoch: 6| Step: 2
Training loss: 1.8765056133270264
Validation loss: 2.1512395105054303

Epoch: 6| Step: 3
Training loss: 2.592344045639038
Validation loss: 2.1960695482069448

Epoch: 6| Step: 4
Training loss: 2.778883457183838
Validation loss: 2.2259368614483903

Epoch: 6| Step: 5
Training loss: 2.0638504028320312
Validation loss: 2.2034611394328456

Epoch: 6| Step: 6
Training loss: 2.6001954078674316
Validation loss: 2.1268397338928713

Epoch: 6| Step: 7
Training loss: 2.2276580333709717
Validation loss: 2.087161276930122

Epoch: 6| Step: 8
Training loss: 1.8007404804229736
Validation loss: 2.0614479511014876

Epoch: 6| Step: 9
Training loss: 1.9922106266021729
Validation loss: 2.0415902676120883

Epoch: 6| Step: 10
Training loss: 2.700601100921631
Validation loss: 2.0305359914738643

Epoch: 6| Step: 11
Training loss: 1.838724136352539
Validation loss: 2.0317763923316874

Epoch: 6| Step: 12
Training loss: 2.485950469970703
Validation loss: 2.039253186154109

Epoch: 6| Step: 13
Training loss: 1.181896448135376
Validation loss: 2.0403085472763225

Epoch: 125| Step: 0
Training loss: 1.9457848072052002
Validation loss: 2.0233808525146975

Epoch: 6| Step: 1
Training loss: 1.6735507249832153
Validation loss: 2.0198576065801803

Epoch: 6| Step: 2
Training loss: 2.461850881576538
Validation loss: 2.0161967123708417

Epoch: 6| Step: 3
Training loss: 2.3695249557495117
Validation loss: 2.006615980978935

Epoch: 6| Step: 4
Training loss: 1.9384965896606445
Validation loss: 2.006379455648443

Epoch: 6| Step: 5
Training loss: 2.457428455352783
Validation loss: 2.0191741092230684

Epoch: 6| Step: 6
Training loss: 2.1216022968292236
Validation loss: 2.029886140618273

Epoch: 6| Step: 7
Training loss: 3.1190929412841797
Validation loss: 2.0244476026104343

Epoch: 6| Step: 8
Training loss: 1.9241262674331665
Validation loss: 2.042537663572578

Epoch: 6| Step: 9
Training loss: 1.6187055110931396
Validation loss: 2.041739712479294

Epoch: 6| Step: 10
Training loss: 2.869572877883911
Validation loss: 2.042960297676825

Epoch: 6| Step: 11
Training loss: 2.187286853790283
Validation loss: 2.052872669312262

Epoch: 6| Step: 12
Training loss: 1.7565269470214844
Validation loss: 2.048536149404382

Epoch: 6| Step: 13
Training loss: 1.6198482513427734
Validation loss: 2.033448137262816

Epoch: 126| Step: 0
Training loss: 2.385162830352783
Validation loss: 2.039743500371133

Epoch: 6| Step: 1
Training loss: 2.1517763137817383
Validation loss: 2.033778022694331

Epoch: 6| Step: 2
Training loss: 1.4802203178405762
Validation loss: 2.0499601697409027

Epoch: 6| Step: 3
Training loss: 2.484266757965088
Validation loss: 2.071567004726779

Epoch: 6| Step: 4
Training loss: 2.239898204803467
Validation loss: 2.0953281002659954

Epoch: 6| Step: 5
Training loss: 1.989579439163208
Validation loss: 2.106053431828817

Epoch: 6| Step: 6
Training loss: 2.216338634490967
Validation loss: 2.12424293128393

Epoch: 6| Step: 7
Training loss: 1.3299660682678223
Validation loss: 2.1166012338412705

Epoch: 6| Step: 8
Training loss: 2.3535447120666504
Validation loss: 2.1049512227376304

Epoch: 6| Step: 9
Training loss: 1.7391133308410645
Validation loss: 2.0895401252213346

Epoch: 6| Step: 10
Training loss: 1.7030012607574463
Validation loss: 2.0701517443503104

Epoch: 6| Step: 11
Training loss: 2.6475396156311035
Validation loss: 2.050440401159307

Epoch: 6| Step: 12
Training loss: 2.721188545227051
Validation loss: 2.036769033760153

Epoch: 6| Step: 13
Training loss: 2.4697248935699463
Validation loss: 2.032858852417238

Epoch: 127| Step: 0
Training loss: 1.5433897972106934
Validation loss: 2.031352112370153

Epoch: 6| Step: 1
Training loss: 2.959669589996338
Validation loss: 2.0498141255429996

Epoch: 6| Step: 2
Training loss: 1.7102411985397339
Validation loss: 2.0658466046856296

Epoch: 6| Step: 3
Training loss: 2.6770248413085938
Validation loss: 2.0717967940915014

Epoch: 6| Step: 4
Training loss: 2.5505638122558594
Validation loss: 2.0669426354028846

Epoch: 6| Step: 5
Training loss: 1.9045028686523438
Validation loss: 2.077662807638927

Epoch: 6| Step: 6
Training loss: 1.7878292798995972
Validation loss: 2.073714707487373

Epoch: 6| Step: 7
Training loss: 2.0334274768829346
Validation loss: 2.0983045562621085

Epoch: 6| Step: 8
Training loss: 2.1359457969665527
Validation loss: 2.097831300509873

Epoch: 6| Step: 9
Training loss: 1.9286689758300781
Validation loss: 2.1186577837954284

Epoch: 6| Step: 10
Training loss: 2.456517219543457
Validation loss: 2.118297461540468

Epoch: 6| Step: 11
Training loss: 2.493269920349121
Validation loss: 2.1250883558745026

Epoch: 6| Step: 12
Training loss: 1.7153681516647339
Validation loss: 2.1207406046569988

Epoch: 6| Step: 13
Training loss: 2.2473597526550293
Validation loss: 2.0956598174187446

Epoch: 128| Step: 0
Training loss: 1.5305829048156738
Validation loss: 2.059862083004367

Epoch: 6| Step: 1
Training loss: 1.7551466226577759
Validation loss: 2.071567840473626

Epoch: 6| Step: 2
Training loss: 2.1711440086364746
Validation loss: 2.0229008428512083

Epoch: 6| Step: 3
Training loss: 2.460405111312866
Validation loss: 2.0141879845690984

Epoch: 6| Step: 4
Training loss: 2.317805767059326
Validation loss: 2.009809487609453

Epoch: 6| Step: 5
Training loss: 1.858336091041565
Validation loss: 2.0243102722270514

Epoch: 6| Step: 6
Training loss: 2.1534833908081055
Validation loss: 2.0325025255962084

Epoch: 6| Step: 7
Training loss: 2.094377279281616
Validation loss: 2.0402371909028743

Epoch: 6| Step: 8
Training loss: 1.7902276515960693
Validation loss: 2.067566526833401

Epoch: 6| Step: 9
Training loss: 2.6650164127349854
Validation loss: 2.1035681411784184

Epoch: 6| Step: 10
Training loss: 2.8695883750915527
Validation loss: 2.1389992083272626

Epoch: 6| Step: 11
Training loss: 1.72933030128479
Validation loss: 2.1536271085021315

Epoch: 6| Step: 12
Training loss: 2.4444751739501953
Validation loss: 2.16383570624936

Epoch: 6| Step: 13
Training loss: 2.3268847465515137
Validation loss: 2.15467813322621

Epoch: 129| Step: 0
Training loss: 1.9296579360961914
Validation loss: 2.1637078497999456

Epoch: 6| Step: 1
Training loss: 2.0656046867370605
Validation loss: 2.196956326884608

Epoch: 6| Step: 2
Training loss: 1.7535018920898438
Validation loss: 2.2018580449524747

Epoch: 6| Step: 3
Training loss: 2.564363479614258
Validation loss: 2.211390559391309

Epoch: 6| Step: 4
Training loss: 2.552664279937744
Validation loss: 2.2065133458824566

Epoch: 6| Step: 5
Training loss: 2.254349708557129
Validation loss: 2.1987408950764644

Epoch: 6| Step: 6
Training loss: 2.0557332038879395
Validation loss: 2.199166564531224

Epoch: 6| Step: 7
Training loss: 2.4081785678863525
Validation loss: 2.1860619411673596

Epoch: 6| Step: 8
Training loss: 2.566610813140869
Validation loss: 2.1763771849293865

Epoch: 6| Step: 9
Training loss: 2.4626927375793457
Validation loss: 2.114607036754649

Epoch: 6| Step: 10
Training loss: 1.3826351165771484
Validation loss: 2.071015411807645

Epoch: 6| Step: 11
Training loss: 2.1745429039001465
Validation loss: 2.047986158760645

Epoch: 6| Step: 12
Training loss: 2.122865676879883
Validation loss: 2.038237822953091

Epoch: 6| Step: 13
Training loss: 1.8534717559814453
Validation loss: 2.0320154402845647

Epoch: 130| Step: 0
Training loss: 2.905273914337158
Validation loss: 2.025681067538518

Epoch: 6| Step: 1
Training loss: 1.7538073062896729
Validation loss: 2.0464695410061906

Epoch: 6| Step: 2
Training loss: 1.8242285251617432
Validation loss: 2.076191948306176

Epoch: 6| Step: 3
Training loss: 2.8348708152770996
Validation loss: 2.129498497132332

Epoch: 6| Step: 4
Training loss: 2.448596954345703
Validation loss: 2.1511432714359735

Epoch: 6| Step: 5
Training loss: 0.9436224699020386
Validation loss: 2.1671932717805267

Epoch: 6| Step: 6
Training loss: 2.521984100341797
Validation loss: 2.162697248561408

Epoch: 6| Step: 7
Training loss: 1.8046443462371826
Validation loss: 2.1100325430593183

Epoch: 6| Step: 8
Training loss: 2.6852502822875977
Validation loss: 2.056405880117929

Epoch: 6| Step: 9
Training loss: 1.9847023487091064
Validation loss: 2.0253615789515997

Epoch: 6| Step: 10
Training loss: 1.8724604845046997
Validation loss: 2.0479715972818355

Epoch: 6| Step: 11
Training loss: 1.799279808998108
Validation loss: 2.054117992360105

Epoch: 6| Step: 12
Training loss: 2.0459036827087402
Validation loss: 2.1061535073864843

Epoch: 6| Step: 13
Training loss: 2.8342840671539307
Validation loss: 2.1238491932551065

Epoch: 131| Step: 0
Training loss: 1.8181042671203613
Validation loss: 2.14443257675376

Epoch: 6| Step: 1
Training loss: 2.4605510234832764
Validation loss: 2.182008840704477

Epoch: 6| Step: 2
Training loss: 2.0792717933654785
Validation loss: 2.186724019306962

Epoch: 6| Step: 3
Training loss: 2.4827985763549805
Validation loss: 2.16371553174911

Epoch: 6| Step: 4
Training loss: 1.9004913568496704
Validation loss: 2.157930770227986

Epoch: 6| Step: 5
Training loss: 1.9963772296905518
Validation loss: 2.1534094913031465

Epoch: 6| Step: 6
Training loss: 1.9445452690124512
Validation loss: 2.133613814589798

Epoch: 6| Step: 7
Training loss: 2.0241823196411133
Validation loss: 2.1228298089837514

Epoch: 6| Step: 8
Training loss: 3.024806499481201
Validation loss: 2.1265831275652816

Epoch: 6| Step: 9
Training loss: 2.567277669906616
Validation loss: 2.119719397637152

Epoch: 6| Step: 10
Training loss: 2.0694053173065186
Validation loss: 2.1068106466724026

Epoch: 6| Step: 11
Training loss: 1.2925524711608887
Validation loss: 2.10767852106402

Epoch: 6| Step: 12
Training loss: 1.5204658508300781
Validation loss: 2.0937317032967844

Epoch: 6| Step: 13
Training loss: 1.8177274465560913
Validation loss: 2.082980666109311

Epoch: 132| Step: 0
Training loss: 1.9807252883911133
Validation loss: 2.0949384486803444

Epoch: 6| Step: 1
Training loss: 1.8675457239151
Validation loss: 2.08138475366818

Epoch: 6| Step: 2
Training loss: 1.8749979734420776
Validation loss: 2.082856975575929

Epoch: 6| Step: 3
Training loss: 2.533355712890625
Validation loss: 2.066109762396864

Epoch: 6| Step: 4
Training loss: 2.5709502696990967
Validation loss: 2.0713682290046447

Epoch: 6| Step: 5
Training loss: 2.548269271850586
Validation loss: 2.08541896266322

Epoch: 6| Step: 6
Training loss: 1.8958367109298706
Validation loss: 2.070434070402576

Epoch: 6| Step: 7
Training loss: 2.311680316925049
Validation loss: 2.060278983526332

Epoch: 6| Step: 8
Training loss: 2.398615837097168
Validation loss: 2.0402506679616947

Epoch: 6| Step: 9
Training loss: 2.1345396041870117
Validation loss: 2.0255866409629903

Epoch: 6| Step: 10
Training loss: 1.849448561668396
Validation loss: 2.024542259913619

Epoch: 6| Step: 11
Training loss: 2.011385440826416
Validation loss: 2.034251287419309

Epoch: 6| Step: 12
Training loss: 1.8571062088012695
Validation loss: 2.0617542318118516

Epoch: 6| Step: 13
Training loss: 1.6131471395492554
Validation loss: 2.0834490791443856

Epoch: 133| Step: 0
Training loss: 2.4164772033691406
Validation loss: 2.095464380838538

Epoch: 6| Step: 1
Training loss: 1.6176600456237793
Validation loss: 2.1089363918509534

Epoch: 6| Step: 2
Training loss: 1.3001420497894287
Validation loss: 2.1129031078789824

Epoch: 6| Step: 3
Training loss: 2.4793381690979004
Validation loss: 2.1003872938053583

Epoch: 6| Step: 4
Training loss: 2.6094765663146973
Validation loss: 2.0759346433865127

Epoch: 6| Step: 5
Training loss: 1.7869269847869873
Validation loss: 2.0600191957207135

Epoch: 6| Step: 6
Training loss: 1.9039957523345947
Validation loss: 2.0475365628478346

Epoch: 6| Step: 7
Training loss: 1.8287112712860107
Validation loss: 2.042292433400308

Epoch: 6| Step: 8
Training loss: 1.94317626953125
Validation loss: 2.0351719330715876

Epoch: 6| Step: 9
Training loss: 2.467898368835449
Validation loss: 2.043291043209773

Epoch: 6| Step: 10
Training loss: 2.9069576263427734
Validation loss: 2.070369025712372

Epoch: 6| Step: 11
Training loss: 2.222064971923828
Validation loss: 2.0845412644006873

Epoch: 6| Step: 12
Training loss: 1.4917081594467163
Validation loss: 2.1136746496282597

Epoch: 6| Step: 13
Training loss: 1.668378233909607
Validation loss: 2.0961524081486527

Epoch: 134| Step: 0
Training loss: 2.4899356365203857
Validation loss: 2.0811647830470914

Epoch: 6| Step: 1
Training loss: 2.56984806060791
Validation loss: 2.073449586027412

Epoch: 6| Step: 2
Training loss: 1.8398964405059814
Validation loss: 2.0647379634200886

Epoch: 6| Step: 3
Training loss: 1.8239061832427979
Validation loss: 2.0769822328321395

Epoch: 6| Step: 4
Training loss: 2.1273210048675537
Validation loss: 2.0741270665199525

Epoch: 6| Step: 5
Training loss: 1.7323918342590332
Validation loss: 2.0725539115167435

Epoch: 6| Step: 6
Training loss: 2.048783302307129
Validation loss: 2.0571386301389305

Epoch: 6| Step: 7
Training loss: 1.2994509935379028
Validation loss: 2.0713665613564114

Epoch: 6| Step: 8
Training loss: 1.6488386392593384
Validation loss: 2.0787360642545964

Epoch: 6| Step: 9
Training loss: 2.1884515285491943
Validation loss: 2.092551910749046

Epoch: 6| Step: 10
Training loss: 2.722827434539795
Validation loss: 2.115900743392206

Epoch: 6| Step: 11
Training loss: 2.023191452026367
Validation loss: 2.1127872851587113

Epoch: 6| Step: 12
Training loss: 2.243262767791748
Validation loss: 2.096320511192404

Epoch: 6| Step: 13
Training loss: 2.0629940032958984
Validation loss: 2.0851404666900635

Epoch: 135| Step: 0
Training loss: 2.393289566040039
Validation loss: 2.0763693996655044

Epoch: 6| Step: 1
Training loss: 2.871506690979004
Validation loss: 2.0499880211327666

Epoch: 6| Step: 2
Training loss: 1.8822556734085083
Validation loss: 2.036841243825933

Epoch: 6| Step: 3
Training loss: 2.0484261512756348
Validation loss: 2.0219643641543645

Epoch: 6| Step: 4
Training loss: 1.614417314529419
Validation loss: 2.0425662020201325

Epoch: 6| Step: 5
Training loss: 2.1629157066345215
Validation loss: 2.0941370071903354

Epoch: 6| Step: 6
Training loss: 2.8258683681488037
Validation loss: 2.1130274008679133

Epoch: 6| Step: 7
Training loss: 2.0938563346862793
Validation loss: 2.1153196339966147

Epoch: 6| Step: 8
Training loss: 1.5191864967346191
Validation loss: 2.067874212418833

Epoch: 6| Step: 9
Training loss: 1.8700062036514282
Validation loss: 2.057713375296644

Epoch: 6| Step: 10
Training loss: 2.3146209716796875
Validation loss: 2.0614413381904684

Epoch: 6| Step: 11
Training loss: 2.229161024093628
Validation loss: 2.102033640748711

Epoch: 6| Step: 12
Training loss: 1.9136136770248413
Validation loss: 2.1350858942154916

Epoch: 6| Step: 13
Training loss: 1.0276494026184082
Validation loss: 2.1629701173433693

Epoch: 136| Step: 0
Training loss: 1.6233305931091309
Validation loss: 2.1389910392863776

Epoch: 6| Step: 1
Training loss: 2.2926814556121826
Validation loss: 2.100567335723549

Epoch: 6| Step: 2
Training loss: 2.5533506870269775
Validation loss: 2.051458802274478

Epoch: 6| Step: 3
Training loss: 1.9097543954849243
Validation loss: 2.027038515255015

Epoch: 6| Step: 4
Training loss: 1.4803277254104614
Validation loss: 2.0104092603088706

Epoch: 6| Step: 5
Training loss: 1.9016982316970825
Validation loss: 2.020988454100906

Epoch: 6| Step: 6
Training loss: 1.9093711376190186
Validation loss: 2.0385103097525974

Epoch: 6| Step: 7
Training loss: 2.3184895515441895
Validation loss: 2.0703398489182994

Epoch: 6| Step: 8
Training loss: 2.682898998260498
Validation loss: 2.0996594839198615

Epoch: 6| Step: 9
Training loss: 2.045992612838745
Validation loss: 2.103116246961778

Epoch: 6| Step: 10
Training loss: 2.5989630222320557
Validation loss: 2.1111267523099015

Epoch: 6| Step: 11
Training loss: 2.217449903488159
Validation loss: 2.1162503483474895

Epoch: 6| Step: 12
Training loss: 1.6664109230041504
Validation loss: 2.152332064925983

Epoch: 6| Step: 13
Training loss: 1.6301299333572388
Validation loss: 2.1427736987349806

Epoch: 137| Step: 0
Training loss: 2.108844757080078
Validation loss: 2.1095031871590564

Epoch: 6| Step: 1
Training loss: 2.415740966796875
Validation loss: 2.086592815255606

Epoch: 6| Step: 2
Training loss: 2.573096513748169
Validation loss: 2.043985520639727

Epoch: 6| Step: 3
Training loss: 1.6310354471206665
Validation loss: 2.02776506639296

Epoch: 6| Step: 4
Training loss: 2.6394991874694824
Validation loss: 1.99341074497469

Epoch: 6| Step: 5
Training loss: 1.5392177104949951
Validation loss: 1.9981899094837967

Epoch: 6| Step: 6
Training loss: 2.187997341156006
Validation loss: 2.0430553754170737

Epoch: 6| Step: 7
Training loss: 2.000335931777954
Validation loss: 2.103816509246826

Epoch: 6| Step: 8
Training loss: 1.808997631072998
Validation loss: 2.1360822287938928

Epoch: 6| Step: 9
Training loss: 2.5814573764801025
Validation loss: 2.1541115135274906

Epoch: 6| Step: 10
Training loss: 1.5677871704101562
Validation loss: 2.1087018161691646

Epoch: 6| Step: 11
Training loss: 2.7528955936431885
Validation loss: 2.0696669368333716

Epoch: 6| Step: 12
Training loss: 1.5840883255004883
Validation loss: 2.0509750612320437

Epoch: 6| Step: 13
Training loss: 1.1491343975067139
Validation loss: 2.0381991940159954

Epoch: 138| Step: 0
Training loss: 2.402866840362549
Validation loss: 2.0209659901998376

Epoch: 6| Step: 1
Training loss: 2.0747132301330566
Validation loss: 1.9960368833234232

Epoch: 6| Step: 2
Training loss: 1.9738024473190308
Validation loss: 2.0042313273235033

Epoch: 6| Step: 3
Training loss: 1.5302953720092773
Validation loss: 1.9976862758718512

Epoch: 6| Step: 4
Training loss: 2.1882874965667725
Validation loss: 2.0146997487673195

Epoch: 6| Step: 5
Training loss: 2.0653135776519775
Validation loss: 2.0131446699942313

Epoch: 6| Step: 6
Training loss: 2.784052848815918
Validation loss: 2.009206779541508

Epoch: 6| Step: 7
Training loss: 1.7482855319976807
Validation loss: 2.016294684461368

Epoch: 6| Step: 8
Training loss: 2.4222967624664307
Validation loss: 2.0104001504118725

Epoch: 6| Step: 9
Training loss: 2.0350372791290283
Validation loss: 2.019194964439638

Epoch: 6| Step: 10
Training loss: 1.5716519355773926
Validation loss: 2.019580106581411

Epoch: 6| Step: 11
Training loss: 2.000347137451172
Validation loss: 2.017399408484018

Epoch: 6| Step: 12
Training loss: 1.4937275648117065
Validation loss: 2.052091722847313

Epoch: 6| Step: 13
Training loss: 1.8391598463058472
Validation loss: 2.077922797972156

Epoch: 139| Step: 0
Training loss: 1.6487845182418823
Validation loss: 2.1305392429392827

Epoch: 6| Step: 1
Training loss: 2.0744638442993164
Validation loss: 2.147735572630359

Epoch: 6| Step: 2
Training loss: 1.5229461193084717
Validation loss: 2.1602943135846044

Epoch: 6| Step: 3
Training loss: 1.853418231010437
Validation loss: 2.1348575340804232

Epoch: 6| Step: 4
Training loss: 2.444159507751465
Validation loss: 2.139082134410899

Epoch: 6| Step: 5
Training loss: 2.4928812980651855
Validation loss: 2.149924139822683

Epoch: 6| Step: 6
Training loss: 2.4604427814483643
Validation loss: 2.10912993133709

Epoch: 6| Step: 7
Training loss: 1.9332060813903809
Validation loss: 2.044853074576265

Epoch: 6| Step: 8
Training loss: 1.788460373878479
Validation loss: 2.032297674045768

Epoch: 6| Step: 9
Training loss: 1.948110818862915
Validation loss: 2.02136581431153

Epoch: 6| Step: 10
Training loss: 1.7405943870544434
Validation loss: 2.0242017161461616

Epoch: 6| Step: 11
Training loss: 2.0939903259277344
Validation loss: 2.0056656932318084

Epoch: 6| Step: 12
Training loss: 1.8985775709152222
Validation loss: 1.9994836366304787

Epoch: 6| Step: 13
Training loss: 2.0332465171813965
Validation loss: 1.9815360205147856

Epoch: 140| Step: 0
Training loss: 2.1811766624450684
Validation loss: 1.9989898614985968

Epoch: 6| Step: 1
Training loss: 2.3766369819641113
Validation loss: 2.012407196465359

Epoch: 6| Step: 2
Training loss: 2.0394091606140137
Validation loss: 2.012066302760955

Epoch: 6| Step: 3
Training loss: 2.1133217811584473
Validation loss: 2.013471790539321

Epoch: 6| Step: 4
Training loss: 2.260650873184204
Validation loss: 2.005468177539046

Epoch: 6| Step: 5
Training loss: 1.5543224811553955
Validation loss: 2.0018027572221655

Epoch: 6| Step: 6
Training loss: 2.052870273590088
Validation loss: 2.006547035709504

Epoch: 6| Step: 7
Training loss: 1.996703028678894
Validation loss: 2.0343774941659745

Epoch: 6| Step: 8
Training loss: 1.3012868165969849
Validation loss: 2.0787257071464293

Epoch: 6| Step: 9
Training loss: 2.1281919479370117
Validation loss: 2.0876312358405

Epoch: 6| Step: 10
Training loss: 2.068624258041382
Validation loss: 2.1008312112541607

Epoch: 6| Step: 11
Training loss: 1.7217130661010742
Validation loss: 2.10207708420292

Epoch: 6| Step: 12
Training loss: 2.1398239135742188
Validation loss: 2.089161201189923

Epoch: 6| Step: 13
Training loss: 2.184478759765625
Validation loss: 2.0674834200130996

Epoch: 141| Step: 0
Training loss: 1.839808702468872
Validation loss: 2.0607610441023305

Epoch: 6| Step: 1
Training loss: 2.181910276412964
Validation loss: 2.075402631554552

Epoch: 6| Step: 2
Training loss: 1.9871279001235962
Validation loss: 2.056467911248566

Epoch: 6| Step: 3
Training loss: 1.9036879539489746
Validation loss: 2.050788720448812

Epoch: 6| Step: 4
Training loss: 1.149202585220337
Validation loss: 2.028436706912133

Epoch: 6| Step: 5
Training loss: 2.6829609870910645
Validation loss: 2.0109670021200694

Epoch: 6| Step: 6
Training loss: 1.6107501983642578
Validation loss: 2.0137005108658985

Epoch: 6| Step: 7
Training loss: 2.1678450107574463
Validation loss: 2.025192185114789

Epoch: 6| Step: 8
Training loss: 2.0328195095062256
Validation loss: 2.0289807319641113

Epoch: 6| Step: 9
Training loss: 2.0837628841400146
Validation loss: 2.039916774278046

Epoch: 6| Step: 10
Training loss: 1.879777193069458
Validation loss: 2.081764897992534

Epoch: 6| Step: 11
Training loss: 1.6398565769195557
Validation loss: 2.0913546854449856

Epoch: 6| Step: 12
Training loss: 2.512402057647705
Validation loss: 2.095343174472932

Epoch: 6| Step: 13
Training loss: 2.2939796447753906
Validation loss: 2.0745612357252385

Epoch: 142| Step: 0
Training loss: 2.1127848625183105
Validation loss: 2.064381904499505

Epoch: 6| Step: 1
Training loss: 1.782177448272705
Validation loss: 2.0345758853420133

Epoch: 6| Step: 2
Training loss: 2.4072070121765137
Validation loss: 2.0241481552841845

Epoch: 6| Step: 3
Training loss: 1.8351409435272217
Validation loss: 2.0400655167077177

Epoch: 6| Step: 4
Training loss: 1.3223474025726318
Validation loss: 2.0509356965300856

Epoch: 6| Step: 5
Training loss: 2.145120620727539
Validation loss: 2.073637454740463

Epoch: 6| Step: 6
Training loss: 1.660074234008789
Validation loss: 2.056606343997422

Epoch: 6| Step: 7
Training loss: 2.356466770172119
Validation loss: 2.0537359483780397

Epoch: 6| Step: 8
Training loss: 1.851688027381897
Validation loss: 2.0650306452987013

Epoch: 6| Step: 9
Training loss: 2.6983988285064697
Validation loss: 2.0356690524726786

Epoch: 6| Step: 10
Training loss: 1.9805715084075928
Validation loss: 2.017480247764177

Epoch: 6| Step: 11
Training loss: 2.3695151805877686
Validation loss: 2.026000658671061

Epoch: 6| Step: 12
Training loss: 1.3844659328460693
Validation loss: 2.0312682479940434

Epoch: 6| Step: 13
Training loss: 2.170506477355957
Validation loss: 2.0398947385049637

Epoch: 143| Step: 0
Training loss: 1.8669581413269043
Validation loss: 2.05126271452955

Epoch: 6| Step: 1
Training loss: 1.6306424140930176
Validation loss: 2.05478314686847

Epoch: 6| Step: 2
Training loss: 2.3321588039398193
Validation loss: 2.085699135257352

Epoch: 6| Step: 3
Training loss: 1.1725983619689941
Validation loss: 2.100956161816915

Epoch: 6| Step: 4
Training loss: 3.0251007080078125
Validation loss: 2.099635039606402

Epoch: 6| Step: 5
Training loss: 2.091327428817749
Validation loss: 2.0686479742809007

Epoch: 6| Step: 6
Training loss: 1.6700210571289062
Validation loss: 2.0570328773990756

Epoch: 6| Step: 7
Training loss: 1.1111974716186523
Validation loss: 2.0554407181278354

Epoch: 6| Step: 8
Training loss: 2.3132882118225098
Validation loss: 2.0455908518965527

Epoch: 6| Step: 9
Training loss: 1.4465898275375366
Validation loss: 2.0472086257832025

Epoch: 6| Step: 10
Training loss: 2.4454541206359863
Validation loss: 2.0687623100896038

Epoch: 6| Step: 11
Training loss: 1.5823698043823242
Validation loss: 2.05827211564587

Epoch: 6| Step: 12
Training loss: 2.5535571575164795
Validation loss: 2.064197333910132

Epoch: 6| Step: 13
Training loss: 2.5071775913238525
Validation loss: 2.062505288790631

Epoch: 144| Step: 0
Training loss: 2.443537473678589
Validation loss: 2.075045390795636

Epoch: 6| Step: 1
Training loss: 2.1470553874969482
Validation loss: 2.0574268987101894

Epoch: 6| Step: 2
Training loss: 1.7558009624481201
Validation loss: 2.031762792218116

Epoch: 6| Step: 3
Training loss: 1.4483895301818848
Validation loss: 2.0101628841892367

Epoch: 6| Step: 4
Training loss: 1.1596195697784424
Validation loss: 1.9896342318545106

Epoch: 6| Step: 5
Training loss: 2.1544761657714844
Validation loss: 1.9788766945562055

Epoch: 6| Step: 6
Training loss: 1.8176683187484741
Validation loss: 1.9805688409395115

Epoch: 6| Step: 7
Training loss: 1.581204891204834
Validation loss: 2.005590336297148

Epoch: 6| Step: 8
Training loss: 1.7294572591781616
Validation loss: 2.010106594331803

Epoch: 6| Step: 9
Training loss: 2.7042016983032227
Validation loss: 2.0539307466117283

Epoch: 6| Step: 10
Training loss: 2.274552583694458
Validation loss: 2.069956761534496

Epoch: 6| Step: 11
Training loss: 1.7223917245864868
Validation loss: 2.1123888723311888

Epoch: 6| Step: 12
Training loss: 2.271158456802368
Validation loss: 2.0964745590763707

Epoch: 6| Step: 13
Training loss: 2.2788779735565186
Validation loss: 2.094586301875371

Epoch: 145| Step: 0
Training loss: 2.2330288887023926
Validation loss: 2.101097483788767

Epoch: 6| Step: 1
Training loss: 2.1807663440704346
Validation loss: 2.122246285920502

Epoch: 6| Step: 2
Training loss: 2.394932746887207
Validation loss: 2.152048010979929

Epoch: 6| Step: 3
Training loss: 1.9148316383361816
Validation loss: 2.1479217698497157

Epoch: 6| Step: 4
Training loss: 1.7519736289978027
Validation loss: 2.173124719691533

Epoch: 6| Step: 5
Training loss: 1.9869436025619507
Validation loss: 2.1640286368708455

Epoch: 6| Step: 6
Training loss: 1.8863638639450073
Validation loss: 2.1274515095577446

Epoch: 6| Step: 7
Training loss: 1.1122310161590576
Validation loss: 2.0898939922291744

Epoch: 6| Step: 8
Training loss: 2.6941933631896973
Validation loss: 2.065345448832358

Epoch: 6| Step: 9
Training loss: 1.2288098335266113
Validation loss: 2.056057337791689

Epoch: 6| Step: 10
Training loss: 1.5035400390625
Validation loss: 2.038467227771718

Epoch: 6| Step: 11
Training loss: 1.6810033321380615
Validation loss: 2.0358474613517843

Epoch: 6| Step: 12
Training loss: 2.0535573959350586
Validation loss: 2.035815995226624

Epoch: 6| Step: 13
Training loss: 2.6543028354644775
Validation loss: 2.010800935888803

Epoch: 146| Step: 0
Training loss: 1.4162933826446533
Validation loss: 2.0273862910527054

Epoch: 6| Step: 1
Training loss: 1.8217616081237793
Validation loss: 2.0187718945164836

Epoch: 6| Step: 2
Training loss: 2.4252090454101562
Validation loss: 2.0234822201472458

Epoch: 6| Step: 3
Training loss: 1.924243450164795
Validation loss: 2.043603076729723

Epoch: 6| Step: 4
Training loss: 2.2005863189697266
Validation loss: 2.060356834883331

Epoch: 6| Step: 5
Training loss: 1.3639914989471436
Validation loss: 2.0690391986600813

Epoch: 6| Step: 6
Training loss: 1.8655855655670166
Validation loss: 2.082579917805169

Epoch: 6| Step: 7
Training loss: 1.3862688541412354
Validation loss: 2.077735952151719

Epoch: 6| Step: 8
Training loss: 1.8084759712219238
Validation loss: 2.0617432478935487

Epoch: 6| Step: 9
Training loss: 2.7548069953918457
Validation loss: 2.0808899582073255

Epoch: 6| Step: 10
Training loss: 1.9959301948547363
Validation loss: 2.0734597021533596

Epoch: 6| Step: 11
Training loss: 1.8546087741851807
Validation loss: 2.064029485948624

Epoch: 6| Step: 12
Training loss: 1.9052993059158325
Validation loss: 2.066747739750852

Epoch: 6| Step: 13
Training loss: 1.5773375034332275
Validation loss: 2.055473719873736

Epoch: 147| Step: 0
Training loss: 2.3071000576019287
Validation loss: 2.0631356021409393

Epoch: 6| Step: 1
Training loss: 2.3996851444244385
Validation loss: 2.0795573239685385

Epoch: 6| Step: 2
Training loss: 1.596665382385254
Validation loss: 2.104343834743705

Epoch: 6| Step: 3
Training loss: 1.0418999195098877
Validation loss: 2.1267967352303128

Epoch: 6| Step: 4
Training loss: 2.3712215423583984
Validation loss: 2.140782871553975

Epoch: 6| Step: 5
Training loss: 1.8315176963806152
Validation loss: 2.1403567534621044

Epoch: 6| Step: 6
Training loss: 3.1042683124542236
Validation loss: 2.1909260865180724

Epoch: 6| Step: 7
Training loss: 1.545578956604004
Validation loss: 2.1570207483025006

Epoch: 6| Step: 8
Training loss: 1.457597255706787
Validation loss: 2.1420482999535015

Epoch: 6| Step: 9
Training loss: 1.211459755897522
Validation loss: 2.112317542875967

Epoch: 6| Step: 10
Training loss: 2.361504554748535
Validation loss: 2.0806682878924954

Epoch: 6| Step: 11
Training loss: 1.424006462097168
Validation loss: 2.048972673313592

Epoch: 6| Step: 12
Training loss: 1.7826859951019287
Validation loss: 2.0218426565970145

Epoch: 6| Step: 13
Training loss: 2.8138442039489746
Validation loss: 1.994247595469157

Epoch: 148| Step: 0
Training loss: 2.2363667488098145
Validation loss: 1.9874395760156776

Epoch: 6| Step: 1
Training loss: 1.5530765056610107
Validation loss: 1.985579349661386

Epoch: 6| Step: 2
Training loss: 2.092031478881836
Validation loss: 1.9890935933718117

Epoch: 6| Step: 3
Training loss: 1.9463326930999756
Validation loss: 1.9773835879500195

Epoch: 6| Step: 4
Training loss: 1.3502236604690552
Validation loss: 1.9580080650186027

Epoch: 6| Step: 5
Training loss: 1.8818236589431763
Validation loss: 1.9637697140375774

Epoch: 6| Step: 6
Training loss: 2.208615303039551
Validation loss: 1.9619184091526976

Epoch: 6| Step: 7
Training loss: 1.885145664215088
Validation loss: 2.017657897805655

Epoch: 6| Step: 8
Training loss: 1.4177157878875732
Validation loss: 2.063055174325102

Epoch: 6| Step: 9
Training loss: 1.7148512601852417
Validation loss: 2.07140875119035

Epoch: 6| Step: 10
Training loss: 1.4573211669921875
Validation loss: 2.0951726539160616

Epoch: 6| Step: 11
Training loss: 2.3605120182037354
Validation loss: 2.0923364264990694

Epoch: 6| Step: 12
Training loss: 2.4598073959350586
Validation loss: 2.0861596035700973

Epoch: 6| Step: 13
Training loss: 2.6588642597198486
Validation loss: 2.0789425744805285

Epoch: 149| Step: 0
Training loss: 1.2975465059280396
Validation loss: 2.093830766216401

Epoch: 6| Step: 1
Training loss: 1.6023104190826416
Validation loss: 2.095468839009603

Epoch: 6| Step: 2
Training loss: 1.918485403060913
Validation loss: 2.0888962309847594

Epoch: 6| Step: 3
Training loss: 1.1261615753173828
Validation loss: 2.0872410638358003

Epoch: 6| Step: 4
Training loss: 1.8662995100021362
Validation loss: 2.0792707935456307

Epoch: 6| Step: 5
Training loss: 2.2975640296936035
Validation loss: 2.0530185955826954

Epoch: 6| Step: 6
Training loss: 1.1789510250091553
Validation loss: 2.055229021656898

Epoch: 6| Step: 7
Training loss: 1.8607373237609863
Validation loss: 2.0533074948095504

Epoch: 6| Step: 8
Training loss: 2.568617343902588
Validation loss: 2.054288092479911

Epoch: 6| Step: 9
Training loss: 1.7291934490203857
Validation loss: 2.047476294220135

Epoch: 6| Step: 10
Training loss: 2.319136619567871
Validation loss: 2.057503378519448

Epoch: 6| Step: 11
Training loss: 2.2478840351104736
Validation loss: 2.036962975737869

Epoch: 6| Step: 12
Training loss: 1.57667076587677
Validation loss: 2.012594853678057

Epoch: 6| Step: 13
Training loss: 3.1043763160705566
Validation loss: 1.984446697337653

Epoch: 150| Step: 0
Training loss: 1.1373990774154663
Validation loss: 2.0143222796019686

Epoch: 6| Step: 1
Training loss: 2.035360336303711
Validation loss: 2.0352773589472615

Epoch: 6| Step: 2
Training loss: 1.8304941654205322
Validation loss: 2.0642475851120485

Epoch: 6| Step: 3
Training loss: 1.6828694343566895
Validation loss: 2.0858613675640476

Epoch: 6| Step: 4
Training loss: 2.2977232933044434
Validation loss: 2.087406405838587

Epoch: 6| Step: 5
Training loss: 2.116711378097534
Validation loss: 2.0778642303200177

Epoch: 6| Step: 6
Training loss: 1.7644104957580566
Validation loss: 2.0726731259335756

Epoch: 6| Step: 7
Training loss: 2.186553478240967
Validation loss: 2.0676774542818785

Epoch: 6| Step: 8
Training loss: 1.3612098693847656
Validation loss: 2.0673920441699285

Epoch: 6| Step: 9
Training loss: 1.916564702987671
Validation loss: 2.0915481441764423

Epoch: 6| Step: 10
Training loss: 1.578155517578125
Validation loss: 2.1196494820297405

Epoch: 6| Step: 11
Training loss: 2.1839497089385986
Validation loss: 2.1428677266643894

Epoch: 6| Step: 12
Training loss: 2.335768461227417
Validation loss: 2.1654579190797705

Epoch: 6| Step: 13
Training loss: 1.6278902292251587
Validation loss: 2.179649623491431

Epoch: 151| Step: 0
Training loss: 1.467206358909607
Validation loss: 2.1389339175275577

Epoch: 6| Step: 1
Training loss: 1.852719783782959
Validation loss: 2.137282161302464

Epoch: 6| Step: 2
Training loss: 1.6339702606201172
Validation loss: 2.1089675657210813

Epoch: 6| Step: 3
Training loss: 1.8586163520812988
Validation loss: 2.1079944615722983

Epoch: 6| Step: 4
Training loss: 2.3496880531311035
Validation loss: 2.1006097203941754

Epoch: 6| Step: 5
Training loss: 1.8376736640930176
Validation loss: 2.1002183242510726

Epoch: 6| Step: 6
Training loss: 2.46390962600708
Validation loss: 2.0913378910351823

Epoch: 6| Step: 7
Training loss: 2.119077682495117
Validation loss: 2.0879568489648963

Epoch: 6| Step: 8
Training loss: 1.5253424644470215
Validation loss: 2.1140281000444965

Epoch: 6| Step: 9
Training loss: 1.8488681316375732
Validation loss: 2.0958569434381302

Epoch: 6| Step: 10
Training loss: 1.541736125946045
Validation loss: 2.096808301505222

Epoch: 6| Step: 11
Training loss: 1.3970624208450317
Validation loss: 2.1024521679006596

Epoch: 6| Step: 12
Training loss: 1.6216931343078613
Validation loss: 2.0729979930385465

Epoch: 6| Step: 13
Training loss: 2.2211804389953613
Validation loss: 2.0592997663764545

Epoch: 152| Step: 0
Training loss: 1.2272100448608398
Validation loss: 2.0415618624738467

Epoch: 6| Step: 1
Training loss: 1.5529152154922485
Validation loss: 2.030184112569337

Epoch: 6| Step: 2
Training loss: 2.5887632369995117
Validation loss: 2.0785124635183685

Epoch: 6| Step: 3
Training loss: 1.8561747074127197
Validation loss: 2.0949775865001063

Epoch: 6| Step: 4
Training loss: 2.1103577613830566
Validation loss: 2.120902922845656

Epoch: 6| Step: 5
Training loss: 1.7691621780395508
Validation loss: 2.133747536648986

Epoch: 6| Step: 6
Training loss: 2.0152206420898438
Validation loss: 2.107511475522031

Epoch: 6| Step: 7
Training loss: 1.2040965557098389
Validation loss: 2.0627414334204888

Epoch: 6| Step: 8
Training loss: 1.9660910367965698
Validation loss: 2.0355057306187128

Epoch: 6| Step: 9
Training loss: 2.4478304386138916
Validation loss: 2.0216256290353756

Epoch: 6| Step: 10
Training loss: 2.2194230556488037
Validation loss: 2.0144689570191088

Epoch: 6| Step: 11
Training loss: 1.9442038536071777
Validation loss: 2.007069274943362

Epoch: 6| Step: 12
Training loss: 1.9968938827514648
Validation loss: 2.0105556031709075

Epoch: 6| Step: 13
Training loss: 2.1361634731292725
Validation loss: 2.015348898467197

Epoch: 153| Step: 0
Training loss: 1.8144643306732178
Validation loss: 2.04892869405849

Epoch: 6| Step: 1
Training loss: 1.270202875137329
Validation loss: 2.0972059798497025

Epoch: 6| Step: 2
Training loss: 1.8325474262237549
Validation loss: 2.1308622206411054

Epoch: 6| Step: 3
Training loss: 1.1790597438812256
Validation loss: 2.169421503620763

Epoch: 6| Step: 4
Training loss: 1.667153000831604
Validation loss: 2.1872895609947944

Epoch: 6| Step: 5
Training loss: 1.762244701385498
Validation loss: 2.14467595213203

Epoch: 6| Step: 6
Training loss: 2.0195722579956055
Validation loss: 2.0930784466446086

Epoch: 6| Step: 7
Training loss: 1.77472722530365
Validation loss: 2.040125810971824

Epoch: 6| Step: 8
Training loss: 1.5110869407653809
Validation loss: 2.0141492095044864

Epoch: 6| Step: 9
Training loss: 2.0762906074523926
Validation loss: 2.016142624680714

Epoch: 6| Step: 10
Training loss: 2.3180248737335205
Validation loss: 1.9925308817176408

Epoch: 6| Step: 11
Training loss: 1.8954963684082031
Validation loss: 1.9854813442435315

Epoch: 6| Step: 12
Training loss: 2.7980966567993164
Validation loss: 1.9957393933367986

Epoch: 6| Step: 13
Training loss: 2.298823356628418
Validation loss: 1.9929387351518035

Epoch: 154| Step: 0
Training loss: 1.7429084777832031
Validation loss: 1.980412225569448

Epoch: 6| Step: 1
Training loss: 1.7829382419586182
Validation loss: 1.9942240074116697

Epoch: 6| Step: 2
Training loss: 2.089568853378296
Validation loss: 1.9904010552231983

Epoch: 6| Step: 3
Training loss: 1.6302025318145752
Validation loss: 1.9912475078336653

Epoch: 6| Step: 4
Training loss: 1.931404709815979
Validation loss: 2.0186457864699827

Epoch: 6| Step: 5
Training loss: 1.427633285522461
Validation loss: 2.073903736247811

Epoch: 6| Step: 6
Training loss: 1.8834929466247559
Validation loss: 2.1070016378997476

Epoch: 6| Step: 7
Training loss: 2.0409557819366455
Validation loss: 2.1460304234617498

Epoch: 6| Step: 8
Training loss: 1.9763901233673096
Validation loss: 2.1309195923548874

Epoch: 6| Step: 9
Training loss: 1.8857709169387817
Validation loss: 2.1010149114875385

Epoch: 6| Step: 10
Training loss: 2.056077480316162
Validation loss: 2.0562196585439865

Epoch: 6| Step: 11
Training loss: 1.3649747371673584
Validation loss: 2.052730728221196

Epoch: 6| Step: 12
Training loss: 1.9559378623962402
Validation loss: 2.0539298711284513

Epoch: 6| Step: 13
Training loss: 1.9242627620697021
Validation loss: 2.0472385216784734

Epoch: 155| Step: 0
Training loss: 2.179624080657959
Validation loss: 2.049055236642079

Epoch: 6| Step: 1
Training loss: 1.9174689054489136
Validation loss: 2.066176343989629

Epoch: 6| Step: 2
Training loss: 1.4013327360153198
Validation loss: 2.07223484593053

Epoch: 6| Step: 3
Training loss: 1.5038338899612427
Validation loss: 2.056853025190292

Epoch: 6| Step: 4
Training loss: 2.0190491676330566
Validation loss: 2.0508845390812045

Epoch: 6| Step: 5
Training loss: 1.1584231853485107
Validation loss: 2.0579267663340413

Epoch: 6| Step: 6
Training loss: 1.4858542680740356
Validation loss: 2.0928048497887066

Epoch: 6| Step: 7
Training loss: 2.1168737411499023
Validation loss: 2.087218781953217

Epoch: 6| Step: 8
Training loss: 2.2132678031921387
Validation loss: 2.101623729992938

Epoch: 6| Step: 9
Training loss: 2.321491003036499
Validation loss: 2.104198141764569

Epoch: 6| Step: 10
Training loss: 1.4818031787872314
Validation loss: 2.091797303127986

Epoch: 6| Step: 11
Training loss: 1.3560478687286377
Validation loss: 2.0902865445742043

Epoch: 6| Step: 12
Training loss: 1.9309674501419067
Validation loss: 2.07067701637104

Epoch: 6| Step: 13
Training loss: 1.869871735572815
Validation loss: 2.052639353659845

Epoch: 156| Step: 0
Training loss: 1.5696609020233154
Validation loss: 2.0597754011871996

Epoch: 6| Step: 1
Training loss: 1.8480546474456787
Validation loss: 2.0506986879533335

Epoch: 6| Step: 2
Training loss: 1.4746792316436768
Validation loss: 2.0531170906559115

Epoch: 6| Step: 3
Training loss: 1.4298514127731323
Validation loss: 2.050571495486844

Epoch: 6| Step: 4
Training loss: 2.2665815353393555
Validation loss: 2.0450011940412622

Epoch: 6| Step: 5
Training loss: 2.3916399478912354
Validation loss: 2.063578518488074

Epoch: 6| Step: 6
Training loss: 2.0217485427856445
Validation loss: 2.064584965346962

Epoch: 6| Step: 7
Training loss: 1.772679090499878
Validation loss: 2.0614566431250623

Epoch: 6| Step: 8
Training loss: 2.3908486366271973
Validation loss: 2.081289679773392

Epoch: 6| Step: 9
Training loss: 1.5985796451568604
Validation loss: 2.0833580109380905

Epoch: 6| Step: 10
Training loss: 1.445852518081665
Validation loss: 2.0759187052326817

Epoch: 6| Step: 11
Training loss: 1.4918636083602905
Validation loss: 2.0747617931776148

Epoch: 6| Step: 12
Training loss: 1.5530633926391602
Validation loss: 2.0659683994067612

Epoch: 6| Step: 13
Training loss: 2.010838031768799
Validation loss: 2.0645718215614237

Epoch: 157| Step: 0
Training loss: 1.7645225524902344
Validation loss: 2.0793347127975954

Epoch: 6| Step: 1
Training loss: 2.2786219120025635
Validation loss: 2.086009943357078

Epoch: 6| Step: 2
Training loss: 1.6503831148147583
Validation loss: 2.078741095399344

Epoch: 6| Step: 3
Training loss: 2.0824756622314453
Validation loss: 2.0860404634988434

Epoch: 6| Step: 4
Training loss: 1.400604248046875
Validation loss: 2.091338265326715

Epoch: 6| Step: 5
Training loss: 1.951807975769043
Validation loss: 2.1099437718750327

Epoch: 6| Step: 6
Training loss: 1.9416484832763672
Validation loss: 2.1213844771026285

Epoch: 6| Step: 7
Training loss: 1.908454418182373
Validation loss: 2.1436911859819965

Epoch: 6| Step: 8
Training loss: 1.1650851964950562
Validation loss: 2.1468455381290887

Epoch: 6| Step: 9
Training loss: 1.5752155780792236
Validation loss: 2.125549894507213

Epoch: 6| Step: 10
Training loss: 1.5160802602767944
Validation loss: 2.0935597753012054

Epoch: 6| Step: 11
Training loss: 1.9563010931015015
Validation loss: 2.0651780213079145

Epoch: 6| Step: 12
Training loss: 1.7973641157150269
Validation loss: 2.070421306035852

Epoch: 6| Step: 13
Training loss: 1.6628823280334473
Validation loss: 2.0628016764117825

Epoch: 158| Step: 0
Training loss: 1.805122971534729
Validation loss: 2.0742722352345786

Epoch: 6| Step: 1
Training loss: 2.067025661468506
Validation loss: 2.0847634320618003

Epoch: 6| Step: 2
Training loss: 1.1494855880737305
Validation loss: 2.088657643205376

Epoch: 6| Step: 3
Training loss: 1.8676972389221191
Validation loss: 2.0870957605300413

Epoch: 6| Step: 4
Training loss: 1.6187763214111328
Validation loss: 2.06341822942098

Epoch: 6| Step: 5
Training loss: 1.8856563568115234
Validation loss: 2.0404088856071554

Epoch: 6| Step: 6
Training loss: 2.3072428703308105
Validation loss: 2.0134216354739283

Epoch: 6| Step: 7
Training loss: 2.00404953956604
Validation loss: 2.0162949613345567

Epoch: 6| Step: 8
Training loss: 1.3286194801330566
Validation loss: 2.0210924763833322

Epoch: 6| Step: 9
Training loss: 1.6683399677276611
Validation loss: 2.0484002200506066

Epoch: 6| Step: 10
Training loss: 1.4547765254974365
Validation loss: 2.0509130083104616

Epoch: 6| Step: 11
Training loss: 2.368177890777588
Validation loss: 2.065018807688067

Epoch: 6| Step: 12
Training loss: 1.7022552490234375
Validation loss: 2.045262445685684

Epoch: 6| Step: 13
Training loss: 1.6173490285873413
Validation loss: 2.0671414329159643

Epoch: 159| Step: 0
Training loss: 1.8312219381332397
Validation loss: 2.0921744967019684

Epoch: 6| Step: 1
Training loss: 1.2116012573242188
Validation loss: 2.132705805122211

Epoch: 6| Step: 2
Training loss: 2.417445659637451
Validation loss: 2.1702205622068016

Epoch: 6| Step: 3
Training loss: 2.185434341430664
Validation loss: 2.17603366092969

Epoch: 6| Step: 4
Training loss: 1.5821419954299927
Validation loss: 2.1727134386698403

Epoch: 6| Step: 5
Training loss: 1.7105236053466797
Validation loss: 2.185370878506732

Epoch: 6| Step: 6
Training loss: 1.6288162469863892
Validation loss: 2.178516364866687

Epoch: 6| Step: 7
Training loss: 1.5227192640304565
Validation loss: 2.149951737414124

Epoch: 6| Step: 8
Training loss: 1.559783935546875
Validation loss: 2.1254200320090018

Epoch: 6| Step: 9
Training loss: 1.790763020515442
Validation loss: 2.0891180756271526

Epoch: 6| Step: 10
Training loss: 1.9883935451507568
Validation loss: 2.0544470125629055

Epoch: 6| Step: 11
Training loss: 1.727452278137207
Validation loss: 2.0342546432249007

Epoch: 6| Step: 12
Training loss: 1.9105923175811768
Validation loss: 2.020127825839545

Epoch: 6| Step: 13
Training loss: 1.2888859510421753
Validation loss: 1.986124256605743

Epoch: 160| Step: 0
Training loss: 1.7717068195343018
Validation loss: 1.988830615115422

Epoch: 6| Step: 1
Training loss: 1.5521571636199951
Validation loss: 1.9810553917320826

Epoch: 6| Step: 2
Training loss: 1.7675364017486572
Validation loss: 1.971831508862075

Epoch: 6| Step: 3
Training loss: 0.9500197768211365
Validation loss: 1.989458776289417

Epoch: 6| Step: 4
Training loss: 2.1229605674743652
Validation loss: 2.0247120959784395

Epoch: 6| Step: 5
Training loss: 1.8806291818618774
Validation loss: 2.048638279720019

Epoch: 6| Step: 6
Training loss: 1.527524471282959
Validation loss: 2.1267217410508024

Epoch: 6| Step: 7
Training loss: 1.9915482997894287
Validation loss: 2.1544001435720794

Epoch: 6| Step: 8
Training loss: 1.6149859428405762
Validation loss: 2.157363127636653

Epoch: 6| Step: 9
Training loss: 2.175449848175049
Validation loss: 2.116312889642613

Epoch: 6| Step: 10
Training loss: 2.0679855346679688
Validation loss: 2.10539081276104

Epoch: 6| Step: 11
Training loss: 2.4494194984436035
Validation loss: 2.0885122411994526

Epoch: 6| Step: 12
Training loss: 1.3305892944335938
Validation loss: 2.059245140321793

Epoch: 6| Step: 13
Training loss: 1.3974528312683105
Validation loss: 2.0491934796815277

Epoch: 161| Step: 0
Training loss: 1.953783631324768
Validation loss: 2.0462778627231555

Epoch: 6| Step: 1
Training loss: 1.9127118587493896
Validation loss: 2.0594482037328903

Epoch: 6| Step: 2
Training loss: 1.3597464561462402
Validation loss: 2.05711095563827

Epoch: 6| Step: 3
Training loss: 1.4796404838562012
Validation loss: 2.078777608051095

Epoch: 6| Step: 4
Training loss: 1.674196720123291
Validation loss: 2.1305307060159664

Epoch: 6| Step: 5
Training loss: 2.160672187805176
Validation loss: 2.170844942010859

Epoch: 6| Step: 6
Training loss: 2.169485569000244
Validation loss: 2.196037018170921

Epoch: 6| Step: 7
Training loss: 1.8137834072113037
Validation loss: 2.1770576789814937

Epoch: 6| Step: 8
Training loss: 1.7974491119384766
Validation loss: 2.137605256931756

Epoch: 6| Step: 9
Training loss: 1.494530200958252
Validation loss: 2.058902430277999

Epoch: 6| Step: 10
Training loss: 1.5346583127975464
Validation loss: 2.0338337729054112

Epoch: 6| Step: 11
Training loss: 1.6551189422607422
Validation loss: 2.0343663256655455

Epoch: 6| Step: 12
Training loss: 1.9027836322784424
Validation loss: 2.05730777658442

Epoch: 6| Step: 13
Training loss: 1.0877388715744019
Validation loss: 2.07655212443362

Epoch: 162| Step: 0
Training loss: 2.00168514251709
Validation loss: 2.0617009503867036

Epoch: 6| Step: 1
Training loss: 1.9481961727142334
Validation loss: 2.0724753064493977

Epoch: 6| Step: 2
Training loss: 2.0219838619232178
Validation loss: 2.0283406011519896

Epoch: 6| Step: 3
Training loss: 1.2786970138549805
Validation loss: 2.043627292879166

Epoch: 6| Step: 4
Training loss: 1.5347621440887451
Validation loss: 2.0775119758421376

Epoch: 6| Step: 5
Training loss: 2.5427510738372803
Validation loss: 2.1136962829097623

Epoch: 6| Step: 6
Training loss: 1.5055497884750366
Validation loss: 2.127071670306626

Epoch: 6| Step: 7
Training loss: 1.694756269454956
Validation loss: 2.16371290786292

Epoch: 6| Step: 8
Training loss: 1.4213510751724243
Validation loss: 2.1457575623707106

Epoch: 6| Step: 9
Training loss: 1.7254810333251953
Validation loss: 2.1099839415601505

Epoch: 6| Step: 10
Training loss: 1.8433033227920532
Validation loss: 2.097624627492761

Epoch: 6| Step: 11
Training loss: 1.7664551734924316
Validation loss: 2.068930169587494

Epoch: 6| Step: 12
Training loss: 1.3148882389068604
Validation loss: 2.032326748294215

Epoch: 6| Step: 13
Training loss: 1.3615127801895142
Validation loss: 2.0397164706260926

Epoch: 163| Step: 0
Training loss: 1.3949908018112183
Validation loss: 2.0467146929874214

Epoch: 6| Step: 1
Training loss: 1.5299315452575684
Validation loss: 2.0759741926705964

Epoch: 6| Step: 2
Training loss: 1.891282320022583
Validation loss: 2.0898246278044996

Epoch: 6| Step: 3
Training loss: 1.8746486902236938
Validation loss: 2.1080003066729476

Epoch: 6| Step: 4
Training loss: 1.4846735000610352
Validation loss: 2.0981096503555134

Epoch: 6| Step: 5
Training loss: 1.1764719486236572
Validation loss: 2.095475514729818

Epoch: 6| Step: 6
Training loss: 2.720691680908203
Validation loss: 2.0980169798738215

Epoch: 6| Step: 7
Training loss: 1.668434739112854
Validation loss: 2.0876991684718798

Epoch: 6| Step: 8
Training loss: 1.8874940872192383
Validation loss: 2.092753928194764

Epoch: 6| Step: 9
Training loss: 1.1582860946655273
Validation loss: 2.0705814130844606

Epoch: 6| Step: 10
Training loss: 1.2781164646148682
Validation loss: 2.0806238036001883

Epoch: 6| Step: 11
Training loss: 1.5645582675933838
Validation loss: 2.061464959575284

Epoch: 6| Step: 12
Training loss: 1.8079360723495483
Validation loss: 2.0699603249949794

Epoch: 6| Step: 13
Training loss: 2.1161386966705322
Validation loss: 2.073808841807868

Epoch: 164| Step: 0
Training loss: 1.1786653995513916
Validation loss: 2.0755859331418107

Epoch: 6| Step: 1
Training loss: 2.0373942852020264
Validation loss: 2.0896799231088288

Epoch: 6| Step: 2
Training loss: 1.709977388381958
Validation loss: 2.1146785469465357

Epoch: 6| Step: 3
Training loss: 2.3897595405578613
Validation loss: 2.1270756798405803

Epoch: 6| Step: 4
Training loss: 1.258385181427002
Validation loss: 2.1614518037406345

Epoch: 6| Step: 5
Training loss: 0.7266727089881897
Validation loss: 2.2428428947284655

Epoch: 6| Step: 6
Training loss: 1.9050381183624268
Validation loss: 2.2955840300488215

Epoch: 6| Step: 7
Training loss: 2.084749698638916
Validation loss: 2.2446870752560195

Epoch: 6| Step: 8
Training loss: 1.8655930757522583
Validation loss: 2.167637507120768

Epoch: 6| Step: 9
Training loss: 1.5289874076843262
Validation loss: 2.1037835075009252

Epoch: 6| Step: 10
Training loss: 2.1698520183563232
Validation loss: 2.0634606346007316

Epoch: 6| Step: 11
Training loss: 1.8092200756072998
Validation loss: 2.023481781764697

Epoch: 6| Step: 12
Training loss: 1.3551483154296875
Validation loss: 2.003715689464282

Epoch: 6| Step: 13
Training loss: 1.5262131690979004
Validation loss: 2.0033607406000935

Epoch: 165| Step: 0
Training loss: 2.207286834716797
Validation loss: 2.0057507599553754

Epoch: 6| Step: 1
Training loss: 1.7594503164291382
Validation loss: 1.996877908706665

Epoch: 6| Step: 2
Training loss: 1.8959026336669922
Validation loss: 2.00802029332807

Epoch: 6| Step: 3
Training loss: 1.8480815887451172
Validation loss: 2.040001089854907

Epoch: 6| Step: 4
Training loss: 1.528763771057129
Validation loss: 2.022937692621703

Epoch: 6| Step: 5
Training loss: 1.6546050310134888
Validation loss: 2.023005147134104

Epoch: 6| Step: 6
Training loss: 1.5654881000518799
Validation loss: 2.059038277595274

Epoch: 6| Step: 7
Training loss: 1.3872941732406616
Validation loss: 2.0921056885873117

Epoch: 6| Step: 8
Training loss: 1.8009101152420044
Validation loss: 2.126247677751767

Epoch: 6| Step: 9
Training loss: 1.1969406604766846
Validation loss: 2.145481924856863

Epoch: 6| Step: 10
Training loss: 1.9941319227218628
Validation loss: 2.186538114342638

Epoch: 6| Step: 11
Training loss: 1.6832618713378906
Validation loss: 2.1399752222081667

Epoch: 6| Step: 12
Training loss: 1.8089755773544312
Validation loss: 2.1286702976431897

Epoch: 6| Step: 13
Training loss: 1.3932280540466309
Validation loss: 2.086913137025731

Epoch: 166| Step: 0
Training loss: 1.453843355178833
Validation loss: 2.0425934278836815

Epoch: 6| Step: 1
Training loss: 1.5057686567306519
Validation loss: 2.028064766237813

Epoch: 6| Step: 2
Training loss: 2.1757614612579346
Validation loss: 2.0279851805779243

Epoch: 6| Step: 3
Training loss: 1.8303722143173218
Validation loss: 2.0434578234149563

Epoch: 6| Step: 4
Training loss: 1.650528907775879
Validation loss: 2.0675655244499125

Epoch: 6| Step: 5
Training loss: 1.7349306344985962
Validation loss: 2.0548897609915784

Epoch: 6| Step: 6
Training loss: 1.1359643936157227
Validation loss: 2.06466144259258

Epoch: 6| Step: 7
Training loss: 2.07315993309021
Validation loss: 2.03725351056745

Epoch: 6| Step: 8
Training loss: 2.1285510063171387
Validation loss: 2.059546234146241

Epoch: 6| Step: 9
Training loss: 1.4638397693634033
Validation loss: 2.0707417482970865

Epoch: 6| Step: 10
Training loss: 1.0811058282852173
Validation loss: 2.0874795016422065

Epoch: 6| Step: 11
Training loss: 1.7155301570892334
Validation loss: 2.0813564126209547

Epoch: 6| Step: 12
Training loss: 1.333917260169983
Validation loss: 2.0740696948061705

Epoch: 6| Step: 13
Training loss: 2.1338212490081787
Validation loss: 2.0633010838621404

Epoch: 167| Step: 0
Training loss: 1.5492335557937622
Validation loss: 2.062900279157905

Epoch: 6| Step: 1
Training loss: 1.3771440982818604
Validation loss: 2.0685346241920226

Epoch: 6| Step: 2
Training loss: 1.3458404541015625
Validation loss: 2.032083570316274

Epoch: 6| Step: 3
Training loss: 2.0835492610931396
Validation loss: 2.0475746226567093

Epoch: 6| Step: 4
Training loss: 1.6175563335418701
Validation loss: 2.0552629117042787

Epoch: 6| Step: 5
Training loss: 1.7324141263961792
Validation loss: 2.0513960648608465

Epoch: 6| Step: 6
Training loss: 2.142177104949951
Validation loss: 2.0837191176670853

Epoch: 6| Step: 7
Training loss: 1.2495571374893188
Validation loss: 2.1089160467988703

Epoch: 6| Step: 8
Training loss: 1.4255788326263428
Validation loss: 2.1885121971048336

Epoch: 6| Step: 9
Training loss: 2.116213798522949
Validation loss: 2.212661850836969

Epoch: 6| Step: 10
Training loss: 1.4683120250701904
Validation loss: 2.1906381960838073

Epoch: 6| Step: 11
Training loss: 1.9303996562957764
Validation loss: 2.157986387129753

Epoch: 6| Step: 12
Training loss: 1.1402602195739746
Validation loss: 2.10574778433769

Epoch: 6| Step: 13
Training loss: 2.0160577297210693
Validation loss: 2.085828686273226

Epoch: 168| Step: 0
Training loss: 2.1187546253204346
Validation loss: 2.0368454699875205

Epoch: 6| Step: 1
Training loss: 1.2566500902175903
Validation loss: 2.0208558920891053

Epoch: 6| Step: 2
Training loss: 1.6271302700042725
Validation loss: 2.0125392739490797

Epoch: 6| Step: 3
Training loss: 1.8029266595840454
Validation loss: 1.9976587244259414

Epoch: 6| Step: 4
Training loss: 1.7095710039138794
Validation loss: 1.9919832265505226

Epoch: 6| Step: 5
Training loss: 2.4768826961517334
Validation loss: 1.973756226160193

Epoch: 6| Step: 6
Training loss: 1.8501195907592773
Validation loss: 1.9999866767596173

Epoch: 6| Step: 7
Training loss: 1.4336589574813843
Validation loss: 2.012537613991768

Epoch: 6| Step: 8
Training loss: 1.0543828010559082
Validation loss: 2.0332777884698685

Epoch: 6| Step: 9
Training loss: 1.3585034608840942
Validation loss: 2.0562115689759612

Epoch: 6| Step: 10
Training loss: 1.5595206022262573
Validation loss: 2.077051717747924

Epoch: 6| Step: 11
Training loss: 1.910701036453247
Validation loss: 2.1175296101518857

Epoch: 6| Step: 12
Training loss: 1.5048426389694214
Validation loss: 2.145166382994703

Epoch: 6| Step: 13
Training loss: 1.501420021057129
Validation loss: 2.1423012825750534

Epoch: 169| Step: 0
Training loss: 1.3173537254333496
Validation loss: 2.143051109006328

Epoch: 6| Step: 1
Training loss: 1.6211392879486084
Validation loss: 2.1243583104943715

Epoch: 6| Step: 2
Training loss: 1.5288052558898926
Validation loss: 2.0777000688737437

Epoch: 6| Step: 3
Training loss: 1.6618869304656982
Validation loss: 2.042846895033313

Epoch: 6| Step: 4
Training loss: 1.5398728847503662
Validation loss: 2.0348446984444895

Epoch: 6| Step: 5
Training loss: 1.4225490093231201
Validation loss: 2.0513945920493013

Epoch: 6| Step: 6
Training loss: 0.974516749382019
Validation loss: 2.0568670790682555

Epoch: 6| Step: 7
Training loss: 1.4417765140533447
Validation loss: 2.0940903156034407

Epoch: 6| Step: 8
Training loss: 1.3985247611999512
Validation loss: 2.1085430127318188

Epoch: 6| Step: 9
Training loss: 1.940256953239441
Validation loss: 2.1234929869251866

Epoch: 6| Step: 10
Training loss: 1.9816725254058838
Validation loss: 2.1201586031144664

Epoch: 6| Step: 11
Training loss: 2.1481733322143555
Validation loss: 2.1068449276749805

Epoch: 6| Step: 12
Training loss: 1.825923204421997
Validation loss: 2.1019322141524284

Epoch: 6| Step: 13
Training loss: 1.7487452030181885
Validation loss: 2.095961618167098

Epoch: 170| Step: 0
Training loss: 1.2994041442871094
Validation loss: 2.0739699320126603

Epoch: 6| Step: 1
Training loss: 1.788730263710022
Validation loss: 2.0774704461456626

Epoch: 6| Step: 2
Training loss: 1.475832462310791
Validation loss: 2.096293423765449

Epoch: 6| Step: 3
Training loss: 2.2678608894348145
Validation loss: 2.078157509526899

Epoch: 6| Step: 4
Training loss: 1.3217365741729736
Validation loss: 2.0592797353703487

Epoch: 6| Step: 5
Training loss: 2.073045015335083
Validation loss: 2.0534214858085877

Epoch: 6| Step: 6
Training loss: 1.2671126127243042
Validation loss: 2.028583134374311

Epoch: 6| Step: 7
Training loss: 1.6340928077697754
Validation loss: 2.007493670268725

Epoch: 6| Step: 8
Training loss: 1.6194496154785156
Validation loss: 2.0356530707369567

Epoch: 6| Step: 9
Training loss: 0.9512821435928345
Validation loss: 2.0429859610014063

Epoch: 6| Step: 10
Training loss: 2.4154698848724365
Validation loss: 2.0607636179975284

Epoch: 6| Step: 11
Training loss: 1.5804812908172607
Validation loss: 2.061528087944113

Epoch: 6| Step: 12
Training loss: 2.0061864852905273
Validation loss: 2.0578832754524807

Epoch: 6| Step: 13
Training loss: 0.3681388795375824
Validation loss: 2.059959741048915

Epoch: 171| Step: 0
Training loss: 1.3982422351837158
Validation loss: 2.0548584409939346

Epoch: 6| Step: 1
Training loss: 1.915535569190979
Validation loss: 2.0627145241665583

Epoch: 6| Step: 2
Training loss: 1.394181489944458
Validation loss: 2.073305647860291

Epoch: 6| Step: 3
Training loss: 1.4378458261489868
Validation loss: 2.0767061748812274

Epoch: 6| Step: 4
Training loss: 1.3749845027923584
Validation loss: 2.1105382032291864

Epoch: 6| Step: 5
Training loss: 1.7596933841705322
Validation loss: 2.126795338046166

Epoch: 6| Step: 6
Training loss: 2.129628896713257
Validation loss: 2.0968563172125045

Epoch: 6| Step: 7
Training loss: 0.9425778388977051
Validation loss: 2.125625718024469

Epoch: 6| Step: 8
Training loss: 1.8470872640609741
Validation loss: 2.1301685584488737

Epoch: 6| Step: 9
Training loss: 0.8599414825439453
Validation loss: 2.155260673133276

Epoch: 6| Step: 10
Training loss: 1.5958606004714966
Validation loss: 2.1579688454187043

Epoch: 6| Step: 11
Training loss: 2.106855869293213
Validation loss: 2.100535194079081

Epoch: 6| Step: 12
Training loss: 1.9401429891586304
Validation loss: 2.052148075513942

Epoch: 6| Step: 13
Training loss: 1.1761332750320435
Validation loss: 2.0435318639201503

Epoch: 172| Step: 0
Training loss: 1.8473193645477295
Validation loss: 2.0113556705495363

Epoch: 6| Step: 1
Training loss: 1.7145904302597046
Validation loss: 1.9837692053087297

Epoch: 6| Step: 2
Training loss: 1.3773596286773682
Validation loss: 1.950205615771714

Epoch: 6| Step: 3
Training loss: 1.9385788440704346
Validation loss: 1.9633904862147507

Epoch: 6| Step: 4
Training loss: 1.3185477256774902
Validation loss: 1.9881917943236649

Epoch: 6| Step: 5
Training loss: 1.2853882312774658
Validation loss: 2.007265429342947

Epoch: 6| Step: 6
Training loss: 0.8038204312324524
Validation loss: 2.0124532125329457

Epoch: 6| Step: 7
Training loss: 1.7751550674438477
Validation loss: 2.0156634469186105

Epoch: 6| Step: 8
Training loss: 1.6331958770751953
Validation loss: 2.0457159524322837

Epoch: 6| Step: 9
Training loss: 1.5734004974365234
Validation loss: 2.0504023169958465

Epoch: 6| Step: 10
Training loss: 1.6529431343078613
Validation loss: 2.0917266645739154

Epoch: 6| Step: 11
Training loss: 1.7126950025558472
Validation loss: 2.1270255696388984

Epoch: 6| Step: 12
Training loss: 1.560138463973999
Validation loss: 2.1497625984171385

Epoch: 6| Step: 13
Training loss: 2.301870822906494
Validation loss: 2.1102863537367953

Epoch: 173| Step: 0
Training loss: 1.438533067703247
Validation loss: 2.0523634674728557

Epoch: 6| Step: 1
Training loss: 1.7030857801437378
Validation loss: 1.9933360468956731

Epoch: 6| Step: 2
Training loss: 1.9520419836044312
Validation loss: 1.9653829323348178

Epoch: 6| Step: 3
Training loss: 1.1906638145446777
Validation loss: 1.9780684440366683

Epoch: 6| Step: 4
Training loss: 1.0150425434112549
Validation loss: 1.9766689910683581

Epoch: 6| Step: 5
Training loss: 1.8422186374664307
Validation loss: 2.0062530271468626

Epoch: 6| Step: 6
Training loss: 2.0358641147613525
Validation loss: 2.0301079134787283

Epoch: 6| Step: 7
Training loss: 1.770158052444458
Validation loss: 2.06421475256643

Epoch: 6| Step: 8
Training loss: 2.274386405944824
Validation loss: 2.0746591039883193

Epoch: 6| Step: 9
Training loss: 1.62196683883667
Validation loss: 2.0692809474083687

Epoch: 6| Step: 10
Training loss: 1.3551084995269775
Validation loss: 2.1117069746858332

Epoch: 6| Step: 11
Training loss: 1.0702602863311768
Validation loss: 2.1198002830628426

Epoch: 6| Step: 12
Training loss: 1.570373296737671
Validation loss: 2.1593455294127106

Epoch: 6| Step: 13
Training loss: 1.5215389728546143
Validation loss: 2.1427122956962994

Epoch: 174| Step: 0
Training loss: 1.867629885673523
Validation loss: 2.0920078780061457

Epoch: 6| Step: 1
Training loss: 1.5760154724121094
Validation loss: 2.071297149504385

Epoch: 6| Step: 2
Training loss: 1.8858580589294434
Validation loss: 2.0464157494165565

Epoch: 6| Step: 3
Training loss: 1.0009430646896362
Validation loss: 2.035861735702843

Epoch: 6| Step: 4
Training loss: 1.4439096450805664
Validation loss: 1.9994708043272778

Epoch: 6| Step: 5
Training loss: 1.7353174686431885
Validation loss: 1.9834345489419916

Epoch: 6| Step: 6
Training loss: 1.0473384857177734
Validation loss: 1.9823302838110155

Epoch: 6| Step: 7
Training loss: 1.3877904415130615
Validation loss: 1.9959620352714293

Epoch: 6| Step: 8
Training loss: 1.2303067445755005
Validation loss: 1.9934438825935445

Epoch: 6| Step: 9
Training loss: 1.8317735195159912
Validation loss: 2.018383697796893

Epoch: 6| Step: 10
Training loss: 1.9340975284576416
Validation loss: 2.0240540299364316

Epoch: 6| Step: 11
Training loss: 1.7843921184539795
Validation loss: 2.044914132805281

Epoch: 6| Step: 12
Training loss: 1.299358606338501
Validation loss: 2.0680925846099854

Epoch: 6| Step: 13
Training loss: 1.368773102760315
Validation loss: 2.1052712368708786

Epoch: 175| Step: 0
Training loss: 1.5613728761672974
Validation loss: 2.1023486404008764

Epoch: 6| Step: 1
Training loss: 1.3679890632629395
Validation loss: 2.108672317638192

Epoch: 6| Step: 2
Training loss: 1.6104953289031982
Validation loss: 2.116404820513982

Epoch: 6| Step: 3
Training loss: 0.9731118679046631
Validation loss: 2.124682549507387

Epoch: 6| Step: 4
Training loss: 1.8283381462097168
Validation loss: 2.1042114893595376

Epoch: 6| Step: 5
Training loss: 1.5837950706481934
Validation loss: 2.1062423208708405

Epoch: 6| Step: 6
Training loss: 2.016399383544922
Validation loss: 2.0899576140988256

Epoch: 6| Step: 7
Training loss: 1.1015613079071045
Validation loss: 2.0210036346989293

Epoch: 6| Step: 8
Training loss: 1.2609212398529053
Validation loss: 2.0264011570202407

Epoch: 6| Step: 9
Training loss: 1.61687171459198
Validation loss: 2.0039814056888705

Epoch: 6| Step: 10
Training loss: 1.3638696670532227
Validation loss: 2.069770941170313

Epoch: 6| Step: 11
Training loss: 1.8682037591934204
Validation loss: 2.101249066732263

Epoch: 6| Step: 12
Training loss: 1.5824726819992065
Validation loss: 2.1500703493754068

Epoch: 6| Step: 13
Training loss: 1.53441321849823
Validation loss: 2.2004664508245324

Epoch: 176| Step: 0
Training loss: 1.4700212478637695
Validation loss: 2.1918471654256186

Epoch: 6| Step: 1
Training loss: 0.8006358742713928
Validation loss: 2.1652040122657694

Epoch: 6| Step: 2
Training loss: 1.191035509109497
Validation loss: 2.1669932667927077

Epoch: 6| Step: 3
Training loss: 1.7357574701309204
Validation loss: 2.120944869133734

Epoch: 6| Step: 4
Training loss: 1.5647493600845337
Validation loss: 2.1105274974658923

Epoch: 6| Step: 5
Training loss: 1.402766227722168
Validation loss: 2.0910930274635233

Epoch: 6| Step: 6
Training loss: 1.7755966186523438
Validation loss: 2.101982487145291

Epoch: 6| Step: 7
Training loss: 1.8633842468261719
Validation loss: 2.0628263565801803

Epoch: 6| Step: 8
Training loss: 1.1673052310943604
Validation loss: 2.05366563412451

Epoch: 6| Step: 9
Training loss: 1.9790985584259033
Validation loss: 2.0181553466345674

Epoch: 6| Step: 10
Training loss: 1.3210783004760742
Validation loss: 2.0150510136799147

Epoch: 6| Step: 11
Training loss: 1.855865240097046
Validation loss: 2.0141074401076122

Epoch: 6| Step: 12
Training loss: 1.262033224105835
Validation loss: 2.018811155390996

Epoch: 6| Step: 13
Training loss: 1.6842195987701416
Validation loss: 2.019313963510657

Epoch: 177| Step: 0
Training loss: 1.4027273654937744
Validation loss: 2.0293730676815076

Epoch: 6| Step: 1
Training loss: 1.4181272983551025
Validation loss: 2.0304010401489916

Epoch: 6| Step: 2
Training loss: 0.599704921245575
Validation loss: 2.0693529139282885

Epoch: 6| Step: 3
Training loss: 1.8467656373977661
Validation loss: 2.077470992201118

Epoch: 6| Step: 4
Training loss: 1.48277747631073
Validation loss: 2.092467082444058

Epoch: 6| Step: 5
Training loss: 1.520547866821289
Validation loss: 2.104941051493409

Epoch: 6| Step: 6
Training loss: 1.312195897102356
Validation loss: 2.0873899408566055

Epoch: 6| Step: 7
Training loss: 1.779735803604126
Validation loss: 2.060536038491034

Epoch: 6| Step: 8
Training loss: 1.0986073017120361
Validation loss: 2.0375451221260974

Epoch: 6| Step: 9
Training loss: 2.0950934886932373
Validation loss: 2.0126218180502615

Epoch: 6| Step: 10
Training loss: 1.4213213920593262
Validation loss: 1.9900366388341433

Epoch: 6| Step: 11
Training loss: 1.6210485696792603
Validation loss: 1.9612894429955432

Epoch: 6| Step: 12
Training loss: 2.324512481689453
Validation loss: 1.9697992904211885

Epoch: 6| Step: 13
Training loss: 0.5322346687316895
Validation loss: 1.9721775875296643

Epoch: 178| Step: 0
Training loss: 1.9931520223617554
Validation loss: 2.021177726407205

Epoch: 6| Step: 1
Training loss: 1.2346973419189453
Validation loss: 2.024121126820964

Epoch: 6| Step: 2
Training loss: 1.0116277933120728
Validation loss: 2.0670727401651363

Epoch: 6| Step: 3
Training loss: 0.9981110692024231
Validation loss: 2.037510592450378

Epoch: 6| Step: 4
Training loss: 1.7204878330230713
Validation loss: 2.0345324341968825

Epoch: 6| Step: 5
Training loss: 1.0885341167449951
Validation loss: 2.003712997641615

Epoch: 6| Step: 6
Training loss: 1.7625623941421509
Validation loss: 2.018631694137409

Epoch: 6| Step: 7
Training loss: 1.6893424987792969
Validation loss: 2.0298457709691857

Epoch: 6| Step: 8
Training loss: 1.3014788627624512
Validation loss: 2.016693356216595

Epoch: 6| Step: 9
Training loss: 1.515932559967041
Validation loss: 2.015988242241644

Epoch: 6| Step: 10
Training loss: 1.5332099199295044
Validation loss: 2.0223782600895053

Epoch: 6| Step: 11
Training loss: 1.637323260307312
Validation loss: 2.0030849467041674

Epoch: 6| Step: 12
Training loss: 1.57685387134552
Validation loss: 2.0224045758606284

Epoch: 6| Step: 13
Training loss: 1.7284597158432007
Validation loss: 2.0354345857456164

Epoch: 179| Step: 0
Training loss: 1.6203304529190063
Validation loss: 2.0390698896941317

Epoch: 6| Step: 1
Training loss: 1.1431238651275635
Validation loss: 2.0548356527923257

Epoch: 6| Step: 2
Training loss: 1.3993943929672241
Validation loss: 2.062612691233235

Epoch: 6| Step: 3
Training loss: 0.6551852822303772
Validation loss: 2.0611073419611943

Epoch: 6| Step: 4
Training loss: 1.559154748916626
Validation loss: 2.0573437252352313

Epoch: 6| Step: 5
Training loss: 1.7929344177246094
Validation loss: 2.0709891703821

Epoch: 6| Step: 6
Training loss: 1.2893482446670532
Validation loss: 2.07845260507317

Epoch: 6| Step: 7
Training loss: 1.2616734504699707
Validation loss: 2.087449473719443

Epoch: 6| Step: 8
Training loss: 1.9763731956481934
Validation loss: 2.0965703148995676

Epoch: 6| Step: 9
Training loss: 1.4322670698165894
Validation loss: 2.0993657189030803

Epoch: 6| Step: 10
Training loss: 1.7589235305786133
Validation loss: 2.0997599760691323

Epoch: 6| Step: 11
Training loss: 1.1041065454483032
Validation loss: 2.1186892294114634

Epoch: 6| Step: 12
Training loss: 1.6654915809631348
Validation loss: 2.1165453054571666

Epoch: 6| Step: 13
Training loss: 1.2620868682861328
Validation loss: 2.0965734169047368

Epoch: 180| Step: 0
Training loss: 1.5836265087127686
Validation loss: 2.049656706471597

Epoch: 6| Step: 1
Training loss: 1.3947789669036865
Validation loss: 2.0544065788228023

Epoch: 6| Step: 2
Training loss: 1.549769401550293
Validation loss: 2.057169960391137

Epoch: 6| Step: 3
Training loss: 1.3999723196029663
Validation loss: 2.070283992316133

Epoch: 6| Step: 4
Training loss: 1.2499645948410034
Validation loss: 2.037472862069325

Epoch: 6| Step: 5
Training loss: 1.41318941116333
Validation loss: 2.0600589603506108

Epoch: 6| Step: 6
Training loss: 1.029489278793335
Validation loss: 2.0754860549844723

Epoch: 6| Step: 7
Training loss: 1.5813534259796143
Validation loss: 2.096331919393232

Epoch: 6| Step: 8
Training loss: 1.1707546710968018
Validation loss: 2.1094317974582797

Epoch: 6| Step: 9
Training loss: 1.7177029848098755
Validation loss: 2.136982717821675

Epoch: 6| Step: 10
Training loss: 1.4125933647155762
Validation loss: 2.106804750298941

Epoch: 6| Step: 11
Training loss: 1.4211772680282593
Validation loss: 2.097007901437821

Epoch: 6| Step: 12
Training loss: 1.4206206798553467
Validation loss: 2.0689658708469842

Epoch: 6| Step: 13
Training loss: 1.5620489120483398
Validation loss: 2.0365407851434525

Epoch: 181| Step: 0
Training loss: 1.3837106227874756
Validation loss: 1.9902388600892917

Epoch: 6| Step: 1
Training loss: 1.8000297546386719
Validation loss: 1.9776490298650597

Epoch: 6| Step: 2
Training loss: 2.1341466903686523
Validation loss: 1.9654415012687765

Epoch: 6| Step: 3
Training loss: 1.4784369468688965
Validation loss: 1.97727430764065

Epoch: 6| Step: 4
Training loss: 1.646416425704956
Validation loss: 1.9648994386837046

Epoch: 6| Step: 5
Training loss: 1.0527758598327637
Validation loss: 1.980088641566615

Epoch: 6| Step: 6
Training loss: 1.0318493843078613
Validation loss: 1.965351527737033

Epoch: 6| Step: 7
Training loss: 1.291175127029419
Validation loss: 2.014068426624421

Epoch: 6| Step: 8
Training loss: 0.6384025812149048
Validation loss: 2.0207019454689434

Epoch: 6| Step: 9
Training loss: 1.2715861797332764
Validation loss: 2.019640827691683

Epoch: 6| Step: 10
Training loss: 1.146111011505127
Validation loss: 1.9961427565543883

Epoch: 6| Step: 11
Training loss: 1.5196356773376465
Validation loss: 2.004533753600172

Epoch: 6| Step: 12
Training loss: 1.4908174276351929
Validation loss: 2.0090438230063326

Epoch: 6| Step: 13
Training loss: 1.895882487297058
Validation loss: 2.0341666308782433

Epoch: 182| Step: 0
Training loss: 0.8577594757080078
Validation loss: 2.0439803138855965

Epoch: 6| Step: 1
Training loss: 0.7520183324813843
Validation loss: 2.0042677835751603

Epoch: 6| Step: 2
Training loss: 1.9890131950378418
Validation loss: 2.0151631678304365

Epoch: 6| Step: 3
Training loss: 1.56914222240448
Validation loss: 2.008454268978488

Epoch: 6| Step: 4
Training loss: 1.4926187992095947
Validation loss: 2.023961877310148

Epoch: 6| Step: 5
Training loss: 0.8577640652656555
Validation loss: 2.013793735093968

Epoch: 6| Step: 6
Training loss: 1.9039368629455566
Validation loss: 2.0407252106615292

Epoch: 6| Step: 7
Training loss: 1.7834811210632324
Validation loss: 2.0462656508209887

Epoch: 6| Step: 8
Training loss: 1.5022430419921875
Validation loss: 2.0476881663004556

Epoch: 6| Step: 9
Training loss: 1.387341856956482
Validation loss: 2.032848793973205

Epoch: 6| Step: 10
Training loss: 1.1335994005203247
Validation loss: 2.0522645801626225

Epoch: 6| Step: 11
Training loss: 1.5442171096801758
Validation loss: 2.0168369905923003

Epoch: 6| Step: 12
Training loss: 1.3268768787384033
Validation loss: 2.00650740567074

Epoch: 6| Step: 13
Training loss: 0.9734675288200378
Validation loss: 1.9625179806063253

Epoch: 183| Step: 0
Training loss: 1.143181324005127
Validation loss: 1.9578997640199558

Epoch: 6| Step: 1
Training loss: 2.1072583198547363
Validation loss: 1.9302366369514055

Epoch: 6| Step: 2
Training loss: 1.306401014328003
Validation loss: 1.9409186891330186

Epoch: 6| Step: 3
Training loss: 1.0403910875320435
Validation loss: 1.931138188608231

Epoch: 6| Step: 4
Training loss: 0.999276876449585
Validation loss: 1.9426141964491976

Epoch: 6| Step: 5
Training loss: 1.334979772567749
Validation loss: 1.9858262180000223

Epoch: 6| Step: 6
Training loss: 1.271538257598877
Validation loss: 1.9896776650541572

Epoch: 6| Step: 7
Training loss: 1.0187406539916992
Validation loss: 2.042575890018094

Epoch: 6| Step: 8
Training loss: 1.3655807971954346
Validation loss: 2.0928386706177906

Epoch: 6| Step: 9
Training loss: 1.2934902906417847
Validation loss: 2.117050483662595

Epoch: 6| Step: 10
Training loss: 1.9086520671844482
Validation loss: 2.0991474415666316

Epoch: 6| Step: 11
Training loss: 1.9304559230804443
Validation loss: 2.0949129109741538

Epoch: 6| Step: 12
Training loss: 1.252152681350708
Validation loss: 2.0474649501103226

Epoch: 6| Step: 13
Training loss: 1.0580651760101318
Validation loss: 1.995609934611987

Epoch: 184| Step: 0
Training loss: 1.2743299007415771
Validation loss: 2.000101391987134

Epoch: 6| Step: 1
Training loss: 1.5523886680603027
Validation loss: 1.9832363295298752

Epoch: 6| Step: 2
Training loss: 1.0452531576156616
Validation loss: 1.9988712059554232

Epoch: 6| Step: 3
Training loss: 1.2515127658843994
Validation loss: 1.9901259291556574

Epoch: 6| Step: 4
Training loss: 1.569421410560608
Validation loss: 1.9829705287051458

Epoch: 6| Step: 5
Training loss: 1.6217918395996094
Validation loss: 1.9683637824109805

Epoch: 6| Step: 6
Training loss: 1.4788565635681152
Validation loss: 1.955383062362671

Epoch: 6| Step: 7
Training loss: 0.8366356492042542
Validation loss: 1.9584074815114338

Epoch: 6| Step: 8
Training loss: 1.171637773513794
Validation loss: 1.9776215937829786

Epoch: 6| Step: 9
Training loss: 1.4179723262786865
Validation loss: 1.9736287004204207

Epoch: 6| Step: 10
Training loss: 1.5865952968597412
Validation loss: 2.0011507106083695

Epoch: 6| Step: 11
Training loss: 1.8652094602584839
Validation loss: 1.9771734514544088

Epoch: 6| Step: 12
Training loss: 1.205514907836914
Validation loss: 1.9773054481834493

Epoch: 6| Step: 13
Training loss: 0.8539808988571167
Validation loss: 1.9794190109417003

Epoch: 185| Step: 0
Training loss: 1.0915271043777466
Validation loss: 2.04454101926537

Epoch: 6| Step: 1
Training loss: 1.708719253540039
Validation loss: 2.071439431559655

Epoch: 6| Step: 2
Training loss: 1.7043721675872803
Validation loss: 2.110152913678077

Epoch: 6| Step: 3
Training loss: 1.596872329711914
Validation loss: 2.0768814138186875

Epoch: 6| Step: 4
Training loss: 1.3662444353103638
Validation loss: 2.064742881764648

Epoch: 6| Step: 5
Training loss: 1.4071096181869507
Validation loss: 2.050103969471429

Epoch: 6| Step: 6
Training loss: 1.1045231819152832
Validation loss: 2.0105400892996017

Epoch: 6| Step: 7
Training loss: 0.8373461365699768
Validation loss: 2.008654430348386

Epoch: 6| Step: 8
Training loss: 1.2472813129425049
Validation loss: 1.9785249079427412

Epoch: 6| Step: 9
Training loss: 1.306151032447815
Validation loss: 1.9881207558416552

Epoch: 6| Step: 10
Training loss: 1.2306530475616455
Validation loss: 2.009838984858605

Epoch: 6| Step: 11
Training loss: 1.3861252069473267
Validation loss: 2.0386451316136185

Epoch: 6| Step: 12
Training loss: 1.342321515083313
Validation loss: 2.0337435199368383

Epoch: 6| Step: 13
Training loss: 1.3304768800735474
Validation loss: 2.0374337639859927

Epoch: 186| Step: 0
Training loss: 0.9103095531463623
Validation loss: 2.0642692786391064

Epoch: 6| Step: 1
Training loss: 1.1801011562347412
Validation loss: 2.0559111577208324

Epoch: 6| Step: 2
Training loss: 1.2842214107513428
Validation loss: 2.0359748384003997

Epoch: 6| Step: 3
Training loss: 1.410580039024353
Validation loss: 2.081674148959498

Epoch: 6| Step: 4
Training loss: 1.007461428642273
Validation loss: 2.056426150824434

Epoch: 6| Step: 5
Training loss: 1.1376844644546509
Validation loss: 2.0233635312767437

Epoch: 6| Step: 6
Training loss: 1.418357491493225
Validation loss: 2.008912273632583

Epoch: 6| Step: 7
Training loss: 1.2166743278503418
Validation loss: 2.0149475733439126

Epoch: 6| Step: 8
Training loss: 1.684165358543396
Validation loss: 2.0019851910170687

Epoch: 6| Step: 9
Training loss: 1.6228464841842651
Validation loss: 1.9936788197486632

Epoch: 6| Step: 10
Training loss: 1.7483229637145996
Validation loss: 2.0049002221835557

Epoch: 6| Step: 11
Training loss: 1.4424853324890137
Validation loss: 2.0229847559364895

Epoch: 6| Step: 12
Training loss: 1.164101481437683
Validation loss: 2.035836882488702

Epoch: 6| Step: 13
Training loss: 1.1615140438079834
Validation loss: 2.0376806079700427

Epoch: 187| Step: 0
Training loss: 2.089216947555542
Validation loss: 2.044969217751616

Epoch: 6| Step: 1
Training loss: 1.5997517108917236
Validation loss: 2.064702142951309

Epoch: 6| Step: 2
Training loss: 1.177923560142517
Validation loss: 2.042779372584435

Epoch: 6| Step: 3
Training loss: 1.1718647480010986
Validation loss: 2.009188308510729

Epoch: 6| Step: 4
Training loss: 1.5050585269927979
Validation loss: 2.005057777127912

Epoch: 6| Step: 5
Training loss: 1.470810890197754
Validation loss: 2.0264087441147014

Epoch: 6| Step: 6
Training loss: 0.9661340117454529
Validation loss: 1.9849925682108889

Epoch: 6| Step: 7
Training loss: 1.5431582927703857
Validation loss: 2.0069292309463664

Epoch: 6| Step: 8
Training loss: 1.2945433855056763
Validation loss: 1.9814570949923607

Epoch: 6| Step: 9
Training loss: 1.0243839025497437
Validation loss: 1.9799823555895077

Epoch: 6| Step: 10
Training loss: 0.9762789011001587
Validation loss: 1.9444684982299805

Epoch: 6| Step: 11
Training loss: 1.2177096605300903
Validation loss: 1.9604916828934864

Epoch: 6| Step: 12
Training loss: 1.007382869720459
Validation loss: 2.014644338238624

Epoch: 6| Step: 13
Training loss: 0.9013261795043945
Validation loss: 2.055851774830972

Epoch: 188| Step: 0
Training loss: 1.2397652864456177
Validation loss: 2.1066046120018087

Epoch: 6| Step: 1
Training loss: 1.1028445959091187
Validation loss: 2.132568774684783

Epoch: 6| Step: 2
Training loss: 1.2429311275482178
Validation loss: 2.0741086429165256

Epoch: 6| Step: 3
Training loss: 1.3126003742218018
Validation loss: 2.044646989914679

Epoch: 6| Step: 4
Training loss: 1.4449989795684814
Validation loss: 2.0161336801385366

Epoch: 6| Step: 5
Training loss: 1.2378264665603638
Validation loss: 1.9858713906298402

Epoch: 6| Step: 6
Training loss: 1.5608038902282715
Validation loss: 1.977000069874589

Epoch: 6| Step: 7
Training loss: 1.164273977279663
Validation loss: 1.9806273124551261

Epoch: 6| Step: 8
Training loss: 1.5499464273452759
Validation loss: 1.9591647835188015

Epoch: 6| Step: 9
Training loss: 0.8555901646614075
Validation loss: 1.9509352573784449

Epoch: 6| Step: 10
Training loss: 1.573000192642212
Validation loss: 1.9507554590061147

Epoch: 6| Step: 11
Training loss: 1.4677144289016724
Validation loss: 1.9321496140572332

Epoch: 6| Step: 12
Training loss: 0.9618206024169922
Validation loss: 1.9453577072389665

Epoch: 6| Step: 13
Training loss: 1.2734627723693848
Validation loss: 1.9632091112034296

Epoch: 189| Step: 0
Training loss: 1.0338143110275269
Validation loss: 1.9836577164229525

Epoch: 6| Step: 1
Training loss: 1.4257338047027588
Validation loss: 2.042782909126692

Epoch: 6| Step: 2
Training loss: 1.1149474382400513
Validation loss: 2.0414031936276342

Epoch: 6| Step: 3
Training loss: 1.345137119293213
Validation loss: 2.069493361698684

Epoch: 6| Step: 4
Training loss: 1.203752040863037
Validation loss: 2.064546820937946

Epoch: 6| Step: 5
Training loss: 1.181003212928772
Validation loss: 2.009750332883609

Epoch: 6| Step: 6
Training loss: 1.380298376083374
Validation loss: 1.9986379377303585

Epoch: 6| Step: 7
Training loss: 1.53553307056427
Validation loss: 1.965379007401005

Epoch: 6| Step: 8
Training loss: 1.0166218280792236
Validation loss: 1.9477664552709109

Epoch: 6| Step: 9
Training loss: 1.5535330772399902
Validation loss: 1.97415752180161

Epoch: 6| Step: 10
Training loss: 1.212212324142456
Validation loss: 2.007681372345135

Epoch: 6| Step: 11
Training loss: 1.6467649936676025
Validation loss: 1.9810883178505847

Epoch: 6| Step: 12
Training loss: 0.9291859269142151
Validation loss: 1.9949638587172314

Epoch: 6| Step: 13
Training loss: 0.6266753077507019
Validation loss: 2.009305005432457

Epoch: 190| Step: 0
Training loss: 1.612415075302124
Validation loss: 2.001569676142867

Epoch: 6| Step: 1
Training loss: 1.283096194267273
Validation loss: 2.025205413500468

Epoch: 6| Step: 2
Training loss: 1.1826915740966797
Validation loss: 2.0822028754859843

Epoch: 6| Step: 3
Training loss: 1.1119357347488403
Validation loss: 2.040135828397607

Epoch: 6| Step: 4
Training loss: 1.6199015378952026
Validation loss: 2.010916584281511

Epoch: 6| Step: 5
Training loss: 1.1206419467926025
Validation loss: 1.9728477770282375

Epoch: 6| Step: 6
Training loss: 1.1685417890548706
Validation loss: 1.951175356423983

Epoch: 6| Step: 7
Training loss: 0.6810426712036133
Validation loss: 1.9428064310422508

Epoch: 6| Step: 8
Training loss: 1.6380770206451416
Validation loss: 1.9336983824288974

Epoch: 6| Step: 9
Training loss: 1.2966334819793701
Validation loss: 1.9352680970263738

Epoch: 6| Step: 10
Training loss: 0.948341965675354
Validation loss: 1.9525220983771867

Epoch: 6| Step: 11
Training loss: 1.3020398616790771
Validation loss: 1.968214996399418

Epoch: 6| Step: 12
Training loss: 1.411543607711792
Validation loss: 2.0140320818911315

Epoch: 6| Step: 13
Training loss: 1.7227039337158203
Validation loss: 2.0495055644742903

Epoch: 191| Step: 0
Training loss: 1.015078067779541
Validation loss: 2.1370793760463758

Epoch: 6| Step: 1
Training loss: 0.8714354038238525
Validation loss: 2.1780030727386475

Epoch: 6| Step: 2
Training loss: 1.4054182767868042
Validation loss: 2.18581993861865

Epoch: 6| Step: 3
Training loss: 2.063380718231201
Validation loss: 2.1709207027189192

Epoch: 6| Step: 4
Training loss: 1.7607454061508179
Validation loss: 2.074274975766418

Epoch: 6| Step: 5
Training loss: 1.2890324592590332
Validation loss: 1.9971064803420857

Epoch: 6| Step: 6
Training loss: 1.4762635231018066
Validation loss: 1.9648324033265472

Epoch: 6| Step: 7
Training loss: 0.9763987064361572
Validation loss: 1.970222609017485

Epoch: 6| Step: 8
Training loss: 1.4921249151229858
Validation loss: 1.9462880652437928

Epoch: 6| Step: 9
Training loss: 0.8966199159622192
Validation loss: 1.9305955850949852

Epoch: 6| Step: 10
Training loss: 0.989261269569397
Validation loss: 1.9452422325329115

Epoch: 6| Step: 11
Training loss: 1.2698149681091309
Validation loss: 1.95900547376243

Epoch: 6| Step: 12
Training loss: 1.7465429306030273
Validation loss: 1.974181516196138

Epoch: 6| Step: 13
Training loss: 1.7441660165786743
Validation loss: 1.9991136161229943

Epoch: 192| Step: 0
Training loss: 1.6960933208465576
Validation loss: 2.0695643745442873

Epoch: 6| Step: 1
Training loss: 1.372399091720581
Validation loss: 2.0729738409801195

Epoch: 6| Step: 2
Training loss: 0.7790437340736389
Validation loss: 2.0866274320951073

Epoch: 6| Step: 3
Training loss: 1.5128226280212402
Validation loss: 2.0792709294185845

Epoch: 6| Step: 4
Training loss: 1.0943137407302856
Validation loss: 2.0567629850038918

Epoch: 6| Step: 5
Training loss: 1.1036837100982666
Validation loss: 2.0376469601867018

Epoch: 6| Step: 6
Training loss: 1.041252613067627
Validation loss: 2.00583387959388

Epoch: 6| Step: 7
Training loss: 1.6700812578201294
Validation loss: 1.990505696624838

Epoch: 6| Step: 8
Training loss: 1.4216947555541992
Validation loss: 1.954291328307121

Epoch: 6| Step: 9
Training loss: 1.0738177299499512
Validation loss: 1.9485116761217836

Epoch: 6| Step: 10
Training loss: 1.1382266283035278
Validation loss: 1.9528084288361252

Epoch: 6| Step: 11
Training loss: 1.5723023414611816
Validation loss: 1.9717103845329695

Epoch: 6| Step: 12
Training loss: 1.121964931488037
Validation loss: 1.9956755215121853

Epoch: 6| Step: 13
Training loss: 1.5338668823242188
Validation loss: 2.0343324035726567

Epoch: 193| Step: 0
Training loss: 1.6778807640075684
Validation loss: 2.0154536795872513

Epoch: 6| Step: 1
Training loss: 1.2658424377441406
Validation loss: 1.9871336644695652

Epoch: 6| Step: 2
Training loss: 1.128456950187683
Validation loss: 1.9927991410737396

Epoch: 6| Step: 3
Training loss: 1.2882161140441895
Validation loss: 1.986571801606045

Epoch: 6| Step: 4
Training loss: 1.3661085367202759
Validation loss: 1.9504231727251442

Epoch: 6| Step: 5
Training loss: 0.9015460014343262
Validation loss: 1.9596522508128997

Epoch: 6| Step: 6
Training loss: 1.1167808771133423
Validation loss: 1.9584290827474287

Epoch: 6| Step: 7
Training loss: 1.5058311223983765
Validation loss: 1.946891987195579

Epoch: 6| Step: 8
Training loss: 1.3465813398361206
Validation loss: 1.9584355200490644

Epoch: 6| Step: 9
Training loss: 1.3935472965240479
Validation loss: 1.9499353772850447

Epoch: 6| Step: 10
Training loss: 1.0904958248138428
Validation loss: 1.984291789352253

Epoch: 6| Step: 11
Training loss: 1.2496286630630493
Validation loss: 1.9847728372901998

Epoch: 6| Step: 12
Training loss: 0.9413430690765381
Validation loss: 2.0097711342637257

Epoch: 6| Step: 13
Training loss: 0.7488226294517517
Validation loss: 2.0434631250237905

Epoch: 194| Step: 0
Training loss: 1.4943808317184448
Validation loss: 2.03971065116185

Epoch: 6| Step: 1
Training loss: 0.9936470985412598
Validation loss: 2.031787810787078

Epoch: 6| Step: 2
Training loss: 1.4706776142120361
Validation loss: 2.0097468642778296

Epoch: 6| Step: 3
Training loss: 1.0815224647521973
Validation loss: 2.0161330994739326

Epoch: 6| Step: 4
Training loss: 1.0908318758010864
Validation loss: 2.0017438652694866

Epoch: 6| Step: 5
Training loss: 0.6091734170913696
Validation loss: 1.9897050934453164

Epoch: 6| Step: 6
Training loss: 1.088154673576355
Validation loss: 1.9889299382445633

Epoch: 6| Step: 7
Training loss: 1.2414685487747192
Validation loss: 2.0100350046670563

Epoch: 6| Step: 8
Training loss: 1.4775669574737549
Validation loss: 2.0132105504312823

Epoch: 6| Step: 9
Training loss: 1.2776683568954468
Validation loss: 2.001896322414439

Epoch: 6| Step: 10
Training loss: 0.9700755476951599
Validation loss: 2.0033488517166465

Epoch: 6| Step: 11
Training loss: 1.5583677291870117
Validation loss: 2.009266890505309

Epoch: 6| Step: 12
Training loss: 1.429703712463379
Validation loss: 1.9919058135760728

Epoch: 6| Step: 13
Training loss: 0.9363325834274292
Validation loss: 2.0217109610957484

Epoch: 195| Step: 0
Training loss: 1.1585876941680908
Validation loss: 1.9659476459667247

Epoch: 6| Step: 1
Training loss: 1.1496080160140991
Validation loss: 1.9572161974445466

Epoch: 6| Step: 2
Training loss: 1.071936011314392
Validation loss: 1.989102755823443

Epoch: 6| Step: 3
Training loss: 1.6648743152618408
Validation loss: 1.9650147268849034

Epoch: 6| Step: 4
Training loss: 0.8482354283332825
Validation loss: 1.9455956028353782

Epoch: 6| Step: 5
Training loss: 1.414040446281433
Validation loss: 1.9281528406245734

Epoch: 6| Step: 6
Training loss: 0.9805319309234619
Validation loss: 1.9316350644634617

Epoch: 6| Step: 7
Training loss: 1.124596118927002
Validation loss: 1.9230147664264967

Epoch: 6| Step: 8
Training loss: 1.3477015495300293
Validation loss: 1.9421529180260115

Epoch: 6| Step: 9
Training loss: 1.2819806337356567
Validation loss: 1.9933414510501328

Epoch: 6| Step: 10
Training loss: 1.1314493417739868
Validation loss: 2.031223302246422

Epoch: 6| Step: 11
Training loss: 1.1806271076202393
Validation loss: 2.059858945108229

Epoch: 6| Step: 12
Training loss: 1.3398542404174805
Validation loss: 2.0325655501375914

Epoch: 6| Step: 13
Training loss: 0.868349552154541
Validation loss: 1.9915058151368172

Epoch: 196| Step: 0
Training loss: 1.2649974822998047
Validation loss: 1.9587645940883185

Epoch: 6| Step: 1
Training loss: 0.9911143183708191
Validation loss: 1.9382328243665798

Epoch: 6| Step: 2
Training loss: 1.0928337574005127
Validation loss: 1.9336720692214144

Epoch: 6| Step: 3
Training loss: 1.0768812894821167
Validation loss: 1.9286119848169305

Epoch: 6| Step: 4
Training loss: 0.9242222309112549
Validation loss: 1.9386171884434198

Epoch: 6| Step: 5
Training loss: 1.1650614738464355
Validation loss: 1.9532464729842318

Epoch: 6| Step: 6
Training loss: 1.4462429285049438
Validation loss: 1.9582775292858001

Epoch: 6| Step: 7
Training loss: 0.8122208118438721
Validation loss: 1.989790375514697

Epoch: 6| Step: 8
Training loss: 1.760634183883667
Validation loss: 1.981173756302044

Epoch: 6| Step: 9
Training loss: 1.2350088357925415
Validation loss: 1.9485596431198942

Epoch: 6| Step: 10
Training loss: 1.1811796426773071
Validation loss: 1.994222532036484

Epoch: 6| Step: 11
Training loss: 0.9358523488044739
Validation loss: 2.0201658023300992

Epoch: 6| Step: 12
Training loss: 1.3413994312286377
Validation loss: 2.00730961625294

Epoch: 6| Step: 13
Training loss: 1.1147123575210571
Validation loss: 1.9988945761034567

Epoch: 197| Step: 0
Training loss: 1.0748509168624878
Validation loss: 1.998294194539388

Epoch: 6| Step: 1
Training loss: 1.1064355373382568
Validation loss: 1.9693424535054032

Epoch: 6| Step: 2
Training loss: 1.2809778451919556
Validation loss: 1.9629534495774137

Epoch: 6| Step: 3
Training loss: 0.861752986907959
Validation loss: 1.9759968749938472

Epoch: 6| Step: 4
Training loss: 0.7999918460845947
Validation loss: 2.004320962454683

Epoch: 6| Step: 5
Training loss: 1.5025701522827148
Validation loss: 1.953690618597051

Epoch: 6| Step: 6
Training loss: 1.31406569480896
Validation loss: 1.9886638015829108

Epoch: 6| Step: 7
Training loss: 1.4572327136993408
Validation loss: 2.027012777584855

Epoch: 6| Step: 8
Training loss: 1.6171762943267822
Validation loss: 2.0145794524941394

Epoch: 6| Step: 9
Training loss: 1.6444886922836304
Validation loss: 1.9959592434667772

Epoch: 6| Step: 10
Training loss: 1.2295992374420166
Validation loss: 1.9519066682425879

Epoch: 6| Step: 11
Training loss: 0.9076682925224304
Validation loss: 1.9392344746538388

Epoch: 6| Step: 12
Training loss: 0.7591121792793274
Validation loss: 1.9159517390753633

Epoch: 6| Step: 13
Training loss: 1.2113057374954224
Validation loss: 1.910135575520095

Epoch: 198| Step: 0
Training loss: 1.0773248672485352
Validation loss: 1.895012947820848

Epoch: 6| Step: 1
Training loss: 0.9602225422859192
Validation loss: 1.9016839714460476

Epoch: 6| Step: 2
Training loss: 1.2299938201904297
Validation loss: 1.901006325598686

Epoch: 6| Step: 3
Training loss: 1.4775584936141968
Validation loss: 1.911393460407052

Epoch: 6| Step: 4
Training loss: 0.9485775232315063
Validation loss: 1.9444671215549592

Epoch: 6| Step: 5
Training loss: 1.0999637842178345
Validation loss: 2.009584492252719

Epoch: 6| Step: 6
Training loss: 0.4495640695095062
Validation loss: 2.020324122521185

Epoch: 6| Step: 7
Training loss: 1.43545663356781
Validation loss: 2.056708510204028

Epoch: 6| Step: 8
Training loss: 0.9874567985534668
Validation loss: 2.0658202530235372

Epoch: 6| Step: 9
Training loss: 1.439610242843628
Validation loss: 2.042347743947019

Epoch: 6| Step: 10
Training loss: 1.1981570720672607
Validation loss: 2.0128154370092575

Epoch: 6| Step: 11
Training loss: 1.4683117866516113
Validation loss: 1.9751652081807454

Epoch: 6| Step: 12
Training loss: 0.5769208669662476
Validation loss: 1.93101635543249

Epoch: 6| Step: 13
Training loss: 2.137530565261841
Validation loss: 1.9077781297827279

Epoch: 199| Step: 0
Training loss: 1.1618082523345947
Validation loss: 1.8879078011358938

Epoch: 6| Step: 1
Training loss: 1.2681331634521484
Validation loss: 1.8953078485304309

Epoch: 6| Step: 2
Training loss: 1.2083631753921509
Validation loss: 1.8786529494870094

Epoch: 6| Step: 3
Training loss: 1.3265979290008545
Validation loss: 1.901280044227518

Epoch: 6| Step: 4
Training loss: 1.1777479648590088
Validation loss: 1.931162844422043

Epoch: 6| Step: 5
Training loss: 1.0320613384246826
Validation loss: 1.9670615273137246

Epoch: 6| Step: 6
Training loss: 0.8104102611541748
Validation loss: 2.012243914347823

Epoch: 6| Step: 7
Training loss: 0.9409288763999939
Validation loss: 2.059333485941733

Epoch: 6| Step: 8
Training loss: 0.8391064405441284
Validation loss: 2.077684316583859

Epoch: 6| Step: 9
Training loss: 1.0335034132003784
Validation loss: 2.08711382906924

Epoch: 6| Step: 10
Training loss: 1.2612557411193848
Validation loss: 2.0496994782519597

Epoch: 6| Step: 11
Training loss: 1.178661823272705
Validation loss: 2.014505079997483

Epoch: 6| Step: 12
Training loss: 1.6177208423614502
Validation loss: 1.9615965376618087

Epoch: 6| Step: 13
Training loss: 1.1454954147338867
Validation loss: 1.925169087225391

Epoch: 200| Step: 0
Training loss: 1.1973822116851807
Validation loss: 1.8832054381729455

Epoch: 6| Step: 1
Training loss: 1.1892783641815186
Validation loss: 1.879336892917592

Epoch: 6| Step: 2
Training loss: 0.8405580520629883
Validation loss: 1.8780408854125648

Epoch: 6| Step: 3
Training loss: 0.937804102897644
Validation loss: 1.8648988534045476

Epoch: 6| Step: 4
Training loss: 1.39102041721344
Validation loss: 1.8772212895013953

Epoch: 6| Step: 5
Training loss: 1.2197718620300293
Validation loss: 1.9176388761048675

Epoch: 6| Step: 6
Training loss: 1.400164246559143
Validation loss: 1.9396504407287927

Epoch: 6| Step: 7
Training loss: 1.4036728143692017
Validation loss: 2.009108062713377

Epoch: 6| Step: 8
Training loss: 1.3438680171966553
Validation loss: 2.066911628169398

Epoch: 6| Step: 9
Training loss: 0.5674322247505188
Validation loss: 2.1385919586304696

Epoch: 6| Step: 10
Training loss: 1.7709555625915527
Validation loss: 2.177994474287956

Epoch: 6| Step: 11
Training loss: 1.306375503540039
Validation loss: 2.1912141589708227

Epoch: 6| Step: 12
Training loss: 1.1057058572769165
Validation loss: 2.163568150612616

Epoch: 6| Step: 13
Training loss: 1.03733229637146
Validation loss: 2.0656933348665953

Epoch: 201| Step: 0
Training loss: 1.2316776514053345
Validation loss: 2.012663592574417

Epoch: 6| Step: 1
Training loss: 1.1313564777374268
Validation loss: 1.9803465233054212

Epoch: 6| Step: 2
Training loss: 0.916487455368042
Validation loss: 1.9417370032238703

Epoch: 6| Step: 3
Training loss: 1.0803594589233398
Validation loss: 1.9190755121169552

Epoch: 6| Step: 4
Training loss: 1.24711275100708
Validation loss: 1.9226784757388535

Epoch: 6| Step: 5
Training loss: 1.3225297927856445
Validation loss: 1.9091721555238128

Epoch: 6| Step: 6
Training loss: 1.8041176795959473
Validation loss: 1.946647209505881

Epoch: 6| Step: 7
Training loss: 0.8397732377052307
Validation loss: 1.9865688777739001

Epoch: 6| Step: 8
Training loss: 0.8094649910926819
Validation loss: 2.0110447509314424

Epoch: 6| Step: 9
Training loss: 1.137425422668457
Validation loss: 2.0681349423623856

Epoch: 6| Step: 10
Training loss: 1.1820824146270752
Validation loss: 2.071197291856171

Epoch: 6| Step: 11
Training loss: 1.1317905187606812
Validation loss: 2.0545672549996326

Epoch: 6| Step: 12
Training loss: 1.0370969772338867
Validation loss: 2.043842997602237

Epoch: 6| Step: 13
Training loss: 1.2773933410644531
Validation loss: 1.9749612974864181

Epoch: 202| Step: 0
Training loss: 0.7412420511245728
Validation loss: 1.925403969262236

Epoch: 6| Step: 1
Training loss: 0.7945207357406616
Validation loss: 1.9123614526564074

Epoch: 6| Step: 2
Training loss: 1.3176281452178955
Validation loss: 1.9117324018991122

Epoch: 6| Step: 3
Training loss: 1.1475205421447754
Validation loss: 1.9044341066832184

Epoch: 6| Step: 4
Training loss: 0.7450515031814575
Validation loss: 1.8891481571300055

Epoch: 6| Step: 5
Training loss: 1.388063907623291
Validation loss: 1.8953590008520311

Epoch: 6| Step: 6
Training loss: 1.1251078844070435
Validation loss: 1.892923742212275

Epoch: 6| Step: 7
Training loss: 0.9866703748703003
Validation loss: 1.9124201728451637

Epoch: 6| Step: 8
Training loss: 1.479482650756836
Validation loss: 1.9299856514059088

Epoch: 6| Step: 9
Training loss: 0.5648797750473022
Validation loss: 1.9655603144758491

Epoch: 6| Step: 10
Training loss: 0.7518563866615295
Validation loss: 2.0100342951795107

Epoch: 6| Step: 11
Training loss: 1.597593069076538
Validation loss: 2.048508995322771

Epoch: 6| Step: 12
Training loss: 1.4306319952011108
Validation loss: 2.0447873300121677

Epoch: 6| Step: 13
Training loss: 2.195039987564087
Validation loss: 2.0233552507174912

Epoch: 203| Step: 0
Training loss: 1.8238415718078613
Validation loss: 1.9980797716366347

Epoch: 6| Step: 1
Training loss: 1.4170095920562744
Validation loss: 1.9596598558528449

Epoch: 6| Step: 2
Training loss: 1.154177188873291
Validation loss: 1.962948114641251

Epoch: 6| Step: 3
Training loss: 1.1883502006530762
Validation loss: 1.9232768268995388

Epoch: 6| Step: 4
Training loss: 0.7776129245758057
Validation loss: 1.9221231552862352

Epoch: 6| Step: 5
Training loss: 0.571642279624939
Validation loss: 1.883706279980239

Epoch: 6| Step: 6
Training loss: 1.8268799781799316
Validation loss: 1.8901816157884495

Epoch: 6| Step: 7
Training loss: 1.2871747016906738
Validation loss: 1.8478497894861365

Epoch: 6| Step: 8
Training loss: 0.8964312076568604
Validation loss: 1.8700648853855748

Epoch: 6| Step: 9
Training loss: 1.177490472793579
Validation loss: 1.8579529229030813

Epoch: 6| Step: 10
Training loss: 0.7894022464752197
Validation loss: 1.8829295430132138

Epoch: 6| Step: 11
Training loss: 0.9589852690696716
Validation loss: 1.9157105363825315

Epoch: 6| Step: 12
Training loss: 0.7846242189407349
Validation loss: 1.912660168063256

Epoch: 6| Step: 13
Training loss: 0.6780282855033875
Validation loss: 1.960207836602324

Epoch: 204| Step: 0
Training loss: 1.1015321016311646
Validation loss: 1.9660931966638053

Epoch: 6| Step: 1
Training loss: 1.2113498449325562
Validation loss: 1.925361284645655

Epoch: 6| Step: 2
Training loss: 1.1547298431396484
Validation loss: 1.8941288045657578

Epoch: 6| Step: 3
Training loss: 1.2252312898635864
Validation loss: 1.915636577913838

Epoch: 6| Step: 4
Training loss: 1.0868231058120728
Validation loss: 1.8954898093336372

Epoch: 6| Step: 5
Training loss: 0.9898645877838135
Validation loss: 1.8931081500104678

Epoch: 6| Step: 6
Training loss: 0.9880836009979248
Validation loss: 1.8718068304882254

Epoch: 6| Step: 7
Training loss: 0.8823792934417725
Validation loss: 1.8635396688215193

Epoch: 6| Step: 8
Training loss: 1.6499699354171753
Validation loss: 1.8780635915776736

Epoch: 6| Step: 9
Training loss: 0.9216524362564087
Validation loss: 1.9156385044897757

Epoch: 6| Step: 10
Training loss: 1.257228136062622
Validation loss: 1.9289527964848343

Epoch: 6| Step: 11
Training loss: 1.2190965414047241
Validation loss: 1.919797315392443

Epoch: 6| Step: 12
Training loss: 1.074630856513977
Validation loss: 1.9224819214113298

Epoch: 6| Step: 13
Training loss: 1.0457406044006348
Validation loss: 1.9072675358864568

Epoch: 205| Step: 0
Training loss: 0.666386604309082
Validation loss: 1.915131167698932

Epoch: 6| Step: 1
Training loss: 1.3634544610977173
Validation loss: 1.927014248345488

Epoch: 6| Step: 2
Training loss: 1.3210947513580322
Validation loss: 1.8882822234143493

Epoch: 6| Step: 3
Training loss: 1.4923046827316284
Validation loss: 1.9049502905978952

Epoch: 6| Step: 4
Training loss: 1.1913464069366455
Validation loss: 1.8398932282642653

Epoch: 6| Step: 5
Training loss: 0.7638590335845947
Validation loss: 1.8266614906249508

Epoch: 6| Step: 6
Training loss: 0.4718312919139862
Validation loss: 1.8566197964452928

Epoch: 6| Step: 7
Training loss: 1.1608424186706543
Validation loss: 1.8654228474504204

Epoch: 6| Step: 8
Training loss: 0.7048371434211731
Validation loss: 1.941454125988868

Epoch: 6| Step: 9
Training loss: 1.2035727500915527
Validation loss: 1.9219517246369393

Epoch: 6| Step: 10
Training loss: 1.500443696975708
Validation loss: 1.9280528945307578

Epoch: 6| Step: 11
Training loss: 1.2525591850280762
Validation loss: 1.9638007007619387

Epoch: 6| Step: 12
Training loss: 1.0885703563690186
Validation loss: 1.9504570627725253

Epoch: 6| Step: 13
Training loss: 0.9771599173545837
Validation loss: 1.9670153138458089

Epoch: 206| Step: 0
Training loss: 1.1661897897720337
Validation loss: 1.9293113677732405

Epoch: 6| Step: 1
Training loss: 1.4649802446365356
Validation loss: 1.9042568822060861

Epoch: 6| Step: 2
Training loss: 0.9180132150650024
Validation loss: 1.909141998137197

Epoch: 6| Step: 3
Training loss: 1.4866065979003906
Validation loss: 1.89039364681449

Epoch: 6| Step: 4
Training loss: 1.1546798944473267
Validation loss: 1.8844389710375058

Epoch: 6| Step: 5
Training loss: 1.0629472732543945
Validation loss: 1.8816266867422289

Epoch: 6| Step: 6
Training loss: 0.6969091296195984
Validation loss: 1.8860114710305327

Epoch: 6| Step: 7
Training loss: 0.8177056312561035
Validation loss: 1.9132189340488885

Epoch: 6| Step: 8
Training loss: 0.9947710633277893
Validation loss: 1.9250298905116257

Epoch: 6| Step: 9
Training loss: 1.331820011138916
Validation loss: 1.9764333617302678

Epoch: 6| Step: 10
Training loss: 0.8723398447036743
Validation loss: 1.9835677454548497

Epoch: 6| Step: 11
Training loss: 0.681212306022644
Validation loss: 1.9663375295618528

Epoch: 6| Step: 12
Training loss: 1.1018049716949463
Validation loss: 1.9744987487792969

Epoch: 6| Step: 13
Training loss: 1.1886639595031738
Validation loss: 1.9466946842849895

Epoch: 207| Step: 0
Training loss: 0.37662577629089355
Validation loss: 1.9586219787597656

Epoch: 6| Step: 1
Training loss: 1.0273698568344116
Validation loss: 1.9400374863737373

Epoch: 6| Step: 2
Training loss: 0.9436175227165222
Validation loss: 1.9609902058878252

Epoch: 6| Step: 3
Training loss: 1.1435132026672363
Validation loss: 1.9330460345873268

Epoch: 6| Step: 4
Training loss: 0.8880220651626587
Validation loss: 1.9349726271885697

Epoch: 6| Step: 5
Training loss: 1.610666036605835
Validation loss: 1.9389350273275887

Epoch: 6| Step: 6
Training loss: 0.8667277097702026
Validation loss: 1.920404149639991

Epoch: 6| Step: 7
Training loss: 1.1761637926101685
Validation loss: 1.9313348544541227

Epoch: 6| Step: 8
Training loss: 0.9459590911865234
Validation loss: 1.9530683884056665

Epoch: 6| Step: 9
Training loss: 0.7317973375320435
Validation loss: 1.987172144715504

Epoch: 6| Step: 10
Training loss: 1.8693413734436035
Validation loss: 1.9368812986599502

Epoch: 6| Step: 11
Training loss: 0.7845103144645691
Validation loss: 1.917243678082702

Epoch: 6| Step: 12
Training loss: 1.3862378597259521
Validation loss: 1.8823474094431887

Epoch: 6| Step: 13
Training loss: 1.3560538291931152
Validation loss: 1.8690085846890685

Epoch: 208| Step: 0
Training loss: 0.9594065546989441
Validation loss: 1.8674301178224626

Epoch: 6| Step: 1
Training loss: 1.288304328918457
Validation loss: 1.8959308414049045

Epoch: 6| Step: 2
Training loss: 1.3420122861862183
Validation loss: 1.925089697684011

Epoch: 6| Step: 3
Training loss: 1.2197898626327515
Validation loss: 1.9455223519315001

Epoch: 6| Step: 4
Training loss: 1.4266761541366577
Validation loss: 1.9466162855907152

Epoch: 6| Step: 5
Training loss: 0.9312734007835388
Validation loss: 1.9376026917529363

Epoch: 6| Step: 6
Training loss: 1.0478668212890625
Validation loss: 1.919035614177745

Epoch: 6| Step: 7
Training loss: 0.9708681106567383
Validation loss: 1.9310032924016316

Epoch: 6| Step: 8
Training loss: 0.946148693561554
Validation loss: 1.9102620770854335

Epoch: 6| Step: 9
Training loss: 1.1756583452224731
Validation loss: 1.9130523512440343

Epoch: 6| Step: 10
Training loss: 0.4931637942790985
Validation loss: 1.9090142275697441

Epoch: 6| Step: 11
Training loss: 1.1024906635284424
Validation loss: 1.9050214675164991

Epoch: 6| Step: 12
Training loss: 1.2791907787322998
Validation loss: 1.8853520770226755

Epoch: 6| Step: 13
Training loss: 0.8068969249725342
Validation loss: 1.8510914746151175

Epoch: 209| Step: 0
Training loss: 1.1684741973876953
Validation loss: 1.8620188056781728

Epoch: 6| Step: 1
Training loss: 0.7314239740371704
Validation loss: 1.8549824324987267

Epoch: 6| Step: 2
Training loss: 0.9365701079368591
Validation loss: 1.8976010071334017

Epoch: 6| Step: 3
Training loss: 1.3153598308563232
Validation loss: 1.9188456817339825

Epoch: 6| Step: 4
Training loss: 0.9137569665908813
Validation loss: 1.9359134704835954

Epoch: 6| Step: 5
Training loss: 1.2022444009780884
Validation loss: 1.9472794507139473

Epoch: 6| Step: 6
Training loss: 0.6102977991104126
Validation loss: 1.9091779878062587

Epoch: 6| Step: 7
Training loss: 1.1864850521087646
Validation loss: 1.9019991582439792

Epoch: 6| Step: 8
Training loss: 0.7962554693222046
Validation loss: 1.8897759068396784

Epoch: 6| Step: 9
Training loss: 0.9779388904571533
Validation loss: 1.8641563692400533

Epoch: 6| Step: 10
Training loss: 1.115250825881958
Validation loss: 1.8663004752128356

Epoch: 6| Step: 11
Training loss: 1.0530455112457275
Validation loss: 1.860182136617681

Epoch: 6| Step: 12
Training loss: 1.15720534324646
Validation loss: 1.8877947433020479

Epoch: 6| Step: 13
Training loss: 1.3711433410644531
Validation loss: 1.8787944701410109

Epoch: 210| Step: 0
Training loss: 1.2113851308822632
Validation loss: 1.9085765500222482

Epoch: 6| Step: 1
Training loss: 1.192919135093689
Validation loss: 1.9359461799744637

Epoch: 6| Step: 2
Training loss: 0.8756168484687805
Validation loss: 1.957966399449174

Epoch: 6| Step: 3
Training loss: 1.0753388404846191
Validation loss: 1.99181963551429

Epoch: 6| Step: 4
Training loss: 0.6594418287277222
Validation loss: 1.9527909114796629

Epoch: 6| Step: 5
Training loss: 0.9532548189163208
Validation loss: 1.956311810401178

Epoch: 6| Step: 6
Training loss: 1.5549200773239136
Validation loss: 1.9244267722611785

Epoch: 6| Step: 7
Training loss: 1.3316998481750488
Validation loss: 1.887450333564512

Epoch: 6| Step: 8
Training loss: 1.0433614253997803
Validation loss: 1.8926847737322572

Epoch: 6| Step: 9
Training loss: 0.8485348224639893
Validation loss: 1.9055730681265555

Epoch: 6| Step: 10
Training loss: 0.6369022130966187
Validation loss: 1.929787443530175

Epoch: 6| Step: 11
Training loss: 1.4730174541473389
Validation loss: 1.9184257266342

Epoch: 6| Step: 12
Training loss: 1.2209968566894531
Validation loss: 1.9201512144457908

Epoch: 6| Step: 13
Training loss: 0.5980371832847595
Validation loss: 1.8776098784580026

Epoch: 211| Step: 0
Training loss: 0.7479610443115234
Validation loss: 1.8416282425644577

Epoch: 6| Step: 1
Training loss: 1.1368067264556885
Validation loss: 1.8503279865428965

Epoch: 6| Step: 2
Training loss: 0.9288073778152466
Validation loss: 1.8552709779431742

Epoch: 6| Step: 3
Training loss: 1.2098032236099243
Validation loss: 1.9097334261863463

Epoch: 6| Step: 4
Training loss: 1.3954250812530518
Validation loss: 1.9624526744247766

Epoch: 6| Step: 5
Training loss: 1.3653819561004639
Validation loss: 1.9595003153688164

Epoch: 6| Step: 6
Training loss: 0.9645441770553589
Validation loss: 1.9473456618606404

Epoch: 6| Step: 7
Training loss: 1.1003966331481934
Validation loss: 1.9446363295278242

Epoch: 6| Step: 8
Training loss: 1.2424917221069336
Validation loss: 1.9172928576828332

Epoch: 6| Step: 9
Training loss: 0.6570951342582703
Validation loss: 1.8450488608370545

Epoch: 6| Step: 10
Training loss: 0.9358843564987183
Validation loss: 1.8375869476667015

Epoch: 6| Step: 11
Training loss: 0.8764052391052246
Validation loss: 1.8503047343223327

Epoch: 6| Step: 12
Training loss: 1.2295218706130981
Validation loss: 1.8662385632914882

Epoch: 6| Step: 13
Training loss: 1.3436098098754883
Validation loss: 1.885160384639617

Epoch: 212| Step: 0
Training loss: 1.0427533388137817
Validation loss: 1.8969845976880801

Epoch: 6| Step: 1
Training loss: 1.2221691608428955
Validation loss: 1.904468918359408

Epoch: 6| Step: 2
Training loss: 1.2168118953704834
Validation loss: 1.903940567406275

Epoch: 6| Step: 3
Training loss: 0.6429070234298706
Validation loss: 1.9173779859337756

Epoch: 6| Step: 4
Training loss: 0.6412625312805176
Validation loss: 1.9449565051704325

Epoch: 6| Step: 5
Training loss: 0.8752344846725464
Validation loss: 1.9207332006064795

Epoch: 6| Step: 6
Training loss: 0.7895791530609131
Validation loss: 1.9557759531082646

Epoch: 6| Step: 7
Training loss: 1.0154731273651123
Validation loss: 1.9554854054604807

Epoch: 6| Step: 8
Training loss: 1.6139723062515259
Validation loss: 1.9333167204292871

Epoch: 6| Step: 9
Training loss: 0.5701729655265808
Validation loss: 1.875784307397822

Epoch: 6| Step: 10
Training loss: 1.0440092086791992
Validation loss: 1.8827217509669643

Epoch: 6| Step: 11
Training loss: 1.1266063451766968
Validation loss: 1.8700471308923536

Epoch: 6| Step: 12
Training loss: 1.0484538078308105
Validation loss: 1.8833764265942317

Epoch: 6| Step: 13
Training loss: 1.452552318572998
Validation loss: 1.890166990218624

Epoch: 213| Step: 0
Training loss: 0.9601994156837463
Validation loss: 1.9440036230189826

Epoch: 6| Step: 1
Training loss: 0.7381081581115723
Validation loss: 1.9148965856080413

Epoch: 6| Step: 2
Training loss: 0.8622420430183411
Validation loss: 1.915071370781109

Epoch: 6| Step: 3
Training loss: 0.9256875514984131
Validation loss: 1.9401291070445892

Epoch: 6| Step: 4
Training loss: 1.0990935564041138
Validation loss: 1.9630584357887186

Epoch: 6| Step: 5
Training loss: 0.9175190925598145
Validation loss: 1.9575583729692685

Epoch: 6| Step: 6
Training loss: 1.0012764930725098
Validation loss: 1.9124685897622058

Epoch: 6| Step: 7
Training loss: 1.2694040536880493
Validation loss: 1.8337354762579805

Epoch: 6| Step: 8
Training loss: 0.8827246427536011
Validation loss: 1.8422783036385812

Epoch: 6| Step: 9
Training loss: 0.7525738477706909
Validation loss: 1.827183199185197

Epoch: 6| Step: 10
Training loss: 1.18401300907135
Validation loss: 1.8076461104936496

Epoch: 6| Step: 11
Training loss: 0.9203813076019287
Validation loss: 1.7706654058989657

Epoch: 6| Step: 12
Training loss: 1.2424218654632568
Validation loss: 1.7584403599462202

Epoch: 6| Step: 13
Training loss: 1.199572205543518
Validation loss: 1.7653786495167723

Epoch: 214| Step: 0
Training loss: 0.8408989906311035
Validation loss: 1.7548081157028035

Epoch: 6| Step: 1
Training loss: 1.0806365013122559
Validation loss: 1.7661676817042853

Epoch: 6| Step: 2
Training loss: 0.7906976938247681
Validation loss: 1.768987876112743

Epoch: 6| Step: 3
Training loss: 1.0922868251800537
Validation loss: 1.8318814718595116

Epoch: 6| Step: 4
Training loss: 0.8782079815864563
Validation loss: 1.8247247383158693

Epoch: 6| Step: 5
Training loss: 0.8709006905555725
Validation loss: 1.8310500332104263

Epoch: 6| Step: 6
Training loss: 0.9857679009437561
Validation loss: 1.862713186971603

Epoch: 6| Step: 7
Training loss: 0.7161134481430054
Validation loss: 1.8650846609505274

Epoch: 6| Step: 8
Training loss: 1.399904489517212
Validation loss: 1.820026090068202

Epoch: 6| Step: 9
Training loss: 0.8528436422348022
Validation loss: 1.828399549248398

Epoch: 6| Step: 10
Training loss: 1.153307557106018
Validation loss: 1.827405515537467

Epoch: 6| Step: 11
Training loss: 0.7787724733352661
Validation loss: 1.8114099643563712

Epoch: 6| Step: 12
Training loss: 0.8648504018783569
Validation loss: 1.7879172294370589

Epoch: 6| Step: 13
Training loss: 1.3476815223693848
Validation loss: 1.7814946225894395

Epoch: 215| Step: 0
Training loss: 0.7310097217559814
Validation loss: 1.7777659341853151

Epoch: 6| Step: 1
Training loss: 0.8786312341690063
Validation loss: 1.8028961291877172

Epoch: 6| Step: 2
Training loss: 0.9046640396118164
Validation loss: 1.8495932958459342

Epoch: 6| Step: 3
Training loss: 1.0340063571929932
Validation loss: 1.8748400429243683

Epoch: 6| Step: 4
Training loss: 0.3567888140678406
Validation loss: 1.8399147769456268

Epoch: 6| Step: 5
Training loss: 0.9886360168457031
Validation loss: 1.847258529355449

Epoch: 6| Step: 6
Training loss: 1.16534423828125
Validation loss: 1.8537154582238966

Epoch: 6| Step: 7
Training loss: 0.9363264441490173
Validation loss: 1.863086469711796

Epoch: 6| Step: 8
Training loss: 1.0158957242965698
Validation loss: 1.8631714582443237

Epoch: 6| Step: 9
Training loss: 1.6298506259918213
Validation loss: 1.8295800596155145

Epoch: 6| Step: 10
Training loss: 1.3556435108184814
Validation loss: 1.8700816182680027

Epoch: 6| Step: 11
Training loss: 1.0195094347000122
Validation loss: 1.8580450191292712

Epoch: 6| Step: 12
Training loss: 0.6449195146560669
Validation loss: 1.8867257795026224

Epoch: 6| Step: 13
Training loss: 0.4516538977622986
Validation loss: 1.851818020625781

Epoch: 216| Step: 0
Training loss: 1.3694790601730347
Validation loss: 1.8483689190239034

Epoch: 6| Step: 1
Training loss: 0.8526977896690369
Validation loss: 1.805973888725363

Epoch: 6| Step: 2
Training loss: 0.9399020671844482
Validation loss: 1.8250521075341009

Epoch: 6| Step: 3
Training loss: 1.0289382934570312
Validation loss: 1.8358234679827126

Epoch: 6| Step: 4
Training loss: 0.9094679951667786
Validation loss: 1.8541336508207424

Epoch: 6| Step: 5
Training loss: 1.0017294883728027
Validation loss: 1.8527018100984636

Epoch: 6| Step: 6
Training loss: 0.9782696962356567
Validation loss: 1.8410840726667834

Epoch: 6| Step: 7
Training loss: 0.7072370052337646
Validation loss: 1.8387278972133514

Epoch: 6| Step: 8
Training loss: 0.9347445368766785
Validation loss: 1.8710494105533888

Epoch: 6| Step: 9
Training loss: 0.7932602763175964
Validation loss: 1.8686160861804921

Epoch: 6| Step: 10
Training loss: 1.241180658340454
Validation loss: 1.8986435167251094

Epoch: 6| Step: 11
Training loss: 0.6517717838287354
Validation loss: 1.887621561686198

Epoch: 6| Step: 12
Training loss: 1.0071765184402466
Validation loss: 1.8521253447378836

Epoch: 6| Step: 13
Training loss: 0.5982456207275391
Validation loss: 1.9064195771371164

Epoch: 217| Step: 0
Training loss: 0.7917943000793457
Validation loss: 1.8912532893560265

Epoch: 6| Step: 1
Training loss: 0.5791079998016357
Validation loss: 1.8861350167182185

Epoch: 6| Step: 2
Training loss: 1.1604487895965576
Validation loss: 1.9133279259486864

Epoch: 6| Step: 3
Training loss: 0.6499139666557312
Validation loss: 1.9169358899516444

Epoch: 6| Step: 4
Training loss: 0.9555445909500122
Validation loss: 1.8966868449282903

Epoch: 6| Step: 5
Training loss: 1.0492568016052246
Validation loss: 1.8788736353638351

Epoch: 6| Step: 6
Training loss: 0.971430778503418
Validation loss: 1.8761891344542145

Epoch: 6| Step: 7
Training loss: 0.8885264992713928
Validation loss: 1.8933577434990996

Epoch: 6| Step: 8
Training loss: 1.2601909637451172
Validation loss: 1.8889175935458111

Epoch: 6| Step: 9
Training loss: 1.4038763046264648
Validation loss: 1.8877989374181277

Epoch: 6| Step: 10
Training loss: 0.9440779089927673
Validation loss: 1.8529461814511208

Epoch: 6| Step: 11
Training loss: 0.6139506697654724
Validation loss: 1.8589387273275724

Epoch: 6| Step: 12
Training loss: 1.0656641721725464
Validation loss: 1.8237543926444104

Epoch: 6| Step: 13
Training loss: 0.8858671188354492
Validation loss: 1.809894629704055

Epoch: 218| Step: 0
Training loss: 0.9520363807678223
Validation loss: 1.8035817889757053

Epoch: 6| Step: 1
Training loss: 0.6475111842155457
Validation loss: 1.8237656816359489

Epoch: 6| Step: 2
Training loss: 1.2409472465515137
Validation loss: 1.8099263419387162

Epoch: 6| Step: 3
Training loss: 1.0849567651748657
Validation loss: 1.8314562254054572

Epoch: 6| Step: 4
Training loss: 0.7300416231155396
Validation loss: 1.8707385088807793

Epoch: 6| Step: 5
Training loss: 0.5549346804618835
Validation loss: 1.887021319840544

Epoch: 6| Step: 6
Training loss: 1.037429928779602
Validation loss: 1.885754677557176

Epoch: 6| Step: 7
Training loss: 0.9597532153129578
Validation loss: 1.8691785950814523

Epoch: 6| Step: 8
Training loss: 1.0844082832336426
Validation loss: 1.8407226954737017

Epoch: 6| Step: 9
Training loss: 1.2116962671279907
Validation loss: 1.8427586965663458

Epoch: 6| Step: 10
Training loss: 1.1091930866241455
Validation loss: 1.7849918462896859

Epoch: 6| Step: 11
Training loss: 0.9486172795295715
Validation loss: 1.7741110683769308

Epoch: 6| Step: 12
Training loss: 0.7894083261489868
Validation loss: 1.7575038581766107

Epoch: 6| Step: 13
Training loss: 0.6274659037590027
Validation loss: 1.7803598168075725

Epoch: 219| Step: 0
Training loss: 1.0510584115982056
Validation loss: 1.758777992699736

Epoch: 6| Step: 1
Training loss: 0.7307350039482117
Validation loss: 1.7662717808959305

Epoch: 6| Step: 2
Training loss: 0.6745845079421997
Validation loss: 1.7770843877587268

Epoch: 6| Step: 3
Training loss: 0.670185387134552
Validation loss: 1.7783577275532547

Epoch: 6| Step: 4
Training loss: 0.6994889974594116
Validation loss: 1.7758576639236943

Epoch: 6| Step: 5
Training loss: 1.1711487770080566
Validation loss: 1.8091192271119805

Epoch: 6| Step: 6
Training loss: 0.9360367655754089
Validation loss: 1.7994120146638604

Epoch: 6| Step: 7
Training loss: 0.6006935834884644
Validation loss: 1.8385588968953779

Epoch: 6| Step: 8
Training loss: 1.3410546779632568
Validation loss: 1.8569086905448668

Epoch: 6| Step: 9
Training loss: 0.8475137948989868
Validation loss: 1.8259930482474707

Epoch: 6| Step: 10
Training loss: 1.2036373615264893
Validation loss: 1.8529001089834398

Epoch: 6| Step: 11
Training loss: 0.945321261882782
Validation loss: 1.8383597917454217

Epoch: 6| Step: 12
Training loss: 0.7943286895751953
Validation loss: 1.847528781942142

Epoch: 6| Step: 13
Training loss: 0.7505810260772705
Validation loss: 1.857101272511226

Epoch: 220| Step: 0
Training loss: 0.6755480766296387
Validation loss: 1.829636707100817

Epoch: 6| Step: 1
Training loss: 0.9428964853286743
Validation loss: 1.8265588668084913

Epoch: 6| Step: 2
Training loss: 1.0662801265716553
Validation loss: 1.8037351728767477

Epoch: 6| Step: 3
Training loss: 1.1866447925567627
Validation loss: 1.819758120403495

Epoch: 6| Step: 4
Training loss: 0.3760805130004883
Validation loss: 1.7958534206113508

Epoch: 6| Step: 5
Training loss: 1.0421314239501953
Validation loss: 1.8178578666461411

Epoch: 6| Step: 6
Training loss: 1.0267128944396973
Validation loss: 1.8094661517809796

Epoch: 6| Step: 7
Training loss: 1.2795124053955078
Validation loss: 1.7999232507521106

Epoch: 6| Step: 8
Training loss: 0.6768966913223267
Validation loss: 1.8190126060157694

Epoch: 6| Step: 9
Training loss: 1.0721497535705566
Validation loss: 1.8637587908775575

Epoch: 6| Step: 10
Training loss: 0.5219705700874329
Validation loss: 1.842317714486071

Epoch: 6| Step: 11
Training loss: 0.8625432252883911
Validation loss: 1.8623008125571794

Epoch: 6| Step: 12
Training loss: 1.1971503496170044
Validation loss: 1.8524623365812405

Epoch: 6| Step: 13
Training loss: 0.6234243512153625
Validation loss: 1.832966540449409

Epoch: 221| Step: 0
Training loss: 1.5042871236801147
Validation loss: 1.7981068639345066

Epoch: 6| Step: 1
Training loss: 0.868675172328949
Validation loss: 1.7887351102726434

Epoch: 6| Step: 2
Training loss: 0.9200635552406311
Validation loss: 1.8042763394694175

Epoch: 6| Step: 3
Training loss: 0.4326667785644531
Validation loss: 1.7949668476658482

Epoch: 6| Step: 4
Training loss: 0.803591251373291
Validation loss: 1.8100618482917867

Epoch: 6| Step: 5
Training loss: 0.494190514087677
Validation loss: 1.8262695855991815

Epoch: 6| Step: 6
Training loss: 1.105841875076294
Validation loss: 1.8366173480146675

Epoch: 6| Step: 7
Training loss: 0.4690263271331787
Validation loss: 1.8164126385924637

Epoch: 6| Step: 8
Training loss: 0.8590277433395386
Validation loss: 1.8139334929886686

Epoch: 6| Step: 9
Training loss: 0.7691307067871094
Validation loss: 1.8250779810772146

Epoch: 6| Step: 10
Training loss: 1.0561875104904175
Validation loss: 1.84324997983953

Epoch: 6| Step: 11
Training loss: 1.1328094005584717
Validation loss: 1.8252584665052352

Epoch: 6| Step: 12
Training loss: 0.8709407448768616
Validation loss: 1.8526092395987561

Epoch: 6| Step: 13
Training loss: 1.122164249420166
Validation loss: 1.8398091331604989

Epoch: 222| Step: 0
Training loss: 1.1427252292633057
Validation loss: 1.8704941759827316

Epoch: 6| Step: 1
Training loss: 1.023388147354126
Validation loss: 1.8787027417972524

Epoch: 6| Step: 2
Training loss: 0.6033950448036194
Validation loss: 1.88001387862749

Epoch: 6| Step: 3
Training loss: 0.891847550868988
Validation loss: 1.8808281742116457

Epoch: 6| Step: 4
Training loss: 0.9895398020744324
Validation loss: 1.899064774154335

Epoch: 6| Step: 5
Training loss: 0.7763012051582336
Validation loss: 1.8778105320469025

Epoch: 6| Step: 6
Training loss: 1.6244263648986816
Validation loss: 1.8457314455381004

Epoch: 6| Step: 7
Training loss: 0.484569251537323
Validation loss: 1.8056196166623024

Epoch: 6| Step: 8
Training loss: 0.7374545335769653
Validation loss: 1.7541235787894136

Epoch: 6| Step: 9
Training loss: 0.995197057723999
Validation loss: 1.745826103354013

Epoch: 6| Step: 10
Training loss: 0.8197025060653687
Validation loss: 1.793683107181262

Epoch: 6| Step: 11
Training loss: 0.9523260593414307
Validation loss: 1.8042223479158135

Epoch: 6| Step: 12
Training loss: 0.5876060724258423
Validation loss: 1.8022301645689114

Epoch: 6| Step: 13
Training loss: 1.2637429237365723
Validation loss: 1.8105736676082815

Epoch: 223| Step: 0
Training loss: 1.2043813467025757
Validation loss: 1.7817804428838915

Epoch: 6| Step: 1
Training loss: 0.13436907529830933
Validation loss: 1.811278832856045

Epoch: 6| Step: 2
Training loss: 0.6288442015647888
Validation loss: 1.8167220828353718

Epoch: 6| Step: 3
Training loss: 0.6903469562530518
Validation loss: 1.8298969755890548

Epoch: 6| Step: 4
Training loss: 0.8656193017959595
Validation loss: 1.8101469188608148

Epoch: 6| Step: 5
Training loss: 1.2750632762908936
Validation loss: 1.8259494304656982

Epoch: 6| Step: 6
Training loss: 1.0249887704849243
Validation loss: 1.8160064246064873

Epoch: 6| Step: 7
Training loss: 0.49025028944015503
Validation loss: 1.8040634201418968

Epoch: 6| Step: 8
Training loss: 1.1477774381637573
Validation loss: 1.8025836534397577

Epoch: 6| Step: 9
Training loss: 1.257516622543335
Validation loss: 1.80084494749705

Epoch: 6| Step: 10
Training loss: 1.0016579627990723
Validation loss: 1.800519448454662

Epoch: 6| Step: 11
Training loss: 0.4994102418422699
Validation loss: 1.807988541100615

Epoch: 6| Step: 12
Training loss: 0.8498125076293945
Validation loss: 1.778602204015178

Epoch: 6| Step: 13
Training loss: 1.3598425388336182
Validation loss: 1.8031726332120999

Epoch: 224| Step: 0
Training loss: 0.685173511505127
Validation loss: 1.7954618212997273

Epoch: 6| Step: 1
Training loss: 0.860974133014679
Validation loss: 1.8173575529488184

Epoch: 6| Step: 2
Training loss: 0.5262960195541382
Validation loss: 1.7754462675381733

Epoch: 6| Step: 3
Training loss: 1.102063775062561
Validation loss: 1.7693284288529427

Epoch: 6| Step: 4
Training loss: 1.066480040550232
Validation loss: 1.7614667973210734

Epoch: 6| Step: 5
Training loss: 0.6591514348983765
Validation loss: 1.7961094481970674

Epoch: 6| Step: 6
Training loss: 0.6852578520774841
Validation loss: 1.7712364671050862

Epoch: 6| Step: 7
Training loss: 0.6772317886352539
Validation loss: 1.7942444047620218

Epoch: 6| Step: 8
Training loss: 1.3704500198364258
Validation loss: 1.8229334879946966

Epoch: 6| Step: 9
Training loss: 0.9475675821304321
Validation loss: 1.8534546654711488

Epoch: 6| Step: 10
Training loss: 0.993109405040741
Validation loss: 1.8503241000636932

Epoch: 6| Step: 11
Training loss: 0.6072284579277039
Validation loss: 1.836739868246099

Epoch: 6| Step: 12
Training loss: 1.0323371887207031
Validation loss: 1.8376603767436037

Epoch: 6| Step: 13
Training loss: 0.6726601123809814
Validation loss: 1.7860130417731501

Epoch: 225| Step: 0
Training loss: 0.40445199608802795
Validation loss: 1.7944959953267088

Epoch: 6| Step: 1
Training loss: 0.7035844326019287
Validation loss: 1.8220555666954286

Epoch: 6| Step: 2
Training loss: 1.1887733936309814
Validation loss: 1.8455923065062492

Epoch: 6| Step: 3
Training loss: 1.0874277353286743
Validation loss: 1.8126984219397269

Epoch: 6| Step: 4
Training loss: 0.849648654460907
Validation loss: 1.8090582483558244

Epoch: 6| Step: 5
Training loss: 1.0476696491241455
Validation loss: 1.8197868177967687

Epoch: 6| Step: 6
Training loss: 0.8113127946853638
Validation loss: 1.8565570000679261

Epoch: 6| Step: 7
Training loss: 0.5884146690368652
Validation loss: 1.849341966772592

Epoch: 6| Step: 8
Training loss: 0.829809308052063
Validation loss: 1.8364740597304476

Epoch: 6| Step: 9
Training loss: 0.8243457078933716
Validation loss: 1.87396494419344

Epoch: 6| Step: 10
Training loss: 0.9079198241233826
Validation loss: 1.8712498398237332

Epoch: 6| Step: 11
Training loss: 1.0860294103622437
Validation loss: 1.8482413407294982

Epoch: 6| Step: 12
Training loss: 0.7168921232223511
Validation loss: 1.7989745191348496

Epoch: 6| Step: 13
Training loss: 0.7758151888847351
Validation loss: 1.7850100865928076

Epoch: 226| Step: 0
Training loss: 0.5116195678710938
Validation loss: 1.7831798317611858

Epoch: 6| Step: 1
Training loss: 0.8381892442703247
Validation loss: 1.7986821538658553

Epoch: 6| Step: 2
Training loss: 0.6763938069343567
Validation loss: 1.7936172049532655

Epoch: 6| Step: 3
Training loss: 0.7316960096359253
Validation loss: 1.7555309675073112

Epoch: 6| Step: 4
Training loss: 0.7720834016799927
Validation loss: 1.7941945663062475

Epoch: 6| Step: 5
Training loss: 1.235738754272461
Validation loss: 1.798438331132294

Epoch: 6| Step: 6
Training loss: 0.4747407138347626
Validation loss: 1.8078395833251297

Epoch: 6| Step: 7
Training loss: 1.2412432432174683
Validation loss: 1.8679239070543678

Epoch: 6| Step: 8
Training loss: 0.7608338594436646
Validation loss: 1.817174732044179

Epoch: 6| Step: 9
Training loss: 0.6498551964759827
Validation loss: 1.8083965932169268

Epoch: 6| Step: 10
Training loss: 1.1119972467422485
Validation loss: 1.784675407153304

Epoch: 6| Step: 11
Training loss: 0.9877047538757324
Validation loss: 1.7750787504257695

Epoch: 6| Step: 12
Training loss: 0.8753360509872437
Validation loss: 1.7211277664348643

Epoch: 6| Step: 13
Training loss: 0.5846906304359436
Validation loss: 1.716779339698053

Epoch: 227| Step: 0
Training loss: 0.49550461769104004
Validation loss: 1.722339968527517

Epoch: 6| Step: 1
Training loss: 0.6516926288604736
Validation loss: 1.718188262754871

Epoch: 6| Step: 2
Training loss: 1.136889934539795
Validation loss: 1.744525065986059

Epoch: 6| Step: 3
Training loss: 1.1350064277648926
Validation loss: 1.7382539497908724

Epoch: 6| Step: 4
Training loss: 0.9204067587852478
Validation loss: 1.7777837809695993

Epoch: 6| Step: 5
Training loss: 1.0139153003692627
Validation loss: 1.8160655677959483

Epoch: 6| Step: 6
Training loss: 0.3978413939476013
Validation loss: 1.9020065184562438

Epoch: 6| Step: 7
Training loss: 0.34233203530311584
Validation loss: 1.8807351255929599

Epoch: 6| Step: 8
Training loss: 0.815329909324646
Validation loss: 1.875308129095262

Epoch: 6| Step: 9
Training loss: 0.9644273519515991
Validation loss: 1.8789058885266703

Epoch: 6| Step: 10
Training loss: 1.1446453332901
Validation loss: 1.8468835033396238

Epoch: 6| Step: 11
Training loss: 0.5313752889633179
Validation loss: 1.8415900789281374

Epoch: 6| Step: 12
Training loss: 1.2582107782363892
Validation loss: 1.7791969814608175

Epoch: 6| Step: 13
Training loss: 1.1296454668045044
Validation loss: 1.7705806263031498

Epoch: 228| Step: 0
Training loss: 0.8821862936019897
Validation loss: 1.8123050594842562

Epoch: 6| Step: 1
Training loss: 1.0483884811401367
Validation loss: 1.7619735181972545

Epoch: 6| Step: 2
Training loss: 0.6575363874435425
Validation loss: 1.7587705837782992

Epoch: 6| Step: 3
Training loss: 0.8489598035812378
Validation loss: 1.7624877498995872

Epoch: 6| Step: 4
Training loss: 0.8170651197433472
Validation loss: 1.7471236298161168

Epoch: 6| Step: 5
Training loss: 0.699635922908783
Validation loss: 1.7455525475163614

Epoch: 6| Step: 6
Training loss: 0.42956385016441345
Validation loss: 1.7982297776847758

Epoch: 6| Step: 7
Training loss: 0.8434654474258423
Validation loss: 1.7917342596156622

Epoch: 6| Step: 8
Training loss: 0.9344921112060547
Validation loss: 1.8248582065746348

Epoch: 6| Step: 9
Training loss: 0.5887525677680969
Validation loss: 1.852394696204893

Epoch: 6| Step: 10
Training loss: 0.6960254907608032
Validation loss: 1.83896598123735

Epoch: 6| Step: 11
Training loss: 1.0761313438415527
Validation loss: 1.8654339095597625

Epoch: 6| Step: 12
Training loss: 1.4365606307983398
Validation loss: 1.8848421778730167

Epoch: 6| Step: 13
Training loss: 0.5852578282356262
Validation loss: 1.8394512117549937

Epoch: 229| Step: 0
Training loss: 0.4610430598258972
Validation loss: 1.8090046951847691

Epoch: 6| Step: 1
Training loss: 0.8081076145172119
Validation loss: 1.7862701223742576

Epoch: 6| Step: 2
Training loss: 1.072573184967041
Validation loss: 1.767509691176876

Epoch: 6| Step: 3
Training loss: 1.0787473917007446
Validation loss: 1.7758372996443061

Epoch: 6| Step: 4
Training loss: 0.6168733835220337
Validation loss: 1.8192800949978571

Epoch: 6| Step: 5
Training loss: 0.8823361396789551
Validation loss: 1.8141217718842209

Epoch: 6| Step: 6
Training loss: 0.840672492980957
Validation loss: 1.8637187378380888

Epoch: 6| Step: 7
Training loss: 0.6217868328094482
Validation loss: 1.9030236300601755

Epoch: 6| Step: 8
Training loss: 1.2165968418121338
Validation loss: 1.9003894482889483

Epoch: 6| Step: 9
Training loss: 0.8987389206886292
Validation loss: 1.8797222068232875

Epoch: 6| Step: 10
Training loss: 1.2969410419464111
Validation loss: 1.9072239296410674

Epoch: 6| Step: 11
Training loss: 1.148430585861206
Validation loss: 1.8555896884651595

Epoch: 6| Step: 12
Training loss: 0.4052524268627167
Validation loss: 1.816531906845749

Epoch: 6| Step: 13
Training loss: 1.1199177503585815
Validation loss: 1.7681364602940057

Epoch: 230| Step: 0
Training loss: 0.4307296872138977
Validation loss: 1.7919967841076594

Epoch: 6| Step: 1
Training loss: 1.0017229318618774
Validation loss: 1.8279624587746077

Epoch: 6| Step: 2
Training loss: 1.0364174842834473
Validation loss: 1.8586645869798557

Epoch: 6| Step: 3
Training loss: 0.5998868942260742
Validation loss: 1.8780783273840462

Epoch: 6| Step: 4
Training loss: 1.1064622402191162
Validation loss: 1.868490478043915

Epoch: 6| Step: 5
Training loss: 1.0069355964660645
Validation loss: 1.8248020359264907

Epoch: 6| Step: 6
Training loss: 0.855928897857666
Validation loss: 1.8236808738400858

Epoch: 6| Step: 7
Training loss: 0.6425033807754517
Validation loss: 1.791348885464412

Epoch: 6| Step: 8
Training loss: 0.8181757926940918
Validation loss: 1.7622359952618998

Epoch: 6| Step: 9
Training loss: 0.36854857206344604
Validation loss: 1.738374367836983

Epoch: 6| Step: 10
Training loss: 0.9000932574272156
Validation loss: 1.7594585444337578

Epoch: 6| Step: 11
Training loss: 1.0189518928527832
Validation loss: 1.7465156406484625

Epoch: 6| Step: 12
Training loss: 1.1857497692108154
Validation loss: 1.7572386598074308

Epoch: 6| Step: 13
Training loss: 0.5899531841278076
Validation loss: 1.7989307539437407

Epoch: 231| Step: 0
Training loss: 0.796517014503479
Validation loss: 1.7938986286040275

Epoch: 6| Step: 1
Training loss: 1.082669734954834
Validation loss: 1.8377097114439933

Epoch: 6| Step: 2
Training loss: 1.032157063484192
Validation loss: 1.839427722397671

Epoch: 6| Step: 3
Training loss: 0.38872790336608887
Validation loss: 1.8066881484882806

Epoch: 6| Step: 4
Training loss: 0.47483789920806885
Validation loss: 1.8113924328998854

Epoch: 6| Step: 5
Training loss: 0.5866653323173523
Validation loss: 1.8085508295284805

Epoch: 6| Step: 6
Training loss: 0.5182072520256042
Validation loss: 1.7951648466048702

Epoch: 6| Step: 7
Training loss: 0.6499156355857849
Validation loss: 1.806254671465966

Epoch: 6| Step: 8
Training loss: 0.6754398941993713
Validation loss: 1.7603905688049972

Epoch: 6| Step: 9
Training loss: 1.2367249727249146
Validation loss: 1.7489174232688

Epoch: 6| Step: 10
Training loss: 0.9700415730476379
Validation loss: 1.7633436956713278

Epoch: 6| Step: 11
Training loss: 0.8145472407341003
Validation loss: 1.7524778541698252

Epoch: 6| Step: 12
Training loss: 0.9224480390548706
Validation loss: 1.7641188854812293

Epoch: 6| Step: 13
Training loss: 1.308037281036377
Validation loss: 1.7548915160599576

Epoch: 232| Step: 0
Training loss: 1.1629462242126465
Validation loss: 1.7540431202098887

Epoch: 6| Step: 1
Training loss: 0.9262483716011047
Validation loss: 1.7695872552933232

Epoch: 6| Step: 2
Training loss: 0.8366377353668213
Validation loss: 1.7738639334196686

Epoch: 6| Step: 3
Training loss: 0.9321771860122681
Validation loss: 1.7876613370833858

Epoch: 6| Step: 4
Training loss: 0.4136640429496765
Validation loss: 1.770259613631874

Epoch: 6| Step: 5
Training loss: 1.258192777633667
Validation loss: 1.7863351106643677

Epoch: 6| Step: 6
Training loss: 0.6729023456573486
Validation loss: 1.8080753164906656

Epoch: 6| Step: 7
Training loss: 0.6442914605140686
Validation loss: 1.781882975050198

Epoch: 6| Step: 8
Training loss: 0.6200110912322998
Validation loss: 1.7614620988086989

Epoch: 6| Step: 9
Training loss: 0.6418884992599487
Validation loss: 1.7379738233422721

Epoch: 6| Step: 10
Training loss: 0.6460708975791931
Validation loss: 1.7668191412443757

Epoch: 6| Step: 11
Training loss: 0.8237072825431824
Validation loss: 1.8123094163915163

Epoch: 6| Step: 12
Training loss: 0.45572206377983093
Validation loss: 1.8106109108976138

Epoch: 6| Step: 13
Training loss: 0.7638162970542908
Validation loss: 1.7780072650601786

Epoch: 233| Step: 0
Training loss: 0.30699414014816284
Validation loss: 1.765701913064526

Epoch: 6| Step: 1
Training loss: 0.946820080280304
Validation loss: 1.729677733554635

Epoch: 6| Step: 2
Training loss: 1.098581314086914
Validation loss: 1.7021703476546912

Epoch: 6| Step: 3
Training loss: 0.7407094240188599
Validation loss: 1.7055274260941373

Epoch: 6| Step: 4
Training loss: 0.6933664679527283
Validation loss: 1.6918789443149362

Epoch: 6| Step: 5
Training loss: 1.15188467502594
Validation loss: 1.7102165299077188

Epoch: 6| Step: 6
Training loss: 0.9228353500366211
Validation loss: 1.717578927675883

Epoch: 6| Step: 7
Training loss: 0.5884613990783691
Validation loss: 1.766697972051559

Epoch: 6| Step: 8
Training loss: 0.9902123212814331
Validation loss: 1.7953690508360505

Epoch: 6| Step: 9
Training loss: 0.7592541575431824
Validation loss: 1.8512395479345833

Epoch: 6| Step: 10
Training loss: 0.7181312441825867
Validation loss: 1.80879904249663

Epoch: 6| Step: 11
Training loss: 0.7567260265350342
Validation loss: 1.7588549121733634

Epoch: 6| Step: 12
Training loss: 0.7597813606262207
Validation loss: 1.718210562582939

Epoch: 6| Step: 13
Training loss: 0.757617175579071
Validation loss: 1.7112293166498984

Epoch: 234| Step: 0
Training loss: 0.9534454345703125
Validation loss: 1.7353994436161493

Epoch: 6| Step: 1
Training loss: 0.9740941524505615
Validation loss: 1.7369606238539501

Epoch: 6| Step: 2
Training loss: 0.7127546072006226
Validation loss: 1.726421445928594

Epoch: 6| Step: 3
Training loss: 0.5602439045906067
Validation loss: 1.7196959346853278

Epoch: 6| Step: 4
Training loss: 0.707671046257019
Validation loss: 1.717715174280187

Epoch: 6| Step: 5
Training loss: 0.5645862817764282
Validation loss: 1.7452472595758335

Epoch: 6| Step: 6
Training loss: 0.72414231300354
Validation loss: 1.7499141962297502

Epoch: 6| Step: 7
Training loss: 0.7766262292861938
Validation loss: 1.7849558015023508

Epoch: 6| Step: 8
Training loss: 0.5010330677032471
Validation loss: 1.823393677511523

Epoch: 6| Step: 9
Training loss: 1.3670474290847778
Validation loss: 1.820893536331833

Epoch: 6| Step: 10
Training loss: 0.6789121627807617
Validation loss: 1.7662619531795543

Epoch: 6| Step: 11
Training loss: 1.078536033630371
Validation loss: 1.7358902141612063

Epoch: 6| Step: 12
Training loss: 0.9002276659011841
Validation loss: 1.7329172588163806

Epoch: 6| Step: 13
Training loss: 0.7027323246002197
Validation loss: 1.7038507923003166

Epoch: 235| Step: 0
Training loss: 0.9119439721107483
Validation loss: 1.744365479356499

Epoch: 6| Step: 1
Training loss: 0.61307692527771
Validation loss: 1.7408166239338536

Epoch: 6| Step: 2
Training loss: 0.7056429982185364
Validation loss: 1.7624674343293714

Epoch: 6| Step: 3
Training loss: 0.7522403001785278
Validation loss: 1.7737397352854412

Epoch: 6| Step: 4
Training loss: 0.9460647702217102
Validation loss: 1.813190955628631

Epoch: 6| Step: 5
Training loss: 0.5889261960983276
Validation loss: 1.784783758142943

Epoch: 6| Step: 6
Training loss: 0.9526587724685669
Validation loss: 1.7957162293054725

Epoch: 6| Step: 7
Training loss: 0.6791931390762329
Validation loss: 1.8183804391532816

Epoch: 6| Step: 8
Training loss: 0.8738227486610413
Validation loss: 1.781986746736752

Epoch: 6| Step: 9
Training loss: 0.823538064956665
Validation loss: 1.7426403389182141

Epoch: 6| Step: 10
Training loss: 0.8371529579162598
Validation loss: 1.7429863983584988

Epoch: 6| Step: 11
Training loss: 0.5891882181167603
Validation loss: 1.728264893254926

Epoch: 6| Step: 12
Training loss: 0.6815303564071655
Validation loss: 1.7357028633035638

Epoch: 6| Step: 13
Training loss: 0.7754755020141602
Validation loss: 1.7486834372243574

Epoch: 236| Step: 0
Training loss: 1.0715124607086182
Validation loss: 1.7668174582142984

Epoch: 6| Step: 1
Training loss: 0.5810904502868652
Validation loss: 1.7793839721269504

Epoch: 6| Step: 2
Training loss: 0.837591290473938
Validation loss: 1.7353687901650705

Epoch: 6| Step: 3
Training loss: 0.621344804763794
Validation loss: 1.7523937814979142

Epoch: 6| Step: 4
Training loss: 1.0403368473052979
Validation loss: 1.7944962286180066

Epoch: 6| Step: 5
Training loss: 0.6197550296783447
Validation loss: 1.7795655817113898

Epoch: 6| Step: 6
Training loss: 0.7546184062957764
Validation loss: 1.7639846724848594

Epoch: 6| Step: 7
Training loss: 0.7893280386924744
Validation loss: 1.7303006546471709

Epoch: 6| Step: 8
Training loss: 0.6566506624221802
Validation loss: 1.6975002711819065

Epoch: 6| Step: 9
Training loss: 0.500259280204773
Validation loss: 1.726047368459804

Epoch: 6| Step: 10
Training loss: 0.6896989345550537
Validation loss: 1.6704442808704991

Epoch: 6| Step: 11
Training loss: 1.0147347450256348
Validation loss: 1.7050602564247705

Epoch: 6| Step: 12
Training loss: 0.6999766230583191
Validation loss: 1.7071689969749861

Epoch: 6| Step: 13
Training loss: 0.567310631275177
Validation loss: 1.7095572717728154

Epoch: 237| Step: 0
Training loss: 0.7221724987030029
Validation loss: 1.7169552701775745

Epoch: 6| Step: 1
Training loss: 0.4890401065349579
Validation loss: 1.7213389360776512

Epoch: 6| Step: 2
Training loss: 0.8939508199691772
Validation loss: 1.7360778547102405

Epoch: 6| Step: 3
Training loss: 0.6984294652938843
Validation loss: 1.7502310570850168

Epoch: 6| Step: 4
Training loss: 0.6227623224258423
Validation loss: 1.7653747579102874

Epoch: 6| Step: 5
Training loss: 0.9006328582763672
Validation loss: 1.7667221907646424

Epoch: 6| Step: 6
Training loss: 1.3060424327850342
Validation loss: 1.7574091162732852

Epoch: 6| Step: 7
Training loss: 0.8118761777877808
Validation loss: 1.7475953307203067

Epoch: 6| Step: 8
Training loss: 0.7466621994972229
Validation loss: 1.7407538980566046

Epoch: 6| Step: 9
Training loss: 1.1515848636627197
Validation loss: 1.743289093817434

Epoch: 6| Step: 10
Training loss: 0.4189532399177551
Validation loss: 1.7556216434765888

Epoch: 6| Step: 11
Training loss: 0.4477325975894928
Validation loss: 1.7242432012352893

Epoch: 6| Step: 12
Training loss: 0.5142232775688171
Validation loss: 1.7125419429553452

Epoch: 6| Step: 13
Training loss: 0.13624435663223267
Validation loss: 1.7229835858909033

Epoch: 238| Step: 0
Training loss: 1.1277313232421875
Validation loss: 1.6957437402458602

Epoch: 6| Step: 1
Training loss: 0.3148002624511719
Validation loss: 1.736462802015325

Epoch: 6| Step: 2
Training loss: 0.7953043580055237
Validation loss: 1.7165186764091573

Epoch: 6| Step: 3
Training loss: 0.877837061882019
Validation loss: 1.7211238902102235

Epoch: 6| Step: 4
Training loss: 0.5237622261047363
Validation loss: 1.7201541803216422

Epoch: 6| Step: 5
Training loss: 0.6796464920043945
Validation loss: 1.7082755668188936

Epoch: 6| Step: 6
Training loss: 0.9609556198120117
Validation loss: 1.7144816588330012

Epoch: 6| Step: 7
Training loss: 0.6110440492630005
Validation loss: 1.7343311989179222

Epoch: 6| Step: 8
Training loss: 0.6654226779937744
Validation loss: 1.7393274332887383

Epoch: 6| Step: 9
Training loss: 0.6111775636672974
Validation loss: 1.7980083829613143

Epoch: 6| Step: 10
Training loss: 1.157440423965454
Validation loss: 1.8390551356859104

Epoch: 6| Step: 11
Training loss: 0.649086058139801
Validation loss: 1.8797646568667503

Epoch: 6| Step: 12
Training loss: 0.7400928735733032
Validation loss: 1.843002151417476

Epoch: 6| Step: 13
Training loss: 0.3677501082420349
Validation loss: 1.836294089594195

Epoch: 239| Step: 0
Training loss: 0.7628380656242371
Validation loss: 1.8056299942795948

Epoch: 6| Step: 1
Training loss: 0.4649565517902374
Validation loss: 1.8002012237425773

Epoch: 6| Step: 2
Training loss: 0.7615865468978882
Validation loss: 1.7824331163078226

Epoch: 6| Step: 3
Training loss: 0.5660190582275391
Validation loss: 1.7909458170654953

Epoch: 6| Step: 4
Training loss: 0.8279716372489929
Validation loss: 1.7555059053564583

Epoch: 6| Step: 5
Training loss: 0.8188363313674927
Validation loss: 1.7391810340266074

Epoch: 6| Step: 6
Training loss: 0.7075694799423218
Validation loss: 1.768010227910934

Epoch: 6| Step: 7
Training loss: 0.5801572203636169
Validation loss: 1.733503782620994

Epoch: 6| Step: 8
Training loss: 0.8740371465682983
Validation loss: 1.7534045404003513

Epoch: 6| Step: 9
Training loss: 0.6489481925964355
Validation loss: 1.7752524524606683

Epoch: 6| Step: 10
Training loss: 0.7479414939880371
Validation loss: 1.7986209789911907

Epoch: 6| Step: 11
Training loss: 0.8576804399490356
Validation loss: 1.7577139305812057

Epoch: 6| Step: 12
Training loss: 0.8261513710021973
Validation loss: 1.7602920788590626

Epoch: 6| Step: 13
Training loss: 0.7720655202865601
Validation loss: 1.7510898126068937

Epoch: 240| Step: 0
Training loss: 1.0016305446624756
Validation loss: 1.7566553520899948

Epoch: 6| Step: 1
Training loss: 0.804497480392456
Validation loss: 1.746107175786008

Epoch: 6| Step: 2
Training loss: 0.6448614001274109
Validation loss: 1.7521112144634288

Epoch: 6| Step: 3
Training loss: 1.073978304862976
Validation loss: 1.7873676002666514

Epoch: 6| Step: 4
Training loss: 0.6132990121841431
Validation loss: 1.7653666093785276

Epoch: 6| Step: 5
Training loss: 0.7724822759628296
Validation loss: 1.750443204756706

Epoch: 6| Step: 6
Training loss: 0.5142830610275269
Validation loss: 1.784105711085822

Epoch: 6| Step: 7
Training loss: 0.47734174132347107
Validation loss: 1.7765943414421492

Epoch: 6| Step: 8
Training loss: 0.5900800824165344
Validation loss: 1.748831210597869

Epoch: 6| Step: 9
Training loss: 0.7369740009307861
Validation loss: 1.7675484072777532

Epoch: 6| Step: 10
Training loss: 0.6361628770828247
Validation loss: 1.732761949621221

Epoch: 6| Step: 11
Training loss: 0.682809591293335
Validation loss: 1.7877825703672183

Epoch: 6| Step: 12
Training loss: 0.6037498712539673
Validation loss: 1.7676753228710544

Epoch: 6| Step: 13
Training loss: 1.0101395845413208
Validation loss: 1.7610045863736061

Epoch: 241| Step: 0
Training loss: 0.5089592337608337
Validation loss: 1.7691654633450251

Epoch: 6| Step: 1
Training loss: 0.6454490423202515
Validation loss: 1.7476759110727618

Epoch: 6| Step: 2
Training loss: 0.6436961889266968
Validation loss: 1.7252063917857345

Epoch: 6| Step: 3
Training loss: 0.28384798765182495
Validation loss: 1.7177719262338453

Epoch: 6| Step: 4
Training loss: 0.5713542103767395
Validation loss: 1.7152001601393505

Epoch: 6| Step: 5
Training loss: 1.043281078338623
Validation loss: 1.6968313968309792

Epoch: 6| Step: 6
Training loss: 0.6786805391311646
Validation loss: 1.7416523964174333

Epoch: 6| Step: 7
Training loss: 0.8556089401245117
Validation loss: 1.734120104902534

Epoch: 6| Step: 8
Training loss: 0.29542261362075806
Validation loss: 1.7116660200139528

Epoch: 6| Step: 9
Training loss: 1.0992896556854248
Validation loss: 1.7150461994191653

Epoch: 6| Step: 10
Training loss: 0.8608770370483398
Validation loss: 1.71904198456836

Epoch: 6| Step: 11
Training loss: 0.9721252918243408
Validation loss: 1.7285493676380446

Epoch: 6| Step: 12
Training loss: 0.8489170074462891
Validation loss: 1.7538814916405627

Epoch: 6| Step: 13
Training loss: 0.5289425253868103
Validation loss: 1.7423885906896284

Epoch: 242| Step: 0
Training loss: 0.8297339677810669
Validation loss: 1.7530892638749973

Epoch: 6| Step: 1
Training loss: 0.5047483444213867
Validation loss: 1.7378262601872927

Epoch: 6| Step: 2
Training loss: 0.9746912121772766
Validation loss: 1.754146634891469

Epoch: 6| Step: 3
Training loss: 0.5782430768013
Validation loss: 1.7750911904919533

Epoch: 6| Step: 4
Training loss: 0.6152428388595581
Validation loss: 1.7733444962450253

Epoch: 6| Step: 5
Training loss: 1.1149661540985107
Validation loss: 1.7365595358674244

Epoch: 6| Step: 6
Training loss: 0.5459417700767517
Validation loss: 1.7426890967994608

Epoch: 6| Step: 7
Training loss: 0.5708441734313965
Validation loss: 1.7140882502319992

Epoch: 6| Step: 8
Training loss: 0.5973377227783203
Validation loss: 1.7346112830664522

Epoch: 6| Step: 9
Training loss: 0.6848214864730835
Validation loss: 1.7180897215361237

Epoch: 6| Step: 10
Training loss: 0.8947932720184326
Validation loss: 1.710751341235253

Epoch: 6| Step: 11
Training loss: 0.4369393587112427
Validation loss: 1.702224580190515

Epoch: 6| Step: 12
Training loss: 0.7974271774291992
Validation loss: 1.7655781033218547

Epoch: 6| Step: 13
Training loss: 0.4867384135723114
Validation loss: 1.7554710552256594

Epoch: 243| Step: 0
Training loss: 0.4947648048400879
Validation loss: 1.742464365497712

Epoch: 6| Step: 1
Training loss: 0.605710506439209
Validation loss: 1.7177965987113215

Epoch: 6| Step: 2
Training loss: 0.895346999168396
Validation loss: 1.7154477091245754

Epoch: 6| Step: 3
Training loss: 0.5021342635154724
Validation loss: 1.7055423093098465

Epoch: 6| Step: 4
Training loss: 0.7187928557395935
Validation loss: 1.702456856286654

Epoch: 6| Step: 5
Training loss: 0.9283992052078247
Validation loss: 1.7026860521685692

Epoch: 6| Step: 6
Training loss: 0.9412902593612671
Validation loss: 1.710447758756658

Epoch: 6| Step: 7
Training loss: 0.9775010347366333
Validation loss: 1.7200097095581792

Epoch: 6| Step: 8
Training loss: 0.7166643142700195
Validation loss: 1.7267858674449306

Epoch: 6| Step: 9
Training loss: 0.44808363914489746
Validation loss: 1.7307744654276038

Epoch: 6| Step: 10
Training loss: 0.6320286989212036
Validation loss: 1.756843589967297

Epoch: 6| Step: 11
Training loss: 0.6795558333396912
Validation loss: 1.7877663181674095

Epoch: 6| Step: 12
Training loss: 0.6596648693084717
Validation loss: 1.8326107507110925

Epoch: 6| Step: 13
Training loss: 0.734640896320343
Validation loss: 1.8248223912331365

Epoch: 244| Step: 0
Training loss: 0.7601651549339294
Validation loss: 1.7913523386883479

Epoch: 6| Step: 1
Training loss: 0.8201833963394165
Validation loss: 1.7444088638469737

Epoch: 6| Step: 2
Training loss: 0.40856337547302246
Validation loss: 1.737020496399172

Epoch: 6| Step: 3
Training loss: 0.8804477453231812
Validation loss: 1.6762163639068604

Epoch: 6| Step: 4
Training loss: 0.6445660591125488
Validation loss: 1.687210585481377

Epoch: 6| Step: 5
Training loss: 0.7799806594848633
Validation loss: 1.7073517948068597

Epoch: 6| Step: 6
Training loss: 0.9791508913040161
Validation loss: 1.6891869973110896

Epoch: 6| Step: 7
Training loss: 1.0213005542755127
Validation loss: 1.7119179246246174

Epoch: 6| Step: 8
Training loss: 0.595803439617157
Validation loss: 1.7083286905801425

Epoch: 6| Step: 9
Training loss: 0.5401012897491455
Validation loss: 1.7458019705228909

Epoch: 6| Step: 10
Training loss: 0.6922460794448853
Validation loss: 1.7845054634155766

Epoch: 6| Step: 11
Training loss: 0.6982540488243103
Validation loss: 1.8306444985892183

Epoch: 6| Step: 12
Training loss: 0.7628170251846313
Validation loss: 1.8505210876464844

Epoch: 6| Step: 13
Training loss: 0.30289921164512634
Validation loss: 1.8391499929530646

Epoch: 245| Step: 0
Training loss: 0.7149416208267212
Validation loss: 1.8211593845839142

Epoch: 6| Step: 1
Training loss: 0.6393662691116333
Validation loss: 1.7894441619996102

Epoch: 6| Step: 2
Training loss: 0.7124460935592651
Validation loss: 1.7769718016347578

Epoch: 6| Step: 3
Training loss: 0.5695918798446655
Validation loss: 1.7161886281864618

Epoch: 6| Step: 4
Training loss: 0.5647401809692383
Validation loss: 1.676982270774021

Epoch: 6| Step: 5
Training loss: 0.5802949666976929
Validation loss: 1.7165677598727647

Epoch: 6| Step: 6
Training loss: 0.9087313413619995
Validation loss: 1.737401831534601

Epoch: 6| Step: 7
Training loss: 0.7619310617446899
Validation loss: 1.7382761906552058

Epoch: 6| Step: 8
Training loss: 1.2116546630859375
Validation loss: 1.7525290430233043

Epoch: 6| Step: 9
Training loss: 0.9819046854972839
Validation loss: 1.7303803838709348

Epoch: 6| Step: 10
Training loss: 0.484891414642334
Validation loss: 1.6887683304407264

Epoch: 6| Step: 11
Training loss: 0.8357020616531372
Validation loss: 1.7007993844247633

Epoch: 6| Step: 12
Training loss: 0.9358468055725098
Validation loss: 1.7137737658716017

Epoch: 6| Step: 13
Training loss: 0.5733633041381836
Validation loss: 1.7043221612130441

Epoch: 246| Step: 0
Training loss: 0.629417896270752
Validation loss: 1.7033157079450545

Epoch: 6| Step: 1
Training loss: 0.898334801197052
Validation loss: 1.766509929010945

Epoch: 6| Step: 2
Training loss: 0.9409782290458679
Validation loss: 1.7890753105122557

Epoch: 6| Step: 3
Training loss: 0.5210151672363281
Validation loss: 1.8223984062030751

Epoch: 6| Step: 4
Training loss: 0.6289541721343994
Validation loss: 1.8246044676790956

Epoch: 6| Step: 5
Training loss: 0.7406545281410217
Validation loss: 1.8145432677320255

Epoch: 6| Step: 6
Training loss: 0.7351493239402771
Validation loss: 1.7321709497000581

Epoch: 6| Step: 7
Training loss: 0.794340193271637
Validation loss: 1.7206968043440132

Epoch: 6| Step: 8
Training loss: 0.30645430088043213
Validation loss: 1.712948804260582

Epoch: 6| Step: 9
Training loss: 0.854505717754364
Validation loss: 1.6766874213372507

Epoch: 6| Step: 10
Training loss: 0.9154757857322693
Validation loss: 1.6930286820216844

Epoch: 6| Step: 11
Training loss: 0.572023868560791
Validation loss: 1.6833822381111883

Epoch: 6| Step: 12
Training loss: 0.5210787057876587
Validation loss: 1.6935594415151944

Epoch: 6| Step: 13
Training loss: 0.7349298000335693
Validation loss: 1.7137125153695383

Epoch: 247| Step: 0
Training loss: 0.9030388593673706
Validation loss: 1.7095739123641804

Epoch: 6| Step: 1
Training loss: 0.7017273902893066
Validation loss: 1.6927620826228973

Epoch: 6| Step: 2
Training loss: 0.7406473159790039
Validation loss: 1.6748775525759625

Epoch: 6| Step: 3
Training loss: 1.1112871170043945
Validation loss: 1.6817096625604937

Epoch: 6| Step: 4
Training loss: 0.5050473213195801
Validation loss: 1.6525394429442704

Epoch: 6| Step: 5
Training loss: 0.8896925449371338
Validation loss: 1.6725858296117475

Epoch: 6| Step: 6
Training loss: 0.5007678866386414
Validation loss: 1.6832630403580204

Epoch: 6| Step: 7
Training loss: 0.4451180696487427
Validation loss: 1.6615958303533576

Epoch: 6| Step: 8
Training loss: 0.8423216342926025
Validation loss: 1.6656451827736312

Epoch: 6| Step: 9
Training loss: 0.6032282114028931
Validation loss: 1.7109854349526026

Epoch: 6| Step: 10
Training loss: 0.5885698795318604
Validation loss: 1.7205912733590731

Epoch: 6| Step: 11
Training loss: 0.22466330230236053
Validation loss: 1.7476123763668923

Epoch: 6| Step: 12
Training loss: 0.7260029315948486
Validation loss: 1.7387407582293275

Epoch: 6| Step: 13
Training loss: 0.6745988130569458
Validation loss: 1.691260181447511

Epoch: 248| Step: 0
Training loss: 0.7615249156951904
Validation loss: 1.6506117992503668

Epoch: 6| Step: 1
Training loss: 0.4323953092098236
Validation loss: 1.663353689255253

Epoch: 6| Step: 2
Training loss: 0.6904369592666626
Validation loss: 1.6735569495026783

Epoch: 6| Step: 3
Training loss: 0.4633927047252655
Validation loss: 1.6553798388409358

Epoch: 6| Step: 4
Training loss: 0.629682719707489
Validation loss: 1.6824081815699095

Epoch: 6| Step: 5
Training loss: 0.8206708431243896
Validation loss: 1.6777690546486967

Epoch: 6| Step: 6
Training loss: 0.7284517288208008
Validation loss: 1.673089704205913

Epoch: 6| Step: 7
Training loss: 0.752727746963501
Validation loss: 1.6609601141304098

Epoch: 6| Step: 8
Training loss: 0.4053129553794861
Validation loss: 1.6618244891525598

Epoch: 6| Step: 9
Training loss: 0.9723390936851501
Validation loss: 1.6686101741688226

Epoch: 6| Step: 10
Training loss: 0.9521479606628418
Validation loss: 1.6808269267441125

Epoch: 6| Step: 11
Training loss: 0.8582813739776611
Validation loss: 1.682867682108315

Epoch: 6| Step: 12
Training loss: 0.7820627689361572
Validation loss: 1.7654830794180594

Epoch: 6| Step: 13
Training loss: 0.28462520241737366
Validation loss: 1.7416966064001924

Epoch: 249| Step: 0
Training loss: 0.6744066476821899
Validation loss: 1.7964643188702163

Epoch: 6| Step: 1
Training loss: 0.7011109590530396
Validation loss: 1.7317296215282973

Epoch: 6| Step: 2
Training loss: 0.5308815240859985
Validation loss: 1.728767320673953

Epoch: 6| Step: 3
Training loss: 0.20882907509803772
Validation loss: 1.7239430437805832

Epoch: 6| Step: 4
Training loss: 0.7194943428039551
Validation loss: 1.7389287423062068

Epoch: 6| Step: 5
Training loss: 0.3698475658893585
Validation loss: 1.7395132151983117

Epoch: 6| Step: 6
Training loss: 0.7347615957260132
Validation loss: 1.7406513537130048

Epoch: 6| Step: 7
Training loss: 0.9664678573608398
Validation loss: 1.7477144272096696

Epoch: 6| Step: 8
Training loss: 0.8305413722991943
Validation loss: 1.7608041045486287

Epoch: 6| Step: 9
Training loss: 0.989389181137085
Validation loss: 1.7378718199268464

Epoch: 6| Step: 10
Training loss: 0.4756031036376953
Validation loss: 1.701070236903365

Epoch: 6| Step: 11
Training loss: 0.62115478515625
Validation loss: 1.7435880527701428

Epoch: 6| Step: 12
Training loss: 0.8770365715026855
Validation loss: 1.6970804237550305

Epoch: 6| Step: 13
Training loss: 0.6592119932174683
Validation loss: 1.7322892219789567

Epoch: 250| Step: 0
Training loss: 0.5871901512145996
Validation loss: 1.678749329300337

Epoch: 6| Step: 1
Training loss: 0.46270865201950073
Validation loss: 1.6709917668373353

Epoch: 6| Step: 2
Training loss: 0.8204625248908997
Validation loss: 1.6483183227559572

Epoch: 6| Step: 3
Training loss: 0.8626066446304321
Validation loss: 1.6638023340573875

Epoch: 6| Step: 4
Training loss: 0.6268205046653748
Validation loss: 1.6481029551516297

Epoch: 6| Step: 5
Training loss: 0.755638599395752
Validation loss: 1.6936663812206638

Epoch: 6| Step: 6
Training loss: 0.8259757161140442
Validation loss: 1.742653630113089

Epoch: 6| Step: 7
Training loss: 0.5806223154067993
Validation loss: 1.748853365580241

Epoch: 6| Step: 8
Training loss: 1.0539613962173462
Validation loss: 1.768448716850691

Epoch: 6| Step: 9
Training loss: 0.7289714217185974
Validation loss: 1.696595968738679

Epoch: 6| Step: 10
Training loss: 0.736885666847229
Validation loss: 1.6877988538434427

Epoch: 6| Step: 11
Training loss: 0.370561808347702
Validation loss: 1.6680090978581419

Epoch: 6| Step: 12
Training loss: 0.39097216725349426
Validation loss: 1.6578426117538123

Epoch: 6| Step: 13
Training loss: 0.5227309465408325
Validation loss: 1.6507705937149704

Epoch: 251| Step: 0
Training loss: 1.075595498085022
Validation loss: 1.6613329431062103

Epoch: 6| Step: 1
Training loss: 0.8959331512451172
Validation loss: 1.659199946670122

Epoch: 6| Step: 2
Training loss: 0.7603092193603516
Validation loss: 1.6865103321690713

Epoch: 6| Step: 3
Training loss: 0.6092086434364319
Validation loss: 1.7439623622484104

Epoch: 6| Step: 4
Training loss: 0.33959317207336426
Validation loss: 1.751778708991184

Epoch: 6| Step: 5
Training loss: 0.8069902658462524
Validation loss: 1.7798560165589856

Epoch: 6| Step: 6
Training loss: 0.31782910227775574
Validation loss: 1.7529863388307634

Epoch: 6| Step: 7
Training loss: 0.46205490827560425
Validation loss: 1.7564006659292406

Epoch: 6| Step: 8
Training loss: 0.4834299087524414
Validation loss: 1.7063062921647103

Epoch: 6| Step: 9
Training loss: 0.5661928057670593
Validation loss: 1.7300136038052139

Epoch: 6| Step: 10
Training loss: 0.6075427532196045
Validation loss: 1.7087132584664129

Epoch: 6| Step: 11
Training loss: 0.8224098682403564
Validation loss: 1.6975110717999038

Epoch: 6| Step: 12
Training loss: 0.967309832572937
Validation loss: 1.6671515459655433

Epoch: 6| Step: 13
Training loss: 0.3495804965496063
Validation loss: 1.6769940878755303

Epoch: 252| Step: 0
Training loss: 0.431195467710495
Validation loss: 1.6434092137121386

Epoch: 6| Step: 1
Training loss: 0.3746926784515381
Validation loss: 1.6848770956839285

Epoch: 6| Step: 2
Training loss: 0.7304334044456482
Validation loss: 1.6503826725867488

Epoch: 6| Step: 3
Training loss: 0.662047266960144
Validation loss: 1.6958760740936443

Epoch: 6| Step: 4
Training loss: 0.5532261729240417
Validation loss: 1.6781978363631873

Epoch: 6| Step: 5
Training loss: 1.0050065517425537
Validation loss: 1.6685250830906693

Epoch: 6| Step: 6
Training loss: 0.8450594544410706
Validation loss: 1.665169858163403

Epoch: 6| Step: 7
Training loss: 0.45054182410240173
Validation loss: 1.6571478125869588

Epoch: 6| Step: 8
Training loss: 0.567188024520874
Validation loss: 1.6738460717662689

Epoch: 6| Step: 9
Training loss: 0.7071508765220642
Validation loss: 1.6902897973214426

Epoch: 6| Step: 10
Training loss: 0.636520504951477
Validation loss: 1.6618403529608121

Epoch: 6| Step: 11
Training loss: 0.7334533929824829
Validation loss: 1.6726842964849165

Epoch: 6| Step: 12
Training loss: 0.6737028360366821
Validation loss: 1.6533348688515284

Epoch: 6| Step: 13
Training loss: 0.7198100686073303
Validation loss: 1.6577930578621485

Epoch: 253| Step: 0
Training loss: 0.5983916521072388
Validation loss: 1.7133188696317776

Epoch: 6| Step: 1
Training loss: 0.39532357454299927
Validation loss: 1.711053648302632

Epoch: 6| Step: 2
Training loss: 0.7141728401184082
Validation loss: 1.7480115300865584

Epoch: 6| Step: 3
Training loss: 0.4439104199409485
Validation loss: 1.738650256587613

Epoch: 6| Step: 4
Training loss: 0.5895560383796692
Validation loss: 1.6963747957701325

Epoch: 6| Step: 5
Training loss: 0.575739324092865
Validation loss: 1.6862776471722511

Epoch: 6| Step: 6
Training loss: 0.724454402923584
Validation loss: 1.6705246458771408

Epoch: 6| Step: 7
Training loss: 0.5372570753097534
Validation loss: 1.6566319863001506

Epoch: 6| Step: 8
Training loss: 0.5284025073051453
Validation loss: 1.6464780248621458

Epoch: 6| Step: 9
Training loss: 0.7368185520172119
Validation loss: 1.6609782313787809

Epoch: 6| Step: 10
Training loss: 0.8649650812149048
Validation loss: 1.6534268176683815

Epoch: 6| Step: 11
Training loss: 0.6806014180183411
Validation loss: 1.6714270704536027

Epoch: 6| Step: 12
Training loss: 0.7613097429275513
Validation loss: 1.6832191572394422

Epoch: 6| Step: 13
Training loss: 0.9275362491607666
Validation loss: 1.6666451231125863

Epoch: 254| Step: 0
Training loss: 0.6604512929916382
Validation loss: 1.6706731216881865

Epoch: 6| Step: 1
Training loss: 0.842765212059021
Validation loss: 1.6924207748905304

Epoch: 6| Step: 2
Training loss: 0.811747670173645
Validation loss: 1.6518400612697806

Epoch: 6| Step: 3
Training loss: 0.5442473888397217
Validation loss: 1.7129289783457273

Epoch: 6| Step: 4
Training loss: 0.46133169531822205
Validation loss: 1.6763553824476016

Epoch: 6| Step: 5
Training loss: 0.6603976488113403
Validation loss: 1.6881077187035674

Epoch: 6| Step: 6
Training loss: 0.2871846854686737
Validation loss: 1.7130535341078235

Epoch: 6| Step: 7
Training loss: 0.4121285080909729
Validation loss: 1.7232757319686234

Epoch: 6| Step: 8
Training loss: 0.8826085329055786
Validation loss: 1.6884713057548768

Epoch: 6| Step: 9
Training loss: 0.7314103841781616
Validation loss: 1.6887401534665016

Epoch: 6| Step: 10
Training loss: 0.5122088193893433
Validation loss: 1.6884863030525945

Epoch: 6| Step: 11
Training loss: 0.8606173992156982
Validation loss: 1.679835569474005

Epoch: 6| Step: 12
Training loss: 0.6095395088195801
Validation loss: 1.6964795153628114

Epoch: 6| Step: 13
Training loss: 0.4351976811885834
Validation loss: 1.6930961954978205

Epoch: 255| Step: 0
Training loss: 0.6502455472946167
Validation loss: 1.674107390065347

Epoch: 6| Step: 1
Training loss: 0.9323196411132812
Validation loss: 1.7255370591276435

Epoch: 6| Step: 2
Training loss: 0.742129921913147
Validation loss: 1.7761542361269715

Epoch: 6| Step: 3
Training loss: 0.9301021099090576
Validation loss: 1.7979112799449632

Epoch: 6| Step: 4
Training loss: 0.6785510182380676
Validation loss: 1.7426807303582468

Epoch: 6| Step: 5
Training loss: 0.5761266946792603
Validation loss: 1.7594388223463489

Epoch: 6| Step: 6
Training loss: 0.4053623378276825
Validation loss: 1.7374462113585523

Epoch: 6| Step: 7
Training loss: 0.6309316754341125
Validation loss: 1.6881761397084882

Epoch: 6| Step: 8
Training loss: 0.29044193029403687
Validation loss: 1.6693077651403283

Epoch: 6| Step: 9
Training loss: 0.6979451775550842
Validation loss: 1.6651028945881834

Epoch: 6| Step: 10
Training loss: 0.7966185808181763
Validation loss: 1.683218809866136

Epoch: 6| Step: 11
Training loss: 0.5057573318481445
Validation loss: 1.6710150241851807

Epoch: 6| Step: 12
Training loss: 0.46720048785209656
Validation loss: 1.6879471002086517

Epoch: 6| Step: 13
Training loss: 0.2719137966632843
Validation loss: 1.7002644026151268

Epoch: 256| Step: 0
Training loss: 0.4243539571762085
Validation loss: 1.7592626669073617

Epoch: 6| Step: 1
Training loss: 0.46676021814346313
Validation loss: 1.7812305547857796

Epoch: 6| Step: 2
Training loss: 0.5238784551620483
Validation loss: 1.81400268308578

Epoch: 6| Step: 3
Training loss: 0.26034849882125854
Validation loss: 1.773744648502719

Epoch: 6| Step: 4
Training loss: 0.6759164333343506
Validation loss: 1.7512631518866426

Epoch: 6| Step: 5
Training loss: 0.8064223527908325
Validation loss: 1.684229850769043

Epoch: 6| Step: 6
Training loss: 0.9607181549072266
Validation loss: 1.728769584368634

Epoch: 6| Step: 7
Training loss: 0.3609311580657959
Validation loss: 1.669076285695517

Epoch: 6| Step: 8
Training loss: 0.6029075384140015
Validation loss: 1.6930044043448664

Epoch: 6| Step: 9
Training loss: 0.7132976651191711
Validation loss: 1.7008652558890722

Epoch: 6| Step: 10
Training loss: 0.7130448818206787
Validation loss: 1.6987457788118752

Epoch: 6| Step: 11
Training loss: 0.4345252513885498
Validation loss: 1.7238961842752272

Epoch: 6| Step: 12
Training loss: 0.930591881275177
Validation loss: 1.74304913320849

Epoch: 6| Step: 13
Training loss: 0.6582732200622559
Validation loss: 1.7011167951809463

Epoch: 257| Step: 0
Training loss: 0.528561532497406
Validation loss: 1.702472863658782

Epoch: 6| Step: 1
Training loss: 0.5134119987487793
Validation loss: 1.7228842217435119

Epoch: 6| Step: 2
Training loss: 0.6671726703643799
Validation loss: 1.6878213151808708

Epoch: 6| Step: 3
Training loss: 0.486869215965271
Validation loss: 1.7188203924445695

Epoch: 6| Step: 4
Training loss: 0.621220052242279
Validation loss: 1.767708372044307

Epoch: 6| Step: 5
Training loss: 0.7999028563499451
Validation loss: 1.7781415575294084

Epoch: 6| Step: 6
Training loss: 0.3711520731449127
Validation loss: 1.7688863469708351

Epoch: 6| Step: 7
Training loss: 0.6849404573440552
Validation loss: 1.709111587975615

Epoch: 6| Step: 8
Training loss: 0.7297120094299316
Validation loss: 1.656636332952848

Epoch: 6| Step: 9
Training loss: 0.5984879732131958
Validation loss: 1.6303217757132746

Epoch: 6| Step: 10
Training loss: 0.6909436583518982
Validation loss: 1.6744821981717182

Epoch: 6| Step: 11
Training loss: 0.6002410650253296
Validation loss: 1.703706475996202

Epoch: 6| Step: 12
Training loss: 0.38621005415916443
Validation loss: 1.7245144754327753

Epoch: 6| Step: 13
Training loss: 0.6907467246055603
Validation loss: 1.76680205457954

Epoch: 258| Step: 0
Training loss: 0.7748898267745972
Validation loss: 1.7809955009850122

Epoch: 6| Step: 1
Training loss: 0.5607554912567139
Validation loss: 1.677278080294209

Epoch: 6| Step: 2
Training loss: 0.346391499042511
Validation loss: 1.6451987066576559

Epoch: 6| Step: 3
Training loss: 0.6453273296356201
Validation loss: 1.6678802774798485

Epoch: 6| Step: 4
Training loss: 0.523587703704834
Validation loss: 1.6366999982505717

Epoch: 6| Step: 5
Training loss: 0.6687092781066895
Validation loss: 1.6413346182915471

Epoch: 6| Step: 6
Training loss: 0.40034425258636475
Validation loss: 1.642165296821184

Epoch: 6| Step: 7
Training loss: 0.68547523021698
Validation loss: 1.6375166036749398

Epoch: 6| Step: 8
Training loss: 0.6231054067611694
Validation loss: 1.6129285033031175

Epoch: 6| Step: 9
Training loss: 0.914494514465332
Validation loss: 1.6383945147196453

Epoch: 6| Step: 10
Training loss: 0.6092860698699951
Validation loss: 1.6595832647815827

Epoch: 6| Step: 11
Training loss: 0.7071857452392578
Validation loss: 1.6727176417586624

Epoch: 6| Step: 12
Training loss: 0.4797884225845337
Validation loss: 1.7127433874273812

Epoch: 6| Step: 13
Training loss: 0.505243718624115
Validation loss: 1.7351486605982627

Epoch: 259| Step: 0
Training loss: 0.6410930156707764
Validation loss: 1.7713609869762132

Epoch: 6| Step: 1
Training loss: 0.7907843589782715
Validation loss: 1.8388979986149778

Epoch: 6| Step: 2
Training loss: 0.9197570085525513
Validation loss: 1.7836305813122821

Epoch: 6| Step: 3
Training loss: 0.8897199630737305
Validation loss: 1.7079956954525364

Epoch: 6| Step: 4
Training loss: 0.506589412689209
Validation loss: 1.6343284242896623

Epoch: 6| Step: 5
Training loss: 0.6586126089096069
Validation loss: 1.6172387516626747

Epoch: 6| Step: 6
Training loss: 0.624204695224762
Validation loss: 1.6159383584094305

Epoch: 6| Step: 7
Training loss: 0.567453145980835
Validation loss: 1.6455441700514926

Epoch: 6| Step: 8
Training loss: 0.5733316540718079
Validation loss: 1.5862015152490267

Epoch: 6| Step: 9
Training loss: 0.5839530825614929
Validation loss: 1.6420468412419802

Epoch: 6| Step: 10
Training loss: 0.690758466720581
Validation loss: 1.628201557743934

Epoch: 6| Step: 11
Training loss: 0.6668663024902344
Validation loss: 1.6295013773825862

Epoch: 6| Step: 12
Training loss: 0.3509470224380493
Validation loss: 1.6747908720406153

Epoch: 6| Step: 13
Training loss: 0.7323316335678101
Validation loss: 1.6552502826977802

Epoch: 260| Step: 0
Training loss: 0.35612741112709045
Validation loss: 1.6593893753584994

Epoch: 6| Step: 1
Training loss: 0.6209771633148193
Validation loss: 1.6821105518648702

Epoch: 6| Step: 2
Training loss: 0.7230367660522461
Validation loss: 1.6939990071840183

Epoch: 6| Step: 3
Training loss: 0.5111454725265503
Validation loss: 1.7254930439815725

Epoch: 6| Step: 4
Training loss: 0.736177921295166
Validation loss: 1.7080449596528084

Epoch: 6| Step: 5
Training loss: 0.8368107676506042
Validation loss: 1.704063787255236

Epoch: 6| Step: 6
Training loss: 0.7880469560623169
Validation loss: 1.665762439850838

Epoch: 6| Step: 7
Training loss: 0.46225664019584656
Validation loss: 1.7090501875005744

Epoch: 6| Step: 8
Training loss: 0.6734983921051025
Validation loss: 1.6823033837861912

Epoch: 6| Step: 9
Training loss: 0.48703354597091675
Validation loss: 1.7206965287526448

Epoch: 6| Step: 10
Training loss: 0.42435866594314575
Validation loss: 1.7087714325997136

Epoch: 6| Step: 11
Training loss: 0.6125542521476746
Validation loss: 1.7023481220327399

Epoch: 6| Step: 12
Training loss: 0.5896030068397522
Validation loss: 1.6576157295575706

Epoch: 6| Step: 13
Training loss: 1.4103870391845703
Validation loss: 1.6516993930262904

Epoch: 261| Step: 0
Training loss: 0.5855460166931152
Validation loss: 1.6629587052970805

Epoch: 6| Step: 1
Training loss: 0.8551528453826904
Validation loss: 1.7660663480399756

Epoch: 6| Step: 2
Training loss: 0.5104019641876221
Validation loss: 1.8463566482708018

Epoch: 6| Step: 3
Training loss: 0.7370278239250183
Validation loss: 1.8459773166205293

Epoch: 6| Step: 4
Training loss: 0.7374618053436279
Validation loss: 1.7832142447912565

Epoch: 6| Step: 5
Training loss: 0.37396395206451416
Validation loss: 1.7531749843269266

Epoch: 6| Step: 6
Training loss: 0.7513556480407715
Validation loss: 1.6592025513290076

Epoch: 6| Step: 7
Training loss: 0.27753543853759766
Validation loss: 1.6280305052316317

Epoch: 6| Step: 8
Training loss: 0.8950365781784058
Validation loss: 1.637967921072437

Epoch: 6| Step: 9
Training loss: 0.6966292858123779
Validation loss: 1.6301411095485892

Epoch: 6| Step: 10
Training loss: 0.4665646553039551
Validation loss: 1.663033611030989

Epoch: 6| Step: 11
Training loss: 0.36977601051330566
Validation loss: 1.6486051454338977

Epoch: 6| Step: 12
Training loss: 0.586895227432251
Validation loss: 1.644384689228509

Epoch: 6| Step: 13
Training loss: 0.7992947697639465
Validation loss: 1.6337296962738037

Epoch: 262| Step: 0
Training loss: 0.36030691862106323
Validation loss: 1.6327331373768468

Epoch: 6| Step: 1
Training loss: 0.658867359161377
Validation loss: 1.6348336742770286

Epoch: 6| Step: 2
Training loss: 0.3808223605155945
Validation loss: 1.6209757751034153

Epoch: 6| Step: 3
Training loss: 0.588431715965271
Validation loss: 1.683603976362495

Epoch: 6| Step: 4
Training loss: 0.4463479518890381
Validation loss: 1.6791429468380508

Epoch: 6| Step: 5
Training loss: 0.5134317278862
Validation loss: 1.687877126919326

Epoch: 6| Step: 6
Training loss: 0.7940717935562134
Validation loss: 1.6418131756526169

Epoch: 6| Step: 7
Training loss: 0.9362086653709412
Validation loss: 1.601978221247273

Epoch: 6| Step: 8
Training loss: 0.28057944774627686
Validation loss: 1.5911052611566359

Epoch: 6| Step: 9
Training loss: 0.5436185002326965
Validation loss: 1.6005133787790935

Epoch: 6| Step: 10
Training loss: 0.8605889081954956
Validation loss: 1.5828675723844958

Epoch: 6| Step: 11
Training loss: 0.7028872966766357
Validation loss: 1.5990727921967864

Epoch: 6| Step: 12
Training loss: 0.9257172346115112
Validation loss: 1.6423880477105417

Epoch: 6| Step: 13
Training loss: 0.6026776432991028
Validation loss: 1.6279720208978141

Epoch: 263| Step: 0
Training loss: 0.7131881713867188
Validation loss: 1.6508812853085097

Epoch: 6| Step: 1
Training loss: 0.6454483270645142
Validation loss: 1.6205911802989181

Epoch: 6| Step: 2
Training loss: 0.463051974773407
Validation loss: 1.6254698717465965

Epoch: 6| Step: 3
Training loss: 0.5787910223007202
Validation loss: 1.6157580325680394

Epoch: 6| Step: 4
Training loss: 0.5334526896476746
Validation loss: 1.6101099073245961

Epoch: 6| Step: 5
Training loss: 0.3681066036224365
Validation loss: 1.6097656398691156

Epoch: 6| Step: 6
Training loss: 0.42339906096458435
Validation loss: 1.6561278425237185

Epoch: 6| Step: 7
Training loss: 0.4447013735771179
Validation loss: 1.644297029382439

Epoch: 6| Step: 8
Training loss: 0.7323036193847656
Validation loss: 1.6523607238646476

Epoch: 6| Step: 9
Training loss: 0.5067218542098999
Validation loss: 1.6548681310428086

Epoch: 6| Step: 10
Training loss: 0.57643061876297
Validation loss: 1.647994734907663

Epoch: 6| Step: 11
Training loss: 0.7670048475265503
Validation loss: 1.634092959024573

Epoch: 6| Step: 12
Training loss: 0.7759699821472168
Validation loss: 1.6130821627955283

Epoch: 6| Step: 13
Training loss: 0.6942158937454224
Validation loss: 1.6136406326806674

Epoch: 264| Step: 0
Training loss: 0.5913636684417725
Validation loss: 1.6278971138820852

Epoch: 6| Step: 1
Training loss: 0.5251853466033936
Validation loss: 1.6518888396601523

Epoch: 6| Step: 2
Training loss: 0.4400738477706909
Validation loss: 1.6488206271202333

Epoch: 6| Step: 3
Training loss: 0.40221986174583435
Validation loss: 1.6681041435528827

Epoch: 6| Step: 4
Training loss: 0.8603224754333496
Validation loss: 1.6527058450124597

Epoch: 6| Step: 5
Training loss: 0.48068806529045105
Validation loss: 1.6542612775679557

Epoch: 6| Step: 6
Training loss: 0.7025247812271118
Validation loss: 1.6127026414358487

Epoch: 6| Step: 7
Training loss: 0.5615721344947815
Validation loss: 1.6352529878257422

Epoch: 6| Step: 8
Training loss: 0.5283622145652771
Validation loss: 1.6123140781156478

Epoch: 6| Step: 9
Training loss: 0.5723764896392822
Validation loss: 1.6072265217381139

Epoch: 6| Step: 10
Training loss: 0.46629250049591064
Validation loss: 1.641882073494696

Epoch: 6| Step: 11
Training loss: 0.17740444839000702
Validation loss: 1.6335285017567296

Epoch: 6| Step: 12
Training loss: 0.5284236669540405
Validation loss: 1.6243470663665442

Epoch: 6| Step: 13
Training loss: 1.0077654123306274
Validation loss: 1.635385735060579

Epoch: 265| Step: 0
Training loss: 0.7713389992713928
Validation loss: 1.6641105362164077

Epoch: 6| Step: 1
Training loss: 0.3435083031654358
Validation loss: 1.6791461654888686

Epoch: 6| Step: 2
Training loss: 0.7956587076187134
Validation loss: 1.6762768081439439

Epoch: 6| Step: 3
Training loss: 0.6471821069717407
Validation loss: 1.7152290087874218

Epoch: 6| Step: 4
Training loss: 0.5445689558982849
Validation loss: 1.8068188326333159

Epoch: 6| Step: 5
Training loss: 0.7890918254852295
Validation loss: 1.8323402840604064

Epoch: 6| Step: 6
Training loss: 0.5829266905784607
Validation loss: 1.7716281516577608

Epoch: 6| Step: 7
Training loss: 0.42836490273475647
Validation loss: 1.7184679213390555

Epoch: 6| Step: 8
Training loss: 0.590786874294281
Validation loss: 1.6790294890762658

Epoch: 6| Step: 9
Training loss: 0.42664992809295654
Validation loss: 1.6323673161127235

Epoch: 6| Step: 10
Training loss: 0.6148374080657959
Validation loss: 1.6757332586473035

Epoch: 6| Step: 11
Training loss: 0.6565231680870056
Validation loss: 1.6568523222400295

Epoch: 6| Step: 12
Training loss: 0.796949028968811
Validation loss: 1.6404430404786141

Epoch: 6| Step: 13
Training loss: 0.36301368474960327
Validation loss: 1.663381912375009

Epoch: 266| Step: 0
Training loss: 0.39993414282798767
Validation loss: 1.6292113809175388

Epoch: 6| Step: 1
Training loss: 0.31554290652275085
Validation loss: 1.681733496727482

Epoch: 6| Step: 2
Training loss: 0.8787041306495667
Validation loss: 1.6810200855296145

Epoch: 6| Step: 3
Training loss: 0.6086053848266602
Validation loss: 1.743445093913745

Epoch: 6| Step: 4
Training loss: 0.4234457015991211
Validation loss: 1.7693529757120277

Epoch: 6| Step: 5
Training loss: 0.6050945520401001
Validation loss: 1.7670939481386574

Epoch: 6| Step: 6
Training loss: 0.6492695808410645
Validation loss: 1.673875912543266

Epoch: 6| Step: 7
Training loss: 0.5996212363243103
Validation loss: 1.6949405490711171

Epoch: 6| Step: 8
Training loss: 0.5389204025268555
Validation loss: 1.6838961288493166

Epoch: 6| Step: 9
Training loss: 0.8440302014350891
Validation loss: 1.63833604064039

Epoch: 6| Step: 10
Training loss: 0.24473837018013
Validation loss: 1.67733032472672

Epoch: 6| Step: 11
Training loss: 0.6685069799423218
Validation loss: 1.6680615486637238

Epoch: 6| Step: 12
Training loss: 0.5235142111778259
Validation loss: 1.6693984680278326

Epoch: 6| Step: 13
Training loss: 0.346807599067688
Validation loss: 1.6480406958569762

Epoch: 267| Step: 0
Training loss: 0.3383296728134155
Validation loss: 1.6543187966910742

Epoch: 6| Step: 1
Training loss: 0.5247549414634705
Validation loss: 1.6655792369637439

Epoch: 6| Step: 2
Training loss: 0.3375142216682434
Validation loss: 1.6475387773206156

Epoch: 6| Step: 3
Training loss: 0.3607933223247528
Validation loss: 1.6850424505049182

Epoch: 6| Step: 4
Training loss: 0.7225334048271179
Validation loss: 1.7221884830023653

Epoch: 6| Step: 5
Training loss: 0.5909366607666016
Validation loss: 1.6830682998062463

Epoch: 6| Step: 6
Training loss: 0.3627839684486389
Validation loss: 1.6748847000060543

Epoch: 6| Step: 7
Training loss: 0.45722031593322754
Validation loss: 1.6855474223372757

Epoch: 6| Step: 8
Training loss: 0.9697495102882385
Validation loss: 1.7032827388855718

Epoch: 6| Step: 9
Training loss: 0.3511904180049896
Validation loss: 1.734573571912704

Epoch: 6| Step: 10
Training loss: 0.5303962230682373
Validation loss: 1.7082337243582613

Epoch: 6| Step: 11
Training loss: 0.4885709285736084
Validation loss: 1.722021964288527

Epoch: 6| Step: 12
Training loss: 0.7696355581283569
Validation loss: 1.6840498755055089

Epoch: 6| Step: 13
Training loss: 0.8798940777778625
Validation loss: 1.671372631544708

Epoch: 268| Step: 0
Training loss: 0.5483243465423584
Validation loss: 1.6869485301356162

Epoch: 6| Step: 1
Training loss: 0.3093901574611664
Validation loss: 1.6807857610846078

Epoch: 6| Step: 2
Training loss: 0.5007877349853516
Validation loss: 1.6575389446750763

Epoch: 6| Step: 3
Training loss: 0.6322334408760071
Validation loss: 1.6420916934167185

Epoch: 6| Step: 4
Training loss: 0.5686719417572021
Validation loss: 1.6202145391894924

Epoch: 6| Step: 5
Training loss: 0.4443679451942444
Validation loss: 1.6026249162612423

Epoch: 6| Step: 6
Training loss: 0.7762069702148438
Validation loss: 1.6672220947921916

Epoch: 6| Step: 7
Training loss: 0.8103312253952026
Validation loss: 1.6331839074370682

Epoch: 6| Step: 8
Training loss: 0.3297199308872223
Validation loss: 1.699911904591386

Epoch: 6| Step: 9
Training loss: 0.45812782645225525
Validation loss: 1.6681297094591203

Epoch: 6| Step: 10
Training loss: 0.524605393409729
Validation loss: 1.684767048846009

Epoch: 6| Step: 11
Training loss: 0.4996441602706909
Validation loss: 1.6704286913717947

Epoch: 6| Step: 12
Training loss: 0.5413888096809387
Validation loss: 1.6718669476047638

Epoch: 6| Step: 13
Training loss: 0.2494792342185974
Validation loss: 1.6688646334473805

Epoch: 269| Step: 0
Training loss: 0.36097487807273865
Validation loss: 1.647640871745284

Epoch: 6| Step: 1
Training loss: 0.45944979786872864
Validation loss: 1.6349615960992792

Epoch: 6| Step: 2
Training loss: 0.3156897723674774
Validation loss: 1.6633363962173462

Epoch: 6| Step: 3
Training loss: 0.38180094957351685
Validation loss: 1.6501804936316706

Epoch: 6| Step: 4
Training loss: 0.7386561632156372
Validation loss: 1.683192668422576

Epoch: 6| Step: 5
Training loss: 0.29611867666244507
Validation loss: 1.685120269816409

Epoch: 6| Step: 6
Training loss: 0.30997350811958313
Validation loss: 1.6747246852485083

Epoch: 6| Step: 7
Training loss: 0.7492647171020508
Validation loss: 1.6552400345443397

Epoch: 6| Step: 8
Training loss: 0.45540744066238403
Validation loss: 1.6571214134975145

Epoch: 6| Step: 9
Training loss: 0.6934383511543274
Validation loss: 1.6355762135597967

Epoch: 6| Step: 10
Training loss: 0.7685217261314392
Validation loss: 1.6841686797398392

Epoch: 6| Step: 11
Training loss: 0.5523362159729004
Validation loss: 1.6765664341629192

Epoch: 6| Step: 12
Training loss: 0.5374200940132141
Validation loss: 1.6787499202195035

Epoch: 6| Step: 13
Training loss: 0.6580685973167419
Validation loss: 1.6629512386937295

Epoch: 270| Step: 0
Training loss: 0.42535310983657837
Validation loss: 1.7077567961908156

Epoch: 6| Step: 1
Training loss: 0.4866354465484619
Validation loss: 1.6724655948659426

Epoch: 6| Step: 2
Training loss: 0.6046179533004761
Validation loss: 1.7266047385431105

Epoch: 6| Step: 3
Training loss: 0.5683175325393677
Validation loss: 1.7030960552154049

Epoch: 6| Step: 4
Training loss: 0.3785402178764343
Validation loss: 1.7278302818216302

Epoch: 6| Step: 5
Training loss: 0.6257948875427246
Validation loss: 1.690931385563266

Epoch: 6| Step: 6
Training loss: 0.4148842692375183
Validation loss: 1.725181250162022

Epoch: 6| Step: 7
Training loss: 0.7549967169761658
Validation loss: 1.7317415424572524

Epoch: 6| Step: 8
Training loss: 0.37321555614471436
Validation loss: 1.636142264130295

Epoch: 6| Step: 9
Training loss: 0.6288447380065918
Validation loss: 1.6296584580534248

Epoch: 6| Step: 10
Training loss: 0.4054698348045349
Validation loss: 1.6125426497510684

Epoch: 6| Step: 11
Training loss: 0.4147584140300751
Validation loss: 1.6233609773779427

Epoch: 6| Step: 12
Training loss: 0.6409432888031006
Validation loss: 1.6260237398967947

Epoch: 6| Step: 13
Training loss: 0.3978857696056366
Validation loss: 1.6323068347028507

Epoch: 271| Step: 0
Training loss: 0.7425159215927124
Validation loss: 1.6445837341329104

Epoch: 6| Step: 1
Training loss: 0.4094915986061096
Validation loss: 1.6083921283803961

Epoch: 6| Step: 2
Training loss: 0.4923127591609955
Validation loss: 1.6294361570829987

Epoch: 6| Step: 3
Training loss: 0.43357643485069275
Validation loss: 1.6429744817877328

Epoch: 6| Step: 4
Training loss: 0.44217056035995483
Validation loss: 1.672045023210587

Epoch: 6| Step: 5
Training loss: 0.4339466989040375
Validation loss: 1.6877244954468102

Epoch: 6| Step: 6
Training loss: 0.44871795177459717
Validation loss: 1.6919195459735008

Epoch: 6| Step: 7
Training loss: 0.2943480610847473
Validation loss: 1.6798153167129846

Epoch: 6| Step: 8
Training loss: 0.6350519061088562
Validation loss: 1.6540973276220343

Epoch: 6| Step: 9
Training loss: 0.369407057762146
Validation loss: 1.660707425686621

Epoch: 6| Step: 10
Training loss: 0.4941733777523041
Validation loss: 1.643973805571115

Epoch: 6| Step: 11
Training loss: 0.767663836479187
Validation loss: 1.6450828442009546

Epoch: 6| Step: 12
Training loss: 0.5166193842887878
Validation loss: 1.6741617738559682

Epoch: 6| Step: 13
Training loss: 0.6638772487640381
Validation loss: 1.6623404718214465

Epoch: 272| Step: 0
Training loss: 0.4210962653160095
Validation loss: 1.6707869498960433

Epoch: 6| Step: 1
Training loss: 0.6712082028388977
Validation loss: 1.6323443715290358

Epoch: 6| Step: 2
Training loss: 0.3943081200122833
Validation loss: 1.6870683598262008

Epoch: 6| Step: 3
Training loss: 0.6484060287475586
Validation loss: 1.6487194145879438

Epoch: 6| Step: 4
Training loss: 0.3294152021408081
Validation loss: 1.6401393182816044

Epoch: 6| Step: 5
Training loss: 0.39375612139701843
Validation loss: 1.6359572820765997

Epoch: 6| Step: 6
Training loss: 0.4785376191139221
Validation loss: 1.6601260900497437

Epoch: 6| Step: 7
Training loss: 0.4353417456150055
Validation loss: 1.6240217660063057

Epoch: 6| Step: 8
Training loss: 0.6140704154968262
Validation loss: 1.6555455077079035

Epoch: 6| Step: 9
Training loss: 0.9410961270332336
Validation loss: 1.6093432852016982

Epoch: 6| Step: 10
Training loss: 0.5864643454551697
Validation loss: 1.6420905231147684

Epoch: 6| Step: 11
Training loss: 0.3673725724220276
Validation loss: 1.624406781247867

Epoch: 6| Step: 12
Training loss: 0.4642747640609741
Validation loss: 1.6339273478395195

Epoch: 6| Step: 13
Training loss: 0.2565198838710785
Validation loss: 1.6233812391117055

Epoch: 273| Step: 0
Training loss: 0.2769742012023926
Validation loss: 1.6518577221901185

Epoch: 6| Step: 1
Training loss: 0.49979668855667114
Validation loss: 1.6152673177821661

Epoch: 6| Step: 2
Training loss: 0.9314477443695068
Validation loss: 1.670494015498828

Epoch: 6| Step: 3
Training loss: 0.6006804704666138
Validation loss: 1.676481020066046

Epoch: 6| Step: 4
Training loss: 0.449959397315979
Validation loss: 1.6730396004133328

Epoch: 6| Step: 5
Training loss: 0.3898622989654541
Validation loss: 1.6542490861749137

Epoch: 6| Step: 6
Training loss: 0.6048263907432556
Validation loss: 1.634760533609698

Epoch: 6| Step: 7
Training loss: 0.3275444209575653
Validation loss: 1.5926909023715603

Epoch: 6| Step: 8
Training loss: 0.45033055543899536
Validation loss: 1.572187400633289

Epoch: 6| Step: 9
Training loss: 0.46216851472854614
Validation loss: 1.5704260679983324

Epoch: 6| Step: 10
Training loss: 0.6958295106887817
Validation loss: 1.6262897522218767

Epoch: 6| Step: 11
Training loss: 0.41360437870025635
Validation loss: 1.6037156287059988

Epoch: 6| Step: 12
Training loss: 0.3940986096858978
Validation loss: 1.6140816609064739

Epoch: 6| Step: 13
Training loss: 0.34819018840789795
Validation loss: 1.588428170450272

Epoch: 274| Step: 0
Training loss: 0.24646589159965515
Validation loss: 1.6039775597151888

Epoch: 6| Step: 1
Training loss: 0.45840224623680115
Validation loss: 1.6397707487947197

Epoch: 6| Step: 2
Training loss: 0.6225864291191101
Validation loss: 1.6373718797519643

Epoch: 6| Step: 3
Training loss: 0.562802791595459
Validation loss: 1.6844854624040666

Epoch: 6| Step: 4
Training loss: 0.7792623043060303
Validation loss: 1.6556577579949492

Epoch: 6| Step: 5
Training loss: 0.40003031492233276
Validation loss: 1.6522972006951608

Epoch: 6| Step: 6
Training loss: 0.3659360110759735
Validation loss: 1.6173259981216923

Epoch: 6| Step: 7
Training loss: 0.4562355577945709
Validation loss: 1.62194618486589

Epoch: 6| Step: 8
Training loss: 0.3191607594490051
Validation loss: 1.5839886755071662

Epoch: 6| Step: 9
Training loss: 0.42528945207595825
Validation loss: 1.5804847991594704

Epoch: 6| Step: 10
Training loss: 0.607822060585022
Validation loss: 1.5814049282381613

Epoch: 6| Step: 11
Training loss: 0.4041788876056671
Validation loss: 1.6015581597564041

Epoch: 6| Step: 12
Training loss: 0.41919034719467163
Validation loss: 1.5942628140090613

Epoch: 6| Step: 13
Training loss: 0.5362314581871033
Validation loss: 1.5974248481053177

Epoch: 275| Step: 0
Training loss: 0.6255280375480652
Validation loss: 1.6323450970393356

Epoch: 6| Step: 1
Training loss: 0.36454087495803833
Validation loss: 1.6206161540041688

Epoch: 6| Step: 2
Training loss: 0.4991567134857178
Validation loss: 1.6011772219852736

Epoch: 6| Step: 3
Training loss: 0.48740115761756897
Validation loss: 1.645774551617202

Epoch: 6| Step: 4
Training loss: 0.4272105395793915
Validation loss: 1.6294433647586453

Epoch: 6| Step: 5
Training loss: 0.42821961641311646
Validation loss: 1.6596310061793174

Epoch: 6| Step: 6
Training loss: 0.4116429090499878
Validation loss: 1.6774703097599808

Epoch: 6| Step: 7
Training loss: 0.6577290892601013
Validation loss: 1.7198619483619608

Epoch: 6| Step: 8
Training loss: 0.5820968151092529
Validation loss: 1.682394196910243

Epoch: 6| Step: 9
Training loss: 0.3230312168598175
Validation loss: 1.6980617289902062

Epoch: 6| Step: 10
Training loss: 0.3282510042190552
Validation loss: 1.665267611062655

Epoch: 6| Step: 11
Training loss: 0.49153628945350647
Validation loss: 1.6608135687407626

Epoch: 6| Step: 12
Training loss: 0.5578939914703369
Validation loss: 1.6471334311269945

Epoch: 6| Step: 13
Training loss: 0.5000515580177307
Validation loss: 1.6442157722288562

Epoch: 276| Step: 0
Training loss: 0.5430482625961304
Validation loss: 1.6529969925521522

Epoch: 6| Step: 1
Training loss: 0.49875229597091675
Validation loss: 1.632105444067268

Epoch: 6| Step: 2
Training loss: 0.3925827741622925
Validation loss: 1.70389179132318

Epoch: 6| Step: 3
Training loss: 0.42891940474510193
Validation loss: 1.7043770654227144

Epoch: 6| Step: 4
Training loss: 0.5771738290786743
Validation loss: 1.7285639983351513

Epoch: 6| Step: 5
Training loss: 0.3037564754486084
Validation loss: 1.739920537958863

Epoch: 6| Step: 6
Training loss: 0.5921587347984314
Validation loss: 1.7071695507213633

Epoch: 6| Step: 7
Training loss: 0.3831586241722107
Validation loss: 1.7416649826111332

Epoch: 6| Step: 8
Training loss: 0.6321109533309937
Validation loss: 1.7035429298236806

Epoch: 6| Step: 9
Training loss: 0.23153439164161682
Validation loss: 1.6797354272616807

Epoch: 6| Step: 10
Training loss: 0.5120618343353271
Validation loss: 1.6795811242954706

Epoch: 6| Step: 11
Training loss: 0.30050113797187805
Validation loss: 1.683770865522405

Epoch: 6| Step: 12
Training loss: 0.46982574462890625
Validation loss: 1.6513350497009933

Epoch: 6| Step: 13
Training loss: 0.4363929033279419
Validation loss: 1.6570485061214817

Epoch: 277| Step: 0
Training loss: 0.4105144739151001
Validation loss: 1.6702379449721305

Epoch: 6| Step: 1
Training loss: 0.6131646633148193
Validation loss: 1.6589409010384673

Epoch: 6| Step: 2
Training loss: 0.37569156289100647
Validation loss: 1.6791683602076706

Epoch: 6| Step: 3
Training loss: 0.44618967175483704
Validation loss: 1.649543612234054

Epoch: 6| Step: 4
Training loss: 0.34895631670951843
Validation loss: 1.6445883935497654

Epoch: 6| Step: 5
Training loss: 0.500890851020813
Validation loss: 1.6605969321343206

Epoch: 6| Step: 6
Training loss: 0.4488621950149536
Validation loss: 1.6915140113522928

Epoch: 6| Step: 7
Training loss: 0.474397748708725
Validation loss: 1.711089535426068

Epoch: 6| Step: 8
Training loss: 0.4930800199508667
Validation loss: 1.6884237463756273

Epoch: 6| Step: 9
Training loss: 0.35423076152801514
Validation loss: 1.7046539168204031

Epoch: 6| Step: 10
Training loss: 0.36716771125793457
Validation loss: 1.6679444120776268

Epoch: 6| Step: 11
Training loss: 0.424618124961853
Validation loss: 1.675409197807312

Epoch: 6| Step: 12
Training loss: 0.5288348197937012
Validation loss: 1.6834625659450408

Epoch: 6| Step: 13
Training loss: 0.847763180732727
Validation loss: 1.6805230430377427

Epoch: 278| Step: 0
Training loss: 0.49420952796936035
Validation loss: 1.7491226221925469

Epoch: 6| Step: 1
Training loss: 0.4392939805984497
Validation loss: 1.7603443848189486

Epoch: 6| Step: 2
Training loss: 0.5491690039634705
Validation loss: 1.7937646091625254

Epoch: 6| Step: 3
Training loss: 0.48208481073379517
Validation loss: 1.7371923833765008

Epoch: 6| Step: 4
Training loss: 0.43679940700531006
Validation loss: 1.6814363130959131

Epoch: 6| Step: 5
Training loss: 0.7683099508285522
Validation loss: 1.7118024749140586

Epoch: 6| Step: 6
Training loss: 0.44133129715919495
Validation loss: 1.6978701327436714

Epoch: 6| Step: 7
Training loss: 0.3944392204284668
Validation loss: 1.7075177546470397

Epoch: 6| Step: 8
Training loss: 0.43375086784362793
Validation loss: 1.712400564583399

Epoch: 6| Step: 9
Training loss: 0.41165971755981445
Validation loss: 1.695350149626373

Epoch: 6| Step: 10
Training loss: 0.3874174654483795
Validation loss: 1.6838056374621648

Epoch: 6| Step: 11
Training loss: 0.42659008502960205
Validation loss: 1.676604264525957

Epoch: 6| Step: 12
Training loss: 0.35226330161094666
Validation loss: 1.6614497733372513

Epoch: 6| Step: 13
Training loss: 0.37981027364730835
Validation loss: 1.6751685578335997

Epoch: 279| Step: 0
Training loss: 0.2593717575073242
Validation loss: 1.6691809200471448

Epoch: 6| Step: 1
Training loss: 0.5016728043556213
Validation loss: 1.7076936870492914

Epoch: 6| Step: 2
Training loss: 0.6988874077796936
Validation loss: 1.7740914898533975

Epoch: 6| Step: 3
Training loss: 0.40333378314971924
Validation loss: 1.7181424338330504

Epoch: 6| Step: 4
Training loss: 0.3767826557159424
Validation loss: 1.6822207845667356

Epoch: 6| Step: 5
Training loss: 0.3616484999656677
Validation loss: 1.6548475091175368

Epoch: 6| Step: 6
Training loss: 0.5404905080795288
Validation loss: 1.6202460642783874

Epoch: 6| Step: 7
Training loss: 0.4645026624202728
Validation loss: 1.5853387604477585

Epoch: 6| Step: 8
Training loss: 0.5756303071975708
Validation loss: 1.6123993717214113

Epoch: 6| Step: 9
Training loss: 0.3881663680076599
Validation loss: 1.6503491376035957

Epoch: 6| Step: 10
Training loss: 0.37829869985580444
Validation loss: 1.657486049077844

Epoch: 6| Step: 11
Training loss: 0.5448906421661377
Validation loss: 1.6664872887314006

Epoch: 6| Step: 12
Training loss: 0.3698086440563202
Validation loss: 1.6795040484397643

Epoch: 6| Step: 13
Training loss: 0.7252671718597412
Validation loss: 1.6947373062051752

Epoch: 280| Step: 0
Training loss: 0.30061742663383484
Validation loss: 1.6897351036789596

Epoch: 6| Step: 1
Training loss: 0.6436135768890381
Validation loss: 1.6646589630393571

Epoch: 6| Step: 2
Training loss: 0.34415924549102783
Validation loss: 1.7078036544143513

Epoch: 6| Step: 3
Training loss: 0.35141581296920776
Validation loss: 1.676474917319513

Epoch: 6| Step: 4
Training loss: 0.3284309506416321
Validation loss: 1.6851999016218289

Epoch: 6| Step: 5
Training loss: 0.5436820387840271
Validation loss: 1.6734786495085685

Epoch: 6| Step: 6
Training loss: 0.641614556312561
Validation loss: 1.6840348025803924

Epoch: 6| Step: 7
Training loss: 0.5541360378265381
Validation loss: 1.6491795573183285

Epoch: 6| Step: 8
Training loss: 0.4718768000602722
Validation loss: 1.6076161938328897

Epoch: 6| Step: 9
Training loss: 0.5549314022064209
Validation loss: 1.6291902770278275

Epoch: 6| Step: 10
Training loss: 0.5139758586883545
Validation loss: 1.602350401621993

Epoch: 6| Step: 11
Training loss: 0.5040360689163208
Validation loss: 1.6313764664434618

Epoch: 6| Step: 12
Training loss: 0.4258686900138855
Validation loss: 1.6362684067859445

Epoch: 6| Step: 13
Training loss: 0.6013886332511902
Validation loss: 1.6361009331159695

Epoch: 281| Step: 0
Training loss: 0.438689649105072
Validation loss: 1.709414546207715

Epoch: 6| Step: 1
Training loss: 0.3011949956417084
Validation loss: 1.716365493753905

Epoch: 6| Step: 2
Training loss: 0.6124398112297058
Validation loss: 1.7751378731061054

Epoch: 6| Step: 3
Training loss: 0.4317730963230133
Validation loss: 1.7783561701415687

Epoch: 6| Step: 4
Training loss: 0.40999066829681396
Validation loss: 1.7453385565870552

Epoch: 6| Step: 5
Training loss: 0.5339852571487427
Validation loss: 1.6837767106230541

Epoch: 6| Step: 6
Training loss: 0.5817065238952637
Validation loss: 1.6624228826133154

Epoch: 6| Step: 7
Training loss: 0.5387992858886719
Validation loss: 1.6561167842598372

Epoch: 6| Step: 8
Training loss: 0.3426586389541626
Validation loss: 1.6368971492654534

Epoch: 6| Step: 9
Training loss: 0.47312209010124207
Validation loss: 1.6595531971223894

Epoch: 6| Step: 10
Training loss: 0.5154637098312378
Validation loss: 1.64116786244095

Epoch: 6| Step: 11
Training loss: 0.5047181248664856
Validation loss: 1.6357257135452763

Epoch: 6| Step: 12
Training loss: 0.36422523856163025
Validation loss: 1.6264664101344284

Epoch: 6| Step: 13
Training loss: 0.6429094672203064
Validation loss: 1.5992184364667503

Epoch: 282| Step: 0
Training loss: 0.5725300312042236
Validation loss: 1.6214084368880077

Epoch: 6| Step: 1
Training loss: 0.632605254650116
Validation loss: 1.665842980466863

Epoch: 6| Step: 2
Training loss: 0.20590734481811523
Validation loss: 1.696922606037509

Epoch: 6| Step: 3
Training loss: 0.8025745749473572
Validation loss: 1.750955638065133

Epoch: 6| Step: 4
Training loss: 0.3786216378211975
Validation loss: 1.75898963533422

Epoch: 6| Step: 5
Training loss: 0.3367534577846527
Validation loss: 1.6514418753244544

Epoch: 6| Step: 6
Training loss: 0.48844608664512634
Validation loss: 1.6580882713358889

Epoch: 6| Step: 7
Training loss: 0.3816072940826416
Validation loss: 1.6637551105150612

Epoch: 6| Step: 8
Training loss: 0.6757041215896606
Validation loss: 1.633438289806407

Epoch: 6| Step: 9
Training loss: 0.25441426038742065
Validation loss: 1.670889344266666

Epoch: 6| Step: 10
Training loss: 0.33992069959640503
Validation loss: 1.6267443280066214

Epoch: 6| Step: 11
Training loss: 0.31644371151924133
Validation loss: 1.6167570762736823

Epoch: 6| Step: 12
Training loss: 0.32720696926116943
Validation loss: 1.6237954542201052

Epoch: 6| Step: 13
Training loss: 0.33654898405075073
Validation loss: 1.6218978640853718

Epoch: 283| Step: 0
Training loss: 0.25055715441703796
Validation loss: 1.6221880733325917

Epoch: 6| Step: 1
Training loss: 0.1769237518310547
Validation loss: 1.6520975610261321

Epoch: 6| Step: 2
Training loss: 0.536429762840271
Validation loss: 1.6604761692785448

Epoch: 6| Step: 3
Training loss: 0.4874991178512573
Validation loss: 1.7282539311275686

Epoch: 6| Step: 4
Training loss: 0.35978448390960693
Validation loss: 1.7025388543323805

Epoch: 6| Step: 5
Training loss: 0.5099726915359497
Validation loss: 1.6903705430287186

Epoch: 6| Step: 6
Training loss: 0.37619176506996155
Validation loss: 1.6693871046907158

Epoch: 6| Step: 7
Training loss: 0.6173615455627441
Validation loss: 1.6645363812805505

Epoch: 6| Step: 8
Training loss: 0.4048028886318207
Validation loss: 1.631583708588795

Epoch: 6| Step: 9
Training loss: 0.34872502088546753
Validation loss: 1.620007755935833

Epoch: 6| Step: 10
Training loss: 0.6886268258094788
Validation loss: 1.63270144308767

Epoch: 6| Step: 11
Training loss: 0.38432252407073975
Validation loss: 1.5958959735849851

Epoch: 6| Step: 12
Training loss: 0.6101022958755493
Validation loss: 1.5832825245395783

Epoch: 6| Step: 13
Training loss: 0.5010305047035217
Validation loss: 1.5522507877760037

Epoch: 284| Step: 0
Training loss: 0.4596256613731384
Validation loss: 1.5631738349955568

Epoch: 6| Step: 1
Training loss: 0.3106819689273834
Validation loss: 1.5737231200741184

Epoch: 6| Step: 2
Training loss: 0.4462546110153198
Validation loss: 1.592177071878987

Epoch: 6| Step: 3
Training loss: 0.6450097560882568
Validation loss: 1.6576752893386348

Epoch: 6| Step: 4
Training loss: 0.517697811126709
Validation loss: 1.6725933487697313

Epoch: 6| Step: 5
Training loss: 0.27030056715011597
Validation loss: 1.6738896780116583

Epoch: 6| Step: 6
Training loss: 0.5514638423919678
Validation loss: 1.646159723240842

Epoch: 6| Step: 7
Training loss: 0.46925610303878784
Validation loss: 1.6219286918640137

Epoch: 6| Step: 8
Training loss: 0.3721126317977905
Validation loss: 1.5988726705633185

Epoch: 6| Step: 9
Training loss: 0.3895241320133209
Validation loss: 1.6185428045129264

Epoch: 6| Step: 10
Training loss: 0.5371264219284058
Validation loss: 1.624623998518913

Epoch: 6| Step: 11
Training loss: 0.3324219584465027
Validation loss: 1.6385524016554638

Epoch: 6| Step: 12
Training loss: 0.6069463491439819
Validation loss: 1.6160557064958798

Epoch: 6| Step: 13
Training loss: 0.2953950762748718
Validation loss: 1.6048772796507804

Epoch: 285| Step: 0
Training loss: 0.41412004828453064
Validation loss: 1.6011356807524157

Epoch: 6| Step: 1
Training loss: 0.42321133613586426
Validation loss: 1.634573555761768

Epoch: 6| Step: 2
Training loss: 0.4245659410953522
Validation loss: 1.5594238171013453

Epoch: 6| Step: 3
Training loss: 0.5809386968612671
Validation loss: 1.5770019280013217

Epoch: 6| Step: 4
Training loss: 0.3539220690727234
Validation loss: 1.5937229612822175

Epoch: 6| Step: 5
Training loss: 0.26505666971206665
Validation loss: 1.5854402601077993

Epoch: 6| Step: 6
Training loss: 0.6376076936721802
Validation loss: 1.5670099873696604

Epoch: 6| Step: 7
Training loss: 0.34670454263687134
Validation loss: 1.5982221364974976

Epoch: 6| Step: 8
Training loss: 0.30805516242980957
Validation loss: 1.610760288853799

Epoch: 6| Step: 9
Training loss: 0.702290952205658
Validation loss: 1.623353123664856

Epoch: 6| Step: 10
Training loss: 0.4842230975627899
Validation loss: 1.5987942846872474

Epoch: 6| Step: 11
Training loss: 0.48924481868743896
Validation loss: 1.6206273507046443

Epoch: 6| Step: 12
Training loss: 0.42670267820358276
Validation loss: 1.6244715952104138

Epoch: 6| Step: 13
Training loss: 0.5150830745697021
Validation loss: 1.6371359543133808

Epoch: 286| Step: 0
Training loss: 0.5843602418899536
Validation loss: 1.622099240620931

Epoch: 6| Step: 1
Training loss: 0.4415096044540405
Validation loss: 1.638304700133621

Epoch: 6| Step: 2
Training loss: 0.22759224474430084
Validation loss: 1.6433270631297943

Epoch: 6| Step: 3
Training loss: 0.4021111726760864
Validation loss: 1.6301704350338186

Epoch: 6| Step: 4
Training loss: 0.41629305481910706
Validation loss: 1.6108051141103108

Epoch: 6| Step: 5
Training loss: 0.52298903465271
Validation loss: 1.634801535837112

Epoch: 6| Step: 6
Training loss: 0.5172802209854126
Validation loss: 1.6470409311274046

Epoch: 6| Step: 7
Training loss: 0.25812727212905884
Validation loss: 1.5941835859770417

Epoch: 6| Step: 8
Training loss: 0.6264361143112183
Validation loss: 1.6501002004069667

Epoch: 6| Step: 9
Training loss: 0.5538822412490845
Validation loss: 1.6087662404583347

Epoch: 6| Step: 10
Training loss: 0.39465126395225525
Validation loss: 1.658656661228467

Epoch: 6| Step: 11
Training loss: 0.36126255989074707
Validation loss: 1.6425480195271072

Epoch: 6| Step: 12
Training loss: 0.2046073079109192
Validation loss: 1.6441720890742477

Epoch: 6| Step: 13
Training loss: 0.19493968784809113
Validation loss: 1.6514670669391591

Epoch: 287| Step: 0
Training loss: 0.5688772201538086
Validation loss: 1.6377486721161874

Epoch: 6| Step: 1
Training loss: 0.3601214587688446
Validation loss: 1.652754601611886

Epoch: 6| Step: 2
Training loss: 0.3454424738883972
Validation loss: 1.6298915237508795

Epoch: 6| Step: 3
Training loss: 0.3442044258117676
Validation loss: 1.6328146957582044

Epoch: 6| Step: 4
Training loss: 0.5004501938819885
Validation loss: 1.635784267097391

Epoch: 6| Step: 5
Training loss: 0.3247486650943756
Validation loss: 1.6292290482469785

Epoch: 6| Step: 6
Training loss: 0.5622336864471436
Validation loss: 1.638373577466575

Epoch: 6| Step: 7
Training loss: 0.4092816114425659
Validation loss: 1.641769124615577

Epoch: 6| Step: 8
Training loss: 0.40559151768684387
Validation loss: 1.6266457162877566

Epoch: 6| Step: 9
Training loss: 0.6507408022880554
Validation loss: 1.6087587418094758

Epoch: 6| Step: 10
Training loss: 0.5016704797744751
Validation loss: 1.6259283711833339

Epoch: 6| Step: 11
Training loss: 0.27251148223876953
Validation loss: 1.6459978985530075

Epoch: 6| Step: 12
Training loss: 0.3399161100387573
Validation loss: 1.6161151445040138

Epoch: 6| Step: 13
Training loss: 0.22879797220230103
Validation loss: 1.6055018119914557

Epoch: 288| Step: 0
Training loss: 0.3178093433380127
Validation loss: 1.6317466946058377

Epoch: 6| Step: 1
Training loss: 0.3674386441707611
Validation loss: 1.6787192808684481

Epoch: 6| Step: 2
Training loss: 0.5458722114562988
Validation loss: 1.6537164244600522

Epoch: 6| Step: 3
Training loss: 0.513137936592102
Validation loss: 1.6645106577104138

Epoch: 6| Step: 4
Training loss: 0.4165341854095459
Validation loss: 1.6727817955837454

Epoch: 6| Step: 5
Training loss: 0.2868412733078003
Validation loss: 1.6094327383143927

Epoch: 6| Step: 6
Training loss: 0.29091906547546387
Validation loss: 1.66525641692582

Epoch: 6| Step: 7
Training loss: 0.3546814024448395
Validation loss: 1.608406925073234

Epoch: 6| Step: 8
Training loss: 0.6951619386672974
Validation loss: 1.616034020659744

Epoch: 6| Step: 9
Training loss: 0.4205167889595032
Validation loss: 1.6040095911231091

Epoch: 6| Step: 10
Training loss: 0.5410158038139343
Validation loss: 1.6371724964469991

Epoch: 6| Step: 11
Training loss: 0.4111083149909973
Validation loss: 1.6489091509131975

Epoch: 6| Step: 12
Training loss: 0.4415409564971924
Validation loss: 1.6268148652968868

Epoch: 6| Step: 13
Training loss: 0.3353147506713867
Validation loss: 1.6551475076265232

Epoch: 289| Step: 0
Training loss: 0.5396002531051636
Validation loss: 1.633837881908622

Epoch: 6| Step: 1
Training loss: 0.49235799908638
Validation loss: 1.6446536330766575

Epoch: 6| Step: 2
Training loss: 0.361611932516098
Validation loss: 1.5990090088177753

Epoch: 6| Step: 3
Training loss: 0.28798896074295044
Validation loss: 1.6225761764792985

Epoch: 6| Step: 4
Training loss: 0.6114374399185181
Validation loss: 1.6360443471580424

Epoch: 6| Step: 5
Training loss: 0.29655423760414124
Validation loss: 1.6472243109057028

Epoch: 6| Step: 6
Training loss: 0.3231063187122345
Validation loss: 1.596546733251182

Epoch: 6| Step: 7
Training loss: 0.447037011384964
Validation loss: 1.6160159341750606

Epoch: 6| Step: 8
Training loss: 0.3485618233680725
Validation loss: 1.6289292817474694

Epoch: 6| Step: 9
Training loss: 0.2688969373703003
Validation loss: 1.6129593400545017

Epoch: 6| Step: 10
Training loss: 0.6027655601501465
Validation loss: 1.6354968573457451

Epoch: 6| Step: 11
Training loss: 0.5504380464553833
Validation loss: 1.6802391582919705

Epoch: 6| Step: 12
Training loss: 0.5222253799438477
Validation loss: 1.6846550177502375

Epoch: 6| Step: 13
Training loss: 0.33138078451156616
Validation loss: 1.6251468863538516

Epoch: 290| Step: 0
Training loss: 0.3913537263870239
Validation loss: 1.6202005699116697

Epoch: 6| Step: 1
Training loss: 0.6270463466644287
Validation loss: 1.5911781941690752

Epoch: 6| Step: 2
Training loss: 0.3153679668903351
Validation loss: 1.6288808340667396

Epoch: 6| Step: 3
Training loss: 0.2201557755470276
Validation loss: 1.5987229347229004

Epoch: 6| Step: 4
Training loss: 0.3272395133972168
Validation loss: 1.5792831079934233

Epoch: 6| Step: 5
Training loss: 0.33743277192115784
Validation loss: 1.590808637680546

Epoch: 6| Step: 6
Training loss: 0.49295687675476074
Validation loss: 1.5683948404045516

Epoch: 6| Step: 7
Training loss: 0.4691065549850464
Validation loss: 1.651763912170164

Epoch: 6| Step: 8
Training loss: 0.3958742022514343
Validation loss: 1.6169718580861245

Epoch: 6| Step: 9
Training loss: 0.66273033618927
Validation loss: 1.6085297920370614

Epoch: 6| Step: 10
Training loss: 0.5894007682800293
Validation loss: 1.5844148487173102

Epoch: 6| Step: 11
Training loss: 0.3548702001571655
Validation loss: 1.6205807578179143

Epoch: 6| Step: 12
Training loss: 0.46265748143196106
Validation loss: 1.667444440626329

Epoch: 6| Step: 13
Training loss: 0.2950275242328644
Validation loss: 1.7602907432022916

Epoch: 291| Step: 0
Training loss: 0.2546486258506775
Validation loss: 1.7631560166676838

Epoch: 6| Step: 1
Training loss: 0.3792896866798401
Validation loss: 1.7293640105955062

Epoch: 6| Step: 2
Training loss: 0.4396057426929474
Validation loss: 1.6979658654941026

Epoch: 6| Step: 3
Training loss: 0.3805474638938904
Validation loss: 1.6225009208084435

Epoch: 6| Step: 4
Training loss: 0.5561743378639221
Validation loss: 1.6103638884841756

Epoch: 6| Step: 5
Training loss: 0.4558314383029938
Validation loss: 1.618704700982699

Epoch: 6| Step: 6
Training loss: 0.37826675176620483
Validation loss: 1.618960448490676

Epoch: 6| Step: 7
Training loss: 0.4026263952255249
Validation loss: 1.636642288136226

Epoch: 6| Step: 8
Training loss: 0.7444161772727966
Validation loss: 1.6223413508425477

Epoch: 6| Step: 9
Training loss: 0.4041551351547241
Validation loss: 1.6080127877573813

Epoch: 6| Step: 10
Training loss: 0.3460956811904907
Validation loss: 1.6124477117292342

Epoch: 6| Step: 11
Training loss: 0.41840237379074097
Validation loss: 1.6151654258851083

Epoch: 6| Step: 12
Training loss: 0.33411258459091187
Validation loss: 1.61745209334999

Epoch: 6| Step: 13
Training loss: 0.4978069067001343
Validation loss: 1.6084846982391932

Epoch: 292| Step: 0
Training loss: 0.23755796253681183
Validation loss: 1.619140322490405

Epoch: 6| Step: 1
Training loss: 0.4294660985469818
Validation loss: 1.6573123598611483

Epoch: 6| Step: 2
Training loss: 0.45412731170654297
Validation loss: 1.6499124803850729

Epoch: 6| Step: 3
Training loss: 0.4019719064235687
Validation loss: 1.6569648788821312

Epoch: 6| Step: 4
Training loss: 0.5396276712417603
Validation loss: 1.6442544024477723

Epoch: 6| Step: 5
Training loss: 0.26595667004585266
Validation loss: 1.6615773118952268

Epoch: 6| Step: 6
Training loss: 0.4436759948730469
Validation loss: 1.6510009573351951

Epoch: 6| Step: 7
Training loss: 0.37762171030044556
Validation loss: 1.6184751461910944

Epoch: 6| Step: 8
Training loss: 0.47525379061698914
Validation loss: 1.6027767299323954

Epoch: 6| Step: 9
Training loss: 0.6621300578117371
Validation loss: 1.630395454745139

Epoch: 6| Step: 10
Training loss: 0.30253762006759644
Validation loss: 1.6858513662892003

Epoch: 6| Step: 11
Training loss: 0.42313098907470703
Validation loss: 1.6655700270847609

Epoch: 6| Step: 12
Training loss: 0.4861871004104614
Validation loss: 1.6599362422061223

Epoch: 6| Step: 13
Training loss: 0.44262057542800903
Validation loss: 1.6510841564465595

Epoch: 293| Step: 0
Training loss: 0.25600695610046387
Validation loss: 1.6482418032102688

Epoch: 6| Step: 1
Training loss: 0.34686005115509033
Validation loss: 1.6640856291658135

Epoch: 6| Step: 2
Training loss: 0.6691750288009644
Validation loss: 1.6676819106583953

Epoch: 6| Step: 3
Training loss: 0.2730341851711273
Validation loss: 1.7156926611418366

Epoch: 6| Step: 4
Training loss: 0.3236680030822754
Validation loss: 1.6990109951265397

Epoch: 6| Step: 5
Training loss: 0.44930341839790344
Validation loss: 1.6768290381277762

Epoch: 6| Step: 6
Training loss: 0.34482359886169434
Validation loss: 1.712772782130908

Epoch: 6| Step: 7
Training loss: 0.464135080575943
Validation loss: 1.689611163190616

Epoch: 6| Step: 8
Training loss: 0.4751221239566803
Validation loss: 1.6605777766114922

Epoch: 6| Step: 9
Training loss: 0.20395474135875702
Validation loss: 1.6815826674943328

Epoch: 6| Step: 10
Training loss: 0.23889638483524323
Validation loss: 1.6366027029611732

Epoch: 6| Step: 11
Training loss: 0.5968507528305054
Validation loss: 1.618381033661545

Epoch: 6| Step: 12
Training loss: 0.365522563457489
Validation loss: 1.6837038891289824

Epoch: 6| Step: 13
Training loss: 0.439100980758667
Validation loss: 1.6737929697959655

Epoch: 294| Step: 0
Training loss: 0.2669140100479126
Validation loss: 1.6500009067596928

Epoch: 6| Step: 1
Training loss: 0.3299869894981384
Validation loss: 1.635986997235206

Epoch: 6| Step: 2
Training loss: 0.3395540118217468
Validation loss: 1.6424781994153095

Epoch: 6| Step: 3
Training loss: 0.24477741122245789
Validation loss: 1.6317369989169541

Epoch: 6| Step: 4
Training loss: 0.6416146159172058
Validation loss: 1.6543067206618607

Epoch: 6| Step: 5
Training loss: 0.46905630826950073
Validation loss: 1.6587915907623947

Epoch: 6| Step: 6
Training loss: 0.2531907558441162
Validation loss: 1.6665052380613101

Epoch: 6| Step: 7
Training loss: 0.5752098560333252
Validation loss: 1.6794822241670342

Epoch: 6| Step: 8
Training loss: 0.4165090024471283
Validation loss: 1.6813707479866602

Epoch: 6| Step: 9
Training loss: 0.5811701416969299
Validation loss: 1.664188931065221

Epoch: 6| Step: 10
Training loss: 0.18360868096351624
Validation loss: 1.6205219825108845

Epoch: 6| Step: 11
Training loss: 0.42926979064941406
Validation loss: 1.6599065001292894

Epoch: 6| Step: 12
Training loss: 0.4339693784713745
Validation loss: 1.6631301167190715

Epoch: 6| Step: 13
Training loss: 0.3778179883956909
Validation loss: 1.6616730395183767

Epoch: 295| Step: 0
Training loss: 0.48042309284210205
Validation loss: 1.6687734639772804

Epoch: 6| Step: 1
Training loss: 0.5136033296585083
Validation loss: 1.6373341891073412

Epoch: 6| Step: 2
Training loss: 0.5131182670593262
Validation loss: 1.6021231073205189

Epoch: 6| Step: 3
Training loss: 0.3382487893104553
Validation loss: 1.6171171972828526

Epoch: 6| Step: 4
Training loss: 0.419249027967453
Validation loss: 1.6140186696924188

Epoch: 6| Step: 5
Training loss: 0.20855087041854858
Validation loss: 1.617008582238228

Epoch: 6| Step: 6
Training loss: 0.2973397970199585
Validation loss: 1.6166041935643842

Epoch: 6| Step: 7
Training loss: 0.48761317133903503
Validation loss: 1.641903074838782

Epoch: 6| Step: 8
Training loss: 0.23363898694515228
Validation loss: 1.6509439650402273

Epoch: 6| Step: 9
Training loss: 0.35330215096473694
Validation loss: 1.6597084640174784

Epoch: 6| Step: 10
Training loss: 0.39968496561050415
Validation loss: 1.6979659872670327

Epoch: 6| Step: 11
Training loss: 0.36733728647232056
Validation loss: 1.6786588186858802

Epoch: 6| Step: 12
Training loss: 0.4478834867477417
Validation loss: 1.6712515584884151

Epoch: 6| Step: 13
Training loss: 0.5413481593132019
Validation loss: 1.6845983753922165

Epoch: 296| Step: 0
Training loss: 0.33115410804748535
Validation loss: 1.7227109670639038

Epoch: 6| Step: 1
Training loss: 0.20318391919136047
Validation loss: 1.7240199030086558

Epoch: 6| Step: 2
Training loss: 0.5701706409454346
Validation loss: 1.6934599158584431

Epoch: 6| Step: 3
Training loss: 0.6096116304397583
Validation loss: 1.6784981014908

Epoch: 6| Step: 4
Training loss: 0.6761550903320312
Validation loss: 1.6448988094124743

Epoch: 6| Step: 5
Training loss: 0.28365010023117065
Validation loss: 1.6599224869922926

Epoch: 6| Step: 6
Training loss: 0.48018506169319153
Validation loss: 1.6614397687296714

Epoch: 6| Step: 7
Training loss: 0.5091991424560547
Validation loss: 1.6236990074957571

Epoch: 6| Step: 8
Training loss: 0.23195965588092804
Validation loss: 1.6120601533561625

Epoch: 6| Step: 9
Training loss: 0.2586989998817444
Validation loss: 1.6275484895193448

Epoch: 6| Step: 10
Training loss: 0.1436808556318283
Validation loss: 1.6224267790394444

Epoch: 6| Step: 11
Training loss: 0.265958309173584
Validation loss: 1.6500137429083548

Epoch: 6| Step: 12
Training loss: 0.39248448610305786
Validation loss: 1.6726815264712098

Epoch: 6| Step: 13
Training loss: 0.2862033247947693
Validation loss: 1.6711928113814323

Epoch: 297| Step: 0
Training loss: 0.23031751811504364
Validation loss: 1.6253691821969964

Epoch: 6| Step: 1
Training loss: 0.5527088642120361
Validation loss: 1.6751445493390482

Epoch: 6| Step: 2
Training loss: 0.4437980651855469
Validation loss: 1.6406292915344238

Epoch: 6| Step: 3
Training loss: 0.2032555788755417
Validation loss: 1.6453553271550003

Epoch: 6| Step: 4
Training loss: 0.3047889471054077
Validation loss: 1.6786289266360703

Epoch: 6| Step: 5
Training loss: 0.5433676242828369
Validation loss: 1.6629344788930749

Epoch: 6| Step: 6
Training loss: 0.36197391152381897
Validation loss: 1.6149823332345614

Epoch: 6| Step: 7
Training loss: 0.290091335773468
Validation loss: 1.6333670180330995

Epoch: 6| Step: 8
Training loss: 0.6160262823104858
Validation loss: 1.6277401498568955

Epoch: 6| Step: 9
Training loss: 0.20104560256004333
Validation loss: 1.6356070656930246

Epoch: 6| Step: 10
Training loss: 0.3913690745830536
Validation loss: 1.6424213160750687

Epoch: 6| Step: 11
Training loss: 0.5027502775192261
Validation loss: 1.6524567514337518

Epoch: 6| Step: 12
Training loss: 0.3186345100402832
Validation loss: 1.649403945092232

Epoch: 6| Step: 13
Training loss: 0.23295576870441437
Validation loss: 1.6870857695097565

Epoch: 298| Step: 0
Training loss: 0.5047528743743896
Validation loss: 1.7063627294314805

Epoch: 6| Step: 1
Training loss: 0.7401068806648254
Validation loss: 1.6897248375800349

Epoch: 6| Step: 2
Training loss: 0.34649568796157837
Validation loss: 1.6794697776917489

Epoch: 6| Step: 3
Training loss: 0.3836513161659241
Validation loss: 1.6111649262007846

Epoch: 6| Step: 4
Training loss: 0.5904422998428345
Validation loss: 1.6234564986280215

Epoch: 6| Step: 5
Training loss: 0.20170331001281738
Validation loss: 1.6010940529966866

Epoch: 6| Step: 6
Training loss: 0.3049470782279968
Validation loss: 1.6149077800012404

Epoch: 6| Step: 7
Training loss: 0.2868279814720154
Validation loss: 1.580719946533121

Epoch: 6| Step: 8
Training loss: 0.23428687453269958
Validation loss: 1.586611073504212

Epoch: 6| Step: 9
Training loss: 0.3276343047618866
Validation loss: 1.6072149571552072

Epoch: 6| Step: 10
Training loss: 0.35322484374046326
Validation loss: 1.6542328583296908

Epoch: 6| Step: 11
Training loss: 0.43299567699432373
Validation loss: 1.6122185517382879

Epoch: 6| Step: 12
Training loss: 0.22277885675430298
Validation loss: 1.6508331837192658

Epoch: 6| Step: 13
Training loss: 0.5191938877105713
Validation loss: 1.6786449532355032

Epoch: 299| Step: 0
Training loss: 0.3839716911315918
Validation loss: 1.6546985231420046

Epoch: 6| Step: 1
Training loss: 0.4609462022781372
Validation loss: 1.6329314285709011

Epoch: 6| Step: 2
Training loss: 0.4292217493057251
Validation loss: 1.6252889979270198

Epoch: 6| Step: 3
Training loss: 0.2435975819826126
Validation loss: 1.6030017406709733

Epoch: 6| Step: 4
Training loss: 0.4267483949661255
Validation loss: 1.6164057754701184

Epoch: 6| Step: 5
Training loss: 0.18405470252037048
Validation loss: 1.6186525103866414

Epoch: 6| Step: 6
Training loss: 0.40648943185806274
Validation loss: 1.6444236373388639

Epoch: 6| Step: 7
Training loss: 0.36203014850616455
Validation loss: 1.662947630369535

Epoch: 6| Step: 8
Training loss: 0.47174352407455444
Validation loss: 1.6094961012563398

Epoch: 6| Step: 9
Training loss: 0.20265837013721466
Validation loss: 1.6092322987894858

Epoch: 6| Step: 10
Training loss: 0.38752299547195435
Validation loss: 1.6534599155508063

Epoch: 6| Step: 11
Training loss: 0.2967473268508911
Validation loss: 1.6565348102200417

Epoch: 6| Step: 12
Training loss: 0.4985373616218567
Validation loss: 1.672370227434302

Epoch: 6| Step: 13
Training loss: 0.30251190066337585
Validation loss: 1.6428228116804553

Epoch: 300| Step: 0
Training loss: 0.47448214888572693
Validation loss: 1.6713449410212937

Epoch: 6| Step: 1
Training loss: 0.3832012414932251
Validation loss: 1.6567165236319266

Epoch: 6| Step: 2
Training loss: 0.23208190500736237
Validation loss: 1.6442455976240096

Epoch: 6| Step: 3
Training loss: 0.6191178560256958
Validation loss: 1.65237840273047

Epoch: 6| Step: 4
Training loss: 0.19731667637825012
Validation loss: 1.6761973698933919

Epoch: 6| Step: 5
Training loss: 0.12133914977312088
Validation loss: 1.6651388317026117

Epoch: 6| Step: 6
Training loss: 0.24171863496303558
Validation loss: 1.6345108965391755

Epoch: 6| Step: 7
Training loss: 0.2654300928115845
Validation loss: 1.66108270998924

Epoch: 6| Step: 8
Training loss: 0.5282565951347351
Validation loss: 1.6658875737138974

Epoch: 6| Step: 9
Training loss: 0.32663631439208984
Validation loss: 1.6398065820817025

Epoch: 6| Step: 10
Training loss: 0.32628360390663147
Validation loss: 1.6338128466759958

Epoch: 6| Step: 11
Training loss: 0.5494400262832642
Validation loss: 1.6349998417721

Epoch: 6| Step: 12
Training loss: 0.3764888048171997
Validation loss: 1.614261350324077

Epoch: 6| Step: 13
Training loss: 0.2570095658302307
Validation loss: 1.6014036991262948

Epoch: 301| Step: 0
Training loss: 0.6270437836647034
Validation loss: 1.598746891944639

Epoch: 6| Step: 1
Training loss: 0.36855435371398926
Validation loss: 1.6249084088110155

Epoch: 6| Step: 2
Training loss: 0.4319538474082947
Validation loss: 1.6118122967340613

Epoch: 6| Step: 3
Training loss: 0.35171371698379517
Validation loss: 1.657972716516064

Epoch: 6| Step: 4
Training loss: 0.4635637402534485
Validation loss: 1.6219663773813555

Epoch: 6| Step: 5
Training loss: 0.3180563449859619
Validation loss: 1.598738080711775

Epoch: 6| Step: 6
Training loss: 0.32132041454315186
Validation loss: 1.6277005198181316

Epoch: 6| Step: 7
Training loss: 0.32301297783851624
Validation loss: 1.5899567783519786

Epoch: 6| Step: 8
Training loss: 0.4804244041442871
Validation loss: 1.5764600820438837

Epoch: 6| Step: 9
Training loss: 0.34993240237236023
Validation loss: 1.5561007004912182

Epoch: 6| Step: 10
Training loss: 0.45152825117111206
Validation loss: 1.5636299143555343

Epoch: 6| Step: 11
Training loss: 0.24473798274993896
Validation loss: 1.5648636356476815

Epoch: 6| Step: 12
Training loss: 0.376446008682251
Validation loss: 1.5806865666502266

Epoch: 6| Step: 13
Training loss: 0.4453583359718323
Validation loss: 1.5924576367101362

Epoch: 302| Step: 0
Training loss: 0.4404204487800598
Validation loss: 1.6016294610115789

Epoch: 6| Step: 1
Training loss: 0.4086083769798279
Validation loss: 1.598020452325062

Epoch: 6| Step: 2
Training loss: 0.19645637273788452
Validation loss: 1.633978659106839

Epoch: 6| Step: 3
Training loss: 0.43371638655662537
Validation loss: 1.6161560678994784

Epoch: 6| Step: 4
Training loss: 0.5200537443161011
Validation loss: 1.655698977490907

Epoch: 6| Step: 5
Training loss: 0.4506853222846985
Validation loss: 1.6261484071772585

Epoch: 6| Step: 6
Training loss: 0.2831403911113739
Validation loss: 1.5939740057914489

Epoch: 6| Step: 7
Training loss: 0.29662197828292847
Validation loss: 1.593478730929795

Epoch: 6| Step: 8
Training loss: 0.3911173343658447
Validation loss: 1.5918838400994577

Epoch: 6| Step: 9
Training loss: 0.31131264567375183
Validation loss: 1.5560735643550914

Epoch: 6| Step: 10
Training loss: 0.21410520374774933
Validation loss: 1.5788508179367229

Epoch: 6| Step: 11
Training loss: 0.3224763870239258
Validation loss: 1.574250272525254

Epoch: 6| Step: 12
Training loss: 0.4305237829685211
Validation loss: 1.5854091029013357

Epoch: 6| Step: 13
Training loss: 0.5090566277503967
Validation loss: 1.5920817288019324

Epoch: 303| Step: 0
Training loss: 0.35410523414611816
Validation loss: 1.5738287651410667

Epoch: 6| Step: 1
Training loss: 0.40698760747909546
Validation loss: 1.588561322099419

Epoch: 6| Step: 2
Training loss: 0.37937653064727783
Validation loss: 1.5778493150588004

Epoch: 6| Step: 3
Training loss: 0.20745112001895905
Validation loss: 1.616053545346824

Epoch: 6| Step: 4
Training loss: 0.30849501490592957
Validation loss: 1.6038936979027205

Epoch: 6| Step: 5
Training loss: 0.49564701318740845
Validation loss: 1.5736613158256776

Epoch: 6| Step: 6
Training loss: 0.2724960744380951
Validation loss: 1.5555741863866006

Epoch: 6| Step: 7
Training loss: 0.3160313367843628
Validation loss: 1.5699539261479531

Epoch: 6| Step: 8
Training loss: 0.3264748454093933
Validation loss: 1.5633690075207782

Epoch: 6| Step: 9
Training loss: 0.3364304304122925
Validation loss: 1.5525439939191263

Epoch: 6| Step: 10
Training loss: 0.36133602261543274
Validation loss: 1.567025295508805

Epoch: 6| Step: 11
Training loss: 0.4306814670562744
Validation loss: 1.558727140067726

Epoch: 6| Step: 12
Training loss: 0.28303438425064087
Validation loss: 1.5351112632341282

Epoch: 6| Step: 13
Training loss: 0.3659451901912689
Validation loss: 1.53743117086349

Epoch: 304| Step: 0
Training loss: 0.4182596802711487
Validation loss: 1.535340832125756

Epoch: 6| Step: 1
Training loss: 0.262060284614563
Validation loss: 1.5622869153176584

Epoch: 6| Step: 2
Training loss: 0.1444416046142578
Validation loss: 1.5598607729840022

Epoch: 6| Step: 3
Training loss: 0.6291122436523438
Validation loss: 1.5489586489174956

Epoch: 6| Step: 4
Training loss: 0.40519949793815613
Validation loss: 1.5694669741456226

Epoch: 6| Step: 5
Training loss: 0.48589539527893066
Validation loss: 1.5831094595693773

Epoch: 6| Step: 6
Training loss: 0.31150031089782715
Validation loss: 1.6001211404800415

Epoch: 6| Step: 7
Training loss: 0.2712153494358063
Validation loss: 1.6316504183635916

Epoch: 6| Step: 8
Training loss: 0.27166643738746643
Validation loss: 1.6373630300644906

Epoch: 6| Step: 9
Training loss: 0.16508419811725616
Validation loss: 1.5843174572913878

Epoch: 6| Step: 10
Training loss: 0.3660849630832672
Validation loss: 1.597767032602782

Epoch: 6| Step: 11
Training loss: 0.4350549578666687
Validation loss: 1.60843115339997

Epoch: 6| Step: 12
Training loss: 0.5020642876625061
Validation loss: 1.5650755846372215

Epoch: 6| Step: 13
Training loss: 0.27289921045303345
Validation loss: 1.6409952358532978

Epoch: 305| Step: 0
Training loss: 0.2776520252227783
Validation loss: 1.6278010555492934

Epoch: 6| Step: 1
Training loss: 0.3150343894958496
Validation loss: 1.6636377611467916

Epoch: 6| Step: 2
Training loss: 0.22705942392349243
Validation loss: 1.6512079854165354

Epoch: 6| Step: 3
Training loss: 0.4078904986381531
Validation loss: 1.6134022717834802

Epoch: 6| Step: 4
Training loss: 0.42454883456230164
Validation loss: 1.5892609178379018

Epoch: 6| Step: 5
Training loss: 0.36205971240997314
Validation loss: 1.6296890756135345

Epoch: 6| Step: 6
Training loss: 0.44484126567840576
Validation loss: 1.5866075087619085

Epoch: 6| Step: 7
Training loss: 0.40538138151168823
Validation loss: 1.6328027197109756

Epoch: 6| Step: 8
Training loss: 0.3120992183685303
Validation loss: 1.661512541514571

Epoch: 6| Step: 9
Training loss: 0.4150784909725189
Validation loss: 1.7028018172069261

Epoch: 6| Step: 10
Training loss: 0.35310426354408264
Validation loss: 1.713686304707681

Epoch: 6| Step: 11
Training loss: 0.4275016188621521
Validation loss: 1.6784427883804485

Epoch: 6| Step: 12
Training loss: 0.3458559513092041
Validation loss: 1.6651173253213205

Epoch: 6| Step: 13
Training loss: 0.3940642774105072
Validation loss: 1.7042221997373848

Epoch: 306| Step: 0
Training loss: 0.24208953976631165
Validation loss: 1.6922046625485985

Epoch: 6| Step: 1
Training loss: 0.3349579870700836
Validation loss: 1.7006514892783215

Epoch: 6| Step: 2
Training loss: 0.27471810579299927
Validation loss: 1.6817276887996222

Epoch: 6| Step: 3
Training loss: 0.23723401129245758
Validation loss: 1.684978251816124

Epoch: 6| Step: 4
Training loss: 0.31878337264060974
Validation loss: 1.640333071831734

Epoch: 6| Step: 5
Training loss: 0.28785067796707153
Validation loss: 1.6406510914525678

Epoch: 6| Step: 6
Training loss: 0.6578296422958374
Validation loss: 1.666252190066922

Epoch: 6| Step: 7
Training loss: 0.35036003589630127
Validation loss: 1.664998988951406

Epoch: 6| Step: 8
Training loss: 0.16618463397026062
Validation loss: 1.6794699545829528

Epoch: 6| Step: 9
Training loss: 0.35174375772476196
Validation loss: 1.6877367855400167

Epoch: 6| Step: 10
Training loss: 0.33394700288772583
Validation loss: 1.694828688457448

Epoch: 6| Step: 11
Training loss: 0.19192245602607727
Validation loss: 1.6789829461805281

Epoch: 6| Step: 12
Training loss: 0.49516648054122925
Validation loss: 1.7206502691391976

Epoch: 6| Step: 13
Training loss: 0.2642211616039276
Validation loss: 1.6923793297941967

Epoch: 307| Step: 0
Training loss: 0.20937323570251465
Validation loss: 1.709011625218135

Epoch: 6| Step: 1
Training loss: 0.3806508183479309
Validation loss: 1.6678132241772068

Epoch: 6| Step: 2
Training loss: 0.35779330134391785
Validation loss: 1.662411379557784

Epoch: 6| Step: 3
Training loss: 0.4731467068195343
Validation loss: 1.6609155439561414

Epoch: 6| Step: 4
Training loss: 0.3593224287033081
Validation loss: 1.6136284451330862

Epoch: 6| Step: 5
Training loss: 0.22063890099525452
Validation loss: 1.587048827960927

Epoch: 6| Step: 6
Training loss: 0.41397565603256226
Validation loss: 1.629733576569506

Epoch: 6| Step: 7
Training loss: 0.3056894540786743
Validation loss: 1.692477003220589

Epoch: 6| Step: 8
Training loss: 0.4949760138988495
Validation loss: 1.6690968198160971

Epoch: 6| Step: 9
Training loss: 0.6324173212051392
Validation loss: 1.6759519577026367

Epoch: 6| Step: 10
Training loss: 0.1714167594909668
Validation loss: 1.5729936925313805

Epoch: 6| Step: 11
Training loss: 0.16706891357898712
Validation loss: 1.5788603482707855

Epoch: 6| Step: 12
Training loss: 0.3872430920600891
Validation loss: 1.6171326970541349

Epoch: 6| Step: 13
Training loss: 0.3228846788406372
Validation loss: 1.6007808978839586

Epoch: 308| Step: 0
Training loss: 0.5030856132507324
Validation loss: 1.5929091720170871

Epoch: 6| Step: 1
Training loss: 0.29363787174224854
Validation loss: 1.6542769337213168

Epoch: 6| Step: 2
Training loss: 0.34369799494743347
Validation loss: 1.6081467905352194

Epoch: 6| Step: 3
Training loss: 0.3421614468097687
Validation loss: 1.6105876571388655

Epoch: 6| Step: 4
Training loss: 0.15346954762935638
Validation loss: 1.6485634080825313

Epoch: 6| Step: 5
Training loss: 0.317057728767395
Validation loss: 1.6171014911384993

Epoch: 6| Step: 6
Training loss: 0.39536648988723755
Validation loss: 1.6304231113003147

Epoch: 6| Step: 7
Training loss: 0.4597170352935791
Validation loss: 1.6382787342994445

Epoch: 6| Step: 8
Training loss: 0.3774642050266266
Validation loss: 1.627899275031141

Epoch: 6| Step: 9
Training loss: 0.23497700691223145
Validation loss: 1.6230616646428262

Epoch: 6| Step: 10
Training loss: 0.2836975157260895
Validation loss: 1.6213725395100091

Epoch: 6| Step: 11
Training loss: 0.2462356686592102
Validation loss: 1.5938702603822112

Epoch: 6| Step: 12
Training loss: 0.2637411952018738
Validation loss: 1.5800517489833217

Epoch: 6| Step: 13
Training loss: 0.3222463130950928
Validation loss: 1.5787108482853058

Epoch: 309| Step: 0
Training loss: 0.3179585933685303
Validation loss: 1.5890546755124164

Epoch: 6| Step: 1
Training loss: 0.5312525033950806
Validation loss: 1.55283607334219

Epoch: 6| Step: 2
Training loss: 0.35473501682281494
Validation loss: 1.5559919957191712

Epoch: 6| Step: 3
Training loss: 0.35454291105270386
Validation loss: 1.6013683478037517

Epoch: 6| Step: 4
Training loss: 0.16692382097244263
Validation loss: 1.560873427698689

Epoch: 6| Step: 5
Training loss: 0.4419197142124176
Validation loss: 1.6038699714086389

Epoch: 6| Step: 6
Training loss: 0.24428746104240417
Validation loss: 1.6600260337193806

Epoch: 6| Step: 7
Training loss: 0.2772810161113739
Validation loss: 1.648863346345963

Epoch: 6| Step: 8
Training loss: 0.3919908106327057
Validation loss: 1.6875768976826822

Epoch: 6| Step: 9
Training loss: 0.3833160996437073
Validation loss: 1.7294651821095457

Epoch: 6| Step: 10
Training loss: 0.33879896998405457
Validation loss: 1.751463411956705

Epoch: 6| Step: 11
Training loss: 0.452658087015152
Validation loss: 1.7025819465678225

Epoch: 6| Step: 12
Training loss: 0.48130273818969727
Validation loss: 1.6744372306331512

Epoch: 6| Step: 13
Training loss: 0.253665030002594
Validation loss: 1.6908042712878155

Epoch: 310| Step: 0
Training loss: 0.2804582118988037
Validation loss: 1.6748598365373508

Epoch: 6| Step: 1
Training loss: 0.20051544904708862
Validation loss: 1.665480326580745

Epoch: 6| Step: 2
Training loss: 0.27879923582077026
Validation loss: 1.6383220790534891

Epoch: 6| Step: 3
Training loss: 0.2097035050392151
Validation loss: 1.6451745135809785

Epoch: 6| Step: 4
Training loss: 0.3241487443447113
Validation loss: 1.6188044407034432

Epoch: 6| Step: 5
Training loss: 0.20828868448734283
Validation loss: 1.5852837934288928

Epoch: 6| Step: 6
Training loss: 0.21813303232192993
Validation loss: 1.6235475411979101

Epoch: 6| Step: 7
Training loss: 0.35507190227508545
Validation loss: 1.661407204084499

Epoch: 6| Step: 8
Training loss: 0.25883352756500244
Validation loss: 1.6569566393411288

Epoch: 6| Step: 9
Training loss: 0.4937955141067505
Validation loss: 1.6083499026554886

Epoch: 6| Step: 10
Training loss: 0.26289796829223633
Validation loss: 1.6076951424280803

Epoch: 6| Step: 11
Training loss: 0.30054375529289246
Validation loss: 1.584085569586805

Epoch: 6| Step: 12
Training loss: 0.4881020784378052
Validation loss: 1.5853912381715671

Epoch: 6| Step: 13
Training loss: 0.4077039957046509
Validation loss: 1.614725366715462

Epoch: 311| Step: 0
Training loss: 0.3210069239139557
Validation loss: 1.6250173173924929

Epoch: 6| Step: 1
Training loss: 0.41766470670700073
Validation loss: 1.624404150952575

Epoch: 6| Step: 2
Training loss: 0.2799386978149414
Validation loss: 1.6298143658586728

Epoch: 6| Step: 3
Training loss: 0.24634072184562683
Validation loss: 1.6454272911112795

Epoch: 6| Step: 4
Training loss: 0.308651328086853
Validation loss: 1.6093387719123595

Epoch: 6| Step: 5
Training loss: 0.5207464694976807
Validation loss: 1.6143241133741153

Epoch: 6| Step: 6
Training loss: 0.2720516324043274
Validation loss: 1.5872547267585673

Epoch: 6| Step: 7
Training loss: 0.19531619548797607
Validation loss: 1.539071995724914

Epoch: 6| Step: 8
Training loss: 0.32427629828453064
Validation loss: 1.5848109491409794

Epoch: 6| Step: 9
Training loss: 0.31663715839385986
Validation loss: 1.576719250730289

Epoch: 6| Step: 10
Training loss: 0.3936154842376709
Validation loss: 1.5865967453167003

Epoch: 6| Step: 11
Training loss: 0.14841340482234955
Validation loss: 1.5519534676305708

Epoch: 6| Step: 12
Training loss: 0.24258267879486084
Validation loss: 1.5540288597024896

Epoch: 6| Step: 13
Training loss: 0.23376284539699554
Validation loss: 1.5760386195234073

Epoch: 312| Step: 0
Training loss: 0.5035765171051025
Validation loss: 1.5241388120958883

Epoch: 6| Step: 1
Training loss: 0.225433811545372
Validation loss: 1.5281826796070221

Epoch: 6| Step: 2
Training loss: 0.30098816752433777
Validation loss: 1.540941870340737

Epoch: 6| Step: 3
Training loss: 0.1920604109764099
Validation loss: 1.5559724550093375

Epoch: 6| Step: 4
Training loss: 0.5428321957588196
Validation loss: 1.5732621736423944

Epoch: 6| Step: 5
Training loss: 0.24922896921634674
Validation loss: 1.528821792653812

Epoch: 6| Step: 6
Training loss: 0.31901249289512634
Validation loss: 1.5606517612293203

Epoch: 6| Step: 7
Training loss: 0.39380279183387756
Validation loss: 1.545813011866744

Epoch: 6| Step: 8
Training loss: 0.2723824083805084
Validation loss: 1.5900519945288216

Epoch: 6| Step: 9
Training loss: 0.281711608171463
Validation loss: 1.5831039131328624

Epoch: 6| Step: 10
Training loss: 0.3833340108394623
Validation loss: 1.636934216304492

Epoch: 6| Step: 11
Training loss: 0.38795292377471924
Validation loss: 1.6139065578419676

Epoch: 6| Step: 12
Training loss: 0.3155520558357239
Validation loss: 1.6423074173670944

Epoch: 6| Step: 13
Training loss: 0.32663822174072266
Validation loss: 1.6105805789270708

Epoch: 313| Step: 0
Training loss: 0.297284334897995
Validation loss: 1.622993137246819

Epoch: 6| Step: 1
Training loss: 0.4633021354675293
Validation loss: 1.6488066129786993

Epoch: 6| Step: 2
Training loss: 0.27459341287612915
Validation loss: 1.6402521107786445

Epoch: 6| Step: 3
Training loss: 0.401766300201416
Validation loss: 1.6652016844800723

Epoch: 6| Step: 4
Training loss: 0.45843440294265747
Validation loss: 1.670914711490754

Epoch: 6| Step: 5
Training loss: 0.21863412857055664
Validation loss: 1.5859763365919872

Epoch: 6| Step: 6
Training loss: 0.4047248959541321
Validation loss: 1.5760519978820637

Epoch: 6| Step: 7
Training loss: 0.277029812335968
Validation loss: 1.6546427126853698

Epoch: 6| Step: 8
Training loss: 0.2986728549003601
Validation loss: 1.6266886482956588

Epoch: 6| Step: 9
Training loss: 0.2527114748954773
Validation loss: 1.6099281599444728

Epoch: 6| Step: 10
Training loss: 0.4258003830909729
Validation loss: 1.61335495210463

Epoch: 6| Step: 11
Training loss: 0.46980977058410645
Validation loss: 1.6030523347598251

Epoch: 6| Step: 12
Training loss: 0.19454596936702728
Validation loss: 1.6135424971580505

Epoch: 6| Step: 13
Training loss: 0.25254085659980774
Validation loss: 1.653350176349763

Epoch: 314| Step: 0
Training loss: 0.23114895820617676
Validation loss: 1.6286406491392402

Epoch: 6| Step: 1
Training loss: 0.4782112240791321
Validation loss: 1.6648499350393973

Epoch: 6| Step: 2
Training loss: 0.4656214118003845
Validation loss: 1.640122079080151

Epoch: 6| Step: 3
Training loss: 0.5451469421386719
Validation loss: 1.6313740694394676

Epoch: 6| Step: 4
Training loss: 0.14946332573890686
Validation loss: 1.639861709328108

Epoch: 6| Step: 5
Training loss: 0.2728549838066101
Validation loss: 1.6459189538032777

Epoch: 6| Step: 6
Training loss: 0.32502448558807373
Validation loss: 1.6341008909286991

Epoch: 6| Step: 7
Training loss: 0.2787109315395355
Validation loss: 1.60305876885691

Epoch: 6| Step: 8
Training loss: 0.29176008701324463
Validation loss: 1.5960862982657649

Epoch: 6| Step: 9
Training loss: 0.19484259188175201
Validation loss: 1.6386500039408285

Epoch: 6| Step: 10
Training loss: 0.20647989213466644
Validation loss: 1.5997006111247565

Epoch: 6| Step: 11
Training loss: 0.46683382987976074
Validation loss: 1.6199262667727727

Epoch: 6| Step: 12
Training loss: 0.24548658728599548
Validation loss: 1.6152136915473527

Epoch: 6| Step: 13
Training loss: 0.3670107126235962
Validation loss: 1.5631199312466446

Epoch: 315| Step: 0
Training loss: 0.22524622082710266
Validation loss: 1.5759475231170654

Epoch: 6| Step: 1
Training loss: 0.3221668004989624
Validation loss: 1.5541602873033094

Epoch: 6| Step: 2
Training loss: 0.3788498640060425
Validation loss: 1.5775283664785407

Epoch: 6| Step: 3
Training loss: 0.416159451007843
Validation loss: 1.548899237827588

Epoch: 6| Step: 4
Training loss: 0.3568740487098694
Validation loss: 1.584013315939134

Epoch: 6| Step: 5
Training loss: 0.35685819387435913
Validation loss: 1.557212625139503

Epoch: 6| Step: 6
Training loss: 0.37114065885543823
Validation loss: 1.6272390798855854

Epoch: 6| Step: 7
Training loss: 0.2468208223581314
Validation loss: 1.637564395063667

Epoch: 6| Step: 8
Training loss: 0.3924449682235718
Validation loss: 1.5963372274111676

Epoch: 6| Step: 9
Training loss: 0.326127827167511
Validation loss: 1.5881235291880946

Epoch: 6| Step: 10
Training loss: 0.19389382004737854
Validation loss: 1.5532237547700123

Epoch: 6| Step: 11
Training loss: 0.2539776563644409
Validation loss: 1.571195065334279

Epoch: 6| Step: 12
Training loss: 0.2238614559173584
Validation loss: 1.5416810268996863

Epoch: 6| Step: 13
Training loss: 0.4335533380508423
Validation loss: 1.5437229538476596

Epoch: 316| Step: 0
Training loss: 0.46546798944473267
Validation loss: 1.5614744014637445

Epoch: 6| Step: 1
Training loss: 0.24726007878780365
Validation loss: 1.5773782666011522

Epoch: 6| Step: 2
Training loss: 0.3855515718460083
Validation loss: 1.5961732185015114

Epoch: 6| Step: 3
Training loss: 0.5934811234474182
Validation loss: 1.5717148191185408

Epoch: 6| Step: 4
Training loss: 0.35398074984550476
Validation loss: 1.5893031217718636

Epoch: 6| Step: 5
Training loss: 0.3170984983444214
Validation loss: 1.6065944010211575

Epoch: 6| Step: 6
Training loss: 0.3003219962120056
Validation loss: 1.5819966652060067

Epoch: 6| Step: 7
Training loss: 0.20983465015888214
Validation loss: 1.618703439671506

Epoch: 6| Step: 8
Training loss: 0.35155734419822693
Validation loss: 1.6341937536834388

Epoch: 6| Step: 9
Training loss: 0.26071107387542725
Validation loss: 1.6013244775033766

Epoch: 6| Step: 10
Training loss: 0.27206069231033325
Validation loss: 1.5648585724574264

Epoch: 6| Step: 11
Training loss: 0.27894797921180725
Validation loss: 1.523560139440721

Epoch: 6| Step: 12
Training loss: 0.44689008593559265
Validation loss: 1.5098519402165567

Epoch: 6| Step: 13
Training loss: 0.6539163589477539
Validation loss: 1.5107494861848894

Epoch: 317| Step: 0
Training loss: 0.333109974861145
Validation loss: 1.5291245272082667

Epoch: 6| Step: 1
Training loss: 0.43908336758613586
Validation loss: 1.5093749056580246

Epoch: 6| Step: 2
Training loss: 0.3521639406681061
Validation loss: 1.5294806457334948

Epoch: 6| Step: 3
Training loss: 0.14451301097869873
Validation loss: 1.5266565110093804

Epoch: 6| Step: 4
Training loss: 0.21027928590774536
Validation loss: 1.5386217665928665

Epoch: 6| Step: 5
Training loss: 0.3754913806915283
Validation loss: 1.5418556326179094

Epoch: 6| Step: 6
Training loss: 0.296025812625885
Validation loss: 1.5973358634979493

Epoch: 6| Step: 7
Training loss: 0.5183441638946533
Validation loss: 1.62843293528403

Epoch: 6| Step: 8
Training loss: 0.24955978989601135
Validation loss: 1.6151329496855378

Epoch: 6| Step: 9
Training loss: 0.37976378202438354
Validation loss: 1.583788739737644

Epoch: 6| Step: 10
Training loss: 0.34471240639686584
Validation loss: 1.5809113440975067

Epoch: 6| Step: 11
Training loss: 0.2915383577346802
Validation loss: 1.5891671603725803

Epoch: 6| Step: 12
Training loss: 0.3733792304992676
Validation loss: 1.5450940952506116

Epoch: 6| Step: 13
Training loss: 0.36884960532188416
Validation loss: 1.5284955052919285

Epoch: 318| Step: 0
Training loss: 0.33520153164863586
Validation loss: 1.521864535988018

Epoch: 6| Step: 1
Training loss: 0.26827871799468994
Validation loss: 1.5181185814642137

Epoch: 6| Step: 2
Training loss: 0.24874573945999146
Validation loss: 1.5021837501115696

Epoch: 6| Step: 3
Training loss: 0.3296217918395996
Validation loss: 1.4957947397744784

Epoch: 6| Step: 4
Training loss: 0.26661399006843567
Validation loss: 1.5085767597280524

Epoch: 6| Step: 5
Training loss: 0.20657920837402344
Validation loss: 1.5100862140296607

Epoch: 6| Step: 6
Training loss: 0.18106886744499207
Validation loss: 1.501062604688829

Epoch: 6| Step: 7
Training loss: 0.22689449787139893
Validation loss: 1.5291591767341859

Epoch: 6| Step: 8
Training loss: 0.16943714022636414
Validation loss: 1.515250148311738

Epoch: 6| Step: 9
Training loss: 0.4419764280319214
Validation loss: 1.5191876273001395

Epoch: 6| Step: 10
Training loss: 0.26633715629577637
Validation loss: 1.5445743171117639

Epoch: 6| Step: 11
Training loss: 0.20687609910964966
Validation loss: 1.5189483870742142

Epoch: 6| Step: 12
Training loss: 0.28554099798202515
Validation loss: 1.5421427001235306

Epoch: 6| Step: 13
Training loss: 0.26260361075401306
Validation loss: 1.5334482833903322

Epoch: 319| Step: 0
Training loss: 0.21684931218624115
Validation loss: 1.5425853088337889

Epoch: 6| Step: 1
Training loss: 0.3076120615005493
Validation loss: 1.5524933389438096

Epoch: 6| Step: 2
Training loss: 0.2833922505378723
Validation loss: 1.528947111098997

Epoch: 6| Step: 3
Training loss: 0.2816525995731354
Validation loss: 1.5686432674366941

Epoch: 6| Step: 4
Training loss: 0.2534654438495636
Validation loss: 1.57114544991524

Epoch: 6| Step: 5
Training loss: 0.22628211975097656
Validation loss: 1.5186834444281876

Epoch: 6| Step: 6
Training loss: 0.2262135148048401
Validation loss: 1.5388356126764768

Epoch: 6| Step: 7
Training loss: 0.24576938152313232
Validation loss: 1.5704083340142363

Epoch: 6| Step: 8
Training loss: 0.3547217547893524
Validation loss: 1.5254829801538938

Epoch: 6| Step: 9
Training loss: 0.30714350938796997
Validation loss: 1.54910308571272

Epoch: 6| Step: 10
Training loss: 0.41483137011528015
Validation loss: 1.5812991178163918

Epoch: 6| Step: 11
Training loss: 0.19373288750648499
Validation loss: 1.569381162684451

Epoch: 6| Step: 12
Training loss: 0.28563544154167175
Validation loss: 1.618258705703161

Epoch: 6| Step: 13
Training loss: 0.2745848298072815
Validation loss: 1.5533424295404905

Epoch: 320| Step: 0
Training loss: 0.2630710005760193
Validation loss: 1.6039204315472675

Epoch: 6| Step: 1
Training loss: 0.24012041091918945
Validation loss: 1.572479332647016

Epoch: 6| Step: 2
Training loss: 0.32123035192489624
Validation loss: 1.592522709600387

Epoch: 6| Step: 3
Training loss: 0.18698453903198242
Validation loss: 1.5873525027305848

Epoch: 6| Step: 4
Training loss: 0.23971426486968994
Validation loss: 1.5833794686102098

Epoch: 6| Step: 5
Training loss: 0.33566808700561523
Validation loss: 1.5935582524986678

Epoch: 6| Step: 6
Training loss: 0.3366575241088867
Validation loss: 1.5721753412677395

Epoch: 6| Step: 7
Training loss: 0.2214985489845276
Validation loss: 1.6097973136491672

Epoch: 6| Step: 8
Training loss: 0.3281743824481964
Validation loss: 1.5778896808624268

Epoch: 6| Step: 9
Training loss: 0.3092884421348572
Validation loss: 1.5874541036544307

Epoch: 6| Step: 10
Training loss: 0.15207001566886902
Validation loss: 1.6157709565213931

Epoch: 6| Step: 11
Training loss: 0.33027949929237366
Validation loss: 1.6416674596007153

Epoch: 6| Step: 12
Training loss: 0.29488593339920044
Validation loss: 1.6294186371628956

Epoch: 6| Step: 13
Training loss: 0.4629765748977661
Validation loss: 1.6175543954295497

Epoch: 321| Step: 0
Training loss: 0.22468392550945282
Validation loss: 1.5927220582962036

Epoch: 6| Step: 1
Training loss: 0.23582212626934052
Validation loss: 1.5499265097802686

Epoch: 6| Step: 2
Training loss: 0.1557401567697525
Validation loss: 1.5672765572865803

Epoch: 6| Step: 3
Training loss: 0.3377034664154053
Validation loss: 1.6014179157954391

Epoch: 6| Step: 4
Training loss: 0.2860051989555359
Validation loss: 1.6018944645440707

Epoch: 6| Step: 5
Training loss: 0.4231824278831482
Validation loss: 1.586833333456388

Epoch: 6| Step: 6
Training loss: 0.4363004267215729
Validation loss: 1.5931833431284914

Epoch: 6| Step: 7
Training loss: 0.3198809027671814
Validation loss: 1.5828409861492854

Epoch: 6| Step: 8
Training loss: 0.2623588740825653
Validation loss: 1.5466130920635757

Epoch: 6| Step: 9
Training loss: 0.2684782147407532
Validation loss: 1.528991146754193

Epoch: 6| Step: 10
Training loss: 0.23300306499004364
Validation loss: 1.548463982920493

Epoch: 6| Step: 11
Training loss: 0.2539539039134979
Validation loss: 1.5635898164523545

Epoch: 6| Step: 12
Training loss: 0.3767350912094116
Validation loss: 1.580466293519543

Epoch: 6| Step: 13
Training loss: 0.33016830682754517
Validation loss: 1.5914571144247567

Epoch: 322| Step: 0
Training loss: 0.3143309950828552
Validation loss: 1.580652888103198

Epoch: 6| Step: 1
Training loss: 0.4275607466697693
Validation loss: 1.5670122843916698

Epoch: 6| Step: 2
Training loss: 0.23192518949508667
Validation loss: 1.5834877529451925

Epoch: 6| Step: 3
Training loss: 0.3701234459877014
Validation loss: 1.5834740182404876

Epoch: 6| Step: 4
Training loss: 0.2823299169540405
Validation loss: 1.5438187429981847

Epoch: 6| Step: 5
Training loss: 0.361224889755249
Validation loss: 1.5686270754824403

Epoch: 6| Step: 6
Training loss: 0.280494749546051
Validation loss: 1.5549642501338836

Epoch: 6| Step: 7
Training loss: 0.3240538239479065
Validation loss: 1.5485385515356576

Epoch: 6| Step: 8
Training loss: 0.1741359531879425
Validation loss: 1.530674284504306

Epoch: 6| Step: 9
Training loss: 0.24709025025367737
Validation loss: 1.521625913599486

Epoch: 6| Step: 10
Training loss: 0.36895135045051575
Validation loss: 1.538380112699283

Epoch: 6| Step: 11
Training loss: 0.2865527272224426
Validation loss: 1.5434379808364376

Epoch: 6| Step: 12
Training loss: 0.2173122763633728
Validation loss: 1.5755300675669024

Epoch: 6| Step: 13
Training loss: 0.2573322355747223
Validation loss: 1.5684453409205201

Epoch: 323| Step: 0
Training loss: 0.3063354790210724
Validation loss: 1.5846748121323124

Epoch: 6| Step: 1
Training loss: 0.5149746537208557
Validation loss: 1.5719403592489098

Epoch: 6| Step: 2
Training loss: 0.3144795000553131
Validation loss: 1.5679054247435702

Epoch: 6| Step: 3
Training loss: 0.3360060155391693
Validation loss: 1.5068304532317705

Epoch: 6| Step: 4
Training loss: 0.28097981214523315
Validation loss: 1.5610647342538322

Epoch: 6| Step: 5
Training loss: 0.2404443621635437
Validation loss: 1.5549581358509679

Epoch: 6| Step: 6
Training loss: 0.37425321340560913
Validation loss: 1.6096302117070844

Epoch: 6| Step: 7
Training loss: 0.473612904548645
Validation loss: 1.6103799637927805

Epoch: 6| Step: 8
Training loss: 0.3885185420513153
Validation loss: 1.615729857516545

Epoch: 6| Step: 9
Training loss: 0.17066723108291626
Validation loss: 1.6188212594678324

Epoch: 6| Step: 10
Training loss: 0.26345691084861755
Validation loss: 1.6299534920723207

Epoch: 6| Step: 11
Training loss: 0.27581602334976196
Validation loss: 1.5808337760227982

Epoch: 6| Step: 12
Training loss: 0.14089979231357574
Validation loss: 1.573573390642802

Epoch: 6| Step: 13
Training loss: 0.2237890511751175
Validation loss: 1.5755078972026866

Epoch: 324| Step: 0
Training loss: 0.21364866197109222
Validation loss: 1.5821012348257086

Epoch: 6| Step: 1
Training loss: 0.2703489363193512
Validation loss: 1.543700619410443

Epoch: 6| Step: 2
Training loss: 0.2834107279777527
Validation loss: 1.5674758277913576

Epoch: 6| Step: 3
Training loss: 0.27700352668762207
Validation loss: 1.5582259637053295

Epoch: 6| Step: 4
Training loss: 0.19289268553256989
Validation loss: 1.5573210254792245

Epoch: 6| Step: 5
Training loss: 0.21264562010765076
Validation loss: 1.553210857093975

Epoch: 6| Step: 6
Training loss: 0.2160358428955078
Validation loss: 1.5558464539948331

Epoch: 6| Step: 7
Training loss: 0.24565847218036652
Validation loss: 1.5532836503879999

Epoch: 6| Step: 8
Training loss: 0.27674758434295654
Validation loss: 1.5386570448516517

Epoch: 6| Step: 9
Training loss: 0.27793222665786743
Validation loss: 1.5398228719670286

Epoch: 6| Step: 10
Training loss: 0.3200944662094116
Validation loss: 1.5393396346799788

Epoch: 6| Step: 11
Training loss: 0.3103492259979248
Validation loss: 1.5409459298656834

Epoch: 6| Step: 12
Training loss: 0.31048381328582764
Validation loss: 1.530609816633245

Epoch: 6| Step: 13
Training loss: 0.28826528787612915
Validation loss: 1.5500923895066785

Epoch: 325| Step: 0
Training loss: 0.2788727879524231
Validation loss: 1.538774126319475

Epoch: 6| Step: 1
Training loss: 0.2985210120677948
Validation loss: 1.5311165663503832

Epoch: 6| Step: 2
Training loss: 0.22552944719791412
Validation loss: 1.5341734168350056

Epoch: 6| Step: 3
Training loss: 0.2969629764556885
Validation loss: 1.5363561363630398

Epoch: 6| Step: 4
Training loss: 0.42254337668418884
Validation loss: 1.542251963769236

Epoch: 6| Step: 5
Training loss: 0.3125157356262207
Validation loss: 1.5415702660878499

Epoch: 6| Step: 6
Training loss: 0.29719722270965576
Validation loss: 1.5563807820761075

Epoch: 6| Step: 7
Training loss: 0.2511535882949829
Validation loss: 1.5042430636703328

Epoch: 6| Step: 8
Training loss: 0.28862640261650085
Validation loss: 1.5031299526973436

Epoch: 6| Step: 9
Training loss: 0.2563157081604004
Validation loss: 1.5378452065170451

Epoch: 6| Step: 10
Training loss: 0.10786578059196472
Validation loss: 1.529834520432257

Epoch: 6| Step: 11
Training loss: 0.2741394639015198
Validation loss: 1.5710042285662826

Epoch: 6| Step: 12
Training loss: 0.2067784070968628
Validation loss: 1.6054725313699374

Epoch: 6| Step: 13
Training loss: 0.3945719301700592
Validation loss: 1.6345465567804152

Epoch: 326| Step: 0
Training loss: 0.3828054666519165
Validation loss: 1.6676177324787262

Epoch: 6| Step: 1
Training loss: 0.3511335849761963
Validation loss: 1.6346260245128343

Epoch: 6| Step: 2
Training loss: 0.18644818663597107
Validation loss: 1.6068200180607457

Epoch: 6| Step: 3
Training loss: 0.20469164848327637
Validation loss: 1.594416738838278

Epoch: 6| Step: 4
Training loss: 0.2980998754501343
Validation loss: 1.5268171192497335

Epoch: 6| Step: 5
Training loss: 0.2664050757884979
Validation loss: 1.4932758282589655

Epoch: 6| Step: 6
Training loss: 0.410922646522522
Validation loss: 1.5248558892998645

Epoch: 6| Step: 7
Training loss: 0.31661221385002136
Validation loss: 1.5093070819813719

Epoch: 6| Step: 8
Training loss: 0.28952765464782715
Validation loss: 1.5271255611091532

Epoch: 6| Step: 9
Training loss: 0.3567523658275604
Validation loss: 1.5180296462069276

Epoch: 6| Step: 10
Training loss: 0.3430371880531311
Validation loss: 1.5170565715400122

Epoch: 6| Step: 11
Training loss: 0.18330347537994385
Validation loss: 1.5286552508672078

Epoch: 6| Step: 12
Training loss: 0.17474216222763062
Validation loss: 1.5367253031781924

Epoch: 6| Step: 13
Training loss: 0.2497657686471939
Validation loss: 1.5244904359181721

Epoch: 327| Step: 0
Training loss: 0.2757532298564911
Validation loss: 1.5777822848289245

Epoch: 6| Step: 1
Training loss: 0.23180198669433594
Validation loss: 1.5723440236942743

Epoch: 6| Step: 2
Training loss: 0.1354430913925171
Validation loss: 1.5533250865115915

Epoch: 6| Step: 3
Training loss: 0.26331499218940735
Validation loss: 1.5154310477677213

Epoch: 6| Step: 4
Training loss: 0.22923561930656433
Validation loss: 1.5200018677660214

Epoch: 6| Step: 5
Training loss: 0.21645033359527588
Validation loss: 1.5380655847569948

Epoch: 6| Step: 6
Training loss: 0.36726871132850647
Validation loss: 1.505343755086263

Epoch: 6| Step: 7
Training loss: 0.3168865740299225
Validation loss: 1.532569303307482

Epoch: 6| Step: 8
Training loss: 0.3004828095436096
Validation loss: 1.5505691779557096

Epoch: 6| Step: 9
Training loss: 0.2857029438018799
Validation loss: 1.5512954611932077

Epoch: 6| Step: 10
Training loss: 0.23073041439056396
Validation loss: 1.551136052736672

Epoch: 6| Step: 11
Training loss: 0.18989866971969604
Validation loss: 1.5154246514843357

Epoch: 6| Step: 12
Training loss: 0.23487073183059692
Validation loss: 1.525881052017212

Epoch: 6| Step: 13
Training loss: 0.18689706921577454
Validation loss: 1.5325231308578162

Epoch: 328| Step: 0
Training loss: 0.16030031442642212
Validation loss: 1.5346579474787558

Epoch: 6| Step: 1
Training loss: 0.20430171489715576
Validation loss: 1.5491410532305319

Epoch: 6| Step: 2
Training loss: 0.2912445068359375
Validation loss: 1.553597331047058

Epoch: 6| Step: 3
Training loss: 0.3026098906993866
Validation loss: 1.554350116560536

Epoch: 6| Step: 4
Training loss: 0.17297765612602234
Validation loss: 1.604358075767435

Epoch: 6| Step: 5
Training loss: 0.3703233599662781
Validation loss: 1.5739972873400616

Epoch: 6| Step: 6
Training loss: 0.3838185966014862
Validation loss: 1.554802043463594

Epoch: 6| Step: 7
Training loss: 0.3005055785179138
Validation loss: 1.4998283001684374

Epoch: 6| Step: 8
Training loss: 0.27577608823776245
Validation loss: 1.531317134057322

Epoch: 6| Step: 9
Training loss: 0.31525537371635437
Validation loss: 1.4741780655358427

Epoch: 6| Step: 10
Training loss: 0.19218039512634277
Validation loss: 1.5051442602629304

Epoch: 6| Step: 11
Training loss: 0.12291291356086731
Validation loss: 1.5110261517186319

Epoch: 6| Step: 12
Training loss: 0.2298109531402588
Validation loss: 1.513825317864777

Epoch: 6| Step: 13
Training loss: 0.4009159505367279
Validation loss: 1.5231178101672922

Epoch: 329| Step: 0
Training loss: 0.2699587941169739
Validation loss: 1.5340326537368119

Epoch: 6| Step: 1
Training loss: 0.1778673231601715
Validation loss: 1.5338142982093237

Epoch: 6| Step: 2
Training loss: 0.153832346200943
Validation loss: 1.5792860574619745

Epoch: 6| Step: 3
Training loss: 0.20522776246070862
Validation loss: 1.571173781348813

Epoch: 6| Step: 4
Training loss: 0.33925551176071167
Validation loss: 1.602381056354892

Epoch: 6| Step: 5
Training loss: 0.23646292090415955
Validation loss: 1.6039680332265875

Epoch: 6| Step: 6
Training loss: 0.2261771410703659
Validation loss: 1.5979081712743288

Epoch: 6| Step: 7
Training loss: 0.23646055161952972
Validation loss: 1.577309012413025

Epoch: 6| Step: 8
Training loss: 0.20481249690055847
Validation loss: 1.5953658229561263

Epoch: 6| Step: 9
Training loss: 0.389693021774292
Validation loss: 1.630765171461208

Epoch: 6| Step: 10
Training loss: 0.13990087807178497
Validation loss: 1.569414605376541

Epoch: 6| Step: 11
Training loss: 0.1920071840286255
Validation loss: 1.5832555018445498

Epoch: 6| Step: 12
Training loss: 0.4121744930744171
Validation loss: 1.5879916632047264

Epoch: 6| Step: 13
Training loss: 0.5465612411499023
Validation loss: 1.580066119470904

Epoch: 330| Step: 0
Training loss: 0.23772922158241272
Validation loss: 1.5951961932643768

Epoch: 6| Step: 1
Training loss: 0.20997151732444763
Validation loss: 1.6076927018421951

Epoch: 6| Step: 2
Training loss: 0.2743649482727051
Validation loss: 1.6074122664748982

Epoch: 6| Step: 3
Training loss: 0.26087892055511475
Validation loss: 1.6147122152390019

Epoch: 6| Step: 4
Training loss: 0.43505239486694336
Validation loss: 1.5809094393125145

Epoch: 6| Step: 5
Training loss: 0.2917746305465698
Validation loss: 1.5660955200913131

Epoch: 6| Step: 6
Training loss: 0.3191637396812439
Validation loss: 1.5613981575094245

Epoch: 6| Step: 7
Training loss: 0.24302445352077484
Validation loss: 1.5500059550808323

Epoch: 6| Step: 8
Training loss: 0.46882364153862
Validation loss: 1.5215428439519738

Epoch: 6| Step: 9
Training loss: 0.3491550385951996
Validation loss: 1.5663995973525509

Epoch: 6| Step: 10
Training loss: 0.3039345443248749
Validation loss: 1.5569488803545635

Epoch: 6| Step: 11
Training loss: 0.27900099754333496
Validation loss: 1.5909158927138134

Epoch: 6| Step: 12
Training loss: 0.2581433057785034
Validation loss: 1.5832224251121603

Epoch: 6| Step: 13
Training loss: 0.20418156683444977
Validation loss: 1.6024123827616374

Epoch: 331| Step: 0
Training loss: 0.26093214750289917
Validation loss: 1.605579621048384

Epoch: 6| Step: 1
Training loss: 0.3244912028312683
Validation loss: 1.5717960198720295

Epoch: 6| Step: 2
Training loss: 0.2309085577726364
Validation loss: 1.5970273402429396

Epoch: 6| Step: 3
Training loss: 0.3168635070323944
Validation loss: 1.542080803584027

Epoch: 6| Step: 4
Training loss: 0.30575674772262573
Validation loss: 1.543254376739584

Epoch: 6| Step: 5
Training loss: 0.10692258924245834
Validation loss: 1.5232378513582292

Epoch: 6| Step: 6
Training loss: 0.33040404319763184
Validation loss: 1.5142310934682046

Epoch: 6| Step: 7
Training loss: 0.4061080813407898
Validation loss: 1.5280940128910927

Epoch: 6| Step: 8
Training loss: 0.3660849928855896
Validation loss: 1.5584610059697142

Epoch: 6| Step: 9
Training loss: 0.15364260971546173
Validation loss: 1.5517303533451532

Epoch: 6| Step: 10
Training loss: 0.33297616243362427
Validation loss: 1.5620695737100416

Epoch: 6| Step: 11
Training loss: 0.5087704062461853
Validation loss: 1.551560942844678

Epoch: 6| Step: 12
Training loss: 0.24414126574993134
Validation loss: 1.5308964303744736

Epoch: 6| Step: 13
Training loss: 0.2391505241394043
Validation loss: 1.5315371815876295

Epoch: 332| Step: 0
Training loss: 0.24922674894332886
Validation loss: 1.5381571618459557

Epoch: 6| Step: 1
Training loss: 0.40781354904174805
Validation loss: 1.5109048171709942

Epoch: 6| Step: 2
Training loss: 0.22534045577049255
Validation loss: 1.5327853233583513

Epoch: 6| Step: 3
Training loss: 0.20919255912303925
Validation loss: 1.4937927287112

Epoch: 6| Step: 4
Training loss: 0.2345632165670395
Validation loss: 1.5111944995900637

Epoch: 6| Step: 5
Training loss: 0.35494980216026306
Validation loss: 1.4802897899381575

Epoch: 6| Step: 6
Training loss: 0.2449282705783844
Validation loss: 1.4763677632936867

Epoch: 6| Step: 7
Training loss: 0.3603978753089905
Validation loss: 1.4800095993985412

Epoch: 6| Step: 8
Training loss: 0.2807396650314331
Validation loss: 1.5180228025682512

Epoch: 6| Step: 9
Training loss: 0.23752525448799133
Validation loss: 1.509824945080665

Epoch: 6| Step: 10
Training loss: 0.3402811884880066
Validation loss: 1.4989956899355816

Epoch: 6| Step: 11
Training loss: 0.4013577103614807
Validation loss: 1.4941671176623272

Epoch: 6| Step: 12
Training loss: 0.2797430157661438
Validation loss: 1.462277256032472

Epoch: 6| Step: 13
Training loss: 0.26369524002075195
Validation loss: 1.439112897842161

Epoch: 333| Step: 0
Training loss: 0.476382315158844
Validation loss: 1.5086170537497408

Epoch: 6| Step: 1
Training loss: 0.2958320081233978
Validation loss: 1.5198961022079631

Epoch: 6| Step: 2
Training loss: 0.2510811388492584
Validation loss: 1.4945687888770975

Epoch: 6| Step: 3
Training loss: 0.2739313840866089
Validation loss: 1.5338950195620138

Epoch: 6| Step: 4
Training loss: 0.25806373357772827
Validation loss: 1.4955566172958703

Epoch: 6| Step: 5
Training loss: 0.2900931239128113
Validation loss: 1.4912040861704017

Epoch: 6| Step: 6
Training loss: 0.2374449372291565
Validation loss: 1.4962483093302736

Epoch: 6| Step: 7
Training loss: 0.19651386141777039
Validation loss: 1.510423493641679

Epoch: 6| Step: 8
Training loss: 0.4122965633869171
Validation loss: 1.514359551091348

Epoch: 6| Step: 9
Training loss: 0.2158278524875641
Validation loss: 1.539047625757033

Epoch: 6| Step: 10
Training loss: 0.2003435492515564
Validation loss: 1.5580754818454865

Epoch: 6| Step: 11
Training loss: 0.2623933255672455
Validation loss: 1.6061766493705012

Epoch: 6| Step: 12
Training loss: 0.19633284211158752
Validation loss: 1.571019390577911

Epoch: 6| Step: 13
Training loss: 0.2436533272266388
Validation loss: 1.6095834701291976

Epoch: 334| Step: 0
Training loss: 0.44903162121772766
Validation loss: 1.5672871951133973

Epoch: 6| Step: 1
Training loss: 0.3290443420410156
Validation loss: 1.568971428819882

Epoch: 6| Step: 2
Training loss: 0.25000855326652527
Validation loss: 1.5486143840256559

Epoch: 6| Step: 3
Training loss: 0.14337047934532166
Validation loss: 1.5648822758787422

Epoch: 6| Step: 4
Training loss: 0.2338058054447174
Validation loss: 1.5194628136132353

Epoch: 6| Step: 5
Training loss: 0.2153039276599884
Validation loss: 1.5210537551551737

Epoch: 6| Step: 6
Training loss: 0.3047559857368469
Validation loss: 1.5100871593721452

Epoch: 6| Step: 7
Training loss: 0.3469998836517334
Validation loss: 1.529053895704208

Epoch: 6| Step: 8
Training loss: 0.213923841714859
Validation loss: 1.4519111699955438

Epoch: 6| Step: 9
Training loss: 0.16297189891338348
Validation loss: 1.5019213345742994

Epoch: 6| Step: 10
Training loss: 0.26493191719055176
Validation loss: 1.4775184790293376

Epoch: 6| Step: 11
Training loss: 0.27100154757499695
Validation loss: 1.513482306593208

Epoch: 6| Step: 12
Training loss: 0.25595584511756897
Validation loss: 1.4982251095515426

Epoch: 6| Step: 13
Training loss: 0.14439265429973602
Validation loss: 1.4707307648915116

Epoch: 335| Step: 0
Training loss: 0.23850609362125397
Validation loss: 1.4581618879431038

Epoch: 6| Step: 1
Training loss: 0.2680649757385254
Validation loss: 1.4953971114209903

Epoch: 6| Step: 2
Training loss: 0.24356728792190552
Validation loss: 1.4790839687470467

Epoch: 6| Step: 3
Training loss: 0.28339120745658875
Validation loss: 1.4701313716109081

Epoch: 6| Step: 4
Training loss: 0.15585607290267944
Validation loss: 1.4972551227897726

Epoch: 6| Step: 5
Training loss: 0.23739546537399292
Validation loss: 1.5114805544576337

Epoch: 6| Step: 6
Training loss: 0.14001742005348206
Validation loss: 1.513801302961124

Epoch: 6| Step: 7
Training loss: 0.21875891089439392
Validation loss: 1.5366601379968787

Epoch: 6| Step: 8
Training loss: 0.36968564987182617
Validation loss: 1.5060177862003286

Epoch: 6| Step: 9
Training loss: 0.28580763936042786
Validation loss: 1.5431618408490253

Epoch: 6| Step: 10
Training loss: 0.15098267793655396
Validation loss: 1.548877796178223

Epoch: 6| Step: 11
Training loss: 0.2892967462539673
Validation loss: 1.5097826821829683

Epoch: 6| Step: 12
Training loss: 0.3113343119621277
Validation loss: 1.5591730199834353

Epoch: 6| Step: 13
Training loss: 0.21682478487491608
Validation loss: 1.5392297096149896

Epoch: 336| Step: 0
Training loss: 0.3528108596801758
Validation loss: 1.5162855002187914

Epoch: 6| Step: 1
Training loss: 0.2019832730293274
Validation loss: 1.541956461885924

Epoch: 6| Step: 2
Training loss: 0.18461816012859344
Validation loss: 1.5174347053291977

Epoch: 6| Step: 3
Training loss: 0.3178730607032776
Validation loss: 1.526704579271296

Epoch: 6| Step: 4
Training loss: 0.23901914060115814
Validation loss: 1.5349231919934672

Epoch: 6| Step: 5
Training loss: 0.21716277301311493
Validation loss: 1.5114202191752772

Epoch: 6| Step: 6
Training loss: 0.30753952264785767
Validation loss: 1.5218108238712433

Epoch: 6| Step: 7
Training loss: 0.3165397644042969
Validation loss: 1.527418601897455

Epoch: 6| Step: 8
Training loss: 0.2427414506673813
Validation loss: 1.5328528765709168

Epoch: 6| Step: 9
Training loss: 0.24849535524845123
Validation loss: 1.5322307681524625

Epoch: 6| Step: 10
Training loss: 0.3132517337799072
Validation loss: 1.5345523998301516

Epoch: 6| Step: 11
Training loss: 0.27661943435668945
Validation loss: 1.5176840930856683

Epoch: 6| Step: 12
Training loss: 0.2504708170890808
Validation loss: 1.537839581889491

Epoch: 6| Step: 13
Training loss: 0.2566482722759247
Validation loss: 1.536974307029478

Epoch: 337| Step: 0
Training loss: 0.31198251247406006
Validation loss: 1.4712398667489328

Epoch: 6| Step: 1
Training loss: 0.2836524248123169
Validation loss: 1.4996873960700086

Epoch: 6| Step: 2
Training loss: 0.28392767906188965
Validation loss: 1.5047758958672965

Epoch: 6| Step: 3
Training loss: 0.2296159416437149
Validation loss: 1.517626335543971

Epoch: 6| Step: 4
Training loss: 0.4030085802078247
Validation loss: 1.5652901722538857

Epoch: 6| Step: 5
Training loss: 0.375043660402298
Validation loss: 1.5229833433704991

Epoch: 6| Step: 6
Training loss: 0.22401802241802216
Validation loss: 1.5483207241181405

Epoch: 6| Step: 7
Training loss: 0.24419637024402618
Validation loss: 1.5479597263438727

Epoch: 6| Step: 8
Training loss: 0.29073983430862427
Validation loss: 1.5535029031897103

Epoch: 6| Step: 9
Training loss: 0.14782826602458954
Validation loss: 1.5313800111893685

Epoch: 6| Step: 10
Training loss: 0.21755775809288025
Validation loss: 1.568255606517997

Epoch: 6| Step: 11
Training loss: 0.23273080587387085
Validation loss: 1.5627033236206218

Epoch: 6| Step: 12
Training loss: 0.17609715461730957
Validation loss: 1.5523971024379934

Epoch: 6| Step: 13
Training loss: 0.5169841051101685
Validation loss: 1.526124354331724

Epoch: 338| Step: 0
Training loss: 0.2900392413139343
Validation loss: 1.5655288709107267

Epoch: 6| Step: 1
Training loss: 0.0927504152059555
Validation loss: 1.541614176124655

Epoch: 6| Step: 2
Training loss: 0.33887597918510437
Validation loss: 1.5152407897415983

Epoch: 6| Step: 3
Training loss: 0.1504901498556137
Validation loss: 1.501092888975656

Epoch: 6| Step: 4
Training loss: 0.14161662757396698
Validation loss: 1.5181889226359706

Epoch: 6| Step: 5
Training loss: 0.1718284636735916
Validation loss: 1.4798309213371688

Epoch: 6| Step: 6
Training loss: 0.3644530177116394
Validation loss: 1.5045233234282462

Epoch: 6| Step: 7
Training loss: 0.19375312328338623
Validation loss: 1.495840843005847

Epoch: 6| Step: 8
Training loss: 0.21280460059642792
Validation loss: 1.485532642692648

Epoch: 6| Step: 9
Training loss: 0.19192618131637573
Validation loss: 1.4595102610126618

Epoch: 6| Step: 10
Training loss: 0.3936261236667633
Validation loss: 1.4778731458930559

Epoch: 6| Step: 11
Training loss: 0.17019960284233093
Validation loss: 1.4791529114528368

Epoch: 6| Step: 12
Training loss: 0.2259049415588379
Validation loss: 1.4794586294440812

Epoch: 6| Step: 13
Training loss: 0.31053027510643005
Validation loss: 1.482168060477062

Epoch: 339| Step: 0
Training loss: 0.3093315660953522
Validation loss: 1.4748501816103536

Epoch: 6| Step: 1
Training loss: 0.29306840896606445
Validation loss: 1.5635914969187912

Epoch: 6| Step: 2
Training loss: 0.2844890058040619
Validation loss: 1.5301917708048256

Epoch: 6| Step: 3
Training loss: 0.32540440559387207
Validation loss: 1.5668584531353367

Epoch: 6| Step: 4
Training loss: 0.2738081216812134
Validation loss: 1.5898112174003356

Epoch: 6| Step: 5
Training loss: 0.31856608390808105
Validation loss: 1.5663408310182634

Epoch: 6| Step: 6
Training loss: 0.257302463054657
Validation loss: 1.5521018537141944

Epoch: 6| Step: 7
Training loss: 0.16635307669639587
Validation loss: 1.562117927817888

Epoch: 6| Step: 8
Training loss: 0.1521422564983368
Validation loss: 1.5755602992990965

Epoch: 6| Step: 9
Training loss: 0.16984683275222778
Validation loss: 1.5719666429745254

Epoch: 6| Step: 10
Training loss: 0.25631967186927795
Validation loss: 1.626296385642021

Epoch: 6| Step: 11
Training loss: 0.1314467191696167
Validation loss: 1.5742161812320832

Epoch: 6| Step: 12
Training loss: 0.2313106656074524
Validation loss: 1.5521758153874388

Epoch: 6| Step: 13
Training loss: 0.1982419639825821
Validation loss: 1.4906985567462059

Epoch: 340| Step: 0
Training loss: 0.18706074357032776
Validation loss: 1.5299222110420145

Epoch: 6| Step: 1
Training loss: 0.23685255646705627
Validation loss: 1.4776813381461686

Epoch: 6| Step: 2
Training loss: 0.3963249921798706
Validation loss: 1.4933199151869743

Epoch: 6| Step: 3
Training loss: 0.13809558749198914
Validation loss: 1.506682115216409

Epoch: 6| Step: 4
Training loss: 0.21054674685001373
Validation loss: 1.4652411424985496

Epoch: 6| Step: 5
Training loss: 0.21309296786785126
Validation loss: 1.499831150936824

Epoch: 6| Step: 6
Training loss: 0.29260289669036865
Validation loss: 1.477431276793121

Epoch: 6| Step: 7
Training loss: 0.23592332005500793
Validation loss: 1.480544828599499

Epoch: 6| Step: 8
Training loss: 0.29697558283805847
Validation loss: 1.4811078181830786

Epoch: 6| Step: 9
Training loss: 0.19048914313316345
Validation loss: 1.4938552007880261

Epoch: 6| Step: 10
Training loss: 0.1814342439174652
Validation loss: 1.5109124350291427

Epoch: 6| Step: 11
Training loss: 0.19921135902404785
Validation loss: 1.5348945510002874

Epoch: 6| Step: 12
Training loss: 0.4369269013404846
Validation loss: 1.5433939528721634

Epoch: 6| Step: 13
Training loss: 0.37238645553588867
Validation loss: 1.5747501824491767

Epoch: 341| Step: 0
Training loss: 0.22597907483577728
Validation loss: 1.5549741406594553

Epoch: 6| Step: 1
Training loss: 0.2873407006263733
Validation loss: 1.5646432035712785

Epoch: 6| Step: 2
Training loss: 0.24637550115585327
Validation loss: 1.5735698182095763

Epoch: 6| Step: 3
Training loss: 0.23213645815849304
Validation loss: 1.5510275799741027

Epoch: 6| Step: 4
Training loss: 0.2661994993686676
Validation loss: 1.5860414505004883

Epoch: 6| Step: 5
Training loss: 0.3269677460193634
Validation loss: 1.5662196515708842

Epoch: 6| Step: 6
Training loss: 0.3444204330444336
Validation loss: 1.5226571463769483

Epoch: 6| Step: 7
Training loss: 0.2808453440666199
Validation loss: 1.540161527613158

Epoch: 6| Step: 8
Training loss: 0.2470475137233734
Validation loss: 1.5236314573595602

Epoch: 6| Step: 9
Training loss: 0.31132733821868896
Validation loss: 1.4809064531839022

Epoch: 6| Step: 10
Training loss: 0.19725480675697327
Validation loss: 1.5265261178375573

Epoch: 6| Step: 11
Training loss: 0.19703730940818787
Validation loss: 1.496856084433935

Epoch: 6| Step: 12
Training loss: 0.25449439883232117
Validation loss: 1.47588546558093

Epoch: 6| Step: 13
Training loss: 0.19152557849884033
Validation loss: 1.5089613763234948

Epoch: 342| Step: 0
Training loss: 0.2888004183769226
Validation loss: 1.5089539597111363

Epoch: 6| Step: 1
Training loss: 0.2853739261627197
Validation loss: 1.5038027532639042

Epoch: 6| Step: 2
Training loss: 0.19666767120361328
Validation loss: 1.4905754186773812

Epoch: 6| Step: 3
Training loss: 0.22248929738998413
Validation loss: 1.5108844772461922

Epoch: 6| Step: 4
Training loss: 0.237508624792099
Validation loss: 1.5070907992701377

Epoch: 6| Step: 5
Training loss: 0.21096566319465637
Validation loss: 1.5329191107903757

Epoch: 6| Step: 6
Training loss: 0.1906716227531433
Validation loss: 1.5988301243833316

Epoch: 6| Step: 7
Training loss: 0.16861045360565186
Validation loss: 1.5901731214215677

Epoch: 6| Step: 8
Training loss: 0.28076156973838806
Validation loss: 1.6226953537233415

Epoch: 6| Step: 9
Training loss: 0.19438233971595764
Validation loss: 1.574842606821368

Epoch: 6| Step: 10
Training loss: 0.24973252415657043
Validation loss: 1.5980271498362224

Epoch: 6| Step: 11
Training loss: 0.36770668625831604
Validation loss: 1.499479987288034

Epoch: 6| Step: 12
Training loss: 0.34168338775634766
Validation loss: 1.5544508593056792

Epoch: 6| Step: 13
Training loss: 0.2875349223613739
Validation loss: 1.5514220153131792

Epoch: 343| Step: 0
Training loss: 0.19800570607185364
Validation loss: 1.588908838969405

Epoch: 6| Step: 1
Training loss: 0.2968827486038208
Validation loss: 1.5707401434580486

Epoch: 6| Step: 2
Training loss: 0.34341591596603394
Validation loss: 1.604353972660598

Epoch: 6| Step: 3
Training loss: 0.2951265275478363
Validation loss: 1.567584850454843

Epoch: 6| Step: 4
Training loss: 0.2132083773612976
Validation loss: 1.5911360709897933

Epoch: 6| Step: 5
Training loss: 0.10969165712594986
Validation loss: 1.581638854037049

Epoch: 6| Step: 6
Training loss: 0.25530457496643066
Validation loss: 1.6200720687066354

Epoch: 6| Step: 7
Training loss: 0.16335153579711914
Validation loss: 1.5516415276835043

Epoch: 6| Step: 8
Training loss: 0.21566487848758698
Validation loss: 1.5771502576848513

Epoch: 6| Step: 9
Training loss: 0.19110891222953796
Validation loss: 1.5651255230749808

Epoch: 6| Step: 10
Training loss: 0.17836987972259521
Validation loss: 1.5641977017925632

Epoch: 6| Step: 11
Training loss: 0.13644945621490479
Validation loss: 1.5405837848622312

Epoch: 6| Step: 12
Training loss: 0.3353516459465027
Validation loss: 1.5365024369250062

Epoch: 6| Step: 13
Training loss: 0.3733791410923004
Validation loss: 1.5706459437647173

Epoch: 344| Step: 0
Training loss: 0.30577927827835083
Validation loss: 1.5204617656687254

Epoch: 6| Step: 1
Training loss: 0.25167936086654663
Validation loss: 1.5582823432901853

Epoch: 6| Step: 2
Training loss: 0.19740301370620728
Validation loss: 1.5446846497956144

Epoch: 6| Step: 3
Training loss: 0.2509070038795471
Validation loss: 1.5521527233944143

Epoch: 6| Step: 4
Training loss: 0.19796696305274963
Validation loss: 1.5523526707003195

Epoch: 6| Step: 5
Training loss: 0.09785209596157074
Validation loss: 1.5295816647109164

Epoch: 6| Step: 6
Training loss: 0.20656718313694
Validation loss: 1.5495394058124994

Epoch: 6| Step: 7
Training loss: 0.23989060521125793
Validation loss: 1.5187007175978793

Epoch: 6| Step: 8
Training loss: 0.18708667159080505
Validation loss: 1.5343319626264675

Epoch: 6| Step: 9
Training loss: 0.1960812509059906
Validation loss: 1.5102116241249988

Epoch: 6| Step: 10
Training loss: 0.31053879857063293
Validation loss: 1.5146645961269256

Epoch: 6| Step: 11
Training loss: 0.270955890417099
Validation loss: 1.4827096141794676

Epoch: 6| Step: 12
Training loss: 0.1640978902578354
Validation loss: 1.4995141157539942

Epoch: 6| Step: 13
Training loss: 0.22087115049362183
Validation loss: 1.4662202686391852

Epoch: 345| Step: 0
Training loss: 0.23330265283584595
Validation loss: 1.502764981280091

Epoch: 6| Step: 1
Training loss: 0.179264098405838
Validation loss: 1.5091959263688774

Epoch: 6| Step: 2
Training loss: 0.23884618282318115
Validation loss: 1.476596111892372

Epoch: 6| Step: 3
Training loss: 0.2545877695083618
Validation loss: 1.4858776818039596

Epoch: 6| Step: 4
Training loss: 0.2460898607969284
Validation loss: 1.4945880328455279

Epoch: 6| Step: 5
Training loss: 0.3038550317287445
Validation loss: 1.4747879197520595

Epoch: 6| Step: 6
Training loss: 0.25350672006607056
Validation loss: 1.5000435652271393

Epoch: 6| Step: 7
Training loss: 0.2854821979999542
Validation loss: 1.4891592597448697

Epoch: 6| Step: 8
Training loss: 0.2237924039363861
Validation loss: 1.5160472623763546

Epoch: 6| Step: 9
Training loss: 0.23571708798408508
Validation loss: 1.544875979423523

Epoch: 6| Step: 10
Training loss: 0.25150495767593384
Validation loss: 1.539529069777458

Epoch: 6| Step: 11
Training loss: 0.1359647512435913
Validation loss: 1.56594814280028

Epoch: 6| Step: 12
Training loss: 0.2477419227361679
Validation loss: 1.5588781320920555

Epoch: 6| Step: 13
Training loss: 0.18627050518989563
Validation loss: 1.5653169103848037

Epoch: 346| Step: 0
Training loss: 0.32143068313598633
Validation loss: 1.5647402553148166

Epoch: 6| Step: 1
Training loss: 0.1338558793067932
Validation loss: 1.535150260053655

Epoch: 6| Step: 2
Training loss: 0.19155429303646088
Validation loss: 1.5752375395067277

Epoch: 6| Step: 3
Training loss: 0.282678484916687
Validation loss: 1.5493709887227705

Epoch: 6| Step: 4
Training loss: 0.20769089460372925
Validation loss: 1.5321210866333337

Epoch: 6| Step: 5
Training loss: 0.16740979254245758
Validation loss: 1.536148722453784

Epoch: 6| Step: 6
Training loss: 0.3304330110549927
Validation loss: 1.5134251271524737

Epoch: 6| Step: 7
Training loss: 0.1369870901107788
Validation loss: 1.536026907223527

Epoch: 6| Step: 8
Training loss: 0.1357763111591339
Validation loss: 1.5392195319616666

Epoch: 6| Step: 9
Training loss: 0.26246365904808044
Validation loss: 1.5612983075521325

Epoch: 6| Step: 10
Training loss: 0.15706142783164978
Validation loss: 1.5413962839752116

Epoch: 6| Step: 11
Training loss: 0.2919102609157562
Validation loss: 1.5649042360244259

Epoch: 6| Step: 12
Training loss: 0.309944748878479
Validation loss: 1.5179959420234925

Epoch: 6| Step: 13
Training loss: 0.13657504320144653
Validation loss: 1.5081688832211237

Epoch: 347| Step: 0
Training loss: 0.28501784801483154
Validation loss: 1.507167136797341

Epoch: 6| Step: 1
Training loss: 0.24055223166942596
Validation loss: 1.5442848846476565

Epoch: 6| Step: 2
Training loss: 0.1527930498123169
Validation loss: 1.5486753929045893

Epoch: 6| Step: 3
Training loss: 0.24760273098945618
Validation loss: 1.6070202781308083

Epoch: 6| Step: 4
Training loss: 0.1530907154083252
Validation loss: 1.5793643997561546

Epoch: 6| Step: 5
Training loss: 0.39509373903274536
Validation loss: 1.5976957864658807

Epoch: 6| Step: 6
Training loss: 0.21852299571037292
Validation loss: 1.5851503751611198

Epoch: 6| Step: 7
Training loss: 0.19428317248821259
Validation loss: 1.5856019245680941

Epoch: 6| Step: 8
Training loss: 0.1958770751953125
Validation loss: 1.6151245024896437

Epoch: 6| Step: 9
Training loss: 0.2297772765159607
Validation loss: 1.5812208511496102

Epoch: 6| Step: 10
Training loss: 0.17095191776752472
Validation loss: 1.6113631520220029

Epoch: 6| Step: 11
Training loss: 0.2151518315076828
Validation loss: 1.5886467682418002

Epoch: 6| Step: 12
Training loss: 0.2148085981607437
Validation loss: 1.5739632191196564

Epoch: 6| Step: 13
Training loss: 0.18451203405857086
Validation loss: 1.5827140808105469

Epoch: 348| Step: 0
Training loss: 0.19286729395389557
Validation loss: 1.5688382143615394

Epoch: 6| Step: 1
Training loss: 0.3065733015537262
Validation loss: 1.5676561658100416

Epoch: 6| Step: 2
Training loss: 0.2600652277469635
Validation loss: 1.5299363751565256

Epoch: 6| Step: 3
Training loss: 0.1872273087501526
Validation loss: 1.546581950238956

Epoch: 6| Step: 4
Training loss: 0.24527409672737122
Validation loss: 1.54984240634467

Epoch: 6| Step: 5
Training loss: 0.19972413778305054
Validation loss: 1.5759947633230558

Epoch: 6| Step: 6
Training loss: 0.19745224714279175
Validation loss: 1.5261570766407957

Epoch: 6| Step: 7
Training loss: 0.2839782238006592
Validation loss: 1.5451254062755133

Epoch: 6| Step: 8
Training loss: 0.3397195339202881
Validation loss: 1.4896575225296842

Epoch: 6| Step: 9
Training loss: 0.26009857654571533
Validation loss: 1.4767134010150869

Epoch: 6| Step: 10
Training loss: 0.2477445900440216
Validation loss: 1.4997250328781784

Epoch: 6| Step: 11
Training loss: 0.3372951149940491
Validation loss: 1.472571906223092

Epoch: 6| Step: 12
Training loss: 0.2057279795408249
Validation loss: 1.4893238249645437

Epoch: 6| Step: 13
Training loss: 0.18699614703655243
Validation loss: 1.522941820083126

Epoch: 349| Step: 0
Training loss: 0.20376336574554443
Validation loss: 1.529445190583506

Epoch: 6| Step: 1
Training loss: 0.1796395182609558
Validation loss: 1.5551652177687614

Epoch: 6| Step: 2
Training loss: 0.22677552700042725
Validation loss: 1.5244234338883431

Epoch: 6| Step: 3
Training loss: 0.2523099184036255
Validation loss: 1.5739868494772142

Epoch: 6| Step: 4
Training loss: 0.2980960011482239
Validation loss: 1.595946228632363

Epoch: 6| Step: 5
Training loss: 0.16726666688919067
Validation loss: 1.6266101970467517

Epoch: 6| Step: 6
Training loss: 0.26348406076431274
Validation loss: 1.5896441987765733

Epoch: 6| Step: 7
Training loss: 0.23090165853500366
Validation loss: 1.5867407091202275

Epoch: 6| Step: 8
Training loss: 0.20835326611995697
Validation loss: 1.580293034994474

Epoch: 6| Step: 9
Training loss: 0.24358290433883667
Validation loss: 1.553098617061492

Epoch: 6| Step: 10
Training loss: 0.21757256984710693
Validation loss: 1.52668813608026

Epoch: 6| Step: 11
Training loss: 0.13066774606704712
Validation loss: 1.5279690950147566

Epoch: 6| Step: 12
Training loss: 0.5216719508171082
Validation loss: 1.4699052277431692

Epoch: 6| Step: 13
Training loss: 0.19973570108413696
Validation loss: 1.4823454406953627

Epoch: 350| Step: 0
Training loss: 0.2731933891773224
Validation loss: 1.460159101793843

Epoch: 6| Step: 1
Training loss: 0.3086618185043335
Validation loss: 1.509655507661963

Epoch: 6| Step: 2
Training loss: 0.19395625591278076
Validation loss: 1.5438421951827181

Epoch: 6| Step: 3
Training loss: 0.31309062242507935
Validation loss: 1.5578526361014253

Epoch: 6| Step: 4
Training loss: 0.20768675208091736
Validation loss: 1.5562829855949647

Epoch: 6| Step: 5
Training loss: 0.22304494678974152
Validation loss: 1.5496093765381844

Epoch: 6| Step: 6
Training loss: 0.13375979661941528
Validation loss: 1.5485452708377634

Epoch: 6| Step: 7
Training loss: 0.14730390906333923
Validation loss: 1.5963871248306767

Epoch: 6| Step: 8
Training loss: 0.25197091698646545
Validation loss: 1.578742750229374

Epoch: 6| Step: 9
Training loss: 0.27418088912963867
Validation loss: 1.6021991468244983

Epoch: 6| Step: 10
Training loss: 0.22074928879737854
Validation loss: 1.615072674648736

Epoch: 6| Step: 11
Training loss: 0.30014151334762573
Validation loss: 1.6094984598057245

Epoch: 6| Step: 12
Training loss: 0.31924909353256226
Validation loss: 1.5657260917848157

Epoch: 6| Step: 13
Training loss: 0.12211176753044128
Validation loss: 1.5647694603089364

Epoch: 351| Step: 0
Training loss: 0.18862250447273254
Validation loss: 1.5647214279379895

Epoch: 6| Step: 1
Training loss: 0.27673429250717163
Validation loss: 1.5605620504707418

Epoch: 6| Step: 2
Training loss: 0.2170516550540924
Validation loss: 1.5968024717864169

Epoch: 6| Step: 3
Training loss: 0.20094585418701172
Validation loss: 1.6051338936692925

Epoch: 6| Step: 4
Training loss: 0.22838057577610016
Validation loss: 1.5969200621369064

Epoch: 6| Step: 5
Training loss: 0.26694318652153015
Validation loss: 1.542603326100175

Epoch: 6| Step: 6
Training loss: 0.19722023606300354
Validation loss: 1.4732064726532146

Epoch: 6| Step: 7
Training loss: 0.2713199555873871
Validation loss: 1.479563614373566

Epoch: 6| Step: 8
Training loss: 0.22639517486095428
Validation loss: 1.5057205923141972

Epoch: 6| Step: 9
Training loss: 0.32548463344573975
Validation loss: 1.5071607443594164

Epoch: 6| Step: 10
Training loss: 0.3060617744922638
Validation loss: 1.5176728387032785

Epoch: 6| Step: 11
Training loss: 0.17272163927555084
Validation loss: 1.5791194631207375

Epoch: 6| Step: 12
Training loss: 0.3469904363155365
Validation loss: 1.5573027274941886

Epoch: 6| Step: 13
Training loss: 0.060631878674030304
Validation loss: 1.550205579368017

Epoch: 352| Step: 0
Training loss: 0.24756506085395813
Validation loss: 1.5600825855808873

Epoch: 6| Step: 1
Training loss: 0.2314637005329132
Validation loss: 1.5449842124856927

Epoch: 6| Step: 2
Training loss: 0.225315660238266
Validation loss: 1.5329546159313572

Epoch: 6| Step: 3
Training loss: 0.13051165640354156
Validation loss: 1.5350404785525413

Epoch: 6| Step: 4
Training loss: 0.3388047218322754
Validation loss: 1.5058784613045313

Epoch: 6| Step: 5
Training loss: 0.12741616368293762
Validation loss: 1.5785903943482267

Epoch: 6| Step: 6
Training loss: 0.1799442321062088
Validation loss: 1.5960397579336678

Epoch: 6| Step: 7
Training loss: 0.21856901049613953
Validation loss: 1.5823118340584539

Epoch: 6| Step: 8
Training loss: 0.19192218780517578
Validation loss: 1.5558596554622854

Epoch: 6| Step: 9
Training loss: 0.1844465136528015
Validation loss: 1.5476747879417994

Epoch: 6| Step: 10
Training loss: 0.16908928751945496
Validation loss: 1.544231386594875

Epoch: 6| Step: 11
Training loss: 0.21293190121650696
Validation loss: 1.5032912210751606

Epoch: 6| Step: 12
Training loss: 0.26983368396759033
Validation loss: 1.5072892731235874

Epoch: 6| Step: 13
Training loss: 0.16816385090351105
Validation loss: 1.5497211012788998

Epoch: 353| Step: 0
Training loss: 0.2625601291656494
Validation loss: 1.5584224500963766

Epoch: 6| Step: 1
Training loss: 0.27591532468795776
Validation loss: 1.533525836083197

Epoch: 6| Step: 2
Training loss: 0.2709771394729614
Validation loss: 1.5018259286880493

Epoch: 6| Step: 3
Training loss: 0.21337544918060303
Validation loss: 1.5487826806242748

Epoch: 6| Step: 4
Training loss: 0.2265998274087906
Validation loss: 1.5205185208269345

Epoch: 6| Step: 5
Training loss: 0.143730029463768
Validation loss: 1.50901698681616

Epoch: 6| Step: 6
Training loss: 0.18395134806632996
Validation loss: 1.4979512627406786

Epoch: 6| Step: 7
Training loss: 0.24392494559288025
Validation loss: 1.4947753631940452

Epoch: 6| Step: 8
Training loss: 0.13699615001678467
Validation loss: 1.4564699742101854

Epoch: 6| Step: 9
Training loss: 0.1781715750694275
Validation loss: 1.500132328720503

Epoch: 6| Step: 10
Training loss: 0.23937800526618958
Validation loss: 1.506160133628435

Epoch: 6| Step: 11
Training loss: 0.28534841537475586
Validation loss: 1.517647494551956

Epoch: 6| Step: 12
Training loss: 0.29040759801864624
Validation loss: 1.4920268186958887

Epoch: 6| Step: 13
Training loss: 0.24380318820476532
Validation loss: 1.525012118842012

Epoch: 354| Step: 0
Training loss: 0.1956178843975067
Validation loss: 1.528332882030036

Epoch: 6| Step: 1
Training loss: 0.15547582507133484
Validation loss: 1.4959027510817333

Epoch: 6| Step: 2
Training loss: 0.1361120492219925
Validation loss: 1.5241453186158211

Epoch: 6| Step: 3
Training loss: 0.1053353101015091
Validation loss: 1.5048433080796273

Epoch: 6| Step: 4
Training loss: 0.2795340418815613
Validation loss: 1.4878555190178655

Epoch: 6| Step: 5
Training loss: 0.17157195508480072
Validation loss: 1.532968331408757

Epoch: 6| Step: 6
Training loss: 0.42592769861221313
Validation loss: 1.4957253599679599

Epoch: 6| Step: 7
Training loss: 0.3622792959213257
Validation loss: 1.5291734946671354

Epoch: 6| Step: 8
Training loss: 0.2148638516664505
Validation loss: 1.5369492205240394

Epoch: 6| Step: 9
Training loss: 0.10903292149305344
Validation loss: 1.528071298394152

Epoch: 6| Step: 10
Training loss: 0.18320341408252716
Validation loss: 1.5184070179539342

Epoch: 6| Step: 11
Training loss: 0.16521921753883362
Validation loss: 1.5059415294278053

Epoch: 6| Step: 12
Training loss: 0.1440703272819519
Validation loss: 1.5009155042709843

Epoch: 6| Step: 13
Training loss: 0.23395217955112457
Validation loss: 1.5097203164972284

Epoch: 355| Step: 0
Training loss: 0.26661643385887146
Validation loss: 1.5492674663502684

Epoch: 6| Step: 1
Training loss: 0.33395135402679443
Validation loss: 1.5461670826840144

Epoch: 6| Step: 2
Training loss: 0.10814950615167618
Validation loss: 1.549136874496296

Epoch: 6| Step: 3
Training loss: 0.2180788815021515
Validation loss: 1.553592521657226

Epoch: 6| Step: 4
Training loss: 0.09227354824542999
Validation loss: 1.5172238362732755

Epoch: 6| Step: 5
Training loss: 0.21377873420715332
Validation loss: 1.546151808513108

Epoch: 6| Step: 6
Training loss: 0.19379030168056488
Validation loss: 1.5408600786680817

Epoch: 6| Step: 7
Training loss: 0.19361716508865356
Validation loss: 1.5557161749050181

Epoch: 6| Step: 8
Training loss: 0.18880817294120789
Validation loss: 1.5263591863775765

Epoch: 6| Step: 9
Training loss: 0.2293579876422882
Validation loss: 1.488244359211255

Epoch: 6| Step: 10
Training loss: 0.2546842694282532
Validation loss: 1.5380320766920685

Epoch: 6| Step: 11
Training loss: 0.26992425322532654
Validation loss: 1.5156871759763328

Epoch: 6| Step: 12
Training loss: 0.2619597017765045
Validation loss: 1.5353837038881035

Epoch: 6| Step: 13
Training loss: 0.47469764947891235
Validation loss: 1.551111239258961

Epoch: 356| Step: 0
Training loss: 0.32195258140563965
Validation loss: 1.4899699854594406

Epoch: 6| Step: 1
Training loss: 0.19422641396522522
Validation loss: 1.5120064148338892

Epoch: 6| Step: 2
Training loss: 0.2669486403465271
Validation loss: 1.5205434394139115

Epoch: 6| Step: 3
Training loss: 0.256852924823761
Validation loss: 1.5786965931615522

Epoch: 6| Step: 4
Training loss: 0.27191606163978577
Validation loss: 1.6092048332255373

Epoch: 6| Step: 5
Training loss: 0.23892328143119812
Validation loss: 1.6427895586977723

Epoch: 6| Step: 6
Training loss: 0.2488369345664978
Validation loss: 1.6201048621567347

Epoch: 6| Step: 7
Training loss: 0.14141607284545898
Validation loss: 1.6121527430831746

Epoch: 6| Step: 8
Training loss: 0.22500553727149963
Validation loss: 1.5866819863678308

Epoch: 6| Step: 9
Training loss: 0.16819339990615845
Validation loss: 1.5460364600663543

Epoch: 6| Step: 10
Training loss: 0.19188867509365082
Validation loss: 1.5524390717988372

Epoch: 6| Step: 11
Training loss: 0.18895216286182404
Validation loss: 1.5739346409356723

Epoch: 6| Step: 12
Training loss: 0.3416948914527893
Validation loss: 1.5727151023444308

Epoch: 6| Step: 13
Training loss: 0.24649201333522797
Validation loss: 1.5800960166479951

Epoch: 357| Step: 0
Training loss: 0.2397095263004303
Validation loss: 1.5476434384622881

Epoch: 6| Step: 1
Training loss: 0.19566383957862854
Validation loss: 1.5382431655801752

Epoch: 6| Step: 2
Training loss: 0.2853257656097412
Validation loss: 1.5394226171637093

Epoch: 6| Step: 3
Training loss: 0.3246976435184479
Validation loss: 1.5908455630784393

Epoch: 6| Step: 4
Training loss: 0.1370871663093567
Validation loss: 1.6091308209203905

Epoch: 6| Step: 5
Training loss: 0.24045881628990173
Validation loss: 1.5904722803382463

Epoch: 6| Step: 6
Training loss: 0.19543880224227905
Validation loss: 1.5687879541868806

Epoch: 6| Step: 7
Training loss: 0.18216663599014282
Validation loss: 1.515220872817501

Epoch: 6| Step: 8
Training loss: 0.2444145679473877
Validation loss: 1.5320814988946403

Epoch: 6| Step: 9
Training loss: 0.2083275020122528
Validation loss: 1.5002159764689784

Epoch: 6| Step: 10
Training loss: 0.29070568084716797
Validation loss: 1.5193884257347352

Epoch: 6| Step: 11
Training loss: 0.17242436110973358
Validation loss: 1.5225252310434978

Epoch: 6| Step: 12
Training loss: 0.28460365533828735
Validation loss: 1.4649244457162836

Epoch: 6| Step: 13
Training loss: 0.2635310888290405
Validation loss: 1.4830203081971856

Epoch: 358| Step: 0
Training loss: 0.10381527245044708
Validation loss: 1.4768763306320354

Epoch: 6| Step: 1
Training loss: 0.18508680164813995
Validation loss: 1.4900158682177145

Epoch: 6| Step: 2
Training loss: 0.18049627542495728
Validation loss: 1.479498532510573

Epoch: 6| Step: 3
Training loss: 0.29713714122772217
Validation loss: 1.469204004092883

Epoch: 6| Step: 4
Training loss: 0.30821967124938965
Validation loss: 1.5291774439555343

Epoch: 6| Step: 5
Training loss: 0.14253272116184235
Validation loss: 1.545933820868051

Epoch: 6| Step: 6
Training loss: 0.32596534490585327
Validation loss: 1.5826987066576559

Epoch: 6| Step: 7
Training loss: 0.16126951575279236
Validation loss: 1.5661572692214802

Epoch: 6| Step: 8
Training loss: 0.24409347772598267
Validation loss: 1.5788911363129974

Epoch: 6| Step: 9
Training loss: 0.2550637125968933
Validation loss: 1.5013045598101873

Epoch: 6| Step: 10
Training loss: 0.21985165774822235
Validation loss: 1.5041997201981083

Epoch: 6| Step: 11
Training loss: 0.2527647018432617
Validation loss: 1.5307611746172751

Epoch: 6| Step: 12
Training loss: 0.22123336791992188
Validation loss: 1.4821211150897446

Epoch: 6| Step: 13
Training loss: 0.3225916624069214
Validation loss: 1.484814768196434

Epoch: 359| Step: 0
Training loss: 0.21378162503242493
Validation loss: 1.5494046531697756

Epoch: 6| Step: 1
Training loss: 0.20922622084617615
Validation loss: 1.5332606351503761

Epoch: 6| Step: 2
Training loss: 0.16282528638839722
Validation loss: 1.5117350726999261

Epoch: 6| Step: 3
Training loss: 0.16772550344467163
Validation loss: 1.508337878411816

Epoch: 6| Step: 4
Training loss: 0.28140705823898315
Validation loss: 1.4898220646765925

Epoch: 6| Step: 5
Training loss: 0.23798714578151703
Validation loss: 1.5192625009885399

Epoch: 6| Step: 6
Training loss: 0.1907944679260254
Validation loss: 1.5280709087207753

Epoch: 6| Step: 7
Training loss: 0.303459107875824
Validation loss: 1.5374739259801886

Epoch: 6| Step: 8
Training loss: 0.27402031421661377
Validation loss: 1.5738214651743572

Epoch: 6| Step: 9
Training loss: 0.3000714182853699
Validation loss: 1.566376934769333

Epoch: 6| Step: 10
Training loss: 0.12272481620311737
Validation loss: 1.5825746020963114

Epoch: 6| Step: 11
Training loss: 0.12031601369380951
Validation loss: 1.5420095651380477

Epoch: 6| Step: 12
Training loss: 0.21826013922691345
Validation loss: 1.5370594083621938

Epoch: 6| Step: 13
Training loss: 0.16183887422084808
Validation loss: 1.4955360120342625

Epoch: 360| Step: 0
Training loss: 0.13599202036857605
Validation loss: 1.503106624849381

Epoch: 6| Step: 1
Training loss: 0.163102388381958
Validation loss: 1.5135862711937196

Epoch: 6| Step: 2
Training loss: 0.3040757179260254
Validation loss: 1.5028161912836053

Epoch: 6| Step: 3
Training loss: 0.32327285408973694
Validation loss: 1.497786755202919

Epoch: 6| Step: 4
Training loss: 0.14698052406311035
Validation loss: 1.502306777943847

Epoch: 6| Step: 5
Training loss: 0.36503833532333374
Validation loss: 1.484171425142596

Epoch: 6| Step: 6
Training loss: 0.2151360958814621
Validation loss: 1.500805308741908

Epoch: 6| Step: 7
Training loss: 0.2226591557264328
Validation loss: 1.539695410318272

Epoch: 6| Step: 8
Training loss: 0.25089654326438904
Validation loss: 1.5377323486471688

Epoch: 6| Step: 9
Training loss: 0.22932255268096924
Validation loss: 1.5611730852434713

Epoch: 6| Step: 10
Training loss: 0.22320936620235443
Validation loss: 1.55820966792363

Epoch: 6| Step: 11
Training loss: 0.17580293118953705
Validation loss: 1.5384321251223165

Epoch: 6| Step: 12
Training loss: 0.20295366644859314
Validation loss: 1.5448618332544963

Epoch: 6| Step: 13
Training loss: 0.07787799835205078
Validation loss: 1.5192623497337423

Epoch: 361| Step: 0
Training loss: 0.20503239333629608
Validation loss: 1.4937292927054948

Epoch: 6| Step: 1
Training loss: 0.20112404227256775
Validation loss: 1.515546775633289

Epoch: 6| Step: 2
Training loss: 0.2251608967781067
Validation loss: 1.4949104196281844

Epoch: 6| Step: 3
Training loss: 0.11145801842212677
Validation loss: 1.5361987108825355

Epoch: 6| Step: 4
Training loss: 0.1956174075603485
Validation loss: 1.520233920825425

Epoch: 6| Step: 5
Training loss: 0.17218658328056335
Validation loss: 1.5343780325305076

Epoch: 6| Step: 6
Training loss: 0.1582852303981781
Validation loss: 1.5458529046786729

Epoch: 6| Step: 7
Training loss: 0.13102120161056519
Validation loss: 1.5557452658171296

Epoch: 6| Step: 8
Training loss: 0.36117246747016907
Validation loss: 1.5836435082138225

Epoch: 6| Step: 9
Training loss: 0.2319623827934265
Validation loss: 1.5417697711657452

Epoch: 6| Step: 10
Training loss: 0.2758045196533203
Validation loss: 1.5201812136557795

Epoch: 6| Step: 11
Training loss: 0.16189634799957275
Validation loss: 1.5218994175234148

Epoch: 6| Step: 12
Training loss: 0.20123349130153656
Validation loss: 1.5210341574043356

Epoch: 6| Step: 13
Training loss: 0.1910620480775833
Validation loss: 1.5134543052283667

Epoch: 362| Step: 0
Training loss: 0.1217082142829895
Validation loss: 1.5503177642822266

Epoch: 6| Step: 1
Training loss: 0.2694758474826813
Validation loss: 1.5554859266486218

Epoch: 6| Step: 2
Training loss: 0.21693937480449677
Validation loss: 1.5407802879169423

Epoch: 6| Step: 3
Training loss: 0.18588437139987946
Validation loss: 1.5365818924801324

Epoch: 6| Step: 4
Training loss: 0.10155610740184784
Validation loss: 1.545972724114695

Epoch: 6| Step: 5
Training loss: 0.18264895677566528
Validation loss: 1.5122013899587816

Epoch: 6| Step: 6
Training loss: 0.16452831029891968
Validation loss: 1.518834929312429

Epoch: 6| Step: 7
Training loss: 0.16021154820919037
Validation loss: 1.5340591502446

Epoch: 6| Step: 8
Training loss: 0.22331781685352325
Validation loss: 1.5225991536212224

Epoch: 6| Step: 9
Training loss: 0.14314612746238708
Validation loss: 1.4955151709177161

Epoch: 6| Step: 10
Training loss: 0.27781522274017334
Validation loss: 1.4495796984241855

Epoch: 6| Step: 11
Training loss: 0.2835044860839844
Validation loss: 1.445993947726424

Epoch: 6| Step: 12
Training loss: 0.2254886031150818
Validation loss: 1.483179767926534

Epoch: 6| Step: 13
Training loss: 0.2970018684864044
Validation loss: 1.4696901075301632

Epoch: 363| Step: 0
Training loss: 0.15382122993469238
Validation loss: 1.4517781734466553

Epoch: 6| Step: 1
Training loss: 0.19166997075080872
Validation loss: 1.4748601464815037

Epoch: 6| Step: 2
Training loss: 0.17483064532279968
Validation loss: 1.4442570581231067

Epoch: 6| Step: 3
Training loss: 0.09179581701755524
Validation loss: 1.4518089307251798

Epoch: 6| Step: 4
Training loss: 0.2326532006263733
Validation loss: 1.4727360266511158

Epoch: 6| Step: 5
Training loss: 0.23579800128936768
Validation loss: 1.4568614498261483

Epoch: 6| Step: 6
Training loss: 0.1744430512189865
Validation loss: 1.4802593966966033

Epoch: 6| Step: 7
Training loss: 0.113351970911026
Validation loss: 1.513068845195155

Epoch: 6| Step: 8
Training loss: 0.2319653183221817
Validation loss: 1.487734524152612

Epoch: 6| Step: 9
Training loss: 0.21649470925331116
Validation loss: 1.5091742392509215

Epoch: 6| Step: 10
Training loss: 0.27879518270492554
Validation loss: 1.5359405356068765

Epoch: 6| Step: 11
Training loss: 0.16383635997772217
Validation loss: 1.5093170660798267

Epoch: 6| Step: 12
Training loss: 0.3517726957798004
Validation loss: 1.4691916261949847

Epoch: 6| Step: 13
Training loss: 0.30107805132865906
Validation loss: 1.47150343976995

Epoch: 364| Step: 0
Training loss: 0.27130427956581116
Validation loss: 1.5018350590941727

Epoch: 6| Step: 1
Training loss: 0.18427255749702454
Validation loss: 1.4964015586401826

Epoch: 6| Step: 2
Training loss: 0.15731161832809448
Validation loss: 1.4920488448553189

Epoch: 6| Step: 3
Training loss: 0.24505773186683655
Validation loss: 1.4784092723682363

Epoch: 6| Step: 4
Training loss: 0.2591661810874939
Validation loss: 1.4675503071918283

Epoch: 6| Step: 5
Training loss: 0.16994976997375488
Validation loss: 1.4949086430252239

Epoch: 6| Step: 6
Training loss: 0.11873801052570343
Validation loss: 1.4879868825276692

Epoch: 6| Step: 7
Training loss: 0.1458827555179596
Validation loss: 1.5220554464606828

Epoch: 6| Step: 8
Training loss: 0.07983517646789551
Validation loss: 1.5040326336378693

Epoch: 6| Step: 9
Training loss: 0.2218157947063446
Validation loss: 1.5034400698959187

Epoch: 6| Step: 10
Training loss: 0.12960755825042725
Validation loss: 1.4771719773610432

Epoch: 6| Step: 11
Training loss: 0.1308159977197647
Validation loss: 1.4994018564942062

Epoch: 6| Step: 12
Training loss: 0.18103539943695068
Validation loss: 1.4972705943610078

Epoch: 6| Step: 13
Training loss: 0.0873885527253151
Validation loss: 1.5023526991567304

Epoch: 365| Step: 0
Training loss: 0.14218388497829437
Validation loss: 1.521083084485864

Epoch: 6| Step: 1
Training loss: 0.1257275938987732
Validation loss: 1.539490169094455

Epoch: 6| Step: 2
Training loss: 0.14425824582576752
Validation loss: 1.5508342917247484

Epoch: 6| Step: 3
Training loss: 0.1386796236038208
Validation loss: 1.5143622365049136

Epoch: 6| Step: 4
Training loss: 0.2587299048900604
Validation loss: 1.5291448895649244

Epoch: 6| Step: 5
Training loss: 0.21667088568210602
Validation loss: 1.5034111251113236

Epoch: 6| Step: 6
Training loss: 0.20230211317539215
Validation loss: 1.523981644261268

Epoch: 6| Step: 7
Training loss: 0.13850322365760803
Validation loss: 1.5027837035476521

Epoch: 6| Step: 8
Training loss: 0.18294334411621094
Validation loss: 1.5376609935555408

Epoch: 6| Step: 9
Training loss: 0.18797147274017334
Validation loss: 1.5150150393926969

Epoch: 6| Step: 10
Training loss: 0.1624450385570526
Validation loss: 1.5429351073439403

Epoch: 6| Step: 11
Training loss: 0.14411135017871857
Validation loss: 1.517915028397755

Epoch: 6| Step: 12
Training loss: 0.2041746973991394
Validation loss: 1.508755354471104

Epoch: 6| Step: 13
Training loss: 0.1492013931274414
Validation loss: 1.5269782953364874

Epoch: 366| Step: 0
Training loss: 0.13338744640350342
Validation loss: 1.521617644576616

Epoch: 6| Step: 1
Training loss: 0.1619074046611786
Validation loss: 1.5181694017943514

Epoch: 6| Step: 2
Training loss: 0.20873478055000305
Validation loss: 1.5299519351733628

Epoch: 6| Step: 3
Training loss: 0.14722901582717896
Validation loss: 1.4998458111157982

Epoch: 6| Step: 4
Training loss: 0.1361701786518097
Validation loss: 1.4775331827902025

Epoch: 6| Step: 5
Training loss: 0.12844201922416687
Validation loss: 1.5140890690588182

Epoch: 6| Step: 6
Training loss: 0.2765677869319916
Validation loss: 1.5304032871800084

Epoch: 6| Step: 7
Training loss: 0.21042422950267792
Validation loss: 1.5062113551683323

Epoch: 6| Step: 8
Training loss: 0.15349841117858887
Validation loss: 1.532734065927485

Epoch: 6| Step: 9
Training loss: 0.2758401334285736
Validation loss: 1.5343044496351672

Epoch: 6| Step: 10
Training loss: 0.26213693618774414
Validation loss: 1.5081933275345834

Epoch: 6| Step: 11
Training loss: 0.24041572213172913
Validation loss: 1.500520275485131

Epoch: 6| Step: 12
Training loss: 0.1395382583141327
Validation loss: 1.5067819920919274

Epoch: 6| Step: 13
Training loss: 0.13933496177196503
Validation loss: 1.5149773179843862

Epoch: 367| Step: 0
Training loss: 0.15986347198486328
Validation loss: 1.4875620834289058

Epoch: 6| Step: 1
Training loss: 0.18091830611228943
Validation loss: 1.5453411648350377

Epoch: 6| Step: 2
Training loss: 0.1800626814365387
Validation loss: 1.5267494724642845

Epoch: 6| Step: 3
Training loss: 0.13773229718208313
Validation loss: 1.5178634521140848

Epoch: 6| Step: 4
Training loss: 0.11307034641504288
Validation loss: 1.5177158181385328

Epoch: 6| Step: 5
Training loss: 0.14535978436470032
Validation loss: 1.5315553808725009

Epoch: 6| Step: 6
Training loss: 0.264114111661911
Validation loss: 1.4867821598565707

Epoch: 6| Step: 7
Training loss: 0.22175225615501404
Validation loss: 1.530390880441153

Epoch: 6| Step: 8
Training loss: 0.1763981133699417
Validation loss: 1.5143470071977185

Epoch: 6| Step: 9
Training loss: 0.1845223605632782
Validation loss: 1.5006058241731377

Epoch: 6| Step: 10
Training loss: 0.14500963687896729
Validation loss: 1.485029742281924

Epoch: 6| Step: 11
Training loss: 0.1750524342060089
Validation loss: 1.4993797835483347

Epoch: 6| Step: 12
Training loss: 0.1965932995080948
Validation loss: 1.5067870463094404

Epoch: 6| Step: 13
Training loss: 0.2376886010169983
Validation loss: 1.4947977322404102

Epoch: 368| Step: 0
Training loss: 0.11769546568393707
Validation loss: 1.4629612802177347

Epoch: 6| Step: 1
Training loss: 0.2057359516620636
Validation loss: 1.469103749080371

Epoch: 6| Step: 2
Training loss: 0.1972304880619049
Validation loss: 1.4733548036185644

Epoch: 6| Step: 3
Training loss: 0.17790377140045166
Validation loss: 1.4839406833853772

Epoch: 6| Step: 4
Training loss: 0.18303415179252625
Validation loss: 1.4895099978293143

Epoch: 6| Step: 5
Training loss: 0.19532322883605957
Validation loss: 1.4819529915368685

Epoch: 6| Step: 6
Training loss: 0.2627561092376709
Validation loss: 1.456245364681367

Epoch: 6| Step: 7
Training loss: 0.18346822261810303
Validation loss: 1.4797491053099274

Epoch: 6| Step: 8
Training loss: 0.2072695791721344
Validation loss: 1.515569858653571

Epoch: 6| Step: 9
Training loss: 0.28051650524139404
Validation loss: 1.5525311257249566

Epoch: 6| Step: 10
Training loss: 0.27829891443252563
Validation loss: 1.5925913536420433

Epoch: 6| Step: 11
Training loss: 0.31035298109054565
Validation loss: 1.5797685833387478

Epoch: 6| Step: 12
Training loss: 0.17146258056163788
Validation loss: 1.5105813011046378

Epoch: 6| Step: 13
Training loss: 0.2527313828468323
Validation loss: 1.500416016065946

Epoch: 369| Step: 0
Training loss: 0.16052889823913574
Validation loss: 1.454040478634578

Epoch: 6| Step: 1
Training loss: 0.1758263111114502
Validation loss: 1.470491099101241

Epoch: 6| Step: 2
Training loss: 0.1697351038455963
Validation loss: 1.4996803011945499

Epoch: 6| Step: 3
Training loss: 0.16667440533638
Validation loss: 1.5270473354606218

Epoch: 6| Step: 4
Training loss: 0.18905727565288544
Validation loss: 1.5147667572062502

Epoch: 6| Step: 5
Training loss: 0.14669831097126007
Validation loss: 1.5083615292784989

Epoch: 6| Step: 6
Training loss: 0.2507551908493042
Validation loss: 1.5195919890557565

Epoch: 6| Step: 7
Training loss: 0.17186355590820312
Validation loss: 1.4927431248849439

Epoch: 6| Step: 8
Training loss: 0.21448974311351776
Validation loss: 1.546365305941592

Epoch: 6| Step: 9
Training loss: 0.2337413877248764
Validation loss: 1.4988914651255454

Epoch: 6| Step: 10
Training loss: 0.2082105576992035
Validation loss: 1.5335005496137886

Epoch: 6| Step: 11
Training loss: 0.28141695261001587
Validation loss: 1.5045204931689846

Epoch: 6| Step: 12
Training loss: 0.19928628206253052
Validation loss: 1.5552944880659862

Epoch: 6| Step: 13
Training loss: 0.16665641963481903
Validation loss: 1.5772062950236823

Epoch: 370| Step: 0
Training loss: 0.22297900915145874
Validation loss: 1.548343047018974

Epoch: 6| Step: 1
Training loss: 0.17954608798027039
Validation loss: 1.5920175031949115

Epoch: 6| Step: 2
Training loss: 0.1795196831226349
Validation loss: 1.559246891288347

Epoch: 6| Step: 3
Training loss: 0.18672649562358856
Validation loss: 1.574992408034622

Epoch: 6| Step: 4
Training loss: 0.17163985967636108
Validation loss: 1.5655335252003004

Epoch: 6| Step: 5
Training loss: 0.18436673283576965
Validation loss: 1.5360159755394023

Epoch: 6| Step: 6
Training loss: 0.23447342216968536
Validation loss: 1.5340051407455115

Epoch: 6| Step: 7
Training loss: 0.15723270177841187
Validation loss: 1.5239362832038634

Epoch: 6| Step: 8
Training loss: 0.15199118852615356
Validation loss: 1.5217604598691385

Epoch: 6| Step: 9
Training loss: 0.2465684711933136
Validation loss: 1.5377436748114965

Epoch: 6| Step: 10
Training loss: 0.24452562630176544
Validation loss: 1.5173062598833473

Epoch: 6| Step: 11
Training loss: 0.19927889108657837
Validation loss: 1.5285314193335913

Epoch: 6| Step: 12
Training loss: 0.09609581530094147
Validation loss: 1.505252311306615

Epoch: 6| Step: 13
Training loss: 0.20664355158805847
Validation loss: 1.521973306132901

Epoch: 371| Step: 0
Training loss: 0.13996663689613342
Validation loss: 1.5234563683950773

Epoch: 6| Step: 1
Training loss: 0.09838492423295975
Validation loss: 1.525437012795479

Epoch: 6| Step: 2
Training loss: 0.30154675245285034
Validation loss: 1.551283174945462

Epoch: 6| Step: 3
Training loss: 0.18563120067119598
Validation loss: 1.5329296960625598

Epoch: 6| Step: 4
Training loss: 0.28367576003074646
Validation loss: 1.5208447530705442

Epoch: 6| Step: 5
Training loss: 0.22268006205558777
Validation loss: 1.5447488882208382

Epoch: 6| Step: 6
Training loss: 0.17947405576705933
Validation loss: 1.5503324552248883

Epoch: 6| Step: 7
Training loss: 0.18814343214035034
Validation loss: 1.5641717551856913

Epoch: 6| Step: 8
Training loss: 0.21916785836219788
Validation loss: 1.5505682627360027

Epoch: 6| Step: 9
Training loss: 0.19950571656227112
Validation loss: 1.5483594991827523

Epoch: 6| Step: 10
Training loss: 0.1739521026611328
Validation loss: 1.5439397096633911

Epoch: 6| Step: 11
Training loss: 0.2344382405281067
Validation loss: 1.5083201444277199

Epoch: 6| Step: 12
Training loss: 0.15068528056144714
Validation loss: 1.4973610306298861

Epoch: 6| Step: 13
Training loss: 0.16574618220329285
Validation loss: 1.4986053218123734

Epoch: 372| Step: 0
Training loss: 0.21568724513053894
Validation loss: 1.5473725103562879

Epoch: 6| Step: 1
Training loss: 0.2618013620376587
Validation loss: 1.548967561414165

Epoch: 6| Step: 2
Training loss: 0.19147345423698425
Validation loss: 1.5703628460566204

Epoch: 6| Step: 3
Training loss: 0.2046942114830017
Validation loss: 1.5697060067166564

Epoch: 6| Step: 4
Training loss: 0.19691595435142517
Validation loss: 1.5458342016384166

Epoch: 6| Step: 5
Training loss: 0.15034650266170502
Validation loss: 1.5062715443231727

Epoch: 6| Step: 6
Training loss: 0.3134964406490326
Validation loss: 1.5189648943562661

Epoch: 6| Step: 7
Training loss: 0.14291855692863464
Validation loss: 1.4953559483251264

Epoch: 6| Step: 8
Training loss: 0.28432202339172363
Validation loss: 1.4998901492805892

Epoch: 6| Step: 9
Training loss: 0.122026726603508
Validation loss: 1.5329124619883876

Epoch: 6| Step: 10
Training loss: 0.22317366302013397
Validation loss: 1.5285376079620854

Epoch: 6| Step: 11
Training loss: 0.27578315138816833
Validation loss: 1.5203798573504212

Epoch: 6| Step: 12
Training loss: 0.22204048931598663
Validation loss: 1.5384394667481864

Epoch: 6| Step: 13
Training loss: 0.21631069481372833
Validation loss: 1.5296050015316214

Epoch: 373| Step: 0
Training loss: 0.15199798345565796
Validation loss: 1.5063071135551698

Epoch: 6| Step: 1
Training loss: 0.16324970126152039
Validation loss: 1.5377214679154017

Epoch: 6| Step: 2
Training loss: 0.15158122777938843
Validation loss: 1.5318207304964784

Epoch: 6| Step: 3
Training loss: 0.14820706844329834
Validation loss: 1.5172373043593539

Epoch: 6| Step: 4
Training loss: 0.23407423496246338
Validation loss: 1.5584966726200555

Epoch: 6| Step: 5
Training loss: 0.11645392328500748
Validation loss: 1.527158805119094

Epoch: 6| Step: 6
Training loss: 0.27625101804733276
Validation loss: 1.6033896233445855

Epoch: 6| Step: 7
Training loss: 0.17432500422000885
Validation loss: 1.5857706018673476

Epoch: 6| Step: 8
Training loss: 0.18276599049568176
Validation loss: 1.6067354422743603

Epoch: 6| Step: 9
Training loss: 0.1545839011669159
Validation loss: 1.613600992387341

Epoch: 6| Step: 10
Training loss: 0.24068300426006317
Validation loss: 1.6067395466630177

Epoch: 6| Step: 11
Training loss: 0.14599710702896118
Validation loss: 1.5994197617294967

Epoch: 6| Step: 12
Training loss: 0.23483064770698547
Validation loss: 1.603939066651047

Epoch: 6| Step: 13
Training loss: 0.20535705983638763
Validation loss: 1.616133254061463

Epoch: 374| Step: 0
Training loss: 0.21907338500022888
Validation loss: 1.5849763911257508

Epoch: 6| Step: 1
Training loss: 0.2535243034362793
Validation loss: 1.5988031459111038

Epoch: 6| Step: 2
Training loss: 0.2457493245601654
Validation loss: 1.5507904009152484

Epoch: 6| Step: 3
Training loss: 0.23700526356697083
Validation loss: 1.5255374716174217

Epoch: 6| Step: 4
Training loss: 0.23209601640701294
Validation loss: 1.517436178781653

Epoch: 6| Step: 5
Training loss: 0.1285739243030548
Validation loss: 1.5325855183345016

Epoch: 6| Step: 6
Training loss: 0.1565391719341278
Validation loss: 1.515457441729884

Epoch: 6| Step: 7
Training loss: 0.19965386390686035
Validation loss: 1.5239154625964422

Epoch: 6| Step: 8
Training loss: 0.21099640429019928
Validation loss: 1.5241993601604173

Epoch: 6| Step: 9
Training loss: 0.15210425853729248
Validation loss: 1.488076247194762

Epoch: 6| Step: 10
Training loss: 0.1728897988796234
Validation loss: 1.490548792705741

Epoch: 6| Step: 11
Training loss: 0.2073579579591751
Validation loss: 1.500956646216813

Epoch: 6| Step: 12
Training loss: 0.13778215646743774
Validation loss: 1.4505455481108798

Epoch: 6| Step: 13
Training loss: 0.21863143146038055
Validation loss: 1.488009407956113

Epoch: 375| Step: 0
Training loss: 0.17161348462104797
Validation loss: 1.50391383453082

Epoch: 6| Step: 1
Training loss: 0.16159415245056152
Validation loss: 1.4944671738532282

Epoch: 6| Step: 2
Training loss: 0.19522184133529663
Validation loss: 1.484536865706085

Epoch: 6| Step: 3
Training loss: 0.17404159903526306
Validation loss: 1.4737208991922357

Epoch: 6| Step: 4
Training loss: 0.3158057630062103
Validation loss: 1.5344646823021673

Epoch: 6| Step: 5
Training loss: 0.15850462019443512
Validation loss: 1.4945825005090365

Epoch: 6| Step: 6
Training loss: 0.1338309794664383
Validation loss: 1.4972122600001674

Epoch: 6| Step: 7
Training loss: 0.1963699609041214
Validation loss: 1.503715153663389

Epoch: 6| Step: 8
Training loss: 0.18866251409053802
Validation loss: 1.4833819968726045

Epoch: 6| Step: 9
Training loss: 0.25437694787979126
Validation loss: 1.4908361358027304

Epoch: 6| Step: 10
Training loss: 0.1094384714961052
Validation loss: 1.4711956990662443

Epoch: 6| Step: 11
Training loss: 0.15824957191944122
Validation loss: 1.50143555671938

Epoch: 6| Step: 12
Training loss: 0.16255313158035278
Validation loss: 1.4997560619026102

Epoch: 6| Step: 13
Training loss: 0.1621006280183792
Validation loss: 1.527190774999639

Epoch: 376| Step: 0
Training loss: 0.20573951303958893
Validation loss: 1.5125758314645419

Epoch: 6| Step: 1
Training loss: 0.17045193910598755
Validation loss: 1.5470229054010043

Epoch: 6| Step: 2
Training loss: 0.18095919489860535
Validation loss: 1.511197578522467

Epoch: 6| Step: 3
Training loss: 0.11317110061645508
Validation loss: 1.5350335477500834

Epoch: 6| Step: 4
Training loss: 0.14738509058952332
Validation loss: 1.504692978756402

Epoch: 6| Step: 5
Training loss: 0.16357731819152832
Validation loss: 1.4991861581802368

Epoch: 6| Step: 6
Training loss: 0.22673062980175018
Validation loss: 1.489296397855205

Epoch: 6| Step: 7
Training loss: 0.17427997291088104
Validation loss: 1.493423335013851

Epoch: 6| Step: 8
Training loss: 0.14479371905326843
Validation loss: 1.4820177631993448

Epoch: 6| Step: 9
Training loss: 0.10638934373855591
Validation loss: 1.4897307939426874

Epoch: 6| Step: 10
Training loss: 0.24297583103179932
Validation loss: 1.4865678253994192

Epoch: 6| Step: 11
Training loss: 0.12976384162902832
Validation loss: 1.495872325794671

Epoch: 6| Step: 12
Training loss: 0.1333821713924408
Validation loss: 1.5148643550052439

Epoch: 6| Step: 13
Training loss: 0.2576799988746643
Validation loss: 1.484727995370024

Epoch: 377| Step: 0
Training loss: 0.08816111087799072
Validation loss: 1.4970558279304094

Epoch: 6| Step: 1
Training loss: 0.17905373871326447
Validation loss: 1.4996752572315994

Epoch: 6| Step: 2
Training loss: 0.20959025621414185
Validation loss: 1.5169226110622447

Epoch: 6| Step: 3
Training loss: 0.20423755049705505
Validation loss: 1.4941888483621741

Epoch: 6| Step: 4
Training loss: 0.105936199426651
Validation loss: 1.4618901488601521

Epoch: 6| Step: 5
Training loss: 0.14945225417613983
Validation loss: 1.4864655387017034

Epoch: 6| Step: 6
Training loss: 0.15789148211479187
Validation loss: 1.4978438987526843

Epoch: 6| Step: 7
Training loss: 0.14992453157901764
Validation loss: 1.48902936391933

Epoch: 6| Step: 8
Training loss: 0.14103491604328156
Validation loss: 1.5285157772802538

Epoch: 6| Step: 9
Training loss: 0.21408456563949585
Validation loss: 1.5285209865980252

Epoch: 6| Step: 10
Training loss: 0.21857041120529175
Validation loss: 1.5424779922731462

Epoch: 6| Step: 11
Training loss: 0.25340819358825684
Validation loss: 1.5284391885162683

Epoch: 6| Step: 12
Training loss: 0.13727827370166779
Validation loss: 1.519785605451112

Epoch: 6| Step: 13
Training loss: 0.22221797704696655
Validation loss: 1.5236317893510223

Epoch: 378| Step: 0
Training loss: 0.15882062911987305
Validation loss: 1.5122138428431686

Epoch: 6| Step: 1
Training loss: 0.17680832743644714
Validation loss: 1.5060251899944839

Epoch: 6| Step: 2
Training loss: 0.1883351355791092
Validation loss: 1.5050559428430372

Epoch: 6| Step: 3
Training loss: 0.1587994247674942
Validation loss: 1.4752602474663847

Epoch: 6| Step: 4
Training loss: 0.10017047822475433
Validation loss: 1.4739481851618776

Epoch: 6| Step: 5
Training loss: 0.1102827861905098
Validation loss: 1.4933217968992007

Epoch: 6| Step: 6
Training loss: 0.19709694385528564
Validation loss: 1.5338665048281352

Epoch: 6| Step: 7
Training loss: 0.21942031383514404
Validation loss: 1.5051772850815968

Epoch: 6| Step: 8
Training loss: 0.15098558366298676
Validation loss: 1.483969191069244

Epoch: 6| Step: 9
Training loss: 0.3322380781173706
Validation loss: 1.4803105823455318

Epoch: 6| Step: 10
Training loss: 0.17654135823249817
Validation loss: 1.4399422586605113

Epoch: 6| Step: 11
Training loss: 0.15810848772525787
Validation loss: 1.4660431505531393

Epoch: 6| Step: 12
Training loss: 0.25456297397613525
Validation loss: 1.4560198835147324

Epoch: 6| Step: 13
Training loss: 0.14613282680511475
Validation loss: 1.4380410300788058

Epoch: 379| Step: 0
Training loss: 0.0883941575884819
Validation loss: 1.4480983006056918

Epoch: 6| Step: 1
Training loss: 0.20527566969394684
Validation loss: 1.4822858854006695

Epoch: 6| Step: 2
Training loss: 0.32704126834869385
Validation loss: 1.4691691244802167

Epoch: 6| Step: 3
Training loss: 0.1649966537952423
Validation loss: 1.478930394495687

Epoch: 6| Step: 4
Training loss: 0.26095372438430786
Validation loss: 1.4708015854640673

Epoch: 6| Step: 5
Training loss: 0.15415866672992706
Validation loss: 1.478119771967652

Epoch: 6| Step: 6
Training loss: 0.12220809608697891
Validation loss: 1.4742746276240195

Epoch: 6| Step: 7
Training loss: 0.2660650610923767
Validation loss: 1.492765494572219

Epoch: 6| Step: 8
Training loss: 0.21875755488872528
Validation loss: 1.47610971812279

Epoch: 6| Step: 9
Training loss: 0.14753587543964386
Validation loss: 1.4704814598124514

Epoch: 6| Step: 10
Training loss: 0.2203163504600525
Validation loss: 1.4939249266860306

Epoch: 6| Step: 11
Training loss: 0.21316897869110107
Validation loss: 1.5176675973399993

Epoch: 6| Step: 12
Training loss: 0.24423667788505554
Validation loss: 1.5279868879625875

Epoch: 6| Step: 13
Training loss: 0.10319558531045914
Validation loss: 1.523118761277968

Epoch: 380| Step: 0
Training loss: 0.18880270421504974
Validation loss: 1.5213885589312481

Epoch: 6| Step: 1
Training loss: 0.11441456526517868
Validation loss: 1.5067199737794938

Epoch: 6| Step: 2
Training loss: 0.13267692923545837
Validation loss: 1.518732637487432

Epoch: 6| Step: 3
Training loss: 0.194255992770195
Validation loss: 1.4866923978251796

Epoch: 6| Step: 4
Training loss: 0.18594497442245483
Validation loss: 1.5471579656806043

Epoch: 6| Step: 5
Training loss: 0.19617252051830292
Validation loss: 1.5471619200962845

Epoch: 6| Step: 6
Training loss: 0.285391628742218
Validation loss: 1.5654313884755617

Epoch: 6| Step: 7
Training loss: 0.18934069573879242
Validation loss: 1.558366802430922

Epoch: 6| Step: 8
Training loss: 0.23029349744319916
Validation loss: 1.5586615762402933

Epoch: 6| Step: 9
Training loss: 0.2748052477836609
Validation loss: 1.5675299174042159

Epoch: 6| Step: 10
Training loss: 0.1448281854391098
Validation loss: 1.5479782255746986

Epoch: 6| Step: 11
Training loss: 0.18527334928512573
Validation loss: 1.523439645767212

Epoch: 6| Step: 12
Training loss: 0.12648051977157593
Validation loss: 1.5427554320263606

Epoch: 6| Step: 13
Training loss: 0.28175440430641174
Validation loss: 1.5056874239316551

Epoch: 381| Step: 0
Training loss: 0.18720170855522156
Validation loss: 1.5182024176402757

Epoch: 6| Step: 1
Training loss: 0.1842772662639618
Validation loss: 1.4976335366566975

Epoch: 6| Step: 2
Training loss: 0.10693259537220001
Validation loss: 1.4734235040603145

Epoch: 6| Step: 3
Training loss: 0.16861453652381897
Validation loss: 1.4775340236643308

Epoch: 6| Step: 4
Training loss: 0.11733043193817139
Validation loss: 1.4604428199029738

Epoch: 6| Step: 5
Training loss: 0.30472445487976074
Validation loss: 1.4546889079514371

Epoch: 6| Step: 6
Training loss: 0.15803252160549164
Validation loss: 1.4652128270877305

Epoch: 6| Step: 7
Training loss: 0.22232164442539215
Validation loss: 1.4728235801060994

Epoch: 6| Step: 8
Training loss: 0.16011765599250793
Validation loss: 1.4530838510041595

Epoch: 6| Step: 9
Training loss: 0.1626134067773819
Validation loss: 1.4526720957089496

Epoch: 6| Step: 10
Training loss: 0.20818865299224854
Validation loss: 1.5395016939409318

Epoch: 6| Step: 11
Training loss: 0.2786571681499481
Validation loss: 1.5840094166417276

Epoch: 6| Step: 12
Training loss: 0.21102003753185272
Validation loss: 1.5606968659226612

Epoch: 6| Step: 13
Training loss: 0.2810094654560089
Validation loss: 1.5725345637208672

Epoch: 382| Step: 0
Training loss: 0.26201093196868896
Validation loss: 1.5202031250922912

Epoch: 6| Step: 1
Training loss: 0.17112159729003906
Validation loss: 1.4924574000861055

Epoch: 6| Step: 2
Training loss: 0.17290696501731873
Validation loss: 1.4663064633646319

Epoch: 6| Step: 3
Training loss: 0.19402113556861877
Validation loss: 1.4781146549409436

Epoch: 6| Step: 4
Training loss: 0.2634389400482178
Validation loss: 1.4776338402942946

Epoch: 6| Step: 5
Training loss: 0.19109311699867249
Validation loss: 1.4843784442511938

Epoch: 6| Step: 6
Training loss: 0.15253880620002747
Validation loss: 1.5003777614203833

Epoch: 6| Step: 7
Training loss: 0.24344097077846527
Validation loss: 1.4846541054787175

Epoch: 6| Step: 8
Training loss: 0.21030516922473907
Validation loss: 1.509089522464301

Epoch: 6| Step: 9
Training loss: 0.24344149231910706
Validation loss: 1.4820197500208372

Epoch: 6| Step: 10
Training loss: 0.20503149926662445
Validation loss: 1.521379856653111

Epoch: 6| Step: 11
Training loss: 0.16750377416610718
Validation loss: 1.4896627087746896

Epoch: 6| Step: 12
Training loss: 0.18282729387283325
Validation loss: 1.5337472872067524

Epoch: 6| Step: 13
Training loss: 0.3479013442993164
Validation loss: 1.5521002892524964

Epoch: 383| Step: 0
Training loss: 0.23817715048789978
Validation loss: 1.5630619807909893

Epoch: 6| Step: 1
Training loss: 0.5024890899658203
Validation loss: 1.6409162834126463

Epoch: 6| Step: 2
Training loss: 0.362573504447937
Validation loss: 1.6152556596263763

Epoch: 6| Step: 3
Training loss: 0.21345770359039307
Validation loss: 1.5959388440655125

Epoch: 6| Step: 4
Training loss: 0.3270148038864136
Validation loss: 1.59734978342569

Epoch: 6| Step: 5
Training loss: 0.3596949577331543
Validation loss: 1.519298654730602

Epoch: 6| Step: 6
Training loss: 0.17803119122982025
Validation loss: 1.4570585053454164

Epoch: 6| Step: 7
Training loss: 0.2709301710128784
Validation loss: 1.4534074741025125

Epoch: 6| Step: 8
Training loss: 0.2849019169807434
Validation loss: 1.4549542011753205

Epoch: 6| Step: 9
Training loss: 0.12856541574001312
Validation loss: 1.46629072261113

Epoch: 6| Step: 10
Training loss: 0.22142432630062103
Validation loss: 1.5046260549176125

Epoch: 6| Step: 11
Training loss: 0.19470849633216858
Validation loss: 1.4759023766363821

Epoch: 6| Step: 12
Training loss: 0.25658148527145386
Validation loss: 1.4928624219791864

Epoch: 6| Step: 13
Training loss: 0.21516773104667664
Validation loss: 1.5161516525412118

Epoch: 384| Step: 0
Training loss: 0.23640793561935425
Validation loss: 1.5231392255393408

Epoch: 6| Step: 1
Training loss: 0.26997479796409607
Validation loss: 1.5111738212646977

Epoch: 6| Step: 2
Training loss: 0.1627875566482544
Validation loss: 1.5210963090260823

Epoch: 6| Step: 3
Training loss: 0.15169772505760193
Validation loss: 1.4935038794753372

Epoch: 6| Step: 4
Training loss: 0.22453075647354126
Validation loss: 1.532039338542569

Epoch: 6| Step: 5
Training loss: 0.2528355121612549
Validation loss: 1.533650444399926

Epoch: 6| Step: 6
Training loss: 0.2569304406642914
Validation loss: 1.5635649696473153

Epoch: 6| Step: 7
Training loss: 0.25904521346092224
Validation loss: 1.5186442854583904

Epoch: 6| Step: 8
Training loss: 0.4611738324165344
Validation loss: 1.5121216876532442

Epoch: 6| Step: 9
Training loss: 0.2371615767478943
Validation loss: 1.50163225717442

Epoch: 6| Step: 10
Training loss: 0.21597284078598022
Validation loss: 1.4741064271619242

Epoch: 6| Step: 11
Training loss: 0.19679908454418182
Validation loss: 1.4460174447746688

Epoch: 6| Step: 12
Training loss: 0.14422842860221863
Validation loss: 1.4339898350418254

Epoch: 6| Step: 13
Training loss: 0.13073402643203735
Validation loss: 1.4407641195481824

Epoch: 385| Step: 0
Training loss: 0.10734425485134125
Validation loss: 1.4482844298885715

Epoch: 6| Step: 1
Training loss: 0.15135473012924194
Validation loss: 1.4270747182189778

Epoch: 6| Step: 2
Training loss: 0.1763676255941391
Validation loss: 1.4410963148199103

Epoch: 6| Step: 3
Training loss: 0.2347113937139511
Validation loss: 1.413941070597659

Epoch: 6| Step: 4
Training loss: 0.15425273776054382
Validation loss: 1.446027563464257

Epoch: 6| Step: 5
Training loss: 0.21006827056407928
Validation loss: 1.4445314407348633

Epoch: 6| Step: 6
Training loss: 0.11697649210691452
Validation loss: 1.4921906314870363

Epoch: 6| Step: 7
Training loss: 0.14491388201713562
Validation loss: 1.5210273458111672

Epoch: 6| Step: 8
Training loss: 0.179075688123703
Validation loss: 1.4898608128229778

Epoch: 6| Step: 9
Training loss: 0.1952386498451233
Validation loss: 1.4798181121067335

Epoch: 6| Step: 10
Training loss: 0.2068319320678711
Validation loss: 1.5106577745047949

Epoch: 6| Step: 11
Training loss: 0.14212054014205933
Validation loss: 1.4968763538586196

Epoch: 6| Step: 12
Training loss: 0.15806764364242554
Validation loss: 1.4703528842618387

Epoch: 6| Step: 13
Training loss: 0.27100563049316406
Validation loss: 1.4639937903291436

Epoch: 386| Step: 0
Training loss: 0.1657857745885849
Validation loss: 1.4839396476745605

Epoch: 6| Step: 1
Training loss: 0.18090558052062988
Validation loss: 1.4910425986013105

Epoch: 6| Step: 2
Training loss: 0.32271426916122437
Validation loss: 1.5052866096137671

Epoch: 6| Step: 3
Training loss: 0.1893804371356964
Validation loss: 1.5209480267699047

Epoch: 6| Step: 4
Training loss: 0.15530121326446533
Validation loss: 1.5354303083112162

Epoch: 6| Step: 5
Training loss: 0.1735108345746994
Validation loss: 1.5028454270414127

Epoch: 6| Step: 6
Training loss: 0.22615592181682587
Validation loss: 1.5141262469753143

Epoch: 6| Step: 7
Training loss: 0.16746005415916443
Validation loss: 1.5341140954725203

Epoch: 6| Step: 8
Training loss: 0.1587848663330078
Validation loss: 1.5076097749894666

Epoch: 6| Step: 9
Training loss: 0.17204411327838898
Validation loss: 1.519445865384994

Epoch: 6| Step: 10
Training loss: 0.13649117946624756
Validation loss: 1.5087125916634836

Epoch: 6| Step: 11
Training loss: 0.12730851769447327
Validation loss: 1.48724510464617

Epoch: 6| Step: 12
Training loss: 0.146136075258255
Validation loss: 1.4750163209053777

Epoch: 6| Step: 13
Training loss: 0.18747259676456451
Validation loss: 1.4964639858532978

Epoch: 387| Step: 0
Training loss: 0.21668243408203125
Validation loss: 1.469276996069057

Epoch: 6| Step: 1
Training loss: 0.21053700149059296
Validation loss: 1.4589348710993284

Epoch: 6| Step: 2
Training loss: 0.17759831249713898
Validation loss: 1.432692268843292

Epoch: 6| Step: 3
Training loss: 0.2681959271430969
Validation loss: 1.4557961110145814

Epoch: 6| Step: 4
Training loss: 0.18863017857074738
Validation loss: 1.452301183054524

Epoch: 6| Step: 5
Training loss: 0.14328095316886902
Validation loss: 1.4659985778152302

Epoch: 6| Step: 6
Training loss: 0.09462790936231613
Validation loss: 1.4568979458142353

Epoch: 6| Step: 7
Training loss: 0.2779291868209839
Validation loss: 1.407411620181094

Epoch: 6| Step: 8
Training loss: 0.1420314460992813
Validation loss: 1.3869955283339306

Epoch: 6| Step: 9
Training loss: 0.23548784852027893
Validation loss: 1.399218177282682

Epoch: 6| Step: 10
Training loss: 0.14316780865192413
Validation loss: 1.4251635350206846

Epoch: 6| Step: 11
Training loss: 0.23261304199695587
Validation loss: 1.480232282351422

Epoch: 6| Step: 12
Training loss: 0.11378694325685501
Validation loss: 1.4402120690191946

Epoch: 6| Step: 13
Training loss: 0.12856896221637726
Validation loss: 1.4842129292026642

Epoch: 388| Step: 0
Training loss: 0.19324377179145813
Validation loss: 1.5022428189554522

Epoch: 6| Step: 1
Training loss: 0.11541462689638138
Validation loss: 1.4911757066685667

Epoch: 6| Step: 2
Training loss: 0.32578045129776
Validation loss: 1.4832844343236697

Epoch: 6| Step: 3
Training loss: 0.19910314679145813
Validation loss: 1.4759070206713933

Epoch: 6| Step: 4
Training loss: 0.2980397939682007
Validation loss: 1.4681116816818074

Epoch: 6| Step: 5
Training loss: 0.17080473899841309
Validation loss: 1.5232354466633131

Epoch: 6| Step: 6
Training loss: 0.3260708451271057
Validation loss: 1.5355582980699436

Epoch: 6| Step: 7
Training loss: 0.17048613727092743
Validation loss: 1.5325119194164072

Epoch: 6| Step: 8
Training loss: 0.23533615469932556
Validation loss: 1.532763405512738

Epoch: 6| Step: 9
Training loss: 0.17642909288406372
Validation loss: 1.5160012027268768

Epoch: 6| Step: 10
Training loss: 0.289455771446228
Validation loss: 1.4945016458470335

Epoch: 6| Step: 11
Training loss: 0.23363041877746582
Validation loss: 1.4982452674578595

Epoch: 6| Step: 12
Training loss: 0.18302014470100403
Validation loss: 1.437481354641658

Epoch: 6| Step: 13
Training loss: 0.18719924986362457
Validation loss: 1.428556328178734

Epoch: 389| Step: 0
Training loss: 0.24771694839000702
Validation loss: 1.404002622891498

Epoch: 6| Step: 1
Training loss: 0.15587851405143738
Validation loss: 1.423733349769346

Epoch: 6| Step: 2
Training loss: 0.2841050922870636
Validation loss: 1.4534827816870906

Epoch: 6| Step: 3
Training loss: 0.1663905382156372
Validation loss: 1.465115165197721

Epoch: 6| Step: 4
Training loss: 0.26162225008010864
Validation loss: 1.4686108404590237

Epoch: 6| Step: 5
Training loss: 0.16237106919288635
Validation loss: 1.4843309515266008

Epoch: 6| Step: 6
Training loss: 0.1187303364276886
Validation loss: 1.4684060658178022

Epoch: 6| Step: 7
Training loss: 0.20915251970291138
Validation loss: 1.4964839502047467

Epoch: 6| Step: 8
Training loss: 0.130636528134346
Validation loss: 1.4803618615673435

Epoch: 6| Step: 9
Training loss: 0.2064380794763565
Validation loss: 1.5499327516043058

Epoch: 6| Step: 10
Training loss: 0.1740925908088684
Validation loss: 1.5220075371444866

Epoch: 6| Step: 11
Training loss: 0.15102355182170868
Validation loss: 1.5132381403318016

Epoch: 6| Step: 12
Training loss: 0.2673441767692566
Validation loss: 1.521491095583926

Epoch: 6| Step: 13
Training loss: 0.10414502024650574
Validation loss: 1.52535032456921

Epoch: 390| Step: 0
Training loss: 0.1408260613679886
Validation loss: 1.4795794384453886

Epoch: 6| Step: 1
Training loss: 0.14784249663352966
Validation loss: 1.4534770340047858

Epoch: 6| Step: 2
Training loss: 0.15603221952915192
Validation loss: 1.4776522997886903

Epoch: 6| Step: 3
Training loss: 0.1793946921825409
Validation loss: 1.4613745251009542

Epoch: 6| Step: 4
Training loss: 0.1990155428647995
Validation loss: 1.483102225488232

Epoch: 6| Step: 5
Training loss: 0.09824781119823456
Validation loss: 1.4777545954591484

Epoch: 6| Step: 6
Training loss: 0.16134031116962433
Validation loss: 1.5089419593093216

Epoch: 6| Step: 7
Training loss: 0.25948768854141235
Validation loss: 1.5030287029922649

Epoch: 6| Step: 8
Training loss: 0.2654566764831543
Validation loss: 1.547065722045078

Epoch: 6| Step: 9
Training loss: 0.28028708696365356
Validation loss: 1.5570725728106756

Epoch: 6| Step: 10
Training loss: 0.2760809063911438
Validation loss: 1.5324336033995434

Epoch: 6| Step: 11
Training loss: 0.2658080458641052
Validation loss: 1.5130326504348426

Epoch: 6| Step: 12
Training loss: 0.2719235122203827
Validation loss: 1.5034638681719381

Epoch: 6| Step: 13
Training loss: 0.19846634566783905
Validation loss: 1.4760124503925283

Epoch: 391| Step: 0
Training loss: 0.15369842946529388
Validation loss: 1.4674764217868927

Epoch: 6| Step: 1
Training loss: 0.22336247563362122
Validation loss: 1.4503294421780495

Epoch: 6| Step: 2
Training loss: 0.21720625460147858
Validation loss: 1.481354723694504

Epoch: 6| Step: 3
Training loss: 0.31349751353263855
Validation loss: 1.4595220806778118

Epoch: 6| Step: 4
Training loss: 0.17991797626018524
Validation loss: 1.4346676693167737

Epoch: 6| Step: 5
Training loss: 0.20516687631607056
Validation loss: 1.462206817442371

Epoch: 6| Step: 6
Training loss: 0.21129730343818665
Validation loss: 1.4537809811612612

Epoch: 6| Step: 7
Training loss: 0.24688589572906494
Validation loss: 1.4600276101020075

Epoch: 6| Step: 8
Training loss: 0.16385282576084137
Validation loss: 1.5033342120467976

Epoch: 6| Step: 9
Training loss: 0.2460528016090393
Validation loss: 1.480451912008306

Epoch: 6| Step: 10
Training loss: 0.1730666160583496
Validation loss: 1.4852339990677372

Epoch: 6| Step: 11
Training loss: 0.23442019522190094
Validation loss: 1.4697401344135244

Epoch: 6| Step: 12
Training loss: 0.15552657842636108
Validation loss: 1.4941155634900576

Epoch: 6| Step: 13
Training loss: 0.11079706251621246
Validation loss: 1.4716941643786687

Epoch: 392| Step: 0
Training loss: 0.19866102933883667
Validation loss: 1.5000960878146592

Epoch: 6| Step: 1
Training loss: 0.2656604051589966
Validation loss: 1.49101923934875

Epoch: 6| Step: 2
Training loss: 0.2749654948711395
Validation loss: 1.5326616840977823

Epoch: 6| Step: 3
Training loss: 0.1887049376964569
Validation loss: 1.5348418425488215

Epoch: 6| Step: 4
Training loss: 0.14505863189697266
Validation loss: 1.475452620496032

Epoch: 6| Step: 5
Training loss: 0.24487078189849854
Validation loss: 1.5359710993305329

Epoch: 6| Step: 6
Training loss: 0.217201828956604
Validation loss: 1.5083186011160574

Epoch: 6| Step: 7
Training loss: 0.12153828144073486
Validation loss: 1.5308677291357389

Epoch: 6| Step: 8
Training loss: 0.15064626932144165
Validation loss: 1.5248282417174308

Epoch: 6| Step: 9
Training loss: 0.1635969579219818
Validation loss: 1.5236305895672049

Epoch: 6| Step: 10
Training loss: 0.17656761407852173
Validation loss: 1.4945290345017628

Epoch: 6| Step: 11
Training loss: 0.11934714764356613
Validation loss: 1.4829016782904183

Epoch: 6| Step: 12
Training loss: 0.2377009391784668
Validation loss: 1.5241573792631908

Epoch: 6| Step: 13
Training loss: 0.09513678401708603
Validation loss: 1.5524931620526057

Epoch: 393| Step: 0
Training loss: 0.1019316166639328
Validation loss: 1.5433694579268014

Epoch: 6| Step: 1
Training loss: 0.17568045854568481
Validation loss: 1.5076798815881052

Epoch: 6| Step: 2
Training loss: 0.16531752049922943
Validation loss: 1.495152601631739

Epoch: 6| Step: 3
Training loss: 0.224594384431839
Validation loss: 1.4930293918937765

Epoch: 6| Step: 4
Training loss: 0.20326480269432068
Validation loss: 1.4705572012932069

Epoch: 6| Step: 5
Training loss: 0.22198441624641418
Validation loss: 1.4707394549923558

Epoch: 6| Step: 6
Training loss: 0.18369904160499573
Validation loss: 1.5511896623078214

Epoch: 6| Step: 7
Training loss: 0.3291471302509308
Validation loss: 1.5208881170518938

Epoch: 6| Step: 8
Training loss: 0.16950948536396027
Validation loss: 1.5389278165755733

Epoch: 6| Step: 9
Training loss: 0.28172603249549866
Validation loss: 1.5549860372338244

Epoch: 6| Step: 10
Training loss: 0.20596268773078918
Validation loss: 1.545481062704517

Epoch: 6| Step: 11
Training loss: 0.35698240995407104
Validation loss: 1.558114254346458

Epoch: 6| Step: 12
Training loss: 0.23647844791412354
Validation loss: 1.5881909811368553

Epoch: 6| Step: 13
Training loss: 0.3170185685157776
Validation loss: 1.5249342700486541

Epoch: 394| Step: 0
Training loss: 0.25727230310440063
Validation loss: 1.5105069209170598

Epoch: 6| Step: 1
Training loss: 0.20659418404102325
Validation loss: 1.5111216486141246

Epoch: 6| Step: 2
Training loss: 0.20183596014976501
Validation loss: 1.5635210814014557

Epoch: 6| Step: 3
Training loss: 0.185038223862648
Validation loss: 1.5889496816101896

Epoch: 6| Step: 4
Training loss: 0.1509728729724884
Validation loss: 1.602542540078522

Epoch: 6| Step: 5
Training loss: 0.390707790851593
Validation loss: 1.5842919682943692

Epoch: 6| Step: 6
Training loss: 0.16550478339195251
Validation loss: 1.5634620253757765

Epoch: 6| Step: 7
Training loss: 0.22887182235717773
Validation loss: 1.5249894242132864

Epoch: 6| Step: 8
Training loss: 0.23063035309314728
Validation loss: 1.5194613215743855

Epoch: 6| Step: 9
Training loss: 0.25082817673683167
Validation loss: 1.466994608602216

Epoch: 6| Step: 10
Training loss: 0.2054005265235901
Validation loss: 1.4950482383851083

Epoch: 6| Step: 11
Training loss: 0.21792025864124298
Validation loss: 1.503923382810367

Epoch: 6| Step: 12
Training loss: 0.18969663977622986
Validation loss: 1.4802641150771931

Epoch: 6| Step: 13
Training loss: 0.13698898255825043
Validation loss: 1.4659548856878792

Epoch: 395| Step: 0
Training loss: 0.11452435702085495
Validation loss: 1.4924561644113192

Epoch: 6| Step: 1
Training loss: 0.1459665447473526
Validation loss: 1.5312033763495825

Epoch: 6| Step: 2
Training loss: 0.11401788145303726
Validation loss: 1.535873818141158

Epoch: 6| Step: 3
Training loss: 0.16876310110092163
Validation loss: 1.5880981978549753

Epoch: 6| Step: 4
Training loss: 0.1961054801940918
Validation loss: 1.6165348252942484

Epoch: 6| Step: 5
Training loss: 0.3381348252296448
Validation loss: 1.6041051431368756

Epoch: 6| Step: 6
Training loss: 0.1905839741230011
Validation loss: 1.5532303189718595

Epoch: 6| Step: 7
Training loss: 0.2208877056837082
Validation loss: 1.5525977714087373

Epoch: 6| Step: 8
Training loss: 0.14108580350875854
Validation loss: 1.511744401788199

Epoch: 6| Step: 9
Training loss: 0.18863293528556824
Validation loss: 1.5323438503408944

Epoch: 6| Step: 10
Training loss: 0.16689671576023102
Validation loss: 1.5014495375335857

Epoch: 6| Step: 11
Training loss: 0.30889105796813965
Validation loss: 1.4872694374412618

Epoch: 6| Step: 12
Training loss: 0.2035067081451416
Validation loss: 1.510628479783253

Epoch: 6| Step: 13
Training loss: 0.2003186047077179
Validation loss: 1.4881761881612963

Epoch: 396| Step: 0
Training loss: 0.17211656272411346
Validation loss: 1.5103084406545084

Epoch: 6| Step: 1
Training loss: 0.17109623551368713
Validation loss: 1.5322231400397517

Epoch: 6| Step: 2
Training loss: 0.1752188801765442
Validation loss: 1.5173509697760306

Epoch: 6| Step: 3
Training loss: 0.1737341284751892
Validation loss: 1.5389705832286547

Epoch: 6| Step: 4
Training loss: 0.3101809620857239
Validation loss: 1.5384958322330187

Epoch: 6| Step: 5
Training loss: 0.2941083312034607
Validation loss: 1.5819427492798015

Epoch: 6| Step: 6
Training loss: 0.12703219056129456
Validation loss: 1.5686457375044465

Epoch: 6| Step: 7
Training loss: 0.2400626242160797
Validation loss: 1.5739313171755882

Epoch: 6| Step: 8
Training loss: 0.12284979969263077
Validation loss: 1.5251106075061265

Epoch: 6| Step: 9
Training loss: 0.1603635549545288
Validation loss: 1.5392421125083842

Epoch: 6| Step: 10
Training loss: 0.14704230427742004
Validation loss: 1.5370611266423297

Epoch: 6| Step: 11
Training loss: 0.1780676692724228
Validation loss: 1.5408545155679025

Epoch: 6| Step: 12
Training loss: 0.1593828797340393
Validation loss: 1.5250927376490768

Epoch: 6| Step: 13
Training loss: 0.10121593624353409
Validation loss: 1.524671946802447

Epoch: 397| Step: 0
Training loss: 0.17842242121696472
Validation loss: 1.5252299385686074

Epoch: 6| Step: 1
Training loss: 0.1724725365638733
Validation loss: 1.5169996574360838

Epoch: 6| Step: 2
Training loss: 0.19599953293800354
Validation loss: 1.5028519399704472

Epoch: 6| Step: 3
Training loss: 0.15994912385940552
Validation loss: 1.5070106675547938

Epoch: 6| Step: 4
Training loss: 0.1327185183763504
Validation loss: 1.505278928305513

Epoch: 6| Step: 5
Training loss: 0.12424653768539429
Validation loss: 1.503053887556958

Epoch: 6| Step: 6
Training loss: 0.2435862123966217
Validation loss: 1.472897602665809

Epoch: 6| Step: 7
Training loss: 0.1315792351961136
Validation loss: 1.5173759973177345

Epoch: 6| Step: 8
Training loss: 0.12851649522781372
Validation loss: 1.4793966021589053

Epoch: 6| Step: 9
Training loss: 0.13634178042411804
Validation loss: 1.4894033465334164

Epoch: 6| Step: 10
Training loss: 0.15189379453659058
Validation loss: 1.4682453870773315

Epoch: 6| Step: 11
Training loss: 0.12430021911859512
Validation loss: 1.4844018515720163

Epoch: 6| Step: 12
Training loss: 0.2040954828262329
Validation loss: 1.4712735440141411

Epoch: 6| Step: 13
Training loss: 0.1361398696899414
Validation loss: 1.4690493922079764

Epoch: 398| Step: 0
Training loss: 0.17832911014556885
Validation loss: 1.4614859537411762

Epoch: 6| Step: 1
Training loss: 0.1501840054988861
Validation loss: 1.487763907319756

Epoch: 6| Step: 2
Training loss: 0.09920821338891983
Validation loss: 1.4748895347759288

Epoch: 6| Step: 3
Training loss: 0.11174391210079193
Validation loss: 1.4576008947946693

Epoch: 6| Step: 4
Training loss: 0.09301084280014038
Validation loss: 1.4512394628217142

Epoch: 6| Step: 5
Training loss: 0.24009643495082855
Validation loss: 1.4724883276929137

Epoch: 6| Step: 6
Training loss: 0.09488658607006073
Validation loss: 1.46767347410161

Epoch: 6| Step: 7
Training loss: 0.12556147575378418
Validation loss: 1.49187768531102

Epoch: 6| Step: 8
Training loss: 0.15736953914165497
Validation loss: 1.4637806043829968

Epoch: 6| Step: 9
Training loss: 0.2139129787683487
Validation loss: 1.4743886545140257

Epoch: 6| Step: 10
Training loss: 0.1282968968153
Validation loss: 1.5209074635659494

Epoch: 6| Step: 11
Training loss: 0.18743431568145752
Validation loss: 1.4651792972318587

Epoch: 6| Step: 12
Training loss: 0.1597643941640854
Validation loss: 1.4723564527368034

Epoch: 6| Step: 13
Training loss: 0.11197479814291
Validation loss: 1.456234819145613

Epoch: 399| Step: 0
Training loss: 0.1093674898147583
Validation loss: 1.5022203012179303

Epoch: 6| Step: 1
Training loss: 0.14590686559677124
Validation loss: 1.5050783881577112

Epoch: 6| Step: 2
Training loss: 0.18992941081523895
Validation loss: 1.5554687387199813

Epoch: 6| Step: 3
Training loss: 0.19728976488113403
Validation loss: 1.5626218395848428

Epoch: 6| Step: 4
Training loss: 0.10967620462179184
Validation loss: 1.5987392933137956

Epoch: 6| Step: 5
Training loss: 0.16009487211704254
Validation loss: 1.5456393034227434

Epoch: 6| Step: 6
Training loss: 0.26113834977149963
Validation loss: 1.51965868537144

Epoch: 6| Step: 7
Training loss: 0.148079514503479
Validation loss: 1.4693315529054212

Epoch: 6| Step: 8
Training loss: 0.15619295835494995
Validation loss: 1.470079005405467

Epoch: 6| Step: 9
Training loss: 0.16489937901496887
Validation loss: 1.4725886826874108

Epoch: 6| Step: 10
Training loss: 0.16151317954063416
Validation loss: 1.452055190199165

Epoch: 6| Step: 11
Training loss: 0.08657016605138779
Validation loss: 1.4712428841539609

Epoch: 6| Step: 12
Training loss: 0.2022937834262848
Validation loss: 1.4618713727561377

Epoch: 6| Step: 13
Training loss: 0.16929411888122559
Validation loss: 1.4614203488954933

Epoch: 400| Step: 0
Training loss: 0.12528309226036072
Validation loss: 1.463940958822927

Epoch: 6| Step: 1
Training loss: 0.10931165516376495
Validation loss: 1.4539785820950744

Epoch: 6| Step: 2
Training loss: 0.28375744819641113
Validation loss: 1.4517732743294007

Epoch: 6| Step: 3
Training loss: 0.10902295261621475
Validation loss: 1.4667154037824242

Epoch: 6| Step: 4
Training loss: 0.1726800799369812
Validation loss: 1.510723542141658

Epoch: 6| Step: 5
Training loss: 0.11459443718194962
Validation loss: 1.5461399542388095

Epoch: 6| Step: 6
Training loss: 0.2787948548793793
Validation loss: 1.5815713149245068

Epoch: 6| Step: 7
Training loss: 0.17428897321224213
Validation loss: 1.5815166311879312

Epoch: 6| Step: 8
Training loss: 0.20104604959487915
Validation loss: 1.5721953633011028

Epoch: 6| Step: 9
Training loss: 0.13113118708133698
Validation loss: 1.5144812727487216

Epoch: 6| Step: 10
Training loss: 0.19914919137954712
Validation loss: 1.4777035431195331

Epoch: 6| Step: 11
Training loss: 0.12521085143089294
Validation loss: 1.516547176145738

Epoch: 6| Step: 12
Training loss: 0.19830667972564697
Validation loss: 1.5188173222285446

Epoch: 6| Step: 13
Training loss: 0.360100120306015
Validation loss: 1.555063900768116

Testing loss: 2.059233474731445
