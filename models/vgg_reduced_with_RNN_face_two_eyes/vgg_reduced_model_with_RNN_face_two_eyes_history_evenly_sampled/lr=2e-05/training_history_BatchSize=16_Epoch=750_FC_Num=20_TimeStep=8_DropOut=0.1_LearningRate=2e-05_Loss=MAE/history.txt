Epoch: 1| Step: 0
Training loss: 5.067488193511963
Validation loss: 5.173287637772098

Epoch: 6| Step: 1
Training loss: 5.252742290496826
Validation loss: 5.159703182917769

Epoch: 6| Step: 2
Training loss: 4.976569175720215
Validation loss: 5.150568721114948

Epoch: 6| Step: 3
Training loss: 3.8232500553131104
Validation loss: 5.142109727346769

Epoch: 6| Step: 4
Training loss: 4.81827974319458
Validation loss: 5.132430620090936

Epoch: 6| Step: 5
Training loss: 5.405755996704102
Validation loss: 5.121101164048718

Epoch: 6| Step: 6
Training loss: 4.5738067626953125
Validation loss: 5.108360223872687

Epoch: 6| Step: 7
Training loss: 4.719354629516602
Validation loss: 5.093805841220322

Epoch: 6| Step: 8
Training loss: 5.218116760253906
Validation loss: 5.077272010105912

Epoch: 6| Step: 9
Training loss: 4.634491920471191
Validation loss: 5.0598677973593436

Epoch: 6| Step: 10
Training loss: 3.744243860244751
Validation loss: 5.039320981630715

Epoch: 6| Step: 11
Training loss: 5.0891523361206055
Validation loss: 5.017313721359417

Epoch: 6| Step: 12
Training loss: 5.636430740356445
Validation loss: 4.992873371288341

Epoch: 6| Step: 13
Training loss: 5.927953720092773
Validation loss: 4.966133209966844

Epoch: 2| Step: 0
Training loss: 4.079984188079834
Validation loss: 4.937711602898054

Epoch: 6| Step: 1
Training loss: 5.492480278015137
Validation loss: 4.906872667292113

Epoch: 6| Step: 2
Training loss: 4.5641303062438965
Validation loss: 4.873930587563463

Epoch: 6| Step: 3
Training loss: 4.111025333404541
Validation loss: 4.837889896926059

Epoch: 6| Step: 4
Training loss: 4.779367446899414
Validation loss: 4.799963756274152

Epoch: 6| Step: 5
Training loss: 4.392897605895996
Validation loss: 4.760574930457659

Epoch: 6| Step: 6
Training loss: 4.62584114074707
Validation loss: 4.72009301441972

Epoch: 6| Step: 7
Training loss: 4.8119072914123535
Validation loss: 4.680818598757508

Epoch: 6| Step: 8
Training loss: 4.26042366027832
Validation loss: 4.639176222585863

Epoch: 6| Step: 9
Training loss: 5.607817649841309
Validation loss: 4.59703391598117

Epoch: 6| Step: 10
Training loss: 3.814505100250244
Validation loss: 4.554287587442706

Epoch: 6| Step: 11
Training loss: 4.875270843505859
Validation loss: 4.512627386277722

Epoch: 6| Step: 12
Training loss: 3.2496862411499023
Validation loss: 4.4761487181468675

Epoch: 6| Step: 13
Training loss: 4.069151878356934
Validation loss: 4.441478575429609

Epoch: 3| Step: 0
Training loss: 3.4916086196899414
Validation loss: 4.4041092113782

Epoch: 6| Step: 1
Training loss: 3.976562976837158
Validation loss: 4.372453520374913

Epoch: 6| Step: 2
Training loss: 3.8470981121063232
Validation loss: 4.3462573738508326

Epoch: 6| Step: 3
Training loss: 3.9358766078948975
Validation loss: 4.321230016728883

Epoch: 6| Step: 4
Training loss: 4.814678192138672
Validation loss: 4.300677343081403

Epoch: 6| Step: 5
Training loss: 4.2253217697143555
Validation loss: 4.283431235180106

Epoch: 6| Step: 6
Training loss: 6.169287204742432
Validation loss: 4.269669363575597

Epoch: 6| Step: 7
Training loss: 4.395306587219238
Validation loss: 4.260006796929144

Epoch: 6| Step: 8
Training loss: 3.6401336193084717
Validation loss: 4.2514819175966325

Epoch: 6| Step: 9
Training loss: 2.9029245376586914
Validation loss: 4.239928112235121

Epoch: 6| Step: 10
Training loss: 4.172687530517578
Validation loss: 4.227337339872955

Epoch: 6| Step: 11
Training loss: 3.1428098678588867
Validation loss: 4.212863419645576

Epoch: 6| Step: 12
Training loss: 5.027158737182617
Validation loss: 4.196678382094189

Epoch: 6| Step: 13
Training loss: 3.362199068069458
Validation loss: 4.179745689515145

Epoch: 4| Step: 0
Training loss: 4.73698616027832
Validation loss: 4.163689177523377

Epoch: 6| Step: 1
Training loss: 4.119901180267334
Validation loss: 4.1473891068530335

Epoch: 6| Step: 2
Training loss: 4.485389232635498
Validation loss: 4.129472809453165

Epoch: 6| Step: 3
Training loss: 3.3986635208129883
Validation loss: 4.113886305080947

Epoch: 6| Step: 4
Training loss: 3.1552419662475586
Validation loss: 4.100040392209125

Epoch: 6| Step: 5
Training loss: 3.8030786514282227
Validation loss: 4.089704872459493

Epoch: 6| Step: 6
Training loss: 3.2393085956573486
Validation loss: 4.078455889096824

Epoch: 6| Step: 7
Training loss: 3.8020172119140625
Validation loss: 4.07065991432436

Epoch: 6| Step: 8
Training loss: 3.654050350189209
Validation loss: 4.063324636028659

Epoch: 6| Step: 9
Training loss: 4.299933433532715
Validation loss: 4.0525386564193235

Epoch: 6| Step: 10
Training loss: 3.833305835723877
Validation loss: 4.042355206704909

Epoch: 6| Step: 11
Training loss: 4.14836311340332
Validation loss: 4.0318484408881075

Epoch: 6| Step: 12
Training loss: 4.470751762390137
Validation loss: 4.0212747871234855

Epoch: 6| Step: 13
Training loss: 3.5509650707244873
Validation loss: 4.014309829281222

Epoch: 5| Step: 0
Training loss: 4.179726600646973
Validation loss: 4.004465415913572

Epoch: 6| Step: 1
Training loss: 3.3019638061523438
Validation loss: 3.995769070040795

Epoch: 6| Step: 2
Training loss: 4.075073719024658
Validation loss: 3.9843894717513875

Epoch: 6| Step: 3
Training loss: 3.998286247253418
Validation loss: 3.976272434316656

Epoch: 6| Step: 4
Training loss: 3.5956594944000244
Validation loss: 3.9671836206989903

Epoch: 6| Step: 5
Training loss: 4.0835442543029785
Validation loss: 3.956519485801779

Epoch: 6| Step: 6
Training loss: 4.387829303741455
Validation loss: 3.9456791006108767

Epoch: 6| Step: 7
Training loss: 3.5488715171813965
Validation loss: 3.9339271053191154

Epoch: 6| Step: 8
Training loss: 3.929826498031616
Validation loss: 3.9248996344945764

Epoch: 6| Step: 9
Training loss: 3.097659111022949
Validation loss: 3.9106283008411364

Epoch: 6| Step: 10
Training loss: 3.9932563304901123
Validation loss: 3.8997956168267036

Epoch: 6| Step: 11
Training loss: 4.049093246459961
Validation loss: 3.887695179190687

Epoch: 6| Step: 12
Training loss: 3.071835994720459
Validation loss: 3.876218239466349

Epoch: 6| Step: 13
Training loss: 3.9385719299316406
Validation loss: 3.865563428530129

Epoch: 6| Step: 0
Training loss: 2.724059820175171
Validation loss: 3.8550833425214215

Epoch: 6| Step: 1
Training loss: 4.131007194519043
Validation loss: 3.8444081583330707

Epoch: 6| Step: 2
Training loss: 5.365567207336426
Validation loss: 3.8355250050944667

Epoch: 6| Step: 3
Training loss: 3.2613251209259033
Validation loss: 3.8261818526893534

Epoch: 6| Step: 4
Training loss: 4.134971618652344
Validation loss: 3.8154475663297918

Epoch: 6| Step: 5
Training loss: 3.3373186588287354
Validation loss: 3.8062265432009132

Epoch: 6| Step: 6
Training loss: 3.765065908432007
Validation loss: 3.79870940280217

Epoch: 6| Step: 7
Training loss: 4.1970720291137695
Validation loss: 3.791519877731159

Epoch: 6| Step: 8
Training loss: 2.235792398452759
Validation loss: 3.7846663690382436

Epoch: 6| Step: 9
Training loss: 2.9723644256591797
Validation loss: 3.7753920298750683

Epoch: 6| Step: 10
Training loss: 4.059109687805176
Validation loss: 3.7681548262155182

Epoch: 6| Step: 11
Training loss: 4.406164169311523
Validation loss: 3.759923627299647

Epoch: 6| Step: 12
Training loss: 2.5319652557373047
Validation loss: 3.7509371311433855

Epoch: 6| Step: 13
Training loss: 5.128885269165039
Validation loss: 3.7460356784123245

Epoch: 7| Step: 0
Training loss: 3.107515335083008
Validation loss: 3.740058575907061

Epoch: 6| Step: 1
Training loss: 3.731078624725342
Validation loss: 3.7319756784746723

Epoch: 6| Step: 2
Training loss: 3.885518789291382
Validation loss: 3.7232832754811933

Epoch: 6| Step: 3
Training loss: 5.295337677001953
Validation loss: 3.7139227159561647

Epoch: 6| Step: 4
Training loss: 3.511549949645996
Validation loss: 3.7045835807759273

Epoch: 6| Step: 5
Training loss: 2.8117549419403076
Validation loss: 3.6988012201042584

Epoch: 6| Step: 6
Training loss: 3.6774606704711914
Validation loss: 3.6946757480662358

Epoch: 6| Step: 7
Training loss: 2.5425667762756348
Validation loss: 3.6863079327408985

Epoch: 6| Step: 8
Training loss: 4.110513687133789
Validation loss: 3.677612458505938

Epoch: 6| Step: 9
Training loss: 3.408479928970337
Validation loss: 3.669640715404223

Epoch: 6| Step: 10
Training loss: 4.051681995391846
Validation loss: 3.66343290575089

Epoch: 6| Step: 11
Training loss: 3.6457462310791016
Validation loss: 3.658376593743601

Epoch: 6| Step: 12
Training loss: 3.542501449584961
Validation loss: 3.6488952585445937

Epoch: 6| Step: 13
Training loss: 2.55423641204834
Validation loss: 3.6413926001518004

Epoch: 8| Step: 0
Training loss: 3.6031382083892822
Validation loss: 3.636499809962447

Epoch: 6| Step: 1
Training loss: 4.540909767150879
Validation loss: 3.630965822486467

Epoch: 6| Step: 2
Training loss: 3.862887382507324
Validation loss: 3.6227982941494195

Epoch: 6| Step: 3
Training loss: 3.9530391693115234
Validation loss: 3.6147402307038665

Epoch: 6| Step: 4
Training loss: 3.0544350147247314
Validation loss: 3.607138692691762

Epoch: 6| Step: 5
Training loss: 2.7848739624023438
Validation loss: 3.601834948344897

Epoch: 6| Step: 6
Training loss: 3.2819504737854004
Validation loss: 3.6011815635106896

Epoch: 6| Step: 7
Training loss: 4.391141891479492
Validation loss: 3.586922832714614

Epoch: 6| Step: 8
Training loss: 2.1428709030151367
Validation loss: 3.5833430162040134

Epoch: 6| Step: 9
Training loss: 3.4759469032287598
Validation loss: 3.5828397350926555

Epoch: 6| Step: 10
Training loss: 4.182694911956787
Validation loss: 3.5742845355823474

Epoch: 6| Step: 11
Training loss: 3.64911150932312
Validation loss: 3.5626694617732877

Epoch: 6| Step: 12
Training loss: 2.6565232276916504
Validation loss: 3.5675785182624735

Epoch: 6| Step: 13
Training loss: 3.844027280807495
Validation loss: 3.5515925525337138

Epoch: 9| Step: 0
Training loss: 4.189081192016602
Validation loss: 3.544146135289182

Epoch: 6| Step: 1
Training loss: 3.5488977432250977
Validation loss: 3.5437712618099746

Epoch: 6| Step: 2
Training loss: 2.719080924987793
Validation loss: 3.5376997916929183

Epoch: 6| Step: 3
Training loss: 3.527446985244751
Validation loss: 3.5321983906530563

Epoch: 6| Step: 4
Training loss: 4.250585556030273
Validation loss: 3.52938510012883

Epoch: 6| Step: 5
Training loss: 4.208865165710449
Validation loss: 3.5155067392574844

Epoch: 6| Step: 6
Training loss: 3.4163851737976074
Validation loss: 3.510178096832768

Epoch: 6| Step: 7
Training loss: 2.678795576095581
Validation loss: 3.506665519488755

Epoch: 6| Step: 8
Training loss: 2.9926464557647705
Validation loss: 3.5037755940550115

Epoch: 6| Step: 9
Training loss: 2.7545762062072754
Validation loss: 3.5048393793003534

Epoch: 6| Step: 10
Training loss: 3.582432746887207
Validation loss: 3.4979281246021228

Epoch: 6| Step: 11
Training loss: 3.632869243621826
Validation loss: 3.4876225891933648

Epoch: 6| Step: 12
Training loss: 3.5131640434265137
Validation loss: 3.4859545461593138

Epoch: 6| Step: 13
Training loss: 3.130323886871338
Validation loss: 3.4783671132979856

Epoch: 10| Step: 0
Training loss: 3.438957691192627
Validation loss: 3.4713403947891726

Epoch: 6| Step: 1
Training loss: 3.3915534019470215
Validation loss: 3.4627862002259944

Epoch: 6| Step: 2
Training loss: 3.754819393157959
Validation loss: 3.4556148052215576

Epoch: 6| Step: 3
Training loss: 3.1365838050842285
Validation loss: 3.4499938975098314

Epoch: 6| Step: 4
Training loss: 4.263978004455566
Validation loss: 3.444557143795875

Epoch: 6| Step: 5
Training loss: 2.974249839782715
Validation loss: 3.4362729236643803

Epoch: 6| Step: 6
Training loss: 3.8209333419799805
Validation loss: 3.4295911891486055

Epoch: 6| Step: 7
Training loss: 2.246591806411743
Validation loss: 3.4262525420035086

Epoch: 6| Step: 8
Training loss: 3.269202470779419
Validation loss: 3.432221802332068

Epoch: 6| Step: 9
Training loss: 3.320448160171509
Validation loss: 3.414751652748354

Epoch: 6| Step: 10
Training loss: 4.061129570007324
Validation loss: 3.4202013272111134

Epoch: 6| Step: 11
Training loss: 2.976447582244873
Validation loss: 3.4139715907394246

Epoch: 6| Step: 12
Training loss: 3.443737030029297
Validation loss: 3.4050598964896253

Epoch: 6| Step: 13
Training loss: 3.095381498336792
Validation loss: 3.3913610571174213

Epoch: 11| Step: 0
Training loss: 4.155529975891113
Validation loss: 3.388254224613149

Epoch: 6| Step: 1
Training loss: 3.7877516746520996
Validation loss: 3.3877371511151715

Epoch: 6| Step: 2
Training loss: 3.198657512664795
Validation loss: 3.3764574886650167

Epoch: 6| Step: 3
Training loss: 3.6136369705200195
Validation loss: 3.371154413428358

Epoch: 6| Step: 4
Training loss: 4.1171875
Validation loss: 3.369422392178607

Epoch: 6| Step: 5
Training loss: 3.1049721240997314
Validation loss: 3.361000660927065

Epoch: 6| Step: 6
Training loss: 3.815342426300049
Validation loss: 3.3588891772813696

Epoch: 6| Step: 7
Training loss: 2.7735071182250977
Validation loss: 3.3466722990876887

Epoch: 6| Step: 8
Training loss: 2.746466636657715
Validation loss: 3.340756718830396

Epoch: 6| Step: 9
Training loss: 3.925450563430786
Validation loss: 3.348091302379485

Epoch: 6| Step: 10
Training loss: 3.0631203651428223
Validation loss: 3.3343431539432977

Epoch: 6| Step: 11
Training loss: 2.9233384132385254
Validation loss: 3.335745693534933

Epoch: 6| Step: 12
Training loss: 2.8144173622131348
Validation loss: 3.340584098651845

Epoch: 6| Step: 13
Training loss: 1.7571626901626587
Validation loss: 3.335281579725204

Epoch: 12| Step: 0
Training loss: 3.5239858627319336
Validation loss: 3.3302487634843394

Epoch: 6| Step: 1
Training loss: 3.096386432647705
Validation loss: 3.321200309261199

Epoch: 6| Step: 2
Training loss: 3.804737091064453
Validation loss: 3.3111925740395822

Epoch: 6| Step: 3
Training loss: 2.4710800647735596
Validation loss: 3.3049587844520487

Epoch: 6| Step: 4
Training loss: 2.9687538146972656
Validation loss: 3.3007748665348178

Epoch: 6| Step: 5
Training loss: 3.9506478309631348
Validation loss: 3.29910724137419

Epoch: 6| Step: 6
Training loss: 2.8250222206115723
Validation loss: 3.292026094211045

Epoch: 6| Step: 7
Training loss: 3.751007556915283
Validation loss: 3.2854478487404446

Epoch: 6| Step: 8
Training loss: 2.3935718536376953
Validation loss: 3.2791611430465535

Epoch: 6| Step: 9
Training loss: 3.1103110313415527
Validation loss: 3.2781235838449128

Epoch: 6| Step: 10
Training loss: 3.0548646450042725
Validation loss: 3.272436454731931

Epoch: 6| Step: 11
Training loss: 3.515688896179199
Validation loss: 3.263879301727459

Epoch: 6| Step: 12
Training loss: 3.073430299758911
Validation loss: 3.260986589616345

Epoch: 6| Step: 13
Training loss: 4.880670070648193
Validation loss: 3.2660874243705504

Epoch: 13| Step: 0
Training loss: 3.564696788787842
Validation loss: 3.2583348674158894

Epoch: 6| Step: 1
Training loss: 2.8157949447631836
Validation loss: 3.2837318810083533

Epoch: 6| Step: 2
Training loss: 4.047006607055664
Validation loss: 3.3036634640027116

Epoch: 6| Step: 3
Training loss: 3.852613925933838
Validation loss: 3.2864310433787685

Epoch: 6| Step: 4
Training loss: 3.014948844909668
Validation loss: 3.2643588871084233

Epoch: 6| Step: 5
Training loss: 3.2874464988708496
Validation loss: 3.247378813323154

Epoch: 6| Step: 6
Training loss: 2.9642281532287598
Validation loss: 3.2410591674107376

Epoch: 6| Step: 7
Training loss: 3.4346752166748047
Validation loss: 3.2462483042029926

Epoch: 6| Step: 8
Training loss: 2.7210264205932617
Validation loss: 3.2476147451708393

Epoch: 6| Step: 9
Training loss: 2.353081703186035
Validation loss: 3.242560653276341

Epoch: 6| Step: 10
Training loss: 2.6622154712677
Validation loss: 3.2363690483954644

Epoch: 6| Step: 11
Training loss: 3.7152533531188965
Validation loss: 3.231759814805882

Epoch: 6| Step: 12
Training loss: 3.620138168334961
Validation loss: 3.2188354025604906

Epoch: 6| Step: 13
Training loss: 3.2381651401519775
Validation loss: 3.2109080053144887

Epoch: 14| Step: 0
Training loss: 3.0390913486480713
Validation loss: 3.2030602347466255

Epoch: 6| Step: 1
Training loss: 3.0279805660247803
Validation loss: 3.1963618724576888

Epoch: 6| Step: 2
Training loss: 3.1969990730285645
Validation loss: 3.1880938750441357

Epoch: 6| Step: 3
Training loss: 2.636483669281006
Validation loss: 3.184921444103282

Epoch: 6| Step: 4
Training loss: 3.2134406566619873
Validation loss: 3.183066819303779

Epoch: 6| Step: 5
Training loss: 2.2810451984405518
Validation loss: 3.1783725343724734

Epoch: 6| Step: 6
Training loss: 4.443057537078857
Validation loss: 3.1727064322399836

Epoch: 6| Step: 7
Training loss: 3.435380458831787
Validation loss: 3.171007825482276

Epoch: 6| Step: 8
Training loss: 3.371169090270996
Validation loss: 3.1706130658426592

Epoch: 6| Step: 9
Training loss: 3.205829620361328
Validation loss: 3.1605054691273677

Epoch: 6| Step: 10
Training loss: 2.6379711627960205
Validation loss: 3.1615750635823896

Epoch: 6| Step: 11
Training loss: 3.7748680114746094
Validation loss: 3.155836013055617

Epoch: 6| Step: 12
Training loss: 2.6108622550964355
Validation loss: 3.145275072384906

Epoch: 6| Step: 13
Training loss: 4.052169322967529
Validation loss: 3.1388095707021733

Epoch: 15| Step: 0
Training loss: 2.8187685012817383
Validation loss: 3.1392739075486378

Epoch: 6| Step: 1
Training loss: 3.5797882080078125
Validation loss: 3.1348276369033323

Epoch: 6| Step: 2
Training loss: 3.5599184036254883
Validation loss: 3.1363225624125493

Epoch: 6| Step: 3
Training loss: 3.124083995819092
Validation loss: 3.1254504726779078

Epoch: 6| Step: 4
Training loss: 2.2647976875305176
Validation loss: 3.1201941915737685

Epoch: 6| Step: 5
Training loss: 2.962646007537842
Validation loss: 3.110046922519643

Epoch: 6| Step: 6
Training loss: 3.109990119934082
Validation loss: 3.105736065936345

Epoch: 6| Step: 7
Training loss: 2.6653506755828857
Validation loss: 3.1059311871887534

Epoch: 6| Step: 8
Training loss: 3.051968812942505
Validation loss: 3.097195384322956

Epoch: 6| Step: 9
Training loss: 4.058107376098633
Validation loss: 3.0890317142650647

Epoch: 6| Step: 10
Training loss: 3.890717029571533
Validation loss: 3.086653332556448

Epoch: 6| Step: 11
Training loss: 2.6930623054504395
Validation loss: 3.0765196200340026

Epoch: 6| Step: 12
Training loss: 3.092733383178711
Validation loss: 3.0723754385466218

Epoch: 6| Step: 13
Training loss: 2.8686273097991943
Validation loss: 3.06936574751331

Epoch: 16| Step: 0
Training loss: 3.0116117000579834
Validation loss: 3.067306587772985

Epoch: 6| Step: 1
Training loss: 2.7655739784240723
Validation loss: 3.0625143999694497

Epoch: 6| Step: 2
Training loss: 2.627413034439087
Validation loss: 3.0575192051549114

Epoch: 6| Step: 3
Training loss: 2.7106642723083496
Validation loss: 3.047304637970463

Epoch: 6| Step: 4
Training loss: 3.5846292972564697
Validation loss: 3.045542158106322

Epoch: 6| Step: 5
Training loss: 3.1142220497131348
Validation loss: 3.0366449612443165

Epoch: 6| Step: 6
Training loss: 2.7386093139648438
Validation loss: 3.0313610261486423

Epoch: 6| Step: 7
Training loss: 3.6287295818328857
Validation loss: 3.0247142853275424

Epoch: 6| Step: 8
Training loss: 4.2617597579956055
Validation loss: 3.018603019816901

Epoch: 6| Step: 9
Training loss: 2.8413801193237305
Validation loss: 3.0191455887209986

Epoch: 6| Step: 10
Training loss: 2.6090283393859863
Validation loss: 3.0120612959707938

Epoch: 6| Step: 11
Training loss: 3.1514272689819336
Validation loss: 3.009328862672211

Epoch: 6| Step: 12
Training loss: 3.073298931121826
Validation loss: 3.0018679044579946

Epoch: 6| Step: 13
Training loss: 3.14174747467041
Validation loss: 2.997718454689108

Epoch: 17| Step: 0
Training loss: 3.3641533851623535
Validation loss: 2.9990067507631037

Epoch: 6| Step: 1
Training loss: 3.9667513370513916
Validation loss: 3.0120483649674283

Epoch: 6| Step: 2
Training loss: 3.6740007400512695
Validation loss: 2.989848482993341

Epoch: 6| Step: 3
Training loss: 1.9597129821777344
Validation loss: 2.993248519077096

Epoch: 6| Step: 4
Training loss: 3.0830025672912598
Validation loss: 3.0096488973145843

Epoch: 6| Step: 5
Training loss: 2.9388937950134277
Validation loss: 3.021057367324829

Epoch: 6| Step: 6
Training loss: 3.307889461517334
Validation loss: 3.010837931786814

Epoch: 6| Step: 7
Training loss: 3.899993658065796
Validation loss: 2.9961749610080513

Epoch: 6| Step: 8
Training loss: 2.6810462474823
Validation loss: 2.9778691312318206

Epoch: 6| Step: 9
Training loss: 2.4584860801696777
Validation loss: 2.9793596882973947

Epoch: 6| Step: 10
Training loss: 2.201826572418213
Validation loss: 2.976282209478399

Epoch: 6| Step: 11
Training loss: 3.110808849334717
Validation loss: 2.9657753257341284

Epoch: 6| Step: 12
Training loss: 3.0272560119628906
Validation loss: 2.9521133181869343

Epoch: 6| Step: 13
Training loss: 3.256162405014038
Validation loss: 2.947000308703351

Epoch: 18| Step: 0
Training loss: 2.760554790496826
Validation loss: 2.944836588316066

Epoch: 6| Step: 1
Training loss: 2.2270407676696777
Validation loss: 2.9458434069028465

Epoch: 6| Step: 2
Training loss: 2.955040454864502
Validation loss: 2.9463185828219176

Epoch: 6| Step: 3
Training loss: 3.2270588874816895
Validation loss: 2.9383580402661393

Epoch: 6| Step: 4
Training loss: 3.617126703262329
Validation loss: 2.929792450320336

Epoch: 6| Step: 5
Training loss: 2.2325997352600098
Validation loss: 2.934985996574484

Epoch: 6| Step: 6
Training loss: 3.5150341987609863
Validation loss: 2.915179452588481

Epoch: 6| Step: 7
Training loss: 2.9805212020874023
Validation loss: 2.91267793409286

Epoch: 6| Step: 8
Training loss: 2.418765068054199
Validation loss: 2.902096507369831

Epoch: 6| Step: 9
Training loss: 3.4993693828582764
Validation loss: 2.902655481010355

Epoch: 6| Step: 10
Training loss: 2.767083168029785
Validation loss: 2.897106550073111

Epoch: 6| Step: 11
Training loss: 3.223261594772339
Validation loss: 2.89118803188365

Epoch: 6| Step: 12
Training loss: 3.4900074005126953
Validation loss: 2.888033131117462

Epoch: 6| Step: 13
Training loss: 3.399831533432007
Validation loss: 2.8873648258947555

Epoch: 19| Step: 0
Training loss: 3.5101265907287598
Validation loss: 2.885717345822242

Epoch: 6| Step: 1
Training loss: 3.3009886741638184
Validation loss: 2.8818067863423336

Epoch: 6| Step: 2
Training loss: 2.7828078269958496
Validation loss: 2.8771438931906097

Epoch: 6| Step: 3
Training loss: 2.283860445022583
Validation loss: 2.8834454756911083

Epoch: 6| Step: 4
Training loss: 2.8415322303771973
Validation loss: 2.882285717994936

Epoch: 6| Step: 5
Training loss: 3.261448621749878
Validation loss: 2.8743288491361882

Epoch: 6| Step: 6
Training loss: 2.670753002166748
Validation loss: 2.8714039223168486

Epoch: 6| Step: 7
Training loss: 3.2222886085510254
Validation loss: 2.864246993936518

Epoch: 6| Step: 8
Training loss: 3.7298312187194824
Validation loss: 2.859965178274339

Epoch: 6| Step: 9
Training loss: 2.4248273372650146
Validation loss: 2.8583043365068335

Epoch: 6| Step: 10
Training loss: 2.8665223121643066
Validation loss: 2.8564603379977647

Epoch: 6| Step: 11
Training loss: 3.0281848907470703
Validation loss: 2.8537547280711513

Epoch: 6| Step: 12
Training loss: 2.929279088973999
Validation loss: 2.85082717352016

Epoch: 6| Step: 13
Training loss: 2.6482436656951904
Validation loss: 2.8780233193469305

Epoch: 20| Step: 0
Training loss: 2.1433544158935547
Validation loss: 2.88243225056638

Epoch: 6| Step: 1
Training loss: 3.618350028991699
Validation loss: 2.8407461873946653

Epoch: 6| Step: 2
Training loss: 2.7414190769195557
Validation loss: 2.841766985513831

Epoch: 6| Step: 3
Training loss: 3.430511951446533
Validation loss: 2.8559115163741575

Epoch: 6| Step: 4
Training loss: 2.759687900543213
Validation loss: 2.8640476272952173

Epoch: 6| Step: 5
Training loss: 3.584568977355957
Validation loss: 2.8692359924316406

Epoch: 6| Step: 6
Training loss: 1.6967511177062988
Validation loss: 2.8678420153997277

Epoch: 6| Step: 7
Training loss: 4.239285469055176
Validation loss: 2.8587691963359876

Epoch: 6| Step: 8
Training loss: 2.880774974822998
Validation loss: 2.839910707166118

Epoch: 6| Step: 9
Training loss: 2.935817003250122
Validation loss: 2.8246695277511433

Epoch: 6| Step: 10
Training loss: 3.4145755767822266
Validation loss: 2.8307142719145744

Epoch: 6| Step: 11
Training loss: 2.756416082382202
Validation loss: 2.8336949553540958

Epoch: 6| Step: 12
Training loss: 2.455728530883789
Validation loss: 2.8305140182536137

Epoch: 6| Step: 13
Training loss: 2.5694947242736816
Validation loss: 2.8186959861427225

Epoch: 21| Step: 0
Training loss: 2.790764570236206
Validation loss: 2.811464194328554

Epoch: 6| Step: 1
Training loss: 2.169487714767456
Validation loss: 2.8057990433067403

Epoch: 6| Step: 2
Training loss: 3.154188871383667
Validation loss: 2.80163541916878

Epoch: 6| Step: 3
Training loss: 4.021602630615234
Validation loss: 2.80771436614375

Epoch: 6| Step: 4
Training loss: 3.865724802017212
Validation loss: 2.8070710269353722

Epoch: 6| Step: 5
Training loss: 2.186922073364258
Validation loss: 2.80232407200721

Epoch: 6| Step: 6
Training loss: 2.8928818702697754
Validation loss: 2.8135937003679174

Epoch: 6| Step: 7
Training loss: 3.2298924922943115
Validation loss: 2.800737368163242

Epoch: 6| Step: 8
Training loss: 2.488837242126465
Validation loss: 2.7907016738768546

Epoch: 6| Step: 9
Training loss: 3.902535915374756
Validation loss: 2.7889160545923377

Epoch: 6| Step: 10
Training loss: 1.8288382291793823
Validation loss: 2.7832321274665093

Epoch: 6| Step: 11
Training loss: 3.315609931945801
Validation loss: 2.7841517591989167

Epoch: 6| Step: 12
Training loss: 2.342705726623535
Validation loss: 2.7829396109427176

Epoch: 6| Step: 13
Training loss: 2.6639528274536133
Validation loss: 2.7814486872765327

Epoch: 22| Step: 0
Training loss: 2.8486995697021484
Validation loss: 2.786637629232099

Epoch: 6| Step: 1
Training loss: 3.0602774620056152
Validation loss: 2.7850560295966362

Epoch: 6| Step: 2
Training loss: 3.8200554847717285
Validation loss: 2.7734342672491588

Epoch: 6| Step: 3
Training loss: 2.451748847961426
Validation loss: 2.7735835736797703

Epoch: 6| Step: 4
Training loss: 3.242560863494873
Validation loss: 2.7776828427468576

Epoch: 6| Step: 5
Training loss: 2.165987968444824
Validation loss: 2.7716797833801596

Epoch: 6| Step: 6
Training loss: 2.9943201541900635
Validation loss: 2.779158274332682

Epoch: 6| Step: 7
Training loss: 2.3378677368164062
Validation loss: 2.7716069862406743

Epoch: 6| Step: 8
Training loss: 3.113114356994629
Validation loss: 2.7628077999238045

Epoch: 6| Step: 9
Training loss: 2.9526822566986084
Validation loss: 2.7641746844014814

Epoch: 6| Step: 10
Training loss: 2.7561631202697754
Validation loss: 2.7631929100200696

Epoch: 6| Step: 11
Training loss: 2.2709686756134033
Validation loss: 2.7668358869450067

Epoch: 6| Step: 12
Training loss: 3.804708957672119
Validation loss: 2.776342039467186

Epoch: 6| Step: 13
Training loss: 2.8670499324798584
Validation loss: 2.7632462927090224

Epoch: 23| Step: 0
Training loss: 2.1632513999938965
Validation loss: 2.754212805019912

Epoch: 6| Step: 1
Training loss: 3.4772226810455322
Validation loss: 2.748829323758361

Epoch: 6| Step: 2
Training loss: 2.726571798324585
Validation loss: 2.757520503895257

Epoch: 6| Step: 3
Training loss: 2.9836184978485107
Validation loss: 2.7512609561284385

Epoch: 6| Step: 4
Training loss: 3.153567314147949
Validation loss: 2.7546431761915966

Epoch: 6| Step: 5
Training loss: 2.6840908527374268
Validation loss: 2.8191081247022076

Epoch: 6| Step: 6
Training loss: 2.95513916015625
Validation loss: 2.963307862640709

Epoch: 6| Step: 7
Training loss: 2.8327136039733887
Validation loss: 2.9533056751374276

Epoch: 6| Step: 8
Training loss: 2.6394214630126953
Validation loss: 2.834977662691506

Epoch: 6| Step: 9
Training loss: 4.210382461547852
Validation loss: 2.7600918687799925

Epoch: 6| Step: 10
Training loss: 2.604166030883789
Validation loss: 2.8143937818465696

Epoch: 6| Step: 11
Training loss: 2.780367136001587
Validation loss: 2.9568141865473923

Epoch: 6| Step: 12
Training loss: 3.2872743606567383
Validation loss: 3.0796445672230055

Epoch: 6| Step: 13
Training loss: 2.9038522243499756
Validation loss: 3.130050725834344

Epoch: 24| Step: 0
Training loss: 2.8670654296875
Validation loss: 3.1765081190293833

Epoch: 6| Step: 1
Training loss: 3.922257423400879
Validation loss: 3.0649615897927234

Epoch: 6| Step: 2
Training loss: 3.4908833503723145
Validation loss: 2.942850958916449

Epoch: 6| Step: 3
Training loss: 2.7984023094177246
Validation loss: 2.8983789387569634

Epoch: 6| Step: 4
Training loss: 3.0440354347229004
Validation loss: 2.933835264175169

Epoch: 6| Step: 5
Training loss: 3.3761653900146484
Validation loss: 3.0964645211414625

Epoch: 6| Step: 6
Training loss: 2.9824471473693848
Validation loss: 3.1170651399961082

Epoch: 6| Step: 7
Training loss: 2.5956175327301025
Validation loss: 3.0888801620852564

Epoch: 6| Step: 8
Training loss: 3.4392809867858887
Validation loss: 3.0624302330837456

Epoch: 6| Step: 9
Training loss: 3.058168888092041
Validation loss: 3.030019073076146

Epoch: 6| Step: 10
Training loss: 3.199601650238037
Validation loss: 3.0059509661889847

Epoch: 6| Step: 11
Training loss: 2.9547319412231445
Validation loss: 2.9510950324355916

Epoch: 6| Step: 12
Training loss: 2.1920437812805176
Validation loss: 2.8795871632073515

Epoch: 6| Step: 13
Training loss: 3.2944014072418213
Validation loss: 2.8367383736436085

Epoch: 25| Step: 0
Training loss: 2.8106467723846436
Validation loss: 2.8073952608211066

Epoch: 6| Step: 1
Training loss: 3.0878043174743652
Validation loss: 2.7986024579694195

Epoch: 6| Step: 2
Training loss: 3.06819486618042
Validation loss: 2.7844362258911133

Epoch: 6| Step: 3
Training loss: 2.3099331855773926
Validation loss: 2.7653885246605

Epoch: 6| Step: 4
Training loss: 2.634349822998047
Validation loss: 2.774436076482137

Epoch: 6| Step: 5
Training loss: 2.5453872680664062
Validation loss: 2.768602091778991

Epoch: 6| Step: 6
Training loss: 2.7970504760742188
Validation loss: 2.751900008929673

Epoch: 6| Step: 7
Training loss: 2.642913579940796
Validation loss: 2.73624724213795

Epoch: 6| Step: 8
Training loss: 3.317263126373291
Validation loss: 2.727541841486449

Epoch: 6| Step: 9
Training loss: 2.9650096893310547
Validation loss: 2.729647264685682

Epoch: 6| Step: 10
Training loss: 3.064239978790283
Validation loss: 2.7338992395708637

Epoch: 6| Step: 11
Training loss: 3.015282154083252
Validation loss: 2.736925632722916

Epoch: 6| Step: 12
Training loss: 3.601851463317871
Validation loss: 2.7419653374661683

Epoch: 6| Step: 13
Training loss: 2.6035056114196777
Validation loss: 2.7427358601682927

Epoch: 26| Step: 0
Training loss: 3.0747551918029785
Validation loss: 2.7487380760972218

Epoch: 6| Step: 1
Training loss: 3.781905174255371
Validation loss: 2.745160689917944

Epoch: 6| Step: 2
Training loss: 2.6939382553100586
Validation loss: 2.737322789366527

Epoch: 6| Step: 3
Training loss: 2.4578843116760254
Validation loss: 2.7253998889718005

Epoch: 6| Step: 4
Training loss: 3.0988550186157227
Validation loss: 2.713460235185521

Epoch: 6| Step: 5
Training loss: 2.556608200073242
Validation loss: 2.707760569869831

Epoch: 6| Step: 6
Training loss: 3.647688388824463
Validation loss: 2.7078986321726153

Epoch: 6| Step: 7
Training loss: 2.9338817596435547
Validation loss: 2.707969750127485

Epoch: 6| Step: 8
Training loss: 3.056682825088501
Validation loss: 2.7046215457300984

Epoch: 6| Step: 9
Training loss: 1.9928120374679565
Validation loss: 2.7015757048001854

Epoch: 6| Step: 10
Training loss: 3.0169734954833984
Validation loss: 2.700069519781297

Epoch: 6| Step: 11
Training loss: 2.6745762825012207
Validation loss: 2.698681564741237

Epoch: 6| Step: 12
Training loss: 2.608738899230957
Validation loss: 2.693895004128897

Epoch: 6| Step: 13
Training loss: 2.3831286430358887
Validation loss: 2.688579805435673

Epoch: 27| Step: 0
Training loss: 3.5098252296447754
Validation loss: 2.6912388109391734

Epoch: 6| Step: 1
Training loss: 2.75762939453125
Validation loss: 2.688006806117232

Epoch: 6| Step: 2
Training loss: 2.418482780456543
Validation loss: 2.689226729895479

Epoch: 6| Step: 3
Training loss: 2.4249634742736816
Validation loss: 2.6809828076311337

Epoch: 6| Step: 4
Training loss: 2.381711959838867
Validation loss: 2.6809345881144204

Epoch: 6| Step: 5
Training loss: 2.5421550273895264
Validation loss: 2.679798403093892

Epoch: 6| Step: 6
Training loss: 2.180133581161499
Validation loss: 2.678993219970375

Epoch: 6| Step: 7
Training loss: 2.8830604553222656
Validation loss: 2.6814251971501175

Epoch: 6| Step: 8
Training loss: 2.6707582473754883
Validation loss: 2.6828246988276

Epoch: 6| Step: 9
Training loss: 3.261929988861084
Validation loss: 2.6819838400809997

Epoch: 6| Step: 10
Training loss: 2.893942356109619
Validation loss: 2.6834065401425926

Epoch: 6| Step: 11
Training loss: 3.757856845855713
Validation loss: 2.683012198376399

Epoch: 6| Step: 12
Training loss: 2.936718463897705
Validation loss: 2.685848653957408

Epoch: 6| Step: 13
Training loss: 3.6179869174957275
Validation loss: 2.687552505923856

Epoch: 28| Step: 0
Training loss: 2.591693878173828
Validation loss: 2.6860182849309777

Epoch: 6| Step: 1
Training loss: 2.9649314880371094
Validation loss: 2.6812224131758495

Epoch: 6| Step: 2
Training loss: 2.150045394897461
Validation loss: 2.6783534506315827

Epoch: 6| Step: 3
Training loss: 2.864724636077881
Validation loss: 2.6790418163422616

Epoch: 6| Step: 4
Training loss: 3.4650933742523193
Validation loss: 2.6785657175125612

Epoch: 6| Step: 5
Training loss: 3.656282424926758
Validation loss: 2.682813221408475

Epoch: 6| Step: 6
Training loss: 3.1019351482391357
Validation loss: 2.6783213461599042

Epoch: 6| Step: 7
Training loss: 2.031196355819702
Validation loss: 2.6787110118455786

Epoch: 6| Step: 8
Training loss: 3.7307004928588867
Validation loss: 2.674091262202109

Epoch: 6| Step: 9
Training loss: 2.503753185272217
Validation loss: 2.673145099352765

Epoch: 6| Step: 10
Training loss: 2.9017691612243652
Validation loss: 2.6711031236956195

Epoch: 6| Step: 11
Training loss: 2.4051923751831055
Validation loss: 2.668310437151181

Epoch: 6| Step: 12
Training loss: 2.5975680351257324
Validation loss: 2.6714759052440686

Epoch: 6| Step: 13
Training loss: 2.6238183975219727
Validation loss: 2.678298783558671

Epoch: 29| Step: 0
Training loss: 3.625861644744873
Validation loss: 2.674920159001504

Epoch: 6| Step: 1
Training loss: 2.664280652999878
Validation loss: 2.6766682594053206

Epoch: 6| Step: 2
Training loss: 2.8376238346099854
Validation loss: 2.6865759511147775

Epoch: 6| Step: 3
Training loss: 3.5279483795166016
Validation loss: 2.6911981541623353

Epoch: 6| Step: 4
Training loss: 3.0607638359069824
Validation loss: 2.681844521594304

Epoch: 6| Step: 5
Training loss: 2.719390392303467
Validation loss: 2.6737661797513246

Epoch: 6| Step: 6
Training loss: 2.1237244606018066
Validation loss: 2.6610368759401384

Epoch: 6| Step: 7
Training loss: 3.2164669036865234
Validation loss: 2.6591110178219375

Epoch: 6| Step: 8
Training loss: 2.592134475708008
Validation loss: 2.660689687216154

Epoch: 6| Step: 9
Training loss: 2.8352320194244385
Validation loss: 2.6595413377208095

Epoch: 6| Step: 10
Training loss: 2.626622200012207
Validation loss: 2.656521225488314

Epoch: 6| Step: 11
Training loss: 2.562692165374756
Validation loss: 2.6559708220984346

Epoch: 6| Step: 12
Training loss: 2.708012104034424
Validation loss: 2.655500024877569

Epoch: 6| Step: 13
Training loss: 2.188610792160034
Validation loss: 2.6531158647229596

Epoch: 30| Step: 0
Training loss: 2.6726508140563965
Validation loss: 2.652221912978798

Epoch: 6| Step: 1
Training loss: 2.1619930267333984
Validation loss: 2.6579288692884546

Epoch: 6| Step: 2
Training loss: 2.24169659614563
Validation loss: 2.6596393815932737

Epoch: 6| Step: 3
Training loss: 2.7328438758850098
Validation loss: 2.666863933686287

Epoch: 6| Step: 4
Training loss: 3.160033941268921
Validation loss: 2.6512933187587286

Epoch: 6| Step: 5
Training loss: 2.60749888420105
Validation loss: 2.6548155020642024

Epoch: 6| Step: 6
Training loss: 2.3743677139282227
Validation loss: 2.6521487979478735

Epoch: 6| Step: 7
Training loss: 3.4682233333587646
Validation loss: 2.6524033905357443

Epoch: 6| Step: 8
Training loss: 3.043100357055664
Validation loss: 2.6519025192465833

Epoch: 6| Step: 9
Training loss: 2.713124990463257
Validation loss: 2.6496153877627466

Epoch: 6| Step: 10
Training loss: 2.9869415760040283
Validation loss: 2.6477378773432907

Epoch: 6| Step: 11
Training loss: 3.3080148696899414
Validation loss: 2.6455044105488765

Epoch: 6| Step: 12
Training loss: 3.402956962585449
Validation loss: 2.651972891182028

Epoch: 6| Step: 13
Training loss: 2.2226946353912354
Validation loss: 2.6532749283698296

Epoch: 31| Step: 0
Training loss: 3.5983612537384033
Validation loss: 2.6516804541310957

Epoch: 6| Step: 1
Training loss: 2.232250928878784
Validation loss: 2.6512906961543585

Epoch: 6| Step: 2
Training loss: 2.8434884548187256
Validation loss: 2.651818847143522

Epoch: 6| Step: 3
Training loss: 3.5821051597595215
Validation loss: 2.652911647673576

Epoch: 6| Step: 4
Training loss: 2.505854845046997
Validation loss: 2.646012129322175

Epoch: 6| Step: 5
Training loss: 2.765768527984619
Validation loss: 2.6479527950286865

Epoch: 6| Step: 6
Training loss: 1.9591562747955322
Validation loss: 2.642076956328525

Epoch: 6| Step: 7
Training loss: 3.441282272338867
Validation loss: 2.6382555141243884

Epoch: 6| Step: 8
Training loss: 2.6835036277770996
Validation loss: 2.6445775032043457

Epoch: 6| Step: 9
Training loss: 2.629490375518799
Validation loss: 2.6664937696149273

Epoch: 6| Step: 10
Training loss: 2.384018898010254
Validation loss: 2.6698902242927143

Epoch: 6| Step: 11
Training loss: 3.7452735900878906
Validation loss: 2.6753869569429787

Epoch: 6| Step: 12
Training loss: 1.8036823272705078
Validation loss: 2.6478326602648665

Epoch: 6| Step: 13
Training loss: 3.4620232582092285
Validation loss: 2.6417532146617932

Epoch: 32| Step: 0
Training loss: 2.3259401321411133
Validation loss: 2.6355479019944386

Epoch: 6| Step: 1
Training loss: 3.1258792877197266
Validation loss: 2.6342312494913735

Epoch: 6| Step: 2
Training loss: 2.4838857650756836
Validation loss: 2.6335945385758595

Epoch: 6| Step: 3
Training loss: 2.7241902351379395
Validation loss: 2.631776617419335

Epoch: 6| Step: 4
Training loss: 3.104365348815918
Validation loss: 2.630208264115036

Epoch: 6| Step: 5
Training loss: 2.689457654953003
Validation loss: 2.6280724502378896

Epoch: 6| Step: 6
Training loss: 2.569790840148926
Validation loss: 2.630380456165601

Epoch: 6| Step: 7
Training loss: 2.7913641929626465
Validation loss: 2.6304091458679526

Epoch: 6| Step: 8
Training loss: 2.639116048812866
Validation loss: 2.629052495443693

Epoch: 6| Step: 9
Training loss: 2.444460391998291
Validation loss: 2.629085774062782

Epoch: 6| Step: 10
Training loss: 2.9308533668518066
Validation loss: 2.6305277373201106

Epoch: 6| Step: 11
Training loss: 3.171621084213257
Validation loss: 2.630819305296867

Epoch: 6| Step: 12
Training loss: 3.199810028076172
Validation loss: 2.632194842061689

Epoch: 6| Step: 13
Training loss: 3.0944204330444336
Validation loss: 2.625621716181437

Epoch: 33| Step: 0
Training loss: 2.28507661819458
Validation loss: 2.625972053056122

Epoch: 6| Step: 1
Training loss: 2.4896578788757324
Validation loss: 2.624696885385821

Epoch: 6| Step: 2
Training loss: 2.8018906116485596
Validation loss: 2.6228280939081663

Epoch: 6| Step: 3
Training loss: 2.2016091346740723
Validation loss: 2.6224465447087444

Epoch: 6| Step: 4
Training loss: 2.171910524368286
Validation loss: 2.6228998925096247

Epoch: 6| Step: 5
Training loss: 3.1735870838165283
Validation loss: 2.6183650519258235

Epoch: 6| Step: 6
Training loss: 3.326467990875244
Validation loss: 2.621368761985533

Epoch: 6| Step: 7
Training loss: 3.3829033374786377
Validation loss: 2.6220245207509687

Epoch: 6| Step: 8
Training loss: 2.849539041519165
Validation loss: 2.624051158146192

Epoch: 6| Step: 9
Training loss: 3.0373287200927734
Validation loss: 2.618909256432646

Epoch: 6| Step: 10
Training loss: 2.5299439430236816
Validation loss: 2.6146209111777683

Epoch: 6| Step: 11
Training loss: 2.9613680839538574
Validation loss: 2.613023199060912

Epoch: 6| Step: 12
Training loss: 2.8480420112609863
Validation loss: 2.612760523314117

Epoch: 6| Step: 13
Training loss: 3.054607629776001
Validation loss: 2.6140686414575063

Epoch: 34| Step: 0
Training loss: 2.5365023612976074
Validation loss: 2.6111327858381372

Epoch: 6| Step: 1
Training loss: 3.316433906555176
Validation loss: 2.613489181764664

Epoch: 6| Step: 2
Training loss: 3.1022486686706543
Validation loss: 2.6134748945954027

Epoch: 6| Step: 3
Training loss: 3.5104246139526367
Validation loss: 2.611251797727359

Epoch: 6| Step: 4
Training loss: 1.6314539909362793
Validation loss: 2.611923271609891

Epoch: 6| Step: 5
Training loss: 2.5876126289367676
Validation loss: 2.6090564804692424

Epoch: 6| Step: 6
Training loss: 3.133904457092285
Validation loss: 2.608895327455254

Epoch: 6| Step: 7
Training loss: 3.0362370014190674
Validation loss: 2.6045987657321397

Epoch: 6| Step: 8
Training loss: 3.196791172027588
Validation loss: 2.6089842909125873

Epoch: 6| Step: 9
Training loss: 2.3510022163391113
Validation loss: 2.6079991812347085

Epoch: 6| Step: 10
Training loss: 2.901132583618164
Validation loss: 2.6125813632883053

Epoch: 6| Step: 11
Training loss: 2.4219112396240234
Validation loss: 2.6218419715922368

Epoch: 6| Step: 12
Training loss: 2.183353900909424
Validation loss: 2.6181722507681897

Epoch: 6| Step: 13
Training loss: 3.094357490539551
Validation loss: 2.628759027809225

Epoch: 35| Step: 0
Training loss: 2.791692018508911
Validation loss: 2.6591438426766345

Epoch: 6| Step: 1
Training loss: 3.2852067947387695
Validation loss: 2.67593046926683

Epoch: 6| Step: 2
Training loss: 2.891066312789917
Validation loss: 2.668037296623312

Epoch: 6| Step: 3
Training loss: 3.508179187774658
Validation loss: 2.6289541336797897

Epoch: 6| Step: 4
Training loss: 3.147585391998291
Validation loss: 2.620045156889064

Epoch: 6| Step: 5
Training loss: 1.9055651426315308
Validation loss: 2.600957288536974

Epoch: 6| Step: 6
Training loss: 2.8745923042297363
Validation loss: 2.5953585383712605

Epoch: 6| Step: 7
Training loss: 3.198091506958008
Validation loss: 2.603029743317635

Epoch: 6| Step: 8
Training loss: 2.966026782989502
Validation loss: 2.60003928215273

Epoch: 6| Step: 9
Training loss: 1.7307157516479492
Validation loss: 2.5988282567711285

Epoch: 6| Step: 10
Training loss: 2.18601131439209
Validation loss: 2.6005629134434525

Epoch: 6| Step: 11
Training loss: 2.5021774768829346
Validation loss: 2.6063801729550926

Epoch: 6| Step: 12
Training loss: 3.554401397705078
Validation loss: 2.6202720237034622

Epoch: 6| Step: 13
Training loss: 2.120750904083252
Validation loss: 2.63852757792319

Epoch: 36| Step: 0
Training loss: 2.779686450958252
Validation loss: 2.639790350391019

Epoch: 6| Step: 1
Training loss: 2.9399778842926025
Validation loss: 2.6279759509589082

Epoch: 6| Step: 2
Training loss: 2.6333584785461426
Validation loss: 2.613088346296741

Epoch: 6| Step: 3
Training loss: 2.554420232772827
Validation loss: 2.6012304059920774

Epoch: 6| Step: 4
Training loss: 2.6004722118377686
Validation loss: 2.595352301033594

Epoch: 6| Step: 5
Training loss: 3.1552929878234863
Validation loss: 2.596580918117236

Epoch: 6| Step: 6
Training loss: 3.005850315093994
Validation loss: 2.5935316598543556

Epoch: 6| Step: 7
Training loss: 3.1089165210723877
Validation loss: 2.599986184027887

Epoch: 6| Step: 8
Training loss: 2.4335083961486816
Validation loss: 2.5946067405003372

Epoch: 6| Step: 9
Training loss: 2.083585500717163
Validation loss: 2.5918554541885213

Epoch: 6| Step: 10
Training loss: 3.2839438915252686
Validation loss: 2.5923772755489556

Epoch: 6| Step: 11
Training loss: 2.7897510528564453
Validation loss: 2.589568640596123

Epoch: 6| Step: 12
Training loss: 2.5546786785125732
Validation loss: 2.5894853761119228

Epoch: 6| Step: 13
Training loss: 2.908404588699341
Validation loss: 2.6043156193148707

Epoch: 37| Step: 0
Training loss: 2.6175296306610107
Validation loss: 2.6120235484133483

Epoch: 6| Step: 1
Training loss: 2.1527132987976074
Validation loss: 2.6228316881323375

Epoch: 6| Step: 2
Training loss: 3.3040480613708496
Validation loss: 2.611664390051237

Epoch: 6| Step: 3
Training loss: 2.1102819442749023
Validation loss: 2.596485840376987

Epoch: 6| Step: 4
Training loss: 2.4890923500061035
Validation loss: 2.598965967855146

Epoch: 6| Step: 5
Training loss: 2.683051586151123
Validation loss: 2.601648489634196

Epoch: 6| Step: 6
Training loss: 2.9997177124023438
Validation loss: 2.5919204142785843

Epoch: 6| Step: 7
Training loss: 3.1398205757141113
Validation loss: 2.5940265758063203

Epoch: 6| Step: 8
Training loss: 3.028489112854004
Validation loss: 2.5942724750887964

Epoch: 6| Step: 9
Training loss: 2.471446990966797
Validation loss: 2.6144849433693835

Epoch: 6| Step: 10
Training loss: 3.04713773727417
Validation loss: 2.608572575353807

Epoch: 6| Step: 11
Training loss: 2.9440417289733887
Validation loss: 2.586050095096711

Epoch: 6| Step: 12
Training loss: 2.458488941192627
Validation loss: 2.5763473818379063

Epoch: 6| Step: 13
Training loss: 3.6730902194976807
Validation loss: 2.577608936576433

Epoch: 38| Step: 0
Training loss: 2.883780002593994
Validation loss: 2.576229559477939

Epoch: 6| Step: 1
Training loss: 2.8463029861450195
Validation loss: 2.5795026902229554

Epoch: 6| Step: 2
Training loss: 3.015718698501587
Validation loss: 2.5765488327190442

Epoch: 6| Step: 3
Training loss: 2.612494945526123
Validation loss: 2.5766142619553434

Epoch: 6| Step: 4
Training loss: 2.569207191467285
Validation loss: 2.577678544546968

Epoch: 6| Step: 5
Training loss: 2.6472532749176025
Validation loss: 2.5773071037825717

Epoch: 6| Step: 6
Training loss: 3.3754305839538574
Validation loss: 2.5737037684327815

Epoch: 6| Step: 7
Training loss: 3.134995698928833
Validation loss: 2.573529322942098

Epoch: 6| Step: 8
Training loss: 2.584108829498291
Validation loss: 2.5702615245696037

Epoch: 6| Step: 9
Training loss: 2.9538636207580566
Validation loss: 2.5695301076417327

Epoch: 6| Step: 10
Training loss: 1.650367021560669
Validation loss: 2.5712975199504564

Epoch: 6| Step: 11
Training loss: 3.016711473464966
Validation loss: 2.5678511870804654

Epoch: 6| Step: 12
Training loss: 2.915287494659424
Validation loss: 2.57273962420802

Epoch: 6| Step: 13
Training loss: 1.876729965209961
Validation loss: 2.5835094810813986

Epoch: 39| Step: 0
Training loss: 3.5434443950653076
Validation loss: 2.610537144445604

Epoch: 6| Step: 1
Training loss: 2.3062570095062256
Validation loss: 2.6153218156547955

Epoch: 6| Step: 2
Training loss: 2.55546498298645
Validation loss: 2.581396415669431

Epoch: 6| Step: 3
Training loss: 3.6871438026428223
Validation loss: 2.5651334049881145

Epoch: 6| Step: 4
Training loss: 3.127046585083008
Validation loss: 2.5778740195817846

Epoch: 6| Step: 5
Training loss: 2.5396058559417725
Validation loss: 2.612425027355071

Epoch: 6| Step: 6
Training loss: 1.9293537139892578
Validation loss: 2.7039999295306463

Epoch: 6| Step: 7
Training loss: 3.0754306316375732
Validation loss: 2.8079418546410015

Epoch: 6| Step: 8
Training loss: 2.435051441192627
Validation loss: 2.880769460431991

Epoch: 6| Step: 9
Training loss: 2.387744903564453
Validation loss: 2.7786678473154702

Epoch: 6| Step: 10
Training loss: 3.0438616275787354
Validation loss: 2.676603494151946

Epoch: 6| Step: 11
Training loss: 3.0605034828186035
Validation loss: 2.5880323071633615

Epoch: 6| Step: 12
Training loss: 3.0840871334075928
Validation loss: 2.5586263877089306

Epoch: 6| Step: 13
Training loss: 2.309340476989746
Validation loss: 2.57102793775579

Epoch: 40| Step: 0
Training loss: 3.0342562198638916
Validation loss: 2.6208540162732525

Epoch: 6| Step: 1
Training loss: 3.1380276679992676
Validation loss: 2.6583406630382744

Epoch: 6| Step: 2
Training loss: 2.853646755218506
Validation loss: 2.6244176741569274

Epoch: 6| Step: 3
Training loss: 2.4165432453155518
Validation loss: 2.5958846563934

Epoch: 6| Step: 4
Training loss: 3.037837028503418
Validation loss: 2.606176230215257

Epoch: 6| Step: 5
Training loss: 3.3259942531585693
Validation loss: 2.620218712796447

Epoch: 6| Step: 6
Training loss: 2.7933390140533447
Validation loss: 2.5872182153886363

Epoch: 6| Step: 7
Training loss: 3.5806527137756348
Validation loss: 2.564213022109001

Epoch: 6| Step: 8
Training loss: 2.2866578102111816
Validation loss: 2.554649750391642

Epoch: 6| Step: 9
Training loss: 2.355433464050293
Validation loss: 2.5510478814442954

Epoch: 6| Step: 10
Training loss: 1.8122601509094238
Validation loss: 2.5494670688465075

Epoch: 6| Step: 11
Training loss: 2.411921977996826
Validation loss: 2.551986899427188

Epoch: 6| Step: 12
Training loss: 2.5777387619018555
Validation loss: 2.5561354391036497

Epoch: 6| Step: 13
Training loss: 2.9969491958618164
Validation loss: 2.562294790821691

Epoch: 41| Step: 0
Training loss: 3.001683235168457
Validation loss: 2.555074791754446

Epoch: 6| Step: 1
Training loss: 1.8055009841918945
Validation loss: 2.5529934001225296

Epoch: 6| Step: 2
Training loss: 2.770658254623413
Validation loss: 2.553473795613935

Epoch: 6| Step: 3
Training loss: 2.728468179702759
Validation loss: 2.5776030120029243

Epoch: 6| Step: 4
Training loss: 2.842768430709839
Validation loss: 2.608629975267636

Epoch: 6| Step: 5
Training loss: 3.0398964881896973
Validation loss: 2.6358266389498146

Epoch: 6| Step: 6
Training loss: 3.0585954189300537
Validation loss: 2.63693178853681

Epoch: 6| Step: 7
Training loss: 2.555124521255493
Validation loss: 2.6321068707332818

Epoch: 6| Step: 8
Training loss: 2.974639654159546
Validation loss: 2.608421843539002

Epoch: 6| Step: 9
Training loss: 1.633980631828308
Validation loss: 2.590762628022061

Epoch: 6| Step: 10
Training loss: 2.967632293701172
Validation loss: 2.565804625070223

Epoch: 6| Step: 11
Training loss: 3.3986895084381104
Validation loss: 2.546974315438219

Epoch: 6| Step: 12
Training loss: 3.3869564533233643
Validation loss: 2.539189361756848

Epoch: 6| Step: 13
Training loss: 1.8813843727111816
Validation loss: 2.5373426714251117

Epoch: 42| Step: 0
Training loss: 2.2200095653533936
Validation loss: 2.5447242798343783

Epoch: 6| Step: 1
Training loss: 2.4768147468566895
Validation loss: 2.5569144551472

Epoch: 6| Step: 2
Training loss: 2.178164482116699
Validation loss: 2.5620052455573954

Epoch: 6| Step: 3
Training loss: 3.504178285598755
Validation loss: 2.5661153049879175

Epoch: 6| Step: 4
Training loss: 2.9082589149475098
Validation loss: 2.5472968662938764

Epoch: 6| Step: 5
Training loss: 2.494600296020508
Validation loss: 2.5412168041352303

Epoch: 6| Step: 6
Training loss: 2.739704132080078
Validation loss: 2.5324489378160044

Epoch: 6| Step: 7
Training loss: 2.312715768814087
Validation loss: 2.527617548101692

Epoch: 6| Step: 8
Training loss: 2.5064632892608643
Validation loss: 2.5256014203512542

Epoch: 6| Step: 9
Training loss: 3.060783863067627
Validation loss: 2.5244662018232447

Epoch: 6| Step: 10
Training loss: 3.3126461505889893
Validation loss: 2.5299528644930933

Epoch: 6| Step: 11
Training loss: 3.1249637603759766
Validation loss: 2.5340812872814875

Epoch: 6| Step: 12
Training loss: 2.529439926147461
Validation loss: 2.537130114852741

Epoch: 6| Step: 13
Training loss: 2.852670192718506
Validation loss: 2.5452322652263026

Epoch: 43| Step: 0
Training loss: 2.3435564041137695
Validation loss: 2.540877519115325

Epoch: 6| Step: 1
Training loss: 2.681438446044922
Validation loss: 2.581907464611915

Epoch: 6| Step: 2
Training loss: 2.802964210510254
Validation loss: 2.6059368477072766

Epoch: 6| Step: 3
Training loss: 2.7707748413085938
Validation loss: 2.6011445471035537

Epoch: 6| Step: 4
Training loss: 2.9422266483306885
Validation loss: 2.5775410000995924

Epoch: 6| Step: 5
Training loss: 2.823639392852783
Validation loss: 2.545171360815725

Epoch: 6| Step: 6
Training loss: 2.4427266120910645
Validation loss: 2.528382029584659

Epoch: 6| Step: 7
Training loss: 2.774172782897949
Validation loss: 2.5248110550706104

Epoch: 6| Step: 8
Training loss: 2.8990583419799805
Validation loss: 2.518879013676797

Epoch: 6| Step: 9
Training loss: 2.945404052734375
Validation loss: 2.5188764038906304

Epoch: 6| Step: 10
Training loss: 2.0510478019714355
Validation loss: 2.527860718388711

Epoch: 6| Step: 11
Training loss: 2.6747899055480957
Validation loss: 2.545370835129933

Epoch: 6| Step: 12
Training loss: 2.8411941528320312
Validation loss: 2.5488748370960193

Epoch: 6| Step: 13
Training loss: 3.3654990196228027
Validation loss: 2.558502451066048

Epoch: 44| Step: 0
Training loss: 2.2222237586975098
Validation loss: 2.555573755694974

Epoch: 6| Step: 1
Training loss: 2.1873717308044434
Validation loss: 2.5441084728446057

Epoch: 6| Step: 2
Training loss: 3.835557460784912
Validation loss: 2.5363888561084704

Epoch: 6| Step: 3
Training loss: 2.808459997177124
Validation loss: 2.5298951389969035

Epoch: 6| Step: 4
Training loss: 2.5820884704589844
Validation loss: 2.5261278895921606

Epoch: 6| Step: 5
Training loss: 2.926687240600586
Validation loss: 2.522233501557381

Epoch: 6| Step: 6
Training loss: 2.821038246154785
Validation loss: 2.523081712825324

Epoch: 6| Step: 7
Training loss: 2.193542003631592
Validation loss: 2.522078211589526

Epoch: 6| Step: 8
Training loss: 2.7722394466400146
Validation loss: 2.5282406537763533

Epoch: 6| Step: 9
Training loss: 2.3605878353118896
Validation loss: 2.550090592394593

Epoch: 6| Step: 10
Training loss: 2.354503631591797
Validation loss: 2.536934421908471

Epoch: 6| Step: 11
Training loss: 3.396038055419922
Validation loss: 2.522596861726494

Epoch: 6| Step: 12
Training loss: 2.6474106311798096
Validation loss: 2.517759184683523

Epoch: 6| Step: 13
Training loss: 3.141633987426758
Validation loss: 2.5074864805385633

Epoch: 45| Step: 0
Training loss: 3.775319814682007
Validation loss: 2.5065291748251965

Epoch: 6| Step: 1
Training loss: 2.769735813140869
Validation loss: 2.5104008695130706

Epoch: 6| Step: 2
Training loss: 2.3013553619384766
Validation loss: 2.5092158984112483

Epoch: 6| Step: 3
Training loss: 2.796753406524658
Validation loss: 2.5116871941474175

Epoch: 6| Step: 4
Training loss: 2.717104911804199
Validation loss: 2.5119051497469664

Epoch: 6| Step: 5
Training loss: 1.5147992372512817
Validation loss: 2.5098577032807055

Epoch: 6| Step: 6
Training loss: 3.0705342292785645
Validation loss: 2.505901067487655

Epoch: 6| Step: 7
Training loss: 2.6016645431518555
Validation loss: 2.5037388340119393

Epoch: 6| Step: 8
Training loss: 2.3112406730651855
Validation loss: 2.5004062870497346

Epoch: 6| Step: 9
Training loss: 2.4516654014587402
Validation loss: 2.4986060768045406

Epoch: 6| Step: 10
Training loss: 2.7942652702331543
Validation loss: 2.500024249476771

Epoch: 6| Step: 11
Training loss: 3.1065633296966553
Validation loss: 2.512298587829836

Epoch: 6| Step: 12
Training loss: 2.8846421241760254
Validation loss: 2.5127687659314883

Epoch: 6| Step: 13
Training loss: 2.693429946899414
Validation loss: 2.516620502677015

Epoch: 46| Step: 0
Training loss: 3.224889039993286
Validation loss: 2.531195689273137

Epoch: 6| Step: 1
Training loss: 2.941315174102783
Validation loss: 2.5275479311584146

Epoch: 6| Step: 2
Training loss: 3.0093460083007812
Validation loss: 2.53742826625865

Epoch: 6| Step: 3
Training loss: 2.8642234802246094
Validation loss: 2.535393273958596

Epoch: 6| Step: 4
Training loss: 2.5208210945129395
Validation loss: 2.536202533270723

Epoch: 6| Step: 5
Training loss: 2.571554183959961
Validation loss: 2.51193481363276

Epoch: 6| Step: 6
Training loss: 1.9474343061447144
Validation loss: 2.5091559169112996

Epoch: 6| Step: 7
Training loss: 2.9772467613220215
Validation loss: 2.4986192436628443

Epoch: 6| Step: 8
Training loss: 2.8638153076171875
Validation loss: 2.4958120469124085

Epoch: 6| Step: 9
Training loss: 2.9538135528564453
Validation loss: 2.4938571940186205

Epoch: 6| Step: 10
Training loss: 1.9648637771606445
Validation loss: 2.4938319575402046

Epoch: 6| Step: 11
Training loss: 3.0598931312561035
Validation loss: 2.4904770005133843

Epoch: 6| Step: 12
Training loss: 2.4539079666137695
Validation loss: 2.4929852075474237

Epoch: 6| Step: 13
Training loss: 2.377469539642334
Validation loss: 2.4927656547997588

Epoch: 47| Step: 0
Training loss: 2.9026455879211426
Validation loss: 2.489547288545998

Epoch: 6| Step: 1
Training loss: 2.954619884490967
Validation loss: 2.4878138752393824

Epoch: 6| Step: 2
Training loss: 2.158095598220825
Validation loss: 2.487847863986928

Epoch: 6| Step: 3
Training loss: 2.2249512672424316
Validation loss: 2.488995223916987

Epoch: 6| Step: 4
Training loss: 2.7113611698150635
Validation loss: 2.4929385492878575

Epoch: 6| Step: 5
Training loss: 2.7185869216918945
Validation loss: 2.4914316618314354

Epoch: 6| Step: 6
Training loss: 2.914928913116455
Validation loss: 2.489579976245921

Epoch: 6| Step: 7
Training loss: 2.842437744140625
Validation loss: 2.4898997199150825

Epoch: 6| Step: 8
Training loss: 3.1887717247009277
Validation loss: 2.491676825349049

Epoch: 6| Step: 9
Training loss: 2.2873547077178955
Validation loss: 2.4899635904578754

Epoch: 6| Step: 10
Training loss: 2.0454936027526855
Validation loss: 2.4953279520875666

Epoch: 6| Step: 11
Training loss: 3.200974941253662
Validation loss: 2.4874590955754763

Epoch: 6| Step: 12
Training loss: 2.436572313308716
Validation loss: 2.490287426979311

Epoch: 6| Step: 13
Training loss: 3.3135123252868652
Validation loss: 2.4819790368439048

Epoch: 48| Step: 0
Training loss: 2.120459794998169
Validation loss: 2.4802442237895024

Epoch: 6| Step: 1
Training loss: 3.4750101566314697
Validation loss: 2.4772054956805323

Epoch: 6| Step: 2
Training loss: 2.9483208656311035
Validation loss: 2.475747487878287

Epoch: 6| Step: 3
Training loss: 2.8307929039001465
Validation loss: 2.4792473623829503

Epoch: 6| Step: 4
Training loss: 2.123286724090576
Validation loss: 2.4771762663318264

Epoch: 6| Step: 5
Training loss: 3.1001529693603516
Validation loss: 2.4787054087526057

Epoch: 6| Step: 6
Training loss: 2.3079257011413574
Validation loss: 2.476154504283782

Epoch: 6| Step: 7
Training loss: 3.1508216857910156
Validation loss: 2.4813114968679284

Epoch: 6| Step: 8
Training loss: 2.8469643592834473
Validation loss: 2.4830073131028043

Epoch: 6| Step: 9
Training loss: 2.3389506340026855
Validation loss: 2.4951728159381497

Epoch: 6| Step: 10
Training loss: 3.5468223094940186
Validation loss: 2.5079016429121777

Epoch: 6| Step: 11
Training loss: 2.0125832557678223
Validation loss: 2.5038649112947526

Epoch: 6| Step: 12
Training loss: 2.5280051231384277
Validation loss: 2.5120092950841433

Epoch: 6| Step: 13
Training loss: 1.7964158058166504
Validation loss: 2.506517320550898

Epoch: 49| Step: 0
Training loss: 2.599027395248413
Validation loss: 2.471423490073091

Epoch: 6| Step: 1
Training loss: 2.5554909706115723
Validation loss: 2.4703120903302263

Epoch: 6| Step: 2
Training loss: 2.6063804626464844
Validation loss: 2.478412416673476

Epoch: 6| Step: 3
Training loss: 2.244795083999634
Validation loss: 2.487637994109943

Epoch: 6| Step: 4
Training loss: 3.078112840652466
Validation loss: 2.500603206696049

Epoch: 6| Step: 5
Training loss: 2.9431369304656982
Validation loss: 2.5097748566699285

Epoch: 6| Step: 6
Training loss: 2.7355809211730957
Validation loss: 2.5171779176240325

Epoch: 6| Step: 7
Training loss: 3.250559091567993
Validation loss: 2.5158023988046954

Epoch: 6| Step: 8
Training loss: 2.3404181003570557
Validation loss: 2.511939264112903

Epoch: 6| Step: 9
Training loss: 2.8356893062591553
Validation loss: 2.5106282285464707

Epoch: 6| Step: 10
Training loss: 2.4953527450561523
Validation loss: 2.5019871393839517

Epoch: 6| Step: 11
Training loss: 2.5051331520080566
Validation loss: 2.494031721545804

Epoch: 6| Step: 12
Training loss: 2.9069762229919434
Validation loss: 2.4840192076980427

Epoch: 6| Step: 13
Training loss: 2.8369994163513184
Validation loss: 2.4754358209589475

Epoch: 50| Step: 0
Training loss: 2.7906105518341064
Validation loss: 2.472982947544385

Epoch: 6| Step: 1
Training loss: 2.8773398399353027
Validation loss: 2.4750528489389727

Epoch: 6| Step: 2
Training loss: 2.497626304626465
Validation loss: 2.472467166121288

Epoch: 6| Step: 3
Training loss: 3.012669563293457
Validation loss: 2.476644523682133

Epoch: 6| Step: 4
Training loss: 3.005784273147583
Validation loss: 2.4781748017957135

Epoch: 6| Step: 5
Training loss: 2.029705762863159
Validation loss: 2.466329559203117

Epoch: 6| Step: 6
Training loss: 2.566490650177002
Validation loss: 2.4663834700020413

Epoch: 6| Step: 7
Training loss: 3.1192688941955566
Validation loss: 2.465107753712644

Epoch: 6| Step: 8
Training loss: 3.2741594314575195
Validation loss: 2.4701021409803823

Epoch: 6| Step: 9
Training loss: 2.702258348464966
Validation loss: 2.4659890308175036

Epoch: 6| Step: 10
Training loss: 1.9380125999450684
Validation loss: 2.4728377916479625

Epoch: 6| Step: 11
Training loss: 2.365248680114746
Validation loss: 2.4701938885514454

Epoch: 6| Step: 12
Training loss: 2.7320902347564697
Validation loss: 2.4708059551895305

Epoch: 6| Step: 13
Training loss: 2.6565561294555664
Validation loss: 2.4730635176422777

Epoch: 51| Step: 0
Training loss: 2.4401912689208984
Validation loss: 2.474335855053317

Epoch: 6| Step: 1
Training loss: 2.53775691986084
Validation loss: 2.470647352997975

Epoch: 6| Step: 2
Training loss: 2.395392417907715
Validation loss: 2.4706946316585747

Epoch: 6| Step: 3
Training loss: 2.113680124282837
Validation loss: 2.467350762377503

Epoch: 6| Step: 4
Training loss: 2.864922523498535
Validation loss: 2.467268802786386

Epoch: 6| Step: 5
Training loss: 3.0149905681610107
Validation loss: 2.4687424013691563

Epoch: 6| Step: 6
Training loss: 2.8803045749664307
Validation loss: 2.4673473796536847

Epoch: 6| Step: 7
Training loss: 2.627798557281494
Validation loss: 2.465186024224886

Epoch: 6| Step: 8
Training loss: 2.285212278366089
Validation loss: 2.466333354673078

Epoch: 6| Step: 9
Training loss: 3.430072784423828
Validation loss: 2.462554813713156

Epoch: 6| Step: 10
Training loss: 2.4469823837280273
Validation loss: 2.467382695085259

Epoch: 6| Step: 11
Training loss: 2.896878719329834
Validation loss: 2.482448503535281

Epoch: 6| Step: 12
Training loss: 2.6606528759002686
Validation loss: 2.4869956047304216

Epoch: 6| Step: 13
Training loss: 2.761669158935547
Validation loss: 2.479692377069945

Epoch: 52| Step: 0
Training loss: 2.8473618030548096
Validation loss: 2.47936079835379

Epoch: 6| Step: 1
Training loss: 1.9184224605560303
Validation loss: 2.475667312581052

Epoch: 6| Step: 2
Training loss: 3.296038866043091
Validation loss: 2.4689537453395065

Epoch: 6| Step: 3
Training loss: 2.7784507274627686
Validation loss: 2.456424541370843

Epoch: 6| Step: 4
Training loss: 2.4987659454345703
Validation loss: 2.454730608130014

Epoch: 6| Step: 5
Training loss: 3.6172144412994385
Validation loss: 2.457667073895854

Epoch: 6| Step: 6
Training loss: 2.004633903503418
Validation loss: 2.448173492185531

Epoch: 6| Step: 7
Training loss: 2.604628086090088
Validation loss: 2.446953723507543

Epoch: 6| Step: 8
Training loss: 3.0103092193603516
Validation loss: 2.448012803190498

Epoch: 6| Step: 9
Training loss: 3.0051610469818115
Validation loss: 2.448118976367417

Epoch: 6| Step: 10
Training loss: 2.6849441528320312
Validation loss: 2.455019353538431

Epoch: 6| Step: 11
Training loss: 1.8319231271743774
Validation loss: 2.4589897048088813

Epoch: 6| Step: 12
Training loss: 2.3724019527435303
Validation loss: 2.47954301680288

Epoch: 6| Step: 13
Training loss: 3.0726470947265625
Validation loss: 2.494148296694602

Epoch: 53| Step: 0
Training loss: 2.49224591255188
Validation loss: 2.4894225930654876

Epoch: 6| Step: 1
Training loss: 2.558990001678467
Validation loss: 2.4917479125402306

Epoch: 6| Step: 2
Training loss: 3.5311503410339355
Validation loss: 2.4768731004448346

Epoch: 6| Step: 3
Training loss: 2.3571784496307373
Validation loss: 2.4557725511571413

Epoch: 6| Step: 4
Training loss: 2.2471652030944824
Validation loss: 2.4449655496945946

Epoch: 6| Step: 5
Training loss: 2.966799259185791
Validation loss: 2.4389564606451217

Epoch: 6| Step: 6
Training loss: 3.1322226524353027
Validation loss: 2.4404348788722867

Epoch: 6| Step: 7
Training loss: 2.853257894515991
Validation loss: 2.44131746087023

Epoch: 6| Step: 8
Training loss: 2.5358757972717285
Validation loss: 2.44658838805332

Epoch: 6| Step: 9
Training loss: 1.9729893207550049
Validation loss: 2.453608394950949

Epoch: 6| Step: 10
Training loss: 2.172142505645752
Validation loss: 2.461322446023264

Epoch: 6| Step: 11
Training loss: 2.8153061866760254
Validation loss: 2.49241369001327

Epoch: 6| Step: 12
Training loss: 2.8263638019561768
Validation loss: 2.482820531373383

Epoch: 6| Step: 13
Training loss: 3.2170052528381348
Validation loss: 2.4591064504397813

Epoch: 54| Step: 0
Training loss: 3.237799882888794
Validation loss: 2.448846596543507

Epoch: 6| Step: 1
Training loss: 2.625814914703369
Validation loss: 2.442273821882022

Epoch: 6| Step: 2
Training loss: 2.5335397720336914
Validation loss: 2.4338014612915697

Epoch: 6| Step: 3
Training loss: 2.7089526653289795
Validation loss: 2.431066277206585

Epoch: 6| Step: 4
Training loss: 2.330794095993042
Validation loss: 2.4291403396155244

Epoch: 6| Step: 5
Training loss: 2.378159999847412
Validation loss: 2.439314939642465

Epoch: 6| Step: 6
Training loss: 2.8839104175567627
Validation loss: 2.444342933675294

Epoch: 6| Step: 7
Training loss: 3.183750629425049
Validation loss: 2.462932002159857

Epoch: 6| Step: 8
Training loss: 2.313241958618164
Validation loss: 2.4678068801920903

Epoch: 6| Step: 9
Training loss: 1.9728033542633057
Validation loss: 2.4915823705734743

Epoch: 6| Step: 10
Training loss: 3.1670279502868652
Validation loss: 2.4763226611639864

Epoch: 6| Step: 11
Training loss: 2.5180137157440186
Validation loss: 2.466191396918348

Epoch: 6| Step: 12
Training loss: 2.946657657623291
Validation loss: 2.460763300618818

Epoch: 6| Step: 13
Training loss: 2.020916223526001
Validation loss: 2.451407468447121

Epoch: 55| Step: 0
Training loss: 1.77058744430542
Validation loss: 2.4309073007234963

Epoch: 6| Step: 1
Training loss: 2.6792564392089844
Validation loss: 2.4228383289870394

Epoch: 6| Step: 2
Training loss: 2.574281692504883
Validation loss: 2.422811472287742

Epoch: 6| Step: 3
Training loss: 2.4425652027130127
Validation loss: 2.424349183677345

Epoch: 6| Step: 4
Training loss: 3.563133478164673
Validation loss: 2.4270298070805048

Epoch: 6| Step: 5
Training loss: 3.5020923614501953
Validation loss: 2.4354783822131414

Epoch: 6| Step: 6
Training loss: 2.7982542514801025
Validation loss: 2.4427859372990106

Epoch: 6| Step: 7
Training loss: 3.0375304222106934
Validation loss: 2.444697400575043

Epoch: 6| Step: 8
Training loss: 2.8623037338256836
Validation loss: 2.4429691709497923

Epoch: 6| Step: 9
Training loss: 2.397609233856201
Validation loss: 2.437157255347057

Epoch: 6| Step: 10
Training loss: 2.197406530380249
Validation loss: 2.428760044036373

Epoch: 6| Step: 11
Training loss: 2.6162643432617188
Validation loss: 2.4247762336525867

Epoch: 6| Step: 12
Training loss: 2.7281267642974854
Validation loss: 2.4144423443783998

Epoch: 6| Step: 13
Training loss: 1.8370274305343628
Validation loss: 2.4115015332416823

Epoch: 56| Step: 0
Training loss: 2.7980270385742188
Validation loss: 2.414530133688322

Epoch: 6| Step: 1
Training loss: 1.7671749591827393
Validation loss: 2.41336973251835

Epoch: 6| Step: 2
Training loss: 2.294719934463501
Validation loss: 2.4137383250780005

Epoch: 6| Step: 3
Training loss: 2.8141775131225586
Validation loss: 2.414148622943509

Epoch: 6| Step: 4
Training loss: 3.2712485790252686
Validation loss: 2.4147443117633944

Epoch: 6| Step: 5
Training loss: 3.3145203590393066
Validation loss: 2.413056463323614

Epoch: 6| Step: 6
Training loss: 2.8398475646972656
Validation loss: 2.4167748946015553

Epoch: 6| Step: 7
Training loss: 2.5841307640075684
Validation loss: 2.4239701019820346

Epoch: 6| Step: 8
Training loss: 2.4723494052886963
Validation loss: 2.433707699980787

Epoch: 6| Step: 9
Training loss: 2.75003719329834
Validation loss: 2.450367707078175

Epoch: 6| Step: 10
Training loss: 3.202049493789673
Validation loss: 2.4545318131805747

Epoch: 6| Step: 11
Training loss: 2.6288962364196777
Validation loss: 2.465584707516496

Epoch: 6| Step: 12
Training loss: 1.9263783693313599
Validation loss: 2.4657832627655356

Epoch: 6| Step: 13
Training loss: 2.2575457096099854
Validation loss: 2.4604739860821794

Epoch: 57| Step: 0
Training loss: 1.4241913557052612
Validation loss: 2.434874285933792

Epoch: 6| Step: 1
Training loss: 3.509469509124756
Validation loss: 2.4083161636065413

Epoch: 6| Step: 2
Training loss: 1.6763718128204346
Validation loss: 2.417002647153793

Epoch: 6| Step: 3
Training loss: 1.7996385097503662
Validation loss: 2.4377407668739237

Epoch: 6| Step: 4
Training loss: 2.819490909576416
Validation loss: 2.4581850959408666

Epoch: 6| Step: 5
Training loss: 3.7161314487457275
Validation loss: 2.473150068713773

Epoch: 6| Step: 6
Training loss: 2.4966797828674316
Validation loss: 2.475273529688517

Epoch: 6| Step: 7
Training loss: 3.344613790512085
Validation loss: 2.470456930898851

Epoch: 6| Step: 8
Training loss: 2.4691097736358643
Validation loss: 2.4683028677458405

Epoch: 6| Step: 9
Training loss: 2.6288576126098633
Validation loss: 2.4606616009948072

Epoch: 6| Step: 10
Training loss: 3.3972620964050293
Validation loss: 2.4544775614174466

Epoch: 6| Step: 11
Training loss: 2.254570960998535
Validation loss: 2.448713228266726

Epoch: 6| Step: 12
Training loss: 2.9840853214263916
Validation loss: 2.440035245751822

Epoch: 6| Step: 13
Training loss: 3.436492919921875
Validation loss: 2.4359235148276053

Epoch: 58| Step: 0
Training loss: 2.4618027210235596
Validation loss: 2.4336921220184653

Epoch: 6| Step: 1
Training loss: 3.083085536956787
Validation loss: 2.4310633802926667

Epoch: 6| Step: 2
Training loss: 2.0162558555603027
Validation loss: 2.4379273563302974

Epoch: 6| Step: 3
Training loss: 3.2562360763549805
Validation loss: 2.4612837837588404

Epoch: 6| Step: 4
Training loss: 2.737706184387207
Validation loss: 2.454889564103978

Epoch: 6| Step: 5
Training loss: 2.240365982055664
Validation loss: 2.447719076628326

Epoch: 6| Step: 6
Training loss: 3.1047799587249756
Validation loss: 2.4301081370281916

Epoch: 6| Step: 7
Training loss: 2.127570867538452
Validation loss: 2.4070272189314648

Epoch: 6| Step: 8
Training loss: 2.9330668449401855
Validation loss: 2.4022184392457366

Epoch: 6| Step: 9
Training loss: 2.3272290229797363
Validation loss: 2.399856675055719

Epoch: 6| Step: 10
Training loss: 2.7268242835998535
Validation loss: 2.3988894390803512

Epoch: 6| Step: 11
Training loss: 2.8148770332336426
Validation loss: 2.406133113368865

Epoch: 6| Step: 12
Training loss: 2.5862317085266113
Validation loss: 2.4289064407348633

Epoch: 6| Step: 13
Training loss: 2.6926379203796387
Validation loss: 2.4870103969368884

Epoch: 59| Step: 0
Training loss: 2.4300920963287354
Validation loss: 2.536335265764626

Epoch: 6| Step: 1
Training loss: 3.414112091064453
Validation loss: 2.5708120048687024

Epoch: 6| Step: 2
Training loss: 2.6168606281280518
Validation loss: 2.53364755517693

Epoch: 6| Step: 3
Training loss: 2.6376500129699707
Validation loss: 2.4944683300551547

Epoch: 6| Step: 4
Training loss: 1.9702479839324951
Validation loss: 2.4611815380793747

Epoch: 6| Step: 5
Training loss: 3.4405808448791504
Validation loss: 2.448528374395063

Epoch: 6| Step: 6
Training loss: 3.035848379135132
Validation loss: 2.4363820783553587

Epoch: 6| Step: 7
Training loss: 1.9604662656784058
Validation loss: 2.4321563807866906

Epoch: 6| Step: 8
Training loss: 2.5375194549560547
Validation loss: 2.4224216758563952

Epoch: 6| Step: 9
Training loss: 1.847901701927185
Validation loss: 2.426563101430093

Epoch: 6| Step: 10
Training loss: 1.9759458303451538
Validation loss: 2.4173039364558395

Epoch: 6| Step: 11
Training loss: 3.5141286849975586
Validation loss: 2.4097501001050396

Epoch: 6| Step: 12
Training loss: 2.9209694862365723
Validation loss: 2.4037368374486126

Epoch: 6| Step: 13
Training loss: 3.0187878608703613
Validation loss: 2.4019276275429675

Epoch: 60| Step: 0
Training loss: 2.914368152618408
Validation loss: 2.3910847017841954

Epoch: 6| Step: 1
Training loss: 2.383002758026123
Validation loss: 2.393399138604441

Epoch: 6| Step: 2
Training loss: 2.2529454231262207
Validation loss: 2.3989090419584707

Epoch: 6| Step: 3
Training loss: 2.946432590484619
Validation loss: 2.4037774557708413

Epoch: 6| Step: 4
Training loss: 2.659583806991577
Validation loss: 2.4064761874496297

Epoch: 6| Step: 5
Training loss: 2.136451482772827
Validation loss: 2.417674938837687

Epoch: 6| Step: 6
Training loss: 2.5058634281158447
Validation loss: 2.4203371181282947

Epoch: 6| Step: 7
Training loss: 2.463205099105835
Validation loss: 2.4276196597724833

Epoch: 6| Step: 8
Training loss: 2.8801937103271484
Validation loss: 2.4178218046824136

Epoch: 6| Step: 9
Training loss: 2.8692402839660645
Validation loss: 2.422711472357473

Epoch: 6| Step: 10
Training loss: 2.554993152618408
Validation loss: 2.41218848254091

Epoch: 6| Step: 11
Training loss: 2.7538511753082275
Validation loss: 2.4047776742648055

Epoch: 6| Step: 12
Training loss: 3.243828773498535
Validation loss: 2.3967248906371412

Epoch: 6| Step: 13
Training loss: 2.587540864944458
Validation loss: 2.392290232002094

Epoch: 61| Step: 0
Training loss: 2.617964744567871
Validation loss: 2.384339722253943

Epoch: 6| Step: 1
Training loss: 2.7603349685668945
Validation loss: 2.383459342423306

Epoch: 6| Step: 2
Training loss: 2.151337146759033
Validation loss: 2.3844992114651586

Epoch: 6| Step: 3
Training loss: 2.064850091934204
Validation loss: 2.4034861082671792

Epoch: 6| Step: 4
Training loss: 2.7679007053375244
Validation loss: 2.4502777925101658

Epoch: 6| Step: 5
Training loss: 2.990316152572632
Validation loss: 2.5920687285802697

Epoch: 6| Step: 6
Training loss: 2.497448205947876
Validation loss: 2.710754984168596

Epoch: 6| Step: 7
Training loss: 3.4939582347869873
Validation loss: 2.782915189702024

Epoch: 6| Step: 8
Training loss: 3.646121025085449
Validation loss: 2.6316405111743557

Epoch: 6| Step: 9
Training loss: 2.116321563720703
Validation loss: 2.461913062680152

Epoch: 6| Step: 10
Training loss: 2.7315096855163574
Validation loss: 2.39074714978536

Epoch: 6| Step: 11
Training loss: 2.976604461669922
Validation loss: 2.3798179677737656

Epoch: 6| Step: 12
Training loss: 2.598723888397217
Validation loss: 2.405857114381688

Epoch: 6| Step: 13
Training loss: 1.95155930519104
Validation loss: 2.4630924065907798

Epoch: 62| Step: 0
Training loss: 2.853191614151001
Validation loss: 2.5191150788337953

Epoch: 6| Step: 1
Training loss: 2.828232765197754
Validation loss: 2.5649323104530253

Epoch: 6| Step: 2
Training loss: 2.485434055328369
Validation loss: 2.6426506196298907

Epoch: 6| Step: 3
Training loss: 3.3723151683807373
Validation loss: 2.6597000501489125

Epoch: 6| Step: 4
Training loss: 3.123678207397461
Validation loss: 2.647350675316267

Epoch: 6| Step: 5
Training loss: 2.665414333343506
Validation loss: 2.653714264592817

Epoch: 6| Step: 6
Training loss: 2.924935817718506
Validation loss: 2.6452992218796925

Epoch: 6| Step: 7
Training loss: 1.8989624977111816
Validation loss: 2.6262387896096833

Epoch: 6| Step: 8
Training loss: 2.349717140197754
Validation loss: 2.6056788198409544

Epoch: 6| Step: 9
Training loss: 2.6106691360473633
Validation loss: 2.581397976926578

Epoch: 6| Step: 10
Training loss: 2.6324868202209473
Validation loss: 2.5592994715577815

Epoch: 6| Step: 11
Training loss: 3.360661745071411
Validation loss: 2.522565867311211

Epoch: 6| Step: 12
Training loss: 3.1097469329833984
Validation loss: 2.508869524924986

Epoch: 6| Step: 13
Training loss: 2.7652792930603027
Validation loss: 2.4920398650630826

Epoch: 63| Step: 0
Training loss: 2.396899700164795
Validation loss: 2.483608025376515

Epoch: 6| Step: 1
Training loss: 3.0695483684539795
Validation loss: 2.4843029822072675

Epoch: 6| Step: 2
Training loss: 2.1360578536987305
Validation loss: 2.4829827482982347

Epoch: 6| Step: 3
Training loss: 3.3003249168395996
Validation loss: 2.4755772339400424

Epoch: 6| Step: 4
Training loss: 3.4351882934570312
Validation loss: 2.469562433099234

Epoch: 6| Step: 5
Training loss: 2.23715877532959
Validation loss: 2.4470649175746466

Epoch: 6| Step: 6
Training loss: 2.037332057952881
Validation loss: 2.4449778244059575

Epoch: 6| Step: 7
Training loss: 2.2007415294647217
Validation loss: 2.470097226481284

Epoch: 6| Step: 8
Training loss: 2.4802427291870117
Validation loss: 2.483711006820843

Epoch: 6| Step: 9
Training loss: 2.6282715797424316
Validation loss: 2.5085777774933846

Epoch: 6| Step: 10
Training loss: 2.6916208267211914
Validation loss: 2.4998788884890977

Epoch: 6| Step: 11
Training loss: 3.519768238067627
Validation loss: 2.48862709024901

Epoch: 6| Step: 12
Training loss: 2.079681634902954
Validation loss: 2.4503309470351025

Epoch: 6| Step: 13
Training loss: 3.381293296813965
Validation loss: 2.4277129891098186

Epoch: 64| Step: 0
Training loss: 2.4305267333984375
Validation loss: 2.39920412981382

Epoch: 6| Step: 1
Training loss: 2.4984235763549805
Validation loss: 2.3726665794208484

Epoch: 6| Step: 2
Training loss: 2.854412078857422
Validation loss: 2.370559071981779

Epoch: 6| Step: 3
Training loss: 2.7369303703308105
Validation loss: 2.3770895465727775

Epoch: 6| Step: 4
Training loss: 2.4906105995178223
Validation loss: 2.390869367507196

Epoch: 6| Step: 5
Training loss: 2.8089027404785156
Validation loss: 2.4096588908985095

Epoch: 6| Step: 6
Training loss: 3.0776965618133545
Validation loss: 2.431008142809714

Epoch: 6| Step: 7
Training loss: 2.217357635498047
Validation loss: 2.4203766161395657

Epoch: 6| Step: 8
Training loss: 2.2956933975219727
Validation loss: 2.420541254422998

Epoch: 6| Step: 9
Training loss: 2.7883284091949463
Validation loss: 2.418828784778554

Epoch: 6| Step: 10
Training loss: 3.035543441772461
Validation loss: 2.4158574355545865

Epoch: 6| Step: 11
Training loss: 3.081611156463623
Validation loss: 2.413548167033862

Epoch: 6| Step: 12
Training loss: 2.0455079078674316
Validation loss: 2.4055486340676584

Epoch: 6| Step: 13
Training loss: 3.1862611770629883
Validation loss: 2.3969257595718547

Epoch: 65| Step: 0
Training loss: 3.0337886810302734
Validation loss: 2.388612513901085

Epoch: 6| Step: 1
Training loss: 2.788341999053955
Validation loss: 2.38395022320491

Epoch: 6| Step: 2
Training loss: 2.757699966430664
Validation loss: 2.3788428691125687

Epoch: 6| Step: 3
Training loss: 2.4864249229431152
Validation loss: 2.3717865200452906

Epoch: 6| Step: 4
Training loss: 2.997100591659546
Validation loss: 2.371054285316057

Epoch: 6| Step: 5
Training loss: 2.230464458465576
Validation loss: 2.369990705161966

Epoch: 6| Step: 6
Training loss: 2.286769390106201
Validation loss: 2.368071586854996

Epoch: 6| Step: 7
Training loss: 3.313664436340332
Validation loss: 2.365197435502083

Epoch: 6| Step: 8
Training loss: 2.5569822788238525
Validation loss: 2.3829784752220236

Epoch: 6| Step: 9
Training loss: 3.031641721725464
Validation loss: 2.3885358482278805

Epoch: 6| Step: 10
Training loss: 1.8075377941131592
Validation loss: 2.387705170980064

Epoch: 6| Step: 11
Training loss: 2.2716450691223145
Validation loss: 2.385916668881652

Epoch: 6| Step: 12
Training loss: 2.087021589279175
Validation loss: 2.3899696462897846

Epoch: 6| Step: 13
Training loss: 3.5435659885406494
Validation loss: 2.3944142685141614

Epoch: 66| Step: 0
Training loss: 3.0333123207092285
Validation loss: 2.376959582810761

Epoch: 6| Step: 1
Training loss: 2.3203444480895996
Validation loss: 2.3784689005985054

Epoch: 6| Step: 2
Training loss: 2.9481146335601807
Validation loss: 2.362363388461451

Epoch: 6| Step: 3
Training loss: 2.5355820655822754
Validation loss: 2.3675354911435034

Epoch: 6| Step: 4
Training loss: 2.0520565509796143
Validation loss: 2.3609685282553396

Epoch: 6| Step: 5
Training loss: 1.5578935146331787
Validation loss: 2.3780499248094458

Epoch: 6| Step: 6
Training loss: 2.9776692390441895
Validation loss: 2.3949965892299527

Epoch: 6| Step: 7
Training loss: 2.943563222885132
Validation loss: 2.4061790820091002

Epoch: 6| Step: 8
Training loss: 2.5155029296875
Validation loss: 2.39980141321818

Epoch: 6| Step: 9
Training loss: 2.582028865814209
Validation loss: 2.3842003396762315

Epoch: 6| Step: 10
Training loss: 2.267963409423828
Validation loss: 2.3644873352460962

Epoch: 6| Step: 11
Training loss: 3.1342504024505615
Validation loss: 2.3418316174578924

Epoch: 6| Step: 12
Training loss: 2.7453486919403076
Validation loss: 2.3437701245789886

Epoch: 6| Step: 13
Training loss: 3.3107540607452393
Validation loss: 2.345825711886088

Epoch: 67| Step: 0
Training loss: 2.439183235168457
Validation loss: 2.343745467483356

Epoch: 6| Step: 1
Training loss: 2.2709898948669434
Validation loss: 2.3459345884220575

Epoch: 6| Step: 2
Training loss: 3.4213714599609375
Validation loss: 2.3450253471251457

Epoch: 6| Step: 3
Training loss: 2.4810397624969482
Validation loss: 2.3455819929799726

Epoch: 6| Step: 4
Training loss: 2.407743215560913
Validation loss: 2.344266140332786

Epoch: 6| Step: 5
Training loss: 3.318018913269043
Validation loss: 2.344258831393334

Epoch: 6| Step: 6
Training loss: 2.024735450744629
Validation loss: 2.3445706521311114

Epoch: 6| Step: 7
Training loss: 2.6389822959899902
Validation loss: 2.3368859983259633

Epoch: 6| Step: 8
Training loss: 2.117683172225952
Validation loss: 2.3391316783043647

Epoch: 6| Step: 9
Training loss: 2.329531192779541
Validation loss: 2.3466597898032076

Epoch: 6| Step: 10
Training loss: 3.0500383377075195
Validation loss: 2.3546291807646393

Epoch: 6| Step: 11
Training loss: 2.8590896129608154
Validation loss: 2.370154444889356

Epoch: 6| Step: 12
Training loss: 2.724252700805664
Validation loss: 2.3834279044981925

Epoch: 6| Step: 13
Training loss: 2.4878451824188232
Validation loss: 2.396562644230422

Epoch: 68| Step: 0
Training loss: 2.271117925643921
Validation loss: 2.4170447652057936

Epoch: 6| Step: 1
Training loss: 2.944272518157959
Validation loss: 2.4296218272178405

Epoch: 6| Step: 2
Training loss: 2.2658705711364746
Validation loss: 2.405218724281557

Epoch: 6| Step: 3
Training loss: 3.154794692993164
Validation loss: 2.434403791222521

Epoch: 6| Step: 4
Training loss: 2.791884422302246
Validation loss: 2.4077891662556636

Epoch: 6| Step: 5
Training loss: 2.82129168510437
Validation loss: 2.3824015586606917

Epoch: 6| Step: 6
Training loss: 2.549773693084717
Validation loss: 2.350822893522119

Epoch: 6| Step: 7
Training loss: 2.827793598175049
Validation loss: 2.341881485395534

Epoch: 6| Step: 8
Training loss: 3.0881264209747314
Validation loss: 2.334127195419804

Epoch: 6| Step: 9
Training loss: 1.725755214691162
Validation loss: 2.3343681699486187

Epoch: 6| Step: 10
Training loss: 2.396043300628662
Validation loss: 2.332090740562767

Epoch: 6| Step: 11
Training loss: 2.7354469299316406
Validation loss: 2.3345636654925603

Epoch: 6| Step: 12
Training loss: 2.97590970993042
Validation loss: 2.335274536122558

Epoch: 6| Step: 13
Training loss: 1.9145970344543457
Validation loss: 2.3377143259971374

Epoch: 69| Step: 0
Training loss: 2.831820487976074
Validation loss: 2.340501880133024

Epoch: 6| Step: 1
Training loss: 2.994147539138794
Validation loss: 2.3524516269724858

Epoch: 6| Step: 2
Training loss: 2.956252098083496
Validation loss: 2.3792168094265844

Epoch: 6| Step: 3
Training loss: 2.820746421813965
Validation loss: 2.382696372206493

Epoch: 6| Step: 4
Training loss: 2.420264959335327
Validation loss: 2.352734440116472

Epoch: 6| Step: 5
Training loss: 2.392709255218506
Validation loss: 2.3346800599046933

Epoch: 6| Step: 6
Training loss: 2.434238910675049
Validation loss: 2.332298109608312

Epoch: 6| Step: 7
Training loss: 2.8639116287231445
Validation loss: 2.3304478506888113

Epoch: 6| Step: 8
Training loss: 2.8546409606933594
Validation loss: 2.328043491609635

Epoch: 6| Step: 9
Training loss: 2.215435266494751
Validation loss: 2.331470609993063

Epoch: 6| Step: 10
Training loss: 1.9209333658218384
Validation loss: 2.32858629380503

Epoch: 6| Step: 11
Training loss: 3.005843162536621
Validation loss: 2.325284804067304

Epoch: 6| Step: 12
Training loss: 2.2436630725860596
Validation loss: 2.326165550498552

Epoch: 6| Step: 13
Training loss: 2.700185537338257
Validation loss: 2.3267774120453866

Epoch: 70| Step: 0
Training loss: 2.4226512908935547
Validation loss: 2.336536463870797

Epoch: 6| Step: 1
Training loss: 2.764820098876953
Validation loss: 2.3437589547967397

Epoch: 6| Step: 2
Training loss: 2.3843941688537598
Validation loss: 2.3581022806065057

Epoch: 6| Step: 3
Training loss: 2.651275873184204
Validation loss: 2.3652767955615954

Epoch: 6| Step: 4
Training loss: 2.2356278896331787
Validation loss: 2.392845166626797

Epoch: 6| Step: 5
Training loss: 2.5087077617645264
Validation loss: 2.400561019938479

Epoch: 6| Step: 6
Training loss: 3.0043725967407227
Validation loss: 2.4158078419264926

Epoch: 6| Step: 7
Training loss: 3.1979503631591797
Validation loss: 2.4263504115484094

Epoch: 6| Step: 8
Training loss: 2.0162105560302734
Validation loss: 2.37922046261449

Epoch: 6| Step: 9
Training loss: 2.588639736175537
Validation loss: 2.3477875558278893

Epoch: 6| Step: 10
Training loss: 2.963876247406006
Validation loss: 2.3289504845937095

Epoch: 6| Step: 11
Training loss: 2.3557329177856445
Validation loss: 2.327069159476988

Epoch: 6| Step: 12
Training loss: 2.7848010063171387
Validation loss: 2.326316992441813

Epoch: 6| Step: 13
Training loss: 2.6099634170532227
Validation loss: 2.3258132473115

Epoch: 71| Step: 0
Training loss: 2.6021535396575928
Validation loss: 2.326841861970963

Epoch: 6| Step: 1
Training loss: 2.159970760345459
Validation loss: 2.3252021881841842

Epoch: 6| Step: 2
Training loss: 2.176100254058838
Validation loss: 2.3270624504294446

Epoch: 6| Step: 3
Training loss: 2.6289167404174805
Validation loss: 2.324722813021752

Epoch: 6| Step: 4
Training loss: 2.5491671562194824
Validation loss: 2.3236382725418254

Epoch: 6| Step: 5
Training loss: 2.568828582763672
Validation loss: 2.323593670322049

Epoch: 6| Step: 6
Training loss: 2.4513230323791504
Validation loss: 2.3236340579166206

Epoch: 6| Step: 7
Training loss: 2.9916439056396484
Validation loss: 2.318163646164761

Epoch: 6| Step: 8
Training loss: 3.111746311187744
Validation loss: 2.317481558809998

Epoch: 6| Step: 9
Training loss: 2.8873424530029297
Validation loss: 2.3171701354365193

Epoch: 6| Step: 10
Training loss: 3.044724941253662
Validation loss: 2.322279063604211

Epoch: 6| Step: 11
Training loss: 2.385662317276001
Validation loss: 2.3170539832884267

Epoch: 6| Step: 12
Training loss: 2.3034324645996094
Validation loss: 2.324678856839416

Epoch: 6| Step: 13
Training loss: 2.3644871711730957
Validation loss: 2.338852258138759

Epoch: 72| Step: 0
Training loss: 2.1825342178344727
Validation loss: 2.329509832525766

Epoch: 6| Step: 1
Training loss: 2.575507640838623
Validation loss: 2.337892979703924

Epoch: 6| Step: 2
Training loss: 2.486266613006592
Validation loss: 2.3395243819041918

Epoch: 6| Step: 3
Training loss: 3.057543992996216
Validation loss: 2.3549627616841304

Epoch: 6| Step: 4
Training loss: 2.101090431213379
Validation loss: 2.3560542291210544

Epoch: 6| Step: 5
Training loss: 3.0911693572998047
Validation loss: 2.3560600998581096

Epoch: 6| Step: 6
Training loss: 2.968803882598877
Validation loss: 2.3758976062138877

Epoch: 6| Step: 7
Training loss: 2.576869010925293
Validation loss: 2.3767171752068306

Epoch: 6| Step: 8
Training loss: 1.6002541780471802
Validation loss: 2.345863180775796

Epoch: 6| Step: 9
Training loss: 2.958892345428467
Validation loss: 2.331531947658908

Epoch: 6| Step: 10
Training loss: 2.699167251586914
Validation loss: 2.322717269261678

Epoch: 6| Step: 11
Training loss: 3.082526206970215
Validation loss: 2.3205908729184057

Epoch: 6| Step: 12
Training loss: 1.808319091796875
Validation loss: 2.3036878160251084

Epoch: 6| Step: 13
Training loss: 3.0559587478637695
Validation loss: 2.309441897176927

Epoch: 73| Step: 0
Training loss: 2.380547523498535
Validation loss: 2.30702317401927

Epoch: 6| Step: 1
Training loss: 1.8259227275848389
Validation loss: 2.3074222482660764

Epoch: 6| Step: 2
Training loss: 2.8561763763427734
Validation loss: 2.3149189513216735

Epoch: 6| Step: 3
Training loss: 2.692244529724121
Validation loss: 2.3325607161368094

Epoch: 6| Step: 4
Training loss: 2.523996114730835
Validation loss: 2.3339900560276483

Epoch: 6| Step: 5
Training loss: 2.9659786224365234
Validation loss: 2.3397572502013175

Epoch: 6| Step: 6
Training loss: 1.8649550676345825
Validation loss: 2.347024861202445

Epoch: 6| Step: 7
Training loss: 3.2976109981536865
Validation loss: 2.338639097829019

Epoch: 6| Step: 8
Training loss: 2.9996509552001953
Validation loss: 2.343741804040888

Epoch: 6| Step: 9
Training loss: 2.285633087158203
Validation loss: 2.3342600355866137

Epoch: 6| Step: 10
Training loss: 2.4735019207000732
Validation loss: 2.313417500065219

Epoch: 6| Step: 11
Training loss: 1.948664665222168
Validation loss: 2.3095392450209586

Epoch: 6| Step: 12
Training loss: 2.686221122741699
Validation loss: 2.3018598761609805

Epoch: 6| Step: 13
Training loss: 3.754814624786377
Validation loss: 2.2988542023525445

Epoch: 74| Step: 0
Training loss: 1.952737808227539
Validation loss: 2.298293029108355

Epoch: 6| Step: 1
Training loss: 1.7986869812011719
Validation loss: 2.29742528289877

Epoch: 6| Step: 2
Training loss: 3.0800232887268066
Validation loss: 2.294484192325223

Epoch: 6| Step: 3
Training loss: 2.9771103858947754
Validation loss: 2.2952182395483858

Epoch: 6| Step: 4
Training loss: 1.8282880783081055
Validation loss: 2.299412368446268

Epoch: 6| Step: 5
Training loss: 2.341667652130127
Validation loss: 2.307975633170015

Epoch: 6| Step: 6
Training loss: 3.15554141998291
Validation loss: 2.323365398632583

Epoch: 6| Step: 7
Training loss: 2.941234588623047
Validation loss: 2.3516376838889173

Epoch: 6| Step: 8
Training loss: 3.344453811645508
Validation loss: 2.357226187183011

Epoch: 6| Step: 9
Training loss: 2.9396235942840576
Validation loss: 2.3546927334159933

Epoch: 6| Step: 10
Training loss: 2.204514980316162
Validation loss: 2.3608048474916847

Epoch: 6| Step: 11
Training loss: 2.4155120849609375
Validation loss: 2.338402409707346

Epoch: 6| Step: 12
Training loss: 2.2902848720550537
Validation loss: 2.312774342875327

Epoch: 6| Step: 13
Training loss: 2.8266704082489014
Validation loss: 2.2986374003912813

Epoch: 75| Step: 0
Training loss: 2.308803081512451
Validation loss: 2.2955933899007817

Epoch: 6| Step: 1
Training loss: 2.6213152408599854
Validation loss: 2.2874949478333995

Epoch: 6| Step: 2
Training loss: 2.0236306190490723
Validation loss: 2.288102049981394

Epoch: 6| Step: 3
Training loss: 2.924276828765869
Validation loss: 2.2835221623861663

Epoch: 6| Step: 4
Training loss: 2.1059765815734863
Validation loss: 2.286139142128729

Epoch: 6| Step: 5
Training loss: 3.5421230792999268
Validation loss: 2.28455993693362

Epoch: 6| Step: 6
Training loss: 2.397181510925293
Validation loss: 2.2850879135952202

Epoch: 6| Step: 7
Training loss: 2.531681537628174
Validation loss: 2.28473432858785

Epoch: 6| Step: 8
Training loss: 2.686598300933838
Validation loss: 2.2856719852775655

Epoch: 6| Step: 9
Training loss: 2.9405171871185303
Validation loss: 2.288000904103761

Epoch: 6| Step: 10
Training loss: 2.081976890563965
Validation loss: 2.296221307528916

Epoch: 6| Step: 11
Training loss: 2.670835494995117
Validation loss: 2.2916442937748407

Epoch: 6| Step: 12
Training loss: 2.7890777587890625
Validation loss: 2.30699655061127

Epoch: 6| Step: 13
Training loss: 1.9517165422439575
Validation loss: 2.323885363917197

Epoch: 76| Step: 0
Training loss: 2.524488687515259
Validation loss: 2.348262635610437

Epoch: 6| Step: 1
Training loss: 2.9436721801757812
Validation loss: 2.3633860157382105

Epoch: 6| Step: 2
Training loss: 2.753080368041992
Validation loss: 2.3871063186276342

Epoch: 6| Step: 3
Training loss: 2.332493305206299
Validation loss: 2.3652255612034954

Epoch: 6| Step: 4
Training loss: 2.630209445953369
Validation loss: 2.323654249150266

Epoch: 6| Step: 5
Training loss: 2.1585559844970703
Validation loss: 2.2851120477081626

Epoch: 6| Step: 6
Training loss: 2.7829391956329346
Validation loss: 2.2837992868115826

Epoch: 6| Step: 7
Training loss: 2.613266944885254
Validation loss: 2.275981254475091

Epoch: 6| Step: 8
Training loss: 2.0816850662231445
Validation loss: 2.2834528376979213

Epoch: 6| Step: 9
Training loss: 2.9799325466156006
Validation loss: 2.2955808434435117

Epoch: 6| Step: 10
Training loss: 2.512261390686035
Validation loss: 2.3000377608883764

Epoch: 6| Step: 11
Training loss: 2.3087801933288574
Validation loss: 2.3124568846917923

Epoch: 6| Step: 12
Training loss: 2.6748805046081543
Validation loss: 2.305154477396319

Epoch: 6| Step: 13
Training loss: 2.3793931007385254
Validation loss: 2.3026295772162815

Epoch: 77| Step: 0
Training loss: 2.4449663162231445
Validation loss: 2.2881269044773553

Epoch: 6| Step: 1
Training loss: 2.5610713958740234
Validation loss: 2.287763208471319

Epoch: 6| Step: 2
Training loss: 1.8971126079559326
Validation loss: 2.282378873517436

Epoch: 6| Step: 3
Training loss: 2.442800760269165
Validation loss: 2.2720026636636383

Epoch: 6| Step: 4
Training loss: 2.616011142730713
Validation loss: 2.27380338791878

Epoch: 6| Step: 5
Training loss: 2.7417654991149902
Validation loss: 2.313718108720677

Epoch: 6| Step: 6
Training loss: 1.8672823905944824
Validation loss: 2.333500313502486

Epoch: 6| Step: 7
Training loss: 2.7879252433776855
Validation loss: 2.3263849596823416

Epoch: 6| Step: 8
Training loss: 2.5773143768310547
Validation loss: 2.3139464137374715

Epoch: 6| Step: 9
Training loss: 2.168330669403076
Validation loss: 2.2879490839537753

Epoch: 6| Step: 10
Training loss: 3.0737173557281494
Validation loss: 2.2741179568793184

Epoch: 6| Step: 11
Training loss: 2.841477632522583
Validation loss: 2.2661310934251353

Epoch: 6| Step: 12
Training loss: 3.1140904426574707
Validation loss: 2.267934686394148

Epoch: 6| Step: 13
Training loss: 2.797572374343872
Validation loss: 2.2679289797300934

Epoch: 78| Step: 0
Training loss: 2.31516432762146
Validation loss: 2.261996933208999

Epoch: 6| Step: 1
Training loss: 2.208280563354492
Validation loss: 2.2720132720085884

Epoch: 6| Step: 2
Training loss: 2.298901081085205
Validation loss: 2.2746755871721493

Epoch: 6| Step: 3
Training loss: 2.111672878265381
Validation loss: 2.2794375368343887

Epoch: 6| Step: 4
Training loss: 2.2311418056488037
Validation loss: 2.2887660149605042

Epoch: 6| Step: 5
Training loss: 2.4774622917175293
Validation loss: 2.306185350623182

Epoch: 6| Step: 6
Training loss: 3.3405280113220215
Validation loss: 2.314480161154142

Epoch: 6| Step: 7
Training loss: 2.4487409591674805
Validation loss: 2.3064965765963317

Epoch: 6| Step: 8
Training loss: 2.7606608867645264
Validation loss: 2.3308461404615834

Epoch: 6| Step: 9
Training loss: 2.7357821464538574
Validation loss: 2.3111582494551137

Epoch: 6| Step: 10
Training loss: 2.6174354553222656
Validation loss: 2.3050544056841122

Epoch: 6| Step: 11
Training loss: 2.9951627254486084
Validation loss: 2.2929905332544798

Epoch: 6| Step: 12
Training loss: 2.3637595176696777
Validation loss: 2.2871714817580355

Epoch: 6| Step: 13
Training loss: 2.8950796127319336
Validation loss: 2.2757571487016577

Epoch: 79| Step: 0
Training loss: 2.5362887382507324
Validation loss: 2.2708640893300376

Epoch: 6| Step: 1
Training loss: 2.588557243347168
Validation loss: 2.2689349779518704

Epoch: 6| Step: 2
Training loss: 1.9046831130981445
Validation loss: 2.2664870831274215

Epoch: 6| Step: 3
Training loss: 2.884556770324707
Validation loss: 2.2725634369798886

Epoch: 6| Step: 4
Training loss: 2.810558795928955
Validation loss: 2.2706102555797947

Epoch: 6| Step: 5
Training loss: 2.447427988052368
Validation loss: 2.26886014656354

Epoch: 6| Step: 6
Training loss: 2.003077983856201
Validation loss: 2.2662544353033907

Epoch: 6| Step: 7
Training loss: 2.174635171890259
Validation loss: 2.2727568329021497

Epoch: 6| Step: 8
Training loss: 2.844831943511963
Validation loss: 2.2682244623861005

Epoch: 6| Step: 9
Training loss: 2.5717530250549316
Validation loss: 2.2553106995039087

Epoch: 6| Step: 10
Training loss: 2.637381076812744
Validation loss: 2.2605064709981284

Epoch: 6| Step: 11
Training loss: 3.0472960472106934
Validation loss: 2.256164191871561

Epoch: 6| Step: 12
Training loss: 2.5769476890563965
Validation loss: 2.2525069995593

Epoch: 6| Step: 13
Training loss: 2.1485047340393066
Validation loss: 2.2496107932059997

Epoch: 80| Step: 0
Training loss: 2.9438939094543457
Validation loss: 2.251409166602678

Epoch: 6| Step: 1
Training loss: 2.3419108390808105
Validation loss: 2.2572320110054425

Epoch: 6| Step: 2
Training loss: 2.4737749099731445
Validation loss: 2.2617590760671966

Epoch: 6| Step: 3
Training loss: 1.7335708141326904
Validation loss: 2.2631458415780017

Epoch: 6| Step: 4
Training loss: 2.0312604904174805
Validation loss: 2.278838070490027

Epoch: 6| Step: 5
Training loss: 2.2716622352600098
Validation loss: 2.283754159045476

Epoch: 6| Step: 6
Training loss: 2.757181167602539
Validation loss: 2.286254941776235

Epoch: 6| Step: 7
Training loss: 2.6429755687713623
Validation loss: 2.2603003722365185

Epoch: 6| Step: 8
Training loss: 2.8992137908935547
Validation loss: 2.247304090889551

Epoch: 6| Step: 9
Training loss: 3.0488784313201904
Validation loss: 2.2496643579134377

Epoch: 6| Step: 10
Training loss: 2.6718897819519043
Validation loss: 2.2394349626315537

Epoch: 6| Step: 11
Training loss: 2.5853164196014404
Validation loss: 2.2391026404596146

Epoch: 6| Step: 12
Training loss: 2.5000128746032715
Validation loss: 2.245988345915271

Epoch: 6| Step: 13
Training loss: 2.4015355110168457
Validation loss: 2.2423395777261383

Epoch: 81| Step: 0
Training loss: 3.08426570892334
Validation loss: 2.2380539832576627

Epoch: 6| Step: 1
Training loss: 2.293539047241211
Validation loss: 2.24132360822411

Epoch: 6| Step: 2
Training loss: 2.728774070739746
Validation loss: 2.2488874286733647

Epoch: 6| Step: 3
Training loss: 2.509434223175049
Validation loss: 2.2526964231203963

Epoch: 6| Step: 4
Training loss: 2.2107162475585938
Validation loss: 2.291403808901387

Epoch: 6| Step: 5
Training loss: 2.4088497161865234
Validation loss: 2.3307175661927912

Epoch: 6| Step: 6
Training loss: 2.7524161338806152
Validation loss: 2.353274496652747

Epoch: 6| Step: 7
Training loss: 1.8520121574401855
Validation loss: 2.404470371943648

Epoch: 6| Step: 8
Training loss: 2.414623975753784
Validation loss: 2.392092607354605

Epoch: 6| Step: 9
Training loss: 2.649787425994873
Validation loss: 2.3238537593554427

Epoch: 6| Step: 10
Training loss: 2.407193660736084
Validation loss: 2.286189984249812

Epoch: 6| Step: 11
Training loss: 2.5941593647003174
Validation loss: 2.247572252827306

Epoch: 6| Step: 12
Training loss: 2.899216890335083
Validation loss: 2.2429053885962373

Epoch: 6| Step: 13
Training loss: 2.7763707637786865
Validation loss: 2.2360679308573403

Epoch: 82| Step: 0
Training loss: 2.291346549987793
Validation loss: 2.243755348267094

Epoch: 6| Step: 1
Training loss: 3.128934860229492
Validation loss: 2.236373462984639

Epoch: 6| Step: 2
Training loss: 2.104771614074707
Validation loss: 2.2455122086309616

Epoch: 6| Step: 3
Training loss: 1.684908390045166
Validation loss: 2.239393993090558

Epoch: 6| Step: 4
Training loss: 2.6186141967773438
Validation loss: 2.2369263184967862

Epoch: 6| Step: 5
Training loss: 2.2208352088928223
Validation loss: 2.2330951844492266

Epoch: 6| Step: 6
Training loss: 2.498478412628174
Validation loss: 2.2381895511381087

Epoch: 6| Step: 7
Training loss: 2.1378350257873535
Validation loss: 2.235701168737104

Epoch: 6| Step: 8
Training loss: 2.962399482727051
Validation loss: 2.2443333159210863

Epoch: 6| Step: 9
Training loss: 2.9529757499694824
Validation loss: 2.2413031106354087

Epoch: 6| Step: 10
Training loss: 2.514031410217285
Validation loss: 2.2542108463984665

Epoch: 6| Step: 11
Training loss: 2.695758819580078
Validation loss: 2.2632316543209936

Epoch: 6| Step: 12
Training loss: 2.9013657569885254
Validation loss: 2.265813576277866

Epoch: 6| Step: 13
Training loss: 2.576887369155884
Validation loss: 2.2821937094452562

Epoch: 83| Step: 0
Training loss: 2.1091389656066895
Validation loss: 2.271403608783599

Epoch: 6| Step: 1
Training loss: 2.32277250289917
Validation loss: 2.280954848053635

Epoch: 6| Step: 2
Training loss: 2.72856068611145
Validation loss: 2.29408827904732

Epoch: 6| Step: 3
Training loss: 2.894974946975708
Validation loss: 2.296786108324605

Epoch: 6| Step: 4
Training loss: 2.711305618286133
Validation loss: 2.2749389140836653

Epoch: 6| Step: 5
Training loss: 2.9590344429016113
Validation loss: 2.254333665294032

Epoch: 6| Step: 6
Training loss: 2.5081381797790527
Validation loss: 2.2454652350435973

Epoch: 6| Step: 7
Training loss: 2.6594791412353516
Validation loss: 2.233607335757184

Epoch: 6| Step: 8
Training loss: 1.9993784427642822
Validation loss: 2.222438943001532

Epoch: 6| Step: 9
Training loss: 3.040950298309326
Validation loss: 2.2184654589622252

Epoch: 6| Step: 10
Training loss: 2.2990946769714355
Validation loss: 2.217386407236899

Epoch: 6| Step: 11
Training loss: 1.9168614149093628
Validation loss: 2.229233349523237

Epoch: 6| Step: 12
Training loss: 2.6800124645233154
Validation loss: 2.2427637551420476

Epoch: 6| Step: 13
Training loss: 2.1094510555267334
Validation loss: 2.2596570394372426

Epoch: 84| Step: 0
Training loss: 1.97622549533844
Validation loss: 2.2711038128022225

Epoch: 6| Step: 1
Training loss: 2.287436008453369
Validation loss: 2.252467493857107

Epoch: 6| Step: 2
Training loss: 3.028489112854004
Validation loss: 2.23156330790571

Epoch: 6| Step: 3
Training loss: 1.9710676670074463
Validation loss: 2.2174959246830275

Epoch: 6| Step: 4
Training loss: 2.0416197776794434
Validation loss: 2.2136316414802306

Epoch: 6| Step: 5
Training loss: 2.660761833190918
Validation loss: 2.218299162003302

Epoch: 6| Step: 6
Training loss: 3.2818803787231445
Validation loss: 2.222457811396609

Epoch: 6| Step: 7
Training loss: 3.1450135707855225
Validation loss: 2.2239356143500215

Epoch: 6| Step: 8
Training loss: 2.7634263038635254
Validation loss: 2.2286949849897817

Epoch: 6| Step: 9
Training loss: 2.7947046756744385
Validation loss: 2.2283168326142015

Epoch: 6| Step: 10
Training loss: 2.3952279090881348
Validation loss: 2.247798631268163

Epoch: 6| Step: 11
Training loss: 2.2362866401672363
Validation loss: 2.259345995482578

Epoch: 6| Step: 12
Training loss: 1.9916589260101318
Validation loss: 2.3170218518985215

Epoch: 6| Step: 13
Training loss: 2.80369234085083
Validation loss: 2.354138089764503

Epoch: 85| Step: 0
Training loss: 2.5042853355407715
Validation loss: 2.3311271821298907

Epoch: 6| Step: 1
Training loss: 2.5177576541900635
Validation loss: 2.2741823170774724

Epoch: 6| Step: 2
Training loss: 2.414280414581299
Validation loss: 2.2506378773720033

Epoch: 6| Step: 3
Training loss: 2.6132709980010986
Validation loss: 2.228567579741119

Epoch: 6| Step: 4
Training loss: 2.310343027114868
Validation loss: 2.209973548048286

Epoch: 6| Step: 5
Training loss: 2.625875473022461
Validation loss: 2.220157987327986

Epoch: 6| Step: 6
Training loss: 2.6319289207458496
Validation loss: 2.2092973955215944

Epoch: 6| Step: 7
Training loss: 3.003480911254883
Validation loss: 2.2191922639005925

Epoch: 6| Step: 8
Training loss: 2.6772327423095703
Validation loss: 2.213472636797095

Epoch: 6| Step: 9
Training loss: 2.1358978748321533
Validation loss: 2.207765781751243

Epoch: 6| Step: 10
Training loss: 2.1126925945281982
Validation loss: 2.209712892450312

Epoch: 6| Step: 11
Training loss: 2.943525791168213
Validation loss: 2.212943882070562

Epoch: 6| Step: 12
Training loss: 2.4767351150512695
Validation loss: 2.242618530027328

Epoch: 6| Step: 13
Training loss: 1.7783870697021484
Validation loss: 2.281859299188019

Epoch: 86| Step: 0
Training loss: 2.7758052349090576
Validation loss: 2.317510535640101

Epoch: 6| Step: 1
Training loss: 1.660973310470581
Validation loss: 2.361744137220485

Epoch: 6| Step: 2
Training loss: 1.9139015674591064
Validation loss: 2.363312005996704

Epoch: 6| Step: 3
Training loss: 2.638765573501587
Validation loss: 2.359187731178858

Epoch: 6| Step: 4
Training loss: 2.533515691757202
Validation loss: 2.3305182508243028

Epoch: 6| Step: 5
Training loss: 2.4902570247650146
Validation loss: 2.286672748545165

Epoch: 6| Step: 6
Training loss: 2.6239633560180664
Validation loss: 2.2570555927932903

Epoch: 6| Step: 7
Training loss: 2.0590853691101074
Validation loss: 2.250903937124437

Epoch: 6| Step: 8
Training loss: 2.717013359069824
Validation loss: 2.2473979996096705

Epoch: 6| Step: 9
Training loss: 2.7236030101776123
Validation loss: 2.242922507306581

Epoch: 6| Step: 10
Training loss: 2.6313600540161133
Validation loss: 2.236602093583794

Epoch: 6| Step: 11
Training loss: 3.11214542388916
Validation loss: 2.2262936702338596

Epoch: 6| Step: 12
Training loss: 3.0029220581054688
Validation loss: 2.235695492836737

Epoch: 6| Step: 13
Training loss: 1.8452614545822144
Validation loss: 2.2621633365590084

Epoch: 87| Step: 0
Training loss: 2.603259563446045
Validation loss: 2.294377537183864

Epoch: 6| Step: 1
Training loss: 2.393718957901001
Validation loss: 2.336346798045661

Epoch: 6| Step: 2
Training loss: 2.161562919616699
Validation loss: 2.345303243206393

Epoch: 6| Step: 3
Training loss: 2.727881669998169
Validation loss: 2.3124966800853772

Epoch: 6| Step: 4
Training loss: 2.9451916217803955
Validation loss: 2.305914835263324

Epoch: 6| Step: 5
Training loss: 2.4080421924591064
Validation loss: 2.261661453913617

Epoch: 6| Step: 6
Training loss: 1.9022170305252075
Validation loss: 2.245271603266398

Epoch: 6| Step: 7
Training loss: 1.9263335466384888
Validation loss: 2.232885786282119

Epoch: 6| Step: 8
Training loss: 2.57588529586792
Validation loss: 2.2233388962284213

Epoch: 6| Step: 9
Training loss: 2.3507914543151855
Validation loss: 2.20708357134173

Epoch: 6| Step: 10
Training loss: 2.921633243560791
Validation loss: 2.2106898036054385

Epoch: 6| Step: 11
Training loss: 2.987614154815674
Validation loss: 2.2059632924295243

Epoch: 6| Step: 12
Training loss: 2.476003646850586
Validation loss: 2.198058061702277

Epoch: 6| Step: 13
Training loss: 2.739755868911743
Validation loss: 2.1990276716088735

Epoch: 88| Step: 0
Training loss: 2.1010568141937256
Validation loss: 2.196018212585039

Epoch: 6| Step: 1
Training loss: 1.8183236122131348
Validation loss: 2.194958168973205

Epoch: 6| Step: 2
Training loss: 2.710705041885376
Validation loss: 2.192133311302431

Epoch: 6| Step: 3
Training loss: 2.142815113067627
Validation loss: 2.184978785053376

Epoch: 6| Step: 4
Training loss: 2.521862030029297
Validation loss: 2.1976151056187128

Epoch: 6| Step: 5
Training loss: 2.2159366607666016
Validation loss: 2.206093067763954

Epoch: 6| Step: 6
Training loss: 2.3136980533599854
Validation loss: 2.221376685686009

Epoch: 6| Step: 7
Training loss: 3.4032440185546875
Validation loss: 2.235336531874954

Epoch: 6| Step: 8
Training loss: 3.0136032104492188
Validation loss: 2.2294457599680912

Epoch: 6| Step: 9
Training loss: 2.1655850410461426
Validation loss: 2.2008192769942747

Epoch: 6| Step: 10
Training loss: 2.4491424560546875
Validation loss: 2.1953329783613964

Epoch: 6| Step: 11
Training loss: 1.8763189315795898
Validation loss: 2.189443826675415

Epoch: 6| Step: 12
Training loss: 2.8178114891052246
Validation loss: 2.185620733486709

Epoch: 6| Step: 13
Training loss: 3.4283223152160645
Validation loss: 2.177592437754395

Epoch: 89| Step: 0
Training loss: 2.288893699645996
Validation loss: 2.1797109752572994

Epoch: 6| Step: 1
Training loss: 2.473240852355957
Validation loss: 2.178780132724393

Epoch: 6| Step: 2
Training loss: 1.9931316375732422
Validation loss: 2.197263538196523

Epoch: 6| Step: 3
Training loss: 2.8386597633361816
Validation loss: 2.222223657433705

Epoch: 6| Step: 4
Training loss: 2.3348782062530518
Validation loss: 2.216943604971773

Epoch: 6| Step: 5
Training loss: 2.60318660736084
Validation loss: 2.2107021680442234

Epoch: 6| Step: 6
Training loss: 2.0274922847747803
Validation loss: 2.1969125681026007

Epoch: 6| Step: 7
Training loss: 2.311648368835449
Validation loss: 2.1866367299069642

Epoch: 6| Step: 8
Training loss: 2.436850070953369
Validation loss: 2.1896017495022027

Epoch: 6| Step: 9
Training loss: 1.9149316549301147
Validation loss: 2.1795719938893474

Epoch: 6| Step: 10
Training loss: 3.0528926849365234
Validation loss: 2.1917333013267926

Epoch: 6| Step: 11
Training loss: 2.553171396255493
Validation loss: 2.189631054478307

Epoch: 6| Step: 12
Training loss: 3.144925355911255
Validation loss: 2.1856229100176083

Epoch: 6| Step: 13
Training loss: 2.687631607055664
Validation loss: 2.187860063327256

Epoch: 90| Step: 0
Training loss: 2.6686344146728516
Validation loss: 2.1916936571880052

Epoch: 6| Step: 1
Training loss: 2.6118874549865723
Validation loss: 2.2198548906592914

Epoch: 6| Step: 2
Training loss: 3.2777905464172363
Validation loss: 2.2296457213740193

Epoch: 6| Step: 3
Training loss: 2.1767029762268066
Validation loss: 2.205075410104567

Epoch: 6| Step: 4
Training loss: 2.5253076553344727
Validation loss: 2.1927624107688986

Epoch: 6| Step: 5
Training loss: 2.1348934173583984
Validation loss: 2.171121422962476

Epoch: 6| Step: 6
Training loss: 2.297999858856201
Validation loss: 2.1675310045160274

Epoch: 6| Step: 7
Training loss: 2.4497859477996826
Validation loss: 2.1697947350881432

Epoch: 6| Step: 8
Training loss: 2.8261477947235107
Validation loss: 2.1685457152705037

Epoch: 6| Step: 9
Training loss: 2.4499902725219727
Validation loss: 2.170533662201256

Epoch: 6| Step: 10
Training loss: 2.1666107177734375
Validation loss: 2.1707123735899567

Epoch: 6| Step: 11
Training loss: 2.424968957901001
Validation loss: 2.1839378879916285

Epoch: 6| Step: 12
Training loss: 2.4490914344787598
Validation loss: 2.2273869591374553

Epoch: 6| Step: 13
Training loss: 1.5908827781677246
Validation loss: 2.241871274927611

Epoch: 91| Step: 0
Training loss: 2.7050986289978027
Validation loss: 2.228769031904077

Epoch: 6| Step: 1
Training loss: 3.264254093170166
Validation loss: 2.2378671169281006

Epoch: 6| Step: 2
Training loss: 1.9131050109863281
Validation loss: 2.225434882666475

Epoch: 6| Step: 3
Training loss: 2.7358486652374268
Validation loss: 2.2003373740821757

Epoch: 6| Step: 4
Training loss: 2.411288261413574
Validation loss: 2.178412031101924

Epoch: 6| Step: 5
Training loss: 2.6576924324035645
Validation loss: 2.16943323099485

Epoch: 6| Step: 6
Training loss: 2.5783581733703613
Validation loss: 2.172576947878766

Epoch: 6| Step: 7
Training loss: 2.479809284210205
Validation loss: 2.166081948946881

Epoch: 6| Step: 8
Training loss: 2.1569161415100098
Validation loss: 2.169275455577399

Epoch: 6| Step: 9
Training loss: 2.3466200828552246
Validation loss: 2.159714311681768

Epoch: 6| Step: 10
Training loss: 1.295936942100525
Validation loss: 2.1686486992784726

Epoch: 6| Step: 11
Training loss: 2.382934331893921
Validation loss: 2.1961607522861932

Epoch: 6| Step: 12
Training loss: 2.6366405487060547
Validation loss: 2.225083512644614

Epoch: 6| Step: 13
Training loss: 3.3377702236175537
Validation loss: 2.255777665363845

Epoch: 92| Step: 0
Training loss: 2.5816221237182617
Validation loss: 2.305521370262228

Epoch: 6| Step: 1
Training loss: 2.9674735069274902
Validation loss: 2.3186954887964393

Epoch: 6| Step: 2
Training loss: 2.4806606769561768
Validation loss: 2.2723352588633055

Epoch: 6| Step: 3
Training loss: 3.2298455238342285
Validation loss: 2.2144789003556773

Epoch: 6| Step: 4
Training loss: 2.1671078205108643
Validation loss: 2.1733149918176795

Epoch: 6| Step: 5
Training loss: 2.074305295944214
Validation loss: 2.167362830972159

Epoch: 6| Step: 6
Training loss: 2.0571300983428955
Validation loss: 2.1725694594844693

Epoch: 6| Step: 7
Training loss: 1.9980823993682861
Validation loss: 2.1837183634440103

Epoch: 6| Step: 8
Training loss: 2.4101741313934326
Validation loss: 2.174940586090088

Epoch: 6| Step: 9
Training loss: 2.539191246032715
Validation loss: 2.166257148147911

Epoch: 6| Step: 10
Training loss: 2.6950418949127197
Validation loss: 2.1705805409339165

Epoch: 6| Step: 11
Training loss: 2.199890613555908
Validation loss: 2.178012737663843

Epoch: 6| Step: 12
Training loss: 2.5541794300079346
Validation loss: 2.19305012559378

Epoch: 6| Step: 13
Training loss: 2.88266921043396
Validation loss: 2.1975939402016262

Epoch: 93| Step: 0
Training loss: 2.499739646911621
Validation loss: 2.246799002411545

Epoch: 6| Step: 1
Training loss: 2.8421332836151123
Validation loss: 2.2857804695765176

Epoch: 6| Step: 2
Training loss: 2.304561138153076
Validation loss: 2.298838746163153

Epoch: 6| Step: 3
Training loss: 1.5398896932601929
Validation loss: 2.315756631153886

Epoch: 6| Step: 4
Training loss: 2.0630688667297363
Validation loss: 2.3095441326018302

Epoch: 6| Step: 5
Training loss: 2.8017499446868896
Validation loss: 2.3015902990935952

Epoch: 6| Step: 6
Training loss: 2.4561569690704346
Validation loss: 2.249764221970753

Epoch: 6| Step: 7
Training loss: 2.7092926502227783
Validation loss: 2.2060635089874268

Epoch: 6| Step: 8
Training loss: 2.7077109813690186
Validation loss: 2.1946946908068914

Epoch: 6| Step: 9
Training loss: 1.9459621906280518
Validation loss: 2.172896389038332

Epoch: 6| Step: 10
Training loss: 2.637754440307617
Validation loss: 2.1745390815119587

Epoch: 6| Step: 11
Training loss: 2.84881854057312
Validation loss: 2.1661176835336993

Epoch: 6| Step: 12
Training loss: 2.409656047821045
Validation loss: 2.1693987974556546

Epoch: 6| Step: 13
Training loss: 2.8311195373535156
Validation loss: 2.1715947902330788

Epoch: 94| Step: 0
Training loss: 2.8397133350372314
Validation loss: 2.1749079970903296

Epoch: 6| Step: 1
Training loss: 2.225991725921631
Validation loss: 2.1781075308399815

Epoch: 6| Step: 2
Training loss: 2.782545566558838
Validation loss: 2.181323560335303

Epoch: 6| Step: 3
Training loss: 2.657090187072754
Validation loss: 2.1808176207286056

Epoch: 6| Step: 4
Training loss: 2.5765633583068848
Validation loss: 2.1777389523803548

Epoch: 6| Step: 5
Training loss: 2.0131659507751465
Validation loss: 2.185606151498774

Epoch: 6| Step: 6
Training loss: 2.435565948486328
Validation loss: 2.1909087422073528

Epoch: 6| Step: 7
Training loss: 1.449852466583252
Validation loss: 2.1671360795215895

Epoch: 6| Step: 8
Training loss: 2.0442943572998047
Validation loss: 2.1573786043351695

Epoch: 6| Step: 9
Training loss: 2.9406933784484863
Validation loss: 2.1467134862817745

Epoch: 6| Step: 10
Training loss: 1.9863866567611694
Validation loss: 2.1492094211680914

Epoch: 6| Step: 11
Training loss: 1.9287463426589966
Validation loss: 2.1458400141808296

Epoch: 6| Step: 12
Training loss: 3.731649398803711
Validation loss: 2.154970976614183

Epoch: 6| Step: 13
Training loss: 2.411804437637329
Validation loss: 2.145170627101775

Epoch: 95| Step: 0
Training loss: 2.7194995880126953
Validation loss: 2.1515814540206746

Epoch: 6| Step: 1
Training loss: 2.6845781803131104
Validation loss: 2.1561205528115712

Epoch: 6| Step: 2
Training loss: 2.85304594039917
Validation loss: 2.1464091013836604

Epoch: 6| Step: 3
Training loss: 2.376901626586914
Validation loss: 2.157265470873925

Epoch: 6| Step: 4
Training loss: 2.7546255588531494
Validation loss: 2.1540049096589446

Epoch: 6| Step: 5
Training loss: 2.2410573959350586
Validation loss: 2.1519941129992084

Epoch: 6| Step: 6
Training loss: 2.1434390544891357
Validation loss: 2.152140535334105

Epoch: 6| Step: 7
Training loss: 2.448561191558838
Validation loss: 2.149502695247691

Epoch: 6| Step: 8
Training loss: 1.8474678993225098
Validation loss: 2.1508609864019577

Epoch: 6| Step: 9
Training loss: 2.748781204223633
Validation loss: 2.1538878230638403

Epoch: 6| Step: 10
Training loss: 2.7589774131774902
Validation loss: 2.1515305554994972

Epoch: 6| Step: 11
Training loss: 1.8875610828399658
Validation loss: 2.158633747408467

Epoch: 6| Step: 12
Training loss: 2.293121099472046
Validation loss: 2.1608749743430846

Epoch: 6| Step: 13
Training loss: 1.7961649894714355
Validation loss: 2.168919499202441

Epoch: 96| Step: 0
Training loss: 2.3108110427856445
Validation loss: 2.1627518925615536

Epoch: 6| Step: 1
Training loss: 2.251694440841675
Validation loss: 2.1591160220484578

Epoch: 6| Step: 2
Training loss: 3.2057766914367676
Validation loss: 2.1488161522855043

Epoch: 6| Step: 3
Training loss: 2.8946895599365234
Validation loss: 2.1489911745953303

Epoch: 6| Step: 4
Training loss: 2.0891566276550293
Validation loss: 2.1430471943270777

Epoch: 6| Step: 5
Training loss: 2.6560630798339844
Validation loss: 2.14307334346156

Epoch: 6| Step: 6
Training loss: 2.4264633655548096
Validation loss: 2.1419540477055374

Epoch: 6| Step: 7
Training loss: 1.8389371633529663
Validation loss: 2.138587890132781

Epoch: 6| Step: 8
Training loss: 2.3665452003479004
Validation loss: 2.1373129967720277

Epoch: 6| Step: 9
Training loss: 2.361159324645996
Validation loss: 2.133940477525034

Epoch: 6| Step: 10
Training loss: 2.2650132179260254
Validation loss: 2.1358332082789433

Epoch: 6| Step: 11
Training loss: 2.0657858848571777
Validation loss: 2.1455159956409084

Epoch: 6| Step: 12
Training loss: 2.4112915992736816
Validation loss: 2.1433903478807017

Epoch: 6| Step: 13
Training loss: 2.8798325061798096
Validation loss: 2.156695253105574

Epoch: 97| Step: 0
Training loss: 1.8215365409851074
Validation loss: 2.1557830123491186

Epoch: 6| Step: 1
Training loss: 2.573613405227661
Validation loss: 2.1515060752950688

Epoch: 6| Step: 2
Training loss: 2.331908702850342
Validation loss: 2.1552374388581965

Epoch: 6| Step: 3
Training loss: 3.0680644512176514
Validation loss: 2.154694563599043

Epoch: 6| Step: 4
Training loss: 1.8575847148895264
Validation loss: 2.156242416751

Epoch: 6| Step: 5
Training loss: 2.9056999683380127
Validation loss: 2.1470154562304096

Epoch: 6| Step: 6
Training loss: 2.199937105178833
Validation loss: 2.1379105429495535

Epoch: 6| Step: 7
Training loss: 3.218118190765381
Validation loss: 2.135561284198556

Epoch: 6| Step: 8
Training loss: 2.0522029399871826
Validation loss: 2.1393332712111937

Epoch: 6| Step: 9
Training loss: 1.9560043811798096
Validation loss: 2.127035710119432

Epoch: 6| Step: 10
Training loss: 2.676746368408203
Validation loss: 2.129287019852669

Epoch: 6| Step: 11
Training loss: 2.345130443572998
Validation loss: 2.1283616301833943

Epoch: 6| Step: 12
Training loss: 2.4007668495178223
Validation loss: 2.1301803306866716

Epoch: 6| Step: 13
Training loss: 1.8927552700042725
Validation loss: 2.144223783605842

Epoch: 98| Step: 0
Training loss: 2.600743532180786
Validation loss: 2.165741423124908

Epoch: 6| Step: 1
Training loss: 2.053750514984131
Validation loss: 2.177247924189414

Epoch: 6| Step: 2
Training loss: 2.835660457611084
Validation loss: 2.188268456407773

Epoch: 6| Step: 3
Training loss: 2.868065595626831
Validation loss: 2.1857166572283675

Epoch: 6| Step: 4
Training loss: 2.745126724243164
Validation loss: 2.1552608730972453

Epoch: 6| Step: 5
Training loss: 2.0537476539611816
Validation loss: 2.125798950913132

Epoch: 6| Step: 6
Training loss: 2.267953395843506
Validation loss: 2.1300977853036698

Epoch: 6| Step: 7
Training loss: 1.8612960577011108
Validation loss: 2.1227209824387745

Epoch: 6| Step: 8
Training loss: 2.4318928718566895
Validation loss: 2.127111368281867

Epoch: 6| Step: 9
Training loss: 2.383387804031372
Validation loss: 2.1304371972237863

Epoch: 6| Step: 10
Training loss: 2.69606351852417
Validation loss: 2.1476037963744132

Epoch: 6| Step: 11
Training loss: 2.4504096508026123
Validation loss: 2.144261848541998

Epoch: 6| Step: 12
Training loss: 2.259387493133545
Validation loss: 2.1562536557515464

Epoch: 6| Step: 13
Training loss: 2.295212745666504
Validation loss: 2.1514156377443703

Epoch: 99| Step: 0
Training loss: 3.0784621238708496
Validation loss: 2.1333572274895123

Epoch: 6| Step: 1
Training loss: 2.2212867736816406
Validation loss: 2.1299920697366037

Epoch: 6| Step: 2
Training loss: 2.1777875423431396
Validation loss: 2.1283023870119484

Epoch: 6| Step: 3
Training loss: 2.3805084228515625
Validation loss: 2.1299469547887004

Epoch: 6| Step: 4
Training loss: 2.3966379165649414
Validation loss: 2.1410311140039915

Epoch: 6| Step: 5
Training loss: 2.59414005279541
Validation loss: 2.137431420305724

Epoch: 6| Step: 6
Training loss: 2.321226119995117
Validation loss: 2.1334182293184343

Epoch: 6| Step: 7
Training loss: 2.1522083282470703
Validation loss: 2.1422109526972615

Epoch: 6| Step: 8
Training loss: 2.2810959815979004
Validation loss: 2.135564106766896

Epoch: 6| Step: 9
Training loss: 1.6815757751464844
Validation loss: 2.1330744451092136

Epoch: 6| Step: 10
Training loss: 2.4038968086242676
Validation loss: 2.1168045664346344

Epoch: 6| Step: 11
Training loss: 2.114419937133789
Validation loss: 2.118941032758323

Epoch: 6| Step: 12
Training loss: 2.724221706390381
Validation loss: 2.1279129161629626

Epoch: 6| Step: 13
Training loss: 3.334324836730957
Validation loss: 2.1233420397645686

Epoch: 100| Step: 0
Training loss: 2.319312572479248
Validation loss: 2.1193033161983696

Epoch: 6| Step: 1
Training loss: 1.568009853363037
Validation loss: 2.120044240387537

Epoch: 6| Step: 2
Training loss: 2.3430120944976807
Validation loss: 2.1265252790143414

Epoch: 6| Step: 3
Training loss: 2.168272018432617
Validation loss: 2.116062036124609

Epoch: 6| Step: 4
Training loss: 2.5347681045532227
Validation loss: 2.1193361218257616

Epoch: 6| Step: 5
Training loss: 2.2087509632110596
Validation loss: 2.118854720105407

Epoch: 6| Step: 6
Training loss: 1.9004945755004883
Validation loss: 2.1160052796845794

Epoch: 6| Step: 7
Training loss: 2.1954593658447266
Validation loss: 2.117229107887514

Epoch: 6| Step: 8
Training loss: 2.905942916870117
Validation loss: 2.132384387395715

Epoch: 6| Step: 9
Training loss: 2.593902111053467
Validation loss: 2.148091362368676

Epoch: 6| Step: 10
Training loss: 2.6831135749816895
Validation loss: 2.185036818186442

Epoch: 6| Step: 11
Training loss: 3.0327882766723633
Validation loss: 2.1977386525882188

Epoch: 6| Step: 12
Training loss: 2.2351491451263428
Validation loss: 2.183865471552777

Epoch: 6| Step: 13
Training loss: 2.916962146759033
Validation loss: 2.171557218797745

Epoch: 101| Step: 0
Training loss: 2.5192158222198486
Validation loss: 2.1480678255840013

Epoch: 6| Step: 1
Training loss: 2.2743124961853027
Validation loss: 2.1260711582758094

Epoch: 6| Step: 2
Training loss: 2.43239164352417
Validation loss: 2.1058469959484634

Epoch: 6| Step: 3
Training loss: 2.4405550956726074
Validation loss: 2.0997198538113664

Epoch: 6| Step: 4
Training loss: 2.4966959953308105
Validation loss: 2.1014396657225904

Epoch: 6| Step: 5
Training loss: 2.215847969055176
Validation loss: 2.1058894870101765

Epoch: 6| Step: 6
Training loss: 2.4924044609069824
Validation loss: 2.1052892592645462

Epoch: 6| Step: 7
Training loss: 1.7026135921478271
Validation loss: 2.103733533172197

Epoch: 6| Step: 8
Training loss: 2.2576375007629395
Validation loss: 2.1211091138983287

Epoch: 6| Step: 9
Training loss: 2.454068422317505
Validation loss: 2.1277911611782607

Epoch: 6| Step: 10
Training loss: 2.916952610015869
Validation loss: 2.1376353310000513

Epoch: 6| Step: 11
Training loss: 2.2043778896331787
Validation loss: 2.1231989193988103

Epoch: 6| Step: 12
Training loss: 2.308164596557617
Validation loss: 2.1118531637294318

Epoch: 6| Step: 13
Training loss: 2.529676914215088
Validation loss: 2.097674113447948

Epoch: 102| Step: 0
Training loss: 2.846144676208496
Validation loss: 2.106791136085346

Epoch: 6| Step: 1
Training loss: 3.207709789276123
Validation loss: 2.1095102102525773

Epoch: 6| Step: 2
Training loss: 2.400952100753784
Validation loss: 2.1076846302196546

Epoch: 6| Step: 3
Training loss: 2.4981799125671387
Validation loss: 2.112955101074711

Epoch: 6| Step: 4
Training loss: 1.4741671085357666
Validation loss: 2.108244438325205

Epoch: 6| Step: 5
Training loss: 1.9444788694381714
Validation loss: 2.1047024162866736

Epoch: 6| Step: 6
Training loss: 1.8620123863220215
Validation loss: 2.1040913135774675

Epoch: 6| Step: 7
Training loss: 2.2326884269714355
Validation loss: 2.114038259752335

Epoch: 6| Step: 8
Training loss: 3.0612099170684814
Validation loss: 2.1130958872456707

Epoch: 6| Step: 9
Training loss: 1.7732205390930176
Validation loss: 2.1102537032096618

Epoch: 6| Step: 10
Training loss: 2.247265100479126
Validation loss: 2.1072205779373006

Epoch: 6| Step: 11
Training loss: 2.5051817893981934
Validation loss: 2.1026179213677683

Epoch: 6| Step: 12
Training loss: 2.7062740325927734
Validation loss: 2.120983385270642

Epoch: 6| Step: 13
Training loss: 2.0999960899353027
Validation loss: 2.140981007647771

Epoch: 103| Step: 0
Training loss: 2.35835337638855
Validation loss: 2.180261032555693

Epoch: 6| Step: 1
Training loss: 2.179488182067871
Validation loss: 2.209243356540639

Epoch: 6| Step: 2
Training loss: 1.0284557342529297
Validation loss: 2.2257331058543217

Epoch: 6| Step: 3
Training loss: 2.400954246520996
Validation loss: 2.198168821232293

Epoch: 6| Step: 4
Training loss: 2.5418012142181396
Validation loss: 2.2036523613878476

Epoch: 6| Step: 5
Training loss: 2.5585594177246094
Validation loss: 2.179122301840013

Epoch: 6| Step: 6
Training loss: 2.6127359867095947
Validation loss: 2.14152318046939

Epoch: 6| Step: 7
Training loss: 2.0313613414764404
Validation loss: 2.103081541676675

Epoch: 6| Step: 8
Training loss: 2.438028335571289
Validation loss: 2.1042993850605463

Epoch: 6| Step: 9
Training loss: 2.9493179321289062
Validation loss: 2.119887962136217

Epoch: 6| Step: 10
Training loss: 2.4704408645629883
Validation loss: 2.1178880558219007

Epoch: 6| Step: 11
Training loss: 2.4208617210388184
Validation loss: 2.107980376930647

Epoch: 6| Step: 12
Training loss: 2.8628523349761963
Validation loss: 2.0925488151529783

Epoch: 6| Step: 13
Training loss: 3.3118460178375244
Validation loss: 2.098309555361348

Epoch: 104| Step: 0
Training loss: 2.0825881958007812
Validation loss: 2.1003529769118114

Epoch: 6| Step: 1
Training loss: 2.3529956340789795
Validation loss: 2.121644463590396

Epoch: 6| Step: 2
Training loss: 2.742722511291504
Validation loss: 2.1179722983350038

Epoch: 6| Step: 3
Training loss: 1.7224106788635254
Validation loss: 2.1103928858234036

Epoch: 6| Step: 4
Training loss: 1.7872774600982666
Validation loss: 2.098320327779298

Epoch: 6| Step: 5
Training loss: 2.3944382667541504
Validation loss: 2.097092910479474

Epoch: 6| Step: 6
Training loss: 2.783018112182617
Validation loss: 2.0930101204943914

Epoch: 6| Step: 7
Training loss: 2.371798038482666
Validation loss: 2.0911914917730514

Epoch: 6| Step: 8
Training loss: 2.733715057373047
Validation loss: 2.0978502996506228

Epoch: 6| Step: 9
Training loss: 2.6349213123321533
Validation loss: 2.1140463531658216

Epoch: 6| Step: 10
Training loss: 2.355876922607422
Validation loss: 2.1230395968242357

Epoch: 6| Step: 11
Training loss: 2.5897092819213867
Validation loss: 2.1074982894364225

Epoch: 6| Step: 12
Training loss: 2.136932373046875
Validation loss: 2.104032257551788

Epoch: 6| Step: 13
Training loss: 2.222240447998047
Validation loss: 2.1006183547358357

Epoch: 105| Step: 0
Training loss: 2.2430214881896973
Validation loss: 2.108466315013106

Epoch: 6| Step: 1
Training loss: 2.14627742767334
Validation loss: 2.1071157814354025

Epoch: 6| Step: 2
Training loss: 2.3932607173919678
Validation loss: 2.1163001521941154

Epoch: 6| Step: 3
Training loss: 2.7165331840515137
Validation loss: 2.108739911869008

Epoch: 6| Step: 4
Training loss: 2.7954583168029785
Validation loss: 2.1031315147235827

Epoch: 6| Step: 5
Training loss: 2.3585526943206787
Validation loss: 2.099392565347815

Epoch: 6| Step: 6
Training loss: 2.12192702293396
Validation loss: 2.087255331777757

Epoch: 6| Step: 7
Training loss: 2.759589433670044
Validation loss: 2.077410258272643

Epoch: 6| Step: 8
Training loss: 2.169671058654785
Validation loss: 2.0761193178033315

Epoch: 6| Step: 9
Training loss: 2.6044726371765137
Validation loss: 2.083767011601438

Epoch: 6| Step: 10
Training loss: 2.5470314025878906
Validation loss: 2.0770006871992543

Epoch: 6| Step: 11
Training loss: 1.4869461059570312
Validation loss: 2.087529300361551

Epoch: 6| Step: 12
Training loss: 2.3918447494506836
Validation loss: 2.1143600248521373

Epoch: 6| Step: 13
Training loss: 2.353351593017578
Validation loss: 2.1140553335989676

Epoch: 106| Step: 0
Training loss: 1.9723018407821655
Validation loss: 2.1045078000714703

Epoch: 6| Step: 1
Training loss: 2.279996156692505
Validation loss: 2.0971420682886595

Epoch: 6| Step: 2
Training loss: 2.1324920654296875
Validation loss: 2.0933831814796693

Epoch: 6| Step: 3
Training loss: 1.495316982269287
Validation loss: 2.1054809836931128

Epoch: 6| Step: 4
Training loss: 1.6123995780944824
Validation loss: 2.0915648783406904

Epoch: 6| Step: 5
Training loss: 2.4908409118652344
Validation loss: 2.0845453610984226

Epoch: 6| Step: 6
Training loss: 2.93334698677063
Validation loss: 2.0742496136696107

Epoch: 6| Step: 7
Training loss: 2.1081290245056152
Validation loss: 2.0789025240047003

Epoch: 6| Step: 8
Training loss: 2.2132763862609863
Validation loss: 2.081030589278026

Epoch: 6| Step: 9
Training loss: 2.57479190826416
Validation loss: 2.0765165385379585

Epoch: 6| Step: 10
Training loss: 2.713878631591797
Validation loss: 2.084296340583473

Epoch: 6| Step: 11
Training loss: 3.2477827072143555
Validation loss: 2.1183529387238207

Epoch: 6| Step: 12
Training loss: 2.04154634475708
Validation loss: 2.1321668445423083

Epoch: 6| Step: 13
Training loss: 3.59871506690979
Validation loss: 2.1723523909045803

Epoch: 107| Step: 0
Training loss: 2.6329681873321533
Validation loss: 2.185048741679038

Epoch: 6| Step: 1
Training loss: 3.100253105163574
Validation loss: 2.176820038467325

Epoch: 6| Step: 2
Training loss: 1.7232016324996948
Validation loss: 2.1371219119718

Epoch: 6| Step: 3
Training loss: 2.567814350128174
Validation loss: 2.100944247297061

Epoch: 6| Step: 4
Training loss: 2.0338711738586426
Validation loss: 2.0881036404640443

Epoch: 6| Step: 5
Training loss: 2.5927982330322266
Validation loss: 2.0701093840342697

Epoch: 6| Step: 6
Training loss: 2.443398952484131
Validation loss: 2.0750221847206034

Epoch: 6| Step: 7
Training loss: 2.018867015838623
Validation loss: 2.081016384145265

Epoch: 6| Step: 8
Training loss: 2.2031302452087402
Validation loss: 2.093826542618454

Epoch: 6| Step: 9
Training loss: 2.484389305114746
Validation loss: 2.0831336206005466

Epoch: 6| Step: 10
Training loss: 2.562730550765991
Validation loss: 2.076911057195356

Epoch: 6| Step: 11
Training loss: 2.31710147857666
Validation loss: 2.06716828192434

Epoch: 6| Step: 12
Training loss: 1.7544578313827515
Validation loss: 2.084660283980831

Epoch: 6| Step: 13
Training loss: 3.0660624504089355
Validation loss: 2.097605116905705

Epoch: 108| Step: 0
Training loss: 2.4852817058563232
Validation loss: 2.1062867282539286

Epoch: 6| Step: 1
Training loss: 2.098374605178833
Validation loss: 2.119632451764999

Epoch: 6| Step: 2
Training loss: 2.053173542022705
Validation loss: 2.129448988104379

Epoch: 6| Step: 3
Training loss: 2.272033929824829
Validation loss: 2.106191627440914

Epoch: 6| Step: 4
Training loss: 2.415886402130127
Validation loss: 2.0886694077522523

Epoch: 6| Step: 5
Training loss: 1.8763412237167358
Validation loss: 2.071264320804227

Epoch: 6| Step: 6
Training loss: 2.4862260818481445
Validation loss: 2.0759752335086947

Epoch: 6| Step: 7
Training loss: 2.4326224327087402
Validation loss: 2.0671504082218295

Epoch: 6| Step: 8
Training loss: 1.8608684539794922
Validation loss: 2.0779371389778714

Epoch: 6| Step: 9
Training loss: 2.3100545406341553
Validation loss: 2.072232589926771

Epoch: 6| Step: 10
Training loss: 3.205338954925537
Validation loss: 2.080890255589639

Epoch: 6| Step: 11
Training loss: 2.5185184478759766
Validation loss: 2.085859981916284

Epoch: 6| Step: 12
Training loss: 2.5238025188446045
Validation loss: 2.10644801457723

Epoch: 6| Step: 13
Training loss: 2.1614999771118164
Validation loss: 2.120313972555181

Epoch: 109| Step: 0
Training loss: 2.5638418197631836
Validation loss: 2.1078814486021638

Epoch: 6| Step: 1
Training loss: 1.8678522109985352
Validation loss: 2.1023067146219234

Epoch: 6| Step: 2
Training loss: 2.230098247528076
Validation loss: 2.081666270891825

Epoch: 6| Step: 3
Training loss: 2.4835100173950195
Validation loss: 2.0715285372990433

Epoch: 6| Step: 4
Training loss: 2.3370063304901123
Validation loss: 2.0601754855084162

Epoch: 6| Step: 5
Training loss: 2.393890380859375
Validation loss: 2.0713420926883654

Epoch: 6| Step: 6
Training loss: 2.639143228530884
Validation loss: 2.074990164849066

Epoch: 6| Step: 7
Training loss: 2.5482394695281982
Validation loss: 2.079683465342368

Epoch: 6| Step: 8
Training loss: 3.1076807975769043
Validation loss: 2.0848200013560634

Epoch: 6| Step: 9
Training loss: 2.327846050262451
Validation loss: 2.0839681087001676

Epoch: 6| Step: 10
Training loss: 2.0393896102905273
Validation loss: 2.0811551014582315

Epoch: 6| Step: 11
Training loss: 1.8619844913482666
Validation loss: 2.0719974579349643

Epoch: 6| Step: 12
Training loss: 2.2121448516845703
Validation loss: 2.065266716864801

Epoch: 6| Step: 13
Training loss: 2.9430665969848633
Validation loss: 2.08409212481591

Epoch: 110| Step: 0
Training loss: 2.2933995723724365
Validation loss: 2.16440349753185

Epoch: 6| Step: 1
Training loss: 2.603100538253784
Validation loss: 2.2054318356257614

Epoch: 6| Step: 2
Training loss: 1.9685142040252686
Validation loss: 2.236336085104173

Epoch: 6| Step: 3
Training loss: 1.51934015750885
Validation loss: 2.2346847954616753

Epoch: 6| Step: 4
Training loss: 2.6789019107818604
Validation loss: 2.226053745515885

Epoch: 6| Step: 5
Training loss: 2.2620604038238525
Validation loss: 2.1882515286886566

Epoch: 6| Step: 6
Training loss: 2.8197946548461914
Validation loss: 2.1441549613911617

Epoch: 6| Step: 7
Training loss: 2.140018939971924
Validation loss: 2.1250108441998883

Epoch: 6| Step: 8
Training loss: 3.0906262397766113
Validation loss: 2.0851594196852816

Epoch: 6| Step: 9
Training loss: 2.995809555053711
Validation loss: 2.0721898078918457

Epoch: 6| Step: 10
Training loss: 2.05612850189209
Validation loss: 2.070087899443924

Epoch: 6| Step: 11
Training loss: 2.290719509124756
Validation loss: 2.069366990879018

Epoch: 6| Step: 12
Training loss: 2.2210965156555176
Validation loss: 2.067125892126432

Epoch: 6| Step: 13
Training loss: 2.326931953430176
Validation loss: 2.0648600221962057

Epoch: 111| Step: 0
Training loss: 2.224205732345581
Validation loss: 2.079724075973675

Epoch: 6| Step: 1
Training loss: 2.8412318229675293
Validation loss: 2.0845970594754784

Epoch: 6| Step: 2
Training loss: 2.9868366718292236
Validation loss: 2.1084134424886396

Epoch: 6| Step: 3
Training loss: 2.545128345489502
Validation loss: 2.1212029892911195

Epoch: 6| Step: 4
Training loss: 2.629009485244751
Validation loss: 2.112762886990783

Epoch: 6| Step: 5
Training loss: 2.028109550476074
Validation loss: 2.097862301334258

Epoch: 6| Step: 6
Training loss: 2.788585662841797
Validation loss: 2.0866554667872768

Epoch: 6| Step: 7
Training loss: 2.5492005348205566
Validation loss: 2.0744753319730043

Epoch: 6| Step: 8
Training loss: 1.1949360370635986
Validation loss: 2.061591964896007

Epoch: 6| Step: 9
Training loss: 1.6854491233825684
Validation loss: 2.0603392239539855

Epoch: 6| Step: 10
Training loss: 2.021299362182617
Validation loss: 2.07184995630736

Epoch: 6| Step: 11
Training loss: 2.12160325050354
Validation loss: 2.103555617793914

Epoch: 6| Step: 12
Training loss: 2.5065436363220215
Validation loss: 2.1092997263836604

Epoch: 6| Step: 13
Training loss: 2.871825695037842
Validation loss: 2.1112465755913847

Epoch: 112| Step: 0
Training loss: 2.1916370391845703
Validation loss: 2.0845346245714413

Epoch: 6| Step: 1
Training loss: 1.67970871925354
Validation loss: 2.0714551646222352

Epoch: 6| Step: 2
Training loss: 2.6572296619415283
Validation loss: 2.046598349848101

Epoch: 6| Step: 3
Training loss: 2.9648470878601074
Validation loss: 2.0523339138236096

Epoch: 6| Step: 4
Training loss: 2.468916416168213
Validation loss: 2.054669653215716

Epoch: 6| Step: 5
Training loss: 2.193432092666626
Validation loss: 2.048608056960567

Epoch: 6| Step: 6
Training loss: 1.9695823192596436
Validation loss: 2.049035769636913

Epoch: 6| Step: 7
Training loss: 2.5701119899749756
Validation loss: 2.0476563284474034

Epoch: 6| Step: 8
Training loss: 1.6085302829742432
Validation loss: 2.067332443370614

Epoch: 6| Step: 9
Training loss: 2.5657546520233154
Validation loss: 2.0850930547201507

Epoch: 6| Step: 10
Training loss: 2.738776683807373
Validation loss: 2.109035116370006

Epoch: 6| Step: 11
Training loss: 2.3968234062194824
Validation loss: 2.115473360143682

Epoch: 6| Step: 12
Training loss: 1.916001558303833
Validation loss: 2.12765980920484

Epoch: 6| Step: 13
Training loss: 3.019382953643799
Validation loss: 2.1376491054411857

Epoch: 113| Step: 0
Training loss: 3.150825023651123
Validation loss: 2.124488462683975

Epoch: 6| Step: 1
Training loss: 1.9976835250854492
Validation loss: 2.0923853689624416

Epoch: 6| Step: 2
Training loss: 1.585382342338562
Validation loss: 2.0702186348617717

Epoch: 6| Step: 3
Training loss: 2.314326047897339
Validation loss: 2.045437917914442

Epoch: 6| Step: 4
Training loss: 2.2808918952941895
Validation loss: 2.043211588295557

Epoch: 6| Step: 5
Training loss: 2.0907132625579834
Validation loss: 2.0397432632343744

Epoch: 6| Step: 6
Training loss: 1.9592723846435547
Validation loss: 2.0351229508717856

Epoch: 6| Step: 7
Training loss: 2.357926368713379
Validation loss: 2.0474366500813472

Epoch: 6| Step: 8
Training loss: 2.036276340484619
Validation loss: 2.057548802386048

Epoch: 6| Step: 9
Training loss: 2.404977560043335
Validation loss: 2.0776341512639034

Epoch: 6| Step: 10
Training loss: 2.5672459602355957
Validation loss: 2.0760173413061325

Epoch: 6| Step: 11
Training loss: 1.8633742332458496
Validation loss: 2.0791189760290165

Epoch: 6| Step: 12
Training loss: 3.270045280456543
Validation loss: 2.0645194950924126

Epoch: 6| Step: 13
Training loss: 2.9917736053466797
Validation loss: 2.067617239490632

Epoch: 114| Step: 0
Training loss: 2.7516684532165527
Validation loss: 2.0619037894792456

Epoch: 6| Step: 1
Training loss: 2.2799251079559326
Validation loss: 2.0619155770988873

Epoch: 6| Step: 2
Training loss: 2.4321866035461426
Validation loss: 2.040847373265092

Epoch: 6| Step: 3
Training loss: 1.6902954578399658
Validation loss: 2.0374748245362313

Epoch: 6| Step: 4
Training loss: 2.350277900695801
Validation loss: 2.038732228740569

Epoch: 6| Step: 5
Training loss: 2.1345763206481934
Validation loss: 2.031635670251744

Epoch: 6| Step: 6
Training loss: 2.6195945739746094
Validation loss: 2.027211079033472

Epoch: 6| Step: 7
Training loss: 1.970154047012329
Validation loss: 2.031049322056514

Epoch: 6| Step: 8
Training loss: 2.5174243450164795
Validation loss: 2.0397821446900726

Epoch: 6| Step: 9
Training loss: 2.1560707092285156
Validation loss: 2.0280383094664542

Epoch: 6| Step: 10
Training loss: 2.1909165382385254
Validation loss: 2.040279661455462

Epoch: 6| Step: 11
Training loss: 1.9981958866119385
Validation loss: 2.050939034390193

Epoch: 6| Step: 12
Training loss: 2.3667373657226562
Validation loss: 2.070948705878309

Epoch: 6| Step: 13
Training loss: 3.159031629562378
Validation loss: 2.078472646333838

Epoch: 115| Step: 0
Training loss: 1.5614559650421143
Validation loss: 2.074150564850018

Epoch: 6| Step: 1
Training loss: 2.1232709884643555
Validation loss: 2.0662168815571773

Epoch: 6| Step: 2
Training loss: 1.901507019996643
Validation loss: 2.0449773560288134

Epoch: 6| Step: 3
Training loss: 2.341111898422241
Validation loss: 2.023933251698812

Epoch: 6| Step: 4
Training loss: 2.6152024269104004
Validation loss: 2.0250120047600038

Epoch: 6| Step: 5
Training loss: 2.9232139587402344
Validation loss: 2.0284874016238796

Epoch: 6| Step: 6
Training loss: 2.4611012935638428
Validation loss: 2.0483104182827856

Epoch: 6| Step: 7
Training loss: 2.4831557273864746
Validation loss: 2.0476110276355537

Epoch: 6| Step: 8
Training loss: 2.09501314163208
Validation loss: 2.0357973908865326

Epoch: 6| Step: 9
Training loss: 2.9670166969299316
Validation loss: 2.0316378147371355

Epoch: 6| Step: 10
Training loss: 2.3818440437316895
Validation loss: 2.0317251707917903

Epoch: 6| Step: 11
Training loss: 2.4906201362609863
Validation loss: 2.0418992209178146

Epoch: 6| Step: 12
Training loss: 1.8491265773773193
Validation loss: 2.071650548647809

Epoch: 6| Step: 13
Training loss: 1.9456912279129028
Validation loss: 2.0945796133369528

Epoch: 116| Step: 0
Training loss: 2.499542713165283
Validation loss: 2.125134462951332

Epoch: 6| Step: 1
Training loss: 2.4049155712127686
Validation loss: 2.1055977472694973

Epoch: 6| Step: 2
Training loss: 2.2917935848236084
Validation loss: 2.0625133437495076

Epoch: 6| Step: 3
Training loss: 2.157935619354248
Validation loss: 2.03021151532409

Epoch: 6| Step: 4
Training loss: 2.1567559242248535
Validation loss: 2.01998447602795

Epoch: 6| Step: 5
Training loss: 2.008162021636963
Validation loss: 2.03093256104377

Epoch: 6| Step: 6
Training loss: 2.501765489578247
Validation loss: 2.039958856439078

Epoch: 6| Step: 7
Training loss: 2.139810562133789
Validation loss: 2.0440054708911526

Epoch: 6| Step: 8
Training loss: 2.6448936462402344
Validation loss: 2.0397867989796463

Epoch: 6| Step: 9
Training loss: 2.8627190589904785
Validation loss: 2.025939313314294

Epoch: 6| Step: 10
Training loss: 1.6818801164627075
Validation loss: 2.018558515015469

Epoch: 6| Step: 11
Training loss: 2.382312536239624
Validation loss: 2.023327435216596

Epoch: 6| Step: 12
Training loss: 2.343759536743164
Validation loss: 2.028766844862251

Epoch: 6| Step: 13
Training loss: 2.498867988586426
Validation loss: 2.040559712276664

Epoch: 117| Step: 0
Training loss: 2.6336402893066406
Validation loss: 2.06852247125359

Epoch: 6| Step: 1
Training loss: 2.4702248573303223
Validation loss: 2.063613566660112

Epoch: 6| Step: 2
Training loss: 1.6686086654663086
Validation loss: 2.049195735685287

Epoch: 6| Step: 3
Training loss: 2.533090114593506
Validation loss: 2.035246682423417

Epoch: 6| Step: 4
Training loss: 1.8892333507537842
Validation loss: 2.0285898126581663

Epoch: 6| Step: 5
Training loss: 1.8118493556976318
Validation loss: 2.032098823978055

Epoch: 6| Step: 6
Training loss: 3.3761696815490723
Validation loss: 2.042843346954674

Epoch: 6| Step: 7
Training loss: 1.8855981826782227
Validation loss: 2.048113566572948

Epoch: 6| Step: 8
Training loss: 2.6382429599761963
Validation loss: 2.039193948109945

Epoch: 6| Step: 9
Training loss: 2.507808208465576
Validation loss: 2.0303494135538735

Epoch: 6| Step: 10
Training loss: 2.4286835193634033
Validation loss: 2.046195278885544

Epoch: 6| Step: 11
Training loss: 2.0387344360351562
Validation loss: 2.0479240520026094

Epoch: 6| Step: 12
Training loss: 2.1753644943237305
Validation loss: 2.0548739548652404

Epoch: 6| Step: 13
Training loss: 2.587062358856201
Validation loss: 2.0716965839427006

Epoch: 118| Step: 0
Training loss: 2.5674362182617188
Validation loss: 2.067182767775751

Epoch: 6| Step: 1
Training loss: 2.721648693084717
Validation loss: 2.059024662099859

Epoch: 6| Step: 2
Training loss: 2.6351571083068848
Validation loss: 2.054960379036524

Epoch: 6| Step: 3
Training loss: 1.9499268531799316
Validation loss: 2.061153301628687

Epoch: 6| Step: 4
Training loss: 2.35910964012146
Validation loss: 2.040271556505593

Epoch: 6| Step: 5
Training loss: 2.061742067337036
Validation loss: 2.018729789282686

Epoch: 6| Step: 6
Training loss: 2.351435899734497
Validation loss: 2.0202806201032413

Epoch: 6| Step: 7
Training loss: 1.9883302450180054
Validation loss: 2.026154556582051

Epoch: 6| Step: 8
Training loss: 1.409433364868164
Validation loss: 2.0239536070054576

Epoch: 6| Step: 9
Training loss: 2.9109768867492676
Validation loss: 2.018447320948365

Epoch: 6| Step: 10
Training loss: 2.57553768157959
Validation loss: 2.016693825362831

Epoch: 6| Step: 11
Training loss: 1.982079029083252
Validation loss: 2.026660273152013

Epoch: 6| Step: 12
Training loss: 2.0900168418884277
Validation loss: 2.018474109711186

Epoch: 6| Step: 13
Training loss: 2.5269839763641357
Validation loss: 2.031540004155969

Epoch: 119| Step: 0
Training loss: 1.7469749450683594
Validation loss: 2.038838706990724

Epoch: 6| Step: 1
Training loss: 2.2901487350463867
Validation loss: 2.022993555632971

Epoch: 6| Step: 2
Training loss: 2.3614673614501953
Validation loss: 2.024917289774905

Epoch: 6| Step: 3
Training loss: 2.545750617980957
Validation loss: 2.0286847775982273

Epoch: 6| Step: 4
Training loss: 2.637770891189575
Validation loss: 2.026733952183877

Epoch: 6| Step: 5
Training loss: 1.8352382183074951
Validation loss: 2.021982087883898

Epoch: 6| Step: 6
Training loss: 2.5739972591400146
Validation loss: 2.0266936978986188

Epoch: 6| Step: 7
Training loss: 2.8038747310638428
Validation loss: 2.0424205846683954

Epoch: 6| Step: 8
Training loss: 1.1342158317565918
Validation loss: 2.0302204931935957

Epoch: 6| Step: 9
Training loss: 1.581848382949829
Validation loss: 2.0479812160615

Epoch: 6| Step: 10
Training loss: 2.7402334213256836
Validation loss: 2.0460825607340825

Epoch: 6| Step: 11
Training loss: 2.585059404373169
Validation loss: 2.0529971661106234

Epoch: 6| Step: 12
Training loss: 2.1704087257385254
Validation loss: 2.0381573425826205

Epoch: 6| Step: 13
Training loss: 3.0790064334869385
Validation loss: 2.030793482257474

Epoch: 120| Step: 0
Training loss: 1.7664787769317627
Validation loss: 2.038374385526103

Epoch: 6| Step: 1
Training loss: 2.250985860824585
Validation loss: 2.0312756825518865

Epoch: 6| Step: 2
Training loss: 1.935467004776001
Validation loss: 2.029094547353765

Epoch: 6| Step: 3
Training loss: 1.9998773336410522
Validation loss: 2.0254688262939453

Epoch: 6| Step: 4
Training loss: 2.749107837677002
Validation loss: 2.0168711613583308

Epoch: 6| Step: 5
Training loss: 2.342578887939453
Validation loss: 2.0235680431448

Epoch: 6| Step: 6
Training loss: 2.578892707824707
Validation loss: 2.027405156884142

Epoch: 6| Step: 7
Training loss: 2.3900389671325684
Validation loss: 2.021278340329406

Epoch: 6| Step: 8
Training loss: 2.694939613342285
Validation loss: 2.015718474183031

Epoch: 6| Step: 9
Training loss: 2.4360601902008057
Validation loss: 2.024725875546855

Epoch: 6| Step: 10
Training loss: 2.5720582008361816
Validation loss: 2.0138768560142926

Epoch: 6| Step: 11
Training loss: 1.8770183324813843
Validation loss: 2.0206713304724744

Epoch: 6| Step: 12
Training loss: 2.6559019088745117
Validation loss: 2.026205378194009

Epoch: 6| Step: 13
Training loss: 0.7044458985328674
Validation loss: 2.036280162872807

Epoch: 121| Step: 0
Training loss: 2.1190223693847656
Validation loss: 2.035761515299479

Epoch: 6| Step: 1
Training loss: 2.644181251525879
Validation loss: 2.0245059023621264

Epoch: 6| Step: 2
Training loss: 3.057400703430176
Validation loss: 2.030945926584223

Epoch: 6| Step: 3
Training loss: 2.542574405670166
Validation loss: 2.0119063892672138

Epoch: 6| Step: 4
Training loss: 2.657794237136841
Validation loss: 2.007041178723817

Epoch: 6| Step: 5
Training loss: 2.4254322052001953
Validation loss: 2.016439268665929

Epoch: 6| Step: 6
Training loss: 1.93578040599823
Validation loss: 2.01418472361821

Epoch: 6| Step: 7
Training loss: 2.935307264328003
Validation loss: 2.0255145154973513

Epoch: 6| Step: 8
Training loss: 1.5547206401824951
Validation loss: 2.0380376154376614

Epoch: 6| Step: 9
Training loss: 1.6296796798706055
Validation loss: 2.051931256889015

Epoch: 6| Step: 10
Training loss: 1.7824797630310059
Validation loss: 2.044923710566695

Epoch: 6| Step: 11
Training loss: 2.0422496795654297
Validation loss: 2.038169668566796

Epoch: 6| Step: 12
Training loss: 2.450185775756836
Validation loss: 2.01142450558242

Epoch: 6| Step: 13
Training loss: 1.962760329246521
Validation loss: 1.9975598204520442

Epoch: 122| Step: 0
Training loss: 2.428279161453247
Validation loss: 1.9913520338714763

Epoch: 6| Step: 1
Training loss: 2.226987600326538
Validation loss: 2.0015918939344344

Epoch: 6| Step: 2
Training loss: 1.9629497528076172
Validation loss: 2.002533519139854

Epoch: 6| Step: 3
Training loss: 1.859933853149414
Validation loss: 2.0221996179191013

Epoch: 6| Step: 4
Training loss: 2.839531898498535
Validation loss: 2.047395429303569

Epoch: 6| Step: 5
Training loss: 2.591226577758789
Validation loss: 2.0742074110174693

Epoch: 6| Step: 6
Training loss: 2.4330177307128906
Validation loss: 2.100058901694513

Epoch: 6| Step: 7
Training loss: 2.001390218734741
Validation loss: 2.0911249858076855

Epoch: 6| Step: 8
Training loss: 1.7744578123092651
Validation loss: 2.0660882406337286

Epoch: 6| Step: 9
Training loss: 2.4520134925842285
Validation loss: 2.022019268364035

Epoch: 6| Step: 10
Training loss: 3.009610652923584
Validation loss: 2.006278457180146

Epoch: 6| Step: 11
Training loss: 2.460076332092285
Validation loss: 2.007944150637555

Epoch: 6| Step: 12
Training loss: 2.738443374633789
Validation loss: 2.025421820661073

Epoch: 6| Step: 13
Training loss: 1.0104432106018066
Validation loss: 2.019645416608421

Epoch: 123| Step: 0
Training loss: 2.063936233520508
Validation loss: 2.029445107265185

Epoch: 6| Step: 1
Training loss: 2.5739874839782715
Validation loss: 2.0215689302772604

Epoch: 6| Step: 2
Training loss: 2.0469603538513184
Validation loss: 2.0269774134441088

Epoch: 6| Step: 3
Training loss: 2.8159241676330566
Validation loss: 2.050697184378101

Epoch: 6| Step: 4
Training loss: 2.7750635147094727
Validation loss: 2.072028116513324

Epoch: 6| Step: 5
Training loss: 1.8986735343933105
Validation loss: 2.1021764688594367

Epoch: 6| Step: 6
Training loss: 2.8456015586853027
Validation loss: 2.0973096624497445

Epoch: 6| Step: 7
Training loss: 1.300995111465454
Validation loss: 2.063548331619591

Epoch: 6| Step: 8
Training loss: 2.271732807159424
Validation loss: 2.040061185436864

Epoch: 6| Step: 9
Training loss: 2.0580570697784424
Validation loss: 2.0367967338972193

Epoch: 6| Step: 10
Training loss: 1.9787958860397339
Validation loss: 2.0204413898529543

Epoch: 6| Step: 11
Training loss: 2.889697551727295
Validation loss: 2.019851238496842

Epoch: 6| Step: 12
Training loss: 1.918700933456421
Validation loss: 2.0157070698276645

Epoch: 6| Step: 13
Training loss: 2.341076612472534
Validation loss: 2.0060913896047943

Epoch: 124| Step: 0
Training loss: 2.1614365577697754
Validation loss: 2.0182627785590386

Epoch: 6| Step: 1
Training loss: 1.4386026859283447
Validation loss: 2.0172886002448296

Epoch: 6| Step: 2
Training loss: 1.7347675561904907
Validation loss: 2.0045326025255266

Epoch: 6| Step: 3
Training loss: 2.964339256286621
Validation loss: 2.0106344479386524

Epoch: 6| Step: 4
Training loss: 2.6029391288757324
Validation loss: 2.016269983783845

Epoch: 6| Step: 5
Training loss: 2.675114393234253
Validation loss: 2.0244099004294283

Epoch: 6| Step: 6
Training loss: 2.2293031215667725
Validation loss: 2.034238323088615

Epoch: 6| Step: 7
Training loss: 2.6610050201416016
Validation loss: 2.058635752688172

Epoch: 6| Step: 8
Training loss: 1.9754735231399536
Validation loss: 2.0774963363524406

Epoch: 6| Step: 9
Training loss: 2.377389907836914
Validation loss: 2.0733929705876175

Epoch: 6| Step: 10
Training loss: 1.9824001789093018
Validation loss: 2.0781822409681094

Epoch: 6| Step: 11
Training loss: 2.0387208461761475
Validation loss: 2.0547564311694075

Epoch: 6| Step: 12
Training loss: 2.1406707763671875
Validation loss: 2.0127320026838653

Epoch: 6| Step: 13
Training loss: 3.0566916465759277
Validation loss: 1.997956496413036

Epoch: 125| Step: 0
Training loss: 2.077916145324707
Validation loss: 1.9911382916153118

Epoch: 6| Step: 1
Training loss: 2.816760540008545
Validation loss: 1.9829953242373723

Epoch: 6| Step: 2
Training loss: 2.592524290084839
Validation loss: 1.9830160076900194

Epoch: 6| Step: 3
Training loss: 2.790834903717041
Validation loss: 1.979489508495536

Epoch: 6| Step: 4
Training loss: 2.8121814727783203
Validation loss: 1.9847449500073668

Epoch: 6| Step: 5
Training loss: 1.7948222160339355
Validation loss: 1.9787237157103836

Epoch: 6| Step: 6
Training loss: 1.5839431285858154
Validation loss: 1.996721803501088

Epoch: 6| Step: 7
Training loss: 1.7708616256713867
Validation loss: 2.007653142816277

Epoch: 6| Step: 8
Training loss: 2.0879454612731934
Validation loss: 2.0263692422579695

Epoch: 6| Step: 9
Training loss: 2.795191526412964
Validation loss: 2.039616430959394

Epoch: 6| Step: 10
Training loss: 2.048081159591675
Validation loss: 2.0443125745301605

Epoch: 6| Step: 11
Training loss: 2.170785427093506
Validation loss: 2.0440041095979753

Epoch: 6| Step: 12
Training loss: 2.152064561843872
Validation loss: 2.0300846176762737

Epoch: 6| Step: 13
Training loss: 2.243321657180786
Validation loss: 2.0062527938555648

Epoch: 126| Step: 0
Training loss: 2.5036845207214355
Validation loss: 1.9960074758016935

Epoch: 6| Step: 1
Training loss: 2.535677194595337
Validation loss: 1.9889445022870136

Epoch: 6| Step: 2
Training loss: 2.233285903930664
Validation loss: 2.0064251525427705

Epoch: 6| Step: 3
Training loss: 1.8911876678466797
Validation loss: 2.0051702735244588

Epoch: 6| Step: 4
Training loss: 2.179147243499756
Validation loss: 1.992275289309922

Epoch: 6| Step: 5
Training loss: 2.4499335289001465
Validation loss: 1.9892213703483663

Epoch: 6| Step: 6
Training loss: 2.0669074058532715
Validation loss: 2.006349194434381

Epoch: 6| Step: 7
Training loss: 2.1206068992614746
Validation loss: 2.027364971817181

Epoch: 6| Step: 8
Training loss: 2.3928751945495605
Validation loss: 2.0366797101113105

Epoch: 6| Step: 9
Training loss: 2.4732165336608887
Validation loss: 2.0291752597337127

Epoch: 6| Step: 10
Training loss: 1.7933759689331055
Validation loss: 2.0232279454508135

Epoch: 6| Step: 11
Training loss: 1.9712408781051636
Validation loss: 2.005654788786365

Epoch: 6| Step: 12
Training loss: 2.7687501907348633
Validation loss: 2.006716766665059

Epoch: 6| Step: 13
Training loss: 2.3723835945129395
Validation loss: 2.019149758482492

Epoch: 127| Step: 0
Training loss: 1.5408852100372314
Validation loss: 2.0200465340768137

Epoch: 6| Step: 1
Training loss: 3.0866425037384033
Validation loss: 2.026157702169111

Epoch: 6| Step: 2
Training loss: 2.4130468368530273
Validation loss: 2.0343034575062413

Epoch: 6| Step: 3
Training loss: 2.4508309364318848
Validation loss: 2.0399924068040747

Epoch: 6| Step: 4
Training loss: 2.63580060005188
Validation loss: 2.0408177375793457

Epoch: 6| Step: 5
Training loss: 2.6789169311523438
Validation loss: 2.0345608213896393

Epoch: 6| Step: 6
Training loss: 2.129322052001953
Validation loss: 2.032392842795259

Epoch: 6| Step: 7
Training loss: 2.10418963432312
Validation loss: 2.0165144346093618

Epoch: 6| Step: 8
Training loss: 1.9185445308685303
Validation loss: 2.0075537620052213

Epoch: 6| Step: 9
Training loss: 2.249849319458008
Validation loss: 2.0009745308147964

Epoch: 6| Step: 10
Training loss: 0.9371961355209351
Validation loss: 1.9946982655473935

Epoch: 6| Step: 11
Training loss: 2.2347769737243652
Validation loss: 1.9946182491958782

Epoch: 6| Step: 12
Training loss: 2.5406928062438965
Validation loss: 2.008205070290514

Epoch: 6| Step: 13
Training loss: 2.875441789627075
Validation loss: 2.0219499590576335

Epoch: 128| Step: 0
Training loss: 2.067798614501953
Validation loss: 2.018806101173483

Epoch: 6| Step: 1
Training loss: 2.199498414993286
Validation loss: 2.0115833859289847

Epoch: 6| Step: 2
Training loss: 2.1827712059020996
Validation loss: 2.0137329563017814

Epoch: 6| Step: 3
Training loss: 2.154026508331299
Validation loss: 2.0225342217312066

Epoch: 6| Step: 4
Training loss: 1.7386460304260254
Validation loss: 2.0173564957034205

Epoch: 6| Step: 5
Training loss: 2.218214750289917
Validation loss: 2.0246997597397014

Epoch: 6| Step: 6
Training loss: 2.21467924118042
Validation loss: 2.0259475169643277

Epoch: 6| Step: 7
Training loss: 2.3022658824920654
Validation loss: 2.0392160915559336

Epoch: 6| Step: 8
Training loss: 2.2965173721313477
Validation loss: 2.049463374640352

Epoch: 6| Step: 9
Training loss: 2.483830213546753
Validation loss: 2.034875739005304

Epoch: 6| Step: 10
Training loss: 3.181706428527832
Validation loss: 2.0404846591334187

Epoch: 6| Step: 11
Training loss: 1.7298825979232788
Validation loss: 2.0393794044371574

Epoch: 6| Step: 12
Training loss: 2.489130973815918
Validation loss: 2.018639382495675

Epoch: 6| Step: 13
Training loss: 1.8303228616714478
Validation loss: 2.014183743025667

Epoch: 129| Step: 0
Training loss: 2.1013875007629395
Validation loss: 2.0155635802976546

Epoch: 6| Step: 1
Training loss: 2.0842373371124268
Validation loss: 2.013042647351501

Epoch: 6| Step: 2
Training loss: 1.751555323600769
Validation loss: 2.004262116647536

Epoch: 6| Step: 3
Training loss: 2.3277015686035156
Validation loss: 2.003630838086528

Epoch: 6| Step: 4
Training loss: 2.926238775253296
Validation loss: 2.000917355219523

Epoch: 6| Step: 5
Training loss: 1.6382954120635986
Validation loss: 2.004249797072462

Epoch: 6| Step: 6
Training loss: 2.4827260971069336
Validation loss: 2.0002411539836595

Epoch: 6| Step: 7
Training loss: 2.1018519401550293
Validation loss: 1.9997250969691942

Epoch: 6| Step: 8
Training loss: 2.5562191009521484
Validation loss: 1.9916115371129846

Epoch: 6| Step: 9
Training loss: 2.0804715156555176
Validation loss: 1.9929381698690436

Epoch: 6| Step: 10
Training loss: 2.578432321548462
Validation loss: 1.9854877174541514

Epoch: 6| Step: 11
Training loss: 2.059011697769165
Validation loss: 1.9844471780202722

Epoch: 6| Step: 12
Training loss: 2.018381357192993
Validation loss: 1.9816403055703768

Epoch: 6| Step: 13
Training loss: 2.5656137466430664
Validation loss: 1.9796481952872327

Epoch: 130| Step: 0
Training loss: 1.9885649681091309
Validation loss: 1.9860190729941092

Epoch: 6| Step: 1
Training loss: 2.9203174114227295
Validation loss: 1.9825005697947677

Epoch: 6| Step: 2
Training loss: 2.654963970184326
Validation loss: 1.981863861442894

Epoch: 6| Step: 3
Training loss: 2.1361818313598633
Validation loss: 1.9694655813196653

Epoch: 6| Step: 4
Training loss: 2.0490169525146484
Validation loss: 1.9687047799428303

Epoch: 6| Step: 5
Training loss: 2.6620678901672363
Validation loss: 1.9676702753190072

Epoch: 6| Step: 6
Training loss: 1.8656280040740967
Validation loss: 1.9622245501446467

Epoch: 6| Step: 7
Training loss: 2.8624777793884277
Validation loss: 1.9740752148371872

Epoch: 6| Step: 8
Training loss: 1.7554514408111572
Validation loss: 1.9827618214391893

Epoch: 6| Step: 9
Training loss: 2.2528185844421387
Validation loss: 1.9796521612392959

Epoch: 6| Step: 10
Training loss: 1.6804065704345703
Validation loss: 1.992950124125327

Epoch: 6| Step: 11
Training loss: 2.1769261360168457
Validation loss: 2.0050664973515335

Epoch: 6| Step: 12
Training loss: 2.1070358753204346
Validation loss: 1.992797500343733

Epoch: 6| Step: 13
Training loss: 1.811838150024414
Validation loss: 1.9809683125506166

Epoch: 131| Step: 0
Training loss: 2.265713691711426
Validation loss: 1.9723293678734892

Epoch: 6| Step: 1
Training loss: 2.378236770629883
Validation loss: 1.9734070788147628

Epoch: 6| Step: 2
Training loss: 2.056079864501953
Validation loss: 1.9628421337373796

Epoch: 6| Step: 3
Training loss: 2.4663782119750977
Validation loss: 1.9633850692420878

Epoch: 6| Step: 4
Training loss: 1.7947415113449097
Validation loss: 1.967761606298467

Epoch: 6| Step: 5
Training loss: 2.2565388679504395
Validation loss: 1.959239677716327

Epoch: 6| Step: 6
Training loss: 2.3507723808288574
Validation loss: 1.959171095202046

Epoch: 6| Step: 7
Training loss: 2.0375688076019287
Validation loss: 1.9770905510071786

Epoch: 6| Step: 8
Training loss: 2.1598057746887207
Validation loss: 1.9991528923793505

Epoch: 6| Step: 9
Training loss: 2.4989752769470215
Validation loss: 1.9970239862318961

Epoch: 6| Step: 10
Training loss: 2.4678406715393066
Validation loss: 2.0041282766608783

Epoch: 6| Step: 11
Training loss: 2.686645746231079
Validation loss: 1.9914464437833397

Epoch: 6| Step: 12
Training loss: 2.1108591556549072
Validation loss: 1.9920323561596613

Epoch: 6| Step: 13
Training loss: 0.9954472780227661
Validation loss: 1.9987316746865549

Epoch: 132| Step: 0
Training loss: 2.385507583618164
Validation loss: 1.995502853906283

Epoch: 6| Step: 1
Training loss: 2.333496570587158
Validation loss: 2.000837702904978

Epoch: 6| Step: 2
Training loss: 2.7938525676727295
Validation loss: 2.0034781271411526

Epoch: 6| Step: 3
Training loss: 1.6719729900360107
Validation loss: 2.011882269254295

Epoch: 6| Step: 4
Training loss: 1.6509310007095337
Validation loss: 2.005657490863595

Epoch: 6| Step: 5
Training loss: 1.87734055519104
Validation loss: 2.015838876847298

Epoch: 6| Step: 6
Training loss: 1.72282075881958
Validation loss: 2.02452592695913

Epoch: 6| Step: 7
Training loss: 1.8607430458068848
Validation loss: 2.041537561724263

Epoch: 6| Step: 8
Training loss: 2.808444023132324
Validation loss: 2.043618058645597

Epoch: 6| Step: 9
Training loss: 2.8904640674591064
Validation loss: 2.044929201884936

Epoch: 6| Step: 10
Training loss: 2.5322790145874023
Validation loss: 2.030784922261392

Epoch: 6| Step: 11
Training loss: 2.5039923191070557
Validation loss: 2.0156873887585056

Epoch: 6| Step: 12
Training loss: 1.8901796340942383
Validation loss: 2.0024141547500447

Epoch: 6| Step: 13
Training loss: 2.245731830596924
Validation loss: 1.9976091013159802

Epoch: 133| Step: 0
Training loss: 1.8378512859344482
Validation loss: 2.015207862341276

Epoch: 6| Step: 1
Training loss: 2.0930991172790527
Validation loss: 2.009532211929239

Epoch: 6| Step: 2
Training loss: 2.0678486824035645
Validation loss: 2.0098750770732923

Epoch: 6| Step: 3
Training loss: 2.1634628772735596
Validation loss: 1.997148508666664

Epoch: 6| Step: 4
Training loss: 2.596637725830078
Validation loss: 1.9821059883281749

Epoch: 6| Step: 5
Training loss: 2.273014545440674
Validation loss: 1.9699768379170408

Epoch: 6| Step: 6
Training loss: 2.063918352127075
Validation loss: 1.9795612071150093

Epoch: 6| Step: 7
Training loss: 2.2795767784118652
Validation loss: 1.991137340504636

Epoch: 6| Step: 8
Training loss: 2.2710375785827637
Validation loss: 1.9897968897255518

Epoch: 6| Step: 9
Training loss: 2.158301830291748
Validation loss: 1.983467214850969

Epoch: 6| Step: 10
Training loss: 1.9804056882858276
Validation loss: 1.9806540448178527

Epoch: 6| Step: 11
Training loss: 2.8049824237823486
Validation loss: 1.9540997371878674

Epoch: 6| Step: 12
Training loss: 2.6366183757781982
Validation loss: 1.9555823213310652

Epoch: 6| Step: 13
Training loss: 1.979665756225586
Validation loss: 1.960320959809006

Epoch: 134| Step: 0
Training loss: 1.9875469207763672
Validation loss: 1.9613104943306214

Epoch: 6| Step: 1
Training loss: 2.376300811767578
Validation loss: 1.9727664070744668

Epoch: 6| Step: 2
Training loss: 2.484220504760742
Validation loss: 1.993418506396714

Epoch: 6| Step: 3
Training loss: 2.307284355163574
Validation loss: 2.0123940719071256

Epoch: 6| Step: 4
Training loss: 2.2802367210388184
Validation loss: 2.0391843459939443

Epoch: 6| Step: 5
Training loss: 2.3828682899475098
Validation loss: 2.0419039110983572

Epoch: 6| Step: 6
Training loss: 2.1477508544921875
Validation loss: 2.04363759615088

Epoch: 6| Step: 7
Training loss: 2.2472951412200928
Validation loss: 2.034227994180495

Epoch: 6| Step: 8
Training loss: 2.334043502807617
Validation loss: 2.015997758475683

Epoch: 6| Step: 9
Training loss: 1.8251749277114868
Validation loss: 2.020632158043564

Epoch: 6| Step: 10
Training loss: 2.5641167163848877
Validation loss: 2.0344436963399253

Epoch: 6| Step: 11
Training loss: 1.8283004760742188
Validation loss: 2.030388051463712

Epoch: 6| Step: 12
Training loss: 1.810455560684204
Validation loss: 2.021604645636774

Epoch: 6| Step: 13
Training loss: 3.100879430770874
Validation loss: 2.004091578145181

Epoch: 135| Step: 0
Training loss: 2.427140235900879
Validation loss: 2.0088828776472356

Epoch: 6| Step: 1
Training loss: 2.112818717956543
Validation loss: 2.006452951380002

Epoch: 6| Step: 2
Training loss: 2.4593048095703125
Validation loss: 2.006763337760843

Epoch: 6| Step: 3
Training loss: 2.9199488162994385
Validation loss: 2.0129965812929216

Epoch: 6| Step: 4
Training loss: 2.2741994857788086
Validation loss: 2.010231060366477

Epoch: 6| Step: 5
Training loss: 2.0416736602783203
Validation loss: 1.9855337732581682

Epoch: 6| Step: 6
Training loss: 2.130347967147827
Validation loss: 1.9581784612389022

Epoch: 6| Step: 7
Training loss: 1.4049149751663208
Validation loss: 1.9459633314481346

Epoch: 6| Step: 8
Training loss: 1.9883798360824585
Validation loss: 1.947626680456182

Epoch: 6| Step: 9
Training loss: 2.439737558364868
Validation loss: 1.941104495397178

Epoch: 6| Step: 10
Training loss: 2.0857393741607666
Validation loss: 1.9491050320286905

Epoch: 6| Step: 11
Training loss: 2.8942198753356934
Validation loss: 1.9573957227891492

Epoch: 6| Step: 12
Training loss: 1.967563509941101
Validation loss: 1.9446921810027091

Epoch: 6| Step: 13
Training loss: 1.590380072593689
Validation loss: 1.9507969887025896

Epoch: 136| Step: 0
Training loss: 1.6990852355957031
Validation loss: 1.9660684665044148

Epoch: 6| Step: 1
Training loss: 2.246631145477295
Validation loss: 1.97148161549722

Epoch: 6| Step: 2
Training loss: 2.8210654258728027
Validation loss: 1.9748761397536083

Epoch: 6| Step: 3
Training loss: 2.1910629272460938
Validation loss: 1.975778127229342

Epoch: 6| Step: 4
Training loss: 2.291147232055664
Validation loss: 1.9690960017583703

Epoch: 6| Step: 5
Training loss: 2.483776569366455
Validation loss: 1.9571367630394556

Epoch: 6| Step: 6
Training loss: 2.9101643562316895
Validation loss: 1.9488187348970802

Epoch: 6| Step: 7
Training loss: 2.2363507747650146
Validation loss: 1.9496100641066028

Epoch: 6| Step: 8
Training loss: 1.4030956029891968
Validation loss: 1.9607031832459152

Epoch: 6| Step: 9
Training loss: 2.248243808746338
Validation loss: 1.9524944956584642

Epoch: 6| Step: 10
Training loss: 2.745175361633301
Validation loss: 1.957943327965275

Epoch: 6| Step: 11
Training loss: 1.168481707572937
Validation loss: 1.9563805005883659

Epoch: 6| Step: 12
Training loss: 2.025277614593506
Validation loss: 1.9621981715643277

Epoch: 6| Step: 13
Training loss: 2.440678358078003
Validation loss: 1.9587195265677668

Epoch: 137| Step: 0
Training loss: 2.245241165161133
Validation loss: 1.9732705944327897

Epoch: 6| Step: 1
Training loss: 2.684378147125244
Validation loss: 1.996242771866501

Epoch: 6| Step: 2
Training loss: 2.098524570465088
Validation loss: 1.9951063227909867

Epoch: 6| Step: 3
Training loss: 1.0163577795028687
Validation loss: 1.998012032560123

Epoch: 6| Step: 4
Training loss: 1.7883098125457764
Validation loss: 1.9855353050334479

Epoch: 6| Step: 5
Training loss: 2.530083179473877
Validation loss: 1.971522428656137

Epoch: 6| Step: 6
Training loss: 1.986466646194458
Validation loss: 1.9687597841344855

Epoch: 6| Step: 7
Training loss: 2.0939347743988037
Validation loss: 1.960230363312588

Epoch: 6| Step: 8
Training loss: 2.7637600898742676
Validation loss: 1.9580291112263997

Epoch: 6| Step: 9
Training loss: 2.382188320159912
Validation loss: 1.96959896497829

Epoch: 6| Step: 10
Training loss: 2.406921863555908
Validation loss: 1.9696082825301795

Epoch: 6| Step: 11
Training loss: 2.129899501800537
Validation loss: 1.963852726003175

Epoch: 6| Step: 12
Training loss: 2.367122173309326
Validation loss: 1.9624198739246657

Epoch: 6| Step: 13
Training loss: 2.524418830871582
Validation loss: 1.9617135934932257

Epoch: 138| Step: 0
Training loss: 1.3646032810211182
Validation loss: 1.9535980250245781

Epoch: 6| Step: 1
Training loss: 1.573595404624939
Validation loss: 1.9528111885952693

Epoch: 6| Step: 2
Training loss: 2.1082444190979004
Validation loss: 1.9819780780423073

Epoch: 6| Step: 3
Training loss: 2.134192943572998
Validation loss: 1.9762060360241962

Epoch: 6| Step: 4
Training loss: 2.46803617477417
Validation loss: 1.9735287799630115

Epoch: 6| Step: 5
Training loss: 2.268947124481201
Validation loss: 1.9692045475846978

Epoch: 6| Step: 6
Training loss: 2.0096373558044434
Validation loss: 1.9729285624719435

Epoch: 6| Step: 7
Training loss: 2.269225597381592
Validation loss: 1.9711020813193372

Epoch: 6| Step: 8
Training loss: 2.3662896156311035
Validation loss: 1.9567613473502539

Epoch: 6| Step: 9
Training loss: 2.145139217376709
Validation loss: 1.956402761961824

Epoch: 6| Step: 10
Training loss: 2.3930459022521973
Validation loss: 1.946017292238051

Epoch: 6| Step: 11
Training loss: 2.6352524757385254
Validation loss: 1.9454947440854964

Epoch: 6| Step: 12
Training loss: 2.6880064010620117
Validation loss: 1.9495516118182932

Epoch: 6| Step: 13
Training loss: 1.9574273824691772
Validation loss: 1.939784553743178

Epoch: 139| Step: 0
Training loss: 2.2201523780822754
Validation loss: 1.9548682679412186

Epoch: 6| Step: 1
Training loss: 2.2395005226135254
Validation loss: 1.9620055357615154

Epoch: 6| Step: 2
Training loss: 2.4967474937438965
Validation loss: 1.9644232501265824

Epoch: 6| Step: 3
Training loss: 2.2437822818756104
Validation loss: 1.9802107708428496

Epoch: 6| Step: 4
Training loss: 2.0203394889831543
Validation loss: 1.9848149796967864

Epoch: 6| Step: 5
Training loss: 1.9038114547729492
Validation loss: 1.9641164925790602

Epoch: 6| Step: 6
Training loss: 1.553537368774414
Validation loss: 1.960532211488293

Epoch: 6| Step: 7
Training loss: 2.1548707485198975
Validation loss: 1.9485516022610407

Epoch: 6| Step: 8
Training loss: 2.4160819053649902
Validation loss: 1.9299979389354747

Epoch: 6| Step: 9
Training loss: 2.3526387214660645
Validation loss: 1.9393203207241592

Epoch: 6| Step: 10
Training loss: 2.487107515335083
Validation loss: 1.9389022806639313

Epoch: 6| Step: 11
Training loss: 2.08805513381958
Validation loss: 1.9555900122529717

Epoch: 6| Step: 12
Training loss: 2.405494213104248
Validation loss: 1.9534774570054905

Epoch: 6| Step: 13
Training loss: 1.8945238590240479
Validation loss: 1.9453859060041365

Epoch: 140| Step: 0
Training loss: 2.1940736770629883
Validation loss: 1.9429917463692286

Epoch: 6| Step: 1
Training loss: 2.065258741378784
Validation loss: 1.938920053102637

Epoch: 6| Step: 2
Training loss: 3.209505081176758
Validation loss: 1.936813449346891

Epoch: 6| Step: 3
Training loss: 2.7030997276306152
Validation loss: 1.9458055470579414

Epoch: 6| Step: 4
Training loss: 2.239039421081543
Validation loss: 1.9712586838711974

Epoch: 6| Step: 5
Training loss: 1.7717801332473755
Validation loss: 1.965624895147098

Epoch: 6| Step: 6
Training loss: 2.6781177520751953
Validation loss: 1.9649298883253528

Epoch: 6| Step: 7
Training loss: 1.7809371948242188
Validation loss: 1.9497438387204242

Epoch: 6| Step: 8
Training loss: 2.5922908782958984
Validation loss: 1.9395065948527346

Epoch: 6| Step: 9
Training loss: 2.006391763687134
Validation loss: 1.9530558586120605

Epoch: 6| Step: 10
Training loss: 1.2654578685760498
Validation loss: 1.9700011617393904

Epoch: 6| Step: 11
Training loss: 1.6695666313171387
Validation loss: 1.9601634061464699

Epoch: 6| Step: 12
Training loss: 2.2613658905029297
Validation loss: 1.953555348098919

Epoch: 6| Step: 13
Training loss: 2.226780652999878
Validation loss: 1.9622656427403933

Epoch: 141| Step: 0
Training loss: 3.208327293395996
Validation loss: 1.98755294276822

Epoch: 6| Step: 1
Training loss: 2.1339774131774902
Validation loss: 1.997871780908236

Epoch: 6| Step: 2
Training loss: 1.042029619216919
Validation loss: 1.9662780018262966

Epoch: 6| Step: 3
Training loss: 1.8326690196990967
Validation loss: 1.9686079999451995

Epoch: 6| Step: 4
Training loss: 1.6728318929672241
Validation loss: 1.9823644225315382

Epoch: 6| Step: 5
Training loss: 2.577324151992798
Validation loss: 2.00302521387736

Epoch: 6| Step: 6
Training loss: 2.554469108581543
Validation loss: 1.9889994385421916

Epoch: 6| Step: 7
Training loss: 2.131305456161499
Validation loss: 1.9788137276967366

Epoch: 6| Step: 8
Training loss: 2.254737615585327
Validation loss: 1.9881387449079944

Epoch: 6| Step: 9
Training loss: 2.6813974380493164
Validation loss: 2.0062011416240404

Epoch: 6| Step: 10
Training loss: 1.863980770111084
Validation loss: 2.0489999658317974

Epoch: 6| Step: 11
Training loss: 2.7125864028930664
Validation loss: 2.0631502072016397

Epoch: 6| Step: 12
Training loss: 2.358339309692383
Validation loss: 2.0741076905240297

Epoch: 6| Step: 13
Training loss: 2.3748371601104736
Validation loss: 2.094984516020744

Epoch: 142| Step: 0
Training loss: 2.2534587383270264
Validation loss: 2.082111704734064

Epoch: 6| Step: 1
Training loss: 2.325078010559082
Validation loss: 2.0417227745056152

Epoch: 6| Step: 2
Training loss: 2.524263858795166
Validation loss: 2.0195538228557957

Epoch: 6| Step: 3
Training loss: 1.891603946685791
Validation loss: 1.987478119070812

Epoch: 6| Step: 4
Training loss: 2.7320456504821777
Validation loss: 2.008459856433253

Epoch: 6| Step: 5
Training loss: 1.7972064018249512
Validation loss: 1.997386452972248

Epoch: 6| Step: 6
Training loss: 2.153576374053955
Validation loss: 2.0813219239634853

Epoch: 6| Step: 7
Training loss: 2.4109842777252197
Validation loss: 2.059115855924545

Epoch: 6| Step: 8
Training loss: 2.1925816535949707
Validation loss: 2.0967650528877013

Epoch: 6| Step: 9
Training loss: 2.2333076000213623
Validation loss: 2.031117646924911

Epoch: 6| Step: 10
Training loss: 3.099825859069824
Validation loss: 1.9847938501706688

Epoch: 6| Step: 11
Training loss: 2.3947978019714355
Validation loss: 2.0022623410788913

Epoch: 6| Step: 12
Training loss: 1.9310716390609741
Validation loss: 2.0184794343927854

Epoch: 6| Step: 13
Training loss: 2.1416094303131104
Validation loss: 2.0354246529199744

Epoch: 143| Step: 0
Training loss: 2.28690242767334
Validation loss: 2.0296506625349804

Epoch: 6| Step: 1
Training loss: 1.8427832126617432
Validation loss: 2.0125055620747228

Epoch: 6| Step: 2
Training loss: 2.811690330505371
Validation loss: 1.9757073451113958

Epoch: 6| Step: 3
Training loss: 2.1686336994171143
Validation loss: 1.9499164858172018

Epoch: 6| Step: 4
Training loss: 2.300267219543457
Validation loss: 1.9533457704769668

Epoch: 6| Step: 5
Training loss: 1.8086962699890137
Validation loss: 1.9570317755463302

Epoch: 6| Step: 6
Training loss: 3.0490033626556396
Validation loss: 1.951501028512114

Epoch: 6| Step: 7
Training loss: 2.591531276702881
Validation loss: 1.9472673862211165

Epoch: 6| Step: 8
Training loss: 1.8515634536743164
Validation loss: 1.945768783169408

Epoch: 6| Step: 9
Training loss: 2.0682950019836426
Validation loss: 1.947046079943257

Epoch: 6| Step: 10
Training loss: 2.168135166168213
Validation loss: 1.9475775854561919

Epoch: 6| Step: 11
Training loss: 2.303162097930908
Validation loss: 1.9357177557483796

Epoch: 6| Step: 12
Training loss: 2.285935878753662
Validation loss: 1.9322955839095577

Epoch: 6| Step: 13
Training loss: 2.2630271911621094
Validation loss: 1.9305565562299503

Epoch: 144| Step: 0
Training loss: 1.6741526126861572
Validation loss: 1.9529281559810843

Epoch: 6| Step: 1
Training loss: 2.449773073196411
Validation loss: 1.954870395762946

Epoch: 6| Step: 2
Training loss: 2.303982973098755
Validation loss: 1.9705343105459725

Epoch: 6| Step: 3
Training loss: 2.8544836044311523
Validation loss: 1.9624721747572704

Epoch: 6| Step: 4
Training loss: 3.1235365867614746
Validation loss: 1.971719334202428

Epoch: 6| Step: 5
Training loss: 2.0455069541931152
Validation loss: 1.984272740220511

Epoch: 6| Step: 6
Training loss: 2.298999071121216
Validation loss: 1.9662069902625134

Epoch: 6| Step: 7
Training loss: 2.1328659057617188
Validation loss: 1.9564085416896368

Epoch: 6| Step: 8
Training loss: 2.212465763092041
Validation loss: 1.9557022599763767

Epoch: 6| Step: 9
Training loss: 1.6381916999816895
Validation loss: 1.9344003726077337

Epoch: 6| Step: 10
Training loss: 1.855270504951477
Validation loss: 1.935469554316613

Epoch: 6| Step: 11
Training loss: 1.9881662130355835
Validation loss: 1.9377249171656947

Epoch: 6| Step: 12
Training loss: 2.039867877960205
Validation loss: 1.9393209462524743

Epoch: 6| Step: 13
Training loss: 2.40736985206604
Validation loss: 1.9269887119211175

Epoch: 145| Step: 0
Training loss: 1.9339202642440796
Validation loss: 1.9351567940045429

Epoch: 6| Step: 1
Training loss: 2.4252452850341797
Validation loss: 1.9501023048995643

Epoch: 6| Step: 2
Training loss: 2.4883618354797363
Validation loss: 1.969082078626079

Epoch: 6| Step: 3
Training loss: 2.455173969268799
Validation loss: 1.9611099573873705

Epoch: 6| Step: 4
Training loss: 1.5042868852615356
Validation loss: 1.9877108335494995

Epoch: 6| Step: 5
Training loss: 1.7711689472198486
Validation loss: 2.007913303631608

Epoch: 6| Step: 6
Training loss: 2.3517096042633057
Validation loss: 2.0045787237023793

Epoch: 6| Step: 7
Training loss: 1.9368582963943481
Validation loss: 1.9921820958455403

Epoch: 6| Step: 8
Training loss: 2.890237331390381
Validation loss: 1.9758463585248558

Epoch: 6| Step: 9
Training loss: 1.9414132833480835
Validation loss: 1.9500032304435648

Epoch: 6| Step: 10
Training loss: 1.6118214130401611
Validation loss: 1.9359169031984063

Epoch: 6| Step: 11
Training loss: 2.5820000171661377
Validation loss: 1.9384562161660963

Epoch: 6| Step: 12
Training loss: 2.3014769554138184
Validation loss: 1.940104643503825

Epoch: 6| Step: 13
Training loss: 2.7765421867370605
Validation loss: 1.955166527020034

Epoch: 146| Step: 0
Training loss: 1.7084264755249023
Validation loss: 1.976969297214221

Epoch: 6| Step: 1
Training loss: 1.8411784172058105
Validation loss: 1.9890701270872546

Epoch: 6| Step: 2
Training loss: 1.9899506568908691
Validation loss: 1.9791654168918569

Epoch: 6| Step: 3
Training loss: 2.5060229301452637
Validation loss: 1.9761107403744933

Epoch: 6| Step: 4
Training loss: 1.922036051750183
Validation loss: 1.947243272617299

Epoch: 6| Step: 5
Training loss: 2.319150924682617
Validation loss: 1.9603491239650275

Epoch: 6| Step: 6
Training loss: 2.655649185180664
Validation loss: 1.956631229769799

Epoch: 6| Step: 7
Training loss: 2.226620674133301
Validation loss: 1.9545485204265964

Epoch: 6| Step: 8
Training loss: 2.611072301864624
Validation loss: 1.9521022817139984

Epoch: 6| Step: 9
Training loss: 1.4643919467926025
Validation loss: 1.9535955549568258

Epoch: 6| Step: 10
Training loss: 2.9952967166900635
Validation loss: 1.9672206832516579

Epoch: 6| Step: 11
Training loss: 2.1644930839538574
Validation loss: 1.968546494360893

Epoch: 6| Step: 12
Training loss: 1.7081624269485474
Validation loss: 1.9987635535578574

Epoch: 6| Step: 13
Training loss: 2.3312253952026367
Validation loss: 1.9906791422956733

Epoch: 147| Step: 0
Training loss: 2.333784580230713
Validation loss: 1.9968573329269246

Epoch: 6| Step: 1
Training loss: 2.4019079208374023
Validation loss: 2.0090869754873295

Epoch: 6| Step: 2
Training loss: 2.3458094596862793
Validation loss: 2.0123848376735562

Epoch: 6| Step: 3
Training loss: 2.1456305980682373
Validation loss: 2.017567362836612

Epoch: 6| Step: 4
Training loss: 2.238842010498047
Validation loss: 2.0031665038037043

Epoch: 6| Step: 5
Training loss: 1.9908194541931152
Validation loss: 1.985880559490573

Epoch: 6| Step: 6
Training loss: 1.938826084136963
Validation loss: 1.9628468226361018

Epoch: 6| Step: 7
Training loss: 2.432631254196167
Validation loss: 1.951114554559031

Epoch: 6| Step: 8
Training loss: 2.21671199798584
Validation loss: 1.9609762596827682

Epoch: 6| Step: 9
Training loss: 1.8916778564453125
Validation loss: 1.9664856208268033

Epoch: 6| Step: 10
Training loss: 2.347039222717285
Validation loss: 1.9599030120398409

Epoch: 6| Step: 11
Training loss: 2.2815403938293457
Validation loss: 1.9589178677528136

Epoch: 6| Step: 12
Training loss: 1.918558955192566
Validation loss: 1.953148159929501

Epoch: 6| Step: 13
Training loss: 1.6011536121368408
Validation loss: 1.9401702086130779

Epoch: 148| Step: 0
Training loss: 1.5926580429077148
Validation loss: 1.9478227605101883

Epoch: 6| Step: 1
Training loss: 2.7420802116394043
Validation loss: 1.9547558907539613

Epoch: 6| Step: 2
Training loss: 2.434663772583008
Validation loss: 2.008270894327471

Epoch: 6| Step: 3
Training loss: 1.9814152717590332
Validation loss: 2.0578210046214442

Epoch: 6| Step: 4
Training loss: 2.3322594165802
Validation loss: 2.09320068359375

Epoch: 6| Step: 5
Training loss: 3.1202425956726074
Validation loss: 2.0988014077627533

Epoch: 6| Step: 6
Training loss: 2.6926722526550293
Validation loss: 2.085948703109577

Epoch: 6| Step: 7
Training loss: 2.026230573654175
Validation loss: 2.0322650248004543

Epoch: 6| Step: 8
Training loss: 1.7444181442260742
Validation loss: 1.9626890984914636

Epoch: 6| Step: 9
Training loss: 1.3847863674163818
Validation loss: 1.920309994810371

Epoch: 6| Step: 10
Training loss: 2.05003023147583
Validation loss: 1.9347139917394167

Epoch: 6| Step: 11
Training loss: 2.057539701461792
Validation loss: 1.9384178602567284

Epoch: 6| Step: 12
Training loss: 2.2710752487182617
Validation loss: 1.9648558426928777

Epoch: 6| Step: 13
Training loss: 2.1185877323150635
Validation loss: 1.9740254327815066

Epoch: 149| Step: 0
Training loss: 1.7174372673034668
Validation loss: 1.9900880193197599

Epoch: 6| Step: 1
Training loss: 1.6800730228424072
Validation loss: 1.988068797255075

Epoch: 6| Step: 2
Training loss: 2.254580497741699
Validation loss: 1.9883978161760556

Epoch: 6| Step: 3
Training loss: 3.024480104446411
Validation loss: 1.9902173767807663

Epoch: 6| Step: 4
Training loss: 2.8339931964874268
Validation loss: 1.9857809556427823

Epoch: 6| Step: 5
Training loss: 1.7497656345367432
Validation loss: 1.9718608651109921

Epoch: 6| Step: 6
Training loss: 2.3244192600250244
Validation loss: 1.9372505449479627

Epoch: 6| Step: 7
Training loss: 2.023669958114624
Validation loss: 1.9229467145858272

Epoch: 6| Step: 8
Training loss: 1.9075026512145996
Validation loss: 1.929489480551853

Epoch: 6| Step: 9
Training loss: 2.3847577571868896
Validation loss: 1.9666057953270533

Epoch: 6| Step: 10
Training loss: 2.1071369647979736
Validation loss: 2.0118092234416673

Epoch: 6| Step: 11
Training loss: 2.074544668197632
Validation loss: 2.0377151812276533

Epoch: 6| Step: 12
Training loss: 2.6774206161499023
Validation loss: 2.0459954905253586

Epoch: 6| Step: 13
Training loss: 2.597262144088745
Validation loss: 2.0574224482300463

Epoch: 150| Step: 0
Training loss: 1.6027729511260986
Validation loss: 2.0912851569473103

Epoch: 6| Step: 1
Training loss: 1.955566167831421
Validation loss: 2.0936441242053943

Epoch: 6| Step: 2
Training loss: 2.7334134578704834
Validation loss: 2.081002540485833

Epoch: 6| Step: 3
Training loss: 1.4441308975219727
Validation loss: 2.0457726973359303

Epoch: 6| Step: 4
Training loss: 2.0200791358947754
Validation loss: 2.0061869505913026

Epoch: 6| Step: 5
Training loss: 2.2344489097595215
Validation loss: 1.9659401947452175

Epoch: 6| Step: 6
Training loss: 1.7046473026275635
Validation loss: 1.9509417062164636

Epoch: 6| Step: 7
Training loss: 2.5526201725006104
Validation loss: 1.9399269191167687

Epoch: 6| Step: 8
Training loss: 1.9612574577331543
Validation loss: 1.9388875986940117

Epoch: 6| Step: 9
Training loss: 3.0373597145080566
Validation loss: 1.9473448440592775

Epoch: 6| Step: 10
Training loss: 2.3025336265563965
Validation loss: 1.944662429953134

Epoch: 6| Step: 11
Training loss: 1.8766409158706665
Validation loss: 1.9391487516382688

Epoch: 6| Step: 12
Training loss: 1.738497257232666
Validation loss: 1.9350834123549923

Epoch: 6| Step: 13
Training loss: 3.4300456047058105
Validation loss: 1.9247522713035665

Epoch: 151| Step: 0
Training loss: 2.4070725440979004
Validation loss: 1.9303551117579143

Epoch: 6| Step: 1
Training loss: 2.0720996856689453
Validation loss: 1.9390400558389642

Epoch: 6| Step: 2
Training loss: 1.4553664922714233
Validation loss: 1.9575565938026673

Epoch: 6| Step: 3
Training loss: 2.4098362922668457
Validation loss: 1.9756140362831853

Epoch: 6| Step: 4
Training loss: 2.0646462440490723
Validation loss: 1.9934755730372604

Epoch: 6| Step: 5
Training loss: 2.0636138916015625
Validation loss: 1.994670803828906

Epoch: 6| Step: 6
Training loss: 2.617032051086426
Validation loss: 1.9936033397592523

Epoch: 6| Step: 7
Training loss: 1.7496678829193115
Validation loss: 1.9849316766185146

Epoch: 6| Step: 8
Training loss: 2.397573947906494
Validation loss: 1.9726703218234483

Epoch: 6| Step: 9
Training loss: 2.109687566757202
Validation loss: 1.9465268427325833

Epoch: 6| Step: 10
Training loss: 2.144655466079712
Validation loss: 1.936738593603975

Epoch: 6| Step: 11
Training loss: 2.0388641357421875
Validation loss: 1.9269306685334893

Epoch: 6| Step: 12
Training loss: 2.372814893722534
Validation loss: 1.9306569048153457

Epoch: 6| Step: 13
Training loss: 1.8156733512878418
Validation loss: 1.9266974746540029

Epoch: 152| Step: 0
Training loss: 1.9271382093429565
Validation loss: 1.9335766889715706

Epoch: 6| Step: 1
Training loss: 2.161585807800293
Validation loss: 1.9367842802437403

Epoch: 6| Step: 2
Training loss: 2.715517044067383
Validation loss: 1.953037251708328

Epoch: 6| Step: 3
Training loss: 1.648844599723816
Validation loss: 1.9626233398273427

Epoch: 6| Step: 4
Training loss: 1.9469395875930786
Validation loss: 1.9476542998385686

Epoch: 6| Step: 5
Training loss: 1.7833213806152344
Validation loss: 1.946167140878657

Epoch: 6| Step: 6
Training loss: 1.413938283920288
Validation loss: 1.9572014283108454

Epoch: 6| Step: 7
Training loss: 2.0471878051757812
Validation loss: 1.9655186309609363

Epoch: 6| Step: 8
Training loss: 1.877581238746643
Validation loss: 1.9694543807737288

Epoch: 6| Step: 9
Training loss: 2.209242343902588
Validation loss: 1.9641361890300628

Epoch: 6| Step: 10
Training loss: 2.173098087310791
Validation loss: 1.9665886945621942

Epoch: 6| Step: 11
Training loss: 2.9393608570098877
Validation loss: 1.9675737580945414

Epoch: 6| Step: 12
Training loss: 2.297682523727417
Validation loss: 1.9515388832297376

Epoch: 6| Step: 13
Training loss: 2.578695297241211
Validation loss: 1.9505562807924004

Epoch: 153| Step: 0
Training loss: 1.5949782133102417
Validation loss: 1.9426380857344596

Epoch: 6| Step: 1
Training loss: 2.0609488487243652
Validation loss: 1.9416157673763972

Epoch: 6| Step: 2
Training loss: 1.8148421049118042
Validation loss: 1.9326611744460238

Epoch: 6| Step: 3
Training loss: 1.399083137512207
Validation loss: 1.9264115005411127

Epoch: 6| Step: 4
Training loss: 2.3713011741638184
Validation loss: 1.9376657701307727

Epoch: 6| Step: 5
Training loss: 2.5483977794647217
Validation loss: 1.956236941840059

Epoch: 6| Step: 6
Training loss: 2.39673113822937
Validation loss: 1.957756697490651

Epoch: 6| Step: 7
Training loss: 2.1611504554748535
Validation loss: 1.9525638729013421

Epoch: 6| Step: 8
Training loss: 2.3337326049804688
Validation loss: 1.9252667427062988

Epoch: 6| Step: 9
Training loss: 2.3917784690856934
Validation loss: 1.9069836370406612

Epoch: 6| Step: 10
Training loss: 2.2878527641296387
Validation loss: 1.9076595588396954

Epoch: 6| Step: 11
Training loss: 1.9266715049743652
Validation loss: 1.9106974319745136

Epoch: 6| Step: 12
Training loss: 1.757216215133667
Validation loss: 1.906550525337137

Epoch: 6| Step: 13
Training loss: 2.1904456615448
Validation loss: 1.908379175329721

Epoch: 154| Step: 0
Training loss: 2.3579578399658203
Validation loss: 1.8991561730702717

Epoch: 6| Step: 1
Training loss: 2.3302431106567383
Validation loss: 1.8971511817747546

Epoch: 6| Step: 2
Training loss: 2.3498213291168213
Validation loss: 1.885967355902477

Epoch: 6| Step: 3
Training loss: 1.7258998155593872
Validation loss: 1.8871666193008423

Epoch: 6| Step: 4
Training loss: 2.3702502250671387
Validation loss: 1.9044335657550442

Epoch: 6| Step: 5
Training loss: 2.2675466537475586
Validation loss: 1.922657916622777

Epoch: 6| Step: 6
Training loss: 1.7013370990753174
Validation loss: 1.917057583408971

Epoch: 6| Step: 7
Training loss: 1.862013816833496
Validation loss: 1.9045709692021853

Epoch: 6| Step: 8
Training loss: 1.941792607307434
Validation loss: 1.8951110019478747

Epoch: 6| Step: 9
Training loss: 2.1423749923706055
Validation loss: 1.8973652855042489

Epoch: 6| Step: 10
Training loss: 1.5917761325836182
Validation loss: 1.9069483485273135

Epoch: 6| Step: 11
Training loss: 2.0249547958374023
Validation loss: 1.9157826785118348

Epoch: 6| Step: 12
Training loss: 2.12906551361084
Validation loss: 1.9156308161315097

Epoch: 6| Step: 13
Training loss: 2.0934574604034424
Validation loss: 1.912642809652513

Epoch: 155| Step: 0
Training loss: 2.1864562034606934
Validation loss: 1.8980912675139725

Epoch: 6| Step: 1
Training loss: 1.845217227935791
Validation loss: 1.9045467453618203

Epoch: 6| Step: 2
Training loss: 2.4041967391967773
Validation loss: 1.892507682564438

Epoch: 6| Step: 3
Training loss: 1.7415072917938232
Validation loss: 1.900901968761157

Epoch: 6| Step: 4
Training loss: 1.6033803224563599
Validation loss: 1.901038449297669

Epoch: 6| Step: 5
Training loss: 1.5409846305847168
Validation loss: 1.9143438339233398

Epoch: 6| Step: 6
Training loss: 2.3791067600250244
Validation loss: 1.9307086134469638

Epoch: 6| Step: 7
Training loss: 2.297194004058838
Validation loss: 1.9276313807374688

Epoch: 6| Step: 8
Training loss: 2.3189101219177246
Validation loss: 1.9070952669266732

Epoch: 6| Step: 9
Training loss: 1.5919251441955566
Validation loss: 1.8910397662911365

Epoch: 6| Step: 10
Training loss: 1.9312673807144165
Validation loss: 1.8753601671547018

Epoch: 6| Step: 11
Training loss: 2.4301981925964355
Validation loss: 1.8932276669368948

Epoch: 6| Step: 12
Training loss: 2.357357978820801
Validation loss: 1.8766005833943684

Epoch: 6| Step: 13
Training loss: 1.9658851623535156
Validation loss: 1.873278566586074

Epoch: 156| Step: 0
Training loss: 1.5104293823242188
Validation loss: 1.8730204797560168

Epoch: 6| Step: 1
Training loss: 1.839846134185791
Validation loss: 1.88544068285214

Epoch: 6| Step: 2
Training loss: 2.7029643058776855
Validation loss: 1.876639776332404

Epoch: 6| Step: 3
Training loss: 1.8178479671478271
Validation loss: 1.8901616770734069

Epoch: 6| Step: 4
Training loss: 2.542020559310913
Validation loss: 1.897452926123014

Epoch: 6| Step: 5
Training loss: 1.952521562576294
Validation loss: 1.8772809031189128

Epoch: 6| Step: 6
Training loss: 2.2996864318847656
Validation loss: 1.8533395874884822

Epoch: 6| Step: 7
Training loss: 1.6373159885406494
Validation loss: 1.8596654284384944

Epoch: 6| Step: 8
Training loss: 1.8676120042800903
Validation loss: 1.8772325182473788

Epoch: 6| Step: 9
Training loss: 2.3337156772613525
Validation loss: 1.8896064732664375

Epoch: 6| Step: 10
Training loss: 2.081834316253662
Validation loss: 1.8853313653699812

Epoch: 6| Step: 11
Training loss: 2.2691733837127686
Validation loss: 1.8957981845384002

Epoch: 6| Step: 12
Training loss: 2.236095428466797
Validation loss: 1.8663296417523456

Epoch: 6| Step: 13
Training loss: 1.5308480262756348
Validation loss: 1.8786888532741095

Epoch: 157| Step: 0
Training loss: 2.593937635421753
Validation loss: 1.9307140586196736

Epoch: 6| Step: 1
Training loss: 1.6280832290649414
Validation loss: 1.9501371204212148

Epoch: 6| Step: 2
Training loss: 2.369157314300537
Validation loss: 1.9473376158745057

Epoch: 6| Step: 3
Training loss: 1.8669906854629517
Validation loss: 1.9163696176262313

Epoch: 6| Step: 4
Training loss: 2.66872501373291
Validation loss: 1.8725619995465843

Epoch: 6| Step: 5
Training loss: 2.1683759689331055
Validation loss: 1.8682792340555499

Epoch: 6| Step: 6
Training loss: 1.2693692445755005
Validation loss: 1.8693209694277855

Epoch: 6| Step: 7
Training loss: 2.9386191368103027
Validation loss: 1.8771414769593107

Epoch: 6| Step: 8
Training loss: 2.1081056594848633
Validation loss: 1.8600375613858622

Epoch: 6| Step: 9
Training loss: 1.9896117448806763
Validation loss: 1.8670830534350487

Epoch: 6| Step: 10
Training loss: 1.5616881847381592
Validation loss: 1.897529645632672

Epoch: 6| Step: 11
Training loss: 1.8418349027633667
Validation loss: 1.9199190293588946

Epoch: 6| Step: 12
Training loss: 1.976231575012207
Validation loss: 1.9434682643541725

Epoch: 6| Step: 13
Training loss: 2.2775166034698486
Validation loss: 1.9292351045916158

Epoch: 158| Step: 0
Training loss: 2.619919776916504
Validation loss: 1.9177244735020462

Epoch: 6| Step: 1
Training loss: 2.279905319213867
Validation loss: 1.9117888071203744

Epoch: 6| Step: 2
Training loss: 2.372077465057373
Validation loss: 1.9112721463685394

Epoch: 6| Step: 3
Training loss: 2.6414194107055664
Validation loss: 1.914597798419255

Epoch: 6| Step: 4
Training loss: 2.5072741508483887
Validation loss: 1.9452123283058085

Epoch: 6| Step: 5
Training loss: 1.7139568328857422
Validation loss: 1.9604767496867845

Epoch: 6| Step: 6
Training loss: 1.419938564300537
Validation loss: 1.9532621265739523

Epoch: 6| Step: 7
Training loss: 1.6476061344146729
Validation loss: 1.9563970527341288

Epoch: 6| Step: 8
Training loss: 2.4879815578460693
Validation loss: 1.9515757368456932

Epoch: 6| Step: 9
Training loss: 1.7192562818527222
Validation loss: 1.9447626016473258

Epoch: 6| Step: 10
Training loss: 2.3331146240234375
Validation loss: 1.9300108737843011

Epoch: 6| Step: 11
Training loss: 1.3252348899841309
Validation loss: 1.915837393012098

Epoch: 6| Step: 12
Training loss: 1.722398281097412
Validation loss: 1.8922549498978483

Epoch: 6| Step: 13
Training loss: 1.9842629432678223
Validation loss: 1.8760575068894254

Epoch: 159| Step: 0
Training loss: 1.5316007137298584
Validation loss: 1.9136983656114148

Epoch: 6| Step: 1
Training loss: 1.9101057052612305
Validation loss: 1.963852115856704

Epoch: 6| Step: 2
Training loss: 1.7793183326721191
Validation loss: 2.0002577458658526

Epoch: 6| Step: 3
Training loss: 2.633965015411377
Validation loss: 2.0343235628579253

Epoch: 6| Step: 4
Training loss: 2.190333843231201
Validation loss: 2.0270201852244716

Epoch: 6| Step: 5
Training loss: 2.3067879676818848
Validation loss: 1.9701869590308076

Epoch: 6| Step: 6
Training loss: 1.8155769109725952
Validation loss: 1.92187548452808

Epoch: 6| Step: 7
Training loss: 2.1416454315185547
Validation loss: 1.8987251891884753

Epoch: 6| Step: 8
Training loss: 2.3981728553771973
Validation loss: 1.899016349546371

Epoch: 6| Step: 9
Training loss: 2.2569479942321777
Validation loss: 1.916977055611149

Epoch: 6| Step: 10
Training loss: 2.14897084236145
Validation loss: 1.9160247989880141

Epoch: 6| Step: 11
Training loss: 2.3275821208953857
Validation loss: 1.9151923220644715

Epoch: 6| Step: 12
Training loss: 2.1717300415039062
Validation loss: 1.8944641031244749

Epoch: 6| Step: 13
Training loss: 2.607201099395752
Validation loss: 1.8750031801962084

Epoch: 160| Step: 0
Training loss: 1.9105664491653442
Validation loss: 1.843835207723802

Epoch: 6| Step: 1
Training loss: 1.8025822639465332
Validation loss: 1.8524734102269655

Epoch: 6| Step: 2
Training loss: 1.810267686843872
Validation loss: 1.9173385520135202

Epoch: 6| Step: 3
Training loss: 3.2530531883239746
Validation loss: 2.025940731007566

Epoch: 6| Step: 4
Training loss: 2.6883387565612793
Validation loss: 2.1120923744734896

Epoch: 6| Step: 5
Training loss: 2.1342530250549316
Validation loss: 2.086456460337485

Epoch: 6| Step: 6
Training loss: 2.7440762519836426
Validation loss: 2.0585862398147583

Epoch: 6| Step: 7
Training loss: 1.7184374332427979
Validation loss: 1.985643853423416

Epoch: 6| Step: 8
Training loss: 1.4287188053131104
Validation loss: 1.9015379592936525

Epoch: 6| Step: 9
Training loss: 1.9811103343963623
Validation loss: 1.863131921778443

Epoch: 6| Step: 10
Training loss: 1.879873275756836
Validation loss: 1.8924630482991536

Epoch: 6| Step: 11
Training loss: 1.7951222658157349
Validation loss: 1.8943004403063046

Epoch: 6| Step: 12
Training loss: 2.540217876434326
Validation loss: 1.9266212576179094

Epoch: 6| Step: 13
Training loss: 3.2570877075195312
Validation loss: 1.9393135142582718

Epoch: 161| Step: 0
Training loss: 1.4019132852554321
Validation loss: 1.9391630375257103

Epoch: 6| Step: 1
Training loss: 1.5104374885559082
Validation loss: 1.917241173405801

Epoch: 6| Step: 2
Training loss: 2.00810170173645
Validation loss: 1.895355773228471

Epoch: 6| Step: 3
Training loss: 2.030485153198242
Validation loss: 1.8932080909770022

Epoch: 6| Step: 4
Training loss: 2.530324935913086
Validation loss: 1.9046058372784687

Epoch: 6| Step: 5
Training loss: 1.3749845027923584
Validation loss: 1.93986726063554

Epoch: 6| Step: 6
Training loss: 2.8339478969573975
Validation loss: 1.9650322275777017

Epoch: 6| Step: 7
Training loss: 2.287856101989746
Validation loss: 1.9992892178156043

Epoch: 6| Step: 8
Training loss: 1.944200038909912
Validation loss: 2.000275734932192

Epoch: 6| Step: 9
Training loss: 2.422482490539551
Validation loss: 2.01442111820303

Epoch: 6| Step: 10
Training loss: 2.233389139175415
Validation loss: 1.9995955446714997

Epoch: 6| Step: 11
Training loss: 1.8642246723175049
Validation loss: 1.9739757942897018

Epoch: 6| Step: 12
Training loss: 2.321347236633301
Validation loss: 1.9424478546265633

Epoch: 6| Step: 13
Training loss: 1.9407408237457275
Validation loss: 1.913646190397201

Epoch: 162| Step: 0
Training loss: 2.0100653171539307
Validation loss: 1.892149886777324

Epoch: 6| Step: 1
Training loss: 1.701793909072876
Validation loss: 1.891781710809277

Epoch: 6| Step: 2
Training loss: 2.345592975616455
Validation loss: 1.892056389521527

Epoch: 6| Step: 3
Training loss: 1.6283974647521973
Validation loss: 1.8971512830385597

Epoch: 6| Step: 4
Training loss: 1.6762604713439941
Validation loss: 1.8942904446714668

Epoch: 6| Step: 5
Training loss: 2.3329553604125977
Validation loss: 1.8917272603639992

Epoch: 6| Step: 6
Training loss: 2.1253907680511475
Validation loss: 1.8891156950304586

Epoch: 6| Step: 7
Training loss: 2.4635815620422363
Validation loss: 1.8787180198136197

Epoch: 6| Step: 8
Training loss: 2.364924430847168
Validation loss: 1.866218541258125

Epoch: 6| Step: 9
Training loss: 1.5046801567077637
Validation loss: 1.8535000662649832

Epoch: 6| Step: 10
Training loss: 1.9035097360610962
Validation loss: 1.8620794614156086

Epoch: 6| Step: 11
Training loss: 2.3987326622009277
Validation loss: 1.8930294821339269

Epoch: 6| Step: 12
Training loss: 1.95614492893219
Validation loss: 1.9292389449252878

Epoch: 6| Step: 13
Training loss: 1.9617352485656738
Validation loss: 1.9458823793677873

Epoch: 163| Step: 0
Training loss: 1.9406704902648926
Validation loss: 1.9574595523136917

Epoch: 6| Step: 1
Training loss: 2.2721967697143555
Validation loss: 1.95216872871563

Epoch: 6| Step: 2
Training loss: 2.102642059326172
Validation loss: 1.9480028767739572

Epoch: 6| Step: 3
Training loss: 2.0900893211364746
Validation loss: 1.932356447301885

Epoch: 6| Step: 4
Training loss: 1.6862146854400635
Validation loss: 1.9096059145465973

Epoch: 6| Step: 5
Training loss: 2.7478840351104736
Validation loss: 1.9039730102785173

Epoch: 6| Step: 6
Training loss: 2.1878347396850586
Validation loss: 1.909661860876186

Epoch: 6| Step: 7
Training loss: 2.0379111766815186
Validation loss: 1.8978647993456932

Epoch: 6| Step: 8
Training loss: 2.1335701942443848
Validation loss: 1.8897030340727938

Epoch: 6| Step: 9
Training loss: 1.5773626565933228
Validation loss: 1.8750147614427792

Epoch: 6| Step: 10
Training loss: 1.4862968921661377
Validation loss: 1.8690090999808362

Epoch: 6| Step: 11
Training loss: 1.7000659704208374
Validation loss: 1.8757924059385895

Epoch: 6| Step: 12
Training loss: 2.0725107192993164
Validation loss: 1.893599392265402

Epoch: 6| Step: 13
Training loss: 2.652754783630371
Validation loss: 1.88412763995509

Epoch: 164| Step: 0
Training loss: 1.4087311029434204
Validation loss: 1.874324652456468

Epoch: 6| Step: 1
Training loss: 1.8381659984588623
Validation loss: 1.8721887168063913

Epoch: 6| Step: 2
Training loss: 1.6103579998016357
Validation loss: 1.87598499431405

Epoch: 6| Step: 3
Training loss: 1.970818042755127
Validation loss: 1.8680767756636425

Epoch: 6| Step: 4
Training loss: 1.921028733253479
Validation loss: 1.87474867861758

Epoch: 6| Step: 5
Training loss: 2.4364209175109863
Validation loss: 1.8869842713879001

Epoch: 6| Step: 6
Training loss: 2.2165634632110596
Validation loss: 1.8861527019931423

Epoch: 6| Step: 7
Training loss: 2.0052855014801025
Validation loss: 1.8911553429019066

Epoch: 6| Step: 8
Training loss: 1.8619213104248047
Validation loss: 1.8954430434011644

Epoch: 6| Step: 9
Training loss: 1.4617011547088623
Validation loss: 1.8843648318321473

Epoch: 6| Step: 10
Training loss: 2.827019214630127
Validation loss: 1.895562748755178

Epoch: 6| Step: 11
Training loss: 1.4944322109222412
Validation loss: 1.8944027500767862

Epoch: 6| Step: 12
Training loss: 2.6717023849487305
Validation loss: 1.884587344302926

Epoch: 6| Step: 13
Training loss: 2.1740195751190186
Validation loss: 1.868543214695428

Epoch: 165| Step: 0
Training loss: 2.168531894683838
Validation loss: 1.8391079056647517

Epoch: 6| Step: 1
Training loss: 2.2334110736846924
Validation loss: 1.8279902204390495

Epoch: 6| Step: 2
Training loss: 2.0027689933776855
Validation loss: 1.8195821751830399

Epoch: 6| Step: 3
Training loss: 1.4847155809402466
Validation loss: 1.8227783992726316

Epoch: 6| Step: 4
Training loss: 1.4353277683258057
Validation loss: 1.814698616663615

Epoch: 6| Step: 5
Training loss: 2.3739521503448486
Validation loss: 1.8219371457253732

Epoch: 6| Step: 6
Training loss: 1.569103717803955
Validation loss: 1.8219366740154963

Epoch: 6| Step: 7
Training loss: 2.1821980476379395
Validation loss: 1.8225261934341923

Epoch: 6| Step: 8
Training loss: 1.7276301383972168
Validation loss: 1.824350364746586

Epoch: 6| Step: 9
Training loss: 1.6763708591461182
Validation loss: 1.8203892515551658

Epoch: 6| Step: 10
Training loss: 2.0028834342956543
Validation loss: 1.8246775763009184

Epoch: 6| Step: 11
Training loss: 2.2666211128234863
Validation loss: 1.8314587800733504

Epoch: 6| Step: 12
Training loss: 2.1882357597351074
Validation loss: 1.8684863082824215

Epoch: 6| Step: 13
Training loss: 2.403973340988159
Validation loss: 1.8760232002504411

Epoch: 166| Step: 0
Training loss: 1.846397042274475
Validation loss: 1.881113101077336

Epoch: 6| Step: 1
Training loss: 1.820791482925415
Validation loss: 1.882832447687785

Epoch: 6| Step: 2
Training loss: 2.654478073120117
Validation loss: 1.8814774123571252

Epoch: 6| Step: 3
Training loss: 1.747721791267395
Validation loss: 1.8874788809848089

Epoch: 6| Step: 4
Training loss: 1.0896306037902832
Validation loss: 1.8982232206611223

Epoch: 6| Step: 5
Training loss: 1.9229673147201538
Validation loss: 1.8984583475256478

Epoch: 6| Step: 6
Training loss: 1.5896152257919312
Validation loss: 1.9065838372835548

Epoch: 6| Step: 7
Training loss: 1.7498787641525269
Validation loss: 1.9013193743203276

Epoch: 6| Step: 8
Training loss: 1.8805155754089355
Validation loss: 1.9101540298872097

Epoch: 6| Step: 9
Training loss: 2.119934320449829
Validation loss: 1.9086645854416715

Epoch: 6| Step: 10
Training loss: 2.098266124725342
Validation loss: 1.8998649222876436

Epoch: 6| Step: 11
Training loss: 2.346789836883545
Validation loss: 1.8941986881276613

Epoch: 6| Step: 12
Training loss: 3.277261257171631
Validation loss: 1.875056674403529

Epoch: 6| Step: 13
Training loss: 1.0829132795333862
Validation loss: 1.8709595408490909

Epoch: 167| Step: 0
Training loss: 2.1575653553009033
Validation loss: 1.8608290559502059

Epoch: 6| Step: 1
Training loss: 1.7988934516906738
Validation loss: 1.8509819033325359

Epoch: 6| Step: 2
Training loss: 1.7043979167938232
Validation loss: 1.8545256225011681

Epoch: 6| Step: 3
Training loss: 1.709996223449707
Validation loss: 1.8463098079927507

Epoch: 6| Step: 4
Training loss: 1.9199610948562622
Validation loss: 1.848085348324109

Epoch: 6| Step: 5
Training loss: 1.8000948429107666
Validation loss: 1.843801793231759

Epoch: 6| Step: 6
Training loss: 2.4026665687561035
Validation loss: 1.842218839994041

Epoch: 6| Step: 7
Training loss: 2.3632426261901855
Validation loss: 1.8483211686534267

Epoch: 6| Step: 8
Training loss: 1.9161691665649414
Validation loss: 1.8487181317421697

Epoch: 6| Step: 9
Training loss: 2.6935224533081055
Validation loss: 1.8493797689355829

Epoch: 6| Step: 10
Training loss: 1.1433823108673096
Validation loss: 1.8586355511860182

Epoch: 6| Step: 11
Training loss: 2.312485456466675
Validation loss: 1.867205273720526

Epoch: 6| Step: 12
Training loss: 1.584787368774414
Validation loss: 1.886196961966894

Epoch: 6| Step: 13
Training loss: 1.6213041543960571
Validation loss: 1.8734311147402691

Epoch: 168| Step: 0
Training loss: 1.2388368844985962
Validation loss: 1.873734522891301

Epoch: 6| Step: 1
Training loss: 2.441176414489746
Validation loss: 1.8777635558958976

Epoch: 6| Step: 2
Training loss: 1.554526686668396
Validation loss: 1.8637810804510628

Epoch: 6| Step: 3
Training loss: 2.4496469497680664
Validation loss: 1.8539580850191013

Epoch: 6| Step: 4
Training loss: 2.2887539863586426
Validation loss: 1.8517498021484704

Epoch: 6| Step: 5
Training loss: 1.788355827331543
Validation loss: 1.8508048865102953

Epoch: 6| Step: 6
Training loss: 1.8737473487854004
Validation loss: 1.8623980270918978

Epoch: 6| Step: 7
Training loss: 2.2406556606292725
Validation loss: 1.8623333848932737

Epoch: 6| Step: 8
Training loss: 2.081273078918457
Validation loss: 1.8635946422494867

Epoch: 6| Step: 9
Training loss: 1.6377418041229248
Validation loss: 1.8691559286527737

Epoch: 6| Step: 10
Training loss: 2.4460289478302
Validation loss: 1.872188332260296

Epoch: 6| Step: 11
Training loss: 1.8868274688720703
Validation loss: 1.883750654035999

Epoch: 6| Step: 12
Training loss: 1.578566551208496
Validation loss: 1.8832810437807472

Epoch: 6| Step: 13
Training loss: 1.8539371490478516
Validation loss: 1.8723008773660148

Epoch: 169| Step: 0
Training loss: 2.0436198711395264
Validation loss: 1.8828720174809939

Epoch: 6| Step: 1
Training loss: 1.3720942735671997
Validation loss: 1.8969254801350255

Epoch: 6| Step: 2
Training loss: 2.1252553462982178
Validation loss: 1.887010875568595

Epoch: 6| Step: 3
Training loss: 1.643294334411621
Validation loss: 1.8828823463891142

Epoch: 6| Step: 4
Training loss: 1.9053056240081787
Validation loss: 1.864790255023587

Epoch: 6| Step: 5
Training loss: 1.861314296722412
Validation loss: 1.8492832722202424

Epoch: 6| Step: 6
Training loss: 1.969295620918274
Validation loss: 1.8458462351111955

Epoch: 6| Step: 7
Training loss: 1.6242363452911377
Validation loss: 1.8470733857923938

Epoch: 6| Step: 8
Training loss: 1.3754692077636719
Validation loss: 1.8417780694141184

Epoch: 6| Step: 9
Training loss: 2.5805163383483887
Validation loss: 1.8492263824709

Epoch: 6| Step: 10
Training loss: 1.9127142429351807
Validation loss: 1.8520305284889795

Epoch: 6| Step: 11
Training loss: 2.303736686706543
Validation loss: 1.8484540895749164

Epoch: 6| Step: 12
Training loss: 2.2766828536987305
Validation loss: 1.8457925729854132

Epoch: 6| Step: 13
Training loss: 2.220670700073242
Validation loss: 1.8439722971249652

Epoch: 170| Step: 0
Training loss: 2.017486333847046
Validation loss: 1.850230945053921

Epoch: 6| Step: 1
Training loss: 2.02583384513855
Validation loss: 1.868080985161566

Epoch: 6| Step: 2
Training loss: 1.383448600769043
Validation loss: 1.8485749985582085

Epoch: 6| Step: 3
Training loss: 1.9219313859939575
Validation loss: 1.8537883655999297

Epoch: 6| Step: 4
Training loss: 2.1268563270568848
Validation loss: 1.8783424579969017

Epoch: 6| Step: 5
Training loss: 2.0670888423919678
Validation loss: 1.8811448543302474

Epoch: 6| Step: 6
Training loss: 2.6247735023498535
Validation loss: 1.9085924240850634

Epoch: 6| Step: 7
Training loss: 1.2609034776687622
Validation loss: 1.9145700816185243

Epoch: 6| Step: 8
Training loss: 1.5993494987487793
Validation loss: 1.907072103151711

Epoch: 6| Step: 9
Training loss: 2.4539031982421875
Validation loss: 1.8711464251241376

Epoch: 6| Step: 10
Training loss: 3.003965377807617
Validation loss: 1.8671858631154543

Epoch: 6| Step: 11
Training loss: 1.5265719890594482
Validation loss: 1.8698037696141068

Epoch: 6| Step: 12
Training loss: 2.045072078704834
Validation loss: 1.8570459529917727

Epoch: 6| Step: 13
Training loss: 0.9287145137786865
Validation loss: 1.8517536424821424

Epoch: 171| Step: 0
Training loss: 1.7668547630310059
Validation loss: 1.8459419153069938

Epoch: 6| Step: 1
Training loss: 1.5355374813079834
Validation loss: 1.8375917416746899

Epoch: 6| Step: 2
Training loss: 1.3387224674224854
Validation loss: 1.8484553214042418

Epoch: 6| Step: 3
Training loss: 2.1513519287109375
Validation loss: 1.8625888260461951

Epoch: 6| Step: 4
Training loss: 2.1077346801757812
Validation loss: 1.864513292107531

Epoch: 6| Step: 5
Training loss: 1.7279698848724365
Validation loss: 1.8608383901657597

Epoch: 6| Step: 6
Training loss: 1.887171745300293
Validation loss: 1.8555753692503898

Epoch: 6| Step: 7
Training loss: 2.7271780967712402
Validation loss: 1.8676700130585702

Epoch: 6| Step: 8
Training loss: 2.3157265186309814
Validation loss: 1.8662444135194183

Epoch: 6| Step: 9
Training loss: 2.0148396492004395
Validation loss: 1.8585990910889

Epoch: 6| Step: 10
Training loss: 1.4608688354492188
Validation loss: 1.84994980853091

Epoch: 6| Step: 11
Training loss: 1.5750226974487305
Validation loss: 1.8475310623004872

Epoch: 6| Step: 12
Training loss: 2.094417095184326
Validation loss: 1.8531102621427147

Epoch: 6| Step: 13
Training loss: 2.3853979110717773
Validation loss: 1.8440788907389487

Epoch: 172| Step: 0
Training loss: 2.347116708755493
Validation loss: 1.8515846767733175

Epoch: 6| Step: 1
Training loss: 1.8566548824310303
Validation loss: 1.862517996500897

Epoch: 6| Step: 2
Training loss: 1.5945963859558105
Validation loss: 1.8595399343839256

Epoch: 6| Step: 3
Training loss: 2.3188772201538086
Validation loss: 1.8784339261311356

Epoch: 6| Step: 4
Training loss: 2.664363384246826
Validation loss: 1.8960518170428533

Epoch: 6| Step: 5
Training loss: 2.3800644874572754
Validation loss: 1.901668543456703

Epoch: 6| Step: 6
Training loss: 2.024588108062744
Validation loss: 1.8740103783146027

Epoch: 6| Step: 7
Training loss: 1.8394181728363037
Validation loss: 1.84962930346048

Epoch: 6| Step: 8
Training loss: 1.84356689453125
Validation loss: 1.841889266044863

Epoch: 6| Step: 9
Training loss: 2.1963579654693604
Validation loss: 1.8529904004066222

Epoch: 6| Step: 10
Training loss: 1.4606037139892578
Validation loss: 1.8758586529762513

Epoch: 6| Step: 11
Training loss: 1.3582770824432373
Validation loss: 1.8684260511911044

Epoch: 6| Step: 12
Training loss: 1.899840235710144
Validation loss: 1.8725629993664321

Epoch: 6| Step: 13
Training loss: 1.5781168937683105
Validation loss: 1.8615458908901419

Epoch: 173| Step: 0
Training loss: 1.976460337638855
Validation loss: 1.8516768358087028

Epoch: 6| Step: 1
Training loss: 2.6962904930114746
Validation loss: 1.8910203736315492

Epoch: 6| Step: 2
Training loss: 1.7133030891418457
Validation loss: 1.9363029926053938

Epoch: 6| Step: 3
Training loss: 2.0589523315429688
Validation loss: 1.9481169241730885

Epoch: 6| Step: 4
Training loss: 1.6949433088302612
Validation loss: 1.953491449356079

Epoch: 6| Step: 5
Training loss: 1.818737268447876
Validation loss: 1.9618675426770282

Epoch: 6| Step: 6
Training loss: 2.179837942123413
Validation loss: 1.9405676062389086

Epoch: 6| Step: 7
Training loss: 1.7657248973846436
Validation loss: 1.909081966646256

Epoch: 6| Step: 8
Training loss: 1.436722755432129
Validation loss: 1.8853656835453485

Epoch: 6| Step: 9
Training loss: 1.948809027671814
Validation loss: 1.8803538173757575

Epoch: 6| Step: 10
Training loss: 2.88356876373291
Validation loss: 1.8782365642568117

Epoch: 6| Step: 11
Training loss: 1.862235188484192
Validation loss: 1.8859612531559442

Epoch: 6| Step: 12
Training loss: 1.4040544033050537
Validation loss: 1.8804929230802803

Epoch: 6| Step: 13
Training loss: 1.684399962425232
Validation loss: 1.8746055197972122

Epoch: 174| Step: 0
Training loss: 1.7389812469482422
Validation loss: 1.8708117572210168

Epoch: 6| Step: 1
Training loss: 1.7551562786102295
Validation loss: 1.8784781297047932

Epoch: 6| Step: 2
Training loss: 2.4592628479003906
Validation loss: 1.8966410236973916

Epoch: 6| Step: 3
Training loss: 1.8806147575378418
Validation loss: 1.8706712286959413

Epoch: 6| Step: 4
Training loss: 2.2036733627319336
Validation loss: 1.8832794543235534

Epoch: 6| Step: 5
Training loss: 2.358609676361084
Validation loss: 1.8665995162020448

Epoch: 6| Step: 6
Training loss: 1.8613262176513672
Validation loss: 1.872421774812924

Epoch: 6| Step: 7
Training loss: 2.5089938640594482
Validation loss: 1.8572761499753563

Epoch: 6| Step: 8
Training loss: 1.6578359603881836
Validation loss: 1.8604973875066286

Epoch: 6| Step: 9
Training loss: 1.96141517162323
Validation loss: 1.85894218696061

Epoch: 6| Step: 10
Training loss: 1.5317790508270264
Validation loss: 1.864910150087008

Epoch: 6| Step: 11
Training loss: 1.7814463376998901
Validation loss: 1.8831644917047152

Epoch: 6| Step: 12
Training loss: 1.5701210498809814
Validation loss: 1.8827944763245121

Epoch: 6| Step: 13
Training loss: 1.270076870918274
Validation loss: 1.891859826221261

Epoch: 175| Step: 0
Training loss: 1.2249934673309326
Validation loss: 1.8703520515913605

Epoch: 6| Step: 1
Training loss: 1.3655261993408203
Validation loss: 1.8778926659655828

Epoch: 6| Step: 2
Training loss: 1.9859496355056763
Validation loss: 1.8612994365794684

Epoch: 6| Step: 3
Training loss: 1.726143479347229
Validation loss: 1.8605551835029357

Epoch: 6| Step: 4
Training loss: 1.8961862325668335
Validation loss: 1.8522819319079

Epoch: 6| Step: 5
Training loss: 2.2085862159729004
Validation loss: 1.8447956385151032

Epoch: 6| Step: 6
Training loss: 1.8019235134124756
Validation loss: 1.839292671090813

Epoch: 6| Step: 7
Training loss: 1.736635446548462
Validation loss: 1.8335397128135926

Epoch: 6| Step: 8
Training loss: 2.6426877975463867
Validation loss: 1.8365754594085038

Epoch: 6| Step: 9
Training loss: 1.4833394289016724
Validation loss: 1.8383213371358893

Epoch: 6| Step: 10
Training loss: 1.9288671016693115
Validation loss: 1.8552312786861131

Epoch: 6| Step: 11
Training loss: 1.9025123119354248
Validation loss: 1.863309706411054

Epoch: 6| Step: 12
Training loss: 2.6884021759033203
Validation loss: 1.8683848996316232

Epoch: 6| Step: 13
Training loss: 2.1455461978912354
Validation loss: 1.8778893665600849

Epoch: 176| Step: 0
Training loss: 2.0065464973449707
Validation loss: 1.8795986547265002

Epoch: 6| Step: 1
Training loss: 1.3570947647094727
Validation loss: 1.8699987139753116

Epoch: 6| Step: 2
Training loss: 1.1826872825622559
Validation loss: 1.8715800982649609

Epoch: 6| Step: 3
Training loss: 1.795928955078125
Validation loss: 1.8725009490084905

Epoch: 6| Step: 4
Training loss: 2.3958396911621094
Validation loss: 1.8745421542916247

Epoch: 6| Step: 5
Training loss: 2.004866123199463
Validation loss: 1.8690724321590957

Epoch: 6| Step: 6
Training loss: 2.1131153106689453
Validation loss: 1.865120368619119

Epoch: 6| Step: 7
Training loss: 1.5984793901443481
Validation loss: 1.9028366650304487

Epoch: 6| Step: 8
Training loss: 1.8790578842163086
Validation loss: 1.9325135805273568

Epoch: 6| Step: 9
Training loss: 2.1980323791503906
Validation loss: 1.9648358334777176

Epoch: 6| Step: 10
Training loss: 2.2773077487945557
Validation loss: 1.9511214763887468

Epoch: 6| Step: 11
Training loss: 2.403520107269287
Validation loss: 1.935552332990913

Epoch: 6| Step: 12
Training loss: 1.7622246742248535
Validation loss: 1.9228770271424325

Epoch: 6| Step: 13
Training loss: 1.4762327671051025
Validation loss: 1.9370009168501823

Epoch: 177| Step: 0
Training loss: 1.7415403127670288
Validation loss: 1.9024584588184152

Epoch: 6| Step: 1
Training loss: 1.4648687839508057
Validation loss: 1.8884630331429102

Epoch: 6| Step: 2
Training loss: 1.436213731765747
Validation loss: 1.8850811912167458

Epoch: 6| Step: 3
Training loss: 1.9719408750534058
Validation loss: 1.8854008925858365

Epoch: 6| Step: 4
Training loss: 1.8539496660232544
Validation loss: 1.8665051075720018

Epoch: 6| Step: 5
Training loss: 1.980482578277588
Validation loss: 1.864705272900161

Epoch: 6| Step: 6
Training loss: 2.016153573989868
Validation loss: 1.8673481172130955

Epoch: 6| Step: 7
Training loss: 1.7049217224121094
Validation loss: 1.8651966843553769

Epoch: 6| Step: 8
Training loss: 2.391909122467041
Validation loss: 1.8754172722498577

Epoch: 6| Step: 9
Training loss: 1.5143532752990723
Validation loss: 1.877462956213182

Epoch: 6| Step: 10
Training loss: 1.876320719718933
Validation loss: 1.8840213898689515

Epoch: 6| Step: 11
Training loss: 1.9358149766921997
Validation loss: 1.8885435455588884

Epoch: 6| Step: 12
Training loss: 2.3263134956359863
Validation loss: 1.8825172429443688

Epoch: 6| Step: 13
Training loss: 2.2673892974853516
Validation loss: 1.8735853138790335

Epoch: 178| Step: 0
Training loss: 2.82138729095459
Validation loss: 1.878703933890148

Epoch: 6| Step: 1
Training loss: 1.3076322078704834
Validation loss: 1.8829181655760734

Epoch: 6| Step: 2
Training loss: 2.2667222023010254
Validation loss: 1.8939678310066141

Epoch: 6| Step: 3
Training loss: 1.7155108451843262
Validation loss: 1.8829544564729095

Epoch: 6| Step: 4
Training loss: 2.089986801147461
Validation loss: 1.8734933855713054

Epoch: 6| Step: 5
Training loss: 1.3040820360183716
Validation loss: 1.8624901181908065

Epoch: 6| Step: 6
Training loss: 1.867092251777649
Validation loss: 1.8692675816115512

Epoch: 6| Step: 7
Training loss: 1.9594961404800415
Validation loss: 1.8506517153914257

Epoch: 6| Step: 8
Training loss: 1.9116542339324951
Validation loss: 1.8629858698896182

Epoch: 6| Step: 9
Training loss: 1.3288270235061646
Validation loss: 1.8607699063516432

Epoch: 6| Step: 10
Training loss: 1.3938367366790771
Validation loss: 1.8672519627437796

Epoch: 6| Step: 11
Training loss: 1.753159523010254
Validation loss: 1.8815095117015224

Epoch: 6| Step: 12
Training loss: 2.6505181789398193
Validation loss: 1.875910661553824

Epoch: 6| Step: 13
Training loss: 2.3107526302337646
Validation loss: 1.8765408838948896

Epoch: 179| Step: 0
Training loss: 1.2470660209655762
Validation loss: 1.870295427178824

Epoch: 6| Step: 1
Training loss: 1.6938670873641968
Validation loss: 1.8563711502218758

Epoch: 6| Step: 2
Training loss: 1.81034517288208
Validation loss: 1.8529052196010467

Epoch: 6| Step: 3
Training loss: 1.988548994064331
Validation loss: 1.858087880637056

Epoch: 6| Step: 4
Training loss: 2.3132431507110596
Validation loss: 1.8649868029420094

Epoch: 6| Step: 5
Training loss: 1.5199865102767944
Validation loss: 1.8713748737048077

Epoch: 6| Step: 6
Training loss: 2.0447702407836914
Validation loss: 1.88389499725834

Epoch: 6| Step: 7
Training loss: 1.9360814094543457
Validation loss: 1.8964761046953098

Epoch: 6| Step: 8
Training loss: 1.5116182565689087
Validation loss: 1.8783972891428138

Epoch: 6| Step: 9
Training loss: 2.0726656913757324
Validation loss: 1.8894759749853483

Epoch: 6| Step: 10
Training loss: 2.3748996257781982
Validation loss: 1.8781248959161903

Epoch: 6| Step: 11
Training loss: 2.2185468673706055
Validation loss: 1.8840687403114893

Epoch: 6| Step: 12
Training loss: 1.5005159378051758
Validation loss: 1.87899858977205

Epoch: 6| Step: 13
Training loss: 2.0748465061187744
Validation loss: 1.8954625514245802

Epoch: 180| Step: 0
Training loss: 1.9919465780258179
Validation loss: 1.891566732878326

Epoch: 6| Step: 1
Training loss: 1.6335489749908447
Validation loss: 1.8792967886053107

Epoch: 6| Step: 2
Training loss: 1.9194947481155396
Validation loss: 1.859431384712137

Epoch: 6| Step: 3
Training loss: 1.4200425148010254
Validation loss: 1.8473426859865907

Epoch: 6| Step: 4
Training loss: 1.478546142578125
Validation loss: 1.8597273108779744

Epoch: 6| Step: 5
Training loss: 2.366534471511841
Validation loss: 1.8564594650781283

Epoch: 6| Step: 6
Training loss: 2.1039838790893555
Validation loss: 1.866697980511573

Epoch: 6| Step: 7
Training loss: 1.7147974967956543
Validation loss: 1.875888603989796

Epoch: 6| Step: 8
Training loss: 1.5110864639282227
Validation loss: 1.8685597347956833

Epoch: 6| Step: 9
Training loss: 2.0086700916290283
Validation loss: 1.8586760426080355

Epoch: 6| Step: 10
Training loss: 2.05942964553833
Validation loss: 1.8546018151826755

Epoch: 6| Step: 11
Training loss: 2.1588990688323975
Validation loss: 1.853294131576374

Epoch: 6| Step: 12
Training loss: 2.0761566162109375
Validation loss: 1.8369793917543145

Epoch: 6| Step: 13
Training loss: 1.5277358293533325
Validation loss: 1.8397090537573701

Epoch: 181| Step: 0
Training loss: 2.5215871334075928
Validation loss: 1.834509685475339

Epoch: 6| Step: 1
Training loss: 1.8567103147506714
Validation loss: 1.8250470661347913

Epoch: 6| Step: 2
Training loss: 1.824313998222351
Validation loss: 1.836964161165299

Epoch: 6| Step: 3
Training loss: 1.6858431100845337
Validation loss: 1.8451852695916289

Epoch: 6| Step: 4
Training loss: 0.970966100692749
Validation loss: 1.8602448932586177

Epoch: 6| Step: 5
Training loss: 1.9617244005203247
Validation loss: 1.8562718514473207

Epoch: 6| Step: 6
Training loss: 1.6009396314620972
Validation loss: 1.8788006754331692

Epoch: 6| Step: 7
Training loss: 1.9270079135894775
Validation loss: 1.8866812606011667

Epoch: 6| Step: 8
Training loss: 1.549011468887329
Validation loss: 1.9039951409063032

Epoch: 6| Step: 9
Training loss: 1.8607559204101562
Validation loss: 1.8939849945806688

Epoch: 6| Step: 10
Training loss: 1.5907628536224365
Validation loss: 1.8961726439896451

Epoch: 6| Step: 11
Training loss: 2.220724105834961
Validation loss: 1.9185349172161472

Epoch: 6| Step: 12
Training loss: 2.269758701324463
Validation loss: 1.9133053928293207

Epoch: 6| Step: 13
Training loss: 2.4733495712280273
Validation loss: 1.9082038184647918

Epoch: 182| Step: 0
Training loss: 1.4494502544403076
Validation loss: 1.894883035331644

Epoch: 6| Step: 1
Training loss: 2.2270240783691406
Validation loss: 1.87481140834029

Epoch: 6| Step: 2
Training loss: 2.4394242763519287
Validation loss: 1.878231466457408

Epoch: 6| Step: 3
Training loss: 2.0258727073669434
Validation loss: 1.8805772527571647

Epoch: 6| Step: 4
Training loss: 1.898310899734497
Validation loss: 1.8779040254572386

Epoch: 6| Step: 5
Training loss: 2.1865768432617188
Validation loss: 1.871222439632621

Epoch: 6| Step: 6
Training loss: 2.054291248321533
Validation loss: 1.8870641159754928

Epoch: 6| Step: 7
Training loss: 2.393972873687744
Validation loss: 1.8951312547088952

Epoch: 6| Step: 8
Training loss: 1.0439512729644775
Validation loss: 1.8937022057912682

Epoch: 6| Step: 9
Training loss: 2.0994043350219727
Validation loss: 1.8641261310987576

Epoch: 6| Step: 10
Training loss: 1.5497103929519653
Validation loss: 1.8660977489204817

Epoch: 6| Step: 11
Training loss: 1.9600907564163208
Validation loss: 1.8482409055515001

Epoch: 6| Step: 12
Training loss: 1.5216948986053467
Validation loss: 1.8487153886466898

Epoch: 6| Step: 13
Training loss: 0.9448481798171997
Validation loss: 1.871512984716764

Epoch: 183| Step: 0
Training loss: 1.1610901355743408
Validation loss: 1.893629336869845

Epoch: 6| Step: 1
Training loss: 2.2184934616088867
Validation loss: 1.9389439936607116

Epoch: 6| Step: 2
Training loss: 1.9752049446105957
Validation loss: 1.9510323386038504

Epoch: 6| Step: 3
Training loss: 1.439768671989441
Validation loss: 1.9486991615705593

Epoch: 6| Step: 4
Training loss: 2.0002238750457764
Validation loss: 1.9303042991186983

Epoch: 6| Step: 5
Training loss: 2.4795639514923096
Validation loss: 1.9116376446139427

Epoch: 6| Step: 6
Training loss: 1.4081804752349854
Validation loss: 1.9075582924709524

Epoch: 6| Step: 7
Training loss: 2.5545597076416016
Validation loss: 1.8926414623055408

Epoch: 6| Step: 8
Training loss: 1.3517251014709473
Validation loss: 1.8951122119862547

Epoch: 6| Step: 9
Training loss: 3.055692672729492
Validation loss: 1.898438278064933

Epoch: 6| Step: 10
Training loss: 1.7137244939804077
Validation loss: 1.895214505093072

Epoch: 6| Step: 11
Training loss: 1.6936225891113281
Validation loss: 1.905915311587754

Epoch: 6| Step: 12
Training loss: 1.6326255798339844
Validation loss: 1.9234682821458386

Epoch: 6| Step: 13
Training loss: 1.279394507408142
Validation loss: 1.9368858350220548

Epoch: 184| Step: 0
Training loss: 1.2499696016311646
Validation loss: 1.9284548592823807

Epoch: 6| Step: 1
Training loss: 2.0745863914489746
Validation loss: 1.9194871123119066

Epoch: 6| Step: 2
Training loss: 2.112180233001709
Validation loss: 1.9174948892285746

Epoch: 6| Step: 3
Training loss: 1.7058062553405762
Validation loss: 1.9029558550926946

Epoch: 6| Step: 4
Training loss: 1.8285820484161377
Validation loss: 1.8828523005208662

Epoch: 6| Step: 5
Training loss: 2.049347400665283
Validation loss: 1.8591297147094563

Epoch: 6| Step: 6
Training loss: 1.9130513668060303
Validation loss: 1.8457777782153058

Epoch: 6| Step: 7
Training loss: 2.327155113220215
Validation loss: 1.8399133118250037

Epoch: 6| Step: 8
Training loss: 1.5631928443908691
Validation loss: 1.8325984093450731

Epoch: 6| Step: 9
Training loss: 2.3323357105255127
Validation loss: 1.845973253250122

Epoch: 6| Step: 10
Training loss: 1.6549012660980225
Validation loss: 1.8289019279582526

Epoch: 6| Step: 11
Training loss: 1.8635998964309692
Validation loss: 1.8224942376536708

Epoch: 6| Step: 12
Training loss: 1.4495062828063965
Validation loss: 1.841774259844134

Epoch: 6| Step: 13
Training loss: 1.6816221475601196
Validation loss: 1.859111411597139

Epoch: 185| Step: 0
Training loss: 2.1935882568359375
Validation loss: 1.903925690599667

Epoch: 6| Step: 1
Training loss: 1.4612442255020142
Validation loss: 1.9459196136843773

Epoch: 6| Step: 2
Training loss: 1.6146457195281982
Validation loss: 1.9583122627709502

Epoch: 6| Step: 3
Training loss: 2.21042799949646
Validation loss: 1.9629575924206806

Epoch: 6| Step: 4
Training loss: 1.6629722118377686
Validation loss: 1.9422093873382897

Epoch: 6| Step: 5
Training loss: 1.7483599185943604
Validation loss: 1.8913499821898758

Epoch: 6| Step: 6
Training loss: 1.9490418434143066
Validation loss: 1.8548539069391066

Epoch: 6| Step: 7
Training loss: 1.320990800857544
Validation loss: 1.8520760356739003

Epoch: 6| Step: 8
Training loss: 1.898146152496338
Validation loss: 1.8519534513514528

Epoch: 6| Step: 9
Training loss: 1.7307848930358887
Validation loss: 1.8580152808978994

Epoch: 6| Step: 10
Training loss: 1.7342712879180908
Validation loss: 1.864513171616421

Epoch: 6| Step: 11
Training loss: 2.340439796447754
Validation loss: 1.883614892600685

Epoch: 6| Step: 12
Training loss: 2.2367610931396484
Validation loss: 1.9077081244478944

Epoch: 6| Step: 13
Training loss: 1.91111421585083
Validation loss: 1.9343179912977322

Epoch: 186| Step: 0
Training loss: 1.6511197090148926
Validation loss: 1.941248106700118

Epoch: 6| Step: 1
Training loss: 1.5166124105453491
Validation loss: 1.9674326360866587

Epoch: 6| Step: 2
Training loss: 2.2711472511291504
Validation loss: 1.9579443829033965

Epoch: 6| Step: 3
Training loss: 1.7802419662475586
Validation loss: 1.9622559688424552

Epoch: 6| Step: 4
Training loss: 2.581498146057129
Validation loss: 1.9627079681683612

Epoch: 6| Step: 5
Training loss: 1.4589588642120361
Validation loss: 1.9608499837178055

Epoch: 6| Step: 6
Training loss: 2.029148817062378
Validation loss: 1.9665919337221371

Epoch: 6| Step: 7
Training loss: 2.076265811920166
Validation loss: 1.958438750236265

Epoch: 6| Step: 8
Training loss: 1.4770119190216064
Validation loss: 1.953479141317388

Epoch: 6| Step: 9
Training loss: 1.3481028079986572
Validation loss: 1.9283985912158925

Epoch: 6| Step: 10
Training loss: 1.7928025722503662
Validation loss: 1.9061205746025167

Epoch: 6| Step: 11
Training loss: 1.7187901735305786
Validation loss: 1.8875218194018129

Epoch: 6| Step: 12
Training loss: 1.9104163646697998
Validation loss: 1.8867918663127448

Epoch: 6| Step: 13
Training loss: 2.5315492153167725
Validation loss: 1.8645949312435683

Epoch: 187| Step: 0
Training loss: 2.258124351501465
Validation loss: 1.8600116916882095

Epoch: 6| Step: 1
Training loss: 2.0021018981933594
Validation loss: 1.8817781068945443

Epoch: 6| Step: 2
Training loss: 1.7866559028625488
Validation loss: 1.8863220163570937

Epoch: 6| Step: 3
Training loss: 0.9297345280647278
Validation loss: 1.8738115833651634

Epoch: 6| Step: 4
Training loss: 2.3421411514282227
Validation loss: 1.867951093181487

Epoch: 6| Step: 5
Training loss: 2.0545144081115723
Validation loss: 1.8669227323224467

Epoch: 6| Step: 6
Training loss: 2.6716034412384033
Validation loss: 1.8619103418883456

Epoch: 6| Step: 7
Training loss: 1.232808232307434
Validation loss: 1.8628422829412645

Epoch: 6| Step: 8
Training loss: 1.7543549537658691
Validation loss: 1.875315123988736

Epoch: 6| Step: 9
Training loss: 1.5673236846923828
Validation loss: 1.8810022992472495

Epoch: 6| Step: 10
Training loss: 1.8236340284347534
Validation loss: 1.8844478335431827

Epoch: 6| Step: 11
Training loss: 1.5546271800994873
Validation loss: 1.9030698883918025

Epoch: 6| Step: 12
Training loss: 1.4010486602783203
Validation loss: 1.9373985221309047

Epoch: 6| Step: 13
Training loss: 1.9960882663726807
Validation loss: 1.9609752226901311

Epoch: 188| Step: 0
Training loss: 2.7938077449798584
Validation loss: 1.9842522836500598

Epoch: 6| Step: 1
Training loss: 1.877272367477417
Validation loss: 1.9667449920408187

Epoch: 6| Step: 2
Training loss: 2.158958911895752
Validation loss: 1.9690262527876004

Epoch: 6| Step: 3
Training loss: 1.0329501628875732
Validation loss: 1.9611874870074693

Epoch: 6| Step: 4
Training loss: 2.326122999191284
Validation loss: 1.947559195180093

Epoch: 6| Step: 5
Training loss: 1.1069424152374268
Validation loss: 1.9220540702983897

Epoch: 6| Step: 6
Training loss: 1.2968922853469849
Validation loss: 1.9152448946429836

Epoch: 6| Step: 7
Training loss: 2.1167373657226562
Validation loss: 1.9003504373693978

Epoch: 6| Step: 8
Training loss: 1.5077624320983887
Validation loss: 1.8882097762118104

Epoch: 6| Step: 9
Training loss: 2.230316162109375
Validation loss: 1.8751221279944144

Epoch: 6| Step: 10
Training loss: 1.209264874458313
Validation loss: 1.8586802021149667

Epoch: 6| Step: 11
Training loss: 2.1202235221862793
Validation loss: 1.8499435699114235

Epoch: 6| Step: 12
Training loss: 1.9850952625274658
Validation loss: 1.854731155980018

Epoch: 6| Step: 13
Training loss: 1.2789090871810913
Validation loss: 1.8536203599745227

Epoch: 189| Step: 0
Training loss: 1.5146586894989014
Validation loss: 1.855971441474012

Epoch: 6| Step: 1
Training loss: 2.642035722732544
Validation loss: 1.8742831394236574

Epoch: 6| Step: 2
Training loss: 2.1090128421783447
Validation loss: 1.8899436420009983

Epoch: 6| Step: 3
Training loss: 1.3172941207885742
Validation loss: 1.8974319414425922

Epoch: 6| Step: 4
Training loss: 1.6570122241973877
Validation loss: 1.9194775999233287

Epoch: 6| Step: 5
Training loss: 1.8016277551651
Validation loss: 1.9343931982594151

Epoch: 6| Step: 6
Training loss: 1.6853153705596924
Validation loss: 1.9312610433947655

Epoch: 6| Step: 7
Training loss: 1.5087056159973145
Validation loss: 1.933810362251856

Epoch: 6| Step: 8
Training loss: 2.022341012954712
Validation loss: 1.9474035873207995

Epoch: 6| Step: 9
Training loss: 2.0453829765319824
Validation loss: 1.9400457361693024

Epoch: 6| Step: 10
Training loss: 2.012312412261963
Validation loss: 1.9081474683618034

Epoch: 6| Step: 11
Training loss: 1.9591538906097412
Validation loss: 1.9018316384284728

Epoch: 6| Step: 12
Training loss: 1.1828776597976685
Validation loss: 1.9032279060732933

Epoch: 6| Step: 13
Training loss: 1.8765826225280762
Validation loss: 1.9048045707005326

Epoch: 190| Step: 0
Training loss: 1.8656280040740967
Validation loss: 1.8915051337211364

Epoch: 6| Step: 1
Training loss: 1.6628385782241821
Validation loss: 1.8821673854704826

Epoch: 6| Step: 2
Training loss: 1.7601624727249146
Validation loss: 1.8596502734768776

Epoch: 6| Step: 3
Training loss: 1.9363682270050049
Validation loss: 1.8485159694507558

Epoch: 6| Step: 4
Training loss: 1.6858128309249878
Validation loss: 1.8527246547001663

Epoch: 6| Step: 5
Training loss: 1.640121579170227
Validation loss: 1.8509652755593742

Epoch: 6| Step: 6
Training loss: 2.249277114868164
Validation loss: 1.857135049758419

Epoch: 6| Step: 7
Training loss: 1.9004682302474976
Validation loss: 1.8775310234356952

Epoch: 6| Step: 8
Training loss: 1.5366413593292236
Validation loss: 1.88245052419683

Epoch: 6| Step: 9
Training loss: 1.4397227764129639
Validation loss: 1.8995786431015178

Epoch: 6| Step: 10
Training loss: 2.0575203895568848
Validation loss: 1.9044701194250455

Epoch: 6| Step: 11
Training loss: 1.7011280059814453
Validation loss: 1.9036512746605823

Epoch: 6| Step: 12
Training loss: 2.532853603363037
Validation loss: 1.892753626710625

Epoch: 6| Step: 13
Training loss: 1.1328188180923462
Validation loss: 1.9067332154961043

Epoch: 191| Step: 0
Training loss: 1.6825001239776611
Validation loss: 1.8894185673805974

Epoch: 6| Step: 1
Training loss: 1.5285568237304688
Validation loss: 1.8936148689639183

Epoch: 6| Step: 2
Training loss: 2.350048542022705
Validation loss: 1.8812955028267317

Epoch: 6| Step: 3
Training loss: 1.317520022392273
Validation loss: 1.8900519135177776

Epoch: 6| Step: 4
Training loss: 1.5914549827575684
Validation loss: 1.891057801503007

Epoch: 6| Step: 5
Training loss: 1.7876543998718262
Validation loss: 1.9131245805371193

Epoch: 6| Step: 6
Training loss: 2.198270082473755
Validation loss: 1.9098579729757001

Epoch: 6| Step: 7
Training loss: 1.6937649250030518
Validation loss: 1.9234817527955579

Epoch: 6| Step: 8
Training loss: 1.8997383117675781
Validation loss: 1.9290197985146635

Epoch: 6| Step: 9
Training loss: 2.4901514053344727
Validation loss: 1.9496932516815841

Epoch: 6| Step: 10
Training loss: 1.2395082712173462
Validation loss: 1.9705505396730156

Epoch: 6| Step: 11
Training loss: 1.4587687253952026
Validation loss: 1.9734216044026036

Epoch: 6| Step: 12
Training loss: 1.4144129753112793
Validation loss: 1.9537092857463385

Epoch: 6| Step: 13
Training loss: 2.6416540145874023
Validation loss: 1.9642738706322127

Epoch: 192| Step: 0
Training loss: 1.246910572052002
Validation loss: 1.9375384981914232

Epoch: 6| Step: 1
Training loss: 2.075550079345703
Validation loss: 1.8964327496867026

Epoch: 6| Step: 2
Training loss: 2.2787747383117676
Validation loss: 1.884594061041391

Epoch: 6| Step: 3
Training loss: 1.4081780910491943
Validation loss: 1.8689951909485685

Epoch: 6| Step: 4
Training loss: 1.7780048847198486
Validation loss: 1.878127763348241

Epoch: 6| Step: 5
Training loss: 1.7419514656066895
Validation loss: 1.8866485844376266

Epoch: 6| Step: 6
Training loss: 1.76828932762146
Validation loss: 1.8791905141645862

Epoch: 6| Step: 7
Training loss: 2.2607784271240234
Validation loss: 1.8405549692851242

Epoch: 6| Step: 8
Training loss: 1.4643528461456299
Validation loss: 1.8455670623369114

Epoch: 6| Step: 9
Training loss: 1.70504891872406
Validation loss: 1.8571034221238987

Epoch: 6| Step: 10
Training loss: 1.3586630821228027
Validation loss: 1.8317260319186794

Epoch: 6| Step: 11
Training loss: 2.662567138671875
Validation loss: 1.842898916172725

Epoch: 6| Step: 12
Training loss: 1.682869553565979
Validation loss: 1.8632410559602963

Epoch: 6| Step: 13
Training loss: 2.0288443565368652
Validation loss: 1.922587570323739

Epoch: 193| Step: 0
Training loss: 1.288539171218872
Validation loss: 1.9450423204770653

Epoch: 6| Step: 1
Training loss: 2.2487709522247314
Validation loss: 1.9807632007906515

Epoch: 6| Step: 2
Training loss: 1.2778860330581665
Validation loss: 2.011297591270939

Epoch: 6| Step: 3
Training loss: 2.16780686378479
Validation loss: 1.976674336259083

Epoch: 6| Step: 4
Training loss: 1.8731751441955566
Validation loss: 1.9572776004832277

Epoch: 6| Step: 5
Training loss: 1.5151557922363281
Validation loss: 1.906534300055555

Epoch: 6| Step: 6
Training loss: 2.1384096145629883
Validation loss: 1.8563156589385001

Epoch: 6| Step: 7
Training loss: 2.0547287464141846
Validation loss: 1.8400601187059957

Epoch: 6| Step: 8
Training loss: 1.9566800594329834
Validation loss: 1.8407001764543596

Epoch: 6| Step: 9
Training loss: 1.2184538841247559
Validation loss: 1.85215590846154

Epoch: 6| Step: 10
Training loss: 2.3325343132019043
Validation loss: 1.901176869228322

Epoch: 6| Step: 11
Training loss: 2.3870139122009277
Validation loss: 1.9005801780249483

Epoch: 6| Step: 12
Training loss: 1.7719509601593018
Validation loss: 1.9276494877312773

Epoch: 6| Step: 13
Training loss: 0.9102684855461121
Validation loss: 1.8993646906268211

Epoch: 194| Step: 0
Training loss: 2.2893810272216797
Validation loss: 1.914053250384587

Epoch: 6| Step: 1
Training loss: 1.9108984470367432
Validation loss: 1.9031081302191621

Epoch: 6| Step: 2
Training loss: 1.778854250907898
Validation loss: 1.8925986930888186

Epoch: 6| Step: 3
Training loss: 2.1008729934692383
Validation loss: 1.854848519448311

Epoch: 6| Step: 4
Training loss: 1.9022005796432495
Validation loss: 1.8355113216625747

Epoch: 6| Step: 5
Training loss: 1.4865827560424805
Validation loss: 1.8209260676496772

Epoch: 6| Step: 6
Training loss: 1.989408254623413
Validation loss: 1.829645586270158

Epoch: 6| Step: 7
Training loss: 2.0287792682647705
Validation loss: 1.8677411181952364

Epoch: 6| Step: 8
Training loss: 1.1873564720153809
Validation loss: 1.896237555370536

Epoch: 6| Step: 9
Training loss: 1.7307277917861938
Validation loss: 1.9083311429587744

Epoch: 6| Step: 10
Training loss: 1.3125675916671753
Validation loss: 1.9414595083523822

Epoch: 6| Step: 11
Training loss: 1.9994235038757324
Validation loss: 1.9429570692841724

Epoch: 6| Step: 12
Training loss: 1.6560118198394775
Validation loss: 1.9392098124309252

Epoch: 6| Step: 13
Training loss: 1.7197299003601074
Validation loss: 1.9640269228207168

Epoch: 195| Step: 0
Training loss: 1.501084804534912
Validation loss: 1.9472653647904754

Epoch: 6| Step: 1
Training loss: 1.7540020942687988
Validation loss: 1.952999839218714

Epoch: 6| Step: 2
Training loss: 2.2631540298461914
Validation loss: 1.9516875641320341

Epoch: 6| Step: 3
Training loss: 1.834397315979004
Validation loss: 1.9430457225409887

Epoch: 6| Step: 4
Training loss: 2.1934027671813965
Validation loss: 1.9214296443488008

Epoch: 6| Step: 5
Training loss: 1.6208441257476807
Validation loss: 1.9204701428772302

Epoch: 6| Step: 6
Training loss: 1.2601618766784668
Validation loss: 1.9169959265698668

Epoch: 6| Step: 7
Training loss: 2.5513527393341064
Validation loss: 1.9428433013218704

Epoch: 6| Step: 8
Training loss: 1.1506588459014893
Validation loss: 1.9213623154547907

Epoch: 6| Step: 9
Training loss: 2.3253962993621826
Validation loss: 1.9149518653910647

Epoch: 6| Step: 10
Training loss: 1.5162712335586548
Validation loss: 1.9033415727717902

Epoch: 6| Step: 11
Training loss: 1.67585027217865
Validation loss: 1.8645975282115321

Epoch: 6| Step: 12
Training loss: 1.9850211143493652
Validation loss: 1.8473042698316677

Epoch: 6| Step: 13
Training loss: 1.3309327363967896
Validation loss: 1.8399680583707747

Epoch: 196| Step: 0
Training loss: 1.8118507862091064
Validation loss: 1.8335571660790393

Epoch: 6| Step: 1
Training loss: 0.9243699312210083
Validation loss: 1.8540472061403337

Epoch: 6| Step: 2
Training loss: 1.8235890865325928
Validation loss: 1.8510436678445468

Epoch: 6| Step: 3
Training loss: 2.1898856163024902
Validation loss: 1.8615148631475305

Epoch: 6| Step: 4
Training loss: 2.130751848220825
Validation loss: 1.8733648433480212

Epoch: 6| Step: 5
Training loss: 1.79338800907135
Validation loss: 1.8807701218512751

Epoch: 6| Step: 6
Training loss: 1.7541728019714355
Validation loss: 1.8866876991846229

Epoch: 6| Step: 7
Training loss: 1.4101886749267578
Validation loss: 1.8853835367387342

Epoch: 6| Step: 8
Training loss: 2.6290745735168457
Validation loss: 1.8705709121560539

Epoch: 6| Step: 9
Training loss: 1.5947586297988892
Validation loss: 1.8893332186565603

Epoch: 6| Step: 10
Training loss: 1.840181827545166
Validation loss: 1.9081812212544103

Epoch: 6| Step: 11
Training loss: 1.5201382637023926
Validation loss: 1.9018427274560417

Epoch: 6| Step: 12
Training loss: 1.2596087455749512
Validation loss: 1.942404225308408

Epoch: 6| Step: 13
Training loss: 1.8501826524734497
Validation loss: 1.9461055686396938

Epoch: 197| Step: 0
Training loss: 2.3733279705047607
Validation loss: 1.9731561406966178

Epoch: 6| Step: 1
Training loss: 2.3531765937805176
Validation loss: 1.9767998367227533

Epoch: 6| Step: 2
Training loss: 1.056707501411438
Validation loss: 1.9730681578318279

Epoch: 6| Step: 3
Training loss: 1.2434509992599487
Validation loss: 1.9555761660298994

Epoch: 6| Step: 4
Training loss: 1.6379411220550537
Validation loss: 1.945749270018711

Epoch: 6| Step: 5
Training loss: 1.7130513191223145
Validation loss: 1.9121869712747552

Epoch: 6| Step: 6
Training loss: 1.6126956939697266
Validation loss: 1.9085779625882384

Epoch: 6| Step: 7
Training loss: 2.1099019050598145
Validation loss: 1.879421826331846

Epoch: 6| Step: 8
Training loss: 2.129061222076416
Validation loss: 1.8750288665935557

Epoch: 6| Step: 9
Training loss: 2.0791258811950684
Validation loss: 1.8574206854707451

Epoch: 6| Step: 10
Training loss: 1.6949782371520996
Validation loss: 1.8852101628498366

Epoch: 6| Step: 11
Training loss: 1.063201904296875
Validation loss: 1.913288693274221

Epoch: 6| Step: 12
Training loss: 1.4540338516235352
Validation loss: 1.917871964875088

Epoch: 6| Step: 13
Training loss: 1.6040034294128418
Validation loss: 1.924378010534471

Epoch: 198| Step: 0
Training loss: 1.0873234272003174
Validation loss: 1.9350824740625197

Epoch: 6| Step: 1
Training loss: 1.772955298423767
Validation loss: 1.9262573975388722

Epoch: 6| Step: 2
Training loss: 1.7131192684173584
Validation loss: 1.897646910400801

Epoch: 6| Step: 3
Training loss: 1.4290361404418945
Validation loss: 1.8689930259540517

Epoch: 6| Step: 4
Training loss: 1.5590479373931885
Validation loss: 1.8497087596565165

Epoch: 6| Step: 5
Training loss: 2.2304961681365967
Validation loss: 1.8357210518211446

Epoch: 6| Step: 6
Training loss: 1.9794270992279053
Validation loss: 1.850383286835045

Epoch: 6| Step: 7
Training loss: 1.8526060581207275
Validation loss: 1.8525360399676907

Epoch: 6| Step: 8
Training loss: 1.91264808177948
Validation loss: 1.860042187475389

Epoch: 6| Step: 9
Training loss: 2.104583740234375
Validation loss: 1.8573019927547825

Epoch: 6| Step: 10
Training loss: 1.4656178951263428
Validation loss: 1.8389816207270469

Epoch: 6| Step: 11
Training loss: 1.7137218713760376
Validation loss: 1.8460796417728547

Epoch: 6| Step: 12
Training loss: 1.9699838161468506
Validation loss: 1.8816464511297082

Epoch: 6| Step: 13
Training loss: 2.0778985023498535
Validation loss: 1.922466024275749

Epoch: 199| Step: 0
Training loss: 1.8071335554122925
Validation loss: 1.9511448811459284

Epoch: 6| Step: 1
Training loss: 1.6469883918762207
Validation loss: 1.9866696378236175

Epoch: 6| Step: 2
Training loss: 1.657476782798767
Validation loss: 1.9818570024223738

Epoch: 6| Step: 3
Training loss: 1.3733469247817993
Validation loss: 1.9412330773568922

Epoch: 6| Step: 4
Training loss: 2.164947032928467
Validation loss: 1.9269151226166756

Epoch: 6| Step: 5
Training loss: 1.35166335105896
Validation loss: 1.9182096424923147

Epoch: 6| Step: 6
Training loss: 2.263947010040283
Validation loss: 1.9159159429611698

Epoch: 6| Step: 7
Training loss: 1.1892825365066528
Validation loss: 1.9344940236819688

Epoch: 6| Step: 8
Training loss: 2.0228190422058105
Validation loss: 1.9235367672417754

Epoch: 6| Step: 9
Training loss: 2.091782569885254
Validation loss: 1.9355911131828063

Epoch: 6| Step: 10
Training loss: 1.8335752487182617
Validation loss: 1.9228383007869925

Epoch: 6| Step: 11
Training loss: 1.5006837844848633
Validation loss: 1.924259921555878

Epoch: 6| Step: 12
Training loss: 1.8167372941970825
Validation loss: 1.9427857924533147

Epoch: 6| Step: 13
Training loss: 1.853142261505127
Validation loss: 1.9921858208153838

Epoch: 200| Step: 0
Training loss: 1.803879737854004
Validation loss: 1.997893717981154

Epoch: 6| Step: 1
Training loss: 1.6013782024383545
Validation loss: 2.002803051343528

Epoch: 6| Step: 2
Training loss: 1.9622280597686768
Validation loss: 1.9991393102112638

Epoch: 6| Step: 3
Training loss: 1.7341039180755615
Validation loss: 1.9602301838577434

Epoch: 6| Step: 4
Training loss: 2.079951286315918
Validation loss: 1.9194661212223831

Epoch: 6| Step: 5
Training loss: 1.495670199394226
Validation loss: 1.8826523801331878

Epoch: 6| Step: 6
Training loss: 1.944016933441162
Validation loss: 1.8726932002652077

Epoch: 6| Step: 7
Training loss: 1.3655508756637573
Validation loss: 1.8434478954602314

Epoch: 6| Step: 8
Training loss: 2.053312301635742
Validation loss: 1.835124320881341

Epoch: 6| Step: 9
Training loss: 2.074298858642578
Validation loss: 1.8425542539165867

Epoch: 6| Step: 10
Training loss: 1.7814356088638306
Validation loss: 1.8499647494285338

Epoch: 6| Step: 11
Training loss: 1.1559933423995972
Validation loss: 1.87227617027939

Epoch: 6| Step: 12
Training loss: 1.9266297817230225
Validation loss: 1.8874454344472578

Epoch: 6| Step: 13
Training loss: 0.3028545379638672
Validation loss: 1.890081081339108

Epoch: 201| Step: 0
Training loss: 1.5747601985931396
Validation loss: 1.9051250360345329

Epoch: 6| Step: 1
Training loss: 1.643041968345642
Validation loss: 1.9215167312211887

Epoch: 6| Step: 2
Training loss: 1.707526445388794
Validation loss: 1.9290755205256964

Epoch: 6| Step: 3
Training loss: 1.7518701553344727
Validation loss: 1.9576415054259761

Epoch: 6| Step: 4
Training loss: 1.4994392395019531
Validation loss: 1.9695566290168351

Epoch: 6| Step: 5
Training loss: 1.5268701314926147
Validation loss: 1.974182403215798

Epoch: 6| Step: 6
Training loss: 1.438669204711914
Validation loss: 1.967763534156225

Epoch: 6| Step: 7
Training loss: 2.5125539302825928
Validation loss: 1.9557144667512627

Epoch: 6| Step: 8
Training loss: 2.532297372817993
Validation loss: 1.9594724152677803

Epoch: 6| Step: 9
Training loss: 2.086550235748291
Validation loss: 1.9383838868910266

Epoch: 6| Step: 10
Training loss: 1.6274791955947876
Validation loss: 1.9298608597888742

Epoch: 6| Step: 11
Training loss: 1.133095145225525
Validation loss: 1.9152954573272376

Epoch: 6| Step: 12
Training loss: 1.1946884393692017
Validation loss: 1.8880864163880706

Epoch: 6| Step: 13
Training loss: 0.8533690571784973
Validation loss: 1.8675699900555354

Epoch: 202| Step: 0
Training loss: 1.5901494026184082
Validation loss: 1.8797354826363184

Epoch: 6| Step: 1
Training loss: 1.6052213907241821
Validation loss: 1.8620797511070006

Epoch: 6| Step: 2
Training loss: 1.633981704711914
Validation loss: 1.8614265816186064

Epoch: 6| Step: 3
Training loss: 2.0676181316375732
Validation loss: 1.860857170115235

Epoch: 6| Step: 4
Training loss: 1.6193424463272095
Validation loss: 1.861009874651509

Epoch: 6| Step: 5
Training loss: 1.2675007581710815
Validation loss: 1.8807050310155398

Epoch: 6| Step: 6
Training loss: 1.5948801040649414
Validation loss: 1.8973957928278113

Epoch: 6| Step: 7
Training loss: 1.49654221534729
Validation loss: 1.915489645414455

Epoch: 6| Step: 8
Training loss: 1.0648387670516968
Validation loss: 1.9194085162173036

Epoch: 6| Step: 9
Training loss: 0.8511228561401367
Validation loss: 1.9372343491482478

Epoch: 6| Step: 10
Training loss: 2.4259355068206787
Validation loss: 1.9785142406340568

Epoch: 6| Step: 11
Training loss: 1.9995594024658203
Validation loss: 1.9945786537662629

Epoch: 6| Step: 12
Training loss: 1.9006861448287964
Validation loss: 2.001539373910555

Epoch: 6| Step: 13
Training loss: 2.839354991912842
Validation loss: 1.9779320980912896

Epoch: 203| Step: 0
Training loss: 2.051537275314331
Validation loss: 1.9934525874353224

Epoch: 6| Step: 1
Training loss: 1.625762939453125
Validation loss: 1.957309579336515

Epoch: 6| Step: 2
Training loss: 1.5613491535186768
Validation loss: 1.945138221145958

Epoch: 6| Step: 3
Training loss: 2.196424722671509
Validation loss: 1.9520154838920922

Epoch: 6| Step: 4
Training loss: 1.4782195091247559
Validation loss: 1.9627563568853563

Epoch: 6| Step: 5
Training loss: 1.8651516437530518
Validation loss: 1.9387113458366805

Epoch: 6| Step: 6
Training loss: 1.7520220279693604
Validation loss: 1.942360895936207

Epoch: 6| Step: 7
Training loss: 0.909580409526825
Validation loss: 1.9309881630764212

Epoch: 6| Step: 8
Training loss: 1.967574119567871
Validation loss: 1.9362572136745657

Epoch: 6| Step: 9
Training loss: 2.0068931579589844
Validation loss: 1.924787675180743

Epoch: 6| Step: 10
Training loss: 1.2507928609848022
Validation loss: 1.9219133213002195

Epoch: 6| Step: 11
Training loss: 1.3004841804504395
Validation loss: 1.9215615795504661

Epoch: 6| Step: 12
Training loss: 1.9756863117218018
Validation loss: 1.9292362159298313

Epoch: 6| Step: 13
Training loss: 1.4216876029968262
Validation loss: 1.9357852448699295

Epoch: 204| Step: 0
Training loss: 1.7865252494812012
Validation loss: 1.9292557675351378

Epoch: 6| Step: 1
Training loss: 1.6409327983856201
Validation loss: 1.95538495432946

Epoch: 6| Step: 2
Training loss: 1.686906337738037
Validation loss: 1.9336330095926921

Epoch: 6| Step: 3
Training loss: 1.9753761291503906
Validation loss: 1.9335253956497356

Epoch: 6| Step: 4
Training loss: 1.2908127307891846
Validation loss: 1.9098865614142468

Epoch: 6| Step: 5
Training loss: 2.1439504623413086
Validation loss: 1.8984748445531374

Epoch: 6| Step: 6
Training loss: 2.0353376865386963
Validation loss: 1.8881963965713338

Epoch: 6| Step: 7
Training loss: 2.2602174282073975
Validation loss: 1.8576688740843086

Epoch: 6| Step: 8
Training loss: 1.0552947521209717
Validation loss: 1.8590654583387478

Epoch: 6| Step: 9
Training loss: 1.3168504238128662
Validation loss: 1.8478007598589825

Epoch: 6| Step: 10
Training loss: 1.2595362663269043
Validation loss: 1.8736771691230036

Epoch: 6| Step: 11
Training loss: 1.344777226448059
Validation loss: 1.8874949665479763

Epoch: 6| Step: 12
Training loss: 2.0855655670166016
Validation loss: 1.90313813506916

Epoch: 6| Step: 13
Training loss: 1.2966864109039307
Validation loss: 1.9363512890313261

Epoch: 205| Step: 0
Training loss: 1.9958429336547852
Validation loss: 1.9362183373461488

Epoch: 6| Step: 1
Training loss: 1.128429889678955
Validation loss: 1.961365920241161

Epoch: 6| Step: 2
Training loss: 1.6401588916778564
Validation loss: 1.9963080754844091

Epoch: 6| Step: 3
Training loss: 2.0264692306518555
Validation loss: 2.014196313837523

Epoch: 6| Step: 4
Training loss: 1.804893136024475
Validation loss: 2.0313021341959634

Epoch: 6| Step: 5
Training loss: 2.177309513092041
Validation loss: 2.0863426616114955

Epoch: 6| Step: 6
Training loss: 1.4088093042373657
Validation loss: 2.125511651398033

Epoch: 6| Step: 7
Training loss: 2.1603055000305176
Validation loss: 2.145657411185644

Epoch: 6| Step: 8
Training loss: 1.6261720657348633
Validation loss: 2.0857063698512253

Epoch: 6| Step: 9
Training loss: 1.5830190181732178
Validation loss: 2.0702187656074442

Epoch: 6| Step: 10
Training loss: 1.49842369556427
Validation loss: 2.0492773056030273

Epoch: 6| Step: 11
Training loss: 2.0302658081054688
Validation loss: 2.0017100226494575

Epoch: 6| Step: 12
Training loss: 1.3264338970184326
Validation loss: 1.989695095246838

Epoch: 6| Step: 13
Training loss: 0.9494771957397461
Validation loss: 1.9674592146309473

Epoch: 206| Step: 0
Training loss: 1.791488528251648
Validation loss: 1.991622894041

Epoch: 6| Step: 1
Training loss: 2.0838074684143066
Validation loss: 1.939407080732366

Epoch: 6| Step: 2
Training loss: 1.7121502161026
Validation loss: 1.8855079130459858

Epoch: 6| Step: 3
Training loss: 1.9265470504760742
Validation loss: 1.8510153267973213

Epoch: 6| Step: 4
Training loss: 1.839667558670044
Validation loss: 1.8171913264900126

Epoch: 6| Step: 5
Training loss: 1.6453171968460083
Validation loss: 1.7847259518920735

Epoch: 6| Step: 6
Training loss: 1.7404541969299316
Validation loss: 1.8185149059500745

Epoch: 6| Step: 7
Training loss: 1.486713171005249
Validation loss: 1.8488993388350292

Epoch: 6| Step: 8
Training loss: 2.0260863304138184
Validation loss: 1.8953021521209388

Epoch: 6| Step: 9
Training loss: 1.2680158615112305
Validation loss: 1.9120112260182698

Epoch: 6| Step: 10
Training loss: 2.4602131843566895
Validation loss: 1.9209723139321933

Epoch: 6| Step: 11
Training loss: 1.282141923904419
Validation loss: 1.9322614028889646

Epoch: 6| Step: 12
Training loss: 1.6355035305023193
Validation loss: 1.930644727522327

Epoch: 6| Step: 13
Training loss: 1.7553876638412476
Validation loss: 1.9477164283875497

Epoch: 207| Step: 0
Training loss: 2.5213186740875244
Validation loss: 1.9502437524898077

Epoch: 6| Step: 1
Training loss: 1.3490278720855713
Validation loss: 1.9189385367978005

Epoch: 6| Step: 2
Training loss: 1.5905382633209229
Validation loss: 1.9152265235941897

Epoch: 6| Step: 3
Training loss: 1.3506274223327637
Validation loss: 1.889261632837275

Epoch: 6| Step: 4
Training loss: 1.5270867347717285
Validation loss: 1.8860407695975354

Epoch: 6| Step: 5
Training loss: 1.8217012882232666
Validation loss: 1.8658016343270578

Epoch: 6| Step: 6
Training loss: 2.2049155235290527
Validation loss: 1.8653820471097065

Epoch: 6| Step: 7
Training loss: 1.7042282819747925
Validation loss: 1.8584217717570644

Epoch: 6| Step: 8
Training loss: 1.4911394119262695
Validation loss: 1.8359941974762948

Epoch: 6| Step: 9
Training loss: 1.749516248703003
Validation loss: 1.840130639332597

Epoch: 6| Step: 10
Training loss: 1.2180793285369873
Validation loss: 1.8486718490559568

Epoch: 6| Step: 11
Training loss: 1.5564649105072021
Validation loss: 1.8711175662215038

Epoch: 6| Step: 12
Training loss: 1.6794466972351074
Validation loss: 1.8639951188077208

Epoch: 6| Step: 13
Training loss: 1.3283886909484863
Validation loss: 1.9136050721650482

Epoch: 208| Step: 0
Training loss: 1.4434173107147217
Validation loss: 1.9476624893885788

Epoch: 6| Step: 1
Training loss: 1.267352819442749
Validation loss: 1.9937918724552277

Epoch: 6| Step: 2
Training loss: 1.9511735439300537
Validation loss: 2.0236212771425963

Epoch: 6| Step: 3
Training loss: 2.188910961151123
Validation loss: 2.040441584843461

Epoch: 6| Step: 4
Training loss: 1.3693383932113647
Validation loss: 2.0745522847739597

Epoch: 6| Step: 5
Training loss: 2.616360902786255
Validation loss: 2.0823193955165085

Epoch: 6| Step: 6
Training loss: 1.112452745437622
Validation loss: 2.0716533148160545

Epoch: 6| Step: 7
Training loss: 1.7994935512542725
Validation loss: 2.0531167227734803

Epoch: 6| Step: 8
Training loss: 2.1936254501342773
Validation loss: 1.9941376870678318

Epoch: 6| Step: 9
Training loss: 1.3843249082565308
Validation loss: 1.9676797518166163

Epoch: 6| Step: 10
Training loss: 1.629171371459961
Validation loss: 1.92512244947495

Epoch: 6| Step: 11
Training loss: 1.2128503322601318
Validation loss: 1.873186449850759

Epoch: 6| Step: 12
Training loss: 1.0767033100128174
Validation loss: 1.8645868019391132

Epoch: 6| Step: 13
Training loss: 1.777105450630188
Validation loss: 1.8283598192276493

Epoch: 209| Step: 0
Training loss: 1.4152666330337524
Validation loss: 1.8177028317605295

Epoch: 6| Step: 1
Training loss: 1.707869529724121
Validation loss: 1.8329146651811496

Epoch: 6| Step: 2
Training loss: 1.3565809726715088
Validation loss: 1.8130542142416841

Epoch: 6| Step: 3
Training loss: 1.5061283111572266
Validation loss: 1.8164937957640617

Epoch: 6| Step: 4
Training loss: 1.8034641742706299
Validation loss: 1.870022245632705

Epoch: 6| Step: 5
Training loss: 1.9649711847305298
Validation loss: 1.8454608660872265

Epoch: 6| Step: 6
Training loss: 1.302290439605713
Validation loss: 1.8804283513817737

Epoch: 6| Step: 7
Training loss: 1.1755433082580566
Validation loss: 1.902257566810936

Epoch: 6| Step: 8
Training loss: 1.3847298622131348
Validation loss: 1.9407038893750919

Epoch: 6| Step: 9
Training loss: 1.9414230585098267
Validation loss: 1.9707636179462555

Epoch: 6| Step: 10
Training loss: 2.02312970161438
Validation loss: 1.988409488431869

Epoch: 6| Step: 11
Training loss: 2.4882912635803223
Validation loss: 2.025462829938499

Epoch: 6| Step: 12
Training loss: 1.2554433345794678
Validation loss: 2.0214928439868394

Epoch: 6| Step: 13
Training loss: 1.4220006465911865
Validation loss: 2.047295283245784

Epoch: 210| Step: 0
Training loss: 2.3169243335723877
Validation loss: 2.027576895170314

Epoch: 6| Step: 1
Training loss: 1.9246158599853516
Validation loss: 2.0278104479594896

Epoch: 6| Step: 2
Training loss: 1.3745932579040527
Validation loss: 2.0100767048456336

Epoch: 6| Step: 3
Training loss: 1.6242530345916748
Validation loss: 1.9882339277575094

Epoch: 6| Step: 4
Training loss: 1.9541881084442139
Validation loss: 1.964393561886203

Epoch: 6| Step: 5
Training loss: 1.5220122337341309
Validation loss: 1.9488682413613925

Epoch: 6| Step: 6
Training loss: 1.4860543012619019
Validation loss: 1.945824403916636

Epoch: 6| Step: 7
Training loss: 1.1876455545425415
Validation loss: 1.9377227496075373

Epoch: 6| Step: 8
Training loss: 2.180546760559082
Validation loss: 1.964686491156137

Epoch: 6| Step: 9
Training loss: 1.9111356735229492
Validation loss: 1.971339169368949

Epoch: 6| Step: 10
Training loss: 1.0808242559432983
Validation loss: 1.9674522928012315

Epoch: 6| Step: 11
Training loss: 1.4161784648895264
Validation loss: 1.9924607071825253

Epoch: 6| Step: 12
Training loss: 1.0457099676132202
Validation loss: 2.0106505796473515

Epoch: 6| Step: 13
Training loss: 0.5913116931915283
Validation loss: 2.0011016245811217

Epoch: 211| Step: 0
Training loss: 1.063280701637268
Validation loss: 1.9797924628821753

Epoch: 6| Step: 1
Training loss: 1.105792760848999
Validation loss: 1.961943546930949

Epoch: 6| Step: 2
Training loss: 1.184722661972046
Validation loss: 1.9617313261955016

Epoch: 6| Step: 3
Training loss: 1.7157444953918457
Validation loss: 1.9452790931988788

Epoch: 6| Step: 4
Training loss: 1.1624529361724854
Validation loss: 1.9472177054292412

Epoch: 6| Step: 5
Training loss: 1.9038546085357666
Validation loss: 1.927180359440465

Epoch: 6| Step: 6
Training loss: 1.2755324840545654
Validation loss: 1.9484643564429334

Epoch: 6| Step: 7
Training loss: 1.5346424579620361
Validation loss: 1.973549601852253

Epoch: 6| Step: 8
Training loss: 2.4389376640319824
Validation loss: 1.9984002959343694

Epoch: 6| Step: 9
Training loss: 1.7324068546295166
Validation loss: 2.0085146068244852

Epoch: 6| Step: 10
Training loss: 1.5005736351013184
Validation loss: 1.9934362134625834

Epoch: 6| Step: 11
Training loss: 1.2493727207183838
Validation loss: 1.9787694856684694

Epoch: 6| Step: 12
Training loss: 2.4401400089263916
Validation loss: 1.9730039424793695

Epoch: 6| Step: 13
Training loss: 2.9116265773773193
Validation loss: 1.958416203016876

Epoch: 212| Step: 0
Training loss: 1.9012495279312134
Validation loss: 1.940756179953134

Epoch: 6| Step: 1
Training loss: 1.3755762577056885
Validation loss: 1.9403158182738929

Epoch: 6| Step: 2
Training loss: 2.1541666984558105
Validation loss: 1.9242802281533518

Epoch: 6| Step: 3
Training loss: 1.664491891860962
Validation loss: 1.9315900430884412

Epoch: 6| Step: 4
Training loss: 1.3082005977630615
Validation loss: 1.9206784963607788

Epoch: 6| Step: 5
Training loss: 1.2664589881896973
Validation loss: 1.9188098215287732

Epoch: 6| Step: 6
Training loss: 1.0078034400939941
Validation loss: 1.9666819380175682

Epoch: 6| Step: 7
Training loss: 1.727773666381836
Validation loss: 1.98695953430668

Epoch: 6| Step: 8
Training loss: 2.0970375537872314
Validation loss: 2.0057284229545185

Epoch: 6| Step: 9
Training loss: 1.5542900562286377
Validation loss: 1.9661370182550082

Epoch: 6| Step: 10
Training loss: 1.6624083518981934
Validation loss: 1.9791101127542474

Epoch: 6| Step: 11
Training loss: 1.568784475326538
Validation loss: 1.9769609705094369

Epoch: 6| Step: 12
Training loss: 1.6485185623168945
Validation loss: 2.0201408375975904

Epoch: 6| Step: 13
Training loss: 1.66609525680542
Validation loss: 2.048822388854078

Epoch: 213| Step: 0
Training loss: 1.4918460845947266
Validation loss: 2.0124919440156672

Epoch: 6| Step: 1
Training loss: 2.090579032897949
Validation loss: 2.00863778591156

Epoch: 6| Step: 2
Training loss: 1.743384599685669
Validation loss: 1.9906910478427846

Epoch: 6| Step: 3
Training loss: 1.5654699802398682
Validation loss: 1.981052690936673

Epoch: 6| Step: 4
Training loss: 1.8430131673812866
Validation loss: 1.9525035324917044

Epoch: 6| Step: 5
Training loss: 1.8256382942199707
Validation loss: 1.935874686446241

Epoch: 6| Step: 6
Training loss: 1.8046537637710571
Validation loss: 1.928429913777177

Epoch: 6| Step: 7
Training loss: 1.6230804920196533
Validation loss: 1.9138493512266426

Epoch: 6| Step: 8
Training loss: 1.624475359916687
Validation loss: 1.8741360569512973

Epoch: 6| Step: 9
Training loss: 1.4050354957580566
Validation loss: 1.8749394903900802

Epoch: 6| Step: 10
Training loss: 1.391024112701416
Validation loss: 1.847785993288922

Epoch: 6| Step: 11
Training loss: 1.1937202215194702
Validation loss: 1.8669248819351196

Epoch: 6| Step: 12
Training loss: 1.8608741760253906
Validation loss: 1.8887926109375492

Epoch: 6| Step: 13
Training loss: 1.7024426460266113
Validation loss: 1.909248698142267

Epoch: 214| Step: 0
Training loss: 1.2968977689743042
Validation loss: 1.955926933596211

Epoch: 6| Step: 1
Training loss: 1.852384328842163
Validation loss: 2.00099443363887

Epoch: 6| Step: 2
Training loss: 1.5792920589447021
Validation loss: 1.9940711836661063

Epoch: 6| Step: 3
Training loss: 1.4795422554016113
Validation loss: 1.9982639999799832

Epoch: 6| Step: 4
Training loss: 1.463008999824524
Validation loss: 1.975477110955023

Epoch: 6| Step: 5
Training loss: 1.3072803020477295
Validation loss: 1.9736415109326761

Epoch: 6| Step: 6
Training loss: 1.9975988864898682
Validation loss: 1.9947157700856526

Epoch: 6| Step: 7
Training loss: 1.008986234664917
Validation loss: 2.0021429728436213

Epoch: 6| Step: 8
Training loss: 1.3202533721923828
Validation loss: 2.028051536570313

Epoch: 6| Step: 9
Training loss: 2.186518907546997
Validation loss: 2.068681242645428

Epoch: 6| Step: 10
Training loss: 1.9103566408157349
Validation loss: 2.07077548837149

Epoch: 6| Step: 11
Training loss: 1.5359089374542236
Validation loss: 2.0451555841712543

Epoch: 6| Step: 12
Training loss: 1.4959923028945923
Validation loss: 2.0349458109947944

Epoch: 6| Step: 13
Training loss: 1.631896734237671
Validation loss: 2.0362831264413814

Epoch: 215| Step: 0
Training loss: 1.233508825302124
Validation loss: 2.0094709665544572

Epoch: 6| Step: 1
Training loss: 1.5229151248931885
Validation loss: 2.0008569263642833

Epoch: 6| Step: 2
Training loss: 2.207127809524536
Validation loss: 2.0092852679632043

Epoch: 6| Step: 3
Training loss: 1.7125201225280762
Validation loss: 2.0122302732160016

Epoch: 6| Step: 4
Training loss: 1.151073694229126
Validation loss: 2.0218210630519415

Epoch: 6| Step: 5
Training loss: 1.6328632831573486
Validation loss: 2.007347103088133

Epoch: 6| Step: 6
Training loss: 1.4777684211730957
Validation loss: 1.9739928655726935

Epoch: 6| Step: 7
Training loss: 1.234496831893921
Validation loss: 1.9664017205597253

Epoch: 6| Step: 8
Training loss: 1.4124748706817627
Validation loss: 1.946379925615044

Epoch: 6| Step: 9
Training loss: 1.267925500869751
Validation loss: 1.9220489481444

Epoch: 6| Step: 10
Training loss: 1.9090536832809448
Validation loss: 1.926165920431896

Epoch: 6| Step: 11
Training loss: 1.729629397392273
Validation loss: 1.9347728247283607

Epoch: 6| Step: 12
Training loss: 1.1355397701263428
Validation loss: 1.934125461886006

Epoch: 6| Step: 13
Training loss: 1.6246275901794434
Validation loss: 1.959163942644673

Epoch: 216| Step: 0
Training loss: 1.2653497457504272
Validation loss: 1.9633481835806241

Epoch: 6| Step: 1
Training loss: 1.6593971252441406
Validation loss: 1.9703883458209295

Epoch: 6| Step: 2
Training loss: 1.2686573266983032
Validation loss: 1.957857729286276

Epoch: 6| Step: 3
Training loss: 2.0925633907318115
Validation loss: 1.9643170679769208

Epoch: 6| Step: 4
Training loss: 1.0667001008987427
Validation loss: 1.9612977735457882

Epoch: 6| Step: 5
Training loss: 1.489945650100708
Validation loss: 1.9846993966769146

Epoch: 6| Step: 6
Training loss: 1.4629100561141968
Validation loss: 1.961434478400856

Epoch: 6| Step: 7
Training loss: 1.5858577489852905
Validation loss: 1.9526691859768284

Epoch: 6| Step: 8
Training loss: 1.4875688552856445
Validation loss: 1.9337366140016945

Epoch: 6| Step: 9
Training loss: 0.9043494462966919
Validation loss: 1.9300793870802848

Epoch: 6| Step: 10
Training loss: 1.7538965940475464
Validation loss: 1.9366142416513095

Epoch: 6| Step: 11
Training loss: 1.8725649118423462
Validation loss: 1.944293027283043

Epoch: 6| Step: 12
Training loss: 1.4679627418518066
Validation loss: 1.952701953149611

Epoch: 6| Step: 13
Training loss: 1.7382662296295166
Validation loss: 1.945140584822624

Epoch: 217| Step: 0
Training loss: 1.788719892501831
Validation loss: 1.9609333135748421

Epoch: 6| Step: 1
Training loss: 1.2042131423950195
Validation loss: 1.9755012835225751

Epoch: 6| Step: 2
Training loss: 1.2214897871017456
Validation loss: 2.000106091140419

Epoch: 6| Step: 3
Training loss: 1.0496397018432617
Validation loss: 2.014821913934523

Epoch: 6| Step: 4
Training loss: 2.1680331230163574
Validation loss: 2.018799093461806

Epoch: 6| Step: 5
Training loss: 1.3091049194335938
Validation loss: 2.029853800291656

Epoch: 6| Step: 6
Training loss: 1.506962537765503
Validation loss: 2.0369259042124592

Epoch: 6| Step: 7
Training loss: 1.7125146389007568
Validation loss: 2.0401049685734574

Epoch: 6| Step: 8
Training loss: 1.4750277996063232
Validation loss: 2.0080381183214087

Epoch: 6| Step: 9
Training loss: 1.101941704750061
Validation loss: 2.0062490432493147

Epoch: 6| Step: 10
Training loss: 1.4487102031707764
Validation loss: 1.9754579810686008

Epoch: 6| Step: 11
Training loss: 1.4423112869262695
Validation loss: 1.9895749117738457

Epoch: 6| Step: 12
Training loss: 2.0391669273376465
Validation loss: 1.9852389827851327

Epoch: 6| Step: 13
Training loss: 1.2964205741882324
Validation loss: 1.9743310584816882

Epoch: 218| Step: 0
Training loss: 1.251800537109375
Validation loss: 1.958063010246523

Epoch: 6| Step: 1
Training loss: 1.3909389972686768
Validation loss: 1.9701520076362036

Epoch: 6| Step: 2
Training loss: 0.8686667680740356
Validation loss: 1.9409310612627255

Epoch: 6| Step: 3
Training loss: 1.6533873081207275
Validation loss: 1.9503316827999648

Epoch: 6| Step: 4
Training loss: 1.3966703414916992
Validation loss: 1.9513589348844302

Epoch: 6| Step: 5
Training loss: 1.1840804815292358
Validation loss: 1.951996531537784

Epoch: 6| Step: 6
Training loss: 1.3012856245040894
Validation loss: 1.9565830704986409

Epoch: 6| Step: 7
Training loss: 1.4743905067443848
Validation loss: 1.9770997647316224

Epoch: 6| Step: 8
Training loss: 1.781400442123413
Validation loss: 2.0039361599952943

Epoch: 6| Step: 9
Training loss: 1.8590476512908936
Validation loss: 2.016058116830805

Epoch: 6| Step: 10
Training loss: 1.5838626623153687
Validation loss: 2.0090982452515633

Epoch: 6| Step: 11
Training loss: 1.413769245147705
Validation loss: 1.9904399841062483

Epoch: 6| Step: 12
Training loss: 2.0777969360351562
Validation loss: 1.9756568734363844

Epoch: 6| Step: 13
Training loss: 1.1553922891616821
Validation loss: 1.9570194034166233

Epoch: 219| Step: 0
Training loss: 2.0525259971618652
Validation loss: 1.9673137651976718

Epoch: 6| Step: 1
Training loss: 1.029982566833496
Validation loss: 1.9661719209404402

Epoch: 6| Step: 2
Training loss: 2.108258008956909
Validation loss: 1.9815609711472706

Epoch: 6| Step: 3
Training loss: 1.2849361896514893
Validation loss: 1.976868898637833

Epoch: 6| Step: 4
Training loss: 1.662945032119751
Validation loss: 1.9764949121782858

Epoch: 6| Step: 5
Training loss: 1.4748928546905518
Validation loss: 1.9896366468039892

Epoch: 6| Step: 6
Training loss: 1.9374662637710571
Validation loss: 1.9828006221402077

Epoch: 6| Step: 7
Training loss: 1.6771793365478516
Validation loss: 1.9730257795703026

Epoch: 6| Step: 8
Training loss: 1.458311676979065
Validation loss: 1.9606817845375306

Epoch: 6| Step: 9
Training loss: 0.37838828563690186
Validation loss: 1.9471450851809593

Epoch: 6| Step: 10
Training loss: 1.137948989868164
Validation loss: 1.96887969457975

Epoch: 6| Step: 11
Training loss: 1.5360016822814941
Validation loss: 1.9798462852354972

Epoch: 6| Step: 12
Training loss: 1.034496784210205
Validation loss: 1.9857385055993193

Epoch: 6| Step: 13
Training loss: 1.4621922969818115
Validation loss: 2.008118050072783

Epoch: 220| Step: 0
Training loss: 1.0025824308395386
Validation loss: 2.0178978584145986

Epoch: 6| Step: 1
Training loss: 1.4293851852416992
Validation loss: 2.0206913319967126

Epoch: 6| Step: 2
Training loss: 1.3888057470321655
Validation loss: 2.0305352416089786

Epoch: 6| Step: 3
Training loss: 1.9423761367797852
Validation loss: 2.027010638226745

Epoch: 6| Step: 4
Training loss: 1.467293381690979
Validation loss: 1.99722715603408

Epoch: 6| Step: 5
Training loss: 1.4534790515899658
Validation loss: 1.9886068131334038

Epoch: 6| Step: 6
Training loss: 1.8600788116455078
Validation loss: 1.9699219503710348

Epoch: 6| Step: 7
Training loss: 1.5811240673065186
Validation loss: 1.9499560633013326

Epoch: 6| Step: 8
Training loss: 2.3739190101623535
Validation loss: 1.9365882514625468

Epoch: 6| Step: 9
Training loss: 1.7198303937911987
Validation loss: 1.9224933770395094

Epoch: 6| Step: 10
Training loss: 1.1503214836120605
Validation loss: 1.9331783017804545

Epoch: 6| Step: 11
Training loss: 1.6094887256622314
Validation loss: 1.9367070608241583

Epoch: 6| Step: 12
Training loss: 0.9995718002319336
Validation loss: 1.9421438594018259

Epoch: 6| Step: 13
Training loss: 1.390531063079834
Validation loss: 1.9335304050035373

Epoch: 221| Step: 0
Training loss: 1.149516224861145
Validation loss: 1.909041106059987

Epoch: 6| Step: 1
Training loss: 1.398659348487854
Validation loss: 1.8985181905890023

Epoch: 6| Step: 2
Training loss: 1.4923571348190308
Validation loss: 1.9286268757235618

Epoch: 6| Step: 3
Training loss: 1.915108561515808
Validation loss: 1.966953028914749

Epoch: 6| Step: 4
Training loss: 1.7643828392028809
Validation loss: 1.9883419224011

Epoch: 6| Step: 5
Training loss: 2.0304925441741943
Validation loss: 2.008545111584407

Epoch: 6| Step: 6
Training loss: 1.6319471597671509
Validation loss: 2.0175557136535645

Epoch: 6| Step: 7
Training loss: 1.542664885520935
Validation loss: 2.015175629687566

Epoch: 6| Step: 8
Training loss: 1.235244631767273
Validation loss: 1.9857903360038676

Epoch: 6| Step: 9
Training loss: 1.3580129146575928
Validation loss: 1.9694870992373394

Epoch: 6| Step: 10
Training loss: 1.5081727504730225
Validation loss: 1.9599850370037941

Epoch: 6| Step: 11
Training loss: 1.4447169303894043
Validation loss: 1.9732160811783166

Epoch: 6| Step: 12
Training loss: 1.3464202880859375
Validation loss: 1.9963367446776359

Epoch: 6| Step: 13
Training loss: 1.3467466831207275
Validation loss: 2.0161352798502934

Epoch: 222| Step: 0
Training loss: 1.6721692085266113
Validation loss: 2.011753682167299

Epoch: 6| Step: 1
Training loss: 1.4109153747558594
Validation loss: 1.9920012707351356

Epoch: 6| Step: 2
Training loss: 1.6431446075439453
Validation loss: 1.9887060990897558

Epoch: 6| Step: 3
Training loss: 1.3710863590240479
Validation loss: 1.9943342452408166

Epoch: 6| Step: 4
Training loss: 1.9864593744277954
Validation loss: 1.9961281925119378

Epoch: 6| Step: 5
Training loss: 0.6144357323646545
Validation loss: 2.0051228166908346

Epoch: 6| Step: 6
Training loss: 1.3059452772140503
Validation loss: 1.9945222049631097

Epoch: 6| Step: 7
Training loss: 1.184701919555664
Validation loss: 2.014364270753758

Epoch: 6| Step: 8
Training loss: 1.611135482788086
Validation loss: 2.014408967828238

Epoch: 6| Step: 9
Training loss: 1.870725154876709
Validation loss: 1.99862580145559

Epoch: 6| Step: 10
Training loss: 1.6097404956817627
Validation loss: 1.988055803442514

Epoch: 6| Step: 11
Training loss: 0.8710674047470093
Validation loss: 1.9681807307786838

Epoch: 6| Step: 12
Training loss: 1.341447353363037
Validation loss: 1.965648320413405

Epoch: 6| Step: 13
Training loss: 2.004755973815918
Validation loss: 1.9341409924209758

Epoch: 223| Step: 0
Training loss: 1.751528263092041
Validation loss: 1.9051949849692724

Epoch: 6| Step: 1
Training loss: 1.6010160446166992
Validation loss: 1.8766084704347836

Epoch: 6| Step: 2
Training loss: 1.2054380178451538
Validation loss: 1.8470541149057367

Epoch: 6| Step: 3
Training loss: 0.8714630007743835
Validation loss: 1.8390460424525763

Epoch: 6| Step: 4
Training loss: 1.0874367952346802
Validation loss: 1.8132962257631364

Epoch: 6| Step: 5
Training loss: 2.0609755516052246
Validation loss: 1.8384910014367872

Epoch: 6| Step: 6
Training loss: 2.0150885581970215
Validation loss: 1.8365900811328684

Epoch: 6| Step: 7
Training loss: 1.1612226963043213
Validation loss: 1.8930894174883444

Epoch: 6| Step: 8
Training loss: 1.711596965789795
Validation loss: 1.9111298489314255

Epoch: 6| Step: 9
Training loss: 1.5670114755630493
Validation loss: 1.9365517349653347

Epoch: 6| Step: 10
Training loss: 0.9957493543624878
Validation loss: 1.9805719339719383

Epoch: 6| Step: 11
Training loss: 1.5341341495513916
Validation loss: 1.9805088350849767

Epoch: 6| Step: 12
Training loss: 1.7463016510009766
Validation loss: 1.9595200707835536

Epoch: 6| Step: 13
Training loss: 1.460868000984192
Validation loss: 1.9392077487002137

Epoch: 224| Step: 0
Training loss: 0.8992414474487305
Validation loss: 1.9499913005418674

Epoch: 6| Step: 1
Training loss: 1.4195672273635864
Validation loss: 1.9469241608855545

Epoch: 6| Step: 2
Training loss: 1.724096417427063
Validation loss: 1.9634031377812868

Epoch: 6| Step: 3
Training loss: 1.3374792337417603
Validation loss: 1.9501600611594416

Epoch: 6| Step: 4
Training loss: 1.3980406522750854
Validation loss: 1.9703073988678634

Epoch: 6| Step: 5
Training loss: 1.1115916967391968
Validation loss: 1.998455810290511

Epoch: 6| Step: 6
Training loss: 1.2333494424819946
Validation loss: 1.9900067954935052

Epoch: 6| Step: 7
Training loss: 1.2187600135803223
Validation loss: 1.9890023892925632

Epoch: 6| Step: 8
Training loss: 1.7541348934173584
Validation loss: 1.9685363231166717

Epoch: 6| Step: 9
Training loss: 1.5295628309249878
Validation loss: 1.981902978753531

Epoch: 6| Step: 10
Training loss: 1.7717342376708984
Validation loss: 1.9875552513266121

Epoch: 6| Step: 11
Training loss: 1.2794582843780518
Validation loss: 1.9914518940833308

Epoch: 6| Step: 12
Training loss: 1.4674795866012573
Validation loss: 1.9693414088218444

Epoch: 6| Step: 13
Training loss: 2.096597671508789
Validation loss: 1.9570443681491319

Epoch: 225| Step: 0
Training loss: 1.9906773567199707
Validation loss: 1.9587175692281416

Epoch: 6| Step: 1
Training loss: 1.379164457321167
Validation loss: 1.9685611853035547

Epoch: 6| Step: 2
Training loss: 1.2350085973739624
Validation loss: 1.959789591450845

Epoch: 6| Step: 3
Training loss: 1.4562793970108032
Validation loss: 1.973929161666542

Epoch: 6| Step: 4
Training loss: 2.34853196144104
Validation loss: 1.9698733309263825

Epoch: 6| Step: 5
Training loss: 1.253250241279602
Validation loss: 1.9708970605686147

Epoch: 6| Step: 6
Training loss: 1.629849910736084
Validation loss: 1.9854021123660508

Epoch: 6| Step: 7
Training loss: 1.0787017345428467
Validation loss: 2.005042960566859

Epoch: 6| Step: 8
Training loss: 1.0341227054595947
Validation loss: 1.998070014420376

Epoch: 6| Step: 9
Training loss: 1.5595072507858276
Validation loss: 1.9929632730381464

Epoch: 6| Step: 10
Training loss: 1.315873146057129
Validation loss: 1.9733080094860447

Epoch: 6| Step: 11
Training loss: 1.3909075260162354
Validation loss: 1.9609391356027255

Epoch: 6| Step: 12
Training loss: 0.928594172000885
Validation loss: 1.9483840157908778

Epoch: 6| Step: 13
Training loss: 1.1205418109893799
Validation loss: 1.9500487491648684

Epoch: 226| Step: 0
Training loss: 2.0574254989624023
Validation loss: 1.964928364240995

Epoch: 6| Step: 1
Training loss: 0.9785655736923218
Validation loss: 1.957838104617211

Epoch: 6| Step: 2
Training loss: 1.4065455198287964
Validation loss: 1.9559188991464593

Epoch: 6| Step: 3
Training loss: 0.8510199785232544
Validation loss: 1.9565347933000135

Epoch: 6| Step: 4
Training loss: 1.2668652534484863
Validation loss: 1.9636062063196653

Epoch: 6| Step: 5
Training loss: 2.0484936237335205
Validation loss: 1.9629292616280176

Epoch: 6| Step: 6
Training loss: 1.0635240077972412
Validation loss: 1.9817759939419326

Epoch: 6| Step: 7
Training loss: 1.0985159873962402
Validation loss: 2.02263500613551

Epoch: 6| Step: 8
Training loss: 1.2360011339187622
Validation loss: 2.028644597658547

Epoch: 6| Step: 9
Training loss: 1.5549750328063965
Validation loss: 2.0299144303926857

Epoch: 6| Step: 10
Training loss: 0.9352914094924927
Validation loss: 2.037857581210393

Epoch: 6| Step: 11
Training loss: 1.9089066982269287
Validation loss: 2.0185144421874837

Epoch: 6| Step: 12
Training loss: 1.3429973125457764
Validation loss: 1.9991889717758342

Epoch: 6| Step: 13
Training loss: 2.347154140472412
Validation loss: 1.9770785095871135

Epoch: 227| Step: 0
Training loss: 1.5471752882003784
Validation loss: 1.9715739168146604

Epoch: 6| Step: 1
Training loss: 1.6866883039474487
Validation loss: 1.9688297266601233

Epoch: 6| Step: 2
Training loss: 1.1676828861236572
Validation loss: 1.965966518207263

Epoch: 6| Step: 3
Training loss: 1.0585044622421265
Validation loss: 1.9379317337466824

Epoch: 6| Step: 4
Training loss: 1.2056972980499268
Validation loss: 1.9443784875254477

Epoch: 6| Step: 5
Training loss: 1.3709421157836914
Validation loss: 1.9419741784372637

Epoch: 6| Step: 6
Training loss: 1.6999499797821045
Validation loss: 1.9377102557049002

Epoch: 6| Step: 7
Training loss: 1.588100552558899
Validation loss: 1.9525805596382386

Epoch: 6| Step: 8
Training loss: 1.0680794715881348
Validation loss: 1.9668774656070176

Epoch: 6| Step: 9
Training loss: 1.7535649538040161
Validation loss: 1.974308697126245

Epoch: 6| Step: 10
Training loss: 0.7137582898139954
Validation loss: 1.9978049903787591

Epoch: 6| Step: 11
Training loss: 1.3853232860565186
Validation loss: 2.022554373228422

Epoch: 6| Step: 12
Training loss: 1.4402425289154053
Validation loss: 2.045910673756753

Epoch: 6| Step: 13
Training loss: 1.8909674882888794
Validation loss: 2.0891148390308505

Epoch: 228| Step: 0
Training loss: 1.2947453260421753
Validation loss: 2.1187954538611957

Epoch: 6| Step: 1
Training loss: 1.276672601699829
Validation loss: 2.12381455462466

Epoch: 6| Step: 2
Training loss: 0.960468053817749
Validation loss: 2.077468382414951

Epoch: 6| Step: 3
Training loss: 0.969520628452301
Validation loss: 2.0872601783403786

Epoch: 6| Step: 4
Training loss: 1.6610784530639648
Validation loss: 2.056150887602119

Epoch: 6| Step: 5
Training loss: 1.2848379611968994
Validation loss: 2.025794457363826

Epoch: 6| Step: 6
Training loss: 1.425256371498108
Validation loss: 1.9816739405355146

Epoch: 6| Step: 7
Training loss: 1.081991195678711
Validation loss: 1.9710518339628815

Epoch: 6| Step: 8
Training loss: 1.6890127658843994
Validation loss: 1.9455710123944026

Epoch: 6| Step: 9
Training loss: 1.7165719270706177
Validation loss: 1.9341594660153953

Epoch: 6| Step: 10
Training loss: 1.643514633178711
Validation loss: 1.89624604358468

Epoch: 6| Step: 11
Training loss: 1.9018003940582275
Validation loss: 1.901586426201687

Epoch: 6| Step: 12
Training loss: 1.7990328073501587
Validation loss: 1.924607171807238

Epoch: 6| Step: 13
Training loss: 1.1567959785461426
Validation loss: 1.90719937252742

Epoch: 229| Step: 0
Training loss: 1.4774621725082397
Validation loss: 1.9260826546658751

Epoch: 6| Step: 1
Training loss: 1.7562057971954346
Validation loss: 1.9520377023245699

Epoch: 6| Step: 2
Training loss: 1.8344924449920654
Validation loss: 1.9617679016564482

Epoch: 6| Step: 3
Training loss: 1.419498085975647
Validation loss: 1.9926608044614074

Epoch: 6| Step: 4
Training loss: 1.716455101966858
Validation loss: 2.0008412253472114

Epoch: 6| Step: 5
Training loss: 0.8444154262542725
Validation loss: 2.056885709044754

Epoch: 6| Step: 6
Training loss: 1.2966824769973755
Validation loss: 2.0435535959018174

Epoch: 6| Step: 7
Training loss: 1.6341817378997803
Validation loss: 2.029871804739839

Epoch: 6| Step: 8
Training loss: 1.697830080986023
Validation loss: 2.030078044501684

Epoch: 6| Step: 9
Training loss: 0.9160764217376709
Validation loss: 2.019805428802326

Epoch: 6| Step: 10
Training loss: 1.6052272319793701
Validation loss: 2.0154124562458327

Epoch: 6| Step: 11
Training loss: 1.3685712814331055
Validation loss: 1.9967704755003735

Epoch: 6| Step: 12
Training loss: 1.5703153610229492
Validation loss: 1.986825054691684

Epoch: 6| Step: 13
Training loss: 1.3735700845718384
Validation loss: 1.9525867431394515

Epoch: 230| Step: 0
Training loss: 1.5140345096588135
Validation loss: 1.9632086382117322

Epoch: 6| Step: 1
Training loss: 1.1671466827392578
Validation loss: 1.956407175269178

Epoch: 6| Step: 2
Training loss: 0.8505507707595825
Validation loss: 1.9773500773214525

Epoch: 6| Step: 3
Training loss: 1.421377420425415
Validation loss: 1.9764829912493307

Epoch: 6| Step: 4
Training loss: 1.027329683303833
Validation loss: 1.9903392804566251

Epoch: 6| Step: 5
Training loss: 0.8595156073570251
Validation loss: 1.9715838893767326

Epoch: 6| Step: 6
Training loss: 2.0441861152648926
Validation loss: 2.018735193437146

Epoch: 6| Step: 7
Training loss: 1.622788429260254
Validation loss: 1.9997381971728416

Epoch: 6| Step: 8
Training loss: 2.0095129013061523
Validation loss: 2.0140423479900567

Epoch: 6| Step: 9
Training loss: 2.1928482055664062
Validation loss: 1.9770733182148268

Epoch: 6| Step: 10
Training loss: 1.1305830478668213
Validation loss: 1.9518913761261971

Epoch: 6| Step: 11
Training loss: 1.0220353603363037
Validation loss: 1.9392905260926934

Epoch: 6| Step: 12
Training loss: 1.5861058235168457
Validation loss: 1.9429584062227638

Epoch: 6| Step: 13
Training loss: 1.2458513975143433
Validation loss: 1.9296019961757045

Epoch: 231| Step: 0
Training loss: 0.9728409051895142
Validation loss: 1.90478846462824

Epoch: 6| Step: 1
Training loss: 1.1228981018066406
Validation loss: 1.9096870550545313

Epoch: 6| Step: 2
Training loss: 2.292076826095581
Validation loss: 1.89615600339828

Epoch: 6| Step: 3
Training loss: 0.6216781139373779
Validation loss: 1.8958280009608115

Epoch: 6| Step: 4
Training loss: 1.9059257507324219
Validation loss: 1.911750365329045

Epoch: 6| Step: 5
Training loss: 1.2019596099853516
Validation loss: 1.9583574161734632

Epoch: 6| Step: 6
Training loss: 1.672276496887207
Validation loss: 1.9645272698453677

Epoch: 6| Step: 7
Training loss: 0.8307495713233948
Validation loss: 2.007071118200979

Epoch: 6| Step: 8
Training loss: 1.6178841590881348
Validation loss: 2.0305778288072154

Epoch: 6| Step: 9
Training loss: 1.4440698623657227
Validation loss: 2.0618566518188803

Epoch: 6| Step: 10
Training loss: 1.716137170791626
Validation loss: 2.078793065522307

Epoch: 6| Step: 11
Training loss: 1.881028413772583
Validation loss: 2.0766813216670865

Epoch: 6| Step: 12
Training loss: 1.815983772277832
Validation loss: 2.0521975589054886

Epoch: 6| Step: 13
Training loss: 1.667549967765808
Validation loss: 2.0405049375308457

Epoch: 232| Step: 0
Training loss: 1.889533281326294
Validation loss: 2.0054709629345964

Epoch: 6| Step: 1
Training loss: 1.5589725971221924
Validation loss: 2.005201483285555

Epoch: 6| Step: 2
Training loss: 1.2045427560806274
Validation loss: 1.9978008411263908

Epoch: 6| Step: 3
Training loss: 1.5186760425567627
Validation loss: 1.9801189002170358

Epoch: 6| Step: 4
Training loss: 1.2837183475494385
Validation loss: 1.9982283294841807

Epoch: 6| Step: 5
Training loss: 1.389174222946167
Validation loss: 2.0198361796717488

Epoch: 6| Step: 6
Training loss: 1.3934210538864136
Validation loss: 2.027105869785432

Epoch: 6| Step: 7
Training loss: 1.6284689903259277
Validation loss: 2.052120557395361

Epoch: 6| Step: 8
Training loss: 1.3076504468917847
Validation loss: 2.0481553167425175

Epoch: 6| Step: 9
Training loss: 1.3328012228012085
Validation loss: 2.0292559926227858

Epoch: 6| Step: 10
Training loss: 0.8822460174560547
Validation loss: 2.0134169452933857

Epoch: 6| Step: 11
Training loss: 1.053114891052246
Validation loss: 1.9974308872735629

Epoch: 6| Step: 12
Training loss: 2.051387310028076
Validation loss: 1.9807593566115185

Epoch: 6| Step: 13
Training loss: 1.0230742692947388
Validation loss: 1.9683658922872236

Epoch: 233| Step: 0
Training loss: 1.8405097723007202
Validation loss: 1.934314609855734

Epoch: 6| Step: 1
Training loss: 1.2579097747802734
Validation loss: 1.921469315405815

Epoch: 6| Step: 2
Training loss: 1.0852103233337402
Validation loss: 1.911495872723159

Epoch: 6| Step: 3
Training loss: 1.3933637142181396
Validation loss: 1.9325591889760827

Epoch: 6| Step: 4
Training loss: 1.543626070022583
Validation loss: 1.906747712883898

Epoch: 6| Step: 5
Training loss: 1.322278380393982
Validation loss: 1.9356996436272897

Epoch: 6| Step: 6
Training loss: 0.9674875736236572
Validation loss: 1.9183408598746023

Epoch: 6| Step: 7
Training loss: 1.2176432609558105
Validation loss: 1.9176699717839558

Epoch: 6| Step: 8
Training loss: 1.1862398386001587
Validation loss: 1.9154145897075694

Epoch: 6| Step: 9
Training loss: 1.605671763420105
Validation loss: 1.9218003749847412

Epoch: 6| Step: 10
Training loss: 1.4124518632888794
Validation loss: 1.9307791110007995

Epoch: 6| Step: 11
Training loss: 0.8982477188110352
Validation loss: 1.940092004755492

Epoch: 6| Step: 12
Training loss: 1.3010287284851074
Validation loss: 1.9705227754449333

Epoch: 6| Step: 13
Training loss: 1.8628069162368774
Validation loss: 2.0015368974337013

Epoch: 234| Step: 0
Training loss: 1.2229132652282715
Validation loss: 2.0360798592208535

Epoch: 6| Step: 1
Training loss: 1.5024733543395996
Validation loss: 2.0492802025169454

Epoch: 6| Step: 2
Training loss: 1.2395336627960205
Validation loss: 2.027877749935273

Epoch: 6| Step: 3
Training loss: 1.0668108463287354
Validation loss: 2.035910916584794

Epoch: 6| Step: 4
Training loss: 0.9112694263458252
Validation loss: 2.048897595815761

Epoch: 6| Step: 5
Training loss: 1.6393556594848633
Validation loss: 2.036108639932448

Epoch: 6| Step: 6
Training loss: 1.7642920017242432
Validation loss: 2.042132221242433

Epoch: 6| Step: 7
Training loss: 1.365181803703308
Validation loss: 2.0323560571157806

Epoch: 6| Step: 8
Training loss: 1.0672264099121094
Validation loss: 2.026791114960947

Epoch: 6| Step: 9
Training loss: 1.3077749013900757
Validation loss: 2.0367279642371723

Epoch: 6| Step: 10
Training loss: 1.533779501914978
Validation loss: 2.022050835753

Epoch: 6| Step: 11
Training loss: 1.5441616773605347
Validation loss: 2.0249688907336165

Epoch: 6| Step: 12
Training loss: 1.0567959547042847
Validation loss: 2.0375312912848687

Epoch: 6| Step: 13
Training loss: 1.638162612915039
Validation loss: 2.0203239481936217

Epoch: 235| Step: 0
Training loss: 1.244993805885315
Validation loss: 2.0018460430124754

Epoch: 6| Step: 1
Training loss: 0.9508845806121826
Validation loss: 1.9872454340739916

Epoch: 6| Step: 2
Training loss: 0.9814361929893494
Validation loss: 2.0046458705779044

Epoch: 6| Step: 3
Training loss: 1.5406975746154785
Validation loss: 1.9926919206496208

Epoch: 6| Step: 4
Training loss: 1.5895373821258545
Validation loss: 2.0182856462335073

Epoch: 6| Step: 5
Training loss: 1.288527488708496
Validation loss: 2.0339888911093436

Epoch: 6| Step: 6
Training loss: 1.0398553609848022
Validation loss: 2.0370174531013734

Epoch: 6| Step: 7
Training loss: 1.3262991905212402
Validation loss: 2.032224803842524

Epoch: 6| Step: 8
Training loss: 1.3180954456329346
Validation loss: 2.0080932891497048

Epoch: 6| Step: 9
Training loss: 1.8804545402526855
Validation loss: 1.9914464540379022

Epoch: 6| Step: 10
Training loss: 0.9666310548782349
Validation loss: 1.98956819247174

Epoch: 6| Step: 11
Training loss: 1.292255163192749
Validation loss: 1.9569071326204526

Epoch: 6| Step: 12
Training loss: 1.0707042217254639
Validation loss: 1.9665092986117128

Epoch: 6| Step: 13
Training loss: 1.5761061906814575
Validation loss: 1.9785077007867957

Epoch: 236| Step: 0
Training loss: 1.7388508319854736
Validation loss: 1.9621031348423292

Epoch: 6| Step: 1
Training loss: 1.586767554283142
Validation loss: 1.9854909527686335

Epoch: 6| Step: 2
Training loss: 1.669421672821045
Validation loss: 1.9727652021633681

Epoch: 6| Step: 3
Training loss: 1.531665325164795
Validation loss: 1.9805203676223755

Epoch: 6| Step: 4
Training loss: 0.7317845821380615
Validation loss: 1.995374269382928

Epoch: 6| Step: 5
Training loss: 1.2080930471420288
Validation loss: 2.0023316029579408

Epoch: 6| Step: 6
Training loss: 0.9588915109634399
Validation loss: 2.025795372583533

Epoch: 6| Step: 7
Training loss: 1.1801555156707764
Validation loss: 2.024141409063852

Epoch: 6| Step: 8
Training loss: 1.7407512664794922
Validation loss: 2.0042297340208486

Epoch: 6| Step: 9
Training loss: 0.7725580930709839
Validation loss: 2.0122907187349055

Epoch: 6| Step: 10
Training loss: 0.8886783123016357
Validation loss: 1.9961591907726821

Epoch: 6| Step: 11
Training loss: 1.1467676162719727
Validation loss: 1.9927756709437217

Epoch: 6| Step: 12
Training loss: 1.1696786880493164
Validation loss: 1.978197689979307

Epoch: 6| Step: 13
Training loss: 1.4532546997070312
Validation loss: 1.9762455071172407

Epoch: 237| Step: 0
Training loss: 1.0781255960464478
Validation loss: 1.9864332419569775

Epoch: 6| Step: 1
Training loss: 1.0577802658081055
Validation loss: 1.9720321727055374

Epoch: 6| Step: 2
Training loss: 1.364348292350769
Validation loss: 1.9701406186626804

Epoch: 6| Step: 3
Training loss: 1.391890287399292
Validation loss: 1.9902312191583778

Epoch: 6| Step: 4
Training loss: 1.354743242263794
Validation loss: 1.9758406403244182

Epoch: 6| Step: 5
Training loss: 1.5891528129577637
Validation loss: 1.9497956665613319

Epoch: 6| Step: 6
Training loss: 1.1817245483398438
Validation loss: 1.9463134247769591

Epoch: 6| Step: 7
Training loss: 1.32206392288208
Validation loss: 1.937969587182486

Epoch: 6| Step: 8
Training loss: 1.3732471466064453
Validation loss: 1.9417594517430952

Epoch: 6| Step: 9
Training loss: 1.6731199026107788
Validation loss: 1.966954206907621

Epoch: 6| Step: 10
Training loss: 1.3444385528564453
Validation loss: 1.9469159956901305

Epoch: 6| Step: 11
Training loss: 0.6859962940216064
Validation loss: 1.9595291153077157

Epoch: 6| Step: 12
Training loss: 0.7567917108535767
Validation loss: 1.973833026424531

Epoch: 6| Step: 13
Training loss: 1.0691550970077515
Validation loss: 2.00901597674175

Epoch: 238| Step: 0
Training loss: 1.834169864654541
Validation loss: 2.023332295879241

Epoch: 6| Step: 1
Training loss: 0.9356964826583862
Validation loss: 2.0427503483269804

Epoch: 6| Step: 2
Training loss: 1.237464427947998
Validation loss: 2.0374007712128344

Epoch: 6| Step: 3
Training loss: 1.0453815460205078
Validation loss: 2.027033175191572

Epoch: 6| Step: 4
Training loss: 1.1702296733856201
Validation loss: 2.02422196121626

Epoch: 6| Step: 5
Training loss: 1.533534049987793
Validation loss: 2.034908225459437

Epoch: 6| Step: 6
Training loss: 1.1470844745635986
Validation loss: 2.0415344340826875

Epoch: 6| Step: 7
Training loss: 1.0028831958770752
Validation loss: 2.0441518163168304

Epoch: 6| Step: 8
Training loss: 1.0083069801330566
Validation loss: 2.022930000417976

Epoch: 6| Step: 9
Training loss: 1.7120988368988037
Validation loss: 2.046148121997874

Epoch: 6| Step: 10
Training loss: 1.6076641082763672
Validation loss: 2.018001671760313

Epoch: 6| Step: 11
Training loss: 1.1986037492752075
Validation loss: 2.007956963713451

Epoch: 6| Step: 12
Training loss: 0.8416314125061035
Validation loss: 1.9943622542965798

Epoch: 6| Step: 13
Training loss: 0.866366446018219
Validation loss: 1.9814693902128486

Epoch: 239| Step: 0
Training loss: 1.221537709236145
Validation loss: 1.9563392387923373

Epoch: 6| Step: 1
Training loss: 1.3117306232452393
Validation loss: 1.9361703062570224

Epoch: 6| Step: 2
Training loss: 1.9425674676895142
Validation loss: 1.9343480576751053

Epoch: 6| Step: 3
Training loss: 0.7416094541549683
Validation loss: 1.959236151428633

Epoch: 6| Step: 4
Training loss: 1.334539532661438
Validation loss: 1.9438915970504924

Epoch: 6| Step: 5
Training loss: 1.1559031009674072
Validation loss: 1.987382645248085

Epoch: 6| Step: 6
Training loss: 1.3639110326766968
Validation loss: 1.9855576189615394

Epoch: 6| Step: 7
Training loss: 1.0129003524780273
Validation loss: 1.9670922871558898

Epoch: 6| Step: 8
Training loss: 1.4516897201538086
Validation loss: 1.9701991965693813

Epoch: 6| Step: 9
Training loss: 1.519484281539917
Validation loss: 1.9784194641215826

Epoch: 6| Step: 10
Training loss: 1.15486741065979
Validation loss: 1.9837599537705863

Epoch: 6| Step: 11
Training loss: 1.3113350868225098
Validation loss: 1.9949674824232697

Epoch: 6| Step: 12
Training loss: 0.9971061944961548
Validation loss: 1.968363586292472

Epoch: 6| Step: 13
Training loss: 0.7855712175369263
Validation loss: 1.9790024039565877

Epoch: 240| Step: 0
Training loss: 1.7575721740722656
Validation loss: 1.9722999577881188

Epoch: 6| Step: 1
Training loss: 1.244610071182251
Validation loss: 1.9866187764752297

Epoch: 6| Step: 2
Training loss: 0.830030620098114
Validation loss: 1.9756452075896724

Epoch: 6| Step: 3
Training loss: 1.4091156721115112
Validation loss: 1.9936516297760831

Epoch: 6| Step: 4
Training loss: 0.7738133668899536
Validation loss: 2.0075612965450493

Epoch: 6| Step: 5
Training loss: 1.1494805812835693
Validation loss: 2.0204538786283104

Epoch: 6| Step: 6
Training loss: 1.4885241985321045
Validation loss: 2.001893365254966

Epoch: 6| Step: 7
Training loss: 1.1453522443771362
Validation loss: 1.9903167998918923

Epoch: 6| Step: 8
Training loss: 1.4272894859313965
Validation loss: 1.9949148995901949

Epoch: 6| Step: 9
Training loss: 1.3367221355438232
Validation loss: 1.9958335045845277

Epoch: 6| Step: 10
Training loss: 0.8494923114776611
Validation loss: 1.9675349189389137

Epoch: 6| Step: 11
Training loss: 1.5020071268081665
Validation loss: 1.9637477936283234

Epoch: 6| Step: 12
Training loss: 0.8872274160385132
Validation loss: 1.9508883350638933

Epoch: 6| Step: 13
Training loss: 1.0739660263061523
Validation loss: 1.9626029486297278

Epoch: 241| Step: 0
Training loss: 1.1322388648986816
Validation loss: 1.9872200540317002

Epoch: 6| Step: 1
Training loss: 1.280522346496582
Validation loss: 2.0040693565081527

Epoch: 6| Step: 2
Training loss: 0.8324555158615112
Validation loss: 1.9968518544268865

Epoch: 6| Step: 3
Training loss: 1.5235084295272827
Validation loss: 2.0137650838462253

Epoch: 6| Step: 4
Training loss: 1.211824893951416
Validation loss: 1.9769993546188518

Epoch: 6| Step: 5
Training loss: 1.027333378791809
Validation loss: 1.9741670098356021

Epoch: 6| Step: 6
Training loss: 1.4196960926055908
Validation loss: 1.9782131346323157

Epoch: 6| Step: 7
Training loss: 1.3100571632385254
Validation loss: 1.9588770097301853

Epoch: 6| Step: 8
Training loss: 1.1986773014068604
Validation loss: 1.9418464360698577

Epoch: 6| Step: 9
Training loss: 1.229393482208252
Validation loss: 1.9358127181248

Epoch: 6| Step: 10
Training loss: 0.8686255812644958
Validation loss: 1.9148118188304286

Epoch: 6| Step: 11
Training loss: 1.3115489482879639
Validation loss: 1.9302169815186532

Epoch: 6| Step: 12
Training loss: 1.5932281017303467
Validation loss: 1.9468601249879407

Epoch: 6| Step: 13
Training loss: 1.3537306785583496
Validation loss: 1.996313400166009

Epoch: 242| Step: 0
Training loss: 1.4042751789093018
Validation loss: 2.03945271302295

Epoch: 6| Step: 1
Training loss: 1.3398443460464478
Validation loss: 2.064821443250102

Epoch: 6| Step: 2
Training loss: 1.4367213249206543
Validation loss: 2.0776136459842807

Epoch: 6| Step: 3
Training loss: 1.4305578470230103
Validation loss: 2.085846475375596

Epoch: 6| Step: 4
Training loss: 1.6789698600769043
Validation loss: 2.070369694822578

Epoch: 6| Step: 5
Training loss: 1.0458481311798096
Validation loss: 1.9848217079716344

Epoch: 6| Step: 6
Training loss: 0.9612062573432922
Validation loss: 1.9482595638562274

Epoch: 6| Step: 7
Training loss: 1.863724946975708
Validation loss: 1.928739288801788

Epoch: 6| Step: 8
Training loss: 1.1478803157806396
Validation loss: 1.9441094629226192

Epoch: 6| Step: 9
Training loss: 1.5631186962127686
Validation loss: 1.9245651639917845

Epoch: 6| Step: 10
Training loss: 0.34352952241897583
Validation loss: 1.898426692972901

Epoch: 6| Step: 11
Training loss: 1.0576751232147217
Validation loss: 1.8892001259711482

Epoch: 6| Step: 12
Training loss: 0.959758996963501
Validation loss: 1.885041098440847

Epoch: 6| Step: 13
Training loss: 1.1646203994750977
Validation loss: 1.9285206076919392

Epoch: 243| Step: 0
Training loss: 1.3898091316223145
Validation loss: 1.9552970188920216

Epoch: 6| Step: 1
Training loss: 1.0576997995376587
Validation loss: 1.9931491715933687

Epoch: 6| Step: 2
Training loss: 0.9742302894592285
Validation loss: 2.004472532579976

Epoch: 6| Step: 3
Training loss: 1.0062845945358276
Validation loss: 1.9759555708977483

Epoch: 6| Step: 4
Training loss: 2.057939052581787
Validation loss: 1.9984341770090082

Epoch: 6| Step: 5
Training loss: 0.7300558090209961
Validation loss: 1.9623544728884132

Epoch: 6| Step: 6
Training loss: 1.061704158782959
Validation loss: 1.973519420111051

Epoch: 6| Step: 7
Training loss: 0.7214481830596924
Validation loss: 1.9665133350638933

Epoch: 6| Step: 8
Training loss: 1.328040361404419
Validation loss: 1.9562906398568103

Epoch: 6| Step: 9
Training loss: 0.9849178791046143
Validation loss: 1.953772743542989

Epoch: 6| Step: 10
Training loss: 1.7998230457305908
Validation loss: 1.9651374073438748

Epoch: 6| Step: 11
Training loss: 1.3356306552886963
Validation loss: 1.9607684394364715

Epoch: 6| Step: 12
Training loss: 1.3423153162002563
Validation loss: 1.9370825995681107

Epoch: 6| Step: 13
Training loss: 1.0516688823699951
Validation loss: 1.9413983539868427

Epoch: 244| Step: 0
Training loss: 1.143507957458496
Validation loss: 1.9701013462517851

Epoch: 6| Step: 1
Training loss: 1.3455231189727783
Validation loss: 1.9844429339132001

Epoch: 6| Step: 2
Training loss: 1.278956651687622
Validation loss: 1.9710036285461918

Epoch: 6| Step: 3
Training loss: 0.6414712071418762
Validation loss: 1.9648474685607418

Epoch: 6| Step: 4
Training loss: 1.255890130996704
Validation loss: 1.9599918037332513

Epoch: 6| Step: 5
Training loss: 1.549041986465454
Validation loss: 1.948776824499971

Epoch: 6| Step: 6
Training loss: 0.6275180578231812
Validation loss: 1.9685051466829033

Epoch: 6| Step: 7
Training loss: 0.8360545635223389
Validation loss: 1.976926742061492

Epoch: 6| Step: 8
Training loss: 1.4775478839874268
Validation loss: 1.9830124083385672

Epoch: 6| Step: 9
Training loss: 1.4325168132781982
Validation loss: 1.9954681755394064

Epoch: 6| Step: 10
Training loss: 1.3213527202606201
Validation loss: 1.9796288782550442

Epoch: 6| Step: 11
Training loss: 1.4876327514648438
Validation loss: 1.9851229434372277

Epoch: 6| Step: 12
Training loss: 0.8400223851203918
Validation loss: 1.9953071763438563

Epoch: 6| Step: 13
Training loss: 1.7604345083236694
Validation loss: 1.9903364130245742

Epoch: 245| Step: 0
Training loss: 1.1658201217651367
Validation loss: 1.9894650969454037

Epoch: 6| Step: 1
Training loss: 0.8904049396514893
Validation loss: 1.9821090313696093

Epoch: 6| Step: 2
Training loss: 0.8074570894241333
Validation loss: 1.9987420125674176

Epoch: 6| Step: 3
Training loss: 1.1963893175125122
Validation loss: 1.9643556635866883

Epoch: 6| Step: 4
Training loss: 1.4827836751937866
Validation loss: 1.9413282614882275

Epoch: 6| Step: 5
Training loss: 1.4695054292678833
Validation loss: 1.9302805264790852

Epoch: 6| Step: 6
Training loss: 1.5622243881225586
Validation loss: 1.9130310243175876

Epoch: 6| Step: 7
Training loss: 1.2809100151062012
Validation loss: 1.9326055306260304

Epoch: 6| Step: 8
Training loss: 1.020827293395996
Validation loss: 1.9560949546034618

Epoch: 6| Step: 9
Training loss: 1.14601469039917
Validation loss: 1.9066797020614787

Epoch: 6| Step: 10
Training loss: 1.1128968000411987
Validation loss: 1.8729568835227721

Epoch: 6| Step: 11
Training loss: 1.0210838317871094
Validation loss: 1.8828146303853681

Epoch: 6| Step: 12
Training loss: 1.2885671854019165
Validation loss: 1.9250003291714577

Epoch: 6| Step: 13
Training loss: 1.8628616333007812
Validation loss: 1.9366745141244703

Epoch: 246| Step: 0
Training loss: 1.3498544692993164
Validation loss: 1.9661117869038736

Epoch: 6| Step: 1
Training loss: 0.9409091472625732
Validation loss: 1.9958890689316617

Epoch: 6| Step: 2
Training loss: 0.792813777923584
Validation loss: 2.025351470516574

Epoch: 6| Step: 3
Training loss: 1.277274489402771
Validation loss: 2.027673173976201

Epoch: 6| Step: 4
Training loss: 1.2675690650939941
Validation loss: 1.9950663710153231

Epoch: 6| Step: 5
Training loss: 1.6843209266662598
Validation loss: 1.9819386774493801

Epoch: 6| Step: 6
Training loss: 1.3286787271499634
Validation loss: 1.973230436284055

Epoch: 6| Step: 7
Training loss: 1.648169994354248
Validation loss: 1.963739925815213

Epoch: 6| Step: 8
Training loss: 1.069290041923523
Validation loss: 1.9774500682789793

Epoch: 6| Step: 9
Training loss: 1.0766863822937012
Validation loss: 1.9829089731298468

Epoch: 6| Step: 10
Training loss: 0.9374844431877136
Validation loss: 1.9418666362762451

Epoch: 6| Step: 11
Training loss: 1.080840826034546
Validation loss: 1.94022754187225

Epoch: 6| Step: 12
Training loss: 0.7987393140792847
Validation loss: 1.939211053232993

Epoch: 6| Step: 13
Training loss: 0.916321337223053
Validation loss: 1.9133672970597462

Epoch: 247| Step: 0
Training loss: 1.0215857028961182
Validation loss: 1.9164527282919934

Epoch: 6| Step: 1
Training loss: 0.9695084095001221
Validation loss: 1.907050855698124

Epoch: 6| Step: 2
Training loss: 1.4859514236450195
Validation loss: 1.902399601474885

Epoch: 6| Step: 3
Training loss: 1.0609114170074463
Validation loss: 1.919696795043125

Epoch: 6| Step: 4
Training loss: 1.4332990646362305
Validation loss: 1.9251976013183594

Epoch: 6| Step: 5
Training loss: 1.1201343536376953
Validation loss: 1.9331375386125298

Epoch: 6| Step: 6
Training loss: 1.1555664539337158
Validation loss: 1.9528134292171848

Epoch: 6| Step: 7
Training loss: 1.380638837814331
Validation loss: 2.0085418698608235

Epoch: 6| Step: 8
Training loss: 1.0884053707122803
Validation loss: 2.019322159469769

Epoch: 6| Step: 9
Training loss: 0.4654841423034668
Validation loss: 2.0349774155565488

Epoch: 6| Step: 10
Training loss: 1.2186546325683594
Validation loss: 2.0373653673356578

Epoch: 6| Step: 11
Training loss: 1.7649306058883667
Validation loss: 2.0477056849387383

Epoch: 6| Step: 12
Training loss: 1.0578298568725586
Validation loss: 2.0265440748583887

Epoch: 6| Step: 13
Training loss: 0.5440337657928467
Validation loss: 2.0053611609243576

Epoch: 248| Step: 0
Training loss: 1.155639886856079
Validation loss: 1.9729638766216975

Epoch: 6| Step: 1
Training loss: 0.947672963142395
Validation loss: 1.9538386508982668

Epoch: 6| Step: 2
Training loss: 0.8891624212265015
Validation loss: 1.9492650660135413

Epoch: 6| Step: 3
Training loss: 1.1577566862106323
Validation loss: 1.9526662185627928

Epoch: 6| Step: 4
Training loss: 0.8283677697181702
Validation loss: 1.9529565559920443

Epoch: 6| Step: 5
Training loss: 1.1721078157424927
Validation loss: 1.9298590408858431

Epoch: 6| Step: 6
Training loss: 1.0622644424438477
Validation loss: 1.9530082236054123

Epoch: 6| Step: 7
Training loss: 1.1989364624023438
Validation loss: 1.9416708100226618

Epoch: 6| Step: 8
Training loss: 0.9994572997093201
Validation loss: 1.9528068380971109

Epoch: 6| Step: 9
Training loss: 1.0777733325958252
Validation loss: 1.9459677973101217

Epoch: 6| Step: 10
Training loss: 0.9137561321258545
Validation loss: 1.9543943764061056

Epoch: 6| Step: 11
Training loss: 1.6326727867126465
Validation loss: 1.9608731398018457

Epoch: 6| Step: 12
Training loss: 1.4508042335510254
Validation loss: 1.9483957867468558

Epoch: 6| Step: 13
Training loss: 0.7273855209350586
Validation loss: 1.9413935933061826

Epoch: 249| Step: 0
Training loss: 0.9764014482498169
Validation loss: 1.9293882193103913

Epoch: 6| Step: 1
Training loss: 1.2973737716674805
Validation loss: 1.9234860520209036

Epoch: 6| Step: 2
Training loss: 0.7623457908630371
Validation loss: 1.9113503476624847

Epoch: 6| Step: 3
Training loss: 1.0776011943817139
Validation loss: 1.9296882819103938

Epoch: 6| Step: 4
Training loss: 0.9872364401817322
Validation loss: 1.9217024208396993

Epoch: 6| Step: 5
Training loss: 1.321929693222046
Validation loss: 1.9381760217810189

Epoch: 6| Step: 6
Training loss: 0.7419321537017822
Validation loss: 1.9501531060023973

Epoch: 6| Step: 7
Training loss: 1.1179076433181763
Validation loss: 1.9665834544807352

Epoch: 6| Step: 8
Training loss: 0.9544007778167725
Validation loss: 1.9968828693512948

Epoch: 6| Step: 9
Training loss: 1.3738281726837158
Validation loss: 2.0126994963615172

Epoch: 6| Step: 10
Training loss: 0.685126781463623
Validation loss: 2.025881977491481

Epoch: 6| Step: 11
Training loss: 1.2831330299377441
Validation loss: 2.0280236339056366

Epoch: 6| Step: 12
Training loss: 1.4157640933990479
Validation loss: 2.0116861622820617

Epoch: 6| Step: 13
Training loss: 1.3157010078430176
Validation loss: 2.0088470789694015

Epoch: 250| Step: 0
Training loss: 1.3387258052825928
Validation loss: 2.005995879891098

Epoch: 6| Step: 1
Training loss: 0.675639271736145
Validation loss: 1.9802950659105856

Epoch: 6| Step: 2
Training loss: 0.7151736617088318
Validation loss: 1.9841699600219727

Epoch: 6| Step: 3
Training loss: 1.117092490196228
Validation loss: 1.9635720022263066

Epoch: 6| Step: 4
Training loss: 1.176984429359436
Validation loss: 1.9453211343416603

Epoch: 6| Step: 5
Training loss: 1.4384489059448242
Validation loss: 1.9302777833836053

Epoch: 6| Step: 6
Training loss: 1.3029707670211792
Validation loss: 1.937775347822456

Epoch: 6| Step: 7
Training loss: 1.036208152770996
Validation loss: 1.922341412113559

Epoch: 6| Step: 8
Training loss: 0.9282702803611755
Validation loss: 1.9526746785768898

Epoch: 6| Step: 9
Training loss: 1.5336015224456787
Validation loss: 1.9385155131739955

Epoch: 6| Step: 10
Training loss: 0.725533664226532
Validation loss: 1.9335636990044707

Epoch: 6| Step: 11
Training loss: 0.5508413314819336
Validation loss: 1.9542750209890387

Epoch: 6| Step: 12
Training loss: 0.9424518346786499
Validation loss: 1.9618116476202523

Epoch: 6| Step: 13
Training loss: 1.722385048866272
Validation loss: 1.9821143534875685

Epoch: 251| Step: 0
Training loss: 0.9772395491600037
Validation loss: 1.9817847141655542

Epoch: 6| Step: 1
Training loss: 0.927112877368927
Validation loss: 2.0075425755593086

Epoch: 6| Step: 2
Training loss: 1.2191553115844727
Validation loss: 2.000163359026755

Epoch: 6| Step: 3
Training loss: 1.009779930114746
Validation loss: 2.0190450401716333

Epoch: 6| Step: 4
Training loss: 1.066556692123413
Validation loss: 2.0284859518851004

Epoch: 6| Step: 5
Training loss: 1.2000606060028076
Validation loss: 2.0259119746505574

Epoch: 6| Step: 6
Training loss: 1.1211494207382202
Validation loss: 2.0239710705254668

Epoch: 6| Step: 7
Training loss: 1.3122506141662598
Validation loss: 2.009542072972944

Epoch: 6| Step: 8
Training loss: 1.0254907608032227
Validation loss: 1.971867012721236

Epoch: 6| Step: 9
Training loss: 1.4892578125
Validation loss: 1.9522415899461316

Epoch: 6| Step: 10
Training loss: 0.7239973545074463
Validation loss: 1.9277496081526562

Epoch: 6| Step: 11
Training loss: 1.0975887775421143
Validation loss: 1.9251217778011034

Epoch: 6| Step: 12
Training loss: 1.0001420974731445
Validation loss: 1.9340822901777042

Epoch: 6| Step: 13
Training loss: 0.7878968715667725
Validation loss: 1.9301734996098343

Epoch: 252| Step: 0
Training loss: 0.8820275068283081
Validation loss: 1.9143353380182737

Epoch: 6| Step: 1
Training loss: 1.3266692161560059
Validation loss: 1.9433341000669746

Epoch: 6| Step: 2
Training loss: 1.0189553499221802
Validation loss: 1.943278020428073

Epoch: 6| Step: 3
Training loss: 0.9041497707366943
Validation loss: 1.9412120772946266

Epoch: 6| Step: 4
Training loss: 1.4196765422821045
Validation loss: 1.9652034390357234

Epoch: 6| Step: 5
Training loss: 1.335022211074829
Validation loss: 1.9839846280313307

Epoch: 6| Step: 6
Training loss: 1.3066797256469727
Validation loss: 1.9764698513092533

Epoch: 6| Step: 7
Training loss: 0.7431678771972656
Validation loss: 1.9757189263579666

Epoch: 6| Step: 8
Training loss: 0.7330877184867859
Validation loss: 1.9424910147984822

Epoch: 6| Step: 9
Training loss: 0.9731764793395996
Validation loss: 1.9496155567066644

Epoch: 6| Step: 10
Training loss: 0.9046063423156738
Validation loss: 1.9265226010353333

Epoch: 6| Step: 11
Training loss: 0.8602948188781738
Validation loss: 1.91275865544555

Epoch: 6| Step: 12
Training loss: 1.648179531097412
Validation loss: 1.9282573448714388

Epoch: 6| Step: 13
Training loss: 0.7206271886825562
Validation loss: 1.9123245503312798

Epoch: 253| Step: 0
Training loss: 1.1312456130981445
Validation loss: 1.9381239234760244

Epoch: 6| Step: 1
Training loss: 0.57095867395401
Validation loss: 1.9739036226785311

Epoch: 6| Step: 2
Training loss: 0.6340154409408569
Validation loss: 2.024676699792185

Epoch: 6| Step: 3
Training loss: 1.0917165279388428
Validation loss: 2.0670385155626523

Epoch: 6| Step: 4
Training loss: 1.0085951089859009
Validation loss: 2.085891064777169

Epoch: 6| Step: 5
Training loss: 0.8670939207077026
Validation loss: 2.0813238825849307

Epoch: 6| Step: 6
Training loss: 1.0917929410934448
Validation loss: 2.035959692411525

Epoch: 6| Step: 7
Training loss: 0.7055821418762207
Validation loss: 2.0396901228094615

Epoch: 6| Step: 8
Training loss: 1.212003469467163
Validation loss: 2.0171905281723186

Epoch: 6| Step: 9
Training loss: 1.1625611782073975
Validation loss: 1.9737679958343506

Epoch: 6| Step: 10
Training loss: 1.0916367769241333
Validation loss: 1.9480642362307476

Epoch: 6| Step: 11
Training loss: 2.2890634536743164
Validation loss: 1.9522410695270827

Epoch: 6| Step: 12
Training loss: 1.2495670318603516
Validation loss: 1.9460022039310907

Epoch: 6| Step: 13
Training loss: 0.9898538589477539
Validation loss: 1.9462773992169289

Epoch: 254| Step: 0
Training loss: 0.9197854995727539
Validation loss: 1.9182330792950046

Epoch: 6| Step: 1
Training loss: 0.6335479617118835
Validation loss: 1.939432264656149

Epoch: 6| Step: 2
Training loss: 0.9394502639770508
Validation loss: 1.9117113518458542

Epoch: 6| Step: 3
Training loss: 0.8494890928268433
Validation loss: 1.923048548800971

Epoch: 6| Step: 4
Training loss: 1.1351814270019531
Validation loss: 1.9351267378817323

Epoch: 6| Step: 5
Training loss: 1.2161976099014282
Validation loss: 1.9584436301262147

Epoch: 6| Step: 6
Training loss: 1.3618203401565552
Validation loss: 1.9405729219477663

Epoch: 6| Step: 7
Training loss: 1.0689589977264404
Validation loss: 1.917756877919679

Epoch: 6| Step: 8
Training loss: 0.9988349080085754
Validation loss: 1.9398370801761586

Epoch: 6| Step: 9
Training loss: 1.1507035493850708
Validation loss: 1.9587224914181618

Epoch: 6| Step: 10
Training loss: 0.7369413375854492
Validation loss: 1.979917041717037

Epoch: 6| Step: 11
Training loss: 0.9312888383865356
Validation loss: 1.9919435695935321

Epoch: 6| Step: 12
Training loss: 1.2849903106689453
Validation loss: 1.9910335233134608

Epoch: 6| Step: 13
Training loss: 1.1031824350357056
Validation loss: 2.0296209037944837

Epoch: 255| Step: 0
Training loss: 0.8077985048294067
Validation loss: 1.9991254537336287

Epoch: 6| Step: 1
Training loss: 0.8942885398864746
Validation loss: 1.9852297254787978

Epoch: 6| Step: 2
Training loss: 1.2696890830993652
Validation loss: 1.9744842847188313

Epoch: 6| Step: 3
Training loss: 1.1073956489562988
Validation loss: 1.9460815050268685

Epoch: 6| Step: 4
Training loss: 1.0737608671188354
Validation loss: 1.9206263480647918

Epoch: 6| Step: 5
Training loss: 1.4151127338409424
Validation loss: 1.9039309973357825

Epoch: 6| Step: 6
Training loss: 0.7053442597389221
Validation loss: 1.90333580329854

Epoch: 6| Step: 7
Training loss: 0.9665494561195374
Validation loss: 1.896415566885343

Epoch: 6| Step: 8
Training loss: 1.021998405456543
Validation loss: 1.8896722896124727

Epoch: 6| Step: 9
Training loss: 1.2267154455184937
Validation loss: 1.8693311534902102

Epoch: 6| Step: 10
Training loss: 1.0106956958770752
Validation loss: 1.8899456557407175

Epoch: 6| Step: 11
Training loss: 0.8922111392021179
Validation loss: 1.903782900943551

Epoch: 6| Step: 12
Training loss: 1.1885900497436523
Validation loss: 1.9484803407422957

Epoch: 6| Step: 13
Training loss: 0.8097999691963196
Validation loss: 1.9499306319862284

Epoch: 256| Step: 0
Training loss: 0.8126727938652039
Validation loss: 1.957588141964328

Epoch: 6| Step: 1
Training loss: 0.8608555197715759
Validation loss: 1.962931151031166

Epoch: 6| Step: 2
Training loss: 0.7719053030014038
Validation loss: 1.9387835046296478

Epoch: 6| Step: 3
Training loss: 1.5505497455596924
Validation loss: 1.939329767739901

Epoch: 6| Step: 4
Training loss: 0.8878180980682373
Validation loss: 1.9413399593804472

Epoch: 6| Step: 5
Training loss: 1.0068883895874023
Validation loss: 1.94568508414812

Epoch: 6| Step: 6
Training loss: 0.614463746547699
Validation loss: 1.9386916878402873

Epoch: 6| Step: 7
Training loss: 1.4757153987884521
Validation loss: 1.9684554146182152

Epoch: 6| Step: 8
Training loss: 0.5000136494636536
Validation loss: 1.9541194733753

Epoch: 6| Step: 9
Training loss: 1.4663623571395874
Validation loss: 1.9481522472955848

Epoch: 6| Step: 10
Training loss: 1.1323914527893066
Validation loss: 1.9586830831343127

Epoch: 6| Step: 11
Training loss: 0.8681796193122864
Validation loss: 1.9273927134852256

Epoch: 6| Step: 12
Training loss: 1.043097734451294
Validation loss: 1.9139765206203665

Epoch: 6| Step: 13
Training loss: 1.076140284538269
Validation loss: 1.9289442851979246

Epoch: 257| Step: 0
Training loss: 0.7847745418548584
Validation loss: 1.9187980031454435

Epoch: 6| Step: 1
Training loss: 0.8435325622558594
Validation loss: 1.9200069212144422

Epoch: 6| Step: 2
Training loss: 1.1516001224517822
Validation loss: 1.929240334418512

Epoch: 6| Step: 3
Training loss: 0.7887529134750366
Validation loss: 1.9276730424614363

Epoch: 6| Step: 4
Training loss: 1.0814144611358643
Validation loss: 1.9438561829187537

Epoch: 6| Step: 5
Training loss: 0.9927810430526733
Validation loss: 1.9568193933015228

Epoch: 6| Step: 6
Training loss: 0.9511715173721313
Validation loss: 1.9667219654206307

Epoch: 6| Step: 7
Training loss: 1.1400554180145264
Validation loss: 1.9636432688723329

Epoch: 6| Step: 8
Training loss: 1.5057605504989624
Validation loss: 1.9805789827018656

Epoch: 6| Step: 9
Training loss: 0.8707046508789062
Validation loss: 1.9574618544629825

Epoch: 6| Step: 10
Training loss: 1.0890130996704102
Validation loss: 1.9443113573135868

Epoch: 6| Step: 11
Training loss: 0.8442081809043884
Validation loss: 1.9238045548879972

Epoch: 6| Step: 12
Training loss: 1.1354286670684814
Validation loss: 1.8857413748259186

Epoch: 6| Step: 13
Training loss: 1.100587248802185
Validation loss: 1.905870088966944

Epoch: 258| Step: 0
Training loss: 1.3793301582336426
Validation loss: 1.90558115513094

Epoch: 6| Step: 1
Training loss: 0.36703044176101685
Validation loss: 1.8979404869899954

Epoch: 6| Step: 2
Training loss: 1.2026491165161133
Validation loss: 1.930144457406895

Epoch: 6| Step: 3
Training loss: 0.8776633739471436
Validation loss: 1.9547895628918883

Epoch: 6| Step: 4
Training loss: 1.6883293390274048
Validation loss: 1.9637264064563218

Epoch: 6| Step: 5
Training loss: 0.4288373589515686
Validation loss: 1.9518493478016188

Epoch: 6| Step: 6
Training loss: 0.6775974035263062
Validation loss: 1.9716088489819599

Epoch: 6| Step: 7
Training loss: 0.715735673904419
Validation loss: 1.9530607320929085

Epoch: 6| Step: 8
Training loss: 1.141462802886963
Validation loss: 1.9660083401587702

Epoch: 6| Step: 9
Training loss: 1.4149634838104248
Validation loss: 1.9774815113313737

Epoch: 6| Step: 10
Training loss: 0.938259482383728
Validation loss: 1.9657893808939124

Epoch: 6| Step: 11
Training loss: 1.1442770957946777
Validation loss: 1.9530015530124787

Epoch: 6| Step: 12
Training loss: 0.8736723065376282
Validation loss: 1.946846903011363

Epoch: 6| Step: 13
Training loss: 0.886591911315918
Validation loss: 1.9194691040182625

Epoch: 259| Step: 0
Training loss: 1.2551968097686768
Validation loss: 1.9125461757823985

Epoch: 6| Step: 1
Training loss: 0.7637888193130493
Validation loss: 1.9235244925304125

Epoch: 6| Step: 2
Training loss: 1.5475366115570068
Validation loss: 1.9434851984823904

Epoch: 6| Step: 3
Training loss: 0.40951007604599
Validation loss: 1.9560157419532858

Epoch: 6| Step: 4
Training loss: 1.0982859134674072
Validation loss: 1.9691644355814943

Epoch: 6| Step: 5
Training loss: 1.614398717880249
Validation loss: 1.9853782499990156

Epoch: 6| Step: 6
Training loss: 0.7121186256408691
Validation loss: 1.968074966502446

Epoch: 6| Step: 7
Training loss: 0.8582272529602051
Validation loss: 1.9577607441973943

Epoch: 6| Step: 8
Training loss: 1.1425790786743164
Validation loss: 1.9807586259739374

Epoch: 6| Step: 9
Training loss: 0.7242776155471802
Validation loss: 1.9151192454881565

Epoch: 6| Step: 10
Training loss: 0.825076699256897
Validation loss: 1.9319337567975443

Epoch: 6| Step: 11
Training loss: 0.7558161020278931
Validation loss: 1.8979864966484807

Epoch: 6| Step: 12
Training loss: 1.0671610832214355
Validation loss: 1.8945133378428798

Epoch: 6| Step: 13
Training loss: 1.0373648405075073
Validation loss: 1.8789870008345573

Epoch: 260| Step: 0
Training loss: 0.8407412767410278
Validation loss: 1.9134749750937186

Epoch: 6| Step: 1
Training loss: 0.8609139323234558
Validation loss: 1.9385249614715576

Epoch: 6| Step: 2
Training loss: 0.4215836822986603
Validation loss: 1.968939499188495

Epoch: 6| Step: 3
Training loss: 0.8891090750694275
Validation loss: 2.0102614843717186

Epoch: 6| Step: 4
Training loss: 1.3910181522369385
Validation loss: 2.0124796628952026

Epoch: 6| Step: 5
Training loss: 1.0203511714935303
Validation loss: 1.994031883055164

Epoch: 6| Step: 6
Training loss: 1.1163272857666016
Validation loss: 1.9898876169676423

Epoch: 6| Step: 7
Training loss: 1.1676955223083496
Validation loss: 1.9957367835506317

Epoch: 6| Step: 8
Training loss: 1.0417611598968506
Validation loss: 1.9969542385429464

Epoch: 6| Step: 9
Training loss: 0.7198815941810608
Validation loss: 1.9998438794125792

Epoch: 6| Step: 10
Training loss: 0.7830238938331604
Validation loss: 1.973728520895845

Epoch: 6| Step: 11
Training loss: 1.3356900215148926
Validation loss: 1.935750158884192

Epoch: 6| Step: 12
Training loss: 1.024829626083374
Validation loss: 1.9638839191006077

Epoch: 6| Step: 13
Training loss: 1.1564021110534668
Validation loss: 1.9426312984958771

Epoch: 261| Step: 0
Training loss: 0.8403319120407104
Validation loss: 1.972154059717732

Epoch: 6| Step: 1
Training loss: 1.0027095079421997
Validation loss: 1.9714914650045416

Epoch: 6| Step: 2
Training loss: 1.1531922817230225
Validation loss: 1.980724080916374

Epoch: 6| Step: 3
Training loss: 1.0450190305709839
Validation loss: 1.9926190863373459

Epoch: 6| Step: 4
Training loss: 0.716654360294342
Validation loss: 2.0023814657683014

Epoch: 6| Step: 5
Training loss: 0.8500616550445557
Validation loss: 2.026752127114163

Epoch: 6| Step: 6
Training loss: 1.7092021703720093
Validation loss: 2.0267178448297645

Epoch: 6| Step: 7
Training loss: 1.4589065313339233
Validation loss: 2.061692305790481

Epoch: 6| Step: 8
Training loss: 0.7008672952651978
Validation loss: 2.0398065556762037

Epoch: 6| Step: 9
Training loss: 0.5787064433097839
Validation loss: 2.017002364640595

Epoch: 6| Step: 10
Training loss: 1.6576309204101562
Validation loss: 1.9833559887383574

Epoch: 6| Step: 11
Training loss: 0.7647294998168945
Validation loss: 1.970813266692623

Epoch: 6| Step: 12
Training loss: 1.0378296375274658
Validation loss: 1.924523115158081

Epoch: 6| Step: 13
Training loss: 0.7983390092849731
Validation loss: 1.9072994993579002

Epoch: 262| Step: 0
Training loss: 1.227210283279419
Validation loss: 1.8630492315497449

Epoch: 6| Step: 1
Training loss: 0.796481728553772
Validation loss: 1.8419318878522484

Epoch: 6| Step: 2
Training loss: 0.8748812675476074
Validation loss: 1.855158334137291

Epoch: 6| Step: 3
Training loss: 1.6858903169631958
Validation loss: 1.8488329366971088

Epoch: 6| Step: 4
Training loss: 1.1320236921310425
Validation loss: 1.8444916304721628

Epoch: 6| Step: 5
Training loss: 1.3141279220581055
Validation loss: 1.804865760187949

Epoch: 6| Step: 6
Training loss: 1.2776024341583252
Validation loss: 1.8099034652915051

Epoch: 6| Step: 7
Training loss: 1.253277063369751
Validation loss: 1.8775812041374944

Epoch: 6| Step: 8
Training loss: 1.1055114269256592
Validation loss: 1.9302298650946668

Epoch: 6| Step: 9
Training loss: 0.7935110330581665
Validation loss: 1.9529627318023353

Epoch: 6| Step: 10
Training loss: 0.8646312952041626
Validation loss: 1.9705258095136253

Epoch: 6| Step: 11
Training loss: 1.4499242305755615
Validation loss: 1.97951756241501

Epoch: 6| Step: 12
Training loss: 0.58436119556427
Validation loss: 2.015711829226504

Epoch: 6| Step: 13
Training loss: 1.2768150568008423
Validation loss: 2.0023502175525953

Epoch: 263| Step: 0
Training loss: 1.1469535827636719
Validation loss: 1.9952356853792745

Epoch: 6| Step: 1
Training loss: 0.7254540920257568
Validation loss: 1.9569325754719396

Epoch: 6| Step: 2
Training loss: 1.4184774160385132
Validation loss: 1.9509673964592718

Epoch: 6| Step: 3
Training loss: 1.254955530166626
Validation loss: 1.946746010934153

Epoch: 6| Step: 4
Training loss: 1.566105842590332
Validation loss: 1.9390698312431254

Epoch: 6| Step: 5
Training loss: 0.7536731958389282
Validation loss: 1.9570010797951811

Epoch: 6| Step: 6
Training loss: 1.2894444465637207
Validation loss: 1.944815202425885

Epoch: 6| Step: 7
Training loss: 0.3600761890411377
Validation loss: 1.9305502317285026

Epoch: 6| Step: 8
Training loss: 1.2130193710327148
Validation loss: 1.936697567662885

Epoch: 6| Step: 9
Training loss: 0.7109025716781616
Validation loss: 1.9413166969053206

Epoch: 6| Step: 10
Training loss: 0.6601313948631287
Validation loss: 1.968747487632177

Epoch: 6| Step: 11
Training loss: 1.0904862880706787
Validation loss: 1.992911074751167

Epoch: 6| Step: 12
Training loss: 0.8687008619308472
Validation loss: 1.9901985917040097

Epoch: 6| Step: 13
Training loss: 0.871437668800354
Validation loss: 1.969190474479429

Epoch: 264| Step: 0
Training loss: 1.2107460498809814
Validation loss: 1.9489400925174836

Epoch: 6| Step: 1
Training loss: 0.9064344167709351
Validation loss: 1.930521413844119

Epoch: 6| Step: 2
Training loss: 0.8020349144935608
Validation loss: 1.9406888036317722

Epoch: 6| Step: 3
Training loss: 1.1546411514282227
Validation loss: 1.9141649071888258

Epoch: 6| Step: 4
Training loss: 0.6766356229782104
Validation loss: 1.9215302416073379

Epoch: 6| Step: 5
Training loss: 1.0583186149597168
Validation loss: 1.9362420881948164

Epoch: 6| Step: 6
Training loss: 1.1507680416107178
Validation loss: 1.9566101284437283

Epoch: 6| Step: 7
Training loss: 0.6345219612121582
Validation loss: 1.9872345129648845

Epoch: 6| Step: 8
Training loss: 0.7763397693634033
Validation loss: 2.0094549168822584

Epoch: 6| Step: 9
Training loss: 1.2607536315917969
Validation loss: 2.0053666701880832

Epoch: 6| Step: 10
Training loss: 1.0711942911148071
Validation loss: 2.0024735812217958

Epoch: 6| Step: 11
Training loss: 0.6712562441825867
Validation loss: 1.9899894165736374

Epoch: 6| Step: 12
Training loss: 1.1734914779663086
Validation loss: 1.972551594498337

Epoch: 6| Step: 13
Training loss: 1.2354363203048706
Validation loss: 1.931925881293512

Epoch: 265| Step: 0
Training loss: 0.42316001653671265
Validation loss: 1.9051523670073478

Epoch: 6| Step: 1
Training loss: 1.0354416370391846
Validation loss: 1.8770808558310232

Epoch: 6| Step: 2
Training loss: 1.1700185537338257
Validation loss: 1.9187381216274795

Epoch: 6| Step: 3
Training loss: 0.8000025153160095
Validation loss: 1.9321574382884528

Epoch: 6| Step: 4
Training loss: 1.498940348625183
Validation loss: 1.9484282129554338

Epoch: 6| Step: 5
Training loss: 1.30045485496521
Validation loss: 1.9619008674416492

Epoch: 6| Step: 6
Training loss: 0.9064682722091675
Validation loss: 1.9498661205332766

Epoch: 6| Step: 7
Training loss: 1.1466675996780396
Validation loss: 1.9364554984595186

Epoch: 6| Step: 8
Training loss: 0.507574200630188
Validation loss: 1.9489103824861589

Epoch: 6| Step: 9
Training loss: 0.6908265948295593
Validation loss: 1.962450986267418

Epoch: 6| Step: 10
Training loss: 1.5630947351455688
Validation loss: 1.9889138231995285

Epoch: 6| Step: 11
Training loss: 0.948624849319458
Validation loss: 2.0122495030844085

Epoch: 6| Step: 12
Training loss: 0.8453477025032043
Validation loss: 1.9859154608941847

Epoch: 6| Step: 13
Training loss: 0.5727095007896423
Validation loss: 1.9626500401445615

Epoch: 266| Step: 0
Training loss: 0.718015193939209
Validation loss: 1.923183721880759

Epoch: 6| Step: 1
Training loss: 1.235266923904419
Validation loss: 1.9093795027784122

Epoch: 6| Step: 2
Training loss: 0.9729938507080078
Validation loss: 1.8877056849900113

Epoch: 6| Step: 3
Training loss: 0.9390742182731628
Validation loss: 1.8821632451908563

Epoch: 6| Step: 4
Training loss: 0.7694900035858154
Validation loss: 1.8875265608551681

Epoch: 6| Step: 5
Training loss: 1.365255355834961
Validation loss: 1.864987378479332

Epoch: 6| Step: 6
Training loss: 0.9524611234664917
Validation loss: 1.9044023316393617

Epoch: 6| Step: 7
Training loss: 0.566199779510498
Validation loss: 1.9329024476389731

Epoch: 6| Step: 8
Training loss: 0.746574878692627
Validation loss: 1.9211623745579873

Epoch: 6| Step: 9
Training loss: 0.6589536666870117
Validation loss: 1.9759008794702508

Epoch: 6| Step: 10
Training loss: 1.2846707105636597
Validation loss: 1.9711949594559208

Epoch: 6| Step: 11
Training loss: 0.7157367467880249
Validation loss: 1.9698162130130235

Epoch: 6| Step: 12
Training loss: 1.1444079875946045
Validation loss: 1.9827905803598382

Epoch: 6| Step: 13
Training loss: 0.5749994516372681
Validation loss: 1.9672002817994805

Epoch: 267| Step: 0
Training loss: 1.0139492750167847
Validation loss: 1.9867198518527451

Epoch: 6| Step: 1
Training loss: 0.36329731345176697
Validation loss: 1.9753562404263405

Epoch: 6| Step: 2
Training loss: 0.8778848648071289
Validation loss: 1.9733717415922432

Epoch: 6| Step: 3
Training loss: 0.7283239364624023
Validation loss: 1.9576086075075212

Epoch: 6| Step: 4
Training loss: 0.9035478234291077
Validation loss: 1.9766146982869794

Epoch: 6| Step: 5
Training loss: 1.1031829118728638
Validation loss: 1.9684347286019275

Epoch: 6| Step: 6
Training loss: 1.6839590072631836
Validation loss: 1.9478198764144734

Epoch: 6| Step: 7
Training loss: 1.47682523727417
Validation loss: 1.9435751899596183

Epoch: 6| Step: 8
Training loss: 0.8247498273849487
Validation loss: 1.9372527150697605

Epoch: 6| Step: 9
Training loss: 0.5991796851158142
Validation loss: 1.9276806449377408

Epoch: 6| Step: 10
Training loss: 0.4222131669521332
Validation loss: 1.9278258687706404

Epoch: 6| Step: 11
Training loss: 1.1507654190063477
Validation loss: 1.9103401796792143

Epoch: 6| Step: 12
Training loss: 0.8215030431747437
Validation loss: 1.9051942902226602

Epoch: 6| Step: 13
Training loss: 0.5060031414031982
Validation loss: 1.917763303684932

Epoch: 268| Step: 0
Training loss: 1.1789830923080444
Validation loss: 1.9328221377506052

Epoch: 6| Step: 1
Training loss: 1.058022141456604
Validation loss: 1.9794667959213257

Epoch: 6| Step: 2
Training loss: 1.1452741622924805
Validation loss: 1.9783113182231944

Epoch: 6| Step: 3
Training loss: 0.9475771188735962
Validation loss: 1.9711982562977781

Epoch: 6| Step: 4
Training loss: 0.7784454226493835
Validation loss: 1.9677550420966199

Epoch: 6| Step: 5
Training loss: 1.0911505222320557
Validation loss: 1.9568915777308966

Epoch: 6| Step: 6
Training loss: 0.7573436498641968
Validation loss: 1.9403751768091673

Epoch: 6| Step: 7
Training loss: 0.8421010375022888
Validation loss: 1.9597139076520038

Epoch: 6| Step: 8
Training loss: 0.8368638753890991
Validation loss: 1.9444838852010748

Epoch: 6| Step: 9
Training loss: 1.0680477619171143
Validation loss: 1.9582034208441292

Epoch: 6| Step: 10
Training loss: 1.2063363790512085
Validation loss: 1.9546356842082033

Epoch: 6| Step: 11
Training loss: 0.6298157572746277
Validation loss: 1.9595552605967368

Epoch: 6| Step: 12
Training loss: 0.4246683716773987
Validation loss: 1.9651882469013173

Epoch: 6| Step: 13
Training loss: 0.8357154130935669
Validation loss: 1.9263895942318825

Epoch: 269| Step: 0
Training loss: 1.1116943359375
Validation loss: 1.9130822996939383

Epoch: 6| Step: 1
Training loss: 0.7923747301101685
Validation loss: 1.930646469516139

Epoch: 6| Step: 2
Training loss: 1.668562412261963
Validation loss: 1.9043438178236767

Epoch: 6| Step: 3
Training loss: 0.8355910778045654
Validation loss: 1.9157004984476234

Epoch: 6| Step: 4
Training loss: 0.36612337827682495
Validation loss: 1.9218974715919905

Epoch: 6| Step: 5
Training loss: 0.4654499292373657
Validation loss: 1.9145278084662654

Epoch: 6| Step: 6
Training loss: 0.6926255226135254
Validation loss: 1.9287675696034585

Epoch: 6| Step: 7
Training loss: 0.8604040145874023
Validation loss: 1.9467696195007653

Epoch: 6| Step: 8
Training loss: 0.8806344270706177
Validation loss: 1.9641426917045348

Epoch: 6| Step: 9
Training loss: 0.6934428215026855
Validation loss: 1.9726591328138947

Epoch: 6| Step: 10
Training loss: 0.8731504082679749
Validation loss: 1.9871670405069988

Epoch: 6| Step: 11
Training loss: 1.1135303974151611
Validation loss: 2.006353937169557

Epoch: 6| Step: 12
Training loss: 1.1110285520553589
Validation loss: 1.9979525894247077

Epoch: 6| Step: 13
Training loss: 1.233169436454773
Validation loss: 2.0012738063771236

Epoch: 270| Step: 0
Training loss: 0.5653128623962402
Validation loss: 1.9884963689311859

Epoch: 6| Step: 1
Training loss: 1.1696536540985107
Validation loss: 1.9819848639990694

Epoch: 6| Step: 2
Training loss: 0.9316076636314392
Validation loss: 1.944669524828593

Epoch: 6| Step: 3
Training loss: 0.699609637260437
Validation loss: 1.9355761376760339

Epoch: 6| Step: 4
Training loss: 1.0182199478149414
Validation loss: 1.9204616700449297

Epoch: 6| Step: 5
Training loss: 0.8050004839897156
Validation loss: 1.9183419289127472

Epoch: 6| Step: 6
Training loss: 0.9153895378112793
Validation loss: 1.9272633278241722

Epoch: 6| Step: 7
Training loss: 0.4808463454246521
Validation loss: 1.9222949012633292

Epoch: 6| Step: 8
Training loss: 0.950744092464447
Validation loss: 1.93479674349549

Epoch: 6| Step: 9
Training loss: 0.9803556203842163
Validation loss: 1.9442562518581268

Epoch: 6| Step: 10
Training loss: 1.0774105787277222
Validation loss: 1.9305068446743874

Epoch: 6| Step: 11
Training loss: 0.8259900808334351
Validation loss: 1.9237753652757215

Epoch: 6| Step: 12
Training loss: 0.5339803099632263
Validation loss: 1.955023355381463

Epoch: 6| Step: 13
Training loss: 1.4252703189849854
Validation loss: 1.9367811910567745

Epoch: 271| Step: 0
Training loss: 0.6943750977516174
Validation loss: 1.9835324979597522

Epoch: 6| Step: 1
Training loss: 1.103226900100708
Validation loss: 1.9781516252025482

Epoch: 6| Step: 2
Training loss: 1.2824918031692505
Validation loss: 1.9823888168540051

Epoch: 6| Step: 3
Training loss: 0.8050701022148132
Validation loss: 1.9767021440690564

Epoch: 6| Step: 4
Training loss: 0.628265917301178
Validation loss: 1.9652208999920917

Epoch: 6| Step: 5
Training loss: 1.2594548463821411
Validation loss: 1.9642213544537943

Epoch: 6| Step: 6
Training loss: 0.7995725274085999
Validation loss: 1.9496005017270324

Epoch: 6| Step: 7
Training loss: 1.3338377475738525
Validation loss: 1.944369444283106

Epoch: 6| Step: 8
Training loss: 0.6422382593154907
Validation loss: 1.9315944217866468

Epoch: 6| Step: 9
Training loss: 0.6198570728302002
Validation loss: 1.9380304313475085

Epoch: 6| Step: 10
Training loss: 0.8007720708847046
Validation loss: 1.926984251186412

Epoch: 6| Step: 11
Training loss: 0.8521528244018555
Validation loss: 1.9255987085321897

Epoch: 6| Step: 12
Training loss: 0.592553973197937
Validation loss: 1.945844260595178

Epoch: 6| Step: 13
Training loss: 0.7052689790725708
Validation loss: 1.9622863185021184

Epoch: 272| Step: 0
Training loss: 0.9266116619110107
Validation loss: 1.9430468723338137

Epoch: 6| Step: 1
Training loss: 0.5786994695663452
Validation loss: 1.9514839546654814

Epoch: 6| Step: 2
Training loss: 0.5781174898147583
Validation loss: 1.967197964268346

Epoch: 6| Step: 3
Training loss: 0.8586850762367249
Validation loss: 1.9661494416575278

Epoch: 6| Step: 4
Training loss: 1.1458066701889038
Validation loss: 1.9760104610073952

Epoch: 6| Step: 5
Training loss: 0.7433370351791382
Validation loss: 1.9813283310141614

Epoch: 6| Step: 6
Training loss: 1.161851406097412
Validation loss: 1.9612002680378575

Epoch: 6| Step: 7
Training loss: 1.005950689315796
Validation loss: 1.9855583739537064

Epoch: 6| Step: 8
Training loss: 1.3142062425613403
Validation loss: 1.9528691678918817

Epoch: 6| Step: 9
Training loss: 0.604288637638092
Validation loss: 1.9507388068783669

Epoch: 6| Step: 10
Training loss: 0.843448281288147
Validation loss: 1.973756694024609

Epoch: 6| Step: 11
Training loss: 0.7812535762786865
Validation loss: 1.9670820031114804

Epoch: 6| Step: 12
Training loss: 0.5889461040496826
Validation loss: 1.9457333831376926

Epoch: 6| Step: 13
Training loss: 0.8834577202796936
Validation loss: 1.9698580131735852

Epoch: 273| Step: 0
Training loss: 1.0169997215270996
Validation loss: 1.9670555514674033

Epoch: 6| Step: 1
Training loss: 1.2360899448394775
Validation loss: 1.9270278612772624

Epoch: 6| Step: 2
Training loss: 0.7923626899719238
Validation loss: 1.9358463095080467

Epoch: 6| Step: 3
Training loss: 0.3812289834022522
Validation loss: 1.9441761303973455

Epoch: 6| Step: 4
Training loss: 0.8267558813095093
Validation loss: 1.9370816715302006

Epoch: 6| Step: 5
Training loss: 0.46013179421424866
Validation loss: 1.9363008622200257

Epoch: 6| Step: 6
Training loss: 1.2646929025650024
Validation loss: 1.9399439134905416

Epoch: 6| Step: 7
Training loss: 1.5025956630706787
Validation loss: 1.930858870988251

Epoch: 6| Step: 8
Training loss: 0.43586939573287964
Validation loss: 1.937827182072465

Epoch: 6| Step: 9
Training loss: 0.2539803385734558
Validation loss: 1.9741486913414412

Epoch: 6| Step: 10
Training loss: 0.8000088930130005
Validation loss: 1.987336665071467

Epoch: 6| Step: 11
Training loss: 1.0797444581985474
Validation loss: 1.97329028191105

Epoch: 6| Step: 12
Training loss: 0.9258561134338379
Validation loss: 1.97307462076987

Epoch: 6| Step: 13
Training loss: 1.3295246362686157
Validation loss: 1.9487445328825264

Epoch: 274| Step: 0
Training loss: 0.7644076943397522
Validation loss: 1.9358836976430749

Epoch: 6| Step: 1
Training loss: 1.268786072731018
Validation loss: 1.9495028180460776

Epoch: 6| Step: 2
Training loss: 0.4965819716453552
Validation loss: 1.9103561601331156

Epoch: 6| Step: 3
Training loss: 0.44851934909820557
Validation loss: 1.9172504563485422

Epoch: 6| Step: 4
Training loss: 0.7861990928649902
Validation loss: 1.9010462658379668

Epoch: 6| Step: 5
Training loss: 1.3286967277526855
Validation loss: 1.917350043532669

Epoch: 6| Step: 6
Training loss: 0.7618063688278198
Validation loss: 1.892915718017086

Epoch: 6| Step: 7
Training loss: 0.6026718616485596
Validation loss: 1.9234256000928982

Epoch: 6| Step: 8
Training loss: 0.6581429243087769
Validation loss: 1.9629563362367692

Epoch: 6| Step: 9
Training loss: 0.46816930174827576
Validation loss: 1.9437053665038078

Epoch: 6| Step: 10
Training loss: 0.684115469455719
Validation loss: 1.9320980118167015

Epoch: 6| Step: 11
Training loss: 0.994655430316925
Validation loss: 1.9138488256803123

Epoch: 6| Step: 12
Training loss: 1.552643895149231
Validation loss: 1.8955947083811606

Epoch: 6| Step: 13
Training loss: 1.3437994718551636
Validation loss: 1.8872360183346657

Epoch: 275| Step: 0
Training loss: 0.9859707951545715
Validation loss: 1.8780215581258137

Epoch: 6| Step: 1
Training loss: 0.7720515131950378
Validation loss: 1.9126137905223395

Epoch: 6| Step: 2
Training loss: 1.2783206701278687
Validation loss: 1.9055735488091745

Epoch: 6| Step: 3
Training loss: 0.6926126480102539
Validation loss: 1.8909730988164102

Epoch: 6| Step: 4
Training loss: 0.7765070199966431
Validation loss: 1.8902263000447264

Epoch: 6| Step: 5
Training loss: 0.8780852556228638
Validation loss: 1.8862975874254782

Epoch: 6| Step: 6
Training loss: 1.044851541519165
Validation loss: 1.9042231600771669

Epoch: 6| Step: 7
Training loss: 0.8655012249946594
Validation loss: 1.9377650355779996

Epoch: 6| Step: 8
Training loss: 0.5555598735809326
Validation loss: 1.9394514355608212

Epoch: 6| Step: 9
Training loss: 0.7106715440750122
Validation loss: 1.9412647883097331

Epoch: 6| Step: 10
Training loss: 1.1058889627456665
Validation loss: 1.9561188413250832

Epoch: 6| Step: 11
Training loss: 0.6336886286735535
Validation loss: 1.9528420894376692

Epoch: 6| Step: 12
Training loss: 0.9227610230445862
Validation loss: 1.9571762597689064

Epoch: 6| Step: 13
Training loss: 0.3703766465187073
Validation loss: 1.9754863259612874

Epoch: 276| Step: 0
Training loss: 0.98386150598526
Validation loss: 1.9564971667464062

Epoch: 6| Step: 1
Training loss: 0.7951796650886536
Validation loss: 1.964743286050776

Epoch: 6| Step: 2
Training loss: 0.6544742584228516
Validation loss: 1.9237113204053653

Epoch: 6| Step: 3
Training loss: 0.48284417390823364
Validation loss: 1.941268861934703

Epoch: 6| Step: 4
Training loss: 1.252497911453247
Validation loss: 1.9390342235565186

Epoch: 6| Step: 5
Training loss: 1.2080307006835938
Validation loss: 1.9141440852995841

Epoch: 6| Step: 6
Training loss: 0.6992688179016113
Validation loss: 1.9176812812846193

Epoch: 6| Step: 7
Training loss: 0.4799517095088959
Validation loss: 1.9304086239107194

Epoch: 6| Step: 8
Training loss: 0.9618561267852783
Validation loss: 1.919306488447292

Epoch: 6| Step: 9
Training loss: 0.8656094670295715
Validation loss: 1.8940429790045625

Epoch: 6| Step: 10
Training loss: 1.0461289882659912
Validation loss: 1.9037024692822528

Epoch: 6| Step: 11
Training loss: 0.954795241355896
Validation loss: 1.9173539351391535

Epoch: 6| Step: 12
Training loss: 0.39240169525146484
Validation loss: 1.9082390582689674

Epoch: 6| Step: 13
Training loss: 0.7118449211120605
Validation loss: 1.9162880271993659

Epoch: 277| Step: 0
Training loss: 0.5299925804138184
Validation loss: 1.9258316127202844

Epoch: 6| Step: 1
Training loss: 0.8729436993598938
Validation loss: 1.939448986002194

Epoch: 6| Step: 2
Training loss: 0.7395791411399841
Validation loss: 1.912484658661709

Epoch: 6| Step: 3
Training loss: 1.6378016471862793
Validation loss: 1.9507188002268474

Epoch: 6| Step: 4
Training loss: 0.9603821635246277
Validation loss: 1.978743855671216

Epoch: 6| Step: 5
Training loss: 0.8546009063720703
Validation loss: 1.9921896508944932

Epoch: 6| Step: 6
Training loss: 0.6609081029891968
Validation loss: 1.9960249393217024

Epoch: 6| Step: 7
Training loss: 1.1863090991973877
Validation loss: 1.9984446007718322

Epoch: 6| Step: 8
Training loss: 0.729454755783081
Validation loss: 2.0434468228329896

Epoch: 6| Step: 9
Training loss: 0.5645984411239624
Validation loss: 2.030313450803039

Epoch: 6| Step: 10
Training loss: 0.6256116628646851
Validation loss: 2.0065764534857964

Epoch: 6| Step: 11
Training loss: 0.8341791033744812
Validation loss: 1.9626585719405965

Epoch: 6| Step: 12
Training loss: 0.8456844687461853
Validation loss: 1.9094351491620463

Epoch: 6| Step: 13
Training loss: 0.37869659066200256
Validation loss: 1.899876348433956

Epoch: 278| Step: 0
Training loss: 1.0854061841964722
Validation loss: 1.9152056273593698

Epoch: 6| Step: 1
Training loss: 1.055076003074646
Validation loss: 1.9073007798963977

Epoch: 6| Step: 2
Training loss: 0.7283285856246948
Validation loss: 1.8980677358565792

Epoch: 6| Step: 3
Training loss: 0.9185216426849365
Validation loss: 1.8842149883188226

Epoch: 6| Step: 4
Training loss: 0.6318025588989258
Validation loss: 1.9248008369117655

Epoch: 6| Step: 5
Training loss: 1.3917667865753174
Validation loss: 1.9703294045181685

Epoch: 6| Step: 6
Training loss: 0.8757142424583435
Validation loss: 1.9822940993052658

Epoch: 6| Step: 7
Training loss: 0.7791754603385925
Validation loss: 2.0031842954697145

Epoch: 6| Step: 8
Training loss: 1.1112644672393799
Validation loss: 1.9622105629213396

Epoch: 6| Step: 9
Training loss: 0.533146858215332
Validation loss: 1.965055323416187

Epoch: 6| Step: 10
Training loss: 0.5698133111000061
Validation loss: 1.962252179781596

Epoch: 6| Step: 11
Training loss: 0.7267133593559265
Validation loss: 1.929287096505524

Epoch: 6| Step: 12
Training loss: 0.940268874168396
Validation loss: 1.9240091846835228

Epoch: 6| Step: 13
Training loss: 0.38676902651786804
Validation loss: 1.9150729922838108

Epoch: 279| Step: 0
Training loss: 0.6327378749847412
Validation loss: 1.9260862950355775

Epoch: 6| Step: 1
Training loss: 0.8059340715408325
Validation loss: 1.939510565932079

Epoch: 6| Step: 2
Training loss: 1.249990701675415
Validation loss: 1.9244434654071767

Epoch: 6| Step: 3
Training loss: 0.9858791828155518
Validation loss: 1.9388478263731925

Epoch: 6| Step: 4
Training loss: 0.9557538628578186
Validation loss: 1.9364761152575094

Epoch: 6| Step: 5
Training loss: 0.47466179728507996
Validation loss: 1.9405852415228402

Epoch: 6| Step: 6
Training loss: 0.5674623847007751
Validation loss: 1.9230529749265282

Epoch: 6| Step: 7
Training loss: 0.9339725971221924
Validation loss: 1.9178709624915995

Epoch: 6| Step: 8
Training loss: 1.2159686088562012
Validation loss: 1.9322765296505344

Epoch: 6| Step: 9
Training loss: 0.711434006690979
Validation loss: 1.9158994805428289

Epoch: 6| Step: 10
Training loss: 0.5060445070266724
Validation loss: 1.934301023842186

Epoch: 6| Step: 11
Training loss: 0.7059425115585327
Validation loss: 1.9228597789682367

Epoch: 6| Step: 12
Training loss: 0.8291134238243103
Validation loss: 1.9383650851506058

Epoch: 6| Step: 13
Training loss: 0.479406476020813
Validation loss: 1.926522199825574

Epoch: 280| Step: 0
Training loss: 0.9989834427833557
Validation loss: 1.944971683204815

Epoch: 6| Step: 1
Training loss: 0.5091789364814758
Validation loss: 1.9575655562903291

Epoch: 6| Step: 2
Training loss: 0.3858168125152588
Validation loss: 1.951414063412656

Epoch: 6| Step: 3
Training loss: 0.9196820259094238
Validation loss: 1.9349644927568332

Epoch: 6| Step: 4
Training loss: 0.5084902048110962
Validation loss: 1.9116437191604285

Epoch: 6| Step: 5
Training loss: 0.8869615793228149
Validation loss: 1.9216163132780342

Epoch: 6| Step: 6
Training loss: 0.8925132751464844
Validation loss: 1.8908283556661298

Epoch: 6| Step: 7
Training loss: 1.0651681423187256
Validation loss: 1.9120706460809196

Epoch: 6| Step: 8
Training loss: 0.8876104354858398
Validation loss: 1.903848676271336

Epoch: 6| Step: 9
Training loss: 0.9572207927703857
Validation loss: 1.9242235781044088

Epoch: 6| Step: 10
Training loss: 0.7366349697113037
Validation loss: 1.9243985709323679

Epoch: 6| Step: 11
Training loss: 1.1530709266662598
Validation loss: 1.914204018090361

Epoch: 6| Step: 12
Training loss: 0.7219840288162231
Validation loss: 1.9073961896281089

Epoch: 6| Step: 13
Training loss: 0.8441436290740967
Validation loss: 1.913548308034097

Epoch: 281| Step: 0
Training loss: 0.6688469648361206
Validation loss: 1.9285037697002452

Epoch: 6| Step: 1
Training loss: 0.6436699628829956
Validation loss: 1.9368083835929952

Epoch: 6| Step: 2
Training loss: 1.676095724105835
Validation loss: 1.9473349022608932

Epoch: 6| Step: 3
Training loss: 1.1448830366134644
Validation loss: 1.9487467094134259

Epoch: 6| Step: 4
Training loss: 0.7167783975601196
Validation loss: 1.926339913440007

Epoch: 6| Step: 5
Training loss: 0.30928730964660645
Validation loss: 1.9084913474257275

Epoch: 6| Step: 6
Training loss: 0.41736796498298645
Validation loss: 1.910578058611962

Epoch: 6| Step: 7
Training loss: 0.4465625286102295
Validation loss: 1.9191858768463135

Epoch: 6| Step: 8
Training loss: 0.5543251037597656
Validation loss: 1.9308783290206746

Epoch: 6| Step: 9
Training loss: 1.2173532247543335
Validation loss: 1.9090600808461506

Epoch: 6| Step: 10
Training loss: 0.7989497184753418
Validation loss: 1.9058758315219675

Epoch: 6| Step: 11
Training loss: 1.1779320240020752
Validation loss: 1.9219298042276853

Epoch: 6| Step: 12
Training loss: 0.7390609979629517
Validation loss: 1.9015191267895442

Epoch: 6| Step: 13
Training loss: 0.7850490212440491
Validation loss: 1.8739788724530129

Epoch: 282| Step: 0
Training loss: 0.7072921991348267
Validation loss: 1.8617484877186437

Epoch: 6| Step: 1
Training loss: 1.1898293495178223
Validation loss: 1.8897990385691326

Epoch: 6| Step: 2
Training loss: 0.8741841316223145
Validation loss: 1.889078651705096

Epoch: 6| Step: 3
Training loss: 0.907187819480896
Validation loss: 1.898160405056451

Epoch: 6| Step: 4
Training loss: 0.5508389472961426
Validation loss: 1.891507419206763

Epoch: 6| Step: 5
Training loss: 0.953803300857544
Validation loss: 1.927227395837025

Epoch: 6| Step: 6
Training loss: 0.36395248770713806
Validation loss: 1.9017950821948308

Epoch: 6| Step: 7
Training loss: 0.5646530389785767
Validation loss: 1.8920432316359652

Epoch: 6| Step: 8
Training loss: 1.358132243156433
Validation loss: 1.9219479727488693

Epoch: 6| Step: 9
Training loss: 0.689283013343811
Validation loss: 1.9066134281055902

Epoch: 6| Step: 10
Training loss: 0.3930273652076721
Validation loss: 1.9080298177657589

Epoch: 6| Step: 11
Training loss: 0.8799670338630676
Validation loss: 1.901568902436123

Epoch: 6| Step: 12
Training loss: 0.9895594716072083
Validation loss: 1.8609784162172707

Epoch: 6| Step: 13
Training loss: 1.0005842447280884
Validation loss: 1.894467907567178

Epoch: 283| Step: 0
Training loss: 0.7458212375640869
Validation loss: 1.8986150051957817

Epoch: 6| Step: 1
Training loss: 0.6637358665466309
Validation loss: 1.8887743783253494

Epoch: 6| Step: 2
Training loss: 1.0730500221252441
Validation loss: 1.884128152683217

Epoch: 6| Step: 3
Training loss: 0.8141456842422485
Validation loss: 1.94257531755714

Epoch: 6| Step: 4
Training loss: 0.9149010181427002
Validation loss: 1.960541453412784

Epoch: 6| Step: 5
Training loss: 1.0115149021148682
Validation loss: 1.9708452224731445

Epoch: 6| Step: 6
Training loss: 0.9793144464492798
Validation loss: 1.96614166485366

Epoch: 6| Step: 7
Training loss: 0.7138084173202515
Validation loss: 1.962548973739788

Epoch: 6| Step: 8
Training loss: 0.9969674348831177
Validation loss: 1.915222224368844

Epoch: 6| Step: 9
Training loss: 0.7529972195625305
Validation loss: 1.9083485141877206

Epoch: 6| Step: 10
Training loss: 0.4490121603012085
Validation loss: 1.8936496524400608

Epoch: 6| Step: 11
Training loss: 0.6772480010986328
Validation loss: 1.866305729394318

Epoch: 6| Step: 12
Training loss: 0.7229896187782288
Validation loss: 1.8919606029346425

Epoch: 6| Step: 13
Training loss: 0.5099982023239136
Validation loss: 1.8942500545132546

Epoch: 284| Step: 0
Training loss: 1.033848524093628
Validation loss: 1.9322224169649103

Epoch: 6| Step: 1
Training loss: 0.7902030944824219
Validation loss: 1.9172685735969133

Epoch: 6| Step: 2
Training loss: 0.6287336349487305
Validation loss: 1.9393614466472338

Epoch: 6| Step: 3
Training loss: 0.18800890445709229
Validation loss: 1.9534792092538649

Epoch: 6| Step: 4
Training loss: 0.6813156008720398
Validation loss: 1.9466165496457009

Epoch: 6| Step: 5
Training loss: 0.6314138174057007
Validation loss: 1.9667501590585197

Epoch: 6| Step: 6
Training loss: 0.6186054944992065
Validation loss: 1.970948330817684

Epoch: 6| Step: 7
Training loss: 1.286696195602417
Validation loss: 1.9792270839855235

Epoch: 6| Step: 8
Training loss: 1.2470003366470337
Validation loss: 1.9251334154477684

Epoch: 6| Step: 9
Training loss: 0.6083667278289795
Validation loss: 1.9369846390139671

Epoch: 6| Step: 10
Training loss: 1.0185015201568604
Validation loss: 1.9011912756068732

Epoch: 6| Step: 11
Training loss: 0.6193645596504211
Validation loss: 1.8632394985486103

Epoch: 6| Step: 12
Training loss: 0.6823117136955261
Validation loss: 1.8400773566256288

Epoch: 6| Step: 13
Training loss: 1.1176282167434692
Validation loss: 1.8407304235683974

Epoch: 285| Step: 0
Training loss: 0.7037372589111328
Validation loss: 1.830606278552804

Epoch: 6| Step: 1
Training loss: 0.9301192760467529
Validation loss: 1.842316489065847

Epoch: 6| Step: 2
Training loss: 1.1154851913452148
Validation loss: 1.816244468894056

Epoch: 6| Step: 3
Training loss: 0.688366174697876
Validation loss: 1.8357660257688133

Epoch: 6| Step: 4
Training loss: 0.7308467030525208
Validation loss: 1.8519122985101515

Epoch: 6| Step: 5
Training loss: 1.1019234657287598
Validation loss: 1.8627263307571411

Epoch: 6| Step: 6
Training loss: 0.6772509813308716
Validation loss: 1.8844602056728896

Epoch: 6| Step: 7
Training loss: 0.7022436261177063
Validation loss: 1.912914704251033

Epoch: 6| Step: 8
Training loss: 0.44054529070854187
Validation loss: 1.9020080899679532

Epoch: 6| Step: 9
Training loss: 0.4130702018737793
Validation loss: 1.916912119875672

Epoch: 6| Step: 10
Training loss: 0.9960864782333374
Validation loss: 1.9040127704220433

Epoch: 6| Step: 11
Training loss: 0.938090980052948
Validation loss: 1.9373173482956425

Epoch: 6| Step: 12
Training loss: 0.7897652983665466
Validation loss: 1.9084783382313226

Epoch: 6| Step: 13
Training loss: 0.6054380536079407
Validation loss: 1.8997177180423532

Epoch: 286| Step: 0
Training loss: 0.5230451226234436
Validation loss: 1.877245092904696

Epoch: 6| Step: 1
Training loss: 0.34266310930252075
Validation loss: 1.8786130746205647

Epoch: 6| Step: 2
Training loss: 0.6742001175880432
Validation loss: 1.8788148126294535

Epoch: 6| Step: 3
Training loss: 0.7119764685630798
Validation loss: 1.8899268052911247

Epoch: 6| Step: 4
Training loss: 0.7341245412826538
Validation loss: 1.8995078930290796

Epoch: 6| Step: 5
Training loss: 1.0103908777236938
Validation loss: 1.9166768571381927

Epoch: 6| Step: 6
Training loss: 0.3908969759941101
Validation loss: 1.9172088535883094

Epoch: 6| Step: 7
Training loss: 1.0994384288787842
Validation loss: 1.9015257102186962

Epoch: 6| Step: 8
Training loss: 0.67397540807724
Validation loss: 1.9054334958394368

Epoch: 6| Step: 9
Training loss: 1.3932515382766724
Validation loss: 1.9092488019697127

Epoch: 6| Step: 10
Training loss: 0.7041407823562622
Validation loss: 1.9293692240151026

Epoch: 6| Step: 11
Training loss: 0.658825159072876
Validation loss: 1.9156324453251337

Epoch: 6| Step: 12
Training loss: 1.1298105716705322
Validation loss: 1.898177028984152

Epoch: 6| Step: 13
Training loss: 0.460594117641449
Validation loss: 1.9195443096981253

Epoch: 287| Step: 0
Training loss: 0.7319248914718628
Validation loss: 1.9245088715707102

Epoch: 6| Step: 1
Training loss: 1.129873275756836
Validation loss: 1.9303184965605378

Epoch: 6| Step: 2
Training loss: 0.5206730365753174
Validation loss: 1.9255806476839128

Epoch: 6| Step: 3
Training loss: 0.8455944657325745
Validation loss: 1.9213970309944564

Epoch: 6| Step: 4
Training loss: 0.6792294979095459
Validation loss: 1.9189728280549407

Epoch: 6| Step: 5
Training loss: 0.994813859462738
Validation loss: 1.910380486519106

Epoch: 6| Step: 6
Training loss: 0.43710508942604065
Validation loss: 1.9153506781465264

Epoch: 6| Step: 7
Training loss: 0.7003301382064819
Validation loss: 1.8994368891562186

Epoch: 6| Step: 8
Training loss: 0.6055734157562256
Validation loss: 1.8911871346094276

Epoch: 6| Step: 9
Training loss: 0.7701508402824402
Validation loss: 1.8752815313236688

Epoch: 6| Step: 10
Training loss: 0.7638269662857056
Validation loss: 1.8776305080741964

Epoch: 6| Step: 11
Training loss: 0.8941762447357178
Validation loss: 1.8422329297629736

Epoch: 6| Step: 12
Training loss: 0.5397985577583313
Validation loss: 1.8571307018239012

Epoch: 6| Step: 13
Training loss: 0.5936943292617798
Validation loss: 1.8454178417882612

Epoch: 288| Step: 0
Training loss: 0.40169352293014526
Validation loss: 1.8443138625032158

Epoch: 6| Step: 1
Training loss: 0.5424172282218933
Validation loss: 1.8758576903291928

Epoch: 6| Step: 2
Training loss: 1.0765069723129272
Validation loss: 1.8880263246515745

Epoch: 6| Step: 3
Training loss: 0.7027332782745361
Validation loss: 1.886757226400478

Epoch: 6| Step: 4
Training loss: 0.3135725259780884
Validation loss: 1.888948122660319

Epoch: 6| Step: 5
Training loss: 0.5334200263023376
Validation loss: 1.9238849198946388

Epoch: 6| Step: 6
Training loss: 0.9048902988433838
Validation loss: 1.9311456731570664

Epoch: 6| Step: 7
Training loss: 0.7280583381652832
Validation loss: 1.9183137038702607

Epoch: 6| Step: 8
Training loss: 0.9095605611801147
Validation loss: 1.9209254403268137

Epoch: 6| Step: 9
Training loss: 1.244840145111084
Validation loss: 1.9441406470473095

Epoch: 6| Step: 10
Training loss: 0.6598595380783081
Validation loss: 1.9222853491383214

Epoch: 6| Step: 11
Training loss: 0.7619496583938599
Validation loss: 1.9370870500482538

Epoch: 6| Step: 12
Training loss: 0.6321353912353516
Validation loss: 1.9366011337567401

Epoch: 6| Step: 13
Training loss: 0.8216065168380737
Validation loss: 1.9363561163666427

Epoch: 289| Step: 0
Training loss: 0.5797522664070129
Validation loss: 1.9277442027163763

Epoch: 6| Step: 1
Training loss: 0.554154634475708
Validation loss: 1.919225133875365

Epoch: 6| Step: 2
Training loss: 0.600951075553894
Validation loss: 1.887127971777352

Epoch: 6| Step: 3
Training loss: 0.4568580389022827
Validation loss: 1.9066101530546784

Epoch: 6| Step: 4
Training loss: 0.5610582828521729
Validation loss: 1.912007567703083

Epoch: 6| Step: 5
Training loss: 0.6937694549560547
Validation loss: 1.890543560827932

Epoch: 6| Step: 6
Training loss: 0.6628879308700562
Validation loss: 1.8888381283770326

Epoch: 6| Step: 7
Training loss: 1.160131812095642
Validation loss: 1.8737512647464711

Epoch: 6| Step: 8
Training loss: 0.6509394645690918
Validation loss: 1.8851339112045944

Epoch: 6| Step: 9
Training loss: 1.2634493112564087
Validation loss: 1.8878419335170458

Epoch: 6| Step: 10
Training loss: 0.761619508266449
Validation loss: 1.8906795856773213

Epoch: 6| Step: 11
Training loss: 0.8874754905700684
Validation loss: 1.8933407145161782

Epoch: 6| Step: 12
Training loss: 0.4791603088378906
Validation loss: 1.9056802103596349

Epoch: 6| Step: 13
Training loss: 0.6194786429405212
Validation loss: 1.9042880458216513

Epoch: 290| Step: 0
Training loss: 1.0396759510040283
Validation loss: 1.9444172254172705

Epoch: 6| Step: 1
Training loss: 0.6833562850952148
Validation loss: 1.9459263214501001

Epoch: 6| Step: 2
Training loss: 0.7044210433959961
Validation loss: 1.9444373717872045

Epoch: 6| Step: 3
Training loss: 0.8237894177436829
Validation loss: 1.9485571845885246

Epoch: 6| Step: 4
Training loss: 0.807874321937561
Validation loss: 1.9015517632166545

Epoch: 6| Step: 5
Training loss: 0.9373847246170044
Validation loss: 1.8964578220921178

Epoch: 6| Step: 6
Training loss: 0.399854838848114
Validation loss: 1.8922966552037064

Epoch: 6| Step: 7
Training loss: 0.4630909562110901
Validation loss: 1.87155778690051

Epoch: 6| Step: 8
Training loss: 0.38645362854003906
Validation loss: 1.8781155219642065

Epoch: 6| Step: 9
Training loss: 1.241229772567749
Validation loss: 1.8843646023863105

Epoch: 6| Step: 10
Training loss: 1.0316028594970703
Validation loss: 1.897768723067417

Epoch: 6| Step: 11
Training loss: 0.7759670615196228
Validation loss: 1.914426742061492

Epoch: 6| Step: 12
Training loss: 0.5697709321975708
Validation loss: 1.937554508127192

Epoch: 6| Step: 13
Training loss: 1.1926401853561401
Validation loss: 1.9523758401152909

Epoch: 291| Step: 0
Training loss: 0.8482124209403992
Validation loss: 1.9356172353990617

Epoch: 6| Step: 1
Training loss: 1.0278946161270142
Validation loss: 1.950701976335177

Epoch: 6| Step: 2
Training loss: 0.8319491744041443
Validation loss: 1.9104236684819704

Epoch: 6| Step: 3
Training loss: 0.7871532440185547
Validation loss: 1.890750886291586

Epoch: 6| Step: 4
Training loss: 0.5047491192817688
Validation loss: 1.9121425779916907

Epoch: 6| Step: 5
Training loss: 0.7522183656692505
Validation loss: 1.9243841735265588

Epoch: 6| Step: 6
Training loss: 0.8890348672866821
Validation loss: 1.909765721649252

Epoch: 6| Step: 7
Training loss: 1.013890027999878
Validation loss: 1.906912971568364

Epoch: 6| Step: 8
Training loss: 0.4706467390060425
Validation loss: 1.9008041056253577

Epoch: 6| Step: 9
Training loss: 0.6314605474472046
Validation loss: 1.9285640767825547

Epoch: 6| Step: 10
Training loss: 0.3403143286705017
Validation loss: 1.9214250349229383

Epoch: 6| Step: 11
Training loss: 0.618675708770752
Validation loss: 1.9083761963793027

Epoch: 6| Step: 12
Training loss: 0.9028912782669067
Validation loss: 1.929024919386833

Epoch: 6| Step: 13
Training loss: 0.862274706363678
Validation loss: 1.9097484068203998

Epoch: 292| Step: 0
Training loss: 0.6221578121185303
Validation loss: 1.9539735714594524

Epoch: 6| Step: 1
Training loss: 0.8755136132240295
Validation loss: 1.9449595161663589

Epoch: 6| Step: 2
Training loss: 0.7089588046073914
Validation loss: 1.9506261835816086

Epoch: 6| Step: 3
Training loss: 0.6758296489715576
Validation loss: 1.9203166705305859

Epoch: 6| Step: 4
Training loss: 0.5714780688285828
Validation loss: 1.925830578291288

Epoch: 6| Step: 5
Training loss: 1.0181225538253784
Validation loss: 1.9281068066115021

Epoch: 6| Step: 6
Training loss: 1.0581698417663574
Validation loss: 1.9140071112622496

Epoch: 6| Step: 7
Training loss: 0.9363616704940796
Validation loss: 1.8883512507202804

Epoch: 6| Step: 8
Training loss: 0.6461961269378662
Validation loss: 1.889870757697731

Epoch: 6| Step: 9
Training loss: 0.8089408874511719
Validation loss: 1.8893603304381013

Epoch: 6| Step: 10
Training loss: 0.47366806864738464
Validation loss: 1.9197252501723587

Epoch: 6| Step: 11
Training loss: 0.5057808756828308
Validation loss: 1.9038353863582815

Epoch: 6| Step: 12
Training loss: 0.7896316647529602
Validation loss: 1.9148342160768406

Epoch: 6| Step: 13
Training loss: 0.5083194375038147
Validation loss: 1.8979816693131641

Epoch: 293| Step: 0
Training loss: 0.7176251411437988
Validation loss: 1.9079858026196879

Epoch: 6| Step: 1
Training loss: 0.802703857421875
Validation loss: 1.900465642252276

Epoch: 6| Step: 2
Training loss: 0.8534607887268066
Validation loss: 1.9132217822536346

Epoch: 6| Step: 3
Training loss: 0.9960650205612183
Validation loss: 1.9173306188275736

Epoch: 6| Step: 4
Training loss: 0.8844451904296875
Validation loss: 1.920820143914992

Epoch: 6| Step: 5
Training loss: 0.7458781003952026
Validation loss: 1.945256736970717

Epoch: 6| Step: 6
Training loss: 0.5832379460334778
Validation loss: 1.9494963781808012

Epoch: 6| Step: 7
Training loss: 0.658038318157196
Validation loss: 1.9642943746300154

Epoch: 6| Step: 8
Training loss: 0.6445807218551636
Validation loss: 1.9634850589177941

Epoch: 6| Step: 9
Training loss: 0.6566858291625977
Validation loss: 1.93999146902433

Epoch: 6| Step: 10
Training loss: 0.8099722266197205
Validation loss: 1.9315118558945195

Epoch: 6| Step: 11
Training loss: 0.7224680781364441
Validation loss: 1.9115880535494896

Epoch: 6| Step: 12
Training loss: 0.7436608672142029
Validation loss: 1.9263605866380917

Epoch: 6| Step: 13
Training loss: 0.2602514326572418
Validation loss: 1.903214595651114

Epoch: 294| Step: 0
Training loss: 0.7239920496940613
Validation loss: 1.8922580057574856

Epoch: 6| Step: 1
Training loss: 0.9670076966285706
Validation loss: 1.905218232062555

Epoch: 6| Step: 2
Training loss: 0.7850766181945801
Validation loss: 1.9306562933870541

Epoch: 6| Step: 3
Training loss: 0.5458217859268188
Validation loss: 1.9434389491235056

Epoch: 6| Step: 4
Training loss: 0.5547016859054565
Validation loss: 1.9357446752568728

Epoch: 6| Step: 5
Training loss: 0.8492591381072998
Validation loss: 1.9314845351762668

Epoch: 6| Step: 6
Training loss: 0.41094493865966797
Validation loss: 1.9231940905253093

Epoch: 6| Step: 7
Training loss: 0.9786020517349243
Validation loss: 1.8963981059289747

Epoch: 6| Step: 8
Training loss: 0.3996615409851074
Validation loss: 1.9276090309184084

Epoch: 6| Step: 9
Training loss: 0.5029246211051941
Validation loss: 1.9422515335903372

Epoch: 6| Step: 10
Training loss: 0.5005922317504883
Validation loss: 1.9483528880662815

Epoch: 6| Step: 11
Training loss: 0.6577053070068359
Validation loss: 1.8958601118415914

Epoch: 6| Step: 12
Training loss: 1.0404248237609863
Validation loss: 1.9191187838072419

Epoch: 6| Step: 13
Training loss: 0.596145749092102
Validation loss: 1.9296635837965115

Epoch: 295| Step: 0
Training loss: 0.919227123260498
Validation loss: 1.9321529403809579

Epoch: 6| Step: 1
Training loss: 0.3067088723182678
Validation loss: 1.9223763609445224

Epoch: 6| Step: 2
Training loss: 0.8405783176422119
Validation loss: 1.9136554720581218

Epoch: 6| Step: 3
Training loss: 1.014096975326538
Validation loss: 1.9232490049895419

Epoch: 6| Step: 4
Training loss: 0.445600688457489
Validation loss: 1.9216778585987706

Epoch: 6| Step: 5
Training loss: 0.6754602193832397
Validation loss: 1.9322023699360509

Epoch: 6| Step: 6
Training loss: 0.8272426128387451
Validation loss: 1.9162971191508795

Epoch: 6| Step: 7
Training loss: 0.6510410308837891
Validation loss: 1.9247265631152737

Epoch: 6| Step: 8
Training loss: 0.5368214845657349
Validation loss: 1.9205310261377724

Epoch: 6| Step: 9
Training loss: 0.7669631242752075
Validation loss: 1.9130752855731594

Epoch: 6| Step: 10
Training loss: 0.49062860012054443
Validation loss: 1.8857727678873206

Epoch: 6| Step: 11
Training loss: 0.6099522113800049
Validation loss: 1.8696939650402273

Epoch: 6| Step: 12
Training loss: 0.4713478684425354
Validation loss: 1.8664204830764441

Epoch: 6| Step: 13
Training loss: 0.6942092776298523
Validation loss: 1.8756943389933596

Epoch: 296| Step: 0
Training loss: 0.5668508410453796
Validation loss: 1.856517271328998

Epoch: 6| Step: 1
Training loss: 0.4243929088115692
Validation loss: 1.8678843718703075

Epoch: 6| Step: 2
Training loss: 0.6525861024856567
Validation loss: 1.8610579031769947

Epoch: 6| Step: 3
Training loss: 0.6159310340881348
Validation loss: 1.8938153982162476

Epoch: 6| Step: 4
Training loss: 0.6638827919960022
Validation loss: 1.8696803303175076

Epoch: 6| Step: 5
Training loss: 0.5676175355911255
Validation loss: 1.8842647460199171

Epoch: 6| Step: 6
Training loss: 0.9369615316390991
Validation loss: 1.9023945728937786

Epoch: 6| Step: 7
Training loss: 0.6750165820121765
Validation loss: 1.894707105493033

Epoch: 6| Step: 8
Training loss: 0.5110225677490234
Validation loss: 1.907430246312131

Epoch: 6| Step: 9
Training loss: 0.752595067024231
Validation loss: 1.9063358345339376

Epoch: 6| Step: 10
Training loss: 0.4994744062423706
Validation loss: 1.9078704234092467

Epoch: 6| Step: 11
Training loss: 0.6540789008140564
Validation loss: 1.9182369273195985

Epoch: 6| Step: 12
Training loss: 1.1282941102981567
Validation loss: 1.921156301293322

Epoch: 6| Step: 13
Training loss: 0.6496463418006897
Validation loss: 1.943983800949589

Epoch: 297| Step: 0
Training loss: 0.48886778950691223
Validation loss: 1.918470823636619

Epoch: 6| Step: 1
Training loss: 0.5627317428588867
Validation loss: 1.9374040813856228

Epoch: 6| Step: 2
Training loss: 0.6006905436515808
Validation loss: 1.9334466316366707

Epoch: 6| Step: 3
Training loss: 0.7605075836181641
Validation loss: 1.9234435968501593

Epoch: 6| Step: 4
Training loss: 0.8495063781738281
Validation loss: 1.955063368684502

Epoch: 6| Step: 5
Training loss: 0.8177501559257507
Validation loss: 1.9075304897882606

Epoch: 6| Step: 6
Training loss: 0.7472339868545532
Validation loss: 1.9090132918409122

Epoch: 6| Step: 7
Training loss: 0.3683895468711853
Validation loss: 1.8850516580766248

Epoch: 6| Step: 8
Training loss: 0.6426514983177185
Validation loss: 1.889328525912377

Epoch: 6| Step: 9
Training loss: 0.6762941479682922
Validation loss: 1.871765048273148

Epoch: 6| Step: 10
Training loss: 0.4111987352371216
Validation loss: 1.8727476519923056

Epoch: 6| Step: 11
Training loss: 0.9061814546585083
Validation loss: 1.887334374330377

Epoch: 6| Step: 12
Training loss: 0.5164167284965515
Validation loss: 1.858109692091583

Epoch: 6| Step: 13
Training loss: 0.642507791519165
Validation loss: 1.8642977078755696

Epoch: 298| Step: 0
Training loss: 0.9899167418479919
Validation loss: 1.8928796283660396

Epoch: 6| Step: 1
Training loss: 0.43972283601760864
Validation loss: 1.8837648360959944

Epoch: 6| Step: 2
Training loss: 0.5860743522644043
Validation loss: 1.8959180719108992

Epoch: 6| Step: 3
Training loss: 0.5087922811508179
Validation loss: 1.8967517217000325

Epoch: 6| Step: 4
Training loss: 0.47710683941841125
Validation loss: 1.9240386024598153

Epoch: 6| Step: 5
Training loss: 0.8363803625106812
Validation loss: 1.886457814965197

Epoch: 6| Step: 6
Training loss: 0.4082030653953552
Validation loss: 1.9138952711577057

Epoch: 6| Step: 7
Training loss: 0.41524365544319153
Validation loss: 1.903187265960119

Epoch: 6| Step: 8
Training loss: 0.6131076216697693
Validation loss: 1.9095044994866976

Epoch: 6| Step: 9
Training loss: 0.9592666625976562
Validation loss: 1.9002339211843347

Epoch: 6| Step: 10
Training loss: 0.8004943132400513
Validation loss: 1.907247099825131

Epoch: 6| Step: 11
Training loss: 0.9897370338439941
Validation loss: 1.906322076756467

Epoch: 6| Step: 12
Training loss: 0.43582040071487427
Validation loss: 1.878345133155905

Epoch: 6| Step: 13
Training loss: 0.21389234066009521
Validation loss: 1.8980403241290842

Epoch: 299| Step: 0
Training loss: 0.3709114193916321
Validation loss: 1.8923270740816671

Epoch: 6| Step: 1
Training loss: 0.8810379505157471
Validation loss: 1.897726474269744

Epoch: 6| Step: 2
Training loss: 0.507226288318634
Validation loss: 1.9103996189691688

Epoch: 6| Step: 3
Training loss: 0.6973851919174194
Validation loss: 1.8947200223963747

Epoch: 6| Step: 4
Training loss: 0.715006947517395
Validation loss: 1.8936529441546368

Epoch: 6| Step: 5
Training loss: 0.6448587775230408
Validation loss: 1.9302727932571082

Epoch: 6| Step: 6
Training loss: 0.63880854845047
Validation loss: 1.9243073283985097

Epoch: 6| Step: 7
Training loss: 0.8044196367263794
Validation loss: 1.961070966976945

Epoch: 6| Step: 8
Training loss: 0.40838950872421265
Validation loss: 1.9583496765423847

Epoch: 6| Step: 9
Training loss: 0.6408825516700745
Validation loss: 1.956168992545015

Epoch: 6| Step: 10
Training loss: 0.8139220476150513
Validation loss: 1.9184445078654955

Epoch: 6| Step: 11
Training loss: 0.7024536728858948
Validation loss: 1.9392850860472648

Epoch: 6| Step: 12
Training loss: 0.45680567622184753
Validation loss: 1.9535931541073708

Epoch: 6| Step: 13
Training loss: 0.6867578625679016
Validation loss: 1.9624634788882347

Epoch: 300| Step: 0
Training loss: 0.7838384509086609
Validation loss: 1.9361867186843709

Epoch: 6| Step: 1
Training loss: 1.142993450164795
Validation loss: 1.944705770861718

Epoch: 6| Step: 2
Training loss: 0.6570767760276794
Validation loss: 1.9228738533553256

Epoch: 6| Step: 3
Training loss: 0.3942497968673706
Validation loss: 1.899415905757617

Epoch: 6| Step: 4
Training loss: 0.4445975720882416
Validation loss: 1.8628155416057957

Epoch: 6| Step: 5
Training loss: 0.5803512334823608
Validation loss: 1.8652703351871942

Epoch: 6| Step: 6
Training loss: 0.7475637197494507
Validation loss: 1.878137824355915

Epoch: 6| Step: 7
Training loss: 0.40966248512268066
Validation loss: 1.8728979851609917

Epoch: 6| Step: 8
Training loss: 1.311781644821167
Validation loss: 1.89700226629934

Epoch: 6| Step: 9
Training loss: 0.42944109439849854
Validation loss: 1.8867961943790477

Epoch: 6| Step: 10
Training loss: 0.8248452544212341
Validation loss: 1.8947659923184303

Epoch: 6| Step: 11
Training loss: 0.5134351849555969
Validation loss: 1.9125406049912976

Epoch: 6| Step: 12
Training loss: 0.5380030870437622
Validation loss: 1.9118175429682578

Epoch: 6| Step: 13
Training loss: 0.43925920128822327
Validation loss: 1.943218279910344

Epoch: 301| Step: 0
Training loss: 0.6092556715011597
Validation loss: 1.9289448043351531

Epoch: 6| Step: 1
Training loss: 0.7800641059875488
Validation loss: 1.9318830531130555

Epoch: 6| Step: 2
Training loss: 0.642020583152771
Validation loss: 1.9718914249891877

Epoch: 6| Step: 3
Training loss: 0.6041834354400635
Validation loss: 1.9324108849289596

Epoch: 6| Step: 4
Training loss: 0.8181678056716919
Validation loss: 1.894305097159519

Epoch: 6| Step: 5
Training loss: 0.8038151264190674
Validation loss: 1.8919734801015546

Epoch: 6| Step: 6
Training loss: 0.6647794246673584
Validation loss: 1.8848520889077136

Epoch: 6| Step: 7
Training loss: 0.6819587349891663
Validation loss: 1.8716089366584696

Epoch: 6| Step: 8
Training loss: 0.34807607531547546
Validation loss: 1.8765838351300967

Epoch: 6| Step: 9
Training loss: 0.6222410798072815
Validation loss: 1.8909100717113865

Epoch: 6| Step: 10
Training loss: 0.5902401208877563
Validation loss: 1.8627200562466857

Epoch: 6| Step: 11
Training loss: 0.35155847668647766
Validation loss: 1.8805631360700052

Epoch: 6| Step: 12
Training loss: 1.0713363885879517
Validation loss: 1.8644484243085306

Epoch: 6| Step: 13
Training loss: 0.6520722508430481
Validation loss: 1.8702466052065614

Epoch: 302| Step: 0
Training loss: 0.46857061982154846
Validation loss: 1.8812244502446984

Epoch: 6| Step: 1
Training loss: 0.4560980200767517
Validation loss: 1.8970729125443326

Epoch: 6| Step: 2
Training loss: 0.5256196856498718
Validation loss: 1.8992237711465487

Epoch: 6| Step: 3
Training loss: 0.3546774089336395
Validation loss: 1.893253243097695

Epoch: 6| Step: 4
Training loss: 0.4353485703468323
Validation loss: 1.8769479567004788

Epoch: 6| Step: 5
Training loss: 0.46054503321647644
Validation loss: 1.873195109828826

Epoch: 6| Step: 6
Training loss: 0.7086682319641113
Validation loss: 1.8912467712997107

Epoch: 6| Step: 7
Training loss: 0.8489708304405212
Validation loss: 1.8892696493415422

Epoch: 6| Step: 8
Training loss: 0.6144465208053589
Validation loss: 1.9217324513261036

Epoch: 6| Step: 9
Training loss: 0.6875024437904358
Validation loss: 1.941174723768747

Epoch: 6| Step: 10
Training loss: 1.4119091033935547
Validation loss: 1.9413172480880574

Epoch: 6| Step: 11
Training loss: 0.520294189453125
Validation loss: 1.9580308237383444

Epoch: 6| Step: 12
Training loss: 0.6782634258270264
Validation loss: 1.9047834962926886

Epoch: 6| Step: 13
Training loss: 1.4438132047653198
Validation loss: 1.8791316234937279

Epoch: 303| Step: 0
Training loss: 0.5763713121414185
Validation loss: 1.876750603798897

Epoch: 6| Step: 1
Training loss: 0.6125177145004272
Validation loss: 1.8912402558070358

Epoch: 6| Step: 2
Training loss: 0.23385056853294373
Validation loss: 1.847293644823054

Epoch: 6| Step: 3
Training loss: 0.7027163505554199
Validation loss: 1.858112410832477

Epoch: 6| Step: 4
Training loss: 0.34744298458099365
Validation loss: 1.8315311734394362

Epoch: 6| Step: 5
Training loss: 0.5092073678970337
Validation loss: 1.8470961611757997

Epoch: 6| Step: 6
Training loss: 1.18515944480896
Validation loss: 1.8423923600104548

Epoch: 6| Step: 7
Training loss: 0.2161978781223297
Validation loss: 1.8404536567708498

Epoch: 6| Step: 8
Training loss: 0.5521662831306458
Validation loss: 1.8614382051652478

Epoch: 6| Step: 9
Training loss: 0.7818894386291504
Validation loss: 1.8517342305952502

Epoch: 6| Step: 10
Training loss: 0.6950319409370422
Validation loss: 1.8548737905358756

Epoch: 6| Step: 11
Training loss: 0.5864077806472778
Validation loss: 1.8486481276891564

Epoch: 6| Step: 12
Training loss: 0.8762012720108032
Validation loss: 1.8651401483884422

Epoch: 6| Step: 13
Training loss: 0.9295065999031067
Validation loss: 1.8679321645408549

Epoch: 304| Step: 0
Training loss: 0.9565986394882202
Validation loss: 1.8688345750172932

Epoch: 6| Step: 1
Training loss: 0.46401962637901306
Validation loss: 1.8677759837078791

Epoch: 6| Step: 2
Training loss: 0.5783205032348633
Validation loss: 1.8912254687278502

Epoch: 6| Step: 3
Training loss: 0.7948223948478699
Validation loss: 1.8735972399352698

Epoch: 6| Step: 4
Training loss: 0.5742281675338745
Validation loss: 1.8768348155483123

Epoch: 6| Step: 5
Training loss: 1.013595700263977
Validation loss: 1.8954230149586995

Epoch: 6| Step: 6
Training loss: 0.5918353199958801
Validation loss: 1.8736177682876587

Epoch: 6| Step: 7
Training loss: 0.33871275186538696
Validation loss: 1.8834408649834253

Epoch: 6| Step: 8
Training loss: 0.27826380729675293
Validation loss: 1.882801495572572

Epoch: 6| Step: 9
Training loss: 0.5205990076065063
Validation loss: 1.8692058363268453

Epoch: 6| Step: 10
Training loss: 0.3100489377975464
Validation loss: 1.8824916911381546

Epoch: 6| Step: 11
Training loss: 0.740451991558075
Validation loss: 1.885371313300184

Epoch: 6| Step: 12
Training loss: 0.5820763111114502
Validation loss: 1.8939371173099806

Epoch: 6| Step: 13
Training loss: 0.4924609363079071
Validation loss: 1.8795775354549449

Epoch: 305| Step: 0
Training loss: 0.5187808871269226
Validation loss: 1.9065147881866784

Epoch: 6| Step: 1
Training loss: 0.7273876667022705
Validation loss: 1.9043053811596287

Epoch: 6| Step: 2
Training loss: 0.2413877248764038
Validation loss: 1.9122929367967831

Epoch: 6| Step: 3
Training loss: 0.6736433506011963
Validation loss: 1.8706423185204948

Epoch: 6| Step: 4
Training loss: 0.43706953525543213
Validation loss: 1.8703356327549103

Epoch: 6| Step: 5
Training loss: 0.538068950176239
Validation loss: 1.8819953574929187

Epoch: 6| Step: 6
Training loss: 0.5637909173965454
Validation loss: 1.8895627631936023

Epoch: 6| Step: 7
Training loss: 0.9067894220352173
Validation loss: 1.8754948864700973

Epoch: 6| Step: 8
Training loss: 0.6996313333511353
Validation loss: 1.8777958090587328

Epoch: 6| Step: 9
Training loss: 0.8528997302055359
Validation loss: 1.8861689823929981

Epoch: 6| Step: 10
Training loss: 0.3854674994945526
Validation loss: 1.9040648642406668

Epoch: 6| Step: 11
Training loss: 0.4147803783416748
Validation loss: 1.8941445145555722

Epoch: 6| Step: 12
Training loss: 0.6398634910583496
Validation loss: 1.912222396942877

Epoch: 6| Step: 13
Training loss: 0.8944905400276184
Validation loss: 1.8757860737462198

Epoch: 306| Step: 0
Training loss: 0.5620955228805542
Validation loss: 1.8865959990409114

Epoch: 6| Step: 1
Training loss: 0.9664930701255798
Validation loss: 1.8891341455521122

Epoch: 6| Step: 2
Training loss: 1.0208282470703125
Validation loss: 1.8779650516407465

Epoch: 6| Step: 3
Training loss: 0.7244287133216858
Validation loss: 1.8961997185983965

Epoch: 6| Step: 4
Training loss: 0.5536007881164551
Validation loss: 1.8750220191094182

Epoch: 6| Step: 5
Training loss: 0.6378164887428284
Validation loss: 1.9069193076061945

Epoch: 6| Step: 6
Training loss: 0.5627474188804626
Validation loss: 1.90605075897709

Epoch: 6| Step: 7
Training loss: 0.7916222214698792
Validation loss: 1.9010971169317923

Epoch: 6| Step: 8
Training loss: 0.24880149960517883
Validation loss: 1.9087786443771855

Epoch: 6| Step: 9
Training loss: 0.4992562532424927
Validation loss: 1.8902492279647498

Epoch: 6| Step: 10
Training loss: 0.24142630398273468
Validation loss: 1.9013773523351198

Epoch: 6| Step: 11
Training loss: 0.5182921886444092
Validation loss: 1.901315942887337

Epoch: 6| Step: 12
Training loss: 0.4605223536491394
Validation loss: 1.88803986067413

Epoch: 6| Step: 13
Training loss: 0.4923328757286072
Validation loss: 1.8931911478760421

Epoch: 307| Step: 0
Training loss: 0.6449504494667053
Validation loss: 1.8772393042041409

Epoch: 6| Step: 1
Training loss: 0.39273548126220703
Validation loss: 1.8805754928178684

Epoch: 6| Step: 2
Training loss: 0.6644370555877686
Validation loss: 1.880678907517464

Epoch: 6| Step: 3
Training loss: 0.7217512726783752
Validation loss: 1.8737239350554764

Epoch: 6| Step: 4
Training loss: 0.5533660650253296
Validation loss: 1.8653799897880965

Epoch: 6| Step: 5
Training loss: 0.5374934673309326
Validation loss: 1.8555455387279551

Epoch: 6| Step: 6
Training loss: 0.8984337449073792
Validation loss: 1.8791788495996946

Epoch: 6| Step: 7
Training loss: 0.6441404223442078
Validation loss: 1.8978804131989837

Epoch: 6| Step: 8
Training loss: 0.3339691460132599
Validation loss: 1.8888097681025022

Epoch: 6| Step: 9
Training loss: 0.412567675113678
Validation loss: 1.8916697130408338

Epoch: 6| Step: 10
Training loss: 0.7987245321273804
Validation loss: 1.8766802510907572

Epoch: 6| Step: 11
Training loss: 0.5989568829536438
Validation loss: 1.8664317746316232

Epoch: 6| Step: 12
Training loss: 0.617160439491272
Validation loss: 1.8747626235408168

Epoch: 6| Step: 13
Training loss: 0.3378155529499054
Validation loss: 1.9015087658359158

Epoch: 308| Step: 0
Training loss: 0.5774025917053223
Validation loss: 1.8828965874128445

Epoch: 6| Step: 1
Training loss: 0.6678768992424011
Validation loss: 1.8766328198935396

Epoch: 6| Step: 2
Training loss: 0.4739665687084198
Validation loss: 1.8620799767073763

Epoch: 6| Step: 3
Training loss: 0.5306953191757202
Validation loss: 1.8728708759430917

Epoch: 6| Step: 4
Training loss: 0.4817068576812744
Validation loss: 1.893336829318795

Epoch: 6| Step: 5
Training loss: 0.7007906436920166
Validation loss: 1.900383267351376

Epoch: 6| Step: 6
Training loss: 0.9760444164276123
Validation loss: 1.890316444058572

Epoch: 6| Step: 7
Training loss: 0.6171373128890991
Validation loss: 1.88009879537808

Epoch: 6| Step: 8
Training loss: 0.6026360988616943
Validation loss: 1.8891791733362342

Epoch: 6| Step: 9
Training loss: 0.4608120322227478
Validation loss: 1.8838882087379374

Epoch: 6| Step: 10
Training loss: 0.6664642095565796
Validation loss: 1.8976447633517686

Epoch: 6| Step: 11
Training loss: 0.6762248873710632
Validation loss: 1.877049635815364

Epoch: 6| Step: 12
Training loss: 0.41110578179359436
Validation loss: 1.8751372393741403

Epoch: 6| Step: 13
Training loss: 0.6815427541732788
Validation loss: 1.8760593104106125

Epoch: 309| Step: 0
Training loss: 0.9275529384613037
Validation loss: 1.9001625558381439

Epoch: 6| Step: 1
Training loss: 0.46202775835990906
Validation loss: 1.9097576602812736

Epoch: 6| Step: 2
Training loss: 0.8448062539100647
Validation loss: 1.9183296003649313

Epoch: 6| Step: 3
Training loss: 0.5986353158950806
Validation loss: 1.9125529181572698

Epoch: 6| Step: 4
Training loss: 0.7241559028625488
Validation loss: 1.9012527119728826

Epoch: 6| Step: 5
Training loss: 0.554287314414978
Validation loss: 1.888109839090737

Epoch: 6| Step: 6
Training loss: 0.8126909732818604
Validation loss: 1.8792007046361123

Epoch: 6| Step: 7
Training loss: 0.356208860874176
Validation loss: 1.914877914613293

Epoch: 6| Step: 8
Training loss: 0.5099655389785767
Validation loss: 1.8678265566466956

Epoch: 6| Step: 9
Training loss: 0.13597369194030762
Validation loss: 1.886420783176217

Epoch: 6| Step: 10
Training loss: 0.402072012424469
Validation loss: 1.8953143781231296

Epoch: 6| Step: 11
Training loss: 0.3370758295059204
Validation loss: 1.885355878901738

Epoch: 6| Step: 12
Training loss: 0.7791690826416016
Validation loss: 1.9054436119653846

Epoch: 6| Step: 13
Training loss: 0.7786516547203064
Validation loss: 1.9108522143415225

Epoch: 310| Step: 0
Training loss: 0.825579047203064
Validation loss: 1.9413766091869724

Epoch: 6| Step: 1
Training loss: 0.5577275156974792
Validation loss: 1.9283293344641244

Epoch: 6| Step: 2
Training loss: 0.2589694857597351
Validation loss: 1.9141159480617893

Epoch: 6| Step: 3
Training loss: 0.7107596397399902
Validation loss: 1.8979676564534504

Epoch: 6| Step: 4
Training loss: 0.6942551136016846
Validation loss: 1.9037466728559105

Epoch: 6| Step: 5
Training loss: 0.5080440640449524
Validation loss: 1.8787899940244612

Epoch: 6| Step: 6
Training loss: 0.6730376482009888
Validation loss: 1.8463206124562088

Epoch: 6| Step: 7
Training loss: 1.0754753351211548
Validation loss: 1.8284709312582528

Epoch: 6| Step: 8
Training loss: 0.520266056060791
Validation loss: 1.8306675418730705

Epoch: 6| Step: 9
Training loss: 0.3759409785270691
Validation loss: 1.8291659188526932

Epoch: 6| Step: 10
Training loss: 0.47999176383018494
Validation loss: 1.8309954520194762

Epoch: 6| Step: 11
Training loss: 0.22975343465805054
Validation loss: 1.8154202045932892

Epoch: 6| Step: 12
Training loss: 0.6341111660003662
Validation loss: 1.8312730353365663

Epoch: 6| Step: 13
Training loss: 0.5195912718772888
Validation loss: 1.8537126984647525

Epoch: 311| Step: 0
Training loss: 0.3370424509048462
Validation loss: 1.8273907297401017

Epoch: 6| Step: 1
Training loss: 0.7518905997276306
Validation loss: 1.8293520276264479

Epoch: 6| Step: 2
Training loss: 0.5139293670654297
Validation loss: 1.8363663406782254

Epoch: 6| Step: 3
Training loss: 0.4277820587158203
Validation loss: 1.8653784567309963

Epoch: 6| Step: 4
Training loss: 0.5160627961158752
Validation loss: 1.8230280671068417

Epoch: 6| Step: 5
Training loss: 0.4756418466567993
Validation loss: 1.8119714439556163

Epoch: 6| Step: 6
Training loss: 0.5949848294258118
Validation loss: 1.8287135580534577

Epoch: 6| Step: 7
Training loss: 0.3346668779850006
Validation loss: 1.8478177990964664

Epoch: 6| Step: 8
Training loss: 0.8084198832511902
Validation loss: 1.8889462537662958

Epoch: 6| Step: 9
Training loss: 0.7658968567848206
Validation loss: 1.9190524265330324

Epoch: 6| Step: 10
Training loss: 0.3995240330696106
Validation loss: 1.8786887917467343

Epoch: 6| Step: 11
Training loss: 0.8060095906257629
Validation loss: 1.9149518884638304

Epoch: 6| Step: 12
Training loss: 0.716727614402771
Validation loss: 1.9048481654095393

Epoch: 6| Step: 13
Training loss: 0.5966601371765137
Validation loss: 1.8762274096089024

Epoch: 312| Step: 0
Training loss: 0.7249057292938232
Validation loss: 1.8701488946073799

Epoch: 6| Step: 1
Training loss: 0.4149053394794464
Validation loss: 1.869661719568314

Epoch: 6| Step: 2
Training loss: 0.37931957840919495
Validation loss: 1.8470857656130226

Epoch: 6| Step: 3
Training loss: 0.5553561449050903
Validation loss: 1.8613372233606154

Epoch: 6| Step: 4
Training loss: 0.5099469423294067
Validation loss: 1.8482374093865837

Epoch: 6| Step: 5
Training loss: 0.5228671431541443
Validation loss: 1.845549661626098

Epoch: 6| Step: 6
Training loss: 0.5955407619476318
Validation loss: 1.864169974480906

Epoch: 6| Step: 7
Training loss: 0.5005027055740356
Validation loss: 1.8888092681925783

Epoch: 6| Step: 8
Training loss: 0.7992059588432312
Validation loss: 1.8738489074091758

Epoch: 6| Step: 9
Training loss: 0.6293582320213318
Validation loss: 1.8702333729754212

Epoch: 6| Step: 10
Training loss: 0.23614028096199036
Validation loss: 1.8807608850540654

Epoch: 6| Step: 11
Training loss: 0.6544328331947327
Validation loss: 1.8504787222031625

Epoch: 6| Step: 12
Training loss: 0.5391098260879517
Validation loss: 1.8601196222407843

Epoch: 6| Step: 13
Training loss: 0.4254227876663208
Validation loss: 1.8531476502777429

Epoch: 313| Step: 0
Training loss: 0.6696231961250305
Validation loss: 1.8567748338945451

Epoch: 6| Step: 1
Training loss: 0.46500831842422485
Validation loss: 1.8985517550540227

Epoch: 6| Step: 2
Training loss: 0.3934522569179535
Validation loss: 1.8674321097712363

Epoch: 6| Step: 3
Training loss: 0.534996747970581
Validation loss: 1.9077519601391209

Epoch: 6| Step: 4
Training loss: 0.5808482766151428
Validation loss: 1.9273304785451582

Epoch: 6| Step: 5
Training loss: 0.34848612546920776
Validation loss: 1.9034768919790945

Epoch: 6| Step: 6
Training loss: 0.7665353417396545
Validation loss: 1.8807848845758746

Epoch: 6| Step: 7
Training loss: 0.4504331946372986
Validation loss: 1.895960925727762

Epoch: 6| Step: 8
Training loss: 0.38915157318115234
Validation loss: 1.8654689763181953

Epoch: 6| Step: 9
Training loss: 0.6707907915115356
Validation loss: 1.869818284947385

Epoch: 6| Step: 10
Training loss: 0.3629106283187866
Validation loss: 1.8599025331517702

Epoch: 6| Step: 11
Training loss: 0.784244179725647
Validation loss: 1.852579479576439

Epoch: 6| Step: 12
Training loss: 0.7069640159606934
Validation loss: 1.8414310498904156

Epoch: 6| Step: 13
Training loss: 0.7019007205963135
Validation loss: 1.8605622091600973

Epoch: 314| Step: 0
Training loss: 0.4740030765533447
Validation loss: 1.8470485902601672

Epoch: 6| Step: 1
Training loss: 0.4702044129371643
Validation loss: 1.8378671202608334

Epoch: 6| Step: 2
Training loss: 0.576857328414917
Validation loss: 1.850657343864441

Epoch: 6| Step: 3
Training loss: 0.5142111778259277
Validation loss: 1.8407076340849682

Epoch: 6| Step: 4
Training loss: 0.5891187787055969
Validation loss: 1.8409692266935944

Epoch: 6| Step: 5
Training loss: 0.48966458439826965
Validation loss: 1.8873911032112696

Epoch: 6| Step: 6
Training loss: 0.3107507824897766
Validation loss: 1.8922286136175996

Epoch: 6| Step: 7
Training loss: 0.8078189492225647
Validation loss: 1.898262652017737

Epoch: 6| Step: 8
Training loss: 0.5461834669113159
Validation loss: 1.9174273219159854

Epoch: 6| Step: 9
Training loss: 0.6329449415206909
Validation loss: 1.9013812093324558

Epoch: 6| Step: 10
Training loss: 0.5774936079978943
Validation loss: 1.8995365173585954

Epoch: 6| Step: 11
Training loss: 0.5344470739364624
Validation loss: 1.8864158302225091

Epoch: 6| Step: 12
Training loss: 0.6305025815963745
Validation loss: 1.867603204583609

Epoch: 6| Step: 13
Training loss: 0.7859074473381042
Validation loss: 1.8899787523413216

Epoch: 315| Step: 0
Training loss: 0.6891619563102722
Validation loss: 1.8665580698238906

Epoch: 6| Step: 1
Training loss: 0.6169617176055908
Validation loss: 1.8883018288561093

Epoch: 6| Step: 2
Training loss: 0.46846485137939453
Validation loss: 1.8905377323909471

Epoch: 6| Step: 3
Training loss: 0.5348745584487915
Validation loss: 1.923523497837846

Epoch: 6| Step: 4
Training loss: 0.36322811245918274
Validation loss: 1.899593714744814

Epoch: 6| Step: 5
Training loss: 0.3809330463409424
Validation loss: 1.8692395533284833

Epoch: 6| Step: 6
Training loss: 0.3510499596595764
Validation loss: 1.8453812329999861

Epoch: 6| Step: 7
Training loss: 0.9261099100112915
Validation loss: 1.8474838297854188

Epoch: 6| Step: 8
Training loss: 0.8869099020957947
Validation loss: 1.8782402828175535

Epoch: 6| Step: 9
Training loss: 0.3387012481689453
Validation loss: 1.8840582806576964

Epoch: 6| Step: 10
Training loss: 0.568703830242157
Validation loss: 1.8431387024541055

Epoch: 6| Step: 11
Training loss: 0.4249591827392578
Validation loss: 1.832007251760011

Epoch: 6| Step: 12
Training loss: 0.8529907464981079
Validation loss: 1.8436513728992914

Epoch: 6| Step: 13
Training loss: 0.395985871553421
Validation loss: 1.8448971522751676

Epoch: 316| Step: 0
Training loss: 0.5570607781410217
Validation loss: 1.8464191318840109

Epoch: 6| Step: 1
Training loss: 1.0071419477462769
Validation loss: 1.8616839788293327

Epoch: 6| Step: 2
Training loss: 0.557188868522644
Validation loss: 1.8837935052892214

Epoch: 6| Step: 3
Training loss: 0.5289018154144287
Validation loss: 1.9011215112542594

Epoch: 6| Step: 4
Training loss: 0.45564472675323486
Validation loss: 1.910107445973222

Epoch: 6| Step: 5
Training loss: 0.4899466037750244
Validation loss: 1.9168932540442354

Epoch: 6| Step: 6
Training loss: 0.8075084686279297
Validation loss: 1.891514475627612

Epoch: 6| Step: 7
Training loss: 0.8433799743652344
Validation loss: 1.9027678581976122

Epoch: 6| Step: 8
Training loss: 0.2807818651199341
Validation loss: 1.8896293268408826

Epoch: 6| Step: 9
Training loss: 0.4996587634086609
Validation loss: 1.8934784140638126

Epoch: 6| Step: 10
Training loss: 0.7616613507270813
Validation loss: 1.882591062976468

Epoch: 6| Step: 11
Training loss: 0.3591024577617645
Validation loss: 1.884268674799191

Epoch: 6| Step: 12
Training loss: 0.7907884120941162
Validation loss: 1.8778464037884948

Epoch: 6| Step: 13
Training loss: 0.5574951767921448
Validation loss: 1.8768128707844725

Epoch: 317| Step: 0
Training loss: 0.8518041372299194
Validation loss: 1.8878415297436457

Epoch: 6| Step: 1
Training loss: 0.72465580701828
Validation loss: 1.8488368552218202

Epoch: 6| Step: 2
Training loss: 0.5324311852455139
Validation loss: 1.8288777912816694

Epoch: 6| Step: 3
Training loss: 0.42706918716430664
Validation loss: 1.8124776450536584

Epoch: 6| Step: 4
Training loss: 0.5342823266983032
Validation loss: 1.8193060428865495

Epoch: 6| Step: 5
Training loss: 0.5482491850852966
Validation loss: 1.827604357914258

Epoch: 6| Step: 6
Training loss: 0.4337213635444641
Validation loss: 1.8212768993070048

Epoch: 6| Step: 7
Training loss: 0.4365800619125366
Validation loss: 1.8197611326812415

Epoch: 6| Step: 8
Training loss: 0.5343025922775269
Validation loss: 1.8147317260824225

Epoch: 6| Step: 9
Training loss: 0.4366067349910736
Validation loss: 1.8157405417452577

Epoch: 6| Step: 10
Training loss: 0.5534926652908325
Validation loss: 1.854774909634744

Epoch: 6| Step: 11
Training loss: 0.4380743205547333
Validation loss: 1.8303124648268505

Epoch: 6| Step: 12
Training loss: 0.8943501710891724
Validation loss: 1.8474480541803504

Epoch: 6| Step: 13
Training loss: 0.5792877078056335
Validation loss: 1.8597843262457079

Epoch: 318| Step: 0
Training loss: 0.7214334011077881
Validation loss: 1.8615938655791744

Epoch: 6| Step: 1
Training loss: 0.5386778116226196
Validation loss: 1.8674902928772794

Epoch: 6| Step: 2
Training loss: 0.4307105243206024
Validation loss: 1.8240050808075936

Epoch: 6| Step: 3
Training loss: 0.47304046154022217
Validation loss: 1.8713760017066874

Epoch: 6| Step: 4
Training loss: 0.4897489547729492
Validation loss: 1.830958774012904

Epoch: 6| Step: 5
Training loss: 0.7457163333892822
Validation loss: 1.8403021135637838

Epoch: 6| Step: 6
Training loss: 0.361032098531723
Validation loss: 1.824764411936524

Epoch: 6| Step: 7
Training loss: 0.594883143901825
Validation loss: 1.8208409714442428

Epoch: 6| Step: 8
Training loss: 0.26745176315307617
Validation loss: 1.8109410232113254

Epoch: 6| Step: 9
Training loss: 0.5564811825752258
Validation loss: 1.814093259073073

Epoch: 6| Step: 10
Training loss: 0.5544850826263428
Validation loss: 1.8122364218517015

Epoch: 6| Step: 11
Training loss: 0.5286877751350403
Validation loss: 1.860423904593273

Epoch: 6| Step: 12
Training loss: 0.6360867023468018
Validation loss: 1.8519498173908522

Epoch: 6| Step: 13
Training loss: 0.8348322510719299
Validation loss: 1.8513987397634855

Epoch: 319| Step: 0
Training loss: 0.7235604524612427
Validation loss: 1.8559916967986732

Epoch: 6| Step: 1
Training loss: 0.550521969795227
Validation loss: 1.8563394161962694

Epoch: 6| Step: 2
Training loss: 0.9335081577301025
Validation loss: 1.85555737762041

Epoch: 6| Step: 3
Training loss: 0.4246392846107483
Validation loss: 1.8402784973062494

Epoch: 6| Step: 4
Training loss: 0.43983447551727295
Validation loss: 1.815615100245322

Epoch: 6| Step: 5
Training loss: 0.7729817628860474
Validation loss: 1.8176738177576373

Epoch: 6| Step: 6
Training loss: 0.5481374263763428
Validation loss: 1.8119588193073068

Epoch: 6| Step: 7
Training loss: 0.3026184141635895
Validation loss: 1.834348468370335

Epoch: 6| Step: 8
Training loss: 0.3788675367832184
Validation loss: 1.8342526317924581

Epoch: 6| Step: 9
Training loss: 0.6571680903434753
Validation loss: 1.8472664458777315

Epoch: 6| Step: 10
Training loss: 0.7898702025413513
Validation loss: 1.8309656650789323

Epoch: 6| Step: 11
Training loss: 0.5953606367111206
Validation loss: 1.8197251878758913

Epoch: 6| Step: 12
Training loss: 0.5425626635551453
Validation loss: 1.800571971042182

Epoch: 6| Step: 13
Training loss: 0.39517298340797424
Validation loss: 1.8137209940982122

Epoch: 320| Step: 0
Training loss: 0.4364224374294281
Validation loss: 1.8260908562649962

Epoch: 6| Step: 1
Training loss: 1.1346381902694702
Validation loss: 1.8273632372579267

Epoch: 6| Step: 2
Training loss: 0.5298948287963867
Validation loss: 1.825659824955848

Epoch: 6| Step: 3
Training loss: 0.3307371139526367
Validation loss: 1.826072992817048

Epoch: 6| Step: 4
Training loss: 0.506223738193512
Validation loss: 1.7984895244721444

Epoch: 6| Step: 5
Training loss: 0.4386195242404938
Validation loss: 1.8126680120345084

Epoch: 6| Step: 6
Training loss: 0.4148443937301636
Validation loss: 1.8219641870067966

Epoch: 6| Step: 7
Training loss: 0.6773514747619629
Validation loss: 1.8597390561975458

Epoch: 6| Step: 8
Training loss: 0.6056149005889893
Validation loss: 1.8248792015096194

Epoch: 6| Step: 9
Training loss: 0.43908411264419556
Validation loss: 1.8348456582715433

Epoch: 6| Step: 10
Training loss: 0.4652005136013031
Validation loss: 1.8286315407804263

Epoch: 6| Step: 11
Training loss: 0.3656005561351776
Validation loss: 1.8600662164790656

Epoch: 6| Step: 12
Training loss: 0.626530647277832
Validation loss: 1.8283229130570606

Epoch: 6| Step: 13
Training loss: 0.41047143936157227
Validation loss: 1.844559900222286

Epoch: 321| Step: 0
Training loss: 0.39530307054519653
Validation loss: 1.8566513202523673

Epoch: 6| Step: 1
Training loss: 0.5592548847198486
Validation loss: 1.8593191292978102

Epoch: 6| Step: 2
Training loss: 0.44053956866264343
Validation loss: 1.8787988667847009

Epoch: 6| Step: 3
Training loss: 0.78901207447052
Validation loss: 1.878042677397369

Epoch: 6| Step: 4
Training loss: 0.5193927884101868
Validation loss: 1.9204131057185512

Epoch: 6| Step: 5
Training loss: 0.7189464569091797
Validation loss: 1.9394873419115621

Epoch: 6| Step: 6
Training loss: 0.589747428894043
Validation loss: 1.9128886204893871

Epoch: 6| Step: 7
Training loss: 0.6943637132644653
Validation loss: 1.9234061933332873

Epoch: 6| Step: 8
Training loss: 0.4491140842437744
Validation loss: 1.901091997341443

Epoch: 6| Step: 9
Training loss: 0.5531826615333557
Validation loss: 1.8471989644471036

Epoch: 6| Step: 10
Training loss: 0.27869078516960144
Validation loss: 1.8397816265783002

Epoch: 6| Step: 11
Training loss: 0.4886830449104309
Validation loss: 1.8526956932519072

Epoch: 6| Step: 12
Training loss: 0.40212082862854004
Validation loss: 1.8488523678113056

Epoch: 6| Step: 13
Training loss: 0.5542287826538086
Validation loss: 1.8342396533617409

Epoch: 322| Step: 0
Training loss: 0.7571537494659424
Validation loss: 1.7909142022491784

Epoch: 6| Step: 1
Training loss: 0.28782111406326294
Validation loss: 1.7942691874760452

Epoch: 6| Step: 2
Training loss: 0.45987290143966675
Validation loss: 1.8223711162485101

Epoch: 6| Step: 3
Training loss: 0.3985369801521301
Validation loss: 1.8084092902880844

Epoch: 6| Step: 4
Training loss: 0.5450106859207153
Validation loss: 1.7886533762819024

Epoch: 6| Step: 5
Training loss: 0.6878296136856079
Validation loss: 1.7871992447042977

Epoch: 6| Step: 6
Training loss: 0.45659682154655457
Validation loss: 1.8264939144093504

Epoch: 6| Step: 7
Training loss: 0.34075120091438293
Validation loss: 1.8152575915859592

Epoch: 6| Step: 8
Training loss: 0.5099303126335144
Validation loss: 1.8088944189010128

Epoch: 6| Step: 9
Training loss: 0.8792018890380859
Validation loss: 1.808278622165803

Epoch: 6| Step: 10
Training loss: 0.3522977828979492
Validation loss: 1.8072956198005266

Epoch: 6| Step: 11
Training loss: 0.47155076265335083
Validation loss: 1.8411460627791703

Epoch: 6| Step: 12
Training loss: 0.44154080748558044
Validation loss: 1.818896742277248

Epoch: 6| Step: 13
Training loss: 0.2601391077041626
Validation loss: 1.7935958446994904

Epoch: 323| Step: 0
Training loss: 0.4718031585216522
Validation loss: 1.7925714754289197

Epoch: 6| Step: 1
Training loss: 0.6249856352806091
Validation loss: 1.8356446655847694

Epoch: 6| Step: 2
Training loss: 0.3354783058166504
Validation loss: 1.841049107172156

Epoch: 6| Step: 3
Training loss: 0.3440473675727844
Validation loss: 1.8204789174500333

Epoch: 6| Step: 4
Training loss: 0.30915963649749756
Validation loss: 1.8051123721625215

Epoch: 6| Step: 5
Training loss: 0.714012861251831
Validation loss: 1.7888922358071933

Epoch: 6| Step: 6
Training loss: 0.6086039543151855
Validation loss: 1.805965059547014

Epoch: 6| Step: 7
Training loss: 0.5716755390167236
Validation loss: 1.8166593736217869

Epoch: 6| Step: 8
Training loss: 0.40515467524528503
Validation loss: 1.80781820384405

Epoch: 6| Step: 9
Training loss: 0.6369631290435791
Validation loss: 1.830316266705913

Epoch: 6| Step: 10
Training loss: 0.5356079936027527
Validation loss: 1.8066607521426292

Epoch: 6| Step: 11
Training loss: 0.8141136765480042
Validation loss: 1.8158074091839533

Epoch: 6| Step: 12
Training loss: 0.5042819380760193
Validation loss: 1.8310772436921314

Epoch: 6| Step: 13
Training loss: 0.3353263735771179
Validation loss: 1.8503646991586173

Epoch: 324| Step: 0
Training loss: 0.3631224036216736
Validation loss: 1.8580305909597745

Epoch: 6| Step: 1
Training loss: 0.5739084482192993
Validation loss: 1.8686082927129601

Epoch: 6| Step: 2
Training loss: 0.5546066164970398
Validation loss: 1.854095389766078

Epoch: 6| Step: 3
Training loss: 0.3888343572616577
Validation loss: 1.8596134595973517

Epoch: 6| Step: 4
Training loss: 0.2747305929660797
Validation loss: 1.844968899603813

Epoch: 6| Step: 5
Training loss: 0.37525835633277893
Validation loss: 1.8310058745004798

Epoch: 6| Step: 6
Training loss: 0.4053308963775635
Validation loss: 1.850829170596215

Epoch: 6| Step: 7
Training loss: 0.4555799961090088
Validation loss: 1.8461386131983932

Epoch: 6| Step: 8
Training loss: 0.6042578220367432
Validation loss: 1.843336997493621

Epoch: 6| Step: 9
Training loss: 0.2940417230129242
Validation loss: 1.8557207520290087

Epoch: 6| Step: 10
Training loss: 0.6443540453910828
Validation loss: 1.8467216722426876

Epoch: 6| Step: 11
Training loss: 0.4913245439529419
Validation loss: 1.8484616484693301

Epoch: 6| Step: 12
Training loss: 0.4126337468624115
Validation loss: 1.8586796252958235

Epoch: 6| Step: 13
Training loss: 1.18692946434021
Validation loss: 1.8530177941886328

Epoch: 325| Step: 0
Training loss: 0.3896973133087158
Validation loss: 1.8753527710514684

Epoch: 6| Step: 1
Training loss: 0.6826720237731934
Validation loss: 1.8451510962619577

Epoch: 6| Step: 2
Training loss: 0.33621466159820557
Validation loss: 1.8594523360652309

Epoch: 6| Step: 3
Training loss: 0.2960759997367859
Validation loss: 1.862170175839496

Epoch: 6| Step: 4
Training loss: 0.5019862055778503
Validation loss: 1.8386215855998378

Epoch: 6| Step: 5
Training loss: 0.39381343126296997
Validation loss: 1.8391138507473854

Epoch: 6| Step: 6
Training loss: 0.5520257949829102
Validation loss: 1.8179519253392373

Epoch: 6| Step: 7
Training loss: 0.3887290358543396
Validation loss: 1.8304730724262934

Epoch: 6| Step: 8
Training loss: 0.2430191934108734
Validation loss: 1.82854579212845

Epoch: 6| Step: 9
Training loss: 0.8239191174507141
Validation loss: 1.8245900895005913

Epoch: 6| Step: 10
Training loss: 0.6805227994918823
Validation loss: 1.813943209186677

Epoch: 6| Step: 11
Training loss: 0.5117425918579102
Validation loss: 1.8090485219032533

Epoch: 6| Step: 12
Training loss: 0.45019927620887756
Validation loss: 1.828014527597735

Epoch: 6| Step: 13
Training loss: 0.8065004348754883
Validation loss: 1.789321652022741

Epoch: 326| Step: 0
Training loss: 0.22571873664855957
Validation loss: 1.7751571388654812

Epoch: 6| Step: 1
Training loss: 0.2512510418891907
Validation loss: 1.786982685007075

Epoch: 6| Step: 2
Training loss: 0.5911779403686523
Validation loss: 1.8177402666819993

Epoch: 6| Step: 3
Training loss: 0.96399986743927
Validation loss: 1.849448965441796

Epoch: 6| Step: 4
Training loss: 0.27807700634002686
Validation loss: 1.8540368656958304

Epoch: 6| Step: 5
Training loss: 0.6166863441467285
Validation loss: 1.8255856665231849

Epoch: 6| Step: 6
Training loss: 0.537682294845581
Validation loss: 1.8136813358594013

Epoch: 6| Step: 7
Training loss: 0.4420110583305359
Validation loss: 1.8442618090619323

Epoch: 6| Step: 8
Training loss: 0.3926101326942444
Validation loss: 1.8501042371155114

Epoch: 6| Step: 9
Training loss: 0.2749764323234558
Validation loss: 1.850603207465141

Epoch: 6| Step: 10
Training loss: 0.49616724252700806
Validation loss: 1.8930050814023582

Epoch: 6| Step: 11
Training loss: 0.7508476972579956
Validation loss: 1.9000969753470471

Epoch: 6| Step: 12
Training loss: 0.936922550201416
Validation loss: 1.8828014404542985

Epoch: 6| Step: 13
Training loss: 0.40700429677963257
Validation loss: 1.872903859743508

Epoch: 327| Step: 0
Training loss: 0.5493613481521606
Validation loss: 1.8509278733243224

Epoch: 6| Step: 1
Training loss: 0.550971508026123
Validation loss: 1.842008726571196

Epoch: 6| Step: 2
Training loss: 0.990315854549408
Validation loss: 1.8156794604434763

Epoch: 6| Step: 3
Training loss: 0.473312646150589
Validation loss: 1.7994591074605142

Epoch: 6| Step: 4
Training loss: 0.4773576855659485
Validation loss: 1.816749765026954

Epoch: 6| Step: 5
Training loss: 0.5236443877220154
Validation loss: 1.8448174756060365

Epoch: 6| Step: 6
Training loss: 0.6317049264907837
Validation loss: 1.8563683032989502

Epoch: 6| Step: 7
Training loss: 0.37917399406433105
Validation loss: 1.8336483637491863

Epoch: 6| Step: 8
Training loss: 0.3760548233985901
Validation loss: 1.8416332762728456

Epoch: 6| Step: 9
Training loss: 0.30702000856399536
Validation loss: 1.8019640214981572

Epoch: 6| Step: 10
Training loss: 0.504835844039917
Validation loss: 1.8189641057804067

Epoch: 6| Step: 11
Training loss: 0.43489331007003784
Validation loss: 1.8242785353814401

Epoch: 6| Step: 12
Training loss: 0.1694227010011673
Validation loss: 1.8426516299606652

Epoch: 6| Step: 13
Training loss: 0.23337575793266296
Validation loss: 1.8467052380243938

Epoch: 328| Step: 0
Training loss: 0.4082144498825073
Validation loss: 1.8710092600955759

Epoch: 6| Step: 1
Training loss: 0.6204206347465515
Validation loss: 1.8510225280638664

Epoch: 6| Step: 2
Training loss: 0.584869384765625
Validation loss: 1.828179810636787

Epoch: 6| Step: 3
Training loss: 0.33696427941322327
Validation loss: 1.8349608759726248

Epoch: 6| Step: 4
Training loss: 0.3369061350822449
Validation loss: 1.8178718756603938

Epoch: 6| Step: 5
Training loss: 0.39537477493286133
Validation loss: 1.8318249615289832

Epoch: 6| Step: 6
Training loss: 0.7150900363922119
Validation loss: 1.8470628235929756

Epoch: 6| Step: 7
Training loss: 0.46979570388793945
Validation loss: 1.85071216347397

Epoch: 6| Step: 8
Training loss: 0.5864740014076233
Validation loss: 1.8623101352363505

Epoch: 6| Step: 9
Training loss: 0.3966652452945709
Validation loss: 1.8300147312943653

Epoch: 6| Step: 10
Training loss: 0.6772837042808533
Validation loss: 1.807696650105138

Epoch: 6| Step: 11
Training loss: 0.3431698679924011
Validation loss: 1.7912423815778507

Epoch: 6| Step: 12
Training loss: 0.7283381223678589
Validation loss: 1.794049855201475

Epoch: 6| Step: 13
Training loss: 0.5907852053642273
Validation loss: 1.7994306318221553

Epoch: 329| Step: 0
Training loss: 0.557856559753418
Validation loss: 1.7960294421001146

Epoch: 6| Step: 1
Training loss: 0.4754720628261566
Validation loss: 1.8130405346552532

Epoch: 6| Step: 2
Training loss: 0.1804533302783966
Validation loss: 1.7809093998324486

Epoch: 6| Step: 3
Training loss: 0.36743003129959106
Validation loss: 1.8012207246595813

Epoch: 6| Step: 4
Training loss: 0.6354866027832031
Validation loss: 1.7971446565402451

Epoch: 6| Step: 5
Training loss: 0.6456367373466492
Validation loss: 1.8403745235935334

Epoch: 6| Step: 6
Training loss: 0.3121190667152405
Validation loss: 1.8213930206914102

Epoch: 6| Step: 7
Training loss: 0.5694562196731567
Validation loss: 1.8373430903239916

Epoch: 6| Step: 8
Training loss: 0.48823368549346924
Validation loss: 1.8474567718403314

Epoch: 6| Step: 9
Training loss: 0.3568894863128662
Validation loss: 1.8498509289115987

Epoch: 6| Step: 10
Training loss: 0.406928151845932
Validation loss: 1.847686247159076

Epoch: 6| Step: 11
Training loss: 0.2747281491756439
Validation loss: 1.8612248448915378

Epoch: 6| Step: 12
Training loss: 0.49047788977622986
Validation loss: 1.817832213576122

Epoch: 6| Step: 13
Training loss: 1.173981785774231
Validation loss: 1.8243720352008779

Epoch: 330| Step: 0
Training loss: 0.4223208427429199
Validation loss: 1.8304563260847522

Epoch: 6| Step: 1
Training loss: 0.5032321810722351
Validation loss: 1.7947210829745057

Epoch: 6| Step: 2
Training loss: 0.4156803488731384
Validation loss: 1.8257895387629026

Epoch: 6| Step: 3
Training loss: 0.7183245420455933
Validation loss: 1.831194411041916

Epoch: 6| Step: 4
Training loss: 0.5151029825210571
Validation loss: 1.8093857560106503

Epoch: 6| Step: 5
Training loss: 0.42673787474632263
Validation loss: 1.8156453447957193

Epoch: 6| Step: 6
Training loss: 0.5878819227218628
Validation loss: 1.839160757680093

Epoch: 6| Step: 7
Training loss: 0.4689955413341522
Validation loss: 1.8279836844372492

Epoch: 6| Step: 8
Training loss: 0.542519211769104
Validation loss: 1.8022594900541409

Epoch: 6| Step: 9
Training loss: 0.3223181664943695
Validation loss: 1.801237843369925

Epoch: 6| Step: 10
Training loss: 0.36002278327941895
Validation loss: 1.8071948251416605

Epoch: 6| Step: 11
Training loss: 0.4100419282913208
Validation loss: 1.825592110233922

Epoch: 6| Step: 12
Training loss: 0.4448307752609253
Validation loss: 1.8034747313427668

Epoch: 6| Step: 13
Training loss: 0.3046720027923584
Validation loss: 1.794612943485219

Epoch: 331| Step: 0
Training loss: 0.5700299739837646
Validation loss: 1.7891411806947441

Epoch: 6| Step: 1
Training loss: 0.3103911280632019
Validation loss: 1.797119112424953

Epoch: 6| Step: 2
Training loss: 0.31521546840667725
Validation loss: 1.784625502042873

Epoch: 6| Step: 3
Training loss: 0.5934606194496155
Validation loss: 1.7880493684481549

Epoch: 6| Step: 4
Training loss: 0.44850850105285645
Validation loss: 1.771915437072836

Epoch: 6| Step: 5
Training loss: 0.4953685402870178
Validation loss: 1.7952262175980436

Epoch: 6| Step: 6
Training loss: 0.7392994165420532
Validation loss: 1.8020708740398448

Epoch: 6| Step: 7
Training loss: 0.28303587436676025
Validation loss: 1.7758702885720037

Epoch: 6| Step: 8
Training loss: 0.2100648283958435
Validation loss: 1.8008725232975458

Epoch: 6| Step: 9
Training loss: 0.4168018102645874
Validation loss: 1.8375664270052345

Epoch: 6| Step: 10
Training loss: 0.4716664254665375
Validation loss: 1.8226829369862874

Epoch: 6| Step: 11
Training loss: 0.9934277534484863
Validation loss: 1.8209387563890027

Epoch: 6| Step: 12
Training loss: 0.39613646268844604
Validation loss: 1.7989659488842051

Epoch: 6| Step: 13
Training loss: 0.2331383228302002
Validation loss: 1.821418018751247

Epoch: 332| Step: 0
Training loss: 0.5545729994773865
Validation loss: 1.851126750310262

Epoch: 6| Step: 1
Training loss: 0.6754747033119202
Validation loss: 1.8529115723025413

Epoch: 6| Step: 2
Training loss: 0.5252765417098999
Validation loss: 1.8506377448317826

Epoch: 6| Step: 3
Training loss: 0.24904018640518188
Validation loss: 1.8079145634046165

Epoch: 6| Step: 4
Training loss: 0.29944872856140137
Validation loss: 1.8322177471653107

Epoch: 6| Step: 5
Training loss: 0.6162614822387695
Validation loss: 1.8302207031557638

Epoch: 6| Step: 6
Training loss: 0.43862009048461914
Validation loss: 1.8338827247260718

Epoch: 6| Step: 7
Training loss: 0.5528892278671265
Validation loss: 1.8349339692823348

Epoch: 6| Step: 8
Training loss: 0.1466730386018753
Validation loss: 1.8361330903986448

Epoch: 6| Step: 9
Training loss: 0.5070945024490356
Validation loss: 1.8519132598753898

Epoch: 6| Step: 10
Training loss: 0.3741258680820465
Validation loss: 1.843039874107607

Epoch: 6| Step: 11
Training loss: 0.2939993739128113
Validation loss: 1.845140519962516

Epoch: 6| Step: 12
Training loss: 0.8334187269210815
Validation loss: 1.8703875054595291

Epoch: 6| Step: 13
Training loss: 0.40412256121635437
Validation loss: 1.8754154610377487

Epoch: 333| Step: 0
Training loss: 0.44411158561706543
Validation loss: 1.8315509698724235

Epoch: 6| Step: 1
Training loss: 0.24197956919670105
Validation loss: 1.8322501592738654

Epoch: 6| Step: 2
Training loss: 0.6793031692504883
Validation loss: 1.8295470565877936

Epoch: 6| Step: 3
Training loss: 0.37183576822280884
Validation loss: 1.8443999521193966

Epoch: 6| Step: 4
Training loss: 0.6124933362007141
Validation loss: 1.8360159448398057

Epoch: 6| Step: 5
Training loss: 0.35855942964553833
Validation loss: 1.83887344021951

Epoch: 6| Step: 6
Training loss: 0.4029708206653595
Validation loss: 1.845616953347319

Epoch: 6| Step: 7
Training loss: 0.47317421436309814
Validation loss: 1.811255447326168

Epoch: 6| Step: 8
Training loss: 0.3590965270996094
Validation loss: 1.8185726417008268

Epoch: 6| Step: 9
Training loss: 0.3691510558128357
Validation loss: 1.8283389768292826

Epoch: 6| Step: 10
Training loss: 0.6440144777297974
Validation loss: 1.8078773701062767

Epoch: 6| Step: 11
Training loss: 0.7921121716499329
Validation loss: 1.8134874015726068

Epoch: 6| Step: 12
Training loss: 0.3395497500896454
Validation loss: 1.8004608833661644

Epoch: 6| Step: 13
Training loss: 0.16467635333538055
Validation loss: 1.776866130931403

Epoch: 334| Step: 0
Training loss: 0.4412158727645874
Validation loss: 1.7887096507574922

Epoch: 6| Step: 1
Training loss: 0.4921318292617798
Validation loss: 1.7813425153814337

Epoch: 6| Step: 2
Training loss: 0.5614410638809204
Validation loss: 1.8195953330686014

Epoch: 6| Step: 3
Training loss: 0.34462517499923706
Validation loss: 1.8249633824953468

Epoch: 6| Step: 4
Training loss: 0.3209534287452698
Validation loss: 1.8318261779764646

Epoch: 6| Step: 5
Training loss: 0.4542456865310669
Validation loss: 1.7997766784442368

Epoch: 6| Step: 6
Training loss: 0.4160437285900116
Validation loss: 1.8205375235567811

Epoch: 6| Step: 7
Training loss: 0.3247706890106201
Validation loss: 1.8196357065631497

Epoch: 6| Step: 8
Training loss: 0.5983947515487671
Validation loss: 1.8277166274286085

Epoch: 6| Step: 9
Training loss: 0.45563986897468567
Validation loss: 1.84961651602099

Epoch: 6| Step: 10
Training loss: 0.40678077936172485
Validation loss: 1.8416083692222514

Epoch: 6| Step: 11
Training loss: 0.3140411972999573
Validation loss: 1.8350904936431556

Epoch: 6| Step: 12
Training loss: 0.7431139945983887
Validation loss: 1.8457282345782045

Epoch: 6| Step: 13
Training loss: 0.527296781539917
Validation loss: 1.85180954522984

Epoch: 335| Step: 0
Training loss: 0.4131595492362976
Validation loss: 1.8353102719911965

Epoch: 6| Step: 1
Training loss: 0.4353227913379669
Validation loss: 1.841190835481049

Epoch: 6| Step: 2
Training loss: 0.5460284948348999
Validation loss: 1.8488933463250437

Epoch: 6| Step: 3
Training loss: 0.3685307502746582
Validation loss: 1.8470403763555712

Epoch: 6| Step: 4
Training loss: 0.5463383793830872
Validation loss: 1.8377277742150009

Epoch: 6| Step: 5
Training loss: 0.34340545535087585
Validation loss: 1.8314842139520953

Epoch: 6| Step: 6
Training loss: 0.39711588621139526
Validation loss: 1.8436724011616041

Epoch: 6| Step: 7
Training loss: 0.4873369336128235
Validation loss: 1.8197713680164789

Epoch: 6| Step: 8
Training loss: 0.7602307200431824
Validation loss: 1.833990422628259

Epoch: 6| Step: 9
Training loss: 0.31274276971817017
Validation loss: 1.830938958352612

Epoch: 6| Step: 10
Training loss: 0.45026177167892456
Validation loss: 1.806149322499511

Epoch: 6| Step: 11
Training loss: 0.2410389482975006
Validation loss: 1.819340585380472

Epoch: 6| Step: 12
Training loss: 0.4865293502807617
Validation loss: 1.8093148111015238

Epoch: 6| Step: 13
Training loss: 0.29828765988349915
Validation loss: 1.8408853956448135

Epoch: 336| Step: 0
Training loss: 0.7862282991409302
Validation loss: 1.8228342187020086

Epoch: 6| Step: 1
Training loss: 0.560096263885498
Validation loss: 1.8152162656989148

Epoch: 6| Step: 2
Training loss: 0.4782617390155792
Validation loss: 1.8133222133882585

Epoch: 6| Step: 3
Training loss: 0.37131011486053467
Validation loss: 1.7984093478930894

Epoch: 6| Step: 4
Training loss: 0.39927810430526733
Validation loss: 1.7956597574295536

Epoch: 6| Step: 5
Training loss: 0.3723639249801636
Validation loss: 1.7839523028301936

Epoch: 6| Step: 6
Training loss: 0.28537848591804504
Validation loss: 1.8010263417356758

Epoch: 6| Step: 7
Training loss: 0.395365834236145
Validation loss: 1.793679291202176

Epoch: 6| Step: 8
Training loss: 0.443509966135025
Validation loss: 1.8148055871327717

Epoch: 6| Step: 9
Training loss: 0.26257359981536865
Validation loss: 1.8236601775692356

Epoch: 6| Step: 10
Training loss: 0.3557017743587494
Validation loss: 1.808059505237046

Epoch: 6| Step: 11
Training loss: 0.5542815923690796
Validation loss: 1.8225747436605475

Epoch: 6| Step: 12
Training loss: 0.21915435791015625
Validation loss: 1.8107846808689896

Epoch: 6| Step: 13
Training loss: 0.5038584470748901
Validation loss: 1.790435221887404

Epoch: 337| Step: 0
Training loss: 0.37342530488967896
Validation loss: 1.7932216839123798

Epoch: 6| Step: 1
Training loss: 0.6070702075958252
Validation loss: 1.7942425589407645

Epoch: 6| Step: 2
Training loss: 0.6704272031784058
Validation loss: 1.7920488554944274

Epoch: 6| Step: 3
Training loss: 0.3619031310081482
Validation loss: 1.7662474686099636

Epoch: 6| Step: 4
Training loss: 0.30518320202827454
Validation loss: 1.7798172927671863

Epoch: 6| Step: 5
Training loss: 0.19069695472717285
Validation loss: 1.814223011334737

Epoch: 6| Step: 6
Training loss: 0.6309199929237366
Validation loss: 1.7909345191012147

Epoch: 6| Step: 7
Training loss: 0.3324889540672302
Validation loss: 1.8198191350506199

Epoch: 6| Step: 8
Training loss: 0.18012258410453796
Validation loss: 1.7811058849416754

Epoch: 6| Step: 9
Training loss: 0.3708445727825165
Validation loss: 1.7908638100470267

Epoch: 6| Step: 10
Training loss: 0.5567131042480469
Validation loss: 1.8042405100278958

Epoch: 6| Step: 11
Training loss: 0.31819361448287964
Validation loss: 1.7573066475570842

Epoch: 6| Step: 12
Training loss: 0.2449800670146942
Validation loss: 1.7730202854320567

Epoch: 6| Step: 13
Training loss: 0.6896078586578369
Validation loss: 1.8069818558231476

Epoch: 338| Step: 0
Training loss: 0.6174544095993042
Validation loss: 1.7860740794930408

Epoch: 6| Step: 1
Training loss: 0.507988691329956
Validation loss: 1.7992288399768133

Epoch: 6| Step: 2
Training loss: 0.30478066205978394
Validation loss: 1.8201344115759737

Epoch: 6| Step: 3
Training loss: 0.09796357899904251
Validation loss: 1.8074556012307443

Epoch: 6| Step: 4
Training loss: 0.6295512318611145
Validation loss: 1.8207981419819657

Epoch: 6| Step: 5
Training loss: 0.3006106913089752
Validation loss: 1.8185493997348252

Epoch: 6| Step: 6
Training loss: 0.402696430683136
Validation loss: 1.8152201406417354

Epoch: 6| Step: 7
Training loss: 0.31502193212509155
Validation loss: 1.7776730111850205

Epoch: 6| Step: 8
Training loss: 0.6722139120101929
Validation loss: 1.8040833960297287

Epoch: 6| Step: 9
Training loss: 0.40253180265426636
Validation loss: 1.8212262917590398

Epoch: 6| Step: 10
Training loss: 0.3242189288139343
Validation loss: 1.7926977449847805

Epoch: 6| Step: 11
Training loss: 0.34192755818367004
Validation loss: 1.8155335303275817

Epoch: 6| Step: 12
Training loss: 0.4805987775325775
Validation loss: 1.7861137954137658

Epoch: 6| Step: 13
Training loss: 0.19361822307109833
Validation loss: 1.7744292738617107

Epoch: 339| Step: 0
Training loss: 0.4326976239681244
Validation loss: 1.7898656168291647

Epoch: 6| Step: 1
Training loss: 0.367412805557251
Validation loss: 1.7755931974739156

Epoch: 6| Step: 2
Training loss: 0.31230077147483826
Validation loss: 1.7948216225511284

Epoch: 6| Step: 3
Training loss: 0.5415338277816772
Validation loss: 1.7987557688067037

Epoch: 6| Step: 4
Training loss: 0.4780254364013672
Validation loss: 1.818402717190404

Epoch: 6| Step: 5
Training loss: 0.5459398031234741
Validation loss: 1.817535977209768

Epoch: 6| Step: 6
Training loss: 0.3652348518371582
Validation loss: 1.8347457108959075

Epoch: 6| Step: 7
Training loss: 0.2063734531402588
Validation loss: 1.832087432184527

Epoch: 6| Step: 8
Training loss: 0.4524441957473755
Validation loss: 1.8277391336297477

Epoch: 6| Step: 9
Training loss: 0.3029913306236267
Validation loss: 1.8173658988809074

Epoch: 6| Step: 10
Training loss: 0.2355598360300064
Validation loss: 1.808491627375285

Epoch: 6| Step: 11
Training loss: 0.4888986051082611
Validation loss: 1.8061035871505737

Epoch: 6| Step: 12
Training loss: 0.6722564101219177
Validation loss: 1.8129744375905683

Epoch: 6| Step: 13
Training loss: 0.4624985456466675
Validation loss: 1.8158866820796844

Epoch: 340| Step: 0
Training loss: 0.35875776410102844
Validation loss: 1.8247587937180714

Epoch: 6| Step: 1
Training loss: 0.24137753248214722
Validation loss: 1.8312432612142255

Epoch: 6| Step: 2
Training loss: 0.5264929533004761
Validation loss: 1.8333837870628602

Epoch: 6| Step: 3
Training loss: 0.3445761203765869
Validation loss: 1.8100007528899817

Epoch: 6| Step: 4
Training loss: 0.3697294592857361
Validation loss: 1.840171020518067

Epoch: 6| Step: 5
Training loss: 0.2847099304199219
Validation loss: 1.8405230609319543

Epoch: 6| Step: 6
Training loss: 0.43150192499160767
Validation loss: 1.8524958715643933

Epoch: 6| Step: 7
Training loss: 0.546384334564209
Validation loss: 1.8354490104541983

Epoch: 6| Step: 8
Training loss: 0.2537052035331726
Validation loss: 1.820424090149582

Epoch: 6| Step: 9
Training loss: 0.40242546796798706
Validation loss: 1.798920053307728

Epoch: 6| Step: 10
Training loss: 0.22429674863815308
Validation loss: 1.8265806821084791

Epoch: 6| Step: 11
Training loss: 0.775812029838562
Validation loss: 1.8128785369216756

Epoch: 6| Step: 12
Training loss: 0.4833301305770874
Validation loss: 1.8198135514413156

Epoch: 6| Step: 13
Training loss: 0.7563063502311707
Validation loss: 1.8184410083678462

Epoch: 341| Step: 0
Training loss: 0.5032691955566406
Validation loss: 1.7826082014268445

Epoch: 6| Step: 1
Training loss: 0.5697992444038391
Validation loss: 1.7572298934382777

Epoch: 6| Step: 2
Training loss: 0.4083121418952942
Validation loss: 1.7886076870784964

Epoch: 6| Step: 3
Training loss: 0.26400458812713623
Validation loss: 1.7908812838215982

Epoch: 6| Step: 4
Training loss: 0.5077347755432129
Validation loss: 1.7828176713758899

Epoch: 6| Step: 5
Training loss: 0.454598993062973
Validation loss: 1.7767787428312405

Epoch: 6| Step: 6
Training loss: 0.29200172424316406
Validation loss: 1.790685902359665

Epoch: 6| Step: 7
Training loss: 0.40661755204200745
Validation loss: 1.7683071961966894

Epoch: 6| Step: 8
Training loss: 0.27183961868286133
Validation loss: 1.799542647536083

Epoch: 6| Step: 9
Training loss: 0.43272665143013
Validation loss: 1.7869910527301092

Epoch: 6| Step: 10
Training loss: 0.3120439648628235
Validation loss: 1.786683872181882

Epoch: 6| Step: 11
Training loss: 0.43299973011016846
Validation loss: 1.8365202321801135

Epoch: 6| Step: 12
Training loss: 0.4222194254398346
Validation loss: 1.7965129665149155

Epoch: 6| Step: 13
Training loss: 0.39357906579971313
Validation loss: 1.7827381754434237

Epoch: 342| Step: 0
Training loss: 0.16543419659137726
Validation loss: 1.8114432340027184

Epoch: 6| Step: 1
Training loss: 0.4677971601486206
Validation loss: 1.8037275511731383

Epoch: 6| Step: 2
Training loss: 0.337420254945755
Validation loss: 1.8159295974239227

Epoch: 6| Step: 3
Training loss: 0.4116765260696411
Validation loss: 1.7935834930789085

Epoch: 6| Step: 4
Training loss: 0.5837426781654358
Validation loss: 1.7983371186000046

Epoch: 6| Step: 5
Training loss: 0.35764846205711365
Validation loss: 1.8024810603869859

Epoch: 6| Step: 6
Training loss: 0.24952423572540283
Validation loss: 1.7783387258488645

Epoch: 6| Step: 7
Training loss: 0.36199697852134705
Validation loss: 1.7606200620692263

Epoch: 6| Step: 8
Training loss: 0.891527533531189
Validation loss: 1.7630279564088391

Epoch: 6| Step: 9
Training loss: 0.22048692405223846
Validation loss: 1.7692433672566568

Epoch: 6| Step: 10
Training loss: 0.2839469313621521
Validation loss: 1.7688499202010453

Epoch: 6| Step: 11
Training loss: 0.48088324069976807
Validation loss: 1.7574446842234621

Epoch: 6| Step: 12
Training loss: 0.3153148293495178
Validation loss: 1.7615720828374226

Epoch: 6| Step: 13
Training loss: 0.29775869846343994
Validation loss: 1.7705046963948075

Epoch: 343| Step: 0
Training loss: 0.5235400199890137
Validation loss: 1.7914028539452502

Epoch: 6| Step: 1
Training loss: 0.45187634229660034
Validation loss: 1.8197050658605431

Epoch: 6| Step: 2
Training loss: 0.49336105585098267
Validation loss: 1.8089897632598877

Epoch: 6| Step: 3
Training loss: 0.30178555846214294
Validation loss: 1.810063931249803

Epoch: 6| Step: 4
Training loss: 0.3002360761165619
Validation loss: 1.8152644249700731

Epoch: 6| Step: 5
Training loss: 0.25432127714157104
Validation loss: 1.7869005587793165

Epoch: 6| Step: 6
Training loss: 0.2900528013706207
Validation loss: 1.7874852585536178

Epoch: 6| Step: 7
Training loss: 0.25623980164527893
Validation loss: 1.7804156439278715

Epoch: 6| Step: 8
Training loss: 0.4794713258743286
Validation loss: 1.7839605346802743

Epoch: 6| Step: 9
Training loss: 0.23193421959877014
Validation loss: 1.7564648274452455

Epoch: 6| Step: 10
Training loss: 0.5895733833312988
Validation loss: 1.721846785596622

Epoch: 6| Step: 11
Training loss: 0.808425784111023
Validation loss: 1.7397129907402942

Epoch: 6| Step: 12
Training loss: 0.24291253089904785
Validation loss: 1.7529618406808505

Epoch: 6| Step: 13
Training loss: 0.6375277042388916
Validation loss: 1.736198697038876

Epoch: 344| Step: 0
Training loss: 0.2594248652458191
Validation loss: 1.7808819188866565

Epoch: 6| Step: 1
Training loss: 0.5272605419158936
Validation loss: 1.7599927891967118

Epoch: 6| Step: 2
Training loss: 0.3911445736885071
Validation loss: 1.789398189513914

Epoch: 6| Step: 3
Training loss: 0.46139389276504517
Validation loss: 1.8141722973956858

Epoch: 6| Step: 4
Training loss: 0.6507694721221924
Validation loss: 1.7951605037976337

Epoch: 6| Step: 5
Training loss: 0.3896646797657013
Validation loss: 1.827435713942333

Epoch: 6| Step: 6
Training loss: 0.3235115706920624
Validation loss: 1.8079048536157096

Epoch: 6| Step: 7
Training loss: 0.43343862891197205
Validation loss: 1.8191194918847853

Epoch: 6| Step: 8
Training loss: 0.34852439165115356
Validation loss: 1.7972713811423189

Epoch: 6| Step: 9
Training loss: 0.2394818365573883
Validation loss: 1.8158025190394411

Epoch: 6| Step: 10
Training loss: 0.5366417765617371
Validation loss: 1.8468489364911151

Epoch: 6| Step: 11
Training loss: 0.5477638840675354
Validation loss: 1.8174303718792495

Epoch: 6| Step: 12
Training loss: 0.26123589277267456
Validation loss: 1.7730909765407603

Epoch: 6| Step: 13
Training loss: 0.4673832356929779
Validation loss: 1.770604500206568

Epoch: 345| Step: 0
Training loss: 0.3985733389854431
Validation loss: 1.7695069723231818

Epoch: 6| Step: 1
Training loss: 0.22323070466518402
Validation loss: 1.7764579583239812

Epoch: 6| Step: 2
Training loss: 0.25723204016685486
Validation loss: 1.7855544654271935

Epoch: 6| Step: 3
Training loss: 0.3803500533103943
Validation loss: 1.769363937839385

Epoch: 6| Step: 4
Training loss: 0.2657657563686371
Validation loss: 1.7925104569363337

Epoch: 6| Step: 5
Training loss: 0.6146295666694641
Validation loss: 1.7711708981503722

Epoch: 6| Step: 6
Training loss: 0.3647816777229309
Validation loss: 1.7768608011225218

Epoch: 6| Step: 7
Training loss: 0.5584458112716675
Validation loss: 1.7929116987412976

Epoch: 6| Step: 8
Training loss: 0.3928598165512085
Validation loss: 1.8384535876653527

Epoch: 6| Step: 9
Training loss: 0.8024768829345703
Validation loss: 1.8529960891251922

Epoch: 6| Step: 10
Training loss: 0.6103998422622681
Validation loss: 1.8832186806586482

Epoch: 6| Step: 11
Training loss: 0.2691720724105835
Validation loss: 1.885817789262341

Epoch: 6| Step: 12
Training loss: 0.4501761794090271
Validation loss: 1.8961549087237286

Epoch: 6| Step: 13
Training loss: 0.4845046401023865
Validation loss: 1.8954417859354327

Epoch: 346| Step: 0
Training loss: 0.47432848811149597
Validation loss: 1.897756766247493

Epoch: 6| Step: 1
Training loss: 0.5963364243507385
Validation loss: 1.8794874222047868

Epoch: 6| Step: 2
Training loss: 0.5267124176025391
Validation loss: 1.86362708896719

Epoch: 6| Step: 3
Training loss: 0.42331576347351074
Validation loss: 1.8324876312286622

Epoch: 6| Step: 4
Training loss: 0.7351981401443481
Validation loss: 1.8070720626461891

Epoch: 6| Step: 5
Training loss: 0.5022896528244019
Validation loss: 1.825630977589597

Epoch: 6| Step: 6
Training loss: 0.9627975225448608
Validation loss: 1.7823304053275817

Epoch: 6| Step: 7
Training loss: 0.3252434730529785
Validation loss: 1.793435417195802

Epoch: 6| Step: 8
Training loss: 0.49952319264411926
Validation loss: 1.7935761636303318

Epoch: 6| Step: 9
Training loss: 0.4016207456588745
Validation loss: 1.8217174007046608

Epoch: 6| Step: 10
Training loss: 0.430747389793396
Validation loss: 1.8443948761109383

Epoch: 6| Step: 11
Training loss: 0.4250878691673279
Validation loss: 1.8255641127145419

Epoch: 6| Step: 12
Training loss: 0.4521006941795349
Validation loss: 1.7984005943421395

Epoch: 6| Step: 13
Training loss: 0.1891624927520752
Validation loss: 1.8044743012356501

Epoch: 347| Step: 0
Training loss: 0.5132526755332947
Validation loss: 1.7977154972732707

Epoch: 6| Step: 1
Training loss: 0.3883611857891083
Validation loss: 1.7627555349821686

Epoch: 6| Step: 2
Training loss: 0.5240684747695923
Validation loss: 1.7791002309450539

Epoch: 6| Step: 3
Training loss: 0.4021727442741394
Validation loss: 1.786979534933644

Epoch: 6| Step: 4
Training loss: 0.330096036195755
Validation loss: 1.8109644600140151

Epoch: 6| Step: 5
Training loss: 0.43709373474121094
Validation loss: 1.846231509280461

Epoch: 6| Step: 6
Training loss: 0.46260136365890503
Validation loss: 1.8068245546792143

Epoch: 6| Step: 7
Training loss: 0.8477978706359863
Validation loss: 1.8321040830304545

Epoch: 6| Step: 8
Training loss: 0.17456524074077606
Validation loss: 1.8190781442067956

Epoch: 6| Step: 9
Training loss: 0.327199250459671
Validation loss: 1.8327414066560808

Epoch: 6| Step: 10
Training loss: 0.42070966958999634
Validation loss: 1.8304556262108587

Epoch: 6| Step: 11
Training loss: 0.4670296311378479
Validation loss: 1.8248560543983214

Epoch: 6| Step: 12
Training loss: 0.41892582178115845
Validation loss: 1.8327856038206367

Epoch: 6| Step: 13
Training loss: 0.2397211641073227
Validation loss: 1.795122564479869

Epoch: 348| Step: 0
Training loss: 0.4001883268356323
Validation loss: 1.7849997512755855

Epoch: 6| Step: 1
Training loss: 0.19951564073562622
Validation loss: 1.7801062150668072

Epoch: 6| Step: 2
Training loss: 0.4412161111831665
Validation loss: 1.7913848841062157

Epoch: 6| Step: 3
Training loss: 0.37410494685173035
Validation loss: 1.789274546407884

Epoch: 6| Step: 4
Training loss: 0.47287487983703613
Validation loss: 1.770631036450786

Epoch: 6| Step: 5
Training loss: 0.4681016802787781
Validation loss: 1.7658783953676942

Epoch: 6| Step: 6
Training loss: 0.30835095047950745
Validation loss: 1.7403390933108587

Epoch: 6| Step: 7
Training loss: 0.9088761806488037
Validation loss: 1.7615159455166067

Epoch: 6| Step: 8
Training loss: 0.42790281772613525
Validation loss: 1.7639506939918763

Epoch: 6| Step: 9
Training loss: 0.2793329358100891
Validation loss: 1.7934941719937068

Epoch: 6| Step: 10
Training loss: 0.3203745484352112
Validation loss: 1.7968628316797235

Epoch: 6| Step: 11
Training loss: 0.1338750720024109
Validation loss: 1.7727065714456702

Epoch: 6| Step: 12
Training loss: 0.3039926290512085
Validation loss: 1.7859061174495245

Epoch: 6| Step: 13
Training loss: 0.3368188738822937
Validation loss: 1.77851233302906

Epoch: 349| Step: 0
Training loss: 0.3056783974170685
Validation loss: 1.7773047762532388

Epoch: 6| Step: 1
Training loss: 0.5491898655891418
Validation loss: 1.789549304592994

Epoch: 6| Step: 2
Training loss: 0.33198821544647217
Validation loss: 1.7538792369186238

Epoch: 6| Step: 3
Training loss: 0.7499606609344482
Validation loss: 1.7879745780780751

Epoch: 6| Step: 4
Training loss: 0.4157344698905945
Validation loss: 1.7656551368774906

Epoch: 6| Step: 5
Training loss: 0.2872125506401062
Validation loss: 1.7752607419926634

Epoch: 6| Step: 6
Training loss: 0.3541752099990845
Validation loss: 1.8028530074704079

Epoch: 6| Step: 7
Training loss: 0.5026085376739502
Validation loss: 1.8334304581406295

Epoch: 6| Step: 8
Training loss: 0.4320718050003052
Validation loss: 1.843529667905582

Epoch: 6| Step: 9
Training loss: 0.42978426814079285
Validation loss: 1.8030087768390615

Epoch: 6| Step: 10
Training loss: 0.23904204368591309
Validation loss: 1.793785511806447

Epoch: 6| Step: 11
Training loss: 0.3754320740699768
Validation loss: 1.7837869877456336

Epoch: 6| Step: 12
Training loss: 0.3444344401359558
Validation loss: 1.775369200655209

Epoch: 6| Step: 13
Training loss: 0.2658657431602478
Validation loss: 1.7634392258941487

Epoch: 350| Step: 0
Training loss: 0.3471909463405609
Validation loss: 1.7773021498034078

Epoch: 6| Step: 1
Training loss: 0.3977254629135132
Validation loss: 1.7799366084478234

Epoch: 6| Step: 2
Training loss: 0.33365732431411743
Validation loss: 1.8293463491624402

Epoch: 6| Step: 3
Training loss: 0.2929309904575348
Validation loss: 1.7932148941101567

Epoch: 6| Step: 4
Training loss: 0.6435450911521912
Validation loss: 1.8118394818357242

Epoch: 6| Step: 5
Training loss: 0.2607853412628174
Validation loss: 1.7968527309356197

Epoch: 6| Step: 6
Training loss: 0.4752768576145172
Validation loss: 1.7748123984183035

Epoch: 6| Step: 7
Training loss: 0.15606075525283813
Validation loss: 1.8016884762753722

Epoch: 6| Step: 8
Training loss: 0.23090851306915283
Validation loss: 1.7964679207853091

Epoch: 6| Step: 9
Training loss: 0.2574172019958496
Validation loss: 1.7927456658373597

Epoch: 6| Step: 10
Training loss: 0.7136939764022827
Validation loss: 1.7929763576035858

Epoch: 6| Step: 11
Training loss: 0.2002643644809723
Validation loss: 1.7751400804006925

Epoch: 6| Step: 12
Training loss: 0.336254358291626
Validation loss: 1.7819930321426802

Epoch: 6| Step: 13
Training loss: 0.3389633893966675
Validation loss: 1.773335220993206

Epoch: 351| Step: 0
Training loss: 0.2695615291595459
Validation loss: 1.7691972524889055

Epoch: 6| Step: 1
Training loss: 0.36785879731178284
Validation loss: 1.7766053804787256

Epoch: 6| Step: 2
Training loss: 0.25556835532188416
Validation loss: 1.791221377670124

Epoch: 6| Step: 3
Training loss: 0.398410439491272
Validation loss: 1.8063467946103824

Epoch: 6| Step: 4
Training loss: 0.3373110890388489
Validation loss: 1.8297442505436559

Epoch: 6| Step: 5
Training loss: 0.2970181107521057
Validation loss: 1.8316999532843148

Epoch: 6| Step: 6
Training loss: 0.7243074774742126
Validation loss: 1.8365408502599245

Epoch: 6| Step: 7
Training loss: 0.5107424855232239
Validation loss: 1.8037431445173038

Epoch: 6| Step: 8
Training loss: 0.46790510416030884
Validation loss: 1.7840467691421509

Epoch: 6| Step: 9
Training loss: 0.2980877161026001
Validation loss: 1.7967356610041794

Epoch: 6| Step: 10
Training loss: 0.2538672983646393
Validation loss: 1.7952369925796345

Epoch: 6| Step: 11
Training loss: 0.5647870898246765
Validation loss: 1.7661617981490267

Epoch: 6| Step: 12
Training loss: 0.15465906262397766
Validation loss: 1.768483813090991

Epoch: 6| Step: 13
Training loss: 0.32008668780326843
Validation loss: 1.761279231758528

Epoch: 352| Step: 0
Training loss: 0.4157675504684448
Validation loss: 1.7782075558939288

Epoch: 6| Step: 1
Training loss: 0.6856124401092529
Validation loss: 1.769461331828948

Epoch: 6| Step: 2
Training loss: 0.23718445003032684
Validation loss: 1.7486196487180647

Epoch: 6| Step: 3
Training loss: 0.4172927737236023
Validation loss: 1.7500272335544709

Epoch: 6| Step: 4
Training loss: 0.39213669300079346
Validation loss: 1.7875981125780331

Epoch: 6| Step: 5
Training loss: 0.24653419852256775
Validation loss: 1.776405426763719

Epoch: 6| Step: 6
Training loss: 0.4521391689777374
Validation loss: 1.8107811584267566

Epoch: 6| Step: 7
Training loss: 0.294828861951828
Validation loss: 1.7847329826765164

Epoch: 6| Step: 8
Training loss: 0.45609742403030396
Validation loss: 1.8086951035325245

Epoch: 6| Step: 9
Training loss: 0.4176180362701416
Validation loss: 1.7572254186035485

Epoch: 6| Step: 10
Training loss: 0.3283825218677521
Validation loss: 1.74345197216157

Epoch: 6| Step: 11
Training loss: 0.30373188853263855
Validation loss: 1.7552470071341402

Epoch: 6| Step: 12
Training loss: 0.26578062772750854
Validation loss: 1.7554991040178525

Epoch: 6| Step: 13
Training loss: 0.13782840967178345
Validation loss: 1.7129442717439385

Epoch: 353| Step: 0
Training loss: 0.38229238986968994
Validation loss: 1.7101854124376852

Epoch: 6| Step: 1
Training loss: 0.4976545572280884
Validation loss: 1.7155745285813526

Epoch: 6| Step: 2
Training loss: 0.3475656509399414
Validation loss: 1.7000495054388558

Epoch: 6| Step: 3
Training loss: 0.3759695291519165
Validation loss: 1.7547048599489274

Epoch: 6| Step: 4
Training loss: 0.24935230612754822
Validation loss: 1.7693278751065653

Epoch: 6| Step: 5
Training loss: 0.6629048585891724
Validation loss: 1.7255215811473068

Epoch: 6| Step: 6
Training loss: 0.5550915002822876
Validation loss: 1.738761858273578

Epoch: 6| Step: 7
Training loss: 0.2258869707584381
Validation loss: 1.780686616897583

Epoch: 6| Step: 8
Training loss: 0.46792522072792053
Validation loss: 1.7919915491534817

Epoch: 6| Step: 9
Training loss: 0.3866526186466217
Validation loss: 1.7972517667278167

Epoch: 6| Step: 10
Training loss: 0.4139106273651123
Validation loss: 1.7981456671991656

Epoch: 6| Step: 11
Training loss: 0.39552438259124756
Validation loss: 1.7927324079698133

Epoch: 6| Step: 12
Training loss: 0.15058398246765137
Validation loss: 1.7842745588671776

Epoch: 6| Step: 13
Training loss: 0.641040563583374
Validation loss: 1.773135604396943

Epoch: 354| Step: 0
Training loss: 0.36606743931770325
Validation loss: 1.7848899672108312

Epoch: 6| Step: 1
Training loss: 0.2589450478553772
Validation loss: 1.78459571894779

Epoch: 6| Step: 2
Training loss: 0.2881624698638916
Validation loss: 1.7553006160643794

Epoch: 6| Step: 3
Training loss: 0.34078145027160645
Validation loss: 1.7546855967531922

Epoch: 6| Step: 4
Training loss: 0.4220663011074066
Validation loss: 1.746181768755759

Epoch: 6| Step: 5
Training loss: 0.3827391266822815
Validation loss: 1.7616401641599593

Epoch: 6| Step: 6
Training loss: 0.1985897570848465
Validation loss: 1.7456077068082747

Epoch: 6| Step: 7
Training loss: 0.37304359674453735
Validation loss: 1.7793058003148725

Epoch: 6| Step: 8
Training loss: 0.7070707082748413
Validation loss: 1.7662113225588234

Epoch: 6| Step: 9
Training loss: 0.508384108543396
Validation loss: 1.8095722480486798

Epoch: 6| Step: 10
Training loss: 0.5251492857933044
Validation loss: 1.8119182599488126

Epoch: 6| Step: 11
Training loss: 0.3455493450164795
Validation loss: 1.7790550249879078

Epoch: 6| Step: 12
Training loss: 0.29548174142837524
Validation loss: 1.7915513726972765

Epoch: 6| Step: 13
Training loss: 0.550512433052063
Validation loss: 1.8005958218728342

Epoch: 355| Step: 0
Training loss: 0.49941831827163696
Validation loss: 1.794935610986525

Epoch: 6| Step: 1
Training loss: 0.31279000639915466
Validation loss: 1.7793579114380704

Epoch: 6| Step: 2
Training loss: 0.35725119709968567
Validation loss: 1.7954518051557644

Epoch: 6| Step: 3
Training loss: 0.6854465007781982
Validation loss: 1.7502869636781755

Epoch: 6| Step: 4
Training loss: 0.30143702030181885
Validation loss: 1.75019028622617

Epoch: 6| Step: 5
Training loss: 0.32563167810440063
Validation loss: 1.737885917386701

Epoch: 6| Step: 6
Training loss: 0.2157621681690216
Validation loss: 1.7665963685640724

Epoch: 6| Step: 7
Training loss: 0.5887212753295898
Validation loss: 1.7807216272559216

Epoch: 6| Step: 8
Training loss: 0.4187113046646118
Validation loss: 1.8004229812211887

Epoch: 6| Step: 9
Training loss: 0.3296564817428589
Validation loss: 1.7959989950221071

Epoch: 6| Step: 10
Training loss: 0.5793564319610596
Validation loss: 1.7599994085168327

Epoch: 6| Step: 11
Training loss: 0.2812294661998749
Validation loss: 1.7464419077801447

Epoch: 6| Step: 12
Training loss: 0.2218588888645172
Validation loss: 1.7598758794928109

Epoch: 6| Step: 13
Training loss: 0.26387155055999756
Validation loss: 1.80684369866566

Epoch: 356| Step: 0
Training loss: 0.47897621989250183
Validation loss: 1.804497508592503

Epoch: 6| Step: 1
Training loss: 0.4845266342163086
Validation loss: 1.7702361486291374

Epoch: 6| Step: 2
Training loss: 0.5411838889122009
Validation loss: 1.7896169821421306

Epoch: 6| Step: 3
Training loss: 0.4022131562232971
Validation loss: 1.798644478603076

Epoch: 6| Step: 4
Training loss: 0.4650319218635559
Validation loss: 1.836149792517385

Epoch: 6| Step: 5
Training loss: 0.437644362449646
Validation loss: 1.864672842846122

Epoch: 6| Step: 6
Training loss: 0.47535255551338196
Validation loss: 1.8352153544784875

Epoch: 6| Step: 7
Training loss: 0.3153105080127716
Validation loss: 1.8165915691724388

Epoch: 6| Step: 8
Training loss: 0.24247150123119354
Validation loss: 1.8016978284364105

Epoch: 6| Step: 9
Training loss: 0.3669428825378418
Validation loss: 1.7643574540333082

Epoch: 6| Step: 10
Training loss: 0.29383182525634766
Validation loss: 1.75361164410909

Epoch: 6| Step: 11
Training loss: 0.29328304529190063
Validation loss: 1.739747106388051

Epoch: 6| Step: 12
Training loss: 0.3483874797821045
Validation loss: 1.770209316284426

Epoch: 6| Step: 13
Training loss: 0.3386755585670471
Validation loss: 1.7266057998903337

Epoch: 357| Step: 0
Training loss: 0.18696290254592896
Validation loss: 1.7480761748488232

Epoch: 6| Step: 1
Training loss: 0.3098480999469757
Validation loss: 1.7655128945586502

Epoch: 6| Step: 2
Training loss: 0.22035878896713257
Validation loss: 1.7597780689116447

Epoch: 6| Step: 3
Training loss: 0.42067408561706543
Validation loss: 1.7869984488333426

Epoch: 6| Step: 4
Training loss: 0.283957302570343
Validation loss: 1.7560040476501628

Epoch: 6| Step: 5
Training loss: 0.21279166638851166
Validation loss: 1.765774521776425

Epoch: 6| Step: 6
Training loss: 0.5197079181671143
Validation loss: 1.7794438985086256

Epoch: 6| Step: 7
Training loss: 0.4275836944580078
Validation loss: 1.770525663129745

Epoch: 6| Step: 8
Training loss: 0.2995224595069885
Validation loss: 1.7856428661654073

Epoch: 6| Step: 9
Training loss: 0.47785839438438416
Validation loss: 1.7970001389903407

Epoch: 6| Step: 10
Training loss: 0.4382658004760742
Validation loss: 1.7955244523222729

Epoch: 6| Step: 11
Training loss: 0.24607598781585693
Validation loss: 1.7777276936397757

Epoch: 6| Step: 12
Training loss: 0.5994192361831665
Validation loss: 1.765062903845182

Epoch: 6| Step: 13
Training loss: 0.46972528100013733
Validation loss: 1.757266984190992

Epoch: 358| Step: 0
Training loss: 0.2224251925945282
Validation loss: 1.7349035842444307

Epoch: 6| Step: 1
Training loss: 0.4022279977798462
Validation loss: 1.7359139560371317

Epoch: 6| Step: 2
Training loss: 0.5803985595703125
Validation loss: 1.756530938609954

Epoch: 6| Step: 3
Training loss: 0.26711732149124146
Validation loss: 1.7777524699446976

Epoch: 6| Step: 4
Training loss: 0.3002129793167114
Validation loss: 1.7829617909205857

Epoch: 6| Step: 5
Training loss: 0.25741273164749146
Validation loss: 1.7615878351273075

Epoch: 6| Step: 6
Training loss: 0.18028324842453003
Validation loss: 1.741647453718288

Epoch: 6| Step: 7
Training loss: 0.2228773832321167
Validation loss: 1.7357593595340688

Epoch: 6| Step: 8
Training loss: 0.382832407951355
Validation loss: 1.72084375222524

Epoch: 6| Step: 9
Training loss: 0.2914259433746338
Validation loss: 1.7430081188037831

Epoch: 6| Step: 10
Training loss: 0.3168676495552063
Validation loss: 1.752916282223117

Epoch: 6| Step: 11
Training loss: 0.3269008994102478
Validation loss: 1.7228330335309427

Epoch: 6| Step: 12
Training loss: 0.6312062740325928
Validation loss: 1.7573733663046232

Epoch: 6| Step: 13
Training loss: 0.4975697100162506
Validation loss: 1.7616954593248264

Epoch: 359| Step: 0
Training loss: 0.33062994480133057
Validation loss: 1.754834064873316

Epoch: 6| Step: 1
Training loss: 0.23006045818328857
Validation loss: 1.75151474501497

Epoch: 6| Step: 2
Training loss: 0.32912546396255493
Validation loss: 1.7216822716497606

Epoch: 6| Step: 3
Training loss: 0.31951904296875
Validation loss: 1.7079508625051028

Epoch: 6| Step: 4
Training loss: 0.1867964267730713
Validation loss: 1.7543272638833651

Epoch: 6| Step: 5
Training loss: 0.34296125173568726
Validation loss: 1.750730659372063

Epoch: 6| Step: 6
Training loss: 0.2545890808105469
Validation loss: 1.7513528831543461

Epoch: 6| Step: 7
Training loss: 0.14720727503299713
Validation loss: 1.746902564520477

Epoch: 6| Step: 8
Training loss: 0.32718074321746826
Validation loss: 1.737208604812622

Epoch: 6| Step: 9
Training loss: 0.4131476879119873
Validation loss: 1.7449635985077068

Epoch: 6| Step: 10
Training loss: 0.3835400342941284
Validation loss: 1.7336070229930263

Epoch: 6| Step: 11
Training loss: 0.331723690032959
Validation loss: 1.7782484292984009

Epoch: 6| Step: 12
Training loss: 0.46672821044921875
Validation loss: 1.7832763816720696

Epoch: 6| Step: 13
Training loss: 0.734520673751831
Validation loss: 1.768095665080573

Epoch: 360| Step: 0
Training loss: 0.4141715168952942
Validation loss: 1.7620604474057433

Epoch: 6| Step: 1
Training loss: 0.34138938784599304
Validation loss: 1.7600724081839285

Epoch: 6| Step: 2
Training loss: 0.3758864998817444
Validation loss: 1.7395242696167321

Epoch: 6| Step: 3
Training loss: 0.1997697353363037
Validation loss: 1.7294390137477587

Epoch: 6| Step: 4
Training loss: 0.32288873195648193
Validation loss: 1.7244482360860354

Epoch: 6| Step: 5
Training loss: 0.2609585225582123
Validation loss: 1.7420830483077674

Epoch: 6| Step: 6
Training loss: 0.31098389625549316
Validation loss: 1.7637360352341847

Epoch: 6| Step: 7
Training loss: 0.126534104347229
Validation loss: 1.7261394851951188

Epoch: 6| Step: 8
Training loss: 0.2835603356361389
Validation loss: 1.7518470159140966

Epoch: 6| Step: 9
Training loss: 0.3288070559501648
Validation loss: 1.7761977552085795

Epoch: 6| Step: 10
Training loss: 0.5403061509132385
Validation loss: 1.7604892279512139

Epoch: 6| Step: 11
Training loss: 0.39542925357818604
Validation loss: 1.8009973290146037

Epoch: 6| Step: 12
Training loss: 0.3742232322692871
Validation loss: 1.7956003271123415

Epoch: 6| Step: 13
Training loss: 0.27040791511535645
Validation loss: 1.7961860946429673

Epoch: 361| Step: 0
Training loss: 0.5589095950126648
Validation loss: 1.776136552133868

Epoch: 6| Step: 1
Training loss: 0.20272991061210632
Validation loss: 1.7904285551399313

Epoch: 6| Step: 2
Training loss: 0.42592501640319824
Validation loss: 1.796377185852297

Epoch: 6| Step: 3
Training loss: 0.3063907027244568
Validation loss: 1.7566751882594118

Epoch: 6| Step: 4
Training loss: 0.16655300557613373
Validation loss: 1.7232992713169386

Epoch: 6| Step: 5
Training loss: 0.26927852630615234
Validation loss: 1.7449984435112245

Epoch: 6| Step: 6
Training loss: 0.465562641620636
Validation loss: 1.7381701777058263

Epoch: 6| Step: 7
Training loss: 0.4476024806499481
Validation loss: 1.6880579789479573

Epoch: 6| Step: 8
Training loss: 0.2842075824737549
Validation loss: 1.710826091868903

Epoch: 6| Step: 9
Training loss: 0.47902053594589233
Validation loss: 1.6919254795197518

Epoch: 6| Step: 10
Training loss: 0.2728155553340912
Validation loss: 1.7405693479763564

Epoch: 6| Step: 11
Training loss: 0.13576525449752808
Validation loss: 1.706730293971236

Epoch: 6| Step: 12
Training loss: 0.40241605043411255
Validation loss: 1.703236759349864

Epoch: 6| Step: 13
Training loss: 0.26340341567993164
Validation loss: 1.7027234031308083

Epoch: 362| Step: 0
Training loss: 0.2941020727157593
Validation loss: 1.6978521488046134

Epoch: 6| Step: 1
Training loss: 0.13137301802635193
Validation loss: 1.7169249493588683

Epoch: 6| Step: 2
Training loss: 0.2910713851451874
Validation loss: 1.7060371060525217

Epoch: 6| Step: 3
Training loss: 0.24138855934143066
Validation loss: 1.7352083600977415

Epoch: 6| Step: 4
Training loss: 0.31475216150283813
Validation loss: 1.7409716601012855

Epoch: 6| Step: 5
Training loss: 0.23717331886291504
Validation loss: 1.7267739131886473

Epoch: 6| Step: 6
Training loss: 0.18537381291389465
Validation loss: 1.7261702206826979

Epoch: 6| Step: 7
Training loss: 0.39862555265426636
Validation loss: 1.705333827644266

Epoch: 6| Step: 8
Training loss: 0.3221915066242218
Validation loss: 1.7085909010261617

Epoch: 6| Step: 9
Training loss: 0.37462419271469116
Validation loss: 1.7193859674597298

Epoch: 6| Step: 10
Training loss: 0.19281864166259766
Validation loss: 1.7142629687504103

Epoch: 6| Step: 11
Training loss: 0.18554839491844177
Validation loss: 1.7362755037123156

Epoch: 6| Step: 12
Training loss: 0.792740523815155
Validation loss: 1.7393559102089173

Epoch: 6| Step: 13
Training loss: 0.6223180294036865
Validation loss: 1.7581157261325466

Epoch: 363| Step: 0
Training loss: 0.2207663655281067
Validation loss: 1.7725341499492686

Epoch: 6| Step: 1
Training loss: 0.22580887377262115
Validation loss: 1.7148137425863614

Epoch: 6| Step: 2
Training loss: 0.47229334712028503
Validation loss: 1.7287622728655416

Epoch: 6| Step: 3
Training loss: 0.3876081705093384
Validation loss: 1.7323595234142837

Epoch: 6| Step: 4
Training loss: 0.20810258388519287
Validation loss: 1.7220860924772037

Epoch: 6| Step: 5
Training loss: 0.24675479531288147
Validation loss: 1.7170391774946643

Epoch: 6| Step: 6
Training loss: 0.48336225748062134
Validation loss: 1.720069742971851

Epoch: 6| Step: 7
Training loss: 0.2526741623878479
Validation loss: 1.7363935644908617

Epoch: 6| Step: 8
Training loss: 0.27543333172798157
Validation loss: 1.7466294086107643

Epoch: 6| Step: 9
Training loss: 0.4702123701572418
Validation loss: 1.754325920535672

Epoch: 6| Step: 10
Training loss: 0.2300454080104828
Validation loss: 1.7385721347665275

Epoch: 6| Step: 11
Training loss: 0.3164599537849426
Validation loss: 1.7736341620004306

Epoch: 6| Step: 12
Training loss: 0.21095791459083557
Validation loss: 1.78766280604947

Epoch: 6| Step: 13
Training loss: 0.41026803851127625
Validation loss: 1.7626373588397939

Epoch: 364| Step: 0
Training loss: 0.22527629137039185
Validation loss: 1.7615420190236901

Epoch: 6| Step: 1
Training loss: 0.23331725597381592
Validation loss: 1.7258295397604666

Epoch: 6| Step: 2
Training loss: 0.1710478961467743
Validation loss: 1.7644130388895671

Epoch: 6| Step: 3
Training loss: 0.3856879472732544
Validation loss: 1.751560595727736

Epoch: 6| Step: 4
Training loss: 0.4242878556251526
Validation loss: 1.7525242964426677

Epoch: 6| Step: 5
Training loss: 0.33854541182518005
Validation loss: 1.7735602868500577

Epoch: 6| Step: 6
Training loss: 0.4791593551635742
Validation loss: 1.741944090012581

Epoch: 6| Step: 7
Training loss: 0.34554070234298706
Validation loss: 1.7500603724551458

Epoch: 6| Step: 8
Training loss: 0.4029771089553833
Validation loss: 1.7720311277656144

Epoch: 6| Step: 9
Training loss: 0.5541657209396362
Validation loss: 1.7673572391592047

Epoch: 6| Step: 10
Training loss: 0.3723648190498352
Validation loss: 1.7794171187185472

Epoch: 6| Step: 11
Training loss: 0.2588798403739929
Validation loss: 1.7463452739100302

Epoch: 6| Step: 12
Training loss: 0.27205491065979004
Validation loss: 1.7707963592262679

Epoch: 6| Step: 13
Training loss: 0.29366791248321533
Validation loss: 1.7709435057896439

Epoch: 365| Step: 0
Training loss: 0.22896067798137665
Validation loss: 1.7522677516424527

Epoch: 6| Step: 1
Training loss: 0.348929762840271
Validation loss: 1.7267587261815225

Epoch: 6| Step: 2
Training loss: 0.23697009682655334
Validation loss: 1.7332936512526644

Epoch: 6| Step: 3
Training loss: 0.14018428325653076
Validation loss: 1.7046267114659792

Epoch: 6| Step: 4
Training loss: 0.22118732333183289
Validation loss: 1.7359637380928121

Epoch: 6| Step: 5
Training loss: 0.34475672245025635
Validation loss: 1.7325916046737342

Epoch: 6| Step: 6
Training loss: 0.3199577331542969
Validation loss: 1.7258507782413113

Epoch: 6| Step: 7
Training loss: 0.3322134017944336
Validation loss: 1.7247154046130437

Epoch: 6| Step: 8
Training loss: 0.39164021611213684
Validation loss: 1.7113279681051932

Epoch: 6| Step: 9
Training loss: 0.3226556181907654
Validation loss: 1.7221683225324076

Epoch: 6| Step: 10
Training loss: 0.38047289848327637
Validation loss: 1.7408585945765178

Epoch: 6| Step: 11
Training loss: 0.22105884552001953
Validation loss: 1.7636870312434372

Epoch: 6| Step: 12
Training loss: 0.2867964208126068
Validation loss: 1.7797663442550167

Epoch: 6| Step: 13
Training loss: 0.9303850531578064
Validation loss: 1.7520820786876063

Epoch: 366| Step: 0
Training loss: 0.5792341232299805
Validation loss: 1.7922114428653513

Epoch: 6| Step: 1
Training loss: 0.6777794361114502
Validation loss: 1.782849068282753

Epoch: 6| Step: 2
Training loss: 0.3446435332298279
Validation loss: 1.7839007762170607

Epoch: 6| Step: 3
Training loss: 0.4385380148887634
Validation loss: 1.7542393540823331

Epoch: 6| Step: 4
Training loss: 0.4278082847595215
Validation loss: 1.743743009464715

Epoch: 6| Step: 5
Training loss: 0.30181893706321716
Validation loss: 1.7466956389847623

Epoch: 6| Step: 6
Training loss: 0.2628382444381714
Validation loss: 1.736892613031531

Epoch: 6| Step: 7
Training loss: 0.3155665993690491
Validation loss: 1.74290370556616

Epoch: 6| Step: 8
Training loss: 0.46457189321517944
Validation loss: 1.7259576859012726

Epoch: 6| Step: 9
Training loss: 0.35896140336990356
Validation loss: 1.7367435565558813

Epoch: 6| Step: 10
Training loss: 0.3412911593914032
Validation loss: 1.7411331028066657

Epoch: 6| Step: 11
Training loss: 0.26907098293304443
Validation loss: 1.7310275364947576

Epoch: 6| Step: 12
Training loss: 0.1992775946855545
Validation loss: 1.732487638791402

Epoch: 6| Step: 13
Training loss: 0.13471288979053497
Validation loss: 1.7275638118866952

Epoch: 367| Step: 0
Training loss: 0.20803678035736084
Validation loss: 1.7656834920247395

Epoch: 6| Step: 1
Training loss: 0.3227229416370392
Validation loss: 1.7932109755854453

Epoch: 6| Step: 2
Training loss: 0.27069908380508423
Validation loss: 1.8248111817144579

Epoch: 6| Step: 3
Training loss: 0.16198283433914185
Validation loss: 1.8072465401823803

Epoch: 6| Step: 4
Training loss: 0.32881617546081543
Validation loss: 1.8119056827278548

Epoch: 6| Step: 5
Training loss: 0.2703644037246704
Validation loss: 1.8169343445890693

Epoch: 6| Step: 6
Training loss: 0.45791763067245483
Validation loss: 1.7764800325516732

Epoch: 6| Step: 7
Training loss: 0.22237536311149597
Validation loss: 1.7571763210399176

Epoch: 6| Step: 8
Training loss: 0.7829227447509766
Validation loss: 1.7668600518216369

Epoch: 6| Step: 9
Training loss: 0.29769572615623474
Validation loss: 1.7471870350581344

Epoch: 6| Step: 10
Training loss: 0.1772686243057251
Validation loss: 1.748791338295065

Epoch: 6| Step: 11
Training loss: 0.3121567964553833
Validation loss: 1.7431706010654409

Epoch: 6| Step: 12
Training loss: 0.3922407031059265
Validation loss: 1.7447704435676656

Epoch: 6| Step: 13
Training loss: 0.12246400862932205
Validation loss: 1.7441489376047605

Epoch: 368| Step: 0
Training loss: 0.27726805210113525
Validation loss: 1.7493237577458864

Epoch: 6| Step: 1
Training loss: 0.21372714638710022
Validation loss: 1.754420663720818

Epoch: 6| Step: 2
Training loss: 0.31909602880477905
Validation loss: 1.7215293536904037

Epoch: 6| Step: 3
Training loss: 0.18987269699573517
Validation loss: 1.7351281360913349

Epoch: 6| Step: 4
Training loss: 0.22902880609035492
Validation loss: 1.7356921703584733

Epoch: 6| Step: 5
Training loss: 0.44869041442871094
Validation loss: 1.718146070357292

Epoch: 6| Step: 6
Training loss: 0.3460772633552551
Validation loss: 1.7313299845623713

Epoch: 6| Step: 7
Training loss: 0.23932147026062012
Validation loss: 1.751131248730485

Epoch: 6| Step: 8
Training loss: 0.14150705933570862
Validation loss: 1.7376887157399168

Epoch: 6| Step: 9
Training loss: 0.35723742842674255
Validation loss: 1.7261307906079035

Epoch: 6| Step: 10
Training loss: 0.3460272252559662
Validation loss: 1.758197202477404

Epoch: 6| Step: 11
Training loss: 0.6091881394386292
Validation loss: 1.7379237451860983

Epoch: 6| Step: 12
Training loss: 0.1429263949394226
Validation loss: 1.7185532200721003

Epoch: 6| Step: 13
Training loss: 0.4804631471633911
Validation loss: 1.7517764952874952

Epoch: 369| Step: 0
Training loss: 0.4843934178352356
Validation loss: 1.73979522848642

Epoch: 6| Step: 1
Training loss: 0.478047251701355
Validation loss: 1.7284310222953878

Epoch: 6| Step: 2
Training loss: 0.28087109327316284
Validation loss: 1.7418555649377967

Epoch: 6| Step: 3
Training loss: 0.2707001566886902
Validation loss: 1.7751583348038376

Epoch: 6| Step: 4
Training loss: 0.21683324873447418
Validation loss: 1.750532345105243

Epoch: 6| Step: 5
Training loss: 0.4263777434825897
Validation loss: 1.7851958364568732

Epoch: 6| Step: 6
Training loss: 0.22255969047546387
Validation loss: 1.778384203551918

Epoch: 6| Step: 7
Training loss: 0.2221236228942871
Validation loss: 1.7943308058605398

Epoch: 6| Step: 8
Training loss: 0.19751156866550446
Validation loss: 1.7635377427583099

Epoch: 6| Step: 9
Training loss: 0.1816284954547882
Validation loss: 1.7643093742350096

Epoch: 6| Step: 10
Training loss: 0.334639310836792
Validation loss: 1.7677760649752874

Epoch: 6| Step: 11
Training loss: 0.3580593168735504
Validation loss: 1.7420474226756761

Epoch: 6| Step: 12
Training loss: 0.5255138278007507
Validation loss: 1.7434275041344345

Epoch: 6| Step: 13
Training loss: 0.24351082742214203
Validation loss: 1.7465815018582087

Epoch: 370| Step: 0
Training loss: 0.2945311665534973
Validation loss: 1.7171801559386715

Epoch: 6| Step: 1
Training loss: 0.2813466489315033
Validation loss: 1.7440763981111589

Epoch: 6| Step: 2
Training loss: 0.6897478699684143
Validation loss: 1.7236015309569657

Epoch: 6| Step: 3
Training loss: 0.32375389337539673
Validation loss: 1.7629300996821413

Epoch: 6| Step: 4
Training loss: 0.48788803815841675
Validation loss: 1.7667797060423

Epoch: 6| Step: 5
Training loss: 0.32219481468200684
Validation loss: 1.7671144752092258

Epoch: 6| Step: 6
Training loss: 0.21742340922355652
Validation loss: 1.7303519588644787

Epoch: 6| Step: 7
Training loss: 0.2511065900325775
Validation loss: 1.7418765534636795

Epoch: 6| Step: 8
Training loss: 0.5482909083366394
Validation loss: 1.7558185842729384

Epoch: 6| Step: 9
Training loss: 0.3091087341308594
Validation loss: 1.7670135421137656

Epoch: 6| Step: 10
Training loss: 0.17749767005443573
Validation loss: 1.7603847288316297

Epoch: 6| Step: 11
Training loss: 0.2726280689239502
Validation loss: 1.7243968145821684

Epoch: 6| Step: 12
Training loss: 0.33665376901626587
Validation loss: 1.711990124435835

Epoch: 6| Step: 13
Training loss: 0.2644030749797821
Validation loss: 1.7042814339360883

Epoch: 371| Step: 0
Training loss: 0.20934608578681946
Validation loss: 1.700925297634576

Epoch: 6| Step: 1
Training loss: 0.4008946418762207
Validation loss: 1.7355965645082536

Epoch: 6| Step: 2
Training loss: 0.21755321323871613
Validation loss: 1.7042274680188907

Epoch: 6| Step: 3
Training loss: 0.2497752606868744
Validation loss: 1.7232690562484085

Epoch: 6| Step: 4
Training loss: 0.38403069972991943
Validation loss: 1.6993092131871048

Epoch: 6| Step: 5
Training loss: 0.2841913104057312
Validation loss: 1.6822258298115065

Epoch: 6| Step: 6
Training loss: 0.2774661183357239
Validation loss: 1.7147232114627797

Epoch: 6| Step: 7
Training loss: 0.35428839921951294
Validation loss: 1.7181120482824181

Epoch: 6| Step: 8
Training loss: 0.253864049911499
Validation loss: 1.7069940297834334

Epoch: 6| Step: 9
Training loss: 0.26868578791618347
Validation loss: 1.7222759864663566

Epoch: 6| Step: 10
Training loss: 0.34327393770217896
Validation loss: 1.7518704886077552

Epoch: 6| Step: 11
Training loss: 0.44981276988983154
Validation loss: 1.744166148606167

Epoch: 6| Step: 12
Training loss: 0.3418661653995514
Validation loss: 1.7382540459273963

Epoch: 6| Step: 13
Training loss: 0.326709508895874
Validation loss: 1.7297888737852856

Epoch: 372| Step: 0
Training loss: 0.4044840335845947
Validation loss: 1.733194056377616

Epoch: 6| Step: 1
Training loss: 0.31512752175331116
Validation loss: 1.7207752991748113

Epoch: 6| Step: 2
Training loss: 0.5432233810424805
Validation loss: 1.7494512860492994

Epoch: 6| Step: 3
Training loss: 0.21021342277526855
Validation loss: 1.766173557568622

Epoch: 6| Step: 4
Training loss: 0.43043023347854614
Validation loss: 1.7606408711402648

Epoch: 6| Step: 5
Training loss: 0.2760744094848633
Validation loss: 1.7964799891236007

Epoch: 6| Step: 6
Training loss: 0.7554210424423218
Validation loss: 1.7534291077685613

Epoch: 6| Step: 7
Training loss: 0.240587517619133
Validation loss: 1.776830247653428

Epoch: 6| Step: 8
Training loss: 0.20695221424102783
Validation loss: 1.7687889863086004

Epoch: 6| Step: 9
Training loss: 0.23712608218193054
Validation loss: 1.7602008337615638

Epoch: 6| Step: 10
Training loss: 0.22712066769599915
Validation loss: 1.7843412160873413

Epoch: 6| Step: 11
Training loss: 0.3574857711791992
Validation loss: 1.7815443943905573

Epoch: 6| Step: 12
Training loss: 0.2947307229042053
Validation loss: 1.8174083104697607

Epoch: 6| Step: 13
Training loss: 0.3097584843635559
Validation loss: 1.8151923430863248

Epoch: 373| Step: 0
Training loss: 0.2885638475418091
Validation loss: 1.8297554344259284

Epoch: 6| Step: 1
Training loss: 0.3732891380786896
Validation loss: 1.7924388916261735

Epoch: 6| Step: 2
Training loss: 0.2674822211265564
Validation loss: 1.782075943485383

Epoch: 6| Step: 3
Training loss: 0.4260736405849457
Validation loss: 1.734113617609906

Epoch: 6| Step: 4
Training loss: 0.3866839110851288
Validation loss: 1.769240064005698

Epoch: 6| Step: 5
Training loss: 0.5248302221298218
Validation loss: 1.7663999526731429

Epoch: 6| Step: 6
Training loss: 0.19494670629501343
Validation loss: 1.7820424264477146

Epoch: 6| Step: 7
Training loss: 0.20594054460525513
Validation loss: 1.7898789400695472

Epoch: 6| Step: 8
Training loss: 0.33383095264434814
Validation loss: 1.81807291764085

Epoch: 6| Step: 9
Training loss: 0.36434733867645264
Validation loss: 1.8117760201936126

Epoch: 6| Step: 10
Training loss: 0.38450706005096436
Validation loss: 1.7926754925840644

Epoch: 6| Step: 11
Training loss: 0.3279423713684082
Validation loss: 1.8049783809210664

Epoch: 6| Step: 12
Training loss: 0.19704018533229828
Validation loss: 1.7505945441543416

Epoch: 6| Step: 13
Training loss: 0.2415333390235901
Validation loss: 1.7637687434432328

Epoch: 374| Step: 0
Training loss: 0.22522449493408203
Validation loss: 1.7705727789991645

Epoch: 6| Step: 1
Training loss: 0.28039994835853577
Validation loss: 1.7712414290315361

Epoch: 6| Step: 2
Training loss: 0.60456782579422
Validation loss: 1.7620832330437117

Epoch: 6| Step: 3
Training loss: 0.4165596663951874
Validation loss: 1.7386861462746896

Epoch: 6| Step: 4
Training loss: 0.3706333041191101
Validation loss: 1.7817795404823877

Epoch: 6| Step: 5
Training loss: 0.23132732510566711
Validation loss: 1.7098269116493963

Epoch: 6| Step: 6
Training loss: 0.1527976542711258
Validation loss: 1.726294994354248

Epoch: 6| Step: 7
Training loss: 0.21732309460639954
Validation loss: 1.7326847571198658

Epoch: 6| Step: 8
Training loss: 0.48851412534713745
Validation loss: 1.7407953303347352

Epoch: 6| Step: 9
Training loss: 0.3114847242832184
Validation loss: 1.7576556487749981

Epoch: 6| Step: 10
Training loss: 0.20113928616046906
Validation loss: 1.7772596343871085

Epoch: 6| Step: 11
Training loss: 0.27885544300079346
Validation loss: 1.8063919980038878

Epoch: 6| Step: 12
Training loss: 0.3365374207496643
Validation loss: 1.8058005532910746

Epoch: 6| Step: 13
Training loss: 0.19627435505390167
Validation loss: 1.763166509648805

Epoch: 375| Step: 0
Training loss: 0.23388487100601196
Validation loss: 1.7781246400648547

Epoch: 6| Step: 1
Training loss: 0.3925062417984009
Validation loss: 1.7454553470816663

Epoch: 6| Step: 2
Training loss: 0.30169814825057983
Validation loss: 1.7480556099645552

Epoch: 6| Step: 3
Training loss: 0.1763952374458313
Validation loss: 1.7036599215640817

Epoch: 6| Step: 4
Training loss: 0.18461710214614868
Validation loss: 1.6984610134555447

Epoch: 6| Step: 5
Training loss: 0.3100639581680298
Validation loss: 1.69736050662174

Epoch: 6| Step: 6
Training loss: 0.5701845288276672
Validation loss: 1.724119633756658

Epoch: 6| Step: 7
Training loss: 0.3340962827205658
Validation loss: 1.7051056354276595

Epoch: 6| Step: 8
Training loss: 0.44296932220458984
Validation loss: 1.7328187624613445

Epoch: 6| Step: 9
Training loss: 0.2550114691257477
Validation loss: 1.7208501523540867

Epoch: 6| Step: 10
Training loss: 0.3407050371170044
Validation loss: 1.7112849502153293

Epoch: 6| Step: 11
Training loss: 0.3603047728538513
Validation loss: 1.7046281599229383

Epoch: 6| Step: 12
Training loss: 0.17210166156291962
Validation loss: 1.7335818749602123

Epoch: 6| Step: 13
Training loss: 0.2516185939311981
Validation loss: 1.7395511955343268

Epoch: 376| Step: 0
Training loss: 0.3193284571170807
Validation loss: 1.7566352326382872

Epoch: 6| Step: 1
Training loss: 0.3144136965274811
Validation loss: 1.7640097218175088

Epoch: 6| Step: 2
Training loss: 0.2957371473312378
Validation loss: 1.7195124805614512

Epoch: 6| Step: 3
Training loss: 0.5180782079696655
Validation loss: 1.7385682905873945

Epoch: 6| Step: 4
Training loss: 0.14339129626750946
Validation loss: 1.7053331751977243

Epoch: 6| Step: 5
Training loss: 0.4693371653556824
Validation loss: 1.7016578823007562

Epoch: 6| Step: 6
Training loss: 0.2447848916053772
Validation loss: 1.6900404601968744

Epoch: 6| Step: 7
Training loss: 0.3723272681236267
Validation loss: 1.7069746986512215

Epoch: 6| Step: 8
Training loss: 0.23162779211997986
Validation loss: 1.70778097773111

Epoch: 6| Step: 9
Training loss: 0.37480995059013367
Validation loss: 1.6873256762822468

Epoch: 6| Step: 10
Training loss: 0.28483283519744873
Validation loss: 1.6897144163808515

Epoch: 6| Step: 11
Training loss: 0.20799870789051056
Validation loss: 1.6857785896588398

Epoch: 6| Step: 12
Training loss: 0.1696004867553711
Validation loss: 1.704556913786037

Epoch: 6| Step: 13
Training loss: 0.26172634959220886
Validation loss: 1.6925731922990532

Epoch: 377| Step: 0
Training loss: 0.23017068207263947
Validation loss: 1.7172781382837603

Epoch: 6| Step: 1
Training loss: 0.4544100761413574
Validation loss: 1.7003476965811946

Epoch: 6| Step: 2
Training loss: 0.18526454269886017
Validation loss: 1.7495315010829637

Epoch: 6| Step: 3
Training loss: 0.2535725235939026
Validation loss: 1.752420651015415

Epoch: 6| Step: 4
Training loss: 0.29695606231689453
Validation loss: 1.7228876595856042

Epoch: 6| Step: 5
Training loss: 0.4711498022079468
Validation loss: 1.7544863352211573

Epoch: 6| Step: 6
Training loss: 0.24253158271312714
Validation loss: 1.7368185622717744

Epoch: 6| Step: 7
Training loss: 0.30023038387298584
Validation loss: 1.7430803429695867

Epoch: 6| Step: 8
Training loss: 0.2374064028263092
Validation loss: 1.7174687911105413

Epoch: 6| Step: 9
Training loss: 0.2145286202430725
Validation loss: 1.7189734481996106

Epoch: 6| Step: 10
Training loss: 0.21257217228412628
Validation loss: 1.7473505209851008

Epoch: 6| Step: 11
Training loss: 0.37636321783065796
Validation loss: 1.6897129230601813

Epoch: 6| Step: 12
Training loss: 0.12313061207532883
Validation loss: 1.6986290357446159

Epoch: 6| Step: 13
Training loss: 0.8538622260093689
Validation loss: 1.7100850869250555

Epoch: 378| Step: 0
Training loss: 0.20673838257789612
Validation loss: 1.7221442153376918

Epoch: 6| Step: 1
Training loss: 0.16172632575035095
Validation loss: 1.7470664529390232

Epoch: 6| Step: 2
Training loss: 0.39348655939102173
Validation loss: 1.7437593411373835

Epoch: 6| Step: 3
Training loss: 0.29213425517082214
Validation loss: 1.7578767358615834

Epoch: 6| Step: 4
Training loss: 0.30238771438598633
Validation loss: 1.7599466103379444

Epoch: 6| Step: 5
Training loss: 0.3665976822376251
Validation loss: 1.7345549496271278

Epoch: 6| Step: 6
Training loss: 0.34545743465423584
Validation loss: 1.7053006464435208

Epoch: 6| Step: 7
Training loss: 0.3829139471054077
Validation loss: 1.7043746363732122

Epoch: 6| Step: 8
Training loss: 0.2759990990161896
Validation loss: 1.7209339564846409

Epoch: 6| Step: 9
Training loss: 0.3036728501319885
Validation loss: 1.7338544937872118

Epoch: 6| Step: 10
Training loss: 0.17672817409038544
Validation loss: 1.7399217210790163

Epoch: 6| Step: 11
Training loss: 0.56229168176651
Validation loss: 1.7399200598398845

Epoch: 6| Step: 12
Training loss: 0.29492688179016113
Validation loss: 1.73275710434042

Epoch: 6| Step: 13
Training loss: 0.27262699604034424
Validation loss: 1.7498758531385852

Epoch: 379| Step: 0
Training loss: 0.30007773637771606
Validation loss: 1.7182428926549933

Epoch: 6| Step: 1
Training loss: 0.33816415071487427
Validation loss: 1.7152489128933157

Epoch: 6| Step: 2
Training loss: 0.30848613381385803
Validation loss: 1.7298383033403786

Epoch: 6| Step: 3
Training loss: 0.3812248706817627
Validation loss: 1.7406999193212038

Epoch: 6| Step: 4
Training loss: 0.2618638575077057
Validation loss: 1.7310038125643166

Epoch: 6| Step: 5
Training loss: 0.4069786071777344
Validation loss: 1.730853647314092

Epoch: 6| Step: 6
Training loss: 0.39503538608551025
Validation loss: 1.7283838333622101

Epoch: 6| Step: 7
Training loss: 0.39225250482559204
Validation loss: 1.6688469532997376

Epoch: 6| Step: 8
Training loss: 0.20440569519996643
Validation loss: 1.699135293242752

Epoch: 6| Step: 9
Training loss: 0.28924641013145447
Validation loss: 1.681248390546409

Epoch: 6| Step: 10
Training loss: 0.5235766768455505
Validation loss: 1.683102894854802

Epoch: 6| Step: 11
Training loss: 0.2737129330635071
Validation loss: 1.678932661010373

Epoch: 6| Step: 12
Training loss: 0.15033575892448425
Validation loss: 1.6926219142893308

Epoch: 6| Step: 13
Training loss: 0.10212239623069763
Validation loss: 1.7305302748116114

Epoch: 380| Step: 0
Training loss: 0.4593967795372009
Validation loss: 1.7331362571767581

Epoch: 6| Step: 1
Training loss: 0.3233790695667267
Validation loss: 1.7061566088789253

Epoch: 6| Step: 2
Training loss: 0.5359556674957275
Validation loss: 1.7430221995999735

Epoch: 6| Step: 3
Training loss: 0.3051605522632599
Validation loss: 1.703320175088862

Epoch: 6| Step: 4
Training loss: 0.35377126932144165
Validation loss: 1.7232579108207458

Epoch: 6| Step: 5
Training loss: 0.5202291011810303
Validation loss: 1.6958122266236173

Epoch: 6| Step: 6
Training loss: 0.18248401582241058
Validation loss: 1.6931345103889384

Epoch: 6| Step: 7
Training loss: 0.3406217694282532
Validation loss: 1.6935746362132411

Epoch: 6| Step: 8
Training loss: 0.385398805141449
Validation loss: 1.6983860269669564

Epoch: 6| Step: 9
Training loss: 0.1867525726556778
Validation loss: 1.689947634614924

Epoch: 6| Step: 10
Training loss: 0.2583872377872467
Validation loss: 1.7084707662623415

Epoch: 6| Step: 11
Training loss: 0.15832336246967316
Validation loss: 1.7042830208296418

Epoch: 6| Step: 12
Training loss: 0.28845149278640747
Validation loss: 1.7208382403978737

Epoch: 6| Step: 13
Training loss: 0.3620281219482422
Validation loss: 1.7147100843409055

Epoch: 381| Step: 0
Training loss: 0.27798259258270264
Validation loss: 1.726251095853826

Epoch: 6| Step: 1
Training loss: 0.3537323474884033
Validation loss: 1.7182260367178148

Epoch: 6| Step: 2
Training loss: 0.3849593997001648
Validation loss: 1.738051006870885

Epoch: 6| Step: 3
Training loss: 0.38900482654571533
Validation loss: 1.7396308670761764

Epoch: 6| Step: 4
Training loss: 0.41732919216156006
Validation loss: 1.7364258766174316

Epoch: 6| Step: 5
Training loss: 0.16202324628829956
Validation loss: 1.6933253657433294

Epoch: 6| Step: 6
Training loss: 0.37757885456085205
Validation loss: 1.7043424755014398

Epoch: 6| Step: 7
Training loss: 0.18436408042907715
Validation loss: 1.7105692150772258

Epoch: 6| Step: 8
Training loss: 0.3017347455024719
Validation loss: 1.7117430907423778

Epoch: 6| Step: 9
Training loss: 0.2885515093803406
Validation loss: 1.7157063291918846

Epoch: 6| Step: 10
Training loss: 0.30508720874786377
Validation loss: 1.7289447553696171

Epoch: 6| Step: 11
Training loss: 0.3222914934158325
Validation loss: 1.7295288026973765

Epoch: 6| Step: 12
Training loss: 0.2799651026725769
Validation loss: 1.7537213371646019

Epoch: 6| Step: 13
Training loss: 0.21714116632938385
Validation loss: 1.6888083360528434

Epoch: 382| Step: 0
Training loss: 0.2762926518917084
Validation loss: 1.7152669365688036

Epoch: 6| Step: 1
Training loss: 0.14747193455696106
Validation loss: 1.7042191361868253

Epoch: 6| Step: 2
Training loss: 0.27972084283828735
Validation loss: 1.7205329454073341

Epoch: 6| Step: 3
Training loss: 0.28218868374824524
Validation loss: 1.7020360641582037

Epoch: 6| Step: 4
Training loss: 0.31049901247024536
Validation loss: 1.7112120543756792

Epoch: 6| Step: 5
Training loss: 0.21252486109733582
Validation loss: 1.7364351454601492

Epoch: 6| Step: 6
Training loss: 0.2978241443634033
Validation loss: 1.7346415955533263

Epoch: 6| Step: 7
Training loss: 0.1881481111049652
Validation loss: 1.7248748912606189

Epoch: 6| Step: 8
Training loss: 0.2549166977405548
Validation loss: 1.745231689945344

Epoch: 6| Step: 9
Training loss: 0.509649395942688
Validation loss: 1.731878747222244

Epoch: 6| Step: 10
Training loss: 0.2582666873931885
Validation loss: 1.7159085119924238

Epoch: 6| Step: 11
Training loss: 0.3663789629936218
Validation loss: 1.6818017459684802

Epoch: 6| Step: 12
Training loss: 0.2100888192653656
Validation loss: 1.7012266702549432

Epoch: 6| Step: 13
Training loss: 0.25998416543006897
Validation loss: 1.7027294994682394

Epoch: 383| Step: 0
Training loss: 0.40847963094711304
Validation loss: 1.7212385413467244

Epoch: 6| Step: 1
Training loss: 0.2904093563556671
Validation loss: 1.7387498988900134

Epoch: 6| Step: 2
Training loss: 0.3091382384300232
Validation loss: 1.7095903517097555

Epoch: 6| Step: 3
Training loss: 0.32005593180656433
Validation loss: 1.7450835858621905

Epoch: 6| Step: 4
Training loss: 0.451911985874176
Validation loss: 1.7417399357723933

Epoch: 6| Step: 5
Training loss: 0.47031646966934204
Validation loss: 1.748485549803703

Epoch: 6| Step: 6
Training loss: 0.24297958612442017
Validation loss: 1.7485754618080713

Epoch: 6| Step: 7
Training loss: 0.2809188961982727
Validation loss: 1.707594999703028

Epoch: 6| Step: 8
Training loss: 0.1941221058368683
Validation loss: 1.750225572175877

Epoch: 6| Step: 9
Training loss: 0.21732337772846222
Validation loss: 1.7563235580280263

Epoch: 6| Step: 10
Training loss: 0.6018372774124146
Validation loss: 1.7832333413503503

Epoch: 6| Step: 11
Training loss: 0.6314754486083984
Validation loss: 1.7704822427483016

Epoch: 6| Step: 12
Training loss: 0.34842371940612793
Validation loss: 1.7912335511176818

Epoch: 6| Step: 13
Training loss: 0.197865828871727
Validation loss: 1.7697134120489961

Epoch: 384| Step: 0
Training loss: 0.376587450504303
Validation loss: 1.748416357142951

Epoch: 6| Step: 1
Training loss: 0.3199145495891571
Validation loss: 1.7161764842207714

Epoch: 6| Step: 2
Training loss: 0.31077900528907776
Validation loss: 1.751959567428917

Epoch: 6| Step: 3
Training loss: 0.4968249797821045
Validation loss: 1.7486254733095887

Epoch: 6| Step: 4
Training loss: 0.30834487080574036
Validation loss: 1.7353312610298075

Epoch: 6| Step: 5
Training loss: 0.3777487874031067
Validation loss: 1.768935183043121

Epoch: 6| Step: 6
Training loss: 0.39704883098602295
Validation loss: 1.744358415244728

Epoch: 6| Step: 7
Training loss: 0.4529321491718292
Validation loss: 1.7360538077610794

Epoch: 6| Step: 8
Training loss: 0.17918714880943298
Validation loss: 1.7685644511253602

Epoch: 6| Step: 9
Training loss: 0.2668989896774292
Validation loss: 1.7512596409807923

Epoch: 6| Step: 10
Training loss: 0.17715919017791748
Validation loss: 1.714403401138962

Epoch: 6| Step: 11
Training loss: 0.3425680696964264
Validation loss: 1.7253730976453392

Epoch: 6| Step: 12
Training loss: 0.197666198015213
Validation loss: 1.72960913437669

Epoch: 6| Step: 13
Training loss: 0.14446793496608734
Validation loss: 1.7318289613211026

Epoch: 385| Step: 0
Training loss: 0.4290897250175476
Validation loss: 1.7115397299489667

Epoch: 6| Step: 1
Training loss: 0.3502011299133301
Validation loss: 1.7122432211393952

Epoch: 6| Step: 2
Training loss: 0.47743505239486694
Validation loss: 1.7004460762905818

Epoch: 6| Step: 3
Training loss: 0.2601388990879059
Validation loss: 1.678358704813065

Epoch: 6| Step: 4
Training loss: 0.288952499628067
Validation loss: 1.687801589248001

Epoch: 6| Step: 5
Training loss: 0.37989985942840576
Validation loss: 1.7014777429642216

Epoch: 6| Step: 6
Training loss: 0.28014636039733887
Validation loss: 1.686255653699239

Epoch: 6| Step: 7
Training loss: 0.25555774569511414
Validation loss: 1.6977133533006072

Epoch: 6| Step: 8
Training loss: 0.4308796226978302
Validation loss: 1.7457739294216197

Epoch: 6| Step: 9
Training loss: 0.31418994069099426
Validation loss: 1.7348275851177912

Epoch: 6| Step: 10
Training loss: 0.14554405212402344
Validation loss: 1.7094663240576302

Epoch: 6| Step: 11
Training loss: 0.21551580727100372
Validation loss: 1.733941792159952

Epoch: 6| Step: 12
Training loss: 0.362545907497406
Validation loss: 1.7425732330609394

Epoch: 6| Step: 13
Training loss: 0.36796748638153076
Validation loss: 1.7389925103033743

Epoch: 386| Step: 0
Training loss: 0.2604503035545349
Validation loss: 1.7309785504494943

Epoch: 6| Step: 1
Training loss: 0.15259894728660583
Validation loss: 1.7229261449588242

Epoch: 6| Step: 2
Training loss: 0.25971266627311707
Validation loss: 1.6955136195305855

Epoch: 6| Step: 3
Training loss: 0.19374379515647888
Validation loss: 1.707394338423206

Epoch: 6| Step: 4
Training loss: 0.5003966689109802
Validation loss: 1.693783938243825

Epoch: 6| Step: 5
Training loss: 0.13080279529094696
Validation loss: 1.7155591851921492

Epoch: 6| Step: 6
Training loss: 0.319528728723526
Validation loss: 1.69432282704179

Epoch: 6| Step: 7
Training loss: 0.2963654398918152
Validation loss: 1.7089296258905882

Epoch: 6| Step: 8
Training loss: 0.36199134588241577
Validation loss: 1.7373040440262004

Epoch: 6| Step: 9
Training loss: 0.21620669960975647
Validation loss: 1.7090397573286487

Epoch: 6| Step: 10
Training loss: 0.3289231061935425
Validation loss: 1.7400182741944508

Epoch: 6| Step: 11
Training loss: 0.45175182819366455
Validation loss: 1.685804520883868

Epoch: 6| Step: 12
Training loss: 0.5769858360290527
Validation loss: 1.7344414188015846

Epoch: 6| Step: 13
Training loss: 0.10000845044851303
Validation loss: 1.7545194369490429

Epoch: 387| Step: 0
Training loss: 0.390211820602417
Validation loss: 1.713157469226468

Epoch: 6| Step: 1
Training loss: 0.20990604162216187
Validation loss: 1.7112215026732414

Epoch: 6| Step: 2
Training loss: 0.1361171007156372
Validation loss: 1.6920052971891177

Epoch: 6| Step: 3
Training loss: 0.33575600385665894
Validation loss: 1.7280129796715193

Epoch: 6| Step: 4
Training loss: 0.2746349573135376
Validation loss: 1.728210445373289

Epoch: 6| Step: 5
Training loss: 0.6003779172897339
Validation loss: 1.7492450052692043

Epoch: 6| Step: 6
Training loss: 0.2222561240196228
Validation loss: 1.734141859956967

Epoch: 6| Step: 7
Training loss: 0.22249223291873932
Validation loss: 1.7328028268711542

Epoch: 6| Step: 8
Training loss: 0.33771470189094543
Validation loss: 1.7082008251579859

Epoch: 6| Step: 9
Training loss: 0.3215101361274719
Validation loss: 1.7259089305836668

Epoch: 6| Step: 10
Training loss: 0.2768317461013794
Validation loss: 1.728844678530129

Epoch: 6| Step: 11
Training loss: 0.2624094486236572
Validation loss: 1.7068146505663473

Epoch: 6| Step: 12
Training loss: 0.19306372106075287
Validation loss: 1.7010811644215738

Epoch: 6| Step: 13
Training loss: 0.11299724131822586
Validation loss: 1.7043848306901994

Epoch: 388| Step: 0
Training loss: 0.1683933287858963
Validation loss: 1.7026589865325599

Epoch: 6| Step: 1
Training loss: 0.4007307291030884
Validation loss: 1.72971301181342

Epoch: 6| Step: 2
Training loss: 0.24943721294403076
Validation loss: 1.7469114616353025

Epoch: 6| Step: 3
Training loss: 0.3266109228134155
Validation loss: 1.751498483842419

Epoch: 6| Step: 4
Training loss: 0.323996901512146
Validation loss: 1.7389601225494056

Epoch: 6| Step: 5
Training loss: 0.19024081528186798
Validation loss: 1.6977124291081582

Epoch: 6| Step: 6
Training loss: 0.1900099664926529
Validation loss: 1.6939897409049414

Epoch: 6| Step: 7
Training loss: 0.1412040889263153
Validation loss: 1.7377447146241383

Epoch: 6| Step: 8
Training loss: 0.18053263425827026
Validation loss: 1.7514784348908292

Epoch: 6| Step: 9
Training loss: 0.642757773399353
Validation loss: 1.7211755937145603

Epoch: 6| Step: 10
Training loss: 0.3132469356060028
Validation loss: 1.7400266355083835

Epoch: 6| Step: 11
Training loss: 0.2608679533004761
Validation loss: 1.7129322662148425

Epoch: 6| Step: 12
Training loss: 0.24095693230628967
Validation loss: 1.7195898153448617

Epoch: 6| Step: 13
Training loss: 0.16931761801242828
Validation loss: 1.7358062331394484

Epoch: 389| Step: 0
Training loss: 0.1418347805738449
Validation loss: 1.7452070225951493

Epoch: 6| Step: 1
Training loss: 0.2510649561882019
Validation loss: 1.726435178069658

Epoch: 6| Step: 2
Training loss: 0.31759119033813477
Validation loss: 1.7545829588367092

Epoch: 6| Step: 3
Training loss: 0.2280283421278
Validation loss: 1.7569412941573768

Epoch: 6| Step: 4
Training loss: 0.3747144341468811
Validation loss: 1.7302923420424103

Epoch: 6| Step: 5
Training loss: 0.2767374515533447
Validation loss: 1.6974445043071624

Epoch: 6| Step: 6
Training loss: 0.3099522590637207
Validation loss: 1.7339984960453485

Epoch: 6| Step: 7
Training loss: 0.199588805437088
Validation loss: 1.7192338858881304

Epoch: 6| Step: 8
Training loss: 0.30679967999458313
Validation loss: 1.7202240164561937

Epoch: 6| Step: 9
Training loss: 0.6008701324462891
Validation loss: 1.7612784139571651

Epoch: 6| Step: 10
Training loss: 0.4147137999534607
Validation loss: 1.8058053447354225

Epoch: 6| Step: 11
Training loss: 0.3490394949913025
Validation loss: 1.828152964192052

Epoch: 6| Step: 12
Training loss: 0.3370831608772278
Validation loss: 1.7860465716290217

Epoch: 6| Step: 13
Training loss: 0.43078505992889404
Validation loss: 1.7460072168739893

Epoch: 390| Step: 0
Training loss: 0.2296857237815857
Validation loss: 1.7581361468120287

Epoch: 6| Step: 1
Training loss: 0.2676393389701843
Validation loss: 1.7876598463263562

Epoch: 6| Step: 2
Training loss: 0.2667834162712097
Validation loss: 1.8416960470138057

Epoch: 6| Step: 3
Training loss: 0.36618268489837646
Validation loss: 1.8423469540893391

Epoch: 6| Step: 4
Training loss: 0.24647049605846405
Validation loss: 1.836018084197916

Epoch: 6| Step: 5
Training loss: 0.4592888057231903
Validation loss: 1.8108006831138366

Epoch: 6| Step: 6
Training loss: 0.3687659800052643
Validation loss: 1.793105351027622

Epoch: 6| Step: 7
Training loss: 0.41718772053718567
Validation loss: 1.7562836523978942

Epoch: 6| Step: 8
Training loss: 0.20559915900230408
Validation loss: 1.7198757894577519

Epoch: 6| Step: 9
Training loss: 0.2655411660671234
Validation loss: 1.7426916399309713

Epoch: 6| Step: 10
Training loss: 0.2842065691947937
Validation loss: 1.72587965637125

Epoch: 6| Step: 11
Training loss: 0.24927860498428345
Validation loss: 1.7535126427168488

Epoch: 6| Step: 12
Training loss: 0.3668862283229828
Validation loss: 1.7533252636591594

Epoch: 6| Step: 13
Training loss: 0.5427888631820679
Validation loss: 1.753229841109245

Epoch: 391| Step: 0
Training loss: 0.20859116315841675
Validation loss: 1.759617756771785

Epoch: 6| Step: 1
Training loss: 0.37254905700683594
Validation loss: 1.7495385267401253

Epoch: 6| Step: 2
Training loss: 0.3477553725242615
Validation loss: 1.7058299318436654

Epoch: 6| Step: 3
Training loss: 0.3416815400123596
Validation loss: 1.7165531266120173

Epoch: 6| Step: 4
Training loss: 0.25256478786468506
Validation loss: 1.7167227819401731

Epoch: 6| Step: 5
Training loss: 0.20092299580574036
Validation loss: 1.7287915688689037

Epoch: 6| Step: 6
Training loss: 0.3290709853172302
Validation loss: 1.7401639517917429

Epoch: 6| Step: 7
Training loss: 0.1934889853000641
Validation loss: 1.7902449151521087

Epoch: 6| Step: 8
Training loss: 0.17344631254673004
Validation loss: 1.8272531173562492

Epoch: 6| Step: 9
Training loss: 0.3289007842540741
Validation loss: 1.801528428190498

Epoch: 6| Step: 10
Training loss: 0.27418094873428345
Validation loss: 1.8147192449979885

Epoch: 6| Step: 11
Training loss: 0.21068018674850464
Validation loss: 1.8109067460542083

Epoch: 6| Step: 12
Training loss: 0.5684426426887512
Validation loss: 1.8073943071467902

Epoch: 6| Step: 13
Training loss: 0.76009202003479
Validation loss: 1.8120294975978073

Epoch: 392| Step: 0
Training loss: 0.2877172827720642
Validation loss: 1.816852408070718

Epoch: 6| Step: 1
Training loss: 0.32042497396469116
Validation loss: 1.7940896454677786

Epoch: 6| Step: 2
Training loss: 0.24335598945617676
Validation loss: 1.776481992454939

Epoch: 6| Step: 3
Training loss: 0.2485485076904297
Validation loss: 1.7659285209512199

Epoch: 6| Step: 4
Training loss: 0.23469148576259613
Validation loss: 1.7351822391633065

Epoch: 6| Step: 5
Training loss: 0.31670844554901123
Validation loss: 1.746147801799159

Epoch: 6| Step: 6
Training loss: 0.3395201563835144
Validation loss: 1.7359660735694311

Epoch: 6| Step: 7
Training loss: 0.3103145360946655
Validation loss: 1.7542296442934262

Epoch: 6| Step: 8
Training loss: 0.3971267640590668
Validation loss: 1.7489519157717306

Epoch: 6| Step: 9
Training loss: 0.25117412209510803
Validation loss: 1.7440084013887631

Epoch: 6| Step: 10
Training loss: 0.3608494997024536
Validation loss: 1.7459846004363029

Epoch: 6| Step: 11
Training loss: 0.29780691862106323
Validation loss: 1.7394281407838226

Epoch: 6| Step: 12
Training loss: 0.18502408266067505
Validation loss: 1.7055827789409186

Epoch: 6| Step: 13
Training loss: 0.16530758142471313
Validation loss: 1.7171536709672661

Epoch: 393| Step: 0
Training loss: 0.41052675247192383
Validation loss: 1.7299653304520475

Epoch: 6| Step: 1
Training loss: 0.19975000619888306
Validation loss: 1.6748745351709344

Epoch: 6| Step: 2
Training loss: 0.27536702156066895
Validation loss: 1.705793329464492

Epoch: 6| Step: 3
Training loss: 0.28736621141433716
Validation loss: 1.712315636296426

Epoch: 6| Step: 4
Training loss: 0.2202371060848236
Validation loss: 1.7158970243187361

Epoch: 6| Step: 5
Training loss: 0.19913727045059204
Validation loss: 1.6919972794030302

Epoch: 6| Step: 6
Training loss: 0.287807822227478
Validation loss: 1.7097249120794318

Epoch: 6| Step: 7
Training loss: 0.2769904136657715
Validation loss: 1.685210483048552

Epoch: 6| Step: 8
Training loss: 0.3303675353527069
Validation loss: 1.7111242086656633

Epoch: 6| Step: 9
Training loss: 0.3527623414993286
Validation loss: 1.6829059713630266

Epoch: 6| Step: 10
Training loss: 0.15028004348278046
Validation loss: 1.699032655326269

Epoch: 6| Step: 11
Training loss: 0.1591692864894867
Validation loss: 1.6639311121356102

Epoch: 6| Step: 12
Training loss: 0.28214120864868164
Validation loss: 1.6788132998251146

Epoch: 6| Step: 13
Training loss: 0.16268406808376312
Validation loss: 1.6990566727935628

Epoch: 394| Step: 0
Training loss: 0.1903826892375946
Validation loss: 1.6873218628668016

Epoch: 6| Step: 1
Training loss: 0.2756507992744446
Validation loss: 1.684227564001596

Epoch: 6| Step: 2
Training loss: 0.21208466589450836
Validation loss: 1.6970229712865685

Epoch: 6| Step: 3
Training loss: 0.2208600789308548
Validation loss: 1.7042573780141852

Epoch: 6| Step: 4
Training loss: 0.2405422031879425
Validation loss: 1.6750982076891008

Epoch: 6| Step: 5
Training loss: 0.29334166646003723
Validation loss: 1.6789236991636214

Epoch: 6| Step: 6
Training loss: 0.3164832890033722
Validation loss: 1.644387863015616

Epoch: 6| Step: 7
Training loss: 0.25605344772338867
Validation loss: 1.677839590657142

Epoch: 6| Step: 8
Training loss: 0.16816365718841553
Validation loss: 1.6883205393309235

Epoch: 6| Step: 9
Training loss: 0.15065591037273407
Validation loss: 1.68031112353007

Epoch: 6| Step: 10
Training loss: 0.40068358182907104
Validation loss: 1.6892256147118025

Epoch: 6| Step: 11
Training loss: 0.31764158606529236
Validation loss: 1.6899931046270555

Epoch: 6| Step: 12
Training loss: 0.21183186769485474
Validation loss: 1.7010350060719315

Epoch: 6| Step: 13
Training loss: 0.8093936443328857
Validation loss: 1.662858384911732

Epoch: 395| Step: 0
Training loss: 0.3449092507362366
Validation loss: 1.6657158636277722

Epoch: 6| Step: 1
Training loss: 0.23874372243881226
Validation loss: 1.6609216377299318

Epoch: 6| Step: 2
Training loss: 0.47020962834358215
Validation loss: 1.6866938632021669

Epoch: 6| Step: 3
Training loss: 0.2814812958240509
Validation loss: 1.701988204833

Epoch: 6| Step: 4
Training loss: 0.2397722601890564
Validation loss: 1.6906850440527803

Epoch: 6| Step: 5
Training loss: 0.30754488706588745
Validation loss: 1.7665727407701555

Epoch: 6| Step: 6
Training loss: 0.29100626707077026
Validation loss: 1.7198467921185236

Epoch: 6| Step: 7
Training loss: 0.4131433963775635
Validation loss: 1.6937993431604037

Epoch: 6| Step: 8
Training loss: 0.13491365313529968
Validation loss: 1.6934568676897275

Epoch: 6| Step: 9
Training loss: 0.14923226833343506
Validation loss: 1.719418857687263

Epoch: 6| Step: 10
Training loss: 0.15352585911750793
Validation loss: 1.695779097977505

Epoch: 6| Step: 11
Training loss: 0.36731860041618347
Validation loss: 1.7332386021972985

Epoch: 6| Step: 12
Training loss: 0.22103829681873322
Validation loss: 1.713115881848079

Epoch: 6| Step: 13
Training loss: 0.30952441692352295
Validation loss: 1.6990574508584955

Epoch: 396| Step: 0
Training loss: 0.3494742214679718
Validation loss: 1.7123171629444245

Epoch: 6| Step: 1
Training loss: 0.10650226473808289
Validation loss: 1.7004152882483698

Epoch: 6| Step: 2
Training loss: 0.1379210650920868
Validation loss: 1.7212775932845248

Epoch: 6| Step: 3
Training loss: 0.16871818900108337
Validation loss: 1.6780311497308875

Epoch: 6| Step: 4
Training loss: 0.2891111969947815
Validation loss: 1.6706154718193957

Epoch: 6| Step: 5
Training loss: 0.17756226658821106
Validation loss: 1.6726986874816239

Epoch: 6| Step: 6
Training loss: 0.4654550552368164
Validation loss: 1.6631092102296892

Epoch: 6| Step: 7
Training loss: 0.2343548685312271
Validation loss: 1.6439967200320253

Epoch: 6| Step: 8
Training loss: 0.2045753002166748
Validation loss: 1.6142779088789416

Epoch: 6| Step: 9
Training loss: 0.43383926153182983
Validation loss: 1.635186477374005

Epoch: 6| Step: 10
Training loss: 0.31207236647605896
Validation loss: 1.6426289687233586

Epoch: 6| Step: 11
Training loss: 0.13323071599006653
Validation loss: 1.6524977530202558

Epoch: 6| Step: 12
Training loss: 0.19662019610404968
Validation loss: 1.6721603985755675

Epoch: 6| Step: 13
Training loss: 0.29107868671417236
Validation loss: 1.6579247559270551

Epoch: 397| Step: 0
Training loss: 0.25904038548469543
Validation loss: 1.6716521606650403

Epoch: 6| Step: 1
Training loss: 0.14304542541503906
Validation loss: 1.671204113191174

Epoch: 6| Step: 2
Training loss: 0.2702649235725403
Validation loss: 1.649595977157675

Epoch: 6| Step: 3
Training loss: 0.15780815482139587
Validation loss: 1.6644994892099851

Epoch: 6| Step: 4
Training loss: 0.11476477235555649
Validation loss: 1.6475848126155075

Epoch: 6| Step: 5
Training loss: 0.2580726742744446
Validation loss: 1.6581194836606261

Epoch: 6| Step: 6
Training loss: 0.1302383840084076
Validation loss: 1.701242257190007

Epoch: 6| Step: 7
Training loss: 0.18636740744113922
Validation loss: 1.6690912246704102

Epoch: 6| Step: 8
Training loss: 0.4645995795726776
Validation loss: 1.6692794471658685

Epoch: 6| Step: 9
Training loss: 0.2169877290725708
Validation loss: 1.7131569180437314

Epoch: 6| Step: 10
Training loss: 0.20294439792633057
Validation loss: 1.6979602254847044

Epoch: 6| Step: 11
Training loss: 0.22758328914642334
Validation loss: 1.690846412412582

Epoch: 6| Step: 12
Training loss: 0.338531494140625
Validation loss: 1.6972760154354958

Epoch: 6| Step: 13
Training loss: 0.5771061182022095
Validation loss: 1.7375151905962216

Epoch: 398| Step: 0
Training loss: 0.4849885404109955
Validation loss: 1.7116831323151946

Epoch: 6| Step: 1
Training loss: 0.560012936592102
Validation loss: 1.706535964883784

Epoch: 6| Step: 2
Training loss: 0.189041405916214
Validation loss: 1.70093713396339

Epoch: 6| Step: 3
Training loss: 0.22318199276924133
Validation loss: 1.6951989550744333

Epoch: 6| Step: 4
Training loss: 0.23116160929203033
Validation loss: 1.7168994757436937

Epoch: 6| Step: 5
Training loss: 0.36776572465896606
Validation loss: 1.7185535994909142

Epoch: 6| Step: 6
Training loss: 0.25448301434516907
Validation loss: 1.7345596872350222

Epoch: 6| Step: 7
Training loss: 0.17694875597953796
Validation loss: 1.7217032114664714

Epoch: 6| Step: 8
Training loss: 0.3008632957935333
Validation loss: 1.7292031254819644

Epoch: 6| Step: 9
Training loss: 0.15155333280563354
Validation loss: 1.7049803862007715

Epoch: 6| Step: 10
Training loss: 0.27658987045288086
Validation loss: 1.6953978935877483

Epoch: 6| Step: 11
Training loss: 0.1632770448923111
Validation loss: 1.6499269726455852

Epoch: 6| Step: 12
Training loss: 0.15339700877666473
Validation loss: 1.6835740586762786

Epoch: 6| Step: 13
Training loss: 0.4330071806907654
Validation loss: 1.7008620692837624

Epoch: 399| Step: 0
Training loss: 0.4356944262981415
Validation loss: 1.6940548112315517

Epoch: 6| Step: 1
Training loss: 0.0954914391040802
Validation loss: 1.703747075091126

Epoch: 6| Step: 2
Training loss: 0.25299257040023804
Validation loss: 1.6746472210012457

Epoch: 6| Step: 3
Training loss: 0.38932114839553833
Validation loss: 1.7035095486589658

Epoch: 6| Step: 4
Training loss: 0.20304521918296814
Validation loss: 1.6949442214863275

Epoch: 6| Step: 5
Training loss: 0.23939073085784912
Validation loss: 1.7024642741808327

Epoch: 6| Step: 6
Training loss: 0.195768803358078
Validation loss: 1.6689568693919847

Epoch: 6| Step: 7
Training loss: 0.13836364448070526
Validation loss: 1.6816968225663709

Epoch: 6| Step: 8
Training loss: 0.23180529475212097
Validation loss: 1.6926809921059558

Epoch: 6| Step: 9
Training loss: 0.28241026401519775
Validation loss: 1.7006513585326493

Epoch: 6| Step: 10
Training loss: 0.35597294569015503
Validation loss: 1.6780089075847338

Epoch: 6| Step: 11
Training loss: 0.19137904047966003
Validation loss: 1.705526175037507

Epoch: 6| Step: 12
Training loss: 0.30904892086982727
Validation loss: 1.6919683564093806

Epoch: 6| Step: 13
Training loss: 0.2007881999015808
Validation loss: 1.6922074415350472

Epoch: 400| Step: 0
Training loss: 0.35686588287353516
Validation loss: 1.674983238661161

Epoch: 6| Step: 1
Training loss: 0.2788923978805542
Validation loss: 1.6729661931273758

Epoch: 6| Step: 2
Training loss: 0.2853369414806366
Validation loss: 1.6951886005299066

Epoch: 6| Step: 3
Training loss: 0.20993104577064514
Validation loss: 1.6874488489602202

Epoch: 6| Step: 4
Training loss: 0.1674441397190094
Validation loss: 1.7028408614538049

Epoch: 6| Step: 5
Training loss: 0.24519795179367065
Validation loss: 1.6692954583834576

Epoch: 6| Step: 6
Training loss: 0.11599589139223099
Validation loss: 1.6774663925170898

Epoch: 6| Step: 7
Training loss: 0.36012953519821167
Validation loss: 1.6665031608714853

Epoch: 6| Step: 8
Training loss: 0.23521491885185242
Validation loss: 1.6670035905735467

Epoch: 6| Step: 9
Training loss: 0.202290341258049
Validation loss: 1.6838182659559353

Epoch: 6| Step: 10
Training loss: 0.18104258179664612
Validation loss: 1.6821133129058345

Epoch: 6| Step: 11
Training loss: 0.3270135521888733
Validation loss: 1.651832861285056

Epoch: 6| Step: 12
Training loss: 0.2483387291431427
Validation loss: 1.6453506888881806

Epoch: 6| Step: 13
Training loss: 0.11651918292045593
Validation loss: 1.6411361335426249

Epoch: 401| Step: 0
Training loss: 0.17541448771953583
Validation loss: 1.6557542995740009

Epoch: 6| Step: 1
Training loss: 0.23996855318546295
Validation loss: 1.6457133895607405

Epoch: 6| Step: 2
Training loss: 0.2239818572998047
Validation loss: 1.6661197421371297

Epoch: 6| Step: 3
Training loss: 0.36259183287620544
Validation loss: 1.6625188358368412

Epoch: 6| Step: 4
Training loss: 0.23739507794380188
Validation loss: 1.702032422506681

Epoch: 6| Step: 5
Training loss: 0.15821096301078796
Validation loss: 1.6802196143775858

Epoch: 6| Step: 6
Training loss: 0.1900540292263031
Validation loss: 1.6805600978994881

Epoch: 6| Step: 7
Training loss: 0.27843689918518066
Validation loss: 1.7149403928428568

Epoch: 6| Step: 8
Training loss: 0.2337472289800644
Validation loss: 1.6775285402933757

Epoch: 6| Step: 9
Training loss: 0.2310817390680313
Validation loss: 1.6987980245262064

Epoch: 6| Step: 10
Training loss: 0.20053473114967346
Validation loss: 1.6770487408484183

Epoch: 6| Step: 11
Training loss: 0.20583856105804443
Validation loss: 1.6879073407060357

Epoch: 6| Step: 12
Training loss: 0.26900261640548706
Validation loss: 1.69457911035066

Epoch: 6| Step: 13
Training loss: 0.5432481169700623
Validation loss: 1.7157721109287714

Epoch: 402| Step: 0
Training loss: 0.18130441009998322
Validation loss: 1.6865189113924581

Epoch: 6| Step: 1
Training loss: 0.23924852907657623
Validation loss: 1.7060353512405066

Epoch: 6| Step: 2
Training loss: 0.3231717646121979
Validation loss: 1.6833945474316996

Epoch: 6| Step: 3
Training loss: 0.24798735976219177
Validation loss: 1.6761810959026378

Epoch: 6| Step: 4
Training loss: 0.1706196665763855
Validation loss: 1.6761929181314283

Epoch: 6| Step: 5
Training loss: 0.31365731358528137
Validation loss: 1.6928795204367688

Epoch: 6| Step: 6
Training loss: 0.14539940655231476
Validation loss: 1.7259584485843618

Epoch: 6| Step: 7
Training loss: 0.19324572384357452
Validation loss: 1.738030807946318

Epoch: 6| Step: 8
Training loss: 0.42470836639404297
Validation loss: 1.7316734303710282

Epoch: 6| Step: 9
Training loss: 0.18350839614868164
Validation loss: 1.73829480396804

Epoch: 6| Step: 10
Training loss: 0.2715257406234741
Validation loss: 1.695120785825996

Epoch: 6| Step: 11
Training loss: 0.21674054861068726
Validation loss: 1.674436697395899

Epoch: 6| Step: 12
Training loss: 0.261444628238678
Validation loss: 1.658735800814885

Epoch: 6| Step: 13
Training loss: 0.04851303994655609
Validation loss: 1.6296469062887213

Epoch: 403| Step: 0
Training loss: 0.1621047556400299
Validation loss: 1.6292132869843514

Epoch: 6| Step: 1
Training loss: 0.12933678925037384
Validation loss: 1.6380443701180079

Epoch: 6| Step: 2
Training loss: 0.14025118947029114
Validation loss: 1.6468724640466834

Epoch: 6| Step: 3
Training loss: 0.31845396757125854
Validation loss: 1.656530939122682

Epoch: 6| Step: 4
Training loss: 0.2674580514431
Validation loss: 1.657288791030966

Epoch: 6| Step: 5
Training loss: 0.3244473934173584
Validation loss: 1.627540498651484

Epoch: 6| Step: 6
Training loss: 0.18806953728199005
Validation loss: 1.6428494825158069

Epoch: 6| Step: 7
Training loss: 0.30317434668540955
Validation loss: 1.635572310416929

Epoch: 6| Step: 8
Training loss: 0.21496251225471497
Validation loss: 1.6224158105029856

Epoch: 6| Step: 9
Training loss: 0.29476141929626465
Validation loss: 1.6320788245047293

Epoch: 6| Step: 10
Training loss: 0.43234583735466003
Validation loss: 1.655735009460039

Epoch: 6| Step: 11
Training loss: 0.14801111817359924
Validation loss: 1.6522876165246452

Epoch: 6| Step: 12
Training loss: 0.22273291647434235
Validation loss: 1.639590690212865

Epoch: 6| Step: 13
Training loss: 0.23037570714950562
Validation loss: 1.6665207378325924

Epoch: 404| Step: 0
Training loss: 0.3126170337200165
Validation loss: 1.6476981460407216

Epoch: 6| Step: 1
Training loss: 0.1937127709388733
Validation loss: 1.6581307521430395

Epoch: 6| Step: 2
Training loss: 0.19103942811489105
Validation loss: 1.6725957893556165

Epoch: 6| Step: 3
Training loss: 0.2701098620891571
Validation loss: 1.6712550911852109

Epoch: 6| Step: 4
Training loss: 0.22980046272277832
Validation loss: 1.6427013835599344

Epoch: 6| Step: 5
Training loss: 0.20516455173492432
Validation loss: 1.6536537767738424

Epoch: 6| Step: 6
Training loss: 0.09044268727302551
Validation loss: 1.6425005210343229

Epoch: 6| Step: 7
Training loss: 0.3632442355155945
Validation loss: 1.669552041638282

Epoch: 6| Step: 8
Training loss: 0.1132868230342865
Validation loss: 1.6530869622384348

Epoch: 6| Step: 9
Training loss: 0.32703959941864014
Validation loss: 1.6847672603463615

Epoch: 6| Step: 10
Training loss: 0.19033774733543396
Validation loss: 1.6763920873724005

Epoch: 6| Step: 11
Training loss: 0.18393796682357788
Validation loss: 1.6664586554291427

Epoch: 6| Step: 12
Training loss: 0.22507405281066895
Validation loss: 1.6491664814692673

Epoch: 6| Step: 13
Training loss: 0.6485382914543152
Validation loss: 1.6719391717705676

Epoch: 405| Step: 0
Training loss: 0.1254844069480896
Validation loss: 1.6169743909630725

Epoch: 6| Step: 1
Training loss: 0.33381718397140503
Validation loss: 1.6661898743721746

Epoch: 6| Step: 2
Training loss: 0.211074560880661
Validation loss: 1.6772896500043972

Epoch: 6| Step: 3
Training loss: 0.35882461071014404
Validation loss: 1.7018066016576623

Epoch: 6| Step: 4
Training loss: 0.14552408456802368
Validation loss: 1.665401008821303

Epoch: 6| Step: 5
Training loss: 0.12346472591161728
Validation loss: 1.6750021929381995

Epoch: 6| Step: 6
Training loss: 0.26996302604675293
Validation loss: 1.6833044046996741

Epoch: 6| Step: 7
Training loss: 0.18530891835689545
Validation loss: 1.6600256645551292

Epoch: 6| Step: 8
Training loss: 0.3190227150917053
Validation loss: 1.6502050738180838

Epoch: 6| Step: 9
Training loss: 0.143917053937912
Validation loss: 1.6708771080099127

Epoch: 6| Step: 10
Training loss: 0.1620205044746399
Validation loss: 1.645910184870484

Epoch: 6| Step: 11
Training loss: 0.3816852867603302
Validation loss: 1.6665865817377645

Epoch: 6| Step: 12
Training loss: 0.16763946413993835
Validation loss: 1.6650971494695193

Epoch: 6| Step: 13
Training loss: 0.20000416040420532
Validation loss: 1.669873700346998

Epoch: 406| Step: 0
Training loss: 0.3050558567047119
Validation loss: 1.6520131262399818

Epoch: 6| Step: 1
Training loss: 0.22924049198627472
Validation loss: 1.659635243877288

Epoch: 6| Step: 2
Training loss: 0.16158854961395264
Validation loss: 1.6306360678006244

Epoch: 6| Step: 3
Training loss: 0.13561539351940155
Validation loss: 1.6529166339546122

Epoch: 6| Step: 4
Training loss: 0.20170506834983826
Validation loss: 1.6670938614876039

Epoch: 6| Step: 5
Training loss: 0.2559507489204407
Validation loss: 1.6849742627912951

Epoch: 6| Step: 6
Training loss: 0.10523766279220581
Validation loss: 1.6810905689834266

Epoch: 6| Step: 7
Training loss: 0.33165624737739563
Validation loss: 1.700804264314713

Epoch: 6| Step: 8
Training loss: 0.2135508954524994
Validation loss: 1.6813109126142276

Epoch: 6| Step: 9
Training loss: 0.18458440899848938
Validation loss: 1.6807718456432383

Epoch: 6| Step: 10
Training loss: 0.1712619960308075
Validation loss: 1.655904705806445

Epoch: 6| Step: 11
Training loss: 0.08312925696372986
Validation loss: 1.6623861135975007

Epoch: 6| Step: 12
Training loss: 0.21907177567481995
Validation loss: 1.6708735285266754

Epoch: 6| Step: 13
Training loss: 0.3820827901363373
Validation loss: 1.699900351544862

Epoch: 407| Step: 0
Training loss: 0.16192537546157837
Validation loss: 1.688085643194055

Epoch: 6| Step: 1
Training loss: 0.2187979817390442
Validation loss: 1.6805220573179183

Epoch: 6| Step: 2
Training loss: 0.28053802251815796
Validation loss: 1.6519688239661596

Epoch: 6| Step: 3
Training loss: 0.1530732810497284
Validation loss: 1.6577961393581924

Epoch: 6| Step: 4
Training loss: 0.2708178758621216
Validation loss: 1.6483717272358556

Epoch: 6| Step: 5
Training loss: 0.4421056807041168
Validation loss: 1.6361345962811542

Epoch: 6| Step: 6
Training loss: 0.2582881450653076
Validation loss: 1.6431799024663947

Epoch: 6| Step: 7
Training loss: 0.2767522633075714
Validation loss: 1.6220388040747693

Epoch: 6| Step: 8
Training loss: 0.31213536858558655
Validation loss: 1.6374832212284047

Epoch: 6| Step: 9
Training loss: 0.44658759236335754
Validation loss: 1.6421949965979463

Epoch: 6| Step: 10
Training loss: 0.21241965889930725
Validation loss: 1.630167486847088

Epoch: 6| Step: 11
Training loss: 0.12789586186408997
Validation loss: 1.6330867608388264

Epoch: 6| Step: 12
Training loss: 0.08712823688983917
Validation loss: 1.6464421967024445

Epoch: 6| Step: 13
Training loss: 0.16765420138835907
Validation loss: 1.6599711705279607

Epoch: 408| Step: 0
Training loss: 0.18153101205825806
Validation loss: 1.6822744531016196

Epoch: 6| Step: 1
Training loss: 0.261188805103302
Validation loss: 1.6919726094891947

Epoch: 6| Step: 2
Training loss: 0.3965423107147217
Validation loss: 1.6653365345411404

Epoch: 6| Step: 3
Training loss: 0.3290383219718933
Validation loss: 1.6937033764777645

Epoch: 6| Step: 4
Training loss: 0.15662425756454468
Validation loss: 1.6457351715334

Epoch: 6| Step: 5
Training loss: 0.1866476684808731
Validation loss: 1.665215855003685

Epoch: 6| Step: 6
Training loss: 0.11414432525634766
Validation loss: 1.6675612990574171

Epoch: 6| Step: 7
Training loss: 0.16844017803668976
Validation loss: 1.6465991466276106

Epoch: 6| Step: 8
Training loss: 0.16339623928070068
Validation loss: 1.6534095720578266

Epoch: 6| Step: 9
Training loss: 0.27545490860939026
Validation loss: 1.6195370240878033

Epoch: 6| Step: 10
Training loss: 0.21013092994689941
Validation loss: 1.6407456128827986

Epoch: 6| Step: 11
Training loss: 0.19016239047050476
Validation loss: 1.6194610352157264

Epoch: 6| Step: 12
Training loss: 0.22203871607780457
Validation loss: 1.6443246333829817

Epoch: 6| Step: 13
Training loss: 0.29060035943984985
Validation loss: 1.6292396899192565

Epoch: 409| Step: 0
Training loss: 0.15488937497138977
Validation loss: 1.6610314935766242

Epoch: 6| Step: 1
Training loss: 0.3806021809577942
Validation loss: 1.6514438070276731

Epoch: 6| Step: 2
Training loss: 0.21212363243103027
Validation loss: 1.6704224104522376

Epoch: 6| Step: 3
Training loss: 0.20604002475738525
Validation loss: 1.6578983183830016

Epoch: 6| Step: 4
Training loss: 0.31122830510139465
Validation loss: 1.6639471835987543

Epoch: 6| Step: 5
Training loss: 0.11483274400234222
Validation loss: 1.6659985639715706

Epoch: 6| Step: 6
Training loss: 0.2394682914018631
Validation loss: 1.6556870937347412

Epoch: 6| Step: 7
Training loss: 0.23937642574310303
Validation loss: 1.6929175200000885

Epoch: 6| Step: 8
Training loss: 0.12433566153049469
Validation loss: 1.6967501332682948

Epoch: 6| Step: 9
Training loss: 0.18485283851623535
Validation loss: 1.7199201827408166

Epoch: 6| Step: 10
Training loss: 0.24987992644309998
Validation loss: 1.6668800948768534

Epoch: 6| Step: 11
Training loss: 0.250141978263855
Validation loss: 1.6731165378324446

Epoch: 6| Step: 12
Training loss: 0.17988374829292297
Validation loss: 1.7090371616425053

Epoch: 6| Step: 13
Training loss: 0.15967363119125366
Validation loss: 1.680061040386077

Epoch: 410| Step: 0
Training loss: 0.17113709449768066
Validation loss: 1.683951558605317

Epoch: 6| Step: 1
Training loss: 0.16427487134933472
Validation loss: 1.7064197960720267

Epoch: 6| Step: 2
Training loss: 0.11898155510425568
Validation loss: 1.7136040784979378

Epoch: 6| Step: 3
Training loss: 0.2865845859050751
Validation loss: 1.7160700034069758

Epoch: 6| Step: 4
Training loss: 0.29971715807914734
Validation loss: 1.7047985023067844

Epoch: 6| Step: 5
Training loss: 0.1256110668182373
Validation loss: 1.6763318020810363

Epoch: 6| Step: 6
Training loss: 0.2914443612098694
Validation loss: 1.6847649197424612

Epoch: 6| Step: 7
Training loss: 0.2026781141757965
Validation loss: 1.664559104109323

Epoch: 6| Step: 8
Training loss: 0.1756993681192398
Validation loss: 1.6246885766265213

Epoch: 6| Step: 9
Training loss: 0.14030900597572327
Validation loss: 1.6340742354751916

Epoch: 6| Step: 10
Training loss: 0.32152897119522095
Validation loss: 1.6511250465146956

Epoch: 6| Step: 11
Training loss: 0.1677917093038559
Validation loss: 1.642090937142731

Epoch: 6| Step: 12
Training loss: 0.35914504528045654
Validation loss: 1.6490836425494122

Epoch: 6| Step: 13
Training loss: 0.19880376756191254
Validation loss: 1.6412593549297703

Epoch: 411| Step: 0
Training loss: 0.1760862022638321
Validation loss: 1.652635225685694

Epoch: 6| Step: 1
Training loss: 0.21589882671833038
Validation loss: 1.6351676807608655

Epoch: 6| Step: 2
Training loss: 0.311387300491333
Validation loss: 1.6417379212635819

Epoch: 6| Step: 3
Training loss: 0.17601966857910156
Validation loss: 1.6441187102307555

Epoch: 6| Step: 4
Training loss: 0.1932188868522644
Validation loss: 1.677701796254804

Epoch: 6| Step: 5
Training loss: 0.23254559934139252
Validation loss: 1.6991815951562697

Epoch: 6| Step: 6
Training loss: 0.22260192036628723
Validation loss: 1.687167420182177

Epoch: 6| Step: 7
Training loss: 0.17070376873016357
Validation loss: 1.710558210649798

Epoch: 6| Step: 8
Training loss: 0.1353069245815277
Validation loss: 1.6828037949018582

Epoch: 6| Step: 9
Training loss: 0.26247984170913696
Validation loss: 1.6855804881741923

Epoch: 6| Step: 10
Training loss: 0.11836409568786621
Validation loss: 1.6514740797781176

Epoch: 6| Step: 11
Training loss: 0.44493788480758667
Validation loss: 1.6549147329022806

Epoch: 6| Step: 12
Training loss: 0.1305222362279892
Validation loss: 1.6469328903382825

Epoch: 6| Step: 13
Training loss: 0.1448720544576645
Validation loss: 1.6669346427404752

Epoch: 412| Step: 0
Training loss: 0.0738292783498764
Validation loss: 1.6425960102388937

Epoch: 6| Step: 1
Training loss: 0.3992959260940552
Validation loss: 1.6578907351340018

Epoch: 6| Step: 2
Training loss: 0.21036532521247864
Validation loss: 1.652687559845627

Epoch: 6| Step: 3
Training loss: 0.3225727677345276
Validation loss: 1.6684500735293153

Epoch: 6| Step: 4
Training loss: 0.16242828965187073
Validation loss: 1.6591521411813714

Epoch: 6| Step: 5
Training loss: 0.21627071499824524
Validation loss: 1.6899766896360664

Epoch: 6| Step: 6
Training loss: 0.2485956996679306
Validation loss: 1.6435427499073807

Epoch: 6| Step: 7
Training loss: 0.16464471817016602
Validation loss: 1.66416895774103

Epoch: 6| Step: 8
Training loss: 0.1725115031003952
Validation loss: 1.634734179383965

Epoch: 6| Step: 9
Training loss: 0.11972525715827942
Validation loss: 1.6517263445802914

Epoch: 6| Step: 10
Training loss: 0.2618330121040344
Validation loss: 1.670385932409635

Epoch: 6| Step: 11
Training loss: 0.18248414993286133
Validation loss: 1.6787974501168856

Epoch: 6| Step: 12
Training loss: 0.18293794989585876
Validation loss: 1.6761105483578098

Epoch: 6| Step: 13
Training loss: 0.4446185529232025
Validation loss: 1.6755433390217442

Epoch: 413| Step: 0
Training loss: 0.14631563425064087
Validation loss: 1.6913717292970227

Epoch: 6| Step: 1
Training loss: 0.19949908554553986
Validation loss: 1.6583136025295462

Epoch: 6| Step: 2
Training loss: 0.28619813919067383
Validation loss: 1.6734226172970188

Epoch: 6| Step: 3
Training loss: 0.2157607078552246
Validation loss: 1.6655518598453973

Epoch: 6| Step: 4
Training loss: 0.315900593996048
Validation loss: 1.679861096925633

Epoch: 6| Step: 5
Training loss: 0.15908890962600708
Validation loss: 1.6679156159841886

Epoch: 6| Step: 6
Training loss: 0.2205997109413147
Validation loss: 1.6722223809970322

Epoch: 6| Step: 7
Training loss: 0.36331427097320557
Validation loss: 1.6723227090733026

Epoch: 6| Step: 8
Training loss: 0.15920180082321167
Validation loss: 1.6653933499449043

Epoch: 6| Step: 9
Training loss: 0.224871426820755
Validation loss: 1.6404460117381106

Epoch: 6| Step: 10
Training loss: 0.1768488883972168
Validation loss: 1.6573543215310702

Epoch: 6| Step: 11
Training loss: 0.09862110018730164
Validation loss: 1.679880509453435

Epoch: 6| Step: 12
Training loss: 0.13983486592769623
Validation loss: 1.6471304329492713

Epoch: 6| Step: 13
Training loss: 0.2924506366252899
Validation loss: 1.6603432047751643

Epoch: 414| Step: 0
Training loss: 0.16206757724285126
Validation loss: 1.6716902550830637

Epoch: 6| Step: 1
Training loss: 0.1726859211921692
Validation loss: 1.7042719177020493

Epoch: 6| Step: 2
Training loss: 0.19125881791114807
Validation loss: 1.7101676835808703

Epoch: 6| Step: 3
Training loss: 0.12497150897979736
Validation loss: 1.69543420755735

Epoch: 6| Step: 4
Training loss: 0.38060468435287476
Validation loss: 1.6984258005695958

Epoch: 6| Step: 5
Training loss: 0.24009118974208832
Validation loss: 1.6908701722339918

Epoch: 6| Step: 6
Training loss: 0.20312762260437012
Validation loss: 1.7333656998090847

Epoch: 6| Step: 7
Training loss: 0.20853576064109802
Validation loss: 1.7075262390157229

Epoch: 6| Step: 8
Training loss: 0.10941050946712494
Validation loss: 1.708661606234889

Epoch: 6| Step: 9
Training loss: 0.43310728669166565
Validation loss: 1.6763029406147618

Epoch: 6| Step: 10
Training loss: 0.13968877494335175
Validation loss: 1.6722918133581839

Epoch: 6| Step: 11
Training loss: 0.2248542159795761
Validation loss: 1.6841815992068219

Epoch: 6| Step: 12
Training loss: 0.19317403435707092
Validation loss: 1.6957770470649964

Epoch: 6| Step: 13
Training loss: 0.26465192437171936
Validation loss: 1.6673912002194313

Epoch: 415| Step: 0
Training loss: 0.23177587985992432
Validation loss: 1.6611062378011725

Epoch: 6| Step: 1
Training loss: 0.2233073115348816
Validation loss: 1.6410503771997267

Epoch: 6| Step: 2
Training loss: 0.1837369203567505
Validation loss: 1.6670206169928274

Epoch: 6| Step: 3
Training loss: 0.23005971312522888
Validation loss: 1.672434413304893

Epoch: 6| Step: 4
Training loss: 0.2648746371269226
Validation loss: 1.6909719538945023

Epoch: 6| Step: 5
Training loss: 0.2917804718017578
Validation loss: 1.736366464245704

Epoch: 6| Step: 6
Training loss: 0.2488231211900711
Validation loss: 1.7575730944192538

Epoch: 6| Step: 7
Training loss: 0.388445109128952
Validation loss: 1.7694446886739423

Epoch: 6| Step: 8
Training loss: 0.3250771164894104
Validation loss: 1.7292448807788152

Epoch: 6| Step: 9
Training loss: 0.22190050780773163
Validation loss: 1.693070689837138

Epoch: 6| Step: 10
Training loss: 0.21727514266967773
Validation loss: 1.661462249294404

Epoch: 6| Step: 11
Training loss: 0.12896806001663208
Validation loss: 1.640490367848386

Epoch: 6| Step: 12
Training loss: 0.18374021351337433
Validation loss: 1.6327213523208455

Epoch: 6| Step: 13
Training loss: 0.22838419675827026
Validation loss: 1.6368538846251786

Epoch: 416| Step: 0
Training loss: 0.32192695140838623
Validation loss: 1.637551530714958

Epoch: 6| Step: 1
Training loss: 0.16764162480831146
Validation loss: 1.6567493843775924

Epoch: 6| Step: 2
Training loss: 0.30447885394096375
Validation loss: 1.647195921149305

Epoch: 6| Step: 3
Training loss: 0.15463531017303467
Validation loss: 1.65447288110692

Epoch: 6| Step: 4
Training loss: 0.4274834990501404
Validation loss: 1.652032772699992

Epoch: 6| Step: 5
Training loss: 0.2076362818479538
Validation loss: 1.6904029359099686

Epoch: 6| Step: 6
Training loss: 0.12416338920593262
Validation loss: 1.7231880682770924

Epoch: 6| Step: 7
Training loss: 0.21398162841796875
Validation loss: 1.7219663332867365

Epoch: 6| Step: 8
Training loss: 0.22684885561466217
Validation loss: 1.7028261269292524

Epoch: 6| Step: 9
Training loss: 0.24492287635803223
Validation loss: 1.7142501390108498

Epoch: 6| Step: 10
Training loss: 0.2132554054260254
Validation loss: 1.695030612330283

Epoch: 6| Step: 11
Training loss: 0.14253810048103333
Validation loss: 1.6805679234125281

Epoch: 6| Step: 12
Training loss: 0.20786407589912415
Validation loss: 1.6676425177563903

Epoch: 6| Step: 13
Training loss: 0.28243690729141235
Validation loss: 1.6696602862368348

Epoch: 417| Step: 0
Training loss: 0.1886044442653656
Validation loss: 1.6730906732620732

Epoch: 6| Step: 1
Training loss: 0.11543838679790497
Validation loss: 1.6598201503035843

Epoch: 6| Step: 2
Training loss: 0.2125215232372284
Validation loss: 1.6678179925487888

Epoch: 6| Step: 3
Training loss: 0.11488626152276993
Validation loss: 1.6606368172553279

Epoch: 6| Step: 4
Training loss: 0.22647136449813843
Validation loss: 1.6704071273085892

Epoch: 6| Step: 5
Training loss: 0.13965517282485962
Validation loss: 1.6673732944714126

Epoch: 6| Step: 6
Training loss: 0.1729949414730072
Validation loss: 1.6504071310002317

Epoch: 6| Step: 7
Training loss: 0.37643590569496155
Validation loss: 1.6542177277226602

Epoch: 6| Step: 8
Training loss: 0.25620055198669434
Validation loss: 1.654831172317587

Epoch: 6| Step: 9
Training loss: 0.18316984176635742
Validation loss: 1.6314660400472663

Epoch: 6| Step: 10
Training loss: 0.1487559676170349
Validation loss: 1.6327696051648868

Epoch: 6| Step: 11
Training loss: 0.24776789546012878
Validation loss: 1.6266903620894237

Epoch: 6| Step: 12
Training loss: 0.1275186836719513
Validation loss: 1.6413223640893095

Epoch: 6| Step: 13
Training loss: 0.28834861516952515
Validation loss: 1.6532439698455155

Epoch: 418| Step: 0
Training loss: 0.23177886009216309
Validation loss: 1.6294320462852396

Epoch: 6| Step: 1
Training loss: 0.3455796241760254
Validation loss: 1.6595767121161185

Epoch: 6| Step: 2
Training loss: 0.25448140501976013
Validation loss: 1.6579976017757128

Epoch: 6| Step: 3
Training loss: 0.19285470247268677
Validation loss: 1.6270397452897922

Epoch: 6| Step: 4
Training loss: 0.1247435212135315
Validation loss: 1.67893039026568

Epoch: 6| Step: 5
Training loss: 0.28893211483955383
Validation loss: 1.6401022365016322

Epoch: 6| Step: 6
Training loss: 0.20206624269485474
Validation loss: 1.6479028860727947

Epoch: 6| Step: 7
Training loss: 0.1969204545021057
Validation loss: 1.6591045612929969

Epoch: 6| Step: 8
Training loss: 0.2145031988620758
Validation loss: 1.6820777090646888

Epoch: 6| Step: 9
Training loss: 0.13739518821239471
Validation loss: 1.6662869799521662

Epoch: 6| Step: 10
Training loss: 0.25066423416137695
Validation loss: 1.705963429584298

Epoch: 6| Step: 11
Training loss: 0.49496984481811523
Validation loss: 1.7515562542023198

Epoch: 6| Step: 12
Training loss: 0.3108198046684265
Validation loss: 1.7421237704574422

Epoch: 6| Step: 13
Training loss: 0.15137498080730438
Validation loss: 1.7242917450525428

Epoch: 419| Step: 0
Training loss: 0.1943729817867279
Validation loss: 1.7093889149286414

Epoch: 6| Step: 1
Training loss: 0.39182955026626587
Validation loss: 1.6767946686795963

Epoch: 6| Step: 2
Training loss: 0.2752426862716675
Validation loss: 1.635489893856869

Epoch: 6| Step: 3
Training loss: 0.33622515201568604
Validation loss: 1.6804047605042816

Epoch: 6| Step: 4
Training loss: 0.3656786382198334
Validation loss: 1.6582334092868272

Epoch: 6| Step: 5
Training loss: 0.2552286684513092
Validation loss: 1.6954615154573995

Epoch: 6| Step: 6
Training loss: 0.3177511692047119
Validation loss: 1.665019251966989

Epoch: 6| Step: 7
Training loss: 0.11110015213489532
Validation loss: 1.6315836291159354

Epoch: 6| Step: 8
Training loss: 0.27164626121520996
Validation loss: 1.6283831622010918

Epoch: 6| Step: 9
Training loss: 0.22286687791347504
Validation loss: 1.6330733914529123

Epoch: 6| Step: 10
Training loss: 0.22137302160263062
Validation loss: 1.6489480490325599

Epoch: 6| Step: 11
Training loss: 0.2395055890083313
Validation loss: 1.6560513383598738

Epoch: 6| Step: 12
Training loss: 0.26513785123825073
Validation loss: 1.6947729036372194

Epoch: 6| Step: 13
Training loss: 0.2358742505311966
Validation loss: 1.7054052557996524

Epoch: 420| Step: 0
Training loss: 0.31238269805908203
Validation loss: 1.6936172977570565

Epoch: 6| Step: 1
Training loss: 0.15574561059474945
Validation loss: 1.667196548113259

Epoch: 6| Step: 2
Training loss: 0.26794594526290894
Validation loss: 1.6492386812804847

Epoch: 6| Step: 3
Training loss: 0.20640063285827637
Validation loss: 1.6275135586338658

Epoch: 6| Step: 4
Training loss: 0.10314656794071198
Validation loss: 1.6412651961849583

Epoch: 6| Step: 5
Training loss: 0.3098175525665283
Validation loss: 1.6134425504233247

Epoch: 6| Step: 6
Training loss: 0.18929561972618103
Validation loss: 1.6477143174858504

Epoch: 6| Step: 7
Training loss: 0.10503976792097092
Validation loss: 1.6447781221840971

Epoch: 6| Step: 8
Training loss: 0.28075817227363586
Validation loss: 1.6512835589788293

Epoch: 6| Step: 9
Training loss: 0.42424070835113525
Validation loss: 1.6232859960166357

Epoch: 6| Step: 10
Training loss: 0.1112823411822319
Validation loss: 1.6510790804381013

Epoch: 6| Step: 11
Training loss: 0.24341143667697906
Validation loss: 1.6453723561379217

Epoch: 6| Step: 12
Training loss: 0.20465798676013947
Validation loss: 1.6413310881583922

Epoch: 6| Step: 13
Training loss: 0.06446393579244614
Validation loss: 1.646477210906244

Epoch: 421| Step: 0
Training loss: 0.2430514395236969
Validation loss: 1.6402105592912244

Epoch: 6| Step: 1
Training loss: 0.13886681199073792
Validation loss: 1.6416510766552341

Epoch: 6| Step: 2
Training loss: 0.18112680315971375
Validation loss: 1.617153335643071

Epoch: 6| Step: 3
Training loss: 0.27397602796554565
Validation loss: 1.6293295762872184

Epoch: 6| Step: 4
Training loss: 0.17417415976524353
Validation loss: 1.6143562204094344

Epoch: 6| Step: 5
Training loss: 0.23181992769241333
Validation loss: 1.6328788508651078

Epoch: 6| Step: 6
Training loss: 0.23733484745025635
Validation loss: 1.62298019150252

Epoch: 6| Step: 7
Training loss: 0.27834463119506836
Validation loss: 1.6071121705475675

Epoch: 6| Step: 8
Training loss: 0.1679956167936325
Validation loss: 1.6821124899771907

Epoch: 6| Step: 9
Training loss: 0.21298475563526154
Validation loss: 1.6633339658860238

Epoch: 6| Step: 10
Training loss: 0.1975998729467392
Validation loss: 1.7041707961790022

Epoch: 6| Step: 11
Training loss: 0.1622803509235382
Validation loss: 1.687093578359132

Epoch: 6| Step: 12
Training loss: 0.21056678891181946
Validation loss: 1.6801710872239963

Epoch: 6| Step: 13
Training loss: 0.3059527575969696
Validation loss: 1.654258556263421

Epoch: 422| Step: 0
Training loss: 0.12600837647914886
Validation loss: 1.643513641049785

Epoch: 6| Step: 1
Training loss: 0.14940635859966278
Validation loss: 1.6366130228965514

Epoch: 6| Step: 2
Training loss: 0.3672472834587097
Validation loss: 1.6507527610307098

Epoch: 6| Step: 3
Training loss: 0.18613547086715698
Validation loss: 1.6758213248304141

Epoch: 6| Step: 4
Training loss: 0.14746345579624176
Validation loss: 1.651513030452113

Epoch: 6| Step: 5
Training loss: 0.12831619381904602
Validation loss: 1.687547432479038

Epoch: 6| Step: 6
Training loss: 0.28701916337013245
Validation loss: 1.6926955548665856

Epoch: 6| Step: 7
Training loss: 0.1801794320344925
Validation loss: 1.6679903935360652

Epoch: 6| Step: 8
Training loss: 0.09635381400585175
Validation loss: 1.6778569811133928

Epoch: 6| Step: 9
Training loss: 0.22555068135261536
Validation loss: 1.6723827315915016

Epoch: 6| Step: 10
Training loss: 0.12985840439796448
Validation loss: 1.6820864049337243

Epoch: 6| Step: 11
Training loss: 0.3499531149864197
Validation loss: 1.680175604358796

Epoch: 6| Step: 12
Training loss: 0.17930968105793
Validation loss: 1.6506706437756937

Epoch: 6| Step: 13
Training loss: 0.1256290078163147
Validation loss: 1.647534462713426

Epoch: 423| Step: 0
Training loss: 0.12358463555574417
Validation loss: 1.6270314108940862

Epoch: 6| Step: 1
Training loss: 0.3191913664340973
Validation loss: 1.6521006591858403

Epoch: 6| Step: 2
Training loss: 0.13953252136707306
Validation loss: 1.6375278093481576

Epoch: 6| Step: 3
Training loss: 0.25034037232398987
Validation loss: 1.6214618708497734

Epoch: 6| Step: 4
Training loss: 0.11340292543172836
Validation loss: 1.6083900338859969

Epoch: 6| Step: 5
Training loss: 0.18822118639945984
Validation loss: 1.6381464389062697

Epoch: 6| Step: 6
Training loss: 0.15279921889305115
Validation loss: 1.6391805730840212

Epoch: 6| Step: 7
Training loss: 0.10403218120336533
Validation loss: 1.6354537510102796

Epoch: 6| Step: 8
Training loss: 0.13625867664813995
Validation loss: 1.6569591933681118

Epoch: 6| Step: 9
Training loss: 0.1416938304901123
Validation loss: 1.6583057680437643

Epoch: 6| Step: 10
Training loss: 0.16963474452495575
Validation loss: 1.647091971289727

Epoch: 6| Step: 11
Training loss: 0.24312667548656464
Validation loss: 1.6681130829677786

Epoch: 6| Step: 12
Training loss: 0.28739744424819946
Validation loss: 1.6714959093319472

Epoch: 6| Step: 13
Training loss: 0.16308924555778503
Validation loss: 1.681249777475993

Epoch: 424| Step: 0
Training loss: 0.15087321400642395
Validation loss: 1.6782449906872166

Epoch: 6| Step: 1
Training loss: 0.14994513988494873
Validation loss: 1.6659629421849405

Epoch: 6| Step: 2
Training loss: 0.19222529232501984
Validation loss: 1.6645747782081686

Epoch: 6| Step: 3
Training loss: 0.10902362316846848
Validation loss: 1.6269213743107294

Epoch: 6| Step: 4
Training loss: 0.19088900089263916
Validation loss: 1.6332927788457563

Epoch: 6| Step: 5
Training loss: 0.3571120798587799
Validation loss: 1.6178548938484603

Epoch: 6| Step: 6
Training loss: 0.1760457158088684
Validation loss: 1.6332264830989223

Epoch: 6| Step: 7
Training loss: 0.267301082611084
Validation loss: 1.633252679660756

Epoch: 6| Step: 8
Training loss: 0.17194479703903198
Validation loss: 1.6289340129462622

Epoch: 6| Step: 9
Training loss: 0.18272444605827332
Validation loss: 1.6136320598663823

Epoch: 6| Step: 10
Training loss: 0.11260572075843811
Validation loss: 1.6203169322782947

Epoch: 6| Step: 11
Training loss: 0.10451814532279968
Validation loss: 1.6280530832147087

Epoch: 6| Step: 12
Training loss: 0.24224838614463806
Validation loss: 1.6272330104663808

Epoch: 6| Step: 13
Training loss: 0.05615304410457611
Validation loss: 1.6402365699891122

Epoch: 425| Step: 0
Training loss: 0.12518975138664246
Validation loss: 1.638870841713362

Epoch: 6| Step: 1
Training loss: 0.11163228005170822
Validation loss: 1.5961731633832377

Epoch: 6| Step: 2
Training loss: 0.23124437034130096
Validation loss: 1.6344848339275648

Epoch: 6| Step: 3
Training loss: 0.23220501840114594
Validation loss: 1.6304313469958562

Epoch: 6| Step: 4
Training loss: 0.25725582242012024
Validation loss: 1.611196594853555

Epoch: 6| Step: 5
Training loss: 0.2777503430843353
Validation loss: 1.6480332254081644

Epoch: 6| Step: 6
Training loss: 0.19985634088516235
Validation loss: 1.6497764754038986

Epoch: 6| Step: 7
Training loss: 0.2018304467201233
Validation loss: 1.6874057054519653

Epoch: 6| Step: 8
Training loss: 0.17993894219398499
Validation loss: 1.6632558171467116

Epoch: 6| Step: 9
Training loss: 0.16968345642089844
Validation loss: 1.6007548314268871

Epoch: 6| Step: 10
Training loss: 0.1567450612783432
Validation loss: 1.6333225632226596

Epoch: 6| Step: 11
Training loss: 0.1556720733642578
Validation loss: 1.6138139681149555

Epoch: 6| Step: 12
Training loss: 0.1790560781955719
Validation loss: 1.6546459556907736

Epoch: 6| Step: 13
Training loss: 0.2340538203716278
Validation loss: 1.6675375930724605

Epoch: 426| Step: 0
Training loss: 0.1879560500383377
Validation loss: 1.6704330162335468

Epoch: 6| Step: 1
Training loss: 0.2108222246170044
Validation loss: 1.6768947134735763

Epoch: 6| Step: 2
Training loss: 0.2045881152153015
Validation loss: 1.6771547204704695

Epoch: 6| Step: 3
Training loss: 0.17924945056438446
Validation loss: 1.6550786443935928

Epoch: 6| Step: 4
Training loss: 0.21612364053726196
Validation loss: 1.6456837641295565

Epoch: 6| Step: 5
Training loss: 0.14111657440662384
Validation loss: 1.6615408171889603

Epoch: 6| Step: 6
Training loss: 0.12330031394958496
Validation loss: 1.6630329765299314

Epoch: 6| Step: 7
Training loss: 0.15395334362983704
Validation loss: 1.647661102715359

Epoch: 6| Step: 8
Training loss: 0.3315955400466919
Validation loss: 1.6388136699635496

Epoch: 6| Step: 9
Training loss: 0.3507556915283203
Validation loss: 1.6614979633720972

Epoch: 6| Step: 10
Training loss: 0.1855921745300293
Validation loss: 1.6470717819788123

Epoch: 6| Step: 11
Training loss: 0.1356450468301773
Validation loss: 1.6441358622684275

Epoch: 6| Step: 12
Training loss: 0.24404439330101013
Validation loss: 1.6465334879454745

Epoch: 6| Step: 13
Training loss: 0.2036711573600769
Validation loss: 1.6485269851582025

Epoch: 427| Step: 0
Training loss: 0.16886311769485474
Validation loss: 1.6541196748774538

Epoch: 6| Step: 1
Training loss: 0.26372480392456055
Validation loss: 1.6434560539901897

Epoch: 6| Step: 2
Training loss: 0.19393998384475708
Validation loss: 1.6299358734520533

Epoch: 6| Step: 3
Training loss: 0.1979895532131195
Validation loss: 1.6342726010148243

Epoch: 6| Step: 4
Training loss: 0.22676844894886017
Validation loss: 1.6090237773874754

Epoch: 6| Step: 5
Training loss: 0.07560199499130249
Validation loss: 1.6345432689113002

Epoch: 6| Step: 6
Training loss: 0.1488713026046753
Validation loss: 1.6122853679041709

Epoch: 6| Step: 7
Training loss: 0.19892831146717072
Validation loss: 1.629886466969726

Epoch: 6| Step: 8
Training loss: 0.1491817831993103
Validation loss: 1.643385697436589

Epoch: 6| Step: 9
Training loss: 0.237522155046463
Validation loss: 1.6217725417947257

Epoch: 6| Step: 10
Training loss: 0.1472896933555603
Validation loss: 1.633899461838507

Epoch: 6| Step: 11
Training loss: 0.139404758810997
Validation loss: 1.635558730812483

Epoch: 6| Step: 12
Training loss: 0.24883872270584106
Validation loss: 1.6439682386254753

Epoch: 6| Step: 13
Training loss: 0.34091976284980774
Validation loss: 1.65052157063638

Epoch: 428| Step: 0
Training loss: 0.13657040894031525
Validation loss: 1.6554322524737286

Epoch: 6| Step: 1
Training loss: 0.20515581965446472
Validation loss: 1.6501312422496017

Epoch: 6| Step: 2
Training loss: 0.09911031275987625
Validation loss: 1.651753176925003

Epoch: 6| Step: 3
Training loss: 0.13510121405124664
Validation loss: 1.6315512439256072

Epoch: 6| Step: 4
Training loss: 0.24666766822338104
Validation loss: 1.6168120086833995

Epoch: 6| Step: 5
Training loss: 0.15727007389068604
Validation loss: 1.6149560174634379

Epoch: 6| Step: 6
Training loss: 0.21083062887191772
Validation loss: 1.6163926624482678

Epoch: 6| Step: 7
Training loss: 0.3083333969116211
Validation loss: 1.608605520699614

Epoch: 6| Step: 8
Training loss: 0.11809961497783661
Validation loss: 1.5910223248184368

Epoch: 6| Step: 9
Training loss: 0.10667318850755692
Validation loss: 1.6307082817118654

Epoch: 6| Step: 10
Training loss: 0.14530271291732788
Validation loss: 1.6158708583924077

Epoch: 6| Step: 11
Training loss: 0.3885401487350464
Validation loss: 1.629738696159855

Epoch: 6| Step: 12
Training loss: 0.12079517543315887
Validation loss: 1.644084253618794

Epoch: 6| Step: 13
Training loss: 0.2551219165325165
Validation loss: 1.612887743980654

Epoch: 429| Step: 0
Training loss: 0.1331658959388733
Validation loss: 1.6124293688804872

Epoch: 6| Step: 1
Training loss: 0.18600651621818542
Validation loss: 1.616731575740281

Epoch: 6| Step: 2
Training loss: 0.20831893384456635
Validation loss: 1.6164614128810104

Epoch: 6| Step: 3
Training loss: 0.07532345503568649
Validation loss: 1.597876343675839

Epoch: 6| Step: 4
Training loss: 0.186242938041687
Validation loss: 1.620748726270532

Epoch: 6| Step: 5
Training loss: 0.2892771363258362
Validation loss: 1.5980475077065088

Epoch: 6| Step: 6
Training loss: 0.09066896140575409
Validation loss: 1.5938999601589736

Epoch: 6| Step: 7
Training loss: 0.15672892332077026
Validation loss: 1.6114810333457044

Epoch: 6| Step: 8
Training loss: 0.2104097306728363
Validation loss: 1.6264321714319208

Epoch: 6| Step: 9
Training loss: 0.1391412764787674
Validation loss: 1.617744162518491

Epoch: 6| Step: 10
Training loss: 0.13671380281448364
Validation loss: 1.623690737191067

Epoch: 6| Step: 11
Training loss: 0.16884243488311768
Validation loss: 1.6366953708792245

Epoch: 6| Step: 12
Training loss: 0.27449625730514526
Validation loss: 1.635729326996752

Epoch: 6| Step: 13
Training loss: 0.1919233798980713
Validation loss: 1.6402705997549079

Epoch: 430| Step: 0
Training loss: 0.09644002467393875
Validation loss: 1.6683375399599794

Epoch: 6| Step: 1
Training loss: 0.09816627204418182
Validation loss: 1.6451811303374588

Epoch: 6| Step: 2
Training loss: 0.12075363099575043
Validation loss: 1.6366522837710638

Epoch: 6| Step: 3
Training loss: 0.17931781709194183
Validation loss: 1.67313769684043

Epoch: 6| Step: 4
Training loss: 0.1994447261095047
Validation loss: 1.6834557428154895

Epoch: 6| Step: 5
Training loss: 0.10394458472728729
Validation loss: 1.6639666557312012

Epoch: 6| Step: 6
Training loss: 0.22830460965633392
Validation loss: 1.6470483445352124

Epoch: 6| Step: 7
Training loss: 0.2209506630897522
Validation loss: 1.6661372389844669

Epoch: 6| Step: 8
Training loss: 0.2363831102848053
Validation loss: 1.6383644791059597

Epoch: 6| Step: 9
Training loss: 0.35141807794570923
Validation loss: 1.6562532417235836

Epoch: 6| Step: 10
Training loss: 0.16359616816043854
Validation loss: 1.6576193917182185

Epoch: 6| Step: 11
Training loss: 0.15668372809886932
Validation loss: 1.6315981277855494

Epoch: 6| Step: 12
Training loss: 0.13904860615730286
Validation loss: 1.6262637697240359

Epoch: 6| Step: 13
Training loss: 0.27704980969429016
Validation loss: 1.6620924729172901

Epoch: 431| Step: 0
Training loss: 0.1584564745426178
Validation loss: 1.6620893811666837

Epoch: 6| Step: 1
Training loss: 0.2579277753829956
Validation loss: 1.6211134836237917

Epoch: 6| Step: 2
Training loss: 0.18530738353729248
Validation loss: 1.6252836360726306

Epoch: 6| Step: 3
Training loss: 0.16866850852966309
Validation loss: 1.612997765182167

Epoch: 6| Step: 4
Training loss: 0.12392649054527283
Validation loss: 1.6245707555483746

Epoch: 6| Step: 5
Training loss: 0.13727658987045288
Validation loss: 1.5870911921224287

Epoch: 6| Step: 6
Training loss: 0.3696710765361786
Validation loss: 1.607558652918826

Epoch: 6| Step: 7
Training loss: 0.11170554161071777
Validation loss: 1.6242367593191003

Epoch: 6| Step: 8
Training loss: 0.2058921754360199
Validation loss: 1.623803231023973

Epoch: 6| Step: 9
Training loss: 0.25222262740135193
Validation loss: 1.6171603452774785

Epoch: 6| Step: 10
Training loss: 0.10128653049468994
Validation loss: 1.617572014049817

Epoch: 6| Step: 11
Training loss: 0.12459960579872131
Validation loss: 1.6062790257956392

Epoch: 6| Step: 12
Training loss: 0.07889074087142944
Validation loss: 1.6119414465401762

Epoch: 6| Step: 13
Training loss: 0.2306186854839325
Validation loss: 1.6060353639305278

Epoch: 432| Step: 0
Training loss: 0.1516161412000656
Validation loss: 1.6436701538742229

Epoch: 6| Step: 1
Training loss: 0.09121152758598328
Validation loss: 1.6119031008853708

Epoch: 6| Step: 2
Training loss: 0.09777762740850449
Validation loss: 1.6403517774356309

Epoch: 6| Step: 3
Training loss: 0.2951069474220276
Validation loss: 1.6560901300881499

Epoch: 6| Step: 4
Training loss: 0.23776492476463318
Validation loss: 1.6628050881047403

Epoch: 6| Step: 5
Training loss: 0.22818607091903687
Validation loss: 1.6427763777394448

Epoch: 6| Step: 6
Training loss: 0.21579071879386902
Validation loss: 1.646938403447469

Epoch: 6| Step: 7
Training loss: 0.1416403353214264
Validation loss: 1.6179788843277962

Epoch: 6| Step: 8
Training loss: 0.11148732155561447
Validation loss: 1.6295077826387139

Epoch: 6| Step: 9
Training loss: 0.2026604861021042
Validation loss: 1.637818838960381

Epoch: 6| Step: 10
Training loss: 0.18060815334320068
Validation loss: 1.6488141693094724

Epoch: 6| Step: 11
Training loss: 0.14227500557899475
Validation loss: 1.6406132726259128

Epoch: 6| Step: 12
Training loss: 0.22034794092178345
Validation loss: 1.6315771379778463

Epoch: 6| Step: 13
Training loss: 0.2777727246284485
Validation loss: 1.6144022223769978

Epoch: 433| Step: 0
Training loss: 0.18528416752815247
Validation loss: 1.6477430123154835

Epoch: 6| Step: 1
Training loss: 0.11469577997922897
Validation loss: 1.6159270463451263

Epoch: 6| Step: 2
Training loss: 0.31890594959259033
Validation loss: 1.6087302443801716

Epoch: 6| Step: 3
Training loss: 0.11926909536123276
Validation loss: 1.575941962580527

Epoch: 6| Step: 4
Training loss: 0.142745703458786
Validation loss: 1.598851393627864

Epoch: 6| Step: 5
Training loss: 0.3211658298969269
Validation loss: 1.5948510144346504

Epoch: 6| Step: 6
Training loss: 0.1495344638824463
Validation loss: 1.5819925902992167

Epoch: 6| Step: 7
Training loss: 0.1561349630355835
Validation loss: 1.6156601995550177

Epoch: 6| Step: 8
Training loss: 0.18552269041538239
Validation loss: 1.6020519759065361

Epoch: 6| Step: 9
Training loss: 0.09920912981033325
Validation loss: 1.619259367706955

Epoch: 6| Step: 10
Training loss: 0.09657998383045197
Validation loss: 1.6205415956435665

Epoch: 6| Step: 11
Training loss: 0.18381178379058838
Validation loss: 1.62783565316149

Epoch: 6| Step: 12
Training loss: 0.1087343841791153
Validation loss: 1.6061986851435837

Epoch: 6| Step: 13
Training loss: 0.2784483730792999
Validation loss: 1.6421452670968988

Epoch: 434| Step: 0
Training loss: 0.1349097192287445
Validation loss: 1.6588013402877315

Epoch: 6| Step: 1
Training loss: 0.12818017601966858
Validation loss: 1.636847794696849

Epoch: 6| Step: 2
Training loss: 0.18776455521583557
Validation loss: 1.6578099689176005

Epoch: 6| Step: 3
Training loss: 0.09591708332300186
Validation loss: 1.6265099715161067

Epoch: 6| Step: 4
Training loss: 0.23370583355426788
Validation loss: 1.6189796091407858

Epoch: 6| Step: 5
Training loss: 0.10411706566810608
Validation loss: 1.6225036530084507

Epoch: 6| Step: 6
Training loss: 0.30905842781066895
Validation loss: 1.6076047356410692

Epoch: 6| Step: 7
Training loss: 0.19472169876098633
Validation loss: 1.6355618123085267

Epoch: 6| Step: 8
Training loss: 0.15619346499443054
Validation loss: 1.6545757657738143

Epoch: 6| Step: 9
Training loss: 0.18833252787590027
Validation loss: 1.625436077194829

Epoch: 6| Step: 10
Training loss: 0.1819523572921753
Validation loss: 1.6240646916051065

Epoch: 6| Step: 11
Training loss: 0.2585301399230957
Validation loss: 1.6233035954095985

Epoch: 6| Step: 12
Training loss: 0.15091203153133392
Validation loss: 1.6327148496463735

Epoch: 6| Step: 13
Training loss: 0.2065805345773697
Validation loss: 1.6568413485762894

Epoch: 435| Step: 0
Training loss: 0.07924506068229675
Validation loss: 1.6592723810544578

Epoch: 6| Step: 1
Training loss: 0.18284468352794647
Validation loss: 1.6484955831240582

Epoch: 6| Step: 2
Training loss: 0.14217916131019592
Validation loss: 1.627840744551792

Epoch: 6| Step: 3
Training loss: 0.10932739078998566
Validation loss: 1.6654801394349785

Epoch: 6| Step: 4
Training loss: 0.13135676085948944
Validation loss: 1.6741379845526911

Epoch: 6| Step: 5
Training loss: 0.15596990287303925
Validation loss: 1.6843701972756335

Epoch: 6| Step: 6
Training loss: 0.3209496736526489
Validation loss: 1.6642966680629279

Epoch: 6| Step: 7
Training loss: 0.2760946452617645
Validation loss: 1.6535305233411892

Epoch: 6| Step: 8
Training loss: 0.2266755998134613
Validation loss: 1.6445635454629057

Epoch: 6| Step: 9
Training loss: 0.20557326078414917
Validation loss: 1.6635261421562524

Epoch: 6| Step: 10
Training loss: 0.13885703682899475
Validation loss: 1.6455408065549788

Epoch: 6| Step: 11
Training loss: 0.20249603688716888
Validation loss: 1.6581214140820246

Epoch: 6| Step: 12
Training loss: 0.1819092333316803
Validation loss: 1.6417928921279086

Epoch: 6| Step: 13
Training loss: 0.23497891426086426
Validation loss: 1.6379681659001175

Epoch: 436| Step: 0
Training loss: 0.16592150926589966
Validation loss: 1.622744656378223

Epoch: 6| Step: 1
Training loss: 0.11056237667798996
Validation loss: 1.6278517451337589

Epoch: 6| Step: 2
Training loss: 0.25649571418762207
Validation loss: 1.6188754958491172

Epoch: 6| Step: 3
Training loss: 0.12142585963010788
Validation loss: 1.6206901124728623

Epoch: 6| Step: 4
Training loss: 0.26338592171669006
Validation loss: 1.637226681555471

Epoch: 6| Step: 5
Training loss: 0.1301496922969818
Validation loss: 1.640413229183484

Epoch: 6| Step: 6
Training loss: 0.1993882805109024
Validation loss: 1.6238154954807733

Epoch: 6| Step: 7
Training loss: 0.1406979262828827
Validation loss: 1.639573149783637

Epoch: 6| Step: 8
Training loss: 0.15896038711071014
Validation loss: 1.6209909794151143

Epoch: 6| Step: 9
Training loss: 0.18433839082717896
Validation loss: 1.6191919349854993

Epoch: 6| Step: 10
Training loss: 0.10644997656345367
Validation loss: 1.614477119138164

Epoch: 6| Step: 11
Training loss: 0.19055500626564026
Validation loss: 1.6150819986097273

Epoch: 6| Step: 12
Training loss: 0.19724828004837036
Validation loss: 1.6424814847207838

Epoch: 6| Step: 13
Training loss: 0.17464770376682281
Validation loss: 1.663229275775212

Epoch: 437| Step: 0
Training loss: 0.212620347738266
Validation loss: 1.6688039302825928

Epoch: 6| Step: 1
Training loss: 0.26735761761665344
Validation loss: 1.6513454068091609

Epoch: 6| Step: 2
Training loss: 0.203244149684906
Validation loss: 1.6672455431312643

Epoch: 6| Step: 3
Training loss: 0.18711335957050323
Validation loss: 1.6505007000379666

Epoch: 6| Step: 4
Training loss: 0.18961834907531738
Validation loss: 1.6370135327821136

Epoch: 6| Step: 5
Training loss: 0.2152448147535324
Validation loss: 1.6414645333443918

Epoch: 6| Step: 6
Training loss: 0.14430706202983856
Validation loss: 1.6157687415358841

Epoch: 6| Step: 7
Training loss: 0.1619189828634262
Validation loss: 1.6105560628316735

Epoch: 6| Step: 8
Training loss: 0.2060708850622177
Validation loss: 1.6111584055808283

Epoch: 6| Step: 9
Training loss: 0.10618186742067337
Validation loss: 1.6274165978995703

Epoch: 6| Step: 10
Training loss: 0.18785527348518372
Validation loss: 1.6227886933152393

Epoch: 6| Step: 11
Training loss: 0.15015023946762085
Validation loss: 1.6120375458912184

Epoch: 6| Step: 12
Training loss: 0.10936545580625534
Validation loss: 1.605648006803246

Epoch: 6| Step: 13
Training loss: 0.1868842989206314
Validation loss: 1.5917428475554272

Epoch: 438| Step: 0
Training loss: 0.29094693064689636
Validation loss: 1.61057694496647

Epoch: 6| Step: 1
Training loss: 0.1379554122686386
Validation loss: 1.6265613648199266

Epoch: 6| Step: 2
Training loss: 0.15878161787986755
Validation loss: 1.6434604262792936

Epoch: 6| Step: 3
Training loss: 0.2028907984495163
Validation loss: 1.6128418343041533

Epoch: 6| Step: 4
Training loss: 0.20179864764213562
Validation loss: 1.615473816471715

Epoch: 6| Step: 5
Training loss: 0.06610752642154694
Validation loss: 1.6041611151028705

Epoch: 6| Step: 6
Training loss: 0.137435182929039
Validation loss: 1.5904447494014617

Epoch: 6| Step: 7
Training loss: 0.17223845422267914
Validation loss: 1.5733010115162018

Epoch: 6| Step: 8
Training loss: 0.2490677684545517
Validation loss: 1.6016618769655946

Epoch: 6| Step: 9
Training loss: 0.09698913991451263
Validation loss: 1.5937415040949339

Epoch: 6| Step: 10
Training loss: 0.18228954076766968
Validation loss: 1.6043991914359472

Epoch: 6| Step: 11
Training loss: 0.21541345119476318
Validation loss: 1.5937727471833587

Epoch: 6| Step: 12
Training loss: 0.10331274569034576
Validation loss: 1.6196134756970149

Epoch: 6| Step: 13
Training loss: 0.09880729019641876
Validation loss: 1.5971910210065945

Epoch: 439| Step: 0
Training loss: 0.16438844799995422
Validation loss: 1.5969322753208939

Epoch: 6| Step: 1
Training loss: 0.08331137150526047
Validation loss: 1.6272316850641722

Epoch: 6| Step: 2
Training loss: 0.07233292609453201
Validation loss: 1.6163667466050835

Epoch: 6| Step: 3
Training loss: 0.28283149003982544
Validation loss: 1.6175336273767615

Epoch: 6| Step: 4
Training loss: 0.25089600682258606
Validation loss: 1.629501884983432

Epoch: 6| Step: 5
Training loss: 0.18291276693344116
Validation loss: 1.6396209962906376

Epoch: 6| Step: 6
Training loss: 0.15159183740615845
Validation loss: 1.621517163451

Epoch: 6| Step: 7
Training loss: 0.16835300624370575
Validation loss: 1.619174845757023

Epoch: 6| Step: 8
Training loss: 0.13283203542232513
Validation loss: 1.6334768931070964

Epoch: 6| Step: 9
Training loss: 0.15113839507102966
Validation loss: 1.6139800433189637

Epoch: 6| Step: 10
Training loss: 0.15252843499183655
Validation loss: 1.6253196885508876

Epoch: 6| Step: 11
Training loss: 0.16202571988105774
Validation loss: 1.6156839145127164

Epoch: 6| Step: 12
Training loss: 0.25068357586860657
Validation loss: 1.6189670947290236

Epoch: 6| Step: 13
Training loss: 0.08485803753137589
Validation loss: 1.6159242276222474

Epoch: 440| Step: 0
Training loss: 0.1693825125694275
Validation loss: 1.6300862963481615

Epoch: 6| Step: 1
Training loss: 0.10577013343572617
Validation loss: 1.5805981402756066

Epoch: 6| Step: 2
Training loss: 0.08950262516736984
Validation loss: 1.6226002503466863

Epoch: 6| Step: 3
Training loss: 0.16068536043167114
Validation loss: 1.5980650455720964

Epoch: 6| Step: 4
Training loss: 0.26016658544540405
Validation loss: 1.645500740697307

Epoch: 6| Step: 5
Training loss: 0.40571466088294983
Validation loss: 1.6019626073939826

Epoch: 6| Step: 6
Training loss: 0.1299733817577362
Validation loss: 1.6213339669730074

Epoch: 6| Step: 7
Training loss: 0.09903620183467865
Validation loss: 1.6140392063766398

Epoch: 6| Step: 8
Training loss: 0.10388139635324478
Validation loss: 1.5929811205915225

Epoch: 6| Step: 9
Training loss: 0.22877663373947144
Validation loss: 1.6186663726324677

Epoch: 6| Step: 10
Training loss: 0.12322373688220978
Validation loss: 1.6034599093980686

Epoch: 6| Step: 11
Training loss: 0.1533891260623932
Validation loss: 1.6134169729807044

Epoch: 6| Step: 12
Training loss: 0.175228089094162
Validation loss: 1.6219819720073412

Epoch: 6| Step: 13
Training loss: 0.3327344059944153
Validation loss: 1.615772993333878

Epoch: 441| Step: 0
Training loss: 0.17112895846366882
Validation loss: 1.5953135387871855

Epoch: 6| Step: 1
Training loss: 0.18041861057281494
Validation loss: 1.6091455374994585

Epoch: 6| Step: 2
Training loss: 0.0663633793592453
Validation loss: 1.6177499025098738

Epoch: 6| Step: 3
Training loss: 0.2357100546360016
Validation loss: 1.6451156934102376

Epoch: 6| Step: 4
Training loss: 0.1460966169834137
Validation loss: 1.6410859823226929

Epoch: 6| Step: 5
Training loss: 0.1701313853263855
Validation loss: 1.6273843883186259

Epoch: 6| Step: 6
Training loss: 0.17411327362060547
Validation loss: 1.6350358596412085

Epoch: 6| Step: 7
Training loss: 0.14091186225414276
Validation loss: 1.603585409861739

Epoch: 6| Step: 8
Training loss: 0.32435673475265503
Validation loss: 1.6093252307625228

Epoch: 6| Step: 9
Training loss: 0.07048188894987106
Validation loss: 1.6078884063228485

Epoch: 6| Step: 10
Training loss: 0.08167657256126404
Validation loss: 1.6145667350420387

Epoch: 6| Step: 11
Training loss: 0.37812477350234985
Validation loss: 1.6007301448493876

Epoch: 6| Step: 12
Training loss: 0.09565351158380508
Validation loss: 1.6481915789265786

Epoch: 6| Step: 13
Training loss: 0.14986902475357056
Validation loss: 1.6059988416651243

Epoch: 442| Step: 0
Training loss: 0.11801093816757202
Validation loss: 1.6391214119490756

Epoch: 6| Step: 1
Training loss: 0.11797326803207397
Validation loss: 1.6316979790246615

Epoch: 6| Step: 2
Training loss: 0.21502035856246948
Validation loss: 1.6302600804195608

Epoch: 6| Step: 3
Training loss: 0.09736446291208267
Validation loss: 1.6199694436083558

Epoch: 6| Step: 4
Training loss: 0.11055485904216766
Validation loss: 1.615242213331243

Epoch: 6| Step: 5
Training loss: 0.1655757874250412
Validation loss: 1.6198930022537068

Epoch: 6| Step: 6
Training loss: 0.160274937748909
Validation loss: 1.6214689464979275

Epoch: 6| Step: 7
Training loss: 0.15698012709617615
Validation loss: 1.6327929881311232

Epoch: 6| Step: 8
Training loss: 0.2731572091579437
Validation loss: 1.6332866017536452

Epoch: 6| Step: 9
Training loss: 0.13176466524600983
Validation loss: 1.601703873244665

Epoch: 6| Step: 10
Training loss: 0.24834051728248596
Validation loss: 1.6183257359330372

Epoch: 6| Step: 11
Training loss: 0.324413537979126
Validation loss: 1.5911999646053518

Epoch: 6| Step: 12
Training loss: 0.11345494538545609
Validation loss: 1.58810087942308

Epoch: 6| Step: 13
Training loss: 0.2916967272758484
Validation loss: 1.633578413276262

Epoch: 443| Step: 0
Training loss: 0.1056964173913002
Validation loss: 1.6119381637983425

Epoch: 6| Step: 1
Training loss: 0.08955995738506317
Validation loss: 1.6395644757055468

Epoch: 6| Step: 2
Training loss: 0.19856154918670654
Validation loss: 1.6547201769326323

Epoch: 6| Step: 3
Training loss: 0.2603670358657837
Validation loss: 1.6658540989762993

Epoch: 6| Step: 4
Training loss: 0.14965063333511353
Validation loss: 1.6601627385744484

Epoch: 6| Step: 5
Training loss: 0.3623534142971039
Validation loss: 1.6709509562420588

Epoch: 6| Step: 6
Training loss: 0.09521928429603577
Validation loss: 1.6771928879522509

Epoch: 6| Step: 7
Training loss: 0.18354831635951996
Validation loss: 1.6334692329488776

Epoch: 6| Step: 8
Training loss: 0.19168904423713684
Validation loss: 1.6416408887473486

Epoch: 6| Step: 9
Training loss: 0.17268690466880798
Validation loss: 1.6476785008625319

Epoch: 6| Step: 10
Training loss: 0.11655111610889435
Validation loss: 1.631231947611737

Epoch: 6| Step: 11
Training loss: 0.1902003437280655
Validation loss: 1.6281305782256588

Epoch: 6| Step: 12
Training loss: 0.18032662570476532
Validation loss: 1.633595379449988

Epoch: 6| Step: 13
Training loss: 0.25788694620132446
Validation loss: 1.6092467948954592

Epoch: 444| Step: 0
Training loss: 0.08981119096279144
Validation loss: 1.6263565363422516

Epoch: 6| Step: 1
Training loss: 0.14768671989440918
Validation loss: 1.5759180540679603

Epoch: 6| Step: 2
Training loss: 0.09019221365451813
Validation loss: 1.58896888584219

Epoch: 6| Step: 3
Training loss: 0.13364842534065247
Validation loss: 1.6202376145188526

Epoch: 6| Step: 4
Training loss: 0.19749978184700012
Validation loss: 1.598104400019492

Epoch: 6| Step: 5
Training loss: 0.17868614196777344
Validation loss: 1.6118988990783691

Epoch: 6| Step: 6
Training loss: 0.21007616817951202
Validation loss: 1.6401198256400324

Epoch: 6| Step: 7
Training loss: 0.08102889358997345
Validation loss: 1.6442960372535131

Epoch: 6| Step: 8
Training loss: 0.12787505984306335
Validation loss: 1.613214268479296

Epoch: 6| Step: 9
Training loss: 0.12668544054031372
Validation loss: 1.6209369026204592

Epoch: 6| Step: 10
Training loss: 0.23160824179649353
Validation loss: 1.6282957394917805

Epoch: 6| Step: 11
Training loss: 0.143079474568367
Validation loss: 1.6169535126737369

Epoch: 6| Step: 12
Training loss: 0.29929643869400024
Validation loss: 1.6077494390549198

Epoch: 6| Step: 13
Training loss: 0.1561288833618164
Validation loss: 1.593431386896359

Epoch: 445| Step: 0
Training loss: 0.09917203336954117
Validation loss: 1.5920842655243412

Epoch: 6| Step: 1
Training loss: 0.061206988990306854
Validation loss: 1.622169921475072

Epoch: 6| Step: 2
Training loss: 0.15788117051124573
Validation loss: 1.6172287617960284

Epoch: 6| Step: 3
Training loss: 0.12506204843521118
Validation loss: 1.60270599139634

Epoch: 6| Step: 4
Training loss: 0.4760974049568176
Validation loss: 1.6240364941217567

Epoch: 6| Step: 5
Training loss: 0.10128572583198547
Validation loss: 1.629315814664287

Epoch: 6| Step: 6
Training loss: 0.1123015433549881
Validation loss: 1.6201168260266703

Epoch: 6| Step: 7
Training loss: 0.14491787552833557
Validation loss: 1.6088025557097567

Epoch: 6| Step: 8
Training loss: 0.0794801414012909
Validation loss: 1.6198048463431738

Epoch: 6| Step: 9
Training loss: 0.22824130952358246
Validation loss: 1.6206652682314637

Epoch: 6| Step: 10
Training loss: 0.2104150950908661
Validation loss: 1.6458035540837113

Epoch: 6| Step: 11
Training loss: 0.15117233991622925
Validation loss: 1.6465747971688547

Epoch: 6| Step: 12
Training loss: 0.14014732837677002
Validation loss: 1.6446220650467822

Epoch: 6| Step: 13
Training loss: 0.03839804232120514
Validation loss: 1.6644819974899292

Epoch: 446| Step: 0
Training loss: 0.13112501800060272
Validation loss: 1.700524204520769

Epoch: 6| Step: 1
Training loss: 0.1608007550239563
Validation loss: 1.677239553902739

Epoch: 6| Step: 2
Training loss: 0.12856656312942505
Validation loss: 1.671373753137486

Epoch: 6| Step: 3
Training loss: 0.13738581538200378
Validation loss: 1.6802275693544777

Epoch: 6| Step: 4
Training loss: 0.08091716468334198
Validation loss: 1.6721498299670476

Epoch: 6| Step: 5
Training loss: 0.1772487461566925
Validation loss: 1.6314988424701076

Epoch: 6| Step: 6
Training loss: 0.11689896136522293
Validation loss: 1.6416342514817432

Epoch: 6| Step: 7
Training loss: 0.09536711126565933
Validation loss: 1.6122314840234735

Epoch: 6| Step: 8
Training loss: 0.30224013328552246
Validation loss: 1.6260629405257523

Epoch: 6| Step: 9
Training loss: 0.21543069183826447
Validation loss: 1.641583308096855

Epoch: 6| Step: 10
Training loss: 0.13481275737285614
Validation loss: 1.6352151568217943

Epoch: 6| Step: 11
Training loss: 0.2323310524225235
Validation loss: 1.6197414962194299

Epoch: 6| Step: 12
Training loss: 0.10755972564220428
Validation loss: 1.646960005965284

Epoch: 6| Step: 13
Training loss: 0.11951139569282532
Validation loss: 1.6534251346383044

Epoch: 447| Step: 0
Training loss: 0.14892004430294037
Validation loss: 1.6568907730041011

Epoch: 6| Step: 1
Training loss: 0.2750816345214844
Validation loss: 1.6635906593773955

Epoch: 6| Step: 2
Training loss: 0.12071289867162704
Validation loss: 1.6586108822976389

Epoch: 6| Step: 3
Training loss: 0.1815899759531021
Validation loss: 1.6809515953063965

Epoch: 6| Step: 4
Training loss: 0.13054300844669342
Validation loss: 1.6988853985263455

Epoch: 6| Step: 5
Training loss: 0.13380587100982666
Validation loss: 1.6929075858926261

Epoch: 6| Step: 6
Training loss: 0.30332791805267334
Validation loss: 1.7014762368253482

Epoch: 6| Step: 7
Training loss: 0.1830514669418335
Validation loss: 1.6978232424746278

Epoch: 6| Step: 8
Training loss: 0.24126778542995453
Validation loss: 1.6962733678920294

Epoch: 6| Step: 9
Training loss: 0.08472084999084473
Validation loss: 1.6539568260151853

Epoch: 6| Step: 10
Training loss: 0.1854884773492813
Validation loss: 1.6818200401080552

Epoch: 6| Step: 11
Training loss: 0.1270231157541275
Validation loss: 1.6726586767422256

Epoch: 6| Step: 12
Training loss: 0.11016620695590973
Validation loss: 1.640131281268212

Epoch: 6| Step: 13
Training loss: 0.09354013949632645
Validation loss: 1.6844135535660612

Epoch: 448| Step: 0
Training loss: 0.31920766830444336
Validation loss: 1.6815051673561014

Epoch: 6| Step: 1
Training loss: 0.11423134058713913
Validation loss: 1.688369051102669

Epoch: 6| Step: 2
Training loss: 0.1180492639541626
Validation loss: 1.7095058451416671

Epoch: 6| Step: 3
Training loss: 0.08883710950613022
Validation loss: 1.6759552571081346

Epoch: 6| Step: 4
Training loss: 0.18662169575691223
Validation loss: 1.6886642658582298

Epoch: 6| Step: 5
Training loss: 0.3399887979030609
Validation loss: 1.699043663599158

Epoch: 6| Step: 6
Training loss: 0.18146350979804993
Validation loss: 1.6569652429191015

Epoch: 6| Step: 7
Training loss: 0.1847783327102661
Validation loss: 1.6975601360362063

Epoch: 6| Step: 8
Training loss: 0.11375649273395538
Validation loss: 1.6651922874553229

Epoch: 6| Step: 9
Training loss: 0.1117134839296341
Validation loss: 1.6342255838455693

Epoch: 6| Step: 10
Training loss: 0.1417360007762909
Validation loss: 1.6586435764066634

Epoch: 6| Step: 11
Training loss: 0.1711914837360382
Validation loss: 1.6327209716202111

Epoch: 6| Step: 12
Training loss: 0.26117977499961853
Validation loss: 1.6598282546125434

Epoch: 6| Step: 13
Training loss: 0.16724304854869843
Validation loss: 1.6818240765602357

Epoch: 449| Step: 0
Training loss: 0.36171022057533264
Validation loss: 1.6789650314597673

Epoch: 6| Step: 1
Training loss: 0.1206306666135788
Validation loss: 1.6752768908777544

Epoch: 6| Step: 2
Training loss: 0.09081857651472092
Validation loss: 1.6929635719586444

Epoch: 6| Step: 3
Training loss: 0.215449720621109
Validation loss: 1.6788186091248707

Epoch: 6| Step: 4
Training loss: 0.14486852288246155
Validation loss: 1.6636886583861483

Epoch: 6| Step: 5
Training loss: 0.21621032059192657
Validation loss: 1.68355695919324

Epoch: 6| Step: 6
Training loss: 0.10706093162298203
Validation loss: 1.6733937821080607

Epoch: 6| Step: 7
Training loss: 0.19739076495170593
Validation loss: 1.6745151768448532

Epoch: 6| Step: 8
Training loss: 0.08726096898317337
Validation loss: 1.6845420483619935

Epoch: 6| Step: 9
Training loss: 0.14705732464790344
Validation loss: 1.6398399491463937

Epoch: 6| Step: 10
Training loss: 0.17113542556762695
Validation loss: 1.67308598051789

Epoch: 6| Step: 11
Training loss: 0.20856600999832153
Validation loss: 1.683834215646149

Epoch: 6| Step: 12
Training loss: 0.19964629411697388
Validation loss: 1.6733192730975408

Epoch: 6| Step: 13
Training loss: 0.08473891764879227
Validation loss: 1.6670473621737572

Epoch: 450| Step: 0
Training loss: 0.17455482482910156
Validation loss: 1.6520911557700044

Epoch: 6| Step: 1
Training loss: 0.09204397350549698
Validation loss: 1.6602812697810512

Epoch: 6| Step: 2
Training loss: 0.13017751276493073
Validation loss: 1.6929792050392396

Epoch: 6| Step: 3
Training loss: 0.1282126009464264
Validation loss: 1.662364254715622

Epoch: 6| Step: 4
Training loss: 0.21257489919662476
Validation loss: 1.6714920895074004

Epoch: 6| Step: 5
Training loss: 0.10630889236927032
Validation loss: 1.664946222818026

Epoch: 6| Step: 6
Training loss: 0.21089541912078857
Validation loss: 1.6477141149582402

Epoch: 6| Step: 7
Training loss: 0.10346603393554688
Validation loss: 1.6564966965747137

Epoch: 6| Step: 8
Training loss: 0.1658981740474701
Validation loss: 1.671432448971656

Epoch: 6| Step: 9
Training loss: 0.16082704067230225
Validation loss: 1.696149900395383

Epoch: 6| Step: 10
Training loss: 0.20930905640125275
Validation loss: 1.6674601429252214

Epoch: 6| Step: 11
Training loss: 0.18755687773227692
Validation loss: 1.6405283789480887

Epoch: 6| Step: 12
Training loss: 0.22117196023464203
Validation loss: 1.6516202483125912

Epoch: 6| Step: 13
Training loss: 0.22835636138916016
Validation loss: 1.6628359376743276

Epoch: 451| Step: 0
Training loss: 0.13342101871967316
Validation loss: 1.667354251748772

Epoch: 6| Step: 1
Training loss: 0.11480202525854111
Validation loss: 1.692579125845304

Epoch: 6| Step: 2
Training loss: 0.11774565279483795
Validation loss: 1.6810288070350565

Epoch: 6| Step: 3
Training loss: 0.15128998458385468
Validation loss: 1.6869101126988728

Epoch: 6| Step: 4
Training loss: 0.13212880492210388
Validation loss: 1.6833409737515193

Epoch: 6| Step: 5
Training loss: 0.37493884563446045
Validation loss: 1.695091547504548

Epoch: 6| Step: 6
Training loss: 0.16865113377571106
Validation loss: 1.6935349959199146

Epoch: 6| Step: 7
Training loss: 0.24509641528129578
Validation loss: 1.6843588685476651

Epoch: 6| Step: 8
Training loss: 0.23172107338905334
Validation loss: 1.7025695129107403

Epoch: 6| Step: 9
Training loss: 0.1816113293170929
Validation loss: 1.663329291087325

Epoch: 6| Step: 10
Training loss: 0.1371036171913147
Validation loss: 1.6227760968669769

Epoch: 6| Step: 11
Training loss: 0.06242554634809494
Validation loss: 1.6547953236487605

Epoch: 6| Step: 12
Training loss: 0.20703855156898499
Validation loss: 1.6196606966757006

Epoch: 6| Step: 13
Training loss: 0.14845654368400574
Validation loss: 1.6600735366985362

Epoch: 452| Step: 0
Training loss: 0.09760655462741852
Validation loss: 1.6317662077565347

Epoch: 6| Step: 1
Training loss: 0.12876874208450317
Validation loss: 1.605279702012257

Epoch: 6| Step: 2
Training loss: 0.15239620208740234
Validation loss: 1.6348816220478346

Epoch: 6| Step: 3
Training loss: 0.059697747230529785
Validation loss: 1.6250197938693467

Epoch: 6| Step: 4
Training loss: 0.17300686240196228
Validation loss: 1.643850185537851

Epoch: 6| Step: 5
Training loss: 0.15674158930778503
Validation loss: 1.6456156212796447

Epoch: 6| Step: 6
Training loss: 0.2277122586965561
Validation loss: 1.6425393037898566

Epoch: 6| Step: 7
Training loss: 0.2496497929096222
Validation loss: 1.659349581246735

Epoch: 6| Step: 8
Training loss: 0.13978932797908783
Validation loss: 1.6840874213044361

Epoch: 6| Step: 9
Training loss: 0.15021800994873047
Validation loss: 1.6864499994503555

Epoch: 6| Step: 10
Training loss: 0.3994814157485962
Validation loss: 1.6856138462661414

Epoch: 6| Step: 11
Training loss: 0.08786790072917938
Validation loss: 1.6705148271335069

Epoch: 6| Step: 12
Training loss: 0.1561177372932434
Validation loss: 1.6471920269791798

Epoch: 6| Step: 13
Training loss: 0.07324882596731186
Validation loss: 1.6388240450172014

Epoch: 453| Step: 0
Training loss: 0.12507745623588562
Validation loss: 1.6765079466245507

Epoch: 6| Step: 1
Training loss: 0.19764859974384308
Validation loss: 1.6442982278844362

Epoch: 6| Step: 2
Training loss: 0.14303548634052277
Validation loss: 1.6622594543682632

Epoch: 6| Step: 3
Training loss: 0.18625394999980927
Validation loss: 1.6533348765424503

Epoch: 6| Step: 4
Training loss: 0.10107795894145966
Validation loss: 1.657638943323525

Epoch: 6| Step: 5
Training loss: 0.1516776978969574
Validation loss: 1.6470082408638411

Epoch: 6| Step: 6
Training loss: 0.15390431880950928
Validation loss: 1.6507096649498068

Epoch: 6| Step: 7
Training loss: 0.16438929736614227
Validation loss: 1.6274565048115228

Epoch: 6| Step: 8
Training loss: 0.1294988989830017
Validation loss: 1.6072334153677827

Epoch: 6| Step: 9
Training loss: 0.33471667766571045
Validation loss: 1.6170660238112173

Epoch: 6| Step: 10
Training loss: 0.10182467103004456
Validation loss: 1.6420345588396954

Epoch: 6| Step: 11
Training loss: 0.12238230556249619
Validation loss: 1.6487304715700046

Epoch: 6| Step: 12
Training loss: 0.21656687557697296
Validation loss: 1.6507954802564395

Epoch: 6| Step: 13
Training loss: 0.21416956186294556
Validation loss: 1.6308599723282682

Epoch: 454| Step: 0
Training loss: 0.09195784479379654
Validation loss: 1.6537606485428349

Epoch: 6| Step: 1
Training loss: 0.19346171617507935
Validation loss: 1.6383800865501486

Epoch: 6| Step: 2
Training loss: 0.1476176530122757
Validation loss: 1.629838267962138

Epoch: 6| Step: 3
Training loss: 0.278796523809433
Validation loss: 1.654571080720553

Epoch: 6| Step: 4
Training loss: 0.1286141723394394
Validation loss: 1.6777035036394674

Epoch: 6| Step: 5
Training loss: 0.15364190936088562
Validation loss: 1.635325372859996

Epoch: 6| Step: 6
Training loss: 0.21413645148277283
Validation loss: 1.6562676391293925

Epoch: 6| Step: 7
Training loss: 0.14833247661590576
Validation loss: 1.6525390430163311

Epoch: 6| Step: 8
Training loss: 0.12414257973432541
Validation loss: 1.6578057581378567

Epoch: 6| Step: 9
Training loss: 0.16451239585876465
Validation loss: 1.6621153828918294

Epoch: 6| Step: 10
Training loss: 0.13575679063796997
Validation loss: 1.6389102499972108

Epoch: 6| Step: 11
Training loss: 0.08017954975366592
Validation loss: 1.6552968807117914

Epoch: 6| Step: 12
Training loss: 0.0652686282992363
Validation loss: 1.6193111788841985

Epoch: 6| Step: 13
Training loss: 0.08158102631568909
Validation loss: 1.6315148197194582

Epoch: 455| Step: 0
Training loss: 0.2717030942440033
Validation loss: 1.650241751824656

Epoch: 6| Step: 1
Training loss: 0.08280828595161438
Validation loss: 1.6535983059995918

Epoch: 6| Step: 2
Training loss: 0.13258028030395508
Validation loss: 1.6531991067753042

Epoch: 6| Step: 3
Training loss: 0.0912826806306839
Validation loss: 1.6512102234748103

Epoch: 6| Step: 4
Training loss: 0.26323145627975464
Validation loss: 1.7032113985348774

Epoch: 6| Step: 5
Training loss: 0.20340579748153687
Validation loss: 1.7173348126872894

Epoch: 6| Step: 6
Training loss: 0.33150479197502136
Validation loss: 1.693112672657095

Epoch: 6| Step: 7
Training loss: 0.18604716658592224
Validation loss: 1.687062176324988

Epoch: 6| Step: 8
Training loss: 0.11353334784507751
Validation loss: 1.649140061870698

Epoch: 6| Step: 9
Training loss: 0.15849140286445618
Validation loss: 1.633943175756803

Epoch: 6| Step: 10
Training loss: 0.23621992766857147
Validation loss: 1.6244349159220213

Epoch: 6| Step: 11
Training loss: 0.15151429176330566
Validation loss: 1.61390676934232

Epoch: 6| Step: 12
Training loss: 0.22671714425086975
Validation loss: 1.6010291461021668

Epoch: 6| Step: 13
Training loss: 0.19676509499549866
Validation loss: 1.5998472526509275

Epoch: 456| Step: 0
Training loss: 0.1883348822593689
Validation loss: 1.6058788094469296

Epoch: 6| Step: 1
Training loss: 0.13611923158168793
Validation loss: 1.6256520414865145

Epoch: 6| Step: 2
Training loss: 0.23688894510269165
Validation loss: 1.601008959995803

Epoch: 6| Step: 3
Training loss: 0.16524629294872284
Validation loss: 1.6279274750781316

Epoch: 6| Step: 4
Training loss: 0.1514260172843933
Validation loss: 1.6337003887340587

Epoch: 6| Step: 5
Training loss: 0.11253861337900162
Validation loss: 1.6304225370448122

Epoch: 6| Step: 6
Training loss: 0.199159175157547
Validation loss: 1.6641753155698058

Epoch: 6| Step: 7
Training loss: 0.08404318988323212
Validation loss: 1.6495071226550686

Epoch: 6| Step: 8
Training loss: 0.16447842121124268
Validation loss: 1.629770448130946

Epoch: 6| Step: 9
Training loss: 0.1995004266500473
Validation loss: 1.6405212212634344

Epoch: 6| Step: 10
Training loss: 0.21561460196971893
Validation loss: 1.6613105471416185

Epoch: 6| Step: 11
Training loss: 0.2391391545534134
Validation loss: 1.6477036976045178

Epoch: 6| Step: 12
Training loss: 0.15371157228946686
Validation loss: 1.6525003294790945

Epoch: 6| Step: 13
Training loss: 0.11619716137647629
Validation loss: 1.6751921407638057

Epoch: 457| Step: 0
Training loss: 0.16042865812778473
Validation loss: 1.6651737292607625

Epoch: 6| Step: 1
Training loss: 0.19574692845344543
Validation loss: 1.665398346480503

Epoch: 6| Step: 2
Training loss: 0.08933262526988983
Validation loss: 1.6536990058037542

Epoch: 6| Step: 3
Training loss: 0.23575949668884277
Validation loss: 1.6392447487000497

Epoch: 6| Step: 4
Training loss: 0.14568182826042175
Validation loss: 1.6504580872033232

Epoch: 6| Step: 5
Training loss: 0.13075509667396545
Validation loss: 1.6671185237105175

Epoch: 6| Step: 6
Training loss: 0.20316949486732483
Validation loss: 1.6815026883156068

Epoch: 6| Step: 7
Training loss: 0.13920122385025024
Validation loss: 1.7031489162034885

Epoch: 6| Step: 8
Training loss: 0.1351279616355896
Validation loss: 1.659314094692148

Epoch: 6| Step: 9
Training loss: 0.13851019740104675
Validation loss: 1.655053448933427

Epoch: 6| Step: 10
Training loss: 0.1026710718870163
Validation loss: 1.6401964618313698

Epoch: 6| Step: 11
Training loss: 0.2331216037273407
Validation loss: 1.6498807425140052

Epoch: 6| Step: 12
Training loss: 0.1193452924489975
Validation loss: 1.646753695703322

Epoch: 6| Step: 13
Training loss: 0.15313118696212769
Validation loss: 1.6479720684789843

Epoch: 458| Step: 0
Training loss: 0.23820824921131134
Validation loss: 1.6545274052568661

Epoch: 6| Step: 1
Training loss: 0.1310650110244751
Validation loss: 1.6646928325776131

Epoch: 6| Step: 2
Training loss: 0.13217467069625854
Validation loss: 1.662864787604219

Epoch: 6| Step: 3
Training loss: 0.2042670100927353
Validation loss: 1.6750365418772544

Epoch: 6| Step: 4
Training loss: 0.1396891474723816
Validation loss: 1.6721554058854298

Epoch: 6| Step: 5
Training loss: 0.1876154989004135
Validation loss: 1.6687884510204356

Epoch: 6| Step: 6
Training loss: 0.12455597519874573
Validation loss: 1.6785826759953653

Epoch: 6| Step: 7
Training loss: 0.1687331199645996
Validation loss: 1.6718826755400626

Epoch: 6| Step: 8
Training loss: 0.22501133382320404
Validation loss: 1.6322712872617988

Epoch: 6| Step: 9
Training loss: 0.1839766800403595
Validation loss: 1.6521695352369739

Epoch: 6| Step: 10
Training loss: 0.19783367216587067
Validation loss: 1.6487333415656962

Epoch: 6| Step: 11
Training loss: 0.08643186837434769
Validation loss: 1.647462406466084

Epoch: 6| Step: 12
Training loss: 0.09928343445062637
Validation loss: 1.6443822153152958

Epoch: 6| Step: 13
Training loss: 0.5337592363357544
Validation loss: 1.6710793151650378

Epoch: 459| Step: 0
Training loss: 0.11715587228536606
Validation loss: 1.667970254857053

Epoch: 6| Step: 1
Training loss: 0.1292973756790161
Validation loss: 1.6572552124659221

Epoch: 6| Step: 2
Training loss: 0.24642162024974823
Validation loss: 1.6619438176514

Epoch: 6| Step: 3
Training loss: 0.16288651525974274
Validation loss: 1.648837116456801

Epoch: 6| Step: 4
Training loss: 0.1440725028514862
Validation loss: 1.684172115018291

Epoch: 6| Step: 5
Training loss: 0.23590706288814545
Validation loss: 1.6656830887640677

Epoch: 6| Step: 6
Training loss: 0.3639964759349823
Validation loss: 1.6726025458305114

Epoch: 6| Step: 7
Training loss: 0.15541699528694153
Validation loss: 1.6971756232682096

Epoch: 6| Step: 8
Training loss: 0.16775712370872498
Validation loss: 1.7107627878906906

Epoch: 6| Step: 9
Training loss: 0.09885070472955704
Validation loss: 1.6919520644731418

Epoch: 6| Step: 10
Training loss: 0.2039870172739029
Validation loss: 1.68011095446925

Epoch: 6| Step: 11
Training loss: 0.15113897621631622
Validation loss: 1.6725612776253813

Epoch: 6| Step: 12
Training loss: 0.14332301914691925
Validation loss: 1.6572117792662753

Epoch: 6| Step: 13
Training loss: 0.12424089014530182
Validation loss: 1.6618696053822835

Epoch: 460| Step: 0
Training loss: 0.1699732542037964
Validation loss: 1.677223147884492

Epoch: 6| Step: 1
Training loss: 0.1127462163567543
Validation loss: 1.6548049142283778

Epoch: 6| Step: 2
Training loss: 0.16271378099918365
Validation loss: 1.6490765425466722

Epoch: 6| Step: 3
Training loss: 0.12170776724815369
Validation loss: 1.65513043057534

Epoch: 6| Step: 4
Training loss: 0.18029473721981049
Validation loss: 1.6066775706506544

Epoch: 6| Step: 5
Training loss: 0.121256023645401
Validation loss: 1.6349267036684099

Epoch: 6| Step: 6
Training loss: 0.15932652354240417
Validation loss: 1.5827389788883988

Epoch: 6| Step: 7
Training loss: 0.20330151915550232
Validation loss: 1.6203471370922622

Epoch: 6| Step: 8
Training loss: 0.14051789045333862
Validation loss: 1.6221213379213888

Epoch: 6| Step: 9
Training loss: 0.30141961574554443
Validation loss: 1.5997084366377963

Epoch: 6| Step: 10
Training loss: 0.18415963649749756
Validation loss: 1.643663844754619

Epoch: 6| Step: 11
Training loss: 0.09598970413208008
Validation loss: 1.652429155124131

Epoch: 6| Step: 12
Training loss: 0.1566438525915146
Validation loss: 1.6453204597196271

Epoch: 6| Step: 13
Training loss: 0.11862729489803314
Validation loss: 1.6528011272030492

Epoch: 461| Step: 0
Training loss: 0.06730612367391586
Validation loss: 1.6460174514401344

Epoch: 6| Step: 1
Training loss: 0.13751864433288574
Validation loss: 1.665776853920311

Epoch: 6| Step: 2
Training loss: 0.14642944931983948
Validation loss: 1.6698971409951486

Epoch: 6| Step: 3
Training loss: 0.23606310784816742
Validation loss: 1.6580396724003617

Epoch: 6| Step: 4
Training loss: 0.21262431144714355
Validation loss: 1.6308133486778504

Epoch: 6| Step: 5
Training loss: 0.120831198990345
Validation loss: 1.604184360914333

Epoch: 6| Step: 6
Training loss: 0.23661410808563232
Validation loss: 1.6298068505461498

Epoch: 6| Step: 7
Training loss: 0.13531258702278137
Validation loss: 1.6225086296758344

Epoch: 6| Step: 8
Training loss: 0.18940255045890808
Validation loss: 1.6016846984945319

Epoch: 6| Step: 9
Training loss: 0.12509992718696594
Validation loss: 1.608509922540316

Epoch: 6| Step: 10
Training loss: 0.16662588715553284
Validation loss: 1.6181920010556456

Epoch: 6| Step: 11
Training loss: 0.19688530266284943
Validation loss: 1.6161137191198205

Epoch: 6| Step: 12
Training loss: 0.1593695878982544
Validation loss: 1.6210955233984097

Epoch: 6| Step: 13
Training loss: 0.09711851179599762
Validation loss: 1.611929444856541

Epoch: 462| Step: 0
Training loss: 0.09630495309829712
Validation loss: 1.6162586378794845

Epoch: 6| Step: 1
Training loss: 0.14512649178504944
Validation loss: 1.600368481810375

Epoch: 6| Step: 2
Training loss: 0.1459265500307083
Validation loss: 1.6186877565999185

Epoch: 6| Step: 3
Training loss: 0.13834042847156525
Validation loss: 1.6158896787192232

Epoch: 6| Step: 4
Training loss: 0.13794860243797302
Validation loss: 1.624788547074923

Epoch: 6| Step: 5
Training loss: 0.2204062044620514
Validation loss: 1.6386887719554286

Epoch: 6| Step: 6
Training loss: 0.29984980821609497
Validation loss: 1.6008473814174693

Epoch: 6| Step: 7
Training loss: 0.10716363787651062
Validation loss: 1.6356194942228255

Epoch: 6| Step: 8
Training loss: 0.22770632803440094
Validation loss: 1.6448712259210565

Epoch: 6| Step: 9
Training loss: 0.15165108442306519
Validation loss: 1.6538421107876686

Epoch: 6| Step: 10
Training loss: 0.06371504068374634
Validation loss: 1.6381716036027478

Epoch: 6| Step: 11
Training loss: 0.15443383157253265
Validation loss: 1.6414889904760546

Epoch: 6| Step: 12
Training loss: 0.16607022285461426
Validation loss: 1.6606798697543401

Epoch: 6| Step: 13
Training loss: 0.11675400286912918
Validation loss: 1.6550451709378151

Epoch: 463| Step: 0
Training loss: 0.13683876395225525
Validation loss: 1.6532182860118088

Epoch: 6| Step: 1
Training loss: 0.1422121822834015
Validation loss: 1.6271144126051216

Epoch: 6| Step: 2
Training loss: 0.08053654432296753
Validation loss: 1.6403553216688094

Epoch: 6| Step: 3
Training loss: 0.34336602687835693
Validation loss: 1.6547955787310036

Epoch: 6| Step: 4
Training loss: 0.13606560230255127
Validation loss: 1.63887345662681

Epoch: 6| Step: 5
Training loss: 0.1770012229681015
Validation loss: 1.6590626085958173

Epoch: 6| Step: 6
Training loss: 0.18527045845985413
Validation loss: 1.6782687235903997

Epoch: 6| Step: 7
Training loss: 0.21141603589057922
Validation loss: 1.6536046894647742

Epoch: 6| Step: 8
Training loss: 0.09085947275161743
Validation loss: 1.6470238649716942

Epoch: 6| Step: 9
Training loss: 0.20172515511512756
Validation loss: 1.6123209140634025

Epoch: 6| Step: 10
Training loss: 0.09510564804077148
Validation loss: 1.5967295221103135

Epoch: 6| Step: 11
Training loss: 0.26513856649398804
Validation loss: 1.5780300068598923

Epoch: 6| Step: 12
Training loss: 0.2245229184627533
Validation loss: 1.6038068802125993

Epoch: 6| Step: 13
Training loss: 0.14765959978103638
Validation loss: 1.6015166672327186

Epoch: 464| Step: 0
Training loss: 0.2139064073562622
Validation loss: 1.6266988605581305

Epoch: 6| Step: 1
Training loss: 0.08151525259017944
Validation loss: 1.6156856718883719

Epoch: 6| Step: 2
Training loss: 0.07756327837705612
Validation loss: 1.6108761666923441

Epoch: 6| Step: 3
Training loss: 0.10058391839265823
Validation loss: 1.5959854984796176

Epoch: 6| Step: 4
Training loss: 0.12729720771312714
Validation loss: 1.6086265540892077

Epoch: 6| Step: 5
Training loss: 0.23195937275886536
Validation loss: 1.5826712244300432

Epoch: 6| Step: 6
Training loss: 0.12230058014392853
Validation loss: 1.5784516014078611

Epoch: 6| Step: 7
Training loss: 0.10062672197818756
Validation loss: 1.5927792364551174

Epoch: 6| Step: 8
Training loss: 0.12467887997627258
Validation loss: 1.578664356662381

Epoch: 6| Step: 9
Training loss: 0.27386170625686646
Validation loss: 1.6046091100221038

Epoch: 6| Step: 10
Training loss: 0.14958907663822174
Validation loss: 1.5982523784842542

Epoch: 6| Step: 11
Training loss: 0.28636014461517334
Validation loss: 1.5922645445792907

Epoch: 6| Step: 12
Training loss: 0.14231564104557037
Validation loss: 1.617547123662887

Epoch: 6| Step: 13
Training loss: 0.09873095154762268
Validation loss: 1.6097670101350354

Epoch: 465| Step: 0
Training loss: 0.07069695740938187
Validation loss: 1.6012559744619554

Epoch: 6| Step: 1
Training loss: 0.2786572575569153
Validation loss: 1.5848862432664441

Epoch: 6| Step: 2
Training loss: 0.1184057667851448
Validation loss: 1.5835094003267185

Epoch: 6| Step: 3
Training loss: 0.22524787485599518
Validation loss: 1.5728006311642226

Epoch: 6| Step: 4
Training loss: 0.07451276481151581
Validation loss: 1.5888826180529851

Epoch: 6| Step: 5
Training loss: 0.2514040470123291
Validation loss: 1.5938067564400293

Epoch: 6| Step: 6
Training loss: 0.12010827660560608
Validation loss: 1.5876662538897606

Epoch: 6| Step: 7
Training loss: 0.1561734527349472
Validation loss: 1.609475920277257

Epoch: 6| Step: 8
Training loss: 0.10623317211866379
Validation loss: 1.6088792201011413

Epoch: 6| Step: 9
Training loss: 0.18813571333885193
Validation loss: 1.5819266393620481

Epoch: 6| Step: 10
Training loss: 0.1932961642742157
Validation loss: 1.5762763151558496

Epoch: 6| Step: 11
Training loss: 0.13004425168037415
Validation loss: 1.5798786506857923

Epoch: 6| Step: 12
Training loss: 0.14621515572071075
Validation loss: 1.6026730998869865

Epoch: 6| Step: 13
Training loss: 0.1470009684562683
Validation loss: 1.5965095399528422

Epoch: 466| Step: 0
Training loss: 0.1564323753118515
Validation loss: 1.598713715871175

Epoch: 6| Step: 1
Training loss: 0.1148621067404747
Validation loss: 1.611844906242945

Epoch: 6| Step: 2
Training loss: 0.0843949094414711
Validation loss: 1.622588481954349

Epoch: 6| Step: 3
Training loss: 0.06462609767913818
Validation loss: 1.6411663793748426

Epoch: 6| Step: 4
Training loss: 0.11949877440929413
Validation loss: 1.6408817883460753

Epoch: 6| Step: 5
Training loss: 0.2003217190504074
Validation loss: 1.629484203553969

Epoch: 6| Step: 6
Training loss: 0.16984789073467255
Validation loss: 1.6086197117323517

Epoch: 6| Step: 7
Training loss: 0.11365138739347458
Validation loss: 1.6096781825506559

Epoch: 6| Step: 8
Training loss: 0.18602102994918823
Validation loss: 1.6183493086086806

Epoch: 6| Step: 9
Training loss: 0.15390649437904358
Validation loss: 1.6219598106158677

Epoch: 6| Step: 10
Training loss: 0.12604880332946777
Validation loss: 1.6153509924488683

Epoch: 6| Step: 11
Training loss: 0.1386299729347229
Validation loss: 1.6279117791883406

Epoch: 6| Step: 12
Training loss: 0.27156275510787964
Validation loss: 1.5905501752771356

Epoch: 6| Step: 13
Training loss: 0.10926419496536255
Validation loss: 1.6310109630707772

Epoch: 467| Step: 0
Training loss: 0.16214817762374878
Validation loss: 1.6045139246089484

Epoch: 6| Step: 1
Training loss: 0.12105214595794678
Validation loss: 1.6043498234082294

Epoch: 6| Step: 2
Training loss: 0.10456518828868866
Validation loss: 1.5611823310134232

Epoch: 6| Step: 3
Training loss: 0.1165342777967453
Validation loss: 1.5966086983680725

Epoch: 6| Step: 4
Training loss: 0.063820481300354
Validation loss: 1.580684211946303

Epoch: 6| Step: 5
Training loss: 0.06296481192111969
Validation loss: 1.5783625059230353

Epoch: 6| Step: 6
Training loss: 0.12875500321388245
Validation loss: 1.5669546178592149

Epoch: 6| Step: 7
Training loss: 0.16830331087112427
Validation loss: 1.561955903166084

Epoch: 6| Step: 8
Training loss: 0.33205121755599976
Validation loss: 1.5491646899971911

Epoch: 6| Step: 9
Training loss: 0.0880100205540657
Validation loss: 1.5857169987053

Epoch: 6| Step: 10
Training loss: 0.10468319058418274
Validation loss: 1.574571442860429

Epoch: 6| Step: 11
Training loss: 0.10387279093265533
Validation loss: 1.5859229564666748

Epoch: 6| Step: 12
Training loss: 0.07781508564949036
Validation loss: 1.5691495531348771

Epoch: 6| Step: 13
Training loss: 0.08711051940917969
Validation loss: 1.6215313121836672

Epoch: 468| Step: 0
Training loss: 0.07045523077249527
Validation loss: 1.5650204458544332

Epoch: 6| Step: 1
Training loss: 0.18724662065505981
Validation loss: 1.6209920247395833

Epoch: 6| Step: 2
Training loss: 0.2097747027873993
Validation loss: 1.5925979050256873

Epoch: 6| Step: 3
Training loss: 0.1262243390083313
Validation loss: 1.6005936848220004

Epoch: 6| Step: 4
Training loss: 0.09741007536649704
Validation loss: 1.5873994865725118

Epoch: 6| Step: 5
Training loss: 0.16270409524440765
Validation loss: 1.592017609585998

Epoch: 6| Step: 6
Training loss: 0.12541408836841583
Validation loss: 1.5672695341930594

Epoch: 6| Step: 7
Training loss: 0.20821450650691986
Validation loss: 1.5662873560382473

Epoch: 6| Step: 8
Training loss: 0.04642551764845848
Validation loss: 1.5560945067354428

Epoch: 6| Step: 9
Training loss: 0.1261037439107895
Validation loss: 1.571664612780335

Epoch: 6| Step: 10
Training loss: 0.1038724035024643
Validation loss: 1.587550195314551

Epoch: 6| Step: 11
Training loss: 0.15672099590301514
Validation loss: 1.5866586803108134

Epoch: 6| Step: 12
Training loss: 0.21980512142181396
Validation loss: 1.5975965902369509

Epoch: 6| Step: 13
Training loss: 0.12166253477334976
Validation loss: 1.5882929576340543

Epoch: 469| Step: 0
Training loss: 0.13260376453399658
Validation loss: 1.6084106981113393

Epoch: 6| Step: 1
Training loss: 0.14335113763809204
Validation loss: 1.5797982138972129

Epoch: 6| Step: 2
Training loss: 0.08691366761922836
Validation loss: 1.5862162625917824

Epoch: 6| Step: 3
Training loss: 0.22838392853736877
Validation loss: 1.6284596509830926

Epoch: 6| Step: 4
Training loss: 0.09653506428003311
Validation loss: 1.5990721628230105

Epoch: 6| Step: 5
Training loss: 0.12015269696712494
Validation loss: 1.6289826477727583

Epoch: 6| Step: 6
Training loss: 0.07666155695915222
Validation loss: 1.6154706234573035

Epoch: 6| Step: 7
Training loss: 0.1863826960325241
Validation loss: 1.6022402381384244

Epoch: 6| Step: 8
Training loss: 0.05547574162483215
Validation loss: 1.6050795714060466

Epoch: 6| Step: 9
Training loss: 0.0730288103222847
Validation loss: 1.6141222010376632

Epoch: 6| Step: 10
Training loss: 0.07438524812459946
Validation loss: 1.5979038374398344

Epoch: 6| Step: 11
Training loss: 0.06422247737646103
Validation loss: 1.5861310510225193

Epoch: 6| Step: 12
Training loss: 0.2815212905406952
Validation loss: 1.5993845180798603

Epoch: 6| Step: 13
Training loss: 0.2725531756877899
Validation loss: 1.597207364856556

Epoch: 470| Step: 0
Training loss: 0.11416777223348618
Validation loss: 1.5989422785338534

Epoch: 6| Step: 1
Training loss: 0.11860720068216324
Validation loss: 1.6193082819702804

Epoch: 6| Step: 2
Training loss: 0.10471182316541672
Validation loss: 1.627612986872273

Epoch: 6| Step: 3
Training loss: 0.15055681765079498
Validation loss: 1.6144345473217707

Epoch: 6| Step: 4
Training loss: 0.150356262922287
Validation loss: 1.6140860114046323

Epoch: 6| Step: 5
Training loss: 0.2213217169046402
Validation loss: 1.612871016225507

Epoch: 6| Step: 6
Training loss: 0.18004463613033295
Validation loss: 1.6324708051578973

Epoch: 6| Step: 7
Training loss: 0.11260416358709335
Validation loss: 1.6513335051075104

Epoch: 6| Step: 8
Training loss: 0.13982108235359192
Validation loss: 1.6514712046551447

Epoch: 6| Step: 9
Training loss: 0.2167464941740036
Validation loss: 1.6372667256221975

Epoch: 6| Step: 10
Training loss: 0.13925042748451233
Validation loss: 1.6435391864468973

Epoch: 6| Step: 11
Training loss: 0.16423514485359192
Validation loss: 1.6380978348434612

Epoch: 6| Step: 12
Training loss: 0.16377700865268707
Validation loss: 1.626420949095039

Epoch: 6| Step: 13
Training loss: 0.18863646686077118
Validation loss: 1.6341179237570813

Epoch: 471| Step: 0
Training loss: 0.12334471940994263
Validation loss: 1.6386295518567484

Epoch: 6| Step: 1
Training loss: 0.10532814264297485
Validation loss: 1.6405339548664708

Epoch: 6| Step: 2
Training loss: 0.2161456048488617
Validation loss: 1.645665358471614

Epoch: 6| Step: 3
Training loss: 0.1837063729763031
Validation loss: 1.6489407977750223

Epoch: 6| Step: 4
Training loss: 0.25902342796325684
Validation loss: 1.6371992275279055

Epoch: 6| Step: 5
Training loss: 0.07876896113157272
Validation loss: 1.6519032729569303

Epoch: 6| Step: 6
Training loss: 0.12050491571426392
Validation loss: 1.6201114372540546

Epoch: 6| Step: 7
Training loss: 0.11908616870641708
Validation loss: 1.6202350547236781

Epoch: 6| Step: 8
Training loss: 0.12069071829319
Validation loss: 1.604441467151847

Epoch: 6| Step: 9
Training loss: 0.29323187470436096
Validation loss: 1.6018034873470184

Epoch: 6| Step: 10
Training loss: 0.14646287262439728
Validation loss: 1.6227069644517795

Epoch: 6| Step: 11
Training loss: 0.1078992560505867
Validation loss: 1.6012018816445464

Epoch: 6| Step: 12
Training loss: 0.1100691556930542
Validation loss: 1.6356616084293654

Epoch: 6| Step: 13
Training loss: 0.1548316776752472
Validation loss: 1.6210772760452763

Epoch: 472| Step: 0
Training loss: 0.18031543493270874
Validation loss: 1.637629968504752

Epoch: 6| Step: 1
Training loss: 0.15045839548110962
Validation loss: 1.6347367225154754

Epoch: 6| Step: 2
Training loss: 0.10258489102125168
Validation loss: 1.6553985200902468

Epoch: 6| Step: 3
Training loss: 0.11237733066082001
Validation loss: 1.6351034871993526

Epoch: 6| Step: 4
Training loss: 0.13538214564323425
Validation loss: 1.6525408632011824

Epoch: 6| Step: 5
Training loss: 0.20176184177398682
Validation loss: 1.623052982873814

Epoch: 6| Step: 6
Training loss: 0.05757541209459305
Validation loss: 1.6176129156543362

Epoch: 6| Step: 7
Training loss: 0.1452173888683319
Validation loss: 1.6376132811269453

Epoch: 6| Step: 8
Training loss: 0.25607097148895264
Validation loss: 1.5925250386679044

Epoch: 6| Step: 9
Training loss: 0.16480204463005066
Validation loss: 1.6109026285909838

Epoch: 6| Step: 10
Training loss: 0.13533931970596313
Validation loss: 1.6116054032438545

Epoch: 6| Step: 11
Training loss: 0.2491452693939209
Validation loss: 1.6523665978062538

Epoch: 6| Step: 12
Training loss: 0.13416090607643127
Validation loss: 1.6197701167034846

Epoch: 6| Step: 13
Training loss: 0.16024452447891235
Validation loss: 1.6340895404097855

Epoch: 473| Step: 0
Training loss: 0.18665023148059845
Validation loss: 1.6427600665759015

Epoch: 6| Step: 1
Training loss: 0.1681584119796753
Validation loss: 1.6394848092909782

Epoch: 6| Step: 2
Training loss: 0.27029892802238464
Validation loss: 1.6482895292261595

Epoch: 6| Step: 3
Training loss: 0.13118597865104675
Validation loss: 1.6157124202738526

Epoch: 6| Step: 4
Training loss: 0.2099960446357727
Validation loss: 1.6437179914084814

Epoch: 6| Step: 5
Training loss: 0.16539040207862854
Validation loss: 1.620362203608277

Epoch: 6| Step: 6
Training loss: 0.18763473629951477
Validation loss: 1.618071848346341

Epoch: 6| Step: 7
Training loss: 0.22740980982780457
Validation loss: 1.6076869067325388

Epoch: 6| Step: 8
Training loss: 0.3489854335784912
Validation loss: 1.6062115969196442

Epoch: 6| Step: 9
Training loss: 0.15254250168800354
Validation loss: 1.6417061423742643

Epoch: 6| Step: 10
Training loss: 0.13208860158920288
Validation loss: 1.6090716520945232

Epoch: 6| Step: 11
Training loss: 0.13440343737602234
Validation loss: 1.6002056470481298

Epoch: 6| Step: 12
Training loss: 0.14374716579914093
Validation loss: 1.59425050468855

Epoch: 6| Step: 13
Training loss: 0.06100142002105713
Validation loss: 1.5781438363495695

Epoch: 474| Step: 0
Training loss: 0.12803290784358978
Validation loss: 1.6127129370166409

Epoch: 6| Step: 1
Training loss: 0.09513872861862183
Validation loss: 1.6213715204628565

Epoch: 6| Step: 2
Training loss: 0.2218417227268219
Validation loss: 1.619824868376537

Epoch: 6| Step: 3
Training loss: 0.20749488472938538
Validation loss: 1.6137227063537927

Epoch: 6| Step: 4
Training loss: 0.11933828890323639
Validation loss: 1.591989408257187

Epoch: 6| Step: 5
Training loss: 0.140144944190979
Validation loss: 1.6147916522077335

Epoch: 6| Step: 6
Training loss: 0.23758931457996368
Validation loss: 1.592095963416561

Epoch: 6| Step: 7
Training loss: 0.15421032905578613
Validation loss: 1.5675187649265412

Epoch: 6| Step: 8
Training loss: 0.1470125913619995
Validation loss: 1.5754275655233732

Epoch: 6| Step: 9
Training loss: 0.1290241926908493
Validation loss: 1.5893059930493754

Epoch: 6| Step: 10
Training loss: 0.11300715804100037
Validation loss: 1.6175926590478549

Epoch: 6| Step: 11
Training loss: 0.13424518704414368
Validation loss: 1.6102368716270692

Epoch: 6| Step: 12
Training loss: 0.29411500692367554
Validation loss: 1.6078259688551708

Epoch: 6| Step: 13
Training loss: 0.21670790016651154
Validation loss: 1.6251871457663916

Epoch: 475| Step: 0
Training loss: 0.10157749056816101
Validation loss: 1.6045937922693068

Epoch: 6| Step: 1
Training loss: 0.13042210042476654
Validation loss: 1.6389312949231876

Epoch: 6| Step: 2
Training loss: 0.10105803608894348
Validation loss: 1.612045241940406

Epoch: 6| Step: 3
Training loss: 0.15323185920715332
Validation loss: 1.6311196768155662

Epoch: 6| Step: 4
Training loss: 0.12717100977897644
Validation loss: 1.6404026580113236

Epoch: 6| Step: 5
Training loss: 0.13550110161304474
Validation loss: 1.674005872459822

Epoch: 6| Step: 6
Training loss: 0.11897194385528564
Validation loss: 1.6478533373084119

Epoch: 6| Step: 7
Training loss: 0.20488232374191284
Validation loss: 1.6319626217247338

Epoch: 6| Step: 8
Training loss: 0.2731631100177765
Validation loss: 1.6421917253924954

Epoch: 6| Step: 9
Training loss: 0.07035356760025024
Validation loss: 1.6275872594566756

Epoch: 6| Step: 10
Training loss: 0.24567559361457825
Validation loss: 1.63232054761661

Epoch: 6| Step: 11
Training loss: 0.1548232138156891
Validation loss: 1.608463256589828

Epoch: 6| Step: 12
Training loss: 0.16238194704055786
Validation loss: 1.614857550590269

Epoch: 6| Step: 13
Training loss: 0.14161624014377594
Validation loss: 1.6054485049299014

Epoch: 476| Step: 0
Training loss: 0.1656852513551712
Validation loss: 1.6147730440221808

Epoch: 6| Step: 1
Training loss: 0.13153570890426636
Validation loss: 1.6200040745478805

Epoch: 6| Step: 2
Training loss: 0.1389811784029007
Validation loss: 1.6480381117072156

Epoch: 6| Step: 3
Training loss: 0.19761201739311218
Validation loss: 1.65093086483658

Epoch: 6| Step: 4
Training loss: 0.3088485300540924
Validation loss: 1.654717594064692

Epoch: 6| Step: 5
Training loss: 0.29253917932510376
Validation loss: 1.6532407422219553

Epoch: 6| Step: 6
Training loss: 0.17170345783233643
Validation loss: 1.6854736035869968

Epoch: 6| Step: 7
Training loss: 0.19412851333618164
Validation loss: 1.6424269060934744

Epoch: 6| Step: 8
Training loss: 0.14279258251190186
Validation loss: 1.605205379506593

Epoch: 6| Step: 9
Training loss: 0.10051083564758301
Validation loss: 1.6099273876477314

Epoch: 6| Step: 10
Training loss: 0.11241857707500458
Validation loss: 1.625630545359786

Epoch: 6| Step: 11
Training loss: 0.2071228325366974
Validation loss: 1.6491729315891062

Epoch: 6| Step: 12
Training loss: 0.11210763454437256
Validation loss: 1.596967525379632

Epoch: 6| Step: 13
Training loss: 0.11483340710401535
Validation loss: 1.6189669204014603

Epoch: 477| Step: 0
Training loss: 0.2574951946735382
Validation loss: 1.6076892486182592

Epoch: 6| Step: 1
Training loss: 0.23308847844600677
Validation loss: 1.5608815890486523

Epoch: 6| Step: 2
Training loss: 0.19290319085121155
Validation loss: 1.564479967599274

Epoch: 6| Step: 3
Training loss: 0.18309561908245087
Validation loss: 1.5700725804093063

Epoch: 6| Step: 4
Training loss: 0.15947602689266205
Validation loss: 1.5862942703308598

Epoch: 6| Step: 5
Training loss: 0.15312762558460236
Validation loss: 1.5916464613970889

Epoch: 6| Step: 6
Training loss: 0.13214480876922607
Validation loss: 1.6283639605327318

Epoch: 6| Step: 7
Training loss: 0.15395487844944
Validation loss: 1.5978682246259464

Epoch: 6| Step: 8
Training loss: 0.1292445808649063
Validation loss: 1.6011733944698046

Epoch: 6| Step: 9
Training loss: 0.12343911081552505
Validation loss: 1.6132382269828551

Epoch: 6| Step: 10
Training loss: 0.12091663479804993
Validation loss: 1.618579949102094

Epoch: 6| Step: 11
Training loss: 0.09424126148223877
Validation loss: 1.6072678360887753

Epoch: 6| Step: 12
Training loss: 0.13549014925956726
Validation loss: 1.6164347984457528

Epoch: 6| Step: 13
Training loss: 0.17751187086105347
Validation loss: 1.6034427509512952

Epoch: 478| Step: 0
Training loss: 0.09533025324344635
Validation loss: 1.6107642349376474

Epoch: 6| Step: 1
Training loss: 0.31707000732421875
Validation loss: 1.583671926170267

Epoch: 6| Step: 2
Training loss: 0.13701391220092773
Validation loss: 1.588998871464883

Epoch: 6| Step: 3
Training loss: 0.08862161636352539
Validation loss: 1.6120220973927488

Epoch: 6| Step: 4
Training loss: 0.1718025803565979
Validation loss: 1.6558706555315243

Epoch: 6| Step: 5
Training loss: 0.16316287219524384
Validation loss: 1.6357828891405495

Epoch: 6| Step: 6
Training loss: 0.1373571902513504
Validation loss: 1.634653405476642

Epoch: 6| Step: 7
Training loss: 0.16191351413726807
Validation loss: 1.6343961044024395

Epoch: 6| Step: 8
Training loss: 0.19380806386470795
Validation loss: 1.6293379593920965

Epoch: 6| Step: 9
Training loss: 0.13172714412212372
Validation loss: 1.6096321575103267

Epoch: 6| Step: 10
Training loss: 0.16028088331222534
Validation loss: 1.6184373914554555

Epoch: 6| Step: 11
Training loss: 0.23881438374519348
Validation loss: 1.6188760829228226

Epoch: 6| Step: 12
Training loss: 0.12495236098766327
Validation loss: 1.6254424920646093

Epoch: 6| Step: 13
Training loss: 0.09002024680376053
Validation loss: 1.6134206530868367

Epoch: 479| Step: 0
Training loss: 0.11440901458263397
Validation loss: 1.631560702477732

Epoch: 6| Step: 1
Training loss: 0.11033092439174652
Validation loss: 1.6604475949400215

Epoch: 6| Step: 2
Training loss: 0.11839673668146133
Validation loss: 1.63339090219108

Epoch: 6| Step: 3
Training loss: 0.1583975851535797
Validation loss: 1.6480220261440481

Epoch: 6| Step: 4
Training loss: 0.23776200413703918
Validation loss: 1.5952769966535671

Epoch: 6| Step: 5
Training loss: 0.2677639424800873
Validation loss: 1.5957231354969803

Epoch: 6| Step: 6
Training loss: 0.09848083555698395
Validation loss: 1.6107557550553353

Epoch: 6| Step: 7
Training loss: 0.09639805555343628
Validation loss: 1.5861647077786025

Epoch: 6| Step: 8
Training loss: 0.17699968814849854
Validation loss: 1.5701639716343214

Epoch: 6| Step: 9
Training loss: 0.1927402913570404
Validation loss: 1.5617576081265685

Epoch: 6| Step: 10
Training loss: 0.08181337267160416
Validation loss: 1.5765701775909753

Epoch: 6| Step: 11
Training loss: 0.07891246676445007
Validation loss: 1.547589768645584

Epoch: 6| Step: 12
Training loss: 0.2209376096725464
Validation loss: 1.5937926564165341

Epoch: 6| Step: 13
Training loss: 0.13045530021190643
Validation loss: 1.5844443869847122

Epoch: 480| Step: 0
Training loss: 0.07906356453895569
Validation loss: 1.596571219864712

Epoch: 6| Step: 1
Training loss: 0.15127412974834442
Validation loss: 1.5750000540928175

Epoch: 6| Step: 2
Training loss: 0.10762657225131989
Validation loss: 1.5683218240737915

Epoch: 6| Step: 3
Training loss: 0.13158005475997925
Validation loss: 1.5765621303230204

Epoch: 6| Step: 4
Training loss: 0.10067127645015717
Validation loss: 1.5854502570244573

Epoch: 6| Step: 5
Training loss: 0.21308766305446625
Validation loss: 1.602003760235284

Epoch: 6| Step: 6
Training loss: 0.21040858328342438
Validation loss: 1.6049231636908747

Epoch: 6| Step: 7
Training loss: 0.18307340145111084
Validation loss: 1.6141861850215542

Epoch: 6| Step: 8
Training loss: 0.14961105585098267
Validation loss: 1.608809769153595

Epoch: 6| Step: 9
Training loss: 0.10141556710004807
Validation loss: 1.6349750193216468

Epoch: 6| Step: 10
Training loss: 0.2308817058801651
Validation loss: 1.6249153037225046

Epoch: 6| Step: 11
Training loss: 0.30399811267852783
Validation loss: 1.641996359312406

Epoch: 6| Step: 12
Training loss: 0.17485566437244415
Validation loss: 1.6320269389819073

Epoch: 6| Step: 13
Training loss: 0.10735984146595001
Validation loss: 1.6254179246963993

Epoch: 481| Step: 0
Training loss: 0.1279873549938202
Validation loss: 1.6048914155652445

Epoch: 6| Step: 1
Training loss: 0.12534618377685547
Validation loss: 1.604649825762677

Epoch: 6| Step: 2
Training loss: 0.20378103852272034
Validation loss: 1.6038325576372043

Epoch: 6| Step: 3
Training loss: 0.10874297469854355
Validation loss: 1.6035047147863655

Epoch: 6| Step: 4
Training loss: 0.07997340708971024
Validation loss: 1.6150650452542048

Epoch: 6| Step: 5
Training loss: 0.1812247335910797
Validation loss: 1.6330295378162014

Epoch: 6| Step: 6
Training loss: 0.1500641405582428
Validation loss: 1.6124580303827922

Epoch: 6| Step: 7
Training loss: 0.20514777302742004
Validation loss: 1.6145408435534405

Epoch: 6| Step: 8
Training loss: 0.09854380041360855
Validation loss: 1.5980760743541103

Epoch: 6| Step: 9
Training loss: 0.2966594696044922
Validation loss: 1.6122007651995587

Epoch: 6| Step: 10
Training loss: 0.1553681194782257
Validation loss: 1.5723508173419583

Epoch: 6| Step: 11
Training loss: 0.20497173070907593
Validation loss: 1.5857409841270858

Epoch: 6| Step: 12
Training loss: 0.10504992306232452
Validation loss: 1.5925832704831195

Epoch: 6| Step: 13
Training loss: 0.08760043233633041
Validation loss: 1.599075239191773

Epoch: 482| Step: 0
Training loss: 0.13445739448070526
Validation loss: 1.578122938832929

Epoch: 6| Step: 1
Training loss: 0.13902878761291504
Validation loss: 1.6132357735787668

Epoch: 6| Step: 2
Training loss: 0.05969024449586868
Validation loss: 1.6218856829468922

Epoch: 6| Step: 3
Training loss: 0.18926768004894257
Validation loss: 1.615009323243172

Epoch: 6| Step: 4
Training loss: 0.15830974280834198
Validation loss: 1.6115956178275488

Epoch: 6| Step: 5
Training loss: 0.07502126693725586
Validation loss: 1.6204084209216538

Epoch: 6| Step: 6
Training loss: 0.18432043492794037
Validation loss: 1.607553876856322

Epoch: 6| Step: 7
Training loss: 0.17441177368164062
Validation loss: 1.6147598489638297

Epoch: 6| Step: 8
Training loss: 0.19244492053985596
Validation loss: 1.6097147618570635

Epoch: 6| Step: 9
Training loss: 0.08823985606431961
Validation loss: 1.6296184832049954

Epoch: 6| Step: 10
Training loss: 0.22278901934623718
Validation loss: 1.6129551523475236

Epoch: 6| Step: 11
Training loss: 0.092709019780159
Validation loss: 1.578613615805103

Epoch: 6| Step: 12
Training loss: 0.23634880781173706
Validation loss: 1.60596635008371

Epoch: 6| Step: 13
Training loss: 0.0732259675860405
Validation loss: 1.5986036126331618

Epoch: 483| Step: 0
Training loss: 0.10920466482639313
Validation loss: 1.6145008123049172

Epoch: 6| Step: 1
Training loss: 0.12719488143920898
Validation loss: 1.571194984579599

Epoch: 6| Step: 2
Training loss: 0.15682220458984375
Validation loss: 1.6293125690952424

Epoch: 6| Step: 3
Training loss: 0.13868379592895508
Validation loss: 1.6186127765204317

Epoch: 6| Step: 4
Training loss: 0.14990225434303284
Validation loss: 1.6148064456960207

Epoch: 6| Step: 5
Training loss: 0.1493915617465973
Validation loss: 1.6208631223247898

Epoch: 6| Step: 6
Training loss: 0.05563194304704666
Validation loss: 1.6102590266094412

Epoch: 6| Step: 7
Training loss: 0.051333893090486526
Validation loss: 1.6075629393259685

Epoch: 6| Step: 8
Training loss: 0.15157775580883026
Validation loss: 1.6325522199753792

Epoch: 6| Step: 9
Training loss: 0.24588343501091003
Validation loss: 1.6370328857052712

Epoch: 6| Step: 10
Training loss: 0.3166429102420807
Validation loss: 1.5915579513836933

Epoch: 6| Step: 11
Training loss: 0.10864893347024918
Validation loss: 1.6065727151850218

Epoch: 6| Step: 12
Training loss: 0.07616470754146576
Validation loss: 1.6272991716220815

Epoch: 6| Step: 13
Training loss: 0.16980472207069397
Validation loss: 1.596239674475885

Epoch: 484| Step: 0
Training loss: 0.07028138637542725
Validation loss: 1.6108031939434748

Epoch: 6| Step: 1
Training loss: 0.13306979835033417
Validation loss: 1.597900999489651

Epoch: 6| Step: 2
Training loss: 0.08571553230285645
Validation loss: 1.6286214102980912

Epoch: 6| Step: 3
Training loss: 0.1341928094625473
Validation loss: 1.6213058130715483

Epoch: 6| Step: 4
Training loss: 0.15715956687927246
Validation loss: 1.6350264779983028

Epoch: 6| Step: 5
Training loss: 0.19773221015930176
Validation loss: 1.6487354129873297

Epoch: 6| Step: 6
Training loss: 0.12492792308330536
Validation loss: 1.6131157349514704

Epoch: 6| Step: 7
Training loss: 0.11150059849023819
Validation loss: 1.5847178710404264

Epoch: 6| Step: 8
Training loss: 0.15448209643363953
Validation loss: 1.586200524401921

Epoch: 6| Step: 9
Training loss: 0.12408033013343811
Validation loss: 1.5963279534411687

Epoch: 6| Step: 10
Training loss: 0.25990235805511475
Validation loss: 1.5836419213202693

Epoch: 6| Step: 11
Training loss: 0.22231079638004303
Validation loss: 1.578190726618613

Epoch: 6| Step: 12
Training loss: 0.06115355342626572
Validation loss: 1.5790577793634066

Epoch: 6| Step: 13
Training loss: 0.17690791189670563
Validation loss: 1.5789766452645744

Epoch: 485| Step: 0
Training loss: 0.17036393284797668
Validation loss: 1.5819978201261131

Epoch: 6| Step: 1
Training loss: 0.2119084894657135
Validation loss: 1.6208546494924894

Epoch: 6| Step: 2
Training loss: 0.14112302660942078
Validation loss: 1.64486861741671

Epoch: 6| Step: 3
Training loss: 0.2300252765417099
Validation loss: 1.6125401937833397

Epoch: 6| Step: 4
Training loss: 0.1077418252825737
Validation loss: 1.5908161106929983

Epoch: 6| Step: 5
Training loss: 0.06308206915855408
Validation loss: 1.5950423056079495

Epoch: 6| Step: 6
Training loss: 0.16897907853126526
Validation loss: 1.5922102492342713

Epoch: 6| Step: 7
Training loss: 0.08165815472602844
Validation loss: 1.6252085355020338

Epoch: 6| Step: 8
Training loss: 0.11689735949039459
Validation loss: 1.6276228524023486

Epoch: 6| Step: 9
Training loss: 0.21685105562210083
Validation loss: 1.6370686613103396

Epoch: 6| Step: 10
Training loss: 0.1569531261920929
Validation loss: 1.6251484835019676

Epoch: 6| Step: 11
Training loss: 0.14811648428440094
Validation loss: 1.6199243068695068

Epoch: 6| Step: 12
Training loss: 0.1919623464345932
Validation loss: 1.6271258169604885

Epoch: 6| Step: 13
Training loss: 0.15053987503051758
Validation loss: 1.5830359433286934

Epoch: 486| Step: 0
Training loss: 0.09479612857103348
Validation loss: 1.5692055289463331

Epoch: 6| Step: 1
Training loss: 0.09387712180614471
Validation loss: 1.5529653205666492

Epoch: 6| Step: 2
Training loss: 0.12171325087547302
Validation loss: 1.5632770907494329

Epoch: 6| Step: 3
Training loss: 0.10000278800725937
Validation loss: 1.562022929550499

Epoch: 6| Step: 4
Training loss: 0.10795985162258148
Validation loss: 1.5614641481830227

Epoch: 6| Step: 5
Training loss: 0.17774565517902374
Validation loss: 1.5936211783398864

Epoch: 6| Step: 6
Training loss: 0.20187470316886902
Validation loss: 1.6035996842127975

Epoch: 6| Step: 7
Training loss: 0.21954479813575745
Validation loss: 1.5985967702763055

Epoch: 6| Step: 8
Training loss: 0.31025809049606323
Validation loss: 1.612164007720127

Epoch: 6| Step: 9
Training loss: 0.14916616678237915
Validation loss: 1.6227652693307528

Epoch: 6| Step: 10
Training loss: 0.16022604703903198
Validation loss: 1.6057532372013215

Epoch: 6| Step: 11
Training loss: 0.1759549230337143
Validation loss: 1.6059173217383764

Epoch: 6| Step: 12
Training loss: 0.1359022706747055
Validation loss: 1.5988382652241697

Epoch: 6| Step: 13
Training loss: 0.10914315283298492
Validation loss: 1.6085032173382339

Epoch: 487| Step: 0
Training loss: 0.21068426966667175
Validation loss: 1.637401456473976

Epoch: 6| Step: 1
Training loss: 0.16743969917297363
Validation loss: 1.6188171089336436

Epoch: 6| Step: 2
Training loss: 0.2917928099632263
Validation loss: 1.6350871619357858

Epoch: 6| Step: 3
Training loss: 0.19350652396678925
Validation loss: 1.6206624802722727

Epoch: 6| Step: 4
Training loss: 0.180978924036026
Validation loss: 1.6153112515326469

Epoch: 6| Step: 5
Training loss: 0.14646221697330475
Validation loss: 1.608718313196654

Epoch: 6| Step: 6
Training loss: 0.14233365654945374
Validation loss: 1.5882759042965469

Epoch: 6| Step: 7
Training loss: 0.13231343030929565
Validation loss: 1.5965494981376074

Epoch: 6| Step: 8
Training loss: 0.15129701793193817
Validation loss: 1.5881255134459464

Epoch: 6| Step: 9
Training loss: 0.1311463713645935
Validation loss: 1.602258123377318

Epoch: 6| Step: 10
Training loss: 0.14286984503269196
Validation loss: 1.596446660898065

Epoch: 6| Step: 11
Training loss: 0.06610976159572601
Validation loss: 1.5844102508278304

Epoch: 6| Step: 12
Training loss: 0.1591823399066925
Validation loss: 1.5459876034849434

Epoch: 6| Step: 13
Training loss: 0.11273935437202454
Validation loss: 1.601824006726665

Epoch: 488| Step: 0
Training loss: 0.12891721725463867
Validation loss: 1.5850195987250215

Epoch: 6| Step: 1
Training loss: 0.18540996313095093
Validation loss: 1.6091429283542018

Epoch: 6| Step: 2
Training loss: 0.2031182497739792
Validation loss: 1.6010254839415192

Epoch: 6| Step: 3
Training loss: 0.10629866272211075
Validation loss: 1.5860937256966867

Epoch: 6| Step: 4
Training loss: 0.14941784739494324
Validation loss: 1.5661461404574815

Epoch: 6| Step: 5
Training loss: 0.19990292191505432
Validation loss: 1.5507497351656678

Epoch: 6| Step: 6
Training loss: 0.12826460599899292
Validation loss: 1.5522758999178488

Epoch: 6| Step: 7
Training loss: 0.10468360781669617
Validation loss: 1.5726547100210702

Epoch: 6| Step: 8
Training loss: 0.0919625461101532
Validation loss: 1.5497132796113209

Epoch: 6| Step: 9
Training loss: 0.1793694645166397
Validation loss: 1.585236168676807

Epoch: 6| Step: 10
Training loss: 0.10900144279003143
Validation loss: 1.5892355057501024

Epoch: 6| Step: 11
Training loss: 0.16679233312606812
Validation loss: 1.551238816271546

Epoch: 6| Step: 12
Training loss: 0.08018432557582855
Validation loss: 1.5694912877134097

Epoch: 6| Step: 13
Training loss: 0.2873687446117401
Validation loss: 1.5475297204909786

Epoch: 489| Step: 0
Training loss: 0.12268069386482239
Validation loss: 1.613574553561467

Epoch: 6| Step: 1
Training loss: 0.09899069368839264
Validation loss: 1.619593870255255

Epoch: 6| Step: 2
Training loss: 0.09105322510004044
Validation loss: 1.6061365924855715

Epoch: 6| Step: 3
Training loss: 0.18490605056285858
Validation loss: 1.6240151774498723

Epoch: 6| Step: 4
Training loss: 0.415231317281723
Validation loss: 1.6239876977859005

Epoch: 6| Step: 5
Training loss: 0.10629873722791672
Validation loss: 1.6071176772476525

Epoch: 6| Step: 6
Training loss: 0.14867451786994934
Validation loss: 1.631882909805544

Epoch: 6| Step: 7
Training loss: 0.20235857367515564
Validation loss: 1.6504019665461716

Epoch: 6| Step: 8
Training loss: 0.1229758933186531
Validation loss: 1.624668223883516

Epoch: 6| Step: 9
Training loss: 0.1274627298116684
Validation loss: 1.6520023217765234

Epoch: 6| Step: 10
Training loss: 0.18696202337741852
Validation loss: 1.6291273575957104

Epoch: 6| Step: 11
Training loss: 0.10119335353374481
Validation loss: 1.6615196556173346

Epoch: 6| Step: 12
Training loss: 0.19692552089691162
Validation loss: 1.6173572335191952

Epoch: 6| Step: 13
Training loss: 0.12376514822244644
Validation loss: 1.590077812953662

Epoch: 490| Step: 0
Training loss: 0.1330994814634323
Validation loss: 1.6045620159436298

Epoch: 6| Step: 1
Training loss: 0.14512240886688232
Validation loss: 1.5782816768974386

Epoch: 6| Step: 2
Training loss: 0.15567252039909363
Validation loss: 1.5783472573885353

Epoch: 6| Step: 3
Training loss: 0.07659263908863068
Validation loss: 1.572160933607368

Epoch: 6| Step: 4
Training loss: 0.15228059887886047
Validation loss: 1.584732033873117

Epoch: 6| Step: 5
Training loss: 0.12900547683238983
Validation loss: 1.5852542923342796

Epoch: 6| Step: 6
Training loss: 0.14282555878162384
Validation loss: 1.579174853140308

Epoch: 6| Step: 7
Training loss: 0.16387787461280823
Validation loss: 1.572347984519056

Epoch: 6| Step: 8
Training loss: 0.07820054888725281
Validation loss: 1.5944637342165875

Epoch: 6| Step: 9
Training loss: 0.19817137718200684
Validation loss: 1.576663250564247

Epoch: 6| Step: 10
Training loss: 0.13221466541290283
Validation loss: 1.5796834345786803

Epoch: 6| Step: 11
Training loss: 0.23024074733257294
Validation loss: 1.5968518757051038

Epoch: 6| Step: 12
Training loss: 0.1399000734090805
Validation loss: 1.5809137769924697

Epoch: 6| Step: 13
Training loss: 0.13635680079460144
Validation loss: 1.6164860571584394

Epoch: 491| Step: 0
Training loss: 0.08933883905410767
Validation loss: 1.595971083128324

Epoch: 6| Step: 1
Training loss: 0.11478206515312195
Validation loss: 1.55657031202829

Epoch: 6| Step: 2
Training loss: 0.2794637382030487
Validation loss: 1.586272338385223

Epoch: 6| Step: 3
Training loss: 0.1350003331899643
Validation loss: 1.568027860374861

Epoch: 6| Step: 4
Training loss: 0.1622273027896881
Validation loss: 1.6034172093996437

Epoch: 6| Step: 5
Training loss: 0.06709440052509308
Validation loss: 1.5539078468917518

Epoch: 6| Step: 6
Training loss: 0.1758720576763153
Validation loss: 1.5972575115901169

Epoch: 6| Step: 7
Training loss: 0.12021955102682114
Validation loss: 1.5854076441898142

Epoch: 6| Step: 8
Training loss: 0.1535586416721344
Validation loss: 1.5832480192184448

Epoch: 6| Step: 9
Training loss: 0.09353916347026825
Validation loss: 1.5855194176397016

Epoch: 6| Step: 10
Training loss: 0.13878825306892395
Validation loss: 1.5917760281152622

Epoch: 6| Step: 11
Training loss: 0.10298144817352295
Validation loss: 1.5873885859725296

Epoch: 6| Step: 12
Training loss: 0.13951408863067627
Validation loss: 1.5754593918400426

Epoch: 6| Step: 13
Training loss: 0.05387253314256668
Validation loss: 1.6167704546323387

Epoch: 492| Step: 0
Training loss: 0.14794594049453735
Validation loss: 1.6309793456908195

Epoch: 6| Step: 1
Training loss: 0.09014958888292313
Validation loss: 1.6417594494358185

Epoch: 6| Step: 2
Training loss: 0.15706516802310944
Validation loss: 1.6394817175403718

Epoch: 6| Step: 3
Training loss: 0.12012466788291931
Validation loss: 1.6449498514975271

Epoch: 6| Step: 4
Training loss: 0.14034916460514069
Validation loss: 1.641316443361262

Epoch: 6| Step: 5
Training loss: 0.22689314186573029
Validation loss: 1.6113765444806827

Epoch: 6| Step: 6
Training loss: 0.12288793921470642
Validation loss: 1.5790522008813836

Epoch: 6| Step: 7
Training loss: 0.14970794320106506
Validation loss: 1.6070077086007724

Epoch: 6| Step: 8
Training loss: 0.19400063157081604
Validation loss: 1.5877531600254837

Epoch: 6| Step: 9
Training loss: 0.1784871220588684
Validation loss: 1.556465204044055

Epoch: 6| Step: 10
Training loss: 0.14939746260643005
Validation loss: 1.5615490482699486

Epoch: 6| Step: 11
Training loss: 0.30551573634147644
Validation loss: 1.5802936592409689

Epoch: 6| Step: 12
Training loss: 0.12036758661270142
Validation loss: 1.5867358356393793

Epoch: 6| Step: 13
Training loss: 0.2576284408569336
Validation loss: 1.594517696288324

Epoch: 493| Step: 0
Training loss: 0.1890001893043518
Validation loss: 1.5994883442437777

Epoch: 6| Step: 1
Training loss: 0.09512841701507568
Validation loss: 1.589945884161098

Epoch: 6| Step: 2
Training loss: 0.1324591040611267
Validation loss: 1.600788616365002

Epoch: 6| Step: 3
Training loss: 0.10037408024072647
Validation loss: 1.5843630093400196

Epoch: 6| Step: 4
Training loss: 0.10875086486339569
Validation loss: 1.5985605357795634

Epoch: 6| Step: 5
Training loss: 0.1542133241891861
Validation loss: 1.5989271133176741

Epoch: 6| Step: 6
Training loss: 0.17651475965976715
Validation loss: 1.5971135375320271

Epoch: 6| Step: 7
Training loss: 0.1578352004289627
Validation loss: 1.5996287266413372

Epoch: 6| Step: 8
Training loss: 0.11568039655685425
Validation loss: 1.5923122513678767

Epoch: 6| Step: 9
Training loss: 0.20322264730930328
Validation loss: 1.5767499080268286

Epoch: 6| Step: 10
Training loss: 0.2310696691274643
Validation loss: 1.6015031812011555

Epoch: 6| Step: 11
Training loss: 0.10469414293766022
Validation loss: 1.6252122963628461

Epoch: 6| Step: 12
Training loss: 0.11221729218959808
Validation loss: 1.60842687724739

Epoch: 6| Step: 13
Training loss: 0.11632350087165833
Validation loss: 1.5844023484055714

Epoch: 494| Step: 0
Training loss: 0.11707863211631775
Validation loss: 1.6332934184740948

Epoch: 6| Step: 1
Training loss: 0.102584108710289
Validation loss: 1.6094915975806534

Epoch: 6| Step: 2
Training loss: 0.12370213866233826
Validation loss: 1.6367536167944632

Epoch: 6| Step: 3
Training loss: 0.16371797025203705
Validation loss: 1.6651841261053597

Epoch: 6| Step: 4
Training loss: 0.07765882462263107
Validation loss: 1.6256403820489043

Epoch: 6| Step: 5
Training loss: 0.15526819229125977
Validation loss: 1.6743376870309152

Epoch: 6| Step: 6
Training loss: 0.14205017685890198
Validation loss: 1.6345190104617868

Epoch: 6| Step: 7
Training loss: 0.149619922041893
Validation loss: 1.6514220173640917

Epoch: 6| Step: 8
Training loss: 0.14386135339736938
Validation loss: 1.6504571399381083

Epoch: 6| Step: 9
Training loss: 0.07068295776844025
Validation loss: 1.6470822506053473

Epoch: 6| Step: 10
Training loss: 0.16081979870796204
Validation loss: 1.6196210063913816

Epoch: 6| Step: 11
Training loss: 0.2573452293872833
Validation loss: 1.6182419048842562

Epoch: 6| Step: 12
Training loss: 0.1777038276195526
Validation loss: 1.6034092172499625

Epoch: 6| Step: 13
Training loss: 0.14932796359062195
Validation loss: 1.610125894187599

Epoch: 495| Step: 0
Training loss: 0.1599089354276657
Validation loss: 1.6097408135732014

Epoch: 6| Step: 1
Training loss: 0.2184898555278778
Validation loss: 1.5912113792152816

Epoch: 6| Step: 2
Training loss: 0.11192159354686737
Validation loss: 1.6138237394312376

Epoch: 6| Step: 3
Training loss: 0.08645834028720856
Validation loss: 1.6089184450846847

Epoch: 6| Step: 4
Training loss: 0.0828380435705185
Validation loss: 1.5891892064002253

Epoch: 6| Step: 5
Training loss: 0.14988760650157928
Validation loss: 1.5986495992188812

Epoch: 6| Step: 6
Training loss: 0.09044850617647171
Validation loss: 1.5750270787105765

Epoch: 6| Step: 7
Training loss: 0.136919766664505
Validation loss: 1.5623549645946873

Epoch: 6| Step: 8
Training loss: 0.07591497898101807
Validation loss: 1.582693870349597

Epoch: 6| Step: 9
Training loss: 0.3357417583465576
Validation loss: 1.5662195913253292

Epoch: 6| Step: 10
Training loss: 0.13539224863052368
Validation loss: 1.572698272684569

Epoch: 6| Step: 11
Training loss: 0.08725272864103317
Validation loss: 1.607144489083239

Epoch: 6| Step: 12
Training loss: 0.17180560529232025
Validation loss: 1.5975037659368208

Epoch: 6| Step: 13
Training loss: 0.20959824323654175
Validation loss: 1.6080068490838493

Epoch: 496| Step: 0
Training loss: 0.12617239356040955
Validation loss: 1.600288414186047

Epoch: 6| Step: 1
Training loss: 0.07347116619348526
Validation loss: 1.617644138233636

Epoch: 6| Step: 2
Training loss: 0.2492392659187317
Validation loss: 1.6207180215466408

Epoch: 6| Step: 3
Training loss: 0.08893411606550217
Validation loss: 1.6425859979403916

Epoch: 6| Step: 4
Training loss: 0.12480004876852036
Validation loss: 1.6026305562706404

Epoch: 6| Step: 5
Training loss: 0.10506270825862885
Validation loss: 1.6384886823674685

Epoch: 6| Step: 6
Training loss: 0.2142062485218048
Validation loss: 1.6334768905434558

Epoch: 6| Step: 7
Training loss: 0.1178528368473053
Validation loss: 1.6269529686179212

Epoch: 6| Step: 8
Training loss: 0.11760135740041733
Validation loss: 1.6066044940743396

Epoch: 6| Step: 9
Training loss: 0.13700853288173676
Validation loss: 1.595661917040425

Epoch: 6| Step: 10
Training loss: 0.07958493381738663
Validation loss: 1.578809368994928

Epoch: 6| Step: 11
Training loss: 0.14380833506584167
Validation loss: 1.5995215164717806

Epoch: 6| Step: 12
Training loss: 0.15550382435321808
Validation loss: 1.584828229360683

Epoch: 6| Step: 13
Training loss: 0.15390193462371826
Validation loss: 1.6150683754233903

Epoch: 497| Step: 0
Training loss: 0.11641108989715576
Validation loss: 1.6090521017710369

Epoch: 6| Step: 1
Training loss: 0.10144703090190887
Validation loss: 1.573092141459065

Epoch: 6| Step: 2
Training loss: 0.1327252835035324
Validation loss: 1.5554446135797808

Epoch: 6| Step: 3
Training loss: 0.07393848150968552
Validation loss: 1.5704380850638113

Epoch: 6| Step: 4
Training loss: 0.08601740747690201
Validation loss: 1.5787998501972487

Epoch: 6| Step: 5
Training loss: 0.1581295132637024
Validation loss: 1.571435405362037

Epoch: 6| Step: 6
Training loss: 0.158165842294693
Validation loss: 1.5733977133227932

Epoch: 6| Step: 7
Training loss: 0.2119031548500061
Validation loss: 1.6050952429412513

Epoch: 6| Step: 8
Training loss: 0.19944289326667786
Validation loss: 1.5944206253174813

Epoch: 6| Step: 9
Training loss: 0.12666180729866028
Validation loss: 1.626423607590378

Epoch: 6| Step: 10
Training loss: 0.16386906802654266
Validation loss: 1.6144839845677859

Epoch: 6| Step: 11
Training loss: 0.10717126727104187
Validation loss: 1.6209770710237565

Epoch: 6| Step: 12
Training loss: 0.08200009167194366
Validation loss: 1.5971931667738064

Epoch: 6| Step: 13
Training loss: 0.1181902214884758
Validation loss: 1.6018856481839252

Epoch: 498| Step: 0
Training loss: 0.17181572318077087
Validation loss: 1.5981108732120965

Epoch: 6| Step: 1
Training loss: 0.1848250776529312
Validation loss: 1.582840705430636

Epoch: 6| Step: 2
Training loss: 0.12151531875133514
Validation loss: 1.5837739641948412

Epoch: 6| Step: 3
Training loss: 0.16269798576831818
Validation loss: 1.5604781361036404

Epoch: 6| Step: 4
Training loss: 0.32176530361175537
Validation loss: 1.564326435007075

Epoch: 6| Step: 5
Training loss: 0.11338555812835693
Validation loss: 1.5949440630533362

Epoch: 6| Step: 6
Training loss: 0.15303105115890503
Validation loss: 1.5706669156269362

Epoch: 6| Step: 7
Training loss: 0.16239750385284424
Validation loss: 1.5770193972895223

Epoch: 6| Step: 8
Training loss: 0.08068608492612839
Validation loss: 1.554627505681848

Epoch: 6| Step: 9
Training loss: 0.08037760853767395
Validation loss: 1.5755785216567337

Epoch: 6| Step: 10
Training loss: 0.12758088111877441
Validation loss: 1.5933413813191075

Epoch: 6| Step: 11
Training loss: 0.1534464955329895
Validation loss: 1.5895251099781325

Epoch: 6| Step: 12
Training loss: 0.06665351986885071
Validation loss: 1.576862737696658

Epoch: 6| Step: 13
Training loss: 0.15491989254951477
Validation loss: 1.5829529634086035

Epoch: 499| Step: 0
Training loss: 0.13487617671489716
Validation loss: 1.6014951685423493

Epoch: 6| Step: 1
Training loss: 0.19139938056468964
Validation loss: 1.6414718012655936

Epoch: 6| Step: 2
Training loss: 0.1296532154083252
Validation loss: 1.6385436942500453

Epoch: 6| Step: 3
Training loss: 0.219292551279068
Validation loss: 1.6400147920013757

Epoch: 6| Step: 4
Training loss: 0.13043522834777832
Validation loss: 1.5998134273354725

Epoch: 6| Step: 5
Training loss: 0.17084085941314697
Validation loss: 1.630087225667892

Epoch: 6| Step: 6
Training loss: 0.12582412362098694
Validation loss: 1.5798270343452372

Epoch: 6| Step: 7
Training loss: 0.28522345423698425
Validation loss: 1.5788522619073109

Epoch: 6| Step: 8
Training loss: 0.1623835265636444
Validation loss: 1.6063886521964945

Epoch: 6| Step: 9
Training loss: 0.09397831559181213
Validation loss: 1.6207500939728112

Epoch: 6| Step: 10
Training loss: 0.25353533029556274
Validation loss: 1.5716088151419034

Epoch: 6| Step: 11
Training loss: 0.10887078940868378
Validation loss: 1.6181574354889572

Epoch: 6| Step: 12
Training loss: 0.10455822944641113
Validation loss: 1.5814087070444578

Epoch: 6| Step: 13
Training loss: 0.09598355740308762
Validation loss: 1.5698580459881855

Epoch: 500| Step: 0
Training loss: 0.12087950110435486
Validation loss: 1.5999273446298414

Epoch: 6| Step: 1
Training loss: 0.13807399570941925
Validation loss: 1.6351783557604718

Epoch: 6| Step: 2
Training loss: 0.22123220562934875
Validation loss: 1.635102697598037

Epoch: 6| Step: 3
Training loss: 0.24820804595947266
Validation loss: 1.6028720159684458

Epoch: 6| Step: 4
Training loss: 0.12528909742832184
Validation loss: 1.5997531798578077

Epoch: 6| Step: 5
Training loss: 0.1555703729391098
Validation loss: 1.5781703584937639

Epoch: 6| Step: 6
Training loss: 0.11070422828197479
Validation loss: 1.573012767299529

Epoch: 6| Step: 7
Training loss: 0.15497153997421265
Validation loss: 1.5768824469658635

Epoch: 6| Step: 8
Training loss: 0.11522981524467468
Validation loss: 1.5503741925762546

Epoch: 6| Step: 9
Training loss: 0.08162789791822433
Validation loss: 1.5556431367833128

Epoch: 6| Step: 10
Training loss: 0.09562660753726959
Validation loss: 1.555045316296239

Epoch: 6| Step: 11
Training loss: 0.10024259239435196
Validation loss: 1.5554107414778842

Epoch: 6| Step: 12
Training loss: 0.17256303131580353
Validation loss: 1.5508912327469035

Epoch: 6| Step: 13
Training loss: 0.08742909878492355
Validation loss: 1.5650888681411743

Epoch: 501| Step: 0
Training loss: 0.11578735709190369
Validation loss: 1.5426451326698385

Epoch: 6| Step: 1
Training loss: 0.08969096094369888
Validation loss: 1.5524633135846866

Epoch: 6| Step: 2
Training loss: 0.3030216693878174
Validation loss: 1.5442599801607029

Epoch: 6| Step: 3
Training loss: 0.12565892934799194
Validation loss: 1.576110166247173

Epoch: 6| Step: 4
Training loss: 0.12133530527353287
Validation loss: 1.594383365364485

Epoch: 6| Step: 5
Training loss: 0.09583623707294464
Validation loss: 1.5904900604678738

Epoch: 6| Step: 6
Training loss: 0.12385916709899902
Validation loss: 1.5893741974266626

Epoch: 6| Step: 7
Training loss: 0.1445210874080658
Validation loss: 1.5994047413590133

Epoch: 6| Step: 8
Training loss: 0.1913805603981018
Validation loss: 1.570030512348298

Epoch: 6| Step: 9
Training loss: 0.15778383612632751
Validation loss: 1.5971795089783207

Epoch: 6| Step: 10
Training loss: 0.12053634226322174
Validation loss: 1.5761374773517731

Epoch: 6| Step: 11
Training loss: 0.1480916142463684
Validation loss: 1.588400831786535

Epoch: 6| Step: 12
Training loss: 0.15292701125144958
Validation loss: 1.5617704083842616

Epoch: 6| Step: 13
Training loss: 0.09659132361412048
Validation loss: 1.5784617636793403

Epoch: 502| Step: 0
Training loss: 0.24677972495555878
Validation loss: 1.5607651792546755

Epoch: 6| Step: 1
Training loss: 0.18261632323265076
Validation loss: 1.5635346161421908

Epoch: 6| Step: 2
Training loss: 0.15252956748008728
Validation loss: 1.548839787001251

Epoch: 6| Step: 3
Training loss: 0.10085432231426239
Validation loss: 1.5824105483229443

Epoch: 6| Step: 4
Training loss: 0.09181506931781769
Validation loss: 1.5720095019186697

Epoch: 6| Step: 5
Training loss: 0.10224707424640656
Validation loss: 1.5689486662546794

Epoch: 6| Step: 6
Training loss: 0.11125974357128143
Validation loss: 1.5922570151667441

Epoch: 6| Step: 7
Training loss: 0.07260645925998688
Validation loss: 1.579661435978387

Epoch: 6| Step: 8
Training loss: 0.11588917672634125
Validation loss: 1.5575501611155849

Epoch: 6| Step: 9
Training loss: 0.07998412102460861
Validation loss: 1.587158755589557

Epoch: 6| Step: 10
Training loss: 0.08516865223646164
Validation loss: 1.5912285415075158

Epoch: 6| Step: 11
Training loss: 0.06381483376026154
Validation loss: 1.5916762749354045

Epoch: 6| Step: 12
Training loss: 0.10853084921836853
Validation loss: 1.6243917788228681

Epoch: 6| Step: 13
Training loss: 0.13699039816856384
Validation loss: 1.5994817108236334

Epoch: 503| Step: 0
Training loss: 0.0817028135061264
Validation loss: 1.5741474538721063

Epoch: 6| Step: 1
Training loss: 0.06041378527879715
Validation loss: 1.6096839020329137

Epoch: 6| Step: 2
Training loss: 0.20556625723838806
Validation loss: 1.6019669643012426

Epoch: 6| Step: 3
Training loss: 0.15579251945018768
Validation loss: 1.6103309469838296

Epoch: 6| Step: 4
Training loss: 0.06558483839035034
Validation loss: 1.5855348635745306

Epoch: 6| Step: 5
Training loss: 0.13264164328575134
Validation loss: 1.586495494329801

Epoch: 6| Step: 6
Training loss: 0.13542777299880981
Validation loss: 1.578728986042802

Epoch: 6| Step: 7
Training loss: 0.19089335203170776
Validation loss: 1.5569143167106054

Epoch: 6| Step: 8
Training loss: 0.10817524790763855
Validation loss: 1.5851813221490512

Epoch: 6| Step: 9
Training loss: 0.1752958595752716
Validation loss: 1.5721153392586658

Epoch: 6| Step: 10
Training loss: 0.15791717171669006
Validation loss: 1.5771392135209934

Epoch: 6| Step: 11
Training loss: 0.08747197687625885
Validation loss: 1.5450298042707546

Epoch: 6| Step: 12
Training loss: 0.11495475471019745
Validation loss: 1.5722670875569826

Epoch: 6| Step: 13
Training loss: 0.08049368858337402
Validation loss: 1.6105038145537018

Epoch: 504| Step: 0
Training loss: 0.12407604604959488
Validation loss: 1.5965982085915023

Epoch: 6| Step: 1
Training loss: 0.08138449490070343
Validation loss: 1.5623967570643271

Epoch: 6| Step: 2
Training loss: 0.07757748663425446
Validation loss: 1.567446477951542

Epoch: 6| Step: 3
Training loss: 0.07157900929450989
Validation loss: 1.567188242430328

Epoch: 6| Step: 4
Training loss: 0.04182245954871178
Validation loss: 1.565226258770112

Epoch: 6| Step: 5
Training loss: 0.08721556514501572
Validation loss: 1.5830445251157206

Epoch: 6| Step: 6
Training loss: 0.09377667307853699
Validation loss: 1.5713902974641452

Epoch: 6| Step: 7
Training loss: 0.1269378364086151
Validation loss: 1.6021086631282684

Epoch: 6| Step: 8
Training loss: 0.18015626072883606
Validation loss: 1.5922952775032289

Epoch: 6| Step: 9
Training loss: 0.11025120317935944
Validation loss: 1.5845916630119405

Epoch: 6| Step: 10
Training loss: 0.1453103870153427
Validation loss: 1.5990848656623595

Epoch: 6| Step: 11
Training loss: 0.1464703381061554
Validation loss: 1.5951170408597557

Epoch: 6| Step: 12
Training loss: 0.27684658765792847
Validation loss: 1.617296713654713

Epoch: 6| Step: 13
Training loss: 0.08965054899454117
Validation loss: 1.6120652896101757

Epoch: 505| Step: 0
Training loss: 0.12216640263795853
Validation loss: 1.6087145266994354

Epoch: 6| Step: 1
Training loss: 0.10061483830213547
Validation loss: 1.5985825189980127

Epoch: 6| Step: 2
Training loss: 0.22149178385734558
Validation loss: 1.613027100921959

Epoch: 6| Step: 3
Training loss: 0.07928667217493057
Validation loss: 1.6094626047277962

Epoch: 6| Step: 4
Training loss: 0.1454218327999115
Validation loss: 1.6172567375244633

Epoch: 6| Step: 5
Training loss: 0.2126426100730896
Validation loss: 1.6090763025386359

Epoch: 6| Step: 6
Training loss: 0.12341949343681335
Validation loss: 1.623494387954794

Epoch: 6| Step: 7
Training loss: 0.11097793281078339
Validation loss: 1.6080030741230134

Epoch: 6| Step: 8
Training loss: 0.13449864089488983
Validation loss: 1.6235720496023855

Epoch: 6| Step: 9
Training loss: 0.07723153382539749
Validation loss: 1.5915869820502497

Epoch: 6| Step: 10
Training loss: 0.08378677070140839
Validation loss: 1.6187783909100357

Epoch: 6| Step: 11
Training loss: 0.1479635238647461
Validation loss: 1.5997078777641378

Epoch: 6| Step: 12
Training loss: 0.1315167248249054
Validation loss: 1.5978924779481785

Epoch: 6| Step: 13
Training loss: 0.07496465742588043
Validation loss: 1.6028434717527

Epoch: 506| Step: 0
Training loss: 0.12636378407478333
Validation loss: 1.597003827812851

Epoch: 6| Step: 1
Training loss: 0.09030413627624512
Validation loss: 1.6221462308719594

Epoch: 6| Step: 2
Training loss: 0.12468388676643372
Validation loss: 1.6163130050064416

Epoch: 6| Step: 3
Training loss: 0.12295329570770264
Validation loss: 1.625223736609182

Epoch: 6| Step: 4
Training loss: 0.0958273783326149
Validation loss: 1.604542584829433

Epoch: 6| Step: 5
Training loss: 0.10766080021858215
Validation loss: 1.5785748868860223

Epoch: 6| Step: 6
Training loss: 0.09298381209373474
Validation loss: 1.5848403822991155

Epoch: 6| Step: 7
Training loss: 0.11630699038505554
Validation loss: 1.5927415470923147

Epoch: 6| Step: 8
Training loss: 0.07286418229341507
Validation loss: 1.589460507836393

Epoch: 6| Step: 9
Training loss: 0.2501533031463623
Validation loss: 1.600965021758951

Epoch: 6| Step: 10
Training loss: 0.11249059438705444
Validation loss: 1.5754438433595883

Epoch: 6| Step: 11
Training loss: 0.09383189678192139
Validation loss: 1.5891113037704139

Epoch: 6| Step: 12
Training loss: 0.21639889478683472
Validation loss: 1.5764643889601513

Epoch: 6| Step: 13
Training loss: 0.04370425269007683
Validation loss: 1.5692596371455858

Epoch: 507| Step: 0
Training loss: 0.06927292048931122
Validation loss: 1.5945046755575365

Epoch: 6| Step: 1
Training loss: 0.10990992933511734
Validation loss: 1.5549571988403157

Epoch: 6| Step: 2
Training loss: 0.08428102731704712
Validation loss: 1.5875030050995529

Epoch: 6| Step: 3
Training loss: 0.2308652549982071
Validation loss: 1.563493171045857

Epoch: 6| Step: 4
Training loss: 0.08473051339387894
Validation loss: 1.6029859512082991

Epoch: 6| Step: 5
Training loss: 0.08068665862083435
Validation loss: 1.5859447563848188

Epoch: 6| Step: 6
Training loss: 0.1339196264743805
Validation loss: 1.5728469407686623

Epoch: 6| Step: 7
Training loss: 0.1300397515296936
Validation loss: 1.565743669386833

Epoch: 6| Step: 8
Training loss: 0.09804275631904602
Validation loss: 1.5986798271056144

Epoch: 6| Step: 9
Training loss: 0.12434230744838715
Validation loss: 1.5873501877630911

Epoch: 6| Step: 10
Training loss: 0.17246034741401672
Validation loss: 1.5811433215295114

Epoch: 6| Step: 11
Training loss: 0.14580224454402924
Validation loss: 1.633701427008516

Epoch: 6| Step: 12
Training loss: 0.24875524640083313
Validation loss: 1.602447566165719

Epoch: 6| Step: 13
Training loss: 0.06034769117832184
Validation loss: 1.570070219296281

Epoch: 508| Step: 0
Training loss: 0.26504600048065186
Validation loss: 1.5883820236370128

Epoch: 6| Step: 1
Training loss: 0.10078942775726318
Validation loss: 1.584827068031475

Epoch: 6| Step: 2
Training loss: 0.18244801461696625
Validation loss: 1.5662908823259416

Epoch: 6| Step: 3
Training loss: 0.1351391226053238
Validation loss: 1.5720709869938512

Epoch: 6| Step: 4
Training loss: 0.11911062896251678
Validation loss: 1.5877346537446464

Epoch: 6| Step: 5
Training loss: 0.13874657452106476
Validation loss: 1.5490222977053734

Epoch: 6| Step: 6
Training loss: 0.06665962934494019
Validation loss: 1.5559155184735534

Epoch: 6| Step: 7
Training loss: 0.1026696264743805
Validation loss: 1.580578008005696

Epoch: 6| Step: 8
Training loss: 0.08706885576248169
Validation loss: 1.5716200413242463

Epoch: 6| Step: 9
Training loss: 0.13281357288360596
Validation loss: 1.5868735608234201

Epoch: 6| Step: 10
Training loss: 0.1126432865858078
Validation loss: 1.5561687279773015

Epoch: 6| Step: 11
Training loss: 0.10767878592014313
Validation loss: 1.5946988367265271

Epoch: 6| Step: 12
Training loss: 0.19833430647850037
Validation loss: 1.583866616731049

Epoch: 6| Step: 13
Training loss: 0.054374054074287415
Validation loss: 1.5978308134181525

Epoch: 509| Step: 0
Training loss: 0.07798726856708527
Validation loss: 1.5634126611935195

Epoch: 6| Step: 1
Training loss: 0.19475118815898895
Validation loss: 1.586969801174697

Epoch: 6| Step: 2
Training loss: 0.0845600813627243
Validation loss: 1.6029832606674523

Epoch: 6| Step: 3
Training loss: 0.10868147015571594
Validation loss: 1.571331230542993

Epoch: 6| Step: 4
Training loss: 0.10571456700563431
Validation loss: 1.6055550350937793

Epoch: 6| Step: 5
Training loss: 0.1250738501548767
Validation loss: 1.6076571544011433

Epoch: 6| Step: 6
Training loss: 0.0946655198931694
Validation loss: 1.5969024345438967

Epoch: 6| Step: 7
Training loss: 0.24221591651439667
Validation loss: 1.6293637098804596

Epoch: 6| Step: 8
Training loss: 0.08598829805850983
Validation loss: 1.5995520519953903

Epoch: 6| Step: 9
Training loss: 0.1256701946258545
Validation loss: 1.6238916599622337

Epoch: 6| Step: 10
Training loss: 0.15409721434116364
Validation loss: 1.6044410018510715

Epoch: 6| Step: 11
Training loss: 0.0973612517118454
Validation loss: 1.5916883240463913

Epoch: 6| Step: 12
Training loss: 0.1232454925775528
Validation loss: 1.6012651535772509

Epoch: 6| Step: 13
Training loss: 0.22864028811454773
Validation loss: 1.5896061581950034

Epoch: 510| Step: 0
Training loss: 0.10752639919519424
Validation loss: 1.6220291237677298

Epoch: 6| Step: 1
Training loss: 0.1846766322851181
Validation loss: 1.6198565331838464

Epoch: 6| Step: 2
Training loss: 0.12250495702028275
Validation loss: 1.5997660647156418

Epoch: 6| Step: 3
Training loss: 0.12016276270151138
Validation loss: 1.558810798070764

Epoch: 6| Step: 4
Training loss: 0.0422632098197937
Validation loss: 1.5869837653252385

Epoch: 6| Step: 5
Training loss: 0.07722596824169159
Validation loss: 1.5593268922580186

Epoch: 6| Step: 6
Training loss: 0.1173512190580368
Validation loss: 1.5678156345121321

Epoch: 6| Step: 7
Training loss: 0.20250460505485535
Validation loss: 1.6015654597231137

Epoch: 6| Step: 8
Training loss: 0.1522655189037323
Validation loss: 1.5733499764114298

Epoch: 6| Step: 9
Training loss: 0.1516803503036499
Validation loss: 1.5643302753407469

Epoch: 6| Step: 10
Training loss: 0.13463473320007324
Validation loss: 1.5852266588518698

Epoch: 6| Step: 11
Training loss: 0.10987938940525055
Validation loss: 1.5803540201597317

Epoch: 6| Step: 12
Training loss: 0.13999032974243164
Validation loss: 1.577855925406179

Epoch: 6| Step: 13
Training loss: 0.10229012370109558
Validation loss: 1.5680295651958835

Epoch: 511| Step: 0
Training loss: 0.18174581229686737
Validation loss: 1.5678483106756722

Epoch: 6| Step: 1
Training loss: 0.1352720707654953
Validation loss: 1.5818237014996108

Epoch: 6| Step: 2
Training loss: 0.185135155916214
Validation loss: 1.6053143855064147

Epoch: 6| Step: 3
Training loss: 0.13639876246452332
Validation loss: 1.6138474992526475

Epoch: 6| Step: 4
Training loss: 0.08605305850505829
Validation loss: 1.5896965188364829

Epoch: 6| Step: 5
Training loss: 0.12686723470687866
Validation loss: 1.5913662859188613

Epoch: 6| Step: 6
Training loss: 0.12336301803588867
Validation loss: 1.615058679734507

Epoch: 6| Step: 7
Training loss: 0.1019483357667923
Validation loss: 1.5925106130620486

Epoch: 6| Step: 8
Training loss: 0.12609754502773285
Validation loss: 1.5671649094550841

Epoch: 6| Step: 9
Training loss: 0.07908128947019577
Validation loss: 1.5695676316497147

Epoch: 6| Step: 10
Training loss: 0.13287055492401123
Validation loss: 1.5602542559305828

Epoch: 6| Step: 11
Training loss: 0.1310616433620453
Validation loss: 1.565122215978561

Epoch: 6| Step: 12
Training loss: 0.13774757087230682
Validation loss: 1.5560606461699291

Epoch: 6| Step: 13
Training loss: 0.06262098252773285
Validation loss: 1.548876444498698

Epoch: 512| Step: 0
Training loss: 0.2913731634616852
Validation loss: 1.5782619407100063

Epoch: 6| Step: 1
Training loss: 0.0659957304596901
Validation loss: 1.5814015942235147

Epoch: 6| Step: 2
Training loss: 0.1709394007921219
Validation loss: 1.5565749246587035

Epoch: 6| Step: 3
Training loss: 0.12681224942207336
Validation loss: 1.5916088499048704

Epoch: 6| Step: 4
Training loss: 0.06514116376638412
Validation loss: 1.5904301417771207

Epoch: 6| Step: 5
Training loss: 0.11673222482204437
Validation loss: 1.5907265114527878

Epoch: 6| Step: 6
Training loss: 0.04434187337756157
Validation loss: 1.6058234322455622

Epoch: 6| Step: 7
Training loss: 0.12376347929239273
Validation loss: 1.5963866492753387

Epoch: 6| Step: 8
Training loss: 0.08848350495100021
Validation loss: 1.6188043355941772

Epoch: 6| Step: 9
Training loss: 0.08085939288139343
Validation loss: 1.5979401629458192

Epoch: 6| Step: 10
Training loss: 0.15499964356422424
Validation loss: 1.6109501661792878

Epoch: 6| Step: 11
Training loss: 0.1253175139427185
Validation loss: 1.612296405658927

Epoch: 6| Step: 12
Training loss: 0.08770556002855301
Validation loss: 1.6081060401854976

Epoch: 6| Step: 13
Training loss: 0.054635390639305115
Validation loss: 1.6209716540510937

Epoch: 513| Step: 0
Training loss: 0.13254259526729584
Validation loss: 1.6634785282996394

Epoch: 6| Step: 1
Training loss: 0.07062995433807373
Validation loss: 1.6231455290189354

Epoch: 6| Step: 2
Training loss: 0.08997499197721481
Validation loss: 1.6347391951468684

Epoch: 6| Step: 3
Training loss: 0.08923143148422241
Validation loss: 1.61955125101151

Epoch: 6| Step: 4
Training loss: 0.12216881662607193
Validation loss: 1.6325901721113472

Epoch: 6| Step: 5
Training loss: 0.08672037720680237
Validation loss: 1.6181307992627543

Epoch: 6| Step: 6
Training loss: 0.10544861853122711
Validation loss: 1.5811387774764851

Epoch: 6| Step: 7
Training loss: 0.10652333498001099
Validation loss: 1.5896734499162244

Epoch: 6| Step: 8
Training loss: 0.18262457847595215
Validation loss: 1.5588759427429528

Epoch: 6| Step: 9
Training loss: 0.10692957788705826
Validation loss: 1.581365546872539

Epoch: 6| Step: 10
Training loss: 0.16557997465133667
Validation loss: 1.571943712490861

Epoch: 6| Step: 11
Training loss: 0.20585884153842926
Validation loss: 1.5840311704143402

Epoch: 6| Step: 12
Training loss: 0.08040392398834229
Validation loss: 1.6187008145034953

Epoch: 6| Step: 13
Training loss: 0.12313931435346603
Validation loss: 1.5794261527317826

Epoch: 514| Step: 0
Training loss: 0.1269749402999878
Validation loss: 1.5788054466247559

Epoch: 6| Step: 1
Training loss: 0.10136227309703827
Validation loss: 1.605943105554068

Epoch: 6| Step: 2
Training loss: 0.05260669067502022
Validation loss: 1.5960940045695151

Epoch: 6| Step: 3
Training loss: 0.06411297619342804
Validation loss: 1.6076871425874772

Epoch: 6| Step: 4
Training loss: 0.08860455453395844
Validation loss: 1.629869052158889

Epoch: 6| Step: 5
Training loss: 0.11262593418359756
Validation loss: 1.6185994507164083

Epoch: 6| Step: 6
Training loss: 0.15906961262226105
Validation loss: 1.6199201691535212

Epoch: 6| Step: 7
Training loss: 0.0755983293056488
Validation loss: 1.6229745995613836

Epoch: 6| Step: 8
Training loss: 0.08629940450191498
Validation loss: 1.6268782590025215

Epoch: 6| Step: 9
Training loss: 0.04261083900928497
Validation loss: 1.6047032071698097

Epoch: 6| Step: 10
Training loss: 0.07450158894062042
Validation loss: 1.6030809738302743

Epoch: 6| Step: 11
Training loss: 0.15643197298049927
Validation loss: 1.5939565807260492

Epoch: 6| Step: 12
Training loss: 0.28958606719970703
Validation loss: 1.6166320052198184

Epoch: 6| Step: 13
Training loss: 0.1469058245420456
Validation loss: 1.6310686757487636

Epoch: 515| Step: 0
Training loss: 0.0612264946103096
Validation loss: 1.6042508297069098

Epoch: 6| Step: 1
Training loss: 0.164088636636734
Validation loss: 1.601757405906595

Epoch: 6| Step: 2
Training loss: 0.09058695286512375
Validation loss: 1.6157092073912263

Epoch: 6| Step: 3
Training loss: 0.09434513747692108
Validation loss: 1.6177595071895148

Epoch: 6| Step: 4
Training loss: 0.09024006128311157
Validation loss: 1.6516325537876417

Epoch: 6| Step: 5
Training loss: 0.1388384997844696
Validation loss: 1.614557158562445

Epoch: 6| Step: 6
Training loss: 0.16251903772354126
Validation loss: 1.5957458339711672

Epoch: 6| Step: 7
Training loss: 0.257524698972702
Validation loss: 1.6342926768846409

Epoch: 6| Step: 8
Training loss: 0.08324010670185089
Validation loss: 1.62209923677547

Epoch: 6| Step: 9
Training loss: 0.06774519383907318
Validation loss: 1.6246403648007302

Epoch: 6| Step: 10
Training loss: 0.06597469747066498
Validation loss: 1.6173988414067093

Epoch: 6| Step: 11
Training loss: 0.18255358934402466
Validation loss: 1.5940102120881439

Epoch: 6| Step: 12
Training loss: 0.10476649552583694
Validation loss: 1.599382637649454

Epoch: 6| Step: 13
Training loss: 0.12419239431619644
Validation loss: 1.5774548989470287

Epoch: 516| Step: 0
Training loss: 0.09499770402908325
Validation loss: 1.5759457080594954

Epoch: 6| Step: 1
Training loss: 0.08442835509777069
Validation loss: 1.5756677312235678

Epoch: 6| Step: 2
Training loss: 0.10235613584518433
Validation loss: 1.5961593991966658

Epoch: 6| Step: 3
Training loss: 0.09788183867931366
Validation loss: 1.6074284359972963

Epoch: 6| Step: 4
Training loss: 0.1256525218486786
Validation loss: 1.6138289910490795

Epoch: 6| Step: 5
Training loss: 0.07667221873998642
Validation loss: 1.598081443258511

Epoch: 6| Step: 6
Training loss: 0.21673500537872314
Validation loss: 1.6112574838822888

Epoch: 6| Step: 7
Training loss: 0.06431609392166138
Validation loss: 1.606872006129193

Epoch: 6| Step: 8
Training loss: 0.08472360670566559
Validation loss: 1.6295518721303632

Epoch: 6| Step: 9
Training loss: 0.11243022978305817
Validation loss: 1.6035521440608527

Epoch: 6| Step: 10
Training loss: 0.07446593791246414
Validation loss: 1.5915552813519713

Epoch: 6| Step: 11
Training loss: 0.14043301343917847
Validation loss: 1.570410260590174

Epoch: 6| Step: 12
Training loss: 0.23573848605155945
Validation loss: 1.5751566809992636

Epoch: 6| Step: 13
Training loss: 0.08278349786996841
Validation loss: 1.551529335719283

Epoch: 517| Step: 0
Training loss: 0.0750037208199501
Validation loss: 1.569686189774544

Epoch: 6| Step: 1
Training loss: 0.11847762763500214
Validation loss: 1.5678816687676214

Epoch: 6| Step: 2
Training loss: 0.08463022112846375
Validation loss: 1.598229254445722

Epoch: 6| Step: 3
Training loss: 0.12778319418430328
Validation loss: 1.586564407553724

Epoch: 6| Step: 4
Training loss: 0.10643285512924194
Validation loss: 1.5980422445522842

Epoch: 6| Step: 5
Training loss: 0.1145564541220665
Validation loss: 1.59463341646297

Epoch: 6| Step: 6
Training loss: 0.15628598630428314
Validation loss: 1.625894110689881

Epoch: 6| Step: 7
Training loss: 0.1362248659133911
Validation loss: 1.62803146659687

Epoch: 6| Step: 8
Training loss: 0.13776624202728271
Validation loss: 1.6346919536590576

Epoch: 6| Step: 9
Training loss: 0.06670874357223511
Validation loss: 1.6421811734476397

Epoch: 6| Step: 10
Training loss: 0.10948482155799866
Validation loss: 1.6401747657406716

Epoch: 6| Step: 11
Training loss: 0.12360044568777084
Validation loss: 1.6353065711195751

Epoch: 6| Step: 12
Training loss: 0.2821412682533264
Validation loss: 1.6509022699889315

Epoch: 6| Step: 13
Training loss: 0.2591436803340912
Validation loss: 1.650472621763906

Epoch: 518| Step: 0
Training loss: 0.14689211547374725
Validation loss: 1.6110817463167253

Epoch: 6| Step: 1
Training loss: 0.12353343516588211
Validation loss: 1.6481710505741898

Epoch: 6| Step: 2
Training loss: 0.16652846336364746
Validation loss: 1.6325744300760248

Epoch: 6| Step: 3
Training loss: 0.09349994361400604
Validation loss: 1.5795359419238182

Epoch: 6| Step: 4
Training loss: 0.2516515851020813
Validation loss: 1.6085161983325917

Epoch: 6| Step: 5
Training loss: 0.09316292405128479
Validation loss: 1.5830757579495829

Epoch: 6| Step: 6
Training loss: 0.05508509278297424
Validation loss: 1.5758822092445948

Epoch: 6| Step: 7
Training loss: 0.13332295417785645
Validation loss: 1.548008373988572

Epoch: 6| Step: 8
Training loss: 0.11058837920427322
Validation loss: 1.5894794720475391

Epoch: 6| Step: 9
Training loss: 0.13932383060455322
Validation loss: 1.5613569072497788

Epoch: 6| Step: 10
Training loss: 0.12065790593624115
Validation loss: 1.5697336350717852

Epoch: 6| Step: 11
Training loss: 0.18381769955158234
Validation loss: 1.5606459891924294

Epoch: 6| Step: 12
Training loss: 0.07299358397722244
Validation loss: 1.5887665761414396

Epoch: 6| Step: 13
Training loss: 0.13408051431179047
Validation loss: 1.607310886024147

Epoch: 519| Step: 0
Training loss: 0.09716571867465973
Validation loss: 1.6003301656374367

Epoch: 6| Step: 1
Training loss: 0.13822023570537567
Validation loss: 1.6060633428635136

Epoch: 6| Step: 2
Training loss: 0.10821250081062317
Validation loss: 1.6127739324364612

Epoch: 6| Step: 3
Training loss: 0.23122185468673706
Validation loss: 1.6083777046972705

Epoch: 6| Step: 4
Training loss: 0.16178740561008453
Validation loss: 1.6299026345693937

Epoch: 6| Step: 5
Training loss: 0.08666826784610748
Validation loss: 1.6127445665738915

Epoch: 6| Step: 6
Training loss: 0.09225830435752869
Validation loss: 1.6316090604310394

Epoch: 6| Step: 7
Training loss: 0.08394847810268402
Validation loss: 1.6093913778181999

Epoch: 6| Step: 8
Training loss: 0.1514490693807602
Validation loss: 1.6210119532000633

Epoch: 6| Step: 9
Training loss: 0.11197338253259659
Validation loss: 1.6320078347318916

Epoch: 6| Step: 10
Training loss: 0.15992923080921173
Validation loss: 1.6218959054639261

Epoch: 6| Step: 11
Training loss: 0.1291787475347519
Validation loss: 1.6005919979464622

Epoch: 6| Step: 12
Training loss: 0.0752238780260086
Validation loss: 1.6029553374936503

Epoch: 6| Step: 13
Training loss: 0.11910229176282883
Validation loss: 1.582514347568635

Epoch: 520| Step: 0
Training loss: 0.05758866295218468
Validation loss: 1.6193820020203948

Epoch: 6| Step: 1
Training loss: 0.1260353922843933
Validation loss: 1.586779789258075

Epoch: 6| Step: 2
Training loss: 0.0718376487493515
Validation loss: 1.5747678331149522

Epoch: 6| Step: 3
Training loss: 0.10366551578044891
Validation loss: 1.580604536558992

Epoch: 6| Step: 4
Training loss: 0.09998183697462082
Validation loss: 1.5809229804623512

Epoch: 6| Step: 5
Training loss: 0.13777056336402893
Validation loss: 1.6111795658706336

Epoch: 6| Step: 6
Training loss: 0.16739773750305176
Validation loss: 1.6163443288495463

Epoch: 6| Step: 7
Training loss: 0.2831920087337494
Validation loss: 1.627746210944268

Epoch: 6| Step: 8
Training loss: 0.19680637121200562
Validation loss: 1.6301136375755392

Epoch: 6| Step: 9
Training loss: 0.09957430511713028
Validation loss: 1.6042913698380994

Epoch: 6| Step: 10
Training loss: 0.09915569424629211
Validation loss: 1.6027399339983541

Epoch: 6| Step: 11
Training loss: 0.13360252976417542
Validation loss: 1.598971680928302

Epoch: 6| Step: 12
Training loss: 0.10708512365818024
Validation loss: 1.5936771503058813

Epoch: 6| Step: 13
Training loss: 0.04099392890930176
Validation loss: 1.5889501571655273

Epoch: 521| Step: 0
Training loss: 0.1458592712879181
Validation loss: 1.5585519716303835

Epoch: 6| Step: 1
Training loss: 0.2091905176639557
Validation loss: 1.5755538684065624

Epoch: 6| Step: 2
Training loss: 0.09870626777410507
Validation loss: 1.5980848009868334

Epoch: 6| Step: 3
Training loss: 0.21931353211402893
Validation loss: 1.5928823614633212

Epoch: 6| Step: 4
Training loss: 0.24142032861709595
Validation loss: 1.5864441907534035

Epoch: 6| Step: 5
Training loss: 0.09257190674543381
Validation loss: 1.5600445257720126

Epoch: 6| Step: 6
Training loss: 0.08378303796052933
Validation loss: 1.5665960414435274

Epoch: 6| Step: 7
Training loss: 0.12812647223472595
Validation loss: 1.57558064435118

Epoch: 6| Step: 8
Training loss: 0.13312464952468872
Validation loss: 1.5719973105256275

Epoch: 6| Step: 9
Training loss: 0.11106621474027634
Validation loss: 1.560122275224296

Epoch: 6| Step: 10
Training loss: 0.09870250523090363
Validation loss: 1.5826887328137633

Epoch: 6| Step: 11
Training loss: 0.10744497179985046
Validation loss: 1.575533547709065

Epoch: 6| Step: 12
Training loss: 0.08417254686355591
Validation loss: 1.6045997745247298

Epoch: 6| Step: 13
Training loss: 0.11562246829271317
Validation loss: 1.6287211602733982

Epoch: 522| Step: 0
Training loss: 0.07102219760417938
Validation loss: 1.6031971029056016

Epoch: 6| Step: 1
Training loss: 0.19165097177028656
Validation loss: 1.6055549870255172

Epoch: 6| Step: 2
Training loss: 0.08190568536520004
Validation loss: 1.5729403777789044

Epoch: 6| Step: 3
Training loss: 0.14052116870880127
Validation loss: 1.5430126228640157

Epoch: 6| Step: 4
Training loss: 0.16507838666439056
Validation loss: 1.5612303928662372

Epoch: 6| Step: 5
Training loss: 0.1462964117527008
Validation loss: 1.5960235185520624

Epoch: 6| Step: 6
Training loss: 0.15057086944580078
Validation loss: 1.5898110764001006

Epoch: 6| Step: 7
Training loss: 0.13561823964118958
Validation loss: 1.6231052080790203

Epoch: 6| Step: 8
Training loss: 0.11243721842765808
Validation loss: 1.634342138485242

Epoch: 6| Step: 9
Training loss: 0.07311862707138062
Validation loss: 1.6495190897295553

Epoch: 6| Step: 10
Training loss: 0.2873525619506836
Validation loss: 1.6904507926715318

Epoch: 6| Step: 11
Training loss: 0.44895005226135254
Validation loss: 1.6737325178679598

Epoch: 6| Step: 12
Training loss: 0.13777227699756622
Validation loss: 1.6367632624923543

Epoch: 6| Step: 13
Training loss: 0.1464327722787857
Validation loss: 1.6329006328377673

Epoch: 523| Step: 0
Training loss: 0.2935444116592407
Validation loss: 1.5944068149853778

Epoch: 6| Step: 1
Training loss: 0.11863891780376434
Validation loss: 1.6041879833385508

Epoch: 6| Step: 2
Training loss: 0.07253331691026688
Validation loss: 1.585611924048393

Epoch: 6| Step: 3
Training loss: 0.08539776504039764
Validation loss: 1.592968592079737

Epoch: 6| Step: 4
Training loss: 0.14983443915843964
Validation loss: 1.590064238476497

Epoch: 6| Step: 5
Training loss: 0.12730565667152405
Validation loss: 1.5997576559743574

Epoch: 6| Step: 6
Training loss: 0.12400425970554352
Validation loss: 1.6070769281797512

Epoch: 6| Step: 7
Training loss: 0.1090063527226448
Validation loss: 1.5950341160579393

Epoch: 6| Step: 8
Training loss: 0.1664169281721115
Validation loss: 1.5882202527856315

Epoch: 6| Step: 9
Training loss: 0.17825964093208313
Validation loss: 1.6077453013389342

Epoch: 6| Step: 10
Training loss: 0.1822032630443573
Validation loss: 1.5858508707374654

Epoch: 6| Step: 11
Training loss: 0.08324862271547318
Validation loss: 1.5958479771050074

Epoch: 6| Step: 12
Training loss: 0.1284797191619873
Validation loss: 1.5963824282410324

Epoch: 6| Step: 13
Training loss: 0.1535668969154358
Validation loss: 1.6074766138548493

Epoch: 524| Step: 0
Training loss: 0.22672635316848755
Validation loss: 1.6116125186284382

Epoch: 6| Step: 1
Training loss: 0.15128713846206665
Validation loss: 1.6326058064737627

Epoch: 6| Step: 2
Training loss: 0.15058472752571106
Validation loss: 1.6188455435537523

Epoch: 6| Step: 3
Training loss: 0.1834159642457962
Validation loss: 1.6414479363349177

Epoch: 6| Step: 4
Training loss: 0.1656164824962616
Validation loss: 1.6280179305743145

Epoch: 6| Step: 5
Training loss: 0.11779388785362244
Validation loss: 1.644494721966405

Epoch: 6| Step: 6
Training loss: 0.12426082044839859
Validation loss: 1.649845306591321

Epoch: 6| Step: 7
Training loss: 0.1661967933177948
Validation loss: 1.6528287215899395

Epoch: 6| Step: 8
Training loss: 0.1409059762954712
Validation loss: 1.6181406436427948

Epoch: 6| Step: 9
Training loss: 0.19327515363693237
Validation loss: 1.6052167684801164

Epoch: 6| Step: 10
Training loss: 0.12190357595682144
Validation loss: 1.6265509820753528

Epoch: 6| Step: 11
Training loss: 0.15914475917816162
Validation loss: 1.6062378447542909

Epoch: 6| Step: 12
Training loss: 0.11059107631444931
Validation loss: 1.5978616764468532

Epoch: 6| Step: 13
Training loss: 0.09203793108463287
Validation loss: 1.5858082989210724

Epoch: 525| Step: 0
Training loss: 0.11137418448925018
Validation loss: 1.570658262057971

Epoch: 6| Step: 1
Training loss: 0.1793150007724762
Validation loss: 1.5998419971876248

Epoch: 6| Step: 2
Training loss: 0.0911249965429306
Validation loss: 1.6167441145066292

Epoch: 6| Step: 3
Training loss: 0.10770304501056671
Validation loss: 1.6094090605294833

Epoch: 6| Step: 4
Training loss: 0.2667205333709717
Validation loss: 1.6164775227987638

Epoch: 6| Step: 5
Training loss: 0.1356900930404663
Validation loss: 1.6112489546498945

Epoch: 6| Step: 6
Training loss: 0.13277509808540344
Validation loss: 1.621385826859423

Epoch: 6| Step: 7
Training loss: 0.13405069708824158
Validation loss: 1.6248550235584218

Epoch: 6| Step: 8
Training loss: 0.10074062645435333
Validation loss: 1.6035426842269076

Epoch: 6| Step: 9
Training loss: 0.15208543837070465
Validation loss: 1.6269692336359332

Epoch: 6| Step: 10
Training loss: 0.1574426293373108
Validation loss: 1.6130427288752731

Epoch: 6| Step: 11
Training loss: 0.1244935393333435
Validation loss: 1.6003780339353828

Epoch: 6| Step: 12
Training loss: 0.26465731859207153
Validation loss: 1.5884208063925467

Epoch: 6| Step: 13
Training loss: 0.08732984960079193
Validation loss: 1.6058292709371096

Epoch: 526| Step: 0
Training loss: 0.10388202220201492
Validation loss: 1.6189569439939273

Epoch: 6| Step: 1
Training loss: 0.09527343511581421
Validation loss: 1.609863696559783

Epoch: 6| Step: 2
Training loss: 0.16315993666648865
Validation loss: 1.617340865955558

Epoch: 6| Step: 3
Training loss: 0.14807307720184326
Validation loss: 1.6384133190237067

Epoch: 6| Step: 4
Training loss: 0.12208689749240875
Validation loss: 1.6078980392025364

Epoch: 6| Step: 5
Training loss: 0.2541102468967438
Validation loss: 1.6122270591797367

Epoch: 6| Step: 6
Training loss: 0.22570666670799255
Validation loss: 1.592830604122531

Epoch: 6| Step: 7
Training loss: 0.12712031602859497
Validation loss: 1.5799399742516138

Epoch: 6| Step: 8
Training loss: 0.08671969175338745
Validation loss: 1.5924663030973045

Epoch: 6| Step: 9
Training loss: 0.1913374960422516
Validation loss: 1.6046932153804327

Epoch: 6| Step: 10
Training loss: 0.14312389492988586
Validation loss: 1.6028100085514847

Epoch: 6| Step: 11
Training loss: 0.1306810975074768
Validation loss: 1.587032320678875

Epoch: 6| Step: 12
Training loss: 0.1826302856206894
Validation loss: 1.585391011289371

Epoch: 6| Step: 13
Training loss: 0.053704481571912766
Validation loss: 1.5742630266374158

Epoch: 527| Step: 0
Training loss: 0.06596655398607254
Validation loss: 1.5823289553324382

Epoch: 6| Step: 1
Training loss: 0.11094269156455994
Validation loss: 1.6051187451167772

Epoch: 6| Step: 2
Training loss: 0.2034759223461151
Validation loss: 1.6129724505127117

Epoch: 6| Step: 3
Training loss: 0.19842396676540375
Validation loss: 1.6333812616204704

Epoch: 6| Step: 4
Training loss: 0.218435138463974
Validation loss: 1.6221388969370114

Epoch: 6| Step: 5
Training loss: 0.16196686029434204
Validation loss: 1.6154156218292892

Epoch: 6| Step: 6
Training loss: 0.13845422863960266
Validation loss: 1.5821576349196895

Epoch: 6| Step: 7
Training loss: 0.09789164364337921
Validation loss: 1.604942108995171

Epoch: 6| Step: 8
Training loss: 0.2569376528263092
Validation loss: 1.6199589326817503

Epoch: 6| Step: 9
Training loss: 0.18752624094486237
Validation loss: 1.6289698564878075

Epoch: 6| Step: 10
Training loss: 0.22424569725990295
Validation loss: 1.61240682935202

Epoch: 6| Step: 11
Training loss: 0.12183581292629242
Validation loss: 1.6150046804899811

Epoch: 6| Step: 12
Training loss: 0.15172848105430603
Validation loss: 1.5731713688501747

Epoch: 6| Step: 13
Training loss: 0.28590309619903564
Validation loss: 1.5971502027203959

Epoch: 528| Step: 0
Training loss: 0.1882905215024948
Validation loss: 1.6189837237840057

Epoch: 6| Step: 1
Training loss: 0.13457152247428894
Validation loss: 1.6150923749451995

Epoch: 6| Step: 2
Training loss: 0.21773700416088104
Validation loss: 1.6442698894008514

Epoch: 6| Step: 3
Training loss: 0.16818320751190186
Validation loss: 1.6274113334635252

Epoch: 6| Step: 4
Training loss: 0.24506399035453796
Validation loss: 1.6503256277371479

Epoch: 6| Step: 5
Training loss: 0.13603517413139343
Validation loss: 1.6140817980612479

Epoch: 6| Step: 6
Training loss: 0.12614870071411133
Validation loss: 1.6436084983169392

Epoch: 6| Step: 7
Training loss: 0.3045617938041687
Validation loss: 1.6246266294551153

Epoch: 6| Step: 8
Training loss: 0.10992053151130676
Validation loss: 1.6120697798267487

Epoch: 6| Step: 9
Training loss: 0.25768762826919556
Validation loss: 1.6386901537577312

Epoch: 6| Step: 10
Training loss: 0.09516316652297974
Validation loss: 1.5926355713157243

Epoch: 6| Step: 11
Training loss: 0.10037457197904587
Validation loss: 1.5949045791420886

Epoch: 6| Step: 12
Training loss: 0.1216508150100708
Validation loss: 1.5767337276089577

Epoch: 6| Step: 13
Training loss: 0.08366486430168152
Validation loss: 1.5560119857070267

Epoch: 529| Step: 0
Training loss: 0.1202959194779396
Validation loss: 1.5680803714259979

Epoch: 6| Step: 1
Training loss: 0.13435772061347961
Validation loss: 1.5973735342743576

Epoch: 6| Step: 2
Training loss: 0.09535055607557297
Validation loss: 1.5954062733598935

Epoch: 6| Step: 3
Training loss: 0.13856792449951172
Validation loss: 1.5896985210398191

Epoch: 6| Step: 4
Training loss: 0.12280946224927902
Validation loss: 1.5927126048713602

Epoch: 6| Step: 5
Training loss: 0.09256929159164429
Validation loss: 1.6423945952487249

Epoch: 6| Step: 6
Training loss: 0.09880699217319489
Validation loss: 1.6165125344389228

Epoch: 6| Step: 7
Training loss: 0.1822669953107834
Validation loss: 1.6154084205627441

Epoch: 6| Step: 8
Training loss: 0.20602653920650482
Validation loss: 1.6071947313124133

Epoch: 6| Step: 9
Training loss: 0.16306138038635254
Validation loss: 1.6212509293710031

Epoch: 6| Step: 10
Training loss: 0.09895897656679153
Validation loss: 1.6087800777086647

Epoch: 6| Step: 11
Training loss: 0.15158984065055847
Validation loss: 1.6121239303260722

Epoch: 6| Step: 12
Training loss: 0.09993728995323181
Validation loss: 1.6050112132103211

Epoch: 6| Step: 13
Training loss: 0.09724331647157669
Validation loss: 1.6026502040124708

Epoch: 530| Step: 0
Training loss: 0.2127281129360199
Validation loss: 1.6111129009595482

Epoch: 6| Step: 1
Training loss: 0.11638399958610535
Validation loss: 1.5875447950055521

Epoch: 6| Step: 2
Training loss: 0.19140729308128357
Validation loss: 1.59588485892101

Epoch: 6| Step: 3
Training loss: 0.10208529233932495
Validation loss: 1.6450012601831907

Epoch: 6| Step: 4
Training loss: 0.16262193024158478
Validation loss: 1.6318795014453191

Epoch: 6| Step: 5
Training loss: 0.11712050437927246
Validation loss: 1.6337855374941261

Epoch: 6| Step: 6
Training loss: 0.07222306728363037
Validation loss: 1.6211798101343133

Epoch: 6| Step: 7
Training loss: 0.13298282027244568
Validation loss: 1.6106621488448112

Epoch: 6| Step: 8
Training loss: 0.08124003559350967
Validation loss: 1.6318813229119906

Epoch: 6| Step: 9
Training loss: 0.12778033316135406
Validation loss: 1.6423608974743915

Epoch: 6| Step: 10
Training loss: 0.0865885317325592
Validation loss: 1.623156334764214

Epoch: 6| Step: 11
Training loss: 0.1452062726020813
Validation loss: 1.6421420792097687

Epoch: 6| Step: 12
Training loss: 0.22723034024238586
Validation loss: 1.6521130377246487

Epoch: 6| Step: 13
Training loss: 0.05754711851477623
Validation loss: 1.6332947316990103

Epoch: 531| Step: 0
Training loss: 0.11623117327690125
Validation loss: 1.63139747676029

Epoch: 6| Step: 1
Training loss: 0.15371477603912354
Validation loss: 1.6504579359485256

Epoch: 6| Step: 2
Training loss: 0.0672588050365448
Validation loss: 1.6431945728999313

Epoch: 6| Step: 3
Training loss: 0.1773025393486023
Validation loss: 1.6271764937267508

Epoch: 6| Step: 4
Training loss: 0.13467183709144592
Validation loss: 1.635365298999253

Epoch: 6| Step: 5
Training loss: 0.11986488103866577
Validation loss: 1.6141342834759784

Epoch: 6| Step: 6
Training loss: 0.2174033373594284
Validation loss: 1.6081352182613906

Epoch: 6| Step: 7
Training loss: 0.16732297837734222
Validation loss: 1.621467375627128

Epoch: 6| Step: 8
Training loss: 0.12281077355146408
Validation loss: 1.6090375300376647

Epoch: 6| Step: 9
Training loss: 0.1653246283531189
Validation loss: 1.5830509188354656

Epoch: 6| Step: 10
Training loss: 0.09905075281858444
Validation loss: 1.5806596843145226

Epoch: 6| Step: 11
Training loss: 0.08378603309392929
Validation loss: 1.609371748021854

Epoch: 6| Step: 12
Training loss: 0.10661746561527252
Validation loss: 1.5792190374866608

Epoch: 6| Step: 13
Training loss: 0.04741750657558441
Validation loss: 1.5884472606002644

Epoch: 532| Step: 0
Training loss: 0.18417730927467346
Validation loss: 1.5826231574499479

Epoch: 6| Step: 1
Training loss: 0.15979725122451782
Validation loss: 1.592777855293725

Epoch: 6| Step: 2
Training loss: 0.13353216648101807
Validation loss: 1.6270377892319874

Epoch: 6| Step: 3
Training loss: 0.1046895757317543
Validation loss: 1.6011548862662366

Epoch: 6| Step: 4
Training loss: 0.1844254732131958
Validation loss: 1.6182313657576037

Epoch: 6| Step: 5
Training loss: 0.0892086923122406
Validation loss: 1.62341590978766

Epoch: 6| Step: 6
Training loss: 0.09253089129924774
Validation loss: 1.6237982332065541

Epoch: 6| Step: 7
Training loss: 0.07994957268238068
Validation loss: 1.6317877154196463

Epoch: 6| Step: 8
Training loss: 0.0713278204202652
Validation loss: 1.6640564856990692

Epoch: 6| Step: 9
Training loss: 0.11557622998952866
Validation loss: 1.5926923585194412

Epoch: 6| Step: 10
Training loss: 0.10905780643224716
Validation loss: 1.619422503696975

Epoch: 6| Step: 11
Training loss: 0.1910383552312851
Validation loss: 1.5958165135434879

Epoch: 6| Step: 12
Training loss: 0.09633408486843109
Validation loss: 1.5911035819720196

Epoch: 6| Step: 13
Training loss: 0.11123251914978027
Validation loss: 1.5876216619245467

Epoch: 533| Step: 0
Training loss: 0.0941639244556427
Validation loss: 1.5693956164903538

Epoch: 6| Step: 1
Training loss: 0.1098918467760086
Validation loss: 1.56889989683705

Epoch: 6| Step: 2
Training loss: 0.10636195540428162
Validation loss: 1.5700799624125164

Epoch: 6| Step: 3
Training loss: 0.13642890751361847
Validation loss: 1.548760752524099

Epoch: 6| Step: 4
Training loss: 0.13901448249816895
Validation loss: 1.5797932596616848

Epoch: 6| Step: 5
Training loss: 0.09897767752408981
Validation loss: 1.5969682534535725

Epoch: 6| Step: 6
Training loss: 0.2048434615135193
Validation loss: 1.584764297290515

Epoch: 6| Step: 7
Training loss: 0.04976905137300491
Validation loss: 1.5785919299689672

Epoch: 6| Step: 8
Training loss: 0.07956624776124954
Validation loss: 1.6037373030057518

Epoch: 6| Step: 9
Training loss: 0.11679080128669739
Validation loss: 1.6118781425619637

Epoch: 6| Step: 10
Training loss: 0.1566019505262375
Validation loss: 1.6249389891983361

Epoch: 6| Step: 11
Training loss: 0.13700415194034576
Validation loss: 1.6392722514367872

Epoch: 6| Step: 12
Training loss: 0.17703497409820557
Validation loss: 1.6210721692731302

Epoch: 6| Step: 13
Training loss: 0.09473273158073425
Validation loss: 1.6236895297163276

Epoch: 534| Step: 0
Training loss: 0.14214563369750977
Validation loss: 1.6544793985223258

Epoch: 6| Step: 1
Training loss: 0.1894112527370453
Validation loss: 1.64890040633499

Epoch: 6| Step: 2
Training loss: 0.13407288491725922
Validation loss: 1.6192607597638202

Epoch: 6| Step: 3
Training loss: 0.11535833030939102
Validation loss: 1.642338869392231

Epoch: 6| Step: 4
Training loss: 0.1002083569765091
Validation loss: 1.632356579585742

Epoch: 6| Step: 5
Training loss: 0.25400304794311523
Validation loss: 1.5974992859748103

Epoch: 6| Step: 6
Training loss: 0.1421981304883957
Validation loss: 1.6040121957819948

Epoch: 6| Step: 7
Training loss: 0.11288883537054062
Validation loss: 1.5669125203163392

Epoch: 6| Step: 8
Training loss: 0.08785820752382278
Validation loss: 1.5785535432959115

Epoch: 6| Step: 9
Training loss: 0.1273537576198578
Validation loss: 1.6047618466038858

Epoch: 6| Step: 10
Training loss: 0.10289689898490906
Validation loss: 1.6085870945325462

Epoch: 6| Step: 11
Training loss: 0.15043601393699646
Validation loss: 1.5820713286758752

Epoch: 6| Step: 12
Training loss: 0.12417256832122803
Validation loss: 1.5994663341071016

Epoch: 6| Step: 13
Training loss: 0.11658278852701187
Validation loss: 1.5881805791649768

Epoch: 535| Step: 0
Training loss: 0.2358529418706894
Validation loss: 1.6140732073014783

Epoch: 6| Step: 1
Training loss: 0.21488477289676666
Validation loss: 1.5852701971607823

Epoch: 6| Step: 2
Training loss: 0.1232333779335022
Validation loss: 1.6112765509595153

Epoch: 6| Step: 3
Training loss: 0.2262805551290512
Validation loss: 1.6021762124953731

Epoch: 6| Step: 4
Training loss: 0.2603212893009186
Validation loss: 1.6406070750246766

Epoch: 6| Step: 5
Training loss: 0.13663388788700104
Validation loss: 1.5993476003728888

Epoch: 6| Step: 6
Training loss: 0.12011414766311646
Validation loss: 1.6217273448103218

Epoch: 6| Step: 7
Training loss: 0.08662520349025726
Validation loss: 1.590986882486651

Epoch: 6| Step: 8
Training loss: 0.08640338480472565
Validation loss: 1.5901832298565937

Epoch: 6| Step: 9
Training loss: 0.14358025789260864
Validation loss: 1.6006077245999408

Epoch: 6| Step: 10
Training loss: 0.11130660772323608
Validation loss: 1.6096814601652083

Epoch: 6| Step: 11
Training loss: 0.18143588304519653
Validation loss: 1.6183294814120057

Epoch: 6| Step: 12
Training loss: 0.17672550678253174
Validation loss: 1.6038545741829822

Epoch: 6| Step: 13
Training loss: 0.13113529980182648
Validation loss: 1.6199051885194675

Epoch: 536| Step: 0
Training loss: 0.13990150392055511
Validation loss: 1.5740121077465754

Epoch: 6| Step: 1
Training loss: 0.10887164622545242
Validation loss: 1.5980260013252177

Epoch: 6| Step: 2
Training loss: 0.15915343165397644
Validation loss: 1.633172268508583

Epoch: 6| Step: 3
Training loss: 0.13169875741004944
Validation loss: 1.6597023625527658

Epoch: 6| Step: 4
Training loss: 0.14018189907073975
Validation loss: 1.620927724786984

Epoch: 6| Step: 5
Training loss: 0.06855397671461105
Validation loss: 1.5816028323224796

Epoch: 6| Step: 6
Training loss: 0.14398787915706635
Validation loss: 1.616578245675692

Epoch: 6| Step: 7
Training loss: 0.10833149403333664
Validation loss: 1.6003172000249226

Epoch: 6| Step: 8
Training loss: 0.13793563842773438
Validation loss: 1.6019001558262815

Epoch: 6| Step: 9
Training loss: 0.1136159598827362
Validation loss: 1.5645926716507121

Epoch: 6| Step: 10
Training loss: 0.20957528054714203
Validation loss: 1.5705184116158435

Epoch: 6| Step: 11
Training loss: 0.0837017297744751
Validation loss: 1.5909496263791156

Epoch: 6| Step: 12
Training loss: 0.09847797453403473
Validation loss: 1.5842942409617926

Epoch: 6| Step: 13
Training loss: 0.040840890258550644
Validation loss: 1.5679114941627748

Epoch: 537| Step: 0
Training loss: 0.1683429628610611
Validation loss: 1.6028773348818544

Epoch: 6| Step: 1
Training loss: 0.09357251226902008
Validation loss: 1.6026297935875513

Epoch: 6| Step: 2
Training loss: 0.1341330111026764
Validation loss: 1.5787510756523377

Epoch: 6| Step: 3
Training loss: 0.08914981782436371
Validation loss: 1.599404045330581

Epoch: 6| Step: 4
Training loss: 0.15184292197227478
Validation loss: 1.5797170246801069

Epoch: 6| Step: 5
Training loss: 0.07824339717626572
Validation loss: 1.5848899977181548

Epoch: 6| Step: 6
Training loss: 0.0975319966673851
Validation loss: 1.5817006672582319

Epoch: 6| Step: 7
Training loss: 0.12323565036058426
Validation loss: 1.6064035097757976

Epoch: 6| Step: 8
Training loss: 0.07089182734489441
Validation loss: 1.6259770560008224

Epoch: 6| Step: 9
Training loss: 0.18404638767242432
Validation loss: 1.6071905320690525

Epoch: 6| Step: 10
Training loss: 0.10655787587165833
Validation loss: 1.5909955399010771

Epoch: 6| Step: 11
Training loss: 0.09001575410366058
Validation loss: 1.6009849668830953

Epoch: 6| Step: 12
Training loss: 0.08606941252946854
Validation loss: 1.6086544477811424

Epoch: 6| Step: 13
Training loss: 0.11727824807167053
Validation loss: 1.601311033771884

Epoch: 538| Step: 0
Training loss: 0.08642308413982391
Validation loss: 1.5923852869259414

Epoch: 6| Step: 1
Training loss: 0.0978500247001648
Validation loss: 1.6278452475865681

Epoch: 6| Step: 2
Training loss: 0.08789432048797607
Validation loss: 1.5940002933625252

Epoch: 6| Step: 3
Training loss: 0.13923603296279907
Validation loss: 1.6115218259954964

Epoch: 6| Step: 4
Training loss: 0.13852769136428833
Validation loss: 1.6229509512583415

Epoch: 6| Step: 5
Training loss: 0.09691473841667175
Validation loss: 1.6230271554762317

Epoch: 6| Step: 6
Training loss: 0.09331457316875458
Validation loss: 1.6299884511578469

Epoch: 6| Step: 7
Training loss: 0.1355701982975006
Validation loss: 1.6573674242983583

Epoch: 6| Step: 8
Training loss: 0.2301272749900818
Validation loss: 1.627884716115972

Epoch: 6| Step: 9
Training loss: 0.0982171818614006
Validation loss: 1.6106582482655842

Epoch: 6| Step: 10
Training loss: 0.10807152092456818
Validation loss: 1.609225341068801

Epoch: 6| Step: 11
Training loss: 0.18474379181861877
Validation loss: 1.6264835249993108

Epoch: 6| Step: 12
Training loss: 0.05582323670387268
Validation loss: 1.6054328051946496

Epoch: 6| Step: 13
Training loss: 0.16518156230449677
Validation loss: 1.5998458535440507

Epoch: 539| Step: 0
Training loss: 0.09839929640293121
Validation loss: 1.618698081662578

Epoch: 6| Step: 1
Training loss: 0.1048203632235527
Validation loss: 1.6160704115385651

Epoch: 6| Step: 2
Training loss: 0.07841280102729797
Validation loss: 1.5933528151563419

Epoch: 6| Step: 3
Training loss: 0.1062113493680954
Validation loss: 1.6241835624940935

Epoch: 6| Step: 4
Training loss: 0.23998311161994934
Validation loss: 1.6325033967212965

Epoch: 6| Step: 5
Training loss: 0.13053452968597412
Validation loss: 1.6407501800085909

Epoch: 6| Step: 6
Training loss: 0.04836275056004524
Validation loss: 1.6273842627002346

Epoch: 6| Step: 7
Training loss: 0.11431662738323212
Validation loss: 1.6308925177461358

Epoch: 6| Step: 8
Training loss: 0.07838066667318344
Validation loss: 1.6108551666300783

Epoch: 6| Step: 9
Training loss: 0.11364132165908813
Validation loss: 1.610487473908291

Epoch: 6| Step: 10
Training loss: 0.24774041771888733
Validation loss: 1.5856020976138372

Epoch: 6| Step: 11
Training loss: 0.05702190101146698
Validation loss: 1.568047813189927

Epoch: 6| Step: 12
Training loss: 0.07138483971357346
Validation loss: 1.6076599731240222

Epoch: 6| Step: 13
Training loss: 0.05809696391224861
Validation loss: 1.5700232662180418

Epoch: 540| Step: 0
Training loss: 0.10747057944536209
Validation loss: 1.581410349056285

Epoch: 6| Step: 1
Training loss: 0.09899554401636124
Validation loss: 1.5841923888011644

Epoch: 6| Step: 2
Training loss: 0.06802353262901306
Validation loss: 1.5863012908607401

Epoch: 6| Step: 3
Training loss: 0.2033890336751938
Validation loss: 1.5906986639063845

Epoch: 6| Step: 4
Training loss: 0.11222722381353378
Validation loss: 1.6194490245593491

Epoch: 6| Step: 5
Training loss: 0.11609907448291779
Validation loss: 1.5922985922905706

Epoch: 6| Step: 6
Training loss: 0.1475001871585846
Validation loss: 1.6037707636433263

Epoch: 6| Step: 7
Training loss: 0.05690040439367294
Validation loss: 1.6184679000608382

Epoch: 6| Step: 8
Training loss: 0.12201395630836487
Validation loss: 1.6155167779614847

Epoch: 6| Step: 9
Training loss: 0.09065450727939606
Validation loss: 1.5941673132681078

Epoch: 6| Step: 10
Training loss: 0.10513117909431458
Validation loss: 1.5718752325222056

Epoch: 6| Step: 11
Training loss: 0.09383757412433624
Validation loss: 1.599303045580464

Epoch: 6| Step: 12
Training loss: 0.06416068971157074
Validation loss: 1.5536585584763558

Epoch: 6| Step: 13
Training loss: 0.10570265352725983
Validation loss: 1.5663966440385388

Epoch: 541| Step: 0
Training loss: 0.09482771158218384
Validation loss: 1.5674974982456495

Epoch: 6| Step: 1
Training loss: 0.10243481397628784
Validation loss: 1.5759413319249307

Epoch: 6| Step: 2
Training loss: 0.07188010960817337
Validation loss: 1.577735456087256

Epoch: 6| Step: 3
Training loss: 0.07267945259809494
Validation loss: 1.5839311474113054

Epoch: 6| Step: 4
Training loss: 0.10929910838603973
Validation loss: 1.575466355969829

Epoch: 6| Step: 5
Training loss: 0.12311108410358429
Validation loss: 1.6015673862990512

Epoch: 6| Step: 6
Training loss: 0.1432143896818161
Validation loss: 1.6025595498341385

Epoch: 6| Step: 7
Training loss: 0.15570902824401855
Validation loss: 1.6133134929082726

Epoch: 6| Step: 8
Training loss: 0.17072901129722595
Validation loss: 1.6343651279326408

Epoch: 6| Step: 9
Training loss: 0.12852364778518677
Validation loss: 1.6153193391779417

Epoch: 6| Step: 10
Training loss: 0.08909140527248383
Validation loss: 1.603004461975508

Epoch: 6| Step: 11
Training loss: 0.07529611885547638
Validation loss: 1.6175809457737913

Epoch: 6| Step: 12
Training loss: 0.2346220314502716
Validation loss: 1.6127076277168848

Epoch: 6| Step: 13
Training loss: 0.11391183733940125
Validation loss: 1.604875805557415

Epoch: 542| Step: 0
Training loss: 0.11474618315696716
Validation loss: 1.6206137364910496

Epoch: 6| Step: 1
Training loss: 0.12387793511152267
Validation loss: 1.5954095202107583

Epoch: 6| Step: 2
Training loss: 0.06278512626886368
Validation loss: 1.5781057201406008

Epoch: 6| Step: 3
Training loss: 0.1470106840133667
Validation loss: 1.6039137840270996

Epoch: 6| Step: 4
Training loss: 0.2365013211965561
Validation loss: 1.597124292004493

Epoch: 6| Step: 5
Training loss: 0.08457903563976288
Validation loss: 1.5930641274298392

Epoch: 6| Step: 6
Training loss: 0.0738530382514
Validation loss: 1.598646334422532

Epoch: 6| Step: 7
Training loss: 0.046927034854888916
Validation loss: 1.5749316100151307

Epoch: 6| Step: 8
Training loss: 0.19019970297813416
Validation loss: 1.5748177010525939

Epoch: 6| Step: 9
Training loss: 0.10573801398277283
Validation loss: 1.5862799857252388

Epoch: 6| Step: 10
Training loss: 0.13153350353240967
Validation loss: 1.591486297627931

Epoch: 6| Step: 11
Training loss: 0.09533476084470749
Validation loss: 1.5804541200719855

Epoch: 6| Step: 12
Training loss: 0.06836079061031342
Validation loss: 1.6075988085039201

Epoch: 6| Step: 13
Training loss: 0.1030968576669693
Validation loss: 1.601277873080264

Epoch: 543| Step: 0
Training loss: 0.08640027046203613
Validation loss: 1.5903260771946242

Epoch: 6| Step: 1
Training loss: 0.11000585556030273
Validation loss: 1.5753245001198144

Epoch: 6| Step: 2
Training loss: 0.0489048957824707
Validation loss: 1.5758226962499722

Epoch: 6| Step: 3
Training loss: 0.126929372549057
Validation loss: 1.5922088994774768

Epoch: 6| Step: 4
Training loss: 0.10718642920255661
Validation loss: 1.5852698613238592

Epoch: 6| Step: 5
Training loss: 0.09507997334003448
Validation loss: 1.6000516709461008

Epoch: 6| Step: 6
Training loss: 0.049601584672927856
Validation loss: 1.5876963587217434

Epoch: 6| Step: 7
Training loss: 0.11421416699886322
Validation loss: 1.6040831112092542

Epoch: 6| Step: 8
Training loss: 0.12752100825309753
Validation loss: 1.5799264574563632

Epoch: 6| Step: 9
Training loss: 0.08709092438220978
Validation loss: 1.5632278560310282

Epoch: 6| Step: 10
Training loss: 0.07147236913442612
Validation loss: 1.5763328921410344

Epoch: 6| Step: 11
Training loss: 0.1618947833776474
Validation loss: 1.5774581291342293

Epoch: 6| Step: 12
Training loss: 0.17065393924713135
Validation loss: 1.5785541252423358

Epoch: 6| Step: 13
Training loss: 0.10554951429367065
Validation loss: 1.6102083242067726

Epoch: 544| Step: 0
Training loss: 0.19652442634105682
Validation loss: 1.6014945981323079

Epoch: 6| Step: 1
Training loss: 0.1667250096797943
Validation loss: 1.6275460630334833

Epoch: 6| Step: 2
Training loss: 0.1022254005074501
Validation loss: 1.6181193192799885

Epoch: 6| Step: 3
Training loss: 0.11230065673589706
Validation loss: 1.609463204619705

Epoch: 6| Step: 4
Training loss: 0.12660574913024902
Validation loss: 1.6124545271678636

Epoch: 6| Step: 5
Training loss: 0.05357760936021805
Validation loss: 1.61518261765921

Epoch: 6| Step: 6
Training loss: 0.07079390436410904
Validation loss: 1.6184509313234718

Epoch: 6| Step: 7
Training loss: 0.10418865084648132
Validation loss: 1.609221367425816

Epoch: 6| Step: 8
Training loss: 0.12250030785799026
Validation loss: 1.5926362737532584

Epoch: 6| Step: 9
Training loss: 0.0838221088051796
Validation loss: 1.5868337128752021

Epoch: 6| Step: 10
Training loss: 0.06650839745998383
Validation loss: 1.586780450677359

Epoch: 6| Step: 11
Training loss: 0.11024495959281921
Validation loss: 1.591212236753074

Epoch: 6| Step: 12
Training loss: 0.07979216426610947
Validation loss: 1.5836359813649168

Epoch: 6| Step: 13
Training loss: 0.06761565804481506
Validation loss: 1.6023949474416754

Epoch: 545| Step: 0
Training loss: 0.12068091332912445
Validation loss: 1.5989679982585292

Epoch: 6| Step: 1
Training loss: 0.10096906125545502
Validation loss: 1.5749455036655549

Epoch: 6| Step: 2
Training loss: 0.1341738998889923
Validation loss: 1.6013012406646565

Epoch: 6| Step: 3
Training loss: 0.07661302387714386
Validation loss: 1.5893844237891577

Epoch: 6| Step: 4
Training loss: 0.07492350041866302
Validation loss: 1.6199734569877706

Epoch: 6| Step: 5
Training loss: 0.060059092938899994
Validation loss: 1.6085463044463948

Epoch: 6| Step: 6
Training loss: 0.057662054896354675
Validation loss: 1.6188644952671503

Epoch: 6| Step: 7
Training loss: 0.10909157991409302
Validation loss: 1.6234625936836324

Epoch: 6| Step: 8
Training loss: 0.074452705681324
Validation loss: 1.6385046359031432

Epoch: 6| Step: 9
Training loss: 0.1102568656206131
Validation loss: 1.6226218285099152

Epoch: 6| Step: 10
Training loss: 0.11119125783443451
Validation loss: 1.6399592020178353

Epoch: 6| Step: 11
Training loss: 0.10680784285068512
Validation loss: 1.6471762759711153

Epoch: 6| Step: 12
Training loss: 0.2367076724767685
Validation loss: 1.6263964804269935

Epoch: 6| Step: 13
Training loss: 0.044628724455833435
Validation loss: 1.6273006880155174

Epoch: 546| Step: 0
Training loss: 0.0773971825838089
Validation loss: 1.5866908129825388

Epoch: 6| Step: 1
Training loss: 0.26270556449890137
Validation loss: 1.6054581634459957

Epoch: 6| Step: 2
Training loss: 0.0680282786488533
Validation loss: 1.6181678592517812

Epoch: 6| Step: 3
Training loss: 0.09175878763198853
Validation loss: 1.583508142860987

Epoch: 6| Step: 4
Training loss: 0.1077125072479248
Validation loss: 1.6028290551195863

Epoch: 6| Step: 5
Training loss: 0.06144636869430542
Validation loss: 1.5862770875295003

Epoch: 6| Step: 6
Training loss: 0.0989154577255249
Validation loss: 1.599108188383041

Epoch: 6| Step: 7
Training loss: 0.09680022299289703
Validation loss: 1.6094788607730661

Epoch: 6| Step: 8
Training loss: 0.04059227555990219
Validation loss: 1.5951710221587971

Epoch: 6| Step: 9
Training loss: 0.09621389210224152
Validation loss: 1.5998644444250292

Epoch: 6| Step: 10
Training loss: 0.10386518388986588
Validation loss: 1.5847596160827144

Epoch: 6| Step: 11
Training loss: 0.09239667654037476
Validation loss: 1.6054336601688015

Epoch: 6| Step: 12
Training loss: 0.039382994174957275
Validation loss: 1.605061084993424

Epoch: 6| Step: 13
Training loss: 0.06513852626085281
Validation loss: 1.604949802480718

Epoch: 547| Step: 0
Training loss: 0.1631840616464615
Validation loss: 1.6086763784449587

Epoch: 6| Step: 1
Training loss: 0.0692913830280304
Validation loss: 1.6069301623170094

Epoch: 6| Step: 2
Training loss: 0.11009624600410461
Validation loss: 1.6298376719156902

Epoch: 6| Step: 3
Training loss: 0.08196403086185455
Validation loss: 1.6181487037289528

Epoch: 6| Step: 4
Training loss: 0.0847993865609169
Validation loss: 1.6162126474483038

Epoch: 6| Step: 5
Training loss: 0.08561922609806061
Validation loss: 1.621987929908178

Epoch: 6| Step: 6
Training loss: 0.060392480343580246
Validation loss: 1.6275766575208275

Epoch: 6| Step: 7
Training loss: 0.16675075888633728
Validation loss: 1.6350513709488737

Epoch: 6| Step: 8
Training loss: 0.03618670254945755
Validation loss: 1.6025457318111131

Epoch: 6| Step: 9
Training loss: 0.20649506151676178
Validation loss: 1.5719918589438162

Epoch: 6| Step: 10
Training loss: 0.04992800951004028
Validation loss: 1.5947214518823931

Epoch: 6| Step: 11
Training loss: 0.08536148071289062
Validation loss: 1.5941351825191128

Epoch: 6| Step: 12
Training loss: 0.11286119371652603
Validation loss: 1.597836321400058

Epoch: 6| Step: 13
Training loss: 0.1423804610967636
Validation loss: 1.5822010514556721

Epoch: 548| Step: 0
Training loss: 0.22227123379707336
Validation loss: 1.5878821713950044

Epoch: 6| Step: 1
Training loss: 0.09345261752605438
Validation loss: 1.5585417568042714

Epoch: 6| Step: 2
Training loss: 0.057457469403743744
Validation loss: 1.5833020082084082

Epoch: 6| Step: 3
Training loss: 0.08752164989709854
Validation loss: 1.6127023786626837

Epoch: 6| Step: 4
Training loss: 0.12817411124706268
Validation loss: 1.6364798840656076

Epoch: 6| Step: 5
Training loss: 0.07015001028776169
Validation loss: 1.6435330952367475

Epoch: 6| Step: 6
Training loss: 0.11374667286872864
Validation loss: 1.6545895376513082

Epoch: 6| Step: 7
Training loss: 0.2441014051437378
Validation loss: 1.6398380930705736

Epoch: 6| Step: 8
Training loss: 0.10103739798069
Validation loss: 1.6584473681706253

Epoch: 6| Step: 9
Training loss: 0.15092012286186218
Validation loss: 1.6516632969661424

Epoch: 6| Step: 10
Training loss: 0.12328746169805527
Validation loss: 1.5909849136106429

Epoch: 6| Step: 11
Training loss: 0.15314887464046478
Validation loss: 1.6288067627978582

Epoch: 6| Step: 12
Training loss: 0.11504021286964417
Validation loss: 1.6068486910994335

Epoch: 6| Step: 13
Training loss: 0.07420364767313004
Validation loss: 1.6213975734608148

Epoch: 549| Step: 0
Training loss: 0.052270129323005676
Validation loss: 1.609942275990722

Epoch: 6| Step: 1
Training loss: 0.0809350311756134
Validation loss: 1.6077077581036476

Epoch: 6| Step: 2
Training loss: 0.11434648931026459
Validation loss: 1.6092275855361775

Epoch: 6| Step: 3
Training loss: 0.05493764579296112
Validation loss: 1.6175673911648412

Epoch: 6| Step: 4
Training loss: 0.10967586934566498
Validation loss: 1.608281430377755

Epoch: 6| Step: 5
Training loss: 0.3079301714897156
Validation loss: 1.6151244101985809

Epoch: 6| Step: 6
Training loss: 0.0711003914475441
Validation loss: 1.6111798799166115

Epoch: 6| Step: 7
Training loss: 0.06637480854988098
Validation loss: 1.6301311985138924

Epoch: 6| Step: 8
Training loss: 0.11119896173477173
Validation loss: 1.5984279571040985

Epoch: 6| Step: 9
Training loss: 0.07418204098939896
Validation loss: 1.599050147559053

Epoch: 6| Step: 10
Training loss: 0.1720367670059204
Validation loss: 1.5797002828249367

Epoch: 6| Step: 11
Training loss: 0.055881090462207794
Validation loss: 1.6028309534954768

Epoch: 6| Step: 12
Training loss: 0.08949480205774307
Validation loss: 1.5700513521830242

Epoch: 6| Step: 13
Training loss: 0.09287634491920471
Validation loss: 1.556019695856238

Epoch: 550| Step: 0
Training loss: 0.1427633911371231
Validation loss: 1.581455840859362

Epoch: 6| Step: 1
Training loss: 0.07277590036392212
Validation loss: 1.6337300577471334

Epoch: 6| Step: 2
Training loss: 0.19916419684886932
Validation loss: 1.588672161102295

Epoch: 6| Step: 3
Training loss: 0.07900044322013855
Validation loss: 1.6025611956914265

Epoch: 6| Step: 4
Training loss: 0.06949889659881592
Validation loss: 1.5857395536156111

Epoch: 6| Step: 5
Training loss: 0.08147233724594116
Validation loss: 1.607296048953969

Epoch: 6| Step: 6
Training loss: 0.09021104872226715
Validation loss: 1.6304038199045325

Epoch: 6| Step: 7
Training loss: 0.07310828566551208
Validation loss: 1.6434205385946459

Epoch: 6| Step: 8
Training loss: 0.08559365570545197
Validation loss: 1.6348387272127214

Epoch: 6| Step: 9
Training loss: 0.08351313322782516
Validation loss: 1.6361076190907469

Epoch: 6| Step: 10
Training loss: 0.08139143884181976
Validation loss: 1.6167079787100516

Epoch: 6| Step: 11
Training loss: 0.07518626004457474
Validation loss: 1.6347283817106677

Epoch: 6| Step: 12
Training loss: 0.16264957189559937
Validation loss: 1.6365839268571587

Epoch: 6| Step: 13
Training loss: 0.21145041286945343
Validation loss: 1.6057049279571862

Epoch: 551| Step: 0
Training loss: 0.0526517853140831
Validation loss: 1.6036089620282572

Epoch: 6| Step: 1
Training loss: 0.06833904981613159
Validation loss: 1.574464887701055

Epoch: 6| Step: 2
Training loss: 0.08619418740272522
Validation loss: 1.600013739319258

Epoch: 6| Step: 3
Training loss: 0.07641559839248657
Validation loss: 1.6092172976463073

Epoch: 6| Step: 4
Training loss: 0.11385007947683334
Validation loss: 1.5952464419026529

Epoch: 6| Step: 5
Training loss: 0.10172896087169647
Validation loss: 1.5980671605756205

Epoch: 6| Step: 6
Training loss: 0.11938665807247162
Validation loss: 1.599112545290301

Epoch: 6| Step: 7
Training loss: 0.13044938445091248
Validation loss: 1.5965028360325804

Epoch: 6| Step: 8
Training loss: 0.12095271795988083
Validation loss: 1.5986297899676907

Epoch: 6| Step: 9
Training loss: 0.24367544054985046
Validation loss: 1.619666903249679

Epoch: 6| Step: 10
Training loss: 0.10120008140802383
Validation loss: 1.6231898312927575

Epoch: 6| Step: 11
Training loss: 0.08468500524759293
Validation loss: 1.6197579278740832

Epoch: 6| Step: 12
Training loss: 0.10266007483005524
Validation loss: 1.6230594406845749

Epoch: 6| Step: 13
Training loss: 0.05602720007300377
Validation loss: 1.6233715511137439

Epoch: 552| Step: 0
Training loss: 0.061788491904735565
Validation loss: 1.6160061795224425

Epoch: 6| Step: 1
Training loss: 0.13181397318840027
Validation loss: 1.6337689584301365

Epoch: 6| Step: 2
Training loss: 0.08718077093362808
Validation loss: 1.6259767188820788

Epoch: 6| Step: 3
Training loss: 0.17107519507408142
Validation loss: 1.6178899413795882

Epoch: 6| Step: 4
Training loss: 0.0802890956401825
Validation loss: 1.6261525936024164

Epoch: 6| Step: 5
Training loss: 0.1031293272972107
Validation loss: 1.6204811424337409

Epoch: 6| Step: 6
Training loss: 0.1641840934753418
Validation loss: 1.5970838967189993

Epoch: 6| Step: 7
Training loss: 0.05988450348377228
Validation loss: 1.6013240609117734

Epoch: 6| Step: 8
Training loss: 0.0577734000980854
Validation loss: 1.6072214162477882

Epoch: 6| Step: 9
Training loss: 0.08977798372507095
Validation loss: 1.5760292289077595

Epoch: 6| Step: 10
Training loss: 0.07291989028453827
Validation loss: 1.5546033715689054

Epoch: 6| Step: 11
Training loss: 0.06092599779367447
Validation loss: 1.5748291759080784

Epoch: 6| Step: 12
Training loss: 0.066177137196064
Validation loss: 1.5950953729691044

Epoch: 6| Step: 13
Training loss: 0.07525734603404999
Validation loss: 1.583321213722229

Epoch: 553| Step: 0
Training loss: 0.07923173159360886
Validation loss: 1.5719703756352907

Epoch: 6| Step: 1
Training loss: 0.07520764321088791
Validation loss: 1.587939336735715

Epoch: 6| Step: 2
Training loss: 0.09660070389509201
Validation loss: 1.5793703371478665

Epoch: 6| Step: 3
Training loss: 0.06154970824718475
Validation loss: 1.6064253327667073

Epoch: 6| Step: 4
Training loss: 0.22031210362911224
Validation loss: 1.6016111476446993

Epoch: 6| Step: 5
Training loss: 0.11903107911348343
Validation loss: 1.5841235524864608

Epoch: 6| Step: 6
Training loss: 0.07379908859729767
Validation loss: 1.575788955534658

Epoch: 6| Step: 7
Training loss: 0.05838073790073395
Validation loss: 1.5762092272440593

Epoch: 6| Step: 8
Training loss: 0.06869405508041382
Validation loss: 1.5961314862774265

Epoch: 6| Step: 9
Training loss: 0.1329847276210785
Validation loss: 1.5663913001296341

Epoch: 6| Step: 10
Training loss: 0.124232716858387
Validation loss: 1.5812924485052786

Epoch: 6| Step: 11
Training loss: 0.17100229859352112
Validation loss: 1.592049152620377

Epoch: 6| Step: 12
Training loss: 0.142489492893219
Validation loss: 1.5847299047695693

Epoch: 6| Step: 13
Training loss: 0.09682133793830872
Validation loss: 1.5783682805235668

Epoch: 554| Step: 0
Training loss: 0.051762063056230545
Validation loss: 1.5774420486983431

Epoch: 6| Step: 1
Training loss: 0.1055285781621933
Validation loss: 1.5891603436521304

Epoch: 6| Step: 2
Training loss: 0.1495407521724701
Validation loss: 1.6191948242084955

Epoch: 6| Step: 3
Training loss: 0.13165906071662903
Validation loss: 1.6131360659035303

Epoch: 6| Step: 4
Training loss: 0.11491920799016953
Validation loss: 1.627251531488152

Epoch: 6| Step: 5
Training loss: 0.12173748016357422
Validation loss: 1.6356870692263368

Epoch: 6| Step: 6
Training loss: 0.0741131529211998
Validation loss: 1.5651912702027189

Epoch: 6| Step: 7
Training loss: 0.06513794511556625
Validation loss: 1.5490993838156424

Epoch: 6| Step: 8
Training loss: 0.10605435073375702
Validation loss: 1.538891973034028

Epoch: 6| Step: 9
Training loss: 0.10816233605146408
Validation loss: 1.5364696441158172

Epoch: 6| Step: 10
Training loss: 0.18400761485099792
Validation loss: 1.558445833062613

Epoch: 6| Step: 11
Training loss: 0.0769658014178276
Validation loss: 1.5415558379183534

Epoch: 6| Step: 12
Training loss: 0.05826391279697418
Validation loss: 1.5614854597276258

Epoch: 6| Step: 13
Training loss: 0.11063795536756516
Validation loss: 1.5927158222403577

Epoch: 555| Step: 0
Training loss: 0.08384023606777191
Validation loss: 1.5757661775876117

Epoch: 6| Step: 1
Training loss: 0.15414613485336304
Validation loss: 1.6374742369497977

Epoch: 6| Step: 2
Training loss: 0.09853672981262207
Validation loss: 1.6154030817811207

Epoch: 6| Step: 3
Training loss: 0.09758608788251877
Validation loss: 1.6272433278381184

Epoch: 6| Step: 4
Training loss: 0.20947666466236115
Validation loss: 1.6236760770120928

Epoch: 6| Step: 5
Training loss: 0.1800745576620102
Validation loss: 1.6182233569442586

Epoch: 6| Step: 6
Training loss: 0.1230342760682106
Validation loss: 1.6203736733364802

Epoch: 6| Step: 7
Training loss: 0.18333128094673157
Validation loss: 1.587679337429744

Epoch: 6| Step: 8
Training loss: 0.10636699944734573
Validation loss: 1.5726221171758508

Epoch: 6| Step: 9
Training loss: 0.1599682867527008
Validation loss: 1.5807801369697816

Epoch: 6| Step: 10
Training loss: 0.11243191361427307
Validation loss: 1.5414770546779837

Epoch: 6| Step: 11
Training loss: 0.054048217833042145
Validation loss: 1.5857476848427967

Epoch: 6| Step: 12
Training loss: 0.08899624645709991
Validation loss: 1.582780263757193

Epoch: 6| Step: 13
Training loss: 0.14983081817626953
Validation loss: 1.6213593098425096

Epoch: 556| Step: 0
Training loss: 0.17678585648536682
Validation loss: 1.6028384918807654

Epoch: 6| Step: 1
Training loss: 0.11020832508802414
Validation loss: 1.6142460376985612

Epoch: 6| Step: 2
Training loss: 0.14020034670829773
Validation loss: 1.6393221706472418

Epoch: 6| Step: 3
Training loss: 0.12357445806264877
Validation loss: 1.6402676810500443

Epoch: 6| Step: 4
Training loss: 0.14360061287879944
Validation loss: 1.6462605589179582

Epoch: 6| Step: 5
Training loss: 0.07842373847961426
Validation loss: 1.627913676282411

Epoch: 6| Step: 6
Training loss: 0.1110369861125946
Validation loss: 1.6045698363293883

Epoch: 6| Step: 7
Training loss: 0.12584984302520752
Validation loss: 1.5971867570313074

Epoch: 6| Step: 8
Training loss: 0.07750961929559708
Validation loss: 1.576788648482292

Epoch: 6| Step: 9
Training loss: 0.12962278723716736
Validation loss: 1.547879510028388

Epoch: 6| Step: 10
Training loss: 0.24824389815330505
Validation loss: 1.546671022651016

Epoch: 6| Step: 11
Training loss: 0.05805319920182228
Validation loss: 1.5552017099113875

Epoch: 6| Step: 12
Training loss: 0.08620134741067886
Validation loss: 1.5309785335294661

Epoch: 6| Step: 13
Training loss: 0.059785619378089905
Validation loss: 1.538623131090595

Epoch: 557| Step: 0
Training loss: 0.19705717265605927
Validation loss: 1.5286577516986477

Epoch: 6| Step: 1
Training loss: 0.1229570284485817
Validation loss: 1.5479613542556763

Epoch: 6| Step: 2
Training loss: 0.08821506798267365
Validation loss: 1.5686180591583252

Epoch: 6| Step: 3
Training loss: 0.06987341493368149
Validation loss: 1.5583858746354298

Epoch: 6| Step: 4
Training loss: 0.06145288050174713
Validation loss: 1.5595121563121837

Epoch: 6| Step: 5
Training loss: 0.08468509465456009
Validation loss: 1.57886367459451

Epoch: 6| Step: 6
Training loss: 0.11554484069347382
Validation loss: 1.5688807618233465

Epoch: 6| Step: 7
Training loss: 0.07358980178833008
Validation loss: 1.5639823457246185

Epoch: 6| Step: 8
Training loss: 0.11052774637937546
Validation loss: 1.5817054266570716

Epoch: 6| Step: 9
Training loss: 0.07216229289770126
Validation loss: 1.5703926073607577

Epoch: 6| Step: 10
Training loss: 0.1640278697013855
Validation loss: 1.5814702357015302

Epoch: 6| Step: 11
Training loss: 0.15493622422218323
Validation loss: 1.5645003293150215

Epoch: 6| Step: 12
Training loss: 0.15601150691509247
Validation loss: 1.58038741542447

Epoch: 6| Step: 13
Training loss: 0.09005454182624817
Validation loss: 1.588714438100015

Epoch: 558| Step: 0
Training loss: 0.12763769924640656
Validation loss: 1.5492443435935563

Epoch: 6| Step: 1
Training loss: 0.1177455261349678
Validation loss: 1.5800202738854192

Epoch: 6| Step: 2
Training loss: 0.16939884424209595
Validation loss: 1.589722309061276

Epoch: 6| Step: 3
Training loss: 0.13143113255500793
Validation loss: 1.5589331298746087

Epoch: 6| Step: 4
Training loss: 0.06802190095186234
Validation loss: 1.5540342689842306

Epoch: 6| Step: 5
Training loss: 0.05991687625646591
Validation loss: 1.5746831022283083

Epoch: 6| Step: 6
Training loss: 0.1267097294330597
Validation loss: 1.5361259239976124

Epoch: 6| Step: 7
Training loss: 0.14784693717956543
Validation loss: 1.5491659128537743

Epoch: 6| Step: 8
Training loss: 0.09817405045032501
Validation loss: 1.5354015750269736

Epoch: 6| Step: 9
Training loss: 0.0767185315489769
Validation loss: 1.5579354032393424

Epoch: 6| Step: 10
Training loss: 0.2534217834472656
Validation loss: 1.5576379042799755

Epoch: 6| Step: 11
Training loss: 0.1403397023677826
Validation loss: 1.5837342303286317

Epoch: 6| Step: 12
Training loss: 0.07050330936908722
Validation loss: 1.5852206189145324

Epoch: 6| Step: 13
Training loss: 0.1509891301393509
Validation loss: 1.5650315233456191

Epoch: 559| Step: 0
Training loss: 0.04547836259007454
Validation loss: 1.601568341255188

Epoch: 6| Step: 1
Training loss: 0.18059863150119781
Validation loss: 1.5799143557907434

Epoch: 6| Step: 2
Training loss: 0.07396287471055984
Validation loss: 1.5721634088024017

Epoch: 6| Step: 3
Training loss: 0.09385861456394196
Validation loss: 1.570129858550205

Epoch: 6| Step: 4
Training loss: 0.07740607857704163
Validation loss: 1.5951094935017247

Epoch: 6| Step: 5
Training loss: 0.12388907372951508
Validation loss: 1.5935710745473062

Epoch: 6| Step: 6
Training loss: 0.12095368653535843
Validation loss: 1.598841744084512

Epoch: 6| Step: 7
Training loss: 0.10855531692504883
Validation loss: 1.5933797859376477

Epoch: 6| Step: 8
Training loss: 0.15892428159713745
Validation loss: 1.5942911704381306

Epoch: 6| Step: 9
Training loss: 0.2028544545173645
Validation loss: 1.593952848065284

Epoch: 6| Step: 10
Training loss: 0.12727820873260498
Validation loss: 1.5715321571596208

Epoch: 6| Step: 11
Training loss: 0.04802752286195755
Validation loss: 1.571608656196184

Epoch: 6| Step: 12
Training loss: 0.053338855504989624
Validation loss: 1.5929002249112694

Epoch: 6| Step: 13
Training loss: 0.06713896244764328
Validation loss: 1.5521886399997178

Epoch: 560| Step: 0
Training loss: 0.06373348832130432
Validation loss: 1.6027727973076604

Epoch: 6| Step: 1
Training loss: 0.08483627438545227
Validation loss: 1.5850924291918356

Epoch: 6| Step: 2
Training loss: 0.09552931785583496
Validation loss: 1.5830194193829772

Epoch: 6| Step: 3
Training loss: 0.0479251965880394
Validation loss: 1.594275027193049

Epoch: 6| Step: 4
Training loss: 0.06643795967102051
Validation loss: 1.5967802168220602

Epoch: 6| Step: 5
Training loss: 0.056754231452941895
Validation loss: 1.5974877752283567

Epoch: 6| Step: 6
Training loss: 0.06130150705575943
Validation loss: 1.5932129249777844

Epoch: 6| Step: 7
Training loss: 0.24381133913993835
Validation loss: 1.616866486046904

Epoch: 6| Step: 8
Training loss: 0.09892416000366211
Validation loss: 1.596223094130075

Epoch: 6| Step: 9
Training loss: 0.12192418426275253
Validation loss: 1.6045667394515006

Epoch: 6| Step: 10
Training loss: 0.12481711059808731
Validation loss: 1.5990209964013868

Epoch: 6| Step: 11
Training loss: 0.16652315855026245
Validation loss: 1.5862624324778074

Epoch: 6| Step: 12
Training loss: 0.132222980260849
Validation loss: 1.59119108159055

Epoch: 6| Step: 13
Training loss: 0.175901859998703
Validation loss: 1.567465410437635

Epoch: 561| Step: 0
Training loss: 0.15286606550216675
Validation loss: 1.5832752963548065

Epoch: 6| Step: 1
Training loss: 0.20163114368915558
Validation loss: 1.5906122884442728

Epoch: 6| Step: 2
Training loss: 0.12891295552253723
Validation loss: 1.5807325455450243

Epoch: 6| Step: 3
Training loss: 0.05940466746687889
Validation loss: 1.5784405969804334

Epoch: 6| Step: 4
Training loss: 0.10842172801494598
Validation loss: 1.5740023005393244

Epoch: 6| Step: 5
Training loss: 0.12416461855173111
Validation loss: 1.563184724059156

Epoch: 6| Step: 6
Training loss: 0.12278777360916138
Validation loss: 1.5914969008455995

Epoch: 6| Step: 7
Training loss: 0.09896932542324066
Validation loss: 1.5710978905359905

Epoch: 6| Step: 8
Training loss: 0.11933034658432007
Validation loss: 1.5958932292076848

Epoch: 6| Step: 9
Training loss: 0.06452298909425735
Validation loss: 1.5827556758798578

Epoch: 6| Step: 10
Training loss: 0.21836568415164948
Validation loss: 1.5640414927595405

Epoch: 6| Step: 11
Training loss: 0.05623049661517143
Validation loss: 1.5795809235624088

Epoch: 6| Step: 12
Training loss: 0.1168159618973732
Validation loss: 1.57911773907241

Epoch: 6| Step: 13
Training loss: 0.15188631415367126
Validation loss: 1.547368428399486

Epoch: 562| Step: 0
Training loss: 0.07619122415781021
Validation loss: 1.5570428736748234

Epoch: 6| Step: 1
Training loss: 0.07340153306722641
Validation loss: 1.5735303791620399

Epoch: 6| Step: 2
Training loss: 0.07419119030237198
Validation loss: 1.5705137201534805

Epoch: 6| Step: 3
Training loss: 0.11521720886230469
Validation loss: 1.6058621803919475

Epoch: 6| Step: 4
Training loss: 0.08765631914138794
Validation loss: 1.6127592350846978

Epoch: 6| Step: 5
Training loss: 0.06368724256753922
Validation loss: 1.6040087246125745

Epoch: 6| Step: 6
Training loss: 0.14370614290237427
Validation loss: 1.617744004854592

Epoch: 6| Step: 7
Training loss: 0.038112200796604156
Validation loss: 1.6085190298736736

Epoch: 6| Step: 8
Training loss: 0.10480673611164093
Validation loss: 1.6169142928174747

Epoch: 6| Step: 9
Training loss: 0.05575408414006233
Validation loss: 1.6038081069146433

Epoch: 6| Step: 10
Training loss: 0.052257806062698364
Validation loss: 1.572396271972246

Epoch: 6| Step: 11
Training loss: 0.21674932539463043
Validation loss: 1.5879116353168283

Epoch: 6| Step: 12
Training loss: 0.07782568037509918
Validation loss: 1.5986765994820544

Epoch: 6| Step: 13
Training loss: 0.08184339106082916
Validation loss: 1.5880898647410895

Epoch: 563| Step: 0
Training loss: 0.07510077953338623
Validation loss: 1.5943085275670534

Epoch: 6| Step: 1
Training loss: 0.06571488082408905
Validation loss: 1.625948094552563

Epoch: 6| Step: 2
Training loss: 0.13727153837680817
Validation loss: 1.5915301160145832

Epoch: 6| Step: 3
Training loss: 0.07160016894340515
Validation loss: 1.6199124090133175

Epoch: 6| Step: 4
Training loss: 0.1071397066116333
Validation loss: 1.6204565622473275

Epoch: 6| Step: 5
Training loss: 0.100199855864048
Validation loss: 1.6030678261992752

Epoch: 6| Step: 6
Training loss: 0.058250121772289276
Validation loss: 1.5881115967227566

Epoch: 6| Step: 7
Training loss: 0.09961379319429398
Validation loss: 1.6086835630478398

Epoch: 6| Step: 8
Training loss: 0.14828188717365265
Validation loss: 1.5939896420765949

Epoch: 6| Step: 9
Training loss: 0.09362680464982986
Validation loss: 1.610542410163469

Epoch: 6| Step: 10
Training loss: 0.1164407730102539
Validation loss: 1.5930894427402045

Epoch: 6| Step: 11
Training loss: 0.06953199952840805
Validation loss: 1.5892214249539118

Epoch: 6| Step: 12
Training loss: 0.24674849212169647
Validation loss: 1.605878750483195

Epoch: 6| Step: 13
Training loss: 0.061720769852399826
Validation loss: 1.5796064817777244

Epoch: 564| Step: 0
Training loss: 0.09828156232833862
Validation loss: 1.6044202799438148

Epoch: 6| Step: 1
Training loss: 0.08276054263114929
Validation loss: 1.6110409728942379

Epoch: 6| Step: 2
Training loss: 0.07176102697849274
Validation loss: 1.6257350611430343

Epoch: 6| Step: 3
Training loss: 0.10780002921819687
Validation loss: 1.5933228154336252

Epoch: 6| Step: 4
Training loss: 0.11029098927974701
Validation loss: 1.620160146426129

Epoch: 6| Step: 5
Training loss: 0.12111753225326538
Validation loss: 1.595075189426381

Epoch: 6| Step: 6
Training loss: 0.10567568242549896
Validation loss: 1.606120159549098

Epoch: 6| Step: 7
Training loss: 0.08699803054332733
Validation loss: 1.610152639368529

Epoch: 6| Step: 8
Training loss: 0.08543841540813446
Validation loss: 1.5856736629239974

Epoch: 6| Step: 9
Training loss: 0.110963374376297
Validation loss: 1.594008861049529

Epoch: 6| Step: 10
Training loss: 0.09306151419878006
Validation loss: 1.6080509898483113

Epoch: 6| Step: 11
Training loss: 0.111166812479496
Validation loss: 1.6218713073320286

Epoch: 6| Step: 12
Training loss: 0.23021294176578522
Validation loss: 1.5908980574659122

Epoch: 6| Step: 13
Training loss: 0.2959132790565491
Validation loss: 1.5867459774017334

Epoch: 565| Step: 0
Training loss: 0.0806717798113823
Validation loss: 1.6007429540798228

Epoch: 6| Step: 1
Training loss: 0.1253172755241394
Validation loss: 1.5996019250603133

Epoch: 6| Step: 2
Training loss: 0.0926353931427002
Validation loss: 1.5934082564487253

Epoch: 6| Step: 3
Training loss: 0.05097731947898865
Validation loss: 1.5931013732828119

Epoch: 6| Step: 4
Training loss: 0.06510288268327713
Validation loss: 1.619944667303434

Epoch: 6| Step: 5
Training loss: 0.06357159465551376
Validation loss: 1.6078060724401986

Epoch: 6| Step: 6
Training loss: 0.14143255352973938
Validation loss: 1.5843952701937767

Epoch: 6| Step: 7
Training loss: 0.08566391468048096
Validation loss: 1.6040531768593738

Epoch: 6| Step: 8
Training loss: 0.09100338816642761
Validation loss: 1.580102453949631

Epoch: 6| Step: 9
Training loss: 0.10788634419441223
Validation loss: 1.59790285172001

Epoch: 6| Step: 10
Training loss: 0.04956784099340439
Validation loss: 1.6012288857531805

Epoch: 6| Step: 11
Training loss: 0.2139512151479721
Validation loss: 1.5873647934647017

Epoch: 6| Step: 12
Training loss: 0.07998335361480713
Validation loss: 1.5978471476544616

Epoch: 6| Step: 13
Training loss: 0.06037797033786774
Validation loss: 1.6029877547294862

Epoch: 566| Step: 0
Training loss: 0.07513028383255005
Validation loss: 1.6009002706056

Epoch: 6| Step: 1
Training loss: 0.17405137419700623
Validation loss: 1.5779402038102508

Epoch: 6| Step: 2
Training loss: 0.059744078665971756
Validation loss: 1.5662397351316226

Epoch: 6| Step: 3
Training loss: 0.057810697704553604
Validation loss: 1.5603096382592314

Epoch: 6| Step: 4
Training loss: 0.11056812107563019
Validation loss: 1.5701319222809167

Epoch: 6| Step: 5
Training loss: 0.13292968273162842
Validation loss: 1.5711996580964775

Epoch: 6| Step: 6
Training loss: 0.10496029257774353
Validation loss: 1.5745362671472694

Epoch: 6| Step: 7
Training loss: 0.10448348522186279
Validation loss: 1.5760181834620814

Epoch: 6| Step: 8
Training loss: 0.062264833599328995
Validation loss: 1.6059098807714318

Epoch: 6| Step: 9
Training loss: 0.08186075091362
Validation loss: 1.5973928538701867

Epoch: 6| Step: 10
Training loss: 0.10660239309072495
Validation loss: 1.6066504409236293

Epoch: 6| Step: 11
Training loss: 0.05502978712320328
Validation loss: 1.5949745947314846

Epoch: 6| Step: 12
Training loss: 0.0972830131649971
Validation loss: 1.5871714045924525

Epoch: 6| Step: 13
Training loss: 0.07094944268465042
Validation loss: 1.5745578504377795

Epoch: 567| Step: 0
Training loss: 0.10081325471401215
Validation loss: 1.5782397921367357

Epoch: 6| Step: 1
Training loss: 0.0809517428278923
Validation loss: 1.5539423752856512

Epoch: 6| Step: 2
Training loss: 0.05724933370947838
Validation loss: 1.5635362594358382

Epoch: 6| Step: 3
Training loss: 0.07250352203845978
Validation loss: 1.557436361107775

Epoch: 6| Step: 4
Training loss: 0.0688859149813652
Validation loss: 1.5475062298518356

Epoch: 6| Step: 5
Training loss: 0.10479288548231125
Validation loss: 1.5636509080086984

Epoch: 6| Step: 6
Training loss: 0.2124386727809906
Validation loss: 1.571107454197381

Epoch: 6| Step: 7
Training loss: 0.05799942836165428
Validation loss: 1.5773042786505915

Epoch: 6| Step: 8
Training loss: 0.15818938612937927
Validation loss: 1.6051277460590485

Epoch: 6| Step: 9
Training loss: 0.07623615860939026
Validation loss: 1.581151658488858

Epoch: 6| Step: 10
Training loss: 0.0571770966053009
Validation loss: 1.580921712742057

Epoch: 6| Step: 11
Training loss: 0.0809992179274559
Validation loss: 1.5744744834079538

Epoch: 6| Step: 12
Training loss: 0.1534983515739441
Validation loss: 1.5780124292578748

Epoch: 6| Step: 13
Training loss: 0.073651522397995
Validation loss: 1.5823473558630994

Epoch: 568| Step: 0
Training loss: 0.10203871876001358
Validation loss: 1.6067510035730177

Epoch: 6| Step: 1
Training loss: 0.08374123275279999
Validation loss: 1.5865159983276038

Epoch: 6| Step: 2
Training loss: 0.07583124935626984
Validation loss: 1.6165578685781008

Epoch: 6| Step: 3
Training loss: 0.0913512259721756
Validation loss: 1.6070532773130684

Epoch: 6| Step: 4
Training loss: 0.07283537089824677
Validation loss: 1.6133829380876274

Epoch: 6| Step: 5
Training loss: 0.0946883037686348
Validation loss: 1.6036798210554226

Epoch: 6| Step: 6
Training loss: 0.13419979810714722
Validation loss: 1.6158170738527853

Epoch: 6| Step: 7
Training loss: 0.06918136775493622
Validation loss: 1.6180885889196908

Epoch: 6| Step: 8
Training loss: 0.06536246836185455
Validation loss: 1.584995706876119

Epoch: 6| Step: 9
Training loss: 0.04482366144657135
Validation loss: 1.602198298259448

Epoch: 6| Step: 10
Training loss: 0.20169585943222046
Validation loss: 1.5926041167269471

Epoch: 6| Step: 11
Training loss: 0.0903497189283371
Validation loss: 1.5929794516614688

Epoch: 6| Step: 12
Training loss: 0.09912987053394318
Validation loss: 1.574280777285176

Epoch: 6| Step: 13
Training loss: 0.10263490676879883
Validation loss: 1.595304327626382

Epoch: 569| Step: 0
Training loss: 0.1508522927761078
Validation loss: 1.5645183222268217

Epoch: 6| Step: 1
Training loss: 0.05028337985277176
Validation loss: 1.5773427947874992

Epoch: 6| Step: 2
Training loss: 0.08695199340581894
Validation loss: 1.5632195703444942

Epoch: 6| Step: 3
Training loss: 0.1333543062210083
Validation loss: 1.5959595505909254

Epoch: 6| Step: 4
Training loss: 0.0602496899664402
Validation loss: 1.5865435645144472

Epoch: 6| Step: 5
Training loss: 0.0755389854311943
Validation loss: 1.6301138631759151

Epoch: 6| Step: 6
Training loss: 0.08206698298454285
Validation loss: 1.6025378050342682

Epoch: 6| Step: 7
Training loss: 0.05386130511760712
Validation loss: 1.597604501631952

Epoch: 6| Step: 8
Training loss: 0.08615792542695999
Validation loss: 1.610753788742968

Epoch: 6| Step: 9
Training loss: 0.11484938114881516
Validation loss: 1.6048732508895218

Epoch: 6| Step: 10
Training loss: 0.0868406742811203
Validation loss: 1.6157221832583029

Epoch: 6| Step: 11
Training loss: 0.0794496089220047
Validation loss: 1.6070529472443364

Epoch: 6| Step: 12
Training loss: 0.07946977019309998
Validation loss: 1.6007153500792801

Epoch: 6| Step: 13
Training loss: 0.14175944030284882
Validation loss: 1.6298658860627042

Epoch: 570| Step: 0
Training loss: 0.05853688716888428
Validation loss: 1.560083576427993

Epoch: 6| Step: 1
Training loss: 0.12543243169784546
Validation loss: 1.6059569152452613

Epoch: 6| Step: 2
Training loss: 0.07154269516468048
Validation loss: 1.5868637087524577

Epoch: 6| Step: 3
Training loss: 0.12745149433612823
Validation loss: 1.5667008789636756

Epoch: 6| Step: 4
Training loss: 0.052603691816329956
Validation loss: 1.575426560576244

Epoch: 6| Step: 5
Training loss: 0.1429695188999176
Validation loss: 1.5766125725161644

Epoch: 6| Step: 6
Training loss: 0.09302990138530731
Validation loss: 1.561286534032514

Epoch: 6| Step: 7
Training loss: 0.07116430997848511
Validation loss: 1.5874885807755172

Epoch: 6| Step: 8
Training loss: 0.05095095559954643
Validation loss: 1.5790884956236808

Epoch: 6| Step: 9
Training loss: 0.08905324339866638
Validation loss: 1.5884351230436755

Epoch: 6| Step: 10
Training loss: 0.19624152779579163
Validation loss: 1.5568678199603994

Epoch: 6| Step: 11
Training loss: 0.049877576529979706
Validation loss: 1.575893408508711

Epoch: 6| Step: 12
Training loss: 0.10350808501243591
Validation loss: 1.5850022313415364

Epoch: 6| Step: 13
Training loss: 0.02922418713569641
Validation loss: 1.5708303118264804

Epoch: 571| Step: 0
Training loss: 0.06808054447174072
Validation loss: 1.5807430885171379

Epoch: 6| Step: 1
Training loss: 0.10178227722644806
Validation loss: 1.589170935333416

Epoch: 6| Step: 2
Training loss: 0.11177818477153778
Validation loss: 1.6280878359271633

Epoch: 6| Step: 3
Training loss: 0.1345817893743515
Validation loss: 1.6249179981088127

Epoch: 6| Step: 4
Training loss: 0.0945194661617279
Validation loss: 1.6416456084097586

Epoch: 6| Step: 5
Training loss: 0.09301445633172989
Validation loss: 1.6187482021188224

Epoch: 6| Step: 6
Training loss: 0.10702452808618546
Validation loss: 1.5990336300224386

Epoch: 6| Step: 7
Training loss: 0.053502749651670456
Validation loss: 1.5881892840067546

Epoch: 6| Step: 8
Training loss: 0.08682038635015488
Validation loss: 1.6058498729941666

Epoch: 6| Step: 9
Training loss: 0.21684923768043518
Validation loss: 1.5743674437204997

Epoch: 6| Step: 10
Training loss: 0.09617205709218979
Validation loss: 1.562038783104189

Epoch: 6| Step: 11
Training loss: 0.05994367226958275
Validation loss: 1.5630044142405193

Epoch: 6| Step: 12
Training loss: 0.12025641649961472
Validation loss: 1.565028861004819

Epoch: 6| Step: 13
Training loss: 0.04364858567714691
Validation loss: 1.5680873022284558

Epoch: 572| Step: 0
Training loss: 0.16184425354003906
Validation loss: 1.5759389727346358

Epoch: 6| Step: 1
Training loss: 0.14260804653167725
Validation loss: 1.580477649165738

Epoch: 6| Step: 2
Training loss: 0.10235016793012619
Validation loss: 1.5789288782304334

Epoch: 6| Step: 3
Training loss: 0.08278651535511017
Validation loss: 1.5893814486842002

Epoch: 6| Step: 4
Training loss: 0.0877871960401535
Validation loss: 1.5966582900734358

Epoch: 6| Step: 5
Training loss: 0.07392556220293045
Validation loss: 1.5855725042281612

Epoch: 6| Step: 6
Training loss: 0.14505374431610107
Validation loss: 1.5628240839127572

Epoch: 6| Step: 7
Training loss: 0.16248932480812073
Validation loss: 1.5689181089401245

Epoch: 6| Step: 8
Training loss: 0.09365016967058182
Validation loss: 1.5873121228269351

Epoch: 6| Step: 9
Training loss: 0.09012944251298904
Validation loss: 1.5724854225753455

Epoch: 6| Step: 10
Training loss: 0.08799733221530914
Validation loss: 1.5708300862261044

Epoch: 6| Step: 11
Training loss: 0.06708921492099762
Validation loss: 1.5643877521637948

Epoch: 6| Step: 12
Training loss: 0.04709818214178085
Validation loss: 1.5755962517953688

Epoch: 6| Step: 13
Training loss: 0.03798966109752655
Validation loss: 1.5570722690192602

Epoch: 573| Step: 0
Training loss: 0.24006147682666779
Validation loss: 1.5372211433226062

Epoch: 6| Step: 1
Training loss: 0.0997580736875534
Validation loss: 1.5456775747319704

Epoch: 6| Step: 2
Training loss: 0.13020923733711243
Validation loss: 1.563481351380707

Epoch: 6| Step: 3
Training loss: 0.0759938433766365
Validation loss: 1.5451962127480456

Epoch: 6| Step: 4
Training loss: 0.08027569949626923
Validation loss: 1.5650455342826022

Epoch: 6| Step: 5
Training loss: 0.08934645354747772
Validation loss: 1.588326068334682

Epoch: 6| Step: 6
Training loss: 0.11589086055755615
Validation loss: 1.5770256237317157

Epoch: 6| Step: 7
Training loss: 0.0742439329624176
Validation loss: 1.6128397346824728

Epoch: 6| Step: 8
Training loss: 0.07336119562387466
Validation loss: 1.632646168431928

Epoch: 6| Step: 9
Training loss: 0.10902836173772812
Validation loss: 1.620238527174919

Epoch: 6| Step: 10
Training loss: 0.12706944346427917
Validation loss: 1.6546795611740441

Epoch: 6| Step: 11
Training loss: 0.09263330698013306
Validation loss: 1.6182757910861765

Epoch: 6| Step: 12
Training loss: 0.1386781930923462
Validation loss: 1.6058302605023949

Epoch: 6| Step: 13
Training loss: 0.09616623818874359
Validation loss: 1.6006887260303702

Epoch: 574| Step: 0
Training loss: 0.12545767426490784
Validation loss: 1.6095988096729401

Epoch: 6| Step: 1
Training loss: 0.07021209597587585
Validation loss: 1.588715366137925

Epoch: 6| Step: 2
Training loss: 0.08674703538417816
Validation loss: 1.5910745487418225

Epoch: 6| Step: 3
Training loss: 0.2073197066783905
Validation loss: 1.5913333123730076

Epoch: 6| Step: 4
Training loss: 0.14659996330738068
Validation loss: 1.5466822565242808

Epoch: 6| Step: 5
Training loss: 0.08453953266143799
Validation loss: 1.5731165268087899

Epoch: 6| Step: 6
Training loss: 0.06307850778102875
Validation loss: 1.5869736081810408

Epoch: 6| Step: 7
Training loss: 0.10833568871021271
Validation loss: 1.5656398393774544

Epoch: 6| Step: 8
Training loss: 0.0930347591638565
Validation loss: 1.5814037771635159

Epoch: 6| Step: 9
Training loss: 0.1201431155204773
Validation loss: 1.5987271455026442

Epoch: 6| Step: 10
Training loss: 0.1410769522190094
Validation loss: 1.5754901580913092

Epoch: 6| Step: 11
Training loss: 0.09495444595813751
Validation loss: 1.5623857135413795

Epoch: 6| Step: 12
Training loss: 0.16514259576797485
Validation loss: 1.560625248057868

Epoch: 6| Step: 13
Training loss: 0.11525066941976547
Validation loss: 1.5269138313108874

Epoch: 575| Step: 0
Training loss: 0.11767815053462982
Validation loss: 1.571644498455909

Epoch: 6| Step: 1
Training loss: 0.12575620412826538
Validation loss: 1.5538980140480945

Epoch: 6| Step: 2
Training loss: 0.28242188692092896
Validation loss: 1.5509917941144717

Epoch: 6| Step: 3
Training loss: 0.1274494230747223
Validation loss: 1.5738479027184107

Epoch: 6| Step: 4
Training loss: 0.08351797610521317
Validation loss: 1.567371453008344

Epoch: 6| Step: 5
Training loss: 0.0678340494632721
Validation loss: 1.5768927476739372

Epoch: 6| Step: 6
Training loss: 0.04948475956916809
Validation loss: 1.588065190981793

Epoch: 6| Step: 7
Training loss: 0.1572413444519043
Validation loss: 1.6039115100778558

Epoch: 6| Step: 8
Training loss: 0.05106707289814949
Validation loss: 1.5921081573732438

Epoch: 6| Step: 9
Training loss: 0.12050110846757889
Validation loss: 1.5981144687180877

Epoch: 6| Step: 10
Training loss: 0.11850395053625107
Validation loss: 1.5835560419226204

Epoch: 6| Step: 11
Training loss: 0.09370015561580658
Validation loss: 1.5992231907383088

Epoch: 6| Step: 12
Training loss: 0.07028137147426605
Validation loss: 1.5825254442871257

Epoch: 6| Step: 13
Training loss: 0.07570569962263107
Validation loss: 1.5775039426742061

Epoch: 576| Step: 0
Training loss: 0.09706994146108627
Validation loss: 1.5790178827060166

Epoch: 6| Step: 1
Training loss: 0.03727293387055397
Validation loss: 1.5679768849444646

Epoch: 6| Step: 2
Training loss: 0.06927008926868439
Validation loss: 1.5353380890302761

Epoch: 6| Step: 3
Training loss: 0.09373240172863007
Validation loss: 1.5565983505659207

Epoch: 6| Step: 4
Training loss: 0.11615587770938873
Validation loss: 1.5801695540387144

Epoch: 6| Step: 5
Training loss: 0.17280450463294983
Validation loss: 1.5656861592364568

Epoch: 6| Step: 6
Training loss: 0.13069353997707367
Validation loss: 1.5835321558419095

Epoch: 6| Step: 7
Training loss: 0.03828686103224754
Validation loss: 1.5846058553264988

Epoch: 6| Step: 8
Training loss: 0.13008812069892883
Validation loss: 1.5825053799536921

Epoch: 6| Step: 9
Training loss: 0.25372451543807983
Validation loss: 1.5910426749978015

Epoch: 6| Step: 10
Training loss: 0.0705309808254242
Validation loss: 1.575266012581446

Epoch: 6| Step: 11
Training loss: 0.0969371497631073
Validation loss: 1.5890687063176145

Epoch: 6| Step: 12
Training loss: 0.13176605105400085
Validation loss: 1.6315490122764342

Epoch: 6| Step: 13
Training loss: 0.12870560586452484
Validation loss: 1.6074232209113337

Epoch: 577| Step: 0
Training loss: 0.09123227000236511
Validation loss: 1.577204232574791

Epoch: 6| Step: 1
Training loss: 0.10757842659950256
Validation loss: 1.5840601703172088

Epoch: 6| Step: 2
Training loss: 0.11058157682418823
Validation loss: 1.5792971336713402

Epoch: 6| Step: 3
Training loss: 0.19942042231559753
Validation loss: 1.5875606549683439

Epoch: 6| Step: 4
Training loss: 0.09269348531961441
Validation loss: 1.5853469576886905

Epoch: 6| Step: 5
Training loss: 0.15275710821151733
Validation loss: 1.5766888356977893

Epoch: 6| Step: 6
Training loss: 0.1652107536792755
Validation loss: 1.5949319287012982

Epoch: 6| Step: 7
Training loss: 0.09868364036083221
Validation loss: 1.562562713059046

Epoch: 6| Step: 8
Training loss: 0.11059244722127914
Validation loss: 1.5915967508028912

Epoch: 6| Step: 9
Training loss: 0.08210393786430359
Validation loss: 1.6021708160318353

Epoch: 6| Step: 10
Training loss: 0.12990343570709229
Validation loss: 1.577551891085922

Epoch: 6| Step: 11
Training loss: 0.1283811628818512
Validation loss: 1.6065034571514334

Epoch: 6| Step: 12
Training loss: 0.07882650196552277
Validation loss: 1.604294337252135

Epoch: 6| Step: 13
Training loss: 0.20818111300468445
Validation loss: 1.6252958928385088

Epoch: 578| Step: 0
Training loss: 0.10841850191354752
Validation loss: 1.6102190261246057

Epoch: 6| Step: 1
Training loss: 0.19138073921203613
Validation loss: 1.588504893805391

Epoch: 6| Step: 2
Training loss: 0.19455121457576752
Validation loss: 1.581931823043413

Epoch: 6| Step: 3
Training loss: 0.07313375920057297
Validation loss: 1.5678380740586149

Epoch: 6| Step: 4
Training loss: 0.08779443800449371
Validation loss: 1.5597423020229544

Epoch: 6| Step: 5
Training loss: 0.08089904487133026
Validation loss: 1.5753903376158847

Epoch: 6| Step: 6
Training loss: 0.1500188559293747
Validation loss: 1.5752224922180176

Epoch: 6| Step: 7
Training loss: 0.10776398330926895
Validation loss: 1.5570020303931287

Epoch: 6| Step: 8
Training loss: 0.11698048561811447
Validation loss: 1.5640537713163642

Epoch: 6| Step: 9
Training loss: 0.07576661556959152
Validation loss: 1.5334739031330231

Epoch: 6| Step: 10
Training loss: 0.06642274558544159
Validation loss: 1.5475114936469703

Epoch: 6| Step: 11
Training loss: 0.1263885498046875
Validation loss: 1.5499006279053227

Epoch: 6| Step: 12
Training loss: 0.10180798172950745
Validation loss: 1.556235554397747

Epoch: 6| Step: 13
Training loss: 0.10391485691070557
Validation loss: 1.5832012161131828

Epoch: 579| Step: 0
Training loss: 0.07370898127555847
Validation loss: 1.5565960657212041

Epoch: 6| Step: 1
Training loss: 0.08759468793869019
Validation loss: 1.5870188974565076

Epoch: 6| Step: 2
Training loss: 0.07761096954345703
Validation loss: 1.545934679687664

Epoch: 6| Step: 3
Training loss: 0.0473223514854908
Validation loss: 1.5897958022291943

Epoch: 6| Step: 4
Training loss: 0.08156131207942963
Validation loss: 1.5520318310747865

Epoch: 6| Step: 5
Training loss: 0.1959320604801178
Validation loss: 1.5787900288899739

Epoch: 6| Step: 6
Training loss: 0.12078246474266052
Validation loss: 1.543513656944357

Epoch: 6| Step: 7
Training loss: 0.09743151813745499
Validation loss: 1.5492023383417437

Epoch: 6| Step: 8
Training loss: 0.06593906134366989
Validation loss: 1.5648844677914855

Epoch: 6| Step: 9
Training loss: 0.06720708310604095
Validation loss: 1.5738839974967382

Epoch: 6| Step: 10
Training loss: 0.1139347106218338
Validation loss: 1.570370667724199

Epoch: 6| Step: 11
Training loss: 0.08973698318004608
Validation loss: 1.545715803741127

Epoch: 6| Step: 12
Training loss: 0.12938815355300903
Validation loss: 1.5714433872571556

Epoch: 6| Step: 13
Training loss: 0.0639709085226059
Validation loss: 1.5595582838981383

Epoch: 580| Step: 0
Training loss: 0.15405899286270142
Validation loss: 1.5633000327694802

Epoch: 6| Step: 1
Training loss: 0.10399173945188522
Validation loss: 1.5826812982559204

Epoch: 6| Step: 2
Training loss: 0.071178138256073
Validation loss: 1.572232957809202

Epoch: 6| Step: 3
Training loss: 0.08915627002716064
Validation loss: 1.577105083773213

Epoch: 6| Step: 4
Training loss: 0.1350628137588501
Validation loss: 1.6109587761663622

Epoch: 6| Step: 5
Training loss: 0.12526154518127441
Validation loss: 1.585903690707299

Epoch: 6| Step: 6
Training loss: 0.07166595757007599
Validation loss: 1.5902876661669823

Epoch: 6| Step: 7
Training loss: 0.06371842324733734
Validation loss: 1.5995391068920013

Epoch: 6| Step: 8
Training loss: 0.08647577464580536
Validation loss: 1.594126078390306

Epoch: 6| Step: 9
Training loss: 0.1258527636528015
Validation loss: 1.5866929267042427

Epoch: 6| Step: 10
Training loss: 0.1801309883594513
Validation loss: 1.5954148500196395

Epoch: 6| Step: 11
Training loss: 0.09907487779855728
Validation loss: 1.5956769553563928

Epoch: 6| Step: 12
Training loss: 0.1000743955373764
Validation loss: 1.6073255718395274

Epoch: 6| Step: 13
Training loss: 0.12381196022033691
Validation loss: 1.574744821876608

Epoch: 581| Step: 0
Training loss: 0.10693004727363586
Validation loss: 1.549954104167159

Epoch: 6| Step: 1
Training loss: 0.08767849206924438
Validation loss: 1.5712287848995579

Epoch: 6| Step: 2
Training loss: 0.047634903341531754
Validation loss: 1.6024660359146774

Epoch: 6| Step: 3
Training loss: 0.12088102102279663
Validation loss: 1.582662595215664

Epoch: 6| Step: 4
Training loss: 0.06482121348381042
Validation loss: 1.5830458825634373

Epoch: 6| Step: 5
Training loss: 0.05206010863184929
Validation loss: 1.5786047276630197

Epoch: 6| Step: 6
Training loss: 0.09889031946659088
Validation loss: 1.5657164281414402

Epoch: 6| Step: 7
Training loss: 0.08002962172031403
Validation loss: 1.5644344783598376

Epoch: 6| Step: 8
Training loss: 0.1089000552892685
Validation loss: 1.5460151357035483

Epoch: 6| Step: 9
Training loss: 0.1029423177242279
Validation loss: 1.5630030612791739

Epoch: 6| Step: 10
Training loss: 0.06457966566085815
Validation loss: 1.5649497547457296

Epoch: 6| Step: 11
Training loss: 0.056050561368465424
Validation loss: 1.5574851907709593

Epoch: 6| Step: 12
Training loss: 0.24188092350959778
Validation loss: 1.556482526563829

Epoch: 6| Step: 13
Training loss: 0.1506224274635315
Validation loss: 1.5654785889451222

Epoch: 582| Step: 0
Training loss: 0.0714195966720581
Validation loss: 1.5434420941978373

Epoch: 6| Step: 1
Training loss: 0.07862453907728195
Validation loss: 1.5514366024283952

Epoch: 6| Step: 2
Training loss: 0.20722752809524536
Validation loss: 1.5514105141803782

Epoch: 6| Step: 3
Training loss: 0.11427699774503708
Validation loss: 1.5528157834083802

Epoch: 6| Step: 4
Training loss: 0.08442835509777069
Validation loss: 1.5540300453862836

Epoch: 6| Step: 5
Training loss: 0.04936246573925018
Validation loss: 1.5505832036336262

Epoch: 6| Step: 6
Training loss: 0.09471796452999115
Validation loss: 1.555666305685556

Epoch: 6| Step: 7
Training loss: 0.18432584404945374
Validation loss: 1.564149236166349

Epoch: 6| Step: 8
Training loss: 0.06982585042715073
Validation loss: 1.5544299669163202

Epoch: 6| Step: 9
Training loss: 0.04124423861503601
Validation loss: 1.5502260282475462

Epoch: 6| Step: 10
Training loss: 0.10604250431060791
Validation loss: 1.5498638563258673

Epoch: 6| Step: 11
Training loss: 0.0852036103606224
Validation loss: 1.567669427523049

Epoch: 6| Step: 12
Training loss: 0.11843957006931305
Validation loss: 1.5310822827841646

Epoch: 6| Step: 13
Training loss: 0.07275982201099396
Validation loss: 1.567063787932037

Epoch: 583| Step: 0
Training loss: 0.07387714833021164
Validation loss: 1.554282170470043

Epoch: 6| Step: 1
Training loss: 0.04226870834827423
Validation loss: 1.5736311840754684

Epoch: 6| Step: 2
Training loss: 0.21920618414878845
Validation loss: 1.5470911097782913

Epoch: 6| Step: 3
Training loss: 0.10872922092676163
Validation loss: 1.5645600320190511

Epoch: 6| Step: 4
Training loss: 0.10184348374605179
Validation loss: 1.554371298961742

Epoch: 6| Step: 5
Training loss: 0.11731929332017899
Validation loss: 1.5685100837420392

Epoch: 6| Step: 6
Training loss: 0.08294757455587387
Validation loss: 1.5697281347808016

Epoch: 6| Step: 7
Training loss: 0.07419991493225098
Validation loss: 1.574661834265596

Epoch: 6| Step: 8
Training loss: 0.09486816823482513
Validation loss: 1.5736321518498082

Epoch: 6| Step: 9
Training loss: 0.06238177791237831
Validation loss: 1.5295900913976854

Epoch: 6| Step: 10
Training loss: 0.051977649331092834
Validation loss: 1.546544272412536

Epoch: 6| Step: 11
Training loss: 0.05862491577863693
Validation loss: 1.5464309261691185

Epoch: 6| Step: 12
Training loss: 0.07910177111625671
Validation loss: 1.5596155325571697

Epoch: 6| Step: 13
Training loss: 0.17643557488918304
Validation loss: 1.5544711953850203

Epoch: 584| Step: 0
Training loss: 0.06473314762115479
Validation loss: 1.5725495558913036

Epoch: 6| Step: 1
Training loss: 0.10641968250274658
Validation loss: 1.5540516427768174

Epoch: 6| Step: 2
Training loss: 0.16400183737277985
Validation loss: 1.596934131396714

Epoch: 6| Step: 3
Training loss: 0.09702475368976593
Validation loss: 1.5838961921712404

Epoch: 6| Step: 4
Training loss: 0.09394514560699463
Validation loss: 1.587980877968573

Epoch: 6| Step: 5
Training loss: 0.09941236674785614
Validation loss: 1.5984386974765408

Epoch: 6| Step: 6
Training loss: 0.05634976923465729
Validation loss: 1.592885942869289

Epoch: 6| Step: 7
Training loss: 0.04192673787474632
Validation loss: 1.5883285717297626

Epoch: 6| Step: 8
Training loss: 0.11112813651561737
Validation loss: 1.5929295734692646

Epoch: 6| Step: 9
Training loss: 0.17394648492336273
Validation loss: 1.573177917029268

Epoch: 6| Step: 10
Training loss: 0.07126776874065399
Validation loss: 1.5841892842323548

Epoch: 6| Step: 11
Training loss: 0.12457311898469925
Validation loss: 1.6019054292350687

Epoch: 6| Step: 12
Training loss: 0.08308149874210358
Validation loss: 1.5966251306636359

Epoch: 6| Step: 13
Training loss: 0.07154500484466553
Validation loss: 1.5933232294615878

Epoch: 585| Step: 0
Training loss: 0.06446945667266846
Validation loss: 1.5961509161098029

Epoch: 6| Step: 1
Training loss: 0.12729182839393616
Validation loss: 1.580089549864492

Epoch: 6| Step: 2
Training loss: 0.10681123286485672
Validation loss: 1.5815401372089182

Epoch: 6| Step: 3
Training loss: 0.07204300165176392
Validation loss: 1.5760500495151808

Epoch: 6| Step: 4
Training loss: 0.1461913287639618
Validation loss: 1.5383360642258839

Epoch: 6| Step: 5
Training loss: 0.05001039430499077
Validation loss: 1.5700632692665182

Epoch: 6| Step: 6
Training loss: 0.04517006129026413
Validation loss: 1.564513667937248

Epoch: 6| Step: 7
Training loss: 0.06815522909164429
Validation loss: 1.5621813958691013

Epoch: 6| Step: 8
Training loss: 0.07099992781877518
Validation loss: 1.5724011646803988

Epoch: 6| Step: 9
Training loss: 0.07220324873924255
Validation loss: 1.5670847098032634

Epoch: 6| Step: 10
Training loss: 0.0968318060040474
Validation loss: 1.5858714888172765

Epoch: 6| Step: 11
Training loss: 0.08042478561401367
Validation loss: 1.5422491796555058

Epoch: 6| Step: 12
Training loss: 0.119209885597229
Validation loss: 1.5493528830107821

Epoch: 6| Step: 13
Training loss: 0.16957134008407593
Validation loss: 1.5655721438828336

Epoch: 586| Step: 0
Training loss: 0.2087501883506775
Validation loss: 1.5529683187443724

Epoch: 6| Step: 1
Training loss: 0.09690927714109421
Validation loss: 1.5619283081382833

Epoch: 6| Step: 2
Training loss: 0.10882343351840973
Validation loss: 1.5279165621726745

Epoch: 6| Step: 3
Training loss: 0.0638313889503479
Validation loss: 1.5362945679695375

Epoch: 6| Step: 4
Training loss: 0.11537990719079971
Validation loss: 1.5343716913653958

Epoch: 6| Step: 5
Training loss: 0.056417033076286316
Validation loss: 1.5654034806836037

Epoch: 6| Step: 6
Training loss: 0.07802171260118484
Validation loss: 1.5357350726281442

Epoch: 6| Step: 7
Training loss: 0.10756709426641464
Validation loss: 1.5512605315895491

Epoch: 6| Step: 8
Training loss: 0.09046486765146255
Validation loss: 1.537092185789539

Epoch: 6| Step: 9
Training loss: 0.03909709304571152
Validation loss: 1.5665457992143528

Epoch: 6| Step: 10
Training loss: 0.04356513172388077
Validation loss: 1.5535450853327268

Epoch: 6| Step: 11
Training loss: 0.0878981277346611
Validation loss: 1.5683342577308736

Epoch: 6| Step: 12
Training loss: 0.17319083213806152
Validation loss: 1.558237991025371

Epoch: 6| Step: 13
Training loss: 0.11755590885877609
Validation loss: 1.573473777822269

Epoch: 587| Step: 0
Training loss: 0.05337637662887573
Validation loss: 1.5716255287970267

Epoch: 6| Step: 1
Training loss: 0.05297129601240158
Validation loss: 1.5553439086483372

Epoch: 6| Step: 2
Training loss: 0.04012441262602806
Validation loss: 1.549036540010924

Epoch: 6| Step: 3
Training loss: 0.14449447393417358
Validation loss: 1.565232998581343

Epoch: 6| Step: 4
Training loss: 0.08652040362358093
Validation loss: 1.5551503242984894

Epoch: 6| Step: 5
Training loss: 0.11517342180013657
Validation loss: 1.5433690419761084

Epoch: 6| Step: 6
Training loss: 0.06985211372375488
Validation loss: 1.5419068336486816

Epoch: 6| Step: 7
Training loss: 0.10519866645336151
Validation loss: 1.5769988016415668

Epoch: 6| Step: 8
Training loss: 0.2415125072002411
Validation loss: 1.5948603909502748

Epoch: 6| Step: 9
Training loss: 0.08287075161933899
Validation loss: 1.575657456792811

Epoch: 6| Step: 10
Training loss: 0.10241074860095978
Validation loss: 1.5818912188212078

Epoch: 6| Step: 11
Training loss: 0.10455013811588287
Validation loss: 1.6022860593693231

Epoch: 6| Step: 12
Training loss: 0.06915924698114395
Validation loss: 1.633462723865304

Epoch: 6| Step: 13
Training loss: 0.11974391341209412
Validation loss: 1.6201739823946388

Epoch: 588| Step: 0
Training loss: 0.08098138868808746
Validation loss: 1.6310309158858431

Epoch: 6| Step: 1
Training loss: 0.10757935047149658
Validation loss: 1.6266090152084187

Epoch: 6| Step: 2
Training loss: 0.08721759915351868
Validation loss: 1.6039401594028677

Epoch: 6| Step: 3
Training loss: 0.0753682404756546
Validation loss: 1.5945058817504554

Epoch: 6| Step: 4
Training loss: 0.11878948658704758
Validation loss: 1.6190848465888732

Epoch: 6| Step: 5
Training loss: 0.08551367372274399
Validation loss: 1.5719457467397053

Epoch: 6| Step: 6
Training loss: 0.0753844603896141
Validation loss: 1.5716658978052036

Epoch: 6| Step: 7
Training loss: 0.20532242953777313
Validation loss: 1.591359781962569

Epoch: 6| Step: 8
Training loss: 0.06204371154308319
Validation loss: 1.592385507399036

Epoch: 6| Step: 9
Training loss: 0.09786868095397949
Validation loss: 1.583715719561423

Epoch: 6| Step: 10
Training loss: 0.08297176659107208
Validation loss: 1.5928942952104794

Epoch: 6| Step: 11
Training loss: 0.11230454593896866
Validation loss: 1.599681818357078

Epoch: 6| Step: 12
Training loss: 0.03722352534532547
Validation loss: 1.5981803119823497

Epoch: 6| Step: 13
Training loss: 0.21431443095207214
Validation loss: 1.597231408601166

Epoch: 589| Step: 0
Training loss: 0.14899250864982605
Validation loss: 1.6176704411865563

Epoch: 6| Step: 1
Training loss: 0.093537338078022
Validation loss: 1.6475077380416214

Epoch: 6| Step: 2
Training loss: 0.061276018619537354
Validation loss: 1.6194385777237594

Epoch: 6| Step: 3
Training loss: 0.12468604743480682
Validation loss: 1.5929070108680314

Epoch: 6| Step: 4
Training loss: 0.10061173141002655
Validation loss: 1.5772385110137284

Epoch: 6| Step: 5
Training loss: 0.05418914183974266
Validation loss: 1.5822907820824654

Epoch: 6| Step: 6
Training loss: 0.0990525484085083
Validation loss: 1.5699641422558857

Epoch: 6| Step: 7
Training loss: 0.157352015376091
Validation loss: 1.5716132835675312

Epoch: 6| Step: 8
Training loss: 0.1289312243461609
Validation loss: 1.5411415651280393

Epoch: 6| Step: 9
Training loss: 0.08745398372411728
Validation loss: 1.539862803233567

Epoch: 6| Step: 10
Training loss: 0.09337827563285828
Validation loss: 1.5509452371187107

Epoch: 6| Step: 11
Training loss: 0.061547912657260895
Validation loss: 1.5642170342065955

Epoch: 6| Step: 12
Training loss: 0.07330354303121567
Validation loss: 1.5593605400413595

Epoch: 6| Step: 13
Training loss: 0.150845468044281
Validation loss: 1.5768720603758288

Epoch: 590| Step: 0
Training loss: 0.091218501329422
Validation loss: 1.5783711614147309

Epoch: 6| Step: 1
Training loss: 0.12907595932483673
Validation loss: 1.5857178600885535

Epoch: 6| Step: 2
Training loss: 0.08623866736888885
Validation loss: 1.5815576058562084

Epoch: 6| Step: 3
Training loss: 0.06768503785133362
Validation loss: 1.5815385182698567

Epoch: 6| Step: 4
Training loss: 0.07931502163410187
Validation loss: 1.6068388723557996

Epoch: 6| Step: 5
Training loss: 0.0920940488576889
Validation loss: 1.5870854495674052

Epoch: 6| Step: 6
Training loss: 0.22851118445396423
Validation loss: 1.6072712418853596

Epoch: 6| Step: 7
Training loss: 0.0911014974117279
Validation loss: 1.6121743654692045

Epoch: 6| Step: 8
Training loss: 0.028148237615823746
Validation loss: 1.580859286810762

Epoch: 6| Step: 9
Training loss: 0.07252241671085358
Validation loss: 1.6010584882510606

Epoch: 6| Step: 10
Training loss: 0.069951131939888
Validation loss: 1.5814572354798675

Epoch: 6| Step: 11
Training loss: 0.11102645099163055
Validation loss: 1.5933052839771393

Epoch: 6| Step: 12
Training loss: 0.09902355074882507
Validation loss: 1.5677405493233794

Epoch: 6| Step: 13
Training loss: 0.09335294365882874
Validation loss: 1.5598061200111144

Epoch: 591| Step: 0
Training loss: 0.09362157434225082
Validation loss: 1.5778151776200982

Epoch: 6| Step: 1
Training loss: 0.07883155345916748
Validation loss: 1.5542342201355965

Epoch: 6| Step: 2
Training loss: 0.063699871301651
Validation loss: 1.5612414357482747

Epoch: 6| Step: 3
Training loss: 0.092838354408741
Validation loss: 1.5509194571484801

Epoch: 6| Step: 4
Training loss: 0.04955938458442688
Validation loss: 1.5568952009242067

Epoch: 6| Step: 5
Training loss: 0.14736929535865784
Validation loss: 1.5646004497364003

Epoch: 6| Step: 6
Training loss: 0.0718260183930397
Validation loss: 1.575590218267133

Epoch: 6| Step: 7
Training loss: 0.07414183020591736
Validation loss: 1.569364356738265

Epoch: 6| Step: 8
Training loss: 0.06723269820213318
Validation loss: 1.572171744479928

Epoch: 6| Step: 9
Training loss: 0.1151873916387558
Validation loss: 1.5653279994123726

Epoch: 6| Step: 10
Training loss: 0.09826985001564026
Validation loss: 1.5666770512057888

Epoch: 6| Step: 11
Training loss: 0.12096139043569565
Validation loss: 1.5394538570475835

Epoch: 6| Step: 12
Training loss: 0.136878103017807
Validation loss: 1.548674375780167

Epoch: 6| Step: 13
Training loss: 0.1426088660955429
Validation loss: 1.5507644466174546

Epoch: 592| Step: 0
Training loss: 0.08958976715803146
Validation loss: 1.5559782853690527

Epoch: 6| Step: 1
Training loss: 0.102663055062294
Validation loss: 1.5363112752155592

Epoch: 6| Step: 2
Training loss: 0.10804720222949982
Validation loss: 1.551276078788183

Epoch: 6| Step: 3
Training loss: 0.07455205917358398
Validation loss: 1.5673393248229899

Epoch: 6| Step: 4
Training loss: 0.11599211394786835
Validation loss: 1.599655920459378

Epoch: 6| Step: 5
Training loss: 0.07461553812026978
Validation loss: 1.5925489651259555

Epoch: 6| Step: 6
Training loss: 0.1703088879585266
Validation loss: 1.6030314186567902

Epoch: 6| Step: 7
Training loss: 0.07988318055868149
Validation loss: 1.5855776366367136

Epoch: 6| Step: 8
Training loss: 0.07788143306970596
Validation loss: 1.5981514441069735

Epoch: 6| Step: 9
Training loss: 0.11638183891773224
Validation loss: 1.585635777442686

Epoch: 6| Step: 10
Training loss: 0.17089295387268066
Validation loss: 1.5755858664871545

Epoch: 6| Step: 11
Training loss: 0.06369644403457642
Validation loss: 1.5718696514765422

Epoch: 6| Step: 12
Training loss: 0.08075863122940063
Validation loss: 1.5551231189440655

Epoch: 6| Step: 13
Training loss: 0.1138840764760971
Validation loss: 1.5448560304539178

Epoch: 593| Step: 0
Training loss: 0.1014346107840538
Validation loss: 1.5430432058149768

Epoch: 6| Step: 1
Training loss: 0.10399618744850159
Validation loss: 1.5434065595749886

Epoch: 6| Step: 2
Training loss: 0.07149380445480347
Validation loss: 1.5524713249616726

Epoch: 6| Step: 3
Training loss: 0.12312501668930054
Validation loss: 1.5414824883143108

Epoch: 6| Step: 4
Training loss: 0.11432670056819916
Validation loss: 1.5549104200896395

Epoch: 6| Step: 5
Training loss: 0.07430648803710938
Validation loss: 1.583360037496013

Epoch: 6| Step: 6
Training loss: 0.06851279735565186
Validation loss: 1.563304615277116

Epoch: 6| Step: 7
Training loss: 0.10291798412799835
Validation loss: 1.596484414992794

Epoch: 6| Step: 8
Training loss: 0.08991388231515884
Validation loss: 1.5601917120718187

Epoch: 6| Step: 9
Training loss: 0.11975640058517456
Validation loss: 1.561748061128842

Epoch: 6| Step: 10
Training loss: 0.07700031995773315
Validation loss: 1.5429887694697226

Epoch: 6| Step: 11
Training loss: 0.07119850069284439
Validation loss: 1.5554096929488643

Epoch: 6| Step: 12
Training loss: 0.20877975225448608
Validation loss: 1.5778876914772937

Epoch: 6| Step: 13
Training loss: 0.11285734176635742
Validation loss: 1.5466415997474425

Epoch: 594| Step: 0
Training loss: 0.05725359171628952
Validation loss: 1.5452196687780402

Epoch: 6| Step: 1
Training loss: 0.05299684405326843
Validation loss: 1.5389085341525335

Epoch: 6| Step: 2
Training loss: 0.06343559175729752
Validation loss: 1.549336689774708

Epoch: 6| Step: 3
Training loss: 0.21123749017715454
Validation loss: 1.5327032432761243

Epoch: 6| Step: 4
Training loss: 0.05168015882372856
Validation loss: 1.5365615198689122

Epoch: 6| Step: 5
Training loss: 0.14932221174240112
Validation loss: 1.5537381659271896

Epoch: 6| Step: 6
Training loss: 0.07496961951255798
Validation loss: 1.5346328379005514

Epoch: 6| Step: 7
Training loss: 0.05453526973724365
Validation loss: 1.5524120689720236

Epoch: 6| Step: 8
Training loss: 0.12399759143590927
Validation loss: 1.5348044146773636

Epoch: 6| Step: 9
Training loss: 0.08798877149820328
Validation loss: 1.5819289286931355

Epoch: 6| Step: 10
Training loss: 0.07217016816139221
Validation loss: 1.5532873638214604

Epoch: 6| Step: 11
Training loss: 0.12762102484703064
Validation loss: 1.593602208681004

Epoch: 6| Step: 12
Training loss: 0.041999608278274536
Validation loss: 1.5772341579519293

Epoch: 6| Step: 13
Training loss: 0.08064164221286774
Validation loss: 1.5892721991385184

Epoch: 595| Step: 0
Training loss: 0.052581556141376495
Validation loss: 1.5944655197922901

Epoch: 6| Step: 1
Training loss: 0.08503252267837524
Validation loss: 1.5892508119665167

Epoch: 6| Step: 2
Training loss: 0.12365670502185822
Validation loss: 1.5996125334052629

Epoch: 6| Step: 3
Training loss: 0.11364626884460449
Validation loss: 1.5775101018208328

Epoch: 6| Step: 4
Training loss: 0.04298758506774902
Validation loss: 1.579316831404163

Epoch: 6| Step: 5
Training loss: 0.053317468613386154
Validation loss: 1.546364563767628

Epoch: 6| Step: 6
Training loss: 0.05761272832751274
Validation loss: 1.5523537192293393

Epoch: 6| Step: 7
Training loss: 0.09810201078653336
Validation loss: 1.5939091303015267

Epoch: 6| Step: 8
Training loss: 0.06532777845859528
Validation loss: 1.5540811406668795

Epoch: 6| Step: 9
Training loss: 0.1800823211669922
Validation loss: 1.5687768677229523

Epoch: 6| Step: 10
Training loss: 0.0654195100069046
Validation loss: 1.5589505344308832

Epoch: 6| Step: 11
Training loss: 0.1664019525051117
Validation loss: 1.5803629595746276

Epoch: 6| Step: 12
Training loss: 0.04954543709754944
Validation loss: 1.5846226708863371

Epoch: 6| Step: 13
Training loss: 0.06405612081289291
Validation loss: 1.5812113977247668

Epoch: 596| Step: 0
Training loss: 0.07768021523952484
Validation loss: 1.627399194625116

Epoch: 6| Step: 1
Training loss: 0.10711954534053802
Validation loss: 1.624778357885217

Epoch: 6| Step: 2
Training loss: 0.10427099466323853
Validation loss: 1.6234664493991482

Epoch: 6| Step: 3
Training loss: 0.12116867303848267
Validation loss: 1.6044131889138171

Epoch: 6| Step: 4
Training loss: 0.08817697316408157
Validation loss: 1.5898874703273977

Epoch: 6| Step: 5
Training loss: 0.08388932794332504
Validation loss: 1.5901664277558685

Epoch: 6| Step: 6
Training loss: 0.07012729346752167
Validation loss: 1.586151756266112

Epoch: 6| Step: 7
Training loss: 0.06641606241464615
Validation loss: 1.5717241315431492

Epoch: 6| Step: 8
Training loss: 0.08579646795988083
Validation loss: 1.5574056794566493

Epoch: 6| Step: 9
Training loss: 0.0913727879524231
Validation loss: 1.5751059170692199

Epoch: 6| Step: 10
Training loss: 0.10382159054279327
Validation loss: 1.565531615288027

Epoch: 6| Step: 11
Training loss: 0.03303799405694008
Validation loss: 1.5745256677750619

Epoch: 6| Step: 12
Training loss: 0.2048616111278534
Validation loss: 1.5399674228442612

Epoch: 6| Step: 13
Training loss: 0.15689735114574432
Validation loss: 1.5460695194941696

Epoch: 597| Step: 0
Training loss: 0.12155089527368546
Validation loss: 1.5487673128804853

Epoch: 6| Step: 1
Training loss: 0.07957521080970764
Validation loss: 1.5514905632183116

Epoch: 6| Step: 2
Training loss: 0.08872395008802414
Validation loss: 1.5631823424370057

Epoch: 6| Step: 3
Training loss: 0.07046747207641602
Validation loss: 1.5699547868902965

Epoch: 6| Step: 4
Training loss: 0.07523554563522339
Validation loss: 1.5692890267218313

Epoch: 6| Step: 5
Training loss: 0.22129517793655396
Validation loss: 1.5810027558316466

Epoch: 6| Step: 6
Training loss: 0.04196545481681824
Validation loss: 1.5867578368033133

Epoch: 6| Step: 7
Training loss: 0.07162746787071228
Validation loss: 1.6059810935810048

Epoch: 6| Step: 8
Training loss: 0.06720658391714096
Validation loss: 1.5917660664486628

Epoch: 6| Step: 9
Training loss: 0.057539068162441254
Validation loss: 1.5966111104334555

Epoch: 6| Step: 10
Training loss: 0.10015719383955002
Validation loss: 1.5989026305496052

Epoch: 6| Step: 11
Training loss: 0.04927865415811539
Validation loss: 1.6050077663954867

Epoch: 6| Step: 12
Training loss: 0.09226882457733154
Validation loss: 1.6034348933927474

Epoch: 6| Step: 13
Training loss: 0.05537724122405052
Validation loss: 1.6148543768031622

Epoch: 598| Step: 0
Training loss: 0.067604199051857
Validation loss: 1.5976526468030867

Epoch: 6| Step: 1
Training loss: 0.0980926901102066
Validation loss: 1.5768014025944534

Epoch: 6| Step: 2
Training loss: 0.05215032771229744
Validation loss: 1.5615148877584806

Epoch: 6| Step: 3
Training loss: 0.07970139384269714
Validation loss: 1.5389433394196212

Epoch: 6| Step: 4
Training loss: 0.17653459310531616
Validation loss: 1.5462394183681858

Epoch: 6| Step: 5
Training loss: 0.06774663925170898
Validation loss: 1.5420601726860128

Epoch: 6| Step: 6
Training loss: 0.058944039046764374
Validation loss: 1.5522515132863035

Epoch: 6| Step: 7
Training loss: 0.12343546748161316
Validation loss: 1.560314666840338

Epoch: 6| Step: 8
Training loss: 0.1670636385679245
Validation loss: 1.5626411079078593

Epoch: 6| Step: 9
Training loss: 0.09163326770067215
Validation loss: 1.5229617254708403

Epoch: 6| Step: 10
Training loss: 0.09867596626281738
Validation loss: 1.532917825124597

Epoch: 6| Step: 11
Training loss: 0.09544006735086441
Validation loss: 1.5350426473925192

Epoch: 6| Step: 12
Training loss: 0.09451565146446228
Validation loss: 1.5504956578695646

Epoch: 6| Step: 13
Training loss: 0.0664932057261467
Validation loss: 1.5500898297115038

Epoch: 599| Step: 0
Training loss: 0.06502800434827805
Validation loss: 1.5701809121716408

Epoch: 6| Step: 1
Training loss: 0.12350104749202728
Validation loss: 1.5806706079872705

Epoch: 6| Step: 2
Training loss: 0.07137012481689453
Validation loss: 1.557140581069454

Epoch: 6| Step: 3
Training loss: 0.10308454930782318
Validation loss: 1.5788731651921426

Epoch: 6| Step: 4
Training loss: 0.08157917857170105
Validation loss: 1.6123408899512341

Epoch: 6| Step: 5
Training loss: 0.0929836556315422
Validation loss: 1.6298621931383688

Epoch: 6| Step: 6
Training loss: 0.1484997570514679
Validation loss: 1.600919169764365

Epoch: 6| Step: 7
Training loss: 0.18077850341796875
Validation loss: 1.6392591871241087

Epoch: 6| Step: 8
Training loss: 0.13712471723556519
Validation loss: 1.6380687413677093

Epoch: 6| Step: 9
Training loss: 0.1265801042318344
Validation loss: 1.6000502365891651

Epoch: 6| Step: 10
Training loss: 0.08051930367946625
Validation loss: 1.5808467300989295

Epoch: 6| Step: 11
Training loss: 0.05630970746278763
Validation loss: 1.5548155756406887

Epoch: 6| Step: 12
Training loss: 0.11918006092309952
Validation loss: 1.5738941764318815

Epoch: 6| Step: 13
Training loss: 0.12815669178962708
Validation loss: 1.539400105835289

Epoch: 600| Step: 0
Training loss: 0.11929543316364288
Validation loss: 1.5765251433977516

Epoch: 6| Step: 1
Training loss: 0.07958637923002243
Validation loss: 1.5702529709826234

Epoch: 6| Step: 2
Training loss: 0.21171097457408905
Validation loss: 1.5734983810814478

Epoch: 6| Step: 3
Training loss: 0.07437504082918167
Validation loss: 1.556556814460344

Epoch: 6| Step: 4
Training loss: 0.06716926395893097
Validation loss: 1.5097446851832892

Epoch: 6| Step: 5
Training loss: 0.05449637770652771
Validation loss: 1.5416146657800163

Epoch: 6| Step: 6
Training loss: 0.046696946024894714
Validation loss: 1.5546041778338853

Epoch: 6| Step: 7
Training loss: 0.11796820908784866
Validation loss: 1.6054296429439256

Epoch: 6| Step: 8
Training loss: 0.09886963665485382
Validation loss: 1.5907880285734772

Epoch: 6| Step: 9
Training loss: 0.13203759491443634
Validation loss: 1.6408244038140902

Epoch: 6| Step: 10
Training loss: 0.07392475754022598
Validation loss: 1.598143922385349

Epoch: 6| Step: 11
Training loss: 0.07854381203651428
Validation loss: 1.5777836871403519

Epoch: 6| Step: 12
Training loss: 0.19441622495651245
Validation loss: 1.5946940414367183

Epoch: 6| Step: 13
Training loss: 0.13319021463394165
Validation loss: 1.58615691174743

Epoch: 601| Step: 0
Training loss: 0.16391542553901672
Validation loss: 1.5865991589843587

Epoch: 6| Step: 1
Training loss: 0.10345044732093811
Validation loss: 1.5932775466672835

Epoch: 6| Step: 2
Training loss: 0.12434612959623337
Validation loss: 1.5982038308215398

Epoch: 6| Step: 3
Training loss: 0.12997998297214508
Validation loss: 1.5982660965252948

Epoch: 6| Step: 4
Training loss: 0.06302076578140259
Validation loss: 1.5847944854408182

Epoch: 6| Step: 5
Training loss: 0.05413880944252014
Validation loss: 1.5697821724799372

Epoch: 6| Step: 6
Training loss: 0.06474477052688599
Validation loss: 1.5455382985453452

Epoch: 6| Step: 7
Training loss: 0.07896425575017929
Validation loss: 1.5333955992934525

Epoch: 6| Step: 8
Training loss: 0.09409422427415848
Validation loss: 1.5531178943572506

Epoch: 6| Step: 9
Training loss: 0.07647870481014252
Validation loss: 1.5247298645716842

Epoch: 6| Step: 10
Training loss: 0.06185240298509598
Validation loss: 1.5449059150552238

Epoch: 6| Step: 11
Training loss: 0.09230583906173706
Validation loss: 1.5455987235551238

Epoch: 6| Step: 12
Training loss: 0.11616760492324829
Validation loss: 1.5311865473306308

Epoch: 6| Step: 13
Training loss: 0.12498126924037933
Validation loss: 1.5804874589366298

Epoch: 602| Step: 0
Training loss: 0.11949373781681061
Validation loss: 1.6183977819258166

Epoch: 6| Step: 1
Training loss: 0.14326608180999756
Validation loss: 1.6103417783655145

Epoch: 6| Step: 2
Training loss: 0.0962965190410614
Validation loss: 1.6137582653312272

Epoch: 6| Step: 3
Training loss: 0.15295782685279846
Validation loss: 1.601138573820873

Epoch: 6| Step: 4
Training loss: 0.16402065753936768
Validation loss: 1.5759330103474278

Epoch: 6| Step: 5
Training loss: 0.156564399600029
Validation loss: 1.5806959752113587

Epoch: 6| Step: 6
Training loss: 0.053401000797748566
Validation loss: 1.588560611970963

Epoch: 6| Step: 7
Training loss: 0.11647243797779083
Validation loss: 1.6003894203452653

Epoch: 6| Step: 8
Training loss: 0.1403605043888092
Validation loss: 1.6165778598477762

Epoch: 6| Step: 9
Training loss: 0.09468190371990204
Validation loss: 1.6033241671900595

Epoch: 6| Step: 10
Training loss: 0.11061175167560577
Validation loss: 1.5949160437430105

Epoch: 6| Step: 11
Training loss: 0.09751385450363159
Validation loss: 1.5668576494339974

Epoch: 6| Step: 12
Training loss: 0.13486500084400177
Validation loss: 1.5855044293147262

Epoch: 6| Step: 13
Training loss: 0.10059311985969543
Validation loss: 1.5503671169281006

Epoch: 603| Step: 0
Training loss: 0.10408952832221985
Validation loss: 1.5526452038877754

Epoch: 6| Step: 1
Training loss: 0.10518248379230499
Validation loss: 1.5571296670103585

Epoch: 6| Step: 2
Training loss: 0.08901023119688034
Validation loss: 1.5753611057035384

Epoch: 6| Step: 3
Training loss: 0.2449280023574829
Validation loss: 1.5830707780776485

Epoch: 6| Step: 4
Training loss: 0.12868963181972504
Validation loss: 1.6088304622198946

Epoch: 6| Step: 5
Training loss: 0.10193511843681335
Validation loss: 1.5830381019141084

Epoch: 6| Step: 6
Training loss: 0.15080562233924866
Validation loss: 1.6000029886922529

Epoch: 6| Step: 7
Training loss: 0.07564044743776321
Validation loss: 1.5429519568720171

Epoch: 6| Step: 8
Training loss: 0.06428876519203186
Validation loss: 1.5421445651720929

Epoch: 6| Step: 9
Training loss: 0.10981033742427826
Validation loss: 1.5243438065692942

Epoch: 6| Step: 10
Training loss: 0.12358727306127548
Validation loss: 1.55059160917036

Epoch: 6| Step: 11
Training loss: 0.08429263532161713
Validation loss: 1.5364619096120198

Epoch: 6| Step: 12
Training loss: 0.07089321315288544
Validation loss: 1.5316325490192702

Epoch: 6| Step: 13
Training loss: 0.07228104025125504
Validation loss: 1.5396023193995159

Epoch: 604| Step: 0
Training loss: 0.058065466582775116
Validation loss: 1.5472126083989297

Epoch: 6| Step: 1
Training loss: 0.13528606295585632
Validation loss: 1.55550750096639

Epoch: 6| Step: 2
Training loss: 0.07966926693916321
Validation loss: 1.5577669451313634

Epoch: 6| Step: 3
Training loss: 0.07975178956985474
Validation loss: 1.555635897062158

Epoch: 6| Step: 4
Training loss: 0.054783228784799576
Validation loss: 1.5659352540969849

Epoch: 6| Step: 5
Training loss: 0.09885203838348389
Validation loss: 1.570108325250687

Epoch: 6| Step: 6
Training loss: 0.1261903941631317
Validation loss: 1.5717952584707608

Epoch: 6| Step: 7
Training loss: 0.22573231160640717
Validation loss: 1.567864219347636

Epoch: 6| Step: 8
Training loss: 0.08213343471288681
Validation loss: 1.602999976886216

Epoch: 6| Step: 9
Training loss: 0.14945465326309204
Validation loss: 1.5691769866533176

Epoch: 6| Step: 10
Training loss: 0.10288017988204956
Validation loss: 1.6126435136282316

Epoch: 6| Step: 11
Training loss: 0.0376063771545887
Validation loss: 1.6036180642343336

Epoch: 6| Step: 12
Training loss: 0.09113628417253494
Validation loss: 1.5898507000297628

Epoch: 6| Step: 13
Training loss: 0.08730477839708328
Validation loss: 1.6039449873790945

Epoch: 605| Step: 0
Training loss: 0.09806840866804123
Validation loss: 1.5996223226670296

Epoch: 6| Step: 1
Training loss: 0.0582408681511879
Validation loss: 1.5930871296954412

Epoch: 6| Step: 2
Training loss: 0.09226939082145691
Validation loss: 1.5996624654339207

Epoch: 6| Step: 3
Training loss: 0.07012590765953064
Validation loss: 1.5952913043319539

Epoch: 6| Step: 4
Training loss: 0.11647428572177887
Validation loss: 1.5682953403842064

Epoch: 6| Step: 5
Training loss: 0.07891471683979034
Validation loss: 1.5997155738133255

Epoch: 6| Step: 6
Training loss: 0.2399490773677826
Validation loss: 1.59989159722482

Epoch: 6| Step: 7
Training loss: 0.061210997402668
Validation loss: 1.5693562620429582

Epoch: 6| Step: 8
Training loss: 0.09972088038921356
Validation loss: 1.5788527855309107

Epoch: 6| Step: 9
Training loss: 0.1695670634508133
Validation loss: 1.5782549855529622

Epoch: 6| Step: 10
Training loss: 0.08585987240076065
Validation loss: 1.5618785401826263

Epoch: 6| Step: 11
Training loss: 0.07650204747915268
Validation loss: 1.5451577594203334

Epoch: 6| Step: 12
Training loss: 0.14823028445243835
Validation loss: 1.5645950968547533

Epoch: 6| Step: 13
Training loss: 0.11471085995435715
Validation loss: 1.545528265737718

Epoch: 606| Step: 0
Training loss: 0.14177978038787842
Validation loss: 1.5903786895095662

Epoch: 6| Step: 1
Training loss: 0.16220462322235107
Validation loss: 1.5704842357225315

Epoch: 6| Step: 2
Training loss: 0.10720451921224594
Validation loss: 1.5781857454648582

Epoch: 6| Step: 3
Training loss: 0.10201030969619751
Validation loss: 1.6070726174180225

Epoch: 6| Step: 4
Training loss: 0.06537952274084091
Validation loss: 1.5947707974782555

Epoch: 6| Step: 5
Training loss: 0.12031599134206772
Validation loss: 1.5957627751493966

Epoch: 6| Step: 6
Training loss: 0.0649532824754715
Validation loss: 1.6034420267228158

Epoch: 6| Step: 7
Training loss: 0.05484465882182121
Validation loss: 1.604209380765115

Epoch: 6| Step: 8
Training loss: 0.04853465035557747
Validation loss: 1.6099675470782864

Epoch: 6| Step: 9
Training loss: 0.10872196406126022
Validation loss: 1.6287853205075828

Epoch: 6| Step: 10
Training loss: 0.14033494889736176
Validation loss: 1.6296798465072468

Epoch: 6| Step: 11
Training loss: 0.06759268045425415
Validation loss: 1.6226441129561393

Epoch: 6| Step: 12
Training loss: 0.0929219126701355
Validation loss: 1.5859777812034852

Epoch: 6| Step: 13
Training loss: 0.03560290113091469
Validation loss: 1.573384823337678

Epoch: 607| Step: 0
Training loss: 0.10560691356658936
Validation loss: 1.5784978699940506

Epoch: 6| Step: 1
Training loss: 0.0641796663403511
Validation loss: 1.5719073337893332

Epoch: 6| Step: 2
Training loss: 0.12266324460506439
Validation loss: 1.5333218318159862

Epoch: 6| Step: 3
Training loss: 0.10834875702857971
Validation loss: 1.5500526191085897

Epoch: 6| Step: 4
Training loss: 0.07037708163261414
Validation loss: 1.574854722587011

Epoch: 6| Step: 5
Training loss: 0.11263313889503479
Validation loss: 1.5702787868438228

Epoch: 6| Step: 6
Training loss: 0.20105904340744019
Validation loss: 1.5510062761204217

Epoch: 6| Step: 7
Training loss: 0.10718926787376404
Validation loss: 1.574577905798471

Epoch: 6| Step: 8
Training loss: 0.07741279900074005
Validation loss: 1.597832118311236

Epoch: 6| Step: 9
Training loss: 0.040276750922203064
Validation loss: 1.619035828498102

Epoch: 6| Step: 10
Training loss: 0.0761401504278183
Validation loss: 1.615469112191149

Epoch: 6| Step: 11
Training loss: 0.1226038932800293
Validation loss: 1.6416719023899367

Epoch: 6| Step: 12
Training loss: 0.09873802214860916
Validation loss: 1.6551404922239241

Epoch: 6| Step: 13
Training loss: 0.11753903329372406
Validation loss: 1.6541762069989276

Epoch: 608| Step: 0
Training loss: 0.11469073593616486
Validation loss: 1.631310143778401

Epoch: 6| Step: 1
Training loss: 0.06298995763063431
Validation loss: 1.6090664261130876

Epoch: 6| Step: 2
Training loss: 0.09372243285179138
Validation loss: 1.5891756883231543

Epoch: 6| Step: 3
Training loss: 0.06412795186042786
Validation loss: 1.5749364495277405

Epoch: 6| Step: 4
Training loss: 0.08418232202529907
Validation loss: 1.5489711697383592

Epoch: 6| Step: 5
Training loss: 0.14206144213676453
Validation loss: 1.5294324249349616

Epoch: 6| Step: 6
Training loss: 0.0510115921497345
Validation loss: 1.5215150399874615

Epoch: 6| Step: 7
Training loss: 0.17017298936843872
Validation loss: 1.5525895190495316

Epoch: 6| Step: 8
Training loss: 0.09738103300333023
Validation loss: 1.5549923501988894

Epoch: 6| Step: 9
Training loss: 0.049702394753694534
Validation loss: 1.5436264584141393

Epoch: 6| Step: 10
Training loss: 0.06142295151948929
Validation loss: 1.5764144569314935

Epoch: 6| Step: 11
Training loss: 0.10129494220018387
Validation loss: 1.5805113392491494

Epoch: 6| Step: 12
Training loss: 0.12765313684940338
Validation loss: 1.6018659709602274

Epoch: 6| Step: 13
Training loss: 0.0445069745182991
Validation loss: 1.6022547534717027

Epoch: 609| Step: 0
Training loss: 0.07448260486125946
Validation loss: 1.6055628330476823

Epoch: 6| Step: 1
Training loss: 0.11059601604938507
Validation loss: 1.608202644573745

Epoch: 6| Step: 2
Training loss: 0.13623657822608948
Validation loss: 1.6072147277093702

Epoch: 6| Step: 3
Training loss: 0.07062817364931107
Validation loss: 1.5943269383522771

Epoch: 6| Step: 4
Training loss: 0.08452305197715759
Validation loss: 1.5884580740364649

Epoch: 6| Step: 5
Training loss: 0.10186482965946198
Validation loss: 1.5733684160376107

Epoch: 6| Step: 6
Training loss: 0.10380282998085022
Validation loss: 1.5547203351092596

Epoch: 6| Step: 7
Training loss: 0.08179906755685806
Validation loss: 1.5573765103534987

Epoch: 6| Step: 8
Training loss: 0.04351859539747238
Validation loss: 1.573661140216294

Epoch: 6| Step: 9
Training loss: 0.08126404881477356
Validation loss: 1.558324510051358

Epoch: 6| Step: 10
Training loss: 0.1786317378282547
Validation loss: 1.5777122743668095

Epoch: 6| Step: 11
Training loss: 0.10562597215175629
Validation loss: 1.5599219260677215

Epoch: 6| Step: 12
Training loss: 0.06484095752239227
Validation loss: 1.5346884624932402

Epoch: 6| Step: 13
Training loss: 0.07439491152763367
Validation loss: 1.5312205283872542

Epoch: 610| Step: 0
Training loss: 0.22647377848625183
Validation loss: 1.560628144971786

Epoch: 6| Step: 1
Training loss: 0.11089812219142914
Validation loss: 1.555202837913267

Epoch: 6| Step: 2
Training loss: 0.07805100828409195
Validation loss: 1.5677372614542644

Epoch: 6| Step: 3
Training loss: 0.06184123456478119
Validation loss: 1.5598691317342943

Epoch: 6| Step: 4
Training loss: 0.09847468882799149
Validation loss: 1.5934440602538407

Epoch: 6| Step: 5
Training loss: 0.0710681676864624
Validation loss: 1.5527159296056277

Epoch: 6| Step: 6
Training loss: 0.07763365656137466
Validation loss: 1.5719170281963963

Epoch: 6| Step: 7
Training loss: 0.06545326113700867
Validation loss: 1.5671057534474198

Epoch: 6| Step: 8
Training loss: 0.057777177542448044
Validation loss: 1.5938252338799097

Epoch: 6| Step: 9
Training loss: 0.06588525325059891
Validation loss: 1.582177012197433

Epoch: 6| Step: 10
Training loss: 0.04502230882644653
Validation loss: 1.5785148118131904

Epoch: 6| Step: 11
Training loss: 0.04085072875022888
Validation loss: 1.5795129755491852

Epoch: 6| Step: 12
Training loss: 0.07006637752056122
Validation loss: 1.557246503009591

Epoch: 6| Step: 13
Training loss: 0.09408196061849594
Validation loss: 1.5557393950800742

Epoch: 611| Step: 0
Training loss: 0.06233382970094681
Validation loss: 1.583076524478133

Epoch: 6| Step: 1
Training loss: 0.055336400866508484
Validation loss: 1.56858483822115

Epoch: 6| Step: 2
Training loss: 0.10140138119459152
Validation loss: 1.5647793264799221

Epoch: 6| Step: 3
Training loss: 0.04730071872472763
Validation loss: 1.5559344624960294

Epoch: 6| Step: 4
Training loss: 0.07994560152292252
Validation loss: 1.5820263085826751

Epoch: 6| Step: 5
Training loss: 0.163113072514534
Validation loss: 1.588761688560568

Epoch: 6| Step: 6
Training loss: 0.08107172697782516
Validation loss: 1.5611274139855498

Epoch: 6| Step: 7
Training loss: 0.1240985319018364
Validation loss: 1.584179489843307

Epoch: 6| Step: 8
Training loss: 0.05419626086950302
Validation loss: 1.5664805840420466

Epoch: 6| Step: 9
Training loss: 0.07130960375070572
Validation loss: 1.5573475809507473

Epoch: 6| Step: 10
Training loss: 0.05341660976409912
Validation loss: 1.5918073859266055

Epoch: 6| Step: 11
Training loss: 0.22038769721984863
Validation loss: 1.5756266950279154

Epoch: 6| Step: 12
Training loss: 0.15417948365211487
Validation loss: 1.5580617304771178

Epoch: 6| Step: 13
Training loss: 0.08300952613353729
Validation loss: 1.5855086734217982

Epoch: 612| Step: 0
Training loss: 0.10143361985683441
Validation loss: 1.5765180049404022

Epoch: 6| Step: 1
Training loss: 0.0635916069149971
Validation loss: 1.6024463458727765

Epoch: 6| Step: 2
Training loss: 0.0655345618724823
Validation loss: 1.5619897098951443

Epoch: 6| Step: 3
Training loss: 0.08975039422512054
Validation loss: 1.5813351151763753

Epoch: 6| Step: 4
Training loss: 0.10459093749523163
Validation loss: 1.5909668912169754

Epoch: 6| Step: 5
Training loss: 0.10554400831460953
Validation loss: 1.5751243406726467

Epoch: 6| Step: 6
Training loss: 0.05293704569339752
Validation loss: 1.5929234655954505

Epoch: 6| Step: 7
Training loss: 0.10077838599681854
Validation loss: 1.581219816720614

Epoch: 6| Step: 8
Training loss: 0.13040266931056976
Validation loss: 1.5849902706761514

Epoch: 6| Step: 9
Training loss: 0.04080240800976753
Validation loss: 1.5754504601160686

Epoch: 6| Step: 10
Training loss: 0.18609993159770966
Validation loss: 1.5786997067031039

Epoch: 6| Step: 11
Training loss: 0.0817217230796814
Validation loss: 1.6113952500845796

Epoch: 6| Step: 12
Training loss: 0.1498565822839737
Validation loss: 1.6280006452273297

Epoch: 6| Step: 13
Training loss: 0.07247959822416306
Validation loss: 1.6025026036847023

Epoch: 613| Step: 0
Training loss: 0.09805063158273697
Validation loss: 1.5777529990801247

Epoch: 6| Step: 1
Training loss: 0.0698772668838501
Validation loss: 1.5687093580922773

Epoch: 6| Step: 2
Training loss: 0.06906931102275848
Validation loss: 1.5607650305635186

Epoch: 6| Step: 3
Training loss: 0.11148651689291
Validation loss: 1.5500730865745134

Epoch: 6| Step: 4
Training loss: 0.11609940975904465
Validation loss: 1.5400424721420451

Epoch: 6| Step: 5
Training loss: 0.20335380733013153
Validation loss: 1.5803259745720895

Epoch: 6| Step: 6
Training loss: 0.08422388136386871
Validation loss: 1.5787310459280526

Epoch: 6| Step: 7
Training loss: 0.10421624779701233
Validation loss: 1.5793402541068293

Epoch: 6| Step: 8
Training loss: 0.0733344554901123
Validation loss: 1.5698552746926584

Epoch: 6| Step: 9
Training loss: 0.1084202378988266
Validation loss: 1.5580378834919264

Epoch: 6| Step: 10
Training loss: 0.08786238729953766
Validation loss: 1.5670479625783942

Epoch: 6| Step: 11
Training loss: 0.1825968623161316
Validation loss: 1.5894939271352624

Epoch: 6| Step: 12
Training loss: 0.07160980999469757
Validation loss: 1.589986705010937

Epoch: 6| Step: 13
Training loss: 0.042209163308143616
Validation loss: 1.6066293408793788

Epoch: 614| Step: 0
Training loss: 0.06169864907860756
Validation loss: 1.5591187182293142

Epoch: 6| Step: 1
Training loss: 0.04742218554019928
Validation loss: 1.5733033700655865

Epoch: 6| Step: 2
Training loss: 0.08140383660793304
Validation loss: 1.5840864396223457

Epoch: 6| Step: 3
Training loss: 0.05806059390306473
Validation loss: 1.5778900654085222

Epoch: 6| Step: 4
Training loss: 0.09535469114780426
Validation loss: 1.5470625354397682

Epoch: 6| Step: 5
Training loss: 0.10190875828266144
Validation loss: 1.5598380258006435

Epoch: 6| Step: 6
Training loss: 0.0646640807390213
Validation loss: 1.5622572937319357

Epoch: 6| Step: 7
Training loss: 0.18170227110385895
Validation loss: 1.5287489967961465

Epoch: 6| Step: 8
Training loss: 0.07840066403150558
Validation loss: 1.5593775318514915

Epoch: 6| Step: 9
Training loss: 0.07843881845474243
Validation loss: 1.5661628746217298

Epoch: 6| Step: 10
Training loss: 0.0739729255437851
Validation loss: 1.5283478511277067

Epoch: 6| Step: 11
Training loss: 0.11149957031011581
Validation loss: 1.5306010848732405

Epoch: 6| Step: 12
Training loss: 0.07735252380371094
Validation loss: 1.5194522565410984

Epoch: 6| Step: 13
Training loss: 0.0887199267745018
Validation loss: 1.534491426201277

Epoch: 615| Step: 0
Training loss: 0.06137077510356903
Validation loss: 1.5244570483443558

Epoch: 6| Step: 1
Training loss: 0.1215750128030777
Validation loss: 1.532987356185913

Epoch: 6| Step: 2
Training loss: 0.15177348256111145
Validation loss: 1.568344344374954

Epoch: 6| Step: 3
Training loss: 0.07268902659416199
Validation loss: 1.5690730681983374

Epoch: 6| Step: 4
Training loss: 0.09912609308958054
Validation loss: 1.5684834718704224

Epoch: 6| Step: 5
Training loss: 0.10184517502784729
Validation loss: 1.5864168636260494

Epoch: 6| Step: 6
Training loss: 0.0566549226641655
Validation loss: 1.599983085227269

Epoch: 6| Step: 7
Training loss: 0.09349307417869568
Validation loss: 1.560785787079924

Epoch: 6| Step: 8
Training loss: 0.07990577071905136
Validation loss: 1.5594559600276332

Epoch: 6| Step: 9
Training loss: 0.12192373722791672
Validation loss: 1.555324540984246

Epoch: 6| Step: 10
Training loss: 0.06952524930238724
Validation loss: 1.5682393523954576

Epoch: 6| Step: 11
Training loss: 0.13499468564987183
Validation loss: 1.5748201365111976

Epoch: 6| Step: 12
Training loss: 0.061798740178346634
Validation loss: 1.583218893697185

Epoch: 6| Step: 13
Training loss: 0.05923912301659584
Validation loss: 1.5874304784241544

Epoch: 616| Step: 0
Training loss: 0.05105476826429367
Validation loss: 1.5692741691425283

Epoch: 6| Step: 1
Training loss: 0.07291808724403381
Validation loss: 1.5874263483990905

Epoch: 6| Step: 2
Training loss: 0.0641949325799942
Validation loss: 1.5772147999014905

Epoch: 6| Step: 3
Training loss: 0.05950538069009781
Validation loss: 1.5917660702941239

Epoch: 6| Step: 4
Training loss: 0.08777162432670593
Validation loss: 1.592092655038321

Epoch: 6| Step: 5
Training loss: 0.07086034119129181
Validation loss: 1.582291369797081

Epoch: 6| Step: 6
Training loss: 0.05559837818145752
Validation loss: 1.5963473960917482

Epoch: 6| Step: 7
Training loss: 0.08924856781959534
Validation loss: 1.582106658207473

Epoch: 6| Step: 8
Training loss: 0.06650765985250473
Validation loss: 1.5821273390964796

Epoch: 6| Step: 9
Training loss: 0.05832934379577637
Validation loss: 1.5637966496970064

Epoch: 6| Step: 10
Training loss: 0.06610852479934692
Validation loss: 1.5465934404762842

Epoch: 6| Step: 11
Training loss: 0.11735472083091736
Validation loss: 1.5644439599847282

Epoch: 6| Step: 12
Training loss: 0.2101098746061325
Validation loss: 1.526333357698174

Epoch: 6| Step: 13
Training loss: 0.08009640127420425
Validation loss: 1.5369452609810779

Epoch: 617| Step: 0
Training loss: 0.051733702421188354
Validation loss: 1.5342386486709758

Epoch: 6| Step: 1
Training loss: 0.10165660083293915
Validation loss: 1.5475753033032982

Epoch: 6| Step: 2
Training loss: 0.13187430799007416
Validation loss: 1.5313082971880514

Epoch: 6| Step: 3
Training loss: 0.0605524480342865
Validation loss: 1.530148902247029

Epoch: 6| Step: 4
Training loss: 0.05628255754709244
Validation loss: 1.5319708290920462

Epoch: 6| Step: 5
Training loss: 0.03811153769493103
Validation loss: 1.5648617667536582

Epoch: 6| Step: 6
Training loss: 0.06042150408029556
Validation loss: 1.5774608286478187

Epoch: 6| Step: 7
Training loss: 0.09455785900354385
Validation loss: 1.5808997102963027

Epoch: 6| Step: 8
Training loss: 0.1970893144607544
Validation loss: 1.587581475575765

Epoch: 6| Step: 9
Training loss: 0.09325862675905228
Validation loss: 1.5867209479372988

Epoch: 6| Step: 10
Training loss: 0.08884963393211365
Validation loss: 1.5763905150915987

Epoch: 6| Step: 11
Training loss: 0.23148465156555176
Validation loss: 1.561849033960732

Epoch: 6| Step: 12
Training loss: 0.07071585208177567
Validation loss: 1.5539987439750342

Epoch: 6| Step: 13
Training loss: 0.10366766154766083
Validation loss: 1.6040822972533524

Epoch: 618| Step: 0
Training loss: 0.07528112828731537
Validation loss: 1.5928760638801

Epoch: 6| Step: 1
Training loss: 0.19409823417663574
Validation loss: 1.6165151057704803

Epoch: 6| Step: 2
Training loss: 0.09888219088315964
Validation loss: 1.6222462436204315

Epoch: 6| Step: 3
Training loss: 0.044989366084337234
Validation loss: 1.598240585737331

Epoch: 6| Step: 4
Training loss: 0.12365194410085678
Validation loss: 1.5948081042176934

Epoch: 6| Step: 5
Training loss: 0.0985138788819313
Validation loss: 1.5865493102740216

Epoch: 6| Step: 6
Training loss: 0.06583769619464874
Validation loss: 1.5717379354661511

Epoch: 6| Step: 7
Training loss: 0.07623264193534851
Validation loss: 1.5635817576480169

Epoch: 6| Step: 8
Training loss: 0.11499612033367157
Validation loss: 1.5577196690344042

Epoch: 6| Step: 9
Training loss: 0.09140001237392426
Validation loss: 1.571721798630171

Epoch: 6| Step: 10
Training loss: 0.06758882105350494
Validation loss: 1.612217200699673

Epoch: 6| Step: 11
Training loss: 0.0697694718837738
Validation loss: 1.5912312307665426

Epoch: 6| Step: 12
Training loss: 0.13991212844848633
Validation loss: 1.5955808252416632

Epoch: 6| Step: 13
Training loss: 0.05911906436085701
Validation loss: 1.5984011029684415

Epoch: 619| Step: 0
Training loss: 0.07392823696136475
Validation loss: 1.620891862018134

Epoch: 6| Step: 1
Training loss: 0.08878344297409058
Validation loss: 1.587631885723401

Epoch: 6| Step: 2
Training loss: 0.11537706106901169
Validation loss: 1.6189142645046275

Epoch: 6| Step: 3
Training loss: 0.11005246639251709
Validation loss: 1.5769214219944452

Epoch: 6| Step: 4
Training loss: 0.17898735404014587
Validation loss: 1.5827873983690817

Epoch: 6| Step: 5
Training loss: 0.06202985346317291
Validation loss: 1.59231424203483

Epoch: 6| Step: 6
Training loss: 0.08070305734872818
Validation loss: 1.6108818823291409

Epoch: 6| Step: 7
Training loss: 0.08751747012138367
Validation loss: 1.5839742409285678

Epoch: 6| Step: 8
Training loss: 0.0522187165915966
Validation loss: 1.606672768310834

Epoch: 6| Step: 9
Training loss: 0.10332989692687988
Validation loss: 1.5839731334358134

Epoch: 6| Step: 10
Training loss: 0.06060055270791054
Validation loss: 1.5867371918052755

Epoch: 6| Step: 11
Training loss: 0.07544581592082977
Validation loss: 1.5861254533131917

Epoch: 6| Step: 12
Training loss: 0.12601786851882935
Validation loss: 1.5916923130712202

Epoch: 6| Step: 13
Training loss: 0.05712077394127846
Validation loss: 1.6130128047799552

Epoch: 620| Step: 0
Training loss: 0.14685042202472687
Validation loss: 1.5970175240629463

Epoch: 6| Step: 1
Training loss: 0.2200552225112915
Validation loss: 1.586135748893984

Epoch: 6| Step: 2
Training loss: 0.06893149018287659
Validation loss: 1.5809372791679956

Epoch: 6| Step: 3
Training loss: 0.10191386193037033
Validation loss: 1.5788827788445257

Epoch: 6| Step: 4
Training loss: 0.041542958468198776
Validation loss: 1.5713135311680455

Epoch: 6| Step: 5
Training loss: 0.10260985046625137
Validation loss: 1.5466901461283367

Epoch: 6| Step: 6
Training loss: 0.053008876740932465
Validation loss: 1.5559151320047275

Epoch: 6| Step: 7
Training loss: 0.07916146516799927
Validation loss: 1.5678251892007806

Epoch: 6| Step: 8
Training loss: 0.039848655462265015
Validation loss: 1.533749044582408

Epoch: 6| Step: 9
Training loss: 0.049351003021001816
Validation loss: 1.559025405555643

Epoch: 6| Step: 10
Training loss: 0.08354079723358154
Validation loss: 1.5542819628151514

Epoch: 6| Step: 11
Training loss: 0.053722962737083435
Validation loss: 1.5576987253722323

Epoch: 6| Step: 12
Training loss: 0.05014125257730484
Validation loss: 1.5672850288370603

Epoch: 6| Step: 13
Training loss: 0.08322003483772278
Validation loss: 1.5802094756916005

Epoch: 621| Step: 0
Training loss: 0.056146297603845596
Validation loss: 1.5335432855031823

Epoch: 6| Step: 1
Training loss: 0.07267700135707855
Validation loss: 1.5661564962838286

Epoch: 6| Step: 2
Training loss: 0.12840014696121216
Validation loss: 1.5617095616555983

Epoch: 6| Step: 3
Training loss: 0.12199553847312927
Validation loss: 1.5725504595746276

Epoch: 6| Step: 4
Training loss: 0.046484172344207764
Validation loss: 1.5498658559655631

Epoch: 6| Step: 5
Training loss: 0.15836921334266663
Validation loss: 1.5612684539569321

Epoch: 6| Step: 6
Training loss: 0.060610607266426086
Validation loss: 1.5444636165454824

Epoch: 6| Step: 7
Training loss: 0.04237038269639015
Validation loss: 1.5562241923424505

Epoch: 6| Step: 8
Training loss: 0.05431408807635307
Validation loss: 1.5635076774063932

Epoch: 6| Step: 9
Training loss: 0.06646546721458435
Validation loss: 1.5508445180872434

Epoch: 6| Step: 10
Training loss: 0.04480728134512901
Validation loss: 1.549573225359763

Epoch: 6| Step: 11
Training loss: 0.09361372888088226
Validation loss: 1.561678550576651

Epoch: 6| Step: 12
Training loss: 0.05670250952243805
Validation loss: 1.5673864964515931

Epoch: 6| Step: 13
Training loss: 0.06557141244411469
Validation loss: 1.5819706839899863

Epoch: 622| Step: 0
Training loss: 0.08146069198846817
Validation loss: 1.5619099575986144

Epoch: 6| Step: 1
Training loss: 0.09219373762607574
Validation loss: 1.5664844666757891

Epoch: 6| Step: 2
Training loss: 0.09758838266134262
Validation loss: 1.5711787810889624

Epoch: 6| Step: 3
Training loss: 0.037383370101451874
Validation loss: 1.5701532043436521

Epoch: 6| Step: 4
Training loss: 0.07440343499183655
Validation loss: 1.5873059265075191

Epoch: 6| Step: 5
Training loss: 0.07045519351959229
Validation loss: 1.5827244404823548

Epoch: 6| Step: 6
Training loss: 0.12157320976257324
Validation loss: 1.5863823659958378

Epoch: 6| Step: 7
Training loss: 0.07587496936321259
Validation loss: 1.6149033705393474

Epoch: 6| Step: 8
Training loss: 0.12143287807703018
Validation loss: 1.6125229366364018

Epoch: 6| Step: 9
Training loss: 0.12474633753299713
Validation loss: 1.5994226317251883

Epoch: 6| Step: 10
Training loss: 0.22827167809009552
Validation loss: 1.6013821555722145

Epoch: 6| Step: 11
Training loss: 0.06752707064151764
Validation loss: 1.5691117343082224

Epoch: 6| Step: 12
Training loss: 0.08459022641181946
Validation loss: 1.5665574022518691

Epoch: 6| Step: 13
Training loss: 0.11961103975772858
Validation loss: 1.5728249857502599

Epoch: 623| Step: 0
Training loss: 0.05792305991053581
Validation loss: 1.5806395622991747

Epoch: 6| Step: 1
Training loss: 0.10579200834035873
Validation loss: 1.5513757685179352

Epoch: 6| Step: 2
Training loss: 0.14319467544555664
Validation loss: 1.549214852753506

Epoch: 6| Step: 3
Training loss: 0.06651865690946579
Validation loss: 1.5086890600060905

Epoch: 6| Step: 4
Training loss: 0.1237560361623764
Validation loss: 1.5314493281866914

Epoch: 6| Step: 5
Training loss: 0.11984920501708984
Validation loss: 1.554081287435306

Epoch: 6| Step: 6
Training loss: 0.07098512351512909
Validation loss: 1.5444979052389822

Epoch: 6| Step: 7
Training loss: 0.13572059571743011
Validation loss: 1.532036296782955

Epoch: 6| Step: 8
Training loss: 0.06009235978126526
Validation loss: 1.5589634410796627

Epoch: 6| Step: 9
Training loss: 0.1215614378452301
Validation loss: 1.5612995239996141

Epoch: 6| Step: 10
Training loss: 0.2139071226119995
Validation loss: 1.5459887660959715

Epoch: 6| Step: 11
Training loss: 0.1077195331454277
Validation loss: 1.5573301238398398

Epoch: 6| Step: 12
Training loss: 0.05794993042945862
Validation loss: 1.5645402387906147

Epoch: 6| Step: 13
Training loss: 0.08776288479566574
Validation loss: 1.547130826980837

Epoch: 624| Step: 0
Training loss: 0.03693167120218277
Validation loss: 1.5686738055239442

Epoch: 6| Step: 1
Training loss: 0.07581533491611481
Validation loss: 1.5755955634578582

Epoch: 6| Step: 2
Training loss: 0.07092863321304321
Validation loss: 1.5934134324391682

Epoch: 6| Step: 3
Training loss: 0.09508480131626129
Validation loss: 1.5596648198302074

Epoch: 6| Step: 4
Training loss: 0.10339775681495667
Validation loss: 1.5721330988791682

Epoch: 6| Step: 5
Training loss: 0.07037985324859619
Validation loss: 1.5669512325717556

Epoch: 6| Step: 6
Training loss: 0.08193992078304291
Validation loss: 1.5631694319427654

Epoch: 6| Step: 7
Training loss: 0.07989456504583359
Validation loss: 1.5522009672657135

Epoch: 6| Step: 8
Training loss: 0.10590954124927521
Validation loss: 1.552670656993825

Epoch: 6| Step: 9
Training loss: 0.17402520775794983
Validation loss: 1.5353799917364632

Epoch: 6| Step: 10
Training loss: 0.11711739748716354
Validation loss: 1.5506147018042944

Epoch: 6| Step: 11
Training loss: 0.08567649126052856
Validation loss: 1.5714736318075528

Epoch: 6| Step: 12
Training loss: 0.1432240605354309
Validation loss: 1.5849693795686126

Epoch: 6| Step: 13
Training loss: 0.10751465708017349
Validation loss: 1.5671227542302941

Epoch: 625| Step: 0
Training loss: 0.11831405758857727
Validation loss: 1.558705988750663

Epoch: 6| Step: 1
Training loss: 0.12138469517230988
Validation loss: 1.5858156014514226

Epoch: 6| Step: 2
Training loss: 0.17240923643112183
Validation loss: 1.620677250687794

Epoch: 6| Step: 3
Training loss: 0.11560669541358948
Validation loss: 1.6220209342177196

Epoch: 6| Step: 4
Training loss: 0.14979015290737152
Validation loss: 1.6101093856237267

Epoch: 6| Step: 5
Training loss: 0.08207321166992188
Validation loss: 1.5771061630659207

Epoch: 6| Step: 6
Training loss: 0.09956109523773193
Validation loss: 1.6076016105631346

Epoch: 6| Step: 7
Training loss: 0.15644226968288422
Validation loss: 1.599907910952004

Epoch: 6| Step: 8
Training loss: 0.19084136188030243
Validation loss: 1.6311108245644519

Epoch: 6| Step: 9
Training loss: 0.08823255449533463
Validation loss: 1.6248340465689217

Epoch: 6| Step: 10
Training loss: 0.19695809483528137
Validation loss: 1.5824062221793718

Epoch: 6| Step: 11
Training loss: 0.22158317267894745
Validation loss: 1.594954111242807

Epoch: 6| Step: 12
Training loss: 0.05323629826307297
Validation loss: 1.590954754942207

Epoch: 6| Step: 13
Training loss: 0.21258309483528137
Validation loss: 1.5852768728809972

Epoch: 626| Step: 0
Training loss: 0.1501435935497284
Validation loss: 1.5904350024397655

Epoch: 6| Step: 1
Training loss: 0.18766751885414124
Validation loss: 1.5683002023286716

Epoch: 6| Step: 2
Training loss: 0.11394426226615906
Validation loss: 1.5366782962635

Epoch: 6| Step: 3
Training loss: 0.11530541628599167
Validation loss: 1.5393738849188692

Epoch: 6| Step: 4
Training loss: 0.13973423838615417
Validation loss: 1.5487800259743967

Epoch: 6| Step: 5
Training loss: 0.08339548110961914
Validation loss: 1.5523463474806918

Epoch: 6| Step: 6
Training loss: 0.12068791687488556
Validation loss: 1.5469282647614837

Epoch: 6| Step: 7
Training loss: 0.12059548497200012
Validation loss: 1.517531281517398

Epoch: 6| Step: 8
Training loss: 0.20715315639972687
Validation loss: 1.551676663019324

Epoch: 6| Step: 9
Training loss: 0.11498944461345673
Validation loss: 1.572335954635374

Epoch: 6| Step: 10
Training loss: 0.09863119572401047
Validation loss: 1.5903466478470834

Epoch: 6| Step: 11
Training loss: 0.08614169806241989
Validation loss: 1.6356809933980305

Epoch: 6| Step: 12
Training loss: 0.1021929383277893
Validation loss: 1.6517724426843787

Epoch: 6| Step: 13
Training loss: 0.2134317308664322
Validation loss: 1.6634262992489723

Epoch: 627| Step: 0
Training loss: 0.12954431772232056
Validation loss: 1.6746356961547688

Epoch: 6| Step: 1
Training loss: 0.19255580008029938
Validation loss: 1.6291118591062483

Epoch: 6| Step: 2
Training loss: 0.08629465103149414
Validation loss: 1.609586723389164

Epoch: 6| Step: 3
Training loss: 0.07382411509752274
Validation loss: 1.5924219277597242

Epoch: 6| Step: 4
Training loss: 0.10895833373069763
Validation loss: 1.5798670912301669

Epoch: 6| Step: 5
Training loss: 0.06270662695169449
Validation loss: 1.5616454014214136

Epoch: 6| Step: 6
Training loss: 0.05836623162031174
Validation loss: 1.5707424468891595

Epoch: 6| Step: 7
Training loss: 0.09435073286294937
Validation loss: 1.5428570085956204

Epoch: 6| Step: 8
Training loss: 0.15279677510261536
Validation loss: 1.5482083020671722

Epoch: 6| Step: 9
Training loss: 0.10326628386974335
Validation loss: 1.549562769551431

Epoch: 6| Step: 10
Training loss: 0.08748422563076019
Validation loss: 1.546252195553113

Epoch: 6| Step: 11
Training loss: 0.11902756989002228
Validation loss: 1.539946335618214

Epoch: 6| Step: 12
Training loss: 0.11373503506183624
Validation loss: 1.5471238961783789

Epoch: 6| Step: 13
Training loss: 0.16646867990493774
Validation loss: 1.5680063007980265

Epoch: 628| Step: 0
Training loss: 0.12743279337882996
Validation loss: 1.5312345925197806

Epoch: 6| Step: 1
Training loss: 0.16356977820396423
Validation loss: 1.5823067567681754

Epoch: 6| Step: 2
Training loss: 0.062124114483594894
Validation loss: 1.57705351614183

Epoch: 6| Step: 3
Training loss: 0.10778417438268661
Validation loss: 1.5993751787370252

Epoch: 6| Step: 4
Training loss: 0.12010252475738525
Validation loss: 1.6031098340147285

Epoch: 6| Step: 5
Training loss: 0.10848884284496307
Validation loss: 1.602213398102791

Epoch: 6| Step: 6
Training loss: 0.05016350746154785
Validation loss: 1.58999740692877

Epoch: 6| Step: 7
Training loss: 0.06982176750898361
Validation loss: 1.594892341603515

Epoch: 6| Step: 8
Training loss: 0.13833534717559814
Validation loss: 1.5546525793690835

Epoch: 6| Step: 9
Training loss: 0.09350386261940002
Validation loss: 1.5642507550536946

Epoch: 6| Step: 10
Training loss: 0.10033950954675674
Validation loss: 1.5616104987359816

Epoch: 6| Step: 11
Training loss: 0.06185963749885559
Validation loss: 1.5539949645278275

Epoch: 6| Step: 12
Training loss: 0.06345637142658234
Validation loss: 1.5681115350415629

Epoch: 6| Step: 13
Training loss: 0.07356274127960205
Validation loss: 1.5869475680012857

Epoch: 629| Step: 0
Training loss: 0.08496902883052826
Validation loss: 1.5786971584443124

Epoch: 6| Step: 1
Training loss: 0.0865907371044159
Validation loss: 1.5665502907127462

Epoch: 6| Step: 2
Training loss: 0.13459591567516327
Validation loss: 1.547248803159242

Epoch: 6| Step: 3
Training loss: 0.07122063636779785
Validation loss: 1.5721523377203173

Epoch: 6| Step: 4
Training loss: 0.052024953067302704
Validation loss: 1.5847874764473207

Epoch: 6| Step: 5
Training loss: 0.044919703155756
Validation loss: 1.5422915053623978

Epoch: 6| Step: 6
Training loss: 0.08499912172555923
Validation loss: 1.5707500442381828

Epoch: 6| Step: 7
Training loss: 0.12658606469631195
Validation loss: 1.5460883622528405

Epoch: 6| Step: 8
Training loss: 0.044524580240249634
Validation loss: 1.561710206411218

Epoch: 6| Step: 9
Training loss: 0.12339820712804794
Validation loss: 1.5656221579479914

Epoch: 6| Step: 10
Training loss: 0.08059302717447281
Validation loss: 1.561924183881411

Epoch: 6| Step: 11
Training loss: 0.08290345966815948
Validation loss: 1.5689349674409436

Epoch: 6| Step: 12
Training loss: 0.07696115970611572
Validation loss: 1.5692180619444898

Epoch: 6| Step: 13
Training loss: 0.05896291509270668
Validation loss: 1.5733861500217068

Epoch: 630| Step: 0
Training loss: 0.07380254566669464
Validation loss: 1.584973871067006

Epoch: 6| Step: 1
Training loss: 0.07057271897792816
Validation loss: 1.5803781722181587

Epoch: 6| Step: 2
Training loss: 0.05082838237285614
Validation loss: 1.5897199300027662

Epoch: 6| Step: 3
Training loss: 0.09107701480388641
Validation loss: 1.5899415163583652

Epoch: 6| Step: 4
Training loss: 0.05942032113671303
Validation loss: 1.5941441328294816

Epoch: 6| Step: 5
Training loss: 0.11622871458530426
Validation loss: 1.5977769679920648

Epoch: 6| Step: 6
Training loss: 0.08494409173727036
Validation loss: 1.5922607503911501

Epoch: 6| Step: 7
Training loss: 0.05984656512737274
Validation loss: 1.5465023056153329

Epoch: 6| Step: 8
Training loss: 0.0866856798529625
Validation loss: 1.5444037568184636

Epoch: 6| Step: 9
Training loss: 0.15676000714302063
Validation loss: 1.5796235658789193

Epoch: 6| Step: 10
Training loss: 0.08497793972492218
Validation loss: 1.5609759015421714

Epoch: 6| Step: 11
Training loss: 0.059877827763557434
Validation loss: 1.5590752696478238

Epoch: 6| Step: 12
Training loss: 0.049852363765239716
Validation loss: 1.5579624829753753

Epoch: 6| Step: 13
Training loss: 0.12052864581346512
Validation loss: 1.5588268785066501

Epoch: 631| Step: 0
Training loss: 0.060105159878730774
Validation loss: 1.5805941627871605

Epoch: 6| Step: 1
Training loss: 0.08406379818916321
Validation loss: 1.5705581365093109

Epoch: 6| Step: 2
Training loss: 0.09688679873943329
Validation loss: 1.5726994468319802

Epoch: 6| Step: 3
Training loss: 0.13205556571483612
Validation loss: 1.5957210390798506

Epoch: 6| Step: 4
Training loss: 0.12413178384304047
Validation loss: 1.5840999695562548

Epoch: 6| Step: 5
Training loss: 0.05993049591779709
Validation loss: 1.60161728243674

Epoch: 6| Step: 6
Training loss: 0.045105576515197754
Validation loss: 1.5735670751140964

Epoch: 6| Step: 7
Training loss: 0.07696059346199036
Validation loss: 1.5570543414802962

Epoch: 6| Step: 8
Training loss: 0.08644957095384598
Validation loss: 1.5711238871338546

Epoch: 6| Step: 9
Training loss: 0.049264438450336456
Validation loss: 1.5766140120003813

Epoch: 6| Step: 10
Training loss: 0.13542070984840393
Validation loss: 1.5633600078603274

Epoch: 6| Step: 11
Training loss: 0.06328234076499939
Validation loss: 1.5717523905538744

Epoch: 6| Step: 12
Training loss: 0.05572934076189995
Validation loss: 1.5731526087689143

Epoch: 6| Step: 13
Training loss: 0.03356631100177765
Validation loss: 1.558017235930248

Epoch: 632| Step: 0
Training loss: 0.040851086378097534
Validation loss: 1.5760411908549647

Epoch: 6| Step: 1
Training loss: 0.08572535216808319
Validation loss: 1.5823982056751047

Epoch: 6| Step: 2
Training loss: 0.05671890079975128
Validation loss: 1.5856394947216075

Epoch: 6| Step: 3
Training loss: 0.0427374541759491
Validation loss: 1.583787105416739

Epoch: 6| Step: 4
Training loss: 0.11180365085601807
Validation loss: 1.559182777199694

Epoch: 6| Step: 5
Training loss: 0.08958708494901657
Validation loss: 1.5882222408889441

Epoch: 6| Step: 6
Training loss: 0.0825287401676178
Validation loss: 1.5645939182209712

Epoch: 6| Step: 7
Training loss: 0.10101187974214554
Validation loss: 1.5759112014565417

Epoch: 6| Step: 8
Training loss: 0.07828875631093979
Validation loss: 1.5403001154622724

Epoch: 6| Step: 9
Training loss: 0.06925874948501587
Validation loss: 1.5299474206022037

Epoch: 6| Step: 10
Training loss: 0.04851032420992851
Validation loss: 1.5335787726986794

Epoch: 6| Step: 11
Training loss: 0.1639155000448227
Validation loss: 1.5433556097809986

Epoch: 6| Step: 12
Training loss: 0.055553972721099854
Validation loss: 1.5542113101610573

Epoch: 6| Step: 13
Training loss: 0.11120091378688812
Validation loss: 1.5368984001939014

Epoch: 633| Step: 0
Training loss: 0.04087499529123306
Validation loss: 1.5420097868929628

Epoch: 6| Step: 1
Training loss: 0.12541311979293823
Validation loss: 1.5288477072151758

Epoch: 6| Step: 2
Training loss: 0.07932392507791519
Validation loss: 1.523200350423013

Epoch: 6| Step: 3
Training loss: 0.06932514905929565
Validation loss: 1.52783711366756

Epoch: 6| Step: 4
Training loss: 0.17296727001667023
Validation loss: 1.505836481689125

Epoch: 6| Step: 5
Training loss: 0.08953214436769485
Validation loss: 1.5052585447988203

Epoch: 6| Step: 6
Training loss: 0.03714370355010033
Validation loss: 1.5258613645389516

Epoch: 6| Step: 7
Training loss: 0.08447153121232986
Validation loss: 1.521837378060946

Epoch: 6| Step: 8
Training loss: 0.07689933478832245
Validation loss: 1.5580759529144532

Epoch: 6| Step: 9
Training loss: 0.06578667461872101
Validation loss: 1.546808112052179

Epoch: 6| Step: 10
Training loss: 0.05656515806913376
Validation loss: 1.564199859737068

Epoch: 6| Step: 11
Training loss: 0.06557534635066986
Validation loss: 1.5566872960777693

Epoch: 6| Step: 12
Training loss: 0.0640287846326828
Validation loss: 1.5590149728200768

Epoch: 6| Step: 13
Training loss: 0.05034082382917404
Validation loss: 1.524980616825883

Epoch: 634| Step: 0
Training loss: 0.08327087759971619
Validation loss: 1.5373766486362745

Epoch: 6| Step: 1
Training loss: 0.05656751990318298
Validation loss: 1.5356501507502731

Epoch: 6| Step: 2
Training loss: 0.06279901415109634
Validation loss: 1.501296950924781

Epoch: 6| Step: 3
Training loss: 0.09195796400308609
Validation loss: 1.508525897097844

Epoch: 6| Step: 4
Training loss: 0.07523272931575775
Validation loss: 1.5130065051458215

Epoch: 6| Step: 5
Training loss: 0.08893398940563202
Validation loss: 1.5185329516728718

Epoch: 6| Step: 6
Training loss: 0.0636545717716217
Validation loss: 1.551786216356421

Epoch: 6| Step: 7
Training loss: 0.07256390899419785
Validation loss: 1.5029928299688524

Epoch: 6| Step: 8
Training loss: 0.04446745663881302
Validation loss: 1.5328174816664828

Epoch: 6| Step: 9
Training loss: 0.08711741119623184
Validation loss: 1.5464734761945662

Epoch: 6| Step: 10
Training loss: 0.11258459091186523
Validation loss: 1.5521578186301774

Epoch: 6| Step: 11
Training loss: 0.09931951761245728
Validation loss: 1.5489554379575996

Epoch: 6| Step: 12
Training loss: 0.1008918508887291
Validation loss: 1.560014376076319

Epoch: 6| Step: 13
Training loss: 0.05070629343390465
Validation loss: 1.599647302781382

Epoch: 635| Step: 0
Training loss: 0.0357002429664135
Validation loss: 1.5879100791869625

Epoch: 6| Step: 1
Training loss: 0.07071789354085922
Validation loss: 1.5762639071351738

Epoch: 6| Step: 2
Training loss: 0.03684549406170845
Validation loss: 1.595438236831337

Epoch: 6| Step: 3
Training loss: 0.08412954956293106
Validation loss: 1.5865288037125782

Epoch: 6| Step: 4
Training loss: 0.05471045523881912
Validation loss: 1.6027808977711586

Epoch: 6| Step: 5
Training loss: 0.12226173281669617
Validation loss: 1.6011026367064445

Epoch: 6| Step: 6
Training loss: 0.07732225954532623
Validation loss: 1.5881561925334315

Epoch: 6| Step: 7
Training loss: 0.09778192639350891
Validation loss: 1.5537895015490952

Epoch: 6| Step: 8
Training loss: 0.13947878777980804
Validation loss: 1.583414823778214

Epoch: 6| Step: 9
Training loss: 0.07886025309562683
Validation loss: 1.549299741304049

Epoch: 6| Step: 10
Training loss: 0.08205967396497726
Validation loss: 1.5443818415364912

Epoch: 6| Step: 11
Training loss: 0.055284030735492706
Validation loss: 1.5491289733558573

Epoch: 6| Step: 12
Training loss: 0.05945134907960892
Validation loss: 1.5326652667855705

Epoch: 6| Step: 13
Training loss: 0.10981999337673187
Validation loss: 1.540008932031611

Epoch: 636| Step: 0
Training loss: 0.07833217084407806
Validation loss: 1.5431689575154295

Epoch: 6| Step: 1
Training loss: 0.07104847580194473
Validation loss: 1.530992696362157

Epoch: 6| Step: 2
Training loss: 0.16366320848464966
Validation loss: 1.555091183672669

Epoch: 6| Step: 3
Training loss: 0.09575817734003067
Validation loss: 1.5719271206086682

Epoch: 6| Step: 4
Training loss: 0.06073698773980141
Validation loss: 1.5548680392644738

Epoch: 6| Step: 5
Training loss: 0.055079903453588486
Validation loss: 1.5535455749880882

Epoch: 6| Step: 6
Training loss: 0.08820892870426178
Validation loss: 1.5546292515211209

Epoch: 6| Step: 7
Training loss: 0.09825444221496582
Validation loss: 1.560353691859912

Epoch: 6| Step: 8
Training loss: 0.057788193225860596
Validation loss: 1.5728993813196819

Epoch: 6| Step: 9
Training loss: 0.07059236615896225
Validation loss: 1.562228295110887

Epoch: 6| Step: 10
Training loss: 0.06323106586933136
Validation loss: 1.5563845967733732

Epoch: 6| Step: 11
Training loss: 0.05750862509012222
Validation loss: 1.5635822075669483

Epoch: 6| Step: 12
Training loss: 0.05128219723701477
Validation loss: 1.5473695788332211

Epoch: 6| Step: 13
Training loss: 0.13940253853797913
Validation loss: 1.545770937396634

Epoch: 637| Step: 0
Training loss: 0.09341587126255035
Validation loss: 1.5779713264075659

Epoch: 6| Step: 1
Training loss: 0.0571422278881073
Validation loss: 1.561759901303117

Epoch: 6| Step: 2
Training loss: 0.07032658159732819
Validation loss: 1.543305568797614

Epoch: 6| Step: 3
Training loss: 0.05084685981273651
Validation loss: 1.5566898251092562

Epoch: 6| Step: 4
Training loss: 0.10021096467971802
Validation loss: 1.5843147987960486

Epoch: 6| Step: 5
Training loss: 0.18630385398864746
Validation loss: 1.5578263728849349

Epoch: 6| Step: 6
Training loss: 0.08744694292545319
Validation loss: 1.5778106002397434

Epoch: 6| Step: 7
Training loss: 0.11388896405696869
Validation loss: 1.5468976818105227

Epoch: 6| Step: 8
Training loss: 0.09684591740369797
Validation loss: 1.5551337759981874

Epoch: 6| Step: 9
Training loss: 0.04500681906938553
Validation loss: 1.5690011901240195

Epoch: 6| Step: 10
Training loss: 0.057473182678222656
Validation loss: 1.5816286507473196

Epoch: 6| Step: 11
Training loss: 0.05559380352497101
Validation loss: 1.5829875430753153

Epoch: 6| Step: 12
Training loss: 0.05217066407203674
Validation loss: 1.5637495722821964

Epoch: 6| Step: 13
Training loss: 0.07459063082933426
Validation loss: 1.5741146661901986

Epoch: 638| Step: 0
Training loss: 0.0788845345377922
Validation loss: 1.5502101041937386

Epoch: 6| Step: 1
Training loss: 0.0561252124607563
Validation loss: 1.5800884180171515

Epoch: 6| Step: 2
Training loss: 0.13246974349021912
Validation loss: 1.5584259366476407

Epoch: 6| Step: 3
Training loss: 0.06671104580163956
Validation loss: 1.588638997847034

Epoch: 6| Step: 4
Training loss: 0.06303348392248154
Validation loss: 1.5837170244545065

Epoch: 6| Step: 5
Training loss: 0.07536297291517258
Validation loss: 1.6040075350833196

Epoch: 6| Step: 6
Training loss: 0.14231838285923004
Validation loss: 1.6017959322980655

Epoch: 6| Step: 7
Training loss: 0.09556987881660461
Validation loss: 1.5978766692581998

Epoch: 6| Step: 8
Training loss: 0.08311858773231506
Validation loss: 1.5587303446185203

Epoch: 6| Step: 9
Training loss: 0.15448690950870514
Validation loss: 1.6068269193813365

Epoch: 6| Step: 10
Training loss: 0.12864845991134644
Validation loss: 1.606969439855186

Epoch: 6| Step: 11
Training loss: 0.046746812760829926
Validation loss: 1.5708497801134664

Epoch: 6| Step: 12
Training loss: 0.13252636790275574
Validation loss: 1.5980114539464314

Epoch: 6| Step: 13
Training loss: 0.16280296444892883
Validation loss: 1.5557253335111885

Epoch: 639| Step: 0
Training loss: 0.21577009558677673
Validation loss: 1.559118281128586

Epoch: 6| Step: 1
Training loss: 0.09802645444869995
Validation loss: 1.56813266072222

Epoch: 6| Step: 2
Training loss: 0.06847241520881653
Validation loss: 1.5300468107064564

Epoch: 6| Step: 3
Training loss: 0.09298980981111526
Validation loss: 1.5345457305190384

Epoch: 6| Step: 4
Training loss: 0.060915205627679825
Validation loss: 1.5291762012307362

Epoch: 6| Step: 5
Training loss: 0.09325343370437622
Validation loss: 1.5429633099545714

Epoch: 6| Step: 6
Training loss: 0.030210167169570923
Validation loss: 1.5299743913835095

Epoch: 6| Step: 7
Training loss: 0.06442863494157791
Validation loss: 1.5535792009804839

Epoch: 6| Step: 8
Training loss: 0.10973507910966873
Validation loss: 1.5365483337833035

Epoch: 6| Step: 9
Training loss: 0.1374652087688446
Validation loss: 1.534578489359989

Epoch: 6| Step: 10
Training loss: 0.1392117589712143
Validation loss: 1.5212922698707991

Epoch: 6| Step: 11
Training loss: 0.08052545040845871
Validation loss: 1.5184552464433896

Epoch: 6| Step: 12
Training loss: 0.13888917863368988
Validation loss: 1.559981402530465

Epoch: 6| Step: 13
Training loss: 0.13473325967788696
Validation loss: 1.536875654292363

Epoch: 640| Step: 0
Training loss: 0.0670161172747612
Validation loss: 1.56221293762166

Epoch: 6| Step: 1
Training loss: 0.04470856115221977
Validation loss: 1.5507335534659765

Epoch: 6| Step: 2
Training loss: 0.09413090348243713
Validation loss: 1.5747341173951344

Epoch: 6| Step: 3
Training loss: 0.1741933673620224
Validation loss: 1.6007268787712179

Epoch: 6| Step: 4
Training loss: 0.06653329730033875
Validation loss: 1.5629166428760817

Epoch: 6| Step: 5
Training loss: 0.1051773652434349
Validation loss: 1.5910355109040455

Epoch: 6| Step: 6
Training loss: 0.12857767939567566
Validation loss: 1.587376013878853

Epoch: 6| Step: 7
Training loss: 0.0795014500617981
Validation loss: 1.6103801419658046

Epoch: 6| Step: 8
Training loss: 0.03730102255940437
Validation loss: 1.5772691311374787

Epoch: 6| Step: 9
Training loss: 0.10593917965888977
Validation loss: 1.5920146460174232

Epoch: 6| Step: 10
Training loss: 0.06953737884759903
Validation loss: 1.5523568596891177

Epoch: 6| Step: 11
Training loss: 0.0690406858921051
Validation loss: 1.5336939455360494

Epoch: 6| Step: 12
Training loss: 0.09455759823322296
Validation loss: 1.5686030695515294

Epoch: 6| Step: 13
Training loss: 0.0647624135017395
Validation loss: 1.5748117841700071

Epoch: 641| Step: 0
Training loss: 0.06697610020637512
Validation loss: 1.5815159838686708

Epoch: 6| Step: 1
Training loss: 0.050978630781173706
Validation loss: 1.5618502657900575

Epoch: 6| Step: 2
Training loss: 0.0640600174665451
Validation loss: 1.5584361514737528

Epoch: 6| Step: 3
Training loss: 0.1824909746646881
Validation loss: 1.581297073312985

Epoch: 6| Step: 4
Training loss: 0.048814479261636734
Validation loss: 1.5771752416446645

Epoch: 6| Step: 5
Training loss: 0.14867345988750458
Validation loss: 1.559138968426694

Epoch: 6| Step: 6
Training loss: 0.05792897194623947
Validation loss: 1.5836317154668993

Epoch: 6| Step: 7
Training loss: 0.05257240682840347
Validation loss: 1.5815408563101163

Epoch: 6| Step: 8
Training loss: 0.12445376813411713
Validation loss: 1.561993343855745

Epoch: 6| Step: 9
Training loss: 0.08933290094137192
Validation loss: 1.5831719649735319

Epoch: 6| Step: 10
Training loss: 0.09461122751235962
Validation loss: 1.5775145689646404

Epoch: 6| Step: 11
Training loss: 0.08610374480485916
Validation loss: 1.5846720254549416

Epoch: 6| Step: 12
Training loss: 0.10205435007810593
Validation loss: 1.604817723394722

Epoch: 6| Step: 13
Training loss: 0.05693040415644646
Validation loss: 1.6177387186276015

Epoch: 642| Step: 0
Training loss: 0.1259557008743286
Validation loss: 1.6050978988729498

Epoch: 6| Step: 1
Training loss: 0.08149585872888565
Validation loss: 1.5803742793298536

Epoch: 6| Step: 2
Training loss: 0.08142925798892975
Validation loss: 1.578084998233344

Epoch: 6| Step: 3
Training loss: 0.09923058748245239
Validation loss: 1.5325730603228334

Epoch: 6| Step: 4
Training loss: 0.13445086777210236
Validation loss: 1.5217042494845647

Epoch: 6| Step: 5
Training loss: 0.04514946788549423
Validation loss: 1.5734350296758837

Epoch: 6| Step: 6
Training loss: 0.09777192771434784
Validation loss: 1.5519916447260047

Epoch: 6| Step: 7
Training loss: 0.08972901105880737
Validation loss: 1.556898082456281

Epoch: 6| Step: 8
Training loss: 0.121430903673172
Validation loss: 1.5476613237011818

Epoch: 6| Step: 9
Training loss: 0.11206118762493134
Validation loss: 1.5480348140962663

Epoch: 6| Step: 10
Training loss: 0.06657648831605911
Validation loss: 1.5492208337271085

Epoch: 6| Step: 11
Training loss: 0.06227760761976242
Validation loss: 1.5568291012958815

Epoch: 6| Step: 12
Training loss: 0.07775762677192688
Validation loss: 1.5724723954354562

Epoch: 6| Step: 13
Training loss: 0.07763972878456116
Validation loss: 1.5701429305538055

Epoch: 643| Step: 0
Training loss: 0.10366909205913544
Validation loss: 1.6063967725282073

Epoch: 6| Step: 1
Training loss: 0.04967223107814789
Validation loss: 1.591807452581262

Epoch: 6| Step: 2
Training loss: 0.067337766289711
Validation loss: 1.5930298387363393

Epoch: 6| Step: 3
Training loss: 0.038830749690532684
Validation loss: 1.57938596253754

Epoch: 6| Step: 4
Training loss: 0.08092169463634491
Validation loss: 1.5916947741662302

Epoch: 6| Step: 5
Training loss: 0.12882038950920105
Validation loss: 1.598030342850634

Epoch: 6| Step: 6
Training loss: 0.09847894310951233
Validation loss: 1.5712487210509598

Epoch: 6| Step: 7
Training loss: 0.1544869840145111
Validation loss: 1.5753998487226424

Epoch: 6| Step: 8
Training loss: 0.10688193887472153
Validation loss: 1.5621161858240764

Epoch: 6| Step: 9
Training loss: 0.07996910810470581
Validation loss: 1.557581106821696

Epoch: 6| Step: 10
Training loss: 0.08727920055389404
Validation loss: 1.568518304055737

Epoch: 6| Step: 11
Training loss: 0.053342554718256
Validation loss: 1.5423713794318579

Epoch: 6| Step: 12
Training loss: 0.05903291702270508
Validation loss: 1.5604058363104378

Epoch: 6| Step: 13
Training loss: 0.10239394754171371
Validation loss: 1.52977067424405

Epoch: 644| Step: 0
Training loss: 0.09646391123533249
Validation loss: 1.5589968978717763

Epoch: 6| Step: 1
Training loss: 0.054551586508750916
Validation loss: 1.576557913134175

Epoch: 6| Step: 2
Training loss: 0.11656470596790314
Validation loss: 1.547470106873461

Epoch: 6| Step: 3
Training loss: 0.08927186578512192
Validation loss: 1.5760523478190105

Epoch: 6| Step: 4
Training loss: 0.10206936299800873
Validation loss: 1.5874034473972936

Epoch: 6| Step: 5
Training loss: 0.09408566355705261
Validation loss: 1.5694066427087272

Epoch: 6| Step: 6
Training loss: 0.11237131804227829
Validation loss: 1.6097647746404011

Epoch: 6| Step: 7
Training loss: 0.08761777728796005
Validation loss: 1.604517816215433

Epoch: 6| Step: 8
Training loss: 0.057195015251636505
Validation loss: 1.5696847349084833

Epoch: 6| Step: 9
Training loss: 0.12191619724035263
Validation loss: 1.616012333541788

Epoch: 6| Step: 10
Training loss: 0.15285566449165344
Validation loss: 1.6030565897623699

Epoch: 6| Step: 11
Training loss: 0.17337912321090698
Validation loss: 1.5679664240088513

Epoch: 6| Step: 12
Training loss: 0.09252185374498367
Validation loss: 1.5844854385622087

Epoch: 6| Step: 13
Training loss: 0.13007904589176178
Validation loss: 1.5940061423086351

Epoch: 645| Step: 0
Training loss: 0.06534844636917114
Validation loss: 1.5770461995114562

Epoch: 6| Step: 1
Training loss: 0.04465567693114281
Validation loss: 1.5945418752649778

Epoch: 6| Step: 2
Training loss: 0.17102734744548798
Validation loss: 1.5769455843074347

Epoch: 6| Step: 3
Training loss: 0.09155188500881195
Validation loss: 1.6187702475055572

Epoch: 6| Step: 4
Training loss: 0.06566745787858963
Validation loss: 1.5883214518588076

Epoch: 6| Step: 5
Training loss: 0.1570109724998474
Validation loss: 1.57927906128668

Epoch: 6| Step: 6
Training loss: 0.07996474951505661
Validation loss: 1.5611587903832878

Epoch: 6| Step: 7
Training loss: 0.04744524508714676
Validation loss: 1.587362467601735

Epoch: 6| Step: 8
Training loss: 0.15881504118442535
Validation loss: 1.5256714936225646

Epoch: 6| Step: 9
Training loss: 0.06192295253276825
Validation loss: 1.539048429458372

Epoch: 6| Step: 10
Training loss: 0.13337449729442596
Validation loss: 1.577982057807266

Epoch: 6| Step: 11
Training loss: 0.11228518187999725
Validation loss: 1.5620840172613821

Epoch: 6| Step: 12
Training loss: 0.1380264163017273
Validation loss: 1.575894134019011

Epoch: 6| Step: 13
Training loss: 0.14685064554214478
Validation loss: 1.548358795463398

Epoch: 646| Step: 0
Training loss: 0.05406986176967621
Validation loss: 1.5219865024730723

Epoch: 6| Step: 1
Training loss: 0.06421327590942383
Validation loss: 1.5360442002614338

Epoch: 6| Step: 2
Training loss: 0.09188103675842285
Validation loss: 1.534778238624655

Epoch: 6| Step: 3
Training loss: 0.05856913700699806
Validation loss: 1.5051784335926015

Epoch: 6| Step: 4
Training loss: 0.16777966916561127
Validation loss: 1.5279436072995585

Epoch: 6| Step: 5
Training loss: 0.16853290796279907
Validation loss: 1.5421766196527789

Epoch: 6| Step: 6
Training loss: 0.09470637887716293
Validation loss: 1.5252016616123978

Epoch: 6| Step: 7
Training loss: 0.07266925275325775
Validation loss: 1.5252390997384184

Epoch: 6| Step: 8
Training loss: 0.0874072015285492
Validation loss: 1.532310530703555

Epoch: 6| Step: 9
Training loss: 0.06459096074104309
Validation loss: 1.5291279439003236

Epoch: 6| Step: 10
Training loss: 0.09995557367801666
Validation loss: 1.5265115851997046

Epoch: 6| Step: 11
Training loss: 0.07751424610614777
Validation loss: 1.540619811704082

Epoch: 6| Step: 12
Training loss: 0.08619340509176254
Validation loss: 1.5627546438606836

Epoch: 6| Step: 13
Training loss: 0.08011579513549805
Validation loss: 1.5737935317459928

Epoch: 647| Step: 0
Training loss: 0.10956864058971405
Validation loss: 1.5593518762178318

Epoch: 6| Step: 1
Training loss: 0.09571759402751923
Validation loss: 1.6151452609287795

Epoch: 6| Step: 2
Training loss: 0.09424232691526413
Validation loss: 1.5631469782962595

Epoch: 6| Step: 3
Training loss: 0.09230350703001022
Validation loss: 1.5481846909369192

Epoch: 6| Step: 4
Training loss: 0.07166508585214615
Validation loss: 1.5216155129094278

Epoch: 6| Step: 5
Training loss: 0.09464371204376221
Validation loss: 1.5283553267037997

Epoch: 6| Step: 6
Training loss: 0.14039263129234314
Validation loss: 1.5312147678867463

Epoch: 6| Step: 7
Training loss: 0.10416631400585175
Validation loss: 1.506504060119711

Epoch: 6| Step: 8
Training loss: 0.05458424612879753
Validation loss: 1.5113140370256157

Epoch: 6| Step: 9
Training loss: 0.06180737540125847
Validation loss: 1.5017431025863976

Epoch: 6| Step: 10
Training loss: 0.1101374551653862
Validation loss: 1.5503197472582582

Epoch: 6| Step: 11
Training loss: 0.11258818209171295
Validation loss: 1.5426815645669096

Epoch: 6| Step: 12
Training loss: 0.09701139479875565
Validation loss: 1.5086685137082172

Epoch: 6| Step: 13
Training loss: 0.21366292238235474
Validation loss: 1.5241643972294305

Epoch: 648| Step: 0
Training loss: 0.11427375674247742
Validation loss: 1.523060582017386

Epoch: 6| Step: 1
Training loss: 0.0948580875992775
Validation loss: 1.516109912626205

Epoch: 6| Step: 2
Training loss: 0.15539970993995667
Validation loss: 1.5313471914619528

Epoch: 6| Step: 3
Training loss: 0.09583225846290588
Validation loss: 1.5737039940331572

Epoch: 6| Step: 4
Training loss: 0.18531310558319092
Validation loss: 1.5387812929768716

Epoch: 6| Step: 5
Training loss: 0.06913413107395172
Validation loss: 1.5636711992243284

Epoch: 6| Step: 6
Training loss: 0.08696924149990082
Validation loss: 1.54794567631137

Epoch: 6| Step: 7
Training loss: 0.06671474874019623
Validation loss: 1.5567556222279866

Epoch: 6| Step: 8
Training loss: 0.08651696145534515
Validation loss: 1.5563374052765548

Epoch: 6| Step: 9
Training loss: 0.09013678878545761
Validation loss: 1.5646760406032685

Epoch: 6| Step: 10
Training loss: 0.0844673290848732
Validation loss: 1.5757304019825433

Epoch: 6| Step: 11
Training loss: 0.14396438002586365
Validation loss: 1.5742953477367279

Epoch: 6| Step: 12
Training loss: 0.07539310306310654
Validation loss: 1.5705197959817865

Epoch: 6| Step: 13
Training loss: 0.05374310910701752
Validation loss: 1.53990549554107

Epoch: 649| Step: 0
Training loss: 0.10697619616985321
Validation loss: 1.5410518876967891

Epoch: 6| Step: 1
Training loss: 0.041967689990997314
Validation loss: 1.522905776577611

Epoch: 6| Step: 2
Training loss: 0.09707608819007874
Validation loss: 1.5359462525254937

Epoch: 6| Step: 3
Training loss: 0.0900738537311554
Validation loss: 1.5260297893196024

Epoch: 6| Step: 4
Training loss: 0.08487173914909363
Validation loss: 1.5448945952999977

Epoch: 6| Step: 5
Training loss: 0.08903791010379791
Validation loss: 1.5127305138495661

Epoch: 6| Step: 6
Training loss: 0.15752708911895752
Validation loss: 1.5351768257797405

Epoch: 6| Step: 7
Training loss: 0.07989199459552765
Validation loss: 1.5220658356143582

Epoch: 6| Step: 8
Training loss: 0.05275929719209671
Validation loss: 1.5309090127227127

Epoch: 6| Step: 9
Training loss: 0.0883713960647583
Validation loss: 1.5233565120286838

Epoch: 6| Step: 10
Training loss: 0.08179976791143417
Validation loss: 1.5384682199006439

Epoch: 6| Step: 11
Training loss: 0.0727573037147522
Validation loss: 1.5216499092758342

Epoch: 6| Step: 12
Training loss: 0.06465961784124374
Validation loss: 1.5518937623629006

Epoch: 6| Step: 13
Training loss: 0.08873667567968369
Validation loss: 1.5736626989098006

Epoch: 650| Step: 0
Training loss: 0.03872212767601013
Validation loss: 1.5519651956455682

Epoch: 6| Step: 1
Training loss: 0.08217449486255646
Validation loss: 1.5525613241298224

Epoch: 6| Step: 2
Training loss: 0.06754250824451447
Validation loss: 1.551132268803094

Epoch: 6| Step: 3
Training loss: 0.07403857260942459
Validation loss: 1.5726899126524567

Epoch: 6| Step: 4
Training loss: 0.06781651824712753
Validation loss: 1.532722073216592

Epoch: 6| Step: 5
Training loss: 0.13011273741722107
Validation loss: 1.5412528848135343

Epoch: 6| Step: 6
Training loss: 0.08242498338222504
Validation loss: 1.5380221374573246

Epoch: 6| Step: 7
Training loss: 0.09515929222106934
Validation loss: 1.5682611209090038

Epoch: 6| Step: 8
Training loss: 0.19885236024856567
Validation loss: 1.5374333397034676

Epoch: 6| Step: 9
Training loss: 0.0394180491566658
Validation loss: 1.5165468569724792

Epoch: 6| Step: 10
Training loss: 0.1320456564426422
Validation loss: 1.5336342473183908

Epoch: 6| Step: 11
Training loss: 0.1622956097126007
Validation loss: 1.5331868369092223

Epoch: 6| Step: 12
Training loss: 0.06472016870975494
Validation loss: 1.505990195017989

Epoch: 6| Step: 13
Training loss: 0.1281982958316803
Validation loss: 1.5264564470578266

Epoch: 651| Step: 0
Training loss: 0.11343778669834137
Validation loss: 1.551145290815702

Epoch: 6| Step: 1
Training loss: 0.05422358214855194
Validation loss: 1.5613102964175645

Epoch: 6| Step: 2
Training loss: 0.06455501914024353
Validation loss: 1.5805458548248454

Epoch: 6| Step: 3
Training loss: 0.06655177474021912
Validation loss: 1.5781140455635645

Epoch: 6| Step: 4
Training loss: 0.1017884910106659
Validation loss: 1.5670197984223724

Epoch: 6| Step: 5
Training loss: 0.13312190771102905
Validation loss: 1.5934477698418401

Epoch: 6| Step: 6
Training loss: 0.0635482668876648
Validation loss: 1.5748534689667404

Epoch: 6| Step: 7
Training loss: 0.0930410623550415
Validation loss: 1.5768976929367229

Epoch: 6| Step: 8
Training loss: 0.15236231684684753
Validation loss: 1.5369184606818742

Epoch: 6| Step: 9
Training loss: 0.06438231468200684
Validation loss: 1.577884344644444

Epoch: 6| Step: 10
Training loss: 0.08486951142549515
Validation loss: 1.5793023391436505

Epoch: 6| Step: 11
Training loss: 0.08007054030895233
Validation loss: 1.580219171380484

Epoch: 6| Step: 12
Training loss: 0.09590964764356613
Validation loss: 1.5475303921648251

Epoch: 6| Step: 13
Training loss: 0.04225250706076622
Validation loss: 1.5491809819334297

Epoch: 652| Step: 0
Training loss: 0.12070818990468979
Validation loss: 1.5474652128834878

Epoch: 6| Step: 1
Training loss: 0.11198904365301132
Validation loss: 1.555559504416681

Epoch: 6| Step: 2
Training loss: 0.0794336199760437
Validation loss: 1.5407217125738821

Epoch: 6| Step: 3
Training loss: 0.060144856572151184
Validation loss: 1.5406644190511396

Epoch: 6| Step: 4
Training loss: 0.0614011287689209
Validation loss: 1.5283454361782278

Epoch: 6| Step: 5
Training loss: 0.061317019164562225
Validation loss: 1.5368385968669769

Epoch: 6| Step: 6
Training loss: 0.12878867983818054
Validation loss: 1.5408821926322034

Epoch: 6| Step: 7
Training loss: 0.090180903673172
Validation loss: 1.556816816329956

Epoch: 6| Step: 8
Training loss: 0.0986691415309906
Validation loss: 1.5612723199270104

Epoch: 6| Step: 9
Training loss: 0.1555815041065216
Validation loss: 1.550455399738845

Epoch: 6| Step: 10
Training loss: 0.09163466840982437
Validation loss: 1.5695871204458258

Epoch: 6| Step: 11
Training loss: 0.05281363055109978
Validation loss: 1.5492038746033945

Epoch: 6| Step: 12
Training loss: 0.05675620585680008
Validation loss: 1.5484386323600687

Epoch: 6| Step: 13
Training loss: 0.10163778811693192
Validation loss: 1.5607101712175595

Epoch: 653| Step: 0
Training loss: 0.06553830951452255
Validation loss: 1.5630181963725756

Epoch: 6| Step: 1
Training loss: 0.13314786553382874
Validation loss: 1.5649432546348983

Epoch: 6| Step: 2
Training loss: 0.041499726474285126
Validation loss: 1.552247651161686

Epoch: 6| Step: 3
Training loss: 0.09422599524259567
Validation loss: 1.5462068396229898

Epoch: 6| Step: 4
Training loss: 0.0709521621465683
Validation loss: 1.5607907643882177

Epoch: 6| Step: 5
Training loss: 0.1703719049692154
Validation loss: 1.5332183440526326

Epoch: 6| Step: 6
Training loss: 0.07419972121715546
Validation loss: 1.5381858630846905

Epoch: 6| Step: 7
Training loss: 0.06863982230424881
Validation loss: 1.5479943534379363

Epoch: 6| Step: 8
Training loss: 0.06262711435556412
Validation loss: 1.5643773566010177

Epoch: 6| Step: 9
Training loss: 0.04145566001534462
Validation loss: 1.5349502486567344

Epoch: 6| Step: 10
Training loss: 0.07804425060749054
Validation loss: 1.5504796581883584

Epoch: 6| Step: 11
Training loss: 0.06256859004497528
Validation loss: 1.5496122708884619

Epoch: 6| Step: 12
Training loss: 0.03526536375284195
Validation loss: 1.550913578720503

Epoch: 6| Step: 13
Training loss: 0.08171936869621277
Validation loss: 1.5349084318325084

Epoch: 654| Step: 0
Training loss: 0.050742603838443756
Validation loss: 1.546684072863671

Epoch: 6| Step: 1
Training loss: 0.06488776206970215
Validation loss: 1.5451843507828251

Epoch: 6| Step: 2
Training loss: 0.07512465864419937
Validation loss: 1.4947296419451315

Epoch: 6| Step: 3
Training loss: 0.14349091053009033
Validation loss: 1.5100817629086074

Epoch: 6| Step: 4
Training loss: 0.04852371662855148
Validation loss: 1.5213675896326702

Epoch: 6| Step: 5
Training loss: 0.038438230752944946
Validation loss: 1.5305507606075657

Epoch: 6| Step: 6
Training loss: 0.048490509390830994
Validation loss: 1.518672776478593

Epoch: 6| Step: 7
Training loss: 0.05322718620300293
Validation loss: 1.5343340327662807

Epoch: 6| Step: 8
Training loss: 0.1271001100540161
Validation loss: 1.535392076738419

Epoch: 6| Step: 9
Training loss: 0.06856042891740799
Validation loss: 1.5237088357248614

Epoch: 6| Step: 10
Training loss: 0.07369497418403625
Validation loss: 1.5592754463995657

Epoch: 6| Step: 11
Training loss: 0.10033652186393738
Validation loss: 1.5430538346690517

Epoch: 6| Step: 12
Training loss: 0.06936179101467133
Validation loss: 1.5505445932829252

Epoch: 6| Step: 13
Training loss: 0.04030543565750122
Validation loss: 1.5199313240666543

Epoch: 655| Step: 0
Training loss: 0.049844034016132355
Validation loss: 1.5601692661162345

Epoch: 6| Step: 1
Training loss: 0.09749441593885422
Validation loss: 1.5440955546594435

Epoch: 6| Step: 2
Training loss: 0.062435612082481384
Validation loss: 1.5322730528411044

Epoch: 6| Step: 3
Training loss: 0.1173546314239502
Validation loss: 1.5414659079685007

Epoch: 6| Step: 4
Training loss: 0.04177997261285782
Validation loss: 1.5431560149756811

Epoch: 6| Step: 5
Training loss: 0.07075594365596771
Validation loss: 1.5338728556068995

Epoch: 6| Step: 6
Training loss: 0.04658416658639908
Validation loss: 1.518245643185031

Epoch: 6| Step: 7
Training loss: 0.06407049298286438
Validation loss: 1.55314544452134

Epoch: 6| Step: 8
Training loss: 0.068266361951828
Validation loss: 1.5578434467315674

Epoch: 6| Step: 9
Training loss: 0.057526055723428726
Validation loss: 1.5622627305728134

Epoch: 6| Step: 10
Training loss: 0.08409973978996277
Validation loss: 1.5626476836460892

Epoch: 6| Step: 11
Training loss: 0.09679590910673141
Validation loss: 1.5766168217505179

Epoch: 6| Step: 12
Training loss: 0.05024532973766327
Validation loss: 1.5584303320095103

Epoch: 6| Step: 13
Training loss: 0.19653533399105072
Validation loss: 1.5391192622082208

Epoch: 656| Step: 0
Training loss: 0.04949333518743515
Validation loss: 1.5113769474849905

Epoch: 6| Step: 1
Training loss: 0.06757752597332001
Validation loss: 1.535152103311272

Epoch: 6| Step: 2
Training loss: 0.06720581650733948
Validation loss: 1.5304531717813143

Epoch: 6| Step: 3
Training loss: 0.08403252810239792
Validation loss: 1.517537211859098

Epoch: 6| Step: 4
Training loss: 0.06131872534751892
Validation loss: 1.4866401034016763

Epoch: 6| Step: 5
Training loss: 0.05338863655924797
Validation loss: 1.5122218490928732

Epoch: 6| Step: 6
Training loss: 0.1630105972290039
Validation loss: 1.5217490023182285

Epoch: 6| Step: 7
Training loss: 0.11402948200702667
Validation loss: 1.523950049954076

Epoch: 6| Step: 8
Training loss: 0.047253284603357315
Validation loss: 1.541688713976132

Epoch: 6| Step: 9
Training loss: 0.09839604794979095
Validation loss: 1.5508789580355409

Epoch: 6| Step: 10
Training loss: 0.0895189642906189
Validation loss: 1.5307375782279558

Epoch: 6| Step: 11
Training loss: 0.09552475064992905
Validation loss: 1.5139106403114975

Epoch: 6| Step: 12
Training loss: 0.07318937033414841
Validation loss: 1.5321055150801135

Epoch: 6| Step: 13
Training loss: 0.04358697310090065
Validation loss: 1.538497946595633

Epoch: 657| Step: 0
Training loss: 0.07466363906860352
Validation loss: 1.536653443049359

Epoch: 6| Step: 1
Training loss: 0.12603077292442322
Validation loss: 1.5578557739975631

Epoch: 6| Step: 2
Training loss: 0.034847233444452286
Validation loss: 1.5335945134521813

Epoch: 6| Step: 3
Training loss: 0.1104617565870285
Validation loss: 1.573420528442629

Epoch: 6| Step: 4
Training loss: 0.0699126124382019
Validation loss: 1.5853476242352558

Epoch: 6| Step: 5
Training loss: 0.10065244138240814
Validation loss: 1.573389075135672

Epoch: 6| Step: 6
Training loss: 0.18761077523231506
Validation loss: 1.5678690069465226

Epoch: 6| Step: 7
Training loss: 0.1037529706954956
Validation loss: 1.5336100901326826

Epoch: 6| Step: 8
Training loss: 0.046188198029994965
Validation loss: 1.5415896728474607

Epoch: 6| Step: 9
Training loss: 0.0617409385740757
Validation loss: 1.5300127947202293

Epoch: 6| Step: 10
Training loss: 0.051700130105018616
Validation loss: 1.536006490389506

Epoch: 6| Step: 11
Training loss: 0.07137841731309891
Validation loss: 1.5336287662547121

Epoch: 6| Step: 12
Training loss: 0.06533537805080414
Validation loss: 1.5235724192793652

Epoch: 6| Step: 13
Training loss: 0.02157306671142578
Validation loss: 1.507805335906244

Epoch: 658| Step: 0
Training loss: 0.06664790213108063
Validation loss: 1.5213153266137647

Epoch: 6| Step: 1
Training loss: 0.04657503962516785
Validation loss: 1.5022441187212545

Epoch: 6| Step: 2
Training loss: 0.06334805488586426
Validation loss: 1.5414802028286843

Epoch: 6| Step: 3
Training loss: 0.08943415433168411
Validation loss: 1.5165244058896137

Epoch: 6| Step: 4
Training loss: 0.08045701682567596
Validation loss: 1.5221148831869966

Epoch: 6| Step: 5
Training loss: 0.08150575309991837
Validation loss: 1.5502102977486067

Epoch: 6| Step: 6
Training loss: 0.08188360929489136
Validation loss: 1.5720702140561995

Epoch: 6| Step: 7
Training loss: 0.1357438564300537
Validation loss: 1.6059169705196092

Epoch: 6| Step: 8
Training loss: 0.08490931987762451
Validation loss: 1.6008632170256747

Epoch: 6| Step: 9
Training loss: 0.0572853609919548
Validation loss: 1.5792071088667838

Epoch: 6| Step: 10
Training loss: 0.12921014428138733
Validation loss: 1.6017854367533038

Epoch: 6| Step: 11
Training loss: 0.055424101650714874
Validation loss: 1.5734876804454352

Epoch: 6| Step: 12
Training loss: 0.08613715320825577
Validation loss: 1.5873551740441272

Epoch: 6| Step: 13
Training loss: 0.07728274166584015
Validation loss: 1.6052771896444342

Epoch: 659| Step: 0
Training loss: 0.06888122856616974
Validation loss: 1.5958183632102063

Epoch: 6| Step: 1
Training loss: 0.14493200182914734
Validation loss: 1.5765650272369385

Epoch: 6| Step: 2
Training loss: 0.06132812052965164
Validation loss: 1.5895879332737257

Epoch: 6| Step: 3
Training loss: 0.07697802782058716
Validation loss: 1.5783232347939604

Epoch: 6| Step: 4
Training loss: 0.06742953509092331
Validation loss: 1.5736659624243294

Epoch: 6| Step: 5
Training loss: 0.1611320674419403
Validation loss: 1.5814702677470382

Epoch: 6| Step: 6
Training loss: 0.17715124785900116
Validation loss: 1.557863861001948

Epoch: 6| Step: 7
Training loss: 0.09646422415971756
Validation loss: 1.5605956085266606

Epoch: 6| Step: 8
Training loss: 0.14050696790218353
Validation loss: 1.568533843563449

Epoch: 6| Step: 9
Training loss: 0.09403489530086517
Validation loss: 1.589589315076028

Epoch: 6| Step: 10
Training loss: 0.058926939964294434
Validation loss: 1.5918405402091242

Epoch: 6| Step: 11
Training loss: 0.08831726759672165
Validation loss: 1.5770484888425438

Epoch: 6| Step: 12
Training loss: 0.11155480146408081
Validation loss: 1.5540384400275447

Epoch: 6| Step: 13
Training loss: 0.05744244158267975
Validation loss: 1.592718106444164

Epoch: 660| Step: 0
Training loss: 0.0750531256198883
Validation loss: 1.5777480550991592

Epoch: 6| Step: 1
Training loss: 0.20378434658050537
Validation loss: 1.6024970508390857

Epoch: 6| Step: 2
Training loss: 0.07760351896286011
Validation loss: 1.6023982673562982

Epoch: 6| Step: 3
Training loss: 0.13220277428627014
Validation loss: 1.5907165388907156

Epoch: 6| Step: 4
Training loss: 0.18177422881126404
Validation loss: 1.5875614355969172

Epoch: 6| Step: 5
Training loss: 0.07692188769578934
Validation loss: 1.5869112527498634

Epoch: 6| Step: 6
Training loss: 0.08701901882886887
Validation loss: 1.5691011099405185

Epoch: 6| Step: 7
Training loss: 0.059778884053230286
Validation loss: 1.5894681651105163

Epoch: 6| Step: 8
Training loss: 0.10720495879650116
Validation loss: 1.5866163366584367

Epoch: 6| Step: 9
Training loss: 0.10799539089202881
Validation loss: 1.5642767324242541

Epoch: 6| Step: 10
Training loss: 0.10571490228176117
Validation loss: 1.5873718569355626

Epoch: 6| Step: 11
Training loss: 0.06373406201601028
Validation loss: 1.570213326843836

Epoch: 6| Step: 12
Training loss: 0.07071398198604584
Validation loss: 1.5602440411044705

Epoch: 6| Step: 13
Training loss: 0.1519998013973236
Validation loss: 1.5535639550096245

Epoch: 661| Step: 0
Training loss: 0.043824851512908936
Validation loss: 1.5378089053656465

Epoch: 6| Step: 1
Training loss: 0.0770077183842659
Validation loss: 1.5663841001449093

Epoch: 6| Step: 2
Training loss: 0.06053893640637398
Validation loss: 1.546795710440605

Epoch: 6| Step: 3
Training loss: 0.13646981120109558
Validation loss: 1.5710690841879895

Epoch: 6| Step: 4
Training loss: 0.06663934886455536
Validation loss: 1.557884024035546

Epoch: 6| Step: 5
Training loss: 0.063555508852005
Validation loss: 1.5853466782518613

Epoch: 6| Step: 6
Training loss: 0.08195004612207413
Validation loss: 1.6000331986335017

Epoch: 6| Step: 7
Training loss: 0.08667375147342682
Validation loss: 1.5675633722735989

Epoch: 6| Step: 8
Training loss: 0.12144485116004944
Validation loss: 1.5904563293662122

Epoch: 6| Step: 9
Training loss: 0.04976296424865723
Validation loss: 1.568014496116228

Epoch: 6| Step: 10
Training loss: 0.10462252795696259
Validation loss: 1.5881025220758171

Epoch: 6| Step: 11
Training loss: 0.05850694328546524
Validation loss: 1.5682875866531043

Epoch: 6| Step: 12
Training loss: 0.0795765221118927
Validation loss: 1.5772363575555945

Epoch: 6| Step: 13
Training loss: 0.032543640583753586
Validation loss: 1.5524176487358667

Epoch: 662| Step: 0
Training loss: 0.05383508652448654
Validation loss: 1.5698331479103333

Epoch: 6| Step: 1
Training loss: 0.05959717929363251
Validation loss: 1.579651181415845

Epoch: 6| Step: 2
Training loss: 0.05579390376806259
Validation loss: 1.5951377935307

Epoch: 6| Step: 3
Training loss: 0.09657411277294159
Validation loss: 1.582118074099223

Epoch: 6| Step: 4
Training loss: 0.06699049472808838
Validation loss: 1.5879569092104513

Epoch: 6| Step: 5
Training loss: 0.06593932211399078
Validation loss: 1.5800691176486272

Epoch: 6| Step: 6
Training loss: 0.09139443933963776
Validation loss: 1.564631450560785

Epoch: 6| Step: 7
Training loss: 0.18129289150238037
Validation loss: 1.5581240935992169

Epoch: 6| Step: 8
Training loss: 0.09648562967777252
Validation loss: 1.544617691347676

Epoch: 6| Step: 9
Training loss: 0.05532213672995567
Validation loss: 1.5550517997434061

Epoch: 6| Step: 10
Training loss: 0.10742489248514175
Validation loss: 1.536437899835648

Epoch: 6| Step: 11
Training loss: 0.16015858948230743
Validation loss: 1.5556684488891273

Epoch: 6| Step: 12
Training loss: 0.04494630545377731
Validation loss: 1.528796415175161

Epoch: 6| Step: 13
Training loss: 0.10015659034252167
Validation loss: 1.518638809521993

Epoch: 663| Step: 0
Training loss: 0.05226614698767662
Validation loss: 1.5275686940839213

Epoch: 6| Step: 1
Training loss: 0.059825439006090164
Validation loss: 1.5422250340061803

Epoch: 6| Step: 2
Training loss: 0.05880236625671387
Validation loss: 1.5355865570806688

Epoch: 6| Step: 3
Training loss: 0.03207601606845856
Validation loss: 1.5419149450076524

Epoch: 6| Step: 4
Training loss: 0.04414856433868408
Validation loss: 1.5285166489180697

Epoch: 6| Step: 5
Training loss: 0.07332141697406769
Validation loss: 1.5384404300361552

Epoch: 6| Step: 6
Training loss: 0.04333389550447464
Validation loss: 1.530238239995895

Epoch: 6| Step: 7
Training loss: 0.09269359707832336
Validation loss: 1.564239671153407

Epoch: 6| Step: 8
Training loss: 0.07921834290027618
Validation loss: 1.5454005643885622

Epoch: 6| Step: 9
Training loss: 0.1105729341506958
Validation loss: 1.5331911861255605

Epoch: 6| Step: 10
Training loss: 0.08047570288181305
Validation loss: 1.5637086322230678

Epoch: 6| Step: 11
Training loss: 0.04354478418827057
Validation loss: 1.5582777005369945

Epoch: 6| Step: 12
Training loss: 0.17057859897613525
Validation loss: 1.5641109725480438

Epoch: 6| Step: 13
Training loss: 0.05323735252022743
Validation loss: 1.5672502261336132

Epoch: 664| Step: 0
Training loss: 0.06850236654281616
Validation loss: 1.547435434274776

Epoch: 6| Step: 1
Training loss: 0.173988938331604
Validation loss: 1.5286240372606503

Epoch: 6| Step: 2
Training loss: 0.04207141324877739
Validation loss: 1.5395996660314581

Epoch: 6| Step: 3
Training loss: 0.07377234101295471
Validation loss: 1.5372413460926344

Epoch: 6| Step: 4
Training loss: 0.12725281715393066
Validation loss: 1.5585912132775912

Epoch: 6| Step: 5
Training loss: 0.10308597981929779
Validation loss: 1.530229324935585

Epoch: 6| Step: 6
Training loss: 0.07142077386379242
Validation loss: 1.5360394472716956

Epoch: 6| Step: 7
Training loss: 0.06701675802469254
Validation loss: 1.5414243898084086

Epoch: 6| Step: 8
Training loss: 0.06882340461015701
Validation loss: 1.5561227362643006

Epoch: 6| Step: 9
Training loss: 0.0455888956785202
Validation loss: 1.5752460174663092

Epoch: 6| Step: 10
Training loss: 0.06766583770513535
Validation loss: 1.5831556723963829

Epoch: 6| Step: 11
Training loss: 0.08463069796562195
Validation loss: 1.57429293663271

Epoch: 6| Step: 12
Training loss: 0.09278461337089539
Validation loss: 1.5597664848450692

Epoch: 6| Step: 13
Training loss: 0.16570168733596802
Validation loss: 1.5352583418610275

Epoch: 665| Step: 0
Training loss: 0.12445471435785294
Validation loss: 1.5438156935476488

Epoch: 6| Step: 1
Training loss: 0.12831930816173553
Validation loss: 1.5562296503333635

Epoch: 6| Step: 2
Training loss: 0.0833556205034256
Validation loss: 1.5583948589140368

Epoch: 6| Step: 3
Training loss: 0.08322885632514954
Validation loss: 1.5414911316287132

Epoch: 6| Step: 4
Training loss: 0.12577098608016968
Validation loss: 1.5476717269548805

Epoch: 6| Step: 5
Training loss: 0.06450045108795166
Validation loss: 1.5576699702970442

Epoch: 6| Step: 6
Training loss: 0.07844580709934235
Validation loss: 1.5527989787440146

Epoch: 6| Step: 7
Training loss: 0.056188590824604034
Validation loss: 1.5162030317450081

Epoch: 6| Step: 8
Training loss: 0.08848169445991516
Validation loss: 1.561410173293083

Epoch: 6| Step: 9
Training loss: 0.10767542570829391
Validation loss: 1.5469625701186478

Epoch: 6| Step: 10
Training loss: 0.13182668387889862
Validation loss: 1.5125221821569628

Epoch: 6| Step: 11
Training loss: 0.10405407845973969
Validation loss: 1.540791944790912

Epoch: 6| Step: 12
Training loss: 0.15235938131809235
Validation loss: 1.52295143758097

Epoch: 6| Step: 13
Training loss: 0.1255757063627243
Validation loss: 1.551112389051786

Epoch: 666| Step: 0
Training loss: 0.1308807134628296
Validation loss: 1.5585688096220776

Epoch: 6| Step: 1
Training loss: 0.05777028575539589
Validation loss: 1.5596130842803626

Epoch: 6| Step: 2
Training loss: 0.0755821168422699
Validation loss: 1.5561675256298435

Epoch: 6| Step: 3
Training loss: 0.061609964817762375
Validation loss: 1.5801985968825638

Epoch: 6| Step: 4
Training loss: 0.08796268701553345
Validation loss: 1.580664873123169

Epoch: 6| Step: 5
Training loss: 0.08162308484315872
Validation loss: 1.5811824439674296

Epoch: 6| Step: 6
Training loss: 0.07118682563304901
Validation loss: 1.5946469390264122

Epoch: 6| Step: 7
Training loss: 0.14998464286327362
Validation loss: 1.6141276231376074

Epoch: 6| Step: 8
Training loss: 0.06492878496646881
Validation loss: 1.5701950621861283

Epoch: 6| Step: 9
Training loss: 0.13503140211105347
Validation loss: 1.5780021131679576

Epoch: 6| Step: 10
Training loss: 0.04220009967684746
Validation loss: 1.552373227252755

Epoch: 6| Step: 11
Training loss: 0.07329573482275009
Validation loss: 1.5765572363330471

Epoch: 6| Step: 12
Training loss: 0.0652226060628891
Validation loss: 1.5396126136984876

Epoch: 6| Step: 13
Training loss: 0.09361307322978973
Validation loss: 1.5315404015202676

Epoch: 667| Step: 0
Training loss: 0.08425281196832657
Validation loss: 1.5310397686496857

Epoch: 6| Step: 1
Training loss: 0.1214531660079956
Validation loss: 1.5670858429324241

Epoch: 6| Step: 2
Training loss: 0.1075282171368599
Validation loss: 1.5641974761921873

Epoch: 6| Step: 3
Training loss: 0.20459438860416412
Validation loss: 1.5901259594066168

Epoch: 6| Step: 4
Training loss: 0.14274434745311737
Validation loss: 1.553274521263697

Epoch: 6| Step: 5
Training loss: 0.13442960381507874
Validation loss: 1.5591319940423454

Epoch: 6| Step: 6
Training loss: 0.15754082798957825
Validation loss: 1.5705306478725967

Epoch: 6| Step: 7
Training loss: 0.08783906698226929
Validation loss: 1.6158856179124566

Epoch: 6| Step: 8
Training loss: 0.07273756712675095
Validation loss: 1.6159381763909453

Epoch: 6| Step: 9
Training loss: 0.11201760917901993
Validation loss: 1.6269461647156747

Epoch: 6| Step: 10
Training loss: 0.08811910450458527
Validation loss: 1.609431582112466

Epoch: 6| Step: 11
Training loss: 0.13088427484035492
Validation loss: 1.61643636098472

Epoch: 6| Step: 12
Training loss: 0.11761035025119781
Validation loss: 1.5883188914227229

Epoch: 6| Step: 13
Training loss: 0.07494530826807022
Validation loss: 1.5782387256622314

Epoch: 668| Step: 0
Training loss: 0.05778184533119202
Validation loss: 1.5870186462197253

Epoch: 6| Step: 1
Training loss: 0.06592226773500443
Validation loss: 1.5620682406169113

Epoch: 6| Step: 2
Training loss: 0.17128737270832062
Validation loss: 1.5858514796021164

Epoch: 6| Step: 3
Training loss: 0.08906266838312149
Validation loss: 1.5961314978138093

Epoch: 6| Step: 4
Training loss: 0.1043412834405899
Validation loss: 1.569203067851323

Epoch: 6| Step: 5
Training loss: 0.04942946135997772
Validation loss: 1.5818856352119035

Epoch: 6| Step: 6
Training loss: 0.06546817719936371
Validation loss: 1.5769683135453092

Epoch: 6| Step: 7
Training loss: 0.06249307096004486
Validation loss: 1.5530140002568562

Epoch: 6| Step: 8
Training loss: 0.06981891393661499
Validation loss: 1.5850284202124483

Epoch: 6| Step: 9
Training loss: 0.10395859181880951
Validation loss: 1.5950098165901758

Epoch: 6| Step: 10
Training loss: 0.17873257398605347
Validation loss: 1.6162212920445267

Epoch: 6| Step: 11
Training loss: 0.12561839818954468
Validation loss: 1.632721516393846

Epoch: 6| Step: 12
Training loss: 0.11526478081941605
Validation loss: 1.6143306660395798

Epoch: 6| Step: 13
Training loss: 0.12350424379110336
Validation loss: 1.5817618152146697

Epoch: 669| Step: 0
Training loss: 0.03987351059913635
Validation loss: 1.5700533428499777

Epoch: 6| Step: 1
Training loss: 0.1091814637184143
Validation loss: 1.5499185016078334

Epoch: 6| Step: 2
Training loss: 0.07734404504299164
Validation loss: 1.5419688211974276

Epoch: 6| Step: 3
Training loss: 0.05439326539635658
Validation loss: 1.5169018109639485

Epoch: 6| Step: 4
Training loss: 0.06585514545440674
Validation loss: 1.5288849697318128

Epoch: 6| Step: 5
Training loss: 0.17815522849559784
Validation loss: 1.5770333325991066

Epoch: 6| Step: 6
Training loss: 0.06519126892089844
Validation loss: 1.5340589630988337

Epoch: 6| Step: 7
Training loss: 0.17676754295825958
Validation loss: 1.5497921128426828

Epoch: 6| Step: 8
Training loss: 0.06157109886407852
Validation loss: 1.5740214720849068

Epoch: 6| Step: 9
Training loss: 0.0455271415412426
Validation loss: 1.5449599796725857

Epoch: 6| Step: 10
Training loss: 0.11415305733680725
Validation loss: 1.5206182708022415

Epoch: 6| Step: 11
Training loss: 0.08406709134578705
Validation loss: 1.557951590066315

Epoch: 6| Step: 12
Training loss: 0.07674402743577957
Validation loss: 1.546550537950249

Epoch: 6| Step: 13
Training loss: 0.0741448849439621
Validation loss: 1.5338260473743561

Epoch: 670| Step: 0
Training loss: 0.06697796285152435
Validation loss: 1.5706424456770702

Epoch: 6| Step: 1
Training loss: 0.0857740044593811
Validation loss: 1.55609961799396

Epoch: 6| Step: 2
Training loss: 0.05237684026360512
Validation loss: 1.5540446427560621

Epoch: 6| Step: 3
Training loss: 0.07626283168792725
Validation loss: 1.544826143531389

Epoch: 6| Step: 4
Training loss: 0.05864705145359039
Validation loss: 1.5425477053529473

Epoch: 6| Step: 5
Training loss: 0.06406263262033463
Validation loss: 1.559157815030826

Epoch: 6| Step: 6
Training loss: 0.07980857789516449
Validation loss: 1.5331800573615617

Epoch: 6| Step: 7
Training loss: 0.06840075552463531
Validation loss: 1.538900811185119

Epoch: 6| Step: 8
Training loss: 0.09591834992170334
Validation loss: 1.5449771483739216

Epoch: 6| Step: 9
Training loss: 0.07938738167285919
Validation loss: 1.539781290997741

Epoch: 6| Step: 10
Training loss: 0.14721494913101196
Validation loss: 1.5482953145939817

Epoch: 6| Step: 11
Training loss: 0.10059770941734314
Validation loss: 1.5608069127605808

Epoch: 6| Step: 12
Training loss: 0.1114136129617691
Validation loss: 1.5620787592344387

Epoch: 6| Step: 13
Training loss: 0.08714098483324051
Validation loss: 1.5832539168737267

Epoch: 671| Step: 0
Training loss: 0.10277801007032394
Validation loss: 1.584332421261777

Epoch: 6| Step: 1
Training loss: 0.0714392215013504
Validation loss: 1.5787385439360013

Epoch: 6| Step: 2
Training loss: 0.0630011186003685
Validation loss: 1.5761308516225507

Epoch: 6| Step: 3
Training loss: 0.15823465585708618
Validation loss: 1.5649472731415943

Epoch: 6| Step: 4
Training loss: 0.09010045230388641
Validation loss: 1.5628528069424372

Epoch: 6| Step: 5
Training loss: 0.07725207507610321
Validation loss: 1.5614954604897449

Epoch: 6| Step: 6
Training loss: 0.1006203144788742
Validation loss: 1.574038274826542

Epoch: 6| Step: 7
Training loss: 0.13704384863376617
Validation loss: 1.5920312096995692

Epoch: 6| Step: 8
Training loss: 0.11562587320804596
Validation loss: 1.573371765434101

Epoch: 6| Step: 9
Training loss: 0.052599579095840454
Validation loss: 1.5950474213528376

Epoch: 6| Step: 10
Training loss: 0.11283697187900543
Validation loss: 1.593804068462823

Epoch: 6| Step: 11
Training loss: 0.11068187654018402
Validation loss: 1.5769058581321471

Epoch: 6| Step: 12
Training loss: 0.06478525698184967
Validation loss: 1.5598576568788098

Epoch: 6| Step: 13
Training loss: 0.06906601041555405
Validation loss: 1.566619292382271

Epoch: 672| Step: 0
Training loss: 0.11638277769088745
Validation loss: 1.5845274938050138

Epoch: 6| Step: 1
Training loss: 0.07431291043758392
Validation loss: 1.6052524376940984

Epoch: 6| Step: 2
Training loss: 0.1103212982416153
Validation loss: 1.5812410885287869

Epoch: 6| Step: 3
Training loss: 0.07174822688102722
Validation loss: 1.5856212005820325

Epoch: 6| Step: 4
Training loss: 0.08755459636449814
Validation loss: 1.5863558784607918

Epoch: 6| Step: 5
Training loss: 0.10203021764755249
Validation loss: 1.5836765727689188

Epoch: 6| Step: 6
Training loss: 0.06555444747209549
Validation loss: 1.5842583576838176

Epoch: 6| Step: 7
Training loss: 0.1390133798122406
Validation loss: 1.5726075736425256

Epoch: 6| Step: 8
Training loss: 0.09536006301641464
Validation loss: 1.5767761558614752

Epoch: 6| Step: 9
Training loss: 0.14775040745735168
Validation loss: 1.573192645144719

Epoch: 6| Step: 10
Training loss: 0.0599096454679966
Validation loss: 1.5655222182632775

Epoch: 6| Step: 11
Training loss: 0.05990254878997803
Validation loss: 1.5562107357927548

Epoch: 6| Step: 12
Training loss: 0.08582284301519394
Validation loss: 1.5594663978904806

Epoch: 6| Step: 13
Training loss: 0.08669483661651611
Validation loss: 1.536671708988887

Epoch: 673| Step: 0
Training loss: 0.06890733540058136
Validation loss: 1.5345894239282096

Epoch: 6| Step: 1
Training loss: 0.05403248965740204
Validation loss: 1.530082469345421

Epoch: 6| Step: 2
Training loss: 0.08045949041843414
Validation loss: 1.5588165175530218

Epoch: 6| Step: 3
Training loss: 0.055173199623823166
Validation loss: 1.5638308422539824

Epoch: 6| Step: 4
Training loss: 0.13024131953716278
Validation loss: 1.560365387188491

Epoch: 6| Step: 5
Training loss: 0.061021171510219574
Validation loss: 1.5468673680418281

Epoch: 6| Step: 6
Training loss: 0.1282733827829361
Validation loss: 1.562468398001886

Epoch: 6| Step: 7
Training loss: 0.09605288505554199
Validation loss: 1.5155516465504963

Epoch: 6| Step: 8
Training loss: 0.04408153146505356
Validation loss: 1.5329989925507577

Epoch: 6| Step: 9
Training loss: 0.08372033387422562
Validation loss: 1.5371827374222458

Epoch: 6| Step: 10
Training loss: 0.07098236680030823
Validation loss: 1.5306446244639735

Epoch: 6| Step: 11
Training loss: 0.1012493222951889
Validation loss: 1.5272398430814025

Epoch: 6| Step: 12
Training loss: 0.06388576328754425
Validation loss: 1.5287772115840708

Epoch: 6| Step: 13
Training loss: 0.03268654644489288
Validation loss: 1.54123560203019

Epoch: 674| Step: 0
Training loss: 0.05651523172855377
Validation loss: 1.5492972032998198

Epoch: 6| Step: 1
Training loss: 0.0803753137588501
Validation loss: 1.5415989211810532

Epoch: 6| Step: 2
Training loss: 0.06557906419038773
Validation loss: 1.564529784264103

Epoch: 6| Step: 3
Training loss: 0.05925207957625389
Validation loss: 1.5259082118670146

Epoch: 6| Step: 4
Training loss: 0.05489502474665642
Validation loss: 1.5260200192851405

Epoch: 6| Step: 5
Training loss: 0.09173949807882309
Validation loss: 1.5520893002069125

Epoch: 6| Step: 6
Training loss: 0.06341178715229034
Validation loss: 1.5543408316950644

Epoch: 6| Step: 7
Training loss: 0.07585849612951279
Validation loss: 1.5513292166494554

Epoch: 6| Step: 8
Training loss: 0.15856695175170898
Validation loss: 1.5640863282706148

Epoch: 6| Step: 9
Training loss: 0.11005156487226486
Validation loss: 1.5560936658613143

Epoch: 6| Step: 10
Training loss: 0.05795004963874817
Validation loss: 1.5703319811051892

Epoch: 6| Step: 11
Training loss: 0.08157636225223541
Validation loss: 1.5787845157807874

Epoch: 6| Step: 12
Training loss: 0.0529155433177948
Validation loss: 1.5575389708242109

Epoch: 6| Step: 13
Training loss: 0.06276646256446838
Validation loss: 1.5687949913804249

Epoch: 675| Step: 0
Training loss: 0.08499070256948471
Validation loss: 1.5739819926600302

Epoch: 6| Step: 1
Training loss: 0.04990163818001747
Validation loss: 1.613462516056594

Epoch: 6| Step: 2
Training loss: 0.04778211563825607
Validation loss: 1.6044325623460995

Epoch: 6| Step: 3
Training loss: 0.1020931676030159
Validation loss: 1.593802018832135

Epoch: 6| Step: 4
Training loss: 0.07853171974420547
Validation loss: 1.5963124857153943

Epoch: 6| Step: 5
Training loss: 0.08362673223018646
Validation loss: 1.6110617665834324

Epoch: 6| Step: 6
Training loss: 0.14778506755828857
Validation loss: 1.6111513337781351

Epoch: 6| Step: 7
Training loss: 0.07677322626113892
Validation loss: 1.59886226923235

Epoch: 6| Step: 8
Training loss: 0.09694569557905197
Validation loss: 1.596361675570088

Epoch: 6| Step: 9
Training loss: 0.07482864707708359
Validation loss: 1.5955428102964997

Epoch: 6| Step: 10
Training loss: 0.08809525519609451
Validation loss: 1.6002704687015985

Epoch: 6| Step: 11
Training loss: 0.10254152864217758
Validation loss: 1.5831795046406407

Epoch: 6| Step: 12
Training loss: 0.04680607467889786
Validation loss: 1.568961125548168

Epoch: 6| Step: 13
Training loss: 0.0807371661067009
Validation loss: 1.5664818222804735

Epoch: 676| Step: 0
Training loss: 0.07951323688030243
Validation loss: 1.5581359683826406

Epoch: 6| Step: 1
Training loss: 0.1489267796278
Validation loss: 1.5498899682875602

Epoch: 6| Step: 2
Training loss: 0.06206556037068367
Validation loss: 1.575643672738024

Epoch: 6| Step: 3
Training loss: 0.05678385868668556
Validation loss: 1.528632067864941

Epoch: 6| Step: 4
Training loss: 0.050935253500938416
Validation loss: 1.5527863015410721

Epoch: 6| Step: 5
Training loss: 0.11752444505691528
Validation loss: 1.5718374277955742

Epoch: 6| Step: 6
Training loss: 0.050776004791259766
Validation loss: 1.5485115922907347

Epoch: 6| Step: 7
Training loss: 0.0892525315284729
Validation loss: 1.5710918608532156

Epoch: 6| Step: 8
Training loss: 0.11753064393997192
Validation loss: 1.5394980253711823

Epoch: 6| Step: 9
Training loss: 0.06905696541070938
Validation loss: 1.5545378526051838

Epoch: 6| Step: 10
Training loss: 0.05433138087391853
Validation loss: 1.5480433010285901

Epoch: 6| Step: 11
Training loss: 0.061550118029117584
Validation loss: 1.5602445813917345

Epoch: 6| Step: 12
Training loss: 0.0940854623913765
Validation loss: 1.5495617466588174

Epoch: 6| Step: 13
Training loss: 0.09148912876844406
Validation loss: 1.5510264711995279

Epoch: 677| Step: 0
Training loss: 0.05832090973854065
Validation loss: 1.568448793503546

Epoch: 6| Step: 1
Training loss: 0.05676244571805
Validation loss: 1.5470573773948095

Epoch: 6| Step: 2
Training loss: 0.10519857704639435
Validation loss: 1.5686084993423954

Epoch: 6| Step: 3
Training loss: 0.04858122020959854
Validation loss: 1.5548578872475574

Epoch: 6| Step: 4
Training loss: 0.062075477093458176
Validation loss: 1.5589484796729138

Epoch: 6| Step: 5
Training loss: 0.15264539420604706
Validation loss: 1.5513972024763785

Epoch: 6| Step: 6
Training loss: 0.06102458015084267
Validation loss: 1.5768886458489202

Epoch: 6| Step: 7
Training loss: 0.08326602727174759
Validation loss: 1.5680215692007413

Epoch: 6| Step: 8
Training loss: 0.07559028267860413
Validation loss: 1.54830805588794

Epoch: 6| Step: 9
Training loss: 0.0796583741903305
Validation loss: 1.509050138535038

Epoch: 6| Step: 10
Training loss: 0.08383086323738098
Validation loss: 1.5401798819982877

Epoch: 6| Step: 11
Training loss: 0.05640440061688423
Validation loss: 1.5421814149425876

Epoch: 6| Step: 12
Training loss: 0.04190991073846817
Validation loss: 1.507423129132999

Epoch: 6| Step: 13
Training loss: 0.05838906764984131
Validation loss: 1.501395220397621

Epoch: 678| Step: 0
Training loss: 0.07128340005874634
Validation loss: 1.4875376442427277

Epoch: 6| Step: 1
Training loss: 0.037388622760772705
Validation loss: 1.5204919333099036

Epoch: 6| Step: 2
Training loss: 0.11680476367473602
Validation loss: 1.5253250432270828

Epoch: 6| Step: 3
Training loss: 0.05774671584367752
Validation loss: 1.5384593682904397

Epoch: 6| Step: 4
Training loss: 0.051890674978494644
Validation loss: 1.5579792004759594

Epoch: 6| Step: 5
Training loss: 0.10164321959018707
Validation loss: 1.5697384047251877

Epoch: 6| Step: 6
Training loss: 0.08161213994026184
Validation loss: 1.5593930675137428

Epoch: 6| Step: 7
Training loss: 0.06603862345218658
Validation loss: 1.5725887276793038

Epoch: 6| Step: 8
Training loss: 0.08325645327568054
Validation loss: 1.5772127105343727

Epoch: 6| Step: 9
Training loss: 0.06180056184530258
Validation loss: 1.5726875374394078

Epoch: 6| Step: 10
Training loss: 0.09510229527950287
Validation loss: 1.5916317227066203

Epoch: 6| Step: 11
Training loss: 0.06781173497438431
Validation loss: 1.5994239148273264

Epoch: 6| Step: 12
Training loss: 0.06594578921794891
Validation loss: 1.5675272005860523

Epoch: 6| Step: 13
Training loss: 0.05164597928524017
Validation loss: 1.581528050925142

Epoch: 679| Step: 0
Training loss: 0.13691926002502441
Validation loss: 1.5494536135786323

Epoch: 6| Step: 1
Training loss: 0.06277511268854141
Validation loss: 1.5674446487939486

Epoch: 6| Step: 2
Training loss: 0.04839678853750229
Validation loss: 1.5846660342267764

Epoch: 6| Step: 3
Training loss: 0.05823636054992676
Validation loss: 1.5721709061694402

Epoch: 6| Step: 4
Training loss: 0.09554863721132278
Validation loss: 1.570319846112241

Epoch: 6| Step: 5
Training loss: 0.11002827435731888
Validation loss: 1.5703950556375648

Epoch: 6| Step: 6
Training loss: 0.050845831632614136
Validation loss: 1.5836897614181682

Epoch: 6| Step: 7
Training loss: 0.032353661954402924
Validation loss: 1.52668680555077

Epoch: 6| Step: 8
Training loss: 0.11422770470380783
Validation loss: 1.5225192436607935

Epoch: 6| Step: 9
Training loss: 0.05260513722896576
Validation loss: 1.5245797557215537

Epoch: 6| Step: 10
Training loss: 0.06720569729804993
Validation loss: 1.533085992259364

Epoch: 6| Step: 11
Training loss: 0.12667913734912872
Validation loss: 1.535676040957051

Epoch: 6| Step: 12
Training loss: 0.11343178153038025
Validation loss: 1.5428946338674074

Epoch: 6| Step: 13
Training loss: 0.0688544511795044
Validation loss: 1.5681156445575017

Epoch: 680| Step: 0
Training loss: 0.06629148125648499
Validation loss: 1.5354252707573675

Epoch: 6| Step: 1
Training loss: 0.0687301754951477
Validation loss: 1.5846720498095277

Epoch: 6| Step: 2
Training loss: 0.05538567900657654
Validation loss: 1.5598258600440076

Epoch: 6| Step: 3
Training loss: 0.10148914903402328
Validation loss: 1.5801467882689608

Epoch: 6| Step: 4
Training loss: 0.06210845708847046
Validation loss: 1.5892198098603116

Epoch: 6| Step: 5
Training loss: 0.10514388233423233
Validation loss: 1.5609943507820048

Epoch: 6| Step: 6
Training loss: 0.09759356081485748
Validation loss: 1.5924237915264663

Epoch: 6| Step: 7
Training loss: 0.07045432180166245
Validation loss: 1.585919737815857

Epoch: 6| Step: 8
Training loss: 0.08307382464408875
Validation loss: 1.5651718544703659

Epoch: 6| Step: 9
Training loss: 0.0982445776462555
Validation loss: 1.5408647060394287

Epoch: 6| Step: 10
Training loss: 0.13846325874328613
Validation loss: 1.5254509090095438

Epoch: 6| Step: 11
Training loss: 0.03972138836979866
Validation loss: 1.5253671574336227

Epoch: 6| Step: 12
Training loss: 0.058807410299777985
Validation loss: 1.5181701516592374

Epoch: 6| Step: 13
Training loss: 0.08592433482408524
Validation loss: 1.5134763217741443

Epoch: 681| Step: 0
Training loss: 0.10778672993183136
Validation loss: 1.5300992945189118

Epoch: 6| Step: 1
Training loss: 0.0797027051448822
Validation loss: 1.517730592399515

Epoch: 6| Step: 2
Training loss: 0.10684924572706223
Validation loss: 1.5190662837797595

Epoch: 6| Step: 3
Training loss: 0.08729109913110733
Validation loss: 1.5079067061024327

Epoch: 6| Step: 4
Training loss: 0.06674981862306595
Validation loss: 1.5170639355977376

Epoch: 6| Step: 5
Training loss: 0.07619793713092804
Validation loss: 1.506174172124555

Epoch: 6| Step: 6
Training loss: 0.07926681637763977
Validation loss: 1.5464423209108331

Epoch: 6| Step: 7
Training loss: 0.09476535022258759
Validation loss: 1.574840614872594

Epoch: 6| Step: 8
Training loss: 0.15250296890735626
Validation loss: 1.583737680988927

Epoch: 6| Step: 9
Training loss: 0.08263647556304932
Validation loss: 1.5866300687995007

Epoch: 6| Step: 10
Training loss: 0.11555179953575134
Validation loss: 1.5807324891449304

Epoch: 6| Step: 11
Training loss: 0.07890485227108002
Validation loss: 1.6163056960669897

Epoch: 6| Step: 12
Training loss: 0.062395915389060974
Validation loss: 1.592230886541387

Epoch: 6| Step: 13
Training loss: 0.06746956706047058
Validation loss: 1.601742721373035

Epoch: 682| Step: 0
Training loss: 0.0782736986875534
Validation loss: 1.6167038115121986

Epoch: 6| Step: 1
Training loss: 0.11879917234182358
Validation loss: 1.629018242641162

Epoch: 6| Step: 2
Training loss: 0.18106898665428162
Validation loss: 1.6266152551097255

Epoch: 6| Step: 3
Training loss: 0.13220718502998352
Validation loss: 1.6386380336617912

Epoch: 6| Step: 4
Training loss: 0.0921320989727974
Validation loss: 1.6102768528846003

Epoch: 6| Step: 5
Training loss: 0.08653637766838074
Validation loss: 1.5997300763284006

Epoch: 6| Step: 6
Training loss: 0.06532061845064163
Validation loss: 1.5758652251253846

Epoch: 6| Step: 7
Training loss: 0.07864000648260117
Validation loss: 1.5797417753486223

Epoch: 6| Step: 8
Training loss: 0.04259861260652542
Validation loss: 1.5754482476942

Epoch: 6| Step: 9
Training loss: 0.05158045515418053
Validation loss: 1.571249577306932

Epoch: 6| Step: 10
Training loss: 0.11244972795248032
Validation loss: 1.5547756020740797

Epoch: 6| Step: 11
Training loss: 0.06381746381521225
Validation loss: 1.558994279112867

Epoch: 6| Step: 12
Training loss: 0.07444290071725845
Validation loss: 1.5653286134043047

Epoch: 6| Step: 13
Training loss: 0.06397707015275955
Validation loss: 1.5579769995904738

Epoch: 683| Step: 0
Training loss: 0.14408832788467407
Validation loss: 1.5406568101657334

Epoch: 6| Step: 1
Training loss: 0.042992003262043
Validation loss: 1.5637515206490793

Epoch: 6| Step: 2
Training loss: 0.08075588196516037
Validation loss: 1.5656062633760515

Epoch: 6| Step: 3
Training loss: 0.10496500134468079
Validation loss: 1.580237239919683

Epoch: 6| Step: 4
Training loss: 0.14971967041492462
Validation loss: 1.5688078864928214

Epoch: 6| Step: 5
Training loss: 0.11472814530134201
Validation loss: 1.530008904395565

Epoch: 6| Step: 6
Training loss: 0.07480625808238983
Validation loss: 1.5842474737474996

Epoch: 6| Step: 7
Training loss: 0.0939149335026741
Validation loss: 1.5380328483478998

Epoch: 6| Step: 8
Training loss: 0.061723046004772186
Validation loss: 1.568929761968633

Epoch: 6| Step: 9
Training loss: 0.04512327164411545
Validation loss: 1.5575141368373748

Epoch: 6| Step: 10
Training loss: 0.0720747858285904
Validation loss: 1.561764726074793

Epoch: 6| Step: 11
Training loss: 0.05811086669564247
Validation loss: 1.5887821118036907

Epoch: 6| Step: 12
Training loss: 0.09225913882255554
Validation loss: 1.5931765129489284

Epoch: 6| Step: 13
Training loss: 0.07395141571760178
Validation loss: 1.5947490071737638

Epoch: 684| Step: 0
Training loss: 0.10468445718288422
Validation loss: 1.6274786790211995

Epoch: 6| Step: 1
Training loss: 0.07196269184350967
Validation loss: 1.618311684618714

Epoch: 6| Step: 2
Training loss: 0.08331996947526932
Validation loss: 1.6433402684427076

Epoch: 6| Step: 3
Training loss: 0.18608054518699646
Validation loss: 1.63846666325805

Epoch: 6| Step: 4
Training loss: 0.1002291813492775
Validation loss: 1.6069155098289571

Epoch: 6| Step: 5
Training loss: 0.1023765578866005
Validation loss: 1.6081881753859981

Epoch: 6| Step: 6
Training loss: 0.06786013394594193
Validation loss: 1.5498390992482503

Epoch: 6| Step: 7
Training loss: 0.046257466077804565
Validation loss: 1.564569393793742

Epoch: 6| Step: 8
Training loss: 0.08268553018569946
Validation loss: 1.5755530749597857

Epoch: 6| Step: 9
Training loss: 0.11963938176631927
Validation loss: 1.5675088090281333

Epoch: 6| Step: 10
Training loss: 0.14923495054244995
Validation loss: 1.5753676795190381

Epoch: 6| Step: 11
Training loss: 0.14836683869361877
Validation loss: 1.5264569213313441

Epoch: 6| Step: 12
Training loss: 0.10581418871879578
Validation loss: 1.5469520861102688

Epoch: 6| Step: 13
Training loss: 0.10096994042396545
Validation loss: 1.5032677426133105

Epoch: 685| Step: 0
Training loss: 0.09042111039161682
Validation loss: 1.5412615935007732

Epoch: 6| Step: 1
Training loss: 0.1409265249967575
Validation loss: 1.544805980497791

Epoch: 6| Step: 2
Training loss: 0.0922892838716507
Validation loss: 1.57156531400578

Epoch: 6| Step: 3
Training loss: 0.11643549054861069
Validation loss: 1.56656232700553

Epoch: 6| Step: 4
Training loss: 0.10256142169237137
Validation loss: 1.577050962755757

Epoch: 6| Step: 5
Training loss: 0.04049510136246681
Validation loss: 1.5736784229996383

Epoch: 6| Step: 6
Training loss: 0.10246110707521439
Validation loss: 1.5590853357827792

Epoch: 6| Step: 7
Training loss: 0.17012342810630798
Validation loss: 1.56687476429888

Epoch: 6| Step: 8
Training loss: 0.13573835790157318
Validation loss: 1.6167430006047732

Epoch: 6| Step: 9
Training loss: 0.13878458738327026
Validation loss: 1.5394467371766285

Epoch: 6| Step: 10
Training loss: 0.07698749005794525
Validation loss: 1.5484356957097207

Epoch: 6| Step: 11
Training loss: 0.1671893447637558
Validation loss: 1.538620505281674

Epoch: 6| Step: 12
Training loss: 0.14695727825164795
Validation loss: 1.5116399001049738

Epoch: 6| Step: 13
Training loss: 0.04907603934407234
Validation loss: 1.5157637506402948

Epoch: 686| Step: 0
Training loss: 0.09093941003084183
Validation loss: 1.5571297708378042

Epoch: 6| Step: 1
Training loss: 0.07630525529384613
Validation loss: 1.545767335481541

Epoch: 6| Step: 2
Training loss: 0.1283400058746338
Validation loss: 1.546160706909754

Epoch: 6| Step: 3
Training loss: 0.11345358192920685
Validation loss: 1.548081882538334

Epoch: 6| Step: 4
Training loss: 0.13375674188137054
Validation loss: 1.5257106006786387

Epoch: 6| Step: 5
Training loss: 0.09492209553718567
Validation loss: 1.5380488941746373

Epoch: 6| Step: 6
Training loss: 0.0704609751701355
Validation loss: 1.5283351438019865

Epoch: 6| Step: 7
Training loss: 0.06587483733892441
Validation loss: 1.5385646166339997

Epoch: 6| Step: 8
Training loss: 0.08358462154865265
Validation loss: 1.5418749470864572

Epoch: 6| Step: 9
Training loss: 0.19404026865959167
Validation loss: 1.5424888262184717

Epoch: 6| Step: 10
Training loss: 0.08878013491630554
Validation loss: 1.5351238866006174

Epoch: 6| Step: 11
Training loss: 0.1054171547293663
Validation loss: 1.5476166702085925

Epoch: 6| Step: 12
Training loss: 0.07130061089992523
Validation loss: 1.550567312266237

Epoch: 6| Step: 13
Training loss: 0.1611192226409912
Validation loss: 1.5758653827892837

Epoch: 687| Step: 0
Training loss: 0.12990906834602356
Validation loss: 1.5506746589496572

Epoch: 6| Step: 1
Training loss: 0.0751199871301651
Validation loss: 1.532620899138912

Epoch: 6| Step: 2
Training loss: 0.0625581368803978
Validation loss: 1.5189071368145686

Epoch: 6| Step: 3
Training loss: 0.06321868300437927
Validation loss: 1.5473216733624857

Epoch: 6| Step: 4
Training loss: 0.15734615921974182
Validation loss: 1.524706362396158

Epoch: 6| Step: 5
Training loss: 0.05058228597044945
Validation loss: 1.5381909980568835

Epoch: 6| Step: 6
Training loss: 0.08689841628074646
Validation loss: 1.5511722545469961

Epoch: 6| Step: 7
Training loss: 0.08239038288593292
Validation loss: 1.5892629751595118

Epoch: 6| Step: 8
Training loss: 0.06474475562572479
Validation loss: 1.5492149347900062

Epoch: 6| Step: 9
Training loss: 0.04275190457701683
Validation loss: 1.5440391353381577

Epoch: 6| Step: 10
Training loss: 0.1011771410703659
Validation loss: 1.5527722604813115

Epoch: 6| Step: 11
Training loss: 0.13006293773651123
Validation loss: 1.5697769811076503

Epoch: 6| Step: 12
Training loss: 0.06164498254656792
Validation loss: 1.550322832599763

Epoch: 6| Step: 13
Training loss: 0.1011151596903801
Validation loss: 1.5578103244945567

Epoch: 688| Step: 0
Training loss: 0.08266140520572662
Validation loss: 1.5463303699288318

Epoch: 6| Step: 1
Training loss: 0.07446795701980591
Validation loss: 1.5309150706055343

Epoch: 6| Step: 2
Training loss: 0.04088739678263664
Validation loss: 1.5337329756829046

Epoch: 6| Step: 3
Training loss: 0.052471064031124115
Validation loss: 1.5450660554311608

Epoch: 6| Step: 4
Training loss: 0.09049122035503387
Validation loss: 1.5157452450003674

Epoch: 6| Step: 5
Training loss: 0.1484943926334381
Validation loss: 1.5295267412739415

Epoch: 6| Step: 6
Training loss: 0.1209002137184143
Validation loss: 1.5390226776881883

Epoch: 6| Step: 7
Training loss: 0.06869655102491379
Validation loss: 1.5217327174320017

Epoch: 6| Step: 8
Training loss: 0.10506691038608551
Validation loss: 1.5324112484532018

Epoch: 6| Step: 9
Training loss: 0.07847082614898682
Validation loss: 1.5496200720469158

Epoch: 6| Step: 10
Training loss: 0.161015123128891
Validation loss: 1.555470210249706

Epoch: 6| Step: 11
Training loss: 0.0631396546959877
Validation loss: 1.5270543950860218

Epoch: 6| Step: 12
Training loss: 0.08224353194236755
Validation loss: 1.5388595557981921

Epoch: 6| Step: 13
Training loss: 0.03540787845849991
Validation loss: 1.5483235120773315

Epoch: 689| Step: 0
Training loss: 0.06886801868677139
Validation loss: 1.5396587874299736

Epoch: 6| Step: 1
Training loss: 0.16003265976905823
Validation loss: 1.5426734429533764

Epoch: 6| Step: 2
Training loss: 0.04258696362376213
Validation loss: 1.5553062013400498

Epoch: 6| Step: 3
Training loss: 0.04649981111288071
Validation loss: 1.5454303615836686

Epoch: 6| Step: 4
Training loss: 0.09114222228527069
Validation loss: 1.5536737544562227

Epoch: 6| Step: 5
Training loss: 0.06734582781791687
Validation loss: 1.5547504642958283

Epoch: 6| Step: 6
Training loss: 0.09444057941436768
Validation loss: 1.5852708034617926

Epoch: 6| Step: 7
Training loss: 0.10759803652763367
Validation loss: 1.5699457148069977

Epoch: 6| Step: 8
Training loss: 0.08751269429922104
Validation loss: 1.5906774933620165

Epoch: 6| Step: 9
Training loss: 0.08093911409378052
Validation loss: 1.5669055369592482

Epoch: 6| Step: 10
Training loss: 0.07193919271230698
Validation loss: 1.555645719651253

Epoch: 6| Step: 11
Training loss: 0.06414134800434113
Validation loss: 1.5366561117992605

Epoch: 6| Step: 12
Training loss: 0.06440138071775436
Validation loss: 1.5413943003582697

Epoch: 6| Step: 13
Training loss: 0.03463499993085861
Validation loss: 1.5371526178493296

Epoch: 690| Step: 0
Training loss: 0.06696552783250809
Validation loss: 1.5426640638741114

Epoch: 6| Step: 1
Training loss: 0.034202855080366135
Validation loss: 1.5540900845681467

Epoch: 6| Step: 2
Training loss: 0.07823780179023743
Validation loss: 1.5485609090456398

Epoch: 6| Step: 3
Training loss: 0.07639406621456146
Validation loss: 1.5573512226022699

Epoch: 6| Step: 4
Training loss: 0.051254380494356155
Validation loss: 1.5541887437143633

Epoch: 6| Step: 5
Training loss: 0.0750962644815445
Validation loss: 1.5655192764856483

Epoch: 6| Step: 6
Training loss: 0.1346537470817566
Validation loss: 1.5581000889501264

Epoch: 6| Step: 7
Training loss: 0.14688684046268463
Validation loss: 1.5807024894222137

Epoch: 6| Step: 8
Training loss: 0.048390790820121765
Validation loss: 1.5588290768284951

Epoch: 6| Step: 9
Training loss: 0.05958961695432663
Validation loss: 1.5594232402822024

Epoch: 6| Step: 10
Training loss: 0.056504104286432266
Validation loss: 1.5510573002599901

Epoch: 6| Step: 11
Training loss: 0.07668766379356384
Validation loss: 1.5640098471795358

Epoch: 6| Step: 12
Training loss: 0.06449432671070099
Validation loss: 1.555554082316737

Epoch: 6| Step: 13
Training loss: 0.050286464393138885
Validation loss: 1.5696085601724603

Epoch: 691| Step: 0
Training loss: 0.07104343920946121
Validation loss: 1.5589293767047185

Epoch: 6| Step: 1
Training loss: 0.16241565346717834
Validation loss: 1.561355520320195

Epoch: 6| Step: 2
Training loss: 0.04968532919883728
Validation loss: 1.5472519679736065

Epoch: 6| Step: 3
Training loss: 0.07662138342857361
Validation loss: 1.565942754027664

Epoch: 6| Step: 4
Training loss: 0.067561075091362
Validation loss: 1.5808432435476651

Epoch: 6| Step: 5
Training loss: 0.04786199703812599
Validation loss: 1.5510163127735097

Epoch: 6| Step: 6
Training loss: 0.03486696258187294
Validation loss: 1.5647806608548729

Epoch: 6| Step: 7
Training loss: 0.05008310079574585
Validation loss: 1.5536922793234549

Epoch: 6| Step: 8
Training loss: 0.057399459183216095
Validation loss: 1.5592203332531838

Epoch: 6| Step: 9
Training loss: 0.07797965407371521
Validation loss: 1.5751579846105268

Epoch: 6| Step: 10
Training loss: 0.03470846638083458
Validation loss: 1.5557675464178926

Epoch: 6| Step: 11
Training loss: 0.04160313308238983
Validation loss: 1.5510941833578131

Epoch: 6| Step: 12
Training loss: 0.08627966046333313
Validation loss: 1.5339394230996408

Epoch: 6| Step: 13
Training loss: 0.03235604986548424
Validation loss: 1.5437995003115745

Epoch: 692| Step: 0
Training loss: 0.06188231706619263
Validation loss: 1.535754374278489

Epoch: 6| Step: 1
Training loss: 0.050330858677625656
Validation loss: 1.5006184924033381

Epoch: 6| Step: 2
Training loss: 0.05323860049247742
Validation loss: 1.5021595852349394

Epoch: 6| Step: 3
Training loss: 0.08862963318824768
Validation loss: 1.509370719232867

Epoch: 6| Step: 4
Training loss: 0.04596567898988724
Validation loss: 1.5228799312345442

Epoch: 6| Step: 5
Training loss: 0.0827505886554718
Validation loss: 1.5245573591160517

Epoch: 6| Step: 6
Training loss: 0.07126374542713165
Validation loss: 1.505082881578835

Epoch: 6| Step: 7
Training loss: 0.17150729894638062
Validation loss: 1.542821943119008

Epoch: 6| Step: 8
Training loss: 0.07963636517524719
Validation loss: 1.5337614590121853

Epoch: 6| Step: 9
Training loss: 0.07531623542308807
Validation loss: 1.5482780151469733

Epoch: 6| Step: 10
Training loss: 0.0486750602722168
Validation loss: 1.5323656021907766

Epoch: 6| Step: 11
Training loss: 0.09612713754177094
Validation loss: 1.5405944675527594

Epoch: 6| Step: 12
Training loss: 0.07675684988498688
Validation loss: 1.5371437944391722

Epoch: 6| Step: 13
Training loss: 0.06902620196342468
Validation loss: 1.5198106701656053

Epoch: 693| Step: 0
Training loss: 0.03653886914253235
Validation loss: 1.535472418672295

Epoch: 6| Step: 1
Training loss: 0.13132914900779724
Validation loss: 1.5693336981599049

Epoch: 6| Step: 2
Training loss: 0.07585933804512024
Validation loss: 1.5414946995755678

Epoch: 6| Step: 3
Training loss: 0.08702193200588226
Validation loss: 1.5864705577973397

Epoch: 6| Step: 4
Training loss: 0.10869253426790237
Validation loss: 1.5638531587457145

Epoch: 6| Step: 5
Training loss: 0.06598946452140808
Validation loss: 1.5553825337399718

Epoch: 6| Step: 6
Training loss: 0.06743593513965607
Validation loss: 1.5849935854634931

Epoch: 6| Step: 7
Training loss: 0.06913231313228607
Validation loss: 1.5623881099044636

Epoch: 6| Step: 8
Training loss: 0.047589611262083054
Validation loss: 1.5702880973457007

Epoch: 6| Step: 9
Training loss: 0.10667720437049866
Validation loss: 1.565269834251814

Epoch: 6| Step: 10
Training loss: 0.06879052519798279
Validation loss: 1.5903712446971605

Epoch: 6| Step: 11
Training loss: 0.05459047853946686
Validation loss: 1.5780997558306622

Epoch: 6| Step: 12
Training loss: 0.08157454431056976
Validation loss: 1.5797309285850936

Epoch: 6| Step: 13
Training loss: 0.0626612976193428
Validation loss: 1.605455716451009

Epoch: 694| Step: 0
Training loss: 0.03952387720346451
Validation loss: 1.5889807285801056

Epoch: 6| Step: 1
Training loss: 0.06300635635852814
Validation loss: 1.592207674057253

Epoch: 6| Step: 2
Training loss: 0.12730051577091217
Validation loss: 1.5858803692684378

Epoch: 6| Step: 3
Training loss: 0.06644712388515472
Validation loss: 1.5930419455292404

Epoch: 6| Step: 4
Training loss: 0.07295602560043335
Validation loss: 1.6215117400692356

Epoch: 6| Step: 5
Training loss: 0.04709624499082565
Validation loss: 1.6253603389186244

Epoch: 6| Step: 6
Training loss: 0.06725949048995972
Validation loss: 1.587793762965869

Epoch: 6| Step: 7
Training loss: 0.09821631014347076
Validation loss: 1.6206327702409478

Epoch: 6| Step: 8
Training loss: 0.0557413324713707
Validation loss: 1.6183352778034825

Epoch: 6| Step: 9
Training loss: 0.11946834623813629
Validation loss: 1.641894050823745

Epoch: 6| Step: 10
Training loss: 0.125117689371109
Validation loss: 1.6268377278440742

Epoch: 6| Step: 11
Training loss: 0.1299404501914978
Validation loss: 1.605865333029019

Epoch: 6| Step: 12
Training loss: 0.16295771300792694
Validation loss: 1.614632462942472

Epoch: 6| Step: 13
Training loss: 0.05850319564342499
Validation loss: 1.6061048276962773

Epoch: 695| Step: 0
Training loss: 0.10412920266389847
Validation loss: 1.568511966736086

Epoch: 6| Step: 1
Training loss: 0.09056545048952103
Validation loss: 1.5731971840704642

Epoch: 6| Step: 2
Training loss: 0.08962586522102356
Validation loss: 1.5617559109964678

Epoch: 6| Step: 3
Training loss: 0.11768147349357605
Validation loss: 1.5598459730866134

Epoch: 6| Step: 4
Training loss: 0.08511053025722504
Validation loss: 1.5433332779074227

Epoch: 6| Step: 5
Training loss: 0.14735469222068787
Validation loss: 1.532425695850003

Epoch: 6| Step: 6
Training loss: 0.06678120791912079
Validation loss: 1.5596312169105775

Epoch: 6| Step: 7
Training loss: 0.06263284385204315
Validation loss: 1.5583445487483856

Epoch: 6| Step: 8
Training loss: 0.058951485902071
Validation loss: 1.5381203710391957

Epoch: 6| Step: 9
Training loss: 0.06927478313446045
Validation loss: 1.5655956832311486

Epoch: 6| Step: 10
Training loss: 0.03454040735960007
Validation loss: 1.5809500499438214

Epoch: 6| Step: 11
Training loss: 0.063402459025383
Validation loss: 1.560022058025483

Epoch: 6| Step: 12
Training loss: 0.03228046000003815
Validation loss: 1.5916372588885728

Epoch: 6| Step: 13
Training loss: 0.08203407377004623
Validation loss: 1.5815793442469772

Epoch: 696| Step: 0
Training loss: 0.06369175016880035
Validation loss: 1.559122113771336

Epoch: 6| Step: 1
Training loss: 0.05609259009361267
Validation loss: 1.5677781425496584

Epoch: 6| Step: 2
Training loss: 0.04184897989034653
Validation loss: 1.5424179518094627

Epoch: 6| Step: 3
Training loss: 0.0992889553308487
Validation loss: 1.54690598159708

Epoch: 6| Step: 4
Training loss: 0.09100373089313507
Validation loss: 1.5553366394453152

Epoch: 6| Step: 5
Training loss: 0.07788794487714767
Validation loss: 1.518660476130824

Epoch: 6| Step: 6
Training loss: 0.14007988572120667
Validation loss: 1.5300086198314544

Epoch: 6| Step: 7
Training loss: 0.0597325935959816
Validation loss: 1.5523664079686648

Epoch: 6| Step: 8
Training loss: 0.06722638010978699
Validation loss: 1.518499316707734

Epoch: 6| Step: 9
Training loss: 0.04081270098686218
Validation loss: 1.5471587052909277

Epoch: 6| Step: 10
Training loss: 0.1370881199836731
Validation loss: 1.5268097718556721

Epoch: 6| Step: 11
Training loss: 0.04781555011868477
Validation loss: 1.5522925943456671

Epoch: 6| Step: 12
Training loss: 0.09657524526119232
Validation loss: 1.5534775295565206

Epoch: 6| Step: 13
Training loss: 0.08482703566551208
Validation loss: 1.5613802094613352

Epoch: 697| Step: 0
Training loss: 0.12369698286056519
Validation loss: 1.5684164800951559

Epoch: 6| Step: 1
Training loss: 0.06755804270505905
Validation loss: 1.5594558972184376

Epoch: 6| Step: 2
Training loss: 0.09355802834033966
Validation loss: 1.5375269805231402

Epoch: 6| Step: 3
Training loss: 0.061562638729810715
Validation loss: 1.5444523942086004

Epoch: 6| Step: 4
Training loss: 0.10378406941890717
Validation loss: 1.5776746362768195

Epoch: 6| Step: 5
Training loss: 0.12994451820850372
Validation loss: 1.5626390928863196

Epoch: 6| Step: 6
Training loss: 0.10077421367168427
Validation loss: 1.5496064334787347

Epoch: 6| Step: 7
Training loss: 0.07671937346458435
Validation loss: 1.581363577996531

Epoch: 6| Step: 8
Training loss: 0.03958923742175102
Validation loss: 1.5500900681300829

Epoch: 6| Step: 9
Training loss: 0.165568545460701
Validation loss: 1.5564826368003764

Epoch: 6| Step: 10
Training loss: 0.05407821759581566
Validation loss: 1.5587020932987172

Epoch: 6| Step: 11
Training loss: 0.04899456351995468
Validation loss: 1.5533637885124452

Epoch: 6| Step: 12
Training loss: 0.046581387519836426
Validation loss: 1.5293188864184963

Epoch: 6| Step: 13
Training loss: 0.07805465161800385
Validation loss: 1.512280624079448

Epoch: 698| Step: 0
Training loss: 0.05836467444896698
Validation loss: 1.547655100463539

Epoch: 6| Step: 1
Training loss: 0.054933562874794006
Validation loss: 1.5315843782117289

Epoch: 6| Step: 2
Training loss: 0.10123200714588165
Validation loss: 1.5101684075529858

Epoch: 6| Step: 3
Training loss: 0.07957267761230469
Validation loss: 1.540716972402347

Epoch: 6| Step: 4
Training loss: 0.07242309302091599
Validation loss: 1.52431091185539

Epoch: 6| Step: 5
Training loss: 0.05800884589552879
Validation loss: 1.5077021057887743

Epoch: 6| Step: 6
Training loss: 0.08928358554840088
Validation loss: 1.5378802181572042

Epoch: 6| Step: 7
Training loss: 0.07912975549697876
Validation loss: 1.5541134495888986

Epoch: 6| Step: 8
Training loss: 0.02894151210784912
Validation loss: 1.5662409086381235

Epoch: 6| Step: 9
Training loss: 0.03720635175704956
Validation loss: 1.5927287250436761

Epoch: 6| Step: 10
Training loss: 0.11905109137296677
Validation loss: 1.5767984697895665

Epoch: 6| Step: 11
Training loss: 0.12196993082761765
Validation loss: 1.6017513428964922

Epoch: 6| Step: 12
Training loss: 0.03613319247961044
Validation loss: 1.5981769356676327

Epoch: 6| Step: 13
Training loss: 0.08373551815748215
Validation loss: 1.597790277132424

Epoch: 699| Step: 0
Training loss: 0.06137652322649956
Validation loss: 1.5644277680304743

Epoch: 6| Step: 1
Training loss: 0.06150388717651367
Validation loss: 1.5683835578221146

Epoch: 6| Step: 2
Training loss: 0.07133708149194717
Validation loss: 1.5344821753040436

Epoch: 6| Step: 3
Training loss: 0.06058673560619354
Validation loss: 1.5593600888406076

Epoch: 6| Step: 4
Training loss: 0.028620868921279907
Validation loss: 1.5361456524941228

Epoch: 6| Step: 5
Training loss: 0.060607749968767166
Validation loss: 1.5660368229753228

Epoch: 6| Step: 6
Training loss: 0.058356475085020065
Validation loss: 1.5143860578536987

Epoch: 6| Step: 7
Training loss: 0.07831133157014847
Validation loss: 1.5119088913804741

Epoch: 6| Step: 8
Training loss: 0.07567182183265686
Validation loss: 1.5250652015850108

Epoch: 6| Step: 9
Training loss: 0.06667952984571457
Validation loss: 1.523155023974757

Epoch: 6| Step: 10
Training loss: 0.05713457241654396
Validation loss: 1.5560538268858386

Epoch: 6| Step: 11
Training loss: 0.16546690464019775
Validation loss: 1.552898342891406

Epoch: 6| Step: 12
Training loss: 0.10082682222127914
Validation loss: 1.5393395936617287

Epoch: 6| Step: 13
Training loss: 0.06106622889637947
Validation loss: 1.5448150275855936

Epoch: 700| Step: 0
Training loss: 0.03957769274711609
Validation loss: 1.5543779083477554

Epoch: 6| Step: 1
Training loss: 0.04101083055138588
Validation loss: 1.5391632856861237

Epoch: 6| Step: 2
Training loss: 0.07204429805278778
Validation loss: 1.5647022365241923

Epoch: 6| Step: 3
Training loss: 0.07634495198726654
Validation loss: 1.5557013557803245

Epoch: 6| Step: 4
Training loss: 0.1331917941570282
Validation loss: 1.5511040610651816

Epoch: 6| Step: 5
Training loss: 0.0893159955739975
Validation loss: 1.5447627254711684

Epoch: 6| Step: 6
Training loss: 0.06640520691871643
Validation loss: 1.5321474165044806

Epoch: 6| Step: 7
Training loss: 0.03656630218029022
Validation loss: 1.5560259511393886

Epoch: 6| Step: 8
Training loss: 0.07653219997882843
Validation loss: 1.561694937367593

Epoch: 6| Step: 9
Training loss: 0.1184082180261612
Validation loss: 1.5452846295090132

Epoch: 6| Step: 10
Training loss: 0.06736380606889725
Validation loss: 1.5463753240082854

Epoch: 6| Step: 11
Training loss: 0.06137688830494881
Validation loss: 1.5235830596698228

Epoch: 6| Step: 12
Training loss: 0.1530306041240692
Validation loss: 1.5293297113910798

Epoch: 6| Step: 13
Training loss: 0.08540495485067368
Validation loss: 1.5563444745156072

Epoch: 701| Step: 0
Training loss: 0.08037637919187546
Validation loss: 1.553429312603448

Epoch: 6| Step: 1
Training loss: 0.09224969148635864
Validation loss: 1.567484535196776

Epoch: 6| Step: 2
Training loss: 0.05594971776008606
Validation loss: 1.5462475784363285

Epoch: 6| Step: 3
Training loss: 0.07658050954341888
Validation loss: 1.533328830554921

Epoch: 6| Step: 4
Training loss: 0.048056166619062424
Validation loss: 1.5523895191889938

Epoch: 6| Step: 5
Training loss: 0.08853507041931152
Validation loss: 1.5438887547421198

Epoch: 6| Step: 6
Training loss: 0.14343269169330597
Validation loss: 1.5667916984968289

Epoch: 6| Step: 7
Training loss: 0.053202249109745026
Validation loss: 1.57546664309758

Epoch: 6| Step: 8
Training loss: 0.05041908845305443
Validation loss: 1.5779452593095842

Epoch: 6| Step: 9
Training loss: 0.07344961911439896
Validation loss: 1.5744662823215607

Epoch: 6| Step: 10
Training loss: 0.07707223296165466
Validation loss: 1.5563412981648599

Epoch: 6| Step: 11
Training loss: 0.04025954008102417
Validation loss: 1.580436207914865

Epoch: 6| Step: 12
Training loss: 0.11850687861442566
Validation loss: 1.5702182298065515

Epoch: 6| Step: 13
Training loss: 0.07188419252634048
Validation loss: 1.5669884656065254

Epoch: 702| Step: 0
Training loss: 0.1096590906381607
Validation loss: 1.5570412899858208

Epoch: 6| Step: 1
Training loss: 0.08926733583211899
Validation loss: 1.5733879112428235

Epoch: 6| Step: 2
Training loss: 0.055592283606529236
Validation loss: 1.5518132614833053

Epoch: 6| Step: 3
Training loss: 0.07014800608158112
Validation loss: 1.5846806777420865

Epoch: 6| Step: 4
Training loss: 0.06494157016277313
Validation loss: 1.5426936431597638

Epoch: 6| Step: 5
Training loss: 0.10884810984134674
Validation loss: 1.523057500521342

Epoch: 6| Step: 6
Training loss: 0.06780757009983063
Validation loss: 1.5313300099424136

Epoch: 6| Step: 7
Training loss: 0.09497220069169998
Validation loss: 1.5211721427979008

Epoch: 6| Step: 8
Training loss: 0.07166889309883118
Validation loss: 1.5266571326922345

Epoch: 6| Step: 9
Training loss: 0.044154539704322815
Validation loss: 1.5269933233978927

Epoch: 6| Step: 10
Training loss: 0.08741270005702972
Validation loss: 1.5004424561736405

Epoch: 6| Step: 11
Training loss: 0.04641641303896904
Validation loss: 1.5352750555161507

Epoch: 6| Step: 12
Training loss: 0.054425884038209915
Validation loss: 1.5192805086412737

Epoch: 6| Step: 13
Training loss: 0.09309639036655426
Validation loss: 1.5661683403035647

Epoch: 703| Step: 0
Training loss: 0.07025708258152008
Validation loss: 1.5310619518321047

Epoch: 6| Step: 1
Training loss: 0.07488952577114105
Validation loss: 1.5454936886346469

Epoch: 6| Step: 2
Training loss: 0.059461258351802826
Validation loss: 1.5741609001672396

Epoch: 6| Step: 3
Training loss: 0.12492422759532928
Validation loss: 1.5730393778893255

Epoch: 6| Step: 4
Training loss: 0.10814136266708374
Validation loss: 1.5632849559989026

Epoch: 6| Step: 5
Training loss: 0.07636609673500061
Validation loss: 1.5482948608295892

Epoch: 6| Step: 6
Training loss: 0.08684549480676651
Validation loss: 1.560532400684972

Epoch: 6| Step: 7
Training loss: 0.10619822144508362
Validation loss: 1.5542179807539909

Epoch: 6| Step: 8
Training loss: 0.06674406677484512
Validation loss: 1.5581829765791535

Epoch: 6| Step: 9
Training loss: 0.07690989226102829
Validation loss: 1.5800726888000325

Epoch: 6| Step: 10
Training loss: 0.05818880349397659
Validation loss: 1.5907671643841652

Epoch: 6| Step: 11
Training loss: 0.14583662152290344
Validation loss: 1.5858837481467956

Epoch: 6| Step: 12
Training loss: 0.08686737716197968
Validation loss: 1.5528883741747948

Epoch: 6| Step: 13
Training loss: 0.2543541491031647
Validation loss: 1.5333673813009774

Epoch: 704| Step: 0
Training loss: 0.1049412414431572
Validation loss: 1.5282151493974911

Epoch: 6| Step: 1
Training loss: 0.08478520810604095
Validation loss: 1.5388674473249784

Epoch: 6| Step: 2
Training loss: 0.10831480473279953
Validation loss: 1.5517251581274054

Epoch: 6| Step: 3
Training loss: 0.12565551698207855
Validation loss: 1.5856963780618483

Epoch: 6| Step: 4
Training loss: 0.35828930139541626
Validation loss: 1.6374739088037962

Epoch: 6| Step: 5
Training loss: 0.1035102978348732
Validation loss: 1.5576236953017533

Epoch: 6| Step: 6
Training loss: 0.2429324835538864
Validation loss: 1.5602498951778616

Epoch: 6| Step: 7
Training loss: 0.08945376425981522
Validation loss: 1.5237450586852206

Epoch: 6| Step: 8
Training loss: 0.05282704532146454
Validation loss: 1.5456862609873536

Epoch: 6| Step: 9
Training loss: 0.06165754050016403
Validation loss: 1.5430860211772304

Epoch: 6| Step: 10
Training loss: 0.11987228691577911
Validation loss: 1.610197231333743

Epoch: 6| Step: 11
Training loss: 0.08921180665493011
Validation loss: 1.5989317752981698

Epoch: 6| Step: 12
Training loss: 0.20897266268730164
Validation loss: 1.5797220673612369

Epoch: 6| Step: 13
Training loss: 0.05375721678137779
Validation loss: 1.572593423628038

Epoch: 705| Step: 0
Training loss: 0.14565938711166382
Validation loss: 1.5628213215899724

Epoch: 6| Step: 1
Training loss: 0.12444473803043365
Validation loss: 1.5500010392999137

Epoch: 6| Step: 2
Training loss: 0.142243891954422
Validation loss: 1.5295197233077018

Epoch: 6| Step: 3
Training loss: 0.08572366833686829
Validation loss: 1.5184448085805422

Epoch: 6| Step: 4
Training loss: 0.11901240050792694
Validation loss: 1.587777929921304

Epoch: 6| Step: 5
Training loss: 0.10460944473743439
Validation loss: 1.6086365279331003

Epoch: 6| Step: 6
Training loss: 0.13732212781906128
Validation loss: 1.657705448007071

Epoch: 6| Step: 7
Training loss: 0.0910101979970932
Validation loss: 1.6295830594596041

Epoch: 6| Step: 8
Training loss: 0.15341916680335999
Validation loss: 1.6112862504938597

Epoch: 6| Step: 9
Training loss: 0.07587927579879761
Validation loss: 1.5743276060268443

Epoch: 6| Step: 10
Training loss: 0.07214255630970001
Validation loss: 1.562397906857152

Epoch: 6| Step: 11
Training loss: 0.08995642513036728
Validation loss: 1.5818236361267746

Epoch: 6| Step: 12
Training loss: 0.10888311266899109
Validation loss: 1.6080559210110736

Epoch: 6| Step: 13
Training loss: 0.13229531049728394
Validation loss: 1.6189790066852365

Epoch: 706| Step: 0
Training loss: 0.17566971480846405
Validation loss: 1.6253219394273655

Epoch: 6| Step: 1
Training loss: 0.10710179805755615
Validation loss: 1.6125529030317902

Epoch: 6| Step: 2
Training loss: 0.09939861297607422
Validation loss: 1.6014684964251775

Epoch: 6| Step: 3
Training loss: 0.09451369941234589
Validation loss: 1.5734368037152033

Epoch: 6| Step: 4
Training loss: 0.09252829849720001
Validation loss: 1.5497763310709307

Epoch: 6| Step: 5
Training loss: 0.07553678005933762
Validation loss: 1.5651867992134505

Epoch: 6| Step: 6
Training loss: 0.05215395987033844
Validation loss: 1.5757698115482126

Epoch: 6| Step: 7
Training loss: 0.15436473488807678
Validation loss: 1.5456301807075419

Epoch: 6| Step: 8
Training loss: 0.11169730871915817
Validation loss: 1.5693822048043693

Epoch: 6| Step: 9
Training loss: 0.1162824034690857
Validation loss: 1.5734141693320325

Epoch: 6| Step: 10
Training loss: 0.08944804966449738
Validation loss: 1.5469008825158561

Epoch: 6| Step: 11
Training loss: 0.11626143753528595
Validation loss: 1.5568690940897951

Epoch: 6| Step: 12
Training loss: 0.09169131517410278
Validation loss: 1.5893118471227667

Epoch: 6| Step: 13
Training loss: 0.07073614001274109
Validation loss: 1.5742311246933476

Epoch: 707| Step: 0
Training loss: 0.09131285548210144
Validation loss: 1.5829664289310414

Epoch: 6| Step: 1
Training loss: 0.08534364402294159
Validation loss: 1.5601399835719858

Epoch: 6| Step: 2
Training loss: 0.033123038709163666
Validation loss: 1.5353178811329666

Epoch: 6| Step: 3
Training loss: 0.19902876019477844
Validation loss: 1.5485457092203119

Epoch: 6| Step: 4
Training loss: 0.11230700463056564
Validation loss: 1.533740326922427

Epoch: 6| Step: 5
Training loss: 0.11022858321666718
Validation loss: 1.5572630513098933

Epoch: 6| Step: 6
Training loss: 0.0835009217262268
Validation loss: 1.5863294127166911

Epoch: 6| Step: 7
Training loss: 0.1499558985233307
Validation loss: 1.5681611350787583

Epoch: 6| Step: 8
Training loss: 0.08957467973232269
Validation loss: 1.5556689744354577

Epoch: 6| Step: 9
Training loss: 0.06401151418685913
Validation loss: 1.5494678456296203

Epoch: 6| Step: 10
Training loss: 0.07581301033496857
Validation loss: 1.5422637039615261

Epoch: 6| Step: 11
Training loss: 0.1120830550789833
Validation loss: 1.5485790378303939

Epoch: 6| Step: 12
Training loss: 0.13651174306869507
Validation loss: 1.5551478914035264

Epoch: 6| Step: 13
Training loss: 0.06829676032066345
Validation loss: 1.5283031822532736

Epoch: 708| Step: 0
Training loss: 0.08690272271633148
Validation loss: 1.5512756006692046

Epoch: 6| Step: 1
Training loss: 0.0710536316037178
Validation loss: 1.5479309340958953

Epoch: 6| Step: 2
Training loss: 0.15937942266464233
Validation loss: 1.5491141811493905

Epoch: 6| Step: 3
Training loss: 0.06811626255512238
Validation loss: 1.5230934671176377

Epoch: 6| Step: 4
Training loss: 0.05340445041656494
Validation loss: 1.532826680009083

Epoch: 6| Step: 5
Training loss: 0.0435015968978405
Validation loss: 1.5395161951741865

Epoch: 6| Step: 6
Training loss: 0.04987256973981857
Validation loss: 1.5674721156397173

Epoch: 6| Step: 7
Training loss: 0.1015087366104126
Validation loss: 1.5767100267512824

Epoch: 6| Step: 8
Training loss: 0.05908151715993881
Validation loss: 1.5710580707878194

Epoch: 6| Step: 9
Training loss: 0.09492414444684982
Validation loss: 1.5517088879821122

Epoch: 6| Step: 10
Training loss: 0.06931102275848389
Validation loss: 1.5494985926535823

Epoch: 6| Step: 11
Training loss: 0.11759959161281586
Validation loss: 1.5695377267817014

Epoch: 6| Step: 12
Training loss: 0.08462009578943253
Validation loss: 1.5628442764282227

Epoch: 6| Step: 13
Training loss: 0.0803215280175209
Validation loss: 1.566504966828131

Epoch: 709| Step: 0
Training loss: 0.10739052295684814
Validation loss: 1.5552374650073308

Epoch: 6| Step: 1
Training loss: 0.0743308961391449
Validation loss: 1.5690101936299314

Epoch: 6| Step: 2
Training loss: 0.08446070551872253
Validation loss: 1.5787703478208153

Epoch: 6| Step: 3
Training loss: 0.10063708573579788
Validation loss: 1.5664053924622074

Epoch: 6| Step: 4
Training loss: 0.05448625236749649
Validation loss: 1.5749752854788175

Epoch: 6| Step: 5
Training loss: 0.14178124070167542
Validation loss: 1.5477091112444479

Epoch: 6| Step: 6
Training loss: 0.08793476223945618
Validation loss: 1.5436947076551375

Epoch: 6| Step: 7
Training loss: 0.09516417980194092
Validation loss: 1.5795042873710714

Epoch: 6| Step: 8
Training loss: 0.0744735598564148
Validation loss: 1.5782367478134811

Epoch: 6| Step: 9
Training loss: 0.0902094617486
Validation loss: 1.5912522551833943

Epoch: 6| Step: 10
Training loss: 0.0792936235666275
Validation loss: 1.6121708321314987

Epoch: 6| Step: 11
Training loss: 0.053903259336948395
Validation loss: 1.583823037403886

Epoch: 6| Step: 12
Training loss: 0.095828115940094
Validation loss: 1.593025856120612

Epoch: 6| Step: 13
Training loss: 0.10890673100948334
Validation loss: 1.596796775376925

Epoch: 710| Step: 0
Training loss: 0.15081603825092316
Validation loss: 1.6029947521866008

Epoch: 6| Step: 1
Training loss: 0.09262215346097946
Validation loss: 1.5819163630085606

Epoch: 6| Step: 2
Training loss: 0.05309411138296127
Validation loss: 1.5714952945709229

Epoch: 6| Step: 3
Training loss: 0.09615209698677063
Validation loss: 1.536489309803132

Epoch: 6| Step: 4
Training loss: 0.056396178901195526
Validation loss: 1.5360707544511365

Epoch: 6| Step: 5
Training loss: 0.07379571348428726
Validation loss: 1.550517080932535

Epoch: 6| Step: 6
Training loss: 0.07158087193965912
Validation loss: 1.5376359185864847

Epoch: 6| Step: 7
Training loss: 0.08794599026441574
Validation loss: 1.5456810048831406

Epoch: 6| Step: 8
Training loss: 0.08728745579719543
Validation loss: 1.538131299839225

Epoch: 6| Step: 9
Training loss: 0.14161202311515808
Validation loss: 1.5301933314210625

Epoch: 6| Step: 10
Training loss: 0.12937450408935547
Validation loss: 1.5494613788461173

Epoch: 6| Step: 11
Training loss: 0.05747735872864723
Validation loss: 1.5153028682995868

Epoch: 6| Step: 12
Training loss: 0.07025264948606491
Validation loss: 1.5162809401430108

Epoch: 6| Step: 13
Training loss: 0.052797768265008926
Validation loss: 1.5243581559068413

Epoch: 711| Step: 0
Training loss: 0.06316310167312622
Validation loss: 1.489738796346931

Epoch: 6| Step: 1
Training loss: 0.14339841902256012
Validation loss: 1.4874573407634613

Epoch: 6| Step: 2
Training loss: 0.07847084105014801
Validation loss: 1.5032676407085952

Epoch: 6| Step: 3
Training loss: 0.10690603405237198
Validation loss: 1.5262636407729118

Epoch: 6| Step: 4
Training loss: 0.10080396384000778
Validation loss: 1.5217329827688073

Epoch: 6| Step: 5
Training loss: 0.0847158133983612
Validation loss: 1.5515080523747269

Epoch: 6| Step: 6
Training loss: 0.11526571214199066
Validation loss: 1.5527533946498748

Epoch: 6| Step: 7
Training loss: 0.046038635075092316
Validation loss: 1.5117328871962845

Epoch: 6| Step: 8
Training loss: 0.06380148231983185
Validation loss: 1.5483562574591687

Epoch: 6| Step: 9
Training loss: 0.04318217933177948
Validation loss: 1.5213590514275335

Epoch: 6| Step: 10
Training loss: 0.10740025341510773
Validation loss: 1.5184442074068132

Epoch: 6| Step: 11
Training loss: 0.05468467250466347
Validation loss: 1.5389196718892744

Epoch: 6| Step: 12
Training loss: 0.106218621134758
Validation loss: 1.5572080689091836

Epoch: 6| Step: 13
Training loss: 0.06888137757778168
Validation loss: 1.537473190215326

Epoch: 712| Step: 0
Training loss: 0.11115557700395584
Validation loss: 1.5513032405607161

Epoch: 6| Step: 1
Training loss: 0.08114620298147202
Validation loss: 1.5670673962562316

Epoch: 6| Step: 2
Training loss: 0.06230868399143219
Validation loss: 1.5671116959664129

Epoch: 6| Step: 3
Training loss: 0.14568671584129333
Validation loss: 1.5652575403131463

Epoch: 6| Step: 4
Training loss: 0.06557223200798035
Validation loss: 1.5553958415985107

Epoch: 6| Step: 5
Training loss: 0.088763527572155
Validation loss: 1.5534763079817577

Epoch: 6| Step: 6
Training loss: 0.08839397132396698
Validation loss: 1.583946447218618

Epoch: 6| Step: 7
Training loss: 0.09679988026618958
Validation loss: 1.5745574120552308

Epoch: 6| Step: 8
Training loss: 0.09118187427520752
Validation loss: 1.5871044474263345

Epoch: 6| Step: 9
Training loss: 0.038177311420440674
Validation loss: 1.5627305020568192

Epoch: 6| Step: 10
Training loss: 0.12093202769756317
Validation loss: 1.5450228580864527

Epoch: 6| Step: 11
Training loss: 0.06752612441778183
Validation loss: 1.54676563765413

Epoch: 6| Step: 12
Training loss: 0.059570394456386566
Validation loss: 1.5420266620574459

Epoch: 6| Step: 13
Training loss: 0.09336187690496445
Validation loss: 1.5183050113339578

Epoch: 713| Step: 0
Training loss: 0.06983374059200287
Validation loss: 1.5162321367571432

Epoch: 6| Step: 1
Training loss: 0.04748762026429176
Validation loss: 1.5270902238866335

Epoch: 6| Step: 2
Training loss: 0.10349223017692566
Validation loss: 1.5190621370910316

Epoch: 6| Step: 3
Training loss: 0.08131122589111328
Validation loss: 1.5151910358859646

Epoch: 6| Step: 4
Training loss: 0.05492619425058365
Validation loss: 1.523268500963847

Epoch: 6| Step: 5
Training loss: 0.04033995419740677
Validation loss: 1.5484427611033122

Epoch: 6| Step: 6
Training loss: 0.14815475046634674
Validation loss: 1.528182371970146

Epoch: 6| Step: 7
Training loss: 0.07469998300075531
Validation loss: 1.543061110281175

Epoch: 6| Step: 8
Training loss: 0.059781670570373535
Validation loss: 1.534065083790851

Epoch: 6| Step: 9
Training loss: 0.0804477110505104
Validation loss: 1.5283268805473083

Epoch: 6| Step: 10
Training loss: 0.10141357779502869
Validation loss: 1.5354692346306258

Epoch: 6| Step: 11
Training loss: 0.03210407495498657
Validation loss: 1.5187391497755562

Epoch: 6| Step: 12
Training loss: 0.07285109162330627
Validation loss: 1.5535594942749187

Epoch: 6| Step: 13
Training loss: 0.0665411651134491
Validation loss: 1.5471204185998568

Epoch: 714| Step: 0
Training loss: 0.07313811779022217
Validation loss: 1.5354514045100058

Epoch: 6| Step: 1
Training loss: 0.14373916387557983
Validation loss: 1.5591407181114278

Epoch: 6| Step: 2
Training loss: 0.14423781633377075
Validation loss: 1.5792641780709709

Epoch: 6| Step: 3
Training loss: 0.08457386493682861
Validation loss: 1.5751131888358825

Epoch: 6| Step: 4
Training loss: 0.10430184006690979
Validation loss: 1.5701946622581893

Epoch: 6| Step: 5
Training loss: 0.06458646804094315
Validation loss: 1.5750821598114506

Epoch: 6| Step: 6
Training loss: 0.05149669945240021
Validation loss: 1.5798642096980926

Epoch: 6| Step: 7
Training loss: 0.11876029521226883
Validation loss: 1.597931973395809

Epoch: 6| Step: 8
Training loss: 0.08861206471920013
Validation loss: 1.5759355611698602

Epoch: 6| Step: 9
Training loss: 0.0785624086856842
Validation loss: 1.5560012055981545

Epoch: 6| Step: 10
Training loss: 0.06902427971363068
Validation loss: 1.5674823586658766

Epoch: 6| Step: 11
Training loss: 0.07095242291688919
Validation loss: 1.5499736903816141

Epoch: 6| Step: 12
Training loss: 0.10108808428049088
Validation loss: 1.5510283208662463

Epoch: 6| Step: 13
Training loss: 0.06432762742042542
Validation loss: 1.5155984458102976

Epoch: 715| Step: 0
Training loss: 0.07181030511856079
Validation loss: 1.5110312572089575

Epoch: 6| Step: 1
Training loss: 0.12073028832674026
Validation loss: 1.5216819470928562

Epoch: 6| Step: 2
Training loss: 0.07244302332401276
Validation loss: 1.5294894185117496

Epoch: 6| Step: 3
Training loss: 0.06164674460887909
Validation loss: 1.5268975175837034

Epoch: 6| Step: 4
Training loss: 0.12825468182563782
Validation loss: 1.5227583441683041

Epoch: 6| Step: 5
Training loss: 0.05508846789598465
Validation loss: 1.5230040992459943

Epoch: 6| Step: 6
Training loss: 0.15883779525756836
Validation loss: 1.5681163777587235

Epoch: 6| Step: 7
Training loss: 0.062306959182024
Validation loss: 1.5884930600402176

Epoch: 6| Step: 8
Training loss: 0.05182689055800438
Validation loss: 1.5852064586454822

Epoch: 6| Step: 9
Training loss: 0.08719146251678467
Validation loss: 1.6296430633914085

Epoch: 6| Step: 10
Training loss: 0.05295225977897644
Validation loss: 1.5749952011210944

Epoch: 6| Step: 11
Training loss: 0.05167144536972046
Validation loss: 1.5639921478045884

Epoch: 6| Step: 12
Training loss: 0.06452584266662598
Validation loss: 1.5633116806707075

Epoch: 6| Step: 13
Training loss: 0.035834748297929764
Validation loss: 1.5773910963407127

Epoch: 716| Step: 0
Training loss: 0.15236830711364746
Validation loss: 1.5364860027067122

Epoch: 6| Step: 1
Training loss: 0.054320745170116425
Validation loss: 1.5560654952961912

Epoch: 6| Step: 2
Training loss: 0.06668636202812195
Validation loss: 1.5520546244036766

Epoch: 6| Step: 3
Training loss: 0.1097618043422699
Validation loss: 1.5575086737191806

Epoch: 6| Step: 4
Training loss: 0.07936300337314606
Validation loss: 1.53608323425375

Epoch: 6| Step: 5
Training loss: 0.06605829298496246
Validation loss: 1.5342077491103963

Epoch: 6| Step: 6
Training loss: 0.05613163486123085
Validation loss: 1.533205775804417

Epoch: 6| Step: 7
Training loss: 0.08443659543991089
Validation loss: 1.5433580747214697

Epoch: 6| Step: 8
Training loss: 0.1687530130147934
Validation loss: 1.5518044284594956

Epoch: 6| Step: 9
Training loss: 0.08898642659187317
Validation loss: 1.5845560899344824

Epoch: 6| Step: 10
Training loss: 0.1680782437324524
Validation loss: 1.570148141153397

Epoch: 6| Step: 11
Training loss: 0.11287501454353333
Validation loss: 1.5668012121672272

Epoch: 6| Step: 12
Training loss: 0.06518560647964478
Validation loss: 1.5538074611335673

Epoch: 6| Step: 13
Training loss: 0.06681562960147858
Validation loss: 1.5696729844616306

Epoch: 717| Step: 0
Training loss: 0.08372890949249268
Validation loss: 1.5743490021715882

Epoch: 6| Step: 1
Training loss: 0.10261736065149307
Validation loss: 1.6030439689595213

Epoch: 6| Step: 2
Training loss: 0.1526208221912384
Validation loss: 1.5874899125868274

Epoch: 6| Step: 3
Training loss: 0.14068147540092468
Validation loss: 1.5854261434206398

Epoch: 6| Step: 4
Training loss: 0.06359080225229263
Validation loss: 1.5785783272917553

Epoch: 6| Step: 5
Training loss: 0.07792271673679352
Validation loss: 1.553955162725141

Epoch: 6| Step: 6
Training loss: 0.07171623408794403
Validation loss: 1.5736707282322708

Epoch: 6| Step: 7
Training loss: 0.14434590935707092
Validation loss: 1.555272384356427

Epoch: 6| Step: 8
Training loss: 0.0817008912563324
Validation loss: 1.5522665003294587

Epoch: 6| Step: 9
Training loss: 0.06266934424638748
Validation loss: 1.5648895284181

Epoch: 6| Step: 10
Training loss: 0.07927273213863373
Validation loss: 1.558706445078696

Epoch: 6| Step: 11
Training loss: 0.11956273019313812
Validation loss: 1.5430677808741087

Epoch: 6| Step: 12
Training loss: 0.07670488208532333
Validation loss: 1.5433935529442244

Epoch: 6| Step: 13
Training loss: 0.0664094015955925
Validation loss: 1.5533941163811633

Epoch: 718| Step: 0
Training loss: 0.13971289992332458
Validation loss: 1.5302077480541763

Epoch: 6| Step: 1
Training loss: 0.05109049007296562
Validation loss: 1.536181080725885

Epoch: 6| Step: 2
Training loss: 0.035069309175014496
Validation loss: 1.4978202555769233

Epoch: 6| Step: 3
Training loss: 0.06580221652984619
Validation loss: 1.5127791999488749

Epoch: 6| Step: 4
Training loss: 0.09716687351465225
Validation loss: 1.4916448003502303

Epoch: 6| Step: 5
Training loss: 0.11213172972202301
Validation loss: 1.5058886492124168

Epoch: 6| Step: 6
Training loss: 0.10639332234859467
Validation loss: 1.5050784426350747

Epoch: 6| Step: 7
Training loss: 0.09834998100996017
Validation loss: 1.5090066309898131

Epoch: 6| Step: 8
Training loss: 0.05747690796852112
Validation loss: 1.4939317369973788

Epoch: 6| Step: 9
Training loss: 0.1367301642894745
Validation loss: 1.4821613777068354

Epoch: 6| Step: 10
Training loss: 0.07828972488641739
Validation loss: 1.4973846353510374

Epoch: 6| Step: 11
Training loss: 0.05107145011425018
Validation loss: 1.5344127378156107

Epoch: 6| Step: 12
Training loss: 0.06631751358509064
Validation loss: 1.5125228551126295

Epoch: 6| Step: 13
Training loss: 0.0811532586812973
Validation loss: 1.5247739835452008

Epoch: 719| Step: 0
Training loss: 0.034476056694984436
Validation loss: 1.5264243643770936

Epoch: 6| Step: 1
Training loss: 0.0938953310251236
Validation loss: 1.5579023092023787

Epoch: 6| Step: 2
Training loss: 0.0720265656709671
Validation loss: 1.5571412642796834

Epoch: 6| Step: 3
Training loss: 0.05097369849681854
Validation loss: 1.561851518128508

Epoch: 6| Step: 4
Training loss: 0.08916822075843811
Validation loss: 1.5630141894022624

Epoch: 6| Step: 5
Training loss: 0.056231364607810974
Validation loss: 1.5512279425897906

Epoch: 6| Step: 6
Training loss: 0.05761157348752022
Validation loss: 1.540676660435174

Epoch: 6| Step: 7
Training loss: 0.05630137771368027
Validation loss: 1.5383502129585511

Epoch: 6| Step: 8
Training loss: 0.06542922556400299
Validation loss: 1.5580571441240207

Epoch: 6| Step: 9
Training loss: 0.08459828794002533
Validation loss: 1.5516742121788762

Epoch: 6| Step: 10
Training loss: 0.11589828878641129
Validation loss: 1.5360523475113737

Epoch: 6| Step: 11
Training loss: 0.07726042717695236
Validation loss: 1.5238096585837744

Epoch: 6| Step: 12
Training loss: 0.14268279075622559
Validation loss: 1.5219885854310886

Epoch: 6| Step: 13
Training loss: 0.09160742163658142
Validation loss: 1.5001420000548005

Epoch: 720| Step: 0
Training loss: 0.06086500734090805
Validation loss: 1.5314370714208132

Epoch: 6| Step: 1
Training loss: 0.06824418157339096
Validation loss: 1.5158763060005762

Epoch: 6| Step: 2
Training loss: 0.07328853756189346
Validation loss: 1.5461156086255146

Epoch: 6| Step: 3
Training loss: 0.07732737064361572
Validation loss: 1.527418921070714

Epoch: 6| Step: 4
Training loss: 0.04848514497280121
Validation loss: 1.507294774055481

Epoch: 6| Step: 5
Training loss: 0.050349704921245575
Validation loss: 1.5171385939403246

Epoch: 6| Step: 6
Training loss: 0.06400932371616364
Validation loss: 1.5456044532919442

Epoch: 6| Step: 7
Training loss: 0.13105429708957672
Validation loss: 1.528021312529041

Epoch: 6| Step: 8
Training loss: 0.11358100920915604
Validation loss: 1.5423990846962057

Epoch: 6| Step: 9
Training loss: 0.09312582015991211
Validation loss: 1.5654097859577467

Epoch: 6| Step: 10
Training loss: 0.06241145730018616
Validation loss: 1.5506456462285851

Epoch: 6| Step: 11
Training loss: 0.06530555337667465
Validation loss: 1.5400902327670847

Epoch: 6| Step: 12
Training loss: 0.05384211987257004
Validation loss: 1.5450603305011668

Epoch: 6| Step: 13
Training loss: 0.05835447087883949
Validation loss: 1.5562341815681868

Epoch: 721| Step: 0
Training loss: 0.05996860936284065
Validation loss: 1.511128294852472

Epoch: 6| Step: 1
Training loss: 0.05189794301986694
Validation loss: 1.5124445756276448

Epoch: 6| Step: 2
Training loss: 0.04150082543492317
Validation loss: 1.5119799798534763

Epoch: 6| Step: 3
Training loss: 0.04440313205122948
Validation loss: 1.5149529300710207

Epoch: 6| Step: 4
Training loss: 0.06662750989198685
Validation loss: 1.517420772583254

Epoch: 6| Step: 5
Training loss: 0.055236008018255234
Validation loss: 1.4976437066190986

Epoch: 6| Step: 6
Training loss: 0.12583333253860474
Validation loss: 1.4967626512691539

Epoch: 6| Step: 7
Training loss: 0.14707423746585846
Validation loss: 1.506321217424126

Epoch: 6| Step: 8
Training loss: 0.09843370318412781
Validation loss: 1.5232954884088168

Epoch: 6| Step: 9
Training loss: 0.04520082473754883
Validation loss: 1.525989177406475

Epoch: 6| Step: 10
Training loss: 0.07453159987926483
Validation loss: 1.5340508113625229

Epoch: 6| Step: 11
Training loss: 0.03912944719195366
Validation loss: 1.5287517886007986

Epoch: 6| Step: 12
Training loss: 0.07770676910877228
Validation loss: 1.5395439286385812

Epoch: 6| Step: 13
Training loss: 0.05534777045249939
Validation loss: 1.5331474452890375

Epoch: 722| Step: 0
Training loss: 0.12379682064056396
Validation loss: 1.5389939508130472

Epoch: 6| Step: 1
Training loss: 0.04705812409520149
Validation loss: 1.5294988463001866

Epoch: 6| Step: 2
Training loss: 0.059144310653209686
Validation loss: 1.5380444321581113

Epoch: 6| Step: 3
Training loss: 0.10753373801708221
Validation loss: 1.5344717400048369

Epoch: 6| Step: 4
Training loss: 0.044138118624687195
Validation loss: 1.5560485329679263

Epoch: 6| Step: 5
Training loss: 0.08888643980026245
Validation loss: 1.5507148542711813

Epoch: 6| Step: 6
Training loss: 0.061928294599056244
Validation loss: 1.5347684814083962

Epoch: 6| Step: 7
Training loss: 0.06973328441381454
Validation loss: 1.528755763525604

Epoch: 6| Step: 8
Training loss: 0.06365124881267548
Validation loss: 1.529358668993878

Epoch: 6| Step: 9
Training loss: 0.05747893452644348
Validation loss: 1.5190960386747956

Epoch: 6| Step: 10
Training loss: 0.050970710813999176
Validation loss: 1.528075110527777

Epoch: 6| Step: 11
Training loss: 0.05691123381257057
Validation loss: 1.5444684746444866

Epoch: 6| Step: 12
Training loss: 0.04623030126094818
Validation loss: 1.5492527100347704

Epoch: 6| Step: 13
Training loss: 0.10309566557407379
Validation loss: 1.5318544955663784

Epoch: 723| Step: 0
Training loss: 0.0505644790828228
Validation loss: 1.5418761430248138

Epoch: 6| Step: 1
Training loss: 0.06577330827713013
Validation loss: 1.5328675905863445

Epoch: 6| Step: 2
Training loss: 0.08551659435033798
Validation loss: 1.53634125186551

Epoch: 6| Step: 3
Training loss: 0.040870100259780884
Validation loss: 1.5325948435773131

Epoch: 6| Step: 4
Training loss: 0.06602799147367477
Validation loss: 1.534775698056785

Epoch: 6| Step: 5
Training loss: 0.05755990743637085
Validation loss: 1.5220813244901679

Epoch: 6| Step: 6
Training loss: 0.051959749311208725
Validation loss: 1.507356660340422

Epoch: 6| Step: 7
Training loss: 0.10727202892303467
Validation loss: 1.5116276356481737

Epoch: 6| Step: 8
Training loss: 0.05416114628314972
Validation loss: 1.509703731024137

Epoch: 6| Step: 9
Training loss: 0.08390937745571136
Validation loss: 1.50858748087319

Epoch: 6| Step: 10
Training loss: 0.14268162846565247
Validation loss: 1.5194355544223581

Epoch: 6| Step: 11
Training loss: 0.09196840226650238
Validation loss: 1.5209336896096506

Epoch: 6| Step: 12
Training loss: 0.09242914617061615
Validation loss: 1.5546121533199022

Epoch: 6| Step: 13
Training loss: 0.07466201484203339
Validation loss: 1.5642414093017578

Epoch: 724| Step: 0
Training loss: 0.08640599250793457
Validation loss: 1.5573276781266736

Epoch: 6| Step: 1
Training loss: 0.14510613679885864
Validation loss: 1.5768501245847313

Epoch: 6| Step: 2
Training loss: 0.08792021870613098
Validation loss: 1.570584495862325

Epoch: 6| Step: 3
Training loss: 0.07347772270441055
Validation loss: 1.582609877791456

Epoch: 6| Step: 4
Training loss: 0.055991608649492264
Validation loss: 1.5684114028048772

Epoch: 6| Step: 5
Training loss: 0.03710990771651268
Validation loss: 1.537596239838549

Epoch: 6| Step: 6
Training loss: 0.0648917555809021
Validation loss: 1.5312142474676973

Epoch: 6| Step: 7
Training loss: 0.0754719227552414
Validation loss: 1.556882510903061

Epoch: 6| Step: 8
Training loss: 0.05616065859794617
Validation loss: 1.5315558871915262

Epoch: 6| Step: 9
Training loss: 0.06485994160175323
Validation loss: 1.5062917970841931

Epoch: 6| Step: 10
Training loss: 0.0470341295003891
Validation loss: 1.5210034090985534

Epoch: 6| Step: 11
Training loss: 0.06065881624817848
Validation loss: 1.520780747936618

Epoch: 6| Step: 12
Training loss: 0.08214759826660156
Validation loss: 1.5226290277255479

Epoch: 6| Step: 13
Training loss: 0.08553288877010345
Validation loss: 1.5180407627936332

Epoch: 725| Step: 0
Training loss: 0.05877675488591194
Validation loss: 1.5133755424971223

Epoch: 6| Step: 1
Training loss: 0.037951335310935974
Validation loss: 1.5196220541513095

Epoch: 6| Step: 2
Training loss: 0.049016520380973816
Validation loss: 1.5085098666529502

Epoch: 6| Step: 3
Training loss: 0.050947509706020355
Validation loss: 1.4998617864424182

Epoch: 6| Step: 4
Training loss: 0.06272132694721222
Validation loss: 1.5500004650444112

Epoch: 6| Step: 5
Training loss: 0.05411719158291817
Validation loss: 1.530591716048538

Epoch: 6| Step: 6
Training loss: 0.041761819273233414
Validation loss: 1.5387475798206944

Epoch: 6| Step: 7
Training loss: 0.07695651799440384
Validation loss: 1.5218894404749717

Epoch: 6| Step: 8
Training loss: 0.049247510731220245
Validation loss: 1.5240757119271062

Epoch: 6| Step: 9
Training loss: 0.06585920602083206
Validation loss: 1.485936878829874

Epoch: 6| Step: 10
Training loss: 0.08478110283613205
Validation loss: 1.5224550872720697

Epoch: 6| Step: 11
Training loss: 0.1379683017730713
Validation loss: 1.5263678912193543

Epoch: 6| Step: 12
Training loss: 0.04742882028222084
Validation loss: 1.5324939502182828

Epoch: 6| Step: 13
Training loss: 0.17469678819179535
Validation loss: 1.5434271853457215

Epoch: 726| Step: 0
Training loss: 0.10337618738412857
Validation loss: 1.5200154832614365

Epoch: 6| Step: 1
Training loss: 0.04393529146909714
Validation loss: 1.5376396961109613

Epoch: 6| Step: 2
Training loss: 0.046446286141872406
Validation loss: 1.531381396837132

Epoch: 6| Step: 3
Training loss: 0.08057041466236115
Validation loss: 1.5325197455703572

Epoch: 6| Step: 4
Training loss: 0.07743269950151443
Validation loss: 1.5461581830055482

Epoch: 6| Step: 5
Training loss: 0.12044595181941986
Validation loss: 1.5510569746776293

Epoch: 6| Step: 6
Training loss: 0.0989946722984314
Validation loss: 1.5270920722715315

Epoch: 6| Step: 7
Training loss: 0.06568516790866852
Validation loss: 1.5073427743809198

Epoch: 6| Step: 8
Training loss: 0.07729552686214447
Validation loss: 1.497593883545168

Epoch: 6| Step: 9
Training loss: 0.11242707818746567
Validation loss: 1.4870606494206253

Epoch: 6| Step: 10
Training loss: 0.06404247134923935
Validation loss: 1.4753009491069342

Epoch: 6| Step: 11
Training loss: 0.061964068561792374
Validation loss: 1.5083009940321728

Epoch: 6| Step: 12
Training loss: 0.07076139003038406
Validation loss: 1.5077280921320761

Epoch: 6| Step: 13
Training loss: 0.09212199598550797
Validation loss: 1.519403672987415

Epoch: 727| Step: 0
Training loss: 0.05908743664622307
Validation loss: 1.5088637721153997

Epoch: 6| Step: 1
Training loss: 0.06057119369506836
Validation loss: 1.5160846428204608

Epoch: 6| Step: 2
Training loss: 0.036677733063697815
Validation loss: 1.529685458829326

Epoch: 6| Step: 3
Training loss: 0.062426671385765076
Validation loss: 1.539668599764506

Epoch: 6| Step: 4
Training loss: 0.05330454185605049
Validation loss: 1.5533837528638943

Epoch: 6| Step: 5
Training loss: 0.08011719584465027
Validation loss: 1.5717445842681392

Epoch: 6| Step: 6
Training loss: 0.11070491373538971
Validation loss: 1.6168376720079811

Epoch: 6| Step: 7
Training loss: 0.1468050479888916
Validation loss: 1.589669644832611

Epoch: 6| Step: 8
Training loss: 0.09707529842853546
Validation loss: 1.5792829554568055

Epoch: 6| Step: 9
Training loss: 0.047271374613046646
Validation loss: 1.5291520831405476

Epoch: 6| Step: 10
Training loss: 0.09067978709936142
Validation loss: 1.543391079031011

Epoch: 6| Step: 11
Training loss: 0.06242256984114647
Validation loss: 1.5394777790192635

Epoch: 6| Step: 12
Training loss: 0.0576842799782753
Validation loss: 1.5385161817714732

Epoch: 6| Step: 13
Training loss: 0.0318085215985775
Validation loss: 1.5244688231457946

Epoch: 728| Step: 0
Training loss: 0.06833605468273163
Validation loss: 1.4958941910856514

Epoch: 6| Step: 1
Training loss: 0.04827779531478882
Validation loss: 1.4910772462044992

Epoch: 6| Step: 2
Training loss: 0.05533197522163391
Validation loss: 1.5097011238016107

Epoch: 6| Step: 3
Training loss: 0.0709492415189743
Validation loss: 1.4969798980220672

Epoch: 6| Step: 4
Training loss: 0.07365146279335022
Validation loss: 1.5024671336655975

Epoch: 6| Step: 5
Training loss: 0.06218285113573074
Validation loss: 1.5197958177135837

Epoch: 6| Step: 6
Training loss: 0.05418543145060539
Validation loss: 1.512973141926591

Epoch: 6| Step: 7
Training loss: 0.12660229206085205
Validation loss: 1.5029037812704682

Epoch: 6| Step: 8
Training loss: 0.044656045734882355
Validation loss: 1.5468652799565306

Epoch: 6| Step: 9
Training loss: 0.09455517679452896
Validation loss: 1.5598688151246758

Epoch: 6| Step: 10
Training loss: 0.03617672622203827
Validation loss: 1.5622996027751634

Epoch: 6| Step: 11
Training loss: 0.07136701047420502
Validation loss: 1.5626532723826747

Epoch: 6| Step: 12
Training loss: 0.05447286367416382
Validation loss: 1.5668395385947278

Epoch: 6| Step: 13
Training loss: 0.051091667264699936
Validation loss: 1.5556408961613972

Epoch: 729| Step: 0
Training loss: 0.06083954870700836
Validation loss: 1.5512866589330858

Epoch: 6| Step: 1
Training loss: 0.11610613763332367
Validation loss: 1.5259244454804288

Epoch: 6| Step: 2
Training loss: 0.0395122654736042
Validation loss: 1.525863509024343

Epoch: 6| Step: 3
Training loss: 0.03095065988600254
Validation loss: 1.5585462713754306

Epoch: 6| Step: 4
Training loss: 0.09588055312633514
Validation loss: 1.5536134114829443

Epoch: 6| Step: 5
Training loss: 0.06994128227233887
Validation loss: 1.5393007410469877

Epoch: 6| Step: 6
Training loss: 0.06242465227842331
Validation loss: 1.5254218168156122

Epoch: 6| Step: 7
Training loss: 0.04077846556901932
Validation loss: 1.552567167948651

Epoch: 6| Step: 8
Training loss: 0.06909967958927155
Validation loss: 1.5608718510596984

Epoch: 6| Step: 9
Training loss: 0.03896636515855789
Validation loss: 1.5217713623918512

Epoch: 6| Step: 10
Training loss: 0.053339771926403046
Validation loss: 1.5588128887197024

Epoch: 6| Step: 11
Training loss: 0.060792725533246994
Validation loss: 1.5611519493082517

Epoch: 6| Step: 12
Training loss: 0.07329131662845612
Validation loss: 1.5437204632707822

Epoch: 6| Step: 13
Training loss: 0.06747860461473465
Validation loss: 1.5391283041687422

Epoch: 730| Step: 0
Training loss: 0.048977337777614594
Validation loss: 1.535870152135049

Epoch: 6| Step: 1
Training loss: 0.07316439598798752
Validation loss: 1.5716613313203216

Epoch: 6| Step: 2
Training loss: 0.040209680795669556
Validation loss: 1.6103507626441218

Epoch: 6| Step: 3
Training loss: 0.0748499259352684
Validation loss: 1.5936098996029104

Epoch: 6| Step: 4
Training loss: 0.10797668248414993
Validation loss: 1.5940249978855092

Epoch: 6| Step: 5
Training loss: 0.04442991316318512
Validation loss: 1.591389811167153

Epoch: 6| Step: 6
Training loss: 0.059031806886196136
Validation loss: 1.5725284443106702

Epoch: 6| Step: 7
Training loss: 0.06206909567117691
Validation loss: 1.5576884503005652

Epoch: 6| Step: 8
Training loss: 0.12201078236103058
Validation loss: 1.5551044274401922

Epoch: 6| Step: 9
Training loss: 0.06479315459728241
Validation loss: 1.5613653659820557

Epoch: 6| Step: 10
Training loss: 0.10207846760749817
Validation loss: 1.5403895032021306

Epoch: 6| Step: 11
Training loss: 0.07127830386161804
Validation loss: 1.5458393173833047

Epoch: 6| Step: 12
Training loss: 0.058726221323013306
Validation loss: 1.543862271052535

Epoch: 6| Step: 13
Training loss: 0.03438051417469978
Validation loss: 1.5294194529133458

Epoch: 731| Step: 0
Training loss: 0.04617200791835785
Validation loss: 1.5447477422734743

Epoch: 6| Step: 1
Training loss: 0.051344119012355804
Validation loss: 1.5212498159818753

Epoch: 6| Step: 2
Training loss: 0.05156055837869644
Validation loss: 1.5571956352521015

Epoch: 6| Step: 3
Training loss: 0.18265074491500854
Validation loss: 1.5698643756169144

Epoch: 6| Step: 4
Training loss: 0.07516535371541977
Validation loss: 1.5697828467174242

Epoch: 6| Step: 5
Training loss: 0.09560602158308029
Validation loss: 1.5558790199218258

Epoch: 6| Step: 6
Training loss: 0.06372274458408356
Validation loss: 1.56662372491693

Epoch: 6| Step: 7
Training loss: 0.06184368208050728
Validation loss: 1.5450361486404174

Epoch: 6| Step: 8
Training loss: 0.04588799923658371
Validation loss: 1.5461626206674883

Epoch: 6| Step: 9
Training loss: 0.035943083465099335
Validation loss: 1.5575949889357372

Epoch: 6| Step: 10
Training loss: 0.02518966794013977
Validation loss: 1.5554243928642684

Epoch: 6| Step: 11
Training loss: 0.09641595184803009
Validation loss: 1.5435905853907268

Epoch: 6| Step: 12
Training loss: 0.07176288217306137
Validation loss: 1.54103837731064

Epoch: 6| Step: 13
Training loss: 0.09360451251268387
Validation loss: 1.5358936197014266

Epoch: 732| Step: 0
Training loss: 0.074069544672966
Validation loss: 1.5064932787290184

Epoch: 6| Step: 1
Training loss: 0.02959601953625679
Validation loss: 1.515108553312158

Epoch: 6| Step: 2
Training loss: 0.06097152829170227
Validation loss: 1.5506861068869149

Epoch: 6| Step: 3
Training loss: 0.07678946107625961
Validation loss: 1.5216199127576684

Epoch: 6| Step: 4
Training loss: 0.05405080318450928
Validation loss: 1.527120462027929

Epoch: 6| Step: 5
Training loss: 0.04839329421520233
Validation loss: 1.520634824870735

Epoch: 6| Step: 6
Training loss: 0.040745384991168976
Validation loss: 1.5295067884588753

Epoch: 6| Step: 7
Training loss: 0.03967711329460144
Validation loss: 1.5393666285340504

Epoch: 6| Step: 8
Training loss: 0.034905530512332916
Validation loss: 1.5199391739342802

Epoch: 6| Step: 9
Training loss: 0.0636235773563385
Validation loss: 1.5340818717915525

Epoch: 6| Step: 10
Training loss: 0.05774645507335663
Validation loss: 1.5159867117481847

Epoch: 6| Step: 11
Training loss: 0.1369352489709854
Validation loss: 1.5265778546692224

Epoch: 6| Step: 12
Training loss: 0.06875911355018616
Validation loss: 1.5376393987286476

Epoch: 6| Step: 13
Training loss: 0.06516991555690765
Validation loss: 1.5392676373963714

Epoch: 733| Step: 0
Training loss: 0.07611637562513351
Validation loss: 1.5421567834833616

Epoch: 6| Step: 1
Training loss: 0.0392865315079689
Validation loss: 1.5430288763456448

Epoch: 6| Step: 2
Training loss: 0.05995290353894234
Validation loss: 1.525869014442608

Epoch: 6| Step: 3
Training loss: 0.06147509813308716
Validation loss: 1.5371841089699858

Epoch: 6| Step: 4
Training loss: 0.03553298860788345
Validation loss: 1.5374445607585292

Epoch: 6| Step: 5
Training loss: 0.13008135557174683
Validation loss: 1.5110018253326416

Epoch: 6| Step: 6
Training loss: 0.04551900550723076
Validation loss: 1.516917122307644

Epoch: 6| Step: 7
Training loss: 0.037713803350925446
Validation loss: 1.5061078789413616

Epoch: 6| Step: 8
Training loss: 0.06388804316520691
Validation loss: 1.5335656160949378

Epoch: 6| Step: 9
Training loss: 0.05853099375963211
Validation loss: 1.5207044181003366

Epoch: 6| Step: 10
Training loss: 0.049574535340070724
Validation loss: 1.5396180229802285

Epoch: 6| Step: 11
Training loss: 0.05935879796743393
Validation loss: 1.5326851747369254

Epoch: 6| Step: 12
Training loss: 0.0705396831035614
Validation loss: 1.5456252777448265

Epoch: 6| Step: 13
Training loss: 0.0316525474190712
Validation loss: 1.5145892930287186

Epoch: 734| Step: 0
Training loss: 0.051336899399757385
Validation loss: 1.5097878748370754

Epoch: 6| Step: 1
Training loss: 0.07330344617366791
Validation loss: 1.5364315407250517

Epoch: 6| Step: 2
Training loss: 0.037950627505779266
Validation loss: 1.5215309473776049

Epoch: 6| Step: 3
Training loss: 0.04811425879597664
Validation loss: 1.523320089104355

Epoch: 6| Step: 4
Training loss: 0.09050650149583817
Validation loss: 1.527928247246691

Epoch: 6| Step: 5
Training loss: 0.049696192145347595
Validation loss: 1.5184377239596458

Epoch: 6| Step: 6
Training loss: 0.06614622473716736
Validation loss: 1.5047304271369852

Epoch: 6| Step: 7
Training loss: 0.036433055996894836
Validation loss: 1.5280664915679603

Epoch: 6| Step: 8
Training loss: 0.052501924335956573
Validation loss: 1.5210952252470038

Epoch: 6| Step: 9
Training loss: 0.11596490442752838
Validation loss: 1.5290759430136731

Epoch: 6| Step: 10
Training loss: 0.07710849493741989
Validation loss: 1.537475065518451

Epoch: 6| Step: 11
Training loss: 0.05325695872306824
Validation loss: 1.535805292026971

Epoch: 6| Step: 12
Training loss: 0.1121196299791336
Validation loss: 1.5581260573479436

Epoch: 6| Step: 13
Training loss: 0.05535370856523514
Validation loss: 1.5182253570966824

Epoch: 735| Step: 0
Training loss: 0.06155584007501602
Validation loss: 1.5017586702941566

Epoch: 6| Step: 1
Training loss: 0.08036337792873383
Validation loss: 1.4805140623482325

Epoch: 6| Step: 2
Training loss: 0.05789294093847275
Validation loss: 1.5000609018469369

Epoch: 6| Step: 3
Training loss: 0.09566016495227814
Validation loss: 1.5147897197354225

Epoch: 6| Step: 4
Training loss: 0.14870013296604156
Validation loss: 1.5291522408044467

Epoch: 6| Step: 5
Training loss: 0.07125077396631241
Validation loss: 1.527452452208406

Epoch: 6| Step: 6
Training loss: 0.056035447865724564
Validation loss: 1.523700305851557

Epoch: 6| Step: 7
Training loss: 0.12182670086622238
Validation loss: 1.5307183842505179

Epoch: 6| Step: 8
Training loss: 0.050245530903339386
Validation loss: 1.527045420421067

Epoch: 6| Step: 9
Training loss: 0.09303520619869232
Validation loss: 1.525319964654984

Epoch: 6| Step: 10
Training loss: 0.06557922065258026
Validation loss: 1.5811577830263364

Epoch: 6| Step: 11
Training loss: 0.09890957921743393
Validation loss: 1.5607491052278908

Epoch: 6| Step: 12
Training loss: 0.07107983529567719
Validation loss: 1.5661303599675496

Epoch: 6| Step: 13
Training loss: 0.06174936518073082
Validation loss: 1.5758466348853162

Epoch: 736| Step: 0
Training loss: 0.08941320329904556
Validation loss: 1.532286310708651

Epoch: 6| Step: 1
Training loss: 0.10265300422906876
Validation loss: 1.484819132794616

Epoch: 6| Step: 2
Training loss: 0.04636440426111221
Validation loss: 1.493974930496626

Epoch: 6| Step: 3
Training loss: 0.05298459529876709
Validation loss: 1.508138164397209

Epoch: 6| Step: 4
Training loss: 0.11753331124782562
Validation loss: 1.499086868378424

Epoch: 6| Step: 5
Training loss: 0.10160380601882935
Validation loss: 1.5327421490864088

Epoch: 6| Step: 6
Training loss: 0.042726460844278336
Validation loss: 1.4985530645616594

Epoch: 6| Step: 7
Training loss: 0.09418158233165741
Validation loss: 1.476465126519562

Epoch: 6| Step: 8
Training loss: 0.09366536885499954
Validation loss: 1.4999434114784322

Epoch: 6| Step: 9
Training loss: 0.056729309260845184
Validation loss: 1.508749145333485

Epoch: 6| Step: 10
Training loss: 0.12072615325450897
Validation loss: 1.5392094555721487

Epoch: 6| Step: 11
Training loss: 0.11393259465694427
Validation loss: 1.4873725252766763

Epoch: 6| Step: 12
Training loss: 0.133040189743042
Validation loss: 1.4890225343806769

Epoch: 6| Step: 13
Training loss: 0.06954889744520187
Validation loss: 1.530360319281137

Epoch: 737| Step: 0
Training loss: 0.08941864967346191
Validation loss: 1.531875874406548

Epoch: 6| Step: 1
Training loss: 0.08539941906929016
Validation loss: 1.5210233144862677

Epoch: 6| Step: 2
Training loss: 0.0893804132938385
Validation loss: 1.4957838032835273

Epoch: 6| Step: 3
Training loss: 0.0981125608086586
Validation loss: 1.5150220368498115

Epoch: 6| Step: 4
Training loss: 0.07837182283401489
Validation loss: 1.5142887869188864

Epoch: 6| Step: 5
Training loss: 0.06914590299129486
Validation loss: 1.5070867717906993

Epoch: 6| Step: 6
Training loss: 0.06278121471405029
Validation loss: 1.5193968665215276

Epoch: 6| Step: 7
Training loss: 0.10040821135044098
Validation loss: 1.5245556203267907

Epoch: 6| Step: 8
Training loss: 0.10987943410873413
Validation loss: 1.542094103751644

Epoch: 6| Step: 9
Training loss: 0.09060224890708923
Validation loss: 1.5381776530255553

Epoch: 6| Step: 10
Training loss: 0.08990158140659332
Validation loss: 1.5678866563304779

Epoch: 6| Step: 11
Training loss: 0.15390180051326752
Validation loss: 1.5434002286644393

Epoch: 6| Step: 12
Training loss: 0.040174759924411774
Validation loss: 1.5455844799677532

Epoch: 6| Step: 13
Training loss: 0.06165681779384613
Validation loss: 1.5436097627045007

Epoch: 738| Step: 0
Training loss: 0.08197055011987686
Validation loss: 1.5800290498682248

Epoch: 6| Step: 1
Training loss: 0.07698290795087814
Validation loss: 1.5728368643791444

Epoch: 6| Step: 2
Training loss: 0.07521500438451767
Validation loss: 1.5541587683462328

Epoch: 6| Step: 3
Training loss: 0.06804104894399643
Validation loss: 1.5704308325244534

Epoch: 6| Step: 4
Training loss: 0.09462928026914597
Validation loss: 1.567401627058624

Epoch: 6| Step: 5
Training loss: 0.0820416733622551
Validation loss: 1.567452052588104

Epoch: 6| Step: 6
Training loss: 0.16694024205207825
Validation loss: 1.5568189877335743

Epoch: 6| Step: 7
Training loss: 0.10058850049972534
Validation loss: 1.581187957076616

Epoch: 6| Step: 8
Training loss: 0.06872878968715668
Validation loss: 1.6003126944265058

Epoch: 6| Step: 9
Training loss: 0.13896383345127106
Validation loss: 1.597948520414291

Epoch: 6| Step: 10
Training loss: 0.09718505293130875
Validation loss: 1.5925849368495326

Epoch: 6| Step: 11
Training loss: 0.08406147360801697
Validation loss: 1.5722917536253571

Epoch: 6| Step: 12
Training loss: 0.08568322658538818
Validation loss: 1.575753829812491

Epoch: 6| Step: 13
Training loss: 0.055542998015880585
Validation loss: 1.546246483761777

Epoch: 739| Step: 0
Training loss: 0.0843227282166481
Validation loss: 1.528781997260227

Epoch: 6| Step: 1
Training loss: 0.07671954482793808
Validation loss: 1.5248698137139762

Epoch: 6| Step: 2
Training loss: 0.07689026743173599
Validation loss: 1.4914301377470776

Epoch: 6| Step: 3
Training loss: 0.06048976257443428
Validation loss: 1.5361070863662227

Epoch: 6| Step: 4
Training loss: 0.11860232055187225
Validation loss: 1.505390590237033

Epoch: 6| Step: 5
Training loss: 0.11211303621530533
Validation loss: 1.513075836243168

Epoch: 6| Step: 6
Training loss: 0.15855751931667328
Validation loss: 1.5253964726642897

Epoch: 6| Step: 7
Training loss: 0.04805522412061691
Validation loss: 1.4909482720077678

Epoch: 6| Step: 8
Training loss: 0.06723452359437943
Validation loss: 1.50188656263454

Epoch: 6| Step: 9
Training loss: 0.05792106315493584
Validation loss: 1.5493929052865634

Epoch: 6| Step: 10
Training loss: 0.08407539129257202
Validation loss: 1.5747055289565877

Epoch: 6| Step: 11
Training loss: 0.05257750302553177
Validation loss: 1.5847082112425117

Epoch: 6| Step: 12
Training loss: 0.15831977128982544
Validation loss: 1.6161754977318548

Epoch: 6| Step: 13
Training loss: 0.2039070874452591
Validation loss: 1.5986241653401365

Epoch: 740| Step: 0
Training loss: 0.1004549041390419
Validation loss: 1.6127878273687055

Epoch: 6| Step: 1
Training loss: 0.15461289882659912
Validation loss: 1.5745015317393887

Epoch: 6| Step: 2
Training loss: 0.0849202424287796
Validation loss: 1.5355901269502537

Epoch: 6| Step: 3
Training loss: 0.06265667825937271
Validation loss: 1.5473973187067176

Epoch: 6| Step: 4
Training loss: 0.05000963807106018
Validation loss: 1.5358488905814387

Epoch: 6| Step: 5
Training loss: 0.06100419536232948
Validation loss: 1.5704590146259596

Epoch: 6| Step: 6
Training loss: 0.057347968220710754
Validation loss: 1.5569715025604411

Epoch: 6| Step: 7
Training loss: 0.06799592077732086
Validation loss: 1.5702890394836344

Epoch: 6| Step: 8
Training loss: 0.10304586589336395
Validation loss: 1.5522299915231683

Epoch: 6| Step: 9
Training loss: 0.07006560266017914
Validation loss: 1.5724011877531647

Epoch: 6| Step: 10
Training loss: 0.08169001340866089
Validation loss: 1.5814229108953988

Epoch: 6| Step: 11
Training loss: 0.06504976749420166
Validation loss: 1.5849200820410123

Epoch: 6| Step: 12
Training loss: 0.05826789513230324
Validation loss: 1.5641913369137754

Epoch: 6| Step: 13
Training loss: 0.10189977288246155
Validation loss: 1.602887398453169

Epoch: 741| Step: 0
Training loss: 0.06153164803981781
Validation loss: 1.6017026798699492

Epoch: 6| Step: 1
Training loss: 0.10653113573789597
Validation loss: 1.6311313118985904

Epoch: 6| Step: 2
Training loss: 0.08128680288791656
Validation loss: 1.6048013279514928

Epoch: 6| Step: 3
Training loss: 0.0681905522942543
Validation loss: 1.6467636464744486

Epoch: 6| Step: 4
Training loss: 0.050495415925979614
Validation loss: 1.5903927459511706

Epoch: 6| Step: 5
Training loss: 0.05802017077803612
Validation loss: 1.5970598395152757

Epoch: 6| Step: 6
Training loss: 0.1340743899345398
Validation loss: 1.580072985541436

Epoch: 6| Step: 7
Training loss: 0.0774860680103302
Validation loss: 1.5658358405995112

Epoch: 6| Step: 8
Training loss: 0.10514473170042038
Validation loss: 1.583484095911826

Epoch: 6| Step: 9
Training loss: 0.0731407031416893
Validation loss: 1.5733262992674304

Epoch: 6| Step: 10
Training loss: 0.033277954906225204
Validation loss: 1.55397496556723

Epoch: 6| Step: 11
Training loss: 0.05071931332349777
Validation loss: 1.5623113429674538

Epoch: 6| Step: 12
Training loss: 0.06296376138925552
Validation loss: 1.5550014677868094

Epoch: 6| Step: 13
Training loss: 0.0934448093175888
Validation loss: 1.5575350446085776

Epoch: 742| Step: 0
Training loss: 0.048068903386592865
Validation loss: 1.5416447808665614

Epoch: 6| Step: 1
Training loss: 0.06100285053253174
Validation loss: 1.5576840139204455

Epoch: 6| Step: 2
Training loss: 0.07962070405483246
Validation loss: 1.5635709454936366

Epoch: 6| Step: 3
Training loss: 0.08219746500253677
Validation loss: 1.574626809807234

Epoch: 6| Step: 4
Training loss: 0.11809690296649933
Validation loss: 1.5680657215015863

Epoch: 6| Step: 5
Training loss: 0.068905770778656
Validation loss: 1.5551864741950907

Epoch: 6| Step: 6
Training loss: 0.07442215085029602
Validation loss: 1.5426030735815726

Epoch: 6| Step: 7
Training loss: 0.10402951389551163
Validation loss: 1.5429191538082656

Epoch: 6| Step: 8
Training loss: 0.052967369556427
Validation loss: 1.5354396848268406

Epoch: 6| Step: 9
Training loss: 0.07407791167497635
Validation loss: 1.5419175124937488

Epoch: 6| Step: 10
Training loss: 0.03468048945069313
Validation loss: 1.5371732993792462

Epoch: 6| Step: 11
Training loss: 0.13398277759552002
Validation loss: 1.5498263028360182

Epoch: 6| Step: 12
Training loss: 0.07200773805379868
Validation loss: 1.5648667722619989

Epoch: 6| Step: 13
Training loss: 0.10041572153568268
Validation loss: 1.5562282031582249

Epoch: 743| Step: 0
Training loss: 0.03841884061694145
Validation loss: 1.5789831440935853

Epoch: 6| Step: 1
Training loss: 0.050947804003953934
Validation loss: 1.566520288426389

Epoch: 6| Step: 2
Training loss: 0.08091679960489273
Validation loss: 1.5446650648629794

Epoch: 6| Step: 3
Training loss: 0.08926141262054443
Validation loss: 1.548048843619644

Epoch: 6| Step: 4
Training loss: 0.10540394484996796
Validation loss: 1.5487576812826178

Epoch: 6| Step: 5
Training loss: 0.1408408284187317
Validation loss: 1.5550689338355936

Epoch: 6| Step: 6
Training loss: 0.06253061443567276
Validation loss: 1.5567652756167996

Epoch: 6| Step: 7
Training loss: 0.09666154533624649
Validation loss: 1.563882707267679

Epoch: 6| Step: 8
Training loss: 0.07717408239841461
Validation loss: 1.5793468695814892

Epoch: 6| Step: 9
Training loss: 0.06291577965021133
Validation loss: 1.5874656079917826

Epoch: 6| Step: 10
Training loss: 0.07571114599704742
Validation loss: 1.5846755068789247

Epoch: 6| Step: 11
Training loss: 0.13424980640411377
Validation loss: 1.5913682471039474

Epoch: 6| Step: 12
Training loss: 0.10443179309368134
Validation loss: 1.5810375021349998

Epoch: 6| Step: 13
Training loss: 0.055793508887290955
Validation loss: 1.5602039585831344

Epoch: 744| Step: 0
Training loss: 0.09788388013839722
Validation loss: 1.5590032351914274

Epoch: 6| Step: 1
Training loss: 0.12697912752628326
Validation loss: 1.563189241834866

Epoch: 6| Step: 2
Training loss: 0.05867119878530502
Validation loss: 1.5581138005820654

Epoch: 6| Step: 3
Training loss: 0.055371157824993134
Validation loss: 1.5655611881645777

Epoch: 6| Step: 4
Training loss: 0.055558957159519196
Validation loss: 1.553783082192944

Epoch: 6| Step: 5
Training loss: 0.08997208625078201
Validation loss: 1.552130458175495

Epoch: 6| Step: 6
Training loss: 0.04716688394546509
Validation loss: 1.562626108046501

Epoch: 6| Step: 7
Training loss: 0.05619456619024277
Validation loss: 1.566577890867828

Epoch: 6| Step: 8
Training loss: 0.1197095662355423
Validation loss: 1.5791863485049176

Epoch: 6| Step: 9
Training loss: 0.050814494490623474
Validation loss: 1.552712740436677

Epoch: 6| Step: 10
Training loss: 0.07535776495933533
Validation loss: 1.557865463277345

Epoch: 6| Step: 11
Training loss: 0.049787238240242004
Validation loss: 1.5628896156946819

Epoch: 6| Step: 12
Training loss: 0.07107244431972504
Validation loss: 1.5811173505680536

Epoch: 6| Step: 13
Training loss: 0.08910254389047623
Validation loss: 1.5729138069255377

Epoch: 745| Step: 0
Training loss: 0.03532988578081131
Validation loss: 1.5600644965325632

Epoch: 6| Step: 1
Training loss: 0.07492303848266602
Validation loss: 1.5424571216747325

Epoch: 6| Step: 2
Training loss: 0.0905115157365799
Validation loss: 1.5359620253245037

Epoch: 6| Step: 3
Training loss: 0.0533900186419487
Validation loss: 1.5373018364752493

Epoch: 6| Step: 4
Training loss: 0.12740996479988098
Validation loss: 1.5342448872904624

Epoch: 6| Step: 5
Training loss: 0.05013043060898781
Validation loss: 1.544165349775745

Epoch: 6| Step: 6
Training loss: 0.05193209648132324
Validation loss: 1.530104560236777

Epoch: 6| Step: 7
Training loss: 0.03504488617181778
Validation loss: 1.5469374861768497

Epoch: 6| Step: 8
Training loss: 0.0620829239487648
Validation loss: 1.5361805603068361

Epoch: 6| Step: 9
Training loss: 0.11887292563915253
Validation loss: 1.5228803914080384

Epoch: 6| Step: 10
Training loss: 0.05642092600464821
Validation loss: 1.51565650586159

Epoch: 6| Step: 11
Training loss: 0.0819692462682724
Validation loss: 1.5143783707772531

Epoch: 6| Step: 12
Training loss: 0.05023083835840225
Validation loss: 1.5198809664736512

Epoch: 6| Step: 13
Training loss: 0.046255044639110565
Validation loss: 1.5385875099448747

Epoch: 746| Step: 0
Training loss: 0.05817422643303871
Validation loss: 1.515756804455993

Epoch: 6| Step: 1
Training loss: 0.04150839149951935
Validation loss: 1.5281008430706557

Epoch: 6| Step: 2
Training loss: 0.05269104242324829
Validation loss: 1.5303447297824326

Epoch: 6| Step: 3
Training loss: 0.10877426713705063
Validation loss: 1.5445000971517255

Epoch: 6| Step: 4
Training loss: 0.04679630696773529
Validation loss: 1.5426493370404808

Epoch: 6| Step: 5
Training loss: 0.05077967420220375
Validation loss: 1.5403691145681566

Epoch: 6| Step: 6
Training loss: 0.06650496274232864
Validation loss: 1.5296487821045743

Epoch: 6| Step: 7
Training loss: 0.04859252646565437
Validation loss: 1.5348795960026402

Epoch: 6| Step: 8
Training loss: 0.06117022782564163
Validation loss: 1.521444671897478

Epoch: 6| Step: 9
Training loss: 0.04857826232910156
Validation loss: 1.5169362727031912

Epoch: 6| Step: 10
Training loss: 0.06141180545091629
Validation loss: 1.5132323067675355

Epoch: 6| Step: 11
Training loss: 0.11964497715234756
Validation loss: 1.5259678966255599

Epoch: 6| Step: 12
Training loss: 0.06647996604442596
Validation loss: 1.5057748466409662

Epoch: 6| Step: 13
Training loss: 0.05159754306077957
Validation loss: 1.5202527507658927

Epoch: 747| Step: 0
Training loss: 0.06667064875364304
Validation loss: 1.5158781056763024

Epoch: 6| Step: 1
Training loss: 0.03882071375846863
Validation loss: 1.5210408882428241

Epoch: 6| Step: 2
Training loss: 0.07897204160690308
Validation loss: 1.5171468501449914

Epoch: 6| Step: 3
Training loss: 0.08131599426269531
Validation loss: 1.5385241982757405

Epoch: 6| Step: 4
Training loss: 0.06575100868940353
Validation loss: 1.5295959967438892

Epoch: 6| Step: 5
Training loss: 0.11620889604091644
Validation loss: 1.5081660414254794

Epoch: 6| Step: 6
Training loss: 0.061415448784828186
Validation loss: 1.5067742793790755

Epoch: 6| Step: 7
Training loss: 0.1227135881781578
Validation loss: 1.518429526718714

Epoch: 6| Step: 8
Training loss: 0.05084878206253052
Validation loss: 1.5237006096429722

Epoch: 6| Step: 9
Training loss: 0.05663657933473587
Validation loss: 1.516924451756221

Epoch: 6| Step: 10
Training loss: 0.044306859374046326
Validation loss: 1.533966774581581

Epoch: 6| Step: 11
Training loss: 0.06623746454715729
Validation loss: 1.5354733095374158

Epoch: 6| Step: 12
Training loss: 0.09095866978168488
Validation loss: 1.5361574093500774

Epoch: 6| Step: 13
Training loss: 0.164240762591362
Validation loss: 1.5377617907780472

Epoch: 748| Step: 0
Training loss: 0.0490083172917366
Validation loss: 1.53831131996647

Epoch: 6| Step: 1
Training loss: 0.07043924927711487
Validation loss: 1.5738410577979138

Epoch: 6| Step: 2
Training loss: 0.11345679312944412
Validation loss: 1.5510149053348008

Epoch: 6| Step: 3
Training loss: 0.05288706347346306
Validation loss: 1.5464953299491637

Epoch: 6| Step: 4
Training loss: 0.056065384298563004
Validation loss: 1.5462031223440682

Epoch: 6| Step: 5
Training loss: 0.061060525476932526
Validation loss: 1.56380150523237

Epoch: 6| Step: 6
Training loss: 0.05219230800867081
Validation loss: 1.5576590902061873

Epoch: 6| Step: 7
Training loss: 0.07013094425201416
Validation loss: 1.554605378899523

Epoch: 6| Step: 8
Training loss: 0.10104173421859741
Validation loss: 1.5720797302902385

Epoch: 6| Step: 9
Training loss: 0.10439079254865646
Validation loss: 1.560524703994874

Epoch: 6| Step: 10
Training loss: 0.05601797625422478
Validation loss: 1.5568394007221344

Epoch: 6| Step: 11
Training loss: 0.11020780354738235
Validation loss: 1.5620588948649745

Epoch: 6| Step: 12
Training loss: 0.0534939244389534
Validation loss: 1.54364699445745

Epoch: 6| Step: 13
Training loss: 0.056003253906965256
Validation loss: 1.5482830898736113

Epoch: 749| Step: 0
Training loss: 0.10282846540212631
Validation loss: 1.5751545916321457

Epoch: 6| Step: 1
Training loss: 0.09428080916404724
Validation loss: 1.568473505717452

Epoch: 6| Step: 2
Training loss: 0.07319162786006927
Validation loss: 1.578443504148914

Epoch: 6| Step: 3
Training loss: 0.15415650606155396
Validation loss: 1.5766115483417307

Epoch: 6| Step: 4
Training loss: 0.039296649396419525
Validation loss: 1.5244959144182102

Epoch: 6| Step: 5
Training loss: 0.0688578262925148
Validation loss: 1.5450810296561128

Epoch: 6| Step: 6
Training loss: 0.03367762267589569
Validation loss: 1.5222757234368274

Epoch: 6| Step: 7
Training loss: 0.08923612534999847
Validation loss: 1.5383239112874514

Epoch: 6| Step: 8
Training loss: 0.07974482327699661
Validation loss: 1.5396809142122987

Epoch: 6| Step: 9
Training loss: 0.09046679735183716
Validation loss: 1.5645623835184241

Epoch: 6| Step: 10
Training loss: 0.04574139416217804
Validation loss: 1.556224076978622

Epoch: 6| Step: 11
Training loss: 0.06069840118288994
Validation loss: 1.565364404391217

Epoch: 6| Step: 12
Training loss: 0.0591481551527977
Validation loss: 1.5406290843922605

Epoch: 6| Step: 13
Training loss: 0.046814367175102234
Validation loss: 1.5925669170195056

Epoch: 750| Step: 0
Training loss: 0.06417420506477356
Validation loss: 1.572337870956749

Epoch: 6| Step: 1
Training loss: 0.06340160965919495
Validation loss: 1.5623817572029688

Epoch: 6| Step: 2
Training loss: 0.07860736548900604
Validation loss: 1.561823344999744

Epoch: 6| Step: 3
Training loss: 0.10056883096694946
Validation loss: 1.5521136868384577

Epoch: 6| Step: 4
Training loss: 0.0922996997833252
Validation loss: 1.5579601269896313

Epoch: 6| Step: 5
Training loss: 0.09823322296142578
Validation loss: 1.5751175777886504

Epoch: 6| Step: 6
Training loss: 0.16696006059646606
Validation loss: 1.56913407387272

Epoch: 6| Step: 7
Training loss: 0.07615868747234344
Validation loss: 1.5475751341030162

Epoch: 6| Step: 8
Training loss: 0.11057936400175095
Validation loss: 1.5487316218755578

Epoch: 6| Step: 9
Training loss: 0.06299092620611191
Validation loss: 1.556791954143073

Epoch: 6| Step: 10
Training loss: 0.03980078548192978
Validation loss: 1.5417768275865944

Epoch: 6| Step: 11
Training loss: 0.0427156463265419
Validation loss: 1.5363997105629212

Epoch: 6| Step: 12
Training loss: 0.04716899245977402
Validation loss: 1.5093911834942397

Epoch: 6| Step: 13
Training loss: 0.08315417915582657
Validation loss: 1.5225514814417849

Testing loss: 2.3102840158674454
