Epoch: 1| Step: 0
Training loss: 6.127841212633213
Validation loss: 5.836864716862937

Epoch: 6| Step: 1
Training loss: 6.262912686393034
Validation loss: 5.8175015506736765

Epoch: 6| Step: 2
Training loss: 5.206659256510197
Validation loss: 5.801780981627189

Epoch: 6| Step: 3
Training loss: 5.507670169371082
Validation loss: 5.7877411563468435

Epoch: 6| Step: 4
Training loss: 6.488709253643617
Validation loss: 5.772798108300289

Epoch: 6| Step: 5
Training loss: 6.38335873006976
Validation loss: 5.756896724402789

Epoch: 6| Step: 6
Training loss: 6.418341711146651
Validation loss: 5.737219851273082

Epoch: 6| Step: 7
Training loss: 6.37428249734486
Validation loss: 5.71535297401929

Epoch: 6| Step: 8
Training loss: 6.290361012103968
Validation loss: 5.690806440474373

Epoch: 6| Step: 9
Training loss: 5.736213410178301
Validation loss: 5.663224201903793

Epoch: 6| Step: 10
Training loss: 4.421328453552105
Validation loss: 5.63241879114134

Epoch: 6| Step: 11
Training loss: 4.75974598952146
Validation loss: 5.5972439863480945

Epoch: 6| Step: 12
Training loss: 4.621922474295565
Validation loss: 5.558443292445621

Epoch: 6| Step: 13
Training loss: 5.084454438867357
Validation loss: 5.514993588642214

Epoch: 2| Step: 0
Training loss: 6.347255696496635
Validation loss: 5.468381794665208

Epoch: 6| Step: 1
Training loss: 4.808198269556407
Validation loss: 5.416886137625035

Epoch: 6| Step: 2
Training loss: 6.381307137258737
Validation loss: 5.363229656500857

Epoch: 6| Step: 3
Training loss: 4.799830020437979
Validation loss: 5.30358974915675

Epoch: 6| Step: 4
Training loss: 5.71688261968068
Validation loss: 5.243214951103152

Epoch: 6| Step: 5
Training loss: 4.296609988276504
Validation loss: 5.183239005851819

Epoch: 6| Step: 6
Training loss: 5.24786606062956
Validation loss: 5.119421485232735

Epoch: 6| Step: 7
Training loss: 4.859910352845545
Validation loss: 5.053171065562912

Epoch: 6| Step: 8
Training loss: 5.238458572105913
Validation loss: 4.98379482056202

Epoch: 6| Step: 9
Training loss: 5.74499625714664
Validation loss: 4.929749161940302

Epoch: 6| Step: 10
Training loss: 4.9254071837050155
Validation loss: 4.880682242802517

Epoch: 6| Step: 11
Training loss: 4.52428516621784
Validation loss: 4.832211485538474

Epoch: 6| Step: 12
Training loss: 4.5574708158612225
Validation loss: 4.785578971240876

Epoch: 6| Step: 13
Training loss: 3.887872541920797
Validation loss: 4.741877216181749

Epoch: 3| Step: 0
Training loss: 3.8548875426675897
Validation loss: 4.699937868809438

Epoch: 6| Step: 1
Training loss: 5.595696819095487
Validation loss: 4.6617638716111065

Epoch: 6| Step: 2
Training loss: 5.088456287533255
Validation loss: 4.6221837962380485

Epoch: 6| Step: 3
Training loss: 4.636275696897941
Validation loss: 4.584121646749331

Epoch: 6| Step: 4
Training loss: 4.751004163107135
Validation loss: 4.546779960707793

Epoch: 6| Step: 5
Training loss: 4.6964390271270915
Validation loss: 4.515255249477439

Epoch: 6| Step: 6
Training loss: 4.197732749425064
Validation loss: 4.482241694487832

Epoch: 6| Step: 7
Training loss: 3.993586763439801
Validation loss: 4.451532898713493

Epoch: 6| Step: 8
Training loss: 4.934994025415207
Validation loss: 4.425607231304628

Epoch: 6| Step: 9
Training loss: 4.971626073143195
Validation loss: 4.403466505557404

Epoch: 6| Step: 10
Training loss: 3.3267286353241885
Validation loss: 4.377946289914078

Epoch: 6| Step: 11
Training loss: 5.487415134060446
Validation loss: 4.3528402130993795

Epoch: 6| Step: 12
Training loss: 4.2467924243346
Validation loss: 4.31631756354878

Epoch: 6| Step: 13
Training loss: 3.4605545968790836
Validation loss: 4.278144731236932

Epoch: 4| Step: 0
Training loss: 3.8465817572898584
Validation loss: 4.24920936121307

Epoch: 6| Step: 1
Training loss: 4.034324006246639
Validation loss: 4.2254522307910065

Epoch: 6| Step: 2
Training loss: 3.9231399988480558
Validation loss: 4.200611156125755

Epoch: 6| Step: 3
Training loss: 4.047334976272195
Validation loss: 4.17810740343428

Epoch: 6| Step: 4
Training loss: 3.6976851413225966
Validation loss: 4.155023285700198

Epoch: 6| Step: 5
Training loss: 5.0903308837303864
Validation loss: 4.138585051519897

Epoch: 6| Step: 6
Training loss: 4.777355128576494
Validation loss: 4.129974321776507

Epoch: 6| Step: 7
Training loss: 4.484286955391126
Validation loss: 4.120980527809931

Epoch: 6| Step: 8
Training loss: 4.337639332053276
Validation loss: 4.090857057166951

Epoch: 6| Step: 9
Training loss: 3.7106879541917546
Validation loss: 4.075352820794927

Epoch: 6| Step: 10
Training loss: 4.49668380617156
Validation loss: 4.061317017925975

Epoch: 6| Step: 11
Training loss: 4.112176092778321
Validation loss: 4.05156985522206

Epoch: 6| Step: 12
Training loss: 4.194945136383267
Validation loss: 4.041566091203073

Epoch: 6| Step: 13
Training loss: 5.000346171793365
Validation loss: 4.028565757276947

Epoch: 5| Step: 0
Training loss: 4.005123195396458
Validation loss: 4.0111867628997615

Epoch: 6| Step: 1
Training loss: 4.603584816646968
Validation loss: 3.99718760762142

Epoch: 6| Step: 2
Training loss: 3.6972151973003853
Validation loss: 3.9858142277779938

Epoch: 6| Step: 3
Training loss: 4.192971370178052
Validation loss: 3.9751555194848414

Epoch: 6| Step: 4
Training loss: 5.079879504599494
Validation loss: 3.965450774280858

Epoch: 6| Step: 5
Training loss: 3.2897003352734786
Validation loss: 3.944520511285628

Epoch: 6| Step: 6
Training loss: 3.3464817759999246
Validation loss: 3.9576315321911077

Epoch: 6| Step: 7
Training loss: 3.9980862330897367
Validation loss: 3.9320316369162596

Epoch: 6| Step: 8
Training loss: 4.766963583139535
Validation loss: 3.920118212245336

Epoch: 6| Step: 9
Training loss: 3.191265948233703
Validation loss: 3.909248418686575

Epoch: 6| Step: 10
Training loss: 3.9006988143843597
Validation loss: 3.90719932653301

Epoch: 6| Step: 11
Training loss: 4.109989018854846
Validation loss: 3.9016590072156387

Epoch: 6| Step: 12
Training loss: 4.227576848013454
Validation loss: 3.885714897268557

Epoch: 6| Step: 13
Training loss: 4.810418806024634
Validation loss: 3.878139557756208

Epoch: 6| Step: 0
Training loss: 4.454943262289077
Validation loss: 3.870025707627011

Epoch: 6| Step: 1
Training loss: 3.8857592447869522
Validation loss: 3.8593960012869455

Epoch: 6| Step: 2
Training loss: 3.679555837944409
Validation loss: 3.848865763964943

Epoch: 6| Step: 3
Training loss: 4.086669856241879
Validation loss: 3.841928771746789

Epoch: 6| Step: 4
Training loss: 3.121860911172382
Validation loss: 3.8352178664603285

Epoch: 6| Step: 5
Training loss: 3.8101641894428506
Validation loss: 3.82841635041725

Epoch: 6| Step: 6
Training loss: 3.4086342962399074
Validation loss: 3.8212718771038903

Epoch: 6| Step: 7
Training loss: 3.540024649755143
Validation loss: 3.813895766353641

Epoch: 6| Step: 8
Training loss: 4.7367606116975445
Validation loss: 3.807911256904362

Epoch: 6| Step: 9
Training loss: 4.191010327584265
Validation loss: 3.8024845389781396

Epoch: 6| Step: 10
Training loss: 4.581465091834195
Validation loss: 3.8030945870804986

Epoch: 6| Step: 11
Training loss: 4.050037223739046
Validation loss: 3.7919788500275318

Epoch: 6| Step: 12
Training loss: 3.716955697720041
Validation loss: 3.7845101448020775

Epoch: 6| Step: 13
Training loss: 4.505923716759946
Validation loss: 3.776955887982212

Epoch: 7| Step: 0
Training loss: 3.342439483802341
Validation loss: 3.7738876568520547

Epoch: 6| Step: 1
Training loss: 3.7723915435388826
Validation loss: 3.770722059829991

Epoch: 6| Step: 2
Training loss: 4.222789045957678
Validation loss: 3.7620013061483837

Epoch: 6| Step: 3
Training loss: 3.0854932247934985
Validation loss: 3.752570058456085

Epoch: 6| Step: 4
Training loss: 3.0946316474281974
Validation loss: 3.7496492255989224

Epoch: 6| Step: 5
Training loss: 4.979023610803965
Validation loss: 3.7395280517491942

Epoch: 6| Step: 6
Training loss: 3.443743497700446
Validation loss: 3.732128023198247

Epoch: 6| Step: 7
Training loss: 3.815282087983623
Validation loss: 3.718896521196908

Epoch: 6| Step: 8
Training loss: 3.7317453486904952
Validation loss: 3.704655834979624

Epoch: 6| Step: 9
Training loss: 3.4395288202381766
Validation loss: 3.6891092050124206

Epoch: 6| Step: 10
Training loss: 3.692751232735576
Validation loss: 3.6731639072182922

Epoch: 6| Step: 11
Training loss: 4.216562792035096
Validation loss: 3.6529336983356817

Epoch: 6| Step: 12
Training loss: 4.063449924622795
Validation loss: 3.6385359414585747

Epoch: 6| Step: 13
Training loss: 5.7559239927871
Validation loss: 3.628556745315069

Epoch: 8| Step: 0
Training loss: 4.329018621082576
Validation loss: 3.6213507807911176

Epoch: 6| Step: 1
Training loss: 3.96970698315436
Validation loss: 3.6131258452258948

Epoch: 6| Step: 2
Training loss: 3.6068484227984885
Validation loss: 3.6064753002815535

Epoch: 6| Step: 3
Training loss: 3.1379639848595904
Validation loss: 3.599834733562662

Epoch: 6| Step: 4
Training loss: 3.904040146402401
Validation loss: 3.595830505420934

Epoch: 6| Step: 5
Training loss: 3.0306078043752924
Validation loss: 3.5909576353614243

Epoch: 6| Step: 6
Training loss: 4.2476833986022005
Validation loss: 3.582702148052361

Epoch: 6| Step: 7
Training loss: 3.420203092244627
Validation loss: 3.5746979114599187

Epoch: 6| Step: 8
Training loss: 3.343194362785879
Validation loss: 3.571992404747912

Epoch: 6| Step: 9
Training loss: 3.9794776888156127
Validation loss: 3.5659063461708382

Epoch: 6| Step: 10
Training loss: 2.3081549987578858
Validation loss: 3.5621020618887487

Epoch: 6| Step: 11
Training loss: 4.3923796816279586
Validation loss: 3.5558626973081866

Epoch: 6| Step: 12
Training loss: 4.473792585589653
Validation loss: 3.548161639604905

Epoch: 6| Step: 13
Training loss: 4.388169874910749
Validation loss: 3.5391733855334992

Epoch: 9| Step: 0
Training loss: 3.2510262849625775
Validation loss: 3.5251521687800325

Epoch: 6| Step: 1
Training loss: 3.259816822452204
Validation loss: 3.517500637232889

Epoch: 6| Step: 2
Training loss: 4.18457635191367
Validation loss: 3.505594029940872

Epoch: 6| Step: 3
Training loss: 3.7381228231026045
Validation loss: 3.497353949631337

Epoch: 6| Step: 4
Training loss: 4.4895459709766525
Validation loss: 3.486787452081654

Epoch: 6| Step: 5
Training loss: 2.995452294945447
Validation loss: 3.4828562005879644

Epoch: 6| Step: 6
Training loss: 3.741904357519737
Validation loss: 3.4781392696339863

Epoch: 6| Step: 7
Training loss: 3.1873469596475243
Validation loss: 3.474563467458496

Epoch: 6| Step: 8
Training loss: 2.604818054112751
Validation loss: 3.467325082899477

Epoch: 6| Step: 9
Training loss: 4.1286664909396835
Validation loss: 3.4621133429319175

Epoch: 6| Step: 10
Training loss: 3.7016678530642344
Validation loss: 3.4644356470022797

Epoch: 6| Step: 11
Training loss: 3.712722766499183
Validation loss: 3.445894360132402

Epoch: 6| Step: 12
Training loss: 4.528360010844697
Validation loss: 3.444922753608109

Epoch: 6| Step: 13
Training loss: 3.6268220465931065
Validation loss: 3.441032052331813

Epoch: 10| Step: 0
Training loss: 3.6841804951325785
Validation loss: 3.448720241246777

Epoch: 6| Step: 1
Training loss: 3.7122987840370407
Validation loss: 3.4394043227655464

Epoch: 6| Step: 2
Training loss: 3.4549125083963887
Validation loss: 3.437582491931786

Epoch: 6| Step: 3
Training loss: 3.4698646747684636
Validation loss: 3.4350556663225915

Epoch: 6| Step: 4
Training loss: 3.4508879306739013
Validation loss: 3.4259098014968203

Epoch: 6| Step: 5
Training loss: 3.460113771806178
Validation loss: 3.4186784332475977

Epoch: 6| Step: 6
Training loss: 2.867858974399874
Validation loss: 3.4093994741297435

Epoch: 6| Step: 7
Training loss: 3.688480957933574
Validation loss: 3.4041773953772494

Epoch: 6| Step: 8
Training loss: 4.610987908020909
Validation loss: 3.399233404511795

Epoch: 6| Step: 9
Training loss: 2.175182650559133
Validation loss: 3.39485733971618

Epoch: 6| Step: 10
Training loss: 4.022162552092964
Validation loss: 3.4023103007947233

Epoch: 6| Step: 11
Training loss: 3.4737899869118376
Validation loss: 3.427265547764324

Epoch: 6| Step: 12
Training loss: 3.66951867650237
Validation loss: 3.379880474802627

Epoch: 6| Step: 13
Training loss: 5.136854278749157
Validation loss: 3.3774046176427035

Epoch: 11| Step: 0
Training loss: 3.558663829192994
Validation loss: 3.38540387298716

Epoch: 6| Step: 1
Training loss: 3.998609420341996
Validation loss: 3.386579843365329

Epoch: 6| Step: 2
Training loss: 3.869882095669997
Validation loss: 3.379585745111318

Epoch: 6| Step: 3
Training loss: 3.8648529095808177
Validation loss: 3.373674666473496

Epoch: 6| Step: 4
Training loss: 3.879007051969423
Validation loss: 3.357926436680286

Epoch: 6| Step: 5
Training loss: 3.2769156757269777
Validation loss: 3.3419582552630347

Epoch: 6| Step: 6
Training loss: 2.7184751525158717
Validation loss: 3.331751151573567

Epoch: 6| Step: 7
Training loss: 3.384830850631998
Validation loss: 3.326409048855318

Epoch: 6| Step: 8
Training loss: 3.5876673430115185
Validation loss: 3.321764964186295

Epoch: 6| Step: 9
Training loss: 4.108935198438377
Validation loss: 3.33205027395045

Epoch: 6| Step: 10
Training loss: 3.557171366692789
Validation loss: 3.3712753090918746

Epoch: 6| Step: 11
Training loss: 3.2785828422492562
Validation loss: 3.3946082898014933

Epoch: 6| Step: 12
Training loss: 3.52702172922742
Validation loss: 3.3735548698400923

Epoch: 6| Step: 13
Training loss: 3.4419065495006698
Validation loss: 3.3792644587079304

Epoch: 12| Step: 0
Training loss: 3.6152143266596997
Validation loss: 3.3850439056066146

Epoch: 6| Step: 1
Training loss: 3.689463981422619
Validation loss: 3.3779667675100336

Epoch: 6| Step: 2
Training loss: 3.8493932221073184
Validation loss: 3.3697353214477292

Epoch: 6| Step: 3
Training loss: 2.8496806584855574
Validation loss: 3.3609295456460835

Epoch: 6| Step: 4
Training loss: 3.0821602797966956
Validation loss: 3.347935694669997

Epoch: 6| Step: 5
Training loss: 3.7145293831807527
Validation loss: 3.3356882580373317

Epoch: 6| Step: 6
Training loss: 3.0766970037891284
Validation loss: 3.3179763997567258

Epoch: 6| Step: 7
Training loss: 3.593655925016983
Validation loss: 3.3050720337110335

Epoch: 6| Step: 8
Training loss: 3.546420030359952
Validation loss: 3.3012855777009262

Epoch: 6| Step: 9
Training loss: 3.796185717397999
Validation loss: 3.289463778594754

Epoch: 6| Step: 10
Training loss: 3.3243293430028125
Validation loss: 3.2819945569323794

Epoch: 6| Step: 11
Training loss: 4.568034956015004
Validation loss: 3.2757889250231123

Epoch: 6| Step: 12
Training loss: 3.1921418741768117
Validation loss: 3.2712961881408296

Epoch: 6| Step: 13
Training loss: 3.6960700067190113
Validation loss: 3.2685296706590328

Epoch: 13| Step: 0
Training loss: 3.303573817543138
Validation loss: 3.2626105768536346

Epoch: 6| Step: 1
Training loss: 2.119388576363964
Validation loss: 3.260130416432659

Epoch: 6| Step: 2
Training loss: 4.602659758489323
Validation loss: 3.253030777358561

Epoch: 6| Step: 3
Training loss: 2.6660052512389747
Validation loss: 3.2477371077677435

Epoch: 6| Step: 4
Training loss: 3.751806714022561
Validation loss: 3.245180636471639

Epoch: 6| Step: 5
Training loss: 3.527714402504779
Validation loss: 3.245203991473258

Epoch: 6| Step: 6
Training loss: 3.805765175595749
Validation loss: 3.242614249906223

Epoch: 6| Step: 7
Training loss: 2.6750468561935152
Validation loss: 3.2355780369221807

Epoch: 6| Step: 8
Training loss: 3.584205491731467
Validation loss: 3.2322940133062916

Epoch: 6| Step: 9
Training loss: 3.647878861390264
Validation loss: 3.226728045013604

Epoch: 6| Step: 10
Training loss: 3.9957729893259155
Validation loss: 3.2221240892791148

Epoch: 6| Step: 11
Training loss: 3.5629855711776215
Validation loss: 3.241830538152705

Epoch: 6| Step: 12
Training loss: 3.14734594766483
Validation loss: 3.225364261745043

Epoch: 6| Step: 13
Training loss: 3.9747718121751725
Validation loss: 3.215661398615868

Epoch: 14| Step: 0
Training loss: 3.0298880437430666
Validation loss: 3.2142308823140215

Epoch: 6| Step: 1
Training loss: 4.03701653671374
Validation loss: 3.2135967032469206

Epoch: 6| Step: 2
Training loss: 3.19577552779604
Validation loss: 3.212289580849209

Epoch: 6| Step: 3
Training loss: 3.7021553926998765
Validation loss: 3.2029268128925144

Epoch: 6| Step: 4
Training loss: 3.0359419857508354
Validation loss: 3.1939277142421285

Epoch: 6| Step: 5
Training loss: 3.5564597605972654
Validation loss: 3.1861853400809177

Epoch: 6| Step: 6
Training loss: 3.04366755755745
Validation loss: 3.1754698294227106

Epoch: 6| Step: 7
Training loss: 2.9492719430736902
Validation loss: 3.173286253758366

Epoch: 6| Step: 8
Training loss: 3.460696382067132
Validation loss: 3.171434018710864

Epoch: 6| Step: 9
Training loss: 3.6599491024126247
Validation loss: 3.174320631309932

Epoch: 6| Step: 10
Training loss: 3.7911434161872073
Validation loss: 3.1710211494005867

Epoch: 6| Step: 11
Training loss: 3.2699971841222557
Validation loss: 3.1697039995948137

Epoch: 6| Step: 12
Training loss: 3.8075531931897846
Validation loss: 3.179413074250022

Epoch: 6| Step: 13
Training loss: 3.571917617556957
Validation loss: 3.1640793204762483

Epoch: 15| Step: 0
Training loss: 2.8197801251287387
Validation loss: 3.157098573018326

Epoch: 6| Step: 1
Training loss: 3.3802301360114377
Validation loss: 3.151893585308337

Epoch: 6| Step: 2
Training loss: 3.8699534379390674
Validation loss: 3.145577494005297

Epoch: 6| Step: 3
Training loss: 3.984608961229894
Validation loss: 3.139624378947396

Epoch: 6| Step: 4
Training loss: 3.2558341846281067
Validation loss: 3.1358712718184543

Epoch: 6| Step: 5
Training loss: 3.0004891950390187
Validation loss: 3.1301211899739636

Epoch: 6| Step: 6
Training loss: 3.6811304199278334
Validation loss: 3.125697563004889

Epoch: 6| Step: 7
Training loss: 2.9513048486649796
Validation loss: 3.122968828223097

Epoch: 6| Step: 8
Training loss: 3.102704892336005
Validation loss: 3.121239413855372

Epoch: 6| Step: 9
Training loss: 3.6208203653879605
Validation loss: 3.1199213643625447

Epoch: 6| Step: 10
Training loss: 3.9790640346746136
Validation loss: 3.125912981284703

Epoch: 6| Step: 11
Training loss: 3.1306683820603896
Validation loss: 3.122170399018601

Epoch: 6| Step: 12
Training loss: 3.2300697458490455
Validation loss: 3.1162667837263913

Epoch: 6| Step: 13
Training loss: 3.3480993487294253
Validation loss: 3.118299777361861

Epoch: 16| Step: 0
Training loss: 3.9937491451256544
Validation loss: 3.1183197845974755

Epoch: 6| Step: 1
Training loss: 3.1783663467695704
Validation loss: 3.111310892446384

Epoch: 6| Step: 2
Training loss: 3.498979419683705
Validation loss: 3.1104996629582224

Epoch: 6| Step: 3
Training loss: 2.919240814698935
Validation loss: 3.107752521327349

Epoch: 6| Step: 4
Training loss: 2.8921603687400776
Validation loss: 3.1082982135180774

Epoch: 6| Step: 5
Training loss: 3.441150183790638
Validation loss: 3.1064114599446557

Epoch: 6| Step: 6
Training loss: 3.823022423441207
Validation loss: 3.105472566397565

Epoch: 6| Step: 7
Training loss: 3.7020781119672415
Validation loss: 3.1046991535045283

Epoch: 6| Step: 8
Training loss: 3.5103060349294766
Validation loss: 3.103742223741471

Epoch: 6| Step: 9
Training loss: 3.4327467914277654
Validation loss: 3.100078766477444

Epoch: 6| Step: 10
Training loss: 2.7605058955520168
Validation loss: 3.0977545639612334

Epoch: 6| Step: 11
Training loss: 3.7278331453696794
Validation loss: 3.0976368326340133

Epoch: 6| Step: 12
Training loss: 3.103140556857326
Validation loss: 3.0962537617458348

Epoch: 6| Step: 13
Training loss: 2.8327312577765262
Validation loss: 3.096284984768353

Epoch: 17| Step: 0
Training loss: 3.2569868839176674
Validation loss: 3.0956839073855056

Epoch: 6| Step: 1
Training loss: 3.147841631442965
Validation loss: 3.093920820137363

Epoch: 6| Step: 2
Training loss: 3.238580448331105
Validation loss: 3.0963593515899346

Epoch: 6| Step: 3
Training loss: 2.945861927057365
Validation loss: 3.0903339172723263

Epoch: 6| Step: 4
Training loss: 3.8950180315768237
Validation loss: 3.0900271130426415

Epoch: 6| Step: 5
Training loss: 3.5638381051178163
Validation loss: 3.0897665438730533

Epoch: 6| Step: 6
Training loss: 3.5197152313004305
Validation loss: 3.087289328260927

Epoch: 6| Step: 7
Training loss: 3.399059159870897
Validation loss: 3.08681425301185

Epoch: 6| Step: 8
Training loss: 3.6902235932049807
Validation loss: 3.084856713494647

Epoch: 6| Step: 9
Training loss: 2.368775694212043
Validation loss: 3.0867085401326455

Epoch: 6| Step: 10
Training loss: 3.3391289553993166
Validation loss: 3.085101320546072

Epoch: 6| Step: 11
Training loss: 3.3908394600684826
Validation loss: 3.0844557370227794

Epoch: 6| Step: 12
Training loss: 3.7573076888545587
Validation loss: 3.0848564608583473

Epoch: 6| Step: 13
Training loss: 3.4232293501392492
Validation loss: 3.083941855796638

Epoch: 18| Step: 0
Training loss: 3.22222978949115
Validation loss: 3.0828958038512093

Epoch: 6| Step: 1
Training loss: 3.478074745713148
Validation loss: 3.085782738311322

Epoch: 6| Step: 2
Training loss: 3.3059215360862377
Validation loss: 3.0846683258366565

Epoch: 6| Step: 3
Training loss: 3.540153958264778
Validation loss: 3.0840562080039806

Epoch: 6| Step: 4
Training loss: 3.3568267383561476
Validation loss: 3.0820415826306613

Epoch: 6| Step: 5
Training loss: 3.9120166175270916
Validation loss: 3.078186079524572

Epoch: 6| Step: 6
Training loss: 3.2121443139669177
Validation loss: 3.075258791058345

Epoch: 6| Step: 7
Training loss: 2.50960070591419
Validation loss: 3.0742251786528065

Epoch: 6| Step: 8
Training loss: 2.8389842583682454
Validation loss: 3.0732804745069333

Epoch: 6| Step: 9
Training loss: 3.2248780515813
Validation loss: 3.0708465575107953

Epoch: 6| Step: 10
Training loss: 3.643672077268348
Validation loss: 3.0740784937804886

Epoch: 6| Step: 11
Training loss: 3.2412743442973166
Validation loss: 3.0708729339110827

Epoch: 6| Step: 12
Training loss: 3.483219930332974
Validation loss: 3.0720117676078633

Epoch: 6| Step: 13
Training loss: 4.1201578098924765
Validation loss: 3.0689912301592015

Epoch: 19| Step: 0
Training loss: 2.8693437082441062
Validation loss: 3.0660757302228485

Epoch: 6| Step: 1
Training loss: 3.718523034614679
Validation loss: 3.0635337181590847

Epoch: 6| Step: 2
Training loss: 3.579153387883652
Validation loss: 3.0636312903634186

Epoch: 6| Step: 3
Training loss: 2.8773638088367135
Validation loss: 3.0632489033539176

Epoch: 6| Step: 4
Training loss: 3.6552039060061237
Validation loss: 3.059972514088667

Epoch: 6| Step: 5
Training loss: 3.2581555668435946
Validation loss: 3.0615626682283286

Epoch: 6| Step: 6
Training loss: 2.967398566783773
Validation loss: 3.060763106990513

Epoch: 6| Step: 7
Training loss: 3.5226554594802564
Validation loss: 3.0551916249390754

Epoch: 6| Step: 8
Training loss: 3.622621084523427
Validation loss: 3.056744157189085

Epoch: 6| Step: 9
Training loss: 3.2350469066397136
Validation loss: 3.057833550367771

Epoch: 6| Step: 10
Training loss: 2.8357093235835875
Validation loss: 3.054388260670075

Epoch: 6| Step: 11
Training loss: 3.7792134751376008
Validation loss: 3.055247780994145

Epoch: 6| Step: 12
Training loss: 3.2247044568337326
Validation loss: 3.054683986905495

Epoch: 6| Step: 13
Training loss: 3.510302774787199
Validation loss: 3.051873987204046

Epoch: 20| Step: 0
Training loss: 2.4733493309668946
Validation loss: 3.0539475091155355

Epoch: 6| Step: 1
Training loss: 3.4813366973326945
Validation loss: 3.0571282718657784

Epoch: 6| Step: 2
Training loss: 3.8156336428882587
Validation loss: 3.0596579213053348

Epoch: 6| Step: 3
Training loss: 3.393498341483659
Validation loss: 3.0525045759724025

Epoch: 6| Step: 4
Training loss: 3.799847228342244
Validation loss: 3.0469576024842384

Epoch: 6| Step: 5
Training loss: 2.7028561496992025
Validation loss: 3.0465599627103774

Epoch: 6| Step: 6
Training loss: 2.5572757966480797
Validation loss: 3.047980972713072

Epoch: 6| Step: 7
Training loss: 3.1493491090685732
Validation loss: 3.0477169382868925

Epoch: 6| Step: 8
Training loss: 3.650199905564891
Validation loss: 3.0460726497434734

Epoch: 6| Step: 9
Training loss: 3.6390752154169492
Validation loss: 3.042546334854826

Epoch: 6| Step: 10
Training loss: 4.342909916937129
Validation loss: 3.043584734381541

Epoch: 6| Step: 11
Training loss: 2.8586258037028394
Validation loss: 3.0408104368342586

Epoch: 6| Step: 12
Training loss: 3.0994843023265424
Validation loss: 3.047988407981132

Epoch: 6| Step: 13
Training loss: 2.9192169665432384
Validation loss: 3.0567542440179016

Epoch: 21| Step: 0
Training loss: 3.1196339121032186
Validation loss: 3.052382602373672

Epoch: 6| Step: 1
Training loss: 3.457353721277058
Validation loss: 3.0503080713079602

Epoch: 6| Step: 2
Training loss: 3.8599783854299403
Validation loss: 3.056384823964149

Epoch: 6| Step: 3
Training loss: 2.8646365259029127
Validation loss: 3.0513276780203658

Epoch: 6| Step: 4
Training loss: 3.363066025071357
Validation loss: 3.0467854686758105

Epoch: 6| Step: 5
Training loss: 2.864734400609445
Validation loss: 3.0410203223104877

Epoch: 6| Step: 6
Training loss: 3.6143342004643793
Validation loss: 3.037381801198564

Epoch: 6| Step: 7
Training loss: 3.02961120352012
Validation loss: 3.0375845430411883

Epoch: 6| Step: 8
Training loss: 2.5594419514861717
Validation loss: 3.0369346958554044

Epoch: 6| Step: 9
Training loss: 2.985258441005523
Validation loss: 3.031545910665264

Epoch: 6| Step: 10
Training loss: 3.411046282317539
Validation loss: 3.031576480923619

Epoch: 6| Step: 11
Training loss: 4.452422933281007
Validation loss: 3.0341117128839117

Epoch: 6| Step: 12
Training loss: 2.956375674264076
Validation loss: 3.0309979835435583

Epoch: 6| Step: 13
Training loss: 3.675009700217388
Validation loss: 3.0289332936464395

Epoch: 22| Step: 0
Training loss: 3.063223305747399
Validation loss: 3.0287042814127987

Epoch: 6| Step: 1
Training loss: 3.4938043525303137
Validation loss: 3.0272163165816877

Epoch: 6| Step: 2
Training loss: 3.716133800220678
Validation loss: 3.029074319095134

Epoch: 6| Step: 3
Training loss: 3.050738423495018
Validation loss: 3.0300273571351766

Epoch: 6| Step: 4
Training loss: 2.8830496837768815
Validation loss: 3.02911196172917

Epoch: 6| Step: 5
Training loss: 3.4254585905811403
Validation loss: 3.0475806761892787

Epoch: 6| Step: 6
Training loss: 2.9428081844347207
Validation loss: 3.027476783817134

Epoch: 6| Step: 7
Training loss: 3.7742709232641563
Validation loss: 3.0244891123843525

Epoch: 6| Step: 8
Training loss: 3.46484375
Validation loss: 3.0231825240451076

Epoch: 6| Step: 9
Training loss: 3.092718087156664
Validation loss: 3.0240167349806817

Epoch: 6| Step: 10
Training loss: 2.5421259314004554
Validation loss: 3.023472822548507

Epoch: 6| Step: 11
Training loss: 3.6027812757420348
Validation loss: 3.019667383797302

Epoch: 6| Step: 12
Training loss: 3.935220936797721
Validation loss: 3.0207951346341884

Epoch: 6| Step: 13
Training loss: 2.9190830212267778
Validation loss: 3.0236084634726574

Epoch: 23| Step: 0
Training loss: 3.4910799527438776
Validation loss: 3.0291651838255285

Epoch: 6| Step: 1
Training loss: 3.975023252791044
Validation loss: 3.025232133744439

Epoch: 6| Step: 2
Training loss: 3.4826521783948956
Validation loss: 3.0221207237205476

Epoch: 6| Step: 3
Training loss: 2.874796818726917
Validation loss: 3.0182029743299075

Epoch: 6| Step: 4
Training loss: 3.3408642732236298
Validation loss: 3.020972041141072

Epoch: 6| Step: 5
Training loss: 3.053884259152324
Validation loss: 3.0215044276874226

Epoch: 6| Step: 6
Training loss: 2.9471355432277373
Validation loss: 3.032345249898915

Epoch: 6| Step: 7
Training loss: 3.7686083360556824
Validation loss: 3.041188272526547

Epoch: 6| Step: 8
Training loss: 3.2584145993556355
Validation loss: 3.0500298182393086

Epoch: 6| Step: 9
Training loss: 3.2790729384900086
Validation loss: 3.036006136423786

Epoch: 6| Step: 10
Training loss: 2.649913365369446
Validation loss: 3.0187446669094067

Epoch: 6| Step: 11
Training loss: 3.6521953042610287
Validation loss: 3.0181930916255695

Epoch: 6| Step: 12
Training loss: 3.438077704696017
Validation loss: 3.0156903088482685

Epoch: 6| Step: 13
Training loss: 2.2904751425482863
Validation loss: 3.0103101132763097

Epoch: 24| Step: 0
Training loss: 3.3401201457268908
Validation loss: 3.017281794398344

Epoch: 6| Step: 1
Training loss: 3.772526917459509
Validation loss: 3.0193196771394053

Epoch: 6| Step: 2
Training loss: 2.8053291458157856
Validation loss: 3.019317654632784

Epoch: 6| Step: 3
Training loss: 4.204755162063588
Validation loss: 3.0086085262989086

Epoch: 6| Step: 4
Training loss: 2.852253534901124
Validation loss: 3.0067017312098523

Epoch: 6| Step: 5
Training loss: 3.587373599706625
Validation loss: 3.0086166809017487

Epoch: 6| Step: 6
Training loss: 3.0982671570614886
Validation loss: 3.0074348288242683

Epoch: 6| Step: 7
Training loss: 2.805731958775358
Validation loss: 3.0187834412892647

Epoch: 6| Step: 8
Training loss: 2.938610110634655
Validation loss: 3.0437297109413777

Epoch: 6| Step: 9
Training loss: 3.11693264103431
Validation loss: 3.064782933093567

Epoch: 6| Step: 10
Training loss: 3.6314315304053264
Validation loss: 3.042357110316379

Epoch: 6| Step: 11
Training loss: 3.3737308800442807
Validation loss: 3.0073229089362226

Epoch: 6| Step: 12
Training loss: 3.3701419481215154
Validation loss: 3.0006916417882104

Epoch: 6| Step: 13
Training loss: 2.812525346429842
Validation loss: 3.0001671669301895

Epoch: 25| Step: 0
Training loss: 3.280169209093214
Validation loss: 3.012419549167918

Epoch: 6| Step: 1
Training loss: 3.7100063079204557
Validation loss: 3.0297359875753367

Epoch: 6| Step: 2
Training loss: 3.406167685537803
Validation loss: 2.998619284843476

Epoch: 6| Step: 3
Training loss: 2.922132348135856
Validation loss: 2.996750497110025

Epoch: 6| Step: 4
Training loss: 3.421537896539159
Validation loss: 3.0009150049677333

Epoch: 6| Step: 5
Training loss: 3.048670782394962
Validation loss: 3.0314569515738246

Epoch: 6| Step: 6
Training loss: 2.9205260401294524
Validation loss: 3.1149859353225

Epoch: 6| Step: 7
Training loss: 3.3262593229292907
Validation loss: 3.0373831989115265

Epoch: 6| Step: 8
Training loss: 3.4784613406418425
Validation loss: 3.008234573537073

Epoch: 6| Step: 9
Training loss: 3.370578837051189
Validation loss: 2.99616739926146

Epoch: 6| Step: 10
Training loss: 3.239427389007938
Validation loss: 2.996282333465215

Epoch: 6| Step: 11
Training loss: 3.2102244529803805
Validation loss: 3.004273995093998

Epoch: 6| Step: 12
Training loss: 2.9241014453495473
Validation loss: 3.01854774366359

Epoch: 6| Step: 13
Training loss: 4.327267558413129
Validation loss: 3.0162265370399153

Epoch: 26| Step: 0
Training loss: 3.4024722647675185
Validation loss: 3.0014974743213174

Epoch: 6| Step: 1
Training loss: 2.955536680073645
Validation loss: 3.034710519827424

Epoch: 6| Step: 2
Training loss: 3.4178868572778756
Validation loss: 3.0357199026586477

Epoch: 6| Step: 3
Training loss: 3.5049165525855788
Validation loss: 3.001118090999781

Epoch: 6| Step: 4
Training loss: 3.461509226814127
Validation loss: 2.987092328832949

Epoch: 6| Step: 5
Training loss: 4.069248170137331
Validation loss: 2.984054575716813

Epoch: 6| Step: 6
Training loss: 3.3185220356322125
Validation loss: 2.9857169099461065

Epoch: 6| Step: 7
Training loss: 3.8160482685787085
Validation loss: 2.988394260488056

Epoch: 6| Step: 8
Training loss: 3.4632052533059428
Validation loss: 2.988711432599283

Epoch: 6| Step: 9
Training loss: 3.2224209786278664
Validation loss: 2.9909775361307

Epoch: 6| Step: 10
Training loss: 2.4341725844333397
Validation loss: 2.9917457691678093

Epoch: 6| Step: 11
Training loss: 2.5619556500112393
Validation loss: 2.9911445259257836

Epoch: 6| Step: 12
Training loss: 2.910163951069928
Validation loss: 2.9938222075540333

Epoch: 6| Step: 13
Training loss: 2.9282079597372777
Validation loss: 2.9925356443674884

Epoch: 27| Step: 0
Training loss: 3.126464043038805
Validation loss: 2.9899080853367423

Epoch: 6| Step: 1
Training loss: 3.414398386339416
Validation loss: 2.9837908738774064

Epoch: 6| Step: 2
Training loss: 3.2086177716355633
Validation loss: 2.9922106843247924

Epoch: 6| Step: 3
Training loss: 3.371041979342479
Validation loss: 2.9931694567229146

Epoch: 6| Step: 4
Training loss: 3.505661608715156
Validation loss: 2.9865807244996443

Epoch: 6| Step: 5
Training loss: 3.1360201503047898
Validation loss: 2.9791692390548397

Epoch: 6| Step: 6
Training loss: 3.0328004941943427
Validation loss: 2.9792369321084644

Epoch: 6| Step: 7
Training loss: 3.8974226431421757
Validation loss: 2.975364501896004

Epoch: 6| Step: 8
Training loss: 3.5185396446649713
Validation loss: 2.9695974180003737

Epoch: 6| Step: 9
Training loss: 3.130265187251248
Validation loss: 2.968990837306537

Epoch: 6| Step: 10
Training loss: 2.9805952972704697
Validation loss: 2.968005389974167

Epoch: 6| Step: 11
Training loss: 3.2183203549339865
Validation loss: 2.96837298466335

Epoch: 6| Step: 12
Training loss: 2.928886609279972
Validation loss: 2.9677597009029886

Epoch: 6| Step: 13
Training loss: 3.0689952247361227
Validation loss: 2.9670718533585134

Epoch: 28| Step: 0
Training loss: 3.121794620735441
Validation loss: 2.9657086132578434

Epoch: 6| Step: 1
Training loss: 3.647410213419052
Validation loss: 2.9637369763063908

Epoch: 6| Step: 2
Training loss: 3.406199463635648
Validation loss: 2.963778523827271

Epoch: 6| Step: 3
Training loss: 3.9760945762423248
Validation loss: 2.963306313777291

Epoch: 6| Step: 4
Training loss: 3.397725348560488
Validation loss: 2.9633380119146255

Epoch: 6| Step: 5
Training loss: 3.5513064223751556
Validation loss: 2.9632852945416164

Epoch: 6| Step: 6
Training loss: 3.088303212078815
Validation loss: 2.962672285002284

Epoch: 6| Step: 7
Training loss: 2.7730626672321135
Validation loss: 2.966767387079141

Epoch: 6| Step: 8
Training loss: 3.1166147265126667
Validation loss: 2.971537466072647

Epoch: 6| Step: 9
Training loss: 2.8078101156539854
Validation loss: 2.9668715634598044

Epoch: 6| Step: 10
Training loss: 2.507114396420858
Validation loss: 2.9645370702434497

Epoch: 6| Step: 11
Training loss: 2.8943968212711217
Validation loss: 2.9644858114650434

Epoch: 6| Step: 12
Training loss: 3.445952686855109
Validation loss: 2.960912049960378

Epoch: 6| Step: 13
Training loss: 3.634321658135796
Validation loss: 2.9603851467245215

Epoch: 29| Step: 0
Training loss: 3.2742047924198445
Validation loss: 2.9631784510878636

Epoch: 6| Step: 1
Training loss: 3.7695249251080356
Validation loss: 2.9603393272554275

Epoch: 6| Step: 2
Training loss: 2.893297434406859
Validation loss: 2.9586044983347293

Epoch: 6| Step: 3
Training loss: 3.2302321286244062
Validation loss: 2.957368531909383

Epoch: 6| Step: 4
Training loss: 2.979747279927257
Validation loss: 2.95506084534061

Epoch: 6| Step: 5
Training loss: 2.7920410322764826
Validation loss: 2.9568384551215794

Epoch: 6| Step: 6
Training loss: 3.3206975018056877
Validation loss: 2.9509438084084856

Epoch: 6| Step: 7
Training loss: 3.1568272128931905
Validation loss: 2.9458837389591443

Epoch: 6| Step: 8
Training loss: 3.5294834545745815
Validation loss: 2.949224575781004

Epoch: 6| Step: 9
Training loss: 2.81521153605494
Validation loss: 2.947893119488091

Epoch: 6| Step: 10
Training loss: 3.696685987398539
Validation loss: 2.947821073171778

Epoch: 6| Step: 11
Training loss: 3.390123180750821
Validation loss: 2.9485036283813906

Epoch: 6| Step: 12
Training loss: 3.2745030382800193
Validation loss: 2.9494403953852224

Epoch: 6| Step: 13
Training loss: 3.0728255608625483
Validation loss: 2.951007470794203

Epoch: 30| Step: 0
Training loss: 3.5048418613952714
Validation loss: 2.9492311864899143

Epoch: 6| Step: 1
Training loss: 3.655832641777725
Validation loss: 2.9499579828995426

Epoch: 6| Step: 2
Training loss: 3.0573757664790917
Validation loss: 2.9483312818691823

Epoch: 6| Step: 3
Training loss: 3.0505766464180812
Validation loss: 2.950590260448421

Epoch: 6| Step: 4
Training loss: 3.529647058235836
Validation loss: 2.9504968134116645

Epoch: 6| Step: 5
Training loss: 2.916265151225275
Validation loss: 2.9483842979235306

Epoch: 6| Step: 6
Training loss: 3.3793383371668924
Validation loss: 2.9453853109549404

Epoch: 6| Step: 7
Training loss: 3.0198432790752205
Validation loss: 2.9459010376387416

Epoch: 6| Step: 8
Training loss: 2.708444994067384
Validation loss: 2.9419338231081142

Epoch: 6| Step: 9
Training loss: 3.545212410614765
Validation loss: 2.952385424300141

Epoch: 6| Step: 10
Training loss: 3.4333701554579936
Validation loss: 2.9471252699816546

Epoch: 6| Step: 11
Training loss: 3.3061748070630506
Validation loss: 2.94722606280887

Epoch: 6| Step: 12
Training loss: 3.1264675509149025
Validation loss: 2.9501430554653547

Epoch: 6| Step: 13
Training loss: 2.5313485208812083
Validation loss: 2.9441338614142114

Epoch: 31| Step: 0
Training loss: 3.36769443599163
Validation loss: 2.9420072257024437

Epoch: 6| Step: 1
Training loss: 3.3395533385251523
Validation loss: 2.9478785371301983

Epoch: 6| Step: 2
Training loss: 3.2862322085172098
Validation loss: 2.9402863433808863

Epoch: 6| Step: 3
Training loss: 3.2187994795764583
Validation loss: 2.940242301552813

Epoch: 6| Step: 4
Training loss: 3.299405975051874
Validation loss: 2.9426419843678264

Epoch: 6| Step: 5
Training loss: 2.4959232469091814
Validation loss: 2.9397411816478125

Epoch: 6| Step: 6
Training loss: 3.418746144852217
Validation loss: 2.938434395490807

Epoch: 6| Step: 7
Training loss: 3.524213954860543
Validation loss: 2.938522206392756

Epoch: 6| Step: 8
Training loss: 2.5296050955420077
Validation loss: 2.9377128133003234

Epoch: 6| Step: 9
Training loss: 2.780570129278427
Validation loss: 2.9366642381142807

Epoch: 6| Step: 10
Training loss: 3.211915992464835
Validation loss: 2.9491244345501837

Epoch: 6| Step: 11
Training loss: 3.6363535696670604
Validation loss: 2.9557009633229194

Epoch: 6| Step: 12
Training loss: 3.587303682598065
Validation loss: 2.9345739606513472

Epoch: 6| Step: 13
Training loss: 3.430409696483786
Validation loss: 2.9291763299436533

Epoch: 32| Step: 0
Training loss: 2.8706521038401256
Validation loss: 2.932134076580506

Epoch: 6| Step: 1
Training loss: 3.183373566484767
Validation loss: 2.930959590256327

Epoch: 6| Step: 2
Training loss: 2.8256407728389905
Validation loss: 2.9374862213265436

Epoch: 6| Step: 3
Training loss: 3.444995822322621
Validation loss: 2.939862354101505

Epoch: 6| Step: 4
Training loss: 3.344432155154248
Validation loss: 2.933571095167014

Epoch: 6| Step: 5
Training loss: 3.184726780261847
Validation loss: 2.9319361015394096

Epoch: 6| Step: 6
Training loss: 2.7342176991585
Validation loss: 2.933276239545211

Epoch: 6| Step: 7
Training loss: 3.9894532397434626
Validation loss: 2.930627287173238

Epoch: 6| Step: 8
Training loss: 3.3595711584263657
Validation loss: 2.933642392981198

Epoch: 6| Step: 9
Training loss: 2.5965832781674814
Validation loss: 2.936449369637383

Epoch: 6| Step: 10
Training loss: 3.0123505677955777
Validation loss: 2.9387522140229883

Epoch: 6| Step: 11
Training loss: 3.764293767745187
Validation loss: 2.935548280154464

Epoch: 6| Step: 12
Training loss: 3.501399441641407
Validation loss: 2.9298183862031797

Epoch: 6| Step: 13
Training loss: 2.793532436015257
Validation loss: 2.925424135258254

Epoch: 33| Step: 0
Training loss: 3.7261983185683714
Validation loss: 2.9246786565602356

Epoch: 6| Step: 1
Training loss: 3.6939261095952385
Validation loss: 2.9241865173811066

Epoch: 6| Step: 2
Training loss: 2.9661014990079138
Validation loss: 2.923561832805536

Epoch: 6| Step: 3
Training loss: 2.3607042622812027
Validation loss: 2.919463656796226

Epoch: 6| Step: 4
Training loss: 3.1351255026097853
Validation loss: 2.92368207994175

Epoch: 6| Step: 5
Training loss: 3.070392326113209
Validation loss: 2.924007242951335

Epoch: 6| Step: 6
Training loss: 2.170759175132824
Validation loss: 2.919933707547691

Epoch: 6| Step: 7
Training loss: 3.6616082990529395
Validation loss: 2.920137513614757

Epoch: 6| Step: 8
Training loss: 2.317051300758505
Validation loss: 2.9190423727188524

Epoch: 6| Step: 9
Training loss: 3.6479457875121897
Validation loss: 2.9188113845800028

Epoch: 6| Step: 10
Training loss: 3.5817865685413204
Validation loss: 2.9228927281424246

Epoch: 6| Step: 11
Training loss: 3.7023421478107026
Validation loss: 2.9214557555091267

Epoch: 6| Step: 12
Training loss: 3.290859863941946
Validation loss: 2.918589407077286

Epoch: 6| Step: 13
Training loss: 2.7659368824077273
Validation loss: 2.92644763031671

Epoch: 34| Step: 0
Training loss: 3.5364858245155615
Validation loss: 2.932070723993247

Epoch: 6| Step: 1
Training loss: 2.999540770668054
Validation loss: 2.9331491680541077

Epoch: 6| Step: 2
Training loss: 2.888215581566838
Validation loss: 2.9354589558810305

Epoch: 6| Step: 3
Training loss: 3.1967928192523885
Validation loss: 2.9337172456506915

Epoch: 6| Step: 4
Training loss: 3.2110770907537662
Validation loss: 2.919811696639251

Epoch: 6| Step: 5
Training loss: 3.2138744575559675
Validation loss: 2.912023494997996

Epoch: 6| Step: 6
Training loss: 2.6880583959264888
Validation loss: 2.912088917632962

Epoch: 6| Step: 7
Training loss: 3.740962773802432
Validation loss: 2.913222782718901

Epoch: 6| Step: 8
Training loss: 3.048490281970336
Validation loss: 2.911127817543364

Epoch: 6| Step: 9
Training loss: 2.8671399354237592
Validation loss: 2.91344605696233

Epoch: 6| Step: 10
Training loss: 3.4353442281408006
Validation loss: 2.909489636445881

Epoch: 6| Step: 11
Training loss: 3.7758806426694087
Validation loss: 2.9093860479957767

Epoch: 6| Step: 12
Training loss: 3.3534385570097522
Validation loss: 2.9147585148396233

Epoch: 6| Step: 13
Training loss: 2.1444459769661304
Validation loss: 2.9103869473157906

Epoch: 35| Step: 0
Training loss: 3.1520030843264597
Validation loss: 2.920035388043495

Epoch: 6| Step: 1
Training loss: 3.4516195061993975
Validation loss: 2.9229009359412093

Epoch: 6| Step: 2
Training loss: 3.810440257510238
Validation loss: 2.91767729435227

Epoch: 6| Step: 3
Training loss: 2.8329837433806055
Validation loss: 2.909554093966992

Epoch: 6| Step: 4
Training loss: 4.172628156134945
Validation loss: 2.9062487138790973

Epoch: 6| Step: 5
Training loss: 2.7380705356470845
Validation loss: 2.9087173956056787

Epoch: 6| Step: 6
Training loss: 2.4496348634445257
Validation loss: 2.9007758768494996

Epoch: 6| Step: 7
Training loss: 2.8096827490156193
Validation loss: 2.9033416660837688

Epoch: 6| Step: 8
Training loss: 2.807639011464093
Validation loss: 2.898922791731713

Epoch: 6| Step: 9
Training loss: 3.0628104539110668
Validation loss: 2.9016764681162517

Epoch: 6| Step: 10
Training loss: 3.647830234609641
Validation loss: 2.8987206319458534

Epoch: 6| Step: 11
Training loss: 3.6742289039103264
Validation loss: 2.8985665425325546

Epoch: 6| Step: 12
Training loss: 2.3983800427640336
Validation loss: 2.8962412579535624

Epoch: 6| Step: 13
Training loss: 3.129513647056721
Validation loss: 2.894881313673877

Epoch: 36| Step: 0
Training loss: 3.2143708596229774
Validation loss: 2.8985473657983594

Epoch: 6| Step: 1
Training loss: 3.2747497113515514
Validation loss: 2.8959530209335402

Epoch: 6| Step: 2
Training loss: 2.5911878317236017
Validation loss: 2.8940212263243956

Epoch: 6| Step: 3
Training loss: 2.0737137404221384
Validation loss: 2.896140179622544

Epoch: 6| Step: 4
Training loss: 3.3885100488197093
Validation loss: 2.8956052333693396

Epoch: 6| Step: 5
Training loss: 2.87320138812716
Validation loss: 2.894503703318493

Epoch: 6| Step: 6
Training loss: 4.039131916563792
Validation loss: 2.89672514140266

Epoch: 6| Step: 7
Training loss: 3.8491854809267307
Validation loss: 2.916184392220378

Epoch: 6| Step: 8
Training loss: 3.4473334027508393
Validation loss: 2.943918148286277

Epoch: 6| Step: 9
Training loss: 3.0666477375552024
Validation loss: 2.904267009367466

Epoch: 6| Step: 10
Training loss: 3.956283091908403
Validation loss: 2.917414365172213

Epoch: 6| Step: 11
Training loss: 2.6821276173223056
Validation loss: 2.8875957736819133

Epoch: 6| Step: 12
Training loss: 2.4726302159100433
Validation loss: 2.8915784563189626

Epoch: 6| Step: 13
Training loss: 3.1209843584161896
Validation loss: 2.8916099406836415

Epoch: 37| Step: 0
Training loss: 2.8236615276281647
Validation loss: 2.892470827908777

Epoch: 6| Step: 1
Training loss: 2.701676614622627
Validation loss: 2.9030492037835667

Epoch: 6| Step: 2
Training loss: 3.6309028446412777
Validation loss: 2.9039771694921104

Epoch: 6| Step: 3
Training loss: 3.5388434133863247
Validation loss: 2.9111695681426477

Epoch: 6| Step: 4
Training loss: 2.8559825346276444
Validation loss: 2.9291352989967714

Epoch: 6| Step: 5
Training loss: 3.037788653688729
Validation loss: 2.927143443283069

Epoch: 6| Step: 6
Training loss: 2.9727751097808457
Validation loss: 2.9212645701958424

Epoch: 6| Step: 7
Training loss: 2.8099687841996164
Validation loss: 2.894856280514607

Epoch: 6| Step: 8
Training loss: 3.8186768070580017
Validation loss: 2.8989472985275477

Epoch: 6| Step: 9
Training loss: 3.426391408034798
Validation loss: 2.9008312821033604

Epoch: 6| Step: 10
Training loss: 3.62328877014251
Validation loss: 2.906540698119467

Epoch: 6| Step: 11
Training loss: 2.6328253590074513
Validation loss: 2.909967113712604

Epoch: 6| Step: 12
Training loss: 3.28678848051179
Validation loss: 2.9203274818192853

Epoch: 6| Step: 13
Training loss: 3.514393637436618
Validation loss: 2.9207171583624176

Epoch: 38| Step: 0
Training loss: 2.8621619145665593
Validation loss: 2.914148437795249

Epoch: 6| Step: 1
Training loss: 2.950700359937576
Validation loss: 2.8946122854285226

Epoch: 6| Step: 2
Training loss: 3.4185151627971355
Validation loss: 2.8913451145034648

Epoch: 6| Step: 3
Training loss: 3.512975889935979
Validation loss: 2.886915014600558

Epoch: 6| Step: 4
Training loss: 3.6684323018953022
Validation loss: 2.8864787041057394

Epoch: 6| Step: 5
Training loss: 2.5125871405981366
Validation loss: 2.8828179584234404

Epoch: 6| Step: 6
Training loss: 2.495819219974954
Validation loss: 2.882056546360899

Epoch: 6| Step: 7
Training loss: 2.1612572511338426
Validation loss: 2.8834159231322105

Epoch: 6| Step: 8
Training loss: 3.2126144151313984
Validation loss: 2.88331489132682

Epoch: 6| Step: 9
Training loss: 3.5113216935223113
Validation loss: 2.8843432903985438

Epoch: 6| Step: 10
Training loss: 3.994524546035104
Validation loss: 2.884372192661597

Epoch: 6| Step: 11
Training loss: 3.1924382272358534
Validation loss: 2.8856204428764483

Epoch: 6| Step: 12
Training loss: 3.018621349555082
Validation loss: 2.8789954509009807

Epoch: 6| Step: 13
Training loss: 3.7059235761969385
Validation loss: 2.8758199128094866

Epoch: 39| Step: 0
Training loss: 3.407001657407742
Validation loss: 2.8753431292877716

Epoch: 6| Step: 1
Training loss: 3.196350227607553
Validation loss: 2.874131335856276

Epoch: 6| Step: 2
Training loss: 2.7761372924900796
Validation loss: 2.8743582219209025

Epoch: 6| Step: 3
Training loss: 3.0944177696802653
Validation loss: 2.8741528822171873

Epoch: 6| Step: 4
Training loss: 3.637784709471997
Validation loss: 2.8693313775915144

Epoch: 6| Step: 5
Training loss: 3.194501480109361
Validation loss: 2.870045239666283

Epoch: 6| Step: 6
Training loss: 2.5901048163336413
Validation loss: 2.871540809879496

Epoch: 6| Step: 7
Training loss: 3.8679035795358105
Validation loss: 2.866476953509994

Epoch: 6| Step: 8
Training loss: 3.2902713828353245
Validation loss: 2.870414781625651

Epoch: 6| Step: 9
Training loss: 2.967566967202928
Validation loss: 2.8712226241057572

Epoch: 6| Step: 10
Training loss: 3.729060265641025
Validation loss: 2.867923892922133

Epoch: 6| Step: 11
Training loss: 3.1347233374289476
Validation loss: 2.866623679897852

Epoch: 6| Step: 12
Training loss: 2.354064218998277
Validation loss: 2.870913317604528

Epoch: 6| Step: 13
Training loss: 2.5144308347900752
Validation loss: 2.8705857493346723

Epoch: 40| Step: 0
Training loss: 3.3874215317537706
Validation loss: 2.8783428006804694

Epoch: 6| Step: 1
Training loss: 2.7686216854217016
Validation loss: 2.8646921352333843

Epoch: 6| Step: 2
Training loss: 2.5332202543151587
Validation loss: 2.8663035369050878

Epoch: 6| Step: 3
Training loss: 2.7992305106986755
Validation loss: 2.8650055396116962

Epoch: 6| Step: 4
Training loss: 3.4796256640129717
Validation loss: 2.865684941520455

Epoch: 6| Step: 5
Training loss: 3.5763440093318057
Validation loss: 2.8712468753597893

Epoch: 6| Step: 6
Training loss: 3.141372212204461
Validation loss: 2.8730633826372123

Epoch: 6| Step: 7
Training loss: 2.9041491062357663
Validation loss: 2.861972602843355

Epoch: 6| Step: 8
Training loss: 3.240472178962034
Validation loss: 2.8684824615284796

Epoch: 6| Step: 9
Training loss: 3.3322453312674782
Validation loss: 2.8609139331058824

Epoch: 6| Step: 10
Training loss: 3.5291194733966322
Validation loss: 2.858553112842153

Epoch: 6| Step: 11
Training loss: 3.4030385408374095
Validation loss: 2.8581724183700454

Epoch: 6| Step: 12
Training loss: 2.8945875895959294
Validation loss: 2.8541998080227775

Epoch: 6| Step: 13
Training loss: 3.183807178668322
Validation loss: 2.8579041546422714

Epoch: 41| Step: 0
Training loss: 2.650859794048919
Validation loss: 2.85525284960087

Epoch: 6| Step: 1
Training loss: 2.6560981258282457
Validation loss: 2.8605605555233007

Epoch: 6| Step: 2
Training loss: 3.5835534109502682
Validation loss: 2.8869627240128524

Epoch: 6| Step: 3
Training loss: 3.63217977940949
Validation loss: 2.8680878270368395

Epoch: 6| Step: 4
Training loss: 2.8628795388822055
Validation loss: 2.850375180609435

Epoch: 6| Step: 5
Training loss: 2.7714607178617263
Validation loss: 2.851443606179482

Epoch: 6| Step: 6
Training loss: 3.4022181736297514
Validation loss: 2.8548652908281653

Epoch: 6| Step: 7
Training loss: 2.5153628384480458
Validation loss: 2.8561073754985675

Epoch: 6| Step: 8
Training loss: 3.4166967499191676
Validation loss: 2.8586437335439605

Epoch: 6| Step: 9
Training loss: 2.9709783924386595
Validation loss: 2.8622700262949627

Epoch: 6| Step: 10
Training loss: 3.1069967865081662
Validation loss: 2.866478330812409

Epoch: 6| Step: 11
Training loss: 2.9507957031930254
Validation loss: 2.876275980084349

Epoch: 6| Step: 12
Training loss: 3.7859296608913375
Validation loss: 2.8675368585352707

Epoch: 6| Step: 13
Training loss: 3.923353182586612
Validation loss: 2.863200160527722

Epoch: 42| Step: 0
Training loss: 3.811663926800098
Validation loss: 2.8593355657237676

Epoch: 6| Step: 1
Training loss: 2.3875328461150174
Validation loss: 2.8581718245884153

Epoch: 6| Step: 2
Training loss: 3.0054197628192685
Validation loss: 2.8547016525948243

Epoch: 6| Step: 3
Training loss: 3.7166480527220673
Validation loss: 2.852377834342185

Epoch: 6| Step: 4
Training loss: 3.5071902668389776
Validation loss: 2.850358841978094

Epoch: 6| Step: 5
Training loss: 3.2402181872146874
Validation loss: 2.8485549455507315

Epoch: 6| Step: 6
Training loss: 3.052085138695783
Validation loss: 2.845605860592718

Epoch: 6| Step: 7
Training loss: 3.2456027874993625
Validation loss: 2.8464777828557724

Epoch: 6| Step: 8
Training loss: 3.282207821511878
Validation loss: 2.8453401142620276

Epoch: 6| Step: 9
Training loss: 3.378075505263714
Validation loss: 2.8461184613133277

Epoch: 6| Step: 10
Training loss: 2.0580159775361184
Validation loss: 2.8448873447657492

Epoch: 6| Step: 11
Training loss: 3.041068153197185
Validation loss: 2.8427394931805705

Epoch: 6| Step: 12
Training loss: 2.7124792106991977
Validation loss: 2.842107252142544

Epoch: 6| Step: 13
Training loss: 3.5327102207662393
Validation loss: 2.840621886546145

Epoch: 43| Step: 0
Training loss: 3.348111454429093
Validation loss: 2.839980118245898

Epoch: 6| Step: 1
Training loss: 3.0522847982493415
Validation loss: 2.840639305505152

Epoch: 6| Step: 2
Training loss: 2.415998454175543
Validation loss: 2.849537810833874

Epoch: 6| Step: 3
Training loss: 2.679157972148672
Validation loss: 2.8548494430557128

Epoch: 6| Step: 4
Training loss: 3.048071992940047
Validation loss: 2.86115627795431

Epoch: 6| Step: 5
Training loss: 2.6993061940317524
Validation loss: 2.8603897773057128

Epoch: 6| Step: 6
Training loss: 3.1806902979517475
Validation loss: 2.8608169492720035

Epoch: 6| Step: 7
Training loss: 3.4148981743260847
Validation loss: 2.839880434409708

Epoch: 6| Step: 8
Training loss: 3.4943043823420816
Validation loss: 2.836411981120794

Epoch: 6| Step: 9
Training loss: 3.376257203089838
Validation loss: 2.835794632660966

Epoch: 6| Step: 10
Training loss: 3.604204049035987
Validation loss: 2.836020522435044

Epoch: 6| Step: 11
Training loss: 2.3601620605558855
Validation loss: 2.83645519301172

Epoch: 6| Step: 12
Training loss: 3.5798126638402348
Validation loss: 2.8387068896918533

Epoch: 6| Step: 13
Training loss: 3.6314152481376647
Validation loss: 2.8379997462400492

Epoch: 44| Step: 0
Training loss: 2.8786548106149783
Validation loss: 2.837044106999037

Epoch: 6| Step: 1
Training loss: 3.438079507703966
Validation loss: 2.839048546771524

Epoch: 6| Step: 2
Training loss: 3.7260849364792294
Validation loss: 2.8381146389268217

Epoch: 6| Step: 3
Training loss: 2.982336496506314
Validation loss: 2.835852479079741

Epoch: 6| Step: 4
Training loss: 3.3392190627869542
Validation loss: 2.835163132431296

Epoch: 6| Step: 5
Training loss: 3.539032588604972
Validation loss: 2.835313787677457

Epoch: 6| Step: 6
Training loss: 3.0849903053366305
Validation loss: 2.834272886360819

Epoch: 6| Step: 7
Training loss: 2.994493517201289
Validation loss: 2.8348814090763623

Epoch: 6| Step: 8
Training loss: 2.2543945841286273
Validation loss: 2.8330007830858643

Epoch: 6| Step: 9
Training loss: 3.3401501252933334
Validation loss: 2.8290135631798785

Epoch: 6| Step: 10
Training loss: 3.2170064703840997
Validation loss: 2.8287979519167563

Epoch: 6| Step: 11
Training loss: 3.2645583167433183
Validation loss: 2.8266266873137265

Epoch: 6| Step: 12
Training loss: 2.867407850066936
Validation loss: 2.824368511319637

Epoch: 6| Step: 13
Training loss: 2.434593619836789
Validation loss: 2.826250868412643

Epoch: 45| Step: 0
Training loss: 2.5865047328278123
Validation loss: 2.822748433852428

Epoch: 6| Step: 1
Training loss: 2.795653348114223
Validation loss: 2.8253923538430077

Epoch: 6| Step: 2
Training loss: 2.901892399765521
Validation loss: 2.8368033568693884

Epoch: 6| Step: 3
Training loss: 2.8781674393332106
Validation loss: 2.8607154123815883

Epoch: 6| Step: 4
Training loss: 3.6380451541088603
Validation loss: 2.896364398973799

Epoch: 6| Step: 5
Training loss: 3.5342366239541914
Validation loss: 2.9512498350319247

Epoch: 6| Step: 6
Training loss: 3.0547101344370025
Validation loss: 2.8777073404531133

Epoch: 6| Step: 7
Training loss: 2.9778873568944078
Validation loss: 2.832824543421338

Epoch: 6| Step: 8
Training loss: 3.4093563369533872
Validation loss: 2.8226906849027436

Epoch: 6| Step: 9
Training loss: 3.3383425902684105
Validation loss: 2.8153394528467004

Epoch: 6| Step: 10
Training loss: 3.0534389119725236
Validation loss: 2.8170836821562486

Epoch: 6| Step: 11
Training loss: 3.471790802326959
Validation loss: 2.81887289876671

Epoch: 6| Step: 12
Training loss: 2.6564122767526186
Validation loss: 2.8253307563076877

Epoch: 6| Step: 13
Training loss: 3.5544112884187684
Validation loss: 2.8386803591531926

Epoch: 46| Step: 0
Training loss: 3.4564499533346678
Validation loss: 2.815142168206302

Epoch: 6| Step: 1
Training loss: 2.765595516758894
Validation loss: 2.8164752654039606

Epoch: 6| Step: 2
Training loss: 3.7403992140977085
Validation loss: 2.8169192889009462

Epoch: 6| Step: 3
Training loss: 3.2089127516923286
Validation loss: 2.8517191624869196

Epoch: 6| Step: 4
Training loss: 2.822663318108885
Validation loss: 2.8993177449094163

Epoch: 6| Step: 5
Training loss: 3.3872571119103876
Validation loss: 2.9423275614737685

Epoch: 6| Step: 6
Training loss: 2.837524474454351
Validation loss: 2.9351989838186268

Epoch: 6| Step: 7
Training loss: 3.2071689292729118
Validation loss: 2.9272464681484163

Epoch: 6| Step: 8
Training loss: 3.4272086324463733
Validation loss: 2.8610706444627145

Epoch: 6| Step: 9
Training loss: 3.2061048091859616
Validation loss: 2.820629940212274

Epoch: 6| Step: 10
Training loss: 2.8977033399929755
Validation loss: 2.81107178478864

Epoch: 6| Step: 11
Training loss: 2.888299449876727
Validation loss: 2.8196795944218676

Epoch: 6| Step: 12
Training loss: 2.978152513727182
Validation loss: 2.84326155780461

Epoch: 6| Step: 13
Training loss: 3.1997059508167145
Validation loss: 2.897856303121016

Epoch: 47| Step: 0
Training loss: 3.5599864993750217
Validation loss: 2.9377489440480384

Epoch: 6| Step: 1
Training loss: 3.5372770744687925
Validation loss: 2.8705185698635596

Epoch: 6| Step: 2
Training loss: 2.7932555578264093
Validation loss: 2.811050024866805

Epoch: 6| Step: 3
Training loss: 3.48298788471946
Validation loss: 2.8103740373074184

Epoch: 6| Step: 4
Training loss: 2.576807043570574
Validation loss: 2.813721673810601

Epoch: 6| Step: 5
Training loss: 2.991265137343597
Validation loss: 2.8352622307320736

Epoch: 6| Step: 6
Training loss: 2.315605964530924
Validation loss: 2.851009764054795

Epoch: 6| Step: 7
Training loss: 3.184613136019953
Validation loss: 2.8685298376131043

Epoch: 6| Step: 8
Training loss: 3.711545360371764
Validation loss: 2.8837968339825015

Epoch: 6| Step: 9
Training loss: 2.352990410794531
Validation loss: 2.8683619184409666

Epoch: 6| Step: 10
Training loss: 3.042743561899998
Validation loss: 2.859420750000548

Epoch: 6| Step: 11
Training loss: 2.8414562322684933
Validation loss: 2.83765307619742

Epoch: 6| Step: 12
Training loss: 3.8929550363573555
Validation loss: 2.8160546485130267

Epoch: 6| Step: 13
Training loss: 3.29545512064866
Validation loss: 2.8164683640306905

Epoch: 48| Step: 0
Training loss: 3.165309481322297
Validation loss: 2.811143594983478

Epoch: 6| Step: 1
Training loss: 2.924256685150011
Validation loss: 2.8078861799174724

Epoch: 6| Step: 2
Training loss: 3.0762233378631763
Validation loss: 2.803698712291771

Epoch: 6| Step: 3
Training loss: 3.0293219028523652
Validation loss: 2.799488623055324

Epoch: 6| Step: 4
Training loss: 3.3220786031372533
Validation loss: 2.801767378928963

Epoch: 6| Step: 5
Training loss: 3.2676776476363614
Validation loss: 2.8010792181790887

Epoch: 6| Step: 6
Training loss: 3.137178114227138
Validation loss: 2.7981994942870148

Epoch: 6| Step: 7
Training loss: 2.8830840853821433
Validation loss: 2.7961765007606365

Epoch: 6| Step: 8
Training loss: 3.088977253364252
Validation loss: 2.799100038345143

Epoch: 6| Step: 9
Training loss: 3.2926965060208206
Validation loss: 2.8019177839697225

Epoch: 6| Step: 10
Training loss: 3.3756885532611216
Validation loss: 2.803487910960304

Epoch: 6| Step: 11
Training loss: 3.3022726267440086
Validation loss: 2.7998927478201607

Epoch: 6| Step: 12
Training loss: 3.1774201428262656
Validation loss: 2.8026675540733033

Epoch: 6| Step: 13
Training loss: 1.839717528595619
Validation loss: 2.8009923374070205

Epoch: 49| Step: 0
Training loss: 3.0508206373497764
Validation loss: 2.8053714218708516

Epoch: 6| Step: 1
Training loss: 3.1551091615681277
Validation loss: 2.8045683338530925

Epoch: 6| Step: 2
Training loss: 3.1054666003333753
Validation loss: 2.7982081118165136

Epoch: 6| Step: 3
Training loss: 3.022142867452084
Validation loss: 2.8010944366350357

Epoch: 6| Step: 4
Training loss: 3.8319740096706054
Validation loss: 2.8035006930689663

Epoch: 6| Step: 5
Training loss: 2.6827153041075875
Validation loss: 2.8010397292500255

Epoch: 6| Step: 6
Training loss: 3.3135797432266028
Validation loss: 2.799480427968036

Epoch: 6| Step: 7
Training loss: 2.4156280675476256
Validation loss: 2.79971314574484

Epoch: 6| Step: 8
Training loss: 3.0071719589870427
Validation loss: 2.803106896342483

Epoch: 6| Step: 9
Training loss: 2.6935668599831004
Validation loss: 2.7977563437910624

Epoch: 6| Step: 10
Training loss: 3.15063112385069
Validation loss: 2.8012492834760554

Epoch: 6| Step: 11
Training loss: 3.403774376766852
Validation loss: 2.7983702091431972

Epoch: 6| Step: 12
Training loss: 3.232386470727561
Validation loss: 2.7977656169360574

Epoch: 6| Step: 13
Training loss: 3.420463932984194
Validation loss: 2.7994078460483607

Epoch: 50| Step: 0
Training loss: 3.18275157812108
Validation loss: 2.795099523150717

Epoch: 6| Step: 1
Training loss: 3.4066296287160562
Validation loss: 2.7960422577978723

Epoch: 6| Step: 2
Training loss: 3.6966168478752457
Validation loss: 2.7934549594726947

Epoch: 6| Step: 3
Training loss: 3.616797934990462
Validation loss: 2.792962320166754

Epoch: 6| Step: 4
Training loss: 2.8484955480941525
Validation loss: 2.791334075167774

Epoch: 6| Step: 5
Training loss: 2.441007584637802
Validation loss: 2.7909000711258454

Epoch: 6| Step: 6
Training loss: 2.7333867494279405
Validation loss: 2.793117609581289

Epoch: 6| Step: 7
Training loss: 3.313369205083668
Validation loss: 2.7922693121551463

Epoch: 6| Step: 8
Training loss: 2.6315429524419462
Validation loss: 2.8030561408436636

Epoch: 6| Step: 9
Training loss: 2.766613110249903
Validation loss: 2.8087899078255125

Epoch: 6| Step: 10
Training loss: 2.703282081582268
Validation loss: 2.8221514633087335

Epoch: 6| Step: 11
Training loss: 3.307711180665523
Validation loss: 2.831785027504423

Epoch: 6| Step: 12
Training loss: 3.2077350471462616
Validation loss: 2.8418223615684064

Epoch: 6| Step: 13
Training loss: 3.666430783631693
Validation loss: 2.79713154341079

Epoch: 51| Step: 0
Training loss: 2.9104569042995068
Validation loss: 2.788897263023092

Epoch: 6| Step: 1
Training loss: 2.2885939603539662
Validation loss: 2.785363433587164

Epoch: 6| Step: 2
Training loss: 3.1196371219590713
Validation loss: 2.79026730770924

Epoch: 6| Step: 3
Training loss: 3.6616816156423946
Validation loss: 2.7960635202090987

Epoch: 6| Step: 4
Training loss: 3.166573138277952
Validation loss: 2.8126214515049255

Epoch: 6| Step: 5
Training loss: 3.6587401167537656
Validation loss: 2.7988104888715535

Epoch: 6| Step: 6
Training loss: 2.57023884861945
Validation loss: 2.7830225057378866

Epoch: 6| Step: 7
Training loss: 3.733971482186916
Validation loss: 2.7770234148764326

Epoch: 6| Step: 8
Training loss: 3.3978867358572087
Validation loss: 2.779319347491103

Epoch: 6| Step: 9
Training loss: 3.2353733751717155
Validation loss: 2.7812068152822533

Epoch: 6| Step: 10
Training loss: 2.654527621874406
Validation loss: 2.7797542899498544

Epoch: 6| Step: 11
Training loss: 2.902234985449421
Validation loss: 2.781446350658728

Epoch: 6| Step: 12
Training loss: 2.90599616798311
Validation loss: 2.7790193035829445

Epoch: 6| Step: 13
Training loss: 2.685034308329776
Validation loss: 2.7795752321793663

Epoch: 52| Step: 0
Training loss: 2.978088788575922
Validation loss: 2.779910768139329

Epoch: 6| Step: 1
Training loss: 3.2324985829266883
Validation loss: 2.7818937949525075

Epoch: 6| Step: 2
Training loss: 3.913714425757745
Validation loss: 2.7767241532363496

Epoch: 6| Step: 3
Training loss: 2.3793436785140183
Validation loss: 2.775262618781956

Epoch: 6| Step: 4
Training loss: 3.388671875
Validation loss: 2.7738397316120778

Epoch: 6| Step: 5
Training loss: 3.41198387854145
Validation loss: 2.7755970920494053

Epoch: 6| Step: 6
Training loss: 2.822544725602651
Validation loss: 2.7719632186693874

Epoch: 6| Step: 7
Training loss: 2.932951469563542
Validation loss: 2.7705355297679772

Epoch: 6| Step: 8
Training loss: 2.817624657893339
Validation loss: 2.778754255331499

Epoch: 6| Step: 9
Training loss: 2.466211486608496
Validation loss: 2.7813321661763197

Epoch: 6| Step: 10
Training loss: 3.678825001964699
Validation loss: 2.779752773763201

Epoch: 6| Step: 11
Training loss: 3.4581695579141547
Validation loss: 2.7781939435422065

Epoch: 6| Step: 12
Training loss: 2.3469687167578916
Validation loss: 2.7768408094075396

Epoch: 6| Step: 13
Training loss: 2.9349323170020973
Validation loss: 2.7667291910919984

Epoch: 53| Step: 0
Training loss: 3.3336659901249583
Validation loss: 2.764330234173701

Epoch: 6| Step: 1
Training loss: 3.3659016926689813
Validation loss: 2.7677764412789263

Epoch: 6| Step: 2
Training loss: 3.553006019713877
Validation loss: 2.766354538266256

Epoch: 6| Step: 3
Training loss: 3.541577521305513
Validation loss: 2.768930893425792

Epoch: 6| Step: 4
Training loss: 3.213410624712873
Validation loss: 2.7695491818018585

Epoch: 6| Step: 5
Training loss: 3.4270256679209257
Validation loss: 2.768238412157098

Epoch: 6| Step: 6
Training loss: 3.1866260901332417
Validation loss: 2.7832231287083555

Epoch: 6| Step: 7
Training loss: 2.4302076169397306
Validation loss: 2.768876856967629

Epoch: 6| Step: 8
Training loss: 2.8276363393223067
Validation loss: 2.770123332418646

Epoch: 6| Step: 9
Training loss: 2.9487540377871824
Validation loss: 2.768814716931365

Epoch: 6| Step: 10
Training loss: 3.22707556831767
Validation loss: 2.764363101971656

Epoch: 6| Step: 11
Training loss: 1.9867848459185402
Validation loss: 2.7640703273005633

Epoch: 6| Step: 12
Training loss: 2.636019510871332
Validation loss: 2.762946081219741

Epoch: 6| Step: 13
Training loss: 3.2815775389908404
Validation loss: 2.760334781880238

Epoch: 54| Step: 0
Training loss: 3.162703309290205
Validation loss: 2.7608321837013614

Epoch: 6| Step: 1
Training loss: 2.7443540008234977
Validation loss: 2.7594522516968936

Epoch: 6| Step: 2
Training loss: 2.931511639140715
Validation loss: 2.759033144935053

Epoch: 6| Step: 3
Training loss: 2.738899716176815
Validation loss: 2.7593859917914365

Epoch: 6| Step: 4
Training loss: 3.2518910994929437
Validation loss: 2.759737366677376

Epoch: 6| Step: 5
Training loss: 3.275116337464332
Validation loss: 2.765688685546051

Epoch: 6| Step: 6
Training loss: 2.6078805812865014
Validation loss: 2.768367700700233

Epoch: 6| Step: 7
Training loss: 2.7556235295631604
Validation loss: 2.8261014626538445

Epoch: 6| Step: 8
Training loss: 3.4869089534984696
Validation loss: 2.8681183750957033

Epoch: 6| Step: 9
Training loss: 2.8704270192051577
Validation loss: 2.811756930070538

Epoch: 6| Step: 10
Training loss: 3.2798578124512443
Validation loss: 2.7612658695287866

Epoch: 6| Step: 11
Training loss: 3.7293221354265866
Validation loss: 2.7504224648487785

Epoch: 6| Step: 12
Training loss: 3.0589251771064525
Validation loss: 2.752460991321476

Epoch: 6| Step: 13
Training loss: 3.0021469063593944
Validation loss: 2.7603290858956995

Epoch: 55| Step: 0
Training loss: 2.9967010161142986
Validation loss: 2.760781569382299

Epoch: 6| Step: 1
Training loss: 3.101400914054761
Validation loss: 2.7619723863934156

Epoch: 6| Step: 2
Training loss: 3.48663954425812
Validation loss: 2.7667087734703446

Epoch: 6| Step: 3
Training loss: 3.048336988988832
Validation loss: 2.7684910178782576

Epoch: 6| Step: 4
Training loss: 3.106098077693219
Validation loss: 2.7706649220837045

Epoch: 6| Step: 5
Training loss: 3.555012916509285
Validation loss: 2.7690759143893984

Epoch: 6| Step: 6
Training loss: 2.7245855733727393
Validation loss: 2.7699640245634747

Epoch: 6| Step: 7
Training loss: 2.706508569500526
Validation loss: 2.76666412381815

Epoch: 6| Step: 8
Training loss: 3.4873421527321016
Validation loss: 2.7684511030070023

Epoch: 6| Step: 9
Training loss: 2.6977885055049384
Validation loss: 2.7669345560956176

Epoch: 6| Step: 10
Training loss: 2.9552743346129926
Validation loss: 2.7673821234234186

Epoch: 6| Step: 11
Training loss: 2.815533422066793
Validation loss: 2.766856328282757

Epoch: 6| Step: 12
Training loss: 3.335594427616594
Validation loss: 2.763425432162692

Epoch: 6| Step: 13
Training loss: 3.134172938519016
Validation loss: 2.7670678097613677

Epoch: 56| Step: 0
Training loss: 3.777022970439295
Validation loss: 2.762412665159663

Epoch: 6| Step: 1
Training loss: 2.9457201283531607
Validation loss: 2.7598928080224674

Epoch: 6| Step: 2
Training loss: 3.298614043295823
Validation loss: 2.7545912926874956

Epoch: 6| Step: 3
Training loss: 2.6171999802932375
Validation loss: 2.751416440071154

Epoch: 6| Step: 4
Training loss: 3.245702690136419
Validation loss: 2.751386568838257

Epoch: 6| Step: 5
Training loss: 2.727936756329443
Validation loss: 2.750608705924301

Epoch: 6| Step: 6
Training loss: 3.8719552906938794
Validation loss: 2.750532609555318

Epoch: 6| Step: 7
Training loss: 3.3702030707055277
Validation loss: 2.7445564649479777

Epoch: 6| Step: 8
Training loss: 3.116985572642035
Validation loss: 2.7405389832766494

Epoch: 6| Step: 9
Training loss: 3.076582313888393
Validation loss: 2.7400491475127975

Epoch: 6| Step: 10
Training loss: 2.3924025366053603
Validation loss: 2.7414729105768374

Epoch: 6| Step: 11
Training loss: 2.9523393504263162
Validation loss: 2.7455677492664505

Epoch: 6| Step: 12
Training loss: 2.422576015291517
Validation loss: 2.7477690689255665

Epoch: 6| Step: 13
Training loss: 2.484675743085767
Validation loss: 2.7531123387498133

Epoch: 57| Step: 0
Training loss: 2.541359669223007
Validation loss: 2.7726973053561483

Epoch: 6| Step: 1
Training loss: 3.1461501982981463
Validation loss: 2.8040993284824127

Epoch: 6| Step: 2
Training loss: 2.7251278838501145
Validation loss: 2.7927618093345705

Epoch: 6| Step: 3
Training loss: 3.4589344712485666
Validation loss: 2.770661665096449

Epoch: 6| Step: 4
Training loss: 2.807753648178316
Validation loss: 2.7461954332347984

Epoch: 6| Step: 5
Training loss: 3.440539871257546
Validation loss: 2.742702227692233

Epoch: 6| Step: 6
Training loss: 2.95006875426781
Validation loss: 2.7417229517556914

Epoch: 6| Step: 7
Training loss: 3.246321724094537
Validation loss: 2.7413502016037317

Epoch: 6| Step: 8
Training loss: 3.253702548864794
Validation loss: 2.7388486628455895

Epoch: 6| Step: 9
Training loss: 3.175987546632119
Validation loss: 2.7392530815781626

Epoch: 6| Step: 10
Training loss: 2.984761637462982
Validation loss: 2.734556886216716

Epoch: 6| Step: 11
Training loss: 3.911528903749551
Validation loss: 2.7345806226165217

Epoch: 6| Step: 12
Training loss: 2.524691432567829
Validation loss: 2.7332138873047302

Epoch: 6| Step: 13
Training loss: 1.9945554535320285
Validation loss: 2.7335400409657185

Epoch: 58| Step: 0
Training loss: 2.6978371116269386
Validation loss: 2.7315056315685946

Epoch: 6| Step: 1
Training loss: 2.3337564652388623
Validation loss: 2.736306562373369

Epoch: 6| Step: 2
Training loss: 3.363050995675165
Validation loss: 2.7352908633684567

Epoch: 6| Step: 3
Training loss: 3.013633267939683
Validation loss: 2.731774685057705

Epoch: 6| Step: 4
Training loss: 2.855947639605113
Validation loss: 2.7291247275320036

Epoch: 6| Step: 5
Training loss: 3.8758241330807683
Validation loss: 2.73290355462692

Epoch: 6| Step: 6
Training loss: 3.328590181462772
Validation loss: 2.730067698905039

Epoch: 6| Step: 7
Training loss: 3.322871974218004
Validation loss: 2.7290645399588915

Epoch: 6| Step: 8
Training loss: 2.8451432388798374
Validation loss: 2.7305270025703354

Epoch: 6| Step: 9
Training loss: 2.8969230705478464
Validation loss: 2.727978583414469

Epoch: 6| Step: 10
Training loss: 3.609593504529885
Validation loss: 2.7287671437769028

Epoch: 6| Step: 11
Training loss: 2.947493739618928
Validation loss: 2.729948310604614

Epoch: 6| Step: 12
Training loss: 2.3849851615012314
Validation loss: 2.7288863686201035

Epoch: 6| Step: 13
Training loss: 2.9658833366081057
Validation loss: 2.7274719633954083

Epoch: 59| Step: 0
Training loss: 3.01098053787109
Validation loss: 2.7314434147196778

Epoch: 6| Step: 1
Training loss: 3.550201872337767
Validation loss: 2.728104530679328

Epoch: 6| Step: 2
Training loss: 2.5214903319485695
Validation loss: 2.7283962965719852

Epoch: 6| Step: 3
Training loss: 2.7432217725996106
Validation loss: 2.7301448999837112

Epoch: 6| Step: 4
Training loss: 2.908357737820459
Validation loss: 2.7328156218318047

Epoch: 6| Step: 5
Training loss: 3.8749129993147333
Validation loss: 2.737199056867915

Epoch: 6| Step: 6
Training loss: 2.9117808882682397
Validation loss: 2.740036806677174

Epoch: 6| Step: 7
Training loss: 3.040736975181163
Validation loss: 2.7369454926226573

Epoch: 6| Step: 8
Training loss: 2.419854090051438
Validation loss: 2.725581883582931

Epoch: 6| Step: 9
Training loss: 2.811231030187724
Validation loss: 2.7261180393780546

Epoch: 6| Step: 10
Training loss: 2.626350600337113
Validation loss: 2.7252182462083967

Epoch: 6| Step: 11
Training loss: 3.5246803138727976
Validation loss: 2.722982712629847

Epoch: 6| Step: 12
Training loss: 3.172100190686129
Validation loss: 2.721326175825808

Epoch: 6| Step: 13
Training loss: 3.36957891736984
Validation loss: 2.7217299146859877

Epoch: 60| Step: 0
Training loss: 3.536617689329871
Validation loss: 2.7213190764853463

Epoch: 6| Step: 1
Training loss: 3.114441084829511
Validation loss: 2.7227686930022985

Epoch: 6| Step: 2
Training loss: 3.2935899033264517
Validation loss: 2.7192458625964284

Epoch: 6| Step: 3
Training loss: 2.452889789554791
Validation loss: 2.720152660343889

Epoch: 6| Step: 4
Training loss: 2.7992752261137923
Validation loss: 2.718584384006333

Epoch: 6| Step: 5
Training loss: 3.614944190812017
Validation loss: 2.7200305060380634

Epoch: 6| Step: 6
Training loss: 2.2393773775250447
Validation loss: 2.717781933673667

Epoch: 6| Step: 7
Training loss: 2.9566303419815565
Validation loss: 2.716671095212277

Epoch: 6| Step: 8
Training loss: 3.0793662110240607
Validation loss: 2.7168424253407264

Epoch: 6| Step: 9
Training loss: 2.571512516104753
Validation loss: 2.7194272042907635

Epoch: 6| Step: 10
Training loss: 3.0821058218362767
Validation loss: 2.716614805665562

Epoch: 6| Step: 11
Training loss: 3.095906440484341
Validation loss: 2.7160766210169403

Epoch: 6| Step: 12
Training loss: 3.521804735757188
Validation loss: 2.716668853995432

Epoch: 6| Step: 13
Training loss: 2.883484470029934
Validation loss: 2.7145933144183276

Epoch: 61| Step: 0
Training loss: 3.3262204733953338
Validation loss: 2.7140299439808824

Epoch: 6| Step: 1
Training loss: 2.668924051724228
Validation loss: 2.7170014709281833

Epoch: 6| Step: 2
Training loss: 3.1813309754743684
Validation loss: 2.71891776795343

Epoch: 6| Step: 3
Training loss: 2.2660974470364974
Validation loss: 2.720711418859875

Epoch: 6| Step: 4
Training loss: 3.057144776714216
Validation loss: 2.7158526695561016

Epoch: 6| Step: 5
Training loss: 3.9399172916541896
Validation loss: 2.7144200969819474

Epoch: 6| Step: 6
Training loss: 3.3121877559111463
Validation loss: 2.7150291862906486

Epoch: 6| Step: 7
Training loss: 3.2741139152344165
Validation loss: 2.715822472292168

Epoch: 6| Step: 8
Training loss: 3.0746229359256585
Validation loss: 2.713102265009404

Epoch: 6| Step: 9
Training loss: 3.412772277477641
Validation loss: 2.707810836320091

Epoch: 6| Step: 10
Training loss: 2.7693521847965634
Validation loss: 2.7121558819688367

Epoch: 6| Step: 11
Training loss: 2.640040767528302
Validation loss: 2.7123442401966606

Epoch: 6| Step: 12
Training loss: 2.1305993303457424
Validation loss: 2.7111172962961505

Epoch: 6| Step: 13
Training loss: 3.1121045884059306
Validation loss: 2.710903667652449

Epoch: 62| Step: 0
Training loss: 3.5213077985402736
Validation loss: 2.711545343599937

Epoch: 6| Step: 1
Training loss: 3.7134381993643095
Validation loss: 2.7117159803366686

Epoch: 6| Step: 2
Training loss: 3.101595707866935
Validation loss: 2.711269483989903

Epoch: 6| Step: 3
Training loss: 2.9581536968297275
Validation loss: 2.7070011759385184

Epoch: 6| Step: 4
Training loss: 3.228715303111273
Validation loss: 2.707990787195307

Epoch: 6| Step: 5
Training loss: 2.766258899865742
Validation loss: 2.70950913443836

Epoch: 6| Step: 6
Training loss: 2.9918888431035175
Validation loss: 2.7130952858865256

Epoch: 6| Step: 7
Training loss: 2.8280335300891237
Validation loss: 2.723266484213051

Epoch: 6| Step: 8
Training loss: 3.102985814594738
Validation loss: 2.7312175750778835

Epoch: 6| Step: 9
Training loss: 2.614082156675759
Validation loss: 2.7313636917379447

Epoch: 6| Step: 10
Training loss: 2.4615217211731797
Validation loss: 2.725346062211158

Epoch: 6| Step: 11
Training loss: 3.0220144308718893
Validation loss: 2.7177032315072025

Epoch: 6| Step: 12
Training loss: 3.017712912897847
Validation loss: 2.7114723592631487

Epoch: 6| Step: 13
Training loss: 3.004904235227909
Validation loss: 2.7026979420968376

Epoch: 63| Step: 0
Training loss: 3.25351217203075
Validation loss: 2.706443046181675

Epoch: 6| Step: 1
Training loss: 3.2536996178201405
Validation loss: 2.701441970974158

Epoch: 6| Step: 2
Training loss: 3.2097863874336094
Validation loss: 2.7022801224717528

Epoch: 6| Step: 3
Training loss: 2.676628658013732
Validation loss: 2.7005644457048836

Epoch: 6| Step: 4
Training loss: 3.4109737294711153
Validation loss: 2.702324213677978

Epoch: 6| Step: 5
Training loss: 2.808291189479329
Validation loss: 2.7043342055187716

Epoch: 6| Step: 6
Training loss: 3.1864098573364137
Validation loss: 2.7018642863093705

Epoch: 6| Step: 7
Training loss: 3.307444042790657
Validation loss: 2.7008442880760715

Epoch: 6| Step: 8
Training loss: 2.976094206569979
Validation loss: 2.6988153899603837

Epoch: 6| Step: 9
Training loss: 2.62129358476414
Validation loss: 2.7015258660558454

Epoch: 6| Step: 10
Training loss: 3.185783672126973
Validation loss: 2.703232092973277

Epoch: 6| Step: 11
Training loss: 2.320689366622026
Validation loss: 2.6988307538143803

Epoch: 6| Step: 12
Training loss: 2.776436658936711
Validation loss: 2.7025670894808496

Epoch: 6| Step: 13
Training loss: 3.3721868305419505
Validation loss: 2.6987609945268582

Epoch: 64| Step: 0
Training loss: 2.846970296326265
Validation loss: 2.6978090332646945

Epoch: 6| Step: 1
Training loss: 2.9618222970453347
Validation loss: 2.7060875914267495

Epoch: 6| Step: 2
Training loss: 2.7180151987780667
Validation loss: 2.7084000010524174

Epoch: 6| Step: 3
Training loss: 3.071623311253408
Validation loss: 2.735698829284057

Epoch: 6| Step: 4
Training loss: 3.4364111823186763
Validation loss: 2.729098929665447

Epoch: 6| Step: 5
Training loss: 3.1685087635075004
Validation loss: 2.7067340328445595

Epoch: 6| Step: 6
Training loss: 2.8097764285328153
Validation loss: 2.6976132653253084

Epoch: 6| Step: 7
Training loss: 2.881610237158892
Validation loss: 2.6937476524797903

Epoch: 6| Step: 8
Training loss: 3.3467626102215924
Validation loss: 2.6919856258480865

Epoch: 6| Step: 9
Training loss: 2.603326697623978
Validation loss: 2.692710893759523

Epoch: 6| Step: 10
Training loss: 2.9039817900809197
Validation loss: 2.691433350246389

Epoch: 6| Step: 11
Training loss: 3.667430249092409
Validation loss: 2.6910798359044383

Epoch: 6| Step: 12
Training loss: 2.9634853864978528
Validation loss: 2.6912826223219337

Epoch: 6| Step: 13
Training loss: 2.5829994129412106
Validation loss: 2.6912827042431298

Epoch: 65| Step: 0
Training loss: 3.0866489797405374
Validation loss: 2.690943263322921

Epoch: 6| Step: 1
Training loss: 3.38981780538765
Validation loss: 2.6894294411904185

Epoch: 6| Step: 2
Training loss: 3.2313204729965337
Validation loss: 2.691583263944296

Epoch: 6| Step: 3
Training loss: 3.254557714928375
Validation loss: 2.692230346575653

Epoch: 6| Step: 4
Training loss: 3.441142146772201
Validation loss: 2.6959961934620704

Epoch: 6| Step: 5
Training loss: 2.4718874539183346
Validation loss: 2.699930433822634

Epoch: 6| Step: 6
Training loss: 3.0020619300081077
Validation loss: 2.6977129766005783

Epoch: 6| Step: 7
Training loss: 3.022960851983047
Validation loss: 2.6937045757974

Epoch: 6| Step: 8
Training loss: 3.1814535799070707
Validation loss: 2.6870554513174993

Epoch: 6| Step: 9
Training loss: 2.4845614573246904
Validation loss: 2.6856769828117715

Epoch: 6| Step: 10
Training loss: 2.495470616939038
Validation loss: 2.6844982936927515

Epoch: 6| Step: 11
Training loss: 3.3796435306985093
Validation loss: 2.684578261523707

Epoch: 6| Step: 12
Training loss: 2.5164971587166756
Validation loss: 2.683675893192208

Epoch: 6| Step: 13
Training loss: 3.123656785298492
Validation loss: 2.684539618199317

Epoch: 66| Step: 0
Training loss: 3.1515286324174916
Validation loss: 2.682765310928628

Epoch: 6| Step: 1
Training loss: 2.99717293094725
Validation loss: 2.688194676385985

Epoch: 6| Step: 2
Training loss: 2.685356172206295
Validation loss: 2.6849382357638083

Epoch: 6| Step: 3
Training loss: 2.7666839468849136
Validation loss: 2.695376015952551

Epoch: 6| Step: 4
Training loss: 3.170690907418019
Validation loss: 2.7055786148408396

Epoch: 6| Step: 5
Training loss: 2.8727982424495613
Validation loss: 2.7079210546562833

Epoch: 6| Step: 6
Training loss: 2.649275745531332
Validation loss: 2.7071718348926073

Epoch: 6| Step: 7
Training loss: 3.3928794573286702
Validation loss: 2.6977554224325826

Epoch: 6| Step: 8
Training loss: 3.360531204330762
Validation loss: 2.6829052065811143

Epoch: 6| Step: 9
Training loss: 3.1269583097435154
Validation loss: 2.6798282919832053

Epoch: 6| Step: 10
Training loss: 2.7718958908721634
Validation loss: 2.6804014448511695

Epoch: 6| Step: 11
Training loss: 3.215953612149598
Validation loss: 2.6816389701685255

Epoch: 6| Step: 12
Training loss: 2.780839696901071
Validation loss: 2.6815167708047567

Epoch: 6| Step: 13
Training loss: 3.4438214524847592
Validation loss: 2.6838641353708836

Epoch: 67| Step: 0
Training loss: 3.5431742582263315
Validation loss: 2.683702648319078

Epoch: 6| Step: 1
Training loss: 3.5843528953076853
Validation loss: 2.686679664330399

Epoch: 6| Step: 2
Training loss: 2.471345912864631
Validation loss: 2.686928488233692

Epoch: 6| Step: 3
Training loss: 2.6674058803553313
Validation loss: 2.6853628873772175

Epoch: 6| Step: 4
Training loss: 2.744614442801799
Validation loss: 2.6847594172515734

Epoch: 6| Step: 5
Training loss: 3.103426663736384
Validation loss: 2.6835168060632024

Epoch: 6| Step: 6
Training loss: 2.9541853358472885
Validation loss: 2.6778277717174106

Epoch: 6| Step: 7
Training loss: 3.1355720219614196
Validation loss: 2.6770225573226574

Epoch: 6| Step: 8
Training loss: 3.069714825335852
Validation loss: 2.6750910177186604

Epoch: 6| Step: 9
Training loss: 2.652206934235954
Validation loss: 2.6752858301425215

Epoch: 6| Step: 10
Training loss: 3.132350821021584
Validation loss: 2.6744073633956655

Epoch: 6| Step: 11
Training loss: 3.148738723619599
Validation loss: 2.6727945966103426

Epoch: 6| Step: 12
Training loss: 2.7413970590536834
Validation loss: 2.676172302475872

Epoch: 6| Step: 13
Training loss: 3.291694657090043
Validation loss: 2.674215383064605

Epoch: 68| Step: 0
Training loss: 2.9525242754578613
Validation loss: 2.6722225732409206

Epoch: 6| Step: 1
Training loss: 3.666264829869001
Validation loss: 2.672089979754235

Epoch: 6| Step: 2
Training loss: 3.0131739009045404
Validation loss: 2.670512085608867

Epoch: 6| Step: 3
Training loss: 2.9615964131206307
Validation loss: 2.6725561346838624

Epoch: 6| Step: 4
Training loss: 2.853230863614787
Validation loss: 2.669982332875771

Epoch: 6| Step: 5
Training loss: 3.2365396968034204
Validation loss: 2.6723162393409243

Epoch: 6| Step: 6
Training loss: 2.484564144203932
Validation loss: 2.6712377872961683

Epoch: 6| Step: 7
Training loss: 2.90585964411588
Validation loss: 2.6701983828599003

Epoch: 6| Step: 8
Training loss: 3.208261381721387
Validation loss: 2.6747436399062057

Epoch: 6| Step: 9
Training loss: 2.6694939248744145
Validation loss: 2.6699495082550184

Epoch: 6| Step: 10
Training loss: 2.735103575507901
Validation loss: 2.6747907574922527

Epoch: 6| Step: 11
Training loss: 2.9064002869828216
Validation loss: 2.6736213538635054

Epoch: 6| Step: 12
Training loss: 3.2510339119397127
Validation loss: 2.6682367458228935

Epoch: 6| Step: 13
Training loss: 3.1860283839128214
Validation loss: 2.6726303563253886

Epoch: 69| Step: 0
Training loss: 3.357998872167183
Validation loss: 2.6764318676550642

Epoch: 6| Step: 1
Training loss: 3.3254022340629033
Validation loss: 2.6814531292518993

Epoch: 6| Step: 2
Training loss: 3.167165934372111
Validation loss: 2.6807177119814436

Epoch: 6| Step: 3
Training loss: 2.2079536063530902
Validation loss: 2.6854812049033354

Epoch: 6| Step: 4
Training loss: 3.5158468896990724
Validation loss: 2.6828991493651184

Epoch: 6| Step: 5
Training loss: 2.5736201839306543
Validation loss: 2.6848443320591

Epoch: 6| Step: 6
Training loss: 3.008427386165335
Validation loss: 2.6847202035944697

Epoch: 6| Step: 7
Training loss: 2.7467422262310746
Validation loss: 2.6831482751290543

Epoch: 6| Step: 8
Training loss: 3.094770475144036
Validation loss: 2.6832036119305953

Epoch: 6| Step: 9
Training loss: 3.2379565473047793
Validation loss: 2.679341732350324

Epoch: 6| Step: 10
Training loss: 3.152632954128506
Validation loss: 2.6813221558105935

Epoch: 6| Step: 11
Training loss: 2.996848199145753
Validation loss: 2.680985065465104

Epoch: 6| Step: 12
Training loss: 2.455968290292023
Validation loss: 2.6819618169631574

Epoch: 6| Step: 13
Training loss: 3.4410106418559248
Validation loss: 2.6822001155557786

Epoch: 70| Step: 0
Training loss: 3.1829156258702005
Validation loss: 2.68427375240468

Epoch: 6| Step: 1
Training loss: 3.5292990367314907
Validation loss: 2.680500938490605

Epoch: 6| Step: 2
Training loss: 3.238427613267289
Validation loss: 2.682790195496762

Epoch: 6| Step: 3
Training loss: 3.276167066121873
Validation loss: 2.6811349447244295

Epoch: 6| Step: 4
Training loss: 2.910730005835326
Validation loss: 2.7341105821682925

Epoch: 6| Step: 5
Training loss: 2.63011488543902
Validation loss: 2.713475030480767

Epoch: 6| Step: 6
Training loss: 2.8961478595397034
Validation loss: 2.6956069478709943

Epoch: 6| Step: 7
Training loss: 3.581541337817028
Validation loss: 2.6876848161569873

Epoch: 6| Step: 8
Training loss: 3.0811630205796003
Validation loss: 2.6704968189887377

Epoch: 6| Step: 9
Training loss: 3.143687562720633
Validation loss: 2.6695141093725576

Epoch: 6| Step: 10
Training loss: 2.492072697688895
Validation loss: 2.6683030920494084

Epoch: 6| Step: 11
Training loss: 2.484662405220037
Validation loss: 2.6604702262360793

Epoch: 6| Step: 12
Training loss: 2.7501910750158216
Validation loss: 2.6604706376950973

Epoch: 6| Step: 13
Training loss: 2.6904950862627683
Validation loss: 2.6611940153003855

Epoch: 71| Step: 0
Training loss: 2.825359952832139
Validation loss: 2.6601456673908714

Epoch: 6| Step: 1
Training loss: 2.9492675777208004
Validation loss: 2.7282954571630036

Epoch: 6| Step: 2
Training loss: 3.905694784760963
Validation loss: 2.7471565739984922

Epoch: 6| Step: 3
Training loss: 2.4063470003467664
Validation loss: 2.72582758897553

Epoch: 6| Step: 4
Training loss: 3.2477335730022645
Validation loss: 2.734683171733193

Epoch: 6| Step: 5
Training loss: 2.883201841615857
Validation loss: 2.7398572650906163

Epoch: 6| Step: 6
Training loss: 3.091401412840542
Validation loss: 2.7416227044373116

Epoch: 6| Step: 7
Training loss: 3.3437114962918932
Validation loss: 2.741693245142126

Epoch: 6| Step: 8
Training loss: 2.96568911516285
Validation loss: 2.731388410428639

Epoch: 6| Step: 9
Training loss: 3.1826336682604888
Validation loss: 2.7306373066850944

Epoch: 6| Step: 10
Training loss: 3.120235320289079
Validation loss: 2.7280090990767323

Epoch: 6| Step: 11
Training loss: 2.712497053716088
Validation loss: 2.732737597481705

Epoch: 6| Step: 12
Training loss: 3.049783736519456
Validation loss: 2.7341218217638428

Epoch: 6| Step: 13
Training loss: 2.8654047857469704
Validation loss: 2.7294585118812202

Epoch: 72| Step: 0
Training loss: 3.2259408569022843
Validation loss: 2.728880857825911

Epoch: 6| Step: 1
Training loss: 3.1737451912241412
Validation loss: 2.7132472105110748

Epoch: 6| Step: 2
Training loss: 3.033844614082109
Validation loss: 2.6801072376145867

Epoch: 6| Step: 3
Training loss: 2.3486193111293323
Validation loss: 2.6715594066143336

Epoch: 6| Step: 4
Training loss: 3.1423537018315666
Validation loss: 2.6762034682564555

Epoch: 6| Step: 5
Training loss: 2.8377656114928667
Validation loss: 2.669183595653921

Epoch: 6| Step: 6
Training loss: 2.9660542345290937
Validation loss: 2.6713775227288847

Epoch: 6| Step: 7
Training loss: 2.451896602896204
Validation loss: 2.6662576121979216

Epoch: 6| Step: 8
Training loss: 3.167392513676409
Validation loss: 2.664293635631693

Epoch: 6| Step: 9
Training loss: 2.967766046593298
Validation loss: 2.6660766157058045

Epoch: 6| Step: 10
Training loss: 3.4664857364780914
Validation loss: 2.670111218850967

Epoch: 6| Step: 11
Training loss: 2.4795468036275086
Validation loss: 2.662393022485507

Epoch: 6| Step: 12
Training loss: 3.4801728093879367
Validation loss: 2.663568619508587

Epoch: 6| Step: 13
Training loss: 3.2659815543425323
Validation loss: 2.664215596400168

Epoch: 73| Step: 0
Training loss: 3.127024948181625
Validation loss: 2.662935594014035

Epoch: 6| Step: 1
Training loss: 2.8282538958940537
Validation loss: 2.6617683663687433

Epoch: 6| Step: 2
Training loss: 2.364279090253024
Validation loss: 2.66281270962833

Epoch: 6| Step: 3
Training loss: 2.90756327172379
Validation loss: 2.666353125238715

Epoch: 6| Step: 4
Training loss: 3.3906659242471933
Validation loss: 2.6659041039918483

Epoch: 6| Step: 5
Training loss: 3.4326277449161973
Validation loss: 2.6637715119484886

Epoch: 6| Step: 6
Training loss: 2.8099848203147237
Validation loss: 2.657610475959246

Epoch: 6| Step: 7
Training loss: 2.6915143216918
Validation loss: 2.6556468512890254

Epoch: 6| Step: 8
Training loss: 3.728490686508073
Validation loss: 2.6524958391363676

Epoch: 6| Step: 9
Training loss: 3.0262387726365527
Validation loss: 2.656942845900073

Epoch: 6| Step: 10
Training loss: 3.5096784017229425
Validation loss: 2.6530453445124618

Epoch: 6| Step: 11
Training loss: 2.34965178973822
Validation loss: 2.6548265072731745

Epoch: 6| Step: 12
Training loss: 2.5004249211637917
Validation loss: 2.6553828388093135

Epoch: 6| Step: 13
Training loss: 2.673139663238658
Validation loss: 2.649691571671467

Epoch: 74| Step: 0
Training loss: 3.493298108624601
Validation loss: 2.651212480820318

Epoch: 6| Step: 1
Training loss: 3.0630578292085318
Validation loss: 2.650082988526932

Epoch: 6| Step: 2
Training loss: 2.5291666947374756
Validation loss: 2.647053643938102

Epoch: 6| Step: 3
Training loss: 3.171149711180892
Validation loss: 2.6452912626466754

Epoch: 6| Step: 4
Training loss: 3.0290596510616856
Validation loss: 2.6506464611010947

Epoch: 6| Step: 5
Training loss: 3.109812643411822
Validation loss: 2.6473437832751627

Epoch: 6| Step: 6
Training loss: 3.310478601342454
Validation loss: 2.6475165447722224

Epoch: 6| Step: 7
Training loss: 3.0073286187483035
Validation loss: 2.6494026986816306

Epoch: 6| Step: 8
Training loss: 3.0611594243822675
Validation loss: 2.645507264984282

Epoch: 6| Step: 9
Training loss: 2.5928545405747507
Validation loss: 2.6449998261818637

Epoch: 6| Step: 10
Training loss: 2.958976478692022
Validation loss: 2.65013757825688

Epoch: 6| Step: 11
Training loss: 3.0079472499239737
Validation loss: 2.653625665641754

Epoch: 6| Step: 12
Training loss: 2.2685078136972914
Validation loss: 2.6629144450680196

Epoch: 6| Step: 13
Training loss: 3.109082078794425
Validation loss: 2.6698659940557667

Epoch: 75| Step: 0
Training loss: 2.8734445095754633
Validation loss: 2.6543919868611137

Epoch: 6| Step: 1
Training loss: 3.453317628208617
Validation loss: 2.6509290296093995

Epoch: 6| Step: 2
Training loss: 2.9801445980961265
Validation loss: 2.645800892543246

Epoch: 6| Step: 3
Training loss: 3.4554572191246535
Validation loss: 2.6418848791184955

Epoch: 6| Step: 4
Training loss: 3.418317504528738
Validation loss: 2.6420353812619695

Epoch: 6| Step: 5
Training loss: 2.6756840374961994
Validation loss: 2.6397167356601527

Epoch: 6| Step: 6
Training loss: 2.713791282336295
Validation loss: 2.639766830602054

Epoch: 6| Step: 7
Training loss: 3.455100482633287
Validation loss: 2.6390497060051916

Epoch: 6| Step: 8
Training loss: 2.50039841338275
Validation loss: 2.6434417262502263

Epoch: 6| Step: 9
Training loss: 3.284610444403472
Validation loss: 2.6416920550041096

Epoch: 6| Step: 10
Training loss: 2.808417684795648
Validation loss: 2.6418799146335106

Epoch: 6| Step: 11
Training loss: 2.826794559026685
Validation loss: 2.6370255987291116

Epoch: 6| Step: 12
Training loss: 2.374944083910794
Validation loss: 2.6347021794325

Epoch: 6| Step: 13
Training loss: 2.547531792140014
Validation loss: 2.641168210220361

Epoch: 76| Step: 0
Training loss: 3.07676674555732
Validation loss: 2.633989272376209

Epoch: 6| Step: 1
Training loss: 2.7716760333880326
Validation loss: 2.640464281236048

Epoch: 6| Step: 2
Training loss: 2.952040377250287
Validation loss: 2.638868712510194

Epoch: 6| Step: 3
Training loss: 2.8808213053628675
Validation loss: 2.640156647520973

Epoch: 6| Step: 4
Training loss: 2.7052512213345783
Validation loss: 2.6424523603554766

Epoch: 6| Step: 5
Training loss: 2.7554941780251716
Validation loss: 2.6496500858453875

Epoch: 6| Step: 6
Training loss: 3.174353922792548
Validation loss: 2.651677627592901

Epoch: 6| Step: 7
Training loss: 3.3529330210197794
Validation loss: 2.6629292150752297

Epoch: 6| Step: 8
Training loss: 2.534514782457407
Validation loss: 2.676047513100529

Epoch: 6| Step: 9
Training loss: 2.9949371214110747
Validation loss: 2.6834665562581694

Epoch: 6| Step: 10
Training loss: 3.2548482385464976
Validation loss: 2.653234382992302

Epoch: 6| Step: 11
Training loss: 2.894545582106471
Validation loss: 2.6440584041110946

Epoch: 6| Step: 12
Training loss: 3.2622074332177755
Validation loss: 2.633733691021597

Epoch: 6| Step: 13
Training loss: 2.9880943888165667
Validation loss: 2.6334415557116757

Epoch: 77| Step: 0
Training loss: 3.5662064929852773
Validation loss: 2.6394807385188273

Epoch: 6| Step: 1
Training loss: 3.079559611505819
Validation loss: 2.6468386123875174

Epoch: 6| Step: 2
Training loss: 3.6475376759414164
Validation loss: 2.65952427656001

Epoch: 6| Step: 3
Training loss: 2.8944088476249297
Validation loss: 2.6544038044966185

Epoch: 6| Step: 4
Training loss: 3.3038984217881366
Validation loss: 2.647486895646022

Epoch: 6| Step: 5
Training loss: 2.7926996701675435
Validation loss: 2.6456955601022565

Epoch: 6| Step: 6
Training loss: 2.3336970068580274
Validation loss: 2.6450918180942913

Epoch: 6| Step: 7
Training loss: 2.767475091258692
Validation loss: 2.6483886048264687

Epoch: 6| Step: 8
Training loss: 3.0693906220271767
Validation loss: 2.647362951363324

Epoch: 6| Step: 9
Training loss: 2.7286428477855953
Validation loss: 2.6469265945864184

Epoch: 6| Step: 10
Training loss: 2.7418936112769807
Validation loss: 2.643983239806769

Epoch: 6| Step: 11
Training loss: 3.12720472763926
Validation loss: 2.6460038481332395

Epoch: 6| Step: 12
Training loss: 2.8359882781051486
Validation loss: 2.6405200989598527

Epoch: 6| Step: 13
Training loss: 2.8851847825135994
Validation loss: 2.64457872944041

Epoch: 78| Step: 0
Training loss: 3.2197347079154626
Validation loss: 2.6442214019194124

Epoch: 6| Step: 1
Training loss: 3.7935914963316804
Validation loss: 2.6753004139825163

Epoch: 6| Step: 2
Training loss: 2.8467527193676396
Validation loss: 2.646114899918323

Epoch: 6| Step: 3
Training loss: 2.911614829527996
Validation loss: 2.6379888562349096

Epoch: 6| Step: 4
Training loss: 2.9713040257646792
Validation loss: 2.633640111881268

Epoch: 6| Step: 5
Training loss: 3.12393185480405
Validation loss: 2.6321381592959723

Epoch: 6| Step: 6
Training loss: 3.3044129025338416
Validation loss: 2.63040782391651

Epoch: 6| Step: 7
Training loss: 2.6187446175385656
Validation loss: 2.6226593848725743

Epoch: 6| Step: 8
Training loss: 2.943223612184987
Validation loss: 2.623056435441803

Epoch: 6| Step: 9
Training loss: 2.4816785850605916
Validation loss: 2.621135548914146

Epoch: 6| Step: 10
Training loss: 2.9099758425099855
Validation loss: 2.621504047100496

Epoch: 6| Step: 11
Training loss: 2.8066934621744486
Validation loss: 2.627128961456419

Epoch: 6| Step: 12
Training loss: 2.591490899245371
Validation loss: 2.625807381617156

Epoch: 6| Step: 13
Training loss: 3.0664927087731653
Validation loss: 2.641337965981733

Epoch: 79| Step: 0
Training loss: 3.3019686577717144
Validation loss: 2.6529811726465984

Epoch: 6| Step: 1
Training loss: 3.53667957510886
Validation loss: 2.644850310812003

Epoch: 6| Step: 2
Training loss: 3.125102689963154
Validation loss: 2.6256937613232423

Epoch: 6| Step: 3
Training loss: 2.9130913391983944
Validation loss: 2.615304635040962

Epoch: 6| Step: 4
Training loss: 2.290342422271151
Validation loss: 2.6110592876741165

Epoch: 6| Step: 5
Training loss: 2.4486801796462485
Validation loss: 2.6141215591011626

Epoch: 6| Step: 6
Training loss: 3.2452798458801935
Validation loss: 2.615967113781637

Epoch: 6| Step: 7
Training loss: 2.794122460305051
Validation loss: 2.6142605474980396

Epoch: 6| Step: 8
Training loss: 3.22533328677689
Validation loss: 2.609311210192053

Epoch: 6| Step: 9
Training loss: 2.8450857525658386
Validation loss: 2.6053787921650935

Epoch: 6| Step: 10
Training loss: 2.693660417735584
Validation loss: 2.601469374833934

Epoch: 6| Step: 11
Training loss: 2.964954077636805
Validation loss: 2.5998172135306765

Epoch: 6| Step: 12
Training loss: 3.251171634467356
Validation loss: 2.598933883381993

Epoch: 6| Step: 13
Training loss: 2.251558611705634
Validation loss: 2.5983221855551415

Epoch: 80| Step: 0
Training loss: 3.208651654854373
Validation loss: 2.598494562798874

Epoch: 6| Step: 1
Training loss: 3.4707371973566703
Validation loss: 2.596453577532651

Epoch: 6| Step: 2
Training loss: 3.239817292984119
Validation loss: 2.599833112622805

Epoch: 6| Step: 3
Training loss: 2.5049854160881764
Validation loss: 2.5992375074560634

Epoch: 6| Step: 4
Training loss: 2.7320529342371156
Validation loss: 2.596367773334966

Epoch: 6| Step: 5
Training loss: 2.157263255120267
Validation loss: 2.599374299411743

Epoch: 6| Step: 6
Training loss: 2.80338080524373
Validation loss: 2.595645854619421

Epoch: 6| Step: 7
Training loss: 3.4135188667219634
Validation loss: 2.5970537810554664

Epoch: 6| Step: 8
Training loss: 3.8091380820950556
Validation loss: 2.59694966789759

Epoch: 6| Step: 9
Training loss: 2.7200285437432594
Validation loss: 2.5968633223197854

Epoch: 6| Step: 10
Training loss: 3.1417890071236805
Validation loss: 2.5950024522990325

Epoch: 6| Step: 11
Training loss: 2.4148264049745087
Validation loss: 2.597181387721358

Epoch: 6| Step: 12
Training loss: 2.1968994920648655
Validation loss: 2.597402625663739

Epoch: 6| Step: 13
Training loss: 3.0155443566168336
Validation loss: 2.5967913875266646

Epoch: 81| Step: 0
Training loss: 3.0356765360047833
Validation loss: 2.5973236820993773

Epoch: 6| Step: 1
Training loss: 2.4502102002649035
Validation loss: 2.60158814650371

Epoch: 6| Step: 2
Training loss: 2.8597635307455453
Validation loss: 2.6022315716548

Epoch: 6| Step: 3
Training loss: 3.264943320934686
Validation loss: 2.606930410996131

Epoch: 6| Step: 4
Training loss: 2.559198718585033
Validation loss: 2.60714538197146

Epoch: 6| Step: 5
Training loss: 2.895499084356575
Validation loss: 2.6135094001026684

Epoch: 6| Step: 6
Training loss: 3.0123345800545436
Validation loss: 2.6073803065588534

Epoch: 6| Step: 7
Training loss: 2.909911771400292
Validation loss: 2.59805155147348

Epoch: 6| Step: 8
Training loss: 2.924981082952901
Validation loss: 2.6007303512478326

Epoch: 6| Step: 9
Training loss: 2.816509779298404
Validation loss: 2.5981989241026153

Epoch: 6| Step: 10
Training loss: 3.064062226104335
Validation loss: 2.594895726685288

Epoch: 6| Step: 11
Training loss: 2.9551804267032695
Validation loss: 2.5920816228259778

Epoch: 6| Step: 12
Training loss: 3.1960815399615523
Validation loss: 2.5919006224516017

Epoch: 6| Step: 13
Training loss: 3.4774703651333767
Validation loss: 2.5905638388008856

Epoch: 82| Step: 0
Training loss: 2.982744820228116
Validation loss: 2.593003901188517

Epoch: 6| Step: 1
Training loss: 2.851304635708074
Validation loss: 2.5934127487546497

Epoch: 6| Step: 2
Training loss: 3.212761799278971
Validation loss: 2.6026667538438533

Epoch: 6| Step: 3
Training loss: 2.7748864056131013
Validation loss: 2.5993828916334594

Epoch: 6| Step: 4
Training loss: 2.614262737259556
Validation loss: 2.598096299445445

Epoch: 6| Step: 5
Training loss: 2.939250181169075
Validation loss: 2.5985183335143613

Epoch: 6| Step: 6
Training loss: 2.2459175372454006
Validation loss: 2.597335636999004

Epoch: 6| Step: 7
Training loss: 2.5954815703273986
Validation loss: 2.6005601997838252

Epoch: 6| Step: 8
Training loss: 3.7134931578105093
Validation loss: 2.590353319023536

Epoch: 6| Step: 9
Training loss: 3.4739231334696887
Validation loss: 2.590975918050045

Epoch: 6| Step: 10
Training loss: 2.0962156893720714
Validation loss: 2.5951031059949914

Epoch: 6| Step: 11
Training loss: 2.9120713864054713
Validation loss: 2.591544068091078

Epoch: 6| Step: 12
Training loss: 3.343995415068408
Validation loss: 2.6089628032933

Epoch: 6| Step: 13
Training loss: 3.5564910002505674
Validation loss: 2.6420190447709877

Epoch: 83| Step: 0
Training loss: 2.5975584083429997
Validation loss: 2.637660017798427

Epoch: 6| Step: 1
Training loss: 2.3761975130387794
Validation loss: 2.6421143288711284

Epoch: 6| Step: 2
Training loss: 2.6702227028825707
Validation loss: 2.638191977463132

Epoch: 6| Step: 3
Training loss: 2.7362690496500437
Validation loss: 2.6274582768397665

Epoch: 6| Step: 4
Training loss: 3.352180761830327
Validation loss: 2.632629082391981

Epoch: 6| Step: 5
Training loss: 2.611203586573101
Validation loss: 2.636845836668253

Epoch: 6| Step: 6
Training loss: 2.9403004385098424
Validation loss: 2.6093785683397064

Epoch: 6| Step: 7
Training loss: 3.638059309599162
Validation loss: 2.6168596498555887

Epoch: 6| Step: 8
Training loss: 3.3225950047534822
Validation loss: 2.5951597462475804

Epoch: 6| Step: 9
Training loss: 3.594627604926973
Validation loss: 2.586108909462572

Epoch: 6| Step: 10
Training loss: 2.802094432331401
Validation loss: 2.5815753499223315

Epoch: 6| Step: 11
Training loss: 2.405830842208321
Validation loss: 2.588574372118358

Epoch: 6| Step: 12
Training loss: 3.1103406777183955
Validation loss: 2.5919870116945134

Epoch: 6| Step: 13
Training loss: 2.8624899318468033
Validation loss: 2.594369813507737

Epoch: 84| Step: 0
Training loss: 2.9386391561447036
Validation loss: 2.5930017903644713

Epoch: 6| Step: 1
Training loss: 3.0867569620040496
Validation loss: 2.5931159978125193

Epoch: 6| Step: 2
Training loss: 3.32740267226496
Validation loss: 2.5989981370069737

Epoch: 6| Step: 3
Training loss: 2.5003494018532004
Validation loss: 2.59863329688834

Epoch: 6| Step: 4
Training loss: 2.625458631867759
Validation loss: 2.5960891658664265

Epoch: 6| Step: 5
Training loss: 2.8755787805873547
Validation loss: 2.5968081467562287

Epoch: 6| Step: 6
Training loss: 3.636028220139575
Validation loss: 2.593127034890371

Epoch: 6| Step: 7
Training loss: 2.8500308587260803
Validation loss: 2.594290719352779

Epoch: 6| Step: 8
Training loss: 3.1326018379140277
Validation loss: 2.5885875637834777

Epoch: 6| Step: 9
Training loss: 3.233616836808288
Validation loss: 2.587614699188426

Epoch: 6| Step: 10
Training loss: 2.689841736175909
Validation loss: 2.583582470802499

Epoch: 6| Step: 11
Training loss: 3.0492183183908708
Validation loss: 2.5799403099350253

Epoch: 6| Step: 12
Training loss: 2.362027527728677
Validation loss: 2.5865213951688317

Epoch: 6| Step: 13
Training loss: 2.8304075019141837
Validation loss: 2.60113157412088

Epoch: 85| Step: 0
Training loss: 3.5089290345724473
Validation loss: 2.6201986770053995

Epoch: 6| Step: 1
Training loss: 2.6911470374199475
Validation loss: 2.6470751162063846

Epoch: 6| Step: 2
Training loss: 2.9769885942152836
Validation loss: 2.640378450845969

Epoch: 6| Step: 3
Training loss: 3.079683635366677
Validation loss: 2.6730965042938366

Epoch: 6| Step: 4
Training loss: 3.024119061280782
Validation loss: 2.648658991225116

Epoch: 6| Step: 5
Training loss: 2.6063816467261876
Validation loss: 2.6201832287717703

Epoch: 6| Step: 6
Training loss: 2.7935515535949524
Validation loss: 2.6004568623861806

Epoch: 6| Step: 7
Training loss: 3.5237162748294657
Validation loss: 2.586928025700244

Epoch: 6| Step: 8
Training loss: 3.170977686346072
Validation loss: 2.5793510417893564

Epoch: 6| Step: 9
Training loss: 2.5913660514963723
Validation loss: 2.5809571462134637

Epoch: 6| Step: 10
Training loss: 3.025003821000137
Validation loss: 2.5707596133996153

Epoch: 6| Step: 11
Training loss: 2.4625876086766363
Validation loss: 2.5781165029933266

Epoch: 6| Step: 12
Training loss: 2.923683952900059
Validation loss: 2.5781651359210764

Epoch: 6| Step: 13
Training loss: 2.4857171230112054
Validation loss: 2.579613845813316

Epoch: 86| Step: 0
Training loss: 3.4102832119478523
Validation loss: 2.577114944754226

Epoch: 6| Step: 1
Training loss: 3.221191073179553
Validation loss: 2.5738241159681037

Epoch: 6| Step: 2
Training loss: 2.93387981295007
Validation loss: 2.5747370599500834

Epoch: 6| Step: 3
Training loss: 2.599247449390231
Validation loss: 2.580879059473301

Epoch: 6| Step: 4
Training loss: 2.56355468630956
Validation loss: 2.593247702163583

Epoch: 6| Step: 5
Training loss: 2.723403981232883
Validation loss: 2.6042642141140933

Epoch: 6| Step: 6
Training loss: 2.7792040554049984
Validation loss: 2.6355673809180264

Epoch: 6| Step: 7
Training loss: 2.9100546595103487
Validation loss: 2.6426326185022524

Epoch: 6| Step: 8
Training loss: 3.304705969215529
Validation loss: 2.6508944004501727

Epoch: 6| Step: 9
Training loss: 3.2140550167310034
Validation loss: 2.6648544112700554

Epoch: 6| Step: 10
Training loss: 2.669504910261801
Validation loss: 2.6372263775153346

Epoch: 6| Step: 11
Training loss: 3.332622802028544
Validation loss: 2.615961308271355

Epoch: 6| Step: 12
Training loss: 2.6937196309442224
Validation loss: 2.5768104381344425

Epoch: 6| Step: 13
Training loss: 2.6597499453098834
Validation loss: 2.5744262354754652

Epoch: 87| Step: 0
Training loss: 3.0302160013590744
Validation loss: 2.5746230424264014

Epoch: 6| Step: 1
Training loss: 2.7926563008142513
Validation loss: 2.578319815903516

Epoch: 6| Step: 2
Training loss: 2.7479615025384896
Validation loss: 2.5790732749418988

Epoch: 6| Step: 3
Training loss: 2.582772429906014
Validation loss: 2.5839288291814273

Epoch: 6| Step: 4
Training loss: 3.285560900502105
Validation loss: 2.586920310768901

Epoch: 6| Step: 5
Training loss: 2.816804939653117
Validation loss: 2.5896652007442533

Epoch: 6| Step: 6
Training loss: 3.029117738799979
Validation loss: 2.5903825304788954

Epoch: 6| Step: 7
Training loss: 3.172378725540076
Validation loss: 2.593416601014627

Epoch: 6| Step: 8
Training loss: 3.4519772930967645
Validation loss: 2.5821750166398805

Epoch: 6| Step: 9
Training loss: 3.3936394155340097
Validation loss: 2.590191691063371

Epoch: 6| Step: 10
Training loss: 2.6533712607537225
Validation loss: 2.5857995659491895

Epoch: 6| Step: 11
Training loss: 3.1863098914712147
Validation loss: 2.5895084709813316

Epoch: 6| Step: 12
Training loss: 2.2573262783390184
Validation loss: 2.5888284914817308

Epoch: 6| Step: 13
Training loss: 2.5559493282112986
Validation loss: 2.5828612038715772

Epoch: 88| Step: 0
Training loss: 2.8432254517076694
Validation loss: 2.584931155010576

Epoch: 6| Step: 1
Training loss: 2.8844044329463046
Validation loss: 2.5907950452583743

Epoch: 6| Step: 2
Training loss: 3.495103953811563
Validation loss: 2.5942454234956918

Epoch: 6| Step: 3
Training loss: 3.010618174495487
Validation loss: 2.6108630341858117

Epoch: 6| Step: 4
Training loss: 2.580503164507118
Validation loss: 2.5935370180762356

Epoch: 6| Step: 5
Training loss: 2.974972437883173
Validation loss: 2.593064062411781

Epoch: 6| Step: 6
Training loss: 3.14988111241343
Validation loss: 2.591655413753518

Epoch: 6| Step: 7
Training loss: 2.5012997109783996
Validation loss: 2.5854590139050786

Epoch: 6| Step: 8
Training loss: 2.4796554553744286
Validation loss: 2.591232238176468

Epoch: 6| Step: 9
Training loss: 3.179052491010582
Validation loss: 2.5942202143193467

Epoch: 6| Step: 10
Training loss: 2.7915190662441463
Validation loss: 2.592615471730977

Epoch: 6| Step: 11
Training loss: 3.2628442341518373
Validation loss: 2.5923272085390634

Epoch: 6| Step: 12
Training loss: 2.799069699645166
Validation loss: 2.6014561193951518

Epoch: 6| Step: 13
Training loss: 3.098086775774212
Validation loss: 2.6053740395373377

Epoch: 89| Step: 0
Training loss: 2.7322182132932338
Validation loss: 2.58387887601518

Epoch: 6| Step: 1
Training loss: 2.4485317891265534
Validation loss: 2.574960619550355

Epoch: 6| Step: 2
Training loss: 2.585478773659569
Validation loss: 2.5758459354933065

Epoch: 6| Step: 3
Training loss: 3.3077424630745313
Validation loss: 2.5665516330407945

Epoch: 6| Step: 4
Training loss: 2.587734462416833
Validation loss: 2.566671186500962

Epoch: 6| Step: 5
Training loss: 2.9755099781082532
Validation loss: 2.563588647223199

Epoch: 6| Step: 6
Training loss: 2.91194857505832
Validation loss: 2.5626063030932578

Epoch: 6| Step: 7
Training loss: 3.0038503733424684
Validation loss: 2.574969301201051

Epoch: 6| Step: 8
Training loss: 2.2878695038414376
Validation loss: 2.5801633392093377

Epoch: 6| Step: 9
Training loss: 3.459368141119273
Validation loss: 2.576352647001429

Epoch: 6| Step: 10
Training loss: 3.4502934372545218
Validation loss: 2.574171093198916

Epoch: 6| Step: 11
Training loss: 2.5422489770772247
Validation loss: 2.5762838711094984

Epoch: 6| Step: 12
Training loss: 3.315217540847003
Validation loss: 2.5689815532945057

Epoch: 6| Step: 13
Training loss: 3.32126853194
Validation loss: 2.569840018092795

Epoch: 90| Step: 0
Training loss: 2.615478321916852
Validation loss: 2.561622921729363

Epoch: 6| Step: 1
Training loss: 2.5640789842744036
Validation loss: 2.5604343747680964

Epoch: 6| Step: 2
Training loss: 2.6914661328833414
Validation loss: 2.563054696790059

Epoch: 6| Step: 3
Training loss: 3.129831774886138
Validation loss: 2.5631461140542084

Epoch: 6| Step: 4
Training loss: 2.8024642761022567
Validation loss: 2.563379228422871

Epoch: 6| Step: 5
Training loss: 2.8140083506879825
Validation loss: 2.560123282820516

Epoch: 6| Step: 6
Training loss: 3.3169371917914803
Validation loss: 2.5581100842111058

Epoch: 6| Step: 7
Training loss: 3.1288838475029
Validation loss: 2.5584841378698644

Epoch: 6| Step: 8
Training loss: 3.4381836644812283
Validation loss: 2.5666878367641526

Epoch: 6| Step: 9
Training loss: 2.997286204905399
Validation loss: 2.564911898552152

Epoch: 6| Step: 10
Training loss: 2.394146588094477
Validation loss: 2.584902164606134

Epoch: 6| Step: 11
Training loss: 3.7992317828598687
Validation loss: 2.6008265363759224

Epoch: 6| Step: 12
Training loss: 2.498266191078688
Validation loss: 2.5910410626067195

Epoch: 6| Step: 13
Training loss: 2.1749490622332575
Validation loss: 2.587931341530855

Epoch: 91| Step: 0
Training loss: 2.475706704709615
Validation loss: 2.572839344608655

Epoch: 6| Step: 1
Training loss: 2.997784750348802
Validation loss: 2.5609264990168192

Epoch: 6| Step: 2
Training loss: 3.0534307914350207
Validation loss: 2.5559015484194934

Epoch: 6| Step: 3
Training loss: 3.126851258295461
Validation loss: 2.558064293016639

Epoch: 6| Step: 4
Training loss: 2.7314683560656507
Validation loss: 2.5557252922806053

Epoch: 6| Step: 5
Training loss: 2.944397478108932
Validation loss: 2.5566630401063652

Epoch: 6| Step: 6
Training loss: 2.8015603826613757
Validation loss: 2.555925045243741

Epoch: 6| Step: 7
Training loss: 3.3019924853289635
Validation loss: 2.5557052051821887

Epoch: 6| Step: 8
Training loss: 2.578076541329621
Validation loss: 2.5527304924800123

Epoch: 6| Step: 9
Training loss: 3.8692530192534518
Validation loss: 2.552697389388721

Epoch: 6| Step: 10
Training loss: 2.221385089499529
Validation loss: 2.553911787580736

Epoch: 6| Step: 11
Training loss: 2.7874712852743877
Validation loss: 2.554320298304455

Epoch: 6| Step: 12
Training loss: 2.8067022965888717
Validation loss: 2.5553187207352726

Epoch: 6| Step: 13
Training loss: 2.811331188205006
Validation loss: 2.5533162523922073

Epoch: 92| Step: 0
Training loss: 2.719846657750176
Validation loss: 2.556605806692306

Epoch: 6| Step: 1
Training loss: 2.396379911575589
Validation loss: 2.55284021307245

Epoch: 6| Step: 2
Training loss: 2.954802505941995
Validation loss: 2.5552234998674224

Epoch: 6| Step: 3
Training loss: 2.9924609505026467
Validation loss: 2.552748615542679

Epoch: 6| Step: 4
Training loss: 2.8850644627712745
Validation loss: 2.552535973280603

Epoch: 6| Step: 5
Training loss: 3.0697921816788005
Validation loss: 2.550144199361431

Epoch: 6| Step: 6
Training loss: 3.153158354417397
Validation loss: 2.5501285760640617

Epoch: 6| Step: 7
Training loss: 3.273903023841953
Validation loss: 2.550250634485929

Epoch: 6| Step: 8
Training loss: 2.6349932867033417
Validation loss: 2.5488218004494514

Epoch: 6| Step: 9
Training loss: 3.5668541249957255
Validation loss: 2.554231990733718

Epoch: 6| Step: 10
Training loss: 2.6115181168320922
Validation loss: 2.5491673244271422

Epoch: 6| Step: 11
Training loss: 1.8059843613801878
Validation loss: 2.5510723727606917

Epoch: 6| Step: 12
Training loss: 3.453679105049677
Validation loss: 2.553404209105689

Epoch: 6| Step: 13
Training loss: 2.8182821388790993
Validation loss: 2.556109509775834

Epoch: 93| Step: 0
Training loss: 2.988238804334988
Validation loss: 2.570908379973054

Epoch: 6| Step: 1
Training loss: 2.950519360875534
Validation loss: 2.5846074578148808

Epoch: 6| Step: 2
Training loss: 2.728482595037641
Validation loss: 2.6055821335377454

Epoch: 6| Step: 3
Training loss: 3.0713103325475717
Validation loss: 2.6123891066323273

Epoch: 6| Step: 4
Training loss: 3.0712080176111427
Validation loss: 2.586350615705011

Epoch: 6| Step: 5
Training loss: 2.6075282157329585
Validation loss: 2.5659819236398542

Epoch: 6| Step: 6
Training loss: 3.128922404082051
Validation loss: 2.5525397616876626

Epoch: 6| Step: 7
Training loss: 2.9936296856940006
Validation loss: 2.5481412180811795

Epoch: 6| Step: 8
Training loss: 2.8408146055288155
Validation loss: 2.550471049246005

Epoch: 6| Step: 9
Training loss: 2.876137715667465
Validation loss: 2.55067950964504

Epoch: 6| Step: 10
Training loss: 3.316372317442719
Validation loss: 2.556051330203384

Epoch: 6| Step: 11
Training loss: 2.9519525047141073
Validation loss: 2.553219888501083

Epoch: 6| Step: 12
Training loss: 2.624594339179193
Validation loss: 2.5567395100982604

Epoch: 6| Step: 13
Training loss: 2.667929072385231
Validation loss: 2.5569300649755293

Epoch: 94| Step: 0
Training loss: 3.1971427320609136
Validation loss: 2.5612627094178295

Epoch: 6| Step: 1
Training loss: 3.538420427364246
Validation loss: 2.558607947911261

Epoch: 6| Step: 2
Training loss: 3.3965615893861196
Validation loss: 2.555049083276705

Epoch: 6| Step: 3
Training loss: 2.487913478818823
Validation loss: 2.5488518218087455

Epoch: 6| Step: 4
Training loss: 2.7201420519704387
Validation loss: 2.5472428039712773

Epoch: 6| Step: 5
Training loss: 2.7291570959335902
Validation loss: 2.545035780163123

Epoch: 6| Step: 6
Training loss: 2.3800356835006338
Validation loss: 2.547745146893824

Epoch: 6| Step: 7
Training loss: 2.9437794224266924
Validation loss: 2.548923860363725

Epoch: 6| Step: 8
Training loss: 2.8636108042249266
Validation loss: 2.5593655271806974

Epoch: 6| Step: 9
Training loss: 3.2657593329876735
Validation loss: 2.5589883244101483

Epoch: 6| Step: 10
Training loss: 2.8631296989437334
Validation loss: 2.576041086964114

Epoch: 6| Step: 11
Training loss: 3.009987735659938
Validation loss: 2.58997435178516

Epoch: 6| Step: 12
Training loss: 1.9538023727729035
Validation loss: 2.592122646383075

Epoch: 6| Step: 13
Training loss: 3.460595796478052
Validation loss: 2.602057250810635

Epoch: 95| Step: 0
Training loss: 2.9179754499692994
Validation loss: 2.613293032818346

Epoch: 6| Step: 1
Training loss: 2.859613794246715
Validation loss: 2.660187718099872

Epoch: 6| Step: 2
Training loss: 2.9554982816393984
Validation loss: 2.6659096372639888

Epoch: 6| Step: 3
Training loss: 3.2304122163376268
Validation loss: 2.671836029019913

Epoch: 6| Step: 4
Training loss: 2.8157181871512544
Validation loss: 2.5859078417762196

Epoch: 6| Step: 5
Training loss: 3.167250696501195
Validation loss: 2.545659770647796

Epoch: 6| Step: 6
Training loss: 2.6457817693376513
Validation loss: 2.5416902046451844

Epoch: 6| Step: 7
Training loss: 2.9093812870732116
Validation loss: 2.547564619201337

Epoch: 6| Step: 8
Training loss: 2.808155349238019
Validation loss: 2.5612426702520157

Epoch: 6| Step: 9
Training loss: 2.5821679060376193
Validation loss: 2.5810253227975557

Epoch: 6| Step: 10
Training loss: 3.2444172373230398
Validation loss: 2.566732362453247

Epoch: 6| Step: 11
Training loss: 2.894444596902164
Validation loss: 2.5494866996006187

Epoch: 6| Step: 12
Training loss: 3.337784481425636
Validation loss: 2.549580018116476

Epoch: 6| Step: 13
Training loss: 2.8154900657168276
Validation loss: 2.5442599020511403

Epoch: 96| Step: 0
Training loss: 3.309848660008588
Validation loss: 2.5409856664302692

Epoch: 6| Step: 1
Training loss: 2.8287403427815505
Validation loss: 2.539585380637833

Epoch: 6| Step: 2
Training loss: 2.953653923987295
Validation loss: 2.5384260835539685

Epoch: 6| Step: 3
Training loss: 2.947149295925326
Validation loss: 2.540218736329891

Epoch: 6| Step: 4
Training loss: 2.5621609347180963
Validation loss: 2.539970028020312

Epoch: 6| Step: 5
Training loss: 2.8768437320088203
Validation loss: 2.557908038375061

Epoch: 6| Step: 6
Training loss: 2.6973867202745287
Validation loss: 2.5551009505753686

Epoch: 6| Step: 7
Training loss: 2.7596434655929634
Validation loss: 2.570692460995736

Epoch: 6| Step: 8
Training loss: 2.9595148297218836
Validation loss: 2.5626553344066676

Epoch: 6| Step: 9
Training loss: 2.0198183427465235
Validation loss: 2.5656109985594626

Epoch: 6| Step: 10
Training loss: 2.9973523854615154
Validation loss: 2.5643495037463135

Epoch: 6| Step: 11
Training loss: 3.4169457174337245
Validation loss: 2.56635951199417

Epoch: 6| Step: 12
Training loss: 3.334759184737397
Validation loss: 2.574173316067257

Epoch: 6| Step: 13
Training loss: 2.7218070546198025
Validation loss: 2.5688615834246296

Epoch: 97| Step: 0
Training loss: 3.289776867195935
Validation loss: 2.569642794431722

Epoch: 6| Step: 1
Training loss: 2.57878215390683
Validation loss: 2.570692524820173

Epoch: 6| Step: 2
Training loss: 2.9833156443094557
Validation loss: 2.573541470133423

Epoch: 6| Step: 3
Training loss: 2.5950159866928386
Validation loss: 2.5682625783404034

Epoch: 6| Step: 4
Training loss: 2.183025907271008
Validation loss: 2.5576067028441485

Epoch: 6| Step: 5
Training loss: 2.935662689259422
Validation loss: 2.553543503513647

Epoch: 6| Step: 6
Training loss: 3.159764514309361
Validation loss: 2.5559588617957587

Epoch: 6| Step: 7
Training loss: 3.1064872175242573
Validation loss: 2.564663897535834

Epoch: 6| Step: 8
Training loss: 3.3939756371113177
Validation loss: 2.5590267799080038

Epoch: 6| Step: 9
Training loss: 2.8835274654884206
Validation loss: 2.5435782845123693

Epoch: 6| Step: 10
Training loss: 2.705809566611553
Validation loss: 2.541937749222547

Epoch: 6| Step: 11
Training loss: 3.17977027879042
Validation loss: 2.5371734088906095

Epoch: 6| Step: 12
Training loss: 2.6897165783045702
Validation loss: 2.5409603869097515

Epoch: 6| Step: 13
Training loss: 2.787752928613153
Validation loss: 2.5400237303017645

Epoch: 98| Step: 0
Training loss: 2.516492611085021
Validation loss: 2.5376635159458143

Epoch: 6| Step: 1
Training loss: 3.1932360330728824
Validation loss: 2.533647453908616

Epoch: 6| Step: 2
Training loss: 3.5159362655175013
Validation loss: 2.5335206421445085

Epoch: 6| Step: 3
Training loss: 2.8556998559863516
Validation loss: 2.5351585798861005

Epoch: 6| Step: 4
Training loss: 2.760411494028295
Validation loss: 2.53085896357913

Epoch: 6| Step: 5
Training loss: 3.0112928195694337
Validation loss: 2.537356110607177

Epoch: 6| Step: 6
Training loss: 3.469113717470387
Validation loss: 2.5321289009245405

Epoch: 6| Step: 7
Training loss: 3.073129385789306
Validation loss: 2.54090354238221

Epoch: 6| Step: 8
Training loss: 2.7377333589489954
Validation loss: 2.546672937593995

Epoch: 6| Step: 9
Training loss: 2.4469476175068126
Validation loss: 2.5350976795599274

Epoch: 6| Step: 10
Training loss: 2.4862901515413216
Validation loss: 2.5328434312054533

Epoch: 6| Step: 11
Training loss: 3.1214047922685815
Validation loss: 2.534135687481236

Epoch: 6| Step: 12
Training loss: 2.5441556115091957
Validation loss: 2.5345650672563576

Epoch: 6| Step: 13
Training loss: 2.520759602458884
Validation loss: 2.532312929358415

Epoch: 99| Step: 0
Training loss: 2.9737599713678255
Validation loss: 2.5308993658914227

Epoch: 6| Step: 1
Training loss: 2.8353262418575595
Validation loss: 2.5307540194948133

Epoch: 6| Step: 2
Training loss: 2.4833599392107866
Validation loss: 2.539851684600312

Epoch: 6| Step: 3
Training loss: 3.2327320883528095
Validation loss: 2.5569519962889973

Epoch: 6| Step: 4
Training loss: 2.7034386248923
Validation loss: 2.5798607117858094

Epoch: 6| Step: 5
Training loss: 3.030405143115504
Validation loss: 2.617906614959278

Epoch: 6| Step: 6
Training loss: 2.6532122127006312
Validation loss: 2.5963852007987573

Epoch: 6| Step: 7
Training loss: 2.6056707895802713
Validation loss: 2.568060921971981

Epoch: 6| Step: 8
Training loss: 2.678385693604649
Validation loss: 2.5558461846903326

Epoch: 6| Step: 9
Training loss: 2.9572320061166133
Validation loss: 2.5428077305649914

Epoch: 6| Step: 10
Training loss: 3.3898258234250296
Validation loss: 2.5314556024652437

Epoch: 6| Step: 11
Training loss: 2.989812082362669
Validation loss: 2.5315470316760185

Epoch: 6| Step: 12
Training loss: 2.8175479093470734
Validation loss: 2.5292835018114666

Epoch: 6| Step: 13
Training loss: 3.461978247818247
Validation loss: 2.532421902697284

Epoch: 100| Step: 0
Training loss: 2.6973579053955383
Validation loss: 2.529341039265284

Epoch: 6| Step: 1
Training loss: 3.385012996766962
Validation loss: 2.5287634580970804

Epoch: 6| Step: 2
Training loss: 3.2947496551205515
Validation loss: 2.5297509974203773

Epoch: 6| Step: 3
Training loss: 2.4618468526997086
Validation loss: 2.5290699347548697

Epoch: 6| Step: 4
Training loss: 2.6295842604337567
Validation loss: 2.5298550386658376

Epoch: 6| Step: 5
Training loss: 3.2416734402805614
Validation loss: 2.533186094747194

Epoch: 6| Step: 6
Training loss: 3.02493225526222
Validation loss: 2.5346111889311347

Epoch: 6| Step: 7
Training loss: 2.8903622069628168
Validation loss: 2.534114353863802

Epoch: 6| Step: 8
Training loss: 2.9720371719541214
Validation loss: 2.5420667379510613

Epoch: 6| Step: 9
Training loss: 2.8581817305002546
Validation loss: 2.591395226803481

Epoch: 6| Step: 10
Training loss: 2.608534352008171
Validation loss: 2.597124690873466

Epoch: 6| Step: 11
Training loss: 2.3744584520198817
Validation loss: 2.5940060460125673

Epoch: 6| Step: 12
Training loss: 3.3124730810835024
Validation loss: 2.560187908673573

Epoch: 6| Step: 13
Training loss: 2.3444431551507394
Validation loss: 2.5375588007382546

Epoch: 101| Step: 0
Training loss: 3.000253189846823
Validation loss: 2.5309745023883043

Epoch: 6| Step: 1
Training loss: 3.1079064356443755
Validation loss: 2.5358623663520716

Epoch: 6| Step: 2
Training loss: 2.6867067807644482
Validation loss: 2.5360392245950236

Epoch: 6| Step: 3
Training loss: 3.2433918014645746
Validation loss: 2.528612174994854

Epoch: 6| Step: 4
Training loss: 2.8666060271244276
Validation loss: 2.5285008606275343

Epoch: 6| Step: 5
Training loss: 2.720498235454103
Validation loss: 2.5366813738647775

Epoch: 6| Step: 6
Training loss: 2.59398512176741
Validation loss: 2.5343122484418985

Epoch: 6| Step: 7
Training loss: 2.8965191109157042
Validation loss: 2.5334559644357992

Epoch: 6| Step: 8
Training loss: 2.921148036341145
Validation loss: 2.525604840181842

Epoch: 6| Step: 9
Training loss: 2.19078014221664
Validation loss: 2.5260881472743852

Epoch: 6| Step: 10
Training loss: 2.838971829265532
Validation loss: 2.5274355277778033

Epoch: 6| Step: 11
Training loss: 3.0445721653633013
Validation loss: 2.5302253461129776

Epoch: 6| Step: 12
Training loss: 3.070650116118754
Validation loss: 2.5296443848557852

Epoch: 6| Step: 13
Training loss: 3.3544007845534924
Validation loss: 2.5279692355302856

Epoch: 102| Step: 0
Training loss: 3.1096896678482673
Validation loss: 2.533217024993718

Epoch: 6| Step: 1
Training loss: 2.5092067942413774
Validation loss: 2.533703265263168

Epoch: 6| Step: 2
Training loss: 2.706504869683249
Validation loss: 2.537679121023039

Epoch: 6| Step: 3
Training loss: 2.9487873494498364
Validation loss: 2.534496023263139

Epoch: 6| Step: 4
Training loss: 3.0944869579755956
Validation loss: 2.5375940299089157

Epoch: 6| Step: 5
Training loss: 2.5102207112635715
Validation loss: 2.5441632057179486

Epoch: 6| Step: 6
Training loss: 3.016755045514745
Validation loss: 2.5422532265322175

Epoch: 6| Step: 7
Training loss: 2.9989749428776182
Validation loss: 2.5359596920752767

Epoch: 6| Step: 8
Training loss: 2.8718501541341417
Validation loss: 2.5308264972211774

Epoch: 6| Step: 9
Training loss: 3.254769859791927
Validation loss: 2.528059862950283

Epoch: 6| Step: 10
Training loss: 2.3157152042503077
Validation loss: 2.528097639979396

Epoch: 6| Step: 11
Training loss: 3.0512969964583427
Validation loss: 2.5315648435973226

Epoch: 6| Step: 12
Training loss: 2.827503283538396
Validation loss: 2.5259189167820333

Epoch: 6| Step: 13
Training loss: 3.1880640764964507
Validation loss: 2.528867345838107

Epoch: 103| Step: 0
Training loss: 2.7025821559674035
Validation loss: 2.531541859926912

Epoch: 6| Step: 1
Training loss: 2.4353949431360684
Validation loss: 2.530669477589557

Epoch: 6| Step: 2
Training loss: 2.8226881509514956
Validation loss: 2.528332589617459

Epoch: 6| Step: 3
Training loss: 2.8093792873939667
Validation loss: 2.5373564116941476

Epoch: 6| Step: 4
Training loss: 3.380795765261293
Validation loss: 2.537660169029656

Epoch: 6| Step: 5
Training loss: 3.1663303865935135
Validation loss: 2.5416626525906385

Epoch: 6| Step: 6
Training loss: 2.5434875427864903
Validation loss: 2.556366194981478

Epoch: 6| Step: 7
Training loss: 2.894199779645827
Validation loss: 2.5462162231039525

Epoch: 6| Step: 8
Training loss: 2.7725978386198094
Validation loss: 2.5615109731759627

Epoch: 6| Step: 9
Training loss: 2.862327510517589
Validation loss: 2.5604815032769754

Epoch: 6| Step: 10
Training loss: 3.1929744010111785
Validation loss: 2.560418423769085

Epoch: 6| Step: 11
Training loss: 3.3773148686561485
Validation loss: 2.5609999216982895

Epoch: 6| Step: 12
Training loss: 2.9662413588702226
Validation loss: 2.547027964791999

Epoch: 6| Step: 13
Training loss: 1.8246202047553794
Validation loss: 2.55311752034878

Epoch: 104| Step: 0
Training loss: 2.8921242614789997
Validation loss: 2.5267706822636056

Epoch: 6| Step: 1
Training loss: 3.513493684466869
Validation loss: 2.518788182266327

Epoch: 6| Step: 2
Training loss: 1.933219858106002
Validation loss: 2.518807656913157

Epoch: 6| Step: 3
Training loss: 3.4425538798363307
Validation loss: 2.5222784822327156

Epoch: 6| Step: 4
Training loss: 3.145970895214251
Validation loss: 2.520991652366546

Epoch: 6| Step: 5
Training loss: 2.729384920745563
Validation loss: 2.5200213924176427

Epoch: 6| Step: 6
Training loss: 3.2458986666710463
Validation loss: 2.5161169120590263

Epoch: 6| Step: 7
Training loss: 2.824640983791904
Validation loss: 2.516454768847518

Epoch: 6| Step: 8
Training loss: 2.4903697496904633
Validation loss: 2.5233597891570176

Epoch: 6| Step: 9
Training loss: 3.324046613492638
Validation loss: 2.519589954381366

Epoch: 6| Step: 10
Training loss: 2.446886232625579
Validation loss: 2.5197687900522174

Epoch: 6| Step: 11
Training loss: 2.6768541844084375
Validation loss: 2.5231569348106873

Epoch: 6| Step: 12
Training loss: 2.3411172957726656
Validation loss: 2.5225814321713047

Epoch: 6| Step: 13
Training loss: 2.9905786397085032
Validation loss: 2.5365289443837695

Epoch: 105| Step: 0
Training loss: 2.518227125848826
Validation loss: 2.5496146488191243

Epoch: 6| Step: 1
Training loss: 2.9519411973963408
Validation loss: 2.548900465959617

Epoch: 6| Step: 2
Training loss: 2.6480673922407787
Validation loss: 2.54740506973756

Epoch: 6| Step: 3
Training loss: 2.7648310841843964
Validation loss: 2.5934746456849838

Epoch: 6| Step: 4
Training loss: 2.9756828870713323
Validation loss: 2.6708200777249713

Epoch: 6| Step: 5
Training loss: 3.53272371851209
Validation loss: 2.7453793303686354

Epoch: 6| Step: 6
Training loss: 2.698106462045148
Validation loss: 2.7490470611129

Epoch: 6| Step: 7
Training loss: 3.6111024628234074
Validation loss: 2.7951139890526058

Epoch: 6| Step: 8
Training loss: 2.799082902171924
Validation loss: 2.677793913569826

Epoch: 6| Step: 9
Training loss: 2.521323532068631
Validation loss: 2.5554336101069075

Epoch: 6| Step: 10
Training loss: 2.854788014146215
Validation loss: 2.524559929275247

Epoch: 6| Step: 11
Training loss: 3.0345035671100655
Validation loss: 2.5390879791470646

Epoch: 6| Step: 12
Training loss: 2.868825169328527
Validation loss: 2.553024099175637

Epoch: 6| Step: 13
Training loss: 3.0810020672012124
Validation loss: 2.57345110951558

Epoch: 106| Step: 0
Training loss: 2.862869878468115
Validation loss: 2.5895795943405844

Epoch: 6| Step: 1
Training loss: 3.021507258165206
Validation loss: 2.5915539782072505

Epoch: 6| Step: 2
Training loss: 3.026428635629801
Validation loss: 2.6031555326048683

Epoch: 6| Step: 3
Training loss: 3.3198483131410725
Validation loss: 2.6555196261028033

Epoch: 6| Step: 4
Training loss: 3.051512646402165
Validation loss: 2.6458539428244157

Epoch: 6| Step: 5
Training loss: 3.196966139761148
Validation loss: 2.644097418003786

Epoch: 6| Step: 6
Training loss: 2.926075735920263
Validation loss: 2.631207778183094

Epoch: 6| Step: 7
Training loss: 3.417991908403688
Validation loss: 2.6339353066762285

Epoch: 6| Step: 8
Training loss: 2.6431169658330416
Validation loss: 2.633627731883679

Epoch: 6| Step: 9
Training loss: 2.576806673471312
Validation loss: 2.625519822622624

Epoch: 6| Step: 10
Training loss: 2.6751354468449002
Validation loss: 2.6315811484715703

Epoch: 6| Step: 11
Training loss: 3.006336672479225
Validation loss: 2.6344474272496567

Epoch: 6| Step: 12
Training loss: 3.1697445183459934
Validation loss: 2.632059308875735

Epoch: 6| Step: 13
Training loss: 3.0308567067264964
Validation loss: 2.6313541073647433

Epoch: 107| Step: 0
Training loss: 2.9640729502813934
Validation loss: 2.630990926344312

Epoch: 6| Step: 1
Training loss: 2.699676342391475
Validation loss: 2.6289087591211246

Epoch: 6| Step: 2
Training loss: 3.2192462427499953
Validation loss: 2.6176339765479253

Epoch: 6| Step: 3
Training loss: 2.7763786087579447
Validation loss: 2.6076070327341885

Epoch: 6| Step: 4
Training loss: 2.630142261443226
Validation loss: 2.6212636488100944

Epoch: 6| Step: 5
Training loss: 2.836896077557019
Validation loss: 2.6549732225734473

Epoch: 6| Step: 6
Training loss: 2.9382287602704906
Validation loss: 2.645750601782056

Epoch: 6| Step: 7
Training loss: 3.2661757301386105
Validation loss: 2.6276901570737947

Epoch: 6| Step: 8
Training loss: 3.093894569795291
Validation loss: 2.6041521484626595

Epoch: 6| Step: 9
Training loss: 2.804074021084796
Validation loss: 2.565257783700631

Epoch: 6| Step: 10
Training loss: 3.465869429200782
Validation loss: 2.5569053551762218

Epoch: 6| Step: 11
Training loss: 2.828130395367782
Validation loss: 2.5496778719408506

Epoch: 6| Step: 12
Training loss: 2.967547845880557
Validation loss: 2.5476604523584014

Epoch: 6| Step: 13
Training loss: 2.549416987771726
Validation loss: 2.5463301207068225

Epoch: 108| Step: 0
Training loss: 2.7065578999142765
Validation loss: 2.5440133150316195

Epoch: 6| Step: 1
Training loss: 3.099329069812271
Validation loss: 2.563624344698576

Epoch: 6| Step: 2
Training loss: 2.9904172755440936
Validation loss: 2.5739261048118722

Epoch: 6| Step: 3
Training loss: 3.218491627221079
Validation loss: 2.5996639960662087

Epoch: 6| Step: 4
Training loss: 2.884411376194731
Validation loss: 2.6251216123881864

Epoch: 6| Step: 5
Training loss: 2.9489322346339004
Validation loss: 2.6319758498785104

Epoch: 6| Step: 6
Training loss: 2.8490256534598397
Validation loss: 2.6498318754092467

Epoch: 6| Step: 7
Training loss: 2.7665884635014644
Validation loss: 2.6595314830185455

Epoch: 6| Step: 8
Training loss: 3.661904681779347
Validation loss: 2.6543280667964564

Epoch: 6| Step: 9
Training loss: 2.8584056107379245
Validation loss: 2.631072051786146

Epoch: 6| Step: 10
Training loss: 2.5766530776888983
Validation loss: 2.6036298232120303

Epoch: 6| Step: 11
Training loss: 2.4224509261980205
Validation loss: 2.577888782726013

Epoch: 6| Step: 12
Training loss: 3.313255655720085
Validation loss: 2.562914262846437

Epoch: 6| Step: 13
Training loss: 2.5762288837039438
Validation loss: 2.5603294423851346

Epoch: 109| Step: 0
Training loss: 2.3940427197793315
Validation loss: 2.558524335407903

Epoch: 6| Step: 1
Training loss: 3.028339994846954
Validation loss: 2.5591695007940456

Epoch: 6| Step: 2
Training loss: 2.7111355492093203
Validation loss: 2.5579948500261227

Epoch: 6| Step: 3
Training loss: 2.6837202594816665
Validation loss: 2.563708158861092

Epoch: 6| Step: 4
Training loss: 3.265184874740686
Validation loss: 2.5557419295949946

Epoch: 6| Step: 5
Training loss: 2.779594014114432
Validation loss: 2.5548348503647125

Epoch: 6| Step: 6
Training loss: 2.6718841909507036
Validation loss: 2.5563231364394112

Epoch: 6| Step: 7
Training loss: 2.257523778914792
Validation loss: 2.5623178224711634

Epoch: 6| Step: 8
Training loss: 3.152796602869805
Validation loss: 2.5514766840169925

Epoch: 6| Step: 9
Training loss: 3.3643840970946233
Validation loss: 2.5580313631772995

Epoch: 6| Step: 10
Training loss: 3.3921170797115336
Validation loss: 2.5636060345168348

Epoch: 6| Step: 11
Training loss: 2.7432826971554447
Validation loss: 2.565239935896924

Epoch: 6| Step: 12
Training loss: 3.2480145772221616
Validation loss: 2.573680235463209

Epoch: 6| Step: 13
Training loss: 2.7264039613818105
Validation loss: 2.582831573351385

Epoch: 110| Step: 0
Training loss: 2.9708854624350973
Validation loss: 2.5970023024832867

Epoch: 6| Step: 1
Training loss: 2.786456603052666
Validation loss: 2.5825427298086248

Epoch: 6| Step: 2
Training loss: 2.470663174392914
Validation loss: 2.5704724487443316

Epoch: 6| Step: 3
Training loss: 2.2389283634531063
Validation loss: 2.563168274233089

Epoch: 6| Step: 4
Training loss: 3.2083514489657405
Validation loss: 2.5641212806933575

Epoch: 6| Step: 5
Training loss: 2.566806338171901
Validation loss: 2.5551462972275143

Epoch: 6| Step: 6
Training loss: 2.879249086502247
Validation loss: 2.5625109228366068

Epoch: 6| Step: 7
Training loss: 3.1798536552487486
Validation loss: 2.5570294070880806

Epoch: 6| Step: 8
Training loss: 3.2147829367539478
Validation loss: 2.5527399456928337

Epoch: 6| Step: 9
Training loss: 3.0645368381053104
Validation loss: 2.553900935374356

Epoch: 6| Step: 10
Training loss: 2.651063410601725
Validation loss: 2.553884874305354

Epoch: 6| Step: 11
Training loss: 3.6861912619385726
Validation loss: 2.554931044976441

Epoch: 6| Step: 12
Training loss: 2.8690635094299637
Validation loss: 2.5513727125854326

Epoch: 6| Step: 13
Training loss: 2.5521933603248654
Validation loss: 2.5516559071293656

Epoch: 111| Step: 0
Training loss: 3.0084925291537012
Validation loss: 2.552203110844751

Epoch: 6| Step: 1
Training loss: 3.162760902468614
Validation loss: 2.558928690497217

Epoch: 6| Step: 2
Training loss: 2.8304619170192504
Validation loss: 2.5679611750174156

Epoch: 6| Step: 3
Training loss: 2.902889811307311
Validation loss: 2.578578472808356

Epoch: 6| Step: 4
Training loss: 2.633938240236727
Validation loss: 2.571332638125095

Epoch: 6| Step: 5
Training loss: 2.603855165288914
Validation loss: 2.599153366397555

Epoch: 6| Step: 6
Training loss: 2.344760727702983
Validation loss: 2.6165455814131255

Epoch: 6| Step: 7
Training loss: 3.0257423940104533
Validation loss: 2.610639908463796

Epoch: 6| Step: 8
Training loss: 3.6594872122743256
Validation loss: 2.605990529595131

Epoch: 6| Step: 9
Training loss: 2.4443408144552827
Validation loss: 2.5869482717112318

Epoch: 6| Step: 10
Training loss: 3.387268936891501
Validation loss: 2.561214173438428

Epoch: 6| Step: 11
Training loss: 2.6960927524968272
Validation loss: 2.545715901725499

Epoch: 6| Step: 12
Training loss: 2.61072902611915
Validation loss: 2.544347840343023

Epoch: 6| Step: 13
Training loss: 3.2791828728695056
Validation loss: 2.542403892045875

Epoch: 112| Step: 0
Training loss: 2.5597583711854055
Validation loss: 2.5421044691944945

Epoch: 6| Step: 1
Training loss: 3.2474265547061183
Validation loss: 2.541842608024968

Epoch: 6| Step: 2
Training loss: 2.61272932077389
Validation loss: 2.5432144413561537

Epoch: 6| Step: 3
Training loss: 2.3971711335153723
Validation loss: 2.5365908594163513

Epoch: 6| Step: 4
Training loss: 3.0713555115029507
Validation loss: 2.5458562783825736

Epoch: 6| Step: 5
Training loss: 2.9050315025315445
Validation loss: 2.547997018213199

Epoch: 6| Step: 6
Training loss: 2.9196801739428984
Validation loss: 2.5487726649564126

Epoch: 6| Step: 7
Training loss: 2.5306698169541253
Validation loss: 2.554567321477428

Epoch: 6| Step: 8
Training loss: 2.690303227659773
Validation loss: 2.5549960118686807

Epoch: 6| Step: 9
Training loss: 3.050756867100065
Validation loss: 2.553379843700652

Epoch: 6| Step: 10
Training loss: 2.9416116386936513
Validation loss: 2.5559588888769054

Epoch: 6| Step: 11
Training loss: 3.479796544847166
Validation loss: 2.5579063957013264

Epoch: 6| Step: 12
Training loss: 2.6519327421103194
Validation loss: 2.5530559267824002

Epoch: 6| Step: 13
Training loss: 3.621020928466458
Validation loss: 2.5541358992740557

Epoch: 113| Step: 0
Training loss: 3.0428299094810125
Validation loss: 2.5542890575355868

Epoch: 6| Step: 1
Training loss: 2.5243041259910832
Validation loss: 2.5586932499486843

Epoch: 6| Step: 2
Training loss: 3.0869763134837567
Validation loss: 2.5532999466733917

Epoch: 6| Step: 3
Training loss: 3.069248626661448
Validation loss: 2.549946830705116

Epoch: 6| Step: 4
Training loss: 2.7943889288404757
Validation loss: 2.5423607008942173

Epoch: 6| Step: 5
Training loss: 2.2840850145047376
Validation loss: 2.543762293915888

Epoch: 6| Step: 6
Training loss: 2.840269536941955
Validation loss: 2.539916977646691

Epoch: 6| Step: 7
Training loss: 3.095612090784918
Validation loss: 2.541223507707923

Epoch: 6| Step: 8
Training loss: 2.874407831656884
Validation loss: 2.5362434967508647

Epoch: 6| Step: 9
Training loss: 3.0053291671146374
Validation loss: 2.5367195894553416

Epoch: 6| Step: 10
Training loss: 2.6205750362874536
Validation loss: 2.5364341622667066

Epoch: 6| Step: 11
Training loss: 3.1693849608351874
Validation loss: 2.536518305854303

Epoch: 6| Step: 12
Training loss: 3.071702171889079
Validation loss: 2.5436494000568097

Epoch: 6| Step: 13
Training loss: 2.8508751445768055
Validation loss: 2.535190928070446

Epoch: 114| Step: 0
Training loss: 2.712797642563763
Validation loss: 2.5440349455443125

Epoch: 6| Step: 1
Training loss: 2.495315072112648
Validation loss: 2.538717921297669

Epoch: 6| Step: 2
Training loss: 2.6987029492303916
Validation loss: 2.535889624562875

Epoch: 6| Step: 3
Training loss: 2.9164299641791356
Validation loss: 2.549084346624083

Epoch: 6| Step: 4
Training loss: 2.355010385024707
Validation loss: 2.5515354943856257

Epoch: 6| Step: 5
Training loss: 3.0706631603389347
Validation loss: 2.5534642842774953

Epoch: 6| Step: 6
Training loss: 3.252465999815533
Validation loss: 2.5514953274082885

Epoch: 6| Step: 7
Training loss: 3.2428739625315743
Validation loss: 2.5689683163373256

Epoch: 6| Step: 8
Training loss: 3.512566486421745
Validation loss: 2.5622669367096007

Epoch: 6| Step: 9
Training loss: 2.0462755097026615
Validation loss: 2.545263084680744

Epoch: 6| Step: 10
Training loss: 3.3289842526174263
Validation loss: 2.5373717711236723

Epoch: 6| Step: 11
Training loss: 2.632574506467859
Validation loss: 2.5333459426628684

Epoch: 6| Step: 12
Training loss: 2.740042257609603
Validation loss: 2.5317568153239853

Epoch: 6| Step: 13
Training loss: 3.2840442204164044
Validation loss: 2.533080411109472

Epoch: 115| Step: 0
Training loss: 2.719991553938599
Validation loss: 2.5322242096680325

Epoch: 6| Step: 1
Training loss: 2.6775273549795564
Validation loss: 2.5263845803197986

Epoch: 6| Step: 2
Training loss: 3.061957486426231
Validation loss: 2.528440861518752

Epoch: 6| Step: 3
Training loss: 2.422083888736042
Validation loss: 2.5308749053798514

Epoch: 6| Step: 4
Training loss: 2.3995418429167272
Validation loss: 2.5314855472296443

Epoch: 6| Step: 5
Training loss: 3.1138935324635866
Validation loss: 2.534353569831027

Epoch: 6| Step: 6
Training loss: 3.1060392803353802
Validation loss: 2.534346903668023

Epoch: 6| Step: 7
Training loss: 3.075132047717769
Validation loss: 2.5448353321351

Epoch: 6| Step: 8
Training loss: 3.4684283133142033
Validation loss: 2.5468856023148403

Epoch: 6| Step: 9
Training loss: 3.0359966435269383
Validation loss: 2.552691768388561

Epoch: 6| Step: 10
Training loss: 2.645955500948663
Validation loss: 2.5646408716230846

Epoch: 6| Step: 11
Training loss: 3.2173661896121
Validation loss: 2.5585261550387246

Epoch: 6| Step: 12
Training loss: 2.7033157722319814
Validation loss: 2.558425950170983

Epoch: 6| Step: 13
Training loss: 2.35080024810447
Validation loss: 2.561245736618384

Epoch: 116| Step: 0
Training loss: 3.0962668305772376
Validation loss: 2.56413525003625

Epoch: 6| Step: 1
Training loss: 2.6135310351592773
Validation loss: 2.56099473735284

Epoch: 6| Step: 2
Training loss: 3.6599248692873636
Validation loss: 2.5555155571355708

Epoch: 6| Step: 3
Training loss: 2.9396399961363917
Validation loss: 2.540445114568733

Epoch: 6| Step: 4
Training loss: 2.873214830874202
Validation loss: 2.5373889996008723

Epoch: 6| Step: 5
Training loss: 2.0355301584901775
Validation loss: 2.5295811049242607

Epoch: 6| Step: 6
Training loss: 3.2717583840473283
Validation loss: 2.5275107936174863

Epoch: 6| Step: 7
Training loss: 3.091033359314253
Validation loss: 2.5300827079547443

Epoch: 6| Step: 8
Training loss: 3.4153345038596723
Validation loss: 2.532264795713072

Epoch: 6| Step: 9
Training loss: 2.1317057550150667
Validation loss: 2.5371463554459854

Epoch: 6| Step: 10
Training loss: 3.1214915608101497
Validation loss: 2.536350966001675

Epoch: 6| Step: 11
Training loss: 2.7563778006406348
Validation loss: 2.530720670980121

Epoch: 6| Step: 12
Training loss: 2.029684314328837
Validation loss: 2.526639764072023

Epoch: 6| Step: 13
Training loss: 3.1683787352231825
Validation loss: 2.5318181169956886

Epoch: 117| Step: 0
Training loss: 3.402535749551728
Validation loss: 2.548802462596242

Epoch: 6| Step: 1
Training loss: 2.2879911135254196
Validation loss: 2.566619483099617

Epoch: 6| Step: 2
Training loss: 3.3949321338909835
Validation loss: 2.591346283211401

Epoch: 6| Step: 3
Training loss: 3.3680806756584887
Validation loss: 2.574921853432507

Epoch: 6| Step: 4
Training loss: 2.3580176889210667
Validation loss: 2.5639760778046825

Epoch: 6| Step: 5
Training loss: 3.225849211317118
Validation loss: 2.5524129855972286

Epoch: 6| Step: 6
Training loss: 2.540338283750066
Validation loss: 2.5349046076738815

Epoch: 6| Step: 7
Training loss: 2.4011236302307695
Validation loss: 2.5286998575513486

Epoch: 6| Step: 8
Training loss: 3.026767680825366
Validation loss: 2.5292419404822546

Epoch: 6| Step: 9
Training loss: 3.127518821312053
Validation loss: 2.524308230466886

Epoch: 6| Step: 10
Training loss: 2.4656611566829687
Validation loss: 2.523041450541105

Epoch: 6| Step: 11
Training loss: 3.0481605360952684
Validation loss: 2.5231081133828157

Epoch: 6| Step: 12
Training loss: 2.6314061424337347
Validation loss: 2.5279876547557154

Epoch: 6| Step: 13
Training loss: 2.8054795700795156
Validation loss: 2.5333053243521126

Epoch: 118| Step: 0
Training loss: 3.0174536028110173
Validation loss: 2.548933301544159

Epoch: 6| Step: 1
Training loss: 2.615593085783637
Validation loss: 2.5549190642456825

Epoch: 6| Step: 2
Training loss: 2.7065904927300903
Validation loss: 2.5608918210685965

Epoch: 6| Step: 3
Training loss: 3.0999338019901637
Validation loss: 2.590444294461297

Epoch: 6| Step: 4
Training loss: 3.080315444695651
Validation loss: 2.5934805524391518

Epoch: 6| Step: 5
Training loss: 3.005893005619207
Validation loss: 2.591329594514326

Epoch: 6| Step: 6
Training loss: 2.2845808820927593
Validation loss: 2.570047928893203

Epoch: 6| Step: 7
Training loss: 3.0845700095077575
Validation loss: 2.539381049204012

Epoch: 6| Step: 8
Training loss: 2.580818018200122
Validation loss: 2.5215240297725803

Epoch: 6| Step: 9
Training loss: 2.6494582468152674
Validation loss: 2.5314813181822977

Epoch: 6| Step: 10
Training loss: 2.972409532612461
Validation loss: 2.5315859202174096

Epoch: 6| Step: 11
Training loss: 2.977239416652175
Validation loss: 2.5362547004582687

Epoch: 6| Step: 12
Training loss: 3.1720683222143715
Validation loss: 2.536023561915093

Epoch: 6| Step: 13
Training loss: 3.2155274490373573
Validation loss: 2.5382325871278137

Epoch: 119| Step: 0
Training loss: 2.8932839201591274
Validation loss: 2.5405579570710426

Epoch: 6| Step: 1
Training loss: 2.7225569456536003
Validation loss: 2.5432103376560184

Epoch: 6| Step: 2
Training loss: 2.7855404967289985
Validation loss: 2.549086760327898

Epoch: 6| Step: 3
Training loss: 2.9833973186884153
Validation loss: 2.547137322106888

Epoch: 6| Step: 4
Training loss: 3.230093956162453
Validation loss: 2.556809693064788

Epoch: 6| Step: 5
Training loss: 2.7067229740819156
Validation loss: 2.566333567378525

Epoch: 6| Step: 6
Training loss: 2.602775497146018
Validation loss: 2.658515314562235

Epoch: 6| Step: 7
Training loss: 3.0148004382942593
Validation loss: 2.8063081264973513

Epoch: 6| Step: 8
Training loss: 2.8432615091152464
Validation loss: 2.748518621232805

Epoch: 6| Step: 9
Training loss: 2.67948774922299
Validation loss: 2.6125298396841647

Epoch: 6| Step: 10
Training loss: 3.4245887342361603
Validation loss: 2.5574354911532735

Epoch: 6| Step: 11
Training loss: 2.4327084322447474
Validation loss: 2.532580388762418

Epoch: 6| Step: 12
Training loss: 2.949933300234105
Validation loss: 2.531039505843908

Epoch: 6| Step: 13
Training loss: 3.0973666850689314
Validation loss: 2.5491634374800145

Epoch: 120| Step: 0
Training loss: 2.608044679247308
Validation loss: 2.580486664980833

Epoch: 6| Step: 1
Training loss: 2.9929760722979637
Validation loss: 2.626092493959817

Epoch: 6| Step: 2
Training loss: 3.129489420480272
Validation loss: 2.6621385059236378

Epoch: 6| Step: 3
Training loss: 2.6675540719097897
Validation loss: 2.7270425908075144

Epoch: 6| Step: 4
Training loss: 3.181172991646824
Validation loss: 2.706175493690016

Epoch: 6| Step: 5
Training loss: 3.51368517446413
Validation loss: 2.6811865089633082

Epoch: 6| Step: 6
Training loss: 3.102244112465232
Validation loss: 2.6471292827666217

Epoch: 6| Step: 7
Training loss: 2.60856186309455
Validation loss: 2.644519882649094

Epoch: 6| Step: 8
Training loss: 2.827642916061785
Validation loss: 2.644759712148496

Epoch: 6| Step: 9
Training loss: 2.9101863987532277
Validation loss: 2.7202535848469505

Epoch: 6| Step: 10
Training loss: 3.3746659855333854
Validation loss: 2.871055164235529

Epoch: 6| Step: 11
Training loss: 3.070160762541454
Validation loss: 2.8923357033532047

Epoch: 6| Step: 12
Training loss: 2.9359543974970266
Validation loss: 2.8042631047289857

Epoch: 6| Step: 13
Training loss: 2.1083783090893062
Validation loss: 2.7175102004853438

Epoch: 121| Step: 0
Training loss: 2.4807693899992844
Validation loss: 2.640919183007628

Epoch: 6| Step: 1
Training loss: 3.3606874253198744
Validation loss: 2.5720177469653165

Epoch: 6| Step: 2
Training loss: 2.8396289854421792
Validation loss: 2.5543893002383373

Epoch: 6| Step: 3
Training loss: 3.3091540442054446
Validation loss: 2.528938720978822

Epoch: 6| Step: 4
Training loss: 3.2600407652851215
Validation loss: 2.5224350424171234

Epoch: 6| Step: 5
Training loss: 2.9288042288305016
Validation loss: 2.507946531281594

Epoch: 6| Step: 6
Training loss: 2.6712592235186383
Validation loss: 2.5132368355919947

Epoch: 6| Step: 7
Training loss: 2.5778799229513703
Validation loss: 2.5081470874419862

Epoch: 6| Step: 8
Training loss: 2.3471219030708133
Validation loss: 2.511164060768493

Epoch: 6| Step: 9
Training loss: 3.1341379458237233
Validation loss: 2.510341800605968

Epoch: 6| Step: 10
Training loss: 2.9973017956487498
Validation loss: 2.5084646140812956

Epoch: 6| Step: 11
Training loss: 2.78907292895678
Validation loss: 2.5113880172755265

Epoch: 6| Step: 12
Training loss: 2.56227669091773
Validation loss: 2.5050591264974162

Epoch: 6| Step: 13
Training loss: 2.8276095263030476
Validation loss: 2.5025239878068413

Epoch: 122| Step: 0
Training loss: 3.1519283507864215
Validation loss: 2.5056799957397087

Epoch: 6| Step: 1
Training loss: 3.011600952219626
Validation loss: 2.506151809428056

Epoch: 6| Step: 2
Training loss: 2.552085461258812
Validation loss: 2.508689153912267

Epoch: 6| Step: 3
Training loss: 3.304625165635516
Validation loss: 2.507055459225046

Epoch: 6| Step: 4
Training loss: 3.10746484099774
Validation loss: 2.5069379206972586

Epoch: 6| Step: 5
Training loss: 2.500116727011289
Validation loss: 2.508650208830997

Epoch: 6| Step: 6
Training loss: 2.8836761256140613
Validation loss: 2.508337921199978

Epoch: 6| Step: 7
Training loss: 2.591497431275944
Validation loss: 2.5309870163112627

Epoch: 6| Step: 8
Training loss: 3.07806876658858
Validation loss: 2.549950964784157

Epoch: 6| Step: 9
Training loss: 2.878894987045472
Validation loss: 2.555931900867413

Epoch: 6| Step: 10
Training loss: 3.1623204839968166
Validation loss: 2.5416969786365753

Epoch: 6| Step: 11
Training loss: 2.4151730251525585
Validation loss: 2.5518576342439547

Epoch: 6| Step: 12
Training loss: 2.6102951163579995
Validation loss: 2.5279917507156457

Epoch: 6| Step: 13
Training loss: 2.573778685029647
Validation loss: 2.506522632191423

Epoch: 123| Step: 0
Training loss: 2.820379705500134
Validation loss: 2.5048877762630553

Epoch: 6| Step: 1
Training loss: 3.0377404639739787
Validation loss: 2.50181167649832

Epoch: 6| Step: 2
Training loss: 3.359342353129884
Validation loss: 2.4968309282067027

Epoch: 6| Step: 3
Training loss: 2.7109781311684054
Validation loss: 2.5031203639195034

Epoch: 6| Step: 4
Training loss: 2.0859233269942195
Validation loss: 2.502016722524291

Epoch: 6| Step: 5
Training loss: 3.119336451126218
Validation loss: 2.499928242668789

Epoch: 6| Step: 6
Training loss: 2.7825602327666887
Validation loss: 2.4939028129107634

Epoch: 6| Step: 7
Training loss: 2.5533057159377774
Validation loss: 2.4958643628372448

Epoch: 6| Step: 8
Training loss: 2.975950643776186
Validation loss: 2.4993148285228095

Epoch: 6| Step: 9
Training loss: 3.1021989222285815
Validation loss: 2.4972859919994166

Epoch: 6| Step: 10
Training loss: 2.677043889765712
Validation loss: 2.5036598785571726

Epoch: 6| Step: 11
Training loss: 2.879088107489675
Validation loss: 2.509806413854932

Epoch: 6| Step: 12
Training loss: 3.0148140404891426
Validation loss: 2.5217073132821755

Epoch: 6| Step: 13
Training loss: 2.566697938736816
Validation loss: 2.527747611191462

Epoch: 124| Step: 0
Training loss: 2.6031929840699077
Validation loss: 2.5482138481637984

Epoch: 6| Step: 1
Training loss: 2.655723968478827
Validation loss: 2.529646047908871

Epoch: 6| Step: 2
Training loss: 2.8792401434598918
Validation loss: 2.5300814231362123

Epoch: 6| Step: 3
Training loss: 2.996852495190527
Validation loss: 2.5146015714425145

Epoch: 6| Step: 4
Training loss: 3.150258183873353
Validation loss: 2.499942992185938

Epoch: 6| Step: 5
Training loss: 3.0115544018265936
Validation loss: 2.5046499856096425

Epoch: 6| Step: 6
Training loss: 3.0485165599931934
Validation loss: 2.4982337998781254

Epoch: 6| Step: 7
Training loss: 3.0889590379660947
Validation loss: 2.4974925551461142

Epoch: 6| Step: 8
Training loss: 2.9510301698585746
Validation loss: 2.4968430829359765

Epoch: 6| Step: 9
Training loss: 2.598640427547796
Validation loss: 2.4923219775981296

Epoch: 6| Step: 10
Training loss: 2.5165267181221145
Validation loss: 2.5026676178940868

Epoch: 6| Step: 11
Training loss: 2.8069931371677654
Validation loss: 2.499660286331071

Epoch: 6| Step: 12
Training loss: 2.4884524683230884
Validation loss: 2.5074486619175267

Epoch: 6| Step: 13
Training loss: 3.008038559382417
Validation loss: 2.51038825396393

Epoch: 125| Step: 0
Training loss: 2.59156817855222
Validation loss: 2.5271482871193998

Epoch: 6| Step: 1
Training loss: 3.2577043327835056
Validation loss: 2.536467685814035

Epoch: 6| Step: 2
Training loss: 2.2998959144592157
Validation loss: 2.5392040400656635

Epoch: 6| Step: 3
Training loss: 3.09320094313075
Validation loss: 2.538552130180228

Epoch: 6| Step: 4
Training loss: 2.1507235485003586
Validation loss: 2.518264374416488

Epoch: 6| Step: 5
Training loss: 2.720383778032113
Validation loss: 2.5163521240323017

Epoch: 6| Step: 6
Training loss: 3.2725128105967776
Validation loss: 2.509894265150409

Epoch: 6| Step: 7
Training loss: 2.6395292999670454
Validation loss: 2.5083626914221777

Epoch: 6| Step: 8
Training loss: 2.7406182214007178
Validation loss: 2.4986817853060064

Epoch: 6| Step: 9
Training loss: 2.9367267321340877
Validation loss: 2.493149950511068

Epoch: 6| Step: 10
Training loss: 2.7665709693474843
Validation loss: 2.4946664110841947

Epoch: 6| Step: 11
Training loss: 3.0737161576935508
Validation loss: 2.506528662540725

Epoch: 6| Step: 12
Training loss: 2.909284750484114
Validation loss: 2.502787647847982

Epoch: 6| Step: 13
Training loss: 3.2810866542303265
Validation loss: 2.497330599177766

Epoch: 126| Step: 0
Training loss: 2.8418176814100864
Validation loss: 2.511083864941517

Epoch: 6| Step: 1
Training loss: 3.4744949193311547
Validation loss: 2.5123434908693403

Epoch: 6| Step: 2
Training loss: 2.3716578810156705
Validation loss: 2.513931206600614

Epoch: 6| Step: 3
Training loss: 2.8642789551832184
Validation loss: 2.546089612437035

Epoch: 6| Step: 4
Training loss: 2.9956993430304397
Validation loss: 2.529496608951219

Epoch: 6| Step: 5
Training loss: 2.9827333099100355
Validation loss: 2.5181797725737933

Epoch: 6| Step: 6
Training loss: 2.729941386756898
Validation loss: 2.5261228158693383

Epoch: 6| Step: 7
Training loss: 2.3393034398729187
Validation loss: 2.5031307306270545

Epoch: 6| Step: 8
Training loss: 3.1400812541872143
Validation loss: 2.4960038086445624

Epoch: 6| Step: 9
Training loss: 2.1192075657269918
Validation loss: 2.5007120543787607

Epoch: 6| Step: 10
Training loss: 3.121908260622682
Validation loss: 2.4946337974126145

Epoch: 6| Step: 11
Training loss: 2.7496849226351534
Validation loss: 2.4977757167571673

Epoch: 6| Step: 12
Training loss: 2.668502642493881
Validation loss: 2.51633761893248

Epoch: 6| Step: 13
Training loss: 3.190387838817211
Validation loss: 2.543910862605149

Epoch: 127| Step: 0
Training loss: 2.6053552788728047
Validation loss: 2.5314632514828475

Epoch: 6| Step: 1
Training loss: 2.6795755702183937
Validation loss: 2.51408308912961

Epoch: 6| Step: 2
Training loss: 2.667458436565268
Validation loss: 2.502420725987359

Epoch: 6| Step: 3
Training loss: 2.9947624581059777
Validation loss: 2.490233017118608

Epoch: 6| Step: 4
Training loss: 2.4961361590440743
Validation loss: 2.4944095401557167

Epoch: 6| Step: 5
Training loss: 2.344083736818304
Validation loss: 2.495751492337685

Epoch: 6| Step: 6
Training loss: 3.6817802422963104
Validation loss: 2.4878372705775393

Epoch: 6| Step: 7
Training loss: 2.687584276873991
Validation loss: 2.492307557397865

Epoch: 6| Step: 8
Training loss: 2.490123312474329
Validation loss: 2.493959736758371

Epoch: 6| Step: 9
Training loss: 2.90374024013894
Validation loss: 2.5043201891146354

Epoch: 6| Step: 10
Training loss: 2.884872238265626
Validation loss: 2.508058660799959

Epoch: 6| Step: 11
Training loss: 3.2584830858658793
Validation loss: 2.5277964910831487

Epoch: 6| Step: 12
Training loss: 2.8159868454517545
Validation loss: 2.525704624706257

Epoch: 6| Step: 13
Training loss: 3.2149419387154605
Validation loss: 2.515761800552147

Epoch: 128| Step: 0
Training loss: 3.250669850496773
Validation loss: 2.5149974698886766

Epoch: 6| Step: 1
Training loss: 2.7356970506557023
Validation loss: 2.5146732413923116

Epoch: 6| Step: 2
Training loss: 2.6346579403147157
Validation loss: 2.5478800719267034

Epoch: 6| Step: 3
Training loss: 2.6266339076205245
Validation loss: 2.538003595380834

Epoch: 6| Step: 4
Training loss: 2.9495796033376998
Validation loss: 2.5600829802079423

Epoch: 6| Step: 5
Training loss: 2.6837619245714666
Validation loss: 2.6066394575415357

Epoch: 6| Step: 6
Training loss: 2.6239698295952216
Validation loss: 2.6391901131082394

Epoch: 6| Step: 7
Training loss: 3.1276029808599093
Validation loss: 2.55028022587218

Epoch: 6| Step: 8
Training loss: 2.7247389677121716
Validation loss: 2.4913262899188826

Epoch: 6| Step: 9
Training loss: 3.002201861746934
Validation loss: 2.4924186254508203

Epoch: 6| Step: 10
Training loss: 3.2828847536744576
Validation loss: 2.499400476126251

Epoch: 6| Step: 11
Training loss: 3.10994604033242
Validation loss: 2.498710178592528

Epoch: 6| Step: 12
Training loss: 2.2541178004056195
Validation loss: 2.503526894723828

Epoch: 6| Step: 13
Training loss: 2.8686805600341034
Validation loss: 2.5021875491034606

Epoch: 129| Step: 0
Training loss: 3.0417410610629156
Validation loss: 2.503734773764626

Epoch: 6| Step: 1
Training loss: 2.6014828598158726
Validation loss: 2.5097662501372073

Epoch: 6| Step: 2
Training loss: 2.597585117828953
Validation loss: 2.5175335028581487

Epoch: 6| Step: 3
Training loss: 2.7482441585301367
Validation loss: 2.5289596025506027

Epoch: 6| Step: 4
Training loss: 2.4989647629212426
Validation loss: 2.535425105127927

Epoch: 6| Step: 5
Training loss: 2.840133883047208
Validation loss: 2.534679001916218

Epoch: 6| Step: 6
Training loss: 2.369770919094159
Validation loss: 2.517421243411692

Epoch: 6| Step: 7
Training loss: 3.0677111139376634
Validation loss: 2.515852533484773

Epoch: 6| Step: 8
Training loss: 3.1055754637227
Validation loss: 2.5126974407931018

Epoch: 6| Step: 9
Training loss: 2.4601198806085307
Validation loss: 2.5177370424420094

Epoch: 6| Step: 10
Training loss: 3.2351718971299643
Validation loss: 2.5208659805981157

Epoch: 6| Step: 11
Training loss: 2.8980276635470688
Validation loss: 2.5187386532475533

Epoch: 6| Step: 12
Training loss: 3.004377033065511
Validation loss: 2.502332450441608

Epoch: 6| Step: 13
Training loss: 3.4037561649262478
Validation loss: 2.495530688606819

Epoch: 130| Step: 0
Training loss: 3.019812014457379
Validation loss: 2.4953642431359517

Epoch: 6| Step: 1
Training loss: 2.641655624880012
Validation loss: 2.4865579867062366

Epoch: 6| Step: 2
Training loss: 2.630259195471764
Validation loss: 2.4924842086164873

Epoch: 6| Step: 3
Training loss: 2.8033792744008323
Validation loss: 2.497708600532133

Epoch: 6| Step: 4
Training loss: 2.7426807796737656
Validation loss: 2.4993529723275634

Epoch: 6| Step: 5
Training loss: 2.551364428931851
Validation loss: 2.497949427847974

Epoch: 6| Step: 6
Training loss: 2.641343690480558
Validation loss: 2.507071232323428

Epoch: 6| Step: 7
Training loss: 2.8929387910277002
Validation loss: 2.5125435797374376

Epoch: 6| Step: 8
Training loss: 3.077126897883594
Validation loss: 2.5272729851102422

Epoch: 6| Step: 9
Training loss: 3.429530389962846
Validation loss: 2.567453051009809

Epoch: 6| Step: 10
Training loss: 2.779482933781193
Validation loss: 2.5766279013544797

Epoch: 6| Step: 11
Training loss: 2.8284460064712986
Validation loss: 2.5677467204708577

Epoch: 6| Step: 12
Training loss: 2.5048289391745633
Validation loss: 2.542967459594506

Epoch: 6| Step: 13
Training loss: 3.055676702544566
Validation loss: 2.5416893967274956

Epoch: 131| Step: 0
Training loss: 2.438230258417015
Validation loss: 2.535694830547419

Epoch: 6| Step: 1
Training loss: 2.36805452388419
Validation loss: 2.5132788462197366

Epoch: 6| Step: 2
Training loss: 3.2274459848530452
Validation loss: 2.509654964067712

Epoch: 6| Step: 3
Training loss: 2.9858239935316218
Validation loss: 2.505557530021152

Epoch: 6| Step: 4
Training loss: 2.2778164878388485
Validation loss: 2.5040203050140493

Epoch: 6| Step: 5
Training loss: 3.102526920764328
Validation loss: 2.503093815038382

Epoch: 6| Step: 6
Training loss: 2.767036293417666
Validation loss: 2.5064703431566397

Epoch: 6| Step: 7
Training loss: 2.7851456351699895
Validation loss: 2.5109028179340434

Epoch: 6| Step: 8
Training loss: 2.8372473516032555
Validation loss: 2.5049917796770105

Epoch: 6| Step: 9
Training loss: 3.275566774202709
Validation loss: 2.512290085702872

Epoch: 6| Step: 10
Training loss: 2.95169597947916
Validation loss: 2.5145662291474093

Epoch: 6| Step: 11
Training loss: 2.966142332338986
Validation loss: 2.5242293312492667

Epoch: 6| Step: 12
Training loss: 2.3907110659995134
Validation loss: 2.527334680576005

Epoch: 6| Step: 13
Training loss: 2.893303861892776
Validation loss: 2.525755917204654

Epoch: 132| Step: 0
Training loss: 2.5144783392106156
Validation loss: 2.5308812773111877

Epoch: 6| Step: 1
Training loss: 2.892281712214012
Validation loss: 2.52475729130888

Epoch: 6| Step: 2
Training loss: 2.960132821685791
Validation loss: 2.5315065110882418

Epoch: 6| Step: 3
Training loss: 3.2523601472007386
Validation loss: 2.509014348309211

Epoch: 6| Step: 4
Training loss: 2.7013105355487275
Validation loss: 2.5001032274735593

Epoch: 6| Step: 5
Training loss: 2.844118199248904
Validation loss: 2.489241948154415

Epoch: 6| Step: 6
Training loss: 2.8728062096473677
Validation loss: 2.483349058455618

Epoch: 6| Step: 7
Training loss: 1.951437381248958
Validation loss: 2.477519030638363

Epoch: 6| Step: 8
Training loss: 2.8312121660344642
Validation loss: 2.479103574280029

Epoch: 6| Step: 9
Training loss: 1.7626096921293524
Validation loss: 2.4883176991811893

Epoch: 6| Step: 10
Training loss: 2.7023818036256717
Validation loss: 2.486554904015106

Epoch: 6| Step: 11
Training loss: 3.384459343561062
Validation loss: 2.485462151302124

Epoch: 6| Step: 12
Training loss: 3.095452042755472
Validation loss: 2.482115075933602

Epoch: 6| Step: 13
Training loss: 3.4732322258123465
Validation loss: 2.5025357440461304

Epoch: 133| Step: 0
Training loss: 2.6050348792788784
Validation loss: 2.487320349819393

Epoch: 6| Step: 1
Training loss: 3.3717651405857203
Validation loss: 2.507608546411014

Epoch: 6| Step: 2
Training loss: 2.870482669078321
Validation loss: 2.4893655903581418

Epoch: 6| Step: 3
Training loss: 2.581523712646289
Validation loss: 2.4978484442360878

Epoch: 6| Step: 4
Training loss: 2.7387566908768126
Validation loss: 2.5013130718443213

Epoch: 6| Step: 5
Training loss: 2.332295414005987
Validation loss: 2.5378794933258058

Epoch: 6| Step: 6
Training loss: 2.5826762399425465
Validation loss: 2.624331202082291

Epoch: 6| Step: 7
Training loss: 3.421224732645409
Validation loss: 2.620196368924346

Epoch: 6| Step: 8
Training loss: 2.6203377510359984
Validation loss: 2.625590236069961

Epoch: 6| Step: 9
Training loss: 3.1547467268229936
Validation loss: 2.5819740179230193

Epoch: 6| Step: 10
Training loss: 3.0605515490351993
Validation loss: 2.548230640155135

Epoch: 6| Step: 11
Training loss: 2.5638714353610923
Validation loss: 2.515115499699101

Epoch: 6| Step: 12
Training loss: 2.8330372674377946
Validation loss: 2.5060221966256884

Epoch: 6| Step: 13
Training loss: 2.7415598615657366
Validation loss: 2.5038184886039403

Epoch: 134| Step: 0
Training loss: 3.0377399930609426
Validation loss: 2.5083494049000006

Epoch: 6| Step: 1
Training loss: 2.76081352020287
Validation loss: 2.4954070169567886

Epoch: 6| Step: 2
Training loss: 3.1694911774661314
Validation loss: 2.5128491438608553

Epoch: 6| Step: 3
Training loss: 2.1856062184749403
Validation loss: 2.517547117684953

Epoch: 6| Step: 4
Training loss: 3.415091702080365
Validation loss: 2.532592899305617

Epoch: 6| Step: 5
Training loss: 2.8198816704780447
Validation loss: 2.5261327279087706

Epoch: 6| Step: 6
Training loss: 2.39020749105193
Validation loss: 2.542883055571759

Epoch: 6| Step: 7
Training loss: 3.061713292807397
Validation loss: 2.524343516090269

Epoch: 6| Step: 8
Training loss: 3.1371680825038464
Validation loss: 2.5093313121081793

Epoch: 6| Step: 9
Training loss: 2.405277105058359
Validation loss: 2.519224248422482

Epoch: 6| Step: 10
Training loss: 2.871774605707476
Validation loss: 2.4951333011504784

Epoch: 6| Step: 11
Training loss: 2.4790745458931767
Validation loss: 2.494647869150218

Epoch: 6| Step: 12
Training loss: 2.8691411235853037
Validation loss: 2.4951830413593576

Epoch: 6| Step: 13
Training loss: 2.891243533379975
Validation loss: 2.4970670785208884

Epoch: 135| Step: 0
Training loss: 2.210584201150451
Validation loss: 2.5168530862559613

Epoch: 6| Step: 1
Training loss: 2.55243754102189
Validation loss: 2.5216326509474505

Epoch: 6| Step: 2
Training loss: 2.2967208499173486
Validation loss: 2.542380768389328

Epoch: 6| Step: 3
Training loss: 2.915072105130985
Validation loss: 2.5243410675564104

Epoch: 6| Step: 4
Training loss: 2.5536607084567864
Validation loss: 2.537206172939852

Epoch: 6| Step: 5
Training loss: 2.5785131913595354
Validation loss: 2.5238106790506847

Epoch: 6| Step: 6
Training loss: 2.8361348905779695
Validation loss: 2.5149938430699352

Epoch: 6| Step: 7
Training loss: 3.242228827155659
Validation loss: 2.5074961309430024

Epoch: 6| Step: 8
Training loss: 2.9484917357226896
Validation loss: 2.51437731745115

Epoch: 6| Step: 9
Training loss: 2.6552042978424937
Validation loss: 2.5054402389333332

Epoch: 6| Step: 10
Training loss: 3.024071757499619
Validation loss: 2.49858144589047

Epoch: 6| Step: 11
Training loss: 2.9982065562117195
Validation loss: 2.4878371788657447

Epoch: 6| Step: 12
Training loss: 3.224897865038395
Validation loss: 2.4853454725153536

Epoch: 6| Step: 13
Training loss: 3.1205288754218103
Validation loss: 2.4792847543624497

Epoch: 136| Step: 0
Training loss: 2.408936326283984
Validation loss: 2.472755158380489

Epoch: 6| Step: 1
Training loss: 3.068220906377908
Validation loss: 2.4791390953554173

Epoch: 6| Step: 2
Training loss: 3.388353140404547
Validation loss: 2.4728156180676306

Epoch: 6| Step: 3
Training loss: 2.8076328973745266
Validation loss: 2.473684013628372

Epoch: 6| Step: 4
Training loss: 2.92731740067705
Validation loss: 2.473812592147567

Epoch: 6| Step: 5
Training loss: 2.4511531996300517
Validation loss: 2.4795265574213046

Epoch: 6| Step: 6
Training loss: 3.090390163097284
Validation loss: 2.4861618099915965

Epoch: 6| Step: 7
Training loss: 2.5913701917171195
Validation loss: 2.518315697314485

Epoch: 6| Step: 8
Training loss: 3.0543117438429004
Validation loss: 2.546195588774631

Epoch: 6| Step: 9
Training loss: 2.7670829076833177
Validation loss: 2.54612500851894

Epoch: 6| Step: 10
Training loss: 2.6817041043674723
Validation loss: 2.5602111949298867

Epoch: 6| Step: 11
Training loss: 2.6059329235669377
Validation loss: 2.5653905814920988

Epoch: 6| Step: 12
Training loss: 2.2823189099309538
Validation loss: 2.5507432290023

Epoch: 6| Step: 13
Training loss: 3.1210497493769522
Validation loss: 2.5425003169996656

Epoch: 137| Step: 0
Training loss: 3.1320305131324746
Validation loss: 2.5344406248709035

Epoch: 6| Step: 1
Training loss: 2.5762261073352475
Validation loss: 2.493345471153483

Epoch: 6| Step: 2
Training loss: 3.057197495699282
Validation loss: 2.4851359221540807

Epoch: 6| Step: 3
Training loss: 2.5528709182471276
Validation loss: 2.479850524956233

Epoch: 6| Step: 4
Training loss: 2.5397158677084697
Validation loss: 2.4788157469010623

Epoch: 6| Step: 5
Training loss: 2.855801042460103
Validation loss: 2.483268639525067

Epoch: 6| Step: 6
Training loss: 2.73532924894951
Validation loss: 2.486154537181043

Epoch: 6| Step: 7
Training loss: 3.0200824900596897
Validation loss: 2.4829875280641995

Epoch: 6| Step: 8
Training loss: 2.7962910133051797
Validation loss: 2.4895284104919018

Epoch: 6| Step: 9
Training loss: 2.569072946263429
Validation loss: 2.4895280964121587

Epoch: 6| Step: 10
Training loss: 3.1384497553832893
Validation loss: 2.494365374070486

Epoch: 6| Step: 11
Training loss: 2.877623812002841
Validation loss: 2.513264643166571

Epoch: 6| Step: 12
Training loss: 2.6699122308028085
Validation loss: 2.541038469508866

Epoch: 6| Step: 13
Training loss: 2.9846200892285046
Validation loss: 2.541042708881506

Epoch: 138| Step: 0
Training loss: 3.284589829755223
Validation loss: 2.554469350864896

Epoch: 6| Step: 1
Training loss: 2.584974219011025
Validation loss: 2.541433152826322

Epoch: 6| Step: 2
Training loss: 2.30990351719028
Validation loss: 2.5141666184682507

Epoch: 6| Step: 3
Training loss: 2.8990944994301198
Validation loss: 2.5191682811499034

Epoch: 6| Step: 4
Training loss: 2.4116223295293198
Validation loss: 2.501983579120287

Epoch: 6| Step: 5
Training loss: 2.7472667983188344
Validation loss: 2.4826171851868946

Epoch: 6| Step: 6
Training loss: 2.9792895702984237
Validation loss: 2.486370301585507

Epoch: 6| Step: 7
Training loss: 2.6728895614649115
Validation loss: 2.4799675413532203

Epoch: 6| Step: 8
Training loss: 2.6288870234020183
Validation loss: 2.495740919326295

Epoch: 6| Step: 9
Training loss: 2.499976348765077
Validation loss: 2.509557332257925

Epoch: 6| Step: 10
Training loss: 3.2210970719214163
Validation loss: 2.534762165067465

Epoch: 6| Step: 11
Training loss: 2.9788940589509263
Validation loss: 2.5380337972288793

Epoch: 6| Step: 12
Training loss: 2.7923637962080683
Validation loss: 2.5555285593110635

Epoch: 6| Step: 13
Training loss: 3.326839288222111
Validation loss: 2.5626480656026946

Epoch: 139| Step: 0
Training loss: 3.1274729290102408
Validation loss: 2.548764658510098

Epoch: 6| Step: 1
Training loss: 2.8689119314064024
Validation loss: 2.545426943068929

Epoch: 6| Step: 2
Training loss: 2.8104093622707027
Validation loss: 2.514119606789693

Epoch: 6| Step: 3
Training loss: 2.6506547227023693
Validation loss: 2.4851550890169065

Epoch: 6| Step: 4
Training loss: 2.1022266345395613
Validation loss: 2.477126858206205

Epoch: 6| Step: 5
Training loss: 2.713955213746476
Validation loss: 2.472609446502404

Epoch: 6| Step: 6
Training loss: 3.340882970628798
Validation loss: 2.471294027388361

Epoch: 6| Step: 7
Training loss: 2.69835970467712
Validation loss: 2.4689563329062083

Epoch: 6| Step: 8
Training loss: 2.8556941787512384
Validation loss: 2.4657505797739296

Epoch: 6| Step: 9
Training loss: 3.2757462619520563
Validation loss: 2.4698570617697735

Epoch: 6| Step: 10
Training loss: 2.4868955481620576
Validation loss: 2.474378840530292

Epoch: 6| Step: 11
Training loss: 2.6916806727498668
Validation loss: 2.4973945956853867

Epoch: 6| Step: 12
Training loss: 2.6486903607223784
Validation loss: 2.5011959230305334

Epoch: 6| Step: 13
Training loss: 2.6707515920269893
Validation loss: 2.503726032487978

Epoch: 140| Step: 0
Training loss: 3.3273211300849757
Validation loss: 2.494503308658551

Epoch: 6| Step: 1
Training loss: 2.8474310222037857
Validation loss: 2.513843520859565

Epoch: 6| Step: 2
Training loss: 3.152880692634484
Validation loss: 2.5026603735869783

Epoch: 6| Step: 3
Training loss: 2.6029438555682445
Validation loss: 2.4895738260056137

Epoch: 6| Step: 4
Training loss: 3.1493345738515366
Validation loss: 2.4837183085387156

Epoch: 6| Step: 5
Training loss: 2.5073701937879633
Validation loss: 2.4826707505520482

Epoch: 6| Step: 6
Training loss: 2.8575276728747734
Validation loss: 2.4838087783686373

Epoch: 6| Step: 7
Training loss: 2.4814719266638994
Validation loss: 2.497718896299305

Epoch: 6| Step: 8
Training loss: 2.579040457288014
Validation loss: 2.4884973183215218

Epoch: 6| Step: 9
Training loss: 2.64039457320251
Validation loss: 2.4844789912126304

Epoch: 6| Step: 10
Training loss: 2.859781538615913
Validation loss: 2.502150206695813

Epoch: 6| Step: 11
Training loss: 2.363399080223724
Validation loss: 2.5254575466098017

Epoch: 6| Step: 12
Training loss: 2.5954330682738957
Validation loss: 2.5618194728903183

Epoch: 6| Step: 13
Training loss: 3.3884917549392113
Validation loss: 2.5451361083014143

Epoch: 141| Step: 0
Training loss: 2.1731567991364114
Validation loss: 2.555819447258857

Epoch: 6| Step: 1
Training loss: 2.7230867020963156
Validation loss: 2.532513439755568

Epoch: 6| Step: 2
Training loss: 2.9930780345508277
Validation loss: 2.5091970656556306

Epoch: 6| Step: 3
Training loss: 2.9274268621858455
Validation loss: 2.510875486541851

Epoch: 6| Step: 4
Training loss: 3.2113515025453676
Validation loss: 2.506925381831416

Epoch: 6| Step: 5
Training loss: 2.494508625027076
Validation loss: 2.496373337330207

Epoch: 6| Step: 6
Training loss: 2.879793234926378
Validation loss: 2.504742758685767

Epoch: 6| Step: 7
Training loss: 2.8308288126196226
Validation loss: 2.4904729100190255

Epoch: 6| Step: 8
Training loss: 2.9274053611410737
Validation loss: 2.4816349423911013

Epoch: 6| Step: 9
Training loss: 1.9838812506654584
Validation loss: 2.483519904552818

Epoch: 6| Step: 10
Training loss: 3.2013856212482525
Validation loss: 2.4866305391614123

Epoch: 6| Step: 11
Training loss: 2.9857974831546423
Validation loss: 2.4869205917438255

Epoch: 6| Step: 12
Training loss: 2.4382837453803115
Validation loss: 2.4758034150914416

Epoch: 6| Step: 13
Training loss: 2.9573917950193964
Validation loss: 2.4852324234342658

Epoch: 142| Step: 0
Training loss: 2.9489338516158776
Validation loss: 2.4926545448102058

Epoch: 6| Step: 1
Training loss: 3.145007970463246
Validation loss: 2.5032327608272618

Epoch: 6| Step: 2
Training loss: 2.8135660482341405
Validation loss: 2.48102490080886

Epoch: 6| Step: 3
Training loss: 3.0165557215681735
Validation loss: 2.485433088875717

Epoch: 6| Step: 4
Training loss: 2.6844703097848206
Validation loss: 2.485288702082826

Epoch: 6| Step: 5
Training loss: 2.47393621066726
Validation loss: 2.473803060135292

Epoch: 6| Step: 6
Training loss: 2.4404888901507458
Validation loss: 2.493681451743212

Epoch: 6| Step: 7
Training loss: 1.9171976376788562
Validation loss: 2.4767016248209868

Epoch: 6| Step: 8
Training loss: 2.417768972398737
Validation loss: 2.47937502200489

Epoch: 6| Step: 9
Training loss: 3.1630592545281617
Validation loss: 2.4891943503913803

Epoch: 6| Step: 10
Training loss: 2.610977137850863
Validation loss: 2.4936849779679258

Epoch: 6| Step: 11
Training loss: 3.2144873086593044
Validation loss: 2.520810748448021

Epoch: 6| Step: 12
Training loss: 2.8833647408364294
Validation loss: 2.520363251204654

Epoch: 6| Step: 13
Training loss: 2.8851358619050145
Validation loss: 2.565733349603258

Epoch: 143| Step: 0
Training loss: 2.493652869606
Validation loss: 2.55696411487823

Epoch: 6| Step: 1
Training loss: 2.5920207682236716
Validation loss: 2.5498444497883943

Epoch: 6| Step: 2
Training loss: 3.2395523576799024
Validation loss: 2.5118933247505875

Epoch: 6| Step: 3
Training loss: 2.30423010473777
Validation loss: 2.4961149443415804

Epoch: 6| Step: 4
Training loss: 3.410900755687407
Validation loss: 2.481883115950467

Epoch: 6| Step: 5
Training loss: 2.661908573853392
Validation loss: 2.467934138882427

Epoch: 6| Step: 6
Training loss: 2.489684854350187
Validation loss: 2.4635891963873853

Epoch: 6| Step: 7
Training loss: 3.0147053793820544
Validation loss: 2.4661379300957504

Epoch: 6| Step: 8
Training loss: 3.0057835460911266
Validation loss: 2.463546162540285

Epoch: 6| Step: 9
Training loss: 2.461574508329698
Validation loss: 2.466543241216012

Epoch: 6| Step: 10
Training loss: 2.8925858728690126
Validation loss: 2.474349809554586

Epoch: 6| Step: 11
Training loss: 2.6767664522673864
Validation loss: 2.4766825747169143

Epoch: 6| Step: 12
Training loss: 3.111801350938886
Validation loss: 2.48965031266049

Epoch: 6| Step: 13
Training loss: 1.9186756827907163
Validation loss: 2.481984451662897

Epoch: 144| Step: 0
Training loss: 3.137729809616229
Validation loss: 2.4854727577241094

Epoch: 6| Step: 1
Training loss: 2.720820548323016
Validation loss: 2.4861103729352667

Epoch: 6| Step: 2
Training loss: 2.41015941551656
Validation loss: 2.475170198175524

Epoch: 6| Step: 3
Training loss: 2.3856448490555326
Validation loss: 2.466793610685599

Epoch: 6| Step: 4
Training loss: 2.717848003322673
Validation loss: 2.4686588817275172

Epoch: 6| Step: 5
Training loss: 3.0508209499457566
Validation loss: 2.456022270897308

Epoch: 6| Step: 6
Training loss: 2.791949746502148
Validation loss: 2.459854837363685

Epoch: 6| Step: 7
Training loss: 2.6427475564101126
Validation loss: 2.463373687649828

Epoch: 6| Step: 8
Training loss: 2.819496438267882
Validation loss: 2.4674977347874973

Epoch: 6| Step: 9
Training loss: 2.4147130589584536
Validation loss: 2.470901294928674

Epoch: 6| Step: 10
Training loss: 2.756665474854119
Validation loss: 2.4671769079064796

Epoch: 6| Step: 11
Training loss: 2.925192841261809
Validation loss: 2.487573052389631

Epoch: 6| Step: 12
Training loss: 2.996369390229629
Validation loss: 2.4790857628802208

Epoch: 6| Step: 13
Training loss: 3.047317550993299
Validation loss: 2.484380798271163

Epoch: 145| Step: 0
Training loss: 2.3011484678829905
Validation loss: 2.4814757688077655

Epoch: 6| Step: 1
Training loss: 2.57298571124596
Validation loss: 2.4789819487449223

Epoch: 6| Step: 2
Training loss: 2.8911048284715353
Validation loss: 2.475173754915025

Epoch: 6| Step: 3
Training loss: 2.6877826275921266
Validation loss: 2.471932571280212

Epoch: 6| Step: 4
Training loss: 2.7797745637944815
Validation loss: 2.4771913880472853

Epoch: 6| Step: 5
Training loss: 2.5661805865101908
Validation loss: 2.4770455769640907

Epoch: 6| Step: 6
Training loss: 2.9397801416932765
Validation loss: 2.4824701819587944

Epoch: 6| Step: 7
Training loss: 2.389725659318793
Validation loss: 2.476495789193275

Epoch: 6| Step: 8
Training loss: 3.1984352577697317
Validation loss: 2.4887589826567154

Epoch: 6| Step: 9
Training loss: 3.034869206232451
Validation loss: 2.5067213581095253

Epoch: 6| Step: 10
Training loss: 3.2832308648348505
Validation loss: 2.502359673318573

Epoch: 6| Step: 11
Training loss: 2.9551620320209255
Validation loss: 2.50867455289885

Epoch: 6| Step: 12
Training loss: 2.5987448340250388
Validation loss: 2.5014913048731526

Epoch: 6| Step: 13
Training loss: 1.8894017573565196
Validation loss: 2.4854663812926283

Epoch: 146| Step: 0
Training loss: 2.872045906635083
Validation loss: 2.4823434812057164

Epoch: 6| Step: 1
Training loss: 2.742112291831683
Validation loss: 2.4864053791123615

Epoch: 6| Step: 2
Training loss: 2.180826415985219
Validation loss: 2.4801830491209227

Epoch: 6| Step: 3
Training loss: 3.332817959680391
Validation loss: 2.4933787699932046

Epoch: 6| Step: 4
Training loss: 3.004362431327887
Validation loss: 2.4782912167619124

Epoch: 6| Step: 5
Training loss: 2.622680638495062
Validation loss: 2.4904991189010834

Epoch: 6| Step: 6
Training loss: 2.830161525847975
Validation loss: 2.5023658018058828

Epoch: 6| Step: 7
Training loss: 2.598269190931475
Validation loss: 2.4962157639231872

Epoch: 6| Step: 8
Training loss: 2.8002821984453954
Validation loss: 2.4961193411486744

Epoch: 6| Step: 9
Training loss: 2.907901745738018
Validation loss: 2.5028362531279003

Epoch: 6| Step: 10
Training loss: 2.6640278654559952
Validation loss: 2.478391432202762

Epoch: 6| Step: 11
Training loss: 2.316556517180196
Validation loss: 2.484097796099128

Epoch: 6| Step: 12
Training loss: 2.8863592891892482
Validation loss: 2.4814360453606743

Epoch: 6| Step: 13
Training loss: 2.5567156938761775
Validation loss: 2.4783393352852476

Epoch: 147| Step: 0
Training loss: 3.0881858650761065
Validation loss: 2.489738081285695

Epoch: 6| Step: 1
Training loss: 2.8948587291554624
Validation loss: 2.476894852332886

Epoch: 6| Step: 2
Training loss: 2.8136540058696085
Validation loss: 2.47833839603286

Epoch: 6| Step: 3
Training loss: 2.280742745636
Validation loss: 2.482056668883343

Epoch: 6| Step: 4
Training loss: 3.0913421817027955
Validation loss: 2.485224428911623

Epoch: 6| Step: 5
Training loss: 2.8371255030929268
Validation loss: 2.4880806674371807

Epoch: 6| Step: 6
Training loss: 2.6695208970456075
Validation loss: 2.4849784202362493

Epoch: 6| Step: 7
Training loss: 2.8885343672372064
Validation loss: 2.4874572538340143

Epoch: 6| Step: 8
Training loss: 2.7061703676837205
Validation loss: 2.495448236726944

Epoch: 6| Step: 9
Training loss: 2.355889784095319
Validation loss: 2.499268292436268

Epoch: 6| Step: 10
Training loss: 2.5641047407410014
Validation loss: 2.505668567332549

Epoch: 6| Step: 11
Training loss: 2.7605432061516053
Validation loss: 2.503870744453305

Epoch: 6| Step: 12
Training loss: 2.413019739012563
Validation loss: 2.527262596720123

Epoch: 6| Step: 13
Training loss: 3.2509280126950806
Validation loss: 2.529429451632154

Epoch: 148| Step: 0
Training loss: 2.7987002591768473
Validation loss: 2.496690589059843

Epoch: 6| Step: 1
Training loss: 2.7197163936075603
Validation loss: 2.487508696018733

Epoch: 6| Step: 2
Training loss: 2.6296180792999118
Validation loss: 2.478775098622075

Epoch: 6| Step: 3
Training loss: 2.6063320668424748
Validation loss: 2.480267766125942

Epoch: 6| Step: 4
Training loss: 2.585716491659137
Validation loss: 2.478400956911936

Epoch: 6| Step: 5
Training loss: 2.562079976711865
Validation loss: 2.485952009785954

Epoch: 6| Step: 6
Training loss: 3.198880840337175
Validation loss: 2.481868043218997

Epoch: 6| Step: 7
Training loss: 2.7528459388034894
Validation loss: 2.483528674626431

Epoch: 6| Step: 8
Training loss: 3.14296790646156
Validation loss: 2.475683966685165

Epoch: 6| Step: 9
Training loss: 3.08929276406502
Validation loss: 2.488719356918043

Epoch: 6| Step: 10
Training loss: 2.8098600077120306
Validation loss: 2.4833783434763825

Epoch: 6| Step: 11
Training loss: 2.0779053995079275
Validation loss: 2.467910652993558

Epoch: 6| Step: 12
Training loss: 2.4603768815181315
Validation loss: 2.4668012752183075

Epoch: 6| Step: 13
Training loss: 3.003025595521283
Validation loss: 2.478358506610688

Epoch: 149| Step: 0
Training loss: 2.9612474908331
Validation loss: 2.4669808294395215

Epoch: 6| Step: 1
Training loss: 3.241183132271891
Validation loss: 2.470231880040524

Epoch: 6| Step: 2
Training loss: 2.696496764144498
Validation loss: 2.4617289181936344

Epoch: 6| Step: 3
Training loss: 2.4694758446719445
Validation loss: 2.461508128700676

Epoch: 6| Step: 4
Training loss: 2.8172045884378427
Validation loss: 2.4617580688459495

Epoch: 6| Step: 5
Training loss: 2.2788141911390705
Validation loss: 2.4559590303601904

Epoch: 6| Step: 6
Training loss: 2.8430164774478603
Validation loss: 2.4666878709599516

Epoch: 6| Step: 7
Training loss: 3.4262536309329823
Validation loss: 2.464973288860625

Epoch: 6| Step: 8
Training loss: 2.6348852493808503
Validation loss: 2.476524387153176

Epoch: 6| Step: 9
Training loss: 2.4593810957526503
Validation loss: 2.4958903487072184

Epoch: 6| Step: 10
Training loss: 2.906820261802203
Validation loss: 2.514818492682382

Epoch: 6| Step: 11
Training loss: 2.266402328261645
Validation loss: 2.528259658122367

Epoch: 6| Step: 12
Training loss: 2.7555471306931834
Validation loss: 2.5486503325644407

Epoch: 6| Step: 13
Training loss: 2.6013612411594886
Validation loss: 2.505950535012135

Epoch: 150| Step: 0
Training loss: 2.691834436469267
Validation loss: 2.4722427680554553

Epoch: 6| Step: 1
Training loss: 2.17281052454224
Validation loss: 2.4701154823337457

Epoch: 6| Step: 2
Training loss: 2.470979673566777
Validation loss: 2.455314873665945

Epoch: 6| Step: 3
Training loss: 3.217584787954434
Validation loss: 2.4621610090726893

Epoch: 6| Step: 4
Training loss: 2.019998699225583
Validation loss: 2.4622252423916002

Epoch: 6| Step: 5
Training loss: 3.1140852479922088
Validation loss: 2.4629567872969917

Epoch: 6| Step: 6
Training loss: 3.263513347763835
Validation loss: 2.4658870927508985

Epoch: 6| Step: 7
Training loss: 3.144829208758132
Validation loss: 2.464925672810021

Epoch: 6| Step: 8
Training loss: 2.871069169750223
Validation loss: 2.4891658578294864

Epoch: 6| Step: 9
Training loss: 3.2707423948698
Validation loss: 2.5011839186006126

Epoch: 6| Step: 10
Training loss: 2.602305996247926
Validation loss: 2.519208546327558

Epoch: 6| Step: 11
Training loss: 2.719855335960622
Validation loss: 2.570116847718371

Epoch: 6| Step: 12
Training loss: 2.4618975023305096
Validation loss: 2.5748839549235454

Epoch: 6| Step: 13
Training loss: 1.5283483923139298
Validation loss: 2.580906565370677

Testing loss: 2.7533063317176403
