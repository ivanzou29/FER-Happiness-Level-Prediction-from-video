Epoch: 1| Step: 0
Training loss: 5.885471183951962
Validation loss: 5.787333690949034

Epoch: 5| Step: 1
Training loss: 5.945891223065171
Validation loss: 5.768874049658044

Epoch: 5| Step: 2
Training loss: 5.952648233861442
Validation loss: 5.751933458936957

Epoch: 5| Step: 3
Training loss: 5.947213669723799
Validation loss: 5.733655147339648

Epoch: 5| Step: 4
Training loss: 5.578045328890947
Validation loss: 5.713836755929388

Epoch: 5| Step: 5
Training loss: 5.062139427625122
Validation loss: 5.6906727088047875

Epoch: 5| Step: 6
Training loss: 5.163926207897943
Validation loss: 5.6641335329800375

Epoch: 5| Step: 7
Training loss: 6.064453439512874
Validation loss: 5.634237008748865

Epoch: 5| Step: 8
Training loss: 6.5563267327864905
Validation loss: 5.5995552103890605

Epoch: 5| Step: 9
Training loss: 5.464995921308805
Validation loss: 5.560572726436342

Epoch: 5| Step: 10
Training loss: 4.904094830129743
Validation loss: 5.515391518713513

Epoch: 2| Step: 0
Training loss: 5.139434212741672
Validation loss: 5.465562171293256

Epoch: 5| Step: 1
Training loss: 4.5163755222153545
Validation loss: 5.40973765124047

Epoch: 5| Step: 2
Training loss: 4.766490019790732
Validation loss: 5.3462869872617516

Epoch: 5| Step: 3
Training loss: 6.1357131998608985
Validation loss: 5.279884693437935

Epoch: 5| Step: 4
Training loss: 5.157651953407224
Validation loss: 5.209090967345544

Epoch: 5| Step: 5
Training loss: 5.583234226239199
Validation loss: 5.134313820598317

Epoch: 5| Step: 6
Training loss: 5.823907302726577
Validation loss: 5.062258529424008

Epoch: 5| Step: 7
Training loss: 4.85110761441858
Validation loss: 4.988357319676105

Epoch: 5| Step: 8
Training loss: 4.8791562482862165
Validation loss: 4.920769263368069

Epoch: 5| Step: 9
Training loss: 5.303264533810865
Validation loss: 4.856353622376021

Epoch: 5| Step: 10
Training loss: 4.633774141341888
Validation loss: 4.799263838234661

Epoch: 3| Step: 0
Training loss: 4.905398932827538
Validation loss: 4.751276672588674

Epoch: 5| Step: 1
Training loss: 4.273064801075389
Validation loss: 4.71265883208673

Epoch: 5| Step: 2
Training loss: 4.2144586282867955
Validation loss: 4.680645923446663

Epoch: 5| Step: 3
Training loss: 4.443226732223477
Validation loss: 4.652565193411372

Epoch: 5| Step: 4
Training loss: 5.257903915902913
Validation loss: 4.626203460785999

Epoch: 5| Step: 5
Training loss: 5.012335628563708
Validation loss: 4.604430268751867

Epoch: 5| Step: 6
Training loss: 4.751226567966054
Validation loss: 4.579047613272012

Epoch: 5| Step: 7
Training loss: 4.827318241405739
Validation loss: 4.554900358778053

Epoch: 5| Step: 8
Training loss: 5.265860804136862
Validation loss: 4.534762973283301

Epoch: 5| Step: 9
Training loss: 4.200458347197135
Validation loss: 4.513014451428746

Epoch: 5| Step: 10
Training loss: 4.443077128741773
Validation loss: 4.487097376135592

Epoch: 4| Step: 0
Training loss: 4.519439669961302
Validation loss: 4.464176133412107

Epoch: 5| Step: 1
Training loss: 4.2633104018210295
Validation loss: 4.445904013882474

Epoch: 5| Step: 2
Training loss: 4.9851303245780185
Validation loss: 4.430241838757407

Epoch: 5| Step: 3
Training loss: 4.523353167391766
Validation loss: 4.406340574347283

Epoch: 5| Step: 4
Training loss: 4.376102417606878
Validation loss: 4.38218683943407

Epoch: 5| Step: 5
Training loss: 3.1344708170369757
Validation loss: 4.365594199642573

Epoch: 5| Step: 6
Training loss: 5.077593684644604
Validation loss: 4.340943548952856

Epoch: 5| Step: 7
Training loss: 4.465665593106264
Validation loss: 4.31430385030198

Epoch: 5| Step: 8
Training loss: 5.085148388283215
Validation loss: 4.285783961384527

Epoch: 5| Step: 9
Training loss: 4.034774777013049
Validation loss: 4.260201573166666

Epoch: 5| Step: 10
Training loss: 4.458557456019048
Validation loss: 4.23968936186619

Epoch: 5| Step: 0
Training loss: 5.073125919775734
Validation loss: 4.225626883127607

Epoch: 5| Step: 1
Training loss: 4.200051243787325
Validation loss: 4.199744527247628

Epoch: 5| Step: 2
Training loss: 3.665629428038073
Validation loss: 4.188303682223383

Epoch: 5| Step: 3
Training loss: 4.046000146749874
Validation loss: 4.1777605308698025

Epoch: 5| Step: 4
Training loss: 3.5487753192875804
Validation loss: 4.143710391746939

Epoch: 5| Step: 5
Training loss: 4.8939556444010845
Validation loss: 4.122651018962634

Epoch: 5| Step: 6
Training loss: 4.1344350935878555
Validation loss: 4.101885562953683

Epoch: 5| Step: 7
Training loss: 4.412417376990152
Validation loss: 4.08575961087825

Epoch: 5| Step: 8
Training loss: 3.9152704685758364
Validation loss: 4.066134136304931

Epoch: 5| Step: 9
Training loss: 4.155171878349083
Validation loss: 4.046854378695269

Epoch: 5| Step: 10
Training loss: 4.696394149927645
Validation loss: 4.03633921669434

Epoch: 6| Step: 0
Training loss: 4.991676268570994
Validation loss: 4.0153922790072025

Epoch: 5| Step: 1
Training loss: 3.7394767611450073
Validation loss: 3.9977983778762534

Epoch: 5| Step: 2
Training loss: 3.9683095131877066
Validation loss: 3.9845080037189304

Epoch: 5| Step: 3
Training loss: 3.9131240785747248
Validation loss: 3.965706217863647

Epoch: 5| Step: 4
Training loss: 3.294774403236904
Validation loss: 3.9513957514981035

Epoch: 5| Step: 5
Training loss: 4.410910231924549
Validation loss: 3.9422976344044405

Epoch: 5| Step: 6
Training loss: 4.040630928855376
Validation loss: 3.9193401406446067

Epoch: 5| Step: 7
Training loss: 4.907244733330786
Validation loss: 3.910645212698847

Epoch: 5| Step: 8
Training loss: 3.8954452620557833
Validation loss: 3.892263887740237

Epoch: 5| Step: 9
Training loss: 3.490252682083353
Validation loss: 3.8811046810725975

Epoch: 5| Step: 10
Training loss: 4.115995115004774
Validation loss: 3.8704122509656615

Epoch: 7| Step: 0
Training loss: 3.6943203196950476
Validation loss: 3.8548199411220976

Epoch: 5| Step: 1
Training loss: 3.8551131589833902
Validation loss: 3.8368080507512015

Epoch: 5| Step: 2
Training loss: 4.026746970211733
Validation loss: 3.8230933110888095

Epoch: 5| Step: 3
Training loss: 4.345660551055501
Validation loss: 3.8115360380165826

Epoch: 5| Step: 4
Training loss: 4.578079587952032
Validation loss: 3.7966856725920484

Epoch: 5| Step: 5
Training loss: 3.764913784625627
Validation loss: 3.789702264386311

Epoch: 5| Step: 6
Training loss: 3.8182707090888335
Validation loss: 3.7728250157161582

Epoch: 5| Step: 7
Training loss: 4.387119400601246
Validation loss: 3.7593899126377384

Epoch: 5| Step: 8
Training loss: 3.3747720994650345
Validation loss: 3.7504660456931846

Epoch: 5| Step: 9
Training loss: 4.54914909203335
Validation loss: 3.73692108048555

Epoch: 5| Step: 10
Training loss: 2.6442779013961473
Validation loss: 3.723662079600335

Epoch: 8| Step: 0
Training loss: 3.8513600758561806
Validation loss: 3.713776384430841

Epoch: 5| Step: 1
Training loss: 3.251844322973425
Validation loss: 3.700724702218737

Epoch: 5| Step: 2
Training loss: 3.4811032933769943
Validation loss: 3.691048333353859

Epoch: 5| Step: 3
Training loss: 4.065115922727169
Validation loss: 3.678940575040505

Epoch: 5| Step: 4
Training loss: 4.46560430181577
Validation loss: 3.674888492399607

Epoch: 5| Step: 5
Training loss: 4.051603993336866
Validation loss: 3.661358615500693

Epoch: 5| Step: 6
Training loss: 3.6723526015023045
Validation loss: 3.6570544413594455

Epoch: 5| Step: 7
Training loss: 3.598468369928378
Validation loss: 3.649680673450886

Epoch: 5| Step: 8
Training loss: 3.371449757825772
Validation loss: 3.64004073915894

Epoch: 5| Step: 9
Training loss: 4.454179819561648
Validation loss: 3.626873167466694

Epoch: 5| Step: 10
Training loss: 3.944792639597345
Validation loss: 3.6081785546851934

Epoch: 9| Step: 0
Training loss: 4.212323755035494
Validation loss: 3.5937980010191786

Epoch: 5| Step: 1
Training loss: 3.2718134745849414
Validation loss: 3.5811822324562947

Epoch: 5| Step: 2
Training loss: 4.0166479804104265
Validation loss: 3.5821453528136127

Epoch: 5| Step: 3
Training loss: 3.629540329510066
Validation loss: 3.565130574052406

Epoch: 5| Step: 4
Training loss: 3.7017996303466862
Validation loss: 3.5606507771442457

Epoch: 5| Step: 5
Training loss: 4.129501660741215
Validation loss: 3.54704302122874

Epoch: 5| Step: 6
Training loss: 3.5901580108466926
Validation loss: 3.542168418960662

Epoch: 5| Step: 7
Training loss: 3.5915450256235886
Validation loss: 3.5434243414812396

Epoch: 5| Step: 8
Training loss: 3.456010122407995
Validation loss: 3.5232460248797075

Epoch: 5| Step: 9
Training loss: 3.586850384635899
Validation loss: 3.5184242121177576

Epoch: 5| Step: 10
Training loss: 4.101120697931714
Validation loss: 3.5130281639468093

Epoch: 10| Step: 0
Training loss: 3.399971591606387
Validation loss: 3.503351543503255

Epoch: 5| Step: 1
Training loss: 3.6334166321844608
Validation loss: 3.495003880213991

Epoch: 5| Step: 2
Training loss: 3.0667632654428236
Validation loss: 3.483390596577246

Epoch: 5| Step: 3
Training loss: 3.466399487567708
Validation loss: 3.4778401424516816

Epoch: 5| Step: 4
Training loss: 4.387663470317632
Validation loss: 3.4772781533273815

Epoch: 5| Step: 5
Training loss: 3.6871420476423453
Validation loss: 3.46672430720184

Epoch: 5| Step: 6
Training loss: 3.3651076972130882
Validation loss: 3.4530017812053058

Epoch: 5| Step: 7
Training loss: 4.3716788628995005
Validation loss: 3.448273736953434

Epoch: 5| Step: 8
Training loss: 3.844650039124477
Validation loss: 3.4456568649495694

Epoch: 5| Step: 9
Training loss: 3.928367317148739
Validation loss: 3.444207901054222

Epoch: 5| Step: 10
Training loss: 2.9802877988668657
Validation loss: 3.438053379655152

Epoch: 11| Step: 0
Training loss: 4.309967403067328
Validation loss: 3.433551863531372

Epoch: 5| Step: 1
Training loss: 2.751593214965121
Validation loss: 3.424035878356896

Epoch: 5| Step: 2
Training loss: 3.301116384613791
Validation loss: 3.417036514213462

Epoch: 5| Step: 3
Training loss: 3.1288978681321096
Validation loss: 3.4097830693156017

Epoch: 5| Step: 4
Training loss: 4.035251021772477
Validation loss: 3.403639322127106

Epoch: 5| Step: 5
Training loss: 3.5103523557905407
Validation loss: 3.393496723295289

Epoch: 5| Step: 6
Training loss: 3.515652804794561
Validation loss: 3.384855356688516

Epoch: 5| Step: 7
Training loss: 3.4929584787141397
Validation loss: 3.3806235308398613

Epoch: 5| Step: 8
Training loss: 3.163925356306359
Validation loss: 3.3796023682974

Epoch: 5| Step: 9
Training loss: 4.266806637931704
Validation loss: 3.3691617601994084

Epoch: 5| Step: 10
Training loss: 4.12372245656806
Validation loss: 3.400268845783797

Epoch: 12| Step: 0
Training loss: 3.875143479182794
Validation loss: 3.369661495683573

Epoch: 5| Step: 1
Training loss: 3.579470985155395
Validation loss: 3.3664943310021247

Epoch: 5| Step: 2
Training loss: 3.0621769014531894
Validation loss: 3.3694034397223493

Epoch: 5| Step: 3
Training loss: 3.760547047447929
Validation loss: 3.373058161531482

Epoch: 5| Step: 4
Training loss: 3.2176230226130302
Validation loss: 3.3599733583382445

Epoch: 5| Step: 5
Training loss: 3.579537991382476
Validation loss: 3.347266270370335

Epoch: 5| Step: 6
Training loss: 3.7185527845388138
Validation loss: 3.338802670243943

Epoch: 5| Step: 7
Training loss: 2.9860454897114304
Validation loss: 3.3308893301350264

Epoch: 5| Step: 8
Training loss: 3.6543272782757823
Validation loss: 3.3246053799058193

Epoch: 5| Step: 9
Training loss: 4.156255965838058
Validation loss: 3.318383452601354

Epoch: 5| Step: 10
Training loss: 3.6674518322528153
Validation loss: 3.3121001980761053

Epoch: 13| Step: 0
Training loss: 3.4557841147352146
Validation loss: 3.308010664921982

Epoch: 5| Step: 1
Training loss: 3.391302225714012
Validation loss: 3.3237826087978997

Epoch: 5| Step: 2
Training loss: 3.6002492765377303
Validation loss: 3.3023168646177368

Epoch: 5| Step: 3
Training loss: 3.0654914414674135
Validation loss: 3.296820140063957

Epoch: 5| Step: 4
Training loss: 3.0178717115474605
Validation loss: 3.298014141669559

Epoch: 5| Step: 5
Training loss: 4.121832122464035
Validation loss: 3.3143334572553598

Epoch: 5| Step: 6
Training loss: 4.160920007649581
Validation loss: 3.292086597187055

Epoch: 5| Step: 7
Training loss: 3.409588778582849
Validation loss: 3.3066192824547493

Epoch: 5| Step: 8
Training loss: 3.6745037652086068
Validation loss: 3.3393179135508615

Epoch: 5| Step: 9
Training loss: 3.6178314097248774
Validation loss: 3.3318921670501775

Epoch: 5| Step: 10
Training loss: 3.3667726902901385
Validation loss: 3.3036272399067363

Epoch: 14| Step: 0
Training loss: 2.9232924995774776
Validation loss: 3.2881089916493274

Epoch: 5| Step: 1
Training loss: 3.5669144167074887
Validation loss: 3.288072826447644

Epoch: 5| Step: 2
Training loss: 2.815304608168303
Validation loss: 3.293817662885951

Epoch: 5| Step: 3
Training loss: 4.114933794121709
Validation loss: 3.2962554301261897

Epoch: 5| Step: 4
Training loss: 3.435211251993856
Validation loss: 3.28894913334584

Epoch: 5| Step: 5
Training loss: 3.3024561498071288
Validation loss: 3.277878929249675

Epoch: 5| Step: 6
Training loss: 4.601274206071402
Validation loss: 3.265978557392221

Epoch: 5| Step: 7
Training loss: 3.0195947322118837
Validation loss: 3.253858406512779

Epoch: 5| Step: 8
Training loss: 4.148564166130606
Validation loss: 3.2465934088006105

Epoch: 5| Step: 9
Training loss: 3.0916835164093377
Validation loss: 3.241895270839226

Epoch: 5| Step: 10
Training loss: 3.1665898531247456
Validation loss: 3.2413062884639543

Epoch: 15| Step: 0
Training loss: 2.9844254893880304
Validation loss: 3.238367677515906

Epoch: 5| Step: 1
Training loss: 4.031018864119312
Validation loss: 3.238305125007545

Epoch: 5| Step: 2
Training loss: 3.1251152017339914
Validation loss: 3.238083202092462

Epoch: 5| Step: 3
Training loss: 2.4429463892085055
Validation loss: 3.2357703657757613

Epoch: 5| Step: 4
Training loss: 4.1723774239538685
Validation loss: 3.233036465955782

Epoch: 5| Step: 5
Training loss: 3.250216990342947
Validation loss: 3.225853087154781

Epoch: 5| Step: 6
Training loss: 3.056834995317646
Validation loss: 3.2240443340050153

Epoch: 5| Step: 7
Training loss: 3.8006912957864256
Validation loss: 3.226873330663721

Epoch: 5| Step: 8
Training loss: 3.648013758098023
Validation loss: 3.214601652866378

Epoch: 5| Step: 9
Training loss: 3.390236968588779
Validation loss: 3.218745415510367

Epoch: 5| Step: 10
Training loss: 4.101258824323551
Validation loss: 3.217331814896476

Epoch: 16| Step: 0
Training loss: 3.48255359616631
Validation loss: 3.2091886155192637

Epoch: 5| Step: 1
Training loss: 3.0061836092591094
Validation loss: 3.2028242969003426

Epoch: 5| Step: 2
Training loss: 3.97734328962873
Validation loss: 3.2016555901279147

Epoch: 5| Step: 3
Training loss: 3.5864121864637672
Validation loss: 3.20018534613867

Epoch: 5| Step: 4
Training loss: 3.3834838201069166
Validation loss: 3.199407602666705

Epoch: 5| Step: 5
Training loss: 3.550249015778421
Validation loss: 3.1956939208864985

Epoch: 5| Step: 6
Training loss: 2.842625657712041
Validation loss: 3.1955495698718464

Epoch: 5| Step: 7
Training loss: 3.66033407489753
Validation loss: 3.200078792012176

Epoch: 5| Step: 8
Training loss: 3.4882268442180813
Validation loss: 3.1866599915821943

Epoch: 5| Step: 9
Training loss: 3.5528620130229576
Validation loss: 3.1843049815682685

Epoch: 5| Step: 10
Training loss: 3.352098542141992
Validation loss: 3.181732536783218

Epoch: 17| Step: 0
Training loss: 3.2732267107046544
Validation loss: 3.176815123443775

Epoch: 5| Step: 1
Training loss: 3.707478213924672
Validation loss: 3.172400161474317

Epoch: 5| Step: 2
Training loss: 2.937429386669978
Validation loss: 3.165750657373005

Epoch: 5| Step: 3
Training loss: 3.09845014407011
Validation loss: 3.1615110119506276

Epoch: 5| Step: 4
Training loss: 3.5680096501361027
Validation loss: 3.158780058905931

Epoch: 5| Step: 5
Training loss: 3.7614804328065725
Validation loss: 3.1560494411885904

Epoch: 5| Step: 6
Training loss: 2.834467903810077
Validation loss: 3.152635104161075

Epoch: 5| Step: 7
Training loss: 3.147842085884941
Validation loss: 3.1478600419913714

Epoch: 5| Step: 8
Training loss: 4.4054105784253474
Validation loss: 3.1443162185601596

Epoch: 5| Step: 9
Training loss: 3.32776965899389
Validation loss: 3.1408218202122624

Epoch: 5| Step: 10
Training loss: 3.30533775623616
Validation loss: 3.138491578608072

Epoch: 18| Step: 0
Training loss: 3.746506780581853
Validation loss: 3.1402827291513757

Epoch: 5| Step: 1
Training loss: 3.2874073204059746
Validation loss: 3.1351774941639317

Epoch: 5| Step: 2
Training loss: 3.276513159238952
Validation loss: 3.133971021691104

Epoch: 5| Step: 3
Training loss: 2.679697909765905
Validation loss: 3.132635716787447

Epoch: 5| Step: 4
Training loss: 3.4506166763910033
Validation loss: 3.1334421840821833

Epoch: 5| Step: 5
Training loss: 3.2009290657800076
Validation loss: 3.124679768879833

Epoch: 5| Step: 6
Training loss: 3.753708849111951
Validation loss: 3.131348522027261

Epoch: 5| Step: 7
Training loss: 3.244454273952185
Validation loss: 3.1466019399182703

Epoch: 5| Step: 8
Training loss: 3.4118705364588724
Validation loss: 3.1275815305216597

Epoch: 5| Step: 9
Training loss: 3.538061543569301
Validation loss: 3.1247018503682966

Epoch: 5| Step: 10
Training loss: 3.775858037583366
Validation loss: 3.119703223217868

Epoch: 19| Step: 0
Training loss: 3.3252660085638204
Validation loss: 3.114272862109787

Epoch: 5| Step: 1
Training loss: 3.416986465994424
Validation loss: 3.111530838055853

Epoch: 5| Step: 2
Training loss: 4.105421594118453
Validation loss: 3.110565767185262

Epoch: 5| Step: 3
Training loss: 3.079895594672727
Validation loss: 3.1050838170750152

Epoch: 5| Step: 4
Training loss: 2.7888742591741003
Validation loss: 3.1003058132180707

Epoch: 5| Step: 5
Training loss: 4.2550104562920055
Validation loss: 3.096652298208749

Epoch: 5| Step: 6
Training loss: 2.686624517449361
Validation loss: 3.0911291777364074

Epoch: 5| Step: 7
Training loss: 3.3848477555583067
Validation loss: 3.086754428890091

Epoch: 5| Step: 8
Training loss: 3.222111844404847
Validation loss: 3.0842611989286346

Epoch: 5| Step: 9
Training loss: 3.245928047440386
Validation loss: 3.0786995733310523

Epoch: 5| Step: 10
Training loss: 3.2795334458574374
Validation loss: 3.0725928590477034

Epoch: 20| Step: 0
Training loss: 3.2828779269438777
Validation loss: 3.068573495014198

Epoch: 5| Step: 1
Training loss: 3.338363587167298
Validation loss: 3.061583046237089

Epoch: 5| Step: 2
Training loss: 3.201315615337911
Validation loss: 3.0583292118123087

Epoch: 5| Step: 3
Training loss: 2.931296107858816
Validation loss: 3.0517509190110315

Epoch: 5| Step: 4
Training loss: 3.0373921253530534
Validation loss: 3.0502517806069847

Epoch: 5| Step: 5
Training loss: 3.7457788233597396
Validation loss: 3.0478774035989207

Epoch: 5| Step: 6
Training loss: 2.7594432818042094
Validation loss: 3.0446901795320325

Epoch: 5| Step: 7
Training loss: 3.6747061994757924
Validation loss: 3.043245807189633

Epoch: 5| Step: 8
Training loss: 3.407357691971895
Validation loss: 3.0393220296292167

Epoch: 5| Step: 9
Training loss: 3.234525225555277
Validation loss: 3.0368350722287243

Epoch: 5| Step: 10
Training loss: 4.006165997224086
Validation loss: 3.029814371415668

Epoch: 21| Step: 0
Training loss: 3.0073092745635552
Validation loss: 3.0304274919452396

Epoch: 5| Step: 1
Training loss: 2.852388445238358
Validation loss: 3.029644667793082

Epoch: 5| Step: 2
Training loss: 3.5587333710432363
Validation loss: 3.04049050728063

Epoch: 5| Step: 3
Training loss: 2.965749730340154
Validation loss: 3.0370893324935953

Epoch: 5| Step: 4
Training loss: 3.0878137220618282
Validation loss: 3.0275003668596203

Epoch: 5| Step: 5
Training loss: 3.9374654859210922
Validation loss: 3.021081630076664

Epoch: 5| Step: 6
Training loss: 4.269321502810529
Validation loss: 3.021062027729539

Epoch: 5| Step: 7
Training loss: 3.2354912789595254
Validation loss: 3.0130022713303055

Epoch: 5| Step: 8
Training loss: 2.8221295281036936
Validation loss: 3.0104257372216234

Epoch: 5| Step: 9
Training loss: 2.838443542091014
Validation loss: 3.0111257926662107

Epoch: 5| Step: 10
Training loss: 3.5838004997961126
Validation loss: 3.0090475959336267

Epoch: 22| Step: 0
Training loss: 2.725954004281707
Validation loss: 3.0054132995870035

Epoch: 5| Step: 1
Training loss: 2.944992574219336
Validation loss: 3.003917220041611

Epoch: 5| Step: 2
Training loss: 3.667682088064461
Validation loss: 3.0040773077680645

Epoch: 5| Step: 3
Training loss: 2.97387990942779
Validation loss: 3.0029596936607326

Epoch: 5| Step: 4
Training loss: 3.2488233930657193
Validation loss: 3.0042345794688106

Epoch: 5| Step: 5
Training loss: 3.346467527060134
Validation loss: 2.999967445005479

Epoch: 5| Step: 6
Training loss: 2.9680417470849303
Validation loss: 2.9968830754603295

Epoch: 5| Step: 7
Training loss: 3.4385031883554458
Validation loss: 2.995242874517669

Epoch: 5| Step: 8
Training loss: 4.10557699741333
Validation loss: 2.9917262162553317

Epoch: 5| Step: 9
Training loss: 3.4964891263426408
Validation loss: 2.9911575508938437

Epoch: 5| Step: 10
Training loss: 3.086993459315858
Validation loss: 2.9873238780258253

Epoch: 23| Step: 0
Training loss: 3.4514976567903246
Validation loss: 2.9865047348662124

Epoch: 5| Step: 1
Training loss: 3.517550064305414
Validation loss: 2.9834718768527493

Epoch: 5| Step: 2
Training loss: 3.3595477392452793
Validation loss: 2.9836424246447124

Epoch: 5| Step: 3
Training loss: 3.0275001534698975
Validation loss: 2.980077594942435

Epoch: 5| Step: 4
Training loss: 3.4232021875961527
Validation loss: 2.978534283430784

Epoch: 5| Step: 5
Training loss: 3.223728218966472
Validation loss: 2.9745198766257364

Epoch: 5| Step: 6
Training loss: 3.019418810568233
Validation loss: 2.9721880466675197

Epoch: 5| Step: 7
Training loss: 2.6865187339505807
Validation loss: 2.9708212112018133

Epoch: 5| Step: 8
Training loss: 3.4506664240609526
Validation loss: 2.96917650562516

Epoch: 5| Step: 9
Training loss: 3.5018947104982363
Validation loss: 2.9691669872891464

Epoch: 5| Step: 10
Training loss: 3.3288768223587817
Validation loss: 2.968899616989793

Epoch: 24| Step: 0
Training loss: 3.437019730742988
Validation loss: 2.9661428068403546

Epoch: 5| Step: 1
Training loss: 3.604446944141684
Validation loss: 2.963659367243495

Epoch: 5| Step: 2
Training loss: 2.859244588577474
Validation loss: 2.9620934660513987

Epoch: 5| Step: 3
Training loss: 3.545966481549007
Validation loss: 2.959792404017823

Epoch: 5| Step: 4
Training loss: 2.80687150423677
Validation loss: 2.9581173845846833

Epoch: 5| Step: 5
Training loss: 3.0919566495750814
Validation loss: 2.9574552665949136

Epoch: 5| Step: 6
Training loss: 3.876784129267004
Validation loss: 2.9569098690338023

Epoch: 5| Step: 7
Training loss: 3.2783763109139734
Validation loss: 2.9558537091832995

Epoch: 5| Step: 8
Training loss: 3.153825338448833
Validation loss: 2.9522321638016065

Epoch: 5| Step: 9
Training loss: 3.1737282135716356
Validation loss: 2.9519273133056756

Epoch: 5| Step: 10
Training loss: 2.8536317607163406
Validation loss: 2.9521420582393176

Epoch: 25| Step: 0
Training loss: 3.779143574289065
Validation loss: 2.9543205810432633

Epoch: 5| Step: 1
Training loss: 3.3154013541223053
Validation loss: 2.9456027478099247

Epoch: 5| Step: 2
Training loss: 3.254883544995042
Validation loss: 2.9460919116160578

Epoch: 5| Step: 3
Training loss: 3.48305373522269
Validation loss: 2.9414780769271713

Epoch: 5| Step: 4
Training loss: 2.9336213822974586
Validation loss: 2.9430099734904323

Epoch: 5| Step: 5
Training loss: 3.353864399497583
Validation loss: 2.9434565995487056

Epoch: 5| Step: 6
Training loss: 2.5949829112759977
Validation loss: 2.9438464819127073

Epoch: 5| Step: 7
Training loss: 2.9677503006872064
Validation loss: 2.9436150834768515

Epoch: 5| Step: 8
Training loss: 3.398136941181227
Validation loss: 2.939189235801416

Epoch: 5| Step: 9
Training loss: 3.1900011609114207
Validation loss: 2.9353305238401286

Epoch: 5| Step: 10
Training loss: 3.3561750918647584
Validation loss: 2.9502083340345338

Epoch: 26| Step: 0
Training loss: 3.377056060687167
Validation loss: 3.0148386077887603

Epoch: 5| Step: 1
Training loss: 2.879972718427506
Validation loss: 2.949387129728237

Epoch: 5| Step: 2
Training loss: 2.773127492852388
Validation loss: 2.94870128398813

Epoch: 5| Step: 3
Training loss: 3.0350425041025346
Validation loss: 2.9460866017514222

Epoch: 5| Step: 4
Training loss: 2.997529920312547
Validation loss: 2.9546576214180034

Epoch: 5| Step: 5
Training loss: 2.8070120781345445
Validation loss: 2.9748646051887047

Epoch: 5| Step: 6
Training loss: 2.8443948203301344
Validation loss: 2.994349334850845

Epoch: 5| Step: 7
Training loss: 3.6716911107544123
Validation loss: 2.972083123333686

Epoch: 5| Step: 8
Training loss: 3.700143893768826
Validation loss: 2.9504724880238964

Epoch: 5| Step: 9
Training loss: 3.8146242571138544
Validation loss: 2.9402015165855304

Epoch: 5| Step: 10
Training loss: 3.704995113683611
Validation loss: 2.946558477518212

Epoch: 27| Step: 0
Training loss: 3.612868166843514
Validation loss: 2.9399628648818656

Epoch: 5| Step: 1
Training loss: 3.3163958977311925
Validation loss: 2.929581562929816

Epoch: 5| Step: 2
Training loss: 3.1275977971850906
Validation loss: 2.920204503240285

Epoch: 5| Step: 3
Training loss: 3.3499992655283566
Validation loss: 2.9178015409840254

Epoch: 5| Step: 4
Training loss: 2.9392224395568185
Validation loss: 2.9167698351167997

Epoch: 5| Step: 5
Training loss: 2.5100589565936837
Validation loss: 2.9128556546091193

Epoch: 5| Step: 6
Training loss: 2.8518280323716407
Validation loss: 2.9077526058082324

Epoch: 5| Step: 7
Training loss: 3.6910780018987777
Validation loss: 2.905540273795039

Epoch: 5| Step: 8
Training loss: 3.8612564998731305
Validation loss: 2.9025878397291103

Epoch: 5| Step: 9
Training loss: 2.6022061304987867
Validation loss: 2.901159793581937

Epoch: 5| Step: 10
Training loss: 3.290187036363272
Validation loss: 2.8910319353665233

Epoch: 28| Step: 0
Training loss: 2.728127104418665
Validation loss: 2.886590396323765

Epoch: 5| Step: 1
Training loss: 3.0478365432383865
Validation loss: 2.888946611770632

Epoch: 5| Step: 2
Training loss: 3.933694968867472
Validation loss: 2.891356219901134

Epoch: 5| Step: 3
Training loss: 3.2592294662330867
Validation loss: 2.890349741575919

Epoch: 5| Step: 4
Training loss: 3.517553588849393
Validation loss: 2.8883478571363526

Epoch: 5| Step: 5
Training loss: 3.4914024204481544
Validation loss: 2.8759589849630913

Epoch: 5| Step: 6
Training loss: 3.689040298750566
Validation loss: 2.887166333089596

Epoch: 5| Step: 7
Training loss: 2.7766812120432927
Validation loss: 2.8958823196282317

Epoch: 5| Step: 8
Training loss: 2.8620094711925397
Validation loss: 2.895790998058368

Epoch: 5| Step: 9
Training loss: 2.783017828946946
Validation loss: 2.87912862021337

Epoch: 5| Step: 10
Training loss: 2.613065656541513
Validation loss: 2.8652661041044816

Epoch: 29| Step: 0
Training loss: 3.1469574660829087
Validation loss: 2.85780566924439

Epoch: 5| Step: 1
Training loss: 2.9427051285357733
Validation loss: 2.8553420226787476

Epoch: 5| Step: 2
Training loss: 3.457177731271649
Validation loss: 2.8528687091934466

Epoch: 5| Step: 3
Training loss: 3.096141930897582
Validation loss: 2.8507051548673292

Epoch: 5| Step: 4
Training loss: 2.875131023572658
Validation loss: 2.85137927266972

Epoch: 5| Step: 5
Training loss: 3.458200306612782
Validation loss: 2.853579759415747

Epoch: 5| Step: 6
Training loss: 2.6556991903634843
Validation loss: 2.852712938407853

Epoch: 5| Step: 7
Training loss: 3.49653658486429
Validation loss: 2.851022196428262

Epoch: 5| Step: 8
Training loss: 3.2798424017656584
Validation loss: 2.850823862762619

Epoch: 5| Step: 9
Training loss: 3.538780487478986
Validation loss: 2.8490692337250745

Epoch: 5| Step: 10
Training loss: 2.7216018101692345
Validation loss: 2.8483646241589713

Epoch: 30| Step: 0
Training loss: 3.1565779713862474
Validation loss: 2.8489279157763425

Epoch: 5| Step: 1
Training loss: 3.3642758129507557
Validation loss: 2.852475408879992

Epoch: 5| Step: 2
Training loss: 3.3559146535976514
Validation loss: 2.8430944744442486

Epoch: 5| Step: 3
Training loss: 2.7680308766489636
Validation loss: 2.8404238980085346

Epoch: 5| Step: 4
Training loss: 3.2446224031749167
Validation loss: 2.8424603498103695

Epoch: 5| Step: 5
Training loss: 2.957386313000263
Validation loss: 2.8392177454392864

Epoch: 5| Step: 6
Training loss: 3.642923178194479
Validation loss: 2.8403700510280996

Epoch: 5| Step: 7
Training loss: 3.053820865166436
Validation loss: 2.840813964802366

Epoch: 5| Step: 8
Training loss: 2.8969499004273334
Validation loss: 2.8442501731235605

Epoch: 5| Step: 9
Training loss: 3.259558779106191
Validation loss: 2.845213199809578

Epoch: 5| Step: 10
Training loss: 2.9715742630925814
Validation loss: 2.8506477357492934

Epoch: 31| Step: 0
Training loss: 3.0361863674815903
Validation loss: 2.8513676348520423

Epoch: 5| Step: 1
Training loss: 3.1270383671918927
Validation loss: 2.8513922123135838

Epoch: 5| Step: 2
Training loss: 2.230734360040365
Validation loss: 2.8710277950213685

Epoch: 5| Step: 3
Training loss: 3.6864250038597057
Validation loss: 2.874053550508018

Epoch: 5| Step: 4
Training loss: 2.855979028448476
Validation loss: 2.8477821346467693

Epoch: 5| Step: 5
Training loss: 3.154884722941754
Validation loss: 2.83853628145452

Epoch: 5| Step: 6
Training loss: 3.4087783808937813
Validation loss: 2.840964240977284

Epoch: 5| Step: 7
Training loss: 2.608750137160937
Validation loss: 2.8430180194101853

Epoch: 5| Step: 8
Training loss: 3.7016192887967145
Validation loss: 2.839311775957143

Epoch: 5| Step: 9
Training loss: 3.2692535537685243
Validation loss: 2.8369496615429473

Epoch: 5| Step: 10
Training loss: 3.3665259611986236
Validation loss: 2.8303653027228965

Epoch: 32| Step: 0
Training loss: 3.0654835084077394
Validation loss: 2.8331292562683354

Epoch: 5| Step: 1
Training loss: 3.287841860325819
Validation loss: 2.8473907787639976

Epoch: 5| Step: 2
Training loss: 3.123080159785887
Validation loss: 2.8398371301996357

Epoch: 5| Step: 3
Training loss: 3.024183550910422
Validation loss: 2.8310999479686707

Epoch: 5| Step: 4
Training loss: 2.862487932871075
Validation loss: 2.8311815557039424

Epoch: 5| Step: 5
Training loss: 3.4473204005917317
Validation loss: 2.8250680856270796

Epoch: 5| Step: 6
Training loss: 3.5302279183182264
Validation loss: 2.825664738475692

Epoch: 5| Step: 7
Training loss: 3.2280166711199496
Validation loss: 2.826567521082852

Epoch: 5| Step: 8
Training loss: 3.1429672995992335
Validation loss: 2.8289646263628887

Epoch: 5| Step: 9
Training loss: 2.9250766124636356
Validation loss: 2.82939983726835

Epoch: 5| Step: 10
Training loss: 2.85087196663649
Validation loss: 2.8363804127959695

Epoch: 33| Step: 0
Training loss: 2.984185337610824
Validation loss: 2.8371462579190037

Epoch: 5| Step: 1
Training loss: 2.7345133719173997
Validation loss: 2.8287982845159996

Epoch: 5| Step: 2
Training loss: 3.50235478341796
Validation loss: 2.8274074676008083

Epoch: 5| Step: 3
Training loss: 2.8974331249191767
Validation loss: 2.8251427233527853

Epoch: 5| Step: 4
Training loss: 3.30668316547318
Validation loss: 2.828671562279662

Epoch: 5| Step: 5
Training loss: 3.159212440662903
Validation loss: 2.8301060614326654

Epoch: 5| Step: 6
Training loss: 3.0811962935465886
Validation loss: 2.8191992481351202

Epoch: 5| Step: 7
Training loss: 3.148136247558374
Validation loss: 2.8202500015836294

Epoch: 5| Step: 8
Training loss: 2.63543253857403
Validation loss: 2.819482573007532

Epoch: 5| Step: 9
Training loss: 3.406871074085706
Validation loss: 2.8162885874026995

Epoch: 5| Step: 10
Training loss: 3.509640088009493
Validation loss: 2.818679444488877

Epoch: 34| Step: 0
Training loss: 3.180166447439953
Validation loss: 2.8178042910524455

Epoch: 5| Step: 1
Training loss: 2.9098526149799686
Validation loss: 2.8157643105196595

Epoch: 5| Step: 2
Training loss: 3.698826093287408
Validation loss: 2.814361761840646

Epoch: 5| Step: 3
Training loss: 2.6216418266049226
Validation loss: 2.8106560526866318

Epoch: 5| Step: 4
Training loss: 3.53170989426109
Validation loss: 2.8123263488904184

Epoch: 5| Step: 5
Training loss: 3.3441987494127394
Validation loss: 2.8125771952874183

Epoch: 5| Step: 6
Training loss: 3.1730445246609693
Validation loss: 2.823340621865999

Epoch: 5| Step: 7
Training loss: 2.643697091513327
Validation loss: 2.830072357414853

Epoch: 5| Step: 8
Training loss: 2.9419833120032255
Validation loss: 2.834623723972998

Epoch: 5| Step: 9
Training loss: 3.1805475744807143
Validation loss: 2.8193039533699764

Epoch: 5| Step: 10
Training loss: 2.9745345128157665
Validation loss: 2.809420563524081

Epoch: 35| Step: 0
Training loss: 3.475850304509023
Validation loss: 2.814938527898659

Epoch: 5| Step: 1
Training loss: 2.3439971793486514
Validation loss: 2.807016359675841

Epoch: 5| Step: 2
Training loss: 3.1318928802899437
Validation loss: 2.803673824638826

Epoch: 5| Step: 3
Training loss: 3.267426354440059
Validation loss: 2.8037165224913756

Epoch: 5| Step: 4
Training loss: 3.436174032926462
Validation loss: 2.8045041015215437

Epoch: 5| Step: 5
Training loss: 2.9427936012720126
Validation loss: 2.8001824856767006

Epoch: 5| Step: 6
Training loss: 3.159834082629741
Validation loss: 2.8010732288867666

Epoch: 5| Step: 7
Training loss: 3.179248076496891
Validation loss: 2.7989214378168064

Epoch: 5| Step: 8
Training loss: 2.9304774325676157
Validation loss: 2.797992338518004

Epoch: 5| Step: 9
Training loss: 3.3290747778238288
Validation loss: 2.796378592039455

Epoch: 5| Step: 10
Training loss: 2.8944811694385533
Validation loss: 2.798139438366285

Epoch: 36| Step: 0
Training loss: 3.212306118469235
Validation loss: 2.7952624913493485

Epoch: 5| Step: 1
Training loss: 3.201465455907443
Validation loss: 2.7944677124691655

Epoch: 5| Step: 2
Training loss: 2.9468051356006133
Validation loss: 2.7946249162156076

Epoch: 5| Step: 3
Training loss: 3.5363503141390735
Validation loss: 2.793253214690541

Epoch: 5| Step: 4
Training loss: 3.308667250788515
Validation loss: 2.7909815178151907

Epoch: 5| Step: 5
Training loss: 3.219491521362951
Validation loss: 2.792793694455903

Epoch: 5| Step: 6
Training loss: 3.5983860795674096
Validation loss: 2.7910015236420183

Epoch: 5| Step: 7
Training loss: 2.645327922778339
Validation loss: 2.7902581915633182

Epoch: 5| Step: 8
Training loss: 2.8307050033048062
Validation loss: 2.7904252837114982

Epoch: 5| Step: 9
Training loss: 2.785403461372688
Validation loss: 2.789384543379644

Epoch: 5| Step: 10
Training loss: 2.640526583490982
Validation loss: 2.7929464369006696

Epoch: 37| Step: 0
Training loss: 3.4814936609107754
Validation loss: 2.808026641850201

Epoch: 5| Step: 1
Training loss: 3.29799108913275
Validation loss: 2.81006734414436

Epoch: 5| Step: 2
Training loss: 2.359520408747433
Validation loss: 2.8006456002198648

Epoch: 5| Step: 3
Training loss: 3.01654402411539
Validation loss: 2.7971992380353576

Epoch: 5| Step: 4
Training loss: 3.0744847494017917
Validation loss: 2.795524326487581

Epoch: 5| Step: 5
Training loss: 2.9897781113675315
Validation loss: 2.810277285227462

Epoch: 5| Step: 6
Training loss: 2.5461084815480253
Validation loss: 2.81262485313619

Epoch: 5| Step: 7
Training loss: 3.176660394919236
Validation loss: 2.8128115974740346

Epoch: 5| Step: 8
Training loss: 3.4680059511338226
Validation loss: 2.7888303320964276

Epoch: 5| Step: 9
Training loss: 3.4419532367160706
Validation loss: 2.7815502705655604

Epoch: 5| Step: 10
Training loss: 3.0390284519200526
Validation loss: 2.7833416972612794

Epoch: 38| Step: 0
Training loss: 3.5321058738366973
Validation loss: 2.7794019968779935

Epoch: 5| Step: 1
Training loss: 2.612140492065246
Validation loss: 2.7819398653759295

Epoch: 5| Step: 2
Training loss: 2.900962531735746
Validation loss: 2.786632672156645

Epoch: 5| Step: 3
Training loss: 2.670908256666137
Validation loss: 2.7860142265457584

Epoch: 5| Step: 4
Training loss: 3.506283433180202
Validation loss: 2.796740991312035

Epoch: 5| Step: 5
Training loss: 3.123483824088228
Validation loss: 2.817545613709815

Epoch: 5| Step: 6
Training loss: 2.9486557176757406
Validation loss: 2.8140843002523397

Epoch: 5| Step: 7
Training loss: 3.645308073444189
Validation loss: 2.8010007889195783

Epoch: 5| Step: 8
Training loss: 3.1170769004991663
Validation loss: 2.7770429156679466

Epoch: 5| Step: 9
Training loss: 2.6973236099849833
Validation loss: 2.7780520802767974

Epoch: 5| Step: 10
Training loss: 3.1922542047836644
Validation loss: 2.7881004241600906

Epoch: 39| Step: 0
Training loss: 2.791441172891936
Validation loss: 2.799059144906072

Epoch: 5| Step: 1
Training loss: 2.55809843204737
Validation loss: 2.781865417669066

Epoch: 5| Step: 2
Training loss: 2.287137520842506
Validation loss: 2.7768248560848696

Epoch: 5| Step: 3
Training loss: 3.4304092794748313
Validation loss: 2.7772552700904383

Epoch: 5| Step: 4
Training loss: 3.084764165782547
Validation loss: 2.777976376670338

Epoch: 5| Step: 5
Training loss: 2.9310755175490097
Validation loss: 2.7936142987526242

Epoch: 5| Step: 6
Training loss: 3.279386881535422
Validation loss: 2.812134334077957

Epoch: 5| Step: 7
Training loss: 4.110700154312766
Validation loss: 2.791304038722054

Epoch: 5| Step: 8
Training loss: 2.930878989484379
Validation loss: 2.777556808734123

Epoch: 5| Step: 9
Training loss: 3.2668939342720025
Validation loss: 2.7748358591763185

Epoch: 5| Step: 10
Training loss: 3.0965240064047963
Validation loss: 2.772993803719938

Epoch: 40| Step: 0
Training loss: 2.7826808720536675
Validation loss: 2.7725445846878127

Epoch: 5| Step: 1
Training loss: 2.5491820575623185
Validation loss: 2.775079785668622

Epoch: 5| Step: 2
Training loss: 3.2308395154525047
Validation loss: 2.7737529865795176

Epoch: 5| Step: 3
Training loss: 2.7291294901016836
Validation loss: 2.778779864364292

Epoch: 5| Step: 4
Training loss: 2.9034592550002793
Validation loss: 2.779061542614965

Epoch: 5| Step: 5
Training loss: 2.8709387912583324
Validation loss: 2.7883383872371277

Epoch: 5| Step: 6
Training loss: 3.566439006943282
Validation loss: 2.7872173042003

Epoch: 5| Step: 7
Training loss: 2.895282683859731
Validation loss: 2.7840374754506345

Epoch: 5| Step: 8
Training loss: 2.8497064271941075
Validation loss: 2.7714343085792867

Epoch: 5| Step: 9
Training loss: 3.9623456329217275
Validation loss: 2.771767802802169

Epoch: 5| Step: 10
Training loss: 3.4108002394328856
Validation loss: 2.7686077209417834

Epoch: 41| Step: 0
Training loss: 2.81529690167703
Validation loss: 2.771656745497406

Epoch: 5| Step: 1
Training loss: 2.679895598669711
Validation loss: 2.763712059258467

Epoch: 5| Step: 2
Training loss: 2.6569468762159034
Validation loss: 2.7672689696521995

Epoch: 5| Step: 3
Training loss: 3.032851592435456
Validation loss: 2.7721758382872905

Epoch: 5| Step: 4
Training loss: 3.516797086518029
Validation loss: 2.76585078396844

Epoch: 5| Step: 5
Training loss: 3.173176014737886
Validation loss: 2.769648248008648

Epoch: 5| Step: 6
Training loss: 3.274178141198975
Validation loss: 2.765911558579647

Epoch: 5| Step: 7
Training loss: 3.122411647795821
Validation loss: 2.7696771031229823

Epoch: 5| Step: 8
Training loss: 3.2474037951402663
Validation loss: 2.771642673290339

Epoch: 5| Step: 9
Training loss: 3.4850530264061685
Validation loss: 2.7759198073130618

Epoch: 5| Step: 10
Training loss: 2.7079485595471646
Validation loss: 2.790052268249164

Epoch: 42| Step: 0
Training loss: 3.4647175487427426
Validation loss: 2.7818986376678687

Epoch: 5| Step: 1
Training loss: 3.010893118530749
Validation loss: 2.7719908473977037

Epoch: 5| Step: 2
Training loss: 2.6657776443406083
Validation loss: 2.768172757084287

Epoch: 5| Step: 3
Training loss: 3.1763396012760157
Validation loss: 2.7642601097668225

Epoch: 5| Step: 4
Training loss: 2.7306317675038003
Validation loss: 2.7620168343654177

Epoch: 5| Step: 5
Training loss: 3.338090474332825
Validation loss: 2.7590216416527205

Epoch: 5| Step: 6
Training loss: 2.7823330774133086
Validation loss: 2.756615989304454

Epoch: 5| Step: 7
Training loss: 3.4226887053357355
Validation loss: 2.757090693495496

Epoch: 5| Step: 8
Training loss: 2.865480502114018
Validation loss: 2.754125703439968

Epoch: 5| Step: 9
Training loss: 2.8748032875765155
Validation loss: 2.7543996536037363

Epoch: 5| Step: 10
Training loss: 3.3564406243148084
Validation loss: 2.7509023038166074

Epoch: 43| Step: 0
Training loss: 3.6688068963859015
Validation loss: 2.751770340908334

Epoch: 5| Step: 1
Training loss: 2.7156239218759097
Validation loss: 2.751665343842439

Epoch: 5| Step: 2
Training loss: 2.6663143898816015
Validation loss: 2.751050051312289

Epoch: 5| Step: 3
Training loss: 3.238707805374883
Validation loss: 2.7652702643998177

Epoch: 5| Step: 4
Training loss: 2.8099558873633983
Validation loss: 2.783650316380503

Epoch: 5| Step: 5
Training loss: 3.2114480162702392
Validation loss: 2.7795755254751437

Epoch: 5| Step: 6
Training loss: 3.021695051387804
Validation loss: 2.779958057358652

Epoch: 5| Step: 7
Training loss: 3.3283740026605955
Validation loss: 2.7719748337929464

Epoch: 5| Step: 8
Training loss: 2.8629899650928166
Validation loss: 2.7645364413542617

Epoch: 5| Step: 9
Training loss: 2.7649067953725255
Validation loss: 2.751642665068055

Epoch: 5| Step: 10
Training loss: 3.3071021959394007
Validation loss: 2.7481510569317416

Epoch: 44| Step: 0
Training loss: 3.175492051811524
Validation loss: 2.7420958961864836

Epoch: 5| Step: 1
Training loss: 3.0024996516269606
Validation loss: 2.739637195536947

Epoch: 5| Step: 2
Training loss: 2.98728377704965
Validation loss: 2.7412033734144408

Epoch: 5| Step: 3
Training loss: 2.4689874655558746
Validation loss: 2.74153584053666

Epoch: 5| Step: 4
Training loss: 3.0924559690136393
Validation loss: 2.741126480980849

Epoch: 5| Step: 5
Training loss: 3.0887637559745755
Validation loss: 2.735614979474845

Epoch: 5| Step: 6
Training loss: 3.225204958058383
Validation loss: 2.7421651298873297

Epoch: 5| Step: 7
Training loss: 3.471106338907441
Validation loss: 2.7645936895473358

Epoch: 5| Step: 8
Training loss: 2.8523535062465815
Validation loss: 2.793707946305201

Epoch: 5| Step: 9
Training loss: 3.6232821899660257
Validation loss: 2.827703942832649

Epoch: 5| Step: 10
Training loss: 2.335796849535988
Validation loss: 2.809202757636544

Epoch: 45| Step: 0
Training loss: 2.8833118202715227
Validation loss: 2.7501468936174227

Epoch: 5| Step: 1
Training loss: 3.3113816010707913
Validation loss: 2.7305787926473046

Epoch: 5| Step: 2
Training loss: 3.281789680785643
Validation loss: 2.728575375575007

Epoch: 5| Step: 3
Training loss: 2.705350279630726
Validation loss: 2.740704695327596

Epoch: 5| Step: 4
Training loss: 3.085664761236676
Validation loss: 2.7537649304149037

Epoch: 5| Step: 5
Training loss: 2.7902986581300757
Validation loss: 2.7398565343213064

Epoch: 5| Step: 6
Training loss: 3.509801627745575
Validation loss: 2.7293953072190837

Epoch: 5| Step: 7
Training loss: 3.113894757520409
Validation loss: 2.7289327355094386

Epoch: 5| Step: 8
Training loss: 2.9749357328766104
Validation loss: 2.7249171759700466

Epoch: 5| Step: 9
Training loss: 2.7628721340385316
Validation loss: 2.730058357326922

Epoch: 5| Step: 10
Training loss: 3.1926734677641457
Validation loss: 2.738139999398038

Epoch: 46| Step: 0
Training loss: 3.6808608466316173
Validation loss: 2.749605332297963

Epoch: 5| Step: 1
Training loss: 3.039038336885786
Validation loss: 2.729846050359035

Epoch: 5| Step: 2
Training loss: 2.4375737496981063
Validation loss: 2.7317981199916703

Epoch: 5| Step: 3
Training loss: 3.217955111525405
Validation loss: 2.735714538889134

Epoch: 5| Step: 4
Training loss: 3.681608374983087
Validation loss: 2.7336318423929433

Epoch: 5| Step: 5
Training loss: 3.0451993589488007
Validation loss: 2.7388766527653123

Epoch: 5| Step: 6
Training loss: 2.926397403881075
Validation loss: 2.7321794593474666

Epoch: 5| Step: 7
Training loss: 2.9481705375423277
Validation loss: 2.7228858634247777

Epoch: 5| Step: 8
Training loss: 2.9217597816312035
Validation loss: 2.7206162518472294

Epoch: 5| Step: 9
Training loss: 2.992837939768176
Validation loss: 2.7206352598856514

Epoch: 5| Step: 10
Training loss: 2.156960301266914
Validation loss: 2.720685162421756

Epoch: 47| Step: 0
Training loss: 3.595993270647077
Validation loss: 2.7224775312081806

Epoch: 5| Step: 1
Training loss: 2.8235106365313576
Validation loss: 2.72222381056281

Epoch: 5| Step: 2
Training loss: 2.76038022767014
Validation loss: 2.7208763504214506

Epoch: 5| Step: 3
Training loss: 2.896821180582348
Validation loss: 2.722684545736714

Epoch: 5| Step: 4
Training loss: 3.2129443503296833
Validation loss: 2.722170236046629

Epoch: 5| Step: 5
Training loss: 2.8877294936364746
Validation loss: 2.7277939090104613

Epoch: 5| Step: 6
Training loss: 2.821047362223766
Validation loss: 2.7190760104791365

Epoch: 5| Step: 7
Training loss: 2.6757943480233712
Validation loss: 2.71993828042206

Epoch: 5| Step: 8
Training loss: 3.2869004779879276
Validation loss: 2.7180648145863913

Epoch: 5| Step: 9
Training loss: 3.274995637847092
Validation loss: 2.7179371183523875

Epoch: 5| Step: 10
Training loss: 3.2674078204367554
Validation loss: 2.715409635696707

Epoch: 48| Step: 0
Training loss: 2.8730377466820487
Validation loss: 2.714394998042788

Epoch: 5| Step: 1
Training loss: 2.700528524026738
Validation loss: 2.7139558541948285

Epoch: 5| Step: 2
Training loss: 3.8929082459661477
Validation loss: 2.7111313280626836

Epoch: 5| Step: 3
Training loss: 2.923984520856848
Validation loss: 2.709817886190939

Epoch: 5| Step: 4
Training loss: 3.3125267747480702
Validation loss: 2.7090328815003795

Epoch: 5| Step: 5
Training loss: 2.807992841716891
Validation loss: 2.7115734801567015

Epoch: 5| Step: 6
Training loss: 2.426640799021224
Validation loss: 2.7125310325293444

Epoch: 5| Step: 7
Training loss: 3.4204926507383235
Validation loss: 2.730703230529454

Epoch: 5| Step: 8
Training loss: 3.1173670819785904
Validation loss: 2.753071418711889

Epoch: 5| Step: 9
Training loss: 2.8779754169042473
Validation loss: 2.7315050252685324

Epoch: 5| Step: 10
Training loss: 2.895135772631013
Validation loss: 2.7076260958243603

Epoch: 49| Step: 0
Training loss: 3.028231661623655
Validation loss: 2.706357242278457

Epoch: 5| Step: 1
Training loss: 3.2107386469466155
Validation loss: 2.707495006530579

Epoch: 5| Step: 2
Training loss: 3.223277343084882
Validation loss: 2.709380948860356

Epoch: 5| Step: 3
Training loss: 3.483144500091908
Validation loss: 2.710135494198777

Epoch: 5| Step: 4
Training loss: 3.3708529955491295
Validation loss: 2.7112571483176233

Epoch: 5| Step: 5
Training loss: 2.92644726413833
Validation loss: 2.715608345274356

Epoch: 5| Step: 6
Training loss: 2.881157459419606
Validation loss: 2.7177671344482612

Epoch: 5| Step: 7
Training loss: 2.965185495013158
Validation loss: 2.712934893400745

Epoch: 5| Step: 8
Training loss: 2.9936991326902427
Validation loss: 2.70976141170992

Epoch: 5| Step: 9
Training loss: 2.5664723937918565
Validation loss: 2.708486686763311

Epoch: 5| Step: 10
Training loss: 2.729149320901586
Validation loss: 2.7086881898896316

Epoch: 50| Step: 0
Training loss: 3.270793857862694
Validation loss: 2.7076969721167936

Epoch: 5| Step: 1
Training loss: 2.160920985580086
Validation loss: 2.7048387322545784

Epoch: 5| Step: 2
Training loss: 3.638807637194884
Validation loss: 2.706046451982049

Epoch: 5| Step: 3
Training loss: 3.2892350176511824
Validation loss: 2.7025580028775877

Epoch: 5| Step: 4
Training loss: 3.374694810420131
Validation loss: 2.7045752012540185

Epoch: 5| Step: 5
Training loss: 2.4783374671243115
Validation loss: 2.702700692886685

Epoch: 5| Step: 6
Training loss: 2.3696950592359114
Validation loss: 2.698475348972198

Epoch: 5| Step: 7
Training loss: 2.9839670591504883
Validation loss: 2.700917711473006

Epoch: 5| Step: 8
Training loss: 3.3452170888024324
Validation loss: 2.7000369290477773

Epoch: 5| Step: 9
Training loss: 2.810397994476871
Validation loss: 2.702046168810024

Epoch: 5| Step: 10
Training loss: 3.303724071849815
Validation loss: 2.7210342190100065

Epoch: 51| Step: 0
Training loss: 2.518018827493709
Validation loss: 2.722022145354807

Epoch: 5| Step: 1
Training loss: 3.151188483903174
Validation loss: 2.7386745634837517

Epoch: 5| Step: 2
Training loss: 3.265083377585548
Validation loss: 2.7200017349975356

Epoch: 5| Step: 3
Training loss: 3.475424728234806
Validation loss: 2.6964950252585864

Epoch: 5| Step: 4
Training loss: 2.821940113554163
Validation loss: 2.6938830555777096

Epoch: 5| Step: 5
Training loss: 2.899099433764815
Validation loss: 2.693760580822432

Epoch: 5| Step: 6
Training loss: 3.663503120197161
Validation loss: 2.6981591737169355

Epoch: 5| Step: 7
Training loss: 2.8415146310655466
Validation loss: 2.6976970114884655

Epoch: 5| Step: 8
Training loss: 2.522137475328815
Validation loss: 2.697565508587445

Epoch: 5| Step: 9
Training loss: 2.781802690432248
Validation loss: 2.6965555480964998

Epoch: 5| Step: 10
Training loss: 3.2023689680369887
Validation loss: 2.6958491317418734

Epoch: 52| Step: 0
Training loss: 3.216013217101765
Validation loss: 2.695181873800865

Epoch: 5| Step: 1
Training loss: 2.9251806154484896
Validation loss: 2.696539410707309

Epoch: 5| Step: 2
Training loss: 3.355479834363968
Validation loss: 2.699385841900838

Epoch: 5| Step: 3
Training loss: 2.8032857213038618
Validation loss: 2.6982404877435577

Epoch: 5| Step: 4
Training loss: 3.4345721173491848
Validation loss: 2.693280733032073

Epoch: 5| Step: 5
Training loss: 3.1020252257353795
Validation loss: 2.6936088048586626

Epoch: 5| Step: 6
Training loss: 3.18743836586398
Validation loss: 2.687533818857523

Epoch: 5| Step: 7
Training loss: 2.836110175474359
Validation loss: 2.6891616478773526

Epoch: 5| Step: 8
Training loss: 2.628292652638556
Validation loss: 2.690642503502319

Epoch: 5| Step: 9
Training loss: 2.6868917087302493
Validation loss: 2.6885595095685306

Epoch: 5| Step: 10
Training loss: 2.941096275582643
Validation loss: 2.690728561761566

Epoch: 53| Step: 0
Training loss: 3.3026081875472455
Validation loss: 2.692627894153191

Epoch: 5| Step: 1
Training loss: 2.9581825504471526
Validation loss: 2.6947499115339797

Epoch: 5| Step: 2
Training loss: 2.9627718515044967
Validation loss: 2.699183795338685

Epoch: 5| Step: 3
Training loss: 3.4929232579670804
Validation loss: 2.696558421138696

Epoch: 5| Step: 4
Training loss: 2.6611058449034943
Validation loss: 2.698701001826288

Epoch: 5| Step: 5
Training loss: 3.1693643489802357
Validation loss: 2.6953066884804935

Epoch: 5| Step: 6
Training loss: 3.235410220566956
Validation loss: 2.6929041030718994

Epoch: 5| Step: 7
Training loss: 2.530533865891413
Validation loss: 2.681635964988133

Epoch: 5| Step: 8
Training loss: 2.9035142717649545
Validation loss: 2.679086006884668

Epoch: 5| Step: 9
Training loss: 3.416337222211698
Validation loss: 2.679404043398369

Epoch: 5| Step: 10
Training loss: 2.172096735112083
Validation loss: 2.6792041136049995

Epoch: 54| Step: 0
Training loss: 2.985396764510998
Validation loss: 2.675025639120259

Epoch: 5| Step: 1
Training loss: 2.966396322326685
Validation loss: 2.677454487974959

Epoch: 5| Step: 2
Training loss: 3.129469612448221
Validation loss: 2.6777376033228286

Epoch: 5| Step: 3
Training loss: 3.366442958713975
Validation loss: 2.6749038257700715

Epoch: 5| Step: 4
Training loss: 3.083571828605257
Validation loss: 2.6761424017994067

Epoch: 5| Step: 5
Training loss: 2.790906707795413
Validation loss: 2.6756936810102077

Epoch: 5| Step: 6
Training loss: 3.1062885857685814
Validation loss: 2.679314030431423

Epoch: 5| Step: 7
Training loss: 2.806632979667301
Validation loss: 2.686933682434502

Epoch: 5| Step: 8
Training loss: 3.2313659233977194
Validation loss: 2.6942064971469843

Epoch: 5| Step: 9
Training loss: 2.5295573096794786
Validation loss: 2.705855424132524

Epoch: 5| Step: 10
Training loss: 3.0477952398873165
Validation loss: 2.7093764259775655

Epoch: 55| Step: 0
Training loss: 2.975814444991984
Validation loss: 2.7023079105649046

Epoch: 5| Step: 1
Training loss: 3.4145825860653227
Validation loss: 2.6748296068319974

Epoch: 5| Step: 2
Training loss: 2.6046128361280583
Validation loss: 2.6726895011795033

Epoch: 5| Step: 3
Training loss: 3.1736301019955038
Validation loss: 2.6729121008551617

Epoch: 5| Step: 4
Training loss: 3.127056208286822
Validation loss: 2.683331296789178

Epoch: 5| Step: 5
Training loss: 2.6716334362029803
Validation loss: 2.7142345520176616

Epoch: 5| Step: 6
Training loss: 2.898705811947171
Validation loss: 2.702102534145208

Epoch: 5| Step: 7
Training loss: 2.9095614036561437
Validation loss: 2.6805732406680893

Epoch: 5| Step: 8
Training loss: 2.468096876063869
Validation loss: 2.6744792618833237

Epoch: 5| Step: 9
Training loss: 3.5263377093063113
Validation loss: 2.6728360435589247

Epoch: 5| Step: 10
Training loss: 3.328522421162085
Validation loss: 2.6709801111310907

Epoch: 56| Step: 0
Training loss: 2.832041183980422
Validation loss: 2.6678768843537086

Epoch: 5| Step: 1
Training loss: 2.828932504603209
Validation loss: 2.672242645989387

Epoch: 5| Step: 2
Training loss: 3.170426662865643
Validation loss: 2.6937381321283227

Epoch: 5| Step: 3
Training loss: 2.8950728554526752
Validation loss: 2.7211819941608675

Epoch: 5| Step: 4
Training loss: 2.485818887179023
Validation loss: 2.76872479686499

Epoch: 5| Step: 5
Training loss: 3.1098721360787147
Validation loss: 2.7417844883978297

Epoch: 5| Step: 6
Training loss: 2.988856441017569
Validation loss: 2.6871796512673862

Epoch: 5| Step: 7
Training loss: 3.126697231975673
Validation loss: 2.667322074105265

Epoch: 5| Step: 8
Training loss: 3.3934837279002
Validation loss: 2.6722635014182097

Epoch: 5| Step: 9
Training loss: 3.214461645730899
Validation loss: 2.673093218576991

Epoch: 5| Step: 10
Training loss: 2.9784463042650504
Validation loss: 2.682575781772955

Epoch: 57| Step: 0
Training loss: 2.5921005151650647
Validation loss: 2.6954101126319405

Epoch: 5| Step: 1
Training loss: 3.225708338106801
Validation loss: 2.7221065372418534

Epoch: 5| Step: 2
Training loss: 3.4131989598150043
Validation loss: 2.6776470039238576

Epoch: 5| Step: 3
Training loss: 2.8448055111019617
Validation loss: 2.673525899115054

Epoch: 5| Step: 4
Training loss: 2.882371491398829
Validation loss: 2.6763667478710103

Epoch: 5| Step: 5
Training loss: 3.1489234719642836
Validation loss: 2.7697054220140815

Epoch: 5| Step: 6
Training loss: 3.291681909324668
Validation loss: 2.841503163963506

Epoch: 5| Step: 7
Training loss: 3.1599590301272134
Validation loss: 2.7707501723634858

Epoch: 5| Step: 8
Training loss: 3.0777136823159723
Validation loss: 2.746111717218439

Epoch: 5| Step: 9
Training loss: 2.532500535036654
Validation loss: 2.695445617460752

Epoch: 5| Step: 10
Training loss: 3.255639684962201
Validation loss: 2.6941469625447345

Epoch: 58| Step: 0
Training loss: 3.1173623401683517
Validation loss: 2.6871887526649174

Epoch: 5| Step: 1
Training loss: 3.0294830835641045
Validation loss: 2.6841319825222225

Epoch: 5| Step: 2
Training loss: 2.929364239978338
Validation loss: 2.6834201107261992

Epoch: 5| Step: 3
Training loss: 3.0696505155668334
Validation loss: 2.714062649205357

Epoch: 5| Step: 4
Training loss: 2.831251239565816
Validation loss: 2.704399137220093

Epoch: 5| Step: 5
Training loss: 2.870418380919157
Validation loss: 2.687357676258129

Epoch: 5| Step: 6
Training loss: 2.8620991055478893
Validation loss: 2.678279477492589

Epoch: 5| Step: 7
Training loss: 3.479528229403916
Validation loss: 2.6662309281631122

Epoch: 5| Step: 8
Training loss: 2.67070115387707
Validation loss: 2.661299721709627

Epoch: 5| Step: 9
Training loss: 3.0931463712338205
Validation loss: 2.6586492841433977

Epoch: 5| Step: 10
Training loss: 3.3022167447613615
Validation loss: 2.657728114247425

Epoch: 59| Step: 0
Training loss: 2.635939012311084
Validation loss: 2.659565820426383

Epoch: 5| Step: 1
Training loss: 3.1852471861444003
Validation loss: 2.6589339650487034

Epoch: 5| Step: 2
Training loss: 2.809210824890008
Validation loss: 2.6607799299143062

Epoch: 5| Step: 3
Training loss: 2.7060488725239757
Validation loss: 2.6631984717526023

Epoch: 5| Step: 4
Training loss: 3.137367039025086
Validation loss: 2.664556289911869

Epoch: 5| Step: 5
Training loss: 3.0747494851389607
Validation loss: 2.6666414214164655

Epoch: 5| Step: 6
Training loss: 2.749834055662123
Validation loss: 2.669185313914002

Epoch: 5| Step: 7
Training loss: 3.5432684623351927
Validation loss: 2.660357248938172

Epoch: 5| Step: 8
Training loss: 2.9826102106750794
Validation loss: 2.6606618532556108

Epoch: 5| Step: 9
Training loss: 2.907441910010071
Validation loss: 2.6601732133113054

Epoch: 5| Step: 10
Training loss: 3.1260200361609156
Validation loss: 2.6514824719300267

Epoch: 60| Step: 0
Training loss: 3.157836062321251
Validation loss: 2.649590395737481

Epoch: 5| Step: 1
Training loss: 3.4863045998856146
Validation loss: 2.653827600671151

Epoch: 5| Step: 2
Training loss: 3.505804153900062
Validation loss: 2.6499500573332297

Epoch: 5| Step: 3
Training loss: 2.8950161958811322
Validation loss: 2.652016028368219

Epoch: 5| Step: 4
Training loss: 3.279722893802438
Validation loss: 2.655491716220487

Epoch: 5| Step: 5
Training loss: 2.921237814881519
Validation loss: 2.65259473550316

Epoch: 5| Step: 6
Training loss: 3.384247578963486
Validation loss: 2.6535027732778285

Epoch: 5| Step: 7
Training loss: 2.647461747999922
Validation loss: 2.653816367810211

Epoch: 5| Step: 8
Training loss: 2.297760254374784
Validation loss: 2.658673596028457

Epoch: 5| Step: 9
Training loss: 2.2960674916492536
Validation loss: 2.6588021185375

Epoch: 5| Step: 10
Training loss: 2.6668148198298582
Validation loss: 2.6700178484189347

Epoch: 61| Step: 0
Training loss: 3.0862690807817224
Validation loss: 2.6620865534672857

Epoch: 5| Step: 1
Training loss: 2.6893855732597576
Validation loss: 2.6496105228673326

Epoch: 5| Step: 2
Training loss: 3.5649752132629478
Validation loss: 2.647891566567115

Epoch: 5| Step: 3
Training loss: 2.8981851226249993
Validation loss: 2.6462730260054887

Epoch: 5| Step: 4
Training loss: 2.4490038033670447
Validation loss: 2.6463692438636306

Epoch: 5| Step: 5
Training loss: 3.293399949989497
Validation loss: 2.6439912895220004

Epoch: 5| Step: 6
Training loss: 3.290038192898371
Validation loss: 2.6446451757661884

Epoch: 5| Step: 7
Training loss: 2.9736754666481047
Validation loss: 2.646712109666459

Epoch: 5| Step: 8
Training loss: 2.668026120642774
Validation loss: 2.6414437167672613

Epoch: 5| Step: 9
Training loss: 2.508633202997237
Validation loss: 2.645044723922907

Epoch: 5| Step: 10
Training loss: 3.286200576242254
Validation loss: 2.6434286618849345

Epoch: 62| Step: 0
Training loss: 2.705629897048195
Validation loss: 2.644000906097397

Epoch: 5| Step: 1
Training loss: 3.204753034006235
Validation loss: 2.6441028592316114

Epoch: 5| Step: 2
Training loss: 2.878971673643915
Validation loss: 2.644763262795952

Epoch: 5| Step: 3
Training loss: 3.29889027981336
Validation loss: 2.649945040237574

Epoch: 5| Step: 4
Training loss: 2.659649547207064
Validation loss: 2.643657714851288

Epoch: 5| Step: 5
Training loss: 3.1211609719763382
Validation loss: 2.6413648927592

Epoch: 5| Step: 6
Training loss: 2.7876501273881287
Validation loss: 2.6409988745422854

Epoch: 5| Step: 7
Training loss: 2.4929972800902926
Validation loss: 2.63894286936147

Epoch: 5| Step: 8
Training loss: 3.1396352242626313
Validation loss: 2.6409952586498306

Epoch: 5| Step: 9
Training loss: 3.5547329742541156
Validation loss: 2.641206542713118

Epoch: 5| Step: 10
Training loss: 2.801015336005253
Validation loss: 2.6415944614352487

Epoch: 63| Step: 0
Training loss: 2.5736333386890444
Validation loss: 2.6573379421563494

Epoch: 5| Step: 1
Training loss: 3.0537860447571177
Validation loss: 2.660313909603526

Epoch: 5| Step: 2
Training loss: 2.91445879248628
Validation loss: 2.668479964984265

Epoch: 5| Step: 3
Training loss: 2.8067532638214154
Validation loss: 2.6565531915319633

Epoch: 5| Step: 4
Training loss: 2.6493169624035273
Validation loss: 2.639952173233301

Epoch: 5| Step: 5
Training loss: 3.260544763228246
Validation loss: 2.635962121008224

Epoch: 5| Step: 6
Training loss: 2.994670266164834
Validation loss: 2.6338394307870328

Epoch: 5| Step: 7
Training loss: 2.90262336462218
Validation loss: 2.6331686730369994

Epoch: 5| Step: 8
Training loss: 3.1509684572569
Validation loss: 2.6396987473991405

Epoch: 5| Step: 9
Training loss: 3.1114835251328024
Validation loss: 2.6415015858640536

Epoch: 5| Step: 10
Training loss: 3.344900200784838
Validation loss: 2.639849530529725

Epoch: 64| Step: 0
Training loss: 3.013789750054197
Validation loss: 2.6343302859714877

Epoch: 5| Step: 1
Training loss: 2.877086048461016
Validation loss: 2.6353135032619455

Epoch: 5| Step: 2
Training loss: 3.0510280377435355
Validation loss: 2.632015035076593

Epoch: 5| Step: 3
Training loss: 3.225694886093374
Validation loss: 2.630363282560001

Epoch: 5| Step: 4
Training loss: 2.8156232658152263
Validation loss: 2.632702184156244

Epoch: 5| Step: 5
Training loss: 3.225886461127082
Validation loss: 2.6304635870215716

Epoch: 5| Step: 6
Training loss: 3.5090381545576848
Validation loss: 2.6295683740250295

Epoch: 5| Step: 7
Training loss: 2.329349682145518
Validation loss: 2.629537752323628

Epoch: 5| Step: 8
Training loss: 2.8061820380938243
Validation loss: 2.6257349524576346

Epoch: 5| Step: 9
Training loss: 2.924345389907399
Validation loss: 2.6284764206381626

Epoch: 5| Step: 10
Training loss: 2.724267731716592
Validation loss: 2.630054908906661

Epoch: 65| Step: 0
Training loss: 2.9107483536701615
Validation loss: 2.6330430188035057

Epoch: 5| Step: 1
Training loss: 2.882984187278293
Validation loss: 2.6451879606795745

Epoch: 5| Step: 2
Training loss: 3.3011484517458265
Validation loss: 2.6446648064124108

Epoch: 5| Step: 3
Training loss: 2.4766817756113246
Validation loss: 2.637478774389245

Epoch: 5| Step: 4
Training loss: 3.1117086423287854
Validation loss: 2.6327342676624954

Epoch: 5| Step: 5
Training loss: 3.099024120669002
Validation loss: 2.63426134404444

Epoch: 5| Step: 6
Training loss: 2.5442695630687613
Validation loss: 2.6268298377762465

Epoch: 5| Step: 7
Training loss: 3.1663097548540766
Validation loss: 2.631609517003843

Epoch: 5| Step: 8
Training loss: 2.9563834162279354
Validation loss: 2.624437266952389

Epoch: 5| Step: 9
Training loss: 2.857671845375968
Validation loss: 2.6274396143441474

Epoch: 5| Step: 10
Training loss: 3.331451186641066
Validation loss: 2.6250714508661184

Epoch: 66| Step: 0
Training loss: 3.154815952355589
Validation loss: 2.6264435314378645

Epoch: 5| Step: 1
Training loss: 2.6784216557364466
Validation loss: 2.6262827267151754

Epoch: 5| Step: 2
Training loss: 2.617275498462299
Validation loss: 2.6242752041427333

Epoch: 5| Step: 3
Training loss: 3.3156113317784954
Validation loss: 2.6278746403402824

Epoch: 5| Step: 4
Training loss: 2.8806678630729556
Validation loss: 2.626289303016029

Epoch: 5| Step: 5
Training loss: 2.9471695203640214
Validation loss: 2.642066885680298

Epoch: 5| Step: 6
Training loss: 3.253995639997397
Validation loss: 2.6455209547813325

Epoch: 5| Step: 7
Training loss: 2.725927677961184
Validation loss: 2.644141364421573

Epoch: 5| Step: 8
Training loss: 2.377977311991011
Validation loss: 2.631090732363042

Epoch: 5| Step: 9
Training loss: 3.256680152289882
Validation loss: 2.629453353367846

Epoch: 5| Step: 10
Training loss: 3.392289135647783
Validation loss: 2.629506519458744

Epoch: 67| Step: 0
Training loss: 2.7728216642694568
Validation loss: 2.625614013387997

Epoch: 5| Step: 1
Training loss: 2.3008807279003918
Validation loss: 2.6277731034159255

Epoch: 5| Step: 2
Training loss: 3.143643878336296
Validation loss: 2.6301160999469917

Epoch: 5| Step: 3
Training loss: 2.8013469385467022
Validation loss: 2.622453373282631

Epoch: 5| Step: 4
Training loss: 2.714119135255283
Validation loss: 2.6217845300336866

Epoch: 5| Step: 5
Training loss: 3.2053337111491373
Validation loss: 2.624132409507867

Epoch: 5| Step: 6
Training loss: 3.4336281905980344
Validation loss: 2.6229037378647977

Epoch: 5| Step: 7
Training loss: 2.4998076364896367
Validation loss: 2.626623793131794

Epoch: 5| Step: 8
Training loss: 3.0878093981449797
Validation loss: 2.6321625329443084

Epoch: 5| Step: 9
Training loss: 3.287039454006049
Validation loss: 2.630366494950636

Epoch: 5| Step: 10
Training loss: 3.247652232865269
Validation loss: 2.6230346404766207

Epoch: 68| Step: 0
Training loss: 3.2632646563443473
Validation loss: 2.6187486351785547

Epoch: 5| Step: 1
Training loss: 2.983296304256293
Validation loss: 2.6180036540434957

Epoch: 5| Step: 2
Training loss: 3.0931187766030446
Validation loss: 2.6164434853015326

Epoch: 5| Step: 3
Training loss: 2.965362382843701
Validation loss: 2.615469586534377

Epoch: 5| Step: 4
Training loss: 3.342948175711548
Validation loss: 2.6157496747101

Epoch: 5| Step: 5
Training loss: 2.940422065697113
Validation loss: 2.615533842667173

Epoch: 5| Step: 6
Training loss: 2.8919361337070413
Validation loss: 2.6178594058260716

Epoch: 5| Step: 7
Training loss: 2.787138117406105
Validation loss: 2.6197201611766574

Epoch: 5| Step: 8
Training loss: 2.7308371190345686
Validation loss: 2.6219110728926194

Epoch: 5| Step: 9
Training loss: 2.97596490422956
Validation loss: 2.6327842568966764

Epoch: 5| Step: 10
Training loss: 2.4995524959587687
Validation loss: 2.636933242781555

Epoch: 69| Step: 0
Training loss: 2.983554587515464
Validation loss: 2.6350811088840227

Epoch: 5| Step: 1
Training loss: 3.356109025150448
Validation loss: 2.6458497124835865

Epoch: 5| Step: 2
Training loss: 3.2496011929478374
Validation loss: 2.6464935194808885

Epoch: 5| Step: 3
Training loss: 2.88181244166125
Validation loss: 2.6259688529491587

Epoch: 5| Step: 4
Training loss: 2.8030279238422864
Validation loss: 2.6158240253665874

Epoch: 5| Step: 5
Training loss: 2.6692550931637036
Validation loss: 2.608732721544797

Epoch: 5| Step: 6
Training loss: 3.282117311202424
Validation loss: 2.6104687721961595

Epoch: 5| Step: 7
Training loss: 2.911542769534414
Validation loss: 2.611226680018853

Epoch: 5| Step: 8
Training loss: 3.1088405130582566
Validation loss: 2.6109282824784144

Epoch: 5| Step: 9
Training loss: 2.471132794438665
Validation loss: 2.60697090686091

Epoch: 5| Step: 10
Training loss: 2.7050498327435175
Validation loss: 2.609266351937442

Epoch: 70| Step: 0
Training loss: 2.753287690948924
Validation loss: 2.6072876792505126

Epoch: 5| Step: 1
Training loss: 3.1997263672184912
Validation loss: 2.607388675753793

Epoch: 5| Step: 2
Training loss: 3.3006440083339763
Validation loss: 2.60823606320006

Epoch: 5| Step: 3
Training loss: 2.91366238953703
Validation loss: 2.6069292722252255

Epoch: 5| Step: 4
Training loss: 2.7332210176543823
Validation loss: 2.6085377730967965

Epoch: 5| Step: 5
Training loss: 3.168869323289608
Validation loss: 2.603793709576875

Epoch: 5| Step: 6
Training loss: 2.940585524712623
Validation loss: 2.6062162075889983

Epoch: 5| Step: 7
Training loss: 2.7552857319008686
Validation loss: 2.607844595037391

Epoch: 5| Step: 8
Training loss: 3.0059824739251098
Validation loss: 2.6068474416779557

Epoch: 5| Step: 9
Training loss: 2.856946236793188
Validation loss: 2.60775767234146

Epoch: 5| Step: 10
Training loss: 2.6994109464858833
Validation loss: 2.6066007563672686

Epoch: 71| Step: 0
Training loss: 3.1235769464948078
Validation loss: 2.602894929192506

Epoch: 5| Step: 1
Training loss: 2.9946689923357517
Validation loss: 2.602733881091711

Epoch: 5| Step: 2
Training loss: 3.108295042264036
Validation loss: 2.6009278995870533

Epoch: 5| Step: 3
Training loss: 2.456767688194161
Validation loss: 2.6055883685249523

Epoch: 5| Step: 4
Training loss: 3.3026772014196824
Validation loss: 2.606448644858012

Epoch: 5| Step: 5
Training loss: 3.224852914930697
Validation loss: 2.6048704647527607

Epoch: 5| Step: 6
Training loss: 2.7488911734112094
Validation loss: 2.6054354107433286

Epoch: 5| Step: 7
Training loss: 3.0900216804904264
Validation loss: 2.600708701377976

Epoch: 5| Step: 8
Training loss: 2.765101755073738
Validation loss: 2.5983294433595363

Epoch: 5| Step: 9
Training loss: 3.2840482859621978
Validation loss: 2.5984083879391813

Epoch: 5| Step: 10
Training loss: 1.9996773936437604
Validation loss: 2.598424005093844

Epoch: 72| Step: 0
Training loss: 2.913899353205734
Validation loss: 2.5991228376145448

Epoch: 5| Step: 1
Training loss: 3.18761084868722
Validation loss: 2.601706362915579

Epoch: 5| Step: 2
Training loss: 2.8670815596380756
Validation loss: 2.6042084235668512

Epoch: 5| Step: 3
Training loss: 2.641562120633226
Validation loss: 2.6124567465447948

Epoch: 5| Step: 4
Training loss: 2.894319719623991
Validation loss: 2.6054141660061143

Epoch: 5| Step: 5
Training loss: 3.005901413215217
Validation loss: 2.605768518480175

Epoch: 5| Step: 6
Training loss: 2.7452619657603963
Validation loss: 2.598147365601061

Epoch: 5| Step: 7
Training loss: 3.1124033533740834
Validation loss: 2.5935618429559866

Epoch: 5| Step: 8
Training loss: 2.777668994256964
Validation loss: 2.594752237049652

Epoch: 5| Step: 9
Training loss: 3.2642907150053766
Validation loss: 2.5943223677787666

Epoch: 5| Step: 10
Training loss: 2.880054177728327
Validation loss: 2.59625991102358

Epoch: 73| Step: 0
Training loss: 2.856471854844632
Validation loss: 2.595132681852476

Epoch: 5| Step: 1
Training loss: 2.7662202873306296
Validation loss: 2.5959282179651058

Epoch: 5| Step: 2
Training loss: 2.912089562044857
Validation loss: 2.5937751465364336

Epoch: 5| Step: 3
Training loss: 3.25996587559913
Validation loss: 2.590937293599284

Epoch: 5| Step: 4
Training loss: 2.627377296435498
Validation loss: 2.598538151814675

Epoch: 5| Step: 5
Training loss: 2.8648111333724984
Validation loss: 2.6030532865444345

Epoch: 5| Step: 6
Training loss: 3.111625125596143
Validation loss: 2.6159916812178916

Epoch: 5| Step: 7
Training loss: 3.176647485739837
Validation loss: 2.6027658947125056

Epoch: 5| Step: 8
Training loss: 2.612592164380582
Validation loss: 2.586386418298163

Epoch: 5| Step: 9
Training loss: 3.116120961467411
Validation loss: 2.586487434050406

Epoch: 5| Step: 10
Training loss: 3.1072424855412617
Validation loss: 2.5920011908749876

Epoch: 74| Step: 0
Training loss: 2.8443552567817942
Validation loss: 2.5949229200087145

Epoch: 5| Step: 1
Training loss: 2.3173177897272583
Validation loss: 2.5969802483870796

Epoch: 5| Step: 2
Training loss: 3.113117515250159
Validation loss: 2.605016584611448

Epoch: 5| Step: 3
Training loss: 3.063181898533918
Validation loss: 2.5976908861963444

Epoch: 5| Step: 4
Training loss: 3.228634960740653
Validation loss: 2.594132565314531

Epoch: 5| Step: 5
Training loss: 3.092585797364804
Validation loss: 2.5896157245202254

Epoch: 5| Step: 6
Training loss: 2.9171035076159892
Validation loss: 2.6029625045919014

Epoch: 5| Step: 7
Training loss: 2.9078348412083375
Validation loss: 2.633972627084164

Epoch: 5| Step: 8
Training loss: 3.2068880632335555
Validation loss: 2.6809118525626645

Epoch: 5| Step: 9
Training loss: 3.1063952713275356
Validation loss: 2.681865353291649

Epoch: 5| Step: 10
Training loss: 2.7365337460662484
Validation loss: 2.613433768203138

Epoch: 75| Step: 0
Training loss: 3.0660770312422403
Validation loss: 2.580402868250967

Epoch: 5| Step: 1
Training loss: 2.7731775296291157
Validation loss: 2.5849789536072527

Epoch: 5| Step: 2
Training loss: 3.0177315583463926
Validation loss: 2.5934613518556007

Epoch: 5| Step: 3
Training loss: 3.4560792463453502
Validation loss: 2.596812763028313

Epoch: 5| Step: 4
Training loss: 2.8890813881569724
Validation loss: 2.6033003464145734

Epoch: 5| Step: 5
Training loss: 3.420532660022952
Validation loss: 2.592501497361099

Epoch: 5| Step: 6
Training loss: 2.8128175344296027
Validation loss: 2.5875087953679285

Epoch: 5| Step: 7
Training loss: 2.593646587470433
Validation loss: 2.587620891275218

Epoch: 5| Step: 8
Training loss: 2.693745121431469
Validation loss: 2.58646756504316

Epoch: 5| Step: 9
Training loss: 3.4191418187869216
Validation loss: 2.5834979201041923

Epoch: 5| Step: 10
Training loss: 1.9225174985171116
Validation loss: 2.5816638611873652

Testing loss: 2.7990631977327585
