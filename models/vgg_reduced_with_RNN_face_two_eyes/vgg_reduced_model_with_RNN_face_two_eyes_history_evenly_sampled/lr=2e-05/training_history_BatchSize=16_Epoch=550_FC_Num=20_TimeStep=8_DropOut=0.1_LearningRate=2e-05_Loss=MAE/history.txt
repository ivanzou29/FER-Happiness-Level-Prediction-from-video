Epoch: 1| Step: 0
Training loss: 4.263916015625
Validation loss: 5.2482533557440645

Epoch: 6| Step: 1
Training loss: 4.648963928222656
Validation loss: 5.229707097494474

Epoch: 6| Step: 2
Training loss: 5.983867168426514
Validation loss: 5.21562228151547

Epoch: 6| Step: 3
Training loss: 6.276158332824707
Validation loss: 5.2031378951123965

Epoch: 6| Step: 4
Training loss: 3.8973541259765625
Validation loss: 5.190319625280237

Epoch: 6| Step: 5
Training loss: 4.613463401794434
Validation loss: 5.175785074951828

Epoch: 6| Step: 6
Training loss: 5.212737560272217
Validation loss: 5.158728794385028

Epoch: 6| Step: 7
Training loss: 5.928289413452148
Validation loss: 5.139139641997635

Epoch: 6| Step: 8
Training loss: 4.797236442565918
Validation loss: 5.116807040347848

Epoch: 6| Step: 9
Training loss: 4.481925964355469
Validation loss: 5.091460022875058

Epoch: 6| Step: 10
Training loss: 4.134251594543457
Validation loss: 5.062209703588999

Epoch: 6| Step: 11
Training loss: 5.293206214904785
Validation loss: 5.0295760298287995

Epoch: 6| Step: 12
Training loss: 4.487855434417725
Validation loss: 4.99367626251713

Epoch: 6| Step: 13
Training loss: 5.070478439331055
Validation loss: 4.953771955223494

Epoch: 2| Step: 0
Training loss: 5.860686779022217
Validation loss: 4.908433206619755

Epoch: 6| Step: 1
Training loss: 4.894020080566406
Validation loss: 4.860801712159188

Epoch: 6| Step: 2
Training loss: 4.571357727050781
Validation loss: 4.806739745601531

Epoch: 6| Step: 3
Training loss: 4.920062065124512
Validation loss: 4.7513353696433445

Epoch: 6| Step: 4
Training loss: 5.614691734313965
Validation loss: 4.692008203075778

Epoch: 6| Step: 5
Training loss: 3.6769790649414062
Validation loss: 4.6299514514143745

Epoch: 6| Step: 6
Training loss: 4.448024749755859
Validation loss: 4.567804459602602

Epoch: 6| Step: 7
Training loss: 4.591198921203613
Validation loss: 4.503154298310639

Epoch: 6| Step: 8
Training loss: 3.0855042934417725
Validation loss: 4.435218452125468

Epoch: 6| Step: 9
Training loss: 4.279198169708252
Validation loss: 4.369275654515913

Epoch: 6| Step: 10
Training loss: 3.3408102989196777
Validation loss: 4.308172800207651

Epoch: 6| Step: 11
Training loss: 3.9789586067199707
Validation loss: 4.254581174542827

Epoch: 6| Step: 12
Training loss: 3.5086770057678223
Validation loss: 4.202789204095

Epoch: 6| Step: 13
Training loss: 4.007791519165039
Validation loss: 4.154060912388627

Epoch: 3| Step: 0
Training loss: 3.529538631439209
Validation loss: 4.100856319550545

Epoch: 6| Step: 1
Training loss: 2.8577959537506104
Validation loss: 4.033430709633776

Epoch: 6| Step: 2
Training loss: 4.185295104980469
Validation loss: 3.9806668681483113

Epoch: 6| Step: 3
Training loss: 3.985285758972168
Validation loss: 3.9466058490096882

Epoch: 6| Step: 4
Training loss: 3.5650105476379395
Validation loss: 3.9119646190315165

Epoch: 6| Step: 5
Training loss: 4.221487522125244
Validation loss: 3.883863684951618

Epoch: 6| Step: 6
Training loss: 3.464834213256836
Validation loss: 3.8575066187048472

Epoch: 6| Step: 7
Training loss: 3.6992108821868896
Validation loss: 3.8385954569744807

Epoch: 6| Step: 8
Training loss: 4.701854228973389
Validation loss: 3.8185226994176067

Epoch: 6| Step: 9
Training loss: 3.915102958679199
Validation loss: 3.802112184545045

Epoch: 6| Step: 10
Training loss: 3.727766990661621
Validation loss: 3.787703339771558

Epoch: 6| Step: 11
Training loss: 3.957369089126587
Validation loss: 3.7672242759376444

Epoch: 6| Step: 12
Training loss: 3.6349334716796875
Validation loss: 3.7507731940156672

Epoch: 6| Step: 13
Training loss: 2.3055028915405273
Validation loss: 3.7322817617847073

Epoch: 4| Step: 0
Training loss: 3.3924007415771484
Validation loss: 3.718715677979172

Epoch: 6| Step: 1
Training loss: 3.9802775382995605
Validation loss: 3.709758117634763

Epoch: 6| Step: 2
Training loss: 3.671274185180664
Validation loss: 3.7005809942881265

Epoch: 6| Step: 3
Training loss: 3.5265846252441406
Validation loss: 3.689333431182369

Epoch: 6| Step: 4
Training loss: 3.4972167015075684
Validation loss: 3.6722925093866166

Epoch: 6| Step: 5
Training loss: 4.38107967376709
Validation loss: 3.661918176117764

Epoch: 6| Step: 6
Training loss: 4.377281188964844
Validation loss: 3.6503364706552155

Epoch: 6| Step: 7
Training loss: 3.106642723083496
Validation loss: 3.6423146596518894

Epoch: 6| Step: 8
Training loss: 3.2545671463012695
Validation loss: 3.633056638061359

Epoch: 6| Step: 9
Training loss: 3.7705416679382324
Validation loss: 3.62059663444437

Epoch: 6| Step: 10
Training loss: 3.017754554748535
Validation loss: 3.61297353365088

Epoch: 6| Step: 11
Training loss: 3.208683967590332
Validation loss: 3.6012620208083943

Epoch: 6| Step: 12
Training loss: 3.9368066787719727
Validation loss: 3.5917098394004245

Epoch: 6| Step: 13
Training loss: 2.187800168991089
Validation loss: 3.582211522645848

Epoch: 5| Step: 0
Training loss: 3.0205390453338623
Validation loss: 3.571461623714816

Epoch: 6| Step: 1
Training loss: 3.9168500900268555
Validation loss: 3.5624663701621433

Epoch: 6| Step: 2
Training loss: 2.8601202964782715
Validation loss: 3.5533749159946235

Epoch: 6| Step: 3
Training loss: 3.816422939300537
Validation loss: 3.544216976370863

Epoch: 6| Step: 4
Training loss: 3.7327075004577637
Validation loss: 3.535647069254229

Epoch: 6| Step: 5
Training loss: 3.6219024658203125
Validation loss: 3.5274869806023053

Epoch: 6| Step: 6
Training loss: 3.2284293174743652
Validation loss: 3.5261138510960404

Epoch: 6| Step: 7
Training loss: 3.5815694332122803
Validation loss: 3.5174788044344996

Epoch: 6| Step: 8
Training loss: 4.316181182861328
Validation loss: 3.513604474324052

Epoch: 6| Step: 9
Training loss: 3.4231390953063965
Validation loss: 3.5088936667288504

Epoch: 6| Step: 10
Training loss: 3.576694965362549
Validation loss: 3.4998143616543023

Epoch: 6| Step: 11
Training loss: 2.744187831878662
Validation loss: 3.4901852479545017

Epoch: 6| Step: 12
Training loss: 3.10807466506958
Validation loss: 3.479443227091143

Epoch: 6| Step: 13
Training loss: 3.4128832817077637
Validation loss: 3.475988559825446

Epoch: 6| Step: 0
Training loss: 3.862774610519409
Validation loss: 3.471894900004069

Epoch: 6| Step: 1
Training loss: 2.7941856384277344
Validation loss: 3.4654412115773847

Epoch: 6| Step: 2
Training loss: 4.296970844268799
Validation loss: 3.452273145798714

Epoch: 6| Step: 3
Training loss: 2.6460585594177246
Validation loss: 3.4493389462911956

Epoch: 6| Step: 4
Training loss: 3.236309051513672
Validation loss: 3.4483273721510366

Epoch: 6| Step: 5
Training loss: 3.535291910171509
Validation loss: 3.4462781413908927

Epoch: 6| Step: 6
Training loss: 3.80316162109375
Validation loss: 3.430736013638076

Epoch: 6| Step: 7
Training loss: 2.8914103507995605
Validation loss: 3.4235413946131223

Epoch: 6| Step: 8
Training loss: 4.197746753692627
Validation loss: 3.419419737272365

Epoch: 6| Step: 9
Training loss: 2.8257179260253906
Validation loss: 3.411598446548626

Epoch: 6| Step: 10
Training loss: 2.253530979156494
Validation loss: 3.411507470633394

Epoch: 6| Step: 11
Training loss: 3.1401898860931396
Validation loss: 3.399254991162208

Epoch: 6| Step: 12
Training loss: 3.441478729248047
Validation loss: 3.395633569327734

Epoch: 6| Step: 13
Training loss: 5.095992565155029
Validation loss: 3.3937045656224734

Epoch: 7| Step: 0
Training loss: 2.1059985160827637
Validation loss: 3.387962915564096

Epoch: 6| Step: 1
Training loss: 3.135305404663086
Validation loss: 3.383662974962624

Epoch: 6| Step: 2
Training loss: 2.6578381061553955
Validation loss: 3.372130601636825

Epoch: 6| Step: 3
Training loss: 3.7789933681488037
Validation loss: 3.3646234235455914

Epoch: 6| Step: 4
Training loss: 3.166501045227051
Validation loss: 3.3605129385507233

Epoch: 6| Step: 5
Training loss: 4.022284507751465
Validation loss: 3.3566624836255143

Epoch: 6| Step: 6
Training loss: 3.3358004093170166
Validation loss: 3.3485395318718365

Epoch: 6| Step: 7
Training loss: 4.233577728271484
Validation loss: 3.342168777219711

Epoch: 6| Step: 8
Training loss: 2.2958972454071045
Validation loss: 3.337524672990204

Epoch: 6| Step: 9
Training loss: 4.383373737335205
Validation loss: 3.3349382646622194

Epoch: 6| Step: 10
Training loss: 3.801401138305664
Validation loss: 3.3310077369854016

Epoch: 6| Step: 11
Training loss: 1.8158974647521973
Validation loss: 3.322242441997733

Epoch: 6| Step: 12
Training loss: 3.7183938026428223
Validation loss: 3.318094768831807

Epoch: 6| Step: 13
Training loss: 4.42069673538208
Validation loss: 3.3134581094147055

Epoch: 8| Step: 0
Training loss: 2.736685276031494
Validation loss: 3.3074669325223534

Epoch: 6| Step: 1
Training loss: 3.2233924865722656
Validation loss: 3.3046578720051754

Epoch: 6| Step: 2
Training loss: 3.2139432430267334
Validation loss: 3.299866845530848

Epoch: 6| Step: 3
Training loss: 3.2462716102600098
Validation loss: 3.2961382840269353

Epoch: 6| Step: 4
Training loss: 2.9223990440368652
Validation loss: 3.289798762208672

Epoch: 6| Step: 5
Training loss: 3.402810573577881
Validation loss: 3.2882509513567855

Epoch: 6| Step: 6
Training loss: 3.450772762298584
Validation loss: 3.2954604061700965

Epoch: 6| Step: 7
Training loss: 2.2924327850341797
Validation loss: 3.2748573057113157

Epoch: 6| Step: 8
Training loss: 4.46132755279541
Validation loss: 3.2768438323851554

Epoch: 6| Step: 9
Training loss: 3.43269681930542
Validation loss: 3.274020233461934

Epoch: 6| Step: 10
Training loss: 3.4756360054016113
Validation loss: 3.2643685289608535

Epoch: 6| Step: 11
Training loss: 3.6868691444396973
Validation loss: 3.2576972951171217

Epoch: 6| Step: 12
Training loss: 3.1588008403778076
Validation loss: 3.2545080415664183

Epoch: 6| Step: 13
Training loss: 2.6028144359588623
Validation loss: 3.2482574524418

Epoch: 9| Step: 0
Training loss: 2.826495885848999
Validation loss: 3.250633280764344

Epoch: 6| Step: 1
Training loss: 3.6636877059936523
Validation loss: 3.2510486161837013

Epoch: 6| Step: 2
Training loss: 3.225287437438965
Validation loss: 3.250436957164477

Epoch: 6| Step: 3
Training loss: 3.066537618637085
Validation loss: 3.246114735962242

Epoch: 6| Step: 4
Training loss: 3.472248077392578
Validation loss: 3.238896580152614

Epoch: 6| Step: 5
Training loss: 3.86395263671875
Validation loss: 3.2286561868524037

Epoch: 6| Step: 6
Training loss: 3.4693918228149414
Validation loss: 3.219349020270891

Epoch: 6| Step: 7
Training loss: 3.083019256591797
Validation loss: 3.2166367012967347

Epoch: 6| Step: 8
Training loss: 3.1098828315734863
Validation loss: 3.211866389038742

Epoch: 6| Step: 9
Training loss: 3.0682756900787354
Validation loss: 3.198363568193169

Epoch: 6| Step: 10
Training loss: 3.6594276428222656
Validation loss: 3.1948585151344218

Epoch: 6| Step: 11
Training loss: 3.018927812576294
Validation loss: 3.1882408793254564

Epoch: 6| Step: 12
Training loss: 3.105396270751953
Validation loss: 3.1824808146363948

Epoch: 6| Step: 13
Training loss: 1.7283689975738525
Validation loss: 3.17541213445766

Epoch: 10| Step: 0
Training loss: 3.522786855697632
Validation loss: 3.1738503184369815

Epoch: 6| Step: 1
Training loss: 2.0788729190826416
Validation loss: 3.169041992515646

Epoch: 6| Step: 2
Training loss: 4.012784957885742
Validation loss: 3.1626418687964

Epoch: 6| Step: 3
Training loss: 3.268928050994873
Validation loss: 3.1614827007375736

Epoch: 6| Step: 4
Training loss: 3.4661812782287598
Validation loss: 3.15340773008203

Epoch: 6| Step: 5
Training loss: 3.8542182445526123
Validation loss: 3.1486013268911712

Epoch: 6| Step: 6
Training loss: 2.8698086738586426
Validation loss: 3.1429934604193575

Epoch: 6| Step: 7
Training loss: 2.6478748321533203
Validation loss: 3.1390333996024182

Epoch: 6| Step: 8
Training loss: 3.368690252304077
Validation loss: 3.1385047794670187

Epoch: 6| Step: 9
Training loss: 3.8935890197753906
Validation loss: 3.1330806260467856

Epoch: 6| Step: 10
Training loss: 2.6465749740600586
Validation loss: 3.1244734102679836

Epoch: 6| Step: 11
Training loss: 3.064425468444824
Validation loss: 3.1254463529074066

Epoch: 6| Step: 12
Training loss: 2.88498854637146
Validation loss: 3.1223122689031784

Epoch: 6| Step: 13
Training loss: 2.343825340270996
Validation loss: 3.1163701395834646

Epoch: 11| Step: 0
Training loss: 4.054227352142334
Validation loss: 3.113652539509599

Epoch: 6| Step: 1
Training loss: 4.2032999992370605
Validation loss: 3.10476714821272

Epoch: 6| Step: 2
Training loss: 2.880915641784668
Validation loss: 3.096599858294251

Epoch: 6| Step: 3
Training loss: 2.819572687149048
Validation loss: 3.091659922753611

Epoch: 6| Step: 4
Training loss: 2.352112293243408
Validation loss: 3.0953698824810725

Epoch: 6| Step: 5
Training loss: 4.505088806152344
Validation loss: 3.181125566523562

Epoch: 6| Step: 6
Training loss: 2.588623285293579
Validation loss: 3.0812023044914327

Epoch: 6| Step: 7
Training loss: 1.9862784147262573
Validation loss: 3.1306479336113058

Epoch: 6| Step: 8
Training loss: 2.182467460632324
Validation loss: 3.1717714443001697

Epoch: 6| Step: 9
Training loss: 4.3748321533203125
Validation loss: 3.2151109274997505

Epoch: 6| Step: 10
Training loss: 3.2737085819244385
Validation loss: 3.2263091430869153

Epoch: 6| Step: 11
Training loss: 3.0466408729553223
Validation loss: 3.2230177746024182

Epoch: 6| Step: 12
Training loss: 3.1008660793304443
Validation loss: 3.22169937369644

Epoch: 6| Step: 13
Training loss: 3.09761118888855
Validation loss: 3.2168896839182866

Epoch: 12| Step: 0
Training loss: 2.477187156677246
Validation loss: 3.18959237939568

Epoch: 6| Step: 1
Training loss: 3.103914260864258
Validation loss: 3.1597584293734644

Epoch: 6| Step: 2
Training loss: 3.380380630493164
Validation loss: 3.1349213328412784

Epoch: 6| Step: 3
Training loss: 3.519770622253418
Validation loss: 3.098342026433637

Epoch: 6| Step: 4
Training loss: 3.16616153717041
Validation loss: 3.0721828168438328

Epoch: 6| Step: 5
Training loss: 3.8983800411224365
Validation loss: 3.0761841958568943

Epoch: 6| Step: 6
Training loss: 3.69427490234375
Validation loss: 3.0887349087704896

Epoch: 6| Step: 7
Training loss: 3.146660566329956
Validation loss: 3.0817575454711914

Epoch: 6| Step: 8
Training loss: 2.9442691802978516
Validation loss: 3.045476967288602

Epoch: 6| Step: 9
Training loss: 2.978440046310425
Validation loss: 3.0306099512243785

Epoch: 6| Step: 10
Training loss: 2.0194244384765625
Validation loss: 3.022284794879216

Epoch: 6| Step: 11
Training loss: 2.4398975372314453
Validation loss: 3.0223992050334973

Epoch: 6| Step: 12
Training loss: 3.8826839923858643
Validation loss: 3.0199829839891

Epoch: 6| Step: 13
Training loss: 2.972144603729248
Validation loss: 3.0201683505888908

Epoch: 13| Step: 0
Training loss: 3.147282123565674
Validation loss: 3.017415626074678

Epoch: 6| Step: 1
Training loss: 3.127102851867676
Validation loss: 3.014622665220691

Epoch: 6| Step: 2
Training loss: 2.9998087882995605
Validation loss: 3.0084469164571455

Epoch: 6| Step: 3
Training loss: 2.5310428142547607
Validation loss: 3.006824193462249

Epoch: 6| Step: 4
Training loss: 4.443999767303467
Validation loss: 3.0047583708199124

Epoch: 6| Step: 5
Training loss: 2.1633553504943848
Validation loss: 2.9980876138133388

Epoch: 6| Step: 6
Training loss: 3.569483995437622
Validation loss: 2.9917465281742874

Epoch: 6| Step: 7
Training loss: 3.030604600906372
Validation loss: 2.981877201346941

Epoch: 6| Step: 8
Training loss: 2.4790167808532715
Validation loss: 2.9814178815452

Epoch: 6| Step: 9
Training loss: 3.027268171310425
Validation loss: 2.970703988946894

Epoch: 6| Step: 10
Training loss: 3.245925188064575
Validation loss: 2.9717140607936408

Epoch: 6| Step: 11
Training loss: 3.1726269721984863
Validation loss: 2.9713796056726927

Epoch: 6| Step: 12
Training loss: 2.9916977882385254
Validation loss: 2.9616798482915407

Epoch: 6| Step: 13
Training loss: 2.7670738697052
Validation loss: 2.9672472989687355

Epoch: 14| Step: 0
Training loss: 2.7780921459198
Validation loss: 2.9852040185723254

Epoch: 6| Step: 1
Training loss: 3.3859739303588867
Validation loss: 3.0096379736418366

Epoch: 6| Step: 2
Training loss: 2.194244146347046
Validation loss: 3.038114845111806

Epoch: 6| Step: 3
Training loss: 3.192718029022217
Validation loss: 3.0000979131267917

Epoch: 6| Step: 4
Training loss: 2.781771421432495
Validation loss: 2.992316815160936

Epoch: 6| Step: 5
Training loss: 3.2452657222747803
Validation loss: 2.97739044825236

Epoch: 6| Step: 6
Training loss: 3.069291591644287
Validation loss: 2.9693027593756236

Epoch: 6| Step: 7
Training loss: 3.4314627647399902
Validation loss: 2.9523530493500414

Epoch: 6| Step: 8
Training loss: 3.343959331512451
Validation loss: 2.944283095739221

Epoch: 6| Step: 9
Training loss: 3.3361287117004395
Validation loss: 2.9528693076102965

Epoch: 6| Step: 10
Training loss: 3.012847423553467
Validation loss: 2.9509118449303413

Epoch: 6| Step: 11
Training loss: 2.9223618507385254
Validation loss: 2.9524413154971216

Epoch: 6| Step: 12
Training loss: 2.754930019378662
Validation loss: 2.933886815142888

Epoch: 6| Step: 13
Training loss: 3.259096622467041
Validation loss: 2.926105340321859

Epoch: 15| Step: 0
Training loss: 2.9009008407592773
Validation loss: 2.9200726606512584

Epoch: 6| Step: 1
Training loss: 3.070497989654541
Validation loss: 2.9071240860928773

Epoch: 6| Step: 2
Training loss: 3.2431392669677734
Validation loss: 2.89771201533656

Epoch: 6| Step: 3
Training loss: 3.0462746620178223
Validation loss: 2.8896981388010006

Epoch: 6| Step: 4
Training loss: 2.2468714714050293
Validation loss: 2.8832300811685543

Epoch: 6| Step: 5
Training loss: 3.3913228511810303
Validation loss: 2.8794284302701234

Epoch: 6| Step: 6
Training loss: 3.221001625061035
Validation loss: 2.8713721536820933

Epoch: 6| Step: 7
Training loss: 2.8325576782226562
Validation loss: 2.8655243689014065

Epoch: 6| Step: 8
Training loss: 2.382707118988037
Validation loss: 2.862006405348419

Epoch: 6| Step: 9
Training loss: 3.175935983657837
Validation loss: 2.870390874083324

Epoch: 6| Step: 10
Training loss: 2.790882110595703
Validation loss: 2.845718353025375

Epoch: 6| Step: 11
Training loss: 3.325314998626709
Validation loss: 2.8382010562445528

Epoch: 6| Step: 12
Training loss: 3.3859992027282715
Validation loss: 2.839766445980277

Epoch: 6| Step: 13
Training loss: 2.6264963150024414
Validation loss: 2.8340190200395483

Epoch: 16| Step: 0
Training loss: 3.322378158569336
Validation loss: 2.8329651278834187

Epoch: 6| Step: 1
Training loss: 2.6584668159484863
Validation loss: 2.8238896862153084

Epoch: 6| Step: 2
Training loss: 3.128983497619629
Validation loss: 2.8202194654813377

Epoch: 6| Step: 3
Training loss: 2.86362361907959
Validation loss: 2.816658112310594

Epoch: 6| Step: 4
Training loss: 1.9486865997314453
Validation loss: 2.8143979913444928

Epoch: 6| Step: 5
Training loss: 2.0514328479766846
Validation loss: 2.809587783710931

Epoch: 6| Step: 6
Training loss: 3.296722650527954
Validation loss: 2.8056852125352427

Epoch: 6| Step: 7
Training loss: 3.2257790565490723
Validation loss: 2.7986790980062177

Epoch: 6| Step: 8
Training loss: 3.1097311973571777
Validation loss: 2.794576388533397

Epoch: 6| Step: 9
Training loss: 3.5711631774902344
Validation loss: 2.794248237404772

Epoch: 6| Step: 10
Training loss: 3.2721238136291504
Validation loss: 2.7923060206956762

Epoch: 6| Step: 11
Training loss: 2.645500421524048
Validation loss: 2.7889370661909862

Epoch: 6| Step: 12
Training loss: 3.3148112297058105
Validation loss: 2.814533728425221

Epoch: 6| Step: 13
Training loss: 2.493119716644287
Validation loss: 2.7840457475313576

Epoch: 17| Step: 0
Training loss: 2.0656909942626953
Validation loss: 2.774075338917394

Epoch: 6| Step: 1
Training loss: 3.418333053588867
Validation loss: 2.7887408912822766

Epoch: 6| Step: 2
Training loss: 2.855280637741089
Validation loss: 2.7791314560879945

Epoch: 6| Step: 3
Training loss: 2.8006207942962646
Validation loss: 2.7747380682217178

Epoch: 6| Step: 4
Training loss: 2.5011143684387207
Validation loss: 2.7644415465734338

Epoch: 6| Step: 5
Training loss: 3.5142006874084473
Validation loss: 2.7586082258532123

Epoch: 6| Step: 6
Training loss: 3.069427490234375
Validation loss: 2.7579363469154603

Epoch: 6| Step: 7
Training loss: 2.622852325439453
Validation loss: 2.7557277987080235

Epoch: 6| Step: 8
Training loss: 2.9514288902282715
Validation loss: 2.7552295372050297

Epoch: 6| Step: 9
Training loss: 2.7368111610412598
Validation loss: 2.756365155660978

Epoch: 6| Step: 10
Training loss: 3.307124137878418
Validation loss: 2.7537906323709795

Epoch: 6| Step: 11
Training loss: 3.027729034423828
Validation loss: 2.7488169849559827

Epoch: 6| Step: 12
Training loss: 2.892695188522339
Validation loss: 2.7412004317006757

Epoch: 6| Step: 13
Training loss: 2.954387664794922
Validation loss: 2.738263894152898

Epoch: 18| Step: 0
Training loss: 2.6163253784179688
Validation loss: 2.731733145252351

Epoch: 6| Step: 1
Training loss: 2.3534765243530273
Validation loss: 2.725947539011637

Epoch: 6| Step: 2
Training loss: 3.6625308990478516
Validation loss: 2.727080055462417

Epoch: 6| Step: 3
Training loss: 2.8488309383392334
Validation loss: 2.726482311884562

Epoch: 6| Step: 4
Training loss: 3.293368339538574
Validation loss: 2.7169619580750823

Epoch: 6| Step: 5
Training loss: 2.4543912410736084
Validation loss: 2.7179945694502963

Epoch: 6| Step: 6
Training loss: 2.371950149536133
Validation loss: 2.7243916065462175

Epoch: 6| Step: 7
Training loss: 3.3449854850769043
Validation loss: 2.7266137343581005

Epoch: 6| Step: 8
Training loss: 2.5956456661224365
Validation loss: 2.7282843512873494

Epoch: 6| Step: 9
Training loss: 3.3393852710723877
Validation loss: 2.7299331926530406

Epoch: 6| Step: 10
Training loss: 3.1291112899780273
Validation loss: 2.721219696024413

Epoch: 6| Step: 11
Training loss: 2.2485697269439697
Validation loss: 2.7125740179451565

Epoch: 6| Step: 12
Training loss: 2.9813356399536133
Validation loss: 2.7043247094718357

Epoch: 6| Step: 13
Training loss: 3.414790153503418
Validation loss: 2.6971293085364887

Epoch: 19| Step: 0
Training loss: 2.9351611137390137
Validation loss: 2.693768039826424

Epoch: 6| Step: 1
Training loss: 2.472569465637207
Validation loss: 2.7269806054330643

Epoch: 6| Step: 2
Training loss: 2.9408388137817383
Validation loss: 2.7147893239093084

Epoch: 6| Step: 3
Training loss: 2.300562858581543
Validation loss: 2.6881522940051172

Epoch: 6| Step: 4
Training loss: 2.916518211364746
Validation loss: 2.691745096637357

Epoch: 6| Step: 5
Training loss: 2.0745010375976562
Validation loss: 2.6903260138727005

Epoch: 6| Step: 6
Training loss: 2.1551437377929688
Validation loss: 2.6901749231482066

Epoch: 6| Step: 7
Training loss: 3.188506603240967
Validation loss: 2.6963926463998775

Epoch: 6| Step: 8
Training loss: 3.9436888694763184
Validation loss: 2.69914327385605

Epoch: 6| Step: 9
Training loss: 3.7915940284729004
Validation loss: 2.6955516210166355

Epoch: 6| Step: 10
Training loss: 2.790555477142334
Validation loss: 2.6889125429173952

Epoch: 6| Step: 11
Training loss: 2.7262163162231445
Validation loss: 2.680790762747488

Epoch: 6| Step: 12
Training loss: 2.5388009548187256
Validation loss: 2.679506327516289

Epoch: 6| Step: 13
Training loss: 3.686192035675049
Validation loss: 2.678027988761984

Epoch: 20| Step: 0
Training loss: 2.747917652130127
Validation loss: 2.6772193139599216

Epoch: 6| Step: 1
Training loss: 2.709423780441284
Validation loss: 2.675609888569001

Epoch: 6| Step: 2
Training loss: 2.749001979827881
Validation loss: 2.6729511625023297

Epoch: 6| Step: 3
Training loss: 2.839012622833252
Validation loss: 2.67001756288672

Epoch: 6| Step: 4
Training loss: 3.1128902435302734
Validation loss: 2.6683541446603756

Epoch: 6| Step: 5
Training loss: 3.060948610305786
Validation loss: 2.6663903779880975

Epoch: 6| Step: 6
Training loss: 3.6391186714172363
Validation loss: 2.667513898623887

Epoch: 6| Step: 7
Training loss: 3.457132339477539
Validation loss: 2.6622473706481276

Epoch: 6| Step: 8
Training loss: 2.336956024169922
Validation loss: 2.6554336547851562

Epoch: 6| Step: 9
Training loss: 2.0405941009521484
Validation loss: 2.652972141901652

Epoch: 6| Step: 10
Training loss: 3.211625814437866
Validation loss: 2.6525539352047827

Epoch: 6| Step: 11
Training loss: 2.646036148071289
Validation loss: 2.651006447371616

Epoch: 6| Step: 12
Training loss: 2.6331734657287598
Validation loss: 2.6525832453081684

Epoch: 6| Step: 13
Training loss: 2.4089322090148926
Validation loss: 2.6472789972059187

Epoch: 21| Step: 0
Training loss: 2.144461154937744
Validation loss: 2.6862852086303053

Epoch: 6| Step: 1
Training loss: 2.92375111579895
Validation loss: 2.8025595500905025

Epoch: 6| Step: 2
Training loss: 3.089216947555542
Validation loss: 2.8447046356816448

Epoch: 6| Step: 3
Training loss: 2.4380311965942383
Validation loss: 2.838548773078508

Epoch: 6| Step: 4
Training loss: 2.7087550163269043
Validation loss: 2.8052220523998304

Epoch: 6| Step: 5
Training loss: 2.227599620819092
Validation loss: 2.7777802687819286

Epoch: 6| Step: 6
Training loss: 2.868638277053833
Validation loss: 2.7587335545529603

Epoch: 6| Step: 7
Training loss: 3.83413028717041
Validation loss: 2.727634478640813

Epoch: 6| Step: 8
Training loss: 3.671009063720703
Validation loss: 2.7168922834498908

Epoch: 6| Step: 9
Training loss: 2.973959445953369
Validation loss: 2.702024629039149

Epoch: 6| Step: 10
Training loss: 3.191164970397949
Validation loss: 2.6888054109388784

Epoch: 6| Step: 11
Training loss: 2.7555036544799805
Validation loss: 2.6798564234087543

Epoch: 6| Step: 12
Training loss: 2.5545272827148438
Validation loss: 2.6626373619161625

Epoch: 6| Step: 13
Training loss: 3.2073609828948975
Validation loss: 2.652779584289879

Epoch: 22| Step: 0
Training loss: 2.7583999633789062
Validation loss: 2.6403886502788914

Epoch: 6| Step: 1
Training loss: 2.2533302307128906
Validation loss: 2.6323748685980357

Epoch: 6| Step: 2
Training loss: 3.649968385696411
Validation loss: 2.629298233216809

Epoch: 6| Step: 3
Training loss: 2.2289085388183594
Validation loss: 2.626718718518493

Epoch: 6| Step: 4
Training loss: 3.63322114944458
Validation loss: 2.6276424777123237

Epoch: 6| Step: 5
Training loss: 2.3144822120666504
Validation loss: 2.6232561116577475

Epoch: 6| Step: 6
Training loss: 2.7313320636749268
Validation loss: 2.6432059490552513

Epoch: 6| Step: 7
Training loss: 3.0105361938476562
Validation loss: 2.6384366481534895

Epoch: 6| Step: 8
Training loss: 2.4154109954833984
Validation loss: 2.622428568460608

Epoch: 6| Step: 9
Training loss: 3.2397165298461914
Validation loss: 2.6144135280322005

Epoch: 6| Step: 10
Training loss: 3.027010917663574
Validation loss: 2.6129453976949057

Epoch: 6| Step: 11
Training loss: 3.121526002883911
Validation loss: 2.6145000534672893

Epoch: 6| Step: 12
Training loss: 2.3774662017822266
Validation loss: 2.6141909578795075

Epoch: 6| Step: 13
Training loss: 2.617570161819458
Validation loss: 2.6188318139763287

Epoch: 23| Step: 0
Training loss: 3.038376808166504
Validation loss: 2.613877729703021

Epoch: 6| Step: 1
Training loss: 2.775648832321167
Validation loss: 2.60745007248335

Epoch: 6| Step: 2
Training loss: 2.3649795055389404
Validation loss: 2.601523112225276

Epoch: 6| Step: 3
Training loss: 2.3865976333618164
Validation loss: 2.597126319844236

Epoch: 6| Step: 4
Training loss: 3.0820345878601074
Validation loss: 2.591822470388105

Epoch: 6| Step: 5
Training loss: 2.378931760787964
Validation loss: 2.5936960097282165

Epoch: 6| Step: 6
Training loss: 2.423736572265625
Validation loss: 2.5940035466224916

Epoch: 6| Step: 7
Training loss: 3.134850025177002
Validation loss: 2.6412948280252437

Epoch: 6| Step: 8
Training loss: 3.280517339706421
Validation loss: 2.6277979522623043

Epoch: 6| Step: 9
Training loss: 2.8226191997528076
Validation loss: 2.577439446603098

Epoch: 6| Step: 10
Training loss: 3.3193888664245605
Validation loss: 2.573221463029103

Epoch: 6| Step: 11
Training loss: 3.378319263458252
Validation loss: 2.5840698698515534

Epoch: 6| Step: 12
Training loss: 2.217048168182373
Validation loss: 2.5982569597100698

Epoch: 6| Step: 13
Training loss: 2.459744453430176
Validation loss: 2.62654951823655

Epoch: 24| Step: 0
Training loss: 2.7312421798706055
Validation loss: 2.6458918612490416

Epoch: 6| Step: 1
Training loss: 2.381253719329834
Validation loss: 2.619571557608984

Epoch: 6| Step: 2
Training loss: 3.1611406803131104
Validation loss: 2.5915196890472085

Epoch: 6| Step: 3
Training loss: 3.337477445602417
Validation loss: 2.5763013439793743

Epoch: 6| Step: 4
Training loss: 3.0929107666015625
Validation loss: 2.5609145754127094

Epoch: 6| Step: 5
Training loss: 2.8983469009399414
Validation loss: 2.5596354187175794

Epoch: 6| Step: 6
Training loss: 2.5687294006347656
Validation loss: 2.555856482956999

Epoch: 6| Step: 7
Training loss: 2.9763083457946777
Validation loss: 2.5630689077479865

Epoch: 6| Step: 8
Training loss: 2.8809876441955566
Validation loss: 2.559084112926196

Epoch: 6| Step: 9
Training loss: 2.09250545501709
Validation loss: 2.554659084607196

Epoch: 6| Step: 10
Training loss: 3.168821334838867
Validation loss: 2.5499640844201528

Epoch: 6| Step: 11
Training loss: 2.4306540489196777
Validation loss: 2.55554029762104

Epoch: 6| Step: 12
Training loss: 2.946218967437744
Validation loss: 2.5515444253080632

Epoch: 6| Step: 13
Training loss: 1.910164713859558
Validation loss: 2.5507564621586956

Epoch: 25| Step: 0
Training loss: 3.0284841060638428
Validation loss: 2.540443830592658

Epoch: 6| Step: 1
Training loss: 1.4666775465011597
Validation loss: 2.5487880604241484

Epoch: 6| Step: 2
Training loss: 3.306915760040283
Validation loss: 2.573158869179346

Epoch: 6| Step: 3
Training loss: 1.8956589698791504
Validation loss: 2.533326789896975

Epoch: 6| Step: 4
Training loss: 3.5771095752716064
Validation loss: 2.530355067663295

Epoch: 6| Step: 5
Training loss: 3.3773674964904785
Validation loss: 2.53382630502024

Epoch: 6| Step: 6
Training loss: 3.4284093379974365
Validation loss: 2.5386659381210164

Epoch: 6| Step: 7
Training loss: 3.0338289737701416
Validation loss: 2.547669328669066

Epoch: 6| Step: 8
Training loss: 2.6928093433380127
Validation loss: 2.5471981404930033

Epoch: 6| Step: 9
Training loss: 1.9334712028503418
Validation loss: 2.5434374193991385

Epoch: 6| Step: 10
Training loss: 2.8335301876068115
Validation loss: 2.54694619999137

Epoch: 6| Step: 11
Training loss: 2.456559896469116
Validation loss: 2.5434052995456162

Epoch: 6| Step: 12
Training loss: 2.8096868991851807
Validation loss: 2.535770054786436

Epoch: 6| Step: 13
Training loss: 3.1369376182556152
Validation loss: 2.5330371702871015

Epoch: 26| Step: 0
Training loss: 3.1353158950805664
Validation loss: 2.5284643173217773

Epoch: 6| Step: 1
Training loss: 2.510061740875244
Validation loss: 2.5245314951865905

Epoch: 6| Step: 2
Training loss: 2.934049606323242
Validation loss: 2.5314173595879668

Epoch: 6| Step: 3
Training loss: 3.0745513439178467
Validation loss: 2.518484902638261

Epoch: 6| Step: 4
Training loss: 1.5552862882614136
Validation loss: 2.5125002040657947

Epoch: 6| Step: 5
Training loss: 2.510798454284668
Validation loss: 2.515330091599495

Epoch: 6| Step: 6
Training loss: 2.2932839393615723
Validation loss: 2.521945543186639

Epoch: 6| Step: 7
Training loss: 3.2163305282592773
Validation loss: 2.5431231708936792

Epoch: 6| Step: 8
Training loss: 4.160146713256836
Validation loss: 2.576454988089941

Epoch: 6| Step: 9
Training loss: 2.480374574661255
Validation loss: 2.553805064129573

Epoch: 6| Step: 10
Training loss: 2.4757726192474365
Validation loss: 2.5254148796040523

Epoch: 6| Step: 11
Training loss: 2.59535813331604
Validation loss: 2.510084165039883

Epoch: 6| Step: 12
Training loss: 3.04850172996521
Validation loss: 2.4978819893252466

Epoch: 6| Step: 13
Training loss: 2.4389255046844482
Validation loss: 2.4990880412440144

Epoch: 27| Step: 0
Training loss: 2.6272568702697754
Validation loss: 2.5035119953975884

Epoch: 6| Step: 1
Training loss: 3.1822397708892822
Validation loss: 2.510517663853143

Epoch: 6| Step: 2
Training loss: 1.9296302795410156
Validation loss: 2.5059894361803607

Epoch: 6| Step: 3
Training loss: 2.4735536575317383
Validation loss: 2.519516303975095

Epoch: 6| Step: 4
Training loss: 3.2097818851470947
Validation loss: 2.519416028453458

Epoch: 6| Step: 5
Training loss: 2.3212268352508545
Validation loss: 2.504780169456236

Epoch: 6| Step: 6
Training loss: 2.996764898300171
Validation loss: 2.5038659290600846

Epoch: 6| Step: 7
Training loss: 2.4355554580688477
Validation loss: 2.502740454930131

Epoch: 6| Step: 8
Training loss: 3.2540552616119385
Validation loss: 2.4914094196852816

Epoch: 6| Step: 9
Training loss: 2.551499366760254
Validation loss: 2.4929550078607376

Epoch: 6| Step: 10
Training loss: 2.3679237365722656
Validation loss: 2.4943193312614196

Epoch: 6| Step: 11
Training loss: 2.798297882080078
Validation loss: 2.495324409136208

Epoch: 6| Step: 12
Training loss: 2.6689438819885254
Validation loss: 2.509093789644139

Epoch: 6| Step: 13
Training loss: 4.1883392333984375
Validation loss: 2.5569420988841722

Epoch: 28| Step: 0
Training loss: 2.7942347526550293
Validation loss: 2.5529051211572464

Epoch: 6| Step: 1
Training loss: 2.594818592071533
Validation loss: 2.5553408694523636

Epoch: 6| Step: 2
Training loss: 2.372879981994629
Validation loss: 2.5450389410859797

Epoch: 6| Step: 3
Training loss: 2.611489772796631
Validation loss: 2.508930003771218

Epoch: 6| Step: 4
Training loss: 2.768998146057129
Validation loss: 2.506423980959

Epoch: 6| Step: 5
Training loss: 3.215395212173462
Validation loss: 2.5058144625797065

Epoch: 6| Step: 6
Training loss: 2.6925806999206543
Validation loss: 2.528518843394454

Epoch: 6| Step: 7
Training loss: 3.0815672874450684
Validation loss: 2.5428519454053653

Epoch: 6| Step: 8
Training loss: 2.1258742809295654
Validation loss: 2.532362727708714

Epoch: 6| Step: 9
Training loss: 3.0844950675964355
Validation loss: 2.5172014800451135

Epoch: 6| Step: 10
Training loss: 2.3862991333007812
Validation loss: 2.500020155342676

Epoch: 6| Step: 11
Training loss: 2.5354156494140625
Validation loss: 2.5137082735697427

Epoch: 6| Step: 12
Training loss: 2.829291343688965
Validation loss: 2.5292562002776773

Epoch: 6| Step: 13
Training loss: 3.7454423904418945
Validation loss: 2.535422419988981

Epoch: 29| Step: 0
Training loss: 2.377466917037964
Validation loss: 2.5097635869056947

Epoch: 6| Step: 1
Training loss: 2.7997748851776123
Validation loss: 2.5230029013849076

Epoch: 6| Step: 2
Training loss: 2.9542977809906006
Validation loss: 2.496696856714064

Epoch: 6| Step: 3
Training loss: 2.8013367652893066
Validation loss: 2.4683853118650374

Epoch: 6| Step: 4
Training loss: 2.041224718093872
Validation loss: 2.466505386496103

Epoch: 6| Step: 5
Training loss: 3.145073413848877
Validation loss: 2.4691312287443425

Epoch: 6| Step: 6
Training loss: 3.35585355758667
Validation loss: 2.4772088784043507

Epoch: 6| Step: 7
Training loss: 2.6612167358398438
Validation loss: 2.484979857680618

Epoch: 6| Step: 8
Training loss: 2.922055244445801
Validation loss: 2.4889415976821736

Epoch: 6| Step: 9
Training loss: 2.058171510696411
Validation loss: 2.488388407614923

Epoch: 6| Step: 10
Training loss: 2.3171706199645996
Validation loss: 2.497639963703771

Epoch: 6| Step: 11
Training loss: 2.9419803619384766
Validation loss: 2.502738134835356

Epoch: 6| Step: 12
Training loss: 2.6506595611572266
Validation loss: 2.4822459938705608

Epoch: 6| Step: 13
Training loss: 3.2997446060180664
Validation loss: 2.4805584594767582

Epoch: 30| Step: 0
Training loss: 2.6366844177246094
Validation loss: 2.4906570526861374

Epoch: 6| Step: 1
Training loss: 2.3572840690612793
Validation loss: 2.50068421517649

Epoch: 6| Step: 2
Training loss: 1.5767983198165894
Validation loss: 2.4931343370868313

Epoch: 6| Step: 3
Training loss: 2.6035513877868652
Validation loss: 2.4823126997998965

Epoch: 6| Step: 4
Training loss: 3.115809917449951
Validation loss: 2.471160514380342

Epoch: 6| Step: 5
Training loss: 3.221869468688965
Validation loss: 2.479758903544436

Epoch: 6| Step: 6
Training loss: 3.2744412422180176
Validation loss: 2.4688830093670915

Epoch: 6| Step: 7
Training loss: 2.528658390045166
Validation loss: 2.4673725251228578

Epoch: 6| Step: 8
Training loss: 3.062623977661133
Validation loss: 2.4668867793134464

Epoch: 6| Step: 9
Training loss: 2.5862886905670166
Validation loss: 2.470178493889429

Epoch: 6| Step: 10
Training loss: 3.091956615447998
Validation loss: 2.469123537822436

Epoch: 6| Step: 11
Training loss: 2.7921195030212402
Validation loss: 2.4611216642523326

Epoch: 6| Step: 12
Training loss: 2.1150450706481934
Validation loss: 2.456875237085486

Epoch: 6| Step: 13
Training loss: 3.3101840019226074
Validation loss: 2.4482471840355986

Epoch: 31| Step: 0
Training loss: 2.536597728729248
Validation loss: 2.4465499334437872

Epoch: 6| Step: 1
Training loss: 3.3435420989990234
Validation loss: 2.4565394924532984

Epoch: 6| Step: 2
Training loss: 2.3234431743621826
Validation loss: 2.4680511002899497

Epoch: 6| Step: 3
Training loss: 3.2541842460632324
Validation loss: 2.4616923178395917

Epoch: 6| Step: 4
Training loss: 2.356684684753418
Validation loss: 2.457205193017119

Epoch: 6| Step: 5
Training loss: 3.0942065715789795
Validation loss: 2.4488591276189333

Epoch: 6| Step: 6
Training loss: 2.600637435913086
Validation loss: 2.4413491833594536

Epoch: 6| Step: 7
Training loss: 1.998098373413086
Validation loss: 2.449295082399922

Epoch: 6| Step: 8
Training loss: 2.141274929046631
Validation loss: 2.4579962043352026

Epoch: 6| Step: 9
Training loss: 2.6234192848205566
Validation loss: 2.45888424945134

Epoch: 6| Step: 10
Training loss: 2.832426071166992
Validation loss: 2.4728801173548542

Epoch: 6| Step: 11
Training loss: 2.8608498573303223
Validation loss: 2.4886500245781353

Epoch: 6| Step: 12
Training loss: 2.7245874404907227
Validation loss: 2.5019375124285297

Epoch: 6| Step: 13
Training loss: 3.2931106090545654
Validation loss: 2.507542787059661

Epoch: 32| Step: 0
Training loss: 2.7856087684631348
Validation loss: 2.4747675849545385

Epoch: 6| Step: 1
Training loss: 3.0286953449249268
Validation loss: 2.4545992112928823

Epoch: 6| Step: 2
Training loss: 2.4399428367614746
Validation loss: 2.441322793242752

Epoch: 6| Step: 3
Training loss: 2.8686275482177734
Validation loss: 2.4362989292349866

Epoch: 6| Step: 4
Training loss: 2.8540449142456055
Validation loss: 2.434128592091222

Epoch: 6| Step: 5
Training loss: 2.7302603721618652
Validation loss: 2.4618431291272564

Epoch: 6| Step: 6
Training loss: 2.4080398082733154
Validation loss: 2.4771920968127508

Epoch: 6| Step: 7
Training loss: 3.148937225341797
Validation loss: 2.4707110979223765

Epoch: 6| Step: 8
Training loss: 3.010707139968872
Validation loss: 2.4390584435514224

Epoch: 6| Step: 9
Training loss: 2.0799381732940674
Validation loss: 2.4540155010838665

Epoch: 6| Step: 10
Training loss: 2.3917043209075928
Validation loss: 2.515274137578985

Epoch: 6| Step: 11
Training loss: 2.8839244842529297
Validation loss: 2.546149576863935

Epoch: 6| Step: 12
Training loss: 2.8319077491760254
Validation loss: 2.569109393704322

Epoch: 6| Step: 13
Training loss: 1.754255771636963
Validation loss: 2.5511434514035463

Epoch: 33| Step: 0
Training loss: 2.821906805038452
Validation loss: 2.518699372968366

Epoch: 6| Step: 1
Training loss: 2.7243077754974365
Validation loss: 2.4797214820820797

Epoch: 6| Step: 2
Training loss: 3.136190176010132
Validation loss: 2.519026945996028

Epoch: 6| Step: 3
Training loss: 2.7189388275146484
Validation loss: 2.548052441689276

Epoch: 6| Step: 4
Training loss: 3.5215368270874023
Validation loss: 2.578299560854512

Epoch: 6| Step: 5
Training loss: 2.963913917541504
Validation loss: 2.5277970939554195

Epoch: 6| Step: 6
Training loss: 2.5527658462524414
Validation loss: 2.455125370333272

Epoch: 6| Step: 7
Training loss: 2.23169207572937
Validation loss: 2.425692553161293

Epoch: 6| Step: 8
Training loss: 2.0442612171173096
Validation loss: 2.430532883572322

Epoch: 6| Step: 9
Training loss: 2.468522071838379
Validation loss: 2.446262798001689

Epoch: 6| Step: 10
Training loss: 2.8584094047546387
Validation loss: 2.4709254285340667

Epoch: 6| Step: 11
Training loss: 2.312021493911743
Validation loss: 2.4927603121726745

Epoch: 6| Step: 12
Training loss: 3.1264851093292236
Validation loss: 2.4836697757885022

Epoch: 6| Step: 13
Training loss: 1.9754213094711304
Validation loss: 2.418972797291253

Epoch: 34| Step: 0
Training loss: 2.722317695617676
Validation loss: 2.4063826658392466

Epoch: 6| Step: 1
Training loss: 3.239985942840576
Validation loss: 2.4111012438292145

Epoch: 6| Step: 2
Training loss: 2.9600181579589844
Validation loss: 2.4199078454766223

Epoch: 6| Step: 3
Training loss: 2.6690409183502197
Validation loss: 2.418989699373963

Epoch: 6| Step: 4
Training loss: 3.3213655948638916
Validation loss: 2.4290266895806916

Epoch: 6| Step: 5
Training loss: 2.0656025409698486
Validation loss: 2.4315375205009215

Epoch: 6| Step: 6
Training loss: 2.4092233180999756
Validation loss: 2.4188345401517806

Epoch: 6| Step: 7
Training loss: 3.088477611541748
Validation loss: 2.4081815776004585

Epoch: 6| Step: 8
Training loss: 2.512666702270508
Validation loss: 2.4020415198418403

Epoch: 6| Step: 9
Training loss: 2.8543503284454346
Validation loss: 2.4149350350902927

Epoch: 6| Step: 10
Training loss: 2.4010074138641357
Validation loss: 2.4303698693552325

Epoch: 6| Step: 11
Training loss: 2.803311586380005
Validation loss: 2.4437374735391266

Epoch: 6| Step: 12
Training loss: 2.054422378540039
Validation loss: 2.455984215582571

Epoch: 6| Step: 13
Training loss: 2.2937326431274414
Validation loss: 2.428873946589808

Epoch: 35| Step: 0
Training loss: 1.7288507223129272
Validation loss: 2.41249946625002

Epoch: 6| Step: 1
Training loss: 2.567110538482666
Validation loss: 2.406703190136981

Epoch: 6| Step: 2
Training loss: 3.843010187149048
Validation loss: 2.402019716078235

Epoch: 6| Step: 3
Training loss: 2.8154006004333496
Validation loss: 2.3924941350055

Epoch: 6| Step: 4
Training loss: 3.0869197845458984
Validation loss: 2.3879393582702964

Epoch: 6| Step: 5
Training loss: 3.000483989715576
Validation loss: 2.3931125415268766

Epoch: 6| Step: 6
Training loss: 2.6125669479370117
Validation loss: 2.3979798875829226

Epoch: 6| Step: 7
Training loss: 1.662430763244629
Validation loss: 2.3923300132956555

Epoch: 6| Step: 8
Training loss: 2.7141799926757812
Validation loss: 2.39712324706457

Epoch: 6| Step: 9
Training loss: 2.6532230377197266
Validation loss: 2.406018898051272

Epoch: 6| Step: 10
Training loss: 2.1043176651000977
Validation loss: 2.4281914875071537

Epoch: 6| Step: 11
Training loss: 3.0826680660247803
Validation loss: 2.441721034306352

Epoch: 6| Step: 12
Training loss: 2.319378137588501
Validation loss: 2.4254838420498754

Epoch: 6| Step: 13
Training loss: 2.9851489067077637
Validation loss: 2.409712979870458

Epoch: 36| Step: 0
Training loss: 3.5428237915039062
Validation loss: 2.3840972582499185

Epoch: 6| Step: 1
Training loss: 2.6113061904907227
Validation loss: 2.3676527328388666

Epoch: 6| Step: 2
Training loss: 2.6623892784118652
Validation loss: 2.3619591164332565

Epoch: 6| Step: 3
Training loss: 2.649526596069336
Validation loss: 2.367421437335271

Epoch: 6| Step: 4
Training loss: 2.5295193195343018
Validation loss: 2.3643072318005305

Epoch: 6| Step: 5
Training loss: 2.9262514114379883
Validation loss: 2.360849521493399

Epoch: 6| Step: 6
Training loss: 2.3258345127105713
Validation loss: 2.3550185849589687

Epoch: 6| Step: 7
Training loss: 2.9175736904144287
Validation loss: 2.352890650431315

Epoch: 6| Step: 8
Training loss: 2.6784236431121826
Validation loss: 2.350089260326919

Epoch: 6| Step: 9
Training loss: 2.84454607963562
Validation loss: 2.350801552495649

Epoch: 6| Step: 10
Training loss: 2.393094301223755
Validation loss: 2.3472903646448606

Epoch: 6| Step: 11
Training loss: 2.3215060234069824
Validation loss: 2.351696409204955

Epoch: 6| Step: 12
Training loss: 2.043940544128418
Validation loss: 2.351306676864624

Epoch: 6| Step: 13
Training loss: 1.9521969556808472
Validation loss: 2.350655915916607

Epoch: 37| Step: 0
Training loss: 2.4700591564178467
Validation loss: 2.3595132289394254

Epoch: 6| Step: 1
Training loss: 3.076923370361328
Validation loss: 2.3657589189467894

Epoch: 6| Step: 2
Training loss: 1.957148790359497
Validation loss: 2.371177557976015

Epoch: 6| Step: 3
Training loss: 3.280683994293213
Validation loss: 2.374496767597814

Epoch: 6| Step: 4
Training loss: 2.1059536933898926
Validation loss: 2.361362636730235

Epoch: 6| Step: 5
Training loss: 1.8476190567016602
Validation loss: 2.3625583981954925

Epoch: 6| Step: 6
Training loss: 2.731825828552246
Validation loss: 2.3600781732989895

Epoch: 6| Step: 7
Training loss: 2.5978851318359375
Validation loss: 2.360385012883012

Epoch: 6| Step: 8
Training loss: 3.5868074893951416
Validation loss: 2.3577877295914518

Epoch: 6| Step: 9
Training loss: 2.5362234115600586
Validation loss: 2.3633231168152182

Epoch: 6| Step: 10
Training loss: 2.6316757202148438
Validation loss: 2.3682286098439205

Epoch: 6| Step: 11
Training loss: 2.340940237045288
Validation loss: 2.3760731976519347

Epoch: 6| Step: 12
Training loss: 2.5334901809692383
Validation loss: 2.3714143050614225

Epoch: 6| Step: 13
Training loss: 2.867427349090576
Validation loss: 2.3724870643308087

Epoch: 38| Step: 0
Training loss: 2.085503101348877
Validation loss: 2.380821225463703

Epoch: 6| Step: 1
Training loss: 2.515727996826172
Validation loss: 2.366303931000412

Epoch: 6| Step: 2
Training loss: 2.824800491333008
Validation loss: 2.351965037725305

Epoch: 6| Step: 3
Training loss: 2.2977089881896973
Validation loss: 2.346267654049781

Epoch: 6| Step: 4
Training loss: 2.5182414054870605
Validation loss: 2.3482396525721394

Epoch: 6| Step: 5
Training loss: 2.4152302742004395
Validation loss: 2.337072385254727

Epoch: 6| Step: 6
Training loss: 3.0498714447021484
Validation loss: 2.340936294165991

Epoch: 6| Step: 7
Training loss: 3.652853012084961
Validation loss: 2.338569912859189

Epoch: 6| Step: 8
Training loss: 2.5189003944396973
Validation loss: 2.339469558449202

Epoch: 6| Step: 9
Training loss: 3.169098377227783
Validation loss: 2.3451123724701586

Epoch: 6| Step: 10
Training loss: 2.351412296295166
Validation loss: 2.348571874762094

Epoch: 6| Step: 11
Training loss: 2.1568329334259033
Validation loss: 2.348232520523892

Epoch: 6| Step: 12
Training loss: 2.67734432220459
Validation loss: 2.352052834726149

Epoch: 6| Step: 13
Training loss: 1.9202537536621094
Validation loss: 2.3409900665283203

Epoch: 39| Step: 0
Training loss: 2.685426712036133
Validation loss: 2.3410451117382256

Epoch: 6| Step: 1
Training loss: 2.236769914627075
Validation loss: 2.3448555341330906

Epoch: 6| Step: 2
Training loss: 2.3574774265289307
Validation loss: 2.3410155439889557

Epoch: 6| Step: 3
Training loss: 3.133542776107788
Validation loss: 2.338350834385041

Epoch: 6| Step: 4
Training loss: 2.414318084716797
Validation loss: 2.3386153892804216

Epoch: 6| Step: 5
Training loss: 2.074315309524536
Validation loss: 2.3433703863492577

Epoch: 6| Step: 6
Training loss: 2.5606155395507812
Validation loss: 2.3477985833280828

Epoch: 6| Step: 7
Training loss: 3.209017276763916
Validation loss: 2.355526944642426

Epoch: 6| Step: 8
Training loss: 2.73250150680542
Validation loss: 2.3436683659912436

Epoch: 6| Step: 9
Training loss: 2.446708917617798
Validation loss: 2.346302863090269

Epoch: 6| Step: 10
Training loss: 2.901923179626465
Validation loss: 2.367798251490439

Epoch: 6| Step: 11
Training loss: 1.7664536237716675
Validation loss: 2.381056229273478

Epoch: 6| Step: 12
Training loss: 2.9132490158081055
Validation loss: 2.3806104044760428

Epoch: 6| Step: 13
Training loss: 2.945389986038208
Validation loss: 2.3648212776389173

Epoch: 40| Step: 0
Training loss: 2.1963882446289062
Validation loss: 2.338517686372162

Epoch: 6| Step: 1
Training loss: 2.2456021308898926
Validation loss: 2.34535781029732

Epoch: 6| Step: 2
Training loss: 2.973918914794922
Validation loss: 2.3488054301149104

Epoch: 6| Step: 3
Training loss: 2.3109593391418457
Validation loss: 2.352141834074451

Epoch: 6| Step: 4
Training loss: 2.3420910835266113
Validation loss: 2.353056164198024

Epoch: 6| Step: 5
Training loss: 2.8797223567962646
Validation loss: 2.337938916298651

Epoch: 6| Step: 6
Training loss: 2.224102020263672
Validation loss: 2.3179187185020855

Epoch: 6| Step: 7
Training loss: 3.0746610164642334
Validation loss: 2.322382834649855

Epoch: 6| Step: 8
Training loss: 2.8438775539398193
Validation loss: 2.3269819495498494

Epoch: 6| Step: 9
Training loss: 2.256770133972168
Validation loss: 2.329341116771903

Epoch: 6| Step: 10
Training loss: 2.8258090019226074
Validation loss: 2.324983460928804

Epoch: 6| Step: 11
Training loss: 3.0490283966064453
Validation loss: 2.3213955920229674

Epoch: 6| Step: 12
Training loss: 2.732463836669922
Validation loss: 2.3203067933359454

Epoch: 6| Step: 13
Training loss: 2.3099145889282227
Validation loss: 2.332849548709008

Epoch: 41| Step: 0
Training loss: 2.345548152923584
Validation loss: 2.383522167000719

Epoch: 6| Step: 1
Training loss: 2.7709035873413086
Validation loss: 2.430117796826106

Epoch: 6| Step: 2
Training loss: 2.276822566986084
Validation loss: 2.39417242234753

Epoch: 6| Step: 3
Training loss: 2.491461753845215
Validation loss: 2.3886017619922595

Epoch: 6| Step: 4
Training loss: 2.8466715812683105
Validation loss: 2.390071375395662

Epoch: 6| Step: 5
Training loss: 3.1962780952453613
Validation loss: 2.426524762184389

Epoch: 6| Step: 6
Training loss: 2.538041591644287
Validation loss: 2.496666605754565

Epoch: 6| Step: 7
Training loss: 2.3915791511535645
Validation loss: 2.5359706596661638

Epoch: 6| Step: 8
Training loss: 2.9892468452453613
Validation loss: 2.435787267582391

Epoch: 6| Step: 9
Training loss: 2.7768492698669434
Validation loss: 2.325622390675288

Epoch: 6| Step: 10
Training loss: 2.027656078338623
Validation loss: 2.305206039900421

Epoch: 6| Step: 11
Training loss: 2.643322467803955
Validation loss: 2.3036190412377797

Epoch: 6| Step: 12
Training loss: 2.6557095050811768
Validation loss: 2.310896611982776

Epoch: 6| Step: 13
Training loss: 2.5727996826171875
Validation loss: 2.314126573583131

Epoch: 42| Step: 0
Training loss: 2.3292109966278076
Validation loss: 2.318922955502746

Epoch: 6| Step: 1
Training loss: 2.7532739639282227
Validation loss: 2.3292979630090858

Epoch: 6| Step: 2
Training loss: 3.1185903549194336
Validation loss: 2.3400707270509455

Epoch: 6| Step: 3
Training loss: 2.8820481300354004
Validation loss: 2.3333920176311205

Epoch: 6| Step: 4
Training loss: 2.5882010459899902
Validation loss: 2.318179876573624

Epoch: 6| Step: 5
Training loss: 3.109138011932373
Validation loss: 2.3106244635838333

Epoch: 6| Step: 6
Training loss: 1.9314202070236206
Validation loss: 2.307050023027646

Epoch: 6| Step: 7
Training loss: 2.338076114654541
Validation loss: 2.3010548776195896

Epoch: 6| Step: 8
Training loss: 2.545919179916382
Validation loss: 2.297656833484609

Epoch: 6| Step: 9
Training loss: 1.8653877973556519
Validation loss: 2.2997862139055805

Epoch: 6| Step: 10
Training loss: 3.1480836868286133
Validation loss: 2.317493461793469

Epoch: 6| Step: 11
Training loss: 2.661457061767578
Validation loss: 2.351309850651731

Epoch: 6| Step: 12
Training loss: 2.966604471206665
Validation loss: 2.387890654225503

Epoch: 6| Step: 13
Training loss: 1.916053295135498
Validation loss: 2.406733492369293

Epoch: 43| Step: 0
Training loss: 2.066100597381592
Validation loss: 2.4090623547953944

Epoch: 6| Step: 1
Training loss: 2.643415927886963
Validation loss: 2.3782188328363563

Epoch: 6| Step: 2
Training loss: 2.3679866790771484
Validation loss: 2.3650582298155753

Epoch: 6| Step: 3
Training loss: 2.4717273712158203
Validation loss: 2.3545061670323855

Epoch: 6| Step: 4
Training loss: 2.464775800704956
Validation loss: 2.3595938656919744

Epoch: 6| Step: 5
Training loss: 2.395015239715576
Validation loss: 2.3609849919555006

Epoch: 6| Step: 6
Training loss: 3.2105770111083984
Validation loss: 2.3523498196755686

Epoch: 6| Step: 7
Training loss: 2.2318038940429688
Validation loss: 2.332495630428355

Epoch: 6| Step: 8
Training loss: 2.9885950088500977
Validation loss: 2.3284841275984243

Epoch: 6| Step: 9
Training loss: 2.3939008712768555
Validation loss: 2.3284049290482716

Epoch: 6| Step: 10
Training loss: 2.719298839569092
Validation loss: 2.3168897449329333

Epoch: 6| Step: 11
Training loss: 2.423954963684082
Validation loss: 2.3095977024365495

Epoch: 6| Step: 12
Training loss: 2.7650132179260254
Validation loss: 2.297439411122312

Epoch: 6| Step: 13
Training loss: 3.6198654174804688
Validation loss: 2.2929598772397606

Epoch: 44| Step: 0
Training loss: 3.121764898300171
Validation loss: 2.2875271740780083

Epoch: 6| Step: 1
Training loss: 2.006704330444336
Validation loss: 2.2853741671449397

Epoch: 6| Step: 2
Training loss: 2.231544017791748
Validation loss: 2.287614348114178

Epoch: 6| Step: 3
Training loss: 2.7410333156585693
Validation loss: 2.2856355251804477

Epoch: 6| Step: 4
Training loss: 3.0262513160705566
Validation loss: 2.285518935931626

Epoch: 6| Step: 5
Training loss: 2.7785768508911133
Validation loss: 2.2800773600096345

Epoch: 6| Step: 6
Training loss: 2.521512031555176
Validation loss: 2.2824966830592

Epoch: 6| Step: 7
Training loss: 2.013334274291992
Validation loss: 2.2830515612838087

Epoch: 6| Step: 8
Training loss: 2.712536334991455
Validation loss: 2.276677885363179

Epoch: 6| Step: 9
Training loss: 2.427152633666992
Validation loss: 2.2763094338037635

Epoch: 6| Step: 10
Training loss: 2.3866400718688965
Validation loss: 2.2744664466509255

Epoch: 6| Step: 11
Training loss: 3.269435405731201
Validation loss: 2.287687906654932

Epoch: 6| Step: 12
Training loss: 2.2075552940368652
Validation loss: 2.302633249631492

Epoch: 6| Step: 13
Training loss: 2.4890129566192627
Validation loss: 2.329940531843452

Epoch: 45| Step: 0
Training loss: 3.1915440559387207
Validation loss: 2.389168898264567

Epoch: 6| Step: 1
Training loss: 2.570558547973633
Validation loss: 2.3644099953354045

Epoch: 6| Step: 2
Training loss: 1.7461161613464355
Validation loss: 2.3333751027302077

Epoch: 6| Step: 3
Training loss: 2.2907981872558594
Validation loss: 2.3240190859763854

Epoch: 6| Step: 4
Training loss: 3.183664560317993
Validation loss: 2.3064605548817623

Epoch: 6| Step: 5
Training loss: 2.981555938720703
Validation loss: 2.2992765570199616

Epoch: 6| Step: 6
Training loss: 2.886788845062256
Validation loss: 2.2897799015045166

Epoch: 6| Step: 7
Training loss: 3.1257596015930176
Validation loss: 2.2806287452738774

Epoch: 6| Step: 8
Training loss: 3.0733070373535156
Validation loss: 2.2813578408251525

Epoch: 6| Step: 9
Training loss: 2.0735528469085693
Validation loss: 2.2825665627756426

Epoch: 6| Step: 10
Training loss: 2.0205118656158447
Validation loss: 2.282088774506764

Epoch: 6| Step: 11
Training loss: 2.485506534576416
Validation loss: 2.28310554258285

Epoch: 6| Step: 12
Training loss: 2.367492914199829
Validation loss: 2.283172235693983

Epoch: 6| Step: 13
Training loss: 1.7369893789291382
Validation loss: 2.283116420110067

Epoch: 46| Step: 0
Training loss: 2.2895846366882324
Validation loss: 2.2841670590062297

Epoch: 6| Step: 1
Training loss: 3.6028385162353516
Validation loss: 2.2834383646647134

Epoch: 6| Step: 2
Training loss: 2.286837577819824
Validation loss: 2.285207045975552

Epoch: 6| Step: 3
Training loss: 2.802994728088379
Validation loss: 2.2811365717200824

Epoch: 6| Step: 4
Training loss: 1.762991189956665
Validation loss: 2.28060660823699

Epoch: 6| Step: 5
Training loss: 2.461188793182373
Validation loss: 2.2867256800333657

Epoch: 6| Step: 6
Training loss: 2.5313689708709717
Validation loss: 2.295633424994766

Epoch: 6| Step: 7
Training loss: 2.260293483734131
Validation loss: 2.2984977255585375

Epoch: 6| Step: 8
Training loss: 2.5180225372314453
Validation loss: 2.3156658193116546

Epoch: 6| Step: 9
Training loss: 2.649574041366577
Validation loss: 2.3523131006507465

Epoch: 6| Step: 10
Training loss: 2.7452409267425537
Validation loss: 2.373764093204211

Epoch: 6| Step: 11
Training loss: 2.6281306743621826
Validation loss: 2.3823623734135784

Epoch: 6| Step: 12
Training loss: 2.386305332183838
Validation loss: 2.3637497604534192

Epoch: 6| Step: 13
Training loss: 3.1702146530151367
Validation loss: 2.3236752735671176

Epoch: 47| Step: 0
Training loss: 2.6141092777252197
Validation loss: 2.266740499004241

Epoch: 6| Step: 1
Training loss: 2.394442558288574
Validation loss: 2.2626779284528507

Epoch: 6| Step: 2
Training loss: 1.674511194229126
Validation loss: 2.26787309492788

Epoch: 6| Step: 3
Training loss: 2.393437147140503
Validation loss: 2.2862330649488714

Epoch: 6| Step: 4
Training loss: 2.7807469367980957
Validation loss: 2.3085410030939246

Epoch: 6| Step: 5
Training loss: 3.4920105934143066
Validation loss: 2.3260935403967418

Epoch: 6| Step: 6
Training loss: 3.187817096710205
Validation loss: 2.326955113359677

Epoch: 6| Step: 7
Training loss: 2.274369716644287
Validation loss: 2.3102274530677387

Epoch: 6| Step: 8
Training loss: 2.712355136871338
Validation loss: 2.284341299405662

Epoch: 6| Step: 9
Training loss: 3.246875286102295
Validation loss: 2.2695938451315767

Epoch: 6| Step: 10
Training loss: 1.8660435676574707
Validation loss: 2.262321218367546

Epoch: 6| Step: 11
Training loss: 2.774595260620117
Validation loss: 2.2578037836218394

Epoch: 6| Step: 12
Training loss: 2.5917816162109375
Validation loss: 2.2610838451693134

Epoch: 6| Step: 13
Training loss: 2.128711223602295
Validation loss: 2.300236055927892

Epoch: 48| Step: 0
Training loss: 2.8019185066223145
Validation loss: 2.3632297054413827

Epoch: 6| Step: 1
Training loss: 2.6688032150268555
Validation loss: 2.406906716285213

Epoch: 6| Step: 2
Training loss: 2.7346200942993164
Validation loss: 2.4655038515726724

Epoch: 6| Step: 3
Training loss: 2.257274627685547
Validation loss: 2.409524420256256

Epoch: 6| Step: 4
Training loss: 2.9264113903045654
Validation loss: 2.3368504765213176

Epoch: 6| Step: 5
Training loss: 2.490016460418701
Validation loss: 2.295719741493143

Epoch: 6| Step: 6
Training loss: 2.8194475173950195
Validation loss: 2.2662471289275796

Epoch: 6| Step: 7
Training loss: 2.9118099212646484
Validation loss: 2.247294351618777

Epoch: 6| Step: 8
Training loss: 2.5274810791015625
Validation loss: 2.2451281547546387

Epoch: 6| Step: 9
Training loss: 2.4087438583374023
Validation loss: 2.2448669505375687

Epoch: 6| Step: 10
Training loss: 1.912886381149292
Validation loss: 2.2528465588887534

Epoch: 6| Step: 11
Training loss: 2.4876253604888916
Validation loss: 2.254447785756921

Epoch: 6| Step: 12
Training loss: 2.8650901317596436
Validation loss: 2.2492921967660227

Epoch: 6| Step: 13
Training loss: 2.4721133708953857
Validation loss: 2.2470865505997852

Epoch: 49| Step: 0
Training loss: 2.10782527923584
Validation loss: 2.2524075149207987

Epoch: 6| Step: 1
Training loss: 2.560145854949951
Validation loss: 2.26837973056301

Epoch: 6| Step: 2
Training loss: 2.3448848724365234
Validation loss: 2.2874341575048303

Epoch: 6| Step: 3
Training loss: 2.965306282043457
Validation loss: 2.308969954008697

Epoch: 6| Step: 4
Training loss: 1.9348984956741333
Validation loss: 2.3502200059993292

Epoch: 6| Step: 5
Training loss: 2.6655120849609375
Validation loss: 2.392150548196608

Epoch: 6| Step: 6
Training loss: 2.1527013778686523
Validation loss: 2.4182986008223666

Epoch: 6| Step: 7
Training loss: 2.6148033142089844
Validation loss: 2.40241487051851

Epoch: 6| Step: 8
Training loss: 2.4048337936401367
Validation loss: 2.355692635300339

Epoch: 6| Step: 9
Training loss: 3.1183712482452393
Validation loss: 2.2830098085505988

Epoch: 6| Step: 10
Training loss: 2.5310006141662598
Validation loss: 2.2496885868810836

Epoch: 6| Step: 11
Training loss: 3.2991151809692383
Validation loss: 2.2379826973843318

Epoch: 6| Step: 12
Training loss: 2.5004546642303467
Validation loss: 2.236021590489213

Epoch: 6| Step: 13
Training loss: 2.658653974533081
Validation loss: 2.235764467588035

Epoch: 50| Step: 0
Training loss: 3.0549449920654297
Validation loss: 2.2509710788726807

Epoch: 6| Step: 1
Training loss: 2.319897174835205
Validation loss: 2.2646940113395773

Epoch: 6| Step: 2
Training loss: 2.536468267440796
Validation loss: 2.3114598335758334

Epoch: 6| Step: 3
Training loss: 3.299050807952881
Validation loss: 2.300432510273431

Epoch: 6| Step: 4
Training loss: 3.1005492210388184
Validation loss: 2.2589208605468913

Epoch: 6| Step: 5
Training loss: 2.0222043991088867
Validation loss: 2.239749582864905

Epoch: 6| Step: 6
Training loss: 2.591763973236084
Validation loss: 2.2313134362620692

Epoch: 6| Step: 7
Training loss: 1.8237712383270264
Validation loss: 2.2280439202503493

Epoch: 6| Step: 8
Training loss: 2.661698579788208
Validation loss: 2.241841608478177

Epoch: 6| Step: 9
Training loss: 2.599984884262085
Validation loss: 2.2721629681125766

Epoch: 6| Step: 10
Training loss: 2.8497211933135986
Validation loss: 2.299083029070208

Epoch: 6| Step: 11
Training loss: 2.0669007301330566
Validation loss: 2.289346238618256

Epoch: 6| Step: 12
Training loss: 2.424135684967041
Validation loss: 2.297371861755207

Epoch: 6| Step: 13
Training loss: 3.0376429557800293
Validation loss: 2.2709436724262853

Epoch: 51| Step: 0
Training loss: 2.527401924133301
Validation loss: 2.2378436955072547

Epoch: 6| Step: 1
Training loss: 2.1675751209259033
Validation loss: 2.230592922497821

Epoch: 6| Step: 2
Training loss: 2.3846609592437744
Validation loss: 2.2394685129965506

Epoch: 6| Step: 3
Training loss: 2.7370128631591797
Validation loss: 2.2507147378818964

Epoch: 6| Step: 4
Training loss: 2.5700645446777344
Validation loss: 2.2645977953428864

Epoch: 6| Step: 5
Training loss: 2.7823691368103027
Validation loss: 2.2658591424265215

Epoch: 6| Step: 6
Training loss: 2.67168927192688
Validation loss: 2.2757488989060923

Epoch: 6| Step: 7
Training loss: 2.238929510116577
Validation loss: 2.278147476975636

Epoch: 6| Step: 8
Training loss: 2.2409114837646484
Validation loss: 2.2939891251184608

Epoch: 6| Step: 9
Training loss: 2.9474263191223145
Validation loss: 2.2978716127334105

Epoch: 6| Step: 10
Training loss: 3.084214925765991
Validation loss: 2.2814116811239593

Epoch: 6| Step: 11
Training loss: 2.355672836303711
Validation loss: 2.2561585928804133

Epoch: 6| Step: 12
Training loss: 2.747267246246338
Validation loss: 2.225771073372133

Epoch: 6| Step: 13
Training loss: 2.2252142429351807
Validation loss: 2.2236718311104724

Epoch: 52| Step: 0
Training loss: 2.83652925491333
Validation loss: 2.2254002812088176

Epoch: 6| Step: 1
Training loss: 2.305283546447754
Validation loss: 2.2338983115329536

Epoch: 6| Step: 2
Training loss: 3.162123680114746
Validation loss: 2.2498182250607397

Epoch: 6| Step: 3
Training loss: 2.584261894226074
Validation loss: 2.281137804831228

Epoch: 6| Step: 4
Training loss: 2.5134453773498535
Validation loss: 2.299895142996183

Epoch: 6| Step: 5
Training loss: 2.491116523742676
Validation loss: 2.282176243361606

Epoch: 6| Step: 6
Training loss: 2.2354273796081543
Validation loss: 2.3012531957318707

Epoch: 6| Step: 7
Training loss: 2.807647466659546
Validation loss: 2.264925592689104

Epoch: 6| Step: 8
Training loss: 2.0698697566986084
Validation loss: 2.239185410161172

Epoch: 6| Step: 9
Training loss: 2.5839414596557617
Validation loss: 2.2296583242313837

Epoch: 6| Step: 10
Training loss: 2.22239089012146
Validation loss: 2.2260978119347685

Epoch: 6| Step: 11
Training loss: 2.2781107425689697
Validation loss: 2.2320109721153014

Epoch: 6| Step: 12
Training loss: 2.656497001647949
Validation loss: 2.2213635137004237

Epoch: 6| Step: 13
Training loss: 2.7255678176879883
Validation loss: 2.2199739281849196

Epoch: 53| Step: 0
Training loss: 2.7285678386688232
Validation loss: 2.2185278784844185

Epoch: 6| Step: 1
Training loss: 2.251682758331299
Validation loss: 2.218275316299931

Epoch: 6| Step: 2
Training loss: 2.2986791133880615
Validation loss: 2.2114157061423025

Epoch: 6| Step: 3
Training loss: 2.1898293495178223
Validation loss: 2.2086110871325255

Epoch: 6| Step: 4
Training loss: 2.469590187072754
Validation loss: 2.22743514532684

Epoch: 6| Step: 5
Training loss: 3.0497140884399414
Validation loss: 2.2513925695932038

Epoch: 6| Step: 6
Training loss: 2.075394868850708
Validation loss: 2.279159417716406

Epoch: 6| Step: 7
Training loss: 2.479421615600586
Validation loss: 2.2979517777760825

Epoch: 6| Step: 8
Training loss: 2.5634219646453857
Validation loss: 2.3008259291289956

Epoch: 6| Step: 9
Training loss: 2.2327704429626465
Validation loss: 2.2700073180660123

Epoch: 6| Step: 10
Training loss: 2.844113826751709
Validation loss: 2.2288816564826557

Epoch: 6| Step: 11
Training loss: 2.556114673614502
Validation loss: 2.2131596790846957

Epoch: 6| Step: 12
Training loss: 3.0192418098449707
Validation loss: 2.2047473397306216

Epoch: 6| Step: 13
Training loss: 2.413778781890869
Validation loss: 2.2028321578938472

Epoch: 54| Step: 0
Training loss: 2.3780503273010254
Validation loss: 2.200373467578683

Epoch: 6| Step: 1
Training loss: 2.74294114112854
Validation loss: 2.2063025659130466

Epoch: 6| Step: 2
Training loss: 2.067777156829834
Validation loss: 2.2044910307853454

Epoch: 6| Step: 3
Training loss: 3.083209991455078
Validation loss: 2.208774943505564

Epoch: 6| Step: 4
Training loss: 1.9631505012512207
Validation loss: 2.210011678357278

Epoch: 6| Step: 5
Training loss: 2.9104294776916504
Validation loss: 2.2097660136479202

Epoch: 6| Step: 6
Training loss: 2.153017520904541
Validation loss: 2.2132193862750964

Epoch: 6| Step: 7
Training loss: 2.8999710083007812
Validation loss: 2.214322251658286

Epoch: 6| Step: 8
Training loss: 2.0539238452911377
Validation loss: 2.227286074751167

Epoch: 6| Step: 9
Training loss: 2.646883726119995
Validation loss: 2.2624672253926597

Epoch: 6| Step: 10
Training loss: 2.06156587600708
Validation loss: 2.2670945736669723

Epoch: 6| Step: 11
Training loss: 3.2009811401367188
Validation loss: 2.2670579956423853

Epoch: 6| Step: 12
Training loss: 2.658006191253662
Validation loss: 2.252268692498566

Epoch: 6| Step: 13
Training loss: 2.3670239448547363
Validation loss: 2.2359078058632473

Epoch: 55| Step: 0
Training loss: 2.33156156539917
Validation loss: 2.2683533904373006

Epoch: 6| Step: 1
Training loss: 2.7017693519592285
Validation loss: 2.2772177791082733

Epoch: 6| Step: 2
Training loss: 2.9969778060913086
Validation loss: 2.2729018939438688

Epoch: 6| Step: 3
Training loss: 2.7770915031433105
Validation loss: 2.257704283601494

Epoch: 6| Step: 4
Training loss: 1.8674519062042236
Validation loss: 2.25655561108743

Epoch: 6| Step: 5
Training loss: 2.6067910194396973
Validation loss: 2.2612806391972367

Epoch: 6| Step: 6
Training loss: 2.588531494140625
Validation loss: 2.2657711787890364

Epoch: 6| Step: 7
Training loss: 2.5086004734039307
Validation loss: 2.2318258259886052

Epoch: 6| Step: 8
Training loss: 1.9188690185546875
Validation loss: 2.224657953426402

Epoch: 6| Step: 9
Training loss: 2.2364718914031982
Validation loss: 2.223052591405889

Epoch: 6| Step: 10
Training loss: 2.6710972785949707
Validation loss: 2.2048432442449752

Epoch: 6| Step: 11
Training loss: 2.387002944946289
Validation loss: 2.1972185668124946

Epoch: 6| Step: 12
Training loss: 2.497389316558838
Validation loss: 2.1923562390829927

Epoch: 6| Step: 13
Training loss: 3.3187789916992188
Validation loss: 2.181198445699548

Epoch: 56| Step: 0
Training loss: 2.4462859630584717
Validation loss: 2.186541623966668

Epoch: 6| Step: 1
Training loss: 2.4991021156311035
Validation loss: 2.189702464688209

Epoch: 6| Step: 2
Training loss: 2.304171562194824
Validation loss: 2.1953477141677693

Epoch: 6| Step: 3
Training loss: 2.579524040222168
Validation loss: 2.1953966002310477

Epoch: 6| Step: 4
Training loss: 2.403979539871216
Validation loss: 2.2145414429326213

Epoch: 6| Step: 5
Training loss: 2.5343055725097656
Validation loss: 2.2447163622866393

Epoch: 6| Step: 6
Training loss: 3.311596632003784
Validation loss: 2.2475398253369074

Epoch: 6| Step: 7
Training loss: 1.5014903545379639
Validation loss: 2.233621956199728

Epoch: 6| Step: 8
Training loss: 3.303588390350342
Validation loss: 2.23452692134406

Epoch: 6| Step: 9
Training loss: 2.7767677307128906
Validation loss: 2.228343448331279

Epoch: 6| Step: 10
Training loss: 2.7595560550689697
Validation loss: 2.2029016120459444

Epoch: 6| Step: 11
Training loss: 2.2676713466644287
Validation loss: 2.19090356621691

Epoch: 6| Step: 12
Training loss: 2.318169116973877
Validation loss: 2.18589944993296

Epoch: 6| Step: 13
Training loss: 1.756564974784851
Validation loss: 2.1819420142840316

Epoch: 57| Step: 0
Training loss: 2.375217914581299
Validation loss: 2.183403725265175

Epoch: 6| Step: 1
Training loss: 3.023125410079956
Validation loss: 2.1798305408928984

Epoch: 6| Step: 2
Training loss: 1.5729434490203857
Validation loss: 2.1819517022819928

Epoch: 6| Step: 3
Training loss: 2.591549873352051
Validation loss: 2.1939391307933356

Epoch: 6| Step: 4
Training loss: 2.18782901763916
Validation loss: 2.187162555674071

Epoch: 6| Step: 5
Training loss: 2.0462098121643066
Validation loss: 2.2173276434662523

Epoch: 6| Step: 6
Training loss: 2.1861140727996826
Validation loss: 2.216971899873467

Epoch: 6| Step: 7
Training loss: 1.9693005084991455
Validation loss: 2.2525609770128803

Epoch: 6| Step: 8
Training loss: 1.9307317733764648
Validation loss: 2.258485991467712

Epoch: 6| Step: 9
Training loss: 3.2202773094177246
Validation loss: 2.24133050569924

Epoch: 6| Step: 10
Training loss: 3.0289759635925293
Validation loss: 2.2327529999517624

Epoch: 6| Step: 11
Training loss: 2.9565625190734863
Validation loss: 2.215420433270034

Epoch: 6| Step: 12
Training loss: 2.715848922729492
Validation loss: 2.1870498208589453

Epoch: 6| Step: 13
Training loss: 3.290029764175415
Validation loss: 2.1880952465918755

Epoch: 58| Step: 0
Training loss: 3.0311474800109863
Validation loss: 2.181814157834617

Epoch: 6| Step: 1
Training loss: 3.02351975440979
Validation loss: 2.1830724952041463

Epoch: 6| Step: 2
Training loss: 2.6345882415771484
Validation loss: 2.1694332886767644

Epoch: 6| Step: 3
Training loss: 2.805258274078369
Validation loss: 2.1747574703667754

Epoch: 6| Step: 4
Training loss: 2.334017753601074
Validation loss: 2.171012250326013

Epoch: 6| Step: 5
Training loss: 2.763807773590088
Validation loss: 2.177691928801998

Epoch: 6| Step: 6
Training loss: 1.704959511756897
Validation loss: 2.1862147905493297

Epoch: 6| Step: 7
Training loss: 2.195152759552002
Validation loss: 2.211861164339127

Epoch: 6| Step: 8
Training loss: 2.8330888748168945
Validation loss: 2.2798002560933432

Epoch: 6| Step: 9
Training loss: 2.4749178886413574
Validation loss: 2.35832715547213

Epoch: 6| Step: 10
Training loss: 2.400771379470825
Validation loss: 2.3933868613294376

Epoch: 6| Step: 11
Training loss: 2.7355871200561523
Validation loss: 2.459833656587908

Epoch: 6| Step: 12
Training loss: 1.533828616142273
Validation loss: 2.468256345359228

Epoch: 6| Step: 13
Training loss: 2.726724863052368
Validation loss: 2.461493533144715

Epoch: 59| Step: 0
Training loss: 2.521929979324341
Validation loss: 2.381630487339471

Epoch: 6| Step: 1
Training loss: 2.9761085510253906
Validation loss: 2.2679628697774743

Epoch: 6| Step: 2
Training loss: 3.091574192047119
Validation loss: 2.187110790642359

Epoch: 6| Step: 3
Training loss: 2.434969663619995
Validation loss: 2.1673349667620916

Epoch: 6| Step: 4
Training loss: 2.2392702102661133
Validation loss: 2.164089434890337

Epoch: 6| Step: 5
Training loss: 2.2912604808807373
Validation loss: 2.183268418876074

Epoch: 6| Step: 6
Training loss: 2.008303165435791
Validation loss: 2.2063665979651996

Epoch: 6| Step: 7
Training loss: 2.804300308227539
Validation loss: 2.236404131817561

Epoch: 6| Step: 8
Training loss: 3.0513322353363037
Validation loss: 2.3101184393769953

Epoch: 6| Step: 9
Training loss: 2.413259506225586
Validation loss: 2.293724618932252

Epoch: 6| Step: 10
Training loss: 2.8840017318725586
Validation loss: 2.214470976142473

Epoch: 6| Step: 11
Training loss: 2.4451584815979004
Validation loss: 2.185955919245238

Epoch: 6| Step: 12
Training loss: 2.420867681503296
Validation loss: 2.1639956787068355

Epoch: 6| Step: 13
Training loss: 2.4519948959350586
Validation loss: 2.172734128531589

Epoch: 60| Step: 0
Training loss: 2.252016544342041
Validation loss: 2.19814637912217

Epoch: 6| Step: 1
Training loss: 2.2529191970825195
Validation loss: 2.2575808558412778

Epoch: 6| Step: 2
Training loss: 2.037446975708008
Validation loss: 2.3219063000012468

Epoch: 6| Step: 3
Training loss: 2.916639804840088
Validation loss: 2.3781060070119877

Epoch: 6| Step: 4
Training loss: 2.015219211578369
Validation loss: 2.403232712899485

Epoch: 6| Step: 5
Training loss: 2.5931873321533203
Validation loss: 2.411976198996267

Epoch: 6| Step: 6
Training loss: 3.116546392440796
Validation loss: 2.3631076300016014

Epoch: 6| Step: 7
Training loss: 2.467233180999756
Validation loss: 2.301208875512564

Epoch: 6| Step: 8
Training loss: 2.6314401626586914
Validation loss: 2.249452475578554

Epoch: 6| Step: 9
Training loss: 2.3305001258850098
Validation loss: 2.223706576132005

Epoch: 6| Step: 10
Training loss: 2.4407362937927246
Validation loss: 2.2191329079289592

Epoch: 6| Step: 11
Training loss: 2.7180347442626953
Validation loss: 2.2281395132823656

Epoch: 6| Step: 12
Training loss: 2.885408401489258
Validation loss: 2.2462879150144515

Epoch: 6| Step: 13
Training loss: 2.9893763065338135
Validation loss: 2.2290406611657914

Epoch: 61| Step: 0
Training loss: 2.0378048419952393
Validation loss: 2.2072692609602407

Epoch: 6| Step: 1
Training loss: 2.252002239227295
Validation loss: 2.1630049802923716

Epoch: 6| Step: 2
Training loss: 2.4850564002990723
Validation loss: 2.1631479494033323

Epoch: 6| Step: 3
Training loss: 2.4830353260040283
Validation loss: 2.1632229333282798

Epoch: 6| Step: 4
Training loss: 2.5002307891845703
Validation loss: 2.1534099989039923

Epoch: 6| Step: 5
Training loss: 2.1206881999969482
Validation loss: 2.1564973451757945

Epoch: 6| Step: 6
Training loss: 2.8154397010803223
Validation loss: 2.191997769058392

Epoch: 6| Step: 7
Training loss: 2.7013461589813232
Validation loss: 2.2211107028427945

Epoch: 6| Step: 8
Training loss: 1.865579605102539
Validation loss: 2.2653168042500815

Epoch: 6| Step: 9
Training loss: 2.5522165298461914
Validation loss: 2.3069131156449676

Epoch: 6| Step: 10
Training loss: 2.7376811504364014
Validation loss: 2.2782679039944886

Epoch: 6| Step: 11
Training loss: 1.7787102460861206
Validation loss: 2.2325564199878323

Epoch: 6| Step: 12
Training loss: 3.7432103157043457
Validation loss: 2.2033963382885022

Epoch: 6| Step: 13
Training loss: 2.9062037467956543
Validation loss: 2.172953772288497

Epoch: 62| Step: 0
Training loss: 2.495035171508789
Validation loss: 2.158798722810643

Epoch: 6| Step: 1
Training loss: 2.141397476196289
Validation loss: 2.1532674963756273

Epoch: 6| Step: 2
Training loss: 2.305875301361084
Validation loss: 2.144260762840189

Epoch: 6| Step: 3
Training loss: 1.928652048110962
Validation loss: 2.139521110442377

Epoch: 6| Step: 4
Training loss: 2.59554386138916
Validation loss: 2.149759850194377

Epoch: 6| Step: 5
Training loss: 3.0203046798706055
Validation loss: 2.1567862854208997

Epoch: 6| Step: 6
Training loss: 2.7568492889404297
Validation loss: 2.189274976330419

Epoch: 6| Step: 7
Training loss: 2.944044589996338
Validation loss: 2.2273582540532595

Epoch: 6| Step: 8
Training loss: 2.5802063941955566
Validation loss: 2.2138681642470823

Epoch: 6| Step: 9
Training loss: 2.1787476539611816
Validation loss: 2.199340166584138

Epoch: 6| Step: 10
Training loss: 2.496497631072998
Validation loss: 2.1822207589303293

Epoch: 6| Step: 11
Training loss: 2.2067837715148926
Validation loss: 2.184919354736164

Epoch: 6| Step: 12
Training loss: 2.356606960296631
Validation loss: 2.1628016758990545

Epoch: 6| Step: 13
Training loss: 2.0693578720092773
Validation loss: 2.137629617926895

Epoch: 63| Step: 0
Training loss: 3.0296130180358887
Validation loss: 2.129597063987486

Epoch: 6| Step: 1
Training loss: 2.7234373092651367
Validation loss: 2.1324843283622497

Epoch: 6| Step: 2
Training loss: 2.7296788692474365
Validation loss: 2.132819847394061

Epoch: 6| Step: 3
Training loss: 2.6495227813720703
Validation loss: 2.1354304026531916

Epoch: 6| Step: 4
Training loss: 2.8639721870422363
Validation loss: 2.1318730846528084

Epoch: 6| Step: 5
Training loss: 1.544740080833435
Validation loss: 2.1292224289268575

Epoch: 6| Step: 6
Training loss: 2.1697826385498047
Validation loss: 2.132899301026457

Epoch: 6| Step: 7
Training loss: 2.4197988510131836
Validation loss: 2.13592630047952

Epoch: 6| Step: 8
Training loss: 2.8838510513305664
Validation loss: 2.1322199093398226

Epoch: 6| Step: 9
Training loss: 2.551927089691162
Validation loss: 2.1338076770946546

Epoch: 6| Step: 10
Training loss: 2.4339382648468018
Validation loss: 2.1583088264670423

Epoch: 6| Step: 11
Training loss: 2.1738929748535156
Validation loss: 2.2027433533822336

Epoch: 6| Step: 12
Training loss: 2.0661091804504395
Validation loss: 2.2530163641898864

Epoch: 6| Step: 13
Training loss: 2.124577283859253
Validation loss: 2.28203486370784

Epoch: 64| Step: 0
Training loss: 2.1429765224456787
Validation loss: 2.2712446412732525

Epoch: 6| Step: 1
Training loss: 2.3281404972076416
Validation loss: 2.2494037202609483

Epoch: 6| Step: 2
Training loss: 2.0589799880981445
Validation loss: 2.1781691107698666

Epoch: 6| Step: 3
Training loss: 2.79984188079834
Validation loss: 2.124630130747313

Epoch: 6| Step: 4
Training loss: 2.1931991577148438
Validation loss: 2.1204453668286725

Epoch: 6| Step: 5
Training loss: 2.023895740509033
Validation loss: 2.1205401830775763

Epoch: 6| Step: 6
Training loss: 3.3236942291259766
Validation loss: 2.1360542953655286

Epoch: 6| Step: 7
Training loss: 2.794696569442749
Validation loss: 2.16551834793501

Epoch: 6| Step: 8
Training loss: 2.3570189476013184
Validation loss: 2.214854044298972

Epoch: 6| Step: 9
Training loss: 3.307011604309082
Validation loss: 2.2247514699095037

Epoch: 6| Step: 10
Training loss: 2.563594341278076
Validation loss: 2.215516580048428

Epoch: 6| Step: 11
Training loss: 2.458836555480957
Validation loss: 2.1890647565164874

Epoch: 6| Step: 12
Training loss: 2.419743299484253
Validation loss: 2.174060265223185

Epoch: 6| Step: 13
Training loss: 2.556541681289673
Validation loss: 2.147491584541977

Epoch: 65| Step: 0
Training loss: 2.801844596862793
Validation loss: 2.1236328668491815

Epoch: 6| Step: 1
Training loss: 3.2217769622802734
Validation loss: 2.1163899462710143

Epoch: 6| Step: 2
Training loss: 2.1309268474578857
Validation loss: 2.1193980760471796

Epoch: 6| Step: 3
Training loss: 2.486276626586914
Validation loss: 2.1214725791767077

Epoch: 6| Step: 4
Training loss: 1.720515251159668
Validation loss: 2.1157889750696

Epoch: 6| Step: 5
Training loss: 2.2424840927124023
Validation loss: 2.141183243002943

Epoch: 6| Step: 6
Training loss: 1.8809318542480469
Validation loss: 2.177197710160286

Epoch: 6| Step: 7
Training loss: 2.333984851837158
Validation loss: 2.196547838949388

Epoch: 6| Step: 8
Training loss: 3.3515384197235107
Validation loss: 2.22466157585062

Epoch: 6| Step: 9
Training loss: 1.7910792827606201
Validation loss: 2.1820380098076275

Epoch: 6| Step: 10
Training loss: 2.879671335220337
Validation loss: 2.1589139635844896

Epoch: 6| Step: 11
Training loss: 2.7935028076171875
Validation loss: 2.142666739802207

Epoch: 6| Step: 12
Training loss: 2.0708909034729004
Validation loss: 2.134513424288842

Epoch: 6| Step: 13
Training loss: 3.0997395515441895
Validation loss: 2.1305801124982935

Epoch: 66| Step: 0
Training loss: 2.8486361503601074
Validation loss: 2.1235224072651198

Epoch: 6| Step: 1
Training loss: 2.708592414855957
Validation loss: 2.1235853023426507

Epoch: 6| Step: 2
Training loss: 2.6040544509887695
Validation loss: 2.1134108138340775

Epoch: 6| Step: 3
Training loss: 2.604980945587158
Validation loss: 2.1169330714851298

Epoch: 6| Step: 4
Training loss: 3.0244736671447754
Validation loss: 2.11631299859734

Epoch: 6| Step: 5
Training loss: 1.9690868854522705
Validation loss: 2.121078073337514

Epoch: 6| Step: 6
Training loss: 2.5003252029418945
Validation loss: 2.1267625234460317

Epoch: 6| Step: 7
Training loss: 2.232698917388916
Validation loss: 2.116357543135202

Epoch: 6| Step: 8
Training loss: 2.156459331512451
Validation loss: 2.120903431728322

Epoch: 6| Step: 9
Training loss: 2.7411389350891113
Validation loss: 2.1215714485414567

Epoch: 6| Step: 10
Training loss: 1.840084433555603
Validation loss: 2.124625903303905

Epoch: 6| Step: 11
Training loss: 1.621999740600586
Validation loss: 2.1491209063478696

Epoch: 6| Step: 12
Training loss: 2.8614351749420166
Validation loss: 2.170909179154263

Epoch: 6| Step: 13
Training loss: 2.007000207901001
Validation loss: 2.1837508857891126

Epoch: 67| Step: 0
Training loss: 3.4228217601776123
Validation loss: 2.155225573047515

Epoch: 6| Step: 1
Training loss: 1.9832470417022705
Validation loss: 2.1543054785779727

Epoch: 6| Step: 2
Training loss: 1.9165812730789185
Validation loss: 2.142345557930649

Epoch: 6| Step: 3
Training loss: 2.3774969577789307
Validation loss: 2.1483737140573482

Epoch: 6| Step: 4
Training loss: 2.4464354515075684
Validation loss: 2.1253344358936435

Epoch: 6| Step: 5
Training loss: 2.6190266609191895
Validation loss: 2.10749610136914

Epoch: 6| Step: 6
Training loss: 2.786135196685791
Validation loss: 2.0994872790510937

Epoch: 6| Step: 7
Training loss: 1.9685964584350586
Validation loss: 2.1003589860854612

Epoch: 6| Step: 8
Training loss: 2.676347255706787
Validation loss: 2.093892461510115

Epoch: 6| Step: 9
Training loss: 2.3610341548919678
Validation loss: 2.0992249135048158

Epoch: 6| Step: 10
Training loss: 2.194577217102051
Validation loss: 2.0968863502625497

Epoch: 6| Step: 11
Training loss: 2.203958511352539
Validation loss: 2.102034189367807

Epoch: 6| Step: 12
Training loss: 2.186819553375244
Validation loss: 2.099858728788232

Epoch: 6| Step: 13
Training loss: 2.517627716064453
Validation loss: 2.1032340347125964

Epoch: 68| Step: 0
Training loss: 2.161592960357666
Validation loss: 2.1175610275678736

Epoch: 6| Step: 1
Training loss: 2.897871255874634
Validation loss: 2.176415176801784

Epoch: 6| Step: 2
Training loss: 2.72371768951416
Validation loss: 2.2780691705724245

Epoch: 6| Step: 3
Training loss: 2.4572622776031494
Validation loss: 2.3683533822336504

Epoch: 6| Step: 4
Training loss: 2.32210373878479
Validation loss: 2.382195888027068

Epoch: 6| Step: 5
Training loss: 2.677882194519043
Validation loss: 2.339910243147163

Epoch: 6| Step: 6
Training loss: 2.4070000648498535
Validation loss: 2.263466336393869

Epoch: 6| Step: 7
Training loss: 2.413963794708252
Validation loss: 2.1968359408840055

Epoch: 6| Step: 8
Training loss: 2.565308094024658
Validation loss: 2.1239137470081286

Epoch: 6| Step: 9
Training loss: 2.2601795196533203
Validation loss: 2.100120485469859

Epoch: 6| Step: 10
Training loss: 2.4153594970703125
Validation loss: 2.097436953616399

Epoch: 6| Step: 11
Training loss: 2.5971076488494873
Validation loss: 2.0963137893266577

Epoch: 6| Step: 12
Training loss: 2.390934944152832
Validation loss: 2.107670671196394

Epoch: 6| Step: 13
Training loss: 2.077404260635376
Validation loss: 2.1207340558369956

Epoch: 69| Step: 0
Training loss: 2.501574754714966
Validation loss: 2.1304816840797343

Epoch: 6| Step: 1
Training loss: 2.6836905479431152
Validation loss: 2.139271810490598

Epoch: 6| Step: 2
Training loss: 2.6360208988189697
Validation loss: 2.1246301717655633

Epoch: 6| Step: 3
Training loss: 2.7027132511138916
Validation loss: 2.1077409918590257

Epoch: 6| Step: 4
Training loss: 2.2393317222595215
Validation loss: 2.103198782090218

Epoch: 6| Step: 5
Training loss: 3.008843421936035
Validation loss: 2.098906499083324

Epoch: 6| Step: 6
Training loss: 2.5543155670166016
Validation loss: 2.0997098915038572

Epoch: 6| Step: 7
Training loss: 1.894608736038208
Validation loss: 2.0976961812665387

Epoch: 6| Step: 8
Training loss: 2.858954668045044
Validation loss: 2.091962304166568

Epoch: 6| Step: 9
Training loss: 2.5191566944122314
Validation loss: 2.0927693010658346

Epoch: 6| Step: 10
Training loss: 3.3466014862060547
Validation loss: 2.0922654315989506

Epoch: 6| Step: 11
Training loss: 1.7198536396026611
Validation loss: 2.1021883231337353

Epoch: 6| Step: 12
Training loss: 1.8791518211364746
Validation loss: 2.0947511760137414

Epoch: 6| Step: 13
Training loss: 2.0297861099243164
Validation loss: 2.1023942501314226

Epoch: 70| Step: 0
Training loss: 2.041930675506592
Validation loss: 2.1189175575010237

Epoch: 6| Step: 1
Training loss: 2.3761868476867676
Validation loss: 2.129383966486941

Epoch: 6| Step: 2
Training loss: 1.9745591878890991
Validation loss: 2.12863407340101

Epoch: 6| Step: 3
Training loss: 2.405381917953491
Validation loss: 2.1229871857550835

Epoch: 6| Step: 4
Training loss: 2.7726988792419434
Validation loss: 2.1074068059203444

Epoch: 6| Step: 5
Training loss: 1.6871278285980225
Validation loss: 2.0972298524713002

Epoch: 6| Step: 6
Training loss: 2.521622896194458
Validation loss: 2.098708506553404

Epoch: 6| Step: 7
Training loss: 3.025855541229248
Validation loss: 2.0914289592414774

Epoch: 6| Step: 8
Training loss: 2.324049472808838
Validation loss: 2.0953019716406382

Epoch: 6| Step: 9
Training loss: 3.3310422897338867
Validation loss: 2.0876737076749086

Epoch: 6| Step: 10
Training loss: 2.397952079772949
Validation loss: 2.09133945357415

Epoch: 6| Step: 11
Training loss: 2.0056309700012207
Validation loss: 2.079303947828149

Epoch: 6| Step: 12
Training loss: 1.8497445583343506
Validation loss: 2.077482464492962

Epoch: 6| Step: 13
Training loss: 2.7599048614501953
Validation loss: 2.092368438679685

Epoch: 71| Step: 0
Training loss: 2.653777837753296
Validation loss: 2.095261650700723

Epoch: 6| Step: 1
Training loss: 1.9611663818359375
Validation loss: 2.0969539252660607

Epoch: 6| Step: 2
Training loss: 2.0843470096588135
Validation loss: 2.1000253885023055

Epoch: 6| Step: 3
Training loss: 2.6757192611694336
Validation loss: 2.096399435433008

Epoch: 6| Step: 4
Training loss: 2.875065803527832
Validation loss: 2.096828240220265

Epoch: 6| Step: 5
Training loss: 2.207733154296875
Validation loss: 2.0920892684690413

Epoch: 6| Step: 6
Training loss: 2.3288676738739014
Validation loss: 2.097003356102974

Epoch: 6| Step: 7
Training loss: 2.807568073272705
Validation loss: 2.104675503187282

Epoch: 6| Step: 8
Training loss: 2.5096025466918945
Validation loss: 2.081730819517566

Epoch: 6| Step: 9
Training loss: 2.2119081020355225
Validation loss: 2.076283824059271

Epoch: 6| Step: 10
Training loss: 2.7312941551208496
Validation loss: 2.06325162354336

Epoch: 6| Step: 11
Training loss: 2.0657691955566406
Validation loss: 2.071736192190519

Epoch: 6| Step: 12
Training loss: 1.8217179775238037
Validation loss: 2.071931705679945

Epoch: 6| Step: 13
Training loss: 2.4783270359039307
Validation loss: 2.0743062470548894

Epoch: 72| Step: 0
Training loss: 2.339801549911499
Validation loss: 2.08349750503417

Epoch: 6| Step: 1
Training loss: 2.006868839263916
Validation loss: 2.0958150920047554

Epoch: 6| Step: 2
Training loss: 2.7112441062927246
Validation loss: 2.0916277413727133

Epoch: 6| Step: 3
Training loss: 2.0796494483947754
Validation loss: 2.1042230359969603

Epoch: 6| Step: 4
Training loss: 1.9116981029510498
Validation loss: 2.109009911937098

Epoch: 6| Step: 5
Training loss: 2.5368330478668213
Validation loss: 2.1260781775238695

Epoch: 6| Step: 6
Training loss: 2.6732301712036133
Validation loss: 2.1026607918482956

Epoch: 6| Step: 7
Training loss: 1.7800670862197876
Validation loss: 2.110937503076369

Epoch: 6| Step: 8
Training loss: 2.6017510890960693
Validation loss: 2.078224041128671

Epoch: 6| Step: 9
Training loss: 2.3891568183898926
Validation loss: 2.0650840318331154

Epoch: 6| Step: 10
Training loss: 2.190155029296875
Validation loss: 2.072658695200438

Epoch: 6| Step: 11
Training loss: 2.933443069458008
Validation loss: 2.0689955347327778

Epoch: 6| Step: 12
Training loss: 2.8401293754577637
Validation loss: 2.071340596804055

Epoch: 6| Step: 13
Training loss: 2.1361987590789795
Validation loss: 2.067349228807675

Epoch: 73| Step: 0
Training loss: 2.3155770301818848
Validation loss: 2.0663357998735163

Epoch: 6| Step: 1
Training loss: 2.2781903743743896
Validation loss: 2.060781773700509

Epoch: 6| Step: 2
Training loss: 2.8774986267089844
Validation loss: 2.0656415647076023

Epoch: 6| Step: 3
Training loss: 3.2260661125183105
Validation loss: 2.051659991664271

Epoch: 6| Step: 4
Training loss: 2.1045920848846436
Validation loss: 2.0521554100898003

Epoch: 6| Step: 5
Training loss: 2.4040822982788086
Validation loss: 2.049042299229612

Epoch: 6| Step: 6
Training loss: 1.8289507627487183
Validation loss: 2.071625477524214

Epoch: 6| Step: 7
Training loss: 2.697390556335449
Validation loss: 2.120686379812097

Epoch: 6| Step: 8
Training loss: 2.62847900390625
Validation loss: 2.1356590178705033

Epoch: 6| Step: 9
Training loss: 2.1044020652770996
Validation loss: 2.1498031334210466

Epoch: 6| Step: 10
Training loss: 2.312840461730957
Validation loss: 2.140512620249102

Epoch: 6| Step: 11
Training loss: 1.9981008768081665
Validation loss: 2.115429873107582

Epoch: 6| Step: 12
Training loss: 1.9832079410552979
Validation loss: 2.094210669558535

Epoch: 6| Step: 13
Training loss: 2.8816099166870117
Validation loss: 2.0677174150302844

Epoch: 74| Step: 0
Training loss: 2.457828998565674
Validation loss: 2.06759367194227

Epoch: 6| Step: 1
Training loss: 2.1824088096618652
Validation loss: 2.0605458085254957

Epoch: 6| Step: 2
Training loss: 2.4188661575317383
Validation loss: 2.051284049146919

Epoch: 6| Step: 3
Training loss: 2.1655495166778564
Validation loss: 2.0657274748689387

Epoch: 6| Step: 4
Training loss: 2.274562120437622
Validation loss: 2.0590057014137186

Epoch: 6| Step: 5
Training loss: 2.5335512161254883
Validation loss: 2.0874800861522718

Epoch: 6| Step: 6
Training loss: 2.1394643783569336
Validation loss: 2.1009562938444075

Epoch: 6| Step: 7
Training loss: 2.5034351348876953
Validation loss: 2.1180022519121886

Epoch: 6| Step: 8
Training loss: 2.355945110321045
Validation loss: 2.1494064920692035

Epoch: 6| Step: 9
Training loss: 2.5691792964935303
Validation loss: 2.131747735443936

Epoch: 6| Step: 10
Training loss: 1.9603891372680664
Validation loss: 2.140457735266737

Epoch: 6| Step: 11
Training loss: 2.623276948928833
Validation loss: 2.1389711056986163

Epoch: 6| Step: 12
Training loss: 2.4213056564331055
Validation loss: 2.1012102301402757

Epoch: 6| Step: 13
Training loss: 2.4927918910980225
Validation loss: 2.072654369056866

Epoch: 75| Step: 0
Training loss: 2.398789644241333
Validation loss: 2.0527629826658513

Epoch: 6| Step: 1
Training loss: 2.162860870361328
Validation loss: 2.0496189260995514

Epoch: 6| Step: 2
Training loss: 2.634376049041748
Validation loss: 2.0479205269967355

Epoch: 6| Step: 3
Training loss: 2.8240644931793213
Validation loss: 2.0458246123406196

Epoch: 6| Step: 4
Training loss: 2.3307902812957764
Validation loss: 2.0472197250653337

Epoch: 6| Step: 5
Training loss: 2.633455514907837
Validation loss: 2.0550738739710983

Epoch: 6| Step: 6
Training loss: 2.5708394050598145
Validation loss: 2.0479212319979103

Epoch: 6| Step: 7
Training loss: 1.9230318069458008
Validation loss: 2.0496130681806997

Epoch: 6| Step: 8
Training loss: 2.601966619491577
Validation loss: 2.045234682739422

Epoch: 6| Step: 9
Training loss: 2.5989327430725098
Validation loss: 2.048384271642213

Epoch: 6| Step: 10
Training loss: 1.6592828035354614
Validation loss: 2.0511582910373645

Epoch: 6| Step: 11
Training loss: 2.290148973464966
Validation loss: 2.0707080082226823

Epoch: 6| Step: 12
Training loss: 2.009459972381592
Validation loss: 2.0954680391537246

Epoch: 6| Step: 13
Training loss: 2.7678651809692383
Validation loss: 2.110441005358132

Epoch: 76| Step: 0
Training loss: 2.6237576007843018
Validation loss: 2.1359889609839326

Epoch: 6| Step: 1
Training loss: 1.7687995433807373
Validation loss: 2.162202754328328

Epoch: 6| Step: 2
Training loss: 3.021638870239258
Validation loss: 2.1892304394834783

Epoch: 6| Step: 3
Training loss: 2.5523972511291504
Validation loss: 2.213196954419536

Epoch: 6| Step: 4
Training loss: 1.7464947700500488
Validation loss: 2.2025745402100267

Epoch: 6| Step: 5
Training loss: 2.0690665245056152
Validation loss: 2.1675538837268786

Epoch: 6| Step: 6
Training loss: 2.308396100997925
Validation loss: 2.120958951211745

Epoch: 6| Step: 7
Training loss: 2.406571388244629
Validation loss: 2.091640664685157

Epoch: 6| Step: 8
Training loss: 2.131333351135254
Validation loss: 2.055618688624392

Epoch: 6| Step: 9
Training loss: 3.2530665397644043
Validation loss: 2.04463626492408

Epoch: 6| Step: 10
Training loss: 2.0499472618103027
Validation loss: 2.044196012199566

Epoch: 6| Step: 11
Training loss: 2.316112518310547
Validation loss: 2.0518525505578644

Epoch: 6| Step: 12
Training loss: 2.372873306274414
Validation loss: 2.053314878094581

Epoch: 6| Step: 13
Training loss: 2.060835123062134
Validation loss: 2.0430444107260755

Epoch: 77| Step: 0
Training loss: 2.636093854904175
Validation loss: 2.04188048455023

Epoch: 6| Step: 1
Training loss: 2.4359474182128906
Validation loss: 2.0396153926849365

Epoch: 6| Step: 2
Training loss: 2.5229358673095703
Validation loss: 2.0378280506339124

Epoch: 6| Step: 3
Training loss: 2.089632034301758
Validation loss: 2.03284671614247

Epoch: 6| Step: 4
Training loss: 3.0923523902893066
Validation loss: 2.0553301777890933

Epoch: 6| Step: 5
Training loss: 2.431293487548828
Validation loss: 2.053664327949606

Epoch: 6| Step: 6
Training loss: 2.1392884254455566
Validation loss: 2.0609647035598755

Epoch: 6| Step: 7
Training loss: 2.329270362854004
Validation loss: 2.074425756290395

Epoch: 6| Step: 8
Training loss: 2.2802696228027344
Validation loss: 2.0661121388917327

Epoch: 6| Step: 9
Training loss: 2.0238778591156006
Validation loss: 2.081311624537232

Epoch: 6| Step: 10
Training loss: 2.349351406097412
Validation loss: 2.095573099710608

Epoch: 6| Step: 11
Training loss: 1.7496410608291626
Validation loss: 2.1114751677359305

Epoch: 6| Step: 12
Training loss: 2.60392689704895
Validation loss: 2.110319032463976

Epoch: 6| Step: 13
Training loss: 2.330148935317993
Validation loss: 2.0933287425707747

Epoch: 78| Step: 0
Training loss: 1.6175123453140259
Validation loss: 2.0968348518494637

Epoch: 6| Step: 1
Training loss: 2.8186802864074707
Validation loss: 2.0734181557932208

Epoch: 6| Step: 2
Training loss: 3.180995464324951
Validation loss: 2.0652944528928368

Epoch: 6| Step: 3
Training loss: 2.5411875247955322
Validation loss: 2.0559319988373788

Epoch: 6| Step: 4
Training loss: 1.9530601501464844
Validation loss: 2.049780479041479

Epoch: 6| Step: 5
Training loss: 2.168490171432495
Validation loss: 2.058120781375516

Epoch: 6| Step: 6
Training loss: 1.8539183139801025
Validation loss: 2.040198977275561

Epoch: 6| Step: 7
Training loss: 2.6057910919189453
Validation loss: 2.040343112843011

Epoch: 6| Step: 8
Training loss: 2.0456433296203613
Validation loss: 2.080722347382576

Epoch: 6| Step: 9
Training loss: 2.4417691230773926
Validation loss: 2.1302294449139665

Epoch: 6| Step: 10
Training loss: 2.499804973602295
Validation loss: 2.186040693713773

Epoch: 6| Step: 11
Training loss: 2.2331581115722656
Validation loss: 2.1894189990976805

Epoch: 6| Step: 12
Training loss: 2.584275245666504
Validation loss: 2.136665003274077

Epoch: 6| Step: 13
Training loss: 1.7028952836990356
Validation loss: 2.0789552170743226

Epoch: 79| Step: 0
Training loss: 2.7546563148498535
Validation loss: 2.0356346420062486

Epoch: 6| Step: 1
Training loss: 2.6191444396972656
Validation loss: 2.030194874732725

Epoch: 6| Step: 2
Training loss: 2.015594959259033
Validation loss: 2.0214582361200804

Epoch: 6| Step: 3
Training loss: 2.0756945610046387
Validation loss: 2.03507722193195

Epoch: 6| Step: 4
Training loss: 3.1167993545532227
Validation loss: 2.0264968487524215

Epoch: 6| Step: 5
Training loss: 2.1142454147338867
Validation loss: 2.0296563102353002

Epoch: 6| Step: 6
Training loss: 2.0727643966674805
Validation loss: 2.029172674302132

Epoch: 6| Step: 7
Training loss: 2.8031415939331055
Validation loss: 2.0175454719092256

Epoch: 6| Step: 8
Training loss: 2.4377877712249756
Validation loss: 2.0487246000638573

Epoch: 6| Step: 9
Training loss: 2.0890419483184814
Validation loss: 2.086829762304983

Epoch: 6| Step: 10
Training loss: 2.0846006870269775
Validation loss: 2.090376559124198

Epoch: 6| Step: 11
Training loss: 2.135647773742676
Validation loss: 2.134350807436051

Epoch: 6| Step: 12
Training loss: 2.3906097412109375
Validation loss: 2.1543633425107567

Epoch: 6| Step: 13
Training loss: 1.6893144845962524
Validation loss: 2.1207088193585797

Epoch: 80| Step: 0
Training loss: 2.0543863773345947
Validation loss: 2.064117039403608

Epoch: 6| Step: 1
Training loss: 2.6554980278015137
Validation loss: 2.0305612523068666

Epoch: 6| Step: 2
Training loss: 2.388463020324707
Validation loss: 2.0269005401160127

Epoch: 6| Step: 3
Training loss: 1.9800012111663818
Validation loss: 2.0333542990428146

Epoch: 6| Step: 4
Training loss: 2.5536835193634033
Validation loss: 2.0401523087614324

Epoch: 6| Step: 5
Training loss: 2.4509031772613525
Validation loss: 2.0363628402833016

Epoch: 6| Step: 6
Training loss: 2.760556697845459
Validation loss: 2.0361884319654076

Epoch: 6| Step: 7
Training loss: 2.1909446716308594
Validation loss: 2.0418793039937175

Epoch: 6| Step: 8
Training loss: 2.751400947570801
Validation loss: 2.0377091541085193

Epoch: 6| Step: 9
Training loss: 2.7385916709899902
Validation loss: 2.0454791002376105

Epoch: 6| Step: 10
Training loss: 1.6874973773956299
Validation loss: 2.059899285275449

Epoch: 6| Step: 11
Training loss: 2.4404563903808594
Validation loss: 2.070901886109383

Epoch: 6| Step: 12
Training loss: 2.635108470916748
Validation loss: 2.085156956026631

Epoch: 6| Step: 13
Training loss: 2.222872495651245
Validation loss: 2.056447721296741

Epoch: 81| Step: 0
Training loss: 1.3824996948242188
Validation loss: 2.1007224949457313

Epoch: 6| Step: 1
Training loss: 2.609433650970459
Validation loss: 2.254969467398941

Epoch: 6| Step: 2
Training loss: 3.0281434059143066
Validation loss: 2.2735842645809217

Epoch: 6| Step: 3
Training loss: 3.1886096000671387
Validation loss: 2.244933292429934

Epoch: 6| Step: 4
Training loss: 3.038576126098633
Validation loss: 2.182575382212157

Epoch: 6| Step: 5
Training loss: 2.6455063819885254
Validation loss: 2.146112570198633

Epoch: 6| Step: 6
Training loss: 2.3422374725341797
Validation loss: 2.1103957007008214

Epoch: 6| Step: 7
Training loss: 1.759098768234253
Validation loss: 2.081004269661442

Epoch: 6| Step: 8
Training loss: 1.9824059009552002
Validation loss: 2.089934766933482

Epoch: 6| Step: 9
Training loss: 1.700840711593628
Validation loss: 2.135615941016905

Epoch: 6| Step: 10
Training loss: 1.75771164894104
Validation loss: 2.2189222292233537

Epoch: 6| Step: 11
Training loss: 2.080221176147461
Validation loss: 2.2819472999982935

Epoch: 6| Step: 12
Training loss: 3.140428066253662
Validation loss: 2.2879261983338224

Epoch: 6| Step: 13
Training loss: 2.6861867904663086
Validation loss: 2.2537495205479283

Epoch: 82| Step: 0
Training loss: 1.9982351064682007
Validation loss: 2.1509294099705194

Epoch: 6| Step: 1
Training loss: 2.1979928016662598
Validation loss: 2.061379571114817

Epoch: 6| Step: 2
Training loss: 2.482151508331299
Validation loss: 2.0269309038756997

Epoch: 6| Step: 3
Training loss: 2.3737847805023193
Validation loss: 2.0270861451343825

Epoch: 6| Step: 4
Training loss: 2.637634038925171
Validation loss: 2.0114461068184144

Epoch: 6| Step: 5
Training loss: 2.497814655303955
Validation loss: 2.000511415543095

Epoch: 6| Step: 6
Training loss: 2.527507781982422
Validation loss: 2.00841050891466

Epoch: 6| Step: 7
Training loss: 2.623842477798462
Validation loss: 2.0457592164316485

Epoch: 6| Step: 8
Training loss: 2.2723422050476074
Validation loss: 2.04679968280177

Epoch: 6| Step: 9
Training loss: 2.08754563331604
Validation loss: 2.054587633379044

Epoch: 6| Step: 10
Training loss: 2.092644691467285
Validation loss: 2.0757838808080202

Epoch: 6| Step: 11
Training loss: 1.3169970512390137
Validation loss: 2.048140364308511

Epoch: 6| Step: 12
Training loss: 2.6554431915283203
Validation loss: 2.025327230012545

Epoch: 6| Step: 13
Training loss: 2.758172035217285
Validation loss: 2.015748152168848

Epoch: 83| Step: 0
Training loss: 3.108053684234619
Validation loss: 2.024245886392491

Epoch: 6| Step: 1
Training loss: 2.6770856380462646
Validation loss: 2.0373260590337936

Epoch: 6| Step: 2
Training loss: 1.82515549659729
Validation loss: 2.0361948013305664

Epoch: 6| Step: 3
Training loss: 2.2657012939453125
Validation loss: 2.0628296175310687

Epoch: 6| Step: 4
Training loss: 1.739283561706543
Validation loss: 2.0446527286242415

Epoch: 6| Step: 5
Training loss: 2.3884224891662598
Validation loss: 2.003202079444803

Epoch: 6| Step: 6
Training loss: 1.771894931793213
Validation loss: 2.0128146858625513

Epoch: 6| Step: 7
Training loss: 2.782806158065796
Validation loss: 2.0117715994517007

Epoch: 6| Step: 8
Training loss: 2.3751425743103027
Validation loss: 2.010888970026406

Epoch: 6| Step: 9
Training loss: 2.449657440185547
Validation loss: 2.0037680774606685

Epoch: 6| Step: 10
Training loss: 2.2483885288238525
Validation loss: 2.0149877661017963

Epoch: 6| Step: 11
Training loss: 1.889594554901123
Validation loss: 2.005797464360473

Epoch: 6| Step: 12
Training loss: 2.069714069366455
Validation loss: 2.013685803259573

Epoch: 6| Step: 13
Training loss: 2.404902219772339
Validation loss: 2.0284486214319863

Epoch: 84| Step: 0
Training loss: 1.964135766029358
Validation loss: 2.062895272367744

Epoch: 6| Step: 1
Training loss: 2.017124891281128
Validation loss: 2.077572919989145

Epoch: 6| Step: 2
Training loss: 2.390517473220825
Validation loss: 2.074533486879

Epoch: 6| Step: 3
Training loss: 2.3043277263641357
Validation loss: 2.0807791166408087

Epoch: 6| Step: 4
Training loss: 1.7548086643218994
Validation loss: 2.0378009016795824

Epoch: 6| Step: 5
Training loss: 2.700714588165283
Validation loss: 2.034773080579696

Epoch: 6| Step: 6
Training loss: 2.7720439434051514
Validation loss: 2.0437825725924585

Epoch: 6| Step: 7
Training loss: 2.5499000549316406
Validation loss: 2.040453689072722

Epoch: 6| Step: 8
Training loss: 2.743860960006714
Validation loss: 2.035422582780161

Epoch: 6| Step: 9
Training loss: 1.8602298498153687
Validation loss: 2.017679273441274

Epoch: 6| Step: 10
Training loss: 2.4871668815612793
Validation loss: 2.003766959713351

Epoch: 6| Step: 11
Training loss: 2.2912437915802
Validation loss: 2.0133600645167853

Epoch: 6| Step: 12
Training loss: 1.8029382228851318
Validation loss: 2.0130176800553516

Epoch: 6| Step: 13
Training loss: 2.2956531047821045
Validation loss: 2.0006290712664203

Epoch: 85| Step: 0
Training loss: 2.1472299098968506
Validation loss: 2.032396172964445

Epoch: 6| Step: 1
Training loss: 2.960236072540283
Validation loss: 2.056543529674571

Epoch: 6| Step: 2
Training loss: 2.491154193878174
Validation loss: 2.074536731166224

Epoch: 6| Step: 3
Training loss: 1.8463191986083984
Validation loss: 2.078641019841676

Epoch: 6| Step: 4
Training loss: 2.4613428115844727
Validation loss: 2.0347265646021855

Epoch: 6| Step: 5
Training loss: 2.4465508460998535
Validation loss: 2.020515536749235

Epoch: 6| Step: 6
Training loss: 2.7813830375671387
Validation loss: 2.0000171943377425

Epoch: 6| Step: 7
Training loss: 2.6286003589630127
Validation loss: 2.0037485335462835

Epoch: 6| Step: 8
Training loss: 2.2666187286376953
Validation loss: 1.9971188652899958

Epoch: 6| Step: 9
Training loss: 1.6487308740615845
Validation loss: 1.9951689743226575

Epoch: 6| Step: 10
Training loss: 1.5746322870254517
Validation loss: 1.9956475509110319

Epoch: 6| Step: 11
Training loss: 2.1736528873443604
Validation loss: 2.0085417814152215

Epoch: 6| Step: 12
Training loss: 1.9692878723144531
Validation loss: 2.043679360420473

Epoch: 6| Step: 13
Training loss: 2.3827311992645264
Validation loss: 2.085007679077887

Epoch: 86| Step: 0
Training loss: 2.4714465141296387
Validation loss: 2.070959253977704

Epoch: 6| Step: 1
Training loss: 2.06231951713562
Validation loss: 2.0381580027200843

Epoch: 6| Step: 2
Training loss: 2.6766252517700195
Validation loss: 2.010929428121095

Epoch: 6| Step: 3
Training loss: 2.535277843475342
Validation loss: 2.004154089958437

Epoch: 6| Step: 4
Training loss: 2.083829402923584
Validation loss: 1.9925289230961953

Epoch: 6| Step: 5
Training loss: 1.2698637247085571
Validation loss: 2.003954064461493

Epoch: 6| Step: 6
Training loss: 2.1308305263519287
Validation loss: 1.9905049800872803

Epoch: 6| Step: 7
Training loss: 2.4343581199645996
Validation loss: 1.9964031762974237

Epoch: 6| Step: 8
Training loss: 2.4562981128692627
Validation loss: 2.00369861818129

Epoch: 6| Step: 9
Training loss: 2.6073384284973145
Validation loss: 1.996943699416294

Epoch: 6| Step: 10
Training loss: 2.71563982963562
Validation loss: 2.010950246164876

Epoch: 6| Step: 11
Training loss: 2.059890031814575
Validation loss: 2.005072315533956

Epoch: 6| Step: 12
Training loss: 1.6066992282867432
Validation loss: 2.023676900453465

Epoch: 6| Step: 13
Training loss: 2.326826810836792
Validation loss: 2.045256568539527

Epoch: 87| Step: 0
Training loss: 2.366971731185913
Validation loss: 2.0532607839953516

Epoch: 6| Step: 1
Training loss: 2.4050891399383545
Validation loss: 2.0380663782037716

Epoch: 6| Step: 2
Training loss: 2.0145044326782227
Validation loss: 2.003920626896684

Epoch: 6| Step: 3
Training loss: 2.408339023590088
Validation loss: 1.97655794184695

Epoch: 6| Step: 4
Training loss: 1.8015930652618408
Validation loss: 1.9842937172100108

Epoch: 6| Step: 5
Training loss: 2.1781623363494873
Validation loss: 1.9850198556018133

Epoch: 6| Step: 6
Training loss: 1.7013695240020752
Validation loss: 1.9761283038764872

Epoch: 6| Step: 7
Training loss: 2.031186103820801
Validation loss: 1.9847402393176992

Epoch: 6| Step: 8
Training loss: 1.7548174858093262
Validation loss: 2.0079127511670514

Epoch: 6| Step: 9
Training loss: 3.040708541870117
Validation loss: 2.05342613240724

Epoch: 6| Step: 10
Training loss: 2.3671953678131104
Validation loss: 2.1136960086002143

Epoch: 6| Step: 11
Training loss: 3.121534824371338
Validation loss: 2.1454551989032375

Epoch: 6| Step: 12
Training loss: 2.5381929874420166
Validation loss: 2.0967735346927436

Epoch: 6| Step: 13
Training loss: 2.416477918624878
Validation loss: 2.042209529107617

Epoch: 88| Step: 0
Training loss: 2.328310489654541
Validation loss: 2.009486861126397

Epoch: 6| Step: 1
Training loss: 2.8714728355407715
Validation loss: 2.0005393822987876

Epoch: 6| Step: 2
Training loss: 1.8924983739852905
Validation loss: 1.9952808336545063

Epoch: 6| Step: 3
Training loss: 2.2943644523620605
Validation loss: 2.0020455109175814

Epoch: 6| Step: 4
Training loss: 1.4214227199554443
Validation loss: 1.9898591938839163

Epoch: 6| Step: 5
Training loss: 2.3088974952697754
Validation loss: 1.9905698581408429

Epoch: 6| Step: 6
Training loss: 1.7716357707977295
Validation loss: 1.9871350706264537

Epoch: 6| Step: 7
Training loss: 2.3624892234802246
Validation loss: 2.0305415866195515

Epoch: 6| Step: 8
Training loss: 2.117279529571533
Validation loss: 2.034268856048584

Epoch: 6| Step: 9
Training loss: 1.7265042066574097
Validation loss: 2.0314150946114653

Epoch: 6| Step: 10
Training loss: 2.6966423988342285
Validation loss: 2.0446690436332458

Epoch: 6| Step: 11
Training loss: 2.0063893795013428
Validation loss: 2.0228127356498473

Epoch: 6| Step: 12
Training loss: 2.9540462493896484
Validation loss: 1.996073063983712

Epoch: 6| Step: 13
Training loss: 2.5565762519836426
Validation loss: 1.9781679004751227

Epoch: 89| Step: 0
Training loss: 1.9843090772628784
Validation loss: 1.9828524768993419

Epoch: 6| Step: 1
Training loss: 2.586556911468506
Validation loss: 1.9890384827890704

Epoch: 6| Step: 2
Training loss: 2.7101259231567383
Validation loss: 1.994617715958626

Epoch: 6| Step: 3
Training loss: 1.9506841897964478
Validation loss: 1.9951073328653972

Epoch: 6| Step: 4
Training loss: 1.763465404510498
Validation loss: 1.9965822030139226

Epoch: 6| Step: 5
Training loss: 2.4176087379455566
Validation loss: 2.003888839034624

Epoch: 6| Step: 6
Training loss: 2.5391275882720947
Validation loss: 2.0053005679961173

Epoch: 6| Step: 7
Training loss: 1.7609965801239014
Validation loss: 2.0153641598199004

Epoch: 6| Step: 8
Training loss: 2.360591411590576
Validation loss: 2.0092925948481404

Epoch: 6| Step: 9
Training loss: 2.0725038051605225
Validation loss: 2.0058905898883777

Epoch: 6| Step: 10
Training loss: 1.4251315593719482
Validation loss: 1.9776197184798538

Epoch: 6| Step: 11
Training loss: 2.2376177310943604
Validation loss: 1.9778976414793281

Epoch: 6| Step: 12
Training loss: 2.677365779876709
Validation loss: 1.9745139486046248

Epoch: 6| Step: 13
Training loss: 2.7496747970581055
Validation loss: 1.9695315578932404

Epoch: 90| Step: 0
Training loss: 1.7562028169631958
Validation loss: 1.9792127878435197

Epoch: 6| Step: 1
Training loss: 2.6939361095428467
Validation loss: 1.986931404759807

Epoch: 6| Step: 2
Training loss: 2.378983497619629
Validation loss: 1.999177776357179

Epoch: 6| Step: 3
Training loss: 2.7405738830566406
Validation loss: 1.9934807336458595

Epoch: 6| Step: 4
Training loss: 2.097850799560547
Validation loss: 2.00684775844697

Epoch: 6| Step: 5
Training loss: 2.120680332183838
Validation loss: 2.0093523968932447

Epoch: 6| Step: 6
Training loss: 2.532412052154541
Validation loss: 2.0246637149523665

Epoch: 6| Step: 7
Training loss: 2.615295648574829
Validation loss: 2.012927157904512

Epoch: 6| Step: 8
Training loss: 1.8039748668670654
Validation loss: 1.9754265508344095

Epoch: 6| Step: 9
Training loss: 2.2835137844085693
Validation loss: 1.9758096369363929

Epoch: 6| Step: 10
Training loss: 1.778940200805664
Validation loss: 1.9851919861250027

Epoch: 6| Step: 11
Training loss: 2.0822603702545166
Validation loss: 1.9988930789373254

Epoch: 6| Step: 12
Training loss: 2.0283138751983643
Validation loss: 2.0123865527491414

Epoch: 6| Step: 13
Training loss: 1.8895893096923828
Validation loss: 2.013797075517716

Epoch: 91| Step: 0
Training loss: 2.282787799835205
Validation loss: 2.000025628715433

Epoch: 6| Step: 1
Training loss: 2.1061229705810547
Validation loss: 1.9866359528674875

Epoch: 6| Step: 2
Training loss: 2.565805673599243
Validation loss: 1.9920394958988312

Epoch: 6| Step: 3
Training loss: 1.916927695274353
Validation loss: 1.9816646499018515

Epoch: 6| Step: 4
Training loss: 2.036473512649536
Validation loss: 1.9880497147960048

Epoch: 6| Step: 5
Training loss: 2.28663969039917
Validation loss: 1.9937108998657556

Epoch: 6| Step: 6
Training loss: 2.658912420272827
Validation loss: 2.0133037208228983

Epoch: 6| Step: 7
Training loss: 1.5002704858779907
Validation loss: 2.032316941086964

Epoch: 6| Step: 8
Training loss: 2.3336331844329834
Validation loss: 2.0430324885153

Epoch: 6| Step: 9
Training loss: 2.619002103805542
Validation loss: 2.036959973714685

Epoch: 6| Step: 10
Training loss: 1.8060096502304077
Validation loss: 2.000296086393377

Epoch: 6| Step: 11
Training loss: 1.9810775518417358
Validation loss: 1.9614116440537155

Epoch: 6| Step: 12
Training loss: 2.1473569869995117
Validation loss: 1.9561948071243942

Epoch: 6| Step: 13
Training loss: 3.3280272483825684
Validation loss: 1.9598095852841613

Epoch: 92| Step: 0
Training loss: 3.026608467102051
Validation loss: 1.967141051446238

Epoch: 6| Step: 1
Training loss: 2.5228281021118164
Validation loss: 1.9699771891358078

Epoch: 6| Step: 2
Training loss: 2.734029769897461
Validation loss: 1.9781167225171161

Epoch: 6| Step: 3
Training loss: 2.193574905395508
Validation loss: 2.007433432404713

Epoch: 6| Step: 4
Training loss: 2.35416316986084
Validation loss: 2.0225599427377023

Epoch: 6| Step: 5
Training loss: 2.014500141143799
Validation loss: 2.0468972754734818

Epoch: 6| Step: 6
Training loss: 1.8500460386276245
Validation loss: 2.0294858819694928

Epoch: 6| Step: 7
Training loss: 2.0898985862731934
Validation loss: 2.0164511998494468

Epoch: 6| Step: 8
Training loss: 1.9993932247161865
Validation loss: 1.9915430391988447

Epoch: 6| Step: 9
Training loss: 2.0436649322509766
Validation loss: 1.9840848932984054

Epoch: 6| Step: 10
Training loss: 2.3050904273986816
Validation loss: 1.976406648594846

Epoch: 6| Step: 11
Training loss: 2.0379140377044678
Validation loss: 1.9786837152255479

Epoch: 6| Step: 12
Training loss: 1.7485512495040894
Validation loss: 1.965870125319368

Epoch: 6| Step: 13
Training loss: 1.8541001081466675
Validation loss: 1.9737647079652356

Epoch: 93| Step: 0
Training loss: 2.22320818901062
Validation loss: 1.981185797722109

Epoch: 6| Step: 1
Training loss: 1.753872275352478
Validation loss: 1.9902133505831483

Epoch: 6| Step: 2
Training loss: 1.8283803462982178
Validation loss: 1.9904794539174726

Epoch: 6| Step: 3
Training loss: 2.2130990028381348
Validation loss: 1.990283776355046

Epoch: 6| Step: 4
Training loss: 2.376927375793457
Validation loss: 1.9830292386393393

Epoch: 6| Step: 5
Training loss: 2.9419753551483154
Validation loss: 1.9874348307168612

Epoch: 6| Step: 6
Training loss: 1.9673388004302979
Validation loss: 2.005353953248711

Epoch: 6| Step: 7
Training loss: 2.0075316429138184
Validation loss: 2.0290202351026636

Epoch: 6| Step: 8
Training loss: 2.462186098098755
Validation loss: 2.0523777187511487

Epoch: 6| Step: 9
Training loss: 2.6827304363250732
Validation loss: 2.081108708535471

Epoch: 6| Step: 10
Training loss: 1.7082915306091309
Validation loss: 2.057609317123249

Epoch: 6| Step: 11
Training loss: 1.8682767152786255
Validation loss: 2.0201590356006416

Epoch: 6| Step: 12
Training loss: 1.9743881225585938
Validation loss: 1.9896895539376043

Epoch: 6| Step: 13
Training loss: 3.027841806411743
Validation loss: 1.9772793426308581

Epoch: 94| Step: 0
Training loss: 2.3078646659851074
Validation loss: 1.983109325490972

Epoch: 6| Step: 1
Training loss: 2.0773768424987793
Validation loss: 1.9945920462249427

Epoch: 6| Step: 2
Training loss: 2.4829695224761963
Validation loss: 2.0174815039480887

Epoch: 6| Step: 3
Training loss: 2.3403913974761963
Validation loss: 2.044040036457841

Epoch: 6| Step: 4
Training loss: 2.3369333744049072
Validation loss: 2.068697379481408

Epoch: 6| Step: 5
Training loss: 2.4665441513061523
Validation loss: 2.0891316795861847

Epoch: 6| Step: 6
Training loss: 2.410088062286377
Validation loss: 2.1132697700172343

Epoch: 6| Step: 7
Training loss: 1.634476661682129
Validation loss: 2.115419908236432

Epoch: 6| Step: 8
Training loss: 2.0232105255126953
Validation loss: 2.1094107115140526

Epoch: 6| Step: 9
Training loss: 2.574772834777832
Validation loss: 2.0962597734184674

Epoch: 6| Step: 10
Training loss: 2.0889861583709717
Validation loss: 2.08228805757338

Epoch: 6| Step: 11
Training loss: 1.8519521951675415
Validation loss: 2.062923167341499

Epoch: 6| Step: 12
Training loss: 2.3465261459350586
Validation loss: 2.018777948553844

Epoch: 6| Step: 13
Training loss: 1.732757806777954
Validation loss: 2.0288434336262364

Epoch: 95| Step: 0
Training loss: 2.3843133449554443
Validation loss: 2.030078057319887

Epoch: 6| Step: 1
Training loss: 2.111938714981079
Validation loss: 2.030396733232724

Epoch: 6| Step: 2
Training loss: 2.5258970260620117
Validation loss: 2.0372051295413764

Epoch: 6| Step: 3
Training loss: 3.4561445713043213
Validation loss: 2.0274720794411114

Epoch: 6| Step: 4
Training loss: 1.9967947006225586
Validation loss: 2.0217169048965618

Epoch: 6| Step: 5
Training loss: 1.888392448425293
Validation loss: 2.013692359770498

Epoch: 6| Step: 6
Training loss: 1.8786970376968384
Validation loss: 1.996762446177903

Epoch: 6| Step: 7
Training loss: 2.4677419662475586
Validation loss: 1.971574834598008

Epoch: 6| Step: 8
Training loss: 2.761427402496338
Validation loss: 1.97918463137842

Epoch: 6| Step: 9
Training loss: 2.5338783264160156
Validation loss: 1.9660081350675194

Epoch: 6| Step: 10
Training loss: 2.132723331451416
Validation loss: 1.9578383558539934

Epoch: 6| Step: 11
Training loss: 1.8458240032196045
Validation loss: 1.956439793750804

Epoch: 6| Step: 12
Training loss: 1.898911714553833
Validation loss: 2.0044399653711626

Epoch: 6| Step: 13
Training loss: 1.6443803310394287
Validation loss: 2.026731724380165

Epoch: 96| Step: 0
Training loss: 1.8362927436828613
Validation loss: 2.017700333749094

Epoch: 6| Step: 1
Training loss: 2.2050836086273193
Validation loss: 2.012374770256781

Epoch: 6| Step: 2
Training loss: 1.8619951009750366
Validation loss: 1.9821357329686482

Epoch: 6| Step: 3
Training loss: 1.6066453456878662
Validation loss: 1.959693492099803

Epoch: 6| Step: 4
Training loss: 1.9954020977020264
Validation loss: 1.9458461871711157

Epoch: 6| Step: 5
Training loss: 1.8674901723861694
Validation loss: 1.9440583644374725

Epoch: 6| Step: 6
Training loss: 2.211207866668701
Validation loss: 1.9371280195892497

Epoch: 6| Step: 7
Training loss: 1.7549338340759277
Validation loss: 1.9343548705500941

Epoch: 6| Step: 8
Training loss: 2.934814453125
Validation loss: 1.9363223455285514

Epoch: 6| Step: 9
Training loss: 2.359168529510498
Validation loss: 1.9278302423415645

Epoch: 6| Step: 10
Training loss: 2.7364754676818848
Validation loss: 1.9534410097265755

Epoch: 6| Step: 11
Training loss: 2.9017333984375
Validation loss: 1.964353725474368

Epoch: 6| Step: 12
Training loss: 2.1145811080932617
Validation loss: 1.960669873863138

Epoch: 6| Step: 13
Training loss: 2.4827356338500977
Validation loss: 1.9433593762818204

Epoch: 97| Step: 0
Training loss: 2.0121326446533203
Validation loss: 1.9302362498416696

Epoch: 6| Step: 1
Training loss: 3.0550293922424316
Validation loss: 1.9277303680296867

Epoch: 6| Step: 2
Training loss: 2.6088318824768066
Validation loss: 1.934675233338469

Epoch: 6| Step: 3
Training loss: 2.435762405395508
Validation loss: 1.9311790184308124

Epoch: 6| Step: 4
Training loss: 2.4684200286865234
Validation loss: 1.9314876871724282

Epoch: 6| Step: 5
Training loss: 1.6662638187408447
Validation loss: 1.9302856127421062

Epoch: 6| Step: 6
Training loss: 2.7933478355407715
Validation loss: 1.929952121550037

Epoch: 6| Step: 7
Training loss: 1.0400590896606445
Validation loss: 1.9364579262272004

Epoch: 6| Step: 8
Training loss: 2.047882080078125
Validation loss: 1.9466974401986727

Epoch: 6| Step: 9
Training loss: 2.193446159362793
Validation loss: 1.9548402396581506

Epoch: 6| Step: 10
Training loss: 2.1429712772369385
Validation loss: 1.9598029736549623

Epoch: 6| Step: 11
Training loss: 1.151003122329712
Validation loss: 1.9569155375162761

Epoch: 6| Step: 12
Training loss: 2.134124755859375
Validation loss: 1.942361880374211

Epoch: 6| Step: 13
Training loss: 2.7720727920532227
Validation loss: 1.9407419132929977

Epoch: 98| Step: 0
Training loss: 2.569053888320923
Validation loss: 1.9462247612655803

Epoch: 6| Step: 1
Training loss: 2.605142593383789
Validation loss: 1.9470081701073596

Epoch: 6| Step: 2
Training loss: 2.179517984390259
Validation loss: 1.9448035173518683

Epoch: 6| Step: 3
Training loss: 2.256923198699951
Validation loss: 1.941333737424625

Epoch: 6| Step: 4
Training loss: 1.9288668632507324
Validation loss: 1.9524752504082137

Epoch: 6| Step: 5
Training loss: 2.594790458679199
Validation loss: 1.9776652013101885

Epoch: 6| Step: 6
Training loss: 1.9954098463058472
Validation loss: 1.9753716504702004

Epoch: 6| Step: 7
Training loss: 1.7337418794631958
Validation loss: 1.9777198709467405

Epoch: 6| Step: 8
Training loss: 2.2926316261291504
Validation loss: 1.9757991119097638

Epoch: 6| Step: 9
Training loss: 2.263167381286621
Validation loss: 1.9916535244193128

Epoch: 6| Step: 10
Training loss: 1.7024540901184082
Validation loss: 2.007769005272978

Epoch: 6| Step: 11
Training loss: 2.286980152130127
Validation loss: 2.027061511111516

Epoch: 6| Step: 12
Training loss: 1.9093575477600098
Validation loss: 2.0081779905544814

Epoch: 6| Step: 13
Training loss: 2.0460705757141113
Validation loss: 1.9831387266036002

Epoch: 99| Step: 0
Training loss: 2.1541337966918945
Validation loss: 1.994711583660495

Epoch: 6| Step: 1
Training loss: 2.5800821781158447
Validation loss: 1.998054547976422

Epoch: 6| Step: 2
Training loss: 2.1568799018859863
Validation loss: 1.9824856147971204

Epoch: 6| Step: 3
Training loss: 2.383625030517578
Validation loss: 1.961501762431155

Epoch: 6| Step: 4
Training loss: 2.549574375152588
Validation loss: 1.9313776121344617

Epoch: 6| Step: 5
Training loss: 2.3244361877441406
Validation loss: 1.9396246440948979

Epoch: 6| Step: 6
Training loss: 2.1122217178344727
Validation loss: 1.9345198190340431

Epoch: 6| Step: 7
Training loss: 2.0604796409606934
Validation loss: 1.9216122755440332

Epoch: 6| Step: 8
Training loss: 2.2517740726470947
Validation loss: 1.9417926316620202

Epoch: 6| Step: 9
Training loss: 2.4103963375091553
Validation loss: 1.9644159360598492

Epoch: 6| Step: 10
Training loss: 1.808210849761963
Validation loss: 1.9683077540448917

Epoch: 6| Step: 11
Training loss: 1.6531274318695068
Validation loss: 2.0044796800100677

Epoch: 6| Step: 12
Training loss: 2.307342767715454
Validation loss: 2.0170140048509

Epoch: 6| Step: 13
Training loss: 1.6839994192123413
Validation loss: 2.025913696135244

Epoch: 100| Step: 0
Training loss: 1.747506022453308
Validation loss: 2.0115785688482304

Epoch: 6| Step: 1
Training loss: 2.22102427482605
Validation loss: 2.0030535677427888

Epoch: 6| Step: 2
Training loss: 2.113138437271118
Validation loss: 1.989360527325702

Epoch: 6| Step: 3
Training loss: 2.7925777435302734
Validation loss: 1.9881129546832013

Epoch: 6| Step: 4
Training loss: 2.1383869647979736
Validation loss: 1.9816233893876434

Epoch: 6| Step: 5
Training loss: 3.2026824951171875
Validation loss: 1.979284171135195

Epoch: 6| Step: 6
Training loss: 1.3870477676391602
Validation loss: 1.9683104317675355

Epoch: 6| Step: 7
Training loss: 2.185762643814087
Validation loss: 1.964204898444555

Epoch: 6| Step: 8
Training loss: 2.4383115768432617
Validation loss: 1.9665149527211343

Epoch: 6| Step: 9
Training loss: 2.095690965652466
Validation loss: 1.9657465719407605

Epoch: 6| Step: 10
Training loss: 1.8893353939056396
Validation loss: 1.9684355387123682

Epoch: 6| Step: 11
Training loss: 1.7851266860961914
Validation loss: 1.9802175760269165

Epoch: 6| Step: 12
Training loss: 2.1870386600494385
Validation loss: 1.9636468938601914

Epoch: 6| Step: 13
Training loss: 2.186215400695801
Validation loss: 1.9596575088398431

Epoch: 101| Step: 0
Training loss: 1.8770124912261963
Validation loss: 1.9744995306896906

Epoch: 6| Step: 1
Training loss: 1.8621270656585693
Validation loss: 1.9633403901130921

Epoch: 6| Step: 2
Training loss: 2.164860963821411
Validation loss: 1.9787645724511915

Epoch: 6| Step: 3
Training loss: 2.669999599456787
Validation loss: 1.9985375071084628

Epoch: 6| Step: 4
Training loss: 1.3366715908050537
Validation loss: 1.9843363018446072

Epoch: 6| Step: 5
Training loss: 1.9606382846832275
Validation loss: 1.985459299497707

Epoch: 6| Step: 6
Training loss: 1.9373825788497925
Validation loss: 1.9726877545797696

Epoch: 6| Step: 7
Training loss: 2.4359169006347656
Validation loss: 1.9445244855778192

Epoch: 6| Step: 8
Training loss: 2.453749656677246
Validation loss: 1.9448557797298636

Epoch: 6| Step: 9
Training loss: 1.8716007471084595
Validation loss: 1.9366138237778858

Epoch: 6| Step: 10
Training loss: 2.4944751262664795
Validation loss: 1.936766674441676

Epoch: 6| Step: 11
Training loss: 2.6068906784057617
Validation loss: 1.948832304246964

Epoch: 6| Step: 12
Training loss: 2.2417876720428467
Validation loss: 1.9506867265188566

Epoch: 6| Step: 13
Training loss: 2.0614614486694336
Validation loss: 1.9633039377068962

Epoch: 102| Step: 0
Training loss: 1.993607759475708
Validation loss: 1.9519632554823352

Epoch: 6| Step: 1
Training loss: 1.7411117553710938
Validation loss: 1.9562462619555894

Epoch: 6| Step: 2
Training loss: 1.7142736911773682
Validation loss: 1.9437693972741403

Epoch: 6| Step: 3
Training loss: 2.2006497383117676
Validation loss: 1.9491140316891413

Epoch: 6| Step: 4
Training loss: 1.9090955257415771
Validation loss: 1.9599360804403982

Epoch: 6| Step: 5
Training loss: 2.468942165374756
Validation loss: 1.966111260075723

Epoch: 6| Step: 6
Training loss: 2.0661253929138184
Validation loss: 1.9707598686218262

Epoch: 6| Step: 7
Training loss: 1.9156115055084229
Validation loss: 1.9773268263827088

Epoch: 6| Step: 8
Training loss: 1.9936652183532715
Validation loss: 1.9694712162017822

Epoch: 6| Step: 9
Training loss: 2.4415621757507324
Validation loss: 1.9562116412706272

Epoch: 6| Step: 10
Training loss: 2.3886425495147705
Validation loss: 1.951175852488446

Epoch: 6| Step: 11
Training loss: 2.1386380195617676
Validation loss: 1.980080177707057

Epoch: 6| Step: 12
Training loss: 2.6451518535614014
Validation loss: 1.9940661102212884

Epoch: 6| Step: 13
Training loss: 2.090014934539795
Validation loss: 1.9999558156536472

Epoch: 103| Step: 0
Training loss: 2.054128646850586
Validation loss: 2.011698317784135

Epoch: 6| Step: 1
Training loss: 1.9233243465423584
Validation loss: 2.022048710494913

Epoch: 6| Step: 2
Training loss: 2.098237991333008
Validation loss: 2.0716804368521577

Epoch: 6| Step: 3
Training loss: 2.4295878410339355
Validation loss: 2.0801309513789352

Epoch: 6| Step: 4
Training loss: 2.106846332550049
Validation loss: 2.0969534843198714

Epoch: 6| Step: 5
Training loss: 2.0096185207366943
Validation loss: 2.1169724541325725

Epoch: 6| Step: 6
Training loss: 2.86552095413208
Validation loss: 2.094264725203155

Epoch: 6| Step: 7
Training loss: 1.8321101665496826
Validation loss: 2.0794392760081957

Epoch: 6| Step: 8
Training loss: 1.9998137950897217
Validation loss: 2.077804437247656

Epoch: 6| Step: 9
Training loss: 2.4950413703918457
Validation loss: 2.0282642161974342

Epoch: 6| Step: 10
Training loss: 1.9537010192871094
Validation loss: 2.0138967998566164

Epoch: 6| Step: 11
Training loss: 2.205883502960205
Validation loss: 1.990473360143682

Epoch: 6| Step: 12
Training loss: 2.3840394020080566
Validation loss: 1.9806640981346049

Epoch: 6| Step: 13
Training loss: 2.445070505142212
Validation loss: 1.9859298018998996

Epoch: 104| Step: 0
Training loss: 2.4543378353118896
Validation loss: 1.9744311404484574

Epoch: 6| Step: 1
Training loss: 2.6392595767974854
Validation loss: 1.974835518867739

Epoch: 6| Step: 2
Training loss: 2.041090488433838
Validation loss: 1.963479490690334

Epoch: 6| Step: 3
Training loss: 2.3093230724334717
Validation loss: 1.9771323383495372

Epoch: 6| Step: 4
Training loss: 2.1878812313079834
Validation loss: 1.999322311852568

Epoch: 6| Step: 5
Training loss: 2.535367965698242
Validation loss: 2.0137467051065094

Epoch: 6| Step: 6
Training loss: 2.025862216949463
Validation loss: 2.013081307052284

Epoch: 6| Step: 7
Training loss: 2.5741004943847656
Validation loss: 1.9895992740508048

Epoch: 6| Step: 8
Training loss: 1.9301928281784058
Validation loss: 1.9779976465368783

Epoch: 6| Step: 9
Training loss: 1.413233995437622
Validation loss: 1.9495496108967771

Epoch: 6| Step: 10
Training loss: 1.984586238861084
Validation loss: 1.9603576019246092

Epoch: 6| Step: 11
Training loss: 1.4236068725585938
Validation loss: 1.9490134100760184

Epoch: 6| Step: 12
Training loss: 2.4351043701171875
Validation loss: 1.9512956334698586

Epoch: 6| Step: 13
Training loss: 2.431302070617676
Validation loss: 1.952204655575496

Epoch: 105| Step: 0
Training loss: 2.642742872238159
Validation loss: 1.9687340656916301

Epoch: 6| Step: 1
Training loss: 2.0286898612976074
Validation loss: 2.001816516281456

Epoch: 6| Step: 2
Training loss: 2.7483832836151123
Validation loss: 2.000120916674214

Epoch: 6| Step: 3
Training loss: 2.644026041030884
Validation loss: 1.976805979205716

Epoch: 6| Step: 4
Training loss: 1.8301945924758911
Validation loss: 1.9700946756588515

Epoch: 6| Step: 5
Training loss: 1.8443796634674072
Validation loss: 1.9682981121924616

Epoch: 6| Step: 6
Training loss: 2.069779396057129
Validation loss: 1.9379572868347168

Epoch: 6| Step: 7
Training loss: 1.9883155822753906
Validation loss: 1.918956297700123

Epoch: 6| Step: 8
Training loss: 2.2972354888916016
Validation loss: 1.9189991220351188

Epoch: 6| Step: 9
Training loss: 2.2482032775878906
Validation loss: 1.923690019115325

Epoch: 6| Step: 10
Training loss: 1.0893447399139404
Validation loss: 1.914753311423845

Epoch: 6| Step: 11
Training loss: 2.042304039001465
Validation loss: 1.9138953108941354

Epoch: 6| Step: 12
Training loss: 2.9136006832122803
Validation loss: 1.915470443746095

Epoch: 6| Step: 13
Training loss: 1.139551043510437
Validation loss: 1.9119393364075692

Epoch: 106| Step: 0
Training loss: 2.3742752075195312
Validation loss: 1.9132811048979401

Epoch: 6| Step: 1
Training loss: 2.5504841804504395
Validation loss: 1.909270146841644

Epoch: 6| Step: 2
Training loss: 1.5437427759170532
Validation loss: 1.9220127187749392

Epoch: 6| Step: 3
Training loss: 1.3238410949707031
Validation loss: 1.931041189419326

Epoch: 6| Step: 4
Training loss: 2.036729574203491
Validation loss: 1.9437514210260043

Epoch: 6| Step: 5
Training loss: 2.2335002422332764
Validation loss: 1.943004729927227

Epoch: 6| Step: 6
Training loss: 2.5372800827026367
Validation loss: 1.9464935897499003

Epoch: 6| Step: 7
Training loss: 2.3789000511169434
Validation loss: 1.934861078057238

Epoch: 6| Step: 8
Training loss: 2.602252721786499
Validation loss: 1.9476333895037252

Epoch: 6| Step: 9
Training loss: 2.366485834121704
Validation loss: 1.9647243740738078

Epoch: 6| Step: 10
Training loss: 2.560770034790039
Validation loss: 1.9662678228911532

Epoch: 6| Step: 11
Training loss: 1.7478711605072021
Validation loss: 1.9673710484658518

Epoch: 6| Step: 12
Training loss: 1.4317095279693604
Validation loss: 1.9907102866839337

Epoch: 6| Step: 13
Training loss: 1.804248332977295
Validation loss: 2.024110132648099

Epoch: 107| Step: 0
Training loss: 2.5217552185058594
Validation loss: 2.0002406233100483

Epoch: 6| Step: 1
Training loss: 1.886802077293396
Validation loss: 1.9934460155425533

Epoch: 6| Step: 2
Training loss: 1.9708714485168457
Validation loss: 1.9897999840397989

Epoch: 6| Step: 3
Training loss: 2.2936649322509766
Validation loss: 2.017206935472386

Epoch: 6| Step: 4
Training loss: 1.7066268920898438
Validation loss: 2.0194917917251587

Epoch: 6| Step: 5
Training loss: 2.014578104019165
Validation loss: 2.005114370776761

Epoch: 6| Step: 6
Training loss: 2.1707348823547363
Validation loss: 1.99987026568382

Epoch: 6| Step: 7
Training loss: 2.155496120452881
Validation loss: 2.002114430550606

Epoch: 6| Step: 8
Training loss: 2.612926483154297
Validation loss: 2.0002526596028316

Epoch: 6| Step: 9
Training loss: 2.1275768280029297
Validation loss: 1.998060090567476

Epoch: 6| Step: 10
Training loss: 1.932504653930664
Validation loss: 1.980281242760279

Epoch: 6| Step: 11
Training loss: 2.239685535430908
Validation loss: 1.922492968138828

Epoch: 6| Step: 12
Training loss: 1.7679579257965088
Validation loss: 1.9015129304701281

Epoch: 6| Step: 13
Training loss: 2.3371548652648926
Validation loss: 1.8954790164065618

Epoch: 108| Step: 0
Training loss: 1.8729106187820435
Validation loss: 1.8869362492715158

Epoch: 6| Step: 1
Training loss: 2.3359639644622803
Validation loss: 1.8996333229926325

Epoch: 6| Step: 2
Training loss: 2.434758186340332
Validation loss: 1.8860814712380851

Epoch: 6| Step: 3
Training loss: 2.0286900997161865
Validation loss: 1.892385463560781

Epoch: 6| Step: 4
Training loss: 3.0454518795013428
Validation loss: 1.9009122592146679

Epoch: 6| Step: 5
Training loss: 2.051438570022583
Validation loss: 1.8999275046010171

Epoch: 6| Step: 6
Training loss: 1.300714135169983
Validation loss: 1.9179852675366145

Epoch: 6| Step: 7
Training loss: 2.3700695037841797
Validation loss: 1.9260960701973207

Epoch: 6| Step: 8
Training loss: 1.5288913249969482
Validation loss: 1.9172070744217082

Epoch: 6| Step: 9
Training loss: 2.0995330810546875
Validation loss: 1.9182181204518964

Epoch: 6| Step: 10
Training loss: 2.1689507961273193
Validation loss: 1.9111944065299085

Epoch: 6| Step: 11
Training loss: 2.4131250381469727
Validation loss: 1.915901050772718

Epoch: 6| Step: 12
Training loss: 1.3903380632400513
Validation loss: 1.9207407005371586

Epoch: 6| Step: 13
Training loss: 2.6828043460845947
Validation loss: 1.917220236152731

Epoch: 109| Step: 0
Training loss: 2.6440558433532715
Validation loss: 1.919698558827882

Epoch: 6| Step: 1
Training loss: 2.360766649246216
Validation loss: 1.9278437565731745

Epoch: 6| Step: 2
Training loss: 2.310349941253662
Validation loss: 1.9674610681431268

Epoch: 6| Step: 3
Training loss: 2.070106267929077
Validation loss: 1.964848813190255

Epoch: 6| Step: 4
Training loss: 1.6953721046447754
Validation loss: 1.9359910577856085

Epoch: 6| Step: 5
Training loss: 2.571253538131714
Validation loss: 1.9140289880896126

Epoch: 6| Step: 6
Training loss: 1.968256950378418
Validation loss: 1.910669147327382

Epoch: 6| Step: 7
Training loss: 1.7293338775634766
Validation loss: 1.924965735404722

Epoch: 6| Step: 8
Training loss: 2.070100784301758
Validation loss: 1.944101018290366

Epoch: 6| Step: 9
Training loss: 1.9102190732955933
Validation loss: 1.9293780096115605

Epoch: 6| Step: 10
Training loss: 2.3081741333007812
Validation loss: 1.938998104423605

Epoch: 6| Step: 11
Training loss: 2.2296323776245117
Validation loss: 1.9424810127545429

Epoch: 6| Step: 12
Training loss: 1.7597930431365967
Validation loss: 1.9327770099844983

Epoch: 6| Step: 13
Training loss: 0.998987078666687
Validation loss: 1.9263360782336163

Epoch: 110| Step: 0
Training loss: 2.5266339778900146
Validation loss: 1.9105583096063266

Epoch: 6| Step: 1
Training loss: 1.7710176706314087
Validation loss: 1.896342408272528

Epoch: 6| Step: 2
Training loss: 1.9667719602584839
Validation loss: 1.8879316929847962

Epoch: 6| Step: 3
Training loss: 1.927225112915039
Validation loss: 1.8962355018943868

Epoch: 6| Step: 4
Training loss: 2.1504335403442383
Validation loss: 1.8930018307060323

Epoch: 6| Step: 5
Training loss: 2.5604398250579834
Validation loss: 1.8930798269087268

Epoch: 6| Step: 6
Training loss: 2.016911506652832
Validation loss: 1.900166557681176

Epoch: 6| Step: 7
Training loss: 1.372254490852356
Validation loss: 1.9113423914037726

Epoch: 6| Step: 8
Training loss: 2.360175848007202
Validation loss: 1.9166405739322785

Epoch: 6| Step: 9
Training loss: 1.3468965291976929
Validation loss: 1.924080459020471

Epoch: 6| Step: 10
Training loss: 2.5659701824188232
Validation loss: 1.9274144864851428

Epoch: 6| Step: 11
Training loss: 1.5322067737579346
Validation loss: 1.9466240303490752

Epoch: 6| Step: 12
Training loss: 2.4411988258361816
Validation loss: 1.9466566603670838

Epoch: 6| Step: 13
Training loss: 2.501190423965454
Validation loss: 1.951843528337376

Epoch: 111| Step: 0
Training loss: 2.17456316947937
Validation loss: 1.941651121262581

Epoch: 6| Step: 1
Training loss: 1.9891631603240967
Validation loss: 1.9380718213255688

Epoch: 6| Step: 2
Training loss: 1.9163118600845337
Validation loss: 1.9482749572364233

Epoch: 6| Step: 3
Training loss: 1.9121050834655762
Validation loss: 1.955911503043226

Epoch: 6| Step: 4
Training loss: 1.6904865503311157
Validation loss: 1.9580588930396623

Epoch: 6| Step: 5
Training loss: 2.168940544128418
Validation loss: 1.96986319557313

Epoch: 6| Step: 6
Training loss: 2.269143581390381
Validation loss: 1.976820340720556

Epoch: 6| Step: 7
Training loss: 1.8982362747192383
Validation loss: 1.9621779611033778

Epoch: 6| Step: 8
Training loss: 2.2087745666503906
Validation loss: 1.9536187033499441

Epoch: 6| Step: 9
Training loss: 2.279858112335205
Validation loss: 1.9467414040719309

Epoch: 6| Step: 10
Training loss: 2.322707176208496
Validation loss: 1.9457245488320627

Epoch: 6| Step: 11
Training loss: 2.1511964797973633
Validation loss: 1.9430484194909372

Epoch: 6| Step: 12
Training loss: 1.8679898977279663
Validation loss: 1.9426543930525422

Epoch: 6| Step: 13
Training loss: 1.4600520133972168
Validation loss: 1.9296480686433855

Epoch: 112| Step: 0
Training loss: 1.9207733869552612
Validation loss: 1.9335910863773798

Epoch: 6| Step: 1
Training loss: 2.1177754402160645
Validation loss: 1.9249925997949415

Epoch: 6| Step: 2
Training loss: 2.008305549621582
Validation loss: 1.9256876130257883

Epoch: 6| Step: 3
Training loss: 1.9181259870529175
Validation loss: 1.9311554970279816

Epoch: 6| Step: 4
Training loss: 1.6813545227050781
Validation loss: 1.9306550333576817

Epoch: 6| Step: 5
Training loss: 1.462688684463501
Validation loss: 1.9399036822780487

Epoch: 6| Step: 6
Training loss: 2.202991008758545
Validation loss: 1.9574834274989303

Epoch: 6| Step: 7
Training loss: 2.610513687133789
Validation loss: 1.9565439788244103

Epoch: 6| Step: 8
Training loss: 1.426625370979309
Validation loss: 1.9587175256462508

Epoch: 6| Step: 9
Training loss: 2.649235486984253
Validation loss: 1.9895539258116035

Epoch: 6| Step: 10
Training loss: 2.8414721488952637
Validation loss: 2.0254271261153685

Epoch: 6| Step: 11
Training loss: 2.1745684146881104
Validation loss: 2.0147806521384948

Epoch: 6| Step: 12
Training loss: 2.019533157348633
Validation loss: 1.9891978438182543

Epoch: 6| Step: 13
Training loss: 2.045057773590088
Validation loss: 1.96221463910995

Epoch: 113| Step: 0
Training loss: 1.5405076742172241
Validation loss: 1.9475296517854095

Epoch: 6| Step: 1
Training loss: 2.2606451511383057
Validation loss: 1.929188725768879

Epoch: 6| Step: 2
Training loss: 2.185349225997925
Validation loss: 1.9215562266688193

Epoch: 6| Step: 3
Training loss: 2.6501517295837402
Validation loss: 1.8987418579798874

Epoch: 6| Step: 4
Training loss: 2.005976915359497
Validation loss: 1.9043756146584787

Epoch: 6| Step: 5
Training loss: 1.6715240478515625
Validation loss: 1.935774149433259

Epoch: 6| Step: 6
Training loss: 2.1389362812042236
Validation loss: 1.9703115109474427

Epoch: 6| Step: 7
Training loss: 2.4649877548217773
Validation loss: 1.9806917175169914

Epoch: 6| Step: 8
Training loss: 2.632547378540039
Validation loss: 1.966527206923372

Epoch: 6| Step: 9
Training loss: 1.5286197662353516
Validation loss: 1.9728758065931258

Epoch: 6| Step: 10
Training loss: 1.911313533782959
Validation loss: 1.954893377519423

Epoch: 6| Step: 11
Training loss: 1.9498775005340576
Validation loss: 1.9446303113814323

Epoch: 6| Step: 12
Training loss: 1.5023765563964844
Validation loss: 1.9342548437015985

Epoch: 6| Step: 13
Training loss: 2.873849630355835
Validation loss: 1.9203043906919417

Epoch: 114| Step: 0
Training loss: 2.4082090854644775
Validation loss: 1.9293972881891395

Epoch: 6| Step: 1
Training loss: 2.395087242126465
Validation loss: 1.9466696541796449

Epoch: 6| Step: 2
Training loss: 1.7669880390167236
Validation loss: 1.9576714064485283

Epoch: 6| Step: 3
Training loss: 1.8450722694396973
Validation loss: 1.9389612751622354

Epoch: 6| Step: 4
Training loss: 1.8692841529846191
Validation loss: 1.9386420865212717

Epoch: 6| Step: 5
Training loss: 2.3711416721343994
Validation loss: 1.9253645186783166

Epoch: 6| Step: 6
Training loss: 2.1031763553619385
Validation loss: 1.9212297085792787

Epoch: 6| Step: 7
Training loss: 1.7376973628997803
Validation loss: 1.950315736955212

Epoch: 6| Step: 8
Training loss: 2.473710060119629
Validation loss: 1.982168533468759

Epoch: 6| Step: 9
Training loss: 2.082045793533325
Validation loss: 1.997265951607817

Epoch: 6| Step: 10
Training loss: 2.2052676677703857
Validation loss: 1.9934540435832033

Epoch: 6| Step: 11
Training loss: 1.9369611740112305
Validation loss: 2.025046081953151

Epoch: 6| Step: 12
Training loss: 2.6821107864379883
Validation loss: 1.998166690590561

Epoch: 6| Step: 13
Training loss: 1.6538233757019043
Validation loss: 1.966278483790736

Epoch: 115| Step: 0
Training loss: 2.010099411010742
Validation loss: 1.9569358979502032

Epoch: 6| Step: 1
Training loss: 2.5194244384765625
Validation loss: 1.9756078809820197

Epoch: 6| Step: 2
Training loss: 1.9615497589111328
Validation loss: 1.9795945446978334

Epoch: 6| Step: 3
Training loss: 1.646507740020752
Validation loss: 2.001805172171644

Epoch: 6| Step: 4
Training loss: 1.9922480583190918
Validation loss: 1.9696623433020808

Epoch: 6| Step: 5
Training loss: 1.8944884538650513
Validation loss: 1.9488393568223523

Epoch: 6| Step: 6
Training loss: 2.015195369720459
Validation loss: 1.9645705581993185

Epoch: 6| Step: 7
Training loss: 2.0421152114868164
Validation loss: 2.0078535361956527

Epoch: 6| Step: 8
Training loss: 2.4339637756347656
Validation loss: 2.077949777726204

Epoch: 6| Step: 9
Training loss: 2.3707003593444824
Validation loss: 2.096227556146601

Epoch: 6| Step: 10
Training loss: 2.2830657958984375
Validation loss: 2.076211380702193

Epoch: 6| Step: 11
Training loss: 2.095284938812256
Validation loss: 2.031279256266932

Epoch: 6| Step: 12
Training loss: 2.5171618461608887
Validation loss: 1.9968637458739742

Epoch: 6| Step: 13
Training loss: 2.926666021347046
Validation loss: 1.9586085581010388

Epoch: 116| Step: 0
Training loss: 1.6995124816894531
Validation loss: 1.9285398990877214

Epoch: 6| Step: 1
Training loss: 1.6107158660888672
Validation loss: 1.9304374469223844

Epoch: 6| Step: 2
Training loss: 2.1534643173217773
Validation loss: 1.9555555723046745

Epoch: 6| Step: 3
Training loss: 2.1942970752716064
Validation loss: 1.9469315159705378

Epoch: 6| Step: 4
Training loss: 2.711810827255249
Validation loss: 1.9661244089885423

Epoch: 6| Step: 5
Training loss: 2.4309632778167725
Validation loss: 1.9678065520460888

Epoch: 6| Step: 6
Training loss: 2.1994030475616455
Validation loss: 1.9404382628779258

Epoch: 6| Step: 7
Training loss: 2.491938591003418
Validation loss: 1.910822924747262

Epoch: 6| Step: 8
Training loss: 2.378338098526001
Validation loss: 1.898648267151207

Epoch: 6| Step: 9
Training loss: 2.099473714828491
Validation loss: 1.8938311863971014

Epoch: 6| Step: 10
Training loss: 2.1241836547851562
Validation loss: 1.910467278572821

Epoch: 6| Step: 11
Training loss: 1.6227481365203857
Validation loss: 1.952453761972407

Epoch: 6| Step: 12
Training loss: 1.6317452192306519
Validation loss: 1.9879621216045913

Epoch: 6| Step: 13
Training loss: 2.123978614807129
Validation loss: 2.004613576396819

Epoch: 117| Step: 0
Training loss: 2.2516496181488037
Validation loss: 2.0022575009253716

Epoch: 6| Step: 1
Training loss: 1.8868844509124756
Validation loss: 1.976121057746231

Epoch: 6| Step: 2
Training loss: 3.1480016708374023
Validation loss: 1.9278513411039948

Epoch: 6| Step: 3
Training loss: 2.5631914138793945
Validation loss: 1.900335891272432

Epoch: 6| Step: 4
Training loss: 2.145263671875
Validation loss: 1.8872656719658965

Epoch: 6| Step: 5
Training loss: 2.021028995513916
Validation loss: 1.8940914074579875

Epoch: 6| Step: 6
Training loss: 1.9242618083953857
Validation loss: 1.9047968195330711

Epoch: 6| Step: 7
Training loss: 2.1465272903442383
Validation loss: 1.9495771290153585

Epoch: 6| Step: 8
Training loss: 1.6310851573944092
Validation loss: 1.9727370662073935

Epoch: 6| Step: 9
Training loss: 2.4637393951416016
Validation loss: 1.9522654958950576

Epoch: 6| Step: 10
Training loss: 1.9086246490478516
Validation loss: 1.9093073350127026

Epoch: 6| Step: 11
Training loss: 1.9868115186691284
Validation loss: 1.8912751649015693

Epoch: 6| Step: 12
Training loss: 1.4710979461669922
Validation loss: 1.8816356402571484

Epoch: 6| Step: 13
Training loss: 1.698222279548645
Validation loss: 1.8898766143347627

Epoch: 118| Step: 0
Training loss: 2.113785743713379
Validation loss: 1.8880526788773075

Epoch: 6| Step: 1
Training loss: 1.5917888879776
Validation loss: 1.8874626416032032

Epoch: 6| Step: 2
Training loss: 2.0366992950439453
Validation loss: 1.87662677098346

Epoch: 6| Step: 3
Training loss: 2.203641891479492
Validation loss: 1.9017072698121429

Epoch: 6| Step: 4
Training loss: 1.578397274017334
Validation loss: 1.8978273766015166

Epoch: 6| Step: 5
Training loss: 1.9798271656036377
Validation loss: 1.9333470444525442

Epoch: 6| Step: 6
Training loss: 1.886335849761963
Validation loss: 1.9076068978155813

Epoch: 6| Step: 7
Training loss: 2.371220588684082
Validation loss: 1.8834535985864618

Epoch: 6| Step: 8
Training loss: 2.1743903160095215
Validation loss: 1.8949246842374083

Epoch: 6| Step: 9
Training loss: 2.3232581615448
Validation loss: 1.8898459942110124

Epoch: 6| Step: 10
Training loss: 2.784296989440918
Validation loss: 1.9230403348963747

Epoch: 6| Step: 11
Training loss: 2.383584976196289
Validation loss: 1.9660224440277263

Epoch: 6| Step: 12
Training loss: 1.7081475257873535
Validation loss: 2.0268643453557003

Epoch: 6| Step: 13
Training loss: 1.9108644723892212
Validation loss: 2.0547877332215667

Epoch: 119| Step: 0
Training loss: 2.3420543670654297
Validation loss: 2.042669229609992

Epoch: 6| Step: 1
Training loss: 1.8974192142486572
Validation loss: 1.992883264377553

Epoch: 6| Step: 2
Training loss: 2.1276917457580566
Validation loss: 1.974530320013723

Epoch: 6| Step: 3
Training loss: 2.349426746368408
Validation loss: 1.972513247561711

Epoch: 6| Step: 4
Training loss: 1.4635059833526611
Validation loss: 1.9617823862260388

Epoch: 6| Step: 5
Training loss: 2.1289610862731934
Validation loss: 1.9811286746814687

Epoch: 6| Step: 6
Training loss: 2.503917694091797
Validation loss: 1.993356817512102

Epoch: 6| Step: 7
Training loss: 2.2854180335998535
Validation loss: 2.003056970975732

Epoch: 6| Step: 8
Training loss: 1.376044750213623
Validation loss: 1.9947368457753172

Epoch: 6| Step: 9
Training loss: 2.219557762145996
Validation loss: 1.9668604455968386

Epoch: 6| Step: 10
Training loss: 2.193610668182373
Validation loss: 1.9521487579550794

Epoch: 6| Step: 11
Training loss: 1.6893565654754639
Validation loss: 1.9525317991933515

Epoch: 6| Step: 12
Training loss: 1.8943718671798706
Validation loss: 1.9350442860716133

Epoch: 6| Step: 13
Training loss: 2.1506576538085938
Validation loss: 1.9292445285345918

Epoch: 120| Step: 0
Training loss: 2.272191047668457
Validation loss: 1.9093526178790676

Epoch: 6| Step: 1
Training loss: 2.32454252243042
Validation loss: 1.931389538190698

Epoch: 6| Step: 2
Training loss: 2.652428150177002
Validation loss: 1.924354136631053

Epoch: 6| Step: 3
Training loss: 1.5554249286651611
Validation loss: 1.9117001833454255

Epoch: 6| Step: 4
Training loss: 0.9620596170425415
Validation loss: 1.9062551452267555

Epoch: 6| Step: 5
Training loss: 1.5792208909988403
Validation loss: 1.9077881613085348

Epoch: 6| Step: 6
Training loss: 1.7390730381011963
Validation loss: 1.904589553033152

Epoch: 6| Step: 7
Training loss: 3.0044922828674316
Validation loss: 1.9062568231295514

Epoch: 6| Step: 8
Training loss: 2.648822784423828
Validation loss: 1.9063733136782082

Epoch: 6| Step: 9
Training loss: 2.136259078979492
Validation loss: 1.919971199445827

Epoch: 6| Step: 10
Training loss: 1.5759265422821045
Validation loss: 1.9397563626689296

Epoch: 6| Step: 11
Training loss: 2.106436014175415
Validation loss: 1.950450030706262

Epoch: 6| Step: 12
Training loss: 1.9819512367248535
Validation loss: 1.9836254786419611

Epoch: 6| Step: 13
Training loss: 1.6879571676254272
Validation loss: 1.9750775496164958

Epoch: 121| Step: 0
Training loss: 1.6388908624649048
Validation loss: 1.976541123082561

Epoch: 6| Step: 1
Training loss: 2.125767707824707
Validation loss: 1.9635740069932834

Epoch: 6| Step: 2
Training loss: 2.2867369651794434
Validation loss: 1.9637074367974394

Epoch: 6| Step: 3
Training loss: 2.2596659660339355
Validation loss: 1.9484811636709398

Epoch: 6| Step: 4
Training loss: 2.2211053371429443
Validation loss: 1.925675461369176

Epoch: 6| Step: 5
Training loss: 2.5100297927856445
Validation loss: 1.9251518646876018

Epoch: 6| Step: 6
Training loss: 1.8822715282440186
Validation loss: 1.9342237569952523

Epoch: 6| Step: 7
Training loss: 1.8686354160308838
Validation loss: 1.9310538461131435

Epoch: 6| Step: 8
Training loss: 2.2182083129882812
Validation loss: 1.92131672751519

Epoch: 6| Step: 9
Training loss: 1.7244341373443604
Validation loss: 1.9284235687666043

Epoch: 6| Step: 10
Training loss: 1.838751196861267
Validation loss: 1.9173019098979172

Epoch: 6| Step: 11
Training loss: 2.2518129348754883
Validation loss: 1.915910509324843

Epoch: 6| Step: 12
Training loss: 1.8912670612335205
Validation loss: 1.944827441246279

Epoch: 6| Step: 13
Training loss: 1.6073355674743652
Validation loss: 1.9575988272184968

Epoch: 122| Step: 0
Training loss: 1.7404018640518188
Validation loss: 1.9915142623327111

Epoch: 6| Step: 1
Training loss: 1.7117724418640137
Validation loss: 1.9969856239134265

Epoch: 6| Step: 2
Training loss: 2.206804037094116
Validation loss: 1.9803206536077684

Epoch: 6| Step: 3
Training loss: 2.2615928649902344
Validation loss: 1.9825384296396726

Epoch: 6| Step: 4
Training loss: 2.2003674507141113
Validation loss: 2.003205692896279

Epoch: 6| Step: 5
Training loss: 2.042039394378662
Validation loss: 2.002663848220661

Epoch: 6| Step: 6
Training loss: 1.0634949207305908
Validation loss: 1.9955202366716118

Epoch: 6| Step: 7
Training loss: 2.0661873817443848
Validation loss: 2.000794461978379

Epoch: 6| Step: 8
Training loss: 2.2107009887695312
Validation loss: 1.9939835327927784

Epoch: 6| Step: 9
Training loss: 2.7616844177246094
Validation loss: 2.0005822348338302

Epoch: 6| Step: 10
Training loss: 1.8490524291992188
Validation loss: 1.982429083957467

Epoch: 6| Step: 11
Training loss: 2.1501359939575195
Validation loss: 1.98680539284983

Epoch: 6| Step: 12
Training loss: 1.9697059392929077
Validation loss: 1.9817324761421449

Epoch: 6| Step: 13
Training loss: 2.0303640365600586
Validation loss: 1.9784429624516477

Epoch: 123| Step: 0
Training loss: 1.4835517406463623
Validation loss: 1.9870228357212518

Epoch: 6| Step: 1
Training loss: 1.6466336250305176
Validation loss: 1.9811465772249366

Epoch: 6| Step: 2
Training loss: 1.7229595184326172
Validation loss: 1.959583677271361

Epoch: 6| Step: 3
Training loss: 2.6471729278564453
Validation loss: 1.9570992210859894

Epoch: 6| Step: 4
Training loss: 1.8837549686431885
Validation loss: 1.9328677244083856

Epoch: 6| Step: 5
Training loss: 1.9980971813201904
Validation loss: 1.9381245464406989

Epoch: 6| Step: 6
Training loss: 1.7721437215805054
Validation loss: 1.9406352645607405

Epoch: 6| Step: 7
Training loss: 1.5100653171539307
Validation loss: 1.9343015045248053

Epoch: 6| Step: 8
Training loss: 1.8445268869400024
Validation loss: 1.9311456705934258

Epoch: 6| Step: 9
Training loss: 2.7681884765625
Validation loss: 1.931876282538137

Epoch: 6| Step: 10
Training loss: 1.797532558441162
Validation loss: 1.9357616414305985

Epoch: 6| Step: 11
Training loss: 2.857726573944092
Validation loss: 1.9402654965718586

Epoch: 6| Step: 12
Training loss: 1.9674561023712158
Validation loss: 1.9397714189303819

Epoch: 6| Step: 13
Training loss: 1.9919692277908325
Validation loss: 1.9348241782957507

Epoch: 124| Step: 0
Training loss: 2.111138343811035
Validation loss: 1.9256222696714504

Epoch: 6| Step: 1
Training loss: 1.707537293434143
Validation loss: 1.9052650415769188

Epoch: 6| Step: 2
Training loss: 2.5950989723205566
Validation loss: 1.9301391993799517

Epoch: 6| Step: 3
Training loss: 1.8810018301010132
Validation loss: 1.9439380181733

Epoch: 6| Step: 4
Training loss: 2.0508956909179688
Validation loss: 1.9401465744100592

Epoch: 6| Step: 5
Training loss: 1.4576852321624756
Validation loss: 1.928828703459873

Epoch: 6| Step: 6
Training loss: 2.7497172355651855
Validation loss: 1.9422188740904613

Epoch: 6| Step: 7
Training loss: 1.3005375862121582
Validation loss: 1.9693605028172976

Epoch: 6| Step: 8
Training loss: 2.18807315826416
Validation loss: 1.9862922917130172

Epoch: 6| Step: 9
Training loss: 1.9520398378372192
Validation loss: 2.0102581670207362

Epoch: 6| Step: 10
Training loss: 2.1143651008605957
Validation loss: 2.019899179858546

Epoch: 6| Step: 11
Training loss: 2.561732769012451
Validation loss: 2.007837144277429

Epoch: 6| Step: 12
Training loss: 1.3631186485290527
Validation loss: 1.9907423168100336

Epoch: 6| Step: 13
Training loss: 1.617409348487854
Validation loss: 1.9717586604497765

Epoch: 125| Step: 0
Training loss: 1.846902847290039
Validation loss: 1.9694697318538543

Epoch: 6| Step: 1
Training loss: 1.985703468322754
Validation loss: 1.9954631892583703

Epoch: 6| Step: 2
Training loss: 1.9381563663482666
Validation loss: 2.0497996345643075

Epoch: 6| Step: 3
Training loss: 2.1459224224090576
Validation loss: 2.0932652219649284

Epoch: 6| Step: 4
Training loss: 2.6000075340270996
Validation loss: 2.078403126808905

Epoch: 6| Step: 5
Training loss: 1.6890114545822144
Validation loss: 2.0084752510952693

Epoch: 6| Step: 6
Training loss: 1.6387765407562256
Validation loss: 1.9862394358522149

Epoch: 6| Step: 7
Training loss: 1.9434889554977417
Validation loss: 2.00023679835822

Epoch: 6| Step: 8
Training loss: 2.3095271587371826
Validation loss: 2.027446064897763

Epoch: 6| Step: 9
Training loss: 2.7495126724243164
Validation loss: 2.045811512136972

Epoch: 6| Step: 10
Training loss: 2.139302968978882
Validation loss: 2.050571469850438

Epoch: 6| Step: 11
Training loss: 1.8791879415512085
Validation loss: 2.0302694818024993

Epoch: 6| Step: 12
Training loss: 2.2040135860443115
Validation loss: 2.0038676646447953

Epoch: 6| Step: 13
Training loss: 1.7981758117675781
Validation loss: 1.9793314369775916

Epoch: 126| Step: 0
Training loss: 1.8282532691955566
Validation loss: 1.9381096914250364

Epoch: 6| Step: 1
Training loss: 2.2133028507232666
Validation loss: 1.9311786877211703

Epoch: 6| Step: 2
Training loss: 1.7677422761917114
Validation loss: 1.9304935009248796

Epoch: 6| Step: 3
Training loss: 1.8942391872406006
Validation loss: 1.9412695771904402

Epoch: 6| Step: 4
Training loss: 2.6756887435913086
Validation loss: 1.9435609668813727

Epoch: 6| Step: 5
Training loss: 2.6198720932006836
Validation loss: 1.9376915116463937

Epoch: 6| Step: 6
Training loss: 2.37862491607666
Validation loss: 1.9464062131861204

Epoch: 6| Step: 7
Training loss: 1.8312073945999146
Validation loss: 1.9705671238642868

Epoch: 6| Step: 8
Training loss: 1.571808099746704
Validation loss: 1.9550902074383152

Epoch: 6| Step: 9
Training loss: 1.2571351528167725
Validation loss: 1.9796536430235832

Epoch: 6| Step: 10
Training loss: 2.393655300140381
Validation loss: 2.014413836181805

Epoch: 6| Step: 11
Training loss: 2.445221424102783
Validation loss: 2.036432509781212

Epoch: 6| Step: 12
Training loss: 1.6253643035888672
Validation loss: 2.0495648089275567

Epoch: 6| Step: 13
Training loss: 1.3711708784103394
Validation loss: 2.0236869319792716

Epoch: 127| Step: 0
Training loss: 1.9444555044174194
Validation loss: 1.9823867787597

Epoch: 6| Step: 1
Training loss: 2.600801467895508
Validation loss: 1.9296508899299047

Epoch: 6| Step: 2
Training loss: 2.070188045501709
Validation loss: 1.9167843608446018

Epoch: 6| Step: 3
Training loss: 1.8604931831359863
Validation loss: 1.9161574789272842

Epoch: 6| Step: 4
Training loss: 2.0198514461517334
Validation loss: 1.9362058524162538

Epoch: 6| Step: 5
Training loss: 1.8201526403427124
Validation loss: 1.9562595262322375

Epoch: 6| Step: 6
Training loss: 2.1238865852355957
Validation loss: 1.9434003471046366

Epoch: 6| Step: 7
Training loss: 1.3069355487823486
Validation loss: 1.9433111298468806

Epoch: 6| Step: 8
Training loss: 2.2576303482055664
Validation loss: 1.9407090756200975

Epoch: 6| Step: 9
Training loss: 2.1214218139648438
Validation loss: 1.9392592983861123

Epoch: 6| Step: 10
Training loss: 1.7515788078308105
Validation loss: 1.9408550672633673

Epoch: 6| Step: 11
Training loss: 1.3166675567626953
Validation loss: 1.941729184119932

Epoch: 6| Step: 12
Training loss: 2.129716157913208
Validation loss: 1.9482246419434905

Epoch: 6| Step: 13
Training loss: 2.2356815338134766
Validation loss: 1.9489444455792826

Epoch: 128| Step: 0
Training loss: 2.1423819065093994
Validation loss: 1.9470262181374334

Epoch: 6| Step: 1
Training loss: 1.9303226470947266
Validation loss: 1.93948398610597

Epoch: 6| Step: 2
Training loss: 2.3173985481262207
Validation loss: 1.9365023310466478

Epoch: 6| Step: 3
Training loss: 1.879713773727417
Validation loss: 1.9393129284663866

Epoch: 6| Step: 4
Training loss: 2.034986972808838
Validation loss: 1.9339079510781072

Epoch: 6| Step: 5
Training loss: 2.3014745712280273
Validation loss: 1.9327309259804346

Epoch: 6| Step: 6
Training loss: 1.9623582363128662
Validation loss: 1.9471816785873906

Epoch: 6| Step: 7
Training loss: 1.472524642944336
Validation loss: 1.9370576053537347

Epoch: 6| Step: 8
Training loss: 2.1320884227752686
Validation loss: 1.937570297589866

Epoch: 6| Step: 9
Training loss: 1.7585151195526123
Validation loss: 1.9291749590186662

Epoch: 6| Step: 10
Training loss: 1.7769625186920166
Validation loss: 1.9294358581625006

Epoch: 6| Step: 11
Training loss: 1.2260119915008545
Validation loss: 1.9271869608151015

Epoch: 6| Step: 12
Training loss: 1.9663926362991333
Validation loss: 1.9217691318963164

Epoch: 6| Step: 13
Training loss: 1.9049203395843506
Validation loss: 1.92197899792784

Epoch: 129| Step: 0
Training loss: 1.426865577697754
Validation loss: 1.930138082914455

Epoch: 6| Step: 1
Training loss: 1.773258924484253
Validation loss: 1.93917739775873

Epoch: 6| Step: 2
Training loss: 1.3366199731826782
Validation loss: 1.9514395844551824

Epoch: 6| Step: 3
Training loss: 2.3493776321411133
Validation loss: 1.9514833804099792

Epoch: 6| Step: 4
Training loss: 2.008246898651123
Validation loss: 1.9446078731167702

Epoch: 6| Step: 5
Training loss: 1.887188196182251
Validation loss: 1.9439817936189714

Epoch: 6| Step: 6
Training loss: 1.8848974704742432
Validation loss: 1.9369064518200454

Epoch: 6| Step: 7
Training loss: 2.1163291931152344
Validation loss: 1.9439472306159236

Epoch: 6| Step: 8
Training loss: 1.8416614532470703
Validation loss: 1.938425261487243

Epoch: 6| Step: 9
Training loss: 2.4469470977783203
Validation loss: 1.9296557711016746

Epoch: 6| Step: 10
Training loss: 2.2419028282165527
Validation loss: 1.9450164507794123

Epoch: 6| Step: 11
Training loss: 1.3118720054626465
Validation loss: 1.9266907489427956

Epoch: 6| Step: 12
Training loss: 1.579237461090088
Validation loss: 1.934561583303636

Epoch: 6| Step: 13
Training loss: 3.187866687774658
Validation loss: 1.9589963190017208

Epoch: 130| Step: 0
Training loss: 1.9119000434875488
Validation loss: 1.9953448605793778

Epoch: 6| Step: 1
Training loss: 2.2979342937469482
Validation loss: 2.0253877088587773

Epoch: 6| Step: 2
Training loss: 1.864074945449829
Validation loss: 2.042731310731621

Epoch: 6| Step: 3
Training loss: 1.5457239151000977
Validation loss: 2.066160463517712

Epoch: 6| Step: 4
Training loss: 1.7002770900726318
Validation loss: 2.0537049334536315

Epoch: 6| Step: 5
Training loss: 1.458681344985962
Validation loss: 2.0637350133670274

Epoch: 6| Step: 6
Training loss: 2.219749927520752
Validation loss: 2.0621830058354202

Epoch: 6| Step: 7
Training loss: 1.646284580230713
Validation loss: 2.0396104025584396

Epoch: 6| Step: 8
Training loss: 2.4154210090637207
Validation loss: 2.0350470337816464

Epoch: 6| Step: 9
Training loss: 2.988736629486084
Validation loss: 2.047311903328024

Epoch: 6| Step: 10
Training loss: 2.218144178390503
Validation loss: 2.061681842291227

Epoch: 6| Step: 11
Training loss: 1.6439437866210938
Validation loss: 2.031554461807333

Epoch: 6| Step: 12
Training loss: 1.620439887046814
Validation loss: 1.9912679323586084

Epoch: 6| Step: 13
Training loss: 1.5620417594909668
Validation loss: 1.978163541004222

Epoch: 131| Step: 0
Training loss: 2.0453996658325195
Validation loss: 1.996196404580147

Epoch: 6| Step: 1
Training loss: 2.6153664588928223
Validation loss: 2.0206077867938625

Epoch: 6| Step: 2
Training loss: 2.2103524208068848
Validation loss: 2.0276713653277327

Epoch: 6| Step: 3
Training loss: 2.2376601696014404
Validation loss: 2.0122859554906047

Epoch: 6| Step: 4
Training loss: 1.971871018409729
Validation loss: 1.9870856910623529

Epoch: 6| Step: 5
Training loss: 1.9579232931137085
Validation loss: 1.968969721947947

Epoch: 6| Step: 6
Training loss: 1.6374211311340332
Validation loss: 1.920329224678778

Epoch: 6| Step: 7
Training loss: 1.5437902212142944
Validation loss: 1.8896199067433674

Epoch: 6| Step: 8
Training loss: 1.856123685836792
Validation loss: 1.8966726974774433

Epoch: 6| Step: 9
Training loss: 1.4338953495025635
Validation loss: 1.9035870823808896

Epoch: 6| Step: 10
Training loss: 2.098390579223633
Validation loss: 1.9139875224841538

Epoch: 6| Step: 11
Training loss: 1.9452564716339111
Validation loss: 1.9267597480486798

Epoch: 6| Step: 12
Training loss: 2.179957628250122
Validation loss: 1.9328888231708157

Epoch: 6| Step: 13
Training loss: 1.8241288661956787
Validation loss: 1.9272650082906086

Epoch: 132| Step: 0
Training loss: 1.2862138748168945
Validation loss: 1.9525527185009373

Epoch: 6| Step: 1
Training loss: 1.5560426712036133
Validation loss: 1.9607670319977628

Epoch: 6| Step: 2
Training loss: 2.23366117477417
Validation loss: 1.988401359127414

Epoch: 6| Step: 3
Training loss: 1.6928995847702026
Validation loss: 1.986663887577672

Epoch: 6| Step: 4
Training loss: 3.0441396236419678
Validation loss: 1.9789139737365067

Epoch: 6| Step: 5
Training loss: 2.0266475677490234
Validation loss: 1.9749708252568399

Epoch: 6| Step: 6
Training loss: 1.9259400367736816
Validation loss: 1.9805785199647308

Epoch: 6| Step: 7
Training loss: 1.5422592163085938
Validation loss: 1.970275309778029

Epoch: 6| Step: 8
Training loss: 1.0109797716140747
Validation loss: 1.9717278839439474

Epoch: 6| Step: 9
Training loss: 1.6453462839126587
Validation loss: 1.9700572503510343

Epoch: 6| Step: 10
Training loss: 2.370213270187378
Validation loss: 1.987603033742597

Epoch: 6| Step: 11
Training loss: 2.09306001663208
Validation loss: 1.9839098966249855

Epoch: 6| Step: 12
Training loss: 2.284663200378418
Validation loss: 1.974195703383415

Epoch: 6| Step: 13
Training loss: 1.9552464485168457
Validation loss: 1.94116214911143

Epoch: 133| Step: 0
Training loss: 1.6026034355163574
Validation loss: 1.9396197847140733

Epoch: 6| Step: 1
Training loss: 1.8039493560791016
Validation loss: 1.960673479623692

Epoch: 6| Step: 2
Training loss: 2.1358509063720703
Validation loss: 1.9543269911120016

Epoch: 6| Step: 3
Training loss: 1.964212417602539
Validation loss: 1.9286078009554135

Epoch: 6| Step: 4
Training loss: 1.8598437309265137
Validation loss: 1.924501924104588

Epoch: 6| Step: 5
Training loss: 1.735599160194397
Validation loss: 1.903619635489679

Epoch: 6| Step: 6
Training loss: 2.0680835247039795
Validation loss: 1.899724127143942

Epoch: 6| Step: 7
Training loss: 1.7778292894363403
Validation loss: 1.9092499491988972

Epoch: 6| Step: 8
Training loss: 1.7905735969543457
Validation loss: 1.9067825604510564

Epoch: 6| Step: 9
Training loss: 1.1413708925247192
Validation loss: 1.9183458461556384

Epoch: 6| Step: 10
Training loss: 2.0317745208740234
Validation loss: 1.9161562714525449

Epoch: 6| Step: 11
Training loss: 1.8711433410644531
Validation loss: 1.9299860590247697

Epoch: 6| Step: 12
Training loss: 2.3750691413879395
Validation loss: 1.9493757524797994

Epoch: 6| Step: 13
Training loss: 2.6660356521606445
Validation loss: 1.9747697127762662

Epoch: 134| Step: 0
Training loss: 1.752164363861084
Validation loss: 1.9543147689552718

Epoch: 6| Step: 1
Training loss: 2.2599308490753174
Validation loss: 1.9664146951449815

Epoch: 6| Step: 2
Training loss: 1.9841150045394897
Validation loss: 1.963962657477266

Epoch: 6| Step: 3
Training loss: 1.4504233598709106
Validation loss: 1.9800810506266933

Epoch: 6| Step: 4
Training loss: 1.7292135953903198
Validation loss: 1.9858558690676125

Epoch: 6| Step: 5
Training loss: 1.7517859935760498
Validation loss: 1.9744304777473531

Epoch: 6| Step: 6
Training loss: 1.630577564239502
Validation loss: 1.984434537990119

Epoch: 6| Step: 7
Training loss: 1.350687026977539
Validation loss: 1.9830782362209853

Epoch: 6| Step: 8
Training loss: 2.446077585220337
Validation loss: 1.972834212805635

Epoch: 6| Step: 9
Training loss: 2.9932377338409424
Validation loss: 1.9846100140643377

Epoch: 6| Step: 10
Training loss: 2.1021060943603516
Validation loss: 1.9851957700585807

Epoch: 6| Step: 11
Training loss: 1.4123083353042603
Validation loss: 1.996410003272436

Epoch: 6| Step: 12
Training loss: 1.5215239524841309
Validation loss: 1.9905148590764692

Epoch: 6| Step: 13
Training loss: 1.285094976425171
Validation loss: 1.977219585449465

Epoch: 135| Step: 0
Training loss: 2.4674127101898193
Validation loss: 1.9773743242345831

Epoch: 6| Step: 1
Training loss: 2.4407169818878174
Validation loss: 1.963837949178552

Epoch: 6| Step: 2
Training loss: 1.630265235900879
Validation loss: 1.9563701716802453

Epoch: 6| Step: 3
Training loss: 1.7951781749725342
Validation loss: 1.937946222161734

Epoch: 6| Step: 4
Training loss: 1.540766954421997
Validation loss: 1.9518879587932298

Epoch: 6| Step: 5
Training loss: 2.4004406929016113
Validation loss: 1.9385201290089598

Epoch: 6| Step: 6
Training loss: 1.2028777599334717
Validation loss: 1.9277450115449968

Epoch: 6| Step: 7
Training loss: 2.0989160537719727
Validation loss: 1.9379122846870012

Epoch: 6| Step: 8
Training loss: 1.3735322952270508
Validation loss: 1.9474293211454987

Epoch: 6| Step: 9
Training loss: 1.50534188747406
Validation loss: 1.9430339003121981

Epoch: 6| Step: 10
Training loss: 1.922481656074524
Validation loss: 1.9514992288363877

Epoch: 6| Step: 11
Training loss: 1.2749570608139038
Validation loss: 1.9625004568407614

Epoch: 6| Step: 12
Training loss: 2.491609573364258
Validation loss: 1.9672056782630183

Epoch: 6| Step: 13
Training loss: 1.5644224882125854
Validation loss: 1.9677461001180834

Epoch: 136| Step: 0
Training loss: 1.6892321109771729
Validation loss: 1.9774957497914631

Epoch: 6| Step: 1
Training loss: 1.7148990631103516
Validation loss: 1.9997724743299587

Epoch: 6| Step: 2
Training loss: 1.4706696271896362
Validation loss: 2.0232382000133557

Epoch: 6| Step: 3
Training loss: 2.2403886318206787
Validation loss: 2.035127237278928

Epoch: 6| Step: 4
Training loss: 2.148001194000244
Validation loss: 2.018155974726523

Epoch: 6| Step: 5
Training loss: 1.62758469581604
Validation loss: 2.010339293428647

Epoch: 6| Step: 6
Training loss: 1.6658591032028198
Validation loss: 2.003525871102528

Epoch: 6| Step: 7
Training loss: 1.9973499774932861
Validation loss: 1.9841493022057317

Epoch: 6| Step: 8
Training loss: 1.4277122020721436
Validation loss: 1.961349674450454

Epoch: 6| Step: 9
Training loss: 2.46714448928833
Validation loss: 1.9583632138467604

Epoch: 6| Step: 10
Training loss: 1.971584439277649
Validation loss: 1.943590393630407

Epoch: 6| Step: 11
Training loss: 1.2234303951263428
Validation loss: 1.9541418193488993

Epoch: 6| Step: 12
Training loss: 2.2981181144714355
Validation loss: 1.956463119035126

Epoch: 6| Step: 13
Training loss: 2.116326332092285
Validation loss: 1.9388415544263777

Epoch: 137| Step: 0
Training loss: 2.317953586578369
Validation loss: 1.9236242707057665

Epoch: 6| Step: 1
Training loss: 1.8214409351348877
Validation loss: 1.9130415929261075

Epoch: 6| Step: 2
Training loss: 1.263607382774353
Validation loss: 1.9015099053741784

Epoch: 6| Step: 3
Training loss: 2.940551996231079
Validation loss: 1.9015846585714689

Epoch: 6| Step: 4
Training loss: 2.1387548446655273
Validation loss: 1.9130017321596864

Epoch: 6| Step: 5
Training loss: 1.6300666332244873
Validation loss: 1.9230178325406966

Epoch: 6| Step: 6
Training loss: 1.6653727293014526
Validation loss: 1.9413733174723964

Epoch: 6| Step: 7
Training loss: 1.2760279178619385
Validation loss: 1.952065549870973

Epoch: 6| Step: 8
Training loss: 1.5811378955841064
Validation loss: 1.948064656667812

Epoch: 6| Step: 9
Training loss: 1.9061082601547241
Validation loss: 1.9636201653429257

Epoch: 6| Step: 10
Training loss: 1.7768516540527344
Validation loss: 1.9673925458744008

Epoch: 6| Step: 11
Training loss: 2.0635859966278076
Validation loss: 1.9666838466480214

Epoch: 6| Step: 12
Training loss: 2.1295723915100098
Validation loss: 1.989381831179383

Epoch: 6| Step: 13
Training loss: 0.9804466962814331
Validation loss: 1.986769142971244

Epoch: 138| Step: 0
Training loss: 2.0452895164489746
Validation loss: 1.9847866489041237

Epoch: 6| Step: 1
Training loss: 1.2027690410614014
Validation loss: 1.9828881332951207

Epoch: 6| Step: 2
Training loss: 1.5298542976379395
Validation loss: 1.974161700535846

Epoch: 6| Step: 3
Training loss: 1.8631190061569214
Validation loss: 1.9943187236785889

Epoch: 6| Step: 4
Training loss: 1.912675380706787
Validation loss: 1.9899819089520363

Epoch: 6| Step: 5
Training loss: 1.8760130405426025
Validation loss: 2.0080372377108504

Epoch: 6| Step: 6
Training loss: 2.09639835357666
Validation loss: 1.9970546858285063

Epoch: 6| Step: 7
Training loss: 1.4187982082366943
Validation loss: 2.003581136785528

Epoch: 6| Step: 8
Training loss: 1.425080418586731
Validation loss: 2.0145314970324115

Epoch: 6| Step: 9
Training loss: 2.302985429763794
Validation loss: 1.9954118408182615

Epoch: 6| Step: 10
Training loss: 1.8704729080200195
Validation loss: 2.014047340680194

Epoch: 6| Step: 11
Training loss: 2.572991371154785
Validation loss: 1.9879464987785584

Epoch: 6| Step: 12
Training loss: 1.5628505945205688
Validation loss: 1.9872806431144796

Epoch: 6| Step: 13
Training loss: 1.6567060947418213
Validation loss: 1.990650289802141

Epoch: 139| Step: 0
Training loss: 2.137235164642334
Validation loss: 1.988005163849041

Epoch: 6| Step: 1
Training loss: 2.3856067657470703
Validation loss: 1.981434376009049

Epoch: 6| Step: 2
Training loss: 1.6943345069885254
Validation loss: 1.9659487816595262

Epoch: 6| Step: 3
Training loss: 1.8086612224578857
Validation loss: 1.955693619225615

Epoch: 6| Step: 4
Training loss: 2.3293070793151855
Validation loss: 1.9341272641253728

Epoch: 6| Step: 5
Training loss: 2.1275923252105713
Validation loss: 1.9370087603087067

Epoch: 6| Step: 6
Training loss: 1.4122294187545776
Validation loss: 1.9331897702268375

Epoch: 6| Step: 7
Training loss: 2.528294563293457
Validation loss: 1.9749081801342707

Epoch: 6| Step: 8
Training loss: 1.547582983970642
Validation loss: 1.9873698347358293

Epoch: 6| Step: 9
Training loss: 1.5711661577224731
Validation loss: 1.9713212290117819

Epoch: 6| Step: 10
Training loss: 1.3449482917785645
Validation loss: 1.9762846641643073

Epoch: 6| Step: 11
Training loss: 1.519614577293396
Validation loss: 1.9935380335777038

Epoch: 6| Step: 12
Training loss: 1.3510265350341797
Validation loss: 2.00493892546623

Epoch: 6| Step: 13
Training loss: 1.9406509399414062
Validation loss: 2.017580650186026

Epoch: 140| Step: 0
Training loss: 2.073054313659668
Validation loss: 2.0107179457141506

Epoch: 6| Step: 1
Training loss: 1.3701703548431396
Validation loss: 2.0364937654105564

Epoch: 6| Step: 2
Training loss: 1.7552034854888916
Validation loss: 2.0272074489183325

Epoch: 6| Step: 3
Training loss: 2.393467903137207
Validation loss: 2.0314050105310257

Epoch: 6| Step: 4
Training loss: 1.8253588676452637
Validation loss: 2.032418777865748

Epoch: 6| Step: 5
Training loss: 1.8155630826950073
Validation loss: 2.0131818658562115

Epoch: 6| Step: 6
Training loss: 1.6478965282440186
Validation loss: 2.027240712155578

Epoch: 6| Step: 7
Training loss: 1.9240269660949707
Validation loss: 2.015946771508904

Epoch: 6| Step: 8
Training loss: 1.8238686323165894
Validation loss: 2.0047829356244815

Epoch: 6| Step: 9
Training loss: 1.4630274772644043
Validation loss: 2.0038776513068908

Epoch: 6| Step: 10
Training loss: 1.6196544170379639
Validation loss: 2.007793088113108

Epoch: 6| Step: 11
Training loss: 1.9383246898651123
Validation loss: 2.0083498775318103

Epoch: 6| Step: 12
Training loss: 2.1102850437164307
Validation loss: 2.035311673277168

Epoch: 6| Step: 13
Training loss: 0.8792434930801392
Validation loss: 2.0245530951407646

Epoch: 141| Step: 0
Training loss: 0.9744695425033569
Validation loss: 2.011886783825454

Epoch: 6| Step: 1
Training loss: 1.5099798440933228
Validation loss: 2.018323823969851

Epoch: 6| Step: 2
Training loss: 2.1446127891540527
Validation loss: 2.019499158346525

Epoch: 6| Step: 3
Training loss: 1.9828591346740723
Validation loss: 2.0270283094016452

Epoch: 6| Step: 4
Training loss: 1.6741260290145874
Validation loss: 2.02137569714618

Epoch: 6| Step: 5
Training loss: 1.794885516166687
Validation loss: 2.0150697026201474

Epoch: 6| Step: 6
Training loss: 2.127920150756836
Validation loss: 1.9911497715980775

Epoch: 6| Step: 7
Training loss: 1.3346549272537231
Validation loss: 1.9655560242232455

Epoch: 6| Step: 8
Training loss: 2.326049327850342
Validation loss: 1.9793796603397658

Epoch: 6| Step: 9
Training loss: 2.2099454402923584
Validation loss: 1.9686756377579064

Epoch: 6| Step: 10
Training loss: 1.080672264099121
Validation loss: 1.9905948664552422

Epoch: 6| Step: 11
Training loss: 2.2150583267211914
Validation loss: 1.9815614018388974

Epoch: 6| Step: 12
Training loss: 1.166988492012024
Validation loss: 1.97419390883497

Epoch: 6| Step: 13
Training loss: 2.791776657104492
Validation loss: 1.9635489653515559

Epoch: 142| Step: 0
Training loss: 1.3742822408676147
Validation loss: 1.940648219918692

Epoch: 6| Step: 1
Training loss: 1.8328993320465088
Validation loss: 1.9712155390811223

Epoch: 6| Step: 2
Training loss: 2.1630778312683105
Validation loss: 1.9973808796175065

Epoch: 6| Step: 3
Training loss: 1.6966592073440552
Validation loss: 2.0076552334652153

Epoch: 6| Step: 4
Training loss: 1.8144235610961914
Validation loss: 2.0168370200741674

Epoch: 6| Step: 5
Training loss: 2.2552473545074463
Validation loss: 2.0217567720720844

Epoch: 6| Step: 6
Training loss: 1.8621253967285156
Validation loss: 2.0121705532073975

Epoch: 6| Step: 7
Training loss: 2.1027286052703857
Validation loss: 1.9981530571496615

Epoch: 6| Step: 8
Training loss: 1.6216628551483154
Validation loss: 1.9948699012879403

Epoch: 6| Step: 9
Training loss: 1.4336166381835938
Validation loss: 2.007069892780755

Epoch: 6| Step: 10
Training loss: 1.8437330722808838
Validation loss: 2.006360048888832

Epoch: 6| Step: 11
Training loss: 2.0227088928222656
Validation loss: 2.007736985401441

Epoch: 6| Step: 12
Training loss: 1.4886572360992432
Validation loss: 1.9816138436717372

Epoch: 6| Step: 13
Training loss: 1.4006321430206299
Validation loss: 1.990138658913233

Epoch: 143| Step: 0
Training loss: 1.6909997463226318
Validation loss: 1.9787897089476227

Epoch: 6| Step: 1
Training loss: 1.729323387145996
Validation loss: 1.9814972249410485

Epoch: 6| Step: 2
Training loss: 2.073925733566284
Validation loss: 1.9807059175224715

Epoch: 6| Step: 3
Training loss: 1.875619649887085
Validation loss: 1.9798275565588346

Epoch: 6| Step: 4
Training loss: 1.6626147031784058
Validation loss: 1.984493556843009

Epoch: 6| Step: 5
Training loss: 0.8461560606956482
Validation loss: 1.9909991397652576

Epoch: 6| Step: 6
Training loss: 2.488915205001831
Validation loss: 1.9944151652756559

Epoch: 6| Step: 7
Training loss: 1.8572425842285156
Validation loss: 2.017736615673188

Epoch: 6| Step: 8
Training loss: 1.405235767364502
Validation loss: 2.041448243202702

Epoch: 6| Step: 9
Training loss: 1.9017421007156372
Validation loss: 2.033542763802313

Epoch: 6| Step: 10
Training loss: 2.0236148834228516
Validation loss: 2.0064700380448373

Epoch: 6| Step: 11
Training loss: 1.6560856103897095
Validation loss: 2.0029845237731934

Epoch: 6| Step: 12
Training loss: 1.680062174797058
Validation loss: 1.9906829223837903

Epoch: 6| Step: 13
Training loss: 1.662948727607727
Validation loss: 2.0010795336897655

Epoch: 144| Step: 0
Training loss: 1.9542236328125
Validation loss: 2.009684307600862

Epoch: 6| Step: 1
Training loss: 1.930367350578308
Validation loss: 2.0304050548102266

Epoch: 6| Step: 2
Training loss: 1.6245841979980469
Validation loss: 2.0143328712832544

Epoch: 6| Step: 3
Training loss: 1.8938982486724854
Validation loss: 2.0063415599125687

Epoch: 6| Step: 4
Training loss: 1.287742018699646
Validation loss: 2.0051545930165116

Epoch: 6| Step: 5
Training loss: 1.0631074905395508
Validation loss: 2.000611050154573

Epoch: 6| Step: 6
Training loss: 2.4822566509246826
Validation loss: 1.9928747351451586

Epoch: 6| Step: 7
Training loss: 1.9320143461227417
Validation loss: 2.0127738611672514

Epoch: 6| Step: 8
Training loss: 1.9633142948150635
Validation loss: 2.015240607723113

Epoch: 6| Step: 9
Training loss: 1.0394295454025269
Validation loss: 2.0030024205484698

Epoch: 6| Step: 10
Training loss: 2.114833354949951
Validation loss: 1.965058252375613

Epoch: 6| Step: 11
Training loss: 2.1225643157958984
Validation loss: 1.967734198416433

Epoch: 6| Step: 12
Training loss: 1.8284385204315186
Validation loss: 1.9408807011060818

Epoch: 6| Step: 13
Training loss: 1.3877367973327637
Validation loss: 1.9401599681505592

Epoch: 145| Step: 0
Training loss: 1.6747050285339355
Validation loss: 1.9376699168195006

Epoch: 6| Step: 1
Training loss: 1.8315033912658691
Validation loss: 1.946807671618718

Epoch: 6| Step: 2
Training loss: 2.3898165225982666
Validation loss: 1.9607696328111874

Epoch: 6| Step: 3
Training loss: 1.7124545574188232
Validation loss: 1.970003238288305

Epoch: 6| Step: 4
Training loss: 1.2286216020584106
Validation loss: 1.9713397205516856

Epoch: 6| Step: 5
Training loss: 1.653669834136963
Validation loss: 2.0044822718507502

Epoch: 6| Step: 6
Training loss: 2.086463451385498
Validation loss: 2.032735614366429

Epoch: 6| Step: 7
Training loss: 1.5660362243652344
Validation loss: 2.05112858228786

Epoch: 6| Step: 8
Training loss: 2.0975522994995117
Validation loss: 2.043971420616232

Epoch: 6| Step: 9
Training loss: 1.0929455757141113
Validation loss: 2.042306689805882

Epoch: 6| Step: 10
Training loss: 1.2437427043914795
Validation loss: 2.0308760289222962

Epoch: 6| Step: 11
Training loss: 2.307544231414795
Validation loss: 2.0078289560092393

Epoch: 6| Step: 12
Training loss: 1.4406002759933472
Validation loss: 2.010661766093264

Epoch: 6| Step: 13
Training loss: 2.072211980819702
Validation loss: 2.000515627604659

Epoch: 146| Step: 0
Training loss: 1.5349831581115723
Validation loss: 1.9913905769266107

Epoch: 6| Step: 1
Training loss: 1.9478639364242554
Validation loss: 1.9908482874593427

Epoch: 6| Step: 2
Training loss: 1.5898983478546143
Validation loss: 1.9654515943219584

Epoch: 6| Step: 3
Training loss: 1.6107759475708008
Validation loss: 1.9662357658468268

Epoch: 6| Step: 4
Training loss: 1.9638864994049072
Validation loss: 1.9818212998810636

Epoch: 6| Step: 5
Training loss: 1.3613548278808594
Validation loss: 2.006507514625467

Epoch: 6| Step: 6
Training loss: 1.9291894435882568
Validation loss: 2.028174538766184

Epoch: 6| Step: 7
Training loss: 1.6828677654266357
Validation loss: 2.077446614542315

Epoch: 6| Step: 8
Training loss: 2.524421215057373
Validation loss: 2.077309130340494

Epoch: 6| Step: 9
Training loss: 1.175886869430542
Validation loss: 2.0845797856648765

Epoch: 6| Step: 10
Training loss: 1.5900806188583374
Validation loss: 2.049596021252294

Epoch: 6| Step: 11
Training loss: 1.1881122589111328
Validation loss: 2.044265300996842

Epoch: 6| Step: 12
Training loss: 1.9208948612213135
Validation loss: 2.0225981256013275

Epoch: 6| Step: 13
Training loss: 1.9816635847091675
Validation loss: 2.032509575607956

Epoch: 147| Step: 0
Training loss: 1.7523831129074097
Validation loss: 2.01646811603218

Epoch: 6| Step: 1
Training loss: 0.9070666432380676
Validation loss: 2.0193628457284745

Epoch: 6| Step: 2
Training loss: 1.3468847274780273
Validation loss: 2.008612484060308

Epoch: 6| Step: 3
Training loss: 2.100888252258301
Validation loss: 2.003015079805928

Epoch: 6| Step: 4
Training loss: 1.5137858390808105
Validation loss: 2.036191636516202

Epoch: 6| Step: 5
Training loss: 1.968519687652588
Validation loss: 2.03962444233638

Epoch: 6| Step: 6
Training loss: 1.841767430305481
Validation loss: 2.043070399633018

Epoch: 6| Step: 7
Training loss: 1.9096866846084595
Validation loss: 2.0270557736837738

Epoch: 6| Step: 8
Training loss: 1.9326839447021484
Validation loss: 2.0410647776819046

Epoch: 6| Step: 9
Training loss: 2.546426773071289
Validation loss: 2.022163152694702

Epoch: 6| Step: 10
Training loss: 1.117630124092102
Validation loss: 1.996169731181155

Epoch: 6| Step: 11
Training loss: 1.4443011283874512
Validation loss: 1.9842165862360308

Epoch: 6| Step: 12
Training loss: 1.2392195463180542
Validation loss: 1.990796055845035

Epoch: 6| Step: 13
Training loss: 2.0596981048583984
Validation loss: 1.993770363510296

Epoch: 148| Step: 0
Training loss: 2.580418586730957
Validation loss: 2.025797008186258

Epoch: 6| Step: 1
Training loss: 2.250575065612793
Validation loss: 2.0586314739719516

Epoch: 6| Step: 2
Training loss: 1.8587249517440796
Validation loss: 2.0525208032259377

Epoch: 6| Step: 3
Training loss: 1.2568964958190918
Validation loss: 2.017145073542031

Epoch: 6| Step: 4
Training loss: 0.8628976345062256
Validation loss: 2.0077005201770413

Epoch: 6| Step: 5
Training loss: 1.1325807571411133
Validation loss: 2.0175759689782256

Epoch: 6| Step: 6
Training loss: 1.6353687047958374
Validation loss: 2.019826009709348

Epoch: 6| Step: 7
Training loss: 1.6048343181610107
Validation loss: 2.008348993075791

Epoch: 6| Step: 8
Training loss: 2.0205893516540527
Validation loss: 2.0025343087411698

Epoch: 6| Step: 9
Training loss: 1.4332125186920166
Validation loss: 1.9733329229457404

Epoch: 6| Step: 10
Training loss: 1.6051324605941772
Validation loss: 1.9664152130003898

Epoch: 6| Step: 11
Training loss: 0.9425187706947327
Validation loss: 1.978344791678972

Epoch: 6| Step: 12
Training loss: 1.8429864645004272
Validation loss: 1.9816366241824241

Epoch: 6| Step: 13
Training loss: 3.4705371856689453
Validation loss: 1.9975280915537188

Epoch: 149| Step: 0
Training loss: 1.759360432624817
Validation loss: 1.9951076174295077

Epoch: 6| Step: 1
Training loss: 1.563212513923645
Validation loss: 1.9846008413581437

Epoch: 6| Step: 2
Training loss: 1.4178614616394043
Validation loss: 1.994829793130198

Epoch: 6| Step: 3
Training loss: 2.015111207962036
Validation loss: 1.9865655424774333

Epoch: 6| Step: 4
Training loss: 1.2559454441070557
Validation loss: 2.007134170942409

Epoch: 6| Step: 5
Training loss: 2.3931288719177246
Validation loss: 2.004750103078863

Epoch: 6| Step: 6
Training loss: 1.1895965337753296
Validation loss: 2.0082757472991943

Epoch: 6| Step: 7
Training loss: 1.2691574096679688
Validation loss: 2.0162361360365346

Epoch: 6| Step: 8
Training loss: 1.5440595149993896
Validation loss: 2.003885366583383

Epoch: 6| Step: 9
Training loss: 1.2723801136016846
Validation loss: 1.9970893424044374

Epoch: 6| Step: 10
Training loss: 1.9887323379516602
Validation loss: 2.020114078316637

Epoch: 6| Step: 11
Training loss: 1.8750314712524414
Validation loss: 2.032803479061332

Epoch: 6| Step: 12
Training loss: 1.6012660264968872
Validation loss: 2.0541734028888006

Epoch: 6| Step: 13
Training loss: 2.2845373153686523
Validation loss: 2.059290850034324

Epoch: 150| Step: 0
Training loss: 1.4448916912078857
Validation loss: 2.021259933389643

Epoch: 6| Step: 1
Training loss: 1.676483392715454
Validation loss: 2.011451287936139

Epoch: 6| Step: 2
Training loss: 2.668868064880371
Validation loss: 1.9803203126435638

Epoch: 6| Step: 3
Training loss: 1.5080509185791016
Validation loss: 1.9672430343525384

Epoch: 6| Step: 4
Training loss: 1.0772316455841064
Validation loss: 1.9616433446125319

Epoch: 6| Step: 5
Training loss: 2.108048915863037
Validation loss: 1.970768859309535

Epoch: 6| Step: 6
Training loss: 1.5936253070831299
Validation loss: 1.951502089859337

Epoch: 6| Step: 7
Training loss: 1.815794825553894
Validation loss: 1.9606451578037714

Epoch: 6| Step: 8
Training loss: 1.5942003726959229
Validation loss: 1.9581384248630975

Epoch: 6| Step: 9
Training loss: 1.4801427125930786
Validation loss: 1.9848285375102874

Epoch: 6| Step: 10
Training loss: 1.715031623840332
Validation loss: 2.0117703996678835

Epoch: 6| Step: 11
Training loss: 1.1191754341125488
Validation loss: 2.028748651986481

Epoch: 6| Step: 12
Training loss: 1.4743506908416748
Validation loss: 2.0282353688311834

Epoch: 6| Step: 13
Training loss: 1.3330055475234985
Validation loss: 2.0574468515252553

Epoch: 151| Step: 0
Training loss: 1.4676392078399658
Validation loss: 2.08201789727775

Epoch: 6| Step: 1
Training loss: 1.9148812294006348
Validation loss: 2.153770605723063

Epoch: 6| Step: 2
Training loss: 2.1435439586639404
Validation loss: 2.2321684539958997

Epoch: 6| Step: 3
Training loss: 1.8887317180633545
Validation loss: 2.220953426053447

Epoch: 6| Step: 4
Training loss: 2.082818031311035
Validation loss: 2.1730118464398127

Epoch: 6| Step: 5
Training loss: 2.317828416824341
Validation loss: 2.1239403088887534

Epoch: 6| Step: 6
Training loss: 1.3522018194198608
Validation loss: 2.0587070565069876

Epoch: 6| Step: 7
Training loss: 1.6763713359832764
Validation loss: 2.028989356051209

Epoch: 6| Step: 8
Training loss: 0.961012601852417
Validation loss: 2.0430658325072257

Epoch: 6| Step: 9
Training loss: 1.5694026947021484
Validation loss: 2.075585085858581

Epoch: 6| Step: 10
Training loss: 2.2864134311676025
Validation loss: 2.096252061987436

Epoch: 6| Step: 11
Training loss: 1.2922337055206299
Validation loss: 2.0817920802741923

Epoch: 6| Step: 12
Training loss: 1.7454524040222168
Validation loss: 2.082813004011749

Epoch: 6| Step: 13
Training loss: 1.8819836378097534
Validation loss: 2.019640299581712

Epoch: 152| Step: 0
Training loss: 1.650743007659912
Validation loss: 1.9941249303920294

Epoch: 6| Step: 1
Training loss: 1.3634874820709229
Validation loss: 2.004026089945147

Epoch: 6| Step: 2
Training loss: 1.5647556781768799
Validation loss: 2.0555772960826917

Epoch: 6| Step: 3
Training loss: 2.1974501609802246
Validation loss: 2.1083677173942648

Epoch: 6| Step: 4
Training loss: 1.230106234550476
Validation loss: 2.147169513087119

Epoch: 6| Step: 5
Training loss: 1.6459074020385742
Validation loss: 2.1450948356300272

Epoch: 6| Step: 6
Training loss: 2.131901502609253
Validation loss: 2.114049429534584

Epoch: 6| Step: 7
Training loss: 1.4171444177627563
Validation loss: 2.079821176426385

Epoch: 6| Step: 8
Training loss: 1.6219377517700195
Validation loss: 2.0478583740931686

Epoch: 6| Step: 9
Training loss: 2.272130250930786
Validation loss: 2.0457930975062872

Epoch: 6| Step: 10
Training loss: 0.9745163917541504
Validation loss: 2.0346629632416593

Epoch: 6| Step: 11
Training loss: 2.005969285964966
Validation loss: 2.0096779587448284

Epoch: 6| Step: 12
Training loss: 1.8592416048049927
Validation loss: 2.0033593959705804

Epoch: 6| Step: 13
Training loss: 1.86517333984375
Validation loss: 1.9961497527296825

Epoch: 153| Step: 0
Training loss: 1.510941982269287
Validation loss: 2.0087425144769813

Epoch: 6| Step: 1
Training loss: 1.428564190864563
Validation loss: 2.0365893789516982

Epoch: 6| Step: 2
Training loss: 1.456430196762085
Validation loss: 2.0466681526553248

Epoch: 6| Step: 3
Training loss: 1.6285160779953003
Validation loss: 2.038280669079032

Epoch: 6| Step: 4
Training loss: 1.7135305404663086
Validation loss: 2.04323769897543

Epoch: 6| Step: 5
Training loss: 1.225807547569275
Validation loss: 2.0390737659187725

Epoch: 6| Step: 6
Training loss: 1.4684937000274658
Validation loss: 2.006250883943291

Epoch: 6| Step: 7
Training loss: 1.4814095497131348
Validation loss: 2.009275390255836

Epoch: 6| Step: 8
Training loss: 1.552452802658081
Validation loss: 2.040199190057734

Epoch: 6| Step: 9
Training loss: 2.312880039215088
Validation loss: 2.0569392327339417

Epoch: 6| Step: 10
Training loss: 1.3949869871139526
Validation loss: 2.0384998167714765

Epoch: 6| Step: 11
Training loss: 2.0923891067504883
Validation loss: 2.023326617415233

Epoch: 6| Step: 12
Training loss: 1.819716215133667
Validation loss: 2.0048573363211846

Epoch: 6| Step: 13
Training loss: 1.9391767978668213
Validation loss: 1.9988947055673087

Epoch: 154| Step: 0
Training loss: 1.193967580795288
Validation loss: 2.0266818128606325

Epoch: 6| Step: 1
Training loss: 1.2989753484725952
Validation loss: 2.022365462395453

Epoch: 6| Step: 2
Training loss: 1.4907734394073486
Validation loss: 2.024401685243012

Epoch: 6| Step: 3
Training loss: 1.3147766590118408
Validation loss: 2.02847800203549

Epoch: 6| Step: 4
Training loss: 1.994896411895752
Validation loss: 2.0352620283762612

Epoch: 6| Step: 5
Training loss: 2.1059648990631104
Validation loss: 2.0346124300392727

Epoch: 6| Step: 6
Training loss: 1.2242871522903442
Validation loss: 2.0345693826675415

Epoch: 6| Step: 7
Training loss: 1.5847222805023193
Validation loss: 2.028675917656191

Epoch: 6| Step: 8
Training loss: 1.9040634632110596
Validation loss: 2.0391609822550127

Epoch: 6| Step: 9
Training loss: 1.2930214405059814
Validation loss: 2.0158930670830513

Epoch: 6| Step: 10
Training loss: 1.6930900812149048
Validation loss: 2.002027419305617

Epoch: 6| Step: 11
Training loss: 1.5325944423675537
Validation loss: 2.000399225501604

Epoch: 6| Step: 12
Training loss: 1.258804440498352
Validation loss: 1.978913313599043

Epoch: 6| Step: 13
Training loss: 2.686523914337158
Validation loss: 1.9879644429811867

Epoch: 155| Step: 0
Training loss: 2.013134479522705
Validation loss: 1.97575391492536

Epoch: 6| Step: 1
Training loss: 0.9971336126327515
Validation loss: 1.9673470515076832

Epoch: 6| Step: 2
Training loss: 1.0993757247924805
Validation loss: 1.9814892161277033

Epoch: 6| Step: 3
Training loss: 2.188335418701172
Validation loss: 1.972126317280595

Epoch: 6| Step: 4
Training loss: 1.1716032028198242
Validation loss: 1.978572440403764

Epoch: 6| Step: 5
Training loss: 1.2545771598815918
Validation loss: 1.9987135484654417

Epoch: 6| Step: 6
Training loss: 1.3687050342559814
Validation loss: 1.980611821656586

Epoch: 6| Step: 7
Training loss: 1.8413782119750977
Validation loss: 1.999693505225643

Epoch: 6| Step: 8
Training loss: 2.268305778503418
Validation loss: 1.9912172696923698

Epoch: 6| Step: 9
Training loss: 1.5457179546356201
Validation loss: 1.9942620582478021

Epoch: 6| Step: 10
Training loss: 2.0302460193634033
Validation loss: 1.9776748611081032

Epoch: 6| Step: 11
Training loss: 1.8445487022399902
Validation loss: 2.0206050949711956

Epoch: 6| Step: 12
Training loss: 0.9192929267883301
Validation loss: 1.9893001805069626

Epoch: 6| Step: 13
Training loss: 1.108224630355835
Validation loss: 2.0004898322525846

Epoch: 156| Step: 0
Training loss: 1.6577541828155518
Validation loss: 2.026609746358728

Epoch: 6| Step: 1
Training loss: 0.888911247253418
Validation loss: 2.026468834569377

Epoch: 6| Step: 2
Training loss: 1.8490028381347656
Validation loss: 2.046237849420117

Epoch: 6| Step: 3
Training loss: 0.9503475427627563
Validation loss: 2.0515933869987406

Epoch: 6| Step: 4
Training loss: 1.6874728202819824
Validation loss: 2.037602193893925

Epoch: 6| Step: 5
Training loss: 1.6252095699310303
Validation loss: 2.0407051950372677

Epoch: 6| Step: 6
Training loss: 1.7215182781219482
Validation loss: 2.0106346043207313

Epoch: 6| Step: 7
Training loss: 1.486707329750061
Validation loss: 2.0213961370529665

Epoch: 6| Step: 8
Training loss: 1.5146173238754272
Validation loss: 2.024252405730627

Epoch: 6| Step: 9
Training loss: 1.6537257432937622
Validation loss: 2.0302041704936693

Epoch: 6| Step: 10
Training loss: 1.852479338645935
Validation loss: 2.022815386454264

Epoch: 6| Step: 11
Training loss: 1.412405252456665
Validation loss: 2.0291575924042733

Epoch: 6| Step: 12
Training loss: 1.2352185249328613
Validation loss: 2.0086618982335573

Epoch: 6| Step: 13
Training loss: 1.8764300346374512
Validation loss: 2.0192859941913235

Epoch: 157| Step: 0
Training loss: 1.5292384624481201
Validation loss: 2.0133160134797454

Epoch: 6| Step: 1
Training loss: 1.9837630987167358
Validation loss: 2.0116425380911878

Epoch: 6| Step: 2
Training loss: 1.4098190069198608
Validation loss: 2.015185658649732

Epoch: 6| Step: 3
Training loss: 1.4124281406402588
Validation loss: 2.024656998213901

Epoch: 6| Step: 4
Training loss: 1.2156710624694824
Validation loss: 2.03121954394925

Epoch: 6| Step: 5
Training loss: 1.8665881156921387
Validation loss: 2.0643263555342153

Epoch: 6| Step: 6
Training loss: 1.301896572113037
Validation loss: 2.042845238921463

Epoch: 6| Step: 7
Training loss: 1.080206274986267
Validation loss: 2.041781284475839

Epoch: 6| Step: 8
Training loss: 2.3236117362976074
Validation loss: 2.0319383311015304

Epoch: 6| Step: 9
Training loss: 1.628092885017395
Validation loss: 2.0116342190773255

Epoch: 6| Step: 10
Training loss: 1.8728406429290771
Validation loss: 2.002763023940466

Epoch: 6| Step: 11
Training loss: 1.4456908702850342
Validation loss: 1.9894247362690587

Epoch: 6| Step: 12
Training loss: 1.3011860847473145
Validation loss: 1.9914229967260872

Epoch: 6| Step: 13
Training loss: 0.7002546787261963
Validation loss: 1.981479065392607

Epoch: 158| Step: 0
Training loss: 2.0019309520721436
Validation loss: 1.982473583631618

Epoch: 6| Step: 1
Training loss: 1.4084807634353638
Validation loss: 2.0085301758140646

Epoch: 6| Step: 2
Training loss: 1.2929883003234863
Validation loss: 2.0252391702385357

Epoch: 6| Step: 3
Training loss: 1.7278964519500732
Validation loss: 2.0167717856745564

Epoch: 6| Step: 4
Training loss: 1.7652161121368408
Validation loss: 1.972894323769436

Epoch: 6| Step: 5
Training loss: 1.7243053913116455
Validation loss: 1.9824214186719669

Epoch: 6| Step: 6
Training loss: 1.0018993616104126
Validation loss: 1.9876089416524416

Epoch: 6| Step: 7
Training loss: 1.6767785549163818
Validation loss: 2.0079553665653354

Epoch: 6| Step: 8
Training loss: 1.2415233850479126
Validation loss: 2.0246858314801286

Epoch: 6| Step: 9
Training loss: 1.5918512344360352
Validation loss: 2.040624938985353

Epoch: 6| Step: 10
Training loss: 2.235276222229004
Validation loss: 2.0379866297527025

Epoch: 6| Step: 11
Training loss: 0.9040281772613525
Validation loss: 2.0091256890245663

Epoch: 6| Step: 12
Training loss: 1.7645738124847412
Validation loss: 2.0142778427370134

Epoch: 6| Step: 13
Training loss: 1.6296038627624512
Validation loss: 2.043386729814673

Epoch: 159| Step: 0
Training loss: 1.3634300231933594
Validation loss: 2.0883945034396265

Epoch: 6| Step: 1
Training loss: 1.4987913370132446
Validation loss: 2.134175754362537

Epoch: 6| Step: 2
Training loss: 1.1498552560806274
Validation loss: 2.1494439609589113

Epoch: 6| Step: 3
Training loss: 1.8166635036468506
Validation loss: 2.1479502518971763

Epoch: 6| Step: 4
Training loss: 1.579529047012329
Validation loss: 2.1099423311089955

Epoch: 6| Step: 5
Training loss: 1.2433769702911377
Validation loss: 2.026106975411856

Epoch: 6| Step: 6
Training loss: 1.4756417274475098
Validation loss: 1.9954880104270032

Epoch: 6| Step: 7
Training loss: 1.7038335800170898
Validation loss: 1.9710105055121965

Epoch: 6| Step: 8
Training loss: 1.8248648643493652
Validation loss: 1.9843929685572141

Epoch: 6| Step: 9
Training loss: 1.5634453296661377
Validation loss: 1.9770101757459744

Epoch: 6| Step: 10
Training loss: 1.7297894954681396
Validation loss: 1.9880965255921887

Epoch: 6| Step: 11
Training loss: 1.4771702289581299
Validation loss: 1.9813232280874764

Epoch: 6| Step: 12
Training loss: 1.4699851274490356
Validation loss: 2.0017294217181463

Epoch: 6| Step: 13
Training loss: 1.3091708421707153
Validation loss: 2.0005676848914034

Epoch: 160| Step: 0
Training loss: 1.0981401205062866
Validation loss: 1.9961623261051793

Epoch: 6| Step: 1
Training loss: 2.0420329570770264
Validation loss: 2.036452562578263

Epoch: 6| Step: 2
Training loss: 1.2092058658599854
Validation loss: 2.050239204078592

Epoch: 6| Step: 3
Training loss: 1.1653629541397095
Validation loss: 2.0398741640070432

Epoch: 6| Step: 4
Training loss: 2.006406545639038
Validation loss: 2.0283554677040345

Epoch: 6| Step: 5
Training loss: 1.2178246974945068
Validation loss: 1.9814430308598343

Epoch: 6| Step: 6
Training loss: 2.1551599502563477
Validation loss: 1.941885918699285

Epoch: 6| Step: 7
Training loss: 1.6476943492889404
Validation loss: 1.9377477425400929

Epoch: 6| Step: 8
Training loss: 1.4575425386428833
Validation loss: 1.9376135154436993

Epoch: 6| Step: 9
Training loss: 1.6308788061141968
Validation loss: 1.9647150911310667

Epoch: 6| Step: 10
Training loss: 1.8909002542495728
Validation loss: 1.9714089644852506

Epoch: 6| Step: 11
Training loss: 0.8386452198028564
Validation loss: 1.9690478412053918

Epoch: 6| Step: 12
Training loss: 1.7883321046829224
Validation loss: 1.9823614833175496

Epoch: 6| Step: 13
Training loss: 1.6582270860671997
Validation loss: 1.9907412580264512

Epoch: 161| Step: 0
Training loss: 1.2621556520462036
Validation loss: 2.031113016989923

Epoch: 6| Step: 1
Training loss: 1.4841489791870117
Validation loss: 2.0562183959509737

Epoch: 6| Step: 2
Training loss: 1.325406789779663
Validation loss: 2.098644748810799

Epoch: 6| Step: 3
Training loss: 0.9471893310546875
Validation loss: 2.1272450185591176

Epoch: 6| Step: 4
Training loss: 1.704392910003662
Validation loss: 2.125675706453221

Epoch: 6| Step: 5
Training loss: 1.3466812372207642
Validation loss: 2.1235699679261897

Epoch: 6| Step: 6
Training loss: 1.7127537727355957
Validation loss: 2.0902021905427337

Epoch: 6| Step: 7
Training loss: 1.435503363609314
Validation loss: 2.0622374408988544

Epoch: 6| Step: 8
Training loss: 1.9361053705215454
Validation loss: 2.0490761033950315

Epoch: 6| Step: 9
Training loss: 1.1429452896118164
Validation loss: 2.042016952268539

Epoch: 6| Step: 10
Training loss: 1.6765425205230713
Validation loss: 1.9941997656258204

Epoch: 6| Step: 11
Training loss: 2.0370380878448486
Validation loss: 1.976198859112237

Epoch: 6| Step: 12
Training loss: 1.6553479433059692
Validation loss: 1.9506119297396751

Epoch: 6| Step: 13
Training loss: 1.8393616676330566
Validation loss: 1.9662688009200557

Epoch: 162| Step: 0
Training loss: 1.1210427284240723
Validation loss: 1.9569294811576925

Epoch: 6| Step: 1
Training loss: 1.497869849205017
Validation loss: 1.9787465628757273

Epoch: 6| Step: 2
Training loss: 1.2127490043640137
Validation loss: 1.9911488512510895

Epoch: 6| Step: 3
Training loss: 2.288801908493042
Validation loss: 1.988704143031951

Epoch: 6| Step: 4
Training loss: 1.4269218444824219
Validation loss: 1.9873575971972557

Epoch: 6| Step: 5
Training loss: 0.9281114339828491
Validation loss: 1.9933098746884255

Epoch: 6| Step: 6
Training loss: 1.9839985370635986
Validation loss: 1.9961362218344083

Epoch: 6| Step: 7
Training loss: 1.3560926914215088
Validation loss: 1.9987807684047247

Epoch: 6| Step: 8
Training loss: 1.4155464172363281
Validation loss: 1.99750764395601

Epoch: 6| Step: 9
Training loss: 1.2349753379821777
Validation loss: 1.9842570058761104

Epoch: 6| Step: 10
Training loss: 1.3122475147247314
Validation loss: 2.022918129480013

Epoch: 6| Step: 11
Training loss: 1.3299198150634766
Validation loss: 2.0309363949683403

Epoch: 6| Step: 12
Training loss: 1.9701576232910156
Validation loss: 2.070136190742575

Epoch: 6| Step: 13
Training loss: 1.8352266550064087
Validation loss: 2.090370975514894

Epoch: 163| Step: 0
Training loss: 1.2378416061401367
Validation loss: 2.067152310443181

Epoch: 6| Step: 1
Training loss: 0.7713735699653625
Validation loss: 2.044854087214316

Epoch: 6| Step: 2
Training loss: 1.3839510679244995
Validation loss: 1.9985713317830076

Epoch: 6| Step: 3
Training loss: 1.582709789276123
Validation loss: 1.9856437906142204

Epoch: 6| Step: 4
Training loss: 1.6086905002593994
Validation loss: 1.9921396957930697

Epoch: 6| Step: 5
Training loss: 1.6627764701843262
Validation loss: 1.9830142208324966

Epoch: 6| Step: 6
Training loss: 1.1331367492675781
Validation loss: 1.9931563882417576

Epoch: 6| Step: 7
Training loss: 1.6672122478485107
Validation loss: 2.019854963466685

Epoch: 6| Step: 8
Training loss: 1.1574530601501465
Validation loss: 2.0369035813116256

Epoch: 6| Step: 9
Training loss: 1.646306037902832
Validation loss: 2.0413461859508226

Epoch: 6| Step: 10
Training loss: 1.7857924699783325
Validation loss: 2.0467938120647142

Epoch: 6| Step: 11
Training loss: 1.0969468355178833
Validation loss: 2.034800309006886

Epoch: 6| Step: 12
Training loss: 2.0053176879882812
Validation loss: 2.0192693651363416

Epoch: 6| Step: 13
Training loss: 1.3604965209960938
Validation loss: 1.987413260244554

Epoch: 164| Step: 0
Training loss: 1.2334822416305542
Validation loss: 1.9919721900775869

Epoch: 6| Step: 1
Training loss: 1.6998531818389893
Validation loss: 2.00243305647245

Epoch: 6| Step: 2
Training loss: 1.3056858777999878
Validation loss: 2.055916638784511

Epoch: 6| Step: 3
Training loss: 2.0991086959838867
Validation loss: 2.0734435409627934

Epoch: 6| Step: 4
Training loss: 1.4516727924346924
Validation loss: 2.082657601243706

Epoch: 6| Step: 5
Training loss: 1.2645549774169922
Validation loss: 2.088682275946422

Epoch: 6| Step: 6
Training loss: 1.6570014953613281
Validation loss: 2.0408772947967693

Epoch: 6| Step: 7
Training loss: 1.0534849166870117
Validation loss: 2.0289269878018286

Epoch: 6| Step: 8
Training loss: 1.1822975873947144
Validation loss: 2.0458826582918883

Epoch: 6| Step: 9
Training loss: 1.770582914352417
Validation loss: 2.0694467688119538

Epoch: 6| Step: 10
Training loss: 1.0177515745162964
Validation loss: 2.0959735249960296

Epoch: 6| Step: 11
Training loss: 1.6989293098449707
Validation loss: 2.0835246091247885

Epoch: 6| Step: 12
Training loss: 1.119469165802002
Validation loss: 2.074480128544633

Epoch: 6| Step: 13
Training loss: 1.6614760160446167
Validation loss: 2.0679050376338344

Epoch: 165| Step: 0
Training loss: 1.3459190130233765
Validation loss: 2.048613694406325

Epoch: 6| Step: 1
Training loss: 2.005610466003418
Validation loss: 2.0574808710364887

Epoch: 6| Step: 2
Training loss: 1.6556370258331299
Validation loss: 2.057069682305859

Epoch: 6| Step: 3
Training loss: 1.3769922256469727
Validation loss: 2.0475433065045263

Epoch: 6| Step: 4
Training loss: 1.0294393301010132
Validation loss: 2.026432380881361

Epoch: 6| Step: 5
Training loss: 1.3566596508026123
Validation loss: 2.0021044797794794

Epoch: 6| Step: 6
Training loss: 1.2143168449401855
Validation loss: 2.009041322174893

Epoch: 6| Step: 7
Training loss: 1.600593090057373
Validation loss: 1.9979070976216307

Epoch: 6| Step: 8
Training loss: 0.5223473310470581
Validation loss: 1.9889629989541986

Epoch: 6| Step: 9
Training loss: 1.2066857814788818
Validation loss: 1.9815146884610575

Epoch: 6| Step: 10
Training loss: 1.4698882102966309
Validation loss: 1.9648863833437684

Epoch: 6| Step: 11
Training loss: 1.598146915435791
Validation loss: 1.9613628695088048

Epoch: 6| Step: 12
Training loss: 1.1764326095581055
Validation loss: 1.9762436369413972

Epoch: 6| Step: 13
Training loss: 2.31258225440979
Validation loss: 1.9493754820157123

Epoch: 166| Step: 0
Training loss: 1.553389549255371
Validation loss: 1.92980561717864

Epoch: 6| Step: 1
Training loss: 1.4072449207305908
Validation loss: 1.9416278369965092

Epoch: 6| Step: 2
Training loss: 1.7911982536315918
Validation loss: 1.938741462205046

Epoch: 6| Step: 3
Training loss: 1.9035786390304565
Validation loss: 1.949834430089561

Epoch: 6| Step: 4
Training loss: 0.6912080645561218
Validation loss: 1.9664594896378056

Epoch: 6| Step: 5
Training loss: 1.4926373958587646
Validation loss: 1.9768723774981756

Epoch: 6| Step: 6
Training loss: 1.4053971767425537
Validation loss: 1.9706102699361823

Epoch: 6| Step: 7
Training loss: 1.1002933979034424
Validation loss: 1.9755473380447717

Epoch: 6| Step: 8
Training loss: 1.38494873046875
Validation loss: 1.9752183973148305

Epoch: 6| Step: 9
Training loss: 1.6000566482543945
Validation loss: 1.9866425747512488

Epoch: 6| Step: 10
Training loss: 1.683482050895691
Validation loss: 1.9834687068898191

Epoch: 6| Step: 11
Training loss: 0.9040627479553223
Validation loss: 1.9991924865271455

Epoch: 6| Step: 12
Training loss: 1.1913373470306396
Validation loss: 2.0365210874106294

Epoch: 6| Step: 13
Training loss: 1.2259565591812134
Validation loss: 2.092928727467855

Epoch: 167| Step: 0
Training loss: 1.2222715616226196
Validation loss: 2.076535362069325

Epoch: 6| Step: 1
Training loss: 1.2588255405426025
Validation loss: 2.0961256411767777

Epoch: 6| Step: 2
Training loss: 0.4344906508922577
Validation loss: 2.0923377698467625

Epoch: 6| Step: 3
Training loss: 1.4219856262207031
Validation loss: 2.0981013749235418

Epoch: 6| Step: 4
Training loss: 1.7838025093078613
Validation loss: 2.043206602014521

Epoch: 6| Step: 5
Training loss: 2.131152391433716
Validation loss: 2.025657259007936

Epoch: 6| Step: 6
Training loss: 1.6842628717422485
Validation loss: 2.011984066296649

Epoch: 6| Step: 7
Training loss: 1.4612573385238647
Validation loss: 2.032632863649758

Epoch: 6| Step: 8
Training loss: 1.8524682521820068
Validation loss: 2.0421487464699695

Epoch: 6| Step: 9
Training loss: 1.368922472000122
Validation loss: 2.036807986997789

Epoch: 6| Step: 10
Training loss: 0.7354462146759033
Validation loss: 2.0251988441713396

Epoch: 6| Step: 11
Training loss: 1.2934499979019165
Validation loss: 2.0191891090844267

Epoch: 6| Step: 12
Training loss: 1.305832028388977
Validation loss: 2.0023325771413822

Epoch: 6| Step: 13
Training loss: 1.4835302829742432
Validation loss: 2.0147981874404417

Epoch: 168| Step: 0
Training loss: 1.334051489830017
Validation loss: 2.0003895426309235

Epoch: 6| Step: 1
Training loss: 0.6176937222480774
Validation loss: 1.9732643314587173

Epoch: 6| Step: 2
Training loss: 1.5055760145187378
Validation loss: 1.979331293413716

Epoch: 6| Step: 3
Training loss: 2.1157021522521973
Validation loss: 1.9773785170688425

Epoch: 6| Step: 4
Training loss: 1.6074397563934326
Validation loss: 1.9964716972843293

Epoch: 6| Step: 5
Training loss: 1.1588828563690186
Validation loss: 1.9829961728024226

Epoch: 6| Step: 6
Training loss: 1.1212515830993652
Validation loss: 2.004617262912053

Epoch: 6| Step: 7
Training loss: 1.1425646543502808
Validation loss: 2.0262115386224564

Epoch: 6| Step: 8
Training loss: 1.0269861221313477
Validation loss: 2.072597675426032

Epoch: 6| Step: 9
Training loss: 0.9698195457458496
Validation loss: 2.0502462848540275

Epoch: 6| Step: 10
Training loss: 1.749760389328003
Validation loss: 2.073752277640886

Epoch: 6| Step: 11
Training loss: 1.858440637588501
Validation loss: 2.0310589369907173

Epoch: 6| Step: 12
Training loss: 1.8636056184768677
Validation loss: 1.9891686221604705

Epoch: 6| Step: 13
Training loss: 1.2140650749206543
Validation loss: 1.99782605068658

Epoch: 169| Step: 0
Training loss: 1.168999195098877
Validation loss: 1.9918864644983763

Epoch: 6| Step: 1
Training loss: 1.5917315483093262
Validation loss: 1.9833358872321345

Epoch: 6| Step: 2
Training loss: 1.1071643829345703
Validation loss: 2.001788031670355

Epoch: 6| Step: 3
Training loss: 1.1168525218963623
Validation loss: 1.9929415974565732

Epoch: 6| Step: 4
Training loss: 0.931365966796875
Validation loss: 1.9783621488078948

Epoch: 6| Step: 5
Training loss: 1.2474267482757568
Validation loss: 1.966925064722697

Epoch: 6| Step: 6
Training loss: 1.2301831245422363
Validation loss: 1.9801703242845432

Epoch: 6| Step: 7
Training loss: 1.5855162143707275
Validation loss: 1.949181483637902

Epoch: 6| Step: 8
Training loss: 1.402390480041504
Validation loss: 1.9408339172281244

Epoch: 6| Step: 9
Training loss: 1.6629940271377563
Validation loss: 1.9346012761515956

Epoch: 6| Step: 10
Training loss: 1.1979529857635498
Validation loss: 1.952775998782086

Epoch: 6| Step: 11
Training loss: 1.6940641403198242
Validation loss: 1.978415886561076

Epoch: 6| Step: 12
Training loss: 1.932558298110962
Validation loss: 1.9911757976778093

Epoch: 6| Step: 13
Training loss: 2.0864343643188477
Validation loss: 2.0440818596911687

Epoch: 170| Step: 0
Training loss: 1.4063422679901123
Validation loss: 2.0063301183844127

Epoch: 6| Step: 1
Training loss: 1.632988691329956
Validation loss: 2.0063845944660965

Epoch: 6| Step: 2
Training loss: 1.0095168352127075
Validation loss: 2.010741997790593

Epoch: 6| Step: 3
Training loss: 0.8980050683021545
Validation loss: 2.0475414952924176

Epoch: 6| Step: 4
Training loss: 1.654428243637085
Validation loss: 2.067902503475066

Epoch: 6| Step: 5
Training loss: 1.506778597831726
Validation loss: 2.047431745836812

Epoch: 6| Step: 6
Training loss: 1.6034419536590576
Validation loss: 2.039373904146174

Epoch: 6| Step: 7
Training loss: 1.6593091487884521
Validation loss: 1.9959192993820354

Epoch: 6| Step: 8
Training loss: 0.7558690309524536
Validation loss: 2.025614446209323

Epoch: 6| Step: 9
Training loss: 1.2886520624160767
Validation loss: 2.0320892936439923

Epoch: 6| Step: 10
Training loss: 1.2407352924346924
Validation loss: 2.00572346743717

Epoch: 6| Step: 11
Training loss: 1.2035281658172607
Validation loss: 2.0118503852557112

Epoch: 6| Step: 12
Training loss: 1.6272904872894287
Validation loss: 2.0205270526229695

Epoch: 6| Step: 13
Training loss: 1.3208400011062622
Validation loss: 1.9940321394192275

Epoch: 171| Step: 0
Training loss: 0.913411557674408
Validation loss: 1.9895025530169088

Epoch: 6| Step: 1
Training loss: 1.2735182046890259
Validation loss: 1.9835958198834491

Epoch: 6| Step: 2
Training loss: 1.6514815092086792
Validation loss: 1.9466286538749613

Epoch: 6| Step: 3
Training loss: 1.3380060195922852
Validation loss: 1.9346374209209154

Epoch: 6| Step: 4
Training loss: 1.3214030265808105
Validation loss: 1.9363320835175053

Epoch: 6| Step: 5
Training loss: 1.6054613590240479
Validation loss: 1.9717994530995686

Epoch: 6| Step: 6
Training loss: 1.6864646673202515
Validation loss: 1.9996064362987396

Epoch: 6| Step: 7
Training loss: 1.3520872592926025
Validation loss: 2.0100103270622993

Epoch: 6| Step: 8
Training loss: 1.260162591934204
Validation loss: 1.988796095694265

Epoch: 6| Step: 9
Training loss: 1.8658726215362549
Validation loss: 1.973083693494079

Epoch: 6| Step: 10
Training loss: 1.0096991062164307
Validation loss: 1.9918634224963445

Epoch: 6| Step: 11
Training loss: 1.1619709730148315
Validation loss: 2.03336299491185

Epoch: 6| Step: 12
Training loss: 1.3623701333999634
Validation loss: 2.0186767155124294

Epoch: 6| Step: 13
Training loss: 1.3081049919128418
Validation loss: 2.0049318651999197

Epoch: 172| Step: 0
Training loss: 1.5296118259429932
Validation loss: 1.9893980051881524

Epoch: 6| Step: 1
Training loss: 1.467012882232666
Validation loss: 2.0158474624797864

Epoch: 6| Step: 2
Training loss: 1.4613051414489746
Validation loss: 2.0085525640877346

Epoch: 6| Step: 3
Training loss: 1.2937119007110596
Validation loss: 2.032478304319484

Epoch: 6| Step: 4
Training loss: 1.0842349529266357
Validation loss: 2.029359062512716

Epoch: 6| Step: 5
Training loss: 1.424113154411316
Validation loss: 2.0363563568361345

Epoch: 6| Step: 6
Training loss: 1.673208475112915
Validation loss: 2.010474584435904

Epoch: 6| Step: 7
Training loss: 1.0592284202575684
Validation loss: 1.9970497405657204

Epoch: 6| Step: 8
Training loss: 1.0299265384674072
Validation loss: 2.0117092594023673

Epoch: 6| Step: 9
Training loss: 1.6237447261810303
Validation loss: 2.037195263370391

Epoch: 6| Step: 10
Training loss: 1.1528174877166748
Validation loss: 2.00655520859585

Epoch: 6| Step: 11
Training loss: 1.1167576313018799
Validation loss: 1.9874814761582242

Epoch: 6| Step: 12
Training loss: 0.9758968949317932
Validation loss: 1.923137923722626

Epoch: 6| Step: 13
Training loss: 1.7175791263580322
Validation loss: 1.9061801689927296

Epoch: 173| Step: 0
Training loss: 1.1823945045471191
Validation loss: 1.9013966732127692

Epoch: 6| Step: 1
Training loss: 0.8797995448112488
Validation loss: 1.9003063324959046

Epoch: 6| Step: 2
Training loss: 2.0346004962921143
Validation loss: 1.8933394493595246

Epoch: 6| Step: 3
Training loss: 1.6474366188049316
Validation loss: 1.9271665567992835

Epoch: 6| Step: 4
Training loss: 0.9118714928627014
Validation loss: 1.969387387716642

Epoch: 6| Step: 5
Training loss: 1.188938021659851
Validation loss: 1.9839666992105462

Epoch: 6| Step: 6
Training loss: 1.0830802917480469
Validation loss: 2.01581774603936

Epoch: 6| Step: 7
Training loss: 1.075619101524353
Validation loss: 2.0360697136130383

Epoch: 6| Step: 8
Training loss: 1.156903862953186
Validation loss: 2.0110225267307733

Epoch: 6| Step: 9
Training loss: 1.2009708881378174
Validation loss: 2.0086453140422864

Epoch: 6| Step: 10
Training loss: 1.8844118118286133
Validation loss: 2.0016147680180048

Epoch: 6| Step: 11
Training loss: 1.3480918407440186
Validation loss: 1.995872955168447

Epoch: 6| Step: 12
Training loss: 1.3552634716033936
Validation loss: 2.0049248728700864

Epoch: 6| Step: 13
Training loss: 1.652635097503662
Validation loss: 2.001811219799903

Epoch: 174| Step: 0
Training loss: 1.510676383972168
Validation loss: 1.9781785331746584

Epoch: 6| Step: 1
Training loss: 0.6029990911483765
Validation loss: 1.9766391169640325

Epoch: 6| Step: 2
Training loss: 1.2560268640518188
Validation loss: 1.9864676255051807

Epoch: 6| Step: 3
Training loss: 1.2058602571487427
Validation loss: 1.9857231699010378

Epoch: 6| Step: 4
Training loss: 1.8041598796844482
Validation loss: 1.9863613728554017

Epoch: 6| Step: 5
Training loss: 1.9650614261627197
Validation loss: 1.9828144773360221

Epoch: 6| Step: 6
Training loss: 1.4225196838378906
Validation loss: 1.96390389755208

Epoch: 6| Step: 7
Training loss: 0.7458872199058533
Validation loss: 1.973447976573821

Epoch: 6| Step: 8
Training loss: 1.1915204524993896
Validation loss: 1.965269575836838

Epoch: 6| Step: 9
Training loss: 1.1936736106872559
Validation loss: 1.9537954638081212

Epoch: 6| Step: 10
Training loss: 1.260767936706543
Validation loss: 1.9573356566890594

Epoch: 6| Step: 11
Training loss: 0.961441159248352
Validation loss: 1.9530328473737162

Epoch: 6| Step: 12
Training loss: 1.071382999420166
Validation loss: 1.9676526643896615

Epoch: 6| Step: 13
Training loss: 1.4040703773498535
Validation loss: 1.9851690325685727

Epoch: 175| Step: 0
Training loss: 1.0637943744659424
Validation loss: 2.0079531695253108

Epoch: 6| Step: 1
Training loss: 1.192354679107666
Validation loss: 2.027462213270126

Epoch: 6| Step: 2
Training loss: 1.410448670387268
Validation loss: 2.0323559404701315

Epoch: 6| Step: 3
Training loss: 1.8221464157104492
Validation loss: 1.979934456527874

Epoch: 6| Step: 4
Training loss: 1.475823163986206
Validation loss: 1.9267645036020586

Epoch: 6| Step: 5
Training loss: 1.178225040435791
Validation loss: 1.9265157791876024

Epoch: 6| Step: 6
Training loss: 1.2795305252075195
Validation loss: 1.9133097689638856

Epoch: 6| Step: 7
Training loss: 1.0836055278778076
Validation loss: 1.909301068193169

Epoch: 6| Step: 8
Training loss: 1.4008651971817017
Validation loss: 1.9284103083354172

Epoch: 6| Step: 9
Training loss: 1.279787540435791
Validation loss: 1.921698406178464

Epoch: 6| Step: 10
Training loss: 1.0974725484848022
Validation loss: 1.9374959776478429

Epoch: 6| Step: 11
Training loss: 0.6658515930175781
Validation loss: 1.976059365016158

Epoch: 6| Step: 12
Training loss: 1.5515056848526
Validation loss: 1.9922061299764982

Epoch: 6| Step: 13
Training loss: 1.183011770248413
Validation loss: 2.017997634026312

Epoch: 176| Step: 0
Training loss: 1.0971999168395996
Validation loss: 2.0679649281245407

Epoch: 6| Step: 1
Training loss: 1.429864764213562
Validation loss: 2.0330624759838147

Epoch: 6| Step: 2
Training loss: 1.0906810760498047
Validation loss: 2.019372401698943

Epoch: 6| Step: 3
Training loss: 1.2282261848449707
Validation loss: 1.960720431420111

Epoch: 6| Step: 4
Training loss: 1.4221632480621338
Validation loss: 1.946807192217919

Epoch: 6| Step: 5
Training loss: 1.6284611225128174
Validation loss: 1.8901856458315285

Epoch: 6| Step: 6
Training loss: 1.614741325378418
Validation loss: 1.9068326309163084

Epoch: 6| Step: 7
Training loss: 1.199358582496643
Validation loss: 1.909729702498323

Epoch: 6| Step: 8
Training loss: 1.2882287502288818
Validation loss: 1.917474232694154

Epoch: 6| Step: 9
Training loss: 1.8357486724853516
Validation loss: 1.9507854241196827

Epoch: 6| Step: 10
Training loss: 1.351051926612854
Validation loss: 1.98082564210379

Epoch: 6| Step: 11
Training loss: 1.0607903003692627
Validation loss: 1.9960898481389528

Epoch: 6| Step: 12
Training loss: 0.7395947575569153
Validation loss: 2.0400510026562597

Epoch: 6| Step: 13
Training loss: 0.29396340250968933
Validation loss: 2.0352303751053347

Epoch: 177| Step: 0
Training loss: 1.3079948425292969
Validation loss: 2.026366456862419

Epoch: 6| Step: 1
Training loss: 0.7684992551803589
Validation loss: 2.0386128951144475

Epoch: 6| Step: 2
Training loss: 0.8894721269607544
Validation loss: 1.9964966697077597

Epoch: 6| Step: 3
Training loss: 1.4420771598815918
Validation loss: 1.9894175862753263

Epoch: 6| Step: 4
Training loss: 0.9759546518325806
Validation loss: 1.9534265200297039

Epoch: 6| Step: 5
Training loss: 1.2692514657974243
Validation loss: 1.9246162868315173

Epoch: 6| Step: 6
Training loss: 0.8768223524093628
Validation loss: 1.9341159866702171

Epoch: 6| Step: 7
Training loss: 1.0488485097885132
Validation loss: 1.9040666985255417

Epoch: 6| Step: 8
Training loss: 1.6319688558578491
Validation loss: 1.9223752047425957

Epoch: 6| Step: 9
Training loss: 1.9426909685134888
Validation loss: 1.9175306904700495

Epoch: 6| Step: 10
Training loss: 1.1228892803192139
Validation loss: 1.9175690912431287

Epoch: 6| Step: 11
Training loss: 1.0880615711212158
Validation loss: 1.9084682644054454

Epoch: 6| Step: 12
Training loss: 1.3960704803466797
Validation loss: 1.930722298160676

Epoch: 6| Step: 13
Training loss: 1.9242545366287231
Validation loss: 1.9074092218952794

Epoch: 178| Step: 0
Training loss: 1.431467056274414
Validation loss: 1.9073979239309988

Epoch: 6| Step: 1
Training loss: 0.8100471496582031
Validation loss: 1.9224743073986423

Epoch: 6| Step: 2
Training loss: 1.6239125728607178
Validation loss: 1.947896868951859

Epoch: 6| Step: 3
Training loss: 1.2125686407089233
Validation loss: 1.9547034079028713

Epoch: 6| Step: 4
Training loss: 0.7518866062164307
Validation loss: 1.9716489007396083

Epoch: 6| Step: 5
Training loss: 1.661881923675537
Validation loss: 1.9961785795868083

Epoch: 6| Step: 6
Training loss: 0.9415502548217773
Validation loss: 1.9957965996957594

Epoch: 6| Step: 7
Training loss: 1.4226539134979248
Validation loss: 2.0012671332205496

Epoch: 6| Step: 8
Training loss: 0.9954653978347778
Validation loss: 2.0139964934318297

Epoch: 6| Step: 9
Training loss: 0.5881105661392212
Validation loss: 2.0211521515282254

Epoch: 6| Step: 10
Training loss: 1.0400874614715576
Validation loss: 2.010989499348466

Epoch: 6| Step: 11
Training loss: 1.6807482242584229
Validation loss: 1.9953503762522051

Epoch: 6| Step: 12
Training loss: 0.6763243675231934
Validation loss: 1.9654362163236063

Epoch: 6| Step: 13
Training loss: 2.03271222114563
Validation loss: 1.967746300082053

Epoch: 179| Step: 0
Training loss: 0.7987593412399292
Validation loss: 1.9246032135460966

Epoch: 6| Step: 1
Training loss: 1.2711764574050903
Validation loss: 1.950006172221194

Epoch: 6| Step: 2
Training loss: 1.4570648670196533
Validation loss: 1.9209947637332383

Epoch: 6| Step: 3
Training loss: 1.1543569564819336
Validation loss: 1.9289633740660965

Epoch: 6| Step: 4
Training loss: 0.8341912627220154
Validation loss: 1.934048616757957

Epoch: 6| Step: 5
Training loss: 1.2338356971740723
Validation loss: 1.954664646938283

Epoch: 6| Step: 6
Training loss: 1.4283442497253418
Validation loss: 1.9854696617331555

Epoch: 6| Step: 7
Training loss: 1.1720952987670898
Validation loss: 1.991664522437639

Epoch: 6| Step: 8
Training loss: 1.7604031562805176
Validation loss: 2.023056464810525

Epoch: 6| Step: 9
Training loss: 1.3572478294372559
Validation loss: 2.0053794999276437

Epoch: 6| Step: 10
Training loss: 1.0918629169464111
Validation loss: 1.9735811577048352

Epoch: 6| Step: 11
Training loss: 1.4395549297332764
Validation loss: 1.9878041321231472

Epoch: 6| Step: 12
Training loss: 1.2239353656768799
Validation loss: 1.9734859158915858

Epoch: 6| Step: 13
Training loss: 0.5848559737205505
Validation loss: 1.9500474865718553

Epoch: 180| Step: 0
Training loss: 1.3344316482543945
Validation loss: 1.9499477071146811

Epoch: 6| Step: 1
Training loss: 1.02471923828125
Validation loss: 1.973907341239273

Epoch: 6| Step: 2
Training loss: 0.9697821736335754
Validation loss: 1.9746976321743381

Epoch: 6| Step: 3
Training loss: 1.0374410152435303
Validation loss: 1.9454761217999201

Epoch: 6| Step: 4
Training loss: 1.0990735292434692
Validation loss: 1.9334475789018857

Epoch: 6| Step: 5
Training loss: 1.1011860370635986
Validation loss: 1.9501859475207586

Epoch: 6| Step: 6
Training loss: 0.5997710824012756
Validation loss: 1.9670159361695732

Epoch: 6| Step: 7
Training loss: 1.0649454593658447
Validation loss: 1.9588260727543985

Epoch: 6| Step: 8
Training loss: 1.7325347661972046
Validation loss: 1.9427202260622414

Epoch: 6| Step: 9
Training loss: 1.4434727430343628
Validation loss: 1.910988361604752

Epoch: 6| Step: 10
Training loss: 1.1273704767227173
Validation loss: 1.9288987562220583

Epoch: 6| Step: 11
Training loss: 1.124136209487915
Validation loss: 1.9190485374901884

Epoch: 6| Step: 12
Training loss: 2.0527427196502686
Validation loss: 1.9235180911197458

Epoch: 6| Step: 13
Training loss: 0.9490273594856262
Validation loss: 1.9278508873396023

Epoch: 181| Step: 0
Training loss: 1.2370518445968628
Validation loss: 1.911160199872909

Epoch: 6| Step: 1
Training loss: 0.8558105230331421
Validation loss: 1.968861432485683

Epoch: 6| Step: 2
Training loss: 1.4889737367630005
Validation loss: 1.9788605295201784

Epoch: 6| Step: 3
Training loss: 1.6923717260360718
Validation loss: 2.0096786970733316

Epoch: 6| Step: 4
Training loss: 0.7740586400032043
Validation loss: 1.995368085881715

Epoch: 6| Step: 5
Training loss: 0.8640508651733398
Validation loss: 1.9837413577623264

Epoch: 6| Step: 6
Training loss: 0.9469717741012573
Validation loss: 1.9972727016736103

Epoch: 6| Step: 7
Training loss: 1.3533942699432373
Validation loss: 1.9861459885874102

Epoch: 6| Step: 8
Training loss: 0.6525427103042603
Validation loss: 2.0142005464082122

Epoch: 6| Step: 9
Training loss: 1.2226473093032837
Validation loss: 2.0256108186578237

Epoch: 6| Step: 10
Training loss: 1.4553327560424805
Validation loss: 2.059306070368777

Epoch: 6| Step: 11
Training loss: 1.2099719047546387
Validation loss: 2.020461202949606

Epoch: 6| Step: 12
Training loss: 1.4556639194488525
Validation loss: 1.9766161877621886

Epoch: 6| Step: 13
Training loss: 1.2776566743850708
Validation loss: 1.9345316809992636

Epoch: 182| Step: 0
Training loss: 0.8613721132278442
Validation loss: 1.9556575821292015

Epoch: 6| Step: 1
Training loss: 1.3503435850143433
Validation loss: 1.9330560853404384

Epoch: 6| Step: 2
Training loss: 1.169638991355896
Validation loss: 1.9365222133615965

Epoch: 6| Step: 3
Training loss: 1.3732802867889404
Validation loss: 1.943033117119984

Epoch: 6| Step: 4
Training loss: 1.3367998600006104
Validation loss: 1.9326239708931214

Epoch: 6| Step: 5
Training loss: 0.9096702337265015
Validation loss: 1.9572205415336035

Epoch: 6| Step: 6
Training loss: 1.2014594078063965
Validation loss: 1.973913167112617

Epoch: 6| Step: 7
Training loss: 1.2379958629608154
Validation loss: 2.0072985567072386

Epoch: 6| Step: 8
Training loss: 1.416416049003601
Validation loss: 2.0141295027989212

Epoch: 6| Step: 9
Training loss: 0.9694873690605164
Validation loss: 2.0204724009319017

Epoch: 6| Step: 10
Training loss: 1.783177137374878
Validation loss: 1.9703571937417472

Epoch: 6| Step: 11
Training loss: 0.8993225693702698
Validation loss: 1.9533415289335354

Epoch: 6| Step: 12
Training loss: 1.0226346254348755
Validation loss: 1.9591298052059707

Epoch: 6| Step: 13
Training loss: 1.326627254486084
Validation loss: 1.975813490088268

Epoch: 183| Step: 0
Training loss: 0.8051068782806396
Validation loss: 1.9864594808188818

Epoch: 6| Step: 1
Training loss: 1.0807064771652222
Validation loss: 1.9960686929764286

Epoch: 6| Step: 2
Training loss: 1.2712483406066895
Validation loss: 1.9707850576728903

Epoch: 6| Step: 3
Training loss: 0.4506213963031769
Validation loss: 1.9867953702967653

Epoch: 6| Step: 4
Training loss: 1.1744431257247925
Validation loss: 1.9802354458839662

Epoch: 6| Step: 5
Training loss: 0.9476948380470276
Validation loss: 2.0199594548953477

Epoch: 6| Step: 6
Training loss: 0.9987806081771851
Validation loss: 2.0615140699571177

Epoch: 6| Step: 7
Training loss: 0.920951247215271
Validation loss: 2.0665070292770222

Epoch: 6| Step: 8
Training loss: 1.7408459186553955
Validation loss: 2.044566518516951

Epoch: 6| Step: 9
Training loss: 0.8964239358901978
Validation loss: 1.9999510267729401

Epoch: 6| Step: 10
Training loss: 1.207200527191162
Validation loss: 1.9912354061680455

Epoch: 6| Step: 11
Training loss: 1.7358760833740234
Validation loss: 1.9510454900803105

Epoch: 6| Step: 12
Training loss: 1.308738112449646
Validation loss: 1.9349625097808016

Epoch: 6| Step: 13
Training loss: 1.1413967609405518
Validation loss: 1.9349520911452591

Epoch: 184| Step: 0
Training loss: 0.9354413151741028
Validation loss: 1.9219179396988244

Epoch: 6| Step: 1
Training loss: 1.059903621673584
Validation loss: 1.9223802628055695

Epoch: 6| Step: 2
Training loss: 1.4982976913452148
Validation loss: 1.951561027957547

Epoch: 6| Step: 3
Training loss: 1.2100436687469482
Validation loss: 1.9607367489927559

Epoch: 6| Step: 4
Training loss: 1.2580764293670654
Validation loss: 1.9763674069476385

Epoch: 6| Step: 5
Training loss: 0.9057407379150391
Validation loss: 1.9829140837474535

Epoch: 6| Step: 6
Training loss: 1.3093929290771484
Validation loss: 1.998220759053384

Epoch: 6| Step: 7
Training loss: 0.9838050603866577
Validation loss: 1.9823845509559876

Epoch: 6| Step: 8
Training loss: 0.9104503393173218
Validation loss: 1.9676595054646975

Epoch: 6| Step: 9
Training loss: 1.4662296772003174
Validation loss: 1.988855541393321

Epoch: 6| Step: 10
Training loss: 0.96601402759552
Validation loss: 1.9561686220989432

Epoch: 6| Step: 11
Training loss: 0.7029788494110107
Validation loss: 1.980987798783087

Epoch: 6| Step: 12
Training loss: 1.272096872329712
Validation loss: 2.0084668743994927

Epoch: 6| Step: 13
Training loss: 1.0182325839996338
Validation loss: 2.064695090375921

Epoch: 185| Step: 0
Training loss: 1.2439128160476685
Validation loss: 2.075908722416047

Epoch: 6| Step: 1
Training loss: 1.2966783046722412
Validation loss: 2.037609533597064

Epoch: 6| Step: 2
Training loss: 0.7853362560272217
Validation loss: 2.0234657359379593

Epoch: 6| Step: 3
Training loss: 0.6653227806091309
Validation loss: 1.9775304127764959

Epoch: 6| Step: 4
Training loss: 1.6539921760559082
Validation loss: 1.9431997088975803

Epoch: 6| Step: 5
Training loss: 0.9475851058959961
Validation loss: 1.917898711337838

Epoch: 6| Step: 6
Training loss: 0.9330040812492371
Validation loss: 1.9154428160318764

Epoch: 6| Step: 7
Training loss: 1.4777889251708984
Validation loss: 1.928167184193929

Epoch: 6| Step: 8
Training loss: 1.4430153369903564
Validation loss: 1.9316955112641858

Epoch: 6| Step: 9
Training loss: 0.7138440012931824
Validation loss: 1.9306301916799238

Epoch: 6| Step: 10
Training loss: 1.3427557945251465
Validation loss: 1.9316711733418126

Epoch: 6| Step: 11
Training loss: 1.1434277296066284
Validation loss: 1.9539513818679317

Epoch: 6| Step: 12
Training loss: 1.3414933681488037
Validation loss: 1.9948711613173127

Epoch: 6| Step: 13
Training loss: 0.5185577869415283
Validation loss: 2.038866235363868

Epoch: 186| Step: 0
Training loss: 1.363919973373413
Validation loss: 2.083675676776517

Epoch: 6| Step: 1
Training loss: 1.0170670747756958
Validation loss: 2.1173404442366732

Epoch: 6| Step: 2
Training loss: 1.5777313709259033
Validation loss: 2.085035838106627

Epoch: 6| Step: 3
Training loss: 1.5123976469039917
Validation loss: 2.0491687123493483

Epoch: 6| Step: 4
Training loss: 1.425419807434082
Validation loss: 2.0192294684789514

Epoch: 6| Step: 5
Training loss: 1.3158490657806396
Validation loss: 1.9859976781311857

Epoch: 6| Step: 6
Training loss: 1.2908215522766113
Validation loss: 1.9677787673088811

Epoch: 6| Step: 7
Training loss: 0.7673518061637878
Validation loss: 1.9557331428732923

Epoch: 6| Step: 8
Training loss: 0.6931271553039551
Validation loss: 1.9290130625488937

Epoch: 6| Step: 9
Training loss: 0.9687808752059937
Validation loss: 1.9298128915089432

Epoch: 6| Step: 10
Training loss: 0.7684592604637146
Validation loss: 1.927399568660285

Epoch: 6| Step: 11
Training loss: 0.9606859087944031
Validation loss: 1.9553454460636261

Epoch: 6| Step: 12
Training loss: 1.4057174921035767
Validation loss: 1.9687851859677223

Epoch: 6| Step: 13
Training loss: 0.9927524924278259
Validation loss: 1.970167790689776

Epoch: 187| Step: 0
Training loss: 1.0755579471588135
Validation loss: 1.9539429039083502

Epoch: 6| Step: 1
Training loss: 1.8952109813690186
Validation loss: 1.972169033942684

Epoch: 6| Step: 2
Training loss: 1.1339044570922852
Validation loss: 1.918479980960969

Epoch: 6| Step: 3
Training loss: 1.0629947185516357
Validation loss: 1.9282065822232155

Epoch: 6| Step: 4
Training loss: 0.9542719125747681
Validation loss: 1.9421857992808025

Epoch: 6| Step: 5
Training loss: 0.7894327640533447
Validation loss: 1.944851557413737

Epoch: 6| Step: 6
Training loss: 1.5013773441314697
Validation loss: 1.9624246628053728

Epoch: 6| Step: 7
Training loss: 0.6695382595062256
Validation loss: 1.9839798032596547

Epoch: 6| Step: 8
Training loss: 1.4752329587936401
Validation loss: 2.0008073634998773

Epoch: 6| Step: 9
Training loss: 1.489118218421936
Validation loss: 2.007541793648915

Epoch: 6| Step: 10
Training loss: 0.6528943777084351
Validation loss: 1.9859521363371162

Epoch: 6| Step: 11
Training loss: 0.791551411151886
Validation loss: 1.9658428968921784

Epoch: 6| Step: 12
Training loss: 0.6155028343200684
Validation loss: 1.94945595213162

Epoch: 6| Step: 13
Training loss: 0.49265092611312866
Validation loss: 1.9370342018783733

Epoch: 188| Step: 0
Training loss: 1.4570047855377197
Validation loss: 1.9364237144429197

Epoch: 6| Step: 1
Training loss: 1.70619535446167
Validation loss: 1.9241514334114649

Epoch: 6| Step: 2
Training loss: 1.0086398124694824
Validation loss: 1.9533447129752046

Epoch: 6| Step: 3
Training loss: 1.0042661428451538
Validation loss: 1.940145415644492

Epoch: 6| Step: 4
Training loss: 1.0247917175292969
Validation loss: 1.9334506424524451

Epoch: 6| Step: 5
Training loss: 1.308321475982666
Validation loss: 1.952874247745801

Epoch: 6| Step: 6
Training loss: 0.969393789768219
Validation loss: 1.9745606581370037

Epoch: 6| Step: 7
Training loss: 0.912712574005127
Validation loss: 1.9660562443476852

Epoch: 6| Step: 8
Training loss: 0.5243794918060303
Validation loss: 1.9308534770883539

Epoch: 6| Step: 9
Training loss: 0.8824043869972229
Validation loss: 1.9277332187980734

Epoch: 6| Step: 10
Training loss: 0.6023646593093872
Validation loss: 1.9018527230908793

Epoch: 6| Step: 11
Training loss: 1.2471617460250854
Validation loss: 1.895364276824459

Epoch: 6| Step: 12
Training loss: 0.9974205493927002
Validation loss: 1.8904781713280627

Epoch: 6| Step: 13
Training loss: 1.5051413774490356
Validation loss: 1.9013870531512844

Epoch: 189| Step: 0
Training loss: 1.1549694538116455
Validation loss: 1.9224257892177952

Epoch: 6| Step: 1
Training loss: 1.2997846603393555
Validation loss: 1.9330719401759486

Epoch: 6| Step: 2
Training loss: 1.2337228059768677
Validation loss: 1.9221819357205463

Epoch: 6| Step: 3
Training loss: 1.0977754592895508
Validation loss: 1.923109850575847

Epoch: 6| Step: 4
Training loss: 0.6978188157081604
Validation loss: 1.9421990468937864

Epoch: 6| Step: 5
Training loss: 0.5827460289001465
Validation loss: 1.936502513065133

Epoch: 6| Step: 6
Training loss: 1.0314412117004395
Validation loss: 1.9469510637303835

Epoch: 6| Step: 7
Training loss: 1.4012997150421143
Validation loss: 1.9304368995851087

Epoch: 6| Step: 8
Training loss: 0.935072124004364
Validation loss: 1.9346061957779752

Epoch: 6| Step: 9
Training loss: 1.2590336799621582
Validation loss: 1.9272640648708548

Epoch: 6| Step: 10
Training loss: 1.0580488443374634
Validation loss: 1.9214069945837862

Epoch: 6| Step: 11
Training loss: 1.1153626441955566
Validation loss: 1.9208381163176669

Epoch: 6| Step: 12
Training loss: 0.7852696180343628
Validation loss: 1.9345810233905751

Epoch: 6| Step: 13
Training loss: 0.6808357238769531
Validation loss: 1.9302245878404187

Epoch: 190| Step: 0
Training loss: 1.8272920846939087
Validation loss: 1.9147189227483605

Epoch: 6| Step: 1
Training loss: 0.9323227405548096
Validation loss: 1.9126078031396354

Epoch: 6| Step: 2
Training loss: 0.7636603713035583
Validation loss: 1.9290019517303796

Epoch: 6| Step: 3
Training loss: 0.8320978879928589
Validation loss: 1.9364950990164151

Epoch: 6| Step: 4
Training loss: 0.6967260241508484
Validation loss: 1.9376144870635001

Epoch: 6| Step: 5
Training loss: 0.8763293623924255
Validation loss: 1.9596994884552494

Epoch: 6| Step: 6
Training loss: 1.31383216381073
Validation loss: 1.962638472998014

Epoch: 6| Step: 7
Training loss: 1.0051296949386597
Validation loss: 2.0012791515678487

Epoch: 6| Step: 8
Training loss: 0.8122908473014832
Validation loss: 2.000419262916811

Epoch: 6| Step: 9
Training loss: 1.2194702625274658
Validation loss: 1.9667924629744662

Epoch: 6| Step: 10
Training loss: 0.6310198307037354
Validation loss: 1.9364142417907715

Epoch: 6| Step: 11
Training loss: 1.506469488143921
Validation loss: 1.9214834397838962

Epoch: 6| Step: 12
Training loss: 0.9851574897766113
Validation loss: 1.9104524812390726

Epoch: 6| Step: 13
Training loss: 1.1238068342208862
Validation loss: 1.905349700681625

Epoch: 191| Step: 0
Training loss: 1.3151503801345825
Validation loss: 1.887444414118285

Epoch: 6| Step: 1
Training loss: 1.2608160972595215
Validation loss: 1.9119630821289555

Epoch: 6| Step: 2
Training loss: 0.5586725473403931
Validation loss: 1.938402928331847

Epoch: 6| Step: 3
Training loss: 1.038898229598999
Validation loss: 1.9482109828661847

Epoch: 6| Step: 4
Training loss: 0.7658942937850952
Validation loss: 1.9708835373642624

Epoch: 6| Step: 5
Training loss: 1.0247855186462402
Validation loss: 1.9846931029391546

Epoch: 6| Step: 6
Training loss: 1.6264326572418213
Validation loss: 1.9984838962554932

Epoch: 6| Step: 7
Training loss: 0.8655538558959961
Validation loss: 1.987386885509696

Epoch: 6| Step: 8
Training loss: 1.5441817045211792
Validation loss: 1.9716023757893553

Epoch: 6| Step: 9
Training loss: 0.7623424530029297
Validation loss: 1.9496154413428357

Epoch: 6| Step: 10
Training loss: 0.6081423759460449
Validation loss: 1.9176876301406531

Epoch: 6| Step: 11
Training loss: 1.0787243843078613
Validation loss: 1.884676355187611

Epoch: 6| Step: 12
Training loss: 1.1000983715057373
Validation loss: 1.9074121752092916

Epoch: 6| Step: 13
Training loss: 0.8747054934501648
Validation loss: 1.9111614919477893

Epoch: 192| Step: 0
Training loss: 1.0581889152526855
Validation loss: 1.903011336121508

Epoch: 6| Step: 1
Training loss: 1.2156224250793457
Validation loss: 1.8846231416989399

Epoch: 6| Step: 2
Training loss: 1.095282793045044
Validation loss: 1.8908464959872666

Epoch: 6| Step: 3
Training loss: 1.5177180767059326
Validation loss: 1.9359811698236773

Epoch: 6| Step: 4
Training loss: 1.0152167081832886
Validation loss: 1.960147185992169

Epoch: 6| Step: 5
Training loss: 1.064067006111145
Validation loss: 1.9942024420666438

Epoch: 6| Step: 6
Training loss: 0.6952435374259949
Validation loss: 1.9458869400844778

Epoch: 6| Step: 7
Training loss: 1.0530800819396973
Validation loss: 1.908667302900745

Epoch: 6| Step: 8
Training loss: 0.6545587182044983
Validation loss: 1.8906984047223163

Epoch: 6| Step: 9
Training loss: 0.9942604899406433
Validation loss: 1.8901414396942302

Epoch: 6| Step: 10
Training loss: 1.0771875381469727
Validation loss: 1.8951984400390296

Epoch: 6| Step: 11
Training loss: 0.6651512384414673
Validation loss: 1.8866163402475336

Epoch: 6| Step: 12
Training loss: 0.9745833277702332
Validation loss: 1.872858585849885

Epoch: 6| Step: 13
Training loss: 1.0154160261154175
Validation loss: 1.9094470265091106

Epoch: 193| Step: 0
Training loss: 1.3823282718658447
Validation loss: 1.9104620256731588

Epoch: 6| Step: 1
Training loss: 0.7498469352722168
Validation loss: 1.9358331567497664

Epoch: 6| Step: 2
Training loss: 0.9857323169708252
Validation loss: 1.9719716784774617

Epoch: 6| Step: 3
Training loss: 1.1382111310958862
Validation loss: 1.9619565099798224

Epoch: 6| Step: 4
Training loss: 0.9041345715522766
Validation loss: 1.9612071001401512

Epoch: 6| Step: 5
Training loss: 0.44498389959335327
Validation loss: 1.9412383341020154

Epoch: 6| Step: 6
Training loss: 1.1873891353607178
Validation loss: 1.9222114457879016

Epoch: 6| Step: 7
Training loss: 1.0681612491607666
Validation loss: 1.939633495064192

Epoch: 6| Step: 8
Training loss: 0.6510045528411865
Validation loss: 1.9397523941532258

Epoch: 6| Step: 9
Training loss: 0.9279897212982178
Validation loss: 1.9222585078208678

Epoch: 6| Step: 10
Training loss: 0.8365198373794556
Validation loss: 1.9250580559494674

Epoch: 6| Step: 11
Training loss: 1.1908316612243652
Validation loss: 1.9161953259539861

Epoch: 6| Step: 12
Training loss: 1.2314953804016113
Validation loss: 1.8983157655244232

Epoch: 6| Step: 13
Training loss: 0.757148802280426
Validation loss: 1.905767015231553

Epoch: 194| Step: 0
Training loss: 0.9721990823745728
Validation loss: 1.9077989875629384

Epoch: 6| Step: 1
Training loss: 1.1136430501937866
Validation loss: 1.8972266899642123

Epoch: 6| Step: 2
Training loss: 1.1396348476409912
Validation loss: 1.892261907618533

Epoch: 6| Step: 3
Training loss: 1.22813081741333
Validation loss: 1.8794266754581082

Epoch: 6| Step: 4
Training loss: 1.2473490238189697
Validation loss: 1.8972349756507463

Epoch: 6| Step: 5
Training loss: 0.7445838451385498
Validation loss: 1.901722570901276

Epoch: 6| Step: 6
Training loss: 0.9304300546646118
Validation loss: 1.916045847759452

Epoch: 6| Step: 7
Training loss: 0.9863229393959045
Validation loss: 1.9647167959520895

Epoch: 6| Step: 8
Training loss: 0.6321552395820618
Validation loss: 1.9651931460185716

Epoch: 6| Step: 9
Training loss: 1.2332507371902466
Validation loss: 1.937499648781233

Epoch: 6| Step: 10
Training loss: 1.1218836307525635
Validation loss: 1.9079263799933976

Epoch: 6| Step: 11
Training loss: 0.8374975919723511
Validation loss: 1.9030050846838182

Epoch: 6| Step: 12
Training loss: 0.9321188926696777
Validation loss: 1.8792622512386692

Epoch: 6| Step: 13
Training loss: 0.37480711936950684
Validation loss: 1.863986107610887

Epoch: 195| Step: 0
Training loss: 0.9853327870368958
Validation loss: 1.8613914905055877

Epoch: 6| Step: 1
Training loss: 1.3971552848815918
Validation loss: 1.8702270651376376

Epoch: 6| Step: 2
Training loss: 1.168940544128418
Validation loss: 1.8499843676884968

Epoch: 6| Step: 3
Training loss: 1.2946316003799438
Validation loss: 1.9048771050668531

Epoch: 6| Step: 4
Training loss: 0.5945155620574951
Validation loss: 1.8926078055494575

Epoch: 6| Step: 5
Training loss: 0.9545110464096069
Validation loss: 1.9273505133967246

Epoch: 6| Step: 6
Training loss: 1.0049376487731934
Validation loss: 1.9210240930639289

Epoch: 6| Step: 7
Training loss: 0.7634716629981995
Validation loss: 1.916330688743181

Epoch: 6| Step: 8
Training loss: 0.7361328601837158
Validation loss: 1.879957245242211

Epoch: 6| Step: 9
Training loss: 0.9189510345458984
Validation loss: 1.8767748212301603

Epoch: 6| Step: 10
Training loss: 1.40939462184906
Validation loss: 1.8588966400392595

Epoch: 6| Step: 11
Training loss: 0.7384068369865417
Validation loss: 1.873744959472328

Epoch: 6| Step: 12
Training loss: 0.6007487177848816
Validation loss: 1.8738243067136375

Epoch: 6| Step: 13
Training loss: 0.9059863686561584
Validation loss: 1.88663621358974

Epoch: 196| Step: 0
Training loss: 0.6411957740783691
Validation loss: 1.9090883962569698

Epoch: 6| Step: 1
Training loss: 0.5908305644989014
Validation loss: 1.958358851812219

Epoch: 6| Step: 2
Training loss: 1.3874297142028809
Validation loss: 1.9581410859220771

Epoch: 6| Step: 3
Training loss: 0.8199636340141296
Validation loss: 1.98900152919113

Epoch: 6| Step: 4
Training loss: 0.7562751770019531
Validation loss: 1.9521621555410407

Epoch: 6| Step: 5
Training loss: 0.897118091583252
Validation loss: 1.9107879041343607

Epoch: 6| Step: 6
Training loss: 1.4206488132476807
Validation loss: 1.8665645276346514

Epoch: 6| Step: 7
Training loss: 0.9429415464401245
Validation loss: 1.851556078080208

Epoch: 6| Step: 8
Training loss: 0.9661667346954346
Validation loss: 1.8268690468162618

Epoch: 6| Step: 9
Training loss: 1.134899616241455
Validation loss: 1.8301312718340146

Epoch: 6| Step: 10
Training loss: 0.9713037014007568
Validation loss: 1.85444793393535

Epoch: 6| Step: 11
Training loss: 1.1527087688446045
Validation loss: 1.8080770104162154

Epoch: 6| Step: 12
Training loss: 0.9322508573532104
Validation loss: 1.8355486642929815

Epoch: 6| Step: 13
Training loss: 0.7207255959510803
Validation loss: 1.8333360123377975

Epoch: 197| Step: 0
Training loss: 0.8638261556625366
Validation loss: 1.8477965272882932

Epoch: 6| Step: 1
Training loss: 0.6861873865127563
Validation loss: 1.8799162167374805

Epoch: 6| Step: 2
Training loss: 1.1822773218154907
Validation loss: 1.9194563755425074

Epoch: 6| Step: 3
Training loss: 0.7159303426742554
Validation loss: 1.9739671420025569

Epoch: 6| Step: 4
Training loss: 1.2667088508605957
Validation loss: 1.9971480318295058

Epoch: 6| Step: 5
Training loss: 0.890688955783844
Validation loss: 2.012320928676154

Epoch: 6| Step: 6
Training loss: 0.8185027837753296
Validation loss: 1.9953589567574121

Epoch: 6| Step: 7
Training loss: 0.9449484348297119
Validation loss: 1.953155194559405

Epoch: 6| Step: 8
Training loss: 0.6968374252319336
Validation loss: 1.8920200665791829

Epoch: 6| Step: 9
Training loss: 0.9782246351242065
Validation loss: 1.8664391361257082

Epoch: 6| Step: 10
Training loss: 1.1950058937072754
Validation loss: 1.8442745772741174

Epoch: 6| Step: 11
Training loss: 0.7433704733848572
Validation loss: 1.865853673668318

Epoch: 6| Step: 12
Training loss: 1.2782211303710938
Validation loss: 1.8632188125323224

Epoch: 6| Step: 13
Training loss: 0.8351617455482483
Validation loss: 1.8483899075497863

Epoch: 198| Step: 0
Training loss: 1.3621934652328491
Validation loss: 1.8476911590945335

Epoch: 6| Step: 1
Training loss: 0.9306546449661255
Validation loss: 1.8586977861260856

Epoch: 6| Step: 2
Training loss: 0.9250887632369995
Validation loss: 1.8631676602107223

Epoch: 6| Step: 3
Training loss: 0.6254596710205078
Validation loss: 1.8748597739845194

Epoch: 6| Step: 4
Training loss: 1.0670984983444214
Validation loss: 1.9299319931255874

Epoch: 6| Step: 5
Training loss: 0.7458983063697815
Validation loss: 1.9462487184873192

Epoch: 6| Step: 6
Training loss: 1.1225765943527222
Validation loss: 1.9398863161763837

Epoch: 6| Step: 7
Training loss: 1.2432225942611694
Validation loss: 1.9032511711120605

Epoch: 6| Step: 8
Training loss: 0.8586955070495605
Validation loss: 1.912880184829876

Epoch: 6| Step: 9
Training loss: 1.0487643480300903
Validation loss: 1.8804103443699498

Epoch: 6| Step: 10
Training loss: 0.6136536002159119
Validation loss: 1.868455748404226

Epoch: 6| Step: 11
Training loss: 0.7807149887084961
Validation loss: 1.8873300603640977

Epoch: 6| Step: 12
Training loss: 0.8311408758163452
Validation loss: 1.8932530264700613

Epoch: 6| Step: 13
Training loss: 0.9920613169670105
Validation loss: 1.8819938923722954

Epoch: 199| Step: 0
Training loss: 0.7758013010025024
Validation loss: 1.8962777481284192

Epoch: 6| Step: 1
Training loss: 1.1784090995788574
Validation loss: 1.871902552984094

Epoch: 6| Step: 2
Training loss: 0.9003750085830688
Validation loss: 1.8760949950064383

Epoch: 6| Step: 3
Training loss: 0.7987291812896729
Validation loss: 1.8787825851030246

Epoch: 6| Step: 4
Training loss: 0.8683767318725586
Validation loss: 1.8930566131427724

Epoch: 6| Step: 5
Training loss: 0.5142735242843628
Validation loss: 1.8859787166759532

Epoch: 6| Step: 6
Training loss: 0.6946169137954712
Validation loss: 1.8626931662200599

Epoch: 6| Step: 7
Training loss: 0.9655595421791077
Validation loss: 1.8632441182290354

Epoch: 6| Step: 8
Training loss: 0.9396079778671265
Validation loss: 1.8684741681621921

Epoch: 6| Step: 9
Training loss: 0.7880171537399292
Validation loss: 1.872231009185955

Epoch: 6| Step: 10
Training loss: 1.012995719909668
Validation loss: 1.8568485488173783

Epoch: 6| Step: 11
Training loss: 1.309687852859497
Validation loss: 1.883747375139626

Epoch: 6| Step: 12
Training loss: 0.9879781007766724
Validation loss: 1.8599254456899499

Epoch: 6| Step: 13
Training loss: 0.694087028503418
Validation loss: 1.89625992057144

Epoch: 200| Step: 0
Training loss: 0.7502261400222778
Validation loss: 1.9007355731020692

Epoch: 6| Step: 1
Training loss: 0.7645785212516785
Validation loss: 1.9535383921797558

Epoch: 6| Step: 2
Training loss: 0.8155089616775513
Validation loss: 1.955971940871208

Epoch: 6| Step: 3
Training loss: 0.7601822018623352
Validation loss: 1.9154103340641144

Epoch: 6| Step: 4
Training loss: 0.969387948513031
Validation loss: 1.874773225476665

Epoch: 6| Step: 5
Training loss: 1.1643049716949463
Validation loss: 1.8778803938178605

Epoch: 6| Step: 6
Training loss: 1.0283055305480957
Validation loss: 1.8739815168483283

Epoch: 6| Step: 7
Training loss: 1.1397897005081177
Validation loss: 1.8677747108603036

Epoch: 6| Step: 8
Training loss: 1.0755231380462646
Validation loss: 1.8512393428433327

Epoch: 6| Step: 9
Training loss: 0.7120426893234253
Validation loss: 1.8630150774473786

Epoch: 6| Step: 10
Training loss: 0.6049798727035522
Validation loss: 1.866807380030232

Epoch: 6| Step: 11
Training loss: 0.6754143834114075
Validation loss: 1.8885274830684866

Epoch: 6| Step: 12
Training loss: 1.0005519390106201
Validation loss: 1.9288176246868667

Epoch: 6| Step: 13
Training loss: 1.5649142265319824
Validation loss: 1.9889999435793968

Epoch: 201| Step: 0
Training loss: 0.9257860779762268
Validation loss: 1.9543589648380075

Epoch: 6| Step: 1
Training loss: 0.8307223320007324
Validation loss: 1.8930369833464264

Epoch: 6| Step: 2
Training loss: 1.0974818468093872
Validation loss: 1.8681385465847549

Epoch: 6| Step: 3
Training loss: 1.2177422046661377
Validation loss: 1.8835745126970354

Epoch: 6| Step: 4
Training loss: 0.7306113243103027
Validation loss: 1.8678322287016018

Epoch: 6| Step: 5
Training loss: 0.5529375076293945
Validation loss: 1.853000125577373

Epoch: 6| Step: 6
Training loss: 1.01882004737854
Validation loss: 1.8629682294784053

Epoch: 6| Step: 7
Training loss: 0.9198744297027588
Validation loss: 1.8688926389140468

Epoch: 6| Step: 8
Training loss: 0.4111485183238983
Validation loss: 1.8830362353273618

Epoch: 6| Step: 9
Training loss: 0.9376108646392822
Validation loss: 1.8775228608039118

Epoch: 6| Step: 10
Training loss: 1.0199552774429321
Validation loss: 1.8836064671957364

Epoch: 6| Step: 11
Training loss: 0.8626275062561035
Validation loss: 1.8622604826445222

Epoch: 6| Step: 12
Training loss: 0.7459333539009094
Validation loss: 1.848346451277374

Epoch: 6| Step: 13
Training loss: 1.2132983207702637
Validation loss: 1.8605799469896542

Epoch: 202| Step: 0
Training loss: 1.0571825504302979
Validation loss: 1.8520207187180877

Epoch: 6| Step: 1
Training loss: 0.9076992869377136
Validation loss: 1.8711913042171027

Epoch: 6| Step: 2
Training loss: 1.1180830001831055
Validation loss: 1.8919007944804367

Epoch: 6| Step: 3
Training loss: 0.3889906704425812
Validation loss: 1.8726255637343212

Epoch: 6| Step: 4
Training loss: 0.9298096299171448
Validation loss: 1.8735240595315092

Epoch: 6| Step: 5
Training loss: 0.7722114324569702
Validation loss: 1.8703529962929346

Epoch: 6| Step: 6
Training loss: 0.831936240196228
Validation loss: 1.8674512396576584

Epoch: 6| Step: 7
Training loss: 1.015380620956421
Validation loss: 1.8819955830932946

Epoch: 6| Step: 8
Training loss: 0.9119161367416382
Validation loss: 1.8800184752351494

Epoch: 6| Step: 9
Training loss: 0.8819484710693359
Validation loss: 1.8863834475958219

Epoch: 6| Step: 10
Training loss: 1.12595534324646
Validation loss: 1.874133212592012

Epoch: 6| Step: 11
Training loss: 0.6542152166366577
Validation loss: 1.8819782759553643

Epoch: 6| Step: 12
Training loss: 0.5152695178985596
Validation loss: 1.8627477909929009

Epoch: 6| Step: 13
Training loss: 0.7805951237678528
Validation loss: 1.9162951092566214

Epoch: 203| Step: 0
Training loss: 0.5665727853775024
Validation loss: 1.8837163909789054

Epoch: 6| Step: 1
Training loss: 0.6271851658821106
Validation loss: 1.8696670391226327

Epoch: 6| Step: 2
Training loss: 1.2189452648162842
Validation loss: 1.8845872853391914

Epoch: 6| Step: 3
Training loss: 1.2024316787719727
Validation loss: 1.8487110317394297

Epoch: 6| Step: 4
Training loss: 1.0611116886138916
Validation loss: 1.897922408196234

Epoch: 6| Step: 5
Training loss: 0.8248187899589539
Validation loss: 1.90803998772816

Epoch: 6| Step: 6
Training loss: 0.85411536693573
Validation loss: 1.859638637112033

Epoch: 6| Step: 7
Training loss: 0.8650964498519897
Validation loss: 1.8455496193260275

Epoch: 6| Step: 8
Training loss: 0.9918453097343445
Validation loss: 1.8085237151832991

Epoch: 6| Step: 9
Training loss: 0.8105757236480713
Validation loss: 1.842148498822284

Epoch: 6| Step: 10
Training loss: 0.9542481899261475
Validation loss: 1.84868194723642

Epoch: 6| Step: 11
Training loss: 0.7363994121551514
Validation loss: 1.8273392261997345

Epoch: 6| Step: 12
Training loss: 0.8723437786102295
Validation loss: 1.834486198681657

Epoch: 6| Step: 13
Training loss: 0.9374205470085144
Validation loss: 1.8579811665319628

Epoch: 204| Step: 0
Training loss: 0.7590070962905884
Validation loss: 1.9506574394882366

Epoch: 6| Step: 1
Training loss: 1.05096435546875
Validation loss: 2.021790994110928

Epoch: 6| Step: 2
Training loss: 1.2677335739135742
Validation loss: 2.025340630162147

Epoch: 6| Step: 3
Training loss: 0.9355908632278442
Validation loss: 2.063014402184435

Epoch: 6| Step: 4
Training loss: 0.956465482711792
Validation loss: 1.9593681263667282

Epoch: 6| Step: 5
Training loss: 0.9733882546424866
Validation loss: 1.879592434052498

Epoch: 6| Step: 6
Training loss: 0.5067216157913208
Validation loss: 1.8580785553942445

Epoch: 6| Step: 7
Training loss: 1.0679689645767212
Validation loss: 1.895743570020122

Epoch: 6| Step: 8
Training loss: 0.9088007211685181
Validation loss: 1.9044640730786067

Epoch: 6| Step: 9
Training loss: 0.6685976386070251
Validation loss: 1.9065062563906434

Epoch: 6| Step: 10
Training loss: 1.1244292259216309
Validation loss: 1.8730898595625354

Epoch: 6| Step: 11
Training loss: 0.9479227066040039
Validation loss: 1.8569788304708337

Epoch: 6| Step: 12
Training loss: 1.0264520645141602
Validation loss: 1.8053718125948341

Epoch: 6| Step: 13
Training loss: 0.9559523463249207
Validation loss: 1.8245141775377336

Epoch: 205| Step: 0
Training loss: 0.6215431690216064
Validation loss: 1.8554955631174066

Epoch: 6| Step: 1
Training loss: 1.0042622089385986
Validation loss: 1.846344409450408

Epoch: 6| Step: 2
Training loss: 0.9020417928695679
Validation loss: 1.8471935179925734

Epoch: 6| Step: 3
Training loss: 0.7652974128723145
Validation loss: 1.853447655195831

Epoch: 6| Step: 4
Training loss: 0.6961355209350586
Validation loss: 1.843694806098938

Epoch: 6| Step: 5
Training loss: 1.1562871932983398
Validation loss: 1.864782847383971

Epoch: 6| Step: 6
Training loss: 1.0072417259216309
Validation loss: 1.8597068799439298

Epoch: 6| Step: 7
Training loss: 1.0057358741760254
Validation loss: 1.8531976592156194

Epoch: 6| Step: 8
Training loss: 0.6628775596618652
Validation loss: 1.8540247999211794

Epoch: 6| Step: 9
Training loss: 0.8458470106124878
Validation loss: 1.8542599421675487

Epoch: 6| Step: 10
Training loss: 0.7041206955909729
Validation loss: 1.8383593431083105

Epoch: 6| Step: 11
Training loss: 0.4293501377105713
Validation loss: 1.8634424337776758

Epoch: 6| Step: 12
Training loss: 0.8971648216247559
Validation loss: 1.8498679950673094

Epoch: 6| Step: 13
Training loss: 0.7969931960105896
Validation loss: 1.8581976531654276

Epoch: 206| Step: 0
Training loss: 0.8611100912094116
Validation loss: 1.8437167277900122

Epoch: 6| Step: 1
Training loss: 0.9884437918663025
Validation loss: 1.8531834515192176

Epoch: 6| Step: 2
Training loss: 0.6462972164154053
Validation loss: 1.8327742135652931

Epoch: 6| Step: 3
Training loss: 0.49959856271743774
Validation loss: 1.8369119141691475

Epoch: 6| Step: 4
Training loss: 0.7956560254096985
Validation loss: 1.8310782973484327

Epoch: 6| Step: 5
Training loss: 0.7764790058135986
Validation loss: 1.8388609693896385

Epoch: 6| Step: 6
Training loss: 0.917952299118042
Validation loss: 1.829227550055391

Epoch: 6| Step: 7
Training loss: 0.9039217233657837
Validation loss: 1.8528873497439968

Epoch: 6| Step: 8
Training loss: 0.8462926149368286
Validation loss: 1.8764659153517855

Epoch: 6| Step: 9
Training loss: 0.7895866632461548
Validation loss: 1.8793578122251777

Epoch: 6| Step: 10
Training loss: 1.0778546333312988
Validation loss: 1.8547347361041653

Epoch: 6| Step: 11
Training loss: 0.9246247410774231
Validation loss: 1.8408102258559196

Epoch: 6| Step: 12
Training loss: 0.6277697086334229
Validation loss: 1.8364860652595438

Epoch: 6| Step: 13
Training loss: 0.7654524445533752
Validation loss: 1.8411226170037382

Epoch: 207| Step: 0
Training loss: 0.967205286026001
Validation loss: 1.8198543440911077

Epoch: 6| Step: 1
Training loss: 1.0277016162872314
Validation loss: 1.848156165051204

Epoch: 6| Step: 2
Training loss: 0.4912481904029846
Validation loss: 1.8815467421726515

Epoch: 6| Step: 3
Training loss: 0.9924384951591492
Validation loss: 1.8539007325326242

Epoch: 6| Step: 4
Training loss: 1.0283071994781494
Validation loss: 1.8989364498405046

Epoch: 6| Step: 5
Training loss: 0.6696588397026062
Validation loss: 1.9068425342600832

Epoch: 6| Step: 6
Training loss: 0.7192189693450928
Validation loss: 1.9246255608015164

Epoch: 6| Step: 7
Training loss: 0.7191846370697021
Validation loss: 1.9382984689486924

Epoch: 6| Step: 8
Training loss: 0.6647567749023438
Validation loss: 1.9571199494023477

Epoch: 6| Step: 9
Training loss: 1.2224353551864624
Validation loss: 1.9368942437633392

Epoch: 6| Step: 10
Training loss: 0.909517765045166
Validation loss: 1.9089286365816671

Epoch: 6| Step: 11
Training loss: 1.0849969387054443
Validation loss: 1.911791472024815

Epoch: 6| Step: 12
Training loss: 0.7132641077041626
Validation loss: 1.8916384750796902

Epoch: 6| Step: 13
Training loss: 0.8563978672027588
Validation loss: 1.9011914012252644

Epoch: 208| Step: 0
Training loss: 0.4691043496131897
Validation loss: 1.872750623251802

Epoch: 6| Step: 1
Training loss: 0.3374868631362915
Validation loss: 1.886963523844237

Epoch: 6| Step: 2
Training loss: 0.7377820014953613
Validation loss: 1.8738762832457019

Epoch: 6| Step: 3
Training loss: 1.3619991540908813
Validation loss: 1.8698418063502158

Epoch: 6| Step: 4
Training loss: 0.7365108132362366
Validation loss: 1.8555159953332716

Epoch: 6| Step: 5
Training loss: 0.6513014435768127
Validation loss: 1.8402045926740092

Epoch: 6| Step: 6
Training loss: 0.6403405666351318
Validation loss: 1.833261332204265

Epoch: 6| Step: 7
Training loss: 0.8445315361022949
Validation loss: 1.8629665541392502

Epoch: 6| Step: 8
Training loss: 0.8270250558853149
Validation loss: 1.8752002446882186

Epoch: 6| Step: 9
Training loss: 0.945087730884552
Validation loss: 1.8593321051648868

Epoch: 6| Step: 10
Training loss: 0.5613014698028564
Validation loss: 1.835559501442858

Epoch: 6| Step: 11
Training loss: 0.8739891648292542
Validation loss: 1.8371965128888366

Epoch: 6| Step: 12
Training loss: 0.9631808996200562
Validation loss: 1.814765287983802

Epoch: 6| Step: 13
Training loss: 1.5836526155471802
Validation loss: 1.831358414824291

Epoch: 209| Step: 0
Training loss: 0.7668131589889526
Validation loss: 1.8381254288458055

Epoch: 6| Step: 1
Training loss: 0.7114627361297607
Validation loss: 1.813943519387194

Epoch: 6| Step: 2
Training loss: 0.3728100657463074
Validation loss: 1.8244018785415157

Epoch: 6| Step: 3
Training loss: 0.844780683517456
Validation loss: 1.8309999127541818

Epoch: 6| Step: 4
Training loss: 1.2855994701385498
Validation loss: 1.850265263229288

Epoch: 6| Step: 5
Training loss: 0.6408895254135132
Validation loss: 1.888897321557486

Epoch: 6| Step: 6
Training loss: 0.957385778427124
Validation loss: 1.9023995117474628

Epoch: 6| Step: 7
Training loss: 0.7605578899383545
Validation loss: 1.9197828564592587

Epoch: 6| Step: 8
Training loss: 0.798559308052063
Validation loss: 1.8726646438721688

Epoch: 6| Step: 9
Training loss: 0.9095418453216553
Validation loss: 1.8626874621196459

Epoch: 6| Step: 10
Training loss: 0.7799993753433228
Validation loss: 1.850260974258505

Epoch: 6| Step: 11
Training loss: 0.8606826066970825
Validation loss: 1.8585976887774724

Epoch: 6| Step: 12
Training loss: 0.7798008322715759
Validation loss: 1.840386257376722

Epoch: 6| Step: 13
Training loss: 1.1461349725723267
Validation loss: 1.849426459240657

Epoch: 210| Step: 0
Training loss: 0.7998765707015991
Validation loss: 1.8186120935665664

Epoch: 6| Step: 1
Training loss: 0.8570144772529602
Validation loss: 1.8158314894604426

Epoch: 6| Step: 2
Training loss: 0.8113124966621399
Validation loss: 1.7874394565500238

Epoch: 6| Step: 3
Training loss: 0.7987675666809082
Validation loss: 1.8070410015762493

Epoch: 6| Step: 4
Training loss: 0.6899464130401611
Validation loss: 1.8045614355353898

Epoch: 6| Step: 5
Training loss: 0.8012358546257019
Validation loss: 1.8083956151880243

Epoch: 6| Step: 6
Training loss: 0.7721728086471558
Validation loss: 1.8059247616798646

Epoch: 6| Step: 7
Training loss: 0.8577231168746948
Validation loss: 1.8422185131298598

Epoch: 6| Step: 8
Training loss: 1.0112903118133545
Validation loss: 1.8308214474749822

Epoch: 6| Step: 9
Training loss: 0.7215304970741272
Validation loss: 1.812870635781237

Epoch: 6| Step: 10
Training loss: 0.35946452617645264
Validation loss: 1.835264507160392

Epoch: 6| Step: 11
Training loss: 0.9121860265731812
Validation loss: 1.8009560890095209

Epoch: 6| Step: 12
Training loss: 0.9373512864112854
Validation loss: 1.8174695109808316

Epoch: 6| Step: 13
Training loss: 0.30263376235961914
Validation loss: 1.8382413874390304

Epoch: 211| Step: 0
Training loss: 0.7405819296836853
Validation loss: 1.8497348498272639

Epoch: 6| Step: 1
Training loss: 0.5083644986152649
Validation loss: 1.863337270675167

Epoch: 6| Step: 2
Training loss: 0.4666040539741516
Validation loss: 1.8609752655029297

Epoch: 6| Step: 3
Training loss: 0.5645233392715454
Validation loss: 1.8491461379553682

Epoch: 6| Step: 4
Training loss: 0.814349889755249
Validation loss: 1.8719917369145218

Epoch: 6| Step: 5
Training loss: 0.8065842986106873
Validation loss: 1.8559538395174089

Epoch: 6| Step: 6
Training loss: 0.8482236862182617
Validation loss: 1.8286237691038398

Epoch: 6| Step: 7
Training loss: 0.7251259088516235
Validation loss: 1.838195857181344

Epoch: 6| Step: 8
Training loss: 1.011390209197998
Validation loss: 1.80766676574625

Epoch: 6| Step: 9
Training loss: 0.632327139377594
Validation loss: 1.805084672025455

Epoch: 6| Step: 10
Training loss: 1.1513234376907349
Validation loss: 1.8126112517490183

Epoch: 6| Step: 11
Training loss: 0.985450029373169
Validation loss: 1.8125773552925355

Epoch: 6| Step: 12
Training loss: 0.8575416207313538
Validation loss: 1.809051000943748

Epoch: 6| Step: 13
Training loss: 0.3377804756164551
Validation loss: 1.7876508184658584

Epoch: 212| Step: 0
Training loss: 0.9155912399291992
Validation loss: 1.8027687752118675

Epoch: 6| Step: 1
Training loss: 0.5492881536483765
Validation loss: 1.7800323322255125

Epoch: 6| Step: 2
Training loss: 0.5710117220878601
Validation loss: 1.7720341861888926

Epoch: 6| Step: 3
Training loss: 0.5229198932647705
Validation loss: 1.7899285567704069

Epoch: 6| Step: 4
Training loss: 0.6884078979492188
Validation loss: 1.8302655091849707

Epoch: 6| Step: 5
Training loss: 0.5189590454101562
Validation loss: 1.8185322412880518

Epoch: 6| Step: 6
Training loss: 0.6139629483222961
Validation loss: 1.8384103698115195

Epoch: 6| Step: 7
Training loss: 0.889855146408081
Validation loss: 1.8250039546720442

Epoch: 6| Step: 8
Training loss: 0.9643205404281616
Validation loss: 1.8078776572340278

Epoch: 6| Step: 9
Training loss: 0.6976471543312073
Validation loss: 1.7844423735013573

Epoch: 6| Step: 10
Training loss: 0.609485924243927
Validation loss: 1.7850799150364374

Epoch: 6| Step: 11
Training loss: 1.11642324924469
Validation loss: 1.8056401257873864

Epoch: 6| Step: 12
Training loss: 1.0207099914550781
Validation loss: 1.7842157938147103

Epoch: 6| Step: 13
Training loss: 0.9588829874992371
Validation loss: 1.8259197499162407

Epoch: 213| Step: 0
Training loss: 0.8093221187591553
Validation loss: 1.7979464364308182

Epoch: 6| Step: 1
Training loss: 0.4962657392024994
Validation loss: 1.7857316719588412

Epoch: 6| Step: 2
Training loss: 0.9313706755638123
Validation loss: 1.794983212665845

Epoch: 6| Step: 3
Training loss: 0.8676002621650696
Validation loss: 1.7689316195826377

Epoch: 6| Step: 4
Training loss: 0.8499454259872437
Validation loss: 1.8233487400957333

Epoch: 6| Step: 5
Training loss: 1.1464275121688843
Validation loss: 1.8642698769928308

Epoch: 6| Step: 6
Training loss: 1.0027101039886475
Validation loss: 1.8960302696433118

Epoch: 6| Step: 7
Training loss: 0.8701257705688477
Validation loss: 1.8525405378751858

Epoch: 6| Step: 8
Training loss: 0.4947061538696289
Validation loss: 1.8477977142539075

Epoch: 6| Step: 9
Training loss: 0.6501176357269287
Validation loss: 1.8273457968106834

Epoch: 6| Step: 10
Training loss: 0.7885540723800659
Validation loss: 1.8327234098988194

Epoch: 6| Step: 11
Training loss: 0.5443511009216309
Validation loss: 1.8408895538699241

Epoch: 6| Step: 12
Training loss: 0.8560704588890076
Validation loss: 1.8575730221245879

Epoch: 6| Step: 13
Training loss: 0.3324492871761322
Validation loss: 1.8428426634880803

Epoch: 214| Step: 0
Training loss: 0.4307622015476227
Validation loss: 1.8132744412268362

Epoch: 6| Step: 1
Training loss: 0.9346610307693481
Validation loss: 1.8114777098419845

Epoch: 6| Step: 2
Training loss: 0.6933639049530029
Validation loss: 1.8037515186494397

Epoch: 6| Step: 3
Training loss: 0.6699978113174438
Validation loss: 1.7934458396768058

Epoch: 6| Step: 4
Training loss: 0.7300902605056763
Validation loss: 1.765548094626396

Epoch: 6| Step: 5
Training loss: 0.548943042755127
Validation loss: 1.7912190832117552

Epoch: 6| Step: 6
Training loss: 0.5010666847229004
Validation loss: 1.8149313836969354

Epoch: 6| Step: 7
Training loss: 0.5534762740135193
Validation loss: 1.781320853899884

Epoch: 6| Step: 8
Training loss: 0.886305570602417
Validation loss: 1.7838375145389187

Epoch: 6| Step: 9
Training loss: 0.8172395825386047
Validation loss: 1.7686334938131354

Epoch: 6| Step: 10
Training loss: 1.3730056285858154
Validation loss: 1.815784272327218

Epoch: 6| Step: 11
Training loss: 0.4653950333595276
Validation loss: 1.8170500673273557

Epoch: 6| Step: 12
Training loss: 0.6144881248474121
Validation loss: 1.8341681675244403

Epoch: 6| Step: 13
Training loss: 0.45052364468574524
Validation loss: 1.8312253618753085

Epoch: 215| Step: 0
Training loss: 1.103899359703064
Validation loss: 1.8619791038574711

Epoch: 6| Step: 1
Training loss: 0.726722002029419
Validation loss: 1.8518300287185177

Epoch: 6| Step: 2
Training loss: 0.5961328148841858
Validation loss: 1.8732215589092625

Epoch: 6| Step: 3
Training loss: 0.7453182935714722
Validation loss: 1.8605997805954309

Epoch: 6| Step: 4
Training loss: 0.9662580490112305
Validation loss: 1.8635377742910897

Epoch: 6| Step: 5
Training loss: 0.3981228470802307
Validation loss: 1.8383465197778517

Epoch: 6| Step: 6
Training loss: 1.1892809867858887
Validation loss: 1.8316198805327057

Epoch: 6| Step: 7
Training loss: 0.6559558510780334
Validation loss: 1.855646159059258

Epoch: 6| Step: 8
Training loss: 0.7558424472808838
Validation loss: 1.8474265119080902

Epoch: 6| Step: 9
Training loss: 0.5864603519439697
Validation loss: 1.840666837589715

Epoch: 6| Step: 10
Training loss: 0.8743289709091187
Validation loss: 1.8274436304646153

Epoch: 6| Step: 11
Training loss: 0.6615132093429565
Validation loss: 1.7814095674022552

Epoch: 6| Step: 12
Training loss: 0.3878050446510315
Validation loss: 1.8059321321466917

Epoch: 6| Step: 13
Training loss: 0.5833680629730225
Validation loss: 1.78739486458481

Epoch: 216| Step: 0
Training loss: 0.9261393547058105
Validation loss: 1.8095668054396106

Epoch: 6| Step: 1
Training loss: 0.5749503970146179
Validation loss: 1.8110031274057203

Epoch: 6| Step: 2
Training loss: 0.6658543944358826
Validation loss: 1.8256755798093733

Epoch: 6| Step: 3
Training loss: 0.8277468681335449
Validation loss: 1.8072465696642477

Epoch: 6| Step: 4
Training loss: 0.7107770442962646
Validation loss: 1.80509138876392

Epoch: 6| Step: 5
Training loss: 0.759950578212738
Validation loss: 1.7892060766937912

Epoch: 6| Step: 6
Training loss: 0.7498703002929688
Validation loss: 1.7882613276922574

Epoch: 6| Step: 7
Training loss: 0.6112821102142334
Validation loss: 1.7806375526612805

Epoch: 6| Step: 8
Training loss: 0.5911926627159119
Validation loss: 1.795479275846994

Epoch: 6| Step: 9
Training loss: 0.6085149645805359
Validation loss: 1.7741727854615899

Epoch: 6| Step: 10
Training loss: 0.9812023043632507
Validation loss: 1.7839135880111365

Epoch: 6| Step: 11
Training loss: 0.4903470277786255
Validation loss: 1.782277346939169

Epoch: 6| Step: 12
Training loss: 0.8773138523101807
Validation loss: 1.772759420897371

Epoch: 6| Step: 13
Training loss: 0.3988507091999054
Validation loss: 1.7590644897953156

Epoch: 217| Step: 0
Training loss: 0.6585889458656311
Validation loss: 1.7849995243933894

Epoch: 6| Step: 1
Training loss: 0.534704327583313
Validation loss: 1.7737461789961784

Epoch: 6| Step: 2
Training loss: 0.9302731156349182
Validation loss: 1.8118067172265822

Epoch: 6| Step: 3
Training loss: 0.5490332245826721
Validation loss: 1.7646723613944104

Epoch: 6| Step: 4
Training loss: 0.7172494530677795
Validation loss: 1.79156699872786

Epoch: 6| Step: 5
Training loss: 0.5932016372680664
Validation loss: 1.7887620836175897

Epoch: 6| Step: 6
Training loss: 0.7668870687484741
Validation loss: 1.801352729079544

Epoch: 6| Step: 7
Training loss: 0.7134052515029907
Validation loss: 1.8011101907299412

Epoch: 6| Step: 8
Training loss: 0.8978606462478638
Validation loss: 1.829533225746565

Epoch: 6| Step: 9
Training loss: 0.6051210165023804
Validation loss: 1.845900845784013

Epoch: 6| Step: 10
Training loss: 0.5529261231422424
Validation loss: 1.8257667890159033

Epoch: 6| Step: 11
Training loss: 0.7894425392150879
Validation loss: 1.8382712064250823

Epoch: 6| Step: 12
Training loss: 0.7414050102233887
Validation loss: 1.8396086923537716

Epoch: 6| Step: 13
Training loss: 0.5210893154144287
Validation loss: 1.8139646232769053

Epoch: 218| Step: 0
Training loss: 0.613511323928833
Validation loss: 1.8357272007132088

Epoch: 6| Step: 1
Training loss: 0.4394296407699585
Validation loss: 1.8414013052499423

Epoch: 6| Step: 2
Training loss: 0.49796032905578613
Validation loss: 1.8615751638207385

Epoch: 6| Step: 3
Training loss: 0.6710507869720459
Validation loss: 1.8601640744875836

Epoch: 6| Step: 4
Training loss: 0.46238964796066284
Validation loss: 1.8318734912462131

Epoch: 6| Step: 5
Training loss: 0.7569908499717712
Validation loss: 1.8419041338787283

Epoch: 6| Step: 6
Training loss: 0.9191215634346008
Validation loss: 1.8183806096353838

Epoch: 6| Step: 7
Training loss: 0.6542937755584717
Validation loss: 1.8034922410083074

Epoch: 6| Step: 8
Training loss: 0.5830768942832947
Validation loss: 1.8037824694828322

Epoch: 6| Step: 9
Training loss: 0.8234480619430542
Validation loss: 1.8059689408989363

Epoch: 6| Step: 10
Training loss: 0.8118493556976318
Validation loss: 1.786037096413233

Epoch: 6| Step: 11
Training loss: 0.6912221908569336
Validation loss: 1.792694769879823

Epoch: 6| Step: 12
Training loss: 0.8828660249710083
Validation loss: 1.7804406278876848

Epoch: 6| Step: 13
Training loss: 0.7146875858306885
Validation loss: 1.7926952428715204

Epoch: 219| Step: 0
Training loss: 0.9597485065460205
Validation loss: 1.7838886976242065

Epoch: 6| Step: 1
Training loss: 0.36460602283477783
Validation loss: 1.7918954536479006

Epoch: 6| Step: 2
Training loss: 0.6318905353546143
Validation loss: 1.77057433384721

Epoch: 6| Step: 3
Training loss: 0.5956546068191528
Validation loss: 1.8048708951601418

Epoch: 6| Step: 4
Training loss: 0.5160754323005676
Validation loss: 1.8010811203269548

Epoch: 6| Step: 5
Training loss: 0.3773152828216553
Validation loss: 1.8216850283325359

Epoch: 6| Step: 6
Training loss: 0.622078001499176
Validation loss: 1.8040241285036969

Epoch: 6| Step: 7
Training loss: 0.6870787143707275
Validation loss: 1.7932835778882426

Epoch: 6| Step: 8
Training loss: 0.7397486567497253
Validation loss: 1.8018372981779036

Epoch: 6| Step: 9
Training loss: 0.9536500573158264
Validation loss: 1.8232142412534325

Epoch: 6| Step: 10
Training loss: 0.3624333441257477
Validation loss: 1.8370268985789309

Epoch: 6| Step: 11
Training loss: 0.7438849210739136
Validation loss: 1.845064522117697

Epoch: 6| Step: 12
Training loss: 0.8804966807365417
Validation loss: 1.8449031896488641

Epoch: 6| Step: 13
Training loss: 0.711119532585144
Validation loss: 1.8425634676410305

Epoch: 220| Step: 0
Training loss: 0.4111049175262451
Validation loss: 1.8547443292474235

Epoch: 6| Step: 1
Training loss: 0.5228406190872192
Validation loss: 1.850762273675652

Epoch: 6| Step: 2
Training loss: 0.40214046835899353
Validation loss: 1.8471824840832782

Epoch: 6| Step: 3
Training loss: 0.8169301152229309
Validation loss: 1.835040638523717

Epoch: 6| Step: 4
Training loss: 0.754881739616394
Validation loss: 1.821902339176465

Epoch: 6| Step: 5
Training loss: 0.6076866388320923
Validation loss: 1.7851275218430387

Epoch: 6| Step: 6
Training loss: 0.4644041657447815
Validation loss: 1.7743689501157371

Epoch: 6| Step: 7
Training loss: 0.6374070048332214
Validation loss: 1.807031810924571

Epoch: 6| Step: 8
Training loss: 1.0157139301300049
Validation loss: 1.800919081575127

Epoch: 6| Step: 9
Training loss: 0.6324706077575684
Validation loss: 1.8174707838284072

Epoch: 6| Step: 10
Training loss: 0.7070393562316895
Validation loss: 1.805827909900296

Epoch: 6| Step: 11
Training loss: 0.6270551681518555
Validation loss: 1.805753843758696

Epoch: 6| Step: 12
Training loss: 0.7606399655342102
Validation loss: 1.808568275103005

Epoch: 6| Step: 13
Training loss: 0.5418016314506531
Validation loss: 1.8168020043321835

Epoch: 221| Step: 0
Training loss: 0.4572831094264984
Validation loss: 1.8263486572491225

Epoch: 6| Step: 1
Training loss: 0.5323605537414551
Validation loss: 1.829566358238138

Epoch: 6| Step: 2
Training loss: 0.4620823264122009
Validation loss: 1.8184338256876955

Epoch: 6| Step: 3
Training loss: 0.5882831811904907
Validation loss: 1.8241342139500443

Epoch: 6| Step: 4
Training loss: 0.8548711538314819
Validation loss: 1.8282371720960062

Epoch: 6| Step: 5
Training loss: 0.6966527700424194
Validation loss: 1.8484884923504246

Epoch: 6| Step: 6
Training loss: 0.6136111617088318
Validation loss: 1.8649644595320507

Epoch: 6| Step: 7
Training loss: 0.4981786012649536
Validation loss: 1.875021170544368

Epoch: 6| Step: 8
Training loss: 0.5026215314865112
Validation loss: 1.8571159467902234

Epoch: 6| Step: 9
Training loss: 0.7962214350700378
Validation loss: 1.839306087904079

Epoch: 6| Step: 10
Training loss: 0.32493025064468384
Validation loss: 1.846820290370654

Epoch: 6| Step: 11
Training loss: 0.8818260431289673
Validation loss: 1.832284337730818

Epoch: 6| Step: 12
Training loss: 0.7257317304611206
Validation loss: 1.8570922555462006

Epoch: 6| Step: 13
Training loss: 0.8398467302322388
Validation loss: 1.8641294305042555

Epoch: 222| Step: 0
Training loss: 0.741922914981842
Validation loss: 1.85154309580403

Epoch: 6| Step: 1
Training loss: 0.6604188084602356
Validation loss: 1.8629031655608967

Epoch: 6| Step: 2
Training loss: 0.5557096004486084
Validation loss: 1.8563667907509753

Epoch: 6| Step: 3
Training loss: 0.4719367027282715
Validation loss: 1.8455305996761526

Epoch: 6| Step: 4
Training loss: 1.05331552028656
Validation loss: 1.8975442263387865

Epoch: 6| Step: 5
Training loss: 0.4372655153274536
Validation loss: 1.907001700452579

Epoch: 6| Step: 6
Training loss: 0.8420361876487732
Validation loss: 1.9012286893783077

Epoch: 6| Step: 7
Training loss: 0.5106308460235596
Validation loss: 1.8674682301859702

Epoch: 6| Step: 8
Training loss: 0.8260974287986755
Validation loss: 1.846378513561782

Epoch: 6| Step: 9
Training loss: 0.9210903644561768
Validation loss: 1.847908527620377

Epoch: 6| Step: 10
Training loss: 0.8552452325820923
Validation loss: 1.8624541708218154

Epoch: 6| Step: 11
Training loss: 0.8234079480171204
Validation loss: 1.8300621817188878

Epoch: 6| Step: 12
Training loss: 0.5538051128387451
Validation loss: 1.7861288080933273

Epoch: 6| Step: 13
Training loss: 0.4584251642227173
Validation loss: 1.7597636740694764

Epoch: 223| Step: 0
Training loss: 0.608401894569397
Validation loss: 1.7911876427230013

Epoch: 6| Step: 1
Training loss: 0.610435962677002
Validation loss: 1.799293621893852

Epoch: 6| Step: 2
Training loss: 0.8239617943763733
Validation loss: 1.8061055790993474

Epoch: 6| Step: 3
Training loss: 0.7839998602867126
Validation loss: 1.8288906479394564

Epoch: 6| Step: 4
Training loss: 0.7411205768585205
Validation loss: 1.8338900202064103

Epoch: 6| Step: 5
Training loss: 0.9428709745407104
Validation loss: 1.819942597419985

Epoch: 6| Step: 6
Training loss: 0.6083961129188538
Validation loss: 1.8127111478518414

Epoch: 6| Step: 7
Training loss: 0.5736453533172607
Validation loss: 1.8062890575778099

Epoch: 6| Step: 8
Training loss: 0.6079304218292236
Validation loss: 1.832910119846303

Epoch: 6| Step: 9
Training loss: 0.7953608632087708
Validation loss: 1.8240718405733827

Epoch: 6| Step: 10
Training loss: 0.829524040222168
Validation loss: 1.8425235338108514

Epoch: 6| Step: 11
Training loss: 0.4977038502693176
Validation loss: 1.8030039072036743

Epoch: 6| Step: 12
Training loss: 0.5021425485610962
Validation loss: 1.7942752799680155

Epoch: 6| Step: 13
Training loss: 0.30913591384887695
Validation loss: 1.7977654908293037

Epoch: 224| Step: 0
Training loss: 0.45465773344039917
Validation loss: 1.7915656387165029

Epoch: 6| Step: 1
Training loss: 0.6745224595069885
Validation loss: 1.8100073632373606

Epoch: 6| Step: 2
Training loss: 0.6426186561584473
Validation loss: 1.8223940595503776

Epoch: 6| Step: 3
Training loss: 0.5742145776748657
Validation loss: 1.8552839935466807

Epoch: 6| Step: 4
Training loss: 1.016295313835144
Validation loss: 1.8382935267622753

Epoch: 6| Step: 5
Training loss: 0.3778955340385437
Validation loss: 1.8887522630794074

Epoch: 6| Step: 6
Training loss: 0.5223429203033447
Validation loss: 1.8855249125470397

Epoch: 6| Step: 7
Training loss: 0.26361364126205444
Validation loss: 1.910882108954973

Epoch: 6| Step: 8
Training loss: 0.7025128602981567
Validation loss: 1.8710027112755725

Epoch: 6| Step: 9
Training loss: 0.45990535616874695
Validation loss: 1.842279521367883

Epoch: 6| Step: 10
Training loss: 0.7652038335800171
Validation loss: 1.8483542985813592

Epoch: 6| Step: 11
Training loss: 1.0453555583953857
Validation loss: 1.7926238839344313

Epoch: 6| Step: 12
Training loss: 0.6878069639205933
Validation loss: 1.8032764875760643

Epoch: 6| Step: 13
Training loss: 0.6391688585281372
Validation loss: 1.7851935355894026

Epoch: 225| Step: 0
Training loss: 0.5873222947120667
Validation loss: 1.7687190322465793

Epoch: 6| Step: 1
Training loss: 0.6724656224250793
Validation loss: 1.7796313198663856

Epoch: 6| Step: 2
Training loss: 0.38559770584106445
Validation loss: 1.8092441610110703

Epoch: 6| Step: 3
Training loss: 0.6515927910804749
Validation loss: 1.7879697674064225

Epoch: 6| Step: 4
Training loss: 0.6365355253219604
Validation loss: 1.8269530778290124

Epoch: 6| Step: 5
Training loss: 0.6189296841621399
Validation loss: 1.8274097916900471

Epoch: 6| Step: 6
Training loss: 0.7182297706604004
Validation loss: 1.8117007952864452

Epoch: 6| Step: 7
Training loss: 0.4302595853805542
Validation loss: 1.7817123013157998

Epoch: 6| Step: 8
Training loss: 0.5400063991546631
Validation loss: 1.7877957872165147

Epoch: 6| Step: 9
Training loss: 0.5227435827255249
Validation loss: 1.782525436852568

Epoch: 6| Step: 10
Training loss: 0.9036009311676025
Validation loss: 1.7728539884731334

Epoch: 6| Step: 11
Training loss: 0.3657210171222687
Validation loss: 1.7823565134438135

Epoch: 6| Step: 12
Training loss: 0.5103015303611755
Validation loss: 1.7715480981334564

Epoch: 6| Step: 13
Training loss: 0.6597244739532471
Validation loss: 1.784085630088724

Epoch: 226| Step: 0
Training loss: 0.477671355009079
Validation loss: 1.7823129905167447

Epoch: 6| Step: 1
Training loss: 0.33548909425735474
Validation loss: 1.763732369228076

Epoch: 6| Step: 2
Training loss: 0.7593172788619995
Validation loss: 1.79132858655786

Epoch: 6| Step: 3
Training loss: 0.9463399052619934
Validation loss: 1.784100321031386

Epoch: 6| Step: 4
Training loss: 0.3304438292980194
Validation loss: 1.8151475383389382

Epoch: 6| Step: 5
Training loss: 0.5906351804733276
Validation loss: 1.7736445408995434

Epoch: 6| Step: 6
Training loss: 0.8060541749000549
Validation loss: 1.7753580308729602

Epoch: 6| Step: 7
Training loss: 0.6371220350265503
Validation loss: 1.8084146566288446

Epoch: 6| Step: 8
Training loss: 0.4970439076423645
Validation loss: 1.7807508412227835

Epoch: 6| Step: 9
Training loss: 0.534674346446991
Validation loss: 1.7662831224421018

Epoch: 6| Step: 10
Training loss: 0.5341663360595703
Validation loss: 1.7701431961469754

Epoch: 6| Step: 11
Training loss: 0.752139151096344
Validation loss: 1.793568685490598

Epoch: 6| Step: 12
Training loss: 0.33850690722465515
Validation loss: 1.8049945869753439

Epoch: 6| Step: 13
Training loss: 0.5652223825454712
Validation loss: 1.8407755282617384

Epoch: 227| Step: 0
Training loss: 0.48255419731140137
Validation loss: 1.8057238196813932

Epoch: 6| Step: 1
Training loss: 0.7864935398101807
Validation loss: 1.8028672382395754

Epoch: 6| Step: 2
Training loss: 0.2621442377567291
Validation loss: 1.7805786876268284

Epoch: 6| Step: 3
Training loss: 0.507935643196106
Validation loss: 1.779466655946547

Epoch: 6| Step: 4
Training loss: 0.6718933582305908
Validation loss: 1.8102981967310752

Epoch: 6| Step: 5
Training loss: 0.8091963529586792
Validation loss: 1.805269648951869

Epoch: 6| Step: 6
Training loss: 0.33485299348831177
Validation loss: 1.8516680937941357

Epoch: 6| Step: 7
Training loss: 0.5349725484848022
Validation loss: 1.8461821143345167

Epoch: 6| Step: 8
Training loss: 0.47052204608917236
Validation loss: 1.8374248602057015

Epoch: 6| Step: 9
Training loss: 0.6024744510650635
Validation loss: 1.8301046984170073

Epoch: 6| Step: 10
Training loss: 0.6083052158355713
Validation loss: 1.7959861627189062

Epoch: 6| Step: 11
Training loss: 0.7446258068084717
Validation loss: 1.7906929882623817

Epoch: 6| Step: 12
Training loss: 0.6210699081420898
Validation loss: 1.8001805582354147

Epoch: 6| Step: 13
Training loss: 0.6829370856285095
Validation loss: 1.7791983158357683

Epoch: 228| Step: 0
Training loss: 0.3958410322666168
Validation loss: 1.78278644879659

Epoch: 6| Step: 1
Training loss: 0.4226001501083374
Validation loss: 1.7872507905447355

Epoch: 6| Step: 2
Training loss: 0.3310384750366211
Validation loss: 1.7914493122408468

Epoch: 6| Step: 3
Training loss: 0.42318928241729736
Validation loss: 1.808790042836179

Epoch: 6| Step: 4
Training loss: 0.5667105317115784
Validation loss: 1.810081317860593

Epoch: 6| Step: 5
Training loss: 0.7726612687110901
Validation loss: 1.790799363966911

Epoch: 6| Step: 6
Training loss: 0.44683194160461426
Validation loss: 1.7595665852228801

Epoch: 6| Step: 7
Training loss: 0.5065044164657593
Validation loss: 1.7753081860080842

Epoch: 6| Step: 8
Training loss: 0.6877387762069702
Validation loss: 1.7681167689702844

Epoch: 6| Step: 9
Training loss: 0.6013727784156799
Validation loss: 1.7736877741352204

Epoch: 6| Step: 10
Training loss: 0.7349886894226074
Validation loss: 1.7690485651775072

Epoch: 6| Step: 11
Training loss: 0.7925751209259033
Validation loss: 1.7711449284707346

Epoch: 6| Step: 12
Training loss: 0.7042988538742065
Validation loss: 1.7494963856153591

Epoch: 6| Step: 13
Training loss: 0.3802144229412079
Validation loss: 1.7674313142735472

Epoch: 229| Step: 0
Training loss: 0.5481739044189453
Validation loss: 1.7843579912698397

Epoch: 6| Step: 1
Training loss: 0.5823555588722229
Validation loss: 1.7961358101137224

Epoch: 6| Step: 2
Training loss: 0.5325372219085693
Validation loss: 1.8560288362605597

Epoch: 6| Step: 3
Training loss: 0.9165503978729248
Validation loss: 1.829113124519266

Epoch: 6| Step: 4
Training loss: 0.46689483523368835
Validation loss: 1.8623528185711111

Epoch: 6| Step: 5
Training loss: 0.30441832542419434
Validation loss: 1.8211699378105901

Epoch: 6| Step: 6
Training loss: 0.49694815278053284
Validation loss: 1.791141612555391

Epoch: 6| Step: 7
Training loss: 0.6697688102722168
Validation loss: 1.77878580170293

Epoch: 6| Step: 8
Training loss: 0.45395198464393616
Validation loss: 1.7676180511392572

Epoch: 6| Step: 9
Training loss: 0.35877519845962524
Validation loss: 1.807018595357095

Epoch: 6| Step: 10
Training loss: 0.677151083946228
Validation loss: 1.7912984727531351

Epoch: 6| Step: 11
Training loss: 0.607789933681488
Validation loss: 1.7983325796742593

Epoch: 6| Step: 12
Training loss: 0.4190651476383209
Validation loss: 1.7842262457775813

Epoch: 6| Step: 13
Training loss: 0.7205692529678345
Validation loss: 1.7709365762690061

Epoch: 230| Step: 0
Training loss: 0.5026042461395264
Validation loss: 1.7725777369673534

Epoch: 6| Step: 1
Training loss: 0.5407482981681824
Validation loss: 1.7697222284091416

Epoch: 6| Step: 2
Training loss: 0.4382621943950653
Validation loss: 1.75165851910909

Epoch: 6| Step: 3
Training loss: 0.531335711479187
Validation loss: 1.7605138606922601

Epoch: 6| Step: 4
Training loss: 0.39416196942329407
Validation loss: 1.7730069775735178

Epoch: 6| Step: 5
Training loss: 0.4016127288341522
Validation loss: 1.765538659147037

Epoch: 6| Step: 6
Training loss: 0.7029359936714172
Validation loss: 1.7545685268217517

Epoch: 6| Step: 7
Training loss: 0.6565700769424438
Validation loss: 1.7500471607331307

Epoch: 6| Step: 8
Training loss: 0.555884599685669
Validation loss: 1.7345684753951205

Epoch: 6| Step: 9
Training loss: 0.5221825242042542
Validation loss: 1.7602410521558536

Epoch: 6| Step: 10
Training loss: 0.4293038845062256
Validation loss: 1.7658310936343284

Epoch: 6| Step: 11
Training loss: 0.6670202016830444
Validation loss: 1.7731166424289826

Epoch: 6| Step: 12
Training loss: 0.602581262588501
Validation loss: 1.8006506837824339

Epoch: 6| Step: 13
Training loss: 0.26801547408103943
Validation loss: 1.7804304630525651

Epoch: 231| Step: 0
Training loss: 0.37885284423828125
Validation loss: 1.8012840760651456

Epoch: 6| Step: 1
Training loss: 0.38075700402259827
Validation loss: 1.8257940917886712

Epoch: 6| Step: 2
Training loss: 0.7509573698043823
Validation loss: 1.8080418186803018

Epoch: 6| Step: 3
Training loss: 0.4180302619934082
Validation loss: 1.8133050369960007

Epoch: 6| Step: 4
Training loss: 0.8031243085861206
Validation loss: 1.8239258476482925

Epoch: 6| Step: 5
Training loss: 0.5479322075843811
Validation loss: 1.8311263463830436

Epoch: 6| Step: 6
Training loss: 0.49106165766716003
Validation loss: 1.8034572421863515

Epoch: 6| Step: 7
Training loss: 0.4122489094734192
Validation loss: 1.7715223335450696

Epoch: 6| Step: 8
Training loss: 0.5074493288993835
Validation loss: 1.769469040696339

Epoch: 6| Step: 9
Training loss: 0.40090417861938477
Validation loss: 1.7731943104856758

Epoch: 6| Step: 10
Training loss: 0.6512608528137207
Validation loss: 1.8164049553614792

Epoch: 6| Step: 11
Training loss: 0.5595188140869141
Validation loss: 1.7878691214387135

Epoch: 6| Step: 12
Training loss: 0.7289448380470276
Validation loss: 1.7948865031683316

Epoch: 6| Step: 13
Training loss: 0.45741668343544006
Validation loss: 1.8028300128957278

Epoch: 232| Step: 0
Training loss: 0.500859260559082
Validation loss: 1.790755574421216

Epoch: 6| Step: 1
Training loss: 0.7225979566574097
Validation loss: 1.8124854539030342

Epoch: 6| Step: 2
Training loss: 0.2846510410308838
Validation loss: 1.812174040784118

Epoch: 6| Step: 3
Training loss: 0.5661846399307251
Validation loss: 1.7952266764897171

Epoch: 6| Step: 4
Training loss: 0.481400728225708
Validation loss: 1.791155722833449

Epoch: 6| Step: 5
Training loss: 0.7233444452285767
Validation loss: 1.7552421554442375

Epoch: 6| Step: 6
Training loss: 0.496903657913208
Validation loss: 1.7668809416473552

Epoch: 6| Step: 7
Training loss: 0.4985799193382263
Validation loss: 1.7505030875564904

Epoch: 6| Step: 8
Training loss: 0.5555815100669861
Validation loss: 1.740859313677716

Epoch: 6| Step: 9
Training loss: 0.714961051940918
Validation loss: 1.7374345730709773

Epoch: 6| Step: 10
Training loss: 0.42011889815330505
Validation loss: 1.7556704231487807

Epoch: 6| Step: 11
Training loss: 0.6188011765480042
Validation loss: 1.7296875958801599

Epoch: 6| Step: 12
Training loss: 0.5850002765655518
Validation loss: 1.7191336103664931

Epoch: 6| Step: 13
Training loss: 0.40068671107292175
Validation loss: 1.736368799722323

Epoch: 233| Step: 0
Training loss: 0.30768686532974243
Validation loss: 1.7416325794753207

Epoch: 6| Step: 1
Training loss: 0.3435576558113098
Validation loss: 1.7557203603047196

Epoch: 6| Step: 2
Training loss: 0.48891007900238037
Validation loss: 1.7410723201690181

Epoch: 6| Step: 3
Training loss: 0.5237810015678406
Validation loss: 1.792165135824552

Epoch: 6| Step: 4
Training loss: 0.5659191012382507
Validation loss: 1.822172693026963

Epoch: 6| Step: 5
Training loss: 0.685349702835083
Validation loss: 1.807447725726712

Epoch: 6| Step: 6
Training loss: 0.2420801818370819
Validation loss: 1.8121121160445675

Epoch: 6| Step: 7
Training loss: 0.562539279460907
Validation loss: 1.8353640507626277

Epoch: 6| Step: 8
Training loss: 0.5355752110481262
Validation loss: 1.821224865093026

Epoch: 6| Step: 9
Training loss: 0.6356688141822815
Validation loss: 1.8380271183547152

Epoch: 6| Step: 10
Training loss: 1.062230110168457
Validation loss: 1.815097503764655

Epoch: 6| Step: 11
Training loss: 0.4963211715221405
Validation loss: 1.7828524458792903

Epoch: 6| Step: 12
Training loss: 0.5198002457618713
Validation loss: 1.7479473057613577

Epoch: 6| Step: 13
Training loss: 0.8334861993789673
Validation loss: 1.7800356200946275

Epoch: 234| Step: 0
Training loss: 0.6893515586853027
Validation loss: 1.7559328015132616

Epoch: 6| Step: 1
Training loss: 0.4174864888191223
Validation loss: 1.7651802878226004

Epoch: 6| Step: 2
Training loss: 0.41252219676971436
Validation loss: 1.7374691104376188

Epoch: 6| Step: 3
Training loss: 0.46547722816467285
Validation loss: 1.7454215185616606

Epoch: 6| Step: 4
Training loss: 0.4407764971256256
Validation loss: 1.7459899494724889

Epoch: 6| Step: 5
Training loss: 0.6640464067459106
Validation loss: 1.7211307338489

Epoch: 6| Step: 6
Training loss: 0.3977176547050476
Validation loss: 1.7580777086237425

Epoch: 6| Step: 7
Training loss: 0.6593703031539917
Validation loss: 1.728076736132304

Epoch: 6| Step: 8
Training loss: 0.45528313517570496
Validation loss: 1.7699085512468893

Epoch: 6| Step: 9
Training loss: 0.5105578899383545
Validation loss: 1.7379600360829344

Epoch: 6| Step: 10
Training loss: 0.8046090602874756
Validation loss: 1.7456231911977131

Epoch: 6| Step: 11
Training loss: 0.5720430612564087
Validation loss: 1.767921414426578

Epoch: 6| Step: 12
Training loss: 0.5529414415359497
Validation loss: 1.7523060793517737

Epoch: 6| Step: 13
Training loss: 0.45541560649871826
Validation loss: 1.749509294827779

Epoch: 235| Step: 0
Training loss: 0.3572298586368561
Validation loss: 1.7671332199086425

Epoch: 6| Step: 1
Training loss: 0.34071874618530273
Validation loss: 1.7891779151014102

Epoch: 6| Step: 2
Training loss: 0.5875218510627747
Validation loss: 1.7970286338560042

Epoch: 6| Step: 3
Training loss: 0.6682916879653931
Validation loss: 1.8012691274766

Epoch: 6| Step: 4
Training loss: 0.4683954417705536
Validation loss: 1.7658263047536213

Epoch: 6| Step: 5
Training loss: 0.45425868034362793
Validation loss: 1.7653954246992707

Epoch: 6| Step: 6
Training loss: 0.43421489000320435
Validation loss: 1.7470078750323224

Epoch: 6| Step: 7
Training loss: 0.6779781579971313
Validation loss: 1.741766934753746

Epoch: 6| Step: 8
Training loss: 0.6892194747924805
Validation loss: 1.8086370165630052

Epoch: 6| Step: 9
Training loss: 0.5539705157279968
Validation loss: 1.756227090794553

Epoch: 6| Step: 10
Training loss: 0.4218515157699585
Validation loss: 1.75441772642956

Epoch: 6| Step: 11
Training loss: 0.31961381435394287
Validation loss: 1.7781250707564815

Epoch: 6| Step: 12
Training loss: 0.36313337087631226
Validation loss: 1.7678687187933153

Epoch: 6| Step: 13
Training loss: 0.6991955637931824
Validation loss: 1.7729949053897653

Epoch: 236| Step: 0
Training loss: 0.3947508931159973
Validation loss: 1.799966468605944

Epoch: 6| Step: 1
Training loss: 0.5468801259994507
Validation loss: 1.7842181933823453

Epoch: 6| Step: 2
Training loss: 0.7034028768539429
Validation loss: 1.7782677245396439

Epoch: 6| Step: 3
Training loss: 0.5328241586685181
Validation loss: 1.8149869723986554

Epoch: 6| Step: 4
Training loss: 0.36326122283935547
Validation loss: 1.832985524208315

Epoch: 6| Step: 5
Training loss: 0.5485994815826416
Validation loss: 1.8172300118272022

Epoch: 6| Step: 6
Training loss: 0.6229956150054932
Validation loss: 1.800494691377045

Epoch: 6| Step: 7
Training loss: 0.43770766258239746
Validation loss: 1.8013946587039578

Epoch: 6| Step: 8
Training loss: 0.3551322817802429
Validation loss: 1.813712143128918

Epoch: 6| Step: 9
Training loss: 0.5576121807098389
Validation loss: 1.812927334539352

Epoch: 6| Step: 10
Training loss: 0.5359535217285156
Validation loss: 1.8313638779424852

Epoch: 6| Step: 11
Training loss: 0.41963234543800354
Validation loss: 1.8324060388790664

Epoch: 6| Step: 12
Training loss: 0.34108099341392517
Validation loss: 1.8065371974822013

Epoch: 6| Step: 13
Training loss: 0.3909875452518463
Validation loss: 1.7990307961740801

Epoch: 237| Step: 0
Training loss: 0.3279421031475067
Validation loss: 1.8000901501665834

Epoch: 6| Step: 1
Training loss: 0.7200900316238403
Validation loss: 1.7712733963484406

Epoch: 6| Step: 2
Training loss: 0.4752225875854492
Validation loss: 1.7498776784507177

Epoch: 6| Step: 3
Training loss: 0.3822129964828491
Validation loss: 1.741423685063598

Epoch: 6| Step: 4
Training loss: 0.760723352432251
Validation loss: 1.7538187119268602

Epoch: 6| Step: 5
Training loss: 0.40900659561157227
Validation loss: 1.7446653073833835

Epoch: 6| Step: 6
Training loss: 0.4769458770751953
Validation loss: 1.7256160897593344

Epoch: 6| Step: 7
Training loss: 0.5604081153869629
Validation loss: 1.7599679834099227

Epoch: 6| Step: 8
Training loss: 0.5850789546966553
Validation loss: 1.7599439242834687

Epoch: 6| Step: 9
Training loss: 0.40871095657348633
Validation loss: 1.7590243470284246

Epoch: 6| Step: 10
Training loss: 0.282107949256897
Validation loss: 1.7407284539232972

Epoch: 6| Step: 11
Training loss: 0.4765627980232239
Validation loss: 1.7731730348320418

Epoch: 6| Step: 12
Training loss: 0.37516331672668457
Validation loss: 1.7619708225291262

Epoch: 6| Step: 13
Training loss: 0.5623910427093506
Validation loss: 1.7509513119215607

Epoch: 238| Step: 0
Training loss: 0.38647201657295227
Validation loss: 1.731917655596169

Epoch: 6| Step: 1
Training loss: 0.3571259677410126
Validation loss: 1.7183218117683166

Epoch: 6| Step: 2
Training loss: 0.3260525166988373
Validation loss: 1.7077878508516537

Epoch: 6| Step: 3
Training loss: 0.6127095222473145
Validation loss: 1.7232322897962344

Epoch: 6| Step: 4
Training loss: 0.40200525522232056
Validation loss: 1.7228495151765886

Epoch: 6| Step: 5
Training loss: 0.30880361795425415
Validation loss: 1.7641063800422094

Epoch: 6| Step: 6
Training loss: 0.6385151147842407
Validation loss: 1.766469241470419

Epoch: 6| Step: 7
Training loss: 0.6735782623291016
Validation loss: 1.759869610109637

Epoch: 6| Step: 8
Training loss: 0.4897230267524719
Validation loss: 1.7503512251761653

Epoch: 6| Step: 9
Training loss: 0.6327677369117737
Validation loss: 1.7651818977889193

Epoch: 6| Step: 10
Training loss: 0.4839327335357666
Validation loss: 1.735940364099318

Epoch: 6| Step: 11
Training loss: 0.660576343536377
Validation loss: 1.7750629942904237

Epoch: 6| Step: 12
Training loss: 0.38211387395858765
Validation loss: 1.7728338562032229

Epoch: 6| Step: 13
Training loss: 0.46974408626556396
Validation loss: 1.8046299328086197

Epoch: 239| Step: 0
Training loss: 0.6416119337081909
Validation loss: 1.8187213610577326

Epoch: 6| Step: 1
Training loss: 0.46940362453460693
Validation loss: 1.8361001629983225

Epoch: 6| Step: 2
Training loss: 0.3578281104564667
Validation loss: 1.8483243514132757

Epoch: 6| Step: 3
Training loss: 0.5620827674865723
Validation loss: 1.808637229345178

Epoch: 6| Step: 4
Training loss: 0.5321741104125977
Validation loss: 1.7240782130149104

Epoch: 6| Step: 5
Training loss: 0.26729345321655273
Validation loss: 1.7509690202692503

Epoch: 6| Step: 6
Training loss: 0.5451714992523193
Validation loss: 1.7818776689549929

Epoch: 6| Step: 7
Training loss: 0.5176975727081299
Validation loss: 1.7895206494997906

Epoch: 6| Step: 8
Training loss: 0.5650794506072998
Validation loss: 1.799838440392607

Epoch: 6| Step: 9
Training loss: 0.37711459398269653
Validation loss: 1.802977313277542

Epoch: 6| Step: 10
Training loss: 0.49883466958999634
Validation loss: 1.75651204457847

Epoch: 6| Step: 11
Training loss: 0.7658265829086304
Validation loss: 1.7269161439711047

Epoch: 6| Step: 12
Training loss: 0.5518920421600342
Validation loss: 1.7406825583468202

Epoch: 6| Step: 13
Training loss: 0.5706290006637573
Validation loss: 1.7497961739058137

Epoch: 240| Step: 0
Training loss: 0.4774702489376068
Validation loss: 1.7686033684720275

Epoch: 6| Step: 1
Training loss: 0.4612275958061218
Validation loss: 1.7874838588058308

Epoch: 6| Step: 2
Training loss: 0.5319240093231201
Validation loss: 1.7896709160138202

Epoch: 6| Step: 3
Training loss: 0.713116466999054
Validation loss: 1.7991973482152468

Epoch: 6| Step: 4
Training loss: 0.6764076948165894
Validation loss: 1.8296965732369372

Epoch: 6| Step: 5
Training loss: 0.2774868905544281
Validation loss: 1.800535544272392

Epoch: 6| Step: 6
Training loss: 0.4610626697540283
Validation loss: 1.752912764908165

Epoch: 6| Step: 7
Training loss: 0.3433268666267395
Validation loss: 1.7504478167462092

Epoch: 6| Step: 8
Training loss: 0.7245311737060547
Validation loss: 1.7737375010726273

Epoch: 6| Step: 9
Training loss: 0.39024031162261963
Validation loss: 1.7757948137098742

Epoch: 6| Step: 10
Training loss: 0.5517295598983765
Validation loss: 1.745247571699081

Epoch: 6| Step: 11
Training loss: 0.5814204812049866
Validation loss: 1.758723666591029

Epoch: 6| Step: 12
Training loss: 0.3309926688671112
Validation loss: 1.788660475002822

Epoch: 6| Step: 13
Training loss: 0.34207895398139954
Validation loss: 1.8079135815302532

Epoch: 241| Step: 0
Training loss: 0.653933048248291
Validation loss: 1.80057345667193

Epoch: 6| Step: 1
Training loss: 0.45381247997283936
Validation loss: 1.818685846944009

Epoch: 6| Step: 2
Training loss: 0.25393134355545044
Validation loss: 1.8126056425033077

Epoch: 6| Step: 3
Training loss: 0.6213040351867676
Validation loss: 1.8274155265541487

Epoch: 6| Step: 4
Training loss: 0.5401037335395813
Validation loss: 1.7765569199797928

Epoch: 6| Step: 5
Training loss: 0.25932225584983826
Validation loss: 1.7555496743930283

Epoch: 6| Step: 6
Training loss: 0.4884561002254486
Validation loss: 1.7732767789594588

Epoch: 6| Step: 7
Training loss: 0.5172485709190369
Validation loss: 1.7610594585377684

Epoch: 6| Step: 8
Training loss: 0.49847203493118286
Validation loss: 1.798319039806243

Epoch: 6| Step: 9
Training loss: 0.45189452171325684
Validation loss: 1.7609835235021447

Epoch: 6| Step: 10
Training loss: 0.5451759099960327
Validation loss: 1.7726688295282342

Epoch: 6| Step: 11
Training loss: 0.48384952545166016
Validation loss: 1.796389820755169

Epoch: 6| Step: 12
Training loss: 0.5044951438903809
Validation loss: 1.7601761356476815

Epoch: 6| Step: 13
Training loss: 0.39177796244621277
Validation loss: 1.8007622124046407

Epoch: 242| Step: 0
Training loss: 0.4707038998603821
Validation loss: 1.8214576526354718

Epoch: 6| Step: 1
Training loss: 0.41974079608917236
Validation loss: 1.7979795189313992

Epoch: 6| Step: 2
Training loss: 0.40596693754196167
Validation loss: 1.7909031952581098

Epoch: 6| Step: 3
Training loss: 0.7867911458015442
Validation loss: 1.7705315556577457

Epoch: 6| Step: 4
Training loss: 0.29032203555107117
Validation loss: 1.7630947738565423

Epoch: 6| Step: 5
Training loss: 0.34798330068588257
Validation loss: 1.7719687531071324

Epoch: 6| Step: 6
Training loss: 0.5276393890380859
Validation loss: 1.76286228241459

Epoch: 6| Step: 7
Training loss: 0.278735876083374
Validation loss: 1.8023035269911571

Epoch: 6| Step: 8
Training loss: 0.6693419218063354
Validation loss: 1.769444836724189

Epoch: 6| Step: 9
Training loss: 0.47004735469818115
Validation loss: 1.7567594410270773

Epoch: 6| Step: 10
Training loss: 0.3635188639163971
Validation loss: 1.7359248668916765

Epoch: 6| Step: 11
Training loss: 0.6175535917282104
Validation loss: 1.7312763929367065

Epoch: 6| Step: 12
Training loss: 0.3269882798194885
Validation loss: 1.7130578589695755

Epoch: 6| Step: 13
Training loss: 0.5935600399971008
Validation loss: 1.7457727988560994

Epoch: 243| Step: 0
Training loss: 0.39146849513053894
Validation loss: 1.7554714231080906

Epoch: 6| Step: 1
Training loss: 0.8180617690086365
Validation loss: 1.7685333939008816

Epoch: 6| Step: 2
Training loss: 0.4180612862110138
Validation loss: 1.7314140437751688

Epoch: 6| Step: 3
Training loss: 0.7248235940933228
Validation loss: 1.736691608223864

Epoch: 6| Step: 4
Training loss: 0.35395634174346924
Validation loss: 1.7878556764254006

Epoch: 6| Step: 5
Training loss: 0.46586745977401733
Validation loss: 1.8438538146275345

Epoch: 6| Step: 6
Training loss: 0.4632396399974823
Validation loss: 1.8353108565012615

Epoch: 6| Step: 7
Training loss: 0.5553939342498779
Validation loss: 1.8478274678671232

Epoch: 6| Step: 8
Training loss: 0.5658547878265381
Validation loss: 1.814722671303698

Epoch: 6| Step: 9
Training loss: 0.3697066307067871
Validation loss: 1.8126646229015884

Epoch: 6| Step: 10
Training loss: 0.30812448263168335
Validation loss: 1.8371038321525819

Epoch: 6| Step: 11
Training loss: 0.39657357335090637
Validation loss: 1.8457751684291388

Epoch: 6| Step: 12
Training loss: 0.47302955389022827
Validation loss: 1.869203422659187

Epoch: 6| Step: 13
Training loss: 0.5178235769271851
Validation loss: 1.8598926759535266

Epoch: 244| Step: 0
Training loss: 0.34454336762428284
Validation loss: 1.8450034574795795

Epoch: 6| Step: 1
Training loss: 0.48829519748687744
Validation loss: 1.7877553727037163

Epoch: 6| Step: 2
Training loss: 0.480161190032959
Validation loss: 1.7950718223407705

Epoch: 6| Step: 3
Training loss: 0.258239209651947
Validation loss: 1.8080689631482607

Epoch: 6| Step: 4
Training loss: 0.3958706259727478
Validation loss: 1.8053725156732785

Epoch: 6| Step: 5
Training loss: 0.5928553938865662
Validation loss: 1.7982295623389624

Epoch: 6| Step: 6
Training loss: 0.6759133338928223
Validation loss: 1.744419854174378

Epoch: 6| Step: 7
Training loss: 0.40292730927467346
Validation loss: 1.766091710777693

Epoch: 6| Step: 8
Training loss: 0.31968480348587036
Validation loss: 1.763270261467144

Epoch: 6| Step: 9
Training loss: 0.4889376163482666
Validation loss: 1.7864006014280422

Epoch: 6| Step: 10
Training loss: 0.37434089183807373
Validation loss: 1.7740458237227572

Epoch: 6| Step: 11
Training loss: 0.6647155284881592
Validation loss: 1.7484530646313903

Epoch: 6| Step: 12
Training loss: 0.49591830372810364
Validation loss: 1.7377048602668188

Epoch: 6| Step: 13
Training loss: 0.7604287266731262
Validation loss: 1.7617362481291576

Epoch: 245| Step: 0
Training loss: 0.4123374819755554
Validation loss: 1.8059030758437289

Epoch: 6| Step: 1
Training loss: 0.3862084448337555
Validation loss: 1.7881709119325042

Epoch: 6| Step: 2
Training loss: 0.5965004563331604
Validation loss: 1.7946518851864723

Epoch: 6| Step: 3
Training loss: 0.6053139567375183
Validation loss: 1.7598448081683087

Epoch: 6| Step: 4
Training loss: 0.42921847105026245
Validation loss: 1.7690991291435816

Epoch: 6| Step: 5
Training loss: 0.23824018239974976
Validation loss: 1.739887350349016

Epoch: 6| Step: 6
Training loss: 0.28744643926620483
Validation loss: 1.7744856765193324

Epoch: 6| Step: 7
Training loss: 0.5231990814208984
Validation loss: 1.817780565190059

Epoch: 6| Step: 8
Training loss: 0.4934080243110657
Validation loss: 1.8203364764490435

Epoch: 6| Step: 9
Training loss: 0.4883040189743042
Validation loss: 1.803136255151482

Epoch: 6| Step: 10
Training loss: 0.4438724219799042
Validation loss: 1.761396445253844

Epoch: 6| Step: 11
Training loss: 0.5472867488861084
Validation loss: 1.7805895933540918

Epoch: 6| Step: 12
Training loss: 0.6616076231002808
Validation loss: 1.7599840433366838

Epoch: 6| Step: 13
Training loss: 1.0451806783676147
Validation loss: 1.7807336494486818

Epoch: 246| Step: 0
Training loss: 0.6283968687057495
Validation loss: 1.7742318427690895

Epoch: 6| Step: 1
Training loss: 0.3461996912956238
Validation loss: 1.7673101143170429

Epoch: 6| Step: 2
Training loss: 0.47081151604652405
Validation loss: 1.7774578781538113

Epoch: 6| Step: 3
Training loss: 0.5015020966529846
Validation loss: 1.7761739953871696

Epoch: 6| Step: 4
Training loss: 0.6102045774459839
Validation loss: 1.7772526177026893

Epoch: 6| Step: 5
Training loss: 0.3241034746170044
Validation loss: 1.798847463823134

Epoch: 6| Step: 6
Training loss: 0.389443963766098
Validation loss: 1.8378856899917766

Epoch: 6| Step: 7
Training loss: 0.7523086667060852
Validation loss: 1.802681653730331

Epoch: 6| Step: 8
Training loss: 0.7441772222518921
Validation loss: 1.820262320580021

Epoch: 6| Step: 9
Training loss: 0.17184004187583923
Validation loss: 1.8212621570915304

Epoch: 6| Step: 10
Training loss: 0.439633309841156
Validation loss: 1.8150696344273065

Epoch: 6| Step: 11
Training loss: 0.47180813550949097
Validation loss: 1.7603559981110275

Epoch: 6| Step: 12
Training loss: 0.35680150985717773
Validation loss: 1.7377243554720314

Epoch: 6| Step: 13
Training loss: 0.219737708568573
Validation loss: 1.7316968082099833

Epoch: 247| Step: 0
Training loss: 0.47669535875320435
Validation loss: 1.7276066272489485

Epoch: 6| Step: 1
Training loss: 0.5653345584869385
Validation loss: 1.7414881901074482

Epoch: 6| Step: 2
Training loss: 0.7522597312927246
Validation loss: 1.7072930874363068

Epoch: 6| Step: 3
Training loss: 0.29506170749664307
Validation loss: 1.7405883599353094

Epoch: 6| Step: 4
Training loss: 0.21752619743347168
Validation loss: 1.7112731677229687

Epoch: 6| Step: 5
Training loss: 0.5677260160446167
Validation loss: 1.7048008672652706

Epoch: 6| Step: 6
Training loss: 0.3347472548484802
Validation loss: 1.7366000888168172

Epoch: 6| Step: 7
Training loss: 0.43483996391296387
Validation loss: 1.745192236797784

Epoch: 6| Step: 8
Training loss: 0.4158288240432739
Validation loss: 1.7394236928673201

Epoch: 6| Step: 9
Training loss: 0.31814858317375183
Validation loss: 1.7618411048766105

Epoch: 6| Step: 10
Training loss: 0.4492516815662384
Validation loss: 1.7576271052001624

Epoch: 6| Step: 11
Training loss: 0.3144475221633911
Validation loss: 1.7399020810281076

Epoch: 6| Step: 12
Training loss: 0.3557747006416321
Validation loss: 1.7616084121888684

Epoch: 6| Step: 13
Training loss: 0.45302343368530273
Validation loss: 1.760340593194449

Epoch: 248| Step: 0
Training loss: 0.33895808458328247
Validation loss: 1.773698942635649

Epoch: 6| Step: 1
Training loss: 0.6021402478218079
Validation loss: 1.7763198447483841

Epoch: 6| Step: 2
Training loss: 0.36150839924812317
Validation loss: 1.7687183503181703

Epoch: 6| Step: 3
Training loss: 0.5847846269607544
Validation loss: 1.7684027200104089

Epoch: 6| Step: 4
Training loss: 0.47299546003341675
Validation loss: 1.766608074147214

Epoch: 6| Step: 5
Training loss: 0.32466426491737366
Validation loss: 1.7190046079697148

Epoch: 6| Step: 6
Training loss: 0.37542247772216797
Validation loss: 1.7016534049023864

Epoch: 6| Step: 7
Training loss: 0.4384165406227112
Validation loss: 1.7292423286745626

Epoch: 6| Step: 8
Training loss: 0.2858492434024811
Validation loss: 1.7022625835992957

Epoch: 6| Step: 9
Training loss: 0.24421507120132446
Validation loss: 1.6982303332257014

Epoch: 6| Step: 10
Training loss: 0.5261532068252563
Validation loss: 1.7151959698687318

Epoch: 6| Step: 11
Training loss: 0.5332443714141846
Validation loss: 1.7412717714104602

Epoch: 6| Step: 12
Training loss: 0.5211113691329956
Validation loss: 1.7647395877427952

Epoch: 6| Step: 13
Training loss: 0.27297279238700867
Validation loss: 1.7691313053971978

Epoch: 249| Step: 0
Training loss: 0.5494123697280884
Validation loss: 1.7640438656653128

Epoch: 6| Step: 1
Training loss: 0.32648366689682007
Validation loss: 1.8097214788518927

Epoch: 6| Step: 2
Training loss: 0.34374284744262695
Validation loss: 1.7939899057470343

Epoch: 6| Step: 3
Training loss: 0.5423531532287598
Validation loss: 1.8292436907368321

Epoch: 6| Step: 4
Training loss: 0.6301456689834595
Validation loss: 1.8352162017617175

Epoch: 6| Step: 5
Training loss: 0.6804803013801575
Validation loss: 1.8288973403233353

Epoch: 6| Step: 6
Training loss: 0.4415559768676758
Validation loss: 1.80080916548288

Epoch: 6| Step: 7
Training loss: 0.45631417632102966
Validation loss: 1.7594665840107908

Epoch: 6| Step: 8
Training loss: 0.4297722578048706
Validation loss: 1.7432269191229215

Epoch: 6| Step: 9
Training loss: 0.44566139578819275
Validation loss: 1.7232557291625648

Epoch: 6| Step: 10
Training loss: 0.33220112323760986
Validation loss: 1.7275363681136922

Epoch: 6| Step: 11
Training loss: 0.3638867735862732
Validation loss: 1.7533684610038676

Epoch: 6| Step: 12
Training loss: 0.4276297390460968
Validation loss: 1.7538111978961575

Epoch: 6| Step: 13
Training loss: 0.4857114553451538
Validation loss: 1.7529304283921436

Epoch: 250| Step: 0
Training loss: 0.4359254837036133
Validation loss: 1.7518486143440328

Epoch: 6| Step: 1
Training loss: 0.5544933676719666
Validation loss: 1.7347845903006933

Epoch: 6| Step: 2
Training loss: 0.4969474971294403
Validation loss: 1.7257144444732255

Epoch: 6| Step: 3
Training loss: 0.43753743171691895
Validation loss: 1.7222647743840371

Epoch: 6| Step: 4
Training loss: 0.38358044624328613
Validation loss: 1.7663381945702337

Epoch: 6| Step: 5
Training loss: 0.40391698479652405
Validation loss: 1.7038236074550177

Epoch: 6| Step: 6
Training loss: 0.35219043493270874
Validation loss: 1.720837914815513

Epoch: 6| Step: 7
Training loss: 0.4359102249145508
Validation loss: 1.7649759233638804

Epoch: 6| Step: 8
Training loss: 0.3648788034915924
Validation loss: 1.7389540454392791

Epoch: 6| Step: 9
Training loss: 0.36273497343063354
Validation loss: 1.78351241542447

Epoch: 6| Step: 10
Training loss: 0.5015731453895569
Validation loss: 1.7786854120992845

Epoch: 6| Step: 11
Training loss: 0.32816052436828613
Validation loss: 1.7903677840386667

Epoch: 6| Step: 12
Training loss: 0.25463107228279114
Validation loss: 1.7796143780472458

Epoch: 6| Step: 13
Training loss: 0.4160168468952179
Validation loss: 1.766954836025033

Epoch: 251| Step: 0
Training loss: 0.3042752742767334
Validation loss: 1.7572416631124352

Epoch: 6| Step: 1
Training loss: 0.32846197485923767
Validation loss: 1.737572666137449

Epoch: 6| Step: 2
Training loss: 0.3912978768348694
Validation loss: 1.7689740580897177

Epoch: 6| Step: 3
Training loss: 0.5702903270721436
Validation loss: 1.7105200713680637

Epoch: 6| Step: 4
Training loss: 0.3181018829345703
Validation loss: 1.7173299693292188

Epoch: 6| Step: 5
Training loss: 0.4116612374782562
Validation loss: 1.729493527002232

Epoch: 6| Step: 6
Training loss: 0.38331812620162964
Validation loss: 1.698137926798995

Epoch: 6| Step: 7
Training loss: 0.5209963321685791
Validation loss: 1.7125001799675725

Epoch: 6| Step: 8
Training loss: 0.3676467537879944
Validation loss: 1.711100047634494

Epoch: 6| Step: 9
Training loss: 0.42813318967819214
Validation loss: 1.7257247996586624

Epoch: 6| Step: 10
Training loss: 0.32141801714897156
Validation loss: 1.7131640539374402

Epoch: 6| Step: 11
Training loss: 0.5239506959915161
Validation loss: 1.7304527169914656

Epoch: 6| Step: 12
Training loss: 0.4810086488723755
Validation loss: 1.7543626959605882

Epoch: 6| Step: 13
Training loss: 0.21886099874973297
Validation loss: 1.724922530112728

Epoch: 252| Step: 0
Training loss: 0.400917649269104
Validation loss: 1.7100275165291243

Epoch: 6| Step: 1
Training loss: 0.28063130378723145
Validation loss: 1.6775968690072336

Epoch: 6| Step: 2
Training loss: 0.3386000096797943
Validation loss: 1.7092755468942786

Epoch: 6| Step: 3
Training loss: 0.1978689581155777
Validation loss: 1.7376882722300868

Epoch: 6| Step: 4
Training loss: 0.3314964175224304
Validation loss: 1.742810255737715

Epoch: 6| Step: 5
Training loss: 0.3878903388977051
Validation loss: 1.7289828215875933

Epoch: 6| Step: 6
Training loss: 0.614579975605011
Validation loss: 1.774677639366478

Epoch: 6| Step: 7
Training loss: 0.5298166275024414
Validation loss: 1.7271765996051092

Epoch: 6| Step: 8
Training loss: 0.24164935946464539
Validation loss: 1.7589146039819206

Epoch: 6| Step: 9
Training loss: 0.20850375294685364
Validation loss: 1.7665466454721266

Epoch: 6| Step: 10
Training loss: 0.6944093704223633
Validation loss: 1.7631117336211666

Epoch: 6| Step: 11
Training loss: 0.47531968355178833
Validation loss: 1.818770065102526

Epoch: 6| Step: 12
Training loss: 0.4374072551727295
Validation loss: 1.798612266458491

Epoch: 6| Step: 13
Training loss: 0.3518470227718353
Validation loss: 1.773588498433431

Epoch: 253| Step: 0
Training loss: 0.23493628203868866
Validation loss: 1.7178381899351716

Epoch: 6| Step: 1
Training loss: 0.42367854714393616
Validation loss: 1.7270387218844505

Epoch: 6| Step: 2
Training loss: 0.5013294219970703
Validation loss: 1.7229503264991186

Epoch: 6| Step: 3
Training loss: 0.5137150287628174
Validation loss: 1.718668863337527

Epoch: 6| Step: 4
Training loss: 0.6381361484527588
Validation loss: 1.7350891149172218

Epoch: 6| Step: 5
Training loss: 0.3416742980480194
Validation loss: 1.720382111046904

Epoch: 6| Step: 6
Training loss: 0.37465378642082214
Validation loss: 1.7443820161204184

Epoch: 6| Step: 7
Training loss: 0.5145074129104614
Validation loss: 1.7131739662539573

Epoch: 6| Step: 8
Training loss: 0.5221166014671326
Validation loss: 1.7177607244060886

Epoch: 6| Step: 9
Training loss: 0.3652348220348358
Validation loss: 1.7361360846027252

Epoch: 6| Step: 10
Training loss: 0.2647721469402313
Validation loss: 1.7611781499719108

Epoch: 6| Step: 11
Training loss: 0.4857195317745209
Validation loss: 1.7950437850849603

Epoch: 6| Step: 12
Training loss: 0.388160765171051
Validation loss: 1.7499835311725576

Epoch: 6| Step: 13
Training loss: 0.3156850337982178
Validation loss: 1.7266901475127026

Epoch: 254| Step: 0
Training loss: 0.23483239114284515
Validation loss: 1.7714827791337044

Epoch: 6| Step: 1
Training loss: 0.5052361488342285
Validation loss: 1.6969541272809427

Epoch: 6| Step: 2
Training loss: 0.4894002676010132
Validation loss: 1.7326946399545158

Epoch: 6| Step: 3
Training loss: 0.43112796545028687
Validation loss: 1.7215843815957346

Epoch: 6| Step: 4
Training loss: 0.5549699664115906
Validation loss: 1.7285531220897552

Epoch: 6| Step: 5
Training loss: 0.4046933650970459
Validation loss: 1.7336877020456458

Epoch: 6| Step: 6
Training loss: 0.254565954208374
Validation loss: 1.7422621198879775

Epoch: 6| Step: 7
Training loss: 0.4231971502304077
Validation loss: 1.748529254749257

Epoch: 6| Step: 8
Training loss: 0.47949522733688354
Validation loss: 1.7361731759963497

Epoch: 6| Step: 9
Training loss: 0.39929625391960144
Validation loss: 1.7673088055784985

Epoch: 6| Step: 10
Training loss: 0.43812960386276245
Validation loss: 1.7444381636957969

Epoch: 6| Step: 11
Training loss: 0.21300257742404938
Validation loss: 1.7621101102521342

Epoch: 6| Step: 12
Training loss: 0.2134818732738495
Validation loss: 1.7194963988437448

Epoch: 6| Step: 13
Training loss: 0.3707371950149536
Validation loss: 1.7342747001237766

Epoch: 255| Step: 0
Training loss: 0.6696550846099854
Validation loss: 1.7618234836927025

Epoch: 6| Step: 1
Training loss: 0.28422510623931885
Validation loss: 1.7493598666242374

Epoch: 6| Step: 2
Training loss: 0.5964149236679077
Validation loss: 1.747455978906283

Epoch: 6| Step: 3
Training loss: 0.26538515090942383
Validation loss: 1.7392725624063963

Epoch: 6| Step: 4
Training loss: 0.3386991322040558
Validation loss: 1.743976495599234

Epoch: 6| Step: 5
Training loss: 0.19685447216033936
Validation loss: 1.72970232143197

Epoch: 6| Step: 6
Training loss: 0.35732531547546387
Validation loss: 1.725686752667991

Epoch: 6| Step: 7
Training loss: 0.4641323685646057
Validation loss: 1.7468042322384414

Epoch: 6| Step: 8
Training loss: 0.5464682579040527
Validation loss: 1.744305774729739

Epoch: 6| Step: 9
Training loss: 0.3584672212600708
Validation loss: 1.7939703003052743

Epoch: 6| Step: 10
Training loss: 0.45961493253707886
Validation loss: 1.8073581431501655

Epoch: 6| Step: 11
Training loss: 0.5650466680526733
Validation loss: 1.8091792611665622

Epoch: 6| Step: 12
Training loss: 0.38048532605171204
Validation loss: 1.7778684631470711

Epoch: 6| Step: 13
Training loss: 0.3864498734474182
Validation loss: 1.7381784736469228

Epoch: 256| Step: 0
Training loss: 0.4199233055114746
Validation loss: 1.7232125382269583

Epoch: 6| Step: 1
Training loss: 0.5696449279785156
Validation loss: 1.6902357685950495

Epoch: 6| Step: 2
Training loss: 0.3485400080680847
Validation loss: 1.7474709608221566

Epoch: 6| Step: 3
Training loss: 0.3267332911491394
Validation loss: 1.711417830118569

Epoch: 6| Step: 4
Training loss: 0.31528663635253906
Validation loss: 1.6924809832726755

Epoch: 6| Step: 5
Training loss: 0.4070568084716797
Validation loss: 1.6824828194033714

Epoch: 6| Step: 6
Training loss: 0.3845101594924927
Validation loss: 1.6512245183349938

Epoch: 6| Step: 7
Training loss: 0.35096344351768494
Validation loss: 1.6733238543233564

Epoch: 6| Step: 8
Training loss: 0.4456416666507721
Validation loss: 1.6535056944816344

Epoch: 6| Step: 9
Training loss: 0.42411118745803833
Validation loss: 1.694564414280717

Epoch: 6| Step: 10
Training loss: 0.35093894600868225
Validation loss: 1.6745619209863807

Epoch: 6| Step: 11
Training loss: 0.30622971057891846
Validation loss: 1.6558888471254738

Epoch: 6| Step: 12
Training loss: 0.4141451418399811
Validation loss: 1.6755578466641006

Epoch: 6| Step: 13
Training loss: 0.13527314364910126
Validation loss: 1.6669581897797123

Epoch: 257| Step: 0
Training loss: 0.43970873951911926
Validation loss: 1.671205944912408

Epoch: 6| Step: 1
Training loss: 0.3264671862125397
Validation loss: 1.6547847114583498

Epoch: 6| Step: 2
Training loss: 0.44262513518333435
Validation loss: 1.6924648156730078

Epoch: 6| Step: 3
Training loss: 0.3720465898513794
Validation loss: 1.6787346832213863

Epoch: 6| Step: 4
Training loss: 0.23098710179328918
Validation loss: 1.6863247527871081

Epoch: 6| Step: 5
Training loss: 0.36666277050971985
Validation loss: 1.674485691132084

Epoch: 6| Step: 6
Training loss: 0.4071881175041199
Validation loss: 1.7112311060710619

Epoch: 6| Step: 7
Training loss: 0.26329702138900757
Validation loss: 1.715982130778733

Epoch: 6| Step: 8
Training loss: 0.7837576270103455
Validation loss: 1.6925073695439163

Epoch: 6| Step: 9
Training loss: 0.25241798162460327
Validation loss: 1.7106594001093218

Epoch: 6| Step: 10
Training loss: 0.5335050225257874
Validation loss: 1.7001943293438162

Epoch: 6| Step: 11
Training loss: 0.22077670693397522
Validation loss: 1.676036423252475

Epoch: 6| Step: 12
Training loss: 0.40657275915145874
Validation loss: 1.7128821624222623

Epoch: 6| Step: 13
Training loss: 0.3804846405982971
Validation loss: 1.696923025192753

Epoch: 258| Step: 0
Training loss: 0.2726784348487854
Validation loss: 1.7153979411689184

Epoch: 6| Step: 1
Training loss: 0.36902517080307007
Validation loss: 1.7054393163291357

Epoch: 6| Step: 2
Training loss: 0.21132507920265198
Validation loss: 1.7096228727730371

Epoch: 6| Step: 3
Training loss: 0.24115686118602753
Validation loss: 1.7034141337999733

Epoch: 6| Step: 4
Training loss: 0.5215818881988525
Validation loss: 1.7150267311321792

Epoch: 6| Step: 5
Training loss: 0.268067866563797
Validation loss: 1.7092635695652296

Epoch: 6| Step: 6
Training loss: 0.5500485897064209
Validation loss: 1.6803324658383605

Epoch: 6| Step: 7
Training loss: 0.4809844493865967
Validation loss: 1.6758180664431663

Epoch: 6| Step: 8
Training loss: 0.2966010570526123
Validation loss: 1.6767989268866919

Epoch: 6| Step: 9
Training loss: 0.296084463596344
Validation loss: 1.6732641061147053

Epoch: 6| Step: 10
Training loss: 0.353341668844223
Validation loss: 1.6915200371896066

Epoch: 6| Step: 11
Training loss: 0.3193676471710205
Validation loss: 1.6739497684663343

Epoch: 6| Step: 12
Training loss: 0.4413588047027588
Validation loss: 1.676022619329473

Epoch: 6| Step: 13
Training loss: 0.5811307430267334
Validation loss: 1.6752406281809653

Epoch: 259| Step: 0
Training loss: 0.4167386591434479
Validation loss: 1.6479772944604196

Epoch: 6| Step: 1
Training loss: 0.5149943828582764
Validation loss: 1.705898356694047

Epoch: 6| Step: 2
Training loss: 0.29109859466552734
Validation loss: 1.6834195172914894

Epoch: 6| Step: 3
Training loss: 0.3954809308052063
Validation loss: 1.6711417487872544

Epoch: 6| Step: 4
Training loss: 0.2522946000099182
Validation loss: 1.6366899039155693

Epoch: 6| Step: 5
Training loss: 0.568037748336792
Validation loss: 1.704336081781695

Epoch: 6| Step: 6
Training loss: 0.4086056351661682
Validation loss: 1.727223701374505

Epoch: 6| Step: 7
Training loss: 0.5158140659332275
Validation loss: 1.7959456187422558

Epoch: 6| Step: 8
Training loss: 0.44846993684768677
Validation loss: 1.7875207880491852

Epoch: 6| Step: 9
Training loss: 0.35793375968933105
Validation loss: 1.752827803293864

Epoch: 6| Step: 10
Training loss: 0.5133464336395264
Validation loss: 1.7327372745801044

Epoch: 6| Step: 11
Training loss: 0.4470553696155548
Validation loss: 1.704335654935529

Epoch: 6| Step: 12
Training loss: 0.22710195183753967
Validation loss: 1.6622158968320457

Epoch: 6| Step: 13
Training loss: 0.3266300559043884
Validation loss: 1.71692406874831

Epoch: 260| Step: 0
Training loss: 0.3316690921783447
Validation loss: 1.699812130261493

Epoch: 6| Step: 1
Training loss: 0.7081034183502197
Validation loss: 1.726056069456121

Epoch: 6| Step: 2
Training loss: 0.25174570083618164
Validation loss: 1.7029189345657185

Epoch: 6| Step: 3
Training loss: 0.34541743993759155
Validation loss: 1.6464012143432454

Epoch: 6| Step: 4
Training loss: 0.5280773639678955
Validation loss: 1.6649372000848093

Epoch: 6| Step: 5
Training loss: 0.4889603555202484
Validation loss: 1.660413166528107

Epoch: 6| Step: 6
Training loss: 0.3396061062812805
Validation loss: 1.6658099992300874

Epoch: 6| Step: 7
Training loss: 0.3420991599559784
Validation loss: 1.68216521252868

Epoch: 6| Step: 8
Training loss: 0.4849567413330078
Validation loss: 1.6641254143048358

Epoch: 6| Step: 9
Training loss: 0.3047272861003876
Validation loss: 1.7089050226314093

Epoch: 6| Step: 10
Training loss: 0.3652958869934082
Validation loss: 1.6540708407278983

Epoch: 6| Step: 11
Training loss: 0.4508764147758484
Validation loss: 1.6452555464160057

Epoch: 6| Step: 12
Training loss: 0.33274146914482117
Validation loss: 1.7008719969821233

Epoch: 6| Step: 13
Training loss: 0.2326156497001648
Validation loss: 1.6618758657927155

Epoch: 261| Step: 0
Training loss: 0.265048086643219
Validation loss: 1.7070339559226908

Epoch: 6| Step: 1
Training loss: 0.5039910674095154
Validation loss: 1.6736815808921732

Epoch: 6| Step: 2
Training loss: 0.5108842849731445
Validation loss: 1.701772770574016

Epoch: 6| Step: 3
Training loss: 0.387243390083313
Validation loss: 1.7125806539289412

Epoch: 6| Step: 4
Training loss: 0.18965335190296173
Validation loss: 1.7240311638001473

Epoch: 6| Step: 5
Training loss: 0.631289005279541
Validation loss: 1.7331234293599282

Epoch: 6| Step: 6
Training loss: 0.26773083209991455
Validation loss: 1.7173337192945584

Epoch: 6| Step: 7
Training loss: 0.316062867641449
Validation loss: 1.7508179244174753

Epoch: 6| Step: 8
Training loss: 0.35016095638275146
Validation loss: 1.7686915416871347

Epoch: 6| Step: 9
Training loss: 0.30171167850494385
Validation loss: 1.7132072038547967

Epoch: 6| Step: 10
Training loss: 0.43886035680770874
Validation loss: 1.7553311496652582

Epoch: 6| Step: 11
Training loss: 0.16716407239437103
Validation loss: 1.7627669585648404

Epoch: 6| Step: 12
Training loss: 0.4576692581176758
Validation loss: 1.7422663729677919

Epoch: 6| Step: 13
Training loss: 0.25008541345596313
Validation loss: 1.7555343950948408

Epoch: 262| Step: 0
Training loss: 0.3113808333873749
Validation loss: 1.7121379952276907

Epoch: 6| Step: 1
Training loss: 0.3120422959327698
Validation loss: 1.7352912989995812

Epoch: 6| Step: 2
Training loss: 0.41412273049354553
Validation loss: 1.7223737829474992

Epoch: 6| Step: 3
Training loss: 0.29296159744262695
Validation loss: 1.672997764361802

Epoch: 6| Step: 4
Training loss: 0.6375813484191895
Validation loss: 1.6929918386602913

Epoch: 6| Step: 5
Training loss: 0.21150130033493042
Validation loss: 1.6875943676117928

Epoch: 6| Step: 6
Training loss: 0.3865385055541992
Validation loss: 1.6964070104783582

Epoch: 6| Step: 7
Training loss: 0.3008832633495331
Validation loss: 1.7097008183438291

Epoch: 6| Step: 8
Training loss: 0.32511207461357117
Validation loss: 1.6960356921278021

Epoch: 6| Step: 9
Training loss: 0.37573322653770447
Validation loss: 1.6843864981846144

Epoch: 6| Step: 10
Training loss: 0.3277343511581421
Validation loss: 1.6911502320279357

Epoch: 6| Step: 11
Training loss: 0.23591606318950653
Validation loss: 1.670927647621401

Epoch: 6| Step: 12
Training loss: 0.411998450756073
Validation loss: 1.6754874811377576

Epoch: 6| Step: 13
Training loss: 0.1080753281712532
Validation loss: 1.6911898370712035

Epoch: 263| Step: 0
Training loss: 0.3621509075164795
Validation loss: 1.7022951572172103

Epoch: 6| Step: 1
Training loss: 0.4773677587509155
Validation loss: 1.7166565977117068

Epoch: 6| Step: 2
Training loss: 0.4139430522918701
Validation loss: 1.7217895753922001

Epoch: 6| Step: 3
Training loss: 0.4667056202888489
Validation loss: 1.6996526231047928

Epoch: 6| Step: 4
Training loss: 0.6133164167404175
Validation loss: 1.7172110490901495

Epoch: 6| Step: 5
Training loss: 0.21018347144126892
Validation loss: 1.7372048080608409

Epoch: 6| Step: 6
Training loss: 0.3248264193534851
Validation loss: 1.7290905348716243

Epoch: 6| Step: 7
Training loss: 0.2775941789150238
Validation loss: 1.7468940237516999

Epoch: 6| Step: 8
Training loss: 0.21952864527702332
Validation loss: 1.7190147279411234

Epoch: 6| Step: 9
Training loss: 0.30037420988082886
Validation loss: 1.690445589762862

Epoch: 6| Step: 10
Training loss: 0.2766290605068207
Validation loss: 1.7099052885527253

Epoch: 6| Step: 11
Training loss: 0.2287604957818985
Validation loss: 1.6985681056976318

Epoch: 6| Step: 12
Training loss: 0.27212244272232056
Validation loss: 1.712263725137198

Epoch: 6| Step: 13
Training loss: 0.5442850589752197
Validation loss: 1.7182371808636574

Epoch: 264| Step: 0
Training loss: 0.381683349609375
Validation loss: 1.7212759512726978

Epoch: 6| Step: 1
Training loss: 0.424866259098053
Validation loss: 1.721594351594166

Epoch: 6| Step: 2
Training loss: 0.3327062726020813
Validation loss: 1.7293745522857995

Epoch: 6| Step: 3
Training loss: 0.23859238624572754
Validation loss: 1.7056772529437978

Epoch: 6| Step: 4
Training loss: 0.40359824895858765
Validation loss: 1.705576467898584

Epoch: 6| Step: 5
Training loss: 0.29969102144241333
Validation loss: 1.7069847186406453

Epoch: 6| Step: 6
Training loss: 0.3155288100242615
Validation loss: 1.7047269626330304

Epoch: 6| Step: 7
Training loss: 0.5348132848739624
Validation loss: 1.7451859930510163

Epoch: 6| Step: 8
Training loss: 0.5180454850196838
Validation loss: 1.709606703891549

Epoch: 6| Step: 9
Training loss: 0.40294602513313293
Validation loss: 1.7162008516250118

Epoch: 6| Step: 10
Training loss: 0.48663294315338135
Validation loss: 1.6718747205631708

Epoch: 6| Step: 11
Training loss: 0.30324530601501465
Validation loss: 1.6682143647183654

Epoch: 6| Step: 12
Training loss: 0.2631826400756836
Validation loss: 1.689301436947238

Epoch: 6| Step: 13
Training loss: 0.29683855175971985
Validation loss: 1.6705166652638426

Epoch: 265| Step: 0
Training loss: 0.3476274609565735
Validation loss: 1.701095204199514

Epoch: 6| Step: 1
Training loss: 0.25712481141090393
Validation loss: 1.6977404240638978

Epoch: 6| Step: 2
Training loss: 0.3682566285133362
Validation loss: 1.6947442344439927

Epoch: 6| Step: 3
Training loss: 0.3933333158493042
Validation loss: 1.6894308072264477

Epoch: 6| Step: 4
Training loss: 0.3237374424934387
Validation loss: 1.7048207136892504

Epoch: 6| Step: 5
Training loss: 0.40603315830230713
Validation loss: 1.6969143203509751

Epoch: 6| Step: 6
Training loss: 0.2340678572654724
Validation loss: 1.7370345746317217

Epoch: 6| Step: 7
Training loss: 0.4409465193748474
Validation loss: 1.7306077659771006

Epoch: 6| Step: 8
Training loss: 0.3393629491329193
Validation loss: 1.707541004303963

Epoch: 6| Step: 9
Training loss: 0.40619832277297974
Validation loss: 1.744138022904755

Epoch: 6| Step: 10
Training loss: 0.1941733956336975
Validation loss: 1.7441911787115119

Epoch: 6| Step: 11
Training loss: 0.49641168117523193
Validation loss: 1.7651452659278788

Epoch: 6| Step: 12
Training loss: 0.3344036340713501
Validation loss: 1.730503269421157

Epoch: 6| Step: 13
Training loss: 0.5915532112121582
Validation loss: 1.7329842544371081

Epoch: 266| Step: 0
Training loss: 0.22739773988723755
Validation loss: 1.722736475288227

Epoch: 6| Step: 1
Training loss: 0.49815917015075684
Validation loss: 1.7583919609746625

Epoch: 6| Step: 2
Training loss: 0.18719610571861267
Validation loss: 1.7341252065473987

Epoch: 6| Step: 3
Training loss: 0.32563596963882446
Validation loss: 1.73380155973537

Epoch: 6| Step: 4
Training loss: 0.34201011061668396
Validation loss: 1.7320693987672047

Epoch: 6| Step: 5
Training loss: 0.396695613861084
Validation loss: 1.7235277673249603

Epoch: 6| Step: 6
Training loss: 0.2839466333389282
Validation loss: 1.7412376160262732

Epoch: 6| Step: 7
Training loss: 0.24411463737487793
Validation loss: 1.7664588292439778

Epoch: 6| Step: 8
Training loss: 0.49047014117240906
Validation loss: 1.7440197262712704

Epoch: 6| Step: 9
Training loss: 0.5404263138771057
Validation loss: 1.72855959656418

Epoch: 6| Step: 10
Training loss: 0.24453327059745789
Validation loss: 1.7497374780716435

Epoch: 6| Step: 11
Training loss: 0.4745326042175293
Validation loss: 1.6987029826769264

Epoch: 6| Step: 12
Training loss: 0.1831929087638855
Validation loss: 1.7083024645364413

Epoch: 6| Step: 13
Training loss: 0.4409624934196472
Validation loss: 1.722625732421875

Epoch: 267| Step: 0
Training loss: 0.42980706691741943
Validation loss: 1.6948927525551087

Epoch: 6| Step: 1
Training loss: 0.4116159975528717
Validation loss: 1.704160085288427

Epoch: 6| Step: 2
Training loss: 0.3275339603424072
Validation loss: 1.6776555161322317

Epoch: 6| Step: 3
Training loss: 0.18440310657024384
Validation loss: 1.6641460144391624

Epoch: 6| Step: 4
Training loss: 0.4168562591075897
Validation loss: 1.7135411385566957

Epoch: 6| Step: 5
Training loss: 0.511512041091919
Validation loss: 1.6944933527259416

Epoch: 6| Step: 6
Training loss: 0.31248193979263306
Validation loss: 1.6550325514167867

Epoch: 6| Step: 7
Training loss: 0.2044488787651062
Validation loss: 1.6677014468818583

Epoch: 6| Step: 8
Training loss: 0.5623834729194641
Validation loss: 1.659966867457154

Epoch: 6| Step: 9
Training loss: 0.3277743458747864
Validation loss: 1.6503765083128406

Epoch: 6| Step: 10
Training loss: 0.33019840717315674
Validation loss: 1.6488468262457079

Epoch: 6| Step: 11
Training loss: 0.39005401730537415
Validation loss: 1.6929690171313543

Epoch: 6| Step: 12
Training loss: 0.2375073879957199
Validation loss: 1.6919932826872794

Epoch: 6| Step: 13
Training loss: 0.3941572904586792
Validation loss: 1.6988036350537372

Epoch: 268| Step: 0
Training loss: 0.24538463354110718
Validation loss: 1.6823327477260301

Epoch: 6| Step: 1
Training loss: 0.2877212464809418
Validation loss: 1.6883416752661429

Epoch: 6| Step: 2
Training loss: 0.6142417192459106
Validation loss: 1.7332401416635002

Epoch: 6| Step: 3
Training loss: 0.2406778335571289
Validation loss: 1.7398696868650374

Epoch: 6| Step: 4
Training loss: 0.3544468879699707
Validation loss: 1.7765422508280764

Epoch: 6| Step: 5
Training loss: 0.3962705135345459
Validation loss: 1.7546071262769802

Epoch: 6| Step: 6
Training loss: 0.30925536155700684
Validation loss: 1.735269082489834

Epoch: 6| Step: 7
Training loss: 0.23889002203941345
Validation loss: 1.6865818205700125

Epoch: 6| Step: 8
Training loss: 0.3638767600059509
Validation loss: 1.6384759064643615

Epoch: 6| Step: 9
Training loss: 0.21472573280334473
Validation loss: 1.6545627040247763

Epoch: 6| Step: 10
Training loss: 0.37722766399383545
Validation loss: 1.6735241143934187

Epoch: 6| Step: 11
Training loss: 0.7141742706298828
Validation loss: 1.7090565773748583

Epoch: 6| Step: 12
Training loss: 0.5436617136001587
Validation loss: 1.6889995759533298

Epoch: 6| Step: 13
Training loss: 0.4816892445087433
Validation loss: 1.6556158322159962

Epoch: 269| Step: 0
Training loss: 0.2884191870689392
Validation loss: 1.6665766392984698

Epoch: 6| Step: 1
Training loss: 0.3947070240974426
Validation loss: 1.6738557149005193

Epoch: 6| Step: 2
Training loss: 0.3726481795310974
Validation loss: 1.7017585333957468

Epoch: 6| Step: 3
Training loss: 0.4541935920715332
Validation loss: 1.710241715113322

Epoch: 6| Step: 4
Training loss: 0.366042822599411
Validation loss: 1.720783382333735

Epoch: 6| Step: 5
Training loss: 0.3528459668159485
Validation loss: 1.7208323388971307

Epoch: 6| Step: 6
Training loss: 0.36812838912010193
Validation loss: 1.7260695939422936

Epoch: 6| Step: 7
Training loss: 0.2580873668193817
Validation loss: 1.6768251695940573

Epoch: 6| Step: 8
Training loss: 0.519370436668396
Validation loss: 1.6790103950808126

Epoch: 6| Step: 9
Training loss: 0.47668689489364624
Validation loss: 1.685122807820638

Epoch: 6| Step: 10
Training loss: 0.3782974183559418
Validation loss: 1.7030675975225305

Epoch: 6| Step: 11
Training loss: 0.2311297357082367
Validation loss: 1.6859839834192747

Epoch: 6| Step: 12
Training loss: 0.3422170877456665
Validation loss: 1.667132632706755

Epoch: 6| Step: 13
Training loss: 0.3201518654823303
Validation loss: 1.663988923513761

Epoch: 270| Step: 0
Training loss: 0.4312099516391754
Validation loss: 1.7067957283348165

Epoch: 6| Step: 1
Training loss: 0.42245978116989136
Validation loss: 1.6942753689263457

Epoch: 6| Step: 2
Training loss: 0.2623854875564575
Validation loss: 1.6762948523285568

Epoch: 6| Step: 3
Training loss: 0.3510294258594513
Validation loss: 1.6870930989583333

Epoch: 6| Step: 4
Training loss: 0.4180479049682617
Validation loss: 1.693347574562155

Epoch: 6| Step: 5
Training loss: 0.2433435469865799
Validation loss: 1.685776593864605

Epoch: 6| Step: 6
Training loss: 0.5022340416908264
Validation loss: 1.7018500835664812

Epoch: 6| Step: 7
Training loss: 0.296916127204895
Validation loss: 1.6768493037069998

Epoch: 6| Step: 8
Training loss: 0.4320778250694275
Validation loss: 1.6619383904241747

Epoch: 6| Step: 9
Training loss: 0.21531635522842407
Validation loss: 1.6575274787923342

Epoch: 6| Step: 10
Training loss: 0.27974483370780945
Validation loss: 1.6853203978589786

Epoch: 6| Step: 11
Training loss: 0.31155240535736084
Validation loss: 1.670806493169518

Epoch: 6| Step: 12
Training loss: 0.2364022582769394
Validation loss: 1.6506618748429

Epoch: 6| Step: 13
Training loss: 0.4020371437072754
Validation loss: 1.6903439824299147

Epoch: 271| Step: 0
Training loss: 0.19343870878219604
Validation loss: 1.6724431617285616

Epoch: 6| Step: 1
Training loss: 0.25502216815948486
Validation loss: 1.6902456924479494

Epoch: 6| Step: 2
Training loss: 0.6320907473564148
Validation loss: 1.6631735909369685

Epoch: 6| Step: 3
Training loss: 0.25507497787475586
Validation loss: 1.6950030737025763

Epoch: 6| Step: 4
Training loss: 0.1813095360994339
Validation loss: 1.6592633467848583

Epoch: 6| Step: 5
Training loss: 0.3134916424751282
Validation loss: 1.7043503971510037

Epoch: 6| Step: 6
Training loss: 0.37826675176620483
Validation loss: 1.6626957949771677

Epoch: 6| Step: 7
Training loss: 0.2780638039112091
Validation loss: 1.6812546458295596

Epoch: 6| Step: 8
Training loss: 0.2982228994369507
Validation loss: 1.6419402143006683

Epoch: 6| Step: 9
Training loss: 0.4025212824344635
Validation loss: 1.6223294658045615

Epoch: 6| Step: 10
Training loss: 0.3401816487312317
Validation loss: 1.6389593283335369

Epoch: 6| Step: 11
Training loss: 0.31381094455718994
Validation loss: 1.6631931412604548

Epoch: 6| Step: 12
Training loss: 0.25714725255966187
Validation loss: 1.6478344689133346

Epoch: 6| Step: 13
Training loss: 0.41202035546302795
Validation loss: 1.63767453675629

Epoch: 272| Step: 0
Training loss: 0.3970392644405365
Validation loss: 1.618907977175969

Epoch: 6| Step: 1
Training loss: 0.3565364480018616
Validation loss: 1.6699763248043675

Epoch: 6| Step: 2
Training loss: 0.39628279209136963
Validation loss: 1.669600591864637

Epoch: 6| Step: 3
Training loss: 0.15454857051372528
Validation loss: 1.6724186340967815

Epoch: 6| Step: 4
Training loss: 0.3072972893714905
Validation loss: 1.701150381436912

Epoch: 6| Step: 5
Training loss: 0.3592481017112732
Validation loss: 1.6919455028349353

Epoch: 6| Step: 6
Training loss: 0.26516082882881165
Validation loss: 1.6983976300044725

Epoch: 6| Step: 7
Training loss: 0.45144137740135193
Validation loss: 1.690859338288666

Epoch: 6| Step: 8
Training loss: 0.3139135539531708
Validation loss: 1.654343230749971

Epoch: 6| Step: 9
Training loss: 0.3464822769165039
Validation loss: 1.66593587270347

Epoch: 6| Step: 10
Training loss: 0.3836284577846527
Validation loss: 1.6956821385250296

Epoch: 6| Step: 11
Training loss: 0.3559558391571045
Validation loss: 1.6594369885742024

Epoch: 6| Step: 12
Training loss: 0.33254027366638184
Validation loss: 1.66647574850308

Epoch: 6| Step: 13
Training loss: 0.26541242003440857
Validation loss: 1.6411215541183308

Epoch: 273| Step: 0
Training loss: 0.25981125235557556
Validation loss: 1.6403766473134358

Epoch: 6| Step: 1
Training loss: 0.17150314152240753
Validation loss: 1.6573376937579083

Epoch: 6| Step: 2
Training loss: 0.3808326721191406
Validation loss: 1.673880636051137

Epoch: 6| Step: 3
Training loss: 0.28798311948776245
Validation loss: 1.6697665786230436

Epoch: 6| Step: 4
Training loss: 0.2694125771522522
Validation loss: 1.6671378227972216

Epoch: 6| Step: 5
Training loss: 0.3652777075767517
Validation loss: 1.715320880695056

Epoch: 6| Step: 6
Training loss: 0.4578094482421875
Validation loss: 1.712214264818417

Epoch: 6| Step: 7
Training loss: 0.21858832240104675
Validation loss: 1.7135978949967252

Epoch: 6| Step: 8
Training loss: 0.24645736813545227
Validation loss: 1.7067267228198308

Epoch: 6| Step: 9
Training loss: 0.256409227848053
Validation loss: 1.7342453720749065

Epoch: 6| Step: 10
Training loss: 0.3339748978614807
Validation loss: 1.7452448234763196

Epoch: 6| Step: 11
Training loss: 0.3496938943862915
Validation loss: 1.7239814906991937

Epoch: 6| Step: 12
Training loss: 0.41101527214050293
Validation loss: 1.726229654845371

Epoch: 6| Step: 13
Training loss: 0.4171299934387207
Validation loss: 1.713634370475687

Epoch: 274| Step: 0
Training loss: 0.21713021397590637
Validation loss: 1.6903093066266788

Epoch: 6| Step: 1
Training loss: 0.3759368062019348
Validation loss: 1.6961873577487083

Epoch: 6| Step: 2
Training loss: 0.26187995076179504
Validation loss: 1.70078646239414

Epoch: 6| Step: 3
Training loss: 0.3374377191066742
Validation loss: 1.674011573996595

Epoch: 6| Step: 4
Training loss: 0.3450857996940613
Validation loss: 1.6955548999130086

Epoch: 6| Step: 5
Training loss: 0.21027210354804993
Validation loss: 1.658009688059489

Epoch: 6| Step: 6
Training loss: 0.27847233414649963
Validation loss: 1.6620777813337182

Epoch: 6| Step: 7
Training loss: 0.20429345965385437
Validation loss: 1.6469230190400155

Epoch: 6| Step: 8
Training loss: 0.375984787940979
Validation loss: 1.6103100289580643

Epoch: 6| Step: 9
Training loss: 0.4610025882720947
Validation loss: 1.6686602241249495

Epoch: 6| Step: 10
Training loss: 0.40866348147392273
Validation loss: 1.6240916482863887

Epoch: 6| Step: 11
Training loss: 0.23290517926216125
Validation loss: 1.6457130716693016

Epoch: 6| Step: 12
Training loss: 0.4015086889266968
Validation loss: 1.6085292587998092

Epoch: 6| Step: 13
Training loss: 0.3110441267490387
Validation loss: 1.6312388912323983

Epoch: 275| Step: 0
Training loss: 0.3224840760231018
Validation loss: 1.6232090239883752

Epoch: 6| Step: 1
Training loss: 0.260680615901947
Validation loss: 1.6341331812643236

Epoch: 6| Step: 2
Training loss: 0.24241085350513458
Validation loss: 1.62332324827871

Epoch: 6| Step: 3
Training loss: 0.31118300557136536
Validation loss: 1.6532698959432623

Epoch: 6| Step: 4
Training loss: 0.3968552350997925
Validation loss: 1.6377852104043449

Epoch: 6| Step: 5
Training loss: 0.34748223423957825
Validation loss: 1.6244523268873974

Epoch: 6| Step: 6
Training loss: 0.33263134956359863
Validation loss: 1.681952609810778

Epoch: 6| Step: 7
Training loss: 0.422973096370697
Validation loss: 1.6920329063169417

Epoch: 6| Step: 8
Training loss: 0.3614313006401062
Validation loss: 1.6784930895733576

Epoch: 6| Step: 9
Training loss: 0.45256784558296204
Validation loss: 1.671406695919652

Epoch: 6| Step: 10
Training loss: 0.3793089687824249
Validation loss: 1.6659264487604941

Epoch: 6| Step: 11
Training loss: 0.17921587824821472
Validation loss: 1.6901403909088464

Epoch: 6| Step: 12
Training loss: 0.4166441261768341
Validation loss: 1.6984311572967037

Epoch: 6| Step: 13
Training loss: 0.14995244145393372
Validation loss: 1.7590674059365385

Epoch: 276| Step: 0
Training loss: 0.5723258852958679
Validation loss: 1.8232340851137716

Epoch: 6| Step: 1
Training loss: 0.45465177297592163
Validation loss: 1.809162029656031

Epoch: 6| Step: 2
Training loss: 0.34879136085510254
Validation loss: 1.750060700601147

Epoch: 6| Step: 3
Training loss: 0.312020480632782
Validation loss: 1.7186776912340553

Epoch: 6| Step: 4
Training loss: 0.20728562772274017
Validation loss: 1.6801144538387176

Epoch: 6| Step: 5
Training loss: 0.36394816637039185
Validation loss: 1.6684739025690223

Epoch: 6| Step: 6
Training loss: 0.4431189298629761
Validation loss: 1.674966425024053

Epoch: 6| Step: 7
Training loss: 0.31405025720596313
Validation loss: 1.6614358335412958

Epoch: 6| Step: 8
Training loss: 0.4887619614601135
Validation loss: 1.6411451742213259

Epoch: 6| Step: 9
Training loss: 0.19415196776390076
Validation loss: 1.6396405773778115

Epoch: 6| Step: 10
Training loss: 0.4960455596446991
Validation loss: 1.617699617980629

Epoch: 6| Step: 11
Training loss: 0.3803814649581909
Validation loss: 1.636447391202373

Epoch: 6| Step: 12
Training loss: 0.3000190556049347
Validation loss: 1.6197449763615925

Epoch: 6| Step: 13
Training loss: 0.3280298709869385
Validation loss: 1.6400988448050715

Epoch: 277| Step: 0
Training loss: 0.35876989364624023
Validation loss: 1.6425597488239247

Epoch: 6| Step: 1
Training loss: 0.3065463900566101
Validation loss: 1.6000961283201813

Epoch: 6| Step: 2
Training loss: 0.27368152141571045
Validation loss: 1.6291037041653869

Epoch: 6| Step: 3
Training loss: 0.23464888334274292
Validation loss: 1.6201882003456034

Epoch: 6| Step: 4
Training loss: 0.33551234006881714
Validation loss: 1.6384946184773599

Epoch: 6| Step: 5
Training loss: 0.3698354959487915
Validation loss: 1.648216268708629

Epoch: 6| Step: 6
Training loss: 0.1784951388835907
Validation loss: 1.6746471364011046

Epoch: 6| Step: 7
Training loss: 0.32911014556884766
Validation loss: 1.6594888881970478

Epoch: 6| Step: 8
Training loss: 0.3989731967449188
Validation loss: 1.6880929495698662

Epoch: 6| Step: 9
Training loss: 0.28455260396003723
Validation loss: 1.7079126424686883

Epoch: 6| Step: 10
Training loss: 0.23573559522628784
Validation loss: 1.6859507970912482

Epoch: 6| Step: 11
Training loss: 0.23592522740364075
Validation loss: 1.7077403286451935

Epoch: 6| Step: 12
Training loss: 0.40150073170661926
Validation loss: 1.7443428219005626

Epoch: 6| Step: 13
Training loss: 0.13122643530368805
Validation loss: 1.722516223948489

Epoch: 278| Step: 0
Training loss: 0.22498759627342224
Validation loss: 1.726177482194798

Epoch: 6| Step: 1
Training loss: 0.24303632974624634
Validation loss: 1.732141719069532

Epoch: 6| Step: 2
Training loss: 0.25775814056396484
Validation loss: 1.7111089588493429

Epoch: 6| Step: 3
Training loss: 0.1473189890384674
Validation loss: 1.7284582686680618

Epoch: 6| Step: 4
Training loss: 0.36501678824424744
Validation loss: 1.7108765725166566

Epoch: 6| Step: 5
Training loss: 0.35337647795677185
Validation loss: 1.7035926080519153

Epoch: 6| Step: 6
Training loss: 0.25905346870422363
Validation loss: 1.6792319897682435

Epoch: 6| Step: 7
Training loss: 0.17984074354171753
Validation loss: 1.647744873518585

Epoch: 6| Step: 8
Training loss: 0.35205143690109253
Validation loss: 1.6561348463899346

Epoch: 6| Step: 9
Training loss: 0.203579843044281
Validation loss: 1.6639358176979968

Epoch: 6| Step: 10
Training loss: 0.32922735810279846
Validation loss: 1.702432345318538

Epoch: 6| Step: 11
Training loss: 0.3681008219718933
Validation loss: 1.6703033421629219

Epoch: 6| Step: 12
Training loss: 0.2975625693798065
Validation loss: 1.6689702080142113

Epoch: 6| Step: 13
Training loss: 0.12640491127967834
Validation loss: 1.6614306126871417

Epoch: 279| Step: 0
Training loss: 0.2880984842777252
Validation loss: 1.6525175315077587

Epoch: 6| Step: 1
Training loss: 0.19628554582595825
Validation loss: 1.675918322737499

Epoch: 6| Step: 2
Training loss: 0.4101579785346985
Validation loss: 1.6470896672177058

Epoch: 6| Step: 3
Training loss: 0.22804850339889526
Validation loss: 1.6646412431552846

Epoch: 6| Step: 4
Training loss: 0.19627948105335236
Validation loss: 1.6754856365983204

Epoch: 6| Step: 5
Training loss: 0.20624813437461853
Validation loss: 1.6976687767172371

Epoch: 6| Step: 6
Training loss: 0.3466792106628418
Validation loss: 1.6528277217700917

Epoch: 6| Step: 7
Training loss: 0.2826419472694397
Validation loss: 1.678430231668616

Epoch: 6| Step: 8
Training loss: 0.27904975414276123
Validation loss: 1.6997991595216977

Epoch: 6| Step: 9
Training loss: 0.24176634848117828
Validation loss: 1.7019873716497933

Epoch: 6| Step: 10
Training loss: 0.17429450154304504
Validation loss: 1.7042693720068982

Epoch: 6| Step: 11
Training loss: 0.20403730869293213
Validation loss: 1.7291742947793776

Epoch: 6| Step: 12
Training loss: 0.5054900646209717
Validation loss: 1.724616426293568

Epoch: 6| Step: 13
Training loss: 0.23568595945835114
Validation loss: 1.7290070518370597

Epoch: 280| Step: 0
Training loss: 0.2158806324005127
Validation loss: 1.7032436824614001

Epoch: 6| Step: 1
Training loss: 0.2661952078342438
Validation loss: 1.7466746709680046

Epoch: 6| Step: 2
Training loss: 0.26562315225601196
Validation loss: 1.707579296122315

Epoch: 6| Step: 3
Training loss: 0.2720963954925537
Validation loss: 1.7092129286899362

Epoch: 6| Step: 4
Training loss: 0.21522298455238342
Validation loss: 1.6863804850527035

Epoch: 6| Step: 5
Training loss: 0.3170478940010071
Validation loss: 1.6988546117659538

Epoch: 6| Step: 6
Training loss: 0.3479045629501343
Validation loss: 1.7147913427763088

Epoch: 6| Step: 7
Training loss: 0.5230357050895691
Validation loss: 1.6903440170390631

Epoch: 6| Step: 8
Training loss: 0.4004669189453125
Validation loss: 1.6785815826026342

Epoch: 6| Step: 9
Training loss: 0.23920249938964844
Validation loss: 1.6893015356474026

Epoch: 6| Step: 10
Training loss: 0.2404116690158844
Validation loss: 1.7101148815565212

Epoch: 6| Step: 11
Training loss: 0.3464468717575073
Validation loss: 1.6710700758041874

Epoch: 6| Step: 12
Training loss: 0.2902020215988159
Validation loss: 1.7325177948961976

Epoch: 6| Step: 13
Training loss: 0.3241507112979889
Validation loss: 1.7422754226192352

Epoch: 281| Step: 0
Training loss: 0.2118096798658371
Validation loss: 1.8111225315319595

Epoch: 6| Step: 1
Training loss: 0.3185808062553406
Validation loss: 1.8174926055374967

Epoch: 6| Step: 2
Training loss: 0.38155192136764526
Validation loss: 1.7901791628970896

Epoch: 6| Step: 3
Training loss: 0.23797325789928436
Validation loss: 1.7446578433436732

Epoch: 6| Step: 4
Training loss: 0.17245328426361084
Validation loss: 1.6964247406169932

Epoch: 6| Step: 5
Training loss: 0.33402949571609497
Validation loss: 1.662371362409284

Epoch: 6| Step: 6
Training loss: 0.398947536945343
Validation loss: 1.688137282607376

Epoch: 6| Step: 7
Training loss: 0.35728758573532104
Validation loss: 1.6748493192016438

Epoch: 6| Step: 8
Training loss: 0.2938636839389801
Validation loss: 1.6567057204502884

Epoch: 6| Step: 9
Training loss: 0.28337034583091736
Validation loss: 1.6354737666345411

Epoch: 6| Step: 10
Training loss: 0.3650161325931549
Validation loss: 1.725370817286994

Epoch: 6| Step: 11
Training loss: 0.19676029682159424
Validation loss: 1.669548761460089

Epoch: 6| Step: 12
Training loss: 0.45088762044906616
Validation loss: 1.7168547184236589

Epoch: 6| Step: 13
Training loss: 0.39787745475769043
Validation loss: 1.6889909698117165

Epoch: 282| Step: 0
Training loss: 0.48328766226768494
Validation loss: 1.6963764384228697

Epoch: 6| Step: 1
Training loss: 0.30101972818374634
Validation loss: 1.7083322527588054

Epoch: 6| Step: 2
Training loss: 0.21078215539455414
Validation loss: 1.7163059698638095

Epoch: 6| Step: 3
Training loss: 0.34152740240097046
Validation loss: 1.7021505012307117

Epoch: 6| Step: 4
Training loss: 0.517798662185669
Validation loss: 1.725019225510218

Epoch: 6| Step: 5
Training loss: 0.3009721040725708
Validation loss: 1.7048422110977994

Epoch: 6| Step: 6
Training loss: 0.16019505262374878
Validation loss: 1.7058710846849667

Epoch: 6| Step: 7
Training loss: 0.33372217416763306
Validation loss: 1.6974151570309874

Epoch: 6| Step: 8
Training loss: 0.306171178817749
Validation loss: 1.7134501293141355

Epoch: 6| Step: 9
Training loss: 0.21514257788658142
Validation loss: 1.715959793777876

Epoch: 6| Step: 10
Training loss: 0.3175605833530426
Validation loss: 1.7333885482562486

Epoch: 6| Step: 11
Training loss: 0.3487313985824585
Validation loss: 1.723493686286352

Epoch: 6| Step: 12
Training loss: 0.29132431745529175
Validation loss: 1.719734707186299

Epoch: 6| Step: 13
Training loss: 0.1442619115114212
Validation loss: 1.692406189057135

Epoch: 283| Step: 0
Training loss: 0.37032783031463623
Validation loss: 1.697541541950677

Epoch: 6| Step: 1
Training loss: 0.2815621793270111
Validation loss: 1.6889766493151266

Epoch: 6| Step: 2
Training loss: 0.28474557399749756
Validation loss: 1.6474538836427914

Epoch: 6| Step: 3
Training loss: 0.2452296018600464
Validation loss: 1.6542882714220273

Epoch: 6| Step: 4
Training loss: 0.3869091272354126
Validation loss: 1.699193258439341

Epoch: 6| Step: 5
Training loss: 0.3628999590873718
Validation loss: 1.654256341277912

Epoch: 6| Step: 6
Training loss: 0.18382060527801514
Validation loss: 1.6753582249405563

Epoch: 6| Step: 7
Training loss: 0.28504678606987
Validation loss: 1.6853722180089643

Epoch: 6| Step: 8
Training loss: 0.21870547533035278
Validation loss: 1.6631385562240437

Epoch: 6| Step: 9
Training loss: 0.12495724856853485
Validation loss: 1.6802877174910678

Epoch: 6| Step: 10
Training loss: 0.37040868401527405
Validation loss: 1.6764179577109635

Epoch: 6| Step: 11
Training loss: 0.3938145935535431
Validation loss: 1.6652151269297446

Epoch: 6| Step: 12
Training loss: 0.47329506278038025
Validation loss: 1.6509192400081183

Epoch: 6| Step: 13
Training loss: 0.18739598989486694
Validation loss: 1.6208914018446399

Epoch: 284| Step: 0
Training loss: 0.4223649203777313
Validation loss: 1.6212702579395746

Epoch: 6| Step: 1
Training loss: 0.2501576244831085
Validation loss: 1.6549163787595687

Epoch: 6| Step: 2
Training loss: 0.269009530544281
Validation loss: 1.6435546766045273

Epoch: 6| Step: 3
Training loss: 0.23618775606155396
Validation loss: 1.6291269108813295

Epoch: 6| Step: 4
Training loss: 0.2241244614124298
Validation loss: 1.62224349475676

Epoch: 6| Step: 5
Training loss: 0.26501360535621643
Validation loss: 1.6280431721800117

Epoch: 6| Step: 6
Training loss: 0.2524600028991699
Validation loss: 1.6403873479494484

Epoch: 6| Step: 7
Training loss: 0.20943942666053772
Validation loss: 1.6355428106041365

Epoch: 6| Step: 8
Training loss: 0.20658880472183228
Validation loss: 1.618181965684378

Epoch: 6| Step: 9
Training loss: 0.22563710808753967
Validation loss: 1.6293877504205192

Epoch: 6| Step: 10
Training loss: 0.21543371677398682
Validation loss: 1.6271986320454588

Epoch: 6| Step: 11
Training loss: 0.38178470730781555
Validation loss: 1.6083171854736984

Epoch: 6| Step: 12
Training loss: 0.2759125530719757
Validation loss: 1.6062092755430488

Epoch: 6| Step: 13
Training loss: 0.15240846574306488
Validation loss: 1.5973446010261454

Epoch: 285| Step: 0
Training loss: 0.2460695207118988
Validation loss: 1.6318328367766513

Epoch: 6| Step: 1
Training loss: 0.18498656153678894
Validation loss: 1.6314184383679462

Epoch: 6| Step: 2
Training loss: 0.23959672451019287
Validation loss: 1.6644351636209795

Epoch: 6| Step: 3
Training loss: 0.35749417543411255
Validation loss: 1.6831764585228377

Epoch: 6| Step: 4
Training loss: 0.3382726013660431
Validation loss: 1.6715229467679096

Epoch: 6| Step: 5
Training loss: 0.3209752142429352
Validation loss: 1.6663080844827878

Epoch: 6| Step: 6
Training loss: 0.2646329998970032
Validation loss: 1.6910840657449537

Epoch: 6| Step: 7
Training loss: 0.25885337591171265
Validation loss: 1.6955132599799865

Epoch: 6| Step: 8
Training loss: 0.3802087903022766
Validation loss: 1.6788526837543776

Epoch: 6| Step: 9
Training loss: 0.351472407579422
Validation loss: 1.6598148820220784

Epoch: 6| Step: 10
Training loss: 0.18726320564746857
Validation loss: 1.659790587681596

Epoch: 6| Step: 11
Training loss: 0.22649645805358887
Validation loss: 1.6360848885710522

Epoch: 6| Step: 12
Training loss: 0.35826486349105835
Validation loss: 1.6566226969483078

Epoch: 6| Step: 13
Training loss: 0.3034210205078125
Validation loss: 1.6560942767768778

Epoch: 286| Step: 0
Training loss: 0.2498599886894226
Validation loss: 1.6664002864591536

Epoch: 6| Step: 1
Training loss: 0.2822796702384949
Validation loss: 1.654704470788279

Epoch: 6| Step: 2
Training loss: 0.2699272036552429
Validation loss: 1.6592500107262724

Epoch: 6| Step: 3
Training loss: 0.32220107316970825
Validation loss: 1.6340626901195896

Epoch: 6| Step: 4
Training loss: 0.30084794759750366
Validation loss: 1.6428562851362332

Epoch: 6| Step: 5
Training loss: 0.2459196150302887
Validation loss: 1.637771498772406

Epoch: 6| Step: 6
Training loss: 0.4168146252632141
Validation loss: 1.6488736803813646

Epoch: 6| Step: 7
Training loss: 0.24661454558372498
Validation loss: 1.6574745626859768

Epoch: 6| Step: 8
Training loss: 0.15338394045829773
Validation loss: 1.6713700371403848

Epoch: 6| Step: 9
Training loss: 0.22128915786743164
Validation loss: 1.6761965623465918

Epoch: 6| Step: 10
Training loss: 0.18673811852931976
Validation loss: 1.6880582289029193

Epoch: 6| Step: 11
Training loss: 0.36516445875167847
Validation loss: 1.692539556052095

Epoch: 6| Step: 12
Training loss: 0.2818259298801422
Validation loss: 1.7102038142501668

Epoch: 6| Step: 13
Training loss: 0.5472480058670044
Validation loss: 1.7090357657401793

Epoch: 287| Step: 0
Training loss: 0.2922648787498474
Validation loss: 1.7187232484099686

Epoch: 6| Step: 1
Training loss: 0.4074084460735321
Validation loss: 1.7476361669519895

Epoch: 6| Step: 2
Training loss: 0.2770687937736511
Validation loss: 1.7163333316003122

Epoch: 6| Step: 3
Training loss: 0.3224756717681885
Validation loss: 1.742142927262091

Epoch: 6| Step: 4
Training loss: 0.3905232548713684
Validation loss: 1.6798905877656833

Epoch: 6| Step: 5
Training loss: 0.16194477677345276
Validation loss: 1.6864420085824945

Epoch: 6| Step: 6
Training loss: 0.32603567838668823
Validation loss: 1.6763546402736376

Epoch: 6| Step: 7
Training loss: 0.19011977314949036
Validation loss: 1.6337020576641124

Epoch: 6| Step: 8
Training loss: 0.29806071519851685
Validation loss: 1.635448855738486

Epoch: 6| Step: 9
Training loss: 0.1664956510066986
Validation loss: 1.6858370457926104

Epoch: 6| Step: 10
Training loss: 0.29546448588371277
Validation loss: 1.6560636822895338

Epoch: 6| Step: 11
Training loss: 0.17449820041656494
Validation loss: 1.6833164486833798

Epoch: 6| Step: 12
Training loss: 0.27316009998321533
Validation loss: 1.6894007728945823

Epoch: 6| Step: 13
Training loss: 0.3281290829181671
Validation loss: 1.6846210392572547

Epoch: 288| Step: 0
Training loss: 0.28334665298461914
Validation loss: 1.6747177749551752

Epoch: 6| Step: 1
Training loss: 0.2541159987449646
Validation loss: 1.6490187145048572

Epoch: 6| Step: 2
Training loss: 0.25755637884140015
Validation loss: 1.6557172959850681

Epoch: 6| Step: 3
Training loss: 0.27337297797203064
Validation loss: 1.7019455227800595

Epoch: 6| Step: 4
Training loss: 0.2278798669576645
Validation loss: 1.7149699259829778

Epoch: 6| Step: 5
Training loss: 0.2936924695968628
Validation loss: 1.6905519808492353

Epoch: 6| Step: 6
Training loss: 0.32235461473464966
Validation loss: 1.6670824802050026

Epoch: 6| Step: 7
Training loss: 0.41366639733314514
Validation loss: 1.6951109722096434

Epoch: 6| Step: 8
Training loss: 0.273948073387146
Validation loss: 1.687982004175904

Epoch: 6| Step: 9
Training loss: 0.3302619457244873
Validation loss: 1.6895038158662858

Epoch: 6| Step: 10
Training loss: 0.2309679388999939
Validation loss: 1.6990424561244186

Epoch: 6| Step: 11
Training loss: 0.08807086199522018
Validation loss: 1.684713609756962

Epoch: 6| Step: 12
Training loss: 0.25280138850212097
Validation loss: 1.6979831790411344

Epoch: 6| Step: 13
Training loss: 0.5081844925880432
Validation loss: 1.7382893485407676

Epoch: 289| Step: 0
Training loss: 0.4225390553474426
Validation loss: 1.7816113643748785

Epoch: 6| Step: 1
Training loss: 0.2570095956325531
Validation loss: 1.7220790898928078

Epoch: 6| Step: 2
Training loss: 0.2867906093597412
Validation loss: 1.675946754793967

Epoch: 6| Step: 3
Training loss: 0.32592618465423584
Validation loss: 1.665355625972953

Epoch: 6| Step: 4
Training loss: 0.27991995215415955
Validation loss: 1.649037189381097

Epoch: 6| Step: 5
Training loss: 0.4460896849632263
Validation loss: 1.6442867402107484

Epoch: 6| Step: 6
Training loss: 0.5135478973388672
Validation loss: 1.6496348560497325

Epoch: 6| Step: 7
Training loss: 0.37202882766723633
Validation loss: 1.6190903020161453

Epoch: 6| Step: 8
Training loss: 0.391745001077652
Validation loss: 1.6437192501560334

Epoch: 6| Step: 9
Training loss: 0.2468709647655487
Validation loss: 1.623861333375336

Epoch: 6| Step: 10
Training loss: 0.2857987582683563
Validation loss: 1.643974566972384

Epoch: 6| Step: 11
Training loss: 0.3016558289527893
Validation loss: 1.6589002378525273

Epoch: 6| Step: 12
Training loss: 0.1828422248363495
Validation loss: 1.6601567435008224

Epoch: 6| Step: 13
Training loss: 0.3921412527561188
Validation loss: 1.6653026303937357

Epoch: 290| Step: 0
Training loss: 0.476399302482605
Validation loss: 1.713972246775063

Epoch: 6| Step: 1
Training loss: 0.4251840114593506
Validation loss: 1.7221516704046598

Epoch: 6| Step: 2
Training loss: 0.2086688131093979
Validation loss: 1.691038432941642

Epoch: 6| Step: 3
Training loss: 0.17345578968524933
Validation loss: 1.689280322802964

Epoch: 6| Step: 4
Training loss: 0.3771975040435791
Validation loss: 1.6301979576387713

Epoch: 6| Step: 5
Training loss: 0.21208786964416504
Validation loss: 1.6465780158196726

Epoch: 6| Step: 6
Training loss: 0.15892967581748962
Validation loss: 1.6626632367410967

Epoch: 6| Step: 7
Training loss: 0.3166440725326538
Validation loss: 1.6546782972992107

Epoch: 6| Step: 8
Training loss: 0.32625871896743774
Validation loss: 1.6679588876744753

Epoch: 6| Step: 9
Training loss: 0.3083666265010834
Validation loss: 1.6860926497367121

Epoch: 6| Step: 10
Training loss: 0.30542537569999695
Validation loss: 1.6604553576438659

Epoch: 6| Step: 11
Training loss: 0.37563902139663696
Validation loss: 1.6768567856921945

Epoch: 6| Step: 12
Training loss: 0.22513139247894287
Validation loss: 1.6718208161733483

Epoch: 6| Step: 13
Training loss: 0.28904759883880615
Validation loss: 1.6891150654003184

Epoch: 291| Step: 0
Training loss: 0.15684974193572998
Validation loss: 1.7084871210077757

Epoch: 6| Step: 1
Training loss: 0.44797569513320923
Validation loss: 1.6840355197588603

Epoch: 6| Step: 2
Training loss: 0.2963618040084839
Validation loss: 1.6786197065025248

Epoch: 6| Step: 3
Training loss: 0.11679916083812714
Validation loss: 1.7157878862914218

Epoch: 6| Step: 4
Training loss: 0.24164322018623352
Validation loss: 1.7098259836114862

Epoch: 6| Step: 5
Training loss: 0.17340900003910065
Validation loss: 1.673871228771825

Epoch: 6| Step: 6
Training loss: 0.3461347818374634
Validation loss: 1.728550240557681

Epoch: 6| Step: 7
Training loss: 0.25828686356544495
Validation loss: 1.6736340099765408

Epoch: 6| Step: 8
Training loss: 0.35091376304626465
Validation loss: 1.7043904271177066

Epoch: 6| Step: 9
Training loss: 0.26395124197006226
Validation loss: 1.6844408460842666

Epoch: 6| Step: 10
Training loss: 0.25736480951309204
Validation loss: 1.6429601471911195

Epoch: 6| Step: 11
Training loss: 0.31565403938293457
Validation loss: 1.6401390080810876

Epoch: 6| Step: 12
Training loss: 0.12923389673233032
Validation loss: 1.6727934678395588

Epoch: 6| Step: 13
Training loss: 0.2994423508644104
Validation loss: 1.6630884319223382

Epoch: 292| Step: 0
Training loss: 0.30572426319122314
Validation loss: 1.6520421915156867

Epoch: 6| Step: 1
Training loss: 0.23074595630168915
Validation loss: 1.6601436650881203

Epoch: 6| Step: 2
Training loss: 0.13039645552635193
Validation loss: 1.6225531383227276

Epoch: 6| Step: 3
Training loss: 0.2163325697183609
Validation loss: 1.680182768452552

Epoch: 6| Step: 4
Training loss: 0.24306629598140717
Validation loss: 1.6774750204496487

Epoch: 6| Step: 5
Training loss: 0.29470571875572205
Validation loss: 1.6650483294199871

Epoch: 6| Step: 6
Training loss: 0.21951118111610413
Validation loss: 1.637664479594077

Epoch: 6| Step: 7
Training loss: 0.4780844449996948
Validation loss: 1.683310798419419

Epoch: 6| Step: 8
Training loss: 0.22488147020339966
Validation loss: 1.663312069831356

Epoch: 6| Step: 9
Training loss: 0.3030044138431549
Validation loss: 1.6848521976060764

Epoch: 6| Step: 10
Training loss: 0.16399258375167847
Validation loss: 1.6355614008442048

Epoch: 6| Step: 11
Training loss: 0.345793217420578
Validation loss: 1.6380700295971287

Epoch: 6| Step: 12
Training loss: 0.2803442180156708
Validation loss: 1.6660406743326495

Epoch: 6| Step: 13
Training loss: 0.3598136901855469
Validation loss: 1.6655425948481406

Epoch: 293| Step: 0
Training loss: 0.35601478815078735
Validation loss: 1.640532148781643

Epoch: 6| Step: 1
Training loss: 0.35559481382369995
Validation loss: 1.6819401723082348

Epoch: 6| Step: 2
Training loss: 0.19471116364002228
Validation loss: 1.6419917306592386

Epoch: 6| Step: 3
Training loss: 0.21715527772903442
Validation loss: 1.6464929490961053

Epoch: 6| Step: 4
Training loss: 0.11774803698062897
Validation loss: 1.6681113422557872

Epoch: 6| Step: 5
Training loss: 0.1891302764415741
Validation loss: 1.6744624978752547

Epoch: 6| Step: 6
Training loss: 0.28570985794067383
Validation loss: 1.6828103347491192

Epoch: 6| Step: 7
Training loss: 0.2683452367782593
Validation loss: 1.6567227776332567

Epoch: 6| Step: 8
Training loss: 0.23247911036014557
Validation loss: 1.6629537997707244

Epoch: 6| Step: 9
Training loss: 0.222775399684906
Validation loss: 1.6964313971099032

Epoch: 6| Step: 10
Training loss: 0.21867671608924866
Validation loss: 1.6625666797802012

Epoch: 6| Step: 11
Training loss: 0.14111869037151337
Validation loss: 1.6743252508101925

Epoch: 6| Step: 12
Training loss: 0.34657418727874756
Validation loss: 1.6873966365732171

Epoch: 6| Step: 13
Training loss: 0.33039215207099915
Validation loss: 1.651954024068771

Epoch: 294| Step: 0
Training loss: 0.22716888785362244
Validation loss: 1.6769236236490228

Epoch: 6| Step: 1
Training loss: 0.14869706332683563
Validation loss: 1.650349901568505

Epoch: 6| Step: 2
Training loss: 0.2540540397167206
Validation loss: 1.6449901173191686

Epoch: 6| Step: 3
Training loss: 0.2860449552536011
Validation loss: 1.6465513501116025

Epoch: 6| Step: 4
Training loss: 0.2979530692100525
Validation loss: 1.6421974166747062

Epoch: 6| Step: 5
Training loss: 0.1514185667037964
Validation loss: 1.6145984626585437

Epoch: 6| Step: 6
Training loss: 0.19084320962429047
Validation loss: 1.6193631669526458

Epoch: 6| Step: 7
Training loss: 0.3075980544090271
Validation loss: 1.65278229149439

Epoch: 6| Step: 8
Training loss: 0.28062599897384644
Validation loss: 1.6610032807114303

Epoch: 6| Step: 9
Training loss: 0.17315153777599335
Validation loss: 1.6156306689785374

Epoch: 6| Step: 10
Training loss: 0.36412137746810913
Validation loss: 1.6026878997843752

Epoch: 6| Step: 11
Training loss: 0.20958827435970306
Validation loss: 1.6109763499229186

Epoch: 6| Step: 12
Training loss: 0.27323412895202637
Validation loss: 1.6374875281446724

Epoch: 6| Step: 13
Training loss: 0.23697413504123688
Validation loss: 1.6271602325541998

Epoch: 295| Step: 0
Training loss: 0.37610456347465515
Validation loss: 1.632180094718933

Epoch: 6| Step: 1
Training loss: 0.24412544071674347
Validation loss: 1.6733228762944539

Epoch: 6| Step: 2
Training loss: 0.18149465322494507
Validation loss: 1.6410460920744045

Epoch: 6| Step: 3
Training loss: 0.0707944706082344
Validation loss: 1.637272092603868

Epoch: 6| Step: 4
Training loss: 0.18819504976272583
Validation loss: 1.6617782590209798

Epoch: 6| Step: 5
Training loss: 0.3298565149307251
Validation loss: 1.6439971475191013

Epoch: 6| Step: 6
Training loss: 0.30545324087142944
Validation loss: 1.6135722578212779

Epoch: 6| Step: 7
Training loss: 0.11856018006801605
Validation loss: 1.6348556600591189

Epoch: 6| Step: 8
Training loss: 0.19334501028060913
Validation loss: 1.6127176720608947

Epoch: 6| Step: 9
Training loss: 0.21303926408290863
Validation loss: 1.6077110767364502

Epoch: 6| Step: 10
Training loss: 0.14503154158592224
Validation loss: 1.6243164077881844

Epoch: 6| Step: 11
Training loss: 0.20599782466888428
Validation loss: 1.5863609313964844

Epoch: 6| Step: 12
Training loss: 0.20348043739795685
Validation loss: 1.6173515499279063

Epoch: 6| Step: 13
Training loss: 0.21628180146217346
Validation loss: 1.588344782911321

Epoch: 296| Step: 0
Training loss: 0.25008803606033325
Validation loss: 1.6137333992988832

Epoch: 6| Step: 1
Training loss: 0.24209731817245483
Validation loss: 1.5871648250087615

Epoch: 6| Step: 2
Training loss: 0.2610035538673401
Validation loss: 1.6173175316984936

Epoch: 6| Step: 3
Training loss: 0.32143351435661316
Validation loss: 1.6345601056211738

Epoch: 6| Step: 4
Training loss: 0.21103595197200775
Validation loss: 1.6410314370227117

Epoch: 6| Step: 5
Training loss: 0.33633023500442505
Validation loss: 1.649744149177305

Epoch: 6| Step: 6
Training loss: 0.1766493320465088
Validation loss: 1.6496475781163862

Epoch: 6| Step: 7
Training loss: 0.20069243013858795
Validation loss: 1.6389791093846804

Epoch: 6| Step: 8
Training loss: 0.2051919549703598
Validation loss: 1.646377948022658

Epoch: 6| Step: 9
Training loss: 0.37459319829940796
Validation loss: 1.6184226902582313

Epoch: 6| Step: 10
Training loss: 0.24799686670303345
Validation loss: 1.6366968436907696

Epoch: 6| Step: 11
Training loss: 0.33944690227508545
Validation loss: 1.6236247875357186

Epoch: 6| Step: 12
Training loss: 0.1696210652589798
Validation loss: 1.6293158620916388

Epoch: 6| Step: 13
Training loss: 0.2609300911426544
Validation loss: 1.6116956446760444

Epoch: 297| Step: 0
Training loss: 0.20076657831668854
Validation loss: 1.5752594265886533

Epoch: 6| Step: 1
Training loss: 0.24204891920089722
Validation loss: 1.6127849112274826

Epoch: 6| Step: 2
Training loss: 0.1541559398174286
Validation loss: 1.617210752220564

Epoch: 6| Step: 3
Training loss: 0.2678012251853943
Validation loss: 1.6434753235950266

Epoch: 6| Step: 4
Training loss: 0.11110188066959381
Validation loss: 1.6071694461248254

Epoch: 6| Step: 5
Training loss: 0.22856342792510986
Validation loss: 1.6316803552771126

Epoch: 6| Step: 6
Training loss: 0.2622910439968109
Validation loss: 1.6173839761364845

Epoch: 6| Step: 7
Training loss: 0.2254737913608551
Validation loss: 1.6379400530169088

Epoch: 6| Step: 8
Training loss: 0.2511465847492218
Validation loss: 1.6023886767766808

Epoch: 6| Step: 9
Training loss: 0.20124812424182892
Validation loss: 1.5778941057061637

Epoch: 6| Step: 10
Training loss: 0.16245484352111816
Validation loss: 1.5799563161788448

Epoch: 6| Step: 11
Training loss: 0.31782233715057373
Validation loss: 1.5783047663268222

Epoch: 6| Step: 12
Training loss: 0.2333846092224121
Validation loss: 1.5815559766625846

Epoch: 6| Step: 13
Training loss: 0.2698225677013397
Validation loss: 1.5758414050584197

Epoch: 298| Step: 0
Training loss: 0.2755166292190552
Validation loss: 1.5971133350044169

Epoch: 6| Step: 1
Training loss: 0.27222585678100586
Validation loss: 1.6117668920947659

Epoch: 6| Step: 2
Training loss: 0.21908041834831238
Validation loss: 1.579177628281296

Epoch: 6| Step: 3
Training loss: 0.16803216934204102
Validation loss: 1.6178351025427542

Epoch: 6| Step: 4
Training loss: 0.23335391283035278
Validation loss: 1.6090758808197514

Epoch: 6| Step: 5
Training loss: 0.19965717196464539
Validation loss: 1.6302061952570432

Epoch: 6| Step: 6
Training loss: 0.43446049094200134
Validation loss: 1.6330002994947537

Epoch: 6| Step: 7
Training loss: 0.1257104128599167
Validation loss: 1.6640863110942226

Epoch: 6| Step: 8
Training loss: 0.2728483974933624
Validation loss: 1.6866384193461428

Epoch: 6| Step: 9
Training loss: 0.12733867764472961
Validation loss: 1.6857204296255623

Epoch: 6| Step: 10
Training loss: 0.2881964445114136
Validation loss: 1.6441412061773322

Epoch: 6| Step: 11
Training loss: 0.2390838861465454
Validation loss: 1.648628197690492

Epoch: 6| Step: 12
Training loss: 0.20111508667469025
Validation loss: 1.6569454631497782

Epoch: 6| Step: 13
Training loss: 0.1934211254119873
Validation loss: 1.6799393507742113

Epoch: 299| Step: 0
Training loss: 0.2312505841255188
Validation loss: 1.673550413500878

Epoch: 6| Step: 1
Training loss: 0.23381124436855316
Validation loss: 1.6221937120601695

Epoch: 6| Step: 2
Training loss: 0.19864621758460999
Validation loss: 1.6408927812371203

Epoch: 6| Step: 3
Training loss: 0.3179210424423218
Validation loss: 1.6358003398423553

Epoch: 6| Step: 4
Training loss: 0.20018281042575836
Validation loss: 1.6503940730966546

Epoch: 6| Step: 5
Training loss: 0.1335972547531128
Validation loss: 1.644583999469716

Epoch: 6| Step: 6
Training loss: 0.2847748398780823
Validation loss: 1.6263534125461374

Epoch: 6| Step: 7
Training loss: 0.2108583152294159
Validation loss: 1.6258122946626397

Epoch: 6| Step: 8
Training loss: 0.18914133310317993
Validation loss: 1.6279581464746946

Epoch: 6| Step: 9
Training loss: 0.20849621295928955
Validation loss: 1.6007982556537916

Epoch: 6| Step: 10
Training loss: 0.1759703904390335
Validation loss: 1.6022452513376872

Epoch: 6| Step: 11
Training loss: 0.20248767733573914
Validation loss: 1.5919212372072282

Epoch: 6| Step: 12
Training loss: 0.36340683698654175
Validation loss: 1.6260693098909111

Epoch: 6| Step: 13
Training loss: 0.18063884973526
Validation loss: 1.5941911487169163

Epoch: 300| Step: 0
Training loss: 0.2752695083618164
Validation loss: 1.6204066263732089

Epoch: 6| Step: 1
Training loss: 0.26845645904541016
Validation loss: 1.622705485231133

Epoch: 6| Step: 2
Training loss: 0.22271005809307098
Validation loss: 1.6230662215140559

Epoch: 6| Step: 3
Training loss: 0.14881545305252075
Validation loss: 1.6508279718378538

Epoch: 6| Step: 4
Training loss: 0.111900195479393
Validation loss: 1.6342474081182992

Epoch: 6| Step: 5
Training loss: 0.17252451181411743
Validation loss: 1.6155345337365263

Epoch: 6| Step: 6
Training loss: 0.25173428654670715
Validation loss: 1.6360438267389934

Epoch: 6| Step: 7
Training loss: 0.13660867512226105
Validation loss: 1.6418676530161211

Epoch: 6| Step: 8
Training loss: 0.19773486256599426
Validation loss: 1.6224128687253563

Epoch: 6| Step: 9
Training loss: 0.27876782417297363
Validation loss: 1.6494580597005866

Epoch: 6| Step: 10
Training loss: 0.1873680055141449
Validation loss: 1.6486444857812697

Epoch: 6| Step: 11
Training loss: 0.307284951210022
Validation loss: 1.6256466655321018

Epoch: 6| Step: 12
Training loss: 0.3530848026275635
Validation loss: 1.6625466603104786

Epoch: 6| Step: 13
Training loss: 0.21061663329601288
Validation loss: 1.613440921229701

Epoch: 301| Step: 0
Training loss: 0.2832186818122864
Validation loss: 1.6276149775392266

Epoch: 6| Step: 1
Training loss: 0.2218855917453766
Validation loss: 1.6145021043797976

Epoch: 6| Step: 2
Training loss: 0.2684832215309143
Validation loss: 1.6195865061975294

Epoch: 6| Step: 3
Training loss: 0.19434234499931335
Validation loss: 1.6160800700546594

Epoch: 6| Step: 4
Training loss: 0.19259291887283325
Validation loss: 1.6169841943248626

Epoch: 6| Step: 5
Training loss: 0.19076837599277496
Validation loss: 1.6130284211968864

Epoch: 6| Step: 6
Training loss: 0.17905914783477783
Validation loss: 1.6355682893465924

Epoch: 6| Step: 7
Training loss: 0.15911215543746948
Validation loss: 1.587271123804072

Epoch: 6| Step: 8
Training loss: 0.29733502864837646
Validation loss: 1.612896998723348

Epoch: 6| Step: 9
Training loss: 0.1158839762210846
Validation loss: 1.6418463209623932

Epoch: 6| Step: 10
Training loss: 0.2631140351295471
Validation loss: 1.6217016417493102

Epoch: 6| Step: 11
Training loss: 0.29010868072509766
Validation loss: 1.610318208253512

Epoch: 6| Step: 12
Training loss: 0.242388516664505
Validation loss: 1.6495370211139802

Epoch: 6| Step: 13
Training loss: 0.18435342609882355
Validation loss: 1.6425664860715148

Epoch: 302| Step: 0
Training loss: 0.22805120050907135
Validation loss: 1.6380563525743381

Epoch: 6| Step: 1
Training loss: 0.19185495376586914
Validation loss: 1.6284547903204476

Epoch: 6| Step: 2
Training loss: 0.265553742647171
Validation loss: 1.629424270763192

Epoch: 6| Step: 3
Training loss: 0.2144688069820404
Validation loss: 1.6198211549430765

Epoch: 6| Step: 4
Training loss: 0.297899067401886
Validation loss: 1.631049753517233

Epoch: 6| Step: 5
Training loss: 0.16758067905902863
Validation loss: 1.6040159867655845

Epoch: 6| Step: 6
Training loss: 0.16784974932670593
Validation loss: 1.5966642261833273

Epoch: 6| Step: 7
Training loss: 0.15855050086975098
Validation loss: 1.583974060191903

Epoch: 6| Step: 8
Training loss: 0.34085750579833984
Validation loss: 1.6090133279882453

Epoch: 6| Step: 9
Training loss: 0.37277793884277344
Validation loss: 1.6780898256968426

Epoch: 6| Step: 10
Training loss: 0.2378653883934021
Validation loss: 1.6456175619556057

Epoch: 6| Step: 11
Training loss: 0.1236608698964119
Validation loss: 1.6240216352606331

Epoch: 6| Step: 12
Training loss: 0.11056730151176453
Validation loss: 1.6332703008446643

Epoch: 6| Step: 13
Training loss: 0.2292078137397766
Validation loss: 1.656107182143837

Epoch: 303| Step: 0
Training loss: 0.1921178698539734
Validation loss: 1.6431652679238269

Epoch: 6| Step: 1
Training loss: 0.24853172898292542
Validation loss: 1.6568301262394074

Epoch: 6| Step: 2
Training loss: 0.25070643424987793
Validation loss: 1.6696278138827252

Epoch: 6| Step: 3
Training loss: 0.26748308539390564
Validation loss: 1.6442613652957383

Epoch: 6| Step: 4
Training loss: 0.30452680587768555
Validation loss: 1.6442142327626545

Epoch: 6| Step: 5
Training loss: 0.16091671586036682
Validation loss: 1.6814575413221955

Epoch: 6| Step: 6
Training loss: 0.25584539771080017
Validation loss: 1.6470822326598629

Epoch: 6| Step: 7
Training loss: 0.23471599817276
Validation loss: 1.6387462141693279

Epoch: 6| Step: 8
Training loss: 0.19601301848888397
Validation loss: 1.6730581457896898

Epoch: 6| Step: 9
Training loss: 0.35760945081710815
Validation loss: 1.6766344622899128

Epoch: 6| Step: 10
Training loss: 0.1014137715101242
Validation loss: 1.6499030243965886

Epoch: 6| Step: 11
Training loss: 0.184419646859169
Validation loss: 1.6484283811302596

Epoch: 6| Step: 12
Training loss: 0.1919422745704651
Validation loss: 1.65529618981064

Epoch: 6| Step: 13
Training loss: 0.14390188455581665
Validation loss: 1.638468982071005

Epoch: 304| Step: 0
Training loss: 0.17640404403209686
Validation loss: 1.6470721921613138

Epoch: 6| Step: 1
Training loss: 0.23119446635246277
Validation loss: 1.6803581714630127

Epoch: 6| Step: 2
Training loss: 0.2170110046863556
Validation loss: 1.6563014561130154

Epoch: 6| Step: 3
Training loss: 0.1444394290447235
Validation loss: 1.599379261334737

Epoch: 6| Step: 4
Training loss: 0.27504032850265503
Validation loss: 1.6195458417297692

Epoch: 6| Step: 5
Training loss: 0.18119609355926514
Validation loss: 1.6331976395781322

Epoch: 6| Step: 6
Training loss: 0.24663764238357544
Validation loss: 1.666524621748155

Epoch: 6| Step: 7
Training loss: 0.217512845993042
Validation loss: 1.6658385774140716

Epoch: 6| Step: 8
Training loss: 0.20375469326972961
Validation loss: 1.6439327604027205

Epoch: 6| Step: 9
Training loss: 0.20099762082099915
Validation loss: 1.6530079380158456

Epoch: 6| Step: 10
Training loss: 0.30887341499328613
Validation loss: 1.6447132556669173

Epoch: 6| Step: 11
Training loss: 0.27503150701522827
Validation loss: 1.6467403980993456

Epoch: 6| Step: 12
Training loss: 0.20044083893299103
Validation loss: 1.6354561621142971

Epoch: 6| Step: 13
Training loss: 0.10695343464612961
Validation loss: 1.6434285076715613

Epoch: 305| Step: 0
Training loss: 0.16814857721328735
Validation loss: 1.6234042734228156

Epoch: 6| Step: 1
Training loss: 0.2684711217880249
Validation loss: 1.6134547430981871

Epoch: 6| Step: 2
Training loss: 0.12379148602485657
Validation loss: 1.6176474530209777

Epoch: 6| Step: 3
Training loss: 0.1848723292350769
Validation loss: 1.623358767519715

Epoch: 6| Step: 4
Training loss: 0.15825873613357544
Validation loss: 1.611036632650642

Epoch: 6| Step: 5
Training loss: 0.2728719711303711
Validation loss: 1.6036787725264026

Epoch: 6| Step: 6
Training loss: 0.4126184582710266
Validation loss: 1.6013021981844338

Epoch: 6| Step: 7
Training loss: 0.2667507827281952
Validation loss: 1.5744001711568525

Epoch: 6| Step: 8
Training loss: 0.2006310671567917
Validation loss: 1.5991518715376496

Epoch: 6| Step: 9
Training loss: 0.2544718384742737
Validation loss: 1.5768556928121915

Epoch: 6| Step: 10
Training loss: 0.33076754212379456
Validation loss: 1.5829928575023529

Epoch: 6| Step: 11
Training loss: 0.16043493151664734
Validation loss: 1.6164566009275374

Epoch: 6| Step: 12
Training loss: 0.36193370819091797
Validation loss: 1.6636813404739543

Epoch: 6| Step: 13
Training loss: 0.28268659114837646
Validation loss: 1.6763187070046701

Epoch: 306| Step: 0
Training loss: 0.30624887347221375
Validation loss: 1.6407395242362894

Epoch: 6| Step: 1
Training loss: 0.2182476818561554
Validation loss: 1.6384925111647575

Epoch: 6| Step: 2
Training loss: 0.13785532116889954
Validation loss: 1.617424024048672

Epoch: 6| Step: 3
Training loss: 0.1901489794254303
Validation loss: 1.6403149404833395

Epoch: 6| Step: 4
Training loss: 0.27262091636657715
Validation loss: 1.6225926555613035

Epoch: 6| Step: 5
Training loss: 0.13913074135780334
Validation loss: 1.5958101185419227

Epoch: 6| Step: 6
Training loss: 0.2135782241821289
Validation loss: 1.619656333359339

Epoch: 6| Step: 7
Training loss: 0.2762640118598938
Validation loss: 1.5793130179887176

Epoch: 6| Step: 8
Training loss: 0.22627103328704834
Validation loss: 1.6068166712278962

Epoch: 6| Step: 9
Training loss: 0.25435391068458557
Validation loss: 1.5979444493529618

Epoch: 6| Step: 10
Training loss: 0.16602350771427155
Validation loss: 1.5580814153917375

Epoch: 6| Step: 11
Training loss: 0.24923843145370483
Validation loss: 1.5760633637828212

Epoch: 6| Step: 12
Training loss: 0.12587380409240723
Validation loss: 1.5846566179747223

Epoch: 6| Step: 13
Training loss: 0.28037863969802856
Validation loss: 1.5744561290228238

Epoch: 307| Step: 0
Training loss: 0.260570764541626
Validation loss: 1.5915922823772635

Epoch: 6| Step: 1
Training loss: 0.21383479237556458
Validation loss: 1.6037826371449295

Epoch: 6| Step: 2
Training loss: 0.24627652764320374
Validation loss: 1.6018148250477289

Epoch: 6| Step: 3
Training loss: 0.17442545294761658
Validation loss: 1.5834975768161077

Epoch: 6| Step: 4
Training loss: 0.21154950559139252
Validation loss: 1.5977284703203427

Epoch: 6| Step: 5
Training loss: 0.1475716531276703
Validation loss: 1.5724720365257674

Epoch: 6| Step: 6
Training loss: 0.33586475253105164
Validation loss: 1.6164987676887101

Epoch: 6| Step: 7
Training loss: 0.18737033009529114
Validation loss: 1.5831495613180182

Epoch: 6| Step: 8
Training loss: 0.18380209803581238
Validation loss: 1.6016650097344511

Epoch: 6| Step: 9
Training loss: 0.19975224137306213
Validation loss: 1.6041799873434088

Epoch: 6| Step: 10
Training loss: 0.23477111756801605
Validation loss: 1.596582043555475

Epoch: 6| Step: 11
Training loss: 0.23158273100852966
Validation loss: 1.5736538748587332

Epoch: 6| Step: 12
Training loss: 0.11842725425958633
Validation loss: 1.5814562741146292

Epoch: 6| Step: 13
Training loss: 0.35707616806030273
Validation loss: 1.5922220932540072

Epoch: 308| Step: 0
Training loss: 0.19202253222465515
Validation loss: 1.5927233157619354

Epoch: 6| Step: 1
Training loss: 0.12909191846847534
Validation loss: 1.5609229585175872

Epoch: 6| Step: 2
Training loss: 0.18934477865695953
Validation loss: 1.5841525639257124

Epoch: 6| Step: 3
Training loss: 0.13159313797950745
Validation loss: 1.574134716423609

Epoch: 6| Step: 4
Training loss: 0.18845057487487793
Validation loss: 1.607218474470159

Epoch: 6| Step: 5
Training loss: 0.18048778176307678
Validation loss: 1.5732110110662316

Epoch: 6| Step: 6
Training loss: 0.1767270565032959
Validation loss: 1.5490363323560326

Epoch: 6| Step: 7
Training loss: 0.2042463719844818
Validation loss: 1.5640952394854637

Epoch: 6| Step: 8
Training loss: 0.1719263792037964
Validation loss: 1.5804445000105007

Epoch: 6| Step: 9
Training loss: 0.45147159695625305
Validation loss: 1.5671603705293389

Epoch: 6| Step: 10
Training loss: 0.18804025650024414
Validation loss: 1.5692320831360356

Epoch: 6| Step: 11
Training loss: 0.12663790583610535
Validation loss: 1.565310533328723

Epoch: 6| Step: 12
Training loss: 0.14785327017307281
Validation loss: 1.5770000552618375

Epoch: 6| Step: 13
Training loss: 0.1706905961036682
Validation loss: 1.5824022793000745

Epoch: 309| Step: 0
Training loss: 0.13112694025039673
Validation loss: 1.563028948281401

Epoch: 6| Step: 1
Training loss: 0.24009186029434204
Validation loss: 1.614589113061146

Epoch: 6| Step: 2
Training loss: 0.19553568959236145
Validation loss: 1.594290232145658

Epoch: 6| Step: 3
Training loss: 0.20197276771068573
Validation loss: 1.554904568579889

Epoch: 6| Step: 4
Training loss: 0.14909088611602783
Validation loss: 1.5645815018684632

Epoch: 6| Step: 5
Training loss: 0.20429468154907227
Validation loss: 1.5645196655745148

Epoch: 6| Step: 6
Training loss: 0.21086442470550537
Validation loss: 1.6373897752454203

Epoch: 6| Step: 7
Training loss: 0.27418214082717896
Validation loss: 1.648068162702745

Epoch: 6| Step: 8
Training loss: 0.3591655492782593
Validation loss: 1.6580803830136535

Epoch: 6| Step: 9
Training loss: 0.2508905529975891
Validation loss: 1.6930383149013724

Epoch: 6| Step: 10
Training loss: 0.29252883791923523
Validation loss: 1.6820400299564484

Epoch: 6| Step: 11
Training loss: 0.20278504490852356
Validation loss: 1.66987568460485

Epoch: 6| Step: 12
Training loss: 0.2975339889526367
Validation loss: 1.6044024049594838

Epoch: 6| Step: 13
Training loss: 0.12366355955600739
Validation loss: 1.6240983477202795

Epoch: 310| Step: 0
Training loss: 0.27498286962509155
Validation loss: 1.580812833642447

Epoch: 6| Step: 1
Training loss: 0.20988373458385468
Validation loss: 1.6234626770019531

Epoch: 6| Step: 2
Training loss: 0.24658380448818207
Validation loss: 1.607083224481152

Epoch: 6| Step: 3
Training loss: 0.22440214455127716
Validation loss: 1.6562119914639382

Epoch: 6| Step: 4
Training loss: 0.32592424750328064
Validation loss: 1.6251919897653724

Epoch: 6| Step: 5
Training loss: 0.12423007190227509
Validation loss: 1.6395155665695027

Epoch: 6| Step: 6
Training loss: 0.10050220787525177
Validation loss: 1.6068936253106723

Epoch: 6| Step: 7
Training loss: 0.1352764517068863
Validation loss: 1.6058808347230316

Epoch: 6| Step: 8
Training loss: 0.1849147230386734
Validation loss: 1.6074463641771706

Epoch: 6| Step: 9
Training loss: 0.29043540358543396
Validation loss: 1.6233344167791388

Epoch: 6| Step: 10
Training loss: 0.2646716833114624
Validation loss: 1.6566145868711575

Epoch: 6| Step: 11
Training loss: 0.3146588206291199
Validation loss: 1.6552747526476461

Epoch: 6| Step: 12
Training loss: 0.26800960302352905
Validation loss: 1.6173687468292892

Epoch: 6| Step: 13
Training loss: 0.21281307935714722
Validation loss: 1.6205570595238799

Epoch: 311| Step: 0
Training loss: 0.18503138422966003
Validation loss: 1.6158443202254593

Epoch: 6| Step: 1
Training loss: 0.14419150352478027
Validation loss: 1.6250573627410396

Epoch: 6| Step: 2
Training loss: 0.3416067659854889
Validation loss: 1.664164585451926

Epoch: 6| Step: 3
Training loss: 0.21322879195213318
Validation loss: 1.6582542157942248

Epoch: 6| Step: 4
Training loss: 0.28631699085235596
Validation loss: 1.687616681539884

Epoch: 6| Step: 5
Training loss: 0.30510252714157104
Validation loss: 1.6665670064187819

Epoch: 6| Step: 6
Training loss: 0.3488510251045227
Validation loss: 1.638529444253573

Epoch: 6| Step: 7
Training loss: 0.18599718809127808
Validation loss: 1.6402525799248808

Epoch: 6| Step: 8
Training loss: 0.16945959627628326
Validation loss: 1.6825317182848532

Epoch: 6| Step: 9
Training loss: 0.3425982892513275
Validation loss: 1.704077846260481

Epoch: 6| Step: 10
Training loss: 0.44455069303512573
Validation loss: 1.7282213626369354

Epoch: 6| Step: 11
Training loss: 0.16363736987113953
Validation loss: 1.6910150307481007

Epoch: 6| Step: 12
Training loss: 0.33505260944366455
Validation loss: 1.6778479673529183

Epoch: 6| Step: 13
Training loss: 0.2750124931335449
Validation loss: 1.6289413238084445

Epoch: 312| Step: 0
Training loss: 0.18497547507286072
Validation loss: 1.6107887760285409

Epoch: 6| Step: 1
Training loss: 0.23465092480182648
Validation loss: 1.6208282363030218

Epoch: 6| Step: 2
Training loss: 0.20314612984657288
Validation loss: 1.6459190742943877

Epoch: 6| Step: 3
Training loss: 0.29426461458206177
Validation loss: 1.615332047144572

Epoch: 6| Step: 4
Training loss: 0.07824284583330154
Validation loss: 1.6405610999753397

Epoch: 6| Step: 5
Training loss: 0.32823023200035095
Validation loss: 1.6283662460183586

Epoch: 6| Step: 6
Training loss: 0.16198760271072388
Validation loss: 1.6116488620799074

Epoch: 6| Step: 7
Training loss: 0.18969792127609253
Validation loss: 1.6310156852968278

Epoch: 6| Step: 8
Training loss: 0.16719232499599457
Validation loss: 1.6324661277955579

Epoch: 6| Step: 9
Training loss: 0.28823143243789673
Validation loss: 1.6109998995257961

Epoch: 6| Step: 10
Training loss: 0.18121197819709778
Validation loss: 1.5978908923364454

Epoch: 6| Step: 11
Training loss: 0.21263675391674042
Validation loss: 1.6150043625985422

Epoch: 6| Step: 12
Training loss: 0.23226556181907654
Validation loss: 1.6129459488776423

Epoch: 6| Step: 13
Training loss: 0.05013172701001167
Validation loss: 1.610280143317356

Epoch: 313| Step: 0
Training loss: 0.12480759620666504
Validation loss: 1.6008237074780207

Epoch: 6| Step: 1
Training loss: 0.08777359873056412
Validation loss: 1.607777181492057

Epoch: 6| Step: 2
Training loss: 0.11959965527057648
Validation loss: 1.6149329934068906

Epoch: 6| Step: 3
Training loss: 0.24320203065872192
Validation loss: 1.5821231283167356

Epoch: 6| Step: 4
Training loss: 0.1257367730140686
Validation loss: 1.6396584703076271

Epoch: 6| Step: 5
Training loss: 0.2840277850627899
Validation loss: 1.6184278816305182

Epoch: 6| Step: 6
Training loss: 0.15729768574237823
Validation loss: 1.632406847451323

Epoch: 6| Step: 7
Training loss: 0.15809372067451477
Validation loss: 1.5849265436972342

Epoch: 6| Step: 8
Training loss: 0.1495717167854309
Validation loss: 1.612494840416857

Epoch: 6| Step: 9
Training loss: 0.22676366567611694
Validation loss: 1.619877762691949

Epoch: 6| Step: 10
Training loss: 0.2766229510307312
Validation loss: 1.6394902237000004

Epoch: 6| Step: 11
Training loss: 0.19428761303424835
Validation loss: 1.5944866723911737

Epoch: 6| Step: 12
Training loss: 0.2363567054271698
Validation loss: 1.618199025430987

Epoch: 6| Step: 13
Training loss: 0.21065980195999146
Validation loss: 1.5545099166131788

Epoch: 314| Step: 0
Training loss: 0.21358099579811096
Validation loss: 1.5785856503312305

Epoch: 6| Step: 1
Training loss: 0.20081230998039246
Validation loss: 1.6060210915022

Epoch: 6| Step: 2
Training loss: 0.16322538256645203
Validation loss: 1.5783489840005034

Epoch: 6| Step: 3
Training loss: 0.17167457938194275
Validation loss: 1.5939751498160823

Epoch: 6| Step: 4
Training loss: 0.259796142578125
Validation loss: 1.6086799598509265

Epoch: 6| Step: 5
Training loss: 0.23531463742256165
Validation loss: 1.6199648316188524

Epoch: 6| Step: 6
Training loss: 0.17413142323493958
Validation loss: 1.6140802675677883

Epoch: 6| Step: 7
Training loss: 0.09516830742359161
Validation loss: 1.6210991144180298

Epoch: 6| Step: 8
Training loss: 0.17959484457969666
Validation loss: 1.6244047662263275

Epoch: 6| Step: 9
Training loss: 0.16943921148777008
Validation loss: 1.6284660895665486

Epoch: 6| Step: 10
Training loss: 0.13402292132377625
Validation loss: 1.647927075304011

Epoch: 6| Step: 11
Training loss: 0.25983941555023193
Validation loss: 1.6387876451656382

Epoch: 6| Step: 12
Training loss: 0.13761422038078308
Validation loss: 1.6658028659000192

Epoch: 6| Step: 13
Training loss: 0.22791904211044312
Validation loss: 1.6700259036915277

Epoch: 315| Step: 0
Training loss: 0.2248794436454773
Validation loss: 1.6643083980006557

Epoch: 6| Step: 1
Training loss: 0.20066878199577332
Validation loss: 1.6459706034711612

Epoch: 6| Step: 2
Training loss: 0.16846628487110138
Validation loss: 1.626343797611934

Epoch: 6| Step: 3
Training loss: 0.17672774195671082
Validation loss: 1.6337125993544055

Epoch: 6| Step: 4
Training loss: 0.22606872022151947
Validation loss: 1.64870770067297

Epoch: 6| Step: 5
Training loss: 0.17178502678871155
Validation loss: 1.6146285072449715

Epoch: 6| Step: 6
Training loss: 0.1038660779595375
Validation loss: 1.6170325343326857

Epoch: 6| Step: 7
Training loss: 0.23543104529380798
Validation loss: 1.620098029413531

Epoch: 6| Step: 8
Training loss: 0.29920533299446106
Validation loss: 1.6357760698564592

Epoch: 6| Step: 9
Training loss: 0.22889010608196259
Validation loss: 1.5810417616239159

Epoch: 6| Step: 10
Training loss: 0.13692829012870789
Validation loss: 1.5887551974224787

Epoch: 6| Step: 11
Training loss: 0.19994328916072845
Validation loss: 1.598152522117861

Epoch: 6| Step: 12
Training loss: 0.15307453274726868
Validation loss: 1.5704496881013275

Epoch: 6| Step: 13
Training loss: 0.1332361102104187
Validation loss: 1.583985686302185

Epoch: 316| Step: 0
Training loss: 0.12620532512664795
Validation loss: 1.5905794866623417

Epoch: 6| Step: 1
Training loss: 0.1690295934677124
Validation loss: 1.6088552718521447

Epoch: 6| Step: 2
Training loss: 0.14754226803779602
Validation loss: 1.6203560239525252

Epoch: 6| Step: 3
Training loss: 0.2596661150455475
Validation loss: 1.64581230250738

Epoch: 6| Step: 4
Training loss: 0.3497732877731323
Validation loss: 1.661082883034983

Epoch: 6| Step: 5
Training loss: 0.16157536208629608
Validation loss: 1.6687711977189588

Epoch: 6| Step: 6
Training loss: 0.2481909692287445
Validation loss: 1.6819487284588557

Epoch: 6| Step: 7
Training loss: 0.16441771388053894
Validation loss: 1.6618685760805685

Epoch: 6| Step: 8
Training loss: 0.15341491997241974
Validation loss: 1.671397070730886

Epoch: 6| Step: 9
Training loss: 0.1739102005958557
Validation loss: 1.675075779679001

Epoch: 6| Step: 10
Training loss: 0.21741411089897156
Validation loss: 1.7004849141643894

Epoch: 6| Step: 11
Training loss: 0.30295509099960327
Validation loss: 1.6692251377208258

Epoch: 6| Step: 12
Training loss: 0.28381186723709106
Validation loss: 1.6637932690241004

Epoch: 6| Step: 13
Training loss: 0.12703344225883484
Validation loss: 1.6557353414515013

Epoch: 317| Step: 0
Training loss: 0.12789206206798553
Validation loss: 1.6407408842476465

Epoch: 6| Step: 1
Training loss: 0.18828967213630676
Validation loss: 1.6578778041306363

Epoch: 6| Step: 2
Training loss: 0.2479463815689087
Validation loss: 1.6384206965405455

Epoch: 6| Step: 3
Training loss: 0.17647585272789001
Validation loss: 1.6417229008930985

Epoch: 6| Step: 4
Training loss: 0.15654367208480835
Validation loss: 1.6527843295886953

Epoch: 6| Step: 5
Training loss: 0.17831961810588837
Validation loss: 1.6331824371891637

Epoch: 6| Step: 6
Training loss: 0.22921119630336761
Validation loss: 1.651268668072198

Epoch: 6| Step: 7
Training loss: 0.16613297164440155
Validation loss: 1.6204205815510084

Epoch: 6| Step: 8
Training loss: 0.21866394579410553
Validation loss: 1.6312834883248934

Epoch: 6| Step: 9
Training loss: 0.23997846245765686
Validation loss: 1.5987987723401798

Epoch: 6| Step: 10
Training loss: 0.16233140230178833
Validation loss: 1.6262801180603683

Epoch: 6| Step: 11
Training loss: 0.2241438925266266
Validation loss: 1.62634664581668

Epoch: 6| Step: 12
Training loss: 0.21866357326507568
Validation loss: 1.6229892251312092

Epoch: 6| Step: 13
Training loss: 0.16359880566596985
Validation loss: 1.6114081772424842

Epoch: 318| Step: 0
Training loss: 0.15388135612010956
Validation loss: 1.6221954143175514

Epoch: 6| Step: 1
Training loss: 0.1871407926082611
Validation loss: 1.6044391162933842

Epoch: 6| Step: 2
Training loss: 0.1325293928384781
Validation loss: 1.592290191240208

Epoch: 6| Step: 3
Training loss: 0.18648290634155273
Validation loss: 1.5974476927070207

Epoch: 6| Step: 4
Training loss: 0.18175555765628815
Validation loss: 1.5823709035432467

Epoch: 6| Step: 5
Training loss: 0.2202402502298355
Validation loss: 1.608776254038657

Epoch: 6| Step: 6
Training loss: 0.14796532690525055
Validation loss: 1.6112732912904473

Epoch: 6| Step: 7
Training loss: 0.2104072868824005
Validation loss: 1.6243078221556961

Epoch: 6| Step: 8
Training loss: 0.19952821731567383
Validation loss: 1.6311173605662521

Epoch: 6| Step: 9
Training loss: 0.26593896746635437
Validation loss: 1.652413986062491

Epoch: 6| Step: 10
Training loss: 0.14069636166095734
Validation loss: 1.6313668451001566

Epoch: 6| Step: 11
Training loss: 0.2911083698272705
Validation loss: 1.6113361671406736

Epoch: 6| Step: 12
Training loss: 0.266224205493927
Validation loss: 1.6265923207806003

Epoch: 6| Step: 13
Training loss: 0.14375093579292297
Validation loss: 1.606701026680649

Epoch: 319| Step: 0
Training loss: 0.14790865778923035
Validation loss: 1.5838991390761508

Epoch: 6| Step: 1
Training loss: 0.17156291007995605
Validation loss: 1.5819398305749381

Epoch: 6| Step: 2
Training loss: 0.16388413310050964
Validation loss: 1.5722425573615617

Epoch: 6| Step: 3
Training loss: 0.2119484543800354
Validation loss: 1.581838769938356

Epoch: 6| Step: 4
Training loss: 0.15712860226631165
Validation loss: 1.583879465697914

Epoch: 6| Step: 5
Training loss: 0.0926770567893982
Validation loss: 1.587179272405563

Epoch: 6| Step: 6
Training loss: 0.14075343310832977
Validation loss: 1.6091084390558221

Epoch: 6| Step: 7
Training loss: 0.16439007222652435
Validation loss: 1.593520087580527

Epoch: 6| Step: 8
Training loss: 0.23580852150917053
Validation loss: 1.5847771244664346

Epoch: 6| Step: 9
Training loss: 0.10800749808549881
Validation loss: 1.599375795292598

Epoch: 6| Step: 10
Training loss: 0.18391795456409454
Validation loss: 1.5757112387687928

Epoch: 6| Step: 11
Training loss: 0.1361759752035141
Validation loss: 1.6002107294656898

Epoch: 6| Step: 12
Training loss: 0.18778479099273682
Validation loss: 1.5881863717109925

Epoch: 6| Step: 13
Training loss: 0.22515654563903809
Validation loss: 1.5920310930539203

Epoch: 320| Step: 0
Training loss: 0.17415127158164978
Validation loss: 1.5813739133137528

Epoch: 6| Step: 1
Training loss: 0.13400611281394958
Validation loss: 1.5958698718778548

Epoch: 6| Step: 2
Training loss: 0.24916590750217438
Validation loss: 1.5610247786327074

Epoch: 6| Step: 3
Training loss: 0.2030830681324005
Validation loss: 1.560529262788834

Epoch: 6| Step: 4
Training loss: 0.1559855043888092
Validation loss: 1.6022018066016577

Epoch: 6| Step: 5
Training loss: 0.14414618909358978
Validation loss: 1.6373887754255725

Epoch: 6| Step: 6
Training loss: 0.29104000329971313
Validation loss: 1.6151897727802236

Epoch: 6| Step: 7
Training loss: 0.2968156933784485
Validation loss: 1.6414341151073415

Epoch: 6| Step: 8
Training loss: 0.29050132632255554
Validation loss: 1.625625778270024

Epoch: 6| Step: 9
Training loss: 0.168384850025177
Validation loss: 1.605259579996909

Epoch: 6| Step: 10
Training loss: 0.07321818172931671
Validation loss: 1.571090393809862

Epoch: 6| Step: 11
Training loss: 0.09340155124664307
Validation loss: 1.612112315752173

Epoch: 6| Step: 12
Training loss: 0.12685297429561615
Validation loss: 1.5841476519902546

Epoch: 6| Step: 13
Training loss: 0.32658231258392334
Validation loss: 1.616297407816815

Epoch: 321| Step: 0
Training loss: 0.2347412109375
Validation loss: 1.6452596264500772

Epoch: 6| Step: 1
Training loss: 0.18755097687244415
Validation loss: 1.6249580370482577

Epoch: 6| Step: 2
Training loss: 0.2579745650291443
Validation loss: 1.6401412256302372

Epoch: 6| Step: 3
Training loss: 0.18757301568984985
Validation loss: 1.6115015963072419

Epoch: 6| Step: 4
Training loss: 0.19398345053195953
Validation loss: 1.614897669002574

Epoch: 6| Step: 5
Training loss: 0.1756654977798462
Validation loss: 1.634782575791882

Epoch: 6| Step: 6
Training loss: 0.19088318943977356
Validation loss: 1.6132244845872283

Epoch: 6| Step: 7
Training loss: 0.20626506209373474
Validation loss: 1.6193563592049383

Epoch: 6| Step: 8
Training loss: 0.19168679416179657
Validation loss: 1.6477544974255305

Epoch: 6| Step: 9
Training loss: 0.20017141103744507
Validation loss: 1.631045110764042

Epoch: 6| Step: 10
Training loss: 0.1289309561252594
Validation loss: 1.6173381946420158

Epoch: 6| Step: 11
Training loss: 0.23226958513259888
Validation loss: 1.5931662346727105

Epoch: 6| Step: 12
Training loss: 0.1895104944705963
Validation loss: 1.603730450394333

Epoch: 6| Step: 13
Training loss: 0.33048298954963684
Validation loss: 1.6086690964237336

Epoch: 322| Step: 0
Training loss: 0.17064520716667175
Validation loss: 1.6206445027423162

Epoch: 6| Step: 1
Training loss: 0.24227862060070038
Validation loss: 1.6222079210383917

Epoch: 6| Step: 2
Training loss: 0.17770540714263916
Validation loss: 1.6069028845397375

Epoch: 6| Step: 3
Training loss: 0.12946413457393646
Validation loss: 1.6252412616565663

Epoch: 6| Step: 4
Training loss: 0.0900648906826973
Validation loss: 1.6380172519273655

Epoch: 6| Step: 5
Training loss: 0.15722137689590454
Validation loss: 1.6288673352169734

Epoch: 6| Step: 6
Training loss: 0.12254813313484192
Validation loss: 1.6365107592716013

Epoch: 6| Step: 7
Training loss: 0.229914128780365
Validation loss: 1.6566382915742937

Epoch: 6| Step: 8
Training loss: 0.273555189371109
Validation loss: 1.6530406782704015

Epoch: 6| Step: 9
Training loss: 0.13963520526885986
Validation loss: 1.6412655845765145

Epoch: 6| Step: 10
Training loss: 0.171482652425766
Validation loss: 1.6134590025871032

Epoch: 6| Step: 11
Training loss: 0.19219312071800232
Validation loss: 1.637383072606979

Epoch: 6| Step: 12
Training loss: 0.20873454213142395
Validation loss: 1.635347959815815

Epoch: 6| Step: 13
Training loss: 0.2980581820011139
Validation loss: 1.5841635401530931

Epoch: 323| Step: 0
Training loss: 0.21949893236160278
Validation loss: 1.6049893543284426

Epoch: 6| Step: 1
Training loss: 0.23786723613739014
Validation loss: 1.5801500812653573

Epoch: 6| Step: 2
Training loss: 0.24509571492671967
Validation loss: 1.5635337150225075

Epoch: 6| Step: 3
Training loss: 0.10279062390327454
Validation loss: 1.6099844728746722

Epoch: 6| Step: 4
Training loss: 0.16643716394901276
Validation loss: 1.5678251571552728

Epoch: 6| Step: 5
Training loss: 0.19494053721427917
Validation loss: 1.5896534586465487

Epoch: 6| Step: 6
Training loss: 0.15028983354568481
Validation loss: 1.5876429734691497

Epoch: 6| Step: 7
Training loss: 0.15610873699188232
Validation loss: 1.620538652584117

Epoch: 6| Step: 8
Training loss: 0.1739473193883896
Validation loss: 1.604273025707532

Epoch: 6| Step: 9
Training loss: 0.14305655658245087
Validation loss: 1.6043411980393112

Epoch: 6| Step: 10
Training loss: 0.24805991351604462
Validation loss: 1.616596665433658

Epoch: 6| Step: 11
Training loss: 0.13838107883930206
Validation loss: 1.6212675404805008

Epoch: 6| Step: 12
Training loss: 0.23497813940048218
Validation loss: 1.6102089702442128

Epoch: 6| Step: 13
Training loss: 0.1396464705467224
Validation loss: 1.5798727363668463

Epoch: 324| Step: 0
Training loss: 0.22155654430389404
Validation loss: 1.5847091751713906

Epoch: 6| Step: 1
Training loss: 0.08222327381372452
Validation loss: 1.6318204377287178

Epoch: 6| Step: 2
Training loss: 0.16069111227989197
Validation loss: 1.6321925693942654

Epoch: 6| Step: 3
Training loss: 0.23419694602489471
Validation loss: 1.678441616796678

Epoch: 6| Step: 4
Training loss: 0.22756020724773407
Validation loss: 1.604476927429117

Epoch: 6| Step: 5
Training loss: 0.12786582112312317
Validation loss: 1.625135633253282

Epoch: 6| Step: 6
Training loss: 0.2102966010570526
Validation loss: 1.6079677856096657

Epoch: 6| Step: 7
Training loss: 0.09949764609336853
Validation loss: 1.6128521452667892

Epoch: 6| Step: 8
Training loss: 0.2261679470539093
Validation loss: 1.6466206568543629

Epoch: 6| Step: 9
Training loss: 0.11909987777471542
Validation loss: 1.6423874042367423

Epoch: 6| Step: 10
Training loss: 0.17074085772037506
Validation loss: 1.6396088600158691

Epoch: 6| Step: 11
Training loss: 0.14426946640014648
Validation loss: 1.610339476216224

Epoch: 6| Step: 12
Training loss: 0.2043590545654297
Validation loss: 1.618489824315553

Epoch: 6| Step: 13
Training loss: 0.1384943276643753
Validation loss: 1.576220545717465

Epoch: 325| Step: 0
Training loss: 0.170654296875
Validation loss: 1.5906014186079784

Epoch: 6| Step: 1
Training loss: 0.13567037880420685
Validation loss: 1.5804192917321318

Epoch: 6| Step: 2
Training loss: 0.13971231877803802
Validation loss: 1.5817789057249665

Epoch: 6| Step: 3
Training loss: 0.10631564259529114
Validation loss: 1.5671772110846736

Epoch: 6| Step: 4
Training loss: 0.1889318823814392
Validation loss: 1.5758226122907413

Epoch: 6| Step: 5
Training loss: 0.27843794226646423
Validation loss: 1.5178537919957151

Epoch: 6| Step: 6
Training loss: 0.17548266053199768
Validation loss: 1.558189288262398

Epoch: 6| Step: 7
Training loss: 0.1496683955192566
Validation loss: 1.5603087153486026

Epoch: 6| Step: 8
Training loss: 0.13622786104679108
Validation loss: 1.574650643974222

Epoch: 6| Step: 9
Training loss: 0.0966191291809082
Validation loss: 1.5638636722359607

Epoch: 6| Step: 10
Training loss: 0.2820509970188141
Validation loss: 1.549975597730247

Epoch: 6| Step: 11
Training loss: 0.19250503182411194
Validation loss: 1.552928945069672

Epoch: 6| Step: 12
Training loss: 0.27430644631385803
Validation loss: 1.5864572858297696

Epoch: 6| Step: 13
Training loss: 0.2628878355026245
Validation loss: 1.5610369533620856

Epoch: 326| Step: 0
Training loss: 0.2006990760564804
Validation loss: 1.582383228886512

Epoch: 6| Step: 1
Training loss: 0.10683320462703705
Validation loss: 1.596323424769986

Epoch: 6| Step: 2
Training loss: 0.23868098855018616
Validation loss: 1.6121422859930223

Epoch: 6| Step: 3
Training loss: 0.13095614314079285
Validation loss: 1.6349793070106096

Epoch: 6| Step: 4
Training loss: 0.2124747931957245
Validation loss: 1.6300907058100547

Epoch: 6| Step: 5
Training loss: 0.21132391691207886
Validation loss: 1.5959087879427019

Epoch: 6| Step: 6
Training loss: 0.23702166974544525
Validation loss: 1.5982186640462568

Epoch: 6| Step: 7
Training loss: 0.23283366858959198
Validation loss: 1.6235321260267688

Epoch: 6| Step: 8
Training loss: 0.20207402110099792
Validation loss: 1.6129594015818771

Epoch: 6| Step: 9
Training loss: 0.08791930973529816
Validation loss: 1.619588113600208

Epoch: 6| Step: 10
Training loss: 0.20479273796081543
Validation loss: 1.631040027064662

Epoch: 6| Step: 11
Training loss: 0.16266724467277527
Validation loss: 1.6096845108975646

Epoch: 6| Step: 12
Training loss: 0.15163829922676086
Validation loss: 1.6285489451500677

Epoch: 6| Step: 13
Training loss: 0.12225408107042313
Validation loss: 1.5854581645739976

Epoch: 327| Step: 0
Training loss: 0.11879000067710876
Validation loss: 1.6028949752930672

Epoch: 6| Step: 1
Training loss: 0.16014134883880615
Validation loss: 1.5827762952414892

Epoch: 6| Step: 2
Training loss: 0.18426509201526642
Validation loss: 1.585542994160806

Epoch: 6| Step: 3
Training loss: 0.23618482053279877
Validation loss: 1.556151182420792

Epoch: 6| Step: 4
Training loss: 0.08968311548233032
Validation loss: 1.5691704724424629

Epoch: 6| Step: 5
Training loss: 0.1634727567434311
Validation loss: 1.5668774638124692

Epoch: 6| Step: 6
Training loss: 0.15632686018943787
Validation loss: 1.6051894387891215

Epoch: 6| Step: 7
Training loss: 0.19248676300048828
Validation loss: 1.5741020094963811

Epoch: 6| Step: 8
Training loss: 0.12200294435024261
Validation loss: 1.5944927943650113

Epoch: 6| Step: 9
Training loss: 0.23393139243125916
Validation loss: 1.5877160077453942

Epoch: 6| Step: 10
Training loss: 0.16177624464035034
Validation loss: 1.5655686111860379

Epoch: 6| Step: 11
Training loss: 0.18568222224712372
Validation loss: 1.6279396139165407

Epoch: 6| Step: 12
Training loss: 0.2835450768470764
Validation loss: 1.5889454528849611

Epoch: 6| Step: 13
Training loss: 0.19435402750968933
Validation loss: 1.6040411867121214

Epoch: 328| Step: 0
Training loss: 0.12405838817358017
Validation loss: 1.579164852378189

Epoch: 6| Step: 1
Training loss: 0.2033035159111023
Validation loss: 1.5417232526245939

Epoch: 6| Step: 2
Training loss: 0.23739482462406158
Validation loss: 1.5926716763486144

Epoch: 6| Step: 3
Training loss: 0.3110696077346802
Validation loss: 1.611721061891125

Epoch: 6| Step: 4
Training loss: 0.1473984718322754
Validation loss: 1.593280497417655

Epoch: 6| Step: 5
Training loss: 0.12391138076782227
Validation loss: 1.5986751433341735

Epoch: 6| Step: 6
Training loss: 0.12005409598350525
Validation loss: 1.6090923483653734

Epoch: 6| Step: 7
Training loss: 0.18051326274871826
Validation loss: 1.6009212616951234

Epoch: 6| Step: 8
Training loss: 0.16912320256233215
Validation loss: 1.5892773802562425

Epoch: 6| Step: 9
Training loss: 0.25339192152023315
Validation loss: 1.6126149213442238

Epoch: 6| Step: 10
Training loss: 0.2130437046289444
Validation loss: 1.6267546646056636

Epoch: 6| Step: 11
Training loss: 0.18576908111572266
Validation loss: 1.6300663589149393

Epoch: 6| Step: 12
Training loss: 0.1173848882317543
Validation loss: 1.6024916889846965

Epoch: 6| Step: 13
Training loss: 0.17659761011600494
Validation loss: 1.6135363239114002

Epoch: 329| Step: 0
Training loss: 0.10381840914487839
Validation loss: 1.6029044902452858

Epoch: 6| Step: 1
Training loss: 0.20391179621219635
Validation loss: 1.6392587615597634

Epoch: 6| Step: 2
Training loss: 0.15374037623405457
Validation loss: 1.6144547193281111

Epoch: 6| Step: 3
Training loss: 0.1311335265636444
Validation loss: 1.665167083022415

Epoch: 6| Step: 4
Training loss: 0.30947205424308777
Validation loss: 1.6412418638506243

Epoch: 6| Step: 5
Training loss: 0.22956500947475433
Validation loss: 1.6752339293879848

Epoch: 6| Step: 6
Training loss: 0.14256241917610168
Validation loss: 1.6477515030932683

Epoch: 6| Step: 7
Training loss: 0.1311362087726593
Validation loss: 1.6391501144696308

Epoch: 6| Step: 8
Training loss: 0.19118568301200867
Validation loss: 1.6023656975838445

Epoch: 6| Step: 9
Training loss: 0.1781570315361023
Validation loss: 1.594231031274283

Epoch: 6| Step: 10
Training loss: 0.18445844948291779
Validation loss: 1.6184536013551938

Epoch: 6| Step: 11
Training loss: 0.26699280738830566
Validation loss: 1.6490004216471026

Epoch: 6| Step: 12
Training loss: 0.32014453411102295
Validation loss: 1.6588951592804284

Epoch: 6| Step: 13
Training loss: 0.09354232251644135
Validation loss: 1.6521782746879004

Epoch: 330| Step: 0
Training loss: 0.17718586325645447
Validation loss: 1.6241307053514706

Epoch: 6| Step: 1
Training loss: 0.14578711986541748
Validation loss: 1.5837696406149095

Epoch: 6| Step: 2
Training loss: 0.1678711473941803
Validation loss: 1.6350020330439332

Epoch: 6| Step: 3
Training loss: 0.17582526803016663
Validation loss: 1.6385836729439356

Epoch: 6| Step: 4
Training loss: 0.2347697615623474
Validation loss: 1.6312683833542692

Epoch: 6| Step: 5
Training loss: 0.22068260610103607
Validation loss: 1.6488421488833684

Epoch: 6| Step: 6
Training loss: 0.14009356498718262
Validation loss: 1.6596669907210975

Epoch: 6| Step: 7
Training loss: 0.20976370573043823
Validation loss: 1.6688071168879026

Epoch: 6| Step: 8
Training loss: 0.1191137284040451
Validation loss: 1.6675210742540256

Epoch: 6| Step: 9
Training loss: 0.1436809003353119
Validation loss: 1.6468652358619116

Epoch: 6| Step: 10
Training loss: 0.29411935806274414
Validation loss: 1.6611019206303421

Epoch: 6| Step: 11
Training loss: 0.16583466529846191
Validation loss: 1.6852935385960404

Epoch: 6| Step: 12
Training loss: 0.23012983798980713
Validation loss: 1.6766247762146818

Epoch: 6| Step: 13
Training loss: 0.1903572976589203
Validation loss: 1.6595000810520624

Epoch: 331| Step: 0
Training loss: 0.15362131595611572
Validation loss: 1.636710456622544

Epoch: 6| Step: 1
Training loss: 0.14616331458091736
Validation loss: 1.6571042845326085

Epoch: 6| Step: 2
Training loss: 0.18086442351341248
Validation loss: 1.6478065034394622

Epoch: 6| Step: 3
Training loss: 0.21806415915489197
Validation loss: 1.6287060258209065

Epoch: 6| Step: 4
Training loss: 0.17773014307022095
Validation loss: 1.6262738461135535

Epoch: 6| Step: 5
Training loss: 0.17083026468753815
Validation loss: 1.596476157506307

Epoch: 6| Step: 6
Training loss: 0.1425335705280304
Validation loss: 1.6025490273711502

Epoch: 6| Step: 7
Training loss: 0.14831511676311493
Validation loss: 1.6538376385165798

Epoch: 6| Step: 8
Training loss: 0.22945232689380646
Validation loss: 1.5919673276203934

Epoch: 6| Step: 9
Training loss: 0.3421063721179962
Validation loss: 1.613707216837073

Epoch: 6| Step: 10
Training loss: 0.11988694220781326
Validation loss: 1.5977210267897575

Epoch: 6| Step: 11
Training loss: 0.26977741718292236
Validation loss: 1.591351145057268

Epoch: 6| Step: 12
Training loss: 0.16629450023174286
Validation loss: 1.6030295036172355

Epoch: 6| Step: 13
Training loss: 0.13242384791374207
Validation loss: 1.600515237418554

Epoch: 332| Step: 0
Training loss: 0.11187933385372162
Validation loss: 1.6331118563170075

Epoch: 6| Step: 1
Training loss: 0.11899791657924652
Validation loss: 1.6914757733703942

Epoch: 6| Step: 2
Training loss: 0.35164493322372437
Validation loss: 1.6582534684929797

Epoch: 6| Step: 3
Training loss: 0.1967596709728241
Validation loss: 1.6370937196157311

Epoch: 6| Step: 4
Training loss: 0.21281498670578003
Validation loss: 1.6393900757194848

Epoch: 6| Step: 5
Training loss: 0.16735434532165527
Validation loss: 1.5947010773484425

Epoch: 6| Step: 6
Training loss: 0.1412133425474167
Validation loss: 1.5781202829012306

Epoch: 6| Step: 7
Training loss: 0.16209739446640015
Validation loss: 1.5877813485360914

Epoch: 6| Step: 8
Training loss: 0.2091279774904251
Validation loss: 1.5792505420664305

Epoch: 6| Step: 9
Training loss: 0.22455890476703644
Validation loss: 1.5847229598670878

Epoch: 6| Step: 10
Training loss: 0.17001739144325256
Validation loss: 1.600758296187206

Epoch: 6| Step: 11
Training loss: 0.14931893348693848
Validation loss: 1.5830971758852723

Epoch: 6| Step: 12
Training loss: 0.20980089902877808
Validation loss: 1.6201966731779036

Epoch: 6| Step: 13
Training loss: 0.22574397921562195
Validation loss: 1.6543066245253368

Epoch: 333| Step: 0
Training loss: 0.16757582128047943
Validation loss: 1.6341625772496706

Epoch: 6| Step: 1
Training loss: 0.14856505393981934
Validation loss: 1.674131521614649

Epoch: 6| Step: 2
Training loss: 0.1526263803243637
Validation loss: 1.6286722357555101

Epoch: 6| Step: 3
Training loss: 0.19585834443569183
Validation loss: 1.627592605929221

Epoch: 6| Step: 4
Training loss: 0.17427793145179749
Validation loss: 1.6228722026271205

Epoch: 6| Step: 5
Training loss: 0.10748715698719025
Validation loss: 1.620897885291807

Epoch: 6| Step: 6
Training loss: 0.3610419034957886
Validation loss: 1.622980426075638

Epoch: 6| Step: 7
Training loss: 0.14850899577140808
Validation loss: 1.5992550260277205

Epoch: 6| Step: 8
Training loss: 0.16742223501205444
Validation loss: 1.6024837455441874

Epoch: 6| Step: 9
Training loss: 0.15804864466190338
Validation loss: 1.6122056450895084

Epoch: 6| Step: 10
Training loss: 0.101270392537117
Validation loss: 1.5947670949402677

Epoch: 6| Step: 11
Training loss: 0.10147769749164581
Validation loss: 1.5942458888535858

Epoch: 6| Step: 12
Training loss: 0.2175559401512146
Validation loss: 1.5839467958737445

Epoch: 6| Step: 13
Training loss: 0.22913575172424316
Validation loss: 1.5633882745619743

Epoch: 334| Step: 0
Training loss: 0.3642469644546509
Validation loss: 1.5969101126476

Epoch: 6| Step: 1
Training loss: 0.263985812664032
Validation loss: 1.6094273726145427

Epoch: 6| Step: 2
Training loss: 0.1376453936100006
Validation loss: 1.609813770940227

Epoch: 6| Step: 3
Training loss: 0.1590128242969513
Validation loss: 1.583759041242702

Epoch: 6| Step: 4
Training loss: 0.21956956386566162
Validation loss: 1.5863504345699022

Epoch: 6| Step: 5
Training loss: 0.17566679418087006
Validation loss: 1.5884762758849769

Epoch: 6| Step: 6
Training loss: 0.23048993945121765
Validation loss: 1.6130548895046275

Epoch: 6| Step: 7
Training loss: 0.19630341231822968
Validation loss: 1.6131277084350586

Epoch: 6| Step: 8
Training loss: 0.21818187832832336
Validation loss: 1.6143313345088754

Epoch: 6| Step: 9
Training loss: 0.2411903738975525
Validation loss: 1.6035870185462378

Epoch: 6| Step: 10
Training loss: 0.20571812987327576
Validation loss: 1.5985383384971208

Epoch: 6| Step: 11
Training loss: 0.19698435068130493
Validation loss: 1.5743174578553887

Epoch: 6| Step: 12
Training loss: 0.10998173803091049
Validation loss: 1.5808459840795046

Epoch: 6| Step: 13
Training loss: 0.21959199011325836
Validation loss: 1.593567071422454

Epoch: 335| Step: 0
Training loss: 0.3168157935142517
Validation loss: 1.6178728265147055

Epoch: 6| Step: 1
Training loss: 0.12395065277814865
Validation loss: 1.621356104009895

Epoch: 6| Step: 2
Training loss: 0.20749138295650482
Validation loss: 1.5841580693439772

Epoch: 6| Step: 3
Training loss: 0.21144595742225647
Validation loss: 1.560906574290286

Epoch: 6| Step: 4
Training loss: 0.13701264560222626
Validation loss: 1.5659895097055743

Epoch: 6| Step: 5
Training loss: 0.2633136510848999
Validation loss: 1.5611088686091925

Epoch: 6| Step: 6
Training loss: 0.12268047779798508
Validation loss: 1.603024007171713

Epoch: 6| Step: 7
Training loss: 0.2725558280944824
Validation loss: 1.5892276584461171

Epoch: 6| Step: 8
Training loss: 0.2153370976448059
Validation loss: 1.6119979568707046

Epoch: 6| Step: 9
Training loss: 0.16446518898010254
Validation loss: 1.6038876477108206

Epoch: 6| Step: 10
Training loss: 0.13935628533363342
Validation loss: 1.5956951302866782

Epoch: 6| Step: 11
Training loss: 0.16623732447624207
Validation loss: 1.5840655424261605

Epoch: 6| Step: 12
Training loss: 0.2458493709564209
Validation loss: 1.5625642768798336

Epoch: 6| Step: 13
Training loss: 0.07075998932123184
Validation loss: 1.561650937603366

Epoch: 336| Step: 0
Training loss: 0.26035356521606445
Validation loss: 1.5863113057228826

Epoch: 6| Step: 1
Training loss: 0.1456354260444641
Validation loss: 1.5635139570441297

Epoch: 6| Step: 2
Training loss: 0.12051118910312653
Validation loss: 1.5820250363760098

Epoch: 6| Step: 3
Training loss: 0.15013821423053741
Validation loss: 1.5632001853758288

Epoch: 6| Step: 4
Training loss: 0.1880485862493515
Validation loss: 1.545957206397928

Epoch: 6| Step: 5
Training loss: 0.1980626881122589
Validation loss: 1.5482697973969162

Epoch: 6| Step: 6
Training loss: 0.1348617523908615
Validation loss: 1.566543391955796

Epoch: 6| Step: 7
Training loss: 0.2120145708322525
Validation loss: 1.57212532079348

Epoch: 6| Step: 8
Training loss: 0.19354218244552612
Validation loss: 1.5876665064083633

Epoch: 6| Step: 9
Training loss: 0.1361810266971588
Validation loss: 1.5767090378269073

Epoch: 6| Step: 10
Training loss: 0.1878792941570282
Validation loss: 1.6004972393794725

Epoch: 6| Step: 11
Training loss: 0.18092137575149536
Validation loss: 1.5730684316286476

Epoch: 6| Step: 12
Training loss: 0.19361203908920288
Validation loss: 1.5783387102106565

Epoch: 6| Step: 13
Training loss: 0.0978662446141243
Validation loss: 1.5321850699763144

Epoch: 337| Step: 0
Training loss: 0.15882615745067596
Validation loss: 1.5428053781550417

Epoch: 6| Step: 1
Training loss: 0.16475237905979156
Validation loss: 1.5431484009629937

Epoch: 6| Step: 2
Training loss: 0.17563310265541077
Validation loss: 1.5749581321593253

Epoch: 6| Step: 3
Training loss: 0.12753435969352722
Validation loss: 1.5940019815198836

Epoch: 6| Step: 4
Training loss: 0.21786542236804962
Validation loss: 1.5975670917059785

Epoch: 6| Step: 5
Training loss: 0.407703161239624
Validation loss: 1.5953980479189145

Epoch: 6| Step: 6
Training loss: 0.12324389815330505
Validation loss: 1.5766211120031213

Epoch: 6| Step: 7
Training loss: 0.24332687258720398
Validation loss: 1.5817424751097156

Epoch: 6| Step: 8
Training loss: 0.22786051034927368
Validation loss: 1.573718006892871

Epoch: 6| Step: 9
Training loss: 0.09767422825098038
Validation loss: 1.5618186984010922

Epoch: 6| Step: 10
Training loss: 0.11646910011768341
Validation loss: 1.5813143817327355

Epoch: 6| Step: 11
Training loss: 0.20044073462486267
Validation loss: 1.5784553879050798

Epoch: 6| Step: 12
Training loss: 0.17305032908916473
Validation loss: 1.6051087712728849

Epoch: 6| Step: 13
Training loss: 0.23405152559280396
Validation loss: 1.5997849484925628

Epoch: 338| Step: 0
Training loss: 0.16644425690174103
Validation loss: 1.574332211607246

Epoch: 6| Step: 1
Training loss: 0.1179618090391159
Validation loss: 1.5487952296451857

Epoch: 6| Step: 2
Training loss: 0.2290458083152771
Validation loss: 1.5225561780314292

Epoch: 6| Step: 3
Training loss: 0.1060335710644722
Validation loss: 1.5154843458565332

Epoch: 6| Step: 4
Training loss: 0.08780387043952942
Validation loss: 1.5407704666096678

Epoch: 6| Step: 5
Training loss: 0.12061065435409546
Validation loss: 1.5628812569443897

Epoch: 6| Step: 6
Training loss: 0.17142538726329803
Validation loss: 1.55742722429255

Epoch: 6| Step: 7
Training loss: 0.16957595944404602
Validation loss: 1.5632749590822446

Epoch: 6| Step: 8
Training loss: 0.15950632095336914
Validation loss: 1.566740491056955

Epoch: 6| Step: 9
Training loss: 0.17453381419181824
Validation loss: 1.5531811009171188

Epoch: 6| Step: 10
Training loss: 0.2354479283094406
Validation loss: 1.5743012171919628

Epoch: 6| Step: 11
Training loss: 0.12518127262592316
Validation loss: 1.5855761189614572

Epoch: 6| Step: 12
Training loss: 0.188705712556839
Validation loss: 1.5752346695110362

Epoch: 6| Step: 13
Training loss: 0.09674212336540222
Validation loss: 1.5755500665275

Epoch: 339| Step: 0
Training loss: 0.18254533410072327
Validation loss: 1.583184415294278

Epoch: 6| Step: 1
Training loss: 0.1765395700931549
Validation loss: 1.5784043150563394

Epoch: 6| Step: 2
Training loss: 0.07146415114402771
Validation loss: 1.5778676232983988

Epoch: 6| Step: 3
Training loss: 0.25978216528892517
Validation loss: 1.552885211924071

Epoch: 6| Step: 4
Training loss: 0.18961802124977112
Validation loss: 1.5658127236109909

Epoch: 6| Step: 5
Training loss: 0.12613868713378906
Validation loss: 1.5461583445149083

Epoch: 6| Step: 6
Training loss: 0.18038183450698853
Validation loss: 1.5435187701256043

Epoch: 6| Step: 7
Training loss: 0.15074437856674194
Validation loss: 1.5675113765142297

Epoch: 6| Step: 8
Training loss: 0.1723700612783432
Validation loss: 1.573735325567184

Epoch: 6| Step: 9
Training loss: 0.164117693901062
Validation loss: 1.5667229942096177

Epoch: 6| Step: 10
Training loss: 0.11445540189743042
Validation loss: 1.5394508184925202

Epoch: 6| Step: 11
Training loss: 0.13165123760700226
Validation loss: 1.5569943727985505

Epoch: 6| Step: 12
Training loss: 0.12318816035985947
Validation loss: 1.552855028901049

Epoch: 6| Step: 13
Training loss: 0.09966031461954117
Validation loss: 1.5055584574258456

Epoch: 340| Step: 0
Training loss: 0.2176457643508911
Validation loss: 1.567968547985118

Epoch: 6| Step: 1
Training loss: 0.1629820615053177
Validation loss: 1.5589753927723053

Epoch: 6| Step: 2
Training loss: 0.23344072699546814
Validation loss: 1.5686689166612522

Epoch: 6| Step: 3
Training loss: 0.17069628834724426
Validation loss: 1.5605137860903175

Epoch: 6| Step: 4
Training loss: 0.1857609748840332
Validation loss: 1.5292493502298992

Epoch: 6| Step: 5
Training loss: 0.1211213618516922
Validation loss: 1.537043079253166

Epoch: 6| Step: 6
Training loss: 0.09739847481250763
Validation loss: 1.540939566909626

Epoch: 6| Step: 7
Training loss: 0.14901414513587952
Validation loss: 1.5547949575608777

Epoch: 6| Step: 8
Training loss: 0.08156643807888031
Validation loss: 1.5291418721598964

Epoch: 6| Step: 9
Training loss: 0.1229388639330864
Validation loss: 1.5445163070514638

Epoch: 6| Step: 10
Training loss: 0.13714951276779175
Validation loss: 1.5497428806879188

Epoch: 6| Step: 11
Training loss: 0.20326663553714752
Validation loss: 1.53911853221155

Epoch: 6| Step: 12
Training loss: 0.1465548276901245
Validation loss: 1.5463203986485798

Epoch: 6| Step: 13
Training loss: 0.2599281668663025
Validation loss: 1.5700383481159006

Epoch: 341| Step: 0
Training loss: 0.13088564574718475
Validation loss: 1.5980373377441077

Epoch: 6| Step: 1
Training loss: 0.10828149318695068
Validation loss: 1.5903251119839248

Epoch: 6| Step: 2
Training loss: 0.18198421597480774
Validation loss: 1.5956889275581605

Epoch: 6| Step: 3
Training loss: 0.11768573522567749
Validation loss: 1.6306507574614657

Epoch: 6| Step: 4
Training loss: 0.19721591472625732
Validation loss: 1.6356678367942892

Epoch: 6| Step: 5
Training loss: 0.12188860774040222
Validation loss: 1.655993350090519

Epoch: 6| Step: 6
Training loss: 0.12528598308563232
Validation loss: 1.611905627353217

Epoch: 6| Step: 7
Training loss: 0.168329656124115
Validation loss: 1.60847823081478

Epoch: 6| Step: 8
Training loss: 0.22783374786376953
Validation loss: 1.6109282316700104

Epoch: 6| Step: 9
Training loss: 0.13293957710266113
Validation loss: 1.6033402104531564

Epoch: 6| Step: 10
Training loss: 0.11088195443153381
Validation loss: 1.5862846605239376

Epoch: 6| Step: 11
Training loss: 0.24164322018623352
Validation loss: 1.586023844698424

Epoch: 6| Step: 12
Training loss: 0.18121151626110077
Validation loss: 1.580929120381673

Epoch: 6| Step: 13
Training loss: 0.28740355372428894
Validation loss: 1.5666515058086765

Epoch: 342| Step: 0
Training loss: 0.20008735358715057
Validation loss: 1.5219818892017487

Epoch: 6| Step: 1
Training loss: 0.17220044136047363
Validation loss: 1.526807722224984

Epoch: 6| Step: 2
Training loss: 0.18902862071990967
Validation loss: 1.5062756141026814

Epoch: 6| Step: 3
Training loss: 0.18223616480827332
Validation loss: 1.567049805836011

Epoch: 6| Step: 4
Training loss: 0.15534202754497528
Validation loss: 1.5709553034074846

Epoch: 6| Step: 5
Training loss: 0.16434578597545624
Validation loss: 1.5360537318773166

Epoch: 6| Step: 6
Training loss: 0.08428564667701721
Validation loss: 1.5685741145123717

Epoch: 6| Step: 7
Training loss: 0.13562050461769104
Validation loss: 1.5404434383556407

Epoch: 6| Step: 8
Training loss: 0.15092334151268005
Validation loss: 1.5474421734450965

Epoch: 6| Step: 9
Training loss: 0.16258341073989868
Validation loss: 1.5534004716462986

Epoch: 6| Step: 10
Training loss: 0.18573744595050812
Validation loss: 1.534741456790637

Epoch: 6| Step: 11
Training loss: 0.23051753640174866
Validation loss: 1.5486073827230802

Epoch: 6| Step: 12
Training loss: 0.13741150498390198
Validation loss: 1.568607643086423

Epoch: 6| Step: 13
Training loss: 0.10662487149238586
Validation loss: 1.5779240105741767

Epoch: 343| Step: 0
Training loss: 0.12813429534435272
Validation loss: 1.6187671294776342

Epoch: 6| Step: 1
Training loss: 0.1752273440361023
Validation loss: 1.5910587118517967

Epoch: 6| Step: 2
Training loss: 0.21929046511650085
Validation loss: 1.6212601738591348

Epoch: 6| Step: 3
Training loss: 0.17063739895820618
Validation loss: 1.6217596056640788

Epoch: 6| Step: 4
Training loss: 0.2121717929840088
Validation loss: 1.6397601430134108

Epoch: 6| Step: 5
Training loss: 0.11139491945505142
Validation loss: 1.6197934894151584

Epoch: 6| Step: 6
Training loss: 0.1924489587545395
Validation loss: 1.6351124586597565

Epoch: 6| Step: 7
Training loss: 0.15997755527496338
Validation loss: 1.6395660497808968

Epoch: 6| Step: 8
Training loss: 0.16745194792747498
Validation loss: 1.6292025286664245

Epoch: 6| Step: 9
Training loss: 0.14977309107780457
Validation loss: 1.6379834195618987

Epoch: 6| Step: 10
Training loss: 0.16534528136253357
Validation loss: 1.6497806156835249

Epoch: 6| Step: 11
Training loss: 0.20626336336135864
Validation loss: 1.6517043062435683

Epoch: 6| Step: 12
Training loss: 0.11296001076698303
Validation loss: 1.6098927528627458

Epoch: 6| Step: 13
Training loss: 0.1252007782459259
Validation loss: 1.6193991258580198

Epoch: 344| Step: 0
Training loss: 0.10695445537567139
Validation loss: 1.5764717869861151

Epoch: 6| Step: 1
Training loss: 0.1692763864994049
Validation loss: 1.5775736134539369

Epoch: 6| Step: 2
Training loss: 0.13697251677513123
Validation loss: 1.5707720889840076

Epoch: 6| Step: 3
Training loss: 0.21545785665512085
Validation loss: 1.5862430923728532

Epoch: 6| Step: 4
Training loss: 0.23620718717575073
Validation loss: 1.5856281941936863

Epoch: 6| Step: 5
Training loss: 0.10736396908760071
Validation loss: 1.5782593950148551

Epoch: 6| Step: 6
Training loss: 0.10552085936069489
Validation loss: 1.5763239757989043

Epoch: 6| Step: 7
Training loss: 0.07095237076282501
Validation loss: 1.5891981983697543

Epoch: 6| Step: 8
Training loss: 0.15137915313243866
Validation loss: 1.5843523061403664

Epoch: 6| Step: 9
Training loss: 0.16324827075004578
Validation loss: 1.6163523966266262

Epoch: 6| Step: 10
Training loss: 0.2794422507286072
Validation loss: 1.6075550343400689

Epoch: 6| Step: 11
Training loss: 0.13581398129463196
Validation loss: 1.6153931784373459

Epoch: 6| Step: 12
Training loss: 0.1369038075208664
Validation loss: 1.580452452423752

Epoch: 6| Step: 13
Training loss: 0.11489331722259521
Validation loss: 1.6189137607492425

Epoch: 345| Step: 0
Training loss: 0.10994866490364075
Validation loss: 1.6053877940741919

Epoch: 6| Step: 1
Training loss: 0.1742769181728363
Validation loss: 1.6248531033915858

Epoch: 6| Step: 2
Training loss: 0.17280301451683044
Validation loss: 1.6063719000867618

Epoch: 6| Step: 3
Training loss: 0.13711661100387573
Validation loss: 1.6133614534972816

Epoch: 6| Step: 4
Training loss: 0.19057348370552063
Validation loss: 1.5912877231515863

Epoch: 6| Step: 5
Training loss: 0.2403060793876648
Validation loss: 1.6345609311134583

Epoch: 6| Step: 6
Training loss: 0.18012095987796783
Validation loss: 1.6372595294829337

Epoch: 6| Step: 7
Training loss: 0.1619013249874115
Validation loss: 1.6300300808363064

Epoch: 6| Step: 8
Training loss: 0.1577826738357544
Validation loss: 1.6175413900806057

Epoch: 6| Step: 9
Training loss: 0.22578555345535278
Validation loss: 1.6094010747889036

Epoch: 6| Step: 10
Training loss: 0.16468137502670288
Validation loss: 1.6075109820212088

Epoch: 6| Step: 11
Training loss: 0.19409970939159393
Validation loss: 1.5875595013300579

Epoch: 6| Step: 12
Training loss: 0.08393685519695282
Validation loss: 1.5490628762911725

Epoch: 6| Step: 13
Training loss: 0.2319946587085724
Validation loss: 1.5696483760751703

Epoch: 346| Step: 0
Training loss: 0.17629531025886536
Validation loss: 1.5953229672165328

Epoch: 6| Step: 1
Training loss: 0.21546253561973572
Validation loss: 1.615403098444785

Epoch: 6| Step: 2
Training loss: 0.2422758936882019
Validation loss: 1.6380614170464136

Epoch: 6| Step: 3
Training loss: 0.1672682762145996
Validation loss: 1.603197552824533

Epoch: 6| Step: 4
Training loss: 0.154145747423172
Validation loss: 1.577257239690391

Epoch: 6| Step: 5
Training loss: 0.2096939980983734
Validation loss: 1.5900833991266066

Epoch: 6| Step: 6
Training loss: 0.2130967676639557
Validation loss: 1.5852475217593613

Epoch: 6| Step: 7
Training loss: 0.07347013056278229
Validation loss: 1.595586843388055

Epoch: 6| Step: 8
Training loss: 0.10096621513366699
Validation loss: 1.6394595561488983

Epoch: 6| Step: 9
Training loss: 0.2127567082643509
Validation loss: 1.6332037762929035

Epoch: 6| Step: 10
Training loss: 0.10914988815784454
Validation loss: 1.5907431225622854

Epoch: 6| Step: 11
Training loss: 0.09683513641357422
Validation loss: 1.5889661440285303

Epoch: 6| Step: 12
Training loss: 0.11017583310604095
Validation loss: 1.614324128755959

Epoch: 6| Step: 13
Training loss: 0.12361548840999603
Validation loss: 1.5920782563506917

Epoch: 347| Step: 0
Training loss: 0.13427242636680603
Validation loss: 1.5974844027591009

Epoch: 6| Step: 1
Training loss: 0.09560714662075043
Validation loss: 1.5915727294901365

Epoch: 6| Step: 2
Training loss: 0.12865599989891052
Validation loss: 1.585011007965252

Epoch: 6| Step: 3
Training loss: 0.21180200576782227
Validation loss: 1.6064376754145469

Epoch: 6| Step: 4
Training loss: 0.15390966832637787
Validation loss: 1.607040802637736

Epoch: 6| Step: 5
Training loss: 0.10302075743675232
Validation loss: 1.5837749101782357

Epoch: 6| Step: 6
Training loss: 0.10955001413822174
Validation loss: 1.5922903463404665

Epoch: 6| Step: 7
Training loss: 0.27271533012390137
Validation loss: 1.5834295954755557

Epoch: 6| Step: 8
Training loss: 0.11455094814300537
Validation loss: 1.6081181597966019

Epoch: 6| Step: 9
Training loss: 0.07830263674259186
Validation loss: 1.5643109929177068

Epoch: 6| Step: 10
Training loss: 0.09109313786029816
Validation loss: 1.5919122593377226

Epoch: 6| Step: 11
Training loss: 0.15125080943107605
Validation loss: 1.5892423980979509

Epoch: 6| Step: 12
Training loss: 0.2165226936340332
Validation loss: 1.6146412139297814

Epoch: 6| Step: 13
Training loss: 0.15903425216674805
Validation loss: 1.6141805956440587

Epoch: 348| Step: 0
Training loss: 0.1461862325668335
Validation loss: 1.6270061769793112

Epoch: 6| Step: 1
Training loss: 0.14958304166793823
Validation loss: 1.6523542134992537

Epoch: 6| Step: 2
Training loss: 0.10705570876598358
Validation loss: 1.6413358270481069

Epoch: 6| Step: 3
Training loss: 0.09643414616584778
Validation loss: 1.6370478496756604

Epoch: 6| Step: 4
Training loss: 0.16866463422775269
Validation loss: 1.6296273085378832

Epoch: 6| Step: 5
Training loss: 0.2709290385246277
Validation loss: 1.6529456492393249

Epoch: 6| Step: 6
Training loss: 0.27900800108909607
Validation loss: 1.6227134619989703

Epoch: 6| Step: 7
Training loss: 0.24194510281085968
Validation loss: 1.6512319144382273

Epoch: 6| Step: 8
Training loss: 0.1758052557706833
Validation loss: 1.6253149996521652

Epoch: 6| Step: 9
Training loss: 0.14293046295642853
Validation loss: 1.6061236672503973

Epoch: 6| Step: 10
Training loss: 0.1218566745519638
Validation loss: 1.6217001702195855

Epoch: 6| Step: 11
Training loss: 0.1608414649963379
Validation loss: 1.6210641976325744

Epoch: 6| Step: 12
Training loss: 0.1733856499195099
Validation loss: 1.616956244232834

Epoch: 6| Step: 13
Training loss: 0.1854248046875
Validation loss: 1.6193344400775047

Epoch: 349| Step: 0
Training loss: 0.20443663001060486
Validation loss: 1.6049495102256857

Epoch: 6| Step: 1
Training loss: 0.18091130256652832
Validation loss: 1.5841560427860548

Epoch: 6| Step: 2
Training loss: 0.21113914251327515
Validation loss: 1.590971641643073

Epoch: 6| Step: 3
Training loss: 0.12796363234519958
Validation loss: 1.6005199942537534

Epoch: 6| Step: 4
Training loss: 0.1357758492231369
Validation loss: 1.6236235480154715

Epoch: 6| Step: 5
Training loss: 0.14505816996097565
Validation loss: 1.652354771091092

Epoch: 6| Step: 6
Training loss: 0.17379260063171387
Validation loss: 1.6654131335596885

Epoch: 6| Step: 7
Training loss: 0.2531772553920746
Validation loss: 1.631593253022881

Epoch: 6| Step: 8
Training loss: 0.16254094243049622
Validation loss: 1.6275898051518265

Epoch: 6| Step: 9
Training loss: 0.21576042473316193
Validation loss: 1.6248269978389944

Epoch: 6| Step: 10
Training loss: 0.12303068488836288
Validation loss: 1.5954257852287703

Epoch: 6| Step: 11
Training loss: 0.13117629289627075
Validation loss: 1.6225140992031302

Epoch: 6| Step: 12
Training loss: 0.1373750865459442
Validation loss: 1.6307782998649023

Epoch: 6| Step: 13
Training loss: 0.13501599431037903
Validation loss: 1.6097744748156557

Epoch: 350| Step: 0
Training loss: 0.17291469871997833
Validation loss: 1.6371107562895744

Epoch: 6| Step: 1
Training loss: 0.08699093014001846
Validation loss: 1.6261979918326102

Epoch: 6| Step: 2
Training loss: 0.1043374314904213
Validation loss: 1.6122542145431682

Epoch: 6| Step: 3
Training loss: 0.11965226382017136
Validation loss: 1.6298850710673998

Epoch: 6| Step: 4
Training loss: 0.14582164585590363
Validation loss: 1.6156169893921062

Epoch: 6| Step: 5
Training loss: 0.15039482712745667
Validation loss: 1.617852492999005

Epoch: 6| Step: 6
Training loss: 0.2160855233669281
Validation loss: 1.6506992963052565

Epoch: 6| Step: 7
Training loss: 0.17989495396614075
Validation loss: 1.6480432357839359

Epoch: 6| Step: 8
Training loss: 0.15757521986961365
Validation loss: 1.6521465662987

Epoch: 6| Step: 9
Training loss: 0.059545282274484634
Validation loss: 1.6530713855579335

Epoch: 6| Step: 10
Training loss: 0.13512860238552094
Validation loss: 1.6580497064898092

Epoch: 6| Step: 11
Training loss: 0.11388836801052094
Validation loss: 1.679534605754319

Epoch: 6| Step: 12
Training loss: 0.13425284624099731
Validation loss: 1.65740329475813

Epoch: 6| Step: 13
Training loss: 0.13819047808647156
Validation loss: 1.6384829987761795

Epoch: 351| Step: 0
Training loss: 0.15532232820987701
Validation loss: 1.621097013514529

Epoch: 6| Step: 1
Training loss: 0.10747992992401123
Validation loss: 1.6442699150372577

Epoch: 6| Step: 2
Training loss: 0.17713335156440735
Validation loss: 1.6357777695502005

Epoch: 6| Step: 3
Training loss: 0.16049276292324066
Validation loss: 1.6379506370072723

Epoch: 6| Step: 4
Training loss: 0.11531999707221985
Validation loss: 1.6174250969322779

Epoch: 6| Step: 5
Training loss: 0.11665733903646469
Validation loss: 1.6543756338857836

Epoch: 6| Step: 6
Training loss: 0.10247442871332169
Validation loss: 1.6256542769811486

Epoch: 6| Step: 7
Training loss: 0.1963251829147339
Validation loss: 1.616048369356381

Epoch: 6| Step: 8
Training loss: 0.18189311027526855
Validation loss: 1.5926480908547678

Epoch: 6| Step: 9
Training loss: 0.10911208391189575
Validation loss: 1.6385364904198596

Epoch: 6| Step: 10
Training loss: 0.15747229754924774
Validation loss: 1.6061268801330237

Epoch: 6| Step: 11
Training loss: 0.13257962465286255
Validation loss: 1.5836722632890106

Epoch: 6| Step: 12
Training loss: 0.16063368320465088
Validation loss: 1.5980791250864665

Epoch: 6| Step: 13
Training loss: 0.23208239674568176
Validation loss: 1.6333708211939821

Epoch: 352| Step: 0
Training loss: 0.15936648845672607
Validation loss: 1.5991706027779529

Epoch: 6| Step: 1
Training loss: 0.1715182662010193
Validation loss: 1.6161988409616614

Epoch: 6| Step: 2
Training loss: 0.2169109433889389
Validation loss: 1.614192533236678

Epoch: 6| Step: 3
Training loss: 0.15745055675506592
Validation loss: 1.642322724865329

Epoch: 6| Step: 4
Training loss: 0.12462955713272095
Validation loss: 1.6371297733758086

Epoch: 6| Step: 5
Training loss: 0.20625311136245728
Validation loss: 1.652677994902416

Epoch: 6| Step: 6
Training loss: 0.19705212116241455
Validation loss: 1.5974454623396679

Epoch: 6| Step: 7
Training loss: 0.10201800614595413
Validation loss: 1.6081088242992279

Epoch: 6| Step: 8
Training loss: 0.2295026332139969
Validation loss: 1.6533990643357719

Epoch: 6| Step: 9
Training loss: 0.19956554472446442
Validation loss: 1.6671572500659573

Epoch: 6| Step: 10
Training loss: 0.10895352810621262
Validation loss: 1.6746730150714997

Epoch: 6| Step: 11
Training loss: 0.11661618947982788
Validation loss: 1.66776071440789

Epoch: 6| Step: 12
Training loss: 0.2018364518880844
Validation loss: 1.6503808408655145

Epoch: 6| Step: 13
Training loss: 0.21407561004161835
Validation loss: 1.6471509805289648

Epoch: 353| Step: 0
Training loss: 0.1169554591178894
Validation loss: 1.5674728039772279

Epoch: 6| Step: 1
Training loss: 0.14431115984916687
Validation loss: 1.5783900189143356

Epoch: 6| Step: 2
Training loss: 0.17784927785396576
Validation loss: 1.5903468542201544

Epoch: 6| Step: 3
Training loss: 0.26120346784591675
Validation loss: 1.6070599145786737

Epoch: 6| Step: 4
Training loss: 0.15261662006378174
Validation loss: 1.6081124121142971

Epoch: 6| Step: 5
Training loss: 0.1546991467475891
Validation loss: 1.594827341136112

Epoch: 6| Step: 6
Training loss: 0.22295360267162323
Validation loss: 1.6240029642658849

Epoch: 6| Step: 7
Training loss: 0.13466301560401917
Validation loss: 1.5983035141421902

Epoch: 6| Step: 8
Training loss: 0.16714325547218323
Validation loss: 1.5828506318471764

Epoch: 6| Step: 9
Training loss: 0.16403618454933167
Validation loss: 1.6022975931885421

Epoch: 6| Step: 10
Training loss: 0.13560603559017181
Validation loss: 1.6357917067825154

Epoch: 6| Step: 11
Training loss: 0.19734764099121094
Validation loss: 1.6664663232782835

Epoch: 6| Step: 12
Training loss: 0.21614745259284973
Validation loss: 1.6588206188653105

Epoch: 6| Step: 13
Training loss: 0.062385525554418564
Validation loss: 1.620931439502265

Epoch: 354| Step: 0
Training loss: 0.25648319721221924
Validation loss: 1.6092152185337518

Epoch: 6| Step: 1
Training loss: 0.2536897361278534
Validation loss: 1.6296155632183116

Epoch: 6| Step: 2
Training loss: 0.14856117963790894
Validation loss: 1.621297449193975

Epoch: 6| Step: 3
Training loss: 0.15519939363002777
Validation loss: 1.6142970259471605

Epoch: 6| Step: 4
Training loss: 0.2080422192811966
Validation loss: 1.5947058611018683

Epoch: 6| Step: 5
Training loss: 0.1237822026014328
Validation loss: 1.5730856336573118

Epoch: 6| Step: 6
Training loss: 0.08105508983135223
Validation loss: 1.5846478605783114

Epoch: 6| Step: 7
Training loss: 0.10326597839593887
Validation loss: 1.6068149420522875

Epoch: 6| Step: 8
Training loss: 0.17236259579658508
Validation loss: 1.574571386460335

Epoch: 6| Step: 9
Training loss: 0.12884797155857086
Validation loss: 1.5916749008240239

Epoch: 6| Step: 10
Training loss: 0.12842726707458496
Validation loss: 1.5848116118420836

Epoch: 6| Step: 11
Training loss: 0.14783397316932678
Validation loss: 1.555306706377255

Epoch: 6| Step: 12
Training loss: 0.09403889626264572
Validation loss: 1.5647769794669202

Epoch: 6| Step: 13
Training loss: 0.12380822747945786
Validation loss: 1.5626687477993708

Epoch: 355| Step: 0
Training loss: 0.1027161180973053
Validation loss: 1.5885966580401185

Epoch: 6| Step: 1
Training loss: 0.15996026992797852
Validation loss: 1.5638844864342802

Epoch: 6| Step: 2
Training loss: 0.16505587100982666
Validation loss: 1.5409365571955198

Epoch: 6| Step: 3
Training loss: 0.10300174355506897
Validation loss: 1.5883835387486283

Epoch: 6| Step: 4
Training loss: 0.18593716621398926
Validation loss: 1.573598241293302

Epoch: 6| Step: 5
Training loss: 0.19776210188865662
Validation loss: 1.5939537812304754

Epoch: 6| Step: 6
Training loss: 0.09492352604866028
Validation loss: 1.6251445329317482

Epoch: 6| Step: 7
Training loss: 0.13707083463668823
Validation loss: 1.599722844298168

Epoch: 6| Step: 8
Training loss: 0.1070859283208847
Validation loss: 1.6105313454904864

Epoch: 6| Step: 9
Training loss: 0.14829373359680176
Validation loss: 1.5789371254623576

Epoch: 6| Step: 10
Training loss: 0.18129003047943115
Validation loss: 1.5985824561888171

Epoch: 6| Step: 11
Training loss: 0.12356461584568024
Validation loss: 1.5632033873629827

Epoch: 6| Step: 12
Training loss: 0.1136113703250885
Validation loss: 1.5728237744300597

Epoch: 6| Step: 13
Training loss: 0.1383453756570816
Validation loss: 1.5738587161546111

Epoch: 356| Step: 0
Training loss: 0.1585196554660797
Validation loss: 1.6015523966922556

Epoch: 6| Step: 1
Training loss: 0.11824870854616165
Validation loss: 1.624017673154031

Epoch: 6| Step: 2
Training loss: 0.20943903923034668
Validation loss: 1.6312323462578557

Epoch: 6| Step: 3
Training loss: 0.25254011154174805
Validation loss: 1.64255355763179

Epoch: 6| Step: 4
Training loss: 0.1855127513408661
Validation loss: 1.5841661922393306

Epoch: 6| Step: 5
Training loss: 0.1293579787015915
Validation loss: 1.5265711379307572

Epoch: 6| Step: 6
Training loss: 0.06888284534215927
Validation loss: 1.5147735470084733

Epoch: 6| Step: 7
Training loss: 0.1426754891872406
Validation loss: 1.5402989900240334

Epoch: 6| Step: 8
Training loss: 0.11460280418395996
Validation loss: 1.5719667314201273

Epoch: 6| Step: 9
Training loss: 0.10180841386318207
Validation loss: 1.5404827120483562

Epoch: 6| Step: 10
Training loss: 0.17800398170948029
Validation loss: 1.5690128854525986

Epoch: 6| Step: 11
Training loss: 0.17450672388076782
Validation loss: 1.5529955510170228

Epoch: 6| Step: 12
Training loss: 0.22567754983901978
Validation loss: 1.5538960297902424

Epoch: 6| Step: 13
Training loss: 0.13286437094211578
Validation loss: 1.5424153420232958

Epoch: 357| Step: 0
Training loss: 0.27849525213241577
Validation loss: 1.5748161090317594

Epoch: 6| Step: 1
Training loss: 0.09752951562404633
Validation loss: 1.5866633205003635

Epoch: 6| Step: 2
Training loss: 0.18878138065338135
Validation loss: 1.6083493130181425

Epoch: 6| Step: 3
Training loss: 0.23098871111869812
Validation loss: 1.5862207745993009

Epoch: 6| Step: 4
Training loss: 0.2103029489517212
Validation loss: 1.5761971255784393

Epoch: 6| Step: 5
Training loss: 0.21461786329746246
Validation loss: 1.5586055350560013

Epoch: 6| Step: 6
Training loss: 0.1819818615913391
Validation loss: 1.5358924609358593

Epoch: 6| Step: 7
Training loss: 0.14594244956970215
Validation loss: 1.5305381833866079

Epoch: 6| Step: 8
Training loss: 0.22219684720039368
Validation loss: 1.5532999756515666

Epoch: 6| Step: 9
Training loss: 0.21740299463272095
Validation loss: 1.6159471683604743

Epoch: 6| Step: 10
Training loss: 0.22298413515090942
Validation loss: 1.5745214057225052

Epoch: 6| Step: 11
Training loss: 0.23854553699493408
Validation loss: 1.5574577751980032

Epoch: 6| Step: 12
Training loss: 0.13157039880752563
Validation loss: 1.5413184178772794

Epoch: 6| Step: 13
Training loss: 0.1044352799654007
Validation loss: 1.512651603708985

Epoch: 358| Step: 0
Training loss: 0.12800778448581696
Validation loss: 1.5462808685918008

Epoch: 6| Step: 1
Training loss: 0.11075737327337265
Validation loss: 1.5241271834219656

Epoch: 6| Step: 2
Training loss: 0.09691424667835236
Validation loss: 1.5471792092887304

Epoch: 6| Step: 3
Training loss: 0.16426794230937958
Validation loss: 1.5501101119543916

Epoch: 6| Step: 4
Training loss: 0.24981948733329773
Validation loss: 1.5620965444913475

Epoch: 6| Step: 5
Training loss: 0.11400005221366882
Validation loss: 1.5532043839013705

Epoch: 6| Step: 6
Training loss: 0.18028458952903748
Validation loss: 1.5472841378181212

Epoch: 6| Step: 7
Training loss: 0.12774860858917236
Validation loss: 1.5359850365628478

Epoch: 6| Step: 8
Training loss: 0.1878359317779541
Validation loss: 1.558861236418447

Epoch: 6| Step: 9
Training loss: 0.22550556063652039
Validation loss: 1.5523506941333893

Epoch: 6| Step: 10
Training loss: 0.11977984011173248
Validation loss: 1.5772397505339755

Epoch: 6| Step: 11
Training loss: 0.08619633316993713
Validation loss: 1.5363167844792849

Epoch: 6| Step: 12
Training loss: 0.11422918736934662
Validation loss: 1.535939198668285

Epoch: 6| Step: 13
Training loss: 0.19609151780605316
Validation loss: 1.5598875886650496

Epoch: 359| Step: 0
Training loss: 0.14422598481178284
Validation loss: 1.5600302719300794

Epoch: 6| Step: 1
Training loss: 0.15695790946483612
Validation loss: 1.5445760219327864

Epoch: 6| Step: 2
Training loss: 0.12590521574020386
Validation loss: 1.5520852868274977

Epoch: 6| Step: 3
Training loss: 0.1539759784936905
Validation loss: 1.5309325264346214

Epoch: 6| Step: 4
Training loss: 0.14213785529136658
Validation loss: 1.5466627062007945

Epoch: 6| Step: 5
Training loss: 0.13093766570091248
Validation loss: 1.550634608473829

Epoch: 6| Step: 6
Training loss: 0.13913340866565704
Validation loss: 1.580189674131332

Epoch: 6| Step: 7
Training loss: 0.08853267133235931
Validation loss: 1.5674710119924238

Epoch: 6| Step: 8
Training loss: 0.18061262369155884
Validation loss: 1.573427301581188

Epoch: 6| Step: 9
Training loss: 0.09092327207326889
Validation loss: 1.5463723392896755

Epoch: 6| Step: 10
Training loss: 0.17147894203662872
Validation loss: 1.5269225989618609

Epoch: 6| Step: 11
Training loss: 0.07503943890333176
Validation loss: 1.5431630720374405

Epoch: 6| Step: 12
Training loss: 0.12630926072597504
Validation loss: 1.5442224529481703

Epoch: 6| Step: 13
Training loss: 0.15117068588733673
Validation loss: 1.5231710531378304

Epoch: 360| Step: 0
Training loss: 0.1327003836631775
Validation loss: 1.5644620951785837

Epoch: 6| Step: 1
Training loss: 0.15144658088684082
Validation loss: 1.557820616229888

Epoch: 6| Step: 2
Training loss: 0.181833878159523
Validation loss: 1.5586292346318562

Epoch: 6| Step: 3
Training loss: 0.2169712781906128
Validation loss: 1.5819862875887143

Epoch: 6| Step: 4
Training loss: 0.1714901328086853
Validation loss: 1.5833372467307634

Epoch: 6| Step: 5
Training loss: 0.125893235206604
Validation loss: 1.57093862436151

Epoch: 6| Step: 6
Training loss: 0.1072491854429245
Validation loss: 1.5621684161565637

Epoch: 6| Step: 7
Training loss: 0.10224780440330505
Validation loss: 1.5557023363728677

Epoch: 6| Step: 8
Training loss: 0.12804433703422546
Validation loss: 1.5217880292605328

Epoch: 6| Step: 9
Training loss: 0.11429084837436676
Validation loss: 1.5779485215422928

Epoch: 6| Step: 10
Training loss: 0.12084750831127167
Validation loss: 1.5496569256628714

Epoch: 6| Step: 11
Training loss: 0.11136947572231293
Validation loss: 1.5592300814967002

Epoch: 6| Step: 12
Training loss: 0.12083064019680023
Validation loss: 1.554742504191655

Epoch: 6| Step: 13
Training loss: 0.1689658761024475
Validation loss: 1.5590293227985341

Epoch: 361| Step: 0
Training loss: 0.08655868470668793
Validation loss: 1.5935200337440736

Epoch: 6| Step: 1
Training loss: 0.1813039779663086
Validation loss: 1.5742973948037753

Epoch: 6| Step: 2
Training loss: 0.08660238981246948
Validation loss: 1.5715408248286094

Epoch: 6| Step: 3
Training loss: 0.22365716099739075
Validation loss: 1.5586501270212152

Epoch: 6| Step: 4
Training loss: 0.1562173217535019
Validation loss: 1.5656029870433192

Epoch: 6| Step: 5
Training loss: 0.19320392608642578
Validation loss: 1.5733353245642878

Epoch: 6| Step: 6
Training loss: 0.10683220624923706
Validation loss: 1.5774418282252487

Epoch: 6| Step: 7
Training loss: 0.1590813249349594
Validation loss: 1.5877188239046323

Epoch: 6| Step: 8
Training loss: 0.1156882643699646
Validation loss: 1.5727735456599985

Epoch: 6| Step: 9
Training loss: 0.1120595633983612
Validation loss: 1.5719515277493386

Epoch: 6| Step: 10
Training loss: 0.07799986004829407
Validation loss: 1.530163611135175

Epoch: 6| Step: 11
Training loss: 0.10219687968492508
Validation loss: 1.5383400737598378

Epoch: 6| Step: 12
Training loss: 0.1378602385520935
Validation loss: 1.5616437696641492

Epoch: 6| Step: 13
Training loss: 0.094220370054245
Validation loss: 1.5517470323911278

Epoch: 362| Step: 0
Training loss: 0.1481470912694931
Validation loss: 1.563074097838453

Epoch: 6| Step: 1
Training loss: 0.14557981491088867
Validation loss: 1.5185899978042932

Epoch: 6| Step: 2
Training loss: 0.10290684551000595
Validation loss: 1.5534301765503422

Epoch: 6| Step: 3
Training loss: 0.07215164601802826
Validation loss: 1.5874098577807028

Epoch: 6| Step: 4
Training loss: 0.177903413772583
Validation loss: 1.5862111096741052

Epoch: 6| Step: 5
Training loss: 0.0834197923541069
Validation loss: 1.5909280078385466

Epoch: 6| Step: 6
Training loss: 0.0830230861902237
Validation loss: 1.5648036541477326

Epoch: 6| Step: 7
Training loss: 0.1365949809551239
Validation loss: 1.5688669604639853

Epoch: 6| Step: 8
Training loss: 0.1178540512919426
Validation loss: 1.574632904862845

Epoch: 6| Step: 9
Training loss: 0.1814955621957779
Validation loss: 1.5549708309993948

Epoch: 6| Step: 10
Training loss: 0.12253554910421371
Validation loss: 1.5737253709505963

Epoch: 6| Step: 11
Training loss: 0.14378327131271362
Validation loss: 1.5503548217076126

Epoch: 6| Step: 12
Training loss: 0.11877113580703735
Validation loss: 1.5498292087226786

Epoch: 6| Step: 13
Training loss: 0.11030590534210205
Validation loss: 1.5646604696909587

Epoch: 363| Step: 0
Training loss: 0.12284354120492935
Validation loss: 1.5422371125990344

Epoch: 6| Step: 1
Training loss: 0.17303957045078278
Validation loss: 1.5287310333662136

Epoch: 6| Step: 2
Training loss: 0.1256914734840393
Validation loss: 1.5189252822629866

Epoch: 6| Step: 3
Training loss: 0.1279251128435135
Validation loss: 1.5382374678888628

Epoch: 6| Step: 4
Training loss: 0.10703888535499573
Validation loss: 1.531631120430526

Epoch: 6| Step: 5
Training loss: 0.14681130647659302
Validation loss: 1.551291340140886

Epoch: 6| Step: 6
Training loss: 0.22238293290138245
Validation loss: 1.536277142904138

Epoch: 6| Step: 7
Training loss: 0.15130683779716492
Validation loss: 1.5296303802920925

Epoch: 6| Step: 8
Training loss: 0.10592982172966003
Validation loss: 1.5266473857305383

Epoch: 6| Step: 9
Training loss: 0.13130971789360046
Validation loss: 1.4992657963947584

Epoch: 6| Step: 10
Training loss: 0.12850835919380188
Validation loss: 1.5474180162593882

Epoch: 6| Step: 11
Training loss: 0.12184782326221466
Validation loss: 1.5468051420745028

Epoch: 6| Step: 12
Training loss: 0.12011063098907471
Validation loss: 1.5502347305256834

Epoch: 6| Step: 13
Training loss: 0.2254565805196762
Validation loss: 1.5817923366382558

Epoch: 364| Step: 0
Training loss: 0.14102627336978912
Validation loss: 1.5691310705677155

Epoch: 6| Step: 1
Training loss: 0.14704982936382294
Validation loss: 1.577376247734152

Epoch: 6| Step: 2
Training loss: 0.10318847000598907
Validation loss: 1.5694750547409058

Epoch: 6| Step: 3
Training loss: 0.11346723139286041
Validation loss: 1.5812285689897434

Epoch: 6| Step: 4
Training loss: 0.13608267903327942
Validation loss: 1.566030954801908

Epoch: 6| Step: 5
Training loss: 0.1208718791604042
Validation loss: 1.5783482251628753

Epoch: 6| Step: 6
Training loss: 0.10840831696987152
Validation loss: 1.5525987327739756

Epoch: 6| Step: 7
Training loss: 0.0901336744427681
Validation loss: 1.5784856606555242

Epoch: 6| Step: 8
Training loss: 0.17126819491386414
Validation loss: 1.5498074011136127

Epoch: 6| Step: 9
Training loss: 0.10958234965801239
Validation loss: 1.5400654705621863

Epoch: 6| Step: 10
Training loss: 0.12547695636749268
Validation loss: 1.538512760593045

Epoch: 6| Step: 11
Training loss: 0.1874856948852539
Validation loss: 1.5334969374441332

Epoch: 6| Step: 12
Training loss: 0.11745293438434601
Validation loss: 1.555713463855046

Epoch: 6| Step: 13
Training loss: 0.07371335476636887
Validation loss: 1.5202888109350716

Epoch: 365| Step: 0
Training loss: 0.09452153742313385
Validation loss: 1.5103312641061761

Epoch: 6| Step: 1
Training loss: 0.0909656435251236
Validation loss: 1.5000661124465287

Epoch: 6| Step: 2
Training loss: 0.18347734212875366
Validation loss: 1.496858128937342

Epoch: 6| Step: 3
Training loss: 0.08173565566539764
Validation loss: 1.5086017488151469

Epoch: 6| Step: 4
Training loss: 0.1012585237622261
Validation loss: 1.5412788762841174

Epoch: 6| Step: 5
Training loss: 0.13830702006816864
Validation loss: 1.5216064299306562

Epoch: 6| Step: 6
Training loss: 0.0936504527926445
Validation loss: 1.5275892570454588

Epoch: 6| Step: 7
Training loss: 0.10982789099216461
Validation loss: 1.5228418496347242

Epoch: 6| Step: 8
Training loss: 0.08893445134162903
Validation loss: 1.5480470144620506

Epoch: 6| Step: 9
Training loss: 0.2133629024028778
Validation loss: 1.5393460771088958

Epoch: 6| Step: 10
Training loss: 0.13124845921993256
Validation loss: 1.5400654885076708

Epoch: 6| Step: 11
Training loss: 0.15410727262496948
Validation loss: 1.5439184314461165

Epoch: 6| Step: 12
Training loss: 0.11507672071456909
Validation loss: 1.5770993937728226

Epoch: 6| Step: 13
Training loss: 0.16292747855186462
Validation loss: 1.583942558175774

Epoch: 366| Step: 0
Training loss: 0.13938060402870178
Validation loss: 1.5597707045975553

Epoch: 6| Step: 1
Training loss: 0.13275784254074097
Validation loss: 1.5832074752417944

Epoch: 6| Step: 2
Training loss: 0.10018463432788849
Validation loss: 1.569710995561333

Epoch: 6| Step: 3
Training loss: 0.13830983638763428
Validation loss: 1.5703739132932437

Epoch: 6| Step: 4
Training loss: 0.10985440015792847
Validation loss: 1.5457409299829954

Epoch: 6| Step: 5
Training loss: 0.12467597424983978
Validation loss: 1.5402149090202906

Epoch: 6| Step: 6
Training loss: 0.17780472338199615
Validation loss: 1.5442211358777937

Epoch: 6| Step: 7
Training loss: 0.13558511435985565
Validation loss: 1.550186889145964

Epoch: 6| Step: 8
Training loss: 0.17139972746372223
Validation loss: 1.5550734560976747

Epoch: 6| Step: 9
Training loss: 0.10168897360563278
Validation loss: 1.5722187039672688

Epoch: 6| Step: 10
Training loss: 0.09187565743923187
Validation loss: 1.5411719070967806

Epoch: 6| Step: 11
Training loss: 0.1282215118408203
Validation loss: 1.550768336942119

Epoch: 6| Step: 12
Training loss: 0.13507483899593353
Validation loss: 1.5296025763275802

Epoch: 6| Step: 13
Training loss: 0.16712525486946106
Validation loss: 1.563563023844073

Epoch: 367| Step: 0
Training loss: 0.11752749979496002
Validation loss: 1.5492438603472967

Epoch: 6| Step: 1
Training loss: 0.08551990985870361
Validation loss: 1.5845860563298708

Epoch: 6| Step: 2
Training loss: 0.1972751021385193
Validation loss: 1.5902653650570941

Epoch: 6| Step: 3
Training loss: 0.17346787452697754
Validation loss: 1.5813808261707265

Epoch: 6| Step: 4
Training loss: 0.09173703193664551
Validation loss: 1.5563226361428537

Epoch: 6| Step: 5
Training loss: 0.15229955315589905
Validation loss: 1.5457965430393015

Epoch: 6| Step: 6
Training loss: 0.11613868176937103
Validation loss: 1.5258025379591091

Epoch: 6| Step: 7
Training loss: 0.13421903550624847
Validation loss: 1.5551764208783385

Epoch: 6| Step: 8
Training loss: 0.1049262210726738
Validation loss: 1.5713369025978992

Epoch: 6| Step: 9
Training loss: 0.18615040183067322
Validation loss: 1.5745703789495653

Epoch: 6| Step: 10
Training loss: 0.1115708127617836
Validation loss: 1.5380287798502112

Epoch: 6| Step: 11
Training loss: 0.11901729553937912
Validation loss: 1.525451757574594

Epoch: 6| Step: 12
Training loss: 0.12503382563591003
Validation loss: 1.5465019749056907

Epoch: 6| Step: 13
Training loss: 0.11164159327745438
Validation loss: 1.539473118320588

Epoch: 368| Step: 0
Training loss: 0.16980253159999847
Validation loss: 1.5419013884759718

Epoch: 6| Step: 1
Training loss: 0.1099097952246666
Validation loss: 1.5949273840073617

Epoch: 6| Step: 2
Training loss: 0.17282167077064514
Validation loss: 1.557778678914552

Epoch: 6| Step: 3
Training loss: 0.1733669638633728
Validation loss: 1.5560999237081057

Epoch: 6| Step: 4
Training loss: 0.08825384080410004
Validation loss: 1.5301356969341156

Epoch: 6| Step: 5
Training loss: 0.17212527990341187
Validation loss: 1.5376080184854486

Epoch: 6| Step: 6
Training loss: 0.08717148005962372
Validation loss: 1.5307651565920921

Epoch: 6| Step: 7
Training loss: 0.14072909951210022
Validation loss: 1.5410447889758694

Epoch: 6| Step: 8
Training loss: 0.15948191285133362
Validation loss: 1.5589820415742937

Epoch: 6| Step: 9
Training loss: 0.13482308387756348
Validation loss: 1.546195807636425

Epoch: 6| Step: 10
Training loss: 0.10267229378223419
Validation loss: 1.5475860911030923

Epoch: 6| Step: 11
Training loss: 0.09781259298324585
Validation loss: 1.5717967652505445

Epoch: 6| Step: 12
Training loss: 0.1699313074350357
Validation loss: 1.608908660309289

Epoch: 6| Step: 13
Training loss: 0.12885096669197083
Validation loss: 1.6426374143169773

Epoch: 369| Step: 0
Training loss: 0.17891937494277954
Validation loss: 1.641900481716279

Epoch: 6| Step: 1
Training loss: 0.10286372154951096
Validation loss: 1.5855089079949163

Epoch: 6| Step: 2
Training loss: 0.09462957084178925
Validation loss: 1.627169744942778

Epoch: 6| Step: 3
Training loss: 0.15579530596733093
Validation loss: 1.591438901039862

Epoch: 6| Step: 4
Training loss: 0.19229656457901
Validation loss: 1.5590665942879134

Epoch: 6| Step: 5
Training loss: 0.2245524674654007
Validation loss: 1.5862666227484261

Epoch: 6| Step: 6
Training loss: 0.11614594608545303
Validation loss: 1.616981630684227

Epoch: 6| Step: 7
Training loss: 0.17702817916870117
Validation loss: 1.6149207417682936

Epoch: 6| Step: 8
Training loss: 0.21405147016048431
Validation loss: 1.6525930512335993

Epoch: 6| Step: 9
Training loss: 0.1438320130109787
Validation loss: 1.6019225780681898

Epoch: 6| Step: 10
Training loss: 0.10954346507787704
Validation loss: 1.5891174565079391

Epoch: 6| Step: 11
Training loss: 0.11511921882629395
Validation loss: 1.548497829385983

Epoch: 6| Step: 12
Training loss: 0.08665519952774048
Validation loss: 1.5851679630176996

Epoch: 6| Step: 13
Training loss: 0.10908179730176926
Validation loss: 1.5762398691587551

Epoch: 370| Step: 0
Training loss: 0.13071992993354797
Validation loss: 1.5891721645991008

Epoch: 6| Step: 1
Training loss: 0.16271139681339264
Validation loss: 1.5842895751358361

Epoch: 6| Step: 2
Training loss: 0.13145726919174194
Validation loss: 1.5657810985401113

Epoch: 6| Step: 3
Training loss: 0.10022912919521332
Validation loss: 1.5713832506569483

Epoch: 6| Step: 4
Training loss: 0.1456087827682495
Validation loss: 1.5864104417062574

Epoch: 6| Step: 5
Training loss: 0.12300195544958115
Validation loss: 1.577459289181617

Epoch: 6| Step: 6
Training loss: 0.1314319670200348
Validation loss: 1.5723348484244397

Epoch: 6| Step: 7
Training loss: 0.0802348405122757
Validation loss: 1.5754130950538061

Epoch: 6| Step: 8
Training loss: 0.14511238038539886
Validation loss: 1.5643600943267986

Epoch: 6| Step: 9
Training loss: 0.10561415553092957
Validation loss: 1.5655082964128064

Epoch: 6| Step: 10
Training loss: 0.06296626478433609
Validation loss: 1.5585327289437736

Epoch: 6| Step: 11
Training loss: 0.09659460932016373
Validation loss: 1.5791470081575456

Epoch: 6| Step: 12
Training loss: 0.16816715896129608
Validation loss: 1.5784799309187039

Epoch: 6| Step: 13
Training loss: 0.15983913838863373
Validation loss: 1.5897977448278857

Epoch: 371| Step: 0
Training loss: 0.14351993799209595
Validation loss: 1.5654234296532088

Epoch: 6| Step: 1
Training loss: 0.09861257672309875
Validation loss: 1.548618967815112

Epoch: 6| Step: 2
Training loss: 0.14865592122077942
Validation loss: 1.5504381592555712

Epoch: 6| Step: 3
Training loss: 0.09116745740175247
Validation loss: 1.5343035779973513

Epoch: 6| Step: 4
Training loss: 0.1872521936893463
Validation loss: 1.5672321550307735

Epoch: 6| Step: 5
Training loss: 0.21678878366947174
Validation loss: 1.5866934330232683

Epoch: 6| Step: 6
Training loss: 0.3002188205718994
Validation loss: 1.5855320371607298

Epoch: 6| Step: 7
Training loss: 0.1507466435432434
Validation loss: 1.5740519146765433

Epoch: 6| Step: 8
Training loss: 0.08730072528123856
Validation loss: 1.5680510062043385

Epoch: 6| Step: 9
Training loss: 0.1127370074391365
Validation loss: 1.5384118300612255

Epoch: 6| Step: 10
Training loss: 0.1450212597846985
Validation loss: 1.5406254952953709

Epoch: 6| Step: 11
Training loss: 0.17324331402778625
Validation loss: 1.6038026527691913

Epoch: 6| Step: 12
Training loss: 0.2011219561100006
Validation loss: 1.5851857534018896

Epoch: 6| Step: 13
Training loss: 0.16857396066188812
Validation loss: 1.547208812928969

Epoch: 372| Step: 0
Training loss: 0.16091392934322357
Validation loss: 1.545532315008102

Epoch: 6| Step: 1
Training loss: 0.23661991953849792
Validation loss: 1.5875114881864159

Epoch: 6| Step: 2
Training loss: 0.1429058015346527
Validation loss: 1.5564083232674548

Epoch: 6| Step: 3
Training loss: 0.18598666787147522
Validation loss: 1.5462493563211093

Epoch: 6| Step: 4
Training loss: 0.10882028937339783
Validation loss: 1.5944519414696643

Epoch: 6| Step: 5
Training loss: 0.10168565064668655
Validation loss: 1.5906592094770042

Epoch: 6| Step: 6
Training loss: 0.16281826794147491
Validation loss: 1.5981263640106365

Epoch: 6| Step: 7
Training loss: 0.09054718166589737
Validation loss: 1.6173016037992252

Epoch: 6| Step: 8
Training loss: 0.12401024997234344
Validation loss: 1.5845377483675558

Epoch: 6| Step: 9
Training loss: 0.1044272929430008
Validation loss: 1.5968915544530398

Epoch: 6| Step: 10
Training loss: 0.11309677362442017
Validation loss: 1.59857012379554

Epoch: 6| Step: 11
Training loss: 0.16137126088142395
Validation loss: 1.5913987031546972

Epoch: 6| Step: 12
Training loss: 0.11533434689044952
Validation loss: 1.568094148430773

Epoch: 6| Step: 13
Training loss: 0.263931006193161
Validation loss: 1.6024923504039805

Epoch: 373| Step: 0
Training loss: 0.1677314192056656
Validation loss: 1.5894134916285032

Epoch: 6| Step: 1
Training loss: 0.10979318618774414
Validation loss: 1.5602096831926735

Epoch: 6| Step: 2
Training loss: 0.14247114956378937
Validation loss: 1.5769334570054085

Epoch: 6| Step: 3
Training loss: 0.08425149321556091
Validation loss: 1.5601903956423524

Epoch: 6| Step: 4
Training loss: 0.10846344381570816
Validation loss: 1.5929327716109574

Epoch: 6| Step: 5
Training loss: 0.20017024874687195
Validation loss: 1.555202091893842

Epoch: 6| Step: 6
Training loss: 0.11768535524606705
Validation loss: 1.5285536563524635

Epoch: 6| Step: 7
Training loss: 0.09267830103635788
Validation loss: 1.5405507792708695

Epoch: 6| Step: 8
Training loss: 0.09145040065050125
Validation loss: 1.5403299011209959

Epoch: 6| Step: 9
Training loss: 0.15298905968666077
Validation loss: 1.5609834296728975

Epoch: 6| Step: 10
Training loss: 0.1189618781208992
Validation loss: 1.5889740669599144

Epoch: 6| Step: 11
Training loss: 0.1266152709722519
Validation loss: 1.5925174028642717

Epoch: 6| Step: 12
Training loss: 0.12263575941324234
Validation loss: 1.5593770063051613

Epoch: 6| Step: 13
Training loss: 0.10059309005737305
Validation loss: 1.576000008531796

Epoch: 374| Step: 0
Training loss: 0.090377077460289
Validation loss: 1.571866488584908

Epoch: 6| Step: 1
Training loss: 0.06996757537126541
Validation loss: 1.6105801187535769

Epoch: 6| Step: 2
Training loss: 0.1319722682237625
Validation loss: 1.6347093966699415

Epoch: 6| Step: 3
Training loss: 0.20547427237033844
Validation loss: 1.6412218437399915

Epoch: 6| Step: 4
Training loss: 0.2796398997306824
Validation loss: 1.6233189054714736

Epoch: 6| Step: 5
Training loss: 0.2014818638563156
Validation loss: 1.6473172492878412

Epoch: 6| Step: 6
Training loss: 0.1436150074005127
Validation loss: 1.6236931111222954

Epoch: 6| Step: 7
Training loss: 0.1489202082157135
Validation loss: 1.5913584911695091

Epoch: 6| Step: 8
Training loss: 0.15253977477550507
Validation loss: 1.5790463910307935

Epoch: 6| Step: 9
Training loss: 0.14990919828414917
Validation loss: 1.5538545731575257

Epoch: 6| Step: 10
Training loss: 0.13075509667396545
Validation loss: 1.5952947729377336

Epoch: 6| Step: 11
Training loss: 0.21028293669223785
Validation loss: 1.6076401715637536

Epoch: 6| Step: 12
Training loss: 0.16180607676506042
Validation loss: 1.6201083275579637

Epoch: 6| Step: 13
Training loss: 0.13347016274929047
Validation loss: 1.6246759365963679

Epoch: 375| Step: 0
Training loss: 0.22142836451530457
Validation loss: 1.6082208130949287

Epoch: 6| Step: 1
Training loss: 0.0869574323296547
Validation loss: 1.6177710025541243

Epoch: 6| Step: 2
Training loss: 0.17480215430259705
Validation loss: 1.6019671373469855

Epoch: 6| Step: 3
Training loss: 0.15018901228904724
Validation loss: 1.5695015012577016

Epoch: 6| Step: 4
Training loss: 0.1638461947441101
Validation loss: 1.5596345496434036

Epoch: 6| Step: 5
Training loss: 0.1574721783399582
Validation loss: 1.609212137037708

Epoch: 6| Step: 6
Training loss: 0.1530005931854248
Validation loss: 1.5986630532049364

Epoch: 6| Step: 7
Training loss: 0.15385037660598755
Validation loss: 1.5501900783149145

Epoch: 6| Step: 8
Training loss: 0.09488317370414734
Validation loss: 1.582279610377486

Epoch: 6| Step: 9
Training loss: 0.10873836278915405
Validation loss: 1.5798086209963726

Epoch: 6| Step: 10
Training loss: 0.11030549556016922
Validation loss: 1.6010902286857687

Epoch: 6| Step: 11
Training loss: 0.1613810807466507
Validation loss: 1.5601144849613149

Epoch: 6| Step: 12
Training loss: 0.21321818232536316
Validation loss: 1.6053543859912502

Epoch: 6| Step: 13
Training loss: 0.11852247267961502
Validation loss: 1.5902384993850545

Epoch: 376| Step: 0
Training loss: 0.16773752868175507
Validation loss: 1.6122306969857985

Epoch: 6| Step: 1
Training loss: 0.11948127299547195
Validation loss: 1.6062002451189104

Epoch: 6| Step: 2
Training loss: 0.17175599932670593
Validation loss: 1.59584677732119

Epoch: 6| Step: 3
Training loss: 0.138464093208313
Validation loss: 1.5527678388421253

Epoch: 6| Step: 4
Training loss: 0.08007263392210007
Validation loss: 1.575541183512698

Epoch: 6| Step: 5
Training loss: 0.13328063488006592
Validation loss: 1.5802987487085405

Epoch: 6| Step: 6
Training loss: 0.14979159832000732
Validation loss: 1.6225997068548714

Epoch: 6| Step: 7
Training loss: 0.10591743141412735
Validation loss: 1.5792764527823335

Epoch: 6| Step: 8
Training loss: 0.17279988527297974
Validation loss: 1.6085521905652937

Epoch: 6| Step: 9
Training loss: 0.14672893285751343
Validation loss: 1.6036953720995175

Epoch: 6| Step: 10
Training loss: 0.1197236180305481
Validation loss: 1.5738181196233278

Epoch: 6| Step: 11
Training loss: 0.16697174310684204
Validation loss: 1.5599764918768277

Epoch: 6| Step: 12
Training loss: 0.09847651422023773
Validation loss: 1.5687322514031523

Epoch: 6| Step: 13
Training loss: 0.11228866130113602
Validation loss: 1.552662589216745

Epoch: 377| Step: 0
Training loss: 0.08785837888717651
Validation loss: 1.5586501693212858

Epoch: 6| Step: 1
Training loss: 0.07196170836687088
Validation loss: 1.5569883610612603

Epoch: 6| Step: 2
Training loss: 0.11048178374767303
Validation loss: 1.5258759554996286

Epoch: 6| Step: 3
Training loss: 0.13391777873039246
Validation loss: 1.5578081005363054

Epoch: 6| Step: 4
Training loss: 0.17266950011253357
Validation loss: 1.5456817534662062

Epoch: 6| Step: 5
Training loss: 0.14305317401885986
Validation loss: 1.5685416165218558

Epoch: 6| Step: 6
Training loss: 0.1144869327545166
Validation loss: 1.5792903002872263

Epoch: 6| Step: 7
Training loss: 0.1744573712348938
Validation loss: 1.574670930062571

Epoch: 6| Step: 8
Training loss: 0.09933093935251236
Validation loss: 1.5471508092777704

Epoch: 6| Step: 9
Training loss: 0.11539701372385025
Validation loss: 1.5749391573731617

Epoch: 6| Step: 10
Training loss: 0.1053241565823555
Validation loss: 1.5665247927429855

Epoch: 6| Step: 11
Training loss: 0.20016516745090485
Validation loss: 1.5985865272501463

Epoch: 6| Step: 12
Training loss: 0.08376777917146683
Validation loss: 1.5571261541817778

Epoch: 6| Step: 13
Training loss: 0.11152593046426773
Validation loss: 1.579639245105046

Epoch: 378| Step: 0
Training loss: 0.11352463066577911
Validation loss: 1.548969796908799

Epoch: 6| Step: 1
Training loss: 0.14031916856765747
Validation loss: 1.5659567066418227

Epoch: 6| Step: 2
Training loss: 0.20394855737686157
Validation loss: 1.552318516597953

Epoch: 6| Step: 3
Training loss: 0.09105736017227173
Validation loss: 1.5554821196422781

Epoch: 6| Step: 4
Training loss: 0.10704828053712845
Validation loss: 1.5865629731967885

Epoch: 6| Step: 5
Training loss: 0.12093394994735718
Validation loss: 1.556080332366369

Epoch: 6| Step: 6
Training loss: 0.1498294174671173
Validation loss: 1.5394888859923168

Epoch: 6| Step: 7
Training loss: 0.1080283373594284
Validation loss: 1.5433788120105703

Epoch: 6| Step: 8
Training loss: 0.13983836770057678
Validation loss: 1.5269529742579306

Epoch: 6| Step: 9
Training loss: 0.11510732769966125
Validation loss: 1.518990630744606

Epoch: 6| Step: 10
Training loss: 0.155528724193573
Validation loss: 1.501516588272587

Epoch: 6| Step: 11
Training loss: 0.15399229526519775
Validation loss: 1.5225465092607724

Epoch: 6| Step: 12
Training loss: 0.07922913134098053
Validation loss: 1.5299702575129848

Epoch: 6| Step: 13
Training loss: 0.11566102504730225
Validation loss: 1.5374369544367636

Epoch: 379| Step: 0
Training loss: 0.14000430703163147
Validation loss: 1.5506814987428728

Epoch: 6| Step: 1
Training loss: 0.09291820228099823
Validation loss: 1.5804685495233024

Epoch: 6| Step: 2
Training loss: 0.16459687054157257
Validation loss: 1.5879193006023284

Epoch: 6| Step: 3
Training loss: 0.17924939095973969
Validation loss: 1.6082408992193078

Epoch: 6| Step: 4
Training loss: 0.23446163535118103
Validation loss: 1.6183168708637197

Epoch: 6| Step: 5
Training loss: 0.12885279953479767
Validation loss: 1.5962279926064193

Epoch: 6| Step: 6
Training loss: 0.09655249863862991
Validation loss: 1.5638050366473455

Epoch: 6| Step: 7
Training loss: 0.16888266801834106
Validation loss: 1.5532982387850363

Epoch: 6| Step: 8
Training loss: 0.12512367963790894
Validation loss: 1.5425693809345205

Epoch: 6| Step: 9
Training loss: 0.16921411454677582
Validation loss: 1.5720586033277615

Epoch: 6| Step: 10
Training loss: 0.12423212826251984
Validation loss: 1.5597858569955314

Epoch: 6| Step: 11
Training loss: 0.12627552449703217
Validation loss: 1.5693285824150167

Epoch: 6| Step: 12
Training loss: 0.17152683436870575
Validation loss: 1.5737772577552385

Epoch: 6| Step: 13
Training loss: 0.20487114787101746
Validation loss: 1.5847337245941162

Epoch: 380| Step: 0
Training loss: 0.15154260396957397
Validation loss: 1.571362631295317

Epoch: 6| Step: 1
Training loss: 0.11034615337848663
Validation loss: 1.5772069013246925

Epoch: 6| Step: 2
Training loss: 0.13943755626678467
Validation loss: 1.5889195729327459

Epoch: 6| Step: 3
Training loss: 0.15555855631828308
Validation loss: 1.5785235820278045

Epoch: 6| Step: 4
Training loss: 0.18669790029525757
Validation loss: 1.5898252200054865

Epoch: 6| Step: 5
Training loss: 0.13722969591617584
Validation loss: 1.615024310286327

Epoch: 6| Step: 6
Training loss: 0.11598431318998337
Validation loss: 1.603285098588595

Epoch: 6| Step: 7
Training loss: 0.1612684726715088
Validation loss: 1.5951945794525968

Epoch: 6| Step: 8
Training loss: 0.11914049088954926
Validation loss: 1.555235025703266

Epoch: 6| Step: 9
Training loss: 0.12952183187007904
Validation loss: 1.5471298515155751

Epoch: 6| Step: 10
Training loss: 0.1145368292927742
Validation loss: 1.5417985057318082

Epoch: 6| Step: 11
Training loss: 0.11026468873023987
Validation loss: 1.5673807635102222

Epoch: 6| Step: 12
Training loss: 0.1980803906917572
Validation loss: 1.5792545144275953

Epoch: 6| Step: 13
Training loss: 0.10920137912034988
Validation loss: 1.570557112334877

Epoch: 381| Step: 0
Training loss: 0.1430920660495758
Validation loss: 1.5539175297624321

Epoch: 6| Step: 1
Training loss: 0.12040876597166061
Validation loss: 1.5735144717718965

Epoch: 6| Step: 2
Training loss: 0.1231885701417923
Validation loss: 1.5528866590992096

Epoch: 6| Step: 3
Training loss: 0.09026901423931122
Validation loss: 1.5547394701229629

Epoch: 6| Step: 4
Training loss: 0.16469699144363403
Validation loss: 1.5583095306991248

Epoch: 6| Step: 5
Training loss: 0.11811546236276627
Validation loss: 1.5283620331877021

Epoch: 6| Step: 6
Training loss: 0.11989051848649979
Validation loss: 1.5613357636236376

Epoch: 6| Step: 7
Training loss: 0.15341052412986755
Validation loss: 1.542448313646419

Epoch: 6| Step: 8
Training loss: 0.09843288362026215
Validation loss: 1.563769531506364

Epoch: 6| Step: 9
Training loss: 0.21672280132770538
Validation loss: 1.5552518137039677

Epoch: 6| Step: 10
Training loss: 0.11213759332895279
Validation loss: 1.5820314922640402

Epoch: 6| Step: 11
Training loss: 0.08307290822267532
Validation loss: 1.5646346140933294

Epoch: 6| Step: 12
Training loss: 0.09780845046043396
Validation loss: 1.6101477492240168

Epoch: 6| Step: 13
Training loss: 0.2365977019071579
Validation loss: 1.6114639236081032

Epoch: 382| Step: 0
Training loss: 0.2038523256778717
Validation loss: 1.5952699312599756

Epoch: 6| Step: 1
Training loss: 0.12995535135269165
Validation loss: 1.5765958114336895

Epoch: 6| Step: 2
Training loss: 0.07597000151872635
Validation loss: 1.5840534933151738

Epoch: 6| Step: 3
Training loss: 0.16893918812274933
Validation loss: 1.5993077908792803

Epoch: 6| Step: 4
Training loss: 0.12477246671915054
Validation loss: 1.5768655295013099

Epoch: 6| Step: 5
Training loss: 0.10779030621051788
Validation loss: 1.5821733423458633

Epoch: 6| Step: 6
Training loss: 0.12161202728748322
Validation loss: 1.5537148175701019

Epoch: 6| Step: 7
Training loss: 0.07799817621707916
Validation loss: 1.5350347154883928

Epoch: 6| Step: 8
Training loss: 0.07841655611991882
Validation loss: 1.5635204802277267

Epoch: 6| Step: 9
Training loss: 0.10802873969078064
Validation loss: 1.538900117720327

Epoch: 6| Step: 10
Training loss: 0.09652510285377502
Validation loss: 1.5681311699651903

Epoch: 6| Step: 11
Training loss: 0.08369702845811844
Validation loss: 1.5491871538982596

Epoch: 6| Step: 12
Training loss: 0.20544861257076263
Validation loss: 1.5514658054997843

Epoch: 6| Step: 13
Training loss: 0.1265920251607895
Validation loss: 1.5412908125949163

Epoch: 383| Step: 0
Training loss: 0.09109371155500412
Validation loss: 1.562798584020266

Epoch: 6| Step: 1
Training loss: 0.14734423160552979
Validation loss: 1.560577041359358

Epoch: 6| Step: 2
Training loss: 0.12101493030786514
Validation loss: 1.5623080730438232

Epoch: 6| Step: 3
Training loss: 0.11793883889913559
Validation loss: 1.5662169892300841

Epoch: 6| Step: 4
Training loss: 0.13890159130096436
Validation loss: 1.5844933871299989

Epoch: 6| Step: 5
Training loss: 0.135447695851326
Validation loss: 1.5554923344683904

Epoch: 6| Step: 6
Training loss: 0.07499764859676361
Validation loss: 1.5442988693073232

Epoch: 6| Step: 7
Training loss: 0.11499368399381638
Validation loss: 1.5635417456267982

Epoch: 6| Step: 8
Training loss: 0.10414956510066986
Validation loss: 1.5428386452377483

Epoch: 6| Step: 9
Training loss: 0.18609383702278137
Validation loss: 1.5438141515178065

Epoch: 6| Step: 10
Training loss: 0.06457069516181946
Validation loss: 1.5449651864267164

Epoch: 6| Step: 11
Training loss: 0.053925491869449615
Validation loss: 1.542884026804278

Epoch: 6| Step: 12
Training loss: 0.16625641286373138
Validation loss: 1.5462755939011932

Epoch: 6| Step: 13
Training loss: 0.1225019320845604
Validation loss: 1.5491056134623866

Epoch: 384| Step: 0
Training loss: 0.10799877345561981
Validation loss: 1.5459365562726093

Epoch: 6| Step: 1
Training loss: 0.11329412460327148
Validation loss: 1.5102017323176067

Epoch: 6| Step: 2
Training loss: 0.06697070598602295
Validation loss: 1.543201433715

Epoch: 6| Step: 3
Training loss: 0.06845955550670624
Validation loss: 1.544628067683148

Epoch: 6| Step: 4
Training loss: 0.08205203711986542
Validation loss: 1.5403161958981586

Epoch: 6| Step: 5
Training loss: 0.07219339162111282
Validation loss: 1.5652557778102096

Epoch: 6| Step: 6
Training loss: 0.16328778862953186
Validation loss: 1.551500649862392

Epoch: 6| Step: 7
Training loss: 0.1496487706899643
Validation loss: 1.5511314189562233

Epoch: 6| Step: 8
Training loss: 0.14679941534996033
Validation loss: 1.5591986217806417

Epoch: 6| Step: 9
Training loss: 0.1057838425040245
Validation loss: 1.541860531735164

Epoch: 6| Step: 10
Training loss: 0.15653371810913086
Validation loss: 1.5338545524945824

Epoch: 6| Step: 11
Training loss: 0.13619965314865112
Validation loss: 1.4881061418082124

Epoch: 6| Step: 12
Training loss: 0.1915048062801361
Validation loss: 1.5418580334673646

Epoch: 6| Step: 13
Training loss: 0.11706696450710297
Validation loss: 1.5053937768423429

Epoch: 385| Step: 0
Training loss: 0.1400575488805771
Validation loss: 1.5084385897523613

Epoch: 6| Step: 1
Training loss: 0.13131040334701538
Validation loss: 1.5153353932083293

Epoch: 6| Step: 2
Training loss: 0.0884670615196228
Validation loss: 1.4933889219837804

Epoch: 6| Step: 3
Training loss: 0.1844044327735901
Validation loss: 1.4597680312331005

Epoch: 6| Step: 4
Training loss: 0.08250287175178528
Validation loss: 1.4754632467864661

Epoch: 6| Step: 5
Training loss: 0.06850484013557434
Validation loss: 1.4820585789219025

Epoch: 6| Step: 6
Training loss: 0.06209225952625275
Validation loss: 1.5007061298175524

Epoch: 6| Step: 7
Training loss: 0.10327355563640594
Validation loss: 1.4939214696166336

Epoch: 6| Step: 8
Training loss: 0.13756117224693298
Validation loss: 1.5242032568941835

Epoch: 6| Step: 9
Training loss: 0.13659825921058655
Validation loss: 1.5028395780953028

Epoch: 6| Step: 10
Training loss: 0.0980466902256012
Validation loss: 1.4863798631134855

Epoch: 6| Step: 11
Training loss: 0.09681781381368637
Validation loss: 1.534706461814142

Epoch: 6| Step: 12
Training loss: 0.10831589996814728
Validation loss: 1.5341670558016787

Epoch: 6| Step: 13
Training loss: 0.1266513466835022
Validation loss: 1.5403021894475466

Epoch: 386| Step: 0
Training loss: 0.09207171201705933
Validation loss: 1.5197355362676805

Epoch: 6| Step: 1
Training loss: 0.10046862810850143
Validation loss: 1.5427048398602394

Epoch: 6| Step: 2
Training loss: 0.1511794626712799
Validation loss: 1.5166088047847952

Epoch: 6| Step: 3
Training loss: 0.17097103595733643
Validation loss: 1.5068741947092035

Epoch: 6| Step: 4
Training loss: 0.07511193305253983
Validation loss: 1.509957891638561

Epoch: 6| Step: 5
Training loss: 0.07261809706687927
Validation loss: 1.509035853929417

Epoch: 6| Step: 6
Training loss: 0.1407611072063446
Validation loss: 1.4986500240141345

Epoch: 6| Step: 7
Training loss: 0.0845114141702652
Validation loss: 1.516243834649363

Epoch: 6| Step: 8
Training loss: 0.08803334832191467
Validation loss: 1.5122496043482134

Epoch: 6| Step: 9
Training loss: 0.10860274732112885
Validation loss: 1.5150137434723556

Epoch: 6| Step: 10
Training loss: 0.09988629072904587
Validation loss: 1.4825518938802904

Epoch: 6| Step: 11
Training loss: 0.19498053193092346
Validation loss: 1.5259003216220486

Epoch: 6| Step: 12
Training loss: 0.13961252570152283
Validation loss: 1.5118474909054336

Epoch: 6| Step: 13
Training loss: 0.06840100884437561
Validation loss: 1.5005142509296376

Epoch: 387| Step: 0
Training loss: 0.08272361755371094
Validation loss: 1.511790673578939

Epoch: 6| Step: 1
Training loss: 0.06268320232629776
Validation loss: 1.5339646057416034

Epoch: 6| Step: 2
Training loss: 0.17684684693813324
Validation loss: 1.5349268323631697

Epoch: 6| Step: 3
Training loss: 0.12650355696678162
Validation loss: 1.5212126983109342

Epoch: 6| Step: 4
Training loss: 0.11704401671886444
Validation loss: 1.5144193544182727

Epoch: 6| Step: 5
Training loss: 0.08274587988853455
Validation loss: 1.49184456563765

Epoch: 6| Step: 6
Training loss: 0.12536978721618652
Validation loss: 1.5208228582976966

Epoch: 6| Step: 7
Training loss: 0.1331268846988678
Validation loss: 1.536905168205179

Epoch: 6| Step: 8
Training loss: 0.11769932508468628
Validation loss: 1.5374894501060568

Epoch: 6| Step: 9
Training loss: 0.14488816261291504
Validation loss: 1.539253725800463

Epoch: 6| Step: 10
Training loss: 0.0969274491071701
Validation loss: 1.5137924622463923

Epoch: 6| Step: 11
Training loss: 0.10449688136577606
Validation loss: 1.5252634761154011

Epoch: 6| Step: 12
Training loss: 0.16962212324142456
Validation loss: 1.5379433157623454

Epoch: 6| Step: 13
Training loss: 0.16281430423259735
Validation loss: 1.5505400088525587

Epoch: 388| Step: 0
Training loss: 0.0979890376329422
Validation loss: 1.5538693333184848

Epoch: 6| Step: 1
Training loss: 0.05638376995921135
Validation loss: 1.5597339759590805

Epoch: 6| Step: 2
Training loss: 0.15701425075531006
Validation loss: 1.5782861299412225

Epoch: 6| Step: 3
Training loss: 0.15818628668785095
Validation loss: 1.6129687716883998

Epoch: 6| Step: 4
Training loss: 0.1969691812992096
Validation loss: 1.5818358416198401

Epoch: 6| Step: 5
Training loss: 0.13549600541591644
Validation loss: 1.5825297588943152

Epoch: 6| Step: 6
Training loss: 0.0632791668176651
Validation loss: 1.5572895516631424

Epoch: 6| Step: 7
Training loss: 0.1142326146364212
Validation loss: 1.553549160239517

Epoch: 6| Step: 8
Training loss: 0.15855292975902557
Validation loss: 1.56721269699835

Epoch: 6| Step: 9
Training loss: 0.19259068369865417
Validation loss: 1.5732451215867074

Epoch: 6| Step: 10
Training loss: 0.10747796297073364
Validation loss: 1.5428833487213298

Epoch: 6| Step: 11
Training loss: 0.0911027118563652
Validation loss: 1.5351430011051956

Epoch: 6| Step: 12
Training loss: 0.05629933625459671
Validation loss: 1.5517092327917776

Epoch: 6| Step: 13
Training loss: 0.21144722402095795
Validation loss: 1.5709247409656484

Epoch: 389| Step: 0
Training loss: 0.13260018825531006
Validation loss: 1.5303018400746007

Epoch: 6| Step: 1
Training loss: 0.11458907276391983
Validation loss: 1.5381768159968878

Epoch: 6| Step: 2
Training loss: 0.11227370798587799
Validation loss: 1.5332751107472244

Epoch: 6| Step: 3
Training loss: 0.11917488276958466
Validation loss: 1.5508648221210768

Epoch: 6| Step: 4
Training loss: 0.11394750326871872
Validation loss: 1.5542123227991083

Epoch: 6| Step: 5
Training loss: 0.2063806653022766
Validation loss: 1.5684029902181318

Epoch: 6| Step: 6
Training loss: 0.10276471078395844
Validation loss: 1.5488422551462728

Epoch: 6| Step: 7
Training loss: 0.1173497661948204
Validation loss: 1.547134409668625

Epoch: 6| Step: 8
Training loss: 0.09128309786319733
Validation loss: 1.5592865687544628

Epoch: 6| Step: 9
Training loss: 0.12950457632541656
Validation loss: 1.5249038909071235

Epoch: 6| Step: 10
Training loss: 0.1172359436750412
Validation loss: 1.5608610094234507

Epoch: 6| Step: 11
Training loss: 0.17242740094661713
Validation loss: 1.53236626168733

Epoch: 6| Step: 12
Training loss: 0.10013747960329056
Validation loss: 1.5368578715990948

Epoch: 6| Step: 13
Training loss: 0.09175615757703781
Validation loss: 1.5291835595202703

Epoch: 390| Step: 0
Training loss: 0.14335383474826813
Validation loss: 1.5555134281035392

Epoch: 6| Step: 1
Training loss: 0.11313335597515106
Validation loss: 1.5238282475420224

Epoch: 6| Step: 2
Training loss: 0.13532891869544983
Validation loss: 1.5305725451438659

Epoch: 6| Step: 3
Training loss: 0.09264864772558212
Validation loss: 1.5339242719834851

Epoch: 6| Step: 4
Training loss: 0.1253206431865692
Validation loss: 1.5137895473869898

Epoch: 6| Step: 5
Training loss: 0.18471530079841614
Validation loss: 1.5394581364047142

Epoch: 6| Step: 6
Training loss: 0.11493081599473953
Validation loss: 1.5348902453658402

Epoch: 6| Step: 7
Training loss: 0.0930553674697876
Validation loss: 1.5412541153610393

Epoch: 6| Step: 8
Training loss: 0.1445615589618683
Validation loss: 1.539610311549197

Epoch: 6| Step: 9
Training loss: 0.14641793072223663
Validation loss: 1.5314081522726244

Epoch: 6| Step: 10
Training loss: 0.10540399700403214
Validation loss: 1.5089805985009799

Epoch: 6| Step: 11
Training loss: 0.09928350150585175
Validation loss: 1.5202338862162765

Epoch: 6| Step: 12
Training loss: 0.08427908271551132
Validation loss: 1.5233953909207416

Epoch: 6| Step: 13
Training loss: 0.17217382788658142
Validation loss: 1.5711777287144815

Epoch: 391| Step: 0
Training loss: 0.1678525060415268
Validation loss: 1.5949831329366213

Epoch: 6| Step: 1
Training loss: 0.08166779577732086
Validation loss: 1.5798321513719455

Epoch: 6| Step: 2
Training loss: 0.11778755486011505
Validation loss: 1.5866470503550705

Epoch: 6| Step: 3
Training loss: 0.10898706316947937
Validation loss: 1.5706464077836724

Epoch: 6| Step: 4
Training loss: 0.0894341766834259
Validation loss: 1.5552468786957443

Epoch: 6| Step: 5
Training loss: 0.11243137717247009
Validation loss: 1.5610576906511862

Epoch: 6| Step: 6
Training loss: 0.08804875612258911
Validation loss: 1.6209464688454904

Epoch: 6| Step: 7
Training loss: 0.20736733078956604
Validation loss: 1.6343182876545896

Epoch: 6| Step: 8
Training loss: 0.29509878158569336
Validation loss: 1.6178794227620608

Epoch: 6| Step: 9
Training loss: 0.13617989420890808
Validation loss: 1.5872992879600936

Epoch: 6| Step: 10
Training loss: 0.2369185984134674
Validation loss: 1.5678940614064534

Epoch: 6| Step: 11
Training loss: 0.11305177211761475
Validation loss: 1.561346512327912

Epoch: 6| Step: 12
Training loss: 0.15874284505844116
Validation loss: 1.5128683864429433

Epoch: 6| Step: 13
Training loss: 0.24703629314899445
Validation loss: 1.559599954594848

Epoch: 392| Step: 0
Training loss: 0.11067766696214676
Validation loss: 1.5725606423552319

Epoch: 6| Step: 1
Training loss: 0.1888030469417572
Validation loss: 1.6074674334577335

Epoch: 6| Step: 2
Training loss: 0.1600678265094757
Validation loss: 1.5799824794133503

Epoch: 6| Step: 3
Training loss: 0.18306080996990204
Validation loss: 1.5293246520462858

Epoch: 6| Step: 4
Training loss: 0.21695517003536224
Validation loss: 1.5259271424303773

Epoch: 6| Step: 5
Training loss: 0.18532101809978485
Validation loss: 1.5379640966333368

Epoch: 6| Step: 6
Training loss: 0.1310151219367981
Validation loss: 1.5207792937114675

Epoch: 6| Step: 7
Training loss: 0.09736509621143341
Validation loss: 1.540948042305567

Epoch: 6| Step: 8
Training loss: 0.08703039586544037
Validation loss: 1.5611970783561788

Epoch: 6| Step: 9
Training loss: 0.09385297447443008
Validation loss: 1.541375010244308

Epoch: 6| Step: 10
Training loss: 0.12611901760101318
Validation loss: 1.5985213864234187

Epoch: 6| Step: 11
Training loss: 0.2523641586303711
Validation loss: 1.5891969203948975

Epoch: 6| Step: 12
Training loss: 0.21385063230991364
Validation loss: 1.5805936551863147

Epoch: 6| Step: 13
Training loss: 0.1411556601524353
Validation loss: 1.5664099262606712

Epoch: 393| Step: 0
Training loss: 0.09438210725784302
Validation loss: 1.5587460956265848

Epoch: 6| Step: 1
Training loss: 0.14009246230125427
Validation loss: 1.542437272687112

Epoch: 6| Step: 2
Training loss: 0.1791808158159256
Validation loss: 1.5944690499254452

Epoch: 6| Step: 3
Training loss: 0.16883760690689087
Validation loss: 1.604447180225003

Epoch: 6| Step: 4
Training loss: 0.13205912709236145
Validation loss: 1.5766732884991554

Epoch: 6| Step: 5
Training loss: 0.1972828209400177
Validation loss: 1.547077299446188

Epoch: 6| Step: 6
Training loss: 0.16119056940078735
Validation loss: 1.5187832001716859

Epoch: 6| Step: 7
Training loss: 0.17821656167507172
Validation loss: 1.5310734747558512

Epoch: 6| Step: 8
Training loss: 0.13788890838623047
Validation loss: 1.5180019890108416

Epoch: 6| Step: 9
Training loss: 0.12957488000392914
Validation loss: 1.5158779928761144

Epoch: 6| Step: 10
Training loss: 0.11494944989681244
Validation loss: 1.5102501434664573

Epoch: 6| Step: 11
Training loss: 0.10426269471645355
Validation loss: 1.5218074565292687

Epoch: 6| Step: 12
Training loss: 0.08917392790317535
Validation loss: 1.508784080064425

Epoch: 6| Step: 13
Training loss: 0.13705092668533325
Validation loss: 1.5106415684505174

Epoch: 394| Step: 0
Training loss: 0.06780260801315308
Validation loss: 1.5323537703483336

Epoch: 6| Step: 1
Training loss: 0.16435210406780243
Validation loss: 1.5059903590909895

Epoch: 6| Step: 2
Training loss: 0.10708048939704895
Validation loss: 1.5319277355747838

Epoch: 6| Step: 3
Training loss: 0.08369554579257965
Validation loss: 1.5462860561186267

Epoch: 6| Step: 4
Training loss: 0.15148374438285828
Validation loss: 1.576142616169427

Epoch: 6| Step: 5
Training loss: 0.11924277245998383
Validation loss: 1.5294422000967047

Epoch: 6| Step: 6
Training loss: 0.12245918810367584
Validation loss: 1.5441690683364868

Epoch: 6| Step: 7
Training loss: 0.08932127058506012
Validation loss: 1.5048070133373301

Epoch: 6| Step: 8
Training loss: 0.11619022488594055
Validation loss: 1.5469665463252733

Epoch: 6| Step: 9
Training loss: 0.05280359834432602
Validation loss: 1.5265450067417596

Epoch: 6| Step: 10
Training loss: 0.13955941796302795
Validation loss: 1.5048150740643984

Epoch: 6| Step: 11
Training loss: 0.0890418142080307
Validation loss: 1.523910568606469

Epoch: 6| Step: 12
Training loss: 0.14821186661720276
Validation loss: 1.5226122365202954

Epoch: 6| Step: 13
Training loss: 0.14943449199199677
Validation loss: 1.5405820492775208

Epoch: 395| Step: 0
Training loss: 0.11346465349197388
Validation loss: 1.5385944343382312

Epoch: 6| Step: 1
Training loss: 0.09611809253692627
Validation loss: 1.5466553684203856

Epoch: 6| Step: 2
Training loss: 0.10593165457248688
Validation loss: 1.5426446250689927

Epoch: 6| Step: 3
Training loss: 0.13236066699028015
Validation loss: 1.5454568273277693

Epoch: 6| Step: 4
Training loss: 0.10360972583293915
Validation loss: 1.52150974991501

Epoch: 6| Step: 5
Training loss: 0.04825184494256973
Validation loss: 1.5492205427538963

Epoch: 6| Step: 6
Training loss: 0.128315269947052
Validation loss: 1.5470699956340175

Epoch: 6| Step: 7
Training loss: 0.18593131005764008
Validation loss: 1.542127340070663

Epoch: 6| Step: 8
Training loss: 0.17668196558952332
Validation loss: 1.5777150379714144

Epoch: 6| Step: 9
Training loss: 0.12421457469463348
Validation loss: 1.550484352214362

Epoch: 6| Step: 10
Training loss: 0.18040311336517334
Validation loss: 1.5389829117764708

Epoch: 6| Step: 11
Training loss: 0.13981519639492035
Validation loss: 1.5139414738583308

Epoch: 6| Step: 12
Training loss: 0.07707612216472626
Validation loss: 1.5414942182520384

Epoch: 6| Step: 13
Training loss: 0.16241484880447388
Validation loss: 1.5300823193724438

Epoch: 396| Step: 0
Training loss: 0.12097568809986115
Validation loss: 1.572205489681613

Epoch: 6| Step: 1
Training loss: 0.11987197399139404
Validation loss: 1.5540347278759044

Epoch: 6| Step: 2
Training loss: 0.29232317209243774
Validation loss: 1.576906996388589

Epoch: 6| Step: 3
Training loss: 0.13883545994758606
Validation loss: 1.5898954804225633

Epoch: 6| Step: 4
Training loss: 0.10061425715684891
Validation loss: 1.5576505366192068

Epoch: 6| Step: 5
Training loss: 0.10446272045373917
Validation loss: 1.558521875130233

Epoch: 6| Step: 6
Training loss: 0.08909573405981064
Validation loss: 1.5473966739510978

Epoch: 6| Step: 7
Training loss: 0.09647414833307266
Validation loss: 1.5450927301119732

Epoch: 6| Step: 8
Training loss: 0.1631830632686615
Validation loss: 1.5394621228659024

Epoch: 6| Step: 9
Training loss: 0.130622997879982
Validation loss: 1.5487883757519465

Epoch: 6| Step: 10
Training loss: 0.12482236325740814
Validation loss: 1.5588073217740623

Epoch: 6| Step: 11
Training loss: 0.13981993496418
Validation loss: 1.5396235335257746

Epoch: 6| Step: 12
Training loss: 0.09700930118560791
Validation loss: 1.547296335620265

Epoch: 6| Step: 13
Training loss: 0.09455810487270355
Validation loss: 1.534732372530045

Epoch: 397| Step: 0
Training loss: 0.1276056170463562
Validation loss: 1.4971422341562086

Epoch: 6| Step: 1
Training loss: 0.10088783502578735
Validation loss: 1.508946257252847

Epoch: 6| Step: 2
Training loss: 0.09851597249507904
Validation loss: 1.5439792281837874

Epoch: 6| Step: 3
Training loss: 0.16866335272789001
Validation loss: 1.5202644640399563

Epoch: 6| Step: 4
Training loss: 0.09822475910186768
Validation loss: 1.5477164265930012

Epoch: 6| Step: 5
Training loss: 0.1662357747554779
Validation loss: 1.5467364352236512

Epoch: 6| Step: 6
Training loss: 0.08922722935676575
Validation loss: 1.5289642272457

Epoch: 6| Step: 7
Training loss: 0.10427272319793701
Validation loss: 1.5442832080266808

Epoch: 6| Step: 8
Training loss: 0.13020701706409454
Validation loss: 1.5396847494186894

Epoch: 6| Step: 9
Training loss: 0.1367824226617813
Validation loss: 1.580640621082757

Epoch: 6| Step: 10
Training loss: 0.06356439739465714
Validation loss: 1.5395535256273003

Epoch: 6| Step: 11
Training loss: 0.14822383224964142
Validation loss: 1.5507421160256991

Epoch: 6| Step: 12
Training loss: 0.07014776021242142
Validation loss: 1.5416285145667292

Epoch: 6| Step: 13
Training loss: 0.08897665143013
Validation loss: 1.5333076818014986

Epoch: 398| Step: 0
Training loss: 0.13558021187782288
Validation loss: 1.54058628056639

Epoch: 6| Step: 1
Training loss: 0.07976950705051422
Validation loss: 1.549318613544587

Epoch: 6| Step: 2
Training loss: 0.06731121987104416
Validation loss: 1.588147383864208

Epoch: 6| Step: 3
Training loss: 0.09832403063774109
Validation loss: 1.558309006434615

Epoch: 6| Step: 4
Training loss: 0.1281934678554535
Validation loss: 1.5583987864114905

Epoch: 6| Step: 5
Training loss: 0.09577562659978867
Validation loss: 1.5505329690953737

Epoch: 6| Step: 6
Training loss: 0.127424955368042
Validation loss: 1.5721372929952477

Epoch: 6| Step: 7
Training loss: 0.13388894498348236
Validation loss: 1.5403108269937578

Epoch: 6| Step: 8
Training loss: 0.06889985501766205
Validation loss: 1.5682015342097129

Epoch: 6| Step: 9
Training loss: 0.10301566869020462
Validation loss: 1.5474019415916935

Epoch: 6| Step: 10
Training loss: 0.15816447138786316
Validation loss: 1.5440099034258115

Epoch: 6| Step: 11
Training loss: 0.08491363376379013
Validation loss: 1.5342796951211908

Epoch: 6| Step: 12
Training loss: 0.10932354629039764
Validation loss: 1.5482548577811128

Epoch: 6| Step: 13
Training loss: 0.11234758794307709
Validation loss: 1.5369468453109905

Epoch: 399| Step: 0
Training loss: 0.10483633726835251
Validation loss: 1.5413323448550316

Epoch: 6| Step: 1
Training loss: 0.06571047008037567
Validation loss: 1.5307964381351267

Epoch: 6| Step: 2
Training loss: 0.12247735261917114
Validation loss: 1.5539969987766717

Epoch: 6| Step: 3
Training loss: 0.15473321080207825
Validation loss: 1.548867061573972

Epoch: 6| Step: 4
Training loss: 0.09300832450389862
Validation loss: 1.5390326848594091

Epoch: 6| Step: 5
Training loss: 0.15810666978359222
Validation loss: 1.57434251487896

Epoch: 6| Step: 6
Training loss: 0.1200423613190651
Validation loss: 1.542348930912633

Epoch: 6| Step: 7
Training loss: 0.14670242369174957
Validation loss: 1.541116338904186

Epoch: 6| Step: 8
Training loss: 0.12495727092027664
Validation loss: 1.5791580779578096

Epoch: 6| Step: 9
Training loss: 0.15569353103637695
Validation loss: 1.5524377284511444

Epoch: 6| Step: 10
Training loss: 0.09472189843654633
Validation loss: 1.5557948645725046

Epoch: 6| Step: 11
Training loss: 0.09156370162963867
Validation loss: 1.543644647444448

Epoch: 6| Step: 12
Training loss: 0.14575418829917908
Validation loss: 1.5208123396801692

Epoch: 6| Step: 13
Training loss: 0.09001781791448593
Validation loss: 1.5433010824265019

Epoch: 400| Step: 0
Training loss: 0.09876397252082825
Validation loss: 1.51789750014582

Epoch: 6| Step: 1
Training loss: 0.09607338905334473
Validation loss: 1.5018014190017537

Epoch: 6| Step: 2
Training loss: 0.14579899609088898
Validation loss: 1.5022302455799554

Epoch: 6| Step: 3
Training loss: 0.17872965335845947
Validation loss: 1.522456180664801

Epoch: 6| Step: 4
Training loss: 0.11802904307842255
Validation loss: 1.527176849303707

Epoch: 6| Step: 5
Training loss: 0.06661280989646912
Validation loss: 1.524707729457527

Epoch: 6| Step: 6
Training loss: 0.08798417448997498
Validation loss: 1.5437163864412615

Epoch: 6| Step: 7
Training loss: 0.11798692494630814
Validation loss: 1.5582384217169978

Epoch: 6| Step: 8
Training loss: 0.15786899626255035
Validation loss: 1.551934330694137

Epoch: 6| Step: 9
Training loss: 0.11585267633199692
Validation loss: 1.5407348743049047

Epoch: 6| Step: 10
Training loss: 0.14855417609214783
Validation loss: 1.5555281036643571

Epoch: 6| Step: 11
Training loss: 0.0844697579741478
Validation loss: 1.5127097701513639

Epoch: 6| Step: 12
Training loss: 0.06966403126716614
Validation loss: 1.5016376228742703

Epoch: 6| Step: 13
Training loss: 0.08873830735683441
Validation loss: 1.5495120197214105

Epoch: 401| Step: 0
Training loss: 0.076909638941288
Validation loss: 1.57495125262968

Epoch: 6| Step: 1
Training loss: 0.12230345606803894
Validation loss: 1.538033099584682

Epoch: 6| Step: 2
Training loss: 0.1477290391921997
Validation loss: 1.599355475876921

Epoch: 6| Step: 3
Training loss: 0.13942652940750122
Validation loss: 1.5910103474893877

Epoch: 6| Step: 4
Training loss: 0.16929806768894196
Validation loss: 1.585164826403382

Epoch: 6| Step: 5
Training loss: 0.13509784638881683
Validation loss: 1.5658037713778916

Epoch: 6| Step: 6
Training loss: 0.06910213828086853
Validation loss: 1.5616476676797355

Epoch: 6| Step: 7
Training loss: 0.1167190819978714
Validation loss: 1.563659873700911

Epoch: 6| Step: 8
Training loss: 0.13409188389778137
Validation loss: 1.5588700643149755

Epoch: 6| Step: 9
Training loss: 0.1359708309173584
Validation loss: 1.5976261618316814

Epoch: 6| Step: 10
Training loss: 0.19693049788475037
Validation loss: 1.548895594894245

Epoch: 6| Step: 11
Training loss: 0.14836600422859192
Validation loss: 1.5704104413268387

Epoch: 6| Step: 12
Training loss: 0.10900197178125381
Validation loss: 1.5724338985258532

Epoch: 6| Step: 13
Training loss: 0.1515844762325287
Validation loss: 1.5590468798914263

Epoch: 402| Step: 0
Training loss: 0.07021203637123108
Validation loss: 1.5376573249857912

Epoch: 6| Step: 1
Training loss: 0.09347327053546906
Validation loss: 1.5572456685445641

Epoch: 6| Step: 2
Training loss: 0.09825322031974792
Validation loss: 1.5405616382116913

Epoch: 6| Step: 3
Training loss: 0.10079607367515564
Validation loss: 1.5442592815686298

Epoch: 6| Step: 4
Training loss: 0.16372084617614746
Validation loss: 1.557860166795792

Epoch: 6| Step: 5
Training loss: 0.06409165263175964
Validation loss: 1.5342530640222694

Epoch: 6| Step: 6
Training loss: 0.10096501559019089
Validation loss: 1.503884273190652

Epoch: 6| Step: 7
Training loss: 0.09494394063949585
Validation loss: 1.5271750355279574

Epoch: 6| Step: 8
Training loss: 0.1227225586771965
Validation loss: 1.5688484099603468

Epoch: 6| Step: 9
Training loss: 0.14610138535499573
Validation loss: 1.5609468580574117

Epoch: 6| Step: 10
Training loss: 0.09855958819389343
Validation loss: 1.5541860929099462

Epoch: 6| Step: 11
Training loss: 0.09977743029594421
Validation loss: 1.5449806246706235

Epoch: 6| Step: 12
Training loss: 0.0842365100979805
Validation loss: 1.545710035549697

Epoch: 6| Step: 13
Training loss: 0.133790522813797
Validation loss: 1.5520732761711202

Epoch: 403| Step: 0
Training loss: 0.10532799363136292
Validation loss: 1.5507471189703992

Epoch: 6| Step: 1
Training loss: 0.22072088718414307
Validation loss: 1.5642422988850584

Epoch: 6| Step: 2
Training loss: 0.11726412177085876
Validation loss: 1.5521587710226736

Epoch: 6| Step: 3
Training loss: 0.12936940789222717
Validation loss: 1.5278512431729225

Epoch: 6| Step: 4
Training loss: 0.11177536845207214
Validation loss: 1.5288145055053055

Epoch: 6| Step: 5
Training loss: 0.09212590754032135
Validation loss: 1.5155021529043875

Epoch: 6| Step: 6
Training loss: 0.14461049437522888
Validation loss: 1.4943821776297785

Epoch: 6| Step: 7
Training loss: 0.11666212975978851
Validation loss: 1.516265200030419

Epoch: 6| Step: 8
Training loss: 0.1501762419939041
Validation loss: 1.5356260127918695

Epoch: 6| Step: 9
Training loss: 0.16446055471897125
Validation loss: 1.568828567381828

Epoch: 6| Step: 10
Training loss: 0.061925508081912994
Validation loss: 1.5112246339039137

Epoch: 6| Step: 11
Training loss: 0.09555858373641968
Validation loss: 1.5483429303733252

Epoch: 6| Step: 12
Training loss: 0.16412591934204102
Validation loss: 1.5350752158831524

Epoch: 6| Step: 13
Training loss: 0.16320784389972687
Validation loss: 1.5442753273953673

Epoch: 404| Step: 0
Training loss: 0.06070161983370781
Validation loss: 1.5465878587897106

Epoch: 6| Step: 1
Training loss: 0.1337127834558487
Validation loss: 1.5504738053967875

Epoch: 6| Step: 2
Training loss: 0.17854878306388855
Validation loss: 1.5381393304435156

Epoch: 6| Step: 3
Training loss: 0.10221219062805176
Validation loss: 1.5730735627553796

Epoch: 6| Step: 4
Training loss: 0.16138571500778198
Validation loss: 1.573507329469086

Epoch: 6| Step: 5
Training loss: 0.1392587125301361
Validation loss: 1.5724395244352278

Epoch: 6| Step: 6
Training loss: 0.11362600326538086
Validation loss: 1.5264366422930071

Epoch: 6| Step: 7
Training loss: 0.07701154053211212
Validation loss: 1.5519249580239738

Epoch: 6| Step: 8
Training loss: 0.13128650188446045
Validation loss: 1.557995351411963

Epoch: 6| Step: 9
Training loss: 0.1534973382949829
Validation loss: 1.5725786609034385

Epoch: 6| Step: 10
Training loss: 0.23738624155521393
Validation loss: 1.5557129318996141

Epoch: 6| Step: 11
Training loss: 0.12921032309532166
Validation loss: 1.557792257237178

Epoch: 6| Step: 12
Training loss: 0.20993787050247192
Validation loss: 1.545669489009406

Epoch: 6| Step: 13
Training loss: 0.14374008774757385
Validation loss: 1.5341480380745345

Epoch: 405| Step: 0
Training loss: 0.10697084665298462
Validation loss: 1.5066133929837136

Epoch: 6| Step: 1
Training loss: 0.11634834110736847
Validation loss: 1.5503164875891902

Epoch: 6| Step: 2
Training loss: 0.16309306025505066
Validation loss: 1.514207669483718

Epoch: 6| Step: 3
Training loss: 0.08266352862119675
Validation loss: 1.5244185193892448

Epoch: 6| Step: 4
Training loss: 0.09522153437137604
Validation loss: 1.5481386325692619

Epoch: 6| Step: 5
Training loss: 0.07659856230020523
Validation loss: 1.5503452452280189

Epoch: 6| Step: 6
Training loss: 0.16966769099235535
Validation loss: 1.5346222859556957

Epoch: 6| Step: 7
Training loss: 0.14811056852340698
Validation loss: 1.5230902843577887

Epoch: 6| Step: 8
Training loss: 0.1361922025680542
Validation loss: 1.5286622816516506

Epoch: 6| Step: 9
Training loss: 0.0913923978805542
Validation loss: 1.5181046109045706

Epoch: 6| Step: 10
Training loss: 0.14770779013633728
Validation loss: 1.547522146214721

Epoch: 6| Step: 11
Training loss: 0.10071036964654922
Validation loss: 1.5412464141845703

Epoch: 6| Step: 12
Training loss: 0.1495531052350998
Validation loss: 1.56012043645305

Epoch: 6| Step: 13
Training loss: 0.1505780816078186
Validation loss: 1.5592697256354875

Epoch: 406| Step: 0
Training loss: 0.08598487079143524
Validation loss: 1.5579613139552455

Epoch: 6| Step: 1
Training loss: 0.1596149206161499
Validation loss: 1.558070751928514

Epoch: 6| Step: 2
Training loss: 0.07601580768823624
Validation loss: 1.5723483972651984

Epoch: 6| Step: 3
Training loss: 0.05551113933324814
Validation loss: 1.5789082665597238

Epoch: 6| Step: 4
Training loss: 0.06466346234083176
Validation loss: 1.557070303988713

Epoch: 6| Step: 5
Training loss: 0.09995445609092712
Validation loss: 1.5521208855413622

Epoch: 6| Step: 6
Training loss: 0.1087048351764679
Validation loss: 1.5636000299966464

Epoch: 6| Step: 7
Training loss: 0.12071206420660019
Validation loss: 1.5400765608715754

Epoch: 6| Step: 8
Training loss: 0.09691799432039261
Validation loss: 1.5457082833013227

Epoch: 6| Step: 9
Training loss: 0.07355169951915741
Validation loss: 1.5688844906386508

Epoch: 6| Step: 10
Training loss: 0.16068631410598755
Validation loss: 1.5559734067609232

Epoch: 6| Step: 11
Training loss: 0.1448603868484497
Validation loss: 1.5390831770435456

Epoch: 6| Step: 12
Training loss: 0.09286147356033325
Validation loss: 1.5485356418035363

Epoch: 6| Step: 13
Training loss: 0.15859991312026978
Validation loss: 1.5504636245389138

Epoch: 407| Step: 0
Training loss: 0.10345388948917389
Validation loss: 1.5505993154741102

Epoch: 6| Step: 1
Training loss: 0.0926099419593811
Validation loss: 1.5233009912634408

Epoch: 6| Step: 2
Training loss: 0.11155566573143005
Validation loss: 1.5360992967441518

Epoch: 6| Step: 3
Training loss: 0.11607341468334198
Validation loss: 1.5645730636453117

Epoch: 6| Step: 4
Training loss: 0.13980606198310852
Validation loss: 1.5636374335135184

Epoch: 6| Step: 5
Training loss: 0.13334789872169495
Validation loss: 1.5485678103662306

Epoch: 6| Step: 6
Training loss: 0.20449981093406677
Validation loss: 1.5430148827132357

Epoch: 6| Step: 7
Training loss: 0.16414663195610046
Validation loss: 1.519256430287515

Epoch: 6| Step: 8
Training loss: 0.13194888830184937
Validation loss: 1.5280636689996208

Epoch: 6| Step: 9
Training loss: 0.1150086522102356
Validation loss: 1.5592251375157347

Epoch: 6| Step: 10
Training loss: 0.08376775681972504
Validation loss: 1.5471582130719257

Epoch: 6| Step: 11
Training loss: 0.07125665247440338
Validation loss: 1.5551670507718158

Epoch: 6| Step: 12
Training loss: 0.09001186490058899
Validation loss: 1.5404219345379901

Epoch: 6| Step: 13
Training loss: 0.08335866034030914
Validation loss: 1.5509465689300208

Epoch: 408| Step: 0
Training loss: 0.13505254685878754
Validation loss: 1.5286810000737507

Epoch: 6| Step: 1
Training loss: 0.08529910445213318
Validation loss: 1.5495991770939161

Epoch: 6| Step: 2
Training loss: 0.16293266415596008
Validation loss: 1.5602424042199248

Epoch: 6| Step: 3
Training loss: 0.08282794058322906
Validation loss: 1.546424602949491

Epoch: 6| Step: 4
Training loss: 0.13474681973457336
Validation loss: 1.5727152709038026

Epoch: 6| Step: 5
Training loss: 0.1492619812488556
Validation loss: 1.59073337944605

Epoch: 6| Step: 6
Training loss: 0.056272827088832855
Validation loss: 1.5614119293869182

Epoch: 6| Step: 7
Training loss: 0.13249748945236206
Validation loss: 1.5554458736091532

Epoch: 6| Step: 8
Training loss: 0.11748684197664261
Validation loss: 1.527253920032132

Epoch: 6| Step: 9
Training loss: 0.08241192996501923
Validation loss: 1.5074905233998452

Epoch: 6| Step: 10
Training loss: 0.09782133251428604
Validation loss: 1.5223352063086726

Epoch: 6| Step: 11
Training loss: 0.11259870231151581
Validation loss: 1.5221891441652853

Epoch: 6| Step: 12
Training loss: 0.10297223925590515
Validation loss: 1.5312156754155313

Epoch: 6| Step: 13
Training loss: 0.07975023239850998
Validation loss: 1.5255179110393728

Epoch: 409| Step: 0
Training loss: 0.07066942751407623
Validation loss: 1.5364637874787854

Epoch: 6| Step: 1
Training loss: 0.1569884568452835
Validation loss: 1.5250433734668198

Epoch: 6| Step: 2
Training loss: 0.18756157159805298
Validation loss: 1.5576701189882012

Epoch: 6| Step: 3
Training loss: 0.19301405549049377
Validation loss: 1.5475743944926927

Epoch: 6| Step: 4
Training loss: 0.07828705757856369
Validation loss: 1.5448872729014325

Epoch: 6| Step: 5
Training loss: 0.0935324877500534
Validation loss: 1.5442886249993437

Epoch: 6| Step: 6
Training loss: 0.08294852077960968
Validation loss: 1.5680989347478396

Epoch: 6| Step: 7
Training loss: 0.09246193617582321
Validation loss: 1.5286123906412432

Epoch: 6| Step: 8
Training loss: 0.15210336446762085
Validation loss: 1.5472746433750275

Epoch: 6| Step: 9
Training loss: 0.13627707958221436
Validation loss: 1.5515888608911985

Epoch: 6| Step: 10
Training loss: 0.14263533055782318
Validation loss: 1.5188906141506728

Epoch: 6| Step: 11
Training loss: 0.08327517658472061
Validation loss: 1.5305676537175332

Epoch: 6| Step: 12
Training loss: 0.08011098206043243
Validation loss: 1.52899896073085

Epoch: 6| Step: 13
Training loss: 0.06992370635271072
Validation loss: 1.5584348376079271

Epoch: 410| Step: 0
Training loss: 0.14802703261375427
Validation loss: 1.5751579679468626

Epoch: 6| Step: 1
Training loss: 0.14063982665538788
Validation loss: 1.57138809850139

Epoch: 6| Step: 2
Training loss: 0.11435295641422272
Validation loss: 1.5467439710452993

Epoch: 6| Step: 3
Training loss: 0.11365606635808945
Validation loss: 1.5531516716044436

Epoch: 6| Step: 4
Training loss: 0.1284201294183731
Validation loss: 1.5736997306987803

Epoch: 6| Step: 5
Training loss: 0.13238167762756348
Validation loss: 1.5637871167993034

Epoch: 6| Step: 6
Training loss: 0.12198977917432785
Validation loss: 1.5329463084538777

Epoch: 6| Step: 7
Training loss: 0.10517993569374084
Validation loss: 1.5507524192974131

Epoch: 6| Step: 8
Training loss: 0.10507780313491821
Validation loss: 1.5761352021207091

Epoch: 6| Step: 9
Training loss: 0.10520822554826736
Validation loss: 1.5351315224042503

Epoch: 6| Step: 10
Training loss: 0.15887601673603058
Validation loss: 1.5551937600617767

Epoch: 6| Step: 11
Training loss: 0.06332972645759583
Validation loss: 1.5533116120164112

Epoch: 6| Step: 12
Training loss: 0.0821264311671257
Validation loss: 1.5514334773504606

Epoch: 6| Step: 13
Training loss: 0.12180941551923752
Validation loss: 1.5406199168133479

Epoch: 411| Step: 0
Training loss: 0.07641811668872833
Validation loss: 1.5435424799560218

Epoch: 6| Step: 1
Training loss: 0.09886758029460907
Validation loss: 1.544303673569874

Epoch: 6| Step: 2
Training loss: 0.09191570430994034
Validation loss: 1.5426653380035071

Epoch: 6| Step: 3
Training loss: 0.08974970132112503
Validation loss: 1.542487168824801

Epoch: 6| Step: 4
Training loss: 0.08350896090269089
Validation loss: 1.5498740980702062

Epoch: 6| Step: 5
Training loss: 0.10451658815145493
Validation loss: 1.5390760129497898

Epoch: 6| Step: 6
Training loss: 0.1326058954000473
Validation loss: 1.539028593288955

Epoch: 6| Step: 7
Training loss: 0.1556384563446045
Validation loss: 1.5178876474339476

Epoch: 6| Step: 8
Training loss: 0.13496467471122742
Validation loss: 1.5187600274239816

Epoch: 6| Step: 9
Training loss: 0.1250314712524414
Validation loss: 1.543287169548773

Epoch: 6| Step: 10
Training loss: 0.12268207222223282
Validation loss: 1.55619550776738

Epoch: 6| Step: 11
Training loss: 0.06704895943403244
Validation loss: 1.5395938786127235

Epoch: 6| Step: 12
Training loss: 0.07985430955886841
Validation loss: 1.5193787816391195

Epoch: 6| Step: 13
Training loss: 0.09116159379482269
Validation loss: 1.5340352904412053

Epoch: 412| Step: 0
Training loss: 0.10730381309986115
Validation loss: 1.5493112328231975

Epoch: 6| Step: 1
Training loss: 0.1166997104883194
Validation loss: 1.5463143664021646

Epoch: 6| Step: 2
Training loss: 0.19238637387752533
Validation loss: 1.5648080347686686

Epoch: 6| Step: 3
Training loss: 0.0992872565984726
Validation loss: 1.5762849238611036

Epoch: 6| Step: 4
Training loss: 0.10825388133525848
Validation loss: 1.5332687529184486

Epoch: 6| Step: 5
Training loss: 0.14218029379844666
Validation loss: 1.56056934531017

Epoch: 6| Step: 6
Training loss: 0.07619334012269974
Validation loss: 1.5504744873251965

Epoch: 6| Step: 7
Training loss: 0.1394670456647873
Validation loss: 1.5446017544756654

Epoch: 6| Step: 8
Training loss: 0.10429032891988754
Validation loss: 1.553394099717499

Epoch: 6| Step: 9
Training loss: 0.11026819050312042
Validation loss: 1.5355952003950715

Epoch: 6| Step: 10
Training loss: 0.14655160903930664
Validation loss: 1.564320779615833

Epoch: 6| Step: 11
Training loss: 0.17943063378334045
Validation loss: 1.551528997318719

Epoch: 6| Step: 12
Training loss: 0.09750238060951233
Validation loss: 1.5502023530262772

Epoch: 6| Step: 13
Training loss: 0.07748650014400482
Validation loss: 1.5576440544538601

Epoch: 413| Step: 0
Training loss: 0.07451269775629044
Validation loss: 1.5397626751212663

Epoch: 6| Step: 1
Training loss: 0.16330356895923615
Validation loss: 1.5062043218202488

Epoch: 6| Step: 2
Training loss: 0.06699297577142715
Validation loss: 1.5624439088247155

Epoch: 6| Step: 3
Training loss: 0.05713288113474846
Validation loss: 1.569731867441567

Epoch: 6| Step: 4
Training loss: 0.11075801402330399
Validation loss: 1.5628972168891662

Epoch: 6| Step: 5
Training loss: 0.10348662734031677
Validation loss: 1.5769641143019482

Epoch: 6| Step: 6
Training loss: 0.08440618216991425
Validation loss: 1.5326250714640464

Epoch: 6| Step: 7
Training loss: 0.09811245650053024
Validation loss: 1.5644811840467556

Epoch: 6| Step: 8
Training loss: 0.101407490670681
Validation loss: 1.5365773029224847

Epoch: 6| Step: 9
Training loss: 0.10033690929412842
Validation loss: 1.6071752591799664

Epoch: 6| Step: 10
Training loss: 0.06131488457322121
Validation loss: 1.5600907546217724

Epoch: 6| Step: 11
Training loss: 0.12791447341442108
Validation loss: 1.5636478213853733

Epoch: 6| Step: 12
Training loss: 0.11335733532905579
Validation loss: 1.5506593104331725

Epoch: 6| Step: 13
Training loss: 0.08278538286685944
Validation loss: 1.5134335243573753

Epoch: 414| Step: 0
Training loss: 0.1029919981956482
Validation loss: 1.5670828242455759

Epoch: 6| Step: 1
Training loss: 0.10984686017036438
Validation loss: 1.5503846688937115

Epoch: 6| Step: 2
Training loss: 0.1547490954399109
Validation loss: 1.5464107797991844

Epoch: 6| Step: 3
Training loss: 0.10374563187360764
Validation loss: 1.5493990400786042

Epoch: 6| Step: 4
Training loss: 0.09473292529582977
Validation loss: 1.5405384238048265

Epoch: 6| Step: 5
Training loss: 0.09315628558397293
Validation loss: 1.5192429814287411

Epoch: 6| Step: 6
Training loss: 0.09457775950431824
Validation loss: 1.5300089056773851

Epoch: 6| Step: 7
Training loss: 0.13276122510433197
Validation loss: 1.5629818683029504

Epoch: 6| Step: 8
Training loss: 0.11737073957920074
Validation loss: 1.5722634253963348

Epoch: 6| Step: 9
Training loss: 0.13762465119361877
Validation loss: 1.550420662408234

Epoch: 6| Step: 10
Training loss: 0.1248169019818306
Validation loss: 1.5646670185109621

Epoch: 6| Step: 11
Training loss: 0.1270400881767273
Validation loss: 1.548570716252891

Epoch: 6| Step: 12
Training loss: 0.14304323494434357
Validation loss: 1.5217268710495324

Epoch: 6| Step: 13
Training loss: 0.09696344286203384
Validation loss: 1.543934408054557

Epoch: 415| Step: 0
Training loss: 0.06986533105373383
Validation loss: 1.5084752728862147

Epoch: 6| Step: 1
Training loss: 0.150028258562088
Validation loss: 1.5139408393572735

Epoch: 6| Step: 2
Training loss: 0.24188348650932312
Validation loss: 1.5353451076374258

Epoch: 6| Step: 3
Training loss: 0.13157619535923004
Validation loss: 1.532625389355485

Epoch: 6| Step: 4
Training loss: 0.0858892947435379
Validation loss: 1.5254717834534184

Epoch: 6| Step: 5
Training loss: 0.09810968488454819
Validation loss: 1.5277862215554843

Epoch: 6| Step: 6
Training loss: 0.07578427344560623
Validation loss: 1.5171567073432348

Epoch: 6| Step: 7
Training loss: 0.0814693421125412
Validation loss: 1.5315596442068777

Epoch: 6| Step: 8
Training loss: 0.13388094305992126
Validation loss: 1.5348320930234847

Epoch: 6| Step: 9
Training loss: 0.09956201910972595
Validation loss: 1.5431894794587167

Epoch: 6| Step: 10
Training loss: 0.12938104569911957
Validation loss: 1.5621448409172796

Epoch: 6| Step: 11
Training loss: 0.11410875618457794
Validation loss: 1.5551530763667116

Epoch: 6| Step: 12
Training loss: 0.11415524035692215
Validation loss: 1.5741841677696473

Epoch: 6| Step: 13
Training loss: 0.08905717730522156
Validation loss: 1.5705702330476494

Epoch: 416| Step: 0
Training loss: 0.07867889851331711
Validation loss: 1.575807959802689

Epoch: 6| Step: 1
Training loss: 0.15281841158866882
Validation loss: 1.5619847838596632

Epoch: 6| Step: 2
Training loss: 0.12018605321645737
Validation loss: 1.5743706136621454

Epoch: 6| Step: 3
Training loss: 0.15780872106552124
Validation loss: 1.5675961471373034

Epoch: 6| Step: 4
Training loss: 0.10746987164020538
Validation loss: 1.5679065130090202

Epoch: 6| Step: 5
Training loss: 0.0912589505314827
Validation loss: 1.5700271001426123

Epoch: 6| Step: 6
Training loss: 0.052677132189273834
Validation loss: 1.580472784016722

Epoch: 6| Step: 7
Training loss: 0.1285419464111328
Validation loss: 1.5622636592516335

Epoch: 6| Step: 8
Training loss: 0.10399475693702698
Validation loss: 1.552468671593615

Epoch: 6| Step: 9
Training loss: 0.10175198316574097
Validation loss: 1.565025996136409

Epoch: 6| Step: 10
Training loss: 0.0851786732673645
Validation loss: 1.556866422776253

Epoch: 6| Step: 11
Training loss: 0.09816848486661911
Validation loss: 1.5491918966334353

Epoch: 6| Step: 12
Training loss: 0.08374738693237305
Validation loss: 1.5676389458358928

Epoch: 6| Step: 13
Training loss: 0.0767456665635109
Validation loss: 1.544989271830487

Epoch: 417| Step: 0
Training loss: 0.07965466380119324
Validation loss: 1.5456830788684148

Epoch: 6| Step: 1
Training loss: 0.09633467346429825
Validation loss: 1.5391276074993996

Epoch: 6| Step: 2
Training loss: 0.14765940606594086
Validation loss: 1.5329182141570634

Epoch: 6| Step: 3
Training loss: 0.1014631912112236
Validation loss: 1.5507080465234735

Epoch: 6| Step: 4
Training loss: 0.1079760491847992
Validation loss: 1.5799259139645485

Epoch: 6| Step: 5
Training loss: 0.07992318272590637
Validation loss: 1.554012910012276

Epoch: 6| Step: 6
Training loss: 0.1068698838353157
Validation loss: 1.5465496163214407

Epoch: 6| Step: 7
Training loss: 0.07705707103013992
Validation loss: 1.5586761351554625

Epoch: 6| Step: 8
Training loss: 0.10392186045646667
Validation loss: 1.5457680379190752

Epoch: 6| Step: 9
Training loss: 0.10634103417396545
Validation loss: 1.5424213345332811

Epoch: 6| Step: 10
Training loss: 0.07849659025669098
Validation loss: 1.569375967466703

Epoch: 6| Step: 11
Training loss: 0.09308219701051712
Validation loss: 1.538916846757294

Epoch: 6| Step: 12
Training loss: 0.0864255428314209
Validation loss: 1.5574536426092989

Epoch: 6| Step: 13
Training loss: 0.21368950605392456
Validation loss: 1.5710283364019086

Epoch: 418| Step: 0
Training loss: 0.175664484500885
Validation loss: 1.5384514639454503

Epoch: 6| Step: 1
Training loss: 0.0880897268652916
Validation loss: 1.5617419635095904

Epoch: 6| Step: 2
Training loss: 0.10256393998861313
Validation loss: 1.582707808863732

Epoch: 6| Step: 3
Training loss: 0.11837975680828094
Validation loss: 1.5691792862389677

Epoch: 6| Step: 4
Training loss: 0.04719625413417816
Validation loss: 1.5687764113949192

Epoch: 6| Step: 5
Training loss: 0.07024458050727844
Validation loss: 1.5518843576472292

Epoch: 6| Step: 6
Training loss: 0.1378905475139618
Validation loss: 1.5414484829031012

Epoch: 6| Step: 7
Training loss: 0.07690411806106567
Validation loss: 1.5509124827641312

Epoch: 6| Step: 8
Training loss: 0.07328583300113678
Validation loss: 1.5948163745223836

Epoch: 6| Step: 9
Training loss: 0.18777447938919067
Validation loss: 1.5913207620702765

Epoch: 6| Step: 10
Training loss: 0.0653613805770874
Validation loss: 1.5681952712356404

Epoch: 6| Step: 11
Training loss: 0.09135228395462036
Validation loss: 1.5555376724530292

Epoch: 6| Step: 12
Training loss: 0.08670979738235474
Validation loss: 1.5769484132848761

Epoch: 6| Step: 13
Training loss: 0.09472506493330002
Validation loss: 1.5737546707994194

Epoch: 419| Step: 0
Training loss: 0.10306894779205322
Validation loss: 1.5131934663300872

Epoch: 6| Step: 1
Training loss: 0.11637924611568451
Validation loss: 1.5406766245442052

Epoch: 6| Step: 2
Training loss: 0.09001895785331726
Validation loss: 1.5335707215852634

Epoch: 6| Step: 3
Training loss: 0.06775323301553726
Validation loss: 1.5426038170373568

Epoch: 6| Step: 4
Training loss: 0.10243253409862518
Validation loss: 1.5489073479047386

Epoch: 6| Step: 5
Training loss: 0.10408613085746765
Validation loss: 1.5761651198069255

Epoch: 6| Step: 6
Training loss: 0.08273851871490479
Validation loss: 1.558766480415098

Epoch: 6| Step: 7
Training loss: 0.08015591651201248
Validation loss: 1.5673345519650368

Epoch: 6| Step: 8
Training loss: 0.12890109419822693
Validation loss: 1.5475133862546695

Epoch: 6| Step: 9
Training loss: 0.08277775347232819
Validation loss: 1.564215120448861

Epoch: 6| Step: 10
Training loss: 0.08274886012077332
Validation loss: 1.5196544560053016

Epoch: 6| Step: 11
Training loss: 0.11599187552928925
Validation loss: 1.524006844848715

Epoch: 6| Step: 12
Training loss: 0.14102882146835327
Validation loss: 1.548214436859213

Epoch: 6| Step: 13
Training loss: 0.11442109942436218
Validation loss: 1.541997851863984

Epoch: 420| Step: 0
Training loss: 0.0878816545009613
Validation loss: 1.5435173716596378

Epoch: 6| Step: 1
Training loss: 0.15215849876403809
Validation loss: 1.538423325425835

Epoch: 6| Step: 2
Training loss: 0.12814250588417053
Validation loss: 1.5354179297724078

Epoch: 6| Step: 3
Training loss: 0.12144844233989716
Validation loss: 1.5111410438373525

Epoch: 6| Step: 4
Training loss: 0.060049109160900116
Validation loss: 1.5372426971312492

Epoch: 6| Step: 5
Training loss: 0.09010666608810425
Validation loss: 1.526557457703416

Epoch: 6| Step: 6
Training loss: 0.106656014919281
Validation loss: 1.5270394074019564

Epoch: 6| Step: 7
Training loss: 0.13332626223564148
Validation loss: 1.5820769776580155

Epoch: 6| Step: 8
Training loss: 0.09712138772010803
Validation loss: 1.539778717102543

Epoch: 6| Step: 9
Training loss: 0.12513402104377747
Validation loss: 1.5231503696851834

Epoch: 6| Step: 10
Training loss: 0.08331724256277084
Validation loss: 1.5076143985153527

Epoch: 6| Step: 11
Training loss: 0.09919866919517517
Validation loss: 1.5307582245078137

Epoch: 6| Step: 12
Training loss: 0.07200384140014648
Validation loss: 1.510858057647623

Epoch: 6| Step: 13
Training loss: 0.06675209105014801
Validation loss: 1.5118839689480361

Epoch: 421| Step: 0
Training loss: 0.0944749265909195
Validation loss: 1.5309060427450365

Epoch: 6| Step: 1
Training loss: 0.13231512904167175
Validation loss: 1.5298616527229227

Epoch: 6| Step: 2
Training loss: 0.1462949812412262
Validation loss: 1.5619313716888428

Epoch: 6| Step: 3
Training loss: 0.10859058052301407
Validation loss: 1.554336505551492

Epoch: 6| Step: 4
Training loss: 0.14646020531654358
Validation loss: 1.5442449687629618

Epoch: 6| Step: 5
Training loss: 0.10151404142379761
Validation loss: 1.5255746123611287

Epoch: 6| Step: 6
Training loss: 0.09028567373752594
Validation loss: 1.5071233216152395

Epoch: 6| Step: 7
Training loss: 0.09460240602493286
Validation loss: 1.5073192773326751

Epoch: 6| Step: 8
Training loss: 0.08971743285655975
Validation loss: 1.5133774588184972

Epoch: 6| Step: 9
Training loss: 0.0731736272573471
Validation loss: 1.521759181894282

Epoch: 6| Step: 10
Training loss: 0.09439411759376526
Validation loss: 1.505954207912568

Epoch: 6| Step: 11
Training loss: 0.13125422596931458
Validation loss: 1.515609839911102

Epoch: 6| Step: 12
Training loss: 0.08658207952976227
Validation loss: 1.5001607146314395

Epoch: 6| Step: 13
Training loss: 0.09151103347539902
Validation loss: 1.5168533914832658

Epoch: 422| Step: 0
Training loss: 0.06580497324466705
Validation loss: 1.5525613638662523

Epoch: 6| Step: 1
Training loss: 0.09028397500514984
Validation loss: 1.5465205856548843

Epoch: 6| Step: 2
Training loss: 0.07835251092910767
Validation loss: 1.5168122963238788

Epoch: 6| Step: 3
Training loss: 0.07132041454315186
Validation loss: 1.520791385763435

Epoch: 6| Step: 4
Training loss: 0.10597527772188187
Validation loss: 1.5086448756597375

Epoch: 6| Step: 5
Training loss: 0.05145992711186409
Validation loss: 1.5330721665454168

Epoch: 6| Step: 6
Training loss: 0.13246160745620728
Validation loss: 1.5356692344911638

Epoch: 6| Step: 7
Training loss: 0.14050936698913574
Validation loss: 1.5392981908654655

Epoch: 6| Step: 8
Training loss: 0.09974279999732971
Validation loss: 1.554907997449239

Epoch: 6| Step: 9
Training loss: 0.11884323507547379
Validation loss: 1.569183616228001

Epoch: 6| Step: 10
Training loss: 0.08686885982751846
Validation loss: 1.549616704704941

Epoch: 6| Step: 11
Training loss: 0.07679785788059235
Validation loss: 1.5479960005770448

Epoch: 6| Step: 12
Training loss: 0.12553739547729492
Validation loss: 1.5405891326165968

Epoch: 6| Step: 13
Training loss: 0.07426652312278748
Validation loss: 1.58169226877151

Epoch: 423| Step: 0
Training loss: 0.0707584023475647
Validation loss: 1.537880451448502

Epoch: 6| Step: 1
Training loss: 0.07807298749685287
Validation loss: 1.575958212216695

Epoch: 6| Step: 2
Training loss: 0.0882824957370758
Validation loss: 1.5602151463108678

Epoch: 6| Step: 3
Training loss: 0.12522493302822113
Validation loss: 1.5641220103028

Epoch: 6| Step: 4
Training loss: 0.08633637428283691
Validation loss: 1.5631280945193382

Epoch: 6| Step: 5
Training loss: 0.10436952114105225
Validation loss: 1.5753645076546618

Epoch: 6| Step: 6
Training loss: 0.09425929188728333
Validation loss: 1.5477487041104225

Epoch: 6| Step: 7
Training loss: 0.0632818192243576
Validation loss: 1.5781494725135066

Epoch: 6| Step: 8
Training loss: 0.14441466331481934
Validation loss: 1.5449627304589877

Epoch: 6| Step: 9
Training loss: 0.06087026745080948
Validation loss: 1.541046057977984

Epoch: 6| Step: 10
Training loss: 0.061434030532836914
Validation loss: 1.5490508669166154

Epoch: 6| Step: 11
Training loss: 0.07427582889795303
Validation loss: 1.5527901931475567

Epoch: 6| Step: 12
Training loss: 0.11629730463027954
Validation loss: 1.538821203734285

Epoch: 6| Step: 13
Training loss: 0.17534534633159637
Validation loss: 1.5471094603179603

Epoch: 424| Step: 0
Training loss: 0.1327570229768753
Validation loss: 1.5269073568364626

Epoch: 6| Step: 1
Training loss: 0.09092444181442261
Validation loss: 1.5362856708547121

Epoch: 6| Step: 2
Training loss: 0.04613185673952103
Validation loss: 1.5308025966408432

Epoch: 6| Step: 3
Training loss: 0.13868969678878784
Validation loss: 1.5203742859184102

Epoch: 6| Step: 4
Training loss: 0.11275963485240936
Validation loss: 1.5556800865357923

Epoch: 6| Step: 5
Training loss: 0.0677146464586258
Validation loss: 1.5542583773213048

Epoch: 6| Step: 6
Training loss: 0.11659470200538635
Validation loss: 1.5655175665373444

Epoch: 6| Step: 7
Training loss: 0.1505701243877411
Validation loss: 1.5660223409693728

Epoch: 6| Step: 8
Training loss: 0.1021483764052391
Validation loss: 1.5461410873679704

Epoch: 6| Step: 9
Training loss: 0.12022645026445389
Validation loss: 1.5527376327463376

Epoch: 6| Step: 10
Training loss: 0.12429085373878479
Validation loss: 1.5378972112491567

Epoch: 6| Step: 11
Training loss: 0.07727751135826111
Validation loss: 1.5296545208141368

Epoch: 6| Step: 12
Training loss: 0.08808733522891998
Validation loss: 1.533377629454418

Epoch: 6| Step: 13
Training loss: 0.17010971903800964
Validation loss: 1.5601896432138258

Epoch: 425| Step: 0
Training loss: 0.11659832298755646
Validation loss: 1.5386372573914067

Epoch: 6| Step: 1
Training loss: 0.1375923454761505
Validation loss: 1.5403805676326956

Epoch: 6| Step: 2
Training loss: 0.1370449811220169
Validation loss: 1.5641124633050734

Epoch: 6| Step: 3
Training loss: 0.1111053079366684
Validation loss: 1.5367344015388078

Epoch: 6| Step: 4
Training loss: 0.12922325730323792
Validation loss: 1.5512603277801185

Epoch: 6| Step: 5
Training loss: 0.08118553459644318
Validation loss: 1.5290767851696219

Epoch: 6| Step: 6
Training loss: 0.07599063962697983
Validation loss: 1.526050160008092

Epoch: 6| Step: 7
Training loss: 0.054195042699575424
Validation loss: 1.5472315344759213

Epoch: 6| Step: 8
Training loss: 0.11218585073947906
Validation loss: 1.5501690679980862

Epoch: 6| Step: 9
Training loss: 0.06550323218107224
Validation loss: 1.5270674510668683

Epoch: 6| Step: 10
Training loss: 0.11870815604925156
Validation loss: 1.5066662680718206

Epoch: 6| Step: 11
Training loss: 0.0793464258313179
Validation loss: 1.5356216199936406

Epoch: 6| Step: 12
Training loss: 0.06641379743814468
Validation loss: 1.510655758201435

Epoch: 6| Step: 13
Training loss: 0.13743112981319427
Validation loss: 1.523576859504946

Epoch: 426| Step: 0
Training loss: 0.06649906933307648
Validation loss: 1.5316558563581077

Epoch: 6| Step: 1
Training loss: 0.1003081202507019
Validation loss: 1.5363004745975617

Epoch: 6| Step: 2
Training loss: 0.11877454072237015
Validation loss: 1.5330018125554568

Epoch: 6| Step: 3
Training loss: 0.13445401191711426
Validation loss: 1.5542877515157063

Epoch: 6| Step: 4
Training loss: 0.10534598678350449
Validation loss: 1.5497711582850384

Epoch: 6| Step: 5
Training loss: 0.08256328850984573
Validation loss: 1.5508387357957902

Epoch: 6| Step: 6
Training loss: 0.13976868987083435
Validation loss: 1.5559046704282042

Epoch: 6| Step: 7
Training loss: 0.13430503010749817
Validation loss: 1.5538785316610848

Epoch: 6| Step: 8
Training loss: 0.07964569330215454
Validation loss: 1.5590057142319218

Epoch: 6| Step: 9
Training loss: 0.1136886328458786
Validation loss: 1.5210306388075634

Epoch: 6| Step: 10
Training loss: 0.12937581539154053
Validation loss: 1.5423714422410535

Epoch: 6| Step: 11
Training loss: 0.08188025653362274
Validation loss: 1.5456065964955155

Epoch: 6| Step: 12
Training loss: 0.09192325174808502
Validation loss: 1.5165295318890644

Epoch: 6| Step: 13
Training loss: 0.14866669476032257
Validation loss: 1.5229636135921683

Epoch: 427| Step: 0
Training loss: 0.12051308155059814
Validation loss: 1.5130905489767752

Epoch: 6| Step: 1
Training loss: 0.0578605979681015
Validation loss: 1.5008310707666541

Epoch: 6| Step: 2
Training loss: 0.11530410498380661
Validation loss: 1.4903558915661228

Epoch: 6| Step: 3
Training loss: 0.10006146878004074
Validation loss: 1.493394354338287

Epoch: 6| Step: 4
Training loss: 0.15080684423446655
Validation loss: 1.5020374098131735

Epoch: 6| Step: 5
Training loss: 0.10368199646472931
Validation loss: 1.4952524221071632

Epoch: 6| Step: 6
Training loss: 0.0897865742444992
Validation loss: 1.5360039459761752

Epoch: 6| Step: 7
Training loss: 0.1886233389377594
Validation loss: 1.5048392985456733

Epoch: 6| Step: 8
Training loss: 0.07324287295341492
Validation loss: 1.5086318023743168

Epoch: 6| Step: 9
Training loss: 0.05272872745990753
Validation loss: 1.4931525120171167

Epoch: 6| Step: 10
Training loss: 0.08605650067329407
Validation loss: 1.4935970537124141

Epoch: 6| Step: 11
Training loss: 0.14583779871463776
Validation loss: 1.5180785598293427

Epoch: 6| Step: 12
Training loss: 0.0993429645895958
Validation loss: 1.5127231010826685

Epoch: 6| Step: 13
Training loss: 0.12598583102226257
Validation loss: 1.5089154012741581

Epoch: 428| Step: 0
Training loss: 0.10951147973537445
Validation loss: 1.5147780577341716

Epoch: 6| Step: 1
Training loss: 0.0866183340549469
Validation loss: 1.5461526686145413

Epoch: 6| Step: 2
Training loss: 0.09449034184217453
Validation loss: 1.5366330377517208

Epoch: 6| Step: 3
Training loss: 0.11559777706861496
Validation loss: 1.554168370462233

Epoch: 6| Step: 4
Training loss: 0.06644131988286972
Validation loss: 1.545844297255239

Epoch: 6| Step: 5
Training loss: 0.10339867323637009
Validation loss: 1.5271486492567166

Epoch: 6| Step: 6
Training loss: 0.09246817231178284
Validation loss: 1.5323868989944458

Epoch: 6| Step: 7
Training loss: 0.10528145730495453
Validation loss: 1.5019491295660696

Epoch: 6| Step: 8
Training loss: 0.09084532409906387
Validation loss: 1.5186098339737102

Epoch: 6| Step: 9
Training loss: 0.04569926857948303
Validation loss: 1.5161159307725969

Epoch: 6| Step: 10
Training loss: 0.118168406188488
Validation loss: 1.5165163464443658

Epoch: 6| Step: 11
Training loss: 0.13097262382507324
Validation loss: 1.5174396852011323

Epoch: 6| Step: 12
Training loss: 0.13011714816093445
Validation loss: 1.5402393379519064

Epoch: 6| Step: 13
Training loss: 0.13033080101013184
Validation loss: 1.5193094284303728

Epoch: 429| Step: 0
Training loss: 0.05718327313661575
Validation loss: 1.5288996670835762

Epoch: 6| Step: 1
Training loss: 0.10057296603918076
Validation loss: 1.5544717619496007

Epoch: 6| Step: 2
Training loss: 0.10414637625217438
Validation loss: 1.534584197946774

Epoch: 6| Step: 3
Training loss: 0.12080205976963043
Validation loss: 1.5577322795826902

Epoch: 6| Step: 4
Training loss: 0.08484318852424622
Validation loss: 1.5614650634027296

Epoch: 6| Step: 5
Training loss: 0.1074775978922844
Validation loss: 1.5506629161937262

Epoch: 6| Step: 6
Training loss: 0.10638146102428436
Validation loss: 1.5756394869537764

Epoch: 6| Step: 7
Training loss: 0.14793598651885986
Validation loss: 1.5489205506540114

Epoch: 6| Step: 8
Training loss: 0.1629955917596817
Validation loss: 1.6104047913705148

Epoch: 6| Step: 9
Training loss: 0.11507207155227661
Validation loss: 1.5969910608824862

Epoch: 6| Step: 10
Training loss: 0.0767807587981224
Validation loss: 1.5937232073917185

Epoch: 6| Step: 11
Training loss: 0.1276819407939911
Validation loss: 1.5952670023005495

Epoch: 6| Step: 12
Training loss: 0.05956641584634781
Validation loss: 1.5760151493933894

Epoch: 6| Step: 13
Training loss: 0.0754697322845459
Validation loss: 1.5406501395727998

Epoch: 430| Step: 0
Training loss: 0.08781734853982925
Validation loss: 1.5613477537708897

Epoch: 6| Step: 1
Training loss: 0.11132844537496567
Validation loss: 1.5299347421174407

Epoch: 6| Step: 2
Training loss: 0.10336416959762573
Validation loss: 1.529482462072885

Epoch: 6| Step: 3
Training loss: 0.05939038097858429
Validation loss: 1.5383333570213729

Epoch: 6| Step: 4
Training loss: 0.1257559359073639
Validation loss: 1.543685902831375

Epoch: 6| Step: 5
Training loss: 0.08622823655605316
Validation loss: 1.5293889391806819

Epoch: 6| Step: 6
Training loss: 0.06099274754524231
Validation loss: 1.5228758242822462

Epoch: 6| Step: 7
Training loss: 0.1455797255039215
Validation loss: 1.5468339407315819

Epoch: 6| Step: 8
Training loss: 0.07936496287584305
Validation loss: 1.5234677906959289

Epoch: 6| Step: 9
Training loss: 0.06934723258018494
Validation loss: 1.538130493574245

Epoch: 6| Step: 10
Training loss: 0.13265398144721985
Validation loss: 1.5276954071496123

Epoch: 6| Step: 11
Training loss: 0.08846040815114975
Validation loss: 1.523871209031792

Epoch: 6| Step: 12
Training loss: 0.09777035564184189
Validation loss: 1.5360586277900203

Epoch: 6| Step: 13
Training loss: 0.1552344411611557
Validation loss: 1.539494393974222

Epoch: 431| Step: 0
Training loss: 0.05709933862090111
Validation loss: 1.540966760086757

Epoch: 6| Step: 1
Training loss: 0.1688878834247589
Validation loss: 1.5203797471138738

Epoch: 6| Step: 2
Training loss: 0.08510420471429825
Validation loss: 1.4815698426256898

Epoch: 6| Step: 3
Training loss: 0.10012925416231155
Validation loss: 1.5095333489038611

Epoch: 6| Step: 4
Training loss: 0.08521808683872223
Validation loss: 1.5323189778994488

Epoch: 6| Step: 5
Training loss: 0.10027472674846649
Validation loss: 1.5294732611666444

Epoch: 6| Step: 6
Training loss: 0.08423105627298355
Validation loss: 1.557900792808943

Epoch: 6| Step: 7
Training loss: 0.058785513043403625
Validation loss: 1.5623290320878387

Epoch: 6| Step: 8
Training loss: 0.08879704773426056
Validation loss: 1.5317274601228776

Epoch: 6| Step: 9
Training loss: 0.1013440266251564
Validation loss: 1.5539040155308221

Epoch: 6| Step: 10
Training loss: 0.08188659697771072
Validation loss: 1.5374059010577459

Epoch: 6| Step: 11
Training loss: 0.07106930017471313
Validation loss: 1.5276409708043581

Epoch: 6| Step: 12
Training loss: 0.0794670358300209
Validation loss: 1.5029184523449148

Epoch: 6| Step: 13
Training loss: 0.16565074026584625
Validation loss: 1.5347773810868621

Epoch: 432| Step: 0
Training loss: 0.08346308767795563
Validation loss: 1.5080131792253064

Epoch: 6| Step: 1
Training loss: 0.07261058688163757
Validation loss: 1.5190548025151736

Epoch: 6| Step: 2
Training loss: 0.1373916119337082
Validation loss: 1.5082018516396964

Epoch: 6| Step: 3
Training loss: 0.08094280958175659
Validation loss: 1.5275228895166868

Epoch: 6| Step: 4
Training loss: 0.07126687467098236
Validation loss: 1.5050353542450936

Epoch: 6| Step: 5
Training loss: 0.12401434779167175
Validation loss: 1.5107805587912118

Epoch: 6| Step: 6
Training loss: 0.1099727526307106
Validation loss: 1.495991696593582

Epoch: 6| Step: 7
Training loss: 0.07627072930335999
Validation loss: 1.4876874569923646

Epoch: 6| Step: 8
Training loss: 0.1476990282535553
Validation loss: 1.4840520761346305

Epoch: 6| Step: 9
Training loss: 0.11669450998306274
Validation loss: 1.4962833440431984

Epoch: 6| Step: 10
Training loss: 0.14360767602920532
Validation loss: 1.4854594622888873

Epoch: 6| Step: 11
Training loss: 0.09810882806777954
Validation loss: 1.496174241906853

Epoch: 6| Step: 12
Training loss: 0.10408461838960648
Validation loss: 1.4953514914358816

Epoch: 6| Step: 13
Training loss: 0.11615337431430817
Validation loss: 1.477606286284744

Epoch: 433| Step: 0
Training loss: 0.08088530600070953
Validation loss: 1.5063941158274168

Epoch: 6| Step: 1
Training loss: 0.07534836232662201
Validation loss: 1.5171308184182772

Epoch: 6| Step: 2
Training loss: 0.07370136678218842
Validation loss: 1.5349493866325707

Epoch: 6| Step: 3
Training loss: 0.0789370909333229
Validation loss: 1.5128259184539958

Epoch: 6| Step: 4
Training loss: 0.1386493444442749
Validation loss: 1.517048596053995

Epoch: 6| Step: 5
Training loss: 0.07339233160018921
Validation loss: 1.5620213311205629

Epoch: 6| Step: 6
Training loss: 0.05847235023975372
Validation loss: 1.5356765190760295

Epoch: 6| Step: 7
Training loss: 0.10895024240016937
Validation loss: 1.5490737551002092

Epoch: 6| Step: 8
Training loss: 0.1248675063252449
Validation loss: 1.5602574732995802

Epoch: 6| Step: 9
Training loss: 0.11335873603820801
Validation loss: 1.5503195895943591

Epoch: 6| Step: 10
Training loss: 0.09131219983100891
Validation loss: 1.539057368873268

Epoch: 6| Step: 11
Training loss: 0.15003368258476257
Validation loss: 1.557409236508031

Epoch: 6| Step: 12
Training loss: 0.10951051115989685
Validation loss: 1.5678579743190477

Epoch: 6| Step: 13
Training loss: 0.11286064237356186
Validation loss: 1.5587812854397682

Epoch: 434| Step: 0
Training loss: 0.10905514657497406
Validation loss: 1.5588378572976718

Epoch: 6| Step: 1
Training loss: 0.09315425157546997
Validation loss: 1.528464889013639

Epoch: 6| Step: 2
Training loss: 0.10541382431983948
Validation loss: 1.5280115489036805

Epoch: 6| Step: 3
Training loss: 0.08149930834770203
Validation loss: 1.5268290119786416

Epoch: 6| Step: 4
Training loss: 0.09865694493055344
Validation loss: 1.520060509763738

Epoch: 6| Step: 5
Training loss: 0.10332680493593216
Validation loss: 1.5248311437586302

Epoch: 6| Step: 6
Training loss: 0.11516618728637695
Validation loss: 1.5194738654680149

Epoch: 6| Step: 7
Training loss: 0.07517135888338089
Validation loss: 1.5153518607539516

Epoch: 6| Step: 8
Training loss: 0.11510882526636124
Validation loss: 1.5416587027170325

Epoch: 6| Step: 9
Training loss: 0.11487293243408203
Validation loss: 1.534459687048389

Epoch: 6| Step: 10
Training loss: 0.08590573072433472
Validation loss: 1.5055374221135212

Epoch: 6| Step: 11
Training loss: 0.0909188836812973
Validation loss: 1.4995414121176607

Epoch: 6| Step: 12
Training loss: 0.09758757054805756
Validation loss: 1.5023051461865824

Epoch: 6| Step: 13
Training loss: 0.05011599510908127
Validation loss: 1.5189401590695946

Epoch: 435| Step: 0
Training loss: 0.149497851729393
Validation loss: 1.5101264119148254

Epoch: 6| Step: 1
Training loss: 0.07068291306495667
Validation loss: 1.5248683857661423

Epoch: 6| Step: 2
Training loss: 0.09624287486076355
Validation loss: 1.5423144935279764

Epoch: 6| Step: 3
Training loss: 0.10839353501796722
Validation loss: 1.5458660946097424

Epoch: 6| Step: 4
Training loss: 0.08022032678127289
Validation loss: 1.5364113456459456

Epoch: 6| Step: 5
Training loss: 0.06680728495121002
Validation loss: 1.5199655332872946

Epoch: 6| Step: 6
Training loss: 0.08982974290847778
Validation loss: 1.5590318082481303

Epoch: 6| Step: 7
Training loss: 0.10219822078943253
Validation loss: 1.5763628611000635

Epoch: 6| Step: 8
Training loss: 0.09812311083078384
Validation loss: 1.55582013950553

Epoch: 6| Step: 9
Training loss: 0.10792837291955948
Validation loss: 1.5693351402077624

Epoch: 6| Step: 10
Training loss: 0.07424818724393845
Validation loss: 1.5401201940351916

Epoch: 6| Step: 11
Training loss: 0.0645507276058197
Validation loss: 1.5446879069010417

Epoch: 6| Step: 12
Training loss: 0.07893115282058716
Validation loss: 1.5349057592371458

Epoch: 6| Step: 13
Training loss: 0.08130817115306854
Validation loss: 1.5342591693324428

Epoch: 436| Step: 0
Training loss: 0.06581258773803711
Validation loss: 1.5755047541792675

Epoch: 6| Step: 1
Training loss: 0.05451428145170212
Validation loss: 1.5443161033814954

Epoch: 6| Step: 2
Training loss: 0.07475683838129044
Validation loss: 1.5782492981162122

Epoch: 6| Step: 3
Training loss: 0.05033239349722862
Validation loss: 1.5257651754604873

Epoch: 6| Step: 4
Training loss: 0.054786503314971924
Validation loss: 1.5400364821957004

Epoch: 6| Step: 5
Training loss: 0.0700225904583931
Validation loss: 1.5418282388358988

Epoch: 6| Step: 6
Training loss: 0.07535996288061142
Validation loss: 1.5493004578416065

Epoch: 6| Step: 7
Training loss: 0.07919061183929443
Validation loss: 1.5463053744326356

Epoch: 6| Step: 8
Training loss: 0.09852363914251328
Validation loss: 1.524482891123782

Epoch: 6| Step: 9
Training loss: 0.13502946496009827
Validation loss: 1.5311199439469205

Epoch: 6| Step: 10
Training loss: 0.08173586428165436
Validation loss: 1.5529251797224886

Epoch: 6| Step: 11
Training loss: 0.1249215379357338
Validation loss: 1.548728314779138

Epoch: 6| Step: 12
Training loss: 0.1297321617603302
Validation loss: 1.5346812471266715

Epoch: 6| Step: 13
Training loss: 0.13063740730285645
Validation loss: 1.5436890689275597

Epoch: 437| Step: 0
Training loss: 0.10193067044019699
Validation loss: 1.507561565727316

Epoch: 6| Step: 1
Training loss: 0.07132354378700256
Validation loss: 1.5461047894211226

Epoch: 6| Step: 2
Training loss: 0.10699131339788437
Validation loss: 1.5439209040775095

Epoch: 6| Step: 3
Training loss: 0.11435332894325256
Validation loss: 1.532040355026081

Epoch: 6| Step: 4
Training loss: 0.055518247187137604
Validation loss: 1.5560137841009325

Epoch: 6| Step: 5
Training loss: 0.07788380235433578
Validation loss: 1.5750559260768275

Epoch: 6| Step: 6
Training loss: 0.14562606811523438
Validation loss: 1.5866555295964724

Epoch: 6| Step: 7
Training loss: 0.12891586124897003
Validation loss: 1.5951356208452614

Epoch: 6| Step: 8
Training loss: 0.18228429555892944
Validation loss: 1.6028990899362872

Epoch: 6| Step: 9
Training loss: 0.07021953165531158
Validation loss: 1.5911632942897018

Epoch: 6| Step: 10
Training loss: 0.10380806773900986
Validation loss: 1.5892002146731141

Epoch: 6| Step: 11
Training loss: 0.11750076711177826
Validation loss: 1.577058498577405

Epoch: 6| Step: 12
Training loss: 0.11479423940181732
Validation loss: 1.5545727642633582

Epoch: 6| Step: 13
Training loss: 0.09886550158262253
Validation loss: 1.553435924232647

Epoch: 438| Step: 0
Training loss: 0.06154235824942589
Validation loss: 1.5707804823434481

Epoch: 6| Step: 1
Training loss: 0.06622364372015
Validation loss: 1.5394233542103921

Epoch: 6| Step: 2
Training loss: 0.06534959375858307
Validation loss: 1.5537992703017367

Epoch: 6| Step: 3
Training loss: 0.0764421671628952
Validation loss: 1.5714364769638225

Epoch: 6| Step: 4
Training loss: 0.05252305418252945
Validation loss: 1.5428708663550756

Epoch: 6| Step: 5
Training loss: 0.13047662377357483
Validation loss: 1.5436899098016883

Epoch: 6| Step: 6
Training loss: 0.10155552625656128
Validation loss: 1.5538086006718297

Epoch: 6| Step: 7
Training loss: 0.08430340886116028
Validation loss: 1.524655242120066

Epoch: 6| Step: 8
Training loss: 0.17619678378105164
Validation loss: 1.5537430310762057

Epoch: 6| Step: 9
Training loss: 0.1790616363286972
Validation loss: 1.5351540042508034

Epoch: 6| Step: 10
Training loss: 0.09963769465684891
Validation loss: 1.5469091220568585

Epoch: 6| Step: 11
Training loss: 0.06814160943031311
Validation loss: 1.5795606285013177

Epoch: 6| Step: 12
Training loss: 0.1162179633975029
Validation loss: 1.5460140141107703

Epoch: 6| Step: 13
Training loss: 0.11806130409240723
Validation loss: 1.5470355544038998

Epoch: 439| Step: 0
Training loss: 0.17086035013198853
Validation loss: 1.5685892489648634

Epoch: 6| Step: 1
Training loss: 0.18382206559181213
Validation loss: 1.5676140657035254

Epoch: 6| Step: 2
Training loss: 0.07616716623306274
Validation loss: 1.558814779404671

Epoch: 6| Step: 3
Training loss: 0.12921300530433655
Validation loss: 1.6189704184891076

Epoch: 6| Step: 4
Training loss: 0.11937651038169861
Validation loss: 1.558697792791551

Epoch: 6| Step: 5
Training loss: 0.0644526407122612
Validation loss: 1.5704416087878648

Epoch: 6| Step: 6
Training loss: 0.15960738062858582
Validation loss: 1.5580021078868578

Epoch: 6| Step: 7
Training loss: 0.06636349111795425
Validation loss: 1.5594583249861194

Epoch: 6| Step: 8
Training loss: 0.07532559335231781
Validation loss: 1.5994833618082025

Epoch: 6| Step: 9
Training loss: 0.15750883519649506
Validation loss: 1.5800621214733328

Epoch: 6| Step: 10
Training loss: 0.13849306106567383
Validation loss: 1.5749068849830217

Epoch: 6| Step: 11
Training loss: 0.16206291317939758
Validation loss: 1.5684349524077548

Epoch: 6| Step: 12
Training loss: 0.11619593948125839
Validation loss: 1.5559555099856468

Epoch: 6| Step: 13
Training loss: 0.08329425752162933
Validation loss: 1.5514339464966969

Epoch: 440| Step: 0
Training loss: 0.1038266122341156
Validation loss: 1.580672369208387

Epoch: 6| Step: 1
Training loss: 0.062061555683612823
Validation loss: 1.5400942333282963

Epoch: 6| Step: 2
Training loss: 0.08409473299980164
Validation loss: 1.559250352203205

Epoch: 6| Step: 3
Training loss: 0.11677699536085129
Validation loss: 1.5421944177278908

Epoch: 6| Step: 4
Training loss: 0.13325349986553192
Validation loss: 1.5436863001956735

Epoch: 6| Step: 5
Training loss: 0.1389322280883789
Validation loss: 1.5635185626245314

Epoch: 6| Step: 6
Training loss: 0.10740980505943298
Validation loss: 1.552277772657333

Epoch: 6| Step: 7
Training loss: 0.13220489025115967
Validation loss: 1.5582502054911789

Epoch: 6| Step: 8
Training loss: 0.130553737282753
Validation loss: 1.5676865910971036

Epoch: 6| Step: 9
Training loss: 0.17193973064422607
Validation loss: 1.5854790204314775

Epoch: 6| Step: 10
Training loss: 0.10749363154172897
Validation loss: 1.5838256125809045

Epoch: 6| Step: 11
Training loss: 0.05201401561498642
Validation loss: 1.5588231509731663

Epoch: 6| Step: 12
Training loss: 0.08274511247873306
Validation loss: 1.5631899628587949

Epoch: 6| Step: 13
Training loss: 0.14279699325561523
Validation loss: 1.565157482700963

Epoch: 441| Step: 0
Training loss: 0.10990028083324432
Validation loss: 1.5778967924015497

Epoch: 6| Step: 1
Training loss: 0.09241889417171478
Validation loss: 1.5705584454280075

Epoch: 6| Step: 2
Training loss: 0.15646091103553772
Validation loss: 1.5905483217649563

Epoch: 6| Step: 3
Training loss: 0.06720716506242752
Validation loss: 1.5777730031680035

Epoch: 6| Step: 4
Training loss: 0.05419588088989258
Validation loss: 1.5626235854241155

Epoch: 6| Step: 5
Training loss: 0.11434017866849899
Validation loss: 1.5728112882183445

Epoch: 6| Step: 6
Training loss: 0.09711351990699768
Validation loss: 1.5194566224211006

Epoch: 6| Step: 7
Training loss: 0.06301268190145493
Validation loss: 1.5624363371120986

Epoch: 6| Step: 8
Training loss: 0.08604399859905243
Validation loss: 1.5415695546775736

Epoch: 6| Step: 9
Training loss: 0.08348628878593445
Validation loss: 1.5482943186195948

Epoch: 6| Step: 10
Training loss: 0.12116850912570953
Validation loss: 1.5201668841864473

Epoch: 6| Step: 11
Training loss: 0.1427629441022873
Validation loss: 1.5358042973344044

Epoch: 6| Step: 12
Training loss: 0.1292910873889923
Validation loss: 1.5597025245748541

Epoch: 6| Step: 13
Training loss: 0.11227406561374664
Validation loss: 1.5362097063372213

Epoch: 442| Step: 0
Training loss: 0.11094844341278076
Validation loss: 1.5486528809352587

Epoch: 6| Step: 1
Training loss: 0.06798607110977173
Validation loss: 1.5476215680440266

Epoch: 6| Step: 2
Training loss: 0.10925794392824173
Validation loss: 1.5572210960490729

Epoch: 6| Step: 3
Training loss: 0.07686926424503326
Validation loss: 1.5960402129798807

Epoch: 6| Step: 4
Training loss: 0.15138179063796997
Validation loss: 1.5746107075804023

Epoch: 6| Step: 5
Training loss: 0.08585233986377716
Validation loss: 1.5741672644051172

Epoch: 6| Step: 6
Training loss: 0.06306950002908707
Validation loss: 1.557340184847514

Epoch: 6| Step: 7
Training loss: 0.0929916650056839
Validation loss: 1.59396198872597

Epoch: 6| Step: 8
Training loss: 0.09638325870037079
Validation loss: 1.562261482720734

Epoch: 6| Step: 9
Training loss: 0.07470391690731049
Validation loss: 1.597720738380186

Epoch: 6| Step: 10
Training loss: 0.18026943504810333
Validation loss: 1.5925913344147384

Epoch: 6| Step: 11
Training loss: 0.16378740966320038
Validation loss: 1.5997684399286907

Epoch: 6| Step: 12
Training loss: 0.15640296041965485
Validation loss: 1.5939248095276535

Epoch: 6| Step: 13
Training loss: 0.08657602220773697
Validation loss: 1.592293914287321

Epoch: 443| Step: 0
Training loss: 0.12735554575920105
Validation loss: 1.5877868244724889

Epoch: 6| Step: 1
Training loss: 0.10830048471689224
Validation loss: 1.5825849374135335

Epoch: 6| Step: 2
Training loss: 0.11686314642429352
Validation loss: 1.5652573224036925

Epoch: 6| Step: 3
Training loss: 0.10954216122627258
Validation loss: 1.6072826693134923

Epoch: 6| Step: 4
Training loss: 0.08505142480134964
Validation loss: 1.5794768025798183

Epoch: 6| Step: 5
Training loss: 0.08049143850803375
Validation loss: 1.6147996200028287

Epoch: 6| Step: 6
Training loss: 0.09786664694547653
Validation loss: 1.5990962264358357

Epoch: 6| Step: 7
Training loss: 0.0848652794957161
Validation loss: 1.599292464153741

Epoch: 6| Step: 8
Training loss: 0.08405161648988724
Validation loss: 1.5870246233478669

Epoch: 6| Step: 9
Training loss: 0.10650273412466049
Validation loss: 1.5730061941249396

Epoch: 6| Step: 10
Training loss: 0.1136486604809761
Validation loss: 1.5725363992875623

Epoch: 6| Step: 11
Training loss: 0.06800428032875061
Validation loss: 1.5738354165066955

Epoch: 6| Step: 12
Training loss: 0.12477494031190872
Validation loss: 1.564814047146869

Epoch: 6| Step: 13
Training loss: 0.11036111414432526
Validation loss: 1.5605665983692292

Epoch: 444| Step: 0
Training loss: 0.1510884016752243
Validation loss: 1.5416980276825607

Epoch: 6| Step: 1
Training loss: 0.14673852920532227
Validation loss: 1.5588220793713805

Epoch: 6| Step: 2
Training loss: 0.054070450365543365
Validation loss: 1.5392108373744513

Epoch: 6| Step: 3
Training loss: 0.07362138479948044
Validation loss: 1.5409155186786447

Epoch: 6| Step: 4
Training loss: 0.12956225872039795
Validation loss: 1.52872335398069

Epoch: 6| Step: 5
Training loss: 0.05845685303211212
Validation loss: 1.5590154663208993

Epoch: 6| Step: 6
Training loss: 0.05709289014339447
Validation loss: 1.5482904603404384

Epoch: 6| Step: 7
Training loss: 0.0888749286532402
Validation loss: 1.5731469815777195

Epoch: 6| Step: 8
Training loss: 0.1330614984035492
Validation loss: 1.5847185228460579

Epoch: 6| Step: 9
Training loss: 0.10998363792896271
Validation loss: 1.5757749593386086

Epoch: 6| Step: 10
Training loss: 0.10844919085502625
Validation loss: 1.564461802923551

Epoch: 6| Step: 11
Training loss: 0.15000274777412415
Validation loss: 1.546342025520981

Epoch: 6| Step: 12
Training loss: 0.12073170393705368
Validation loss: 1.5582140273945306

Epoch: 6| Step: 13
Training loss: 0.05345359072089195
Validation loss: 1.5795537963990243

Epoch: 445| Step: 0
Training loss: 0.09932010620832443
Validation loss: 1.5854389026600828

Epoch: 6| Step: 1
Training loss: 0.10487155616283417
Validation loss: 1.563430945078532

Epoch: 6| Step: 2
Training loss: 0.13390585780143738
Validation loss: 1.5550144974903395

Epoch: 6| Step: 3
Training loss: 0.06787452101707458
Validation loss: 1.549636653674546

Epoch: 6| Step: 4
Training loss: 0.13127842545509338
Validation loss: 1.5403426565149778

Epoch: 6| Step: 5
Training loss: 0.11770493537187576
Validation loss: 1.5426933662865752

Epoch: 6| Step: 6
Training loss: 0.07266577333211899
Validation loss: 1.5581940162566401

Epoch: 6| Step: 7
Training loss: 0.08987439423799515
Validation loss: 1.5634988725826304

Epoch: 6| Step: 8
Training loss: 0.13418160378932953
Validation loss: 1.5635724606052521

Epoch: 6| Step: 9
Training loss: 0.2194233536720276
Validation loss: 1.572429145536115

Epoch: 6| Step: 10
Training loss: 0.1276121437549591
Validation loss: 1.5559046063371884

Epoch: 6| Step: 11
Training loss: 0.10168992727994919
Validation loss: 1.5341219773856543

Epoch: 6| Step: 12
Training loss: 0.10217303037643433
Validation loss: 1.5278255221664265

Epoch: 6| Step: 13
Training loss: 0.05574875324964523
Validation loss: 1.5134636150893344

Epoch: 446| Step: 0
Training loss: 0.09511274099349976
Validation loss: 1.5039551411905596

Epoch: 6| Step: 1
Training loss: 0.06393858790397644
Validation loss: 1.52807419530807

Epoch: 6| Step: 2
Training loss: 0.1362762153148651
Validation loss: 1.540513998718672

Epoch: 6| Step: 3
Training loss: 0.06305205821990967
Validation loss: 1.5376655145358014

Epoch: 6| Step: 4
Training loss: 0.09012126177549362
Validation loss: 1.5030734013485652

Epoch: 6| Step: 5
Training loss: 0.15423403680324554
Validation loss: 1.5515735444202219

Epoch: 6| Step: 6
Training loss: 0.14072826504707336
Validation loss: 1.5339611409812846

Epoch: 6| Step: 7
Training loss: 0.06448994576931
Validation loss: 1.511359364755692

Epoch: 6| Step: 8
Training loss: 0.07817579805850983
Validation loss: 1.524840897129428

Epoch: 6| Step: 9
Training loss: 0.07252639532089233
Validation loss: 1.5294542979168635

Epoch: 6| Step: 10
Training loss: 0.0783516988158226
Validation loss: 1.5563551565652252

Epoch: 6| Step: 11
Training loss: 0.08799216151237488
Validation loss: 1.5733616582808956

Epoch: 6| Step: 12
Training loss: 0.12785667181015015
Validation loss: 1.58340201967506

Epoch: 6| Step: 13
Training loss: 0.22963759303092957
Validation loss: 1.5751102034763624

Epoch: 447| Step: 0
Training loss: 0.053728025406599045
Validation loss: 1.549041954419946

Epoch: 6| Step: 1
Training loss: 0.09858650714159012
Validation loss: 1.5278679734917098

Epoch: 6| Step: 2
Training loss: 0.14152935147285461
Validation loss: 1.5407129936320807

Epoch: 6| Step: 3
Training loss: 0.09180548042058945
Validation loss: 1.5197141260229132

Epoch: 6| Step: 4
Training loss: 0.08881843835115433
Validation loss: 1.5328356976150184

Epoch: 6| Step: 5
Training loss: 0.14546625316143036
Validation loss: 1.535029024206182

Epoch: 6| Step: 6
Training loss: 0.11446534097194672
Validation loss: 1.5367264491255566

Epoch: 6| Step: 7
Training loss: 0.07187645137310028
Validation loss: 1.5254051121332313

Epoch: 6| Step: 8
Training loss: 0.0708334818482399
Validation loss: 1.5580661219935263

Epoch: 6| Step: 9
Training loss: 0.08809734880924225
Validation loss: 1.5514226498142365

Epoch: 6| Step: 10
Training loss: 0.14235851168632507
Validation loss: 1.552500065936837

Epoch: 6| Step: 11
Training loss: 0.10137905925512314
Validation loss: 1.5294942509743474

Epoch: 6| Step: 12
Training loss: 0.15933901071548462
Validation loss: 1.5317633510917745

Epoch: 6| Step: 13
Training loss: 0.11220695078372955
Validation loss: 1.540826573166796

Epoch: 448| Step: 0
Training loss: 0.07383032888174057
Validation loss: 1.5364670868842834

Epoch: 6| Step: 1
Training loss: 0.11790196597576141
Validation loss: 1.4949642797952056

Epoch: 6| Step: 2
Training loss: 0.17673756182193756
Validation loss: 1.5093457865458664

Epoch: 6| Step: 3
Training loss: 0.12016822397708893
Validation loss: 1.5471198417807137

Epoch: 6| Step: 4
Training loss: 0.1328015923500061
Validation loss: 1.56829579799406

Epoch: 6| Step: 5
Training loss: 0.13014572858810425
Validation loss: 1.5569268644496959

Epoch: 6| Step: 6
Training loss: 0.11376095563173294
Validation loss: 1.5547542725839922

Epoch: 6| Step: 7
Training loss: 0.06884431838989258
Validation loss: 1.5456979761841476

Epoch: 6| Step: 8
Training loss: 0.08971138298511505
Validation loss: 1.5386911745994323

Epoch: 6| Step: 9
Training loss: 0.10512196272611618
Validation loss: 1.530010877117034

Epoch: 6| Step: 10
Training loss: 0.06691914051771164
Validation loss: 1.517335400786451

Epoch: 6| Step: 11
Training loss: 0.08228007704019547
Validation loss: 1.5607692618523874

Epoch: 6| Step: 12
Training loss: 0.12532614171504974
Validation loss: 1.5350326850850096

Epoch: 6| Step: 13
Training loss: 0.09123742580413818
Validation loss: 1.5341146402461554

Epoch: 449| Step: 0
Training loss: 0.0747160017490387
Validation loss: 1.5282465052861038

Epoch: 6| Step: 1
Training loss: 0.12039630115032196
Validation loss: 1.5421437050706597

Epoch: 6| Step: 2
Training loss: 0.10065843909978867
Validation loss: 1.5291984068450106

Epoch: 6| Step: 3
Training loss: 0.09495022892951965
Validation loss: 1.5238701605027722

Epoch: 6| Step: 4
Training loss: 0.08382439613342285
Validation loss: 1.5253077027618245

Epoch: 6| Step: 5
Training loss: 0.0795871689915657
Validation loss: 1.5202870394593926

Epoch: 6| Step: 6
Training loss: 0.09729065746068954
Validation loss: 1.520870376658696

Epoch: 6| Step: 7
Training loss: 0.08786048740148544
Validation loss: 1.5199291949631066

Epoch: 6| Step: 8
Training loss: 0.07788600772619247
Validation loss: 1.49926842540823

Epoch: 6| Step: 9
Training loss: 0.0752682015299797
Validation loss: 1.5356780277785433

Epoch: 6| Step: 10
Training loss: 0.09374546259641647
Validation loss: 1.4869868556658428

Epoch: 6| Step: 11
Training loss: 0.042136482894420624
Validation loss: 1.5448715327888407

Epoch: 6| Step: 12
Training loss: 0.11238311231136322
Validation loss: 1.535023323951229

Epoch: 6| Step: 13
Training loss: 0.11775520443916321
Validation loss: 1.5625138218684862

Epoch: 450| Step: 0
Training loss: 0.1279873549938202
Validation loss: 1.546660057960018

Epoch: 6| Step: 1
Training loss: 0.05893803760409355
Validation loss: 1.5451060059250041

Epoch: 6| Step: 2
Training loss: 0.09809546172618866
Validation loss: 1.5630297910782598

Epoch: 6| Step: 3
Training loss: 0.07976816594600677
Validation loss: 1.5214468151010492

Epoch: 6| Step: 4
Training loss: 0.13600662350654602
Validation loss: 1.5036075897114252

Epoch: 6| Step: 5
Training loss: 0.13279591500759125
Validation loss: 1.519522956622544

Epoch: 6| Step: 6
Training loss: 0.07926058024168015
Validation loss: 1.5192285532592444

Epoch: 6| Step: 7
Training loss: 0.08623447269201279
Validation loss: 1.507959306880992

Epoch: 6| Step: 8
Training loss: 0.07249188423156738
Validation loss: 1.519990490328881

Epoch: 6| Step: 9
Training loss: 0.07738813757896423
Validation loss: 1.5078234147000056

Epoch: 6| Step: 10
Training loss: 0.06608331948518753
Validation loss: 1.5173712622734807

Epoch: 6| Step: 11
Training loss: 0.054315440356731415
Validation loss: 1.5399696801298408

Epoch: 6| Step: 12
Training loss: 0.05174391716718674
Validation loss: 1.5516625014684533

Epoch: 6| Step: 13
Training loss: 0.19382040202617645
Validation loss: 1.5611672004063923

Epoch: 451| Step: 0
Training loss: 0.06784256547689438
Validation loss: 1.5830073510446856

Epoch: 6| Step: 1
Training loss: 0.10597425699234009
Validation loss: 1.5614900973535353

Epoch: 6| Step: 2
Training loss: 0.12258122861385345
Validation loss: 1.5696638399554836

Epoch: 6| Step: 3
Training loss: 0.10159200429916382
Validation loss: 1.5440333915013138

Epoch: 6| Step: 4
Training loss: 0.09246127307415009
Validation loss: 1.5401315125085975

Epoch: 6| Step: 5
Training loss: 0.08368969708681107
Validation loss: 1.517679334968649

Epoch: 6| Step: 6
Training loss: 0.11642231047153473
Validation loss: 1.5208747681751047

Epoch: 6| Step: 7
Training loss: 0.1419464498758316
Validation loss: 1.5286181434508292

Epoch: 6| Step: 8
Training loss: 0.12172336131334305
Validation loss: 1.5279530991790116

Epoch: 6| Step: 9
Training loss: 0.18065589666366577
Validation loss: 1.5150671248794885

Epoch: 6| Step: 10
Training loss: 0.14571413397789001
Validation loss: 1.525887357291355

Epoch: 6| Step: 11
Training loss: 0.13183650374412537
Validation loss: 1.524374242751829

Epoch: 6| Step: 12
Training loss: 0.07931402325630188
Validation loss: 1.5376008825917398

Epoch: 6| Step: 13
Training loss: 0.15905433893203735
Validation loss: 1.5399321509945778

Epoch: 452| Step: 0
Training loss: 0.09742341935634613
Validation loss: 1.5200381381537325

Epoch: 6| Step: 1
Training loss: 0.07021089643239975
Validation loss: 1.5396787107631724

Epoch: 6| Step: 2
Training loss: 0.08652406930923462
Validation loss: 1.5069399008186914

Epoch: 6| Step: 3
Training loss: 0.14723068475723267
Validation loss: 1.5252178215211438

Epoch: 6| Step: 4
Training loss: 0.25560057163238525
Validation loss: 1.5285679409580846

Epoch: 6| Step: 5
Training loss: 0.1509827971458435
Validation loss: 1.5389790996428458

Epoch: 6| Step: 6
Training loss: 0.07073155790567398
Validation loss: 1.521123186234505

Epoch: 6| Step: 7
Training loss: 0.13391289114952087
Validation loss: 1.5248586567499305

Epoch: 6| Step: 8
Training loss: 0.07501217722892761
Validation loss: 1.5382617109565324

Epoch: 6| Step: 9
Training loss: 0.12836015224456787
Validation loss: 1.532831448380665

Epoch: 6| Step: 10
Training loss: 0.08237063884735107
Validation loss: 1.5284236233721498

Epoch: 6| Step: 11
Training loss: 0.06468464434146881
Validation loss: 1.542868823133489

Epoch: 6| Step: 12
Training loss: 0.1334519237279892
Validation loss: 1.5476576589768933

Epoch: 6| Step: 13
Training loss: 0.13759845495224
Validation loss: 1.5270445269923056

Epoch: 453| Step: 0
Training loss: 0.09370128810405731
Validation loss: 1.5286421186180525

Epoch: 6| Step: 1
Training loss: 0.13017670810222626
Validation loss: 1.523213122480659

Epoch: 6| Step: 2
Training loss: 0.17187032103538513
Validation loss: 1.5275199926027687

Epoch: 6| Step: 3
Training loss: 0.1438344269990921
Validation loss: 1.5546368475883239

Epoch: 6| Step: 4
Training loss: 0.07993722707033157
Validation loss: 1.5176164719366259

Epoch: 6| Step: 5
Training loss: 0.1085674986243248
Validation loss: 1.5321821384532477

Epoch: 6| Step: 6
Training loss: 0.1106683760881424
Validation loss: 1.5398658872932516

Epoch: 6| Step: 7
Training loss: 0.06056290864944458
Validation loss: 1.5743949259481123

Epoch: 6| Step: 8
Training loss: 0.13980531692504883
Validation loss: 1.5539023837735575

Epoch: 6| Step: 9
Training loss: 0.1358986347913742
Validation loss: 1.5707854404244372

Epoch: 6| Step: 10
Training loss: 0.13894513249397278
Validation loss: 1.5370013931746125

Epoch: 6| Step: 11
Training loss: 0.08858411014080048
Validation loss: 1.5216532471359416

Epoch: 6| Step: 12
Training loss: 0.06773899495601654
Validation loss: 1.5310603803203953

Epoch: 6| Step: 13
Training loss: 0.1280362606048584
Validation loss: 1.5273435833633586

Epoch: 454| Step: 0
Training loss: 0.10101534426212311
Validation loss: 1.5060971244688957

Epoch: 6| Step: 1
Training loss: 0.11275205761194229
Validation loss: 1.5308048904583018

Epoch: 6| Step: 2
Training loss: 0.08861766010522842
Validation loss: 1.533170764164258

Epoch: 6| Step: 3
Training loss: 0.11139586567878723
Validation loss: 1.5143602971107728

Epoch: 6| Step: 4
Training loss: 0.07623302191495895
Validation loss: 1.5360472317664855

Epoch: 6| Step: 5
Training loss: 0.08854831755161285
Validation loss: 1.5284323064229821

Epoch: 6| Step: 6
Training loss: 0.07819157838821411
Validation loss: 1.5637616592068826

Epoch: 6| Step: 7
Training loss: 0.06489264965057373
Validation loss: 1.529382465988077

Epoch: 6| Step: 8
Training loss: 0.0907035619020462
Validation loss: 1.518391450246175

Epoch: 6| Step: 9
Training loss: 0.13140639662742615
Validation loss: 1.5413398922130626

Epoch: 6| Step: 10
Training loss: 0.07437963038682938
Validation loss: 1.5068708453127133

Epoch: 6| Step: 11
Training loss: 0.09707075357437134
Validation loss: 1.5369101275679886

Epoch: 6| Step: 12
Training loss: 0.04562158137559891
Validation loss: 1.5515944957733154

Epoch: 6| Step: 13
Training loss: 0.06616895645856857
Validation loss: 1.5331635167521815

Epoch: 455| Step: 0
Training loss: 0.11915680021047592
Validation loss: 1.5372316683492353

Epoch: 6| Step: 1
Training loss: 0.07666229456663132
Validation loss: 1.5425495845015331

Epoch: 6| Step: 2
Training loss: 0.12329993396997452
Validation loss: 1.5305802706749208

Epoch: 6| Step: 3
Training loss: 0.06517153233289719
Validation loss: 1.5419724410580051

Epoch: 6| Step: 4
Training loss: 0.0844898521900177
Validation loss: 1.514110016566451

Epoch: 6| Step: 5
Training loss: 0.060677219182252884
Validation loss: 1.5413877207745788

Epoch: 6| Step: 6
Training loss: 0.1116420179605484
Validation loss: 1.5463887709443287

Epoch: 6| Step: 7
Training loss: 0.0889650285243988
Validation loss: 1.5320866953942083

Epoch: 6| Step: 8
Training loss: 0.107765331864357
Validation loss: 1.5360427800045218

Epoch: 6| Step: 9
Training loss: 0.08518131077289581
Validation loss: 1.558003225634175

Epoch: 6| Step: 10
Training loss: 0.07479755580425262
Validation loss: 1.5184303432382562

Epoch: 6| Step: 11
Training loss: 0.07559758424758911
Validation loss: 1.529462278530162

Epoch: 6| Step: 12
Training loss: 0.09720218181610107
Validation loss: 1.5376073673207273

Epoch: 6| Step: 13
Training loss: 0.07852192968130112
Validation loss: 1.5372818464873939

Epoch: 456| Step: 0
Training loss: 0.07725756615400314
Validation loss: 1.5260759758692917

Epoch: 6| Step: 1
Training loss: 0.1087031215429306
Validation loss: 1.5498107915283532

Epoch: 6| Step: 2
Training loss: 0.07069838047027588
Validation loss: 1.5476320853797338

Epoch: 6| Step: 3
Training loss: 0.12220899015665054
Validation loss: 1.5476059208634079

Epoch: 6| Step: 4
Training loss: 0.10146854817867279
Validation loss: 1.5589247621515745

Epoch: 6| Step: 5
Training loss: 0.12112763524055481
Validation loss: 1.531489646562966

Epoch: 6| Step: 6
Training loss: 0.068308025598526
Validation loss: 1.568930027305439

Epoch: 6| Step: 7
Training loss: 0.08865153789520264
Validation loss: 1.5084260766224196

Epoch: 6| Step: 8
Training loss: 0.0703819990158081
Validation loss: 1.5380598255383071

Epoch: 6| Step: 9
Training loss: 0.07587900757789612
Validation loss: 1.5154501507359166

Epoch: 6| Step: 10
Training loss: 0.0913776308298111
Validation loss: 1.5219617377045334

Epoch: 6| Step: 11
Training loss: 0.06570903956890106
Validation loss: 1.5456205407778423

Epoch: 6| Step: 12
Training loss: 0.13040697574615479
Validation loss: 1.5547577629807174

Epoch: 6| Step: 13
Training loss: 0.12840239703655243
Validation loss: 1.5506005838353147

Epoch: 457| Step: 0
Training loss: 0.11202546209096909
Validation loss: 1.5409453248464933

Epoch: 6| Step: 1
Training loss: 0.05598652735352516
Validation loss: 1.5291430322072839

Epoch: 6| Step: 2
Training loss: 0.10894862562417984
Validation loss: 1.5268333868313861

Epoch: 6| Step: 3
Training loss: 0.07573248445987701
Validation loss: 1.5268902676079863

Epoch: 6| Step: 4
Training loss: 0.08129122853279114
Validation loss: 1.5549822994457778

Epoch: 6| Step: 5
Training loss: 0.11061757802963257
Validation loss: 1.5591078150656916

Epoch: 6| Step: 6
Training loss: 0.10727555304765701
Validation loss: 1.5612297211923907

Epoch: 6| Step: 7
Training loss: 0.097226083278656
Validation loss: 1.5437908454607892

Epoch: 6| Step: 8
Training loss: 0.2562978267669678
Validation loss: 1.5794805070405364

Epoch: 6| Step: 9
Training loss: 0.1118493378162384
Validation loss: 1.5596250180275208

Epoch: 6| Step: 10
Training loss: 0.09280223399400711
Validation loss: 1.5421017190461517

Epoch: 6| Step: 11
Training loss: 0.04618590325117111
Validation loss: 1.5585218719256821

Epoch: 6| Step: 12
Training loss: 0.08274181932210922
Validation loss: 1.5410613693216795

Epoch: 6| Step: 13
Training loss: 0.09673510491847992
Validation loss: 1.55557168299152

Epoch: 458| Step: 0
Training loss: 0.05084598809480667
Validation loss: 1.5432474446553055

Epoch: 6| Step: 1
Training loss: 0.08900173008441925
Validation loss: 1.540942411268911

Epoch: 6| Step: 2
Training loss: 0.06584873050451279
Validation loss: 1.5273589370071248

Epoch: 6| Step: 3
Training loss: 0.1324038803577423
Validation loss: 1.5298148765358874

Epoch: 6| Step: 4
Training loss: 0.09862096607685089
Validation loss: 1.5474527228263117

Epoch: 6| Step: 5
Training loss: 0.0380454882979393
Validation loss: 1.5274365114909347

Epoch: 6| Step: 6
Training loss: 0.06060104817152023
Validation loss: 1.5028946181779266

Epoch: 6| Step: 7
Training loss: 0.03887965530157089
Validation loss: 1.5156093553830219

Epoch: 6| Step: 8
Training loss: 0.14188870787620544
Validation loss: 1.5310892904958417

Epoch: 6| Step: 9
Training loss: 0.09740446507930756
Validation loss: 1.5341361120182981

Epoch: 6| Step: 10
Training loss: 0.0937081128358841
Validation loss: 1.5472150489848147

Epoch: 6| Step: 11
Training loss: 0.14495015144348145
Validation loss: 1.538014687517638

Epoch: 6| Step: 12
Training loss: 0.06791427731513977
Validation loss: 1.5250969561197425

Epoch: 6| Step: 13
Training loss: 0.05287159979343414
Validation loss: 1.5237519830785773

Epoch: 459| Step: 0
Training loss: 0.09416486322879791
Validation loss: 1.5403208424968104

Epoch: 6| Step: 1
Training loss: 0.13038791716098785
Validation loss: 1.56366608219762

Epoch: 6| Step: 2
Training loss: 0.06273181736469269
Validation loss: 1.5429861007198211

Epoch: 6| Step: 3
Training loss: 0.10513944178819656
Validation loss: 1.5379038318510978

Epoch: 6| Step: 4
Training loss: 0.06215626746416092
Validation loss: 1.5338880733777118

Epoch: 6| Step: 5
Training loss: 0.08265015482902527
Validation loss: 1.566657345782044

Epoch: 6| Step: 6
Training loss: 0.13141711056232452
Validation loss: 1.5330695708592732

Epoch: 6| Step: 7
Training loss: 0.09690213203430176
Validation loss: 1.54006024073529

Epoch: 6| Step: 8
Training loss: 0.08436509221792221
Validation loss: 1.542093619223564

Epoch: 6| Step: 9
Training loss: 0.0915379449725151
Validation loss: 1.536594977942846

Epoch: 6| Step: 10
Training loss: 0.08529959619045258
Validation loss: 1.528188809912692

Epoch: 6| Step: 11
Training loss: 0.08832661062479019
Validation loss: 1.5356792775533532

Epoch: 6| Step: 12
Training loss: 0.06259544938802719
Validation loss: 1.5339284660995647

Epoch: 6| Step: 13
Training loss: 0.040164366364479065
Validation loss: 1.5383405352151522

Epoch: 460| Step: 0
Training loss: 0.0650012344121933
Validation loss: 1.5218739176309237

Epoch: 6| Step: 1
Training loss: 0.141809344291687
Validation loss: 1.5123581194108533

Epoch: 6| Step: 2
Training loss: 0.09354616701602936
Validation loss: 1.5189589832418708

Epoch: 6| Step: 3
Training loss: 0.04389381781220436
Validation loss: 1.5333756221238004

Epoch: 6| Step: 4
Training loss: 0.03782810643315315
Validation loss: 1.5297270410804338

Epoch: 6| Step: 5
Training loss: 0.14150983095169067
Validation loss: 1.5318544731345227

Epoch: 6| Step: 6
Training loss: 0.1605772078037262
Validation loss: 1.5529263429744269

Epoch: 6| Step: 7
Training loss: 0.12829653918743134
Validation loss: 1.5315440316354074

Epoch: 6| Step: 8
Training loss: 0.10241986811161041
Validation loss: 1.5112994768286263

Epoch: 6| Step: 9
Training loss: 0.08314216881990433
Validation loss: 1.5225786009142477

Epoch: 6| Step: 10
Training loss: 0.10867833346128464
Validation loss: 1.5153830871787122

Epoch: 6| Step: 11
Training loss: 0.08259767293930054
Validation loss: 1.5370243505765033

Epoch: 6| Step: 12
Training loss: 0.04927157610654831
Validation loss: 1.5237513133274612

Epoch: 6| Step: 13
Training loss: 0.058716729283332825
Validation loss: 1.5168049168843094

Epoch: 461| Step: 0
Training loss: 0.05161447823047638
Validation loss: 1.5329513934350782

Epoch: 6| Step: 1
Training loss: 0.06931052356958389
Validation loss: 1.5281163620692428

Epoch: 6| Step: 2
Training loss: 0.06502316892147064
Validation loss: 1.5043290071589972

Epoch: 6| Step: 3
Training loss: 0.06310294568538666
Validation loss: 1.5117823334150418

Epoch: 6| Step: 4
Training loss: 0.10787410289049149
Validation loss: 1.5203498537822435

Epoch: 6| Step: 5
Training loss: 0.07392962276935577
Validation loss: 1.4819481065196376

Epoch: 6| Step: 6
Training loss: 0.09995733946561813
Validation loss: 1.5026715263243644

Epoch: 6| Step: 7
Training loss: 0.09919782727956772
Validation loss: 1.4748513314031786

Epoch: 6| Step: 8
Training loss: 0.09734531491994858
Validation loss: 1.4766922746935198

Epoch: 6| Step: 9
Training loss: 0.057711243629455566
Validation loss: 1.5165465531810638

Epoch: 6| Step: 10
Training loss: 0.07231706380844116
Validation loss: 1.4901453263016158

Epoch: 6| Step: 11
Training loss: 0.11115698516368866
Validation loss: 1.5272924989782355

Epoch: 6| Step: 12
Training loss: 0.1109648272395134
Validation loss: 1.4929683644284484

Epoch: 6| Step: 13
Training loss: 0.062253937125205994
Validation loss: 1.5223821132413802

Epoch: 462| Step: 0
Training loss: 0.07707418501377106
Validation loss: 1.5164791922415457

Epoch: 6| Step: 1
Training loss: 0.07242981344461441
Validation loss: 1.5023992202615226

Epoch: 6| Step: 2
Training loss: 0.08207793533802032
Validation loss: 1.5098279342856458

Epoch: 6| Step: 3
Training loss: 0.05659036338329315
Validation loss: 1.5018157061710153

Epoch: 6| Step: 4
Training loss: 0.06760099530220032
Validation loss: 1.51367461809548

Epoch: 6| Step: 5
Training loss: 0.06994526088237762
Validation loss: 1.517742036491312

Epoch: 6| Step: 6
Training loss: 0.06477652490139008
Validation loss: 1.5186149381822156

Epoch: 6| Step: 7
Training loss: 0.09200172126293182
Validation loss: 1.518621770284509

Epoch: 6| Step: 8
Training loss: 0.11835362017154694
Validation loss: 1.4953633187919535

Epoch: 6| Step: 9
Training loss: 0.0976211279630661
Validation loss: 1.4987172144715504

Epoch: 6| Step: 10
Training loss: 0.09010829031467438
Validation loss: 1.5315277973810832

Epoch: 6| Step: 11
Training loss: 0.09232812374830246
Validation loss: 1.5040558922675349

Epoch: 6| Step: 12
Training loss: 0.11937281489372253
Validation loss: 1.5333024468473209

Epoch: 6| Step: 13
Training loss: 0.06446752697229385
Validation loss: 1.520099450183171

Epoch: 463| Step: 0
Training loss: 0.09185130149126053
Validation loss: 1.4997615609117734

Epoch: 6| Step: 1
Training loss: 0.0917993038892746
Validation loss: 1.5260621501553444

Epoch: 6| Step: 2
Training loss: 0.07734933495521545
Validation loss: 1.525220868408039

Epoch: 6| Step: 3
Training loss: 0.09990211576223373
Validation loss: 1.5288995927379978

Epoch: 6| Step: 4
Training loss: 0.057352736592292786
Validation loss: 1.5345398238910142

Epoch: 6| Step: 5
Training loss: 0.1482391655445099
Validation loss: 1.556393955343513

Epoch: 6| Step: 6
Training loss: 0.06482855975627899
Validation loss: 1.5407097006356845

Epoch: 6| Step: 7
Training loss: 0.12917020916938782
Validation loss: 1.507193499995816

Epoch: 6| Step: 8
Training loss: 0.07925423979759216
Validation loss: 1.549103315158557

Epoch: 6| Step: 9
Training loss: 0.05745181441307068
Validation loss: 1.5163457137282177

Epoch: 6| Step: 10
Training loss: 0.09572131931781769
Validation loss: 1.5195844525931983

Epoch: 6| Step: 11
Training loss: 0.08942989259958267
Validation loss: 1.51202267472462

Epoch: 6| Step: 12
Training loss: 0.12101858109235764
Validation loss: 1.5381565017084922

Epoch: 6| Step: 13
Training loss: 0.07302964478731155
Validation loss: 1.5462711049664406

Epoch: 464| Step: 0
Training loss: 0.08092375099658966
Validation loss: 1.5443019315760622

Epoch: 6| Step: 1
Training loss: 0.0944334864616394
Validation loss: 1.5471024385062597

Epoch: 6| Step: 2
Training loss: 0.04453195631504059
Validation loss: 1.5398807769180627

Epoch: 6| Step: 3
Training loss: 0.09138056635856628
Validation loss: 1.5554679965460172

Epoch: 6| Step: 4
Training loss: 0.12144092470407486
Validation loss: 1.5446514173220562

Epoch: 6| Step: 5
Training loss: 0.0675535798072815
Validation loss: 1.5512547069980251

Epoch: 6| Step: 6
Training loss: 0.11421231925487518
Validation loss: 1.5454733640916887

Epoch: 6| Step: 7
Training loss: 0.0869712382555008
Validation loss: 1.55540253526421

Epoch: 6| Step: 8
Training loss: 0.09303880482912064
Validation loss: 1.5402188301086426

Epoch: 6| Step: 9
Training loss: 0.09059374034404755
Validation loss: 1.5352622078311058

Epoch: 6| Step: 10
Training loss: 0.07394574582576752
Validation loss: 1.526592819921432

Epoch: 6| Step: 11
Training loss: 0.08613141626119614
Validation loss: 1.5332699514204455

Epoch: 6| Step: 12
Training loss: 0.07356876879930496
Validation loss: 1.5341988430228284

Epoch: 6| Step: 13
Training loss: 0.07461331784725189
Validation loss: 1.4908315327859694

Epoch: 465| Step: 0
Training loss: 0.09292400628328323
Validation loss: 1.496381745543531

Epoch: 6| Step: 1
Training loss: 0.11086481809616089
Validation loss: 1.4913187039795743

Epoch: 6| Step: 2
Training loss: 0.08671899139881134
Validation loss: 1.4881703443424676

Epoch: 6| Step: 3
Training loss: 0.11354124546051025
Validation loss: 1.4801917614475373

Epoch: 6| Step: 4
Training loss: 0.07469475269317627
Validation loss: 1.5283365993089573

Epoch: 6| Step: 5
Training loss: 0.13192695379257202
Validation loss: 1.4928533954005088

Epoch: 6| Step: 6
Training loss: 0.05682459473609924
Validation loss: 1.5328027202237038

Epoch: 6| Step: 7
Training loss: 0.09642291069030762
Validation loss: 1.557568186072893

Epoch: 6| Step: 8
Training loss: 0.10155927389860153
Validation loss: 1.5502110604316957

Epoch: 6| Step: 9
Training loss: 0.0984407290816307
Validation loss: 1.5353604388493363

Epoch: 6| Step: 10
Training loss: 0.09280688315629959
Validation loss: 1.5028823716666109

Epoch: 6| Step: 11
Training loss: 0.06730704754590988
Validation loss: 1.5176901496866697

Epoch: 6| Step: 12
Training loss: 0.0751325711607933
Validation loss: 1.5028389269305813

Epoch: 6| Step: 13
Training loss: 0.09311024844646454
Validation loss: 1.525790633693818

Epoch: 466| Step: 0
Training loss: 0.09251660853624344
Validation loss: 1.5560544472868725

Epoch: 6| Step: 1
Training loss: 0.08236296474933624
Validation loss: 1.5372844191007717

Epoch: 6| Step: 2
Training loss: 0.03869078680872917
Validation loss: 1.5250189432533838

Epoch: 6| Step: 3
Training loss: 0.08164125680923462
Validation loss: 1.5331883071571268

Epoch: 6| Step: 4
Training loss: 0.1713884472846985
Validation loss: 1.5344749791647798

Epoch: 6| Step: 5
Training loss: 0.06507428735494614
Validation loss: 1.5607183274402414

Epoch: 6| Step: 6
Training loss: 0.08983364701271057
Validation loss: 1.5693170409048758

Epoch: 6| Step: 7
Training loss: 0.05624664947390556
Validation loss: 1.565483429098642

Epoch: 6| Step: 8
Training loss: 0.11201342195272446
Validation loss: 1.5703599991336945

Epoch: 6| Step: 9
Training loss: 0.11459676921367645
Validation loss: 1.528440656200532

Epoch: 6| Step: 10
Training loss: 0.038175612688064575
Validation loss: 1.5443910808973416

Epoch: 6| Step: 11
Training loss: 0.062129005789756775
Validation loss: 1.535752574602763

Epoch: 6| Step: 12
Training loss: 0.09418715536594391
Validation loss: 1.5396165258140975

Epoch: 6| Step: 13
Training loss: 0.18438632786273956
Validation loss: 1.5135725518708587

Epoch: 467| Step: 0
Training loss: 0.061650898307561874
Validation loss: 1.526335794438598

Epoch: 6| Step: 1
Training loss: 0.07661959528923035
Validation loss: 1.5302624176907282

Epoch: 6| Step: 2
Training loss: 0.051616039127111435
Validation loss: 1.5409111374167985

Epoch: 6| Step: 3
Training loss: 0.07073292881250381
Validation loss: 1.5236970090096997

Epoch: 6| Step: 4
Training loss: 0.10446789860725403
Validation loss: 1.5528995721570906

Epoch: 6| Step: 5
Training loss: 0.06339742243289948
Validation loss: 1.5366579025022444

Epoch: 6| Step: 6
Training loss: 0.055444665253162384
Validation loss: 1.5366498013978362

Epoch: 6| Step: 7
Training loss: 0.08838042616844177
Validation loss: 1.56293099798182

Epoch: 6| Step: 8
Training loss: 0.05912739038467407
Validation loss: 1.5478356897190053

Epoch: 6| Step: 9
Training loss: 0.11372452974319458
Validation loss: 1.5574181131137315

Epoch: 6| Step: 10
Training loss: 0.06890645623207092
Validation loss: 1.5242233020003124

Epoch: 6| Step: 11
Training loss: 0.1068202555179596
Validation loss: 1.5230211750153573

Epoch: 6| Step: 12
Training loss: 0.04836437106132507
Validation loss: 1.5101312680910992

Epoch: 6| Step: 13
Training loss: 0.057514362037181854
Validation loss: 1.5177970265829435

Epoch: 468| Step: 0
Training loss: 0.07320354133844376
Validation loss: 1.516134322330516

Epoch: 6| Step: 1
Training loss: 0.08319638669490814
Validation loss: 1.5006422394065446

Epoch: 6| Step: 2
Training loss: 0.050727587193250656
Validation loss: 1.5025055613569034

Epoch: 6| Step: 3
Training loss: 0.08478046953678131
Validation loss: 1.505258164098186

Epoch: 6| Step: 4
Training loss: 0.07350058853626251
Validation loss: 1.5066219183706469

Epoch: 6| Step: 5
Training loss: 0.12177155911922455
Validation loss: 1.5104545700934626

Epoch: 6| Step: 6
Training loss: 0.06931398808956146
Validation loss: 1.4896058395344725

Epoch: 6| Step: 7
Training loss: 0.10627526044845581
Validation loss: 1.491988294868059

Epoch: 6| Step: 8
Training loss: 0.07809668779373169
Validation loss: 1.5115013904468988

Epoch: 6| Step: 9
Training loss: 0.08028750121593475
Validation loss: 1.5151741966124503

Epoch: 6| Step: 10
Training loss: 0.08154119551181793
Validation loss: 1.5433208583503641

Epoch: 6| Step: 11
Training loss: 0.06195838004350662
Validation loss: 1.528768552246914

Epoch: 6| Step: 12
Training loss: 0.07088049501180649
Validation loss: 1.5638774607771186

Epoch: 6| Step: 13
Training loss: 0.06333014369010925
Validation loss: 1.5573660173723776

Epoch: 469| Step: 0
Training loss: 0.05423303693532944
Validation loss: 1.5657705965862478

Epoch: 6| Step: 1
Training loss: 0.037153467535972595
Validation loss: 1.5590715741598478

Epoch: 6| Step: 2
Training loss: 0.14991448819637299
Validation loss: 1.5336633664305492

Epoch: 6| Step: 3
Training loss: 0.08737802505493164
Validation loss: 1.5466144315658077

Epoch: 6| Step: 4
Training loss: 0.06684545427560806
Validation loss: 1.5201732086878952

Epoch: 6| Step: 5
Training loss: 0.06860177218914032
Validation loss: 1.5135708816589848

Epoch: 6| Step: 6
Training loss: 0.1434856355190277
Validation loss: 1.5310354232788086

Epoch: 6| Step: 7
Training loss: 0.06228841096162796
Validation loss: 1.4802415050486082

Epoch: 6| Step: 8
Training loss: 0.08083410561084747
Validation loss: 1.514622667784332

Epoch: 6| Step: 9
Training loss: 0.11918811500072479
Validation loss: 1.522345140416135

Epoch: 6| Step: 10
Training loss: 0.08037242293357849
Validation loss: 1.4982643396623674

Epoch: 6| Step: 11
Training loss: 0.13508054614067078
Validation loss: 1.4982070205032185

Epoch: 6| Step: 12
Training loss: 0.10075527429580688
Validation loss: 1.4964406067325222

Epoch: 6| Step: 13
Training loss: 0.12275021523237228
Validation loss: 1.5171143559999363

Epoch: 470| Step: 0
Training loss: 0.06397303193807602
Validation loss: 1.49351240229863

Epoch: 6| Step: 1
Training loss: 0.09598147124052048
Validation loss: 1.493320902188619

Epoch: 6| Step: 2
Training loss: 0.07293863594532013
Validation loss: 1.5114633883199384

Epoch: 6| Step: 3
Training loss: 0.07587571442127228
Validation loss: 1.5226218867045578

Epoch: 6| Step: 4
Training loss: 0.09920764714479446
Validation loss: 1.525494812637247

Epoch: 6| Step: 5
Training loss: 0.0744597539305687
Validation loss: 1.5344905250815934

Epoch: 6| Step: 6
Training loss: 0.07416525483131409
Validation loss: 1.5296537414673836

Epoch: 6| Step: 7
Training loss: 0.06314973533153534
Validation loss: 1.4843853417263235

Epoch: 6| Step: 8
Training loss: 0.10135700553655624
Validation loss: 1.5130973733881468

Epoch: 6| Step: 9
Training loss: 0.09138897806406021
Validation loss: 1.547963273140692

Epoch: 6| Step: 10
Training loss: 0.14293399453163147
Validation loss: 1.5434331560647616

Epoch: 6| Step: 11
Training loss: 0.09764888137578964
Validation loss: 1.550153225980779

Epoch: 6| Step: 12
Training loss: 0.11400676518678665
Validation loss: 1.522160627508676

Epoch: 6| Step: 13
Training loss: 0.05366607382893562
Validation loss: 1.550499467439549

Epoch: 471| Step: 0
Training loss: 0.05784716457128525
Validation loss: 1.5563904277739986

Epoch: 6| Step: 1
Training loss: 0.08823247253894806
Validation loss: 1.5420303754909064

Epoch: 6| Step: 2
Training loss: 0.11018413305282593
Validation loss: 1.5183302228168776

Epoch: 6| Step: 3
Training loss: 0.08932912349700928
Validation loss: 1.5159064390326058

Epoch: 6| Step: 4
Training loss: 0.08303828537464142
Validation loss: 1.5062512197802145

Epoch: 6| Step: 5
Training loss: 0.11539743840694427
Validation loss: 1.4972486995881604

Epoch: 6| Step: 6
Training loss: 0.052075427025556564
Validation loss: 1.4893376320920966

Epoch: 6| Step: 7
Training loss: 0.1474858522415161
Validation loss: 1.517627695555328

Epoch: 6| Step: 8
Training loss: 0.1045016199350357
Validation loss: 1.512700770490913

Epoch: 6| Step: 9
Training loss: 0.14254248142242432
Validation loss: 1.5074149280466058

Epoch: 6| Step: 10
Training loss: 0.14630097150802612
Validation loss: 1.4817056873793244

Epoch: 6| Step: 11
Training loss: 0.07612162828445435
Validation loss: 1.5184265221318891

Epoch: 6| Step: 12
Training loss: 0.09409241378307343
Validation loss: 1.4996754187409596

Epoch: 6| Step: 13
Training loss: 0.05835957080125809
Validation loss: 1.5220144077013897

Epoch: 472| Step: 0
Training loss: 0.07538934051990509
Validation loss: 1.5179805601796796

Epoch: 6| Step: 1
Training loss: 0.054083988070487976
Validation loss: 1.5282719801830988

Epoch: 6| Step: 2
Training loss: 0.07910609245300293
Validation loss: 1.5289594486195555

Epoch: 6| Step: 3
Training loss: 0.06805036962032318
Validation loss: 1.5075034761941561

Epoch: 6| Step: 4
Training loss: 0.12773391604423523
Validation loss: 1.5126050133858957

Epoch: 6| Step: 5
Training loss: 0.06622549891471863
Validation loss: 1.5268867272202686

Epoch: 6| Step: 6
Training loss: 0.08048249781131744
Validation loss: 1.5016539942833684

Epoch: 6| Step: 7
Training loss: 0.1699557602405548
Validation loss: 1.5113624001062045

Epoch: 6| Step: 8
Training loss: 0.07351517677307129
Validation loss: 1.5149426665357364

Epoch: 6| Step: 9
Training loss: 0.09046951681375504
Validation loss: 1.5016242214428481

Epoch: 6| Step: 10
Training loss: 0.06786633282899857
Validation loss: 1.5224634460223618

Epoch: 6| Step: 11
Training loss: 0.08669503033161163
Validation loss: 1.5449330511913504

Epoch: 6| Step: 12
Training loss: 0.06434597074985504
Validation loss: 1.558347640498992

Epoch: 6| Step: 13
Training loss: 0.24313293397426605
Validation loss: 1.5510583936527211

Epoch: 473| Step: 0
Training loss: 0.06551466137170792
Validation loss: 1.550688564136464

Epoch: 6| Step: 1
Training loss: 0.07429200410842896
Validation loss: 1.5056014753157092

Epoch: 6| Step: 2
Training loss: 0.09124879539012909
Validation loss: 1.550183952495616

Epoch: 6| Step: 3
Training loss: 0.10676296055316925
Validation loss: 1.5419794231332757

Epoch: 6| Step: 4
Training loss: 0.12381719052791595
Validation loss: 1.536251562897877

Epoch: 6| Step: 5
Training loss: 0.11382848769426346
Validation loss: 1.563180536352178

Epoch: 6| Step: 6
Training loss: 0.07799297571182251
Validation loss: 1.5465424189003565

Epoch: 6| Step: 7
Training loss: 0.07759378850460052
Validation loss: 1.5443563909940823

Epoch: 6| Step: 8
Training loss: 0.09620293974876404
Validation loss: 1.5586128273317892

Epoch: 6| Step: 9
Training loss: 0.16581782698631287
Validation loss: 1.5406188593115857

Epoch: 6| Step: 10
Training loss: 0.06979380548000336
Validation loss: 1.5233271352706417

Epoch: 6| Step: 11
Training loss: 0.08459839224815369
Validation loss: 1.5140445860483314

Epoch: 6| Step: 12
Training loss: 0.04888744279742241
Validation loss: 1.5135944709982923

Epoch: 6| Step: 13
Training loss: 0.06008932366967201
Validation loss: 1.522723187041539

Epoch: 474| Step: 0
Training loss: 0.09583643078804016
Validation loss: 1.5062912177014094

Epoch: 6| Step: 1
Training loss: 0.10859054327011108
Validation loss: 1.5349288294392247

Epoch: 6| Step: 2
Training loss: 0.10158929228782654
Validation loss: 1.4900298708228654

Epoch: 6| Step: 3
Training loss: 0.11148062348365784
Validation loss: 1.4856407821819346

Epoch: 6| Step: 4
Training loss: 0.06369338929653168
Validation loss: 1.4844084888376214

Epoch: 6| Step: 5
Training loss: 0.06877516210079193
Validation loss: 1.4894085885376058

Epoch: 6| Step: 6
Training loss: 0.09166820347309113
Validation loss: 1.466081533380734

Epoch: 6| Step: 7
Training loss: 0.07733622193336487
Validation loss: 1.4697305194793209

Epoch: 6| Step: 8
Training loss: 0.11079305410385132
Validation loss: 1.4871809572301886

Epoch: 6| Step: 9
Training loss: 0.06591285765171051
Validation loss: 1.4893596492787844

Epoch: 6| Step: 10
Training loss: 0.15647399425506592
Validation loss: 1.4830207632433983

Epoch: 6| Step: 11
Training loss: 0.11888737231492996
Validation loss: 1.4953446542063067

Epoch: 6| Step: 12
Training loss: 0.07722482830286026
Validation loss: 1.4851347502841745

Epoch: 6| Step: 13
Training loss: 0.06441043317317963
Validation loss: 1.4879324128550868

Epoch: 475| Step: 0
Training loss: 0.05679886043071747
Validation loss: 1.4986324541030391

Epoch: 6| Step: 1
Training loss: 0.0895175039768219
Validation loss: 1.5162937474507157

Epoch: 6| Step: 2
Training loss: 0.10472384840250015
Validation loss: 1.5255072744943763

Epoch: 6| Step: 3
Training loss: 0.12088906764984131
Validation loss: 1.5214498248151553

Epoch: 6| Step: 4
Training loss: 0.06877913326025009
Validation loss: 1.5114320478131693

Epoch: 6| Step: 5
Training loss: 0.06459306180477142
Validation loss: 1.527856472999819

Epoch: 6| Step: 6
Training loss: 0.09209932386875153
Validation loss: 1.523725034088217

Epoch: 6| Step: 7
Training loss: 0.05920606106519699
Validation loss: 1.5045031219400384

Epoch: 6| Step: 8
Training loss: 0.0712127834558487
Validation loss: 1.5262837807337444

Epoch: 6| Step: 9
Training loss: 0.09066329151391983
Validation loss: 1.5326752649840487

Epoch: 6| Step: 10
Training loss: 0.05505264922976494
Validation loss: 1.5176173743381296

Epoch: 6| Step: 11
Training loss: 0.10844538360834122
Validation loss: 1.5222496935116347

Epoch: 6| Step: 12
Training loss: 0.10575893521308899
Validation loss: 1.5254987760256695

Epoch: 6| Step: 13
Training loss: 0.03962545841932297
Validation loss: 1.5123667665707168

Epoch: 476| Step: 0
Training loss: 0.06526844203472137
Validation loss: 1.5303818602715769

Epoch: 6| Step: 1
Training loss: 0.06703777611255646
Validation loss: 1.5319389531048395

Epoch: 6| Step: 2
Training loss: 0.054616529494524
Validation loss: 1.558401676916307

Epoch: 6| Step: 3
Training loss: 0.11610384285449982
Validation loss: 1.5445039182580926

Epoch: 6| Step: 4
Training loss: 0.07363435626029968
Validation loss: 1.551074392052107

Epoch: 6| Step: 5
Training loss: 0.05214698612689972
Validation loss: 1.5444799059180803

Epoch: 6| Step: 6
Training loss: 0.1320173740386963
Validation loss: 1.53294829399355

Epoch: 6| Step: 7
Training loss: 0.07448270916938782
Validation loss: 1.5580067826855568

Epoch: 6| Step: 8
Training loss: 0.08742661029100418
Validation loss: 1.5541362275359452

Epoch: 6| Step: 9
Training loss: 0.11729566007852554
Validation loss: 1.5523815802348557

Epoch: 6| Step: 10
Training loss: 0.08721446990966797
Validation loss: 1.5394485586433

Epoch: 6| Step: 11
Training loss: 0.12780283391475677
Validation loss: 1.5354282368895829

Epoch: 6| Step: 12
Training loss: 0.10590693354606628
Validation loss: 1.5256462558623283

Epoch: 6| Step: 13
Training loss: 0.09553112834692001
Validation loss: 1.546684657373736

Epoch: 477| Step: 0
Training loss: 0.069521963596344
Validation loss: 1.525109274412996

Epoch: 6| Step: 1
Training loss: 0.05896199494600296
Validation loss: 1.519793034881674

Epoch: 6| Step: 2
Training loss: 0.08526991307735443
Validation loss: 1.5193177192441878

Epoch: 6| Step: 3
Training loss: 0.08997809886932373
Validation loss: 1.5336804953954553

Epoch: 6| Step: 4
Training loss: 0.08756871521472931
Validation loss: 1.5396264201851302

Epoch: 6| Step: 5
Training loss: 0.08103804290294647
Validation loss: 1.5391157198977727

Epoch: 6| Step: 6
Training loss: 0.07818575203418732
Validation loss: 1.528269939525153

Epoch: 6| Step: 7
Training loss: 0.13109207153320312
Validation loss: 1.527720038608838

Epoch: 6| Step: 8
Training loss: 0.057447873055934906
Validation loss: 1.5286757292286042

Epoch: 6| Step: 9
Training loss: 0.08803119510412216
Validation loss: 1.4951570700573664

Epoch: 6| Step: 10
Training loss: 0.1308528482913971
Validation loss: 1.5300924508802352

Epoch: 6| Step: 11
Training loss: 0.07487690448760986
Validation loss: 1.5179295616765176

Epoch: 6| Step: 12
Training loss: 0.10933804512023926
Validation loss: 1.511148755268384

Epoch: 6| Step: 13
Training loss: 0.09093624353408813
Validation loss: 1.473674556901378

Epoch: 478| Step: 0
Training loss: 0.0913562923669815
Validation loss: 1.5069398328822146

Epoch: 6| Step: 1
Training loss: 0.051682908087968826
Validation loss: 1.4811287387724845

Epoch: 6| Step: 2
Training loss: 0.07232151925563812
Validation loss: 1.5137503813671809

Epoch: 6| Step: 3
Training loss: 0.10181926190853119
Validation loss: 1.511971232711628

Epoch: 6| Step: 4
Training loss: 0.09487070143222809
Validation loss: 1.5123369988574777

Epoch: 6| Step: 5
Training loss: 0.09802679717540741
Validation loss: 1.539264816109852

Epoch: 6| Step: 6
Training loss: 0.09358776360750198
Validation loss: 1.531904326972141

Epoch: 6| Step: 7
Training loss: 0.0601794607937336
Validation loss: 1.524141029645038

Epoch: 6| Step: 8
Training loss: 0.07660447061061859
Validation loss: 1.5193912188212078

Epoch: 6| Step: 9
Training loss: 0.10951600968837738
Validation loss: 1.534872930536988

Epoch: 6| Step: 10
Training loss: 0.05283156409859657
Validation loss: 1.5218184237839074

Epoch: 6| Step: 11
Training loss: 0.07348237931728363
Validation loss: 1.530254606918622

Epoch: 6| Step: 12
Training loss: 0.08854241669178009
Validation loss: 1.5256102700387277

Epoch: 6| Step: 13
Training loss: 0.07899272441864014
Validation loss: 1.5133431137249034

Epoch: 479| Step: 0
Training loss: 0.0511501282453537
Validation loss: 1.5494038917685067

Epoch: 6| Step: 1
Training loss: 0.0918179452419281
Validation loss: 1.507650367675289

Epoch: 6| Step: 2
Training loss: 0.10444098711013794
Validation loss: 1.532157939608379

Epoch: 6| Step: 3
Training loss: 0.06499158591032028
Validation loss: 1.520239339079908

Epoch: 6| Step: 4
Training loss: 0.10447652637958527
Validation loss: 1.5192020939242454

Epoch: 6| Step: 5
Training loss: 0.07201528549194336
Validation loss: 1.5133731852295578

Epoch: 6| Step: 6
Training loss: 0.05425764247775078
Validation loss: 1.5066339431270477

Epoch: 6| Step: 7
Training loss: 0.07400195300579071
Validation loss: 1.5065126175521522

Epoch: 6| Step: 8
Training loss: 0.068718820810318
Validation loss: 1.514850103726951

Epoch: 6| Step: 9
Training loss: 0.07994921505451202
Validation loss: 1.5220521496188255

Epoch: 6| Step: 10
Training loss: 0.0683894008398056
Validation loss: 1.5307360618345198

Epoch: 6| Step: 11
Training loss: 0.15527598559856415
Validation loss: 1.5166273258065666

Epoch: 6| Step: 12
Training loss: 0.07173049449920654
Validation loss: 1.524412666597674

Epoch: 6| Step: 13
Training loss: 0.13541102409362793
Validation loss: 1.5082188472952893

Epoch: 480| Step: 0
Training loss: 0.12799140810966492
Validation loss: 1.5216447435399538

Epoch: 6| Step: 1
Training loss: 0.0742754340171814
Validation loss: 1.5330616274187643

Epoch: 6| Step: 2
Training loss: 0.09747380763292313
Validation loss: 1.500524846456384

Epoch: 6| Step: 3
Training loss: 0.07695549726486206
Validation loss: 1.5139281160087996

Epoch: 6| Step: 4
Training loss: 0.08005830645561218
Validation loss: 1.473389401230761

Epoch: 6| Step: 5
Training loss: 0.1036263108253479
Validation loss: 1.4982053067094536

Epoch: 6| Step: 6
Training loss: 0.10403142869472504
Validation loss: 1.4889621273163827

Epoch: 6| Step: 7
Training loss: 0.10889067500829697
Validation loss: 1.510349832555299

Epoch: 6| Step: 8
Training loss: 0.08150885999202728
Validation loss: 1.5090606020342918

Epoch: 6| Step: 9
Training loss: 0.11338572949171066
Validation loss: 1.522755531854527

Epoch: 6| Step: 10
Training loss: 0.07988008111715317
Validation loss: 1.5260253567849436

Epoch: 6| Step: 11
Training loss: 0.05356254801154137
Validation loss: 1.5400916017511839

Epoch: 6| Step: 12
Training loss: 0.05914350971579552
Validation loss: 1.533920265654082

Epoch: 6| Step: 13
Training loss: 0.059836626052856445
Validation loss: 1.5566068285255021

Epoch: 481| Step: 0
Training loss: 0.11313188821077347
Validation loss: 1.5211024130544355

Epoch: 6| Step: 1
Training loss: 0.08949985355138779
Validation loss: 1.542265192154915

Epoch: 6| Step: 2
Training loss: 0.11087089776992798
Validation loss: 1.5464883389011506

Epoch: 6| Step: 3
Training loss: 0.09113520383834839
Validation loss: 1.5354596068782191

Epoch: 6| Step: 4
Training loss: 0.10441428422927856
Validation loss: 1.5583519704880253

Epoch: 6| Step: 5
Training loss: 0.058363139629364014
Validation loss: 1.5453919069741362

Epoch: 6| Step: 6
Training loss: 0.0925293117761612
Validation loss: 1.5292408722703175

Epoch: 6| Step: 7
Training loss: 0.1049487292766571
Validation loss: 1.5421412606393137

Epoch: 6| Step: 8
Training loss: 0.09178324043750763
Validation loss: 1.5274714193036478

Epoch: 6| Step: 9
Training loss: 0.0922040194272995
Validation loss: 1.5082110756187028

Epoch: 6| Step: 10
Training loss: 0.04708436131477356
Validation loss: 1.5127128516474078

Epoch: 6| Step: 11
Training loss: 0.061280205845832825
Validation loss: 1.5063430993787703

Epoch: 6| Step: 12
Training loss: 0.07914642244577408
Validation loss: 1.5313120042124102

Epoch: 6| Step: 13
Training loss: 0.041053492575883865
Validation loss: 1.4900889486394904

Epoch: 482| Step: 0
Training loss: 0.06634816527366638
Validation loss: 1.5316359240521666

Epoch: 6| Step: 1
Training loss: 0.12488684058189392
Validation loss: 1.5184448111441828

Epoch: 6| Step: 2
Training loss: 0.11137025058269501
Validation loss: 1.5329535520204933

Epoch: 6| Step: 3
Training loss: 0.09238798171281815
Validation loss: 1.5227099657058716

Epoch: 6| Step: 4
Training loss: 0.06351668387651443
Validation loss: 1.5331063091114003

Epoch: 6| Step: 5
Training loss: 0.062122538685798645
Validation loss: 1.5254464649385022

Epoch: 6| Step: 6
Training loss: 0.0472743920981884
Validation loss: 1.5542629880289878

Epoch: 6| Step: 7
Training loss: 0.07517276704311371
Validation loss: 1.5282277317457302

Epoch: 6| Step: 8
Training loss: 0.12749512493610382
Validation loss: 1.5469950604182419

Epoch: 6| Step: 9
Training loss: 0.17018988728523254
Validation loss: 1.577149260428644

Epoch: 6| Step: 10
Training loss: 0.10486708581447601
Validation loss: 1.5616459128677205

Epoch: 6| Step: 11
Training loss: 0.059797875583171844
Validation loss: 1.5297826733640445

Epoch: 6| Step: 12
Training loss: 0.08748966455459595
Validation loss: 1.5280033721718738

Epoch: 6| Step: 13
Training loss: 0.06868883967399597
Validation loss: 1.5335127076795023

Epoch: 483| Step: 0
Training loss: 0.1129712164402008
Validation loss: 1.5223875071412774

Epoch: 6| Step: 1
Training loss: 0.08927849680185318
Validation loss: 1.5436411660204652

Epoch: 6| Step: 2
Training loss: 0.06406594067811966
Validation loss: 1.5303876156448035

Epoch: 6| Step: 3
Training loss: 0.14295947551727295
Validation loss: 1.5401882087030718

Epoch: 6| Step: 4
Training loss: 0.11642996221780777
Validation loss: 1.5172892257731447

Epoch: 6| Step: 5
Training loss: 0.09669187664985657
Validation loss: 1.4942558811556907

Epoch: 6| Step: 6
Training loss: 0.10552272945642471
Validation loss: 1.5247732234257523

Epoch: 6| Step: 7
Training loss: 0.09272126853466034
Validation loss: 1.5122341609770251

Epoch: 6| Step: 8
Training loss: 0.08379383385181427
Validation loss: 1.5375090734933012

Epoch: 6| Step: 9
Training loss: 0.08694782108068466
Validation loss: 1.5596614870973813

Epoch: 6| Step: 10
Training loss: 0.10824283957481384
Validation loss: 1.527409145908971

Epoch: 6| Step: 11
Training loss: 0.07400300353765488
Validation loss: 1.55437675727311

Epoch: 6| Step: 12
Training loss: 0.14575932919979095
Validation loss: 1.5548866013044953

Epoch: 6| Step: 13
Training loss: 0.06867431104183197
Validation loss: 1.5390635248153441

Epoch: 484| Step: 0
Training loss: 0.08468439429998398
Validation loss: 1.567478012013179

Epoch: 6| Step: 1
Training loss: 0.1047670915722847
Validation loss: 1.5789555093293548

Epoch: 6| Step: 2
Training loss: 0.2147916555404663
Validation loss: 1.5659116583485757

Epoch: 6| Step: 3
Training loss: 0.1388782113790512
Validation loss: 1.5306859926510883

Epoch: 6| Step: 4
Training loss: 0.1640670895576477
Validation loss: 1.5142789367706544

Epoch: 6| Step: 5
Training loss: 0.12069424986839294
Validation loss: 1.557001164523504

Epoch: 6| Step: 6
Training loss: 0.11400003731250763
Validation loss: 1.535459501768953

Epoch: 6| Step: 7
Training loss: 0.15504635870456696
Validation loss: 1.532046284726871

Epoch: 6| Step: 8
Training loss: 0.13106098771095276
Validation loss: 1.4981481259868992

Epoch: 6| Step: 9
Training loss: 0.07593900710344315
Validation loss: 1.4903963387653392

Epoch: 6| Step: 10
Training loss: 0.09448732435703278
Validation loss: 1.5087479711860738

Epoch: 6| Step: 11
Training loss: 0.1592414528131485
Validation loss: 1.503789508214561

Epoch: 6| Step: 12
Training loss: 0.13676998019218445
Validation loss: 1.4977495529318368

Epoch: 6| Step: 13
Training loss: 0.0782606452703476
Validation loss: 1.5075274795614264

Epoch: 485| Step: 0
Training loss: 0.14554250240325928
Validation loss: 1.5008868581505233

Epoch: 6| Step: 1
Training loss: 0.12225539982318878
Validation loss: 1.5123667806707404

Epoch: 6| Step: 2
Training loss: 0.12024316191673279
Validation loss: 1.5251635915489608

Epoch: 6| Step: 3
Training loss: 0.06987113505601883
Validation loss: 1.5109395641152576

Epoch: 6| Step: 4
Training loss: 0.11678462475538254
Validation loss: 1.5207848036161034

Epoch: 6| Step: 5
Training loss: 0.0714738517999649
Validation loss: 1.5000225536284908

Epoch: 6| Step: 6
Training loss: 0.11483830213546753
Validation loss: 1.5312931999083488

Epoch: 6| Step: 7
Training loss: 0.13006214797496796
Validation loss: 1.5328875267377464

Epoch: 6| Step: 8
Training loss: 0.10827155411243439
Validation loss: 1.5276120683198333

Epoch: 6| Step: 9
Training loss: 0.11658403277397156
Validation loss: 1.5289177279318533

Epoch: 6| Step: 10
Training loss: 0.11685921251773834
Validation loss: 1.5317246798546083

Epoch: 6| Step: 11
Training loss: 0.0487607978284359
Validation loss: 1.535144785399078

Epoch: 6| Step: 12
Training loss: 0.067079558968544
Validation loss: 1.5247392782600977

Epoch: 6| Step: 13
Training loss: 0.1018090471625328
Validation loss: 1.5235756481847456

Epoch: 486| Step: 0
Training loss: 0.0789225697517395
Validation loss: 1.5512260365229782

Epoch: 6| Step: 1
Training loss: 0.058180175721645355
Validation loss: 1.5611947441613803

Epoch: 6| Step: 2
Training loss: 0.0458773598074913
Validation loss: 1.5487811514126357

Epoch: 6| Step: 3
Training loss: 0.10498712211847305
Validation loss: 1.555086733192526

Epoch: 6| Step: 4
Training loss: 0.11573614180088043
Validation loss: 1.5359275187215498

Epoch: 6| Step: 5
Training loss: 0.08619183301925659
Validation loss: 1.5309019357927385

Epoch: 6| Step: 6
Training loss: 0.09380197525024414
Validation loss: 1.543220543092297

Epoch: 6| Step: 7
Training loss: 0.05290422961115837
Validation loss: 1.5475435410776446

Epoch: 6| Step: 8
Training loss: 0.1697569489479065
Validation loss: 1.5519336872203375

Epoch: 6| Step: 9
Training loss: 0.09558466076850891
Validation loss: 1.5691002389436126

Epoch: 6| Step: 10
Training loss: 0.11430754512548447
Validation loss: 1.5531410696685954

Epoch: 6| Step: 11
Training loss: 0.07008376717567444
Validation loss: 1.5556802723997383

Epoch: 6| Step: 12
Training loss: 0.06582078337669373
Validation loss: 1.561278175282222

Epoch: 6| Step: 13
Training loss: 0.13301652669906616
Validation loss: 1.5534981848091207

Epoch: 487| Step: 0
Training loss: 0.037532053887844086
Validation loss: 1.5500637241589126

Epoch: 6| Step: 1
Training loss: 0.06120515242218971
Validation loss: 1.561452038826481

Epoch: 6| Step: 2
Training loss: 0.09134233742952347
Validation loss: 1.5641591023373347

Epoch: 6| Step: 3
Training loss: 0.0907140001654625
Validation loss: 1.5616909803882721

Epoch: 6| Step: 4
Training loss: 0.09099189937114716
Validation loss: 1.551070095390402

Epoch: 6| Step: 5
Training loss: 0.07439163327217102
Validation loss: 1.5593121269697785

Epoch: 6| Step: 6
Training loss: 0.059090882539749146
Validation loss: 1.5615640865859164

Epoch: 6| Step: 7
Training loss: 0.0674508661031723
Validation loss: 1.557075741470501

Epoch: 6| Step: 8
Training loss: 0.1045200303196907
Validation loss: 1.5600527114765619

Epoch: 6| Step: 9
Training loss: 0.13119655847549438
Validation loss: 1.5364292533166948

Epoch: 6| Step: 10
Training loss: 0.11291147023439407
Validation loss: 1.5371430561106691

Epoch: 6| Step: 11
Training loss: 0.07673600316047668
Validation loss: 1.5535968503644388

Epoch: 6| Step: 12
Training loss: 0.07277069985866547
Validation loss: 1.545076738121689

Epoch: 6| Step: 13
Training loss: 0.07705095410346985
Validation loss: 1.5067246383236301

Epoch: 488| Step: 0
Training loss: 0.09910216927528381
Validation loss: 1.5227025619117163

Epoch: 6| Step: 1
Training loss: 0.11262115091085434
Validation loss: 1.5247294761801278

Epoch: 6| Step: 2
Training loss: 0.07686874270439148
Validation loss: 1.5272671099632018

Epoch: 6| Step: 3
Training loss: 0.07404889911413193
Validation loss: 1.503222321951261

Epoch: 6| Step: 4
Training loss: 0.08164867758750916
Validation loss: 1.5072851065666444

Epoch: 6| Step: 5
Training loss: 0.08810899406671524
Validation loss: 1.4937321345011394

Epoch: 6| Step: 6
Training loss: 0.04390011727809906
Validation loss: 1.510765621739049

Epoch: 6| Step: 7
Training loss: 0.129044771194458
Validation loss: 1.5151955222570768

Epoch: 6| Step: 8
Training loss: 0.0575726181268692
Validation loss: 1.5094232802749963

Epoch: 6| Step: 9
Training loss: 0.06306007504463196
Validation loss: 1.4950558113795456

Epoch: 6| Step: 10
Training loss: 0.08921872079372406
Validation loss: 1.5202578216470697

Epoch: 6| Step: 11
Training loss: 0.06821268796920776
Validation loss: 1.4995561158785256

Epoch: 6| Step: 12
Training loss: 0.07858063280582428
Validation loss: 1.5244141355637582

Epoch: 6| Step: 13
Training loss: 0.15597981214523315
Validation loss: 1.5396104153766428

Epoch: 489| Step: 0
Training loss: 0.08962415158748627
Validation loss: 1.5147547798772012

Epoch: 6| Step: 1
Training loss: 0.09784021228551865
Validation loss: 1.5015840389395272

Epoch: 6| Step: 2
Training loss: 0.059061504900455475
Validation loss: 1.4966819888801985

Epoch: 6| Step: 3
Training loss: 0.0447130911052227
Validation loss: 1.4883248690635926

Epoch: 6| Step: 4
Training loss: 0.07714585214853287
Validation loss: 1.5164432192361483

Epoch: 6| Step: 5
Training loss: 0.0942775085568428
Validation loss: 1.538465061495381

Epoch: 6| Step: 6
Training loss: 0.15166033804416656
Validation loss: 1.5308840018446728

Epoch: 6| Step: 7
Training loss: 0.09153574705123901
Validation loss: 1.4994924068450928

Epoch: 6| Step: 8
Training loss: 0.09319857507944107
Validation loss: 1.500661366729326

Epoch: 6| Step: 9
Training loss: 0.058121681213378906
Validation loss: 1.485293053170686

Epoch: 6| Step: 10
Training loss: 0.09122218191623688
Validation loss: 1.5067092936526063

Epoch: 6| Step: 11
Training loss: 0.05973970144987106
Validation loss: 1.517687584764214

Epoch: 6| Step: 12
Training loss: 0.1376909613609314
Validation loss: 1.5209367993057414

Epoch: 6| Step: 13
Training loss: 0.17361903190612793
Validation loss: 1.5023442558062974

Epoch: 490| Step: 0
Training loss: 0.06792112439870834
Validation loss: 1.5188530593790033

Epoch: 6| Step: 1
Training loss: 0.08424961566925049
Validation loss: 1.5139596218703895

Epoch: 6| Step: 2
Training loss: 0.10276395827531815
Validation loss: 1.533097138968847

Epoch: 6| Step: 3
Training loss: 0.10242106020450592
Validation loss: 1.5140942130037534

Epoch: 6| Step: 4
Training loss: 0.08005711436271667
Validation loss: 1.505666809697305

Epoch: 6| Step: 5
Training loss: 0.09264430403709412
Validation loss: 1.5136069623372888

Epoch: 6| Step: 6
Training loss: 0.14538758993148804
Validation loss: 1.5055324217324615

Epoch: 6| Step: 7
Training loss: 0.059209201484918594
Validation loss: 1.5300926226441578

Epoch: 6| Step: 8
Training loss: 0.07779236137866974
Validation loss: 1.5411029810546546

Epoch: 6| Step: 9
Training loss: 0.0369495265185833
Validation loss: 1.523099277609138

Epoch: 6| Step: 10
Training loss: 0.09078971296548843
Validation loss: 1.5104164449117516

Epoch: 6| Step: 11
Training loss: 0.09685517102479935
Validation loss: 1.517909155097059

Epoch: 6| Step: 12
Training loss: 0.11383064836263657
Validation loss: 1.5231058661655714

Epoch: 6| Step: 13
Training loss: 0.09559619426727295
Validation loss: 1.5118766600085842

Epoch: 491| Step: 0
Training loss: 0.07810208201408386
Validation loss: 1.5510297116412912

Epoch: 6| Step: 1
Training loss: 0.06262780725955963
Validation loss: 1.5158665731389036

Epoch: 6| Step: 2
Training loss: 0.03773385286331177
Validation loss: 1.5019062719037455

Epoch: 6| Step: 3
Training loss: 0.07833189517259598
Validation loss: 1.5272974660319667

Epoch: 6| Step: 4
Training loss: 0.08986666053533554
Validation loss: 1.5147777116426857

Epoch: 6| Step: 5
Training loss: 0.08646216988563538
Validation loss: 1.5240965658618557

Epoch: 6| Step: 6
Training loss: 0.11521155387163162
Validation loss: 1.53117081170441

Epoch: 6| Step: 7
Training loss: 0.12907497584819794
Validation loss: 1.5394825076544156

Epoch: 6| Step: 8
Training loss: 0.06545474380254745
Validation loss: 1.5261976744538994

Epoch: 6| Step: 9
Training loss: 0.08867579698562622
Validation loss: 1.505234710631832

Epoch: 6| Step: 10
Training loss: 0.09933960437774658
Validation loss: 1.50315906283676

Epoch: 6| Step: 11
Training loss: 0.08962447941303253
Validation loss: 1.4980775797238914

Epoch: 6| Step: 12
Training loss: 0.08409196138381958
Validation loss: 1.5128239072779173

Epoch: 6| Step: 13
Training loss: 0.11043497920036316
Validation loss: 1.4960426335693688

Epoch: 492| Step: 0
Training loss: 0.1075829416513443
Validation loss: 1.5048415071220809

Epoch: 6| Step: 1
Training loss: 0.03831782937049866
Validation loss: 1.5262611476323937

Epoch: 6| Step: 2
Training loss: 0.09569340944290161
Validation loss: 1.5094532658976894

Epoch: 6| Step: 3
Training loss: 0.10727755725383759
Validation loss: 1.5238732766079646

Epoch: 6| Step: 4
Training loss: 0.04772399365901947
Validation loss: 1.5089186340249994

Epoch: 6| Step: 5
Training loss: 0.06010189652442932
Validation loss: 1.5430197497849822

Epoch: 6| Step: 6
Training loss: 0.13086211681365967
Validation loss: 1.5347828236959313

Epoch: 6| Step: 7
Training loss: 0.07108627259731293
Validation loss: 1.567327086643506

Epoch: 6| Step: 8
Training loss: 0.06982975453138351
Validation loss: 1.5531711014368201

Epoch: 6| Step: 9
Training loss: 0.1177741214632988
Validation loss: 1.5206726206246244

Epoch: 6| Step: 10
Training loss: 0.11335639655590057
Validation loss: 1.5268513515431394

Epoch: 6| Step: 11
Training loss: 0.08781743049621582
Validation loss: 1.5180886125051847

Epoch: 6| Step: 12
Training loss: 0.07935833930969238
Validation loss: 1.5126694992024412

Epoch: 6| Step: 13
Training loss: 0.0509980134665966
Validation loss: 1.5085202429884224

Epoch: 493| Step: 0
Training loss: 0.08342669904232025
Validation loss: 1.486425833676451

Epoch: 6| Step: 1
Training loss: 0.07200413197278976
Validation loss: 1.5032726167350687

Epoch: 6| Step: 2
Training loss: 0.07035472989082336
Validation loss: 1.5003523044688727

Epoch: 6| Step: 3
Training loss: 0.04750858619809151
Validation loss: 1.521748859395263

Epoch: 6| Step: 4
Training loss: 0.0714726597070694
Validation loss: 1.514955896203236

Epoch: 6| Step: 5
Training loss: 0.12535257637500763
Validation loss: 1.496714609925465

Epoch: 6| Step: 6
Training loss: 0.07142680883407593
Validation loss: 1.5033241818028111

Epoch: 6| Step: 7
Training loss: 0.0685114935040474
Validation loss: 1.5109020433118265

Epoch: 6| Step: 8
Training loss: 0.04527534544467926
Validation loss: 1.5055532904081448

Epoch: 6| Step: 9
Training loss: 0.07543720304965973
Validation loss: 1.506097973033946

Epoch: 6| Step: 10
Training loss: 0.07842446863651276
Validation loss: 1.4778906882450145

Epoch: 6| Step: 11
Training loss: 0.052975744009017944
Validation loss: 1.4778891763379496

Epoch: 6| Step: 12
Training loss: 0.07873237133026123
Validation loss: 1.4948145830503075

Epoch: 6| Step: 13
Training loss: 0.11323213577270508
Validation loss: 1.5152345011311192

Epoch: 494| Step: 0
Training loss: 0.06570775806903839
Validation loss: 1.4988480062894924

Epoch: 6| Step: 1
Training loss: 0.037407469004392624
Validation loss: 1.5311719794427194

Epoch: 6| Step: 2
Training loss: 0.04208345711231232
Validation loss: 1.540771012665123

Epoch: 6| Step: 3
Training loss: 0.1017114669084549
Validation loss: 1.5339154543415192

Epoch: 6| Step: 4
Training loss: 0.08818764984607697
Validation loss: 1.5262372365561865

Epoch: 6| Step: 5
Training loss: 0.07603642344474792
Validation loss: 1.5327268082608458

Epoch: 6| Step: 6
Training loss: 0.10278143733739853
Validation loss: 1.5038031711373279

Epoch: 6| Step: 7
Training loss: 0.12375365942716599
Validation loss: 1.4992869624527552

Epoch: 6| Step: 8
Training loss: 0.07770536839962006
Validation loss: 1.5345530176675448

Epoch: 6| Step: 9
Training loss: 0.07175086438655853
Validation loss: 1.5143020563228156

Epoch: 6| Step: 10
Training loss: 0.0690460205078125
Validation loss: 1.4997304357508177

Epoch: 6| Step: 11
Training loss: 0.09438791871070862
Validation loss: 1.5144708976950696

Epoch: 6| Step: 12
Training loss: 0.06498822569847107
Validation loss: 1.50994860997764

Epoch: 6| Step: 13
Training loss: 0.10359382629394531
Validation loss: 1.505042109438168

Epoch: 495| Step: 0
Training loss: 0.06433422863483429
Validation loss: 1.4951073392744987

Epoch: 6| Step: 1
Training loss: 0.08970126509666443
Validation loss: 1.527515310113148

Epoch: 6| Step: 2
Training loss: 0.06270249933004379
Validation loss: 1.5334697872079828

Epoch: 6| Step: 3
Training loss: 0.14110347628593445
Validation loss: 1.5257310841673164

Epoch: 6| Step: 4
Training loss: 0.037428200244903564
Validation loss: 1.5150647291573145

Epoch: 6| Step: 5
Training loss: 0.06461555510759354
Validation loss: 1.5126827634790891

Epoch: 6| Step: 6
Training loss: 0.07572683691978455
Validation loss: 1.5281446108254053

Epoch: 6| Step: 7
Training loss: 0.07681974768638611
Validation loss: 1.5061225301475936

Epoch: 6| Step: 8
Training loss: 0.05640147626399994
Validation loss: 1.5265668592145365

Epoch: 6| Step: 9
Training loss: 0.041345562785863876
Validation loss: 1.5051855694863103

Epoch: 6| Step: 10
Training loss: 0.08691376447677612
Validation loss: 1.4928597199019564

Epoch: 6| Step: 11
Training loss: 0.04727741703391075
Validation loss: 1.5169094262584564

Epoch: 6| Step: 12
Training loss: 0.09327930957078934
Validation loss: 1.5081452067180345

Epoch: 6| Step: 13
Training loss: 0.180677592754364
Validation loss: 1.5182512485852806

Epoch: 496| Step: 0
Training loss: 0.13750463724136353
Validation loss: 1.5069295847287743

Epoch: 6| Step: 1
Training loss: 0.06559489667415619
Validation loss: 1.5136341548735095

Epoch: 6| Step: 2
Training loss: 0.07870829850435257
Validation loss: 1.5040265078185706

Epoch: 6| Step: 3
Training loss: 0.06478188186883926
Validation loss: 1.5282950657670216

Epoch: 6| Step: 4
Training loss: 0.10207543522119522
Validation loss: 1.5293168483241912

Epoch: 6| Step: 5
Training loss: 0.17979831993579865
Validation loss: 1.5163634669396184

Epoch: 6| Step: 6
Training loss: 0.08373871445655823
Validation loss: 1.5547009847497428

Epoch: 6| Step: 7
Training loss: 0.10511279106140137
Validation loss: 1.5108631387833626

Epoch: 6| Step: 8
Training loss: 0.10293348133563995
Validation loss: 1.481864030643176

Epoch: 6| Step: 9
Training loss: 0.07374913990497589
Validation loss: 1.5184385699610556

Epoch: 6| Step: 10
Training loss: 0.0708414688706398
Validation loss: 1.5356060087039907

Epoch: 6| Step: 11
Training loss: 0.09098513424396515
Validation loss: 1.5251024294924993

Epoch: 6| Step: 12
Training loss: 0.13887172937393188
Validation loss: 1.513122502193656

Epoch: 6| Step: 13
Training loss: 0.057110294699668884
Validation loss: 1.504700909378708

Epoch: 497| Step: 0
Training loss: 0.03081706166267395
Validation loss: 1.5160389536170549

Epoch: 6| Step: 1
Training loss: 0.07494340091943741
Validation loss: 1.5128740725978729

Epoch: 6| Step: 2
Training loss: 0.09718097001314163
Validation loss: 1.537819298364783

Epoch: 6| Step: 3
Training loss: 0.11572970449924469
Validation loss: 1.5315554949545092

Epoch: 6| Step: 4
Training loss: 0.12628832459449768
Validation loss: 1.5270274428911106

Epoch: 6| Step: 5
Training loss: 0.15205872058868408
Validation loss: 1.553493087009717

Epoch: 6| Step: 6
Training loss: 0.04660571366548538
Validation loss: 1.5242470618217223

Epoch: 6| Step: 7
Training loss: 0.07260900735855103
Validation loss: 1.502931599975914

Epoch: 6| Step: 8
Training loss: 0.08189903199672699
Validation loss: 1.5021831553469422

Epoch: 6| Step: 9
Training loss: 0.14605197310447693
Validation loss: 1.5237193030695761

Epoch: 6| Step: 10
Training loss: 0.09947364777326584
Validation loss: 1.5016068591866443

Epoch: 6| Step: 11
Training loss: 0.07764028012752533
Validation loss: 1.5057266175106008

Epoch: 6| Step: 12
Training loss: 0.08673030883073807
Validation loss: 1.5421299883114394

Epoch: 6| Step: 13
Training loss: 0.05191558226943016
Validation loss: 1.5260410475474533

Epoch: 498| Step: 0
Training loss: 0.07730761170387268
Validation loss: 1.5019491949389059

Epoch: 6| Step: 1
Training loss: 0.1085560992360115
Validation loss: 1.5413874413377495

Epoch: 6| Step: 2
Training loss: 0.07634009420871735
Validation loss: 1.5455458882034465

Epoch: 6| Step: 3
Training loss: 0.08560441434383392
Validation loss: 1.556680271702428

Epoch: 6| Step: 4
Training loss: 0.049661584198474884
Validation loss: 1.5333849653120963

Epoch: 6| Step: 5
Training loss: 0.10562010109424591
Validation loss: 1.5350761080300936

Epoch: 6| Step: 6
Training loss: 0.08280569314956665
Validation loss: 1.5459684389893726

Epoch: 6| Step: 7
Training loss: 0.1025618463754654
Validation loss: 1.526043668870003

Epoch: 6| Step: 8
Training loss: 0.0654132068157196
Validation loss: 1.5375731081090949

Epoch: 6| Step: 9
Training loss: 0.07791667431592941
Validation loss: 1.5154502237996748

Epoch: 6| Step: 10
Training loss: 0.08996998518705368
Validation loss: 1.5348016985001103

Epoch: 6| Step: 11
Training loss: 0.059097275137901306
Validation loss: 1.5428587121348227

Epoch: 6| Step: 12
Training loss: 0.07956937700510025
Validation loss: 1.5166320249598513

Epoch: 6| Step: 13
Training loss: 0.08334287256002426
Validation loss: 1.5093844988012826

Epoch: 499| Step: 0
Training loss: 0.0643065869808197
Validation loss: 1.516065553952289

Epoch: 6| Step: 1
Training loss: 0.12463750690221786
Validation loss: 1.528925649581417

Epoch: 6| Step: 2
Training loss: 0.09255830943584442
Validation loss: 1.524694740131337

Epoch: 6| Step: 3
Training loss: 0.08428443968296051
Validation loss: 1.5040769013025428

Epoch: 6| Step: 4
Training loss: 0.06905033439397812
Validation loss: 1.545896601933305

Epoch: 6| Step: 5
Training loss: 0.10211026668548584
Validation loss: 1.5462174556588615

Epoch: 6| Step: 6
Training loss: 0.10676880180835724
Validation loss: 1.5721356176560926

Epoch: 6| Step: 7
Training loss: 0.09990866482257843
Validation loss: 1.5311168022053216

Epoch: 6| Step: 8
Training loss: 0.1428203582763672
Validation loss: 1.5760411575276365

Epoch: 6| Step: 9
Training loss: 0.07613803446292877
Validation loss: 1.5186761643296929

Epoch: 6| Step: 10
Training loss: 0.05740085616707802
Validation loss: 1.5217741856011011

Epoch: 6| Step: 11
Training loss: 0.08168933540582657
Validation loss: 1.5145490964253743

Epoch: 6| Step: 12
Training loss: 0.15724626183509827
Validation loss: 1.5373352484036518

Epoch: 6| Step: 13
Training loss: 0.12793970108032227
Validation loss: 1.5534395030749741

Epoch: 500| Step: 0
Training loss: 0.13755366206169128
Validation loss: 1.5239091925723578

Epoch: 6| Step: 1
Training loss: 0.07602250576019287
Validation loss: 1.539049884965343

Epoch: 6| Step: 2
Training loss: 0.10797266662120819
Validation loss: 1.487209326477461

Epoch: 6| Step: 3
Training loss: 0.0697837620973587
Validation loss: 1.523804086510853

Epoch: 6| Step: 4
Training loss: 0.08739210665225983
Validation loss: 1.5176889934847433

Epoch: 6| Step: 5
Training loss: 0.13100814819335938
Validation loss: 1.5192282840769777

Epoch: 6| Step: 6
Training loss: 0.08976194262504578
Validation loss: 1.515253154180383

Epoch: 6| Step: 7
Training loss: 0.0930304154753685
Validation loss: 1.5211859300572386

Epoch: 6| Step: 8
Training loss: 0.1326807290315628
Validation loss: 1.5206054333717591

Epoch: 6| Step: 9
Training loss: 0.08945819735527039
Validation loss: 1.5006325116721533

Epoch: 6| Step: 10
Training loss: 0.09818015992641449
Validation loss: 1.5179433002266833

Epoch: 6| Step: 11
Training loss: 0.10734163224697113
Validation loss: 1.498959381093261

Epoch: 6| Step: 12
Training loss: 0.10864555835723877
Validation loss: 1.50981939864415

Epoch: 6| Step: 13
Training loss: 0.08373203873634338
Validation loss: 1.4960159217157671

Epoch: 501| Step: 0
Training loss: 0.0734764039516449
Validation loss: 1.5076922460268902

Epoch: 6| Step: 1
Training loss: 0.1549186110496521
Validation loss: 1.5279377122079172

Epoch: 6| Step: 2
Training loss: 0.0961170569062233
Validation loss: 1.5144403262804913

Epoch: 6| Step: 3
Training loss: 0.14142785966396332
Validation loss: 1.521908296692756

Epoch: 6| Step: 4
Training loss: 0.08371201902627945
Validation loss: 1.5053785475351478

Epoch: 6| Step: 5
Training loss: 0.08392554521560669
Validation loss: 1.492886351000878

Epoch: 6| Step: 6
Training loss: 0.049977079033851624
Validation loss: 1.4856427587488645

Epoch: 6| Step: 7
Training loss: 0.05898944288492203
Validation loss: 1.5051011987911758

Epoch: 6| Step: 8
Training loss: 0.06453723460435867
Validation loss: 1.5009254742694158

Epoch: 6| Step: 9
Training loss: 0.11644867807626724
Validation loss: 1.5195625776885657

Epoch: 6| Step: 10
Training loss: 0.09151168912649155
Validation loss: 1.5059351075080134

Epoch: 6| Step: 11
Training loss: 0.06746484339237213
Validation loss: 1.4990536782049364

Epoch: 6| Step: 12
Training loss: 0.06526537239551544
Validation loss: 1.5096860726674397

Epoch: 6| Step: 13
Training loss: 0.14226198196411133
Validation loss: 1.4762073851400805

Epoch: 502| Step: 0
Training loss: 0.07450110465288162
Validation loss: 1.5343130750040854

Epoch: 6| Step: 1
Training loss: 0.07986091077327728
Validation loss: 1.5101060508399882

Epoch: 6| Step: 2
Training loss: 0.11271291226148605
Validation loss: 1.483285657821163

Epoch: 6| Step: 3
Training loss: 0.07007108628749847
Validation loss: 1.508274648779182

Epoch: 6| Step: 4
Training loss: 0.06604834645986557
Validation loss: 1.5186417089995516

Epoch: 6| Step: 5
Training loss: 0.07067970931529999
Validation loss: 1.5196927260327082

Epoch: 6| Step: 6
Training loss: 0.10802692174911499
Validation loss: 1.5119455540052025

Epoch: 6| Step: 7
Training loss: 0.03854631632566452
Validation loss: 1.5134169606752292

Epoch: 6| Step: 8
Training loss: 0.07253486663103104
Validation loss: 1.5419996771761166

Epoch: 6| Step: 9
Training loss: 0.11858594417572021
Validation loss: 1.5566386330512263

Epoch: 6| Step: 10
Training loss: 0.1477384865283966
Validation loss: 1.5598455590586509

Epoch: 6| Step: 11
Training loss: 0.09931787848472595
Validation loss: 1.5339281853809152

Epoch: 6| Step: 12
Training loss: 0.06118234246969223
Validation loss: 1.5188631319230603

Epoch: 6| Step: 13
Training loss: 0.12151249498128891
Validation loss: 1.5286405753063899

Epoch: 503| Step: 0
Training loss: 0.04622936248779297
Validation loss: 1.5284402524271319

Epoch: 6| Step: 1
Training loss: 0.1112576350569725
Validation loss: 1.5070931065467097

Epoch: 6| Step: 2
Training loss: 0.10497654974460602
Validation loss: 1.5268747345093758

Epoch: 6| Step: 3
Training loss: 0.12583592534065247
Validation loss: 1.5323988763234948

Epoch: 6| Step: 4
Training loss: 0.06109273433685303
Validation loss: 1.5620167511765675

Epoch: 6| Step: 5
Training loss: 0.07765497267246246
Validation loss: 1.570979090147121

Epoch: 6| Step: 6
Training loss: 0.08813246339559555
Validation loss: 1.5434380936366257

Epoch: 6| Step: 7
Training loss: 0.05885747820138931
Validation loss: 1.5202365376616036

Epoch: 6| Step: 8
Training loss: 0.09160536527633667
Validation loss: 1.5405668199703257

Epoch: 6| Step: 9
Training loss: 0.09278162568807602
Validation loss: 1.5483548538659209

Epoch: 6| Step: 10
Training loss: 0.0874873697757721
Validation loss: 1.522917401406073

Epoch: 6| Step: 11
Training loss: 0.06258648633956909
Validation loss: 1.552707068381771

Epoch: 6| Step: 12
Training loss: 0.12795217335224152
Validation loss: 1.5482381325896069

Epoch: 6| Step: 13
Training loss: 0.10081356763839722
Validation loss: 1.5538287752418107

Epoch: 504| Step: 0
Training loss: 0.0739181786775589
Validation loss: 1.5344501028778732

Epoch: 6| Step: 1
Training loss: 0.15438508987426758
Validation loss: 1.5593696922384284

Epoch: 6| Step: 2
Training loss: 0.159274160861969
Validation loss: 1.5376774393102175

Epoch: 6| Step: 3
Training loss: 0.09774835407733917
Validation loss: 1.5309111290080573

Epoch: 6| Step: 4
Training loss: 0.0674174427986145
Validation loss: 1.5265678013524702

Epoch: 6| Step: 5
Training loss: 0.10125596821308136
Validation loss: 1.518915391737415

Epoch: 6| Step: 6
Training loss: 0.0385703444480896
Validation loss: 1.559122726481448

Epoch: 6| Step: 7
Training loss: 0.10182793438434601
Validation loss: 1.5696905377090618

Epoch: 6| Step: 8
Training loss: 0.09238652139902115
Validation loss: 1.5727532268852316

Epoch: 6| Step: 9
Training loss: 0.07479733973741531
Validation loss: 1.565576167516811

Epoch: 6| Step: 10
Training loss: 0.07168935239315033
Validation loss: 1.5278279114794988

Epoch: 6| Step: 11
Training loss: 0.05641496926546097
Validation loss: 1.5398223195024716

Epoch: 6| Step: 12
Training loss: 0.05229797214269638
Validation loss: 1.5097335974375408

Epoch: 6| Step: 13
Training loss: 0.04540755972266197
Validation loss: 1.5154151660139843

Epoch: 505| Step: 0
Training loss: 0.06268852949142456
Validation loss: 1.4999784910550682

Epoch: 6| Step: 1
Training loss: 0.07455779612064362
Validation loss: 1.529132108534536

Epoch: 6| Step: 2
Training loss: 0.08324819058179855
Validation loss: 1.486448343082141

Epoch: 6| Step: 3
Training loss: 0.09783953428268433
Validation loss: 1.5107392380314488

Epoch: 6| Step: 4
Training loss: 0.08032840490341187
Validation loss: 1.5037404926874305

Epoch: 6| Step: 5
Training loss: 0.06665375828742981
Validation loss: 1.5306343365741033

Epoch: 6| Step: 6
Training loss: 0.08651898801326752
Validation loss: 1.527473395870578

Epoch: 6| Step: 7
Training loss: 0.0698927491903305
Validation loss: 1.5272435039602301

Epoch: 6| Step: 8
Training loss: 0.07265844941139221
Validation loss: 1.552021900812785

Epoch: 6| Step: 9
Training loss: 0.07597731053829193
Validation loss: 1.5285212980803622

Epoch: 6| Step: 10
Training loss: 0.05255232751369476
Validation loss: 1.533935131565217

Epoch: 6| Step: 11
Training loss: 0.04197710007429123
Validation loss: 1.5150898951356129

Epoch: 6| Step: 12
Training loss: 0.05609414726495743
Validation loss: 1.5263592017594205

Epoch: 6| Step: 13
Training loss: 0.07183456420898438
Validation loss: 1.5138071775436401

Epoch: 506| Step: 0
Training loss: 0.0911581814289093
Validation loss: 1.5085245857956588

Epoch: 6| Step: 1
Training loss: 0.05886295065283775
Validation loss: 1.5117634355380971

Epoch: 6| Step: 2
Training loss: 0.06617067754268646
Validation loss: 1.5110494539301882

Epoch: 6| Step: 3
Training loss: 0.08225142955780029
Validation loss: 1.5020994370983494

Epoch: 6| Step: 4
Training loss: 0.06177133321762085
Validation loss: 1.5153751501473047

Epoch: 6| Step: 5
Training loss: 0.09165914356708527
Validation loss: 1.5114052308503019

Epoch: 6| Step: 6
Training loss: 0.06165161728858948
Validation loss: 1.5038171557969944

Epoch: 6| Step: 7
Training loss: 0.13243186473846436
Validation loss: 1.51097579925291

Epoch: 6| Step: 8
Training loss: 0.06802632659673691
Validation loss: 1.5442308161848335

Epoch: 6| Step: 9
Training loss: 0.05381730943918228
Validation loss: 1.541456731416846

Epoch: 6| Step: 10
Training loss: 0.06999265402555466
Validation loss: 1.5341047215205368

Epoch: 6| Step: 11
Training loss: 0.10937703400850296
Validation loss: 1.5390204332208122

Epoch: 6| Step: 12
Training loss: 0.09470626711845398
Validation loss: 1.5379929068267986

Epoch: 6| Step: 13
Training loss: 0.044642865657806396
Validation loss: 1.5552159111986879

Epoch: 507| Step: 0
Training loss: 0.07554972916841507
Validation loss: 1.5720667313503962

Epoch: 6| Step: 1
Training loss: 0.12288206815719604
Validation loss: 1.5354020095640613

Epoch: 6| Step: 2
Training loss: 0.08420726656913757
Validation loss: 1.5150281152417582

Epoch: 6| Step: 3
Training loss: 0.09103904664516449
Validation loss: 1.5237906998203647

Epoch: 6| Step: 4
Training loss: 0.06364292651414871
Validation loss: 1.5213034665712746

Epoch: 6| Step: 5
Training loss: 0.07150145620107651
Validation loss: 1.5165728471612419

Epoch: 6| Step: 6
Training loss: 0.04384860768914223
Validation loss: 1.5143644143176336

Epoch: 6| Step: 7
Training loss: 0.0923578292131424
Validation loss: 1.5310535238635155

Epoch: 6| Step: 8
Training loss: 0.06364623457193375
Validation loss: 1.536615744713814

Epoch: 6| Step: 9
Training loss: 0.07867911458015442
Validation loss: 1.5390808338760047

Epoch: 6| Step: 10
Training loss: 0.0695207267999649
Validation loss: 1.5273223064279045

Epoch: 6| Step: 11
Training loss: 0.1256565898656845
Validation loss: 1.5333028980480727

Epoch: 6| Step: 12
Training loss: 0.06496022641658783
Validation loss: 1.541171266186622

Epoch: 6| Step: 13
Training loss: 0.08920660614967346
Validation loss: 1.5402993617519256

Epoch: 508| Step: 0
Training loss: 0.06754152476787567
Validation loss: 1.5046253787573947

Epoch: 6| Step: 1
Training loss: 0.10263039171695709
Validation loss: 1.527638755818849

Epoch: 6| Step: 2
Training loss: 0.04984750598669052
Validation loss: 1.5011573302489456

Epoch: 6| Step: 3
Training loss: 0.08168277144432068
Validation loss: 1.5112254914417063

Epoch: 6| Step: 4
Training loss: 0.07494582235813141
Validation loss: 1.518561799039123

Epoch: 6| Step: 5
Training loss: 0.05072074010968208
Validation loss: 1.525946887590552

Epoch: 6| Step: 6
Training loss: 0.07775036990642548
Validation loss: 1.5016978030563684

Epoch: 6| Step: 7
Training loss: 0.10423821955919266
Validation loss: 1.5179052891269806

Epoch: 6| Step: 8
Training loss: 0.08840909600257874
Validation loss: 1.5385076743300243

Epoch: 6| Step: 9
Training loss: 0.09236636757850647
Validation loss: 1.5309280272453063

Epoch: 6| Step: 10
Training loss: 0.06817054748535156
Validation loss: 1.5249826754293134

Epoch: 6| Step: 11
Training loss: 0.07563384622335434
Validation loss: 1.5512370928641288

Epoch: 6| Step: 12
Training loss: 0.11361874639987946
Validation loss: 1.5552277513729629

Epoch: 6| Step: 13
Training loss: 0.0615367628633976
Validation loss: 1.5514446676418345

Epoch: 509| Step: 0
Training loss: 0.07010749727487564
Validation loss: 1.544118155715286

Epoch: 6| Step: 1
Training loss: 0.05522902309894562
Validation loss: 1.5281441826974191

Epoch: 6| Step: 2
Training loss: 0.07960077375173569
Validation loss: 1.5337457887588009

Epoch: 6| Step: 3
Training loss: 0.04734724760055542
Validation loss: 1.5348160100239578

Epoch: 6| Step: 4
Training loss: 0.058701835572719574
Validation loss: 1.5614498302500734

Epoch: 6| Step: 5
Training loss: 0.0899612084031105
Validation loss: 1.559511729466018

Epoch: 6| Step: 6
Training loss: 0.07152621448040009
Validation loss: 1.5377181435144076

Epoch: 6| Step: 7
Training loss: 0.05635717138648033
Validation loss: 1.5556828424494753

Epoch: 6| Step: 8
Training loss: 0.15609081089496613
Validation loss: 1.5451681607513017

Epoch: 6| Step: 9
Training loss: 0.07540974020957947
Validation loss: 1.5284678487367527

Epoch: 6| Step: 10
Training loss: 0.04647677019238472
Validation loss: 1.5305208313849665

Epoch: 6| Step: 11
Training loss: 0.06886900961399078
Validation loss: 1.5560342124713364

Epoch: 6| Step: 12
Training loss: 0.06359050422906876
Validation loss: 1.5636686810883142

Epoch: 6| Step: 13
Training loss: 0.11901811510324478
Validation loss: 1.5648271652960009

Epoch: 510| Step: 0
Training loss: 0.10634163022041321
Validation loss: 1.537011755410061

Epoch: 6| Step: 1
Training loss: 0.11134772002696991
Validation loss: 1.5494059388355543

Epoch: 6| Step: 2
Training loss: 0.08152753859758377
Validation loss: 1.5683643420537312

Epoch: 6| Step: 3
Training loss: 0.07323628664016724
Validation loss: 1.5543435722269037

Epoch: 6| Step: 4
Training loss: 0.08642081916332245
Validation loss: 1.5226661594965125

Epoch: 6| Step: 5
Training loss: 0.08209767192602158
Validation loss: 1.5310406556693457

Epoch: 6| Step: 6
Training loss: 0.08952389657497406
Validation loss: 1.553343226191818

Epoch: 6| Step: 7
Training loss: 0.08910732716321945
Validation loss: 1.5295309828173729

Epoch: 6| Step: 8
Training loss: 0.08065550774335861
Validation loss: 1.5444749491189116

Epoch: 6| Step: 9
Training loss: 0.049185775220394135
Validation loss: 1.5499935406510548

Epoch: 6| Step: 10
Training loss: 0.061501722782850266
Validation loss: 1.5523691254277383

Epoch: 6| Step: 11
Training loss: 0.1018480435013771
Validation loss: 1.5370502023286716

Epoch: 6| Step: 12
Training loss: 0.0816483199596405
Validation loss: 1.5402921899672477

Epoch: 6| Step: 13
Training loss: 0.04777646064758301
Validation loss: 1.5390869930226316

Epoch: 511| Step: 0
Training loss: 0.09750285744667053
Validation loss: 1.5468658977939236

Epoch: 6| Step: 1
Training loss: 0.08886324614286423
Validation loss: 1.5168339949782177

Epoch: 6| Step: 2
Training loss: 0.08169523626565933
Validation loss: 1.559673834872502

Epoch: 6| Step: 3
Training loss: 0.09402664005756378
Validation loss: 1.5417278351322297

Epoch: 6| Step: 4
Training loss: 0.08415240049362183
Validation loss: 1.552807577194706

Epoch: 6| Step: 5
Training loss: 0.09332159906625748
Validation loss: 1.5516335502747567

Epoch: 6| Step: 6
Training loss: 0.10685176402330399
Validation loss: 1.5558678655214206

Epoch: 6| Step: 7
Training loss: 0.11330345273017883
Validation loss: 1.5158587258349183

Epoch: 6| Step: 8
Training loss: 0.11916674673557281
Validation loss: 1.4881069320504383

Epoch: 6| Step: 9
Training loss: 0.11308707296848297
Validation loss: 1.5269864554046302

Epoch: 6| Step: 10
Training loss: 0.07328283786773682
Validation loss: 1.524973359159244

Epoch: 6| Step: 11
Training loss: 0.10805812478065491
Validation loss: 1.5350699822107952

Epoch: 6| Step: 12
Training loss: 0.06657449901103973
Validation loss: 1.533379630375934

Epoch: 6| Step: 13
Training loss: 0.09127232432365417
Validation loss: 1.5168103710297616

Epoch: 512| Step: 0
Training loss: 0.055014677345752716
Validation loss: 1.5108042019669727

Epoch: 6| Step: 1
Training loss: 0.058336298912763596
Validation loss: 1.5209713161632579

Epoch: 6| Step: 2
Training loss: 0.08742082118988037
Validation loss: 1.5060380222976848

Epoch: 6| Step: 3
Training loss: 0.10239018499851227
Validation loss: 1.5486273432290683

Epoch: 6| Step: 4
Training loss: 0.10269957780838013
Validation loss: 1.5397657963537401

Epoch: 6| Step: 5
Training loss: 0.10488393902778625
Validation loss: 1.562082790559338

Epoch: 6| Step: 6
Training loss: 0.0801219567656517
Validation loss: 1.5622001219821233

Epoch: 6| Step: 7
Training loss: 0.08374886214733124
Validation loss: 1.556937163875949

Epoch: 6| Step: 8
Training loss: 0.16169175505638123
Validation loss: 1.5428254770976242

Epoch: 6| Step: 9
Training loss: 0.05458124727010727
Validation loss: 1.5715144981620133

Epoch: 6| Step: 10
Training loss: 0.0339023657143116
Validation loss: 1.5280369840642458

Epoch: 6| Step: 11
Training loss: 0.10091561079025269
Validation loss: 1.5020321940863004

Epoch: 6| Step: 12
Training loss: 0.10618484020233154
Validation loss: 1.494490788828942

Epoch: 6| Step: 13
Training loss: 0.08218082040548325
Validation loss: 1.5019114158486808

Epoch: 513| Step: 0
Training loss: 0.0995226502418518
Validation loss: 1.5301941710133706

Epoch: 6| Step: 1
Training loss: 0.11612372100353241
Validation loss: 1.5261429317535893

Epoch: 6| Step: 2
Training loss: 0.07537247985601425
Validation loss: 1.5491415621131979

Epoch: 6| Step: 3
Training loss: 0.08033136278390884
Validation loss: 1.5206317517065233

Epoch: 6| Step: 4
Training loss: 0.07350863516330719
Validation loss: 1.5148812083787815

Epoch: 6| Step: 5
Training loss: 0.10245121270418167
Validation loss: 1.536715284470589

Epoch: 6| Step: 6
Training loss: 0.05981984734535217
Validation loss: 1.5399596832131828

Epoch: 6| Step: 7
Training loss: 0.1415473073720932
Validation loss: 1.5535509381242978

Epoch: 6| Step: 8
Training loss: 0.11230675876140594
Validation loss: 1.5583515115963515

Epoch: 6| Step: 9
Training loss: 0.11317417770624161
Validation loss: 1.5678051364037298

Epoch: 6| Step: 10
Training loss: 0.1211756020784378
Validation loss: 1.5568739803888465

Epoch: 6| Step: 11
Training loss: 0.0658138245344162
Validation loss: 1.5516577023331837

Epoch: 6| Step: 12
Training loss: 0.09034499526023865
Validation loss: 1.5293359666742303

Epoch: 6| Step: 13
Training loss: 0.09159287810325623
Validation loss: 1.5304569685330955

Epoch: 514| Step: 0
Training loss: 0.08016663789749146
Validation loss: 1.5525572440957511

Epoch: 6| Step: 1
Training loss: 0.0520557202398777
Validation loss: 1.572408208283045

Epoch: 6| Step: 2
Training loss: 0.08267848193645477
Validation loss: 1.5577527746077506

Epoch: 6| Step: 3
Training loss: 0.08695483207702637
Validation loss: 1.5400581943091525

Epoch: 6| Step: 4
Training loss: 0.10363900661468506
Validation loss: 1.5344034587183306

Epoch: 6| Step: 5
Training loss: 0.11035113781690598
Validation loss: 1.5424170045442478

Epoch: 6| Step: 6
Training loss: 0.0757947713136673
Validation loss: 1.5302152044029647

Epoch: 6| Step: 7
Training loss: 0.0865563452243805
Validation loss: 1.5469618023082774

Epoch: 6| Step: 8
Training loss: 0.08612282574176788
Validation loss: 1.5548520036922988

Epoch: 6| Step: 9
Training loss: 0.09790514409542084
Validation loss: 1.5229499942512923

Epoch: 6| Step: 10
Training loss: 0.0706726536154747
Validation loss: 1.5376321077346802

Epoch: 6| Step: 11
Training loss: 0.10773864388465881
Validation loss: 1.5242199474765408

Epoch: 6| Step: 12
Training loss: 0.10051794350147247
Validation loss: 1.5141304949278473

Epoch: 6| Step: 13
Training loss: 0.04709920659661293
Validation loss: 1.516134403085196

Epoch: 515| Step: 0
Training loss: 0.05521641671657562
Validation loss: 1.5238991424601565

Epoch: 6| Step: 1
Training loss: 0.07238584011793137
Validation loss: 1.5117836318990236

Epoch: 6| Step: 2
Training loss: 0.11289428919553757
Validation loss: 1.517154694885336

Epoch: 6| Step: 3
Training loss: 0.09096983075141907
Validation loss: 1.5204495383847145

Epoch: 6| Step: 4
Training loss: 0.08355383574962616
Validation loss: 1.5155221826286727

Epoch: 6| Step: 5
Training loss: 0.06643566489219666
Validation loss: 1.5086200083455732

Epoch: 6| Step: 6
Training loss: 0.10675893723964691
Validation loss: 1.533249157731251

Epoch: 6| Step: 7
Training loss: 0.06585942953824997
Validation loss: 1.533687182652053

Epoch: 6| Step: 8
Training loss: 0.06258206814527512
Validation loss: 1.5165108673034176

Epoch: 6| Step: 9
Training loss: 0.07979598641395569
Validation loss: 1.5160982275521884

Epoch: 6| Step: 10
Training loss: 0.04536119103431702
Validation loss: 1.5256873638399187

Epoch: 6| Step: 11
Training loss: 0.09409807622432709
Validation loss: 1.5342775647358229

Epoch: 6| Step: 12
Training loss: 0.09908436238765717
Validation loss: 1.523985715322597

Epoch: 6| Step: 13
Training loss: 0.08493153750896454
Validation loss: 1.5582263469696045

Epoch: 516| Step: 0
Training loss: 0.0997432991862297
Validation loss: 1.5521920957872946

Epoch: 6| Step: 1
Training loss: 0.09437248110771179
Validation loss: 1.5886970104709748

Epoch: 6| Step: 2
Training loss: 0.05968464910984039
Validation loss: 1.5768066144758655

Epoch: 6| Step: 3
Training loss: 0.08584804832935333
Validation loss: 1.5488291427653322

Epoch: 6| Step: 4
Training loss: 0.07571724057197571
Validation loss: 1.5434729040309947

Epoch: 6| Step: 5
Training loss: 0.043471336364746094
Validation loss: 1.5350334746863252

Epoch: 6| Step: 6
Training loss: 0.10649428516626358
Validation loss: 1.527716734076059

Epoch: 6| Step: 7
Training loss: 0.07106854021549225
Validation loss: 1.5055325800372708

Epoch: 6| Step: 8
Training loss: 0.07990146428346634
Validation loss: 1.5186566165698472

Epoch: 6| Step: 9
Training loss: 0.0516471229493618
Validation loss: 1.532107821074865

Epoch: 6| Step: 10
Training loss: 0.05546419322490692
Validation loss: 1.5283768394941926

Epoch: 6| Step: 11
Training loss: 0.11816542595624924
Validation loss: 1.534023234921117

Epoch: 6| Step: 12
Training loss: 0.10330110788345337
Validation loss: 1.5384011973616898

Epoch: 6| Step: 13
Training loss: 0.13266009092330933
Validation loss: 1.512626624876453

Epoch: 517| Step: 0
Training loss: 0.0679759681224823
Validation loss: 1.5094853242238362

Epoch: 6| Step: 1
Training loss: 0.09161503612995148
Validation loss: 1.5201922283377698

Epoch: 6| Step: 2
Training loss: 0.07137449085712433
Validation loss: 1.5125962290712582

Epoch: 6| Step: 3
Training loss: 0.056910671293735504
Validation loss: 1.5311823865418792

Epoch: 6| Step: 4
Training loss: 0.06914475560188293
Validation loss: 1.5414778724793465

Epoch: 6| Step: 5
Training loss: 0.09286558628082275
Validation loss: 1.5711398675877561

Epoch: 6| Step: 6
Training loss: 0.058847762644290924
Validation loss: 1.5214645388305827

Epoch: 6| Step: 7
Training loss: 0.06239616870880127
Validation loss: 1.5371057935940322

Epoch: 6| Step: 8
Training loss: 0.07254770398139954
Validation loss: 1.5122856158082203

Epoch: 6| Step: 9
Training loss: 0.09829984605312347
Validation loss: 1.534423856325047

Epoch: 6| Step: 10
Training loss: 0.08281730115413666
Validation loss: 1.5277929024029804

Epoch: 6| Step: 11
Training loss: 0.1419636309146881
Validation loss: 1.542195588029841

Epoch: 6| Step: 12
Training loss: 0.11125467717647552
Validation loss: 1.5253546545582433

Epoch: 6| Step: 13
Training loss: 0.09567026793956757
Validation loss: 1.5696471045094151

Epoch: 518| Step: 0
Training loss: 0.0484173446893692
Validation loss: 1.526073981356877

Epoch: 6| Step: 1
Training loss: 0.12143750488758087
Validation loss: 1.5341051881031325

Epoch: 6| Step: 2
Training loss: 0.11984635889530182
Validation loss: 1.5378563621992707

Epoch: 6| Step: 3
Training loss: 0.06273872405290604
Validation loss: 1.550756134012694

Epoch: 6| Step: 4
Training loss: 0.08904322236776352
Validation loss: 1.4971509377161663

Epoch: 6| Step: 5
Training loss: 0.11094486713409424
Validation loss: 1.4986485665844334

Epoch: 6| Step: 6
Training loss: 0.08215001225471497
Validation loss: 1.532178218646716

Epoch: 6| Step: 7
Training loss: 0.10714836418628693
Validation loss: 1.547747250526182

Epoch: 6| Step: 8
Training loss: 0.09334705770015717
Validation loss: 1.5289801512995074

Epoch: 6| Step: 9
Training loss: 0.09134538471698761
Validation loss: 1.5203760413713352

Epoch: 6| Step: 10
Training loss: 0.05106120556592941
Validation loss: 1.5356040923826155

Epoch: 6| Step: 11
Training loss: 0.14714011549949646
Validation loss: 1.5165042608014998

Epoch: 6| Step: 12
Training loss: 0.06937313824892044
Validation loss: 1.5133428881245274

Epoch: 6| Step: 13
Training loss: 0.10353562235832214
Validation loss: 1.520062768331138

Epoch: 519| Step: 0
Training loss: 0.08007660508155823
Validation loss: 1.547638302208275

Epoch: 6| Step: 1
Training loss: 0.10503275692462921
Validation loss: 1.5426969733289493

Epoch: 6| Step: 2
Training loss: 0.08314977586269379
Validation loss: 1.5057452609462123

Epoch: 6| Step: 3
Training loss: 0.0758594200015068
Validation loss: 1.5225925336601913

Epoch: 6| Step: 4
Training loss: 0.07284614443778992
Validation loss: 1.5107089563082623

Epoch: 6| Step: 5
Training loss: 0.08671273291110992
Validation loss: 1.5355153211983301

Epoch: 6| Step: 6
Training loss: 0.1575467884540558
Validation loss: 1.5601887638850878

Epoch: 6| Step: 7
Training loss: 0.07996882498264313
Validation loss: 1.5245175669270177

Epoch: 6| Step: 8
Training loss: 0.10410168021917343
Validation loss: 1.5363451075810257

Epoch: 6| Step: 9
Training loss: 0.08942797780036926
Validation loss: 1.5163753301866594

Epoch: 6| Step: 10
Training loss: 0.11347214877605438
Validation loss: 1.5419698299900177

Epoch: 6| Step: 11
Training loss: 0.08791148662567139
Validation loss: 1.5143947434681717

Epoch: 6| Step: 12
Training loss: 0.10422874987125397
Validation loss: 1.5202383277236775

Epoch: 6| Step: 13
Training loss: 0.09172792732715607
Validation loss: 1.5027758100981354

Epoch: 520| Step: 0
Training loss: 0.04101856052875519
Validation loss: 1.5177875641853578

Epoch: 6| Step: 1
Training loss: 0.0988587886095047
Validation loss: 1.5328692736164216

Epoch: 6| Step: 2
Training loss: 0.07550174742937088
Validation loss: 1.5303985841812626

Epoch: 6| Step: 3
Training loss: 0.1027454286813736
Validation loss: 1.5340971523715603

Epoch: 6| Step: 4
Training loss: 0.1195436492562294
Validation loss: 1.5379394754286735

Epoch: 6| Step: 5
Training loss: 0.06993207335472107
Validation loss: 1.538194764044977

Epoch: 6| Step: 6
Training loss: 0.10703735053539276
Validation loss: 1.5481034914652507

Epoch: 6| Step: 7
Training loss: 0.0859295204281807
Validation loss: 1.5462568690699916

Epoch: 6| Step: 8
Training loss: 0.038427408784627914
Validation loss: 1.5407633243068573

Epoch: 6| Step: 9
Training loss: 0.10113639384508133
Validation loss: 1.5306457652840564

Epoch: 6| Step: 10
Training loss: 0.08350365608930588
Validation loss: 1.5403172521181003

Epoch: 6| Step: 11
Training loss: 0.07727053761482239
Validation loss: 1.562634874415654

Epoch: 6| Step: 12
Training loss: 0.14452990889549255
Validation loss: 1.5834803658147012

Epoch: 6| Step: 13
Training loss: 0.13849857449531555
Validation loss: 1.5698260158620856

Epoch: 521| Step: 0
Training loss: 0.08662682771682739
Validation loss: 1.5407856766895582

Epoch: 6| Step: 1
Training loss: 0.09191396087408066
Validation loss: 1.5637872693359212

Epoch: 6| Step: 2
Training loss: 0.07872837036848068
Validation loss: 1.5210834600592171

Epoch: 6| Step: 3
Training loss: 0.08900990337133408
Validation loss: 1.545959206037624

Epoch: 6| Step: 4
Training loss: 0.07856538146734238
Validation loss: 1.5477201220809773

Epoch: 6| Step: 5
Training loss: 0.10062672197818756
Validation loss: 1.5597651902065481

Epoch: 6| Step: 6
Training loss: 0.11513690650463104
Validation loss: 1.5346803908706994

Epoch: 6| Step: 7
Training loss: 0.1184200793504715
Validation loss: 1.5176836649576824

Epoch: 6| Step: 8
Training loss: 0.05832049623131752
Validation loss: 1.5571176095675396

Epoch: 6| Step: 9
Training loss: 0.07365086674690247
Validation loss: 1.5374023106790358

Epoch: 6| Step: 10
Training loss: 0.1263386756181717
Validation loss: 1.5427561472820979

Epoch: 6| Step: 11
Training loss: 0.07621094584465027
Validation loss: 1.569819183759792

Epoch: 6| Step: 12
Training loss: 0.12339012324810028
Validation loss: 1.578223564291513

Epoch: 6| Step: 13
Training loss: 0.07036979496479034
Validation loss: 1.5573728904929212

Epoch: 522| Step: 0
Training loss: 0.07824046909809113
Validation loss: 1.553780258342784

Epoch: 6| Step: 1
Training loss: 0.047823142260313034
Validation loss: 1.561614135260223

Epoch: 6| Step: 2
Training loss: 0.0697176456451416
Validation loss: 1.5444499202953872

Epoch: 6| Step: 3
Training loss: 0.08554080873727798
Validation loss: 1.552881936873159

Epoch: 6| Step: 4
Training loss: 0.17325302958488464
Validation loss: 1.5510507142671974

Epoch: 6| Step: 5
Training loss: 0.10258778929710388
Validation loss: 1.5240525532794256

Epoch: 6| Step: 6
Training loss: 0.08847156912088394
Validation loss: 1.541562145756137

Epoch: 6| Step: 7
Training loss: 0.15446195006370544
Validation loss: 1.531298298989573

Epoch: 6| Step: 8
Training loss: 0.10518831759691238
Validation loss: 1.5531678558677755

Epoch: 6| Step: 9
Training loss: 0.08960111439228058
Validation loss: 1.5442583996762511

Epoch: 6| Step: 10
Training loss: 0.10527008026838303
Validation loss: 1.5544579631538802

Epoch: 6| Step: 11
Training loss: 0.1102953627705574
Validation loss: 1.5311865652761152

Epoch: 6| Step: 12
Training loss: 0.16106750071048737
Validation loss: 1.5434570158681562

Epoch: 6| Step: 13
Training loss: 0.11190570890903473
Validation loss: 1.5136078480751283

Epoch: 523| Step: 0
Training loss: 0.06486398726701736
Validation loss: 1.5355984408368346

Epoch: 6| Step: 1
Training loss: 0.11968070268630981
Validation loss: 1.5291302293859503

Epoch: 6| Step: 2
Training loss: 0.08220311999320984
Validation loss: 1.5215963061137865

Epoch: 6| Step: 3
Training loss: 0.05824340134859085
Validation loss: 1.5546053840268044

Epoch: 6| Step: 4
Training loss: 0.11408507823944092
Validation loss: 1.5412057292076848

Epoch: 6| Step: 5
Training loss: 0.0826825499534607
Validation loss: 1.5494895609476234

Epoch: 6| Step: 6
Training loss: 0.09773729741573334
Validation loss: 1.532257741497409

Epoch: 6| Step: 7
Training loss: 0.10001276433467865
Validation loss: 1.5346121070205525

Epoch: 6| Step: 8
Training loss: 0.057301003485918045
Validation loss: 1.5251873321430658

Epoch: 6| Step: 9
Training loss: 0.07095321267843246
Validation loss: 1.5181286052990985

Epoch: 6| Step: 10
Training loss: 0.07391134649515152
Validation loss: 1.5205984192509805

Epoch: 6| Step: 11
Training loss: 0.061022691428661346
Validation loss: 1.509028661635614

Epoch: 6| Step: 12
Training loss: 0.11192011833190918
Validation loss: 1.5337594503997474

Epoch: 6| Step: 13
Training loss: 0.0667177140712738
Validation loss: 1.4957264597697923

Epoch: 524| Step: 0
Training loss: 0.11629074811935425
Validation loss: 1.5306905841314664

Epoch: 6| Step: 1
Training loss: 0.0795380175113678
Validation loss: 1.5204161931109685

Epoch: 6| Step: 2
Training loss: 0.18779566884040833
Validation loss: 1.4943158011282645

Epoch: 6| Step: 3
Training loss: 0.10899129509925842
Validation loss: 1.489491492830297

Epoch: 6| Step: 4
Training loss: 0.08350598812103271
Validation loss: 1.502651946519011

Epoch: 6| Step: 5
Training loss: 0.05356626957654953
Validation loss: 1.485934301089215

Epoch: 6| Step: 6
Training loss: 0.08591553568840027
Validation loss: 1.536919314374206

Epoch: 6| Step: 7
Training loss: 0.0765981525182724
Validation loss: 1.519481276953092

Epoch: 6| Step: 8
Training loss: 0.19581519067287445
Validation loss: 1.534045966722632

Epoch: 6| Step: 9
Training loss: 0.07147502154111862
Validation loss: 1.5268409136802918

Epoch: 6| Step: 10
Training loss: 0.10270816087722778
Validation loss: 1.503572783162517

Epoch: 6| Step: 11
Training loss: 0.07394503802061081
Validation loss: 1.4848933117364043

Epoch: 6| Step: 12
Training loss: 0.12165412306785583
Validation loss: 1.5110256415541454

Epoch: 6| Step: 13
Training loss: 0.08322086930274963
Validation loss: 1.5314385134686705

Epoch: 525| Step: 0
Training loss: 0.10772895812988281
Validation loss: 1.5307527806169243

Epoch: 6| Step: 1
Training loss: 0.05292884260416031
Validation loss: 1.5226461836086806

Epoch: 6| Step: 2
Training loss: 0.10041098296642303
Validation loss: 1.524768760127406

Epoch: 6| Step: 3
Training loss: 0.08930866420269012
Validation loss: 1.4978987645077448

Epoch: 6| Step: 4
Training loss: 0.06901422142982483
Validation loss: 1.5280431996109665

Epoch: 6| Step: 5
Training loss: 0.05805252492427826
Validation loss: 1.5195981482023835

Epoch: 6| Step: 6
Training loss: 0.11625993251800537
Validation loss: 1.507345643094791

Epoch: 6| Step: 7
Training loss: 0.15452592074871063
Validation loss: 1.5339900293657858

Epoch: 6| Step: 8
Training loss: 0.09723970293998718
Validation loss: 1.5182237035484725

Epoch: 6| Step: 9
Training loss: 0.0284634567797184
Validation loss: 1.5047876924596808

Epoch: 6| Step: 10
Training loss: 0.03682124242186546
Validation loss: 1.5180542289569814

Epoch: 6| Step: 11
Training loss: 0.08780889958143234
Validation loss: 1.4885207747900358

Epoch: 6| Step: 12
Training loss: 0.09615758061408997
Validation loss: 1.5328383279103104

Epoch: 6| Step: 13
Training loss: 0.06256518512964249
Validation loss: 1.5223949058081514

Epoch: 526| Step: 0
Training loss: 0.09941354393959045
Validation loss: 1.4979738009873258

Epoch: 6| Step: 1
Training loss: 0.055800911039114
Validation loss: 1.521502798603427

Epoch: 6| Step: 2
Training loss: 0.06045404076576233
Validation loss: 1.5210834357046312

Epoch: 6| Step: 3
Training loss: 0.0457238033413887
Validation loss: 1.5182553632285005

Epoch: 6| Step: 4
Training loss: 0.04793636128306389
Validation loss: 1.5208715392697243

Epoch: 6| Step: 5
Training loss: 0.0633806511759758
Validation loss: 1.517662553377049

Epoch: 6| Step: 6
Training loss: 0.05880041420459747
Validation loss: 1.521014077689058

Epoch: 6| Step: 7
Training loss: 0.0770721435546875
Validation loss: 1.5111341489258634

Epoch: 6| Step: 8
Training loss: 0.09646350890398026
Validation loss: 1.5179356157138784

Epoch: 6| Step: 9
Training loss: 0.060265474021434784
Validation loss: 1.4927663264736053

Epoch: 6| Step: 10
Training loss: 0.06974773854017258
Validation loss: 1.5061881952388312

Epoch: 6| Step: 11
Training loss: 0.1464591771364212
Validation loss: 1.5003933816827753

Epoch: 6| Step: 12
Training loss: 0.03796596825122833
Validation loss: 1.526252967055126

Epoch: 6| Step: 13
Training loss: 0.08641678094863892
Validation loss: 1.4982956327417845

Epoch: 527| Step: 0
Training loss: 0.05410027131438255
Validation loss: 1.5001052182207826

Epoch: 6| Step: 1
Training loss: 0.07081104815006256
Validation loss: 1.484870110788653

Epoch: 6| Step: 2
Training loss: 0.06739427149295807
Validation loss: 1.4920233834174372

Epoch: 6| Step: 3
Training loss: 0.09884755313396454
Validation loss: 1.4910844102982552

Epoch: 6| Step: 4
Training loss: 0.11241725832223892
Validation loss: 1.5030147644781298

Epoch: 6| Step: 5
Training loss: 0.07026500254869461
Validation loss: 1.5085250844237625

Epoch: 6| Step: 6
Training loss: 0.0929810106754303
Validation loss: 1.4931236556781236

Epoch: 6| Step: 7
Training loss: 0.06454296410083771
Validation loss: 1.5213181908412645

Epoch: 6| Step: 8
Training loss: 0.09208014607429504
Validation loss: 1.5069808370323592

Epoch: 6| Step: 9
Training loss: 0.08434372395277023
Validation loss: 1.4952401243230349

Epoch: 6| Step: 10
Training loss: 0.06824545562267303
Validation loss: 1.5118044435337026

Epoch: 6| Step: 11
Training loss: 0.09982263296842575
Validation loss: 1.5567122761921217

Epoch: 6| Step: 12
Training loss: 0.05882306769490242
Validation loss: 1.5295500947583107

Epoch: 6| Step: 13
Training loss: 0.0660853236913681
Validation loss: 1.538163706179588

Epoch: 528| Step: 0
Training loss: 0.05221386253833771
Validation loss: 1.528495959056321

Epoch: 6| Step: 1
Training loss: 0.03991351276636124
Validation loss: 1.529172791588691

Epoch: 6| Step: 2
Training loss: 0.038005128502845764
Validation loss: 1.5742522772922312

Epoch: 6| Step: 3
Training loss: 0.059443630278110504
Validation loss: 1.5357160734873947

Epoch: 6| Step: 4
Training loss: 0.12763966619968414
Validation loss: 1.5514631348271524

Epoch: 6| Step: 5
Training loss: 0.04714660346508026
Validation loss: 1.5412972434874503

Epoch: 6| Step: 6
Training loss: 0.064220130443573
Validation loss: 1.5544279442038587

Epoch: 6| Step: 7
Training loss: 0.11682545393705368
Validation loss: 1.5327731729835592

Epoch: 6| Step: 8
Training loss: 0.06304191052913666
Validation loss: 1.5471210428463515

Epoch: 6| Step: 9
Training loss: 0.07662101835012436
Validation loss: 1.5305813179221204

Epoch: 6| Step: 10
Training loss: 0.06378425657749176
Validation loss: 1.5347169394134192

Epoch: 6| Step: 11
Training loss: 0.061001017689704895
Validation loss: 1.5435776069600096

Epoch: 6| Step: 12
Training loss: 0.10511881113052368
Validation loss: 1.5235183713256673

Epoch: 6| Step: 13
Training loss: 0.0821918249130249
Validation loss: 1.5167930562009093

Epoch: 529| Step: 0
Training loss: 0.07596886903047562
Validation loss: 1.5232565761894308

Epoch: 6| Step: 1
Training loss: 0.06615714728832245
Validation loss: 1.5076739326600106

Epoch: 6| Step: 2
Training loss: 0.06532932817935944
Validation loss: 1.5123852388833159

Epoch: 6| Step: 3
Training loss: 0.05438980460166931
Validation loss: 1.5034030624615249

Epoch: 6| Step: 4
Training loss: 0.060499407351017
Validation loss: 1.5171453183697117

Epoch: 6| Step: 5
Training loss: 0.07320360839366913
Validation loss: 1.497072595421986

Epoch: 6| Step: 6
Training loss: 0.1095416247844696
Validation loss: 1.504036138134618

Epoch: 6| Step: 7
Training loss: 0.07150618731975555
Validation loss: 1.4930139985135806

Epoch: 6| Step: 8
Training loss: 0.07089239358901978
Validation loss: 1.4651237162210609

Epoch: 6| Step: 9
Training loss: 0.08676499128341675
Validation loss: 1.5029778826621272

Epoch: 6| Step: 10
Training loss: 0.09618255496025085
Validation loss: 1.4932843318549536

Epoch: 6| Step: 11
Training loss: 0.08880896866321564
Validation loss: 1.4794651090457875

Epoch: 6| Step: 12
Training loss: 0.10291802138090134
Validation loss: 1.4836261016066357

Epoch: 6| Step: 13
Training loss: 0.08205512166023254
Validation loss: 1.489861484496824

Epoch: 530| Step: 0
Training loss: 0.10227163136005402
Validation loss: 1.496993378926349

Epoch: 6| Step: 1
Training loss: 0.0969182476401329
Validation loss: 1.5291412466315812

Epoch: 6| Step: 2
Training loss: 0.07487555593252182
Validation loss: 1.5404417886528918

Epoch: 6| Step: 3
Training loss: 0.06815248727798462
Validation loss: 1.5276028379317252

Epoch: 6| Step: 4
Training loss: 0.05072270333766937
Validation loss: 1.5046363133256153

Epoch: 6| Step: 5
Training loss: 0.06311971694231033
Validation loss: 1.513739772060866

Epoch: 6| Step: 6
Training loss: 0.05994609370827675
Validation loss: 1.5006424509068972

Epoch: 6| Step: 7
Training loss: 0.058440931141376495
Validation loss: 1.4853674186173307

Epoch: 6| Step: 8
Training loss: 0.05070636048913002
Validation loss: 1.5060735159022833

Epoch: 6| Step: 9
Training loss: 0.06670062243938446
Validation loss: 1.5031263046367194

Epoch: 6| Step: 10
Training loss: 0.06406165659427643
Validation loss: 1.483632085143879

Epoch: 6| Step: 11
Training loss: 0.06500943005084991
Validation loss: 1.473086384034926

Epoch: 6| Step: 12
Training loss: 0.07366038113832474
Validation loss: 1.5066025609611182

Epoch: 6| Step: 13
Training loss: 0.09720860421657562
Validation loss: 1.4742261966069539

Epoch: 531| Step: 0
Training loss: 0.08232531696557999
Validation loss: 1.4794248201513802

Epoch: 6| Step: 1
Training loss: 0.1513093113899231
Validation loss: 1.4788709930194321

Epoch: 6| Step: 2
Training loss: 0.06436262279748917
Validation loss: 1.4883240666440738

Epoch: 6| Step: 3
Training loss: 0.07323222607374191
Validation loss: 1.4882873476192515

Epoch: 6| Step: 4
Training loss: 0.09372507035732269
Validation loss: 1.4941652013409523

Epoch: 6| Step: 5
Training loss: 0.09589588642120361
Validation loss: 1.5107406634156422

Epoch: 6| Step: 6
Training loss: 0.10237948596477509
Validation loss: 1.5092368773234788

Epoch: 6| Step: 7
Training loss: 0.06472097337245941
Validation loss: 1.4895529144553727

Epoch: 6| Step: 8
Training loss: 0.03836521506309509
Validation loss: 1.5134270306556457

Epoch: 6| Step: 9
Training loss: 0.09451093524694443
Validation loss: 1.5124213695526123

Epoch: 6| Step: 10
Training loss: 0.06117241829633713
Validation loss: 1.5145976799790577

Epoch: 6| Step: 11
Training loss: 0.07810626178979874
Validation loss: 1.5150290330251057

Epoch: 6| Step: 12
Training loss: 0.05614417791366577
Validation loss: 1.527297632668608

Epoch: 6| Step: 13
Training loss: 0.05457146093249321
Validation loss: 1.5379266142845154

Epoch: 532| Step: 0
Training loss: 0.12401843070983887
Validation loss: 1.532078246916494

Epoch: 6| Step: 1
Training loss: 0.05998465418815613
Validation loss: 1.5360891678000008

Epoch: 6| Step: 2
Training loss: 0.07022388279438019
Validation loss: 1.505222019328866

Epoch: 6| Step: 3
Training loss: 0.10131356120109558
Validation loss: 1.5418349158379339

Epoch: 6| Step: 4
Training loss: 0.0958978608250618
Validation loss: 1.5435396400831078

Epoch: 6| Step: 5
Training loss: 0.09928382933139801
Validation loss: 1.5605231420968169

Epoch: 6| Step: 6
Training loss: 0.1042662113904953
Validation loss: 1.5555941289471042

Epoch: 6| Step: 7
Training loss: 0.0641193762421608
Validation loss: 1.5393720531976351

Epoch: 6| Step: 8
Training loss: 0.09419918060302734
Validation loss: 1.5136934967451199

Epoch: 6| Step: 9
Training loss: 0.03812340646982193
Validation loss: 1.5181173137439194

Epoch: 6| Step: 10
Training loss: 0.06164473295211792
Validation loss: 1.5273629055228284

Epoch: 6| Step: 11
Training loss: 0.053936928510665894
Validation loss: 1.533404670735841

Epoch: 6| Step: 12
Training loss: 0.061776816844940186
Validation loss: 1.523330464798917

Epoch: 6| Step: 13
Training loss: 0.06922318041324615
Validation loss: 1.5636193701016006

Epoch: 533| Step: 0
Training loss: 0.13355007767677307
Validation loss: 1.5137347380320232

Epoch: 6| Step: 1
Training loss: 0.12002136558294296
Validation loss: 1.5302525143469534

Epoch: 6| Step: 2
Training loss: 0.12673625349998474
Validation loss: 1.5020134167004657

Epoch: 6| Step: 3
Training loss: 0.03411266952753067
Validation loss: 1.5340935286655222

Epoch: 6| Step: 4
Training loss: 0.05525616183876991
Validation loss: 1.5241970323747205

Epoch: 6| Step: 5
Training loss: 0.08338234573602676
Validation loss: 1.5678488080219557

Epoch: 6| Step: 6
Training loss: 0.07687561959028244
Validation loss: 1.5420163882675992

Epoch: 6| Step: 7
Training loss: 0.04414670914411545
Validation loss: 1.5157706865700342

Epoch: 6| Step: 8
Training loss: 0.0678483173251152
Validation loss: 1.5356908972545336

Epoch: 6| Step: 9
Training loss: 0.06493738293647766
Validation loss: 1.5508927811858475

Epoch: 6| Step: 10
Training loss: 0.048908330500125885
Validation loss: 1.5536817530150056

Epoch: 6| Step: 11
Training loss: 0.05751542001962662
Validation loss: 1.5302625407454788

Epoch: 6| Step: 12
Training loss: 0.06669612973928452
Validation loss: 1.5440240393402755

Epoch: 6| Step: 13
Training loss: 0.15199211239814758
Validation loss: 1.5501725673675537

Epoch: 534| Step: 0
Training loss: 0.05624841898679733
Validation loss: 1.5314119092879757

Epoch: 6| Step: 1
Training loss: 0.10113087296485901
Validation loss: 1.511962624006374

Epoch: 6| Step: 2
Training loss: 0.07861292362213135
Validation loss: 1.5282545551176994

Epoch: 6| Step: 3
Training loss: 0.07747038453817368
Validation loss: 1.507373047131364

Epoch: 6| Step: 4
Training loss: 0.06050214171409607
Validation loss: 1.504127981842205

Epoch: 6| Step: 5
Training loss: 0.0944848507642746
Validation loss: 1.5012228661967861

Epoch: 6| Step: 6
Training loss: 0.1095009446144104
Validation loss: 1.5427779548911638

Epoch: 6| Step: 7
Training loss: 0.11567655950784683
Validation loss: 1.504923241112822

Epoch: 6| Step: 8
Training loss: 0.05765749514102936
Validation loss: 1.5374360187079317

Epoch: 6| Step: 9
Training loss: 0.0661330372095108
Validation loss: 1.5350393185051538

Epoch: 6| Step: 10
Training loss: 0.05549093335866928
Validation loss: 1.5499262553389355

Epoch: 6| Step: 11
Training loss: 0.10318039357662201
Validation loss: 1.5250021514072214

Epoch: 6| Step: 12
Training loss: 0.09290407598018646
Validation loss: 1.5385642897698186

Epoch: 6| Step: 13
Training loss: 0.14553219079971313
Validation loss: 1.5254169523075063

Epoch: 535| Step: 0
Training loss: 0.07036539912223816
Validation loss: 1.5318948850836804

Epoch: 6| Step: 1
Training loss: 0.08070497214794159
Validation loss: 1.5504013851124754

Epoch: 6| Step: 2
Training loss: 0.08986266702413559
Validation loss: 1.540292577717894

Epoch: 6| Step: 3
Training loss: 0.0719572901725769
Validation loss: 1.516737707199589

Epoch: 6| Step: 4
Training loss: 0.041070833802223206
Validation loss: 1.51698136842379

Epoch: 6| Step: 5
Training loss: 0.05085710808634758
Validation loss: 1.540954048915576

Epoch: 6| Step: 6
Training loss: 0.055651165544986725
Validation loss: 1.52238546007423

Epoch: 6| Step: 7
Training loss: 0.09037349373102188
Validation loss: 1.554021018807606

Epoch: 6| Step: 8
Training loss: 0.03319990634918213
Validation loss: 1.535329061169778

Epoch: 6| Step: 9
Training loss: 0.10165780782699585
Validation loss: 1.5155817513824792

Epoch: 6| Step: 10
Training loss: 0.05025796219706535
Validation loss: 1.528232701363102

Epoch: 6| Step: 11
Training loss: 0.08245979249477386
Validation loss: 1.516281206120727

Epoch: 6| Step: 12
Training loss: 0.0704892948269844
Validation loss: 1.5362560800326768

Epoch: 6| Step: 13
Training loss: 0.06242977827787399
Validation loss: 1.5559411459071661

Epoch: 536| Step: 0
Training loss: 0.05153209716081619
Validation loss: 1.5346192723961287

Epoch: 6| Step: 1
Training loss: 0.059195734560489655
Validation loss: 1.505275866036774

Epoch: 6| Step: 2
Training loss: 0.06549136340618134
Validation loss: 1.5220912618021811

Epoch: 6| Step: 3
Training loss: 0.06233752891421318
Validation loss: 1.4998411978444746

Epoch: 6| Step: 4
Training loss: 0.04454851150512695
Validation loss: 1.5100403543441527

Epoch: 6| Step: 5
Training loss: 0.06493286788463593
Validation loss: 1.5321625278842064

Epoch: 6| Step: 6
Training loss: 0.08092416822910309
Validation loss: 1.5282776740289503

Epoch: 6| Step: 7
Training loss: 0.06269523501396179
Validation loss: 1.5099674117180608

Epoch: 6| Step: 8
Training loss: 0.12772293388843536
Validation loss: 1.5163722935543265

Epoch: 6| Step: 9
Training loss: 0.06415100395679474
Validation loss: 1.5283249385895268

Epoch: 6| Step: 10
Training loss: 0.08211393654346466
Validation loss: 1.5229679089720531

Epoch: 6| Step: 11
Training loss: 0.070902019739151
Validation loss: 1.5312133271207091

Epoch: 6| Step: 12
Training loss: 0.045830048620700836
Validation loss: 1.5314803982293734

Epoch: 6| Step: 13
Training loss: 0.10555461794137955
Validation loss: 1.5175167693886706

Epoch: 537| Step: 0
Training loss: 0.07804936170578003
Validation loss: 1.526607446773078

Epoch: 6| Step: 1
Training loss: 0.024927450343966484
Validation loss: 1.5251185894012451

Epoch: 6| Step: 2
Training loss: 0.06022089719772339
Validation loss: 1.525210540781739

Epoch: 6| Step: 3
Training loss: 0.05305027216672897
Validation loss: 1.541300094255837

Epoch: 6| Step: 4
Training loss: 0.07765442878007889
Validation loss: 1.5394536192699144

Epoch: 6| Step: 5
Training loss: 0.05902745574712753
Validation loss: 1.537958486105806

Epoch: 6| Step: 6
Training loss: 0.08282724767923355
Validation loss: 1.5126304485464608

Epoch: 6| Step: 7
Training loss: 0.07589800655841827
Validation loss: 1.512686429485198

Epoch: 6| Step: 8
Training loss: 0.06540398299694061
Validation loss: 1.524570958588713

Epoch: 6| Step: 9
Training loss: 0.08542081713676453
Validation loss: 1.5457399904087026

Epoch: 6| Step: 10
Training loss: 0.05747581273317337
Validation loss: 1.5313799355619697

Epoch: 6| Step: 11
Training loss: 0.09351062774658203
Validation loss: 1.5274316713374148

Epoch: 6| Step: 12
Training loss: 0.07066238671541214
Validation loss: 1.504291574160258

Epoch: 6| Step: 13
Training loss: 0.06705762445926666
Validation loss: 1.525769957932093

Epoch: 538| Step: 0
Training loss: 0.0363096222281456
Validation loss: 1.5103468215593727

Epoch: 6| Step: 1
Training loss: 0.07534264028072357
Validation loss: 1.523561039278584

Epoch: 6| Step: 2
Training loss: 0.05394069477915764
Validation loss: 1.5242330310165242

Epoch: 6| Step: 3
Training loss: 0.09684114158153534
Validation loss: 1.5347937294231948

Epoch: 6| Step: 4
Training loss: 0.060165125876665115
Validation loss: 1.5243953376687982

Epoch: 6| Step: 5
Training loss: 0.07238496840000153
Validation loss: 1.5221613017461633

Epoch: 6| Step: 6
Training loss: 0.07975488156080246
Validation loss: 1.5243091967798048

Epoch: 6| Step: 7
Training loss: 0.051763325929641724
Validation loss: 1.5128395973995168

Epoch: 6| Step: 8
Training loss: 0.06367909908294678
Validation loss: 1.512616616423412

Epoch: 6| Step: 9
Training loss: 0.07529769837856293
Validation loss: 1.4908034596391904

Epoch: 6| Step: 10
Training loss: 0.048879869282245636
Validation loss: 1.5248090528672742

Epoch: 6| Step: 11
Training loss: 0.06750807166099548
Validation loss: 1.4988661081560197

Epoch: 6| Step: 12
Training loss: 0.06142711639404297
Validation loss: 1.515325500119117

Epoch: 6| Step: 13
Training loss: 0.06312213838100433
Validation loss: 1.5331654728099864

Epoch: 539| Step: 0
Training loss: 0.08150915801525116
Validation loss: 1.5201393724769674

Epoch: 6| Step: 1
Training loss: 0.0961216390132904
Validation loss: 1.5123509271170503

Epoch: 6| Step: 2
Training loss: 0.08654837310314178
Validation loss: 1.5155212007543093

Epoch: 6| Step: 3
Training loss: 0.11027082800865173
Validation loss: 1.511389132468931

Epoch: 6| Step: 4
Training loss: 0.10246511548757553
Validation loss: 1.4998023266433387

Epoch: 6| Step: 5
Training loss: 0.08899608254432678
Validation loss: 1.5039576791947888

Epoch: 6| Step: 6
Training loss: 0.06931480765342712
Validation loss: 1.4906783616670998

Epoch: 6| Step: 7
Training loss: 0.08434717357158661
Validation loss: 1.4909389224103702

Epoch: 6| Step: 8
Training loss: 0.040962304919958115
Validation loss: 1.4804666144873506

Epoch: 6| Step: 9
Training loss: 0.07242153584957123
Validation loss: 1.513603392467704

Epoch: 6| Step: 10
Training loss: 0.120064377784729
Validation loss: 1.5050568465263612

Epoch: 6| Step: 11
Training loss: 0.11940154433250427
Validation loss: 1.5320490393587338

Epoch: 6| Step: 12
Training loss: 0.0711432695388794
Validation loss: 1.5296883685614473

Epoch: 6| Step: 13
Training loss: 0.074348583817482
Validation loss: 1.5179806575980237

Epoch: 540| Step: 0
Training loss: 0.07700208574533463
Validation loss: 1.5313460858919288

Epoch: 6| Step: 1
Training loss: 0.07652777433395386
Validation loss: 1.5167690220699515

Epoch: 6| Step: 2
Training loss: 0.07061949372291565
Validation loss: 1.485608789869534

Epoch: 6| Step: 3
Training loss: 0.07644931226968765
Validation loss: 1.5155713272992002

Epoch: 6| Step: 4
Training loss: 0.07456248253583908
Validation loss: 1.5107559709138767

Epoch: 6| Step: 5
Training loss: 0.11648363620042801
Validation loss: 1.5716253583149244

Epoch: 6| Step: 6
Training loss: 0.07509823888540268
Validation loss: 1.5630153058677592

Epoch: 6| Step: 7
Training loss: 0.09877587854862213
Validation loss: 1.5346819008550336

Epoch: 6| Step: 8
Training loss: 0.0943361222743988
Validation loss: 1.5487254050470167

Epoch: 6| Step: 9
Training loss: 0.07878317683935165
Validation loss: 1.5474140406936727

Epoch: 6| Step: 10
Training loss: 0.07346179336309433
Validation loss: 1.5500833206279303

Epoch: 6| Step: 11
Training loss: 0.056308627128601074
Validation loss: 1.5472949781725485

Epoch: 6| Step: 12
Training loss: 0.0592380166053772
Validation loss: 1.5645804700031076

Epoch: 6| Step: 13
Training loss: 0.039075665175914764
Validation loss: 1.536605058177825

Epoch: 541| Step: 0
Training loss: 0.062281228601932526
Validation loss: 1.5563734116092804

Epoch: 6| Step: 1
Training loss: 0.04891839623451233
Validation loss: 1.5491337673638457

Epoch: 6| Step: 2
Training loss: 0.0360349640250206
Validation loss: 1.5458754326707573

Epoch: 6| Step: 3
Training loss: 0.06456992030143738
Validation loss: 1.5280390965041293

Epoch: 6| Step: 4
Training loss: 0.0905924066901207
Validation loss: 1.5488581195954354

Epoch: 6| Step: 5
Training loss: 0.041198864579200745
Validation loss: 1.5205462594186105

Epoch: 6| Step: 6
Training loss: 0.04892722889780998
Validation loss: 1.5584208619210027

Epoch: 6| Step: 7
Training loss: 0.17038840055465698
Validation loss: 1.5196756175769273

Epoch: 6| Step: 8
Training loss: 0.07634686678647995
Validation loss: 1.545710152195346

Epoch: 6| Step: 9
Training loss: 0.11257757246494293
Validation loss: 1.5226072572892713

Epoch: 6| Step: 10
Training loss: 0.12852612137794495
Validation loss: 1.5500410372211086

Epoch: 6| Step: 11
Training loss: 0.08776939660310745
Validation loss: 1.530414419789468

Epoch: 6| Step: 12
Training loss: 0.0727640837430954
Validation loss: 1.5254694043949086

Epoch: 6| Step: 13
Training loss: 0.07378314435482025
Validation loss: 1.5155257589073592

Epoch: 542| Step: 0
Training loss: 0.07273980975151062
Validation loss: 1.5221588739784815

Epoch: 6| Step: 1
Training loss: 0.07711102068424225
Validation loss: 1.5100126356206915

Epoch: 6| Step: 2
Training loss: 0.08119673281908035
Validation loss: 1.5315051386433263

Epoch: 6| Step: 3
Training loss: 0.08761079609394073
Validation loss: 1.5039449737917991

Epoch: 6| Step: 4
Training loss: 0.06708460301160812
Validation loss: 1.535165463724444

Epoch: 6| Step: 5
Training loss: 0.07268963009119034
Validation loss: 1.518275458325622

Epoch: 6| Step: 6
Training loss: 0.07921428233385086
Validation loss: 1.508954219920661

Epoch: 6| Step: 7
Training loss: 0.09825052320957184
Validation loss: 1.5352502010201896

Epoch: 6| Step: 8
Training loss: 0.05536561459302902
Validation loss: 1.5485272022985643

Epoch: 6| Step: 9
Training loss: 0.05646558851003647
Validation loss: 1.5324680395023798

Epoch: 6| Step: 10
Training loss: 0.09560990333557129
Validation loss: 1.539812317458532

Epoch: 6| Step: 11
Training loss: 0.1345513015985489
Validation loss: 1.560830327772325

Epoch: 6| Step: 12
Training loss: 0.06610371917486191
Validation loss: 1.526180516007126

Epoch: 6| Step: 13
Training loss: 0.05923660099506378
Validation loss: 1.5356586607553626

Epoch: 543| Step: 0
Training loss: 0.08575201034545898
Validation loss: 1.530576221404537

Epoch: 6| Step: 1
Training loss: 0.08276249468326569
Validation loss: 1.5393303312281126

Epoch: 6| Step: 2
Training loss: 0.09453803300857544
Validation loss: 1.5296623040271062

Epoch: 6| Step: 3
Training loss: 0.11612750589847565
Validation loss: 1.577016717644148

Epoch: 6| Step: 4
Training loss: 0.06593141704797745
Validation loss: 1.5301704188828826

Epoch: 6| Step: 5
Training loss: 0.1066037192940712
Validation loss: 1.5353687834996048

Epoch: 6| Step: 6
Training loss: 0.07174277305603027
Validation loss: 1.532877004274758

Epoch: 6| Step: 7
Training loss: 0.06434614956378937
Validation loss: 1.542964058537637

Epoch: 6| Step: 8
Training loss: 0.08848027884960175
Validation loss: 1.535534087047782

Epoch: 6| Step: 9
Training loss: 0.04477856308221817
Validation loss: 1.5263759038781608

Epoch: 6| Step: 10
Training loss: 0.06118706613779068
Validation loss: 1.5460982450874903

Epoch: 6| Step: 11
Training loss: 0.10967375338077545
Validation loss: 1.559893613220543

Epoch: 6| Step: 12
Training loss: 0.04076571762561798
Validation loss: 1.5516126694217804

Epoch: 6| Step: 13
Training loss: 0.09856115281581879
Validation loss: 1.5366624439916303

Epoch: 544| Step: 0
Training loss: 0.11209064722061157
Validation loss: 1.5491397650011125

Epoch: 6| Step: 1
Training loss: 0.09931769967079163
Validation loss: 1.534241816048981

Epoch: 6| Step: 2
Training loss: 0.1026758998632431
Validation loss: 1.518551564985706

Epoch: 6| Step: 3
Training loss: 0.12391343712806702
Validation loss: 1.5443986679918023

Epoch: 6| Step: 4
Training loss: 0.075269415974617
Validation loss: 1.5322222530200917

Epoch: 6| Step: 5
Training loss: 0.07823223620653152
Validation loss: 1.5320819513772124

Epoch: 6| Step: 6
Training loss: 0.15063828229904175
Validation loss: 1.5325730923683412

Epoch: 6| Step: 7
Training loss: 0.06117601320147514
Validation loss: 1.5277479771644837

Epoch: 6| Step: 8
Training loss: 0.06373152881860733
Validation loss: 1.539595280924151

Epoch: 6| Step: 9
Training loss: 0.04558960720896721
Validation loss: 1.5330191299479494

Epoch: 6| Step: 10
Training loss: 0.06164614111185074
Validation loss: 1.5164496770469091

Epoch: 6| Step: 11
Training loss: 0.08026086539030075
Validation loss: 1.5031631361412745

Epoch: 6| Step: 12
Training loss: 0.06437830626964569
Validation loss: 1.5085886652751634

Epoch: 6| Step: 13
Training loss: 0.05290670320391655
Validation loss: 1.4935360390652892

Epoch: 545| Step: 0
Training loss: 0.06378047168254852
Validation loss: 1.5007596554294709

Epoch: 6| Step: 1
Training loss: 0.07018464803695679
Validation loss: 1.504504415296739

Epoch: 6| Step: 2
Training loss: 0.08875472843647003
Validation loss: 1.4876937058664137

Epoch: 6| Step: 3
Training loss: 0.08071982115507126
Validation loss: 1.5135433635404032

Epoch: 6| Step: 4
Training loss: 0.07268933206796646
Validation loss: 1.5175163566425283

Epoch: 6| Step: 5
Training loss: 0.08488886803388596
Validation loss: 1.5402689249284807

Epoch: 6| Step: 6
Training loss: 0.08838361501693726
Validation loss: 1.5396873797139814

Epoch: 6| Step: 7
Training loss: 0.10023709386587143
Validation loss: 1.524581386196998

Epoch: 6| Step: 8
Training loss: 0.053790971636772156
Validation loss: 1.5291561747110018

Epoch: 6| Step: 9
Training loss: 0.08691093325614929
Validation loss: 1.536671635925129

Epoch: 6| Step: 10
Training loss: 0.05490745231509209
Validation loss: 1.5271170869950326

Epoch: 6| Step: 11
Training loss: 0.045791320502758026
Validation loss: 1.5241853383279615

Epoch: 6| Step: 12
Training loss: 0.05960875004529953
Validation loss: 1.521826640252144

Epoch: 6| Step: 13
Training loss: 0.09022316336631775
Validation loss: 1.5255386957558252

Epoch: 546| Step: 0
Training loss: 0.09009497612714767
Validation loss: 1.5434312448706677

Epoch: 6| Step: 1
Training loss: 0.1537080705165863
Validation loss: 1.5276792126317178

Epoch: 6| Step: 2
Training loss: 0.08607320487499237
Validation loss: 1.5367981900451004

Epoch: 6| Step: 3
Training loss: 0.04416748136281967
Validation loss: 1.5389133025241155

Epoch: 6| Step: 4
Training loss: 0.11309251189231873
Validation loss: 1.5249477842802643

Epoch: 6| Step: 5
Training loss: 0.08293713629245758
Validation loss: 1.549317136887581

Epoch: 6| Step: 6
Training loss: 0.07957122474908829
Validation loss: 1.5654220798964142

Epoch: 6| Step: 7
Training loss: 0.08127745985984802
Validation loss: 1.5330988719899168

Epoch: 6| Step: 8
Training loss: 0.09497985243797302
Validation loss: 1.5375671976356096

Epoch: 6| Step: 9
Training loss: 0.0892864242196083
Validation loss: 1.5316489973375875

Epoch: 6| Step: 10
Training loss: 0.0638321191072464
Validation loss: 1.5151533311413181

Epoch: 6| Step: 11
Training loss: 0.07396754622459412
Validation loss: 1.4863017964106735

Epoch: 6| Step: 12
Training loss: 0.10207334905862808
Validation loss: 1.49802609925629

Epoch: 6| Step: 13
Training loss: 0.0850294679403305
Validation loss: 1.54390396354019

Epoch: 547| Step: 0
Training loss: 0.13766472041606903
Validation loss: 1.529634407771531

Epoch: 6| Step: 1
Training loss: 0.10758773982524872
Validation loss: 1.5103325843811035

Epoch: 6| Step: 2
Training loss: 0.16067005693912506
Validation loss: 1.5027829882919148

Epoch: 6| Step: 3
Training loss: 0.0675627738237381
Validation loss: 1.4775812561793993

Epoch: 6| Step: 4
Training loss: 0.0682600811123848
Validation loss: 1.51608782686213

Epoch: 6| Step: 5
Training loss: 0.0825478732585907
Validation loss: 1.533886953066754

Epoch: 6| Step: 6
Training loss: 0.12119018286466599
Validation loss: 1.5474673176324496

Epoch: 6| Step: 7
Training loss: 0.05395061522722244
Validation loss: 1.5368308405722342

Epoch: 6| Step: 8
Training loss: 0.075095534324646
Validation loss: 1.549457420584976

Epoch: 6| Step: 9
Training loss: 0.10389204323291779
Validation loss: 1.5048007452359764

Epoch: 6| Step: 10
Training loss: 0.12437925487756729
Validation loss: 1.5131018225864699

Epoch: 6| Step: 11
Training loss: 0.08666893094778061
Validation loss: 1.5073958648148404

Epoch: 6| Step: 12
Training loss: 0.07521176338195801
Validation loss: 1.5256109827308244

Epoch: 6| Step: 13
Training loss: 0.04272586479783058
Validation loss: 1.4981621003920031

Epoch: 548| Step: 0
Training loss: 0.05633752420544624
Validation loss: 1.530028163745839

Epoch: 6| Step: 1
Training loss: 0.08245553821325302
Validation loss: 1.5494043916784308

Epoch: 6| Step: 2
Training loss: 0.0855899378657341
Validation loss: 1.5526429478840162

Epoch: 6| Step: 3
Training loss: 0.09961742907762527
Validation loss: 1.55750399251138

Epoch: 6| Step: 4
Training loss: 0.08122272044420242
Validation loss: 1.575680576344972

Epoch: 6| Step: 5
Training loss: 0.05407004803419113
Validation loss: 1.5532035878909531

Epoch: 6| Step: 6
Training loss: 0.08199211210012436
Validation loss: 1.5574707805469472

Epoch: 6| Step: 7
Training loss: 0.0688670203089714
Validation loss: 1.5463869917777278

Epoch: 6| Step: 8
Training loss: 0.06109314784407616
Validation loss: 1.545854631290641

Epoch: 6| Step: 9
Training loss: 0.09807179868221283
Validation loss: 1.5516804251619565

Epoch: 6| Step: 10
Training loss: 0.0707804411649704
Validation loss: 1.5328273465556483

Epoch: 6| Step: 11
Training loss: 0.06162802875041962
Validation loss: 1.5284179436263217

Epoch: 6| Step: 12
Training loss: 0.11282642185688019
Validation loss: 1.509941085692375

Epoch: 6| Step: 13
Training loss: 0.039831165224313736
Validation loss: 1.5094316210798038

Epoch: 549| Step: 0
Training loss: 0.0856194794178009
Validation loss: 1.497985751398148

Epoch: 6| Step: 1
Training loss: 0.05173049867153168
Validation loss: 1.4856550308965868

Epoch: 6| Step: 2
Training loss: 0.12207196652889252
Validation loss: 1.492202620352468

Epoch: 6| Step: 3
Training loss: 0.06823927164077759
Validation loss: 1.491961540714387

Epoch: 6| Step: 4
Training loss: 0.06657130271196365
Validation loss: 1.4820296258054755

Epoch: 6| Step: 5
Training loss: 0.07416993379592896
Validation loss: 1.4978915170956684

Epoch: 6| Step: 6
Training loss: 0.08885689079761505
Validation loss: 1.4966476053319953

Epoch: 6| Step: 7
Training loss: 0.06466919928789139
Validation loss: 1.4973451809216571

Epoch: 6| Step: 8
Training loss: 0.07668817043304443
Validation loss: 1.5105271557325959

Epoch: 6| Step: 9
Training loss: 0.05072881281375885
Validation loss: 1.506817094741329

Epoch: 6| Step: 10
Training loss: 0.05310070887207985
Validation loss: 1.5357258166036298

Epoch: 6| Step: 11
Training loss: 0.061640720814466476
Validation loss: 1.5187958517382223

Epoch: 6| Step: 12
Training loss: 0.08895982801914215
Validation loss: 1.5182869588175127

Epoch: 6| Step: 13
Training loss: 0.11457943916320801
Validation loss: 1.5079430149447532

Epoch: 550| Step: 0
Training loss: 0.07510720193386078
Validation loss: 1.5362980532389816

Epoch: 6| Step: 1
Training loss: 0.04675845056772232
Validation loss: 1.5190686448927848

Epoch: 6| Step: 2
Training loss: 0.06698911637067795
Validation loss: 1.5432243693259455

Epoch: 6| Step: 3
Training loss: 0.07368230819702148
Validation loss: 1.5158901996510004

Epoch: 6| Step: 4
Training loss: 0.06369303166866302
Validation loss: 1.521935889797826

Epoch: 6| Step: 5
Training loss: 0.08317214250564575
Validation loss: 1.5332268309849564

Epoch: 6| Step: 6
Training loss: 0.09499682486057281
Validation loss: 1.533619701221425

Epoch: 6| Step: 7
Training loss: 0.10214752703905106
Validation loss: 1.5302612537978797

Epoch: 6| Step: 8
Training loss: 0.0946204885840416
Validation loss: 1.531470303894371

Epoch: 6| Step: 9
Training loss: 0.07592223584651947
Validation loss: 1.5137974293001237

Epoch: 6| Step: 10
Training loss: 0.07230056822299957
Validation loss: 1.5319730530502975

Epoch: 6| Step: 11
Training loss: 0.07997536659240723
Validation loss: 1.5103505401201145

Epoch: 6| Step: 12
Training loss: 0.11191669851541519
Validation loss: 1.5112189374944216

Epoch: 6| Step: 13
Training loss: 0.06796720623970032
Validation loss: 1.521509826183319

Testing loss: 2.1981854756673176
